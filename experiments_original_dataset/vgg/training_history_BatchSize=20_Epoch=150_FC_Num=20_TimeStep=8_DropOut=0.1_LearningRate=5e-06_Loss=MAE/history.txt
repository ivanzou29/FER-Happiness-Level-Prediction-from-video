Epoch: 1| Step: 0
Training loss: 4.301507949829102
Validation loss: 4.204386532306671

Epoch: 5| Step: 1
Training loss: 5.040106296539307
Validation loss: 4.1880457401275635

Epoch: 5| Step: 2
Training loss: 3.58253812789917
Validation loss: 4.160514374574025

Epoch: 5| Step: 3
Training loss: 3.8192954063415527
Validation loss: 4.141961912314097

Epoch: 5| Step: 4
Training loss: 4.301520347595215
Validation loss: 4.118901968002319

Epoch: 5| Step: 5
Training loss: 4.273604393005371
Validation loss: 4.101129452387492

Epoch: 5| Step: 6
Training loss: 3.621572494506836
Validation loss: 4.084348142147064

Epoch: 5| Step: 7
Training loss: 4.557602882385254
Validation loss: 4.066938698291779

Epoch: 5| Step: 8
Training loss: 4.246687412261963
Validation loss: 4.04856010278066

Epoch: 5| Step: 9
Training loss: 3.766324996948242
Validation loss: 4.0300487379233045

Epoch: 5| Step: 10
Training loss: 4.985904216766357
Validation loss: 4.008016298214595

Epoch: 5| Step: 11
Training loss: 4.812867641448975
Validation loss: 3.984575172265371

Epoch: 2| Step: 0
Training loss: 4.499980449676514
Validation loss: 3.957303822040558

Epoch: 5| Step: 1
Training loss: 4.509313583374023
Validation loss: 3.9381196995576224

Epoch: 5| Step: 2
Training loss: 4.096118927001953
Validation loss: 3.9151042799154916

Epoch: 5| Step: 3
Training loss: 3.6945736408233643
Validation loss: 3.896175970633825

Epoch: 5| Step: 4
Training loss: 3.6180031299591064
Validation loss: 3.8700953920682273

Epoch: 5| Step: 5
Training loss: 4.716695308685303
Validation loss: 3.8461879591147103

Epoch: 5| Step: 6
Training loss: 4.047603607177734
Validation loss: 3.8218796948591867

Epoch: 5| Step: 7
Training loss: 2.815469980239868
Validation loss: 3.7957405149936676

Epoch: 5| Step: 8
Training loss: 3.484724521636963
Validation loss: 3.761369615793228

Epoch: 5| Step: 9
Training loss: 4.100042819976807
Validation loss: 3.742039829492569

Epoch: 5| Step: 10
Training loss: 4.251034736633301
Validation loss: 3.714844395716985

Epoch: 5| Step: 11
Training loss: 3.1881253719329834
Validation loss: 3.679384837547938

Epoch: 3| Step: 0
Training loss: 3.3536605834960938
Validation loss: 3.6511851251125336

Epoch: 5| Step: 1
Training loss: 4.385031700134277
Validation loss: 3.6181711753209433

Epoch: 5| Step: 2
Training loss: 3.4330894947052
Validation loss: 3.583355983098348

Epoch: 5| Step: 3
Training loss: 3.5893402099609375
Validation loss: 3.537401298681895

Epoch: 5| Step: 4
Training loss: 4.401010990142822
Validation loss: 3.513601154088974

Epoch: 5| Step: 5
Training loss: 2.510200023651123
Validation loss: 3.471970856189728

Epoch: 5| Step: 6
Training loss: 3.847968578338623
Validation loss: 3.432008534669876

Epoch: 5| Step: 7
Training loss: 3.752194881439209
Validation loss: 3.3880401154359183

Epoch: 5| Step: 8
Training loss: 3.9231369495391846
Validation loss: 3.355949262777964

Epoch: 5| Step: 9
Training loss: 3.0950984954833984
Validation loss: 3.3097068766752877

Epoch: 5| Step: 10
Training loss: 3.0655550956726074
Validation loss: 3.26576691865921

Epoch: 5| Step: 11
Training loss: 4.188158988952637
Validation loss: 3.213384876648585

Epoch: 4| Step: 0
Training loss: 3.903787612915039
Validation loss: 3.170831690231959

Epoch: 5| Step: 1
Training loss: 3.5238430500030518
Validation loss: 3.128687024116516

Epoch: 5| Step: 2
Training loss: 2.382669687271118
Validation loss: 3.061065604289373

Epoch: 5| Step: 3
Training loss: 2.714916706085205
Validation loss: 3.0110654135545096

Epoch: 5| Step: 4
Training loss: 3.1063780784606934
Validation loss: 2.962133377790451

Epoch: 5| Step: 5
Training loss: 3.4917945861816406
Validation loss: 2.9082719584306083

Epoch: 5| Step: 6
Training loss: 2.3167452812194824
Validation loss: 2.840397705634435

Epoch: 5| Step: 7
Training loss: 2.6671500205993652
Validation loss: 2.7952351172765098

Epoch: 5| Step: 8
Training loss: 3.4703235626220703
Validation loss: 2.725747843583425

Epoch: 5| Step: 9
Training loss: 2.9055590629577637
Validation loss: 2.6551967163880668

Epoch: 5| Step: 10
Training loss: 2.313286781311035
Validation loss: 2.590711255868276

Epoch: 5| Step: 11
Training loss: 2.278247833251953
Validation loss: 2.540523240963618

Epoch: 5| Step: 0
Training loss: 2.833296537399292
Validation loss: 2.4694874385992684

Epoch: 5| Step: 1
Training loss: 2.1203176975250244
Validation loss: 2.420848935842514

Epoch: 5| Step: 2
Training loss: 2.510654926300049
Validation loss: 2.3636206487814584

Epoch: 5| Step: 3
Training loss: 2.146202802658081
Validation loss: 2.313831811149915

Epoch: 5| Step: 4
Training loss: 2.3330273628234863
Validation loss: 2.2775472551584244

Epoch: 5| Step: 5
Training loss: 1.849409818649292
Validation loss: 2.247805883487066

Epoch: 5| Step: 6
Training loss: 2.035457134246826
Validation loss: 2.1926866869131723

Epoch: 5| Step: 7
Training loss: 2.629488468170166
Validation loss: 2.1547788083553314

Epoch: 5| Step: 8
Training loss: 2.263530731201172
Validation loss: 2.128467629353205

Epoch: 5| Step: 9
Training loss: 1.9509093761444092
Validation loss: 2.147987976670265

Epoch: 5| Step: 10
Training loss: 2.0538957118988037
Validation loss: 2.1407152861356735

Epoch: 5| Step: 11
Training loss: 2.1820526123046875
Validation loss: 2.1539565920829773

Epoch: 6| Step: 0
Training loss: 2.9778590202331543
Validation loss: 2.15214604139328

Epoch: 5| Step: 1
Training loss: 1.624895453453064
Validation loss: 2.1488940119743347

Epoch: 5| Step: 2
Training loss: 2.456353187561035
Validation loss: 2.185213734706243

Epoch: 5| Step: 3
Training loss: 2.5189759731292725
Validation loss: 2.19336074590683

Epoch: 5| Step: 4
Training loss: 2.4806928634643555
Validation loss: 2.1806724270184836

Epoch: 5| Step: 5
Training loss: 1.9603828191757202
Validation loss: 2.1669079860051474

Epoch: 5| Step: 6
Training loss: 1.9417022466659546
Validation loss: 2.1915623943010965

Epoch: 5| Step: 7
Training loss: 1.2822376489639282
Validation loss: 2.164872646331787

Epoch: 5| Step: 8
Training loss: 2.1976444721221924
Validation loss: 2.1569785873095193

Epoch: 5| Step: 9
Training loss: 2.313206195831299
Validation loss: 2.1444828609625497

Epoch: 5| Step: 10
Training loss: 2.0712814331054688
Validation loss: 2.1506307125091553

Epoch: 5| Step: 11
Training loss: 0.9698152542114258
Validation loss: 2.1348300874233246

Epoch: 7| Step: 0
Training loss: 2.1846985816955566
Validation loss: 2.1369813779989877

Epoch: 5| Step: 1
Training loss: 1.8630813360214233
Validation loss: 2.1297420461972556

Epoch: 5| Step: 2
Training loss: 2.0070862770080566
Validation loss: 2.1083012421925864

Epoch: 5| Step: 3
Training loss: 2.3028409481048584
Validation loss: 2.148145834604899

Epoch: 5| Step: 4
Training loss: 1.6672942638397217
Validation loss: 2.1199388752381005

Epoch: 5| Step: 5
Training loss: 1.918989896774292
Validation loss: 2.1057151903708777

Epoch: 5| Step: 6
Training loss: 2.199331045150757
Validation loss: 2.125885089238485

Epoch: 5| Step: 7
Training loss: 2.5605645179748535
Validation loss: 2.1396972437699637

Epoch: 5| Step: 8
Training loss: 2.3962271213531494
Validation loss: 2.1473224610090256

Epoch: 5| Step: 9
Training loss: 2.058096408843994
Validation loss: 2.127484599749247

Epoch: 5| Step: 10
Training loss: 2.1081488132476807
Validation loss: 2.128436471025149

Epoch: 5| Step: 11
Training loss: 2.0601305961608887
Validation loss: 2.1468645632267

Epoch: 8| Step: 0
Training loss: 2.2644124031066895
Validation loss: 2.1190573970476785

Epoch: 5| Step: 1
Training loss: 1.99734628200531
Validation loss: 2.130930617451668

Epoch: 5| Step: 2
Training loss: 2.6378142833709717
Validation loss: 2.1171301156282425

Epoch: 5| Step: 3
Training loss: 1.6352424621582031
Validation loss: 2.110147178173065

Epoch: 5| Step: 4
Training loss: 2.064706325531006
Validation loss: 2.1221952786048255

Epoch: 5| Step: 5
Training loss: 1.491898775100708
Validation loss: 2.1145941813786826

Epoch: 5| Step: 6
Training loss: 2.638828992843628
Validation loss: 2.1141914476950965

Epoch: 5| Step: 7
Training loss: 1.89315664768219
Validation loss: 2.130458707610766

Epoch: 5| Step: 8
Training loss: 2.3897039890289307
Validation loss: 2.1142404824495316

Epoch: 5| Step: 9
Training loss: 2.122898578643799
Validation loss: 2.1014707485834756

Epoch: 5| Step: 10
Training loss: 1.992393136024475
Validation loss: 2.119193365176519

Epoch: 5| Step: 11
Training loss: 1.8089349269866943
Validation loss: 2.1361200561126075

Epoch: 9| Step: 0
Training loss: 2.042151927947998
Validation loss: 2.1308874438206353

Epoch: 5| Step: 1
Training loss: 2.093410015106201
Validation loss: 2.1316386063893638

Epoch: 5| Step: 2
Training loss: 2.1149182319641113
Validation loss: 2.1279716193675995

Epoch: 5| Step: 3
Training loss: 2.5244126319885254
Validation loss: 2.129638448357582

Epoch: 5| Step: 4
Training loss: 1.9747769832611084
Validation loss: 2.1190988272428513

Epoch: 5| Step: 5
Training loss: 2.1612067222595215
Validation loss: 2.1087715526421866

Epoch: 5| Step: 6
Training loss: 2.0293965339660645
Validation loss: 2.1148850421110788

Epoch: 5| Step: 7
Training loss: 2.3025403022766113
Validation loss: 2.1155128180980682

Epoch: 5| Step: 8
Training loss: 2.1170685291290283
Validation loss: 2.1194088757038116

Epoch: 5| Step: 9
Training loss: 1.9170806407928467
Validation loss: 2.134483461578687

Epoch: 5| Step: 10
Training loss: 1.8286302089691162
Validation loss: 2.128057047724724

Epoch: 5| Step: 11
Training loss: 1.8913309574127197
Validation loss: 2.114017575979233

Epoch: 10| Step: 0
Training loss: 1.644213318824768
Validation loss: 2.1267231702804565

Epoch: 5| Step: 1
Training loss: 2.099642276763916
Validation loss: 2.110443597038587

Epoch: 5| Step: 2
Training loss: 2.4972376823425293
Validation loss: 2.1467665334542594

Epoch: 5| Step: 3
Training loss: 2.528961181640625
Validation loss: 2.124081244071325

Epoch: 5| Step: 4
Training loss: 2.3319756984710693
Validation loss: 2.1648971488078437

Epoch: 5| Step: 5
Training loss: 1.4417105913162231
Validation loss: 2.1312200725078583

Epoch: 5| Step: 6
Training loss: 2.22200345993042
Validation loss: 2.119524816672007

Epoch: 5| Step: 7
Training loss: 2.0702712535858154
Validation loss: 2.119904339313507

Epoch: 5| Step: 8
Training loss: 2.044329881668091
Validation loss: 2.1235109120607376

Epoch: 5| Step: 9
Training loss: 2.238558292388916
Validation loss: 2.128298526008924

Epoch: 5| Step: 10
Training loss: 1.6216630935668945
Validation loss: 2.114250789086024

Epoch: 5| Step: 11
Training loss: 3.099721908569336
Validation loss: 2.143433153629303

Epoch: 11| Step: 0
Training loss: 1.8368648290634155
Validation loss: 2.0973521918058395

Epoch: 5| Step: 1
Training loss: 1.8231350183486938
Validation loss: 2.1043978234132132

Epoch: 5| Step: 2
Training loss: 2.213780164718628
Validation loss: 2.1243600895007453

Epoch: 5| Step: 3
Training loss: 2.1897568702697754
Validation loss: 2.0951122542222342

Epoch: 5| Step: 4
Training loss: 2.3239121437072754
Validation loss: 2.104315678278605

Epoch: 5| Step: 5
Training loss: 2.022946357727051
Validation loss: 2.102449198563894

Epoch: 5| Step: 6
Training loss: 2.83437180519104
Validation loss: 2.1090322732925415

Epoch: 5| Step: 7
Training loss: 1.4937242269515991
Validation loss: 2.1132871309916177

Epoch: 5| Step: 8
Training loss: 2.1098453998565674
Validation loss: 2.1217669248580933

Epoch: 5| Step: 9
Training loss: 2.076411008834839
Validation loss: 2.094412977496783

Epoch: 5| Step: 10
Training loss: 2.130337953567505
Validation loss: 2.0627691745758057

Epoch: 5| Step: 11
Training loss: 2.0648880004882812
Validation loss: 2.1253268818060556

Epoch: 12| Step: 0
Training loss: 1.924034833908081
Validation loss: 2.115498185157776

Epoch: 5| Step: 1
Training loss: 2.2184338569641113
Validation loss: 2.110313599308332

Epoch: 5| Step: 2
Training loss: 2.065486431121826
Validation loss: 2.099613517522812

Epoch: 5| Step: 3
Training loss: 1.836460828781128
Validation loss: 2.099338377515475

Epoch: 5| Step: 4
Training loss: 2.0489063262939453
Validation loss: 2.10063074529171

Epoch: 5| Step: 5
Training loss: 1.9086179733276367
Validation loss: 2.102078835169474

Epoch: 5| Step: 6
Training loss: 2.405317544937134
Validation loss: 2.0958554595708847

Epoch: 5| Step: 7
Training loss: 1.623011589050293
Validation loss: 2.111202210187912

Epoch: 5| Step: 8
Training loss: 2.853757381439209
Validation loss: 2.081703762213389

Epoch: 5| Step: 9
Training loss: 2.494387149810791
Validation loss: 2.0994833459456763

Epoch: 5| Step: 10
Training loss: 1.5156646966934204
Validation loss: 2.083271771669388

Epoch: 5| Step: 11
Training loss: 1.9863746166229248
Validation loss: 2.1047247449556985

Epoch: 13| Step: 0
Training loss: 1.9245092868804932
Validation loss: 2.1000909755627313

Epoch: 5| Step: 1
Training loss: 1.8827788829803467
Validation loss: 2.0930666824181876

Epoch: 5| Step: 2
Training loss: 2.9525370597839355
Validation loss: 2.0944982767105103

Epoch: 5| Step: 3
Training loss: 1.3840285539627075
Validation loss: 2.084640309214592

Epoch: 5| Step: 4
Training loss: 2.0895330905914307
Validation loss: 2.093239188194275

Epoch: 5| Step: 5
Training loss: 2.1266090869903564
Validation loss: 2.1147634039322534

Epoch: 5| Step: 6
Training loss: 2.3425564765930176
Validation loss: 2.100978990395864

Epoch: 5| Step: 7
Training loss: 2.365875005722046
Validation loss: 2.0954621036847434

Epoch: 5| Step: 8
Training loss: 1.7398313283920288
Validation loss: 2.070616920789083

Epoch: 5| Step: 9
Training loss: 2.1806280612945557
Validation loss: 2.1054231921831765

Epoch: 5| Step: 10
Training loss: 1.7806094884872437
Validation loss: 2.085203389326731

Epoch: 5| Step: 11
Training loss: 2.6253530979156494
Validation loss: 2.090907484292984

Epoch: 14| Step: 0
Training loss: 2.0549845695495605
Validation loss: 2.093000610669454

Epoch: 5| Step: 1
Training loss: 1.6319490671157837
Validation loss: 2.100741113225619

Epoch: 5| Step: 2
Training loss: 2.3091506958007812
Validation loss: 2.0747726062933602

Epoch: 5| Step: 3
Training loss: 1.8628947734832764
Validation loss: 2.062388608853022

Epoch: 5| Step: 4
Training loss: 2.021730661392212
Validation loss: 2.0921751111745834

Epoch: 5| Step: 5
Training loss: 2.065570831298828
Validation loss: 2.0983379185199738

Epoch: 5| Step: 6
Training loss: 2.115691661834717
Validation loss: 2.0777277648448944

Epoch: 5| Step: 7
Training loss: 2.414691925048828
Validation loss: 2.068456227580706

Epoch: 5| Step: 8
Training loss: 1.9382919073104858
Validation loss: 2.0855629046758017

Epoch: 5| Step: 9
Training loss: 2.5895862579345703
Validation loss: 2.06770812968413

Epoch: 5| Step: 10
Training loss: 1.550485372543335
Validation loss: 2.0957524428764978

Epoch: 5| Step: 11
Training loss: 2.8541998863220215
Validation loss: 2.061550796031952

Epoch: 15| Step: 0
Training loss: 1.7628252506256104
Validation loss: 2.0834793547789254

Epoch: 5| Step: 1
Training loss: 1.8794997930526733
Validation loss: 2.117421348889669

Epoch: 5| Step: 2
Training loss: 1.8784964084625244
Validation loss: 2.0868997822205224

Epoch: 5| Step: 3
Training loss: 1.8191173076629639
Validation loss: 2.0721798042456308

Epoch: 5| Step: 4
Training loss: 2.1789321899414062
Validation loss: 2.0824946214755378

Epoch: 5| Step: 5
Training loss: 2.1430277824401855
Validation loss: 2.062180851896604

Epoch: 5| Step: 6
Training loss: 2.650705575942993
Validation loss: 2.0865180989106498

Epoch: 5| Step: 7
Training loss: 2.256136655807495
Validation loss: 2.07565708955129

Epoch: 5| Step: 8
Training loss: 1.9768915176391602
Validation loss: 2.0665820290644965

Epoch: 5| Step: 9
Training loss: 2.3469367027282715
Validation loss: 2.0807204792896905

Epoch: 5| Step: 10
Training loss: 1.714369535446167
Validation loss: 2.0788783778746924

Epoch: 5| Step: 11
Training loss: 2.2931675910949707
Validation loss: 2.0805533826351166

Epoch: 16| Step: 0
Training loss: 2.0972485542297363
Validation loss: 2.0860562870899835

Epoch: 5| Step: 1
Training loss: 1.8787037134170532
Validation loss: 2.071739991505941

Epoch: 5| Step: 2
Training loss: 2.6030845642089844
Validation loss: 2.0739959329366684

Epoch: 5| Step: 3
Training loss: 2.558964252471924
Validation loss: 2.0776845614115396

Epoch: 5| Step: 4
Training loss: 1.8058936595916748
Validation loss: 2.1179181089003882

Epoch: 5| Step: 5
Training loss: 2.4002857208251953
Validation loss: 2.0631515135367713

Epoch: 5| Step: 6
Training loss: 2.5831661224365234
Validation loss: 2.0868622809648514

Epoch: 5| Step: 7
Training loss: 1.8973029851913452
Validation loss: 2.0780810167392096

Epoch: 5| Step: 8
Training loss: 1.574096441268921
Validation loss: 2.068143015106519

Epoch: 5| Step: 9
Training loss: 1.5440877676010132
Validation loss: 2.093078171213468

Epoch: 5| Step: 10
Training loss: 1.6235097646713257
Validation loss: 2.082357575496038

Epoch: 5| Step: 11
Training loss: 1.7060219049453735
Validation loss: 2.082253580292066

Epoch: 17| Step: 0
Training loss: 1.2496782541275024
Validation loss: 2.0756106277306876

Epoch: 5| Step: 1
Training loss: 2.2716643810272217
Validation loss: 2.0616547564665475

Epoch: 5| Step: 2
Training loss: 1.6595615148544312
Validation loss: 2.0572361250718436

Epoch: 5| Step: 3
Training loss: 2.2425711154937744
Validation loss: 2.095008904735247

Epoch: 5| Step: 4
Training loss: 2.247671604156494
Validation loss: 2.076716015736262

Epoch: 5| Step: 5
Training loss: 2.2660534381866455
Validation loss: 2.06854680677255

Epoch: 5| Step: 6
Training loss: 2.288703680038452
Validation loss: 2.0727688372135162

Epoch: 5| Step: 7
Training loss: 2.308199405670166
Validation loss: 2.0458170672257743

Epoch: 5| Step: 8
Training loss: 1.5911781787872314
Validation loss: 2.058061564962069

Epoch: 5| Step: 9
Training loss: 2.65265154838562
Validation loss: 2.0840225517749786

Epoch: 5| Step: 10
Training loss: 1.7557752132415771
Validation loss: 2.0296500275532403

Epoch: 5| Step: 11
Training loss: 1.2910127639770508
Validation loss: 2.0618826846281686

Epoch: 18| Step: 0
Training loss: 1.936022400856018
Validation loss: 2.0646693259477615

Epoch: 5| Step: 1
Training loss: 2.280921220779419
Validation loss: 2.06497930486997

Epoch: 5| Step: 2
Training loss: 2.2862677574157715
Validation loss: 2.0919081221024194

Epoch: 5| Step: 3
Training loss: 2.0907912254333496
Validation loss: 2.074830641349157

Epoch: 5| Step: 4
Training loss: 2.761260509490967
Validation loss: 2.0824504842360816

Epoch: 5| Step: 5
Training loss: 1.834543228149414
Validation loss: 2.0807644377152124

Epoch: 5| Step: 6
Training loss: 1.8049169778823853
Validation loss: 2.0691281457742057

Epoch: 5| Step: 7
Training loss: 2.43326997756958
Validation loss: 2.066098839044571

Epoch: 5| Step: 8
Training loss: 1.684091567993164
Validation loss: 2.0786246756712594

Epoch: 5| Step: 9
Training loss: 1.5753867626190186
Validation loss: 2.063229883710543

Epoch: 5| Step: 10
Training loss: 1.89511239528656
Validation loss: 2.0664925972620645

Epoch: 5| Step: 11
Training loss: 1.0775880813598633
Validation loss: 2.0610704173644385

Epoch: 19| Step: 0
Training loss: 2.1479923725128174
Validation loss: 2.0842397709687552

Epoch: 5| Step: 1
Training loss: 2.028499126434326
Validation loss: 2.087896297375361

Epoch: 5| Step: 2
Training loss: 1.930659532546997
Validation loss: 2.0497545301914215

Epoch: 5| Step: 3
Training loss: 2.023542642593384
Validation loss: 2.091884767015775

Epoch: 5| Step: 4
Training loss: 1.6901448965072632
Validation loss: 2.0649365733067193

Epoch: 5| Step: 5
Training loss: 2.218931198120117
Validation loss: 2.0874940156936646

Epoch: 5| Step: 6
Training loss: 2.2937827110290527
Validation loss: 2.0673182606697083

Epoch: 5| Step: 7
Training loss: 2.239306926727295
Validation loss: 2.074212913711866

Epoch: 5| Step: 8
Training loss: 1.4415332078933716
Validation loss: 2.0583816717068353

Epoch: 5| Step: 9
Training loss: 2.370614767074585
Validation loss: 2.0776038070519767

Epoch: 5| Step: 10
Training loss: 1.909314751625061
Validation loss: 2.0546909173329673

Epoch: 5| Step: 11
Training loss: 2.4765892028808594
Validation loss: 2.0496114691098533

Epoch: 20| Step: 0
Training loss: 1.7551511526107788
Validation loss: 2.0326605141162872

Epoch: 5| Step: 1
Training loss: 2.175746440887451
Validation loss: 2.0625183333953223

Epoch: 5| Step: 2
Training loss: 2.069481134414673
Validation loss: 2.058205857872963

Epoch: 5| Step: 3
Training loss: 1.9680211544036865
Validation loss: 2.028503735860189

Epoch: 5| Step: 4
Training loss: 2.0968356132507324
Validation loss: 2.032514343659083

Epoch: 5| Step: 5
Training loss: 1.8516712188720703
Validation loss: 2.0517164369424186

Epoch: 5| Step: 6
Training loss: 1.9931799173355103
Validation loss: 2.057417949040731

Epoch: 5| Step: 7
Training loss: 1.9405549764633179
Validation loss: 2.029382959008217

Epoch: 5| Step: 8
Training loss: 2.183762788772583
Validation loss: 2.066470439235369

Epoch: 5| Step: 9
Training loss: 2.2035367488861084
Validation loss: 2.0352071722348533

Epoch: 5| Step: 10
Training loss: 1.9206523895263672
Validation loss: 2.0409881323575974

Epoch: 5| Step: 11
Training loss: 2.430417060852051
Validation loss: 2.0498306502898536

Epoch: 21| Step: 0
Training loss: 2.2167611122131348
Validation loss: 2.033435265223185

Epoch: 5| Step: 1
Training loss: 2.6839165687561035
Validation loss: 2.0585308521986008

Epoch: 5| Step: 2
Training loss: 2.0431456565856934
Validation loss: 2.0751033226648965

Epoch: 5| Step: 3
Training loss: 1.4550206661224365
Validation loss: 2.0445264925559363

Epoch: 5| Step: 4
Training loss: 1.6951382160186768
Validation loss: 2.078786537051201

Epoch: 5| Step: 5
Training loss: 2.068389892578125
Validation loss: 2.0619266033172607

Epoch: 5| Step: 6
Training loss: 2.214022159576416
Validation loss: 2.086459130048752

Epoch: 5| Step: 7
Training loss: 2.2307446002960205
Validation loss: 2.079116851091385

Epoch: 5| Step: 8
Training loss: 1.5579885244369507
Validation loss: 2.0621790339549384

Epoch: 5| Step: 9
Training loss: 2.1116139888763428
Validation loss: 2.069127375880877

Epoch: 5| Step: 10
Training loss: 2.0594351291656494
Validation loss: 2.061809187134107

Epoch: 5| Step: 11
Training loss: 2.683579206466675
Validation loss: 2.0600764602422714

Epoch: 22| Step: 0
Training loss: 1.9936507940292358
Validation loss: 2.0606700032949448

Epoch: 5| Step: 1
Training loss: 2.015862226486206
Validation loss: 2.037571753064791

Epoch: 5| Step: 2
Training loss: 1.5421640872955322
Validation loss: 2.0684166004260383

Epoch: 5| Step: 3
Training loss: 2.184753179550171
Validation loss: 2.032713398337364

Epoch: 5| Step: 4
Training loss: 2.0257763862609863
Validation loss: 2.0531034419933953

Epoch: 5| Step: 5
Training loss: 2.3919084072113037
Validation loss: 2.047019898891449

Epoch: 5| Step: 6
Training loss: 1.6269906759262085
Validation loss: 2.033420647184054

Epoch: 5| Step: 7
Training loss: 2.023172378540039
Validation loss: 2.0587611397107444

Epoch: 5| Step: 8
Training loss: 2.564551591873169
Validation loss: 2.0374663720528283

Epoch: 5| Step: 9
Training loss: 2.064547300338745
Validation loss: 2.0485916435718536

Epoch: 5| Step: 10
Training loss: 1.846515417098999
Validation loss: 2.044255385796229

Epoch: 5| Step: 11
Training loss: 1.7818400859832764
Validation loss: 2.047252615292867

Epoch: 23| Step: 0
Training loss: 1.9054549932479858
Validation loss: 2.0306798915068307

Epoch: 5| Step: 1
Training loss: 1.8349355459213257
Validation loss: 2.026815270384153

Epoch: 5| Step: 2
Training loss: 2.3585104942321777
Validation loss: 2.061318968733152

Epoch: 5| Step: 3
Training loss: 2.5590853691101074
Validation loss: 2.049983104070028

Epoch: 5| Step: 4
Training loss: 1.8073418140411377
Validation loss: 2.046469127138456

Epoch: 5| Step: 5
Training loss: 2.197497606277466
Validation loss: 2.004152854283651

Epoch: 5| Step: 6
Training loss: 2.013244152069092
Validation loss: 2.0379545191923776

Epoch: 5| Step: 7
Training loss: 1.8024914264678955
Validation loss: 2.0527894298235574

Epoch: 5| Step: 8
Training loss: 1.7334873676300049
Validation loss: 2.0621997167666755

Epoch: 5| Step: 9
Training loss: 1.9183309078216553
Validation loss: 2.0257324477036796

Epoch: 5| Step: 10
Training loss: 1.528841257095337
Validation loss: 2.0376058171192803

Epoch: 5| Step: 11
Training loss: 5.1747636795043945
Validation loss: 2.036785920461019

Epoch: 24| Step: 0
Training loss: 1.672645926475525
Validation loss: 2.010444680849711

Epoch: 5| Step: 1
Training loss: 1.8615188598632812
Validation loss: 2.031255309780439

Epoch: 5| Step: 2
Training loss: 2.369129180908203
Validation loss: 2.0361115535100303

Epoch: 5| Step: 3
Training loss: 1.8071660995483398
Validation loss: 2.0414276669422784

Epoch: 5| Step: 4
Training loss: 2.1183853149414062
Validation loss: 2.054826701680819

Epoch: 5| Step: 5
Training loss: 2.1618809700012207
Validation loss: 2.0438431203365326

Epoch: 5| Step: 6
Training loss: 1.8033390045166016
Validation loss: 2.0628037452697754

Epoch: 5| Step: 7
Training loss: 1.95745050907135
Validation loss: 2.0311480363210044

Epoch: 5| Step: 8
Training loss: 1.5746201276779175
Validation loss: 2.058806598186493

Epoch: 5| Step: 9
Training loss: 2.6085093021392822
Validation loss: 2.0573656111955643

Epoch: 5| Step: 10
Training loss: 2.1942532062530518
Validation loss: 2.042876978715261

Epoch: 5| Step: 11
Training loss: 1.9827269315719604
Validation loss: 2.033323665459951

Epoch: 25| Step: 0
Training loss: 2.4873814582824707
Validation loss: 2.02681502699852

Epoch: 5| Step: 1
Training loss: 1.632757544517517
Validation loss: 2.0561471233765283

Epoch: 5| Step: 2
Training loss: 2.093817949295044
Validation loss: 2.0236510733763375

Epoch: 5| Step: 3
Training loss: 2.223930835723877
Validation loss: 2.0300528407096863

Epoch: 5| Step: 4
Training loss: 1.2600071430206299
Validation loss: 2.0635987718900046

Epoch: 5| Step: 5
Training loss: 2.1497857570648193
Validation loss: 2.0223326037327447

Epoch: 5| Step: 6
Training loss: 1.947899580001831
Validation loss: 2.0425661305586496

Epoch: 5| Step: 7
Training loss: 1.7075554132461548
Validation loss: 2.0661237786213555

Epoch: 5| Step: 8
Training loss: 1.9431740045547485
Validation loss: 2.0500019590059915

Epoch: 5| Step: 9
Training loss: 2.4045073986053467
Validation loss: 2.0448038081328073

Epoch: 5| Step: 10
Training loss: 2.4007887840270996
Validation loss: 2.052620311578115

Epoch: 5| Step: 11
Training loss: 1.4337315559387207
Validation loss: 2.037209004163742

Epoch: 26| Step: 0
Training loss: 2.628669023513794
Validation loss: 2.065832922856013

Epoch: 5| Step: 1
Training loss: 2.568857192993164
Validation loss: 2.0445723980665207

Epoch: 5| Step: 2
Training loss: 1.5705722570419312
Validation loss: 2.059339687228203

Epoch: 5| Step: 3
Training loss: 1.991015076637268
Validation loss: 2.0542336801687875

Epoch: 5| Step: 4
Training loss: 1.920413613319397
Validation loss: 2.0558658093214035

Epoch: 5| Step: 5
Training loss: 2.0479183197021484
Validation loss: 2.071130389968554

Epoch: 5| Step: 6
Training loss: 2.3954386711120605
Validation loss: 2.0347185929616294

Epoch: 5| Step: 7
Training loss: 1.4776537418365479
Validation loss: 2.0112525075674057

Epoch: 5| Step: 8
Training loss: 2.310659408569336
Validation loss: 2.013270710905393

Epoch: 5| Step: 9
Training loss: 1.6617014408111572
Validation loss: 2.024083971977234

Epoch: 5| Step: 10
Training loss: 1.5722031593322754
Validation loss: 2.030842492977778

Epoch: 5| Step: 11
Training loss: 1.277133584022522
Validation loss: 2.034597764412562

Epoch: 27| Step: 0
Training loss: 1.6902453899383545
Validation loss: 2.007931331793467

Epoch: 5| Step: 1
Training loss: 2.303086519241333
Validation loss: 2.051799158255259

Epoch: 5| Step: 2
Training loss: 1.8031902313232422
Validation loss: 2.04034390548865

Epoch: 5| Step: 3
Training loss: 1.8217674493789673
Validation loss: 2.0463862319787345

Epoch: 5| Step: 4
Training loss: 2.642570734024048
Validation loss: 2.0289981414874396

Epoch: 5| Step: 5
Training loss: 2.389504909515381
Validation loss: 2.042845924695333

Epoch: 5| Step: 6
Training loss: 1.8989953994750977
Validation loss: 2.0684319734573364

Epoch: 5| Step: 7
Training loss: 1.946252465248108
Validation loss: 2.0405590385198593

Epoch: 5| Step: 8
Training loss: 2.23382830619812
Validation loss: 2.0267645567655563

Epoch: 5| Step: 9
Training loss: 1.4131782054901123
Validation loss: 2.0071589400370917

Epoch: 5| Step: 10
Training loss: 1.9879710674285889
Validation loss: 2.04654194911321

Epoch: 5| Step: 11
Training loss: 1.8258635997772217
Validation loss: 2.0229738652706146

Epoch: 28| Step: 0
Training loss: 2.256472110748291
Validation loss: 2.0127893487612405

Epoch: 5| Step: 1
Training loss: 2.04522705078125
Validation loss: 2.0093940993150077

Epoch: 5| Step: 2
Training loss: 2.2050063610076904
Validation loss: 2.0272001177072525

Epoch: 5| Step: 3
Training loss: 2.1788175106048584
Validation loss: 2.0192119727532067

Epoch: 5| Step: 4
Training loss: 1.6659561395645142
Validation loss: 2.021383658051491

Epoch: 5| Step: 5
Training loss: 1.7619612216949463
Validation loss: 2.023385758201281

Epoch: 5| Step: 6
Training loss: 2.1090619564056396
Validation loss: 2.035181870063146

Epoch: 5| Step: 7
Training loss: 1.6479952335357666
Validation loss: 2.0283708969751992

Epoch: 5| Step: 8
Training loss: 1.958824872970581
Validation loss: 2.0264158099889755

Epoch: 5| Step: 9
Training loss: 2.2163455486297607
Validation loss: 2.040434072415034

Epoch: 5| Step: 10
Training loss: 1.785400629043579
Validation loss: 1.9998033195734024

Epoch: 5| Step: 11
Training loss: 2.3774399757385254
Validation loss: 2.0260408371686935

Epoch: 29| Step: 0
Training loss: 2.723578929901123
Validation loss: 2.0119743247826896

Epoch: 5| Step: 1
Training loss: 1.7267671823501587
Validation loss: 2.0313864847024283

Epoch: 5| Step: 2
Training loss: 1.8265674114227295
Validation loss: 2.044698307911555

Epoch: 5| Step: 3
Training loss: 2.252479076385498
Validation loss: 2.0256964216629663

Epoch: 5| Step: 4
Training loss: 1.9558188915252686
Validation loss: 2.0579837610324225

Epoch: 5| Step: 5
Training loss: 2.065516471862793
Validation loss: 2.014448493719101

Epoch: 5| Step: 6
Training loss: 1.064237356185913
Validation loss: 2.022146056095759

Epoch: 5| Step: 7
Training loss: 2.1822924613952637
Validation loss: 2.0207397987445197

Epoch: 5| Step: 8
Training loss: 1.9061782360076904
Validation loss: 2.053948238492012

Epoch: 5| Step: 9
Training loss: 1.7572882175445557
Validation loss: 2.0278239101171494

Epoch: 5| Step: 10
Training loss: 2.302410840988159
Validation loss: 2.0290135641892753

Epoch: 5| Step: 11
Training loss: 1.763574481010437
Validation loss: 2.010298267006874

Epoch: 30| Step: 0
Training loss: 2.218209981918335
Validation loss: 2.034510334332784

Epoch: 5| Step: 1
Training loss: 1.7077022790908813
Validation loss: 2.0464076598485312

Epoch: 5| Step: 2
Training loss: 2.277773380279541
Validation loss: 2.055192679166794

Epoch: 5| Step: 3
Training loss: 2.164646625518799
Validation loss: 2.021026427547137

Epoch: 5| Step: 4
Training loss: 1.9566524028778076
Validation loss: 2.0519184470176697

Epoch: 5| Step: 5
Training loss: 1.5046985149383545
Validation loss: 2.039169520139694

Epoch: 5| Step: 6
Training loss: 1.8340774774551392
Validation loss: 2.0065730760494866

Epoch: 5| Step: 7
Training loss: 2.4485390186309814
Validation loss: 2.0215570082267127

Epoch: 5| Step: 8
Training loss: 1.5429372787475586
Validation loss: 2.0241693357626596

Epoch: 5| Step: 9
Training loss: 1.8962351083755493
Validation loss: 2.0401172240575156

Epoch: 5| Step: 10
Training loss: 2.146613121032715
Validation loss: 2.0569521536429725

Epoch: 5| Step: 11
Training loss: 3.0781962871551514
Validation loss: 2.0446900526682534

Epoch: 31| Step: 0
Training loss: 1.4819837808609009
Validation loss: 2.0235210359096527

Epoch: 5| Step: 1
Training loss: 2.382309675216675
Validation loss: 2.0393876433372498

Epoch: 5| Step: 2
Training loss: 2.3555233478546143
Validation loss: 2.036050781607628

Epoch: 5| Step: 3
Training loss: 2.5474555492401123
Validation loss: 2.053197224934896

Epoch: 5| Step: 4
Training loss: 1.7173388004302979
Validation loss: 2.0317098200321198

Epoch: 5| Step: 5
Training loss: 2.4412050247192383
Validation loss: 2.0197890053192773

Epoch: 5| Step: 6
Training loss: 2.0892748832702637
Validation loss: 2.033098871509234

Epoch: 5| Step: 7
Training loss: 2.0549278259277344
Validation loss: 2.0100564112265906

Epoch: 5| Step: 8
Training loss: 1.4221842288970947
Validation loss: 2.066362664103508

Epoch: 5| Step: 9
Training loss: 1.9758703708648682
Validation loss: 2.019734417398771

Epoch: 5| Step: 10
Training loss: 1.4759838581085205
Validation loss: 2.038442383209864

Epoch: 5| Step: 11
Training loss: 1.7434037923812866
Validation loss: 2.0346462627251944

Epoch: 32| Step: 0
Training loss: 1.877320647239685
Validation loss: 2.0320579508940377

Epoch: 5| Step: 1
Training loss: 1.4137918949127197
Validation loss: 1.9937351097663243

Epoch: 5| Step: 2
Training loss: 1.4038373231887817
Validation loss: 2.011386831601461

Epoch: 5| Step: 3
Training loss: 2.7843148708343506
Validation loss: 2.007227584719658

Epoch: 5| Step: 4
Training loss: 1.6885395050048828
Validation loss: 2.015950068831444

Epoch: 5| Step: 5
Training loss: 1.847670555114746
Validation loss: 2.0172864894072213

Epoch: 5| Step: 6
Training loss: 2.064177989959717
Validation loss: 2.030794988075892

Epoch: 5| Step: 7
Training loss: 2.589125156402588
Validation loss: 1.9958669344584148

Epoch: 5| Step: 8
Training loss: 2.31217622756958
Validation loss: 2.0191250294446945

Epoch: 5| Step: 9
Training loss: 1.8325984477996826
Validation loss: 2.0230776021877923

Epoch: 5| Step: 10
Training loss: 1.786930799484253
Validation loss: 2.0118719140688577

Epoch: 5| Step: 11
Training loss: 2.5398731231689453
Validation loss: 2.0268082519372306

Epoch: 33| Step: 0
Training loss: 1.7078880071640015
Validation loss: 2.005655348300934

Epoch: 5| Step: 1
Training loss: 1.8338667154312134
Validation loss: 2.032242715358734

Epoch: 5| Step: 2
Training loss: 2.0828499794006348
Validation loss: 2.0359931886196136

Epoch: 5| Step: 3
Training loss: 2.8775389194488525
Validation loss: 2.0345821231603622

Epoch: 5| Step: 4
Training loss: 1.8922001123428345
Validation loss: 2.0287570854028067

Epoch: 5| Step: 5
Training loss: 1.5485793352127075
Validation loss: 2.021736726164818

Epoch: 5| Step: 6
Training loss: 1.5092694759368896
Validation loss: 2.023077184955279

Epoch: 5| Step: 7
Training loss: 1.790938138961792
Validation loss: 2.0233684529860816

Epoch: 5| Step: 8
Training loss: 2.271075963973999
Validation loss: 2.0100566496451697

Epoch: 5| Step: 9
Training loss: 1.7842967510223389
Validation loss: 2.008940373857816

Epoch: 5| Step: 10
Training loss: 2.4491615295410156
Validation loss: 2.006306822101275

Epoch: 5| Step: 11
Training loss: 1.9326967000961304
Validation loss: 1.9973810613155365

Epoch: 34| Step: 0
Training loss: 2.594303607940674
Validation loss: 2.015181839466095

Epoch: 5| Step: 1
Training loss: 2.053520679473877
Validation loss: 2.0097262064615884

Epoch: 5| Step: 2
Training loss: 1.446291446685791
Validation loss: 2.0176866203546524

Epoch: 5| Step: 3
Training loss: 1.7990134954452515
Validation loss: 2.0215569784243903

Epoch: 5| Step: 4
Training loss: 1.9466747045516968
Validation loss: 2.0280434985955558

Epoch: 5| Step: 5
Training loss: 2.1915669441223145
Validation loss: 1.994349737962087

Epoch: 5| Step: 6
Training loss: 1.3455431461334229
Validation loss: 2.0105494558811188

Epoch: 5| Step: 7
Training loss: 2.4919967651367188
Validation loss: 2.0199166735013327

Epoch: 5| Step: 8
Training loss: 1.8405635356903076
Validation loss: 2.0151841839154563

Epoch: 5| Step: 9
Training loss: 2.0686943531036377
Validation loss: 2.02199778954188

Epoch: 5| Step: 10
Training loss: 1.7997945547103882
Validation loss: 2.021618574857712

Epoch: 5| Step: 11
Training loss: 2.5255494117736816
Validation loss: 2.0201988220214844

Epoch: 35| Step: 0
Training loss: 2.1643457412719727
Validation loss: 2.01433531443278

Epoch: 5| Step: 1
Training loss: 1.8152875900268555
Validation loss: 2.011976962288221

Epoch: 5| Step: 2
Training loss: 1.9514150619506836
Validation loss: 2.0015581399202347

Epoch: 5| Step: 3
Training loss: 1.5541328191757202
Validation loss: 2.0091667771339417

Epoch: 5| Step: 4
Training loss: 1.5010894536972046
Validation loss: 2.0232782562573752

Epoch: 5| Step: 5
Training loss: 2.7971091270446777
Validation loss: 2.035918965935707

Epoch: 5| Step: 6
Training loss: 2.043102979660034
Validation loss: 2.0580540845791497

Epoch: 5| Step: 7
Training loss: 2.1334102153778076
Validation loss: 2.066934198141098

Epoch: 5| Step: 8
Training loss: 1.734845757484436
Validation loss: 2.06124218304952

Epoch: 5| Step: 9
Training loss: 2.2537167072296143
Validation loss: 2.062628760933876

Epoch: 5| Step: 10
Training loss: 1.7865846157073975
Validation loss: 2.053223113218943

Epoch: 5| Step: 11
Training loss: 2.4694018363952637
Validation loss: 2.002566466728846

Epoch: 36| Step: 0
Training loss: 1.294650912284851
Validation loss: 2.0306184887886047

Epoch: 5| Step: 1
Training loss: 2.1163132190704346
Validation loss: 2.0130219707886376

Epoch: 5| Step: 2
Training loss: 2.4371135234832764
Validation loss: 2.02072681983312

Epoch: 5| Step: 3
Training loss: 1.8988895416259766
Validation loss: 2.024714464942614

Epoch: 5| Step: 4
Training loss: 1.9699628353118896
Validation loss: 1.9921144843101501

Epoch: 5| Step: 5
Training loss: 1.7822803258895874
Validation loss: 2.0237804452578225

Epoch: 5| Step: 6
Training loss: 2.788440227508545
Validation loss: 2.0150592923164368

Epoch: 5| Step: 7
Training loss: 2.0135791301727295
Validation loss: 1.9989539335171382

Epoch: 5| Step: 8
Training loss: 1.9231884479522705
Validation loss: 1.9917322993278503

Epoch: 5| Step: 9
Training loss: 2.2477991580963135
Validation loss: 2.004172131419182

Epoch: 5| Step: 10
Training loss: 1.3026071786880493
Validation loss: 2.0338787188132605

Epoch: 5| Step: 11
Training loss: 1.5941299200057983
Validation loss: 1.9928071647882462

Epoch: 37| Step: 0
Training loss: 1.5230392217636108
Validation loss: 1.9947443008422852

Epoch: 5| Step: 1
Training loss: 1.358315110206604
Validation loss: 2.0014520982901254

Epoch: 5| Step: 2
Training loss: 2.2819645404815674
Validation loss: 2.015391707420349

Epoch: 5| Step: 3
Training loss: 2.373145818710327
Validation loss: 2.0189229249954224

Epoch: 5| Step: 4
Training loss: 2.185173511505127
Validation loss: 2.038333679238955

Epoch: 5| Step: 5
Training loss: 1.4954332113265991
Validation loss: 2.054056147734324

Epoch: 5| Step: 6
Training loss: 1.7916676998138428
Validation loss: 2.0546371787786484

Epoch: 5| Step: 7
Training loss: 2.279127597808838
Validation loss: 2.032452325026194

Epoch: 5| Step: 8
Training loss: 2.115126848220825
Validation loss: 2.0245905021826425

Epoch: 5| Step: 9
Training loss: 1.6729190349578857
Validation loss: 2.030349845687548

Epoch: 5| Step: 10
Training loss: 2.085712432861328
Validation loss: 2.026646693547567

Epoch: 5| Step: 11
Training loss: 3.9957518577575684
Validation loss: 2.033226062854131

Epoch: 38| Step: 0
Training loss: 2.4009203910827637
Validation loss: 2.0513977309068046

Epoch: 5| Step: 1
Training loss: 2.097560405731201
Validation loss: 2.0153267979621887

Epoch: 5| Step: 2
Training loss: 2.120795965194702
Validation loss: 2.015901098648707

Epoch: 5| Step: 3
Training loss: 1.2111395597457886
Validation loss: 2.030032272140185

Epoch: 5| Step: 4
Training loss: 2.317535877227783
Validation loss: 2.044191141923269

Epoch: 5| Step: 5
Training loss: 1.8293380737304688
Validation loss: 2.00104429324468

Epoch: 5| Step: 6
Training loss: 1.941746473312378
Validation loss: 2.033862441778183

Epoch: 5| Step: 7
Training loss: 1.7036857604980469
Validation loss: 2.003545413414637

Epoch: 5| Step: 8
Training loss: 1.631569504737854
Validation loss: 2.0046977599461875

Epoch: 5| Step: 9
Training loss: 2.554131031036377
Validation loss: 1.9967170804738998

Epoch: 5| Step: 10
Training loss: 1.4713621139526367
Validation loss: 2.024782364567121

Epoch: 5| Step: 11
Training loss: 2.963285207748413
Validation loss: 1.9867408523956935

Epoch: 39| Step: 0
Training loss: 2.019002914428711
Validation loss: 2.012658933798472

Epoch: 5| Step: 1
Training loss: 1.7610490322113037
Validation loss: 2.00259031355381

Epoch: 5| Step: 2
Training loss: 1.2894196510314941
Validation loss: 2.007963334520658

Epoch: 5| Step: 3
Training loss: 1.609779953956604
Validation loss: 2.0092887034018836

Epoch: 5| Step: 4
Training loss: 1.81368887424469
Validation loss: 1.997659683227539

Epoch: 5| Step: 5
Training loss: 2.3331122398376465
Validation loss: 2.000454549988111

Epoch: 5| Step: 6
Training loss: 1.8899433612823486
Validation loss: 2.0007191747426987

Epoch: 5| Step: 7
Training loss: 2.3860223293304443
Validation loss: 2.0262369016806283

Epoch: 5| Step: 8
Training loss: 2.2267372608184814
Validation loss: 2.0100479374329248

Epoch: 5| Step: 9
Training loss: 1.8407875299453735
Validation loss: 2.0380906015634537

Epoch: 5| Step: 10
Training loss: 2.8393070697784424
Validation loss: 2.0525295585393906

Epoch: 5| Step: 11
Training loss: 2.2538111209869385
Validation loss: 2.0313675850629807

Epoch: 40| Step: 0
Training loss: 1.8940298557281494
Validation loss: 2.040048415462176

Epoch: 5| Step: 1
Training loss: 2.3174121379852295
Validation loss: 2.0369771917661033

Epoch: 5| Step: 2
Training loss: 1.6972935199737549
Validation loss: 2.020436684290568

Epoch: 5| Step: 3
Training loss: 1.8759825229644775
Validation loss: 2.041447485486666

Epoch: 5| Step: 4
Training loss: 2.009218692779541
Validation loss: 1.9999533047278721

Epoch: 5| Step: 5
Training loss: 2.089839220046997
Validation loss: 2.0148049940665564

Epoch: 5| Step: 6
Training loss: 2.497544527053833
Validation loss: 1.9998251150051753

Epoch: 5| Step: 7
Training loss: 1.7655651569366455
Validation loss: 2.0028294573227563

Epoch: 5| Step: 8
Training loss: 1.7982763051986694
Validation loss: 1.990377535422643

Epoch: 5| Step: 9
Training loss: 1.9925720691680908
Validation loss: 2.0202295829852424

Epoch: 5| Step: 10
Training loss: 1.5494104623794556
Validation loss: 2.0134472250938416

Epoch: 5| Step: 11
Training loss: 1.05728280544281
Validation loss: 2.017346610625585

Epoch: 41| Step: 0
Training loss: 1.7188453674316406
Validation loss: 2.01643172899882

Epoch: 5| Step: 1
Training loss: 2.2696003913879395
Validation loss: 1.9938732087612152

Epoch: 5| Step: 2
Training loss: 1.998342514038086
Validation loss: 2.008684073885282

Epoch: 5| Step: 3
Training loss: 2.2669692039489746
Validation loss: 1.9840604960918427

Epoch: 5| Step: 4
Training loss: 1.6750686168670654
Validation loss: 1.98112856845061

Epoch: 5| Step: 5
Training loss: 1.4732890129089355
Validation loss: 2.007399767637253

Epoch: 5| Step: 6
Training loss: 2.150627613067627
Validation loss: 1.9997669408718746

Epoch: 5| Step: 7
Training loss: 2.0808041095733643
Validation loss: 1.9973775843779247

Epoch: 5| Step: 8
Training loss: 2.2586188316345215
Validation loss: 1.990274469057719

Epoch: 5| Step: 9
Training loss: 2.1514363288879395
Validation loss: 2.0024745762348175

Epoch: 5| Step: 10
Training loss: 1.284485101699829
Validation loss: 2.006474475065867

Epoch: 5| Step: 11
Training loss: 2.1391475200653076
Validation loss: 2.0063337286313376

Epoch: 42| Step: 0
Training loss: 2.0898425579071045
Validation loss: 2.0361822048823037

Epoch: 5| Step: 1
Training loss: 2.3171675205230713
Validation loss: 2.064346914490064

Epoch: 5| Step: 2
Training loss: 1.7966572046279907
Validation loss: 2.0657413452863693

Epoch: 5| Step: 3
Training loss: 2.3948419094085693
Validation loss: 2.0564647366603217

Epoch: 5| Step: 4
Training loss: 1.993199110031128
Validation loss: 2.070480619867643

Epoch: 5| Step: 5
Training loss: 1.3731698989868164
Validation loss: 2.0525610744953156

Epoch: 5| Step: 6
Training loss: 1.7310583591461182
Validation loss: 2.0742164502541223

Epoch: 5| Step: 7
Training loss: 2.082205295562744
Validation loss: 2.0683394968509674

Epoch: 5| Step: 8
Training loss: 2.1831278800964355
Validation loss: 2.0539528280496597

Epoch: 5| Step: 9
Training loss: 1.6291719675064087
Validation loss: 2.074268768231074

Epoch: 5| Step: 10
Training loss: 1.9159663915634155
Validation loss: 2.03969377775987

Epoch: 5| Step: 11
Training loss: 2.5052804946899414
Validation loss: 2.0389163941144943

Epoch: 43| Step: 0
Training loss: 2.071666717529297
Validation loss: 2.0123167783021927

Epoch: 5| Step: 1
Training loss: 1.47030770778656
Validation loss: 2.0006005068620047

Epoch: 5| Step: 2
Training loss: 1.3782744407653809
Validation loss: 1.9880633801221848

Epoch: 5| Step: 3
Training loss: 1.590790867805481
Validation loss: 1.993951216340065

Epoch: 5| Step: 4
Training loss: 2.3912997245788574
Validation loss: 1.993540604909261

Epoch: 5| Step: 5
Training loss: 2.5889151096343994
Validation loss: 1.9989069153865178

Epoch: 5| Step: 6
Training loss: 2.116443634033203
Validation loss: 1.974938948949178

Epoch: 5| Step: 7
Training loss: 2.203352928161621
Validation loss: 2.005376552542051

Epoch: 5| Step: 8
Training loss: 1.899148941040039
Validation loss: 2.018754964073499

Epoch: 5| Step: 9
Training loss: 1.616337537765503
Validation loss: 1.9819186329841614

Epoch: 5| Step: 10
Training loss: 2.089669704437256
Validation loss: 1.9890182614326477

Epoch: 5| Step: 11
Training loss: 2.6384825706481934
Validation loss: 2.0047490000724792

Epoch: 44| Step: 0
Training loss: 2.1818251609802246
Validation loss: 1.9848415404558182

Epoch: 5| Step: 1
Training loss: 1.7782948017120361
Validation loss: 2.0011042406161628

Epoch: 5| Step: 2
Training loss: 2.138385057449341
Validation loss: 1.9858897527058919

Epoch: 5| Step: 3
Training loss: 1.9955370426177979
Validation loss: 2.005815143386523

Epoch: 5| Step: 4
Training loss: 1.5697662830352783
Validation loss: 1.976894309123357

Epoch: 5| Step: 5
Training loss: 2.078889846801758
Validation loss: 1.9989962081114452

Epoch: 5| Step: 6
Training loss: 2.139740467071533
Validation loss: 1.9922716816266377

Epoch: 5| Step: 7
Training loss: 1.6762338876724243
Validation loss: 1.977988878885905

Epoch: 5| Step: 8
Training loss: 2.1423115730285645
Validation loss: 1.9772291084130604

Epoch: 5| Step: 9
Training loss: 1.8718488216400146
Validation loss: 1.9953620235125225

Epoch: 5| Step: 10
Training loss: 1.7904294729232788
Validation loss: 1.9921255856752396

Epoch: 5| Step: 11
Training loss: 2.076005458831787
Validation loss: 2.0103521645069122

Epoch: 45| Step: 0
Training loss: 1.2961939573287964
Validation loss: 2.0251890122890472

Epoch: 5| Step: 1
Training loss: 1.5829846858978271
Validation loss: 2.036678299307823

Epoch: 5| Step: 2
Training loss: 1.9172872304916382
Validation loss: 2.01496422290802

Epoch: 5| Step: 3
Training loss: 1.755001425743103
Validation loss: 2.029840370019277

Epoch: 5| Step: 4
Training loss: 2.847979784011841
Validation loss: 2.024726872642835

Epoch: 5| Step: 5
Training loss: 2.0618343353271484
Validation loss: 2.013367344935735

Epoch: 5| Step: 6
Training loss: 1.9461538791656494
Validation loss: 2.0189729630947113

Epoch: 5| Step: 7
Training loss: 1.4341180324554443
Validation loss: 2.019285331169764

Epoch: 5| Step: 8
Training loss: 2.2145156860351562
Validation loss: 1.9826304912567139

Epoch: 5| Step: 9
Training loss: 1.843266487121582
Validation loss: 1.987958163022995

Epoch: 5| Step: 10
Training loss: 2.2257273197174072
Validation loss: 2.0097489058971405

Epoch: 5| Step: 11
Training loss: 2.794887065887451
Validation loss: 2.0259040693442025

Epoch: 46| Step: 0
Training loss: 2.2934353351593018
Validation loss: 1.9956637521584828

Epoch: 5| Step: 1
Training loss: 1.7398264408111572
Validation loss: 1.9794619679450989

Epoch: 5| Step: 2
Training loss: 1.6565510034561157
Validation loss: 1.9908638099829357

Epoch: 5| Step: 3
Training loss: 1.3707036972045898
Validation loss: 2.015861893693606

Epoch: 5| Step: 4
Training loss: 1.642351508140564
Validation loss: 1.9719096173842747

Epoch: 5| Step: 5
Training loss: 2.038231372833252
Validation loss: 2.0000399549802146

Epoch: 5| Step: 6
Training loss: 1.9895427227020264
Validation loss: 2.012760410706202

Epoch: 5| Step: 7
Training loss: 2.244886875152588
Validation loss: 1.9990035792191823

Epoch: 5| Step: 8
Training loss: 2.147507905960083
Validation loss: 1.9854346364736557

Epoch: 5| Step: 9
Training loss: 2.001298427581787
Validation loss: 1.9911938259998958

Epoch: 5| Step: 10
Training loss: 1.894713044166565
Validation loss: 1.9999927033980687

Epoch: 5| Step: 11
Training loss: 2.196046829223633
Validation loss: 2.0046314795811973

Epoch: 47| Step: 0
Training loss: 1.5454405546188354
Validation loss: 1.9864078809817631

Epoch: 5| Step: 1
Training loss: 1.889336347579956
Validation loss: 2.0057377765576043

Epoch: 5| Step: 2
Training loss: 2.0696845054626465
Validation loss: 2.0099011162916818

Epoch: 5| Step: 3
Training loss: 2.315760850906372
Validation loss: 2.0242131054401398

Epoch: 5| Step: 4
Training loss: 1.854921579360962
Validation loss: 2.0307878255844116

Epoch: 5| Step: 5
Training loss: 1.1645300388336182
Validation loss: 2.017050787806511

Epoch: 5| Step: 6
Training loss: 2.3225903511047363
Validation loss: 2.025226886073748

Epoch: 5| Step: 7
Training loss: 1.9079281091690063
Validation loss: 2.0392368833223977

Epoch: 5| Step: 8
Training loss: 2.2673099040985107
Validation loss: 2.044402986764908

Epoch: 5| Step: 9
Training loss: 1.826023817062378
Validation loss: 2.0349162022272744

Epoch: 5| Step: 10
Training loss: 1.8641765117645264
Validation loss: 2.024654562274615

Epoch: 5| Step: 11
Training loss: 1.6390581130981445
Validation loss: 2.040930380423864

Epoch: 48| Step: 0
Training loss: 1.488663673400879
Validation loss: 2.0058937619129815

Epoch: 5| Step: 1
Training loss: 1.8919880390167236
Validation loss: 2.0112865219513574

Epoch: 5| Step: 2
Training loss: 2.4954733848571777
Validation loss: 1.992266446352005

Epoch: 5| Step: 3
Training loss: 1.9974772930145264
Validation loss: 1.9813332110643387

Epoch: 5| Step: 4
Training loss: 1.7504045963287354
Validation loss: 1.9982081602017085

Epoch: 5| Step: 5
Training loss: 1.8637340068817139
Validation loss: 1.9866570234298706

Epoch: 5| Step: 6
Training loss: 1.6927467584609985
Validation loss: 1.9871570467948914

Epoch: 5| Step: 7
Training loss: 1.9553248882293701
Validation loss: 2.020309641957283

Epoch: 5| Step: 8
Training loss: 2.502131700515747
Validation loss: 1.990429863333702

Epoch: 5| Step: 9
Training loss: 2.022078037261963
Validation loss: 1.9906999468803406

Epoch: 5| Step: 10
Training loss: 1.546281099319458
Validation loss: 2.000458503762881

Epoch: 5| Step: 11
Training loss: 1.8093130588531494
Validation loss: 1.9699172923962276

Epoch: 49| Step: 0
Training loss: 1.3388235569000244
Validation loss: 1.98226002852122

Epoch: 5| Step: 1
Training loss: 2.279834747314453
Validation loss: 2.0151525090138116

Epoch: 5| Step: 2
Training loss: 2.367980480194092
Validation loss: 2.022632638613383

Epoch: 5| Step: 3
Training loss: 2.349921703338623
Validation loss: 2.005781908830007

Epoch: 5| Step: 4
Training loss: 2.1616358757019043
Validation loss: 2.0277469903230667

Epoch: 5| Step: 5
Training loss: 1.7782081365585327
Validation loss: 2.02876245478789

Epoch: 5| Step: 6
Training loss: 1.5488958358764648
Validation loss: 2.0213140000899634

Epoch: 5| Step: 7
Training loss: 1.7818081378936768
Validation loss: 2.024793396393458

Epoch: 5| Step: 8
Training loss: 2.2582812309265137
Validation loss: 2.00284905731678

Epoch: 5| Step: 9
Training loss: 1.600817084312439
Validation loss: 2.0172905077536902

Epoch: 5| Step: 10
Training loss: 1.7661569118499756
Validation loss: 2.030958076318105

Epoch: 5| Step: 11
Training loss: 1.0875948667526245
Validation loss: 2.020268887281418

Epoch: 50| Step: 0
Training loss: 1.3008081912994385
Validation loss: 2.0037600894769034

Epoch: 5| Step: 1
Training loss: 1.985280990600586
Validation loss: 2.0263222455978394

Epoch: 5| Step: 2
Training loss: 2.155526638031006
Validation loss: 2.021740143497785

Epoch: 5| Step: 3
Training loss: 1.6459076404571533
Validation loss: 2.0413970053195953

Epoch: 5| Step: 4
Training loss: 1.796804666519165
Validation loss: 2.0435591489076614

Epoch: 5| Step: 5
Training loss: 1.8505051136016846
Validation loss: 2.020813927054405

Epoch: 5| Step: 6
Training loss: 2.3707594871520996
Validation loss: 1.997283751765887

Epoch: 5| Step: 7
Training loss: 1.7870641946792603
Validation loss: 2.0148894985516868

Epoch: 5| Step: 8
Training loss: 2.171278953552246
Validation loss: 2.006233369310697

Epoch: 5| Step: 9
Training loss: 1.6298868656158447
Validation loss: 2.0059136549631753

Epoch: 5| Step: 10
Training loss: 2.211322784423828
Validation loss: 2.026780530810356

Epoch: 5| Step: 11
Training loss: 2.6045942306518555
Validation loss: 2.001942897836367

Epoch: 51| Step: 0
Training loss: 1.5371865034103394
Validation loss: 2.0115948567787805

Epoch: 5| Step: 1
Training loss: 1.607435941696167
Validation loss: 2.018560071786245

Epoch: 5| Step: 2
Training loss: 1.9873374700546265
Validation loss: 1.9809905687967937

Epoch: 5| Step: 3
Training loss: 2.6900553703308105
Validation loss: 1.9750180840492249

Epoch: 5| Step: 4
Training loss: 1.6995388269424438
Validation loss: 1.9824142207702

Epoch: 5| Step: 5
Training loss: 1.7926172018051147
Validation loss: 1.9964419951041539

Epoch: 5| Step: 6
Training loss: 1.9350664615631104
Validation loss: 1.9910416901111603

Epoch: 5| Step: 7
Training loss: 2.104759454727173
Validation loss: 1.993503987789154

Epoch: 5| Step: 8
Training loss: 1.3348108530044556
Validation loss: 1.9916531989971797

Epoch: 5| Step: 9
Training loss: 2.2273852825164795
Validation loss: 2.00218203663826

Epoch: 5| Step: 10
Training loss: 2.2204596996307373
Validation loss: 2.016504113872846

Epoch: 5| Step: 11
Training loss: 2.6257476806640625
Validation loss: 2.0360451340675354

Epoch: 52| Step: 0
Training loss: 1.764316201210022
Validation loss: 2.0019169549147287

Epoch: 5| Step: 1
Training loss: 2.1638872623443604
Validation loss: 2.0232947915792465

Epoch: 5| Step: 2
Training loss: 2.0253310203552246
Validation loss: 2.0200836261113486

Epoch: 5| Step: 3
Training loss: 1.434435248374939
Validation loss: 1.9910254180431366

Epoch: 5| Step: 4
Training loss: 1.7426809072494507
Validation loss: 1.9794330447912216

Epoch: 5| Step: 5
Training loss: 1.7956454753875732
Validation loss: 1.9854084302981694

Epoch: 5| Step: 6
Training loss: 2.428478956222534
Validation loss: 1.9991477380196254

Epoch: 5| Step: 7
Training loss: 1.851030945777893
Validation loss: 1.9778333107630413

Epoch: 5| Step: 8
Training loss: 1.841468095779419
Validation loss: 1.9929288029670715

Epoch: 5| Step: 9
Training loss: 1.7816575765609741
Validation loss: 2.0069602131843567

Epoch: 5| Step: 10
Training loss: 2.3516178131103516
Validation loss: 1.9925094743569691

Epoch: 5| Step: 11
Training loss: 3.340242624282837
Validation loss: 2.030525321761767

Epoch: 53| Step: 0
Training loss: 2.628208637237549
Validation loss: 1.9821060746908188

Epoch: 5| Step: 1
Training loss: 1.616860032081604
Validation loss: 2.004087363680204

Epoch: 5| Step: 2
Training loss: 2.0127694606781006
Validation loss: 1.9937413583199184

Epoch: 5| Step: 3
Training loss: 1.9616587162017822
Validation loss: 1.9848630527655284

Epoch: 5| Step: 4
Training loss: 2.376375198364258
Validation loss: 1.9876245260238647

Epoch: 5| Step: 5
Training loss: 1.8173233270645142
Validation loss: 2.017076005538305

Epoch: 5| Step: 6
Training loss: 2.2361655235290527
Validation loss: 2.0031893998384476

Epoch: 5| Step: 7
Training loss: 1.3823028802871704
Validation loss: 2.008737236261368

Epoch: 5| Step: 8
Training loss: 1.4731019735336304
Validation loss: 1.991963138182958

Epoch: 5| Step: 9
Training loss: 1.5071035623550415
Validation loss: 2.0037457744280496

Epoch: 5| Step: 10
Training loss: 2.118961811065674
Validation loss: 2.015781690677007

Epoch: 5| Step: 11
Training loss: 1.0808537006378174
Validation loss: 2.0043619026740394

Epoch: 54| Step: 0
Training loss: 2.2430248260498047
Validation loss: 2.00473261376222

Epoch: 5| Step: 1
Training loss: 1.7233197689056396
Validation loss: 2.0522901068131127

Epoch: 5| Step: 2
Training loss: 1.1229088306427002
Validation loss: 2.019948194424311

Epoch: 5| Step: 3
Training loss: 1.872154951095581
Validation loss: 2.0383903781572976

Epoch: 5| Step: 4
Training loss: 1.813611626625061
Validation loss: 2.0634754647811255

Epoch: 5| Step: 5
Training loss: 1.7739028930664062
Validation loss: 2.0501647690931954

Epoch: 5| Step: 6
Training loss: 1.9080684185028076
Validation loss: 2.045886273185412

Epoch: 5| Step: 7
Training loss: 2.759568691253662
Validation loss: 2.0580579886833825

Epoch: 5| Step: 8
Training loss: 1.8554970026016235
Validation loss: 2.0163633128007254

Epoch: 5| Step: 9
Training loss: 1.9448168277740479
Validation loss: 2.0049529721339545

Epoch: 5| Step: 10
Training loss: 1.8827970027923584
Validation loss: 2.0213658114274344

Epoch: 5| Step: 11
Training loss: 2.0411434173583984
Validation loss: 2.0028727302948632

Epoch: 55| Step: 0
Training loss: 2.2951436042785645
Validation loss: 1.9883257846037548

Epoch: 5| Step: 1
Training loss: 1.8202673196792603
Validation loss: 1.9935911695162456

Epoch: 5| Step: 2
Training loss: 1.1974639892578125
Validation loss: 2.0204047858715057

Epoch: 5| Step: 3
Training loss: 1.569393515586853
Validation loss: 2.0097210655609765

Epoch: 5| Step: 4
Training loss: 1.802910566329956
Validation loss: 2.0065231074889502

Epoch: 5| Step: 5
Training loss: 1.9737188816070557
Validation loss: 2.049542004863421

Epoch: 5| Step: 6
Training loss: 2.3298161029815674
Validation loss: 2.0082869231700897

Epoch: 5| Step: 7
Training loss: 2.0830912590026855
Validation loss: 2.0386897126833596

Epoch: 5| Step: 8
Training loss: 2.318899393081665
Validation loss: 2.004848172267278

Epoch: 5| Step: 9
Training loss: 2.183877944946289
Validation loss: 2.0156146784623465

Epoch: 5| Step: 10
Training loss: 1.5749356746673584
Validation loss: 2.0072433600823083

Epoch: 5| Step: 11
Training loss: 1.2860610485076904
Validation loss: 2.016881063580513

Epoch: 56| Step: 0
Training loss: 1.4627256393432617
Validation loss: 1.9965201318264008

Epoch: 5| Step: 1
Training loss: 1.8044618368148804
Validation loss: 1.9960113614797592

Epoch: 5| Step: 2
Training loss: 1.3803437948226929
Validation loss: 2.005638693769773

Epoch: 5| Step: 3
Training loss: 2.1260015964508057
Validation loss: 2.021578162908554

Epoch: 5| Step: 4
Training loss: 1.703693151473999
Validation loss: 2.021003564198812

Epoch: 5| Step: 5
Training loss: 2.7241501808166504
Validation loss: 2.0276102672020593

Epoch: 5| Step: 6
Training loss: 1.8931214809417725
Validation loss: 2.009709765513738

Epoch: 5| Step: 7
Training loss: 2.1334586143493652
Validation loss: 2.0041419019301734

Epoch: 5| Step: 8
Training loss: 1.9509460926055908
Validation loss: 1.9939706126848857

Epoch: 5| Step: 9
Training loss: 1.7431656122207642
Validation loss: 2.0007193783919015

Epoch: 5| Step: 10
Training loss: 2.019171953201294
Validation loss: 2.004157374302546

Epoch: 5| Step: 11
Training loss: 1.8242143392562866
Validation loss: 2.0140537122885385

Epoch: 57| Step: 0
Training loss: 1.7858797311782837
Validation loss: 1.9956139127413433

Epoch: 5| Step: 1
Training loss: 1.8325248956680298
Validation loss: 1.9823088695605595

Epoch: 5| Step: 2
Training loss: 1.8479121923446655
Validation loss: 1.9905144025882084

Epoch: 5| Step: 3
Training loss: 2.208237886428833
Validation loss: 1.9738614807526271

Epoch: 5| Step: 4
Training loss: 1.375881314277649
Validation loss: 1.9812944481770198

Epoch: 5| Step: 5
Training loss: 1.9075748920440674
Validation loss: 1.949154645204544

Epoch: 5| Step: 6
Training loss: 2.1237449645996094
Validation loss: 2.0086960047483444

Epoch: 5| Step: 7
Training loss: 1.857140302658081
Validation loss: 1.9743234465519588

Epoch: 5| Step: 8
Training loss: 2.269002676010132
Validation loss: 1.9988701542218525

Epoch: 5| Step: 9
Training loss: 1.329541563987732
Validation loss: 2.0244288792212806

Epoch: 5| Step: 10
Training loss: 2.1313719749450684
Validation loss: 2.017805367708206

Epoch: 5| Step: 11
Training loss: 2.67498517036438
Validation loss: 1.9855792373418808

Epoch: 58| Step: 0
Training loss: 1.7545242309570312
Validation loss: 2.026783302426338

Epoch: 5| Step: 1
Training loss: 2.1292786598205566
Validation loss: 2.0397818982601166

Epoch: 5| Step: 2
Training loss: 2.902963638305664
Validation loss: 2.0540049423774085

Epoch: 5| Step: 3
Training loss: 1.7492767572402954
Validation loss: 2.035179704427719

Epoch: 5| Step: 4
Training loss: 1.6418437957763672
Validation loss: 2.0751708447933197

Epoch: 5| Step: 5
Training loss: 1.8026878833770752
Validation loss: 2.062469800313314

Epoch: 5| Step: 6
Training loss: 1.7503410577774048
Validation loss: 2.0445908854405084

Epoch: 5| Step: 7
Training loss: 1.749759316444397
Validation loss: 2.033192664384842

Epoch: 5| Step: 8
Training loss: 2.2668910026550293
Validation loss: 2.0027017990748086

Epoch: 5| Step: 9
Training loss: 1.522435188293457
Validation loss: 1.9922172625859578

Epoch: 5| Step: 10
Training loss: 1.7031704187393188
Validation loss: 1.9758750398953755

Epoch: 5| Step: 11
Training loss: 3.0273149013519287
Validation loss: 1.9899768233299255

Epoch: 59| Step: 0
Training loss: 1.8419339656829834
Validation loss: 1.9794182280699413

Epoch: 5| Step: 1
Training loss: 1.784073829650879
Validation loss: 1.9918222079674404

Epoch: 5| Step: 2
Training loss: 1.3163219690322876
Validation loss: 2.015315572420756

Epoch: 5| Step: 3
Training loss: 2.223586320877075
Validation loss: 2.0234115620454154

Epoch: 5| Step: 4
Training loss: 1.9940330982208252
Validation loss: 2.034532149632772

Epoch: 5| Step: 5
Training loss: 1.8654096126556396
Validation loss: 2.028787429134051

Epoch: 5| Step: 6
Training loss: 1.9159510135650635
Validation loss: 2.0484077831109366

Epoch: 5| Step: 7
Training loss: 2.6335561275482178
Validation loss: 2.0416548401117325

Epoch: 5| Step: 8
Training loss: 1.2452961206436157
Validation loss: 2.065475861231486

Epoch: 5| Step: 9
Training loss: 2.2130277156829834
Validation loss: 1.9856263945500057

Epoch: 5| Step: 10
Training loss: 2.085444927215576
Validation loss: 2.0404851337273917

Epoch: 5| Step: 11
Training loss: 0.8168089985847473
Validation loss: 2.0194843063751855

Epoch: 60| Step: 0
Training loss: 1.7038685083389282
Validation loss: 1.9730852742989857

Epoch: 5| Step: 1
Training loss: 2.1064305305480957
Validation loss: 1.994241292277972

Epoch: 5| Step: 2
Training loss: 2.045546293258667
Validation loss: 1.9782733917236328

Epoch: 5| Step: 3
Training loss: 1.5910990238189697
Validation loss: 1.9946315437555313

Epoch: 5| Step: 4
Training loss: 1.5596580505371094
Validation loss: 1.9908650418122609

Epoch: 5| Step: 5
Training loss: 1.9028619527816772
Validation loss: 2.023658439517021

Epoch: 5| Step: 6
Training loss: 2.1570746898651123
Validation loss: 2.001315732796987

Epoch: 5| Step: 7
Training loss: 2.495131015777588
Validation loss: 2.0201526433229446

Epoch: 5| Step: 8
Training loss: 1.9305588006973267
Validation loss: 1.9951910724242528

Epoch: 5| Step: 9
Training loss: 1.5769044160842896
Validation loss: 2.0141919553279877

Epoch: 5| Step: 10
Training loss: 1.7091214656829834
Validation loss: 2.0127444167931876

Epoch: 5| Step: 11
Training loss: 1.787362813949585
Validation loss: 2.0112999776999154

Epoch: 61| Step: 0
Training loss: 1.846240758895874
Validation loss: 2.0154096335172653

Epoch: 5| Step: 1
Training loss: 1.9423786401748657
Validation loss: 2.0194834172725677

Epoch: 5| Step: 2
Training loss: 1.967270851135254
Validation loss: 2.0221353073914847

Epoch: 5| Step: 3
Training loss: 2.0135958194732666
Validation loss: 2.0186004986365638

Epoch: 5| Step: 4
Training loss: 1.178361177444458
Validation loss: 2.004395286242167

Epoch: 5| Step: 5
Training loss: 1.8085954189300537
Validation loss: 1.9883742928504944

Epoch: 5| Step: 6
Training loss: 2.095242738723755
Validation loss: 1.988919347524643

Epoch: 5| Step: 7
Training loss: 2.0826416015625
Validation loss: 1.9865447928508122

Epoch: 5| Step: 8
Training loss: 2.1308836936950684
Validation loss: 1.9929217447837193

Epoch: 5| Step: 9
Training loss: 2.029055118560791
Validation loss: 2.002099404732386

Epoch: 5| Step: 10
Training loss: 1.4424166679382324
Validation loss: 1.9696014324824016

Epoch: 5| Step: 11
Training loss: 2.7912368774414062
Validation loss: 1.9624491433302562

Epoch: 62| Step: 0
Training loss: 1.9076849222183228
Validation loss: 2.002276688814163

Epoch: 5| Step: 1
Training loss: 2.210641384124756
Validation loss: 2.040795842806498

Epoch: 5| Step: 2
Training loss: 1.9170997142791748
Validation loss: 2.00541290640831

Epoch: 5| Step: 3
Training loss: 1.5586440563201904
Validation loss: 2.0455391158660254

Epoch: 5| Step: 4
Training loss: 1.935327172279358
Validation loss: 2.0553513020277023

Epoch: 5| Step: 5
Training loss: 1.4922654628753662
Validation loss: 2.0474969148635864

Epoch: 5| Step: 6
Training loss: 2.199270248413086
Validation loss: 2.0409929354985556

Epoch: 5| Step: 7
Training loss: 2.164520740509033
Validation loss: 2.050263454516729

Epoch: 5| Step: 8
Training loss: 1.967728853225708
Validation loss: 2.031690756479899

Epoch: 5| Step: 9
Training loss: 1.632372260093689
Validation loss: 2.0024572809537253

Epoch: 5| Step: 10
Training loss: 1.868208646774292
Validation loss: 2.0326807498931885

Epoch: 5| Step: 11
Training loss: 0.9395440816879272
Validation loss: 1.9981279969215393

Epoch: 63| Step: 0
Training loss: 1.9292652606964111
Validation loss: 2.0108753542105355

Epoch: 5| Step: 1
Training loss: 1.8443329334259033
Validation loss: 2.0328189581632614

Epoch: 5| Step: 2
Training loss: 1.523167371749878
Validation loss: 2.012635479370753

Epoch: 5| Step: 3
Training loss: 2.354736328125
Validation loss: 2.010118077198664

Epoch: 5| Step: 4
Training loss: 1.9228439331054688
Validation loss: 1.9979368895292282

Epoch: 5| Step: 5
Training loss: 1.9310022592544556
Validation loss: 2.005418593684832

Epoch: 5| Step: 6
Training loss: 1.297805666923523
Validation loss: 2.0080397774775824

Epoch: 5| Step: 7
Training loss: 2.485827684402466
Validation loss: 2.0042836914459863

Epoch: 5| Step: 8
Training loss: 1.7803516387939453
Validation loss: 2.048963795105616

Epoch: 5| Step: 9
Training loss: 1.7678543329238892
Validation loss: 2.0018707513809204

Epoch: 5| Step: 10
Training loss: 1.6507714986801147
Validation loss: 2.0219292640686035

Epoch: 5| Step: 11
Training loss: 2.1289472579956055
Validation loss: 2.0214287439982095

Epoch: 64| Step: 0
Training loss: 1.6271839141845703
Validation loss: 1.9859199672937393

Epoch: 5| Step: 1
Training loss: 2.004918098449707
Validation loss: 1.9999169905980427

Epoch: 5| Step: 2
Training loss: 1.9235624074935913
Validation loss: 2.0007942567269006

Epoch: 5| Step: 3
Training loss: 1.4584438800811768
Validation loss: 2.0472868432601294

Epoch: 5| Step: 4
Training loss: 2.3751213550567627
Validation loss: 2.036874602238337

Epoch: 5| Step: 5
Training loss: 2.4017014503479004
Validation loss: 2.0078038473924003

Epoch: 5| Step: 6
Training loss: 1.932560682296753
Validation loss: 2.027412310242653

Epoch: 5| Step: 7
Training loss: 2.0703787803649902
Validation loss: 2.003852436939875

Epoch: 5| Step: 8
Training loss: 1.3437913656234741
Validation loss: 2.0001721928517022

Epoch: 5| Step: 9
Training loss: 1.5971457958221436
Validation loss: 2.0069200843572617

Epoch: 5| Step: 10
Training loss: 2.1529700756073
Validation loss: 1.9859765370686848

Epoch: 5| Step: 11
Training loss: 1.0199044942855835
Validation loss: 2.004970818758011

Epoch: 65| Step: 0
Training loss: 1.5726606845855713
Validation loss: 2.015279327829679

Epoch: 5| Step: 1
Training loss: 2.017052412033081
Validation loss: 1.9870840708414714

Epoch: 5| Step: 2
Training loss: 1.650901436805725
Validation loss: 2.0201946000258126

Epoch: 5| Step: 3
Training loss: 2.072530746459961
Validation loss: 2.0182583332061768

Epoch: 5| Step: 4
Training loss: 1.596678614616394
Validation loss: 1.9773972431818645

Epoch: 5| Step: 5
Training loss: 2.125161647796631
Validation loss: 2.0056496808926263

Epoch: 5| Step: 6
Training loss: 1.642677903175354
Validation loss: 2.0195836226145425

Epoch: 5| Step: 7
Training loss: 2.004927635192871
Validation loss: 1.9873424122730892

Epoch: 5| Step: 8
Training loss: 1.815556287765503
Validation loss: 1.9562262743711472

Epoch: 5| Step: 9
Training loss: 2.269075870513916
Validation loss: 1.975894570350647

Epoch: 5| Step: 10
Training loss: 1.7384891510009766
Validation loss: 2.0031728794177375

Epoch: 5| Step: 11
Training loss: 1.8815257549285889
Validation loss: 2.0165807604789734

Epoch: 66| Step: 0
Training loss: 1.9426769018173218
Validation loss: 2.00486325720946

Epoch: 5| Step: 1
Training loss: 1.4106533527374268
Validation loss: 2.0479750682910285

Epoch: 5| Step: 2
Training loss: 1.7798572778701782
Validation loss: 2.0915658424297967

Epoch: 5| Step: 3
Training loss: 1.9141994714736938
Validation loss: 2.1033990581830344

Epoch: 5| Step: 4
Training loss: 2.168501138687134
Validation loss: 2.1256808737913766

Epoch: 5| Step: 5
Training loss: 1.3683276176452637
Validation loss: 2.1651161710421243

Epoch: 5| Step: 6
Training loss: 2.425217390060425
Validation loss: 2.1248693764209747

Epoch: 5| Step: 7
Training loss: 2.031100034713745
Validation loss: 2.0997419307629266

Epoch: 5| Step: 8
Training loss: 2.165745973587036
Validation loss: 2.063491334517797

Epoch: 5| Step: 9
Training loss: 2.200845241546631
Validation loss: 2.000573898355166

Epoch: 5| Step: 10
Training loss: 1.5822222232818604
Validation loss: 1.9923311918973923

Epoch: 5| Step: 11
Training loss: 1.5544661283493042
Validation loss: 1.9828205903371174

Epoch: 67| Step: 0
Training loss: 1.902166724205017
Validation loss: 1.98330161968867

Epoch: 5| Step: 1
Training loss: 1.4130017757415771
Validation loss: 1.9995630135138829

Epoch: 5| Step: 2
Training loss: 2.1219239234924316
Validation loss: 1.9946764161189396

Epoch: 5| Step: 3
Training loss: 2.1182923316955566
Validation loss: 2.0307352046171823

Epoch: 5| Step: 4
Training loss: 1.6377694606781006
Validation loss: 2.0436795204877853

Epoch: 5| Step: 5
Training loss: 2.23017954826355
Validation loss: 2.0390059550603232

Epoch: 5| Step: 6
Training loss: 1.7531999349594116
Validation loss: 2.0285548865795135

Epoch: 5| Step: 7
Training loss: 1.6615722179412842
Validation loss: 2.0053067753712335

Epoch: 5| Step: 8
Training loss: 1.8374850749969482
Validation loss: 2.0337807138760886

Epoch: 5| Step: 9
Training loss: 1.6412570476531982
Validation loss: 1.9792127559582393

Epoch: 5| Step: 10
Training loss: 2.7162322998046875
Validation loss: 1.9667991697788239

Epoch: 5| Step: 11
Training loss: 2.0634214878082275
Validation loss: 2.0105226983626685

Epoch: 68| Step: 0
Training loss: 2.002903699874878
Validation loss: 2.0040243019660315

Epoch: 5| Step: 1
Training loss: 1.4249083995819092
Validation loss: 1.9952835539976757

Epoch: 5| Step: 2
Training loss: 1.3871424198150635
Validation loss: 2.007361486554146

Epoch: 5| Step: 3
Training loss: 1.5232789516448975
Validation loss: 1.996310497323672

Epoch: 5| Step: 4
Training loss: 2.0241286754608154
Validation loss: 2.0142371157805123

Epoch: 5| Step: 5
Training loss: 1.7193918228149414
Validation loss: 2.0273484687010446

Epoch: 5| Step: 6
Training loss: 2.3872597217559814
Validation loss: 2.0281532059113183

Epoch: 5| Step: 7
Training loss: 2.2966723442077637
Validation loss: 2.0306459118922553

Epoch: 5| Step: 8
Training loss: 2.005056381225586
Validation loss: 2.046230678757032

Epoch: 5| Step: 9
Training loss: 1.9652446508407593
Validation loss: 2.0118340253829956

Epoch: 5| Step: 10
Training loss: 1.6839805841445923
Validation loss: 2.0523544947306314

Epoch: 5| Step: 11
Training loss: 0.7546654343605042
Validation loss: 2.028487573067347

Epoch: 69| Step: 0
Training loss: 1.1952017545700073
Validation loss: 2.0198621402184167

Epoch: 5| Step: 1
Training loss: 1.7650964260101318
Validation loss: 1.9973006546497345

Epoch: 5| Step: 2
Training loss: 2.0973010063171387
Validation loss: 2.0090347677469254

Epoch: 5| Step: 3
Training loss: 2.17509388923645
Validation loss: 2.0101100703080497

Epoch: 5| Step: 4
Training loss: 1.8623549938201904
Validation loss: 2.004261920849482

Epoch: 5| Step: 5
Training loss: 2.2231955528259277
Validation loss: 1.9954715172449748

Epoch: 5| Step: 6
Training loss: 1.7832610607147217
Validation loss: 2.00020103653272

Epoch: 5| Step: 7
Training loss: 1.9899232387542725
Validation loss: 1.9933750828107197

Epoch: 5| Step: 8
Training loss: 1.4809776544570923
Validation loss: 1.977664699157079

Epoch: 5| Step: 9
Training loss: 2.036686420440674
Validation loss: 2.007407397031784

Epoch: 5| Step: 10
Training loss: 1.8460862636566162
Validation loss: 2.0331453134616218

Epoch: 5| Step: 11
Training loss: 2.2729268074035645
Validation loss: 2.00989759961764

Epoch: 70| Step: 0
Training loss: 1.9699872732162476
Validation loss: 2.0322241435448327

Epoch: 5| Step: 1
Training loss: 1.7528140544891357
Validation loss: 2.0376568039258323

Epoch: 5| Step: 2
Training loss: 1.624925971031189
Validation loss: 2.0350830256938934

Epoch: 5| Step: 3
Training loss: 1.805349349975586
Validation loss: 2.037987103064855

Epoch: 5| Step: 4
Training loss: 1.8393852710723877
Validation loss: 2.0518808364868164

Epoch: 5| Step: 5
Training loss: 1.4725425243377686
Validation loss: 2.039706736803055

Epoch: 5| Step: 6
Training loss: 1.6674048900604248
Validation loss: 2.0387267818053565

Epoch: 5| Step: 7
Training loss: 2.472038745880127
Validation loss: 2.0245624432961145

Epoch: 5| Step: 8
Training loss: 1.5315525531768799
Validation loss: 2.017703195412954

Epoch: 5| Step: 9
Training loss: 1.5633628368377686
Validation loss: 2.017920265595118

Epoch: 5| Step: 10
Training loss: 2.321645736694336
Validation loss: 2.032703404625257

Epoch: 5| Step: 11
Training loss: 1.9761574268341064
Validation loss: 2.025157610575358

Epoch: 71| Step: 0
Training loss: 2.0571041107177734
Validation loss: 2.04695987701416

Epoch: 5| Step: 1
Training loss: 2.077507495880127
Validation loss: 2.004925698041916

Epoch: 5| Step: 2
Training loss: 1.5244156122207642
Validation loss: 2.022468055287997

Epoch: 5| Step: 3
Training loss: 1.2951161861419678
Validation loss: 2.0429545789957047

Epoch: 5| Step: 4
Training loss: 1.5440952777862549
Validation loss: 2.0553351591030755

Epoch: 5| Step: 5
Training loss: 2.437384843826294
Validation loss: 2.0743044167757034

Epoch: 5| Step: 6
Training loss: 1.5512231588363647
Validation loss: 2.02014222741127

Epoch: 5| Step: 7
Training loss: 2.0649728775024414
Validation loss: 2.022100935379664

Epoch: 5| Step: 8
Training loss: 1.9022095203399658
Validation loss: 2.0621559669574103

Epoch: 5| Step: 9
Training loss: 1.9750869274139404
Validation loss: 2.044706250230471

Epoch: 5| Step: 10
Training loss: 1.817108392715454
Validation loss: 2.0401109059651694

Epoch: 5| Step: 11
Training loss: 1.8129217624664307
Validation loss: 2.020924602945646

Epoch: 72| Step: 0
Training loss: 1.903416395187378
Validation loss: 2.0249601205190024

Epoch: 5| Step: 1
Training loss: 1.768079161643982
Validation loss: 1.9912680834531784

Epoch: 5| Step: 2
Training loss: 1.5639556646347046
Validation loss: 2.0005942781766257

Epoch: 5| Step: 3
Training loss: 1.4790003299713135
Validation loss: 2.0086394598086676

Epoch: 5| Step: 4
Training loss: 2.262681007385254
Validation loss: 1.9931813577810924

Epoch: 5| Step: 5
Training loss: 1.7325353622436523
Validation loss: 1.992023691534996

Epoch: 5| Step: 6
Training loss: 1.5086463689804077
Validation loss: 1.980347290635109

Epoch: 5| Step: 7
Training loss: 2.3346104621887207
Validation loss: 2.0089525282382965

Epoch: 5| Step: 8
Training loss: 2.160977840423584
Validation loss: 2.0191339949766793

Epoch: 5| Step: 9
Training loss: 2.061131000518799
Validation loss: 1.98905411362648

Epoch: 5| Step: 10
Training loss: 1.4442508220672607
Validation loss: 1.9868568927049637

Epoch: 5| Step: 11
Training loss: 1.6091973781585693
Validation loss: 2.0267980645100274

Epoch: 73| Step: 0
Training loss: 1.4468841552734375
Validation loss: 2.0338781972726188

Epoch: 5| Step: 1
Training loss: 1.7404941320419312
Validation loss: 2.011102572083473

Epoch: 5| Step: 2
Training loss: 2.0508599281311035
Validation loss: 2.001193712155024

Epoch: 5| Step: 3
Training loss: 1.7544275522232056
Validation loss: 2.0019058883190155

Epoch: 5| Step: 4
Training loss: 1.5287563800811768
Validation loss: 2.0124884148438773

Epoch: 5| Step: 5
Training loss: 2.08819842338562
Validation loss: 1.9937863399585087

Epoch: 5| Step: 6
Training loss: 1.309535026550293
Validation loss: 1.9964773555596669

Epoch: 5| Step: 7
Training loss: 2.164548397064209
Validation loss: 2.0213597069183984

Epoch: 5| Step: 8
Training loss: 1.6162770986557007
Validation loss: 1.9817515164613724

Epoch: 5| Step: 9
Training loss: 1.9186627864837646
Validation loss: 2.020607054233551

Epoch: 5| Step: 10
Training loss: 2.4457573890686035
Validation loss: 1.9999169458945592

Epoch: 5| Step: 11
Training loss: 1.050879955291748
Validation loss: 2.027779534459114

Epoch: 74| Step: 0
Training loss: 1.57073175907135
Validation loss: 2.0376038750012717

Epoch: 5| Step: 1
Training loss: 1.8755338191986084
Validation loss: 2.0305601259072623

Epoch: 5| Step: 2
Training loss: 1.7380434274673462
Validation loss: 2.0690974444150925

Epoch: 5| Step: 3
Training loss: 1.8759918212890625
Validation loss: 2.068673292795817

Epoch: 5| Step: 4
Training loss: 1.5052229166030884
Validation loss: 2.048585216204325

Epoch: 5| Step: 5
Training loss: 2.173673391342163
Validation loss: 2.066527580221494

Epoch: 5| Step: 6
Training loss: 2.1978988647460938
Validation loss: 2.0187295426925025

Epoch: 5| Step: 7
Training loss: 1.7706451416015625
Validation loss: 2.021177813410759

Epoch: 5| Step: 8
Training loss: 1.7950847148895264
Validation loss: 2.003958354393641

Epoch: 5| Step: 9
Training loss: 1.9324302673339844
Validation loss: 2.0260957032442093

Epoch: 5| Step: 10
Training loss: 1.6720330715179443
Validation loss: 2.0253931184609733

Epoch: 5| Step: 11
Training loss: 1.666966438293457
Validation loss: 1.9949093361695607

Epoch: 75| Step: 0
Training loss: 1.2040379047393799
Validation loss: 2.016134669383367

Epoch: 5| Step: 1
Training loss: 1.6035821437835693
Validation loss: 1.9967424273490906

Epoch: 5| Step: 2
Training loss: 1.5969107151031494
Validation loss: 2.007780278722445

Epoch: 5| Step: 3
Training loss: 2.5855507850646973
Validation loss: 1.9962833921114604

Epoch: 5| Step: 4
Training loss: 2.066284418106079
Validation loss: 2.0236794501543045

Epoch: 5| Step: 5
Training loss: 1.4503793716430664
Validation loss: 1.9669330815474193

Epoch: 5| Step: 6
Training loss: 2.2053885459899902
Validation loss: 1.994919886191686

Epoch: 5| Step: 7
Training loss: 2.0613787174224854
Validation loss: 1.996693844596545

Epoch: 5| Step: 8
Training loss: 1.6047322750091553
Validation loss: 2.000893692175547

Epoch: 5| Step: 9
Training loss: 1.9807920455932617
Validation loss: 2.003117968638738

Epoch: 5| Step: 10
Training loss: 2.023503065109253
Validation loss: 2.0210447013378143

Epoch: 5| Step: 11
Training loss: 0.9522520303726196
Validation loss: 2.020858277877172

Epoch: 76| Step: 0
Training loss: 1.6195251941680908
Validation loss: 2.0279177824656167

Epoch: 5| Step: 1
Training loss: 1.9733364582061768
Validation loss: 1.9953581045071285

Epoch: 5| Step: 2
Training loss: 1.8169008493423462
Validation loss: 2.006223832567533

Epoch: 5| Step: 3
Training loss: 2.0351078510284424
Validation loss: 2.071676418185234

Epoch: 5| Step: 4
Training loss: 1.4909107685089111
Validation loss: 2.0483373403549194

Epoch: 5| Step: 5
Training loss: 2.2700154781341553
Validation loss: 2.063791702191035

Epoch: 5| Step: 6
Training loss: 1.8278814554214478
Validation loss: 2.0401195536057153

Epoch: 5| Step: 7
Training loss: 1.8495960235595703
Validation loss: 2.032161941130956

Epoch: 5| Step: 8
Training loss: 1.6808149814605713
Validation loss: 2.0143304765224457

Epoch: 5| Step: 9
Training loss: 2.072019577026367
Validation loss: 2.0237608601649604

Epoch: 5| Step: 10
Training loss: 1.3493804931640625
Validation loss: 2.029056722919146

Epoch: 5| Step: 11
Training loss: 0.7418577671051025
Validation loss: 2.0070162067810693

Epoch: 77| Step: 0
Training loss: 2.2458553314208984
Validation loss: 1.9941771378119786

Epoch: 5| Step: 1
Training loss: 1.5159648656845093
Validation loss: 2.0244948863983154

Epoch: 5| Step: 2
Training loss: 2.388449192047119
Validation loss: 2.0280407518148422

Epoch: 5| Step: 3
Training loss: 1.6924159526824951
Validation loss: 2.010931819677353

Epoch: 5| Step: 4
Training loss: 1.1945298910140991
Validation loss: 2.0388074815273285

Epoch: 5| Step: 5
Training loss: 1.7668225765228271
Validation loss: 2.0192643155654273

Epoch: 5| Step: 6
Training loss: 2.3501429557800293
Validation loss: 2.0094677905241647

Epoch: 5| Step: 7
Training loss: 1.3980119228363037
Validation loss: 2.0016759634017944

Epoch: 5| Step: 8
Training loss: 1.6305335760116577
Validation loss: 2.0281656930843988

Epoch: 5| Step: 9
Training loss: 1.3734229803085327
Validation loss: 2.0023694137732186

Epoch: 5| Step: 10
Training loss: 2.118039608001709
Validation loss: 1.9936875402927399

Epoch: 5| Step: 11
Training loss: 1.8137587308883667
Validation loss: 2.008301869034767

Epoch: 78| Step: 0
Training loss: 2.1668505668640137
Validation loss: 2.011306112011274

Epoch: 5| Step: 1
Training loss: 1.9963023662567139
Validation loss: 2.0025181621313095

Epoch: 5| Step: 2
Training loss: 1.8521184921264648
Validation loss: 2.0260132253170013

Epoch: 5| Step: 3
Training loss: 2.187187910079956
Validation loss: 1.970941459139188

Epoch: 5| Step: 4
Training loss: 1.3660894632339478
Validation loss: 1.9950265487035115

Epoch: 5| Step: 5
Training loss: 1.9260364770889282
Validation loss: 1.9814250965913136

Epoch: 5| Step: 6
Training loss: 1.3526265621185303
Validation loss: 1.9762741674979527

Epoch: 5| Step: 7
Training loss: 1.5525668859481812
Validation loss: 2.0158043106396994

Epoch: 5| Step: 8
Training loss: 1.6082757711410522
Validation loss: 2.028233448664347

Epoch: 5| Step: 9
Training loss: 1.6526014804840088
Validation loss: 2.0228878408670425

Epoch: 5| Step: 10
Training loss: 1.878451943397522
Validation loss: 2.020760397116343

Epoch: 5| Step: 11
Training loss: 2.5525362491607666
Validation loss: 2.0370099544525146

Epoch: 79| Step: 0
Training loss: 2.2827816009521484
Validation loss: 2.079544633626938

Epoch: 5| Step: 1
Training loss: 1.8621689081192017
Validation loss: 2.065692186355591

Epoch: 5| Step: 2
Training loss: 1.9444687366485596
Validation loss: 2.125848417480787

Epoch: 5| Step: 3
Training loss: 2.029949188232422
Validation loss: 2.0789349426825843

Epoch: 5| Step: 4
Training loss: 2.0474228858947754
Validation loss: 2.0513206273317337

Epoch: 5| Step: 5
Training loss: 1.2660292387008667
Validation loss: 2.050481309493383

Epoch: 5| Step: 6
Training loss: 1.3375391960144043
Validation loss: 2.0362170239289603

Epoch: 5| Step: 7
Training loss: 1.673409104347229
Validation loss: 2.0006441473960876

Epoch: 5| Step: 8
Training loss: 1.2804418802261353
Validation loss: 2.012529601653417

Epoch: 5| Step: 9
Training loss: 2.56394100189209
Validation loss: 1.9956386039654415

Epoch: 5| Step: 10
Training loss: 1.7537959814071655
Validation loss: 2.0318357000748315

Epoch: 5| Step: 11
Training loss: 1.8802920579910278
Validation loss: 2.030102401971817

Epoch: 80| Step: 0
Training loss: 2.149475336074829
Validation loss: 1.9950899481773376

Epoch: 5| Step: 1
Training loss: 1.9967511892318726
Validation loss: 2.0241298774878183

Epoch: 5| Step: 2
Training loss: 1.4815596342086792
Validation loss: 2.030302107334137

Epoch: 5| Step: 3
Training loss: 1.7933056354522705
Validation loss: 2.0276072124640145

Epoch: 5| Step: 4
Training loss: 2.4395644664764404
Validation loss: 1.9961431870857875

Epoch: 5| Step: 5
Training loss: 1.9538047313690186
Validation loss: 1.9944920788208644

Epoch: 5| Step: 6
Training loss: 1.3102784156799316
Validation loss: 2.0094517966111503

Epoch: 5| Step: 7
Training loss: 1.1803284883499146
Validation loss: 2.0393906931082406

Epoch: 5| Step: 8
Training loss: 1.7269700765609741
Validation loss: 2.0144771734873452

Epoch: 5| Step: 9
Training loss: 1.6891168355941772
Validation loss: 2.0137563397487006

Epoch: 5| Step: 10
Training loss: 1.749809980392456
Validation loss: 2.0288079430659614

Epoch: 5| Step: 11
Training loss: 1.9791629314422607
Validation loss: 2.0648699899514518

Epoch: 81| Step: 0
Training loss: 1.6321251392364502
Validation loss: 2.0654112001260123

Epoch: 5| Step: 1
Training loss: 1.954846978187561
Validation loss: 2.0810612638791404

Epoch: 5| Step: 2
Training loss: 1.267902135848999
Validation loss: 2.0941607654094696

Epoch: 5| Step: 3
Training loss: 2.0072834491729736
Validation loss: 2.0597685227791467

Epoch: 5| Step: 4
Training loss: 2.519859790802002
Validation loss: 2.0784061749776206

Epoch: 5| Step: 5
Training loss: 1.6801230907440186
Validation loss: 2.0803588181734085

Epoch: 5| Step: 6
Training loss: 1.3859031200408936
Validation loss: 2.060790409644445

Epoch: 5| Step: 7
Training loss: 2.0546669960021973
Validation loss: 2.0155798892180123

Epoch: 5| Step: 8
Training loss: 1.4212270975112915
Validation loss: 2.0122583905855813

Epoch: 5| Step: 9
Training loss: 1.8338258266448975
Validation loss: 2.0072236210107803

Epoch: 5| Step: 10
Training loss: 1.838700532913208
Validation loss: 2.0259075661500296

Epoch: 5| Step: 11
Training loss: 2.11264705657959
Validation loss: 2.000420108437538

Epoch: 82| Step: 0
Training loss: 1.5747121572494507
Validation loss: 2.012043982744217

Epoch: 5| Step: 1
Training loss: 1.5639790296554565
Validation loss: 2.016208757956823

Epoch: 5| Step: 2
Training loss: 1.6822710037231445
Validation loss: 2.047448063890139

Epoch: 5| Step: 3
Training loss: 2.1772656440734863
Validation loss: 2.0135613779226937

Epoch: 5| Step: 4
Training loss: 1.5676535367965698
Validation loss: 2.026592676838239

Epoch: 5| Step: 5
Training loss: 1.8705469369888306
Validation loss: 1.9939480473597844

Epoch: 5| Step: 6
Training loss: 1.967807412147522
Validation loss: 2.015804504354795

Epoch: 5| Step: 7
Training loss: 1.5083320140838623
Validation loss: 2.0160953054825463

Epoch: 5| Step: 8
Training loss: 1.8888673782348633
Validation loss: 2.005909080306689

Epoch: 5| Step: 9
Training loss: 2.1045567989349365
Validation loss: 2.032859221100807

Epoch: 5| Step: 10
Training loss: 1.7399232387542725
Validation loss: 2.018831173578898

Epoch: 5| Step: 11
Training loss: 0.8856204152107239
Validation loss: 2.0241123040517173

Epoch: 83| Step: 0
Training loss: 1.8848539590835571
Validation loss: 2.0292104383309684

Epoch: 5| Step: 1
Training loss: 2.0827484130859375
Validation loss: 2.0355251183112464

Epoch: 5| Step: 2
Training loss: 1.9719083309173584
Validation loss: 2.0753524055083594

Epoch: 5| Step: 3
Training loss: 2.0416438579559326
Validation loss: 2.0590283622344336

Epoch: 5| Step: 4
Training loss: 1.5692013502120972
Validation loss: 2.0416616102059684

Epoch: 5| Step: 5
Training loss: 1.3401362895965576
Validation loss: 2.060391237338384

Epoch: 5| Step: 6
Training loss: 1.3301221132278442
Validation loss: 2.066019023458163

Epoch: 5| Step: 7
Training loss: 2.250877857208252
Validation loss: 2.0332339704036713

Epoch: 5| Step: 8
Training loss: 1.2591816186904907
Validation loss: 1.9964046825965245

Epoch: 5| Step: 9
Training loss: 1.9521808624267578
Validation loss: 2.0468499263127646

Epoch: 5| Step: 10
Training loss: 1.5488317012786865
Validation loss: 2.01169586678346

Epoch: 5| Step: 11
Training loss: 1.0360517501831055
Validation loss: 2.00498403608799

Epoch: 84| Step: 0
Training loss: 1.5735414028167725
Validation loss: 1.991653988758723

Epoch: 5| Step: 1
Training loss: 1.6402862071990967
Validation loss: 1.998382901151975

Epoch: 5| Step: 2
Training loss: 1.6262563467025757
Validation loss: 2.028999447822571

Epoch: 5| Step: 3
Training loss: 1.4084722995758057
Validation loss: 1.9900565991799037

Epoch: 5| Step: 4
Training loss: 1.628521203994751
Validation loss: 2.020324389139811

Epoch: 5| Step: 5
Training loss: 2.3089239597320557
Validation loss: 1.9743887931108475

Epoch: 5| Step: 6
Training loss: 1.7131189107894897
Validation loss: 2.0066465685764947

Epoch: 5| Step: 7
Training loss: 2.3159420490264893
Validation loss: 2.0299674371878305

Epoch: 5| Step: 8
Training loss: 1.985368013381958
Validation loss: 2.0217627038558326

Epoch: 5| Step: 9
Training loss: 1.7282593250274658
Validation loss: 2.0147623966137567

Epoch: 5| Step: 10
Training loss: 1.501010537147522
Validation loss: 2.0399416287740073

Epoch: 5| Step: 11
Training loss: 2.4923956394195557
Validation loss: 2.039440671602885

Epoch: 85| Step: 0
Training loss: 1.7936897277832031
Validation loss: 2.0520318349202475

Epoch: 5| Step: 1
Training loss: 1.5485748052597046
Validation loss: 2.0517711490392685

Epoch: 5| Step: 2
Training loss: 1.9836177825927734
Validation loss: 2.0599363297224045

Epoch: 5| Step: 3
Training loss: 1.4511239528656006
Validation loss: 2.0427329440911612

Epoch: 5| Step: 4
Training loss: 2.3803749084472656
Validation loss: 2.044358571370443

Epoch: 5| Step: 5
Training loss: 1.361314296722412
Validation loss: 2.0659789790709815

Epoch: 5| Step: 6
Training loss: 2.322197914123535
Validation loss: 2.053051342566808

Epoch: 5| Step: 7
Training loss: 1.603411078453064
Validation loss: 2.01486387103796

Epoch: 5| Step: 8
Training loss: 1.8997522592544556
Validation loss: 1.9996834993362427

Epoch: 5| Step: 9
Training loss: 1.248241662979126
Validation loss: 2.015253489216169

Epoch: 5| Step: 10
Training loss: 1.8437252044677734
Validation loss: 2.0210696359475455

Epoch: 5| Step: 11
Training loss: 0.9906713962554932
Validation loss: 2.007360572616259

Epoch: 86| Step: 0
Training loss: 1.6004524230957031
Validation loss: 2.023861433068911

Epoch: 5| Step: 1
Training loss: 1.5684523582458496
Validation loss: 2.0149114529291787

Epoch: 5| Step: 2
Training loss: 1.9574031829833984
Validation loss: 2.021558001637459

Epoch: 5| Step: 3
Training loss: 1.6421558856964111
Validation loss: 2.034272854526838

Epoch: 5| Step: 4
Training loss: 1.5249507427215576
Validation loss: 2.0202166686455407

Epoch: 5| Step: 5
Training loss: 1.425891399383545
Validation loss: 1.9967983663082123

Epoch: 5| Step: 6
Training loss: 2.4358348846435547
Validation loss: 2.0396972397963204

Epoch: 5| Step: 7
Training loss: 2.1281378269195557
Validation loss: 2.0300660828749337

Epoch: 5| Step: 8
Training loss: 1.7110878229141235
Validation loss: 2.05419651667277

Epoch: 5| Step: 9
Training loss: 1.9372222423553467
Validation loss: 2.0704939315716424

Epoch: 5| Step: 10
Training loss: 1.5571659803390503
Validation loss: 2.0794731030861535

Epoch: 5| Step: 11
Training loss: 1.7955363988876343
Validation loss: 2.0903907418251038

Epoch: 87| Step: 0
Training loss: 1.7297592163085938
Validation loss: 1.9883151799440384

Epoch: 5| Step: 1
Training loss: 2.1237831115722656
Validation loss: 1.988962193330129

Epoch: 5| Step: 2
Training loss: 1.2993476390838623
Validation loss: 2.0107389638821282

Epoch: 5| Step: 3
Training loss: 1.9117752313613892
Validation loss: 2.0270921140909195

Epoch: 5| Step: 4
Training loss: 1.9099643230438232
Validation loss: 2.041827698548635

Epoch: 5| Step: 5
Training loss: 1.5160491466522217
Validation loss: 2.0238861242930093

Epoch: 5| Step: 6
Training loss: 1.6937538385391235
Validation loss: 2.0239709665377936

Epoch: 5| Step: 7
Training loss: 1.7309248447418213
Validation loss: 2.00081866979599

Epoch: 5| Step: 8
Training loss: 1.6395556926727295
Validation loss: 1.9944805800914764

Epoch: 5| Step: 9
Training loss: 1.4654552936553955
Validation loss: 2.047757461667061

Epoch: 5| Step: 10
Training loss: 2.1762421131134033
Validation loss: 2.0338121453921

Epoch: 5| Step: 11
Training loss: 3.172572374343872
Validation loss: 2.0400467018286386

Epoch: 88| Step: 0
Training loss: 1.831332802772522
Validation loss: 2.073837806781133

Epoch: 5| Step: 1
Training loss: 1.5693769454956055
Validation loss: 2.0522986203432083

Epoch: 5| Step: 2
Training loss: 1.9439948797225952
Validation loss: 2.0713333437840142

Epoch: 5| Step: 3
Training loss: 1.7037057876586914
Validation loss: 2.0676740209261575

Epoch: 5| Step: 4
Training loss: 1.9789555072784424
Validation loss: 2.0619510461886725

Epoch: 5| Step: 5
Training loss: 1.9112526178359985
Validation loss: 2.0416918148597083

Epoch: 5| Step: 6
Training loss: 1.9730298519134521
Validation loss: 2.016813645760218

Epoch: 5| Step: 7
Training loss: 1.3752610683441162
Validation loss: 2.0148681153853736

Epoch: 5| Step: 8
Training loss: 1.4829787015914917
Validation loss: 2.0408854484558105

Epoch: 5| Step: 9
Training loss: 1.4143517017364502
Validation loss: 2.028743157784144

Epoch: 5| Step: 10
Training loss: 1.5378202199935913
Validation loss: 1.989550640185674

Epoch: 5| Step: 11
Training loss: 3.0620107650756836
Validation loss: 2.0064543088277182

Epoch: 89| Step: 0
Training loss: 1.4617456197738647
Validation loss: 2.051621894041697

Epoch: 5| Step: 1
Training loss: 1.5262641906738281
Validation loss: 2.0049029489358268

Epoch: 5| Step: 2
Training loss: 1.9449856281280518
Validation loss: 2.017462690671285

Epoch: 5| Step: 3
Training loss: 1.4700038433074951
Validation loss: 1.998259315888087

Epoch: 5| Step: 4
Training loss: 1.8931862115859985
Validation loss: 2.0493862877289453

Epoch: 5| Step: 5
Training loss: 1.0284626483917236
Validation loss: 2.031765878200531

Epoch: 5| Step: 6
Training loss: 2.115856647491455
Validation loss: 2.018880253036817

Epoch: 5| Step: 7
Training loss: 2.193533420562744
Validation loss: 2.0451692789793015

Epoch: 5| Step: 8
Training loss: 1.5964272022247314
Validation loss: 2.0086567948261895

Epoch: 5| Step: 9
Training loss: 2.0346474647521973
Validation loss: 2.0237505584955215

Epoch: 5| Step: 10
Training loss: 1.782665491104126
Validation loss: 2.010997638106346

Epoch: 5| Step: 11
Training loss: 1.3891197443008423
Validation loss: 1.9984257320563

Epoch: 90| Step: 0
Training loss: 1.6645317077636719
Validation loss: 1.998726059993108

Epoch: 5| Step: 1
Training loss: 1.5610134601593018
Validation loss: 2.0100166896979013

Epoch: 5| Step: 2
Training loss: 1.456300139427185
Validation loss: 2.016185944279035

Epoch: 5| Step: 3
Training loss: 1.4320449829101562
Validation loss: 2.012330194314321

Epoch: 5| Step: 4
Training loss: 2.549506425857544
Validation loss: 2.016559804479281

Epoch: 5| Step: 5
Training loss: 1.786512017250061
Validation loss: 1.9961697111527126

Epoch: 5| Step: 6
Training loss: 2.0237011909484863
Validation loss: 2.006742626428604

Epoch: 5| Step: 7
Training loss: 1.6819722652435303
Validation loss: 2.0296652615070343

Epoch: 5| Step: 8
Training loss: 1.22244393825531
Validation loss: 1.9863828072945278

Epoch: 5| Step: 9
Training loss: 1.4850339889526367
Validation loss: 1.972650522987048

Epoch: 5| Step: 10
Training loss: 2.124009609222412
Validation loss: 2.0121086835861206

Epoch: 5| Step: 11
Training loss: 2.5899930000305176
Validation loss: 2.0064721405506134

Epoch: 91| Step: 0
Training loss: 1.7188303470611572
Validation loss: 2.0239697893460593

Epoch: 5| Step: 1
Training loss: 1.9720252752304077
Validation loss: 2.054508790373802

Epoch: 5| Step: 2
Training loss: 1.6522915363311768
Validation loss: 2.078979695836703

Epoch: 5| Step: 3
Training loss: 1.7864269018173218
Validation loss: 2.0970170150200524

Epoch: 5| Step: 4
Training loss: 1.9536726474761963
Validation loss: 2.1125058184067407

Epoch: 5| Step: 5
Training loss: 1.776365876197815
Validation loss: 2.088426167766253

Epoch: 5| Step: 6
Training loss: 1.5029538869857788
Validation loss: 2.077163130044937

Epoch: 5| Step: 7
Training loss: 1.6391899585723877
Validation loss: 2.0397137304147086

Epoch: 5| Step: 8
Training loss: 1.5409691333770752
Validation loss: 2.0467716455459595

Epoch: 5| Step: 9
Training loss: 2.05470871925354
Validation loss: 2.0228098382552466

Epoch: 5| Step: 10
Training loss: 1.6532487869262695
Validation loss: 2.0153810729583106

Epoch: 5| Step: 11
Training loss: 1.5351778268814087
Validation loss: 2.0053751269976297

Epoch: 92| Step: 0
Training loss: 1.6068099737167358
Validation loss: 1.9977032939592998

Epoch: 5| Step: 1
Training loss: 1.6178834438323975
Validation loss: 2.008898069461187

Epoch: 5| Step: 2
Training loss: 1.9305137395858765
Validation loss: 1.9941368301709492

Epoch: 5| Step: 3
Training loss: 1.0306352376937866
Validation loss: 2.0287014146645865

Epoch: 5| Step: 4
Training loss: 1.375017762184143
Validation loss: 2.015787268678347

Epoch: 5| Step: 5
Training loss: 2.1606225967407227
Validation loss: 2.0565143674612045

Epoch: 5| Step: 6
Training loss: 2.1228370666503906
Validation loss: 2.0268965363502502

Epoch: 5| Step: 7
Training loss: 1.771226167678833
Validation loss: 2.036581888794899

Epoch: 5| Step: 8
Training loss: 1.545096755027771
Validation loss: 2.0570522099733353

Epoch: 5| Step: 9
Training loss: 1.6917774677276611
Validation loss: 2.0745226740837097

Epoch: 5| Step: 10
Training loss: 2.1825461387634277
Validation loss: 2.0445036639769874

Epoch: 5| Step: 11
Training loss: 1.068099021911621
Validation loss: 2.071168437600136

Epoch: 93| Step: 0
Training loss: 1.7746860980987549
Validation loss: 1.9938240945339203

Epoch: 5| Step: 1
Training loss: 1.7467238903045654
Validation loss: 2.0222223003705344

Epoch: 5| Step: 2
Training loss: 1.6431503295898438
Validation loss: 2.0128098080555596

Epoch: 5| Step: 3
Training loss: 1.6246391534805298
Validation loss: 2.0090832908948264

Epoch: 5| Step: 4
Training loss: 1.7363450527191162
Validation loss: 2.021917720635732

Epoch: 5| Step: 5
Training loss: 2.0355865955352783
Validation loss: 2.0254517247279487

Epoch: 5| Step: 6
Training loss: 1.180483341217041
Validation loss: 2.060456727941831

Epoch: 5| Step: 7
Training loss: 1.4113705158233643
Validation loss: 1.9822392563025157

Epoch: 5| Step: 8
Training loss: 1.763808250427246
Validation loss: 2.0255379478136697

Epoch: 5| Step: 9
Training loss: 1.448939323425293
Validation loss: 2.001697098215421

Epoch: 5| Step: 10
Training loss: 1.8814866542816162
Validation loss: 2.0234529276688895

Epoch: 5| Step: 11
Training loss: 2.7617664337158203
Validation loss: 2.0279752363761268

Epoch: 94| Step: 0
Training loss: 2.258242130279541
Validation loss: 2.0361185371875763

Epoch: 5| Step: 1
Training loss: 1.324843168258667
Validation loss: 2.0399821400642395

Epoch: 5| Step: 2
Training loss: 1.901937484741211
Validation loss: 2.0149224599202475

Epoch: 5| Step: 3
Training loss: 1.2862063646316528
Validation loss: 2.036826347311338

Epoch: 5| Step: 4
Training loss: 1.8325992822647095
Validation loss: 2.0069305996100106

Epoch: 5| Step: 5
Training loss: 1.8951616287231445
Validation loss: 2.0191331803798676

Epoch: 5| Step: 6
Training loss: 1.153986930847168
Validation loss: 2.0310893853505454

Epoch: 5| Step: 7
Training loss: 0.9915722012519836
Validation loss: 2.073523680369059

Epoch: 5| Step: 8
Training loss: 2.7221577167510986
Validation loss: 2.0552201519409814

Epoch: 5| Step: 9
Training loss: 1.485516905784607
Validation loss: 2.0381549894809723

Epoch: 5| Step: 10
Training loss: 1.6592655181884766
Validation loss: 2.0390916814406714

Epoch: 5| Step: 11
Training loss: 1.1418043375015259
Validation loss: 2.0267615964015326

Epoch: 95| Step: 0
Training loss: 1.496504783630371
Validation loss: 2.0175117005904517

Epoch: 5| Step: 1
Training loss: 1.5874125957489014
Validation loss: 2.0326991279919944

Epoch: 5| Step: 2
Training loss: 2.20752215385437
Validation loss: 2.0135409583648047

Epoch: 5| Step: 3
Training loss: 1.7647888660430908
Validation loss: 2.038441479206085

Epoch: 5| Step: 4
Training loss: 1.3500187397003174
Validation loss: 2.000425507624944

Epoch: 5| Step: 5
Training loss: 1.6639732122421265
Validation loss: 1.9958820243676503

Epoch: 5| Step: 6
Training loss: 1.339250922203064
Validation loss: 1.981597935160001

Epoch: 5| Step: 7
Training loss: 2.158656597137451
Validation loss: 2.001010795434316

Epoch: 5| Step: 8
Training loss: 1.5366917848587036
Validation loss: 2.042673428853353

Epoch: 5| Step: 9
Training loss: 1.9135894775390625
Validation loss: 2.0100195507208505

Epoch: 5| Step: 10
Training loss: 1.3100221157073975
Validation loss: 2.078905542691549

Epoch: 5| Step: 11
Training loss: 1.775835633277893
Validation loss: 2.0663828353087106

Epoch: 96| Step: 0
Training loss: 1.2467392683029175
Validation loss: 2.0597827285528183

Epoch: 5| Step: 1
Training loss: 1.7578521966934204
Validation loss: 2.035745213429133

Epoch: 5| Step: 2
Training loss: 1.2933852672576904
Validation loss: 2.036936193704605

Epoch: 5| Step: 3
Training loss: 2.288118362426758
Validation loss: 2.026382486025492

Epoch: 5| Step: 4
Training loss: 1.5918662548065186
Validation loss: 2.0020255794127784

Epoch: 5| Step: 5
Training loss: 1.7127443552017212
Validation loss: 2.030302216609319

Epoch: 5| Step: 6
Training loss: 1.4443280696868896
Validation loss: 2.0227629939715066

Epoch: 5| Step: 7
Training loss: 1.8320144414901733
Validation loss: 2.0187223652998605

Epoch: 5| Step: 8
Training loss: 1.7892296314239502
Validation loss: 1.987237016359965

Epoch: 5| Step: 9
Training loss: 1.4205642938613892
Validation loss: 2.033022021253904

Epoch: 5| Step: 10
Training loss: 1.827315330505371
Validation loss: 2.02547978858153

Epoch: 5| Step: 11
Training loss: 1.6786277294158936
Validation loss: 2.021667664249738

Epoch: 97| Step: 0
Training loss: 1.5590869188308716
Validation loss: 2.0195196121931076

Epoch: 5| Step: 1
Training loss: 1.424078345298767
Validation loss: 2.0177282243967056

Epoch: 5| Step: 2
Training loss: 1.9892635345458984
Validation loss: 2.05971559882164

Epoch: 5| Step: 3
Training loss: 1.4118834733963013
Validation loss: 2.0180525481700897

Epoch: 5| Step: 4
Training loss: 1.5497773885726929
Validation loss: 2.064671143889427

Epoch: 5| Step: 5
Training loss: 1.7592846155166626
Validation loss: 2.0445527732372284

Epoch: 5| Step: 6
Training loss: 1.5776088237762451
Validation loss: 2.0203360418478646

Epoch: 5| Step: 7
Training loss: 1.4933457374572754
Validation loss: 2.0260548194249473

Epoch: 5| Step: 8
Training loss: 2.042816638946533
Validation loss: 2.036137009660403

Epoch: 5| Step: 9
Training loss: 1.7663295269012451
Validation loss: 2.042339493830999

Epoch: 5| Step: 10
Training loss: 1.2909352779388428
Validation loss: 2.0471179286638894

Epoch: 5| Step: 11
Training loss: 3.271772861480713
Validation loss: 1.9931569298108418

Epoch: 98| Step: 0
Training loss: 1.8370792865753174
Validation loss: 2.016877834995588

Epoch: 5| Step: 1
Training loss: 1.77627694606781
Validation loss: 2.021432792147001

Epoch: 5| Step: 2
Training loss: 1.681078314781189
Validation loss: 2.058138355612755

Epoch: 5| Step: 3
Training loss: 1.4718598127365112
Validation loss: 2.000163197517395

Epoch: 5| Step: 4
Training loss: 1.549142599105835
Validation loss: 2.0279071976741156

Epoch: 5| Step: 5
Training loss: 1.788832426071167
Validation loss: 1.9916982203722

Epoch: 5| Step: 6
Training loss: 1.2700166702270508
Validation loss: 2.0172734459241233

Epoch: 5| Step: 7
Training loss: 1.6495901346206665
Validation loss: 1.9996962696313858

Epoch: 5| Step: 8
Training loss: 1.0071085691452026
Validation loss: 2.0205634931723275

Epoch: 5| Step: 9
Training loss: 1.828468918800354
Validation loss: 2.0405199776093164

Epoch: 5| Step: 10
Training loss: 2.143188238143921
Validation loss: 2.0411097407341003

Epoch: 5| Step: 11
Training loss: 1.0151785612106323
Validation loss: 2.009691293040911

Epoch: 99| Step: 0
Training loss: 1.535561203956604
Validation loss: 2.02960134545962

Epoch: 5| Step: 1
Training loss: 1.3291807174682617
Validation loss: 1.9723106920719147

Epoch: 5| Step: 2
Training loss: 2.0823302268981934
Validation loss: 2.043967142701149

Epoch: 5| Step: 3
Training loss: 1.9498999118804932
Validation loss: 2.0121232122182846

Epoch: 5| Step: 4
Training loss: 1.795250654220581
Validation loss: 2.0305348138014474

Epoch: 5| Step: 5
Training loss: 1.1710569858551025
Validation loss: 2.018636241555214

Epoch: 5| Step: 6
Training loss: 1.9093992710113525
Validation loss: 2.0269362876812616

Epoch: 5| Step: 7
Training loss: 2.1622464656829834
Validation loss: 2.0301218231519065

Epoch: 5| Step: 8
Training loss: 1.37324857711792
Validation loss: 2.016621251900991

Epoch: 5| Step: 9
Training loss: 1.3722507953643799
Validation loss: 2.007697969675064

Epoch: 5| Step: 10
Training loss: 1.3988816738128662
Validation loss: 2.0625548710425696

Epoch: 5| Step: 11
Training loss: 2.1996729373931885
Validation loss: 2.0652372588713965

Epoch: 100| Step: 0
Training loss: 1.3514257669448853
Validation loss: 2.065786356727282

Epoch: 5| Step: 1
Training loss: 1.9298832416534424
Validation loss: 2.1055866479873657

Epoch: 5| Step: 2
Training loss: 2.138038158416748
Validation loss: 2.0938580334186554

Epoch: 5| Step: 3
Training loss: 1.7623100280761719
Validation loss: 2.09094467262427

Epoch: 5| Step: 4
Training loss: 0.9906711578369141
Validation loss: 2.082536538441976

Epoch: 5| Step: 5
Training loss: 1.145871877670288
Validation loss: 2.0364070932070413

Epoch: 5| Step: 6
Training loss: 2.0953383445739746
Validation loss: 2.0470347801844277

Epoch: 5| Step: 7
Training loss: 1.7091891765594482
Validation loss: 2.0166160811980567

Epoch: 5| Step: 8
Training loss: 1.690505027770996
Validation loss: 2.010447636246681

Epoch: 5| Step: 9
Training loss: 1.6016225814819336
Validation loss: 2.030041128396988

Epoch: 5| Step: 10
Training loss: 1.5666840076446533
Validation loss: 2.016295929749807

Epoch: 5| Step: 11
Training loss: 2.3070895671844482
Validation loss: 2.0329569478829703

Epoch: 101| Step: 0
Training loss: 1.6467344760894775
Validation loss: 2.0207038074731827

Epoch: 5| Step: 1
Training loss: 2.2200608253479004
Validation loss: 2.055987815062205

Epoch: 5| Step: 2
Training loss: 1.4288488626480103
Validation loss: 2.0228973031044006

Epoch: 5| Step: 3
Training loss: 1.2490251064300537
Validation loss: 2.0296098788579306

Epoch: 5| Step: 4
Training loss: 1.3723801374435425
Validation loss: 2.0135317792495093

Epoch: 5| Step: 5
Training loss: 2.0358493328094482
Validation loss: 2.0564261029163995

Epoch: 5| Step: 6
Training loss: 1.1256160736083984
Validation loss: 2.0088406056165695

Epoch: 5| Step: 7
Training loss: 1.6438729763031006
Validation loss: 2.075352763136228

Epoch: 5| Step: 8
Training loss: 1.2215901613235474
Validation loss: 2.053612142801285

Epoch: 5| Step: 9
Training loss: 2.2481367588043213
Validation loss: 2.050040915608406

Epoch: 5| Step: 10
Training loss: 1.9062376022338867
Validation loss: 2.0519608855247498

Epoch: 5| Step: 11
Training loss: 1.5756182670593262
Validation loss: 2.019600828488668

Epoch: 102| Step: 0
Training loss: 1.3515360355377197
Validation loss: 2.039510746796926

Epoch: 5| Step: 1
Training loss: 1.7558066844940186
Validation loss: 2.0361739893754325

Epoch: 5| Step: 2
Training loss: 1.7404741048812866
Validation loss: 1.987697998682658

Epoch: 5| Step: 3
Training loss: 1.1870360374450684
Validation loss: 2.017342915137609

Epoch: 5| Step: 4
Training loss: 2.052231550216675
Validation loss: 2.003104949990908

Epoch: 5| Step: 5
Training loss: 1.5729666948318481
Validation loss: 2.056084707379341

Epoch: 5| Step: 6
Training loss: 2.1308906078338623
Validation loss: 2.014602651198705

Epoch: 5| Step: 7
Training loss: 1.5083674192428589
Validation loss: 2.044974992672602

Epoch: 5| Step: 8
Training loss: 1.720131516456604
Validation loss: 2.0215386698643365

Epoch: 5| Step: 9
Training loss: 1.2141889333724976
Validation loss: 1.9885289669036865

Epoch: 5| Step: 10
Training loss: 1.5429795980453491
Validation loss: 2.0237726320823035

Epoch: 5| Step: 11
Training loss: 0.8972501754760742
Validation loss: 2.028576746582985

Epoch: 103| Step: 0
Training loss: 1.5692896842956543
Validation loss: 2.0560970256725946

Epoch: 5| Step: 1
Training loss: 2.109523296356201
Validation loss: 2.048244600494703

Epoch: 5| Step: 2
Training loss: 1.4584277868270874
Validation loss: 2.0705247074365616

Epoch: 5| Step: 3
Training loss: 1.6520376205444336
Validation loss: 2.0563527395327887

Epoch: 5| Step: 4
Training loss: 1.531292200088501
Validation loss: 2.0499236782391868

Epoch: 5| Step: 5
Training loss: 1.1503206491470337
Validation loss: 2.0547561645507812

Epoch: 5| Step: 6
Training loss: 1.5009912252426147
Validation loss: 2.0496468991041183

Epoch: 5| Step: 7
Training loss: 1.7317653894424438
Validation loss: 2.0244077146053314

Epoch: 5| Step: 8
Training loss: 1.6551673412322998
Validation loss: 2.024256264170011

Epoch: 5| Step: 9
Training loss: 1.547369122505188
Validation loss: 2.0623402198155723

Epoch: 5| Step: 10
Training loss: 1.4436546564102173
Validation loss: 2.022892822821935

Epoch: 5| Step: 11
Training loss: 2.3993139266967773
Validation loss: 2.041059970855713

Epoch: 104| Step: 0
Training loss: 1.7557308673858643
Validation loss: 1.9980633010466893

Epoch: 5| Step: 1
Training loss: 1.7272472381591797
Validation loss: 2.040148710211118

Epoch: 5| Step: 2
Training loss: 1.599381685256958
Validation loss: 1.9958809812863667

Epoch: 5| Step: 3
Training loss: 2.2918436527252197
Validation loss: 2.0391031304995217

Epoch: 5| Step: 4
Training loss: 1.8311249017715454
Validation loss: 2.031163732210795

Epoch: 5| Step: 5
Training loss: 1.575478196144104
Validation loss: 2.0565513968467712

Epoch: 5| Step: 6
Training loss: 1.590391755104065
Validation loss: 2.02507850031058

Epoch: 5| Step: 7
Training loss: 1.150130271911621
Validation loss: 2.0037189225355783

Epoch: 5| Step: 8
Training loss: 1.5831959247589111
Validation loss: 2.062715088327726

Epoch: 5| Step: 9
Training loss: 1.1486389636993408
Validation loss: 2.053539425134659

Epoch: 5| Step: 10
Training loss: 1.455559492111206
Validation loss: 2.0655565907557807

Epoch: 5| Step: 11
Training loss: 2.089686870574951
Validation loss: 2.0762467632691064

Epoch: 105| Step: 0
Training loss: 1.8505275249481201
Validation loss: 2.031558265288671

Epoch: 5| Step: 1
Training loss: 1.4789880514144897
Validation loss: 2.1025218218564987

Epoch: 5| Step: 2
Training loss: 1.3789265155792236
Validation loss: 2.0717626909414926

Epoch: 5| Step: 3
Training loss: 1.7016775608062744
Validation loss: 2.040406808257103

Epoch: 5| Step: 4
Training loss: 1.3034216165542603
Validation loss: 2.074064701795578

Epoch: 5| Step: 5
Training loss: 1.5708099603652954
Validation loss: 2.059443493684133

Epoch: 5| Step: 6
Training loss: 1.4352298974990845
Validation loss: 2.005154753724734

Epoch: 5| Step: 7
Training loss: 1.8010553121566772
Validation loss: 2.062133858601252

Epoch: 5| Step: 8
Training loss: 1.9629669189453125
Validation loss: 2.0251144071420035

Epoch: 5| Step: 9
Training loss: 1.6343780755996704
Validation loss: 1.9975788692633312

Epoch: 5| Step: 10
Training loss: 1.9240986108779907
Validation loss: 2.0188711186250052

Epoch: 5| Step: 11
Training loss: 0.8407085537910461
Validation loss: 2.012545794248581

Epoch: 106| Step: 0
Training loss: 1.3837534189224243
Validation loss: 2.0142797032992044

Epoch: 5| Step: 1
Training loss: 1.750043511390686
Validation loss: 2.0145886838436127

Epoch: 5| Step: 2
Training loss: 1.622614860534668
Validation loss: 2.0762020548184714

Epoch: 5| Step: 3
Training loss: 1.5090843439102173
Validation loss: 2.052648589015007

Epoch: 5| Step: 4
Training loss: 1.6576168537139893
Validation loss: 2.052291616797447

Epoch: 5| Step: 5
Training loss: 1.6753613948822021
Validation loss: 2.0676336735486984

Epoch: 5| Step: 6
Training loss: 1.9500694274902344
Validation loss: 2.0739462971687317

Epoch: 5| Step: 7
Training loss: 1.7271209955215454
Validation loss: 2.0745530227820077

Epoch: 5| Step: 8
Training loss: 1.7560068368911743
Validation loss: 2.0894075632095337

Epoch: 5| Step: 9
Training loss: 1.6833261251449585
Validation loss: 2.0637925316890082

Epoch: 5| Step: 10
Training loss: 1.3059297800064087
Validation loss: 2.0293152381976447

Epoch: 5| Step: 11
Training loss: 1.2026387453079224
Validation loss: 2.0349977612495422

Epoch: 107| Step: 0
Training loss: 1.863825798034668
Validation loss: 2.0576392908891044

Epoch: 5| Step: 1
Training loss: 1.3896900415420532
Validation loss: 2.036777287721634

Epoch: 5| Step: 2
Training loss: 1.6574127674102783
Validation loss: 2.0491833984851837

Epoch: 5| Step: 3
Training loss: 1.51321542263031
Validation loss: 2.022795860966047

Epoch: 5| Step: 4
Training loss: 1.887791395187378
Validation loss: 2.0441296646992364

Epoch: 5| Step: 5
Training loss: 1.900734543800354
Validation loss: 2.0463654647270837

Epoch: 5| Step: 6
Training loss: 2.1359801292419434
Validation loss: 2.021393875281016

Epoch: 5| Step: 7
Training loss: 1.4477649927139282
Validation loss: 2.034251421689987

Epoch: 5| Step: 8
Training loss: 1.4869130849838257
Validation loss: 2.0700428982575736

Epoch: 5| Step: 9
Training loss: 1.267610788345337
Validation loss: 2.0481523275375366

Epoch: 5| Step: 10
Training loss: 1.692452073097229
Validation loss: 2.0832477807998657

Epoch: 5| Step: 11
Training loss: 0.5317298769950867
Validation loss: 2.106950953602791

Epoch: 108| Step: 0
Training loss: 1.6290868520736694
Validation loss: 2.0835254043340683

Epoch: 5| Step: 1
Training loss: 1.94052255153656
Validation loss: 2.0700866828362146

Epoch: 5| Step: 2
Training loss: 1.356314778327942
Validation loss: 2.0833234041929245

Epoch: 5| Step: 3
Training loss: 1.7416013479232788
Validation loss: 2.0724904537200928

Epoch: 5| Step: 4
Training loss: 1.596657156944275
Validation loss: 1.9823848058780034

Epoch: 5| Step: 5
Training loss: 1.7866840362548828
Validation loss: 2.0151467074950538

Epoch: 5| Step: 6
Training loss: 1.846946358680725
Validation loss: 2.0106362253427505

Epoch: 5| Step: 7
Training loss: 2.136565685272217
Validation loss: 2.0509247233470282

Epoch: 5| Step: 8
Training loss: 1.7239974737167358
Validation loss: 2.084763318300247

Epoch: 5| Step: 9
Training loss: 1.1934058666229248
Validation loss: 2.0559644550085068

Epoch: 5| Step: 10
Training loss: 1.256326675415039
Validation loss: 2.0313154508670173

Epoch: 5| Step: 11
Training loss: 0.7805964946746826
Validation loss: 2.038001457850138

Epoch: 109| Step: 0
Training loss: 1.6047775745391846
Validation loss: 2.0214254607756934

Epoch: 5| Step: 1
Training loss: 1.3899811506271362
Validation loss: 2.0647109150886536

Epoch: 5| Step: 2
Training loss: 1.2717746496200562
Validation loss: 2.0697608639796576

Epoch: 5| Step: 3
Training loss: 1.953097939491272
Validation loss: 2.0695217698812485

Epoch: 5| Step: 4
Training loss: 1.0458266735076904
Validation loss: 2.0224641114473343

Epoch: 5| Step: 5
Training loss: 1.7475414276123047
Validation loss: 2.057655875881513

Epoch: 5| Step: 6
Training loss: 1.4250150918960571
Validation loss: 2.106682608524958

Epoch: 5| Step: 7
Training loss: 1.354453444480896
Validation loss: 2.0379731555779776

Epoch: 5| Step: 8
Training loss: 1.570850133895874
Validation loss: 2.057421495517095

Epoch: 5| Step: 9
Training loss: 1.870104432106018
Validation loss: 2.069897602001826

Epoch: 5| Step: 10
Training loss: 1.7469971179962158
Validation loss: 2.0373742381731668

Epoch: 5| Step: 11
Training loss: 2.1276237964630127
Validation loss: 2.0403645634651184

Epoch: 110| Step: 0
Training loss: 1.8193944692611694
Validation loss: 2.077728827794393

Epoch: 5| Step: 1
Training loss: 1.3781627416610718
Validation loss: 2.0318514754374823

Epoch: 5| Step: 2
Training loss: 1.2579299211502075
Validation loss: 2.054734463493029

Epoch: 5| Step: 3
Training loss: 1.1271288394927979
Validation loss: 2.0644213060537973

Epoch: 5| Step: 4
Training loss: 1.717922568321228
Validation loss: 2.0781501680612564

Epoch: 5| Step: 5
Training loss: 1.3365509510040283
Validation loss: 2.0660930077234902

Epoch: 5| Step: 6
Training loss: 1.6737020015716553
Validation loss: 2.069503982861837

Epoch: 5| Step: 7
Training loss: 1.5760953426361084
Validation loss: 2.0647930900255838

Epoch: 5| Step: 8
Training loss: 2.295785427093506
Validation loss: 2.0251884112755456

Epoch: 5| Step: 9
Training loss: 1.506218671798706
Validation loss: 2.074927424391111

Epoch: 5| Step: 10
Training loss: 1.7000240087509155
Validation loss: 2.0382237633069358

Epoch: 5| Step: 11
Training loss: 1.309488296508789
Validation loss: 2.056389346718788

Epoch: 111| Step: 0
Training loss: 1.3656402826309204
Validation loss: 2.035743390520414

Epoch: 5| Step: 1
Training loss: 1.590874433517456
Validation loss: 2.0500273406505585

Epoch: 5| Step: 2
Training loss: 1.2287944555282593
Validation loss: 2.0395181328058243

Epoch: 5| Step: 3
Training loss: 1.5106189250946045
Validation loss: 2.040819729367892

Epoch: 5| Step: 4
Training loss: 1.3765733242034912
Validation loss: 2.0675130784511566

Epoch: 5| Step: 5
Training loss: 2.172027111053467
Validation loss: 2.0690507292747498

Epoch: 5| Step: 6
Training loss: 1.3803503513336182
Validation loss: 2.046961466471354

Epoch: 5| Step: 7
Training loss: 1.465509295463562
Validation loss: 2.029681622982025

Epoch: 5| Step: 8
Training loss: 1.7278636693954468
Validation loss: 2.0481056571006775

Epoch: 5| Step: 9
Training loss: 2.141838550567627
Validation loss: 2.052610153953234

Epoch: 5| Step: 10
Training loss: 1.4072520732879639
Validation loss: 2.078647275765737

Epoch: 5| Step: 11
Training loss: 1.3819146156311035
Validation loss: 2.041620204846064

Epoch: 112| Step: 0
Training loss: 1.553765892982483
Validation loss: 2.0739867140849433

Epoch: 5| Step: 1
Training loss: 1.4678022861480713
Validation loss: 2.030016536513964

Epoch: 5| Step: 2
Training loss: 1.7024132013320923
Validation loss: 2.04781844218572

Epoch: 5| Step: 3
Training loss: 1.8867921829223633
Validation loss: 2.033590942621231

Epoch: 5| Step: 4
Training loss: 1.763413667678833
Validation loss: 2.019228314359983

Epoch: 5| Step: 5
Training loss: 1.6283862590789795
Validation loss: 2.0481240351994834

Epoch: 5| Step: 6
Training loss: 1.6579519510269165
Validation loss: 2.072004497051239

Epoch: 5| Step: 7
Training loss: 1.5191729068756104
Validation loss: 2.0643093983332315

Epoch: 5| Step: 8
Training loss: 0.8205366134643555
Validation loss: 2.0914935966332755

Epoch: 5| Step: 9
Training loss: 1.3019126653671265
Validation loss: 2.040694256623586

Epoch: 5| Step: 10
Training loss: 1.3922984600067139
Validation loss: 2.078999027609825

Epoch: 5| Step: 11
Training loss: 2.637302875518799
Validation loss: 2.0831924080848694

Epoch: 113| Step: 0
Training loss: 1.2238147258758545
Validation loss: 2.0629332959651947

Epoch: 5| Step: 1
Training loss: 1.9549872875213623
Validation loss: 2.0714516937732697

Epoch: 5| Step: 2
Training loss: 1.7721138000488281
Validation loss: 2.0767766584952674

Epoch: 5| Step: 3
Training loss: 1.3737714290618896
Validation loss: 2.134388968348503

Epoch: 5| Step: 4
Training loss: 1.2574981451034546
Validation loss: 2.0983893970648446

Epoch: 5| Step: 5
Training loss: 2.154719829559326
Validation loss: 2.039973715941111

Epoch: 5| Step: 6
Training loss: 1.6054162979125977
Validation loss: 2.03810482720534

Epoch: 5| Step: 7
Training loss: 1.2761874198913574
Validation loss: 2.0241743276516595

Epoch: 5| Step: 8
Training loss: 1.7192871570587158
Validation loss: 2.0507940699656806

Epoch: 5| Step: 9
Training loss: 1.4168668985366821
Validation loss: 2.0112201472123465

Epoch: 5| Step: 10
Training loss: 1.6289937496185303
Validation loss: 2.0589967370033264

Epoch: 5| Step: 11
Training loss: 1.2853031158447266
Validation loss: 2.03407821059227

Epoch: 114| Step: 0
Training loss: 1.1967551708221436
Validation loss: 2.049069325129191

Epoch: 5| Step: 1
Training loss: 1.6127246618270874
Validation loss: 2.0461082408825555

Epoch: 5| Step: 2
Training loss: 1.174970269203186
Validation loss: 2.016360968351364

Epoch: 5| Step: 3
Training loss: 1.6319725513458252
Validation loss: 2.0478050311406455

Epoch: 5| Step: 4
Training loss: 1.7838319540023804
Validation loss: 2.0607267717520394

Epoch: 5| Step: 5
Training loss: 1.1819649934768677
Validation loss: 2.0682311405738196

Epoch: 5| Step: 6
Training loss: 1.3334696292877197
Validation loss: 2.06176321208477

Epoch: 5| Step: 7
Training loss: 1.883601188659668
Validation loss: 2.0505648205677667

Epoch: 5| Step: 8
Training loss: 1.4773809909820557
Validation loss: 2.036773299177488

Epoch: 5| Step: 9
Training loss: 1.6174396276474
Validation loss: 2.0224139789740243

Epoch: 5| Step: 10
Training loss: 1.9711151123046875
Validation loss: 2.035256788134575

Epoch: 5| Step: 11
Training loss: 0.7112595438957214
Validation loss: 2.0358366121848426

Epoch: 115| Step: 0
Training loss: 1.9233016967773438
Validation loss: 2.0025103042523065

Epoch: 5| Step: 1
Training loss: 2.162968158721924
Validation loss: 2.07457472383976

Epoch: 5| Step: 2
Training loss: 1.5126190185546875
Validation loss: 2.0344078292449317

Epoch: 5| Step: 3
Training loss: 1.173936128616333
Validation loss: 2.0847141345342

Epoch: 5| Step: 4
Training loss: 1.2847504615783691
Validation loss: 2.0690974642833075

Epoch: 5| Step: 5
Training loss: 1.5573551654815674
Validation loss: 2.079628904660543

Epoch: 5| Step: 6
Training loss: 1.5578010082244873
Validation loss: 2.0359108050664267

Epoch: 5| Step: 7
Training loss: 1.2620160579681396
Validation loss: 2.0887658894062042

Epoch: 5| Step: 8
Training loss: 1.4089128971099854
Validation loss: 2.0659046371777854

Epoch: 5| Step: 9
Training loss: 1.62478506565094
Validation loss: 2.089077035586039

Epoch: 5| Step: 10
Training loss: 1.1635944843292236
Validation loss: 2.032458076874415

Epoch: 5| Step: 11
Training loss: 2.316382884979248
Validation loss: 2.0725159843762717

Epoch: 116| Step: 0
Training loss: 1.1354851722717285
Validation loss: 2.0486261447270713

Epoch: 5| Step: 1
Training loss: 1.2559101581573486
Validation loss: 2.1037367979685464

Epoch: 5| Step: 2
Training loss: 1.5558903217315674
Validation loss: 2.0402747641007104

Epoch: 5| Step: 3
Training loss: 1.39594566822052
Validation loss: 2.070509046316147

Epoch: 5| Step: 4
Training loss: 1.5740315914154053
Validation loss: 2.027698556582133

Epoch: 5| Step: 5
Training loss: 1.2030901908874512
Validation loss: 2.083526889483134

Epoch: 5| Step: 6
Training loss: 1.5753084421157837
Validation loss: 2.085864315430323

Epoch: 5| Step: 7
Training loss: 1.702735185623169
Validation loss: 2.05593770245711

Epoch: 5| Step: 8
Training loss: 1.5005067586898804
Validation loss: 2.0086950411399207

Epoch: 5| Step: 9
Training loss: 1.82675302028656
Validation loss: 2.0776812930901847

Epoch: 5| Step: 10
Training loss: 1.249005913734436
Validation loss: 2.0893157670895257

Epoch: 5| Step: 11
Training loss: 3.7249608039855957
Validation loss: 2.0323688934246698

Epoch: 117| Step: 0
Training loss: 1.3179036378860474
Validation loss: 2.0596343179543815

Epoch: 5| Step: 1
Training loss: 1.8019065856933594
Validation loss: 2.0076235036055246

Epoch: 5| Step: 2
Training loss: 1.5460681915283203
Validation loss: 2.068652724226316

Epoch: 5| Step: 3
Training loss: 1.5923389196395874
Validation loss: 2.0484394828478494

Epoch: 5| Step: 4
Training loss: 1.8733755350112915
Validation loss: 2.058197875817617

Epoch: 5| Step: 5
Training loss: 1.4513658285140991
Validation loss: 2.0607029795646667

Epoch: 5| Step: 6
Training loss: 1.315106749534607
Validation loss: 2.079497834046682

Epoch: 5| Step: 7
Training loss: 1.3364158868789673
Validation loss: 2.032144566377004

Epoch: 5| Step: 8
Training loss: 1.8274259567260742
Validation loss: 2.063474560777346

Epoch: 5| Step: 9
Training loss: 1.303905963897705
Validation loss: 2.0677192509174347

Epoch: 5| Step: 10
Training loss: 1.8051245212554932
Validation loss: 2.0639395167430243

Epoch: 5| Step: 11
Training loss: 1.4243874549865723
Validation loss: 2.059756418069204

Epoch: 118| Step: 0
Training loss: 1.320631742477417
Validation loss: 2.053026780486107

Epoch: 5| Step: 1
Training loss: 1.659637689590454
Validation loss: 2.0802134772141776

Epoch: 5| Step: 2
Training loss: 0.9710747599601746
Validation loss: 2.0733356326818466

Epoch: 5| Step: 3
Training loss: 2.5126194953918457
Validation loss: 2.0456478347380957

Epoch: 5| Step: 4
Training loss: 1.3390624523162842
Validation loss: 2.0495995034774146

Epoch: 5| Step: 5
Training loss: 1.54891836643219
Validation loss: 2.052287057042122

Epoch: 5| Step: 6
Training loss: 1.6396843194961548
Validation loss: 2.050961787501971

Epoch: 5| Step: 7
Training loss: 1.318956732749939
Validation loss: 2.012299736340841

Epoch: 5| Step: 8
Training loss: 1.2110987901687622
Validation loss: 2.0227384070555368

Epoch: 5| Step: 9
Training loss: 1.4526329040527344
Validation loss: 2.039905940492948

Epoch: 5| Step: 10
Training loss: 1.5599541664123535
Validation loss: 2.0433463553587594

Epoch: 5| Step: 11
Training loss: 1.767846703529358
Validation loss: 2.045887658993403

Epoch: 119| Step: 0
Training loss: 0.88733971118927
Validation loss: 2.021904408931732

Epoch: 5| Step: 1
Training loss: 1.3106037378311157
Validation loss: 2.0481310238440833

Epoch: 5| Step: 2
Training loss: 1.5710070133209229
Validation loss: 2.074278935790062

Epoch: 5| Step: 3
Training loss: 1.7456169128417969
Validation loss: 2.0086058924595513

Epoch: 5| Step: 4
Training loss: 1.5273706912994385
Validation loss: 2.0423731605211892

Epoch: 5| Step: 5
Training loss: 1.5590827465057373
Validation loss: 2.0478135496377945

Epoch: 5| Step: 6
Training loss: 1.183802604675293
Validation loss: 2.0358153035243354

Epoch: 5| Step: 7
Training loss: 1.1307204961776733
Validation loss: 2.0378843247890472

Epoch: 5| Step: 8
Training loss: 1.9770538806915283
Validation loss: 2.064924736817678

Epoch: 5| Step: 9
Training loss: 2.236499547958374
Validation loss: 2.093118374546369

Epoch: 5| Step: 10
Training loss: 1.4688971042633057
Validation loss: 2.073892523845037

Epoch: 5| Step: 11
Training loss: 0.8865894079208374
Validation loss: 2.0931747555732727

Epoch: 120| Step: 0
Training loss: 1.6636089086532593
Validation loss: 2.11128639181455

Epoch: 5| Step: 1
Training loss: 1.6343247890472412
Validation loss: 2.090854083498319

Epoch: 5| Step: 2
Training loss: 1.1885648965835571
Validation loss: 2.0575121293465295

Epoch: 5| Step: 3
Training loss: 1.1418342590332031
Validation loss: 2.0705059617757797

Epoch: 5| Step: 4
Training loss: 1.4053196907043457
Validation loss: 2.06746152540048

Epoch: 5| Step: 5
Training loss: 1.4267600774765015
Validation loss: 2.0183264960845313

Epoch: 5| Step: 6
Training loss: 1.709810495376587
Validation loss: 2.0013930847247443

Epoch: 5| Step: 7
Training loss: 1.2703418731689453
Validation loss: 2.0313471605380378

Epoch: 5| Step: 8
Training loss: 1.4172166585922241
Validation loss: 2.0638545552889505

Epoch: 5| Step: 9
Training loss: 2.658884048461914
Validation loss: 2.0418107956647873

Epoch: 5| Step: 10
Training loss: 1.3194091320037842
Validation loss: 2.011527344584465

Epoch: 5| Step: 11
Training loss: 0.4226886034011841
Validation loss: 2.051702782511711

Epoch: 121| Step: 0
Training loss: 2.1392807960510254
Validation loss: 2.046156406402588

Epoch: 5| Step: 1
Training loss: 1.1947342157363892
Validation loss: 2.06537626683712

Epoch: 5| Step: 2
Training loss: 1.090105652809143
Validation loss: 2.074976369738579

Epoch: 5| Step: 3
Training loss: 1.8108676671981812
Validation loss: 2.0390696078538895

Epoch: 5| Step: 4
Training loss: 1.253934621810913
Validation loss: 2.045486271381378

Epoch: 5| Step: 5
Training loss: 1.4652527570724487
Validation loss: 2.058695688843727

Epoch: 5| Step: 6
Training loss: 1.404905080795288
Validation loss: 2.066615104675293

Epoch: 5| Step: 7
Training loss: 1.2368707656860352
Validation loss: 2.0471669137477875

Epoch: 5| Step: 8
Training loss: 1.6185083389282227
Validation loss: 2.045028030872345

Epoch: 5| Step: 9
Training loss: 1.5181782245635986
Validation loss: 2.0502599080403647

Epoch: 5| Step: 10
Training loss: 1.5684947967529297
Validation loss: 2.011991714437803

Epoch: 5| Step: 11
Training loss: 1.448289394378662
Validation loss: 2.0598476280768714

Epoch: 122| Step: 0
Training loss: 1.3037865161895752
Validation loss: 2.0484592268864312

Epoch: 5| Step: 1
Training loss: 1.5053516626358032
Validation loss: 1.9996741116046906

Epoch: 5| Step: 2
Training loss: 2.148963451385498
Validation loss: 2.092571491996447

Epoch: 5| Step: 3
Training loss: 1.1978434324264526
Validation loss: 2.069583977262179

Epoch: 5| Step: 4
Training loss: 1.8722528219223022
Validation loss: 2.047191306948662

Epoch: 5| Step: 5
Training loss: 1.0607426166534424
Validation loss: 2.053358534971873

Epoch: 5| Step: 6
Training loss: 1.4647347927093506
Validation loss: 2.0684909373521805

Epoch: 5| Step: 7
Training loss: 1.7823854684829712
Validation loss: 2.0587240109841027

Epoch: 5| Step: 8
Training loss: 1.654733657836914
Validation loss: 2.0459940284490585

Epoch: 5| Step: 9
Training loss: 1.0738542079925537
Validation loss: 2.0840182503064475

Epoch: 5| Step: 10
Training loss: 1.2371609210968018
Validation loss: 2.054307535290718

Epoch: 5| Step: 11
Training loss: 0.42022740840911865
Validation loss: 2.0652752071619034

Epoch: 123| Step: 0
Training loss: 1.8914636373519897
Validation loss: 2.10784649848938

Epoch: 5| Step: 1
Training loss: 1.0758692026138306
Validation loss: 2.0606760382652283

Epoch: 5| Step: 2
Training loss: 1.5377129316329956
Validation loss: 2.091044927636782

Epoch: 5| Step: 3
Training loss: 1.4251551628112793
Validation loss: 2.070458099246025

Epoch: 5| Step: 4
Training loss: 1.4702215194702148
Validation loss: 2.0661096970240274

Epoch: 5| Step: 5
Training loss: 1.339813470840454
Validation loss: 2.0757123877604804

Epoch: 5| Step: 6
Training loss: 1.4069256782531738
Validation loss: 2.037483443816503

Epoch: 5| Step: 7
Training loss: 1.550903558731079
Validation loss: 2.0733019212881723

Epoch: 5| Step: 8
Training loss: 1.1313883066177368
Validation loss: 2.024522374073664

Epoch: 5| Step: 9
Training loss: 1.8775966167449951
Validation loss: 2.102305307984352

Epoch: 5| Step: 10
Training loss: 1.4989064931869507
Validation loss: 2.0317360758781433

Epoch: 5| Step: 11
Training loss: 1.1314703226089478
Validation loss: 2.044419993956884

Epoch: 124| Step: 0
Training loss: 1.1555529832839966
Validation loss: 2.0169482032457986

Epoch: 5| Step: 1
Training loss: 1.2260806560516357
Validation loss: 2.0684622526168823

Epoch: 5| Step: 2
Training loss: 1.4912599325180054
Validation loss: 2.0915626188119254

Epoch: 5| Step: 3
Training loss: 1.400431513786316
Validation loss: 2.0710379630327225

Epoch: 5| Step: 4
Training loss: 1.0233001708984375
Validation loss: 2.092866142590841

Epoch: 5| Step: 5
Training loss: 1.787396788597107
Validation loss: 2.0530874133110046

Epoch: 5| Step: 6
Training loss: 1.4331252574920654
Validation loss: 2.0325752794742584

Epoch: 5| Step: 7
Training loss: 1.8672561645507812
Validation loss: 2.048967922727267

Epoch: 5| Step: 8
Training loss: 1.361677885055542
Validation loss: 2.0483571191628775

Epoch: 5| Step: 9
Training loss: 1.3201138973236084
Validation loss: 2.0556071549654007

Epoch: 5| Step: 10
Training loss: 1.3503543138504028
Validation loss: 2.090874900420507

Epoch: 5| Step: 11
Training loss: 3.1094765663146973
Validation loss: 2.0893472780783973

Epoch: 125| Step: 0
Training loss: 1.5457446575164795
Validation loss: 2.047954718271891

Epoch: 5| Step: 1
Training loss: 1.3251265287399292
Validation loss: 2.0742384493350983

Epoch: 5| Step: 2
Training loss: 1.2303845882415771
Validation loss: 2.0781906694173813

Epoch: 5| Step: 3
Training loss: 1.972643256187439
Validation loss: 2.036227891842524

Epoch: 5| Step: 4
Training loss: 1.831218957901001
Validation loss: 2.036251256863276

Epoch: 5| Step: 5
Training loss: 0.8842035531997681
Validation loss: 2.023549790183703

Epoch: 5| Step: 6
Training loss: 1.563703179359436
Validation loss: 2.0301201740900674

Epoch: 5| Step: 7
Training loss: 1.2190966606140137
Validation loss: 2.0292833844820657

Epoch: 5| Step: 8
Training loss: 1.5022399425506592
Validation loss: 2.0394493093093238

Epoch: 5| Step: 9
Training loss: 1.540668249130249
Validation loss: 2.0177317708730698

Epoch: 5| Step: 10
Training loss: 1.5205225944519043
Validation loss: 2.0420688092708588

Epoch: 5| Step: 11
Training loss: 1.070594072341919
Validation loss: 2.0792683313290277

Epoch: 126| Step: 0
Training loss: 1.6279804706573486
Validation loss: 2.0615436683098474

Epoch: 5| Step: 1
Training loss: 1.7918939590454102
Validation loss: 2.070922394593557

Epoch: 5| Step: 2
Training loss: 1.6644384860992432
Validation loss: 2.0827776392300925

Epoch: 5| Step: 3
Training loss: 0.9653701782226562
Validation loss: 2.06415519118309

Epoch: 5| Step: 4
Training loss: 1.644826889038086
Validation loss: 2.0444877545038858

Epoch: 5| Step: 5
Training loss: 1.6360485553741455
Validation loss: 2.042317042748133

Epoch: 5| Step: 6
Training loss: 1.0558661222457886
Validation loss: 2.0463234583536782

Epoch: 5| Step: 7
Training loss: 1.460119605064392
Validation loss: 2.0455903907616935

Epoch: 5| Step: 8
Training loss: 1.2668708562850952
Validation loss: 2.0766186863183975

Epoch: 5| Step: 9
Training loss: 1.3174022436141968
Validation loss: 2.0287563105424247

Epoch: 5| Step: 10
Training loss: 1.4719150066375732
Validation loss: 2.0234717577695847

Epoch: 5| Step: 11
Training loss: 1.8924537897109985
Validation loss: 2.04897141456604

Epoch: 127| Step: 0
Training loss: 1.1954047679901123
Validation loss: 2.0639110257228217

Epoch: 5| Step: 1
Training loss: 1.4854843616485596
Validation loss: 2.0523432791233063

Epoch: 5| Step: 2
Training loss: 1.2848626375198364
Validation loss: 2.069961150487264

Epoch: 5| Step: 3
Training loss: 1.6147058010101318
Validation loss: 2.0666543692350388

Epoch: 5| Step: 4
Training loss: 1.0904208421707153
Validation loss: 2.068261995911598

Epoch: 5| Step: 5
Training loss: 1.544803261756897
Validation loss: 2.030845100680987

Epoch: 5| Step: 6
Training loss: 1.320021390914917
Validation loss: 2.0289752135674157

Epoch: 5| Step: 7
Training loss: 1.4836137294769287
Validation loss: 2.072440748413404

Epoch: 5| Step: 8
Training loss: 1.2845056056976318
Validation loss: 2.070118933916092

Epoch: 5| Step: 9
Training loss: 1.6651633977890015
Validation loss: 2.035756210486094

Epoch: 5| Step: 10
Training loss: 1.1394424438476562
Validation loss: 2.035889893770218

Epoch: 5| Step: 11
Training loss: 2.092374086380005
Validation loss: 2.055030773083369

Epoch: 128| Step: 0
Training loss: 1.3397639989852905
Validation loss: 2.0701830883820853

Epoch: 5| Step: 1
Training loss: 1.4445213079452515
Validation loss: 2.0539581974347434

Epoch: 5| Step: 2
Training loss: 1.7597687244415283
Validation loss: 2.132947792609533

Epoch: 5| Step: 3
Training loss: 1.523144006729126
Validation loss: 2.0931383967399597

Epoch: 5| Step: 4
Training loss: 0.7423154711723328
Validation loss: 2.074196313818296

Epoch: 5| Step: 5
Training loss: 1.3718096017837524
Validation loss: 2.0815317233403525

Epoch: 5| Step: 6
Training loss: 1.7407623529434204
Validation loss: 2.0763969669739404

Epoch: 5| Step: 7
Training loss: 1.3836710453033447
Validation loss: 2.0299509118000665

Epoch: 5| Step: 8
Training loss: 1.4728971719741821
Validation loss: 2.058110694090525

Epoch: 5| Step: 9
Training loss: 1.2759764194488525
Validation loss: 2.079382007320722

Epoch: 5| Step: 10
Training loss: 1.1652510166168213
Validation loss: 2.07051187256972

Epoch: 5| Step: 11
Training loss: 2.0840811729431152
Validation loss: 2.092423985401789

Epoch: 129| Step: 0
Training loss: 1.3576701879501343
Validation loss: 2.0520944048961005

Epoch: 5| Step: 1
Training loss: 1.8681952953338623
Validation loss: 2.0407300094763436

Epoch: 5| Step: 2
Training loss: 1.8760337829589844
Validation loss: 2.044821639855703

Epoch: 5| Step: 3
Training loss: 1.2498761415481567
Validation loss: 2.0533526490132012

Epoch: 5| Step: 4
Training loss: 1.4222583770751953
Validation loss: 2.09684985379378

Epoch: 5| Step: 5
Training loss: 1.379122257232666
Validation loss: 2.0460595985253653

Epoch: 5| Step: 6
Training loss: 1.0053318738937378
Validation loss: 2.046005368232727

Epoch: 5| Step: 7
Training loss: 1.040911316871643
Validation loss: 2.072507510582606

Epoch: 5| Step: 8
Training loss: 1.24725341796875
Validation loss: 2.035812775293986

Epoch: 5| Step: 9
Training loss: 1.261763572692871
Validation loss: 2.063764492670695

Epoch: 5| Step: 10
Training loss: 1.5012321472167969
Validation loss: 2.0428959180911384

Epoch: 5| Step: 11
Training loss: 1.0831775665283203
Validation loss: 2.0555766820907593

Epoch: 130| Step: 0
Training loss: 1.0734567642211914
Validation loss: 2.0799015214045844

Epoch: 5| Step: 1
Training loss: 2.106001377105713
Validation loss: 2.086435412367185

Epoch: 5| Step: 2
Training loss: 1.5567764043807983
Validation loss: 2.070221612850825

Epoch: 5| Step: 3
Training loss: 1.2432329654693604
Validation loss: 2.031282057364782

Epoch: 5| Step: 4
Training loss: 0.9455193281173706
Validation loss: 2.0367634246746698

Epoch: 5| Step: 5
Training loss: 1.4295034408569336
Validation loss: 2.0341757188240686

Epoch: 5| Step: 6
Training loss: 1.5064572095870972
Validation loss: 2.049474467833837

Epoch: 5| Step: 7
Training loss: 1.396087408065796
Validation loss: 2.0400830805301666

Epoch: 5| Step: 8
Training loss: 1.2785334587097168
Validation loss: 2.0570707569519677

Epoch: 5| Step: 9
Training loss: 1.4351695775985718
Validation loss: 2.0351924101511636

Epoch: 5| Step: 10
Training loss: 1.1047534942626953
Validation loss: 2.045804778734843

Epoch: 5| Step: 11
Training loss: 1.220109224319458
Validation loss: 2.036945397655169

Epoch: 131| Step: 0
Training loss: 1.595622181892395
Validation loss: 2.060337354739507

Epoch: 5| Step: 1
Training loss: 0.9429023861885071
Validation loss: 2.038370336095492

Epoch: 5| Step: 2
Training loss: 1.0216480493545532
Validation loss: 2.05716838936011

Epoch: 5| Step: 3
Training loss: 1.7251358032226562
Validation loss: 2.062624136606852

Epoch: 5| Step: 4
Training loss: 2.0380449295043945
Validation loss: 2.0154989262421927

Epoch: 5| Step: 5
Training loss: 1.0432186126708984
Validation loss: 2.0802877793709436

Epoch: 5| Step: 6
Training loss: 1.3206639289855957
Validation loss: 2.046902373433113

Epoch: 5| Step: 7
Training loss: 1.6045818328857422
Validation loss: 2.0250651091337204

Epoch: 5| Step: 8
Training loss: 1.2237803936004639
Validation loss: 2.013661985596021

Epoch: 5| Step: 9
Training loss: 1.2024548053741455
Validation loss: 2.01442784567674

Epoch: 5| Step: 10
Training loss: 1.5209848880767822
Validation loss: 2.084142883618673

Epoch: 5| Step: 11
Training loss: 0.7388972640037537
Validation loss: 2.073844686150551

Epoch: 132| Step: 0
Training loss: 1.1582269668579102
Validation loss: 2.0304648031791053

Epoch: 5| Step: 1
Training loss: 1.5648435354232788
Validation loss: 2.027774398525556

Epoch: 5| Step: 2
Training loss: 1.2123665809631348
Validation loss: 2.025101443131765

Epoch: 5| Step: 3
Training loss: 1.2640626430511475
Validation loss: 2.0348017811775208

Epoch: 5| Step: 4
Training loss: 1.002897024154663
Validation loss: 2.0427723626295724

Epoch: 5| Step: 5
Training loss: 1.2563495635986328
Validation loss: 2.0835903535286584

Epoch: 5| Step: 6
Training loss: 1.7307783365249634
Validation loss: 1.9913898954788845

Epoch: 5| Step: 7
Training loss: 1.8481876850128174
Validation loss: 2.0588543663422265

Epoch: 5| Step: 8
Training loss: 1.2222973108291626
Validation loss: 2.045122414827347

Epoch: 5| Step: 9
Training loss: 1.7390692234039307
Validation loss: 2.033389523625374

Epoch: 5| Step: 10
Training loss: 1.287495493888855
Validation loss: 2.080733214815458

Epoch: 5| Step: 11
Training loss: 2.0918216705322266
Validation loss: 2.037281105915705

Epoch: 133| Step: 0
Training loss: 1.7733166217803955
Validation loss: 2.083314230044683

Epoch: 5| Step: 1
Training loss: 1.3979082107543945
Validation loss: 2.0859620620807013

Epoch: 5| Step: 2
Training loss: 1.692922592163086
Validation loss: 2.1087109545866647

Epoch: 5| Step: 3
Training loss: 1.714769721031189
Validation loss: 2.0937997152407966

Epoch: 5| Step: 4
Training loss: 1.516830325126648
Validation loss: 2.1023216297229133

Epoch: 5| Step: 5
Training loss: 1.3148993253707886
Validation loss: 2.093989516297976

Epoch: 5| Step: 6
Training loss: 1.124201774597168
Validation loss: 2.0638937850793204

Epoch: 5| Step: 7
Training loss: 1.2706689834594727
Validation loss: 2.0694655974706015

Epoch: 5| Step: 8
Training loss: 1.3667621612548828
Validation loss: 2.051164651910464

Epoch: 5| Step: 9
Training loss: 1.3941881656646729
Validation loss: 2.041891207297643

Epoch: 5| Step: 10
Training loss: 1.302039623260498
Validation loss: 2.054465740919113

Epoch: 5| Step: 11
Training loss: 0.7013611793518066
Validation loss: 2.074118341008822

Epoch: 134| Step: 0
Training loss: 1.972444772720337
Validation loss: 2.079679697751999

Epoch: 5| Step: 1
Training loss: 1.606795310974121
Validation loss: 2.052570362885793

Epoch: 5| Step: 2
Training loss: 1.2380118370056152
Validation loss: 2.028200780351957

Epoch: 5| Step: 3
Training loss: 1.0997892618179321
Validation loss: 2.02120241522789

Epoch: 5| Step: 4
Training loss: 1.4060242176055908
Validation loss: 2.069333389401436

Epoch: 5| Step: 5
Training loss: 1.102746844291687
Validation loss: 2.081039552887281

Epoch: 5| Step: 6
Training loss: 1.3971073627471924
Validation loss: 2.0471863647301993

Epoch: 5| Step: 7
Training loss: 1.74728262424469
Validation loss: 2.0417962869008384

Epoch: 5| Step: 8
Training loss: 1.201188087463379
Validation loss: 2.0472889641920724

Epoch: 5| Step: 9
Training loss: 1.1406991481781006
Validation loss: 2.052131697535515

Epoch: 5| Step: 10
Training loss: 1.327222466468811
Validation loss: 1.986356313029925

Epoch: 5| Step: 11
Training loss: 2.2271761894226074
Validation loss: 2.047481973965963

Epoch: 135| Step: 0
Training loss: 1.0676008462905884
Validation loss: 2.0495611280202866

Epoch: 5| Step: 1
Training loss: 1.8289076089859009
Validation loss: 2.0486690402030945

Epoch: 5| Step: 2
Training loss: 1.7683794498443604
Validation loss: 2.072302987178167

Epoch: 5| Step: 3
Training loss: 1.9058974981307983
Validation loss: 2.080777496099472

Epoch: 5| Step: 4
Training loss: 1.5688707828521729
Validation loss: 2.051654209693273

Epoch: 5| Step: 5
Training loss: 1.3975260257720947
Validation loss: 2.042850981156031

Epoch: 5| Step: 6
Training loss: 1.6733770370483398
Validation loss: 1.9991973787546158

Epoch: 5| Step: 7
Training loss: 1.4097756147384644
Validation loss: 2.051080415646235

Epoch: 5| Step: 8
Training loss: 1.0156415700912476
Validation loss: 2.0629923939704895

Epoch: 5| Step: 9
Training loss: 1.3664535284042358
Validation loss: 2.051122322678566

Epoch: 5| Step: 10
Training loss: 1.3931424617767334
Validation loss: 2.089574029048284

Epoch: 5| Step: 11
Training loss: 0.7192204594612122
Validation loss: 2.105269660552343

Epoch: 136| Step: 0
Training loss: 1.4920819997787476
Validation loss: 2.0761731217304864

Epoch: 5| Step: 1
Training loss: 1.1574971675872803
Validation loss: 2.086540018518766

Epoch: 5| Step: 2
Training loss: 1.0409433841705322
Validation loss: 2.080507750312487

Epoch: 5| Step: 3
Training loss: 1.4412274360656738
Validation loss: 2.0511377851168313

Epoch: 5| Step: 4
Training loss: 1.2927430868148804
Validation loss: 2.032415280739466

Epoch: 5| Step: 5
Training loss: 1.7267367839813232
Validation loss: 2.052213430404663

Epoch: 5| Step: 6
Training loss: 1.4597694873809814
Validation loss: 2.0568393667538962

Epoch: 5| Step: 7
Training loss: 1.6049718856811523
Validation loss: 2.0629986375570297

Epoch: 5| Step: 8
Training loss: 1.9261114597320557
Validation loss: 2.0621420443058014

Epoch: 5| Step: 9
Training loss: 1.390034556388855
Validation loss: 2.0949612657229104

Epoch: 5| Step: 10
Training loss: 1.7602941989898682
Validation loss: 2.0777537127335868

Epoch: 5| Step: 11
Training loss: 1.5068655014038086
Validation loss: 2.1106345454851785

Epoch: 137| Step: 0
Training loss: 1.4063918590545654
Validation loss: 1.9992188860972722

Epoch: 5| Step: 1
Training loss: 1.7068021297454834
Validation loss: 2.0658925424019494

Epoch: 5| Step: 2
Training loss: 1.2148627042770386
Validation loss: 2.0482860108216605

Epoch: 5| Step: 3
Training loss: 1.45871901512146
Validation loss: 2.1541503220796585

Epoch: 5| Step: 4
Training loss: 1.3209846019744873
Validation loss: 2.0916265100240707

Epoch: 5| Step: 5
Training loss: 1.5726629495620728
Validation loss: 2.0479087879260383

Epoch: 5| Step: 6
Training loss: 0.9936356544494629
Validation loss: 2.0616927395264306

Epoch: 5| Step: 7
Training loss: 1.8991693258285522
Validation loss: 2.0913319289684296

Epoch: 5| Step: 8
Training loss: 1.4453681707382202
Validation loss: 2.045338104168574

Epoch: 5| Step: 9
Training loss: 1.0882434844970703
Validation loss: 2.051346401373545

Epoch: 5| Step: 10
Training loss: 0.9536545872688293
Validation loss: 2.0257057497898736

Epoch: 5| Step: 11
Training loss: 2.255204200744629
Validation loss: 2.0401085565487542

Epoch: 138| Step: 0
Training loss: 1.3289697170257568
Validation loss: 2.0493435660998025

Epoch: 5| Step: 1
Training loss: 1.2863285541534424
Validation loss: 2.0124556670586267

Epoch: 5| Step: 2
Training loss: 1.4143069982528687
Validation loss: 2.030404562751452

Epoch: 5| Step: 3
Training loss: 1.6311063766479492
Validation loss: 1.9966441839933395

Epoch: 5| Step: 4
Training loss: 1.717637062072754
Validation loss: 2.0553399870793023

Epoch: 5| Step: 5
Training loss: 1.3404594659805298
Validation loss: 2.0357004503409066

Epoch: 5| Step: 6
Training loss: 1.0129042863845825
Validation loss: 2.057168891032537

Epoch: 5| Step: 7
Training loss: 1.604882001876831
Validation loss: 2.0567010988791785

Epoch: 5| Step: 8
Training loss: 1.0402629375457764
Validation loss: 2.040515353282293

Epoch: 5| Step: 9
Training loss: 1.5582077503204346
Validation loss: 2.049165884653727

Epoch: 5| Step: 10
Training loss: 1.188105821609497
Validation loss: 2.0095350642999015

Epoch: 5| Step: 11
Training loss: 1.0018807649612427
Validation loss: 2.048359344402949

Epoch: 139| Step: 0
Training loss: 1.1665477752685547
Validation loss: 2.0668921222289405

Epoch: 5| Step: 1
Training loss: 1.270824909210205
Validation loss: 2.0615032464265823

Epoch: 5| Step: 2
Training loss: 1.2939269542694092
Validation loss: 2.0567116489013038

Epoch: 5| Step: 3
Training loss: 1.1452077627182007
Validation loss: 2.056947812438011

Epoch: 5| Step: 4
Training loss: 1.0732529163360596
Validation loss: 2.0443036556243896

Epoch: 5| Step: 5
Training loss: 1.5272226333618164
Validation loss: 2.071254312992096

Epoch: 5| Step: 6
Training loss: 1.3110616207122803
Validation loss: 2.09941029548645

Epoch: 5| Step: 7
Training loss: 1.4614384174346924
Validation loss: 2.075430100162824

Epoch: 5| Step: 8
Training loss: 1.20760178565979
Validation loss: 2.086322625478109

Epoch: 5| Step: 9
Training loss: 1.8955070972442627
Validation loss: 2.08398445447286

Epoch: 5| Step: 10
Training loss: 1.3029733896255493
Validation loss: 2.054076994458834

Epoch: 5| Step: 11
Training loss: 1.0625263452529907
Validation loss: 2.0659432113170624

Epoch: 140| Step: 0
Training loss: 1.5234533548355103
Validation loss: 2.0171301066875458

Epoch: 5| Step: 1
Training loss: 1.6701488494873047
Validation loss: 2.0832177499930062

Epoch: 5| Step: 2
Training loss: 1.821560263633728
Validation loss: 2.084868604938189

Epoch: 5| Step: 3
Training loss: 0.9018777012825012
Validation loss: 2.070773407816887

Epoch: 5| Step: 4
Training loss: 1.1110320091247559
Validation loss: 2.09198326865832

Epoch: 5| Step: 5
Training loss: 1.9467508792877197
Validation loss: 2.049775535861651

Epoch: 5| Step: 6
Training loss: 1.1742395162582397
Validation loss: 2.0352822293837867

Epoch: 5| Step: 7
Training loss: 1.25966215133667
Validation loss: 2.049219101667404

Epoch: 5| Step: 8
Training loss: 1.1910715103149414
Validation loss: 2.0600693076848984

Epoch: 5| Step: 9
Training loss: 0.740710437297821
Validation loss: 2.078221167127291

Epoch: 5| Step: 10
Training loss: 1.2624475955963135
Validation loss: 2.051118642091751

Epoch: 5| Step: 11
Training loss: 1.6833645105361938
Validation loss: 2.012001877029737

Epoch: 141| Step: 0
Training loss: 1.612447738647461
Validation loss: 2.0930334428946176

Epoch: 5| Step: 1
Training loss: 1.272249460220337
Validation loss: 2.060057044029236

Epoch: 5| Step: 2
Training loss: 1.6852006912231445
Validation loss: 2.049008846282959

Epoch: 5| Step: 3
Training loss: 0.8812071681022644
Validation loss: 2.0368044475714364

Epoch: 5| Step: 4
Training loss: 1.0470207929611206
Validation loss: 2.0529005229473114

Epoch: 5| Step: 5
Training loss: 1.2381253242492676
Validation loss: 2.0594826340675354

Epoch: 5| Step: 6
Training loss: 1.2565958499908447
Validation loss: 2.05809023976326

Epoch: 5| Step: 7
Training loss: 1.0809739828109741
Validation loss: 2.0687861492236457

Epoch: 5| Step: 8
Training loss: 1.11910879611969
Validation loss: 2.072115649779638

Epoch: 5| Step: 9
Training loss: 1.2006642818450928
Validation loss: 2.0417960385481515

Epoch: 5| Step: 10
Training loss: 1.5007059574127197
Validation loss: 2.10244653125604

Epoch: 5| Step: 11
Training loss: 1.5179967880249023
Validation loss: 2.0606581221024194

Epoch: 142| Step: 0
Training loss: 1.6974207162857056
Validation loss: 2.06762757897377

Epoch: 5| Step: 1
Training loss: 1.5715887546539307
Validation loss: 2.0507059544324875

Epoch: 5| Step: 2
Training loss: 1.1899821758270264
Validation loss: 2.0042781233787537

Epoch: 5| Step: 3
Training loss: 0.8607556223869324
Validation loss: 2.019363264242808

Epoch: 5| Step: 4
Training loss: 1.6437270641326904
Validation loss: 2.086683750152588

Epoch: 5| Step: 5
Training loss: 1.409024953842163
Validation loss: 2.119881729284922

Epoch: 5| Step: 6
Training loss: 1.2483938932418823
Validation loss: 2.057376742362976

Epoch: 5| Step: 7
Training loss: 1.1806762218475342
Validation loss: 2.0285096615552902

Epoch: 5| Step: 8
Training loss: 0.9218333959579468
Validation loss: 2.0521628757317862

Epoch: 5| Step: 9
Training loss: 1.3980798721313477
Validation loss: 2.0575448125600815

Epoch: 5| Step: 10
Training loss: 1.2926052808761597
Validation loss: 2.0532502035299935

Epoch: 5| Step: 11
Training loss: 0.5490882396697998
Validation loss: 2.0575396517912545

Epoch: 143| Step: 0
Training loss: 1.7476857900619507
Validation loss: 2.0668842097123465

Epoch: 5| Step: 1
Training loss: 1.2706047296524048
Validation loss: 2.0370360811551413

Epoch: 5| Step: 2
Training loss: 1.2531108856201172
Validation loss: 2.0612478305896125

Epoch: 5| Step: 3
Training loss: 1.184258222579956
Validation loss: 2.0623249113559723

Epoch: 5| Step: 4
Training loss: 1.2837352752685547
Validation loss: 2.042635882894198

Epoch: 5| Step: 5
Training loss: 1.0500118732452393
Validation loss: 2.0329237580299377

Epoch: 5| Step: 6
Training loss: 1.3327168226242065
Validation loss: 2.0816084196170173

Epoch: 5| Step: 7
Training loss: 1.5676528215408325
Validation loss: 2.03102108836174

Epoch: 5| Step: 8
Training loss: 1.4820407629013062
Validation loss: 2.0515702267487845

Epoch: 5| Step: 9
Training loss: 1.0027360916137695
Validation loss: 2.058244933684667

Epoch: 5| Step: 10
Training loss: 1.0249075889587402
Validation loss: 2.0373440980911255

Epoch: 5| Step: 11
Training loss: 2.058847665786743
Validation loss: 2.0647392521301904

Epoch: 144| Step: 0
Training loss: 0.837530255317688
Validation loss: 2.043202926715215

Epoch: 5| Step: 1
Training loss: 1.4941179752349854
Validation loss: 2.0033605992794037

Epoch: 5| Step: 2
Training loss: 1.5087854862213135
Validation loss: 2.0412518431742988

Epoch: 5| Step: 3
Training loss: 1.2746484279632568
Validation loss: 2.035356188813845

Epoch: 5| Step: 4
Training loss: 1.3590418100357056
Validation loss: 2.0878735880057016

Epoch: 5| Step: 5
Training loss: 1.3046910762786865
Validation loss: 2.0603367586930594

Epoch: 5| Step: 6
Training loss: 1.2145591974258423
Validation loss: 2.060106794039408

Epoch: 5| Step: 7
Training loss: 1.837546944618225
Validation loss: 2.020914395650228

Epoch: 5| Step: 8
Training loss: 0.78093421459198
Validation loss: 2.030277048548063

Epoch: 5| Step: 9
Training loss: 1.003121018409729
Validation loss: 2.0789580047130585

Epoch: 5| Step: 10
Training loss: 1.5203412771224976
Validation loss: 2.0637058218320212

Epoch: 5| Step: 11
Training loss: 1.771799087524414
Validation loss: 2.0603361378113427

Epoch: 145| Step: 0
Training loss: 1.6086766719818115
Validation loss: 2.071748231848081

Epoch: 5| Step: 1
Training loss: 1.2879972457885742
Validation loss: 2.0657650530338287

Epoch: 5| Step: 2
Training loss: 1.9127628803253174
Validation loss: 2.053108582894007

Epoch: 5| Step: 3
Training loss: 1.0085150003433228
Validation loss: 2.0804669857025146

Epoch: 5| Step: 4
Training loss: 1.4749494791030884
Validation loss: 2.0820681750774384

Epoch: 5| Step: 5
Training loss: 1.2233660221099854
Validation loss: 2.0165101091066995

Epoch: 5| Step: 6
Training loss: 0.9699198007583618
Validation loss: 1.9975415368874867

Epoch: 5| Step: 7
Training loss: 1.2606035470962524
Validation loss: 2.0478864957888923

Epoch: 5| Step: 8
Training loss: 1.3463433980941772
Validation loss: 2.03704867263635

Epoch: 5| Step: 9
Training loss: 0.9117234349250793
Validation loss: 2.0601950039466224

Epoch: 5| Step: 10
Training loss: 1.2573764324188232
Validation loss: 2.04378280043602

Epoch: 5| Step: 11
Training loss: 1.2015125751495361
Validation loss: 2.0572296182314553

Epoch: 146| Step: 0
Training loss: 1.6555131673812866
Validation loss: 2.015508453051249

Epoch: 5| Step: 1
Training loss: 1.2171533107757568
Validation loss: 2.080091193318367

Epoch: 5| Step: 2
Training loss: 1.114776372909546
Validation loss: 2.028167506059011

Epoch: 5| Step: 3
Training loss: 1.558630347251892
Validation loss: 2.02044045428435

Epoch: 5| Step: 4
Training loss: 1.1287236213684082
Validation loss: 2.0216907064119973

Epoch: 5| Step: 5
Training loss: 1.2046353816986084
Validation loss: 2.010070338845253

Epoch: 5| Step: 6
Training loss: 1.603377342224121
Validation loss: 2.0396671493848166

Epoch: 5| Step: 7
Training loss: 0.7461146116256714
Validation loss: 2.019731879234314

Epoch: 5| Step: 8
Training loss: 1.1364859342575073
Validation loss: 2.0415101796388626

Epoch: 5| Step: 9
Training loss: 1.4502599239349365
Validation loss: 2.0564843912919364

Epoch: 5| Step: 10
Training loss: 1.3067255020141602
Validation loss: 2.0698348730802536

Epoch: 5| Step: 11
Training loss: 3.160290479660034
Validation loss: 2.0207988172769547

Epoch: 147| Step: 0
Training loss: 1.6044002771377563
Validation loss: 2.0616753548383713

Epoch: 5| Step: 1
Training loss: 1.3262699842453003
Validation loss: 2.024509305755297

Epoch: 5| Step: 2
Training loss: 1.0611366033554077
Validation loss: 2.070791562398275

Epoch: 5| Step: 3
Training loss: 1.2137415409088135
Validation loss: 2.0100345263878503

Epoch: 5| Step: 4
Training loss: 1.1859357357025146
Validation loss: 2.0378015339374542

Epoch: 5| Step: 5
Training loss: 1.2119187116622925
Validation loss: 2.028347392876943

Epoch: 5| Step: 6
Training loss: 0.9662553668022156
Validation loss: 2.0663220286369324

Epoch: 5| Step: 7
Training loss: 1.109323263168335
Validation loss: 2.089141368865967

Epoch: 5| Step: 8
Training loss: 1.182349443435669
Validation loss: 2.0319441656271615

Epoch: 5| Step: 9
Training loss: 1.5934951305389404
Validation loss: 2.0701774756113687

Epoch: 5| Step: 10
Training loss: 1.4107331037521362
Validation loss: 2.0574615697065988

Epoch: 5| Step: 11
Training loss: 2.1409859657287598
Validation loss: 2.108585755030314

Epoch: 148| Step: 0
Training loss: 1.4773718118667603
Validation loss: 2.0886489003896713

Epoch: 5| Step: 1
Training loss: 1.3723859786987305
Validation loss: 2.0695324490467706

Epoch: 5| Step: 2
Training loss: 1.1524627208709717
Validation loss: 2.0202363779147468

Epoch: 5| Step: 3
Training loss: 1.2764947414398193
Validation loss: 2.043127735455831

Epoch: 5| Step: 4
Training loss: 0.9148033857345581
Validation loss: 2.04997418820858

Epoch: 5| Step: 5
Training loss: 0.8826508522033691
Validation loss: 2.002259780963262

Epoch: 5| Step: 6
Training loss: 1.287413239479065
Validation loss: 2.043743312358856

Epoch: 5| Step: 7
Training loss: 1.3844945430755615
Validation loss: 2.0305714458227158

Epoch: 5| Step: 8
Training loss: 1.409889578819275
Validation loss: 2.071905960639318

Epoch: 5| Step: 9
Training loss: 1.5703935623168945
Validation loss: 2.0354007681210837

Epoch: 5| Step: 10
Training loss: 1.5233023166656494
Validation loss: 2.056990012526512

Epoch: 5| Step: 11
Training loss: 1.0454206466674805
Validation loss: 2.030475785334905

Epoch: 149| Step: 0
Training loss: 0.9919374585151672
Validation loss: 2.03888567785422

Epoch: 5| Step: 1
Training loss: 1.3577295541763306
Validation loss: 2.039401868979136

Epoch: 5| Step: 2
Training loss: 1.369264841079712
Validation loss: 2.0694704055786133

Epoch: 5| Step: 3
Training loss: 0.9173932075500488
Validation loss: 2.0852949072917304

Epoch: 5| Step: 4
Training loss: 1.057854413986206
Validation loss: 2.0670392562945685

Epoch: 5| Step: 5
Training loss: 1.5975887775421143
Validation loss: 2.050786256790161

Epoch: 5| Step: 6
Training loss: 1.3357661962509155
Validation loss: 2.044717252254486

Epoch: 5| Step: 7
Training loss: 1.1678779125213623
Validation loss: 2.0451041013002396

Epoch: 5| Step: 8
Training loss: 1.1714104413986206
Validation loss: 2.0568078011274338

Epoch: 5| Step: 9
Training loss: 1.0227134227752686
Validation loss: 2.044731522599856

Epoch: 5| Step: 10
Training loss: 1.0311607122421265
Validation loss: 2.012119327982267

Epoch: 5| Step: 11
Training loss: 2.039672374725342
Validation loss: 2.0393576373656592

Epoch: 150| Step: 0
Training loss: 0.49402952194213867
Validation loss: 2.029966135819753

Epoch: 5| Step: 1
Training loss: 1.2038776874542236
Validation loss: 2.0542113979657493

Epoch: 5| Step: 2
Training loss: 1.0100687742233276
Validation loss: 2.0219689706961312

Epoch: 5| Step: 3
Training loss: 1.1798144578933716
Validation loss: 2.045862078666687

Epoch: 5| Step: 4
Training loss: 0.6824221014976501
Validation loss: 2.0500937004884086

Epoch: 5| Step: 5
Training loss: 1.3184359073638916
Validation loss: 2.045780216654142

Epoch: 5| Step: 6
Training loss: 1.694838285446167
Validation loss: 2.072451571623484

Epoch: 5| Step: 7
Training loss: 1.665968656539917
Validation loss: 2.102229952812195

Epoch: 5| Step: 8
Training loss: 1.1264697313308716
Validation loss: 2.042239397764206

Epoch: 5| Step: 9
Training loss: 0.6825435757637024
Validation loss: 2.088100870450338

Epoch: 5| Step: 10
Training loss: 1.6484886407852173
Validation loss: 2.0689941197633743

Epoch: 5| Step: 11
Training loss: 2.0367114543914795
Validation loss: 2.042743901411692

Testing loss: 1.8074960245502938
