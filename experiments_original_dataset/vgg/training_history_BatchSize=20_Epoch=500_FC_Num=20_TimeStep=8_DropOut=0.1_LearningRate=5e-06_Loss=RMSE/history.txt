Epoch: 1| Step: 0
Training loss: 3.553607214797458
Validation loss: 3.385317828373962

Epoch: 5| Step: 1
Training loss: 3.6932572502489065
Validation loss: 3.372551801258709

Epoch: 5| Step: 2
Training loss: 3.458182795055599
Validation loss: 3.356221225314452

Epoch: 5| Step: 3
Training loss: 3.676777784640311
Validation loss: 3.3416054702603053

Epoch: 5| Step: 4
Training loss: 3.7236507404335004
Validation loss: 3.3345802935128397

Epoch: 5| Step: 5
Training loss: 3.3772890311085306
Validation loss: 3.318516817898916

Epoch: 5| Step: 6
Training loss: 3.967380437557749
Validation loss: 3.3088499448174775

Epoch: 5| Step: 7
Training loss: 3.0678956126293206
Validation loss: 3.2969379871010305

Epoch: 5| Step: 8
Training loss: 2.798945507668025
Validation loss: 3.286561880682009

Epoch: 5| Step: 9
Training loss: 3.515932061243127
Validation loss: 3.2737413688682806

Epoch: 5| Step: 10
Training loss: 3.2097135935374457
Validation loss: 3.263891012222645

Epoch: 5| Step: 11
Training loss: 3.129236325344955
Validation loss: 3.251671068027893

Epoch: 2| Step: 0
Training loss: 3.8655875547256087
Validation loss: 3.243580297638239

Epoch: 5| Step: 1
Training loss: 2.8939839410659247
Validation loss: 3.2298742359978903

Epoch: 5| Step: 2
Training loss: 3.277945025715619
Validation loss: 3.2213473256973164

Epoch: 5| Step: 3
Training loss: 3.8867753067885755
Validation loss: 3.2115384550407957

Epoch: 5| Step: 4
Training loss: 3.589433549061049
Validation loss: 3.196664370312892

Epoch: 5| Step: 5
Training loss: 3.1490944302435295
Validation loss: 3.1844676123152174

Epoch: 5| Step: 6
Training loss: 2.8626206951432973
Validation loss: 3.172431564985748

Epoch: 5| Step: 7
Training loss: 3.2381460716093557
Validation loss: 3.159030218583035

Epoch: 5| Step: 8
Training loss: 3.5668678945895396
Validation loss: 3.1422712525129497

Epoch: 5| Step: 9
Training loss: 2.893373904082935
Validation loss: 3.1306363932845915

Epoch: 5| Step: 10
Training loss: 3.0662370574342117
Validation loss: 3.1138034511834443

Epoch: 5| Step: 11
Training loss: 3.4742014893741455
Validation loss: 3.1027818456139493

Epoch: 3| Step: 0
Training loss: 3.0923165747875903
Validation loss: 3.085260205849098

Epoch: 5| Step: 1
Training loss: 2.697804854934626
Validation loss: 3.0743660315940966

Epoch: 5| Step: 2
Training loss: 2.9219614923904618
Validation loss: 3.053700885323088

Epoch: 5| Step: 3
Training loss: 3.4759508602149993
Validation loss: 3.0372990196361083

Epoch: 5| Step: 4
Training loss: 3.5324278360974803
Validation loss: 3.0238392683700277

Epoch: 5| Step: 5
Training loss: 2.9161336865961043
Validation loss: 2.9985764225299176

Epoch: 5| Step: 6
Training loss: 2.9612309051323136
Validation loss: 2.9802360393823424

Epoch: 5| Step: 7
Training loss: 3.4815106443291466
Validation loss: 2.958960296566464

Epoch: 5| Step: 8
Training loss: 2.661461777258708
Validation loss: 2.941272545114887

Epoch: 5| Step: 9
Training loss: 3.2342825613771926
Validation loss: 2.91229118531818

Epoch: 5| Step: 10
Training loss: 3.1118546762930923
Validation loss: 2.889656540443651

Epoch: 5| Step: 11
Training loss: 2.766974685558663
Validation loss: 2.8667240028044216

Epoch: 4| Step: 0
Training loss: 3.539215690884635
Validation loss: 2.8379505253539374

Epoch: 5| Step: 1
Training loss: 2.9943025847524454
Validation loss: 2.8121459773446253

Epoch: 5| Step: 2
Training loss: 2.458581480875061
Validation loss: 2.791016824489342

Epoch: 5| Step: 3
Training loss: 2.5587254148195746
Validation loss: 2.758170622428058

Epoch: 5| Step: 4
Training loss: 3.0099985080854705
Validation loss: 2.727833998818964

Epoch: 5| Step: 5
Training loss: 2.4138066918596657
Validation loss: 2.6977130943191714

Epoch: 5| Step: 6
Training loss: 2.717484102737827
Validation loss: 2.6632135181387775

Epoch: 5| Step: 7
Training loss: 2.7013429268983256
Validation loss: 2.649995928587275

Epoch: 5| Step: 8
Training loss: 2.8344165937742796
Validation loss: 2.6285567105576737

Epoch: 5| Step: 9
Training loss: 2.5572088555772052
Validation loss: 2.6044289469565256

Epoch: 5| Step: 10
Training loss: 2.5954020191350273
Validation loss: 2.5784751577235325

Epoch: 5| Step: 11
Training loss: 2.606114617726227
Validation loss: 2.5604733112940408

Epoch: 5| Step: 0
Training loss: 2.784624773975111
Validation loss: 2.543379028319372

Epoch: 5| Step: 1
Training loss: 2.4680973590646746
Validation loss: 2.524649481553424

Epoch: 5| Step: 2
Training loss: 2.7446280810102612
Validation loss: 2.5146975298289984

Epoch: 5| Step: 3
Training loss: 2.554795569137666
Validation loss: 2.515516511777368

Epoch: 5| Step: 4
Training loss: 2.843930919886663
Validation loss: 2.5241779150533263

Epoch: 5| Step: 5
Training loss: 2.620003167798406
Validation loss: 2.5352699830298673

Epoch: 5| Step: 6
Training loss: 2.5375557052436024
Validation loss: 2.534569721918046

Epoch: 5| Step: 7
Training loss: 2.6909985503409346
Validation loss: 2.56296937024308

Epoch: 5| Step: 8
Training loss: 2.4693434762451165
Validation loss: 2.575800647456222

Epoch: 5| Step: 9
Training loss: 2.1532051591942105
Validation loss: 2.5797057382396003

Epoch: 5| Step: 10
Training loss: 2.193431768131335
Validation loss: 2.5626046849398834

Epoch: 5| Step: 11
Training loss: 2.804366834580581
Validation loss: 2.5644742834569794

Epoch: 6| Step: 0
Training loss: 2.4191316880095397
Validation loss: 2.557204601776545

Epoch: 5| Step: 1
Training loss: 1.9659428034831996
Validation loss: 2.564727975721087

Epoch: 5| Step: 2
Training loss: 2.193939865894768
Validation loss: 2.548638055371965

Epoch: 5| Step: 3
Training loss: 2.875215936927166
Validation loss: 2.554452933956737

Epoch: 5| Step: 4
Training loss: 2.480172880053649
Validation loss: 2.5437934659326364

Epoch: 5| Step: 5
Training loss: 2.1471883575655375
Validation loss: 2.5429950054510675

Epoch: 5| Step: 6
Training loss: 2.1955612964765283
Validation loss: 2.543525341901296

Epoch: 5| Step: 7
Training loss: 3.1529566134810896
Validation loss: 2.550401153986764

Epoch: 5| Step: 8
Training loss: 2.429702611551178
Validation loss: 2.533580813638066

Epoch: 5| Step: 9
Training loss: 2.5735298589497666
Validation loss: 2.522772292886978

Epoch: 5| Step: 10
Training loss: 2.8933384711868912
Validation loss: 2.519239186946539

Epoch: 5| Step: 11
Training loss: 3.4542154514992225
Validation loss: 2.523598991556924

Epoch: 7| Step: 0
Training loss: 2.061148229415004
Validation loss: 2.512970955836321

Epoch: 5| Step: 1
Training loss: 2.5867986714543876
Validation loss: 2.509909330575694

Epoch: 5| Step: 2
Training loss: 2.4263045626464526
Validation loss: 2.5059289325466647

Epoch: 5| Step: 3
Training loss: 2.23893592407488
Validation loss: 2.509451412812632

Epoch: 5| Step: 4
Training loss: 2.153161421469156
Validation loss: 2.5076651307059947

Epoch: 5| Step: 5
Training loss: 2.8271214511881277
Validation loss: 2.5120820118473604

Epoch: 5| Step: 6
Training loss: 2.5550378215103087
Validation loss: 2.509874769477195

Epoch: 5| Step: 7
Training loss: 2.724238063436387
Validation loss: 2.5155913111798336

Epoch: 5| Step: 8
Training loss: 2.593432119722229
Validation loss: 2.5105844668477406

Epoch: 5| Step: 9
Training loss: 3.119359992237099
Validation loss: 2.5306373529814965

Epoch: 5| Step: 10
Training loss: 2.5987601551850155
Validation loss: 2.523425681890601

Epoch: 5| Step: 11
Training loss: 2.1442537388750633
Validation loss: 2.51901375830718

Epoch: 8| Step: 0
Training loss: 2.173432813758652
Validation loss: 2.504500097989003

Epoch: 5| Step: 1
Training loss: 2.277845062512966
Validation loss: 2.5183014818214207

Epoch: 5| Step: 2
Training loss: 2.0950201935807757
Validation loss: 2.502879340332355

Epoch: 5| Step: 3
Training loss: 2.5245674367092428
Validation loss: 2.498038384624704

Epoch: 5| Step: 4
Training loss: 3.174330939738015
Validation loss: 2.5083411304272425

Epoch: 5| Step: 5
Training loss: 2.1819399335514964
Validation loss: 2.5073610772949606

Epoch: 5| Step: 6
Training loss: 2.233496860191951
Validation loss: 2.499905465246022

Epoch: 5| Step: 7
Training loss: 2.7821401821664375
Validation loss: 2.5031393684930476

Epoch: 5| Step: 8
Training loss: 1.8868176925968325
Validation loss: 2.5057888283713767

Epoch: 5| Step: 9
Training loss: 3.071113773068153
Validation loss: 2.497029510669943

Epoch: 5| Step: 10
Training loss: 2.9069052337012513
Validation loss: 2.5070653140998234

Epoch: 5| Step: 11
Training loss: 2.9400519790725532
Validation loss: 2.4950603879272717

Epoch: 9| Step: 0
Training loss: 2.0120588589168076
Validation loss: 2.5001563420683204

Epoch: 5| Step: 1
Training loss: 2.9078092596578196
Validation loss: 2.5164465540086436

Epoch: 5| Step: 2
Training loss: 2.0878877702199263
Validation loss: 2.526511690646841

Epoch: 5| Step: 3
Training loss: 1.800792569933747
Validation loss: 2.522912895069616

Epoch: 5| Step: 4
Training loss: 1.8923026594025874
Validation loss: 2.5191323450013257

Epoch: 5| Step: 5
Training loss: 2.9612729327955107
Validation loss: 2.5063360508632053

Epoch: 5| Step: 6
Training loss: 2.6351480962840332
Validation loss: 2.5187212605568208

Epoch: 5| Step: 7
Training loss: 2.8412694487470387
Validation loss: 2.50675736172769

Epoch: 5| Step: 8
Training loss: 2.8554046247929668
Validation loss: 2.5169500924506063

Epoch: 5| Step: 9
Training loss: 2.5677100459487083
Validation loss: 2.512527976188719

Epoch: 5| Step: 10
Training loss: 2.7462843154617693
Validation loss: 2.4866775462941244

Epoch: 5| Step: 11
Training loss: 2.4942983459454937
Validation loss: 2.502175362191764

Epoch: 10| Step: 0
Training loss: 2.8218295172894474
Validation loss: 2.510105045784555

Epoch: 5| Step: 1
Training loss: 2.1452037541999807
Validation loss: 2.50549151167697

Epoch: 5| Step: 2
Training loss: 2.3391015303724783
Validation loss: 2.51150879246892

Epoch: 5| Step: 3
Training loss: 2.6344009271434143
Validation loss: 2.5133539772914455

Epoch: 5| Step: 4
Training loss: 2.511560794022377
Validation loss: 2.4996837415928037

Epoch: 5| Step: 5
Training loss: 2.4453098674918436
Validation loss: 2.4966712128475175

Epoch: 5| Step: 6
Training loss: 2.3620021921288172
Validation loss: 2.4917357502698234

Epoch: 5| Step: 7
Training loss: 2.388187437302034
Validation loss: 2.516168010542606

Epoch: 5| Step: 8
Training loss: 2.3854759464366504
Validation loss: 2.5069846453544544

Epoch: 5| Step: 9
Training loss: 2.8429071204289706
Validation loss: 2.522570940553858

Epoch: 5| Step: 10
Training loss: 2.529234283733264
Validation loss: 2.511874615790319

Epoch: 5| Step: 11
Training loss: 2.5802355825817713
Validation loss: 2.5006058078135203

Epoch: 11| Step: 0
Training loss: 2.7580107274555714
Validation loss: 2.499855820154009

Epoch: 5| Step: 1
Training loss: 2.7211831265714923
Validation loss: 2.5005673599178775

Epoch: 5| Step: 2
Training loss: 2.5483015313003072
Validation loss: 2.5165984163966537

Epoch: 5| Step: 3
Training loss: 2.2471802314489033
Validation loss: 2.5039519386665834

Epoch: 5| Step: 4
Training loss: 2.4001053469107414
Validation loss: 2.5101382027246477

Epoch: 5| Step: 5
Training loss: 2.3779525473747194
Validation loss: 2.503481181659677

Epoch: 5| Step: 6
Training loss: 2.7188737336864737
Validation loss: 2.5054583249630045

Epoch: 5| Step: 7
Training loss: 2.2403627207540375
Validation loss: 2.512036123044629

Epoch: 5| Step: 8
Training loss: 2.096919834436506
Validation loss: 2.5085962007824048

Epoch: 5| Step: 9
Training loss: 2.580149092986879
Validation loss: 2.5013926997824396

Epoch: 5| Step: 10
Training loss: 2.763406844624225
Validation loss: 2.501922853412286

Epoch: 5| Step: 11
Training loss: 2.735605017711301
Validation loss: 2.5036839978175576

Epoch: 12| Step: 0
Training loss: 2.4409431201350973
Validation loss: 2.496589663119793

Epoch: 5| Step: 1
Training loss: 2.473956641481055
Validation loss: 2.4891955354287414

Epoch: 5| Step: 2
Training loss: 2.5271548830005135
Validation loss: 2.486689231442486

Epoch: 5| Step: 3
Training loss: 2.364540559042895
Validation loss: 2.4972446039187166

Epoch: 5| Step: 4
Training loss: 2.6713233958377534
Validation loss: 2.4999209788867325

Epoch: 5| Step: 5
Training loss: 2.7073534929222722
Validation loss: 2.4998791625701315

Epoch: 5| Step: 6
Training loss: 2.599091051850028
Validation loss: 2.4863349652751876

Epoch: 5| Step: 7
Training loss: 2.4432468647594705
Validation loss: 2.4942685270959264

Epoch: 5| Step: 8
Training loss: 2.359263133245393
Validation loss: 2.497567157351572

Epoch: 5| Step: 9
Training loss: 2.397734697487383
Validation loss: 2.4868386047479043

Epoch: 5| Step: 10
Training loss: 2.428844636888412
Validation loss: 2.4930568522098984

Epoch: 5| Step: 11
Training loss: 2.3031756081060997
Validation loss: 2.4945804862286556

Epoch: 13| Step: 0
Training loss: 2.3268918861680166
Validation loss: 2.485773760416065

Epoch: 5| Step: 1
Training loss: 2.640036252090777
Validation loss: 2.477848092346855

Epoch: 5| Step: 2
Training loss: 2.0711151294619246
Validation loss: 2.493996062603728

Epoch: 5| Step: 3
Training loss: 2.2576619134335973
Validation loss: 2.4911409530469553

Epoch: 5| Step: 4
Training loss: 2.7108893926128217
Validation loss: 2.486500892120453

Epoch: 5| Step: 5
Training loss: 2.1592404181446794
Validation loss: 2.4777296186218365

Epoch: 5| Step: 6
Training loss: 2.7028805837216745
Validation loss: 2.4866551785697997

Epoch: 5| Step: 7
Training loss: 2.430373999460206
Validation loss: 2.493766702868519

Epoch: 5| Step: 8
Training loss: 2.747208565692067
Validation loss: 2.4814100026542536

Epoch: 5| Step: 9
Training loss: 2.5706777573988644
Validation loss: 2.469755036559602

Epoch: 5| Step: 10
Training loss: 2.6871917902733333
Validation loss: 2.4903902969913005

Epoch: 5| Step: 11
Training loss: 2.5901793755824847
Validation loss: 2.4912769603466702

Epoch: 14| Step: 0
Training loss: 2.4197615723552435
Validation loss: 2.4866127836097074

Epoch: 5| Step: 1
Training loss: 2.0657477961296133
Validation loss: 2.4862719637113373

Epoch: 5| Step: 2
Training loss: 2.1325743825267334
Validation loss: 2.4720675072376914

Epoch: 5| Step: 3
Training loss: 2.7984035300318166
Validation loss: 2.4929109996042857

Epoch: 5| Step: 4
Training loss: 2.722007728958088
Validation loss: 2.4774259231430213

Epoch: 5| Step: 5
Training loss: 2.5730836533529375
Validation loss: 2.488003366425129

Epoch: 5| Step: 6
Training loss: 2.7440862358377798
Validation loss: 2.4838528974202814

Epoch: 5| Step: 7
Training loss: 2.5687345629597167
Validation loss: 2.497235032766447

Epoch: 5| Step: 8
Training loss: 2.4174049718537263
Validation loss: 2.495866386075835

Epoch: 5| Step: 9
Training loss: 2.878164622875924
Validation loss: 2.4854675225946123

Epoch: 5| Step: 10
Training loss: 2.0135087133067024
Validation loss: 2.4846105044082614

Epoch: 5| Step: 11
Training loss: 1.310817912197567
Validation loss: 2.488524380657528

Epoch: 15| Step: 0
Training loss: 1.9706367050486278
Validation loss: 2.495630295879459

Epoch: 5| Step: 1
Training loss: 2.5802893599065917
Validation loss: 2.4841340306017328

Epoch: 5| Step: 2
Training loss: 2.568020154939271
Validation loss: 2.500640886334641

Epoch: 5| Step: 3
Training loss: 2.8569273765234224
Validation loss: 2.482928336698025

Epoch: 5| Step: 4
Training loss: 2.4788909459595936
Validation loss: 2.491979723872108

Epoch: 5| Step: 5
Training loss: 2.9680640783461776
Validation loss: 2.4874989364212805

Epoch: 5| Step: 6
Training loss: 1.9834152063198998
Validation loss: 2.487864460914613

Epoch: 5| Step: 7
Training loss: 2.416967230773932
Validation loss: 2.4717937509982058

Epoch: 5| Step: 8
Training loss: 2.4889812832194123
Validation loss: 2.484918734790686

Epoch: 5| Step: 9
Training loss: 2.4341493710124675
Validation loss: 2.488422375823519

Epoch: 5| Step: 10
Training loss: 2.504859492916549
Validation loss: 2.4775560834793904

Epoch: 5| Step: 11
Training loss: 1.9774604536845308
Validation loss: 2.4790405166544405

Epoch: 16| Step: 0
Training loss: 2.83492410171341
Validation loss: 2.4783945216860435

Epoch: 5| Step: 1
Training loss: 2.3704795984703004
Validation loss: 2.486932413883378

Epoch: 5| Step: 2
Training loss: 2.273150448849404
Validation loss: 2.4818270030808622

Epoch: 5| Step: 3
Training loss: 2.5567276300906583
Validation loss: 2.4958934076707635

Epoch: 5| Step: 4
Training loss: 2.5173742242815043
Validation loss: 2.4926710148042495

Epoch: 5| Step: 5
Training loss: 2.48270979441392
Validation loss: 2.489055954101793

Epoch: 5| Step: 6
Training loss: 1.9163062821077697
Validation loss: 2.498901396009077

Epoch: 5| Step: 7
Training loss: 2.862298856772891
Validation loss: 2.4890379980126136

Epoch: 5| Step: 8
Training loss: 2.4830160202818505
Validation loss: 2.4811054463882294

Epoch: 5| Step: 9
Training loss: 2.801988923894323
Validation loss: 2.4804929797173103

Epoch: 5| Step: 10
Training loss: 1.9808868027166524
Validation loss: 2.5004202290845288

Epoch: 5| Step: 11
Training loss: 2.719441117763162
Validation loss: 2.488319620248815

Epoch: 17| Step: 0
Training loss: 2.1636606662760878
Validation loss: 2.489294224209999

Epoch: 5| Step: 1
Training loss: 2.1893374763864646
Validation loss: 2.483342369967752

Epoch: 5| Step: 2
Training loss: 2.7004926797152775
Validation loss: 2.4785602386202905

Epoch: 5| Step: 3
Training loss: 2.5727522845144586
Validation loss: 2.4841181664294885

Epoch: 5| Step: 4
Training loss: 2.4903241788341606
Validation loss: 2.4883509116649507

Epoch: 5| Step: 5
Training loss: 2.6156814113353843
Validation loss: 2.48342945491028

Epoch: 5| Step: 6
Training loss: 3.063381146157112
Validation loss: 2.47894868707184

Epoch: 5| Step: 7
Training loss: 2.223245927998039
Validation loss: 2.4751819127914954

Epoch: 5| Step: 8
Training loss: 2.281564978188179
Validation loss: 2.479959446642131

Epoch: 5| Step: 9
Training loss: 2.5455513539421357
Validation loss: 2.4670840730705197

Epoch: 5| Step: 10
Training loss: 2.1570655275665747
Validation loss: 2.4752647457389294

Epoch: 5| Step: 11
Training loss: 2.6457318464224278
Validation loss: 2.4715076528841404

Epoch: 18| Step: 0
Training loss: 2.666933364247397
Validation loss: 2.482752208005667

Epoch: 5| Step: 1
Training loss: 2.473274816487463
Validation loss: 2.4705610251995807

Epoch: 5| Step: 2
Training loss: 2.067123086838357
Validation loss: 2.4738174612527333

Epoch: 5| Step: 3
Training loss: 2.299455503613441
Validation loss: 2.471374388365155

Epoch: 5| Step: 4
Training loss: 2.796482420919444
Validation loss: 2.4700741818005416

Epoch: 5| Step: 5
Training loss: 2.514946982429724
Validation loss: 2.4766788595724343

Epoch: 5| Step: 6
Training loss: 2.4723270432137325
Validation loss: 2.477001259622881

Epoch: 5| Step: 7
Training loss: 2.3278003440659374
Validation loss: 2.4697678234333624

Epoch: 5| Step: 8
Training loss: 2.349833717956374
Validation loss: 2.4608657220938865

Epoch: 5| Step: 9
Training loss: 2.834060426055725
Validation loss: 2.4720628417058585

Epoch: 5| Step: 10
Training loss: 2.186786862341878
Validation loss: 2.4799239233612766

Epoch: 5| Step: 11
Training loss: 3.196512384069361
Validation loss: 2.468127928798339

Epoch: 19| Step: 0
Training loss: 2.1275859133164237
Validation loss: 2.4643341682309177

Epoch: 5| Step: 1
Training loss: 2.2005530962563387
Validation loss: 2.4710586392592417

Epoch: 5| Step: 2
Training loss: 2.5807975095340754
Validation loss: 2.4673649930817567

Epoch: 5| Step: 3
Training loss: 2.1784740064399712
Validation loss: 2.47011767501225

Epoch: 5| Step: 4
Training loss: 2.0191791751404335
Validation loss: 2.4624912745906946

Epoch: 5| Step: 5
Training loss: 2.728469749944295
Validation loss: 2.4798937674298935

Epoch: 5| Step: 6
Training loss: 2.7451327339418814
Validation loss: 2.490139190250924

Epoch: 5| Step: 7
Training loss: 2.385742587239017
Validation loss: 2.4815393855650867

Epoch: 5| Step: 8
Training loss: 2.1615658898000927
Validation loss: 2.4818198461719674

Epoch: 5| Step: 9
Training loss: 3.274229113290015
Validation loss: 2.4777729594132007

Epoch: 5| Step: 10
Training loss: 2.508451291306924
Validation loss: 2.4902944919086503

Epoch: 5| Step: 11
Training loss: 2.5919838832836892
Validation loss: 2.480838728017796

Epoch: 20| Step: 0
Training loss: 2.2320522159156524
Validation loss: 2.484493644648394

Epoch: 5| Step: 1
Training loss: 2.82318999784216
Validation loss: 2.490142533347767

Epoch: 5| Step: 2
Training loss: 1.907198122967846
Validation loss: 2.5030679196990393

Epoch: 5| Step: 3
Training loss: 2.150188606328674
Validation loss: 2.4932715909137713

Epoch: 5| Step: 4
Training loss: 2.115262215414372
Validation loss: 2.4840931362627665

Epoch: 5| Step: 5
Training loss: 2.658616391919821
Validation loss: 2.4808170504596787

Epoch: 5| Step: 6
Training loss: 2.116638112313613
Validation loss: 2.4858599049853853

Epoch: 5| Step: 7
Training loss: 2.374325606316107
Validation loss: 2.490047620365191

Epoch: 5| Step: 8
Training loss: 2.3878063464725097
Validation loss: 2.4953096697494073

Epoch: 5| Step: 9
Training loss: 2.996878748663665
Validation loss: 2.47149141826242

Epoch: 5| Step: 10
Training loss: 2.8997411546615823
Validation loss: 2.475161628551141

Epoch: 5| Step: 11
Training loss: 3.4800886809351357
Validation loss: 2.4826821491648685

Epoch: 21| Step: 0
Training loss: 2.5642259879239924
Validation loss: 2.459383866691198

Epoch: 5| Step: 1
Training loss: 2.344151373509456
Validation loss: 2.466196479935243

Epoch: 5| Step: 2
Training loss: 2.2453356184860946
Validation loss: 2.457965618585259

Epoch: 5| Step: 3
Training loss: 2.571559151482613
Validation loss: 2.463802184080154

Epoch: 5| Step: 4
Training loss: 2.5782406867687726
Validation loss: 2.4514024116952418

Epoch: 5| Step: 5
Training loss: 2.4632855551718644
Validation loss: 2.4586352079468123

Epoch: 5| Step: 6
Training loss: 2.5150972369529025
Validation loss: 2.460370320350096

Epoch: 5| Step: 7
Training loss: 2.160815064333025
Validation loss: 2.4550624534331322

Epoch: 5| Step: 8
Training loss: 2.484887891884782
Validation loss: 2.467719319631635

Epoch: 5| Step: 9
Training loss: 2.4527850067312476
Validation loss: 2.456648812503023

Epoch: 5| Step: 10
Training loss: 2.241168385353128
Validation loss: 2.4527681743174132

Epoch: 5| Step: 11
Training loss: 4.0051317674770095
Validation loss: 2.4567498276889244

Epoch: 22| Step: 0
Training loss: 1.9899745243684648
Validation loss: 2.451630673778573

Epoch: 5| Step: 1
Training loss: 2.689959265815303
Validation loss: 2.4566057986112373

Epoch: 5| Step: 2
Training loss: 2.5445309014418225
Validation loss: 2.4738005310058435

Epoch: 5| Step: 3
Training loss: 2.6970343797958494
Validation loss: 2.4555170905460226

Epoch: 5| Step: 4
Training loss: 2.8782751253387078
Validation loss: 2.457796160689501

Epoch: 5| Step: 5
Training loss: 2.3208336036266486
Validation loss: 2.4574411855834426

Epoch: 5| Step: 6
Training loss: 1.8686145133721297
Validation loss: 2.4547649984026187

Epoch: 5| Step: 7
Training loss: 2.6542458546880896
Validation loss: 2.453641764157594

Epoch: 5| Step: 8
Training loss: 2.2569851002740107
Validation loss: 2.4473451447715795

Epoch: 5| Step: 9
Training loss: 2.2939337758131035
Validation loss: 2.4546133373768444

Epoch: 5| Step: 10
Training loss: 2.526477317341338
Validation loss: 2.474300045038578

Epoch: 5| Step: 11
Training loss: 2.7656216378918916
Validation loss: 2.460192645342694

Epoch: 23| Step: 0
Training loss: 2.485581590840776
Validation loss: 2.4614172412371276

Epoch: 5| Step: 1
Training loss: 2.518288949271935
Validation loss: 2.463900119976187

Epoch: 5| Step: 2
Training loss: 2.5568317898474877
Validation loss: 2.4562509912063373

Epoch: 5| Step: 3
Training loss: 2.7335746247701036
Validation loss: 2.4529792434575177

Epoch: 5| Step: 4
Training loss: 2.4016577756965543
Validation loss: 2.466840311223235

Epoch: 5| Step: 5
Training loss: 2.726660609188051
Validation loss: 2.4575031860301157

Epoch: 5| Step: 6
Training loss: 2.6252261473107277
Validation loss: 2.464826975753784

Epoch: 5| Step: 7
Training loss: 2.1513668550343024
Validation loss: 2.468521948634846

Epoch: 5| Step: 8
Training loss: 1.965974940942612
Validation loss: 2.454220897537373

Epoch: 5| Step: 9
Training loss: 2.490072566740632
Validation loss: 2.473958307902018

Epoch: 5| Step: 10
Training loss: 2.2887568871953357
Validation loss: 2.4612436215169673

Epoch: 5| Step: 11
Training loss: 1.4749120136462537
Validation loss: 2.4678152362849697

Epoch: 24| Step: 0
Training loss: 1.8169070630152677
Validation loss: 2.456623526718041

Epoch: 5| Step: 1
Training loss: 2.312082716950402
Validation loss: 2.4760871735915146

Epoch: 5| Step: 2
Training loss: 2.040966445841415
Validation loss: 2.483779571963824

Epoch: 5| Step: 3
Training loss: 2.965645381427346
Validation loss: 2.490540046631079

Epoch: 5| Step: 4
Training loss: 2.629463397499395
Validation loss: 2.4966316658396672

Epoch: 5| Step: 5
Training loss: 2.6262064386646924
Validation loss: 2.490063678151911

Epoch: 5| Step: 6
Training loss: 1.8611255387400167
Validation loss: 2.4983363437432984

Epoch: 5| Step: 7
Training loss: 2.892016266752005
Validation loss: 2.504260462137848

Epoch: 5| Step: 8
Training loss: 2.570250443750066
Validation loss: 2.483742559454156

Epoch: 5| Step: 9
Training loss: 2.422021479945297
Validation loss: 2.4861705337528948

Epoch: 5| Step: 10
Training loss: 2.423715396691145
Validation loss: 2.476551683644964

Epoch: 5| Step: 11
Training loss: 3.132914172874771
Validation loss: 2.4771677254422158

Epoch: 25| Step: 0
Training loss: 2.2140363671504355
Validation loss: 2.4554670820352924

Epoch: 5| Step: 1
Training loss: 2.7495749752008014
Validation loss: 2.447141241802998

Epoch: 5| Step: 2
Training loss: 2.1698577074783327
Validation loss: 2.4451815089686937

Epoch: 5| Step: 3
Training loss: 2.6823024613740363
Validation loss: 2.447982597815923

Epoch: 5| Step: 4
Training loss: 2.357752968736223
Validation loss: 2.448451037958821

Epoch: 5| Step: 5
Training loss: 2.771473793832206
Validation loss: 2.441586585950365

Epoch: 5| Step: 6
Training loss: 2.3786463603356096
Validation loss: 2.455814964168348

Epoch: 5| Step: 7
Training loss: 1.8948404905275924
Validation loss: 2.454428126219402

Epoch: 5| Step: 8
Training loss: 2.6618422936111616
Validation loss: 2.4372562302854677

Epoch: 5| Step: 9
Training loss: 2.595379972183689
Validation loss: 2.445603904789121

Epoch: 5| Step: 10
Training loss: 1.9090596739372934
Validation loss: 2.4507276155235003

Epoch: 5| Step: 11
Training loss: 3.4406518531465147
Validation loss: 2.4494467207873853

Epoch: 26| Step: 0
Training loss: 2.162459347734201
Validation loss: 2.4505988942008976

Epoch: 5| Step: 1
Training loss: 2.4192355632093023
Validation loss: 2.449507303391975

Epoch: 5| Step: 2
Training loss: 1.7756330033000758
Validation loss: 2.4446038345609464

Epoch: 5| Step: 3
Training loss: 2.4520519849857902
Validation loss: 2.445678007212862

Epoch: 5| Step: 4
Training loss: 2.200173856628073
Validation loss: 2.4452154609511507

Epoch: 5| Step: 5
Training loss: 2.6417756592641655
Validation loss: 2.46644693300199

Epoch: 5| Step: 6
Training loss: 2.572043163785739
Validation loss: 2.458096486066954

Epoch: 5| Step: 7
Training loss: 2.7408338721616854
Validation loss: 2.462595932845909

Epoch: 5| Step: 8
Training loss: 2.293909351104351
Validation loss: 2.454795365904744

Epoch: 5| Step: 9
Training loss: 2.290309319074298
Validation loss: 2.4508887868386346

Epoch: 5| Step: 10
Training loss: 3.1394988361033884
Validation loss: 2.462702736682135

Epoch: 5| Step: 11
Training loss: 2.285958747478204
Validation loss: 2.4569256936239467

Epoch: 27| Step: 0
Training loss: 2.4334812781242934
Validation loss: 2.465000459955984

Epoch: 5| Step: 1
Training loss: 2.1666708970639914
Validation loss: 2.4514254718718815

Epoch: 5| Step: 2
Training loss: 2.1572862429499233
Validation loss: 2.466518633069091

Epoch: 5| Step: 3
Training loss: 2.3539785349344475
Validation loss: 2.459815335630902

Epoch: 5| Step: 4
Training loss: 2.621192441352926
Validation loss: 2.4523045692582968

Epoch: 5| Step: 5
Training loss: 2.479199182206321
Validation loss: 2.453720846522791

Epoch: 5| Step: 6
Training loss: 2.741283300278403
Validation loss: 2.466164047404899

Epoch: 5| Step: 7
Training loss: 2.1717014380613833
Validation loss: 2.449298042096805

Epoch: 5| Step: 8
Training loss: 2.2358349918563594
Validation loss: 2.4535420502655367

Epoch: 5| Step: 9
Training loss: 2.4519449299202405
Validation loss: 2.4590660649254916

Epoch: 5| Step: 10
Training loss: 2.738052249752639
Validation loss: 2.447363552885372

Epoch: 5| Step: 11
Training loss: 2.815275560514178
Validation loss: 2.445870474956311

Epoch: 28| Step: 0
Training loss: 1.6113538705329575
Validation loss: 2.448766205191886

Epoch: 5| Step: 1
Training loss: 3.0824678254439997
Validation loss: 2.460934795398336

Epoch: 5| Step: 2
Training loss: 2.762847540212189
Validation loss: 2.457517194781553

Epoch: 5| Step: 3
Training loss: 2.3000074552332257
Validation loss: 2.4493987338236867

Epoch: 5| Step: 4
Training loss: 2.185529529819744
Validation loss: 2.444921039695534

Epoch: 5| Step: 5
Training loss: 2.3765898954378755
Validation loss: 2.440725596850243

Epoch: 5| Step: 6
Training loss: 2.5536157068763816
Validation loss: 2.4525349063184416

Epoch: 5| Step: 7
Training loss: 2.1332744615100756
Validation loss: 2.4674532941425813

Epoch: 5| Step: 8
Training loss: 2.527636739501434
Validation loss: 2.455794018360722

Epoch: 5| Step: 9
Training loss: 2.8375634610645886
Validation loss: 2.453567622884415

Epoch: 5| Step: 10
Training loss: 1.9423342660827825
Validation loss: 2.450311934958342

Epoch: 5| Step: 11
Training loss: 1.7894882961464957
Validation loss: 2.44968919631582

Epoch: 29| Step: 0
Training loss: 2.426127975673522
Validation loss: 2.4471282433311354

Epoch: 5| Step: 1
Training loss: 1.908996417134651
Validation loss: 2.472573285471203

Epoch: 5| Step: 2
Training loss: 2.5750689339901225
Validation loss: 2.4610135990063156

Epoch: 5| Step: 3
Training loss: 3.0839290215306296
Validation loss: 2.467911722817064

Epoch: 5| Step: 4
Training loss: 2.3656309946606573
Validation loss: 2.4664483870011367

Epoch: 5| Step: 5
Training loss: 2.6362677746567407
Validation loss: 2.4790227565082508

Epoch: 5| Step: 6
Training loss: 2.7375213831236245
Validation loss: 2.4551505495656394

Epoch: 5| Step: 7
Training loss: 2.2272262922269728
Validation loss: 2.4568186912110224

Epoch: 5| Step: 8
Training loss: 1.9613112743134746
Validation loss: 2.4494025380983584

Epoch: 5| Step: 9
Training loss: 2.320714023155483
Validation loss: 2.466109058357025

Epoch: 5| Step: 10
Training loss: 2.285114724849739
Validation loss: 2.4385217538439106

Epoch: 5| Step: 11
Training loss: 2.0008835033189114
Validation loss: 2.449555071260926

Epoch: 30| Step: 0
Training loss: 2.1988597732735826
Validation loss: 2.444255637032165

Epoch: 5| Step: 1
Training loss: 2.5967093441271394
Validation loss: 2.462214168025388

Epoch: 5| Step: 2
Training loss: 2.4523864411827456
Validation loss: 2.467650561034179

Epoch: 5| Step: 3
Training loss: 2.486480780123159
Validation loss: 2.480149616527464

Epoch: 5| Step: 4
Training loss: 2.3897498030963256
Validation loss: 2.4701428126092857

Epoch: 5| Step: 5
Training loss: 2.735884331622828
Validation loss: 2.4750912986639104

Epoch: 5| Step: 6
Training loss: 2.2158297811333614
Validation loss: 2.4662442306873857

Epoch: 5| Step: 7
Training loss: 2.3954203263491096
Validation loss: 2.4638427136435808

Epoch: 5| Step: 8
Training loss: 2.4063141058767363
Validation loss: 2.465485655985345

Epoch: 5| Step: 9
Training loss: 2.2556152211624974
Validation loss: 2.450133498116424

Epoch: 5| Step: 10
Training loss: 2.347334295402459
Validation loss: 2.4469621434127804

Epoch: 5| Step: 11
Training loss: 2.95351088490312
Validation loss: 2.451079935525449

Epoch: 31| Step: 0
Training loss: 2.5695661487337715
Validation loss: 2.457742997318707

Epoch: 5| Step: 1
Training loss: 2.4819266292722717
Validation loss: 2.431937117674189

Epoch: 5| Step: 2
Training loss: 2.2253356766106527
Validation loss: 2.449005515161807

Epoch: 5| Step: 3
Training loss: 2.679127715338333
Validation loss: 2.4344121007087667

Epoch: 5| Step: 4
Training loss: 2.0093464613529717
Validation loss: 2.449196506624349

Epoch: 5| Step: 5
Training loss: 2.4998464537197664
Validation loss: 2.4379709636496694

Epoch: 5| Step: 6
Training loss: 2.1793114122369817
Validation loss: 2.437905208619615

Epoch: 5| Step: 7
Training loss: 2.0873932634122676
Validation loss: 2.4474611399601303

Epoch: 5| Step: 8
Training loss: 2.7662685529153066
Validation loss: 2.458925498477725

Epoch: 5| Step: 9
Training loss: 2.1555947676540796
Validation loss: 2.445489472799106

Epoch: 5| Step: 10
Training loss: 2.4691847406353036
Validation loss: 2.441409712725409

Epoch: 5| Step: 11
Training loss: 3.4864317977407575
Validation loss: 2.4392916745833326

Epoch: 32| Step: 0
Training loss: 2.6848297160333017
Validation loss: 2.431983807104405

Epoch: 5| Step: 1
Training loss: 1.9327211819465258
Validation loss: 2.4445837232859136

Epoch: 5| Step: 2
Training loss: 2.3162203580685814
Validation loss: 2.451321645672348

Epoch: 5| Step: 3
Training loss: 2.346539680917647
Validation loss: 2.4516233476779004

Epoch: 5| Step: 4
Training loss: 2.7421879347233005
Validation loss: 2.4554274054378276

Epoch: 5| Step: 5
Training loss: 2.660134201966725
Validation loss: 2.4416900388447464

Epoch: 5| Step: 6
Training loss: 2.32572998154386
Validation loss: 2.4510596950033885

Epoch: 5| Step: 7
Training loss: 2.1994560479561462
Validation loss: 2.4392143888098325

Epoch: 5| Step: 8
Training loss: 1.9831449646279946
Validation loss: 2.4525750145050806

Epoch: 5| Step: 9
Training loss: 3.2415154553394605
Validation loss: 2.4381232402253747

Epoch: 5| Step: 10
Training loss: 1.6895881731157643
Validation loss: 2.448451942737197

Epoch: 5| Step: 11
Training loss: 2.4102185703424763
Validation loss: 2.453510792680968

Epoch: 33| Step: 0
Training loss: 2.1993843951272587
Validation loss: 2.4338279109371017

Epoch: 5| Step: 1
Training loss: 2.394787723316222
Validation loss: 2.4413402416206855

Epoch: 5| Step: 2
Training loss: 2.409609443549032
Validation loss: 2.444877689448054

Epoch: 5| Step: 3
Training loss: 2.7948634410110533
Validation loss: 2.4525095578654543

Epoch: 5| Step: 4
Training loss: 2.52537457548796
Validation loss: 2.4505961315708857

Epoch: 5| Step: 5
Training loss: 2.8523647068312226
Validation loss: 2.4504746051985857

Epoch: 5| Step: 6
Training loss: 2.2264591661534205
Validation loss: 2.452262060484524

Epoch: 5| Step: 7
Training loss: 2.3176105835835905
Validation loss: 2.4605311709210342

Epoch: 5| Step: 8
Training loss: 2.0604966577855945
Validation loss: 2.454402546376319

Epoch: 5| Step: 9
Training loss: 2.7067136371777645
Validation loss: 2.4385987438206906

Epoch: 5| Step: 10
Training loss: 1.9354802340555373
Validation loss: 2.4552541228146048

Epoch: 5| Step: 11
Training loss: 1.9766094217272139
Validation loss: 2.445269762017115

Epoch: 34| Step: 0
Training loss: 2.526649910494653
Validation loss: 2.4461590334509

Epoch: 5| Step: 1
Training loss: 2.362411666914166
Validation loss: 2.4492541426718053

Epoch: 5| Step: 2
Training loss: 2.663867305641219
Validation loss: 2.4367198388416353

Epoch: 5| Step: 3
Training loss: 2.4845602098440547
Validation loss: 2.451757750588027

Epoch: 5| Step: 4
Training loss: 2.520659438091178
Validation loss: 2.442021899101183

Epoch: 5| Step: 5
Training loss: 2.26495382956632
Validation loss: 2.44768873059845

Epoch: 5| Step: 6
Training loss: 2.7796564573256086
Validation loss: 2.4661713383667263

Epoch: 5| Step: 7
Training loss: 2.515761282884069
Validation loss: 2.446580344883109

Epoch: 5| Step: 8
Training loss: 2.1332219328205744
Validation loss: 2.447718029214598

Epoch: 5| Step: 9
Training loss: 2.277308887456943
Validation loss: 2.4374588041818344

Epoch: 5| Step: 10
Training loss: 1.6191799402928109
Validation loss: 2.447830070154306

Epoch: 5| Step: 11
Training loss: 2.5286456238065265
Validation loss: 2.444708061874607

Epoch: 35| Step: 0
Training loss: 2.2099366635528908
Validation loss: 2.4311509258477844

Epoch: 5| Step: 1
Training loss: 2.341341535955035
Validation loss: 2.4416714618318967

Epoch: 5| Step: 2
Training loss: 2.774080271851428
Validation loss: 2.4382359502223228

Epoch: 5| Step: 3
Training loss: 2.1567150112120523
Validation loss: 2.4364277119456683

Epoch: 5| Step: 4
Training loss: 2.1171886261095945
Validation loss: 2.4235515370071363

Epoch: 5| Step: 5
Training loss: 2.150757137319997
Validation loss: 2.4279720796653534

Epoch: 5| Step: 6
Training loss: 2.3176872223882006
Validation loss: 2.4318289687663683

Epoch: 5| Step: 7
Training loss: 2.8773838609048332
Validation loss: 2.43544169272516

Epoch: 5| Step: 8
Training loss: 1.9618964415196116
Validation loss: 2.438677258953779

Epoch: 5| Step: 9
Training loss: 2.8162915422039845
Validation loss: 2.4354050550899196

Epoch: 5| Step: 10
Training loss: 2.55533043473369
Validation loss: 2.4374425322939306

Epoch: 5| Step: 11
Training loss: 1.565509720325295
Validation loss: 2.438232629664649

Epoch: 36| Step: 0
Training loss: 2.5046661699687327
Validation loss: 2.4245099367237173

Epoch: 5| Step: 1
Training loss: 2.363920973268541
Validation loss: 2.431199806221525

Epoch: 5| Step: 2
Training loss: 2.5032754421863217
Validation loss: 2.4289862836230887

Epoch: 5| Step: 3
Training loss: 2.627124653147671
Validation loss: 2.4516677050995677

Epoch: 5| Step: 4
Training loss: 2.1929205084299626
Validation loss: 2.4438672654682816

Epoch: 5| Step: 5
Training loss: 2.269989650215384
Validation loss: 2.470002021878814

Epoch: 5| Step: 6
Training loss: 2.38025785988687
Validation loss: 2.479787946372062

Epoch: 5| Step: 7
Training loss: 2.127508702153878
Validation loss: 2.4829801926539132

Epoch: 5| Step: 8
Training loss: 2.875075795376984
Validation loss: 2.5091238267481177

Epoch: 5| Step: 9
Training loss: 2.1775726668871407
Validation loss: 2.5163959759172156

Epoch: 5| Step: 10
Training loss: 2.5284014085101583
Validation loss: 2.4940981621091165

Epoch: 5| Step: 11
Training loss: 1.368598950556144
Validation loss: 2.4863131578369018

Epoch: 37| Step: 0
Training loss: 2.179741862176317
Validation loss: 2.4838471721652806

Epoch: 5| Step: 1
Training loss: 2.9038308853004517
Validation loss: 2.469978421241823

Epoch: 5| Step: 2
Training loss: 2.850693829054049
Validation loss: 2.4444287646096603

Epoch: 5| Step: 3
Training loss: 2.5592748303309527
Validation loss: 2.452209111350136

Epoch: 5| Step: 4
Training loss: 1.926040539105919
Validation loss: 2.4374612128603315

Epoch: 5| Step: 5
Training loss: 2.358494575389117
Validation loss: 2.4390541953825835

Epoch: 5| Step: 6
Training loss: 2.320746589925246
Validation loss: 2.4182979973790717

Epoch: 5| Step: 7
Training loss: 1.6295326547034126
Validation loss: 2.4273872280739073

Epoch: 5| Step: 8
Training loss: 2.693944080556885
Validation loss: 2.440668532748092

Epoch: 5| Step: 9
Training loss: 2.3798619748010608
Validation loss: 2.421935886725193

Epoch: 5| Step: 10
Training loss: 2.4526614583381723
Validation loss: 2.422158640997722

Epoch: 5| Step: 11
Training loss: 1.7124916577658067
Validation loss: 2.421559294766067

Epoch: 38| Step: 0
Training loss: 2.1206756798005926
Validation loss: 2.4267358217323958

Epoch: 5| Step: 1
Training loss: 2.340359078594619
Validation loss: 2.4264255718400514

Epoch: 5| Step: 2
Training loss: 2.4157785778895664
Validation loss: 2.439345777647531

Epoch: 5| Step: 3
Training loss: 2.0034821714098747
Validation loss: 2.457170406700779

Epoch: 5| Step: 4
Training loss: 2.1995952277185005
Validation loss: 2.4579294359181874

Epoch: 5| Step: 5
Training loss: 2.5652473422658395
Validation loss: 2.4464802152730374

Epoch: 5| Step: 6
Training loss: 1.9953341298435778
Validation loss: 2.467888810651431

Epoch: 5| Step: 7
Training loss: 2.8412326947485327
Validation loss: 2.480405006691007

Epoch: 5| Step: 8
Training loss: 2.468467986018463
Validation loss: 2.4668007007689017

Epoch: 5| Step: 9
Training loss: 2.6331807679835926
Validation loss: 2.495985889442562

Epoch: 5| Step: 10
Training loss: 2.6236379813770454
Validation loss: 2.4734385509894383

Epoch: 5| Step: 11
Training loss: 1.9020502698294095
Validation loss: 2.4740063324672232

Epoch: 39| Step: 0
Training loss: 2.2709332598710543
Validation loss: 2.4660741130278496

Epoch: 5| Step: 1
Training loss: 2.5082351471027633
Validation loss: 2.443257135315046

Epoch: 5| Step: 2
Training loss: 2.832348783384085
Validation loss: 2.46375005753335

Epoch: 5| Step: 3
Training loss: 2.2431065606406033
Validation loss: 2.43216310987742

Epoch: 5| Step: 4
Training loss: 2.313675349766036
Validation loss: 2.435295485610818

Epoch: 5| Step: 5
Training loss: 1.937332146049358
Validation loss: 2.4565259639318495

Epoch: 5| Step: 6
Training loss: 2.441181337296294
Validation loss: 2.446275042241796

Epoch: 5| Step: 7
Training loss: 2.5195569887251197
Validation loss: 2.459553760460854

Epoch: 5| Step: 8
Training loss: 2.1950292438479395
Validation loss: 2.4388611286196316

Epoch: 5| Step: 9
Training loss: 2.272156869227762
Validation loss: 2.452428731086959

Epoch: 5| Step: 10
Training loss: 2.5239788218847545
Validation loss: 2.4448086074179316

Epoch: 5| Step: 11
Training loss: 1.8575737827890577
Validation loss: 2.4466425210773033

Epoch: 40| Step: 0
Training loss: 2.311007662540477
Validation loss: 2.435403770192908

Epoch: 5| Step: 1
Training loss: 2.4274717574043176
Validation loss: 2.41993620598598

Epoch: 5| Step: 2
Training loss: 2.380020156422379
Validation loss: 2.42809793988258

Epoch: 5| Step: 3
Training loss: 1.7967497408786945
Validation loss: 2.428507543906996

Epoch: 5| Step: 4
Training loss: 2.078067291146854
Validation loss: 2.4226585351268297

Epoch: 5| Step: 5
Training loss: 2.7751533465931093
Validation loss: 2.439551085517683

Epoch: 5| Step: 6
Training loss: 2.5506473991010625
Validation loss: 2.433248312708085

Epoch: 5| Step: 7
Training loss: 2.6575067576396934
Validation loss: 2.4218727563006768

Epoch: 5| Step: 8
Training loss: 1.9519828813966957
Validation loss: 2.4192240347440395

Epoch: 5| Step: 9
Training loss: 2.5201599756052833
Validation loss: 2.433316802323595

Epoch: 5| Step: 10
Training loss: 2.703089190119107
Validation loss: 2.4324929149344157

Epoch: 5| Step: 11
Training loss: 1.8765082333203973
Validation loss: 2.430683475640113

Epoch: 41| Step: 0
Training loss: 1.958245424231924
Validation loss: 2.422548975533107

Epoch: 5| Step: 1
Training loss: 2.4148171242289216
Validation loss: 2.4312880499182348

Epoch: 5| Step: 2
Training loss: 2.152197304951597
Validation loss: 2.444788786327441

Epoch: 5| Step: 3
Training loss: 2.042125170339524
Validation loss: 2.422634395372445

Epoch: 5| Step: 4
Training loss: 2.4136898407434932
Validation loss: 2.423459480197444

Epoch: 5| Step: 5
Training loss: 2.584634043247169
Validation loss: 2.4397222952244477

Epoch: 5| Step: 6
Training loss: 2.3908208629681376
Validation loss: 2.418899704081356

Epoch: 5| Step: 7
Training loss: 2.9016694098000775
Validation loss: 2.440196953919061

Epoch: 5| Step: 8
Training loss: 2.352868614059624
Validation loss: 2.435753608338121

Epoch: 5| Step: 9
Training loss: 2.051829856540954
Validation loss: 2.433478036806331

Epoch: 5| Step: 10
Training loss: 2.31109865360489
Validation loss: 2.4411605426488143

Epoch: 5| Step: 11
Training loss: 3.5261025510383917
Validation loss: 2.453853903844369

Epoch: 42| Step: 0
Training loss: 2.33583277847151
Validation loss: 2.446025780921684

Epoch: 5| Step: 1
Training loss: 2.2927960358385104
Validation loss: 2.44951786403004

Epoch: 5| Step: 2
Training loss: 2.423605909466437
Validation loss: 2.453691249133703

Epoch: 5| Step: 3
Training loss: 2.6949329053633972
Validation loss: 2.4526779472080085

Epoch: 5| Step: 4
Training loss: 1.8972358197044084
Validation loss: 2.436740854841225

Epoch: 5| Step: 5
Training loss: 2.097389587842687
Validation loss: 2.4593082706522624

Epoch: 5| Step: 6
Training loss: 2.104769617190674
Validation loss: 2.457397324502047

Epoch: 5| Step: 7
Training loss: 2.7810053342722103
Validation loss: 2.4465204409923826

Epoch: 5| Step: 8
Training loss: 2.4210233113719792
Validation loss: 2.4490406513103515

Epoch: 5| Step: 9
Training loss: 2.3328369384630205
Validation loss: 2.435085237585618

Epoch: 5| Step: 10
Training loss: 2.572510866192259
Validation loss: 2.429681407924918

Epoch: 5| Step: 11
Training loss: 2.3399353518888693
Validation loss: 2.445591107341674

Epoch: 43| Step: 0
Training loss: 2.370237796136834
Validation loss: 2.4250471444807213

Epoch: 5| Step: 1
Training loss: 2.5344103640195113
Validation loss: 2.4350480723939385

Epoch: 5| Step: 2
Training loss: 2.195987692612588
Validation loss: 2.444943846111044

Epoch: 5| Step: 3
Training loss: 2.166296731716639
Validation loss: 2.4343845354186446

Epoch: 5| Step: 4
Training loss: 2.0703441689426314
Validation loss: 2.4566945834387415

Epoch: 5| Step: 5
Training loss: 1.8926469693885
Validation loss: 2.4467006862418645

Epoch: 5| Step: 6
Training loss: 2.4560381848973414
Validation loss: 2.4468438428679025

Epoch: 5| Step: 7
Training loss: 2.390272725398135
Validation loss: 2.446741298109835

Epoch: 5| Step: 8
Training loss: 2.757991795749647
Validation loss: 2.4556450059101214

Epoch: 5| Step: 9
Training loss: 2.2780412027988364
Validation loss: 2.439023719461376

Epoch: 5| Step: 10
Training loss: 2.840117933215583
Validation loss: 2.469842081723185

Epoch: 5| Step: 11
Training loss: 1.588873039661549
Validation loss: 2.4373589091752

Epoch: 44| Step: 0
Training loss: 2.305777392253943
Validation loss: 2.4428045271509573

Epoch: 5| Step: 1
Training loss: 1.6571821073055555
Validation loss: 2.4365979241227698

Epoch: 5| Step: 2
Training loss: 2.2577419599977695
Validation loss: 2.4394923080502373

Epoch: 5| Step: 3
Training loss: 2.473392515562635
Validation loss: 2.4361832395866188

Epoch: 5| Step: 4
Training loss: 2.0257291446550507
Validation loss: 2.4271328693186422

Epoch: 5| Step: 5
Training loss: 2.518733503036808
Validation loss: 2.430474761952185

Epoch: 5| Step: 6
Training loss: 3.1097712432040066
Validation loss: 2.4385500565691025

Epoch: 5| Step: 7
Training loss: 2.1964080357671523
Validation loss: 2.4222843521526984

Epoch: 5| Step: 8
Training loss: 3.0030662443544194
Validation loss: 2.4057809777195773

Epoch: 5| Step: 9
Training loss: 2.0899223526763056
Validation loss: 2.430245154557363

Epoch: 5| Step: 10
Training loss: 1.7361704837395429
Validation loss: 2.4189666964761707

Epoch: 5| Step: 11
Training loss: 2.3672152980267582
Validation loss: 2.42018102654495

Epoch: 45| Step: 0
Training loss: 1.8784358016561555
Validation loss: 2.4188258224089796

Epoch: 5| Step: 1
Training loss: 2.4931953329597416
Validation loss: 2.4370367494353826

Epoch: 5| Step: 2
Training loss: 2.307525852509037
Validation loss: 2.441876716551329

Epoch: 5| Step: 3
Training loss: 2.1373268949673863
Validation loss: 2.4225389780452486

Epoch: 5| Step: 4
Training loss: 2.3589661098631556
Validation loss: 2.430290384511219

Epoch: 5| Step: 5
Training loss: 2.5013052394091773
Validation loss: 2.4367512343543694

Epoch: 5| Step: 6
Training loss: 2.106573434327963
Validation loss: 2.4374201590348794

Epoch: 5| Step: 7
Training loss: 1.9909083429733399
Validation loss: 2.4340212320471624

Epoch: 5| Step: 8
Training loss: 2.9816956001130293
Validation loss: 2.450179102897113

Epoch: 5| Step: 9
Training loss: 2.6549662461083856
Validation loss: 2.441672450493829

Epoch: 5| Step: 10
Training loss: 2.293141139242167
Validation loss: 2.4405287200588854

Epoch: 5| Step: 11
Training loss: 2.3738500923319186
Validation loss: 2.4516650794153976

Epoch: 46| Step: 0
Training loss: 2.3203736371035983
Validation loss: 2.4496500628196713

Epoch: 5| Step: 1
Training loss: 1.7386606552457933
Validation loss: 2.436261742858614

Epoch: 5| Step: 2
Training loss: 2.3369416085009416
Validation loss: 2.461333155237145

Epoch: 5| Step: 3
Training loss: 2.2895182393487383
Validation loss: 2.472493572618894

Epoch: 5| Step: 4
Training loss: 2.681923247778787
Validation loss: 2.4438706474734366

Epoch: 5| Step: 5
Training loss: 2.4177507292977447
Validation loss: 2.4327413945065293

Epoch: 5| Step: 6
Training loss: 2.4025631688096882
Validation loss: 2.446828711320745

Epoch: 5| Step: 7
Training loss: 2.7857133861861683
Validation loss: 2.4322028964151388

Epoch: 5| Step: 8
Training loss: 2.0587445372165636
Validation loss: 2.439628128522232

Epoch: 5| Step: 9
Training loss: 2.5322679898028517
Validation loss: 2.4257552493099963

Epoch: 5| Step: 10
Training loss: 2.2284003987725716
Validation loss: 2.4305784548331664

Epoch: 5| Step: 11
Training loss: 1.58947614689221
Validation loss: 2.4260110137125475

Epoch: 47| Step: 0
Training loss: 2.270176597145377
Validation loss: 2.427964039806227

Epoch: 5| Step: 1
Training loss: 2.2600020513272048
Validation loss: 2.426774808950792

Epoch: 5| Step: 2
Training loss: 2.3125307235738823
Validation loss: 2.43897643164503

Epoch: 5| Step: 3
Training loss: 2.118638333329021
Validation loss: 2.4363612424878816

Epoch: 5| Step: 4
Training loss: 2.515394117292083
Validation loss: 2.4237600517294045

Epoch: 5| Step: 5
Training loss: 2.167653543738287
Validation loss: 2.4370456133466054

Epoch: 5| Step: 6
Training loss: 2.862350666531933
Validation loss: 2.4313796673202805

Epoch: 5| Step: 7
Training loss: 1.5228317230094741
Validation loss: 2.434980928834597

Epoch: 5| Step: 8
Training loss: 3.0034788941374795
Validation loss: 2.4559791426924957

Epoch: 5| Step: 9
Training loss: 2.2276533700394996
Validation loss: 2.44307491802528

Epoch: 5| Step: 10
Training loss: 2.0150608189872408
Validation loss: 2.442332567595257

Epoch: 5| Step: 11
Training loss: 2.6681892002340932
Validation loss: 2.441581430889506

Epoch: 48| Step: 0
Training loss: 2.2487501275665265
Validation loss: 2.4265000736699807

Epoch: 5| Step: 1
Training loss: 2.1463735202977263
Validation loss: 2.4380712899312

Epoch: 5| Step: 2
Training loss: 3.0183294157286786
Validation loss: 2.4133807827722227

Epoch: 5| Step: 3
Training loss: 2.631613529128682
Validation loss: 2.4300827367260847

Epoch: 5| Step: 4
Training loss: 2.169129866606503
Validation loss: 2.434887076513418

Epoch: 5| Step: 5
Training loss: 2.3338849800684716
Validation loss: 2.4147553709837766

Epoch: 5| Step: 6
Training loss: 1.8074716337307573
Validation loss: 2.4183278430856245

Epoch: 5| Step: 7
Training loss: 2.358853718347746
Validation loss: 2.417877824149114

Epoch: 5| Step: 8
Training loss: 2.5695946337362385
Validation loss: 2.418993825558187

Epoch: 5| Step: 9
Training loss: 2.5297700299471777
Validation loss: 2.4208198443303433

Epoch: 5| Step: 10
Training loss: 2.1573926689882734
Validation loss: 2.414670429408833

Epoch: 5| Step: 11
Training loss: 1.005277180002323
Validation loss: 2.4318320897314236

Epoch: 49| Step: 0
Training loss: 2.128560953397934
Validation loss: 2.433272428817272

Epoch: 5| Step: 1
Training loss: 2.0141985673420737
Validation loss: 2.4234189085879567

Epoch: 5| Step: 2
Training loss: 2.4430010416198082
Validation loss: 2.451276187779536

Epoch: 5| Step: 3
Training loss: 2.5280624853451648
Validation loss: 2.4421536657032052

Epoch: 5| Step: 4
Training loss: 2.464191525793695
Validation loss: 2.4520115724908145

Epoch: 5| Step: 5
Training loss: 2.112569805549415
Validation loss: 2.446891441468613

Epoch: 5| Step: 6
Training loss: 2.0966434129154226
Validation loss: 2.457810080871232

Epoch: 5| Step: 7
Training loss: 2.683945367646523
Validation loss: 2.449411545850968

Epoch: 5| Step: 8
Training loss: 2.255578437254818
Validation loss: 2.456959244765155

Epoch: 5| Step: 9
Training loss: 2.489029081782392
Validation loss: 2.4480029368247904

Epoch: 5| Step: 10
Training loss: 2.4427141028189014
Validation loss: 2.435000017898528

Epoch: 5| Step: 11
Training loss: 2.125594560808452
Validation loss: 2.4490169074905475

Epoch: 50| Step: 0
Training loss: 2.977164780766415
Validation loss: 2.4649412616478665

Epoch: 5| Step: 1
Training loss: 2.022956938364012
Validation loss: 2.4629332689732353

Epoch: 5| Step: 2
Training loss: 1.9061299270585217
Validation loss: 2.4434688308801085

Epoch: 5| Step: 3
Training loss: 2.3576010799481857
Validation loss: 2.462854359395313

Epoch: 5| Step: 4
Training loss: 2.5125601917856994
Validation loss: 2.4931278188770314

Epoch: 5| Step: 5
Training loss: 1.9134855685441192
Validation loss: 2.48940787767821

Epoch: 5| Step: 6
Training loss: 1.7946838287470068
Validation loss: 2.507424404739076

Epoch: 5| Step: 7
Training loss: 1.957171102007737
Validation loss: 2.514174360999587

Epoch: 5| Step: 8
Training loss: 3.175795363879308
Validation loss: 2.5175227476529893

Epoch: 5| Step: 9
Training loss: 2.410843959731747
Validation loss: 2.487248831836844

Epoch: 5| Step: 10
Training loss: 2.3237498090804474
Validation loss: 2.453639468532516

Epoch: 5| Step: 11
Training loss: 2.81640625
Validation loss: 2.445657646838037

Epoch: 51| Step: 0
Training loss: 2.3841742954800993
Validation loss: 2.4153816503588432

Epoch: 5| Step: 1
Training loss: 2.5987422651989553
Validation loss: 2.4168621688448244

Epoch: 5| Step: 2
Training loss: 2.165371275291417
Validation loss: 2.4197407044786132

Epoch: 5| Step: 3
Training loss: 2.429182484631432
Validation loss: 2.401517420957653

Epoch: 5| Step: 4
Training loss: 2.107436129687078
Validation loss: 2.425677143182899

Epoch: 5| Step: 5
Training loss: 2.268205212635576
Validation loss: 2.4167047626408498

Epoch: 5| Step: 6
Training loss: 2.6659517720718773
Validation loss: 2.4272966877778948

Epoch: 5| Step: 7
Training loss: 2.5332515008994037
Validation loss: 2.431555055800461

Epoch: 5| Step: 8
Training loss: 2.2170207847408974
Validation loss: 2.43281925750101

Epoch: 5| Step: 9
Training loss: 2.0844856381542636
Validation loss: 2.409848292958917

Epoch: 5| Step: 10
Training loss: 2.184990778888301
Validation loss: 2.4160700683709413

Epoch: 5| Step: 11
Training loss: 2.7493463086094314
Validation loss: 2.428655611744294

Epoch: 52| Step: 0
Training loss: 2.656068503967116
Validation loss: 2.4053866955649683

Epoch: 5| Step: 1
Training loss: 2.2910758788631904
Validation loss: 2.406891846615589

Epoch: 5| Step: 2
Training loss: 2.3573088030178915
Validation loss: 2.4169160197679913

Epoch: 5| Step: 3
Training loss: 2.393232730922321
Validation loss: 2.4199114561433928

Epoch: 5| Step: 4
Training loss: 2.149749466249302
Validation loss: 2.4058933365288024

Epoch: 5| Step: 5
Training loss: 1.9765433811876416
Validation loss: 2.4183217716882734

Epoch: 5| Step: 6
Training loss: 2.1350091933112796
Validation loss: 2.4188650808631196

Epoch: 5| Step: 7
Training loss: 2.440102972453072
Validation loss: 2.4244164002212436

Epoch: 5| Step: 8
Training loss: 2.6826605583270524
Validation loss: 2.4311915829463224

Epoch: 5| Step: 9
Training loss: 2.037050738272523
Validation loss: 2.465143293345197

Epoch: 5| Step: 10
Training loss: 2.5519477548722294
Validation loss: 2.4760580762566278

Epoch: 5| Step: 11
Training loss: 1.4902802906487238
Validation loss: 2.448575861757608

Epoch: 53| Step: 0
Training loss: 2.4004975955429066
Validation loss: 2.4522863602725993

Epoch: 5| Step: 1
Training loss: 2.4219842701534224
Validation loss: 2.4530134945126463

Epoch: 5| Step: 2
Training loss: 1.6245591959595556
Validation loss: 2.44417077772894

Epoch: 5| Step: 3
Training loss: 2.7607546233580895
Validation loss: 2.461003442920238

Epoch: 5| Step: 4
Training loss: 2.387182911692301
Validation loss: 2.428203162068958

Epoch: 5| Step: 5
Training loss: 2.5865324782274226
Validation loss: 2.422911276665091

Epoch: 5| Step: 6
Training loss: 1.9990645843728752
Validation loss: 2.4271801607248475

Epoch: 5| Step: 7
Training loss: 2.2685018230293856
Validation loss: 2.453645274394962

Epoch: 5| Step: 8
Training loss: 2.0811430161847833
Validation loss: 2.4369192368916996

Epoch: 5| Step: 9
Training loss: 2.368552843409132
Validation loss: 2.4289996613750535

Epoch: 5| Step: 10
Training loss: 2.6746609089631885
Validation loss: 2.434739640609962

Epoch: 5| Step: 11
Training loss: 0.7699401853291463
Validation loss: 2.4122939560418075

Epoch: 54| Step: 0
Training loss: 2.360132058053408
Validation loss: 2.417029955019793

Epoch: 5| Step: 1
Training loss: 2.6509938913373525
Validation loss: 2.415245548135866

Epoch: 5| Step: 2
Training loss: 2.7030267421967475
Validation loss: 2.433486217655959

Epoch: 5| Step: 3
Training loss: 2.3769344683301306
Validation loss: 2.4114211775112264

Epoch: 5| Step: 4
Training loss: 1.4647594376777755
Validation loss: 2.4144383809638725

Epoch: 5| Step: 5
Training loss: 2.3426691233224566
Validation loss: 2.4171041648947758

Epoch: 5| Step: 6
Training loss: 2.0371649671450363
Validation loss: 2.41570778162467

Epoch: 5| Step: 7
Training loss: 2.8267283494834947
Validation loss: 2.4141830570606926

Epoch: 5| Step: 8
Training loss: 1.9329831787340517
Validation loss: 2.4255169628774014

Epoch: 5| Step: 9
Training loss: 2.4230274042838227
Validation loss: 2.406553554791556

Epoch: 5| Step: 10
Training loss: 2.0433931511632673
Validation loss: 2.421475473900279

Epoch: 5| Step: 11
Training loss: 3.0012172772499612
Validation loss: 2.4455513578519517

Epoch: 55| Step: 0
Training loss: 2.052826709648774
Validation loss: 2.437878864547039

Epoch: 5| Step: 1
Training loss: 1.9953890338459872
Validation loss: 2.432607807195958

Epoch: 5| Step: 2
Training loss: 2.3419439859769
Validation loss: 2.4408904891410943

Epoch: 5| Step: 3
Training loss: 2.302208242580547
Validation loss: 2.4634147185238806

Epoch: 5| Step: 4
Training loss: 2.7139870149418455
Validation loss: 2.4600742541648803

Epoch: 5| Step: 5
Training loss: 2.2099485308492337
Validation loss: 2.455140721249682

Epoch: 5| Step: 6
Training loss: 2.0857063765478503
Validation loss: 2.468567648321728

Epoch: 5| Step: 7
Training loss: 2.3564081801687418
Validation loss: 2.490735883888907

Epoch: 5| Step: 8
Training loss: 2.499235036164308
Validation loss: 2.482440791344371

Epoch: 5| Step: 9
Training loss: 2.521785892391868
Validation loss: 2.458391764048777

Epoch: 5| Step: 10
Training loss: 2.167697648977272
Validation loss: 2.4419826956189747

Epoch: 5| Step: 11
Training loss: 2.4819884923626665
Validation loss: 2.4276890012634325

Epoch: 56| Step: 0
Training loss: 2.4236095492829466
Validation loss: 2.438873600899793

Epoch: 5| Step: 1
Training loss: 2.451745489717499
Validation loss: 2.4094639530410453

Epoch: 5| Step: 2
Training loss: 2.5413411875293535
Validation loss: 2.4224594108414546

Epoch: 5| Step: 3
Training loss: 2.130009076811027
Validation loss: 2.422751799167911

Epoch: 5| Step: 4
Training loss: 2.261394681756647
Validation loss: 2.4204726147950693

Epoch: 5| Step: 5
Training loss: 1.9127905531435774
Validation loss: 2.414595720974137

Epoch: 5| Step: 6
Training loss: 2.234254633722519
Validation loss: 2.41345207537601

Epoch: 5| Step: 7
Training loss: 2.268056998012645
Validation loss: 2.433791449013767

Epoch: 5| Step: 8
Training loss: 2.3628635510258738
Validation loss: 2.4010274511538454

Epoch: 5| Step: 9
Training loss: 2.631195477353434
Validation loss: 2.4032238947771516

Epoch: 5| Step: 10
Training loss: 2.1076161150999844
Validation loss: 2.4188528955736976

Epoch: 5| Step: 11
Training loss: 1.35008803186556
Validation loss: 2.4340694140200037

Epoch: 57| Step: 0
Training loss: 1.8663830161295212
Validation loss: 2.455047166174435

Epoch: 5| Step: 1
Training loss: 2.007566444371008
Validation loss: 2.437377979615258

Epoch: 5| Step: 2
Training loss: 2.0880358710587625
Validation loss: 2.4710626513984284

Epoch: 5| Step: 3
Training loss: 2.1019403621369053
Validation loss: 2.4803803435663463

Epoch: 5| Step: 4
Training loss: 2.4759984863350577
Validation loss: 2.5163759646823247

Epoch: 5| Step: 5
Training loss: 2.2745118634041805
Validation loss: 2.507432764285934

Epoch: 5| Step: 6
Training loss: 2.878479717650329
Validation loss: 2.518165210173389

Epoch: 5| Step: 7
Training loss: 2.815283182376625
Validation loss: 2.4792620970420085

Epoch: 5| Step: 8
Training loss: 2.076316333241646
Validation loss: 2.460810158477577

Epoch: 5| Step: 9
Training loss: 1.9150794616826519
Validation loss: 2.4422286293957938

Epoch: 5| Step: 10
Training loss: 2.417702704908883
Validation loss: 2.454858515670774

Epoch: 5| Step: 11
Training loss: 3.5961781135722592
Validation loss: 2.4293763757768363

Epoch: 58| Step: 0
Training loss: 2.397589418655074
Validation loss: 2.4366838299205087

Epoch: 5| Step: 1
Training loss: 2.0412019343419883
Validation loss: 2.409229935213672

Epoch: 5| Step: 2
Training loss: 2.5309822977050604
Validation loss: 2.410065478692432

Epoch: 5| Step: 3
Training loss: 2.1948232954148503
Validation loss: 2.4047458868806197

Epoch: 5| Step: 4
Training loss: 2.2654105249372756
Validation loss: 2.4217940245186345

Epoch: 5| Step: 5
Training loss: 2.07362463537111
Validation loss: 2.407042868145691

Epoch: 5| Step: 6
Training loss: 2.1085501859616125
Validation loss: 2.4122064774256775

Epoch: 5| Step: 7
Training loss: 2.5974126486459927
Validation loss: 2.425652644402794

Epoch: 5| Step: 8
Training loss: 2.389503565030293
Validation loss: 2.428143672143076

Epoch: 5| Step: 9
Training loss: 2.5099003262125716
Validation loss: 2.418029665243844

Epoch: 5| Step: 10
Training loss: 2.1398122316499526
Validation loss: 2.4175745283708125

Epoch: 5| Step: 11
Training loss: 1.7075240691738027
Validation loss: 2.43296825928712

Epoch: 59| Step: 0
Training loss: 2.0419375441038827
Validation loss: 2.4304722114684663

Epoch: 5| Step: 1
Training loss: 2.118457596218319
Validation loss: 2.4284604890211634

Epoch: 5| Step: 2
Training loss: 2.5857678498920116
Validation loss: 2.4326627572129187

Epoch: 5| Step: 3
Training loss: 1.853924496155404
Validation loss: 2.42588580689921

Epoch: 5| Step: 4
Training loss: 2.8178061552336953
Validation loss: 2.4329918841192537

Epoch: 5| Step: 5
Training loss: 1.8787727546456046
Validation loss: 2.439877341091429

Epoch: 5| Step: 6
Training loss: 1.8808560158450986
Validation loss: 2.4488212003218

Epoch: 5| Step: 7
Training loss: 2.4048940628099658
Validation loss: 2.4190403500346

Epoch: 5| Step: 8
Training loss: 2.5724999300082745
Validation loss: 2.449659957773086

Epoch: 5| Step: 9
Training loss: 2.3434832611886076
Validation loss: 2.4740602826979896

Epoch: 5| Step: 10
Training loss: 2.574260798155732
Validation loss: 2.4593785590889694

Epoch: 5| Step: 11
Training loss: 0.8676311973061361
Validation loss: 2.4863636127185784

Epoch: 60| Step: 0
Training loss: 2.1326002078197455
Validation loss: 2.4565575875423757

Epoch: 5| Step: 1
Training loss: 2.4151363021580603
Validation loss: 2.4575959139501444

Epoch: 5| Step: 2
Training loss: 1.8957485417558246
Validation loss: 2.4738618383495177

Epoch: 5| Step: 3
Training loss: 2.45912874144944
Validation loss: 2.4515688023872158

Epoch: 5| Step: 4
Training loss: 1.6821356387065924
Validation loss: 2.4585883680425535

Epoch: 5| Step: 5
Training loss: 1.831288136160004
Validation loss: 2.4629461134473924

Epoch: 5| Step: 6
Training loss: 2.608601072746114
Validation loss: 2.4748366687325816

Epoch: 5| Step: 7
Training loss: 2.8881817363820104
Validation loss: 2.4426606925325793

Epoch: 5| Step: 8
Training loss: 2.109470167485714
Validation loss: 2.432304279504349

Epoch: 5| Step: 9
Training loss: 2.625768458191376
Validation loss: 2.4524412518372634

Epoch: 5| Step: 10
Training loss: 2.319764557434377
Validation loss: 2.42279547150157

Epoch: 5| Step: 11
Training loss: 1.6550195549907358
Validation loss: 2.4122483042297453

Epoch: 61| Step: 0
Training loss: 1.9777335214961496
Validation loss: 2.4232841535004757

Epoch: 5| Step: 1
Training loss: 2.1879190316081836
Validation loss: 2.4045417489474072

Epoch: 5| Step: 2
Training loss: 2.2854862333528634
Validation loss: 2.4022242736052863

Epoch: 5| Step: 3
Training loss: 2.138899058638447
Validation loss: 2.4144010296171503

Epoch: 5| Step: 4
Training loss: 2.394356402287838
Validation loss: 2.4215326497926872

Epoch: 5| Step: 5
Training loss: 2.459256230628631
Validation loss: 2.4152144262863886

Epoch: 5| Step: 6
Training loss: 2.10426593458232
Validation loss: 2.419509142309791

Epoch: 5| Step: 7
Training loss: 2.0819507461643623
Validation loss: 2.438988603966863

Epoch: 5| Step: 8
Training loss: 2.00364817245766
Validation loss: 2.4265904901695197

Epoch: 5| Step: 9
Training loss: 2.9398498875708254
Validation loss: 2.4312230866224755

Epoch: 5| Step: 10
Training loss: 2.42895585111007
Validation loss: 2.4313870013028094

Epoch: 5| Step: 11
Training loss: 2.4755833371842852
Validation loss: 2.457127959870542

Epoch: 62| Step: 0
Training loss: 1.9893620819046296
Validation loss: 2.427877534965927

Epoch: 5| Step: 1
Training loss: 2.474968526620828
Validation loss: 2.4090368473100594

Epoch: 5| Step: 2
Training loss: 2.205328090072604
Validation loss: 2.4184245767103096

Epoch: 5| Step: 3
Training loss: 2.249663751696467
Validation loss: 2.4159216486037014

Epoch: 5| Step: 4
Training loss: 2.0517014537044753
Validation loss: 2.4271349035086125

Epoch: 5| Step: 5
Training loss: 1.8869950307427876
Validation loss: 2.4150849268705428

Epoch: 5| Step: 6
Training loss: 2.371895015265208
Validation loss: 2.407475638254774

Epoch: 5| Step: 7
Training loss: 2.1216833373576267
Validation loss: 2.4047389673744757

Epoch: 5| Step: 8
Training loss: 2.6643765172164358
Validation loss: 2.411566805339518

Epoch: 5| Step: 9
Training loss: 2.6702504712752515
Validation loss: 2.4150830799723626

Epoch: 5| Step: 10
Training loss: 2.1404856615590977
Validation loss: 2.4149416338144443

Epoch: 5| Step: 11
Training loss: 2.499993705741588
Validation loss: 2.423802726339981

Epoch: 63| Step: 0
Training loss: 2.432639729484577
Validation loss: 2.413281161002745

Epoch: 5| Step: 1
Training loss: 2.5346032055183367
Validation loss: 2.4331780390360556

Epoch: 5| Step: 2
Training loss: 2.7032983095916125
Validation loss: 2.4492782492257605

Epoch: 5| Step: 3
Training loss: 2.1404892258848562
Validation loss: 2.4695316558068425

Epoch: 5| Step: 4
Training loss: 2.543470201405118
Validation loss: 2.452092724968214

Epoch: 5| Step: 5
Training loss: 1.95195796432338
Validation loss: 2.46191417548323

Epoch: 5| Step: 6
Training loss: 2.0080271802787633
Validation loss: 2.4697110140527117

Epoch: 5| Step: 7
Training loss: 2.0690382004719505
Validation loss: 2.4530230903920187

Epoch: 5| Step: 8
Training loss: 2.3895998483323826
Validation loss: 2.459647204705918

Epoch: 5| Step: 9
Training loss: 1.7284809346139323
Validation loss: 2.450323428649493

Epoch: 5| Step: 10
Training loss: 2.2017928620912897
Validation loss: 2.434415173474547

Epoch: 5| Step: 11
Training loss: 1.8125369627241965
Validation loss: 2.454800298969633

Epoch: 64| Step: 0
Training loss: 2.0761009053457027
Validation loss: 2.4059049433229585

Epoch: 5| Step: 1
Training loss: 1.6265153421827023
Validation loss: 2.4418298257229707

Epoch: 5| Step: 2
Training loss: 2.001004562815011
Validation loss: 2.4243714048787246

Epoch: 5| Step: 3
Training loss: 2.1359178900777755
Validation loss: 2.437265943228497

Epoch: 5| Step: 4
Training loss: 2.869478645953819
Validation loss: 2.4420934416982565

Epoch: 5| Step: 5
Training loss: 1.7761463869009828
Validation loss: 2.4369959595382853

Epoch: 5| Step: 6
Training loss: 2.570711423764574
Validation loss: 2.4029693305892965

Epoch: 5| Step: 7
Training loss: 1.8663767566801663
Validation loss: 2.430643619274111

Epoch: 5| Step: 8
Training loss: 2.410721031058426
Validation loss: 2.4288012901017293

Epoch: 5| Step: 9
Training loss: 2.6892223605439294
Validation loss: 2.4032849667422447

Epoch: 5| Step: 10
Training loss: 2.285175551634563
Validation loss: 2.4123373111823656

Epoch: 5| Step: 11
Training loss: 2.080788418559191
Validation loss: 2.413254957713472

Epoch: 65| Step: 0
Training loss: 1.7211183356608286
Validation loss: 2.425595889173594

Epoch: 5| Step: 1
Training loss: 2.088921059818401
Validation loss: 2.4396121948276708

Epoch: 5| Step: 2
Training loss: 2.409912294873391
Validation loss: 2.4566715626126507

Epoch: 5| Step: 3
Training loss: 2.301351220817639
Validation loss: 2.483250401432752

Epoch: 5| Step: 4
Training loss: 2.49217094965973
Validation loss: 2.482009653380303

Epoch: 5| Step: 5
Training loss: 2.213341258831465
Validation loss: 2.509820300742368

Epoch: 5| Step: 6
Training loss: 2.015510851562783
Validation loss: 2.485851924469505

Epoch: 5| Step: 7
Training loss: 2.1751128288030674
Validation loss: 2.482616133833835

Epoch: 5| Step: 8
Training loss: 2.045633070312394
Validation loss: 2.4563411841320333

Epoch: 5| Step: 9
Training loss: 2.6327659534901566
Validation loss: 2.4480746211501505

Epoch: 5| Step: 10
Training loss: 2.659930562712062
Validation loss: 2.4433441405579908

Epoch: 5| Step: 11
Training loss: 1.8188149509433735
Validation loss: 2.4261351453680478

Epoch: 66| Step: 0
Training loss: 2.3450810022740285
Validation loss: 2.421428955185666

Epoch: 5| Step: 1
Training loss: 1.9471043679703681
Validation loss: 2.418479267759817

Epoch: 5| Step: 2
Training loss: 2.2280040692098773
Validation loss: 2.434621178679263

Epoch: 5| Step: 3
Training loss: 2.164203074602778
Validation loss: 2.409922348864821

Epoch: 5| Step: 4
Training loss: 2.550107998524412
Validation loss: 2.4247368997558936

Epoch: 5| Step: 5
Training loss: 2.280307104609598
Validation loss: 2.437311743940977

Epoch: 5| Step: 6
Training loss: 2.2784142832501213
Validation loss: 2.421474794936138

Epoch: 5| Step: 7
Training loss: 2.655132462525116
Validation loss: 2.399860392838005

Epoch: 5| Step: 8
Training loss: 2.2706049416388736
Validation loss: 2.438694962597902

Epoch: 5| Step: 9
Training loss: 1.9448008036658486
Validation loss: 2.3957924687314396

Epoch: 5| Step: 10
Training loss: 1.940815519112181
Validation loss: 2.4245416685762553

Epoch: 5| Step: 11
Training loss: 1.3135090990539138
Validation loss: 2.416310988483877

Epoch: 67| Step: 0
Training loss: 2.1720574391534706
Validation loss: 2.4166359502111856

Epoch: 5| Step: 1
Training loss: 1.8446644600410531
Validation loss: 2.428823397141401

Epoch: 5| Step: 2
Training loss: 3.2545565428188943
Validation loss: 2.427258474282206

Epoch: 5| Step: 3
Training loss: 2.1024916626246704
Validation loss: 2.4100831987798563

Epoch: 5| Step: 4
Training loss: 1.9560520059735738
Validation loss: 2.4224810877607323

Epoch: 5| Step: 5
Training loss: 1.8112937596565477
Validation loss: 2.423247336152105

Epoch: 5| Step: 6
Training loss: 2.253607507010548
Validation loss: 2.43077139887561

Epoch: 5| Step: 7
Training loss: 1.7705195953094894
Validation loss: 2.4331543363966035

Epoch: 5| Step: 8
Training loss: 1.9753872841762832
Validation loss: 2.4229683325767506

Epoch: 5| Step: 9
Training loss: 2.4167436938232654
Validation loss: 2.4563633749424074

Epoch: 5| Step: 10
Training loss: 2.534981884712937
Validation loss: 2.462160853931549

Epoch: 5| Step: 11
Training loss: 2.0184979922190376
Validation loss: 2.4401625575702863

Epoch: 68| Step: 0
Training loss: 2.490323891620237
Validation loss: 2.4618740741811607

Epoch: 5| Step: 1
Training loss: 1.5187542259879638
Validation loss: 2.4501726279457263

Epoch: 5| Step: 2
Training loss: 2.198590420933325
Validation loss: 2.454294108356311

Epoch: 5| Step: 3
Training loss: 1.83909854254006
Validation loss: 2.4470332797269623

Epoch: 5| Step: 4
Training loss: 2.667827462829904
Validation loss: 2.4717584700672233

Epoch: 5| Step: 5
Training loss: 2.7041933451209865
Validation loss: 2.469886522202472

Epoch: 5| Step: 6
Training loss: 1.937329192477214
Validation loss: 2.4491191541589363

Epoch: 5| Step: 7
Training loss: 2.587822541115016
Validation loss: 2.439961356289554

Epoch: 5| Step: 8
Training loss: 2.2781106956252626
Validation loss: 2.4070483613099882

Epoch: 5| Step: 9
Training loss: 2.183500612077568
Validation loss: 2.4156371971306063

Epoch: 5| Step: 10
Training loss: 1.9209023472213325
Validation loss: 2.4091176742903904

Epoch: 5| Step: 11
Training loss: 1.9633250500688324
Validation loss: 2.4173869068211453

Epoch: 69| Step: 0
Training loss: 2.359034936915443
Validation loss: 2.4023844128814043

Epoch: 5| Step: 1
Training loss: 2.069067238630991
Validation loss: 2.4048434353397106

Epoch: 5| Step: 2
Training loss: 2.06313741833342
Validation loss: 2.445537333364489

Epoch: 5| Step: 3
Training loss: 2.3334762211600184
Validation loss: 2.413869284229637

Epoch: 5| Step: 4
Training loss: 2.4777116004971274
Validation loss: 2.417969793546469

Epoch: 5| Step: 5
Training loss: 1.8015516375092624
Validation loss: 2.415293210081267

Epoch: 5| Step: 6
Training loss: 1.8720286667658472
Validation loss: 2.4411013461134803

Epoch: 5| Step: 7
Training loss: 2.4971908044966247
Validation loss: 2.4291172196495885

Epoch: 5| Step: 8
Training loss: 2.427623301241507
Validation loss: 2.444561242675146

Epoch: 5| Step: 9
Training loss: 2.247614973986662
Validation loss: 2.441210311147728

Epoch: 5| Step: 10
Training loss: 2.2971697767370824
Validation loss: 2.445968698322356

Epoch: 5| Step: 11
Training loss: 0.9748241669488081
Validation loss: 2.4417117525327834

Epoch: 70| Step: 0
Training loss: 2.006768218519849
Validation loss: 2.4564045287194722

Epoch: 5| Step: 1
Training loss: 2.0283685053103544
Validation loss: 2.4567452665067093

Epoch: 5| Step: 2
Training loss: 2.5819305077087114
Validation loss: 2.459537677159123

Epoch: 5| Step: 3
Training loss: 2.1724498180216982
Validation loss: 2.4739675274059043

Epoch: 5| Step: 4
Training loss: 2.214649117881212
Validation loss: 2.4791506732029434

Epoch: 5| Step: 5
Training loss: 1.9250621884692134
Validation loss: 2.427867694446164

Epoch: 5| Step: 6
Training loss: 2.280329583924662
Validation loss: 2.4522548962849906

Epoch: 5| Step: 7
Training loss: 2.102559473600415
Validation loss: 2.4330062156978847

Epoch: 5| Step: 8
Training loss: 2.1995447164552666
Validation loss: 2.422531225658031

Epoch: 5| Step: 9
Training loss: 2.557659228934488
Validation loss: 2.4128656496477685

Epoch: 5| Step: 10
Training loss: 1.9407605454044012
Validation loss: 2.4112888994831594

Epoch: 5| Step: 11
Training loss: 2.851941227257832
Validation loss: 2.433274931457203

Epoch: 71| Step: 0
Training loss: 2.132205303799343
Validation loss: 2.4154159595272846

Epoch: 5| Step: 1
Training loss: 2.16297130410131
Validation loss: 2.416557156750806

Epoch: 5| Step: 2
Training loss: 2.8535769519312533
Validation loss: 2.4173389615043175

Epoch: 5| Step: 3
Training loss: 1.7817122545586404
Validation loss: 2.4223070928219603

Epoch: 5| Step: 4
Training loss: 2.1547110774110574
Validation loss: 2.42208719246889

Epoch: 5| Step: 5
Training loss: 1.620788030636868
Validation loss: 2.4217720830236127

Epoch: 5| Step: 6
Training loss: 2.2794804437848137
Validation loss: 2.42983294273493

Epoch: 5| Step: 7
Training loss: 2.1591139860608255
Validation loss: 2.4471733723327107

Epoch: 5| Step: 8
Training loss: 2.1563958381316892
Validation loss: 2.4383382048876534

Epoch: 5| Step: 9
Training loss: 2.606955863084435
Validation loss: 2.425208256978217

Epoch: 5| Step: 10
Training loss: 2.098603842612111
Validation loss: 2.4480625893678045

Epoch: 5| Step: 11
Training loss: 0.8853492411951838
Validation loss: 2.457984155301854

Epoch: 72| Step: 0
Training loss: 2.2830703996989863
Validation loss: 2.4564823736356476

Epoch: 5| Step: 1
Training loss: 2.34189308357027
Validation loss: 2.44793135997069

Epoch: 5| Step: 2
Training loss: 2.0869165758788095
Validation loss: 2.460789749715705

Epoch: 5| Step: 3
Training loss: 2.0844493801222987
Validation loss: 2.4163531635815865

Epoch: 5| Step: 4
Training loss: 1.596052488745036
Validation loss: 2.4329922270981896

Epoch: 5| Step: 5
Training loss: 2.111786205979868
Validation loss: 2.4309421909959004

Epoch: 5| Step: 6
Training loss: 2.2610650839196786
Validation loss: 2.446909122221

Epoch: 5| Step: 7
Training loss: 1.5760481359227596
Validation loss: 2.442990204761921

Epoch: 5| Step: 8
Training loss: 2.8823931629401565
Validation loss: 2.4212993183735754

Epoch: 5| Step: 9
Training loss: 2.5461100734340767
Validation loss: 2.4176509198416194

Epoch: 5| Step: 10
Training loss: 2.236351686045372
Validation loss: 2.412569306420695

Epoch: 5| Step: 11
Training loss: 1.6529715858043545
Validation loss: 2.402123407529745

Epoch: 73| Step: 0
Training loss: 2.2840136157363196
Validation loss: 2.4129944200810884

Epoch: 5| Step: 1
Training loss: 2.478641058931978
Validation loss: 2.408524173437342

Epoch: 5| Step: 2
Training loss: 2.3613709350441097
Validation loss: 2.42602980072889

Epoch: 5| Step: 3
Training loss: 1.7806179866204102
Validation loss: 2.4288061389432913

Epoch: 5| Step: 4
Training loss: 1.862788809075467
Validation loss: 2.437455046475601

Epoch: 5| Step: 5
Training loss: 2.1899041180110017
Validation loss: 2.4477850445742058

Epoch: 5| Step: 6
Training loss: 1.722554175711141
Validation loss: 2.450611337145157

Epoch: 5| Step: 7
Training loss: 1.7530063282993291
Validation loss: 2.4591042810302564

Epoch: 5| Step: 8
Training loss: 2.363849766974457
Validation loss: 2.4624927309254927

Epoch: 5| Step: 9
Training loss: 2.255053989922867
Validation loss: 2.4543940507333843

Epoch: 5| Step: 10
Training loss: 2.872489994519689
Validation loss: 2.460033476758107

Epoch: 5| Step: 11
Training loss: 1.3101954436652556
Validation loss: 2.4443349864925863

Epoch: 74| Step: 0
Training loss: 2.9622052782468726
Validation loss: 2.418451260034114

Epoch: 5| Step: 1
Training loss: 2.431936027017992
Validation loss: 2.3875556348473266

Epoch: 5| Step: 2
Training loss: 1.9806827226426924
Validation loss: 2.4095466910481935

Epoch: 5| Step: 3
Training loss: 2.5667326790713885
Validation loss: 2.4179295468374895

Epoch: 5| Step: 4
Training loss: 2.308127522388426
Validation loss: 2.404060903786928

Epoch: 5| Step: 5
Training loss: 2.0106059431667633
Validation loss: 2.390622045477743

Epoch: 5| Step: 6
Training loss: 2.3612382617697043
Validation loss: 2.4047837847658946

Epoch: 5| Step: 7
Training loss: 2.0637158364807533
Validation loss: 2.408016489453534

Epoch: 5| Step: 8
Training loss: 2.032151007725726
Validation loss: 2.4127792725475588

Epoch: 5| Step: 9
Training loss: 1.716334223115006
Validation loss: 2.4224677601280713

Epoch: 5| Step: 10
Training loss: 1.5128369988418109
Validation loss: 2.436127092618825

Epoch: 5| Step: 11
Training loss: 2.433583659094498
Validation loss: 2.467449698871113

Epoch: 75| Step: 0
Training loss: 1.8188806231282486
Validation loss: 2.477112120441567

Epoch: 5| Step: 1
Training loss: 1.701929635338247
Validation loss: 2.469293212681929

Epoch: 5| Step: 2
Training loss: 2.176361937911532
Validation loss: 2.4772551537660084

Epoch: 5| Step: 3
Training loss: 2.3523652490338445
Validation loss: 2.451516871598055

Epoch: 5| Step: 4
Training loss: 1.8376803303157607
Validation loss: 2.470378173849506

Epoch: 5| Step: 5
Training loss: 2.504965333527407
Validation loss: 2.4715336143910878

Epoch: 5| Step: 6
Training loss: 1.8572033293279104
Validation loss: 2.443219415410336

Epoch: 5| Step: 7
Training loss: 2.936153833885867
Validation loss: 2.441458672532888

Epoch: 5| Step: 8
Training loss: 2.0096806840954526
Validation loss: 2.4218977732254237

Epoch: 5| Step: 9
Training loss: 1.865306657119575
Validation loss: 2.4108872935617103

Epoch: 5| Step: 10
Training loss: 2.4857458015536116
Validation loss: 2.413565126638994

Epoch: 5| Step: 11
Training loss: 2.1091171672211906
Validation loss: 2.4086785962155774

Epoch: 76| Step: 0
Training loss: 2.171432450029308
Validation loss: 2.386921326176964

Epoch: 5| Step: 1
Training loss: 2.6620920002986748
Validation loss: 2.422642899875953

Epoch: 5| Step: 2
Training loss: 2.0076559874096302
Validation loss: 2.4316912378970112

Epoch: 5| Step: 3
Training loss: 2.44045626048458
Validation loss: 2.4225361280565347

Epoch: 5| Step: 4
Training loss: 2.2846840916794586
Validation loss: 2.431931627624548

Epoch: 5| Step: 5
Training loss: 2.245817747987965
Validation loss: 2.4187194447719023

Epoch: 5| Step: 6
Training loss: 2.1728419065796687
Validation loss: 2.3968140225899717

Epoch: 5| Step: 7
Training loss: 1.854811381289848
Validation loss: 2.409221548297399

Epoch: 5| Step: 8
Training loss: 2.0129956979568226
Validation loss: 2.4025990999142053

Epoch: 5| Step: 9
Training loss: 2.08966371705555
Validation loss: 2.4184458174157673

Epoch: 5| Step: 10
Training loss: 2.439607442795883
Validation loss: 2.4175762377647505

Epoch: 5| Step: 11
Training loss: 1.937377987373048
Validation loss: 2.432121872676351

Epoch: 77| Step: 0
Training loss: 2.0350012546319864
Validation loss: 2.459266078852333

Epoch: 5| Step: 1
Training loss: 1.962067054567053
Validation loss: 2.456568336242102

Epoch: 5| Step: 2
Training loss: 2.620098078398915
Validation loss: 2.5019755187510215

Epoch: 5| Step: 3
Training loss: 2.0736962646365376
Validation loss: 2.5210745567313846

Epoch: 5| Step: 4
Training loss: 2.095183152452734
Validation loss: 2.507212049036072

Epoch: 5| Step: 5
Training loss: 2.5270378010152537
Validation loss: 2.4726926249499743

Epoch: 5| Step: 6
Training loss: 2.2583476029774565
Validation loss: 2.501957345681523

Epoch: 5| Step: 7
Training loss: 1.7986359964790541
Validation loss: 2.479744059913777

Epoch: 5| Step: 8
Training loss: 2.1589032862788495
Validation loss: 2.4510774591709907

Epoch: 5| Step: 9
Training loss: 2.430116180185721
Validation loss: 2.4627292347242564

Epoch: 5| Step: 10
Training loss: 1.8787308133199516
Validation loss: 2.4320175552840375

Epoch: 5| Step: 11
Training loss: 1.5829966672379092
Validation loss: 2.4079266482523294

Epoch: 78| Step: 0
Training loss: 1.8775915038748374
Validation loss: 2.4138739264289955

Epoch: 5| Step: 1
Training loss: 2.2624090060487814
Validation loss: 2.395101474159922

Epoch: 5| Step: 2
Training loss: 2.3827422585061924
Validation loss: 2.410226207770961

Epoch: 5| Step: 3
Training loss: 1.8366396596114907
Validation loss: 2.4049884122872043

Epoch: 5| Step: 4
Training loss: 2.5144109224905726
Validation loss: 2.404846651223695

Epoch: 5| Step: 5
Training loss: 2.40862513647624
Validation loss: 2.421898191607605

Epoch: 5| Step: 6
Training loss: 1.8296542821877255
Validation loss: 2.4084973265131695

Epoch: 5| Step: 7
Training loss: 1.6000641303323275
Validation loss: 2.4031946014259424

Epoch: 5| Step: 8
Training loss: 2.5479529036416717
Validation loss: 2.4132974023300036

Epoch: 5| Step: 9
Training loss: 2.112942878301283
Validation loss: 2.409662823734376

Epoch: 5| Step: 10
Training loss: 2.02743712340671
Validation loss: 2.4246917751579553

Epoch: 5| Step: 11
Training loss: 2.8891427853674387
Validation loss: 2.464052160866671

Epoch: 79| Step: 0
Training loss: 2.0081657366118724
Validation loss: 2.4395486646502325

Epoch: 5| Step: 1
Training loss: 2.0667776195931964
Validation loss: 2.423711748836159

Epoch: 5| Step: 2
Training loss: 1.9864882983178225
Validation loss: 2.465385494356385

Epoch: 5| Step: 3
Training loss: 2.219013359665677
Validation loss: 2.442107638507305

Epoch: 5| Step: 4
Training loss: 2.123786804347325
Validation loss: 2.4324261848015785

Epoch: 5| Step: 5
Training loss: 2.064145096794636
Validation loss: 2.3962714762115813

Epoch: 5| Step: 6
Training loss: 1.8505329859261446
Validation loss: 2.42983671018444

Epoch: 5| Step: 7
Training loss: 2.1532894210156606
Validation loss: 2.4226266084358663

Epoch: 5| Step: 8
Training loss: 2.3938311849427465
Validation loss: 2.4261334010582516

Epoch: 5| Step: 9
Training loss: 2.332338552499212
Validation loss: 2.4035955336333767

Epoch: 5| Step: 10
Training loss: 1.9682157487925875
Validation loss: 2.40380138639188

Epoch: 5| Step: 11
Training loss: 2.8690056713921757
Validation loss: 2.4072509145375434

Epoch: 80| Step: 0
Training loss: 1.9008691230402626
Validation loss: 2.410100531281777

Epoch: 5| Step: 1
Training loss: 2.418542846167663
Validation loss: 2.403987200389265

Epoch: 5| Step: 2
Training loss: 2.444943043644129
Validation loss: 2.4031786307876555

Epoch: 5| Step: 3
Training loss: 1.7873566336592204
Validation loss: 2.402705819155558

Epoch: 5| Step: 4
Training loss: 2.142573673935668
Validation loss: 2.4259023671978617

Epoch: 5| Step: 5
Training loss: 2.084776480240675
Validation loss: 2.446850858482379

Epoch: 5| Step: 6
Training loss: 1.725383718630938
Validation loss: 2.433067415896661

Epoch: 5| Step: 7
Training loss: 1.7513487931348353
Validation loss: 2.433936673042166

Epoch: 5| Step: 8
Training loss: 2.393430273152453
Validation loss: 2.460045575175894

Epoch: 5| Step: 9
Training loss: 1.8321393922556846
Validation loss: 2.4410557121395207

Epoch: 5| Step: 10
Training loss: 2.5380844345176388
Validation loss: 2.4737260823236467

Epoch: 5| Step: 11
Training loss: 3.115807096158816
Validation loss: 2.4271431221098876

Epoch: 81| Step: 0
Training loss: 1.898344249554407
Validation loss: 2.4263882412539908

Epoch: 5| Step: 1
Training loss: 1.774884209415613
Validation loss: 2.4203341884310317

Epoch: 5| Step: 2
Training loss: 1.679394434712447
Validation loss: 2.4305798894178774

Epoch: 5| Step: 3
Training loss: 2.057857606200847
Validation loss: 2.4396263409240637

Epoch: 5| Step: 4
Training loss: 2.629767130996401
Validation loss: 2.4600411957655117

Epoch: 5| Step: 5
Training loss: 1.5115833468258524
Validation loss: 2.421029878643494

Epoch: 5| Step: 6
Training loss: 2.536848493852504
Validation loss: 2.4304154257267343

Epoch: 5| Step: 7
Training loss: 1.8528982889018768
Validation loss: 2.43317484426606

Epoch: 5| Step: 8
Training loss: 2.0553715368616485
Validation loss: 2.417204315432825

Epoch: 5| Step: 9
Training loss: 2.323344705828395
Validation loss: 2.439042257582971

Epoch: 5| Step: 10
Training loss: 2.4212521644310834
Validation loss: 2.4225481471948274

Epoch: 5| Step: 11
Training loss: 2.611146519693667
Validation loss: 2.415226965151534

Epoch: 82| Step: 0
Training loss: 1.6692638506175457
Validation loss: 2.412565732300921

Epoch: 5| Step: 1
Training loss: 1.8558257391982227
Validation loss: 2.3995882477477877

Epoch: 5| Step: 2
Training loss: 1.892706615704051
Validation loss: 2.411103825364651

Epoch: 5| Step: 3
Training loss: 1.6224175988008394
Validation loss: 2.3982955319017067

Epoch: 5| Step: 4
Training loss: 2.0838239727837715
Validation loss: 2.412144698529154

Epoch: 5| Step: 5
Training loss: 2.514113451890071
Validation loss: 2.4189895258284206

Epoch: 5| Step: 6
Training loss: 1.9857110759556265
Validation loss: 2.391893183440797

Epoch: 5| Step: 7
Training loss: 2.4121929941857325
Validation loss: 2.4126984158884066

Epoch: 5| Step: 8
Training loss: 2.0087512007628425
Validation loss: 2.4121992333852407

Epoch: 5| Step: 9
Training loss: 2.1379437883800754
Validation loss: 2.461796113250038

Epoch: 5| Step: 10
Training loss: 2.455744614186789
Validation loss: 2.4443871734935048

Epoch: 5| Step: 11
Training loss: 2.8667904945361786
Validation loss: 2.4798908952265477

Epoch: 83| Step: 0
Training loss: 2.3680943933050953
Validation loss: 2.4620452042942946

Epoch: 5| Step: 1
Training loss: 1.4309340082356323
Validation loss: 2.467518853582869

Epoch: 5| Step: 2
Training loss: 2.355786759148127
Validation loss: 2.462404467816092

Epoch: 5| Step: 3
Training loss: 1.796815954150452
Validation loss: 2.4771376703033288

Epoch: 5| Step: 4
Training loss: 2.1398784143008505
Validation loss: 2.498472724747352

Epoch: 5| Step: 5
Training loss: 1.6740975980940704
Validation loss: 2.471011196626475

Epoch: 5| Step: 6
Training loss: 1.5875375127490299
Validation loss: 2.4798071391924563

Epoch: 5| Step: 7
Training loss: 2.1762873336683515
Validation loss: 2.4606802629319815

Epoch: 5| Step: 8
Training loss: 2.4233577004335305
Validation loss: 2.4582971042183317

Epoch: 5| Step: 9
Training loss: 2.425735940064712
Validation loss: 2.4374101817871114

Epoch: 5| Step: 10
Training loss: 2.5388192867288732
Validation loss: 2.4128384413697934

Epoch: 5| Step: 11
Training loss: 0.9048599895692518
Validation loss: 2.413083389221188

Epoch: 84| Step: 0
Training loss: 2.317837406521974
Validation loss: 2.4269508167376417

Epoch: 5| Step: 1
Training loss: 2.091160325648983
Validation loss: 2.403267124191472

Epoch: 5| Step: 2
Training loss: 1.5749656855160301
Validation loss: 2.4190961954726578

Epoch: 5| Step: 3
Training loss: 1.7983493229836038
Validation loss: 2.403511962524117

Epoch: 5| Step: 4
Training loss: 1.860610999893039
Validation loss: 2.4074688215009505

Epoch: 5| Step: 5
Training loss: 2.124813071612285
Validation loss: 2.3951997990481195

Epoch: 5| Step: 6
Training loss: 2.37778771072563
Validation loss: 2.4362787300922424

Epoch: 5| Step: 7
Training loss: 1.8988035500605143
Validation loss: 2.4359457163073697

Epoch: 5| Step: 8
Training loss: 2.0938449667274655
Validation loss: 2.4374838445405205

Epoch: 5| Step: 9
Training loss: 2.4810457774947268
Validation loss: 2.446944028644765

Epoch: 5| Step: 10
Training loss: 1.9164998631525825
Validation loss: 2.4326755348741558

Epoch: 5| Step: 11
Training loss: 2.4548696157789833
Validation loss: 2.457718899014238

Epoch: 85| Step: 0
Training loss: 1.7693486740541553
Validation loss: 2.4442048087808965

Epoch: 5| Step: 1
Training loss: 2.246144063634844
Validation loss: 2.4577101642299697

Epoch: 5| Step: 2
Training loss: 2.235553244062273
Validation loss: 2.4022591718139403

Epoch: 5| Step: 3
Training loss: 1.616278425115706
Validation loss: 2.4129901796487063

Epoch: 5| Step: 4
Training loss: 2.230677713469799
Validation loss: 2.436353570779642

Epoch: 5| Step: 5
Training loss: 2.1278987635430835
Validation loss: 2.407936151519965

Epoch: 5| Step: 6
Training loss: 2.5953305495872954
Validation loss: 2.4045707119050976

Epoch: 5| Step: 7
Training loss: 1.9620170509266301
Validation loss: 2.4096395143673126

Epoch: 5| Step: 8
Training loss: 2.338125371660184
Validation loss: 2.412881202096785

Epoch: 5| Step: 9
Training loss: 2.221214752175206
Validation loss: 2.400084854486907

Epoch: 5| Step: 10
Training loss: 1.3888194331710264
Validation loss: 2.4111517463436116

Epoch: 5| Step: 11
Training loss: 1.903483775729794
Validation loss: 2.430096778865485

Epoch: 86| Step: 0
Training loss: 2.4823997850733326
Validation loss: 2.4569017813837095

Epoch: 5| Step: 1
Training loss: 1.8733142904533266
Validation loss: 2.477137788607679

Epoch: 5| Step: 2
Training loss: 1.8597052785709167
Validation loss: 2.5489908841175763

Epoch: 5| Step: 3
Training loss: 1.857286193577149
Validation loss: 2.601428485736914

Epoch: 5| Step: 4
Training loss: 2.3563724637776
Validation loss: 2.6485250865515635

Epoch: 5| Step: 5
Training loss: 2.252327033545537
Validation loss: 2.614028401902028

Epoch: 5| Step: 6
Training loss: 2.377377975974669
Validation loss: 2.658295905637992

Epoch: 5| Step: 7
Training loss: 2.1044035926102245
Validation loss: 2.5814687969437067

Epoch: 5| Step: 8
Training loss: 2.3859165672877896
Validation loss: 2.478139188901441

Epoch: 5| Step: 9
Training loss: 1.6984058759705378
Validation loss: 2.441862851996204

Epoch: 5| Step: 10
Training loss: 1.9135917863285208
Validation loss: 2.414484219715243

Epoch: 5| Step: 11
Training loss: 1.8858430145033154
Validation loss: 2.404764385617787

Epoch: 87| Step: 0
Training loss: 2.242014595834963
Validation loss: 2.417197088425172

Epoch: 5| Step: 1
Training loss: 1.9553473684485905
Validation loss: 2.47136256648982

Epoch: 5| Step: 2
Training loss: 1.8603195227719997
Validation loss: 2.5022412068991304

Epoch: 5| Step: 3
Training loss: 2.047251426503426
Validation loss: 2.523342641576957

Epoch: 5| Step: 4
Training loss: 2.365428006273399
Validation loss: 2.531114311663026

Epoch: 5| Step: 5
Training loss: 2.4158493391833376
Validation loss: 2.526864935570028

Epoch: 5| Step: 6
Training loss: 2.8665524644799736
Validation loss: 2.4788203912552005

Epoch: 5| Step: 7
Training loss: 2.3553349344633383
Validation loss: 2.4593728738021867

Epoch: 5| Step: 8
Training loss: 2.0535618704816265
Validation loss: 2.4471728811426963

Epoch: 5| Step: 9
Training loss: 1.9768978030505409
Validation loss: 2.3966438180310057

Epoch: 5| Step: 10
Training loss: 2.5029023489350206
Validation loss: 2.407574439817491

Epoch: 5| Step: 11
Training loss: 0.9030734987985074
Validation loss: 2.457595392505593

Epoch: 88| Step: 0
Training loss: 2.0998085388823857
Validation loss: 2.542790142453443

Epoch: 5| Step: 1
Training loss: 1.941720979228359
Validation loss: 2.577076324884069

Epoch: 5| Step: 2
Training loss: 2.5908694530417926
Validation loss: 2.6351601597696344

Epoch: 5| Step: 3
Training loss: 2.3429290350905765
Validation loss: 2.672664306384651

Epoch: 5| Step: 4
Training loss: 2.3167545256203605
Validation loss: 2.6431408546364925

Epoch: 5| Step: 5
Training loss: 1.9653871668314247
Validation loss: 2.6081785478053363

Epoch: 5| Step: 6
Training loss: 2.055480339919458
Validation loss: 2.543113776630878

Epoch: 5| Step: 7
Training loss: 1.6384242965396152
Validation loss: 2.5432496821502895

Epoch: 5| Step: 8
Training loss: 2.0721458522688385
Validation loss: 2.4575003058484115

Epoch: 5| Step: 9
Training loss: 2.027302589072162
Validation loss: 2.451448462941788

Epoch: 5| Step: 10
Training loss: 2.0327455150407925
Validation loss: 2.438999920892864

Epoch: 5| Step: 11
Training loss: 2.5509075232850553
Validation loss: 2.4299224421011716

Epoch: 89| Step: 0
Training loss: 1.680151374105273
Validation loss: 2.3843300536432817

Epoch: 5| Step: 1
Training loss: 2.0085458566541297
Validation loss: 2.421390704473297

Epoch: 5| Step: 2
Training loss: 2.5911295879116736
Validation loss: 2.4206469919335274

Epoch: 5| Step: 3
Training loss: 2.2173360698191416
Validation loss: 2.443650746423445

Epoch: 5| Step: 4
Training loss: 2.396263504109665
Validation loss: 2.4311133736120527

Epoch: 5| Step: 5
Training loss: 1.9403289937740456
Validation loss: 2.4231579161631887

Epoch: 5| Step: 6
Training loss: 2.177876256588898
Validation loss: 2.418260880234321

Epoch: 5| Step: 7
Training loss: 2.4722726533391763
Validation loss: 2.442006902429931

Epoch: 5| Step: 8
Training loss: 1.8346841632836717
Validation loss: 2.4223798779328707

Epoch: 5| Step: 9
Training loss: 1.5955463832041394
Validation loss: 2.41163552349372

Epoch: 5| Step: 10
Training loss: 1.7197693316347318
Validation loss: 2.408847884436311

Epoch: 5| Step: 11
Training loss: 2.6037390599453616
Validation loss: 2.4206283437133043

Epoch: 90| Step: 0
Training loss: 1.678734655473446
Validation loss: 2.4394734618227765

Epoch: 5| Step: 1
Training loss: 2.028362040487659
Validation loss: 2.463694278729489

Epoch: 5| Step: 2
Training loss: 1.8624277139243568
Validation loss: 2.4913020658754554

Epoch: 5| Step: 3
Training loss: 2.534966460237454
Validation loss: 2.5283142852023763

Epoch: 5| Step: 4
Training loss: 2.156850316611944
Validation loss: 2.511930532905436

Epoch: 5| Step: 5
Training loss: 2.258323321255758
Validation loss: 2.5430968955977606

Epoch: 5| Step: 6
Training loss: 1.675079554476283
Validation loss: 2.504716207554328

Epoch: 5| Step: 7
Training loss: 2.2211545352890263
Validation loss: 2.513949207260787

Epoch: 5| Step: 8
Training loss: 2.3448837589824465
Validation loss: 2.5113884455037208

Epoch: 5| Step: 9
Training loss: 1.9826620924156557
Validation loss: 2.5253089169734624

Epoch: 5| Step: 10
Training loss: 1.7094445529993223
Validation loss: 2.4850376572944195

Epoch: 5| Step: 11
Training loss: 2.067180755212093
Validation loss: 2.4332430297499323

Epoch: 91| Step: 0
Training loss: 1.8852547282721273
Validation loss: 2.421319450730733

Epoch: 5| Step: 1
Training loss: 2.1370545843397997
Validation loss: 2.4318954109597426

Epoch: 5| Step: 2
Training loss: 2.0585823999776056
Validation loss: 2.4225623970341728

Epoch: 5| Step: 3
Training loss: 1.9530418683480044
Validation loss: 2.4207995375168987

Epoch: 5| Step: 4
Training loss: 2.179212949223633
Validation loss: 2.4226578708459967

Epoch: 5| Step: 5
Training loss: 2.4994187633043627
Validation loss: 2.43443346716451

Epoch: 5| Step: 6
Training loss: 2.494930467878971
Validation loss: 2.3875726253554816

Epoch: 5| Step: 7
Training loss: 1.9467383984300501
Validation loss: 2.4247773489382025

Epoch: 5| Step: 8
Training loss: 1.6632586046274673
Validation loss: 2.403199650746339

Epoch: 5| Step: 9
Training loss: 1.833647383176514
Validation loss: 2.415838257167343

Epoch: 5| Step: 10
Training loss: 2.176015515959342
Validation loss: 2.398767270540713

Epoch: 5| Step: 11
Training loss: 1.3607646810513034
Validation loss: 2.4252936527893034

Epoch: 92| Step: 0
Training loss: 2.0315923549005785
Validation loss: 2.4310489123555152

Epoch: 5| Step: 1
Training loss: 1.8350036193853538
Validation loss: 2.4219040304925654

Epoch: 5| Step: 2
Training loss: 2.2540088544263797
Validation loss: 2.461971804324906

Epoch: 5| Step: 3
Training loss: 2.514555899389549
Validation loss: 2.506424940889452

Epoch: 5| Step: 4
Training loss: 2.2448921505652955
Validation loss: 2.5010081920637055

Epoch: 5| Step: 5
Training loss: 1.86317056451086
Validation loss: 2.5056952692589696

Epoch: 5| Step: 6
Training loss: 1.769144045337311
Validation loss: 2.489968387136258

Epoch: 5| Step: 7
Training loss: 2.143774903266774
Validation loss: 2.45845501943381

Epoch: 5| Step: 8
Training loss: 1.3385414044371273
Validation loss: 2.443927167322435

Epoch: 5| Step: 9
Training loss: 2.165518260708826
Validation loss: 2.4087921931912146

Epoch: 5| Step: 10
Training loss: 2.1155826355877685
Validation loss: 2.410141073598537

Epoch: 5| Step: 11
Training loss: 1.967402345107266
Validation loss: 2.397483105631451

Epoch: 93| Step: 0
Training loss: 1.8973274910453302
Validation loss: 2.410853148637289

Epoch: 5| Step: 1
Training loss: 2.3550884388963387
Validation loss: 2.4199125604293745

Epoch: 5| Step: 2
Training loss: 1.7511022366273585
Validation loss: 2.4133944157932614

Epoch: 5| Step: 3
Training loss: 1.866796348812766
Validation loss: 2.4698506288047932

Epoch: 5| Step: 4
Training loss: 1.6131244426195732
Validation loss: 2.4464294636956456

Epoch: 5| Step: 5
Training loss: 1.9634582002608951
Validation loss: 2.4643133149895045

Epoch: 5| Step: 6
Training loss: 1.5706939992992952
Validation loss: 2.4914512662906696

Epoch: 5| Step: 7
Training loss: 2.2532450269667286
Validation loss: 2.4739501524672853

Epoch: 5| Step: 8
Training loss: 2.1571466544234275
Validation loss: 2.4777032489275927

Epoch: 5| Step: 9
Training loss: 2.0547782384758615
Validation loss: 2.472928651385898

Epoch: 5| Step: 10
Training loss: 2.3828551241705074
Validation loss: 2.459719533106289

Epoch: 5| Step: 11
Training loss: 1.975446846063676
Validation loss: 2.4169185866121703

Epoch: 94| Step: 0
Training loss: 1.7110370624436475
Validation loss: 2.4493661214569102

Epoch: 5| Step: 1
Training loss: 2.0933256715686968
Validation loss: 2.4382069349142546

Epoch: 5| Step: 2
Training loss: 1.5971774477372722
Validation loss: 2.4599800305990382

Epoch: 5| Step: 3
Training loss: 2.043947412131626
Validation loss: 2.4208723638499214

Epoch: 5| Step: 4
Training loss: 1.8913802852999224
Validation loss: 2.420069154573604

Epoch: 5| Step: 5
Training loss: 2.2631401378817455
Validation loss: 2.4111062253503572

Epoch: 5| Step: 6
Training loss: 2.0443279930595253
Validation loss: 2.4291775404379754

Epoch: 5| Step: 7
Training loss: 2.1381455143867405
Validation loss: 2.4191827350805104

Epoch: 5| Step: 8
Training loss: 1.6570490223292562
Validation loss: 2.447634333027303

Epoch: 5| Step: 9
Training loss: 2.4739045040230705
Validation loss: 2.4601006896616853

Epoch: 5| Step: 10
Training loss: 2.0203138122790354
Validation loss: 2.4450189497537744

Epoch: 5| Step: 11
Training loss: 1.1612011862885094
Validation loss: 2.443624878954274

Epoch: 95| Step: 0
Training loss: 1.6948422249925796
Validation loss: 2.4399933207985915

Epoch: 5| Step: 1
Training loss: 1.1714331238854234
Validation loss: 2.463927544554951

Epoch: 5| Step: 2
Training loss: 1.9007028634888354
Validation loss: 2.4797565789507052

Epoch: 5| Step: 3
Training loss: 1.610131613641469
Validation loss: 2.4467573416927713

Epoch: 5| Step: 4
Training loss: 2.012222967568385
Validation loss: 2.4893263334369298

Epoch: 5| Step: 5
Training loss: 1.9460189333285767
Validation loss: 2.519323406468774

Epoch: 5| Step: 6
Training loss: 2.2981945581104988
Validation loss: 2.4625328866986234

Epoch: 5| Step: 7
Training loss: 2.194122100311799
Validation loss: 2.4604753595199886

Epoch: 5| Step: 8
Training loss: 2.7313680627651067
Validation loss: 2.4242333322705836

Epoch: 5| Step: 9
Training loss: 2.1089239697921234
Validation loss: 2.400148760801272

Epoch: 5| Step: 10
Training loss: 1.784630362013999
Validation loss: 2.4360614570527814

Epoch: 5| Step: 11
Training loss: 2.5836479446637717
Validation loss: 2.4253569153507284

Epoch: 96| Step: 0
Training loss: 2.149779410467938
Validation loss: 2.410839505366277

Epoch: 5| Step: 1
Training loss: 1.6078331237004084
Validation loss: 2.4284990272161355

Epoch: 5| Step: 2
Training loss: 2.1691244807948653
Validation loss: 2.428692723415432

Epoch: 5| Step: 3
Training loss: 2.132382080467093
Validation loss: 2.4026310839338407

Epoch: 5| Step: 4
Training loss: 1.9823654091596583
Validation loss: 2.445061415841624

Epoch: 5| Step: 5
Training loss: 1.7887099805789655
Validation loss: 2.4219182410533064

Epoch: 5| Step: 6
Training loss: 2.3487078299804707
Validation loss: 2.4262612810286983

Epoch: 5| Step: 7
Training loss: 2.1820684302112885
Validation loss: 2.4383851139722355

Epoch: 5| Step: 8
Training loss: 1.6915272587928873
Validation loss: 2.441508070793408

Epoch: 5| Step: 9
Training loss: 2.1494577655569524
Validation loss: 2.451619016029538

Epoch: 5| Step: 10
Training loss: 1.74326978517807
Validation loss: 2.5007722218271176

Epoch: 5| Step: 11
Training loss: 1.0521715460831873
Validation loss: 2.505432707056766

Epoch: 97| Step: 0
Training loss: 2.210605124572154
Validation loss: 2.498237127396823

Epoch: 5| Step: 1
Training loss: 2.1821068903251377
Validation loss: 2.5118955823825933

Epoch: 5| Step: 2
Training loss: 1.4372018421948012
Validation loss: 2.4964966386654885

Epoch: 5| Step: 3
Training loss: 1.360969835635203
Validation loss: 2.469120999719773

Epoch: 5| Step: 4
Training loss: 1.9211220855919136
Validation loss: 2.4942146913608174

Epoch: 5| Step: 5
Training loss: 1.6013842227614525
Validation loss: 2.517422912248288

Epoch: 5| Step: 6
Training loss: 2.456687138997063
Validation loss: 2.49261006247792

Epoch: 5| Step: 7
Training loss: 1.9228529884096732
Validation loss: 2.489783775102797

Epoch: 5| Step: 8
Training loss: 2.2682545102466776
Validation loss: 2.4378780210430278

Epoch: 5| Step: 9
Training loss: 1.6870300203647286
Validation loss: 2.4547933101208796

Epoch: 5| Step: 10
Training loss: 2.1568989537339602
Validation loss: 2.459992593680452

Epoch: 5| Step: 11
Training loss: 2.09830798603693
Validation loss: 2.4221693659903227

Epoch: 98| Step: 0
Training loss: 2.0981362928371246
Validation loss: 2.4477757406589418

Epoch: 5| Step: 1
Training loss: 1.9228342655114927
Validation loss: 2.425253204025859

Epoch: 5| Step: 2
Training loss: 1.4064404252715264
Validation loss: 2.4356139907216123

Epoch: 5| Step: 3
Training loss: 2.1489445868191295
Validation loss: 2.443242697162254

Epoch: 5| Step: 4
Training loss: 1.9418586188571718
Validation loss: 2.4211039269360533

Epoch: 5| Step: 5
Training loss: 2.1040670793087743
Validation loss: 2.4353126998608237

Epoch: 5| Step: 6
Training loss: 2.1309376954843455
Validation loss: 2.4397311168042437

Epoch: 5| Step: 7
Training loss: 1.9549394038143637
Validation loss: 2.470278061802246

Epoch: 5| Step: 8
Training loss: 1.5856844695490317
Validation loss: 2.504996181051753

Epoch: 5| Step: 9
Training loss: 2.476297743451137
Validation loss: 2.5202718863513045

Epoch: 5| Step: 10
Training loss: 1.85868130093254
Validation loss: 2.5419914879677634

Epoch: 5| Step: 11
Training loss: 2.6666494210003466
Validation loss: 2.532674894648457

Epoch: 99| Step: 0
Training loss: 1.955791941387482
Validation loss: 2.5187713462802206

Epoch: 5| Step: 1
Training loss: 1.296676896372815
Validation loss: 2.461251988575631

Epoch: 5| Step: 2
Training loss: 2.0790183076185467
Validation loss: 2.462902878789546

Epoch: 5| Step: 3
Training loss: 1.6015199981260249
Validation loss: 2.464783641084278

Epoch: 5| Step: 4
Training loss: 2.237244583980984
Validation loss: 2.46314494115486

Epoch: 5| Step: 5
Training loss: 2.4084178522540287
Validation loss: 2.44788178899281

Epoch: 5| Step: 6
Training loss: 1.9361764632581917
Validation loss: 2.4912206952900724

Epoch: 5| Step: 7
Training loss: 2.047512624885659
Validation loss: 2.438833542332531

Epoch: 5| Step: 8
Training loss: 1.7806522638035263
Validation loss: 2.4543796538096836

Epoch: 5| Step: 9
Training loss: 1.927344811373118
Validation loss: 2.4383773325207247

Epoch: 5| Step: 10
Training loss: 1.7878938547796572
Validation loss: 2.4858293415088255

Epoch: 5| Step: 11
Training loss: 2.2430755239043383
Validation loss: 2.4318153083695706

Epoch: 100| Step: 0
Training loss: 1.6992649115946021
Validation loss: 2.4334636712658098

Epoch: 5| Step: 1
Training loss: 1.9961563369285384
Validation loss: 2.4447491233471212

Epoch: 5| Step: 2
Training loss: 1.7100626481163748
Validation loss: 2.494670010164176

Epoch: 5| Step: 3
Training loss: 1.8149833766711951
Validation loss: 2.5013453439959297

Epoch: 5| Step: 4
Training loss: 1.9959511901949774
Validation loss: 2.5421790026128237

Epoch: 5| Step: 5
Training loss: 1.7898588448815818
Validation loss: 2.5796997693865826

Epoch: 5| Step: 6
Training loss: 2.136113780295175
Validation loss: 2.555748288617075

Epoch: 5| Step: 7
Training loss: 2.417438208530971
Validation loss: 2.5503747176997975

Epoch: 5| Step: 8
Training loss: 2.005256064371209
Validation loss: 2.526963631346723

Epoch: 5| Step: 9
Training loss: 2.263286462316282
Validation loss: 2.4925383955569065

Epoch: 5| Step: 10
Training loss: 1.6135230818339605
Validation loss: 2.4899846090086224

Epoch: 5| Step: 11
Training loss: 0.8739053827612598
Validation loss: 2.4862070146517206

Epoch: 101| Step: 0
Training loss: 1.6452956065644697
Validation loss: 2.4665714884826646

Epoch: 5| Step: 1
Training loss: 2.157331333750461
Validation loss: 2.445856803627631

Epoch: 5| Step: 2
Training loss: 2.253553233937938
Validation loss: 2.4508833230281764

Epoch: 5| Step: 3
Training loss: 1.7800698637378247
Validation loss: 2.470337150317232

Epoch: 5| Step: 4
Training loss: 1.7480135951790146
Validation loss: 2.4320929498522124

Epoch: 5| Step: 5
Training loss: 1.9593527419972192
Validation loss: 2.456140082652542

Epoch: 5| Step: 6
Training loss: 2.016683374551126
Validation loss: 2.461748697915289

Epoch: 5| Step: 7
Training loss: 1.8562094404625202
Validation loss: 2.5118497791591823

Epoch: 5| Step: 8
Training loss: 1.4780266178609467
Validation loss: 2.52647612987722

Epoch: 5| Step: 9
Training loss: 2.1805385445851186
Validation loss: 2.553854492509455

Epoch: 5| Step: 10
Training loss: 1.994698531430934
Validation loss: 2.521565679041605

Epoch: 5| Step: 11
Training loss: 1.9551176358707354
Validation loss: 2.492656002034702

Epoch: 102| Step: 0
Training loss: 1.546338151964685
Validation loss: 2.522431471265237

Epoch: 5| Step: 1
Training loss: 1.6848185392296215
Validation loss: 2.496371236390341

Epoch: 5| Step: 2
Training loss: 1.4337399275674523
Validation loss: 2.538368744583326

Epoch: 5| Step: 3
Training loss: 1.653906982306389
Validation loss: 2.5106501800443093

Epoch: 5| Step: 4
Training loss: 2.0992648245635666
Validation loss: 2.502426743875363

Epoch: 5| Step: 5
Training loss: 1.5963620491102886
Validation loss: 2.509310048435735

Epoch: 5| Step: 6
Training loss: 2.128566217827568
Validation loss: 2.4996534107285933

Epoch: 5| Step: 7
Training loss: 1.5379914560514727
Validation loss: 2.4429525214000747

Epoch: 5| Step: 8
Training loss: 2.203126623274834
Validation loss: 2.485337792578863

Epoch: 5| Step: 9
Training loss: 2.243814868042446
Validation loss: 2.435900214127869

Epoch: 5| Step: 10
Training loss: 2.562666910829774
Validation loss: 2.4649285464605435

Epoch: 5| Step: 11
Training loss: 1.4265036229228996
Validation loss: 2.4441966678713

Epoch: 103| Step: 0
Training loss: 1.757168800326416
Validation loss: 2.4530009827578816

Epoch: 5| Step: 1
Training loss: 2.170511709783181
Validation loss: 2.460988426690736

Epoch: 5| Step: 2
Training loss: 1.6422852607759229
Validation loss: 2.5034660591182485

Epoch: 5| Step: 3
Training loss: 2.3931675772616603
Validation loss: 2.502270978380987

Epoch: 5| Step: 4
Training loss: 1.8892024970418342
Validation loss: 2.5143829225280543

Epoch: 5| Step: 5
Training loss: 2.100465168977202
Validation loss: 2.5015374343826693

Epoch: 5| Step: 6
Training loss: 2.0400438541485735
Validation loss: 2.509899934373619

Epoch: 5| Step: 7
Training loss: 1.8725337657252346
Validation loss: 2.5390367320782805

Epoch: 5| Step: 8
Training loss: 1.4896615103456468
Validation loss: 2.5080764825670343

Epoch: 5| Step: 9
Training loss: 1.7843543323716198
Validation loss: 2.502692675869537

Epoch: 5| Step: 10
Training loss: 1.6608379804307254
Validation loss: 2.4524153413882317

Epoch: 5| Step: 11
Training loss: 1.617478717622671
Validation loss: 2.4829700524011433

Epoch: 104| Step: 0
Training loss: 1.4333066730829114
Validation loss: 2.4380646239152823

Epoch: 5| Step: 1
Training loss: 2.002047325337092
Validation loss: 2.5011203004126026

Epoch: 5| Step: 2
Training loss: 2.05981443865655
Validation loss: 2.4915521523358737

Epoch: 5| Step: 3
Training loss: 1.995395605496946
Validation loss: 2.459239260729798

Epoch: 5| Step: 4
Training loss: 2.2084401182831472
Validation loss: 2.460575121483128

Epoch: 5| Step: 5
Training loss: 1.4165642458225198
Validation loss: 2.4701119903126108

Epoch: 5| Step: 6
Training loss: 1.7696833597788544
Validation loss: 2.4919396080850187

Epoch: 5| Step: 7
Training loss: 1.8635913902658616
Validation loss: 2.490985863683143

Epoch: 5| Step: 8
Training loss: 2.160007023270103
Validation loss: 2.483863542000073

Epoch: 5| Step: 9
Training loss: 1.1712690694227565
Validation loss: 2.494895540011537

Epoch: 5| Step: 10
Training loss: 2.353477332092523
Validation loss: 2.505049852498881

Epoch: 5| Step: 11
Training loss: 0.9079728029311956
Validation loss: 2.5087690222664767

Epoch: 105| Step: 0
Training loss: 1.7961736222436562
Validation loss: 2.4705113996216865

Epoch: 5| Step: 1
Training loss: 1.9938855881461561
Validation loss: 2.486268819185062

Epoch: 5| Step: 2
Training loss: 1.7413047298858975
Validation loss: 2.469542903162651

Epoch: 5| Step: 3
Training loss: 1.3990524048278061
Validation loss: 2.49854956115741

Epoch: 5| Step: 4
Training loss: 1.7078584460668156
Validation loss: 2.543295013624228

Epoch: 5| Step: 5
Training loss: 1.861462038872917
Validation loss: 2.498944089344598

Epoch: 5| Step: 6
Training loss: 2.1156011177191303
Validation loss: 2.4839886858821183

Epoch: 5| Step: 7
Training loss: 1.8514924498879781
Validation loss: 2.490203659765768

Epoch: 5| Step: 8
Training loss: 1.7864943149453774
Validation loss: 2.518838957863471

Epoch: 5| Step: 9
Training loss: 2.5817738922718716
Validation loss: 2.4802835570560338

Epoch: 5| Step: 10
Training loss: 1.618421737791544
Validation loss: 2.4601475007721425

Epoch: 5| Step: 11
Training loss: 2.0010177883594773
Validation loss: 2.471996428251644

Epoch: 106| Step: 0
Training loss: 1.9184256512489914
Validation loss: 2.458942803841228

Epoch: 5| Step: 1
Training loss: 1.9391013265283656
Validation loss: 2.4439607851289677

Epoch: 5| Step: 2
Training loss: 1.756527375822059
Validation loss: 2.4717879093933983

Epoch: 5| Step: 3
Training loss: 1.926826673032197
Validation loss: 2.4790244355527884

Epoch: 5| Step: 4
Training loss: 2.20099639870099
Validation loss: 2.460671708220253

Epoch: 5| Step: 5
Training loss: 2.496287736831909
Validation loss: 2.466885335327307

Epoch: 5| Step: 6
Training loss: 1.664773708465126
Validation loss: 2.4917798401467124

Epoch: 5| Step: 7
Training loss: 1.5650374598788281
Validation loss: 2.4757281441257812

Epoch: 5| Step: 8
Training loss: 1.5243411782904872
Validation loss: 2.4792892054452245

Epoch: 5| Step: 9
Training loss: 1.9286960417739665
Validation loss: 2.4833103613836363

Epoch: 5| Step: 10
Training loss: 1.2657582248222363
Validation loss: 2.4907566654785294

Epoch: 5| Step: 11
Training loss: 2.0156813029624265
Validation loss: 2.5169295606816404

Epoch: 107| Step: 0
Training loss: 1.7250474176938546
Validation loss: 2.5127645859334677

Epoch: 5| Step: 1
Training loss: 2.397354726517004
Validation loss: 2.535912928341738

Epoch: 5| Step: 2
Training loss: 1.435633650252538
Validation loss: 2.5585556920450974

Epoch: 5| Step: 3
Training loss: 1.424906757717317
Validation loss: 2.5196617427813477

Epoch: 5| Step: 4
Training loss: 1.711282912969517
Validation loss: 2.478238963344451

Epoch: 5| Step: 5
Training loss: 1.6469068607382682
Validation loss: 2.5007163293100922

Epoch: 5| Step: 6
Training loss: 2.116344776859048
Validation loss: 2.504206369141359

Epoch: 5| Step: 7
Training loss: 1.600808314945906
Validation loss: 2.5066805549775393

Epoch: 5| Step: 8
Training loss: 1.8889184611318102
Validation loss: 2.5045230480709257

Epoch: 5| Step: 9
Training loss: 2.2582836253571323
Validation loss: 2.508297014818414

Epoch: 5| Step: 10
Training loss: 2.022924173997908
Validation loss: 2.5055807607425695

Epoch: 5| Step: 11
Training loss: 1.295980535693646
Validation loss: 2.4903633852183957

Epoch: 108| Step: 0
Training loss: 2.2389693608847603
Validation loss: 2.536686858914731

Epoch: 5| Step: 1
Training loss: 1.748515180374061
Validation loss: 2.5156965146848087

Epoch: 5| Step: 2
Training loss: 1.8892190292543705
Validation loss: 2.5355655435773943

Epoch: 5| Step: 3
Training loss: 1.7914444171950443
Validation loss: 2.510752083041616

Epoch: 5| Step: 4
Training loss: 1.9888401407640903
Validation loss: 2.53572432154154

Epoch: 5| Step: 5
Training loss: 1.3903932699800041
Validation loss: 2.543357827169465

Epoch: 5| Step: 6
Training loss: 1.4494228990411642
Validation loss: 2.5510928950391363

Epoch: 5| Step: 7
Training loss: 2.0568368787313274
Validation loss: 2.5164809814271076

Epoch: 5| Step: 8
Training loss: 2.1421946318860354
Validation loss: 2.533635612594423

Epoch: 5| Step: 9
Training loss: 1.375443387069095
Validation loss: 2.521092079744435

Epoch: 5| Step: 10
Training loss: 2.0860805962446225
Validation loss: 2.4992692356191695

Epoch: 5| Step: 11
Training loss: 1.3462405522687073
Validation loss: 2.4812396195816717

Epoch: 109| Step: 0
Training loss: 2.1761576191742154
Validation loss: 2.472974181262966

Epoch: 5| Step: 1
Training loss: 1.9206264130636492
Validation loss: 2.473173022192391

Epoch: 5| Step: 2
Training loss: 1.1245556059607844
Validation loss: 2.456171298687294

Epoch: 5| Step: 3
Training loss: 1.5920652572828997
Validation loss: 2.5081415604210133

Epoch: 5| Step: 4
Training loss: 1.804092771618793
Validation loss: 2.498112096822369

Epoch: 5| Step: 5
Training loss: 2.249596135663041
Validation loss: 2.5478398693318876

Epoch: 5| Step: 6
Training loss: 2.032214126658851
Validation loss: 2.571848648943659

Epoch: 5| Step: 7
Training loss: 1.8049003178342329
Validation loss: 2.5416371364649883

Epoch: 5| Step: 8
Training loss: 1.8437340945834735
Validation loss: 2.5824204698338664

Epoch: 5| Step: 9
Training loss: 1.5406956406931827
Validation loss: 2.5679418188156213

Epoch: 5| Step: 10
Training loss: 1.9832366321401236
Validation loss: 2.5079139122507086

Epoch: 5| Step: 11
Training loss: 1.5893357423651016
Validation loss: 2.5056488134968946

Epoch: 110| Step: 0
Training loss: 1.6463205928048197
Validation loss: 2.5197801412818452

Epoch: 5| Step: 1
Training loss: 2.209903650556936
Validation loss: 2.5096949684894216

Epoch: 5| Step: 2
Training loss: 1.7711412124769448
Validation loss: 2.514356064079958

Epoch: 5| Step: 3
Training loss: 2.6939206275093848
Validation loss: 2.5013495180450094

Epoch: 5| Step: 4
Training loss: 1.4998338130443314
Validation loss: 2.464071446017303

Epoch: 5| Step: 5
Training loss: 1.1628977946097898
Validation loss: 2.467315957492223

Epoch: 5| Step: 6
Training loss: 1.6969592275492655
Validation loss: 2.470913779786246

Epoch: 5| Step: 7
Training loss: 1.739067671254876
Validation loss: 2.5135685944698976

Epoch: 5| Step: 8
Training loss: 1.5594553466157275
Validation loss: 2.5162594648689485

Epoch: 5| Step: 9
Training loss: 1.8171111021111976
Validation loss: 2.505442070449712

Epoch: 5| Step: 10
Training loss: 2.0118354837566597
Validation loss: 2.5803622046801427

Epoch: 5| Step: 11
Training loss: 1.4464794499835985
Validation loss: 2.582255832217795

Epoch: 111| Step: 0
Training loss: 1.6713474189936712
Validation loss: 2.5453170211967278

Epoch: 5| Step: 1
Training loss: 1.691201917891015
Validation loss: 2.5343998435449473

Epoch: 5| Step: 2
Training loss: 2.233522692761278
Validation loss: 2.5237829682475263

Epoch: 5| Step: 3
Training loss: 1.618835125897847
Validation loss: 2.474143382061708

Epoch: 5| Step: 4
Training loss: 1.736430419380194
Validation loss: 2.493457518422037

Epoch: 5| Step: 5
Training loss: 1.755876619553459
Validation loss: 2.500003166991453

Epoch: 5| Step: 6
Training loss: 1.7893318073523923
Validation loss: 2.494620734765316

Epoch: 5| Step: 7
Training loss: 1.8589965691660495
Validation loss: 2.463404233592466

Epoch: 5| Step: 8
Training loss: 1.4390520756081955
Validation loss: 2.492122374254684

Epoch: 5| Step: 9
Training loss: 1.701291418419244
Validation loss: 2.5163733630916667

Epoch: 5| Step: 10
Training loss: 2.2215069043388973
Validation loss: 2.485899583394297

Epoch: 5| Step: 11
Training loss: 2.5471727630110297
Validation loss: 2.540569761832361

Epoch: 112| Step: 0
Training loss: 1.8111812792813058
Validation loss: 2.506257890473246

Epoch: 5| Step: 1
Training loss: 1.5202542426149386
Validation loss: 2.4746629788946586

Epoch: 5| Step: 2
Training loss: 1.6471826197277442
Validation loss: 2.4870665663029743

Epoch: 5| Step: 3
Training loss: 1.7174468215194654
Validation loss: 2.4995547454423477

Epoch: 5| Step: 4
Training loss: 1.7506814038779046
Validation loss: 2.5245253242652463

Epoch: 5| Step: 5
Training loss: 2.411926707405209
Validation loss: 2.5193341318542934

Epoch: 5| Step: 6
Training loss: 1.256235116898924
Validation loss: 2.532143780401783

Epoch: 5| Step: 7
Training loss: 2.0581419012752526
Validation loss: 2.526299620104393

Epoch: 5| Step: 8
Training loss: 1.7976688124289433
Validation loss: 2.5079797667182033

Epoch: 5| Step: 9
Training loss: 1.8239504108296836
Validation loss: 2.523331284625063

Epoch: 5| Step: 10
Training loss: 1.668189862713565
Validation loss: 2.5256207826650443

Epoch: 5| Step: 11
Training loss: 2.1884451867730785
Validation loss: 2.501581589774673

Epoch: 113| Step: 0
Training loss: 2.119811736690603
Validation loss: 2.5221859630324333

Epoch: 5| Step: 1
Training loss: 1.8563554753093654
Validation loss: 2.47386199897461

Epoch: 5| Step: 2
Training loss: 1.6172686570300683
Validation loss: 2.5074169841321874

Epoch: 5| Step: 3
Training loss: 1.905123518496252
Validation loss: 2.4567948365604098

Epoch: 5| Step: 4
Training loss: 1.9306511577045635
Validation loss: 2.4896880743639667

Epoch: 5| Step: 5
Training loss: 1.568221792834871
Validation loss: 2.4905919754474537

Epoch: 5| Step: 6
Training loss: 1.5903524948551016
Validation loss: 2.517304280542098

Epoch: 5| Step: 7
Training loss: 1.7666834806445864
Validation loss: 2.5580572133574333

Epoch: 5| Step: 8
Training loss: 1.9251393453522885
Validation loss: 2.5676876219455145

Epoch: 5| Step: 9
Training loss: 1.6385112406368652
Validation loss: 2.5644613490053914

Epoch: 5| Step: 10
Training loss: 1.888585022563499
Validation loss: 2.537184242590686

Epoch: 5| Step: 11
Training loss: 1.4060383107540078
Validation loss: 2.52582636174526

Epoch: 114| Step: 0
Training loss: 1.417814472307259
Validation loss: 2.57151351086257

Epoch: 5| Step: 1
Training loss: 1.9141505629853415
Validation loss: 2.578092266607076

Epoch: 5| Step: 2
Training loss: 1.6332623897767478
Validation loss: 2.5400398212350086

Epoch: 5| Step: 3
Training loss: 1.439974024193976
Validation loss: 2.556113526572704

Epoch: 5| Step: 4
Training loss: 1.342175026459292
Validation loss: 2.543208957154079

Epoch: 5| Step: 5
Training loss: 1.93766685505701
Validation loss: 2.543021620021615

Epoch: 5| Step: 6
Training loss: 2.118520169466191
Validation loss: 2.508302967441134

Epoch: 5| Step: 7
Training loss: 2.2214925230227967
Validation loss: 2.481882132202393

Epoch: 5| Step: 8
Training loss: 1.2664762859993302
Validation loss: 2.517335302432534

Epoch: 5| Step: 9
Training loss: 1.6299555118316993
Validation loss: 2.4888726115108395

Epoch: 5| Step: 10
Training loss: 1.8892736728664612
Validation loss: 2.509900068944579

Epoch: 5| Step: 11
Training loss: 3.2786810127938315
Validation loss: 2.467322846449467

Epoch: 115| Step: 0
Training loss: 1.7332055900647334
Validation loss: 2.476934094233835

Epoch: 5| Step: 1
Training loss: 2.5170577808487726
Validation loss: 2.4969394188545295

Epoch: 5| Step: 2
Training loss: 1.6620543635551515
Validation loss: 2.5362873620304662

Epoch: 5| Step: 3
Training loss: 1.7366916889479656
Validation loss: 2.505394640529193

Epoch: 5| Step: 4
Training loss: 1.5131850905778736
Validation loss: 2.5504762429209853

Epoch: 5| Step: 5
Training loss: 1.6129622247887831
Validation loss: 2.5161209091523955

Epoch: 5| Step: 6
Training loss: 1.5903898983465714
Validation loss: 2.549270381048063

Epoch: 5| Step: 7
Training loss: 2.085658251183247
Validation loss: 2.505362929546045

Epoch: 5| Step: 8
Training loss: 1.099016643019805
Validation loss: 2.443402683068383

Epoch: 5| Step: 9
Training loss: 1.7781086041007998
Validation loss: 2.5003573837736557

Epoch: 5| Step: 10
Training loss: 1.7045468336157565
Validation loss: 2.476351142312023

Epoch: 5| Step: 11
Training loss: 1.8838489259944544
Validation loss: 2.509375745520633

Epoch: 116| Step: 0
Training loss: 1.6309538853836945
Validation loss: 2.5561743442933054

Epoch: 5| Step: 1
Training loss: 1.7880146672844142
Validation loss: 2.5713594810694147

Epoch: 5| Step: 2
Training loss: 1.3290955531470043
Validation loss: 2.58719168959305

Epoch: 5| Step: 3
Training loss: 1.8819733328516042
Validation loss: 2.5817766415118513

Epoch: 5| Step: 4
Training loss: 1.5516950475772162
Validation loss: 2.6352320155314244

Epoch: 5| Step: 5
Training loss: 1.7829571624291065
Validation loss: 2.6283519135868447

Epoch: 5| Step: 6
Training loss: 1.4721273185722734
Validation loss: 2.609189816906973

Epoch: 5| Step: 7
Training loss: 1.5537263592542698
Validation loss: 2.5352572875027706

Epoch: 5| Step: 8
Training loss: 2.3947471035968593
Validation loss: 2.5290218012221897

Epoch: 5| Step: 9
Training loss: 2.2620481471933678
Validation loss: 2.516914203187864

Epoch: 5| Step: 10
Training loss: 1.3656315696436074
Validation loss: 2.540960946106846

Epoch: 5| Step: 11
Training loss: 1.915223123983021
Validation loss: 2.449777072054491

Epoch: 117| Step: 0
Training loss: 1.479179928500761
Validation loss: 2.494979171767922

Epoch: 5| Step: 1
Training loss: 2.3081785496713825
Validation loss: 2.4850722200285404

Epoch: 5| Step: 2
Training loss: 1.6059574023971523
Validation loss: 2.508485412634319

Epoch: 5| Step: 3
Training loss: 1.5361979980606684
Validation loss: 2.498107336772579

Epoch: 5| Step: 4
Training loss: 1.9317069664219066
Validation loss: 2.4597723165324847

Epoch: 5| Step: 5
Training loss: 1.2552178199166875
Validation loss: 2.5034315281131168

Epoch: 5| Step: 6
Training loss: 1.7453763371253266
Validation loss: 2.555419484535064

Epoch: 5| Step: 7
Training loss: 1.9790764302881274
Validation loss: 2.4983314469385265

Epoch: 5| Step: 8
Training loss: 1.2131186254099005
Validation loss: 2.536659147915201

Epoch: 5| Step: 9
Training loss: 1.732674942541864
Validation loss: 2.5342470918387647

Epoch: 5| Step: 10
Training loss: 2.467658079083014
Validation loss: 2.5526186686499974

Epoch: 5| Step: 11
Training loss: 2.4019315536555252
Validation loss: 2.5281687652169604

Epoch: 118| Step: 0
Training loss: 1.7792174136259884
Validation loss: 2.5804503194297257

Epoch: 5| Step: 1
Training loss: 1.8132587686219122
Validation loss: 2.5265672405688355

Epoch: 5| Step: 2
Training loss: 1.6105678544955273
Validation loss: 2.521804907390755

Epoch: 5| Step: 3
Training loss: 1.6714454170281756
Validation loss: 2.4833723860161894

Epoch: 5| Step: 4
Training loss: 1.4453761731118016
Validation loss: 2.4701351673964607

Epoch: 5| Step: 5
Training loss: 1.7413666164017576
Validation loss: 2.5158643786345034

Epoch: 5| Step: 6
Training loss: 1.5957853746636346
Validation loss: 2.506725031924844

Epoch: 5| Step: 7
Training loss: 1.0747072530951611
Validation loss: 2.4900936191646363

Epoch: 5| Step: 8
Training loss: 2.0040154678296007
Validation loss: 2.4966039817656323

Epoch: 5| Step: 9
Training loss: 2.3977628374071283
Validation loss: 2.5356206052304993

Epoch: 5| Step: 10
Training loss: 1.9539051176401157
Validation loss: 2.5571678478671926

Epoch: 5| Step: 11
Training loss: 1.3324156623187762
Validation loss: 2.540623260472427

Epoch: 119| Step: 0
Training loss: 2.037468766049122
Validation loss: 2.538738112635465

Epoch: 5| Step: 1
Training loss: 1.8760369294604684
Validation loss: 2.5426463612765198

Epoch: 5| Step: 2
Training loss: 1.2030949774625161
Validation loss: 2.5424607839470066

Epoch: 5| Step: 3
Training loss: 1.9101653615660115
Validation loss: 2.4703143551502023

Epoch: 5| Step: 4
Training loss: 1.640779687764298
Validation loss: 2.506592777765115

Epoch: 5| Step: 5
Training loss: 1.372025610579081
Validation loss: 2.523461899772286

Epoch: 5| Step: 6
Training loss: 1.706435040511461
Validation loss: 2.4998277346547075

Epoch: 5| Step: 7
Training loss: 1.4464685713738865
Validation loss: 2.478835826458132

Epoch: 5| Step: 8
Training loss: 1.9983765450398434
Validation loss: 2.53047024133145

Epoch: 5| Step: 9
Training loss: 2.2399927755648052
Validation loss: 2.5080941775890326

Epoch: 5| Step: 10
Training loss: 1.2660517973706638
Validation loss: 2.4752457785671043

Epoch: 5| Step: 11
Training loss: 1.866081963937657
Validation loss: 2.4757504420451637

Epoch: 120| Step: 0
Training loss: 1.567988255583318
Validation loss: 2.5272848013322182

Epoch: 5| Step: 1
Training loss: 1.515896330466863
Validation loss: 2.4737143118457214

Epoch: 5| Step: 2
Training loss: 1.963824817536164
Validation loss: 2.5430739615884437

Epoch: 5| Step: 3
Training loss: 1.412560903873456
Validation loss: 2.5493089088476313

Epoch: 5| Step: 4
Training loss: 2.071352715348261
Validation loss: 2.5436395560242757

Epoch: 5| Step: 5
Training loss: 1.5483881937716557
Validation loss: 2.6109541190299734

Epoch: 5| Step: 6
Training loss: 1.7827729524176168
Validation loss: 2.5913335121978447

Epoch: 5| Step: 7
Training loss: 1.5989270367702195
Validation loss: 2.54863639490427

Epoch: 5| Step: 8
Training loss: 1.4163896158864937
Validation loss: 2.6182313725679927

Epoch: 5| Step: 9
Training loss: 1.6275315006565225
Validation loss: 2.5253607976085757

Epoch: 5| Step: 10
Training loss: 1.8263178965893276
Validation loss: 2.507530271785435

Epoch: 5| Step: 11
Training loss: 2.3824313499911502
Validation loss: 2.47443547650206

Epoch: 121| Step: 0
Training loss: 1.895189937644709
Validation loss: 2.489122205721797

Epoch: 5| Step: 1
Training loss: 1.784486607470056
Validation loss: 2.486736454862206

Epoch: 5| Step: 2
Training loss: 1.8342594350775188
Validation loss: 2.440952932360853

Epoch: 5| Step: 3
Training loss: 1.962494494193548
Validation loss: 2.4695602568150066

Epoch: 5| Step: 4
Training loss: 1.530719042218103
Validation loss: 2.464664281406268

Epoch: 5| Step: 5
Training loss: 1.4577763265719466
Validation loss: 2.4649304265391243

Epoch: 5| Step: 6
Training loss: 2.066547122184546
Validation loss: 2.5015583863503514

Epoch: 5| Step: 7
Training loss: 1.734653622353661
Validation loss: 2.5176196197254797

Epoch: 5| Step: 8
Training loss: 1.6298054287632682
Validation loss: 2.582436772606799

Epoch: 5| Step: 9
Training loss: 1.4622805536723504
Validation loss: 2.5751363443492905

Epoch: 5| Step: 10
Training loss: 1.831892776949632
Validation loss: 2.600293845832711

Epoch: 5| Step: 11
Training loss: 1.0845520182859105
Validation loss: 2.5756330295318173

Epoch: 122| Step: 0
Training loss: 1.4104329521933154
Validation loss: 2.5807267287493345

Epoch: 5| Step: 1
Training loss: 1.3323720009538558
Validation loss: 2.5240162637454095

Epoch: 5| Step: 2
Training loss: 1.6710360552301162
Validation loss: 2.5781755114914993

Epoch: 5| Step: 3
Training loss: 1.4083816478650562
Validation loss: 2.529619936151732

Epoch: 5| Step: 4
Training loss: 1.3453376617028052
Validation loss: 2.531902484234554

Epoch: 5| Step: 5
Training loss: 2.493097121359447
Validation loss: 2.520639982900207

Epoch: 5| Step: 6
Training loss: 2.2023385450092583
Validation loss: 2.5010715095702256

Epoch: 5| Step: 7
Training loss: 1.4161035970787241
Validation loss: 2.4771841534522623

Epoch: 5| Step: 8
Training loss: 1.747166792464216
Validation loss: 2.501704679884821

Epoch: 5| Step: 9
Training loss: 1.1944973229130365
Validation loss: 2.5052813534527187

Epoch: 5| Step: 10
Training loss: 1.5253783553993978
Validation loss: 2.5050255252073192

Epoch: 5| Step: 11
Training loss: 1.6706910977344294
Validation loss: 2.4999248215180057

Epoch: 123| Step: 0
Training loss: 1.3466063902052454
Validation loss: 2.5297253337856005

Epoch: 5| Step: 1
Training loss: 1.6337262384953064
Validation loss: 2.498140326872773

Epoch: 5| Step: 2
Training loss: 1.1937451027974444
Validation loss: 2.4914922990250594

Epoch: 5| Step: 3
Training loss: 1.2991592329365997
Validation loss: 2.4874746950737823

Epoch: 5| Step: 4
Training loss: 2.0287086434652957
Validation loss: 2.5289843941879906

Epoch: 5| Step: 5
Training loss: 1.8433163019650116
Validation loss: 2.549928336601299

Epoch: 5| Step: 6
Training loss: 2.1983947836515574
Validation loss: 2.5660085732880975

Epoch: 5| Step: 7
Training loss: 1.6885637533291442
Validation loss: 2.5405652533806586

Epoch: 5| Step: 8
Training loss: 1.6770337099430286
Validation loss: 2.54525769063264

Epoch: 5| Step: 9
Training loss: 1.5157102580522261
Validation loss: 2.4922332440585753

Epoch: 5| Step: 10
Training loss: 1.708056109505122
Validation loss: 2.5082760597314238

Epoch: 5| Step: 11
Training loss: 1.5006772737561735
Validation loss: 2.4897670372152345

Epoch: 124| Step: 0
Training loss: 1.7868571452596056
Validation loss: 2.500028145154833

Epoch: 5| Step: 1
Training loss: 1.4176328487140286
Validation loss: 2.54821047259901

Epoch: 5| Step: 2
Training loss: 2.144246177973259
Validation loss: 2.495294342420836

Epoch: 5| Step: 3
Training loss: 1.2301203158700018
Validation loss: 2.4454130653770383

Epoch: 5| Step: 4
Training loss: 1.8248336376501524
Validation loss: 2.4610802220531856

Epoch: 5| Step: 5
Training loss: 1.874406720713779
Validation loss: 2.4978896373169803

Epoch: 5| Step: 6
Training loss: 1.1522474862963288
Validation loss: 2.4777972676121713

Epoch: 5| Step: 7
Training loss: 1.5822754471303127
Validation loss: 2.498436733084301

Epoch: 5| Step: 8
Training loss: 1.2573363546137617
Validation loss: 2.5144195116644994

Epoch: 5| Step: 9
Training loss: 2.041941397211785
Validation loss: 2.5369645200455504

Epoch: 5| Step: 10
Training loss: 1.8757878237874839
Validation loss: 2.5978184049470303

Epoch: 5| Step: 11
Training loss: 0.37284082444216365
Validation loss: 2.584724239613573

Epoch: 125| Step: 0
Training loss: 1.351463711165659
Validation loss: 2.5307593282150647

Epoch: 5| Step: 1
Training loss: 1.8021305350000159
Validation loss: 2.587805861518427

Epoch: 5| Step: 2
Training loss: 1.6150027642949778
Validation loss: 2.577476207902079

Epoch: 5| Step: 3
Training loss: 1.346191760461959
Validation loss: 2.555603858472835

Epoch: 5| Step: 4
Training loss: 1.843853058601766
Validation loss: 2.5891515690015785

Epoch: 5| Step: 5
Training loss: 1.651886211563611
Validation loss: 2.55665260430646

Epoch: 5| Step: 6
Training loss: 0.9190621215653508
Validation loss: 2.5678996130295375

Epoch: 5| Step: 7
Training loss: 1.7061747272362286
Validation loss: 2.6057454295428935

Epoch: 5| Step: 8
Training loss: 1.5754194579074081
Validation loss: 2.576659360105618

Epoch: 5| Step: 9
Training loss: 1.823298546891038
Validation loss: 2.5705368848446013

Epoch: 5| Step: 10
Training loss: 1.7802329924608995
Validation loss: 2.547121215495756

Epoch: 5| Step: 11
Training loss: 1.614068234222064
Validation loss: 2.5582871425654536

Epoch: 126| Step: 0
Training loss: 1.6807869085514702
Validation loss: 2.5097375494627276

Epoch: 5| Step: 1
Training loss: 1.3143586667542964
Validation loss: 2.51734930379152

Epoch: 5| Step: 2
Training loss: 1.5345550990798005
Validation loss: 2.490459269422548

Epoch: 5| Step: 3
Training loss: 1.7220324989468692
Validation loss: 2.505473962819428

Epoch: 5| Step: 4
Training loss: 1.9084549955319101
Validation loss: 2.525642120906198

Epoch: 5| Step: 5
Training loss: 1.7694537754235333
Validation loss: 2.5556064862092

Epoch: 5| Step: 6
Training loss: 2.3749428792408844
Validation loss: 2.5262955934505205

Epoch: 5| Step: 7
Training loss: 1.0232001458909838
Validation loss: 2.560363068470991

Epoch: 5| Step: 8
Training loss: 1.6262804268666866
Validation loss: 2.581729207573235

Epoch: 5| Step: 9
Training loss: 1.4342916593254735
Validation loss: 2.590497156477497

Epoch: 5| Step: 10
Training loss: 1.335043178388711
Validation loss: 2.6039782029938734

Epoch: 5| Step: 11
Training loss: 0.8014626929773825
Validation loss: 2.62862215968059

Epoch: 127| Step: 0
Training loss: 2.0443141147057027
Validation loss: 2.5910173560004988

Epoch: 5| Step: 1
Training loss: 1.4598195087225252
Validation loss: 2.55916061528181

Epoch: 5| Step: 2
Training loss: 1.5983173522839764
Validation loss: 2.5535827098817

Epoch: 5| Step: 3
Training loss: 1.3835564460227325
Validation loss: 2.5714726636653618

Epoch: 5| Step: 4
Training loss: 1.4395274915597476
Validation loss: 2.5500528562278704

Epoch: 5| Step: 5
Training loss: 1.6589576613051864
Validation loss: 2.5178767210448183

Epoch: 5| Step: 6
Training loss: 2.0219223653678466
Validation loss: 2.5719246064999313

Epoch: 5| Step: 7
Training loss: 1.6862580709638928
Validation loss: 2.552843651430685

Epoch: 5| Step: 8
Training loss: 1.3543244734538533
Validation loss: 2.5054203321780184

Epoch: 5| Step: 9
Training loss: 1.7062716332485965
Validation loss: 2.5933547120900617

Epoch: 5| Step: 10
Training loss: 1.5492949389615411
Validation loss: 2.5304125628937206

Epoch: 5| Step: 11
Training loss: 1.0507814201723549
Validation loss: 2.5073512238382616

Epoch: 128| Step: 0
Training loss: 1.384522151660977
Validation loss: 2.4886531482048437

Epoch: 5| Step: 1
Training loss: 1.4848358242076678
Validation loss: 2.585492822881561

Epoch: 5| Step: 2
Training loss: 1.972856991062413
Validation loss: 2.562023515906175

Epoch: 5| Step: 3
Training loss: 1.3494441018161485
Validation loss: 2.5743116054275736

Epoch: 5| Step: 4
Training loss: 1.499389365200161
Validation loss: 2.5754112372047735

Epoch: 5| Step: 5
Training loss: 1.0417482471309423
Validation loss: 2.5472175118201617

Epoch: 5| Step: 6
Training loss: 1.9726077838647051
Validation loss: 2.5517966706307265

Epoch: 5| Step: 7
Training loss: 1.593486838959996
Validation loss: 2.507803278160371

Epoch: 5| Step: 8
Training loss: 1.6297518870141916
Validation loss: 2.5482636743854337

Epoch: 5| Step: 9
Training loss: 1.7714726659015592
Validation loss: 2.58499995558743

Epoch: 5| Step: 10
Training loss: 1.8456197406966435
Validation loss: 2.4996972337811374

Epoch: 5| Step: 11
Training loss: 1.4824789687107462
Validation loss: 2.5573764380384736

Epoch: 129| Step: 0
Training loss: 1.3654536997468438
Validation loss: 2.5539369443004056

Epoch: 5| Step: 1
Training loss: 1.4150434432083674
Validation loss: 2.627221550634402

Epoch: 5| Step: 2
Training loss: 1.5856731175635002
Validation loss: 2.5565482235329475

Epoch: 5| Step: 3
Training loss: 1.321901121850883
Validation loss: 2.5760078252617724

Epoch: 5| Step: 4
Training loss: 1.376109369283953
Validation loss: 2.577282534810206

Epoch: 5| Step: 5
Training loss: 1.6563604066145574
Validation loss: 2.5467280714095097

Epoch: 5| Step: 6
Training loss: 1.523358073976195
Validation loss: 2.569138866731555

Epoch: 5| Step: 7
Training loss: 1.878379954267505
Validation loss: 2.572554367184176

Epoch: 5| Step: 8
Training loss: 1.6037509016122165
Validation loss: 2.553915881363103

Epoch: 5| Step: 9
Training loss: 1.692028116344298
Validation loss: 2.545185055009722

Epoch: 5| Step: 10
Training loss: 2.0958114268963643
Validation loss: 2.4739821375989943

Epoch: 5| Step: 11
Training loss: 0.8273480207208735
Validation loss: 2.519182765626168

Epoch: 130| Step: 0
Training loss: 1.7104171588756056
Validation loss: 2.511603072425985

Epoch: 5| Step: 1
Training loss: 1.558592067325611
Validation loss: 2.5307837044999024

Epoch: 5| Step: 2
Training loss: 1.826008410966101
Validation loss: 2.496313715213776

Epoch: 5| Step: 3
Training loss: 1.9335054627887114
Validation loss: 2.5462637618343282

Epoch: 5| Step: 4
Training loss: 2.238050944944178
Validation loss: 2.5916037546251536

Epoch: 5| Step: 5
Training loss: 1.2858324677783148
Validation loss: 2.603053039221689

Epoch: 5| Step: 6
Training loss: 1.4087346485184935
Validation loss: 2.5540986855334555

Epoch: 5| Step: 7
Training loss: 1.1489384395552154
Validation loss: 2.5750140908852615

Epoch: 5| Step: 8
Training loss: 1.485276119365297
Validation loss: 2.56349486523104

Epoch: 5| Step: 9
Training loss: 1.0548491177530392
Validation loss: 2.52829876111215

Epoch: 5| Step: 10
Training loss: 1.7848344174688509
Validation loss: 2.5533684368953367

Epoch: 5| Step: 11
Training loss: 0.5674114909450262
Validation loss: 2.5756687852093307

Epoch: 131| Step: 0
Training loss: 1.6366635406578236
Validation loss: 2.5237988743703026

Epoch: 5| Step: 1
Training loss: 1.2503962842294223
Validation loss: 2.5214589868947233

Epoch: 5| Step: 2
Training loss: 1.0763054018902454
Validation loss: 2.5181511226159743

Epoch: 5| Step: 3
Training loss: 2.1603893409504193
Validation loss: 2.4959062477015688

Epoch: 5| Step: 4
Training loss: 1.5450285863855118
Validation loss: 2.5031185428664684

Epoch: 5| Step: 5
Training loss: 1.5896009405051734
Validation loss: 2.484603767338713

Epoch: 5| Step: 6
Training loss: 1.9707029435277728
Validation loss: 2.5177974876640254

Epoch: 5| Step: 7
Training loss: 1.692978337590382
Validation loss: 2.5121331750549736

Epoch: 5| Step: 8
Training loss: 0.9483853044554689
Validation loss: 2.5221822646002465

Epoch: 5| Step: 9
Training loss: 1.373468846992999
Validation loss: 2.5509395423677548

Epoch: 5| Step: 10
Training loss: 1.8021922510414212
Validation loss: 2.590660614640095

Epoch: 5| Step: 11
Training loss: 1.587124535321314
Validation loss: 2.6164747529712264

Epoch: 132| Step: 0
Training loss: 1.2543349914556718
Validation loss: 2.5930469356716648

Epoch: 5| Step: 1
Training loss: 1.4886957827800118
Validation loss: 2.6498488957432187

Epoch: 5| Step: 2
Training loss: 1.2408073963830257
Validation loss: 2.613852495026153

Epoch: 5| Step: 3
Training loss: 1.682435666309637
Validation loss: 2.62506304771155

Epoch: 5| Step: 4
Training loss: 1.4279886794189176
Validation loss: 2.636919112893268

Epoch: 5| Step: 5
Training loss: 1.1308022387471284
Validation loss: 2.556066383973801

Epoch: 5| Step: 6
Training loss: 2.1808554962085447
Validation loss: 2.575111986706518

Epoch: 5| Step: 7
Training loss: 1.6495346829276656
Validation loss: 2.542309977983289

Epoch: 5| Step: 8
Training loss: 1.0230271193674998
Validation loss: 2.556816835210426

Epoch: 5| Step: 9
Training loss: 1.5941469782670201
Validation loss: 2.5045305506315976

Epoch: 5| Step: 10
Training loss: 1.828746722538502
Validation loss: 2.525842770221449

Epoch: 5| Step: 11
Training loss: 1.3025124516688198
Validation loss: 2.4650630258920203

Epoch: 133| Step: 0
Training loss: 1.5511906849650807
Validation loss: 2.477161497487554

Epoch: 5| Step: 1
Training loss: 1.6516982095877624
Validation loss: 2.5297050352943757

Epoch: 5| Step: 2
Training loss: 1.713338760684035
Validation loss: 2.533528005394121

Epoch: 5| Step: 3
Training loss: 1.3565959805546721
Validation loss: 2.5119612217330123

Epoch: 5| Step: 4
Training loss: 1.1458208025622822
Validation loss: 2.5752783578582106

Epoch: 5| Step: 5
Training loss: 1.0691819728985634
Validation loss: 2.610835582205783

Epoch: 5| Step: 6
Training loss: 1.9391257940470366
Validation loss: 2.6042740278365692

Epoch: 5| Step: 7
Training loss: 1.6170501650670532
Validation loss: 2.6589875793363

Epoch: 5| Step: 8
Training loss: 1.3139290523013434
Validation loss: 2.6114512499873097

Epoch: 5| Step: 9
Training loss: 1.9815118514348353
Validation loss: 2.651062631180664

Epoch: 5| Step: 10
Training loss: 1.551600242378509
Validation loss: 2.524434592423622

Epoch: 5| Step: 11
Training loss: 1.805631184420454
Validation loss: 2.511172198072545

Epoch: 134| Step: 0
Training loss: 1.8260745425473668
Validation loss: 2.504295162203714

Epoch: 5| Step: 1
Training loss: 1.260933788346095
Validation loss: 2.5484505306700513

Epoch: 5| Step: 2
Training loss: 0.9204550977506168
Validation loss: 2.5066531939114873

Epoch: 5| Step: 3
Training loss: 1.891914999481978
Validation loss: 2.513978751182282

Epoch: 5| Step: 4
Training loss: 1.4932493256599797
Validation loss: 2.5050023774778514

Epoch: 5| Step: 5
Training loss: 1.2595207981877492
Validation loss: 2.5342541163692287

Epoch: 5| Step: 6
Training loss: 1.8886599456505042
Validation loss: 2.5507568272526036

Epoch: 5| Step: 7
Training loss: 1.393315273963365
Validation loss: 2.5752425099651455

Epoch: 5| Step: 8
Training loss: 1.8301319940836052
Validation loss: 2.593809494806943

Epoch: 5| Step: 9
Training loss: 1.5860578369187524
Validation loss: 2.6347232755816314

Epoch: 5| Step: 10
Training loss: 1.2100824598320565
Validation loss: 2.6083510059046433

Epoch: 5| Step: 11
Training loss: 2.043643526342706
Validation loss: 2.6242379111653893

Epoch: 135| Step: 0
Training loss: 1.4500252261105018
Validation loss: 2.6022202974673485

Epoch: 5| Step: 1
Training loss: 1.3024916758792984
Validation loss: 2.6109462431223456

Epoch: 5| Step: 2
Training loss: 1.4346332990661086
Validation loss: 2.595260234063806

Epoch: 5| Step: 3
Training loss: 1.1607838484072233
Validation loss: 2.583461386572982

Epoch: 5| Step: 4
Training loss: 1.1897227415491973
Validation loss: 2.561451678107759

Epoch: 5| Step: 5
Training loss: 1.456338753676563
Validation loss: 2.5764769864393533

Epoch: 5| Step: 6
Training loss: 2.1388885806305016
Validation loss: 2.533958669443591

Epoch: 5| Step: 7
Training loss: 1.4234638768588137
Validation loss: 2.570308248560828

Epoch: 5| Step: 8
Training loss: 1.8679947006101405
Validation loss: 2.559157540907427

Epoch: 5| Step: 9
Training loss: 1.512322830038163
Validation loss: 2.5119946468181324

Epoch: 5| Step: 10
Training loss: 1.361528904473899
Validation loss: 2.5144661629302107

Epoch: 5| Step: 11
Training loss: 1.5838219574656867
Validation loss: 2.5365939342328603

Epoch: 136| Step: 0
Training loss: 1.0370374176867356
Validation loss: 2.525183806637928

Epoch: 5| Step: 1
Training loss: 1.2614636237077899
Validation loss: 2.535134259066352

Epoch: 5| Step: 2
Training loss: 1.4297855531181147
Validation loss: 2.5499573760116694

Epoch: 5| Step: 3
Training loss: 1.4135102937834283
Validation loss: 2.562152513343554

Epoch: 5| Step: 4
Training loss: 1.53872862936592
Validation loss: 2.59336073378803

Epoch: 5| Step: 5
Training loss: 1.282160133331948
Validation loss: 2.587459151088385

Epoch: 5| Step: 6
Training loss: 1.485511104083859
Validation loss: 2.7016496987332626

Epoch: 5| Step: 7
Training loss: 1.461862852413857
Validation loss: 2.5738092732594273

Epoch: 5| Step: 8
Training loss: 2.279969260861833
Validation loss: 2.610056652949907

Epoch: 5| Step: 9
Training loss: 1.5611419116217609
Validation loss: 2.6182560575515867

Epoch: 5| Step: 10
Training loss: 1.6458781111537095
Validation loss: 2.625697325243296

Epoch: 5| Step: 11
Training loss: 0.9877247808042209
Validation loss: 2.591798507816401

Epoch: 137| Step: 0
Training loss: 1.685698147701113
Validation loss: 2.5512795499516705

Epoch: 5| Step: 1
Training loss: 1.4840310752370676
Validation loss: 2.5121174362908234

Epoch: 5| Step: 2
Training loss: 1.5082117056238202
Validation loss: 2.4818605878410382

Epoch: 5| Step: 3
Training loss: 1.3664480334917013
Validation loss: 2.592717079943786

Epoch: 5| Step: 4
Training loss: 1.1784460343704595
Validation loss: 2.5498131301761537

Epoch: 5| Step: 5
Training loss: 1.4278146118495767
Validation loss: 2.5525955866838297

Epoch: 5| Step: 6
Training loss: 1.4046476772209437
Validation loss: 2.5561129358381796

Epoch: 5| Step: 7
Training loss: 1.0676076081689103
Validation loss: 2.6200699263443084

Epoch: 5| Step: 8
Training loss: 1.622084790371308
Validation loss: 2.6045946869373604

Epoch: 5| Step: 9
Training loss: 1.91670250513599
Validation loss: 2.624290854926646

Epoch: 5| Step: 10
Training loss: 1.5255961456758234
Validation loss: 2.589225814232963

Epoch: 5| Step: 11
Training loss: 1.8917114667026773
Validation loss: 2.682239492458318

Epoch: 138| Step: 0
Training loss: 1.0692767401208636
Validation loss: 2.659701905589339

Epoch: 5| Step: 1
Training loss: 1.6378467105407037
Validation loss: 2.6897646470320957

Epoch: 5| Step: 2
Training loss: 1.0712301956180026
Validation loss: 2.616924361859799

Epoch: 5| Step: 3
Training loss: 1.88986178039049
Validation loss: 2.649836006878283

Epoch: 5| Step: 4
Training loss: 1.338631128470783
Validation loss: 2.6377436174331086

Epoch: 5| Step: 5
Training loss: 1.2232308789381774
Validation loss: 2.637831393359773

Epoch: 5| Step: 6
Training loss: 1.3635359474258408
Validation loss: 2.587624974081459

Epoch: 5| Step: 7
Training loss: 1.8457168820791867
Validation loss: 2.603834097925392

Epoch: 5| Step: 8
Training loss: 1.1613068189568756
Validation loss: 2.557967620415019

Epoch: 5| Step: 9
Training loss: 1.7163862446872318
Validation loss: 2.5507831972668757

Epoch: 5| Step: 10
Training loss: 1.5083748356850755
Validation loss: 2.5075376722485783

Epoch: 5| Step: 11
Training loss: 0.7717904558097266
Validation loss: 2.552168199853813

Epoch: 139| Step: 0
Training loss: 1.3600258858405048
Validation loss: 2.5708903404254584

Epoch: 5| Step: 1
Training loss: 1.8078549814467006
Validation loss: 2.5385342092382324

Epoch: 5| Step: 2
Training loss: 1.1435357148431466
Validation loss: 2.553285219728556

Epoch: 5| Step: 3
Training loss: 1.2035968400246242
Validation loss: 2.509230392124675

Epoch: 5| Step: 4
Training loss: 1.8482583740325367
Validation loss: 2.4921730722709303

Epoch: 5| Step: 5
Training loss: 1.6136096684717989
Validation loss: 2.5515123442193564

Epoch: 5| Step: 6
Training loss: 1.26596130800707
Validation loss: 2.6639159153857985

Epoch: 5| Step: 7
Training loss: 1.0469802689646923
Validation loss: 2.6107783664960875

Epoch: 5| Step: 8
Training loss: 1.7127613118858447
Validation loss: 2.5633963087326026

Epoch: 5| Step: 9
Training loss: 1.3576595400220388
Validation loss: 2.602400815535231

Epoch: 5| Step: 10
Training loss: 1.68350948822094
Validation loss: 2.6327375180578216

Epoch: 5| Step: 11
Training loss: 1.5866134030086503
Validation loss: 2.5727414883632274

Epoch: 140| Step: 0
Training loss: 1.23429942805093
Validation loss: 2.6384663985387915

Epoch: 5| Step: 1
Training loss: 1.2926989040394603
Validation loss: 2.5819578771126057

Epoch: 5| Step: 2
Training loss: 1.4354531186167174
Validation loss: 2.537247213290639

Epoch: 5| Step: 3
Training loss: 1.5539407134609537
Validation loss: 2.5865464813988766

Epoch: 5| Step: 4
Training loss: 1.649009713749819
Validation loss: 2.5647655392637216

Epoch: 5| Step: 5
Training loss: 1.3318800854418014
Validation loss: 2.5672314002969014

Epoch: 5| Step: 6
Training loss: 1.2826616837456948
Validation loss: 2.5878785772463027

Epoch: 5| Step: 7
Training loss: 2.0223757045732125
Validation loss: 2.5429037606352836

Epoch: 5| Step: 8
Training loss: 1.1514463389387206
Validation loss: 2.5255395186987744

Epoch: 5| Step: 9
Training loss: 1.2885800470276016
Validation loss: 2.54248693133371

Epoch: 5| Step: 10
Training loss: 1.2327523974718504
Validation loss: 2.5643679974409457

Epoch: 5| Step: 11
Training loss: 1.6744779484943648
Validation loss: 2.6156521483197017

Epoch: 141| Step: 0
Training loss: 1.6097779001139605
Validation loss: 2.644337908590544

Epoch: 5| Step: 1
Training loss: 1.396451253431515
Validation loss: 2.5535696463462765

Epoch: 5| Step: 2
Training loss: 1.1727728392443173
Validation loss: 2.5797513667764513

Epoch: 5| Step: 3
Training loss: 1.4771102615864644
Validation loss: 2.5570338340005736

Epoch: 5| Step: 4
Training loss: 1.1875249458503627
Validation loss: 2.5897059972154715

Epoch: 5| Step: 5
Training loss: 1.9396779524536074
Validation loss: 2.534042093979881

Epoch: 5| Step: 6
Training loss: 1.398679318112326
Validation loss: 2.5600527265453463

Epoch: 5| Step: 7
Training loss: 1.2072101941840512
Validation loss: 2.5718079210188214

Epoch: 5| Step: 8
Training loss: 1.8081715298997263
Validation loss: 2.624433999500298

Epoch: 5| Step: 9
Training loss: 1.2800668510473698
Validation loss: 2.6117754419708294

Epoch: 5| Step: 10
Training loss: 1.3578579648113507
Validation loss: 2.659655900636834

Epoch: 5| Step: 11
Training loss: 0.4281122637336986
Validation loss: 2.580100048587128

Epoch: 142| Step: 0
Training loss: 1.1815039185189815
Validation loss: 2.638911645077303

Epoch: 5| Step: 1
Training loss: 1.4214367872440248
Validation loss: 2.633335012624503

Epoch: 5| Step: 2
Training loss: 1.4971664208743873
Validation loss: 2.5638472651731505

Epoch: 5| Step: 3
Training loss: 0.9745278180997579
Validation loss: 2.5723718318577693

Epoch: 5| Step: 4
Training loss: 1.7465763662500735
Validation loss: 2.5525416462222323

Epoch: 5| Step: 5
Training loss: 1.1773684108609286
Validation loss: 2.5059585373272895

Epoch: 5| Step: 6
Training loss: 1.5373531860719534
Validation loss: 2.533029441006788

Epoch: 5| Step: 7
Training loss: 1.4135657855426336
Validation loss: 2.508969548059989

Epoch: 5| Step: 8
Training loss: 1.2835347808090156
Validation loss: 2.5843520552859385

Epoch: 5| Step: 9
Training loss: 1.345296546407248
Validation loss: 2.5559717152781167

Epoch: 5| Step: 10
Training loss: 1.7671290380384952
Validation loss: 2.5530874119594347

Epoch: 5| Step: 11
Training loss: 1.9978879266872152
Validation loss: 2.621577154344359

Epoch: 143| Step: 0
Training loss: 1.255793829315354
Validation loss: 2.6707469313735803

Epoch: 5| Step: 1
Training loss: 1.5456377726581276
Validation loss: 2.564930799922126

Epoch: 5| Step: 2
Training loss: 0.9524430508747528
Validation loss: 2.5400574578490893

Epoch: 5| Step: 3
Training loss: 1.5041210467041632
Validation loss: 2.54510027049628

Epoch: 5| Step: 4
Training loss: 1.3529591042399125
Validation loss: 2.547428111998411

Epoch: 5| Step: 5
Training loss: 1.8387052411013476
Validation loss: 2.6072732452054748

Epoch: 5| Step: 6
Training loss: 1.4151602851748653
Validation loss: 2.5568238132748737

Epoch: 5| Step: 7
Training loss: 1.0804878547617829
Validation loss: 2.589822714419544

Epoch: 5| Step: 8
Training loss: 1.677129030098714
Validation loss: 2.5815644104294835

Epoch: 5| Step: 9
Training loss: 1.0161099963155695
Validation loss: 2.551017224553126

Epoch: 5| Step: 10
Training loss: 1.4100046261244832
Validation loss: 2.568089154512346

Epoch: 5| Step: 11
Training loss: 1.7871037717637568
Validation loss: 2.5997512706050756

Epoch: 144| Step: 0
Training loss: 1.207096826444791
Validation loss: 2.587472953440032

Epoch: 5| Step: 1
Training loss: 1.3226946947399327
Validation loss: 2.6903928630729563

Epoch: 5| Step: 2
Training loss: 1.4805747927731443
Validation loss: 2.6444779075603235

Epoch: 5| Step: 3
Training loss: 1.5600399487833403
Validation loss: 2.740538014967496

Epoch: 5| Step: 4
Training loss: 1.1614438499380149
Validation loss: 2.658327883133837

Epoch: 5| Step: 5
Training loss: 1.1240419971249558
Validation loss: 2.658453491140122

Epoch: 5| Step: 6
Training loss: 1.7581363633945004
Validation loss: 2.601197634323703

Epoch: 5| Step: 7
Training loss: 1.017858953402637
Validation loss: 2.620233344329007

Epoch: 5| Step: 8
Training loss: 1.2479287152778067
Validation loss: 2.5582358850150437

Epoch: 5| Step: 9
Training loss: 1.821035544415668
Validation loss: 2.532872284535266

Epoch: 5| Step: 10
Training loss: 1.2240200054241714
Validation loss: 2.557605138912712

Epoch: 5| Step: 11
Training loss: 1.4064341954291313
Validation loss: 2.552614018026159

Epoch: 145| Step: 0
Training loss: 1.5620195031456545
Validation loss: 2.5878117464148374

Epoch: 5| Step: 1
Training loss: 1.302720694634527
Validation loss: 2.597533469298113

Epoch: 5| Step: 2
Training loss: 1.282111413321927
Validation loss: 2.5889490537435433

Epoch: 5| Step: 3
Training loss: 1.5009410608246607
Validation loss: 2.653557261497801

Epoch: 5| Step: 4
Training loss: 1.0459065298983736
Validation loss: 2.652151423856505

Epoch: 5| Step: 5
Training loss: 1.339214744504022
Validation loss: 2.6905568503013217

Epoch: 5| Step: 6
Training loss: 1.3449731183822364
Validation loss: 2.7082079430432784

Epoch: 5| Step: 7
Training loss: 1.524823306744349
Validation loss: 2.688556873633737

Epoch: 5| Step: 8
Training loss: 1.7834131591376416
Validation loss: 2.700121738197169

Epoch: 5| Step: 9
Training loss: 1.7623236520620467
Validation loss: 2.5964272864072386

Epoch: 5| Step: 10
Training loss: 1.039820172553449
Validation loss: 2.529217928681665

Epoch: 5| Step: 11
Training loss: 1.1891588370037132
Validation loss: 2.597660873523699

Epoch: 146| Step: 0
Training loss: 1.3478820611598437
Validation loss: 2.5678352236909663

Epoch: 5| Step: 1
Training loss: 1.2371910422385957
Validation loss: 2.5896654906760213

Epoch: 5| Step: 2
Training loss: 1.068685087943159
Validation loss: 2.5916408979621033

Epoch: 5| Step: 3
Training loss: 1.3359671249228073
Validation loss: 2.6571341595138693

Epoch: 5| Step: 4
Training loss: 1.2578194185623486
Validation loss: 2.6135958685081175

Epoch: 5| Step: 5
Training loss: 1.8865735489788855
Validation loss: 2.5419337465844865

Epoch: 5| Step: 6
Training loss: 1.4346127747236426
Validation loss: 2.6060472539138964

Epoch: 5| Step: 7
Training loss: 1.3410552750416975
Validation loss: 2.6186115850439164

Epoch: 5| Step: 8
Training loss: 1.2290906667112744
Validation loss: 2.665147305074166

Epoch: 5| Step: 9
Training loss: 1.0092349401091691
Validation loss: 2.6157206282003407

Epoch: 5| Step: 10
Training loss: 1.5043439748280445
Validation loss: 2.636925247960174

Epoch: 5| Step: 11
Training loss: 0.9235758850404019
Validation loss: 2.5988105178925385

Epoch: 147| Step: 0
Training loss: 1.1832150901675569
Validation loss: 2.6467987849744725

Epoch: 5| Step: 1
Training loss: 1.534745566687773
Validation loss: 2.5761123353422635

Epoch: 5| Step: 2
Training loss: 1.4754628926041422
Validation loss: 2.6552449886944096

Epoch: 5| Step: 3
Training loss: 1.035824426892496
Validation loss: 2.5459211080458988

Epoch: 5| Step: 4
Training loss: 0.9587302560775147
Validation loss: 2.628038638249906

Epoch: 5| Step: 5
Training loss: 1.358384747302509
Validation loss: 2.560462133584848

Epoch: 5| Step: 6
Training loss: 1.5816594946845717
Validation loss: 2.647183232861459

Epoch: 5| Step: 7
Training loss: 1.727289107349975
Validation loss: 2.578575977223431

Epoch: 5| Step: 8
Training loss: 1.110564494119022
Validation loss: 2.6181301715672567

Epoch: 5| Step: 9
Training loss: 1.1329858055404005
Validation loss: 2.579904978330551

Epoch: 5| Step: 10
Training loss: 1.4309077657462328
Validation loss: 2.6040312134165546

Epoch: 5| Step: 11
Training loss: 1.5159472879893148
Validation loss: 2.586100247612178

Epoch: 148| Step: 0
Training loss: 1.0545211095600753
Validation loss: 2.6117382464573606

Epoch: 5| Step: 1
Training loss: 0.8558544874378179
Validation loss: 2.613075084755458

Epoch: 5| Step: 2
Training loss: 1.0787047886573915
Validation loss: 2.638370958888522

Epoch: 5| Step: 3
Training loss: 1.0916045809458514
Validation loss: 2.6332512913420105

Epoch: 5| Step: 4
Training loss: 1.2185055903360127
Validation loss: 2.6447422764180333

Epoch: 5| Step: 5
Training loss: 1.7652549018181325
Validation loss: 2.6212415639298614

Epoch: 5| Step: 6
Training loss: 1.46324179983652
Validation loss: 2.5768257682107287

Epoch: 5| Step: 7
Training loss: 1.3242847347417563
Validation loss: 2.5857179554289993

Epoch: 5| Step: 8
Training loss: 1.2972240208148853
Validation loss: 2.627807799590757

Epoch: 5| Step: 9
Training loss: 1.8053165677027927
Validation loss: 2.583920624845944

Epoch: 5| Step: 10
Training loss: 1.1660453754252702
Validation loss: 2.619035990400735

Epoch: 5| Step: 11
Training loss: 2.2361694812725195
Validation loss: 2.6000739030544024

Epoch: 149| Step: 0
Training loss: 1.7834336130819415
Validation loss: 2.5781794031741714

Epoch: 5| Step: 1
Training loss: 1.2346507862901615
Validation loss: 2.591573974407337

Epoch: 5| Step: 2
Training loss: 1.0468076997446814
Validation loss: 2.6317887659982486

Epoch: 5| Step: 3
Training loss: 1.3176276995246983
Validation loss: 2.5813111625118608

Epoch: 5| Step: 4
Training loss: 1.4293301662124114
Validation loss: 2.6496462881299028

Epoch: 5| Step: 5
Training loss: 0.9926896814366657
Validation loss: 2.6943450665800324

Epoch: 5| Step: 6
Training loss: 1.2611673762438491
Validation loss: 2.6939478455632577

Epoch: 5| Step: 7
Training loss: 1.2227144562635162
Validation loss: 2.679195733355176

Epoch: 5| Step: 8
Training loss: 1.8672295090805786
Validation loss: 2.644281857337135

Epoch: 5| Step: 9
Training loss: 1.344146936030983
Validation loss: 2.673070101200625

Epoch: 5| Step: 10
Training loss: 1.170982631427494
Validation loss: 2.6426858365478796

Epoch: 5| Step: 11
Training loss: 1.4574384759444667
Validation loss: 2.653969417730241

Epoch: 150| Step: 0
Training loss: 1.2649569691060167
Validation loss: 2.6154572760108494

Epoch: 5| Step: 1
Training loss: 1.492704531586467
Validation loss: 2.5432663531959934

Epoch: 5| Step: 2
Training loss: 1.2327240151873529
Validation loss: 2.6469786835727165

Epoch: 5| Step: 3
Training loss: 1.1453585710405731
Validation loss: 2.5483856869499353

Epoch: 5| Step: 4
Training loss: 1.9003332272493718
Validation loss: 2.5715135823305926

Epoch: 5| Step: 5
Training loss: 1.046534126924559
Validation loss: 2.5757381680508806

Epoch: 5| Step: 6
Training loss: 1.5944276005028386
Validation loss: 2.545396410716351

Epoch: 5| Step: 7
Training loss: 1.1238776012106708
Validation loss: 2.6138477367186788

Epoch: 5| Step: 8
Training loss: 1.226295199091035
Validation loss: 2.618267174444829

Epoch: 5| Step: 9
Training loss: 1.4442490247842337
Validation loss: 2.6665930638487185

Epoch: 5| Step: 10
Training loss: 0.9454120236805781
Validation loss: 2.6805888440454027

Epoch: 5| Step: 11
Training loss: 0.7326690663595474
Validation loss: 2.7004493083451564

Epoch: 151| Step: 0
Training loss: 1.67587920216076
Validation loss: 2.691817380954091

Epoch: 5| Step: 1
Training loss: 1.8248527781010622
Validation loss: 2.6344841047193475

Epoch: 5| Step: 2
Training loss: 1.0332619086058568
Validation loss: 2.624371699420222

Epoch: 5| Step: 3
Training loss: 1.083262380085959
Validation loss: 2.556397669598846

Epoch: 5| Step: 4
Training loss: 0.7561957820656657
Validation loss: 2.596884430685719

Epoch: 5| Step: 5
Training loss: 0.9438151330766527
Validation loss: 2.543647944959568

Epoch: 5| Step: 6
Training loss: 1.192674655799769
Validation loss: 2.546671498443437

Epoch: 5| Step: 7
Training loss: 1.4733492488058997
Validation loss: 2.565120214163579

Epoch: 5| Step: 8
Training loss: 1.4511871542453538
Validation loss: 2.613629225298968

Epoch: 5| Step: 9
Training loss: 1.13313667657457
Validation loss: 2.5652206252459426

Epoch: 5| Step: 10
Training loss: 1.4029839629591048
Validation loss: 2.6206802595362295

Epoch: 5| Step: 11
Training loss: 1.8569101617514827
Validation loss: 2.6599130169191603

Epoch: 152| Step: 0
Training loss: 1.5411194354193627
Validation loss: 2.606369259466626

Epoch: 5| Step: 1
Training loss: 1.1673487417844244
Validation loss: 2.6001624119295914

Epoch: 5| Step: 2
Training loss: 1.009014979543352
Validation loss: 2.6258631093352562

Epoch: 5| Step: 3
Training loss: 0.9793550769992349
Validation loss: 2.657634961214185

Epoch: 5| Step: 4
Training loss: 1.082736615140736
Validation loss: 2.6399247409106996

Epoch: 5| Step: 5
Training loss: 1.1245655704512132
Validation loss: 2.647353941827198

Epoch: 5| Step: 6
Training loss: 1.273125452295297
Validation loss: 2.6976801548883835

Epoch: 5| Step: 7
Training loss: 1.4434972963007207
Validation loss: 2.624772614515564

Epoch: 5| Step: 8
Training loss: 1.1457712272227518
Validation loss: 2.560867347710693

Epoch: 5| Step: 9
Training loss: 1.496697286676346
Validation loss: 2.636025239139607

Epoch: 5| Step: 10
Training loss: 1.5105120749320824
Validation loss: 2.6596477767600857

Epoch: 5| Step: 11
Training loss: 0.7347661052339274
Validation loss: 2.608231185298232

Epoch: 153| Step: 0
Training loss: 1.566303658871559
Validation loss: 2.619319908687158

Epoch: 5| Step: 1
Training loss: 1.2159452688203785
Validation loss: 2.672535121343184

Epoch: 5| Step: 2
Training loss: 1.1770235007053889
Validation loss: 2.642551877797654

Epoch: 5| Step: 3
Training loss: 1.7177816957900907
Validation loss: 2.687092824150081

Epoch: 5| Step: 4
Training loss: 1.5681564180732066
Validation loss: 2.7421982992309184

Epoch: 5| Step: 5
Training loss: 1.183337293985392
Validation loss: 2.6185550248390608

Epoch: 5| Step: 6
Training loss: 1.352079391865601
Validation loss: 2.6450288756103784

Epoch: 5| Step: 7
Training loss: 0.8385771315441762
Validation loss: 2.6145749731550767

Epoch: 5| Step: 8
Training loss: 1.2540268409235318
Validation loss: 2.6060944872899943

Epoch: 5| Step: 9
Training loss: 1.0915445708411322
Validation loss: 2.6124068556916753

Epoch: 5| Step: 10
Training loss: 1.0093340366424906
Validation loss: 2.5092284858531047

Epoch: 5| Step: 11
Training loss: 0.8540669631143497
Validation loss: 2.5811597090932565

Epoch: 154| Step: 0
Training loss: 1.2866369373135036
Validation loss: 2.6132490596109617

Epoch: 5| Step: 1
Training loss: 1.0018063562285597
Validation loss: 2.6212121564382675

Epoch: 5| Step: 2
Training loss: 1.3991308784262537
Validation loss: 2.6165895908286196

Epoch: 5| Step: 3
Training loss: 1.044156544710639
Validation loss: 2.617186953416454

Epoch: 5| Step: 4
Training loss: 1.584235043335151
Validation loss: 2.67805144818443

Epoch: 5| Step: 5
Training loss: 1.676905968174314
Validation loss: 2.6581809897602464

Epoch: 5| Step: 6
Training loss: 0.9759070676467726
Validation loss: 2.648346553354975

Epoch: 5| Step: 7
Training loss: 0.9827737652009234
Validation loss: 2.7124387521758098

Epoch: 5| Step: 8
Training loss: 1.4252084077722518
Validation loss: 2.6109842184754504

Epoch: 5| Step: 9
Training loss: 0.927042395870163
Validation loss: 2.642411543695828

Epoch: 5| Step: 10
Training loss: 1.3382245391926435
Validation loss: 2.656111504179203

Epoch: 5| Step: 11
Training loss: 0.774524964597008
Validation loss: 2.5792937798726783

Epoch: 155| Step: 0
Training loss: 0.8227548842608245
Validation loss: 2.6497781149322237

Epoch: 5| Step: 1
Training loss: 1.2188746559753652
Validation loss: 2.633420845631834

Epoch: 5| Step: 2
Training loss: 1.316201078007501
Validation loss: 2.6436368537029944

Epoch: 5| Step: 3
Training loss: 1.228446194334857
Validation loss: 2.6228556919560138

Epoch: 5| Step: 4
Training loss: 1.781813281491323
Validation loss: 2.6047911289457293

Epoch: 5| Step: 5
Training loss: 1.0815815455874092
Validation loss: 2.5854578408880076

Epoch: 5| Step: 6
Training loss: 1.7107801669865823
Validation loss: 2.5542747638556462

Epoch: 5| Step: 7
Training loss: 1.1035969662015224
Validation loss: 2.6016431381665392

Epoch: 5| Step: 8
Training loss: 1.2529393446231252
Validation loss: 2.593438646863497

Epoch: 5| Step: 9
Training loss: 1.3741965981194988
Validation loss: 2.6549042097419453

Epoch: 5| Step: 10
Training loss: 0.8439655028746255
Validation loss: 2.6958117847279093

Epoch: 5| Step: 11
Training loss: 0.5534957117605491
Validation loss: 2.678937078450421

Epoch: 156| Step: 0
Training loss: 1.3959792710872092
Validation loss: 2.720686157348916

Epoch: 5| Step: 1
Training loss: 1.9256628901571324
Validation loss: 2.726444045065077

Epoch: 5| Step: 2
Training loss: 1.3878006703852468
Validation loss: 2.707539801010056

Epoch: 5| Step: 3
Training loss: 0.8286083178576671
Validation loss: 2.661697016176513

Epoch: 5| Step: 4
Training loss: 1.0732776195172051
Validation loss: 2.6362843322809444

Epoch: 5| Step: 5
Training loss: 1.3577858855313607
Validation loss: 2.555364112807051

Epoch: 5| Step: 6
Training loss: 1.1205924903932547
Validation loss: 2.558132382405609

Epoch: 5| Step: 7
Training loss: 1.0698494570883392
Validation loss: 2.570653048355422

Epoch: 5| Step: 8
Training loss: 0.8233886443670124
Validation loss: 2.5369692189358273

Epoch: 5| Step: 9
Training loss: 1.3161576486270286
Validation loss: 2.60669323745057

Epoch: 5| Step: 10
Training loss: 1.2713024753478943
Validation loss: 2.569124824746396

Epoch: 5| Step: 11
Training loss: 1.3115228466904616
Validation loss: 2.6449486888074127

Epoch: 157| Step: 0
Training loss: 0.8866850724735912
Validation loss: 2.627661313411243

Epoch: 5| Step: 1
Training loss: 1.0047642940995603
Validation loss: 2.685214567952393

Epoch: 5| Step: 2
Training loss: 1.2947785311109596
Validation loss: 2.6387777657842304

Epoch: 5| Step: 3
Training loss: 1.0353365183357757
Validation loss: 2.665885253252389

Epoch: 5| Step: 4
Training loss: 1.3406865886066097
Validation loss: 2.6842831628860133

Epoch: 5| Step: 5
Training loss: 0.8697083751216872
Validation loss: 2.6652656962964794

Epoch: 5| Step: 6
Training loss: 1.3358925259699534
Validation loss: 2.627614675651432

Epoch: 5| Step: 7
Training loss: 1.2241848296412263
Validation loss: 2.6371443416775

Epoch: 5| Step: 8
Training loss: 1.4611697088916034
Validation loss: 2.613929270944081

Epoch: 5| Step: 9
Training loss: 1.68723400986635
Validation loss: 2.583544593038092

Epoch: 5| Step: 10
Training loss: 1.2595619214394045
Validation loss: 2.56539937497457

Epoch: 5| Step: 11
Training loss: 2.0157504966760778
Validation loss: 2.6125877155746084

Epoch: 158| Step: 0
Training loss: 1.3230988935184416
Validation loss: 2.632025200072654

Epoch: 5| Step: 1
Training loss: 1.0617370109868391
Validation loss: 2.6834839710953107

Epoch: 5| Step: 2
Training loss: 1.3061406614547657
Validation loss: 2.665549108655493

Epoch: 5| Step: 3
Training loss: 1.2327544282065088
Validation loss: 2.6158332281506596

Epoch: 5| Step: 4
Training loss: 0.8585639247278479
Validation loss: 2.6656745869510243

Epoch: 5| Step: 5
Training loss: 0.9002379910728225
Validation loss: 2.6822797361435726

Epoch: 5| Step: 6
Training loss: 2.0000448221906137
Validation loss: 2.668588684501302

Epoch: 5| Step: 7
Training loss: 1.2482803914278109
Validation loss: 2.6315639905023502

Epoch: 5| Step: 8
Training loss: 1.1475491364042048
Validation loss: 2.635745406222466

Epoch: 5| Step: 9
Training loss: 1.1930265821067876
Validation loss: 2.618851128190733

Epoch: 5| Step: 10
Training loss: 0.9754019593362095
Validation loss: 2.606289636568204

Epoch: 5| Step: 11
Training loss: 1.285947608212759
Validation loss: 2.589264426590177

Epoch: 159| Step: 0
Training loss: 1.4049549073147614
Validation loss: 2.5770843717613583

Epoch: 5| Step: 1
Training loss: 0.7028754957232287
Validation loss: 2.610871945891228

Epoch: 5| Step: 2
Training loss: 1.3709446752641745
Validation loss: 2.6201572782444815

Epoch: 5| Step: 3
Training loss: 1.6937558810987108
Validation loss: 2.5980777790451386

Epoch: 5| Step: 4
Training loss: 1.1602474395158195
Validation loss: 2.6635761693381474

Epoch: 5| Step: 5
Training loss: 0.7071073712421805
Validation loss: 2.6823955750322996

Epoch: 5| Step: 6
Training loss: 1.3021503380383517
Validation loss: 2.619184349049728

Epoch: 5| Step: 7
Training loss: 1.2046501599176467
Validation loss: 2.657998545461371

Epoch: 5| Step: 8
Training loss: 0.7642129215633595
Validation loss: 2.631824134323651

Epoch: 5| Step: 9
Training loss: 1.5113878306853117
Validation loss: 2.642181507692586

Epoch: 5| Step: 10
Training loss: 1.096422200874506
Validation loss: 2.631293710540369

Epoch: 5| Step: 11
Training loss: 1.342907308667598
Validation loss: 2.5808173984774285

Epoch: 160| Step: 0
Training loss: 1.0185974638780937
Validation loss: 2.5675020205939543

Epoch: 5| Step: 1
Training loss: 0.8930113427658187
Validation loss: 2.6249395847937027

Epoch: 5| Step: 2
Training loss: 1.821313083684587
Validation loss: 2.609643305615675

Epoch: 5| Step: 3
Training loss: 1.224921130541372
Validation loss: 2.565800582276749

Epoch: 5| Step: 4
Training loss: 1.6162394080290712
Validation loss: 2.618590924720341

Epoch: 5| Step: 5
Training loss: 1.0090684974565425
Validation loss: 2.6696706754605373

Epoch: 5| Step: 6
Training loss: 1.2276659333210216
Validation loss: 2.64664643602022

Epoch: 5| Step: 7
Training loss: 1.034724249756012
Validation loss: 2.7363868215157234

Epoch: 5| Step: 8
Training loss: 1.2977372026541854
Validation loss: 2.623464184266172

Epoch: 5| Step: 9
Training loss: 1.0107134091615606
Validation loss: 2.6650005583348024

Epoch: 5| Step: 10
Training loss: 1.253467613815238
Validation loss: 2.64352276428962

Epoch: 5| Step: 11
Training loss: 1.4135183899812933
Validation loss: 2.6209554337278784

Epoch: 161| Step: 0
Training loss: 1.557055180007326
Validation loss: 2.6439124979531825

Epoch: 5| Step: 1
Training loss: 1.004202476168985
Validation loss: 2.5961400552439495

Epoch: 5| Step: 2
Training loss: 1.1422553755896072
Validation loss: 2.603608915999878

Epoch: 5| Step: 3
Training loss: 1.314509216290795
Validation loss: 2.561711438118071

Epoch: 5| Step: 4
Training loss: 0.9649797104397396
Validation loss: 2.687738415396688

Epoch: 5| Step: 5
Training loss: 1.31334418441595
Validation loss: 2.640373846295491

Epoch: 5| Step: 6
Training loss: 1.0853014942844654
Validation loss: 2.670951425234812

Epoch: 5| Step: 7
Training loss: 0.926221332492521
Validation loss: 2.628041639604873

Epoch: 5| Step: 8
Training loss: 1.7093683301945473
Validation loss: 2.707958879016103

Epoch: 5| Step: 9
Training loss: 0.7023585274470951
Validation loss: 2.623519733647971

Epoch: 5| Step: 10
Training loss: 0.9224131032029577
Validation loss: 2.664187075106509

Epoch: 5| Step: 11
Training loss: 0.8330011579956579
Validation loss: 2.7011302725051567

Epoch: 162| Step: 0
Training loss: 0.7276664468756481
Validation loss: 2.66484529660524

Epoch: 5| Step: 1
Training loss: 1.1503718168991206
Validation loss: 2.669453224215545

Epoch: 5| Step: 2
Training loss: 1.2950672280966409
Validation loss: 2.6325982060368287

Epoch: 5| Step: 3
Training loss: 1.0043624257105899
Validation loss: 2.6568700702447714

Epoch: 5| Step: 4
Training loss: 1.4309687475527824
Validation loss: 2.610487449525592

Epoch: 5| Step: 5
Training loss: 1.2679688214521219
Validation loss: 2.719197322322126

Epoch: 5| Step: 6
Training loss: 0.7386132356717451
Validation loss: 2.603048814541777

Epoch: 5| Step: 7
Training loss: 1.1742094566195724
Validation loss: 2.6486065715885805

Epoch: 5| Step: 8
Training loss: 1.5518778039766346
Validation loss: 2.6579397362078994

Epoch: 5| Step: 9
Training loss: 1.1493616861938227
Validation loss: 2.650812492632456

Epoch: 5| Step: 10
Training loss: 1.2157915349411803
Validation loss: 2.6430599565636945

Epoch: 5| Step: 11
Training loss: 1.171940356657314
Validation loss: 2.6342576057701033

Epoch: 163| Step: 0
Training loss: 1.3361283104693422
Validation loss: 2.6210805624465707

Epoch: 5| Step: 1
Training loss: 1.003533260655268
Validation loss: 2.5950352230695066

Epoch: 5| Step: 2
Training loss: 1.2041904636306395
Validation loss: 2.6960440909757963

Epoch: 5| Step: 3
Training loss: 0.8615506462136808
Validation loss: 2.654021259339139

Epoch: 5| Step: 4
Training loss: 0.9190724981102044
Validation loss: 2.650505342673752

Epoch: 5| Step: 5
Training loss: 0.8934651647863198
Validation loss: 2.6206826438601962

Epoch: 5| Step: 6
Training loss: 0.749648210355426
Validation loss: 2.6541521876452734

Epoch: 5| Step: 7
Training loss: 1.0158269828074236
Validation loss: 2.660728945635345

Epoch: 5| Step: 8
Training loss: 1.1976732366045306
Validation loss: 2.623125042464297

Epoch: 5| Step: 9
Training loss: 1.2496569639626154
Validation loss: 2.7439165415289457

Epoch: 5| Step: 10
Training loss: 1.1040882886503356
Validation loss: 2.7198202175266957

Epoch: 5| Step: 11
Training loss: 3.342355455170574
Validation loss: 2.6737596026107417

Epoch: 164| Step: 0
Training loss: 0.6972995183491435
Validation loss: 2.6275305641585285

Epoch: 5| Step: 1
Training loss: 1.4503929953911499
Validation loss: 2.639192433355421

Epoch: 5| Step: 2
Training loss: 1.7819521674470087
Validation loss: 2.619607230052639

Epoch: 5| Step: 3
Training loss: 1.1368814987659568
Validation loss: 2.598869308190474

Epoch: 5| Step: 4
Training loss: 0.90879867879837
Validation loss: 2.6108076156492475

Epoch: 5| Step: 5
Training loss: 1.0612847727548085
Validation loss: 2.6776262108910007

Epoch: 5| Step: 6
Training loss: 0.725618138375315
Validation loss: 2.6310890095647643

Epoch: 5| Step: 7
Training loss: 1.6199186547189628
Validation loss: 2.672290587498

Epoch: 5| Step: 8
Training loss: 1.1147317638971648
Validation loss: 2.6800386460119108

Epoch: 5| Step: 9
Training loss: 0.9852538046154794
Validation loss: 2.667132442496818

Epoch: 5| Step: 10
Training loss: 1.2699023834018703
Validation loss: 2.735364556863343

Epoch: 5| Step: 11
Training loss: 0.40667189185636815
Validation loss: 2.714309756960067

Epoch: 165| Step: 0
Training loss: 1.1891841991569414
Validation loss: 2.64908139663874

Epoch: 5| Step: 1
Training loss: 1.532586429268343
Validation loss: 2.6524252562998383

Epoch: 5| Step: 2
Training loss: 0.8471125603840848
Validation loss: 2.648362973570279

Epoch: 5| Step: 3
Training loss: 0.7741277677812072
Validation loss: 2.6662439530332813

Epoch: 5| Step: 4
Training loss: 1.0442656836378765
Validation loss: 2.6473680885887916

Epoch: 5| Step: 5
Training loss: 1.1930903304724543
Validation loss: 2.6958210304152472

Epoch: 5| Step: 6
Training loss: 0.9804509985787223
Validation loss: 2.651866326789539

Epoch: 5| Step: 7
Training loss: 0.833432589024084
Validation loss: 2.689155002490284

Epoch: 5| Step: 8
Training loss: 1.2340428352093251
Validation loss: 2.6634319487704867

Epoch: 5| Step: 9
Training loss: 1.6069598547876958
Validation loss: 2.6352850795709384

Epoch: 5| Step: 10
Training loss: 1.2354972180528556
Validation loss: 2.7002134206393453

Epoch: 5| Step: 11
Training loss: 0.7232765216388527
Validation loss: 2.723128509063946

Epoch: 166| Step: 0
Training loss: 1.0620483111512
Validation loss: 2.63919740757044

Epoch: 5| Step: 1
Training loss: 0.9215231078361027
Validation loss: 2.683093506054855

Epoch: 5| Step: 2
Training loss: 1.1466053471600093
Validation loss: 2.628588637900093

Epoch: 5| Step: 3
Training loss: 1.5642697801916865
Validation loss: 2.607771504519722

Epoch: 5| Step: 4
Training loss: 0.7033501582445914
Validation loss: 2.6260258168871156

Epoch: 5| Step: 5
Training loss: 1.0456791780599055
Validation loss: 2.638855478566023

Epoch: 5| Step: 6
Training loss: 1.0578442837829676
Validation loss: 2.600300854308161

Epoch: 5| Step: 7
Training loss: 1.4200363847611124
Validation loss: 2.6253609598333454

Epoch: 5| Step: 8
Training loss: 1.3843724562920823
Validation loss: 2.660957051576983

Epoch: 5| Step: 9
Training loss: 0.8952538516023815
Validation loss: 2.6206090586048774

Epoch: 5| Step: 10
Training loss: 1.0635354101960333
Validation loss: 2.6618603155813796

Epoch: 5| Step: 11
Training loss: 1.4268320888060397
Validation loss: 2.6895055015485476

Epoch: 167| Step: 0
Training loss: 0.9691330244818758
Validation loss: 2.7273897593848164

Epoch: 5| Step: 1
Training loss: 1.459660262464395
Validation loss: 2.6725106663635287

Epoch: 5| Step: 2
Training loss: 1.1394036952855573
Validation loss: 2.662417466044046

Epoch: 5| Step: 3
Training loss: 0.823201749810805
Validation loss: 2.662307345669057

Epoch: 5| Step: 4
Training loss: 1.0727229020539575
Validation loss: 2.584573349419653

Epoch: 5| Step: 5
Training loss: 1.2898426816070587
Validation loss: 2.6399558383807418

Epoch: 5| Step: 6
Training loss: 1.1503749256973383
Validation loss: 2.619782397871261

Epoch: 5| Step: 7
Training loss: 1.1621028611457411
Validation loss: 2.621068341302112

Epoch: 5| Step: 8
Training loss: 1.1413462200737068
Validation loss: 2.5833421266057477

Epoch: 5| Step: 9
Training loss: 1.0869510778000548
Validation loss: 2.653084008836649

Epoch: 5| Step: 10
Training loss: 0.8771743325501228
Validation loss: 2.619893625043676

Epoch: 5| Step: 11
Training loss: 0.9986575175257988
Validation loss: 2.6386054364999767

Epoch: 168| Step: 0
Training loss: 0.7572680611759639
Validation loss: 2.624203765544715

Epoch: 5| Step: 1
Training loss: 1.0959871029512667
Validation loss: 2.6515734325956086

Epoch: 5| Step: 2
Training loss: 0.8819369472642233
Validation loss: 2.630004022550468

Epoch: 5| Step: 3
Training loss: 1.1357726259490606
Validation loss: 2.6543088290011085

Epoch: 5| Step: 4
Training loss: 1.1266954150472852
Validation loss: 2.690223001893919

Epoch: 5| Step: 5
Training loss: 1.5905987870430347
Validation loss: 2.592239514565413

Epoch: 5| Step: 6
Training loss: 1.243479027295536
Validation loss: 2.6542104370624178

Epoch: 5| Step: 7
Training loss: 1.1457503664439392
Validation loss: 2.6340390865703247

Epoch: 5| Step: 8
Training loss: 1.304074903109684
Validation loss: 2.628408724075114

Epoch: 5| Step: 9
Training loss: 0.8052467328810359
Validation loss: 2.6569459040969514

Epoch: 5| Step: 10
Training loss: 1.1357000446454935
Validation loss: 2.610431862568954

Epoch: 5| Step: 11
Training loss: 1.2194446149278975
Validation loss: 2.6258959471146928

Epoch: 169| Step: 0
Training loss: 1.2814083931873244
Validation loss: 2.705854258186661

Epoch: 5| Step: 1
Training loss: 1.4982360959069065
Validation loss: 2.6570668703522036

Epoch: 5| Step: 2
Training loss: 1.1602674231902965
Validation loss: 2.6874760434465403

Epoch: 5| Step: 3
Training loss: 0.8610901449754812
Validation loss: 2.6098616521227767

Epoch: 5| Step: 4
Training loss: 0.8516464891923825
Validation loss: 2.685536843021035

Epoch: 5| Step: 5
Training loss: 1.229091394134752
Validation loss: 2.568418665057739

Epoch: 5| Step: 6
Training loss: 0.9296864100858566
Validation loss: 2.631779514290626

Epoch: 5| Step: 7
Training loss: 0.8062718913337
Validation loss: 2.642048352452165

Epoch: 5| Step: 8
Training loss: 1.824676325587914
Validation loss: 2.6661400324634226

Epoch: 5| Step: 9
Training loss: 0.7343338893989863
Validation loss: 2.652298501349264

Epoch: 5| Step: 10
Training loss: 0.859461831994602
Validation loss: 2.689177148751453

Epoch: 5| Step: 11
Training loss: 0.3310086153542818
Validation loss: 2.663008301380458

Epoch: 170| Step: 0
Training loss: 1.23986705236525
Validation loss: 2.7142720706884806

Epoch: 5| Step: 1
Training loss: 1.1409448671586326
Validation loss: 2.684299522407553

Epoch: 5| Step: 2
Training loss: 1.6857880279492443
Validation loss: 2.7530210763323337

Epoch: 5| Step: 3
Training loss: 1.210935235790474
Validation loss: 2.688953965571857

Epoch: 5| Step: 4
Training loss: 0.8194944026143743
Validation loss: 2.704901422084064

Epoch: 5| Step: 5
Training loss: 1.1059352038926356
Validation loss: 2.6754433560095925

Epoch: 5| Step: 6
Training loss: 0.8559716196770044
Validation loss: 2.599638883565089

Epoch: 5| Step: 7
Training loss: 0.9323888688943764
Validation loss: 2.648778480852526

Epoch: 5| Step: 8
Training loss: 0.9260133219022246
Validation loss: 2.6990583108051864

Epoch: 5| Step: 9
Training loss: 1.5275355850295254
Validation loss: 2.7037946977652205

Epoch: 5| Step: 10
Training loss: 0.7399523356268523
Validation loss: 2.6582179614495534

Epoch: 5| Step: 11
Training loss: 1.2680029487816251
Validation loss: 2.625071918168422

Epoch: 171| Step: 0
Training loss: 1.127909923561964
Validation loss: 2.6525509752869727

Epoch: 5| Step: 1
Training loss: 0.9133135017332618
Validation loss: 2.6740371663255185

Epoch: 5| Step: 2
Training loss: 0.899984768897557
Validation loss: 2.7439250096587697

Epoch: 5| Step: 3
Training loss: 0.9596964878368196
Validation loss: 2.718964221158686

Epoch: 5| Step: 4
Training loss: 1.2208673717627212
Validation loss: 2.7154093823216443

Epoch: 5| Step: 5
Training loss: 0.9594966972775294
Validation loss: 2.6958001584798135

Epoch: 5| Step: 6
Training loss: 1.3921473025288942
Validation loss: 2.688474907108402

Epoch: 5| Step: 7
Training loss: 1.1589204004911997
Validation loss: 2.6381279803423934

Epoch: 5| Step: 8
Training loss: 0.934284959875488
Validation loss: 2.6059809080815417

Epoch: 5| Step: 9
Training loss: 0.8050487781341721
Validation loss: 2.634982817199921

Epoch: 5| Step: 10
Training loss: 1.564965934382662
Validation loss: 2.6150308709787105

Epoch: 5| Step: 11
Training loss: 1.868851945322683
Validation loss: 2.642181400537923

Epoch: 172| Step: 0
Training loss: 1.5198081580616651
Validation loss: 2.6294555468078267

Epoch: 5| Step: 1
Training loss: 0.9473814903265465
Validation loss: 2.6374914322845004

Epoch: 5| Step: 2
Training loss: 1.063231665066823
Validation loss: 2.638609709667417

Epoch: 5| Step: 3
Training loss: 1.0831085240805343
Validation loss: 2.7166572789067054

Epoch: 5| Step: 4
Training loss: 0.9070412700142333
Validation loss: 2.669927389143389

Epoch: 5| Step: 5
Training loss: 0.6464121337357287
Validation loss: 2.710848849896447

Epoch: 5| Step: 6
Training loss: 1.33116215519021
Validation loss: 2.6752277070869837

Epoch: 5| Step: 7
Training loss: 1.1373011090292588
Validation loss: 2.74987229679276

Epoch: 5| Step: 8
Training loss: 0.8368925183081546
Validation loss: 2.7760222483821204

Epoch: 5| Step: 9
Training loss: 1.4125474854310978
Validation loss: 2.614908978268189

Epoch: 5| Step: 10
Training loss: 1.0695409290887243
Validation loss: 2.6373979499021223

Epoch: 5| Step: 11
Training loss: 0.6763941901267073
Validation loss: 2.6687853984286765

Epoch: 173| Step: 0
Training loss: 1.2415676849817698
Validation loss: 2.6275353562891692

Epoch: 5| Step: 1
Training loss: 1.122564806097561
Validation loss: 2.6347115230449196

Epoch: 5| Step: 2
Training loss: 0.7850363340898414
Validation loss: 2.6566543346160287

Epoch: 5| Step: 3
Training loss: 0.8424646689367319
Validation loss: 2.636067187019586

Epoch: 5| Step: 4
Training loss: 0.9400631199097857
Validation loss: 2.5701090916747846

Epoch: 5| Step: 5
Training loss: 0.8017017191548357
Validation loss: 2.6454371183198355

Epoch: 5| Step: 6
Training loss: 1.1074322627688789
Validation loss: 2.724278332141019

Epoch: 5| Step: 7
Training loss: 1.2092480595328436
Validation loss: 2.66211036016008

Epoch: 5| Step: 8
Training loss: 1.1700958988632604
Validation loss: 2.6879674298005773

Epoch: 5| Step: 9
Training loss: 1.4956737755530773
Validation loss: 2.7691445414699807

Epoch: 5| Step: 10
Training loss: 1.7370905194675654
Validation loss: 2.7477053186227174

Epoch: 5| Step: 11
Training loss: 0.8570958866862312
Validation loss: 2.7125934047116096

Epoch: 174| Step: 0
Training loss: 1.622537948564301
Validation loss: 2.591753604990543

Epoch: 5| Step: 1
Training loss: 1.0391752712461488
Validation loss: 2.655610901485495

Epoch: 5| Step: 2
Training loss: 1.4221932191341897
Validation loss: 2.648752465738274

Epoch: 5| Step: 3
Training loss: 0.907769606294225
Validation loss: 2.6488612313323685

Epoch: 5| Step: 4
Training loss: 1.2362007449128245
Validation loss: 2.628386791464102

Epoch: 5| Step: 5
Training loss: 1.0045253165943988
Validation loss: 2.64778123449719

Epoch: 5| Step: 6
Training loss: 0.9936164118388078
Validation loss: 2.6062830463207973

Epoch: 5| Step: 7
Training loss: 0.7904103918904011
Validation loss: 2.67220540820159

Epoch: 5| Step: 8
Training loss: 1.1747568934129375
Validation loss: 2.7104682516241714

Epoch: 5| Step: 9
Training loss: 1.1121803596012272
Validation loss: 2.665225687711221

Epoch: 5| Step: 10
Training loss: 1.0279600666245887
Validation loss: 2.772428846738994

Epoch: 5| Step: 11
Training loss: 0.7543936621404783
Validation loss: 2.7651925655875265

Epoch: 175| Step: 0
Training loss: 0.9120809807942389
Validation loss: 2.655775981569504

Epoch: 5| Step: 1
Training loss: 1.0624152879043007
Validation loss: 2.666805939216384

Epoch: 5| Step: 2
Training loss: 1.004035614822001
Validation loss: 2.592585807950992

Epoch: 5| Step: 3
Training loss: 1.1636258528855141
Validation loss: 2.6189318181834675

Epoch: 5| Step: 4
Training loss: 1.0207762734691672
Validation loss: 2.617267368293638

Epoch: 5| Step: 5
Training loss: 1.0312078062731236
Validation loss: 2.5841137888961403

Epoch: 5| Step: 6
Training loss: 1.7186257750961462
Validation loss: 2.642688093883542

Epoch: 5| Step: 7
Training loss: 0.8525756618338685
Validation loss: 2.6331343166428858

Epoch: 5| Step: 8
Training loss: 1.245157637593562
Validation loss: 2.6619967583513096

Epoch: 5| Step: 9
Training loss: 0.7370098813040233
Validation loss: 2.712685474963206

Epoch: 5| Step: 10
Training loss: 1.002857060760414
Validation loss: 2.686629901173762

Epoch: 5| Step: 11
Training loss: 1.6565631354517312
Validation loss: 2.73488924186366

Epoch: 176| Step: 0
Training loss: 1.1934360910283972
Validation loss: 2.645463321875414

Epoch: 5| Step: 1
Training loss: 0.8265228247539961
Validation loss: 2.684361342031589

Epoch: 5| Step: 2
Training loss: 1.04316343854933
Validation loss: 2.5731947294294906

Epoch: 5| Step: 3
Training loss: 0.955968461322482
Validation loss: 2.576239939020172

Epoch: 5| Step: 4
Training loss: 1.503319088148699
Validation loss: 2.595222177910811

Epoch: 5| Step: 5
Training loss: 0.8317918746538543
Validation loss: 2.656377520024689

Epoch: 5| Step: 6
Training loss: 0.93537885395476
Validation loss: 2.635050338545384

Epoch: 5| Step: 7
Training loss: 0.8717341784438226
Validation loss: 2.7108130485998436

Epoch: 5| Step: 8
Training loss: 1.1915324660186977
Validation loss: 2.722692068877783

Epoch: 5| Step: 9
Training loss: 0.7950390253745024
Validation loss: 2.758760329015305

Epoch: 5| Step: 10
Training loss: 1.4383887156008868
Validation loss: 2.6987597290978007

Epoch: 5| Step: 11
Training loss: 1.16552355941075
Validation loss: 2.688492469726681

Epoch: 177| Step: 0
Training loss: 0.9372526796271602
Validation loss: 2.6645449185727785

Epoch: 5| Step: 1
Training loss: 0.6252689259839945
Validation loss: 2.701390281263928

Epoch: 5| Step: 2
Training loss: 1.0252993007137021
Validation loss: 2.7202735337167656

Epoch: 5| Step: 3
Training loss: 1.2559845715140077
Validation loss: 2.652010964672059

Epoch: 5| Step: 4
Training loss: 0.9159246859114528
Validation loss: 2.6233655442954924

Epoch: 5| Step: 5
Training loss: 1.2536705960262287
Validation loss: 2.615743267069984

Epoch: 5| Step: 6
Training loss: 1.041525653195368
Validation loss: 2.62911806580551

Epoch: 5| Step: 7
Training loss: 0.7677579091669916
Validation loss: 2.658545900583664

Epoch: 5| Step: 8
Training loss: 1.1845300577970603
Validation loss: 2.628443329077122

Epoch: 5| Step: 9
Training loss: 1.032279338949112
Validation loss: 2.6830211474584864

Epoch: 5| Step: 10
Training loss: 1.668937169697441
Validation loss: 2.7203547502742786

Epoch: 5| Step: 11
Training loss: 0.5408314415477862
Validation loss: 2.696078430297328

Epoch: 178| Step: 0
Training loss: 1.193114410081629
Validation loss: 2.647520069572162

Epoch: 5| Step: 1
Training loss: 0.9368896086751823
Validation loss: 2.694015083782172

Epoch: 5| Step: 2
Training loss: 1.0713051418325261
Validation loss: 2.657298950570139

Epoch: 5| Step: 3
Training loss: 0.9423309470021551
Validation loss: 2.69593635010458

Epoch: 5| Step: 4
Training loss: 1.6263387007570342
Validation loss: 2.63418863104119

Epoch: 5| Step: 5
Training loss: 1.123914671937531
Validation loss: 2.6429245057566857

Epoch: 5| Step: 6
Training loss: 0.9095852743126056
Validation loss: 2.634930182526714

Epoch: 5| Step: 7
Training loss: 0.7058806567633342
Validation loss: 2.5989105829249293

Epoch: 5| Step: 8
Training loss: 0.9454724515414716
Validation loss: 2.6510618442649374

Epoch: 5| Step: 9
Training loss: 0.6755988255176081
Validation loss: 2.662580068336507

Epoch: 5| Step: 10
Training loss: 0.9735699387492875
Validation loss: 2.7069165277506784

Epoch: 5| Step: 11
Training loss: 1.3332713778327114
Validation loss: 2.6438186827471335

Epoch: 179| Step: 0
Training loss: 1.0404157502630311
Validation loss: 2.7029392935700263

Epoch: 5| Step: 1
Training loss: 1.0054479850278772
Validation loss: 2.648432878848445

Epoch: 5| Step: 2
Training loss: 1.318173317672562
Validation loss: 2.6031784293319324

Epoch: 5| Step: 3
Training loss: 0.8626852956012834
Validation loss: 2.638489083209022

Epoch: 5| Step: 4
Training loss: 0.6140956209680406
Validation loss: 2.6487687502958415

Epoch: 5| Step: 5
Training loss: 0.9103572443433064
Validation loss: 2.721649702655448

Epoch: 5| Step: 6
Training loss: 0.8448824170934581
Validation loss: 2.599448829850411

Epoch: 5| Step: 7
Training loss: 1.412574744145869
Validation loss: 2.6732372098175756

Epoch: 5| Step: 8
Training loss: 1.0690570345652197
Validation loss: 2.708163418697244

Epoch: 5| Step: 9
Training loss: 0.827669990343397
Validation loss: 2.65121308704946

Epoch: 5| Step: 10
Training loss: 1.0912150298083334
Validation loss: 2.6867185424970255

Epoch: 5| Step: 11
Training loss: 1.5292472197947191
Validation loss: 2.667152417664893

Epoch: 180| Step: 0
Training loss: 1.3447136639410664
Validation loss: 2.7187616888796167

Epoch: 5| Step: 1
Training loss: 0.764274963919559
Validation loss: 2.652186292151595

Epoch: 5| Step: 2
Training loss: 0.8651264545311046
Validation loss: 2.614111125651119

Epoch: 5| Step: 3
Training loss: 0.7181067283304536
Validation loss: 2.63501507384412

Epoch: 5| Step: 4
Training loss: 0.7774200402016695
Validation loss: 2.679009569604045

Epoch: 5| Step: 5
Training loss: 0.9749478839737249
Validation loss: 2.669982236018481

Epoch: 5| Step: 6
Training loss: 1.4244574266782075
Validation loss: 2.68053625250297

Epoch: 5| Step: 7
Training loss: 1.1354195947638503
Validation loss: 2.662356205909299

Epoch: 5| Step: 8
Training loss: 0.7094480821379653
Validation loss: 2.708426728227726

Epoch: 5| Step: 9
Training loss: 1.3366005127883698
Validation loss: 2.6775608205907186

Epoch: 5| Step: 10
Training loss: 0.8637291277228137
Validation loss: 2.691825154946227

Epoch: 5| Step: 11
Training loss: 0.4752494044312704
Validation loss: 2.7663828337715324

Epoch: 181| Step: 0
Training loss: 0.7720319132830008
Validation loss: 2.7359647616239675

Epoch: 5| Step: 1
Training loss: 0.7655455489681939
Validation loss: 2.671896988330214

Epoch: 5| Step: 2
Training loss: 0.8607500692672768
Validation loss: 2.6762905369420107

Epoch: 5| Step: 3
Training loss: 1.3384633418618288
Validation loss: 2.6680273270215515

Epoch: 5| Step: 4
Training loss: 0.704945432904963
Validation loss: 2.6939402971073743

Epoch: 5| Step: 5
Training loss: 0.9513263616101485
Validation loss: 2.6539222466008514

Epoch: 5| Step: 6
Training loss: 1.3827129694577531
Validation loss: 2.787422870059276

Epoch: 5| Step: 7
Training loss: 1.0772273984934102
Validation loss: 2.7086291714019017

Epoch: 5| Step: 8
Training loss: 0.9507527456030772
Validation loss: 2.6479190705351243

Epoch: 5| Step: 9
Training loss: 0.7226827255760361
Validation loss: 2.7258346373079596

Epoch: 5| Step: 10
Training loss: 1.0566903770706793
Validation loss: 2.77542529441303

Epoch: 5| Step: 11
Training loss: 1.5600149611220273
Validation loss: 2.7435629402906074

Epoch: 182| Step: 0
Training loss: 1.562666998521967
Validation loss: 2.745334688551832

Epoch: 5| Step: 1
Training loss: 0.9427995620057291
Validation loss: 2.64313318363299

Epoch: 5| Step: 2
Training loss: 0.7062747554322637
Validation loss: 2.662196720711984

Epoch: 5| Step: 3
Training loss: 1.2173403877737732
Validation loss: 2.7463445318323005

Epoch: 5| Step: 4
Training loss: 0.7806040573059634
Validation loss: 2.745345612906842

Epoch: 5| Step: 5
Training loss: 0.8472308660458845
Validation loss: 2.7315640560666936

Epoch: 5| Step: 6
Training loss: 1.0464375279311569
Validation loss: 2.729841823397067

Epoch: 5| Step: 7
Training loss: 0.8203846491011237
Validation loss: 2.786304164198562

Epoch: 5| Step: 8
Training loss: 0.8835793599408123
Validation loss: 2.7065903569275056

Epoch: 5| Step: 9
Training loss: 0.8175589714595302
Validation loss: 2.64771786480459

Epoch: 5| Step: 10
Training loss: 0.9947364086096001
Validation loss: 2.671194439745898

Epoch: 5| Step: 11
Training loss: 1.5127735647176417
Validation loss: 2.761803355488007

Epoch: 183| Step: 0
Training loss: 1.2036238787882847
Validation loss: 2.6628993861613095

Epoch: 5| Step: 1
Training loss: 0.7310744849298266
Validation loss: 2.62114010962673

Epoch: 5| Step: 2
Training loss: 1.0437316961453806
Validation loss: 2.6285468711286506

Epoch: 5| Step: 3
Training loss: 0.952769572791411
Validation loss: 2.6625746583694503

Epoch: 5| Step: 4
Training loss: 0.8408524953462728
Validation loss: 2.609791948885834

Epoch: 5| Step: 5
Training loss: 1.682194741432099
Validation loss: 2.6043041434557797

Epoch: 5| Step: 6
Training loss: 1.0621969688467088
Validation loss: 2.6878407395396966

Epoch: 5| Step: 7
Training loss: 0.8006608826028401
Validation loss: 2.6822975615402678

Epoch: 5| Step: 8
Training loss: 0.944958581168133
Validation loss: 2.6930004099198577

Epoch: 5| Step: 9
Training loss: 1.0538340188194684
Validation loss: 2.761338074170158

Epoch: 5| Step: 10
Training loss: 0.8708222996926867
Validation loss: 2.751212596867264

Epoch: 5| Step: 11
Training loss: 0.6835788398206525
Validation loss: 2.693207771325959

Epoch: 184| Step: 0
Training loss: 1.3631596552008578
Validation loss: 2.712895037485209

Epoch: 5| Step: 1
Training loss: 0.9126666896584144
Validation loss: 2.658526735136559

Epoch: 5| Step: 2
Training loss: 0.8161866837344158
Validation loss: 2.7164335284409913

Epoch: 5| Step: 3
Training loss: 0.6656101368422211
Validation loss: 2.592198210255895

Epoch: 5| Step: 4
Training loss: 1.6447521070474678
Validation loss: 2.670962045715287

Epoch: 5| Step: 5
Training loss: 1.0582971474075693
Validation loss: 2.664015511315574

Epoch: 5| Step: 6
Training loss: 0.9839277916752617
Validation loss: 2.6278600438988913

Epoch: 5| Step: 7
Training loss: 0.6104174280867097
Validation loss: 2.671583810446783

Epoch: 5| Step: 8
Training loss: 0.9697743506819987
Validation loss: 2.6672966530828317

Epoch: 5| Step: 9
Training loss: 0.8625194588829586
Validation loss: 2.630985150331439

Epoch: 5| Step: 10
Training loss: 0.7328418799003108
Validation loss: 2.67485383383094

Epoch: 5| Step: 11
Training loss: 0.3552176877950018
Validation loss: 2.719805446829939

Epoch: 185| Step: 0
Training loss: 1.2215475106948173
Validation loss: 2.663645494476528

Epoch: 5| Step: 1
Training loss: 1.1864909352061974
Validation loss: 2.763572150094755

Epoch: 5| Step: 2
Training loss: 0.94151033324711
Validation loss: 2.7246772456859403

Epoch: 5| Step: 3
Training loss: 0.5733542129776985
Validation loss: 2.657669630477301

Epoch: 5| Step: 4
Training loss: 0.8849907392890162
Validation loss: 2.6481666051306143

Epoch: 5| Step: 5
Training loss: 1.1791754110077228
Validation loss: 2.622897342936927

Epoch: 5| Step: 6
Training loss: 0.6371660124339421
Validation loss: 2.6379934436898824

Epoch: 5| Step: 7
Training loss: 1.3486912830005746
Validation loss: 2.7099244847867374

Epoch: 5| Step: 8
Training loss: 0.9526574598407618
Validation loss: 2.6228286906166516

Epoch: 5| Step: 9
Training loss: 0.963103203201948
Validation loss: 2.596263462396626

Epoch: 5| Step: 10
Training loss: 1.2188317687163102
Validation loss: 2.653132625189953

Epoch: 5| Step: 11
Training loss: 0.9665204201981791
Validation loss: 2.6778608014519865

Epoch: 186| Step: 0
Training loss: 0.7764198525278009
Validation loss: 2.7435028348631962

Epoch: 5| Step: 1
Training loss: 0.836985457055873
Validation loss: 2.667017154956203

Epoch: 5| Step: 2
Training loss: 1.0023486451693235
Validation loss: 2.639714654055964

Epoch: 5| Step: 3
Training loss: 1.6381148254241562
Validation loss: 2.647995734716276

Epoch: 5| Step: 4
Training loss: 0.8229130893742191
Validation loss: 2.6566232007713606

Epoch: 5| Step: 5
Training loss: 0.9568964026291901
Validation loss: 2.663755266777189

Epoch: 5| Step: 6
Training loss: 1.321778426013133
Validation loss: 2.691910178405836

Epoch: 5| Step: 7
Training loss: 0.7575787055796283
Validation loss: 2.6885211394476096

Epoch: 5| Step: 8
Training loss: 1.01206522425321
Validation loss: 2.7186581406110792

Epoch: 5| Step: 9
Training loss: 0.6619939562818429
Validation loss: 2.6433929405150174

Epoch: 5| Step: 10
Training loss: 0.8625246763154738
Validation loss: 2.681152554944304

Epoch: 5| Step: 11
Training loss: 0.44477704967390796
Validation loss: 2.6902268681172887

Epoch: 187| Step: 0
Training loss: 0.8973745277489624
Validation loss: 2.630901695992891

Epoch: 5| Step: 1
Training loss: 0.7596585313490554
Validation loss: 2.6798767267706745

Epoch: 5| Step: 2
Training loss: 0.9848646732258073
Validation loss: 2.586167105385988

Epoch: 5| Step: 3
Training loss: 0.8534009144950886
Validation loss: 2.668430796613805

Epoch: 5| Step: 4
Training loss: 1.143167562135586
Validation loss: 2.7279371532659304

Epoch: 5| Step: 5
Training loss: 0.9903684145405033
Validation loss: 2.688844629032703

Epoch: 5| Step: 6
Training loss: 1.0037590542357593
Validation loss: 2.615333568542681

Epoch: 5| Step: 7
Training loss: 0.9479681497084347
Validation loss: 2.635855714817725

Epoch: 5| Step: 8
Training loss: 0.773501422436916
Validation loss: 2.722104732309225

Epoch: 5| Step: 9
Training loss: 0.8989666582932488
Validation loss: 2.6690825952665875

Epoch: 5| Step: 10
Training loss: 1.4204067152813684
Validation loss: 2.7258517223318264

Epoch: 5| Step: 11
Training loss: 1.4231193882124153
Validation loss: 2.699497122057498

Epoch: 188| Step: 0
Training loss: 1.4346444336067756
Validation loss: 2.622070357963803

Epoch: 5| Step: 1
Training loss: 0.5799869247311006
Validation loss: 2.6710636066923885

Epoch: 5| Step: 2
Training loss: 0.4645628521200832
Validation loss: 2.6872376565266753

Epoch: 5| Step: 3
Training loss: 0.8359521169364953
Validation loss: 2.702895957783549

Epoch: 5| Step: 4
Training loss: 0.7567847843726383
Validation loss: 2.6138209273707482

Epoch: 5| Step: 5
Training loss: 1.230476742673074
Validation loss: 2.5817645305971917

Epoch: 5| Step: 6
Training loss: 1.0957296711634976
Validation loss: 2.6660501182104026

Epoch: 5| Step: 7
Training loss: 1.1479340052925067
Validation loss: 2.6028676658766057

Epoch: 5| Step: 8
Training loss: 0.8115076460604441
Validation loss: 2.6841155021125305

Epoch: 5| Step: 9
Training loss: 0.9836999910044963
Validation loss: 2.7307601685879903

Epoch: 5| Step: 10
Training loss: 1.056046013631558
Validation loss: 2.6710304911046707

Epoch: 5| Step: 11
Training loss: 0.6390084129519934
Validation loss: 2.7059458161535503

Epoch: 189| Step: 0
Training loss: 0.9871889191774587
Validation loss: 2.6420419510407647

Epoch: 5| Step: 1
Training loss: 0.8703153065716677
Validation loss: 2.6452617941584053

Epoch: 5| Step: 2
Training loss: 0.5350977176482848
Validation loss: 2.6031567420871236

Epoch: 5| Step: 3
Training loss: 0.9207795957417422
Validation loss: 2.6334419743142394

Epoch: 5| Step: 4
Training loss: 0.6918751909760553
Validation loss: 2.7242152941978803

Epoch: 5| Step: 5
Training loss: 0.7162729370146063
Validation loss: 2.6510328631201805

Epoch: 5| Step: 6
Training loss: 0.7641861298750748
Validation loss: 2.6718521451809147

Epoch: 5| Step: 7
Training loss: 1.5519712096129648
Validation loss: 2.698950640570394

Epoch: 5| Step: 8
Training loss: 1.103684998063837
Validation loss: 2.6666953947089413

Epoch: 5| Step: 9
Training loss: 0.8942569495345124
Validation loss: 2.620076390916936

Epoch: 5| Step: 10
Training loss: 0.9542736573738446
Validation loss: 2.645757551434599

Epoch: 5| Step: 11
Training loss: 0.6031256838779822
Validation loss: 2.781038694176993

Epoch: 190| Step: 0
Training loss: 0.8468612247486887
Validation loss: 2.7045114926772045

Epoch: 5| Step: 1
Training loss: 0.8742534313532725
Validation loss: 2.6901165844069688

Epoch: 5| Step: 2
Training loss: 0.6815526080211693
Validation loss: 2.7068640770607746

Epoch: 5| Step: 3
Training loss: 1.3407219324881732
Validation loss: 2.718959124330713

Epoch: 5| Step: 4
Training loss: 0.8378339272547506
Validation loss: 2.6560233636548043

Epoch: 5| Step: 5
Training loss: 0.62386318769911
Validation loss: 2.607166063425658

Epoch: 5| Step: 6
Training loss: 1.3068501713572933
Validation loss: 2.6086822778075605

Epoch: 5| Step: 7
Training loss: 1.4010293480238192
Validation loss: 2.674074026521834

Epoch: 5| Step: 8
Training loss: 0.8918302980058954
Validation loss: 2.6540715634471117

Epoch: 5| Step: 9
Training loss: 0.5373888987669114
Validation loss: 2.653828536318118

Epoch: 5| Step: 10
Training loss: 1.0724811719473302
Validation loss: 2.651289423673884

Epoch: 5| Step: 11
Training loss: 0.8470870185455405
Validation loss: 2.728520141466754

Epoch: 191| Step: 0
Training loss: 0.9165868218645117
Validation loss: 2.628232963240458

Epoch: 5| Step: 1
Training loss: 0.6447106314062853
Validation loss: 2.6478236677064175

Epoch: 5| Step: 2
Training loss: 0.6965773147643669
Validation loss: 2.670479906614726

Epoch: 5| Step: 3
Training loss: 0.7817553221103895
Validation loss: 2.720639744969939

Epoch: 5| Step: 4
Training loss: 0.7211203259233779
Validation loss: 2.6782492994190465

Epoch: 5| Step: 5
Training loss: 1.4315216306437197
Validation loss: 2.5834130472272085

Epoch: 5| Step: 6
Training loss: 0.5703297181339084
Validation loss: 2.7444992609401235

Epoch: 5| Step: 7
Training loss: 0.9487209820236256
Validation loss: 2.694571432800424

Epoch: 5| Step: 8
Training loss: 0.8421320767823707
Validation loss: 2.6494159747692256

Epoch: 5| Step: 9
Training loss: 1.2884232756805385
Validation loss: 2.6407334739932122

Epoch: 5| Step: 10
Training loss: 1.0154877203081978
Validation loss: 2.600281389457823

Epoch: 5| Step: 11
Training loss: 0.24617585825746766
Validation loss: 2.6695046348834013

Epoch: 192| Step: 0
Training loss: 0.998464926043001
Validation loss: 2.605935309947787

Epoch: 5| Step: 1
Training loss: 0.9745468394794192
Validation loss: 2.5959578007166457

Epoch: 5| Step: 2
Training loss: 0.8306824761705813
Validation loss: 2.6691086076271104

Epoch: 5| Step: 3
Training loss: 0.8276316054644774
Validation loss: 2.6988455426523736

Epoch: 5| Step: 4
Training loss: 1.0564980119793914
Validation loss: 2.577761160097692

Epoch: 5| Step: 5
Training loss: 1.519882749878923
Validation loss: 2.7133151830559004

Epoch: 5| Step: 6
Training loss: 0.8133545929509215
Validation loss: 2.698759110691417

Epoch: 5| Step: 7
Training loss: 1.0200750428064314
Validation loss: 2.7034866737858967

Epoch: 5| Step: 8
Training loss: 0.6704237145416366
Validation loss: 2.6126873061766633

Epoch: 5| Step: 9
Training loss: 0.9376922410319931
Validation loss: 2.6848917028997836

Epoch: 5| Step: 10
Training loss: 0.5617294066456839
Validation loss: 2.684387206337369

Epoch: 5| Step: 11
Training loss: 0.6632667261337518
Validation loss: 2.6626646937145066

Epoch: 193| Step: 0
Training loss: 0.9213231908329198
Validation loss: 2.6989221920615245

Epoch: 5| Step: 1
Training loss: 0.7342247504885963
Validation loss: 2.6771676585848234

Epoch: 5| Step: 2
Training loss: 1.264990659385242
Validation loss: 2.72889955077326

Epoch: 5| Step: 3
Training loss: 0.6176364569528793
Validation loss: 2.6930174376540186

Epoch: 5| Step: 4
Training loss: 0.6948059680120745
Validation loss: 2.7219148754844342

Epoch: 5| Step: 5
Training loss: 1.0010695102615528
Validation loss: 2.7295469220564414

Epoch: 5| Step: 6
Training loss: 0.7289921733425595
Validation loss: 2.674468033323853

Epoch: 5| Step: 7
Training loss: 0.9212502124221951
Validation loss: 2.693316847751542

Epoch: 5| Step: 8
Training loss: 1.0820544409074173
Validation loss: 2.697040203157635

Epoch: 5| Step: 9
Training loss: 0.8396098676200707
Validation loss: 2.6878146312681372

Epoch: 5| Step: 10
Training loss: 1.0813684740373402
Validation loss: 2.631029549739769

Epoch: 5| Step: 11
Training loss: 1.717172418863093
Validation loss: 2.6515587500397886

Epoch: 194| Step: 0
Training loss: 0.5360522600538875
Validation loss: 2.6827080239904086

Epoch: 5| Step: 1
Training loss: 0.9530381960504539
Validation loss: 2.686186047871574

Epoch: 5| Step: 2
Training loss: 0.5621499455850356
Validation loss: 2.7042686233539888

Epoch: 5| Step: 3
Training loss: 0.9759838068099506
Validation loss: 2.6836503923815673

Epoch: 5| Step: 4
Training loss: 0.5319190020351827
Validation loss: 2.7013539482533093

Epoch: 5| Step: 5
Training loss: 0.9514971731026652
Validation loss: 2.6966208594946197

Epoch: 5| Step: 6
Training loss: 0.6979825263951375
Validation loss: 2.704759816378848

Epoch: 5| Step: 7
Training loss: 1.2133274243982937
Validation loss: 2.6621047365330575

Epoch: 5| Step: 8
Training loss: 1.5532809848860003
Validation loss: 2.746898938242153

Epoch: 5| Step: 9
Training loss: 0.8461842919087472
Validation loss: 2.622976832852406

Epoch: 5| Step: 10
Training loss: 0.8595640841455395
Validation loss: 2.663749903949346

Epoch: 5| Step: 11
Training loss: 0.8913096423209291
Validation loss: 2.6583723864083395

Epoch: 195| Step: 0
Training loss: 0.9768628383374884
Validation loss: 2.67909088017688

Epoch: 5| Step: 1
Training loss: 0.9501151102999478
Validation loss: 2.673257302878149

Epoch: 5| Step: 2
Training loss: 0.5160216915169631
Validation loss: 2.6605145086659823

Epoch: 5| Step: 3
Training loss: 1.3862327046257066
Validation loss: 2.711117334474871

Epoch: 5| Step: 4
Training loss: 1.022803947676379
Validation loss: 2.720526673783355

Epoch: 5| Step: 5
Training loss: 1.3404179446509075
Validation loss: 2.7456048608949177

Epoch: 5| Step: 6
Training loss: 0.5188664650303547
Validation loss: 2.7382293819606818

Epoch: 5| Step: 7
Training loss: 0.9104301138844259
Validation loss: 2.624600243783184

Epoch: 5| Step: 8
Training loss: 0.5653344899419134
Validation loss: 2.696349673273269

Epoch: 5| Step: 9
Training loss: 0.7730099430678473
Validation loss: 2.690383144559937

Epoch: 5| Step: 10
Training loss: 0.8480150368792319
Validation loss: 2.7063801024969707

Epoch: 5| Step: 11
Training loss: 0.6900719521159088
Validation loss: 2.649027572058969

Epoch: 196| Step: 0
Training loss: 1.0702918948675246
Validation loss: 2.6328103455063996

Epoch: 5| Step: 1
Training loss: 0.8625696969551244
Validation loss: 2.707504036678171

Epoch: 5| Step: 2
Training loss: 1.3295980923243034
Validation loss: 2.703288644824229

Epoch: 5| Step: 3
Training loss: 0.48508315464827567
Validation loss: 2.6421758510483953

Epoch: 5| Step: 4
Training loss: 0.8305441232749977
Validation loss: 2.6783078926870574

Epoch: 5| Step: 5
Training loss: 0.9597117351824513
Validation loss: 2.7040007133776855

Epoch: 5| Step: 6
Training loss: 0.8077675104064443
Validation loss: 2.6434293223298635

Epoch: 5| Step: 7
Training loss: 0.8959293683644037
Validation loss: 2.676591278132276

Epoch: 5| Step: 8
Training loss: 0.9369655357218937
Validation loss: 2.628605980845314

Epoch: 5| Step: 9
Training loss: 0.37975034389894646
Validation loss: 2.6665282635733845

Epoch: 5| Step: 10
Training loss: 1.0933478569795134
Validation loss: 2.6139927623906885

Epoch: 5| Step: 11
Training loss: 0.3679298647604626
Validation loss: 2.7033959806002086

Epoch: 197| Step: 0
Training loss: 0.9063467434513842
Validation loss: 2.60784110176823

Epoch: 5| Step: 1
Training loss: 0.531143682724506
Validation loss: 2.698944434853185

Epoch: 5| Step: 2
Training loss: 1.0950380642689441
Validation loss: 2.6138516094951467

Epoch: 5| Step: 3
Training loss: 1.2667777380849095
Validation loss: 2.743040931973865

Epoch: 5| Step: 4
Training loss: 1.1849658931378935
Validation loss: 2.646712192240744

Epoch: 5| Step: 5
Training loss: 0.68927652404413
Validation loss: 2.715811705527075

Epoch: 5| Step: 6
Training loss: 0.9037376965414718
Validation loss: 2.6316718961588443

Epoch: 5| Step: 7
Training loss: 0.969819647402078
Validation loss: 2.6192459741427783

Epoch: 5| Step: 8
Training loss: 0.6270493763276827
Validation loss: 2.646953883641369

Epoch: 5| Step: 9
Training loss: 0.6099799405770798
Validation loss: 2.660408235883585

Epoch: 5| Step: 10
Training loss: 0.9575372409301358
Validation loss: 2.618888154402887

Epoch: 5| Step: 11
Training loss: 0.5777098737554675
Validation loss: 2.5828448854151844

Epoch: 198| Step: 0
Training loss: 0.5828171614800544
Validation loss: 2.5756816807358613

Epoch: 5| Step: 1
Training loss: 0.8593159048396013
Validation loss: 2.679590288332245

Epoch: 5| Step: 2
Training loss: 0.5641899947532499
Validation loss: 2.6742717225406585

Epoch: 5| Step: 3
Training loss: 0.621007517460458
Validation loss: 2.635364974247483

Epoch: 5| Step: 4
Training loss: 0.5991900838786468
Validation loss: 2.6433177889294304

Epoch: 5| Step: 5
Training loss: 0.659822526356027
Validation loss: 2.6278051003992973

Epoch: 5| Step: 6
Training loss: 1.4200392389920427
Validation loss: 2.7198367102808683

Epoch: 5| Step: 7
Training loss: 1.2048148635846614
Validation loss: 2.701428801811838

Epoch: 5| Step: 8
Training loss: 0.8044775161090696
Validation loss: 2.704476847196128

Epoch: 5| Step: 9
Training loss: 0.9921130655557846
Validation loss: 2.718661847640293

Epoch: 5| Step: 10
Training loss: 1.041706650284468
Validation loss: 2.6162806633702926

Epoch: 5| Step: 11
Training loss: 1.3189688622976259
Validation loss: 2.6459547500585687

Epoch: 199| Step: 0
Training loss: 0.9823379632443545
Validation loss: 2.6762955999609823

Epoch: 5| Step: 1
Training loss: 0.6127746822470743
Validation loss: 2.662892751351063

Epoch: 5| Step: 2
Training loss: 0.9284909024796898
Validation loss: 2.7016657563732984

Epoch: 5| Step: 3
Training loss: 1.2405618070175461
Validation loss: 2.7260283900690623

Epoch: 5| Step: 4
Training loss: 0.7172629273088301
Validation loss: 2.684089259526008

Epoch: 5| Step: 5
Training loss: 0.9244887266425911
Validation loss: 2.7313366021481333

Epoch: 5| Step: 6
Training loss: 1.0212788420658399
Validation loss: 2.7011768178280877

Epoch: 5| Step: 7
Training loss: 0.7503688223281233
Validation loss: 2.7077302970522763

Epoch: 5| Step: 8
Training loss: 0.9281921542241505
Validation loss: 2.7516407551306954

Epoch: 5| Step: 9
Training loss: 0.7288230267899557
Validation loss: 2.60453530690568

Epoch: 5| Step: 10
Training loss: 1.1011034502771664
Validation loss: 2.646968621764175

Epoch: 5| Step: 11
Training loss: 0.7266231224446604
Validation loss: 2.72672432289008

Epoch: 200| Step: 0
Training loss: 0.8310352506953327
Validation loss: 2.703132177354402

Epoch: 5| Step: 1
Training loss: 0.5877045752066997
Validation loss: 2.711138583154406

Epoch: 5| Step: 2
Training loss: 1.7211316340463585
Validation loss: 2.7014037368571207

Epoch: 5| Step: 3
Training loss: 0.5352869918277439
Validation loss: 2.7256643934813822

Epoch: 5| Step: 4
Training loss: 0.6976258658940475
Validation loss: 2.715275991230014

Epoch: 5| Step: 5
Training loss: 0.6333197221004431
Validation loss: 2.6694445533357674

Epoch: 5| Step: 6
Training loss: 0.6423797301151487
Validation loss: 2.705377272534454

Epoch: 5| Step: 7
Training loss: 0.6996121285627693
Validation loss: 2.70705503349627

Epoch: 5| Step: 8
Training loss: 1.0660774366798713
Validation loss: 2.7087046197558697

Epoch: 5| Step: 9
Training loss: 0.6395264720388765
Validation loss: 2.6850817986263915

Epoch: 5| Step: 10
Training loss: 0.9762447603209649
Validation loss: 2.660698852619266

Epoch: 5| Step: 11
Training loss: 0.5919255535364977
Validation loss: 2.694052570370295

Epoch: 201| Step: 0
Training loss: 0.8618859109056509
Validation loss: 2.6871555721265525

Epoch: 5| Step: 1
Training loss: 0.5935044533804305
Validation loss: 2.7187425642533034

Epoch: 5| Step: 2
Training loss: 1.1110091732206115
Validation loss: 2.6837098875277343

Epoch: 5| Step: 3
Training loss: 0.9959723305095197
Validation loss: 2.6876681519178245

Epoch: 5| Step: 4
Training loss: 1.0343883617264171
Validation loss: 2.688001567404674

Epoch: 5| Step: 5
Training loss: 0.5078126760629202
Validation loss: 2.702120526326681

Epoch: 5| Step: 6
Training loss: 1.3324314981569911
Validation loss: 2.69850405382916

Epoch: 5| Step: 7
Training loss: 0.873018541665698
Validation loss: 2.7260038282610553

Epoch: 5| Step: 8
Training loss: 0.652167519161422
Validation loss: 2.745673688773362

Epoch: 5| Step: 9
Training loss: 0.84302072444343
Validation loss: 2.7043053323041435

Epoch: 5| Step: 10
Training loss: 0.9628503570493381
Validation loss: 2.742812332739189

Epoch: 5| Step: 11
Training loss: 0.6590038375829583
Validation loss: 2.572427353038619

Epoch: 202| Step: 0
Training loss: 0.9132080649233248
Validation loss: 2.6488045444666235

Epoch: 5| Step: 1
Training loss: 0.7848469898507111
Validation loss: 2.690178286973672

Epoch: 5| Step: 2
Training loss: 0.5839450274323935
Validation loss: 2.686491455420234

Epoch: 5| Step: 3
Training loss: 0.8493348127434072
Validation loss: 2.677707448462717

Epoch: 5| Step: 4
Training loss: 0.8150106666896649
Validation loss: 2.633652429522009

Epoch: 5| Step: 5
Training loss: 0.7664892029272431
Validation loss: 2.663492785082212

Epoch: 5| Step: 6
Training loss: 0.7584019364426835
Validation loss: 2.7164555364216425

Epoch: 5| Step: 7
Training loss: 1.4933365796400162
Validation loss: 2.6994309919267265

Epoch: 5| Step: 8
Training loss: 0.607564976753372
Validation loss: 2.674494673037993

Epoch: 5| Step: 9
Training loss: 0.9675599756798687
Validation loss: 2.720401795609008

Epoch: 5| Step: 10
Training loss: 0.9412342088446175
Validation loss: 2.760808561804819

Epoch: 5| Step: 11
Training loss: 0.4804358122165611
Validation loss: 2.7678054719780927

Epoch: 203| Step: 0
Training loss: 0.8839223181653358
Validation loss: 2.802444793946906

Epoch: 5| Step: 1
Training loss: 1.0503140797215857
Validation loss: 2.8005710240930117

Epoch: 5| Step: 2
Training loss: 0.8388883967710431
Validation loss: 2.692884123405505

Epoch: 5| Step: 3
Training loss: 0.9202691008044918
Validation loss: 2.7233817777114666

Epoch: 5| Step: 4
Training loss: 0.6624271226781476
Validation loss: 2.70344133308529

Epoch: 5| Step: 5
Training loss: 0.701945290073321
Validation loss: 2.735922450022948

Epoch: 5| Step: 6
Training loss: 1.1241412594023485
Validation loss: 2.676699029424785

Epoch: 5| Step: 7
Training loss: 0.9139086928117297
Validation loss: 2.6978324057088696

Epoch: 5| Step: 8
Training loss: 0.8109666220079318
Validation loss: 2.6480983453206988

Epoch: 5| Step: 9
Training loss: 1.0495099172827833
Validation loss: 2.6585744635321182

Epoch: 5| Step: 10
Training loss: 0.6640076782934493
Validation loss: 2.660217822198353

Epoch: 5| Step: 11
Training loss: 2.4596161701074726
Validation loss: 2.7671561591371194

Epoch: 204| Step: 0
Training loss: 0.9931935293801875
Validation loss: 2.7963104388623448

Epoch: 5| Step: 1
Training loss: 1.016540232337398
Validation loss: 2.791659829620036

Epoch: 5| Step: 2
Training loss: 0.8176803138613661
Validation loss: 2.7641956655232627

Epoch: 5| Step: 3
Training loss: 0.5752001569508297
Validation loss: 2.8091139402300676

Epoch: 5| Step: 4
Training loss: 0.88328613808948
Validation loss: 2.6779758670017215

Epoch: 5| Step: 5
Training loss: 1.2284632733808998
Validation loss: 2.7071643592948953

Epoch: 5| Step: 6
Training loss: 0.7514428723589082
Validation loss: 2.723976296875598

Epoch: 5| Step: 7
Training loss: 0.5564019210034274
Validation loss: 2.6511255799348836

Epoch: 5| Step: 8
Training loss: 0.9877769178518588
Validation loss: 2.689182664047178

Epoch: 5| Step: 9
Training loss: 0.9651934341399419
Validation loss: 2.7285115108399807

Epoch: 5| Step: 10
Training loss: 0.9411596394666034
Validation loss: 2.6509458765637075

Epoch: 5| Step: 11
Training loss: 1.390154684022371
Validation loss: 2.6490673152772866

Epoch: 205| Step: 0
Training loss: 0.888882521931045
Validation loss: 2.723019408311531

Epoch: 5| Step: 1
Training loss: 1.001137682345361
Validation loss: 2.7499016975403787

Epoch: 5| Step: 2
Training loss: 0.8482124507855523
Validation loss: 2.6712260211016488

Epoch: 5| Step: 3
Training loss: 0.7763552490851949
Validation loss: 2.73047652127493

Epoch: 5| Step: 4
Training loss: 1.2767827846634492
Validation loss: 2.699538002695335

Epoch: 5| Step: 5
Training loss: 0.8059421498644118
Validation loss: 2.700373713950226

Epoch: 5| Step: 6
Training loss: 0.5654385422719873
Validation loss: 2.716930931837165

Epoch: 5| Step: 7
Training loss: 0.9907961123004052
Validation loss: 2.6885360228991524

Epoch: 5| Step: 8
Training loss: 0.7142520394221035
Validation loss: 2.6935518678699224

Epoch: 5| Step: 9
Training loss: 0.7341524558003579
Validation loss: 2.747176118474995

Epoch: 5| Step: 10
Training loss: 0.962551002885073
Validation loss: 2.7768329807044143

Epoch: 5| Step: 11
Training loss: 0.9024549803772297
Validation loss: 2.669068571041438

Epoch: 206| Step: 0
Training loss: 0.7444729200732432
Validation loss: 2.806868265857828

Epoch: 5| Step: 1
Training loss: 0.8837049243983618
Validation loss: 2.6890249989665564

Epoch: 5| Step: 2
Training loss: 0.9303411221674196
Validation loss: 2.6735403232506187

Epoch: 5| Step: 3
Training loss: 0.9265207483878306
Validation loss: 2.6918086916968114

Epoch: 5| Step: 4
Training loss: 0.6894829935406713
Validation loss: 2.689116893501164

Epoch: 5| Step: 5
Training loss: 0.8075178055232157
Validation loss: 2.611590661123805

Epoch: 5| Step: 6
Training loss: 1.1274825361637528
Validation loss: 2.7054800494702813

Epoch: 5| Step: 7
Training loss: 0.7344849686769235
Validation loss: 2.682774758892722

Epoch: 5| Step: 8
Training loss: 0.8455940863462981
Validation loss: 2.7788605015688654

Epoch: 5| Step: 9
Training loss: 0.9067185275997696
Validation loss: 2.69130984181187

Epoch: 5| Step: 10
Training loss: 0.779446580317767
Validation loss: 2.6260881344684934

Epoch: 5| Step: 11
Training loss: 0.735770583611127
Validation loss: 2.678071820425862

Epoch: 207| Step: 0
Training loss: 0.5408258759504154
Validation loss: 2.629785792084742

Epoch: 5| Step: 1
Training loss: 1.2268533544044704
Validation loss: 2.649384095936086

Epoch: 5| Step: 2
Training loss: 1.2622837655743095
Validation loss: 2.698591948041045

Epoch: 5| Step: 3
Training loss: 0.6820257241286315
Validation loss: 2.671050868546017

Epoch: 5| Step: 4
Training loss: 0.8318612368252644
Validation loss: 2.7170260250699365

Epoch: 5| Step: 5
Training loss: 0.6556372961194943
Validation loss: 2.7373268905902313

Epoch: 5| Step: 6
Training loss: 0.7376253554927226
Validation loss: 2.693628302802722

Epoch: 5| Step: 7
Training loss: 0.6703014577387353
Validation loss: 2.6975785611850602

Epoch: 5| Step: 8
Training loss: 0.7677833341059171
Validation loss: 2.6676972615524774

Epoch: 5| Step: 9
Training loss: 0.6404012196162284
Validation loss: 2.6066925133605032

Epoch: 5| Step: 10
Training loss: 0.99405563380902
Validation loss: 2.7763934577542573

Epoch: 5| Step: 11
Training loss: 1.0897275254272358
Validation loss: 2.653006832664952

Epoch: 208| Step: 0
Training loss: 0.8043175374619642
Validation loss: 2.7302172740123782

Epoch: 5| Step: 1
Training loss: 1.3459999410450711
Validation loss: 2.739472903115839

Epoch: 5| Step: 2
Training loss: 0.6729696139792198
Validation loss: 2.789000527399514

Epoch: 5| Step: 3
Training loss: 0.6785133128986045
Validation loss: 2.7561729860106663

Epoch: 5| Step: 4
Training loss: 0.5376306951558656
Validation loss: 2.737141254439559

Epoch: 5| Step: 5
Training loss: 0.6567005926613118
Validation loss: 2.6689501363499217

Epoch: 5| Step: 6
Training loss: 1.000923326518799
Validation loss: 2.735016407897056

Epoch: 5| Step: 7
Training loss: 0.932121296807108
Validation loss: 2.7299791441925407

Epoch: 5| Step: 8
Training loss: 0.8806465043961218
Validation loss: 2.659150354002008

Epoch: 5| Step: 9
Training loss: 0.9403434864439476
Validation loss: 2.659514683582449

Epoch: 5| Step: 10
Training loss: 0.923359274092392
Validation loss: 2.6733724922497437

Epoch: 5| Step: 11
Training loss: 0.35532118280918606
Validation loss: 2.721787484211377

Epoch: 209| Step: 0
Training loss: 0.6460856565178414
Validation loss: 2.7222647237190065

Epoch: 5| Step: 1
Training loss: 0.628628639885754
Validation loss: 2.709773551258807

Epoch: 5| Step: 2
Training loss: 0.9395209464417467
Validation loss: 2.705844936641638

Epoch: 5| Step: 3
Training loss: 0.7773031482923798
Validation loss: 2.6974567048243054

Epoch: 5| Step: 4
Training loss: 0.8436313828342591
Validation loss: 2.6609259904757017

Epoch: 5| Step: 5
Training loss: 0.8726115666956428
Validation loss: 2.708761402681764

Epoch: 5| Step: 6
Training loss: 0.8694541794174702
Validation loss: 2.7185860069186996

Epoch: 5| Step: 7
Training loss: 0.7772272300611901
Validation loss: 2.7077085960426994

Epoch: 5| Step: 8
Training loss: 0.6845330896202643
Validation loss: 2.736573165896583

Epoch: 5| Step: 9
Training loss: 0.8779269039122654
Validation loss: 2.69263985114508

Epoch: 5| Step: 10
Training loss: 1.2380358816903176
Validation loss: 2.7061295725550507

Epoch: 5| Step: 11
Training loss: 0.510424017042316
Validation loss: 2.648074996430526

Epoch: 210| Step: 0
Training loss: 0.6592813145039473
Validation loss: 2.690906417342886

Epoch: 5| Step: 1
Training loss: 0.668887170645611
Validation loss: 2.698042573286123

Epoch: 5| Step: 2
Training loss: 0.7340531151026682
Validation loss: 2.7246688416986236

Epoch: 5| Step: 3
Training loss: 0.7569558719235155
Validation loss: 2.6408372677089296

Epoch: 5| Step: 4
Training loss: 0.6914665282099929
Validation loss: 2.6852230251290257

Epoch: 5| Step: 5
Training loss: 0.6961030644779406
Validation loss: 2.667085023686877

Epoch: 5| Step: 6
Training loss: 0.8334480723227905
Validation loss: 2.6946964684063275

Epoch: 5| Step: 7
Training loss: 1.2455372300067982
Validation loss: 2.719950359822983

Epoch: 5| Step: 8
Training loss: 0.712605416714522
Validation loss: 2.7774132363541826

Epoch: 5| Step: 9
Training loss: 1.0706540419007227
Validation loss: 2.7041490522397758

Epoch: 5| Step: 10
Training loss: 0.8341718190580597
Validation loss: 2.6899498818029084

Epoch: 5| Step: 11
Training loss: 0.4722448560566844
Validation loss: 2.6835617330048835

Epoch: 211| Step: 0
Training loss: 0.8385623826652832
Validation loss: 2.6303523952701617

Epoch: 5| Step: 1
Training loss: 0.6610306360803384
Validation loss: 2.696274862927889

Epoch: 5| Step: 2
Training loss: 0.5966032138397735
Validation loss: 2.73488050965173

Epoch: 5| Step: 3
Training loss: 0.8897765953974638
Validation loss: 2.709280278868493

Epoch: 5| Step: 4
Training loss: 1.1742614860143463
Validation loss: 2.662479873963226

Epoch: 5| Step: 5
Training loss: 0.40824964705391814
Validation loss: 2.7172908813745282

Epoch: 5| Step: 6
Training loss: 0.6291909373151506
Validation loss: 2.707048299569682

Epoch: 5| Step: 7
Training loss: 0.5740180151268913
Validation loss: 2.682109935245939

Epoch: 5| Step: 8
Training loss: 1.073741182462039
Validation loss: 2.6465992131954095

Epoch: 5| Step: 9
Training loss: 0.5901581892406386
Validation loss: 2.698883591567496

Epoch: 5| Step: 10
Training loss: 1.1185587756863369
Validation loss: 2.7455668986311017

Epoch: 5| Step: 11
Training loss: 0.7830070954241268
Validation loss: 2.6911215223234715

Epoch: 212| Step: 0
Training loss: 1.018146378191425
Validation loss: 2.5949811617890854

Epoch: 5| Step: 1
Training loss: 0.8779989348906919
Validation loss: 2.701508580808387

Epoch: 5| Step: 2
Training loss: 0.8202942619112806
Validation loss: 2.711061648879994

Epoch: 5| Step: 3
Training loss: 0.8877921980054198
Validation loss: 2.6261552395459935

Epoch: 5| Step: 4
Training loss: 0.7538690508426041
Validation loss: 2.6409709447993097

Epoch: 5| Step: 5
Training loss: 0.6405637060476564
Validation loss: 2.6699997528483244

Epoch: 5| Step: 6
Training loss: 0.7856165736921751
Validation loss: 2.7407493479004543

Epoch: 5| Step: 7
Training loss: 0.6686227508053522
Validation loss: 2.674362627045223

Epoch: 5| Step: 8
Training loss: 0.6268598302905475
Validation loss: 2.697738734874384

Epoch: 5| Step: 9
Training loss: 0.9841942091330583
Validation loss: 2.697817904948837

Epoch: 5| Step: 10
Training loss: 1.1782073783911562
Validation loss: 2.791846256505238

Epoch: 5| Step: 11
Training loss: 1.1823549239703268
Validation loss: 2.8039603428562168

Epoch: 213| Step: 0
Training loss: 1.3118936409609534
Validation loss: 2.748512779854518

Epoch: 5| Step: 1
Training loss: 0.6276289247771115
Validation loss: 2.7362144568225872

Epoch: 5| Step: 2
Training loss: 0.8718239499258474
Validation loss: 2.650720139636754

Epoch: 5| Step: 3
Training loss: 0.623715391823452
Validation loss: 2.708811275174637

Epoch: 5| Step: 4
Training loss: 0.8336131142795551
Validation loss: 2.7299846134462498

Epoch: 5| Step: 5
Training loss: 0.5969308177952225
Validation loss: 2.691358815934631

Epoch: 5| Step: 6
Training loss: 0.99560564835319
Validation loss: 2.6737286493686323

Epoch: 5| Step: 7
Training loss: 0.4966254801389004
Validation loss: 2.7334859074676534

Epoch: 5| Step: 8
Training loss: 0.7885004818103893
Validation loss: 2.6891682607159195

Epoch: 5| Step: 9
Training loss: 0.5787147400827969
Validation loss: 2.7045483636209022

Epoch: 5| Step: 10
Training loss: 0.7350348896387205
Validation loss: 2.7516728139524074

Epoch: 5| Step: 11
Training loss: 1.3009819357084844
Validation loss: 2.6677417165168675

Epoch: 214| Step: 0
Training loss: 1.1245240688266946
Validation loss: 2.7544920241971593

Epoch: 5| Step: 1
Training loss: 0.9392057160453758
Validation loss: 2.696783731271009

Epoch: 5| Step: 2
Training loss: 0.8273627533859983
Validation loss: 2.71135832262244

Epoch: 5| Step: 3
Training loss: 0.499394676240999
Validation loss: 2.746459044917179

Epoch: 5| Step: 4
Training loss: 0.877227094712703
Validation loss: 2.707848348965405

Epoch: 5| Step: 5
Training loss: 0.6269304978515182
Validation loss: 2.7170360285324473

Epoch: 5| Step: 6
Training loss: 0.8389447035407399
Validation loss: 2.7618032763547964

Epoch: 5| Step: 7
Training loss: 0.49015480702813763
Validation loss: 2.7482431789433726

Epoch: 5| Step: 8
Training loss: 0.5526452413880236
Validation loss: 2.68330469846749

Epoch: 5| Step: 9
Training loss: 0.6660663887433732
Validation loss: 2.7128299114042207

Epoch: 5| Step: 10
Training loss: 0.5961285182267537
Validation loss: 2.6944668793208555

Epoch: 5| Step: 11
Training loss: 1.274361491671927
Validation loss: 2.7152861493126053

Epoch: 215| Step: 0
Training loss: 0.7443376415496434
Validation loss: 2.6520925036739036

Epoch: 5| Step: 1
Training loss: 0.7916410257972238
Validation loss: 2.737821532226823

Epoch: 5| Step: 2
Training loss: 1.0799234289823074
Validation loss: 2.7998778740895527

Epoch: 5| Step: 3
Training loss: 0.8930634362456594
Validation loss: 2.6825460677503328

Epoch: 5| Step: 4
Training loss: 0.901261047528368
Validation loss: 2.7718648400706467

Epoch: 5| Step: 5
Training loss: 0.7314927374791503
Validation loss: 2.753250574285589

Epoch: 5| Step: 6
Training loss: 0.8107988080916938
Validation loss: 2.7027067290820597

Epoch: 5| Step: 7
Training loss: 0.6919454637947301
Validation loss: 2.7368769107860427

Epoch: 5| Step: 8
Training loss: 0.6050585680190481
Validation loss: 2.7346450200045602

Epoch: 5| Step: 9
Training loss: 0.8158842909669503
Validation loss: 2.718608958506557

Epoch: 5| Step: 10
Training loss: 0.5246925964017076
Validation loss: 2.7374657411042853

Epoch: 5| Step: 11
Training loss: 0.5195615372398191
Validation loss: 2.7337731053161294

Epoch: 216| Step: 0
Training loss: 1.3102660922987623
Validation loss: 2.7498506953427753

Epoch: 5| Step: 1
Training loss: 0.5477571457066386
Validation loss: 2.722183617060778

Epoch: 5| Step: 2
Training loss: 0.938810672094639
Validation loss: 2.701848226528274

Epoch: 5| Step: 3
Training loss: 0.5843830087694333
Validation loss: 2.6572914568907087

Epoch: 5| Step: 4
Training loss: 0.81591760348866
Validation loss: 2.701063627003467

Epoch: 5| Step: 5
Training loss: 0.8855581207974798
Validation loss: 2.765293512755168

Epoch: 5| Step: 6
Training loss: 0.6439013553202857
Validation loss: 2.700512183729474

Epoch: 5| Step: 7
Training loss: 0.77513764143578
Validation loss: 2.7356076831660276

Epoch: 5| Step: 8
Training loss: 0.576230346816214
Validation loss: 2.688074531060709

Epoch: 5| Step: 9
Training loss: 0.6995879322814942
Validation loss: 2.69451556379531

Epoch: 5| Step: 10
Training loss: 0.7573606579472952
Validation loss: 2.6704622255346466

Epoch: 5| Step: 11
Training loss: 0.8350720426466597
Validation loss: 2.713431428706788

Epoch: 217| Step: 0
Training loss: 0.6699176487914481
Validation loss: 2.6851792961332506

Epoch: 5| Step: 1
Training loss: 0.8798088355936877
Validation loss: 2.664018845037347

Epoch: 5| Step: 2
Training loss: 0.7944141612990961
Validation loss: 2.716155100020599

Epoch: 5| Step: 3
Training loss: 0.5644940160175697
Validation loss: 2.685447940738024

Epoch: 5| Step: 4
Training loss: 0.5847167459061825
Validation loss: 2.718979401976792

Epoch: 5| Step: 5
Training loss: 1.0297421500214026
Validation loss: 2.6809768725861676

Epoch: 5| Step: 6
Training loss: 0.7869929755308183
Validation loss: 2.720845197084119

Epoch: 5| Step: 7
Training loss: 0.6457057539741551
Validation loss: 2.704969225365853

Epoch: 5| Step: 8
Training loss: 0.5746184793732573
Validation loss: 2.756896146809794

Epoch: 5| Step: 9
Training loss: 1.2587964965506093
Validation loss: 2.632748822839196

Epoch: 5| Step: 10
Training loss: 0.7589136755306899
Validation loss: 2.710185266322741

Epoch: 5| Step: 11
Training loss: 1.2434323389215154
Validation loss: 2.6837184012687416

Epoch: 218| Step: 0
Training loss: 1.0793820115984332
Validation loss: 2.7413592921855816

Epoch: 5| Step: 1
Training loss: 0.6537038136536579
Validation loss: 2.6784618381000813

Epoch: 5| Step: 2
Training loss: 0.9384387720221995
Validation loss: 2.6961930205010685

Epoch: 5| Step: 3
Training loss: 0.7323863109855221
Validation loss: 2.665976391551357

Epoch: 5| Step: 4
Training loss: 0.9632713694812106
Validation loss: 2.7228726775788115

Epoch: 5| Step: 5
Training loss: 0.6508044281091433
Validation loss: 2.664792314202825

Epoch: 5| Step: 6
Training loss: 1.1481790576184434
Validation loss: 2.6595006798744945

Epoch: 5| Step: 7
Training loss: 0.6502178753151976
Validation loss: 2.756862631693438

Epoch: 5| Step: 8
Training loss: 0.7749587232611063
Validation loss: 2.7247220798822136

Epoch: 5| Step: 9
Training loss: 0.5037433153849574
Validation loss: 2.7177909387209365

Epoch: 5| Step: 10
Training loss: 0.5509828509675396
Validation loss: 2.6780991402041137

Epoch: 5| Step: 11
Training loss: 0.7138560825219954
Validation loss: 2.694544361141961

Epoch: 219| Step: 0
Training loss: 0.5802835685079277
Validation loss: 2.705513415333722

Epoch: 5| Step: 1
Training loss: 0.47611700403695606
Validation loss: 2.7161420942203365

Epoch: 5| Step: 2
Training loss: 0.6386438299431896
Validation loss: 2.660992633265587

Epoch: 5| Step: 3
Training loss: 0.855713343382102
Validation loss: 2.6829699957920257

Epoch: 5| Step: 4
Training loss: 0.658650435862422
Validation loss: 2.7162676802479786

Epoch: 5| Step: 5
Training loss: 0.8728261237578467
Validation loss: 2.735589231920057

Epoch: 5| Step: 6
Training loss: 0.7910335209081907
Validation loss: 2.8035981303850517

Epoch: 5| Step: 7
Training loss: 0.8702183588637835
Validation loss: 2.691873248757858

Epoch: 5| Step: 8
Training loss: 1.0599798158307387
Validation loss: 2.637816250177815

Epoch: 5| Step: 9
Training loss: 0.7138182157530295
Validation loss: 2.6706273919471335

Epoch: 5| Step: 10
Training loss: 0.9069650394216716
Validation loss: 2.788181931713167

Epoch: 5| Step: 11
Training loss: 0.5931869648119202
Validation loss: 2.686630496488779

Epoch: 220| Step: 0
Training loss: 1.0186235618529664
Validation loss: 2.6946845055560957

Epoch: 5| Step: 1
Training loss: 0.9540630164896282
Validation loss: 2.751407342652359

Epoch: 5| Step: 2
Training loss: 0.731345155833663
Validation loss: 2.74178876088035

Epoch: 5| Step: 3
Training loss: 0.6246495694986391
Validation loss: 2.675885096852899

Epoch: 5| Step: 4
Training loss: 1.051387342627959
Validation loss: 2.7015480373533047

Epoch: 5| Step: 5
Training loss: 0.5509178587408656
Validation loss: 2.7706775490031093

Epoch: 5| Step: 6
Training loss: 0.7634068490182615
Validation loss: 2.7125083044250218

Epoch: 5| Step: 7
Training loss: 0.5236441930084105
Validation loss: 2.66915435660941

Epoch: 5| Step: 8
Training loss: 0.6049415015478375
Validation loss: 2.726980605399297

Epoch: 5| Step: 9
Training loss: 0.9505701061001909
Validation loss: 2.7076119354688015

Epoch: 5| Step: 10
Training loss: 0.7029696186888704
Validation loss: 2.679644477728724

Epoch: 5| Step: 11
Training loss: 0.6412707539968127
Validation loss: 2.7006353147416116

Epoch: 221| Step: 0
Training loss: 0.7962276971229656
Validation loss: 2.7216666095493807

Epoch: 5| Step: 1
Training loss: 0.7229846105243553
Validation loss: 2.6944168371794093

Epoch: 5| Step: 2
Training loss: 0.7470586638695607
Validation loss: 2.726429404988006

Epoch: 5| Step: 3
Training loss: 0.4886756219880327
Validation loss: 2.6565130215739794

Epoch: 5| Step: 4
Training loss: 0.9258911453884985
Validation loss: 2.693335171803549

Epoch: 5| Step: 5
Training loss: 0.547841498678594
Validation loss: 2.710568713517867

Epoch: 5| Step: 6
Training loss: 0.5655058445480896
Validation loss: 2.6966592823979765

Epoch: 5| Step: 7
Training loss: 0.9244270238364624
Validation loss: 2.658267758247257

Epoch: 5| Step: 8
Training loss: 0.45301195905070046
Validation loss: 2.633289795728909

Epoch: 5| Step: 9
Training loss: 0.4903148873771279
Validation loss: 2.6399891706687684

Epoch: 5| Step: 10
Training loss: 1.091051423837299
Validation loss: 2.6648872046132195

Epoch: 5| Step: 11
Training loss: 0.8036630275532645
Validation loss: 2.7412412519673413

Epoch: 222| Step: 0
Training loss: 0.7628487836748188
Validation loss: 2.730562131173551

Epoch: 5| Step: 1
Training loss: 0.8710463985693835
Validation loss: 2.7032374981529625

Epoch: 5| Step: 2
Training loss: 0.8702788711159744
Validation loss: 2.681917021182242

Epoch: 5| Step: 3
Training loss: 0.7040315082635422
Validation loss: 2.733313174483542

Epoch: 5| Step: 4
Training loss: 0.7414534703483144
Validation loss: 2.736011113734706

Epoch: 5| Step: 5
Training loss: 1.0344294461675532
Validation loss: 2.7120776898064625

Epoch: 5| Step: 6
Training loss: 0.5954027262720409
Validation loss: 2.741266151980181

Epoch: 5| Step: 7
Training loss: 0.8229173628083838
Validation loss: 2.70251803851158

Epoch: 5| Step: 8
Training loss: 0.5501823415638989
Validation loss: 2.696382986328206

Epoch: 5| Step: 9
Training loss: 0.6416237187152601
Validation loss: 2.748134880039482

Epoch: 5| Step: 10
Training loss: 0.8102017690586052
Validation loss: 2.7368410162112737

Epoch: 5| Step: 11
Training loss: 0.5919864212505407
Validation loss: 2.7340527081151618

Epoch: 223| Step: 0
Training loss: 0.7241693276143177
Validation loss: 2.6955239881019977

Epoch: 5| Step: 1
Training loss: 0.603171833967323
Validation loss: 2.6759948014110004

Epoch: 5| Step: 2
Training loss: 0.7986227205142157
Validation loss: 2.7529473369024053

Epoch: 5| Step: 3
Training loss: 0.6083800189075952
Validation loss: 2.719277754529265

Epoch: 5| Step: 4
Training loss: 0.6985589862621464
Validation loss: 2.703164510125801

Epoch: 5| Step: 5
Training loss: 0.7493106137343511
Validation loss: 2.7849523604328903

Epoch: 5| Step: 6
Training loss: 0.7898169961052566
Validation loss: 2.707352637973921

Epoch: 5| Step: 7
Training loss: 0.42131655430480586
Validation loss: 2.704689572702808

Epoch: 5| Step: 8
Training loss: 1.2051629974797538
Validation loss: 2.6637442390311574

Epoch: 5| Step: 9
Training loss: 0.7865807057010207
Validation loss: 2.759176855148158

Epoch: 5| Step: 10
Training loss: 0.8615379856345413
Validation loss: 2.6983305504387713

Epoch: 5| Step: 11
Training loss: 0.5969426501218394
Validation loss: 2.7116235933026593

Epoch: 224| Step: 0
Training loss: 0.6655311052603716
Validation loss: 2.6669951301185058

Epoch: 5| Step: 1
Training loss: 0.4428982626457789
Validation loss: 2.737556205532501

Epoch: 5| Step: 2
Training loss: 0.6591652197486375
Validation loss: 2.6696882203821652

Epoch: 5| Step: 3
Training loss: 0.7031217151141258
Validation loss: 2.6538866412381936

Epoch: 5| Step: 4
Training loss: 0.8168437825712299
Validation loss: 2.695031292385112

Epoch: 5| Step: 5
Training loss: 0.5125217398242691
Validation loss: 2.7100667993528686

Epoch: 5| Step: 6
Training loss: 1.1131987959460135
Validation loss: 2.7429682352892564

Epoch: 5| Step: 7
Training loss: 0.6141119512394221
Validation loss: 2.6939898613498485

Epoch: 5| Step: 8
Training loss: 0.9178012776297553
Validation loss: 2.6992703040463053

Epoch: 5| Step: 9
Training loss: 0.8265380408664929
Validation loss: 2.639763938116524

Epoch: 5| Step: 10
Training loss: 0.7147518995299155
Validation loss: 2.685883017108157

Epoch: 5| Step: 11
Training loss: 0.7717869418798889
Validation loss: 2.6921085056044594

Epoch: 225| Step: 0
Training loss: 1.0068574268552677
Validation loss: 2.7075704062440136

Epoch: 5| Step: 1
Training loss: 0.64066793716568
Validation loss: 2.759072355505613

Epoch: 5| Step: 2
Training loss: 0.7702440552548631
Validation loss: 2.7583021750423824

Epoch: 5| Step: 3
Training loss: 0.7111560359893663
Validation loss: 2.8426844343665088

Epoch: 5| Step: 4
Training loss: 0.6518647268259338
Validation loss: 2.751803872162983

Epoch: 5| Step: 5
Training loss: 0.6191520328854637
Validation loss: 2.6694765126450863

Epoch: 5| Step: 6
Training loss: 0.5595840532303433
Validation loss: 2.7035181424822268

Epoch: 5| Step: 7
Training loss: 1.0662353714076953
Validation loss: 2.7128065959970318

Epoch: 5| Step: 8
Training loss: 0.8897937442437023
Validation loss: 2.6825099387137343

Epoch: 5| Step: 9
Training loss: 0.8569685795698312
Validation loss: 2.7151393519046927

Epoch: 5| Step: 10
Training loss: 0.664664500510698
Validation loss: 2.6537416414005546

Epoch: 5| Step: 11
Training loss: 0.4316513267329672
Validation loss: 2.724507053509395

Epoch: 226| Step: 0
Training loss: 0.8574705001494549
Validation loss: 2.6973643836140972

Epoch: 5| Step: 1
Training loss: 0.7725278340729345
Validation loss: 2.708084580417453

Epoch: 5| Step: 2
Training loss: 0.7014021004060982
Validation loss: 2.732180804947215

Epoch: 5| Step: 3
Training loss: 0.8810997949924908
Validation loss: 2.80466502259438

Epoch: 5| Step: 4
Training loss: 0.9285822156394848
Validation loss: 2.8310182851324166

Epoch: 5| Step: 5
Training loss: 0.5348528259380995
Validation loss: 2.703542508055629

Epoch: 5| Step: 6
Training loss: 0.47295456922057877
Validation loss: 2.6807942787881465

Epoch: 5| Step: 7
Training loss: 0.8011100652204056
Validation loss: 2.702696205777874

Epoch: 5| Step: 8
Training loss: 0.5991853587807751
Validation loss: 2.7332287738347674

Epoch: 5| Step: 9
Training loss: 0.5222834490614102
Validation loss: 2.714613552076569

Epoch: 5| Step: 10
Training loss: 1.1384246191300798
Validation loss: 2.691982072965589

Epoch: 5| Step: 11
Training loss: 0.5069490280844114
Validation loss: 2.732482611358589

Epoch: 227| Step: 0
Training loss: 0.7660258664502337
Validation loss: 2.6982160068327468

Epoch: 5| Step: 1
Training loss: 0.7980474560735962
Validation loss: 2.689804719037357

Epoch: 5| Step: 2
Training loss: 0.6584126849176213
Validation loss: 2.778370370173683

Epoch: 5| Step: 3
Training loss: 0.5841102336892233
Validation loss: 2.781953433372444

Epoch: 5| Step: 4
Training loss: 0.6271847210999771
Validation loss: 2.785420947807482

Epoch: 5| Step: 5
Training loss: 0.6727805577698545
Validation loss: 2.7753415122396925

Epoch: 5| Step: 6
Training loss: 0.6916951583447991
Validation loss: 2.756627736983358

Epoch: 5| Step: 7
Training loss: 0.6103138660233969
Validation loss: 2.7007716487603144

Epoch: 5| Step: 8
Training loss: 1.1090701046895497
Validation loss: 2.6801208835177177

Epoch: 5| Step: 9
Training loss: 0.665853217675075
Validation loss: 2.732783968212908

Epoch: 5| Step: 10
Training loss: 0.5202845225100934
Validation loss: 2.734134856078444

Epoch: 5| Step: 11
Training loss: 0.8990083953838824
Validation loss: 2.7213968021149753

Epoch: 228| Step: 0
Training loss: 0.3709996154248488
Validation loss: 2.7079852002705325

Epoch: 5| Step: 1
Training loss: 0.6996910588530467
Validation loss: 2.6970031964188

Epoch: 5| Step: 2
Training loss: 0.896841306419025
Validation loss: 2.754453773269442

Epoch: 5| Step: 3
Training loss: 0.6417112909835102
Validation loss: 2.802271554196118

Epoch: 5| Step: 4
Training loss: 0.6364123069199599
Validation loss: 2.712283204463943

Epoch: 5| Step: 5
Training loss: 0.8187439590697162
Validation loss: 2.707948757646121

Epoch: 5| Step: 6
Training loss: 0.9513280846006101
Validation loss: 2.758111622323595

Epoch: 5| Step: 7
Training loss: 0.8304802492768473
Validation loss: 2.6486804779431807

Epoch: 5| Step: 8
Training loss: 0.5221454273764096
Validation loss: 2.741331001119404

Epoch: 5| Step: 9
Training loss: 0.6140927091355481
Validation loss: 2.7997296148834776

Epoch: 5| Step: 10
Training loss: 0.7908890234335633
Validation loss: 2.6756561361424605

Epoch: 5| Step: 11
Training loss: 0.478502483576724
Validation loss: 2.7713504406730056

Epoch: 229| Step: 0
Training loss: 0.6299358493447593
Validation loss: 2.754893031885087

Epoch: 5| Step: 1
Training loss: 0.6904197810863849
Validation loss: 2.730888447229146

Epoch: 5| Step: 2
Training loss: 0.48962020397004236
Validation loss: 2.734915605419208

Epoch: 5| Step: 3
Training loss: 0.6420609268233073
Validation loss: 2.758596501564649

Epoch: 5| Step: 4
Training loss: 0.8986953033760047
Validation loss: 2.7684924567762104

Epoch: 5| Step: 5
Training loss: 0.635235820633033
Validation loss: 2.7124834590471987

Epoch: 5| Step: 6
Training loss: 0.6544065013542729
Validation loss: 2.6502785899115926

Epoch: 5| Step: 7
Training loss: 1.0333779084425525
Validation loss: 2.677581196565066

Epoch: 5| Step: 8
Training loss: 1.0027174980547369
Validation loss: 2.7155945944830653

Epoch: 5| Step: 9
Training loss: 0.6293811545123179
Validation loss: 2.704858213223717

Epoch: 5| Step: 10
Training loss: 0.7066012386819179
Validation loss: 2.69882472355486

Epoch: 5| Step: 11
Training loss: 1.1859046358523093
Validation loss: 2.7478052325401885

Epoch: 230| Step: 0
Training loss: 0.7552430155891084
Validation loss: 2.6968179156707057

Epoch: 5| Step: 1
Training loss: 0.8369434756582061
Validation loss: 2.726239845691901

Epoch: 5| Step: 2
Training loss: 0.43660021966442886
Validation loss: 2.793180186486959

Epoch: 5| Step: 3
Training loss: 0.5811173092732598
Validation loss: 2.7683800625995865

Epoch: 5| Step: 4
Training loss: 0.9532698224215427
Validation loss: 2.739449974024522

Epoch: 5| Step: 5
Training loss: 0.5865129823670636
Validation loss: 2.6806952321244464

Epoch: 5| Step: 6
Training loss: 0.548153282488489
Validation loss: 2.7526351556444086

Epoch: 5| Step: 7
Training loss: 1.0174488417490468
Validation loss: 2.702012264863185

Epoch: 5| Step: 8
Training loss: 1.0099397431707573
Validation loss: 2.7046000768620915

Epoch: 5| Step: 9
Training loss: 0.6428682084115145
Validation loss: 2.75663571920594

Epoch: 5| Step: 10
Training loss: 0.5364582901247865
Validation loss: 2.7864701077696736

Epoch: 5| Step: 11
Training loss: 0.4331747556569358
Validation loss: 2.7072785499864613

Epoch: 231| Step: 0
Training loss: 0.5594569119625039
Validation loss: 2.711110449412618

Epoch: 5| Step: 1
Training loss: 1.0876939140279325
Validation loss: 2.7414679710852092

Epoch: 5| Step: 2
Training loss: 0.8664603406499634
Validation loss: 2.7486184941606493

Epoch: 5| Step: 3
Training loss: 0.6182109941502114
Validation loss: 2.6829946664569255

Epoch: 5| Step: 4
Training loss: 0.7697822819724037
Validation loss: 2.689321285240043

Epoch: 5| Step: 5
Training loss: 0.7232657259521335
Validation loss: 2.681221521962888

Epoch: 5| Step: 6
Training loss: 0.672963391936552
Validation loss: 2.7321820539001127

Epoch: 5| Step: 7
Training loss: 0.7013837871324002
Validation loss: 2.6870213755155006

Epoch: 5| Step: 8
Training loss: 0.7173481829786085
Validation loss: 2.747631599229643

Epoch: 5| Step: 9
Training loss: 0.9504390141358477
Validation loss: 2.796714739052911

Epoch: 5| Step: 10
Training loss: 0.5693868153054877
Validation loss: 2.819621092070586

Epoch: 5| Step: 11
Training loss: 0.33106708784707134
Validation loss: 2.80609111321929

Epoch: 232| Step: 0
Training loss: 0.6763143696707572
Validation loss: 2.8265691028557915

Epoch: 5| Step: 1
Training loss: 1.0012322224956842
Validation loss: 2.7477365845928974

Epoch: 5| Step: 2
Training loss: 0.45316133682303306
Validation loss: 2.7643661759175533

Epoch: 5| Step: 3
Training loss: 0.6938116398482905
Validation loss: 2.697510885164243

Epoch: 5| Step: 4
Training loss: 0.7295260951321061
Validation loss: 2.8003242825722583

Epoch: 5| Step: 5
Training loss: 0.5888530925626444
Validation loss: 2.705919049196388

Epoch: 5| Step: 6
Training loss: 0.8195874234013268
Validation loss: 2.6738298879152724

Epoch: 5| Step: 7
Training loss: 0.6268419779240864
Validation loss: 2.8161404290678616

Epoch: 5| Step: 8
Training loss: 0.7137504513500277
Validation loss: 2.7367014697189345

Epoch: 5| Step: 9
Training loss: 0.6415696506315435
Validation loss: 2.644837155626382

Epoch: 5| Step: 10
Training loss: 0.5943436666306369
Validation loss: 2.760213046691204

Epoch: 5| Step: 11
Training loss: 0.21038165855636629
Validation loss: 2.7599245904385468

Epoch: 233| Step: 0
Training loss: 0.6166807822811398
Validation loss: 2.687200122928853

Epoch: 5| Step: 1
Training loss: 1.0397925429486023
Validation loss: 2.7537445742356983

Epoch: 5| Step: 2
Training loss: 0.8899401993430962
Validation loss: 2.7889050992259863

Epoch: 5| Step: 3
Training loss: 0.7929412761871031
Validation loss: 2.7610754660428665

Epoch: 5| Step: 4
Training loss: 0.9766307044053668
Validation loss: 2.7350352552816135

Epoch: 5| Step: 5
Training loss: 0.5756688912854323
Validation loss: 2.7687017062003205

Epoch: 5| Step: 6
Training loss: 0.696615690901877
Validation loss: 2.7784013196670205

Epoch: 5| Step: 7
Training loss: 0.6920455089485932
Validation loss: 2.667567197295319

Epoch: 5| Step: 8
Training loss: 0.6457327769556445
Validation loss: 2.7746242115530446

Epoch: 5| Step: 9
Training loss: 0.5382207296645468
Validation loss: 2.7254888466454195

Epoch: 5| Step: 10
Training loss: 0.5521746116131462
Validation loss: 2.7501170231022183

Epoch: 5| Step: 11
Training loss: 0.8883556432111371
Validation loss: 2.8059992861598424

Epoch: 234| Step: 0
Training loss: 0.561867384683942
Validation loss: 2.694301279160092

Epoch: 5| Step: 1
Training loss: 0.528502286642608
Validation loss: 2.7530974983923002

Epoch: 5| Step: 2
Training loss: 0.5774549261065516
Validation loss: 2.775777200598733

Epoch: 5| Step: 3
Training loss: 0.5188651152505284
Validation loss: 2.688187577761606

Epoch: 5| Step: 4
Training loss: 1.1528707042962731
Validation loss: 2.7562899434546564

Epoch: 5| Step: 5
Training loss: 0.6461340655257096
Validation loss: 2.7670029765173854

Epoch: 5| Step: 6
Training loss: 0.4930444855708416
Validation loss: 2.7397404082973593

Epoch: 5| Step: 7
Training loss: 0.5727414181023472
Validation loss: 2.763480668030395

Epoch: 5| Step: 8
Training loss: 0.8307727375781798
Validation loss: 2.7890390881322453

Epoch: 5| Step: 9
Training loss: 0.8478875262215148
Validation loss: 2.727492180337253

Epoch: 5| Step: 10
Training loss: 0.6048026820445638
Validation loss: 2.776162852826426

Epoch: 5| Step: 11
Training loss: 0.7855929398652572
Validation loss: 2.7253439948614657

Epoch: 235| Step: 0
Training loss: 0.5569335434492377
Validation loss: 2.7413582521579607

Epoch: 5| Step: 1
Training loss: 0.724168751460836
Validation loss: 2.786831944217096

Epoch: 5| Step: 2
Training loss: 0.9985825506402138
Validation loss: 2.742805581566723

Epoch: 5| Step: 3
Training loss: 0.47538596458940396
Validation loss: 2.6909058488159756

Epoch: 5| Step: 4
Training loss: 0.6409718342200478
Validation loss: 2.7001461969637353

Epoch: 5| Step: 5
Training loss: 0.7231902752612779
Validation loss: 2.726365622450699

Epoch: 5| Step: 6
Training loss: 0.6750608363816661
Validation loss: 2.7711427642499746

Epoch: 5| Step: 7
Training loss: 0.623610095462477
Validation loss: 2.7270607952957455

Epoch: 5| Step: 8
Training loss: 0.9825733591312783
Validation loss: 2.7542938608951872

Epoch: 5| Step: 9
Training loss: 0.7574239304875168
Validation loss: 2.700663303797215

Epoch: 5| Step: 10
Training loss: 0.49456792758685697
Validation loss: 2.7835165282358827

Epoch: 5| Step: 11
Training loss: 0.6365965509460261
Validation loss: 2.7924305323888214

Epoch: 236| Step: 0
Training loss: 0.8738443713325622
Validation loss: 2.6559801937031677

Epoch: 5| Step: 1
Training loss: 0.6297937374562568
Validation loss: 2.7038439637962193

Epoch: 5| Step: 2
Training loss: 0.6865143429410168
Validation loss: 2.827775568301302

Epoch: 5| Step: 3
Training loss: 0.7839826096313854
Validation loss: 2.807299432879424

Epoch: 5| Step: 4
Training loss: 0.7697500314839509
Validation loss: 2.7263743855783784

Epoch: 5| Step: 5
Training loss: 0.6944906757118785
Validation loss: 2.7171658837349018

Epoch: 5| Step: 6
Training loss: 0.5778931848898115
Validation loss: 2.7235144052245337

Epoch: 5| Step: 7
Training loss: 0.6587800799746166
Validation loss: 2.719738893692123

Epoch: 5| Step: 8
Training loss: 0.694654903839755
Validation loss: 2.711847839535957

Epoch: 5| Step: 9
Training loss: 1.0421968382455629
Validation loss: 2.7668310793508675

Epoch: 5| Step: 10
Training loss: 0.5318095402045134
Validation loss: 2.739293309127369

Epoch: 5| Step: 11
Training loss: 0.30846785138029925
Validation loss: 2.8011952780956726

Epoch: 237| Step: 0
Training loss: 0.6766386161081117
Validation loss: 2.758510656121766

Epoch: 5| Step: 1
Training loss: 0.8173407358074962
Validation loss: 2.723430631055867

Epoch: 5| Step: 2
Training loss: 0.6014253286545133
Validation loss: 2.7628665249395143

Epoch: 5| Step: 3
Training loss: 0.7430587473371966
Validation loss: 2.8205933928513214

Epoch: 5| Step: 4
Training loss: 0.8659132797615023
Validation loss: 2.6933723690981854

Epoch: 5| Step: 5
Training loss: 0.4673280925417195
Validation loss: 2.7627235573863897

Epoch: 5| Step: 6
Training loss: 0.7618545020008303
Validation loss: 2.656764014381842

Epoch: 5| Step: 7
Training loss: 1.0969478180887828
Validation loss: 2.7792935794713385

Epoch: 5| Step: 8
Training loss: 0.9065280356261579
Validation loss: 2.6779117502294314

Epoch: 5| Step: 9
Training loss: 0.6053369440156254
Validation loss: 2.7999258575103165

Epoch: 5| Step: 10
Training loss: 0.6659578091313975
Validation loss: 2.7702878842996683

Epoch: 5| Step: 11
Training loss: 0.6468924533866713
Validation loss: 2.7707398525521354

Epoch: 238| Step: 0
Training loss: 0.6114728469902435
Validation loss: 2.7523738195686263

Epoch: 5| Step: 1
Training loss: 0.6291680827556446
Validation loss: 2.6829723951102316

Epoch: 5| Step: 2
Training loss: 0.7041920300906201
Validation loss: 2.711409173217668

Epoch: 5| Step: 3
Training loss: 0.700414285510129
Validation loss: 2.745900729302087

Epoch: 5| Step: 4
Training loss: 0.4729332545672042
Validation loss: 2.6788300605827824

Epoch: 5| Step: 5
Training loss: 0.6120080061806474
Validation loss: 2.667694632512284

Epoch: 5| Step: 6
Training loss: 1.1019506108939217
Validation loss: 2.7363857578159467

Epoch: 5| Step: 7
Training loss: 0.7691498794115155
Validation loss: 2.790082088001182

Epoch: 5| Step: 8
Training loss: 0.9510374189590463
Validation loss: 2.7517851937800604

Epoch: 5| Step: 9
Training loss: 0.8537759274836613
Validation loss: 2.819160476226355

Epoch: 5| Step: 10
Training loss: 0.6446292687068175
Validation loss: 2.719397858640735

Epoch: 5| Step: 11
Training loss: 1.025022197110876
Validation loss: 2.860098443293321

Epoch: 239| Step: 0
Training loss: 0.4871496439351344
Validation loss: 2.7299438066544703

Epoch: 5| Step: 1
Training loss: 0.5571820754441299
Validation loss: 2.6995348894738314

Epoch: 5| Step: 2
Training loss: 0.71580540744309
Validation loss: 2.720575512670315

Epoch: 5| Step: 3
Training loss: 0.7228977521534508
Validation loss: 2.7008406812333865

Epoch: 5| Step: 4
Training loss: 0.741096940151348
Validation loss: 2.7332610540651188

Epoch: 5| Step: 5
Training loss: 1.0776969502205096
Validation loss: 2.7281832209226677

Epoch: 5| Step: 6
Training loss: 0.8435105937819377
Validation loss: 2.6707408684204217

Epoch: 5| Step: 7
Training loss: 0.6220419501481718
Validation loss: 2.6991904147289896

Epoch: 5| Step: 8
Training loss: 0.7354549016189699
Validation loss: 2.7220557000654213

Epoch: 5| Step: 9
Training loss: 0.4944348872644576
Validation loss: 2.7399097485076482

Epoch: 5| Step: 10
Training loss: 0.5838341408073394
Validation loss: 2.747303088221248

Epoch: 5| Step: 11
Training loss: 0.825573571543227
Validation loss: 2.67072568122028

Epoch: 240| Step: 0
Training loss: 0.7994421205832213
Validation loss: 2.676112735012981

Epoch: 5| Step: 1
Training loss: 0.4869489116416039
Validation loss: 2.7032271018618217

Epoch: 5| Step: 2
Training loss: 0.5806038269354425
Validation loss: 2.7585775270635917

Epoch: 5| Step: 3
Training loss: 0.8928943966859226
Validation loss: 2.735801197682057

Epoch: 5| Step: 4
Training loss: 0.7573099731443454
Validation loss: 2.7365112915016367

Epoch: 5| Step: 5
Training loss: 0.7282668192525741
Validation loss: 2.6681915718888622

Epoch: 5| Step: 6
Training loss: 0.5970856679252705
Validation loss: 2.7141394088000266

Epoch: 5| Step: 7
Training loss: 0.8991899407856707
Validation loss: 2.70341523583995

Epoch: 5| Step: 8
Training loss: 0.5692510525220842
Validation loss: 2.692969235164819

Epoch: 5| Step: 9
Training loss: 0.6929663390383233
Validation loss: 2.7429846631049104

Epoch: 5| Step: 10
Training loss: 0.9427288467676334
Validation loss: 2.675759386404889

Epoch: 5| Step: 11
Training loss: 0.48230448541708837
Validation loss: 2.76143410963564

Epoch: 241| Step: 0
Training loss: 0.6218816689751894
Validation loss: 2.6720300224201297

Epoch: 5| Step: 1
Training loss: 0.906809995544328
Validation loss: 2.7676252541918465

Epoch: 5| Step: 2
Training loss: 0.455958060048753
Validation loss: 2.7753358639122854

Epoch: 5| Step: 3
Training loss: 0.6536496961461757
Validation loss: 2.7300184003095747

Epoch: 5| Step: 4
Training loss: 0.9046629459297093
Validation loss: 2.729336399643711

Epoch: 5| Step: 5
Training loss: 0.974793472179663
Validation loss: 2.6906058565906807

Epoch: 5| Step: 6
Training loss: 0.5753789585896424
Validation loss: 2.685372386465695

Epoch: 5| Step: 7
Training loss: 0.770372386097903
Validation loss: 2.6982286977321435

Epoch: 5| Step: 8
Training loss: 0.538875934547812
Validation loss: 2.6296119252959826

Epoch: 5| Step: 9
Training loss: 0.5335988403345601
Validation loss: 2.7776052545907417

Epoch: 5| Step: 10
Training loss: 0.5405753647615011
Validation loss: 2.7000890893719887

Epoch: 5| Step: 11
Training loss: 0.49716861554719854
Validation loss: 2.7025943025673755

Epoch: 242| Step: 0
Training loss: 0.6683368672382916
Validation loss: 2.7954727294670665

Epoch: 5| Step: 1
Training loss: 0.6482755849521318
Validation loss: 2.7914902550674534

Epoch: 5| Step: 2
Training loss: 0.4519950656009659
Validation loss: 2.772717644843054

Epoch: 5| Step: 3
Training loss: 1.105894296647865
Validation loss: 2.7771618618537737

Epoch: 5| Step: 4
Training loss: 0.7572181966859176
Validation loss: 2.803248384241693

Epoch: 5| Step: 5
Training loss: 0.508186290793481
Validation loss: 2.795701279674456

Epoch: 5| Step: 6
Training loss: 0.5963739089252228
Validation loss: 2.76372134610348

Epoch: 5| Step: 7
Training loss: 0.5686481699068926
Validation loss: 2.7803425683700267

Epoch: 5| Step: 8
Training loss: 1.0597681941877608
Validation loss: 2.685229369843789

Epoch: 5| Step: 9
Training loss: 0.7208376709765276
Validation loss: 2.6847410012465662

Epoch: 5| Step: 10
Training loss: 0.4923005050025068
Validation loss: 2.7125987881662232

Epoch: 5| Step: 11
Training loss: 0.9345902108971009
Validation loss: 2.75112329285141

Epoch: 243| Step: 0
Training loss: 0.6589644016931583
Validation loss: 2.7098543933166033

Epoch: 5| Step: 1
Training loss: 0.6373107825691267
Validation loss: 2.7412218674171274

Epoch: 5| Step: 2
Training loss: 0.7508220141535283
Validation loss: 2.7189708561548365

Epoch: 5| Step: 3
Training loss: 0.5105297748296618
Validation loss: 2.761898142857305

Epoch: 5| Step: 4
Training loss: 0.40987891857464687
Validation loss: 2.725054866051774

Epoch: 5| Step: 5
Training loss: 0.733602563969615
Validation loss: 2.7120390787546618

Epoch: 5| Step: 6
Training loss: 0.9060223392107198
Validation loss: 2.7671464804637753

Epoch: 5| Step: 7
Training loss: 0.9857464576539513
Validation loss: 2.7354572152712957

Epoch: 5| Step: 8
Training loss: 0.8140267186712192
Validation loss: 2.772628114467455

Epoch: 5| Step: 9
Training loss: 0.5953728182214281
Validation loss: 2.7542451077389196

Epoch: 5| Step: 10
Training loss: 0.73282858174131
Validation loss: 2.8098263005706166

Epoch: 5| Step: 11
Training loss: 0.3327231882816318
Validation loss: 2.7778239883446783

Epoch: 244| Step: 0
Training loss: 0.4875246518577826
Validation loss: 2.7146750235326658

Epoch: 5| Step: 1
Training loss: 0.8210805294812742
Validation loss: 2.7038202861592273

Epoch: 5| Step: 2
Training loss: 0.3793641695616516
Validation loss: 2.70848206454038

Epoch: 5| Step: 3
Training loss: 0.5138279782817458
Validation loss: 2.714827715416995

Epoch: 5| Step: 4
Training loss: 0.9226197289612301
Validation loss: 2.7189573413520773

Epoch: 5| Step: 5
Training loss: 0.9194299309850535
Validation loss: 2.7674964887360693

Epoch: 5| Step: 6
Training loss: 0.7352261987340366
Validation loss: 2.7216917214950533

Epoch: 5| Step: 7
Training loss: 0.6356791334628361
Validation loss: 2.7009101091724896

Epoch: 5| Step: 8
Training loss: 0.5993406706397286
Validation loss: 2.761788039572491

Epoch: 5| Step: 9
Training loss: 0.6267625513132413
Validation loss: 2.777606452718257

Epoch: 5| Step: 10
Training loss: 0.7265284540546821
Validation loss: 2.6915716222885067

Epoch: 5| Step: 11
Training loss: 0.5811664377669173
Validation loss: 2.728530009947904

Epoch: 245| Step: 0
Training loss: 0.7553549174849618
Validation loss: 2.7410600197360697

Epoch: 5| Step: 1
Training loss: 0.8680385846492366
Validation loss: 2.7795525274874606

Epoch: 5| Step: 2
Training loss: 0.5229982839268088
Validation loss: 2.7483622612412972

Epoch: 5| Step: 3
Training loss: 0.4950527021259398
Validation loss: 2.739979890519853

Epoch: 5| Step: 4
Training loss: 0.8599488856406593
Validation loss: 2.768290476271102

Epoch: 5| Step: 5
Training loss: 0.902136642666354
Validation loss: 2.752473484619558

Epoch: 5| Step: 6
Training loss: 0.593938446256118
Validation loss: 2.7100185848668623

Epoch: 5| Step: 7
Training loss: 0.5675302336953466
Validation loss: 2.6598707541637987

Epoch: 5| Step: 8
Training loss: 0.4898032918524258
Validation loss: 2.698285126778758

Epoch: 5| Step: 9
Training loss: 0.5710792612724499
Validation loss: 2.7187800789407857

Epoch: 5| Step: 10
Training loss: 0.4239435873661707
Validation loss: 2.749224791936151

Epoch: 5| Step: 11
Training loss: 0.8696616336376647
Validation loss: 2.688067956541073

Epoch: 246| Step: 0
Training loss: 0.7100121900694027
Validation loss: 2.7587462799445883

Epoch: 5| Step: 1
Training loss: 0.7232684866965148
Validation loss: 2.7416780583648395

Epoch: 5| Step: 2
Training loss: 0.8849304921392506
Validation loss: 2.761855705207069

Epoch: 5| Step: 3
Training loss: 0.6562893492391125
Validation loss: 2.723296481968365

Epoch: 5| Step: 4
Training loss: 0.6499370562814819
Validation loss: 2.6261759424941737

Epoch: 5| Step: 5
Training loss: 0.3999765068844117
Validation loss: 2.6938762542274213

Epoch: 5| Step: 6
Training loss: 0.7837981059324794
Validation loss: 2.6731432531526074

Epoch: 5| Step: 7
Training loss: 0.5397534572319209
Validation loss: 2.6854835327076567

Epoch: 5| Step: 8
Training loss: 0.44116278491578054
Validation loss: 2.787898229369752

Epoch: 5| Step: 9
Training loss: 0.9759560494884706
Validation loss: 2.7234655752684565

Epoch: 5| Step: 10
Training loss: 0.3655218125499887
Validation loss: 2.760074683664169

Epoch: 5| Step: 11
Training loss: 0.731791761829851
Validation loss: 2.7960575976490056

Epoch: 247| Step: 0
Training loss: 0.6602562371551215
Validation loss: 2.695721481917436

Epoch: 5| Step: 1
Training loss: 0.8613662538285083
Validation loss: 2.788545494708708

Epoch: 5| Step: 2
Training loss: 0.515133883933995
Validation loss: 2.7831473968459055

Epoch: 5| Step: 3
Training loss: 0.5816118918572646
Validation loss: 2.7123140711574085

Epoch: 5| Step: 4
Training loss: 0.5008345434245102
Validation loss: 2.6772963158359304

Epoch: 5| Step: 5
Training loss: 0.6839688824914802
Validation loss: 2.749741578242135

Epoch: 5| Step: 6
Training loss: 0.8589836616738667
Validation loss: 2.7412386825891493

Epoch: 5| Step: 7
Training loss: 0.7365909178296913
Validation loss: 2.6699180258830375

Epoch: 5| Step: 8
Training loss: 0.7281263195893605
Validation loss: 2.6632173937312045

Epoch: 5| Step: 9
Training loss: 0.5029397019065155
Validation loss: 2.812202759329822

Epoch: 5| Step: 10
Training loss: 0.645085391335982
Validation loss: 2.7555739527347978

Epoch: 5| Step: 11
Training loss: 0.7818521849111205
Validation loss: 2.755638032563561

Epoch: 248| Step: 0
Training loss: 0.533440784964925
Validation loss: 2.7435703323036598

Epoch: 5| Step: 1
Training loss: 0.7568240847736193
Validation loss: 2.7012991425861586

Epoch: 5| Step: 2
Training loss: 0.5606205323635605
Validation loss: 2.7137858390169405

Epoch: 5| Step: 3
Training loss: 0.7613057900015555
Validation loss: 2.7596090082902465

Epoch: 5| Step: 4
Training loss: 0.6151944102068069
Validation loss: 2.699063139725436

Epoch: 5| Step: 5
Training loss: 0.6847339820840668
Validation loss: 2.6767544835100208

Epoch: 5| Step: 6
Training loss: 0.875485898390685
Validation loss: 2.774733646171062

Epoch: 5| Step: 7
Training loss: 0.6409255695023104
Validation loss: 2.732189213097992

Epoch: 5| Step: 8
Training loss: 0.6115202190615413
Validation loss: 2.756285092252248

Epoch: 5| Step: 9
Training loss: 0.9884518864296564
Validation loss: 2.6378591336660686

Epoch: 5| Step: 10
Training loss: 0.5365331159398478
Validation loss: 2.7723278028468847

Epoch: 5| Step: 11
Training loss: 0.22268522642882346
Validation loss: 2.7431753286671516

Epoch: 249| Step: 0
Training loss: 0.652990990903727
Validation loss: 2.759048649550824

Epoch: 5| Step: 1
Training loss: 0.7282982877887972
Validation loss: 2.6976515530463323

Epoch: 5| Step: 2
Training loss: 0.7847166966119032
Validation loss: 2.7506324878796713

Epoch: 5| Step: 3
Training loss: 0.6303827711659249
Validation loss: 2.806289148234622

Epoch: 5| Step: 4
Training loss: 0.7617004001069994
Validation loss: 2.7684126524286152

Epoch: 5| Step: 5
Training loss: 0.4214389631610008
Validation loss: 2.780304315786574

Epoch: 5| Step: 6
Training loss: 0.6445215166686348
Validation loss: 2.7816482180282085

Epoch: 5| Step: 7
Training loss: 0.7996596879136472
Validation loss: 2.6818839877530736

Epoch: 5| Step: 8
Training loss: 0.760682090177756
Validation loss: 2.7840224995167517

Epoch: 5| Step: 9
Training loss: 0.4649635929806441
Validation loss: 2.7043130097860004

Epoch: 5| Step: 10
Training loss: 0.4373115065376498
Validation loss: 2.723126364010024

Epoch: 5| Step: 11
Training loss: 0.2895008320689391
Validation loss: 2.6923171570283158

Epoch: 250| Step: 0
Training loss: 0.5788477426634348
Validation loss: 2.7578682862313775

Epoch: 5| Step: 1
Training loss: 0.7645249541097681
Validation loss: 2.7707826650379945

Epoch: 5| Step: 2
Training loss: 0.45721192334452115
Validation loss: 2.69547515968034

Epoch: 5| Step: 3
Training loss: 0.5971336323683297
Validation loss: 2.6865427970304245

Epoch: 5| Step: 4
Training loss: 0.8008717555561916
Validation loss: 2.707011991123171

Epoch: 5| Step: 5
Training loss: 0.3314999312275604
Validation loss: 2.766617778169952

Epoch: 5| Step: 6
Training loss: 0.7023314342331282
Validation loss: 2.7885480454354945

Epoch: 5| Step: 7
Training loss: 0.8043996425668651
Validation loss: 2.7672618971562666

Epoch: 5| Step: 8
Training loss: 0.9403693475904535
Validation loss: 2.702573635487333

Epoch: 5| Step: 9
Training loss: 0.589728363068725
Validation loss: 2.677539913908164

Epoch: 5| Step: 10
Training loss: 0.5592115227274093
Validation loss: 2.7449969927279705

Epoch: 5| Step: 11
Training loss: 0.4237746807101462
Validation loss: 2.7411196188035913

Epoch: 251| Step: 0
Training loss: 0.5815535767786421
Validation loss: 2.752248347059427

Epoch: 5| Step: 1
Training loss: 0.4855528323973484
Validation loss: 2.707981098940676

Epoch: 5| Step: 2
Training loss: 0.5905801079860564
Validation loss: 2.76200860142272

Epoch: 5| Step: 3
Training loss: 0.573358345285508
Validation loss: 2.685473210104738

Epoch: 5| Step: 4
Training loss: 0.5916769327920711
Validation loss: 2.712481972126155

Epoch: 5| Step: 5
Training loss: 0.9053932612683003
Validation loss: 2.745107123520356

Epoch: 5| Step: 6
Training loss: 0.5005907502763486
Validation loss: 2.645545982666574

Epoch: 5| Step: 7
Training loss: 0.8298912286724446
Validation loss: 2.765853073213074

Epoch: 5| Step: 8
Training loss: 0.8242369735655695
Validation loss: 2.756607656996626

Epoch: 5| Step: 9
Training loss: 0.6479650407827092
Validation loss: 2.7655068927265867

Epoch: 5| Step: 10
Training loss: 0.5210888108872994
Validation loss: 2.5848323039182097

Epoch: 5| Step: 11
Training loss: 0.41018743850565725
Validation loss: 2.7602386609150233

Epoch: 252| Step: 0
Training loss: 0.576152503770961
Validation loss: 2.7171105780305846

Epoch: 5| Step: 1
Training loss: 0.7410686693123746
Validation loss: 2.7219689011024686

Epoch: 5| Step: 2
Training loss: 0.5796385361384728
Validation loss: 2.693214964043836

Epoch: 5| Step: 3
Training loss: 0.7018409448312226
Validation loss: 2.7241433113023126

Epoch: 5| Step: 4
Training loss: 0.7309623315449534
Validation loss: 2.703469061591753

Epoch: 5| Step: 5
Training loss: 0.6015609394400036
Validation loss: 2.7044585104769125

Epoch: 5| Step: 6
Training loss: 0.7247964458156331
Validation loss: 2.727414020968724

Epoch: 5| Step: 7
Training loss: 0.6618201150012054
Validation loss: 2.72752801219333

Epoch: 5| Step: 8
Training loss: 0.4600931937207807
Validation loss: 2.715361533427438

Epoch: 5| Step: 9
Training loss: 0.532260886669135
Validation loss: 2.7342825992049193

Epoch: 5| Step: 10
Training loss: 0.6878162436966184
Validation loss: 2.695729592895435

Epoch: 5| Step: 11
Training loss: 0.39403364697554055
Validation loss: 2.7715099316512575

Epoch: 253| Step: 0
Training loss: 0.6057251172136746
Validation loss: 2.7621941236023897

Epoch: 5| Step: 1
Training loss: 0.5181212256907267
Validation loss: 2.7320156418039336

Epoch: 5| Step: 2
Training loss: 0.7981499215628616
Validation loss: 2.7113602205146594

Epoch: 5| Step: 3
Training loss: 0.5112624718560188
Validation loss: 2.798298812544984

Epoch: 5| Step: 4
Training loss: 0.4299735937493772
Validation loss: 2.7377194323913594

Epoch: 5| Step: 5
Training loss: 0.5040812816774668
Validation loss: 2.7229089897843366

Epoch: 5| Step: 6
Training loss: 0.49850877772382785
Validation loss: 2.715345125075902

Epoch: 5| Step: 7
Training loss: 0.6685850635239755
Validation loss: 2.7372136558505082

Epoch: 5| Step: 8
Training loss: 0.7737233568081575
Validation loss: 2.7103703699890906

Epoch: 5| Step: 9
Training loss: 0.535300799151187
Validation loss: 2.728183909126473

Epoch: 5| Step: 10
Training loss: 1.078810432482931
Validation loss: 2.7036845780145655

Epoch: 5| Step: 11
Training loss: 0.3308229676339522
Validation loss: 2.8019730299235492

Epoch: 254| Step: 0
Training loss: 0.7049876654337268
Validation loss: 2.78764504210711

Epoch: 5| Step: 1
Training loss: 0.6290614250617359
Validation loss: 2.8304094849391532

Epoch: 5| Step: 2
Training loss: 0.41949018423033885
Validation loss: 2.7375323422871474

Epoch: 5| Step: 3
Training loss: 0.5381469415052677
Validation loss: 2.7879680014016386

Epoch: 5| Step: 4
Training loss: 0.4490856802843589
Validation loss: 2.7322866948545834

Epoch: 5| Step: 5
Training loss: 0.6492870923736146
Validation loss: 2.6974021366976513

Epoch: 5| Step: 6
Training loss: 0.8012452432785835
Validation loss: 2.6793987277983686

Epoch: 5| Step: 7
Training loss: 0.9904284164850846
Validation loss: 2.767143572547144

Epoch: 5| Step: 8
Training loss: 0.5738115488752288
Validation loss: 2.7316904895605605

Epoch: 5| Step: 9
Training loss: 0.7212196298085862
Validation loss: 2.7241140118101357

Epoch: 5| Step: 10
Training loss: 0.7098214328556798
Validation loss: 2.7264630172929056

Epoch: 5| Step: 11
Training loss: 0.32073395612229094
Validation loss: 2.7598177362063443

Epoch: 255| Step: 0
Training loss: 0.42905868989790585
Validation loss: 2.754672563858204

Epoch: 5| Step: 1
Training loss: 0.532135673951762
Validation loss: 2.6456484817651154

Epoch: 5| Step: 2
Training loss: 0.46544995569943376
Validation loss: 2.7034670809935806

Epoch: 5| Step: 3
Training loss: 0.7980575015592442
Validation loss: 2.7477701278688356

Epoch: 5| Step: 4
Training loss: 0.7372029013195269
Validation loss: 2.72305921348294

Epoch: 5| Step: 5
Training loss: 0.5834188625666884
Validation loss: 2.7663740411704216

Epoch: 5| Step: 6
Training loss: 0.37055206919308437
Validation loss: 2.7166696825381274

Epoch: 5| Step: 7
Training loss: 0.8642827089678544
Validation loss: 2.7026386190911436

Epoch: 5| Step: 8
Training loss: 0.8768793427624226
Validation loss: 2.6589698255729406

Epoch: 5| Step: 9
Training loss: 0.5471077015203092
Validation loss: 2.6346170182261397

Epoch: 5| Step: 10
Training loss: 0.44258153632954456
Validation loss: 2.726715440659765

Epoch: 5| Step: 11
Training loss: 0.14387316636218725
Validation loss: 2.720806754266236

Epoch: 256| Step: 0
Training loss: 0.4360431700308604
Validation loss: 2.6720564893984875

Epoch: 5| Step: 1
Training loss: 0.6332742395772996
Validation loss: 2.7424358751745457

Epoch: 5| Step: 2
Training loss: 0.827836724254846
Validation loss: 2.7155308757254217

Epoch: 5| Step: 3
Training loss: 0.6314117328317955
Validation loss: 2.6760891646707123

Epoch: 5| Step: 4
Training loss: 0.6172456834625937
Validation loss: 2.705460419707656

Epoch: 5| Step: 5
Training loss: 0.6184083236049651
Validation loss: 2.7268954877996685

Epoch: 5| Step: 6
Training loss: 0.7070239577786713
Validation loss: 2.752296532817748

Epoch: 5| Step: 7
Training loss: 0.6738528260941871
Validation loss: 2.7428912050503595

Epoch: 5| Step: 8
Training loss: 0.558769785212856
Validation loss: 2.7662319839116103

Epoch: 5| Step: 9
Training loss: 0.5574928318726082
Validation loss: 2.633680568408121

Epoch: 5| Step: 10
Training loss: 0.8379585220819505
Validation loss: 2.7264287673522003

Epoch: 5| Step: 11
Training loss: 0.45491701147410324
Validation loss: 2.6996394969017934

Epoch: 257| Step: 0
Training loss: 0.6749118659090552
Validation loss: 2.6778328893909675

Epoch: 5| Step: 1
Training loss: 0.48899308769337146
Validation loss: 2.737174016596514

Epoch: 5| Step: 2
Training loss: 0.6848557730056066
Validation loss: 2.779150602665066

Epoch: 5| Step: 3
Training loss: 0.49165016694858943
Validation loss: 2.734524157860958

Epoch: 5| Step: 4
Training loss: 0.6084842039736472
Validation loss: 2.7275007358821597

Epoch: 5| Step: 5
Training loss: 0.42764335256075564
Validation loss: 2.725649654455076

Epoch: 5| Step: 6
Training loss: 0.9090815080351681
Validation loss: 2.734206319783212

Epoch: 5| Step: 7
Training loss: 0.7518266447631311
Validation loss: 2.7854991450304163

Epoch: 5| Step: 8
Training loss: 0.6129947406160463
Validation loss: 2.723043157961409

Epoch: 5| Step: 9
Training loss: 0.4402596595902362
Validation loss: 2.7363699837894915

Epoch: 5| Step: 10
Training loss: 0.5497942257795465
Validation loss: 2.7955574327788377

Epoch: 5| Step: 11
Training loss: 0.28370325060492513
Validation loss: 2.7431064236158895

Epoch: 258| Step: 0
Training loss: 1.0158482232904928
Validation loss: 2.73141505661411

Epoch: 5| Step: 1
Training loss: 0.5855656015812953
Validation loss: 2.751314849510971

Epoch: 5| Step: 2
Training loss: 0.6784417586015034
Validation loss: 2.7755946371400144

Epoch: 5| Step: 3
Training loss: 0.4216524526150416
Validation loss: 2.741502428111596

Epoch: 5| Step: 4
Training loss: 0.4506613414887593
Validation loss: 2.7943847907945765

Epoch: 5| Step: 5
Training loss: 0.4815689763766805
Validation loss: 2.689909712246443

Epoch: 5| Step: 6
Training loss: 0.7520941267709624
Validation loss: 2.6911612345173155

Epoch: 5| Step: 7
Training loss: 0.7748388830494787
Validation loss: 2.7465786783833703

Epoch: 5| Step: 8
Training loss: 0.7376464859910762
Validation loss: 2.657893818488326

Epoch: 5| Step: 9
Training loss: 0.5461170666346084
Validation loss: 2.7823091733251517

Epoch: 5| Step: 10
Training loss: 0.5575151767717685
Validation loss: 2.6547953904987023

Epoch: 5| Step: 11
Training loss: 0.3015109784087058
Validation loss: 2.7594259637552314

Epoch: 259| Step: 0
Training loss: 0.715396271512855
Validation loss: 2.719762208112599

Epoch: 5| Step: 1
Training loss: 0.8398293427407045
Validation loss: 2.763775356049311

Epoch: 5| Step: 2
Training loss: 0.6989203727484122
Validation loss: 2.775596229835321

Epoch: 5| Step: 3
Training loss: 0.37837037802432477
Validation loss: 2.8202575333047766

Epoch: 5| Step: 4
Training loss: 0.5659817387327518
Validation loss: 2.751934642562728

Epoch: 5| Step: 5
Training loss: 0.6879305358434408
Validation loss: 2.6994536022104567

Epoch: 5| Step: 6
Training loss: 0.6664259197735488
Validation loss: 2.7819035651566533

Epoch: 5| Step: 7
Training loss: 0.5736706771536769
Validation loss: 2.6786596108105196

Epoch: 5| Step: 8
Training loss: 0.5716423572463466
Validation loss: 2.7578623463679954

Epoch: 5| Step: 9
Training loss: 0.4426486162038434
Validation loss: 2.7210555440546256

Epoch: 5| Step: 10
Training loss: 0.64963180218839
Validation loss: 2.7137112311298877

Epoch: 5| Step: 11
Training loss: 0.4491489687914467
Validation loss: 2.7205201667342456

Epoch: 260| Step: 0
Training loss: 0.7234230715670215
Validation loss: 2.758615047401791

Epoch: 5| Step: 1
Training loss: 0.5796008988750588
Validation loss: 2.8040912918930467

Epoch: 5| Step: 2
Training loss: 0.5852024299520286
Validation loss: 2.7358988266990556

Epoch: 5| Step: 3
Training loss: 0.7509428296989441
Validation loss: 2.752839645279041

Epoch: 5| Step: 4
Training loss: 0.8439089660657327
Validation loss: 2.763784266546558

Epoch: 5| Step: 5
Training loss: 0.6699355766296535
Validation loss: 2.694348609805105

Epoch: 5| Step: 6
Training loss: 0.3977369620022312
Validation loss: 2.7264236116057825

Epoch: 5| Step: 7
Training loss: 0.5653746055957566
Validation loss: 2.7582319299108327

Epoch: 5| Step: 8
Training loss: 0.6112303731844818
Validation loss: 2.7372860698631603

Epoch: 5| Step: 9
Training loss: 0.48586306109136546
Validation loss: 2.729952420016845

Epoch: 5| Step: 10
Training loss: 0.5836957390458304
Validation loss: 2.762173720836599

Epoch: 5| Step: 11
Training loss: 0.6139375612930132
Validation loss: 2.7442700302365144

Epoch: 261| Step: 0
Training loss: 0.6662860220784788
Validation loss: 2.8129500170356945

Epoch: 5| Step: 1
Training loss: 0.8453125437174167
Validation loss: 2.736906561839749

Epoch: 5| Step: 2
Training loss: 0.6099241911965201
Validation loss: 2.733522543861477

Epoch: 5| Step: 3
Training loss: 0.7640958813823266
Validation loss: 2.7864349055270905

Epoch: 5| Step: 4
Training loss: 0.6304549583240684
Validation loss: 2.7188814869505245

Epoch: 5| Step: 5
Training loss: 0.5173883918066805
Validation loss: 2.780313839678595

Epoch: 5| Step: 6
Training loss: 0.6511774887822396
Validation loss: 2.7134766683768614

Epoch: 5| Step: 7
Training loss: 0.5106583593950708
Validation loss: 2.759017083301221

Epoch: 5| Step: 8
Training loss: 0.650801657623473
Validation loss: 2.7566257189008505

Epoch: 5| Step: 9
Training loss: 0.446451971258254
Validation loss: 2.7586444395974277

Epoch: 5| Step: 10
Training loss: 0.4099508225209517
Validation loss: 2.6706464221992965

Epoch: 5| Step: 11
Training loss: 0.3367063905080598
Validation loss: 2.7261902410192183

Epoch: 262| Step: 0
Training loss: 0.6152041473229035
Validation loss: 2.8850527658986764

Epoch: 5| Step: 1
Training loss: 0.5840740836654676
Validation loss: 2.7212191072134755

Epoch: 5| Step: 2
Training loss: 0.5254995807424627
Validation loss: 2.7226608582817495

Epoch: 5| Step: 3
Training loss: 0.6336839820966585
Validation loss: 2.7548171716997167

Epoch: 5| Step: 4
Training loss: 0.6311051211899306
Validation loss: 2.7468267324443274

Epoch: 5| Step: 5
Training loss: 0.6504933731436466
Validation loss: 2.7108747088427947

Epoch: 5| Step: 6
Training loss: 0.8071478479727807
Validation loss: 2.719601103321962

Epoch: 5| Step: 7
Training loss: 0.8528107759619732
Validation loss: 2.7592693403671698

Epoch: 5| Step: 8
Training loss: 0.8414467705308942
Validation loss: 2.7433804039337235

Epoch: 5| Step: 9
Training loss: 0.6340386791088253
Validation loss: 2.7858906937206482

Epoch: 5| Step: 10
Training loss: 0.47079824539131476
Validation loss: 2.7676868691052983

Epoch: 5| Step: 11
Training loss: 0.8610037887170884
Validation loss: 2.808491297777822

Epoch: 263| Step: 0
Training loss: 0.5092806500540595
Validation loss: 2.8386402754614726

Epoch: 5| Step: 1
Training loss: 1.0632513419043501
Validation loss: 2.7503775171322338

Epoch: 5| Step: 2
Training loss: 0.7207582860993663
Validation loss: 2.89029572475857

Epoch: 5| Step: 3
Training loss: 0.983296757491969
Validation loss: 2.7942375057872075

Epoch: 5| Step: 4
Training loss: 0.47095525486617856
Validation loss: 2.7206201844216955

Epoch: 5| Step: 5
Training loss: 0.418673340342314
Validation loss: 2.717445133477714

Epoch: 5| Step: 6
Training loss: 0.6943056124088801
Validation loss: 2.716577601045437

Epoch: 5| Step: 7
Training loss: 0.9521862472460837
Validation loss: 2.781663713866949

Epoch: 5| Step: 8
Training loss: 0.5793991482176362
Validation loss: 2.744299894622935

Epoch: 5| Step: 9
Training loss: 0.4712890049554542
Validation loss: 2.7407492174150168

Epoch: 5| Step: 10
Training loss: 0.5037420434063113
Validation loss: 2.7502487351895155

Epoch: 5| Step: 11
Training loss: 0.49438102814945284
Validation loss: 2.763753771607534

Epoch: 264| Step: 0
Training loss: 0.5271991955466638
Validation loss: 2.7590749046757432

Epoch: 5| Step: 1
Training loss: 0.8934529564485517
Validation loss: 2.8706270526269857

Epoch: 5| Step: 2
Training loss: 0.7383898700555507
Validation loss: 2.797768135890787

Epoch: 5| Step: 3
Training loss: 0.6646432917303514
Validation loss: 2.774785637380102

Epoch: 5| Step: 4
Training loss: 0.7092037229423034
Validation loss: 2.842173387332696

Epoch: 5| Step: 5
Training loss: 0.41980433038710735
Validation loss: 2.6772751399297885

Epoch: 5| Step: 6
Training loss: 0.4636356297814839
Validation loss: 2.7720852237073617

Epoch: 5| Step: 7
Training loss: 0.651595114387956
Validation loss: 2.7817539122913857

Epoch: 5| Step: 8
Training loss: 0.7535064902377306
Validation loss: 2.6732837391254103

Epoch: 5| Step: 9
Training loss: 0.7940416265909592
Validation loss: 2.7535447336542376

Epoch: 5| Step: 10
Training loss: 0.7750052544200343
Validation loss: 2.7836734807061214

Epoch: 5| Step: 11
Training loss: 0.5086274869777865
Validation loss: 2.8010487271342033

Epoch: 265| Step: 0
Training loss: 0.4131856667185539
Validation loss: 2.722220237697691

Epoch: 5| Step: 1
Training loss: 0.9728886889588003
Validation loss: 2.81517477708613

Epoch: 5| Step: 2
Training loss: 0.6558159346334695
Validation loss: 2.7499392784524033

Epoch: 5| Step: 3
Training loss: 0.8284649421121197
Validation loss: 2.8202773432772674

Epoch: 5| Step: 4
Training loss: 0.5713948730554517
Validation loss: 2.8450342115223526

Epoch: 5| Step: 5
Training loss: 0.5077314165378116
Validation loss: 2.8837079636258003

Epoch: 5| Step: 6
Training loss: 0.4314937427946706
Validation loss: 2.781130438102789

Epoch: 5| Step: 7
Training loss: 0.7745542844264147
Validation loss: 2.7791415984544945

Epoch: 5| Step: 8
Training loss: 0.3937912033865944
Validation loss: 2.7234661224080945

Epoch: 5| Step: 9
Training loss: 0.8097022378184604
Validation loss: 2.7417021790168885

Epoch: 5| Step: 10
Training loss: 0.5418760982973084
Validation loss: 2.764082153204439

Epoch: 5| Step: 11
Training loss: 0.8251942290349766
Validation loss: 2.76361601900016

Epoch: 266| Step: 0
Training loss: 0.44187600112758463
Validation loss: 2.8324756668237505

Epoch: 5| Step: 1
Training loss: 0.3255455033172938
Validation loss: 2.814740214198155

Epoch: 5| Step: 2
Training loss: 0.617490090665188
Validation loss: 2.735520989190559

Epoch: 5| Step: 3
Training loss: 0.9275659669310469
Validation loss: 2.7955417758656456

Epoch: 5| Step: 4
Training loss: 0.5290715487540596
Validation loss: 2.8128342888990514

Epoch: 5| Step: 5
Training loss: 0.8428496749537857
Validation loss: 2.817701707551303

Epoch: 5| Step: 6
Training loss: 0.4533454588917492
Validation loss: 2.8538078978284127

Epoch: 5| Step: 7
Training loss: 0.6810857049756112
Validation loss: 2.7573944509785044

Epoch: 5| Step: 8
Training loss: 0.5911670770623104
Validation loss: 2.772857809600489

Epoch: 5| Step: 9
Training loss: 0.45092066256890423
Validation loss: 2.7598841651391015

Epoch: 5| Step: 10
Training loss: 0.4263184334756299
Validation loss: 2.7521512294386317

Epoch: 5| Step: 11
Training loss: 0.8035239167775448
Validation loss: 2.746764089018215

Epoch: 267| Step: 0
Training loss: 0.5800230468906528
Validation loss: 2.8527889941027107

Epoch: 5| Step: 1
Training loss: 0.8525018672978599
Validation loss: 2.7605511806510776

Epoch: 5| Step: 2
Training loss: 0.5329039017036071
Validation loss: 2.794790659840436

Epoch: 5| Step: 3
Training loss: 0.602179817423886
Validation loss: 2.7918309381653215

Epoch: 5| Step: 4
Training loss: 0.5035059617967146
Validation loss: 2.7316784559739875

Epoch: 5| Step: 5
Training loss: 0.7545005945995862
Validation loss: 2.79505078267042

Epoch: 5| Step: 6
Training loss: 0.637269279391871
Validation loss: 2.784960974882731

Epoch: 5| Step: 7
Training loss: 0.6128541224388097
Validation loss: 2.7504887977318346

Epoch: 5| Step: 8
Training loss: 0.6466156517959188
Validation loss: 2.8599886452898513

Epoch: 5| Step: 9
Training loss: 0.8125597858440842
Validation loss: 2.7809001795475754

Epoch: 5| Step: 10
Training loss: 0.6843019141621278
Validation loss: 2.741425229855998

Epoch: 5| Step: 11
Training loss: 0.3825262517584617
Validation loss: 2.8076150822286037

Epoch: 268| Step: 0
Training loss: 0.5301105115494174
Validation loss: 2.7789206912602347

Epoch: 5| Step: 1
Training loss: 0.9861560029272118
Validation loss: 2.764916891478134

Epoch: 5| Step: 2
Training loss: 0.615178714232534
Validation loss: 2.7326695527862372

Epoch: 5| Step: 3
Training loss: 0.6019298373203883
Validation loss: 2.6998616735028014

Epoch: 5| Step: 4
Training loss: 0.5802719100783105
Validation loss: 2.7824665437842273

Epoch: 5| Step: 5
Training loss: 0.4902197847056915
Validation loss: 2.8214435264422146

Epoch: 5| Step: 6
Training loss: 0.8488048032391016
Validation loss: 2.7956916394170332

Epoch: 5| Step: 7
Training loss: 0.4210284357604724
Validation loss: 2.8078271087453253

Epoch: 5| Step: 8
Training loss: 0.3952019533129347
Validation loss: 2.770882372434136

Epoch: 5| Step: 9
Training loss: 0.7591506312575395
Validation loss: 2.7532127679581793

Epoch: 5| Step: 10
Training loss: 0.5293354147080227
Validation loss: 2.7607170169502857

Epoch: 5| Step: 11
Training loss: 0.5533908948440167
Validation loss: 2.7436925121706417

Epoch: 269| Step: 0
Training loss: 0.6188450537986989
Validation loss: 2.7469179590574355

Epoch: 5| Step: 1
Training loss: 0.4490509549105611
Validation loss: 2.7618446591176706

Epoch: 5| Step: 2
Training loss: 0.6465791016296104
Validation loss: 2.808050206502425

Epoch: 5| Step: 3
Training loss: 0.8789804045865791
Validation loss: 2.715806983202674

Epoch: 5| Step: 4
Training loss: 0.6564767763587153
Validation loss: 2.7650891303906677

Epoch: 5| Step: 5
Training loss: 0.427310803553835
Validation loss: 2.803990322584058

Epoch: 5| Step: 6
Training loss: 0.3462223098369412
Validation loss: 2.7188221859757693

Epoch: 5| Step: 7
Training loss: 0.937493133519776
Validation loss: 2.75287383005833

Epoch: 5| Step: 8
Training loss: 0.36398693986927744
Validation loss: 2.7663367984402374

Epoch: 5| Step: 9
Training loss: 0.7454424506885244
Validation loss: 2.7331667128714376

Epoch: 5| Step: 10
Training loss: 0.4682875100074732
Validation loss: 2.6910945340870653

Epoch: 5| Step: 11
Training loss: 0.4561844667636194
Validation loss: 2.75114686127593

Epoch: 270| Step: 0
Training loss: 0.4326617388034429
Validation loss: 2.745819371110288

Epoch: 5| Step: 1
Training loss: 0.687433694763223
Validation loss: 2.761395983649829

Epoch: 5| Step: 2
Training loss: 0.5250781807135343
Validation loss: 2.794251936356544

Epoch: 5| Step: 3
Training loss: 0.6956324751898719
Validation loss: 2.6857351341152165

Epoch: 5| Step: 4
Training loss: 0.8161038290354898
Validation loss: 2.7730209467592317

Epoch: 5| Step: 5
Training loss: 0.7339747941395259
Validation loss: 2.7338060640907145

Epoch: 5| Step: 6
Training loss: 0.4471992543379789
Validation loss: 2.7166910523410337

Epoch: 5| Step: 7
Training loss: 0.4379641931346427
Validation loss: 2.751179128060725

Epoch: 5| Step: 8
Training loss: 0.6132150359156696
Validation loss: 2.7730256325520304

Epoch: 5| Step: 9
Training loss: 0.3720948819436146
Validation loss: 2.7532815932714976

Epoch: 5| Step: 10
Training loss: 0.6865178809341277
Validation loss: 2.806097821879265

Epoch: 5| Step: 11
Training loss: 1.033317689367028
Validation loss: 2.7535586054270524

Epoch: 271| Step: 0
Training loss: 0.6260021281861274
Validation loss: 2.7807271515950354

Epoch: 5| Step: 1
Training loss: 0.7055894260545169
Validation loss: 2.783787783957424

Epoch: 5| Step: 2
Training loss: 0.4752171553339604
Validation loss: 2.7790171414766687

Epoch: 5| Step: 3
Training loss: 0.7336652044529826
Validation loss: 2.8530657320248913

Epoch: 5| Step: 4
Training loss: 0.47602253951274276
Validation loss: 2.7886003740068515

Epoch: 5| Step: 5
Training loss: 0.5593433019511697
Validation loss: 2.827965410482335

Epoch: 5| Step: 6
Training loss: 0.43371305456763987
Validation loss: 2.7393724169361033

Epoch: 5| Step: 7
Training loss: 0.7615481454578835
Validation loss: 2.7254454721074444

Epoch: 5| Step: 8
Training loss: 0.4190680228544304
Validation loss: 2.6809965741568313

Epoch: 5| Step: 9
Training loss: 0.7477594525611165
Validation loss: 2.784947409341586

Epoch: 5| Step: 10
Training loss: 0.7550580017597478
Validation loss: 2.69915847600613

Epoch: 5| Step: 11
Training loss: 0.44378769136923313
Validation loss: 2.732224565225696

Epoch: 272| Step: 0
Training loss: 0.5141760668778889
Validation loss: 2.6982671124667825

Epoch: 5| Step: 1
Training loss: 0.8091972789284009
Validation loss: 2.728202668985553

Epoch: 5| Step: 2
Training loss: 0.5991458405822175
Validation loss: 2.7570177469402997

Epoch: 5| Step: 3
Training loss: 0.5817580894183191
Validation loss: 2.7305774403315226

Epoch: 5| Step: 4
Training loss: 0.43000228795285667
Validation loss: 2.766382893023191

Epoch: 5| Step: 5
Training loss: 0.7594540700052106
Validation loss: 2.82205744660837

Epoch: 5| Step: 6
Training loss: 0.502160560108451
Validation loss: 2.734209295429024

Epoch: 5| Step: 7
Training loss: 0.49316386609970564
Validation loss: 2.732721853524991

Epoch: 5| Step: 8
Training loss: 0.5862273453033983
Validation loss: 2.72703765255811

Epoch: 5| Step: 9
Training loss: 0.5594257214529065
Validation loss: 2.8089515376789795

Epoch: 5| Step: 10
Training loss: 0.5854009587724796
Validation loss: 2.7005525413620965

Epoch: 5| Step: 11
Training loss: 0.5242088100895196
Validation loss: 2.765387433295907

Epoch: 273| Step: 0
Training loss: 0.7644364220183769
Validation loss: 2.7575414486568715

Epoch: 5| Step: 1
Training loss: 0.6108085447445059
Validation loss: 2.7008643794744644

Epoch: 5| Step: 2
Training loss: 0.7222093179560659
Validation loss: 2.669603430643212

Epoch: 5| Step: 3
Training loss: 0.4823951868250477
Validation loss: 2.7420319153500157

Epoch: 5| Step: 4
Training loss: 0.6921464869143783
Validation loss: 2.6512010385289977

Epoch: 5| Step: 5
Training loss: 0.49874924145786664
Validation loss: 2.723278629457043

Epoch: 5| Step: 6
Training loss: 0.4117221911755245
Validation loss: 2.6795911780896846

Epoch: 5| Step: 7
Training loss: 0.6022879202334849
Validation loss: 2.675029974023798

Epoch: 5| Step: 8
Training loss: 0.4799129558903757
Validation loss: 2.689334910188002

Epoch: 5| Step: 9
Training loss: 0.6782668163184787
Validation loss: 2.762776256430414

Epoch: 5| Step: 10
Training loss: 0.5253637087142057
Validation loss: 2.840190637138322

Epoch: 5| Step: 11
Training loss: 0.47717745767255165
Validation loss: 2.727742520001101

Epoch: 274| Step: 0
Training loss: 0.8683646863877044
Validation loss: 2.793848808725955

Epoch: 5| Step: 1
Training loss: 0.37758536017929173
Validation loss: 2.728320716225966

Epoch: 5| Step: 2
Training loss: 0.4382366722134587
Validation loss: 2.7751082317621836

Epoch: 5| Step: 3
Training loss: 0.6746411932867252
Validation loss: 2.785324892321587

Epoch: 5| Step: 4
Training loss: 0.43800920417337985
Validation loss: 2.760248245043606

Epoch: 5| Step: 5
Training loss: 0.7062783210274739
Validation loss: 2.694725042629659

Epoch: 5| Step: 6
Training loss: 0.5815122709972189
Validation loss: 2.6929639784701767

Epoch: 5| Step: 7
Training loss: 0.36797631533351566
Validation loss: 2.7851863322655346

Epoch: 5| Step: 8
Training loss: 0.8049114249053785
Validation loss: 2.7415255574511144

Epoch: 5| Step: 9
Training loss: 0.58887857454592
Validation loss: 2.781048453096934

Epoch: 5| Step: 10
Training loss: 0.6915790966815973
Validation loss: 2.80055383089696

Epoch: 5| Step: 11
Training loss: 0.45032826940706844
Validation loss: 2.7679790959248756

Epoch: 275| Step: 0
Training loss: 0.6536198543740714
Validation loss: 2.7680621857879273

Epoch: 5| Step: 1
Training loss: 0.6683419952719138
Validation loss: 2.813567499387959

Epoch: 5| Step: 2
Training loss: 0.5949089384519691
Validation loss: 2.801887712185304

Epoch: 5| Step: 3
Training loss: 0.475592861869269
Validation loss: 2.7691427728672697

Epoch: 5| Step: 4
Training loss: 0.6535098680423916
Validation loss: 2.7940652415547236

Epoch: 5| Step: 5
Training loss: 0.6034527100790059
Validation loss: 2.7446384145864604

Epoch: 5| Step: 6
Training loss: 0.5784442638659179
Validation loss: 2.7668943168345557

Epoch: 5| Step: 7
Training loss: 0.44404201637503193
Validation loss: 2.7570981081095467

Epoch: 5| Step: 8
Training loss: 0.6008799755794311
Validation loss: 2.7163921669979043

Epoch: 5| Step: 9
Training loss: 0.7415502924824605
Validation loss: 2.699824683360885

Epoch: 5| Step: 10
Training loss: 0.741960510879103
Validation loss: 2.722874443400068

Epoch: 5| Step: 11
Training loss: 0.2471122103060197
Validation loss: 2.7858617922426347

Epoch: 276| Step: 0
Training loss: 0.5092889888671912
Validation loss: 2.670035143339968

Epoch: 5| Step: 1
Training loss: 0.3296548849850169
Validation loss: 2.77984317817487

Epoch: 5| Step: 2
Training loss: 0.7052866661671408
Validation loss: 2.7714424551297454

Epoch: 5| Step: 3
Training loss: 0.5501398721481936
Validation loss: 2.778041285228649

Epoch: 5| Step: 4
Training loss: 0.5159838612531403
Validation loss: 2.7661457864546706

Epoch: 5| Step: 5
Training loss: 0.6284590843284041
Validation loss: 2.8134462213033262

Epoch: 5| Step: 6
Training loss: 0.7331144999787145
Validation loss: 2.7917725213227227

Epoch: 5| Step: 7
Training loss: 0.5115943349767688
Validation loss: 2.8039932277167305

Epoch: 5| Step: 8
Training loss: 0.6156575276645372
Validation loss: 2.7604903997014687

Epoch: 5| Step: 9
Training loss: 0.5981477698413601
Validation loss: 2.768629159435946

Epoch: 5| Step: 10
Training loss: 0.6020985976487475
Validation loss: 2.7719042806931706

Epoch: 5| Step: 11
Training loss: 0.5820898756161546
Validation loss: 2.7839922191241206

Epoch: 277| Step: 0
Training loss: 0.5168798378622276
Validation loss: 2.760017136984757

Epoch: 5| Step: 1
Training loss: 0.5468984326383222
Validation loss: 2.755141556092226

Epoch: 5| Step: 2
Training loss: 0.46282374224766193
Validation loss: 2.727630282273313

Epoch: 5| Step: 3
Training loss: 0.5644917722360896
Validation loss: 2.738442282447062

Epoch: 5| Step: 4
Training loss: 0.8322554451926742
Validation loss: 2.7438589003493505

Epoch: 5| Step: 5
Training loss: 0.7504205716624759
Validation loss: 2.757228778736348

Epoch: 5| Step: 6
Training loss: 0.3035205477360741
Validation loss: 2.8415204135439636

Epoch: 5| Step: 7
Training loss: 0.45371150830840956
Validation loss: 2.7181612268803903

Epoch: 5| Step: 8
Training loss: 0.7851567434432724
Validation loss: 2.725158012690963

Epoch: 5| Step: 9
Training loss: 0.7666262482963089
Validation loss: 2.7794666680740723

Epoch: 5| Step: 10
Training loss: 0.5823212995364843
Validation loss: 2.782961600905602

Epoch: 5| Step: 11
Training loss: 0.7696600869083249
Validation loss: 2.720094881623429

Epoch: 278| Step: 0
Training loss: 0.35197780238949583
Validation loss: 2.744817973715986

Epoch: 5| Step: 1
Training loss: 0.788237262931438
Validation loss: 2.726644709676679

Epoch: 5| Step: 2
Training loss: 0.41726791592618834
Validation loss: 2.732480557265801

Epoch: 5| Step: 3
Training loss: 0.48266508944571607
Validation loss: 2.8027394222697004

Epoch: 5| Step: 4
Training loss: 0.4087603475561661
Validation loss: 2.6675910179641056

Epoch: 5| Step: 5
Training loss: 0.48653537669745
Validation loss: 2.7564562001014776

Epoch: 5| Step: 6
Training loss: 0.4653817757659621
Validation loss: 2.700413198113231

Epoch: 5| Step: 7
Training loss: 0.8103046836726139
Validation loss: 2.757648794558324

Epoch: 5| Step: 8
Training loss: 0.5626780440101515
Validation loss: 2.711163063449411

Epoch: 5| Step: 9
Training loss: 0.5271996760474441
Validation loss: 2.823150569942698

Epoch: 5| Step: 10
Training loss: 0.7838901921270531
Validation loss: 2.796999177360482

Epoch: 5| Step: 11
Training loss: 0.2418446113165909
Validation loss: 2.7818200852267556

Epoch: 279| Step: 0
Training loss: 0.45161483949708175
Validation loss: 2.791482390304759

Epoch: 5| Step: 1
Training loss: 0.5961709608716609
Validation loss: 2.8500330581476656

Epoch: 5| Step: 2
Training loss: 0.6038997378374475
Validation loss: 2.789730376731021

Epoch: 5| Step: 3
Training loss: 0.4100374685588832
Validation loss: 2.7599947960892055

Epoch: 5| Step: 4
Training loss: 0.8531847559084366
Validation loss: 2.742810355197902

Epoch: 5| Step: 5
Training loss: 0.6496401056394532
Validation loss: 2.7504714178842313

Epoch: 5| Step: 6
Training loss: 0.7547814620701622
Validation loss: 2.7856246568626677

Epoch: 5| Step: 7
Training loss: 0.5542547391397217
Validation loss: 2.7465225145461276

Epoch: 5| Step: 8
Training loss: 0.37854989982193515
Validation loss: 2.739634329656012

Epoch: 5| Step: 9
Training loss: 0.6490159040318616
Validation loss: 2.766390139671026

Epoch: 5| Step: 10
Training loss: 0.5238745274142276
Validation loss: 2.8050132817278617

Epoch: 5| Step: 11
Training loss: 0.45867836673582346
Validation loss: 2.771329187659267

Epoch: 280| Step: 0
Training loss: 0.6177465586765202
Validation loss: 2.811194395858494

Epoch: 5| Step: 1
Training loss: 0.6428392105969606
Validation loss: 2.7792556555902244

Epoch: 5| Step: 2
Training loss: 0.7001559194552547
Validation loss: 2.816165471112852

Epoch: 5| Step: 3
Training loss: 0.6911364745651762
Validation loss: 2.7153448872729773

Epoch: 5| Step: 4
Training loss: 0.8250876813591038
Validation loss: 2.6536747173101274

Epoch: 5| Step: 5
Training loss: 0.524498788819492
Validation loss: 2.878596412966534

Epoch: 5| Step: 6
Training loss: 0.43187831358459605
Validation loss: 2.7565715760786254

Epoch: 5| Step: 7
Training loss: 0.5767910233084146
Validation loss: 2.6908363473421875

Epoch: 5| Step: 8
Training loss: 0.4615214899500672
Validation loss: 2.7395826359060194

Epoch: 5| Step: 9
Training loss: 0.5031730581515518
Validation loss: 2.7846739227839516

Epoch: 5| Step: 10
Training loss: 0.2979950356053948
Validation loss: 2.7710561853914717

Epoch: 5| Step: 11
Training loss: 0.5832101033247419
Validation loss: 2.814444950258665

Epoch: 281| Step: 0
Training loss: 0.4714733802000155
Validation loss: 2.8071203102842364

Epoch: 5| Step: 1
Training loss: 0.46767969326980685
Validation loss: 2.725888016718923

Epoch: 5| Step: 2
Training loss: 0.8520479480947704
Validation loss: 2.7013322217620637

Epoch: 5| Step: 3
Training loss: 0.8178023306564552
Validation loss: 2.7511031762993254

Epoch: 5| Step: 4
Training loss: 0.4900041320684945
Validation loss: 2.7266547215704513

Epoch: 5| Step: 5
Training loss: 0.46087843306369597
Validation loss: 2.7563749534442357

Epoch: 5| Step: 6
Training loss: 0.6562552678941281
Validation loss: 2.7534316246874315

Epoch: 5| Step: 7
Training loss: 0.5960143480125965
Validation loss: 2.7093254595212524

Epoch: 5| Step: 8
Training loss: 0.5565276181804387
Validation loss: 2.7204461890361955

Epoch: 5| Step: 9
Training loss: 0.5522351116299307
Validation loss: 2.7400812390389455

Epoch: 5| Step: 10
Training loss: 0.49375887210938857
Validation loss: 2.8292426645936026

Epoch: 5| Step: 11
Training loss: 0.8089942861527336
Validation loss: 2.820735346690168

Epoch: 282| Step: 0
Training loss: 0.5083728339789503
Validation loss: 2.702927098903652

Epoch: 5| Step: 1
Training loss: 0.4771055035943922
Validation loss: 2.717587916897717

Epoch: 5| Step: 2
Training loss: 0.7000331717533271
Validation loss: 2.7002357226952816

Epoch: 5| Step: 3
Training loss: 0.5322157272495829
Validation loss: 2.738394357156489

Epoch: 5| Step: 4
Training loss: 0.49447189505179057
Validation loss: 2.761202487415902

Epoch: 5| Step: 5
Training loss: 0.6020399403582204
Validation loss: 2.6852695742694754

Epoch: 5| Step: 6
Training loss: 0.6642410487073283
Validation loss: 2.7719262854853777

Epoch: 5| Step: 7
Training loss: 0.4438886801852193
Validation loss: 2.760402677008729

Epoch: 5| Step: 8
Training loss: 0.7965661740732746
Validation loss: 2.763209903059481

Epoch: 5| Step: 9
Training loss: 0.6551078211878096
Validation loss: 2.765020164257562

Epoch: 5| Step: 10
Training loss: 0.7819301696145913
Validation loss: 2.7630389455956066

Epoch: 5| Step: 11
Training loss: 0.4044013510347545
Validation loss: 2.6718364512021795

Epoch: 283| Step: 0
Training loss: 0.7979989446809909
Validation loss: 2.6989016091262616

Epoch: 5| Step: 1
Training loss: 0.6680743262305651
Validation loss: 2.765815246992598

Epoch: 5| Step: 2
Training loss: 0.6931111065888447
Validation loss: 2.776585013420497

Epoch: 5| Step: 3
Training loss: 0.5375667774503492
Validation loss: 2.781710661552972

Epoch: 5| Step: 4
Training loss: 0.6554427176979257
Validation loss: 2.7303855021042103

Epoch: 5| Step: 5
Training loss: 0.5804757190968838
Validation loss: 2.718375498091679

Epoch: 5| Step: 6
Training loss: 0.5327663658954317
Validation loss: 2.7869072502000036

Epoch: 5| Step: 7
Training loss: 0.6974219352693939
Validation loss: 2.7624756973083673

Epoch: 5| Step: 8
Training loss: 0.5367171919132366
Validation loss: 2.720156915792303

Epoch: 5| Step: 9
Training loss: 0.43103521706666553
Validation loss: 2.8103844916271874

Epoch: 5| Step: 10
Training loss: 0.4827709402326413
Validation loss: 2.7773573526799575

Epoch: 5| Step: 11
Training loss: 0.48021660368025104
Validation loss: 2.753386576072694

Epoch: 284| Step: 0
Training loss: 0.5740445450169318
Validation loss: 2.7618382350284287

Epoch: 5| Step: 1
Training loss: 0.7316003693658429
Validation loss: 2.7160636228638713

Epoch: 5| Step: 2
Training loss: 0.6947046902237535
Validation loss: 2.7288534564672244

Epoch: 5| Step: 3
Training loss: 0.6482166005941083
Validation loss: 2.762190527144832

Epoch: 5| Step: 4
Training loss: 0.6320455636760142
Validation loss: 2.708215994616099

Epoch: 5| Step: 5
Training loss: 0.4733770564809995
Validation loss: 2.764575619077137

Epoch: 5| Step: 6
Training loss: 0.5106878598204575
Validation loss: 2.8052552834165763

Epoch: 5| Step: 7
Training loss: 0.5921285474114095
Validation loss: 2.816451824946436

Epoch: 5| Step: 8
Training loss: 0.5671775302063282
Validation loss: 2.8334980325419963

Epoch: 5| Step: 9
Training loss: 0.6590814813997928
Validation loss: 2.712895425637092

Epoch: 5| Step: 10
Training loss: 0.6234750741138168
Validation loss: 2.791947284278247

Epoch: 5| Step: 11
Training loss: 0.4815488630439614
Validation loss: 2.8196962551570226

Epoch: 285| Step: 0
Training loss: 0.5456461041750728
Validation loss: 2.752636988987596

Epoch: 5| Step: 1
Training loss: 0.8968606794855529
Validation loss: 2.767849675767615

Epoch: 5| Step: 2
Training loss: 0.7513503792421949
Validation loss: 2.795553076143164

Epoch: 5| Step: 3
Training loss: 0.5107736960733823
Validation loss: 2.790715967869297

Epoch: 5| Step: 4
Training loss: 0.921616437180203
Validation loss: 2.6923745143330344

Epoch: 5| Step: 5
Training loss: 0.4739713422506062
Validation loss: 2.708961580231467

Epoch: 5| Step: 6
Training loss: 0.7471841563329864
Validation loss: 2.7581639016447395

Epoch: 5| Step: 7
Training loss: 0.729180408529946
Validation loss: 2.8717070635929973

Epoch: 5| Step: 8
Training loss: 0.7266816892587615
Validation loss: 2.822890775404621

Epoch: 5| Step: 9
Training loss: 0.49558634603655966
Validation loss: 2.8502857746769705

Epoch: 5| Step: 10
Training loss: 0.7043707725783914
Validation loss: 2.8262411555911484

Epoch: 5| Step: 11
Training loss: 0.2530240210694462
Validation loss: 2.7608787017991805

Epoch: 286| Step: 0
Training loss: 0.6211799225917392
Validation loss: 2.784182852363371

Epoch: 5| Step: 1
Training loss: 0.41831928777039323
Validation loss: 2.8434600228102624

Epoch: 5| Step: 2
Training loss: 0.4663800090008566
Validation loss: 2.6477343883448556

Epoch: 5| Step: 3
Training loss: 0.63522054949714
Validation loss: 2.696946475340509

Epoch: 5| Step: 4
Training loss: 0.5272353166784837
Validation loss: 2.7512718785161443

Epoch: 5| Step: 5
Training loss: 0.5498545541051434
Validation loss: 2.7460988832862596

Epoch: 5| Step: 6
Training loss: 0.5754012822279766
Validation loss: 2.7141778033091204

Epoch: 5| Step: 7
Training loss: 0.5512292000788712
Validation loss: 2.752849182994245

Epoch: 5| Step: 8
Training loss: 0.875545263696534
Validation loss: 2.772624065763783

Epoch: 5| Step: 9
Training loss: 0.857025228529635
Validation loss: 2.657018924195884

Epoch: 5| Step: 10
Training loss: 0.6460583484549853
Validation loss: 2.8526696098323896

Epoch: 5| Step: 11
Training loss: 0.7950259803629419
Validation loss: 2.769254443742112

Epoch: 287| Step: 0
Training loss: 0.6852533304299856
Validation loss: 2.732144675965094

Epoch: 5| Step: 1
Training loss: 0.4614561040693848
Validation loss: 2.7223983963630207

Epoch: 5| Step: 2
Training loss: 0.44261409280045394
Validation loss: 2.7451056072253666

Epoch: 5| Step: 3
Training loss: 0.5473433804871501
Validation loss: 2.784903223672258

Epoch: 5| Step: 4
Training loss: 0.7764081068471598
Validation loss: 2.6912699140280574

Epoch: 5| Step: 5
Training loss: 0.6912842335769172
Validation loss: 2.7030174586783304

Epoch: 5| Step: 6
Training loss: 0.6005731100557862
Validation loss: 2.720360856025389

Epoch: 5| Step: 7
Training loss: 0.43951098590981796
Validation loss: 2.7418820681110216

Epoch: 5| Step: 8
Training loss: 0.5854702676102348
Validation loss: 2.716298240172395

Epoch: 5| Step: 9
Training loss: 0.5343114770533004
Validation loss: 2.716951754790203

Epoch: 5| Step: 10
Training loss: 0.5883581134082082
Validation loss: 2.807198295857023

Epoch: 5| Step: 11
Training loss: 0.3599580099201012
Validation loss: 2.7468799209116668

Epoch: 288| Step: 0
Training loss: 0.5331452167072104
Validation loss: 2.760745141741037

Epoch: 5| Step: 1
Training loss: 0.5620747124095891
Validation loss: 2.7621888907550938

Epoch: 5| Step: 2
Training loss: 0.7632470864153822
Validation loss: 2.798113962310318

Epoch: 5| Step: 3
Training loss: 0.4567686125100699
Validation loss: 2.743583066868708

Epoch: 5| Step: 4
Training loss: 0.5302937540619846
Validation loss: 2.794415740669807

Epoch: 5| Step: 5
Training loss: 0.4194303430291394
Validation loss: 2.787988618041868

Epoch: 5| Step: 6
Training loss: 0.6904157666822271
Validation loss: 2.7333332874910616

Epoch: 5| Step: 7
Training loss: 0.5521969288494308
Validation loss: 2.744904406631162

Epoch: 5| Step: 8
Training loss: 0.624690861542642
Validation loss: 2.7483202850896857

Epoch: 5| Step: 9
Training loss: 0.5302131295377571
Validation loss: 2.717396081132422

Epoch: 5| Step: 10
Training loss: 0.4887104284506278
Validation loss: 2.7777259660233318

Epoch: 5| Step: 11
Training loss: 0.8037071181585472
Validation loss: 2.7492636865280544

Epoch: 289| Step: 0
Training loss: 0.39165838880448794
Validation loss: 2.7503578195275566

Epoch: 5| Step: 1
Training loss: 0.8501913949116826
Validation loss: 2.8324460903064312

Epoch: 5| Step: 2
Training loss: 0.695048292732598
Validation loss: 2.7310283889601

Epoch: 5| Step: 3
Training loss: 0.6272888710654795
Validation loss: 2.767324618635131

Epoch: 5| Step: 4
Training loss: 0.5764107160635642
Validation loss: 2.7579830502373515

Epoch: 5| Step: 5
Training loss: 0.5601559116250776
Validation loss: 2.774137879531007

Epoch: 5| Step: 6
Training loss: 0.5323431604738725
Validation loss: 2.8252524194221253

Epoch: 5| Step: 7
Training loss: 0.7592720448594239
Validation loss: 2.7227447509976557

Epoch: 5| Step: 8
Training loss: 0.40808881409365994
Validation loss: 2.7379734593710316

Epoch: 5| Step: 9
Training loss: 0.7086862404887218
Validation loss: 2.7433439462633364

Epoch: 5| Step: 10
Training loss: 0.5270319829461265
Validation loss: 2.750936969891509

Epoch: 5| Step: 11
Training loss: 0.33003331619481363
Validation loss: 2.731608791775887

Epoch: 290| Step: 0
Training loss: 0.6007223827159149
Validation loss: 2.696213441732664

Epoch: 5| Step: 1
Training loss: 0.4643745458557044
Validation loss: 2.723464867634361

Epoch: 5| Step: 2
Training loss: 0.27884939666779907
Validation loss: 2.793888458132155

Epoch: 5| Step: 3
Training loss: 0.37171380291886275
Validation loss: 2.7682832238322224

Epoch: 5| Step: 4
Training loss: 0.5149957690018858
Validation loss: 2.7539959976326034

Epoch: 5| Step: 5
Training loss: 0.6246071057400685
Validation loss: 2.7381229853729683

Epoch: 5| Step: 6
Training loss: 0.7571511282944612
Validation loss: 2.7346078682695443

Epoch: 5| Step: 7
Training loss: 0.5906792338261803
Validation loss: 2.7220500451791154

Epoch: 5| Step: 8
Training loss: 0.5169084643286601
Validation loss: 2.793420754161394

Epoch: 5| Step: 9
Training loss: 0.5907986723664747
Validation loss: 2.686104574845348

Epoch: 5| Step: 10
Training loss: 0.6264305194540783
Validation loss: 2.7964360480500607

Epoch: 5| Step: 11
Training loss: 0.43359165362976815
Validation loss: 2.851716076621448

Epoch: 291| Step: 0
Training loss: 0.4435620285898138
Validation loss: 2.7551447795516

Epoch: 5| Step: 1
Training loss: 0.5237115171219731
Validation loss: 2.781476833080168

Epoch: 5| Step: 2
Training loss: 0.4964615517209269
Validation loss: 2.7502871529615724

Epoch: 5| Step: 3
Training loss: 0.5770502668563402
Validation loss: 2.7054453723296583

Epoch: 5| Step: 4
Training loss: 0.7564923300143125
Validation loss: 2.750426736146821

Epoch: 5| Step: 5
Training loss: 0.6393920617609822
Validation loss: 2.739566963688398

Epoch: 5| Step: 6
Training loss: 0.3922945773090491
Validation loss: 2.7739104785484785

Epoch: 5| Step: 7
Training loss: 0.6034232997952044
Validation loss: 2.7380765438428902

Epoch: 5| Step: 8
Training loss: 0.873370560757755
Validation loss: 2.7691687098688913

Epoch: 5| Step: 9
Training loss: 0.6441095301870815
Validation loss: 2.7529756962347385

Epoch: 5| Step: 10
Training loss: 0.6082525675429761
Validation loss: 2.7861999546415213

Epoch: 5| Step: 11
Training loss: 0.41364474185071753
Validation loss: 2.769998275197407

Epoch: 292| Step: 0
Training loss: 0.4525228478527783
Validation loss: 2.788050167747277

Epoch: 5| Step: 1
Training loss: 0.44201353378095176
Validation loss: 2.7144557940973684

Epoch: 5| Step: 2
Training loss: 0.5242813482303212
Validation loss: 2.721881491693112

Epoch: 5| Step: 3
Training loss: 0.5427490723073544
Validation loss: 2.780155634508651

Epoch: 5| Step: 4
Training loss: 0.5432339027712806
Validation loss: 2.746520756694973

Epoch: 5| Step: 5
Training loss: 0.5543987704731985
Validation loss: 2.729354638379755

Epoch: 5| Step: 6
Training loss: 0.5009822138714808
Validation loss: 2.76008820408936

Epoch: 5| Step: 7
Training loss: 0.7639042337398406
Validation loss: 2.7672160685102214

Epoch: 5| Step: 8
Training loss: 0.5096671056730993
Validation loss: 2.744100484859893

Epoch: 5| Step: 9
Training loss: 0.7638669752580567
Validation loss: 2.732475496556272

Epoch: 5| Step: 10
Training loss: 0.6075585999502473
Validation loss: 2.7749351863337215

Epoch: 5| Step: 11
Training loss: 0.4432890748068542
Validation loss: 2.865522176464042

Epoch: 293| Step: 0
Training loss: 0.8125558613867683
Validation loss: 2.777872903440127

Epoch: 5| Step: 1
Training loss: 0.5548735830310828
Validation loss: 2.724382259332679

Epoch: 5| Step: 2
Training loss: 0.7450157486447919
Validation loss: 2.7926188358667834

Epoch: 5| Step: 3
Training loss: 0.25510655371775937
Validation loss: 2.7467820601351

Epoch: 5| Step: 4
Training loss: 0.3183859597556193
Validation loss: 2.752444871078403

Epoch: 5| Step: 5
Training loss: 0.7241580925387421
Validation loss: 2.7425898648899865

Epoch: 5| Step: 6
Training loss: 0.8028826797001654
Validation loss: 2.7297006089598668

Epoch: 5| Step: 7
Training loss: 0.6606496513264154
Validation loss: 2.7038905469072314

Epoch: 5| Step: 8
Training loss: 0.5230059196727957
Validation loss: 2.7117932789213013

Epoch: 5| Step: 9
Training loss: 0.5379482861697648
Validation loss: 2.682065066546554

Epoch: 5| Step: 10
Training loss: 0.5045019664990725
Validation loss: 2.706412060608059

Epoch: 5| Step: 11
Training loss: 0.26984149934131596
Validation loss: 2.736529161146273

Epoch: 294| Step: 0
Training loss: 0.5098756985557878
Validation loss: 2.690986899605925

Epoch: 5| Step: 1
Training loss: 0.6643748951047884
Validation loss: 2.7711787629940563

Epoch: 5| Step: 2
Training loss: 0.47642852901263283
Validation loss: 2.6984316851021837

Epoch: 5| Step: 3
Training loss: 0.6753311422264778
Validation loss: 2.739667000357201

Epoch: 5| Step: 4
Training loss: 0.37453107522730433
Validation loss: 2.7790995009702386

Epoch: 5| Step: 5
Training loss: 0.5224582279883743
Validation loss: 2.7132958333152315

Epoch: 5| Step: 6
Training loss: 0.48605368044095193
Validation loss: 2.7478112194507025

Epoch: 5| Step: 7
Training loss: 0.5165871400027758
Validation loss: 2.793612849163863

Epoch: 5| Step: 8
Training loss: 0.6278261659994688
Validation loss: 2.7113350605112254

Epoch: 5| Step: 9
Training loss: 0.5918739444920635
Validation loss: 2.7466972234235296

Epoch: 5| Step: 10
Training loss: 0.707874995960988
Validation loss: 2.741895089494347

Epoch: 5| Step: 11
Training loss: 0.5002741062317405
Validation loss: 2.752702227060512

Epoch: 295| Step: 0
Training loss: 0.5393616772152238
Validation loss: 2.755102535348616

Epoch: 5| Step: 1
Training loss: 0.3294523729510698
Validation loss: 2.7442155078884065

Epoch: 5| Step: 2
Training loss: 0.6238313955509108
Validation loss: 2.7640855746890143

Epoch: 5| Step: 3
Training loss: 0.6833651351118999
Validation loss: 2.75781139413381

Epoch: 5| Step: 4
Training loss: 0.4739128621964171
Validation loss: 2.766205671023904

Epoch: 5| Step: 5
Training loss: 0.43583014817408133
Validation loss: 2.762043251782216

Epoch: 5| Step: 6
Training loss: 0.6451865823848769
Validation loss: 2.813781386332701

Epoch: 5| Step: 7
Training loss: 0.3704512404636411
Validation loss: 2.7002684010184588

Epoch: 5| Step: 8
Training loss: 0.5450947258373086
Validation loss: 2.8458914187206488

Epoch: 5| Step: 9
Training loss: 0.5831377660942366
Validation loss: 2.7782417880706722

Epoch: 5| Step: 10
Training loss: 0.4992184491223785
Validation loss: 2.77834746532435

Epoch: 5| Step: 11
Training loss: 0.19295966130833947
Validation loss: 2.7598527956201724

Epoch: 296| Step: 0
Training loss: 0.6036625161771662
Validation loss: 2.775237556834198

Epoch: 5| Step: 1
Training loss: 0.4898973955776648
Validation loss: 2.782127524108697

Epoch: 5| Step: 2
Training loss: 0.7527258531516632
Validation loss: 2.7508721955308584

Epoch: 5| Step: 3
Training loss: 0.5015311341267448
Validation loss: 2.7986880345233818

Epoch: 5| Step: 4
Training loss: 0.80518792156554
Validation loss: 2.7701129275586878

Epoch: 5| Step: 5
Training loss: 0.3670044097570495
Validation loss: 2.798256655354979

Epoch: 5| Step: 6
Training loss: 0.46708111907384225
Validation loss: 2.776358832633997

Epoch: 5| Step: 7
Training loss: 0.6270843796283024
Validation loss: 2.7568015063652833

Epoch: 5| Step: 8
Training loss: 0.62745584552938
Validation loss: 2.806381790589478

Epoch: 5| Step: 9
Training loss: 0.49357313054493035
Validation loss: 2.7692874645120935

Epoch: 5| Step: 10
Training loss: 0.4928201666110447
Validation loss: 2.8003905204226274

Epoch: 5| Step: 11
Training loss: 0.6796794320866355
Validation loss: 2.7317717885226944

Epoch: 297| Step: 0
Training loss: 0.5797512533495911
Validation loss: 2.7667764253177913

Epoch: 5| Step: 1
Training loss: 0.6550257935432079
Validation loss: 2.7511330567827397

Epoch: 5| Step: 2
Training loss: 0.5210322445283563
Validation loss: 2.7528208440107895

Epoch: 5| Step: 3
Training loss: 0.461843505374052
Validation loss: 2.7749460585967602

Epoch: 5| Step: 4
Training loss: 0.4341479016542496
Validation loss: 2.8009117730947555

Epoch: 5| Step: 5
Training loss: 0.4366249802701625
Validation loss: 2.7914994151748935

Epoch: 5| Step: 6
Training loss: 0.5869414312039898
Validation loss: 2.8453029612158383

Epoch: 5| Step: 7
Training loss: 0.42674677854192483
Validation loss: 2.810672070628861

Epoch: 5| Step: 8
Training loss: 0.6843114954081969
Validation loss: 2.7919681526244555

Epoch: 5| Step: 9
Training loss: 0.7502098187367711
Validation loss: 2.764164264071454

Epoch: 5| Step: 10
Training loss: 0.4235535536506982
Validation loss: 2.7880648120585296

Epoch: 5| Step: 11
Training loss: 0.6499484050887578
Validation loss: 2.784118041523803

Epoch: 298| Step: 0
Training loss: 0.5259305030778917
Validation loss: 2.772629483142935

Epoch: 5| Step: 1
Training loss: 0.4621232831188912
Validation loss: 2.7460368635743704

Epoch: 5| Step: 2
Training loss: 0.736391950112728
Validation loss: 2.787815980151146

Epoch: 5| Step: 3
Training loss: 0.4695819782902083
Validation loss: 2.813986336063739

Epoch: 5| Step: 4
Training loss: 0.7004284118228856
Validation loss: 2.8018241476469967

Epoch: 5| Step: 5
Training loss: 0.41190260631100667
Validation loss: 2.8103470473907497

Epoch: 5| Step: 6
Training loss: 0.3835481465068734
Validation loss: 2.770497751111243

Epoch: 5| Step: 7
Training loss: 0.667342154202421
Validation loss: 2.760451393388842

Epoch: 5| Step: 8
Training loss: 0.5218262712491571
Validation loss: 2.8231952196663563

Epoch: 5| Step: 9
Training loss: 0.5503832955342793
Validation loss: 2.776505795888898

Epoch: 5| Step: 10
Training loss: 0.5755045501568877
Validation loss: 2.7239825330915055

Epoch: 5| Step: 11
Training loss: 0.2395025597427572
Validation loss: 2.729881310747406

Epoch: 299| Step: 0
Training loss: 0.3987222663657964
Validation loss: 2.7619990305959874

Epoch: 5| Step: 1
Training loss: 0.568898053863249
Validation loss: 2.790033632637449

Epoch: 5| Step: 2
Training loss: 0.7300773020536092
Validation loss: 2.715473956321816

Epoch: 5| Step: 3
Training loss: 0.575447325233861
Validation loss: 2.785482853826137

Epoch: 5| Step: 4
Training loss: 0.7470657647686335
Validation loss: 2.7494306878129247

Epoch: 5| Step: 5
Training loss: 0.4462930190831264
Validation loss: 2.8171959809006193

Epoch: 5| Step: 6
Training loss: 0.4580088048082351
Validation loss: 2.77522883703155

Epoch: 5| Step: 7
Training loss: 0.49742185980591735
Validation loss: 2.7732504087572933

Epoch: 5| Step: 8
Training loss: 0.5318451520924965
Validation loss: 2.782327486124457

Epoch: 5| Step: 9
Training loss: 0.5220726210075399
Validation loss: 2.689239042797807

Epoch: 5| Step: 10
Training loss: 0.5809437878346908
Validation loss: 2.840112263308681

Epoch: 5| Step: 11
Training loss: 0.3285727624725431
Validation loss: 2.780284706935234

Epoch: 300| Step: 0
Training loss: 0.48430260763330785
Validation loss: 2.763051694697044

Epoch: 5| Step: 1
Training loss: 0.3589735899125977
Validation loss: 2.7835741012240924

Epoch: 5| Step: 2
Training loss: 0.40839168081436433
Validation loss: 2.740899869589254

Epoch: 5| Step: 3
Training loss: 0.41044818842647607
Validation loss: 2.7223697002570715

Epoch: 5| Step: 4
Training loss: 0.5194200669255933
Validation loss: 2.7271553750329995

Epoch: 5| Step: 5
Training loss: 0.49443979969533813
Validation loss: 2.725093613483561

Epoch: 5| Step: 6
Training loss: 0.5007938103729805
Validation loss: 2.7581607609515286

Epoch: 5| Step: 7
Training loss: 0.6765063590704543
Validation loss: 2.828881097678426

Epoch: 5| Step: 8
Training loss: 0.7844307047604548
Validation loss: 2.7864393655481967

Epoch: 5| Step: 9
Training loss: 0.42258404381151354
Validation loss: 2.7305419613724125

Epoch: 5| Step: 10
Training loss: 0.6234076958896307
Validation loss: 2.7155967601190127

Epoch: 5| Step: 11
Training loss: 0.1993501641162075
Validation loss: 2.7289939029747106

Epoch: 301| Step: 0
Training loss: 0.4378751780961241
Validation loss: 2.73619516010145

Epoch: 5| Step: 1
Training loss: 0.6466624311508347
Validation loss: 2.8101113984741892

Epoch: 5| Step: 2
Training loss: 0.78928447660412
Validation loss: 2.722993940138848

Epoch: 5| Step: 3
Training loss: 0.4140793958851503
Validation loss: 2.674963502694348

Epoch: 5| Step: 4
Training loss: 0.6512587655808287
Validation loss: 2.7413423074342393

Epoch: 5| Step: 5
Training loss: 0.33352731360306487
Validation loss: 2.7697356650343656

Epoch: 5| Step: 6
Training loss: 0.38131016194043027
Validation loss: 2.7574576238694513

Epoch: 5| Step: 7
Training loss: 0.5745957881895283
Validation loss: 2.6685204370707316

Epoch: 5| Step: 8
Training loss: 0.40197865115005216
Validation loss: 2.794117655233702

Epoch: 5| Step: 9
Training loss: 0.5405222712470887
Validation loss: 2.7480005740720843

Epoch: 5| Step: 10
Training loss: 0.7608413337866258
Validation loss: 2.7808041304473505

Epoch: 5| Step: 11
Training loss: 0.6484446697528132
Validation loss: 2.684229283639226

Epoch: 302| Step: 0
Training loss: 0.7187449413619114
Validation loss: 2.7159275480477305

Epoch: 5| Step: 1
Training loss: 0.652629926578534
Validation loss: 2.7126036296040366

Epoch: 5| Step: 2
Training loss: 0.4219076709106017
Validation loss: 2.7782211849180993

Epoch: 5| Step: 3
Training loss: 0.6159753364155502
Validation loss: 2.731777737841807

Epoch: 5| Step: 4
Training loss: 0.40342502296945537
Validation loss: 2.7340936461521235

Epoch: 5| Step: 5
Training loss: 0.5634698454193711
Validation loss: 2.739073990055871

Epoch: 5| Step: 6
Training loss: 0.5915609714188049
Validation loss: 2.8039594287918828

Epoch: 5| Step: 7
Training loss: 0.6176341408425838
Validation loss: 2.7061666270239964

Epoch: 5| Step: 8
Training loss: 0.4089905112606858
Validation loss: 2.760815986804679

Epoch: 5| Step: 9
Training loss: 0.4775389064796364
Validation loss: 2.7446618794418085

Epoch: 5| Step: 10
Training loss: 0.5139618261945607
Validation loss: 2.723061475330218

Epoch: 5| Step: 11
Training loss: 0.41146114404740414
Validation loss: 2.739839118842656

Epoch: 303| Step: 0
Training loss: 0.7062311651030779
Validation loss: 2.6844368044895894

Epoch: 5| Step: 1
Training loss: 0.5121056353609257
Validation loss: 2.63831326720639

Epoch: 5| Step: 2
Training loss: 0.5265622600249245
Validation loss: 2.750939909384214

Epoch: 5| Step: 3
Training loss: 0.3025390733358087
Validation loss: 2.7040127397163993

Epoch: 5| Step: 4
Training loss: 0.548259290993064
Validation loss: 2.7019460308413272

Epoch: 5| Step: 5
Training loss: 0.7573963084241475
Validation loss: 2.712878215075736

Epoch: 5| Step: 6
Training loss: 0.545038600438344
Validation loss: 2.7436917590634233

Epoch: 5| Step: 7
Training loss: 0.6607953651491975
Validation loss: 2.694719350665589

Epoch: 5| Step: 8
Training loss: 0.4695589079621106
Validation loss: 2.790527838581494

Epoch: 5| Step: 9
Training loss: 0.6970544489933697
Validation loss: 2.773703355538815

Epoch: 5| Step: 10
Training loss: 0.4861727700032893
Validation loss: 2.6792282419015625

Epoch: 5| Step: 11
Training loss: 0.3128904645064534
Validation loss: 2.7894677794674787

Epoch: 304| Step: 0
Training loss: 0.32701616032795494
Validation loss: 2.7355406392910804

Epoch: 5| Step: 1
Training loss: 0.39838992564091386
Validation loss: 2.7421005177264925

Epoch: 5| Step: 2
Training loss: 0.4700971477882526
Validation loss: 2.7880372140594285

Epoch: 5| Step: 3
Training loss: 0.6542054525244355
Validation loss: 2.806094295852064

Epoch: 5| Step: 4
Training loss: 0.5019452580529403
Validation loss: 2.786801883279896

Epoch: 5| Step: 5
Training loss: 0.40593848756195766
Validation loss: 2.800792848358187

Epoch: 5| Step: 6
Training loss: 0.5238405355623282
Validation loss: 2.7913448494607658

Epoch: 5| Step: 7
Training loss: 0.8294193301394931
Validation loss: 2.77211524713554

Epoch: 5| Step: 8
Training loss: 0.4499744692818533
Validation loss: 2.754225399922349

Epoch: 5| Step: 9
Training loss: 0.5608349103277216
Validation loss: 2.785982185158021

Epoch: 5| Step: 10
Training loss: 0.34536464737567624
Validation loss: 2.7469585028445174

Epoch: 5| Step: 11
Training loss: 0.25374107857228145
Validation loss: 2.75886243334403

Epoch: 305| Step: 0
Training loss: 0.600475518225455
Validation loss: 2.6769578968649235

Epoch: 5| Step: 1
Training loss: 0.8053741488324193
Validation loss: 2.8338009200690597

Epoch: 5| Step: 2
Training loss: 0.5199164489875668
Validation loss: 2.7440584471356635

Epoch: 5| Step: 3
Training loss: 0.47099795150311363
Validation loss: 2.762297811056599

Epoch: 5| Step: 4
Training loss: 0.5071974918229756
Validation loss: 2.730030839664924

Epoch: 5| Step: 5
Training loss: 0.5142047279507032
Validation loss: 2.806149727602358

Epoch: 5| Step: 6
Training loss: 0.6605462947867725
Validation loss: 2.7574902671326327

Epoch: 5| Step: 7
Training loss: 0.7360541443604375
Validation loss: 2.7787952108847964

Epoch: 5| Step: 8
Training loss: 0.48907752151088846
Validation loss: 2.81830695745269

Epoch: 5| Step: 9
Training loss: 0.47222000671627445
Validation loss: 2.7070491839718946

Epoch: 5| Step: 10
Training loss: 0.4674571646481296
Validation loss: 2.816115256279262

Epoch: 5| Step: 11
Training loss: 0.3203194082492108
Validation loss: 2.766235528429149

Epoch: 306| Step: 0
Training loss: 0.6696933990660159
Validation loss: 2.775022753917209

Epoch: 5| Step: 1
Training loss: 0.39970283049410826
Validation loss: 2.7055154899006166

Epoch: 5| Step: 2
Training loss: 0.556972953239025
Validation loss: 2.835344089604107

Epoch: 5| Step: 3
Training loss: 0.47371822255634494
Validation loss: 2.725077686602326

Epoch: 5| Step: 4
Training loss: 0.5731676563375673
Validation loss: 2.7878466145449625

Epoch: 5| Step: 5
Training loss: 0.3755638532647497
Validation loss: 2.7191614701956657

Epoch: 5| Step: 6
Training loss: 0.585880734554978
Validation loss: 2.689475752680603

Epoch: 5| Step: 7
Training loss: 0.6510487797666434
Validation loss: 2.7536856705004022

Epoch: 5| Step: 8
Training loss: 0.4726143337610996
Validation loss: 2.7208110407275794

Epoch: 5| Step: 9
Training loss: 0.4620123792864122
Validation loss: 2.763077419227698

Epoch: 5| Step: 10
Training loss: 0.5597761484609066
Validation loss: 2.723892128445588

Epoch: 5| Step: 11
Training loss: 0.808744333592276
Validation loss: 2.7421702559201546

Epoch: 307| Step: 0
Training loss: 0.710771059108692
Validation loss: 2.7279652700604653

Epoch: 5| Step: 1
Training loss: 0.698010813118323
Validation loss: 2.7490011626493573

Epoch: 5| Step: 2
Training loss: 0.4928748463033755
Validation loss: 2.7692925296947766

Epoch: 5| Step: 3
Training loss: 0.5259580986445307
Validation loss: 2.752752479929268

Epoch: 5| Step: 4
Training loss: 0.402977065362589
Validation loss: 2.7343303894763586

Epoch: 5| Step: 5
Training loss: 0.7521446875768717
Validation loss: 2.7980555807827905

Epoch: 5| Step: 6
Training loss: 0.6083868279734774
Validation loss: 2.8129594816060033

Epoch: 5| Step: 7
Training loss: 0.4365606441472009
Validation loss: 2.7666383923288436

Epoch: 5| Step: 8
Training loss: 0.5565093839424867
Validation loss: 2.727431642443233

Epoch: 5| Step: 9
Training loss: 0.4588293909607188
Validation loss: 2.710766804329549

Epoch: 5| Step: 10
Training loss: 0.5426441017941738
Validation loss: 2.7269450395711323

Epoch: 5| Step: 11
Training loss: 0.5699500146916877
Validation loss: 2.7081116304376436

Epoch: 308| Step: 0
Training loss: 0.5652983517876996
Validation loss: 2.8082735659939666

Epoch: 5| Step: 1
Training loss: 0.28566469300674013
Validation loss: 2.7550768481335046

Epoch: 5| Step: 2
Training loss: 0.7345700106509866
Validation loss: 2.735080657004456

Epoch: 5| Step: 3
Training loss: 0.34157146105306313
Validation loss: 2.7071459563789118

Epoch: 5| Step: 4
Training loss: 0.4574035204324907
Validation loss: 2.8257281261059726

Epoch: 5| Step: 5
Training loss: 0.6995024505133307
Validation loss: 2.7071847839999426

Epoch: 5| Step: 6
Training loss: 0.6847314359287032
Validation loss: 2.7387557876957547

Epoch: 5| Step: 7
Training loss: 0.508721462452252
Validation loss: 2.770878602616548

Epoch: 5| Step: 8
Training loss: 0.616668410449097
Validation loss: 2.810246467220363

Epoch: 5| Step: 9
Training loss: 0.5021724592803858
Validation loss: 2.8288494081571067

Epoch: 5| Step: 10
Training loss: 0.46947070983465455
Validation loss: 2.734798903531373

Epoch: 5| Step: 11
Training loss: 0.8192091651659921
Validation loss: 2.766506241452211

Epoch: 309| Step: 0
Training loss: 0.4053295602200649
Validation loss: 2.6875931294887323

Epoch: 5| Step: 1
Training loss: 0.5995526613135846
Validation loss: 2.8311847973993407

Epoch: 5| Step: 2
Training loss: 0.4760495066953623
Validation loss: 2.7722000692678397

Epoch: 5| Step: 3
Training loss: 0.5553601176165146
Validation loss: 2.8274240591114137

Epoch: 5| Step: 4
Training loss: 0.43535686847367866
Validation loss: 2.7950780128710497

Epoch: 5| Step: 5
Training loss: 0.554968695487997
Validation loss: 2.8559043193736966

Epoch: 5| Step: 6
Training loss: 0.6327785906713436
Validation loss: 2.702289896981039

Epoch: 5| Step: 7
Training loss: 0.5670919542780815
Validation loss: 2.788799633243881

Epoch: 5| Step: 8
Training loss: 0.5129482844090425
Validation loss: 2.6996880623384527

Epoch: 5| Step: 9
Training loss: 0.6532314907302923
Validation loss: 2.7090013829407624

Epoch: 5| Step: 10
Training loss: 0.3532329293113165
Validation loss: 2.697472106116469

Epoch: 5| Step: 11
Training loss: 1.0437937127742078
Validation loss: 2.7307557849701105

Epoch: 310| Step: 0
Training loss: 0.6845908168709517
Validation loss: 2.7836025981992636

Epoch: 5| Step: 1
Training loss: 0.4690364280433667
Validation loss: 2.7809402529077762

Epoch: 5| Step: 2
Training loss: 0.5702714774649889
Validation loss: 2.7606615005934754

Epoch: 5| Step: 3
Training loss: 0.6290246366351908
Validation loss: 2.7538129894436554

Epoch: 5| Step: 4
Training loss: 0.6225284823447147
Validation loss: 2.79965941565961

Epoch: 5| Step: 5
Training loss: 0.5740463101715911
Validation loss: 2.8120611519522076

Epoch: 5| Step: 6
Training loss: 0.3735794938644864
Validation loss: 2.7886228740287957

Epoch: 5| Step: 7
Training loss: 0.5457261142789763
Validation loss: 2.7538257704353923

Epoch: 5| Step: 8
Training loss: 0.33220598447514665
Validation loss: 2.7638524943393783

Epoch: 5| Step: 9
Training loss: 0.5501142209831789
Validation loss: 2.7886493957499816

Epoch: 5| Step: 10
Training loss: 0.669345040171795
Validation loss: 2.7872309400943696

Epoch: 5| Step: 11
Training loss: 0.39429795572107457
Validation loss: 2.732914827211155

Epoch: 311| Step: 0
Training loss: 0.3889412832822455
Validation loss: 2.7556166872063685

Epoch: 5| Step: 1
Training loss: 0.49979029668652286
Validation loss: 2.723341178394428

Epoch: 5| Step: 2
Training loss: 0.7372415477673063
Validation loss: 2.770326458070507

Epoch: 5| Step: 3
Training loss: 0.498428452867058
Validation loss: 2.827018331587695

Epoch: 5| Step: 4
Training loss: 0.49621488939411446
Validation loss: 2.8372398587711523

Epoch: 5| Step: 5
Training loss: 0.3705108481580924
Validation loss: 2.7474826774913073

Epoch: 5| Step: 6
Training loss: 0.5000223512422127
Validation loss: 2.8542341702314555

Epoch: 5| Step: 7
Training loss: 0.6302076108523764
Validation loss: 2.834773953787266

Epoch: 5| Step: 8
Training loss: 0.4396371074828234
Validation loss: 2.8042942150369212

Epoch: 5| Step: 9
Training loss: 0.4645904684445454
Validation loss: 2.7664543424180574

Epoch: 5| Step: 10
Training loss: 0.6177613692864174
Validation loss: 2.70931164727213

Epoch: 5| Step: 11
Training loss: 0.8053677470596882
Validation loss: 2.6987206698307005

Epoch: 312| Step: 0
Training loss: 0.5229323782466565
Validation loss: 2.794445632605577

Epoch: 5| Step: 1
Training loss: 0.7178721664933404
Validation loss: 2.818876811584393

Epoch: 5| Step: 2
Training loss: 0.6003760738756344
Validation loss: 2.8773819758506614

Epoch: 5| Step: 3
Training loss: 0.5998587571234548
Validation loss: 2.802853507989082

Epoch: 5| Step: 4
Training loss: 0.8178847582230715
Validation loss: 2.777905203095326

Epoch: 5| Step: 5
Training loss: 0.4206598406585234
Validation loss: 2.770702987607075

Epoch: 5| Step: 6
Training loss: 0.4824850064255635
Validation loss: 2.804401737343843

Epoch: 5| Step: 7
Training loss: 0.6603136495714702
Validation loss: 2.7603646627361944

Epoch: 5| Step: 8
Training loss: 0.42350980345470846
Validation loss: 2.791820555094096

Epoch: 5| Step: 9
Training loss: 0.8747322490294189
Validation loss: 2.7432667817235448

Epoch: 5| Step: 10
Training loss: 0.6269090821194738
Validation loss: 2.822183662817165

Epoch: 5| Step: 11
Training loss: 0.22859297364390563
Validation loss: 2.8599778219121164

Epoch: 313| Step: 0
Training loss: 0.601069235761674
Validation loss: 2.8096048147244104

Epoch: 5| Step: 1
Training loss: 0.6412056873024092
Validation loss: 2.8328801551170133

Epoch: 5| Step: 2
Training loss: 0.4055862873806639
Validation loss: 2.825728632351189

Epoch: 5| Step: 3
Training loss: 0.6079464576024401
Validation loss: 2.8148229260309185

Epoch: 5| Step: 4
Training loss: 0.5816483742407147
Validation loss: 2.8145860565157315

Epoch: 5| Step: 5
Training loss: 0.45177939001026235
Validation loss: 2.7713854115447876

Epoch: 5| Step: 6
Training loss: 0.4939995062841041
Validation loss: 2.7531059887994975

Epoch: 5| Step: 7
Training loss: 0.6178949864246005
Validation loss: 2.8257708542892455

Epoch: 5| Step: 8
Training loss: 0.5485871895941355
Validation loss: 2.8371406013877865

Epoch: 5| Step: 9
Training loss: 0.5028062687517956
Validation loss: 2.8029351032963126

Epoch: 5| Step: 10
Training loss: 0.7217425369336671
Validation loss: 2.845181579901667

Epoch: 5| Step: 11
Training loss: 0.35396113696380976
Validation loss: 2.781912642559726

Epoch: 314| Step: 0
Training loss: 0.4122326020328197
Validation loss: 2.749739396144975

Epoch: 5| Step: 1
Training loss: 0.35316883380554126
Validation loss: 2.792008405142195

Epoch: 5| Step: 2
Training loss: 0.5189895099946892
Validation loss: 2.7904514839761307

Epoch: 5| Step: 3
Training loss: 0.3909735650336313
Validation loss: 2.7940929471170173

Epoch: 5| Step: 4
Training loss: 0.7018085872246538
Validation loss: 2.783778955331558

Epoch: 5| Step: 5
Training loss: 0.6638591454993259
Validation loss: 2.751244660678081

Epoch: 5| Step: 6
Training loss: 0.6449666719919307
Validation loss: 2.794910209626086

Epoch: 5| Step: 7
Training loss: 0.7045969919752826
Validation loss: 2.7390325316497757

Epoch: 5| Step: 8
Training loss: 0.4714252425361119
Validation loss: 2.7671578931095175

Epoch: 5| Step: 9
Training loss: 0.43792242705455003
Validation loss: 2.841878523205341

Epoch: 5| Step: 10
Training loss: 0.689770115068559
Validation loss: 2.8178995752688207

Epoch: 5| Step: 11
Training loss: 0.3662700961331414
Validation loss: 2.780886576335918

Epoch: 315| Step: 0
Training loss: 0.5613550613725584
Validation loss: 2.805477711071808

Epoch: 5| Step: 1
Training loss: 0.5216954979023546
Validation loss: 2.7923188598279416

Epoch: 5| Step: 2
Training loss: 0.361798099358418
Validation loss: 2.7610823758248495

Epoch: 5| Step: 3
Training loss: 0.7400646166040284
Validation loss: 2.766885775388651

Epoch: 5| Step: 4
Training loss: 0.5719227202886825
Validation loss: 2.7450884212839974

Epoch: 5| Step: 5
Training loss: 0.7773984573512845
Validation loss: 2.763143395891369

Epoch: 5| Step: 6
Training loss: 0.4314903066580706
Validation loss: 2.7261845600915127

Epoch: 5| Step: 7
Training loss: 0.4268260700449928
Validation loss: 2.7654336838004427

Epoch: 5| Step: 8
Training loss: 0.43918280870725906
Validation loss: 2.742656787156612

Epoch: 5| Step: 9
Training loss: 0.39736958046619686
Validation loss: 2.7179312916588856

Epoch: 5| Step: 10
Training loss: 0.3644542420136076
Validation loss: 2.7646700185501403

Epoch: 5| Step: 11
Training loss: 0.745573851309104
Validation loss: 2.703313765797978

Epoch: 316| Step: 0
Training loss: 0.42198389908393713
Validation loss: 2.726417497570186

Epoch: 5| Step: 1
Training loss: 0.597465085641528
Validation loss: 2.7377108253224014

Epoch: 5| Step: 2
Training loss: 0.5206865930472655
Validation loss: 2.8472722461358466

Epoch: 5| Step: 3
Training loss: 0.6624185521064608
Validation loss: 2.812558381922853

Epoch: 5| Step: 4
Training loss: 0.374811999561255
Validation loss: 2.7649923703764996

Epoch: 5| Step: 5
Training loss: 0.4571372178301431
Validation loss: 2.7468374447213635

Epoch: 5| Step: 6
Training loss: 0.5788998437442064
Validation loss: 2.7347326135661287

Epoch: 5| Step: 7
Training loss: 0.4303103354516645
Validation loss: 2.769740230852157

Epoch: 5| Step: 8
Training loss: 0.6216840517955708
Validation loss: 2.733815061367414

Epoch: 5| Step: 9
Training loss: 0.40956421767080836
Validation loss: 2.7685263155156767

Epoch: 5| Step: 10
Training loss: 0.6962502403190376
Validation loss: 2.6872897620361575

Epoch: 5| Step: 11
Training loss: 0.35941729089435226
Validation loss: 2.7760908123673635

Epoch: 317| Step: 0
Training loss: 0.6136397024908328
Validation loss: 2.7893679190706853

Epoch: 5| Step: 1
Training loss: 0.6045577055347501
Validation loss: 2.7162790652863333

Epoch: 5| Step: 2
Training loss: 0.6621272441962092
Validation loss: 2.683554155334344

Epoch: 5| Step: 3
Training loss: 0.44917658732374705
Validation loss: 2.7445554517024027

Epoch: 5| Step: 4
Training loss: 0.6737206635962221
Validation loss: 2.7932343719014727

Epoch: 5| Step: 5
Training loss: 0.5677130521059055
Validation loss: 2.799877856349301

Epoch: 5| Step: 6
Training loss: 0.6831453214940139
Validation loss: 2.7420034718144866

Epoch: 5| Step: 7
Training loss: 0.4743397892887699
Validation loss: 2.7818821035154597

Epoch: 5| Step: 8
Training loss: 0.5181629835132648
Validation loss: 2.757064681923763

Epoch: 5| Step: 9
Training loss: 0.48496510338347876
Validation loss: 2.7493590055814017

Epoch: 5| Step: 10
Training loss: 0.562799638837388
Validation loss: 2.7612402041370707

Epoch: 5| Step: 11
Training loss: 0.4540030752048448
Validation loss: 2.7746691158565095

Epoch: 318| Step: 0
Training loss: 0.5635156469161309
Validation loss: 2.7495777607924086

Epoch: 5| Step: 1
Training loss: 0.46920665114356164
Validation loss: 2.745715784982665

Epoch: 5| Step: 2
Training loss: 0.6371629955524587
Validation loss: 2.750724704215056

Epoch: 5| Step: 3
Training loss: 0.7287301982459848
Validation loss: 2.7265026228049316

Epoch: 5| Step: 4
Training loss: 0.32694807607017895
Validation loss: 2.693592742849513

Epoch: 5| Step: 5
Training loss: 0.3530067237329826
Validation loss: 2.879226452822722

Epoch: 5| Step: 6
Training loss: 0.39476987968188854
Validation loss: 2.761160111029831

Epoch: 5| Step: 7
Training loss: 0.31859507348579424
Validation loss: 2.804791341433695

Epoch: 5| Step: 8
Training loss: 0.6581568263039462
Validation loss: 2.7509927113828314

Epoch: 5| Step: 9
Training loss: 0.5532679055303289
Validation loss: 2.747804664939904

Epoch: 5| Step: 10
Training loss: 0.5795537460128414
Validation loss: 2.7900293599512906

Epoch: 5| Step: 11
Training loss: 0.29658566982334683
Validation loss: 2.723524388502845

Epoch: 319| Step: 0
Training loss: 0.3499011841141789
Validation loss: 2.8025985135456986

Epoch: 5| Step: 1
Training loss: 0.45911559806043717
Validation loss: 2.718830834571873

Epoch: 5| Step: 2
Training loss: 0.3180925386051429
Validation loss: 2.7549091109325836

Epoch: 5| Step: 3
Training loss: 0.43825233010468523
Validation loss: 2.6995023991500577

Epoch: 5| Step: 4
Training loss: 0.5388398470826576
Validation loss: 2.777411916533827

Epoch: 5| Step: 5
Training loss: 0.5398683467842772
Validation loss: 2.7886672786217543

Epoch: 5| Step: 6
Training loss: 0.48069311346363164
Validation loss: 2.761665185447561

Epoch: 5| Step: 7
Training loss: 0.4370637830696054
Validation loss: 2.669244482639164

Epoch: 5| Step: 8
Training loss: 0.48898121825621
Validation loss: 2.814479731571427

Epoch: 5| Step: 9
Training loss: 0.5405020358976261
Validation loss: 2.758142471384922

Epoch: 5| Step: 10
Training loss: 0.4200491246661027
Validation loss: 2.677478027686948

Epoch: 5| Step: 11
Training loss: 1.0985999344038722
Validation loss: 2.8214168130136397

Epoch: 320| Step: 0
Training loss: 0.3970718353737648
Validation loss: 2.798609034429957

Epoch: 5| Step: 1
Training loss: 0.5125778790359825
Validation loss: 2.7967630182789986

Epoch: 5| Step: 2
Training loss: 0.4343316612304174
Validation loss: 2.7484592525076073

Epoch: 5| Step: 3
Training loss: 0.606735823334818
Validation loss: 2.6623368328165893

Epoch: 5| Step: 4
Training loss: 0.547879468237733
Validation loss: 2.8152142284708646

Epoch: 5| Step: 5
Training loss: 0.5147828246957304
Validation loss: 2.7749480633557906

Epoch: 5| Step: 6
Training loss: 0.47716406079516877
Validation loss: 2.722509744169594

Epoch: 5| Step: 7
Training loss: 0.4048633752951862
Validation loss: 2.7652328091001883

Epoch: 5| Step: 8
Training loss: 0.46970914622037707
Validation loss: 2.838764137625922

Epoch: 5| Step: 9
Training loss: 0.33620179669273403
Validation loss: 2.7588761631542025

Epoch: 5| Step: 10
Training loss: 0.645766813687704
Validation loss: 2.7793063076249718

Epoch: 5| Step: 11
Training loss: 0.2883503234112353
Validation loss: 2.7636773746287484

Epoch: 321| Step: 0
Training loss: 0.4573012638460801
Validation loss: 2.7959951121335744

Epoch: 5| Step: 1
Training loss: 0.553551868014026
Validation loss: 2.7092139511906326

Epoch: 5| Step: 2
Training loss: 0.5811614892080061
Validation loss: 2.8144389533154457

Epoch: 5| Step: 3
Training loss: 0.48995696345921574
Validation loss: 2.790154970632375

Epoch: 5| Step: 4
Training loss: 0.47657188031079456
Validation loss: 2.7447260240140636

Epoch: 5| Step: 5
Training loss: 0.5303031674194985
Validation loss: 2.797126985987141

Epoch: 5| Step: 6
Training loss: 0.32594819308302514
Validation loss: 2.815669597875148

Epoch: 5| Step: 7
Training loss: 0.43153110685531915
Validation loss: 2.724669603709822

Epoch: 5| Step: 8
Training loss: 0.5763915079764592
Validation loss: 2.804752533281767

Epoch: 5| Step: 9
Training loss: 0.6004715477160817
Validation loss: 2.771357405489242

Epoch: 5| Step: 10
Training loss: 0.5218878053476096
Validation loss: 2.764738314313149

Epoch: 5| Step: 11
Training loss: 0.9202245712373375
Validation loss: 2.8371098304736613

Epoch: 322| Step: 0
Training loss: 0.63231078615981
Validation loss: 2.771581578627931

Epoch: 5| Step: 1
Training loss: 0.5312652305214943
Validation loss: 2.7901761372146887

Epoch: 5| Step: 2
Training loss: 0.32390717391725593
Validation loss: 2.7804113259405447

Epoch: 5| Step: 3
Training loss: 0.37784612949282426
Validation loss: 2.744749070089757

Epoch: 5| Step: 4
Training loss: 0.6628861273734934
Validation loss: 2.8069672453105934

Epoch: 5| Step: 5
Training loss: 0.4655730833002152
Validation loss: 2.7115979155171983

Epoch: 5| Step: 6
Training loss: 0.3080374737900581
Validation loss: 2.7601833400841955

Epoch: 5| Step: 7
Training loss: 0.4869985593582558
Validation loss: 2.7722597227212447

Epoch: 5| Step: 8
Training loss: 0.4728798140508415
Validation loss: 2.7053329035638147

Epoch: 5| Step: 9
Training loss: 0.5814812641093898
Validation loss: 2.7343975429513923

Epoch: 5| Step: 10
Training loss: 0.4368727990669399
Validation loss: 2.7697995678656393

Epoch: 5| Step: 11
Training loss: 0.4531215141425387
Validation loss: 2.7551377485111943

Epoch: 323| Step: 0
Training loss: 0.5758503162052936
Validation loss: 2.762422104279562

Epoch: 5| Step: 1
Training loss: 0.5655662622038934
Validation loss: 2.723423824542245

Epoch: 5| Step: 2
Training loss: 0.373721645899989
Validation loss: 2.729741401191139

Epoch: 5| Step: 3
Training loss: 0.43749293253503485
Validation loss: 2.786161005194167

Epoch: 5| Step: 4
Training loss: 0.5113838497655857
Validation loss: 2.676272686383019

Epoch: 5| Step: 5
Training loss: 0.48914433303497423
Validation loss: 2.747891094290258

Epoch: 5| Step: 6
Training loss: 0.646575575558518
Validation loss: 2.7971418349351023

Epoch: 5| Step: 7
Training loss: 0.6199694840550746
Validation loss: 2.7825434959373125

Epoch: 5| Step: 8
Training loss: 0.5068086238256071
Validation loss: 2.8139533208650507

Epoch: 5| Step: 9
Training loss: 0.5328249865548252
Validation loss: 2.7828461963598987

Epoch: 5| Step: 10
Training loss: 0.631404228065612
Validation loss: 2.749644711691853

Epoch: 5| Step: 11
Training loss: 0.45621812656845223
Validation loss: 2.812431461770685

Epoch: 324| Step: 0
Training loss: 0.49848138143689624
Validation loss: 2.7547721349243077

Epoch: 5| Step: 1
Training loss: 0.5724700198173756
Validation loss: 2.713677054534299

Epoch: 5| Step: 2
Training loss: 0.6671001296715603
Validation loss: 2.657631656864045

Epoch: 5| Step: 3
Training loss: 0.44837376277828395
Validation loss: 2.766733755500902

Epoch: 5| Step: 4
Training loss: 0.41871471327524046
Validation loss: 2.7889871631637835

Epoch: 5| Step: 5
Training loss: 0.6095967989529646
Validation loss: 2.728516779148201

Epoch: 5| Step: 6
Training loss: 0.5633412005178
Validation loss: 2.8045270142468435

Epoch: 5| Step: 7
Training loss: 0.5878523246987825
Validation loss: 2.7764161246834362

Epoch: 5| Step: 8
Training loss: 0.6648919479166548
Validation loss: 2.8151052206192135

Epoch: 5| Step: 9
Training loss: 0.3881952248036399
Validation loss: 2.7799677982855204

Epoch: 5| Step: 10
Training loss: 0.5001587317755827
Validation loss: 2.7116953828362247

Epoch: 5| Step: 11
Training loss: 0.23072994915906314
Validation loss: 2.765343222478874

Epoch: 325| Step: 0
Training loss: 0.494321435710358
Validation loss: 2.8197446623089135

Epoch: 5| Step: 1
Training loss: 0.48028010254742154
Validation loss: 2.7728748485087826

Epoch: 5| Step: 2
Training loss: 0.41409580528619194
Validation loss: 2.8416615422240854

Epoch: 5| Step: 3
Training loss: 0.542263423649758
Validation loss: 2.7755741288693567

Epoch: 5| Step: 4
Training loss: 0.44387446323599733
Validation loss: 2.825240383498523

Epoch: 5| Step: 5
Training loss: 0.6922012543011389
Validation loss: 2.737784412711517

Epoch: 5| Step: 6
Training loss: 0.5694675457023795
Validation loss: 2.8414160019870933

Epoch: 5| Step: 7
Training loss: 0.750057178542964
Validation loss: 2.768770117790667

Epoch: 5| Step: 8
Training loss: 0.5138400422614215
Validation loss: 2.8071489362698228

Epoch: 5| Step: 9
Training loss: 0.4562014031330524
Validation loss: 2.874984734259725

Epoch: 5| Step: 10
Training loss: 0.44736427984852767
Validation loss: 2.807818999625247

Epoch: 5| Step: 11
Training loss: 0.42442083445525625
Validation loss: 2.7682746400205347

Epoch: 326| Step: 0
Training loss: 0.5202452550283975
Validation loss: 2.7370612836594113

Epoch: 5| Step: 1
Training loss: 0.4547397190271907
Validation loss: 2.807146119335742

Epoch: 5| Step: 2
Training loss: 0.5290861660508036
Validation loss: 2.7698554318708326

Epoch: 5| Step: 3
Training loss: 0.3729921870065335
Validation loss: 2.7651789533616404

Epoch: 5| Step: 4
Training loss: 0.4936172065341816
Validation loss: 2.7948917198020555

Epoch: 5| Step: 5
Training loss: 0.7385706258744671
Validation loss: 2.7792975112295952

Epoch: 5| Step: 6
Training loss: 0.4267317809800966
Validation loss: 2.848351898134719

Epoch: 5| Step: 7
Training loss: 0.35732184506003484
Validation loss: 2.7760911415849194

Epoch: 5| Step: 8
Training loss: 0.6398191966654452
Validation loss: 2.792691346377358

Epoch: 5| Step: 9
Training loss: 0.3360048492697624
Validation loss: 2.810899028051837

Epoch: 5| Step: 10
Training loss: 0.3281787079044039
Validation loss: 2.7864451874514975

Epoch: 5| Step: 11
Training loss: 0.47028092883528294
Validation loss: 2.772821098207398

Epoch: 327| Step: 0
Training loss: 0.44183541424099493
Validation loss: 2.8166700108261873

Epoch: 5| Step: 1
Training loss: 0.48813591892372915
Validation loss: 2.8296680350768995

Epoch: 5| Step: 2
Training loss: 0.41367865710872104
Validation loss: 2.7358210019083447

Epoch: 5| Step: 3
Training loss: 0.6774653139772008
Validation loss: 2.725820044980089

Epoch: 5| Step: 4
Training loss: 0.5727593697289772
Validation loss: 2.7958319049060276

Epoch: 5| Step: 5
Training loss: 0.4975973157256024
Validation loss: 2.7342482982526843

Epoch: 5| Step: 6
Training loss: 0.46542107769826147
Validation loss: 2.811964595130679

Epoch: 5| Step: 7
Training loss: 0.4859511971459831
Validation loss: 2.8078920940764225

Epoch: 5| Step: 8
Training loss: 0.6172030966031461
Validation loss: 2.7853288387488604

Epoch: 5| Step: 9
Training loss: 0.5566229834187025
Validation loss: 2.7492241415202376

Epoch: 5| Step: 10
Training loss: 0.585560461170443
Validation loss: 2.7825450418133584

Epoch: 5| Step: 11
Training loss: 0.1042005488803272
Validation loss: 2.710101780252862

Epoch: 328| Step: 0
Training loss: 0.4821438470835337
Validation loss: 2.7704836701255693

Epoch: 5| Step: 1
Training loss: 0.4973436065203825
Validation loss: 2.807427919062049

Epoch: 5| Step: 2
Training loss: 0.619346536276794
Validation loss: 2.7721370854095744

Epoch: 5| Step: 3
Training loss: 0.5662179568152675
Validation loss: 2.78246494788101

Epoch: 5| Step: 4
Training loss: 0.5082405926837195
Validation loss: 2.7297062971271826

Epoch: 5| Step: 5
Training loss: 0.5768929834342175
Validation loss: 2.7860569721306314

Epoch: 5| Step: 6
Training loss: 0.3668291087911833
Validation loss: 2.803338664235396

Epoch: 5| Step: 7
Training loss: 0.4832416164452482
Validation loss: 2.780135585099449

Epoch: 5| Step: 8
Training loss: 0.6115514085452929
Validation loss: 2.760861477311653

Epoch: 5| Step: 9
Training loss: 0.5101374297007637
Validation loss: 2.7594084079919026

Epoch: 5| Step: 10
Training loss: 0.5160214027468278
Validation loss: 2.814491538201047

Epoch: 5| Step: 11
Training loss: 0.2927863125200029
Validation loss: 2.788193924522325

Epoch: 329| Step: 0
Training loss: 0.4836944906535736
Validation loss: 2.856516251511842

Epoch: 5| Step: 1
Training loss: 0.5548449548027689
Validation loss: 2.8242989647862937

Epoch: 5| Step: 2
Training loss: 0.40504281709534656
Validation loss: 2.775986380441073

Epoch: 5| Step: 3
Training loss: 0.5060665339765767
Validation loss: 2.7718734521872275

Epoch: 5| Step: 4
Training loss: 0.7460634315282301
Validation loss: 2.8113945625274392

Epoch: 5| Step: 5
Training loss: 0.6340035661858825
Validation loss: 2.75863566014322

Epoch: 5| Step: 6
Training loss: 0.37812762535381816
Validation loss: 2.772716383695303

Epoch: 5| Step: 7
Training loss: 0.41950776728826555
Validation loss: 2.8012735633761237

Epoch: 5| Step: 8
Training loss: 0.34261886937245406
Validation loss: 2.7497464048614892

Epoch: 5| Step: 9
Training loss: 0.46532924527177877
Validation loss: 2.802313495008634

Epoch: 5| Step: 10
Training loss: 0.4401813830592897
Validation loss: 2.800387544151808

Epoch: 5| Step: 11
Training loss: 0.6976884259945073
Validation loss: 2.7724982197901724

Epoch: 330| Step: 0
Training loss: 0.5610546244803372
Validation loss: 2.776401569208582

Epoch: 5| Step: 1
Training loss: 0.5432391693959628
Validation loss: 2.841680199673852

Epoch: 5| Step: 2
Training loss: 0.5858427352566843
Validation loss: 2.8336247453238053

Epoch: 5| Step: 3
Training loss: 0.5851038024377824
Validation loss: 2.7336907466146805

Epoch: 5| Step: 4
Training loss: 0.45189077727024834
Validation loss: 2.850109437324853

Epoch: 5| Step: 5
Training loss: 0.39939828109342673
Validation loss: 2.726157306778523

Epoch: 5| Step: 6
Training loss: 0.3806188753258543
Validation loss: 2.794705698684246

Epoch: 5| Step: 7
Training loss: 0.47814470823970384
Validation loss: 2.7893006537419796

Epoch: 5| Step: 8
Training loss: 0.33055032440239446
Validation loss: 2.8585057804833687

Epoch: 5| Step: 9
Training loss: 0.4526128011596136
Validation loss: 2.766764458159377

Epoch: 5| Step: 10
Training loss: 0.5859639479708058
Validation loss: 2.8057472649521604

Epoch: 5| Step: 11
Training loss: 0.8797891547922754
Validation loss: 2.715339867797146

Epoch: 331| Step: 0
Training loss: 0.4742852505305743
Validation loss: 2.7745391591921726

Epoch: 5| Step: 1
Training loss: 0.4057495813126675
Validation loss: 2.697072214847888

Epoch: 5| Step: 2
Training loss: 0.2983738806455445
Validation loss: 2.7770821242009074

Epoch: 5| Step: 3
Training loss: 0.489245218507016
Validation loss: 2.7786018501573677

Epoch: 5| Step: 4
Training loss: 0.5868129801860458
Validation loss: 2.789013065217032

Epoch: 5| Step: 5
Training loss: 0.5578302888144157
Validation loss: 2.768729785762159

Epoch: 5| Step: 6
Training loss: 0.7042158354196779
Validation loss: 2.7796560177405976

Epoch: 5| Step: 7
Training loss: 0.6313545008359888
Validation loss: 2.745259664306082

Epoch: 5| Step: 8
Training loss: 0.5413659128903083
Validation loss: 2.7868582940568696

Epoch: 5| Step: 9
Training loss: 0.48201949601395194
Validation loss: 2.778081174546981

Epoch: 5| Step: 10
Training loss: 0.37681486133892844
Validation loss: 2.7899962357298547

Epoch: 5| Step: 11
Training loss: 0.5612591461506905
Validation loss: 2.815077847132185

Epoch: 332| Step: 0
Training loss: 0.6358605668679773
Validation loss: 2.8058461706534206

Epoch: 5| Step: 1
Training loss: 0.6394260165388006
Validation loss: 2.7581468835108494

Epoch: 5| Step: 2
Training loss: 0.36277107593716157
Validation loss: 2.8100397015999024

Epoch: 5| Step: 3
Training loss: 0.44240603691258157
Validation loss: 2.722495553643852

Epoch: 5| Step: 4
Training loss: 0.5549113399553384
Validation loss: 2.889047498098416

Epoch: 5| Step: 5
Training loss: 0.567747698011145
Validation loss: 2.7535568773218437

Epoch: 5| Step: 6
Training loss: 0.47893466896256837
Validation loss: 2.7550419190501017

Epoch: 5| Step: 7
Training loss: 0.5823673071777922
Validation loss: 2.941474751641154

Epoch: 5| Step: 8
Training loss: 0.4071528233058874
Validation loss: 2.7695506516222252

Epoch: 5| Step: 9
Training loss: 0.40319482361293907
Validation loss: 2.812119603040192

Epoch: 5| Step: 10
Training loss: 0.5977073847019791
Validation loss: 2.8652777829963543

Epoch: 5| Step: 11
Training loss: 0.3932589989097555
Validation loss: 2.8033884913381444

Epoch: 333| Step: 0
Training loss: 0.31744724499968063
Validation loss: 2.8199243322438265

Epoch: 5| Step: 1
Training loss: 0.3852608683722155
Validation loss: 2.825632510930084

Epoch: 5| Step: 2
Training loss: 0.5724277201672071
Validation loss: 2.8011907954657116

Epoch: 5| Step: 3
Training loss: 0.42582268469548396
Validation loss: 2.80856669859046

Epoch: 5| Step: 4
Training loss: 0.42481068574024944
Validation loss: 2.769511062699148

Epoch: 5| Step: 5
Training loss: 0.4874877585805926
Validation loss: 2.7620190641938565

Epoch: 5| Step: 6
Training loss: 0.41992673649302537
Validation loss: 2.7926693629147623

Epoch: 5| Step: 7
Training loss: 0.44375308868515295
Validation loss: 2.848892306458266

Epoch: 5| Step: 8
Training loss: 0.5248991358459388
Validation loss: 2.8245758351482833

Epoch: 5| Step: 9
Training loss: 0.48303278184790865
Validation loss: 2.8009676975420024

Epoch: 5| Step: 10
Training loss: 0.5501059321778662
Validation loss: 2.834742743662741

Epoch: 5| Step: 11
Training loss: 0.27246845740875625
Validation loss: 2.773824358541244

Epoch: 334| Step: 0
Training loss: 0.4794419334165862
Validation loss: 2.7840455218150075

Epoch: 5| Step: 1
Training loss: 0.3670084902485503
Validation loss: 2.831789487845475

Epoch: 5| Step: 2
Training loss: 0.477279545763158
Validation loss: 2.856109397677391

Epoch: 5| Step: 3
Training loss: 0.4360772055997194
Validation loss: 2.754146394111559

Epoch: 5| Step: 4
Training loss: 0.5581436210934864
Validation loss: 2.7599823028174453

Epoch: 5| Step: 5
Training loss: 0.4522930597816542
Validation loss: 2.7734828963168696

Epoch: 5| Step: 6
Training loss: 0.42002494789006506
Validation loss: 2.827239324660356

Epoch: 5| Step: 7
Training loss: 0.452060534375523
Validation loss: 2.8070939383057074

Epoch: 5| Step: 8
Training loss: 0.6890786426409296
Validation loss: 2.805691290605005

Epoch: 5| Step: 9
Training loss: 0.5347359113330917
Validation loss: 2.845862306267707

Epoch: 5| Step: 10
Training loss: 0.4005092166097307
Validation loss: 2.847985027574578

Epoch: 5| Step: 11
Training loss: 0.4186507214104781
Validation loss: 2.800546569781636

Epoch: 335| Step: 0
Training loss: 0.5208151019402297
Validation loss: 2.766960468165629

Epoch: 5| Step: 1
Training loss: 0.4603383647854125
Validation loss: 2.8022573386316387

Epoch: 5| Step: 2
Training loss: 0.5188522490878443
Validation loss: 2.832559677459412

Epoch: 5| Step: 3
Training loss: 0.5424280287206604
Validation loss: 2.756987166347297

Epoch: 5| Step: 4
Training loss: 0.46796762023687516
Validation loss: 2.7500946216488167

Epoch: 5| Step: 5
Training loss: 0.4094739415817048
Validation loss: 2.757407507188217

Epoch: 5| Step: 6
Training loss: 0.5409623267847036
Validation loss: 2.8153179021690273

Epoch: 5| Step: 7
Training loss: 0.3354103032489815
Validation loss: 2.787368669680584

Epoch: 5| Step: 8
Training loss: 0.47099078557240226
Validation loss: 2.765920299993308

Epoch: 5| Step: 9
Training loss: 0.4369664344554376
Validation loss: 2.7803128517393336

Epoch: 5| Step: 10
Training loss: 0.6187564367865015
Validation loss: 2.7761978704272177

Epoch: 5| Step: 11
Training loss: 0.17592596878491357
Validation loss: 2.823049754469477

Epoch: 336| Step: 0
Training loss: 0.5514049110385532
Validation loss: 2.800919302814898

Epoch: 5| Step: 1
Training loss: 0.5041481442897897
Validation loss: 2.791554289781218

Epoch: 5| Step: 2
Training loss: 0.6148522052886345
Validation loss: 2.7984719290462268

Epoch: 5| Step: 3
Training loss: 0.5276083670847801
Validation loss: 2.8489012017992783

Epoch: 5| Step: 4
Training loss: 0.40305158700719285
Validation loss: 2.798061531181531

Epoch: 5| Step: 5
Training loss: 0.5421094612883464
Validation loss: 2.744029865314836

Epoch: 5| Step: 6
Training loss: 0.5229613857474517
Validation loss: 2.7914982977430394

Epoch: 5| Step: 7
Training loss: 0.3840884722439464
Validation loss: 2.721611614309019

Epoch: 5| Step: 8
Training loss: 0.47514520232764945
Validation loss: 2.699483947680979

Epoch: 5| Step: 9
Training loss: 0.54324967506248
Validation loss: 2.7847026475190377

Epoch: 5| Step: 10
Training loss: 0.2983941436151025
Validation loss: 2.8332898046618618

Epoch: 5| Step: 11
Training loss: 0.4674117057468113
Validation loss: 2.829694712738669

Epoch: 337| Step: 0
Training loss: 0.46618781797554454
Validation loss: 2.8278075333320256

Epoch: 5| Step: 1
Training loss: 0.6072664215267194
Validation loss: 2.7600660653258333

Epoch: 5| Step: 2
Training loss: 0.5850103800007599
Validation loss: 2.8535084777645046

Epoch: 5| Step: 3
Training loss: 0.6070974286899142
Validation loss: 2.7702236520598467

Epoch: 5| Step: 4
Training loss: 0.6586501417532432
Validation loss: 2.783584879074929

Epoch: 5| Step: 5
Training loss: 0.5610487017477891
Validation loss: 2.7102281886567487

Epoch: 5| Step: 6
Training loss: 0.3894065163289023
Validation loss: 2.7838632079721957

Epoch: 5| Step: 7
Training loss: 0.4957638642454369
Validation loss: 2.79893585373985

Epoch: 5| Step: 8
Training loss: 0.36323331701243
Validation loss: 2.780384486251486

Epoch: 5| Step: 9
Training loss: 0.5641654578420892
Validation loss: 2.8474232003112276

Epoch: 5| Step: 10
Training loss: 0.6710429917347792
Validation loss: 2.7814806867504194

Epoch: 5| Step: 11
Training loss: 0.9005386661126611
Validation loss: 2.858942666227088

Epoch: 338| Step: 0
Training loss: 0.5892051119403284
Validation loss: 2.7733394480104465

Epoch: 5| Step: 1
Training loss: 0.516460724004783
Validation loss: 2.8067449392366712

Epoch: 5| Step: 2
Training loss: 0.7847031381887758
Validation loss: 2.82315608389982

Epoch: 5| Step: 3
Training loss: 0.7705630825318062
Validation loss: 2.8744081081411568

Epoch: 5| Step: 4
Training loss: 0.5002067257771788
Validation loss: 2.826956790452392

Epoch: 5| Step: 5
Training loss: 0.4142699171974898
Validation loss: 2.773025836749243

Epoch: 5| Step: 6
Training loss: 0.7868636815088036
Validation loss: 2.744903085656163

Epoch: 5| Step: 7
Training loss: 0.49058170856530553
Validation loss: 2.7643209928463053

Epoch: 5| Step: 8
Training loss: 0.7592068065984355
Validation loss: 2.7785051745797364

Epoch: 5| Step: 9
Training loss: 0.3775832882951788
Validation loss: 2.795427779096334

Epoch: 5| Step: 10
Training loss: 0.5581843336291251
Validation loss: 2.8402452215698397

Epoch: 5| Step: 11
Training loss: 0.35143789626358163
Validation loss: 2.767372287013452

Epoch: 339| Step: 0
Training loss: 0.7215967608182486
Validation loss: 2.739719751295185

Epoch: 5| Step: 1
Training loss: 0.40905623292019955
Validation loss: 2.8085094433945423

Epoch: 5| Step: 2
Training loss: 0.5106330594532195
Validation loss: 2.760451728070315

Epoch: 5| Step: 3
Training loss: 0.4546312421884632
Validation loss: 2.754651164137805

Epoch: 5| Step: 4
Training loss: 0.46696810594448057
Validation loss: 2.805587891446359

Epoch: 5| Step: 5
Training loss: 0.38931583368328854
Validation loss: 2.7963056286692822

Epoch: 5| Step: 6
Training loss: 0.4219101432008666
Validation loss: 2.7236745162548543

Epoch: 5| Step: 7
Training loss: 0.575363549076478
Validation loss: 2.795061926772719

Epoch: 5| Step: 8
Training loss: 0.6848724830234464
Validation loss: 2.7607280819450106

Epoch: 5| Step: 9
Training loss: 0.3654046707112667
Validation loss: 2.8060948729030035

Epoch: 5| Step: 10
Training loss: 0.5233662115488458
Validation loss: 2.6750193826917954

Epoch: 5| Step: 11
Training loss: 0.5518368284648022
Validation loss: 2.773331692965264

Epoch: 340| Step: 0
Training loss: 0.28883461088245427
Validation loss: 2.7750473615539692

Epoch: 5| Step: 1
Training loss: 0.47573513377521875
Validation loss: 2.8012424764910895

Epoch: 5| Step: 2
Training loss: 0.5443950553904932
Validation loss: 2.7844564799136786

Epoch: 5| Step: 3
Training loss: 0.6638074946242178
Validation loss: 2.789027754338356

Epoch: 5| Step: 4
Training loss: 0.5122082531153503
Validation loss: 2.781413659270423

Epoch: 5| Step: 5
Training loss: 0.4470407512019105
Validation loss: 2.7660735425706773

Epoch: 5| Step: 6
Training loss: 0.33534763358319064
Validation loss: 2.752868128414516

Epoch: 5| Step: 7
Training loss: 0.6384066576423522
Validation loss: 2.713723981349812

Epoch: 5| Step: 8
Training loss: 0.4217439377263669
Validation loss: 2.8008090788852185

Epoch: 5| Step: 9
Training loss: 0.6563003157445615
Validation loss: 2.792579175548967

Epoch: 5| Step: 10
Training loss: 0.47245099994352957
Validation loss: 2.7903472975805013

Epoch: 5| Step: 11
Training loss: 0.31990930721204247
Validation loss: 2.7267802059552033

Epoch: 341| Step: 0
Training loss: 0.5148590930742184
Validation loss: 2.748204056637469

Epoch: 5| Step: 1
Training loss: 0.43915583409274966
Validation loss: 2.7661747287300944

Epoch: 5| Step: 2
Training loss: 0.3965077134953914
Validation loss: 2.788622425170095

Epoch: 5| Step: 3
Training loss: 0.5092699118023459
Validation loss: 2.731484063839335

Epoch: 5| Step: 4
Training loss: 0.44591712060352867
Validation loss: 2.799501638396212

Epoch: 5| Step: 5
Training loss: 0.5217271446884773
Validation loss: 2.845370700666188

Epoch: 5| Step: 6
Training loss: 0.5252335324182069
Validation loss: 2.7939014042472246

Epoch: 5| Step: 7
Training loss: 0.5766132280730458
Validation loss: 2.756943959466447

Epoch: 5| Step: 8
Training loss: 0.6942286670087243
Validation loss: 2.79374972008484

Epoch: 5| Step: 9
Training loss: 0.38411091517189416
Validation loss: 2.7848420289117106

Epoch: 5| Step: 10
Training loss: 0.43472587287183845
Validation loss: 2.734134391007798

Epoch: 5| Step: 11
Training loss: 1.0268647560356283
Validation loss: 2.734306628871079

Epoch: 342| Step: 0
Training loss: 0.4124949852320706
Validation loss: 2.7968285235303045

Epoch: 5| Step: 1
Training loss: 0.7007553861304213
Validation loss: 2.767415428000833

Epoch: 5| Step: 2
Training loss: 0.41491314941494256
Validation loss: 2.731589473429278

Epoch: 5| Step: 3
Training loss: 0.5270404367242804
Validation loss: 2.7523944357396237

Epoch: 5| Step: 4
Training loss: 0.5787921870367994
Validation loss: 2.832490870569639

Epoch: 5| Step: 5
Training loss: 0.6900810429759583
Validation loss: 2.8495656411691335

Epoch: 5| Step: 6
Training loss: 0.832927954939019
Validation loss: 2.7679105050719306

Epoch: 5| Step: 7
Training loss: 0.5130848013665987
Validation loss: 2.849322486957505

Epoch: 5| Step: 8
Training loss: 0.40197288679621673
Validation loss: 2.7731438494753777

Epoch: 5| Step: 9
Training loss: 0.40107673846712577
Validation loss: 2.7501946076979493

Epoch: 5| Step: 10
Training loss: 0.3883485647449319
Validation loss: 2.7636597542109427

Epoch: 5| Step: 11
Training loss: 0.3763128188910699
Validation loss: 2.7902722019289428

Epoch: 343| Step: 0
Training loss: 0.44774498717432215
Validation loss: 2.769503221607647

Epoch: 5| Step: 1
Training loss: 0.6752748962764371
Validation loss: 2.6841268144183723

Epoch: 5| Step: 2
Training loss: 0.4154872852565089
Validation loss: 2.770017357954319

Epoch: 5| Step: 3
Training loss: 0.635926180464644
Validation loss: 2.745703056691103

Epoch: 5| Step: 4
Training loss: 0.38137905172335657
Validation loss: 2.74303437692914

Epoch: 5| Step: 5
Training loss: 0.43598059369457026
Validation loss: 2.811352269557199

Epoch: 5| Step: 6
Training loss: 0.5257315965080709
Validation loss: 2.8149087939836708

Epoch: 5| Step: 7
Training loss: 0.4800829074705213
Validation loss: 2.8573893547163127

Epoch: 5| Step: 8
Training loss: 0.5623584145268569
Validation loss: 2.802467937853235

Epoch: 5| Step: 9
Training loss: 0.3792865457120295
Validation loss: 2.7902798600476793

Epoch: 5| Step: 10
Training loss: 0.6136875871750921
Validation loss: 2.761285034683872

Epoch: 5| Step: 11
Training loss: 0.16476528325052212
Validation loss: 2.8135154621683967

Epoch: 344| Step: 0
Training loss: 0.45785526427429185
Validation loss: 2.820218145424756

Epoch: 5| Step: 1
Training loss: 0.6382736691196315
Validation loss: 2.7255857698410204

Epoch: 5| Step: 2
Training loss: 0.4373157317524776
Validation loss: 2.7690327979990594

Epoch: 5| Step: 3
Training loss: 0.3860456986824908
Validation loss: 2.7871563129353256

Epoch: 5| Step: 4
Training loss: 0.4393682270694685
Validation loss: 2.7405857795278097

Epoch: 5| Step: 5
Training loss: 0.4851709716823847
Validation loss: 2.822859321283918

Epoch: 5| Step: 6
Training loss: 0.31790559408588365
Validation loss: 2.784848339293416

Epoch: 5| Step: 7
Training loss: 0.42430386892393834
Validation loss: 2.816965228449006

Epoch: 5| Step: 8
Training loss: 0.3878480624754541
Validation loss: 2.7760267322894827

Epoch: 5| Step: 9
Training loss: 0.3853928541439537
Validation loss: 2.754508848522435

Epoch: 5| Step: 10
Training loss: 0.5331738921595356
Validation loss: 2.7916707150349276

Epoch: 5| Step: 11
Training loss: 1.0228442736852734
Validation loss: 2.7822429263293253

Epoch: 345| Step: 0
Training loss: 0.47302707596034976
Validation loss: 2.778021510213035

Epoch: 5| Step: 1
Training loss: 0.5279500513527808
Validation loss: 2.7681002630232516

Epoch: 5| Step: 2
Training loss: 0.3544572755210311
Validation loss: 2.760738326471321

Epoch: 5| Step: 3
Training loss: 0.4486476751247934
Validation loss: 2.825972027359414

Epoch: 5| Step: 4
Training loss: 0.3696018546723611
Validation loss: 2.7919889710016306

Epoch: 5| Step: 5
Training loss: 0.44696824628151743
Validation loss: 2.7769478195124724

Epoch: 5| Step: 6
Training loss: 0.4516724620895379
Validation loss: 2.7523741985437513

Epoch: 5| Step: 7
Training loss: 0.4205870217555297
Validation loss: 2.8186562448544703

Epoch: 5| Step: 8
Training loss: 0.6155918838578811
Validation loss: 2.773979101892342

Epoch: 5| Step: 9
Training loss: 0.5408762397654928
Validation loss: 2.7680098242479705

Epoch: 5| Step: 10
Training loss: 0.5506972120305552
Validation loss: 2.7983020040402873

Epoch: 5| Step: 11
Training loss: 0.26166854205998313
Validation loss: 2.792725953972926

Epoch: 346| Step: 0
Training loss: 0.47187472589750096
Validation loss: 2.7563528533336927

Epoch: 5| Step: 1
Training loss: 0.5922190856562264
Validation loss: 2.7567745269014567

Epoch: 5| Step: 2
Training loss: 0.4330753629901706
Validation loss: 2.7232537856725147

Epoch: 5| Step: 3
Training loss: 0.3530126333799239
Validation loss: 2.7868702212698575

Epoch: 5| Step: 4
Training loss: 0.41293552266451916
Validation loss: 2.8664516991219386

Epoch: 5| Step: 5
Training loss: 0.5142551779905903
Validation loss: 2.7617362101433236

Epoch: 5| Step: 6
Training loss: 0.514085088540837
Validation loss: 2.7929225642158

Epoch: 5| Step: 7
Training loss: 0.49991217974468743
Validation loss: 2.7677143523744587

Epoch: 5| Step: 8
Training loss: 0.4879898727784952
Validation loss: 2.763454210316478

Epoch: 5| Step: 9
Training loss: 0.6272955223918566
Validation loss: 2.7997830189067194

Epoch: 5| Step: 10
Training loss: 0.3080342931497461
Validation loss: 2.8166317331435096

Epoch: 5| Step: 11
Training loss: 0.6985537600776426
Validation loss: 2.741473877620646

Epoch: 347| Step: 0
Training loss: 0.49801161398137267
Validation loss: 2.7389050733143128

Epoch: 5| Step: 1
Training loss: 0.6015077541260572
Validation loss: 2.753328705596922

Epoch: 5| Step: 2
Training loss: 0.35824689857647146
Validation loss: 2.713639732878111

Epoch: 5| Step: 3
Training loss: 0.5190125938276713
Validation loss: 2.8170630526441514

Epoch: 5| Step: 4
Training loss: 0.47853882402509357
Validation loss: 2.7859954069163155

Epoch: 5| Step: 5
Training loss: 0.41473021740725274
Validation loss: 2.828485662600777

Epoch: 5| Step: 6
Training loss: 0.5179697534427733
Validation loss: 2.8098729474134734

Epoch: 5| Step: 7
Training loss: 0.5466860035882036
Validation loss: 2.7937326733694063

Epoch: 5| Step: 8
Training loss: 0.5609087689620669
Validation loss: 2.7791828195559067

Epoch: 5| Step: 9
Training loss: 0.3267420735875359
Validation loss: 2.7737767616483464

Epoch: 5| Step: 10
Training loss: 0.5125121452474154
Validation loss: 2.813566341289595

Epoch: 5| Step: 11
Training loss: 0.2667306720145214
Validation loss: 2.795168752227749

Epoch: 348| Step: 0
Training loss: 0.4436516323667479
Validation loss: 2.7737474904071218

Epoch: 5| Step: 1
Training loss: 0.3064016638086254
Validation loss: 2.7669015441912648

Epoch: 5| Step: 2
Training loss: 0.4761234512303912
Validation loss: 2.787686511643918

Epoch: 5| Step: 3
Training loss: 0.5353191434110618
Validation loss: 2.844439513764934

Epoch: 5| Step: 4
Training loss: 0.5620138663773719
Validation loss: 2.8469824113622977

Epoch: 5| Step: 5
Training loss: 0.3805932313286119
Validation loss: 2.798527135501499

Epoch: 5| Step: 6
Training loss: 0.4106998837208682
Validation loss: 2.8225579239110954

Epoch: 5| Step: 7
Training loss: 0.44569514381959024
Validation loss: 2.7786524140060473

Epoch: 5| Step: 8
Training loss: 0.498134680095126
Validation loss: 2.8430800155219407

Epoch: 5| Step: 9
Training loss: 0.7297724704974722
Validation loss: 2.829706715673553

Epoch: 5| Step: 10
Training loss: 0.3411449209108842
Validation loss: 2.830730653474073

Epoch: 5| Step: 11
Training loss: 0.5609062717426476
Validation loss: 2.775555395702267

Epoch: 349| Step: 0
Training loss: 0.5052460594117953
Validation loss: 2.729647955547076

Epoch: 5| Step: 1
Training loss: 0.6233207316025771
Validation loss: 2.8136589594070625

Epoch: 5| Step: 2
Training loss: 0.46683905821899796
Validation loss: 2.733507033145812

Epoch: 5| Step: 3
Training loss: 0.6239120073480358
Validation loss: 2.8047960981137416

Epoch: 5| Step: 4
Training loss: 0.47412360806490883
Validation loss: 2.833550998213433

Epoch: 5| Step: 5
Training loss: 0.3494596746876902
Validation loss: 2.7663676671006834

Epoch: 5| Step: 6
Training loss: 0.48968879767698154
Validation loss: 2.7548863896496925

Epoch: 5| Step: 7
Training loss: 0.3980747516368016
Validation loss: 2.814758693635677

Epoch: 5| Step: 8
Training loss: 0.46499395748539835
Validation loss: 2.8217342206409497

Epoch: 5| Step: 9
Training loss: 0.4024355885400594
Validation loss: 2.7950867418330745

Epoch: 5| Step: 10
Training loss: 0.3198208408322928
Validation loss: 2.7687432944200085

Epoch: 5| Step: 11
Training loss: 0.17906753732676012
Validation loss: 2.75137623393485

Epoch: 350| Step: 0
Training loss: 0.35620997772940877
Validation loss: 2.7868230967177294

Epoch: 5| Step: 1
Training loss: 0.47508645902104046
Validation loss: 2.710100526622625

Epoch: 5| Step: 2
Training loss: 0.5443650548926531
Validation loss: 2.6834899053050267

Epoch: 5| Step: 3
Training loss: 0.6111889763075138
Validation loss: 2.8390935565465427

Epoch: 5| Step: 4
Training loss: 0.3875734344241649
Validation loss: 2.7745000030802642

Epoch: 5| Step: 5
Training loss: 0.5336674495530844
Validation loss: 2.716608654808956

Epoch: 5| Step: 6
Training loss: 0.32513177382713937
Validation loss: 2.8023316522682236

Epoch: 5| Step: 7
Training loss: 0.49579348450769406
Validation loss: 2.806245748181085

Epoch: 5| Step: 8
Training loss: 0.5719880612451234
Validation loss: 2.8345786237773343

Epoch: 5| Step: 9
Training loss: 0.42444363739852065
Validation loss: 2.842642585960449

Epoch: 5| Step: 10
Training loss: 0.34931865517583127
Validation loss: 2.7337104498443234

Epoch: 5| Step: 11
Training loss: 0.8103699640449732
Validation loss: 2.85428406248884

Epoch: 351| Step: 0
Training loss: 0.3913593256494166
Validation loss: 2.819170811460558

Epoch: 5| Step: 1
Training loss: 0.4999347137505154
Validation loss: 2.72284410686953

Epoch: 5| Step: 2
Training loss: 0.3885851816077101
Validation loss: 2.8016480541480897

Epoch: 5| Step: 3
Training loss: 0.4632958517620032
Validation loss: 2.8170930657239586

Epoch: 5| Step: 4
Training loss: 0.27466615114368126
Validation loss: 2.7708327334028087

Epoch: 5| Step: 5
Training loss: 0.4716718842865959
Validation loss: 2.7541732875053784

Epoch: 5| Step: 6
Training loss: 0.508165970073776
Validation loss: 2.7525302127562425

Epoch: 5| Step: 7
Training loss: 0.47973791224094375
Validation loss: 2.7959376847699957

Epoch: 5| Step: 8
Training loss: 0.39268769210818016
Validation loss: 2.804169088922808

Epoch: 5| Step: 9
Training loss: 0.5117284759296086
Validation loss: 2.767933124826558

Epoch: 5| Step: 10
Training loss: 0.5228647828167438
Validation loss: 2.7732809568829078

Epoch: 5| Step: 11
Training loss: 0.5961445158093407
Validation loss: 2.8261168465115456

Epoch: 352| Step: 0
Training loss: 0.5943001156233795
Validation loss: 2.7440835424167487

Epoch: 5| Step: 1
Training loss: 0.40744711485939106
Validation loss: 2.7675063097674246

Epoch: 5| Step: 2
Training loss: 0.3954611291531657
Validation loss: 2.785966310407399

Epoch: 5| Step: 3
Training loss: 0.5876725511589865
Validation loss: 2.723699919707211

Epoch: 5| Step: 4
Training loss: 0.4654823052570072
Validation loss: 2.769271314696382

Epoch: 5| Step: 5
Training loss: 0.5395526592515393
Validation loss: 2.747095770819052

Epoch: 5| Step: 6
Training loss: 0.3622941172412533
Validation loss: 2.6937635974585104

Epoch: 5| Step: 7
Training loss: 0.4941318948449486
Validation loss: 2.85171550880206

Epoch: 5| Step: 8
Training loss: 0.33109681528138796
Validation loss: 2.785352263969802

Epoch: 5| Step: 9
Training loss: 0.39321172646085273
Validation loss: 2.7500927721616426

Epoch: 5| Step: 10
Training loss: 0.4523762567728783
Validation loss: 2.7417693367221085

Epoch: 5| Step: 11
Training loss: 0.29459025199288746
Validation loss: 2.7711844305489786

Epoch: 353| Step: 0
Training loss: 0.42998456223077375
Validation loss: 2.786431072969278

Epoch: 5| Step: 1
Training loss: 0.35083896569958306
Validation loss: 2.7741431542963637

Epoch: 5| Step: 2
Training loss: 0.28589993005960523
Validation loss: 2.8151332890183136

Epoch: 5| Step: 3
Training loss: 0.49797796632863867
Validation loss: 2.7805080567172142

Epoch: 5| Step: 4
Training loss: 0.4749196298266613
Validation loss: 2.728242154571794

Epoch: 5| Step: 5
Training loss: 0.5152168970852715
Validation loss: 2.7769560044715913

Epoch: 5| Step: 6
Training loss: 0.4864233758633717
Validation loss: 2.827702987826232

Epoch: 5| Step: 7
Training loss: 0.33561291649801916
Validation loss: 2.843372452654249

Epoch: 5| Step: 8
Training loss: 0.3901945794541923
Validation loss: 2.7537424422079724

Epoch: 5| Step: 9
Training loss: 0.40051299295411447
Validation loss: 2.8091755292302456

Epoch: 5| Step: 10
Training loss: 0.6196677193536105
Validation loss: 2.70269279111675

Epoch: 5| Step: 11
Training loss: 0.5017205675556118
Validation loss: 2.804369788916354

Epoch: 354| Step: 0
Training loss: 0.4739257850230366
Validation loss: 2.79916108327795

Epoch: 5| Step: 1
Training loss: 0.4883215010265183
Validation loss: 2.8645504388943492

Epoch: 5| Step: 2
Training loss: 0.3366008131592834
Validation loss: 2.7752832136458463

Epoch: 5| Step: 3
Training loss: 0.5006917995601124
Validation loss: 2.8122722992735394

Epoch: 5| Step: 4
Training loss: 0.261538457688433
Validation loss: 2.7934329520782857

Epoch: 5| Step: 5
Training loss: 0.5487221992332562
Validation loss: 2.782588504498752

Epoch: 5| Step: 6
Training loss: 0.40126812308670845
Validation loss: 2.742872650685327

Epoch: 5| Step: 7
Training loss: 0.6390675243749115
Validation loss: 2.7967647836233698

Epoch: 5| Step: 8
Training loss: 0.34500715814987387
Validation loss: 2.7436972770172896

Epoch: 5| Step: 9
Training loss: 0.7353894146704939
Validation loss: 2.769640261751437

Epoch: 5| Step: 10
Training loss: 0.4699428956363452
Validation loss: 2.862982713125068

Epoch: 5| Step: 11
Training loss: 0.5014128393380384
Validation loss: 2.7830696011465195

Epoch: 355| Step: 0
Training loss: 0.5108049401559671
Validation loss: 2.8071656042515722

Epoch: 5| Step: 1
Training loss: 0.5133619642736643
Validation loss: 2.7716160698808774

Epoch: 5| Step: 2
Training loss: 0.4337781222018866
Validation loss: 2.759346233806959

Epoch: 5| Step: 3
Training loss: 0.5935551675064642
Validation loss: 2.7882699632901646

Epoch: 5| Step: 4
Training loss: 0.4759694458527682
Validation loss: 2.813213272071483

Epoch: 5| Step: 5
Training loss: 0.2821797394767901
Validation loss: 2.747130775622521

Epoch: 5| Step: 6
Training loss: 0.25740618911210783
Validation loss: 2.830644710980601

Epoch: 5| Step: 7
Training loss: 0.358713162554545
Validation loss: 2.7811239728341484

Epoch: 5| Step: 8
Training loss: 0.4174997961020971
Validation loss: 2.757954677558636

Epoch: 5| Step: 9
Training loss: 0.47639015082972846
Validation loss: 2.7585279313003763

Epoch: 5| Step: 10
Training loss: 0.564908381941796
Validation loss: 2.7402699206061767

Epoch: 5| Step: 11
Training loss: 0.2079452277221805
Validation loss: 2.8060946038485923

Epoch: 356| Step: 0
Training loss: 0.4648881137738919
Validation loss: 2.8379773281825864

Epoch: 5| Step: 1
Training loss: 0.3542716441060612
Validation loss: 2.8094861023814817

Epoch: 5| Step: 2
Training loss: 0.3012781744757359
Validation loss: 2.768282843446482

Epoch: 5| Step: 3
Training loss: 0.5312518512469181
Validation loss: 2.828339029436402

Epoch: 5| Step: 4
Training loss: 0.7080215347538745
Validation loss: 2.8297013162900164

Epoch: 5| Step: 5
Training loss: 0.602691705247781
Validation loss: 2.8280410297496066

Epoch: 5| Step: 6
Training loss: 0.3592476204399776
Validation loss: 2.777779639296438

Epoch: 5| Step: 7
Training loss: 0.4034946240465233
Validation loss: 2.7720194491164665

Epoch: 5| Step: 8
Training loss: 0.5313177065619439
Validation loss: 2.8178722430283965

Epoch: 5| Step: 9
Training loss: 0.5546691784049134
Validation loss: 2.791928020503587

Epoch: 5| Step: 10
Training loss: 0.41144781662582675
Validation loss: 2.8064360697795823

Epoch: 5| Step: 11
Training loss: 0.2649792085669494
Validation loss: 2.8383053789164054

Epoch: 357| Step: 0
Training loss: 0.3086878717516406
Validation loss: 2.7604231396485255

Epoch: 5| Step: 1
Training loss: 0.34462197205725287
Validation loss: 2.7600698841042526

Epoch: 5| Step: 2
Training loss: 0.5426949009419776
Validation loss: 2.7297608672663247

Epoch: 5| Step: 3
Training loss: 0.6476755146249117
Validation loss: 2.775777154073602

Epoch: 5| Step: 4
Training loss: 0.35317757814289524
Validation loss: 2.8026871840062935

Epoch: 5| Step: 5
Training loss: 0.5190579545880208
Validation loss: 2.7943273872181926

Epoch: 5| Step: 6
Training loss: 0.4791696244300555
Validation loss: 2.75171964515442

Epoch: 5| Step: 7
Training loss: 0.3126165172794226
Validation loss: 2.7837637317743025

Epoch: 5| Step: 8
Training loss: 0.4698573384478217
Validation loss: 2.813212159733325

Epoch: 5| Step: 9
Training loss: 0.5071185725977545
Validation loss: 2.783891159587377

Epoch: 5| Step: 10
Training loss: 0.36367452520107546
Validation loss: 2.7028362068450638

Epoch: 5| Step: 11
Training loss: 0.8390492074151488
Validation loss: 2.808003504615528

Epoch: 358| Step: 0
Training loss: 0.5678464534855344
Validation loss: 2.7962044954640275

Epoch: 5| Step: 1
Training loss: 0.4445491405031251
Validation loss: 2.8111175494995653

Epoch: 5| Step: 2
Training loss: 0.43803315374016893
Validation loss: 2.814214720590137

Epoch: 5| Step: 3
Training loss: 0.37149736640427955
Validation loss: 2.745549465917396

Epoch: 5| Step: 4
Training loss: 0.3387801638507419
Validation loss: 2.894635368942168

Epoch: 5| Step: 5
Training loss: 0.3172866206019393
Validation loss: 2.8274006381341454

Epoch: 5| Step: 6
Training loss: 0.4599702190264528
Validation loss: 2.813917749308579

Epoch: 5| Step: 7
Training loss: 0.29782598416923045
Validation loss: 2.779525983298174

Epoch: 5| Step: 8
Training loss: 0.5256770321179428
Validation loss: 2.7889305639182216

Epoch: 5| Step: 9
Training loss: 0.38109581284005767
Validation loss: 2.7532826540518545

Epoch: 5| Step: 10
Training loss: 0.5648235966423004
Validation loss: 2.7699770907087022

Epoch: 5| Step: 11
Training loss: 0.5729768779210389
Validation loss: 2.752678708041902

Epoch: 359| Step: 0
Training loss: 0.45909833102166975
Validation loss: 2.7421099913566427

Epoch: 5| Step: 1
Training loss: 0.3813289193252765
Validation loss: 2.7895050819642644

Epoch: 5| Step: 2
Training loss: 0.4396165332038529
Validation loss: 2.7849818313720536

Epoch: 5| Step: 3
Training loss: 0.4121997969082254
Validation loss: 2.831946027503871

Epoch: 5| Step: 4
Training loss: 0.5136652898910278
Validation loss: 2.777866366218864

Epoch: 5| Step: 5
Training loss: 0.42628975347244275
Validation loss: 2.753686500240847

Epoch: 5| Step: 6
Training loss: 0.363361431830389
Validation loss: 2.8246231774423873

Epoch: 5| Step: 7
Training loss: 0.3232556827182844
Validation loss: 2.8101767445816384

Epoch: 5| Step: 8
Training loss: 0.5035337505525888
Validation loss: 2.7636783918791408

Epoch: 5| Step: 9
Training loss: 0.5105051982420695
Validation loss: 2.8208267151732875

Epoch: 5| Step: 10
Training loss: 0.6631008590345208
Validation loss: 2.8372420260923787

Epoch: 5| Step: 11
Training loss: 0.43455640792032907
Validation loss: 2.824956960125181

Epoch: 360| Step: 0
Training loss: 0.48441306856747246
Validation loss: 2.740309127183172

Epoch: 5| Step: 1
Training loss: 0.3390320698315651
Validation loss: 2.7888820885473615

Epoch: 5| Step: 2
Training loss: 0.3979213962307145
Validation loss: 2.808324628518383

Epoch: 5| Step: 3
Training loss: 0.44326024900916766
Validation loss: 2.7659241430135135

Epoch: 5| Step: 4
Training loss: 0.5373203764787762
Validation loss: 2.8086020478827676

Epoch: 5| Step: 5
Training loss: 0.48705978202281736
Validation loss: 2.8256340789367806

Epoch: 5| Step: 6
Training loss: 0.6221518231082611
Validation loss: 2.7698507694070726

Epoch: 5| Step: 7
Training loss: 0.5762345102177052
Validation loss: 2.8364391566279843

Epoch: 5| Step: 8
Training loss: 0.3879081852713352
Validation loss: 2.7636968568856726

Epoch: 5| Step: 9
Training loss: 0.48092352271140903
Validation loss: 2.799191962598466

Epoch: 5| Step: 10
Training loss: 0.4739244015742558
Validation loss: 2.8335736934771365

Epoch: 5| Step: 11
Training loss: 0.3098477825877692
Validation loss: 2.8086564150324422

Epoch: 361| Step: 0
Training loss: 0.5771055254014494
Validation loss: 2.8063356839574283

Epoch: 5| Step: 1
Training loss: 0.5066402697065603
Validation loss: 2.826020632837922

Epoch: 5| Step: 2
Training loss: 0.3249224070393086
Validation loss: 2.6812288246415306

Epoch: 5| Step: 3
Training loss: 0.5012860448344114
Validation loss: 2.7366390410139028

Epoch: 5| Step: 4
Training loss: 0.47594929939115865
Validation loss: 2.7392717838214384

Epoch: 5| Step: 5
Training loss: 0.517680032162501
Validation loss: 2.675275623970598

Epoch: 5| Step: 6
Training loss: 0.40762000894049844
Validation loss: 2.811928885365343

Epoch: 5| Step: 7
Training loss: 0.40071942854610165
Validation loss: 2.779137023060414

Epoch: 5| Step: 8
Training loss: 0.5230654347825469
Validation loss: 2.7710291116906762

Epoch: 5| Step: 9
Training loss: 0.44973208081191357
Validation loss: 2.7570392976410822

Epoch: 5| Step: 10
Training loss: 0.5253574119762418
Validation loss: 2.693387812186998

Epoch: 5| Step: 11
Training loss: 0.5714686967181452
Validation loss: 2.732681934632161

Epoch: 362| Step: 0
Training loss: 0.3810481068459877
Validation loss: 2.8413553915296084

Epoch: 5| Step: 1
Training loss: 0.37387737479901656
Validation loss: 2.7338682667901635

Epoch: 5| Step: 2
Training loss: 0.3842053667105707
Validation loss: 2.7824397060685704

Epoch: 5| Step: 3
Training loss: 0.3933828087411372
Validation loss: 2.8085710032058793

Epoch: 5| Step: 4
Training loss: 0.6402899633623951
Validation loss: 2.77455916311179

Epoch: 5| Step: 5
Training loss: 0.5247945133610056
Validation loss: 2.7647121632753904

Epoch: 5| Step: 6
Training loss: 0.4954524212627435
Validation loss: 2.7921737072843595

Epoch: 5| Step: 7
Training loss: 0.3890481976863843
Validation loss: 2.757211257622954

Epoch: 5| Step: 8
Training loss: 0.5532108046364017
Validation loss: 2.74632906097757

Epoch: 5| Step: 9
Training loss: 0.3313548884683227
Validation loss: 2.77592681422924

Epoch: 5| Step: 10
Training loss: 0.512916212177256
Validation loss: 2.7797210934349312

Epoch: 5| Step: 11
Training loss: 0.3430067936298168
Validation loss: 2.761518004377203

Epoch: 363| Step: 0
Training loss: 0.5237386605758225
Validation loss: 2.8172474106328123

Epoch: 5| Step: 1
Training loss: 0.4117242903219017
Validation loss: 2.850077969895534

Epoch: 5| Step: 2
Training loss: 0.43357216721164543
Validation loss: 2.767159120890559

Epoch: 5| Step: 3
Training loss: 0.48723997859915014
Validation loss: 2.767295674026744

Epoch: 5| Step: 4
Training loss: 0.36645064583168574
Validation loss: 2.7705332347343092

Epoch: 5| Step: 5
Training loss: 0.28098186320864527
Validation loss: 2.832494356722708

Epoch: 5| Step: 6
Training loss: 0.49982239131720874
Validation loss: 2.797733494795564

Epoch: 5| Step: 7
Training loss: 0.5787350297149297
Validation loss: 2.7070248206036114

Epoch: 5| Step: 8
Training loss: 0.4064782125199084
Validation loss: 2.7472497633059336

Epoch: 5| Step: 9
Training loss: 0.5170942527863994
Validation loss: 2.7859655009781132

Epoch: 5| Step: 10
Training loss: 0.4089567902014922
Validation loss: 2.7598031615817966

Epoch: 5| Step: 11
Training loss: 0.443695411548184
Validation loss: 2.7860971210741665

Epoch: 364| Step: 0
Training loss: 0.5324737534748282
Validation loss: 2.763988743601787

Epoch: 5| Step: 1
Training loss: 0.4206853977956176
Validation loss: 2.789862157482651

Epoch: 5| Step: 2
Training loss: 0.47127134603628157
Validation loss: 2.7893498733030424

Epoch: 5| Step: 3
Training loss: 0.34028120496001457
Validation loss: 2.7740236907567093

Epoch: 5| Step: 4
Training loss: 0.4425500886122494
Validation loss: 2.856087224093648

Epoch: 5| Step: 5
Training loss: 0.2785537811294508
Validation loss: 2.717787824476832

Epoch: 5| Step: 6
Training loss: 0.4985689007942509
Validation loss: 2.768485491929045

Epoch: 5| Step: 7
Training loss: 0.509402646443697
Validation loss: 2.796934993817929

Epoch: 5| Step: 8
Training loss: 0.39145659619741585
Validation loss: 2.7330168957153695

Epoch: 5| Step: 9
Training loss: 0.44214807476153856
Validation loss: 2.7699869567401043

Epoch: 5| Step: 10
Training loss: 0.36949685483066236
Validation loss: 2.7563617121403126

Epoch: 5| Step: 11
Training loss: 0.33244704970391636
Validation loss: 2.7961556061756743

Epoch: 365| Step: 0
Training loss: 0.5610277459275216
Validation loss: 2.7487818628187317

Epoch: 5| Step: 1
Training loss: 0.37089288194140585
Validation loss: 2.813172270643169

Epoch: 5| Step: 2
Training loss: 0.3600731371060066
Validation loss: 2.7572621524923564

Epoch: 5| Step: 3
Training loss: 0.27193234211653444
Validation loss: 2.823595761801931

Epoch: 5| Step: 4
Training loss: 0.397273907720442
Validation loss: 2.8132476872436594

Epoch: 5| Step: 5
Training loss: 0.5269411316136695
Validation loss: 2.798176847836269

Epoch: 5| Step: 6
Training loss: 0.30850848698032124
Validation loss: 2.771808030969153

Epoch: 5| Step: 7
Training loss: 0.4778961063835838
Validation loss: 2.7104902787197545

Epoch: 5| Step: 8
Training loss: 0.43466074141984024
Validation loss: 2.7798747295004023

Epoch: 5| Step: 9
Training loss: 0.4098453433274519
Validation loss: 2.8100185503013626

Epoch: 5| Step: 10
Training loss: 0.4445512522402537
Validation loss: 2.8267010674673787

Epoch: 5| Step: 11
Training loss: 0.7879806126736586
Validation loss: 2.789553783327661

Epoch: 366| Step: 0
Training loss: 0.4690396526599885
Validation loss: 2.75226250329257

Epoch: 5| Step: 1
Training loss: 0.3760537204589329
Validation loss: 2.7700508573605362

Epoch: 5| Step: 2
Training loss: 0.5685143800139704
Validation loss: 2.8140980913310947

Epoch: 5| Step: 3
Training loss: 0.5650482736068154
Validation loss: 2.8183317476091787

Epoch: 5| Step: 4
Training loss: 0.6542461546412086
Validation loss: 2.720772137374805

Epoch: 5| Step: 5
Training loss: 0.5925294980621311
Validation loss: 2.764828687635621

Epoch: 5| Step: 6
Training loss: 0.4330916891733677
Validation loss: 2.83472952498856

Epoch: 5| Step: 7
Training loss: 0.4987777134837049
Validation loss: 2.8146864727915277

Epoch: 5| Step: 8
Training loss: 0.533710168786156
Validation loss: 2.79785880575524

Epoch: 5| Step: 9
Training loss: 0.5423002999676482
Validation loss: 2.8448658629810026

Epoch: 5| Step: 10
Training loss: 0.5270559867982085
Validation loss: 2.8139062791862077

Epoch: 5| Step: 11
Training loss: 0.37904526431531127
Validation loss: 2.792982717625831

Epoch: 367| Step: 0
Training loss: 0.4469194863591016
Validation loss: 2.806365234767385

Epoch: 5| Step: 1
Training loss: 0.4405371287499511
Validation loss: 2.822898176116257

Epoch: 5| Step: 2
Training loss: 0.4450096639912537
Validation loss: 2.8738737872081903

Epoch: 5| Step: 3
Training loss: 0.658744544055502
Validation loss: 2.816576042118754

Epoch: 5| Step: 4
Training loss: 0.36161382566395817
Validation loss: 2.8550643564966447

Epoch: 5| Step: 5
Training loss: 0.44396504443481577
Validation loss: 2.824657077287151

Epoch: 5| Step: 6
Training loss: 0.3684203573741125
Validation loss: 2.8215215527111672

Epoch: 5| Step: 7
Training loss: 0.35361618382132576
Validation loss: 2.705774093318582

Epoch: 5| Step: 8
Training loss: 0.45098598994086286
Validation loss: 2.8132207406162966

Epoch: 5| Step: 9
Training loss: 0.6473096207542433
Validation loss: 2.7441258657472587

Epoch: 5| Step: 10
Training loss: 0.5329913882209344
Validation loss: 2.750433992328309

Epoch: 5| Step: 11
Training loss: 0.4352296606358708
Validation loss: 2.859573187152557

Epoch: 368| Step: 0
Training loss: 0.3591664787381972
Validation loss: 2.778374020773029

Epoch: 5| Step: 1
Training loss: 0.6098425856316975
Validation loss: 2.774126148245011

Epoch: 5| Step: 2
Training loss: 0.5302111341431194
Validation loss: 2.7708903835035548

Epoch: 5| Step: 3
Training loss: 0.36384903211854125
Validation loss: 2.7201481399387477

Epoch: 5| Step: 4
Training loss: 0.4564678109875501
Validation loss: 2.709039340553705

Epoch: 5| Step: 5
Training loss: 0.3188299317274848
Validation loss: 2.745822695960905

Epoch: 5| Step: 6
Training loss: 0.44928503791341007
Validation loss: 2.7870422405096007

Epoch: 5| Step: 7
Training loss: 0.5099575222314484
Validation loss: 2.8123890183769125

Epoch: 5| Step: 8
Training loss: 0.4184385315623826
Validation loss: 2.7906503618546696

Epoch: 5| Step: 9
Training loss: 0.3453155435453898
Validation loss: 2.8143505648673908

Epoch: 5| Step: 10
Training loss: 0.543114512246806
Validation loss: 2.7801109617544415

Epoch: 5| Step: 11
Training loss: 0.36556624568090484
Validation loss: 2.7938444494259054

Epoch: 369| Step: 0
Training loss: 0.3781137929784622
Validation loss: 2.775559275489707

Epoch: 5| Step: 1
Training loss: 0.4072249158647577
Validation loss: 2.853358256347789

Epoch: 5| Step: 2
Training loss: 0.5605518726298883
Validation loss: 2.8266089118393176

Epoch: 5| Step: 3
Training loss: 0.423821286616554
Validation loss: 2.8658633279649663

Epoch: 5| Step: 4
Training loss: 0.34526652983803136
Validation loss: 2.7742830894784927

Epoch: 5| Step: 5
Training loss: 0.46108238723285977
Validation loss: 2.760895112998066

Epoch: 5| Step: 6
Training loss: 0.4190706363488343
Validation loss: 2.847090139400908

Epoch: 5| Step: 7
Training loss: 0.42354586646866615
Validation loss: 2.8785984490704153

Epoch: 5| Step: 8
Training loss: 0.3790395050118581
Validation loss: 2.8156261271913046

Epoch: 5| Step: 9
Training loss: 0.35637835566139364
Validation loss: 2.753613803206566

Epoch: 5| Step: 10
Training loss: 0.5580695300074385
Validation loss: 2.787760287193831

Epoch: 5| Step: 11
Training loss: 0.4517092456431319
Validation loss: 2.766866893637235

Epoch: 370| Step: 0
Training loss: 0.4655535271853176
Validation loss: 2.838807922381539

Epoch: 5| Step: 1
Training loss: 0.41858107732404987
Validation loss: 2.8159528412304176

Epoch: 5| Step: 2
Training loss: 0.397593501897985
Validation loss: 2.784474154247084

Epoch: 5| Step: 3
Training loss: 0.5317004201701916
Validation loss: 2.8317007323575933

Epoch: 5| Step: 4
Training loss: 0.4465846912697711
Validation loss: 2.8086162171860125

Epoch: 5| Step: 5
Training loss: 0.3285723996629344
Validation loss: 2.832852110013322

Epoch: 5| Step: 6
Training loss: 0.3434981051764776
Validation loss: 2.837430772763132

Epoch: 5| Step: 7
Training loss: 0.46790501410473256
Validation loss: 2.7953205210878234

Epoch: 5| Step: 8
Training loss: 0.5547826174997058
Validation loss: 2.862058564954201

Epoch: 5| Step: 9
Training loss: 0.4595720141144656
Validation loss: 2.866245049052143

Epoch: 5| Step: 10
Training loss: 0.4473260730391345
Validation loss: 2.856259870894701

Epoch: 5| Step: 11
Training loss: 0.40932565784842995
Validation loss: 2.8205491527624287

Epoch: 371| Step: 0
Training loss: 0.29109384138481603
Validation loss: 2.8381845908764873

Epoch: 5| Step: 1
Training loss: 0.38172712019410804
Validation loss: 2.791832635462874

Epoch: 5| Step: 2
Training loss: 0.5648929242141195
Validation loss: 2.77466431826986

Epoch: 5| Step: 3
Training loss: 0.48005120036620064
Validation loss: 2.780687936145048

Epoch: 5| Step: 4
Training loss: 0.3279783170812204
Validation loss: 2.859687534477204

Epoch: 5| Step: 5
Training loss: 0.4790380001086508
Validation loss: 2.7843617986615157

Epoch: 5| Step: 6
Training loss: 0.43529249897047145
Validation loss: 2.834230473193725

Epoch: 5| Step: 7
Training loss: 0.5340954088191214
Validation loss: 2.8243695540240945

Epoch: 5| Step: 8
Training loss: 0.44861113878308434
Validation loss: 2.8445111468271

Epoch: 5| Step: 9
Training loss: 0.39961094189408447
Validation loss: 2.786388181831287

Epoch: 5| Step: 10
Training loss: 0.3458884545236723
Validation loss: 2.7662387353696754

Epoch: 5| Step: 11
Training loss: 0.10186379929852701
Validation loss: 2.821016303081928

Epoch: 372| Step: 0
Training loss: 0.41253925339013775
Validation loss: 2.7827611168457214

Epoch: 5| Step: 1
Training loss: 0.3431778394249126
Validation loss: 2.7907674584331748

Epoch: 5| Step: 2
Training loss: 0.38466460939999864
Validation loss: 2.832827411857138

Epoch: 5| Step: 3
Training loss: 0.3951922064034434
Validation loss: 2.8298136304734895

Epoch: 5| Step: 4
Training loss: 0.3758002325961706
Validation loss: 2.8191020125499153

Epoch: 5| Step: 5
Training loss: 0.4930869013787397
Validation loss: 2.8258973370339135

Epoch: 5| Step: 6
Training loss: 0.40007425229999644
Validation loss: 2.9031626528846446

Epoch: 5| Step: 7
Training loss: 0.4778892465683491
Validation loss: 2.845991079492723

Epoch: 5| Step: 8
Training loss: 0.5044121679156567
Validation loss: 2.7972690120044907

Epoch: 5| Step: 9
Training loss: 0.497521486105916
Validation loss: 2.7893005931963986

Epoch: 5| Step: 10
Training loss: 0.4467394369751926
Validation loss: 2.8770381917503567

Epoch: 5| Step: 11
Training loss: 0.5351880753235742
Validation loss: 2.7659593548865042

Epoch: 373| Step: 0
Training loss: 0.3749166038287307
Validation loss: 2.7654812482698037

Epoch: 5| Step: 1
Training loss: 0.4606880385794601
Validation loss: 2.8136251636098173

Epoch: 5| Step: 2
Training loss: 0.49423979717716354
Validation loss: 2.779111808214455

Epoch: 5| Step: 3
Training loss: 0.42225135687366694
Validation loss: 2.8146322644712534

Epoch: 5| Step: 4
Training loss: 0.612388763252823
Validation loss: 2.8426176513563024

Epoch: 5| Step: 5
Training loss: 0.41725997009616594
Validation loss: 2.763932207514615

Epoch: 5| Step: 6
Training loss: 0.4434814957131216
Validation loss: 2.7956894043507607

Epoch: 5| Step: 7
Training loss: 0.40396131881638914
Validation loss: 2.7961121944996203

Epoch: 5| Step: 8
Training loss: 0.6000454587404893
Validation loss: 2.820132277094076

Epoch: 5| Step: 9
Training loss: 0.3211239793567467
Validation loss: 2.864162328589355

Epoch: 5| Step: 10
Training loss: 0.49752672746643173
Validation loss: 2.828171727899165

Epoch: 5| Step: 11
Training loss: 0.6161123399399288
Validation loss: 2.8452652677483843

Epoch: 374| Step: 0
Training loss: 0.46128518520847733
Validation loss: 2.8235283760120713

Epoch: 5| Step: 1
Training loss: 0.3822252089330754
Validation loss: 2.785632670112876

Epoch: 5| Step: 2
Training loss: 0.5270210691724616
Validation loss: 2.791690041078859

Epoch: 5| Step: 3
Training loss: 0.3810329530775337
Validation loss: 2.8349253772376124

Epoch: 5| Step: 4
Training loss: 0.5996204586433618
Validation loss: 2.7925002516550324

Epoch: 5| Step: 5
Training loss: 0.5647750253405583
Validation loss: 2.7461477231852887

Epoch: 5| Step: 6
Training loss: 0.5849944090779812
Validation loss: 2.8088322495314477

Epoch: 5| Step: 7
Training loss: 0.4607999725780959
Validation loss: 2.8594180835194924

Epoch: 5| Step: 8
Training loss: 0.4846691038574602
Validation loss: 2.7774431986112407

Epoch: 5| Step: 9
Training loss: 0.34435254087788814
Validation loss: 2.7967632491591106

Epoch: 5| Step: 10
Training loss: 0.49202919488055497
Validation loss: 2.7852336557126347

Epoch: 5| Step: 11
Training loss: 0.5772322385722768
Validation loss: 2.789530660480031

Epoch: 375| Step: 0
Training loss: 0.42542409353595106
Validation loss: 2.761896008131565

Epoch: 5| Step: 1
Training loss: 0.530728841849525
Validation loss: 2.8119018589751317

Epoch: 5| Step: 2
Training loss: 0.5681680573617721
Validation loss: 2.7968236929167354

Epoch: 5| Step: 3
Training loss: 0.4332834284576667
Validation loss: 2.7759715471602844

Epoch: 5| Step: 4
Training loss: 0.30810688338884457
Validation loss: 2.7900800513902997

Epoch: 5| Step: 5
Training loss: 0.5342352522660724
Validation loss: 2.8343024536516452

Epoch: 5| Step: 6
Training loss: 0.4556750365308053
Validation loss: 2.789220686130038

Epoch: 5| Step: 7
Training loss: 0.48231655005850127
Validation loss: 2.8110899039445685

Epoch: 5| Step: 8
Training loss: 0.4342417299848046
Validation loss: 2.7976538001842224

Epoch: 5| Step: 9
Training loss: 0.3378261989847188
Validation loss: 2.730695101151822

Epoch: 5| Step: 10
Training loss: 0.33018305763998007
Validation loss: 2.76887284860979

Epoch: 5| Step: 11
Training loss: 0.5138925578728141
Validation loss: 2.787001723785926

Epoch: 376| Step: 0
Training loss: 0.38496173179230986
Validation loss: 2.795419282190344

Epoch: 5| Step: 1
Training loss: 0.5298604182212013
Validation loss: 2.807457100989711

Epoch: 5| Step: 2
Training loss: 0.30405161599951647
Validation loss: 2.748877494917619

Epoch: 5| Step: 3
Training loss: 0.5214895755351349
Validation loss: 2.7145361124548955

Epoch: 5| Step: 4
Training loss: 0.5251288914271827
Validation loss: 2.829917775050317

Epoch: 5| Step: 5
Training loss: 0.3919799574696091
Validation loss: 2.7760515779434014

Epoch: 5| Step: 6
Training loss: 0.45573865244847955
Validation loss: 2.833366931454284

Epoch: 5| Step: 7
Training loss: 0.4375179491448303
Validation loss: 2.801606209749587

Epoch: 5| Step: 8
Training loss: 0.38517313643573103
Validation loss: 2.798864889247284

Epoch: 5| Step: 9
Training loss: 0.4266997413494112
Validation loss: 2.7487228961040246

Epoch: 5| Step: 10
Training loss: 0.5444766450975247
Validation loss: 2.78570142905735

Epoch: 5| Step: 11
Training loss: 0.2938544047256762
Validation loss: 2.77945823317199

Epoch: 377| Step: 0
Training loss: 0.2525512633359854
Validation loss: 2.7878033585546937

Epoch: 5| Step: 1
Training loss: 0.516734605470367
Validation loss: 2.805931640640408

Epoch: 5| Step: 2
Training loss: 0.35265122423152856
Validation loss: 2.84452179855932

Epoch: 5| Step: 3
Training loss: 0.3330587980107956
Validation loss: 2.7843958354759795

Epoch: 5| Step: 4
Training loss: 0.44675579748677374
Validation loss: 2.7762263232444857

Epoch: 5| Step: 5
Training loss: 0.29237147164631583
Validation loss: 2.790357077347128

Epoch: 5| Step: 6
Training loss: 0.37430498168931203
Validation loss: 2.8426351807378456

Epoch: 5| Step: 7
Training loss: 0.494040105795949
Validation loss: 2.8147982814341135

Epoch: 5| Step: 8
Training loss: 0.5940337506942535
Validation loss: 2.872173294941485

Epoch: 5| Step: 9
Training loss: 0.55735687219023
Validation loss: 2.864202367707892

Epoch: 5| Step: 10
Training loss: 0.5325618422779167
Validation loss: 2.7775482410060817

Epoch: 5| Step: 11
Training loss: 0.49039170981435004
Validation loss: 2.814300589450688

Epoch: 378| Step: 0
Training loss: 0.4879828952982946
Validation loss: 2.741609507016094

Epoch: 5| Step: 1
Training loss: 0.5756088350658451
Validation loss: 2.777275664062349

Epoch: 5| Step: 2
Training loss: 0.43205445073831406
Validation loss: 2.8152057912847006

Epoch: 5| Step: 3
Training loss: 0.43086091125159065
Validation loss: 2.8416167701375254

Epoch: 5| Step: 4
Training loss: 0.46643890637141405
Validation loss: 2.799886190707047

Epoch: 5| Step: 5
Training loss: 0.27959231776276444
Validation loss: 2.8107710292307373

Epoch: 5| Step: 6
Training loss: 0.5196783674932134
Validation loss: 2.7845572941763344

Epoch: 5| Step: 7
Training loss: 0.34794959004842996
Validation loss: 2.762860980549679

Epoch: 5| Step: 8
Training loss: 0.4351529619513888
Validation loss: 2.7870687879651515

Epoch: 5| Step: 9
Training loss: 0.4639139091653462
Validation loss: 2.822441315599782

Epoch: 5| Step: 10
Training loss: 0.4092071087009066
Validation loss: 2.827219960521907

Epoch: 5| Step: 11
Training loss: 0.5579517115990853
Validation loss: 2.81376422442955

Epoch: 379| Step: 0
Training loss: 0.5827857893481087
Validation loss: 2.783400800500204

Epoch: 5| Step: 1
Training loss: 0.36436880021358053
Validation loss: 2.81035941927899

Epoch: 5| Step: 2
Training loss: 0.5080858228625713
Validation loss: 2.8026607437297675

Epoch: 5| Step: 3
Training loss: 0.4133889099539988
Validation loss: 2.800595655547909

Epoch: 5| Step: 4
Training loss: 0.41464282700008237
Validation loss: 2.857673913770144

Epoch: 5| Step: 5
Training loss: 0.3963424917332083
Validation loss: 2.7103920167001947

Epoch: 5| Step: 6
Training loss: 0.4849614162189212
Validation loss: 2.7698914903831904

Epoch: 5| Step: 7
Training loss: 0.43883492962826626
Validation loss: 2.7886148408720706

Epoch: 5| Step: 8
Training loss: 0.3289293127061199
Validation loss: 2.7839923154681028

Epoch: 5| Step: 9
Training loss: 0.5208873402887046
Validation loss: 2.7537390764146488

Epoch: 5| Step: 10
Training loss: 0.39265830136972735
Validation loss: 2.719980662887221

Epoch: 5| Step: 11
Training loss: 0.28058104963159713
Validation loss: 2.767819369185797

Epoch: 380| Step: 0
Training loss: 0.4078179691576439
Validation loss: 2.7844070917942414

Epoch: 5| Step: 1
Training loss: 0.4669322372240022
Validation loss: 2.7724092001016145

Epoch: 5| Step: 2
Training loss: 0.3351762485539793
Validation loss: 2.803127301150327

Epoch: 5| Step: 3
Training loss: 0.42593088932742773
Validation loss: 2.8160576677405174

Epoch: 5| Step: 4
Training loss: 0.44304418913824745
Validation loss: 2.7903359406188346

Epoch: 5| Step: 5
Training loss: 0.5143635375644969
Validation loss: 2.7336758909688097

Epoch: 5| Step: 6
Training loss: 0.4971760935167276
Validation loss: 2.804104127134563

Epoch: 5| Step: 7
Training loss: 0.6067625680996314
Validation loss: 2.806317495965936

Epoch: 5| Step: 8
Training loss: 0.46142581354373235
Validation loss: 2.811158170974199

Epoch: 5| Step: 9
Training loss: 0.40002575508291016
Validation loss: 2.815171721168678

Epoch: 5| Step: 10
Training loss: 0.5024181542238751
Validation loss: 2.7476942481858253

Epoch: 5| Step: 11
Training loss: 0.4682617823945799
Validation loss: 2.851589059923754

Epoch: 381| Step: 0
Training loss: 0.40616485730518115
Validation loss: 2.773484379188603

Epoch: 5| Step: 1
Training loss: 0.6151279417950944
Validation loss: 2.795658799042537

Epoch: 5| Step: 2
Training loss: 0.2453573425880245
Validation loss: 2.760227270046748

Epoch: 5| Step: 3
Training loss: 0.4793373992377858
Validation loss: 2.793454111603699

Epoch: 5| Step: 4
Training loss: 0.5214503702228039
Validation loss: 2.672268022479371

Epoch: 5| Step: 5
Training loss: 0.40583778522185465
Validation loss: 2.793723374793886

Epoch: 5| Step: 6
Training loss: 0.31682430717710375
Validation loss: 2.784579484383138

Epoch: 5| Step: 7
Training loss: 0.4733965726982988
Validation loss: 2.7543321104369745

Epoch: 5| Step: 8
Training loss: 0.41700422997696296
Validation loss: 2.7822835516278683

Epoch: 5| Step: 9
Training loss: 0.4101411362542768
Validation loss: 2.8024049926452346

Epoch: 5| Step: 10
Training loss: 0.2935441660565942
Validation loss: 2.8390428094875633

Epoch: 5| Step: 11
Training loss: 0.34113590090126894
Validation loss: 2.7390053336370226

Epoch: 382| Step: 0
Training loss: 0.44750726827121295
Validation loss: 2.794295906648845

Epoch: 5| Step: 1
Training loss: 0.5310427598080235
Validation loss: 2.7459459730806044

Epoch: 5| Step: 2
Training loss: 0.3237643101928165
Validation loss: 2.820346504492513

Epoch: 5| Step: 3
Training loss: 0.45199175235198874
Validation loss: 2.7495632438910413

Epoch: 5| Step: 4
Training loss: 0.5206818710075998
Validation loss: 2.769558940940919

Epoch: 5| Step: 5
Training loss: 0.4763492044367933
Validation loss: 2.764555481830541

Epoch: 5| Step: 6
Training loss: 0.35069555837414446
Validation loss: 2.8234038736057623

Epoch: 5| Step: 7
Training loss: 0.28559129006857964
Validation loss: 2.7934088798115426

Epoch: 5| Step: 8
Training loss: 0.4121039331447484
Validation loss: 2.819729618836153

Epoch: 5| Step: 9
Training loss: 0.3656161959313589
Validation loss: 2.73967333864567

Epoch: 5| Step: 10
Training loss: 0.3361233596314862
Validation loss: 2.799081067308356

Epoch: 5| Step: 11
Training loss: 0.7273992007186396
Validation loss: 2.799319483024893

Epoch: 383| Step: 0
Training loss: 0.5151945108836538
Validation loss: 2.8054600026337693

Epoch: 5| Step: 1
Training loss: 0.34822235735596335
Validation loss: 2.704580745577266

Epoch: 5| Step: 2
Training loss: 0.2575604767519734
Validation loss: 2.7834478545089993

Epoch: 5| Step: 3
Training loss: 0.4965977549056249
Validation loss: 2.7863717942154027

Epoch: 5| Step: 4
Training loss: 0.34303241303969495
Validation loss: 2.7753528732892825

Epoch: 5| Step: 5
Training loss: 0.44906490842933916
Validation loss: 2.7442792104025

Epoch: 5| Step: 6
Training loss: 0.4994761583902609
Validation loss: 2.8339892018630017

Epoch: 5| Step: 7
Training loss: 0.37280701120817494
Validation loss: 2.767895048881004

Epoch: 5| Step: 8
Training loss: 0.3473232796420399
Validation loss: 2.7580913622444667

Epoch: 5| Step: 9
Training loss: 0.5079597259724352
Validation loss: 2.835434174512802

Epoch: 5| Step: 10
Training loss: 0.27544425550364526
Validation loss: 2.818160154228154

Epoch: 5| Step: 11
Training loss: 0.7764772732977289
Validation loss: 2.8500282166294433

Epoch: 384| Step: 0
Training loss: 0.4815662843331499
Validation loss: 2.799448072867004

Epoch: 5| Step: 1
Training loss: 0.4581863608387107
Validation loss: 2.7388453462603013

Epoch: 5| Step: 2
Training loss: 0.3500139676440484
Validation loss: 2.7175980535444273

Epoch: 5| Step: 3
Training loss: 0.4946248994836327
Validation loss: 2.736644947081586

Epoch: 5| Step: 4
Training loss: 0.48158873304026584
Validation loss: 2.7592621182213075

Epoch: 5| Step: 5
Training loss: 0.450098254815248
Validation loss: 2.7642630152681558

Epoch: 5| Step: 6
Training loss: 0.5989375373436678
Validation loss: 2.822489851653757

Epoch: 5| Step: 7
Training loss: 0.33699640567006023
Validation loss: 2.796389514550242

Epoch: 5| Step: 8
Training loss: 0.4995571499894437
Validation loss: 2.89151908862538

Epoch: 5| Step: 9
Training loss: 0.38765589516072635
Validation loss: 2.7967825684289447

Epoch: 5| Step: 10
Training loss: 0.41408715084760306
Validation loss: 2.7818473931563044

Epoch: 5| Step: 11
Training loss: 0.4034742380282627
Validation loss: 2.8159231493779697

Epoch: 385| Step: 0
Training loss: 0.4368196033179134
Validation loss: 2.7879238814218446

Epoch: 5| Step: 1
Training loss: 0.5088329332880938
Validation loss: 2.783734990213505

Epoch: 5| Step: 2
Training loss: 0.2858757843578939
Validation loss: 2.8366379726615727

Epoch: 5| Step: 3
Training loss: 0.45638361306945274
Validation loss: 2.8728384378435865

Epoch: 5| Step: 4
Training loss: 0.40887532716001546
Validation loss: 2.847588223035947

Epoch: 5| Step: 5
Training loss: 0.4841576365396433
Validation loss: 2.7739877038638245

Epoch: 5| Step: 6
Training loss: 0.43046605062590326
Validation loss: 2.8291925975938947

Epoch: 5| Step: 7
Training loss: 0.380998752229004
Validation loss: 2.815204242170817

Epoch: 5| Step: 8
Training loss: 0.4658741470034328
Validation loss: 2.864322575347369

Epoch: 5| Step: 9
Training loss: 0.4246691608188532
Validation loss: 2.799384658755933

Epoch: 5| Step: 10
Training loss: 0.5055766254384773
Validation loss: 2.788233312307132

Epoch: 5| Step: 11
Training loss: 0.3082225232613237
Validation loss: 2.8668707067117754

Epoch: 386| Step: 0
Training loss: 0.3537829952892758
Validation loss: 2.846098129516214

Epoch: 5| Step: 1
Training loss: 0.25519149912891875
Validation loss: 2.7864314829640864

Epoch: 5| Step: 2
Training loss: 0.43669686509984185
Validation loss: 2.7527847675900254

Epoch: 5| Step: 3
Training loss: 0.40318022504945095
Validation loss: 2.806682606708072

Epoch: 5| Step: 4
Training loss: 0.4080607699899318
Validation loss: 2.818548776418036

Epoch: 5| Step: 5
Training loss: 0.48639254162541984
Validation loss: 2.857226716454283

Epoch: 5| Step: 6
Training loss: 0.3539485703989778
Validation loss: 2.7604396723142473

Epoch: 5| Step: 7
Training loss: 0.4054417088482586
Validation loss: 2.8035871034825566

Epoch: 5| Step: 8
Training loss: 0.5273429870599949
Validation loss: 2.770732197792086

Epoch: 5| Step: 9
Training loss: 0.31148950995926483
Validation loss: 2.7622473578195152

Epoch: 5| Step: 10
Training loss: 0.43888081901645276
Validation loss: 2.834307598923456

Epoch: 5| Step: 11
Training loss: 0.3335527229541609
Validation loss: 2.790216504592986

Epoch: 387| Step: 0
Training loss: 0.4656648196404721
Validation loss: 2.8461808270824807

Epoch: 5| Step: 1
Training loss: 0.4952043686053944
Validation loss: 2.8019086837700975

Epoch: 5| Step: 2
Training loss: 0.4382921948485799
Validation loss: 2.8488988655109138

Epoch: 5| Step: 3
Training loss: 0.3543444659350926
Validation loss: 2.7559716201586593

Epoch: 5| Step: 4
Training loss: 0.33909661828936327
Validation loss: 2.8377081682640974

Epoch: 5| Step: 5
Training loss: 0.5846886614120749
Validation loss: 2.787280770021601

Epoch: 5| Step: 6
Training loss: 0.4226501901583513
Validation loss: 2.764645821603687

Epoch: 5| Step: 7
Training loss: 0.3642375009718517
Validation loss: 2.869235977863171

Epoch: 5| Step: 8
Training loss: 0.3819874806674398
Validation loss: 2.8683542412153424

Epoch: 5| Step: 9
Training loss: 0.3806215766539819
Validation loss: 2.8201160802803127

Epoch: 5| Step: 10
Training loss: 0.324551572370004
Validation loss: 2.793438876761557

Epoch: 5| Step: 11
Training loss: 0.44543234567669504
Validation loss: 2.7948973250538254

Epoch: 388| Step: 0
Training loss: 0.3539560430331766
Validation loss: 2.775687047746877

Epoch: 5| Step: 1
Training loss: 0.44228663462170464
Validation loss: 2.7797472783866244

Epoch: 5| Step: 2
Training loss: 0.348501805927463
Validation loss: 2.754423128144267

Epoch: 5| Step: 3
Training loss: 0.6043109529676449
Validation loss: 2.7480239234585833

Epoch: 5| Step: 4
Training loss: 0.48663611407048685
Validation loss: 2.7452380898873887

Epoch: 5| Step: 5
Training loss: 0.4478635830436804
Validation loss: 2.835057012454546

Epoch: 5| Step: 6
Training loss: 0.5216089735588081
Validation loss: 2.783025160782782

Epoch: 5| Step: 7
Training loss: 0.498606214400391
Validation loss: 2.738668837894977

Epoch: 5| Step: 8
Training loss: 0.4025373270958923
Validation loss: 2.75244465813595

Epoch: 5| Step: 9
Training loss: 0.509459948330975
Validation loss: 2.7494041924510495

Epoch: 5| Step: 10
Training loss: 0.3852923897401291
Validation loss: 2.741869122751275

Epoch: 5| Step: 11
Training loss: 0.438093140976995
Validation loss: 2.875238871671471

Epoch: 389| Step: 0
Training loss: 0.5266904952698664
Validation loss: 2.857801841909238

Epoch: 5| Step: 1
Training loss: 0.4230943647870855
Validation loss: 2.770056265427103

Epoch: 5| Step: 2
Training loss: 0.5776651202948084
Validation loss: 2.771788763420051

Epoch: 5| Step: 3
Training loss: 0.5579752131771178
Validation loss: 2.7796343850687584

Epoch: 5| Step: 4
Training loss: 0.5298375257634389
Validation loss: 2.771601084177757

Epoch: 5| Step: 5
Training loss: 0.4054736642411097
Validation loss: 2.794311456779035

Epoch: 5| Step: 6
Training loss: 0.41879429796403256
Validation loss: 2.8302432078568196

Epoch: 5| Step: 7
Training loss: 0.42668285628178215
Validation loss: 2.810201355472551

Epoch: 5| Step: 8
Training loss: 0.4254454767402085
Validation loss: 2.8056094532427736

Epoch: 5| Step: 9
Training loss: 0.4470408678670182
Validation loss: 2.794712918101377

Epoch: 5| Step: 10
Training loss: 0.4392014185289325
Validation loss: 2.811552679385278

Epoch: 5| Step: 11
Training loss: 0.19050745232090271
Validation loss: 2.815508635498264

Epoch: 390| Step: 0
Training loss: 0.34815993950387486
Validation loss: 2.8285058328906576

Epoch: 5| Step: 1
Training loss: 0.4710051173248017
Validation loss: 2.8532826152049204

Epoch: 5| Step: 2
Training loss: 0.48924713732252767
Validation loss: 2.8007178128700554

Epoch: 5| Step: 3
Training loss: 0.5620535562355752
Validation loss: 2.7984745914195654

Epoch: 5| Step: 4
Training loss: 0.36659267620033137
Validation loss: 2.8048710138749993

Epoch: 5| Step: 5
Training loss: 0.5052972859467334
Validation loss: 2.8119021239410027

Epoch: 5| Step: 6
Training loss: 0.2756219528099001
Validation loss: 2.7506051662012854

Epoch: 5| Step: 7
Training loss: 0.49238708022135724
Validation loss: 2.804393976095061

Epoch: 5| Step: 8
Training loss: 0.4293887747230586
Validation loss: 2.7028693701205544

Epoch: 5| Step: 9
Training loss: 0.45465508637137464
Validation loss: 2.7776600567721377

Epoch: 5| Step: 10
Training loss: 0.4350647246231702
Validation loss: 2.7982578801412465

Epoch: 5| Step: 11
Training loss: 0.7005837611942823
Validation loss: 2.8262035769688327

Epoch: 391| Step: 0
Training loss: 0.4098621222057228
Validation loss: 2.8161616119926687

Epoch: 5| Step: 1
Training loss: 0.49585359121927963
Validation loss: 2.771180584069261

Epoch: 5| Step: 2
Training loss: 0.33054323551894504
Validation loss: 2.804745810778325

Epoch: 5| Step: 3
Training loss: 0.41115832759305887
Validation loss: 2.859826769689895

Epoch: 5| Step: 4
Training loss: 0.432537097277053
Validation loss: 2.8373668946123054

Epoch: 5| Step: 5
Training loss: 0.49025370647112826
Validation loss: 2.9192362479010963

Epoch: 5| Step: 6
Training loss: 0.31515863305147396
Validation loss: 2.8487413185403576

Epoch: 5| Step: 7
Training loss: 0.4132772593314573
Validation loss: 2.8585917089607378

Epoch: 5| Step: 8
Training loss: 0.5319682483089214
Validation loss: 2.8179042639923115

Epoch: 5| Step: 9
Training loss: 0.4870711017124685
Validation loss: 2.799605533793622

Epoch: 5| Step: 10
Training loss: 0.49638418271656914
Validation loss: 2.7213507011914735

Epoch: 5| Step: 11
Training loss: 0.3219050036955144
Validation loss: 2.7746012399747455

Epoch: 392| Step: 0
Training loss: 0.509296888669478
Validation loss: 2.7995496921379326

Epoch: 5| Step: 1
Training loss: 0.32619815423599374
Validation loss: 2.8487655892921295

Epoch: 5| Step: 2
Training loss: 0.39562172838639126
Validation loss: 2.8174132100299523

Epoch: 5| Step: 3
Training loss: 0.467798443406603
Validation loss: 2.7938239720029228

Epoch: 5| Step: 4
Training loss: 0.5018722231492386
Validation loss: 2.8823133827405156

Epoch: 5| Step: 5
Training loss: 0.32444047814569243
Validation loss: 2.827743234035152

Epoch: 5| Step: 6
Training loss: 0.4447122342863607
Validation loss: 2.758383993382757

Epoch: 5| Step: 7
Training loss: 0.526660278478743
Validation loss: 2.7715056770049094

Epoch: 5| Step: 8
Training loss: 0.5795080549833921
Validation loss: 2.8309962203116132

Epoch: 5| Step: 9
Training loss: 0.5626481708771803
Validation loss: 2.715185025946197

Epoch: 5| Step: 10
Training loss: 0.5157885725489048
Validation loss: 2.788365591335351

Epoch: 5| Step: 11
Training loss: 0.10417092930496244
Validation loss: 2.7789658728891755

Epoch: 393| Step: 0
Training loss: 0.35234984077551784
Validation loss: 2.873328649143847

Epoch: 5| Step: 1
Training loss: 0.443533136540504
Validation loss: 2.7705559352657088

Epoch: 5| Step: 2
Training loss: 0.41775701632334744
Validation loss: 2.828223175817665

Epoch: 5| Step: 3
Training loss: 0.44576849094533794
Validation loss: 2.791977300489706

Epoch: 5| Step: 4
Training loss: 0.3847858017021998
Validation loss: 2.802453180932133

Epoch: 5| Step: 5
Training loss: 0.4826023057829974
Validation loss: 2.8288941997028068

Epoch: 5| Step: 6
Training loss: 0.3774153884270275
Validation loss: 2.746418766848946

Epoch: 5| Step: 7
Training loss: 0.49856818348491744
Validation loss: 2.8618584671925884

Epoch: 5| Step: 8
Training loss: 0.2914197407276625
Validation loss: 2.8413185896945934

Epoch: 5| Step: 9
Training loss: 0.39172728463405704
Validation loss: 2.8487834644290957

Epoch: 5| Step: 10
Training loss: 0.3603046459059924
Validation loss: 2.7758066079044084

Epoch: 5| Step: 11
Training loss: 0.2779295604327535
Validation loss: 2.75508033849347

Epoch: 394| Step: 0
Training loss: 0.4440673016067759
Validation loss: 2.75936231930657

Epoch: 5| Step: 1
Training loss: 0.5421189168597997
Validation loss: 2.8034915960071514

Epoch: 5| Step: 2
Training loss: 0.28238677391052447
Validation loss: 2.8048582388108194

Epoch: 5| Step: 3
Training loss: 0.4411812605551071
Validation loss: 2.8224474081698427

Epoch: 5| Step: 4
Training loss: 0.3868086739229297
Validation loss: 2.851214508700927

Epoch: 5| Step: 5
Training loss: 0.488094202454783
Validation loss: 2.8919252718811452

Epoch: 5| Step: 6
Training loss: 0.5349610801158992
Validation loss: 2.8333824249296846

Epoch: 5| Step: 7
Training loss: 0.4341705026139849
Validation loss: 2.809852788322651

Epoch: 5| Step: 8
Training loss: 0.29679018616073877
Validation loss: 2.8185110564642955

Epoch: 5| Step: 9
Training loss: 0.27787189164184206
Validation loss: 2.8165968302716156

Epoch: 5| Step: 10
Training loss: 0.3308751004568019
Validation loss: 2.872794601183832

Epoch: 5| Step: 11
Training loss: 0.33890965220395547
Validation loss: 2.7699831982560945

Epoch: 395| Step: 0
Training loss: 0.4686579772903144
Validation loss: 2.821353456073287

Epoch: 5| Step: 1
Training loss: 0.5237256011651337
Validation loss: 2.764021280979418

Epoch: 5| Step: 2
Training loss: 0.3232293025557519
Validation loss: 2.778587184574262

Epoch: 5| Step: 3
Training loss: 0.3914597746900517
Validation loss: 2.8551630290483696

Epoch: 5| Step: 4
Training loss: 0.4602105502099239
Validation loss: 2.8208582817610317

Epoch: 5| Step: 5
Training loss: 0.19666715996856837
Validation loss: 2.839249721492042

Epoch: 5| Step: 6
Training loss: 0.32303454826481637
Validation loss: 2.8361937912378083

Epoch: 5| Step: 7
Training loss: 0.2998180324305624
Validation loss: 2.8087506062544185

Epoch: 5| Step: 8
Training loss: 0.5488971381730143
Validation loss: 2.8608869262369834

Epoch: 5| Step: 9
Training loss: 0.3554815143347535
Validation loss: 2.875366394911007

Epoch: 5| Step: 10
Training loss: 0.26481699062858743
Validation loss: 2.785395536625524

Epoch: 5| Step: 11
Training loss: 0.3495804225931549
Validation loss: 2.7952657470716744

Epoch: 396| Step: 0
Training loss: 0.5328000679691232
Validation loss: 2.7720335187172167

Epoch: 5| Step: 1
Training loss: 0.39296111598098277
Validation loss: 2.729139107038428

Epoch: 5| Step: 2
Training loss: 0.4049947492824257
Validation loss: 2.861841715091295

Epoch: 5| Step: 3
Training loss: 0.4349985305991512
Validation loss: 2.747446803965533

Epoch: 5| Step: 4
Training loss: 0.34271135338531866
Validation loss: 2.760767483761211

Epoch: 5| Step: 5
Training loss: 0.6015734485769343
Validation loss: 2.7651813819399744

Epoch: 5| Step: 6
Training loss: 0.43861069358765276
Validation loss: 2.792849230932212

Epoch: 5| Step: 7
Training loss: 0.38602275061269764
Validation loss: 2.7638482818197727

Epoch: 5| Step: 8
Training loss: 0.34320490056201003
Validation loss: 2.76290109262884

Epoch: 5| Step: 9
Training loss: 0.32977515768313864
Validation loss: 2.7931451381658174

Epoch: 5| Step: 10
Training loss: 0.4157966431438655
Validation loss: 2.810152649596553

Epoch: 5| Step: 11
Training loss: 0.32842488436148426
Validation loss: 2.746954702002912

Epoch: 397| Step: 0
Training loss: 0.4220499276494991
Validation loss: 2.7681335236518705

Epoch: 5| Step: 1
Training loss: 0.4214428878602704
Validation loss: 2.8284502211248737

Epoch: 5| Step: 2
Training loss: 0.4706081911963349
Validation loss: 2.7472565867253955

Epoch: 5| Step: 3
Training loss: 0.38034435565095703
Validation loss: 2.7812251686387857

Epoch: 5| Step: 4
Training loss: 0.3461235098174733
Validation loss: 2.7370735476427255

Epoch: 5| Step: 5
Training loss: 0.49354351289188325
Validation loss: 2.7548493161622236

Epoch: 5| Step: 6
Training loss: 0.3479620627902787
Validation loss: 2.797026720673572

Epoch: 5| Step: 7
Training loss: 0.361239448182064
Validation loss: 2.7578008793774256

Epoch: 5| Step: 8
Training loss: 0.4315695898370018
Validation loss: 2.791849345070909

Epoch: 5| Step: 9
Training loss: 0.47728291762298
Validation loss: 2.8389903119374176

Epoch: 5| Step: 10
Training loss: 0.3865491128945623
Validation loss: 2.845047148373628

Epoch: 5| Step: 11
Training loss: 0.38595264343328045
Validation loss: 2.8458139035374748

Epoch: 398| Step: 0
Training loss: 0.3540335386304802
Validation loss: 2.8075072548394067

Epoch: 5| Step: 1
Training loss: 0.44354880903103694
Validation loss: 2.799269036975116

Epoch: 5| Step: 2
Training loss: 0.3520017846411742
Validation loss: 2.8303280393809804

Epoch: 5| Step: 3
Training loss: 0.4687319752088673
Validation loss: 2.830120008258308

Epoch: 5| Step: 4
Training loss: 0.38436237252435607
Validation loss: 2.781958196963326

Epoch: 5| Step: 5
Training loss: 0.5268590889877937
Validation loss: 2.755450287971481

Epoch: 5| Step: 6
Training loss: 0.28007401871697013
Validation loss: 2.778029520362903

Epoch: 5| Step: 7
Training loss: 0.5879868083353162
Validation loss: 2.77951238765725

Epoch: 5| Step: 8
Training loss: 0.3962191366336253
Validation loss: 2.768286525291169

Epoch: 5| Step: 9
Training loss: 0.35965473234589107
Validation loss: 2.8300726736721336

Epoch: 5| Step: 10
Training loss: 0.4098139288026384
Validation loss: 2.8026782766791163

Epoch: 5| Step: 11
Training loss: 0.16984521846785658
Validation loss: 2.784376109159044

Epoch: 399| Step: 0
Training loss: 0.3910480497256237
Validation loss: 2.829184532155937

Epoch: 5| Step: 1
Training loss: 0.37691993764939147
Validation loss: 2.7799482335158205

Epoch: 5| Step: 2
Training loss: 0.24316833676178
Validation loss: 2.7980464314874864

Epoch: 5| Step: 3
Training loss: 0.4094392958956728
Validation loss: 2.760789397404681

Epoch: 5| Step: 4
Training loss: 0.4920121440648623
Validation loss: 2.813779490443585

Epoch: 5| Step: 5
Training loss: 0.4134671591733242
Validation loss: 2.861276737658717

Epoch: 5| Step: 6
Training loss: 0.5245729344281365
Validation loss: 2.7691769644570354

Epoch: 5| Step: 7
Training loss: 0.3287950327710631
Validation loss: 2.762498309421166

Epoch: 5| Step: 8
Training loss: 0.4343474084337905
Validation loss: 2.8891104192698545

Epoch: 5| Step: 9
Training loss: 0.49629187945302444
Validation loss: 2.843822384007388

Epoch: 5| Step: 10
Training loss: 0.49530095107997907
Validation loss: 2.782830146649352

Epoch: 5| Step: 11
Training loss: 0.4732247708745032
Validation loss: 2.7395372725314506

Epoch: 400| Step: 0
Training loss: 0.3982801313597817
Validation loss: 2.8088774416229354

Epoch: 5| Step: 1
Training loss: 0.30202566067674114
Validation loss: 2.8473758184412072

Epoch: 5| Step: 2
Training loss: 0.4190647159606012
Validation loss: 2.8505054587538483

Epoch: 5| Step: 3
Training loss: 0.42861412536718757
Validation loss: 2.8145466492693165

Epoch: 5| Step: 4
Training loss: 0.36500052243025505
Validation loss: 2.735173016311264

Epoch: 5| Step: 5
Training loss: 0.5131478483198636
Validation loss: 2.820006152252268

Epoch: 5| Step: 6
Training loss: 0.49825396252830306
Validation loss: 2.8071821305816256

Epoch: 5| Step: 7
Training loss: 0.483032735574149
Validation loss: 2.81291843409919

Epoch: 5| Step: 8
Training loss: 0.43885426725103766
Validation loss: 2.7885265814955384

Epoch: 5| Step: 9
Training loss: 0.48802527775431925
Validation loss: 2.7541722559234953

Epoch: 5| Step: 10
Training loss: 0.41836751650342313
Validation loss: 2.775507588688097

Epoch: 5| Step: 11
Training loss: 0.2902333799938125
Validation loss: 2.7910173583865094

Epoch: 401| Step: 0
Training loss: 0.4333659080341656
Validation loss: 2.7965558258873875

Epoch: 5| Step: 1
Training loss: 0.3396524570571639
Validation loss: 2.8088824424874232

Epoch: 5| Step: 2
Training loss: 0.4850975001049562
Validation loss: 2.834326041912289

Epoch: 5| Step: 3
Training loss: 0.4373500771454965
Validation loss: 2.810361791140485

Epoch: 5| Step: 4
Training loss: 0.46871808261291004
Validation loss: 2.8515228338400362

Epoch: 5| Step: 5
Training loss: 0.44141263028825284
Validation loss: 2.797342037653616

Epoch: 5| Step: 6
Training loss: 0.46076444836470515
Validation loss: 2.7690587467934034

Epoch: 5| Step: 7
Training loss: 0.6124054796895619
Validation loss: 2.863724260116006

Epoch: 5| Step: 8
Training loss: 0.4976186519535075
Validation loss: 2.7640151063468994

Epoch: 5| Step: 9
Training loss: 0.28781280500994333
Validation loss: 2.7741982433034207

Epoch: 5| Step: 10
Training loss: 0.32911121795707693
Validation loss: 2.8385637941577095

Epoch: 5| Step: 11
Training loss: 0.41325109981175895
Validation loss: 2.822298701355385

Epoch: 402| Step: 0
Training loss: 0.36064508160720343
Validation loss: 2.824170535613879

Epoch: 5| Step: 1
Training loss: 0.45917618984251646
Validation loss: 2.826348804277631

Epoch: 5| Step: 2
Training loss: 0.35077013155302145
Validation loss: 2.7868020116090255

Epoch: 5| Step: 3
Training loss: 0.4946932510745335
Validation loss: 2.8057883571803757

Epoch: 5| Step: 4
Training loss: 0.3644489267645096
Validation loss: 2.8647627907229505

Epoch: 5| Step: 5
Training loss: 0.3706247075933683
Validation loss: 2.7566181042297995

Epoch: 5| Step: 6
Training loss: 0.37594584550100557
Validation loss: 2.7756318522850254

Epoch: 5| Step: 7
Training loss: 0.38399441881519714
Validation loss: 2.769493852442672

Epoch: 5| Step: 8
Training loss: 0.6024837375757105
Validation loss: 2.83012320950096

Epoch: 5| Step: 9
Training loss: 0.5030584374224774
Validation loss: 2.85164803154581

Epoch: 5| Step: 10
Training loss: 0.4207521613683735
Validation loss: 2.835918184745313

Epoch: 5| Step: 11
Training loss: 0.36729693303882843
Validation loss: 2.830172863399751

Epoch: 403| Step: 0
Training loss: 0.27963279316955675
Validation loss: 2.8543355513585644

Epoch: 5| Step: 1
Training loss: 0.3705412516286872
Validation loss: 2.820042467795176

Epoch: 5| Step: 2
Training loss: 0.40854119715970827
Validation loss: 2.8056134189381705

Epoch: 5| Step: 3
Training loss: 0.28400274057308456
Validation loss: 2.82935734238791

Epoch: 5| Step: 4
Training loss: 0.4709902002708171
Validation loss: 2.8393800016629664

Epoch: 5| Step: 5
Training loss: 0.43895695120194506
Validation loss: 2.8401006996016562

Epoch: 5| Step: 6
Training loss: 0.49876601714513197
Validation loss: 2.7969727632282755

Epoch: 5| Step: 7
Training loss: 0.45962035575016325
Validation loss: 2.8579147098117623

Epoch: 5| Step: 8
Training loss: 0.34984491181958016
Validation loss: 2.8778704087117855

Epoch: 5| Step: 9
Training loss: 0.3066504288582234
Validation loss: 2.771684083381138

Epoch: 5| Step: 10
Training loss: 0.5401238759441196
Validation loss: 2.7826630506700685

Epoch: 5| Step: 11
Training loss: 0.2534177188467804
Validation loss: 2.8018633615497546

Epoch: 404| Step: 0
Training loss: 0.48091213578331926
Validation loss: 2.7684827540683035

Epoch: 5| Step: 1
Training loss: 0.40856412047108137
Validation loss: 2.8338353306044364

Epoch: 5| Step: 2
Training loss: 0.4924899488962899
Validation loss: 2.7560520082264786

Epoch: 5| Step: 3
Training loss: 0.41976720046062443
Validation loss: 2.89083419936332

Epoch: 5| Step: 4
Training loss: 0.4248998776475852
Validation loss: 2.8273384763878053

Epoch: 5| Step: 5
Training loss: 0.31907384073276546
Validation loss: 2.8564531062093197

Epoch: 5| Step: 6
Training loss: 0.39273070221931383
Validation loss: 2.7519994677216917

Epoch: 5| Step: 7
Training loss: 0.49487306193053904
Validation loss: 2.749462490581609

Epoch: 5| Step: 8
Training loss: 0.4351504108030337
Validation loss: 2.7889985327415303

Epoch: 5| Step: 9
Training loss: 0.3589622366204624
Validation loss: 2.745301994834837

Epoch: 5| Step: 10
Training loss: 0.44075277788928036
Validation loss: 2.8208327091015377

Epoch: 5| Step: 11
Training loss: 0.3533630147067994
Validation loss: 2.8048413304440016

Epoch: 405| Step: 0
Training loss: 0.5436235774169188
Validation loss: 2.797137693858761

Epoch: 5| Step: 1
Training loss: 0.37199807654801315
Validation loss: 2.833174106153531

Epoch: 5| Step: 2
Training loss: 0.4142561765473907
Validation loss: 2.777813520731377

Epoch: 5| Step: 3
Training loss: 0.33955429070946325
Validation loss: 2.8113718595959445

Epoch: 5| Step: 4
Training loss: 0.5491244510532399
Validation loss: 2.7813260750242303

Epoch: 5| Step: 5
Training loss: 0.5441155706526736
Validation loss: 2.8219613303901663

Epoch: 5| Step: 6
Training loss: 0.36111190099915086
Validation loss: 2.800342378233091

Epoch: 5| Step: 7
Training loss: 0.30494948885431217
Validation loss: 2.851784722713925

Epoch: 5| Step: 8
Training loss: 0.34056701647850446
Validation loss: 2.769445729157067

Epoch: 5| Step: 9
Training loss: 0.463265182962721
Validation loss: 2.7858331828716882

Epoch: 5| Step: 10
Training loss: 0.4571728120323113
Validation loss: 2.8024413519435916

Epoch: 5| Step: 11
Training loss: 0.27624144912017323
Validation loss: 2.806675818038377

Epoch: 406| Step: 0
Training loss: 0.39510164480144566
Validation loss: 2.855551172711596

Epoch: 5| Step: 1
Training loss: 0.4373957986718849
Validation loss: 2.780113202198422

Epoch: 5| Step: 2
Training loss: 0.45090370961015025
Validation loss: 2.781001937176257

Epoch: 5| Step: 3
Training loss: 0.4133101592021413
Validation loss: 2.806935078344543

Epoch: 5| Step: 4
Training loss: 0.5324105600902566
Validation loss: 2.7709134898148062

Epoch: 5| Step: 5
Training loss: 0.28051107082007115
Validation loss: 2.719539651891538

Epoch: 5| Step: 6
Training loss: 0.36238487980754475
Validation loss: 2.802441234965032

Epoch: 5| Step: 7
Training loss: 0.2826377091407888
Validation loss: 2.780702429885398

Epoch: 5| Step: 8
Training loss: 0.468373847082433
Validation loss: 2.8571832939249666

Epoch: 5| Step: 9
Training loss: 0.44926354558092857
Validation loss: 2.7755714982163435

Epoch: 5| Step: 10
Training loss: 0.3110912278445291
Validation loss: 2.7772508937444966

Epoch: 5| Step: 11
Training loss: 0.1912879578315258
Validation loss: 2.7756140214324545

Epoch: 407| Step: 0
Training loss: 0.5165352733750083
Validation loss: 2.7694780876391056

Epoch: 5| Step: 1
Training loss: 0.5414665904142665
Validation loss: 2.8563896604153975

Epoch: 5| Step: 2
Training loss: 0.43615724364482716
Validation loss: 2.717438798178396

Epoch: 5| Step: 3
Training loss: 0.3865144363288198
Validation loss: 2.8276797904887054

Epoch: 5| Step: 4
Training loss: 0.4269412626274632
Validation loss: 2.778485059630374

Epoch: 5| Step: 5
Training loss: 0.6492582435393034
Validation loss: 2.7887457802223508

Epoch: 5| Step: 6
Training loss: 0.5824403796975723
Validation loss: 2.7719797305994036

Epoch: 5| Step: 7
Training loss: 0.44014698775800254
Validation loss: 2.853913777464414

Epoch: 5| Step: 8
Training loss: 0.39195433444801614
Validation loss: 2.7622772903772197

Epoch: 5| Step: 9
Training loss: 0.39921803782300636
Validation loss: 2.7827371664558105

Epoch: 5| Step: 10
Training loss: 0.49031891416848483
Validation loss: 2.793268620681073

Epoch: 5| Step: 11
Training loss: 0.28952477838537233
Validation loss: 2.7854519152544936

Epoch: 408| Step: 0
Training loss: 0.35332144362235374
Validation loss: 2.835115315308327

Epoch: 5| Step: 1
Training loss: 0.4307057539985751
Validation loss: 2.848024010513074

Epoch: 5| Step: 2
Training loss: 0.5005306170165961
Validation loss: 2.842260522587663

Epoch: 5| Step: 3
Training loss: 0.3101217971422647
Validation loss: 2.755840069842653

Epoch: 5| Step: 4
Training loss: 0.3099928057704878
Validation loss: 2.851606123081086

Epoch: 5| Step: 5
Training loss: 0.40357270552545293
Validation loss: 2.8204976353064266

Epoch: 5| Step: 6
Training loss: 0.48302991286642616
Validation loss: 2.858977069507488

Epoch: 5| Step: 7
Training loss: 0.5347803285192138
Validation loss: 2.7980031876147082

Epoch: 5| Step: 8
Training loss: 0.4716772075453617
Validation loss: 2.8131359794135187

Epoch: 5| Step: 9
Training loss: 0.413568940292236
Validation loss: 2.8694310708876527

Epoch: 5| Step: 10
Training loss: 0.35664995145771994
Validation loss: 2.781597315786773

Epoch: 5| Step: 11
Training loss: 0.5535709533821211
Validation loss: 2.767356887047284

Epoch: 409| Step: 0
Training loss: 0.25320672729151916
Validation loss: 2.765087398713651

Epoch: 5| Step: 1
Training loss: 0.42188301785232124
Validation loss: 2.8283325983221492

Epoch: 5| Step: 2
Training loss: 0.4410565772019054
Validation loss: 2.80412985412407

Epoch: 5| Step: 3
Training loss: 0.47690352760769233
Validation loss: 2.873972401590862

Epoch: 5| Step: 4
Training loss: 0.3070606222493226
Validation loss: 2.8408867775878854

Epoch: 5| Step: 5
Training loss: 0.39523356784271385
Validation loss: 2.8045541329583537

Epoch: 5| Step: 6
Training loss: 0.6770936427187393
Validation loss: 2.817282626322702

Epoch: 5| Step: 7
Training loss: 0.3096647028418488
Validation loss: 2.8109410945918123

Epoch: 5| Step: 8
Training loss: 0.4023398612121496
Validation loss: 2.7395809062371668

Epoch: 5| Step: 9
Training loss: 0.5116764371427838
Validation loss: 2.830451619504156

Epoch: 5| Step: 10
Training loss: 0.3816270964459019
Validation loss: 2.7835391086094288

Epoch: 5| Step: 11
Training loss: 0.5668739755404635
Validation loss: 2.827249524950685

Epoch: 410| Step: 0
Training loss: 0.5310741301748293
Validation loss: 2.8520626169533956

Epoch: 5| Step: 1
Training loss: 0.2956059335201505
Validation loss: 2.7776483510912513

Epoch: 5| Step: 2
Training loss: 0.4083879590799637
Validation loss: 2.779308841810916

Epoch: 5| Step: 3
Training loss: 0.40129807148619023
Validation loss: 2.774632482133955

Epoch: 5| Step: 4
Training loss: 0.33117351818644464
Validation loss: 2.8158407150545104

Epoch: 5| Step: 5
Training loss: 0.5134680165783646
Validation loss: 2.79400968205261

Epoch: 5| Step: 6
Training loss: 0.3146514977673936
Validation loss: 2.7957605667044194

Epoch: 5| Step: 7
Training loss: 0.4426289730373106
Validation loss: 2.7548422158527126

Epoch: 5| Step: 8
Training loss: 0.5147323105742911
Validation loss: 2.818839698655604

Epoch: 5| Step: 9
Training loss: 0.4274160864383485
Validation loss: 2.8920818712814924

Epoch: 5| Step: 10
Training loss: 0.5094412579183139
Validation loss: 2.791261530890922

Epoch: 5| Step: 11
Training loss: 0.26765716387787003
Validation loss: 2.7951122781554356

Epoch: 411| Step: 0
Training loss: 0.33700754831276625
Validation loss: 2.8587298646936956

Epoch: 5| Step: 1
Training loss: 0.3406359329568904
Validation loss: 2.794017596589211

Epoch: 5| Step: 2
Training loss: 0.43523649095696426
Validation loss: 2.8179895268918638

Epoch: 5| Step: 3
Training loss: 0.4534064438304346
Validation loss: 2.8359197260472166

Epoch: 5| Step: 4
Training loss: 0.394409859744365
Validation loss: 2.7324352650363166

Epoch: 5| Step: 5
Training loss: 0.40762390218924394
Validation loss: 2.81307838285488

Epoch: 5| Step: 6
Training loss: 0.3693791985958964
Validation loss: 2.816574945216708

Epoch: 5| Step: 7
Training loss: 0.33384871376730213
Validation loss: 2.7518605635639264

Epoch: 5| Step: 8
Training loss: 0.3693098255692651
Validation loss: 2.813242129147704

Epoch: 5| Step: 9
Training loss: 0.3812664106620516
Validation loss: 2.847589831281904

Epoch: 5| Step: 10
Training loss: 0.41832619828463086
Validation loss: 2.79293325975184

Epoch: 5| Step: 11
Training loss: 0.9979902277508166
Validation loss: 2.7634750997092046

Epoch: 412| Step: 0
Training loss: 0.43796449934781256
Validation loss: 2.772828234880086

Epoch: 5| Step: 1
Training loss: 0.4529454928030184
Validation loss: 2.786894467646492

Epoch: 5| Step: 2
Training loss: 0.4173525608722254
Validation loss: 2.813424431793337

Epoch: 5| Step: 3
Training loss: 0.533957510148911
Validation loss: 2.787880038682763

Epoch: 5| Step: 4
Training loss: 0.5844441010933864
Validation loss: 2.8213721703559433

Epoch: 5| Step: 5
Training loss: 0.36476515141838545
Validation loss: 2.8186138035589368

Epoch: 5| Step: 6
Training loss: 0.5192814563466838
Validation loss: 2.7393293202541713

Epoch: 5| Step: 7
Training loss: 0.3778894683965302
Validation loss: 2.7967487640591817

Epoch: 5| Step: 8
Training loss: 0.3785420466630897
Validation loss: 2.8227633238712686

Epoch: 5| Step: 9
Training loss: 0.44042809733507626
Validation loss: 2.779106335554645

Epoch: 5| Step: 10
Training loss: 0.4927669172426383
Validation loss: 2.7325017161653324

Epoch: 5| Step: 11
Training loss: 0.48687583078551017
Validation loss: 2.8140909251758397

Epoch: 413| Step: 0
Training loss: 0.5693707725376338
Validation loss: 2.798298382988609

Epoch: 5| Step: 1
Training loss: 0.41439780568099743
Validation loss: 2.8167858846722726

Epoch: 5| Step: 2
Training loss: 0.3684353018995208
Validation loss: 2.7946302651458694

Epoch: 5| Step: 3
Training loss: 0.5895094271416474
Validation loss: 2.7531596404951495

Epoch: 5| Step: 4
Training loss: 0.2825924306912743
Validation loss: 2.856123032172041

Epoch: 5| Step: 5
Training loss: 0.4949726141954543
Validation loss: 2.811816241895495

Epoch: 5| Step: 6
Training loss: 0.5409926261557979
Validation loss: 2.7832746922621974

Epoch: 5| Step: 7
Training loss: 0.4381548374534971
Validation loss: 2.774043086026515

Epoch: 5| Step: 8
Training loss: 0.40084097121701473
Validation loss: 2.852686516784615

Epoch: 5| Step: 9
Training loss: 0.47016524610853594
Validation loss: 2.8175166353368133

Epoch: 5| Step: 10
Training loss: 0.4478967203829715
Validation loss: 2.823577941824385

Epoch: 5| Step: 11
Training loss: 0.5886422102350934
Validation loss: 2.7833147207273585

Epoch: 414| Step: 0
Training loss: 0.3388943839908784
Validation loss: 2.8497114993353487

Epoch: 5| Step: 1
Training loss: 0.25061762037851953
Validation loss: 2.774183976988463

Epoch: 5| Step: 2
Training loss: 0.5093917352466484
Validation loss: 2.779436237972174

Epoch: 5| Step: 3
Training loss: 0.30476065515506096
Validation loss: 2.789509816633776

Epoch: 5| Step: 4
Training loss: 0.39575106828368267
Validation loss: 2.837945601964984

Epoch: 5| Step: 5
Training loss: 0.41705314673075966
Validation loss: 2.7759190163109184

Epoch: 5| Step: 6
Training loss: 0.3510297128960729
Validation loss: 2.755426568881146

Epoch: 5| Step: 7
Training loss: 0.5354251881921974
Validation loss: 2.827947934194558

Epoch: 5| Step: 8
Training loss: 0.4784726960524803
Validation loss: 2.8335144017835603

Epoch: 5| Step: 9
Training loss: 0.3417830764165042
Validation loss: 2.811309081944139

Epoch: 5| Step: 10
Training loss: 0.4569149847576562
Validation loss: 2.813119625783365

Epoch: 5| Step: 11
Training loss: 0.2934727339264448
Validation loss: 2.892710849036026

Epoch: 415| Step: 0
Training loss: 0.5305509455826198
Validation loss: 2.8082043975206004

Epoch: 5| Step: 1
Training loss: 0.4612837476970904
Validation loss: 2.8230746472529833

Epoch: 5| Step: 2
Training loss: 0.431419989350858
Validation loss: 2.786789855962451

Epoch: 5| Step: 3
Training loss: 0.4740995643826945
Validation loss: 2.861120236844156

Epoch: 5| Step: 4
Training loss: 0.16208850772250516
Validation loss: 2.8147789569970882

Epoch: 5| Step: 5
Training loss: 0.3940946599435438
Validation loss: 2.864281958707905

Epoch: 5| Step: 6
Training loss: 0.4253772078430739
Validation loss: 2.825807626587254

Epoch: 5| Step: 7
Training loss: 0.40446868415601506
Validation loss: 2.7612413697908713

Epoch: 5| Step: 8
Training loss: 0.31601816089117196
Validation loss: 2.812495037357049

Epoch: 5| Step: 9
Training loss: 0.3890634222670811
Validation loss: 2.7947954619774418

Epoch: 5| Step: 10
Training loss: 0.5554668431846199
Validation loss: 2.8907155237543427

Epoch: 5| Step: 11
Training loss: 0.46081551052875946
Validation loss: 2.8981508522835835

Epoch: 416| Step: 0
Training loss: 0.5524527435461096
Validation loss: 2.7944479913122353

Epoch: 5| Step: 1
Training loss: 0.4573928022389185
Validation loss: 2.8258020791335574

Epoch: 5| Step: 2
Training loss: 0.36632507580028917
Validation loss: 2.810865283891538

Epoch: 5| Step: 3
Training loss: 0.250156919584504
Validation loss: 2.7985230248731816

Epoch: 5| Step: 4
Training loss: 0.36137577464397724
Validation loss: 2.8423354050437233

Epoch: 5| Step: 5
Training loss: 0.45661933790571185
Validation loss: 2.8161454787670657

Epoch: 5| Step: 6
Training loss: 0.489946212273563
Validation loss: 2.782979734501653

Epoch: 5| Step: 7
Training loss: 0.4396523257286554
Validation loss: 2.8140426925930764

Epoch: 5| Step: 8
Training loss: 0.40391321452941203
Validation loss: 2.821760424107595

Epoch: 5| Step: 9
Training loss: 0.34652916232813324
Validation loss: 2.858335059214554

Epoch: 5| Step: 10
Training loss: 0.4879681613416538
Validation loss: 2.867932544196724

Epoch: 5| Step: 11
Training loss: 0.5714946670283403
Validation loss: 2.866580230126865

Epoch: 417| Step: 0
Training loss: 0.3379853066327553
Validation loss: 2.80995018134296

Epoch: 5| Step: 1
Training loss: 0.375178652169573
Validation loss: 2.804702206203828

Epoch: 5| Step: 2
Training loss: 0.37771734536570106
Validation loss: 2.7533168892556015

Epoch: 5| Step: 3
Training loss: 0.4089623832437329
Validation loss: 2.8507117861892572

Epoch: 5| Step: 4
Training loss: 0.3722408834843632
Validation loss: 2.8287997731690133

Epoch: 5| Step: 5
Training loss: 0.25706218139142695
Validation loss: 2.7972744739898396

Epoch: 5| Step: 6
Training loss: 0.38093585689149634
Validation loss: 2.7726827248113413

Epoch: 5| Step: 7
Training loss: 0.3341825577631031
Validation loss: 2.7934587133347297

Epoch: 5| Step: 8
Training loss: 0.4705364992890566
Validation loss: 2.8164040666449166

Epoch: 5| Step: 9
Training loss: 0.3458572949109323
Validation loss: 2.83012635282287

Epoch: 5| Step: 10
Training loss: 0.4971334271185503
Validation loss: 2.8309600593197772

Epoch: 5| Step: 11
Training loss: 0.16093442437094088
Validation loss: 2.8451250056764312

Epoch: 418| Step: 0
Training loss: 0.4397242578569934
Validation loss: 2.814977317772881

Epoch: 5| Step: 1
Training loss: 0.31129978486496956
Validation loss: 2.7941992585518576

Epoch: 5| Step: 2
Training loss: 0.3327488045789195
Validation loss: 2.8373219742292886

Epoch: 5| Step: 3
Training loss: 0.4296385303683069
Validation loss: 2.8545341997581866

Epoch: 5| Step: 4
Training loss: 0.4475632389500919
Validation loss: 2.7469154564688623

Epoch: 5| Step: 5
Training loss: 0.39201340933898904
Validation loss: 2.8883243684488304

Epoch: 5| Step: 6
Training loss: 0.407119370950699
Validation loss: 2.8182520609141752

Epoch: 5| Step: 7
Training loss: 0.5296746345240403
Validation loss: 2.841972910179684

Epoch: 5| Step: 8
Training loss: 0.3255556418563792
Validation loss: 2.7925272452580066

Epoch: 5| Step: 9
Training loss: 0.2936564575556685
Validation loss: 2.8251389112050003

Epoch: 5| Step: 10
Training loss: 0.5061121423246475
Validation loss: 2.7837476445305

Epoch: 5| Step: 11
Training loss: 0.3258555357328925
Validation loss: 2.8243258338560624

Epoch: 419| Step: 0
Training loss: 0.40595328058781827
Validation loss: 2.839984115496839

Epoch: 5| Step: 1
Training loss: 0.4163425933677517
Validation loss: 2.8433800306450796

Epoch: 5| Step: 2
Training loss: 0.40586556071027574
Validation loss: 2.8473674521326444

Epoch: 5| Step: 3
Training loss: 0.3412258282509058
Validation loss: 2.8682957273626584

Epoch: 5| Step: 4
Training loss: 0.505640873795388
Validation loss: 2.7722034377315534

Epoch: 5| Step: 5
Training loss: 0.45215054670134397
Validation loss: 2.780201825138696

Epoch: 5| Step: 6
Training loss: 0.5050861237048206
Validation loss: 2.805897164058232

Epoch: 5| Step: 7
Training loss: 0.44654716857795856
Validation loss: 2.7979218709920475

Epoch: 5| Step: 8
Training loss: 0.46115469260617453
Validation loss: 2.825841441913904

Epoch: 5| Step: 9
Training loss: 0.43646697291500436
Validation loss: 2.751821348285466

Epoch: 5| Step: 10
Training loss: 0.27395236724381455
Validation loss: 2.8240324445225955

Epoch: 5| Step: 11
Training loss: 0.569469717545235
Validation loss: 2.754321008927365

Epoch: 420| Step: 0
Training loss: 0.6454421109511059
Validation loss: 2.8815556985314044

Epoch: 5| Step: 1
Training loss: 0.4695140651407964
Validation loss: 2.77567462152673

Epoch: 5| Step: 2
Training loss: 0.2322894287999444
Validation loss: 2.777391038966891

Epoch: 5| Step: 3
Training loss: 0.3918458172093876
Validation loss: 2.8041220850374087

Epoch: 5| Step: 4
Training loss: 0.5239768878793735
Validation loss: 2.820742503008743

Epoch: 5| Step: 5
Training loss: 0.3415189321395952
Validation loss: 2.7780940691696085

Epoch: 5| Step: 6
Training loss: 0.425660002357294
Validation loss: 2.7688031048701465

Epoch: 5| Step: 7
Training loss: 0.39316120781504077
Validation loss: 2.857427159424226

Epoch: 5| Step: 8
Training loss: 0.3935104988980551
Validation loss: 2.759234032318844

Epoch: 5| Step: 9
Training loss: 0.4577580403299429
Validation loss: 2.8223115488295702

Epoch: 5| Step: 10
Training loss: 0.4469332396963423
Validation loss: 2.8345230260158116

Epoch: 5| Step: 11
Training loss: 0.2776840164306065
Validation loss: 2.836370083102295

Epoch: 421| Step: 0
Training loss: 0.3505488511555424
Validation loss: 2.8763233055666135

Epoch: 5| Step: 1
Training loss: 0.41175047446399027
Validation loss: 2.819336208814329

Epoch: 5| Step: 2
Training loss: 0.4890420403634161
Validation loss: 2.8936127489358414

Epoch: 5| Step: 3
Training loss: 0.5797360114597383
Validation loss: 2.8062963661719036

Epoch: 5| Step: 4
Training loss: 0.6224027311403054
Validation loss: 2.9024989453285617

Epoch: 5| Step: 5
Training loss: 0.31246863446184403
Validation loss: 2.819590232135655

Epoch: 5| Step: 6
Training loss: 0.46728786678983
Validation loss: 2.781631393570865

Epoch: 5| Step: 7
Training loss: 0.4621045322761014
Validation loss: 2.8160268816416703

Epoch: 5| Step: 8
Training loss: 0.5354726649537243
Validation loss: 2.7935907698277798

Epoch: 5| Step: 9
Training loss: 0.361711659372259
Validation loss: 2.790244278633635

Epoch: 5| Step: 10
Training loss: 0.5009330448040569
Validation loss: 2.768234139285761

Epoch: 5| Step: 11
Training loss: 0.1539620315331705
Validation loss: 2.776984329681498

Epoch: 422| Step: 0
Training loss: 0.398046413791977
Validation loss: 2.762708814706414

Epoch: 5| Step: 1
Training loss: 0.34291959292985236
Validation loss: 2.8272337519061055

Epoch: 5| Step: 2
Training loss: 0.326742313015127
Validation loss: 2.8194518004375224

Epoch: 5| Step: 3
Training loss: 0.4443115563043888
Validation loss: 2.7973140499812064

Epoch: 5| Step: 4
Training loss: 0.4198814550064292
Validation loss: 2.7989073567113274

Epoch: 5| Step: 5
Training loss: 0.4218908412926155
Validation loss: 2.801461041966607

Epoch: 5| Step: 6
Training loss: 0.3900784101586395
Validation loss: 2.773176238241696

Epoch: 5| Step: 7
Training loss: 0.2890106747538398
Validation loss: 2.7992699774127807

Epoch: 5| Step: 8
Training loss: 0.3797489116595345
Validation loss: 2.70179895719759

Epoch: 5| Step: 9
Training loss: 0.5749988576628906
Validation loss: 2.7777950458519696

Epoch: 5| Step: 10
Training loss: 0.44635558519468127
Validation loss: 2.7866581830286483

Epoch: 5| Step: 11
Training loss: 0.5581061629376971
Validation loss: 2.7460374785690567

Epoch: 423| Step: 0
Training loss: 0.5049117650007499
Validation loss: 2.819685372241136

Epoch: 5| Step: 1
Training loss: 0.32584341723032806
Validation loss: 2.7856999134617535

Epoch: 5| Step: 2
Training loss: 0.47859922963242596
Validation loss: 2.740427928930612

Epoch: 5| Step: 3
Training loss: 0.4329282103288468
Validation loss: 2.741102824645946

Epoch: 5| Step: 4
Training loss: 0.3901234840564065
Validation loss: 2.823884088536254

Epoch: 5| Step: 5
Training loss: 0.42202545944472686
Validation loss: 2.802320652286858

Epoch: 5| Step: 6
Training loss: 0.3960670943761983
Validation loss: 2.792881940724151

Epoch: 5| Step: 7
Training loss: 0.35967120112950896
Validation loss: 2.834908900504431

Epoch: 5| Step: 8
Training loss: 0.4559168147727927
Validation loss: 2.8273299032158414

Epoch: 5| Step: 9
Training loss: 0.4812664605087578
Validation loss: 2.8117515486443345

Epoch: 5| Step: 10
Training loss: 0.35642119025558083
Validation loss: 2.7448286395445005

Epoch: 5| Step: 11
Training loss: 0.24524378451949344
Validation loss: 2.840447649789333

Epoch: 424| Step: 0
Training loss: 0.317451845144238
Validation loss: 2.8181779414883943

Epoch: 5| Step: 1
Training loss: 0.34807373011770504
Validation loss: 2.7837177287188064

Epoch: 5| Step: 2
Training loss: 0.32383804490157725
Validation loss: 2.7723482885493596

Epoch: 5| Step: 3
Training loss: 0.5536581347281048
Validation loss: 2.7490088381698627

Epoch: 5| Step: 4
Training loss: 0.3498066393586383
Validation loss: 2.731560190162952

Epoch: 5| Step: 5
Training loss: 0.3951568741980133
Validation loss: 2.8026157190103334

Epoch: 5| Step: 6
Training loss: 0.40927592672996094
Validation loss: 2.8185714708844105

Epoch: 5| Step: 7
Training loss: 0.37320120849500593
Validation loss: 2.7937170524560293

Epoch: 5| Step: 8
Training loss: 0.34545099363756965
Validation loss: 2.7903609507945464

Epoch: 5| Step: 9
Training loss: 0.3987445583091779
Validation loss: 2.7786236589018296

Epoch: 5| Step: 10
Training loss: 0.3801738928084821
Validation loss: 2.858534899704688

Epoch: 5| Step: 11
Training loss: 0.292655994050606
Validation loss: 2.8076330742870272

Epoch: 425| Step: 0
Training loss: 0.44391603855833134
Validation loss: 2.837098468120706

Epoch: 5| Step: 1
Training loss: 0.49620182632289317
Validation loss: 2.810838116508762

Epoch: 5| Step: 2
Training loss: 0.4030089758460286
Validation loss: 2.8851426277903003

Epoch: 5| Step: 3
Training loss: 0.43654091477876267
Validation loss: 2.7724124930640444

Epoch: 5| Step: 4
Training loss: 0.29413170465365446
Validation loss: 2.8144714157212554

Epoch: 5| Step: 5
Training loss: 0.3252037207630485
Validation loss: 2.7533119768899277

Epoch: 5| Step: 6
Training loss: 0.51196032929587
Validation loss: 2.8380064900167006

Epoch: 5| Step: 7
Training loss: 0.36038611021589934
Validation loss: 2.791428727832526

Epoch: 5| Step: 8
Training loss: 0.41229175310614274
Validation loss: 2.8195965986323586

Epoch: 5| Step: 9
Training loss: 0.3719408105271163
Validation loss: 2.821235181752373

Epoch: 5| Step: 10
Training loss: 0.3280570323122899
Validation loss: 2.8359555680861495

Epoch: 5| Step: 11
Training loss: 0.24494011246771685
Validation loss: 2.8077012519966966

Epoch: 426| Step: 0
Training loss: 0.38578232182183514
Validation loss: 2.8288022138513735

Epoch: 5| Step: 1
Training loss: 0.4108351583646638
Validation loss: 2.761003019328702

Epoch: 5| Step: 2
Training loss: 0.3833333189936649
Validation loss: 2.7803152813904135

Epoch: 5| Step: 3
Training loss: 0.44686288483742986
Validation loss: 2.7901059183743415

Epoch: 5| Step: 4
Training loss: 0.4620608848482662
Validation loss: 2.7719499780720493

Epoch: 5| Step: 5
Training loss: 0.5215329208351831
Validation loss: 2.8410635649847515

Epoch: 5| Step: 6
Training loss: 0.4948760880845902
Validation loss: 2.8042472876418065

Epoch: 5| Step: 7
Training loss: 0.3936013508812762
Validation loss: 2.8036562441375628

Epoch: 5| Step: 8
Training loss: 0.4705185587706055
Validation loss: 2.8229679171049527

Epoch: 5| Step: 9
Training loss: 0.2347787399564015
Validation loss: 2.771881444264819

Epoch: 5| Step: 10
Training loss: 0.30245959209077383
Validation loss: 2.818335032737967

Epoch: 5| Step: 11
Training loss: 0.2134792170660573
Validation loss: 2.755593571595075

Epoch: 427| Step: 0
Training loss: 0.3598896777799257
Validation loss: 2.783244360902721

Epoch: 5| Step: 1
Training loss: 0.41302379744990614
Validation loss: 2.7851251223243834

Epoch: 5| Step: 2
Training loss: 0.4650015202620481
Validation loss: 2.7799284970798617

Epoch: 5| Step: 3
Training loss: 0.4402253211781989
Validation loss: 2.777645164476638

Epoch: 5| Step: 4
Training loss: 0.316816499621998
Validation loss: 2.7952821767238034

Epoch: 5| Step: 5
Training loss: 0.5756771226410844
Validation loss: 2.782096426819064

Epoch: 5| Step: 6
Training loss: 0.37536587350721623
Validation loss: 2.792671045473921

Epoch: 5| Step: 7
Training loss: 0.4037865629263647
Validation loss: 2.895387180639537

Epoch: 5| Step: 8
Training loss: 0.38766629281002746
Validation loss: 2.792347513035192

Epoch: 5| Step: 9
Training loss: 0.29910188489330863
Validation loss: 2.812383818875845

Epoch: 5| Step: 10
Training loss: 0.33901344463039135
Validation loss: 2.805514115530049

Epoch: 5| Step: 11
Training loss: 0.21373166184091041
Validation loss: 2.7757715209481226

Epoch: 428| Step: 0
Training loss: 0.5138760005205344
Validation loss: 2.8001406906748887

Epoch: 5| Step: 1
Training loss: 0.361443372338032
Validation loss: 2.747915276090103

Epoch: 5| Step: 2
Training loss: 0.43697883013355027
Validation loss: 2.8117607699348763

Epoch: 5| Step: 3
Training loss: 0.4427722622957186
Validation loss: 2.842798353265314

Epoch: 5| Step: 4
Training loss: 0.31357235499576297
Validation loss: 2.814186685389455

Epoch: 5| Step: 5
Training loss: 0.281163228742825
Validation loss: 2.8006651502706696

Epoch: 5| Step: 6
Training loss: 0.380439409381856
Validation loss: 2.8819638582262574

Epoch: 5| Step: 7
Training loss: 0.4625895684090683
Validation loss: 2.867546703487092

Epoch: 5| Step: 8
Training loss: 0.31483168945687734
Validation loss: 2.774069704166254

Epoch: 5| Step: 9
Training loss: 0.47599200199023467
Validation loss: 2.811527988456213

Epoch: 5| Step: 10
Training loss: 0.49982742967401905
Validation loss: 2.886831006941805

Epoch: 5| Step: 11
Training loss: 0.2746034694812598
Validation loss: 2.8159539630693553

Epoch: 429| Step: 0
Training loss: 0.3757880989449843
Validation loss: 2.852645062361294

Epoch: 5| Step: 1
Training loss: 0.4193494043910667
Validation loss: 2.826138232350988

Epoch: 5| Step: 2
Training loss: 0.2909365296885436
Validation loss: 2.8387810993996676

Epoch: 5| Step: 3
Training loss: 0.38083272987473726
Validation loss: 2.8670530261693434

Epoch: 5| Step: 4
Training loss: 0.381865127111196
Validation loss: 2.828272887660947

Epoch: 5| Step: 5
Training loss: 0.4812394605448577
Validation loss: 2.8459991042827593

Epoch: 5| Step: 6
Training loss: 0.3352887520819662
Validation loss: 2.797105360578473

Epoch: 5| Step: 7
Training loss: 0.5070476641003906
Validation loss: 2.7739644870744713

Epoch: 5| Step: 8
Training loss: 0.33822495121977725
Validation loss: 2.825589678697638

Epoch: 5| Step: 9
Training loss: 0.3168071514678305
Validation loss: 2.8431243662408234

Epoch: 5| Step: 10
Training loss: 0.29428418165781994
Validation loss: 2.8026184766955025

Epoch: 5| Step: 11
Training loss: 0.740348022111116
Validation loss: 2.824615647605276

Epoch: 430| Step: 0
Training loss: 0.39060054702515395
Validation loss: 2.76421413965279

Epoch: 5| Step: 1
Training loss: 0.3430777500360932
Validation loss: 2.8117845296341857

Epoch: 5| Step: 2
Training loss: 0.41465346431694866
Validation loss: 2.8052539235766316

Epoch: 5| Step: 3
Training loss: 0.2628617167343304
Validation loss: 2.783221949463478

Epoch: 5| Step: 4
Training loss: 0.3162707756968315
Validation loss: 2.8426793619182016

Epoch: 5| Step: 5
Training loss: 0.41230579414020385
Validation loss: 2.852509276101679

Epoch: 5| Step: 6
Training loss: 0.4045693405447608
Validation loss: 2.784175593153379

Epoch: 5| Step: 7
Training loss: 0.5047035120263453
Validation loss: 2.804353759659116

Epoch: 5| Step: 8
Training loss: 0.40650458794992433
Validation loss: 2.79356126880295

Epoch: 5| Step: 9
Training loss: 0.4833870934590649
Validation loss: 2.838030744061475

Epoch: 5| Step: 10
Training loss: 0.4473349671562582
Validation loss: 2.8106680519856413

Epoch: 5| Step: 11
Training loss: 0.6367265197654289
Validation loss: 2.833439128433926

Epoch: 431| Step: 0
Training loss: 0.3273467530360893
Validation loss: 2.8385521681471753

Epoch: 5| Step: 1
Training loss: 0.40895549668571834
Validation loss: 2.7680473782314956

Epoch: 5| Step: 2
Training loss: 0.43315814019447074
Validation loss: 2.772882242989812

Epoch: 5| Step: 3
Training loss: 0.4696688229926709
Validation loss: 2.7228496962593054

Epoch: 5| Step: 4
Training loss: 0.3281112622609558
Validation loss: 2.7974842196540193

Epoch: 5| Step: 5
Training loss: 0.3083699779171142
Validation loss: 2.8075131675137412

Epoch: 5| Step: 6
Training loss: 0.34416551835505105
Validation loss: 2.7351683528385036

Epoch: 5| Step: 7
Training loss: 0.32051392944003493
Validation loss: 2.8054160515143236

Epoch: 5| Step: 8
Training loss: 0.2703655846791006
Validation loss: 2.8258808814847978

Epoch: 5| Step: 9
Training loss: 0.42150914258193617
Validation loss: 2.8062278321883776

Epoch: 5| Step: 10
Training loss: 0.5704390241766193
Validation loss: 2.8046257557709326

Epoch: 5| Step: 11
Training loss: 0.25998226969584276
Validation loss: 2.7584107158117246

Epoch: 432| Step: 0
Training loss: 0.44992143157020387
Validation loss: 2.835009399378297

Epoch: 5| Step: 1
Training loss: 0.32643628396310415
Validation loss: 2.7818224207133633

Epoch: 5| Step: 2
Training loss: 0.39536686022179957
Validation loss: 2.795594065917416

Epoch: 5| Step: 3
Training loss: 0.26502596401830564
Validation loss: 2.817556755562754

Epoch: 5| Step: 4
Training loss: 0.4129466730654667
Validation loss: 2.803084539676431

Epoch: 5| Step: 5
Training loss: 0.3296907736629288
Validation loss: 2.8004859225936327

Epoch: 5| Step: 6
Training loss: 0.4316735923916019
Validation loss: 2.7810067023969585

Epoch: 5| Step: 7
Training loss: 0.39403062160580093
Validation loss: 2.818823783399419

Epoch: 5| Step: 8
Training loss: 0.35261581303996414
Validation loss: 2.7876299857721962

Epoch: 5| Step: 9
Training loss: 0.29629179488690577
Validation loss: 2.7512771140736434

Epoch: 5| Step: 10
Training loss: 0.32647670275858076
Validation loss: 2.757217660066153

Epoch: 5| Step: 11
Training loss: 0.5017003116646996
Validation loss: 2.767465894707768

Epoch: 433| Step: 0
Training loss: 0.4535304426061067
Validation loss: 2.787441911933204

Epoch: 5| Step: 1
Training loss: 0.32661851694525074
Validation loss: 2.802481096012811

Epoch: 5| Step: 2
Training loss: 0.40438491673521876
Validation loss: 2.727573098183045

Epoch: 5| Step: 3
Training loss: 0.39148771386215764
Validation loss: 2.778383717542515

Epoch: 5| Step: 4
Training loss: 0.34311016095841557
Validation loss: 2.7798730534904172

Epoch: 5| Step: 5
Training loss: 0.38431441287018925
Validation loss: 2.836566277358879

Epoch: 5| Step: 6
Training loss: 0.3643866303552385
Validation loss: 2.8010640269831977

Epoch: 5| Step: 7
Training loss: 0.26792336905437664
Validation loss: 2.8348700561043

Epoch: 5| Step: 8
Training loss: 0.479678861558898
Validation loss: 2.774137661091764

Epoch: 5| Step: 9
Training loss: 0.310604977720379
Validation loss: 2.794426041221333

Epoch: 5| Step: 10
Training loss: 0.42731652251544844
Validation loss: 2.8803388670624

Epoch: 5| Step: 11
Training loss: 0.6434238746612179
Validation loss: 2.84572373877787

Epoch: 434| Step: 0
Training loss: 0.34446312886153807
Validation loss: 2.8328836355309597

Epoch: 5| Step: 1
Training loss: 0.39473175392719695
Validation loss: 2.7784234446249187

Epoch: 5| Step: 2
Training loss: 0.34205655723621686
Validation loss: 2.7190652277227336

Epoch: 5| Step: 3
Training loss: 0.29460786688071394
Validation loss: 2.8004416025276866

Epoch: 5| Step: 4
Training loss: 0.36655798171853127
Validation loss: 2.8623719690667406

Epoch: 5| Step: 5
Training loss: 0.3600262049237158
Validation loss: 2.8186158547971845

Epoch: 5| Step: 6
Training loss: 0.45959701233557587
Validation loss: 2.8355940618712747

Epoch: 5| Step: 7
Training loss: 0.3512275583761485
Validation loss: 2.8214060177168903

Epoch: 5| Step: 8
Training loss: 0.33273169741031267
Validation loss: 2.7711795158008807

Epoch: 5| Step: 9
Training loss: 0.41204461045315743
Validation loss: 2.7940400956525653

Epoch: 5| Step: 10
Training loss: 0.2165978437402015
Validation loss: 2.7715106843681285

Epoch: 5| Step: 11
Training loss: 0.2689274229971598
Validation loss: 2.829345390637342

Epoch: 435| Step: 0
Training loss: 0.44073281355686167
Validation loss: 2.8258928760111597

Epoch: 5| Step: 1
Training loss: 0.40793871187147257
Validation loss: 2.7738365351922756

Epoch: 5| Step: 2
Training loss: 0.3561035817401364
Validation loss: 2.7840957620032296

Epoch: 5| Step: 3
Training loss: 0.30388443826888334
Validation loss: 2.8038357616431355

Epoch: 5| Step: 4
Training loss: 0.38384327978726335
Validation loss: 2.778610201854159

Epoch: 5| Step: 5
Training loss: 0.3778471942934241
Validation loss: 2.815004522846218

Epoch: 5| Step: 6
Training loss: 0.45649247323732484
Validation loss: 2.7128560206140406

Epoch: 5| Step: 7
Training loss: 0.51090268591001
Validation loss: 2.858144808178599

Epoch: 5| Step: 8
Training loss: 0.2239445258844874
Validation loss: 2.8343011708371915

Epoch: 5| Step: 9
Training loss: 0.3371576506702004
Validation loss: 2.7696775855971176

Epoch: 5| Step: 10
Training loss: 0.28857037175384964
Validation loss: 2.8038911264400888

Epoch: 5| Step: 11
Training loss: 0.3593326626593277
Validation loss: 2.846150541336668

Epoch: 436| Step: 0
Training loss: 0.2846931852030555
Validation loss: 2.7904930755656

Epoch: 5| Step: 1
Training loss: 0.42681418249547437
Validation loss: 2.74954865104012

Epoch: 5| Step: 2
Training loss: 0.3606568157501318
Validation loss: 2.7880495869615713

Epoch: 5| Step: 3
Training loss: 0.5575670530426012
Validation loss: 2.8173188923460986

Epoch: 5| Step: 4
Training loss: 0.41422637359729375
Validation loss: 2.783834363951994

Epoch: 5| Step: 5
Training loss: 0.35535978386795103
Validation loss: 2.7916088572727342

Epoch: 5| Step: 6
Training loss: 0.44403303951976975
Validation loss: 2.816000279105057

Epoch: 5| Step: 7
Training loss: 0.38667680532150295
Validation loss: 2.795013895392638

Epoch: 5| Step: 8
Training loss: 0.4274400543268206
Validation loss: 2.8269924509502937

Epoch: 5| Step: 9
Training loss: 0.39807581847794943
Validation loss: 2.808126761812809

Epoch: 5| Step: 10
Training loss: 0.3292914275853482
Validation loss: 2.7929094677304533

Epoch: 5| Step: 11
Training loss: 0.26507750353977827
Validation loss: 2.8557749947996345

Epoch: 437| Step: 0
Training loss: 0.48272605912293237
Validation loss: 2.764637654098309

Epoch: 5| Step: 1
Training loss: 0.3870724688354509
Validation loss: 2.8099733907032496

Epoch: 5| Step: 2
Training loss: 0.3611755873918196
Validation loss: 2.809645321944903

Epoch: 5| Step: 3
Training loss: 0.37352973086337743
Validation loss: 2.7726655199102495

Epoch: 5| Step: 4
Training loss: 0.5410899032116754
Validation loss: 2.7563632150351123

Epoch: 5| Step: 5
Training loss: 0.3912568323008042
Validation loss: 2.797925481879426

Epoch: 5| Step: 6
Training loss: 0.33852736614051987
Validation loss: 2.881123945081184

Epoch: 5| Step: 7
Training loss: 0.47850959929740033
Validation loss: 2.8183854618041604

Epoch: 5| Step: 8
Training loss: 0.6090768427013902
Validation loss: 2.8439508024870537

Epoch: 5| Step: 9
Training loss: 0.38865458387701896
Validation loss: 2.8100665691405067

Epoch: 5| Step: 10
Training loss: 0.3289889587285938
Validation loss: 2.8185138408922654

Epoch: 5| Step: 11
Training loss: 0.403757260437396
Validation loss: 2.7207072728753676

Epoch: 438| Step: 0
Training loss: 0.3784069231943917
Validation loss: 2.776114845146347

Epoch: 5| Step: 1
Training loss: 0.45526124274287966
Validation loss: 2.7677127443756304

Epoch: 5| Step: 2
Training loss: 0.48452940910060993
Validation loss: 2.7684643353358207

Epoch: 5| Step: 3
Training loss: 0.5388684960266795
Validation loss: 2.7993879661194483

Epoch: 5| Step: 4
Training loss: 0.42420656035668225
Validation loss: 2.795810699418649

Epoch: 5| Step: 5
Training loss: 0.3575094147089413
Validation loss: 2.7731983636908932

Epoch: 5| Step: 6
Training loss: 0.38095338101411863
Validation loss: 2.8204662495952593

Epoch: 5| Step: 7
Training loss: 0.4735418959987816
Validation loss: 2.830443010135072

Epoch: 5| Step: 8
Training loss: 0.5470832428226362
Validation loss: 2.843857773635466

Epoch: 5| Step: 9
Training loss: 0.3943096331608401
Validation loss: 2.7700554656937864

Epoch: 5| Step: 10
Training loss: 0.39831612178030396
Validation loss: 2.7520126975266983

Epoch: 5| Step: 11
Training loss: 0.3171537423609325
Validation loss: 2.7685727216973075

Epoch: 439| Step: 0
Training loss: 0.3733374377788556
Validation loss: 2.7528443654237265

Epoch: 5| Step: 1
Training loss: 0.45601982293836196
Validation loss: 2.768021947521966

Epoch: 5| Step: 2
Training loss: 0.2596377151040616
Validation loss: 2.777359234086666

Epoch: 5| Step: 3
Training loss: 0.4073767442294269
Validation loss: 2.81574206869187

Epoch: 5| Step: 4
Training loss: 0.4357117310963903
Validation loss: 2.77770852055572

Epoch: 5| Step: 5
Training loss: 0.39075843439377395
Validation loss: 2.790252168247882

Epoch: 5| Step: 6
Training loss: 0.38477186013993414
Validation loss: 2.781194875649504

Epoch: 5| Step: 7
Training loss: 0.42752514254937535
Validation loss: 2.823332243355815

Epoch: 5| Step: 8
Training loss: 0.389533348582797
Validation loss: 2.8411104402281073

Epoch: 5| Step: 9
Training loss: 0.46633014729004285
Validation loss: 2.8142653646850277

Epoch: 5| Step: 10
Training loss: 0.3373570059804038
Validation loss: 2.8221095832885386

Epoch: 5| Step: 11
Training loss: 0.45358085721753616
Validation loss: 2.8343339700473447

Epoch: 440| Step: 0
Training loss: 0.3857690536221196
Validation loss: 2.7847313826598716

Epoch: 5| Step: 1
Training loss: 0.401855357507294
Validation loss: 2.7684833461354037

Epoch: 5| Step: 2
Training loss: 0.36322416862037143
Validation loss: 2.8604847434311096

Epoch: 5| Step: 3
Training loss: 0.4574108340708733
Validation loss: 2.758065184200958

Epoch: 5| Step: 4
Training loss: 0.4415980740881384
Validation loss: 2.8153804933976265

Epoch: 5| Step: 5
Training loss: 0.3531477895489014
Validation loss: 2.7816861342893033

Epoch: 5| Step: 6
Training loss: 0.29966889328619123
Validation loss: 2.8228570267874655

Epoch: 5| Step: 7
Training loss: 0.37142369509799794
Validation loss: 2.803707642322439

Epoch: 5| Step: 8
Training loss: 0.31268093116565726
Validation loss: 2.8516493239749567

Epoch: 5| Step: 9
Training loss: 0.4164218441617978
Validation loss: 2.787272127100441

Epoch: 5| Step: 10
Training loss: 0.46067767174659646
Validation loss: 2.8219564653524354

Epoch: 5| Step: 11
Training loss: 0.2765043747160917
Validation loss: 2.7934652638537703

Epoch: 441| Step: 0
Training loss: 0.4038161584959696
Validation loss: 2.745178254546464

Epoch: 5| Step: 1
Training loss: 0.34980209196268336
Validation loss: 2.7922614244531374

Epoch: 5| Step: 2
Training loss: 0.3812474938607315
Validation loss: 2.8082726020406037

Epoch: 5| Step: 3
Training loss: 0.3945375574193175
Validation loss: 2.8254150839615857

Epoch: 5| Step: 4
Training loss: 0.39792152729694036
Validation loss: 2.7953830625506515

Epoch: 5| Step: 5
Training loss: 0.4081437282150013
Validation loss: 2.8454264146491948

Epoch: 5| Step: 6
Training loss: 0.36341414533182365
Validation loss: 2.784099344436568

Epoch: 5| Step: 7
Training loss: 0.5493075086084951
Validation loss: 2.838475044005271

Epoch: 5| Step: 8
Training loss: 0.34569249971947186
Validation loss: 2.7525001778113145

Epoch: 5| Step: 9
Training loss: 0.47915395084039225
Validation loss: 2.81750199249319

Epoch: 5| Step: 10
Training loss: 0.3940092542706387
Validation loss: 2.8297556185935764

Epoch: 5| Step: 11
Training loss: 0.35267297415232274
Validation loss: 2.799062896060692

Epoch: 442| Step: 0
Training loss: 0.4617170595244623
Validation loss: 2.886086731559807

Epoch: 5| Step: 1
Training loss: 0.32311434104722847
Validation loss: 2.7406059914034477

Epoch: 5| Step: 2
Training loss: 0.3507594473505218
Validation loss: 2.8198275303236326

Epoch: 5| Step: 3
Training loss: 0.4052730330499676
Validation loss: 2.771506999637877

Epoch: 5| Step: 4
Training loss: 0.3633437564358047
Validation loss: 2.783024204147069

Epoch: 5| Step: 5
Training loss: 0.3159083463686246
Validation loss: 2.809193150593423

Epoch: 5| Step: 6
Training loss: 0.36459290174008097
Validation loss: 2.852404361283916

Epoch: 5| Step: 7
Training loss: 0.3484351829485981
Validation loss: 2.828763134586342

Epoch: 5| Step: 8
Training loss: 0.29180001151200574
Validation loss: 2.7984505518714156

Epoch: 5| Step: 9
Training loss: 0.43258382698753045
Validation loss: 2.7614860148836944

Epoch: 5| Step: 10
Training loss: 0.3667374754758346
Validation loss: 2.818165290196513

Epoch: 5| Step: 11
Training loss: 0.23095821678712222
Validation loss: 2.825703689119655

Epoch: 443| Step: 0
Training loss: 0.3375570271137869
Validation loss: 2.8147081713564854

Epoch: 5| Step: 1
Training loss: 0.2806492057589926
Validation loss: 2.782673899879325

Epoch: 5| Step: 2
Training loss: 0.3804818262755283
Validation loss: 2.7657155921883265

Epoch: 5| Step: 3
Training loss: 0.39739506056057583
Validation loss: 2.759735607605805

Epoch: 5| Step: 4
Training loss: 0.27132906690895914
Validation loss: 2.812796241558717

Epoch: 5| Step: 5
Training loss: 0.3621900022221151
Validation loss: 2.7906068930157732

Epoch: 5| Step: 6
Training loss: 0.31541677867823587
Validation loss: 2.797033838205156

Epoch: 5| Step: 7
Training loss: 0.3630138972133787
Validation loss: 2.7677585647976986

Epoch: 5| Step: 8
Training loss: 0.4356535024089076
Validation loss: 2.8192444290868783

Epoch: 5| Step: 9
Training loss: 0.4862160917486856
Validation loss: 2.812386701209146

Epoch: 5| Step: 10
Training loss: 0.3879442544763649
Validation loss: 2.827792160371912

Epoch: 5| Step: 11
Training loss: 0.6605171255567008
Validation loss: 2.8385800396953216

Epoch: 444| Step: 0
Training loss: 0.401962877753953
Validation loss: 2.7463220652433096

Epoch: 5| Step: 1
Training loss: 0.49220292506191643
Validation loss: 2.775040210899354

Epoch: 5| Step: 2
Training loss: 0.40914942372279284
Validation loss: 2.8280757984075575

Epoch: 5| Step: 3
Training loss: 0.38834720258681377
Validation loss: 2.7598524968611353

Epoch: 5| Step: 4
Training loss: 0.41357839823190695
Validation loss: 2.7865409850699963

Epoch: 5| Step: 5
Training loss: 0.30868059457383673
Validation loss: 2.8329011725441373

Epoch: 5| Step: 6
Training loss: 0.39592560729943527
Validation loss: 2.7897478039958465

Epoch: 5| Step: 7
Training loss: 0.39051332784857834
Validation loss: 2.847016892873341

Epoch: 5| Step: 8
Training loss: 0.32350920974130126
Validation loss: 2.7837953207411834

Epoch: 5| Step: 9
Training loss: 0.37230754908429664
Validation loss: 2.785892059446243

Epoch: 5| Step: 10
Training loss: 0.5191622979983996
Validation loss: 2.8161314866862455

Epoch: 5| Step: 11
Training loss: 0.22430627523486565
Validation loss: 2.8094245060458016

Epoch: 445| Step: 0
Training loss: 0.27209684868280665
Validation loss: 2.783018410782725

Epoch: 5| Step: 1
Training loss: 0.3086112053678636
Validation loss: 2.831120778321518

Epoch: 5| Step: 2
Training loss: 0.3670385951593793
Validation loss: 2.8144646246606992

Epoch: 5| Step: 3
Training loss: 0.4546334218117536
Validation loss: 2.8417668990993583

Epoch: 5| Step: 4
Training loss: 0.3017891432413369
Validation loss: 2.7691810146131894

Epoch: 5| Step: 5
Training loss: 0.38081492629249475
Validation loss: 2.808245605905883

Epoch: 5| Step: 6
Training loss: 0.4268521830882432
Validation loss: 2.8192829355689186

Epoch: 5| Step: 7
Training loss: 0.5211514042153647
Validation loss: 2.8183917393790088

Epoch: 5| Step: 8
Training loss: 0.4843227758249109
Validation loss: 2.774097489464394

Epoch: 5| Step: 9
Training loss: 0.4459086827602026
Validation loss: 2.863739237255184

Epoch: 5| Step: 10
Training loss: 0.28358475852142606
Validation loss: 2.867060669771206

Epoch: 5| Step: 11
Training loss: 0.43521047011246977
Validation loss: 2.7639402980325767

Epoch: 446| Step: 0
Training loss: 0.37297804432136705
Validation loss: 2.74716063422273

Epoch: 5| Step: 1
Training loss: 0.3502328630219464
Validation loss: 2.88144706292139

Epoch: 5| Step: 2
Training loss: 0.4784667943835149
Validation loss: 2.7247678211587325

Epoch: 5| Step: 3
Training loss: 0.4397302728492859
Validation loss: 2.7728878533241805

Epoch: 5| Step: 4
Training loss: 0.34860297751257596
Validation loss: 2.81684113071287

Epoch: 5| Step: 5
Training loss: 0.262216308543287
Validation loss: 2.859022045760336

Epoch: 5| Step: 6
Training loss: 0.3079357979814347
Validation loss: 2.795206318049204

Epoch: 5| Step: 7
Training loss: 0.4089497031423338
Validation loss: 2.851546972920546

Epoch: 5| Step: 8
Training loss: 0.45062986241652364
Validation loss: 2.8157010758622723

Epoch: 5| Step: 9
Training loss: 0.5285858784269071
Validation loss: 2.88836011048914

Epoch: 5| Step: 10
Training loss: 0.5358228777769591
Validation loss: 2.7892755877590854

Epoch: 5| Step: 11
Training loss: 0.23410213003817004
Validation loss: 2.7153635748608944

Epoch: 447| Step: 0
Training loss: 0.315303930954425
Validation loss: 2.7967341083863837

Epoch: 5| Step: 1
Training loss: 0.47998146220014176
Validation loss: 2.8265309275980828

Epoch: 5| Step: 2
Training loss: 0.33925720548602906
Validation loss: 2.8039264018178813

Epoch: 5| Step: 3
Training loss: 0.442181573026046
Validation loss: 2.813947329934716

Epoch: 5| Step: 4
Training loss: 0.458991338798776
Validation loss: 2.8144243968209537

Epoch: 5| Step: 5
Training loss: 0.4256401178081024
Validation loss: 2.7380632412587924

Epoch: 5| Step: 6
Training loss: 0.4073304883044095
Validation loss: 2.8440529658423883

Epoch: 5| Step: 7
Training loss: 0.45976168777478293
Validation loss: 2.82696896665839

Epoch: 5| Step: 8
Training loss: 0.3262579912726998
Validation loss: 2.829997238572327

Epoch: 5| Step: 9
Training loss: 0.37505169353227347
Validation loss: 2.873156889696376

Epoch: 5| Step: 10
Training loss: 0.3172921153837869
Validation loss: 2.8186578132176217

Epoch: 5| Step: 11
Training loss: 0.335529345586303
Validation loss: 2.7735826266290657

Epoch: 448| Step: 0
Training loss: 0.20316323507353534
Validation loss: 2.8409276307974918

Epoch: 5| Step: 1
Training loss: 0.3775491499009563
Validation loss: 2.842871645584412

Epoch: 5| Step: 2
Training loss: 0.4616430346377162
Validation loss: 2.7838878195393546

Epoch: 5| Step: 3
Training loss: 0.4734506000934778
Validation loss: 2.830482799731363

Epoch: 5| Step: 4
Training loss: 0.39361683470784387
Validation loss: 2.80307935126824

Epoch: 5| Step: 5
Training loss: 0.34811282448219794
Validation loss: 2.7756865466906895

Epoch: 5| Step: 6
Training loss: 0.337479236193652
Validation loss: 2.771030638895351

Epoch: 5| Step: 7
Training loss: 0.3318587808902289
Validation loss: 2.843695790259709

Epoch: 5| Step: 8
Training loss: 0.38027553312863516
Validation loss: 2.797809849506351

Epoch: 5| Step: 9
Training loss: 0.3542591095872344
Validation loss: 2.7934512879720956

Epoch: 5| Step: 10
Training loss: 0.35401101993121953
Validation loss: 2.8381124901119565

Epoch: 5| Step: 11
Training loss: 0.18539277755059938
Validation loss: 2.8439020982526904

Epoch: 449| Step: 0
Training loss: 0.3194431859777144
Validation loss: 2.8042071966347497

Epoch: 5| Step: 1
Training loss: 0.37379464504790416
Validation loss: 2.7914390589795515

Epoch: 5| Step: 2
Training loss: 0.3823820925351285
Validation loss: 2.8373493011721127

Epoch: 5| Step: 3
Training loss: 0.344595216794506
Validation loss: 2.8660403147249185

Epoch: 5| Step: 4
Training loss: 0.47866591604093356
Validation loss: 2.879808244055648

Epoch: 5| Step: 5
Training loss: 0.5212533846409089
Validation loss: 2.8057898371408343

Epoch: 5| Step: 6
Training loss: 0.3465002858358913
Validation loss: 2.7577292886343066

Epoch: 5| Step: 7
Training loss: 0.23349301165848427
Validation loss: 2.8702867165177346

Epoch: 5| Step: 8
Training loss: 0.41503552603617405
Validation loss: 2.7794807535886634

Epoch: 5| Step: 9
Training loss: 0.3393849751111218
Validation loss: 2.7621412911700087

Epoch: 5| Step: 10
Training loss: 0.34600874758974337
Validation loss: 2.757971635645194

Epoch: 5| Step: 11
Training loss: 0.4024297011334083
Validation loss: 2.776104750402553

Epoch: 450| Step: 0
Training loss: 0.23905211189239153
Validation loss: 2.8288691965910893

Epoch: 5| Step: 1
Training loss: 0.4934019062861669
Validation loss: 2.8520111009819558

Epoch: 5| Step: 2
Training loss: 0.4648890913960876
Validation loss: 2.7619832589808953

Epoch: 5| Step: 3
Training loss: 0.34695047897638953
Validation loss: 2.827235579039857

Epoch: 5| Step: 4
Training loss: 0.37841830345877336
Validation loss: 2.857485311781367

Epoch: 5| Step: 5
Training loss: 0.3691178370309443
Validation loss: 2.856478845122353

Epoch: 5| Step: 6
Training loss: 0.42450301760577114
Validation loss: 2.876439383830169

Epoch: 5| Step: 7
Training loss: 0.2803734923087071
Validation loss: 2.7785243133218875

Epoch: 5| Step: 8
Training loss: 0.36919120159524715
Validation loss: 2.762315044569319

Epoch: 5| Step: 9
Training loss: 0.2919491382109239
Validation loss: 2.768948747061822

Epoch: 5| Step: 10
Training loss: 0.39252733499867354
Validation loss: 2.7581779302708633

Epoch: 5| Step: 11
Training loss: 0.19820775827684342
Validation loss: 2.74379386837821

Epoch: 451| Step: 0
Training loss: 0.43509438449906784
Validation loss: 2.798176262052027

Epoch: 5| Step: 1
Training loss: 0.3880476227628885
Validation loss: 2.765423864389072

Epoch: 5| Step: 2
Training loss: 0.26964482388595673
Validation loss: 2.84960049930033

Epoch: 5| Step: 3
Training loss: 0.2947728115068164
Validation loss: 2.809820474080179

Epoch: 5| Step: 4
Training loss: 0.4338587732822297
Validation loss: 2.8010418680648947

Epoch: 5| Step: 5
Training loss: 0.3812149735291912
Validation loss: 2.8126338891549976

Epoch: 5| Step: 6
Training loss: 0.39253462365383684
Validation loss: 2.7949275157346394

Epoch: 5| Step: 7
Training loss: 0.4103240078767145
Validation loss: 2.76362560938918

Epoch: 5| Step: 8
Training loss: 0.32439283500180593
Validation loss: 2.7618337784426226

Epoch: 5| Step: 9
Training loss: 0.30126937050096375
Validation loss: 2.7914167667151304

Epoch: 5| Step: 10
Training loss: 0.3255962500629538
Validation loss: 2.799182554396566

Epoch: 5| Step: 11
Training loss: 0.2732305288383879
Validation loss: 2.8407560839341817

Epoch: 452| Step: 0
Training loss: 0.38734493229275113
Validation loss: 2.86810104548535

Epoch: 5| Step: 1
Training loss: 0.38617253502000837
Validation loss: 2.772578852449169

Epoch: 5| Step: 2
Training loss: 0.35192347114782635
Validation loss: 2.779530264982046

Epoch: 5| Step: 3
Training loss: 0.34906169679527116
Validation loss: 2.802247632302044

Epoch: 5| Step: 4
Training loss: 0.4811555714050887
Validation loss: 2.7544402594496296

Epoch: 5| Step: 5
Training loss: 0.37708946094838286
Validation loss: 2.7360632888747842

Epoch: 5| Step: 6
Training loss: 0.37264781598477736
Validation loss: 2.7420266005505454

Epoch: 5| Step: 7
Training loss: 0.3400970589195408
Validation loss: 2.778810695821007

Epoch: 5| Step: 8
Training loss: 0.43772803902997853
Validation loss: 2.769246454844855

Epoch: 5| Step: 9
Training loss: 0.46635376077372587
Validation loss: 2.7890323598107556

Epoch: 5| Step: 10
Training loss: 0.43411668396708314
Validation loss: 2.7676963664236327

Epoch: 5| Step: 11
Training loss: 0.42510759800775
Validation loss: 2.8577301005168785

Epoch: 453| Step: 0
Training loss: 0.3923198742516057
Validation loss: 2.685583647505107

Epoch: 5| Step: 1
Training loss: 0.6146671647478735
Validation loss: 2.7681615407918736

Epoch: 5| Step: 2
Training loss: 0.3041296032746524
Validation loss: 2.7664338848892265

Epoch: 5| Step: 3
Training loss: 0.32333369270817625
Validation loss: 2.781447757162441

Epoch: 5| Step: 4
Training loss: 0.37684702986110724
Validation loss: 2.8055470211279037

Epoch: 5| Step: 5
Training loss: 0.29187863033168965
Validation loss: 2.7450989919715587

Epoch: 5| Step: 6
Training loss: 0.5030484253796821
Validation loss: 2.7238138365971416

Epoch: 5| Step: 7
Training loss: 0.3569032418722394
Validation loss: 2.769976061426048

Epoch: 5| Step: 8
Training loss: 0.4754169641750696
Validation loss: 2.848002288473541

Epoch: 5| Step: 9
Training loss: 0.301175317608544
Validation loss: 2.8181153225022277

Epoch: 5| Step: 10
Training loss: 0.4225491329832868
Validation loss: 2.8297774227745927

Epoch: 5| Step: 11
Training loss: 0.4547988951780342
Validation loss: 2.754572008250351

Epoch: 454| Step: 0
Training loss: 0.40352944777854416
Validation loss: 2.7959653806605593

Epoch: 5| Step: 1
Training loss: 0.29023556202046336
Validation loss: 2.7640268158536534

Epoch: 5| Step: 2
Training loss: 0.37338994014619875
Validation loss: 2.779186120577606

Epoch: 5| Step: 3
Training loss: 0.31897975878116275
Validation loss: 2.768030873060092

Epoch: 5| Step: 4
Training loss: 0.4090888348139088
Validation loss: 2.78542122599177

Epoch: 5| Step: 5
Training loss: 0.34154048567780215
Validation loss: 2.79308610505083

Epoch: 5| Step: 6
Training loss: 0.3870547405224635
Validation loss: 2.8319728906691273

Epoch: 5| Step: 7
Training loss: 0.42485021588370636
Validation loss: 2.7459433140433935

Epoch: 5| Step: 8
Training loss: 0.36550856309401714
Validation loss: 2.8024624221839156

Epoch: 5| Step: 9
Training loss: 0.45133305432528426
Validation loss: 2.8141488222462576

Epoch: 5| Step: 10
Training loss: 0.4812949450671848
Validation loss: 2.7603011784896636

Epoch: 5| Step: 11
Training loss: 0.5243609239873704
Validation loss: 2.776793474140694

Epoch: 455| Step: 0
Training loss: 0.44652422629500205
Validation loss: 2.7690706896864405

Epoch: 5| Step: 1
Training loss: 0.30561396764177934
Validation loss: 2.7728877207685185

Epoch: 5| Step: 2
Training loss: 0.30425831326369884
Validation loss: 2.853492724539764

Epoch: 5| Step: 3
Training loss: 0.2945502763264127
Validation loss: 2.7559956950124995

Epoch: 5| Step: 4
Training loss: 0.3881500037673268
Validation loss: 2.824697335242245

Epoch: 5| Step: 5
Training loss: 0.48911980911705843
Validation loss: 2.7412741644380314

Epoch: 5| Step: 6
Training loss: 0.4857977920812639
Validation loss: 2.805339786968662

Epoch: 5| Step: 7
Training loss: 0.4487460925482005
Validation loss: 2.8180359822061383

Epoch: 5| Step: 8
Training loss: 0.3945281717916832
Validation loss: 2.7896095686788267

Epoch: 5| Step: 9
Training loss: 0.45890315534400916
Validation loss: 2.794729063081948

Epoch: 5| Step: 10
Training loss: 0.3630248364629641
Validation loss: 2.83026756352876

Epoch: 5| Step: 11
Training loss: 0.4839554015224206
Validation loss: 2.7775564993037025

Epoch: 456| Step: 0
Training loss: 0.4065532102996913
Validation loss: 2.835096544576301

Epoch: 5| Step: 1
Training loss: 0.41831068508929153
Validation loss: 2.8097684806032457

Epoch: 5| Step: 2
Training loss: 0.4535099893329856
Validation loss: 2.8208212354016506

Epoch: 5| Step: 3
Training loss: 0.4994489494255398
Validation loss: 2.8023013251122135

Epoch: 5| Step: 4
Training loss: 0.3444923491368908
Validation loss: 2.752507612591483

Epoch: 5| Step: 5
Training loss: 0.38946106117296925
Validation loss: 2.7886442481690223

Epoch: 5| Step: 6
Training loss: 0.2184892445646137
Validation loss: 2.754440854535164

Epoch: 5| Step: 7
Training loss: 0.3383881318567283
Validation loss: 2.812025775489001

Epoch: 5| Step: 8
Training loss: 0.3773542651494321
Validation loss: 2.855435035043824

Epoch: 5| Step: 9
Training loss: 0.33075699601519876
Validation loss: 2.886810180840422

Epoch: 5| Step: 10
Training loss: 0.4254233229499684
Validation loss: 2.8070814706294978

Epoch: 5| Step: 11
Training loss: 0.6498482306899883
Validation loss: 2.8510398908411436

Epoch: 457| Step: 0
Training loss: 0.4543770887387211
Validation loss: 2.7910012115113463

Epoch: 5| Step: 1
Training loss: 0.5643486269410559
Validation loss: 2.83660419323502

Epoch: 5| Step: 2
Training loss: 0.419214086858554
Validation loss: 2.800057385486695

Epoch: 5| Step: 3
Training loss: 0.3333592168871529
Validation loss: 2.8381895961045442

Epoch: 5| Step: 4
Training loss: 0.41821128724654333
Validation loss: 2.7824191232896434

Epoch: 5| Step: 5
Training loss: 0.31843182260170977
Validation loss: 2.7740899012658597

Epoch: 5| Step: 6
Training loss: 0.4242474112479467
Validation loss: 2.7850058873032735

Epoch: 5| Step: 7
Training loss: 0.30473863955016756
Validation loss: 2.7913314786545276

Epoch: 5| Step: 8
Training loss: 0.49709481889011836
Validation loss: 2.765528355722002

Epoch: 5| Step: 9
Training loss: 0.4063818424203815
Validation loss: 2.7827548124405226

Epoch: 5| Step: 10
Training loss: 0.4268776836562241
Validation loss: 2.799598543445911

Epoch: 5| Step: 11
Training loss: 0.5975367358019574
Validation loss: 2.7534006146076138

Epoch: 458| Step: 0
Training loss: 0.4275015628518432
Validation loss: 2.8375478818889435

Epoch: 5| Step: 1
Training loss: 0.4037033368240877
Validation loss: 2.836028588883963

Epoch: 5| Step: 2
Training loss: 0.43109244495400323
Validation loss: 2.7542398074898893

Epoch: 5| Step: 3
Training loss: 0.43038900505587835
Validation loss: 2.780165978961042

Epoch: 5| Step: 4
Training loss: 0.4154121786211182
Validation loss: 2.7729872754510407

Epoch: 5| Step: 5
Training loss: 0.4117002942691814
Validation loss: 2.7082821413239446

Epoch: 5| Step: 6
Training loss: 0.2165660316487577
Validation loss: 2.819348971128975

Epoch: 5| Step: 7
Training loss: 0.419143203201257
Validation loss: 2.730970628535064

Epoch: 5| Step: 8
Training loss: 0.32684415644390546
Validation loss: 2.7738878018881987

Epoch: 5| Step: 9
Training loss: 0.3178170153766898
Validation loss: 2.7706648349917304

Epoch: 5| Step: 10
Training loss: 0.35016595235487247
Validation loss: 2.7982954612934963

Epoch: 5| Step: 11
Training loss: 0.43092079036148323
Validation loss: 2.7714857299027145

Epoch: 459| Step: 0
Training loss: 0.4075048396928935
Validation loss: 2.749694615805132

Epoch: 5| Step: 1
Training loss: 0.41762987107053995
Validation loss: 2.8217395437348847

Epoch: 5| Step: 2
Training loss: 0.36325446409513446
Validation loss: 2.810373215637559

Epoch: 5| Step: 3
Training loss: 0.392638605118295
Validation loss: 2.7851775722748604

Epoch: 5| Step: 4
Training loss: 0.3385887431156081
Validation loss: 2.775800495276036

Epoch: 5| Step: 5
Training loss: 0.49264193551863406
Validation loss: 2.8234256423957347

Epoch: 5| Step: 6
Training loss: 0.2378499082350218
Validation loss: 2.8280126257782743

Epoch: 5| Step: 7
Training loss: 0.4475494383829203
Validation loss: 2.788957456717455

Epoch: 5| Step: 8
Training loss: 0.31045148092083485
Validation loss: 2.8221189115376695

Epoch: 5| Step: 9
Training loss: 0.44528654926377276
Validation loss: 2.7801771559288615

Epoch: 5| Step: 10
Training loss: 0.33888152254329024
Validation loss: 2.786635093192587

Epoch: 5| Step: 11
Training loss: 0.45794421895240517
Validation loss: 2.7872475846223352

Epoch: 460| Step: 0
Training loss: 0.32947663800192545
Validation loss: 2.77924841389301

Epoch: 5| Step: 1
Training loss: 0.2840020191320652
Validation loss: 2.7262288265580836

Epoch: 5| Step: 2
Training loss: 0.3109220961009175
Validation loss: 2.791888599446604

Epoch: 5| Step: 3
Training loss: 0.40239074580707307
Validation loss: 2.8111481419948414

Epoch: 5| Step: 4
Training loss: 0.41175101731040925
Validation loss: 2.813407850325717

Epoch: 5| Step: 5
Training loss: 0.3589829919101442
Validation loss: 2.829826608823256

Epoch: 5| Step: 6
Training loss: 0.4959638981322549
Validation loss: 2.797237859306794

Epoch: 5| Step: 7
Training loss: 0.3740060070149566
Validation loss: 2.839410520562742

Epoch: 5| Step: 8
Training loss: 0.4726693175219777
Validation loss: 2.80005769059944

Epoch: 5| Step: 9
Training loss: 0.45917471327657194
Validation loss: 2.811754756667616

Epoch: 5| Step: 10
Training loss: 0.37687891886936836
Validation loss: 2.8403674119041242

Epoch: 5| Step: 11
Training loss: 0.30288675226545336
Validation loss: 2.8002609734452037

Epoch: 461| Step: 0
Training loss: 0.45527183110212693
Validation loss: 2.7537773048027256

Epoch: 5| Step: 1
Training loss: 0.34854024304594955
Validation loss: 2.7528844682836984

Epoch: 5| Step: 2
Training loss: 0.28321508185039906
Validation loss: 2.826337962794375

Epoch: 5| Step: 3
Training loss: 0.2886688154830163
Validation loss: 2.756003574534194

Epoch: 5| Step: 4
Training loss: 0.352903035545049
Validation loss: 2.7705418509901305

Epoch: 5| Step: 5
Training loss: 0.3282496124884126
Validation loss: 2.781835076588339

Epoch: 5| Step: 6
Training loss: 0.331311208090272
Validation loss: 2.816699499064922

Epoch: 5| Step: 7
Training loss: 0.4669466775873796
Validation loss: 2.8134257488435392

Epoch: 5| Step: 8
Training loss: 0.32274081712922037
Validation loss: 2.749430084416689

Epoch: 5| Step: 9
Training loss: 0.38706565479167543
Validation loss: 2.8356526234361508

Epoch: 5| Step: 10
Training loss: 0.2978105735716502
Validation loss: 2.751981436820918

Epoch: 5| Step: 11
Training loss: 0.26825026858139456
Validation loss: 2.752088093567013

Epoch: 462| Step: 0
Training loss: 0.36644535954020374
Validation loss: 2.7314437377037732

Epoch: 5| Step: 1
Training loss: 0.3651168756635678
Validation loss: 2.7982620142347043

Epoch: 5| Step: 2
Training loss: 0.3575624283388943
Validation loss: 2.7515127219023237

Epoch: 5| Step: 3
Training loss: 0.49954843992093334
Validation loss: 2.7773460749434458

Epoch: 5| Step: 4
Training loss: 0.3230611288300248
Validation loss: 2.807972308270485

Epoch: 5| Step: 5
Training loss: 0.30850021538270944
Validation loss: 2.792530098283032

Epoch: 5| Step: 6
Training loss: 0.2840041440985442
Validation loss: 2.76914161412695

Epoch: 5| Step: 7
Training loss: 0.209485807206078
Validation loss: 2.7564463595210813

Epoch: 5| Step: 8
Training loss: 0.3326936845514524
Validation loss: 2.7403662811383276

Epoch: 5| Step: 9
Training loss: 0.36142712860557175
Validation loss: 2.814358125698606

Epoch: 5| Step: 10
Training loss: 0.4476851282574837
Validation loss: 2.8160786784335863

Epoch: 5| Step: 11
Training loss: 0.6446152834586237
Validation loss: 2.7958478408944947

Epoch: 463| Step: 0
Training loss: 0.4754816211132932
Validation loss: 2.8144495070798423

Epoch: 5| Step: 1
Training loss: 0.3776575335795283
Validation loss: 2.8659278257572267

Epoch: 5| Step: 2
Training loss: 0.42528105586609033
Validation loss: 2.7793949205516615

Epoch: 5| Step: 3
Training loss: 0.3724861124509356
Validation loss: 2.8009077830087548

Epoch: 5| Step: 4
Training loss: 0.4535939322329006
Validation loss: 2.7853309127163066

Epoch: 5| Step: 5
Training loss: 0.46192038533760543
Validation loss: 2.792853435278817

Epoch: 5| Step: 6
Training loss: 0.4644148956042369
Validation loss: 2.8516771406705574

Epoch: 5| Step: 7
Training loss: 0.3671486610812097
Validation loss: 2.7805459313623575

Epoch: 5| Step: 8
Training loss: 0.30381074105769645
Validation loss: 2.7573354883077945

Epoch: 5| Step: 9
Training loss: 0.4325154100825955
Validation loss: 2.8309306985706235

Epoch: 5| Step: 10
Training loss: 0.4647111783796355
Validation loss: 2.7481649410042577

Epoch: 5| Step: 11
Training loss: 0.3245626487107196
Validation loss: 2.7985526209073286

Epoch: 464| Step: 0
Training loss: 0.4093303175557798
Validation loss: 2.7847230707253434

Epoch: 5| Step: 1
Training loss: 0.24701797172188855
Validation loss: 2.8071040525479103

Epoch: 5| Step: 2
Training loss: 0.41842779460246565
Validation loss: 2.7502126539256273

Epoch: 5| Step: 3
Training loss: 0.335085409187092
Validation loss: 2.762279214422159

Epoch: 5| Step: 4
Training loss: 0.4186015285781622
Validation loss: 2.7820440187619155

Epoch: 5| Step: 5
Training loss: 0.4623577414635864
Validation loss: 2.8022837738518867

Epoch: 5| Step: 6
Training loss: 0.2757994545825727
Validation loss: 2.7322660614880983

Epoch: 5| Step: 7
Training loss: 0.47665438782386915
Validation loss: 2.797125757154144

Epoch: 5| Step: 8
Training loss: 0.2826842454549614
Validation loss: 2.8142475244561416

Epoch: 5| Step: 9
Training loss: 0.48174906157366065
Validation loss: 2.7860710225438647

Epoch: 5| Step: 10
Training loss: 0.38249648927810287
Validation loss: 2.8004172464124273

Epoch: 5| Step: 11
Training loss: 0.25085443278588104
Validation loss: 2.826319671541453

Epoch: 465| Step: 0
Training loss: 0.42155407248882526
Validation loss: 2.8519546343678326

Epoch: 5| Step: 1
Training loss: 0.31080670553130024
Validation loss: 2.8217207826005426

Epoch: 5| Step: 2
Training loss: 0.3760398316096426
Validation loss: 2.754663796989144

Epoch: 5| Step: 3
Training loss: 0.27221559259122624
Validation loss: 2.7472729780501113

Epoch: 5| Step: 4
Training loss: 0.4043579055498231
Validation loss: 2.7867208173006426

Epoch: 5| Step: 5
Training loss: 0.4090061957978938
Validation loss: 2.8096422900669364

Epoch: 5| Step: 6
Training loss: 0.3879852747998725
Validation loss: 2.848414696403176

Epoch: 5| Step: 7
Training loss: 0.46614106848925835
Validation loss: 2.786455169866079

Epoch: 5| Step: 8
Training loss: 0.4896474569681375
Validation loss: 2.7430551103733736

Epoch: 5| Step: 9
Training loss: 0.37773012713121773
Validation loss: 2.798483796112138

Epoch: 5| Step: 10
Training loss: 0.3874670168467692
Validation loss: 2.7970268485335805

Epoch: 5| Step: 11
Training loss: 0.6015170191626719
Validation loss: 2.8311689936464624

Epoch: 466| Step: 0
Training loss: 0.30502013853298093
Validation loss: 2.8406381348661913

Epoch: 5| Step: 1
Training loss: 0.4045086181781131
Validation loss: 2.779900016044416

Epoch: 5| Step: 2
Training loss: 0.3819810440368262
Validation loss: 2.84460286566547

Epoch: 5| Step: 3
Training loss: 0.38233532651937663
Validation loss: 2.856416850152

Epoch: 5| Step: 4
Training loss: 0.2660515669910071
Validation loss: 2.822342963297511

Epoch: 5| Step: 5
Training loss: 0.3790890360928985
Validation loss: 2.775199269680685

Epoch: 5| Step: 6
Training loss: 0.2750949489797481
Validation loss: 2.828298556374957

Epoch: 5| Step: 7
Training loss: 0.3546282714596039
Validation loss: 2.820003115661289

Epoch: 5| Step: 8
Training loss: 0.305527312184799
Validation loss: 2.7697446029832706

Epoch: 5| Step: 9
Training loss: 0.5977368020020996
Validation loss: 2.7928532076324624

Epoch: 5| Step: 10
Training loss: 0.35380030597832035
Validation loss: 2.8257275530644033

Epoch: 5| Step: 11
Training loss: 0.11845881766586346
Validation loss: 2.7964866446702406

Epoch: 467| Step: 0
Training loss: 0.4270582560023132
Validation loss: 2.7936461616408863

Epoch: 5| Step: 1
Training loss: 0.3698428100715816
Validation loss: 2.8201365288303393

Epoch: 5| Step: 2
Training loss: 0.3481209253384309
Validation loss: 2.8099862874591333

Epoch: 5| Step: 3
Training loss: 0.31314589984608765
Validation loss: 2.765658786085982

Epoch: 5| Step: 4
Training loss: 0.4193914212395931
Validation loss: 2.780073995954749

Epoch: 5| Step: 5
Training loss: 0.3868060735888906
Validation loss: 2.7820454702894986

Epoch: 5| Step: 6
Training loss: 0.26636003725496876
Validation loss: 2.7887326284996314

Epoch: 5| Step: 7
Training loss: 0.24352401687118946
Validation loss: 2.7682843829318444

Epoch: 5| Step: 8
Training loss: 0.3843500633214385
Validation loss: 2.8217487711113605

Epoch: 5| Step: 9
Training loss: 0.544036556241027
Validation loss: 2.8271524046066814

Epoch: 5| Step: 10
Training loss: 0.2693329648413317
Validation loss: 2.8406856955634945

Epoch: 5| Step: 11
Training loss: 0.18693867743557185
Validation loss: 2.8329007622613256

Epoch: 468| Step: 0
Training loss: 0.2905567571031863
Validation loss: 2.8255459703771715

Epoch: 5| Step: 1
Training loss: 0.39977175637993323
Validation loss: 2.8346848151348065

Epoch: 5| Step: 2
Training loss: 0.44683874156547954
Validation loss: 2.7437366590993806

Epoch: 5| Step: 3
Training loss: 0.33303696401311184
Validation loss: 2.807902120533758

Epoch: 5| Step: 4
Training loss: 0.4014691411305456
Validation loss: 2.8368350098407764

Epoch: 5| Step: 5
Training loss: 0.33802704455170174
Validation loss: 2.7944397722685097

Epoch: 5| Step: 6
Training loss: 0.40945288885408554
Validation loss: 2.7944475327243596

Epoch: 5| Step: 7
Training loss: 0.5375152996014898
Validation loss: 2.8730606538644015

Epoch: 5| Step: 8
Training loss: 0.43468931476096273
Validation loss: 2.810825700782511

Epoch: 5| Step: 9
Training loss: 0.34336418478312625
Validation loss: 2.8165409833661195

Epoch: 5| Step: 10
Training loss: 0.3163740706857803
Validation loss: 2.8033092870561687

Epoch: 5| Step: 11
Training loss: 0.6110923239199474
Validation loss: 2.803634279328747

Epoch: 469| Step: 0
Training loss: 0.39200820167875394
Validation loss: 2.7785152105478326

Epoch: 5| Step: 1
Training loss: 0.4240671705468066
Validation loss: 2.793029062469105

Epoch: 5| Step: 2
Training loss: 0.3173741970360099
Validation loss: 2.9139933028199807

Epoch: 5| Step: 3
Training loss: 0.4155543460880762
Validation loss: 2.8132445868585787

Epoch: 5| Step: 4
Training loss: 0.4138529985271988
Validation loss: 2.817622246311515

Epoch: 5| Step: 5
Training loss: 0.2528198180300662
Validation loss: 2.8560867858375523

Epoch: 5| Step: 6
Training loss: 0.3728324513560643
Validation loss: 2.8747941993915824

Epoch: 5| Step: 7
Training loss: 0.267570843562716
Validation loss: 2.8213206432806945

Epoch: 5| Step: 8
Training loss: 0.3218869151530334
Validation loss: 2.768530337917889

Epoch: 5| Step: 9
Training loss: 0.450791814009251
Validation loss: 2.8780407098334626

Epoch: 5| Step: 10
Training loss: 0.3245602383475102
Validation loss: 2.804630994448922

Epoch: 5| Step: 11
Training loss: 0.3209497927286632
Validation loss: 2.772979691379363

Epoch: 470| Step: 0
Training loss: 0.36944232701449276
Validation loss: 2.8146506740289503

Epoch: 5| Step: 1
Training loss: 0.30226385406424955
Validation loss: 2.7889089034499226

Epoch: 5| Step: 2
Training loss: 0.4118858201106373
Validation loss: 2.7901979907858676

Epoch: 5| Step: 3
Training loss: 0.3205289109635528
Validation loss: 2.85173642747236

Epoch: 5| Step: 4
Training loss: 0.41466947368316215
Validation loss: 2.789172262103149

Epoch: 5| Step: 5
Training loss: 0.5254885784290823
Validation loss: 2.796874534706347

Epoch: 5| Step: 6
Training loss: 0.22756119649084716
Validation loss: 2.8268518163796004

Epoch: 5| Step: 7
Training loss: 0.2808447540891769
Validation loss: 2.8385811455923906

Epoch: 5| Step: 8
Training loss: 0.2920775272855284
Validation loss: 2.7631234818979076

Epoch: 5| Step: 9
Training loss: 0.32794491049243923
Validation loss: 2.7807376725449657

Epoch: 5| Step: 10
Training loss: 0.37415070522363725
Validation loss: 2.753712824528548

Epoch: 5| Step: 11
Training loss: 0.37953731250907186
Validation loss: 2.7701478351582334

Epoch: 471| Step: 0
Training loss: 0.3928865198818646
Validation loss: 2.8362669565112277

Epoch: 5| Step: 1
Training loss: 0.3576705567784452
Validation loss: 2.7916808033106038

Epoch: 5| Step: 2
Training loss: 0.3317065502552156
Validation loss: 2.7491392320148824

Epoch: 5| Step: 3
Training loss: 0.33751853123758374
Validation loss: 2.7944158615393118

Epoch: 5| Step: 4
Training loss: 0.4429800116236075
Validation loss: 2.845213663618023

Epoch: 5| Step: 5
Training loss: 0.33971167881041703
Validation loss: 2.8590769933834315

Epoch: 5| Step: 6
Training loss: 0.42793445175353284
Validation loss: 2.8373459610320415

Epoch: 5| Step: 7
Training loss: 0.44422414861586007
Validation loss: 2.8061274530773685

Epoch: 5| Step: 8
Training loss: 0.28410493057501485
Validation loss: 2.8605956857612957

Epoch: 5| Step: 9
Training loss: 0.3045741383868902
Validation loss: 2.783964336321897

Epoch: 5| Step: 10
Training loss: 0.3205905730743317
Validation loss: 2.831648147803858

Epoch: 5| Step: 11
Training loss: 0.447582016360492
Validation loss: 2.8330354159935816

Epoch: 472| Step: 0
Training loss: 0.4880725109242624
Validation loss: 2.757798408277781

Epoch: 5| Step: 1
Training loss: 0.27474469666747153
Validation loss: 2.8087853378293484

Epoch: 5| Step: 2
Training loss: 0.26251913920520054
Validation loss: 2.818145465377481

Epoch: 5| Step: 3
Training loss: 0.41862025243596357
Validation loss: 2.800126052755208

Epoch: 5| Step: 4
Training loss: 0.35233777711462005
Validation loss: 2.8181943926654207

Epoch: 5| Step: 5
Training loss: 0.2712183273080063
Validation loss: 2.814921844582083

Epoch: 5| Step: 6
Training loss: 0.3458481285174457
Validation loss: 2.6925770833968854

Epoch: 5| Step: 7
Training loss: 0.3235743219427599
Validation loss: 2.834058855700578

Epoch: 5| Step: 8
Training loss: 0.4271926236072124
Validation loss: 2.826094441120896

Epoch: 5| Step: 9
Training loss: 0.3359218638130128
Validation loss: 2.7587477023194777

Epoch: 5| Step: 10
Training loss: 0.2728991522277155
Validation loss: 2.746611393072223

Epoch: 5| Step: 11
Training loss: 0.24759995004088386
Validation loss: 2.7543005730880012

Epoch: 473| Step: 0
Training loss: 0.42893800392104603
Validation loss: 2.7843647528166184

Epoch: 5| Step: 1
Training loss: 0.4220123067570937
Validation loss: 2.794132063312267

Epoch: 5| Step: 2
Training loss: 0.40683493318768
Validation loss: 2.7743967967227374

Epoch: 5| Step: 3
Training loss: 0.3679212179078865
Validation loss: 2.8106031308388264

Epoch: 5| Step: 4
Training loss: 0.3084603878561548
Validation loss: 2.828607623402307

Epoch: 5| Step: 5
Training loss: 0.4321685255606252
Validation loss: 2.7503431947729986

Epoch: 5| Step: 6
Training loss: 0.3893546619890101
Validation loss: 2.8226136200929988

Epoch: 5| Step: 7
Training loss: 0.3583993106176567
Validation loss: 2.753349944215442

Epoch: 5| Step: 8
Training loss: 0.38999946099023985
Validation loss: 2.7730741379235924

Epoch: 5| Step: 9
Training loss: 0.40899226008905326
Validation loss: 2.818845668615595

Epoch: 5| Step: 10
Training loss: 0.2764449532487515
Validation loss: 2.827279384218034

Epoch: 5| Step: 11
Training loss: 0.26067500016748524
Validation loss: 2.808749874128003

Epoch: 474| Step: 0
Training loss: 0.43393173447890837
Validation loss: 2.7722205523307712

Epoch: 5| Step: 1
Training loss: 0.4585425015201736
Validation loss: 2.8139537939255943

Epoch: 5| Step: 2
Training loss: 0.38722881241445595
Validation loss: 2.803425741488875

Epoch: 5| Step: 3
Training loss: 0.4072612134795892
Validation loss: 2.7745035155521482

Epoch: 5| Step: 4
Training loss: 0.28538780739409164
Validation loss: 2.794771554291355

Epoch: 5| Step: 5
Training loss: 0.3740813208030384
Validation loss: 2.7292631850513933

Epoch: 5| Step: 6
Training loss: 0.403675117250788
Validation loss: 2.7602645520218045

Epoch: 5| Step: 7
Training loss: 0.5524735930764738
Validation loss: 2.739975387504466

Epoch: 5| Step: 8
Training loss: 0.5491987178616654
Validation loss: 2.8519477165995375

Epoch: 5| Step: 9
Training loss: 0.3696226575517269
Validation loss: 2.7507193303707305

Epoch: 5| Step: 10
Training loss: 0.3320698098624356
Validation loss: 2.791544809576117

Epoch: 5| Step: 11
Training loss: 0.6229455321352815
Validation loss: 2.7677286663942855

Epoch: 475| Step: 0
Training loss: 0.36305619518645593
Validation loss: 2.7942307544309526

Epoch: 5| Step: 1
Training loss: 0.3827674994975015
Validation loss: 2.81423966681253

Epoch: 5| Step: 2
Training loss: 0.26139732094773105
Validation loss: 2.7446778881274305

Epoch: 5| Step: 3
Training loss: 0.2730866497359539
Validation loss: 2.75486203464956

Epoch: 5| Step: 4
Training loss: 0.2708420324151162
Validation loss: 2.783548162834521

Epoch: 5| Step: 5
Training loss: 0.27738034987393956
Validation loss: 2.7584100855687392

Epoch: 5| Step: 6
Training loss: 0.4260296927948069
Validation loss: 2.714322039563085

Epoch: 5| Step: 7
Training loss: 0.3497828900112945
Validation loss: 2.767629640432246

Epoch: 5| Step: 8
Training loss: 0.47028321019720487
Validation loss: 2.7589202921665694

Epoch: 5| Step: 9
Training loss: 0.3905466001036154
Validation loss: 2.761321115172337

Epoch: 5| Step: 10
Training loss: 0.4356640371621733
Validation loss: 2.78200054399927

Epoch: 5| Step: 11
Training loss: 0.4597587708097607
Validation loss: 2.796193396771727

Epoch: 476| Step: 0
Training loss: 0.3355604872867888
Validation loss: 2.783772307079452

Epoch: 5| Step: 1
Training loss: 0.43358959161637356
Validation loss: 2.788172643129449

Epoch: 5| Step: 2
Training loss: 0.3723759634768035
Validation loss: 2.8410634530930468

Epoch: 5| Step: 3
Training loss: 0.4524393155308813
Validation loss: 2.7481592223612017

Epoch: 5| Step: 4
Training loss: 0.4012059168501013
Validation loss: 2.7451890148716265

Epoch: 5| Step: 5
Training loss: 0.30140179863663924
Validation loss: 2.787732646981407

Epoch: 5| Step: 6
Training loss: 0.24139557848802476
Validation loss: 2.79328445393132

Epoch: 5| Step: 7
Training loss: 0.44573482765096945
Validation loss: 2.7544548011393326

Epoch: 5| Step: 8
Training loss: 0.29835944727846575
Validation loss: 2.771475385311244

Epoch: 5| Step: 9
Training loss: 0.4227967788412534
Validation loss: 2.798952595475712

Epoch: 5| Step: 10
Training loss: 0.36216943072057023
Validation loss: 2.790614400703262

Epoch: 5| Step: 11
Training loss: 0.3274844707017656
Validation loss: 2.8063600258756427

Epoch: 477| Step: 0
Training loss: 0.3254743644607355
Validation loss: 2.747785818374695

Epoch: 5| Step: 1
Training loss: 0.35280548342138124
Validation loss: 2.776203255784432

Epoch: 5| Step: 2
Training loss: 0.329394439416777
Validation loss: 2.770072385562882

Epoch: 5| Step: 3
Training loss: 0.2752547368474441
Validation loss: 2.7723019778178695

Epoch: 5| Step: 4
Training loss: 0.41204278416957346
Validation loss: 2.7580365170133034

Epoch: 5| Step: 5
Training loss: 0.2790132830108638
Validation loss: 2.7040726171183986

Epoch: 5| Step: 6
Training loss: 0.46739874628104544
Validation loss: 2.8637032191411413

Epoch: 5| Step: 7
Training loss: 0.3602237836695054
Validation loss: 2.7938638493256205

Epoch: 5| Step: 8
Training loss: 0.422660149998749
Validation loss: 2.789792219170526

Epoch: 5| Step: 9
Training loss: 0.31361256676496463
Validation loss: 2.8480080141785638

Epoch: 5| Step: 10
Training loss: 0.35186341441105895
Validation loss: 2.7120944329348826

Epoch: 5| Step: 11
Training loss: 0.4697682764640522
Validation loss: 2.8086425854819144

Epoch: 478| Step: 0
Training loss: 0.46183219651968305
Validation loss: 2.7794609637956356

Epoch: 5| Step: 1
Training loss: 0.4143406995037707
Validation loss: 2.7574533331303694

Epoch: 5| Step: 2
Training loss: 0.43572747972152576
Validation loss: 2.7102314911924568

Epoch: 5| Step: 3
Training loss: 0.33347908077158256
Validation loss: 2.7739366431444124

Epoch: 5| Step: 4
Training loss: 0.2415071205699608
Validation loss: 2.8222304362882977

Epoch: 5| Step: 5
Training loss: 0.3587021956676221
Validation loss: 2.7736128236757596

Epoch: 5| Step: 6
Training loss: 0.33889406520876053
Validation loss: 2.8226079678165252

Epoch: 5| Step: 7
Training loss: 0.46062031840581186
Validation loss: 2.823520104403735

Epoch: 5| Step: 8
Training loss: 0.2761730954846037
Validation loss: 2.7948439627432435

Epoch: 5| Step: 9
Training loss: 0.2861900142218506
Validation loss: 2.833630316026584

Epoch: 5| Step: 10
Training loss: 0.3932522731164809
Validation loss: 2.750282381471684

Epoch: 5| Step: 11
Training loss: 0.2972776543367618
Validation loss: 2.734072328800474

Epoch: 479| Step: 0
Training loss: 0.3009596456616783
Validation loss: 2.851252579939412

Epoch: 5| Step: 1
Training loss: 0.27857961788908253
Validation loss: 2.7407970942796864

Epoch: 5| Step: 2
Training loss: 0.3331953398856058
Validation loss: 2.7685004119666057

Epoch: 5| Step: 3
Training loss: 0.378029566142143
Validation loss: 2.8248332205072093

Epoch: 5| Step: 4
Training loss: 0.39874259636920656
Validation loss: 2.8466274529316435

Epoch: 5| Step: 5
Training loss: 0.372011094875136
Validation loss: 2.8471353313451035

Epoch: 5| Step: 6
Training loss: 0.37875382808601443
Validation loss: 2.767148483693455

Epoch: 5| Step: 7
Training loss: 0.39606301227913887
Validation loss: 2.8588507472206794

Epoch: 5| Step: 8
Training loss: 0.26392215576933836
Validation loss: 2.825684398833163

Epoch: 5| Step: 9
Training loss: 0.28902864257893524
Validation loss: 2.844641423503706

Epoch: 5| Step: 10
Training loss: 0.33584206356591706
Validation loss: 2.8502789992413167

Epoch: 5| Step: 11
Training loss: 0.797653528520834
Validation loss: 2.825877642039946

Epoch: 480| Step: 0
Training loss: 0.40153158491893914
Validation loss: 2.8153312525641776

Epoch: 5| Step: 1
Training loss: 0.402547784569211
Validation loss: 2.8159886516609696

Epoch: 5| Step: 2
Training loss: 0.29760769725908864
Validation loss: 2.7936662812173725

Epoch: 5| Step: 3
Training loss: 0.4276013798996523
Validation loss: 2.7913974458968616

Epoch: 5| Step: 4
Training loss: 0.41771064347019166
Validation loss: 2.834948389137487

Epoch: 5| Step: 5
Training loss: 0.4630037644297111
Validation loss: 2.7532424343146853

Epoch: 5| Step: 6
Training loss: 0.3542289281795418
Validation loss: 2.834350106642766

Epoch: 5| Step: 7
Training loss: 0.3927885032734958
Validation loss: 2.8140910628509155

Epoch: 5| Step: 8
Training loss: 0.42513460524087954
Validation loss: 2.8404290157200944

Epoch: 5| Step: 9
Training loss: 0.3959709375860085
Validation loss: 2.8312592815727027

Epoch: 5| Step: 10
Training loss: 0.25787934968250553
Validation loss: 2.754754594579712

Epoch: 5| Step: 11
Training loss: 0.588089969333598
Validation loss: 2.7790602554031403

Epoch: 481| Step: 0
Training loss: 0.4360946495076945
Validation loss: 2.8227175903975623

Epoch: 5| Step: 1
Training loss: 0.5085748378911482
Validation loss: 2.8173383703753965

Epoch: 5| Step: 2
Training loss: 0.3309029875816133
Validation loss: 2.8086939525458967

Epoch: 5| Step: 3
Training loss: 0.3264096244465931
Validation loss: 2.829516175797441

Epoch: 5| Step: 4
Training loss: 0.3302684663999664
Validation loss: 2.7306610971062764

Epoch: 5| Step: 5
Training loss: 0.2970338446650789
Validation loss: 2.777427307245489

Epoch: 5| Step: 6
Training loss: 0.5006675436394872
Validation loss: 2.782502892285055

Epoch: 5| Step: 7
Training loss: 0.3469435319130476
Validation loss: 2.819653787237687

Epoch: 5| Step: 8
Training loss: 0.4733892069946853
Validation loss: 2.8411663915984193

Epoch: 5| Step: 9
Training loss: 0.35491222790843446
Validation loss: 2.7223784032662275

Epoch: 5| Step: 10
Training loss: 0.3815945303654894
Validation loss: 2.746017104083557

Epoch: 5| Step: 11
Training loss: 0.15829915793620247
Validation loss: 2.7195944187243657

Epoch: 482| Step: 0
Training loss: 0.3750385026239222
Validation loss: 2.8356750163638504

Epoch: 5| Step: 1
Training loss: 0.31533957454936373
Validation loss: 2.7454368344591553

Epoch: 5| Step: 2
Training loss: 0.33962514576998304
Validation loss: 2.7618446555207603

Epoch: 5| Step: 3
Training loss: 0.3627997663433559
Validation loss: 2.753572166866392

Epoch: 5| Step: 4
Training loss: 0.24742447118478125
Validation loss: 2.83164055595761

Epoch: 5| Step: 5
Training loss: 0.36082078524628053
Validation loss: 2.8125852077433766

Epoch: 5| Step: 6
Training loss: 0.4047207844423635
Validation loss: 2.7981614363445737

Epoch: 5| Step: 7
Training loss: 0.5412683826082374
Validation loss: 2.8126959237980405

Epoch: 5| Step: 8
Training loss: 0.3713992618004463
Validation loss: 2.7822823233800436

Epoch: 5| Step: 9
Training loss: 0.4233486434215555
Validation loss: 2.868068344948748

Epoch: 5| Step: 10
Training loss: 0.31321453421011647
Validation loss: 2.7104381885646585

Epoch: 5| Step: 11
Training loss: 0.18381923667018638
Validation loss: 2.772426571419707

Epoch: 483| Step: 0
Training loss: 0.4389371088790183
Validation loss: 2.804743781273329

Epoch: 5| Step: 1
Training loss: 0.3773856177313117
Validation loss: 2.7833810992529915

Epoch: 5| Step: 2
Training loss: 0.40258578085360996
Validation loss: 2.860346794015911

Epoch: 5| Step: 3
Training loss: 0.2778727898760791
Validation loss: 2.79048653230947

Epoch: 5| Step: 4
Training loss: 0.3513453024579074
Validation loss: 2.7679542029337068

Epoch: 5| Step: 5
Training loss: 0.4124424930425778
Validation loss: 2.8040821268640483

Epoch: 5| Step: 6
Training loss: 0.3716564129083543
Validation loss: 2.789899666570426

Epoch: 5| Step: 7
Training loss: 0.2805630188102455
Validation loss: 2.8030749850593706

Epoch: 5| Step: 8
Training loss: 0.4716492795126475
Validation loss: 2.8194194834616386

Epoch: 5| Step: 9
Training loss: 0.3794660660357345
Validation loss: 2.7995889698347862

Epoch: 5| Step: 10
Training loss: 0.29905113924106386
Validation loss: 2.7522814653841987

Epoch: 5| Step: 11
Training loss: 0.38959988552092806
Validation loss: 2.748628557933286

Epoch: 484| Step: 0
Training loss: 0.3165159388546881
Validation loss: 2.788329351325041

Epoch: 5| Step: 1
Training loss: 0.28867162877383334
Validation loss: 2.843857116917526

Epoch: 5| Step: 2
Training loss: 0.39750732975925573
Validation loss: 2.8227727977694825

Epoch: 5| Step: 3
Training loss: 0.32121245795688813
Validation loss: 2.8067735407359593

Epoch: 5| Step: 4
Training loss: 0.3780293493432008
Validation loss: 2.8414609625318197

Epoch: 5| Step: 5
Training loss: 0.2854066298221328
Validation loss: 2.808883407999838

Epoch: 5| Step: 6
Training loss: 0.31677622416177476
Validation loss: 2.891141250836706

Epoch: 5| Step: 7
Training loss: 0.314069644410209
Validation loss: 2.8532931680411093

Epoch: 5| Step: 8
Training loss: 0.3532088302593659
Validation loss: 2.8901539839791557

Epoch: 5| Step: 9
Training loss: 0.3067595378866556
Validation loss: 2.8444207940871364

Epoch: 5| Step: 10
Training loss: 0.379645501470924
Validation loss: 2.8001974464804467

Epoch: 5| Step: 11
Training loss: 0.2903713801433813
Validation loss: 2.8214352311170137

Epoch: 485| Step: 0
Training loss: 0.3679140694196419
Validation loss: 2.811444338725649

Epoch: 5| Step: 1
Training loss: 0.32110513912895083
Validation loss: 2.8013940670104476

Epoch: 5| Step: 2
Training loss: 0.30599818386679606
Validation loss: 2.8236010110216516

Epoch: 5| Step: 3
Training loss: 0.503278207849678
Validation loss: 2.84502845015265

Epoch: 5| Step: 4
Training loss: 0.35942330243124426
Validation loss: 2.778428736282341

Epoch: 5| Step: 5
Training loss: 0.41510020086227994
Validation loss: 2.8498438633428753

Epoch: 5| Step: 6
Training loss: 0.3644506235639911
Validation loss: 2.8228601025384195

Epoch: 5| Step: 7
Training loss: 0.3817927733705067
Validation loss: 2.8096691649434855

Epoch: 5| Step: 8
Training loss: 0.39306735399973086
Validation loss: 2.8003586965095777

Epoch: 5| Step: 9
Training loss: 0.3713587968848839
Validation loss: 2.7802888659670084

Epoch: 5| Step: 10
Training loss: 0.4753944434433409
Validation loss: 2.8903235785239376

Epoch: 5| Step: 11
Training loss: 0.23641900608670993
Validation loss: 2.7531318748177562

Epoch: 486| Step: 0
Training loss: 0.378482778598348
Validation loss: 2.727326789715076

Epoch: 5| Step: 1
Training loss: 0.37342126643438
Validation loss: 2.8067711976962415

Epoch: 5| Step: 2
Training loss: 0.219627620884928
Validation loss: 2.762346681019726

Epoch: 5| Step: 3
Training loss: 0.3729108792216418
Validation loss: 2.805118435593632

Epoch: 5| Step: 4
Training loss: 0.35830699783218145
Validation loss: 2.7815277839553936

Epoch: 5| Step: 5
Training loss: 0.26730449635812276
Validation loss: 2.785492775494728

Epoch: 5| Step: 6
Training loss: 0.31012553295933826
Validation loss: 2.75373762259268

Epoch: 5| Step: 7
Training loss: 0.2980155118386932
Validation loss: 2.735509241188341

Epoch: 5| Step: 8
Training loss: 0.3819892165886414
Validation loss: 2.7752381689375416

Epoch: 5| Step: 9
Training loss: 0.43794233236345687
Validation loss: 2.7190012651288313

Epoch: 5| Step: 10
Training loss: 0.3823004041638185
Validation loss: 2.774434285737482

Epoch: 5| Step: 11
Training loss: 0.49291390599079365
Validation loss: 2.753587997480445

Epoch: 487| Step: 0
Training loss: 0.24420193474565136
Validation loss: 2.7604196668404644

Epoch: 5| Step: 1
Training loss: 0.31390904810310133
Validation loss: 2.6949899010477893

Epoch: 5| Step: 2
Training loss: 0.5293814109495117
Validation loss: 2.8552388500061268

Epoch: 5| Step: 3
Training loss: 0.41078640803613414
Validation loss: 2.775623917533986

Epoch: 5| Step: 4
Training loss: 0.3325494873176561
Validation loss: 2.775101870594359

Epoch: 5| Step: 5
Training loss: 0.31825613910645173
Validation loss: 2.7741824443578937

Epoch: 5| Step: 6
Training loss: 0.4735503449367153
Validation loss: 2.7064156063879725

Epoch: 5| Step: 7
Training loss: 0.2565621922452802
Validation loss: 2.7408837591001642

Epoch: 5| Step: 8
Training loss: 0.3541201696541088
Validation loss: 2.771837229508993

Epoch: 5| Step: 9
Training loss: 0.3897317400539928
Validation loss: 2.7596332925978704

Epoch: 5| Step: 10
Training loss: 0.41806166498480346
Validation loss: 2.7779754442510187

Epoch: 5| Step: 11
Training loss: 0.36409152328652417
Validation loss: 2.730124776163897

Epoch: 488| Step: 0
Training loss: 0.319798254458803
Validation loss: 2.7393970039349065

Epoch: 5| Step: 1
Training loss: 0.41477286385121837
Validation loss: 2.7619633869773264

Epoch: 5| Step: 2
Training loss: 0.32044756763074966
Validation loss: 2.815748163409231

Epoch: 5| Step: 3
Training loss: 0.30135668169500146
Validation loss: 2.7950893079152603

Epoch: 5| Step: 4
Training loss: 0.3325322242588469
Validation loss: 2.775981456301643

Epoch: 5| Step: 5
Training loss: 0.41320899951990486
Validation loss: 2.735981482023923

Epoch: 5| Step: 6
Training loss: 0.29888288457450674
Validation loss: 2.794224984301541

Epoch: 5| Step: 7
Training loss: 0.46966141469045897
Validation loss: 2.779330216094084

Epoch: 5| Step: 8
Training loss: 0.47818751082334954
Validation loss: 2.7081022873163816

Epoch: 5| Step: 9
Training loss: 0.20144380319979346
Validation loss: 2.7445267157947453

Epoch: 5| Step: 10
Training loss: 0.3520092668539475
Validation loss: 2.7938061790308044

Epoch: 5| Step: 11
Training loss: 0.44287324713506243
Validation loss: 2.707833098406404

Epoch: 489| Step: 0
Training loss: 0.34224545062143535
Validation loss: 2.6927202447053484

Epoch: 5| Step: 1
Training loss: 0.4198576767219057
Validation loss: 2.8045636878494205

Epoch: 5| Step: 2
Training loss: 0.35196154517666
Validation loss: 2.7483423503911335

Epoch: 5| Step: 3
Training loss: 0.31516420039454796
Validation loss: 2.7681197608053525

Epoch: 5| Step: 4
Training loss: 0.2918940478078719
Validation loss: 2.7690469007128375

Epoch: 5| Step: 5
Training loss: 0.3085208034008337
Validation loss: 2.7792161084018487

Epoch: 5| Step: 6
Training loss: 0.31673728438855214
Validation loss: 2.768706959030373

Epoch: 5| Step: 7
Training loss: 0.3547704776044772
Validation loss: 2.719564472986578

Epoch: 5| Step: 8
Training loss: 0.27400146635561157
Validation loss: 2.748988272496789

Epoch: 5| Step: 9
Training loss: 0.3375964124158435
Validation loss: 2.79704011397771

Epoch: 5| Step: 10
Training loss: 0.406235474546887
Validation loss: 2.750800614061773

Epoch: 5| Step: 11
Training loss: 0.45828994812955176
Validation loss: 2.7619801765817464

Epoch: 490| Step: 0
Training loss: 0.3955915385976321
Validation loss: 2.787190454627385

Epoch: 5| Step: 1
Training loss: 0.3456234597694334
Validation loss: 2.7717557652807074

Epoch: 5| Step: 2
Training loss: 0.46981672662800483
Validation loss: 2.775467111176536

Epoch: 5| Step: 3
Training loss: 0.43478941805187554
Validation loss: 2.784385342619782

Epoch: 5| Step: 4
Training loss: 0.38928278160115454
Validation loss: 2.8291442327120246

Epoch: 5| Step: 5
Training loss: 0.31546392343578394
Validation loss: 2.801067743762826

Epoch: 5| Step: 6
Training loss: 0.29576374677244793
Validation loss: 2.725749440188425

Epoch: 5| Step: 7
Training loss: 0.37504309168231514
Validation loss: 2.7330893118798056

Epoch: 5| Step: 8
Training loss: 0.31974534088525214
Validation loss: 2.7983404188499996

Epoch: 5| Step: 9
Training loss: 0.4325233857221462
Validation loss: 2.8618112479536952

Epoch: 5| Step: 10
Training loss: 0.24395081580301833
Validation loss: 2.7456483583754183

Epoch: 5| Step: 11
Training loss: 0.17643719780119402
Validation loss: 2.72822787370183

Epoch: 491| Step: 0
Training loss: 0.365924753900419
Validation loss: 2.745640087322137

Epoch: 5| Step: 1
Training loss: 0.31590585818065
Validation loss: 2.7529256386945327

Epoch: 5| Step: 2
Training loss: 0.43463262904122524
Validation loss: 2.810702275656011

Epoch: 5| Step: 3
Training loss: 0.2525365122749685
Validation loss: 2.720307824636404

Epoch: 5| Step: 4
Training loss: 0.33419587872519174
Validation loss: 2.760279170996506

Epoch: 5| Step: 5
Training loss: 0.3805979687467646
Validation loss: 2.834056233766385

Epoch: 5| Step: 6
Training loss: 0.44577185044940176
Validation loss: 2.750022335395275

Epoch: 5| Step: 7
Training loss: 0.3614213153158123
Validation loss: 2.7496010100753234

Epoch: 5| Step: 8
Training loss: 0.29500021746595095
Validation loss: 2.838126816605132

Epoch: 5| Step: 9
Training loss: 0.3707271371185465
Validation loss: 2.762289000058016

Epoch: 5| Step: 10
Training loss: 0.3959808911134654
Validation loss: 2.775215585456351

Epoch: 5| Step: 11
Training loss: 0.0991414429771401
Validation loss: 2.773089968259672

Epoch: 492| Step: 0
Training loss: 0.4453700179047019
Validation loss: 2.8322737701755987

Epoch: 5| Step: 1
Training loss: 0.32852931317310297
Validation loss: 2.796979138586236

Epoch: 5| Step: 2
Training loss: 0.45245565107528124
Validation loss: 2.8011131320536093

Epoch: 5| Step: 3
Training loss: 0.3566346802064562
Validation loss: 2.850984478201438

Epoch: 5| Step: 4
Training loss: 0.4527823698393436
Validation loss: 2.733621468030531

Epoch: 5| Step: 5
Training loss: 0.4698920483846521
Validation loss: 2.729029959004111

Epoch: 5| Step: 6
Training loss: 0.3361928435144034
Validation loss: 2.71184528443566

Epoch: 5| Step: 7
Training loss: 0.2772100421809461
Validation loss: 2.8169879779908973

Epoch: 5| Step: 8
Training loss: 0.3006774178168342
Validation loss: 2.7929758778727884

Epoch: 5| Step: 9
Training loss: 0.408691424480333
Validation loss: 2.7913019288387897

Epoch: 5| Step: 10
Training loss: 0.422569462720372
Validation loss: 2.771083287507102

Epoch: 5| Step: 11
Training loss: 0.4012334187667554
Validation loss: 2.8466108205850276

Epoch: 493| Step: 0
Training loss: 0.27205110305481184
Validation loss: 2.834207075164268

Epoch: 5| Step: 1
Training loss: 0.4105165080155847
Validation loss: 2.777346629352749

Epoch: 5| Step: 2
Training loss: 0.3760976224921009
Validation loss: 2.7228713057829954

Epoch: 5| Step: 3
Training loss: 0.247537788856171
Validation loss: 2.7637860385782855

Epoch: 5| Step: 4
Training loss: 0.29826498887512165
Validation loss: 2.773526995293965

Epoch: 5| Step: 5
Training loss: 0.24031435402749013
Validation loss: 2.782497854720366

Epoch: 5| Step: 6
Training loss: 0.43222501731213686
Validation loss: 2.7874980852379942

Epoch: 5| Step: 7
Training loss: 0.4023118608299868
Validation loss: 2.808814894697986

Epoch: 5| Step: 8
Training loss: 0.33863343193339895
Validation loss: 2.7650338275638284

Epoch: 5| Step: 9
Training loss: 0.30968324063602537
Validation loss: 2.7155612024993667

Epoch: 5| Step: 10
Training loss: 0.29671185176598724
Validation loss: 2.8051247286930376

Epoch: 5| Step: 11
Training loss: 0.47155738018838694
Validation loss: 2.7390885625492576

Epoch: 494| Step: 0
Training loss: 0.4187173645625229
Validation loss: 2.681640376799244

Epoch: 5| Step: 1
Training loss: 0.3443941669703402
Validation loss: 2.8487306145849143

Epoch: 5| Step: 2
Training loss: 0.3037161995287788
Validation loss: 2.7678120006595144

Epoch: 5| Step: 3
Training loss: 0.30904812498768996
Validation loss: 2.764532264883639

Epoch: 5| Step: 4
Training loss: 0.2471242024148816
Validation loss: 2.7696161082278645

Epoch: 5| Step: 5
Training loss: 0.37838045980309515
Validation loss: 2.756523620016449

Epoch: 5| Step: 6
Training loss: 0.44440924071259297
Validation loss: 2.775105955060012

Epoch: 5| Step: 7
Training loss: 0.3110008999391396
Validation loss: 2.7964769715965443

Epoch: 5| Step: 8
Training loss: 0.40445407630789376
Validation loss: 2.7759629692292886

Epoch: 5| Step: 9
Training loss: 0.33920222053686644
Validation loss: 2.7931591760412893

Epoch: 5| Step: 10
Training loss: 0.300448630081351
Validation loss: 2.803555507198176

Epoch: 5| Step: 11
Training loss: 0.6415843990358532
Validation loss: 2.7713078269437035

Epoch: 495| Step: 0
Training loss: 0.46579259314124855
Validation loss: 2.7683975812054444

Epoch: 5| Step: 1
Training loss: 0.4820260497420139
Validation loss: 2.7852870273784185

Epoch: 5| Step: 2
Training loss: 0.3704919050518977
Validation loss: 2.7774974567643183

Epoch: 5| Step: 3
Training loss: 0.3215892166553609
Validation loss: 2.809456771803383

Epoch: 5| Step: 4
Training loss: 0.4977379832079346
Validation loss: 2.756966573710207

Epoch: 5| Step: 5
Training loss: 0.4692339624053329
Validation loss: 2.8121881912603066

Epoch: 5| Step: 6
Training loss: 0.4538571920491786
Validation loss: 2.7977651319751597

Epoch: 5| Step: 7
Training loss: 0.6049432750780558
Validation loss: 2.8169731208081776

Epoch: 5| Step: 8
Training loss: 0.34247734997332446
Validation loss: 2.8346327345202678

Epoch: 5| Step: 9
Training loss: 0.3642931555407377
Validation loss: 2.882273136810492

Epoch: 5| Step: 10
Training loss: 0.5889506114871368
Validation loss: 2.8508276946324176

Epoch: 5| Step: 11
Training loss: 0.6871529483479044
Validation loss: 2.8722253139556275

Epoch: 496| Step: 0
Training loss: 0.30688746048283516
Validation loss: 2.892209132749227

Epoch: 5| Step: 1
Training loss: 0.24149255104996464
Validation loss: 2.8495719128055543

Epoch: 5| Step: 2
Training loss: 0.45490066604661933
Validation loss: 2.7927258152445984

Epoch: 5| Step: 3
Training loss: 0.5857499903419614
Validation loss: 2.7767189027624752

Epoch: 5| Step: 4
Training loss: 0.596412761313893
Validation loss: 2.8276125160797134

Epoch: 5| Step: 5
Training loss: 0.509148351877889
Validation loss: 2.8860306838185115

Epoch: 5| Step: 6
Training loss: 0.3482307552016519
Validation loss: 2.89564611095009

Epoch: 5| Step: 7
Training loss: 0.3528963851205252
Validation loss: 2.7874025842440013

Epoch: 5| Step: 8
Training loss: 0.39029687451619516
Validation loss: 2.8688034403082057

Epoch: 5| Step: 9
Training loss: 0.5593133039921622
Validation loss: 2.8610920397473674

Epoch: 5| Step: 10
Training loss: 0.4643672456260761
Validation loss: 2.8059310954194636

Epoch: 5| Step: 11
Training loss: 0.26524555929926813
Validation loss: 2.84559739718702

Epoch: 497| Step: 0
Training loss: 0.3552042427647819
Validation loss: 2.846522659847683

Epoch: 5| Step: 1
Training loss: 0.5230431850721984
Validation loss: 2.8072765198949483

Epoch: 5| Step: 2
Training loss: 0.3922723936626322
Validation loss: 2.8321080743300997

Epoch: 5| Step: 3
Training loss: 0.31302192733285733
Validation loss: 2.83115353718204

Epoch: 5| Step: 4
Training loss: 0.3460392261034761
Validation loss: 2.8086447819444884

Epoch: 5| Step: 5
Training loss: 0.43264901278784446
Validation loss: 2.8008370990230356

Epoch: 5| Step: 6
Training loss: 0.3378330799118927
Validation loss: 2.8077357135024634

Epoch: 5| Step: 7
Training loss: 0.402243555426316
Validation loss: 2.8788223633951837

Epoch: 5| Step: 8
Training loss: 0.4462907653375439
Validation loss: 2.765656684794563

Epoch: 5| Step: 9
Training loss: 0.5662091142323071
Validation loss: 2.8116705183446746

Epoch: 5| Step: 10
Training loss: 0.44265654391875847
Validation loss: 2.8048946725593575

Epoch: 5| Step: 11
Training loss: 0.6553781712797461
Validation loss: 2.777789016277043

Epoch: 498| Step: 0
Training loss: 0.31509556509000414
Validation loss: 2.7525490232277634

Epoch: 5| Step: 1
Training loss: 0.3353260819314356
Validation loss: 2.761903475168395

Epoch: 5| Step: 2
Training loss: 0.3817739997444491
Validation loss: 2.8089986694068423

Epoch: 5| Step: 3
Training loss: 0.5145316235691247
Validation loss: 2.790717854508868

Epoch: 5| Step: 4
Training loss: 0.2990565829155062
Validation loss: 2.793955524118805

Epoch: 5| Step: 5
Training loss: 0.40237282212785797
Validation loss: 2.799845249577197

Epoch: 5| Step: 6
Training loss: 0.37168535958881815
Validation loss: 2.802206463336077

Epoch: 5| Step: 7
Training loss: 0.37055574870156155
Validation loss: 2.8564722756528793

Epoch: 5| Step: 8
Training loss: 0.3662860640714001
Validation loss: 2.7911784767671235

Epoch: 5| Step: 9
Training loss: 0.2853324293632166
Validation loss: 2.7998266504191576

Epoch: 5| Step: 10
Training loss: 0.3693414575738188
Validation loss: 2.813284351333396

Epoch: 5| Step: 11
Training loss: 0.23238685889094857
Validation loss: 2.7835331164592443

Epoch: 499| Step: 0
Training loss: 0.28826870051001585
Validation loss: 2.8568283493710744

Epoch: 5| Step: 1
Training loss: 0.27173325910652235
Validation loss: 2.789914582470599

Epoch: 5| Step: 2
Training loss: 0.3332845930386975
Validation loss: 2.8604790635375448

Epoch: 5| Step: 3
Training loss: 0.32321025079806964
Validation loss: 2.763693575105518

Epoch: 5| Step: 4
Training loss: 0.5239201782723323
Validation loss: 2.837529480846813

Epoch: 5| Step: 5
Training loss: 0.40833196477595796
Validation loss: 2.788571728608561

Epoch: 5| Step: 6
Training loss: 0.49696590323797113
Validation loss: 2.7481525349316605

Epoch: 5| Step: 7
Training loss: 0.3287514428734391
Validation loss: 2.7581020847973288

Epoch: 5| Step: 8
Training loss: 0.30829312372711865
Validation loss: 2.834886795880833

Epoch: 5| Step: 9
Training loss: 0.3676269417756548
Validation loss: 2.8845459809879466

Epoch: 5| Step: 10
Training loss: 0.36971601419772326
Validation loss: 2.7975094606604896

Epoch: 5| Step: 11
Training loss: 0.35098411878837904
Validation loss: 2.8246513974473535

Epoch: 500| Step: 0
Training loss: 0.42226203189983247
Validation loss: 2.8334441806109596

Epoch: 5| Step: 1
Training loss: 0.3835855191779207
Validation loss: 2.7773965865419608

Epoch: 5| Step: 2
Training loss: 0.2619901075916192
Validation loss: 2.7583942970346182

Epoch: 5| Step: 3
Training loss: 0.45703755887885683
Validation loss: 2.867542210256883

Epoch: 5| Step: 4
Training loss: 0.3527744384521639
Validation loss: 2.83297805568878

Epoch: 5| Step: 5
Training loss: 0.43582469478796276
Validation loss: 2.8537453609645507

Epoch: 5| Step: 6
Training loss: 0.41293171558165365
Validation loss: 2.803878022727909

Epoch: 5| Step: 7
Training loss: 0.3132015221950353
Validation loss: 2.7581100627530133

Epoch: 5| Step: 8
Training loss: 0.23630433711613266
Validation loss: 2.7905005408396284

Epoch: 5| Step: 9
Training loss: 0.2654157964736072
Validation loss: 2.817608601796528

Epoch: 5| Step: 10
Training loss: 0.36051862612209107
Validation loss: 2.8735067006930164

Epoch: 5| Step: 11
Training loss: 0.18615046254361067
Validation loss: 2.8805073116719333

Testing loss: 2.6525310406943623
