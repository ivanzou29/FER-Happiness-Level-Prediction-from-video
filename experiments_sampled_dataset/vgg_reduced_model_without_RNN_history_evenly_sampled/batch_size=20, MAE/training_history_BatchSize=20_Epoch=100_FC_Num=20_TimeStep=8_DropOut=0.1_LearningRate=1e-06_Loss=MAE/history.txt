Epoch: 1| Step: 0
Training loss: 4.522418022155762
Validation loss: 3.912704872828658

Epoch: 5| Step: 1
Training loss: 3.712589979171753
Validation loss: 3.9094484339478197

Epoch: 5| Step: 2
Training loss: 4.105556964874268
Validation loss: 3.9055763162592405

Epoch: 5| Step: 3
Training loss: 3.5975394248962402
Validation loss: 3.902260298370033

Epoch: 5| Step: 4
Training loss: 4.720616817474365
Validation loss: 3.9001571696291686

Epoch: 5| Step: 5
Training loss: 3.4203734397888184
Validation loss: 3.898277892861315

Epoch: 5| Step: 6
Training loss: 3.1441192626953125
Validation loss: 3.8946625699279127

Epoch: 5| Step: 7
Training loss: 3.0080413818359375
Validation loss: 3.89156332067264

Epoch: 5| Step: 8
Training loss: 4.434016704559326
Validation loss: 3.891638368688604

Epoch: 5| Step: 9
Training loss: 3.1161105632781982
Validation loss: 3.8873027165730796

Epoch: 5| Step: 10
Training loss: 3.617798089981079
Validation loss: 3.8838857066246772

Epoch: 2| Step: 0
Training loss: 4.043254852294922
Validation loss: 3.8838563324302755

Epoch: 5| Step: 1
Training loss: 4.883657932281494
Validation loss: 3.8804585420957176

Epoch: 5| Step: 2
Training loss: 4.405522346496582
Validation loss: 3.8757831204322075

Epoch: 5| Step: 3
Training loss: 3.583874464035034
Validation loss: 3.8749064117349605

Epoch: 5| Step: 4
Training loss: 3.8491058349609375
Validation loss: 3.869827829381471

Epoch: 5| Step: 5
Training loss: 3.8220887184143066
Validation loss: 3.8695564885293283

Epoch: 5| Step: 6
Training loss: 3.436649799346924
Validation loss: 3.867265737184914

Epoch: 5| Step: 7
Training loss: 3.4041507244110107
Validation loss: 3.8636727845796974

Epoch: 5| Step: 8
Training loss: 3.4701638221740723
Validation loss: 3.862920017652614

Epoch: 5| Step: 9
Training loss: 3.216069459915161
Validation loss: 3.860981797659269

Epoch: 5| Step: 10
Training loss: 2.978098154067993
Validation loss: 3.8584535403918196

Epoch: 3| Step: 0
Training loss: 3.200166702270508
Validation loss: 3.8547683967057096

Epoch: 5| Step: 1
Training loss: 2.8499603271484375
Validation loss: 3.8517392117490052

Epoch: 5| Step: 2
Training loss: 4.029199123382568
Validation loss: 3.8520051048647974

Epoch: 5| Step: 3
Training loss: 3.5913314819335938
Validation loss: 3.8483277085006877

Epoch: 5| Step: 4
Training loss: 3.45723295211792
Validation loss: 3.8472654050396335

Epoch: 5| Step: 5
Training loss: 4.0026535987854
Validation loss: 3.8420812212010866

Epoch: 5| Step: 6
Training loss: 4.538269996643066
Validation loss: 3.840497111761442

Epoch: 5| Step: 7
Training loss: 3.562711715698242
Validation loss: 3.8397178649902344

Epoch: 5| Step: 8
Training loss: 4.582521438598633
Validation loss: 3.83563498527773

Epoch: 5| Step: 9
Training loss: 3.757483959197998
Validation loss: 3.8351375056851293

Epoch: 5| Step: 10
Training loss: 3.3205137252807617
Validation loss: 3.8317597040566067

Epoch: 4| Step: 0
Training loss: 3.9906280040740967
Validation loss: 3.830966764880765

Epoch: 5| Step: 1
Training loss: 2.816599130630493
Validation loss: 3.825088526612969

Epoch: 5| Step: 2
Training loss: 3.57183837890625
Validation loss: 3.8236899170824277

Epoch: 5| Step: 3
Training loss: 3.837895154953003
Validation loss: 3.822173462119154

Epoch: 5| Step: 4
Training loss: 4.061893939971924
Validation loss: 3.8212654539333877

Epoch: 5| Step: 5
Training loss: 3.852558135986328
Validation loss: 3.8158413158949984

Epoch: 5| Step: 6
Training loss: 3.890401840209961
Validation loss: 3.8142859602487214

Epoch: 5| Step: 7
Training loss: 3.1101672649383545
Validation loss: 3.8131062548647643

Epoch: 5| Step: 8
Training loss: 3.985757827758789
Validation loss: 3.8064442347454768

Epoch: 5| Step: 9
Training loss: 3.643221378326416
Validation loss: 3.8074386017296904

Epoch: 5| Step: 10
Training loss: 3.9860072135925293
Validation loss: 3.8030049621417956

Epoch: 5| Step: 0
Training loss: 3.261075496673584
Validation loss: 3.800358913278067

Epoch: 5| Step: 1
Training loss: 3.8925204277038574
Validation loss: 3.798958552780972

Epoch: 5| Step: 2
Training loss: 3.8810970783233643
Validation loss: 3.794430261017174

Epoch: 5| Step: 3
Training loss: 4.4957051277160645
Validation loss: 3.7939946113094205

Epoch: 5| Step: 4
Training loss: 3.0508556365966797
Validation loss: 3.788943459910731

Epoch: 5| Step: 5
Training loss: 3.2033607959747314
Validation loss: 3.7882353208398305

Epoch: 5| Step: 6
Training loss: 3.908013105392456
Validation loss: 3.783782682111186

Epoch: 5| Step: 7
Training loss: 3.675713062286377
Validation loss: 3.7819192691515853

Epoch: 5| Step: 8
Training loss: 3.5912346839904785
Validation loss: 3.7778997933992775

Epoch: 5| Step: 9
Training loss: 4.064479827880859
Validation loss: 3.7760745145941295

Epoch: 5| Step: 10
Training loss: 3.342008590698242
Validation loss: 3.775726895178518

Epoch: 6| Step: 0
Training loss: 3.2220473289489746
Validation loss: 3.7716367270356868

Epoch: 5| Step: 1
Training loss: 2.8166048526763916
Validation loss: 3.7689307607630247

Epoch: 5| Step: 2
Training loss: 4.1159892082214355
Validation loss: 3.763069463032548

Epoch: 5| Step: 3
Training loss: 3.3165645599365234
Validation loss: 3.760743584684146

Epoch: 5| Step: 4
Training loss: 4.099812030792236
Validation loss: 3.7594300752045005

Epoch: 5| Step: 5
Training loss: 4.1338396072387695
Validation loss: 3.7583513490615355

Epoch: 5| Step: 6
Training loss: 3.785374164581299
Validation loss: 3.7528567570512013

Epoch: 5| Step: 7
Training loss: 2.575890302658081
Validation loss: 3.752652088801066

Epoch: 5| Step: 8
Training loss: 4.474826335906982
Validation loss: 3.7484333284439577

Epoch: 5| Step: 9
Training loss: 3.9659698009490967
Validation loss: 3.743967512602447

Epoch: 5| Step: 10
Training loss: 3.612894296646118
Validation loss: 3.7420860849401003

Epoch: 7| Step: 0
Training loss: 2.5700244903564453
Validation loss: 3.7387151307957147

Epoch: 5| Step: 1
Training loss: 3.860848903656006
Validation loss: 3.7354467966223277

Epoch: 5| Step: 2
Training loss: 4.421525001525879
Validation loss: 3.7313939422689457

Epoch: 5| Step: 3
Training loss: 3.326904773712158
Validation loss: 3.7290763547343593

Epoch: 5| Step: 4
Training loss: 2.9591000080108643
Validation loss: 3.723514644048547

Epoch: 5| Step: 5
Training loss: 3.8969879150390625
Validation loss: 3.7222937307050152

Epoch: 5| Step: 6
Training loss: 3.9544506072998047
Validation loss: 3.722602480201311

Epoch: 5| Step: 7
Training loss: 3.7319836616516113
Validation loss: 3.715573823580178

Epoch: 5| Step: 8
Training loss: 4.531431198120117
Validation loss: 3.713364516535113

Epoch: 5| Step: 9
Training loss: 3.4158718585968018
Validation loss: 3.7101018608257337

Epoch: 5| Step: 10
Training loss: 3.0570316314697266
Validation loss: 3.7073016781960764

Epoch: 8| Step: 0
Training loss: 3.8466567993164062
Validation loss: 3.7026309197948826

Epoch: 5| Step: 1
Training loss: 2.489424228668213
Validation loss: 3.7004916129573697

Epoch: 5| Step: 2
Training loss: 3.727825880050659
Validation loss: 3.697711072942262

Epoch: 5| Step: 3
Training loss: 3.9448647499084473
Validation loss: 3.695279077817035

Epoch: 5| Step: 4
Training loss: 3.475949764251709
Validation loss: 3.689460277557373

Epoch: 5| Step: 5
Training loss: 4.647458076477051
Validation loss: 3.6887652976538545

Epoch: 5| Step: 6
Training loss: 3.810758113861084
Validation loss: 3.683739305824362

Epoch: 5| Step: 7
Training loss: 3.3564934730529785
Validation loss: 3.6816896366816696

Epoch: 5| Step: 8
Training loss: 4.6674981117248535
Validation loss: 3.6743188929814163

Epoch: 5| Step: 9
Training loss: 2.8922293186187744
Validation loss: 3.6737348289899927

Epoch: 5| Step: 10
Training loss: 2.4443063735961914
Validation loss: 3.671615546749484

Epoch: 9| Step: 0
Training loss: 4.363463401794434
Validation loss: 3.6646378501769035

Epoch: 5| Step: 1
Training loss: 4.620370388031006
Validation loss: 3.659947374815582

Epoch: 5| Step: 2
Training loss: 2.0455574989318848
Validation loss: 3.657522201538086

Epoch: 5| Step: 3
Training loss: 3.469128131866455
Validation loss: 3.652259370332123

Epoch: 5| Step: 4
Training loss: 3.7392430305480957
Validation loss: 3.649918766431911

Epoch: 5| Step: 5
Training loss: 3.6309590339660645
Validation loss: 3.647392411385813

Epoch: 5| Step: 6
Training loss: 3.0617611408233643
Validation loss: 3.6425128188184512

Epoch: 5| Step: 7
Training loss: 3.011404514312744
Validation loss: 3.6394419003558416

Epoch: 5| Step: 8
Training loss: 4.373831748962402
Validation loss: 3.636781282322381

Epoch: 5| Step: 9
Training loss: 3.595827102661133
Validation loss: 3.6299130019321235

Epoch: 5| Step: 10
Training loss: 3.112246036529541
Validation loss: 3.6264636439661824

Epoch: 10| Step: 0
Training loss: 2.6969058513641357
Validation loss: 3.622578787547286

Epoch: 5| Step: 1
Training loss: 3.402897357940674
Validation loss: 3.619110010003531

Epoch: 5| Step: 2
Training loss: 3.8527863025665283
Validation loss: 3.6159977118174234

Epoch: 5| Step: 3
Training loss: 4.167354583740234
Validation loss: 3.6136178765245663

Epoch: 5| Step: 4
Training loss: 3.042956829071045
Validation loss: 3.610687566059892

Epoch: 5| Step: 5
Training loss: 3.4826202392578125
Validation loss: 3.6049109120522775

Epoch: 5| Step: 6
Training loss: 3.273777723312378
Validation loss: 3.601804707639961

Epoch: 5| Step: 7
Training loss: 3.402172803878784
Validation loss: 3.595181970186131

Epoch: 5| Step: 8
Training loss: 3.5852179527282715
Validation loss: 3.5904725956660446

Epoch: 5| Step: 9
Training loss: 3.842195987701416
Validation loss: 3.5859064978937947

Epoch: 5| Step: 10
Training loss: 4.0045599937438965
Validation loss: 3.5789606622470322

Epoch: 11| Step: 0
Training loss: 3.3357796669006348
Validation loss: 3.5748238948083695

Epoch: 5| Step: 1
Training loss: 3.2016682624816895
Validation loss: 3.572953324164114

Epoch: 5| Step: 2
Training loss: 3.905038356781006
Validation loss: 3.5683907411431752

Epoch: 5| Step: 3
Training loss: 3.1547226905822754
Validation loss: 3.564102654816002

Epoch: 5| Step: 4
Training loss: 2.8612332344055176
Validation loss: 3.5591228572271203

Epoch: 5| Step: 5
Training loss: 3.7581634521484375
Validation loss: 3.5538697832374164

Epoch: 5| Step: 6
Training loss: 2.717329502105713
Validation loss: 3.549380599811513

Epoch: 5| Step: 7
Training loss: 3.375889539718628
Validation loss: 3.54292917507951

Epoch: 5| Step: 8
Training loss: 3.8492271900177
Validation loss: 3.541952463888353

Epoch: 5| Step: 9
Training loss: 3.9372169971466064
Validation loss: 3.537330227513467

Epoch: 5| Step: 10
Training loss: 4.192147254943848
Validation loss: 3.5295237520689606

Epoch: 12| Step: 0
Training loss: 2.7894973754882812
Validation loss: 3.5258875047006915

Epoch: 5| Step: 1
Training loss: 2.8358988761901855
Validation loss: 3.5205199359565653

Epoch: 5| Step: 2
Training loss: 3.464251756668091
Validation loss: 3.515882635629305

Epoch: 5| Step: 3
Training loss: 3.4938621520996094
Validation loss: 3.5092082177439043

Epoch: 5| Step: 4
Training loss: 3.449697494506836
Validation loss: 3.503882654251591

Epoch: 5| Step: 5
Training loss: 4.1428608894348145
Validation loss: 3.4974040472379295

Epoch: 5| Step: 6
Training loss: 3.0362436771392822
Validation loss: 3.4939677792210735

Epoch: 5| Step: 7
Training loss: 3.3909709453582764
Validation loss: 3.4850964802567677

Epoch: 5| Step: 8
Training loss: 3.5518295764923096
Validation loss: 3.48403658405427

Epoch: 5| Step: 9
Training loss: 3.9164974689483643
Validation loss: 3.468841488643359

Epoch: 5| Step: 10
Training loss: 3.619887590408325
Validation loss: 3.4714010864175777

Epoch: 13| Step: 0
Training loss: 2.8684396743774414
Validation loss: 3.4644516437284407

Epoch: 5| Step: 1
Training loss: 2.8334224224090576
Validation loss: 3.4559622733823714

Epoch: 5| Step: 2
Training loss: 3.5189661979675293
Validation loss: 3.4483406415549656

Epoch: 5| Step: 3
Training loss: 4.070921897888184
Validation loss: 3.446587711252192

Epoch: 5| Step: 4
Training loss: 2.7222402095794678
Validation loss: 3.4404419981023318

Epoch: 5| Step: 5
Training loss: 3.066734790802002
Validation loss: 3.4353244561021046

Epoch: 5| Step: 6
Training loss: 3.4700393676757812
Validation loss: 3.423340784606113

Epoch: 5| Step: 7
Training loss: 3.728036403656006
Validation loss: 3.4173562270338818

Epoch: 5| Step: 8
Training loss: 3.5505993366241455
Validation loss: 3.4154957750792145

Epoch: 5| Step: 9
Training loss: 3.3590164184570312
Validation loss: 3.404067249708278

Epoch: 5| Step: 10
Training loss: 3.9340851306915283
Validation loss: 3.3970810572306314

Epoch: 14| Step: 0
Training loss: 3.1267929077148438
Validation loss: 3.390713284092565

Epoch: 5| Step: 1
Training loss: 2.32035231590271
Validation loss: 3.3857061170762583

Epoch: 5| Step: 2
Training loss: 4.237642288208008
Validation loss: 3.379741276464155

Epoch: 5| Step: 3
Training loss: 3.9232077598571777
Validation loss: 3.3714696258626957

Epoch: 5| Step: 4
Training loss: 2.952927589416504
Validation loss: 3.363854831264865

Epoch: 5| Step: 5
Training loss: 3.65551495552063
Validation loss: 3.3501878476911977

Epoch: 5| Step: 6
Training loss: 3.6104331016540527
Validation loss: 3.34761239892693

Epoch: 5| Step: 7
Training loss: 3.8217480182647705
Validation loss: 3.3415215194866223

Epoch: 5| Step: 8
Training loss: 3.228038787841797
Validation loss: 3.3298280598014913

Epoch: 5| Step: 9
Training loss: 2.8441412448883057
Validation loss: 3.3208394486417054

Epoch: 5| Step: 10
Training loss: 2.511626958847046
Validation loss: 3.3173938874275453

Epoch: 15| Step: 0
Training loss: 3.2924163341522217
Validation loss: 3.3080188305147233

Epoch: 5| Step: 1
Training loss: 2.7740514278411865
Validation loss: 3.296382850216281

Epoch: 5| Step: 2
Training loss: 2.0929720401763916
Validation loss: 3.2873673618480725

Epoch: 5| Step: 3
Training loss: 2.9709155559539795
Validation loss: 3.28369140625

Epoch: 5| Step: 4
Training loss: 3.940920352935791
Validation loss: 3.276418032184724

Epoch: 5| Step: 5
Training loss: 4.0473833084106445
Validation loss: 3.2706343589290494

Epoch: 5| Step: 6
Training loss: 3.2060749530792236
Validation loss: 3.267440003733481

Epoch: 5| Step: 7
Training loss: 3.167936325073242
Validation loss: 3.2457093064503004

Epoch: 5| Step: 8
Training loss: 3.042874813079834
Validation loss: 3.243007336893389

Epoch: 5| Step: 9
Training loss: 3.1576335430145264
Validation loss: 3.2355318402731292

Epoch: 5| Step: 10
Training loss: 3.9959850311279297
Validation loss: 3.2207799162915958

Epoch: 16| Step: 0
Training loss: 3.969991683959961
Validation loss: 3.2151726599662536

Epoch: 5| Step: 1
Training loss: 3.8094356060028076
Validation loss: 3.2030174629662627

Epoch: 5| Step: 2
Training loss: 2.7363440990448
Validation loss: 3.194926133719824

Epoch: 5| Step: 3
Training loss: 3.0004937648773193
Validation loss: 3.1874176507355063

Epoch: 5| Step: 4
Training loss: 2.7169060707092285
Validation loss: 3.172804419712354

Epoch: 5| Step: 5
Training loss: 3.3501601219177246
Validation loss: 3.167432531233757

Epoch: 5| Step: 6
Training loss: 2.9234302043914795
Validation loss: 3.158759194035684

Epoch: 5| Step: 7
Training loss: 3.739452362060547
Validation loss: 3.1488966864924275

Epoch: 5| Step: 8
Training loss: 2.598578453063965
Validation loss: 3.142112344823858

Epoch: 5| Step: 9
Training loss: 3.2779605388641357
Validation loss: 3.1286706104073474

Epoch: 5| Step: 10
Training loss: 2.5873100757598877
Validation loss: 3.112381919737785

Epoch: 17| Step: 0
Training loss: 2.792569398880005
Validation loss: 3.1104387903726227

Epoch: 5| Step: 1
Training loss: 3.3857321739196777
Validation loss: 3.099646393970777

Epoch: 5| Step: 2
Training loss: 3.195266008377075
Validation loss: 3.089857757732432

Epoch: 5| Step: 3
Training loss: 3.6374096870422363
Validation loss: 3.074028515046643

Epoch: 5| Step: 4
Training loss: 2.9810686111450195
Validation loss: 3.067636210431335

Epoch: 5| Step: 5
Training loss: 2.7974424362182617
Validation loss: 3.0596811335573912

Epoch: 5| Step: 6
Training loss: 2.742288589477539
Validation loss: 3.0467287084107757

Epoch: 5| Step: 7
Training loss: 3.0975818634033203
Validation loss: 3.0420713014500116

Epoch: 5| Step: 8
Training loss: 3.2190163135528564
Validation loss: 3.024908350360009

Epoch: 5| Step: 9
Training loss: 3.237070083618164
Validation loss: 3.027507589709374

Epoch: 5| Step: 10
Training loss: 2.6490299701690674
Validation loss: 3.0085338956566265

Epoch: 18| Step: 0
Training loss: 3.643770217895508
Validation loss: 2.996484984633743

Epoch: 5| Step: 1
Training loss: 2.548654079437256
Validation loss: 2.991328300968293

Epoch: 5| Step: 2
Training loss: 2.8364715576171875
Validation loss: 2.97720564821715

Epoch: 5| Step: 3
Training loss: 2.76798677444458
Validation loss: 2.967177708943685

Epoch: 5| Step: 4
Training loss: 2.337609052658081
Validation loss: 2.9602198498223418

Epoch: 5| Step: 5
Training loss: 2.5156781673431396
Validation loss: 2.9474810143952728

Epoch: 5| Step: 6
Training loss: 2.9507765769958496
Validation loss: 2.9352012398422405

Epoch: 5| Step: 7
Training loss: 3.226893663406372
Validation loss: 2.9286691424667195

Epoch: 5| Step: 8
Training loss: 3.449467420578003
Validation loss: 2.9168508052825928

Epoch: 5| Step: 9
Training loss: 4.019643306732178
Validation loss: 2.9071714390990553

Epoch: 5| Step: 10
Training loss: 2.5182249546051025
Validation loss: 2.892360625728484

Epoch: 19| Step: 0
Training loss: 2.8040528297424316
Validation loss: 2.8888536525029007

Epoch: 5| Step: 1
Training loss: 2.9856936931610107
Validation loss: 2.8786399569562686

Epoch: 5| Step: 2
Training loss: 2.716402530670166
Validation loss: 2.8575313270732923

Epoch: 5| Step: 3
Training loss: 3.1348319053649902
Validation loss: 2.8541027422874206

Epoch: 5| Step: 4
Training loss: 2.9829349517822266
Validation loss: 2.8352417586952128

Epoch: 5| Step: 5
Training loss: 3.3242759704589844
Validation loss: 2.8309935497981247

Epoch: 5| Step: 6
Training loss: 2.924349308013916
Validation loss: 2.819663619482389

Epoch: 5| Step: 7
Training loss: 2.949244260787964
Validation loss: 2.802889939277403

Epoch: 5| Step: 8
Training loss: 2.4929401874542236
Validation loss: 2.789713974921934

Epoch: 5| Step: 9
Training loss: 2.8302254676818848
Validation loss: 2.7765113333220124

Epoch: 5| Step: 10
Training loss: 2.96038556098938
Validation loss: 2.7617718942703737

Epoch: 20| Step: 0
Training loss: 2.7737579345703125
Validation loss: 2.749034438081967

Epoch: 5| Step: 1
Training loss: 2.762375831604004
Validation loss: 2.7460131850293887

Epoch: 5| Step: 2
Training loss: 3.074218273162842
Validation loss: 2.722165253854567

Epoch: 5| Step: 3
Training loss: 2.7853894233703613
Validation loss: 2.714841273523146

Epoch: 5| Step: 4
Training loss: 2.9055938720703125
Validation loss: 2.7005617080196256

Epoch: 5| Step: 5
Training loss: 2.9537079334259033
Validation loss: 2.684887865538238

Epoch: 5| Step: 6
Training loss: 2.6722359657287598
Validation loss: 2.668289945971581

Epoch: 5| Step: 7
Training loss: 2.9049019813537598
Validation loss: 2.66148643596198

Epoch: 5| Step: 8
Training loss: 2.9221432209014893
Validation loss: 2.6437258669125137

Epoch: 5| Step: 9
Training loss: 2.3896636962890625
Validation loss: 2.631301867064609

Epoch: 5| Step: 10
Training loss: 3.0378785133361816
Validation loss: 2.614176073381978

Epoch: 21| Step: 0
Training loss: 2.7735331058502197
Validation loss: 2.6105625219242548

Epoch: 5| Step: 1
Training loss: 3.246770143508911
Validation loss: 2.594183788504652

Epoch: 5| Step: 2
Training loss: 2.748898983001709
Validation loss: 2.5778945005068215

Epoch: 5| Step: 3
Training loss: 2.7528042793273926
Validation loss: 2.5615991956444195

Epoch: 5| Step: 4
Training loss: 2.5670392513275146
Validation loss: 2.5515616786095405

Epoch: 5| Step: 5
Training loss: 2.826441764831543
Validation loss: 2.5340449169117916

Epoch: 5| Step: 6
Training loss: 2.2417876720428467
Validation loss: 2.5170053410273727

Epoch: 5| Step: 7
Training loss: 2.715489149093628
Validation loss: 2.493790867508099

Epoch: 5| Step: 8
Training loss: 2.525075912475586
Validation loss: 2.4881439696076098

Epoch: 5| Step: 9
Training loss: 2.1791152954101562
Validation loss: 2.4771515938543502

Epoch: 5| Step: 10
Training loss: 3.6666135787963867
Validation loss: 2.461287044709729

Epoch: 22| Step: 0
Training loss: 3.1072635650634766
Validation loss: 2.45321257909139

Epoch: 5| Step: 1
Training loss: 2.594191312789917
Validation loss: 2.4370334045861357

Epoch: 5| Step: 2
Training loss: 3.0007574558258057
Validation loss: 2.4223489915170977

Epoch: 5| Step: 3
Training loss: 3.331402540206909
Validation loss: 2.4096983786552184

Epoch: 5| Step: 4
Training loss: 2.8036372661590576
Validation loss: 2.397857876234157

Epoch: 5| Step: 5
Training loss: 2.8738884925842285
Validation loss: 2.3754902629442114

Epoch: 5| Step: 6
Training loss: 1.690874457359314
Validation loss: 2.379303627116706

Epoch: 5| Step: 7
Training loss: 1.8243814706802368
Validation loss: 2.364061532482024

Epoch: 5| Step: 8
Training loss: 2.6429083347320557
Validation loss: 2.3338273955929663

Epoch: 5| Step: 9
Training loss: 2.8212637901306152
Validation loss: 2.3312209037042435

Epoch: 5| Step: 10
Training loss: 2.4415738582611084
Validation loss: 2.337725890580044

Epoch: 23| Step: 0
Training loss: 2.5445194244384766
Validation loss: 2.3249469328952093

Epoch: 5| Step: 1
Training loss: 2.1863808631896973
Validation loss: 2.3120338506596063

Epoch: 5| Step: 2
Training loss: 2.5538413524627686
Validation loss: 2.3071400593685847

Epoch: 5| Step: 3
Training loss: 2.5169143676757812
Validation loss: 2.2902741560371975

Epoch: 5| Step: 4
Training loss: 2.3763813972473145
Validation loss: 2.266188524102652

Epoch: 5| Step: 5
Training loss: 2.725539207458496
Validation loss: 2.27358510673687

Epoch: 5| Step: 6
Training loss: 2.7251033782958984
Validation loss: 2.2510784697789017

Epoch: 5| Step: 7
Training loss: 2.2602930068969727
Validation loss: 2.2495468354994252

Epoch: 5| Step: 8
Training loss: 2.616492748260498
Validation loss: 2.256715513044788

Epoch: 5| Step: 9
Training loss: 3.3039727210998535
Validation loss: 2.2228286317599717

Epoch: 5| Step: 10
Training loss: 2.3019354343414307
Validation loss: 2.2262451674348567

Epoch: 24| Step: 0
Training loss: 2.600534439086914
Validation loss: 2.2108537843150478

Epoch: 5| Step: 1
Training loss: 1.8646600246429443
Validation loss: 2.207089349787722

Epoch: 5| Step: 2
Training loss: 2.698202133178711
Validation loss: 2.219396624513852

Epoch: 5| Step: 3
Training loss: 2.211341381072998
Validation loss: 2.2100282484485256

Epoch: 5| Step: 4
Training loss: 3.1716418266296387
Validation loss: 2.189552535292923

Epoch: 5| Step: 5
Training loss: 2.334352493286133
Validation loss: 2.1824463823790192

Epoch: 5| Step: 6
Training loss: 2.682603597640991
Validation loss: 2.1726738227311

Epoch: 5| Step: 7
Training loss: 1.8687102794647217
Validation loss: 2.1586823155803065

Epoch: 5| Step: 8
Training loss: 2.625441074371338
Validation loss: 2.154761419501356

Epoch: 5| Step: 9
Training loss: 2.616894245147705
Validation loss: 2.1566286292127383

Epoch: 5| Step: 10
Training loss: 2.8997035026550293
Validation loss: 2.1285255942293393

Epoch: 25| Step: 0
Training loss: 2.662989377975464
Validation loss: 2.1482684484092136

Epoch: 5| Step: 1
Training loss: 2.1414217948913574
Validation loss: 2.1341216077086744

Epoch: 5| Step: 2
Training loss: 2.287149667739868
Validation loss: 2.1254015109872304

Epoch: 5| Step: 3
Training loss: 2.436309576034546
Validation loss: 2.1111783801868396

Epoch: 5| Step: 4
Training loss: 3.020883798599243
Validation loss: 2.0988559658809374

Epoch: 5| Step: 5
Training loss: 2.7817201614379883
Validation loss: 2.094886766966953

Epoch: 5| Step: 6
Training loss: 2.776484251022339
Validation loss: 2.0864600878889843

Epoch: 5| Step: 7
Training loss: 2.7034993171691895
Validation loss: 2.0835519580430883

Epoch: 5| Step: 8
Training loss: 1.9946483373641968
Validation loss: 2.0871788711958033

Epoch: 5| Step: 9
Training loss: 2.1600141525268555
Validation loss: 2.071228902827027

Epoch: 5| Step: 10
Training loss: 2.1297178268432617
Validation loss: 2.0811769629037506

Epoch: 26| Step: 0
Training loss: 2.6324217319488525
Validation loss: 2.0802198686907367

Epoch: 5| Step: 1
Training loss: 2.267793655395508
Validation loss: 2.066525182416362

Epoch: 5| Step: 2
Training loss: 2.444841146469116
Validation loss: 2.0661900838216147

Epoch: 5| Step: 3
Training loss: 2.7556958198547363
Validation loss: 2.0494826288633448

Epoch: 5| Step: 4
Training loss: 2.6126911640167236
Validation loss: 2.0604151397623043

Epoch: 5| Step: 5
Training loss: 2.318005084991455
Validation loss: 2.074800887415486

Epoch: 5| Step: 6
Training loss: 2.132584810256958
Validation loss: 2.070211748923025

Epoch: 5| Step: 7
Training loss: 2.281409978866577
Validation loss: 2.0696387419136624

Epoch: 5| Step: 8
Training loss: 2.8925089836120605
Validation loss: 2.077848724139634

Epoch: 5| Step: 9
Training loss: 2.2419545650482178
Validation loss: 2.0686070073035454

Epoch: 5| Step: 10
Training loss: 2.0633349418640137
Validation loss: 2.05743012889739

Epoch: 27| Step: 0
Training loss: 2.4300358295440674
Validation loss: 2.054443144029187

Epoch: 5| Step: 1
Training loss: 2.436640501022339
Validation loss: 2.0653610947311565

Epoch: 5| Step: 2
Training loss: 2.595973014831543
Validation loss: 2.07560666402181

Epoch: 5| Step: 3
Training loss: 1.7407896518707275
Validation loss: 2.0599439451771397

Epoch: 5| Step: 4
Training loss: 2.5802111625671387
Validation loss: 2.0391420369507163

Epoch: 5| Step: 5
Training loss: 2.456043004989624
Validation loss: 2.04272828050839

Epoch: 5| Step: 6
Training loss: 2.937782049179077
Validation loss: 2.0454226001616447

Epoch: 5| Step: 7
Training loss: 1.8760325908660889
Validation loss: 2.052917074131709

Epoch: 5| Step: 8
Training loss: 2.898674726486206
Validation loss: 2.038997616819156

Epoch: 5| Step: 9
Training loss: 1.7724580764770508
Validation loss: 2.052550277402324

Epoch: 5| Step: 10
Training loss: 3.097066879272461
Validation loss: 2.038147523838987

Epoch: 28| Step: 0
Training loss: 2.4299638271331787
Validation loss: 2.04602643751329

Epoch: 5| Step: 1
Training loss: 2.6663565635681152
Validation loss: 2.0272850477567284

Epoch: 5| Step: 2
Training loss: 2.7368862628936768
Validation loss: 2.0492427067090104

Epoch: 5| Step: 3
Training loss: 2.624783992767334
Validation loss: 2.040864867548789

Epoch: 5| Step: 4
Training loss: 2.7886011600494385
Validation loss: 2.0203280654004825

Epoch: 5| Step: 5
Training loss: 1.7594506740570068
Validation loss: 2.0409844921481226

Epoch: 5| Step: 6
Training loss: 2.445389986038208
Validation loss: 2.0289416466989825

Epoch: 5| Step: 7
Training loss: 2.6578941345214844
Validation loss: 2.006875388083919

Epoch: 5| Step: 8
Training loss: 1.9066236019134521
Validation loss: 2.0253792065446095

Epoch: 5| Step: 9
Training loss: 2.4066708087921143
Validation loss: 2.0179792527229554

Epoch: 5| Step: 10
Training loss: 2.112135410308838
Validation loss: 2.0208528708386164

Epoch: 29| Step: 0
Training loss: 2.05167555809021
Validation loss: 2.026141092341433

Epoch: 5| Step: 1
Training loss: 2.74603009223938
Validation loss: 2.045816813745806

Epoch: 5| Step: 2
Training loss: 2.904975414276123
Validation loss: 2.0525805962983

Epoch: 5| Step: 3
Training loss: 2.1229233741760254
Validation loss: 2.00953850694882

Epoch: 5| Step: 4
Training loss: 2.1726956367492676
Validation loss: 2.0141443257690756

Epoch: 5| Step: 5
Training loss: 1.9618351459503174
Validation loss: 2.014877470590735

Epoch: 5| Step: 6
Training loss: 2.354124069213867
Validation loss: 2.012028658261863

Epoch: 5| Step: 7
Training loss: 2.4220993518829346
Validation loss: 2.025716702143351

Epoch: 5| Step: 8
Training loss: 2.6729490756988525
Validation loss: 2.0288254676326627

Epoch: 5| Step: 9
Training loss: 2.2355008125305176
Validation loss: 2.0150918678570817

Epoch: 5| Step: 10
Training loss: 2.8875350952148438
Validation loss: 2.015227304991855

Epoch: 30| Step: 0
Training loss: 2.409160614013672
Validation loss: 2.013139929822696

Epoch: 5| Step: 1
Training loss: 2.4094347953796387
Validation loss: 2.0227555049363004

Epoch: 5| Step: 2
Training loss: 1.9716854095458984
Validation loss: 2.005889320886263

Epoch: 5| Step: 3
Training loss: 3.0735394954681396
Validation loss: 2.0010189881888767

Epoch: 5| Step: 4
Training loss: 2.309182643890381
Validation loss: 2.01816112508056

Epoch: 5| Step: 5
Training loss: 2.5155906677246094
Validation loss: 2.0106652680263726

Epoch: 5| Step: 6
Training loss: 2.1237473487854004
Validation loss: 2.020105105574413

Epoch: 5| Step: 7
Training loss: 2.147062063217163
Validation loss: 2.0156573275084138

Epoch: 5| Step: 8
Training loss: 2.6853649616241455
Validation loss: 2.0111791523553992

Epoch: 5| Step: 9
Training loss: 2.5112192630767822
Validation loss: 2.0134096965994885

Epoch: 5| Step: 10
Training loss: 2.3266196250915527
Validation loss: 2.0057491179435485

Epoch: 31| Step: 0
Training loss: 2.231673002243042
Validation loss: 2.0226574943911646

Epoch: 5| Step: 1
Training loss: 2.2946815490722656
Validation loss: 2.0248927236885153

Epoch: 5| Step: 2
Training loss: 2.589609146118164
Validation loss: 2.0332257337467645

Epoch: 5| Step: 3
Training loss: 2.5748188495635986
Validation loss: 2.027073824277488

Epoch: 5| Step: 4
Training loss: 2.2809860706329346
Validation loss: 2.003288612570814

Epoch: 5| Step: 5
Training loss: 2.270303964614868
Validation loss: 2.022623490261775

Epoch: 5| Step: 6
Training loss: 2.5240063667297363
Validation loss: 1.9983050348938152

Epoch: 5| Step: 7
Training loss: 2.1150336265563965
Validation loss: 2.0133428612063007

Epoch: 5| Step: 8
Training loss: 2.6608800888061523
Validation loss: 2.016093989854218

Epoch: 5| Step: 9
Training loss: 2.54492449760437
Validation loss: 2.0321741821945354

Epoch: 5| Step: 10
Training loss: 2.2721571922302246
Validation loss: 2.0203776077557634

Epoch: 32| Step: 0
Training loss: 2.3095078468322754
Validation loss: 2.0140119060393302

Epoch: 5| Step: 1
Training loss: 2.2086844444274902
Validation loss: 2.0136087812403196

Epoch: 5| Step: 2
Training loss: 1.8485281467437744
Validation loss: 2.0209613871830765

Epoch: 5| Step: 3
Training loss: 2.104259729385376
Validation loss: 2.0167605620558544

Epoch: 5| Step: 4
Training loss: 3.1098251342773438
Validation loss: 2.010766580540647

Epoch: 5| Step: 5
Training loss: 2.971238613128662
Validation loss: 2.019384014991022

Epoch: 5| Step: 6
Training loss: 1.9033544063568115
Validation loss: 2.0186225393767

Epoch: 5| Step: 7
Training loss: 2.3181519508361816
Validation loss: 2.0146644461539482

Epoch: 5| Step: 8
Training loss: 2.6023619174957275
Validation loss: 2.031749672787164

Epoch: 5| Step: 9
Training loss: 2.6933116912841797
Validation loss: 2.0151415255761917

Epoch: 5| Step: 10
Training loss: 2.199284076690674
Validation loss: 2.002205793575574

Epoch: 33| Step: 0
Training loss: 2.2773499488830566
Validation loss: 2.0042848317853865

Epoch: 5| Step: 1
Training loss: 2.278904676437378
Validation loss: 1.9957182151015087

Epoch: 5| Step: 2
Training loss: 2.29213809967041
Validation loss: 2.002358509648231

Epoch: 5| Step: 3
Training loss: 2.8943068981170654
Validation loss: 2.0042448684733403

Epoch: 5| Step: 4
Training loss: 1.5703026056289673
Validation loss: 1.9939797078409502

Epoch: 5| Step: 5
Training loss: 2.5671095848083496
Validation loss: 1.9825431941657938

Epoch: 5| Step: 6
Training loss: 2.1058456897735596
Validation loss: 2.005642814020957

Epoch: 5| Step: 7
Training loss: 2.7210030555725098
Validation loss: 1.9789647568938553

Epoch: 5| Step: 8
Training loss: 2.5369927883148193
Validation loss: 1.9970119255845264

Epoch: 5| Step: 9
Training loss: 2.319554328918457
Validation loss: 1.9880856967741443

Epoch: 5| Step: 10
Training loss: 2.593846082687378
Validation loss: 1.9718737602233887

Epoch: 34| Step: 0
Training loss: 2.5527584552764893
Validation loss: 1.9883417698644823

Epoch: 5| Step: 1
Training loss: 2.591153383255005
Validation loss: 1.9836862446159444

Epoch: 5| Step: 2
Training loss: 2.3298728466033936
Validation loss: 1.99209931588942

Epoch: 5| Step: 3
Training loss: 2.679232120513916
Validation loss: 1.987246391593769

Epoch: 5| Step: 4
Training loss: 2.6868977546691895
Validation loss: 1.9875574304211525

Epoch: 5| Step: 5
Training loss: 2.458583354949951
Validation loss: 1.9855975438189764

Epoch: 5| Step: 6
Training loss: 2.8465962409973145
Validation loss: 1.997837943415488

Epoch: 5| Step: 7
Training loss: 1.8738863468170166
Validation loss: 2.0010441708308395

Epoch: 5| Step: 8
Training loss: 1.8332782983779907
Validation loss: 2.0179570362132084

Epoch: 5| Step: 9
Training loss: 2.398695707321167
Validation loss: 1.9984823913984402

Epoch: 5| Step: 10
Training loss: 1.9102754592895508
Validation loss: 2.003526915786087

Epoch: 35| Step: 0
Training loss: 2.2097532749176025
Validation loss: 2.0023559908713064

Epoch: 5| Step: 1
Training loss: 2.706556558609009
Validation loss: 1.9895700485475603

Epoch: 5| Step: 2
Training loss: 1.9602845907211304
Validation loss: 1.9948102530612741

Epoch: 5| Step: 3
Training loss: 3.241142749786377
Validation loss: 1.9936683434312061

Epoch: 5| Step: 4
Training loss: 2.0343399047851562
Validation loss: 2.005689131316318

Epoch: 5| Step: 5
Training loss: 2.220651388168335
Validation loss: 2.0008731760004514

Epoch: 5| Step: 6
Training loss: 2.1796793937683105
Validation loss: 1.9997210156533025

Epoch: 5| Step: 7
Training loss: 2.991363286972046
Validation loss: 1.9790214210428216

Epoch: 5| Step: 8
Training loss: 2.293814182281494
Validation loss: 1.9815981157364384

Epoch: 5| Step: 9
Training loss: 2.145885944366455
Validation loss: 1.9920885614169541

Epoch: 5| Step: 10
Training loss: 2.2397170066833496
Validation loss: 1.969686842733814

Epoch: 36| Step: 0
Training loss: 2.9318206310272217
Validation loss: 1.98918451416877

Epoch: 5| Step: 1
Training loss: 2.56378173828125
Validation loss: 1.9884555544904483

Epoch: 5| Step: 2
Training loss: 2.3330512046813965
Validation loss: 1.9708398977915447

Epoch: 5| Step: 3
Training loss: 1.9833799600601196
Validation loss: 1.9881808270690262

Epoch: 5| Step: 4
Training loss: 2.869337558746338
Validation loss: 1.9828563364603187

Epoch: 5| Step: 5
Training loss: 2.3827383518218994
Validation loss: 1.9856594390766595

Epoch: 5| Step: 6
Training loss: 2.2332236766815186
Validation loss: 1.9657409255222609

Epoch: 5| Step: 7
Training loss: 1.49861478805542
Validation loss: 1.9735386627976612

Epoch: 5| Step: 8
Training loss: 2.769261360168457
Validation loss: 1.9965279563780753

Epoch: 5| Step: 9
Training loss: 2.254884719848633
Validation loss: 1.9920975995320145

Epoch: 5| Step: 10
Training loss: 2.432602882385254
Validation loss: 1.998754624397524

Epoch: 37| Step: 0
Training loss: 2.749145984649658
Validation loss: 1.9979651563911027

Epoch: 5| Step: 1
Training loss: 1.9683643579483032
Validation loss: 1.9864758317188551

Epoch: 5| Step: 2
Training loss: 2.480358362197876
Validation loss: 1.983282050778789

Epoch: 5| Step: 3
Training loss: 2.4654359817504883
Validation loss: 1.9650069577719576

Epoch: 5| Step: 4
Training loss: 2.13417387008667
Validation loss: 1.9935897986094158

Epoch: 5| Step: 5
Training loss: 2.658923864364624
Validation loss: 1.9749856277178692

Epoch: 5| Step: 6
Training loss: 2.0744564533233643
Validation loss: 2.002909974385333

Epoch: 5| Step: 7
Training loss: 2.5501582622528076
Validation loss: 1.9981239406011437

Epoch: 5| Step: 8
Training loss: 2.3949615955352783
Validation loss: 2.0007036885907574

Epoch: 5| Step: 9
Training loss: 2.8050642013549805
Validation loss: 1.9772967753871795

Epoch: 5| Step: 10
Training loss: 1.7930872440338135
Validation loss: 1.9979197235517605

Epoch: 38| Step: 0
Training loss: 1.9592174291610718
Validation loss: 1.9760948675934986

Epoch: 5| Step: 1
Training loss: 2.611140489578247
Validation loss: 1.995602148835377

Epoch: 5| Step: 2
Training loss: 2.0693342685699463
Validation loss: 2.004343335346509

Epoch: 5| Step: 3
Training loss: 1.8888213634490967
Validation loss: 1.997971450128863

Epoch: 5| Step: 4
Training loss: 2.694967746734619
Validation loss: 1.9945492180444861

Epoch: 5| Step: 5
Training loss: 3.3389618396759033
Validation loss: 1.9978160499244608

Epoch: 5| Step: 6
Training loss: 1.9890196323394775
Validation loss: 2.009748725480931

Epoch: 5| Step: 7
Training loss: 2.3514790534973145
Validation loss: 1.9919936144223778

Epoch: 5| Step: 8
Training loss: 1.9263317584991455
Validation loss: 1.987700234177292

Epoch: 5| Step: 9
Training loss: 2.5781443119049072
Validation loss: 1.990751447216157

Epoch: 5| Step: 10
Training loss: 2.778473377227783
Validation loss: 1.9796114275532384

Epoch: 39| Step: 0
Training loss: 2.4057016372680664
Validation loss: 1.9896139637116463

Epoch: 5| Step: 1
Training loss: 2.5909101963043213
Validation loss: 1.9846535177641018

Epoch: 5| Step: 2
Training loss: 2.0882041454315186
Validation loss: 1.9873955147240752

Epoch: 5| Step: 3
Training loss: 2.271864414215088
Validation loss: 1.9748464489495883

Epoch: 5| Step: 4
Training loss: 2.1803109645843506
Validation loss: 1.9835239507818734

Epoch: 5| Step: 5
Training loss: 2.4167189598083496
Validation loss: 1.98744458793312

Epoch: 5| Step: 6
Training loss: 1.9371373653411865
Validation loss: 1.9857948044294953

Epoch: 5| Step: 7
Training loss: 2.6734042167663574
Validation loss: 1.991561302574732

Epoch: 5| Step: 8
Training loss: 2.716688632965088
Validation loss: 1.95923355830613

Epoch: 5| Step: 9
Training loss: 2.2957518100738525
Validation loss: 1.9849385087208082

Epoch: 5| Step: 10
Training loss: 2.482937812805176
Validation loss: 1.9833022920034264

Epoch: 40| Step: 0
Training loss: 2.4735240936279297
Validation loss: 1.9798635949370682

Epoch: 5| Step: 1
Training loss: 2.8324227333068848
Validation loss: 1.9604318347028507

Epoch: 5| Step: 2
Training loss: 1.8742650747299194
Validation loss: 1.9812965034156718

Epoch: 5| Step: 3
Training loss: 1.7269366979599
Validation loss: 1.9836761233627156

Epoch: 5| Step: 4
Training loss: 2.2948474884033203
Validation loss: 1.986141372752446

Epoch: 5| Step: 5
Training loss: 2.9850950241088867
Validation loss: 1.9845278211819228

Epoch: 5| Step: 6
Training loss: 2.751664400100708
Validation loss: 1.9770894653053694

Epoch: 5| Step: 7
Training loss: 2.229203701019287
Validation loss: 1.9910982885668356

Epoch: 5| Step: 8
Training loss: 2.108670711517334
Validation loss: 1.9637957580627934

Epoch: 5| Step: 9
Training loss: 2.5398545265197754
Validation loss: 1.9860905460132066

Epoch: 5| Step: 10
Training loss: 2.111577272415161
Validation loss: 1.9851550389361639

Epoch: 41| Step: 0
Training loss: 2.1132020950317383
Validation loss: 1.9786615410158712

Epoch: 5| Step: 1
Training loss: 2.7989554405212402
Validation loss: 1.9689825196419992

Epoch: 5| Step: 2
Training loss: 1.9041898250579834
Validation loss: 1.9818745210606565

Epoch: 5| Step: 3
Training loss: 2.269026279449463
Validation loss: 1.9817017419363863

Epoch: 5| Step: 4
Training loss: 1.8774020671844482
Validation loss: 1.9869355053030036

Epoch: 5| Step: 5
Training loss: 2.312354803085327
Validation loss: 1.983180010190574

Epoch: 5| Step: 6
Training loss: 2.505897283554077
Validation loss: 1.9904106663119407

Epoch: 5| Step: 7
Training loss: 2.4023919105529785
Validation loss: 1.975316027159332

Epoch: 5| Step: 8
Training loss: 2.8535027503967285
Validation loss: 1.967584276712069

Epoch: 5| Step: 9
Training loss: 2.3844761848449707
Validation loss: 1.9662959191106981

Epoch: 5| Step: 10
Training loss: 2.603820562362671
Validation loss: 1.971143768679711

Epoch: 42| Step: 0
Training loss: 2.0794849395751953
Validation loss: 1.9871670071796705

Epoch: 5| Step: 1
Training loss: 2.020153522491455
Validation loss: 1.9782758464095413

Epoch: 5| Step: 2
Training loss: 2.3720176219940186
Validation loss: 1.980261302763416

Epoch: 5| Step: 3
Training loss: 2.817762851715088
Validation loss: 1.9616809301478888

Epoch: 5| Step: 4
Training loss: 2.4784960746765137
Validation loss: 1.990714321854294

Epoch: 5| Step: 5
Training loss: 2.5475616455078125
Validation loss: 1.9849989375760477

Epoch: 5| Step: 6
Training loss: 2.5932106971740723
Validation loss: 1.9831531970731673

Epoch: 5| Step: 7
Training loss: 1.9817638397216797
Validation loss: 1.9903280401742587

Epoch: 5| Step: 8
Training loss: 3.1016881465911865
Validation loss: 1.9698084400546165

Epoch: 5| Step: 9
Training loss: 1.7161073684692383
Validation loss: 1.9912475321882515

Epoch: 5| Step: 10
Training loss: 2.1379053592681885
Validation loss: 1.9780101032667263

Epoch: 43| Step: 0
Training loss: 2.2507858276367188
Validation loss: 1.9661148722453783

Epoch: 5| Step: 1
Training loss: 2.386322021484375
Validation loss: 1.9785542834189631

Epoch: 5| Step: 2
Training loss: 2.1990551948547363
Validation loss: 1.9825492930668656

Epoch: 5| Step: 3
Training loss: 2.5681099891662598
Validation loss: 1.9784972116511355

Epoch: 5| Step: 4
Training loss: 2.5507209300994873
Validation loss: 1.9879122985306608

Epoch: 5| Step: 5
Training loss: 2.146014928817749
Validation loss: 1.989115535572011

Epoch: 5| Step: 6
Training loss: 2.301783800125122
Validation loss: 1.9725298791803338

Epoch: 5| Step: 7
Training loss: 2.6379153728485107
Validation loss: 1.9777173521698161

Epoch: 5| Step: 8
Training loss: 2.293705701828003
Validation loss: 1.9694613333671325

Epoch: 5| Step: 9
Training loss: 2.157147169113159
Validation loss: 1.9803513314134331

Epoch: 5| Step: 10
Training loss: 2.3615591526031494
Validation loss: 1.978910421812406

Epoch: 44| Step: 0
Training loss: 2.6926193237304688
Validation loss: 1.9645887113386584

Epoch: 5| Step: 1
Training loss: 2.3023698329925537
Validation loss: 1.9644899470831758

Epoch: 5| Step: 2
Training loss: 2.084789752960205
Validation loss: 1.9633064193110312

Epoch: 5| Step: 3
Training loss: 2.1363749504089355
Validation loss: 1.9849676444966307

Epoch: 5| Step: 4
Training loss: 3.0656774044036865
Validation loss: 1.9784814260339225

Epoch: 5| Step: 5
Training loss: 1.9775737524032593
Validation loss: 2.000908633714081

Epoch: 5| Step: 6
Training loss: 2.751352071762085
Validation loss: 1.9871902773457188

Epoch: 5| Step: 7
Training loss: 2.694587230682373
Validation loss: 1.9884824291352303

Epoch: 5| Step: 8
Training loss: 2.142796277999878
Validation loss: 1.9979685916695544

Epoch: 5| Step: 9
Training loss: 2.307313919067383
Validation loss: 1.9905414606935234

Epoch: 5| Step: 10
Training loss: 1.7248643636703491
Validation loss: 1.9914485690414265

Epoch: 45| Step: 0
Training loss: 2.6275126934051514
Validation loss: 1.997809963841592

Epoch: 5| Step: 1
Training loss: 2.473165273666382
Validation loss: 1.9914291468999719

Epoch: 5| Step: 2
Training loss: 2.6205837726593018
Validation loss: 1.9945911130597513

Epoch: 5| Step: 3
Training loss: 3.1021485328674316
Validation loss: 1.9682679381421817

Epoch: 5| Step: 4
Training loss: 2.762923240661621
Validation loss: 1.9810501452415221

Epoch: 5| Step: 5
Training loss: 2.2756195068359375
Validation loss: 1.9729262423771683

Epoch: 5| Step: 6
Training loss: 2.1953094005584717
Validation loss: 1.984447512575375

Epoch: 5| Step: 7
Training loss: 1.8508789539337158
Validation loss: 1.9630818161913144

Epoch: 5| Step: 8
Training loss: 1.847252607345581
Validation loss: 1.972625583730718

Epoch: 5| Step: 9
Training loss: 1.8029758930206299
Validation loss: 1.969777846849093

Epoch: 5| Step: 10
Training loss: 2.232333183288574
Validation loss: 1.9641808617499568

Epoch: 46| Step: 0
Training loss: 2.460537910461426
Validation loss: 1.9527791546237083

Epoch: 5| Step: 1
Training loss: 2.4516561031341553
Validation loss: 1.9733075570034724

Epoch: 5| Step: 2
Training loss: 2.118472099304199
Validation loss: 1.96645740924343

Epoch: 5| Step: 3
Training loss: 2.699476957321167
Validation loss: 1.9789544510585007

Epoch: 5| Step: 4
Training loss: 2.2627131938934326
Validation loss: 1.973789054860351

Epoch: 5| Step: 5
Training loss: 1.8296695947647095
Validation loss: 1.9678938882325285

Epoch: 5| Step: 6
Training loss: 2.1059868335723877
Validation loss: 1.9457245001228907

Epoch: 5| Step: 7
Training loss: 2.320194959640503
Validation loss: 1.9790501722725489

Epoch: 5| Step: 8
Training loss: 2.5617024898529053
Validation loss: 1.9618587006804764

Epoch: 5| Step: 9
Training loss: 2.344348430633545
Validation loss: 1.9557831671930128

Epoch: 5| Step: 10
Training loss: 2.6093175411224365
Validation loss: 1.9609261328174221

Epoch: 47| Step: 0
Training loss: 2.3481650352478027
Validation loss: 1.9656307133295203

Epoch: 5| Step: 1
Training loss: 2.943063259124756
Validation loss: 1.9601069573433167

Epoch: 5| Step: 2
Training loss: 2.383409023284912
Validation loss: 1.9662591462494226

Epoch: 5| Step: 3
Training loss: 2.166457414627075
Validation loss: 1.9621827397295224

Epoch: 5| Step: 4
Training loss: 1.6327524185180664
Validation loss: 1.9695630201729395

Epoch: 5| Step: 5
Training loss: 2.5549159049987793
Validation loss: 1.9747729455271075

Epoch: 5| Step: 6
Training loss: 2.8998265266418457
Validation loss: 1.953027594474054

Epoch: 5| Step: 7
Training loss: 1.9499887228012085
Validation loss: 1.9601904961370653

Epoch: 5| Step: 8
Training loss: 2.6099069118499756
Validation loss: 1.9544597389877483

Epoch: 5| Step: 9
Training loss: 2.290574789047241
Validation loss: 1.9573845042977283

Epoch: 5| Step: 10
Training loss: 1.92288076877594
Validation loss: 1.9394662328945693

Epoch: 48| Step: 0
Training loss: 2.9868104457855225
Validation loss: 1.9601756488123248

Epoch: 5| Step: 1
Training loss: 2.337794542312622
Validation loss: 1.954450309917491

Epoch: 5| Step: 2
Training loss: 2.454867362976074
Validation loss: 1.9629227833081317

Epoch: 5| Step: 3
Training loss: 2.511751890182495
Validation loss: 1.947461264107817

Epoch: 5| Step: 4
Training loss: 2.2292206287384033
Validation loss: 1.9476736566071868

Epoch: 5| Step: 5
Training loss: 2.3375937938690186
Validation loss: 1.9580970759032874

Epoch: 5| Step: 6
Training loss: 2.0649209022521973
Validation loss: 1.9516711158137168

Epoch: 5| Step: 7
Training loss: 1.9559885263442993
Validation loss: 1.9466303317777571

Epoch: 5| Step: 8
Training loss: 1.8263187408447266
Validation loss: 1.952495212196022

Epoch: 5| Step: 9
Training loss: 2.5193417072296143
Validation loss: 1.9415095929176576

Epoch: 5| Step: 10
Training loss: 2.4522273540496826
Validation loss: 1.9458284454960977

Epoch: 49| Step: 0
Training loss: 2.4680638313293457
Validation loss: 1.9645924875813146

Epoch: 5| Step: 1
Training loss: 2.346895217895508
Validation loss: 1.944347922519971

Epoch: 5| Step: 2
Training loss: 1.9386593103408813
Validation loss: 1.954736453230663

Epoch: 5| Step: 3
Training loss: 2.6756134033203125
Validation loss: 1.9443667998877905

Epoch: 5| Step: 4
Training loss: 2.505636692047119
Validation loss: 1.9515637095256517

Epoch: 5| Step: 5
Training loss: 2.323230743408203
Validation loss: 1.948994085352908

Epoch: 5| Step: 6
Training loss: 2.2256827354431152
Validation loss: 1.9248633538523028

Epoch: 5| Step: 7
Training loss: 2.530961513519287
Validation loss: 1.9591047199823524

Epoch: 5| Step: 8
Training loss: 2.4422435760498047
Validation loss: 1.9578308802779003

Epoch: 5| Step: 9
Training loss: 2.038186550140381
Validation loss: 1.920386229791949

Epoch: 5| Step: 10
Training loss: 2.033754587173462
Validation loss: 1.931586270691246

Epoch: 50| Step: 0
Training loss: 2.225736379623413
Validation loss: 1.947553357770366

Epoch: 5| Step: 1
Training loss: 2.375614643096924
Validation loss: 1.9419090632469422

Epoch: 5| Step: 2
Training loss: 2.6334128379821777
Validation loss: 1.9680492595959735

Epoch: 5| Step: 3
Training loss: 1.911695122718811
Validation loss: 1.959419511979626

Epoch: 5| Step: 4
Training loss: 2.0756137371063232
Validation loss: 1.9483675956726074

Epoch: 5| Step: 5
Training loss: 2.6939759254455566
Validation loss: 1.9325088377921813

Epoch: 5| Step: 6
Training loss: 1.832764983177185
Validation loss: 1.9487229265192503

Epoch: 5| Step: 7
Training loss: 2.0732011795043945
Validation loss: 1.962524329462359

Epoch: 5| Step: 8
Training loss: 2.570678234100342
Validation loss: 1.9416561870164768

Epoch: 5| Step: 9
Training loss: 2.676485538482666
Validation loss: 1.944825864607288

Epoch: 5| Step: 10
Training loss: 2.627694606781006
Validation loss: 1.9402303875133555

Epoch: 51| Step: 0
Training loss: 1.7897975444793701
Validation loss: 1.9341522314215218

Epoch: 5| Step: 1
Training loss: 2.6159136295318604
Validation loss: 1.937501093392731

Epoch: 5| Step: 2
Training loss: 2.7755331993103027
Validation loss: 1.9693807094327864

Epoch: 5| Step: 3
Training loss: 2.1409249305725098
Validation loss: 1.9617846755571262

Epoch: 5| Step: 4
Training loss: 2.438581943511963
Validation loss: 1.9591328751656316

Epoch: 5| Step: 5
Training loss: 1.9226558208465576
Validation loss: 1.9483358565197195

Epoch: 5| Step: 6
Training loss: 2.9463162422180176
Validation loss: 1.9639795980145853

Epoch: 5| Step: 7
Training loss: 2.443143367767334
Validation loss: 1.955665365342171

Epoch: 5| Step: 8
Training loss: 2.3101296424865723
Validation loss: 1.9537342081787765

Epoch: 5| Step: 9
Training loss: 1.8335717916488647
Validation loss: 1.946601980475969

Epoch: 5| Step: 10
Training loss: 2.416830539703369
Validation loss: 1.9612982298738213

Epoch: 52| Step: 0
Training loss: 2.1659722328186035
Validation loss: 1.9633634410878664

Epoch: 5| Step: 1
Training loss: 2.4141793251037598
Validation loss: 1.9547491047971992

Epoch: 5| Step: 2
Training loss: 2.1205379962921143
Validation loss: 1.9569666936833372

Epoch: 5| Step: 3
Training loss: 2.1813411712646484
Validation loss: 1.9559510459182083

Epoch: 5| Step: 4
Training loss: 2.6314187049865723
Validation loss: 1.9629506603364022

Epoch: 5| Step: 5
Training loss: 2.2457449436187744
Validation loss: 1.973749601712791

Epoch: 5| Step: 6
Training loss: 2.357997179031372
Validation loss: 1.9554413569870817

Epoch: 5| Step: 7
Training loss: 2.791623592376709
Validation loss: 1.9545797481331775

Epoch: 5| Step: 8
Training loss: 2.2369420528411865
Validation loss: 1.96582079702808

Epoch: 5| Step: 9
Training loss: 1.854373574256897
Validation loss: 1.971013012752738

Epoch: 5| Step: 10
Training loss: 2.574810743331909
Validation loss: 1.9716596731575586

Epoch: 53| Step: 0
Training loss: 2.751473903656006
Validation loss: 1.9790407239749868

Epoch: 5| Step: 1
Training loss: 1.9884815216064453
Validation loss: 1.9501933410603514

Epoch: 5| Step: 2
Training loss: 1.9126110076904297
Validation loss: 1.9648244355314521

Epoch: 5| Step: 3
Training loss: 2.5441832542419434
Validation loss: 1.9487917192520634

Epoch: 5| Step: 4
Training loss: 2.0815553665161133
Validation loss: 1.9563525351144935

Epoch: 5| Step: 5
Training loss: 1.6976124048233032
Validation loss: 1.950784142299365

Epoch: 5| Step: 6
Training loss: 2.909956693649292
Validation loss: 1.9415472771531792

Epoch: 5| Step: 7
Training loss: 3.0142223834991455
Validation loss: 1.9480147874483498

Epoch: 5| Step: 8
Training loss: 1.3586946725845337
Validation loss: 1.9623165617706955

Epoch: 5| Step: 9
Training loss: 2.580699920654297
Validation loss: 1.9496040344238281

Epoch: 5| Step: 10
Training loss: 2.7788782119750977
Validation loss: 1.9487161303079257

Epoch: 54| Step: 0
Training loss: 1.933258056640625
Validation loss: 1.9427676354685137

Epoch: 5| Step: 1
Training loss: 1.9512745141983032
Validation loss: 1.959392165624967

Epoch: 5| Step: 2
Training loss: 2.7133431434631348
Validation loss: 1.9437026477629138

Epoch: 5| Step: 3
Training loss: 2.228891372680664
Validation loss: 1.9436302082512968

Epoch: 5| Step: 4
Training loss: 2.0565731525421143
Validation loss: 1.9480283798709992

Epoch: 5| Step: 5
Training loss: 2.0610718727111816
Validation loss: 1.9476194586805118

Epoch: 5| Step: 6
Training loss: 2.296663284301758
Validation loss: 1.9400330205117502

Epoch: 5| Step: 7
Training loss: 2.584740161895752
Validation loss: 1.940762427545363

Epoch: 5| Step: 8
Training loss: 2.5163257122039795
Validation loss: 1.946290462247787

Epoch: 5| Step: 9
Training loss: 2.7098028659820557
Validation loss: 1.9526771012172903

Epoch: 5| Step: 10
Training loss: 2.576443672180176
Validation loss: 1.9336032713613203

Epoch: 55| Step: 0
Training loss: 2.7765188217163086
Validation loss: 1.950540698984618

Epoch: 5| Step: 1
Training loss: 3.181959629058838
Validation loss: 1.9480770813521517

Epoch: 5| Step: 2
Training loss: 1.6716874837875366
Validation loss: 1.9532513387741581

Epoch: 5| Step: 3
Training loss: 1.9735281467437744
Validation loss: 1.9638422689130228

Epoch: 5| Step: 4
Training loss: 2.31563138961792
Validation loss: 1.9498798411379579

Epoch: 5| Step: 5
Training loss: 1.8345104455947876
Validation loss: 1.9603635405981412

Epoch: 5| Step: 6
Training loss: 1.443345069885254
Validation loss: 1.961560421092536

Epoch: 5| Step: 7
Training loss: 2.7241311073303223
Validation loss: 1.9526519083207654

Epoch: 5| Step: 8
Training loss: 2.118069887161255
Validation loss: 1.9512341817220051

Epoch: 5| Step: 9
Training loss: 3.036189079284668
Validation loss: 1.9520770054991528

Epoch: 5| Step: 10
Training loss: 2.35888671875
Validation loss: 1.9397512443604008

Epoch: 56| Step: 0
Training loss: 2.023564577102661
Validation loss: 1.9478461460400653

Epoch: 5| Step: 1
Training loss: 2.9617602825164795
Validation loss: 1.9453532272769558

Epoch: 5| Step: 2
Training loss: 2.184563159942627
Validation loss: 1.9606137326968613

Epoch: 5| Step: 3
Training loss: 1.8954750299453735
Validation loss: 1.9438466128482614

Epoch: 5| Step: 4
Training loss: 2.2450249195098877
Validation loss: 1.9572965073329147

Epoch: 5| Step: 5
Training loss: 3.002593517303467
Validation loss: 1.968256732468964

Epoch: 5| Step: 6
Training loss: 1.870700478553772
Validation loss: 1.9679476368811823

Epoch: 5| Step: 7
Training loss: 1.9553979635238647
Validation loss: 1.963829783983128

Epoch: 5| Step: 8
Training loss: 2.777564287185669
Validation loss: 1.960998482601617

Epoch: 5| Step: 9
Training loss: 2.3506882190704346
Validation loss: 1.973024788723197

Epoch: 5| Step: 10
Training loss: 2.0504817962646484
Validation loss: 1.9629856207037484

Epoch: 57| Step: 0
Training loss: 2.25160813331604
Validation loss: 1.9769230863099456

Epoch: 5| Step: 1
Training loss: 2.793835163116455
Validation loss: 1.9613436409222182

Epoch: 5| Step: 2
Training loss: 2.3672194480895996
Validation loss: 1.9643791029530187

Epoch: 5| Step: 3
Training loss: 2.619804859161377
Validation loss: 1.9745260835975729

Epoch: 5| Step: 4
Training loss: 2.318504571914673
Validation loss: 1.9701440090774207

Epoch: 5| Step: 5
Training loss: 2.345064878463745
Validation loss: 1.9589050610860188

Epoch: 5| Step: 6
Training loss: 1.9789034128189087
Validation loss: 1.9606056803016252

Epoch: 5| Step: 7
Training loss: 1.5919535160064697
Validation loss: 1.957835643522201

Epoch: 5| Step: 8
Training loss: 2.1256020069122314
Validation loss: 1.9616717805144608

Epoch: 5| Step: 9
Training loss: 2.754838705062866
Validation loss: 1.9667042839911677

Epoch: 5| Step: 10
Training loss: 2.140242099761963
Validation loss: 1.937986255973898

Epoch: 58| Step: 0
Training loss: 2.549976348876953
Validation loss: 1.9595198400558964

Epoch: 5| Step: 1
Training loss: 2.1461873054504395
Validation loss: 1.974941817663049

Epoch: 5| Step: 2
Training loss: 2.143062114715576
Validation loss: 1.9522249852457354

Epoch: 5| Step: 3
Training loss: 1.4261099100112915
Validation loss: 1.9575176649196173

Epoch: 5| Step: 4
Training loss: 2.208078145980835
Validation loss: 1.9382604552853493

Epoch: 5| Step: 5
Training loss: 2.2349910736083984
Validation loss: 1.9550123714631604

Epoch: 5| Step: 6
Training loss: 2.8144466876983643
Validation loss: 1.9358825068319998

Epoch: 5| Step: 7
Training loss: 2.2562899589538574
Validation loss: 1.9535235179367887

Epoch: 5| Step: 8
Training loss: 2.1040573120117188
Validation loss: 1.9407773517793225

Epoch: 5| Step: 9
Training loss: 2.623169422149658
Validation loss: 1.9421893024957309

Epoch: 5| Step: 10
Training loss: 2.945474147796631
Validation loss: 1.9298642143126457

Epoch: 59| Step: 0
Training loss: 2.4754319190979004
Validation loss: 1.9541306008574784

Epoch: 5| Step: 1
Training loss: 2.1640920639038086
Validation loss: 1.9489166813512002

Epoch: 5| Step: 2
Training loss: 2.107780933380127
Validation loss: 1.9478368066972302

Epoch: 5| Step: 3
Training loss: 2.8648135662078857
Validation loss: 1.934898502083235

Epoch: 5| Step: 4
Training loss: 1.9381799697875977
Validation loss: 1.938770850499471

Epoch: 5| Step: 5
Training loss: 2.2429096698760986
Validation loss: 1.9551638582701325

Epoch: 5| Step: 6
Training loss: 2.392961263656616
Validation loss: 1.9617791124569472

Epoch: 5| Step: 7
Training loss: 2.4271457195281982
Validation loss: 1.9412238213323778

Epoch: 5| Step: 8
Training loss: 2.073843002319336
Validation loss: 1.958635037945163

Epoch: 5| Step: 9
Training loss: 1.9723670482635498
Validation loss: 1.9570442912399129

Epoch: 5| Step: 10
Training loss: 2.7826507091522217
Validation loss: 1.9452397195241784

Epoch: 60| Step: 0
Training loss: 2.129542827606201
Validation loss: 1.9375033852874592

Epoch: 5| Step: 1
Training loss: 2.272432804107666
Validation loss: 1.9403002697934386

Epoch: 5| Step: 2
Training loss: 2.5864624977111816
Validation loss: 1.945899526278178

Epoch: 5| Step: 3
Training loss: 2.0560145378112793
Validation loss: 1.9478523321049188

Epoch: 5| Step: 4
Training loss: 2.4038240909576416
Validation loss: 1.9560552976464713

Epoch: 5| Step: 5
Training loss: 2.1677846908569336
Validation loss: 1.9684475609051284

Epoch: 5| Step: 6
Training loss: 2.176107883453369
Validation loss: 1.9378248594140495

Epoch: 5| Step: 7
Training loss: 2.541921615600586
Validation loss: 1.9378777216839533

Epoch: 5| Step: 8
Training loss: 1.9670988321304321
Validation loss: 1.9712715918017971

Epoch: 5| Step: 9
Training loss: 2.4198193550109863
Validation loss: 1.9555175586413311

Epoch: 5| Step: 10
Training loss: 2.552016258239746
Validation loss: 1.9562189668737433

Epoch: 61| Step: 0
Training loss: 2.1480612754821777
Validation loss: 1.9655487383565595

Epoch: 5| Step: 1
Training loss: 2.103245973587036
Validation loss: 1.9436124345307708

Epoch: 5| Step: 2
Training loss: 2.2886059284210205
Validation loss: 1.9506539452460505

Epoch: 5| Step: 3
Training loss: 2.5497524738311768
Validation loss: 1.961494145854827

Epoch: 5| Step: 4
Training loss: 2.3668508529663086
Validation loss: 1.9655357791531471

Epoch: 5| Step: 5
Training loss: 2.118896007537842
Validation loss: 1.9580537811402352

Epoch: 5| Step: 6
Training loss: 2.586069107055664
Validation loss: 1.9572283683284637

Epoch: 5| Step: 7
Training loss: 2.2283976078033447
Validation loss: 1.973142808483493

Epoch: 5| Step: 8
Training loss: 2.9287023544311523
Validation loss: 1.9623945118278585

Epoch: 5| Step: 9
Training loss: 1.68277907371521
Validation loss: 1.9557980004177298

Epoch: 5| Step: 10
Training loss: 2.2308804988861084
Validation loss: 1.947390975490693

Epoch: 62| Step: 0
Training loss: 1.9736782312393188
Validation loss: 1.9773803885265062

Epoch: 5| Step: 1
Training loss: 2.405224561691284
Validation loss: 1.9736050572446597

Epoch: 5| Step: 2
Training loss: 2.647387742996216
Validation loss: 1.9460923082085066

Epoch: 5| Step: 3
Training loss: 2.4046876430511475
Validation loss: 1.9635527954306653

Epoch: 5| Step: 4
Training loss: 2.7213923931121826
Validation loss: 1.9474790198828584

Epoch: 5| Step: 5
Training loss: 2.8678040504455566
Validation loss: 1.9393720755013086

Epoch: 5| Step: 6
Training loss: 1.9941222667694092
Validation loss: 1.960658775862827

Epoch: 5| Step: 7
Training loss: 2.026459217071533
Validation loss: 1.9539552978290025

Epoch: 5| Step: 8
Training loss: 1.8161098957061768
Validation loss: 1.9476204149184688

Epoch: 5| Step: 9
Training loss: 2.3032045364379883
Validation loss: 1.9718573119050713

Epoch: 5| Step: 10
Training loss: 1.9768216609954834
Validation loss: 1.9704258954653175

Epoch: 63| Step: 0
Training loss: 1.8281424045562744
Validation loss: 1.9504287678708312

Epoch: 5| Step: 1
Training loss: 2.3152058124542236
Validation loss: 1.9656368647852251

Epoch: 5| Step: 2
Training loss: 2.5248749256134033
Validation loss: 1.946388513811173

Epoch: 5| Step: 3
Training loss: 2.6590583324432373
Validation loss: 1.9606995146761659

Epoch: 5| Step: 4
Training loss: 2.1450695991516113
Validation loss: 1.9619376685029717

Epoch: 5| Step: 5
Training loss: 2.7027955055236816
Validation loss: 1.9822162787119548

Epoch: 5| Step: 6
Training loss: 2.100369691848755
Validation loss: 1.9557669944660638

Epoch: 5| Step: 7
Training loss: 2.1981570720672607
Validation loss: 1.9412431806646369

Epoch: 5| Step: 8
Training loss: 2.022021532058716
Validation loss: 1.9524587431261617

Epoch: 5| Step: 9
Training loss: 2.043022632598877
Validation loss: 1.962303223148469

Epoch: 5| Step: 10
Training loss: 2.7870538234710693
Validation loss: 1.9550377092053812

Epoch: 64| Step: 0
Training loss: 2.5562968254089355
Validation loss: 1.942181324446073

Epoch: 5| Step: 1
Training loss: 2.2248172760009766
Validation loss: 1.9660925519081853

Epoch: 5| Step: 2
Training loss: 2.4420535564422607
Validation loss: 1.9694400705317014

Epoch: 5| Step: 3
Training loss: 2.471703052520752
Validation loss: 1.9633756760627992

Epoch: 5| Step: 4
Training loss: 2.6123764514923096
Validation loss: 1.9588762611471198

Epoch: 5| Step: 5
Training loss: 1.6981995105743408
Validation loss: 1.969678109691989

Epoch: 5| Step: 6
Training loss: 1.610734224319458
Validation loss: 1.9723296344921153

Epoch: 5| Step: 7
Training loss: 2.4771385192871094
Validation loss: 1.9478810576982395

Epoch: 5| Step: 8
Training loss: 2.2201154232025146
Validation loss: 1.9650651485689226

Epoch: 5| Step: 9
Training loss: 2.633810520172119
Validation loss: 1.9548355469139673

Epoch: 5| Step: 10
Training loss: 2.142094373703003
Validation loss: 1.950782504132999

Epoch: 65| Step: 0
Training loss: 1.7669786214828491
Validation loss: 1.9483274977694276

Epoch: 5| Step: 1
Training loss: 2.6944594383239746
Validation loss: 1.9578277616090671

Epoch: 5| Step: 2
Training loss: 2.4379043579101562
Validation loss: 1.9573664319130681

Epoch: 5| Step: 3
Training loss: 2.8896708488464355
Validation loss: 1.9641996340085102

Epoch: 5| Step: 4
Training loss: 1.976976990699768
Validation loss: 1.965537360919419

Epoch: 5| Step: 5
Training loss: 1.9187034368515015
Validation loss: 1.9685417311165923

Epoch: 5| Step: 6
Training loss: 1.981788992881775
Validation loss: 1.9604498160782682

Epoch: 5| Step: 7
Training loss: 2.129136562347412
Validation loss: 1.9693284444911505

Epoch: 5| Step: 8
Training loss: 2.3092827796936035
Validation loss: 1.9664381037476242

Epoch: 5| Step: 9
Training loss: 2.7258918285369873
Validation loss: 1.9611719359633744

Epoch: 5| Step: 10
Training loss: 2.3475258350372314
Validation loss: 1.9505555950185305

Epoch: 66| Step: 0
Training loss: 1.9760801792144775
Validation loss: 1.9643547727215676

Epoch: 5| Step: 1
Training loss: 2.3032851219177246
Validation loss: 1.946778053878456

Epoch: 5| Step: 2
Training loss: 2.3196792602539062
Validation loss: 1.9524650394275624

Epoch: 5| Step: 3
Training loss: 2.7668557167053223
Validation loss: 1.9489587558213102

Epoch: 5| Step: 4
Training loss: 2.538784980773926
Validation loss: 1.966147889373123

Epoch: 5| Step: 5
Training loss: 2.633735418319702
Validation loss: 1.9427776926307267

Epoch: 5| Step: 6
Training loss: 1.9262275695800781
Validation loss: 1.9556542417054534

Epoch: 5| Step: 7
Training loss: 2.2094666957855225
Validation loss: 1.941523410940683

Epoch: 5| Step: 8
Training loss: 1.840049386024475
Validation loss: 1.9390387855550295

Epoch: 5| Step: 9
Training loss: 2.2215912342071533
Validation loss: 1.957339604695638

Epoch: 5| Step: 10
Training loss: 2.428140163421631
Validation loss: 1.9522478247201571

Epoch: 67| Step: 0
Training loss: 1.8653062582015991
Validation loss: 1.9674340191707815

Epoch: 5| Step: 1
Training loss: 2.2517905235290527
Validation loss: 1.963471898468592

Epoch: 5| Step: 2
Training loss: 1.9546161890029907
Validation loss: 1.971203678397722

Epoch: 5| Step: 3
Training loss: 2.5496432781219482
Validation loss: 1.963938828437559

Epoch: 5| Step: 4
Training loss: 2.503615379333496
Validation loss: 1.9497470099438903

Epoch: 5| Step: 5
Training loss: 2.5123252868652344
Validation loss: 1.9638740785660282

Epoch: 5| Step: 6
Training loss: 2.3537726402282715
Validation loss: 1.9525397862157514

Epoch: 5| Step: 7
Training loss: 2.5722858905792236
Validation loss: 1.9633390647108837

Epoch: 5| Step: 8
Training loss: 2.017326831817627
Validation loss: 1.957098312275384

Epoch: 5| Step: 9
Training loss: 1.8234493732452393
Validation loss: 1.9601952721995692

Epoch: 5| Step: 10
Training loss: 2.6750986576080322
Validation loss: 1.9497740012343212

Epoch: 68| Step: 0
Training loss: 2.074204206466675
Validation loss: 1.9475619562210575

Epoch: 5| Step: 1
Training loss: 2.5210623741149902
Validation loss: 1.9723816558878908

Epoch: 5| Step: 2
Training loss: 2.312112808227539
Validation loss: 1.964695809989847

Epoch: 5| Step: 3
Training loss: 2.1217005252838135
Validation loss: 1.9807101295840355

Epoch: 5| Step: 4
Training loss: 2.271559953689575
Validation loss: 1.9820022198461718

Epoch: 5| Step: 5
Training loss: 2.135903835296631
Validation loss: 1.9850410389643844

Epoch: 5| Step: 6
Training loss: 2.610398530960083
Validation loss: 1.9818497768012426

Epoch: 5| Step: 7
Training loss: 2.584148406982422
Validation loss: 1.9807461846259333

Epoch: 5| Step: 8
Training loss: 2.003340482711792
Validation loss: 1.968774321258709

Epoch: 5| Step: 9
Training loss: 2.12707257270813
Validation loss: 1.9848002618358982

Epoch: 5| Step: 10
Training loss: 2.6185004711151123
Validation loss: 1.9758940691589026

Epoch: 69| Step: 0
Training loss: 2.119520664215088
Validation loss: 1.9746379557476248

Epoch: 5| Step: 1
Training loss: 2.524022102355957
Validation loss: 1.9832197466204244

Epoch: 5| Step: 2
Training loss: 2.3589401245117188
Validation loss: 1.975246129497405

Epoch: 5| Step: 3
Training loss: 2.443694829940796
Validation loss: 1.9788237669134652

Epoch: 5| Step: 4
Training loss: 1.82748281955719
Validation loss: 1.9825642262735674

Epoch: 5| Step: 5
Training loss: 1.9956728219985962
Validation loss: 1.9658503481136855

Epoch: 5| Step: 6
Training loss: 2.3414382934570312
Validation loss: 1.9872828427181448

Epoch: 5| Step: 7
Training loss: 2.216564178466797
Validation loss: 1.9728751797829904

Epoch: 5| Step: 8
Training loss: 2.5092854499816895
Validation loss: 1.9651237713393344

Epoch: 5| Step: 9
Training loss: 2.371826171875
Validation loss: 1.977854464643745

Epoch: 5| Step: 10
Training loss: 2.351702928543091
Validation loss: 1.9910335028043358

Epoch: 70| Step: 0
Training loss: 2.3507602214813232
Validation loss: 1.9696913150049025

Epoch: 5| Step: 1
Training loss: 2.4529457092285156
Validation loss: 1.9725224318042878

Epoch: 5| Step: 2
Training loss: 2.9341797828674316
Validation loss: 1.9673977231466642

Epoch: 5| Step: 3
Training loss: 2.3814034461975098
Validation loss: 1.9678230542008595

Epoch: 5| Step: 4
Training loss: 1.6608383655548096
Validation loss: 1.9792392279512139

Epoch: 5| Step: 5
Training loss: 2.0685012340545654
Validation loss: 1.9604258306564823

Epoch: 5| Step: 6
Training loss: 2.329632520675659
Validation loss: 1.969176496228864

Epoch: 5| Step: 7
Training loss: 2.122617721557617
Validation loss: 1.967872888811173

Epoch: 5| Step: 8
Training loss: 2.67071270942688
Validation loss: 1.9669494423815

Epoch: 5| Step: 9
Training loss: 1.879712462425232
Validation loss: 1.9606893152318976

Epoch: 5| Step: 10
Training loss: 2.30254864692688
Validation loss: 1.94331108754681

Epoch: 71| Step: 0
Training loss: 1.7183854579925537
Validation loss: 1.97196739591578

Epoch: 5| Step: 1
Training loss: 2.39666748046875
Validation loss: 1.9691277063021095

Epoch: 5| Step: 2
Training loss: 2.2078464031219482
Validation loss: 1.9707628885904949

Epoch: 5| Step: 3
Training loss: 2.924189805984497
Validation loss: 1.9681590475061888

Epoch: 5| Step: 4
Training loss: 2.3630921840667725
Validation loss: 1.9662134083368445

Epoch: 5| Step: 5
Training loss: 1.8430083990097046
Validation loss: 1.964250426138601

Epoch: 5| Step: 6
Training loss: 2.4733288288116455
Validation loss: 1.9737760123386179

Epoch: 5| Step: 7
Training loss: 2.4779794216156006
Validation loss: 1.980894834764542

Epoch: 5| Step: 8
Training loss: 2.122743606567383
Validation loss: 1.9569467831683416

Epoch: 5| Step: 9
Training loss: 2.247251510620117
Validation loss: 1.95104815113929

Epoch: 5| Step: 10
Training loss: 2.1617555618286133
Validation loss: 1.9566443799644389

Epoch: 72| Step: 0
Training loss: 1.8940538167953491
Validation loss: 1.9594000488199212

Epoch: 5| Step: 1
Training loss: 2.5537986755371094
Validation loss: 1.9486228419888405

Epoch: 5| Step: 2
Training loss: 2.0343048572540283
Validation loss: 1.9567592579831359

Epoch: 5| Step: 3
Training loss: 2.3977463245391846
Validation loss: 1.963275122386153

Epoch: 5| Step: 4
Training loss: 2.4846150875091553
Validation loss: 1.9538411786479335

Epoch: 5| Step: 5
Training loss: 1.918310523033142
Validation loss: 1.95563159706772

Epoch: 5| Step: 6
Training loss: 2.8233511447906494
Validation loss: 1.9467346963062082

Epoch: 5| Step: 7
Training loss: 2.3016886711120605
Validation loss: 1.9501615980620026

Epoch: 5| Step: 8
Training loss: 2.117279529571533
Validation loss: 1.9370933553223968

Epoch: 5| Step: 9
Training loss: 2.1474227905273438
Validation loss: 1.9428164741044402

Epoch: 5| Step: 10
Training loss: 2.2624473571777344
Validation loss: 1.9288846908077117

Epoch: 73| Step: 0
Training loss: 1.7014373540878296
Validation loss: 1.9568697842218543

Epoch: 5| Step: 1
Training loss: 1.7664878368377686
Validation loss: 1.9357377200998285

Epoch: 5| Step: 2
Training loss: 2.5848286151885986
Validation loss: 1.9386667256714196

Epoch: 5| Step: 3
Training loss: 2.0507874488830566
Validation loss: 1.9488923690652336

Epoch: 5| Step: 4
Training loss: 2.337559938430786
Validation loss: 1.9551225246921662

Epoch: 5| Step: 5
Training loss: 3.1151418685913086
Validation loss: 1.9629223628710675

Epoch: 5| Step: 6
Training loss: 2.1531825065612793
Validation loss: 1.94993987647436

Epoch: 5| Step: 7
Training loss: 2.2487568855285645
Validation loss: 1.9454068342844646

Epoch: 5| Step: 8
Training loss: 2.308295965194702
Validation loss: 1.9476660425944994

Epoch: 5| Step: 9
Training loss: 2.210782527923584
Validation loss: 1.9527771293476064

Epoch: 5| Step: 10
Training loss: 2.684751510620117
Validation loss: 1.9736783837759366

Epoch: 74| Step: 0
Training loss: 2.4257655143737793
Validation loss: 1.9467493039305492

Epoch: 5| Step: 1
Training loss: 1.5522841215133667
Validation loss: 1.9649935922315043

Epoch: 5| Step: 2
Training loss: 2.487328052520752
Validation loss: 1.9537022831619426

Epoch: 5| Step: 3
Training loss: 2.2700653076171875
Validation loss: 1.952543835486135

Epoch: 5| Step: 4
Training loss: 2.105167865753174
Validation loss: 1.9690966529230918

Epoch: 5| Step: 5
Training loss: 2.477604866027832
Validation loss: 1.9601718148877543

Epoch: 5| Step: 6
Training loss: 2.435001850128174
Validation loss: 1.9519758826942855

Epoch: 5| Step: 7
Training loss: 2.583564281463623
Validation loss: 1.9873652714554981

Epoch: 5| Step: 8
Training loss: 2.2155158519744873
Validation loss: 1.9386416789024108

Epoch: 5| Step: 9
Training loss: 2.156710147857666
Validation loss: 1.981549088672925

Epoch: 5| Step: 10
Training loss: 2.3821027278900146
Validation loss: 1.9739026856678787

Epoch: 75| Step: 0
Training loss: 2.208125352859497
Validation loss: 1.9710096069561538

Epoch: 5| Step: 1
Training loss: 1.9626004695892334
Validation loss: 1.970438721359417

Epoch: 5| Step: 2
Training loss: 2.3532652854919434
Validation loss: 1.969609179804402

Epoch: 5| Step: 3
Training loss: 1.7884101867675781
Validation loss: 1.9702553223538142

Epoch: 5| Step: 4
Training loss: 2.8657960891723633
Validation loss: 1.9511840856203468

Epoch: 5| Step: 5
Training loss: 2.2203116416931152
Validation loss: 1.9518547634924612

Epoch: 5| Step: 6
Training loss: 1.9317066669464111
Validation loss: 1.9570100051100536

Epoch: 5| Step: 7
Training loss: 2.9398422241210938
Validation loss: 1.9643810397835189

Epoch: 5| Step: 8
Training loss: 2.174407958984375
Validation loss: 1.9523744557493476

Epoch: 5| Step: 9
Training loss: 2.2395055294036865
Validation loss: 1.9390543212172806

Epoch: 5| Step: 10
Training loss: 2.253725290298462
Validation loss: 1.9491312375632666

Epoch: 76| Step: 0
Training loss: 2.2712926864624023
Validation loss: 1.9512074532047394

Epoch: 5| Step: 1
Training loss: 2.438023805618286
Validation loss: 1.9414272064803748

Epoch: 5| Step: 2
Training loss: 1.8871040344238281
Validation loss: 1.9645134479768815

Epoch: 5| Step: 3
Training loss: 2.333782196044922
Validation loss: 1.974157658956384

Epoch: 5| Step: 4
Training loss: 1.9138336181640625
Validation loss: 1.9595331684235604

Epoch: 5| Step: 5
Training loss: 2.3616580963134766
Validation loss: 1.9687390583817677

Epoch: 5| Step: 6
Training loss: 2.5185985565185547
Validation loss: 1.9549246911079652

Epoch: 5| Step: 7
Training loss: 2.537370204925537
Validation loss: 1.9506274577110045

Epoch: 5| Step: 8
Training loss: 2.289062023162842
Validation loss: 1.9601019992623279

Epoch: 5| Step: 9
Training loss: 2.495544195175171
Validation loss: 1.959130294861332

Epoch: 5| Step: 10
Training loss: 1.7367067337036133
Validation loss: 1.960260921908963

Epoch: 77| Step: 0
Training loss: 2.4476540088653564
Validation loss: 1.9559102071228849

Epoch: 5| Step: 1
Training loss: 2.0498650074005127
Validation loss: 1.938875417555532

Epoch: 5| Step: 2
Training loss: 2.0949113368988037
Validation loss: 1.9640948349429714

Epoch: 5| Step: 3
Training loss: 2.296335458755493
Validation loss: 1.9528659825683923

Epoch: 5| Step: 4
Training loss: 1.6688429117202759
Validation loss: 1.9580228508159678

Epoch: 5| Step: 5
Training loss: 1.7627198696136475
Validation loss: 1.9805845650293494

Epoch: 5| Step: 6
Training loss: 1.828553557395935
Validation loss: 1.961262688841871

Epoch: 5| Step: 7
Training loss: 2.6690759658813477
Validation loss: 1.9676579454893708

Epoch: 5| Step: 8
Training loss: 3.3018670082092285
Validation loss: 1.9684293398293116

Epoch: 5| Step: 9
Training loss: 2.794252395629883
Validation loss: 1.9812643092165712

Epoch: 5| Step: 10
Training loss: 2.154550552368164
Validation loss: 1.9814051146148353

Epoch: 78| Step: 0
Training loss: 2.420790433883667
Validation loss: 1.9757010257372292

Epoch: 5| Step: 1
Training loss: 1.8503338098526
Validation loss: 1.966700476984824

Epoch: 5| Step: 2
Training loss: 2.2832188606262207
Validation loss: 1.9658096041730655

Epoch: 5| Step: 3
Training loss: 2.207603693008423
Validation loss: 1.9692549167140838

Epoch: 5| Step: 4
Training loss: 2.1626689434051514
Validation loss: 1.9569804322335027

Epoch: 5| Step: 5
Training loss: 2.3573689460754395
Validation loss: 1.9630241958043908

Epoch: 5| Step: 6
Training loss: 2.478043556213379
Validation loss: 1.9659023336184922

Epoch: 5| Step: 7
Training loss: 1.7998440265655518
Validation loss: 1.9716400433612127

Epoch: 5| Step: 8
Training loss: 2.8353934288024902
Validation loss: 1.9556462187920847

Epoch: 5| Step: 9
Training loss: 1.9985377788543701
Validation loss: 1.9644498312345116

Epoch: 5| Step: 10
Training loss: 2.6511478424072266
Validation loss: 1.9629730832192205

Epoch: 79| Step: 0
Training loss: 2.3037590980529785
Validation loss: 1.9858662800122333

Epoch: 5| Step: 1
Training loss: 2.0354199409484863
Validation loss: 1.9611959688125118

Epoch: 5| Step: 2
Training loss: 2.1651909351348877
Validation loss: 1.964300609404041

Epoch: 5| Step: 3
Training loss: 2.974754810333252
Validation loss: 1.9648479953888924

Epoch: 5| Step: 4
Training loss: 1.766534447669983
Validation loss: 1.966122147857502

Epoch: 5| Step: 5
Training loss: 2.246696710586548
Validation loss: 1.9771965626747376

Epoch: 5| Step: 6
Training loss: 2.488182544708252
Validation loss: 1.970103843237764

Epoch: 5| Step: 7
Training loss: 2.4915287494659424
Validation loss: 1.9711673977554485

Epoch: 5| Step: 8
Training loss: 1.703809142112732
Validation loss: 1.975151320939423

Epoch: 5| Step: 9
Training loss: 2.640226364135742
Validation loss: 1.9657289520386727

Epoch: 5| Step: 10
Training loss: 2.102450370788574
Validation loss: 1.9872982437892626

Epoch: 80| Step: 0
Training loss: 2.633632183074951
Validation loss: 1.9734600974667458

Epoch: 5| Step: 1
Training loss: 2.3347904682159424
Validation loss: 1.999769672270744

Epoch: 5| Step: 2
Training loss: 2.175166130065918
Validation loss: 1.9706128925405524

Epoch: 5| Step: 3
Training loss: 2.38078236579895
Validation loss: 1.973506736499007

Epoch: 5| Step: 4
Training loss: 2.133118152618408
Validation loss: 1.9707237725616784

Epoch: 5| Step: 5
Training loss: 2.589461088180542
Validation loss: 1.9680822651873353

Epoch: 5| Step: 6
Training loss: 2.3809592723846436
Validation loss: 1.9531553868324525

Epoch: 5| Step: 7
Training loss: 2.0222935676574707
Validation loss: 1.9822896936888337

Epoch: 5| Step: 8
Training loss: 2.256227493286133
Validation loss: 1.9630749058979813

Epoch: 5| Step: 9
Training loss: 2.063758611679077
Validation loss: 1.9697784095682123

Epoch: 5| Step: 10
Training loss: 1.9379990100860596
Validation loss: 1.9754683997041436

Epoch: 81| Step: 0
Training loss: 2.4751288890838623
Validation loss: 1.9739732588491132

Epoch: 5| Step: 1
Training loss: 2.778120756149292
Validation loss: 1.9794573271146385

Epoch: 5| Step: 2
Training loss: 2.417604923248291
Validation loss: 1.9694140777792981

Epoch: 5| Step: 3
Training loss: 2.055842399597168
Validation loss: 1.9628239805980394

Epoch: 5| Step: 4
Training loss: 2.465752124786377
Validation loss: 1.9774161615679342

Epoch: 5| Step: 5
Training loss: 2.60467529296875
Validation loss: 1.9863773417729202

Epoch: 5| Step: 6
Training loss: 2.018691301345825
Validation loss: 1.9787204803959015

Epoch: 5| Step: 7
Training loss: 1.9360682964324951
Validation loss: 1.9887475954589022

Epoch: 5| Step: 8
Training loss: 2.1096205711364746
Validation loss: 1.9715048933541903

Epoch: 5| Step: 9
Training loss: 1.5352094173431396
Validation loss: 1.9989681243896484

Epoch: 5| Step: 10
Training loss: 2.5223379135131836
Validation loss: 1.9763491410081104

Epoch: 82| Step: 0
Training loss: 2.1321377754211426
Validation loss: 1.9860138585490565

Epoch: 5| Step: 1
Training loss: 2.044670820236206
Validation loss: 1.9800432766637495

Epoch: 5| Step: 2
Training loss: 2.3109352588653564
Validation loss: 1.9647528612485496

Epoch: 5| Step: 3
Training loss: 2.339296340942383
Validation loss: 1.9706258107257146

Epoch: 5| Step: 4
Training loss: 2.4845833778381348
Validation loss: 1.9746938367043771

Epoch: 5| Step: 5
Training loss: 2.148528575897217
Validation loss: 1.9695327371679328

Epoch: 5| Step: 6
Training loss: 2.2484302520751953
Validation loss: 1.9638771933894004

Epoch: 5| Step: 7
Training loss: 2.8579204082489014
Validation loss: 1.9822655044576174

Epoch: 5| Step: 8
Training loss: 2.2673423290252686
Validation loss: 1.9950853137559788

Epoch: 5| Step: 9
Training loss: 2.555445432662964
Validation loss: 1.9593466148581555

Epoch: 5| Step: 10
Training loss: 1.4519014358520508
Validation loss: 1.9396559217924714

Epoch: 83| Step: 0
Training loss: 2.176508903503418
Validation loss: 1.9557145026422316

Epoch: 5| Step: 1
Training loss: 2.4137043952941895
Validation loss: 1.960399491812593

Epoch: 5| Step: 2
Training loss: 2.6966605186462402
Validation loss: 1.9736984006820186

Epoch: 5| Step: 3
Training loss: 2.5694775581359863
Validation loss: 1.9628946858067666

Epoch: 5| Step: 4
Training loss: 2.4984240531921387
Validation loss: 1.9601610206788587

Epoch: 5| Step: 5
Training loss: 1.7747869491577148
Validation loss: 1.9951947965929586

Epoch: 5| Step: 6
Training loss: 2.3868069648742676
Validation loss: 1.971324550208225

Epoch: 5| Step: 7
Training loss: 1.9759002923965454
Validation loss: 1.9737427619195753

Epoch: 5| Step: 8
Training loss: 2.0254478454589844
Validation loss: 1.9637399386334162

Epoch: 5| Step: 9
Training loss: 2.600609302520752
Validation loss: 1.9765682387095627

Epoch: 5| Step: 10
Training loss: 1.678938865661621
Validation loss: 1.9822702010472615

Epoch: 84| Step: 0
Training loss: 2.324995994567871
Validation loss: 1.97259247174827

Epoch: 5| Step: 1
Training loss: 2.308445692062378
Validation loss: 1.9504237021169355

Epoch: 5| Step: 2
Training loss: 2.01021146774292
Validation loss: 1.9595773630244757

Epoch: 5| Step: 3
Training loss: 2.4556145668029785
Validation loss: 1.9642879886011924

Epoch: 5| Step: 4
Training loss: 1.7069772481918335
Validation loss: 1.9640974831837479

Epoch: 5| Step: 5
Training loss: 2.1874048709869385
Validation loss: 1.9871283346606838

Epoch: 5| Step: 6
Training loss: 2.3852009773254395
Validation loss: 1.9528289687248968

Epoch: 5| Step: 7
Training loss: 2.015881299972534
Validation loss: 1.9661255344267814

Epoch: 5| Step: 8
Training loss: 2.4240639209747314
Validation loss: 1.9608222925534813

Epoch: 5| Step: 9
Training loss: 2.1936323642730713
Validation loss: 1.9591796910890968

Epoch: 5| Step: 10
Training loss: 2.759664297103882
Validation loss: 1.9446638502100462

Epoch: 85| Step: 0
Training loss: 2.295011043548584
Validation loss: 1.9491597683198991

Epoch: 5| Step: 1
Training loss: 2.0273327827453613
Validation loss: 1.9684307126588718

Epoch: 5| Step: 2
Training loss: 2.7005228996276855
Validation loss: 1.942346808730915

Epoch: 5| Step: 3
Training loss: 2.307598829269409
Validation loss: 1.9663698596339072

Epoch: 5| Step: 4
Training loss: 2.3356518745422363
Validation loss: 1.9663027819766794

Epoch: 5| Step: 5
Training loss: 2.686652421951294
Validation loss: 1.9674891092443978

Epoch: 5| Step: 6
Training loss: 2.281428337097168
Validation loss: 1.9609875961016583

Epoch: 5| Step: 7
Training loss: 2.269568920135498
Validation loss: 1.9693438981169014

Epoch: 5| Step: 8
Training loss: 2.3050503730773926
Validation loss: 1.9671159816044632

Epoch: 5| Step: 9
Training loss: 1.816933035850525
Validation loss: 1.9743994000137493

Epoch: 5| Step: 10
Training loss: 1.6682894229888916
Validation loss: 1.9555072758787422

Epoch: 86| Step: 0
Training loss: 2.063373327255249
Validation loss: 1.9682273275108748

Epoch: 5| Step: 1
Training loss: 2.3248438835144043
Validation loss: 1.963700371403848

Epoch: 5| Step: 2
Training loss: 2.4361889362335205
Validation loss: 1.9643060699585946

Epoch: 5| Step: 3
Training loss: 2.011646270751953
Validation loss: 1.9730548871460782

Epoch: 5| Step: 4
Training loss: 1.3502756357192993
Validation loss: 1.9580404104725007

Epoch: 5| Step: 5
Training loss: 2.656052827835083
Validation loss: 1.978555912612587

Epoch: 5| Step: 6
Training loss: 2.2417140007019043
Validation loss: 1.9603506275402602

Epoch: 5| Step: 7
Training loss: 1.6023540496826172
Validation loss: 1.9600755796637586

Epoch: 5| Step: 8
Training loss: 2.636427402496338
Validation loss: 1.9744689874751593

Epoch: 5| Step: 9
Training loss: 2.5969607830047607
Validation loss: 1.9853889352531844

Epoch: 5| Step: 10
Training loss: 2.9834296703338623
Validation loss: 1.9808326998064596

Epoch: 87| Step: 0
Training loss: 2.075092077255249
Validation loss: 1.9743317365646362

Epoch: 5| Step: 1
Training loss: 2.038647174835205
Validation loss: 1.9744031442108976

Epoch: 5| Step: 2
Training loss: 2.3870909214019775
Validation loss: 1.9690861240510018

Epoch: 5| Step: 3
Training loss: 2.019753932952881
Validation loss: 1.9857775831735263

Epoch: 5| Step: 4
Training loss: 2.335750102996826
Validation loss: 1.9657188743673346

Epoch: 5| Step: 5
Training loss: 2.3715925216674805
Validation loss: 1.9851602687630603

Epoch: 5| Step: 6
Training loss: 2.241178035736084
Validation loss: 1.9613486874488093

Epoch: 5| Step: 7
Training loss: 2.9041452407836914
Validation loss: 1.9678597270801503

Epoch: 5| Step: 8
Training loss: 2.3651089668273926
Validation loss: 1.9666016306928409

Epoch: 5| Step: 9
Training loss: 1.8005281686782837
Validation loss: 1.9719611970327233

Epoch: 5| Step: 10
Training loss: 2.2885873317718506
Validation loss: 1.9685485157915341

Epoch: 88| Step: 0
Training loss: 1.590720534324646
Validation loss: 1.9698136929542787

Epoch: 5| Step: 1
Training loss: 2.8568694591522217
Validation loss: 1.9871440972051313

Epoch: 5| Step: 2
Training loss: 2.1103100776672363
Validation loss: 1.97223787923013

Epoch: 5| Step: 3
Training loss: 2.4177184104919434
Validation loss: 1.9551412469597274

Epoch: 5| Step: 4
Training loss: 2.830292224884033
Validation loss: 1.9598262835574407

Epoch: 5| Step: 5
Training loss: 2.0428271293640137
Validation loss: 1.956325384878343

Epoch: 5| Step: 6
Training loss: 2.3108878135681152
Validation loss: 1.9842146237691243

Epoch: 5| Step: 7
Training loss: 2.057440757751465
Validation loss: 1.977839954437748

Epoch: 5| Step: 8
Training loss: 1.8461977243423462
Validation loss: 1.9877638252832557

Epoch: 5| Step: 9
Training loss: 2.496608257293701
Validation loss: 1.9773321754188948

Epoch: 5| Step: 10
Training loss: 2.2932300567626953
Validation loss: 1.9757851618592457

Epoch: 89| Step: 0
Training loss: 2.758218288421631
Validation loss: 1.9844459974637596

Epoch: 5| Step: 1
Training loss: 2.424027442932129
Validation loss: 1.9874808480662685

Epoch: 5| Step: 2
Training loss: 2.3234505653381348
Validation loss: 1.9698298003083916

Epoch: 5| Step: 3
Training loss: 1.8438892364501953
Validation loss: 1.9781603479898104

Epoch: 5| Step: 4
Training loss: 2.8220646381378174
Validation loss: 1.9980771003230926

Epoch: 5| Step: 5
Training loss: 1.9654490947723389
Validation loss: 1.9801761232396609

Epoch: 5| Step: 6
Training loss: 2.2919678688049316
Validation loss: 1.9658811758923274

Epoch: 5| Step: 7
Training loss: 1.8230464458465576
Validation loss: 1.9774636145560973

Epoch: 5| Step: 8
Training loss: 2.134742498397827
Validation loss: 1.9656447813075075

Epoch: 5| Step: 9
Training loss: 2.7450218200683594
Validation loss: 1.9861095002902451

Epoch: 5| Step: 10
Training loss: 1.6492114067077637
Validation loss: 1.9771284390521306

Epoch: 90| Step: 0
Training loss: 2.0002801418304443
Validation loss: 1.99392742495383

Epoch: 5| Step: 1
Training loss: 1.623805284500122
Validation loss: 1.9821607823012977

Epoch: 5| Step: 2
Training loss: 2.4077608585357666
Validation loss: 1.9735209147135417

Epoch: 5| Step: 3
Training loss: 2.6170012950897217
Validation loss: 2.006010232433196

Epoch: 5| Step: 4
Training loss: 2.5884809494018555
Validation loss: 1.9850403288359284

Epoch: 5| Step: 5
Training loss: 2.6050829887390137
Validation loss: 1.9846988301123343

Epoch: 5| Step: 6
Training loss: 1.8938932418823242
Validation loss: 1.9829380178964267

Epoch: 5| Step: 7
Training loss: 1.8915002346038818
Validation loss: 1.9777206579844158

Epoch: 5| Step: 8
Training loss: 2.190762996673584
Validation loss: 1.9815276925281813

Epoch: 5| Step: 9
Training loss: 2.104480743408203
Validation loss: 1.9874548117319744

Epoch: 5| Step: 10
Training loss: 2.951927661895752
Validation loss: 1.9810276467313048

Epoch: 91| Step: 0
Training loss: 2.846954107284546
Validation loss: 1.974571676664455

Epoch: 5| Step: 1
Training loss: 1.4823596477508545
Validation loss: 1.9767864647731985

Epoch: 5| Step: 2
Training loss: 1.9440889358520508
Validation loss: 1.9760641885060135

Epoch: 5| Step: 3
Training loss: 2.0713534355163574
Validation loss: 1.984920254317663

Epoch: 5| Step: 4
Training loss: 2.5345664024353027
Validation loss: 1.980674196315068

Epoch: 5| Step: 5
Training loss: 2.6774895191192627
Validation loss: 1.9694868364641744

Epoch: 5| Step: 6
Training loss: 2.3195254802703857
Validation loss: 1.9805607885442755

Epoch: 5| Step: 7
Training loss: 2.1416218280792236
Validation loss: 1.980276926871269

Epoch: 5| Step: 8
Training loss: 1.6740682125091553
Validation loss: 1.9740249559443483

Epoch: 5| Step: 9
Training loss: 2.6990089416503906
Validation loss: 1.992585712863553

Epoch: 5| Step: 10
Training loss: 2.433765172958374
Validation loss: 1.9950656147413357

Epoch: 92| Step: 0
Training loss: 1.9878275394439697
Validation loss: 1.9703033201156124

Epoch: 5| Step: 1
Training loss: 2.013953685760498
Validation loss: 1.9814986528888825

Epoch: 5| Step: 2
Training loss: 2.9621286392211914
Validation loss: 1.9895193858813214

Epoch: 5| Step: 3
Training loss: 2.1146512031555176
Validation loss: 1.9785953824238112

Epoch: 5| Step: 4
Training loss: 2.198452949523926
Validation loss: 1.9849432181286555

Epoch: 5| Step: 5
Training loss: 1.8731977939605713
Validation loss: 1.9678000403988747

Epoch: 5| Step: 6
Training loss: 2.2099449634552
Validation loss: 1.9648284181471793

Epoch: 5| Step: 7
Training loss: 2.302649974822998
Validation loss: 1.964458506594422

Epoch: 5| Step: 8
Training loss: 2.495540142059326
Validation loss: 1.9646172369680097

Epoch: 5| Step: 9
Training loss: 2.305177688598633
Validation loss: 1.9789567378259474

Epoch: 5| Step: 10
Training loss: 2.234344244003296
Validation loss: 1.9665930040421025

Epoch: 93| Step: 0
Training loss: 3.121577739715576
Validation loss: 1.9659357840015041

Epoch: 5| Step: 1
Training loss: 1.8632866144180298
Validation loss: 1.9790658130440661

Epoch: 5| Step: 2
Training loss: 2.4610061645507812
Validation loss: 1.968080800066712

Epoch: 5| Step: 3
Training loss: 3.1246328353881836
Validation loss: 1.97487973654142

Epoch: 5| Step: 4
Training loss: 2.2593774795532227
Validation loss: 1.9728870071390623

Epoch: 5| Step: 5
Training loss: 1.7832205295562744
Validation loss: 1.9578612530103294

Epoch: 5| Step: 6
Training loss: 2.2629001140594482
Validation loss: 1.970182276541187

Epoch: 5| Step: 7
Training loss: 1.889105200767517
Validation loss: 1.968489752020887

Epoch: 5| Step: 8
Training loss: 2.143216609954834
Validation loss: 1.9768912497387137

Epoch: 5| Step: 9
Training loss: 1.715461015701294
Validation loss: 1.954629482761506

Epoch: 5| Step: 10
Training loss: 1.9695920944213867
Validation loss: 1.966807944800264

Epoch: 94| Step: 0
Training loss: 1.999829649925232
Validation loss: 1.965245577596849

Epoch: 5| Step: 1
Training loss: 2.0460336208343506
Validation loss: 1.9757429656162058

Epoch: 5| Step: 2
Training loss: 2.800281047821045
Validation loss: 1.9679950206510481

Epoch: 5| Step: 3
Training loss: 2.2737202644348145
Validation loss: 1.9500682584701046

Epoch: 5| Step: 4
Training loss: 2.5174484252929688
Validation loss: 1.9656882555254045

Epoch: 5| Step: 5
Training loss: 2.6450138092041016
Validation loss: 1.9849952215789466

Epoch: 5| Step: 6
Training loss: 1.5425816774368286
Validation loss: 1.9641810770957702

Epoch: 5| Step: 7
Training loss: 2.3949856758117676
Validation loss: 1.9825939696322206

Epoch: 5| Step: 8
Training loss: 2.2857203483581543
Validation loss: 1.9872677890203332

Epoch: 5| Step: 9
Training loss: 2.1213741302490234
Validation loss: 1.9750726633174445

Epoch: 5| Step: 10
Training loss: 2.1382083892822266
Validation loss: 1.98161776860555

Epoch: 95| Step: 0
Training loss: 1.9924513101577759
Validation loss: 1.9753134019913212

Epoch: 5| Step: 1
Training loss: 2.101040840148926
Validation loss: 1.9696112525078557

Epoch: 5| Step: 2
Training loss: 2.1075806617736816
Validation loss: 1.9700480071447228

Epoch: 5| Step: 3
Training loss: 1.490217924118042
Validation loss: 1.969240468035462

Epoch: 5| Step: 4
Training loss: 2.4031014442443848
Validation loss: 1.9756857631027058

Epoch: 5| Step: 5
Training loss: 2.048980951309204
Validation loss: 1.9724771284287976

Epoch: 5| Step: 6
Training loss: 2.432767391204834
Validation loss: 1.9708415436488327

Epoch: 5| Step: 7
Training loss: 1.9136087894439697
Validation loss: 1.965593259821656

Epoch: 5| Step: 8
Training loss: 2.3279941082000732
Validation loss: 1.9619029465542044

Epoch: 5| Step: 9
Training loss: 3.0813357830047607
Validation loss: 1.9715644685170983

Epoch: 5| Step: 10
Training loss: 2.866879463195801
Validation loss: 1.9708430715786514

Epoch: 96| Step: 0
Training loss: 2.3386788368225098
Validation loss: 1.9736207274980442

Epoch: 5| Step: 1
Training loss: 2.036205291748047
Validation loss: 1.9707267592030187

Epoch: 5| Step: 2
Training loss: 1.9180113077163696
Validation loss: 1.9979531585529287

Epoch: 5| Step: 3
Training loss: 2.2133028507232666
Validation loss: 1.996681018542218

Epoch: 5| Step: 4
Training loss: 1.7878310680389404
Validation loss: 1.9730577802145353

Epoch: 5| Step: 5
Training loss: 1.6242929697036743
Validation loss: 1.9733578979328115

Epoch: 5| Step: 6
Training loss: 2.3123998641967773
Validation loss: 1.9675252975956086

Epoch: 5| Step: 7
Training loss: 2.8199219703674316
Validation loss: 1.9636340013114355

Epoch: 5| Step: 8
Training loss: 2.47314453125
Validation loss: 1.961377759133616

Epoch: 5| Step: 9
Training loss: 2.4861645698547363
Validation loss: 1.9762937689340243

Epoch: 5| Step: 10
Training loss: 2.6158857345581055
Validation loss: 1.969425061697601

Epoch: 97| Step: 0
Training loss: 2.2714462280273438
Validation loss: 1.976968276885248

Epoch: 5| Step: 1
Training loss: 2.306269884109497
Validation loss: 1.9580546015052385

Epoch: 5| Step: 2
Training loss: 2.5371580123901367
Validation loss: 1.984547035668486

Epoch: 5| Step: 3
Training loss: 2.3397223949432373
Validation loss: 1.9975179331277007

Epoch: 5| Step: 4
Training loss: 2.245748281478882
Validation loss: 1.9779440510657527

Epoch: 5| Step: 5
Training loss: 2.8350985050201416
Validation loss: 1.982836848946028

Epoch: 5| Step: 6
Training loss: 2.1289925575256348
Validation loss: 1.9842823231092064

Epoch: 5| Step: 7
Training loss: 2.0439414978027344
Validation loss: 1.9948535478243263

Epoch: 5| Step: 8
Training loss: 2.4300713539123535
Validation loss: 1.9848533343243342

Epoch: 5| Step: 9
Training loss: 1.180189847946167
Validation loss: 1.9827595923536567

Epoch: 5| Step: 10
Training loss: 2.38782000541687
Validation loss: 1.9767750347814252

Epoch: 98| Step: 0
Training loss: 2.4244301319122314
Validation loss: 1.9672563832293275

Epoch: 5| Step: 1
Training loss: 1.9471385478973389
Validation loss: 1.9827825856465164

Epoch: 5| Step: 2
Training loss: 2.444270610809326
Validation loss: 1.969798323928669

Epoch: 5| Step: 3
Training loss: 2.1913692951202393
Validation loss: 1.966645202329082

Epoch: 5| Step: 4
Training loss: 2.422732353210449
Validation loss: 1.9734438080941477

Epoch: 5| Step: 5
Training loss: 2.449267625808716
Validation loss: 1.9613930358681628

Epoch: 5| Step: 6
Training loss: 2.293440341949463
Validation loss: 1.9579708665929816

Epoch: 5| Step: 7
Training loss: 1.9954063892364502
Validation loss: 1.9634811468021844

Epoch: 5| Step: 8
Training loss: 1.8056137561798096
Validation loss: 1.9713440069588282

Epoch: 5| Step: 9
Training loss: 2.5657575130462646
Validation loss: 1.9708415539033952

Epoch: 5| Step: 10
Training loss: 2.109670400619507
Validation loss: 1.9675605015088153

Epoch: 99| Step: 0
Training loss: 2.231163740158081
Validation loss: 1.952783029566529

Epoch: 5| Step: 1
Training loss: 2.463636875152588
Validation loss: 1.953009618225918

Epoch: 5| Step: 2
Training loss: 2.5071682929992676
Validation loss: 1.9551465818958897

Epoch: 5| Step: 3
Training loss: 2.261305332183838
Validation loss: 1.9368914942587576

Epoch: 5| Step: 4
Training loss: 1.9362672567367554
Validation loss: 1.963484828190137

Epoch: 5| Step: 5
Training loss: 2.367553234100342
Validation loss: 1.9577826979339763

Epoch: 5| Step: 6
Training loss: 2.6442341804504395
Validation loss: 1.9600206844268306

Epoch: 5| Step: 7
Training loss: 1.8887174129486084
Validation loss: 1.9820761783148653

Epoch: 5| Step: 8
Training loss: 2.072155475616455
Validation loss: 1.9845665065191125

Epoch: 5| Step: 9
Training loss: 1.9443883895874023
Validation loss: 1.9830614225838774

Epoch: 5| Step: 10
Training loss: 2.2117984294891357
Validation loss: 1.9535641529226815

Epoch: 100| Step: 0
Training loss: 3.2624428272247314
Validation loss: 1.9543409770534885

Epoch: 5| Step: 1
Training loss: 2.513423442840576
Validation loss: 1.974150933245177

Epoch: 5| Step: 2
Training loss: 1.4895511865615845
Validation loss: 1.961327491268035

Epoch: 5| Step: 3
Training loss: 2.3999133110046387
Validation loss: 1.9801887555788922

Epoch: 5| Step: 4
Training loss: 2.0079500675201416
Validation loss: 1.9549793325444704

Epoch: 5| Step: 5
Training loss: 2.2206244468688965
Validation loss: 1.977509431941535

Epoch: 5| Step: 6
Training loss: 2.2212862968444824
Validation loss: 1.9635494832069642

Epoch: 5| Step: 7
Training loss: 1.8791439533233643
Validation loss: 1.973678360703171

Epoch: 5| Step: 8
Training loss: 2.1252593994140625
Validation loss: 1.9873517021056144

Epoch: 5| Step: 9
Training loss: 1.8755807876586914
Validation loss: 1.9883266879666237

Epoch: 5| Step: 10
Training loss: 2.610945224761963
Validation loss: 1.9842845778311453

Testing loss: 2.121325929959615
