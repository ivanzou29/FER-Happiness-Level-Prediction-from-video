Epoch: 1| Step: 0
Training loss: 7.463353157043457
Validation loss: 6.357969027693554

Epoch: 5| Step: 1
Training loss: 6.468323707580566
Validation loss: 6.354757052595898

Epoch: 5| Step: 2
Training loss: 5.42706823348999
Validation loss: 6.355140106652373

Epoch: 5| Step: 3
Training loss: 4.338688850402832
Validation loss: 6.353212269403601

Epoch: 5| Step: 4
Training loss: 5.680100440979004
Validation loss: 6.35197998375021

Epoch: 5| Step: 5
Training loss: 6.478131294250488
Validation loss: 6.34821246259956

Epoch: 5| Step: 6
Training loss: 6.283811092376709
Validation loss: 6.34729395117811

Epoch: 5| Step: 7
Training loss: 7.072444915771484
Validation loss: 6.344310873298235

Epoch: 5| Step: 8
Training loss: 6.326806545257568
Validation loss: 6.343247557199129

Epoch: 5| Step: 9
Training loss: 6.2303056716918945
Validation loss: 6.340859131146503

Epoch: 5| Step: 10
Training loss: 5.794952869415283
Validation loss: 6.337277540596583

Epoch: 2| Step: 0
Training loss: 5.8436174392700195
Validation loss: 6.337460405083113

Epoch: 5| Step: 1
Training loss: 6.276375770568848
Validation loss: 6.336456955120128

Epoch: 5| Step: 2
Training loss: 6.4556732177734375
Validation loss: 6.3362324930006455

Epoch: 5| Step: 3
Training loss: 6.509223937988281
Validation loss: 6.3299663041227605

Epoch: 5| Step: 4
Training loss: 6.280461311340332
Validation loss: 6.329690394863006

Epoch: 5| Step: 5
Training loss: 6.202980041503906
Validation loss: 6.328469737883537

Epoch: 5| Step: 6
Training loss: 6.1798858642578125
Validation loss: 6.326477276381626

Epoch: 5| Step: 7
Training loss: 6.087660789489746
Validation loss: 6.324240038471837

Epoch: 5| Step: 8
Training loss: 5.253429889678955
Validation loss: 6.323316963770056

Epoch: 5| Step: 9
Training loss: 5.2778143882751465
Validation loss: 6.320410272126557

Epoch: 5| Step: 10
Training loss: 7.168257236480713
Validation loss: 6.317928078354046

Epoch: 3| Step: 0
Training loss: 6.020392417907715
Validation loss: 6.31628696380123

Epoch: 5| Step: 1
Training loss: 4.486741065979004
Validation loss: 6.312037339774511

Epoch: 5| Step: 2
Training loss: 6.062109470367432
Validation loss: 6.311181488857474

Epoch: 5| Step: 3
Training loss: 5.420170783996582
Validation loss: 6.306636497538577

Epoch: 5| Step: 4
Training loss: 6.599009037017822
Validation loss: 6.30732927527479

Epoch: 5| Step: 5
Training loss: 6.321632385253906
Validation loss: 6.304337932217505

Epoch: 5| Step: 6
Training loss: 6.05654239654541
Validation loss: 6.302078667507376

Epoch: 5| Step: 7
Training loss: 6.489876747131348
Validation loss: 6.299551466459869

Epoch: 5| Step: 8
Training loss: 6.67983865737915
Validation loss: 6.2953536382285495

Epoch: 5| Step: 9
Training loss: 5.986763954162598
Validation loss: 6.292394791879961

Epoch: 5| Step: 10
Training loss: 7.129688262939453
Validation loss: 6.288940645033313

Epoch: 4| Step: 0
Training loss: 5.87421178817749
Validation loss: 6.284542970759894

Epoch: 5| Step: 1
Training loss: 6.385278224945068
Validation loss: 6.284647577552385

Epoch: 5| Step: 2
Training loss: 6.776123046875
Validation loss: 6.277245567690942

Epoch: 5| Step: 3
Training loss: 6.582449436187744
Validation loss: 6.275170228814566

Epoch: 5| Step: 4
Training loss: 6.0590009689331055
Validation loss: 6.27127900174869

Epoch: 5| Step: 5
Training loss: 6.266139984130859
Validation loss: 6.269766894719934

Epoch: 5| Step: 6
Training loss: 5.559615612030029
Validation loss: 6.267301497920867

Epoch: 5| Step: 7
Training loss: 6.260472774505615
Validation loss: 6.262902936627788

Epoch: 5| Step: 8
Training loss: 5.3109025955200195
Validation loss: 6.259468078613281

Epoch: 5| Step: 9
Training loss: 5.369891166687012
Validation loss: 6.255309048519339

Epoch: 5| Step: 10
Training loss: 6.306994438171387
Validation loss: 6.2515578731413814

Epoch: 5| Step: 0
Training loss: 6.743260383605957
Validation loss: 6.248003452054916

Epoch: 5| Step: 1
Training loss: 6.214929103851318
Validation loss: 6.243978290147679

Epoch: 5| Step: 2
Training loss: 5.075212478637695
Validation loss: 6.239266395568848

Epoch: 5| Step: 3
Training loss: 5.945104598999023
Validation loss: 6.236659901116484

Epoch: 5| Step: 4
Training loss: 6.090141296386719
Validation loss: 6.234255888128794

Epoch: 5| Step: 5
Training loss: 5.813347816467285
Validation loss: 6.233249156705795

Epoch: 5| Step: 6
Training loss: 6.2481279373168945
Validation loss: 6.227159587285852

Epoch: 5| Step: 7
Training loss: 5.20141077041626
Validation loss: 6.221586406871837

Epoch: 5| Step: 8
Training loss: 5.738320350646973
Validation loss: 6.2176983689749115

Epoch: 5| Step: 9
Training loss: 6.939763069152832
Validation loss: 6.214599132537842

Epoch: 5| Step: 10
Training loss: 6.304686069488525
Validation loss: 6.212282267949915

Epoch: 6| Step: 0
Training loss: 6.501799583435059
Validation loss: 6.208392404740857

Epoch: 5| Step: 1
Training loss: 5.1520771980285645
Validation loss: 6.2040040057192565

Epoch: 5| Step: 2
Training loss: 5.330496311187744
Validation loss: 6.199482625530612

Epoch: 5| Step: 3
Training loss: 4.632358551025391
Validation loss: 6.196531644431493

Epoch: 5| Step: 4
Training loss: 6.490082740783691
Validation loss: 6.193222963681785

Epoch: 5| Step: 5
Training loss: 6.521934509277344
Validation loss: 6.188533936777422

Epoch: 5| Step: 6
Training loss: 6.669364929199219
Validation loss: 6.186593312089161

Epoch: 5| Step: 7
Training loss: 6.8121538162231445
Validation loss: 6.181162341948478

Epoch: 5| Step: 8
Training loss: 6.047083377838135
Validation loss: 6.177154253887874

Epoch: 5| Step: 9
Training loss: 5.170886993408203
Validation loss: 6.173608779907227

Epoch: 5| Step: 10
Training loss: 6.603650093078613
Validation loss: 6.16978395113381

Epoch: 7| Step: 0
Training loss: 6.785213470458984
Validation loss: 6.16804704871229

Epoch: 5| Step: 1
Training loss: 6.349860668182373
Validation loss: 6.160762766356109

Epoch: 5| Step: 2
Training loss: 6.101825714111328
Validation loss: 6.157476368770804

Epoch: 5| Step: 3
Training loss: 5.410710334777832
Validation loss: 6.155301934929304

Epoch: 5| Step: 4
Training loss: 5.510829925537109
Validation loss: 6.151699963436331

Epoch: 5| Step: 5
Training loss: 5.394215106964111
Validation loss: 6.147288573685513

Epoch: 5| Step: 6
Training loss: 6.372522830963135
Validation loss: 6.139215315541914

Epoch: 5| Step: 7
Training loss: 6.132325649261475
Validation loss: 6.138557987828409

Epoch: 5| Step: 8
Training loss: 5.923458099365234
Validation loss: 6.132477580860097

Epoch: 5| Step: 9
Training loss: 5.329123497009277
Validation loss: 6.1344346743758

Epoch: 5| Step: 10
Training loss: 6.029453277587891
Validation loss: 6.125638054263208

Epoch: 8| Step: 0
Training loss: 6.296457290649414
Validation loss: 6.121006042726578

Epoch: 5| Step: 1
Training loss: 5.242337703704834
Validation loss: 6.118700283829884

Epoch: 5| Step: 2
Training loss: 5.387885570526123
Validation loss: 6.115469850519652

Epoch: 5| Step: 3
Training loss: 6.3001203536987305
Validation loss: 6.108369186360349

Epoch: 5| Step: 4
Training loss: 5.613908290863037
Validation loss: 6.105214154848489

Epoch: 5| Step: 5
Training loss: 5.781811714172363
Validation loss: 6.100721661762525

Epoch: 5| Step: 6
Training loss: 6.639763832092285
Validation loss: 6.0963960924456195

Epoch: 5| Step: 7
Training loss: 4.6690144538879395
Validation loss: 6.09090672257126

Epoch: 5| Step: 8
Training loss: 6.839665412902832
Validation loss: 6.0871311310798895

Epoch: 5| Step: 9
Training loss: 6.127193927764893
Validation loss: 6.082642985928443

Epoch: 5| Step: 10
Training loss: 5.924920558929443
Validation loss: 6.079177154007779

Epoch: 9| Step: 0
Training loss: 5.976826190948486
Validation loss: 6.074956837520804

Epoch: 5| Step: 1
Training loss: 5.833500862121582
Validation loss: 6.068636120006603

Epoch: 5| Step: 2
Training loss: 4.7182698249816895
Validation loss: 6.0653243833972565

Epoch: 5| Step: 3
Training loss: 5.717455863952637
Validation loss: 6.062715955959853

Epoch: 5| Step: 4
Training loss: 5.367100238800049
Validation loss: 6.053994414626911

Epoch: 5| Step: 5
Training loss: 7.123629093170166
Validation loss: 6.048221680425828

Epoch: 5| Step: 6
Training loss: 6.331568241119385
Validation loss: 6.049376287767964

Epoch: 5| Step: 7
Training loss: 5.579588890075684
Validation loss: 6.041933459620322

Epoch: 5| Step: 8
Training loss: 6.049786567687988
Validation loss: 6.036338160114903

Epoch: 5| Step: 9
Training loss: 5.469849109649658
Validation loss: 6.0296626808822795

Epoch: 5| Step: 10
Training loss: 6.125288486480713
Validation loss: 6.025888760884603

Epoch: 10| Step: 0
Training loss: 6.022818088531494
Validation loss: 6.019633687952513

Epoch: 5| Step: 1
Training loss: 4.9411163330078125
Validation loss: 6.017762958362538

Epoch: 5| Step: 2
Training loss: 7.269590854644775
Validation loss: 6.011458048256495

Epoch: 5| Step: 3
Training loss: 7.12350606918335
Validation loss: 6.007107606498144

Epoch: 5| Step: 4
Training loss: 4.514420509338379
Validation loss: 6.000350941893875

Epoch: 5| Step: 5
Training loss: 5.4700026512146
Validation loss: 5.997073855451358

Epoch: 5| Step: 6
Training loss: 6.082785606384277
Validation loss: 5.9890076011739755

Epoch: 5| Step: 7
Training loss: 4.865791320800781
Validation loss: 5.983403498126615

Epoch: 5| Step: 8
Training loss: 5.680493354797363
Validation loss: 5.97963825861613

Epoch: 5| Step: 9
Training loss: 5.855796813964844
Validation loss: 5.974043907657746

Epoch: 5| Step: 10
Training loss: 5.787720203399658
Validation loss: 5.969441706134427

Epoch: 11| Step: 0
Training loss: 6.748135566711426
Validation loss: 5.959455541385117

Epoch: 5| Step: 1
Training loss: 5.861878395080566
Validation loss: 5.955794329284339

Epoch: 5| Step: 2
Training loss: 6.318479061126709
Validation loss: 5.953499973461192

Epoch: 5| Step: 3
Training loss: 5.457327842712402
Validation loss: 5.946454689066897

Epoch: 5| Step: 4
Training loss: 5.579939842224121
Validation loss: 5.9383608910345265

Epoch: 5| Step: 5
Training loss: 6.027117729187012
Validation loss: 5.936506425180743

Epoch: 5| Step: 6
Training loss: 5.171458721160889
Validation loss: 5.927135585456766

Epoch: 5| Step: 7
Training loss: 4.828848838806152
Validation loss: 5.921909434821016

Epoch: 5| Step: 8
Training loss: 6.983346462249756
Validation loss: 5.915360517399286

Epoch: 5| Step: 9
Training loss: 4.975260257720947
Validation loss: 5.9102843038497435

Epoch: 5| Step: 10
Training loss: 4.853527069091797
Validation loss: 5.903895767786169

Epoch: 12| Step: 0
Training loss: 5.118411064147949
Validation loss: 5.899451501907841

Epoch: 5| Step: 1
Training loss: 5.2194504737854
Validation loss: 5.891851014988397

Epoch: 5| Step: 2
Training loss: 5.509793758392334
Validation loss: 5.886443102231589

Epoch: 5| Step: 3
Training loss: 6.189624786376953
Validation loss: 5.881703715170583

Epoch: 5| Step: 4
Training loss: 5.587795257568359
Validation loss: 5.874741220986971

Epoch: 5| Step: 5
Training loss: 5.518246650695801
Validation loss: 5.866856539121238

Epoch: 5| Step: 6
Training loss: 6.1686296463012695
Validation loss: 5.863712203118109

Epoch: 5| Step: 7
Training loss: 5.49685001373291
Validation loss: 5.857766638519943

Epoch: 5| Step: 8
Training loss: 5.608054161071777
Validation loss: 5.851878478962888

Epoch: 5| Step: 9
Training loss: 6.333527565002441
Validation loss: 5.843991105274488

Epoch: 5| Step: 10
Training loss: 5.378253936767578
Validation loss: 5.836578005103655

Epoch: 13| Step: 0
Training loss: 6.3407301902771
Validation loss: 5.82932041024649

Epoch: 5| Step: 1
Training loss: 4.969257354736328
Validation loss: 5.822960381866784

Epoch: 5| Step: 2
Training loss: 6.005550384521484
Validation loss: 5.817743906410792

Epoch: 5| Step: 3
Training loss: 5.3438310623168945
Validation loss: 5.808134766035183

Epoch: 5| Step: 4
Training loss: 6.777407646179199
Validation loss: 5.80432254011913

Epoch: 5| Step: 5
Training loss: 4.970247268676758
Validation loss: 5.795833526119109

Epoch: 5| Step: 6
Training loss: 5.07668924331665
Validation loss: 5.78732846372871

Epoch: 5| Step: 7
Training loss: 6.1894049644470215
Validation loss: 5.778571174990747

Epoch: 5| Step: 8
Training loss: 5.3704423904418945
Validation loss: 5.775149089033886

Epoch: 5| Step: 9
Training loss: 4.72417688369751
Validation loss: 5.7637594130731395

Epoch: 5| Step: 10
Training loss: 5.558622360229492
Validation loss: 5.759648374331895

Epoch: 14| Step: 0
Training loss: 5.759389400482178
Validation loss: 5.753867928699781

Epoch: 5| Step: 1
Training loss: 5.966921329498291
Validation loss: 5.7442537379521195

Epoch: 5| Step: 2
Training loss: 5.19856071472168
Validation loss: 5.735935113763296

Epoch: 5| Step: 3
Training loss: 5.179839134216309
Validation loss: 5.73294642151043

Epoch: 5| Step: 4
Training loss: 6.068284034729004
Validation loss: 5.717638246474728

Epoch: 5| Step: 5
Training loss: 5.667967796325684
Validation loss: 5.716219122691821

Epoch: 5| Step: 6
Training loss: 4.872514724731445
Validation loss: 5.703948759263562

Epoch: 5| Step: 7
Training loss: 5.850505828857422
Validation loss: 5.69816085856448

Epoch: 5| Step: 8
Training loss: 5.889071464538574
Validation loss: 5.686015518762732

Epoch: 5| Step: 9
Training loss: 4.888720512390137
Validation loss: 5.682044670145999

Epoch: 5| Step: 10
Training loss: 4.936549663543701
Validation loss: 5.669638044090681

Epoch: 15| Step: 0
Training loss: 4.870718479156494
Validation loss: 5.6656648266700005

Epoch: 5| Step: 1
Training loss: 6.334371566772461
Validation loss: 5.659896266075872

Epoch: 5| Step: 2
Training loss: 4.855326175689697
Validation loss: 5.644286104427871

Epoch: 5| Step: 3
Training loss: 5.8207197189331055
Validation loss: 5.634190764478458

Epoch: 5| Step: 4
Training loss: 6.280673027038574
Validation loss: 5.627509199162965

Epoch: 5| Step: 5
Training loss: 4.502918243408203
Validation loss: 5.625720572727983

Epoch: 5| Step: 6
Training loss: 4.96024751663208
Validation loss: 5.610882236111548

Epoch: 5| Step: 7
Training loss: 5.4798665046691895
Validation loss: 5.604902898111651

Epoch: 5| Step: 8
Training loss: 5.039595603942871
Validation loss: 5.596291536925941

Epoch: 5| Step: 9
Training loss: 5.771197319030762
Validation loss: 5.589559837054181

Epoch: 5| Step: 10
Training loss: 5.414853572845459
Validation loss: 5.571890431065714

Epoch: 16| Step: 0
Training loss: 4.643620491027832
Validation loss: 5.561022799502137

Epoch: 5| Step: 1
Training loss: 6.6882805824279785
Validation loss: 5.559401019926994

Epoch: 5| Step: 2
Training loss: 5.2650346755981445
Validation loss: 5.548085745944772

Epoch: 5| Step: 3
Training loss: 5.742972373962402
Validation loss: 5.531480635366132

Epoch: 5| Step: 4
Training loss: 5.109393119812012
Validation loss: 5.52331712169032

Epoch: 5| Step: 5
Training loss: 5.240065574645996
Validation loss: 5.511282526036744

Epoch: 5| Step: 6
Training loss: 5.5240888595581055
Validation loss: 5.50183795088081

Epoch: 5| Step: 7
Training loss: 5.144896030426025
Validation loss: 5.494093454012307

Epoch: 5| Step: 8
Training loss: 5.277143478393555
Validation loss: 5.475132485871674

Epoch: 5| Step: 9
Training loss: 4.946954250335693
Validation loss: 5.468083802089896

Epoch: 5| Step: 10
Training loss: 4.459822654724121
Validation loss: 5.451586082417478

Epoch: 17| Step: 0
Training loss: 3.632031202316284
Validation loss: 5.450168691655641

Epoch: 5| Step: 1
Training loss: 6.19553279876709
Validation loss: 5.437580595734299

Epoch: 5| Step: 2
Training loss: 6.306975364685059
Validation loss: 5.418018330809891

Epoch: 5| Step: 3
Training loss: 4.997903347015381
Validation loss: 5.413750084497595

Epoch: 5| Step: 4
Training loss: 6.057376861572266
Validation loss: 5.403912457086706

Epoch: 5| Step: 5
Training loss: 4.135774612426758
Validation loss: 5.3850885514290106

Epoch: 5| Step: 6
Training loss: 4.733360290527344
Validation loss: 5.370506727567283

Epoch: 5| Step: 7
Training loss: 5.053704261779785
Validation loss: 5.355339629675752

Epoch: 5| Step: 8
Training loss: 4.987351417541504
Validation loss: 5.349085361726822

Epoch: 5| Step: 9
Training loss: 4.744987964630127
Validation loss: 5.331291670440345

Epoch: 5| Step: 10
Training loss: 6.016013145446777
Validation loss: 5.319646758417929

Epoch: 18| Step: 0
Training loss: 6.032893180847168
Validation loss: 5.307782403884396

Epoch: 5| Step: 1
Training loss: 4.662829399108887
Validation loss: 5.297873517518402

Epoch: 5| Step: 2
Training loss: 6.0145134925842285
Validation loss: 5.280287988724247

Epoch: 5| Step: 3
Training loss: 5.21724271774292
Validation loss: 5.26344310596425

Epoch: 5| Step: 4
Training loss: 4.766207218170166
Validation loss: 5.261899609719554

Epoch: 5| Step: 5
Training loss: 3.96787691116333
Validation loss: 5.25230626649754

Epoch: 5| Step: 6
Training loss: 5.133712291717529
Validation loss: 5.231510080317015

Epoch: 5| Step: 7
Training loss: 5.816152572631836
Validation loss: 5.223464114691621

Epoch: 5| Step: 8
Training loss: 4.595824718475342
Validation loss: 5.208231992619012

Epoch: 5| Step: 9
Training loss: 3.9102768898010254
Validation loss: 5.1968014624810985

Epoch: 5| Step: 10
Training loss: 4.9512410163879395
Validation loss: 5.1835766966624925

Epoch: 19| Step: 0
Training loss: 5.074368476867676
Validation loss: 5.158226074710969

Epoch: 5| Step: 1
Training loss: 5.099559783935547
Validation loss: 5.144636964285246

Epoch: 5| Step: 2
Training loss: 5.221261024475098
Validation loss: 5.127593053284512

Epoch: 5| Step: 3
Training loss: 5.166780948638916
Validation loss: 5.114876275421471

Epoch: 5| Step: 4
Training loss: 5.5314507484436035
Validation loss: 5.10497030135124

Epoch: 5| Step: 5
Training loss: 5.364297389984131
Validation loss: 5.093844895721764

Epoch: 5| Step: 6
Training loss: 3.8763413429260254
Validation loss: 5.064931695179273

Epoch: 5| Step: 7
Training loss: 4.446760177612305
Validation loss: 5.063772811684557

Epoch: 5| Step: 8
Training loss: 4.981013774871826
Validation loss: 5.0441464557442615

Epoch: 5| Step: 9
Training loss: 4.287585258483887
Validation loss: 5.029589509451261

Epoch: 5| Step: 10
Training loss: 4.166141510009766
Validation loss: 5.010835642455726

Epoch: 20| Step: 0
Training loss: 4.388622760772705
Validation loss: 4.993255969016783

Epoch: 5| Step: 1
Training loss: 4.296801567077637
Validation loss: 4.995105348607545

Epoch: 5| Step: 2
Training loss: 4.133406639099121
Validation loss: 4.962562063688873

Epoch: 5| Step: 3
Training loss: 5.041308403015137
Validation loss: 4.956876539414929

Epoch: 5| Step: 4
Training loss: 4.988170146942139
Validation loss: 4.939281155986171

Epoch: 5| Step: 5
Training loss: 4.372694492340088
Validation loss: 4.91788391400409

Epoch: 5| Step: 6
Training loss: 4.621994972229004
Validation loss: 4.90251067889634

Epoch: 5| Step: 7
Training loss: 4.892515182495117
Validation loss: 4.8900761758127524

Epoch: 5| Step: 8
Training loss: 4.385304927825928
Validation loss: 4.86081463290799

Epoch: 5| Step: 9
Training loss: 5.031013011932373
Validation loss: 4.854633649190267

Epoch: 5| Step: 10
Training loss: 5.55125617980957
Validation loss: 4.837039978273453

Epoch: 21| Step: 0
Training loss: 5.1640167236328125
Validation loss: 4.81478044550906

Epoch: 5| Step: 1
Training loss: 3.627044200897217
Validation loss: 4.811710542248141

Epoch: 5| Step: 2
Training loss: 4.150478363037109
Validation loss: 4.788905697484171

Epoch: 5| Step: 3
Training loss: 4.571158409118652
Validation loss: 4.774137584112024

Epoch: 5| Step: 4
Training loss: 5.7097487449646
Validation loss: 4.751248226370863

Epoch: 5| Step: 5
Training loss: 4.752927303314209
Validation loss: 4.740082838202036

Epoch: 5| Step: 6
Training loss: 3.9712631702423096
Validation loss: 4.736618298356251

Epoch: 5| Step: 7
Training loss: 4.408758163452148
Validation loss: 4.704356173033355

Epoch: 5| Step: 8
Training loss: 4.8018903732299805
Validation loss: 4.673955312339208

Epoch: 5| Step: 9
Training loss: 3.902210235595703
Validation loss: 4.680322749640352

Epoch: 5| Step: 10
Training loss: 4.46262264251709
Validation loss: 4.649067776177519

Epoch: 22| Step: 0
Training loss: 5.1143717765808105
Validation loss: 4.643991680555446

Epoch: 5| Step: 1
Training loss: 5.1509881019592285
Validation loss: 4.6232427473991144

Epoch: 5| Step: 2
Training loss: 3.7951531410217285
Validation loss: 4.604557601354456

Epoch: 5| Step: 3
Training loss: 4.85799503326416
Validation loss: 4.578550641254712

Epoch: 5| Step: 4
Training loss: 5.1420793533325195
Validation loss: 4.560225671337497

Epoch: 5| Step: 5
Training loss: 4.062164783477783
Validation loss: 4.534830277965915

Epoch: 5| Step: 6
Training loss: 3.8323540687561035
Validation loss: 4.528304922965265

Epoch: 5| Step: 7
Training loss: 3.4553382396698
Validation loss: 4.518110347050492

Epoch: 5| Step: 8
Training loss: 4.1996355056762695
Validation loss: 4.4707097648292455

Epoch: 5| Step: 9
Training loss: 3.64689564704895
Validation loss: 4.464131324521957

Epoch: 5| Step: 10
Training loss: 4.031140327453613
Validation loss: 4.445075373495778

Epoch: 23| Step: 0
Training loss: 4.068943977355957
Validation loss: 4.423194357143935

Epoch: 5| Step: 1
Training loss: 4.157238483428955
Validation loss: 4.404377465607018

Epoch: 5| Step: 2
Training loss: 4.2334885597229
Validation loss: 4.397475304142121

Epoch: 5| Step: 3
Training loss: 4.225956916809082
Validation loss: 4.378206135124288

Epoch: 5| Step: 4
Training loss: 4.908324241638184
Validation loss: 4.347453512171263

Epoch: 5| Step: 5
Training loss: 3.0689921379089355
Validation loss: 4.347046529093096

Epoch: 5| Step: 6
Training loss: 3.771146059036255
Validation loss: 4.315971748803252

Epoch: 5| Step: 7
Training loss: 4.6054840087890625
Validation loss: 4.297096031968311

Epoch: 5| Step: 8
Training loss: 4.81853723526001
Validation loss: 4.290302127920171

Epoch: 5| Step: 9
Training loss: 3.463052749633789
Validation loss: 4.256971543835055

Epoch: 5| Step: 10
Training loss: 3.8197968006134033
Validation loss: 4.239626643478229

Epoch: 24| Step: 0
Training loss: 3.670243501663208
Validation loss: 4.195036800958777

Epoch: 5| Step: 1
Training loss: 3.7032477855682373
Validation loss: 4.188794387284146

Epoch: 5| Step: 2
Training loss: 4.440164566040039
Validation loss: 4.160953929347377

Epoch: 5| Step: 3
Training loss: 3.7794532775878906
Validation loss: 4.148707871795983

Epoch: 5| Step: 4
Training loss: 4.159059524536133
Validation loss: 4.11106333168604

Epoch: 5| Step: 5
Training loss: 3.5272622108459473
Validation loss: 4.10755681478849

Epoch: 5| Step: 6
Training loss: 2.8195204734802246
Validation loss: 4.0843124210193595

Epoch: 5| Step: 7
Training loss: 4.031796932220459
Validation loss: 4.073411500582131

Epoch: 5| Step: 8
Training loss: 3.6718475818634033
Validation loss: 4.0407246364060265

Epoch: 5| Step: 9
Training loss: 4.2556281089782715
Validation loss: 4.037074642796671

Epoch: 5| Step: 10
Training loss: 5.084270477294922
Validation loss: 3.9823254462211364

Epoch: 25| Step: 0
Training loss: 2.651583194732666
Validation loss: 3.9961498655298704

Epoch: 5| Step: 1
Training loss: 3.9750373363494873
Validation loss: 3.9858184014597247

Epoch: 5| Step: 2
Training loss: 3.5004591941833496
Validation loss: 3.9572843326035367

Epoch: 5| Step: 3
Training loss: 4.143325328826904
Validation loss: 3.9325637304654686

Epoch: 5| Step: 4
Training loss: 3.708019256591797
Validation loss: 3.9137248890374297

Epoch: 5| Step: 5
Training loss: 3.1503918170928955
Validation loss: 3.8999346302401636

Epoch: 5| Step: 6
Training loss: 3.6764016151428223
Validation loss: 3.8826956236234276

Epoch: 5| Step: 7
Training loss: 4.19382381439209
Validation loss: 3.848381221935313

Epoch: 5| Step: 8
Training loss: 3.588869571685791
Validation loss: 3.8320345263327322

Epoch: 5| Step: 9
Training loss: 4.846067905426025
Validation loss: 3.8016306610517603

Epoch: 5| Step: 10
Training loss: 3.628215789794922
Validation loss: 3.796559279964816

Epoch: 26| Step: 0
Training loss: 4.365706443786621
Validation loss: 3.763151445696431

Epoch: 5| Step: 1
Training loss: 3.3886635303497314
Validation loss: 3.758584919796195

Epoch: 5| Step: 2
Training loss: 3.4129345417022705
Validation loss: 3.719822468296174

Epoch: 5| Step: 3
Training loss: 3.929333448410034
Validation loss: 3.697053699083226

Epoch: 5| Step: 4
Training loss: 3.9912161827087402
Validation loss: 3.7031048344027613

Epoch: 5| Step: 5
Training loss: 3.620161771774292
Validation loss: 3.6557503618219847

Epoch: 5| Step: 6
Training loss: 3.404172420501709
Validation loss: 3.6313680346294115

Epoch: 5| Step: 7
Training loss: 2.8487155437469482
Validation loss: 3.6268547734906598

Epoch: 5| Step: 8
Training loss: 3.575758695602417
Validation loss: 3.606228854066582

Epoch: 5| Step: 9
Training loss: 3.747842311859131
Validation loss: 3.584011700845534

Epoch: 5| Step: 10
Training loss: 2.7879035472869873
Validation loss: 3.5620458510614212

Epoch: 27| Step: 0
Training loss: 2.742253541946411
Validation loss: 3.523178387713689

Epoch: 5| Step: 1
Training loss: 3.180243968963623
Validation loss: 3.510941651559645

Epoch: 5| Step: 2
Training loss: 4.054436683654785
Validation loss: 3.47326926262148

Epoch: 5| Step: 3
Training loss: 3.5383877754211426
Validation loss: 3.480008609833256

Epoch: 5| Step: 4
Training loss: 3.2729732990264893
Validation loss: 3.4477382193329515

Epoch: 5| Step: 5
Training loss: 3.5540051460266113
Validation loss: 3.4146587259025982

Epoch: 5| Step: 6
Training loss: 3.021925926208496
Validation loss: 3.4091121919693483

Epoch: 5| Step: 7
Training loss: 3.163985013961792
Validation loss: 3.4094911980372604

Epoch: 5| Step: 8
Training loss: 3.789834499359131
Validation loss: 3.3638165894375054

Epoch: 5| Step: 9
Training loss: 3.7332565784454346
Validation loss: 3.3578067518049672

Epoch: 5| Step: 10
Training loss: 2.9333155155181885
Validation loss: 3.3065264148096882

Epoch: 28| Step: 0
Training loss: 4.190345764160156
Validation loss: 3.283727276709772

Epoch: 5| Step: 1
Training loss: 3.853719711303711
Validation loss: 3.2648704051971436

Epoch: 5| Step: 2
Training loss: 2.345672845840454
Validation loss: 3.258471909389701

Epoch: 5| Step: 3
Training loss: 2.957714080810547
Validation loss: 3.2330752393250823

Epoch: 5| Step: 4
Training loss: 2.8562729358673096
Validation loss: 3.1991101106007895

Epoch: 5| Step: 5
Training loss: 2.6622183322906494
Validation loss: 3.2000335929214314

Epoch: 5| Step: 6
Training loss: 3.5016379356384277
Validation loss: 3.176462188843758

Epoch: 5| Step: 7
Training loss: 3.498734951019287
Validation loss: 3.1474618347742225

Epoch: 5| Step: 8
Training loss: 3.0624496936798096
Validation loss: 3.135326447025422

Epoch: 5| Step: 9
Training loss: 2.8424201011657715
Validation loss: 3.1208506630313013

Epoch: 5| Step: 10
Training loss: 2.7855567932128906
Validation loss: 3.0892062033376386

Epoch: 29| Step: 0
Training loss: 2.37205171585083
Validation loss: 3.067452733234693

Epoch: 5| Step: 1
Training loss: 2.9715023040771484
Validation loss: 3.0350790715986684

Epoch: 5| Step: 2
Training loss: 3.059196949005127
Validation loss: 3.0303805848603607

Epoch: 5| Step: 3
Training loss: 2.786165714263916
Validation loss: 3.0065472459280365

Epoch: 5| Step: 4
Training loss: 2.741495132446289
Validation loss: 3.007062148022395

Epoch: 5| Step: 5
Training loss: 2.8510539531707764
Validation loss: 2.998491746123119

Epoch: 5| Step: 6
Training loss: 3.2883479595184326
Validation loss: 2.9204920620046635

Epoch: 5| Step: 7
Training loss: 2.5925185680389404
Validation loss: 2.929397218970842

Epoch: 5| Step: 8
Training loss: 4.039319038391113
Validation loss: 2.879363049742996

Epoch: 5| Step: 9
Training loss: 2.4745826721191406
Validation loss: 2.880259629218809

Epoch: 5| Step: 10
Training loss: 3.9760727882385254
Validation loss: 2.858841880675285

Epoch: 30| Step: 0
Training loss: 2.7711853981018066
Validation loss: 2.8311777345595823

Epoch: 5| Step: 1
Training loss: 2.9765625
Validation loss: 2.7980742377619587

Epoch: 5| Step: 2
Training loss: 2.991093873977661
Validation loss: 2.801423531706615

Epoch: 5| Step: 3
Training loss: 2.3984622955322266
Validation loss: 2.8112748015311455

Epoch: 5| Step: 4
Training loss: 2.8723976612091064
Validation loss: 2.759953793659005

Epoch: 5| Step: 5
Training loss: 3.926039218902588
Validation loss: 2.7254121995741323

Epoch: 5| Step: 6
Training loss: 3.146151065826416
Validation loss: 2.7328289965147614

Epoch: 5| Step: 7
Training loss: 2.1881861686706543
Validation loss: 2.6936077661411737

Epoch: 5| Step: 8
Training loss: 2.350557804107666
Validation loss: 2.6584475988982827

Epoch: 5| Step: 9
Training loss: 2.7675631046295166
Validation loss: 2.635626495525401

Epoch: 5| Step: 10
Training loss: 3.2059528827667236
Validation loss: 2.6567613181247505

Epoch: 31| Step: 0
Training loss: 3.161320209503174
Validation loss: 2.627840224132743

Epoch: 5| Step: 1
Training loss: 2.3703339099884033
Validation loss: 2.6021014951890513

Epoch: 5| Step: 2
Training loss: 2.7553203105926514
Validation loss: 2.590008076801095

Epoch: 5| Step: 3
Training loss: 3.0758001804351807
Validation loss: 2.6123126527314544

Epoch: 5| Step: 4
Training loss: 2.7989649772644043
Validation loss: 2.5732585512181765

Epoch: 5| Step: 5
Training loss: 2.4766578674316406
Validation loss: 2.572743777305849

Epoch: 5| Step: 6
Training loss: 2.668121576309204
Validation loss: 2.492906234597647

Epoch: 5| Step: 7
Training loss: 2.971930980682373
Validation loss: 2.4941535431851625

Epoch: 5| Step: 8
Training loss: 2.7237915992736816
Validation loss: 2.480458559528474

Epoch: 5| Step: 9
Training loss: 2.2271389961242676
Validation loss: 2.4458411073171966

Epoch: 5| Step: 10
Training loss: 2.7415473461151123
Validation loss: 2.4852596047104045

Epoch: 32| Step: 0
Training loss: 2.787471294403076
Validation loss: 2.463012890149188

Epoch: 5| Step: 1
Training loss: 2.507319927215576
Validation loss: 2.440651100168946

Epoch: 5| Step: 2
Training loss: 2.498833656311035
Validation loss: 2.4252004700322307

Epoch: 5| Step: 3
Training loss: 2.345386028289795
Validation loss: 2.464865792182184

Epoch: 5| Step: 4
Training loss: 2.4845848083496094
Validation loss: 2.3963114420572915

Epoch: 5| Step: 5
Training loss: 2.8468589782714844
Validation loss: 2.414948355767035

Epoch: 5| Step: 6
Training loss: 2.8880560398101807
Validation loss: 2.348040924277357

Epoch: 5| Step: 7
Training loss: 2.4741051197052
Validation loss: 2.349692935584694

Epoch: 5| Step: 8
Training loss: 2.5542941093444824
Validation loss: 2.351307753593691

Epoch: 5| Step: 9
Training loss: 3.2019553184509277
Validation loss: 2.296522726294815

Epoch: 5| Step: 10
Training loss: 2.411475419998169
Validation loss: 2.2987072954895678

Epoch: 33| Step: 0
Training loss: 2.1449837684631348
Validation loss: 2.2974341018225557

Epoch: 5| Step: 1
Training loss: 2.356813430786133
Validation loss: 2.2728254615619616

Epoch: 5| Step: 2
Training loss: 2.905606269836426
Validation loss: 2.2324290403755764

Epoch: 5| Step: 3
Training loss: 2.4855122566223145
Validation loss: 2.2500775347473803

Epoch: 5| Step: 4
Training loss: 2.8158118724823
Validation loss: 2.2733211594243206

Epoch: 5| Step: 5
Training loss: 2.5717711448669434
Validation loss: 2.2994734548753306

Epoch: 5| Step: 6
Training loss: 2.7275912761688232
Validation loss: 2.2968908868810183

Epoch: 5| Step: 7
Training loss: 2.467747211456299
Validation loss: 2.2754647090870845

Epoch: 5| Step: 8
Training loss: 2.061370372772217
Validation loss: 2.292568568260439

Epoch: 5| Step: 9
Training loss: 2.803466320037842
Validation loss: 2.2758218396094536

Epoch: 5| Step: 10
Training loss: 2.1978378295898438
Validation loss: 2.2558085918426514

Epoch: 34| Step: 0
Training loss: 2.885108470916748
Validation loss: 2.232754276644799

Epoch: 5| Step: 1
Training loss: 1.6859811544418335
Validation loss: 2.2152345334329913

Epoch: 5| Step: 2
Training loss: 2.724302291870117
Validation loss: 2.199932504725713

Epoch: 5| Step: 3
Training loss: 2.22263503074646
Validation loss: 2.161010197413865

Epoch: 5| Step: 4
Training loss: 2.38344669342041
Validation loss: 2.195124690250684

Epoch: 5| Step: 5
Training loss: 2.0895392894744873
Validation loss: 2.235090022446007

Epoch: 5| Step: 6
Training loss: 2.716463565826416
Validation loss: 2.165728420339605

Epoch: 5| Step: 7
Training loss: 3.3634421825408936
Validation loss: 2.172865418977635

Epoch: 5| Step: 8
Training loss: 1.9774471521377563
Validation loss: 2.185128096611269

Epoch: 5| Step: 9
Training loss: 2.578975200653076
Validation loss: 2.2023081523115917

Epoch: 5| Step: 10
Training loss: 3.194215774536133
Validation loss: 2.1244562082393195

Epoch: 35| Step: 0
Training loss: 2.2443959712982178
Validation loss: 2.2066424098066104

Epoch: 5| Step: 1
Training loss: 2.609565496444702
Validation loss: 2.144919782556513

Epoch: 5| Step: 2
Training loss: 2.2496752738952637
Validation loss: 2.1945356579237085

Epoch: 5| Step: 3
Training loss: 2.487605094909668
Validation loss: 2.183391514644828

Epoch: 5| Step: 4
Training loss: 2.3084158897399902
Validation loss: 2.156272598492202

Epoch: 5| Step: 5
Training loss: 2.1698086261749268
Validation loss: 2.1436190925618654

Epoch: 5| Step: 6
Training loss: 2.2144508361816406
Validation loss: 2.1723192199583976

Epoch: 5| Step: 7
Training loss: 2.3319931030273438
Validation loss: 2.122328971021919

Epoch: 5| Step: 8
Training loss: 2.664646863937378
Validation loss: 2.1188478239120974

Epoch: 5| Step: 9
Training loss: 3.14863920211792
Validation loss: 2.1497691216007357

Epoch: 5| Step: 10
Training loss: 2.743759870529175
Validation loss: 2.136140900273477

Epoch: 36| Step: 0
Training loss: 2.791389226913452
Validation loss: 2.160756059872207

Epoch: 5| Step: 1
Training loss: 3.1901607513427734
Validation loss: 2.179095411813387

Epoch: 5| Step: 2
Training loss: 2.4446442127227783
Validation loss: 2.1289959158948673

Epoch: 5| Step: 3
Training loss: 2.1792356967926025
Validation loss: 2.1165528297424316

Epoch: 5| Step: 4
Training loss: 2.6758577823638916
Validation loss: 2.177748990315263

Epoch: 5| Step: 5
Training loss: 2.064347743988037
Validation loss: 2.1615196607446157

Epoch: 5| Step: 6
Training loss: 2.6567835807800293
Validation loss: 2.1647712671628563

Epoch: 5| Step: 7
Training loss: 2.79144287109375
Validation loss: 2.1087687784625637

Epoch: 5| Step: 8
Training loss: 2.5191166400909424
Validation loss: 2.1446336353978803

Epoch: 5| Step: 9
Training loss: 1.8406627178192139
Validation loss: 2.138783149821784

Epoch: 5| Step: 10
Training loss: 2.103750467300415
Validation loss: 2.137763346395185

Epoch: 37| Step: 0
Training loss: 2.7205281257629395
Validation loss: 2.1289931779266684

Epoch: 5| Step: 1
Training loss: 3.0469539165496826
Validation loss: 2.1461010363794144

Epoch: 5| Step: 2
Training loss: 2.160193920135498
Validation loss: 2.066676414141091

Epoch: 5| Step: 3
Training loss: 2.0236077308654785
Validation loss: 2.115052915388538

Epoch: 5| Step: 4
Training loss: 2.6609816551208496
Validation loss: 2.157219471470002

Epoch: 5| Step: 5
Training loss: 2.852403163909912
Validation loss: 2.1307781639919487

Epoch: 5| Step: 6
Training loss: 2.5848636627197266
Validation loss: 2.1725365807933192

Epoch: 5| Step: 7
Training loss: 2.151125907897949
Validation loss: 2.145317014827523

Epoch: 5| Step: 8
Training loss: 2.9545400142669678
Validation loss: 2.1005247433980307

Epoch: 5| Step: 9
Training loss: 1.9644187688827515
Validation loss: 2.156633501411766

Epoch: 5| Step: 10
Training loss: 2.0359506607055664
Validation loss: 2.193944006837824

Epoch: 38| Step: 0
Training loss: 2.1005709171295166
Validation loss: 2.111244104241812

Epoch: 5| Step: 1
Training loss: 2.6379051208496094
Validation loss: 2.1303793704637917

Epoch: 5| Step: 2
Training loss: 2.611128330230713
Validation loss: 2.142672889976091

Epoch: 5| Step: 3
Training loss: 2.2177677154541016
Validation loss: 2.094963736431573

Epoch: 5| Step: 4
Training loss: 2.5645713806152344
Validation loss: 2.154152580486831

Epoch: 5| Step: 5
Training loss: 1.9502118825912476
Validation loss: 2.1132120881029355

Epoch: 5| Step: 6
Training loss: 2.5872738361358643
Validation loss: 2.1066651549390567

Epoch: 5| Step: 7
Training loss: 1.8082252740859985
Validation loss: 2.0961231852090485

Epoch: 5| Step: 8
Training loss: 2.7217087745666504
Validation loss: 2.120758065613367

Epoch: 5| Step: 9
Training loss: 3.016623020172119
Validation loss: 2.121921484188367

Epoch: 5| Step: 10
Training loss: 2.9754974842071533
Validation loss: 2.1104152382061048

Epoch: 39| Step: 0
Training loss: 2.7102019786834717
Validation loss: 2.150943260039053

Epoch: 5| Step: 1
Training loss: 2.735323429107666
Validation loss: 2.1292847305215816

Epoch: 5| Step: 2
Training loss: 2.6971182823181152
Validation loss: 2.138717797494704

Epoch: 5| Step: 3
Training loss: 2.542664051055908
Validation loss: 2.160876399727278

Epoch: 5| Step: 4
Training loss: 2.401247501373291
Validation loss: 2.1574300655754666

Epoch: 5| Step: 5
Training loss: 2.4525513648986816
Validation loss: 2.0575737594276347

Epoch: 5| Step: 6
Training loss: 2.0304970741271973
Validation loss: 2.133119524166148

Epoch: 5| Step: 7
Training loss: 2.2938590049743652
Validation loss: 2.158000869135703

Epoch: 5| Step: 8
Training loss: 1.9031686782836914
Validation loss: 2.0732064247131348

Epoch: 5| Step: 9
Training loss: 2.7215428352355957
Validation loss: 2.0620121353416034

Epoch: 5| Step: 10
Training loss: 2.933718681335449
Validation loss: 2.118077121755128

Epoch: 40| Step: 0
Training loss: 2.556718587875366
Validation loss: 2.1574267366881013

Epoch: 5| Step: 1
Training loss: 2.498607635498047
Validation loss: 2.086074916265344

Epoch: 5| Step: 2
Training loss: 2.5696980953216553
Validation loss: 2.0631859379429973

Epoch: 5| Step: 3
Training loss: 2.016411542892456
Validation loss: 2.062748339868361

Epoch: 5| Step: 4
Training loss: 2.599796772003174
Validation loss: 2.096325489782518

Epoch: 5| Step: 5
Training loss: 2.1863739490509033
Validation loss: 2.1339103355202624

Epoch: 5| Step: 6
Training loss: 3.1341986656188965
Validation loss: 2.1211119236484652

Epoch: 5| Step: 7
Training loss: 1.8530254364013672
Validation loss: 2.0979354958380423

Epoch: 5| Step: 8
Training loss: 2.4630279541015625
Validation loss: 2.0881346746157576

Epoch: 5| Step: 9
Training loss: 2.7549426555633545
Validation loss: 2.1398796535307363

Epoch: 5| Step: 10
Training loss: 2.460343360900879
Validation loss: 2.156208707440284

Epoch: 41| Step: 0
Training loss: 1.8405935764312744
Validation loss: 2.1356843838127713

Epoch: 5| Step: 1
Training loss: 2.728038787841797
Validation loss: 2.0903993601440103

Epoch: 5| Step: 2
Training loss: 2.957737445831299
Validation loss: 2.060877841006043

Epoch: 5| Step: 3
Training loss: 2.646395206451416
Validation loss: 2.0306787439571914

Epoch: 5| Step: 4
Training loss: 2.2648861408233643
Validation loss: 2.100532019010154

Epoch: 5| Step: 5
Training loss: 2.5693612098693848
Validation loss: 2.1282414492740425

Epoch: 5| Step: 6
Training loss: 2.3288111686706543
Validation loss: 2.102688253566783

Epoch: 5| Step: 7
Training loss: 2.5372233390808105
Validation loss: 2.1296943797860095

Epoch: 5| Step: 8
Training loss: 2.99766206741333
Validation loss: 2.115831469976774

Epoch: 5| Step: 9
Training loss: 2.3863697052001953
Validation loss: 2.101799516267674

Epoch: 5| Step: 10
Training loss: 1.9140459299087524
Validation loss: 2.0674756624365367

Epoch: 42| Step: 0
Training loss: 2.939305305480957
Validation loss: 2.1290004099569013

Epoch: 5| Step: 1
Training loss: 2.343177318572998
Validation loss: 2.0920872842111895

Epoch: 5| Step: 2
Training loss: 2.8255410194396973
Validation loss: 2.0641553889038744

Epoch: 5| Step: 3
Training loss: 1.9413448572158813
Validation loss: 2.0820637133813675

Epoch: 5| Step: 4
Training loss: 2.4132213592529297
Validation loss: 2.053341639939175

Epoch: 5| Step: 5
Training loss: 2.6393418312072754
Validation loss: 2.0718257657943235

Epoch: 5| Step: 6
Training loss: 2.8395705223083496
Validation loss: 2.093129047783472

Epoch: 5| Step: 7
Training loss: 1.8552730083465576
Validation loss: 2.0644814506653817

Epoch: 5| Step: 8
Training loss: 2.3591604232788086
Validation loss: 2.0506399946828044

Epoch: 5| Step: 9
Training loss: 2.4848899841308594
Validation loss: 2.0843538955975602

Epoch: 5| Step: 10
Training loss: 2.9019672870635986
Validation loss: 2.040207983345114

Epoch: 43| Step: 0
Training loss: 1.9473800659179688
Validation loss: 2.072905300765909

Epoch: 5| Step: 1
Training loss: 2.819326400756836
Validation loss: 2.1079534689585366

Epoch: 5| Step: 2
Training loss: 2.2112197875976562
Validation loss: 2.0667624024934668

Epoch: 5| Step: 3
Training loss: 2.873472213745117
Validation loss: 2.0567364000505015

Epoch: 5| Step: 4
Training loss: 2.366982936859131
Validation loss: 2.055180393239503

Epoch: 5| Step: 5
Training loss: 2.150158643722534
Validation loss: 2.1005323548470773

Epoch: 5| Step: 6
Training loss: 1.6868032217025757
Validation loss: 2.083108325158396

Epoch: 5| Step: 7
Training loss: 2.564112424850464
Validation loss: 2.0318388682539745

Epoch: 5| Step: 8
Training loss: 2.772625684738159
Validation loss: 2.0390401911991898

Epoch: 5| Step: 9
Training loss: 3.0194005966186523
Validation loss: 2.0827160804502425

Epoch: 5| Step: 10
Training loss: 2.554028034210205
Validation loss: 2.1107078995755924

Epoch: 44| Step: 0
Training loss: 2.3836445808410645
Validation loss: 2.0957919615571217

Epoch: 5| Step: 1
Training loss: 2.34779953956604
Validation loss: 2.0236955522209086

Epoch: 5| Step: 2
Training loss: 1.8330614566802979
Validation loss: 2.0693682637265933

Epoch: 5| Step: 3
Training loss: 2.339171886444092
Validation loss: 2.0237975479454122

Epoch: 5| Step: 4
Training loss: 2.9656875133514404
Validation loss: 2.048070897338211

Epoch: 5| Step: 5
Training loss: 2.3681070804595947
Validation loss: 2.071170937630438

Epoch: 5| Step: 6
Training loss: 2.435023784637451
Validation loss: 2.0423422603196997

Epoch: 5| Step: 7
Training loss: 2.6336166858673096
Validation loss: 2.0421951458018315

Epoch: 5| Step: 8
Training loss: 2.3837757110595703
Validation loss: 2.0956527379251297

Epoch: 5| Step: 9
Training loss: 2.881960868835449
Validation loss: 2.0539573315651185

Epoch: 5| Step: 10
Training loss: 2.2641351222991943
Validation loss: 2.12673996597208

Epoch: 45| Step: 0
Training loss: 2.089716911315918
Validation loss: 2.037503486038536

Epoch: 5| Step: 1
Training loss: 2.422184467315674
Validation loss: 2.0664881429364605

Epoch: 5| Step: 2
Training loss: 2.376012086868286
Validation loss: 2.0349047286536104

Epoch: 5| Step: 3
Training loss: 2.5180411338806152
Validation loss: 2.0884355575807634

Epoch: 5| Step: 4
Training loss: 2.1568827629089355
Validation loss: 2.0748252073923745

Epoch: 5| Step: 5
Training loss: 1.7015348672866821
Validation loss: 2.1059388319651284

Epoch: 5| Step: 6
Training loss: 3.1605818271636963
Validation loss: 2.063395700147075

Epoch: 5| Step: 7
Training loss: 2.6607108116149902
Validation loss: 2.0488023975844025

Epoch: 5| Step: 8
Training loss: 2.341890811920166
Validation loss: 2.085465805504912

Epoch: 5| Step: 9
Training loss: 2.74287486076355
Validation loss: 2.092808567067628

Epoch: 5| Step: 10
Training loss: 2.6616408824920654
Validation loss: 2.087392153278474

Epoch: 46| Step: 0
Training loss: 2.1689388751983643
Validation loss: 2.0867694603499545

Epoch: 5| Step: 1
Training loss: 1.8821481466293335
Validation loss: 2.0599459114895073

Epoch: 5| Step: 2
Training loss: 2.4112532138824463
Validation loss: 2.1059031383965605

Epoch: 5| Step: 3
Training loss: 2.967465877532959
Validation loss: 2.0678006564417193

Epoch: 5| Step: 4
Training loss: 3.280294895172119
Validation loss: 2.094496629571402

Epoch: 5| Step: 5
Training loss: 2.548229694366455
Validation loss: 2.0272010564804077

Epoch: 5| Step: 6
Training loss: 2.6266138553619385
Validation loss: 2.083271175302485

Epoch: 5| Step: 7
Training loss: 1.6615813970565796
Validation loss: 2.0716233279115412

Epoch: 5| Step: 8
Training loss: 2.3256049156188965
Validation loss: 2.069055768751329

Epoch: 5| Step: 9
Training loss: 2.2294836044311523
Validation loss: 2.095834142418318

Epoch: 5| Step: 10
Training loss: 2.8141372203826904
Validation loss: 2.108079001467715

Epoch: 47| Step: 0
Training loss: 2.516270875930786
Validation loss: 2.077872847998014

Epoch: 5| Step: 1
Training loss: 2.9550247192382812
Validation loss: 2.1151109767216507

Epoch: 5| Step: 2
Training loss: 1.9510128498077393
Validation loss: 2.0366851924568095

Epoch: 5| Step: 3
Training loss: 2.146557331085205
Validation loss: 2.060927152633667

Epoch: 5| Step: 4
Training loss: 2.057673931121826
Validation loss: 2.0760515505267727

Epoch: 5| Step: 5
Training loss: 2.0991859436035156
Validation loss: 2.1284409107700473

Epoch: 5| Step: 6
Training loss: 2.207198143005371
Validation loss: 2.1205569210872857

Epoch: 5| Step: 7
Training loss: 3.1602230072021484
Validation loss: 2.099491173221219

Epoch: 5| Step: 8
Training loss: 2.244852066040039
Validation loss: 2.057589591190379

Epoch: 5| Step: 9
Training loss: 2.7722721099853516
Validation loss: 2.0993369497278684

Epoch: 5| Step: 10
Training loss: 2.788499355316162
Validation loss: 2.0498234482221704

Epoch: 48| Step: 0
Training loss: 2.6397511959075928
Validation loss: 2.065388471849503

Epoch: 5| Step: 1
Training loss: 2.1143765449523926
Validation loss: 2.1092966282239525

Epoch: 5| Step: 2
Training loss: 2.873142957687378
Validation loss: 2.080559718993402

Epoch: 5| Step: 3
Training loss: 2.4079227447509766
Validation loss: 2.0607398043396654

Epoch: 5| Step: 4
Training loss: 2.719414710998535
Validation loss: 2.129499489261258

Epoch: 5| Step: 5
Training loss: 2.000476360321045
Validation loss: 2.054356572448566

Epoch: 5| Step: 6
Training loss: 1.635145902633667
Validation loss: 2.055025682654432

Epoch: 5| Step: 7
Training loss: 1.9450668096542358
Validation loss: 2.075196963484569

Epoch: 5| Step: 8
Training loss: 2.802370071411133
Validation loss: 2.0604926924551688

Epoch: 5| Step: 9
Training loss: 2.347642421722412
Validation loss: 2.05971295731042

Epoch: 5| Step: 10
Training loss: 3.572063446044922
Validation loss: 2.1019524194860972

Epoch: 49| Step: 0
Training loss: 2.0880255699157715
Validation loss: 2.0543185049487698

Epoch: 5| Step: 1
Training loss: 1.9468635320663452
Validation loss: 2.093982991351876

Epoch: 5| Step: 2
Training loss: 2.950754404067993
Validation loss: 2.076150245563958

Epoch: 5| Step: 3
Training loss: 2.7135202884674072
Validation loss: 2.094673115720031

Epoch: 5| Step: 4
Training loss: 2.458543300628662
Validation loss: 2.0394824884271108

Epoch: 5| Step: 5
Training loss: 2.078495740890503
Validation loss: 2.046382719470609

Epoch: 5| Step: 6
Training loss: 2.2052228450775146
Validation loss: 2.068670267699867

Epoch: 5| Step: 7
Training loss: 2.820565700531006
Validation loss: 2.0833155801219325

Epoch: 5| Step: 8
Training loss: 2.967240810394287
Validation loss: 2.084197072572606

Epoch: 5| Step: 9
Training loss: 1.7344954013824463
Validation loss: 2.0670420303139636

Epoch: 5| Step: 10
Training loss: 2.919613838195801
Validation loss: 2.0718883493895173

Epoch: 50| Step: 0
Training loss: 2.7726008892059326
Validation loss: 2.0861970583597818

Epoch: 5| Step: 1
Training loss: 2.679548740386963
Validation loss: 2.0761714404629124

Epoch: 5| Step: 2
Training loss: 2.63806414604187
Validation loss: 2.098514190284155

Epoch: 5| Step: 3
Training loss: 2.280987501144409
Validation loss: 2.062962011624408

Epoch: 5| Step: 4
Training loss: 2.234274387359619
Validation loss: 2.089095802717311

Epoch: 5| Step: 5
Training loss: 2.61721134185791
Validation loss: 2.0311899800454416

Epoch: 5| Step: 6
Training loss: 2.863969326019287
Validation loss: 2.066544181557112

Epoch: 5| Step: 7
Training loss: 2.2940433025360107
Validation loss: 2.050440416541151

Epoch: 5| Step: 8
Training loss: 1.9343299865722656
Validation loss: 2.0989406237038235

Epoch: 5| Step: 9
Training loss: 2.161865711212158
Validation loss: 2.0659537200004823

Epoch: 5| Step: 10
Training loss: 2.3624401092529297
Validation loss: 2.036642487331103

Epoch: 51| Step: 0
Training loss: 2.242473602294922
Validation loss: 2.0971796999695482

Epoch: 5| Step: 1
Training loss: 2.4800007343292236
Validation loss: 2.044888445126113

Epoch: 5| Step: 2
Training loss: 2.4699151515960693
Validation loss: 2.088724292734618

Epoch: 5| Step: 3
Training loss: 2.1223387718200684
Validation loss: 2.0823099267098213

Epoch: 5| Step: 4
Training loss: 2.6933586597442627
Validation loss: 2.091250317071074

Epoch: 5| Step: 5
Training loss: 2.7060508728027344
Validation loss: 2.0692222592651204

Epoch: 5| Step: 6
Training loss: 2.2461628913879395
Validation loss: 2.0695476993437736

Epoch: 5| Step: 7
Training loss: 2.2385830879211426
Validation loss: 2.0553479284368534

Epoch: 5| Step: 8
Training loss: 2.5860846042633057
Validation loss: 2.104706359165971

Epoch: 5| Step: 9
Training loss: 2.3393633365631104
Validation loss: 2.070761929276169

Epoch: 5| Step: 10
Training loss: 2.5526063442230225
Validation loss: 2.094296525883418

Epoch: 52| Step: 0
Training loss: 2.7567028999328613
Validation loss: 2.0725064662195023

Epoch: 5| Step: 1
Training loss: 2.3222815990448
Validation loss: 2.0816879054551483

Epoch: 5| Step: 2
Training loss: 1.8782497644424438
Validation loss: 2.092058727818151

Epoch: 5| Step: 3
Training loss: 2.361924886703491
Validation loss: 2.060305985071326

Epoch: 5| Step: 4
Training loss: 1.9031727313995361
Validation loss: 2.113474738213324

Epoch: 5| Step: 5
Training loss: 2.4958674907684326
Validation loss: 2.065151676054924

Epoch: 5| Step: 6
Training loss: 2.2836947441101074
Validation loss: 2.0607417091246574

Epoch: 5| Step: 7
Training loss: 2.177485704421997
Validation loss: 2.068798459986205

Epoch: 5| Step: 8
Training loss: 2.8335375785827637
Validation loss: 2.074747521390197

Epoch: 5| Step: 9
Training loss: 3.127185583114624
Validation loss: 2.084004489324426

Epoch: 5| Step: 10
Training loss: 2.7746798992156982
Validation loss: 2.080134025184057

Epoch: 53| Step: 0
Training loss: 2.6595215797424316
Validation loss: 2.083733747082372

Epoch: 5| Step: 1
Training loss: 2.496652603149414
Validation loss: 2.091699351546585

Epoch: 5| Step: 2
Training loss: 2.0125250816345215
Validation loss: 2.0828527135233723

Epoch: 5| Step: 3
Training loss: 2.2106871604919434
Validation loss: 2.0412843586296163

Epoch: 5| Step: 4
Training loss: 1.9356615543365479
Validation loss: 2.079644498004708

Epoch: 5| Step: 5
Training loss: 2.45996356010437
Validation loss: 2.091773427942748

Epoch: 5| Step: 6
Training loss: 1.9374675750732422
Validation loss: 2.1141451686941166

Epoch: 5| Step: 7
Training loss: 2.710646867752075
Validation loss: 2.0269829791079284

Epoch: 5| Step: 8
Training loss: 2.6527099609375
Validation loss: 2.0571344744774605

Epoch: 5| Step: 9
Training loss: 2.883270263671875
Validation loss: 2.107452566905688

Epoch: 5| Step: 10
Training loss: 3.182558298110962
Validation loss: 2.0632431212291924

Epoch: 54| Step: 0
Training loss: 2.3962018489837646
Validation loss: 2.0682903335940455

Epoch: 5| Step: 1
Training loss: 1.9089996814727783
Validation loss: 2.062055592895836

Epoch: 5| Step: 2
Training loss: 2.549201011657715
Validation loss: 2.0387883724704867

Epoch: 5| Step: 3
Training loss: 2.530393362045288
Validation loss: 2.0604805164439703

Epoch: 5| Step: 4
Training loss: 2.709632396697998
Validation loss: 2.054055436964958

Epoch: 5| Step: 5
Training loss: 1.3933168649673462
Validation loss: 2.0643044440977034

Epoch: 5| Step: 6
Training loss: 2.78372859954834
Validation loss: 2.0819424454883864

Epoch: 5| Step: 7
Training loss: 2.4110844135284424
Validation loss: 2.0342801937492947

Epoch: 5| Step: 8
Training loss: 3.0252037048339844
Validation loss: 2.0561236399476246

Epoch: 5| Step: 9
Training loss: 2.4801697731018066
Validation loss: 2.0808893019153225

Epoch: 5| Step: 10
Training loss: 2.184915781021118
Validation loss: 2.0716973786712973

Epoch: 55| Step: 0
Training loss: 2.474790573120117
Validation loss: 2.037905828927153

Epoch: 5| Step: 1
Training loss: 2.37178111076355
Validation loss: 2.114749446991951

Epoch: 5| Step: 2
Training loss: 1.8029531240463257
Validation loss: 2.0898745341967513

Epoch: 5| Step: 3
Training loss: 2.2178714275360107
Validation loss: 2.0873786352014028

Epoch: 5| Step: 4
Training loss: 2.4725100994110107
Validation loss: 2.0703031093843522

Epoch: 5| Step: 5
Training loss: 2.577270984649658
Validation loss: 2.0261094006158973

Epoch: 5| Step: 6
Training loss: 1.762332558631897
Validation loss: 2.0718112684065297

Epoch: 5| Step: 7
Training loss: 2.337185859680176
Validation loss: 2.052917468932367

Epoch: 5| Step: 8
Training loss: 2.340247631072998
Validation loss: 2.094169114225654

Epoch: 5| Step: 9
Training loss: 2.7779479026794434
Validation loss: 2.0652707533169816

Epoch: 5| Step: 10
Training loss: 3.3991048336029053
Validation loss: 2.0569579678197063

Epoch: 56| Step: 0
Training loss: 2.260409116744995
Validation loss: 2.0726377169291177

Epoch: 5| Step: 1
Training loss: 2.2670862674713135
Validation loss: 2.067666975400781

Epoch: 5| Step: 2
Training loss: 2.2124125957489014
Validation loss: 2.1010378791439916

Epoch: 5| Step: 3
Training loss: 2.247542381286621
Validation loss: 2.064057698813818

Epoch: 5| Step: 4
Training loss: 2.2626559734344482
Validation loss: 2.0844862678999543

Epoch: 5| Step: 5
Training loss: 2.674724578857422
Validation loss: 2.024808624739288

Epoch: 5| Step: 6
Training loss: 2.2395122051239014
Validation loss: 2.0773678313019457

Epoch: 5| Step: 7
Training loss: 2.653414726257324
Validation loss: 2.0544758791564615

Epoch: 5| Step: 8
Training loss: 2.0979647636413574
Validation loss: 2.0571324299740534

Epoch: 5| Step: 9
Training loss: 2.5287108421325684
Validation loss: 2.0925047320704304

Epoch: 5| Step: 10
Training loss: 3.027606248855591
Validation loss: 2.0748844787638676

Epoch: 57| Step: 0
Training loss: 2.246354579925537
Validation loss: 2.0664521237855316

Epoch: 5| Step: 1
Training loss: 2.2256834506988525
Validation loss: 2.089763154265701

Epoch: 5| Step: 2
Training loss: 2.1290123462677
Validation loss: 2.0760602348594257

Epoch: 5| Step: 3
Training loss: 2.413719415664673
Validation loss: 2.091345687066355

Epoch: 5| Step: 4
Training loss: 2.4482665061950684
Validation loss: 2.0546484775440668

Epoch: 5| Step: 5
Training loss: 2.7175750732421875
Validation loss: 2.0715316559678767

Epoch: 5| Step: 6
Training loss: 2.108287811279297
Validation loss: 2.080313758183551

Epoch: 5| Step: 7
Training loss: 2.8315346240997314
Validation loss: 2.1161945763454644

Epoch: 5| Step: 8
Training loss: 2.1971404552459717
Validation loss: 2.029096286783936

Epoch: 5| Step: 9
Training loss: 2.5211002826690674
Validation loss: 2.070255494886829

Epoch: 5| Step: 10
Training loss: 2.518400192260742
Validation loss: 2.0335984922224477

Epoch: 58| Step: 0
Training loss: 2.121333599090576
Validation loss: 2.0813809748618834

Epoch: 5| Step: 1
Training loss: 2.5339932441711426
Validation loss: 2.077026303096484

Epoch: 5| Step: 2
Training loss: 2.8258352279663086
Validation loss: 2.0617873386670182

Epoch: 5| Step: 3
Training loss: 2.3932361602783203
Validation loss: 2.0166590213775635

Epoch: 5| Step: 4
Training loss: 2.741823673248291
Validation loss: 2.073601817571989

Epoch: 5| Step: 5
Training loss: 2.122525930404663
Validation loss: 2.0528698352075394

Epoch: 5| Step: 6
Training loss: 2.0821120738983154
Validation loss: 2.067518949508667

Epoch: 5| Step: 7
Training loss: 2.3224852085113525
Validation loss: 2.058772317824825

Epoch: 5| Step: 8
Training loss: 1.6144511699676514
Validation loss: 2.071154385484675

Epoch: 5| Step: 9
Training loss: 2.909911632537842
Validation loss: 2.0814703331198743

Epoch: 5| Step: 10
Training loss: 2.724881887435913
Validation loss: 2.061137186583652

Epoch: 59| Step: 0
Training loss: 1.9732698202133179
Validation loss: 2.022583496186041

Epoch: 5| Step: 1
Training loss: 2.4835305213928223
Validation loss: 2.042893786584177

Epoch: 5| Step: 2
Training loss: 2.7661378383636475
Validation loss: 2.0820461050156625

Epoch: 5| Step: 3
Training loss: 2.549328565597534
Validation loss: 2.0549788116126932

Epoch: 5| Step: 4
Training loss: 2.769716262817383
Validation loss: 2.063799346646955

Epoch: 5| Step: 5
Training loss: 2.377920150756836
Validation loss: 2.0516213152998235

Epoch: 5| Step: 6
Training loss: 2.793078660964966
Validation loss: 2.0567171753093763

Epoch: 5| Step: 7
Training loss: 1.7751928567886353
Validation loss: 2.048092811338363

Epoch: 5| Step: 8
Training loss: 2.59773325920105
Validation loss: 2.0392481050183697

Epoch: 5| Step: 9
Training loss: 1.97187077999115
Validation loss: 2.0173824987103863

Epoch: 5| Step: 10
Training loss: 2.319176435470581
Validation loss: 2.0008913035033853

Epoch: 60| Step: 0
Training loss: 2.8651750087738037
Validation loss: 2.080131358997796

Epoch: 5| Step: 1
Training loss: 2.344327449798584
Validation loss: 2.0380072670598186

Epoch: 5| Step: 2
Training loss: 2.2638306617736816
Validation loss: 2.044582297725062

Epoch: 5| Step: 3
Training loss: 2.4111104011535645
Validation loss: 2.0418878319442912

Epoch: 5| Step: 4
Training loss: 2.4077870845794678
Validation loss: 2.0409120975002164

Epoch: 5| Step: 5
Training loss: 3.096001148223877
Validation loss: 2.0819681998222106

Epoch: 5| Step: 6
Training loss: 2.1715877056121826
Validation loss: 2.0629210151651853

Epoch: 5| Step: 7
Training loss: 2.398275375366211
Validation loss: 2.0834468603134155

Epoch: 5| Step: 8
Training loss: 2.097522258758545
Validation loss: 2.065870168388531

Epoch: 5| Step: 9
Training loss: 2.586610794067383
Validation loss: 2.0821696878761373

Epoch: 5| Step: 10
Training loss: 1.9563977718353271
Validation loss: 2.051178514316518

Epoch: 61| Step: 0
Training loss: 2.2208468914031982
Validation loss: 2.02775514254006

Epoch: 5| Step: 1
Training loss: 2.782397508621216
Validation loss: 2.061919399487075

Epoch: 5| Step: 2
Training loss: 2.335801601409912
Validation loss: 2.056659954850392

Epoch: 5| Step: 3
Training loss: 2.619497299194336
Validation loss: 2.0650974909464517

Epoch: 5| Step: 4
Training loss: 2.3522536754608154
Validation loss: 2.071277669681016

Epoch: 5| Step: 5
Training loss: 2.154564142227173
Validation loss: 2.0777242029866865

Epoch: 5| Step: 6
Training loss: 2.7034454345703125
Validation loss: 2.0979996714540707

Epoch: 5| Step: 7
Training loss: 2.207491636276245
Validation loss: 2.080506673423193

Epoch: 5| Step: 8
Training loss: 2.121704339981079
Validation loss: 2.0771655600558043

Epoch: 5| Step: 9
Training loss: 2.4399311542510986
Validation loss: 2.0498645254360732

Epoch: 5| Step: 10
Training loss: 2.589019298553467
Validation loss: 2.0099537795589817

Epoch: 62| Step: 0
Training loss: 2.453176259994507
Validation loss: 2.069833086382958

Epoch: 5| Step: 1
Training loss: 2.437175750732422
Validation loss: 2.048492068885475

Epoch: 5| Step: 2
Training loss: 2.521179676055908
Validation loss: 2.0634355314316286

Epoch: 5| Step: 3
Training loss: 2.707340717315674
Validation loss: 2.075477948752783

Epoch: 5| Step: 4
Training loss: 2.383608341217041
Validation loss: 2.0510854669796523

Epoch: 5| Step: 5
Training loss: 2.6489052772521973
Validation loss: 2.098891899149905

Epoch: 5| Step: 6
Training loss: 2.024263858795166
Validation loss: 2.0454909404118857

Epoch: 5| Step: 7
Training loss: 2.1865954399108887
Validation loss: 2.0549521446228027

Epoch: 5| Step: 8
Training loss: 2.5264382362365723
Validation loss: 2.0252077656407512

Epoch: 5| Step: 9
Training loss: 2.5558319091796875
Validation loss: 2.0228753500087286

Epoch: 5| Step: 10
Training loss: 1.749559760093689
Validation loss: 2.04720631722481

Epoch: 63| Step: 0
Training loss: 2.2547221183776855
Validation loss: 2.0902043029826176

Epoch: 5| Step: 1
Training loss: 2.7839818000793457
Validation loss: 2.0305291452715473

Epoch: 5| Step: 2
Training loss: 2.6000475883483887
Validation loss: 2.0481061781606367

Epoch: 5| Step: 3
Training loss: 2.469000816345215
Validation loss: 2.0598959230607554

Epoch: 5| Step: 4
Training loss: 1.9106651544570923
Validation loss: 2.0506597975248932

Epoch: 5| Step: 5
Training loss: 3.1478381156921387
Validation loss: 2.0658343684288765

Epoch: 5| Step: 6
Training loss: 1.90946364402771
Validation loss: 2.0972173585686633

Epoch: 5| Step: 7
Training loss: 2.7412047386169434
Validation loss: 2.0481232161163003

Epoch: 5| Step: 8
Training loss: 2.151623249053955
Validation loss: 2.078006059892716

Epoch: 5| Step: 9
Training loss: 2.645214557647705
Validation loss: 2.0341657028403333

Epoch: 5| Step: 10
Training loss: 1.4694808721542358
Validation loss: 2.076519720015987

Epoch: 64| Step: 0
Training loss: 2.5194458961486816
Validation loss: 2.0525256664522233

Epoch: 5| Step: 1
Training loss: 2.394118070602417
Validation loss: 2.0035615454437914

Epoch: 5| Step: 2
Training loss: 2.4156885147094727
Validation loss: 2.052854134190467

Epoch: 5| Step: 3
Training loss: 2.9045791625976562
Validation loss: 2.0362361836177048

Epoch: 5| Step: 4
Training loss: 2.574341058731079
Validation loss: 2.0485375465885287

Epoch: 5| Step: 5
Training loss: 2.684673309326172
Validation loss: 2.052058653164935

Epoch: 5| Step: 6
Training loss: 2.2273783683776855
Validation loss: 2.0461147177603936

Epoch: 5| Step: 7
Training loss: 2.4223551750183105
Validation loss: 2.0375344881447415

Epoch: 5| Step: 8
Training loss: 2.462968111038208
Validation loss: 2.0964587273136264

Epoch: 5| Step: 9
Training loss: 1.7737354040145874
Validation loss: 2.04656881670798

Epoch: 5| Step: 10
Training loss: 2.12385630607605
Validation loss: 2.0643098867067726

Epoch: 65| Step: 0
Training loss: 2.583629846572876
Validation loss: 2.0785039676133024

Epoch: 5| Step: 1
Training loss: 1.4169232845306396
Validation loss: 2.020595327500374

Epoch: 5| Step: 2
Training loss: 2.300457715988159
Validation loss: 2.043639673981615

Epoch: 5| Step: 3
Training loss: 2.211858034133911
Validation loss: 2.0189707561205794

Epoch: 5| Step: 4
Training loss: 2.558049201965332
Validation loss: 2.0203458929574616

Epoch: 5| Step: 5
Training loss: 2.5430679321289062
Validation loss: 2.0720992934319282

Epoch: 5| Step: 6
Training loss: 2.1249008178710938
Validation loss: 2.0880557901115826

Epoch: 5| Step: 7
Training loss: 2.5165963172912598
Validation loss: 2.0581347583442606

Epoch: 5| Step: 8
Training loss: 2.36222243309021
Validation loss: 2.050734086703229

Epoch: 5| Step: 9
Training loss: 2.4759888648986816
Validation loss: 2.073555579749487

Epoch: 5| Step: 10
Training loss: 3.2281317710876465
Validation loss: 2.0721685001927037

Epoch: 66| Step: 0
Training loss: 2.824902057647705
Validation loss: 2.008622084894488

Epoch: 5| Step: 1
Training loss: 2.1462690830230713
Validation loss: 2.0450278430856685

Epoch: 5| Step: 2
Training loss: 1.5703319311141968
Validation loss: 2.081997944462684

Epoch: 5| Step: 3
Training loss: 2.842064619064331
Validation loss: 2.0609771692624657

Epoch: 5| Step: 4
Training loss: 2.29254150390625
Validation loss: 2.0896536073377057

Epoch: 5| Step: 5
Training loss: 2.59781813621521
Validation loss: 2.0652403972482167

Epoch: 5| Step: 6
Training loss: 1.9819746017456055
Validation loss: 2.0370395504018313

Epoch: 5| Step: 7
Training loss: 2.104389190673828
Validation loss: 2.033133240156276

Epoch: 5| Step: 8
Training loss: 3.0622220039367676
Validation loss: 2.0148802931590746

Epoch: 5| Step: 9
Training loss: 2.72015118598938
Validation loss: 2.0392277215116765

Epoch: 5| Step: 10
Training loss: 1.837329626083374
Validation loss: 2.09014908729061

Epoch: 67| Step: 0
Training loss: 3.051159620285034
Validation loss: 2.0499735468177387

Epoch: 5| Step: 1
Training loss: 2.693138599395752
Validation loss: 2.0422803458347114

Epoch: 5| Step: 2
Training loss: 2.309413433074951
Validation loss: 1.9951860340692664

Epoch: 5| Step: 3
Training loss: 2.3475043773651123
Validation loss: 2.041534108500327

Epoch: 5| Step: 4
Training loss: 2.212538242340088
Validation loss: 2.098735164570552

Epoch: 5| Step: 5
Training loss: 2.8364319801330566
Validation loss: 2.0705170093044156

Epoch: 5| Step: 6
Training loss: 2.5070955753326416
Validation loss: 2.0559079185608895

Epoch: 5| Step: 7
Training loss: 2.2356510162353516
Validation loss: 2.0878523370271087

Epoch: 5| Step: 8
Training loss: 2.278289556503296
Validation loss: 2.0600822433348625

Epoch: 5| Step: 9
Training loss: 1.2566978931427002
Validation loss: 2.0799951732799573

Epoch: 5| Step: 10
Training loss: 2.741460084915161
Validation loss: 2.0384457841996224

Epoch: 68| Step: 0
Training loss: 2.0263400077819824
Validation loss: 2.065725406010946

Epoch: 5| Step: 1
Training loss: 2.9133541584014893
Validation loss: 2.061201749309417

Epoch: 5| Step: 2
Training loss: 2.5258655548095703
Validation loss: 2.047160585721334

Epoch: 5| Step: 3
Training loss: 1.8853422403335571
Validation loss: 2.0400371397695234

Epoch: 5| Step: 4
Training loss: 2.173008441925049
Validation loss: 2.0565116597760107

Epoch: 5| Step: 5
Training loss: 2.3768980503082275
Validation loss: 2.0548281208161385

Epoch: 5| Step: 6
Training loss: 2.231813669204712
Validation loss: 2.0140280800481

Epoch: 5| Step: 7
Training loss: 2.1629152297973633
Validation loss: 2.099371228166806

Epoch: 5| Step: 8
Training loss: 2.5996415615081787
Validation loss: 2.0697756275053947

Epoch: 5| Step: 9
Training loss: 2.7998430728912354
Validation loss: 2.057480158344392

Epoch: 5| Step: 10
Training loss: 2.5530529022216797
Validation loss: 2.0495658574565763

Epoch: 69| Step: 0
Training loss: 2.725710391998291
Validation loss: 2.0707878092283845

Epoch: 5| Step: 1
Training loss: 2.3330178260803223
Validation loss: 2.0643697259246663

Epoch: 5| Step: 2
Training loss: 2.5102016925811768
Validation loss: 2.0519538002629436

Epoch: 5| Step: 3
Training loss: 2.2711195945739746
Validation loss: 2.0388838539841356

Epoch: 5| Step: 4
Training loss: 1.985015869140625
Validation loss: 2.0576752360149095

Epoch: 5| Step: 5
Training loss: 2.2540478706359863
Validation loss: 2.0491871077527284

Epoch: 5| Step: 6
Training loss: 2.3962655067443848
Validation loss: 2.065928882168185

Epoch: 5| Step: 7
Training loss: 2.2997357845306396
Validation loss: 2.0872068969152306

Epoch: 5| Step: 8
Training loss: 2.3446338176727295
Validation loss: 2.035430028874387

Epoch: 5| Step: 9
Training loss: 2.4998221397399902
Validation loss: 2.0417794258363786

Epoch: 5| Step: 10
Training loss: 2.317429304122925
Validation loss: 2.048987837247951

Epoch: 70| Step: 0
Training loss: 1.749143362045288
Validation loss: 2.030863058182501

Epoch: 5| Step: 1
Training loss: 2.8174705505371094
Validation loss: 2.073481999417787

Epoch: 5| Step: 2
Training loss: 2.5147979259490967
Validation loss: 2.039604156248031

Epoch: 5| Step: 3
Training loss: 1.7608039379119873
Validation loss: 2.033485245961015

Epoch: 5| Step: 4
Training loss: 1.9152863025665283
Validation loss: 2.0723640559822

Epoch: 5| Step: 5
Training loss: 2.62670636177063
Validation loss: 2.0643216333081646

Epoch: 5| Step: 6
Training loss: 2.323185682296753
Validation loss: 2.0444451532056256

Epoch: 5| Step: 7
Training loss: 2.859778881072998
Validation loss: 1.9942372742519583

Epoch: 5| Step: 8
Training loss: 2.744750499725342
Validation loss: 2.0019133872883295

Epoch: 5| Step: 9
Training loss: 2.210801362991333
Validation loss: 2.048048564182815

Epoch: 5| Step: 10
Training loss: 2.3030896186828613
Validation loss: 2.0575867570856565

Epoch: 71| Step: 0
Training loss: 2.8966922760009766
Validation loss: 2.0601758290362615

Epoch: 5| Step: 1
Training loss: 2.333862543106079
Validation loss: 2.0220785435809883

Epoch: 5| Step: 2
Training loss: 2.4995920658111572
Validation loss: 2.066075086593628

Epoch: 5| Step: 3
Training loss: 2.1972076892852783
Validation loss: 2.074305498471824

Epoch: 5| Step: 4
Training loss: 2.5604467391967773
Validation loss: 2.0780407113413655

Epoch: 5| Step: 5
Training loss: 1.8547605276107788
Validation loss: 2.073976162941225

Epoch: 5| Step: 6
Training loss: 2.521275520324707
Validation loss: 2.0499772999876287

Epoch: 5| Step: 7
Training loss: 2.006192684173584
Validation loss: 2.0802021616248676

Epoch: 5| Step: 8
Training loss: 2.2971951961517334
Validation loss: 2.046372118816581

Epoch: 5| Step: 9
Training loss: 2.263798475265503
Validation loss: 2.0461849897138533

Epoch: 5| Step: 10
Training loss: 2.69821834564209
Validation loss: 2.071352868951777

Epoch: 72| Step: 0
Training loss: 2.0689120292663574
Validation loss: 2.005921485603497

Epoch: 5| Step: 1
Training loss: 1.9683971405029297
Validation loss: 2.061446561608263

Epoch: 5| Step: 2
Training loss: 2.327545166015625
Validation loss: 2.0684034157824773

Epoch: 5| Step: 3
Training loss: 2.0084667205810547
Validation loss: 2.033618668074249

Epoch: 5| Step: 4
Training loss: 2.8375980854034424
Validation loss: 2.0698468608240925

Epoch: 5| Step: 5
Training loss: 2.2115840911865234
Validation loss: 2.1037113102533485

Epoch: 5| Step: 6
Training loss: 3.231463670730591
Validation loss: 2.04000912943194

Epoch: 5| Step: 7
Training loss: 2.1666014194488525
Validation loss: 2.0445047860504477

Epoch: 5| Step: 8
Training loss: 2.4471702575683594
Validation loss: 2.0340922122360556

Epoch: 5| Step: 9
Training loss: 2.0356569290161133
Validation loss: 2.0523830126690608

Epoch: 5| Step: 10
Training loss: 2.5682270526885986
Validation loss: 2.0418553916356896

Epoch: 73| Step: 0
Training loss: 2.6005301475524902
Validation loss: 2.0290057274603073

Epoch: 5| Step: 1
Training loss: 1.9781467914581299
Validation loss: 2.06157329774672

Epoch: 5| Step: 2
Training loss: 2.0156257152557373
Validation loss: 2.0528191161412064

Epoch: 5| Step: 3
Training loss: 2.5798349380493164
Validation loss: 2.0603441422985447

Epoch: 5| Step: 4
Training loss: 2.1067113876342773
Validation loss: 2.051282085398192

Epoch: 5| Step: 5
Training loss: 2.48402738571167
Validation loss: 2.0311613339249805

Epoch: 5| Step: 6
Training loss: 2.499645948410034
Validation loss: 2.03452520344847

Epoch: 5| Step: 7
Training loss: 2.3806371688842773
Validation loss: 1.997929621768254

Epoch: 5| Step: 8
Training loss: 2.4365038871765137
Validation loss: 2.087467569176869

Epoch: 5| Step: 9
Training loss: 2.2758090496063232
Validation loss: 1.9970406255414408

Epoch: 5| Step: 10
Training loss: 2.2837367057800293
Validation loss: 2.0405071345708703

Epoch: 74| Step: 0
Training loss: 2.586500644683838
Validation loss: 2.074737218118483

Epoch: 5| Step: 1
Training loss: 2.6190483570098877
Validation loss: 2.055271165345305

Epoch: 5| Step: 2
Training loss: 2.604973554611206
Validation loss: 1.991597403762161

Epoch: 5| Step: 3
Training loss: 2.2627158164978027
Validation loss: 1.9973107281551565

Epoch: 5| Step: 4
Training loss: 2.808974266052246
Validation loss: 2.0618161462968394

Epoch: 5| Step: 5
Training loss: 2.625678300857544
Validation loss: 2.016782021009794

Epoch: 5| Step: 6
Training loss: 2.1880507469177246
Validation loss: 2.0935029342610347

Epoch: 5| Step: 7
Training loss: 2.5640451908111572
Validation loss: 1.9579558462224982

Epoch: 5| Step: 8
Training loss: 1.9312463998794556
Validation loss: 2.025182124107115

Epoch: 5| Step: 9
Training loss: 1.73965585231781
Validation loss: 2.037603635941782

Epoch: 5| Step: 10
Training loss: 1.7221163511276245
Validation loss: 2.0289342121411393

Epoch: 75| Step: 0
Training loss: 2.1892433166503906
Validation loss: 2.033368729775952

Epoch: 5| Step: 1
Training loss: 2.4236555099487305
Validation loss: 2.040190032733384

Epoch: 5| Step: 2
Training loss: 2.040405035018921
Validation loss: 2.007027592710269

Epoch: 5| Step: 3
Training loss: 2.26176118850708
Validation loss: 2.0930296297996276

Epoch: 5| Step: 4
Training loss: 2.2901835441589355
Validation loss: 2.0340094720163653

Epoch: 5| Step: 5
Training loss: 2.705354690551758
Validation loss: 2.0725322205533265

Epoch: 5| Step: 6
Training loss: 2.058795928955078
Validation loss: 2.04444416235852

Epoch: 5| Step: 7
Training loss: 2.708376407623291
Validation loss: 2.0545170999342397

Epoch: 5| Step: 8
Training loss: 2.5321342945098877
Validation loss: 2.0230293645653674

Epoch: 5| Step: 9
Training loss: 2.4396588802337646
Validation loss: 2.013669066531684

Epoch: 5| Step: 10
Training loss: 2.255556106567383
Validation loss: 2.0637386678367533

Epoch: 76| Step: 0
Training loss: 2.4336931705474854
Validation loss: 2.0488383462352138

Epoch: 5| Step: 1
Training loss: 2.4809248447418213
Validation loss: 2.051549788444273

Epoch: 5| Step: 2
Training loss: 1.8603603839874268
Validation loss: 2.0398341494221843

Epoch: 5| Step: 3
Training loss: 2.7653956413269043
Validation loss: 2.0173567059219524

Epoch: 5| Step: 4
Training loss: 2.6880297660827637
Validation loss: 2.0117295941998883

Epoch: 5| Step: 5
Training loss: 2.9062952995300293
Validation loss: 2.0532454777789373

Epoch: 5| Step: 6
Training loss: 2.328073740005493
Validation loss: 2.052869978771415

Epoch: 5| Step: 7
Training loss: 2.119858980178833
Validation loss: 2.0313164470016316

Epoch: 5| Step: 8
Training loss: 2.0137343406677246
Validation loss: 2.0446903641505907

Epoch: 5| Step: 9
Training loss: 2.0554916858673096
Validation loss: 2.0847891658864994

Epoch: 5| Step: 10
Training loss: 2.5255167484283447
Validation loss: 2.061231872086884

Epoch: 77| Step: 0
Training loss: 1.9806957244873047
Validation loss: 2.035992512138941

Epoch: 5| Step: 1
Training loss: 2.352921724319458
Validation loss: 2.029982054105369

Epoch: 5| Step: 2
Training loss: 2.6268954277038574
Validation loss: 2.062503542951358

Epoch: 5| Step: 3
Training loss: 3.2507107257843018
Validation loss: 2.0753835503773024

Epoch: 5| Step: 4
Training loss: 2.310136318206787
Validation loss: 2.093708235730407

Epoch: 5| Step: 5
Training loss: 1.9735676050186157
Validation loss: 2.0909369786580405

Epoch: 5| Step: 6
Training loss: 2.2048892974853516
Validation loss: 2.07414771023617

Epoch: 5| Step: 7
Training loss: 2.565716028213501
Validation loss: 2.015917155050462

Epoch: 5| Step: 8
Training loss: 1.6451057195663452
Validation loss: 2.026305029469152

Epoch: 5| Step: 9
Training loss: 2.6084206104278564
Validation loss: 2.0501986113927697

Epoch: 5| Step: 10
Training loss: 2.5723814964294434
Validation loss: 2.0916693415693057

Epoch: 78| Step: 0
Training loss: 2.598475456237793
Validation loss: 2.0472278723152737

Epoch: 5| Step: 1
Training loss: 2.2475948333740234
Validation loss: 2.012977905170892

Epoch: 5| Step: 2
Training loss: 3.0637826919555664
Validation loss: 2.074002418466794

Epoch: 5| Step: 3
Training loss: 2.651965618133545
Validation loss: 2.013618298756179

Epoch: 5| Step: 4
Training loss: 1.517972707748413
Validation loss: 2.0777201152616933

Epoch: 5| Step: 5
Training loss: 2.290752410888672
Validation loss: 2.0581750959478398

Epoch: 5| Step: 6
Training loss: 2.2273802757263184
Validation loss: 2.0472624699274697

Epoch: 5| Step: 7
Training loss: 2.668064832687378
Validation loss: 2.0875960037272465

Epoch: 5| Step: 8
Training loss: 1.9659885168075562
Validation loss: 2.0424996934911257

Epoch: 5| Step: 9
Training loss: 2.235914945602417
Validation loss: 2.0687670092428885

Epoch: 5| Step: 10
Training loss: 2.434812545776367
Validation loss: 2.0283009929041707

Epoch: 79| Step: 0
Training loss: 2.0781404972076416
Validation loss: 2.0180496272220405

Epoch: 5| Step: 1
Training loss: 2.604030132293701
Validation loss: 2.110715707143148

Epoch: 5| Step: 2
Training loss: 2.0054454803466797
Validation loss: 2.060237169265747

Epoch: 5| Step: 3
Training loss: 2.6016793251037598
Validation loss: 2.048305860129736

Epoch: 5| Step: 4
Training loss: 1.9788154363632202
Validation loss: 2.0329443664960962

Epoch: 5| Step: 5
Training loss: 2.5465543270111084
Validation loss: 2.0077726943518526

Epoch: 5| Step: 6
Training loss: 2.7895050048828125
Validation loss: 2.0471653323019705

Epoch: 5| Step: 7
Training loss: 2.030258893966675
Validation loss: 2.0605657151950303

Epoch: 5| Step: 8
Training loss: 2.6189706325531006
Validation loss: 2.0673460319478023

Epoch: 5| Step: 9
Training loss: 2.402832508087158
Validation loss: 2.0880064759203183

Epoch: 5| Step: 10
Training loss: 1.8918734788894653
Validation loss: 2.078821047659843

Epoch: 80| Step: 0
Training loss: 2.633910655975342
Validation loss: 2.042710781097412

Epoch: 5| Step: 1
Training loss: 2.4607486724853516
Validation loss: 2.068262228401758

Epoch: 5| Step: 2
Training loss: 2.5727267265319824
Validation loss: 2.094833720114923

Epoch: 5| Step: 3
Training loss: 2.159592866897583
Validation loss: 2.04276103614479

Epoch: 5| Step: 4
Training loss: 2.094853639602661
Validation loss: 2.0911039126816617

Epoch: 5| Step: 5
Training loss: 3.060584545135498
Validation loss: 2.0951801397467174

Epoch: 5| Step: 6
Training loss: 2.349412441253662
Validation loss: 2.0309029574035318

Epoch: 5| Step: 7
Training loss: 2.132875919342041
Validation loss: 2.0456251816083024

Epoch: 5| Step: 8
Training loss: 1.5301337242126465
Validation loss: 2.0739056243691394

Epoch: 5| Step: 9
Training loss: 2.2248597145080566
Validation loss: 2.0703421408130276

Epoch: 5| Step: 10
Training loss: 2.6530985832214355
Validation loss: 2.127016834033433

Epoch: 81| Step: 0
Training loss: 1.9645087718963623
Validation loss: 2.048570022788099

Epoch: 5| Step: 1
Training loss: 2.495861291885376
Validation loss: 2.109573487312563

Epoch: 5| Step: 2
Training loss: 2.2162842750549316
Validation loss: 2.0521132920377996

Epoch: 5| Step: 3
Training loss: 2.292003631591797
Validation loss: 2.04276184369159

Epoch: 5| Step: 4
Training loss: 2.93717622756958
Validation loss: 2.0731581282872025

Epoch: 5| Step: 5
Training loss: 2.608560085296631
Validation loss: 2.0053054414769655

Epoch: 5| Step: 6
Training loss: 2.3303141593933105
Validation loss: 2.042198011952062

Epoch: 5| Step: 7
Training loss: 2.4909873008728027
Validation loss: 2.0698337208840156

Epoch: 5| Step: 8
Training loss: 1.8803770542144775
Validation loss: 2.0145120210545038

Epoch: 5| Step: 9
Training loss: 2.1053218841552734
Validation loss: 2.0410698280539563

Epoch: 5| Step: 10
Training loss: 2.480545997619629
Validation loss: 2.063378564773067

Epoch: 82| Step: 0
Training loss: 2.256058931350708
Validation loss: 2.0457021549183834

Epoch: 5| Step: 1
Training loss: 1.8034731149673462
Validation loss: 1.9917255627211703

Epoch: 5| Step: 2
Training loss: 3.0264365673065186
Validation loss: 2.0594926828979165

Epoch: 5| Step: 3
Training loss: 2.536086320877075
Validation loss: 2.0463848729287424

Epoch: 5| Step: 4
Training loss: 2.642707347869873
Validation loss: 2.0778972397568407

Epoch: 5| Step: 5
Training loss: 1.6579616069793701
Validation loss: 2.0558067880651003

Epoch: 5| Step: 6
Training loss: 2.516660690307617
Validation loss: 2.053773267294771

Epoch: 5| Step: 7
Training loss: 2.0018656253814697
Validation loss: 2.0595037091162895

Epoch: 5| Step: 8
Training loss: 2.409111499786377
Validation loss: 2.0744509004777476

Epoch: 5| Step: 9
Training loss: 2.7992260456085205
Validation loss: 2.0596297274353685

Epoch: 5| Step: 10
Training loss: 1.8516223430633545
Validation loss: 2.0917336402400846

Epoch: 83| Step: 0
Training loss: 2.241361141204834
Validation loss: 2.0014621186000046

Epoch: 5| Step: 1
Training loss: 2.5695271492004395
Validation loss: 2.0566980031228836

Epoch: 5| Step: 2
Training loss: 2.79443359375
Validation loss: 2.0161230230844147

Epoch: 5| Step: 3
Training loss: 2.5316874980926514
Validation loss: 1.9879526310069586

Epoch: 5| Step: 4
Training loss: 1.92818284034729
Validation loss: 2.016154040572464

Epoch: 5| Step: 5
Training loss: 2.164125442504883
Validation loss: 2.0184570897010063

Epoch: 5| Step: 6
Training loss: 2.022756338119507
Validation loss: 2.0639627531010616

Epoch: 5| Step: 7
Training loss: 2.64799165725708
Validation loss: 2.0302140956283896

Epoch: 5| Step: 8
Training loss: 2.3687360286712646
Validation loss: 2.0243384671467606

Epoch: 5| Step: 9
Training loss: 2.8781609535217285
Validation loss: 2.081173345606814

Epoch: 5| Step: 10
Training loss: 1.611732840538025
Validation loss: 2.0378899369188535

Epoch: 84| Step: 0
Training loss: 1.7157360315322876
Validation loss: 2.052454617715651

Epoch: 5| Step: 1
Training loss: 1.5159356594085693
Validation loss: 2.037522954325522

Epoch: 5| Step: 2
Training loss: 2.229984998703003
Validation loss: 2.038447958166881

Epoch: 5| Step: 3
Training loss: 2.1458892822265625
Validation loss: 2.0564550533089587

Epoch: 5| Step: 4
Training loss: 2.6577975749969482
Validation loss: 2.014404776275799

Epoch: 5| Step: 5
Training loss: 2.1019580364227295
Validation loss: 2.023440440495809

Epoch: 5| Step: 6
Training loss: 2.6830685138702393
Validation loss: 2.027254307141868

Epoch: 5| Step: 7
Training loss: 2.84832501411438
Validation loss: 2.070485420124505

Epoch: 5| Step: 8
Training loss: 2.6426758766174316
Validation loss: 2.0257954430836502

Epoch: 5| Step: 9
Training loss: 2.574728488922119
Validation loss: 2.048078365223382

Epoch: 5| Step: 10
Training loss: 2.588895320892334
Validation loss: 2.0488905137585056

Epoch: 85| Step: 0
Training loss: 2.7349066734313965
Validation loss: 2.0434464844324256

Epoch: 5| Step: 1
Training loss: 2.7884888648986816
Validation loss: 1.9891718613204135

Epoch: 5| Step: 2
Training loss: 1.9690043926239014
Validation loss: 1.9791054853829004

Epoch: 5| Step: 3
Training loss: 1.5429470539093018
Validation loss: 2.0052340389579855

Epoch: 5| Step: 4
Training loss: 3.086928129196167
Validation loss: 2.041337929746156

Epoch: 5| Step: 5
Training loss: 2.005309581756592
Validation loss: 2.022206974285905

Epoch: 5| Step: 6
Training loss: 2.3621487617492676
Validation loss: 1.9992822113857474

Epoch: 5| Step: 7
Training loss: 2.2188305854797363
Validation loss: 2.001965302293019

Epoch: 5| Step: 8
Training loss: 2.5277936458587646
Validation loss: 2.0537432803902576

Epoch: 5| Step: 9
Training loss: 2.6919097900390625
Validation loss: 2.0203214076257523

Epoch: 5| Step: 10
Training loss: 1.8669548034667969
Validation loss: 2.0686429905635055

Epoch: 86| Step: 0
Training loss: 3.1828415393829346
Validation loss: 2.0098217277116674

Epoch: 5| Step: 1
Training loss: 2.2597036361694336
Validation loss: 2.023058734914308

Epoch: 5| Step: 2
Training loss: 2.1818203926086426
Validation loss: 2.054504845732002

Epoch: 5| Step: 3
Training loss: 1.7388547658920288
Validation loss: 1.9947382070684945

Epoch: 5| Step: 4
Training loss: 2.2339446544647217
Validation loss: 2.0377013939683155

Epoch: 5| Step: 5
Training loss: 1.8154211044311523
Validation loss: 2.0585564580014957

Epoch: 5| Step: 6
Training loss: 2.5977587699890137
Validation loss: 2.0422106622367777

Epoch: 5| Step: 7
Training loss: 2.3000094890594482
Validation loss: 2.0473088551593084

Epoch: 5| Step: 8
Training loss: 2.9024558067321777
Validation loss: 2.0965933735652635

Epoch: 5| Step: 9
Training loss: 1.5296880006790161
Validation loss: 2.004069156544183

Epoch: 5| Step: 10
Training loss: 2.960714101791382
Validation loss: 2.0017024817005282

Epoch: 87| Step: 0
Training loss: 2.609665870666504
Validation loss: 2.0325489736372426

Epoch: 5| Step: 1
Training loss: 2.017817497253418
Validation loss: 1.9990297132922756

Epoch: 5| Step: 2
Training loss: 3.0097014904022217
Validation loss: 2.0568086049890004

Epoch: 5| Step: 3
Training loss: 2.2776012420654297
Validation loss: 2.0327481031417847

Epoch: 5| Step: 4
Training loss: 1.9276565313339233
Validation loss: 2.0647425933550765

Epoch: 5| Step: 5
Training loss: 2.645559549331665
Validation loss: 2.055608178979607

Epoch: 5| Step: 6
Training loss: 1.867475152015686
Validation loss: 1.9991060674831431

Epoch: 5| Step: 7
Training loss: 2.398977756500244
Validation loss: 2.0321147031681512

Epoch: 5| Step: 8
Training loss: 1.9704113006591797
Validation loss: 2.0447422522370533

Epoch: 5| Step: 9
Training loss: 2.659872531890869
Validation loss: 2.0098233992053616

Epoch: 5| Step: 10
Training loss: 2.5016937255859375
Validation loss: 2.068411991160403

Epoch: 88| Step: 0
Training loss: 2.517239570617676
Validation loss: 2.0366324199143278

Epoch: 5| Step: 1
Training loss: 1.7532399892807007
Validation loss: 2.063200891658824

Epoch: 5| Step: 2
Training loss: 2.1172292232513428
Validation loss: 2.031972154494255

Epoch: 5| Step: 3
Training loss: 1.6028083562850952
Validation loss: 2.0335295328529934

Epoch: 5| Step: 4
Training loss: 2.781498670578003
Validation loss: 2.057811819097047

Epoch: 5| Step: 5
Training loss: 2.631695508956909
Validation loss: 2.060367094573154

Epoch: 5| Step: 6
Training loss: 3.1297106742858887
Validation loss: 2.0314998344708513

Epoch: 5| Step: 7
Training loss: 2.7785258293151855
Validation loss: 2.1023804218538347

Epoch: 5| Step: 8
Training loss: 1.8280389308929443
Validation loss: 2.0604068643303326

Epoch: 5| Step: 9
Training loss: 1.9795420169830322
Validation loss: 2.066186540870256

Epoch: 5| Step: 10
Training loss: 2.408635377883911
Validation loss: 2.0068354939901702

Epoch: 89| Step: 0
Training loss: 2.7726891040802
Validation loss: 2.013723852813885

Epoch: 5| Step: 1
Training loss: 3.2692580223083496
Validation loss: 2.0473474379508727

Epoch: 5| Step: 2
Training loss: 2.4154210090637207
Validation loss: 2.06105298637062

Epoch: 5| Step: 3
Training loss: 2.240346670150757
Validation loss: 2.0380048751831055

Epoch: 5| Step: 4
Training loss: 2.04154372215271
Validation loss: 2.0444272384848645

Epoch: 5| Step: 5
Training loss: 2.144200563430786
Validation loss: 2.0756998523589103

Epoch: 5| Step: 6
Training loss: 2.4844346046447754
Validation loss: 2.0699448354782595

Epoch: 5| Step: 7
Training loss: 1.6090177297592163
Validation loss: 2.0127798024044243

Epoch: 5| Step: 8
Training loss: 1.8312911987304688
Validation loss: 2.0286491737570813

Epoch: 5| Step: 9
Training loss: 2.7645068168640137
Validation loss: 2.062858630252141

Epoch: 5| Step: 10
Training loss: 2.178454637527466
Validation loss: 2.048404125757115

Epoch: 90| Step: 0
Training loss: 2.322679042816162
Validation loss: 2.045865806200171

Epoch: 5| Step: 1
Training loss: 2.6732115745544434
Validation loss: 2.0334163993917485

Epoch: 5| Step: 2
Training loss: 2.5733394622802734
Validation loss: 2.043359319368998

Epoch: 5| Step: 3
Training loss: 2.653376579284668
Validation loss: 2.069930035580871

Epoch: 5| Step: 4
Training loss: 1.647534966468811
Validation loss: 2.0354961246572514

Epoch: 5| Step: 5
Training loss: 2.1320624351501465
Validation loss: 2.0838792606066634

Epoch: 5| Step: 6
Training loss: 2.0363988876342773
Validation loss: 2.050755421320597

Epoch: 5| Step: 7
Training loss: 2.4885494709014893
Validation loss: 2.07679812113444

Epoch: 5| Step: 8
Training loss: 2.1620843410491943
Validation loss: 2.090007802491547

Epoch: 5| Step: 9
Training loss: 2.752596616744995
Validation loss: 2.0252942295484644

Epoch: 5| Step: 10
Training loss: 2.3770878314971924
Validation loss: 2.0206061768275436

Epoch: 91| Step: 0
Training loss: 2.14837646484375
Validation loss: 2.074747993100074

Epoch: 5| Step: 1
Training loss: 2.296571731567383
Validation loss: 2.0799630970083256

Epoch: 5| Step: 2
Training loss: 2.0166311264038086
Validation loss: 2.0676197518584547

Epoch: 5| Step: 3
Training loss: 2.9972949028015137
Validation loss: 2.0732598253475722

Epoch: 5| Step: 4
Training loss: 2.0725226402282715
Validation loss: 2.0412734003477198

Epoch: 5| Step: 5
Training loss: 1.8455877304077148
Validation loss: 2.061269619131601

Epoch: 5| Step: 6
Training loss: 2.113631248474121
Validation loss: 2.0590979501765263

Epoch: 5| Step: 7
Training loss: 2.5828633308410645
Validation loss: 2.04080516804931

Epoch: 5| Step: 8
Training loss: 2.9425740242004395
Validation loss: 2.068492966313516

Epoch: 5| Step: 9
Training loss: 2.240443706512451
Validation loss: 2.0407789086782806

Epoch: 5| Step: 10
Training loss: 2.3965935707092285
Validation loss: 2.021019927916988

Epoch: 92| Step: 0
Training loss: 2.6944377422332764
Validation loss: 2.025464154058887

Epoch: 5| Step: 1
Training loss: 2.636955738067627
Validation loss: 2.030448523900842

Epoch: 5| Step: 2
Training loss: 2.165907382965088
Validation loss: 2.013351152020116

Epoch: 5| Step: 3
Training loss: 2.0061306953430176
Validation loss: 1.9555721295777189

Epoch: 5| Step: 4
Training loss: 1.6873981952667236
Validation loss: 2.0694340723817066

Epoch: 5| Step: 5
Training loss: 2.447767734527588
Validation loss: 2.0457628875650387

Epoch: 5| Step: 6
Training loss: 2.107804775238037
Validation loss: 2.0550185275334183

Epoch: 5| Step: 7
Training loss: 3.3726487159729004
Validation loss: 2.0488927338712957

Epoch: 5| Step: 8
Training loss: 1.806909203529358
Validation loss: 2.036542346400599

Epoch: 5| Step: 9
Training loss: 2.5650415420532227
Validation loss: 2.030286976086196

Epoch: 5| Step: 10
Training loss: 2.024463415145874
Validation loss: 2.009701339147424

Epoch: 93| Step: 0
Training loss: 1.7485113143920898
Validation loss: 2.032161804937547

Epoch: 5| Step: 1
Training loss: 2.47463321685791
Validation loss: 2.064806374170447

Epoch: 5| Step: 2
Training loss: 2.742962598800659
Validation loss: 2.0323908585374073

Epoch: 5| Step: 3
Training loss: 2.0456645488739014
Validation loss: 2.018407643482249

Epoch: 5| Step: 4
Training loss: 2.3361620903015137
Validation loss: 2.0693511668071953

Epoch: 5| Step: 5
Training loss: 2.1856796741485596
Validation loss: 2.027792258929181

Epoch: 5| Step: 6
Training loss: 1.9726698398590088
Validation loss: 2.114711699947234

Epoch: 5| Step: 7
Training loss: 3.134329319000244
Validation loss: 2.0703737928021337

Epoch: 5| Step: 8
Training loss: 2.3877177238464355
Validation loss: 2.0556288867868404

Epoch: 5| Step: 9
Training loss: 2.4448115825653076
Validation loss: 2.046545041504727

Epoch: 5| Step: 10
Training loss: 2.344515562057495
Validation loss: 2.039124145302721

Epoch: 94| Step: 0
Training loss: 2.305616855621338
Validation loss: 2.039404592206401

Epoch: 5| Step: 1
Training loss: 2.6763455867767334
Validation loss: 2.0581643248117096

Epoch: 5| Step: 2
Training loss: 2.772829532623291
Validation loss: 2.0696100163203415

Epoch: 5| Step: 3
Training loss: 2.4092304706573486
Validation loss: 2.026721308308263

Epoch: 5| Step: 4
Training loss: 2.4769506454467773
Validation loss: 2.0612042001498643

Epoch: 5| Step: 5
Training loss: 2.3805618286132812
Validation loss: 2.07228317183833

Epoch: 5| Step: 6
Training loss: 2.2692618370056152
Validation loss: 2.024938219337053

Epoch: 5| Step: 7
Training loss: 1.934065818786621
Validation loss: 2.0999074700058147

Epoch: 5| Step: 8
Training loss: 1.8981174230575562
Validation loss: 2.0973212616417998

Epoch: 5| Step: 9
Training loss: 2.5212719440460205
Validation loss: 2.0564583398962535

Epoch: 5| Step: 10
Training loss: 1.8667136430740356
Validation loss: 2.0506183370467155

Epoch: 95| Step: 0
Training loss: 2.5899295806884766
Validation loss: 2.0671641416447137

Epoch: 5| Step: 1
Training loss: 2.0808558464050293
Validation loss: 2.0373305710413123

Epoch: 5| Step: 2
Training loss: 2.8315932750701904
Validation loss: 2.0706836344093404

Epoch: 5| Step: 3
Training loss: 1.672806739807129
Validation loss: 2.0677291013861216

Epoch: 5| Step: 4
Training loss: 2.611649990081787
Validation loss: 2.0936272657045754

Epoch: 5| Step: 5
Training loss: 2.194532632827759
Validation loss: 2.0574489537105767

Epoch: 5| Step: 6
Training loss: 2.4049768447875977
Validation loss: 2.027754960521575

Epoch: 5| Step: 7
Training loss: 2.702643871307373
Validation loss: 2.0829040183815906

Epoch: 5| Step: 8
Training loss: 2.0166027545928955
Validation loss: 2.0410130562320834

Epoch: 5| Step: 9
Training loss: 2.3439316749572754
Validation loss: 2.0182015652297647

Epoch: 5| Step: 10
Training loss: 2.446007013320923
Validation loss: 2.0320229427788847

Epoch: 96| Step: 0
Training loss: 2.1900177001953125
Validation loss: 2.0491520640670613

Epoch: 5| Step: 1
Training loss: 2.701301097869873
Validation loss: 2.0714539712475193

Epoch: 5| Step: 2
Training loss: 2.121096134185791
Validation loss: 2.0339603821436563

Epoch: 5| Step: 3
Training loss: 2.220395803451538
Validation loss: 2.032252129688058

Epoch: 5| Step: 4
Training loss: 2.5209059715270996
Validation loss: 2.029339723689582

Epoch: 5| Step: 5
Training loss: 2.1957077980041504
Validation loss: 2.091673162675673

Epoch: 5| Step: 6
Training loss: 2.5244991779327393
Validation loss: 2.0184602686153945

Epoch: 5| Step: 7
Training loss: 1.9072329998016357
Validation loss: 2.0526789003802883

Epoch: 5| Step: 8
Training loss: 2.308547258377075
Validation loss: 1.9829439219608103

Epoch: 5| Step: 9
Training loss: 2.3934519290924072
Validation loss: 2.040823023806336

Epoch: 5| Step: 10
Training loss: 2.3932487964630127
Validation loss: 2.073803017216344

Epoch: 97| Step: 0
Training loss: 2.270599842071533
Validation loss: 2.032040488335394

Epoch: 5| Step: 1
Training loss: 1.9723494052886963
Validation loss: 1.9744166404970231

Epoch: 5| Step: 2
Training loss: 1.7685527801513672
Validation loss: 1.9792270865491641

Epoch: 5| Step: 3
Training loss: 2.216356039047241
Validation loss: 2.0302316578485633

Epoch: 5| Step: 4
Training loss: 2.9913837909698486
Validation loss: 2.0271272556756132

Epoch: 5| Step: 5
Training loss: 2.3953890800476074
Validation loss: 2.028518074302263

Epoch: 5| Step: 6
Training loss: 2.6292548179626465
Validation loss: 2.0250693675010436

Epoch: 5| Step: 7
Training loss: 2.775078535079956
Validation loss: 1.9996720501171645

Epoch: 5| Step: 8
Training loss: 1.9835668802261353
Validation loss: 1.98791334449604

Epoch: 5| Step: 9
Training loss: 2.26379656791687
Validation loss: 2.0450753729830504

Epoch: 5| Step: 10
Training loss: 2.321396589279175
Validation loss: 2.06155583166307

Epoch: 98| Step: 0
Training loss: 1.5021076202392578
Validation loss: 1.986053761615548

Epoch: 5| Step: 1
Training loss: 2.048508405685425
Validation loss: 1.9843020592966387

Epoch: 5| Step: 2
Training loss: 3.308241605758667
Validation loss: 2.005959600530645

Epoch: 5| Step: 3
Training loss: 2.649787187576294
Validation loss: 2.031981037509057

Epoch: 5| Step: 4
Training loss: 2.414396286010742
Validation loss: 2.0440330915553595

Epoch: 5| Step: 5
Training loss: 1.8944346904754639
Validation loss: 2.002756159792664

Epoch: 5| Step: 6
Training loss: 3.0508878231048584
Validation loss: 1.9878457284742785

Epoch: 5| Step: 7
Training loss: 2.47035551071167
Validation loss: 2.0038954775820494

Epoch: 5| Step: 8
Training loss: 2.1993401050567627
Validation loss: 2.0495673225771998

Epoch: 5| Step: 9
Training loss: 1.3758175373077393
Validation loss: 2.0134520671700917

Epoch: 5| Step: 10
Training loss: 2.7253503799438477
Validation loss: 2.0183049043019614

Epoch: 99| Step: 0
Training loss: 2.256073236465454
Validation loss: 2.006817002450266

Epoch: 5| Step: 1
Training loss: 2.87427020072937
Validation loss: 2.052573732150498

Epoch: 5| Step: 2
Training loss: 2.6683340072631836
Validation loss: 2.0173314514980523

Epoch: 5| Step: 3
Training loss: 2.0494384765625
Validation loss: 1.984914223353068

Epoch: 5| Step: 4
Training loss: 2.1164727210998535
Validation loss: 2.0160923145150624

Epoch: 5| Step: 5
Training loss: 2.5002195835113525
Validation loss: 2.053609759576859

Epoch: 5| Step: 6
Training loss: 2.261282444000244
Validation loss: 2.0143471687070784

Epoch: 5| Step: 7
Training loss: 2.2396156787872314
Validation loss: 2.06079359721112

Epoch: 5| Step: 8
Training loss: 2.1423237323760986
Validation loss: 2.0018795510774017

Epoch: 5| Step: 9
Training loss: 2.611745595932007
Validation loss: 2.041383425394694

Epoch: 5| Step: 10
Training loss: 1.893489122390747
Validation loss: 2.0388354537307576

Epoch: 100| Step: 0
Training loss: 2.025190591812134
Validation loss: 2.0585960034401185

Epoch: 5| Step: 1
Training loss: 2.1009621620178223
Validation loss: 2.0112779807018977

Epoch: 5| Step: 2
Training loss: 1.3963593244552612
Validation loss: 1.999972161426339

Epoch: 5| Step: 3
Training loss: 2.3921332359313965
Validation loss: 2.0286611382679274

Epoch: 5| Step: 4
Training loss: 2.310142993927002
Validation loss: 2.002717359091646

Epoch: 5| Step: 5
Training loss: 2.6656033992767334
Validation loss: 2.001002319397465

Epoch: 5| Step: 6
Training loss: 2.1338324546813965
Validation loss: 2.0516000460552912

Epoch: 5| Step: 7
Training loss: 2.473156690597534
Validation loss: 2.0060215739793676

Epoch: 5| Step: 8
Training loss: 2.1410508155822754
Validation loss: 1.9775152706330823

Epoch: 5| Step: 9
Training loss: 2.9187748432159424
Validation loss: 2.074634285383327

Epoch: 5| Step: 10
Training loss: 2.524385452270508
Validation loss: 2.028297698625954

Epoch: 101| Step: 0
Training loss: 2.79799485206604
Validation loss: 2.0561875335631834

Epoch: 5| Step: 1
Training loss: 2.5530941486358643
Validation loss: 2.024530021093225

Epoch: 5| Step: 2
Training loss: 1.9588897228240967
Validation loss: 2.0353485871386785

Epoch: 5| Step: 3
Training loss: 2.4834258556365967
Validation loss: 2.057707885260223

Epoch: 5| Step: 4
Training loss: 2.315150737762451
Validation loss: 2.0021870290079424

Epoch: 5| Step: 5
Training loss: 2.0347774028778076
Validation loss: 2.0048639825595322

Epoch: 5| Step: 6
Training loss: 2.240023136138916
Validation loss: 2.0186209678649902

Epoch: 5| Step: 7
Training loss: 2.6824352741241455
Validation loss: 2.0214012848433627

Epoch: 5| Step: 8
Training loss: 2.4144811630249023
Validation loss: 1.9756740741832282

Epoch: 5| Step: 9
Training loss: 2.0746779441833496
Validation loss: 2.019004588486046

Epoch: 5| Step: 10
Training loss: 2.0464115142822266
Validation loss: 2.032896505889072

Epoch: 102| Step: 0
Training loss: 2.0622363090515137
Validation loss: 2.0307221463931504

Epoch: 5| Step: 1
Training loss: 2.238137722015381
Validation loss: 2.064375695361886

Epoch: 5| Step: 2
Training loss: 3.0675015449523926
Validation loss: 2.0236287091367986

Epoch: 5| Step: 3
Training loss: 2.1981847286224365
Validation loss: 2.0145536263783774

Epoch: 5| Step: 4
Training loss: 2.4596829414367676
Validation loss: 2.0432910688461794

Epoch: 5| Step: 5
Training loss: 2.2790451049804688
Validation loss: 2.030576612359734

Epoch: 5| Step: 6
Training loss: 2.1250829696655273
Validation loss: 1.9678258024236208

Epoch: 5| Step: 7
Training loss: 2.4962539672851562
Validation loss: 2.0532291384153467

Epoch: 5| Step: 8
Training loss: 2.1923680305480957
Validation loss: 2.030585365910684

Epoch: 5| Step: 9
Training loss: 2.2289726734161377
Validation loss: 2.046724780913322

Epoch: 5| Step: 10
Training loss: 2.011582374572754
Validation loss: 2.0211921712403655

Epoch: 103| Step: 0
Training loss: 2.360785484313965
Validation loss: 2.0272022703642487

Epoch: 5| Step: 1
Training loss: 2.4921298027038574
Validation loss: 2.0334427536174817

Epoch: 5| Step: 2
Training loss: 1.8811603784561157
Validation loss: 1.996673660893594

Epoch: 5| Step: 3
Training loss: 2.7476806640625
Validation loss: 2.0210297748606694

Epoch: 5| Step: 4
Training loss: 1.814178705215454
Validation loss: 2.0219055247563187

Epoch: 5| Step: 5
Training loss: 2.544691801071167
Validation loss: 2.0370612118833806

Epoch: 5| Step: 6
Training loss: 2.065640449523926
Validation loss: 2.013749896839101

Epoch: 5| Step: 7
Training loss: 2.3767757415771484
Validation loss: 2.0686686308153215

Epoch: 5| Step: 8
Training loss: 2.2898335456848145
Validation loss: 2.0585953343299126

Epoch: 5| Step: 9
Training loss: 2.103708267211914
Validation loss: 2.0347033892908404

Epoch: 5| Step: 10
Training loss: 2.9093177318573
Validation loss: 2.029023428117075

Epoch: 104| Step: 0
Training loss: 2.4963080883026123
Validation loss: 2.032166942473381

Epoch: 5| Step: 1
Training loss: 3.0137181282043457
Validation loss: 2.0434943527303715

Epoch: 5| Step: 2
Training loss: 2.0544185638427734
Validation loss: 2.02413071099148

Epoch: 5| Step: 3
Training loss: 2.247598648071289
Validation loss: 2.036314813039636

Epoch: 5| Step: 4
Training loss: 2.1732068061828613
Validation loss: 2.056616275541244

Epoch: 5| Step: 5
Training loss: 1.8661344051361084
Validation loss: 2.078933694029367

Epoch: 5| Step: 6
Training loss: 2.381110191345215
Validation loss: 2.033014133412351

Epoch: 5| Step: 7
Training loss: 1.7407983541488647
Validation loss: 2.0547958727805846

Epoch: 5| Step: 8
Training loss: 2.6796488761901855
Validation loss: 2.018592857545422

Epoch: 5| Step: 9
Training loss: 1.445186972618103
Validation loss: 2.0744206315727642

Epoch: 5| Step: 10
Training loss: 3.1677801609039307
Validation loss: 2.0439274541793333

Epoch: 105| Step: 0
Training loss: 2.0073609352111816
Validation loss: 2.0990917477556454

Epoch: 5| Step: 1
Training loss: 3.0614559650421143
Validation loss: 2.072737068258306

Epoch: 5| Step: 2
Training loss: 2.6880850791931152
Validation loss: 2.0580419058440835

Epoch: 5| Step: 3
Training loss: 2.330003261566162
Validation loss: 2.0244860649108887

Epoch: 5| Step: 4
Training loss: 2.334444522857666
Validation loss: 2.0568571821335824

Epoch: 5| Step: 5
Training loss: 2.303483247756958
Validation loss: 2.0317330668049474

Epoch: 5| Step: 6
Training loss: 1.5524766445159912
Validation loss: 2.028256954685334

Epoch: 5| Step: 7
Training loss: 2.8452911376953125
Validation loss: 2.0305589014484036

Epoch: 5| Step: 8
Training loss: 2.4244492053985596
Validation loss: 2.0437964265064528

Epoch: 5| Step: 9
Training loss: 1.8890587091445923
Validation loss: 2.0688932300895773

Epoch: 5| Step: 10
Training loss: 2.0453946590423584
Validation loss: 2.0705772010228967

Epoch: 106| Step: 0
Training loss: 1.6744083166122437
Validation loss: 2.0246631381332234

Epoch: 5| Step: 1
Training loss: 2.7587337493896484
Validation loss: 2.0453307026176044

Epoch: 5| Step: 2
Training loss: 2.3885607719421387
Validation loss: 2.0940968785234677

Epoch: 5| Step: 3
Training loss: 1.6882585287094116
Validation loss: 2.0538370916920323

Epoch: 5| Step: 4
Training loss: 3.128387689590454
Validation loss: 2.1165883874380462

Epoch: 5| Step: 5
Training loss: 2.8560831546783447
Validation loss: 2.0228347547592653

Epoch: 5| Step: 6
Training loss: 2.6078696250915527
Validation loss: 2.0359794683353876

Epoch: 5| Step: 7
Training loss: 1.604503870010376
Validation loss: 2.0706236759821572

Epoch: 5| Step: 8
Training loss: 2.4422004222869873
Validation loss: 2.0159007528776764

Epoch: 5| Step: 9
Training loss: 2.4793155193328857
Validation loss: 2.0718877174521007

Epoch: 5| Step: 10
Training loss: 1.809123158454895
Validation loss: 2.0611515339984687

Epoch: 107| Step: 0
Training loss: 2.6432735919952393
Validation loss: 2.0927010684885006

Epoch: 5| Step: 1
Training loss: 2.260887622833252
Validation loss: 2.000528899572229

Epoch: 5| Step: 2
Training loss: 2.2089664936065674
Validation loss: 1.9818350345857683

Epoch: 5| Step: 3
Training loss: 3.0216357707977295
Validation loss: 2.0230918443331154

Epoch: 5| Step: 4
Training loss: 1.8546199798583984
Validation loss: 2.059815199144425

Epoch: 5| Step: 5
Training loss: 1.9356067180633545
Validation loss: 2.094032185052031

Epoch: 5| Step: 6
Training loss: 2.6464366912841797
Validation loss: 2.0736855845297537

Epoch: 5| Step: 7
Training loss: 2.249509334564209
Validation loss: 2.065407315889994

Epoch: 5| Step: 8
Training loss: 2.1117148399353027
Validation loss: 2.0565586910452893

Epoch: 5| Step: 9
Training loss: 1.9781780242919922
Validation loss: 2.0408315081750192

Epoch: 5| Step: 10
Training loss: 2.484301805496216
Validation loss: 2.051164270729147

Epoch: 108| Step: 0
Training loss: 2.0686497688293457
Validation loss: 2.052417144980482

Epoch: 5| Step: 1
Training loss: 2.140223979949951
Validation loss: 2.022286720173333

Epoch: 5| Step: 2
Training loss: 2.4521584510803223
Validation loss: 2.0627788395010014

Epoch: 5| Step: 3
Training loss: 1.7767406702041626
Validation loss: 2.0384870677865963

Epoch: 5| Step: 4
Training loss: 2.1167473793029785
Validation loss: 2.0228377439642466

Epoch: 5| Step: 5
Training loss: 2.820596218109131
Validation loss: 2.079449289588518

Epoch: 5| Step: 6
Training loss: 2.040323257446289
Validation loss: 2.0022549193392516

Epoch: 5| Step: 7
Training loss: 2.720187187194824
Validation loss: 2.0625043299890335

Epoch: 5| Step: 8
Training loss: 2.3769519329071045
Validation loss: 2.040801150824434

Epoch: 5| Step: 9
Training loss: 2.399935483932495
Validation loss: 2.0271940872233403

Epoch: 5| Step: 10
Training loss: 2.527017116546631
Validation loss: 2.0532039314187984

Epoch: 109| Step: 0
Training loss: 2.1721370220184326
Validation loss: 2.042981875840054

Epoch: 5| Step: 1
Training loss: 2.186617851257324
Validation loss: 2.0578964858926754

Epoch: 5| Step: 2
Training loss: 2.119748592376709
Validation loss: 2.0446000906728927

Epoch: 5| Step: 3
Training loss: 2.2968192100524902
Validation loss: 2.019638607578893

Epoch: 5| Step: 4
Training loss: 2.308933734893799
Validation loss: 2.0629506495691117

Epoch: 5| Step: 5
Training loss: 2.6651949882507324
Validation loss: 2.0490856157836093

Epoch: 5| Step: 6
Training loss: 2.2756195068359375
Validation loss: 2.0705859661102295

Epoch: 5| Step: 7
Training loss: 1.7666599750518799
Validation loss: 2.033978896756326

Epoch: 5| Step: 8
Training loss: 2.371187448501587
Validation loss: 2.1091603438059487

Epoch: 5| Step: 9
Training loss: 2.7491724491119385
Validation loss: 2.108590074764785

Epoch: 5| Step: 10
Training loss: 2.511005163192749
Validation loss: 2.0614015184422976

Epoch: 110| Step: 0
Training loss: 2.228463649749756
Validation loss: 2.0864676737016246

Epoch: 5| Step: 1
Training loss: 2.636744976043701
Validation loss: 2.083156592102461

Epoch: 5| Step: 2
Training loss: 2.648698091506958
Validation loss: 2.0747750189996537

Epoch: 5| Step: 3
Training loss: 2.6747429370880127
Validation loss: 2.0487067186704246

Epoch: 5| Step: 4
Training loss: 2.707327365875244
Validation loss: 2.077070008042038

Epoch: 5| Step: 5
Training loss: 2.214460849761963
Validation loss: 2.1104469863317346

Epoch: 5| Step: 6
Training loss: 1.9011242389678955
Validation loss: 2.0444660904586955

Epoch: 5| Step: 7
Training loss: 1.3996533155441284
Validation loss: 2.069498356952462

Epoch: 5| Step: 8
Training loss: 2.110149621963501
Validation loss: 2.055037780474591

Epoch: 5| Step: 9
Training loss: 1.9809690713882446
Validation loss: 2.0355361302693686

Epoch: 5| Step: 10
Training loss: 3.0756397247314453
Validation loss: 2.06884785749579

Epoch: 111| Step: 0
Training loss: 2.1775245666503906
Validation loss: 2.0824952151185725

Epoch: 5| Step: 1
Training loss: 2.4323534965515137
Validation loss: 2.0527475328855616

Epoch: 5| Step: 2
Training loss: 2.17165207862854
Validation loss: 2.0792283306839647

Epoch: 5| Step: 3
Training loss: 2.1026813983917236
Validation loss: 2.050435737896991

Epoch: 5| Step: 4
Training loss: 2.1070683002471924
Validation loss: 2.042367640361991

Epoch: 5| Step: 5
Training loss: 2.695861339569092
Validation loss: 2.0131778781132033

Epoch: 5| Step: 6
Training loss: 2.7724063396453857
Validation loss: 2.052650886197244

Epoch: 5| Step: 7
Training loss: 1.8545185327529907
Validation loss: 2.019086512186194

Epoch: 5| Step: 8
Training loss: 1.8871660232543945
Validation loss: 2.059046729918449

Epoch: 5| Step: 9
Training loss: 2.584285259246826
Validation loss: 2.043632279160202

Epoch: 5| Step: 10
Training loss: 2.38262939453125
Validation loss: 2.027867632527505

Epoch: 112| Step: 0
Training loss: 2.7306230068206787
Validation loss: 2.0486824256117626

Epoch: 5| Step: 1
Training loss: 1.9241724014282227
Validation loss: 2.064970677898776

Epoch: 5| Step: 2
Training loss: 2.2638237476348877
Validation loss: 2.0390254733383015

Epoch: 5| Step: 3
Training loss: 2.8955845832824707
Validation loss: 2.0187686592020015

Epoch: 5| Step: 4
Training loss: 1.8377506732940674
Validation loss: 2.033567609325532

Epoch: 5| Step: 5
Training loss: 2.477128028869629
Validation loss: 2.0373315349701913

Epoch: 5| Step: 6
Training loss: 1.9523369073867798
Validation loss: 2.0102507504083778

Epoch: 5| Step: 7
Training loss: 2.3015873432159424
Validation loss: 2.0464499330007904

Epoch: 5| Step: 8
Training loss: 2.0719332695007324
Validation loss: 2.0809169841069046

Epoch: 5| Step: 9
Training loss: 2.217566728591919
Validation loss: 2.0820709172115532

Epoch: 5| Step: 10
Training loss: 2.7288522720336914
Validation loss: 1.9852716230577039

Epoch: 113| Step: 0
Training loss: 1.9591947793960571
Validation loss: 1.9998619582063408

Epoch: 5| Step: 1
Training loss: 2.5331130027770996
Validation loss: 2.0100813527261057

Epoch: 5| Step: 2
Training loss: 2.189091205596924
Validation loss: 1.996244977879268

Epoch: 5| Step: 3
Training loss: 2.3540427684783936
Validation loss: 2.0236604470078663

Epoch: 5| Step: 4
Training loss: 2.335939884185791
Validation loss: 2.0233004016260945

Epoch: 5| Step: 5
Training loss: 2.8035836219787598
Validation loss: 2.0110630130255096

Epoch: 5| Step: 6
Training loss: 2.236255168914795
Validation loss: 2.017974297205607

Epoch: 5| Step: 7
Training loss: 2.3533899784088135
Validation loss: 1.982405279272346

Epoch: 5| Step: 8
Training loss: 2.3115196228027344
Validation loss: 2.044864636595531

Epoch: 5| Step: 9
Training loss: 1.8875770568847656
Validation loss: 2.022604666730409

Epoch: 5| Step: 10
Training loss: 1.9158843755722046
Validation loss: 2.000730506835445

Epoch: 114| Step: 0
Training loss: 2.628513813018799
Validation loss: 2.009373818674395

Epoch: 5| Step: 1
Training loss: 2.2236342430114746
Validation loss: 1.9341409719118507

Epoch: 5| Step: 2
Training loss: 2.0861945152282715
Validation loss: 2.0102161874053297

Epoch: 5| Step: 3
Training loss: 2.0007221698760986
Validation loss: 1.9730170414011965

Epoch: 5| Step: 4
Training loss: 2.545297145843506
Validation loss: 2.0051177496551187

Epoch: 5| Step: 5
Training loss: 2.2862555980682373
Validation loss: 2.060444913884645

Epoch: 5| Step: 6
Training loss: 2.7447705268859863
Validation loss: 1.9934736041612522

Epoch: 5| Step: 7
Training loss: 1.9403263330459595
Validation loss: 2.020935963558894

Epoch: 5| Step: 8
Training loss: 2.002924680709839
Validation loss: 2.0115926381080382

Epoch: 5| Step: 9
Training loss: 2.3212406635284424
Validation loss: 2.013845859035369

Epoch: 5| Step: 10
Training loss: 2.66508150100708
Validation loss: 2.0273307395237747

Epoch: 115| Step: 0
Training loss: 1.9374297857284546
Validation loss: 2.015231852890343

Epoch: 5| Step: 1
Training loss: 1.8251848220825195
Validation loss: 2.014316422964937

Epoch: 5| Step: 2
Training loss: 2.3771510124206543
Validation loss: 1.9816934754771571

Epoch: 5| Step: 3
Training loss: 2.0521557331085205
Validation loss: 2.0016312342818066

Epoch: 5| Step: 4
Training loss: 2.958254098892212
Validation loss: 1.9854414591225245

Epoch: 5| Step: 5
Training loss: 2.1345431804656982
Validation loss: 2.0452168782552085

Epoch: 5| Step: 6
Training loss: 1.7568498849868774
Validation loss: 2.0686534348354546

Epoch: 5| Step: 7
Training loss: 2.4693493843078613
Validation loss: 2.0254778182634743

Epoch: 5| Step: 8
Training loss: 2.7607357501983643
Validation loss: 2.050220056246686

Epoch: 5| Step: 9
Training loss: 2.8358263969421387
Validation loss: 1.9891103608633882

Epoch: 5| Step: 10
Training loss: 1.8825383186340332
Validation loss: 2.031064215526786

Epoch: 116| Step: 0
Training loss: 2.5732829570770264
Validation loss: 2.0219035302439043

Epoch: 5| Step: 1
Training loss: 2.4492592811584473
Validation loss: 2.0130152266512633

Epoch: 5| Step: 2
Training loss: 1.8770757913589478
Validation loss: 2.0374420124997377

Epoch: 5| Step: 3
Training loss: 3.0615756511688232
Validation loss: 2.0770710411892144

Epoch: 5| Step: 4
Training loss: 1.581364631652832
Validation loss: 2.042332474903394

Epoch: 5| Step: 5
Training loss: 2.224719762802124
Validation loss: 2.0665253336711595

Epoch: 5| Step: 6
Training loss: 2.1869988441467285
Validation loss: 2.011063260416831

Epoch: 5| Step: 7
Training loss: 2.2611401081085205
Validation loss: 2.088440807916785

Epoch: 5| Step: 8
Training loss: 2.541653871536255
Validation loss: 2.063664569649645

Epoch: 5| Step: 9
Training loss: 2.2539944648742676
Validation loss: 2.053843402093457

Epoch: 5| Step: 10
Training loss: 2.467238187789917
Validation loss: 2.064676495008571

Epoch: 117| Step: 0
Training loss: 2.422301769256592
Validation loss: 2.0831430342889603

Epoch: 5| Step: 1
Training loss: 2.4681341648101807
Validation loss: 2.0141547162045716

Epoch: 5| Step: 2
Training loss: 2.717075824737549
Validation loss: 2.0532042031647055

Epoch: 5| Step: 3
Training loss: 2.302785873413086
Validation loss: 2.070023436700144

Epoch: 5| Step: 4
Training loss: 2.2815921306610107
Validation loss: 2.100589826542844

Epoch: 5| Step: 5
Training loss: 2.457568883895874
Validation loss: 2.087661640618437

Epoch: 5| Step: 6
Training loss: 1.9704967737197876
Validation loss: 2.0478715691515195

Epoch: 5| Step: 7
Training loss: 1.8494892120361328
Validation loss: 2.026929155472786

Epoch: 5| Step: 8
Training loss: 2.130342483520508
Validation loss: 2.1056426737898137

Epoch: 5| Step: 9
Training loss: 2.506577968597412
Validation loss: 2.0900370920858076

Epoch: 5| Step: 10
Training loss: 2.121410846710205
Validation loss: 2.039684352054391

Epoch: 118| Step: 0
Training loss: 2.637591600418091
Validation loss: 2.050839788170271

Epoch: 5| Step: 1
Training loss: 1.687563180923462
Validation loss: 2.0481894887903684

Epoch: 5| Step: 2
Training loss: 2.3647940158843994
Validation loss: 2.0547835724328154

Epoch: 5| Step: 3
Training loss: 2.233646869659424
Validation loss: 2.0679326390707367

Epoch: 5| Step: 4
Training loss: 1.845349907875061
Validation loss: 2.0471525012805896

Epoch: 5| Step: 5
Training loss: 2.4601826667785645
Validation loss: 2.044521544569282

Epoch: 5| Step: 6
Training loss: 2.889435291290283
Validation loss: 2.0850566471776655

Epoch: 5| Step: 7
Training loss: 2.2245094776153564
Validation loss: 2.0445337218623005

Epoch: 5| Step: 8
Training loss: 2.6937592029571533
Validation loss: 2.063466125918973

Epoch: 5| Step: 9
Training loss: 2.5386993885040283
Validation loss: 2.0767766942260084

Epoch: 5| Step: 10
Training loss: 1.8118401765823364
Validation loss: 2.0153559023334133

Epoch: 119| Step: 0
Training loss: 2.1712000370025635
Validation loss: 2.1083721653107674

Epoch: 5| Step: 1
Training loss: 1.7466583251953125
Validation loss: 2.048652979635423

Epoch: 5| Step: 2
Training loss: 2.187885046005249
Validation loss: 2.09957306872132

Epoch: 5| Step: 3
Training loss: 1.9701461791992188
Validation loss: 2.0764923582794848

Epoch: 5| Step: 4
Training loss: 2.5762596130371094
Validation loss: 2.0731157179801696

Epoch: 5| Step: 5
Training loss: 2.6365742683410645
Validation loss: 2.0399504194977465

Epoch: 5| Step: 6
Training loss: 1.9525247812271118
Validation loss: 2.03917137909961

Epoch: 5| Step: 7
Training loss: 2.75114107131958
Validation loss: 2.0263312696128764

Epoch: 5| Step: 8
Training loss: 2.7863821983337402
Validation loss: 2.020582929734261

Epoch: 5| Step: 9
Training loss: 1.8066123723983765
Validation loss: 2.0373436853449833

Epoch: 5| Step: 10
Training loss: 2.37483286857605
Validation loss: 2.041089644996069

Epoch: 120| Step: 0
Training loss: 2.49995756149292
Validation loss: 2.0402734946179133

Epoch: 5| Step: 1
Training loss: 3.0975656509399414
Validation loss: 2.003413395215106

Epoch: 5| Step: 2
Training loss: 2.5509305000305176
Validation loss: 2.001465441078268

Epoch: 5| Step: 3
Training loss: 2.5964763164520264
Validation loss: 2.039666876997999

Epoch: 5| Step: 4
Training loss: 2.0771071910858154
Validation loss: 2.050364883997107

Epoch: 5| Step: 5
Training loss: 1.633938193321228
Validation loss: 2.032089287234891

Epoch: 5| Step: 6
Training loss: 2.3506453037261963
Validation loss: 1.9913019467425603

Epoch: 5| Step: 7
Training loss: 1.6271240711212158
Validation loss: 2.062192763051679

Epoch: 5| Step: 8
Training loss: 2.417684316635132
Validation loss: 2.057170905092711

Epoch: 5| Step: 9
Training loss: 1.879037857055664
Validation loss: 2.03769564372237

Epoch: 5| Step: 10
Training loss: 2.459392547607422
Validation loss: 2.044375173507198

Epoch: 121| Step: 0
Training loss: 2.5872886180877686
Validation loss: 2.024006114211134

Epoch: 5| Step: 1
Training loss: 2.3343536853790283
Validation loss: 2.0375719262707617

Epoch: 5| Step: 2
Training loss: 1.888692855834961
Validation loss: 2.0418126301098893

Epoch: 5| Step: 3
Training loss: 2.1275815963745117
Validation loss: 2.016826425829241

Epoch: 5| Step: 4
Training loss: 2.319301128387451
Validation loss: 1.9957890023467362

Epoch: 5| Step: 5
Training loss: 2.3717451095581055
Validation loss: 2.0123169050421765

Epoch: 5| Step: 6
Training loss: 2.441089153289795
Validation loss: 1.9706578241881503

Epoch: 5| Step: 7
Training loss: 2.507702589035034
Validation loss: 2.0247843893625403

Epoch: 5| Step: 8
Training loss: 2.443479061126709
Validation loss: 2.0289809626917683

Epoch: 5| Step: 9
Training loss: 2.6430723667144775
Validation loss: 2.0477387443665536

Epoch: 5| Step: 10
Training loss: 1.626065731048584
Validation loss: 2.06054425239563

Epoch: 122| Step: 0
Training loss: 2.581860065460205
Validation loss: 2.0156868068120812

Epoch: 5| Step: 1
Training loss: 2.0226263999938965
Validation loss: 2.0596801388648247

Epoch: 5| Step: 2
Training loss: 2.1248226165771484
Validation loss: 2.0872368735651814

Epoch: 5| Step: 3
Training loss: 2.702474594116211
Validation loss: 2.03554129856889

Epoch: 5| Step: 4
Training loss: 2.2332606315612793
Validation loss: 2.0216364693898026

Epoch: 5| Step: 5
Training loss: 2.99629282951355
Validation loss: 2.0369949238274687

Epoch: 5| Step: 6
Training loss: 2.6366467475891113
Validation loss: 2.0158670320305774

Epoch: 5| Step: 7
Training loss: 1.711897850036621
Validation loss: 2.106696126281574

Epoch: 5| Step: 8
Training loss: 1.7782106399536133
Validation loss: 2.0018584433422295

Epoch: 5| Step: 9
Training loss: 2.243147373199463
Validation loss: 2.030192648210833

Epoch: 5| Step: 10
Training loss: 2.5829503536224365
Validation loss: 2.029707334374869

Epoch: 123| Step: 0
Training loss: 2.284498691558838
Validation loss: 2.028078599642682

Epoch: 5| Step: 1
Training loss: 2.192446708679199
Validation loss: 2.027171722022436

Epoch: 5| Step: 2
Training loss: 2.4057533740997314
Validation loss: 2.0735202655997327

Epoch: 5| Step: 3
Training loss: 2.5902838706970215
Validation loss: 2.0413690997708227

Epoch: 5| Step: 4
Training loss: 2.9457123279571533
Validation loss: 1.9966314069686397

Epoch: 5| Step: 5
Training loss: 2.536914825439453
Validation loss: 2.0166892825916247

Epoch: 5| Step: 6
Training loss: 2.4190988540649414
Validation loss: 2.02657978252698

Epoch: 5| Step: 7
Training loss: 2.306368589401245
Validation loss: 2.0200126504385345

Epoch: 5| Step: 8
Training loss: 2.0185976028442383
Validation loss: 2.0619144029514764

Epoch: 5| Step: 9
Training loss: 1.873703956604004
Validation loss: 2.0549155307072464

Epoch: 5| Step: 10
Training loss: 1.4730596542358398
Validation loss: 2.087082257834814

Epoch: 124| Step: 0
Training loss: 1.7760274410247803
Validation loss: 2.0901701732348372

Epoch: 5| Step: 1
Training loss: 2.659060001373291
Validation loss: 2.046495473513039

Epoch: 5| Step: 2
Training loss: 2.5726804733276367
Validation loss: 2.0770256057862313

Epoch: 5| Step: 3
Training loss: 2.4671406745910645
Validation loss: 2.0620204094917542

Epoch: 5| Step: 4
Training loss: 2.2203171253204346
Validation loss: 1.9974581362098776

Epoch: 5| Step: 5
Training loss: 1.902634859085083
Validation loss: 2.055904230763835

Epoch: 5| Step: 6
Training loss: 2.3846943378448486
Validation loss: 2.0498813121549544

Epoch: 5| Step: 7
Training loss: 2.485973834991455
Validation loss: 2.096457897975881

Epoch: 5| Step: 8
Training loss: 1.7947092056274414
Validation loss: 2.0732173406949608

Epoch: 5| Step: 9
Training loss: 2.641989231109619
Validation loss: 2.0667169145358506

Epoch: 5| Step: 10
Training loss: 2.450205087661743
Validation loss: 2.050423647767754

Epoch: 125| Step: 0
Training loss: 1.9416401386260986
Validation loss: 2.072303456644858

Epoch: 5| Step: 1
Training loss: 2.251697540283203
Validation loss: 2.0939421999839043

Epoch: 5| Step: 2
Training loss: 1.8968541622161865
Validation loss: 2.030367096265157

Epoch: 5| Step: 3
Training loss: 2.6566405296325684
Validation loss: 2.044410632502648

Epoch: 5| Step: 4
Training loss: 2.266436815261841
Validation loss: 2.0677137887606056

Epoch: 5| Step: 5
Training loss: 2.3146274089813232
Validation loss: 2.0026288045349943

Epoch: 5| Step: 6
Training loss: 2.4620139598846436
Validation loss: 2.101298878269811

Epoch: 5| Step: 7
Training loss: 1.9616514444351196
Validation loss: 2.043604120131462

Epoch: 5| Step: 8
Training loss: 2.751744508743286
Validation loss: 2.034170393020876

Epoch: 5| Step: 9
Training loss: 2.189335823059082
Validation loss: 2.055745497826607

Epoch: 5| Step: 10
Training loss: 2.0967419147491455
Validation loss: 1.9793546635617492

Epoch: 126| Step: 0
Training loss: 2.7618825435638428
Validation loss: 2.0911039485726306

Epoch: 5| Step: 1
Training loss: 2.353137731552124
Validation loss: 2.0108727357720815

Epoch: 5| Step: 2
Training loss: 2.409188985824585
Validation loss: 2.008356317397087

Epoch: 5| Step: 3
Training loss: 2.231489658355713
Validation loss: 2.032535071014076

Epoch: 5| Step: 4
Training loss: 2.063854217529297
Validation loss: 2.0791286396723923

Epoch: 5| Step: 5
Training loss: 1.6667728424072266
Validation loss: 2.045360747204032

Epoch: 5| Step: 6
Training loss: 2.733224630355835
Validation loss: 2.01579132387715

Epoch: 5| Step: 7
Training loss: 2.40358304977417
Validation loss: 2.030500045386694

Epoch: 5| Step: 8
Training loss: 2.8401174545288086
Validation loss: 2.0390334847152873

Epoch: 5| Step: 9
Training loss: 2.013944149017334
Validation loss: 2.0049120777396747

Epoch: 5| Step: 10
Training loss: 1.7436469793319702
Validation loss: 2.064932697562761

Epoch: 127| Step: 0
Training loss: 1.9518823623657227
Validation loss: 2.060847146536714

Epoch: 5| Step: 1
Training loss: 2.378272771835327
Validation loss: 2.043936942213325

Epoch: 5| Step: 2
Training loss: 2.790126085281372
Validation loss: 2.1212019535803024

Epoch: 5| Step: 3
Training loss: 2.8257455825805664
Validation loss: 2.0417384921863513

Epoch: 5| Step: 4
Training loss: 2.373117446899414
Validation loss: 2.0363630440927323

Epoch: 5| Step: 5
Training loss: 1.8079664707183838
Validation loss: 2.083747269004904

Epoch: 5| Step: 6
Training loss: 2.350118398666382
Validation loss: 2.0764647401789182

Epoch: 5| Step: 7
Training loss: 1.9140589237213135
Validation loss: 2.064284199027605

Epoch: 5| Step: 8
Training loss: 2.353745698928833
Validation loss: 2.057890808710488

Epoch: 5| Step: 9
Training loss: 1.8443940877914429
Validation loss: 2.0643470876960346

Epoch: 5| Step: 10
Training loss: 2.6774959564208984
Validation loss: 2.0839297515089794

Epoch: 128| Step: 0
Training loss: 2.648768186569214
Validation loss: 2.102073554069765

Epoch: 5| Step: 1
Training loss: 2.80757474899292
Validation loss: 2.023319426403251

Epoch: 5| Step: 2
Training loss: 2.0847694873809814
Validation loss: 2.104852214936287

Epoch: 5| Step: 3
Training loss: 2.366555690765381
Validation loss: 2.0338680590352705

Epoch: 5| Step: 4
Training loss: 2.6456665992736816
Validation loss: 2.0238915310111096

Epoch: 5| Step: 5
Training loss: 1.7072432041168213
Validation loss: 2.0882352231651224

Epoch: 5| Step: 6
Training loss: 1.4660351276397705
Validation loss: 2.061692460890739

Epoch: 5| Step: 7
Training loss: 2.0335581302642822
Validation loss: 2.0599489263308945

Epoch: 5| Step: 8
Training loss: 2.486520290374756
Validation loss: 2.098022722428845

Epoch: 5| Step: 9
Training loss: 2.4660892486572266
Validation loss: 2.0783627533143565

Epoch: 5| Step: 10
Training loss: 2.285183906555176
Validation loss: 2.037686614580052

Epoch: 129| Step: 0
Training loss: 2.718534231185913
Validation loss: 1.9991521450781053

Epoch: 5| Step: 1
Training loss: 1.9059293270111084
Validation loss: 2.0605352822170464

Epoch: 5| Step: 2
Training loss: 2.4983482360839844
Validation loss: 1.9762236046534714

Epoch: 5| Step: 3
Training loss: 2.5732548236846924
Validation loss: 2.028625742081673

Epoch: 5| Step: 4
Training loss: 1.8610175848007202
Validation loss: 2.01408762444732

Epoch: 5| Step: 5
Training loss: 2.130542755126953
Validation loss: 2.0214276980328303

Epoch: 5| Step: 6
Training loss: 2.43206524848938
Validation loss: 2.0795976923358057

Epoch: 5| Step: 7
Training loss: 2.442507266998291
Validation loss: 2.0093496563614055

Epoch: 5| Step: 8
Training loss: 2.6588149070739746
Validation loss: 2.004027851166264

Epoch: 5| Step: 9
Training loss: 1.7510120868682861
Validation loss: 2.038817863310537

Epoch: 5| Step: 10
Training loss: 1.9381076097488403
Validation loss: 2.0635779955053843

Epoch: 130| Step: 0
Training loss: 2.245807647705078
Validation loss: 2.0275715063976985

Epoch: 5| Step: 1
Training loss: 2.696376085281372
Validation loss: 2.039435031593487

Epoch: 5| Step: 2
Training loss: 2.0736520290374756
Validation loss: 2.0205436662961076

Epoch: 5| Step: 3
Training loss: 2.0930745601654053
Validation loss: 2.0349027777230866

Epoch: 5| Step: 4
Training loss: 1.883540391921997
Validation loss: 2.0255374703356015

Epoch: 5| Step: 5
Training loss: 2.697657346725464
Validation loss: 2.0756267629643923

Epoch: 5| Step: 6
Training loss: 2.5022506713867188
Validation loss: 1.9897311989979078

Epoch: 5| Step: 7
Training loss: 2.0661208629608154
Validation loss: 2.058707488480435

Epoch: 5| Step: 8
Training loss: 2.231372356414795
Validation loss: 2.0590342424249135

Epoch: 5| Step: 9
Training loss: 1.9690215587615967
Validation loss: 2.0343155014899468

Epoch: 5| Step: 10
Training loss: 2.5279242992401123
Validation loss: 2.0296607760972876

Epoch: 131| Step: 0
Training loss: 2.118028163909912
Validation loss: 2.0279718304193146

Epoch: 5| Step: 1
Training loss: 2.242042064666748
Validation loss: 2.041464641530027

Epoch: 5| Step: 2
Training loss: 2.3492648601531982
Validation loss: 2.0511097651655956

Epoch: 5| Step: 3
Training loss: 2.1449341773986816
Validation loss: 2.0229155581484557

Epoch: 5| Step: 4
Training loss: 2.692993640899658
Validation loss: 2.0262769319677867

Epoch: 5| Step: 5
Training loss: 2.6163227558135986
Validation loss: 2.091708904953413

Epoch: 5| Step: 6
Training loss: 2.5028374195098877
Validation loss: 2.0569949624358967

Epoch: 5| Step: 7
Training loss: 2.254931688308716
Validation loss: 2.0438599381395566

Epoch: 5| Step: 8
Training loss: 1.791670799255371
Validation loss: 2.0570509741383214

Epoch: 5| Step: 9
Training loss: 2.207932472229004
Validation loss: 2.0500292726742324

Epoch: 5| Step: 10
Training loss: 2.3878259658813477
Validation loss: 2.0603346824645996

Epoch: 132| Step: 0
Training loss: 2.365487575531006
Validation loss: 2.0614239528614986

Epoch: 5| Step: 1
Training loss: 2.6090378761291504
Validation loss: 2.041008318624189

Epoch: 5| Step: 2
Training loss: 1.9039547443389893
Validation loss: 2.0420622402621853

Epoch: 5| Step: 3
Training loss: 2.1161415576934814
Validation loss: 1.991585011123329

Epoch: 5| Step: 4
Training loss: 1.4494878053665161
Validation loss: 2.084596190401303

Epoch: 5| Step: 5
Training loss: 2.711879014968872
Validation loss: 2.0378377335045927

Epoch: 5| Step: 6
Training loss: 2.56298565864563
Validation loss: 2.020119032552165

Epoch: 5| Step: 7
Training loss: 2.0836987495422363
Validation loss: 2.028954170083487

Epoch: 5| Step: 8
Training loss: 2.118837833404541
Validation loss: 2.057502487654327

Epoch: 5| Step: 9
Training loss: 2.4966471195220947
Validation loss: 2.050246433545184

Epoch: 5| Step: 10
Training loss: 2.707049608230591
Validation loss: 2.069533758265998

Epoch: 133| Step: 0
Training loss: 1.8877359628677368
Validation loss: 2.0711464010259157

Epoch: 5| Step: 1
Training loss: 2.1592891216278076
Validation loss: 2.0499638844561834

Epoch: 5| Step: 2
Training loss: 2.370176315307617
Validation loss: 2.038223312747094

Epoch: 5| Step: 3
Training loss: 2.476273775100708
Validation loss: 2.0155597848276936

Epoch: 5| Step: 4
Training loss: 2.7352499961853027
Validation loss: 2.0668726685226604

Epoch: 5| Step: 5
Training loss: 1.9850196838378906
Validation loss: 2.087817750951295

Epoch: 5| Step: 6
Training loss: 2.187926769256592
Validation loss: 2.041394333685598

Epoch: 5| Step: 7
Training loss: 2.2544283866882324
Validation loss: 2.11237810760416

Epoch: 5| Step: 8
Training loss: 2.41235613822937
Validation loss: 2.0759501226486696

Epoch: 5| Step: 9
Training loss: 2.0855867862701416
Validation loss: 2.053869519182431

Epoch: 5| Step: 10
Training loss: 2.6041154861450195
Validation loss: 2.0278623373277727

Epoch: 134| Step: 0
Training loss: 2.5167789459228516
Validation loss: 2.063724530640469

Epoch: 5| Step: 1
Training loss: 2.0435757637023926
Validation loss: 2.052310025820168

Epoch: 5| Step: 2
Training loss: 2.096911907196045
Validation loss: 2.0448641623220136

Epoch: 5| Step: 3
Training loss: 1.9198678731918335
Validation loss: 2.0915489760778283

Epoch: 5| Step: 4
Training loss: 2.845093250274658
Validation loss: 2.015888132074828

Epoch: 5| Step: 5
Training loss: 2.2775216102600098
Validation loss: 2.05708876732857

Epoch: 5| Step: 6
Training loss: 1.8056800365447998
Validation loss: 1.9842870645625617

Epoch: 5| Step: 7
Training loss: 2.8192105293273926
Validation loss: 2.042494122700025

Epoch: 5| Step: 8
Training loss: 2.239525556564331
Validation loss: 2.0396796221374185

Epoch: 5| Step: 9
Training loss: 2.3054087162017822
Validation loss: 2.0568643436636975

Epoch: 5| Step: 10
Training loss: 2.2152318954467773
Validation loss: 2.059106053844575

Epoch: 135| Step: 0
Training loss: 2.6822187900543213
Validation loss: 2.004368967907403

Epoch: 5| Step: 1
Training loss: 1.833764672279358
Validation loss: 1.9851865768432617

Epoch: 5| Step: 2
Training loss: 2.029419422149658
Validation loss: 2.0409574406121367

Epoch: 5| Step: 3
Training loss: 2.17447566986084
Validation loss: 2.0907090428054973

Epoch: 5| Step: 4
Training loss: 2.758352279663086
Validation loss: 2.0252119469386276

Epoch: 5| Step: 5
Training loss: 2.1485209465026855
Validation loss: 2.075235628312634

Epoch: 5| Step: 6
Training loss: 2.169766664505005
Validation loss: 2.075929131559146

Epoch: 5| Step: 7
Training loss: 2.4828243255615234
Validation loss: 2.056081577013898

Epoch: 5| Step: 8
Training loss: 2.3089590072631836
Validation loss: 2.0775445635600756

Epoch: 5| Step: 9
Training loss: 2.4621217250823975
Validation loss: 2.052883022574968

Epoch: 5| Step: 10
Training loss: 2.321927070617676
Validation loss: 2.0116930956481607

Epoch: 136| Step: 0
Training loss: 2.085465431213379
Validation loss: 2.006245970726013

Epoch: 5| Step: 1
Training loss: 1.7149759531021118
Validation loss: 2.0672224567782496

Epoch: 5| Step: 2
Training loss: 1.9461711645126343
Validation loss: 2.063077134470786

Epoch: 5| Step: 3
Training loss: 2.9424192905426025
Validation loss: 2.0471172153308825

Epoch: 5| Step: 4
Training loss: 2.998185634613037
Validation loss: 2.047677056763762

Epoch: 5| Step: 5
Training loss: 2.0389764308929443
Validation loss: 2.0102656349059074

Epoch: 5| Step: 6
Training loss: 1.7964948415756226
Validation loss: 2.0289165255843953

Epoch: 5| Step: 7
Training loss: 2.6239161491394043
Validation loss: 2.0424588111139115

Epoch: 5| Step: 8
Training loss: 2.4277384281158447
Validation loss: 1.9884082232752154

Epoch: 5| Step: 9
Training loss: 2.543649196624756
Validation loss: 2.0524369901226414

Epoch: 5| Step: 10
Training loss: 1.734993815422058
Validation loss: 2.0214001171050535

Epoch: 137| Step: 0
Training loss: 1.7962062358856201
Validation loss: 2.0604986785560526

Epoch: 5| Step: 1
Training loss: 2.6454200744628906
Validation loss: 2.0142317818057154

Epoch: 5| Step: 2
Training loss: 2.6601805686950684
Validation loss: 2.014718555635022

Epoch: 5| Step: 3
Training loss: 1.9366124868392944
Validation loss: 2.0131890414863505

Epoch: 5| Step: 4
Training loss: 2.3668971061706543
Validation loss: 2.0118202599146033

Epoch: 5| Step: 5
Training loss: 2.542405605316162
Validation loss: 2.00587050889128

Epoch: 5| Step: 6
Training loss: 2.5425331592559814
Validation loss: 2.0120964639930317

Epoch: 5| Step: 7
Training loss: 2.202528953552246
Validation loss: 2.0413708686828613

Epoch: 5| Step: 8
Training loss: 2.1975460052490234
Validation loss: 2.0203378200531006

Epoch: 5| Step: 9
Training loss: 1.7460256814956665
Validation loss: 2.008533759783673

Epoch: 5| Step: 10
Training loss: 2.3645660877227783
Validation loss: 2.0306862682424565

Epoch: 138| Step: 0
Training loss: 2.0515050888061523
Validation loss: 2.035168304238268

Epoch: 5| Step: 1
Training loss: 2.4741013050079346
Validation loss: 2.0555324656988985

Epoch: 5| Step: 2
Training loss: 2.109247922897339
Validation loss: 2.002541847126458

Epoch: 5| Step: 3
Training loss: 2.462038040161133
Validation loss: 1.9891912193708523

Epoch: 5| Step: 4
Training loss: 1.2925026416778564
Validation loss: 2.085896094640096

Epoch: 5| Step: 5
Training loss: 2.029841899871826
Validation loss: 2.064467107096026

Epoch: 5| Step: 6
Training loss: 2.821068286895752
Validation loss: 1.9997456791580364

Epoch: 5| Step: 7
Training loss: 2.752175807952881
Validation loss: 2.0135802850928357

Epoch: 5| Step: 8
Training loss: 2.55513072013855
Validation loss: 2.0240819941284838

Epoch: 5| Step: 9
Training loss: 1.6160151958465576
Validation loss: 2.0901086843141945

Epoch: 5| Step: 10
Training loss: 2.5204403400421143
Validation loss: 2.0637190752131964

Epoch: 139| Step: 0
Training loss: 2.3604445457458496
Validation loss: 2.039169655051283

Epoch: 5| Step: 1
Training loss: 2.0766282081604004
Validation loss: 2.0281592863862232

Epoch: 5| Step: 2
Training loss: 2.4007201194763184
Validation loss: 2.1025825162087717

Epoch: 5| Step: 3
Training loss: 2.1751506328582764
Validation loss: 2.109663486480713

Epoch: 5| Step: 4
Training loss: 2.6266512870788574
Validation loss: 2.051636626643519

Epoch: 5| Step: 5
Training loss: 2.3306636810302734
Validation loss: 2.0292935845672444

Epoch: 5| Step: 6
Training loss: 2.044785737991333
Validation loss: 2.0750699658547678

Epoch: 5| Step: 7
Training loss: 3.2716784477233887
Validation loss: 2.086158178185904

Epoch: 5| Step: 8
Training loss: 1.749588966369629
Validation loss: 2.0582205377599245

Epoch: 5| Step: 9
Training loss: 2.083566188812256
Validation loss: 2.108308340913506

Epoch: 5| Step: 10
Training loss: 2.020845413208008
Validation loss: 2.0629906756903535

Epoch: 140| Step: 0
Training loss: 2.6508889198303223
Validation loss: 2.084802914691228

Epoch: 5| Step: 1
Training loss: 2.6166980266571045
Validation loss: 2.019718225284289

Epoch: 5| Step: 2
Training loss: 2.3844480514526367
Validation loss: 2.0430812528056483

Epoch: 5| Step: 3
Training loss: 1.9579671621322632
Validation loss: 2.039801028466994

Epoch: 5| Step: 4
Training loss: 1.8245989084243774
Validation loss: 2.0105282196434597

Epoch: 5| Step: 5
Training loss: 2.4738011360168457
Validation loss: 2.046562567833931

Epoch: 5| Step: 6
Training loss: 1.845224380493164
Validation loss: 2.012600584696698

Epoch: 5| Step: 7
Training loss: 2.748884439468384
Validation loss: 2.033748613890781

Epoch: 5| Step: 8
Training loss: 2.089604616165161
Validation loss: 2.050482473065776

Epoch: 5| Step: 9
Training loss: 2.199230670928955
Validation loss: 2.0698100828355357

Epoch: 5| Step: 10
Training loss: 2.0739176273345947
Validation loss: 2.0407309403983493

Epoch: 141| Step: 0
Training loss: 2.2445433139801025
Validation loss: 1.98655713758161

Epoch: 5| Step: 1
Training loss: 2.8895576000213623
Validation loss: 2.0636082310830393

Epoch: 5| Step: 2
Training loss: 1.9873311519622803
Validation loss: 2.0495548761019142

Epoch: 5| Step: 3
Training loss: 1.9813073873519897
Validation loss: 2.0104263649191907

Epoch: 5| Step: 4
Training loss: 2.1172566413879395
Validation loss: 2.0609255618946527

Epoch: 5| Step: 5
Training loss: 2.2606568336486816
Validation loss: 2.032205202246225

Epoch: 5| Step: 6
Training loss: 2.3534977436065674
Validation loss: 2.056561570013723

Epoch: 5| Step: 7
Training loss: 1.9434335231781006
Validation loss: 2.064369290105758

Epoch: 5| Step: 8
Training loss: 3.0867667198181152
Validation loss: 2.067839241796924

Epoch: 5| Step: 9
Training loss: 2.501042366027832
Validation loss: 2.0223746184379823

Epoch: 5| Step: 10
Training loss: 1.72652006149292
Validation loss: 2.0181836902454333

Epoch: 142| Step: 0
Training loss: 1.979466438293457
Validation loss: 2.0689125855763755

Epoch: 5| Step: 1
Training loss: 2.2102127075195312
Validation loss: 2.028804773925453

Epoch: 5| Step: 2
Training loss: 2.7787411212921143
Validation loss: 2.0511691621554795

Epoch: 5| Step: 3
Training loss: 2.188079595565796
Validation loss: 2.018947514154578

Epoch: 5| Step: 4
Training loss: 2.2093164920806885
Validation loss: 2.0702459376345397

Epoch: 5| Step: 5
Training loss: 2.420621871948242
Validation loss: 2.0511847337086997

Epoch: 5| Step: 6
Training loss: 1.9127143621444702
Validation loss: 2.0784279274684128

Epoch: 5| Step: 7
Training loss: 2.261533260345459
Validation loss: 2.0373828616193546

Epoch: 5| Step: 8
Training loss: 2.067800998687744
Validation loss: 2.088791803647113

Epoch: 5| Step: 9
Training loss: 2.5251448154449463
Validation loss: 2.0402286155249483

Epoch: 5| Step: 10
Training loss: 2.53462290763855
Validation loss: 2.023166407820999

Epoch: 143| Step: 0
Training loss: 2.721658706665039
Validation loss: 2.0287706749413603

Epoch: 5| Step: 1
Training loss: 2.231827974319458
Validation loss: 2.1230164394583753

Epoch: 5| Step: 2
Training loss: 1.6818580627441406
Validation loss: 2.0628608285739856

Epoch: 5| Step: 3
Training loss: 2.490403890609741
Validation loss: 2.062090817318168

Epoch: 5| Step: 4
Training loss: 2.3583245277404785
Validation loss: 2.048967415286649

Epoch: 5| Step: 5
Training loss: 2.400238037109375
Validation loss: 2.0788856834493656

Epoch: 5| Step: 6
Training loss: 1.616062879562378
Validation loss: 2.119744928934241

Epoch: 5| Step: 7
Training loss: 1.9227421283721924
Validation loss: 2.017507344163874

Epoch: 5| Step: 8
Training loss: 2.5541038513183594
Validation loss: 2.07463687978765

Epoch: 5| Step: 9
Training loss: 2.390599489212036
Validation loss: 2.0535413757447274

Epoch: 5| Step: 10
Training loss: 2.8104097843170166
Validation loss: 2.0576048871522308

Epoch: 144| Step: 0
Training loss: 2.3859009742736816
Validation loss: 2.0670218557439823

Epoch: 5| Step: 1
Training loss: 1.9812291860580444
Validation loss: 2.056899493740451

Epoch: 5| Step: 2
Training loss: 2.1089890003204346
Validation loss: 2.017211724353093

Epoch: 5| Step: 3
Training loss: 2.1369025707244873
Validation loss: 2.0129256107473887

Epoch: 5| Step: 4
Training loss: 1.7610925436019897
Validation loss: 2.122351138822494

Epoch: 5| Step: 5
Training loss: 3.118800640106201
Validation loss: 2.033409341689079

Epoch: 5| Step: 6
Training loss: 2.2324228286743164
Validation loss: 2.003183821196197

Epoch: 5| Step: 7
Training loss: 2.166898727416992
Validation loss: 2.0351004062160367

Epoch: 5| Step: 8
Training loss: 2.7060956954956055
Validation loss: 2.0227956515486523

Epoch: 5| Step: 9
Training loss: 2.268084764480591
Validation loss: 1.9902493646067958

Epoch: 5| Step: 10
Training loss: 2.461068630218506
Validation loss: 2.018954277038574

Epoch: 145| Step: 0
Training loss: 2.8573107719421387
Validation loss: 2.0773498473628873

Epoch: 5| Step: 1
Training loss: 2.010436534881592
Validation loss: 2.0257055861975557

Epoch: 5| Step: 2
Training loss: 1.7832002639770508
Validation loss: 2.0178933310252365

Epoch: 5| Step: 3
Training loss: 2.326856851577759
Validation loss: 2.0143438449469944

Epoch: 5| Step: 4
Training loss: 2.2395615577697754
Validation loss: 2.0711713913948304

Epoch: 5| Step: 5
Training loss: 2.202697277069092
Validation loss: 1.9847444975247948

Epoch: 5| Step: 6
Training loss: 2.5589938163757324
Validation loss: 2.0221425974240868

Epoch: 5| Step: 7
Training loss: 2.573423385620117
Validation loss: 2.0492467495702926

Epoch: 5| Step: 8
Training loss: 2.0428295135498047
Validation loss: 2.043508239971694

Epoch: 5| Step: 9
Training loss: 2.5344414710998535
Validation loss: 1.9994532985071982

Epoch: 5| Step: 10
Training loss: 2.030404806137085
Validation loss: 2.0259327375760643

Epoch: 146| Step: 0
Training loss: 2.164257526397705
Validation loss: 2.0452647991077875

Epoch: 5| Step: 1
Training loss: 2.350856065750122
Validation loss: 2.024535994375906

Epoch: 5| Step: 2
Training loss: 2.4227795600891113
Validation loss: 2.060955527008221

Epoch: 5| Step: 3
Training loss: 1.3109157085418701
Validation loss: 2.064069290314951

Epoch: 5| Step: 4
Training loss: 2.4485437870025635
Validation loss: 2.106356273415268

Epoch: 5| Step: 5
Training loss: 1.9694149494171143
Validation loss: 2.083223025004069

Epoch: 5| Step: 6
Training loss: 2.417517900466919
Validation loss: 2.083238040247271

Epoch: 5| Step: 7
Training loss: 2.0500802993774414
Validation loss: 2.0287094885303127

Epoch: 5| Step: 8
Training loss: 2.363797187805176
Validation loss: 2.061108386644753

Epoch: 5| Step: 9
Training loss: 2.6401267051696777
Validation loss: 2.1073655184879097

Epoch: 5| Step: 10
Training loss: 3.0718085765838623
Validation loss: 2.0612380709699405

Epoch: 147| Step: 0
Training loss: 1.8099275827407837
Validation loss: 2.049745650701625

Epoch: 5| Step: 1
Training loss: 2.2558581829071045
Validation loss: 2.10994037248755

Epoch: 5| Step: 2
Training loss: 1.482359528541565
Validation loss: 2.055692107446732

Epoch: 5| Step: 3
Training loss: 2.3421337604522705
Validation loss: 2.0307196404344294

Epoch: 5| Step: 4
Training loss: 2.7055492401123047
Validation loss: 2.0825440050453268

Epoch: 5| Step: 5
Training loss: 1.8910099267959595
Validation loss: 2.0819230002741658

Epoch: 5| Step: 6
Training loss: 2.1647825241088867
Validation loss: 2.0555508764841224

Epoch: 5| Step: 7
Training loss: 2.669224262237549
Validation loss: 2.057563438210436

Epoch: 5| Step: 8
Training loss: 2.1800358295440674
Validation loss: 2.0498906309886644

Epoch: 5| Step: 9
Training loss: 1.9392778873443604
Validation loss: 2.0422510126585602

Epoch: 5| Step: 10
Training loss: 3.1561362743377686
Validation loss: 2.031434953853648

Epoch: 148| Step: 0
Training loss: 2.190016508102417
Validation loss: 2.026275714238485

Epoch: 5| Step: 1
Training loss: 2.7826104164123535
Validation loss: 2.0735387212486676

Epoch: 5| Step: 2
Training loss: 2.6270973682403564
Validation loss: 2.052296592343238

Epoch: 5| Step: 3
Training loss: 1.8296924829483032
Validation loss: 2.0261023621405325

Epoch: 5| Step: 4
Training loss: 2.4941744804382324
Validation loss: 2.0481535657759635

Epoch: 5| Step: 5
Training loss: 2.521836996078491
Validation loss: 2.0177194303081882

Epoch: 5| Step: 6
Training loss: 2.364877223968506
Validation loss: 2.034762277398058

Epoch: 5| Step: 7
Training loss: 1.8674583435058594
Validation loss: 2.037496776990993

Epoch: 5| Step: 8
Training loss: 2.418588161468506
Validation loss: 2.0152614783215266

Epoch: 5| Step: 9
Training loss: 1.7989829778671265
Validation loss: 2.0617598384939213

Epoch: 5| Step: 10
Training loss: 2.058624744415283
Validation loss: 2.045157378719699

Epoch: 149| Step: 0
Training loss: 1.9931459426879883
Validation loss: 2.0368636320996028

Epoch: 5| Step: 1
Training loss: 1.7554963827133179
Validation loss: 2.111156843041861

Epoch: 5| Step: 2
Training loss: 2.611020565032959
Validation loss: 2.049553999336817

Epoch: 5| Step: 3
Training loss: 2.0754661560058594
Validation loss: 2.0137565712774954

Epoch: 5| Step: 4
Training loss: 1.7515701055526733
Validation loss: 2.035270228180834

Epoch: 5| Step: 5
Training loss: 2.7303109169006348
Validation loss: 2.022144848300565

Epoch: 5| Step: 6
Training loss: 2.546511173248291
Validation loss: 2.0293585010754165

Epoch: 5| Step: 7
Training loss: 2.0426254272460938
Validation loss: 2.051246803293946

Epoch: 5| Step: 8
Training loss: 2.0825912952423096
Validation loss: 2.0405113773961223

Epoch: 5| Step: 9
Training loss: 2.7273707389831543
Validation loss: 2.0496551785417783

Epoch: 5| Step: 10
Training loss: 2.6312642097473145
Validation loss: 2.129778867126793

Epoch: 150| Step: 0
Training loss: 1.986680030822754
Validation loss: 2.0821016347536476

Epoch: 5| Step: 1
Training loss: 2.140780210494995
Validation loss: 2.072687454121087

Epoch: 5| Step: 2
Training loss: 2.393397569656372
Validation loss: 2.069447230267268

Epoch: 5| Step: 3
Training loss: 1.8167140483856201
Validation loss: 2.0217524279830275

Epoch: 5| Step: 4
Training loss: 2.414060354232788
Validation loss: 2.0725269663718437

Epoch: 5| Step: 5
Training loss: 2.593165159225464
Validation loss: 2.081795688598387

Epoch: 5| Step: 6
Training loss: 2.7871854305267334
Validation loss: 2.012283399540891

Epoch: 5| Step: 7
Training loss: 2.298579692840576
Validation loss: 2.059945903798585

Epoch: 5| Step: 8
Training loss: 1.912835717201233
Validation loss: 2.0603010385267195

Epoch: 5| Step: 9
Training loss: 2.117842435836792
Validation loss: 2.0784597319941365

Epoch: 5| Step: 10
Training loss: 2.2069766521453857
Validation loss: 2.0470534473337154

Epoch: 151| Step: 0
Training loss: 1.8529850244522095
Validation loss: 2.0383969929910477

Epoch: 5| Step: 1
Training loss: 1.9463924169540405
Validation loss: 2.029697718158845

Epoch: 5| Step: 2
Training loss: 2.665444850921631
Validation loss: 2.0323028410634687

Epoch: 5| Step: 3
Training loss: 2.3787055015563965
Validation loss: 2.044192498730075

Epoch: 5| Step: 4
Training loss: 2.5482177734375
Validation loss: 2.063790426459364

Epoch: 5| Step: 5
Training loss: 2.6766357421875
Validation loss: 2.038301449950023

Epoch: 5| Step: 6
Training loss: 1.6886608600616455
Validation loss: 2.0588097559508456

Epoch: 5| Step: 7
Training loss: 2.271635055541992
Validation loss: 2.0771594791002173

Epoch: 5| Step: 8
Training loss: 2.302773952484131
Validation loss: 2.031250796010417

Epoch: 5| Step: 9
Training loss: 2.5190930366516113
Validation loss: 2.0873600154794674

Epoch: 5| Step: 10
Training loss: 2.114396095275879
Validation loss: 2.0630997842358005

Epoch: 152| Step: 0
Training loss: 2.0642521381378174
Validation loss: 2.1066530801916636

Epoch: 5| Step: 1
Training loss: 1.71981680393219
Validation loss: 2.0846998486467587

Epoch: 5| Step: 2
Training loss: 1.9456583261489868
Validation loss: 2.0532997820966985

Epoch: 5| Step: 3
Training loss: 1.5821828842163086
Validation loss: 2.0675651129855903

Epoch: 5| Step: 4
Training loss: 2.7702908515930176
Validation loss: 2.093416513935212

Epoch: 5| Step: 5
Training loss: 2.476720094680786
Validation loss: 2.032852267706266

Epoch: 5| Step: 6
Training loss: 1.9470516443252563
Validation loss: 2.0537458183944866

Epoch: 5| Step: 7
Training loss: 2.712151050567627
Validation loss: 2.0553920961195424

Epoch: 5| Step: 8
Training loss: 2.20524525642395
Validation loss: 2.0669872606954267

Epoch: 5| Step: 9
Training loss: 2.465172529220581
Validation loss: 2.0588785063835884

Epoch: 5| Step: 10
Training loss: 3.1615514755249023
Validation loss: 2.053496265924105

Epoch: 153| Step: 0
Training loss: 2.3528518676757812
Validation loss: 2.060428120756662

Epoch: 5| Step: 1
Training loss: 2.0705981254577637
Validation loss: 2.057877534179277

Epoch: 5| Step: 2
Training loss: 2.2241435050964355
Validation loss: 2.0601987825926913

Epoch: 5| Step: 3
Training loss: 1.91131591796875
Validation loss: 2.0390033183559293

Epoch: 5| Step: 4
Training loss: 2.4476370811462402
Validation loss: 2.0509673023736603

Epoch: 5| Step: 5
Training loss: 2.706918478012085
Validation loss: 1.9962325890858967

Epoch: 5| Step: 6
Training loss: 2.1464626789093018
Validation loss: 2.0568438191567697

Epoch: 5| Step: 7
Training loss: 1.8622112274169922
Validation loss: 2.0369176838987615

Epoch: 5| Step: 8
Training loss: 2.177915096282959
Validation loss: 2.0541943273236676

Epoch: 5| Step: 9
Training loss: 2.1553328037261963
Validation loss: 2.0443940495931976

Epoch: 5| Step: 10
Training loss: 2.542206048965454
Validation loss: 2.0781167758408414

Epoch: 154| Step: 0
Training loss: 2.377926826477051
Validation loss: 2.0419509333948933

Epoch: 5| Step: 1
Training loss: 1.9829639196395874
Validation loss: 2.0054942792461765

Epoch: 5| Step: 2
Training loss: 1.8392956256866455
Validation loss: 1.9880355609360563

Epoch: 5| Step: 3
Training loss: 2.7450783252716064
Validation loss: 1.9888719897116385

Epoch: 5| Step: 4
Training loss: 2.2764391899108887
Validation loss: 2.0629692680092266

Epoch: 5| Step: 5
Training loss: 1.95304274559021
Validation loss: 2.066929091689407

Epoch: 5| Step: 6
Training loss: 3.209768295288086
Validation loss: 2.0426830322511735

Epoch: 5| Step: 7
Training loss: 2.4080893993377686
Validation loss: 2.003342038841658

Epoch: 5| Step: 8
Training loss: 1.6844879388809204
Validation loss: 2.062393916550503

Epoch: 5| Step: 9
Training loss: 2.3080391883850098
Validation loss: 2.0523846277626614

Epoch: 5| Step: 10
Training loss: 1.5359519720077515
Validation loss: 2.0276517714223554

Epoch: 155| Step: 0
Training loss: 2.1521010398864746
Validation loss: 2.0002141203931583

Epoch: 5| Step: 1
Training loss: 2.479280471801758
Validation loss: 2.0085111715460338

Epoch: 5| Step: 2
Training loss: 1.8424131870269775
Validation loss: 1.9993636018486434

Epoch: 5| Step: 3
Training loss: 2.137629270553589
Validation loss: 2.018158661421909

Epoch: 5| Step: 4
Training loss: 2.0858280658721924
Validation loss: 2.0741806209728284

Epoch: 5| Step: 5
Training loss: 1.9250824451446533
Validation loss: 2.005099772125162

Epoch: 5| Step: 6
Training loss: 2.1228432655334473
Validation loss: 2.0480558410767586

Epoch: 5| Step: 7
Training loss: 2.250476837158203
Validation loss: 2.062272587130147

Epoch: 5| Step: 8
Training loss: 2.023625373840332
Validation loss: 2.054001449256815

Epoch: 5| Step: 9
Training loss: 2.4570651054382324
Validation loss: 2.0718610517440306

Epoch: 5| Step: 10
Training loss: 3.0650112628936768
Validation loss: 2.0232594872033722

Epoch: 156| Step: 0
Training loss: 2.0496068000793457
Validation loss: 2.0368985258122927

Epoch: 5| Step: 1
Training loss: 2.582244873046875
Validation loss: 2.0593584096559914

Epoch: 5| Step: 2
Training loss: 1.8953742980957031
Validation loss: 2.0587156690577024

Epoch: 5| Step: 3
Training loss: 2.467864513397217
Validation loss: 2.046785795560447

Epoch: 5| Step: 4
Training loss: 2.024266481399536
Validation loss: 2.0835290339685257

Epoch: 5| Step: 5
Training loss: 1.7822482585906982
Validation loss: 2.076381537222093

Epoch: 5| Step: 6
Training loss: 2.244804859161377
Validation loss: 2.024851211937525

Epoch: 5| Step: 7
Training loss: 2.1749110221862793
Validation loss: 1.9935262895399524

Epoch: 5| Step: 8
Training loss: 2.357724905014038
Validation loss: 2.070150629166634

Epoch: 5| Step: 9
Training loss: 2.632415294647217
Validation loss: 2.021133525397188

Epoch: 5| Step: 10
Training loss: 2.9137496948242188
Validation loss: 2.022204432436215

Epoch: 157| Step: 0
Training loss: 2.834778308868408
Validation loss: 2.020376310553602

Epoch: 5| Step: 1
Training loss: 2.3442368507385254
Validation loss: 2.0329875766590075

Epoch: 5| Step: 2
Training loss: 2.0449166297912598
Validation loss: 2.01247347939399

Epoch: 5| Step: 3
Training loss: 3.26314115524292
Validation loss: 2.0114777344529347

Epoch: 5| Step: 4
Training loss: 1.9554979801177979
Validation loss: 2.050764860645417

Epoch: 5| Step: 5
Training loss: 1.6918834447860718
Validation loss: 2.102903027688303

Epoch: 5| Step: 6
Training loss: 1.8677618503570557
Validation loss: 2.033965810652702

Epoch: 5| Step: 7
Training loss: 1.6497108936309814
Validation loss: 2.046411806537259

Epoch: 5| Step: 8
Training loss: 1.9205377101898193
Validation loss: 2.069896359597483

Epoch: 5| Step: 9
Training loss: 2.6828131675720215
Validation loss: 2.038762605318459

Epoch: 5| Step: 10
Training loss: 2.8160414695739746
Validation loss: 2.049513368196385

Epoch: 158| Step: 0
Training loss: 2.3159022331237793
Validation loss: 2.074839743234778

Epoch: 5| Step: 1
Training loss: 2.038785934448242
Validation loss: 2.049310971331853

Epoch: 5| Step: 2
Training loss: 2.2511279582977295
Validation loss: 2.0222275282747004

Epoch: 5| Step: 3
Training loss: 1.9786975383758545
Validation loss: 2.026846397307611

Epoch: 5| Step: 4
Training loss: 1.8991258144378662
Validation loss: 2.0784816318942654

Epoch: 5| Step: 5
Training loss: 2.376044750213623
Validation loss: 2.085331306662611

Epoch: 5| Step: 6
Training loss: 2.2358040809631348
Validation loss: 2.052441097074939

Epoch: 5| Step: 7
Training loss: 2.223923921585083
Validation loss: 2.050329413465274

Epoch: 5| Step: 8
Training loss: 2.0595641136169434
Validation loss: 2.0399313280659337

Epoch: 5| Step: 9
Training loss: 3.1887919902801514
Validation loss: 2.0282509480753252

Epoch: 5| Step: 10
Training loss: 2.021160125732422
Validation loss: 2.0503824449354604

Epoch: 159| Step: 0
Training loss: 2.2818639278411865
Validation loss: 2.048288422246133

Epoch: 5| Step: 1
Training loss: 2.6957743167877197
Validation loss: 2.0468769496487034

Epoch: 5| Step: 2
Training loss: 1.762067437171936
Validation loss: 2.0177867310021513

Epoch: 5| Step: 3
Training loss: 2.5391314029693604
Validation loss: 2.0718976733505086

Epoch: 5| Step: 4
Training loss: 2.4366116523742676
Validation loss: 2.040209690729777

Epoch: 5| Step: 5
Training loss: 1.8343546390533447
Validation loss: 2.043060641134939

Epoch: 5| Step: 6
Training loss: 2.3826186656951904
Validation loss: 2.0580287876949517

Epoch: 5| Step: 7
Training loss: 2.759340286254883
Validation loss: 2.03510126503565

Epoch: 5| Step: 8
Training loss: 2.384951114654541
Validation loss: 2.0323843084355837

Epoch: 5| Step: 9
Training loss: 1.595172643661499
Validation loss: 2.0369343834538616

Epoch: 5| Step: 10
Training loss: 2.276855945587158
Validation loss: 2.1210742676129906

Epoch: 160| Step: 0
Training loss: 2.366615056991577
Validation loss: 2.065087813203053

Epoch: 5| Step: 1
Training loss: 2.2547996044158936
Validation loss: 2.0721010610621464

Epoch: 5| Step: 2
Training loss: 2.499607801437378
Validation loss: 2.067655131381045

Epoch: 5| Step: 3
Training loss: 1.6791903972625732
Validation loss: 2.046015297212908

Epoch: 5| Step: 4
Training loss: 2.485257387161255
Validation loss: 2.054916630509079

Epoch: 5| Step: 5
Training loss: 1.643609642982483
Validation loss: 2.069766947018203

Epoch: 5| Step: 6
Training loss: 2.5908007621765137
Validation loss: 2.076470869843678

Epoch: 5| Step: 7
Training loss: 1.864148736000061
Validation loss: 2.0690085246998775

Epoch: 5| Step: 8
Training loss: 2.7482776641845703
Validation loss: 2.0285175333740892

Epoch: 5| Step: 9
Training loss: 2.4913716316223145
Validation loss: 2.0781168501864196

Epoch: 5| Step: 10
Training loss: 2.2355964183807373
Validation loss: 2.075944426239178

Epoch: 161| Step: 0
Training loss: 2.784393787384033
Validation loss: 2.06295976074793

Epoch: 5| Step: 1
Training loss: 1.8352845907211304
Validation loss: 2.0867167352348246

Epoch: 5| Step: 2
Training loss: 2.5839812755584717
Validation loss: 2.0472646900402602

Epoch: 5| Step: 3
Training loss: 1.8173000812530518
Validation loss: 2.0203314776061685

Epoch: 5| Step: 4
Training loss: 1.74043869972229
Validation loss: 2.1052375339692637

Epoch: 5| Step: 5
Training loss: 2.5436978340148926
Validation loss: 2.043730669124152

Epoch: 5| Step: 6
Training loss: 1.9771448373794556
Validation loss: 2.048463744501914

Epoch: 5| Step: 7
Training loss: 3.0742263793945312
Validation loss: 2.0406021123291342

Epoch: 5| Step: 8
Training loss: 2.4419779777526855
Validation loss: 2.0360685394656275

Epoch: 5| Step: 9
Training loss: 1.637078046798706
Validation loss: 2.0543084118955877

Epoch: 5| Step: 10
Training loss: 2.3870625495910645
Validation loss: 1.9977426375112226

Epoch: 162| Step: 0
Training loss: 1.6638615131378174
Validation loss: 2.034138810250067

Epoch: 5| Step: 1
Training loss: 2.2415356636047363
Validation loss: 2.053557627944536

Epoch: 5| Step: 2
Training loss: 1.885589599609375
Validation loss: 2.0305818921776226

Epoch: 5| Step: 3
Training loss: 2.3064777851104736
Validation loss: 2.017238465688562

Epoch: 5| Step: 4
Training loss: 2.5561251640319824
Validation loss: 2.033864954466461

Epoch: 5| Step: 5
Training loss: 2.107656955718994
Validation loss: 2.014599529645776

Epoch: 5| Step: 6
Training loss: 2.545208692550659
Validation loss: 2.0892978919449674

Epoch: 5| Step: 7
Training loss: 2.376842737197876
Validation loss: 2.0353846242350917

Epoch: 5| Step: 8
Training loss: 2.3257546424865723
Validation loss: 2.0840075349295013

Epoch: 5| Step: 9
Training loss: 2.371912717819214
Validation loss: 2.064265604942076

Epoch: 5| Step: 10
Training loss: 2.006673812866211
Validation loss: 1.9838472848297448

Epoch: 163| Step: 0
Training loss: 2.2662415504455566
Validation loss: 2.0554889581536733

Epoch: 5| Step: 1
Training loss: 1.5681530237197876
Validation loss: 2.0342055520703717

Epoch: 5| Step: 2
Training loss: 2.5597574710845947
Validation loss: 2.0409083212575605

Epoch: 5| Step: 3
Training loss: 2.962963581085205
Validation loss: 2.083771300572221

Epoch: 5| Step: 4
Training loss: 2.5680785179138184
Validation loss: 2.0731808408614127

Epoch: 5| Step: 5
Training loss: 2.463921070098877
Validation loss: 2.024475484765986

Epoch: 5| Step: 6
Training loss: 1.6696670055389404
Validation loss: 2.0291886355287287

Epoch: 5| Step: 7
Training loss: 2.285933017730713
Validation loss: 1.9963426000328475

Epoch: 5| Step: 8
Training loss: 1.9317328929901123
Validation loss: 2.0540652826268184

Epoch: 5| Step: 9
Training loss: 2.0575063228607178
Validation loss: 2.1136725102701495

Epoch: 5| Step: 10
Training loss: 2.5153403282165527
Validation loss: 2.0180127966788506

Epoch: 164| Step: 0
Training loss: 1.745348572731018
Validation loss: 2.0253654551762406

Epoch: 5| Step: 1
Training loss: 2.4286179542541504
Validation loss: 2.018445248244911

Epoch: 5| Step: 2
Training loss: 2.155632734298706
Validation loss: 2.0588541928158013

Epoch: 5| Step: 3
Training loss: 1.9662721157073975
Validation loss: 2.044764067537041

Epoch: 5| Step: 4
Training loss: 1.9273391962051392
Validation loss: 2.0218884227096394

Epoch: 5| Step: 5
Training loss: 2.126185178756714
Validation loss: 2.023797679972905

Epoch: 5| Step: 6
Training loss: 2.233001232147217
Validation loss: 1.9968276331501622

Epoch: 5| Step: 7
Training loss: 2.5709052085876465
Validation loss: 2.0675961420100224

Epoch: 5| Step: 8
Training loss: 2.301079273223877
Validation loss: 2.075958139152937

Epoch: 5| Step: 9
Training loss: 2.7222933769226074
Validation loss: 2.0457283078983264

Epoch: 5| Step: 10
Training loss: 2.3237974643707275
Validation loss: 2.0404754428453344

Epoch: 165| Step: 0
Training loss: 2.0857958793640137
Validation loss: 2.0255941857573805

Epoch: 5| Step: 1
Training loss: 2.203080892562866
Validation loss: 2.053132621190881

Epoch: 5| Step: 2
Training loss: 2.3282599449157715
Validation loss: 2.06080856374515

Epoch: 5| Step: 3
Training loss: 2.63688325881958
Validation loss: 2.068140491362541

Epoch: 5| Step: 4
Training loss: 1.4708870649337769
Validation loss: 2.042763876658614

Epoch: 5| Step: 5
Training loss: 2.311389207839966
Validation loss: 2.036413046621507

Epoch: 5| Step: 6
Training loss: 2.0112802982330322
Validation loss: 2.0830035376292404

Epoch: 5| Step: 7
Training loss: 2.5725502967834473
Validation loss: 2.060536528146395

Epoch: 5| Step: 8
Training loss: 2.6214096546173096
Validation loss: 2.0091130720671786

Epoch: 5| Step: 9
Training loss: 2.239926815032959
Validation loss: 2.0785915954138643

Epoch: 5| Step: 10
Training loss: 2.463984489440918
Validation loss: 2.080862714398292

Epoch: 166| Step: 0
Training loss: 2.553985595703125
Validation loss: 2.051216456197923

Epoch: 5| Step: 1
Training loss: 2.5751686096191406
Validation loss: 2.011561935947787

Epoch: 5| Step: 2
Training loss: 1.9714984893798828
Validation loss: 1.980137255883986

Epoch: 5| Step: 3
Training loss: 1.933097243309021
Validation loss: 2.056938798196854

Epoch: 5| Step: 4
Training loss: 2.7996907234191895
Validation loss: 2.042790841030818

Epoch: 5| Step: 5
Training loss: 1.6071579456329346
Validation loss: 1.9999181942273212

Epoch: 5| Step: 6
Training loss: 3.136265277862549
Validation loss: 2.0224203371232554

Epoch: 5| Step: 7
Training loss: 1.8883289098739624
Validation loss: 2.0990783963152158

Epoch: 5| Step: 8
Training loss: 2.201761245727539
Validation loss: 2.071783483669322

Epoch: 5| Step: 9
Training loss: 2.2153103351593018
Validation loss: 2.0307968688267533

Epoch: 5| Step: 10
Training loss: 2.021326780319214
Validation loss: 2.0627741595750213

Epoch: 167| Step: 0
Training loss: 1.562167763710022
Validation loss: 2.03460947416162

Epoch: 5| Step: 1
Training loss: 1.3899873495101929
Validation loss: 2.0472752996670303

Epoch: 5| Step: 2
Training loss: 2.3532533645629883
Validation loss: 2.0515108544339418

Epoch: 5| Step: 3
Training loss: 2.5433526039123535
Validation loss: 2.0303604218267624

Epoch: 5| Step: 4
Training loss: 1.9636932611465454
Validation loss: 2.039499848119674

Epoch: 5| Step: 5
Training loss: 2.318275213241577
Validation loss: 2.032516228255405

Epoch: 5| Step: 6
Training loss: 2.7681872844696045
Validation loss: 2.0815885297713743

Epoch: 5| Step: 7
Training loss: 2.8244898319244385
Validation loss: 2.0970961406666744

Epoch: 5| Step: 8
Training loss: 2.324436664581299
Validation loss: 1.97849787435224

Epoch: 5| Step: 9
Training loss: 2.7944998741149902
Validation loss: 2.0611587737196233

Epoch: 5| Step: 10
Training loss: 1.7334438562393188
Validation loss: 2.076663374900818

Epoch: 168| Step: 0
Training loss: 2.2304129600524902
Validation loss: 1.9841841190092024

Epoch: 5| Step: 1
Training loss: 1.895926833152771
Validation loss: 2.0436763289154216

Epoch: 5| Step: 2
Training loss: 2.604226589202881
Validation loss: 2.0480474989901305

Epoch: 5| Step: 3
Training loss: 2.2269906997680664
Validation loss: 2.0249037716978338

Epoch: 5| Step: 4
Training loss: 2.1281442642211914
Validation loss: 2.076103784704721

Epoch: 5| Step: 5
Training loss: 1.8814150094985962
Validation loss: 2.0209409370217273

Epoch: 5| Step: 6
Training loss: 2.3475029468536377
Validation loss: 2.0029143646199215

Epoch: 5| Step: 7
Training loss: 1.8204950094223022
Validation loss: 2.0573750875329457

Epoch: 5| Step: 8
Training loss: 2.263258695602417
Validation loss: 2.0558701689525316

Epoch: 5| Step: 9
Training loss: 2.630439043045044
Validation loss: 2.05150277896594

Epoch: 5| Step: 10
Training loss: 2.4590003490448
Validation loss: 2.0100228555740847

Epoch: 169| Step: 0
Training loss: 1.9502317905426025
Validation loss: 1.9635011675537273

Epoch: 5| Step: 1
Training loss: 2.5193777084350586
Validation loss: 2.048875702324734

Epoch: 5| Step: 2
Training loss: 2.071155548095703
Validation loss: 2.0244071611794094

Epoch: 5| Step: 3
Training loss: 2.90413236618042
Validation loss: 2.0105611649892663

Epoch: 5| Step: 4
Training loss: 3.1360397338867188
Validation loss: 2.085862892930226

Epoch: 5| Step: 5
Training loss: 1.7600669860839844
Validation loss: 2.0276665713197444

Epoch: 5| Step: 6
Training loss: 2.3605329990386963
Validation loss: 2.0486684768430647

Epoch: 5| Step: 7
Training loss: 1.9580974578857422
Validation loss: 2.1068308481606106

Epoch: 5| Step: 8
Training loss: 2.3840298652648926
Validation loss: 2.074897027784778

Epoch: 5| Step: 9
Training loss: 1.786315679550171
Validation loss: 2.0614477562647995

Epoch: 5| Step: 10
Training loss: 1.950134515762329
Validation loss: 2.078118360170754

Epoch: 170| Step: 0
Training loss: 2.4701857566833496
Validation loss: 2.084275181575488

Epoch: 5| Step: 1
Training loss: 2.0459070205688477
Validation loss: 2.153203853996851

Epoch: 5| Step: 2
Training loss: 2.268155574798584
Validation loss: 2.1067491705699632

Epoch: 5| Step: 3
Training loss: 2.5148303508758545
Validation loss: 2.065667739478491

Epoch: 5| Step: 4
Training loss: 1.8321510553359985
Validation loss: 2.0503500494905698

Epoch: 5| Step: 5
Training loss: 1.55484139919281
Validation loss: 2.126881919881349

Epoch: 5| Step: 6
Training loss: 2.3738744258880615
Validation loss: 2.0781101155024704

Epoch: 5| Step: 7
Training loss: 2.1572623252868652
Validation loss: 2.091511834052301

Epoch: 5| Step: 8
Training loss: 2.592423915863037
Validation loss: 2.100845024149905

Epoch: 5| Step: 9
Training loss: 2.584573268890381
Validation loss: 2.0341156810842533

Epoch: 5| Step: 10
Training loss: 1.934649109840393
Validation loss: 2.048156064043763

Epoch: 171| Step: 0
Training loss: 2.279789686203003
Validation loss: 2.0487140763190483

Epoch: 5| Step: 1
Training loss: 1.8152377605438232
Validation loss: 2.0601817202824417

Epoch: 5| Step: 2
Training loss: 2.216200590133667
Validation loss: 2.0847981693924114

Epoch: 5| Step: 3
Training loss: 2.4823126792907715
Validation loss: 2.0400833391374156

Epoch: 5| Step: 4
Training loss: 1.679717779159546
Validation loss: 2.051099158102466

Epoch: 5| Step: 5
Training loss: 2.796107769012451
Validation loss: 2.049120772269464

Epoch: 5| Step: 6
Training loss: 1.615785837173462
Validation loss: 2.0788173688355314

Epoch: 5| Step: 7
Training loss: 2.493884563446045
Validation loss: 2.0850456504411596

Epoch: 5| Step: 8
Training loss: 2.4539270401000977
Validation loss: 2.0839978341133363

Epoch: 5| Step: 9
Training loss: 2.258695602416992
Validation loss: 2.0508149721289195

Epoch: 5| Step: 10
Training loss: 2.5088486671447754
Validation loss: 2.076792296542916

Epoch: 172| Step: 0
Training loss: 2.353677749633789
Validation loss: 2.0598474420526975

Epoch: 5| Step: 1
Training loss: 2.077129364013672
Validation loss: 2.0583702287366314

Epoch: 5| Step: 2
Training loss: 2.644336223602295
Validation loss: 2.064532006940534

Epoch: 5| Step: 3
Training loss: 2.385993242263794
Validation loss: 2.0397058481811197

Epoch: 5| Step: 4
Training loss: 1.9934418201446533
Validation loss: 2.024622295492439

Epoch: 5| Step: 5
Training loss: 2.5325405597686768
Validation loss: 2.0405449303247596

Epoch: 5| Step: 6
Training loss: 1.8532902002334595
Validation loss: 2.045019101071101

Epoch: 5| Step: 7
Training loss: 1.9015569686889648
Validation loss: 1.9881320499604749

Epoch: 5| Step: 8
Training loss: 2.299863576889038
Validation loss: 2.031901042948487

Epoch: 5| Step: 9
Training loss: 2.326552152633667
Validation loss: 2.0478434408864667

Epoch: 5| Step: 10
Training loss: 2.757302761077881
Validation loss: 2.0364045276436755

Epoch: 173| Step: 0
Training loss: 2.2117159366607666
Validation loss: 2.0719008855922247

Epoch: 5| Step: 1
Training loss: 2.1479389667510986
Validation loss: 2.054254872824556

Epoch: 5| Step: 2
Training loss: 2.260568857192993
Validation loss: 2.043426318835187

Epoch: 5| Step: 3
Training loss: 2.0781452655792236
Validation loss: 2.0482022198297645

Epoch: 5| Step: 4
Training loss: 2.1769683361053467
Validation loss: 2.0449560342296476

Epoch: 5| Step: 5
Training loss: 2.460479259490967
Validation loss: 2.0419881625842025

Epoch: 5| Step: 6
Training loss: 2.0999953746795654
Validation loss: 2.030622823264009

Epoch: 5| Step: 7
Training loss: 2.0629897117614746
Validation loss: 2.06151653874305

Epoch: 5| Step: 8
Training loss: 1.863346815109253
Validation loss: 2.0110466710982786

Epoch: 5| Step: 9
Training loss: 2.591153144836426
Validation loss: 2.0113257515814995

Epoch: 5| Step: 10
Training loss: 2.7177724838256836
Validation loss: 2.022569966572587

Epoch: 174| Step: 0
Training loss: 2.0851235389709473
Validation loss: 2.0277474913545834

Epoch: 5| Step: 1
Training loss: 2.885944128036499
Validation loss: 2.079552332560221

Epoch: 5| Step: 2
Training loss: 2.1871895790100098
Validation loss: 2.063135844404979

Epoch: 5| Step: 3
Training loss: 2.632002592086792
Validation loss: 2.060747605498119

Epoch: 5| Step: 4
Training loss: 1.7227205038070679
Validation loss: 2.015327943268643

Epoch: 5| Step: 5
Training loss: 2.2486209869384766
Validation loss: 2.018709526267103

Epoch: 5| Step: 6
Training loss: 2.111480236053467
Validation loss: 2.0164236484035367

Epoch: 5| Step: 7
Training loss: 1.9852359294891357
Validation loss: 2.046984346964026

Epoch: 5| Step: 8
Training loss: 2.1178972721099854
Validation loss: 2.0312616927649385

Epoch: 5| Step: 9
Training loss: 2.385028839111328
Validation loss: 2.0494957098396878

Epoch: 5| Step: 10
Training loss: 1.9774340391159058
Validation loss: 2.0464980627900813

Epoch: 175| Step: 0
Training loss: 2.258721113204956
Validation loss: 2.076574542189157

Epoch: 5| Step: 1
Training loss: 2.1974403858184814
Validation loss: 2.039436951760323

Epoch: 5| Step: 2
Training loss: 1.9902913570404053
Validation loss: 2.0709185702826387

Epoch: 5| Step: 3
Training loss: 2.5302555561065674
Validation loss: 2.0462365496543145

Epoch: 5| Step: 4
Training loss: 2.3033881187438965
Validation loss: 2.0518852382577877

Epoch: 5| Step: 5
Training loss: 1.8326876163482666
Validation loss: 1.9971629842635124

Epoch: 5| Step: 6
Training loss: 2.852186679840088
Validation loss: 1.9867432681463097

Epoch: 5| Step: 7
Training loss: 2.057593822479248
Validation loss: 2.0582928324258454

Epoch: 5| Step: 8
Training loss: 2.1503424644470215
Validation loss: 2.0471136608431415

Epoch: 5| Step: 9
Training loss: 2.5722832679748535
Validation loss: 2.0491693917141167

Epoch: 5| Step: 10
Training loss: 1.980814814567566
Validation loss: 2.0579619587108655

Epoch: 176| Step: 0
Training loss: 2.106166362762451
Validation loss: 2.022687347986365

Epoch: 5| Step: 1
Training loss: 2.256009817123413
Validation loss: 2.0663527237471713

Epoch: 5| Step: 2
Training loss: 1.845381498336792
Validation loss: 2.045674688072615

Epoch: 5| Step: 3
Training loss: 1.579612135887146
Validation loss: 1.9905922284690283

Epoch: 5| Step: 4
Training loss: 2.642468214035034
Validation loss: 2.0043213034188874

Epoch: 5| Step: 5
Training loss: 2.484868288040161
Validation loss: 2.027043814300209

Epoch: 5| Step: 6
Training loss: 1.9549858570098877
Validation loss: 1.9983284704146846

Epoch: 5| Step: 7
Training loss: 2.125030040740967
Validation loss: 2.0108076218635804

Epoch: 5| Step: 8
Training loss: 2.1876883506774902
Validation loss: 2.002752524550243

Epoch: 5| Step: 9
Training loss: 2.112234115600586
Validation loss: 2.0251162513609855

Epoch: 5| Step: 10
Training loss: 2.9162778854370117
Validation loss: 2.0183630553624963

Epoch: 177| Step: 0
Training loss: 2.1672115325927734
Validation loss: 1.9697768072928152

Epoch: 5| Step: 1
Training loss: 2.167754888534546
Validation loss: 2.0579307874043784

Epoch: 5| Step: 2
Training loss: 2.37166690826416
Validation loss: 2.009262507961642

Epoch: 5| Step: 3
Training loss: 2.7880942821502686
Validation loss: 2.0384383073417087

Epoch: 5| Step: 4
Training loss: 2.548395872116089
Validation loss: 2.068686200726417

Epoch: 5| Step: 5
Training loss: 2.2691750526428223
Validation loss: 2.0109626618764733

Epoch: 5| Step: 6
Training loss: 1.7242431640625
Validation loss: 2.0098513698065155

Epoch: 5| Step: 7
Training loss: 2.3274025917053223
Validation loss: 2.020492075591959

Epoch: 5| Step: 8
Training loss: 2.4318511486053467
Validation loss: 2.067155622666882

Epoch: 5| Step: 9
Training loss: 1.8984348773956299
Validation loss: 2.011019963090138

Epoch: 5| Step: 10
Training loss: 1.8067784309387207
Validation loss: 2.0314192707820604

Epoch: 178| Step: 0
Training loss: 1.9233179092407227
Validation loss: 2.013932346015848

Epoch: 5| Step: 1
Training loss: 2.1484577655792236
Validation loss: 2.013662279293101

Epoch: 5| Step: 2
Training loss: 1.8498293161392212
Validation loss: 2.064854298868487

Epoch: 5| Step: 3
Training loss: 2.840956211090088
Validation loss: 2.0519387863015615

Epoch: 5| Step: 4
Training loss: 2.6064224243164062
Validation loss: 2.0209815861076437

Epoch: 5| Step: 5
Training loss: 2.3707334995269775
Validation loss: 2.0362341570597824

Epoch: 5| Step: 6
Training loss: 2.2424495220184326
Validation loss: 2.0680711115560224

Epoch: 5| Step: 7
Training loss: 2.4200022220611572
Validation loss: 2.007744471232096

Epoch: 5| Step: 8
Training loss: 1.8998277187347412
Validation loss: 2.0047838149532193

Epoch: 5| Step: 9
Training loss: 2.3112034797668457
Validation loss: 2.002707883875857

Epoch: 5| Step: 10
Training loss: 1.9699664115905762
Validation loss: 2.103343863641062

Epoch: 179| Step: 0
Training loss: 1.8619025945663452
Validation loss: 2.0799325794302006

Epoch: 5| Step: 1
Training loss: 2.2468771934509277
Validation loss: 2.0447308119907173

Epoch: 5| Step: 2
Training loss: 2.9329943656921387
Validation loss: 2.02715640939692

Epoch: 5| Step: 3
Training loss: 3.184843063354492
Validation loss: 2.0355123499388337

Epoch: 5| Step: 4
Training loss: 2.023430585861206
Validation loss: 2.035562553713399

Epoch: 5| Step: 5
Training loss: 2.277211904525757
Validation loss: 2.092190768129082

Epoch: 5| Step: 6
Training loss: 1.8949016332626343
Validation loss: 2.048120411493445

Epoch: 5| Step: 7
Training loss: 2.251300573348999
Validation loss: 2.0348329877340667

Epoch: 5| Step: 8
Training loss: 2.5267491340637207
Validation loss: 2.0712485415961153

Epoch: 5| Step: 9
Training loss: 1.6989986896514893
Validation loss: 2.044999889148179

Epoch: 5| Step: 10
Training loss: 1.6989235877990723
Validation loss: 2.021353926709903

Epoch: 180| Step: 0
Training loss: 2.3922605514526367
Validation loss: 2.0813948646668465

Epoch: 5| Step: 1
Training loss: 2.539745807647705
Validation loss: 1.999376004742038

Epoch: 5| Step: 2
Training loss: 2.345414876937866
Validation loss: 2.0250465639175905

Epoch: 5| Step: 3
Training loss: 2.5095951557159424
Validation loss: 2.075667932469358

Epoch: 5| Step: 4
Training loss: 2.0771610736846924
Validation loss: 2.0596428584027033

Epoch: 5| Step: 5
Training loss: 2.20863938331604
Validation loss: 2.079241753906332

Epoch: 5| Step: 6
Training loss: 2.314671754837036
Validation loss: 2.0259022251252206

Epoch: 5| Step: 7
Training loss: 1.5987884998321533
Validation loss: 2.1047544017914803

Epoch: 5| Step: 8
Training loss: 1.5963867902755737
Validation loss: 2.040817663233767

Epoch: 5| Step: 9
Training loss: 2.653982162475586
Validation loss: 2.061825430521401

Epoch: 5| Step: 10
Training loss: 2.38151478767395
Validation loss: 2.0651481407944874

Epoch: 181| Step: 0
Training loss: 1.666107177734375
Validation loss: 1.9963852487584597

Epoch: 5| Step: 1
Training loss: 2.3056325912475586
Validation loss: 2.040136132189023

Epoch: 5| Step: 2
Training loss: 2.0451388359069824
Validation loss: 2.018211426273469

Epoch: 5| Step: 3
Training loss: 2.585416078567505
Validation loss: 2.0311260031115626

Epoch: 5| Step: 4
Training loss: 1.7750885486602783
Validation loss: 1.999417487011161

Epoch: 5| Step: 5
Training loss: 2.277085304260254
Validation loss: 2.020511117032779

Epoch: 5| Step: 6
Training loss: 2.832854986190796
Validation loss: 2.040307516692787

Epoch: 5| Step: 7
Training loss: 2.1628987789154053
Validation loss: 2.0836461333818335

Epoch: 5| Step: 8
Training loss: 2.000216245651245
Validation loss: 2.056062859873618

Epoch: 5| Step: 9
Training loss: 2.2813076972961426
Validation loss: 2.033801326187708

Epoch: 5| Step: 10
Training loss: 2.5635416507720947
Validation loss: 2.0629418511544504

Epoch: 182| Step: 0
Training loss: 2.4490435123443604
Validation loss: 1.959448875919465

Epoch: 5| Step: 1
Training loss: 2.7647757530212402
Validation loss: 2.052708206638213

Epoch: 5| Step: 2
Training loss: 1.951951026916504
Validation loss: 2.059117414618051

Epoch: 5| Step: 3
Training loss: 1.725104570388794
Validation loss: 2.031541775631648

Epoch: 5| Step: 4
Training loss: 2.980449676513672
Validation loss: 2.0572105940952095

Epoch: 5| Step: 5
Training loss: 2.5595455169677734
Validation loss: 2.040198064619495

Epoch: 5| Step: 6
Training loss: 2.2127699851989746
Validation loss: 2.0097137087134906

Epoch: 5| Step: 7
Training loss: 2.362722635269165
Validation loss: 2.0603991810993483

Epoch: 5| Step: 8
Training loss: 1.7545948028564453
Validation loss: 2.038025653490456

Epoch: 5| Step: 9
Training loss: 2.0332417488098145
Validation loss: 2.050239009241904

Epoch: 5| Step: 10
Training loss: 1.6933908462524414
Validation loss: 2.0313279154480144

Epoch: 183| Step: 0
Training loss: 1.9062055349349976
Validation loss: 2.0415276814532537

Epoch: 5| Step: 1
Training loss: 2.3488879203796387
Validation loss: 2.0541463949347056

Epoch: 5| Step: 2
Training loss: 2.0286951065063477
Validation loss: 1.9971774752422045

Epoch: 5| Step: 3
Training loss: 1.905839204788208
Validation loss: 1.9742825826009114

Epoch: 5| Step: 4
Training loss: 2.363245725631714
Validation loss: 2.012256032677107

Epoch: 5| Step: 5
Training loss: 2.5830349922180176
Validation loss: 2.063099640671925

Epoch: 5| Step: 6
Training loss: 1.9878028631210327
Validation loss: 1.9838436444600422

Epoch: 5| Step: 7
Training loss: 2.32350492477417
Validation loss: 2.0496920847123667

Epoch: 5| Step: 8
Training loss: 2.0042786598205566
Validation loss: 1.9801106811851583

Epoch: 5| Step: 9
Training loss: 2.099792003631592
Validation loss: 2.022982871660622

Epoch: 5| Step: 10
Training loss: 3.2812421321868896
Validation loss: 2.03566563001243

Epoch: 184| Step: 0
Training loss: 1.8962091207504272
Validation loss: 2.0258489193454867

Epoch: 5| Step: 1
Training loss: 2.7966723442077637
Validation loss: 2.046562535788423

Epoch: 5| Step: 2
Training loss: 1.9127724170684814
Validation loss: 2.0452932747461463

Epoch: 5| Step: 3
Training loss: 1.7393461465835571
Validation loss: 2.012518172623009

Epoch: 5| Step: 4
Training loss: 2.5481977462768555
Validation loss: 2.068580606932281

Epoch: 5| Step: 5
Training loss: 1.8504215478897095
Validation loss: 2.018174291938864

Epoch: 5| Step: 6
Training loss: 2.002532958984375
Validation loss: 2.0762210789547173

Epoch: 5| Step: 7
Training loss: 2.5792319774627686
Validation loss: 2.029025270092872

Epoch: 5| Step: 8
Training loss: 2.7033603191375732
Validation loss: 2.017061648830291

Epoch: 5| Step: 9
Training loss: 2.5011556148529053
Validation loss: 2.1008194672164096

Epoch: 5| Step: 10
Training loss: 1.695410966873169
Validation loss: 2.0969670844334427

Epoch: 185| Step: 0
Training loss: 1.7025541067123413
Validation loss: 2.0860061978781097

Epoch: 5| Step: 1
Training loss: 2.2538986206054688
Validation loss: 2.0943531246595484

Epoch: 5| Step: 2
Training loss: 2.3401379585266113
Validation loss: 2.0675075682260657

Epoch: 5| Step: 3
Training loss: 2.0162036418914795
Validation loss: 2.0404868049006306

Epoch: 5| Step: 4
Training loss: 1.6931737661361694
Validation loss: 2.075912347403906

Epoch: 5| Step: 5
Training loss: 2.400484085083008
Validation loss: 2.055053537891757

Epoch: 5| Step: 6
Training loss: 2.144592523574829
Validation loss: 2.0311196619464504

Epoch: 5| Step: 7
Training loss: 2.5769577026367188
Validation loss: 2.0697553875625774

Epoch: 5| Step: 8
Training loss: 2.4362950325012207
Validation loss: 2.098772116886672

Epoch: 5| Step: 9
Training loss: 2.5972933769226074
Validation loss: 2.1027246059909945

Epoch: 5| Step: 10
Training loss: 2.574373245239258
Validation loss: 2.141945982492098

Epoch: 186| Step: 0
Training loss: 1.8676536083221436
Validation loss: 2.07982732916391

Epoch: 5| Step: 1
Training loss: 2.1149306297302246
Validation loss: 2.1125328386983564

Epoch: 5| Step: 2
Training loss: 1.6764812469482422
Validation loss: 2.14466437473092

Epoch: 5| Step: 3
Training loss: 3.064584732055664
Validation loss: 2.14489834795716

Epoch: 5| Step: 4
Training loss: 1.3812596797943115
Validation loss: 2.046286318891792

Epoch: 5| Step: 5
Training loss: 2.469325304031372
Validation loss: 2.05280795661352

Epoch: 5| Step: 6
Training loss: 2.1509549617767334
Validation loss: 2.104289061279707

Epoch: 5| Step: 7
Training loss: 2.3593039512634277
Validation loss: 2.076036382746953

Epoch: 5| Step: 8
Training loss: 2.483586072921753
Validation loss: 2.1224148517013877

Epoch: 5| Step: 9
Training loss: 2.2881226539611816
Validation loss: 2.1536280647400887

Epoch: 5| Step: 10
Training loss: 2.7473466396331787
Validation loss: 2.077845909262216

Epoch: 187| Step: 0
Training loss: 2.6289353370666504
Validation loss: 2.073997607795141

Epoch: 5| Step: 1
Training loss: 1.986241102218628
Validation loss: 2.0838993313491985

Epoch: 5| Step: 2
Training loss: 1.6272627115249634
Validation loss: 2.11106304712193

Epoch: 5| Step: 3
Training loss: 2.1014034748077393
Validation loss: 2.099165544714979

Epoch: 5| Step: 4
Training loss: 2.268848180770874
Validation loss: 2.099263539878271

Epoch: 5| Step: 5
Training loss: 2.492525815963745
Validation loss: 2.114362862802321

Epoch: 5| Step: 6
Training loss: 2.2138001918792725
Validation loss: 2.1010208975884224

Epoch: 5| Step: 7
Training loss: 1.905517578125
Validation loss: 2.097272483251428

Epoch: 5| Step: 8
Training loss: 2.7153797149658203
Validation loss: 2.0953461098414596

Epoch: 5| Step: 9
Training loss: 2.1526660919189453
Validation loss: 2.1385946145621677

Epoch: 5| Step: 10
Training loss: 2.5008533000946045
Validation loss: 2.073634724463186

Epoch: 188| Step: 0
Training loss: 1.7861770391464233
Validation loss: 2.1093092503086215

Epoch: 5| Step: 1
Training loss: 2.034548282623291
Validation loss: 2.0676263788694977

Epoch: 5| Step: 2
Training loss: 2.6216843128204346
Validation loss: 1.984858505187496

Epoch: 5| Step: 3
Training loss: 2.0443451404571533
Validation loss: 2.043679324529504

Epoch: 5| Step: 4
Training loss: 1.7917331457138062
Validation loss: 1.9964754004632272

Epoch: 5| Step: 5
Training loss: 2.597034215927124
Validation loss: 2.042216034345729

Epoch: 5| Step: 6
Training loss: 2.2213852405548096
Validation loss: 2.0649482370704733

Epoch: 5| Step: 7
Training loss: 1.7755184173583984
Validation loss: 2.0600388485898256

Epoch: 5| Step: 8
Training loss: 2.3274099826812744
Validation loss: 2.0603637272311794

Epoch: 5| Step: 9
Training loss: 2.726863384246826
Validation loss: 2.119682688866892

Epoch: 5| Step: 10
Training loss: 2.8833043575286865
Validation loss: 2.0776581097674627

Epoch: 189| Step: 0
Training loss: 2.411101818084717
Validation loss: 2.0819758125530776

Epoch: 5| Step: 1
Training loss: 2.51983904838562
Validation loss: 2.0033832262921076

Epoch: 5| Step: 2
Training loss: 2.2520594596862793
Validation loss: 2.0612966937403523

Epoch: 5| Step: 3
Training loss: 2.063687562942505
Validation loss: 2.0701896682862313

Epoch: 5| Step: 4
Training loss: 1.6075445413589478
Validation loss: 2.0571241327511367

Epoch: 5| Step: 5
Training loss: 1.9209604263305664
Validation loss: 2.01993437351719

Epoch: 5| Step: 6
Training loss: 1.5724871158599854
Validation loss: 2.0487970895664667

Epoch: 5| Step: 7
Training loss: 2.728945016860962
Validation loss: 2.064210089304114

Epoch: 5| Step: 8
Training loss: 2.686361789703369
Validation loss: 2.0562710185204782

Epoch: 5| Step: 9
Training loss: 2.4327967166900635
Validation loss: 2.0239609954177693

Epoch: 5| Step: 10
Training loss: 2.2490906715393066
Validation loss: 2.0857294221078195

Epoch: 190| Step: 0
Training loss: 1.4970353841781616
Validation loss: 2.0075995998997844

Epoch: 5| Step: 1
Training loss: 2.1243996620178223
Validation loss: 2.02730014119097

Epoch: 5| Step: 2
Training loss: 1.9846088886260986
Validation loss: 2.0450687177719606

Epoch: 5| Step: 3
Training loss: 2.307454824447632
Validation loss: 2.0405689772739204

Epoch: 5| Step: 4
Training loss: 3.102815628051758
Validation loss: 1.9898632623816048

Epoch: 5| Step: 5
Training loss: 1.789071798324585
Validation loss: 2.0394368979238693

Epoch: 5| Step: 6
Training loss: 2.2534148693084717
Validation loss: 2.0993621503153155

Epoch: 5| Step: 7
Training loss: 1.680373191833496
Validation loss: 2.007650997049065

Epoch: 5| Step: 8
Training loss: 1.9597952365875244
Validation loss: 2.0176697161889847

Epoch: 5| Step: 9
Training loss: 2.28151273727417
Validation loss: 2.0425093866163686

Epoch: 5| Step: 10
Training loss: 3.314908504486084
Validation loss: 2.061711859959428

Epoch: 191| Step: 0
Training loss: 2.6044914722442627
Validation loss: 2.032106404663414

Epoch: 5| Step: 1
Training loss: 2.4754505157470703
Validation loss: 1.965497254043497

Epoch: 5| Step: 2
Training loss: 1.846215009689331
Validation loss: 2.0461706628081617

Epoch: 5| Step: 3
Training loss: 2.0677599906921387
Validation loss: 2.0205267629315777

Epoch: 5| Step: 4
Training loss: 2.6044487953186035
Validation loss: 2.022544296838904

Epoch: 5| Step: 5
Training loss: 2.263920783996582
Validation loss: 2.0749240972662486

Epoch: 5| Step: 6
Training loss: 2.24409818649292
Validation loss: 2.0210440851026967

Epoch: 5| Step: 7
Training loss: 2.840933322906494
Validation loss: 2.038790302891885

Epoch: 5| Step: 8
Training loss: 1.9652340412139893
Validation loss: 1.989807423724923

Epoch: 5| Step: 9
Training loss: 1.4910589456558228
Validation loss: 2.0815275125606085

Epoch: 5| Step: 10
Training loss: 2.074164867401123
Validation loss: 1.9890482220598447

Epoch: 192| Step: 0
Training loss: 1.9823188781738281
Validation loss: 2.087793387392516

Epoch: 5| Step: 1
Training loss: 2.2553153038024902
Validation loss: 2.0249511093221684

Epoch: 5| Step: 2
Training loss: 2.2845513820648193
Validation loss: 2.103972996434858

Epoch: 5| Step: 3
Training loss: 2.0393128395080566
Validation loss: 2.0668842664328952

Epoch: 5| Step: 4
Training loss: 1.7956863641738892
Validation loss: 2.078110101402447

Epoch: 5| Step: 5
Training loss: 2.1892483234405518
Validation loss: 2.041075920545927

Epoch: 5| Step: 6
Training loss: 2.0962517261505127
Validation loss: 2.0398008797758367

Epoch: 5| Step: 7
Training loss: 2.5333943367004395
Validation loss: 2.0599605473138953

Epoch: 5| Step: 8
Training loss: 2.009577989578247
Validation loss: 2.039320663739276

Epoch: 5| Step: 9
Training loss: 2.812986135482788
Validation loss: 2.016611986262824

Epoch: 5| Step: 10
Training loss: 2.0006988048553467
Validation loss: 2.0157576043118715

Epoch: 193| Step: 0
Training loss: 2.2023088932037354
Validation loss: 2.0534621836036764

Epoch: 5| Step: 1
Training loss: 2.056767702102661
Validation loss: 1.992801740605344

Epoch: 5| Step: 2
Training loss: 1.7546882629394531
Validation loss: 2.0120918891763173

Epoch: 5| Step: 3
Training loss: 2.4699602127075195
Validation loss: 2.029788799183343

Epoch: 5| Step: 4
Training loss: 1.9485410451889038
Validation loss: 2.0125390868033133

Epoch: 5| Step: 5
Training loss: 2.176877021789551
Validation loss: 2.0207214176013903

Epoch: 5| Step: 6
Training loss: 2.642442226409912
Validation loss: 2.0348867652236775

Epoch: 5| Step: 7
Training loss: 2.1281371116638184
Validation loss: 2.0137714750023297

Epoch: 5| Step: 8
Training loss: 2.770646810531616
Validation loss: 2.043568818799911

Epoch: 5| Step: 9
Training loss: 2.2432093620300293
Validation loss: 1.9947473836201493

Epoch: 5| Step: 10
Training loss: 2.372370958328247
Validation loss: 2.026534726542811

Epoch: 194| Step: 0
Training loss: 2.2078022956848145
Validation loss: 2.0827493693238948

Epoch: 5| Step: 1
Training loss: 2.46389102935791
Validation loss: 2.036778567939676

Epoch: 5| Step: 2
Training loss: 1.8271772861480713
Validation loss: 2.064180358763664

Epoch: 5| Step: 3
Training loss: 1.6096588373184204
Validation loss: 2.069802015058456

Epoch: 5| Step: 4
Training loss: 2.450516939163208
Validation loss: 2.0543711031636884

Epoch: 5| Step: 5
Training loss: 2.363800048828125
Validation loss: 2.02739058515077

Epoch: 5| Step: 6
Training loss: 1.98065185546875
Validation loss: 2.0188000150906142

Epoch: 5| Step: 7
Training loss: 2.247450828552246
Validation loss: 2.055487025168634

Epoch: 5| Step: 8
Training loss: 2.8699238300323486
Validation loss: 2.0028523450256674

Epoch: 5| Step: 9
Training loss: 1.908652901649475
Validation loss: 2.038387155020109

Epoch: 5| Step: 10
Training loss: 2.205684185028076
Validation loss: 2.031996967971966

Epoch: 195| Step: 0
Training loss: 2.0822808742523193
Validation loss: 1.9950664248517764

Epoch: 5| Step: 1
Training loss: 2.1128878593444824
Validation loss: 2.0498039491714968

Epoch: 5| Step: 2
Training loss: 2.085310459136963
Validation loss: 2.037303509250764

Epoch: 5| Step: 3
Training loss: 2.370396614074707
Validation loss: 2.081824723110404

Epoch: 5| Step: 4
Training loss: 2.575355052947998
Validation loss: 2.09254821654289

Epoch: 5| Step: 5
Training loss: 1.9553768634796143
Validation loss: 2.0789011934752106

Epoch: 5| Step: 6
Training loss: 2.863877534866333
Validation loss: 2.094955407163148

Epoch: 5| Step: 7
Training loss: 2.1644246578216553
Validation loss: 2.0422592598904847

Epoch: 5| Step: 8
Training loss: 1.9795974493026733
Validation loss: 2.0694747048039592

Epoch: 5| Step: 9
Training loss: 2.143556833267212
Validation loss: 2.0924559639346216

Epoch: 5| Step: 10
Training loss: 1.8572568893432617
Validation loss: 2.083656677635767

Epoch: 196| Step: 0
Training loss: 1.5204479694366455
Validation loss: 2.075158267892817

Epoch: 5| Step: 1
Training loss: 2.1527624130249023
Validation loss: 2.077360881272183

Epoch: 5| Step: 2
Training loss: 1.921055555343628
Validation loss: 2.0841418748260825

Epoch: 5| Step: 3
Training loss: 2.6531853675842285
Validation loss: 2.1078167576943674

Epoch: 5| Step: 4
Training loss: 1.895311951637268
Validation loss: 2.101055270882063

Epoch: 5| Step: 5
Training loss: 2.742567777633667
Validation loss: 2.112681137618198

Epoch: 5| Step: 6
Training loss: 2.8268470764160156
Validation loss: 2.0592746401345856

Epoch: 5| Step: 7
Training loss: 1.7327522039413452
Validation loss: 2.0383706297925723

Epoch: 5| Step: 8
Training loss: 2.088939905166626
Validation loss: 2.00024458541665

Epoch: 5| Step: 9
Training loss: 2.6668715476989746
Validation loss: 2.0895709735091015

Epoch: 5| Step: 10
Training loss: 2.06355619430542
Validation loss: 2.053656975428263

Epoch: 197| Step: 0
Training loss: 1.9548776149749756
Validation loss: 2.0811196706628285

Epoch: 5| Step: 1
Training loss: 2.1931538581848145
Validation loss: 2.0561617369292886

Epoch: 5| Step: 2
Training loss: 2.1940066814422607
Validation loss: 2.066719975522769

Epoch: 5| Step: 3
Training loss: 2.622347831726074
Validation loss: 1.9958504207672612

Epoch: 5| Step: 4
Training loss: 2.62296724319458
Validation loss: 2.0509610124813613

Epoch: 5| Step: 5
Training loss: 2.841404438018799
Validation loss: 2.0486868991646716

Epoch: 5| Step: 6
Training loss: 2.3247551918029785
Validation loss: 2.006546160226227

Epoch: 5| Step: 7
Training loss: 2.007550001144409
Validation loss: 2.0521000521157378

Epoch: 5| Step: 8
Training loss: 1.8456757068634033
Validation loss: 1.9945172904640116

Epoch: 5| Step: 9
Training loss: 1.834302306175232
Validation loss: 2.065820353005522

Epoch: 5| Step: 10
Training loss: 2.360943078994751
Validation loss: 2.02609666444922

Epoch: 198| Step: 0
Training loss: 1.5550603866577148
Validation loss: 2.0051186674384662

Epoch: 5| Step: 1
Training loss: 2.817692995071411
Validation loss: 2.0408637049377605

Epoch: 5| Step: 2
Training loss: 2.2407217025756836
Validation loss: 2.0361693341244935

Epoch: 5| Step: 3
Training loss: 2.782891035079956
Validation loss: 2.011073056087699

Epoch: 5| Step: 4
Training loss: 2.0689916610717773
Validation loss: 2.0318454260467202

Epoch: 5| Step: 5
Training loss: 2.041855573654175
Validation loss: 2.026776703455115

Epoch: 5| Step: 6
Training loss: 2.581578493118286
Validation loss: 2.1101346810658774

Epoch: 5| Step: 7
Training loss: 2.1735098361968994
Validation loss: 2.0569272912958616

Epoch: 5| Step: 8
Training loss: 2.3869285583496094
Validation loss: 2.016268203335424

Epoch: 5| Step: 9
Training loss: 1.648611307144165
Validation loss: 2.035935189134331

Epoch: 5| Step: 10
Training loss: 2.4251835346221924
Validation loss: 2.0180621967520764

Epoch: 199| Step: 0
Training loss: 2.192350387573242
Validation loss: 2.0736212012588338

Epoch: 5| Step: 1
Training loss: 2.4010074138641357
Validation loss: 2.022797241005846

Epoch: 5| Step: 2
Training loss: 1.8388264179229736
Validation loss: 2.016739494057112

Epoch: 5| Step: 3
Training loss: 2.3007359504699707
Validation loss: 2.0131027544698408

Epoch: 5| Step: 4
Training loss: 2.839446544647217
Validation loss: 2.0734243803126837

Epoch: 5| Step: 5
Training loss: 2.0199830532073975
Validation loss: 2.0634309963513444

Epoch: 5| Step: 6
Training loss: 2.3584401607513428
Validation loss: 2.051586176759453

Epoch: 5| Step: 7
Training loss: 2.033477306365967
Validation loss: 2.043525277927358

Epoch: 5| Step: 8
Training loss: 2.205315113067627
Validation loss: 2.0822050622714463

Epoch: 5| Step: 9
Training loss: 2.1433796882629395
Validation loss: 2.00705490701942

Epoch: 5| Step: 10
Training loss: 1.4703154563903809
Validation loss: 2.010072218474521

Epoch: 200| Step: 0
Training loss: 2.5086402893066406
Validation loss: 2.03760935542404

Epoch: 5| Step: 1
Training loss: 2.763895034790039
Validation loss: 2.0563248665102067

Epoch: 5| Step: 2
Training loss: 2.5627553462982178
Validation loss: 2.04003539008479

Epoch: 5| Step: 3
Training loss: 1.8296810388565063
Validation loss: 2.0131456877595637

Epoch: 5| Step: 4
Training loss: 2.376507520675659
Validation loss: 2.0411867633942635

Epoch: 5| Step: 5
Training loss: 2.139871597290039
Validation loss: 2.0528963970881637

Epoch: 5| Step: 6
Training loss: 1.7782024145126343
Validation loss: 2.0956831593667307

Epoch: 5| Step: 7
Training loss: 1.5215376615524292
Validation loss: 2.059558524880358

Epoch: 5| Step: 8
Training loss: 2.8713362216949463
Validation loss: 2.0474965072447255

Epoch: 5| Step: 9
Training loss: 1.9589145183563232
Validation loss: 2.071125840628019

Epoch: 5| Step: 10
Training loss: 1.7077958583831787
Validation loss: 1.990648300417008

Epoch: 201| Step: 0
Training loss: 1.4607511758804321
Validation loss: 2.0041233903618267

Epoch: 5| Step: 1
Training loss: 2.3644680976867676
Validation loss: 2.0637161590719737

Epoch: 5| Step: 2
Training loss: 2.8769407272338867
Validation loss: 2.0058442200383833

Epoch: 5| Step: 3
Training loss: 2.247004985809326
Validation loss: 2.070646112964999

Epoch: 5| Step: 4
Training loss: 2.1857426166534424
Validation loss: 2.0768798115432903

Epoch: 5| Step: 5
Training loss: 1.869150161743164
Validation loss: 2.007985770061452

Epoch: 5| Step: 6
Training loss: 1.7413339614868164
Validation loss: 1.9654945724753923

Epoch: 5| Step: 7
Training loss: 2.947230577468872
Validation loss: 2.013106228202902

Epoch: 5| Step: 8
Training loss: 2.5017685890197754
Validation loss: 2.044251880338115

Epoch: 5| Step: 9
Training loss: 2.02620267868042
Validation loss: 2.072881278171334

Epoch: 5| Step: 10
Training loss: 1.8292546272277832
Validation loss: 2.015278266322228

Epoch: 202| Step: 0
Training loss: 1.6973543167114258
Validation loss: 2.122857086120113

Epoch: 5| Step: 1
Training loss: 2.2796199321746826
Validation loss: 2.072841280250139

Epoch: 5| Step: 2
Training loss: 2.601228713989258
Validation loss: 2.0501235838859313

Epoch: 5| Step: 3
Training loss: 2.2277560234069824
Validation loss: 2.0460447265255834

Epoch: 5| Step: 4
Training loss: 2.178861141204834
Validation loss: 2.0413043447720107

Epoch: 5| Step: 5
Training loss: 2.5431809425354004
Validation loss: 2.0410708586374917

Epoch: 5| Step: 6
Training loss: 2.5063514709472656
Validation loss: 2.034636652597817

Epoch: 5| Step: 7
Training loss: 1.866784691810608
Validation loss: 2.0531698952439013

Epoch: 5| Step: 8
Training loss: 2.0143942832946777
Validation loss: 2.0757641869206584

Epoch: 5| Step: 9
Training loss: 2.267378330230713
Validation loss: 2.035250468920636

Epoch: 5| Step: 10
Training loss: 2.1068613529205322
Validation loss: 2.0481172479609007

Epoch: 203| Step: 0
Training loss: 2.2281858921051025
Validation loss: 2.038352832999281

Epoch: 5| Step: 1
Training loss: 1.916979193687439
Validation loss: 2.0612286393360426

Epoch: 5| Step: 2
Training loss: 2.6991047859191895
Validation loss: 2.018043336047921

Epoch: 5| Step: 3
Training loss: 1.974599838256836
Validation loss: 2.0810828144832323

Epoch: 5| Step: 4
Training loss: 1.8514617681503296
Validation loss: 2.0822724244927846

Epoch: 5| Step: 5
Training loss: 2.285116672515869
Validation loss: 2.005602740472363

Epoch: 5| Step: 6
Training loss: 2.6529343128204346
Validation loss: 2.042577697384742

Epoch: 5| Step: 7
Training loss: 1.8755441904067993
Validation loss: 2.05231725528676

Epoch: 5| Step: 8
Training loss: 2.744626522064209
Validation loss: 2.131790214969266

Epoch: 5| Step: 9
Training loss: 1.4389091730117798
Validation loss: 2.0688913073591007

Epoch: 5| Step: 10
Training loss: 2.2716829776763916
Validation loss: 2.0385685479769142

Epoch: 204| Step: 0
Training loss: 1.4886115789413452
Validation loss: 2.0652150607878164

Epoch: 5| Step: 1
Training loss: 1.8904441595077515
Validation loss: 2.0729554263494347

Epoch: 5| Step: 2
Training loss: 1.977355718612671
Validation loss: 2.0724221275698755

Epoch: 5| Step: 3
Training loss: 2.591221809387207
Validation loss: 2.032831458635228

Epoch: 5| Step: 4
Training loss: 2.5372703075408936
Validation loss: 2.0919387699455343

Epoch: 5| Step: 5
Training loss: 2.994227886199951
Validation loss: 2.0789799459518923

Epoch: 5| Step: 6
Training loss: 2.244795083999634
Validation loss: 2.0825031406135968

Epoch: 5| Step: 7
Training loss: 2.1469037532806396
Validation loss: 2.0699139461722424

Epoch: 5| Step: 8
Training loss: 2.142225980758667
Validation loss: 2.0403334979088075

Epoch: 5| Step: 9
Training loss: 2.2283518314361572
Validation loss: 2.12214607192624

Epoch: 5| Step: 10
Training loss: 2.004342555999756
Validation loss: 2.084663329585906

Epoch: 205| Step: 0
Training loss: 1.6837942600250244
Validation loss: 2.04969044398236

Epoch: 5| Step: 1
Training loss: 3.0720410346984863
Validation loss: 2.006372180036319

Epoch: 5| Step: 2
Training loss: 2.571753978729248
Validation loss: 2.0596435813493628

Epoch: 5| Step: 3
Training loss: 2.186993360519409
Validation loss: 2.053743700827322

Epoch: 5| Step: 4
Training loss: 1.979189157485962
Validation loss: 2.0305484097491027

Epoch: 5| Step: 5
Training loss: 1.8423058986663818
Validation loss: 2.0470926184808054

Epoch: 5| Step: 6
Training loss: 2.0588669776916504
Validation loss: 2.054256772482267

Epoch: 5| Step: 7
Training loss: 2.3080508708953857
Validation loss: 2.0668310580715055

Epoch: 5| Step: 8
Training loss: 1.9697520732879639
Validation loss: 2.0826036032810005

Epoch: 5| Step: 9
Training loss: 2.0600202083587646
Validation loss: 2.082122516888444

Epoch: 5| Step: 10
Training loss: 2.7191667556762695
Validation loss: 2.0807805138249553

Epoch: 206| Step: 0
Training loss: 1.970529317855835
Validation loss: 2.0353683015351653

Epoch: 5| Step: 1
Training loss: 1.8723148107528687
Validation loss: 2.043579484826775

Epoch: 5| Step: 2
Training loss: 2.4788146018981934
Validation loss: 2.015003317145891

Epoch: 5| Step: 3
Training loss: 2.2013204097747803
Validation loss: 2.008446808784239

Epoch: 5| Step: 4
Training loss: 2.2006866931915283
Validation loss: 2.075672536767939

Epoch: 5| Step: 5
Training loss: 2.2463645935058594
Validation loss: 2.0907475640696864

Epoch: 5| Step: 6
Training loss: 2.1901357173919678
Validation loss: 2.0333964465766825

Epoch: 5| Step: 7
Training loss: 1.830185890197754
Validation loss: 2.0191976126804145

Epoch: 5| Step: 8
Training loss: 1.7676273584365845
Validation loss: 2.053654691224457

Epoch: 5| Step: 9
Training loss: 2.7560923099517822
Validation loss: 2.0062398897704257

Epoch: 5| Step: 10
Training loss: 2.6599388122558594
Validation loss: 2.0144605021322928

Epoch: 207| Step: 0
Training loss: 2.4482195377349854
Validation loss: 2.083079115036995

Epoch: 5| Step: 1
Training loss: 2.0920250415802
Validation loss: 2.055738672133415

Epoch: 5| Step: 2
Training loss: 1.6651474237442017
Validation loss: 2.0494352515025804

Epoch: 5| Step: 3
Training loss: 2.036416530609131
Validation loss: 2.06588944824793

Epoch: 5| Step: 4
Training loss: 1.8746554851531982
Validation loss: 2.1015431342586393

Epoch: 5| Step: 5
Training loss: 2.1361312866210938
Validation loss: 2.0680519021967405

Epoch: 5| Step: 6
Training loss: 2.407763957977295
Validation loss: 2.02581181962003

Epoch: 5| Step: 7
Training loss: 2.1795387268066406
Validation loss: 2.034870416887345

Epoch: 5| Step: 8
Training loss: 2.756467819213867
Validation loss: 2.099860329781809

Epoch: 5| Step: 9
Training loss: 2.3575797080993652
Validation loss: 2.021366347548782

Epoch: 5| Step: 10
Training loss: 2.025770664215088
Validation loss: 2.0837272341533373

Epoch: 208| Step: 0
Training loss: 2.011866331100464
Validation loss: 2.0612963027851556

Epoch: 5| Step: 1
Training loss: 2.493853807449341
Validation loss: 2.0229230926882837

Epoch: 5| Step: 2
Training loss: 2.2209765911102295
Validation loss: 2.0978161750301236

Epoch: 5| Step: 3
Training loss: 2.3547065258026123
Validation loss: 2.0827701963404173

Epoch: 5| Step: 4
Training loss: 2.5390236377716064
Validation loss: 2.02543822667932

Epoch: 5| Step: 5
Training loss: 2.0639758110046387
Validation loss: 2.1017804902086974

Epoch: 5| Step: 6
Training loss: 2.6223905086517334
Validation loss: 2.0223788817723594

Epoch: 5| Step: 7
Training loss: 2.084104061126709
Validation loss: 2.03847792584409

Epoch: 5| Step: 8
Training loss: 1.643723487854004
Validation loss: 2.070954630451818

Epoch: 5| Step: 9
Training loss: 1.624879240989685
Validation loss: 2.085635615933326

Epoch: 5| Step: 10
Training loss: 2.3003344535827637
Validation loss: 2.0752200157411638

Epoch: 209| Step: 0
Training loss: 2.264277696609497
Validation loss: 2.087414023696735

Epoch: 5| Step: 1
Training loss: 1.6925424337387085
Validation loss: 2.0911118112584597

Epoch: 5| Step: 2
Training loss: 2.308164119720459
Validation loss: 2.0263426867864465

Epoch: 5| Step: 3
Training loss: 1.9258533716201782
Validation loss: 2.1185585106572797

Epoch: 5| Step: 4
Training loss: 2.6691231727600098
Validation loss: 2.0333061141352498

Epoch: 5| Step: 5
Training loss: 2.3880774974823
Validation loss: 2.073319119791831

Epoch: 5| Step: 6
Training loss: 1.5436298847198486
Validation loss: 2.0221068269462994

Epoch: 5| Step: 7
Training loss: 2.041260242462158
Validation loss: 2.1138671495581187

Epoch: 5| Step: 8
Training loss: 2.3433780670166016
Validation loss: 2.073212849196567

Epoch: 5| Step: 9
Training loss: 1.9848533868789673
Validation loss: 2.039721195415784

Epoch: 5| Step: 10
Training loss: 3.014051914215088
Validation loss: 2.0160664384083082

Epoch: 210| Step: 0
Training loss: 2.3896918296813965
Validation loss: 2.0201999961688952

Epoch: 5| Step: 1
Training loss: 2.469310760498047
Validation loss: 2.0549575180135746

Epoch: 5| Step: 2
Training loss: 2.495556592941284
Validation loss: 2.054092373899234

Epoch: 5| Step: 3
Training loss: 1.3434213399887085
Validation loss: 2.0158897446047876

Epoch: 5| Step: 4
Training loss: 2.1257123947143555
Validation loss: 2.037274714439146

Epoch: 5| Step: 5
Training loss: 2.1169681549072266
Validation loss: 2.025517876430224

Epoch: 5| Step: 6
Training loss: 2.0200839042663574
Validation loss: 1.9931894515150337

Epoch: 5| Step: 7
Training loss: 2.254556179046631
Validation loss: 2.0717978900478733

Epoch: 5| Step: 8
Training loss: 2.345125436782837
Validation loss: 2.109945297241211

Epoch: 5| Step: 9
Training loss: 2.41996169090271
Validation loss: 2.0509444334173716

Epoch: 5| Step: 10
Training loss: 2.304319143295288
Validation loss: 2.0690246653813187

Epoch: 211| Step: 0
Training loss: 2.4564590454101562
Validation loss: 2.064003675214706

Epoch: 5| Step: 1
Training loss: 1.5512326955795288
Validation loss: 1.9964291036769908

Epoch: 5| Step: 2
Training loss: 2.2519145011901855
Validation loss: 2.075973992706627

Epoch: 5| Step: 3
Training loss: 2.0750460624694824
Validation loss: 2.010149137948149

Epoch: 5| Step: 4
Training loss: 1.9428831338882446
Validation loss: 2.0620486608115574

Epoch: 5| Step: 5
Training loss: 2.1633195877075195
Validation loss: 2.066633329596571

Epoch: 5| Step: 6
Training loss: 2.4776360988616943
Validation loss: 2.059564734017977

Epoch: 5| Step: 7
Training loss: 2.6889350414276123
Validation loss: 2.119814375395416

Epoch: 5| Step: 8
Training loss: 2.014631986618042
Validation loss: 2.045026574083554

Epoch: 5| Step: 9
Training loss: 2.203652858734131
Validation loss: 2.035185601121636

Epoch: 5| Step: 10
Training loss: 2.3992176055908203
Validation loss: 2.079850104547316

Epoch: 212| Step: 0
Training loss: 2.5202383995056152
Validation loss: 2.0135971705118814

Epoch: 5| Step: 1
Training loss: 1.3973405361175537
Validation loss: 2.054081888609035

Epoch: 5| Step: 2
Training loss: 2.4319207668304443
Validation loss: 2.028888343482889

Epoch: 5| Step: 3
Training loss: 2.2631969451904297
Validation loss: 2.0590326965496106

Epoch: 5| Step: 4
Training loss: 2.4525325298309326
Validation loss: 2.041803045939374

Epoch: 5| Step: 5
Training loss: 2.5837416648864746
Validation loss: 2.065840369911604

Epoch: 5| Step: 6
Training loss: 1.5451802015304565
Validation loss: 2.087585033908967

Epoch: 5| Step: 7
Training loss: 2.2998242378234863
Validation loss: 2.048287909518006

Epoch: 5| Step: 8
Training loss: 2.449512243270874
Validation loss: 2.0601627801054265

Epoch: 5| Step: 9
Training loss: 2.2492809295654297
Validation loss: 2.05777725865764

Epoch: 5| Step: 10
Training loss: 2.1061248779296875
Validation loss: 2.049641356673292

Epoch: 213| Step: 0
Training loss: 2.2315306663513184
Validation loss: 2.097457685778218

Epoch: 5| Step: 1
Training loss: 2.6178832054138184
Validation loss: 2.085545644965223

Epoch: 5| Step: 2
Training loss: 2.463635206222534
Validation loss: 2.0712024652829735

Epoch: 5| Step: 3
Training loss: 2.2333455085754395
Validation loss: 2.0476414221589283

Epoch: 5| Step: 4
Training loss: 1.9660634994506836
Validation loss: 2.1243900893836893

Epoch: 5| Step: 5
Training loss: 2.009479522705078
Validation loss: 2.0906479102309032

Epoch: 5| Step: 6
Training loss: 2.2669615745544434
Validation loss: 2.036748340052943

Epoch: 5| Step: 7
Training loss: 2.027599811553955
Validation loss: 2.0753310444534465

Epoch: 5| Step: 8
Training loss: 2.89994215965271
Validation loss: 2.0309382510441605

Epoch: 5| Step: 9
Training loss: 1.862733244895935
Validation loss: 2.0671794670884327

Epoch: 5| Step: 10
Training loss: 1.6065493822097778
Validation loss: 2.0829363715264106

Epoch: 214| Step: 0
Training loss: 2.185025691986084
Validation loss: 2.059621818604008

Epoch: 5| Step: 1
Training loss: 2.288426637649536
Validation loss: 2.0291719180281445

Epoch: 5| Step: 2
Training loss: 2.704569101333618
Validation loss: 2.072124106909639

Epoch: 5| Step: 3
Training loss: 1.7908060550689697
Validation loss: 2.010512678853927

Epoch: 5| Step: 4
Training loss: 2.220771074295044
Validation loss: 2.073439710883684

Epoch: 5| Step: 5
Training loss: 2.237877607345581
Validation loss: 2.0313236918500674

Epoch: 5| Step: 6
Training loss: 2.1942989826202393
Validation loss: 2.0923628627613025

Epoch: 5| Step: 7
Training loss: 2.4766242504119873
Validation loss: 2.029842847137041

Epoch: 5| Step: 8
Training loss: 1.6115802526474
Validation loss: 2.057723924677859

Epoch: 5| Step: 9
Training loss: 2.0983376502990723
Validation loss: 2.0391453337925736

Epoch: 5| Step: 10
Training loss: 2.4394946098327637
Validation loss: 2.0227906703948975

Epoch: 215| Step: 0
Training loss: 2.050078868865967
Validation loss: 2.0679895788110714

Epoch: 5| Step: 1
Training loss: 2.4200339317321777
Validation loss: 2.0821354594281924

Epoch: 5| Step: 2
Training loss: 1.767443060874939
Validation loss: 2.015073609608476

Epoch: 5| Step: 3
Training loss: 2.643667459487915
Validation loss: 2.0527535382137505

Epoch: 5| Step: 4
Training loss: 2.496234178543091
Validation loss: 2.134188449510964

Epoch: 5| Step: 5
Training loss: 2.114168882369995
Validation loss: 2.0388235033199353

Epoch: 5| Step: 6
Training loss: 1.4597269296646118
Validation loss: 2.0463772922433834

Epoch: 5| Step: 7
Training loss: 2.569736957550049
Validation loss: 2.086199232327041

Epoch: 5| Step: 8
Training loss: 1.8575000762939453
Validation loss: 2.0115956350039412

Epoch: 5| Step: 9
Training loss: 2.272169351577759
Validation loss: 2.094147386089448

Epoch: 5| Step: 10
Training loss: 2.342909097671509
Validation loss: 2.1239225966956026

Epoch: 216| Step: 0
Training loss: 2.0847392082214355
Validation loss: 2.048431950230752

Epoch: 5| Step: 1
Training loss: 1.5271183252334595
Validation loss: 2.0711641875646447

Epoch: 5| Step: 2
Training loss: 2.06054425239563
Validation loss: 2.0383066541405133

Epoch: 5| Step: 3
Training loss: 1.995532751083374
Validation loss: 2.021967561014237

Epoch: 5| Step: 4
Training loss: 2.402006149291992
Validation loss: 2.0265006557587655

Epoch: 5| Step: 5
Training loss: 2.4091262817382812
Validation loss: 2.0332678133441555

Epoch: 5| Step: 6
Training loss: 2.4661929607391357
Validation loss: 1.997577239108342

Epoch: 5| Step: 7
Training loss: 2.6247847080230713
Validation loss: 2.0309529996687368

Epoch: 5| Step: 8
Training loss: 2.272095203399658
Validation loss: 1.999250086404944

Epoch: 5| Step: 9
Training loss: 2.504641056060791
Validation loss: 2.0233680843025126

Epoch: 5| Step: 10
Training loss: 1.8014862537384033
Validation loss: 2.0286971830552623

Epoch: 217| Step: 0
Training loss: 2.210899829864502
Validation loss: 2.095122398868684

Epoch: 5| Step: 1
Training loss: 2.65718674659729
Validation loss: 2.0691477406409478

Epoch: 5| Step: 2
Training loss: 2.297849178314209
Validation loss: 2.0005516454737675

Epoch: 5| Step: 3
Training loss: 2.6336774826049805
Validation loss: 2.0217998463620424

Epoch: 5| Step: 4
Training loss: 2.2341649532318115
Validation loss: 2.001766179197578

Epoch: 5| Step: 5
Training loss: 2.673825740814209
Validation loss: 2.0560786595908542

Epoch: 5| Step: 6
Training loss: 1.8419885635375977
Validation loss: 2.019021159859114

Epoch: 5| Step: 7
Training loss: 1.7948144674301147
Validation loss: 2.034828045034921

Epoch: 5| Step: 8
Training loss: 2.1389782428741455
Validation loss: 1.9603667541216778

Epoch: 5| Step: 9
Training loss: 1.569931983947754
Validation loss: 2.044474647891137

Epoch: 5| Step: 10
Training loss: 2.173020124435425
Validation loss: 2.0422777129757788

Epoch: 218| Step: 0
Training loss: 2.010591983795166
Validation loss: 2.030987234525783

Epoch: 5| Step: 1
Training loss: 2.726707935333252
Validation loss: 2.0731646322434947

Epoch: 5| Step: 2
Training loss: 2.6578152179718018
Validation loss: 2.0378381718871412

Epoch: 5| Step: 3
Training loss: 1.9523961544036865
Validation loss: 2.0324384191984772

Epoch: 5| Step: 4
Training loss: 1.548642635345459
Validation loss: 2.0281314619125856

Epoch: 5| Step: 5
Training loss: 1.517954707145691
Validation loss: 2.042115496050927

Epoch: 5| Step: 6
Training loss: 2.319756507873535
Validation loss: 1.9834191517163349

Epoch: 5| Step: 7
Training loss: 2.4407455921173096
Validation loss: 2.0110007844945437

Epoch: 5| Step: 8
Training loss: 2.5181307792663574
Validation loss: 2.0261162583545973

Epoch: 5| Step: 9
Training loss: 1.7374756336212158
Validation loss: 2.0570329517446537

Epoch: 5| Step: 10
Training loss: 2.5977389812469482
Validation loss: 2.0507957191877466

Epoch: 219| Step: 0
Training loss: 1.6002495288848877
Validation loss: 2.066914568665207

Epoch: 5| Step: 1
Training loss: 2.408730983734131
Validation loss: 2.0232675838214096

Epoch: 5| Step: 2
Training loss: 2.726841926574707
Validation loss: 2.0759977999553887

Epoch: 5| Step: 3
Training loss: 2.0114777088165283
Validation loss: 2.07454207892059

Epoch: 5| Step: 4
Training loss: 1.854278564453125
Validation loss: 2.082608171688613

Epoch: 5| Step: 5
Training loss: 2.0690271854400635
Validation loss: 2.011463967702722

Epoch: 5| Step: 6
Training loss: 2.0223774909973145
Validation loss: 2.0297160097347793

Epoch: 5| Step: 7
Training loss: 2.42828369140625
Validation loss: 2.025874783915858

Epoch: 5| Step: 8
Training loss: 2.1239211559295654
Validation loss: 2.0428083660782024

Epoch: 5| Step: 9
Training loss: 2.344447135925293
Validation loss: 2.017634677630599

Epoch: 5| Step: 10
Training loss: 2.5643885135650635
Validation loss: 2.0412336190541587

Epoch: 220| Step: 0
Training loss: 2.252681016921997
Validation loss: 2.0060832577366985

Epoch: 5| Step: 1
Training loss: 2.5596094131469727
Validation loss: 2.042165910044024

Epoch: 5| Step: 2
Training loss: 2.208597421646118
Validation loss: 2.056916767551053

Epoch: 5| Step: 3
Training loss: 2.508791923522949
Validation loss: 2.05361867720081

Epoch: 5| Step: 4
Training loss: 2.277242660522461
Validation loss: 2.019613645410025

Epoch: 5| Step: 5
Training loss: 2.2524352073669434
Validation loss: 2.0188156814985376

Epoch: 5| Step: 6
Training loss: 1.5173978805541992
Validation loss: 2.03365812506727

Epoch: 5| Step: 7
Training loss: 1.9243755340576172
Validation loss: 2.0084298246650287

Epoch: 5| Step: 8
Training loss: 2.5150578022003174
Validation loss: 2.0931290926471835

Epoch: 5| Step: 9
Training loss: 1.8018509149551392
Validation loss: 2.0636344827631468

Epoch: 5| Step: 10
Training loss: 2.2567138671875
Validation loss: 2.0302307759561846

Epoch: 221| Step: 0
Training loss: 2.1686465740203857
Validation loss: 2.0040314633359193

Epoch: 5| Step: 1
Training loss: 2.0529892444610596
Validation loss: 2.021723537034886

Epoch: 5| Step: 2
Training loss: 2.189967632293701
Validation loss: 2.0682274756893033

Epoch: 5| Step: 3
Training loss: 2.340712070465088
Validation loss: 2.0350795522812875

Epoch: 5| Step: 4
Training loss: 2.2381234169006348
Validation loss: 2.011535757331438

Epoch: 5| Step: 5
Training loss: 2.0688767433166504
Validation loss: 2.058888767355232

Epoch: 5| Step: 6
Training loss: 1.925438642501831
Validation loss: 2.014965702128667

Epoch: 5| Step: 7
Training loss: 2.1567678451538086
Validation loss: 2.058408044999646

Epoch: 5| Step: 8
Training loss: 2.360811710357666
Validation loss: 2.0638185316516506

Epoch: 5| Step: 9
Training loss: 1.9269253015518188
Validation loss: 2.043576899395194

Epoch: 5| Step: 10
Training loss: 2.4688379764556885
Validation loss: 2.06886556584348

Epoch: 222| Step: 0
Training loss: 2.1476852893829346
Validation loss: 2.1099327200202533

Epoch: 5| Step: 1
Training loss: 2.5322470664978027
Validation loss: 2.018432004477388

Epoch: 5| Step: 2
Training loss: 2.4634602069854736
Validation loss: 2.0673364823864353

Epoch: 5| Step: 3
Training loss: 2.052687883377075
Validation loss: 2.0632177847687916

Epoch: 5| Step: 4
Training loss: 1.9468564987182617
Validation loss: 2.0520773036505586

Epoch: 5| Step: 5
Training loss: 2.3458101749420166
Validation loss: 2.041334347058368

Epoch: 5| Step: 6
Training loss: 2.1496448516845703
Validation loss: 2.0712967124036563

Epoch: 5| Step: 7
Training loss: 2.021697521209717
Validation loss: 2.02270749820176

Epoch: 5| Step: 8
Training loss: 2.371119260787964
Validation loss: 2.0240698629809963

Epoch: 5| Step: 9
Training loss: 1.9851747751235962
Validation loss: 2.0765203301624586

Epoch: 5| Step: 10
Training loss: 2.2288453578948975
Validation loss: 2.0343379769273984

Epoch: 223| Step: 0
Training loss: 1.8599693775177002
Validation loss: 2.0574063049849642

Epoch: 5| Step: 1
Training loss: 2.506812810897827
Validation loss: 2.061076210391137

Epoch: 5| Step: 2
Training loss: 2.0904855728149414
Validation loss: 2.0142169075627483

Epoch: 5| Step: 3
Training loss: 2.058283567428589
Validation loss: 2.0489786286507883

Epoch: 5| Step: 4
Training loss: 2.8467764854431152
Validation loss: 2.0652794350859938

Epoch: 5| Step: 5
Training loss: 2.158827066421509
Validation loss: 2.0560941593621367

Epoch: 5| Step: 6
Training loss: 2.15421986579895
Validation loss: 2.0737966927148963

Epoch: 5| Step: 7
Training loss: 2.4563632011413574
Validation loss: 2.026202271061559

Epoch: 5| Step: 8
Training loss: 2.675600528717041
Validation loss: 2.0544387371309343

Epoch: 5| Step: 9
Training loss: 1.4005438089370728
Validation loss: 2.0394664477276545

Epoch: 5| Step: 10
Training loss: 1.756883978843689
Validation loss: 2.034043232599894

Epoch: 224| Step: 0
Training loss: 1.835736870765686
Validation loss: 2.024899386590527

Epoch: 5| Step: 1
Training loss: 2.203472137451172
Validation loss: 2.0369008330888647

Epoch: 5| Step: 2
Training loss: 2.3637003898620605
Validation loss: 2.0546703928260395

Epoch: 5| Step: 3
Training loss: 2.605619430541992
Validation loss: 2.0837975035431566

Epoch: 5| Step: 4
Training loss: 2.361945390701294
Validation loss: 2.0217431963130994

Epoch: 5| Step: 5
Training loss: 2.2850232124328613
Validation loss: 2.0929108512017036

Epoch: 5| Step: 6
Training loss: 2.324256181716919
Validation loss: 2.0977375750900595

Epoch: 5| Step: 7
Training loss: 1.8171764612197876
Validation loss: 2.0417730372439147

Epoch: 5| Step: 8
Training loss: 2.0285892486572266
Validation loss: 2.057368051621222

Epoch: 5| Step: 9
Training loss: 1.6639306545257568
Validation loss: 1.9912442520100584

Epoch: 5| Step: 10
Training loss: 2.416534900665283
Validation loss: 2.0249474663888254

Epoch: 225| Step: 0
Training loss: 2.3770642280578613
Validation loss: 2.0197597639535063

Epoch: 5| Step: 1
Training loss: 1.1907962560653687
Validation loss: 2.0819629405134465

Epoch: 5| Step: 2
Training loss: 2.816286563873291
Validation loss: 2.0319175194668513

Epoch: 5| Step: 3
Training loss: 2.2322781085968018
Validation loss: 2.053528654959894

Epoch: 5| Step: 4
Training loss: 1.8177276849746704
Validation loss: 2.050750219693748

Epoch: 5| Step: 5
Training loss: 1.9956926107406616
Validation loss: 2.0746591885884604

Epoch: 5| Step: 6
Training loss: 2.230933666229248
Validation loss: 2.066804060371973

Epoch: 5| Step: 7
Training loss: 1.6640459299087524
Validation loss: 2.0475719039158156

Epoch: 5| Step: 8
Training loss: 2.616997003555298
Validation loss: 2.0851051448493876

Epoch: 5| Step: 9
Training loss: 2.278912305831909
Validation loss: 2.050140474432258

Epoch: 5| Step: 10
Training loss: 2.689865827560425
Validation loss: 2.060516872713643

Epoch: 226| Step: 0
Training loss: 1.6664340496063232
Validation loss: 2.084040275184057

Epoch: 5| Step: 1
Training loss: 1.995826005935669
Validation loss: 2.05264756115534

Epoch: 5| Step: 2
Training loss: 2.0179505348205566
Validation loss: 2.035691794528756

Epoch: 5| Step: 3
Training loss: 2.159966230392456
Validation loss: 2.068276843717021

Epoch: 5| Step: 4
Training loss: 1.962026596069336
Validation loss: 2.1131922006607056

Epoch: 5| Step: 5
Training loss: 2.414654493331909
Validation loss: 2.0350430037385676

Epoch: 5| Step: 6
Training loss: 2.3046867847442627
Validation loss: 2.078406733851279

Epoch: 5| Step: 7
Training loss: 2.42628812789917
Validation loss: 1.9851350258755427

Epoch: 5| Step: 8
Training loss: 2.7791523933410645
Validation loss: 2.0787938948600524

Epoch: 5| Step: 9
Training loss: 1.5124861001968384
Validation loss: 2.0299620589902325

Epoch: 5| Step: 10
Training loss: 2.8132145404815674
Validation loss: 2.075889725838938

Epoch: 227| Step: 0
Training loss: 2.1937241554260254
Validation loss: 1.9964726176313174

Epoch: 5| Step: 1
Training loss: 2.144252300262451
Validation loss: 2.0657986389693392

Epoch: 5| Step: 2
Training loss: 1.9314149618148804
Validation loss: 2.063125741097235

Epoch: 5| Step: 3
Training loss: 2.5891315937042236
Validation loss: 2.0613252116787817

Epoch: 5| Step: 4
Training loss: 2.3454349040985107
Validation loss: 2.061996603524813

Epoch: 5| Step: 5
Training loss: 2.578402042388916
Validation loss: 2.036908575283584

Epoch: 5| Step: 6
Training loss: 1.0727182626724243
Validation loss: 2.0076499087836153

Epoch: 5| Step: 7
Training loss: 2.0719621181488037
Validation loss: 2.0579263958879697

Epoch: 5| Step: 8
Training loss: 1.9354168176651
Validation loss: 2.022355015559863

Epoch: 5| Step: 9
Training loss: 2.601634979248047
Validation loss: 2.0583993516942507

Epoch: 5| Step: 10
Training loss: 2.2223339080810547
Validation loss: 2.049966258387412

Epoch: 228| Step: 0
Training loss: 2.0261740684509277
Validation loss: 2.0575707497135287

Epoch: 5| Step: 1
Training loss: 1.8139228820800781
Validation loss: 2.0447757192837295

Epoch: 5| Step: 2
Training loss: 2.196537494659424
Validation loss: 2.0301431109828334

Epoch: 5| Step: 3
Training loss: 2.6723711490631104
Validation loss: 2.067644448690517

Epoch: 5| Step: 4
Training loss: 2.3658196926116943
Validation loss: 2.0334068062484905

Epoch: 5| Step: 5
Training loss: 1.875083327293396
Validation loss: 2.06529099710526

Epoch: 5| Step: 6
Training loss: 2.3521947860717773
Validation loss: 2.0881500295413438

Epoch: 5| Step: 7
Training loss: 2.5815091133117676
Validation loss: 2.030163400916643

Epoch: 5| Step: 8
Training loss: 1.5927484035491943
Validation loss: 2.0087802743399017

Epoch: 5| Step: 9
Training loss: 2.2734925746917725
Validation loss: 2.0444182580517185

Epoch: 5| Step: 10
Training loss: 2.138822555541992
Validation loss: 2.0302018503988943

Epoch: 229| Step: 0
Training loss: 2.29801607131958
Validation loss: 2.063306385470975

Epoch: 5| Step: 1
Training loss: 2.3044333457946777
Validation loss: 2.0067852402246125

Epoch: 5| Step: 2
Training loss: 1.9002364873886108
Validation loss: 2.0478826543336273

Epoch: 5| Step: 3
Training loss: 2.999793529510498
Validation loss: 2.027950948284518

Epoch: 5| Step: 4
Training loss: 2.5316760540008545
Validation loss: 2.0086914993101552

Epoch: 5| Step: 5
Training loss: 2.250638484954834
Validation loss: 1.988712877355596

Epoch: 5| Step: 6
Training loss: 2.1216883659362793
Validation loss: 2.013514253400987

Epoch: 5| Step: 7
Training loss: 1.7954025268554688
Validation loss: 2.0375031604561755

Epoch: 5| Step: 8
Training loss: 1.7274223566055298
Validation loss: 2.0576908562773015

Epoch: 5| Step: 9
Training loss: 2.125447988510132
Validation loss: 2.02206160688913

Epoch: 5| Step: 10
Training loss: 2.1344518661499023
Validation loss: 2.0267002736368487

Epoch: 230| Step: 0
Training loss: 2.291227102279663
Validation loss: 1.9732826871256675

Epoch: 5| Step: 1
Training loss: 2.476997137069702
Validation loss: 2.039484885431105

Epoch: 5| Step: 2
Training loss: 2.315779209136963
Validation loss: 2.0155768625197874

Epoch: 5| Step: 3
Training loss: 1.4402978420257568
Validation loss: 2.027686293407153

Epoch: 5| Step: 4
Training loss: 1.9758596420288086
Validation loss: 2.027357215522438

Epoch: 5| Step: 5
Training loss: 2.491835355758667
Validation loss: 2.07113839093075

Epoch: 5| Step: 6
Training loss: 1.8086044788360596
Validation loss: 2.030637479597522

Epoch: 5| Step: 7
Training loss: 2.3371903896331787
Validation loss: 2.0054730753744803

Epoch: 5| Step: 8
Training loss: 2.319009304046631
Validation loss: 2.062489330127675

Epoch: 5| Step: 9
Training loss: 2.3132591247558594
Validation loss: 2.0696994309784262

Epoch: 5| Step: 10
Training loss: 2.369915246963501
Validation loss: 2.055765485250822

Epoch: 231| Step: 0
Training loss: 2.3815219402313232
Validation loss: 2.041622987357519

Epoch: 5| Step: 1
Training loss: 2.49310040473938
Validation loss: 2.051350365402878

Epoch: 5| Step: 2
Training loss: 2.3896076679229736
Validation loss: 1.9879623407958655

Epoch: 5| Step: 3
Training loss: 1.7431919574737549
Validation loss: 2.011892767362697

Epoch: 5| Step: 4
Training loss: 2.02915620803833
Validation loss: 2.087595752490464

Epoch: 5| Step: 5
Training loss: 1.9886419773101807
Validation loss: 2.0630855175756637

Epoch: 5| Step: 6
Training loss: 1.9779272079467773
Validation loss: 2.0943589710420176

Epoch: 5| Step: 7
Training loss: 2.113133430480957
Validation loss: 2.0345433065968175

Epoch: 5| Step: 8
Training loss: 2.7025437355041504
Validation loss: 2.0754367433568484

Epoch: 5| Step: 9
Training loss: 1.9875962734222412
Validation loss: 2.0441271771666822

Epoch: 5| Step: 10
Training loss: 2.190656900405884
Validation loss: 2.0322176653851747

Epoch: 232| Step: 0
Training loss: 1.6248226165771484
Validation loss: 2.0735528545994915

Epoch: 5| Step: 1
Training loss: 2.383578062057495
Validation loss: 2.0620434899483957

Epoch: 5| Step: 2
Training loss: 2.319007396697998
Validation loss: 2.0566843889092885

Epoch: 5| Step: 3
Training loss: 2.5354361534118652
Validation loss: 2.090383470699351

Epoch: 5| Step: 4
Training loss: 1.829866647720337
Validation loss: 2.0704916702803744

Epoch: 5| Step: 5
Training loss: 2.61919903755188
Validation loss: 2.0275095021852882

Epoch: 5| Step: 6
Training loss: 2.2075395584106445
Validation loss: 2.0127269426981607

Epoch: 5| Step: 7
Training loss: 1.6527316570281982
Validation loss: 2.038521315461846

Epoch: 5| Step: 8
Training loss: 2.334289073944092
Validation loss: 2.0403078986752416

Epoch: 5| Step: 9
Training loss: 2.1065642833709717
Validation loss: 2.081950154355777

Epoch: 5| Step: 10
Training loss: 2.174661159515381
Validation loss: 2.057080220150691

Epoch: 233| Step: 0
Training loss: 2.364964723587036
Validation loss: 1.997166246496221

Epoch: 5| Step: 1
Training loss: 2.0057971477508545
Validation loss: 2.0678396083975352

Epoch: 5| Step: 2
Training loss: 2.495189666748047
Validation loss: 2.114143028054186

Epoch: 5| Step: 3
Training loss: 2.0249571800231934
Validation loss: 2.0967261739956435

Epoch: 5| Step: 4
Training loss: 2.0091025829315186
Validation loss: 2.112806407354211

Epoch: 5| Step: 5
Training loss: 2.6162052154541016
Validation loss: 2.0826944061504897

Epoch: 5| Step: 6
Training loss: 2.4477944374084473
Validation loss: 2.005986431593536

Epoch: 5| Step: 7
Training loss: 2.632040023803711
Validation loss: 2.0123223694421912

Epoch: 5| Step: 8
Training loss: 1.9839719533920288
Validation loss: 2.053505256611814

Epoch: 5| Step: 9
Training loss: 1.897669792175293
Validation loss: 2.094893111977526

Epoch: 5| Step: 10
Training loss: 1.558175802230835
Validation loss: 2.104640914547828

Epoch: 234| Step: 0
Training loss: 1.9788793325424194
Validation loss: 2.031831938733337

Epoch: 5| Step: 1
Training loss: 1.6212583780288696
Validation loss: 2.056867634096453

Epoch: 5| Step: 2
Training loss: 2.081503391265869
Validation loss: 2.057189315877935

Epoch: 5| Step: 3
Training loss: 2.1644370555877686
Validation loss: 2.0258747992977018

Epoch: 5| Step: 4
Training loss: 2.4135754108428955
Validation loss: 2.041312748386014

Epoch: 5| Step: 5
Training loss: 1.7090648412704468
Validation loss: 2.0514740841363066

Epoch: 5| Step: 6
Training loss: 2.407510995864868
Validation loss: 2.0058153342175227

Epoch: 5| Step: 7
Training loss: 2.2445595264434814
Validation loss: 2.032492844648259

Epoch: 5| Step: 8
Training loss: 2.537830114364624
Validation loss: 2.044708744172127

Epoch: 5| Step: 9
Training loss: 2.1537375450134277
Validation loss: 2.0068509142885924

Epoch: 5| Step: 10
Training loss: 2.5498404502868652
Validation loss: 2.0437044853805215

Epoch: 235| Step: 0
Training loss: 1.35697340965271
Validation loss: 1.94003967572284

Epoch: 5| Step: 1
Training loss: 1.9468896389007568
Validation loss: 2.0533452008360173

Epoch: 5| Step: 2
Training loss: 2.9170074462890625
Validation loss: 1.9932535002308507

Epoch: 5| Step: 3
Training loss: 2.614405393600464
Validation loss: 2.023459271718097

Epoch: 5| Step: 4
Training loss: 2.1412525177001953
Validation loss: 2.072481354077657

Epoch: 5| Step: 5
Training loss: 2.4716079235076904
Validation loss: 2.030255602252099

Epoch: 5| Step: 6
Training loss: 2.502288579940796
Validation loss: 2.0711667665871243

Epoch: 5| Step: 7
Training loss: 2.2908923625946045
Validation loss: 2.0500938559091217

Epoch: 5| Step: 8
Training loss: 1.5225311517715454
Validation loss: 2.082770562941028

Epoch: 5| Step: 9
Training loss: 2.2327804565429688
Validation loss: 2.02434136790614

Epoch: 5| Step: 10
Training loss: 1.7011301517486572
Validation loss: 2.0343219503279655

Epoch: 236| Step: 0
Training loss: 2.291370391845703
Validation loss: 2.0659370409545077

Epoch: 5| Step: 1
Training loss: 1.145932912826538
Validation loss: 2.132317773757442

Epoch: 5| Step: 2
Training loss: 1.8886041641235352
Validation loss: 2.0733178405351538

Epoch: 5| Step: 3
Training loss: 2.2772960662841797
Validation loss: 2.0661716127908356

Epoch: 5| Step: 4
Training loss: 2.4753806591033936
Validation loss: 2.0889835831939534

Epoch: 5| Step: 5
Training loss: 2.536428689956665
Validation loss: 2.1247756096624557

Epoch: 5| Step: 6
Training loss: 1.6254663467407227
Validation loss: 2.091046484567786

Epoch: 5| Step: 7
Training loss: 2.521836042404175
Validation loss: 2.137997281166815

Epoch: 5| Step: 8
Training loss: 2.7388405799865723
Validation loss: 2.1317769609471804

Epoch: 5| Step: 9
Training loss: 2.471484661102295
Validation loss: 2.04351451576397

Epoch: 5| Step: 10
Training loss: 2.047943592071533
Validation loss: 2.0457605687520837

Epoch: 237| Step: 0
Training loss: 2.409973621368408
Validation loss: 2.0959245799690165

Epoch: 5| Step: 1
Training loss: 2.415825128555298
Validation loss: 2.0661952585302372

Epoch: 5| Step: 2
Training loss: 2.231139898300171
Validation loss: 2.0492275658474175

Epoch: 5| Step: 3
Training loss: 1.797650933265686
Validation loss: 1.999334753200572

Epoch: 5| Step: 4
Training loss: 2.018404483795166
Validation loss: 2.066516560892905

Epoch: 5| Step: 5
Training loss: 2.32391095161438
Validation loss: 2.059828104511384

Epoch: 5| Step: 6
Training loss: 2.6374847888946533
Validation loss: 2.073298510684762

Epoch: 5| Step: 7
Training loss: 1.9355251789093018
Validation loss: 2.059892454454976

Epoch: 5| Step: 8
Training loss: 1.8437684774398804
Validation loss: 2.0947895716595393

Epoch: 5| Step: 9
Training loss: 1.9144275188446045
Validation loss: 2.0851898552269064

Epoch: 5| Step: 10
Training loss: 2.283874273300171
Validation loss: 2.047498538929929

Epoch: 238| Step: 0
Training loss: 2.291280508041382
Validation loss: 2.0624560335631013

Epoch: 5| Step: 1
Training loss: 1.4749722480773926
Validation loss: 2.020390998932623

Epoch: 5| Step: 2
Training loss: 2.6148667335510254
Validation loss: 1.987258239458966

Epoch: 5| Step: 3
Training loss: 2.3179049491882324
Validation loss: 2.0652159542165776

Epoch: 5| Step: 4
Training loss: 1.8818175792694092
Validation loss: 1.9821889708119054

Epoch: 5| Step: 5
Training loss: 2.4677021503448486
Validation loss: 2.0397878410995647

Epoch: 5| Step: 6
Training loss: 1.8759090900421143
Validation loss: 2.090417044137114

Epoch: 5| Step: 7
Training loss: 1.747266411781311
Validation loss: 2.0577591926820817

Epoch: 5| Step: 8
Training loss: 2.364077091217041
Validation loss: 2.060052853758617

Epoch: 5| Step: 9
Training loss: 2.2104907035827637
Validation loss: 2.055139067352459

Epoch: 5| Step: 10
Training loss: 2.4072234630584717
Validation loss: 2.0385857461601176

Epoch: 239| Step: 0
Training loss: 2.6154701709747314
Validation loss: 2.0218204093235794

Epoch: 5| Step: 1
Training loss: 2.115560531616211
Validation loss: 2.1051909667189403

Epoch: 5| Step: 2
Training loss: 2.0562026500701904
Validation loss: 2.0943975871609104

Epoch: 5| Step: 3
Training loss: 2.1599788665771484
Validation loss: 2.0640720423831733

Epoch: 5| Step: 4
Training loss: 1.9578577280044556
Validation loss: 2.0640358540319625

Epoch: 5| Step: 5
Training loss: 2.18180513381958
Validation loss: 2.0988372243860716

Epoch: 5| Step: 6
Training loss: 2.256765127182007
Validation loss: 1.9926555695072297

Epoch: 5| Step: 7
Training loss: 1.7869327068328857
Validation loss: 2.0196751663761754

Epoch: 5| Step: 8
Training loss: 2.140850782394409
Validation loss: 2.016113578632314

Epoch: 5| Step: 9
Training loss: 2.0858492851257324
Validation loss: 1.9832122505352061

Epoch: 5| Step: 10
Training loss: 2.566466808319092
Validation loss: 1.9813366743826097

Epoch: 240| Step: 0
Training loss: 2.3502626419067383
Validation loss: 2.0253013731330953

Epoch: 5| Step: 1
Training loss: 2.372215747833252
Validation loss: 2.045602242151896

Epoch: 5| Step: 2
Training loss: 1.7712208032608032
Validation loss: 1.9818476528249762

Epoch: 5| Step: 3
Training loss: 2.364342451095581
Validation loss: 1.9732419239577426

Epoch: 5| Step: 4
Training loss: 1.7120516300201416
Validation loss: 2.051199677169964

Epoch: 5| Step: 5
Training loss: 2.2820017337799072
Validation loss: 2.0111316198943765

Epoch: 5| Step: 6
Training loss: 2.1491966247558594
Validation loss: 2.0374001969573317

Epoch: 5| Step: 7
Training loss: 1.7415637969970703
Validation loss: 2.0231549278382333

Epoch: 5| Step: 8
Training loss: 2.1404500007629395
Validation loss: 2.042719562848409

Epoch: 5| Step: 9
Training loss: 2.598846673965454
Validation loss: 2.057697420479149

Epoch: 5| Step: 10
Training loss: 2.2759554386138916
Validation loss: 2.063369999649704

Epoch: 241| Step: 0
Training loss: 1.6267297267913818
Validation loss: 2.075536219022607

Epoch: 5| Step: 1
Training loss: 1.8761335611343384
Validation loss: 2.078237454096476

Epoch: 5| Step: 2
Training loss: 1.9407341480255127
Validation loss: 2.020261149252615

Epoch: 5| Step: 3
Training loss: 2.3110716342926025
Validation loss: 2.0064621087043517

Epoch: 5| Step: 4
Training loss: 2.25593900680542
Validation loss: 1.9942655204444804

Epoch: 5| Step: 5
Training loss: 2.4536991119384766
Validation loss: 2.031561028572821

Epoch: 5| Step: 6
Training loss: 2.4162614345550537
Validation loss: 2.0610286625482703

Epoch: 5| Step: 7
Training loss: 1.9713029861450195
Validation loss: 2.0537932534371652

Epoch: 5| Step: 8
Training loss: 1.8259271383285522
Validation loss: 2.039772541292252

Epoch: 5| Step: 9
Training loss: 2.7320618629455566
Validation loss: 2.015733001052692

Epoch: 5| Step: 10
Training loss: 1.9863543510437012
Validation loss: 2.0485093080869285

Epoch: 242| Step: 0
Training loss: 2.0972325801849365
Validation loss: 2.0043809388273504

Epoch: 5| Step: 1
Training loss: 1.989335298538208
Validation loss: 2.040540378580811

Epoch: 5| Step: 2
Training loss: 2.282022476196289
Validation loss: 2.0862659459472983

Epoch: 5| Step: 3
Training loss: 2.0979926586151123
Validation loss: 2.0688580620673394

Epoch: 5| Step: 4
Training loss: 1.787388563156128
Validation loss: 2.026520326573362

Epoch: 5| Step: 5
Training loss: 2.415503978729248
Validation loss: 2.0109232292380383

Epoch: 5| Step: 6
Training loss: 2.434196949005127
Validation loss: 2.011950139076479

Epoch: 5| Step: 7
Training loss: 2.619239330291748
Validation loss: 2.0405226061421056

Epoch: 5| Step: 8
Training loss: 2.7380928993225098
Validation loss: 1.986384698139724

Epoch: 5| Step: 9
Training loss: 1.8614933490753174
Validation loss: 2.0326201146648777

Epoch: 5| Step: 10
Training loss: 1.7340545654296875
Validation loss: 2.067378915766234

Epoch: 243| Step: 0
Training loss: 2.552116870880127
Validation loss: 2.0457633515839935

Epoch: 5| Step: 1
Training loss: 2.3927557468414307
Validation loss: 2.0696407248896938

Epoch: 5| Step: 2
Training loss: 2.0407824516296387
Validation loss: 2.0277751645734234

Epoch: 5| Step: 3
Training loss: 2.227607011795044
Validation loss: 2.0666497702239663

Epoch: 5| Step: 4
Training loss: 2.572230577468872
Validation loss: 2.0704733556316746

Epoch: 5| Step: 5
Training loss: 2.0511245727539062
Validation loss: 2.1014510893052623

Epoch: 5| Step: 6
Training loss: 2.1439244747161865
Validation loss: 2.1061076938465075

Epoch: 5| Step: 7
Training loss: 1.491544246673584
Validation loss: 2.1037861865053893

Epoch: 5| Step: 8
Training loss: 2.438835620880127
Validation loss: 2.059650444215344

Epoch: 5| Step: 9
Training loss: 1.9513381719589233
Validation loss: 2.079617346486738

Epoch: 5| Step: 10
Training loss: 1.7800439596176147
Validation loss: 2.0602134991717596

Epoch: 244| Step: 0
Training loss: 2.181497097015381
Validation loss: 2.0545556570893977

Epoch: 5| Step: 1
Training loss: 1.8413925170898438
Validation loss: 2.073605481014457

Epoch: 5| Step: 2
Training loss: 2.4881904125213623
Validation loss: 2.0511659153046145

Epoch: 5| Step: 3
Training loss: 2.1946940422058105
Validation loss: 2.112501179018328

Epoch: 5| Step: 4
Training loss: 1.8772246837615967
Validation loss: 2.098016333836381

Epoch: 5| Step: 5
Training loss: 2.726149320602417
Validation loss: 2.0366030393108243

Epoch: 5| Step: 6
Training loss: 1.857468605041504
Validation loss: 2.0749494388539302

Epoch: 5| Step: 7
Training loss: 1.7422049045562744
Validation loss: 2.0020074690541914

Epoch: 5| Step: 8
Training loss: 2.964897871017456
Validation loss: 2.038903531207833

Epoch: 5| Step: 9
Training loss: 1.4111840724945068
Validation loss: 2.006107097030968

Epoch: 5| Step: 10
Training loss: 2.6703877449035645
Validation loss: 2.004308755679797

Epoch: 245| Step: 0
Training loss: 2.562978744506836
Validation loss: 2.0315666737095004

Epoch: 5| Step: 1
Training loss: 2.071028232574463
Validation loss: 2.0353568125796575

Epoch: 5| Step: 2
Training loss: 2.2926435470581055
Validation loss: 1.9952023157509424

Epoch: 5| Step: 3
Training loss: 2.256186008453369
Validation loss: 2.0101481919647544

Epoch: 5| Step: 4
Training loss: 2.339092254638672
Validation loss: 1.9844767560241043

Epoch: 5| Step: 5
Training loss: 2.024038791656494
Validation loss: 2.0583739575519355

Epoch: 5| Step: 6
Training loss: 2.2940192222595215
Validation loss: 2.088896028457149

Epoch: 5| Step: 7
Training loss: 2.0599465370178223
Validation loss: 2.0524128765188236

Epoch: 5| Step: 8
Training loss: 1.7072792053222656
Validation loss: 2.018222971629071

Epoch: 5| Step: 9
Training loss: 2.4072213172912598
Validation loss: 2.0134384580837783

Epoch: 5| Step: 10
Training loss: 1.7383544445037842
Validation loss: 1.9999454008635653

Epoch: 246| Step: 0
Training loss: 1.9357850551605225
Validation loss: 2.0445702921959663

Epoch: 5| Step: 1
Training loss: 2.4034512042999268
Validation loss: 1.9918051842720277

Epoch: 5| Step: 2
Training loss: 1.7785574197769165
Validation loss: 2.0421071001278457

Epoch: 5| Step: 3
Training loss: 1.9171546697616577
Validation loss: 2.056592848993117

Epoch: 5| Step: 4
Training loss: 2.478776454925537
Validation loss: 1.9490799929506035

Epoch: 5| Step: 5
Training loss: 1.9344860315322876
Validation loss: 2.002178167784086

Epoch: 5| Step: 6
Training loss: 1.9372771978378296
Validation loss: 2.0675074669622604

Epoch: 5| Step: 7
Training loss: 2.1641383171081543
Validation loss: 2.0050778235158613

Epoch: 5| Step: 8
Training loss: 2.1982040405273438
Validation loss: 2.0284539961045787

Epoch: 5| Step: 9
Training loss: 2.318715810775757
Validation loss: 1.9817550169524325

Epoch: 5| Step: 10
Training loss: 3.1578383445739746
Validation loss: 2.0609148522858978

Epoch: 247| Step: 0
Training loss: 2.0819482803344727
Validation loss: 1.9800038696617208

Epoch: 5| Step: 1
Training loss: 2.1777825355529785
Validation loss: 2.01142612067602

Epoch: 5| Step: 2
Training loss: 1.3833829164505005
Validation loss: 2.105557687820927

Epoch: 5| Step: 3
Training loss: 2.9346187114715576
Validation loss: 2.067027835435765

Epoch: 5| Step: 4
Training loss: 2.2992799282073975
Validation loss: 2.0377940465045232

Epoch: 5| Step: 5
Training loss: 1.707094430923462
Validation loss: 2.0332815198488134

Epoch: 5| Step: 6
Training loss: 2.696338653564453
Validation loss: 2.0536520788746495

Epoch: 5| Step: 7
Training loss: 2.0381882190704346
Validation loss: 2.0500975783153246

Epoch: 5| Step: 8
Training loss: 1.9031057357788086
Validation loss: 2.0299644265123593

Epoch: 5| Step: 9
Training loss: 2.461977005004883
Validation loss: 2.0447124576055877

Epoch: 5| Step: 10
Training loss: 1.9308902025222778
Validation loss: 2.0910453219567575

Epoch: 248| Step: 0
Training loss: 2.1270205974578857
Validation loss: 2.0779626395112727

Epoch: 5| Step: 1
Training loss: 2.3724217414855957
Validation loss: 2.0589727868315992

Epoch: 5| Step: 2
Training loss: 1.5511524677276611
Validation loss: 2.0509360092942432

Epoch: 5| Step: 3
Training loss: 2.3241848945617676
Validation loss: 2.0402372883212183

Epoch: 5| Step: 4
Training loss: 1.9971891641616821
Validation loss: 2.0382281554642545

Epoch: 5| Step: 5
Training loss: 2.198133945465088
Validation loss: 2.020744292966781

Epoch: 5| Step: 6
Training loss: 1.533233880996704
Validation loss: 2.115614257833009

Epoch: 5| Step: 7
Training loss: 2.1571547985076904
Validation loss: 2.0983431082899853

Epoch: 5| Step: 8
Training loss: 2.437227725982666
Validation loss: 2.0216983672111266

Epoch: 5| Step: 9
Training loss: 1.791454553604126
Validation loss: 2.0329292487072688

Epoch: 5| Step: 10
Training loss: 2.922556161880493
Validation loss: 2.0301812079644974

Epoch: 249| Step: 0
Training loss: 1.9893417358398438
Validation loss: 2.030408041451567

Epoch: 5| Step: 1
Training loss: 1.983354926109314
Validation loss: 2.089086422356226

Epoch: 5| Step: 2
Training loss: 2.3163058757781982
Validation loss: 2.083481396398237

Epoch: 5| Step: 3
Training loss: 2.805816650390625
Validation loss: 2.1143702999238045

Epoch: 5| Step: 4
Training loss: 1.995462417602539
Validation loss: 2.0659433616104947

Epoch: 5| Step: 5
Training loss: 2.020050525665283
Validation loss: 2.0466301953920754

Epoch: 5| Step: 6
Training loss: 1.4895216226577759
Validation loss: 2.0247141904728387

Epoch: 5| Step: 7
Training loss: 2.3132548332214355
Validation loss: 2.087707132421514

Epoch: 5| Step: 8
Training loss: 1.8487567901611328
Validation loss: 2.036580249827395

Epoch: 5| Step: 9
Training loss: 2.1778297424316406
Validation loss: 2.0649466155677714

Epoch: 5| Step: 10
Training loss: 2.6214914321899414
Validation loss: 2.104053452450742

Epoch: 250| Step: 0
Training loss: 2.164141893386841
Validation loss: 2.0135922124308925

Epoch: 5| Step: 1
Training loss: 1.7849006652832031
Validation loss: 2.03307201785426

Epoch: 5| Step: 2
Training loss: 2.322056293487549
Validation loss: 2.125840389600364

Epoch: 5| Step: 3
Training loss: 1.9710956811904907
Validation loss: 2.0405816672950663

Epoch: 5| Step: 4
Training loss: 2.5631039142608643
Validation loss: 2.04208045108344

Epoch: 5| Step: 5
Training loss: 1.545554518699646
Validation loss: 2.0376553804643693

Epoch: 5| Step: 6
Training loss: 2.960249662399292
Validation loss: 2.054103584699733

Epoch: 5| Step: 7
Training loss: 2.3681023120880127
Validation loss: 2.0215086936950684

Epoch: 5| Step: 8
Training loss: 1.5351312160491943
Validation loss: 2.093045098807222

Epoch: 5| Step: 9
Training loss: 2.0919384956359863
Validation loss: 2.045176212505628

Epoch: 5| Step: 10
Training loss: 2.1913766860961914
Validation loss: 2.0595302979151406

Epoch: 251| Step: 0
Training loss: 2.4941518306732178
Validation loss: 2.061140296279743

Epoch: 5| Step: 1
Training loss: 2.246321201324463
Validation loss: 2.0738936444764495

Epoch: 5| Step: 2
Training loss: 1.9193153381347656
Validation loss: 2.116486146885862

Epoch: 5| Step: 3
Training loss: 2.038642168045044
Validation loss: 1.9978711887072491

Epoch: 5| Step: 4
Training loss: 2.480360746383667
Validation loss: 2.057957672303723

Epoch: 5| Step: 5
Training loss: 1.794434905052185
Validation loss: 2.045420838940528

Epoch: 5| Step: 6
Training loss: 1.670281171798706
Validation loss: 1.9901534741924656

Epoch: 5| Step: 7
Training loss: 2.115847110748291
Validation loss: 2.048332893720237

Epoch: 5| Step: 8
Training loss: 1.8837064504623413
Validation loss: 2.058370445364265

Epoch: 5| Step: 9
Training loss: 2.1388823986053467
Validation loss: 2.0703464438838344

Epoch: 5| Step: 10
Training loss: 3.1584630012512207
Validation loss: 2.070878832570968

Epoch: 252| Step: 0
Training loss: 1.7250782251358032
Validation loss: 2.0085005580738025

Epoch: 5| Step: 1
Training loss: 1.843416452407837
Validation loss: 1.985232642901841

Epoch: 5| Step: 2
Training loss: 1.7285913228988647
Validation loss: 2.052416983471122

Epoch: 5| Step: 3
Training loss: 1.8995943069458008
Validation loss: 1.9925600059570805

Epoch: 5| Step: 4
Training loss: 2.1016974449157715
Validation loss: 2.0213011182764524

Epoch: 5| Step: 5
Training loss: 2.4690892696380615
Validation loss: 2.022697732012759

Epoch: 5| Step: 6
Training loss: 2.17690110206604
Validation loss: 2.0669988047692085

Epoch: 5| Step: 7
Training loss: 2.6993823051452637
Validation loss: 1.9875209946786203

Epoch: 5| Step: 8
Training loss: 2.1555709838867188
Validation loss: 2.0490037164380475

Epoch: 5| Step: 9
Training loss: 2.365485429763794
Validation loss: 2.056047116556475

Epoch: 5| Step: 10
Training loss: 2.317066192626953
Validation loss: 2.0427370532866447

Epoch: 253| Step: 0
Training loss: 2.1196093559265137
Validation loss: 2.0021784843937045

Epoch: 5| Step: 1
Training loss: 2.843528985977173
Validation loss: 2.0389493985842635

Epoch: 5| Step: 2
Training loss: 2.186682939529419
Validation loss: 2.0714975710838073

Epoch: 5| Step: 3
Training loss: 2.2233593463897705
Validation loss: 2.1407296683198664

Epoch: 5| Step: 4
Training loss: 1.7942947149276733
Validation loss: 2.104095032138209

Epoch: 5| Step: 5
Training loss: 1.9588186740875244
Validation loss: 2.073299930941674

Epoch: 5| Step: 6
Training loss: 2.111989736557007
Validation loss: 2.0643620273118377

Epoch: 5| Step: 7
Training loss: 1.9630794525146484
Validation loss: 2.09543921742388

Epoch: 5| Step: 8
Training loss: 2.194553852081299
Validation loss: 2.0725632508595786

Epoch: 5| Step: 9
Training loss: 2.036912441253662
Validation loss: 2.037717237267443

Epoch: 5| Step: 10
Training loss: 2.442819118499756
Validation loss: 2.0211979855773268

Epoch: 254| Step: 0
Training loss: 1.686844825744629
Validation loss: 2.096831888280889

Epoch: 5| Step: 1
Training loss: 2.487961530685425
Validation loss: 2.087764516953499

Epoch: 5| Step: 2
Training loss: 2.5477070808410645
Validation loss: 2.124688028007425

Epoch: 5| Step: 3
Training loss: 1.6623424291610718
Validation loss: 2.0469783185630717

Epoch: 5| Step: 4
Training loss: 2.2015862464904785
Validation loss: 2.072512836866481

Epoch: 5| Step: 5
Training loss: 2.297163724899292
Validation loss: 2.0724031720110165

Epoch: 5| Step: 6
Training loss: 2.063533306121826
Validation loss: 2.065871460463411

Epoch: 5| Step: 7
Training loss: 1.8921054601669312
Validation loss: 2.0926073135868197

Epoch: 5| Step: 8
Training loss: 2.020038604736328
Validation loss: 2.0738337911585325

Epoch: 5| Step: 9
Training loss: 2.1929757595062256
Validation loss: 2.0709934516619612

Epoch: 5| Step: 10
Training loss: 2.6635303497314453
Validation loss: 2.129420780366467

Epoch: 255| Step: 0
Training loss: 1.7684189081192017
Validation loss: 2.095323404958171

Epoch: 5| Step: 1
Training loss: 2.5576138496398926
Validation loss: 2.1074512004852295

Epoch: 5| Step: 2
Training loss: 2.958312511444092
Validation loss: 2.1025195506311234

Epoch: 5| Step: 3
Training loss: 1.943281888961792
Validation loss: 2.053415257443664

Epoch: 5| Step: 4
Training loss: 2.121263265609741
Validation loss: 2.011845373338269

Epoch: 5| Step: 5
Training loss: 2.121102809906006
Validation loss: 2.085704199729427

Epoch: 5| Step: 6
Training loss: 2.08335018157959
Validation loss: 2.0591875391621746

Epoch: 5| Step: 7
Training loss: 2.6109166145324707
Validation loss: 2.117815352255298

Epoch: 5| Step: 8
Training loss: 2.497300624847412
Validation loss: 2.0153678117259854

Epoch: 5| Step: 9
Training loss: 1.6405200958251953
Validation loss: 2.0029313871937413

Epoch: 5| Step: 10
Training loss: 1.667219877243042
Validation loss: 1.9922646809649724

Epoch: 256| Step: 0
Training loss: 1.9643642902374268
Validation loss: 2.0176410700685237

Epoch: 5| Step: 1
Training loss: 1.7184960842132568
Validation loss: 2.0394052869530133

Epoch: 5| Step: 2
Training loss: 2.280646800994873
Validation loss: 1.998870417635928

Epoch: 5| Step: 3
Training loss: 2.4323296546936035
Validation loss: 2.0433724105999036

Epoch: 5| Step: 4
Training loss: 2.4535727500915527
Validation loss: 2.02106963434527

Epoch: 5| Step: 5
Training loss: 2.1896488666534424
Validation loss: 2.05605330774861

Epoch: 5| Step: 6
Training loss: 1.9883899688720703
Validation loss: 2.078934400312362

Epoch: 5| Step: 7
Training loss: 1.9986873865127563
Validation loss: 1.968868940107284

Epoch: 5| Step: 8
Training loss: 2.2488205432891846
Validation loss: 1.9944797908106158

Epoch: 5| Step: 9
Training loss: 1.7029508352279663
Validation loss: 2.077796451507076

Epoch: 5| Step: 10
Training loss: 2.5467844009399414
Validation loss: 2.0947472638981317

Epoch: 257| Step: 0
Training loss: 2.0921826362609863
Validation loss: 2.0394028925126597

Epoch: 5| Step: 1
Training loss: 2.013441562652588
Validation loss: 1.9895231672512588

Epoch: 5| Step: 2
Training loss: 2.0393319129943848
Validation loss: 2.028330515789729

Epoch: 5| Step: 3
Training loss: 2.5611915588378906
Validation loss: 2.0797106578785884

Epoch: 5| Step: 4
Training loss: 1.4480358362197876
Validation loss: 2.0398992761488883

Epoch: 5| Step: 5
Training loss: 2.9947099685668945
Validation loss: 1.9987001239612538

Epoch: 5| Step: 6
Training loss: 2.1832237243652344
Validation loss: 2.049239457294505

Epoch: 5| Step: 7
Training loss: 2.1197309494018555
Validation loss: 2.0369104070048176

Epoch: 5| Step: 8
Training loss: 1.5805835723876953
Validation loss: 2.059533155092629

Epoch: 5| Step: 9
Training loss: 2.09049654006958
Validation loss: 2.05448164222061

Epoch: 5| Step: 10
Training loss: 2.2905616760253906
Validation loss: 2.0566037470294583

Epoch: 258| Step: 0
Training loss: 2.0186357498168945
Validation loss: 2.0236541096882155

Epoch: 5| Step: 1
Training loss: 1.5072656869888306
Validation loss: 2.0965788620774464

Epoch: 5| Step: 2
Training loss: 2.0726940631866455
Validation loss: 2.0161689071245092

Epoch: 5| Step: 3
Training loss: 1.9186897277832031
Validation loss: 2.110465775253952

Epoch: 5| Step: 4
Training loss: 2.5921125411987305
Validation loss: 2.024173331517045

Epoch: 5| Step: 5
Training loss: 2.1292781829833984
Validation loss: 2.0593799391100482

Epoch: 5| Step: 6
Training loss: 2.260676860809326
Validation loss: 2.070246724672215

Epoch: 5| Step: 7
Training loss: 1.6834293603897095
Validation loss: 2.0425965760343816

Epoch: 5| Step: 8
Training loss: 2.1501874923706055
Validation loss: 2.07763078904921

Epoch: 5| Step: 9
Training loss: 2.6105830669403076
Validation loss: 2.0160993222267396

Epoch: 5| Step: 10
Training loss: 2.4446980953216553
Validation loss: 2.0412968512504333

Epoch: 259| Step: 0
Training loss: 2.4026055335998535
Validation loss: 2.0883361947151924

Epoch: 5| Step: 1
Training loss: 1.5038836002349854
Validation loss: 2.037155253912813

Epoch: 5| Step: 2
Training loss: 2.1479859352111816
Validation loss: 2.048963459589148

Epoch: 5| Step: 3
Training loss: 1.9405301809310913
Validation loss: 2.0723232787142516

Epoch: 5| Step: 4
Training loss: 2.1686697006225586
Validation loss: 2.0457546903241064

Epoch: 5| Step: 5
Training loss: 2.473468542098999
Validation loss: 2.099072607614661

Epoch: 5| Step: 6
Training loss: 1.7560077905654907
Validation loss: 2.0515945573006906

Epoch: 5| Step: 7
Training loss: 1.9849777221679688
Validation loss: 2.005120356877645

Epoch: 5| Step: 8
Training loss: 2.5389091968536377
Validation loss: 2.0675641413657897

Epoch: 5| Step: 9
Training loss: 2.5846331119537354
Validation loss: 2.0673381051709576

Epoch: 5| Step: 10
Training loss: 2.3237199783325195
Validation loss: 2.099674214598953

Epoch: 260| Step: 0
Training loss: 2.422841787338257
Validation loss: 2.034004557517267

Epoch: 5| Step: 1
Training loss: 2.856050491333008
Validation loss: 2.0273903159685034

Epoch: 5| Step: 2
Training loss: 2.682647228240967
Validation loss: 2.0691555289811987

Epoch: 5| Step: 3
Training loss: 1.7499803304672241
Validation loss: 2.0879673906551894

Epoch: 5| Step: 4
Training loss: 2.29827880859375
Validation loss: 2.0329670675339235

Epoch: 5| Step: 5
Training loss: 1.883827805519104
Validation loss: 2.0379129686663227

Epoch: 5| Step: 6
Training loss: 1.7111963033676147
Validation loss: 2.081996007632184

Epoch: 5| Step: 7
Training loss: 1.5981966257095337
Validation loss: 2.14320566064568

Epoch: 5| Step: 8
Training loss: 2.221458911895752
Validation loss: 2.049268848152571

Epoch: 5| Step: 9
Training loss: 2.344971179962158
Validation loss: 2.0114356317827777

Epoch: 5| Step: 10
Training loss: 1.517176866531372
Validation loss: 2.079400077942879

Epoch: 261| Step: 0
Training loss: 2.232577085494995
Validation loss: 2.069822789520346

Epoch: 5| Step: 1
Training loss: 2.190798282623291
Validation loss: 2.023524670190709

Epoch: 5| Step: 2
Training loss: 2.19353985786438
Validation loss: 2.0789784705767067

Epoch: 5| Step: 3
Training loss: 1.838667869567871
Validation loss: 2.0763863543028473

Epoch: 5| Step: 4
Training loss: 2.848714828491211
Validation loss: 2.0554672312992874

Epoch: 5| Step: 5
Training loss: 2.2749133110046387
Validation loss: 2.036704001888152

Epoch: 5| Step: 6
Training loss: 2.4752633571624756
Validation loss: 2.0220257505293815

Epoch: 5| Step: 7
Training loss: 1.951480507850647
Validation loss: 2.1028538801336802

Epoch: 5| Step: 8
Training loss: 1.6473442316055298
Validation loss: 2.0911592924466698

Epoch: 5| Step: 9
Training loss: 1.9944219589233398
Validation loss: 2.0374213982653875

Epoch: 5| Step: 10
Training loss: 2.016721725463867
Validation loss: 2.0773994409909813

Epoch: 262| Step: 0
Training loss: 2.517334461212158
Validation loss: 2.056131221914804

Epoch: 5| Step: 1
Training loss: 1.5108654499053955
Validation loss: 2.0717962044541554

Epoch: 5| Step: 2
Training loss: 1.6959521770477295
Validation loss: 2.003972481655818

Epoch: 5| Step: 3
Training loss: 1.6423542499542236
Validation loss: 2.0603329917436004

Epoch: 5| Step: 4
Training loss: 2.3171260356903076
Validation loss: 2.063094546717982

Epoch: 5| Step: 5
Training loss: 2.3993587493896484
Validation loss: 1.9968988177596882

Epoch: 5| Step: 6
Training loss: 2.5893702507019043
Validation loss: 2.010322663091844

Epoch: 5| Step: 7
Training loss: 2.2084431648254395
Validation loss: 2.0582920889700613

Epoch: 5| Step: 8
Training loss: 2.139235496520996
Validation loss: 2.0400577822039203

Epoch: 5| Step: 9
Training loss: 2.2593624591827393
Validation loss: 2.096223299221326

Epoch: 5| Step: 10
Training loss: 2.295095682144165
Validation loss: 2.088080290825136

Epoch: 263| Step: 0
Training loss: 2.0862839221954346
Validation loss: 2.007967015748383

Epoch: 5| Step: 1
Training loss: 2.7928168773651123
Validation loss: 2.0130244237120434

Epoch: 5| Step: 2
Training loss: 2.384793281555176
Validation loss: 2.0910545472175843

Epoch: 5| Step: 3
Training loss: 1.8677088022232056
Validation loss: 2.042031911111647

Epoch: 5| Step: 4
Training loss: 2.4830422401428223
Validation loss: 2.0030963241413073

Epoch: 5| Step: 5
Training loss: 1.8625071048736572
Validation loss: 2.0546558390381517

Epoch: 5| Step: 6
Training loss: 2.070758104324341
Validation loss: 2.00755282884003

Epoch: 5| Step: 7
Training loss: 1.834403395652771
Validation loss: 2.02716996336496

Epoch: 5| Step: 8
Training loss: 2.215759038925171
Validation loss: 2.1014380557562715

Epoch: 5| Step: 9
Training loss: 2.0863070487976074
Validation loss: 2.1155150910859466

Epoch: 5| Step: 10
Training loss: 1.9846410751342773
Validation loss: 2.0762221890111126

Epoch: 264| Step: 0
Training loss: 2.593489408493042
Validation loss: 2.047935926786033

Epoch: 5| Step: 1
Training loss: 2.7472057342529297
Validation loss: 2.0734151178790676

Epoch: 5| Step: 2
Training loss: 1.9023802280426025
Validation loss: 2.0411591196572907

Epoch: 5| Step: 3
Training loss: 1.9784761667251587
Validation loss: 2.0190847099468274

Epoch: 5| Step: 4
Training loss: 1.9331753253936768
Validation loss: 2.0293020458631617

Epoch: 5| Step: 5
Training loss: 1.6576656103134155
Validation loss: 2.0041393285156577

Epoch: 5| Step: 6
Training loss: 1.9860661029815674
Validation loss: 2.0642198260112474

Epoch: 5| Step: 7
Training loss: 1.812389612197876
Validation loss: 2.092557712267804

Epoch: 5| Step: 8
Training loss: 2.9141314029693604
Validation loss: 2.0485064521912606

Epoch: 5| Step: 9
Training loss: 2.2818944454193115
Validation loss: 2.024629069912818

Epoch: 5| Step: 10
Training loss: 1.6404845714569092
Validation loss: 2.064086224443169

Epoch: 265| Step: 0
Training loss: 2.213364839553833
Validation loss: 1.9928232226320493

Epoch: 5| Step: 1
Training loss: 2.1343467235565186
Validation loss: 1.9801723111060359

Epoch: 5| Step: 2
Training loss: 2.507187604904175
Validation loss: 2.032279945188953

Epoch: 5| Step: 3
Training loss: 2.8940138816833496
Validation loss: 2.0609674761372228

Epoch: 5| Step: 4
Training loss: 2.045900344848633
Validation loss: 2.050460769284156

Epoch: 5| Step: 5
Training loss: 1.791892647743225
Validation loss: 2.015928946515565

Epoch: 5| Step: 6
Training loss: 2.2702221870422363
Validation loss: 2.048412533216579

Epoch: 5| Step: 7
Training loss: 1.76620614528656
Validation loss: 1.9783667748974216

Epoch: 5| Step: 8
Training loss: 2.277900218963623
Validation loss: 2.013423929932297

Epoch: 5| Step: 9
Training loss: 1.8811302185058594
Validation loss: 2.058115447721174

Epoch: 5| Step: 10
Training loss: 1.4375674724578857
Validation loss: 2.0489354005423923

Epoch: 266| Step: 0
Training loss: 2.379063129425049
Validation loss: 2.014831277631944

Epoch: 5| Step: 1
Training loss: 1.5303027629852295
Validation loss: 2.0744768624664633

Epoch: 5| Step: 2
Training loss: 2.646981716156006
Validation loss: 2.0668689896983485

Epoch: 5| Step: 3
Training loss: 2.4819910526275635
Validation loss: 2.026267595188592

Epoch: 5| Step: 4
Training loss: 2.461017608642578
Validation loss: 2.0214606279967935

Epoch: 5| Step: 5
Training loss: 2.4053070545196533
Validation loss: 2.057085980651199

Epoch: 5| Step: 6
Training loss: 1.7433669567108154
Validation loss: 2.073236228317343

Epoch: 5| Step: 7
Training loss: 1.8701400756835938
Validation loss: 2.0233692020498295

Epoch: 5| Step: 8
Training loss: 2.1295242309570312
Validation loss: 2.0812309813755814

Epoch: 5| Step: 9
Training loss: 1.8567516803741455
Validation loss: 2.0540715968737038

Epoch: 5| Step: 10
Training loss: 2.2724015712738037
Validation loss: 2.0151097774505615

Epoch: 267| Step: 0
Training loss: 1.772806167602539
Validation loss: 2.037073237921602

Epoch: 5| Step: 1
Training loss: 2.4180705547332764
Validation loss: 1.9624331241012902

Epoch: 5| Step: 2
Training loss: 1.3655935525894165
Validation loss: 2.028539091028193

Epoch: 5| Step: 3
Training loss: 2.2668471336364746
Validation loss: 2.028566687337814

Epoch: 5| Step: 4
Training loss: 2.4322566986083984
Validation loss: 2.015631450119839

Epoch: 5| Step: 5
Training loss: 2.3234198093414307
Validation loss: 2.0558523003773024

Epoch: 5| Step: 6
Training loss: 2.462845802307129
Validation loss: 1.9992172423229422

Epoch: 5| Step: 7
Training loss: 2.16133189201355
Validation loss: 2.054473784662062

Epoch: 5| Step: 8
Training loss: 2.6671743392944336
Validation loss: 2.1103865074855026

Epoch: 5| Step: 9
Training loss: 2.1874377727508545
Validation loss: 2.0216667959767003

Epoch: 5| Step: 10
Training loss: 1.2094773054122925
Validation loss: 2.0563732834272486

Epoch: 268| Step: 0
Training loss: 2.481174945831299
Validation loss: 2.013096204368017

Epoch: 5| Step: 1
Training loss: 2.5379440784454346
Validation loss: 2.0768803319623395

Epoch: 5| Step: 2
Training loss: 1.4361679553985596
Validation loss: 2.0548515653097503

Epoch: 5| Step: 3
Training loss: 1.8377017974853516
Validation loss: 2.044379166377488

Epoch: 5| Step: 4
Training loss: 1.9356132745742798
Validation loss: 2.0800803630582747

Epoch: 5| Step: 5
Training loss: 2.0198168754577637
Validation loss: 2.0133580571861676

Epoch: 5| Step: 6
Training loss: 2.259445905685425
Validation loss: 2.047916980199916

Epoch: 5| Step: 7
Training loss: 2.449159860610962
Validation loss: 2.060009346213392

Epoch: 5| Step: 8
Training loss: 2.136342763900757
Validation loss: 2.0759506469131797

Epoch: 5| Step: 9
Training loss: 1.8821687698364258
Validation loss: 2.0264053165271716

Epoch: 5| Step: 10
Training loss: 2.274165153503418
Validation loss: 2.006038345316405

Epoch: 269| Step: 0
Training loss: 2.135068655014038
Validation loss: 2.055676498720723

Epoch: 5| Step: 1
Training loss: 2.234083890914917
Validation loss: 2.0788550748619983

Epoch: 5| Step: 2
Training loss: 1.4684542417526245
Validation loss: 2.071454276320755

Epoch: 5| Step: 3
Training loss: 1.505710482597351
Validation loss: 2.06789501508077

Epoch: 5| Step: 4
Training loss: 2.4054925441741943
Validation loss: 2.0322792735151065

Epoch: 5| Step: 5
Training loss: 2.4729957580566406
Validation loss: 2.0356653967211322

Epoch: 5| Step: 6
Training loss: 1.9766327142715454
Validation loss: 1.9999234522542646

Epoch: 5| Step: 7
Training loss: 2.099802255630493
Validation loss: 2.0434439182281494

Epoch: 5| Step: 8
Training loss: 2.3733532428741455
Validation loss: 2.057663409940658

Epoch: 5| Step: 9
Training loss: 2.275869846343994
Validation loss: 2.071899224353093

Epoch: 5| Step: 10
Training loss: 2.130314588546753
Validation loss: 2.0615597001967894

Epoch: 270| Step: 0
Training loss: 1.9782495498657227
Validation loss: 2.0689592797269105

Epoch: 5| Step: 1
Training loss: 2.1290371417999268
Validation loss: 2.1003172166885866

Epoch: 5| Step: 2
Training loss: 2.2817342281341553
Validation loss: 2.028094712124076

Epoch: 5| Step: 3
Training loss: 2.5576424598693848
Validation loss: 2.072149271606117

Epoch: 5| Step: 4
Training loss: 1.961941123008728
Validation loss: 2.077037790770172

Epoch: 5| Step: 5
Training loss: 1.701879858970642
Validation loss: 2.030949088834947

Epoch: 5| Step: 6
Training loss: 2.350611686706543
Validation loss: 2.0413366171621505

Epoch: 5| Step: 7
Training loss: 2.2001192569732666
Validation loss: 1.997645378112793

Epoch: 5| Step: 8
Training loss: 1.7943570613861084
Validation loss: 2.0381579552927325

Epoch: 5| Step: 9
Training loss: 1.8353172540664673
Validation loss: 2.1198919562883276

Epoch: 5| Step: 10
Training loss: 2.2873172760009766
Validation loss: 2.0102021271182644

Epoch: 271| Step: 0
Training loss: 2.107672929763794
Validation loss: 2.090964477549317

Epoch: 5| Step: 1
Training loss: 1.4823169708251953
Validation loss: 2.0499808634481123

Epoch: 5| Step: 2
Training loss: 3.339272975921631
Validation loss: 2.0021130679756083

Epoch: 5| Step: 3
Training loss: 1.8094842433929443
Validation loss: 2.055441846129715

Epoch: 5| Step: 4
Training loss: 2.1343209743499756
Validation loss: 2.0352638600974955

Epoch: 5| Step: 5
Training loss: 2.179741382598877
Validation loss: 2.0099531335215413

Epoch: 5| Step: 6
Training loss: 2.274256944656372
Validation loss: 2.039214147034512

Epoch: 5| Step: 7
Training loss: 2.020758867263794
Validation loss: 1.9905167651432816

Epoch: 5| Step: 8
Training loss: 2.199361801147461
Validation loss: 2.0044512287262948

Epoch: 5| Step: 9
Training loss: 1.9148149490356445
Validation loss: 2.0760267601218274

Epoch: 5| Step: 10
Training loss: 1.9744791984558105
Validation loss: 2.041497480484747

Epoch: 272| Step: 0
Training loss: 2.713815927505493
Validation loss: 2.0375197292656027

Epoch: 5| Step: 1
Training loss: 1.8621699810028076
Validation loss: 2.0071920938389276

Epoch: 5| Step: 2
Training loss: 2.497134208679199
Validation loss: 2.026625584530574

Epoch: 5| Step: 3
Training loss: 2.1631345748901367
Validation loss: 1.9861353507605932

Epoch: 5| Step: 4
Training loss: 2.51918625831604
Validation loss: 2.0155280405475247

Epoch: 5| Step: 5
Training loss: 1.824723243713379
Validation loss: 1.9979794192057785

Epoch: 5| Step: 6
Training loss: 1.562374234199524
Validation loss: 2.029723200746762

Epoch: 5| Step: 7
Training loss: 1.8481184244155884
Validation loss: 2.0736380956506215

Epoch: 5| Step: 8
Training loss: 1.9550716876983643
Validation loss: 2.012458106522919

Epoch: 5| Step: 9
Training loss: 1.6938724517822266
Validation loss: 2.049380374211137

Epoch: 5| Step: 10
Training loss: 2.5973567962646484
Validation loss: 2.0733685826742523

Epoch: 273| Step: 0
Training loss: 2.2377333641052246
Validation loss: 2.071398595327972

Epoch: 5| Step: 1
Training loss: 2.438096761703491
Validation loss: 2.0965382142733504

Epoch: 5| Step: 2
Training loss: 2.070655107498169
Validation loss: 2.112057155178439

Epoch: 5| Step: 3
Training loss: 2.370506525039673
Validation loss: 2.0449450246749388

Epoch: 5| Step: 4
Training loss: 1.5794410705566406
Validation loss: 2.050939089508467

Epoch: 5| Step: 5
Training loss: 2.505030393600464
Validation loss: 2.046916736069546

Epoch: 5| Step: 6
Training loss: 1.5616910457611084
Validation loss: 2.084730250861055

Epoch: 5| Step: 7
Training loss: 2.428176164627075
Validation loss: 2.049784069420189

Epoch: 5| Step: 8
Training loss: 2.076263904571533
Validation loss: 2.1102829299947268

Epoch: 5| Step: 9
Training loss: 2.0877203941345215
Validation loss: 2.124030887439687

Epoch: 5| Step: 10
Training loss: 2.152822971343994
Validation loss: 2.0285571134218605

Epoch: 274| Step: 0
Training loss: 2.368131637573242
Validation loss: 2.0204522519983272

Epoch: 5| Step: 1
Training loss: 2.3712210655212402
Validation loss: 2.108195053633823

Epoch: 5| Step: 2
Training loss: 2.137507438659668
Validation loss: 2.090129124220981

Epoch: 5| Step: 3
Training loss: 2.6268725395202637
Validation loss: 2.048647819026824

Epoch: 5| Step: 4
Training loss: 1.9241443872451782
Validation loss: 2.120111629527102

Epoch: 5| Step: 5
Training loss: 2.08410906791687
Validation loss: 2.0249977034907185

Epoch: 5| Step: 6
Training loss: 1.6488440036773682
Validation loss: 2.0501177567307667

Epoch: 5| Step: 7
Training loss: 2.061519145965576
Validation loss: 2.016156129939582

Epoch: 5| Step: 8
Training loss: 2.460791826248169
Validation loss: 2.0521490881519933

Epoch: 5| Step: 9
Training loss: 2.2899391651153564
Validation loss: 2.103633020513801

Epoch: 5| Step: 10
Training loss: 1.7064834833145142
Validation loss: 2.081601773538897

Epoch: 275| Step: 0
Training loss: 1.4345691204071045
Validation loss: 2.042808896751814

Epoch: 5| Step: 1
Training loss: 2.228273868560791
Validation loss: 2.029370710413943

Epoch: 5| Step: 2
Training loss: 2.5009169578552246
Validation loss: 2.019972025707204

Epoch: 5| Step: 3
Training loss: 2.1562294960021973
Validation loss: 2.067239135824224

Epoch: 5| Step: 4
Training loss: 2.1605539321899414
Validation loss: 2.027112845451601

Epoch: 5| Step: 5
Training loss: 2.295876979827881
Validation loss: 2.036541977236348

Epoch: 5| Step: 6
Training loss: 3.059954881668091
Validation loss: 2.0944716956025813

Epoch: 5| Step: 7
Training loss: 1.838436484336853
Validation loss: 2.0933603138052006

Epoch: 5| Step: 8
Training loss: 1.6235347986221313
Validation loss: 2.09306263923645

Epoch: 5| Step: 9
Training loss: 2.1264185905456543
Validation loss: 2.069944135604366

Epoch: 5| Step: 10
Training loss: 2.070643186569214
Validation loss: 2.0505529936923774

Epoch: 276| Step: 0
Training loss: 1.5315061807632446
Validation loss: 2.029190489040908

Epoch: 5| Step: 1
Training loss: 2.0028774738311768
Validation loss: 1.9989607654592043

Epoch: 5| Step: 2
Training loss: 2.2460544109344482
Validation loss: 2.0675699890300794

Epoch: 5| Step: 3
Training loss: 2.666189193725586
Validation loss: 2.0609396760181715

Epoch: 5| Step: 4
Training loss: 2.323000431060791
Validation loss: 2.046608219864548

Epoch: 5| Step: 5
Training loss: 2.324568271636963
Validation loss: 2.0261628448322253

Epoch: 5| Step: 6
Training loss: 2.2570598125457764
Validation loss: 2.007677574311533

Epoch: 5| Step: 7
Training loss: 2.3983821868896484
Validation loss: 2.0277692476908364

Epoch: 5| Step: 8
Training loss: 2.2540900707244873
Validation loss: 2.060512178687639

Epoch: 5| Step: 9
Training loss: 1.793975591659546
Validation loss: 2.0995001408361618

Epoch: 5| Step: 10
Training loss: 1.38260018825531
Validation loss: 2.066039744243827

Epoch: 277| Step: 0
Training loss: 2.476515769958496
Validation loss: 2.0449973921622

Epoch: 5| Step: 1
Training loss: 1.8880701065063477
Validation loss: 2.0983115626919653

Epoch: 5| Step: 2
Training loss: 2.271357297897339
Validation loss: 2.058528207963513

Epoch: 5| Step: 3
Training loss: 1.6902475357055664
Validation loss: 2.0570413745859617

Epoch: 5| Step: 4
Training loss: 2.3676247596740723
Validation loss: 2.0623574923443537

Epoch: 5| Step: 5
Training loss: 2.352273464202881
Validation loss: 2.029736521423504

Epoch: 5| Step: 6
Training loss: 1.6399908065795898
Validation loss: 2.060389139318979

Epoch: 5| Step: 7
Training loss: 1.8229690790176392
Validation loss: 2.078418735534914

Epoch: 5| Step: 8
Training loss: 2.6449637413024902
Validation loss: 2.0508095961745068

Epoch: 5| Step: 9
Training loss: 1.6888841390609741
Validation loss: 2.07177294710631

Epoch: 5| Step: 10
Training loss: 2.3595447540283203
Validation loss: 2.0297204961058912

Epoch: 278| Step: 0
Training loss: 1.9482414722442627
Validation loss: 2.0976826067893737

Epoch: 5| Step: 1
Training loss: 1.9437564611434937
Validation loss: 2.0040486948464507

Epoch: 5| Step: 2
Training loss: 2.0934853553771973
Validation loss: 2.0374596016381377

Epoch: 5| Step: 3
Training loss: 2.5921924114227295
Validation loss: 2.026893413195046

Epoch: 5| Step: 4
Training loss: 2.519989490509033
Validation loss: 2.0779389104535504

Epoch: 5| Step: 5
Training loss: 2.7577898502349854
Validation loss: 2.012491960679331

Epoch: 5| Step: 6
Training loss: 1.6122697591781616
Validation loss: 2.04363727313216

Epoch: 5| Step: 7
Training loss: 2.294766426086426
Validation loss: 2.061780507846545

Epoch: 5| Step: 8
Training loss: 2.1691009998321533
Validation loss: 2.072699018703994

Epoch: 5| Step: 9
Training loss: 1.9809589385986328
Validation loss: 2.0418344210552912

Epoch: 5| Step: 10
Training loss: 1.5060768127441406
Validation loss: 2.090011642825219

Epoch: 279| Step: 0
Training loss: 2.2470905780792236
Validation loss: 2.109496307629411

Epoch: 5| Step: 1
Training loss: 2.334388256072998
Validation loss: 2.0360781697816748

Epoch: 5| Step: 2
Training loss: 1.935093641281128
Validation loss: 2.0378710095600416

Epoch: 5| Step: 3
Training loss: 1.8836028575897217
Validation loss: 2.0594376543516755

Epoch: 5| Step: 4
Training loss: 2.4190707206726074
Validation loss: 2.0008233670265443

Epoch: 5| Step: 5
Training loss: 1.953721284866333
Validation loss: 2.025104888023869

Epoch: 5| Step: 6
Training loss: 1.7560628652572632
Validation loss: 2.062540856740808

Epoch: 5| Step: 7
Training loss: 2.583352565765381
Validation loss: 2.0398052302739953

Epoch: 5| Step: 8
Training loss: 2.390324592590332
Validation loss: 2.0379460537305443

Epoch: 5| Step: 9
Training loss: 1.8876365423202515
Validation loss: 1.9666011974375734

Epoch: 5| Step: 10
Training loss: 1.9138224124908447
Validation loss: 2.014464009192682

Epoch: 280| Step: 0
Training loss: 2.580899715423584
Validation loss: 2.0671502646579536

Epoch: 5| Step: 1
Training loss: 2.470662832260132
Validation loss: 2.035439993745537

Epoch: 5| Step: 2
Training loss: 2.3708457946777344
Validation loss: 2.0728171589553996

Epoch: 5| Step: 3
Training loss: 1.4754831790924072
Validation loss: 2.046412721756966

Epoch: 5| Step: 4
Training loss: 2.418543815612793
Validation loss: 2.0163811240144955

Epoch: 5| Step: 5
Training loss: 2.062685489654541
Validation loss: 1.9972703943970382

Epoch: 5| Step: 6
Training loss: 2.4912593364715576
Validation loss: 2.0438706246755456

Epoch: 5| Step: 7
Training loss: 1.731298804283142
Validation loss: 2.0999772933221634

Epoch: 5| Step: 8
Training loss: 2.0327985286712646
Validation loss: 2.0453988557220786

Epoch: 5| Step: 9
Training loss: 1.5977524518966675
Validation loss: 2.003587172877404

Epoch: 5| Step: 10
Training loss: 2.054460048675537
Validation loss: 2.0890640520280406

Epoch: 281| Step: 0
Training loss: 2.11887788772583
Validation loss: 2.051182016249626

Epoch: 5| Step: 1
Training loss: 2.3924810886383057
Validation loss: 2.079503528533443

Epoch: 5| Step: 2
Training loss: 2.2020151615142822
Validation loss: 1.9770689087529336

Epoch: 5| Step: 3
Training loss: 2.0529911518096924
Validation loss: 2.047498021074521

Epoch: 5| Step: 4
Training loss: 2.392604351043701
Validation loss: 2.115943490817983

Epoch: 5| Step: 5
Training loss: 1.9198963642120361
Validation loss: 2.0300828923461256

Epoch: 5| Step: 6
Training loss: 2.283700466156006
Validation loss: 2.0673430017245713

Epoch: 5| Step: 7
Training loss: 1.9331687688827515
Validation loss: 2.0181965110122517

Epoch: 5| Step: 8
Training loss: 2.0370898246765137
Validation loss: 2.0955391776177192

Epoch: 5| Step: 9
Training loss: 1.7815845012664795
Validation loss: 2.0601759777274182

Epoch: 5| Step: 10
Training loss: 2.6839993000030518
Validation loss: 2.0536056526245607

Epoch: 282| Step: 0
Training loss: 2.191800594329834
Validation loss: 2.080470026180308

Epoch: 5| Step: 1
Training loss: 1.7488527297973633
Validation loss: 2.078557381065943

Epoch: 5| Step: 2
Training loss: 2.183345317840576
Validation loss: 2.121384811657731

Epoch: 5| Step: 3
Training loss: 2.0466442108154297
Validation loss: 2.034584271010532

Epoch: 5| Step: 4
Training loss: 2.3000197410583496
Validation loss: 2.075389039131903

Epoch: 5| Step: 5
Training loss: 2.384650707244873
Validation loss: 2.055668197652345

Epoch: 5| Step: 6
Training loss: 1.7845144271850586
Validation loss: 2.050744154120004

Epoch: 5| Step: 7
Training loss: 1.6920130252838135
Validation loss: 2.0754713037962556

Epoch: 5| Step: 8
Training loss: 2.1813788414001465
Validation loss: 2.0421070104004233

Epoch: 5| Step: 9
Training loss: 2.1163172721862793
Validation loss: 2.087827085166849

Epoch: 5| Step: 10
Training loss: 2.6331117153167725
Validation loss: 2.0594909357768234

Epoch: 283| Step: 0
Training loss: 2.174802303314209
Validation loss: 2.1026542468737532

Epoch: 5| Step: 1
Training loss: 2.3782763481140137
Validation loss: 2.088576369388129

Epoch: 5| Step: 2
Training loss: 1.6863491535186768
Validation loss: 2.045333754631781

Epoch: 5| Step: 3
Training loss: 2.476064443588257
Validation loss: 2.0181543109237507

Epoch: 5| Step: 4
Training loss: 2.3512566089630127
Validation loss: 2.0499050412126767

Epoch: 5| Step: 5
Training loss: 1.8789905309677124
Validation loss: 2.040526831021873

Epoch: 5| Step: 6
Training loss: 1.2715492248535156
Validation loss: 2.0581302194185156

Epoch: 5| Step: 7
Training loss: 2.282776117324829
Validation loss: 2.0867807967688448

Epoch: 5| Step: 8
Training loss: 2.5414135456085205
Validation loss: 2.0405590559846614

Epoch: 5| Step: 9
Training loss: 1.8470966815948486
Validation loss: 2.0353472155909382

Epoch: 5| Step: 10
Training loss: 1.8357889652252197
Validation loss: 1.9963411528577086

Epoch: 284| Step: 0
Training loss: 1.9225984811782837
Validation loss: 2.0743860454969507

Epoch: 5| Step: 1
Training loss: 2.2106518745422363
Validation loss: 2.0930357979189966

Epoch: 5| Step: 2
Training loss: 2.9043824672698975
Validation loss: 2.059423690201134

Epoch: 5| Step: 3
Training loss: 2.2495007514953613
Validation loss: 2.0432270085939797

Epoch: 5| Step: 4
Training loss: 2.0807909965515137
Validation loss: 2.028356182959772

Epoch: 5| Step: 5
Training loss: 2.270369052886963
Validation loss: 2.010029267239314

Epoch: 5| Step: 6
Training loss: 1.7139095067977905
Validation loss: 2.0597393640907864

Epoch: 5| Step: 7
Training loss: 1.5481736660003662
Validation loss: 2.0536314172129475

Epoch: 5| Step: 8
Training loss: 2.177142858505249
Validation loss: 2.0641372050008466

Epoch: 5| Step: 9
Training loss: 1.6883456707000732
Validation loss: 2.0007207739737725

Epoch: 5| Step: 10
Training loss: 2.5431137084960938
Validation loss: 2.0941033440251506

Epoch: 285| Step: 0
Training loss: 1.820519208908081
Validation loss: 2.0309831570553523

Epoch: 5| Step: 1
Training loss: 1.8094837665557861
Validation loss: 1.9788304323791175

Epoch: 5| Step: 2
Training loss: 2.04345703125
Validation loss: 2.006721576054891

Epoch: 5| Step: 3
Training loss: 1.9538707733154297
Validation loss: 2.018635190943236

Epoch: 5| Step: 4
Training loss: 2.3411667346954346
Validation loss: 2.017275398777377

Epoch: 5| Step: 5
Training loss: 1.7381185293197632
Validation loss: 2.0331405157684

Epoch: 5| Step: 6
Training loss: 2.815711259841919
Validation loss: 2.0014962944933163

Epoch: 5| Step: 7
Training loss: 2.146991491317749
Validation loss: 1.9823613935901272

Epoch: 5| Step: 8
Training loss: 2.0550849437713623
Validation loss: 2.075297685079677

Epoch: 5| Step: 9
Training loss: 2.2268826961517334
Validation loss: 1.997758633346968

Epoch: 5| Step: 10
Training loss: 2.034381866455078
Validation loss: 2.0754488065678585

Epoch: 286| Step: 0
Training loss: 2.6217353343963623
Validation loss: 1.9644007041890135

Epoch: 5| Step: 1
Training loss: 2.0264034271240234
Validation loss: 2.0694072490097373

Epoch: 5| Step: 2
Training loss: 1.731762170791626
Validation loss: 2.0679138245121127

Epoch: 5| Step: 3
Training loss: 2.232520580291748
Validation loss: 2.030594115616173

Epoch: 5| Step: 4
Training loss: 2.620980978012085
Validation loss: 2.0274966673184465

Epoch: 5| Step: 5
Training loss: 2.4188694953918457
Validation loss: 2.074752200034357

Epoch: 5| Step: 6
Training loss: 2.1230926513671875
Validation loss: 2.082695504670502

Epoch: 5| Step: 7
Training loss: 1.8772258758544922
Validation loss: 2.0674620443774807

Epoch: 5| Step: 8
Training loss: 2.0018699169158936
Validation loss: 2.110125554505215

Epoch: 5| Step: 9
Training loss: 1.583611249923706
Validation loss: 2.0689793684149302

Epoch: 5| Step: 10
Training loss: 2.1292881965637207
Validation loss: 2.0598823203835437

Epoch: 287| Step: 0
Training loss: 2.176276922225952
Validation loss: 2.0526745703912552

Epoch: 5| Step: 1
Training loss: 1.9761987924575806
Validation loss: 2.0030845775399158

Epoch: 5| Step: 2
Training loss: 1.3797266483306885
Validation loss: 2.0051230410093903

Epoch: 5| Step: 3
Training loss: 1.9408155679702759
Validation loss: 2.0346798948062363

Epoch: 5| Step: 4
Training loss: 1.948175072669983
Validation loss: 2.1218737017723823

Epoch: 5| Step: 5
Training loss: 2.402505397796631
Validation loss: 1.9944486925678868

Epoch: 5| Step: 6
Training loss: 1.8635671138763428
Validation loss: 2.0488220440444125

Epoch: 5| Step: 7
Training loss: 2.576805353164673
Validation loss: 2.0489482290001324

Epoch: 5| Step: 8
Training loss: 2.6054835319519043
Validation loss: 2.052016632531279

Epoch: 5| Step: 9
Training loss: 2.481916666030884
Validation loss: 2.0523369748105287

Epoch: 5| Step: 10
Training loss: 1.916393518447876
Validation loss: 2.0373733684580815

Epoch: 288| Step: 0
Training loss: 1.9055531024932861
Validation loss: 2.028179012319093

Epoch: 5| Step: 1
Training loss: 1.8688167333602905
Validation loss: 2.061006502438617

Epoch: 5| Step: 2
Training loss: 1.8219120502471924
Validation loss: 2.04351943795399

Epoch: 5| Step: 3
Training loss: 2.983232259750366
Validation loss: 2.066048232457971

Epoch: 5| Step: 4
Training loss: 1.8871738910675049
Validation loss: 2.112138286713631

Epoch: 5| Step: 5
Training loss: 2.716707229614258
Validation loss: 2.0370237058208835

Epoch: 5| Step: 6
Training loss: 1.9629570245742798
Validation loss: 2.0531425399164998

Epoch: 5| Step: 7
Training loss: 1.415774941444397
Validation loss: 2.0261808646622526

Epoch: 5| Step: 8
Training loss: 2.116788625717163
Validation loss: 2.036850453704916

Epoch: 5| Step: 9
Training loss: 1.885408639907837
Validation loss: 2.0553483322102535

Epoch: 5| Step: 10
Training loss: 2.5200726985931396
Validation loss: 2.050791560962636

Epoch: 289| Step: 0
Training loss: 2.8543667793273926
Validation loss: 2.0527391766989105

Epoch: 5| Step: 1
Training loss: 2.1636948585510254
Validation loss: 2.0771455149496756

Epoch: 5| Step: 2
Training loss: 2.1630241870880127
Validation loss: 2.0494994219913276

Epoch: 5| Step: 3
Training loss: 1.8016226291656494
Validation loss: 2.08264422416687

Epoch: 5| Step: 4
Training loss: 2.1396548748016357
Validation loss: 2.0637816690629527

Epoch: 5| Step: 5
Training loss: 2.2392821311950684
Validation loss: 2.072702423218758

Epoch: 5| Step: 6
Training loss: 2.1598401069641113
Validation loss: 2.0729905456625004

Epoch: 5| Step: 7
Training loss: 1.1151082515716553
Validation loss: 2.081785983936761

Epoch: 5| Step: 8
Training loss: 2.2135119438171387
Validation loss: 2.04566240438851

Epoch: 5| Step: 9
Training loss: 1.9319076538085938
Validation loss: 2.065060718085176

Epoch: 5| Step: 10
Training loss: 2.137242317199707
Validation loss: 2.0675947127803678

Epoch: 290| Step: 0
Training loss: 2.0532774925231934
Validation loss: 2.061922473292197

Epoch: 5| Step: 1
Training loss: 1.9433969259262085
Validation loss: 2.020755657585718

Epoch: 5| Step: 2
Training loss: 1.658974051475525
Validation loss: 2.1370761830319642

Epoch: 5| Step: 3
Training loss: 2.8222012519836426
Validation loss: 2.0241848627726235

Epoch: 5| Step: 4
Training loss: 1.2278181314468384
Validation loss: 2.0454219336150796

Epoch: 5| Step: 5
Training loss: 2.5995113849639893
Validation loss: 2.045771788525325

Epoch: 5| Step: 6
Training loss: 2.3619112968444824
Validation loss: 2.0497231086095176

Epoch: 5| Step: 7
Training loss: 2.2138445377349854
Validation loss: 2.030642201823573

Epoch: 5| Step: 8
Training loss: 1.9811351299285889
Validation loss: 2.0219017151863343

Epoch: 5| Step: 9
Training loss: 2.3177483081817627
Validation loss: 2.0482545642442602

Epoch: 5| Step: 10
Training loss: 2.1862897872924805
Validation loss: 2.0223947904443227

Epoch: 291| Step: 0
Training loss: 1.8989375829696655
Validation loss: 2.0330568564835416

Epoch: 5| Step: 1
Training loss: 2.0861423015594482
Validation loss: 2.0756344410680954

Epoch: 5| Step: 2
Training loss: 2.3370940685272217
Validation loss: 2.055751044263122

Epoch: 5| Step: 3
Training loss: 2.3961379528045654
Validation loss: 1.9690950429567726

Epoch: 5| Step: 4
Training loss: 1.7088066339492798
Validation loss: 2.0223323350311606

Epoch: 5| Step: 5
Training loss: 2.4938671588897705
Validation loss: 2.0381305435652375

Epoch: 5| Step: 6
Training loss: 2.014716625213623
Validation loss: 2.0271542969570366

Epoch: 5| Step: 7
Training loss: 1.9658063650131226
Validation loss: 2.0071638194463586

Epoch: 5| Step: 8
Training loss: 1.9857231378555298
Validation loss: 2.022892523837346

Epoch: 5| Step: 9
Training loss: 1.9722957611083984
Validation loss: 2.072096847718762

Epoch: 5| Step: 10
Training loss: 1.718414068222046
Validation loss: 2.0580979598465787

Epoch: 292| Step: 0
Training loss: 2.0875191688537598
Validation loss: 2.074162983125256

Epoch: 5| Step: 1
Training loss: 1.9435065984725952
Validation loss: 2.0173961116421606

Epoch: 5| Step: 2
Training loss: 2.0640709400177
Validation loss: 2.0690488994762464

Epoch: 5| Step: 3
Training loss: 1.8780425786972046
Validation loss: 1.9953447106064006

Epoch: 5| Step: 4
Training loss: 1.7978613376617432
Validation loss: 2.0968896086497972

Epoch: 5| Step: 5
Training loss: 2.5143203735351562
Validation loss: 2.106078593961654

Epoch: 5| Step: 6
Training loss: 2.0772502422332764
Validation loss: 2.09844994801347

Epoch: 5| Step: 7
Training loss: 1.972141981124878
Validation loss: 2.058667790505194

Epoch: 5| Step: 8
Training loss: 2.170332908630371
Validation loss: 2.0447582109000093

Epoch: 5| Step: 9
Training loss: 1.5167447328567505
Validation loss: 2.0832464925704466

Epoch: 5| Step: 10
Training loss: 2.4281086921691895
Validation loss: 2.0630599606421685

Epoch: 293| Step: 0
Training loss: 2.5938119888305664
Validation loss: 2.0415152247234056

Epoch: 5| Step: 1
Training loss: 2.5446102619171143
Validation loss: 2.047956169292491

Epoch: 5| Step: 2
Training loss: 2.3055882453918457
Validation loss: 2.0910054329902894

Epoch: 5| Step: 3
Training loss: 1.9227924346923828
Validation loss: 2.015051213643884

Epoch: 5| Step: 4
Training loss: 2.225750684738159
Validation loss: 2.10872467102543

Epoch: 5| Step: 5
Training loss: 1.911553978919983
Validation loss: 2.0627157585595244

Epoch: 5| Step: 6
Training loss: 1.8321365118026733
Validation loss: 2.0142263033056773

Epoch: 5| Step: 7
Training loss: 2.0899343490600586
Validation loss: 2.052611565077177

Epoch: 5| Step: 8
Training loss: 1.9468281269073486
Validation loss: 1.946225949513015

Epoch: 5| Step: 9
Training loss: 1.7963039875030518
Validation loss: 2.0686588312989924

Epoch: 5| Step: 10
Training loss: 2.2420778274536133
Validation loss: 2.0736143871020247

Epoch: 294| Step: 0
Training loss: 1.5815376043319702
Validation loss: 2.051293311580535

Epoch: 5| Step: 1
Training loss: 2.2097911834716797
Validation loss: 2.0595889963129514

Epoch: 5| Step: 2
Training loss: 2.6784424781799316
Validation loss: 1.9929533017578946

Epoch: 5| Step: 3
Training loss: 2.0071940422058105
Validation loss: 2.054779492398744

Epoch: 5| Step: 4
Training loss: 2.6339468955993652
Validation loss: 2.0215185739660777

Epoch: 5| Step: 5
Training loss: 1.9302101135253906
Validation loss: 2.0702063909140964

Epoch: 5| Step: 6
Training loss: 2.3515944480895996
Validation loss: 2.181448559607229

Epoch: 5| Step: 7
Training loss: 1.687313437461853
Validation loss: 2.0576736734759424

Epoch: 5| Step: 8
Training loss: 2.1714985370635986
Validation loss: 2.0446089083148586

Epoch: 5| Step: 9
Training loss: 1.9780515432357788
Validation loss: 2.071301370538691

Epoch: 5| Step: 10
Training loss: 1.7483525276184082
Validation loss: 2.0494909081407773

Epoch: 295| Step: 0
Training loss: 2.6691741943359375
Validation loss: 2.062511154400405

Epoch: 5| Step: 1
Training loss: 1.6113840341567993
Validation loss: 2.1205182229318926

Epoch: 5| Step: 2
Training loss: 2.3901803493499756
Validation loss: 2.084217015133109

Epoch: 5| Step: 3
Training loss: 2.417335033416748
Validation loss: 2.0741873633476997

Epoch: 5| Step: 4
Training loss: 2.563873767852783
Validation loss: 2.100736133513912

Epoch: 5| Step: 5
Training loss: 1.7144191265106201
Validation loss: 2.055955333094443

Epoch: 5| Step: 6
Training loss: 2.0063860416412354
Validation loss: 2.0256336978686753

Epoch: 5| Step: 7
Training loss: 1.7989295721054077
Validation loss: 2.0362947653698664

Epoch: 5| Step: 8
Training loss: 2.001019239425659
Validation loss: 2.0284717877705893

Epoch: 5| Step: 9
Training loss: 1.934739351272583
Validation loss: 2.0229944182980444

Epoch: 5| Step: 10
Training loss: 2.0188279151916504
Validation loss: 2.0917189275064776

Epoch: 296| Step: 0
Training loss: 1.4950135946273804
Validation loss: 2.0587284923881612

Epoch: 5| Step: 1
Training loss: 2.4587321281433105
Validation loss: 2.0550445754040956

Epoch: 5| Step: 2
Training loss: 2.2062058448791504
Validation loss: 2.067533982697354

Epoch: 5| Step: 3
Training loss: 1.8119547367095947
Validation loss: 2.0236170445719073

Epoch: 5| Step: 4
Training loss: 1.9019954204559326
Validation loss: 2.052472250435942

Epoch: 5| Step: 5
Training loss: 2.2044684886932373
Validation loss: 2.0681536454026417

Epoch: 5| Step: 6
Training loss: 2.034534454345703
Validation loss: 2.094123335294826

Epoch: 5| Step: 7
Training loss: 1.9450862407684326
Validation loss: 2.067914678204444

Epoch: 5| Step: 8
Training loss: 1.9859693050384521
Validation loss: 2.070525061699652

Epoch: 5| Step: 9
Training loss: 2.6236672401428223
Validation loss: 2.090458890443207

Epoch: 5| Step: 10
Training loss: 2.3186371326446533
Validation loss: 2.0710717067923596

Epoch: 297| Step: 0
Training loss: 2.2135279178619385
Validation loss: 2.003141185288788

Epoch: 5| Step: 1
Training loss: 2.0016942024230957
Validation loss: 2.0242296970018776

Epoch: 5| Step: 2
Training loss: 2.4276883602142334
Validation loss: 2.013193327893493

Epoch: 5| Step: 3
Training loss: 2.7322866916656494
Validation loss: 2.038133276406155

Epoch: 5| Step: 4
Training loss: 1.874685287475586
Validation loss: 2.078248364951021

Epoch: 5| Step: 5
Training loss: 2.301288604736328
Validation loss: 2.0396289902348674

Epoch: 5| Step: 6
Training loss: 1.2436058521270752
Validation loss: 2.0688940658364245

Epoch: 5| Step: 7
Training loss: 2.2590224742889404
Validation loss: 2.0768209503542994

Epoch: 5| Step: 8
Training loss: 1.7340261936187744
Validation loss: 1.9950972577576995

Epoch: 5| Step: 9
Training loss: 2.3959977626800537
Validation loss: 2.025650962706535

Epoch: 5| Step: 10
Training loss: 2.1615798473358154
Validation loss: 2.028385962209394

Epoch: 298| Step: 0
Training loss: 1.8719863891601562
Validation loss: 2.031837289051343

Epoch: 5| Step: 1
Training loss: 2.0305585861206055
Validation loss: 2.104882650477912

Epoch: 5| Step: 2
Training loss: 1.9632434844970703
Validation loss: 2.051463573209701

Epoch: 5| Step: 3
Training loss: 2.6150290966033936
Validation loss: 2.0126961738832536

Epoch: 5| Step: 4
Training loss: 1.8261438608169556
Validation loss: 2.0535352089071788

Epoch: 5| Step: 5
Training loss: 1.8903074264526367
Validation loss: 2.1152678971649497

Epoch: 5| Step: 6
Training loss: 2.2980048656463623
Validation loss: 2.0571193643795547

Epoch: 5| Step: 7
Training loss: 1.8391402959823608
Validation loss: 2.108466414995091

Epoch: 5| Step: 8
Training loss: 2.0110812187194824
Validation loss: 2.0574762808379305

Epoch: 5| Step: 9
Training loss: 2.1560397148132324
Validation loss: 2.072971272212203

Epoch: 5| Step: 10
Training loss: 2.716675043106079
Validation loss: 2.0605058670043945

Epoch: 299| Step: 0
Training loss: 2.177323579788208
Validation loss: 2.0730189251643356

Epoch: 5| Step: 1
Training loss: 1.7160532474517822
Validation loss: 2.108652453268728

Epoch: 5| Step: 2
Training loss: 1.9729255437850952
Validation loss: 2.0377342547139814

Epoch: 5| Step: 3
Training loss: 2.5169456005096436
Validation loss: 2.0735319634919525

Epoch: 5| Step: 4
Training loss: 1.8720579147338867
Validation loss: 2.0728320549893122

Epoch: 5| Step: 5
Training loss: 2.0086028575897217
Validation loss: 2.040632447888774

Epoch: 5| Step: 6
Training loss: 1.9532020092010498
Validation loss: 2.1126643816630044

Epoch: 5| Step: 7
Training loss: 2.3718268871307373
Validation loss: 2.034410035738381

Epoch: 5| Step: 8
Training loss: 2.4139809608459473
Validation loss: 2.069198153352225

Epoch: 5| Step: 9
Training loss: 1.8235152959823608
Validation loss: 2.00767610919091

Epoch: 5| Step: 10
Training loss: 1.45305597782135
Validation loss: 2.0752473697867444

Epoch: 300| Step: 0
Training loss: 2.416132926940918
Validation loss: 2.105922988666001

Epoch: 5| Step: 1
Training loss: 1.8670612573623657
Validation loss: 2.045508767968865

Epoch: 5| Step: 2
Training loss: 2.1195061206817627
Validation loss: 2.0617136378442087

Epoch: 5| Step: 3
Training loss: 2.5995965003967285
Validation loss: 2.0696970109016664

Epoch: 5| Step: 4
Training loss: 2.2352025508880615
Validation loss: 2.1014875776024273

Epoch: 5| Step: 5
Training loss: 1.4360414743423462
Validation loss: 2.088179490899527

Epoch: 5| Step: 6
Training loss: 2.005033493041992
Validation loss: 2.027164843774611

Epoch: 5| Step: 7
Training loss: 2.1294188499450684
Validation loss: 2.0963758217391146

Epoch: 5| Step: 8
Training loss: 2.3085789680480957
Validation loss: 1.9812560530119045

Epoch: 5| Step: 9
Training loss: 1.3719100952148438
Validation loss: 2.068225992623196

Epoch: 5| Step: 10
Training loss: 2.3767523765563965
Validation loss: 2.027378446312361

Epoch: 301| Step: 0
Training loss: 1.7212660312652588
Validation loss: 2.034499100459519

Epoch: 5| Step: 1
Training loss: 2.6708688735961914
Validation loss: 2.01445665923498

Epoch: 5| Step: 2
Training loss: 2.2872159481048584
Validation loss: 2.0442654791698662

Epoch: 5| Step: 3
Training loss: 2.1013011932373047
Validation loss: 2.036595554761989

Epoch: 5| Step: 4
Training loss: 1.6672031879425049
Validation loss: 2.031011281474944

Epoch: 5| Step: 5
Training loss: 2.0267817974090576
Validation loss: 2.053411950347244

Epoch: 5| Step: 6
Training loss: 1.7978928089141846
Validation loss: 2.0818837227359897

Epoch: 5| Step: 7
Training loss: 1.6608097553253174
Validation loss: 2.073133176372897

Epoch: 5| Step: 8
Training loss: 2.4309935569763184
Validation loss: 2.026061681009108

Epoch: 5| Step: 9
Training loss: 2.0310304164886475
Validation loss: 2.1027633990010908

Epoch: 5| Step: 10
Training loss: 2.5879805088043213
Validation loss: 2.0958950109379266

Epoch: 302| Step: 0
Training loss: 2.2643086910247803
Validation loss: 2.050563512309905

Epoch: 5| Step: 1
Training loss: 2.353999137878418
Validation loss: 2.0816502776197208

Epoch: 5| Step: 2
Training loss: 1.5603229999542236
Validation loss: 2.023685646313493

Epoch: 5| Step: 3
Training loss: 2.437204122543335
Validation loss: 2.0753647268459363

Epoch: 5| Step: 4
Training loss: 1.7018181085586548
Validation loss: 2.0541838010152182

Epoch: 5| Step: 5
Training loss: 2.0642566680908203
Validation loss: 2.1113846596851142

Epoch: 5| Step: 6
Training loss: 2.108720302581787
Validation loss: 2.0281454722086587

Epoch: 5| Step: 7
Training loss: 2.467137336730957
Validation loss: 2.044474723518536

Epoch: 5| Step: 8
Training loss: 1.6574122905731201
Validation loss: 2.0385387687272924

Epoch: 5| Step: 9
Training loss: 2.1138038635253906
Validation loss: 2.053088375317153

Epoch: 5| Step: 10
Training loss: 2.0978996753692627
Validation loss: 1.995154688435216

Epoch: 303| Step: 0
Training loss: 2.097003936767578
Validation loss: 2.0645068076349076

Epoch: 5| Step: 1
Training loss: 2.6243975162506104
Validation loss: 1.9945224433816888

Epoch: 5| Step: 2
Training loss: 2.11552095413208
Validation loss: 2.075031372808641

Epoch: 5| Step: 3
Training loss: 2.4694275856018066
Validation loss: 2.004922689930085

Epoch: 5| Step: 4
Training loss: 1.9365556240081787
Validation loss: 2.050533897133284

Epoch: 5| Step: 5
Training loss: 2.1539018154144287
Validation loss: 2.056706759237474

Epoch: 5| Step: 6
Training loss: 2.3736672401428223
Validation loss: 2.0466976652863207

Epoch: 5| Step: 7
Training loss: 1.6388652324676514
Validation loss: 2.091033661237327

Epoch: 5| Step: 8
Training loss: 1.6950470209121704
Validation loss: 2.079352932591592

Epoch: 5| Step: 9
Training loss: 1.5356931686401367
Validation loss: 2.063160833492074

Epoch: 5| Step: 10
Training loss: 2.263084650039673
Validation loss: 2.111119093433503

Epoch: 304| Step: 0
Training loss: 2.655979871749878
Validation loss: 2.086667735089538

Epoch: 5| Step: 1
Training loss: 2.3534274101257324
Validation loss: 2.01879092185728

Epoch: 5| Step: 2
Training loss: 2.0796680450439453
Validation loss: 2.067946472475606

Epoch: 5| Step: 3
Training loss: 1.643511414527893
Validation loss: 2.0992465583227014

Epoch: 5| Step: 4
Training loss: 2.452491521835327
Validation loss: 2.0300418010321994

Epoch: 5| Step: 5
Training loss: 1.6776764392852783
Validation loss: 2.0509134723294165

Epoch: 5| Step: 6
Training loss: 1.748596429824829
Validation loss: 2.0497406272478003

Epoch: 5| Step: 7
Training loss: 1.8830528259277344
Validation loss: 2.0959686566424627

Epoch: 5| Step: 8
Training loss: 1.9581950902938843
Validation loss: 2.1267312829212477

Epoch: 5| Step: 9
Training loss: 2.199643850326538
Validation loss: 2.0806308202846076

Epoch: 5| Step: 10
Training loss: 1.8528231382369995
Validation loss: 2.071630806051275

Epoch: 305| Step: 0
Training loss: 1.9412482976913452
Validation loss: 1.9986215945213073

Epoch: 5| Step: 1
Training loss: 2.097263813018799
Validation loss: 2.0631169208916287

Epoch: 5| Step: 2
Training loss: 1.5144528150558472
Validation loss: 2.056937462540083

Epoch: 5| Step: 3
Training loss: 2.0659053325653076
Validation loss: 2.0087964022031395

Epoch: 5| Step: 4
Training loss: 1.362000823020935
Validation loss: 2.089206941666142

Epoch: 5| Step: 5
Training loss: 1.9130334854125977
Validation loss: 2.0836244988185104

Epoch: 5| Step: 6
Training loss: 2.700885772705078
Validation loss: 2.041584037965344

Epoch: 5| Step: 7
Training loss: 2.3084983825683594
Validation loss: 2.0457655575967606

Epoch: 5| Step: 8
Training loss: 2.437976121902466
Validation loss: 2.078083997131676

Epoch: 5| Step: 9
Training loss: 2.1853229999542236
Validation loss: 2.065721681041102

Epoch: 5| Step: 10
Training loss: 2.2054054737091064
Validation loss: 2.160164997141848

Epoch: 306| Step: 0
Training loss: 2.2115583419799805
Validation loss: 2.0155021170134186

Epoch: 5| Step: 1
Training loss: 2.0144710540771484
Validation loss: 2.0566908992746824

Epoch: 5| Step: 2
Training loss: 1.846562147140503
Validation loss: 2.0415617637736823

Epoch: 5| Step: 3
Training loss: 1.8488702774047852
Validation loss: 2.0383881830400035

Epoch: 5| Step: 4
Training loss: 1.7737987041473389
Validation loss: 2.0828443419548774

Epoch: 5| Step: 5
Training loss: 1.9121410846710205
Validation loss: 2.0370286639018724

Epoch: 5| Step: 6
Training loss: 2.6341898441314697
Validation loss: 2.094232573304125

Epoch: 5| Step: 7
Training loss: 1.8043873310089111
Validation loss: 2.0713963508605957

Epoch: 5| Step: 8
Training loss: 2.102526903152466
Validation loss: 2.047055244445801

Epoch: 5| Step: 9
Training loss: 2.5526812076568604
Validation loss: 2.0632864531650337

Epoch: 5| Step: 10
Training loss: 2.3223938941955566
Validation loss: 2.0760003084777505

Epoch: 307| Step: 0
Training loss: 1.7720165252685547
Validation loss: 2.0333093186860443

Epoch: 5| Step: 1
Training loss: 2.8850979804992676
Validation loss: 2.1134715259716077

Epoch: 5| Step: 2
Training loss: 2.2223904132843018
Validation loss: 2.0314990602513796

Epoch: 5| Step: 3
Training loss: 1.9204902648925781
Validation loss: 2.049679416482167

Epoch: 5| Step: 4
Training loss: 1.75320303440094
Validation loss: 2.040173545960457

Epoch: 5| Step: 5
Training loss: 2.014157772064209
Validation loss: 2.0472283594069944

Epoch: 5| Step: 6
Training loss: 1.7770273685455322
Validation loss: 2.0419943794127433

Epoch: 5| Step: 7
Training loss: 1.921823263168335
Validation loss: 2.0596540922759683

Epoch: 5| Step: 8
Training loss: 1.7407503128051758
Validation loss: 2.090780140251242

Epoch: 5| Step: 9
Training loss: 2.337218761444092
Validation loss: 2.0303487393163864

Epoch: 5| Step: 10
Training loss: 2.448824882507324
Validation loss: 2.0301915676363054

Epoch: 308| Step: 0
Training loss: 1.689276933670044
Validation loss: 2.063689685636951

Epoch: 5| Step: 1
Training loss: 2.1435980796813965
Validation loss: 2.059459679870195

Epoch: 5| Step: 2
Training loss: 2.125753402709961
Validation loss: 1.9970559522669802

Epoch: 5| Step: 3
Training loss: 1.847887396812439
Validation loss: 2.05799707289665

Epoch: 5| Step: 4
Training loss: 1.9803941249847412
Validation loss: 2.024031577571746

Epoch: 5| Step: 5
Training loss: 1.9695537090301514
Validation loss: 1.9948563652653848

Epoch: 5| Step: 6
Training loss: 1.9673391580581665
Validation loss: 2.040146925116098

Epoch: 5| Step: 7
Training loss: 2.860523223876953
Validation loss: 2.065527344262728

Epoch: 5| Step: 8
Training loss: 2.1525211334228516
Validation loss: 2.0026624753911006

Epoch: 5| Step: 9
Training loss: 2.1418328285217285
Validation loss: 2.0419059773927093

Epoch: 5| Step: 10
Training loss: 2.0977094173431396
Validation loss: 1.9971513543077695

Epoch: 309| Step: 0
Training loss: 1.9384065866470337
Validation loss: 2.069478049073168

Epoch: 5| Step: 1
Training loss: 1.919482946395874
Validation loss: 2.09987299929383

Epoch: 5| Step: 2
Training loss: 1.7153785228729248
Validation loss: 2.078579864194316

Epoch: 5| Step: 3
Training loss: 2.1378750801086426
Validation loss: 2.0895616931300007

Epoch: 5| Step: 4
Training loss: 2.0180306434631348
Validation loss: 2.1111393692672893

Epoch: 5| Step: 5
Training loss: 1.9670798778533936
Validation loss: 2.0364492413818196

Epoch: 5| Step: 6
Training loss: 2.2029478549957275
Validation loss: 2.063454138335361

Epoch: 5| Step: 7
Training loss: 1.7370338439941406
Validation loss: 2.0305254023562194

Epoch: 5| Step: 8
Training loss: 2.6090798377990723
Validation loss: 1.9902853427394744

Epoch: 5| Step: 9
Training loss: 2.7365000247955322
Validation loss: 2.011186533076789

Epoch: 5| Step: 10
Training loss: 2.115649938583374
Validation loss: 2.0156198675914476

Epoch: 310| Step: 0
Training loss: 2.1515491008758545
Validation loss: 2.026125242633204

Epoch: 5| Step: 1
Training loss: 1.5420122146606445
Validation loss: 2.0729865361285467

Epoch: 5| Step: 2
Training loss: 1.9357048273086548
Validation loss: 2.0045889705739994

Epoch: 5| Step: 3
Training loss: 1.9082832336425781
Validation loss: 2.0402401506259875

Epoch: 5| Step: 4
Training loss: 2.176870584487915
Validation loss: 2.04129784722482

Epoch: 5| Step: 5
Training loss: 1.753434419631958
Validation loss: 2.0646109016992713

Epoch: 5| Step: 6
Training loss: 2.660853862762451
Validation loss: 2.0704805709982432

Epoch: 5| Step: 7
Training loss: 1.6122560501098633
Validation loss: 2.057906599454982

Epoch: 5| Step: 8
Training loss: 2.298311710357666
Validation loss: 2.0238472274554673

Epoch: 5| Step: 9
Training loss: 2.2122011184692383
Validation loss: 2.068870198342108

Epoch: 5| Step: 10
Training loss: 2.3625643253326416
Validation loss: 2.0483587493178663

Epoch: 311| Step: 0
Training loss: 2.054568290710449
Validation loss: 2.0167060718741467

Epoch: 5| Step: 1
Training loss: 2.190352201461792
Validation loss: 2.0410379107280443

Epoch: 5| Step: 2
Training loss: 2.0561249256134033
Validation loss: 2.088439274859685

Epoch: 5| Step: 3
Training loss: 2.070497989654541
Validation loss: 2.0550059580033824

Epoch: 5| Step: 4
Training loss: 1.4748191833496094
Validation loss: 2.044501073898808

Epoch: 5| Step: 5
Training loss: 1.7749782800674438
Validation loss: 2.092269351405482

Epoch: 5| Step: 6
Training loss: 1.7659013271331787
Validation loss: 2.025487338342974

Epoch: 5| Step: 7
Training loss: 2.1386916637420654
Validation loss: 2.0167909963156587

Epoch: 5| Step: 8
Training loss: 2.226533889770508
Validation loss: 2.0438007987955564

Epoch: 5| Step: 9
Training loss: 2.4881083965301514
Validation loss: 2.012044466951842

Epoch: 5| Step: 10
Training loss: 2.8059542179107666
Validation loss: 2.020068282722145

Epoch: 312| Step: 0
Training loss: 1.6459290981292725
Validation loss: 2.077490788634105

Epoch: 5| Step: 1
Training loss: 2.4358444213867188
Validation loss: 2.033184894951441

Epoch: 5| Step: 2
Training loss: 2.3867650032043457
Validation loss: 2.099957960908131

Epoch: 5| Step: 3
Training loss: 1.917997121810913
Validation loss: 2.033380836568853

Epoch: 5| Step: 4
Training loss: 2.9700512886047363
Validation loss: 2.013560604023677

Epoch: 5| Step: 5
Training loss: 1.8135830163955688
Validation loss: 2.0662565282596055

Epoch: 5| Step: 6
Training loss: 1.6320759057998657
Validation loss: 2.060268008580772

Epoch: 5| Step: 7
Training loss: 1.786057472229004
Validation loss: 2.0812225995525235

Epoch: 5| Step: 8
Training loss: 1.5483944416046143
Validation loss: 2.0738513085149948

Epoch: 5| Step: 9
Training loss: 2.713669538497925
Validation loss: 2.0276903260138726

Epoch: 5| Step: 10
Training loss: 1.8903874158859253
Validation loss: 2.04759128632084

Epoch: 313| Step: 0
Training loss: 2.370264768600464
Validation loss: 2.1046452342822985

Epoch: 5| Step: 1
Training loss: 1.688081979751587
Validation loss: 2.0984520360987675

Epoch: 5| Step: 2
Training loss: 2.359144926071167
Validation loss: 2.063409892461633

Epoch: 5| Step: 3
Training loss: 2.145998477935791
Validation loss: 2.0236092485407347

Epoch: 5| Step: 4
Training loss: 1.7659698724746704
Validation loss: 2.0408973616938435

Epoch: 5| Step: 5
Training loss: 1.568937063217163
Validation loss: 2.0588921026516984

Epoch: 5| Step: 6
Training loss: 1.876960039138794
Validation loss: 2.061218992356331

Epoch: 5| Step: 7
Training loss: 1.8986581563949585
Validation loss: 2.0484782495806293

Epoch: 5| Step: 8
Training loss: 2.391516923904419
Validation loss: 2.0496287243340605

Epoch: 5| Step: 9
Training loss: 2.7827916145324707
Validation loss: 2.1131488507793796

Epoch: 5| Step: 10
Training loss: 1.7196601629257202
Validation loss: 1.959941307703654

Epoch: 314| Step: 0
Training loss: 1.9779914617538452
Validation loss: 2.0167660533740954

Epoch: 5| Step: 1
Training loss: 2.8102753162384033
Validation loss: 2.013714653189464

Epoch: 5| Step: 2
Training loss: 1.9734313488006592
Validation loss: 2.042418018464119

Epoch: 5| Step: 3
Training loss: 2.013315200805664
Validation loss: 2.013342329250869

Epoch: 5| Step: 4
Training loss: 1.906517744064331
Validation loss: 2.012323361571117

Epoch: 5| Step: 5
Training loss: 2.0976672172546387
Validation loss: 2.052221426399805

Epoch: 5| Step: 6
Training loss: 2.038639783859253
Validation loss: 2.053539506850704

Epoch: 5| Step: 7
Training loss: 1.6904489994049072
Validation loss: 2.062708144546837

Epoch: 5| Step: 8
Training loss: 1.5405932664871216
Validation loss: 2.0337434353366977

Epoch: 5| Step: 9
Training loss: 2.418790102005005
Validation loss: 2.022709132522665

Epoch: 5| Step: 10
Training loss: 2.2826828956604004
Validation loss: 2.068920894335675

Epoch: 315| Step: 0
Training loss: 1.5221264362335205
Validation loss: 2.0705749706555436

Epoch: 5| Step: 1
Training loss: 2.0577268600463867
Validation loss: 1.9973408945145146

Epoch: 5| Step: 2
Training loss: 2.1466689109802246
Validation loss: 2.10562974919555

Epoch: 5| Step: 3
Training loss: 2.566530704498291
Validation loss: 2.0294259466150755

Epoch: 5| Step: 4
Training loss: 2.591738224029541
Validation loss: 2.0143710874742076

Epoch: 5| Step: 5
Training loss: 1.8474597930908203
Validation loss: 2.1043101408148326

Epoch: 5| Step: 6
Training loss: 1.951767921447754
Validation loss: 2.0296414001013643

Epoch: 5| Step: 7
Training loss: 1.968000054359436
Validation loss: 2.039912905744327

Epoch: 5| Step: 8
Training loss: 1.9097782373428345
Validation loss: 2.0807835619936705

Epoch: 5| Step: 9
Training loss: 1.8777406215667725
Validation loss: 2.057828616070491

Epoch: 5| Step: 10
Training loss: 2.0481209754943848
Validation loss: 2.052665396403241

Epoch: 316| Step: 0
Training loss: 2.2231369018554688
Validation loss: 2.0915692390934115

Epoch: 5| Step: 1
Training loss: 1.7501049041748047
Validation loss: 2.062671161467029

Epoch: 5| Step: 2
Training loss: 2.199100971221924
Validation loss: 2.0121916865789764

Epoch: 5| Step: 3
Training loss: 1.7455705404281616
Validation loss: 2.0867458325560375

Epoch: 5| Step: 4
Training loss: 1.9577000141143799
Validation loss: 2.0955687287033244

Epoch: 5| Step: 5
Training loss: 2.610105037689209
Validation loss: 2.080962404128044

Epoch: 5| Step: 6
Training loss: 1.7061866521835327
Validation loss: 2.0506268598700084

Epoch: 5| Step: 7
Training loss: 2.5781426429748535
Validation loss: 2.0718823248340237

Epoch: 5| Step: 8
Training loss: 2.4894051551818848
Validation loss: 2.0338581890188236

Epoch: 5| Step: 9
Training loss: 1.5768197774887085
Validation loss: 1.9964436920740272

Epoch: 5| Step: 10
Training loss: 1.4724422693252563
Validation loss: 2.0646171595460627

Epoch: 317| Step: 0
Training loss: 2.3494694232940674
Validation loss: 2.1042821163772256

Epoch: 5| Step: 1
Training loss: 1.5899101495742798
Validation loss: 2.0511973006750948

Epoch: 5| Step: 2
Training loss: 2.032564640045166
Validation loss: 2.053448164334861

Epoch: 5| Step: 3
Training loss: 2.0034449100494385
Validation loss: 2.062262910668568

Epoch: 5| Step: 4
Training loss: 2.20353627204895
Validation loss: 2.045594943467007

Epoch: 5| Step: 5
Training loss: 1.6513360738754272
Validation loss: 2.071399529774984

Epoch: 5| Step: 6
Training loss: 2.4068541526794434
Validation loss: 2.0575098952939435

Epoch: 5| Step: 7
Training loss: 1.8948156833648682
Validation loss: 2.018418865819131

Epoch: 5| Step: 8
Training loss: 2.605238437652588
Validation loss: 2.0870007186807613

Epoch: 5| Step: 9
Training loss: 2.011620283126831
Validation loss: 1.9801058846135293

Epoch: 5| Step: 10
Training loss: 1.758948564529419
Validation loss: 2.0370916884432555

Epoch: 318| Step: 0
Training loss: 2.0349602699279785
Validation loss: 2.0364789603858866

Epoch: 5| Step: 1
Training loss: 2.1096408367156982
Validation loss: 2.0107409364433697

Epoch: 5| Step: 2
Training loss: 2.17034912109375
Validation loss: 2.03077208611273

Epoch: 5| Step: 3
Training loss: 2.432788848876953
Validation loss: 2.0507634890976774

Epoch: 5| Step: 4
Training loss: 2.021371364593506
Validation loss: 2.0834986009905414

Epoch: 5| Step: 5
Training loss: 1.9383049011230469
Validation loss: 2.0276875944547754

Epoch: 5| Step: 6
Training loss: 2.400704860687256
Validation loss: 2.0415195124123686

Epoch: 5| Step: 7
Training loss: 1.8584235906600952
Validation loss: 2.0033183533658265

Epoch: 5| Step: 8
Training loss: 1.7517458200454712
Validation loss: 2.0694461740473264

Epoch: 5| Step: 9
Training loss: 1.5768057107925415
Validation loss: 2.0423102289117794

Epoch: 5| Step: 10
Training loss: 2.0686068534851074
Validation loss: 2.0007808298192997

Epoch: 319| Step: 0
Training loss: 1.8970038890838623
Validation loss: 2.0164624862773444

Epoch: 5| Step: 1
Training loss: 2.1595945358276367
Validation loss: 2.0739480808217037

Epoch: 5| Step: 2
Training loss: 2.1366214752197266
Validation loss: 2.053566745532456

Epoch: 5| Step: 3
Training loss: 2.3030619621276855
Validation loss: 2.0031602921024447

Epoch: 5| Step: 4
Training loss: 1.8300459384918213
Validation loss: 2.071791671937512

Epoch: 5| Step: 5
Training loss: 1.5754964351654053
Validation loss: 2.0560237848630516

Epoch: 5| Step: 6
Training loss: 1.774896264076233
Validation loss: 2.011304073436286

Epoch: 5| Step: 7
Training loss: 2.44726300239563
Validation loss: 2.029313143863473

Epoch: 5| Step: 8
Training loss: 2.3879849910736084
Validation loss: 2.048045260931856

Epoch: 5| Step: 9
Training loss: 2.2830862998962402
Validation loss: 2.0194255267420123

Epoch: 5| Step: 10
Training loss: 1.601150631904602
Validation loss: 2.039971478523747

Epoch: 320| Step: 0
Training loss: 1.8653974533081055
Validation loss: 1.9890985770892071

Epoch: 5| Step: 1
Training loss: 2.399414539337158
Validation loss: 2.023303883050078

Epoch: 5| Step: 2
Training loss: 2.0887844562530518
Validation loss: 2.1396249263517317

Epoch: 5| Step: 3
Training loss: 2.2030673027038574
Validation loss: 2.0834053985534178

Epoch: 5| Step: 4
Training loss: 2.380812168121338
Validation loss: 2.056366641034362

Epoch: 5| Step: 5
Training loss: 1.8829162120819092
Validation loss: 2.0407464504241943

Epoch: 5| Step: 6
Training loss: 1.8544559478759766
Validation loss: 2.0348883713445356

Epoch: 5| Step: 7
Training loss: 2.280853033065796
Validation loss: 2.0175620073913247

Epoch: 5| Step: 8
Training loss: 1.6695594787597656
Validation loss: 2.0251631377845682

Epoch: 5| Step: 9
Training loss: 1.7165956497192383
Validation loss: 2.06097061146972

Epoch: 5| Step: 10
Training loss: 2.2894699573516846
Validation loss: 2.0861999860373874

Epoch: 321| Step: 0
Training loss: 1.868443250656128
Validation loss: 2.0317137625909623

Epoch: 5| Step: 1
Training loss: 1.7155859470367432
Validation loss: 2.0341532102195163

Epoch: 5| Step: 2
Training loss: 2.0458273887634277
Validation loss: 2.0709510311003654

Epoch: 5| Step: 3
Training loss: 1.6172326803207397
Validation loss: 2.0681208359297885

Epoch: 5| Step: 4
Training loss: 1.9858894348144531
Validation loss: 2.133361106277794

Epoch: 5| Step: 5
Training loss: 2.8931610584259033
Validation loss: 2.009200490931029

Epoch: 5| Step: 6
Training loss: 1.924759864807129
Validation loss: 2.0615351136012743

Epoch: 5| Step: 7
Training loss: 2.2366435527801514
Validation loss: 2.0999043500551613

Epoch: 5| Step: 8
Training loss: 2.2852535247802734
Validation loss: 2.086985441946214

Epoch: 5| Step: 9
Training loss: 1.5450122356414795
Validation loss: 2.097314621812554

Epoch: 5| Step: 10
Training loss: 2.5705626010894775
Validation loss: 2.0283023875246764

Epoch: 322| Step: 0
Training loss: 1.9153534173965454
Validation loss: 2.0472830854436403

Epoch: 5| Step: 1
Training loss: 2.285675048828125
Validation loss: 2.0211814577861498

Epoch: 5| Step: 2
Training loss: 1.5987212657928467
Validation loss: 2.01923648259973

Epoch: 5| Step: 3
Training loss: 1.6449897289276123
Validation loss: 2.0643525585051505

Epoch: 5| Step: 4
Training loss: 2.081376314163208
Validation loss: 2.0552045940071024

Epoch: 5| Step: 5
Training loss: 2.329320192337036
Validation loss: 2.1234467644845285

Epoch: 5| Step: 6
Training loss: 2.757572650909424
Validation loss: 2.079986633793

Epoch: 5| Step: 7
Training loss: 1.8564151525497437
Validation loss: 2.0364403391397126

Epoch: 5| Step: 8
Training loss: 1.9539759159088135
Validation loss: 2.0761191614212526

Epoch: 5| Step: 9
Training loss: 2.2600717544555664
Validation loss: 2.0374987253578762

Epoch: 5| Step: 10
Training loss: 1.9060981273651123
Validation loss: 2.073020883785781

Epoch: 323| Step: 0
Training loss: 1.9704227447509766
Validation loss: 2.0175852429482246

Epoch: 5| Step: 1
Training loss: 2.3659396171569824
Validation loss: 2.054627182663128

Epoch: 5| Step: 2
Training loss: 1.9500402212142944
Validation loss: 2.0886275422188545

Epoch: 5| Step: 3
Training loss: 1.8046057224273682
Validation loss: 2.0098905781263947

Epoch: 5| Step: 4
Training loss: 1.5542008876800537
Validation loss: 2.018083192968881

Epoch: 5| Step: 5
Training loss: 2.263812303543091
Validation loss: 2.1148753858381704

Epoch: 5| Step: 6
Training loss: 1.5951364040374756
Validation loss: 2.114065315133782

Epoch: 5| Step: 7
Training loss: 2.6191372871398926
Validation loss: 2.069063248172883

Epoch: 5| Step: 8
Training loss: 2.0223402976989746
Validation loss: 2.0089597061116207

Epoch: 5| Step: 9
Training loss: 2.8265109062194824
Validation loss: 2.02631740672614

Epoch: 5| Step: 10
Training loss: 1.6837339401245117
Validation loss: 2.063545032214093

Epoch: 324| Step: 0
Training loss: 2.736860990524292
Validation loss: 2.0525036986156175

Epoch: 5| Step: 1
Training loss: 1.8342489004135132
Validation loss: 2.0490732923630746

Epoch: 5| Step: 2
Training loss: 2.4413399696350098
Validation loss: 2.035221933036722

Epoch: 5| Step: 3
Training loss: 1.896146535873413
Validation loss: 2.073022864198172

Epoch: 5| Step: 4
Training loss: 2.342271327972412
Validation loss: 2.054630155204445

Epoch: 5| Step: 5
Training loss: 1.5656745433807373
Validation loss: 2.041969099352437

Epoch: 5| Step: 6
Training loss: 1.9780237674713135
Validation loss: 2.0063219172980196

Epoch: 5| Step: 7
Training loss: 1.8481318950653076
Validation loss: 2.0670866825247325

Epoch: 5| Step: 8
Training loss: 1.680625557899475
Validation loss: 2.017106916314812

Epoch: 5| Step: 9
Training loss: 1.924466848373413
Validation loss: 2.0121044164062827

Epoch: 5| Step: 10
Training loss: 2.116347551345825
Validation loss: 2.1095572876673874

Epoch: 325| Step: 0
Training loss: 2.2178845405578613
Validation loss: 2.0430376170783915

Epoch: 5| Step: 1
Training loss: 2.458446502685547
Validation loss: 2.033519066790099

Epoch: 5| Step: 2
Training loss: 1.8791803121566772
Validation loss: 2.014749506468414

Epoch: 5| Step: 3
Training loss: 2.3432717323303223
Validation loss: 2.0189551371400074

Epoch: 5| Step: 4
Training loss: 2.7881202697753906
Validation loss: 2.059638497649982

Epoch: 5| Step: 5
Training loss: 2.0748372077941895
Validation loss: 2.1028721883732784

Epoch: 5| Step: 6
Training loss: 1.677553415298462
Validation loss: 2.128626993907395

Epoch: 5| Step: 7
Training loss: 1.6995834112167358
Validation loss: 2.1559691403501775

Epoch: 5| Step: 8
Training loss: 1.8206058740615845
Validation loss: 2.0829423896728025

Epoch: 5| Step: 9
Training loss: 1.6875842809677124
Validation loss: 2.056106807083212

Epoch: 5| Step: 10
Training loss: 1.7204910516738892
Validation loss: 2.0639512154363815

Epoch: 326| Step: 0
Training loss: 1.6253913640975952
Validation loss: 2.0166950264284687

Epoch: 5| Step: 1
Training loss: 2.182438611984253
Validation loss: 2.0311175366883636

Epoch: 5| Step: 2
Training loss: 2.295166015625
Validation loss: 2.101599178006572

Epoch: 5| Step: 3
Training loss: 1.761910080909729
Validation loss: 2.0184482592408375

Epoch: 5| Step: 4
Training loss: 2.2604362964630127
Validation loss: 1.995275567936641

Epoch: 5| Step: 5
Training loss: 1.5252101421356201
Validation loss: 2.040158542253638

Epoch: 5| Step: 6
Training loss: 2.2629427909851074
Validation loss: 2.0707650184631348

Epoch: 5| Step: 7
Training loss: 2.0881171226501465
Validation loss: 2.131185595707227

Epoch: 5| Step: 8
Training loss: 2.4307732582092285
Validation loss: 2.0838807731546383

Epoch: 5| Step: 9
Training loss: 1.661394476890564
Validation loss: 2.036166866620382

Epoch: 5| Step: 10
Training loss: 1.9876775741577148
Validation loss: 1.9827205083703483

Epoch: 327| Step: 0
Training loss: 1.939628005027771
Validation loss: 2.033562050070814

Epoch: 5| Step: 1
Training loss: 2.417172431945801
Validation loss: 2.0780503826756633

Epoch: 5| Step: 2
Training loss: 1.6173632144927979
Validation loss: 2.007409188055223

Epoch: 5| Step: 3
Training loss: 2.395982027053833
Validation loss: 2.0281232749262164

Epoch: 5| Step: 4
Training loss: 2.4566519260406494
Validation loss: 2.0874476637891544

Epoch: 5| Step: 5
Training loss: 1.6771490573883057
Validation loss: 2.1129989162568124

Epoch: 5| Step: 6
Training loss: 1.7565628290176392
Validation loss: 2.070404541107916

Epoch: 5| Step: 7
Training loss: 1.2793201208114624
Validation loss: 2.0546102857076995

Epoch: 5| Step: 8
Training loss: 2.948058605194092
Validation loss: 2.0446603862188195

Epoch: 5| Step: 9
Training loss: 2.525353193283081
Validation loss: 2.135302451349074

Epoch: 5| Step: 10
Training loss: 1.4813525676727295
Validation loss: 2.059973684690332

Epoch: 328| Step: 0
Training loss: 2.707866668701172
Validation loss: 1.9976669306396155

Epoch: 5| Step: 1
Training loss: 2.1045451164245605
Validation loss: 2.083688266815678

Epoch: 5| Step: 2
Training loss: 2.439145565032959
Validation loss: 1.9866972661787463

Epoch: 5| Step: 3
Training loss: 2.0824363231658936
Validation loss: 2.0682069473369147

Epoch: 5| Step: 4
Training loss: 1.6651684045791626
Validation loss: 2.130954993668423

Epoch: 5| Step: 5
Training loss: 1.5835301876068115
Validation loss: 2.0662557501946726

Epoch: 5| Step: 6
Training loss: 2.424868583679199
Validation loss: 2.01042345775071

Epoch: 5| Step: 7
Training loss: 1.4974839687347412
Validation loss: 2.0701435894094486

Epoch: 5| Step: 8
Training loss: 2.609766721725464
Validation loss: 2.0419999220037974

Epoch: 5| Step: 9
Training loss: 1.636744499206543
Validation loss: 2.083883462413665

Epoch: 5| Step: 10
Training loss: 1.946466088294983
Validation loss: 2.046917014224555

Epoch: 329| Step: 0
Training loss: 2.2149484157562256
Validation loss: 2.0494778335735364

Epoch: 5| Step: 1
Training loss: 1.8764588832855225
Validation loss: 2.072921263274326

Epoch: 5| Step: 2
Training loss: 2.788179874420166
Validation loss: 2.0153703638302383

Epoch: 5| Step: 3
Training loss: 1.8802343606948853
Validation loss: 2.0889184987673195

Epoch: 5| Step: 4
Training loss: 2.1579301357269287
Validation loss: 2.107123590284778

Epoch: 5| Step: 5
Training loss: 2.079012870788574
Validation loss: 2.0119516182971258

Epoch: 5| Step: 6
Training loss: 2.436591863632202
Validation loss: 2.0757668172159502

Epoch: 5| Step: 7
Training loss: 1.8755626678466797
Validation loss: 2.003482041820403

Epoch: 5| Step: 8
Training loss: 1.2144958972930908
Validation loss: 2.0122558993677937

Epoch: 5| Step: 9
Training loss: 2.0153446197509766
Validation loss: 2.082494133262224

Epoch: 5| Step: 10
Training loss: 2.036878824234009
Validation loss: 2.0589390467571955

Epoch: 330| Step: 0
Training loss: 2.0009145736694336
Validation loss: 2.0354419062214513

Epoch: 5| Step: 1
Training loss: 1.8733704090118408
Validation loss: 1.9919639479729436

Epoch: 5| Step: 2
Training loss: 2.7359766960144043
Validation loss: 2.016754707982463

Epoch: 5| Step: 3
Training loss: 2.2370591163635254
Validation loss: 1.9711296968562628

Epoch: 5| Step: 4
Training loss: 1.3809630870819092
Validation loss: 2.0375412177014094

Epoch: 5| Step: 5
Training loss: 2.1539103984832764
Validation loss: 2.0189314132095664

Epoch: 5| Step: 6
Training loss: 2.399742364883423
Validation loss: 1.9935725247988136

Epoch: 5| Step: 7
Training loss: 1.765477180480957
Validation loss: 2.047528830907678

Epoch: 5| Step: 8
Training loss: 1.9846937656402588
Validation loss: 2.0596998878704604

Epoch: 5| Step: 9
Training loss: 1.8779798746109009
Validation loss: 2.0469858454119776

Epoch: 5| Step: 10
Training loss: 2.142414093017578
Validation loss: 2.069826031243929

Epoch: 331| Step: 0
Training loss: 2.177422046661377
Validation loss: 2.0413502839303788

Epoch: 5| Step: 1
Training loss: 2.2943496704101562
Validation loss: 2.0665830617309897

Epoch: 5| Step: 2
Training loss: 1.9234883785247803
Validation loss: 2.017486560729242

Epoch: 5| Step: 3
Training loss: 1.819663405418396
Validation loss: 2.0578856955292406

Epoch: 5| Step: 4
Training loss: 1.890031099319458
Validation loss: 2.004223859438332

Epoch: 5| Step: 5
Training loss: 2.2256851196289062
Validation loss: 2.006815820611933

Epoch: 5| Step: 6
Training loss: 1.7276856899261475
Validation loss: 2.040093284781261

Epoch: 5| Step: 7
Training loss: 2.547330379486084
Validation loss: 2.0961061446897444

Epoch: 5| Step: 8
Training loss: 2.0036041736602783
Validation loss: 2.0004710830667967

Epoch: 5| Step: 9
Training loss: 2.069342851638794
Validation loss: 2.0436998272454865

Epoch: 5| Step: 10
Training loss: 1.6215333938598633
Validation loss: 2.0101959756625596

Epoch: 332| Step: 0
Training loss: 2.1575000286102295
Validation loss: 1.9985795238966584

Epoch: 5| Step: 1
Training loss: 2.647488594055176
Validation loss: 2.0676304242944203

Epoch: 5| Step: 2
Training loss: 1.6170127391815186
Validation loss: 2.0770863512510895

Epoch: 5| Step: 3
Training loss: 2.077352285385132
Validation loss: 2.0697158305875716

Epoch: 5| Step: 4
Training loss: 1.869300127029419
Validation loss: 2.0591015046642673

Epoch: 5| Step: 5
Training loss: 1.9715179204940796
Validation loss: 2.051106483705582

Epoch: 5| Step: 6
Training loss: 1.463958978652954
Validation loss: 1.9933882272371681

Epoch: 5| Step: 7
Training loss: 1.679325819015503
Validation loss: 2.0898110828092022

Epoch: 5| Step: 8
Training loss: 1.8144525289535522
Validation loss: 2.0752603315537974

Epoch: 5| Step: 9
Training loss: 2.6752874851226807
Validation loss: 2.084903488876999

Epoch: 5| Step: 10
Training loss: 2.3181304931640625
Validation loss: 2.0718482066226263

Epoch: 333| Step: 0
Training loss: 2.3450684547424316
Validation loss: 2.0646755913252473

Epoch: 5| Step: 1
Training loss: 2.3135457038879395
Validation loss: 2.0460941278806297

Epoch: 5| Step: 2
Training loss: 2.5992438793182373
Validation loss: 2.085197946076752

Epoch: 5| Step: 3
Training loss: 1.9626474380493164
Validation loss: 2.0850229083850818

Epoch: 5| Step: 4
Training loss: 1.7354440689086914
Validation loss: 2.065290202376663

Epoch: 5| Step: 5
Training loss: 2.11614990234375
Validation loss: 2.047704282627311

Epoch: 5| Step: 6
Training loss: 1.7067649364471436
Validation loss: 2.088223736773255

Epoch: 5| Step: 7
Training loss: 2.3471548557281494
Validation loss: 2.0891685690931094

Epoch: 5| Step: 8
Training loss: 2.028317451477051
Validation loss: 2.136171385806094

Epoch: 5| Step: 9
Training loss: 1.174849271774292
Validation loss: 2.061271687989594

Epoch: 5| Step: 10
Training loss: 2.2333602905273438
Validation loss: 2.0301419381172425

Epoch: 334| Step: 0
Training loss: 2.4458084106445312
Validation loss: 2.0306920159247612

Epoch: 5| Step: 1
Training loss: 1.4106502532958984
Validation loss: 2.053167881504182

Epoch: 5| Step: 2
Training loss: 2.0359549522399902
Validation loss: 2.0347361385181384

Epoch: 5| Step: 3
Training loss: 1.8191859722137451
Validation loss: 2.0477134348243795

Epoch: 5| Step: 4
Training loss: 2.070840358734131
Validation loss: 2.0165647447750135

Epoch: 5| Step: 5
Training loss: 2.3571324348449707
Validation loss: 2.0554310455117175

Epoch: 5| Step: 6
Training loss: 2.305668592453003
Validation loss: 2.1020893332778767

Epoch: 5| Step: 7
Training loss: 1.9787410497665405
Validation loss: 2.0917470788442962

Epoch: 5| Step: 8
Training loss: 2.148136854171753
Validation loss: 2.0197599728902182

Epoch: 5| Step: 9
Training loss: 1.3669496774673462
Validation loss: 2.004341676671018

Epoch: 5| Step: 10
Training loss: 2.3397817611694336
Validation loss: 2.0337426175353346

Epoch: 335| Step: 0
Training loss: 2.2842891216278076
Validation loss: 2.039076030895274

Epoch: 5| Step: 1
Training loss: 2.5470142364501953
Validation loss: 1.9716607088683753

Epoch: 5| Step: 2
Training loss: 1.5805964469909668
Validation loss: 2.037950385001398

Epoch: 5| Step: 3
Training loss: 2.29386568069458
Validation loss: 2.0379059648001068

Epoch: 5| Step: 4
Training loss: 1.3356701135635376
Validation loss: 2.066160003344218

Epoch: 5| Step: 5
Training loss: 1.8701887130737305
Validation loss: 2.083835058314826

Epoch: 5| Step: 6
Training loss: 2.1313984394073486
Validation loss: 2.0441276822038876

Epoch: 5| Step: 7
Training loss: 1.8288713693618774
Validation loss: 2.0415279954992314

Epoch: 5| Step: 8
Training loss: 2.244450330734253
Validation loss: 2.019235844253212

Epoch: 5| Step: 9
Training loss: 1.7053687572479248
Validation loss: 2.095199209387584

Epoch: 5| Step: 10
Training loss: 2.698720932006836
Validation loss: 2.0144055376770678

Epoch: 336| Step: 0
Training loss: 2.2881224155426025
Validation loss: 2.0898478800250637

Epoch: 5| Step: 1
Training loss: 1.5315895080566406
Validation loss: 2.031223871374643

Epoch: 5| Step: 2
Training loss: 1.6934230327606201
Validation loss: 2.0460288960446595

Epoch: 5| Step: 3
Training loss: 2.6907496452331543
Validation loss: 2.1043614700276363

Epoch: 5| Step: 4
Training loss: 1.9214503765106201
Validation loss: 2.0310700401183097

Epoch: 5| Step: 5
Training loss: 2.590581178665161
Validation loss: 2.0145669188550723

Epoch: 5| Step: 6
Training loss: 2.327584743499756
Validation loss: 2.066042725757886

Epoch: 5| Step: 7
Training loss: 2.4223814010620117
Validation loss: 2.0489972829818726

Epoch: 5| Step: 8
Training loss: 1.7448031902313232
Validation loss: 2.0822064056191394

Epoch: 5| Step: 9
Training loss: 1.6766780614852905
Validation loss: 2.0472103267587642

Epoch: 5| Step: 10
Training loss: 1.6738722324371338
Validation loss: 2.016428255265759

Epoch: 337| Step: 0
Training loss: 2.040526866912842
Validation loss: 2.111642063304942

Epoch: 5| Step: 1
Training loss: 2.519865036010742
Validation loss: 2.0885169890619095

Epoch: 5| Step: 2
Training loss: 1.6356010437011719
Validation loss: 2.0416225066748996

Epoch: 5| Step: 3
Training loss: 1.8319556713104248
Validation loss: 2.0662362216621317

Epoch: 5| Step: 4
Training loss: 1.8198089599609375
Validation loss: 2.0892631892235047

Epoch: 5| Step: 5
Training loss: 1.800548791885376
Validation loss: 2.0781388423776113

Epoch: 5| Step: 6
Training loss: 2.157402515411377
Validation loss: 2.0479016803926036

Epoch: 5| Step: 7
Training loss: 2.5717685222625732
Validation loss: 2.0373096555791874

Epoch: 5| Step: 8
Training loss: 2.03852915763855
Validation loss: 2.0623598303846133

Epoch: 5| Step: 9
Training loss: 1.9231576919555664
Validation loss: 2.072501004383128

Epoch: 5| Step: 10
Training loss: 2.273526430130005
Validation loss: 2.067675100859775

Epoch: 338| Step: 0
Training loss: 1.7423111200332642
Validation loss: 2.028071303521433

Epoch: 5| Step: 1
Training loss: 1.5081291198730469
Validation loss: 2.1200707368953253

Epoch: 5| Step: 2
Training loss: 1.9771757125854492
Validation loss: 2.069916299594346

Epoch: 5| Step: 3
Training loss: 1.7014610767364502
Validation loss: 2.025157090156309

Epoch: 5| Step: 4
Training loss: 1.922803521156311
Validation loss: 2.0473557531192736

Epoch: 5| Step: 5
Training loss: 2.4098386764526367
Validation loss: 2.070462223022215

Epoch: 5| Step: 6
Training loss: 2.059211254119873
Validation loss: 2.042455150235084

Epoch: 5| Step: 7
Training loss: 2.0173168182373047
Validation loss: 2.044578386891273

Epoch: 5| Step: 8
Training loss: 2.0302443504333496
Validation loss: 2.1219160556793213

Epoch: 5| Step: 9
Training loss: 2.2479822635650635
Validation loss: 2.0485415125405915

Epoch: 5| Step: 10
Training loss: 2.608025074005127
Validation loss: 2.0516825183745353

Epoch: 339| Step: 0
Training loss: 2.229750156402588
Validation loss: 2.0058642010534964

Epoch: 5| Step: 1
Training loss: 1.910719633102417
Validation loss: 2.063238725867323

Epoch: 5| Step: 2
Training loss: 2.028815507888794
Validation loss: 2.0572038568476194

Epoch: 5| Step: 3
Training loss: 2.041973114013672
Validation loss: 1.9894369174075384

Epoch: 5| Step: 4
Training loss: 2.1999704837799072
Validation loss: 2.087854544321696

Epoch: 5| Step: 5
Training loss: 2.632936477661133
Validation loss: 2.0337994816482707

Epoch: 5| Step: 6
Training loss: 1.566907525062561
Validation loss: 2.03888927864772

Epoch: 5| Step: 7
Training loss: 1.6010591983795166
Validation loss: 1.9754091385872132

Epoch: 5| Step: 8
Training loss: 1.2079460620880127
Validation loss: 2.0808986156217513

Epoch: 5| Step: 9
Training loss: 2.0280535221099854
Validation loss: 2.073836407353801

Epoch: 5| Step: 10
Training loss: 2.8479833602905273
Validation loss: 2.0694511500738

Epoch: 340| Step: 0
Training loss: 1.61014723777771
Validation loss: 2.1015251554468626

Epoch: 5| Step: 1
Training loss: 1.8444302082061768
Validation loss: 2.0231231130579466

Epoch: 5| Step: 2
Training loss: 2.914346218109131
Validation loss: 2.039859334627787

Epoch: 5| Step: 3
Training loss: 2.345876693725586
Validation loss: 2.0392051063558108

Epoch: 5| Step: 4
Training loss: 1.8969846963882446
Validation loss: 2.0489218363197903

Epoch: 5| Step: 5
Training loss: 2.2997546195983887
Validation loss: 2.007990134659634

Epoch: 5| Step: 6
Training loss: 1.8436628580093384
Validation loss: 2.0225202447624615

Epoch: 5| Step: 7
Training loss: 1.9146177768707275
Validation loss: 1.9948427536154305

Epoch: 5| Step: 8
Training loss: 1.9888734817504883
Validation loss: 1.9995120802233297

Epoch: 5| Step: 9
Training loss: 1.7493187189102173
Validation loss: 2.0305286966344362

Epoch: 5| Step: 10
Training loss: 1.9453508853912354
Validation loss: 2.007453034001012

Epoch: 341| Step: 0
Training loss: 2.1794750690460205
Validation loss: 1.9920187919370589

Epoch: 5| Step: 1
Training loss: 1.7008960247039795
Validation loss: 2.0544324151931272

Epoch: 5| Step: 2
Training loss: 2.4259116649627686
Validation loss: 2.0272127582180883

Epoch: 5| Step: 3
Training loss: 2.0613322257995605
Validation loss: 2.0416803770167853

Epoch: 5| Step: 4
Training loss: 2.310922145843506
Validation loss: 2.0213862003818637

Epoch: 5| Step: 5
Training loss: 2.2761683464050293
Validation loss: 2.077615358496225

Epoch: 5| Step: 6
Training loss: 1.939422607421875
Validation loss: 2.0114736275006364

Epoch: 5| Step: 7
Training loss: 1.6652534008026123
Validation loss: 2.1080823944460962

Epoch: 5| Step: 8
Training loss: 1.5683872699737549
Validation loss: 2.0088780464664584

Epoch: 5| Step: 9
Training loss: 1.7211090326309204
Validation loss: 2.024486823748517

Epoch: 5| Step: 10
Training loss: 2.655949354171753
Validation loss: 2.031986003280968

Epoch: 342| Step: 0
Training loss: 2.1164908409118652
Validation loss: 2.1261482431042578

Epoch: 5| Step: 1
Training loss: 2.032087564468384
Validation loss: 2.100558953900491

Epoch: 5| Step: 2
Training loss: 2.2643306255340576
Validation loss: 2.089281330826462

Epoch: 5| Step: 3
Training loss: 1.792743444442749
Validation loss: 2.024529291737464

Epoch: 5| Step: 4
Training loss: 1.6470539569854736
Validation loss: 2.0701980360092653

Epoch: 5| Step: 5
Training loss: 1.9733142852783203
Validation loss: 2.038702790455152

Epoch: 5| Step: 6
Training loss: 2.8128445148468018
Validation loss: 2.0932897419057865

Epoch: 5| Step: 7
Training loss: 1.6080719232559204
Validation loss: 2.075073678006408

Epoch: 5| Step: 8
Training loss: 2.166383743286133
Validation loss: 2.063064677740938

Epoch: 5| Step: 9
Training loss: 2.280856132507324
Validation loss: 2.029848926810808

Epoch: 5| Step: 10
Training loss: 1.7549824714660645
Validation loss: 2.0232286940338793

Epoch: 343| Step: 0
Training loss: 1.1208137273788452
Validation loss: 2.042678242088646

Epoch: 5| Step: 1
Training loss: 2.098365068435669
Validation loss: 2.0644874342026247

Epoch: 5| Step: 2
Training loss: 2.2899580001831055
Validation loss: 2.0731493837089947

Epoch: 5| Step: 3
Training loss: 2.112518787384033
Validation loss: 2.0399165666231545

Epoch: 5| Step: 4
Training loss: 1.6524946689605713
Validation loss: 2.0353848126626786

Epoch: 5| Step: 5
Training loss: 2.3960351943969727
Validation loss: 2.021732440558813

Epoch: 5| Step: 6
Training loss: 2.4691295623779297
Validation loss: 2.05317033490827

Epoch: 5| Step: 7
Training loss: 2.5623888969421387
Validation loss: 2.0447264640561995

Epoch: 5| Step: 8
Training loss: 2.0850911140441895
Validation loss: 2.024839643509157

Epoch: 5| Step: 9
Training loss: 1.9577382802963257
Validation loss: 2.0511584871558735

Epoch: 5| Step: 10
Training loss: 1.2264081239700317
Validation loss: 2.037351595458164

Epoch: 344| Step: 0
Training loss: 1.6361377239227295
Validation loss: 2.0405957545003583

Epoch: 5| Step: 1
Training loss: 2.189215660095215
Validation loss: 2.1222870913884972

Epoch: 5| Step: 2
Training loss: 2.141881227493286
Validation loss: 2.0194435760539067

Epoch: 5| Step: 3
Training loss: 1.378187894821167
Validation loss: 2.0213383013202297

Epoch: 5| Step: 4
Training loss: 2.279665946960449
Validation loss: 2.0618869719966764

Epoch: 5| Step: 5
Training loss: 2.2081403732299805
Validation loss: 2.0234760110096266

Epoch: 5| Step: 6
Training loss: 1.984614610671997
Validation loss: 2.0108132887912054

Epoch: 5| Step: 7
Training loss: 2.455763578414917
Validation loss: 2.0614038975008073

Epoch: 5| Step: 8
Training loss: 1.9960139989852905
Validation loss: 2.0013895393699728

Epoch: 5| Step: 9
Training loss: 1.3177319765090942
Validation loss: 2.053319063237918

Epoch: 5| Step: 10
Training loss: 2.3728930950164795
Validation loss: 2.0148299022387435

Epoch: 345| Step: 0
Training loss: 2.3246827125549316
Validation loss: 2.0852596400886454

Epoch: 5| Step: 1
Training loss: 1.8534507751464844
Validation loss: 2.0642663022523284

Epoch: 5| Step: 2
Training loss: 2.513296604156494
Validation loss: 2.0215219425898727

Epoch: 5| Step: 3
Training loss: 1.9890190362930298
Validation loss: 2.049103319004018

Epoch: 5| Step: 4
Training loss: 1.8179336786270142
Validation loss: 2.027813602519292

Epoch: 5| Step: 5
Training loss: 1.9936012029647827
Validation loss: 2.0585917426693823

Epoch: 5| Step: 6
Training loss: 1.823613166809082
Validation loss: 2.0901610953833467

Epoch: 5| Step: 7
Training loss: 2.0917904376983643
Validation loss: 2.0521541269876624

Epoch: 5| Step: 8
Training loss: 2.441013813018799
Validation loss: 2.0427743670760945

Epoch: 5| Step: 9
Training loss: 1.5014476776123047
Validation loss: 2.0732811471467376

Epoch: 5| Step: 10
Training loss: 1.9997832775115967
Validation loss: 2.076211278156568

Epoch: 346| Step: 0
Training loss: 2.6404614448547363
Validation loss: 2.061191210182764

Epoch: 5| Step: 1
Training loss: 1.7140220403671265
Validation loss: 2.017088301720158

Epoch: 5| Step: 2
Training loss: 1.7089145183563232
Validation loss: 2.029689327363045

Epoch: 5| Step: 3
Training loss: 2.5858452320098877
Validation loss: 2.0131126616590764

Epoch: 5| Step: 4
Training loss: 1.6351375579833984
Validation loss: 2.038661467131748

Epoch: 5| Step: 5
Training loss: 1.9555118083953857
Validation loss: 2.059759304087649

Epoch: 5| Step: 6
Training loss: 1.9309781789779663
Validation loss: 2.0340238130220802

Epoch: 5| Step: 7
Training loss: 1.3644875288009644
Validation loss: 2.0456658281305784

Epoch: 5| Step: 8
Training loss: 2.2280445098876953
Validation loss: 2.0959852651883195

Epoch: 5| Step: 9
Training loss: 2.1993417739868164
Validation loss: 2.0237664099662536

Epoch: 5| Step: 10
Training loss: 2.4671788215637207
Validation loss: 2.0775520942544423

Epoch: 347| Step: 0
Training loss: 1.738490343093872
Validation loss: 2.064206918080648

Epoch: 5| Step: 1
Training loss: 2.2409017086029053
Validation loss: 2.1338290629848355

Epoch: 5| Step: 2
Training loss: 2.2128450870513916
Validation loss: 2.0288513732212845

Epoch: 5| Step: 3
Training loss: 2.125894069671631
Validation loss: 2.092808526049378

Epoch: 5| Step: 4
Training loss: 2.0012450218200684
Validation loss: 2.0967309218581005

Epoch: 5| Step: 5
Training loss: 1.5985701084136963
Validation loss: 1.9553175844171995

Epoch: 5| Step: 6
Training loss: 1.7478725910186768
Validation loss: 2.0243840102226502

Epoch: 5| Step: 7
Training loss: 2.219831705093384
Validation loss: 2.01164516838648

Epoch: 5| Step: 8
Training loss: 2.277780055999756
Validation loss: 2.032341305927564

Epoch: 5| Step: 9
Training loss: 1.877381682395935
Validation loss: 1.9811898982653053

Epoch: 5| Step: 10
Training loss: 2.302657127380371
Validation loss: 2.0036107622167116

Epoch: 348| Step: 0
Training loss: 2.1192398071289062
Validation loss: 2.0560869632228727

Epoch: 5| Step: 1
Training loss: 2.138671636581421
Validation loss: 2.0775325170127292

Epoch: 5| Step: 2
Training loss: 1.6033480167388916
Validation loss: 2.0111773296069075

Epoch: 5| Step: 3
Training loss: 1.8139522075653076
Validation loss: 2.0273957995958227

Epoch: 5| Step: 4
Training loss: 2.2087626457214355
Validation loss: 2.043215274810791

Epoch: 5| Step: 5
Training loss: 2.1018524169921875
Validation loss: 2.0163008064352055

Epoch: 5| Step: 6
Training loss: 2.8218348026275635
Validation loss: 2.0271534201919392

Epoch: 5| Step: 7
Training loss: 1.9248464107513428
Validation loss: 2.00583049046096

Epoch: 5| Step: 8
Training loss: 1.671769142150879
Validation loss: 2.03873618700171

Epoch: 5| Step: 9
Training loss: 1.6131141185760498
Validation loss: 2.040408993280062

Epoch: 5| Step: 10
Training loss: 2.0735607147216797
Validation loss: 2.0523393871963664

Epoch: 349| Step: 0
Training loss: 2.2956271171569824
Validation loss: 2.0216807755090858

Epoch: 5| Step: 1
Training loss: 1.5937559604644775
Validation loss: 2.03601316226426

Epoch: 5| Step: 2
Training loss: 2.050856590270996
Validation loss: 2.0629963669725644

Epoch: 5| Step: 3
Training loss: 1.8155310153961182
Validation loss: 2.053237902220859

Epoch: 5| Step: 4
Training loss: 2.5244204998016357
Validation loss: 2.0572750388935046

Epoch: 5| Step: 5
Training loss: 1.8176454305648804
Validation loss: 2.0519937494749665

Epoch: 5| Step: 6
Training loss: 1.9963057041168213
Validation loss: 2.0518910795129757

Epoch: 5| Step: 7
Training loss: 1.8844541311264038
Validation loss: 2.128283700635356

Epoch: 5| Step: 8
Training loss: 2.512021541595459
Validation loss: 2.0559404614151164

Epoch: 5| Step: 9
Training loss: 1.978793740272522
Validation loss: 2.051449098894673

Epoch: 5| Step: 10
Training loss: 1.8591220378875732
Validation loss: 2.0433487815241658

Epoch: 350| Step: 0
Training loss: 2.759603261947632
Validation loss: 2.0194187741125784

Epoch: 5| Step: 1
Training loss: 1.6582269668579102
Validation loss: 2.0899968852279005

Epoch: 5| Step: 2
Training loss: 1.569162130355835
Validation loss: 2.0388542118892876

Epoch: 5| Step: 3
Training loss: 2.1143178939819336
Validation loss: 2.147457056148078

Epoch: 5| Step: 4
Training loss: 2.205859422683716
Validation loss: 2.1132570312869166

Epoch: 5| Step: 5
Training loss: 1.7686851024627686
Validation loss: 2.0554510624177995

Epoch: 5| Step: 6
Training loss: 1.8316609859466553
Validation loss: 2.1378209308911393

Epoch: 5| Step: 7
Training loss: 1.435276985168457
Validation loss: 2.0456157345925607

Epoch: 5| Step: 8
Training loss: 3.2194817066192627
Validation loss: 2.0499774973879576

Epoch: 5| Step: 9
Training loss: 1.5859044790267944
Validation loss: 2.0473531420512865

Epoch: 5| Step: 10
Training loss: 1.882154941558838
Validation loss: 2.055308570143997

Epoch: 351| Step: 0
Training loss: 1.1045104265213013
Validation loss: 2.092149821660852

Epoch: 5| Step: 1
Training loss: 1.8538585901260376
Validation loss: 2.064768939889887

Epoch: 5| Step: 2
Training loss: 2.0257041454315186
Validation loss: 2.0898462572405414

Epoch: 5| Step: 3
Training loss: 1.8218202590942383
Validation loss: 2.1034125692100933

Epoch: 5| Step: 4
Training loss: 1.7570703029632568
Validation loss: 2.031014947481053

Epoch: 5| Step: 5
Training loss: 2.4588570594787598
Validation loss: 2.0036479234695435

Epoch: 5| Step: 6
Training loss: 2.1011154651641846
Validation loss: 2.096300332776962

Epoch: 5| Step: 7
Training loss: 2.604273557662964
Validation loss: 1.9879865607907694

Epoch: 5| Step: 8
Training loss: 2.35530948638916
Validation loss: 2.0206260501697497

Epoch: 5| Step: 9
Training loss: 1.6411889791488647
Validation loss: 2.090959600223008

Epoch: 5| Step: 10
Training loss: 2.139085531234741
Validation loss: 2.062302509943644

Epoch: 352| Step: 0
Training loss: 2.1321640014648438
Validation loss: 2.0774322735366

Epoch: 5| Step: 1
Training loss: 2.1594347953796387
Validation loss: 2.0355664991563365

Epoch: 5| Step: 2
Training loss: 2.4582273960113525
Validation loss: 2.0572353819365143

Epoch: 5| Step: 3
Training loss: 1.9005749225616455
Validation loss: 2.036126111143379

Epoch: 5| Step: 4
Training loss: 1.6770681142807007
Validation loss: 2.0125591895913564

Epoch: 5| Step: 5
Training loss: 1.9942989349365234
Validation loss: 1.9867309165257279

Epoch: 5| Step: 6
Training loss: 1.2640044689178467
Validation loss: 2.0047367503566127

Epoch: 5| Step: 7
Training loss: 2.0235226154327393
Validation loss: 2.0457294653820735

Epoch: 5| Step: 8
Training loss: 1.9933464527130127
Validation loss: 2.006770098081199

Epoch: 5| Step: 9
Training loss: 2.1013665199279785
Validation loss: 2.0534988808375534

Epoch: 5| Step: 10
Training loss: 1.7996481657028198
Validation loss: 1.9870722973218529

Epoch: 353| Step: 0
Training loss: 2.292579412460327
Validation loss: 2.013782521729828

Epoch: 5| Step: 1
Training loss: 1.7611751556396484
Validation loss: 2.0080127946792112

Epoch: 5| Step: 2
Training loss: 2.020642042160034
Validation loss: 2.086631659538515

Epoch: 5| Step: 3
Training loss: 1.9904944896697998
Validation loss: 2.056486729652651

Epoch: 5| Step: 4
Training loss: 1.5422972440719604
Validation loss: 2.0365932654309016

Epoch: 5| Step: 5
Training loss: 2.2968573570251465
Validation loss: 2.0749472443775465

Epoch: 5| Step: 6
Training loss: 2.1262121200561523
Validation loss: 2.025351837117185

Epoch: 5| Step: 7
Training loss: 1.777265191078186
Validation loss: 2.004501990092698

Epoch: 5| Step: 8
Training loss: 1.2687543630599976
Validation loss: 1.989310949079452

Epoch: 5| Step: 9
Training loss: 2.955756425857544
Validation loss: 2.0176839495217926

Epoch: 5| Step: 10
Training loss: 1.6467727422714233
Validation loss: 2.0343952845501643

Epoch: 354| Step: 0
Training loss: 2.3467347621917725
Validation loss: 2.0542399242360103

Epoch: 5| Step: 1
Training loss: 1.9361646175384521
Validation loss: 2.055034374678007

Epoch: 5| Step: 2
Training loss: 2.1714816093444824
Validation loss: 2.101932253888858

Epoch: 5| Step: 3
Training loss: 1.9806801080703735
Validation loss: 2.076183839510846

Epoch: 5| Step: 4
Training loss: 2.08333683013916
Validation loss: 1.9822468347446893

Epoch: 5| Step: 5
Training loss: 1.9237267971038818
Validation loss: 2.080421211898968

Epoch: 5| Step: 6
Training loss: 2.4987776279449463
Validation loss: 2.0507950590502833

Epoch: 5| Step: 7
Training loss: 2.478229284286499
Validation loss: 2.0092353692618747

Epoch: 5| Step: 8
Training loss: 1.621609091758728
Validation loss: 1.9821910371062577

Epoch: 5| Step: 9
Training loss: 1.3514797687530518
Validation loss: 2.0801749357613186

Epoch: 5| Step: 10
Training loss: 1.7873375415802002
Validation loss: 2.040630914831674

Epoch: 355| Step: 0
Training loss: 1.4523704051971436
Validation loss: 2.068827315043378

Epoch: 5| Step: 1
Training loss: 2.2101290225982666
Validation loss: 2.0035250827830327

Epoch: 5| Step: 2
Training loss: 1.8974096775054932
Validation loss: 1.995718103583141

Epoch: 5| Step: 3
Training loss: 2.131856918334961
Validation loss: 2.0624707950058805

Epoch: 5| Step: 4
Training loss: 1.7520816326141357
Validation loss: 2.041544441253908

Epoch: 5| Step: 5
Training loss: 1.9073950052261353
Validation loss: 2.0742025195911364

Epoch: 5| Step: 6
Training loss: 2.2319042682647705
Validation loss: 2.1147892154673094

Epoch: 5| Step: 7
Training loss: 2.21787691116333
Validation loss: 2.057263687092771

Epoch: 5| Step: 8
Training loss: 1.5128785371780396
Validation loss: 2.1410745049035675

Epoch: 5| Step: 9
Training loss: 2.546693801879883
Validation loss: 2.077518545171266

Epoch: 5| Step: 10
Training loss: 2.344196319580078
Validation loss: 2.070962034245973

Epoch: 356| Step: 0
Training loss: 2.4837284088134766
Validation loss: 2.0855861645872875

Epoch: 5| Step: 1
Training loss: 1.86371648311615
Validation loss: 2.057755289539214

Epoch: 5| Step: 2
Training loss: 2.0830206871032715
Validation loss: 2.0744493289660384

Epoch: 5| Step: 3
Training loss: 2.0703492164611816
Validation loss: 2.0619248228688396

Epoch: 5| Step: 4
Training loss: 2.06729793548584
Validation loss: 2.0536121924718223

Epoch: 5| Step: 5
Training loss: 2.175109386444092
Validation loss: 2.018978529078986

Epoch: 5| Step: 6
Training loss: 1.5308754444122314
Validation loss: 2.022742545732888

Epoch: 5| Step: 7
Training loss: 2.009725332260132
Validation loss: 2.0338035027186074

Epoch: 5| Step: 8
Training loss: 2.02752947807312
Validation loss: 1.980161122096482

Epoch: 5| Step: 9
Training loss: 1.8434674739837646
Validation loss: 2.0740704844074864

Epoch: 5| Step: 10
Training loss: 1.8080822229385376
Validation loss: 2.0417884447241343

Epoch: 357| Step: 0
Training loss: 2.2569260597229004
Validation loss: 2.101595065926993

Epoch: 5| Step: 1
Training loss: 1.4067938327789307
Validation loss: 2.0183232189506612

Epoch: 5| Step: 2
Training loss: 2.089723825454712
Validation loss: 2.122981030453918

Epoch: 5| Step: 3
Training loss: 2.441009521484375
Validation loss: 2.0843034713499007

Epoch: 5| Step: 4
Training loss: 1.8350032567977905
Validation loss: 2.073506778286349

Epoch: 5| Step: 5
Training loss: 2.3170924186706543
Validation loss: 2.023023513055617

Epoch: 5| Step: 6
Training loss: 2.0644729137420654
Validation loss: 2.092863485377322

Epoch: 5| Step: 7
Training loss: 1.9074420928955078
Validation loss: 1.9805128728189776

Epoch: 5| Step: 8
Training loss: 1.5134773254394531
Validation loss: 2.0649979781079035

Epoch: 5| Step: 9
Training loss: 1.720855712890625
Validation loss: 2.0535751132554907

Epoch: 5| Step: 10
Training loss: 2.006960153579712
Validation loss: 2.050213998363864

Epoch: 358| Step: 0
Training loss: 1.8295676708221436
Validation loss: 2.0579376502703597

Epoch: 5| Step: 1
Training loss: 2.4684200286865234
Validation loss: 2.0933302230732416

Epoch: 5| Step: 2
Training loss: 1.7016441822052002
Validation loss: 2.096725574103735

Epoch: 5| Step: 3
Training loss: 2.1714959144592285
Validation loss: 2.088733732059438

Epoch: 5| Step: 4
Training loss: 1.3079711198806763
Validation loss: 2.1246953266923145

Epoch: 5| Step: 5
Training loss: 1.9664701223373413
Validation loss: 2.0634403228759766

Epoch: 5| Step: 6
Training loss: 1.9932105541229248
Validation loss: 2.0466909331660115

Epoch: 5| Step: 7
Training loss: 1.7876800298690796
Validation loss: 2.0842157743310414

Epoch: 5| Step: 8
Training loss: 2.259147882461548
Validation loss: 2.0550486759472917

Epoch: 5| Step: 9
Training loss: 1.8473758697509766
Validation loss: 2.066353387730096

Epoch: 5| Step: 10
Training loss: 2.5169177055358887
Validation loss: 2.0117220724782636

Epoch: 359| Step: 0
Training loss: 2.1488025188446045
Validation loss: 2.073274773936118

Epoch: 5| Step: 1
Training loss: 1.6729710102081299
Validation loss: 2.056582586739653

Epoch: 5| Step: 2
Training loss: 1.9192523956298828
Validation loss: 2.0852072546558995

Epoch: 5| Step: 3
Training loss: 2.464777708053589
Validation loss: 2.0552052477354645

Epoch: 5| Step: 4
Training loss: 2.2335281372070312
Validation loss: 2.041148019093339

Epoch: 5| Step: 5
Training loss: 1.8834441900253296
Validation loss: 2.077872855688936

Epoch: 5| Step: 6
Training loss: 2.4778389930725098
Validation loss: 2.1139159651212793

Epoch: 5| Step: 7
Training loss: 1.3222954273223877
Validation loss: 2.055272138246926

Epoch: 5| Step: 8
Training loss: 1.6480945348739624
Validation loss: 2.09969332397625

Epoch: 5| Step: 9
Training loss: 2.334336996078491
Validation loss: 2.054244590061967

Epoch: 5| Step: 10
Training loss: 1.7410703897476196
Validation loss: 2.0205270654411724

Epoch: 360| Step: 0
Training loss: 1.9908545017242432
Validation loss: 2.0856570069507887

Epoch: 5| Step: 1
Training loss: 2.5588908195495605
Validation loss: 2.072818076738747

Epoch: 5| Step: 2
Training loss: 1.632427453994751
Validation loss: 2.0735105109471146

Epoch: 5| Step: 3
Training loss: 1.8058990240097046
Validation loss: 2.0502662197236092

Epoch: 5| Step: 4
Training loss: 1.7919368743896484
Validation loss: 2.1045315778383644

Epoch: 5| Step: 5
Training loss: 2.333078384399414
Validation loss: 2.021770418331187

Epoch: 5| Step: 6
Training loss: 2.0545101165771484
Validation loss: 2.079404710441507

Epoch: 5| Step: 7
Training loss: 1.7154486179351807
Validation loss: 2.0479398132652364

Epoch: 5| Step: 8
Training loss: 1.8072326183319092
Validation loss: 2.0994986026517806

Epoch: 5| Step: 9
Training loss: 2.372283935546875
Validation loss: 2.09332251292403

Epoch: 5| Step: 10
Training loss: 1.9976528882980347
Validation loss: 2.102287465526212

Epoch: 361| Step: 0
Training loss: 2.081662654876709
Validation loss: 2.0802863926015873

Epoch: 5| Step: 1
Training loss: 2.4067695140838623
Validation loss: 1.983274870021369

Epoch: 5| Step: 2
Training loss: 2.1680681705474854
Validation loss: 2.042611322095317

Epoch: 5| Step: 3
Training loss: 1.7755905389785767
Validation loss: 2.021669310908164

Epoch: 5| Step: 4
Training loss: 1.9301704168319702
Validation loss: 1.9932055216963573

Epoch: 5| Step: 5
Training loss: 1.411633014678955
Validation loss: 2.0040331835387857

Epoch: 5| Step: 6
Training loss: 1.9385923147201538
Validation loss: 2.1071736504954677

Epoch: 5| Step: 7
Training loss: 2.26371431350708
Validation loss: 2.0031365245901127

Epoch: 5| Step: 8
Training loss: 1.912912130355835
Validation loss: 2.0425130269860707

Epoch: 5| Step: 9
Training loss: 2.1808955669403076
Validation loss: 1.9890551669623262

Epoch: 5| Step: 10
Training loss: 2.050157308578491
Validation loss: 2.0106926438628987

Epoch: 362| Step: 0
Training loss: 2.092824935913086
Validation loss: 2.062016253830284

Epoch: 5| Step: 1
Training loss: 2.0550971031188965
Validation loss: 1.9763524737409366

Epoch: 5| Step: 2
Training loss: 1.8456590175628662
Validation loss: 2.0529563862790345

Epoch: 5| Step: 3
Training loss: 2.355163097381592
Validation loss: 2.0467392680465535

Epoch: 5| Step: 4
Training loss: 2.4224114418029785
Validation loss: 2.0513652678458922

Epoch: 5| Step: 5
Training loss: 2.450861692428589
Validation loss: 2.0694084834027033

Epoch: 5| Step: 6
Training loss: 1.662557601928711
Validation loss: 2.0715073641910347

Epoch: 5| Step: 7
Training loss: 1.5264575481414795
Validation loss: 2.0827623105818227

Epoch: 5| Step: 8
Training loss: 1.8377174139022827
Validation loss: 1.9903789169044905

Epoch: 5| Step: 9
Training loss: 1.3820120096206665
Validation loss: 1.9916680833344818

Epoch: 5| Step: 10
Training loss: 2.304442882537842
Validation loss: 2.084921747125605

Epoch: 363| Step: 0
Training loss: 1.8856302499771118
Validation loss: 2.0949151926143195

Epoch: 5| Step: 1
Training loss: 1.996864676475525
Validation loss: 2.048805549580564

Epoch: 5| Step: 2
Training loss: 1.7767822742462158
Validation loss: 2.0636196033928984

Epoch: 5| Step: 3
Training loss: 1.8577064275741577
Validation loss: 2.088431473701231

Epoch: 5| Step: 4
Training loss: 2.3756299018859863
Validation loss: 2.046498070481003

Epoch: 5| Step: 5
Training loss: 1.78179931640625
Validation loss: 2.0693322227847193

Epoch: 5| Step: 6
Training loss: 1.6540896892547607
Validation loss: 2.024436511019225

Epoch: 5| Step: 7
Training loss: 2.371549129486084
Validation loss: 2.0868094531438683

Epoch: 5| Step: 8
Training loss: 2.2889018058776855
Validation loss: 2.0570791639307493

Epoch: 5| Step: 9
Training loss: 2.1260933876037598
Validation loss: 2.10527439014886

Epoch: 5| Step: 10
Training loss: 1.447858214378357
Validation loss: 2.041247976723538

Epoch: 364| Step: 0
Training loss: 2.3435888290405273
Validation loss: 2.068496060627763

Epoch: 5| Step: 1
Training loss: 2.0037665367126465
Validation loss: 2.0992342913022606

Epoch: 5| Step: 2
Training loss: 1.8786519765853882
Validation loss: 2.0202288448169665

Epoch: 5| Step: 3
Training loss: 1.545981764793396
Validation loss: 2.0325634684613956

Epoch: 5| Step: 4
Training loss: 1.812389612197876
Validation loss: 2.0305007862788376

Epoch: 5| Step: 5
Training loss: 2.0762784481048584
Validation loss: 2.074832145885755

Epoch: 5| Step: 6
Training loss: 2.2652339935302734
Validation loss: 2.02898693853809

Epoch: 5| Step: 7
Training loss: 1.867845892906189
Validation loss: 1.9960608149087558

Epoch: 5| Step: 8
Training loss: 1.989027976989746
Validation loss: 2.090530328853156

Epoch: 5| Step: 9
Training loss: 2.4193146228790283
Validation loss: 2.066360819724298

Epoch: 5| Step: 10
Training loss: 1.7803833484649658
Validation loss: 1.99200959872174

Epoch: 365| Step: 0
Training loss: 2.5579493045806885
Validation loss: 2.0256596380664456

Epoch: 5| Step: 1
Training loss: 2.0418267250061035
Validation loss: 2.0809832772900982

Epoch: 5| Step: 2
Training loss: 1.754860281944275
Validation loss: 2.0184511830729823

Epoch: 5| Step: 3
Training loss: 2.058917284011841
Validation loss: 2.0716513292763823

Epoch: 5| Step: 4
Training loss: 1.9439983367919922
Validation loss: 2.1177476298424507

Epoch: 5| Step: 5
Training loss: 1.6772825717926025
Validation loss: 2.059040443871611

Epoch: 5| Step: 6
Training loss: 1.8968079090118408
Validation loss: 2.0370024429854525

Epoch: 5| Step: 7
Training loss: 2.1448841094970703
Validation loss: 2.021038019528953

Epoch: 5| Step: 8
Training loss: 2.1858654022216797
Validation loss: 2.0621563452546314

Epoch: 5| Step: 9
Training loss: 2.063272476196289
Validation loss: 2.0347237586975098

Epoch: 5| Step: 10
Training loss: 1.5118414163589478
Validation loss: 2.0598118817934425

Epoch: 366| Step: 0
Training loss: 2.052346706390381
Validation loss: 2.031235066793298

Epoch: 5| Step: 1
Training loss: 2.0841028690338135
Validation loss: 2.004046091469385

Epoch: 5| Step: 2
Training loss: 1.88921320438385
Validation loss: 2.0615274419066725

Epoch: 5| Step: 3
Training loss: 1.5530064105987549
Validation loss: 2.0709775929809897

Epoch: 5| Step: 4
Training loss: 1.8663218021392822
Validation loss: 2.0798740668963362

Epoch: 5| Step: 5
Training loss: 2.410517454147339
Validation loss: 2.074439098758082

Epoch: 5| Step: 6
Training loss: 1.789289116859436
Validation loss: 2.0503506045187674

Epoch: 5| Step: 7
Training loss: 2.310472011566162
Validation loss: 2.0412299966299408

Epoch: 5| Step: 8
Training loss: 2.262443780899048
Validation loss: 2.012470324834188

Epoch: 5| Step: 9
Training loss: 1.9675010442733765
Validation loss: 2.049576385046846

Epoch: 5| Step: 10
Training loss: 1.9591764211654663
Validation loss: 2.0758730596111667

Epoch: 367| Step: 0
Training loss: 1.5756478309631348
Validation loss: 2.0173486701903807

Epoch: 5| Step: 1
Training loss: 2.0598011016845703
Validation loss: 2.1017028465065906

Epoch: 5| Step: 2
Training loss: 2.0241165161132812
Validation loss: 2.017371885238155

Epoch: 5| Step: 3
Training loss: 2.0015904903411865
Validation loss: 1.98983597242704

Epoch: 5| Step: 4
Training loss: 1.9893248081207275
Validation loss: 2.0661953521031204

Epoch: 5| Step: 5
Training loss: 2.1214497089385986
Validation loss: 2.043111883183961

Epoch: 5| Step: 6
Training loss: 2.253072500228882
Validation loss: 2.041693687438965

Epoch: 5| Step: 7
Training loss: 1.8277924060821533
Validation loss: 2.0439317687865226

Epoch: 5| Step: 8
Training loss: 2.252370834350586
Validation loss: 2.0498099532178653

Epoch: 5| Step: 9
Training loss: 2.2774100303649902
Validation loss: 2.0380768391393844

Epoch: 5| Step: 10
Training loss: 1.6862852573394775
Validation loss: 2.0315402707745953

Epoch: 368| Step: 0
Training loss: 1.723894715309143
Validation loss: 2.1239951118346183

Epoch: 5| Step: 1
Training loss: 2.3865365982055664
Validation loss: 2.1002415610897924

Epoch: 5| Step: 2
Training loss: 2.328134775161743
Validation loss: 2.0571791651428386

Epoch: 5| Step: 3
Training loss: 2.5748696327209473
Validation loss: 2.0882534250136344

Epoch: 5| Step: 4
Training loss: 2.0241477489471436
Validation loss: 2.0263079725286013

Epoch: 5| Step: 5
Training loss: 2.5753893852233887
Validation loss: 2.06091796710927

Epoch: 5| Step: 6
Training loss: 1.7670719623565674
Validation loss: 2.0007078647613525

Epoch: 5| Step: 7
Training loss: 1.2245752811431885
Validation loss: 2.055319136188876

Epoch: 5| Step: 8
Training loss: 2.140629291534424
Validation loss: 2.0956753684628393

Epoch: 5| Step: 9
Training loss: 1.0951082706451416
Validation loss: 2.02554315136325

Epoch: 5| Step: 10
Training loss: 2.2387685775756836
Validation loss: 2.03693720345856

Epoch: 369| Step: 0
Training loss: 1.5865675210952759
Validation loss: 2.0849095557325628

Epoch: 5| Step: 1
Training loss: 1.6044294834136963
Validation loss: 2.036521483493108

Epoch: 5| Step: 2
Training loss: 1.7893120050430298
Validation loss: 1.9974144992008005

Epoch: 5| Step: 3
Training loss: 1.791632056236267
Validation loss: 2.0483839819508214

Epoch: 5| Step: 4
Training loss: 2.3053324222564697
Validation loss: 2.0174373631836264

Epoch: 5| Step: 5
Training loss: 2.9106860160827637
Validation loss: 2.066811212929346

Epoch: 5| Step: 6
Training loss: 2.5284485816955566
Validation loss: 2.03221010392712

Epoch: 5| Step: 7
Training loss: 1.7494837045669556
Validation loss: 2.0800955372471965

Epoch: 5| Step: 8
Training loss: 1.4784305095672607
Validation loss: 2.060264951439314

Epoch: 5| Step: 9
Training loss: 2.0297915935516357
Validation loss: 2.085729327253116

Epoch: 5| Step: 10
Training loss: 1.873574137687683
Validation loss: 2.009263562899764

Epoch: 370| Step: 0
Training loss: 2.1035518646240234
Validation loss: 2.0646009599008868

Epoch: 5| Step: 1
Training loss: 1.5389772653579712
Validation loss: 2.0827745737568026

Epoch: 5| Step: 2
Training loss: 2.046788454055786
Validation loss: 2.0911183818694083

Epoch: 5| Step: 3
Training loss: 1.6679986715316772
Validation loss: 2.027388708565825

Epoch: 5| Step: 4
Training loss: 1.739676833152771
Validation loss: 2.0269795130657893

Epoch: 5| Step: 5
Training loss: 2.04862904548645
Validation loss: 2.0023345126900622

Epoch: 5| Step: 6
Training loss: 2.2901508808135986
Validation loss: 2.02564787736503

Epoch: 5| Step: 7
Training loss: 1.7093915939331055
Validation loss: 2.0470007799004994

Epoch: 5| Step: 8
Training loss: 2.2979841232299805
Validation loss: 2.124032738388226

Epoch: 5| Step: 9
Training loss: 2.64713716506958
Validation loss: 2.010785218208067

Epoch: 5| Step: 10
Training loss: 2.0626132488250732
Validation loss: 2.051278139955254

Epoch: 371| Step: 0
Training loss: 2.0716474056243896
Validation loss: 2.0892524334692184

Epoch: 5| Step: 1
Training loss: 1.7383496761322021
Validation loss: 2.058834268200782

Epoch: 5| Step: 2
Training loss: 1.6102672815322876
Validation loss: 2.0148868150608514

Epoch: 5| Step: 3
Training loss: 1.4716217517852783
Validation loss: 2.061840599583041

Epoch: 5| Step: 4
Training loss: 2.460313081741333
Validation loss: 2.0235598061674382

Epoch: 5| Step: 5
Training loss: 1.894910454750061
Validation loss: 2.0683599492555023

Epoch: 5| Step: 6
Training loss: 2.2471776008605957
Validation loss: 2.0764617266193515

Epoch: 5| Step: 7
Training loss: 2.0191969871520996
Validation loss: 2.02310400496247

Epoch: 5| Step: 8
Training loss: 1.7132728099822998
Validation loss: 2.076104974233976

Epoch: 5| Step: 9
Training loss: 2.11541485786438
Validation loss: 2.0221402683565692

Epoch: 5| Step: 10
Training loss: 2.4723551273345947
Validation loss: 2.033175876063685

Epoch: 372| Step: 0
Training loss: 1.7935705184936523
Validation loss: 2.0507412341333207

Epoch: 5| Step: 1
Training loss: 2.0829014778137207
Validation loss: 2.014265557771088

Epoch: 5| Step: 2
Training loss: 2.576024055480957
Validation loss: 2.0980136086863856

Epoch: 5| Step: 3
Training loss: 2.063809871673584
Validation loss: 2.0254934987714215

Epoch: 5| Step: 4
Training loss: 1.8949954509735107
Validation loss: 2.0243865802723873

Epoch: 5| Step: 5
Training loss: 1.8329578638076782
Validation loss: 2.028249443218272

Epoch: 5| Step: 6
Training loss: 1.7491562366485596
Validation loss: 2.0307326547561155

Epoch: 5| Step: 7
Training loss: 2.374079942703247
Validation loss: 2.0161739677511235

Epoch: 5| Step: 8
Training loss: 1.4940232038497925
Validation loss: 2.0474750418816843

Epoch: 5| Step: 9
Training loss: 1.854793906211853
Validation loss: 2.015716269452085

Epoch: 5| Step: 10
Training loss: 2.0261003971099854
Validation loss: 2.022313638400006

Epoch: 373| Step: 0
Training loss: 1.8013718128204346
Validation loss: 2.0192705033927836

Epoch: 5| Step: 1
Training loss: 1.7533162832260132
Validation loss: 2.035127320597249

Epoch: 5| Step: 2
Training loss: 2.0667524337768555
Validation loss: 2.0210375529463573

Epoch: 5| Step: 3
Training loss: 2.1270084381103516
Validation loss: 2.0799488508573143

Epoch: 5| Step: 4
Training loss: 1.5468440055847168
Validation loss: 2.0772589970660467

Epoch: 5| Step: 5
Training loss: 1.9820197820663452
Validation loss: 2.0791699130048036

Epoch: 5| Step: 6
Training loss: 1.9321130514144897
Validation loss: 2.103153419750993

Epoch: 5| Step: 7
Training loss: 2.6220033168792725
Validation loss: 2.0489110767200427

Epoch: 5| Step: 8
Training loss: 2.4365782737731934
Validation loss: 2.069816340682327

Epoch: 5| Step: 9
Training loss: 1.3339300155639648
Validation loss: 2.130864529199498

Epoch: 5| Step: 10
Training loss: 1.5243487358093262
Validation loss: 2.1152526691395748

Epoch: 374| Step: 0
Training loss: 1.837627649307251
Validation loss: 2.0752082691397717

Epoch: 5| Step: 1
Training loss: 1.7857248783111572
Validation loss: 2.0243985140195457

Epoch: 5| Step: 2
Training loss: 1.7713515758514404
Validation loss: 2.058983246485392

Epoch: 5| Step: 3
Training loss: 2.3443825244903564
Validation loss: 2.021193858115904

Epoch: 5| Step: 4
Training loss: 1.6398197412490845
Validation loss: 2.044279340774782

Epoch: 5| Step: 5
Training loss: 2.043505907058716
Validation loss: 2.021801984438332

Epoch: 5| Step: 6
Training loss: 1.6819617748260498
Validation loss: 2.097985852149225

Epoch: 5| Step: 7
Training loss: 1.8399951457977295
Validation loss: 2.0464170876369683

Epoch: 5| Step: 8
Training loss: 1.9954588413238525
Validation loss: 2.078992311672498

Epoch: 5| Step: 9
Training loss: 2.1090683937072754
Validation loss: 2.0762346508682414

Epoch: 5| Step: 10
Training loss: 2.199883460998535
Validation loss: 2.057792834056321

Epoch: 375| Step: 0
Training loss: 1.5969038009643555
Validation loss: 2.0780434377731813

Epoch: 5| Step: 1
Training loss: 2.4127354621887207
Validation loss: 2.058243642571152

Epoch: 5| Step: 2
Training loss: 1.8423881530761719
Validation loss: 2.046412237228886

Epoch: 5| Step: 3
Training loss: 2.4485762119293213
Validation loss: 2.0118885488920313

Epoch: 5| Step: 4
Training loss: 1.9244425296783447
Validation loss: 1.9538196094574467

Epoch: 5| Step: 5
Training loss: 2.090564250946045
Validation loss: 2.054658378324201

Epoch: 5| Step: 6
Training loss: 2.176666259765625
Validation loss: 2.0678576423275854

Epoch: 5| Step: 7
Training loss: 1.662071943283081
Validation loss: 1.9861739066339308

Epoch: 5| Step: 8
Training loss: 1.5608189105987549
Validation loss: 1.9916909843362787

Epoch: 5| Step: 9
Training loss: 2.3360161781311035
Validation loss: 2.1035476448715373

Epoch: 5| Step: 10
Training loss: 1.7321405410766602
Validation loss: 2.0687492521860267

Epoch: 376| Step: 0
Training loss: 1.624070167541504
Validation loss: 2.0121037037141862

Epoch: 5| Step: 1
Training loss: 2.264024019241333
Validation loss: 2.0552099904706402

Epoch: 5| Step: 2
Training loss: 1.6384894847869873
Validation loss: 2.0155135495688326

Epoch: 5| Step: 3
Training loss: 1.7434508800506592
Validation loss: 2.03622265015879

Epoch: 5| Step: 4
Training loss: 1.9944556951522827
Validation loss: 2.026505372857535

Epoch: 5| Step: 5
Training loss: 2.245325803756714
Validation loss: 2.051430441999948

Epoch: 5| Step: 6
Training loss: 2.1067068576812744
Validation loss: 2.046093994571317

Epoch: 5| Step: 7
Training loss: 2.2206058502197266
Validation loss: 2.0827173315068728

Epoch: 5| Step: 8
Training loss: 1.9430011510849
Validation loss: 2.0365780527873705

Epoch: 5| Step: 9
Training loss: 2.281186580657959
Validation loss: 2.071990236159294

Epoch: 5| Step: 10
Training loss: 1.5189481973648071
Validation loss: 2.126596863551806

Epoch: 377| Step: 0
Training loss: 2.772129774093628
Validation loss: 1.9923825507522912

Epoch: 5| Step: 1
Training loss: 1.5563760995864868
Validation loss: 2.0863392609421925

Epoch: 5| Step: 2
Training loss: 1.1998999118804932
Validation loss: 2.0376035398052585

Epoch: 5| Step: 3
Training loss: 1.593613862991333
Validation loss: 2.0433042639045307

Epoch: 5| Step: 4
Training loss: 1.8719276189804077
Validation loss: 2.0348682659928516

Epoch: 5| Step: 5
Training loss: 2.0950400829315186
Validation loss: 2.0406339053184754

Epoch: 5| Step: 6
Training loss: 1.947317123413086
Validation loss: 2.0553819517935477

Epoch: 5| Step: 7
Training loss: 2.013572931289673
Validation loss: 2.020258434357182

Epoch: 5| Step: 8
Training loss: 1.800917387008667
Validation loss: 2.072853301161079

Epoch: 5| Step: 9
Training loss: 2.1917757987976074
Validation loss: 1.995835215814652

Epoch: 5| Step: 10
Training loss: 2.4831502437591553
Validation loss: 2.0887398783878615

Epoch: 378| Step: 0
Training loss: 1.9231090545654297
Validation loss: 1.9924364269420665

Epoch: 5| Step: 1
Training loss: 2.276362895965576
Validation loss: 2.098537197677038

Epoch: 5| Step: 2
Training loss: 1.630816102027893
Validation loss: 2.0379171115095898

Epoch: 5| Step: 3
Training loss: 1.843682885169983
Validation loss: 2.0097557319107877

Epoch: 5| Step: 4
Training loss: 2.448895215988159
Validation loss: 2.073792302480308

Epoch: 5| Step: 5
Training loss: 1.7299083471298218
Validation loss: 2.038782106932773

Epoch: 5| Step: 6
Training loss: 2.056272506713867
Validation loss: 2.0500555422998246

Epoch: 5| Step: 7
Training loss: 2.225938558578491
Validation loss: 2.007402273916429

Epoch: 5| Step: 8
Training loss: 1.936353087425232
Validation loss: 2.1080635824511127

Epoch: 5| Step: 9
Training loss: 1.2364552021026611
Validation loss: 2.1325194271661903

Epoch: 5| Step: 10
Training loss: 2.125530481338501
Validation loss: 2.04249737083271

Epoch: 379| Step: 0
Training loss: 2.1587607860565186
Validation loss: 1.9926627118100402

Epoch: 5| Step: 1
Training loss: 1.312951683998108
Validation loss: 2.061193778950681

Epoch: 5| Step: 2
Training loss: 1.8392413854599
Validation loss: 2.0501407141326577

Epoch: 5| Step: 3
Training loss: 1.2609121799468994
Validation loss: 2.078494850025382

Epoch: 5| Step: 4
Training loss: 1.8959643840789795
Validation loss: 2.0544774763045774

Epoch: 5| Step: 5
Training loss: 2.442197322845459
Validation loss: 2.0816930083818335

Epoch: 5| Step: 6
Training loss: 2.103121042251587
Validation loss: 2.039044177660378

Epoch: 5| Step: 7
Training loss: 2.1650710105895996
Validation loss: 2.0700809032686296

Epoch: 5| Step: 8
Training loss: 1.3421285152435303
Validation loss: 2.0473079399396013

Epoch: 5| Step: 9
Training loss: 2.8387019634246826
Validation loss: 1.9956472868560462

Epoch: 5| Step: 10
Training loss: 2.0331859588623047
Validation loss: 2.024154374676366

Epoch: 380| Step: 0
Training loss: 1.5630661249160767
Validation loss: 2.005542003980247

Epoch: 5| Step: 1
Training loss: 2.1250665187835693
Validation loss: 2.0575763717774422

Epoch: 5| Step: 2
Training loss: 2.2258126735687256
Validation loss: 1.9968130639804307

Epoch: 5| Step: 3
Training loss: 2.1125292778015137
Validation loss: 2.0586627529513453

Epoch: 5| Step: 4
Training loss: 1.9087789058685303
Validation loss: 2.1055879182713007

Epoch: 5| Step: 5
Training loss: 1.4117299318313599
Validation loss: 2.0405865689759612

Epoch: 5| Step: 6
Training loss: 2.659553289413452
Validation loss: 2.0348692658126994

Epoch: 5| Step: 7
Training loss: 1.6002477407455444
Validation loss: 2.0281499560161302

Epoch: 5| Step: 8
Training loss: 1.5685726404190063
Validation loss: 2.017264694295904

Epoch: 5| Step: 9
Training loss: 2.1844592094421387
Validation loss: 2.098431525691863

Epoch: 5| Step: 10
Training loss: 2.2981059551239014
Validation loss: 2.084122723148715

Epoch: 381| Step: 0
Training loss: 2.1934638023376465
Validation loss: 2.1004572991401917

Epoch: 5| Step: 1
Training loss: 1.3036386966705322
Validation loss: 1.9933426072520595

Epoch: 5| Step: 2
Training loss: 2.2324538230895996
Validation loss: 2.0364083179863552

Epoch: 5| Step: 3
Training loss: 2.2934727668762207
Validation loss: 2.042350983106962

Epoch: 5| Step: 4
Training loss: 2.217376232147217
Validation loss: 2.057374814505218

Epoch: 5| Step: 5
Training loss: 2.207122325897217
Validation loss: 2.054852886866498

Epoch: 5| Step: 6
Training loss: 2.0037028789520264
Validation loss: 2.034595622811266

Epoch: 5| Step: 7
Training loss: 2.0616884231567383
Validation loss: 2.0109924577897593

Epoch: 5| Step: 8
Training loss: 2.0852229595184326
Validation loss: 2.0365102739744287

Epoch: 5| Step: 9
Training loss: 1.8056418895721436
Validation loss: 2.053314193602531

Epoch: 5| Step: 10
Training loss: 1.3122695684432983
Validation loss: 2.0168474323006085

Epoch: 382| Step: 0
Training loss: 2.0950663089752197
Validation loss: 2.052764338831748

Epoch: 5| Step: 1
Training loss: 2.2030811309814453
Validation loss: 2.095644864984738

Epoch: 5| Step: 2
Training loss: 2.1296615600585938
Validation loss: 2.111948864434355

Epoch: 5| Step: 3
Training loss: 1.79806387424469
Validation loss: 2.1232014856030865

Epoch: 5| Step: 4
Training loss: 1.972884178161621
Validation loss: 2.0412151557143017

Epoch: 5| Step: 5
Training loss: 1.8129041194915771
Validation loss: 2.0742564380809827

Epoch: 5| Step: 6
Training loss: 1.9645206928253174
Validation loss: 2.0537923946175525

Epoch: 5| Step: 7
Training loss: 1.7628753185272217
Validation loss: 2.0877711849827922

Epoch: 5| Step: 8
Training loss: 2.066932439804077
Validation loss: 1.9561087264809558

Epoch: 5| Step: 9
Training loss: 1.8073663711547852
Validation loss: 2.032333811124166

Epoch: 5| Step: 10
Training loss: 1.8958038091659546
Validation loss: 2.0850117065573253

Epoch: 383| Step: 0
Training loss: 2.1706299781799316
Validation loss: 2.0879078372832267

Epoch: 5| Step: 1
Training loss: 1.9189764261245728
Validation loss: 2.0071348964527087

Epoch: 5| Step: 2
Training loss: 2.048126220703125
Validation loss: 2.0702743914819535

Epoch: 5| Step: 3
Training loss: 1.700453758239746
Validation loss: 2.0502357726456015

Epoch: 5| Step: 4
Training loss: 2.1749491691589355
Validation loss: 2.0320732183353876

Epoch: 5| Step: 5
Training loss: 2.1795506477355957
Validation loss: 1.999089123100363

Epoch: 5| Step: 6
Training loss: 1.5657678842544556
Validation loss: 2.0614439851494244

Epoch: 5| Step: 7
Training loss: 1.3512755632400513
Validation loss: 2.097395820002402

Epoch: 5| Step: 8
Training loss: 2.2088277339935303
Validation loss: 2.048220766487942

Epoch: 5| Step: 9
Training loss: 1.8703142404556274
Validation loss: 2.0631919676257717

Epoch: 5| Step: 10
Training loss: 2.154460906982422
Validation loss: 2.0373629716134842

Epoch: 384| Step: 0
Training loss: 1.7469021081924438
Validation loss: 2.0244161826308056

Epoch: 5| Step: 1
Training loss: 2.1271042823791504
Validation loss: 2.1249898044011926

Epoch: 5| Step: 2
Training loss: 1.9886302947998047
Validation loss: 2.0345784156553206

Epoch: 5| Step: 3
Training loss: 1.8704875707626343
Validation loss: 2.0192324576839322

Epoch: 5| Step: 4
Training loss: 2.6282143592834473
Validation loss: 2.048797228003061

Epoch: 5| Step: 5
Training loss: 1.9981095790863037
Validation loss: 2.0822459395213793

Epoch: 5| Step: 6
Training loss: 2.0790648460388184
Validation loss: 2.0684670453430503

Epoch: 5| Step: 7
Training loss: 1.621342420578003
Validation loss: 2.0301548998842955

Epoch: 5| Step: 8
Training loss: 1.511880874633789
Validation loss: 2.054861384053384

Epoch: 5| Step: 9
Training loss: 1.5822069644927979
Validation loss: 2.064969308914677

Epoch: 5| Step: 10
Training loss: 2.2271182537078857
Validation loss: 2.0232603178229382

Epoch: 385| Step: 0
Training loss: 2.208266496658325
Validation loss: 2.0173558624841834

Epoch: 5| Step: 1
Training loss: 2.5349857807159424
Validation loss: 2.09171962225309

Epoch: 5| Step: 2
Training loss: 1.8282983303070068
Validation loss: 2.055034158050373

Epoch: 5| Step: 3
Training loss: 1.7154861688613892
Validation loss: 2.0407580816617577

Epoch: 5| Step: 4
Training loss: 1.6349296569824219
Validation loss: 2.054669495551817

Epoch: 5| Step: 5
Training loss: 2.018855571746826
Validation loss: 2.1033815055765133

Epoch: 5| Step: 6
Training loss: 1.714874505996704
Validation loss: 2.033300038306944

Epoch: 5| Step: 7
Training loss: 1.669110894203186
Validation loss: 2.096303815482765

Epoch: 5| Step: 8
Training loss: 1.9792979955673218
Validation loss: 2.0275166419244584

Epoch: 5| Step: 9
Training loss: 2.0590577125549316
Validation loss: 2.0711688508269606

Epoch: 5| Step: 10
Training loss: 1.8765993118286133
Validation loss: 2.0042928470078336

Epoch: 386| Step: 0
Training loss: 1.7052170038223267
Validation loss: 2.028533704819218

Epoch: 5| Step: 1
Training loss: 2.132321834564209
Validation loss: 2.040830212254678

Epoch: 5| Step: 2
Training loss: 1.8016201257705688
Validation loss: 1.9952358725250408

Epoch: 5| Step: 3
Training loss: 2.0565028190612793
Validation loss: 2.0418540303425123

Epoch: 5| Step: 4
Training loss: 2.1055679321289062
Validation loss: 2.1155306754573697

Epoch: 5| Step: 5
Training loss: 2.316793918609619
Validation loss: 1.9932985677514026

Epoch: 5| Step: 6
Training loss: 1.760007619857788
Validation loss: 1.9942882804460422

Epoch: 5| Step: 7
Training loss: 1.9071762561798096
Validation loss: 2.0967034101486206

Epoch: 5| Step: 8
Training loss: 1.4708060026168823
Validation loss: 2.0712617533181303

Epoch: 5| Step: 9
Training loss: 1.8202130794525146
Validation loss: 2.0383440704755884

Epoch: 5| Step: 10
Training loss: 2.293325424194336
Validation loss: 2.07784632713564

Epoch: 387| Step: 0
Training loss: 1.9565130472183228
Validation loss: 2.0829239173602034

Epoch: 5| Step: 1
Training loss: 2.4439010620117188
Validation loss: 2.0481782779898694

Epoch: 5| Step: 2
Training loss: 2.033311367034912
Validation loss: 1.977789895508879

Epoch: 5| Step: 3
Training loss: 1.5966647863388062
Validation loss: 2.0443203885068177

Epoch: 5| Step: 4
Training loss: 1.6894538402557373
Validation loss: 2.0582125956012356

Epoch: 5| Step: 5
Training loss: 1.6793829202651978
Validation loss: 2.036279079734638

Epoch: 5| Step: 6
Training loss: 2.223747968673706
Validation loss: 2.0725757486076763

Epoch: 5| Step: 7
Training loss: 2.242339611053467
Validation loss: 2.062996688709464

Epoch: 5| Step: 8
Training loss: 1.8016630411148071
Validation loss: 2.030344622109526

Epoch: 5| Step: 9
Training loss: 1.5713481903076172
Validation loss: 2.042380814911217

Epoch: 5| Step: 10
Training loss: 2.0098321437835693
Validation loss: 2.0395175590310046

Epoch: 388| Step: 0
Training loss: 2.338954448699951
Validation loss: 2.0418281696176015

Epoch: 5| Step: 1
Training loss: 1.746911644935608
Validation loss: 2.07821068199732

Epoch: 5| Step: 2
Training loss: 1.5679868459701538
Validation loss: 2.057315129105763

Epoch: 5| Step: 3
Training loss: 1.504793643951416
Validation loss: 2.0409611514819566

Epoch: 5| Step: 4
Training loss: 1.9399681091308594
Validation loss: 2.0000722959477413

Epoch: 5| Step: 5
Training loss: 1.878599762916565
Validation loss: 2.0796090479820006

Epoch: 5| Step: 6
Training loss: 2.3444886207580566
Validation loss: 2.0584529587017593

Epoch: 5| Step: 7
Training loss: 1.9924342632293701
Validation loss: 2.0822315177609845

Epoch: 5| Step: 8
Training loss: 2.066155195236206
Validation loss: 1.989185162769851

Epoch: 5| Step: 9
Training loss: 1.8702421188354492
Validation loss: 2.0886380723727647

Epoch: 5| Step: 10
Training loss: 2.3731868267059326
Validation loss: 2.009592992003246

Epoch: 389| Step: 0
Training loss: 1.5973907709121704
Validation loss: 2.0575184693900486

Epoch: 5| Step: 1
Training loss: 1.8724559545516968
Validation loss: 2.0339153248776674

Epoch: 5| Step: 2
Training loss: 1.9289093017578125
Validation loss: 2.0814415716355845

Epoch: 5| Step: 3
Training loss: 1.9214388132095337
Validation loss: 2.124147609997821

Epoch: 5| Step: 4
Training loss: 1.905083417892456
Validation loss: 2.0630840281004548

Epoch: 5| Step: 5
Training loss: 2.838463306427002
Validation loss: 2.009006570744258

Epoch: 5| Step: 6
Training loss: 2.555363893508911
Validation loss: 2.0234373538724837

Epoch: 5| Step: 7
Training loss: 1.3263475894927979
Validation loss: 1.9894370827623593

Epoch: 5| Step: 8
Training loss: 1.7958767414093018
Validation loss: 2.0917719641039447

Epoch: 5| Step: 9
Training loss: 1.968915581703186
Validation loss: 1.9854637576687721

Epoch: 5| Step: 10
Training loss: 1.5091602802276611
Validation loss: 2.0368251903082735

Epoch: 390| Step: 0
Training loss: 1.7453111410140991
Validation loss: 2.0500058076714955

Epoch: 5| Step: 1
Training loss: 1.7239011526107788
Validation loss: 2.060208466745192

Epoch: 5| Step: 2
Training loss: 2.062124013900757
Validation loss: 2.0409142483947096

Epoch: 5| Step: 3
Training loss: 2.140629768371582
Validation loss: 2.012157359430867

Epoch: 5| Step: 4
Training loss: 2.5197818279266357
Validation loss: 2.028149502251738

Epoch: 5| Step: 5
Training loss: 1.7230703830718994
Validation loss: 1.9765818772777435

Epoch: 5| Step: 6
Training loss: 2.199439287185669
Validation loss: 2.0121880654365785

Epoch: 5| Step: 7
Training loss: 1.8871408700942993
Validation loss: 2.0739452813261297

Epoch: 5| Step: 8
Training loss: 1.6603196859359741
Validation loss: 2.0277801713635846

Epoch: 5| Step: 9
Training loss: 1.9229505062103271
Validation loss: 2.0273585140064196

Epoch: 5| Step: 10
Training loss: 1.4114750623703003
Validation loss: 2.076877627321469

Epoch: 391| Step: 0
Training loss: 1.4419291019439697
Validation loss: 2.0237718679571666

Epoch: 5| Step: 1
Training loss: 2.455620288848877
Validation loss: 2.0232591808483167

Epoch: 5| Step: 2
Training loss: 2.1327266693115234
Validation loss: 2.058877803946054

Epoch: 5| Step: 3
Training loss: 1.8491008281707764
Validation loss: 2.0381689212655507

Epoch: 5| Step: 4
Training loss: 1.9362170696258545
Validation loss: 2.029294644632647

Epoch: 5| Step: 5
Training loss: 1.8691034317016602
Validation loss: 2.0932207838181527

Epoch: 5| Step: 6
Training loss: 2.1964969635009766
Validation loss: 2.0883413053327993

Epoch: 5| Step: 7
Training loss: 1.3550838232040405
Validation loss: 2.0683970323172947

Epoch: 5| Step: 8
Training loss: 2.2824363708496094
Validation loss: 2.043397136913833

Epoch: 5| Step: 9
Training loss: 1.949792504310608
Validation loss: 2.054670182607507

Epoch: 5| Step: 10
Training loss: 1.0461912155151367
Validation loss: 2.0494332826265724

Epoch: 392| Step: 0
Training loss: 2.2728755474090576
Validation loss: 2.0875838623251965

Epoch: 5| Step: 1
Training loss: 2.1680004596710205
Validation loss: 2.0943139137760287

Epoch: 5| Step: 2
Training loss: 1.1755858659744263
Validation loss: 2.075023574213828

Epoch: 5| Step: 3
Training loss: 2.1372952461242676
Validation loss: 2.0472752253214517

Epoch: 5| Step: 4
Training loss: 2.107358694076538
Validation loss: 2.12351962571503

Epoch: 5| Step: 5
Training loss: 1.6013838052749634
Validation loss: 2.0597557842090564

Epoch: 5| Step: 6
Training loss: 1.472882866859436
Validation loss: 2.071230524329729

Epoch: 5| Step: 7
Training loss: 2.0933361053466797
Validation loss: 2.088977790647937

Epoch: 5| Step: 8
Training loss: 2.229745864868164
Validation loss: 2.0435432977573846

Epoch: 5| Step: 9
Training loss: 1.8320789337158203
Validation loss: 2.0705686666632213

Epoch: 5| Step: 10
Training loss: 2.215308666229248
Validation loss: 2.07940762530091

Epoch: 393| Step: 0
Training loss: 1.8404953479766846
Validation loss: 2.104081984489195

Epoch: 5| Step: 1
Training loss: 1.2559895515441895
Validation loss: 2.099966190194571

Epoch: 5| Step: 2
Training loss: 1.377990484237671
Validation loss: 2.039878054331708

Epoch: 5| Step: 3
Training loss: 2.2979419231414795
Validation loss: 2.0402421015565113

Epoch: 5| Step: 4
Training loss: 1.9626424312591553
Validation loss: 2.0825714757365565

Epoch: 5| Step: 5
Training loss: 2.4059383869171143
Validation loss: 2.0000467569597307

Epoch: 5| Step: 6
Training loss: 1.9401302337646484
Validation loss: 2.00783759163272

Epoch: 5| Step: 7
Training loss: 2.130007028579712
Validation loss: 2.112987187600905

Epoch: 5| Step: 8
Training loss: 1.9954115152359009
Validation loss: 2.038236261695944

Epoch: 5| Step: 9
Training loss: 2.00526762008667
Validation loss: 2.0357558778537217

Epoch: 5| Step: 10
Training loss: 1.9449564218521118
Validation loss: 2.074605772572179

Epoch: 394| Step: 0
Training loss: 1.7212921380996704
Validation loss: 2.1028618786924627

Epoch: 5| Step: 1
Training loss: 1.383121371269226
Validation loss: 2.073006794016848

Epoch: 5| Step: 2
Training loss: 1.8729374408721924
Validation loss: 2.093972647061912

Epoch: 5| Step: 3
Training loss: 1.9023281335830688
Validation loss: 2.0565837070506108

Epoch: 5| Step: 4
Training loss: 2.122056245803833
Validation loss: 2.0408166326502317

Epoch: 5| Step: 5
Training loss: 2.2365736961364746
Validation loss: 2.052534628939885

Epoch: 5| Step: 6
Training loss: 2.0040745735168457
Validation loss: 2.060032921452676

Epoch: 5| Step: 7
Training loss: 1.6260955333709717
Validation loss: 2.0199941396713257

Epoch: 5| Step: 8
Training loss: 1.6881002187728882
Validation loss: 2.0371880121128534

Epoch: 5| Step: 9
Training loss: 2.883554220199585
Validation loss: 1.9836189016219108

Epoch: 5| Step: 10
Training loss: 1.6067367792129517
Validation loss: 2.0249029949147213

Epoch: 395| Step: 0
Training loss: 1.95919668674469
Validation loss: 1.98566666213415

Epoch: 5| Step: 1
Training loss: 1.5247094631195068
Validation loss: 2.0476533238605787

Epoch: 5| Step: 2
Training loss: 1.6876064538955688
Validation loss: 2.0397411213126233

Epoch: 5| Step: 3
Training loss: 1.9103271961212158
Validation loss: 2.1037207354781446

Epoch: 5| Step: 4
Training loss: 2.047039747238159
Validation loss: 2.0502297403991863

Epoch: 5| Step: 5
Training loss: 2.0601181983947754
Validation loss: 2.01396938549575

Epoch: 5| Step: 6
Training loss: 2.0625946521759033
Validation loss: 2.081532350150488

Epoch: 5| Step: 7
Training loss: 1.9889898300170898
Validation loss: 2.067427783884028

Epoch: 5| Step: 8
Training loss: 2.0222015380859375
Validation loss: 2.0313464377516057

Epoch: 5| Step: 9
Training loss: 1.9246816635131836
Validation loss: 2.0588391891089817

Epoch: 5| Step: 10
Training loss: 1.5808219909667969
Validation loss: 2.107504265282744

Epoch: 396| Step: 0
Training loss: 1.3558776378631592
Validation loss: 2.071692866663779

Epoch: 5| Step: 1
Training loss: 2.3037467002868652
Validation loss: 2.0195853248719247

Epoch: 5| Step: 2
Training loss: 2.2334468364715576
Validation loss: 2.002561221840561

Epoch: 5| Step: 3
Training loss: 1.5422385931015015
Validation loss: 2.0606963352490495

Epoch: 5| Step: 4
Training loss: 1.9924224615097046
Validation loss: 2.072145632518235

Epoch: 5| Step: 5
Training loss: 1.9843428134918213
Validation loss: 2.0394621767023557

Epoch: 5| Step: 6
Training loss: 1.5493515729904175
Validation loss: 2.0161773158657934

Epoch: 5| Step: 7
Training loss: 2.166529893875122
Validation loss: 2.0183840233792543

Epoch: 5| Step: 8
Training loss: 1.980898141860962
Validation loss: 2.0804767595824374

Epoch: 5| Step: 9
Training loss: 1.6368290185928345
Validation loss: 2.12110839351531

Epoch: 5| Step: 10
Training loss: 2.014768600463867
Validation loss: 2.003382998128091

Epoch: 397| Step: 0
Training loss: 1.974265694618225
Validation loss: 2.018691578219014

Epoch: 5| Step: 1
Training loss: 1.5625373125076294
Validation loss: 2.0378477855395247

Epoch: 5| Step: 2
Training loss: 1.8331485986709595
Validation loss: 2.114998568770706

Epoch: 5| Step: 3
Training loss: 1.6763932704925537
Validation loss: 2.111163572598529

Epoch: 5| Step: 4
Training loss: 2.0173351764678955
Validation loss: 2.0987524242811304

Epoch: 5| Step: 5
Training loss: 1.8605760335922241
Validation loss: 2.0187849101199897

Epoch: 5| Step: 6
Training loss: 1.6717312335968018
Validation loss: 2.0726360582536265

Epoch: 5| Step: 7
Training loss: 1.86862051486969
Validation loss: 2.0886062755379626

Epoch: 5| Step: 8
Training loss: 2.2531542778015137
Validation loss: 2.0641611032588507

Epoch: 5| Step: 9
Training loss: 1.9585695266723633
Validation loss: 2.0725696291974796

Epoch: 5| Step: 10
Training loss: 2.290553569793701
Validation loss: 2.07394318426809

Epoch: 398| Step: 0
Training loss: 1.9944547414779663
Validation loss: 2.0273436756544214

Epoch: 5| Step: 1
Training loss: 2.14841890335083
Validation loss: 2.074116499193253

Epoch: 5| Step: 2
Training loss: 1.7014780044555664
Validation loss: 2.022536837926475

Epoch: 5| Step: 3
Training loss: 1.9118735790252686
Validation loss: 2.1041094538986043

Epoch: 5| Step: 4
Training loss: 2.100630044937134
Validation loss: 1.9980242816350793

Epoch: 5| Step: 5
Training loss: 2.134378433227539
Validation loss: 2.023433962175923

Epoch: 5| Step: 6
Training loss: 2.118678331375122
Validation loss: 1.9851908735049668

Epoch: 5| Step: 7
Training loss: 1.4144668579101562
Validation loss: 2.0515580536216818

Epoch: 5| Step: 8
Training loss: 2.0490708351135254
Validation loss: 2.055560476036482

Epoch: 5| Step: 9
Training loss: 1.8057801723480225
Validation loss: 2.0289190635886243

Epoch: 5| Step: 10
Training loss: 1.8067681789398193
Validation loss: 2.0328001540194274

Epoch: 399| Step: 0
Training loss: 1.7786805629730225
Validation loss: 2.010227458451384

Epoch: 5| Step: 1
Training loss: 1.8551231622695923
Validation loss: 2.027941132104525

Epoch: 5| Step: 2
Training loss: 1.6914533376693726
Validation loss: 2.0487289223619687

Epoch: 5| Step: 3
Training loss: 1.705984354019165
Validation loss: 2.049011899578956

Epoch: 5| Step: 4
Training loss: 2.12683367729187
Validation loss: 2.0436581898761053

Epoch: 5| Step: 5
Training loss: 2.1920361518859863
Validation loss: 2.118527458560082

Epoch: 5| Step: 6
Training loss: 1.9249845743179321
Validation loss: 2.0019056130481023

Epoch: 5| Step: 7
Training loss: 1.8459628820419312
Validation loss: 1.9925263389464347

Epoch: 5| Step: 8
Training loss: 1.8952325582504272
Validation loss: 2.014602175322912

Epoch: 5| Step: 9
Training loss: 1.9519922733306885
Validation loss: 1.9768672835442327

Epoch: 5| Step: 10
Training loss: 1.9234105348587036
Validation loss: 2.0136458950658

Epoch: 400| Step: 0
Training loss: 2.039821147918701
Validation loss: 2.0223902579276793

Epoch: 5| Step: 1
Training loss: 1.7835257053375244
Validation loss: 2.004990901998294

Epoch: 5| Step: 2
Training loss: 1.0018203258514404
Validation loss: 2.0283861211551133

Epoch: 5| Step: 3
Training loss: 2.532597780227661
Validation loss: 2.0402240548082577

Epoch: 5| Step: 4
Training loss: 1.8982980251312256
Validation loss: 2.035081466039022

Epoch: 5| Step: 5
Training loss: 1.9328914880752563
Validation loss: 2.0349260299436507

Epoch: 5| Step: 6
Training loss: 1.3349673748016357
Validation loss: 1.9901749421191472

Epoch: 5| Step: 7
Training loss: 2.144139289855957
Validation loss: 2.0189570021885697

Epoch: 5| Step: 8
Training loss: 2.096299648284912
Validation loss: 1.9796438909346057

Epoch: 5| Step: 9
Training loss: 2.000178337097168
Validation loss: 2.043335921020918

Epoch: 5| Step: 10
Training loss: 2.4519901275634766
Validation loss: 2.000113400079871

Epoch: 401| Step: 0
Training loss: 1.6009706258773804
Validation loss: 2.0007003571397517

Epoch: 5| Step: 1
Training loss: 1.6850357055664062
Validation loss: 2.0676953664389988

Epoch: 5| Step: 2
Training loss: 1.558957815170288
Validation loss: 2.046961551071495

Epoch: 5| Step: 3
Training loss: 1.651039481163025
Validation loss: 2.0384894609451294

Epoch: 5| Step: 4
Training loss: 2.0743656158447266
Validation loss: 2.0280359252806632

Epoch: 5| Step: 5
Training loss: 1.8480056524276733
Validation loss: 2.0207377197921916

Epoch: 5| Step: 6
Training loss: 1.127139687538147
Validation loss: 2.0706795851389566

Epoch: 5| Step: 7
Training loss: 1.6118545532226562
Validation loss: 2.040957943085701

Epoch: 5| Step: 8
Training loss: 2.4638190269470215
Validation loss: 2.030097605079733

Epoch: 5| Step: 9
Training loss: 2.5149078369140625
Validation loss: 2.030467866569437

Epoch: 5| Step: 10
Training loss: 2.052976369857788
Validation loss: 2.0292570924246185

Epoch: 402| Step: 0
Training loss: 1.886967420578003
Validation loss: 2.0093801765031714

Epoch: 5| Step: 1
Training loss: 2.1551501750946045
Validation loss: 2.0186496960219515

Epoch: 5| Step: 2
Training loss: 2.3352108001708984
Validation loss: 2.0162793538903676

Epoch: 5| Step: 3
Training loss: 1.7256393432617188
Validation loss: 2.0962942813032415

Epoch: 5| Step: 4
Training loss: 1.7849843502044678
Validation loss: 2.0447551127403014

Epoch: 5| Step: 5
Training loss: 1.7033164501190186
Validation loss: 2.061668793360392

Epoch: 5| Step: 6
Training loss: 1.700564980506897
Validation loss: 2.013376123161726

Epoch: 5| Step: 7
Training loss: 1.5050019025802612
Validation loss: 2.0329911901104833

Epoch: 5| Step: 8
Training loss: 1.8827850818634033
Validation loss: 2.0605557682693645

Epoch: 5| Step: 9
Training loss: 2.0766584873199463
Validation loss: 2.073589628742587

Epoch: 5| Step: 10
Training loss: 2.2258005142211914
Validation loss: 2.060961499009081

Epoch: 403| Step: 0
Training loss: 2.0404245853424072
Validation loss: 2.0575809555668987

Epoch: 5| Step: 1
Training loss: 1.775530219078064
Validation loss: 2.0151496548806467

Epoch: 5| Step: 2
Training loss: 1.5629613399505615
Validation loss: 2.1337691404486216

Epoch: 5| Step: 3
Training loss: 2.1444969177246094
Validation loss: 2.007110934103689

Epoch: 5| Step: 4
Training loss: 1.8395512104034424
Validation loss: 2.034326409780851

Epoch: 5| Step: 5
Training loss: 2.178335428237915
Validation loss: 2.0699983873674945

Epoch: 5| Step: 6
Training loss: 2.4578757286071777
Validation loss: 2.0219059631388676

Epoch: 5| Step: 7
Training loss: 1.6016390323638916
Validation loss: 2.040866341642154

Epoch: 5| Step: 8
Training loss: 1.9130939245224
Validation loss: 1.999344515544112

Epoch: 5| Step: 9
Training loss: 1.4609915018081665
Validation loss: 2.0276721639017903

Epoch: 5| Step: 10
Training loss: 1.8616825342178345
Validation loss: 2.0546406507492065

Epoch: 404| Step: 0
Training loss: 1.6609115600585938
Validation loss: 2.035408563511346

Epoch: 5| Step: 1
Training loss: 1.631988525390625
Validation loss: 2.057745208022415

Epoch: 5| Step: 2
Training loss: 2.034424304962158
Validation loss: 2.093217149857552

Epoch: 5| Step: 3
Training loss: 1.7561028003692627
Validation loss: 2.0033681136305614

Epoch: 5| Step: 4
Training loss: 2.0365560054779053
Validation loss: 1.9908676570461643

Epoch: 5| Step: 5
Training loss: 2.6887784004211426
Validation loss: 2.023118069094996

Epoch: 5| Step: 6
Training loss: 1.8143638372421265
Validation loss: 2.039640657363399

Epoch: 5| Step: 7
Training loss: 1.9491426944732666
Validation loss: 2.0901999140298493

Epoch: 5| Step: 8
Training loss: 1.682512640953064
Validation loss: 2.066171884536743

Epoch: 5| Step: 9
Training loss: 1.472507119178772
Validation loss: 2.106470218268774

Epoch: 5| Step: 10
Training loss: 2.2461376190185547
Validation loss: 2.0807949983945457

Epoch: 405| Step: 0
Training loss: 2.1737942695617676
Validation loss: 2.0382232512197187

Epoch: 5| Step: 1
Training loss: 1.7760179042816162
Validation loss: 1.9979798178518973

Epoch: 5| Step: 2
Training loss: 1.7737630605697632
Validation loss: 2.0820154259281773

Epoch: 5| Step: 3
Training loss: 2.029083490371704
Validation loss: 2.065772789780812

Epoch: 5| Step: 4
Training loss: 2.432325839996338
Validation loss: 2.0950344275402766

Epoch: 5| Step: 5
Training loss: 1.8220109939575195
Validation loss: 2.1114317986272995

Epoch: 5| Step: 6
Training loss: 2.3178811073303223
Validation loss: 2.017280267130944

Epoch: 5| Step: 7
Training loss: 1.690765619277954
Validation loss: 1.9931213753197783

Epoch: 5| Step: 8
Training loss: 1.9656070470809937
Validation loss: 2.055971746803612

Epoch: 5| Step: 9
Training loss: 1.3246694803237915
Validation loss: 2.0086131198431856

Epoch: 5| Step: 10
Training loss: 1.0887596607208252
Validation loss: 2.0393313592480076

Epoch: 406| Step: 0
Training loss: 2.3177528381347656
Validation loss: 2.0300254642322497

Epoch: 5| Step: 1
Training loss: 2.3003218173980713
Validation loss: 2.0142213336883055

Epoch: 5| Step: 2
Training loss: 1.7873685359954834
Validation loss: 2.008855309537662

Epoch: 5| Step: 3
Training loss: 1.530146837234497
Validation loss: 1.990246001110282

Epoch: 5| Step: 4
Training loss: 1.7463197708129883
Validation loss: 2.0227301043848835

Epoch: 5| Step: 5
Training loss: 2.2152981758117676
Validation loss: 2.034245506409676

Epoch: 5| Step: 6
Training loss: 1.7971782684326172
Validation loss: 1.9976569106501918

Epoch: 5| Step: 7
Training loss: 1.7611865997314453
Validation loss: 2.0616256139611684

Epoch: 5| Step: 8
Training loss: 2.2358386516571045
Validation loss: 2.037093916246968

Epoch: 5| Step: 9
Training loss: 1.8681895732879639
Validation loss: 2.0082677320767472

Epoch: 5| Step: 10
Training loss: 2.002352476119995
Validation loss: 2.0632949721428657

Epoch: 407| Step: 0
Training loss: 1.8750251531600952
Validation loss: 2.082691292608938

Epoch: 5| Step: 1
Training loss: 1.4688405990600586
Validation loss: 2.06729067525556

Epoch: 5| Step: 2
Training loss: 1.7406257390975952
Validation loss: 2.0230546587256977

Epoch: 5| Step: 3
Training loss: 2.1038739681243896
Validation loss: 2.0047674332895586

Epoch: 5| Step: 4
Training loss: 2.030529499053955
Validation loss: 2.0418657384892946

Epoch: 5| Step: 5
Training loss: 1.3955647945404053
Validation loss: 1.9814199811668807

Epoch: 5| Step: 6
Training loss: 2.251767635345459
Validation loss: 2.069735465511199

Epoch: 5| Step: 7
Training loss: 1.5138334035873413
Validation loss: 1.9837755387829197

Epoch: 5| Step: 8
Training loss: 2.00827956199646
Validation loss: 2.0082049267266386

Epoch: 5| Step: 9
Training loss: 2.0475411415100098
Validation loss: 2.012297404709683

Epoch: 5| Step: 10
Training loss: 2.2424089908599854
Validation loss: 2.004920454435451

Epoch: 408| Step: 0
Training loss: 1.5632411241531372
Validation loss: 2.0673796874220653

Epoch: 5| Step: 1
Training loss: 2.363051414489746
Validation loss: 2.128436501308154

Epoch: 5| Step: 2
Training loss: 2.016746997833252
Validation loss: 2.082032747166131

Epoch: 5| Step: 3
Training loss: 1.712598204612732
Validation loss: 2.0611560575423704

Epoch: 5| Step: 4
Training loss: 2.371887683868408
Validation loss: 2.0583435720013035

Epoch: 5| Step: 5
Training loss: 1.8546345233917236
Validation loss: 1.99390378562353

Epoch: 5| Step: 6
Training loss: 1.914304494857788
Validation loss: 2.0140800065891717

Epoch: 5| Step: 7
Training loss: 1.735833764076233
Validation loss: 2.0219893301686933

Epoch: 5| Step: 8
Training loss: 1.4189389944076538
Validation loss: 2.0092947277971493

Epoch: 5| Step: 9
Training loss: 1.4046212434768677
Validation loss: 2.064565320168772

Epoch: 5| Step: 10
Training loss: 2.1644392013549805
Validation loss: 2.0439094599857124

Epoch: 409| Step: 0
Training loss: 2.199606418609619
Validation loss: 1.9808173717990998

Epoch: 5| Step: 1
Training loss: 1.9528754949569702
Validation loss: 2.0718908745755433

Epoch: 5| Step: 2
Training loss: 1.7991584539413452
Validation loss: 2.0715371498497586

Epoch: 5| Step: 3
Training loss: 2.041982650756836
Validation loss: 2.0191317527524886

Epoch: 5| Step: 4
Training loss: 2.360307216644287
Validation loss: 2.055430599438247

Epoch: 5| Step: 5
Training loss: 1.8932101726531982
Validation loss: 1.9640479882558186

Epoch: 5| Step: 6
Training loss: 1.6058101654052734
Validation loss: 2.0408252080281577

Epoch: 5| Step: 7
Training loss: 2.3903491497039795
Validation loss: 2.00845673776442

Epoch: 5| Step: 8
Training loss: 1.9950147867202759
Validation loss: 1.9962218705043997

Epoch: 5| Step: 9
Training loss: 1.5320861339569092
Validation loss: 2.022612931907818

Epoch: 5| Step: 10
Training loss: 1.472162127494812
Validation loss: 2.0708355416533766

Epoch: 410| Step: 0
Training loss: 1.5188426971435547
Validation loss: 1.9862146403199883

Epoch: 5| Step: 1
Training loss: 0.7631601095199585
Validation loss: 2.0651862595670964

Epoch: 5| Step: 2
Training loss: 2.426079511642456
Validation loss: 2.0324728514558528

Epoch: 5| Step: 3
Training loss: 2.0736052989959717
Validation loss: 2.009003895585255

Epoch: 5| Step: 4
Training loss: 2.022735595703125
Validation loss: 2.0487919007578204

Epoch: 5| Step: 5
Training loss: 2.133561849594116
Validation loss: 2.0109600033811343

Epoch: 5| Step: 6
Training loss: 2.2567172050476074
Validation loss: 2.0207000778567408

Epoch: 5| Step: 7
Training loss: 1.96455979347229
Validation loss: 2.0402652422587075

Epoch: 5| Step: 8
Training loss: 1.1633182764053345
Validation loss: 2.0442968696676274

Epoch: 5| Step: 9
Training loss: 2.1242780685424805
Validation loss: 2.039994978135632

Epoch: 5| Step: 10
Training loss: 2.406156539916992
Validation loss: 2.0320744129919235

Epoch: 411| Step: 0
Training loss: 1.7576360702514648
Validation loss: 2.078254104942404

Epoch: 5| Step: 1
Training loss: 1.5219351053237915
Validation loss: 2.0975434062301472

Epoch: 5| Step: 2
Training loss: 2.035112142562866
Validation loss: 2.0144146514195267

Epoch: 5| Step: 3
Training loss: 1.5311305522918701
Validation loss: 1.9872385199351976

Epoch: 5| Step: 4
Training loss: 2.080632448196411
Validation loss: 2.0208790276640203

Epoch: 5| Step: 5
Training loss: 2.0579628944396973
Validation loss: 2.09954942939102

Epoch: 5| Step: 6
Training loss: 2.3396315574645996
Validation loss: 2.053608061164938

Epoch: 5| Step: 7
Training loss: 2.365582227706909
Validation loss: 2.0681173224602976

Epoch: 5| Step: 8
Training loss: 1.6100614070892334
Validation loss: 2.054405132929484

Epoch: 5| Step: 9
Training loss: 1.4979041814804077
Validation loss: 2.0536185515824186

Epoch: 5| Step: 10
Training loss: 2.627915859222412
Validation loss: 2.0761636367408176

Epoch: 412| Step: 0
Training loss: 1.6423231363296509
Validation loss: 2.0670360224221342

Epoch: 5| Step: 1
Training loss: 1.641343355178833
Validation loss: 2.0921709358051257

Epoch: 5| Step: 2
Training loss: 1.7689173221588135
Validation loss: 2.045406236443468

Epoch: 5| Step: 3
Training loss: 1.9775962829589844
Validation loss: 2.029081040813077

Epoch: 5| Step: 4
Training loss: 1.7214126586914062
Validation loss: 2.02769104126961

Epoch: 5| Step: 5
Training loss: 2.440232038497925
Validation loss: 2.0241012111786874

Epoch: 5| Step: 6
Training loss: 1.5329753160476685
Validation loss: 1.9637607348862516

Epoch: 5| Step: 7
Training loss: 2.0084686279296875
Validation loss: 2.078796819974017

Epoch: 5| Step: 8
Training loss: 2.800924301147461
Validation loss: 2.0327532176048524

Epoch: 5| Step: 9
Training loss: 1.9166462421417236
Validation loss: 1.9699315332597302

Epoch: 5| Step: 10
Training loss: 1.5936685800552368
Validation loss: 2.065394345150199

Epoch: 413| Step: 0
Training loss: 1.447131872177124
Validation loss: 2.0407307224888958

Epoch: 5| Step: 1
Training loss: 2.1538376808166504
Validation loss: 2.0097129396213

Epoch: 5| Step: 2
Training loss: 1.93887197971344
Validation loss: 2.0306041458601594

Epoch: 5| Step: 3
Training loss: 1.3787648677825928
Validation loss: 2.052224382277458

Epoch: 5| Step: 4
Training loss: 1.6252189874649048
Validation loss: 2.0416662859660324

Epoch: 5| Step: 5
Training loss: 1.8379452228546143
Validation loss: 2.001021174974339

Epoch: 5| Step: 6
Training loss: 2.1705174446105957
Validation loss: 2.019773825522392

Epoch: 5| Step: 7
Training loss: 2.4254260063171387
Validation loss: 2.072574718024141

Epoch: 5| Step: 8
Training loss: 1.9767738580703735
Validation loss: 2.014320695272056

Epoch: 5| Step: 9
Training loss: 1.7721011638641357
Validation loss: 2.0496845783725863

Epoch: 5| Step: 10
Training loss: 1.653516173362732
Validation loss: 2.0295143768351567

Epoch: 414| Step: 0
Training loss: 1.5998384952545166
Validation loss: 1.995999974589194

Epoch: 5| Step: 1
Training loss: 1.7498743534088135
Validation loss: 2.0072845579475485

Epoch: 5| Step: 2
Training loss: 2.2344985008239746
Validation loss: 2.0173889026846936

Epoch: 5| Step: 3
Training loss: 1.44937002658844
Validation loss: 2.054190242162315

Epoch: 5| Step: 4
Training loss: 1.7712348699569702
Validation loss: 2.0921395337709816

Epoch: 5| Step: 5
Training loss: 2.375063180923462
Validation loss: 2.103491613941808

Epoch: 5| Step: 6
Training loss: 2.526796817779541
Validation loss: 2.0670380566709783

Epoch: 5| Step: 7
Training loss: 2.485433578491211
Validation loss: 2.0052536879816363

Epoch: 5| Step: 8
Training loss: 1.854360818862915
Validation loss: 2.0445893246640443

Epoch: 5| Step: 9
Training loss: 1.3570977449417114
Validation loss: 2.046077291170756

Epoch: 5| Step: 10
Training loss: 1.396661639213562
Validation loss: 2.0152898373142367

Epoch: 415| Step: 0
Training loss: 1.9735743999481201
Validation loss: 2.070365608379405

Epoch: 5| Step: 1
Training loss: 1.0138390064239502
Validation loss: 2.037092249880555

Epoch: 5| Step: 2
Training loss: 2.147427558898926
Validation loss: 2.0138107269041

Epoch: 5| Step: 3
Training loss: 2.1574177742004395
Validation loss: 2.0666794866643925

Epoch: 5| Step: 4
Training loss: 1.785030722618103
Validation loss: 2.0208105220589587

Epoch: 5| Step: 5
Training loss: 1.7970564365386963
Validation loss: 2.131780587216859

Epoch: 5| Step: 6
Training loss: 2.1512210369110107
Validation loss: 2.0294237393204884

Epoch: 5| Step: 7
Training loss: 2.5450985431671143
Validation loss: 2.0316882248847716

Epoch: 5| Step: 8
Training loss: 1.8339996337890625
Validation loss: 2.0753608801031627

Epoch: 5| Step: 9
Training loss: 1.548488974571228
Validation loss: 2.0423398069156113

Epoch: 5| Step: 10
Training loss: 2.133781909942627
Validation loss: 2.059699276442169

Epoch: 416| Step: 0
Training loss: 1.5854008197784424
Validation loss: 2.085890316194104

Epoch: 5| Step: 1
Training loss: 2.1883580684661865
Validation loss: 2.0576856828504995

Epoch: 5| Step: 2
Training loss: 1.8171240091323853
Validation loss: 1.9964032814066897

Epoch: 5| Step: 3
Training loss: 1.5714263916015625
Validation loss: 1.978572327603576

Epoch: 5| Step: 4
Training loss: 2.8956167697906494
Validation loss: 2.0105475507756716

Epoch: 5| Step: 5
Training loss: 1.6038166284561157
Validation loss: 2.070917588408275

Epoch: 5| Step: 6
Training loss: 1.5725728273391724
Validation loss: 2.0417114368049045

Epoch: 5| Step: 7
Training loss: 1.8342339992523193
Validation loss: 1.9020670562662103

Epoch: 5| Step: 8
Training loss: 1.7760534286499023
Validation loss: 2.0644994756226898

Epoch: 5| Step: 9
Training loss: 1.887155532836914
Validation loss: 2.0276570115038144

Epoch: 5| Step: 10
Training loss: 1.5802042484283447
Validation loss: 2.0768094831897366

Epoch: 417| Step: 0
Training loss: 1.7735722064971924
Validation loss: 2.045952679008566

Epoch: 5| Step: 1
Training loss: 1.7943880558013916
Validation loss: 2.05462549835123

Epoch: 5| Step: 2
Training loss: 2.0390143394470215
Validation loss: 2.0709195983025337

Epoch: 5| Step: 3
Training loss: 1.8640491962432861
Validation loss: 2.060325732795141

Epoch: 5| Step: 4
Training loss: 2.2639567852020264
Validation loss: 2.0206606080455165

Epoch: 5| Step: 5
Training loss: 1.773467779159546
Validation loss: 2.09193496037555

Epoch: 5| Step: 6
Training loss: 1.7353744506835938
Validation loss: 2.0707619446580128

Epoch: 5| Step: 7
Training loss: 2.175873279571533
Validation loss: 2.0375200074206115

Epoch: 5| Step: 8
Training loss: 1.4397437572479248
Validation loss: 2.1387706520736858

Epoch: 5| Step: 9
Training loss: 1.811560869216919
Validation loss: 2.0556697755731563

Epoch: 5| Step: 10
Training loss: 2.4268715381622314
Validation loss: 2.017234553572952

Epoch: 418| Step: 0
Training loss: 1.8202022314071655
Validation loss: 2.0285123150835753

Epoch: 5| Step: 1
Training loss: 2.3430984020233154
Validation loss: 2.0338844817171813

Epoch: 5| Step: 2
Training loss: 1.511588454246521
Validation loss: 2.0093153907406713

Epoch: 5| Step: 3
Training loss: 1.2093431949615479
Validation loss: 1.96424699342379

Epoch: 5| Step: 4
Training loss: 1.8443994522094727
Validation loss: 2.061908624505484

Epoch: 5| Step: 5
Training loss: 2.0671849250793457
Validation loss: 2.0316064947394916

Epoch: 5| Step: 6
Training loss: 2.256762742996216
Validation loss: 2.0267930274368613

Epoch: 5| Step: 7
Training loss: 1.7606372833251953
Validation loss: 1.9791629416968233

Epoch: 5| Step: 8
Training loss: 1.9933497905731201
Validation loss: 2.011413343491093

Epoch: 5| Step: 9
Training loss: 1.6434478759765625
Validation loss: 2.0249730540860083

Epoch: 5| Step: 10
Training loss: 2.4056484699249268
Validation loss: 2.0377121689499065

Epoch: 419| Step: 0
Training loss: 1.9169037342071533
Validation loss: 2.0015844029764973

Epoch: 5| Step: 1
Training loss: 1.8502023220062256
Validation loss: 2.0950135210508942

Epoch: 5| Step: 2
Training loss: 1.8726228475570679
Validation loss: 2.018973263361121

Epoch: 5| Step: 3
Training loss: 2.115027666091919
Validation loss: 2.078561818727883

Epoch: 5| Step: 4
Training loss: 2.1458065509796143
Validation loss: 1.9936908560414468

Epoch: 5| Step: 5
Training loss: 1.9474542140960693
Validation loss: 2.030377882783131

Epoch: 5| Step: 6
Training loss: 2.4412755966186523
Validation loss: 2.106194821737146

Epoch: 5| Step: 7
Training loss: 1.2627707719802856
Validation loss: 2.056234641741681

Epoch: 5| Step: 8
Training loss: 1.408121109008789
Validation loss: 2.024748707330355

Epoch: 5| Step: 9
Training loss: 1.933824896812439
Validation loss: 2.0799177872237338

Epoch: 5| Step: 10
Training loss: 2.094755172729492
Validation loss: 2.0316480334087084

Epoch: 420| Step: 0
Training loss: 2.556096315383911
Validation loss: 2.0402342324615805

Epoch: 5| Step: 1
Training loss: 2.066558361053467
Validation loss: 2.021298546944895

Epoch: 5| Step: 2
Training loss: 1.4840748310089111
Validation loss: 2.013032151806739

Epoch: 5| Step: 3
Training loss: 1.1549451351165771
Validation loss: 2.0263833589451288

Epoch: 5| Step: 4
Training loss: 1.6285321712493896
Validation loss: 2.0247137700357745

Epoch: 5| Step: 5
Training loss: 1.565856695175171
Validation loss: 2.038637158691242

Epoch: 5| Step: 6
Training loss: 2.035534143447876
Validation loss: 2.0573523095858994

Epoch: 5| Step: 7
Training loss: 2.5541718006134033
Validation loss: 2.0111831952166814

Epoch: 5| Step: 8
Training loss: 1.6621087789535522
Validation loss: 2.0291302665587394

Epoch: 5| Step: 9
Training loss: 2.054333209991455
Validation loss: 2.030195795079713

Epoch: 5| Step: 10
Training loss: 1.7102570533752441
Validation loss: 2.046460028617613

Epoch: 421| Step: 0
Training loss: 1.8207381963729858
Validation loss: 2.050341603576496

Epoch: 5| Step: 1
Training loss: 1.7645015716552734
Validation loss: 2.0115217893354354

Epoch: 5| Step: 2
Training loss: 2.075730085372925
Validation loss: 2.0731986363728843

Epoch: 5| Step: 3
Training loss: 0.9799823760986328
Validation loss: 2.037549977661461

Epoch: 5| Step: 4
Training loss: 1.6141735315322876
Validation loss: 2.1118115635328394

Epoch: 5| Step: 5
Training loss: 1.7962534427642822
Validation loss: 2.022542453581287

Epoch: 5| Step: 6
Training loss: 1.3946714401245117
Validation loss: 2.06899461566761

Epoch: 5| Step: 7
Training loss: 2.0774085521698
Validation loss: 2.143678770270399

Epoch: 5| Step: 8
Training loss: 2.4707136154174805
Validation loss: 2.0806486991143998

Epoch: 5| Step: 9
Training loss: 2.5066709518432617
Validation loss: 2.144998609378774

Epoch: 5| Step: 10
Training loss: 1.6671644449234009
Validation loss: 2.0312044056512977

Epoch: 422| Step: 0
Training loss: 1.5131723880767822
Validation loss: 2.0583754406180432

Epoch: 5| Step: 1
Training loss: 2.254547119140625
Validation loss: 2.0718738443108013

Epoch: 5| Step: 2
Training loss: 1.5659581422805786
Validation loss: 2.0873459013559486

Epoch: 5| Step: 3
Training loss: 2.036147356033325
Validation loss: 2.10001782191697

Epoch: 5| Step: 4
Training loss: 2.2597250938415527
Validation loss: 2.103406249835927

Epoch: 5| Step: 5
Training loss: 2.140817165374756
Validation loss: 2.050626991897501

Epoch: 5| Step: 6
Training loss: 1.6413100957870483
Validation loss: 2.0427123128726916

Epoch: 5| Step: 7
Training loss: 2.278649091720581
Validation loss: 2.09036950654881

Epoch: 5| Step: 8
Training loss: 1.3128955364227295
Validation loss: 2.105287589052672

Epoch: 5| Step: 9
Training loss: 1.7252721786499023
Validation loss: 2.0517288613063034

Epoch: 5| Step: 10
Training loss: 1.7740384340286255
Validation loss: 2.0734973184524046

Epoch: 423| Step: 0
Training loss: 1.8638204336166382
Validation loss: 2.035984448207322

Epoch: 5| Step: 1
Training loss: 2.0628838539123535
Validation loss: 2.090372093262211

Epoch: 5| Step: 2
Training loss: 2.4067752361297607
Validation loss: 2.051737049574493

Epoch: 5| Step: 3
Training loss: 1.9249827861785889
Validation loss: 2.0443297406678558

Epoch: 5| Step: 4
Training loss: 1.835257887840271
Validation loss: 2.0574892490140853

Epoch: 5| Step: 5
Training loss: 1.5723215341567993
Validation loss: 2.004847156104221

Epoch: 5| Step: 6
Training loss: 1.8294862508773804
Validation loss: 2.018130462656739

Epoch: 5| Step: 7
Training loss: 1.4981181621551514
Validation loss: 2.016961028498988

Epoch: 5| Step: 8
Training loss: 2.2267608642578125
Validation loss: 2.0757328746139363

Epoch: 5| Step: 9
Training loss: 2.18491792678833
Validation loss: 2.07063324733447

Epoch: 5| Step: 10
Training loss: 1.1755259037017822
Validation loss: 1.9807585554738198

Epoch: 424| Step: 0
Training loss: 1.9461305141448975
Validation loss: 2.0665836077864452

Epoch: 5| Step: 1
Training loss: 1.8604259490966797
Validation loss: 2.034321355563338

Epoch: 5| Step: 2
Training loss: 1.8146641254425049
Validation loss: 2.0563263970036663

Epoch: 5| Step: 3
Training loss: 1.6767934560775757
Validation loss: 2.040191409408405

Epoch: 5| Step: 4
Training loss: 2.025599956512451
Validation loss: 2.0375540102681806

Epoch: 5| Step: 5
Training loss: 1.8549998998641968
Validation loss: 2.047867327608088

Epoch: 5| Step: 6
Training loss: 2.0226314067840576
Validation loss: 2.0603235844642884

Epoch: 5| Step: 7
Training loss: 1.917636513710022
Validation loss: 1.974380672618907

Epoch: 5| Step: 8
Training loss: 1.5265165567398071
Validation loss: 2.1031555078362905

Epoch: 5| Step: 9
Training loss: 1.9715874195098877
Validation loss: 2.0105636068569717

Epoch: 5| Step: 10
Training loss: 1.4807666540145874
Validation loss: 2.0590014342338807

Epoch: 425| Step: 0
Training loss: 2.2048840522766113
Validation loss: 2.0351492897156747

Epoch: 5| Step: 1
Training loss: 1.5793523788452148
Validation loss: 1.975345330853616

Epoch: 5| Step: 2
Training loss: 1.9441728591918945
Validation loss: 2.0030578926045406

Epoch: 5| Step: 3
Training loss: 1.6953229904174805
Validation loss: 1.9927148203695975

Epoch: 5| Step: 4
Training loss: 2.2667202949523926
Validation loss: 2.06084511356969

Epoch: 5| Step: 5
Training loss: 1.393509864807129
Validation loss: 2.0014038214119534

Epoch: 5| Step: 6
Training loss: 1.674873948097229
Validation loss: 2.0827477350029895

Epoch: 5| Step: 7
Training loss: 2.724641799926758
Validation loss: 1.9792086501275339

Epoch: 5| Step: 8
Training loss: 1.1440311670303345
Validation loss: 2.0813879864190215

Epoch: 5| Step: 9
Training loss: 1.944515585899353
Validation loss: 2.0442732867374214

Epoch: 5| Step: 10
Training loss: 1.50242280960083
Validation loss: 2.053026688996182

Epoch: 426| Step: 0
Training loss: 1.824666976928711
Validation loss: 2.0589463082692956

Epoch: 5| Step: 1
Training loss: 1.7153091430664062
Validation loss: 2.023865153712611

Epoch: 5| Step: 2
Training loss: 2.305307626724243
Validation loss: 2.0467091427054456

Epoch: 5| Step: 3
Training loss: 2.165572166442871
Validation loss: 2.0850123051674134

Epoch: 5| Step: 4
Training loss: 1.5894265174865723
Validation loss: 2.028576584272487

Epoch: 5| Step: 5
Training loss: 1.6156387329101562
Validation loss: 2.038408225582492

Epoch: 5| Step: 6
Training loss: 1.6968498229980469
Validation loss: 2.0283064085950135

Epoch: 5| Step: 7
Training loss: 1.89031183719635
Validation loss: 2.013906991609963

Epoch: 5| Step: 8
Training loss: 1.3174997568130493
Validation loss: 2.0242638921224945

Epoch: 5| Step: 9
Training loss: 2.0380072593688965
Validation loss: 2.0860504911791895

Epoch: 5| Step: 10
Training loss: 2.263219118118286
Validation loss: 1.9867581257256128

Epoch: 427| Step: 0
Training loss: 2.0909762382507324
Validation loss: 2.064909412014869

Epoch: 5| Step: 1
Training loss: 2.013921022415161
Validation loss: 2.0467818757539153

Epoch: 5| Step: 2
Training loss: 2.303856372833252
Validation loss: 2.05970791334747

Epoch: 5| Step: 3
Training loss: 1.5976369380950928
Validation loss: 2.0612282214626187

Epoch: 5| Step: 4
Training loss: 1.6511642932891846
Validation loss: 2.058629705059913

Epoch: 5| Step: 5
Training loss: 1.6553913354873657
Validation loss: 2.0645777781804404

Epoch: 5| Step: 6
Training loss: 2.237473726272583
Validation loss: 2.061754139520789

Epoch: 5| Step: 7
Training loss: 1.470861792564392
Validation loss: 2.073236375726679

Epoch: 5| Step: 8
Training loss: 1.7604694366455078
Validation loss: 2.0427568830469602

Epoch: 5| Step: 9
Training loss: 1.454972267150879
Validation loss: 2.053013645192628

Epoch: 5| Step: 10
Training loss: 2.213090658187866
Validation loss: 2.0188086378958916

Epoch: 428| Step: 0
Training loss: 2.355463743209839
Validation loss: 2.0810565076848513

Epoch: 5| Step: 1
Training loss: 1.846306562423706
Validation loss: 2.061469667701311

Epoch: 5| Step: 2
Training loss: 1.8387012481689453
Validation loss: 2.0366392930348716

Epoch: 5| Step: 3
Training loss: 2.3014047145843506
Validation loss: 2.0844248289703042

Epoch: 5| Step: 4
Training loss: 2.0236432552337646
Validation loss: 2.0270816869633173

Epoch: 5| Step: 5
Training loss: 2.032351016998291
Validation loss: 2.0425718369022494

Epoch: 5| Step: 6
Training loss: 2.137730598449707
Validation loss: 2.1241374413172402

Epoch: 5| Step: 7
Training loss: 1.5522903203964233
Validation loss: 2.0179905455599547

Epoch: 5| Step: 8
Training loss: 1.637027382850647
Validation loss: 2.034834449009229

Epoch: 5| Step: 9
Training loss: 1.2905380725860596
Validation loss: 2.0253821624222623

Epoch: 5| Step: 10
Training loss: 1.4547783136367798
Validation loss: 2.0925939672736713

Epoch: 429| Step: 0
Training loss: 2.1356730461120605
Validation loss: 2.0331285051120225

Epoch: 5| Step: 1
Training loss: 2.3630013465881348
Validation loss: 2.0333131154378257

Epoch: 5| Step: 2
Training loss: 1.4447392225265503
Validation loss: 2.0151018417009743

Epoch: 5| Step: 3
Training loss: 1.349178433418274
Validation loss: 2.051272307672808

Epoch: 5| Step: 4
Training loss: 2.522341728210449
Validation loss: 2.055859575989426

Epoch: 5| Step: 5
Training loss: 1.7809028625488281
Validation loss: 2.1009701798039098

Epoch: 5| Step: 6
Training loss: 1.4019558429718018
Validation loss: 2.011956040577222

Epoch: 5| Step: 7
Training loss: 1.7128700017929077
Validation loss: 2.015315245556575

Epoch: 5| Step: 8
Training loss: 1.548671007156372
Validation loss: 2.0002000626697334

Epoch: 5| Step: 9
Training loss: 1.8243385553359985
Validation loss: 2.0829894440148466

Epoch: 5| Step: 10
Training loss: 2.1857616901397705
Validation loss: 2.0343207800260155

Epoch: 430| Step: 0
Training loss: 1.5098782777786255
Validation loss: 1.9915956476683259

Epoch: 5| Step: 1
Training loss: 1.8305652141571045
Validation loss: 1.9840319207919541

Epoch: 5| Step: 2
Training loss: 1.7651150226593018
Validation loss: 1.994900659848285

Epoch: 5| Step: 3
Training loss: 1.9206125736236572
Validation loss: 2.0359036537908737

Epoch: 5| Step: 4
Training loss: 1.5666093826293945
Validation loss: 2.050469736899099

Epoch: 5| Step: 5
Training loss: 1.844315528869629
Validation loss: 2.0094423781159105

Epoch: 5| Step: 6
Training loss: 2.02176570892334
Validation loss: 2.050619730385401

Epoch: 5| Step: 7
Training loss: 1.8995945453643799
Validation loss: 2.028200973746597

Epoch: 5| Step: 8
Training loss: 1.26614511013031
Validation loss: 1.9551233245480446

Epoch: 5| Step: 9
Training loss: 2.5048890113830566
Validation loss: 2.030085200904518

Epoch: 5| Step: 10
Training loss: 2.242479085922241
Validation loss: 2.073344179379043

Epoch: 431| Step: 0
Training loss: 1.3084074258804321
Validation loss: 2.0432050087118663

Epoch: 5| Step: 1
Training loss: 2.2923147678375244
Validation loss: 2.032693688587476

Epoch: 5| Step: 2
Training loss: 1.7851276397705078
Validation loss: 2.107428655829481

Epoch: 5| Step: 3
Training loss: 1.8655132055282593
Validation loss: 2.095656605177028

Epoch: 5| Step: 4
Training loss: 2.1968040466308594
Validation loss: 2.030098510044877

Epoch: 5| Step: 5
Training loss: 1.7251991033554077
Validation loss: 2.0494072321922547

Epoch: 5| Step: 6
Training loss: 1.8673633337020874
Validation loss: 2.0458896096034715

Epoch: 5| Step: 7
Training loss: 1.2956165075302124
Validation loss: 2.0688097015503915

Epoch: 5| Step: 8
Training loss: 1.9544897079467773
Validation loss: 2.040952754277055

Epoch: 5| Step: 9
Training loss: 1.477224349975586
Validation loss: 2.0173723313116256

Epoch: 5| Step: 10
Training loss: 2.16821551322937
Validation loss: 2.0759774202941568

Epoch: 432| Step: 0
Training loss: 1.617051362991333
Validation loss: 2.0985214710235596

Epoch: 5| Step: 1
Training loss: 1.7601197957992554
Validation loss: 2.0370700769526984

Epoch: 5| Step: 2
Training loss: 1.547234296798706
Validation loss: 2.044380041860765

Epoch: 5| Step: 3
Training loss: 2.062279224395752
Validation loss: 2.0826814315652333

Epoch: 5| Step: 4
Training loss: 1.3519960641860962
Validation loss: 2.0634058239639446

Epoch: 5| Step: 5
Training loss: 2.140024423599243
Validation loss: 2.084649398762693

Epoch: 5| Step: 6
Training loss: 2.0046334266662598
Validation loss: 2.0378526436385287

Epoch: 5| Step: 7
Training loss: 2.1452784538269043
Validation loss: 2.087190201205592

Epoch: 5| Step: 8
Training loss: 1.7917802333831787
Validation loss: 2.1060388882954917

Epoch: 5| Step: 9
Training loss: 1.5577547550201416
Validation loss: 2.0578934684876473

Epoch: 5| Step: 10
Training loss: 1.9633333683013916
Validation loss: 2.070040956620247

Epoch: 433| Step: 0
Training loss: 1.5250136852264404
Validation loss: 1.9743560232141966

Epoch: 5| Step: 1
Training loss: 2.5111610889434814
Validation loss: 2.073940092517484

Epoch: 5| Step: 2
Training loss: 1.854068398475647
Validation loss: 2.092323492932063

Epoch: 5| Step: 3
Training loss: 1.5360628366470337
Validation loss: 1.9955601692199707

Epoch: 5| Step: 4
Training loss: 1.7619059085845947
Validation loss: 2.074166815768006

Epoch: 5| Step: 5
Training loss: 2.077094554901123
Validation loss: 2.060422856320617

Epoch: 5| Step: 6
Training loss: 2.0624401569366455
Validation loss: 2.0322717056479505

Epoch: 5| Step: 7
Training loss: 1.8763952255249023
Validation loss: 2.0741073726325907

Epoch: 5| Step: 8
Training loss: 1.5229876041412354
Validation loss: 1.9972880399355324

Epoch: 5| Step: 9
Training loss: 1.9913181066513062
Validation loss: 2.004095264660415

Epoch: 5| Step: 10
Training loss: 1.4428735971450806
Validation loss: 2.046248706438208

Epoch: 434| Step: 0
Training loss: 1.9217599630355835
Validation loss: 2.0238875483953827

Epoch: 5| Step: 1
Training loss: 1.8068478107452393
Validation loss: 2.033536195755005

Epoch: 5| Step: 2
Training loss: 2.2236685752868652
Validation loss: 2.04452855612642

Epoch: 5| Step: 3
Training loss: 1.7143453359603882
Validation loss: 2.042899465048185

Epoch: 5| Step: 4
Training loss: 1.906070351600647
Validation loss: 2.0083979829665153

Epoch: 5| Step: 5
Training loss: 1.8045545816421509
Validation loss: 2.0217840389538835

Epoch: 5| Step: 6
Training loss: 1.6503417491912842
Validation loss: 1.9929739326559088

Epoch: 5| Step: 7
Training loss: 1.7104778289794922
Validation loss: 2.0254185712465675

Epoch: 5| Step: 8
Training loss: 1.7370067834854126
Validation loss: 1.9702406724294026

Epoch: 5| Step: 9
Training loss: 1.4920448064804077
Validation loss: 2.020412693741501

Epoch: 5| Step: 10
Training loss: 2.1211583614349365
Validation loss: 2.0058178158216577

Epoch: 435| Step: 0
Training loss: 1.5327045917510986
Validation loss: 2.0956746801253288

Epoch: 5| Step: 1
Training loss: 1.8790897130966187
Validation loss: 1.991967462724255

Epoch: 5| Step: 2
Training loss: 2.0683865547180176
Validation loss: 1.9984537619416431

Epoch: 5| Step: 3
Training loss: 1.2536243200302124
Validation loss: 2.0121387486816733

Epoch: 5| Step: 4
Training loss: 2.242284059524536
Validation loss: 2.0659023446421467

Epoch: 5| Step: 5
Training loss: 1.642953634262085
Validation loss: 1.957401926799487

Epoch: 5| Step: 6
Training loss: 1.472022294998169
Validation loss: 2.0449951515402844

Epoch: 5| Step: 7
Training loss: 2.5193629264831543
Validation loss: 1.9629665984902331

Epoch: 5| Step: 8
Training loss: 1.39822256565094
Validation loss: 2.0544731411882626

Epoch: 5| Step: 9
Training loss: 2.1128714084625244
Validation loss: 2.0497789870026293

Epoch: 5| Step: 10
Training loss: 1.8891749382019043
Validation loss: 1.997290656130801

Epoch: 436| Step: 0
Training loss: 1.606776237487793
Validation loss: 2.055650298313428

Epoch: 5| Step: 1
Training loss: 1.636315941810608
Validation loss: 1.9872219600985128

Epoch: 5| Step: 2
Training loss: 2.0431602001190186
Validation loss: 2.021197831758889

Epoch: 5| Step: 3
Training loss: 1.814505934715271
Validation loss: 2.062153059949157

Epoch: 5| Step: 4
Training loss: 1.4296624660491943
Validation loss: 2.0715800023848012

Epoch: 5| Step: 5
Training loss: 1.1578433513641357
Validation loss: 2.0392375966554046

Epoch: 5| Step: 6
Training loss: 1.9297221899032593
Validation loss: 2.0643017689387

Epoch: 5| Step: 7
Training loss: 1.6609466075897217
Validation loss: 2.0112435561354443

Epoch: 5| Step: 8
Training loss: 2.2079503536224365
Validation loss: 1.9866415890314246

Epoch: 5| Step: 9
Training loss: 2.2925257682800293
Validation loss: 2.0912533806216334

Epoch: 5| Step: 10
Training loss: 2.1290886402130127
Validation loss: 2.047433460912397

Epoch: 437| Step: 0
Training loss: 1.4902403354644775
Validation loss: 2.014152726819438

Epoch: 5| Step: 1
Training loss: 2.3682804107666016
Validation loss: 2.0980910511427027

Epoch: 5| Step: 2
Training loss: 1.6052913665771484
Validation loss: 2.0755137012850855

Epoch: 5| Step: 3
Training loss: 2.1673967838287354
Validation loss: 2.0500935034085344

Epoch: 5| Step: 4
Training loss: 1.7919927835464478
Validation loss: 2.0306608369273524

Epoch: 5| Step: 5
Training loss: 1.586672306060791
Validation loss: 2.0373438712089293

Epoch: 5| Step: 6
Training loss: 1.902098298072815
Validation loss: 2.061232989834201

Epoch: 5| Step: 7
Training loss: 1.6810499429702759
Validation loss: 1.9689778435614802

Epoch: 5| Step: 8
Training loss: 1.043226718902588
Validation loss: 2.04422095770477

Epoch: 5| Step: 9
Training loss: 2.0038681030273438
Validation loss: 1.9290979369994132

Epoch: 5| Step: 10
Training loss: 2.2144806385040283
Validation loss: 2.023594640916394

Epoch: 438| Step: 0
Training loss: 2.013711929321289
Validation loss: 2.0354671119361796

Epoch: 5| Step: 1
Training loss: 1.9076483249664307
Validation loss: 2.097058739713443

Epoch: 5| Step: 2
Training loss: 1.5298173427581787
Validation loss: 2.0113374187100317

Epoch: 5| Step: 3
Training loss: 2.0635576248168945
Validation loss: 2.0776965464315107

Epoch: 5| Step: 4
Training loss: 1.6271966695785522
Validation loss: 2.0174380784393637

Epoch: 5| Step: 5
Training loss: 2.351102828979492
Validation loss: 1.9613383200860792

Epoch: 5| Step: 6
Training loss: 1.2648309469223022
Validation loss: 2.0166745531943535

Epoch: 5| Step: 7
Training loss: 1.5224153995513916
Validation loss: 2.0952408570115284

Epoch: 5| Step: 8
Training loss: 1.6827945709228516
Validation loss: 2.0223317287301503

Epoch: 5| Step: 9
Training loss: 2.1274936199188232
Validation loss: 2.056440794339744

Epoch: 5| Step: 10
Training loss: 2.0349082946777344
Validation loss: 1.9611471481220697

Epoch: 439| Step: 0
Training loss: 1.8905960321426392
Validation loss: 1.9745256977696573

Epoch: 5| Step: 1
Training loss: 1.4143928289413452
Validation loss: 2.0767786989929857

Epoch: 5| Step: 2
Training loss: 1.7727129459381104
Validation loss: 2.051646214659496

Epoch: 5| Step: 3
Training loss: 1.856224775314331
Validation loss: 2.0362396804235314

Epoch: 5| Step: 4
Training loss: 1.7235419750213623
Validation loss: 2.0046884987943914

Epoch: 5| Step: 5
Training loss: 1.5777018070220947
Validation loss: 2.053848616538509

Epoch: 5| Step: 6
Training loss: 1.8450164794921875
Validation loss: 2.0098103041289956

Epoch: 5| Step: 7
Training loss: 1.766244888305664
Validation loss: 2.0414928710588844

Epoch: 5| Step: 8
Training loss: 1.8967167139053345
Validation loss: 2.0664461351210073

Epoch: 5| Step: 9
Training loss: 1.9806811809539795
Validation loss: 2.0534368586796585

Epoch: 5| Step: 10
Training loss: 1.5121955871582031
Validation loss: 2.070695597638366

Epoch: 440| Step: 0
Training loss: 1.5815740823745728
Validation loss: 2.0450017324057956

Epoch: 5| Step: 1
Training loss: 1.8375394344329834
Validation loss: 1.9864717786030104

Epoch: 5| Step: 2
Training loss: 1.9002323150634766
Validation loss: 2.0321073147558395

Epoch: 5| Step: 3
Training loss: 2.3198907375335693
Validation loss: 2.042259775182252

Epoch: 5| Step: 4
Training loss: 2.079047679901123
Validation loss: 2.050434527858611

Epoch: 5| Step: 5
Training loss: 1.6681404113769531
Validation loss: 1.9802696410045828

Epoch: 5| Step: 6
Training loss: 1.9763389825820923
Validation loss: 2.0683037260527253

Epoch: 5| Step: 7
Training loss: 1.432094931602478
Validation loss: 2.051989819413872

Epoch: 5| Step: 8
Training loss: 1.8179264068603516
Validation loss: 2.0241249684364564

Epoch: 5| Step: 9
Training loss: 1.679954171180725
Validation loss: 1.982543550511842

Epoch: 5| Step: 10
Training loss: 1.646667242050171
Validation loss: 2.005254125082365

Epoch: 441| Step: 0
Training loss: 1.8938401937484741
Validation loss: 2.0669363467924056

Epoch: 5| Step: 1
Training loss: 1.975412368774414
Validation loss: 2.042263320697251

Epoch: 5| Step: 2
Training loss: 1.2689746618270874
Validation loss: 2.0225744016708864

Epoch: 5| Step: 3
Training loss: 1.824934959411621
Validation loss: 2.063342473840201

Epoch: 5| Step: 4
Training loss: 1.8413480520248413
Validation loss: 2.0670619626199045

Epoch: 5| Step: 5
Training loss: 1.5432603359222412
Validation loss: 2.054036389115036

Epoch: 5| Step: 6
Training loss: 1.8452465534210205
Validation loss: 2.0341851711273193

Epoch: 5| Step: 7
Training loss: 1.7208976745605469
Validation loss: 2.0542270855237077

Epoch: 5| Step: 8
Training loss: 1.8078724145889282
Validation loss: 2.01612744023723

Epoch: 5| Step: 9
Training loss: 2.0140509605407715
Validation loss: 2.0705655415852866

Epoch: 5| Step: 10
Training loss: 2.28665828704834
Validation loss: 2.077383413109728

Epoch: 442| Step: 0
Training loss: 1.8586944341659546
Validation loss: 2.0399823086236113

Epoch: 5| Step: 1
Training loss: 1.8164546489715576
Validation loss: 2.089252018159436

Epoch: 5| Step: 2
Training loss: 1.4482189416885376
Validation loss: 2.004674542334772

Epoch: 5| Step: 3
Training loss: 1.4679381847381592
Validation loss: 2.083354528232287

Epoch: 5| Step: 4
Training loss: 1.7921569347381592
Validation loss: 2.0856039857351654

Epoch: 5| Step: 5
Training loss: 1.931688904762268
Validation loss: 2.0633737028286023

Epoch: 5| Step: 6
Training loss: 1.759575605392456
Validation loss: 2.0408166070138254

Epoch: 5| Step: 7
Training loss: 1.8150928020477295
Validation loss: 2.0935686070431947

Epoch: 5| Step: 8
Training loss: 1.979821801185608
Validation loss: 2.0424853242853636

Epoch: 5| Step: 9
Training loss: 2.0085434913635254
Validation loss: 2.0765425979450183

Epoch: 5| Step: 10
Training loss: 2.2388827800750732
Validation loss: 1.9498369732210714

Epoch: 443| Step: 0
Training loss: 2.057039260864258
Validation loss: 2.0528417018152054

Epoch: 5| Step: 1
Training loss: 1.6739702224731445
Validation loss: 2.105052915952539

Epoch: 5| Step: 2
Training loss: 1.8002128601074219
Validation loss: 2.036112928903231

Epoch: 5| Step: 3
Training loss: 2.002899169921875
Validation loss: 2.0483083289156676

Epoch: 5| Step: 4
Training loss: 2.639897108078003
Validation loss: 2.0296811942131288

Epoch: 5| Step: 5
Training loss: 2.003918170928955
Validation loss: 2.0160013591089556

Epoch: 5| Step: 6
Training loss: 1.5945603847503662
Validation loss: 2.0433021232646

Epoch: 5| Step: 7
Training loss: 1.6408878564834595
Validation loss: 2.0120167911693616

Epoch: 5| Step: 8
Training loss: 1.9767690896987915
Validation loss: 2.0827400145992154

Epoch: 5| Step: 9
Training loss: 1.5755292177200317
Validation loss: 2.0549166240999774

Epoch: 5| Step: 10
Training loss: 1.8714454174041748
Validation loss: 2.060736520316011

Epoch: 444| Step: 0
Training loss: 1.6836397647857666
Validation loss: 2.11312613948699

Epoch: 5| Step: 1
Training loss: 2.2366127967834473
Validation loss: 1.9731717699317521

Epoch: 5| Step: 2
Training loss: 2.0177321434020996
Validation loss: 2.0284419418663107

Epoch: 5| Step: 3
Training loss: 1.9514806270599365
Validation loss: 2.115792735930412

Epoch: 5| Step: 4
Training loss: 2.165005922317505
Validation loss: 2.076531033362112

Epoch: 5| Step: 5
Training loss: 1.7676795721054077
Validation loss: 2.0505982316950315

Epoch: 5| Step: 6
Training loss: 1.5227975845336914
Validation loss: 1.9915471282056583

Epoch: 5| Step: 7
Training loss: 1.3142870664596558
Validation loss: 2.1422193947658745

Epoch: 5| Step: 8
Training loss: 1.706088662147522
Validation loss: 2.0524923621967273

Epoch: 5| Step: 9
Training loss: 1.684931993484497
Validation loss: 2.0123349120540004

Epoch: 5| Step: 10
Training loss: 1.6949784755706787
Validation loss: 2.066612092397546

Epoch: 445| Step: 0
Training loss: 2.3829283714294434
Validation loss: 1.997053921863597

Epoch: 5| Step: 1
Training loss: 2.245694637298584
Validation loss: 2.0863936972874466

Epoch: 5| Step: 2
Training loss: 1.1497544050216675
Validation loss: 2.0457037033573275

Epoch: 5| Step: 3
Training loss: 1.7275993824005127
Validation loss: 2.0527459472738285

Epoch: 5| Step: 4
Training loss: 1.638624906539917
Validation loss: 2.1112911316656295

Epoch: 5| Step: 5
Training loss: 1.6770236492156982
Validation loss: 2.0611280215683805

Epoch: 5| Step: 6
Training loss: 1.5972157716751099
Validation loss: 2.0717201463637815

Epoch: 5| Step: 7
Training loss: 1.827162742614746
Validation loss: 2.035335261334655

Epoch: 5| Step: 8
Training loss: 2.207949161529541
Validation loss: 2.022076663150582

Epoch: 5| Step: 9
Training loss: 1.4872562885284424
Validation loss: 2.1238163671185895

Epoch: 5| Step: 10
Training loss: 2.0217769145965576
Validation loss: 2.012203816444643

Epoch: 446| Step: 0
Training loss: 2.2174015045166016
Validation loss: 2.0161709785461426

Epoch: 5| Step: 1
Training loss: 1.5557067394256592
Validation loss: 2.051804660468973

Epoch: 5| Step: 2
Training loss: 1.5238181352615356
Validation loss: 2.035648448492891

Epoch: 5| Step: 3
Training loss: 1.2883687019348145
Validation loss: 2.02479225333019

Epoch: 5| Step: 4
Training loss: 2.1628525257110596
Validation loss: 1.9882876103924167

Epoch: 5| Step: 5
Training loss: 2.425832748413086
Validation loss: 2.0881933499408025

Epoch: 5| Step: 6
Training loss: 1.8155815601348877
Validation loss: 2.142425260236186

Epoch: 5| Step: 7
Training loss: 1.2540979385375977
Validation loss: 1.985830089097382

Epoch: 5| Step: 8
Training loss: 1.8656864166259766
Validation loss: 2.041424483381292

Epoch: 5| Step: 9
Training loss: 2.5178980827331543
Validation loss: 2.024511250116492

Epoch: 5| Step: 10
Training loss: 1.4497320652008057
Validation loss: 2.027000375973281

Epoch: 447| Step: 0
Training loss: 2.157670497894287
Validation loss: 2.072992709375197

Epoch: 5| Step: 1
Training loss: 1.6288578510284424
Validation loss: 2.084491019607872

Epoch: 5| Step: 2
Training loss: 2.0525336265563965
Validation loss: 2.0484566227082284

Epoch: 5| Step: 3
Training loss: 2.0314180850982666
Validation loss: 2.06957858608615

Epoch: 5| Step: 4
Training loss: 1.6927894353866577
Validation loss: 2.0260966823947046

Epoch: 5| Step: 5
Training loss: 1.5843875408172607
Validation loss: 2.0272346670909593

Epoch: 5| Step: 6
Training loss: 1.347522258758545
Validation loss: 1.9907513049341017

Epoch: 5| Step: 7
Training loss: 2.3074169158935547
Validation loss: 2.0679759133246636

Epoch: 5| Step: 8
Training loss: 1.7627712488174438
Validation loss: 2.103117125008696

Epoch: 5| Step: 9
Training loss: 1.5157599449157715
Validation loss: 2.0357676808552077

Epoch: 5| Step: 10
Training loss: 1.3695898056030273
Validation loss: 2.0857019860257386

Epoch: 448| Step: 0
Training loss: 2.061980724334717
Validation loss: 2.0332766271406606

Epoch: 5| Step: 1
Training loss: 1.928037405014038
Validation loss: 2.0294131053391324

Epoch: 5| Step: 2
Training loss: 1.9933372735977173
Validation loss: 2.038782355605915

Epoch: 5| Step: 3
Training loss: 2.4469234943389893
Validation loss: 2.075912249985562

Epoch: 5| Step: 4
Training loss: 1.620937705039978
Validation loss: 2.0367692260332007

Epoch: 5| Step: 5
Training loss: 1.9299529790878296
Validation loss: 2.0291434282897622

Epoch: 5| Step: 6
Training loss: 1.8812801837921143
Validation loss: 2.0293736662915958

Epoch: 5| Step: 7
Training loss: 1.3676464557647705
Validation loss: 2.0161256046705347

Epoch: 5| Step: 8
Training loss: 1.0754859447479248
Validation loss: 2.007170877149028

Epoch: 5| Step: 9
Training loss: 1.7371774911880493
Validation loss: 2.024070252654373

Epoch: 5| Step: 10
Training loss: 1.9486666917800903
Validation loss: 2.0344948332796813

Epoch: 449| Step: 0
Training loss: 2.0336148738861084
Validation loss: 2.0121926312805503

Epoch: 5| Step: 1
Training loss: 1.5336436033248901
Validation loss: 2.0572792201913814

Epoch: 5| Step: 2
Training loss: 1.6337859630584717
Validation loss: 2.0151834744279102

Epoch: 5| Step: 3
Training loss: 1.5626087188720703
Validation loss: 2.0263002213611396

Epoch: 5| Step: 4
Training loss: 1.6845512390136719
Validation loss: 1.987011117319907

Epoch: 5| Step: 5
Training loss: 2.1460585594177246
Validation loss: 1.9863830099823654

Epoch: 5| Step: 6
Training loss: 1.6409145593643188
Validation loss: 2.0268986455855833

Epoch: 5| Step: 7
Training loss: 1.6668586730957031
Validation loss: 2.1097649246133785

Epoch: 5| Step: 8
Training loss: 2.4523723125457764
Validation loss: 2.0174378630935506

Epoch: 5| Step: 9
Training loss: 1.934627890586853
Validation loss: 2.035873682268204

Epoch: 5| Step: 10
Training loss: 1.865548849105835
Validation loss: 2.028879775795885

Epoch: 450| Step: 0
Training loss: 2.2444541454315186
Validation loss: 2.0258724253664733

Epoch: 5| Step: 1
Training loss: 2.181436061859131
Validation loss: 2.0953554030387633

Epoch: 5| Step: 2
Training loss: 1.651545763015747
Validation loss: 2.0550015241869035

Epoch: 5| Step: 3
Training loss: 1.7428600788116455
Validation loss: 2.056686983313612

Epoch: 5| Step: 4
Training loss: 1.484292984008789
Validation loss: 1.982907477245536

Epoch: 5| Step: 5
Training loss: 1.6973679065704346
Validation loss: 2.114461645003288

Epoch: 5| Step: 6
Training loss: 1.9979264736175537
Validation loss: 1.9915237272939375

Epoch: 5| Step: 7
Training loss: 1.9817860126495361
Validation loss: 1.983362623440322

Epoch: 5| Step: 8
Training loss: 1.7884061336517334
Validation loss: 2.050576053639894

Epoch: 5| Step: 9
Training loss: 1.8090051412582397
Validation loss: 2.07540117027939

Epoch: 5| Step: 10
Training loss: 1.6777445077896118
Validation loss: 2.098168839690506

Epoch: 451| Step: 0
Training loss: 1.3737341165542603
Validation loss: 2.059350637979405

Epoch: 5| Step: 1
Training loss: 1.9404109716415405
Validation loss: 2.0366068488808087

Epoch: 5| Step: 2
Training loss: 1.6708199977874756
Validation loss: 1.9885136081326393

Epoch: 5| Step: 3
Training loss: 1.275360345840454
Validation loss: 2.031663658798382

Epoch: 5| Step: 4
Training loss: 1.4577375650405884
Validation loss: 2.072337797892991

Epoch: 5| Step: 5
Training loss: 2.117828130722046
Validation loss: 2.096294815822314

Epoch: 5| Step: 6
Training loss: 2.0631911754608154
Validation loss: 2.0879419952310543

Epoch: 5| Step: 7
Training loss: 2.2225921154022217
Validation loss: 2.0803484173231226

Epoch: 5| Step: 8
Training loss: 1.9057159423828125
Validation loss: 2.0217616840075423

Epoch: 5| Step: 9
Training loss: 1.6238372325897217
Validation loss: 2.07316844437712

Epoch: 5| Step: 10
Training loss: 1.9994457960128784
Validation loss: 2.0909695343304704

Epoch: 452| Step: 0
Training loss: 1.821973204612732
Validation loss: 2.0585599996710338

Epoch: 5| Step: 1
Training loss: 1.5861401557922363
Validation loss: 2.0638493799394175

Epoch: 5| Step: 2
Training loss: 2.091701030731201
Validation loss: 2.0816436736814437

Epoch: 5| Step: 3
Training loss: 2.2330451011657715
Validation loss: 2.0295675980147494

Epoch: 5| Step: 4
Training loss: 2.1425387859344482
Validation loss: 2.020245408499113

Epoch: 5| Step: 5
Training loss: 1.6109635829925537
Validation loss: 2.069090767573285

Epoch: 5| Step: 6
Training loss: 1.9427791833877563
Validation loss: 2.0360877616431123

Epoch: 5| Step: 7
Training loss: 1.3532259464263916
Validation loss: 2.0750553095212547

Epoch: 5| Step: 8
Training loss: 1.7935854196548462
Validation loss: 2.0772236649708082

Epoch: 5| Step: 9
Training loss: 2.0740609169006348
Validation loss: 2.0159021680073073

Epoch: 5| Step: 10
Training loss: 1.3181225061416626
Validation loss: 1.9781220318168722

Epoch: 453| Step: 0
Training loss: 1.716214895248413
Validation loss: 2.0447876120126374

Epoch: 5| Step: 1
Training loss: 1.9920552968978882
Validation loss: 2.0316604234839

Epoch: 5| Step: 2
Training loss: 1.9203507900238037
Validation loss: 1.9679241436783985

Epoch: 5| Step: 3
Training loss: 1.7179012298583984
Validation loss: 2.1360689311899166

Epoch: 5| Step: 4
Training loss: 2.0098583698272705
Validation loss: 2.0681544478221605

Epoch: 5| Step: 5
Training loss: 1.718390703201294
Validation loss: 1.9697588823174919

Epoch: 5| Step: 6
Training loss: 1.7391294240951538
Validation loss: 2.0345724039180304

Epoch: 5| Step: 7
Training loss: 1.4308478832244873
Validation loss: 2.069837784254423

Epoch: 5| Step: 8
Training loss: 1.6341934204101562
Validation loss: 1.98866307350897

Epoch: 5| Step: 9
Training loss: 2.024191379547119
Validation loss: 2.0756972374454623

Epoch: 5| Step: 10
Training loss: 2.293363571166992
Validation loss: 2.0242667044362714

Epoch: 454| Step: 0
Training loss: 1.3089160919189453
Validation loss: 2.072460775734276

Epoch: 5| Step: 1
Training loss: 1.2994143962860107
Validation loss: 2.01101948881662

Epoch: 5| Step: 2
Training loss: 1.7648305892944336
Validation loss: 2.0314614824069444

Epoch: 5| Step: 3
Training loss: 1.996557593345642
Validation loss: 2.025655961805774

Epoch: 5| Step: 4
Training loss: 1.6644233465194702
Validation loss: 2.021040101205149

Epoch: 5| Step: 5
Training loss: 2.5114760398864746
Validation loss: 2.0527349659191665

Epoch: 5| Step: 6
Training loss: 2.0976345539093018
Validation loss: 1.9889099418476064

Epoch: 5| Step: 7
Training loss: 2.346534252166748
Validation loss: 2.043258866956157

Epoch: 5| Step: 8
Training loss: 1.4459787607192993
Validation loss: 2.041975600745088

Epoch: 5| Step: 9
Training loss: 1.6488945484161377
Validation loss: 2.0388321914980487

Epoch: 5| Step: 10
Training loss: 1.5832470655441284
Validation loss: 2.0699085996996973

Epoch: 455| Step: 0
Training loss: 1.591728687286377
Validation loss: 2.0283537936466995

Epoch: 5| Step: 1
Training loss: 1.5968554019927979
Validation loss: 2.0282201690058552

Epoch: 5| Step: 2
Training loss: 2.343290328979492
Validation loss: 2.07443679019969

Epoch: 5| Step: 3
Training loss: 1.6461656093597412
Validation loss: 2.158035934612315

Epoch: 5| Step: 4
Training loss: 1.6455707550048828
Validation loss: 2.060163833761728

Epoch: 5| Step: 5
Training loss: 2.09118390083313
Validation loss: 2.0135636714196976

Epoch: 5| Step: 6
Training loss: 1.5813210010528564
Validation loss: 2.0082896447950795

Epoch: 5| Step: 7
Training loss: 1.8559097051620483
Validation loss: 2.0214126110076904

Epoch: 5| Step: 8
Training loss: 1.8181835412979126
Validation loss: 2.0266360800753356

Epoch: 5| Step: 9
Training loss: 1.4422755241394043
Validation loss: 2.0294437844266175

Epoch: 5| Step: 10
Training loss: 2.107813596725464
Validation loss: 2.047194839805685

Epoch: 456| Step: 0
Training loss: 1.7658240795135498
Validation loss: 2.0686499213659637

Epoch: 5| Step: 1
Training loss: 2.2459466457366943
Validation loss: 2.0564433092712076

Epoch: 5| Step: 2
Training loss: 2.273852825164795
Validation loss: 2.0639656974423315

Epoch: 5| Step: 3
Training loss: 2.155661106109619
Validation loss: 1.9969649532789826

Epoch: 5| Step: 4
Training loss: 1.7553746700286865
Validation loss: 1.9832358193653885

Epoch: 5| Step: 5
Training loss: 1.6051490306854248
Validation loss: 2.027700290885023

Epoch: 5| Step: 6
Training loss: 2.066100597381592
Validation loss: 2.031684285850935

Epoch: 5| Step: 7
Training loss: 1.3475630283355713
Validation loss: 2.024618851241245

Epoch: 5| Step: 8
Training loss: 1.3167170286178589
Validation loss: 2.0732988439580446

Epoch: 5| Step: 9
Training loss: 1.723685622215271
Validation loss: 2.074421103282641

Epoch: 5| Step: 10
Training loss: 1.6249933242797852
Validation loss: 2.0496711987321095

Epoch: 457| Step: 0
Training loss: 2.0478413105010986
Validation loss: 2.0634947566575903

Epoch: 5| Step: 1
Training loss: 1.6309592723846436
Validation loss: 2.0233674139104862

Epoch: 5| Step: 2
Training loss: 1.080801010131836
Validation loss: 2.0259074934067263

Epoch: 5| Step: 3
Training loss: 1.7363141775131226
Validation loss: 2.006289246261761

Epoch: 5| Step: 4
Training loss: 2.1307690143585205
Validation loss: 2.0423598609944826

Epoch: 5| Step: 5
Training loss: 1.9257551431655884
Validation loss: 2.0180929117305304

Epoch: 5| Step: 6
Training loss: 1.8449004888534546
Validation loss: 2.0707302785688833

Epoch: 5| Step: 7
Training loss: 2.0847320556640625
Validation loss: 2.1193662305032053

Epoch: 5| Step: 8
Training loss: 1.5065966844558716
Validation loss: 2.100215696519421

Epoch: 5| Step: 9
Training loss: 1.6234455108642578
Validation loss: 2.0463970527854016

Epoch: 5| Step: 10
Training loss: 1.6248940229415894
Validation loss: 2.125714317444832

Epoch: 458| Step: 0
Training loss: 1.7749717235565186
Validation loss: 2.0158631237604285

Epoch: 5| Step: 1
Training loss: 1.373814582824707
Validation loss: 1.9912859726977605

Epoch: 5| Step: 2
Training loss: 1.7673397064208984
Validation loss: 2.098346737123305

Epoch: 5| Step: 3
Training loss: 1.3025436401367188
Validation loss: 2.0276402017121673

Epoch: 5| Step: 4
Training loss: 2.4522323608398438
Validation loss: 2.0471237397963002

Epoch: 5| Step: 5
Training loss: 1.5598456859588623
Validation loss: 2.063652333392892

Epoch: 5| Step: 6
Training loss: 2.3429067134857178
Validation loss: 2.008029386561404

Epoch: 5| Step: 7
Training loss: 1.5328853130340576
Validation loss: 2.008023263305746

Epoch: 5| Step: 8
Training loss: 1.9099311828613281
Validation loss: 2.0159544534580682

Epoch: 5| Step: 9
Training loss: 1.6579759120941162
Validation loss: 2.0351168224888463

Epoch: 5| Step: 10
Training loss: 1.502509355545044
Validation loss: 2.065825528995965

Epoch: 459| Step: 0
Training loss: 1.7668567895889282
Validation loss: 1.9963746916863225

Epoch: 5| Step: 1
Training loss: 1.878414511680603
Validation loss: 2.0190420868576213

Epoch: 5| Step: 2
Training loss: 1.9412286281585693
Validation loss: 1.9872052387524677

Epoch: 5| Step: 3
Training loss: 1.590152382850647
Validation loss: 2.039199931647188

Epoch: 5| Step: 4
Training loss: 1.6181665658950806
Validation loss: 2.035699159868302

Epoch: 5| Step: 5
Training loss: 2.241558790206909
Validation loss: 1.9813783848157493

Epoch: 5| Step: 6
Training loss: 0.838232159614563
Validation loss: 1.996826164184078

Epoch: 5| Step: 7
Training loss: 1.4973807334899902
Validation loss: 2.0965368158073834

Epoch: 5| Step: 8
Training loss: 1.7943181991577148
Validation loss: 2.0528383101186445

Epoch: 5| Step: 9
Training loss: 2.536762237548828
Validation loss: 2.0795951940680064

Epoch: 5| Step: 10
Training loss: 1.941224455833435
Validation loss: 2.116045331442228

Epoch: 460| Step: 0
Training loss: 2.246192693710327
Validation loss: 2.0494648487337175

Epoch: 5| Step: 1
Training loss: 2.0167853832244873
Validation loss: 2.05018356538588

Epoch: 5| Step: 2
Training loss: 2.085432767868042
Validation loss: 2.0050640567656486

Epoch: 5| Step: 3
Training loss: 1.4378883838653564
Validation loss: 2.1452830209526965

Epoch: 5| Step: 4
Training loss: 1.6842925548553467
Validation loss: 2.0412274637529926

Epoch: 5| Step: 5
Training loss: 1.4047605991363525
Validation loss: 2.080663995076251

Epoch: 5| Step: 6
Training loss: 2.078009843826294
Validation loss: 2.1240175975266324

Epoch: 5| Step: 7
Training loss: 1.7037004232406616
Validation loss: 2.1089423446245092

Epoch: 5| Step: 8
Training loss: 1.3161706924438477
Validation loss: 2.0631703843352613

Epoch: 5| Step: 9
Training loss: 2.1241259574890137
Validation loss: 2.019871537403394

Epoch: 5| Step: 10
Training loss: 1.8744596242904663
Validation loss: 2.093440824939359

Epoch: 461| Step: 0
Training loss: 1.3343424797058105
Validation loss: 2.115471522013346

Epoch: 5| Step: 1
Training loss: 1.0278993844985962
Validation loss: 2.082630217716258

Epoch: 5| Step: 2
Training loss: 2.5051872730255127
Validation loss: 2.017640584258623

Epoch: 5| Step: 3
Training loss: 1.9072901010513306
Validation loss: 2.061726300947128

Epoch: 5| Step: 4
Training loss: 1.2813085317611694
Validation loss: 2.0032765455143426

Epoch: 5| Step: 5
Training loss: 1.7586476802825928
Validation loss: 1.9726222022887199

Epoch: 5| Step: 6
Training loss: 1.7747726440429688
Validation loss: 2.0543422442610546

Epoch: 5| Step: 7
Training loss: 2.159388303756714
Validation loss: 2.0207237043688373

Epoch: 5| Step: 8
Training loss: 2.019134044647217
Validation loss: 1.995236450626004

Epoch: 5| Step: 9
Training loss: 2.3646111488342285
Validation loss: 1.9706802060527187

Epoch: 5| Step: 10
Training loss: 1.5180995464324951
Validation loss: 2.0922049412163357

Epoch: 462| Step: 0
Training loss: 1.9537662267684937
Validation loss: 2.030103801399149

Epoch: 5| Step: 1
Training loss: 1.5577003955841064
Validation loss: 2.038290795459542

Epoch: 5| Step: 2
Training loss: 2.215880870819092
Validation loss: 2.036082552325341

Epoch: 5| Step: 3
Training loss: 1.3157117366790771
Validation loss: 2.048581228461317

Epoch: 5| Step: 4
Training loss: 1.588571310043335
Validation loss: 1.9972800490676716

Epoch: 5| Step: 5
Training loss: 2.2634634971618652
Validation loss: 2.050282916715068

Epoch: 5| Step: 6
Training loss: 1.3703832626342773
Validation loss: 2.009776202581262

Epoch: 5| Step: 7
Training loss: 2.0282294750213623
Validation loss: 2.040157551406532

Epoch: 5| Step: 8
Training loss: 1.5149171352386475
Validation loss: 1.9568581440115487

Epoch: 5| Step: 9
Training loss: 1.5841377973556519
Validation loss: 2.006480916853874

Epoch: 5| Step: 10
Training loss: 1.7936365604400635
Validation loss: 2.0594301557028167

Epoch: 463| Step: 0
Training loss: 2.130514621734619
Validation loss: 2.0190955208193873

Epoch: 5| Step: 1
Training loss: 2.5972862243652344
Validation loss: 2.107711281827701

Epoch: 5| Step: 2
Training loss: 1.8308496475219727
Validation loss: 2.0226767537414387

Epoch: 5| Step: 3
Training loss: 1.7064943313598633
Validation loss: 2.0201094124906804

Epoch: 5| Step: 4
Training loss: 1.7950761318206787
Validation loss: 2.019343727378435

Epoch: 5| Step: 5
Training loss: 1.6419458389282227
Validation loss: 2.1199794661614204

Epoch: 5| Step: 6
Training loss: 1.4341421127319336
Validation loss: 2.116028977978614

Epoch: 5| Step: 7
Training loss: 0.8961570858955383
Validation loss: 2.1119315470418623

Epoch: 5| Step: 8
Training loss: 1.7565643787384033
Validation loss: 2.0086604510584185

Epoch: 5| Step: 9
Training loss: 1.4948266744613647
Validation loss: 2.057183886087069

Epoch: 5| Step: 10
Training loss: 1.9952877759933472
Validation loss: 2.0340534986988192

Epoch: 464| Step: 0
Training loss: 2.3356778621673584
Validation loss: 2.1094158746862925

Epoch: 5| Step: 1
Training loss: 2.1427199840545654
Validation loss: 2.0546041342519943

Epoch: 5| Step: 2
Training loss: 1.552923560142517
Validation loss: 2.042786472587175

Epoch: 5| Step: 3
Training loss: 1.638220191001892
Validation loss: 2.041944375602148

Epoch: 5| Step: 4
Training loss: 1.3178554773330688
Validation loss: 2.059193636781426

Epoch: 5| Step: 5
Training loss: 1.9618685245513916
Validation loss: 2.072359058164781

Epoch: 5| Step: 6
Training loss: 1.73634934425354
Validation loss: 1.975934959227039

Epoch: 5| Step: 7
Training loss: 1.5023130178451538
Validation loss: 1.9907727215879707

Epoch: 5| Step: 8
Training loss: 1.7507507801055908
Validation loss: 2.094588209224004

Epoch: 5| Step: 9
Training loss: 1.8417224884033203
Validation loss: 2.035186085649716

Epoch: 5| Step: 10
Training loss: 2.1330649852752686
Validation loss: 2.049308584582421

Epoch: 465| Step: 0
Training loss: 2.194765567779541
Validation loss: 2.0219638321989324

Epoch: 5| Step: 1
Training loss: 1.747829794883728
Validation loss: 2.075373520133316

Epoch: 5| Step: 2
Training loss: 1.6093080043792725
Validation loss: 1.9560206551705637

Epoch: 5| Step: 3
Training loss: 1.8492088317871094
Validation loss: 2.0698331030466224

Epoch: 5| Step: 4
Training loss: 1.6243493556976318
Validation loss: 2.0213210839097218

Epoch: 5| Step: 5
Training loss: 1.3883020877838135
Validation loss: 2.016293271895378

Epoch: 5| Step: 6
Training loss: 2.1525368690490723
Validation loss: 2.0221391031819005

Epoch: 5| Step: 7
Training loss: 1.9039065837860107
Validation loss: 2.057827306050126

Epoch: 5| Step: 8
Training loss: 1.7471643686294556
Validation loss: 2.0471898842883367

Epoch: 5| Step: 9
Training loss: 1.5620368719100952
Validation loss: 1.9514751639417423

Epoch: 5| Step: 10
Training loss: 1.9430694580078125
Validation loss: 2.0391589428788874

Epoch: 466| Step: 0
Training loss: 1.3186839818954468
Validation loss: 2.0882268003238145

Epoch: 5| Step: 1
Training loss: 1.5140113830566406
Validation loss: 2.00910343662385

Epoch: 5| Step: 2
Training loss: 2.131295680999756
Validation loss: 1.9855403823237265

Epoch: 5| Step: 3
Training loss: 1.6329113245010376
Validation loss: 1.973372987521592

Epoch: 5| Step: 4
Training loss: 1.3417885303497314
Validation loss: 2.0752784359839653

Epoch: 5| Step: 5
Training loss: 1.7759120464324951
Validation loss: 1.9367879142043412

Epoch: 5| Step: 6
Training loss: 1.8945207595825195
Validation loss: 2.048894702747304

Epoch: 5| Step: 7
Training loss: 1.7172123193740845
Validation loss: 1.9677757640038767

Epoch: 5| Step: 8
Training loss: 1.656286597251892
Validation loss: 2.131524819199757

Epoch: 5| Step: 9
Training loss: 2.2888360023498535
Validation loss: 2.0030997299378916

Epoch: 5| Step: 10
Training loss: 2.14735746383667
Validation loss: 2.006895161444141

Epoch: 467| Step: 0
Training loss: 1.6535682678222656
Validation loss: 1.9722474903188727

Epoch: 5| Step: 1
Training loss: 1.6359981298446655
Validation loss: 1.9592605560056624

Epoch: 5| Step: 2
Training loss: 2.1067938804626465
Validation loss: 1.9766952376211844

Epoch: 5| Step: 3
Training loss: 1.4305174350738525
Validation loss: 2.0302110000323226

Epoch: 5| Step: 4
Training loss: 1.7624289989471436
Validation loss: 2.1150664514110935

Epoch: 5| Step: 5
Training loss: 1.7154852151870728
Validation loss: 2.0363767890519995

Epoch: 5| Step: 6
Training loss: 2.2451138496398926
Validation loss: 2.0585552876995457

Epoch: 5| Step: 7
Training loss: 1.7481693029403687
Validation loss: 2.1039985431137906

Epoch: 5| Step: 8
Training loss: 1.6354976892471313
Validation loss: 2.005543762637723

Epoch: 5| Step: 9
Training loss: 1.5628905296325684
Validation loss: 2.020631327423998

Epoch: 5| Step: 10
Training loss: 2.001298427581787
Validation loss: 2.004475524348597

Epoch: 468| Step: 0
Training loss: 1.7352755069732666
Validation loss: 2.04111921915444

Epoch: 5| Step: 1
Training loss: 1.9338233470916748
Validation loss: 2.0151818260069816

Epoch: 5| Step: 2
Training loss: 1.6679003238677979
Validation loss: 2.0648152200124597

Epoch: 5| Step: 3
Training loss: 2.0596957206726074
Validation loss: 2.0263760717966224

Epoch: 5| Step: 4
Training loss: 1.7944408655166626
Validation loss: 2.035948266265213

Epoch: 5| Step: 5
Training loss: 1.1170574426651
Validation loss: 2.103149949863393

Epoch: 5| Step: 6
Training loss: 2.1252684593200684
Validation loss: 2.0618813627509662

Epoch: 5| Step: 7
Training loss: 1.6987826824188232
Validation loss: 1.989930696384881

Epoch: 5| Step: 8
Training loss: 1.60480535030365
Validation loss: 2.0849910500229045

Epoch: 5| Step: 9
Training loss: 1.8233959674835205
Validation loss: 2.063917266425266

Epoch: 5| Step: 10
Training loss: 1.3899363279342651
Validation loss: 2.041463105909286

Epoch: 469| Step: 0
Training loss: 1.4032223224639893
Validation loss: 2.012729337138514

Epoch: 5| Step: 1
Training loss: 1.552947998046875
Validation loss: 2.061808100310705

Epoch: 5| Step: 2
Training loss: 1.4899669885635376
Validation loss: 2.0448904434839883

Epoch: 5| Step: 3
Training loss: 1.4826282262802124
Validation loss: 2.0506835240189747

Epoch: 5| Step: 4
Training loss: 1.511643648147583
Validation loss: 2.048084041123749

Epoch: 5| Step: 5
Training loss: 1.6784721612930298
Validation loss: 2.1271738339495916

Epoch: 5| Step: 6
Training loss: 1.6861823797225952
Validation loss: 2.054620344151733

Epoch: 5| Step: 7
Training loss: 1.9615230560302734
Validation loss: 2.045637825483917

Epoch: 5| Step: 8
Training loss: 1.6763916015625
Validation loss: 2.010473806370971

Epoch: 5| Step: 9
Training loss: 2.51043438911438
Validation loss: 1.9920429850137362

Epoch: 5| Step: 10
Training loss: 2.1679234504699707
Validation loss: 2.0679758799973356

Epoch: 470| Step: 0
Training loss: 1.6105550527572632
Validation loss: 2.0648616795898764

Epoch: 5| Step: 1
Training loss: 1.8309389352798462
Validation loss: 1.9690355382939821

Epoch: 5| Step: 2
Training loss: 1.911275863647461
Validation loss: 1.9594187223783104

Epoch: 5| Step: 3
Training loss: 1.432774543762207
Validation loss: 2.0597511978559595

Epoch: 5| Step: 4
Training loss: 2.1219170093536377
Validation loss: 2.0103780966933056

Epoch: 5| Step: 5
Training loss: 1.111143708229065
Validation loss: 2.046371317678882

Epoch: 5| Step: 6
Training loss: 1.5861530303955078
Validation loss: 2.002900710669897

Epoch: 5| Step: 7
Training loss: 1.8417294025421143
Validation loss: 2.074570354594979

Epoch: 5| Step: 8
Training loss: 1.6704177856445312
Validation loss: 2.0440656549187115

Epoch: 5| Step: 9
Training loss: 1.889256238937378
Validation loss: 2.113836076951796

Epoch: 5| Step: 10
Training loss: 1.776661992073059
Validation loss: 2.0134474615896902

Epoch: 471| Step: 0
Training loss: 1.8843612670898438
Validation loss: 2.011180614912382

Epoch: 5| Step: 1
Training loss: 1.8364002704620361
Validation loss: 1.998123316354649

Epoch: 5| Step: 2
Training loss: 1.9922596216201782
Validation loss: 1.9581378634257982

Epoch: 5| Step: 3
Training loss: 1.595371961593628
Validation loss: 2.0752003295447237

Epoch: 5| Step: 4
Training loss: 1.948188066482544
Validation loss: 1.9675869249528455

Epoch: 5| Step: 5
Training loss: 0.9938915967941284
Validation loss: 2.0131102121004494

Epoch: 5| Step: 6
Training loss: 2.374594211578369
Validation loss: 2.0645063692523586

Epoch: 5| Step: 7
Training loss: 1.3029731512069702
Validation loss: 1.9917638583849835

Epoch: 5| Step: 8
Training loss: 1.6078071594238281
Validation loss: 2.0358042973344044

Epoch: 5| Step: 9
Training loss: 2.047088623046875
Validation loss: 2.0090843785193657

Epoch: 5| Step: 10
Training loss: 1.593307375907898
Validation loss: 2.0176065109109365

Epoch: 472| Step: 0
Training loss: 1.9477399587631226
Validation loss: 2.0122482071640673

Epoch: 5| Step: 1
Training loss: 1.8610584735870361
Validation loss: 2.046119474595593

Epoch: 5| Step: 2
Training loss: 2.2380385398864746
Validation loss: 2.0725926583813084

Epoch: 5| Step: 3
Training loss: 1.4931671619415283
Validation loss: 2.02670491767186

Epoch: 5| Step: 4
Training loss: 2.092963695526123
Validation loss: 2.011376844939365

Epoch: 5| Step: 5
Training loss: 1.611412763595581
Validation loss: 2.011674015752731

Epoch: 5| Step: 6
Training loss: 1.40066659450531
Validation loss: 1.997392596737031

Epoch: 5| Step: 7
Training loss: 1.9167381525039673
Validation loss: 2.048976021428262

Epoch: 5| Step: 8
Training loss: 1.877235770225525
Validation loss: 2.009803807863625

Epoch: 5| Step: 9
Training loss: 1.6225147247314453
Validation loss: 1.999295033434386

Epoch: 5| Step: 10
Training loss: 1.4368256330490112
Validation loss: 2.0709924723512385

Epoch: 473| Step: 0
Training loss: 1.5906574726104736
Validation loss: 1.964914842318463

Epoch: 5| Step: 1
Training loss: 1.379328966140747
Validation loss: 2.0537052872360393

Epoch: 5| Step: 2
Training loss: 1.969940423965454
Validation loss: 2.127950750371461

Epoch: 5| Step: 3
Training loss: 2.0820555686950684
Validation loss: 2.0995620373756654

Epoch: 5| Step: 4
Training loss: 1.8562915325164795
Validation loss: 2.077715560954104

Epoch: 5| Step: 5
Training loss: 1.8657833337783813
Validation loss: 2.104048284151221

Epoch: 5| Step: 6
Training loss: 1.304110050201416
Validation loss: 2.0671759805371686

Epoch: 5| Step: 7
Training loss: 1.6828901767730713
Validation loss: 2.0133582815047233

Epoch: 5| Step: 8
Training loss: 2.3016397953033447
Validation loss: 1.9849943204592633

Epoch: 5| Step: 9
Training loss: 1.7039499282836914
Validation loss: 2.050203784819572

Epoch: 5| Step: 10
Training loss: 1.6140592098236084
Validation loss: 2.0263413280569096

Epoch: 474| Step: 0
Training loss: 2.245262622833252
Validation loss: 2.0000349129399946

Epoch: 5| Step: 1
Training loss: 1.7491891384124756
Validation loss: 2.0470644940612135

Epoch: 5| Step: 2
Training loss: 2.3925254344940186
Validation loss: 2.0604214027363765

Epoch: 5| Step: 3
Training loss: 1.7623945474624634
Validation loss: 2.006839544542374

Epoch: 5| Step: 4
Training loss: 1.9161441326141357
Validation loss: 2.0475262339397142

Epoch: 5| Step: 5
Training loss: 1.7701513767242432
Validation loss: 2.0120239975631877

Epoch: 5| Step: 6
Training loss: 1.5939629077911377
Validation loss: 2.05949640914958

Epoch: 5| Step: 7
Training loss: 1.6684154272079468
Validation loss: 2.0101649171562603

Epoch: 5| Step: 8
Training loss: 1.9400503635406494
Validation loss: 2.041006762494323

Epoch: 5| Step: 9
Training loss: 1.3282115459442139
Validation loss: 1.9952602937657347

Epoch: 5| Step: 10
Training loss: 0.741551399230957
Validation loss: 2.0062288853429977

Epoch: 475| Step: 0
Training loss: 2.451038360595703
Validation loss: 1.9981839503011396

Epoch: 5| Step: 1
Training loss: 1.5864413976669312
Validation loss: 2.0103998645659416

Epoch: 5| Step: 2
Training loss: 1.1351182460784912
Validation loss: 2.0429530759011545

Epoch: 5| Step: 3
Training loss: 1.7599576711654663
Validation loss: 2.059144484099521

Epoch: 5| Step: 4
Training loss: 1.9139487743377686
Validation loss: 2.067527276213451

Epoch: 5| Step: 5
Training loss: 1.580683946609497
Validation loss: 1.9412604326842933

Epoch: 5| Step: 6
Training loss: 1.5824480056762695
Validation loss: 2.0191735657312537

Epoch: 5| Step: 7
Training loss: 2.0909831523895264
Validation loss: 2.033808260835627

Epoch: 5| Step: 8
Training loss: 1.938924789428711
Validation loss: 2.0677677482687016

Epoch: 5| Step: 9
Training loss: 1.5298035144805908
Validation loss: 2.00352737211412

Epoch: 5| Step: 10
Training loss: 2.121764659881592
Validation loss: 1.986975246860135

Epoch: 476| Step: 0
Training loss: 2.120145320892334
Validation loss: 2.028464071212276

Epoch: 5| Step: 1
Training loss: 1.5658320188522339
Validation loss: 1.9884543418884277

Epoch: 5| Step: 2
Training loss: 1.972510576248169
Validation loss: 2.017926659635318

Epoch: 5| Step: 3
Training loss: 1.7519347667694092
Validation loss: 2.0006044731345227

Epoch: 5| Step: 4
Training loss: 2.3117010593414307
Validation loss: 2.048451973545936

Epoch: 5| Step: 5
Training loss: 1.493241548538208
Validation loss: 2.0375836164720598

Epoch: 5| Step: 6
Training loss: 1.4841904640197754
Validation loss: 2.0258165251824165

Epoch: 5| Step: 7
Training loss: 1.3965562582015991
Validation loss: 2.065058159571822

Epoch: 5| Step: 8
Training loss: 1.616763710975647
Validation loss: 2.0221896940662014

Epoch: 5| Step: 9
Training loss: 1.8978087902069092
Validation loss: 2.035843241599298

Epoch: 5| Step: 10
Training loss: 1.4917879104614258
Validation loss: 2.070435831623693

Epoch: 477| Step: 0
Training loss: 1.9026635885238647
Validation loss: 2.0667814336797243

Epoch: 5| Step: 1
Training loss: 2.495069980621338
Validation loss: 1.9925017049235683

Epoch: 5| Step: 2
Training loss: 2.3768973350524902
Validation loss: 2.0534691272243375

Epoch: 5| Step: 3
Training loss: 1.2824969291687012
Validation loss: 2.013070342361286

Epoch: 5| Step: 4
Training loss: 1.5501906871795654
Validation loss: 2.004222350735818

Epoch: 5| Step: 5
Training loss: 1.652808427810669
Validation loss: 1.9869957918761878

Epoch: 5| Step: 6
Training loss: 1.2626020908355713
Validation loss: 2.0506526257402156

Epoch: 5| Step: 7
Training loss: 1.9198548793792725
Validation loss: 1.9973693457982873

Epoch: 5| Step: 8
Training loss: 1.8161941766738892
Validation loss: 2.076227007373687

Epoch: 5| Step: 9
Training loss: 1.6697620153427124
Validation loss: 2.0383318393461165

Epoch: 5| Step: 10
Training loss: 1.243112325668335
Validation loss: 2.023781177818134

Epoch: 478| Step: 0
Training loss: 1.7564036846160889
Validation loss: 2.0265183897428614

Epoch: 5| Step: 1
Training loss: 1.9270187616348267
Validation loss: 2.0252761392183203

Epoch: 5| Step: 2
Training loss: 1.765894889831543
Validation loss: 2.0866461338535434

Epoch: 5| Step: 3
Training loss: 1.4453067779541016
Validation loss: 1.9610845837541806

Epoch: 5| Step: 4
Training loss: 1.1811249256134033
Validation loss: 1.9730127844759213

Epoch: 5| Step: 5
Training loss: 1.7093384265899658
Validation loss: 2.025477393980949

Epoch: 5| Step: 6
Training loss: 2.3574633598327637
Validation loss: 2.0145558067547378

Epoch: 5| Step: 7
Training loss: 1.497582197189331
Validation loss: 2.0821591064494145

Epoch: 5| Step: 8
Training loss: 2.1516671180725098
Validation loss: 2.047743123064759

Epoch: 5| Step: 9
Training loss: 1.5253913402557373
Validation loss: 2.0771849886063607

Epoch: 5| Step: 10
Training loss: 1.916236400604248
Validation loss: 2.123275331271592

Epoch: 479| Step: 0
Training loss: 1.67373526096344
Validation loss: 2.0635744910086355

Epoch: 5| Step: 1
Training loss: 1.447359323501587
Validation loss: 2.0329511998802103

Epoch: 5| Step: 2
Training loss: 2.6355056762695312
Validation loss: 2.017871997689688

Epoch: 5| Step: 3
Training loss: 2.0681207180023193
Validation loss: 1.990430840881922

Epoch: 5| Step: 4
Training loss: 1.6684067249298096
Validation loss: 2.0550320251013643

Epoch: 5| Step: 5
Training loss: 1.6265796422958374
Validation loss: 2.073015982104886

Epoch: 5| Step: 6
Training loss: 1.3702170848846436
Validation loss: 1.9980796511455248

Epoch: 5| Step: 7
Training loss: 1.978957176208496
Validation loss: 2.017844728244248

Epoch: 5| Step: 8
Training loss: 1.5966838598251343
Validation loss: 2.0533830042808288

Epoch: 5| Step: 9
Training loss: 1.3231878280639648
Validation loss: 2.059197811670201

Epoch: 5| Step: 10
Training loss: 1.4342001676559448
Validation loss: 2.0832464618067585

Epoch: 480| Step: 0
Training loss: 2.0350303649902344
Validation loss: 2.0864295190380466

Epoch: 5| Step: 1
Training loss: 2.450249433517456
Validation loss: 2.060602677765713

Epoch: 5| Step: 2
Training loss: 1.2499067783355713
Validation loss: 1.948753910679971

Epoch: 5| Step: 3
Training loss: 1.897844672203064
Validation loss: 1.9606499518117597

Epoch: 5| Step: 4
Training loss: 1.9957249164581299
Validation loss: 2.0346404865223873

Epoch: 5| Step: 5
Training loss: 1.8441107273101807
Validation loss: 2.0587770067235476

Epoch: 5| Step: 6
Training loss: 2.055516004562378
Validation loss: 2.033291885929723

Epoch: 5| Step: 7
Training loss: 1.595693826675415
Validation loss: 1.9986249759633055

Epoch: 5| Step: 8
Training loss: 1.2820348739624023
Validation loss: 1.9889406939988494

Epoch: 5| Step: 9
Training loss: 1.485821008682251
Validation loss: 1.9452248042629612

Epoch: 5| Step: 10
Training loss: 1.2902776002883911
Validation loss: 2.0178497760526595

Epoch: 481| Step: 0
Training loss: 1.3754709959030151
Validation loss: 2.039175837270675

Epoch: 5| Step: 1
Training loss: 1.931410551071167
Validation loss: 2.01825290085167

Epoch: 5| Step: 2
Training loss: 2.048962116241455
Validation loss: 2.0544073940605245

Epoch: 5| Step: 3
Training loss: 1.844622254371643
Validation loss: 2.0960487768214238

Epoch: 5| Step: 4
Training loss: 1.7225310802459717
Validation loss: 2.038737694422404

Epoch: 5| Step: 5
Training loss: 1.9516175985336304
Validation loss: 2.028361922951155

Epoch: 5| Step: 6
Training loss: 1.846644401550293
Validation loss: 2.0277324927750455

Epoch: 5| Step: 7
Training loss: 1.7446352243423462
Validation loss: 2.014560318762256

Epoch: 5| Step: 8
Training loss: 1.1765996217727661
Validation loss: 2.0246130676679712

Epoch: 5| Step: 9
Training loss: 1.3171474933624268
Validation loss: 2.020636543150871

Epoch: 5| Step: 10
Training loss: 1.8696516752243042
Validation loss: 2.06911204707238

Epoch: 482| Step: 0
Training loss: 2.4342753887176514
Validation loss: 2.0003390799286547

Epoch: 5| Step: 1
Training loss: 1.130286455154419
Validation loss: 2.006718288185776

Epoch: 5| Step: 2
Training loss: 1.9573628902435303
Validation loss: 2.0754871163316952

Epoch: 5| Step: 3
Training loss: 1.793687105178833
Validation loss: 2.025748009322792

Epoch: 5| Step: 4
Training loss: 1.9504343271255493
Validation loss: 2.03703393731066

Epoch: 5| Step: 5
Training loss: 2.0117385387420654
Validation loss: 1.9981770669260333

Epoch: 5| Step: 6
Training loss: 1.7312917709350586
Validation loss: 2.068586964761057

Epoch: 5| Step: 7
Training loss: 1.8280912637710571
Validation loss: 2.011399115285566

Epoch: 5| Step: 8
Training loss: 1.7382001876831055
Validation loss: 2.0379962792960544

Epoch: 5| Step: 9
Training loss: 1.3195427656173706
Validation loss: 2.0225418101074877

Epoch: 5| Step: 10
Training loss: 1.3506486415863037
Validation loss: 2.016193491156383

Epoch: 483| Step: 0
Training loss: 1.1027275323867798
Validation loss: 2.0303984662537933

Epoch: 5| Step: 1
Training loss: 1.6345481872558594
Validation loss: 2.0448045576772382

Epoch: 5| Step: 2
Training loss: 1.8909286260604858
Validation loss: 2.0203576985225884

Epoch: 5| Step: 3
Training loss: 1.2527281045913696
Validation loss: 2.0628864765167236

Epoch: 5| Step: 4
Training loss: 2.108860731124878
Validation loss: 1.9719830777055474

Epoch: 5| Step: 5
Training loss: 1.5605237483978271
Validation loss: 2.101109766191052

Epoch: 5| Step: 6
Training loss: 1.7237193584442139
Validation loss: 2.0206684617586035

Epoch: 5| Step: 7
Training loss: 2.2859370708465576
Validation loss: 2.0299256155567784

Epoch: 5| Step: 8
Training loss: 1.6612985134124756
Validation loss: 2.033394043163587

Epoch: 5| Step: 9
Training loss: 1.330767273902893
Validation loss: 2.074251728673135

Epoch: 5| Step: 10
Training loss: 2.2621524333953857
Validation loss: 2.046440598785236

Epoch: 484| Step: 0
Training loss: 1.998946189880371
Validation loss: 2.015132070869528

Epoch: 5| Step: 1
Training loss: 1.9886691570281982
Validation loss: 2.035987807858375

Epoch: 5| Step: 2
Training loss: 1.3525339365005493
Validation loss: 2.0149023020139305

Epoch: 5| Step: 3
Training loss: 2.2451000213623047
Validation loss: 1.9912932162643762

Epoch: 5| Step: 4
Training loss: 1.9076464176177979
Validation loss: 2.0558658671635452

Epoch: 5| Step: 5
Training loss: 1.5152928829193115
Validation loss: 2.0443751145434637

Epoch: 5| Step: 6
Training loss: 1.7689688205718994
Validation loss: 2.105544620944608

Epoch: 5| Step: 7
Training loss: 1.727219581604004
Validation loss: 1.9721779259302283

Epoch: 5| Step: 8
Training loss: 1.6230922937393188
Validation loss: 2.013928165999792

Epoch: 5| Step: 9
Training loss: 1.3829013109207153
Validation loss: 2.0365527624725015

Epoch: 5| Step: 10
Training loss: 1.559406042098999
Validation loss: 2.053232567284697

Epoch: 485| Step: 0
Training loss: 1.834054946899414
Validation loss: 2.0361822689733198

Epoch: 5| Step: 1
Training loss: 1.6162458658218384
Validation loss: 2.029416195807918

Epoch: 5| Step: 2
Training loss: 1.4631541967391968
Validation loss: 2.0714272196574877

Epoch: 5| Step: 3
Training loss: 1.6457204818725586
Validation loss: 1.990214822112873

Epoch: 5| Step: 4
Training loss: 1.6965789794921875
Validation loss: 2.0607334798382175

Epoch: 5| Step: 5
Training loss: 1.6907262802124023
Validation loss: 1.985172522965298

Epoch: 5| Step: 6
Training loss: 2.026062488555908
Validation loss: 1.9878478255323184

Epoch: 5| Step: 7
Training loss: 1.6923675537109375
Validation loss: 2.060768267159821

Epoch: 5| Step: 8
Training loss: 1.792431116104126
Validation loss: 1.9932155070766326

Epoch: 5| Step: 9
Training loss: 1.6642204523086548
Validation loss: 2.0512767171347015

Epoch: 5| Step: 10
Training loss: 2.1335179805755615
Validation loss: 2.0136745796408704

Epoch: 486| Step: 0
Training loss: 2.1402134895324707
Validation loss: 2.0506889922644502

Epoch: 5| Step: 1
Training loss: 1.5870716571807861
Validation loss: 2.0090104533780004

Epoch: 5| Step: 2
Training loss: 2.3969526290893555
Validation loss: 1.9661308385992562

Epoch: 5| Step: 3
Training loss: 2.0495166778564453
Validation loss: 2.053477984602733

Epoch: 5| Step: 4
Training loss: 1.6209930181503296
Validation loss: 1.9795334569869503

Epoch: 5| Step: 5
Training loss: 1.0667060613632202
Validation loss: 2.018089213678914

Epoch: 5| Step: 6
Training loss: 1.7422676086425781
Validation loss: 2.022597602618638

Epoch: 5| Step: 7
Training loss: 1.570063591003418
Validation loss: 2.033734868931514

Epoch: 5| Step: 8
Training loss: 1.6721343994140625
Validation loss: 2.0325941424215994

Epoch: 5| Step: 9
Training loss: 1.5111805200576782
Validation loss: 2.023190839316255

Epoch: 5| Step: 10
Training loss: 1.3470104932785034
Validation loss: 2.0480798841804586

Epoch: 487| Step: 0
Training loss: 1.7394688129425049
Validation loss: 2.0711051981936217

Epoch: 5| Step: 1
Training loss: 1.5853906869888306
Validation loss: 2.0500884530364827

Epoch: 5| Step: 2
Training loss: 2.330657958984375
Validation loss: 2.0503203433047057

Epoch: 5| Step: 3
Training loss: 1.7099626064300537
Validation loss: 2.0572954185547365

Epoch: 5| Step: 4
Training loss: 1.5429258346557617
Validation loss: 1.9726032774935487

Epoch: 5| Step: 5
Training loss: 1.6342582702636719
Validation loss: 2.0319090632982153

Epoch: 5| Step: 6
Training loss: 2.141573667526245
Validation loss: 1.9975849428484518

Epoch: 5| Step: 7
Training loss: 1.8340826034545898
Validation loss: 2.072835055730676

Epoch: 5| Step: 8
Training loss: 1.1687684059143066
Validation loss: 2.007762142406997

Epoch: 5| Step: 9
Training loss: 1.5306692123413086
Validation loss: 2.0708081491531862

Epoch: 5| Step: 10
Training loss: 1.8063820600509644
Validation loss: 2.0270716246738227

Epoch: 488| Step: 0
Training loss: 2.155529499053955
Validation loss: 1.9728715086496005

Epoch: 5| Step: 1
Training loss: 1.8417131900787354
Validation loss: 2.032330988555826

Epoch: 5| Step: 2
Training loss: 2.0792734622955322
Validation loss: 2.016898016775808

Epoch: 5| Step: 3
Training loss: 1.4970980882644653
Validation loss: 2.0062444953508276

Epoch: 5| Step: 4
Training loss: 1.56719172000885
Validation loss: 2.0354988703163723

Epoch: 5| Step: 5
Training loss: 2.0646114349365234
Validation loss: 2.007292345005979

Epoch: 5| Step: 6
Training loss: 1.180253267288208
Validation loss: 2.0443154945168445

Epoch: 5| Step: 7
Training loss: 1.5320394039154053
Validation loss: 1.9897223954559655

Epoch: 5| Step: 8
Training loss: 1.642237901687622
Validation loss: 1.9987883516537246

Epoch: 5| Step: 9
Training loss: 1.502777338027954
Validation loss: 2.0008813411958757

Epoch: 5| Step: 10
Training loss: 1.338772177696228
Validation loss: 2.02718860103238

Epoch: 489| Step: 0
Training loss: 1.8649089336395264
Validation loss: 2.003697495306692

Epoch: 5| Step: 1
Training loss: 1.6984939575195312
Validation loss: 2.0310760287828344

Epoch: 5| Step: 2
Training loss: 1.9907169342041016
Validation loss: 1.9920945500814786

Epoch: 5| Step: 3
Training loss: 2.0475592613220215
Validation loss: 1.9567069956051406

Epoch: 5| Step: 4
Training loss: 2.2408127784729004
Validation loss: 2.0247641481379026

Epoch: 5| Step: 5
Training loss: 1.2766082286834717
Validation loss: 2.0533360794026363

Epoch: 5| Step: 6
Training loss: 1.27810537815094
Validation loss: 1.9770799426622288

Epoch: 5| Step: 7
Training loss: 2.1946253776550293
Validation loss: 1.9764484103007982

Epoch: 5| Step: 8
Training loss: 1.3798600435256958
Validation loss: 2.0207490818474882

Epoch: 5| Step: 9
Training loss: 1.7580868005752563
Validation loss: 2.0470685035951677

Epoch: 5| Step: 10
Training loss: 1.3145748376846313
Validation loss: 2.0351602262066257

Epoch: 490| Step: 0
Training loss: 1.3422423601150513
Validation loss: 2.046923336162362

Epoch: 5| Step: 1
Training loss: 2.2405476570129395
Validation loss: 2.088383118311564

Epoch: 5| Step: 2
Training loss: 1.6055707931518555
Validation loss: 1.9940298039426085

Epoch: 5| Step: 3
Training loss: 1.7450319528579712
Validation loss: 1.9437106565762592

Epoch: 5| Step: 4
Training loss: 1.8220653533935547
Validation loss: 2.025223147484564

Epoch: 5| Step: 5
Training loss: 1.4409828186035156
Validation loss: 2.0484767985600296

Epoch: 5| Step: 6
Training loss: 1.8082802295684814
Validation loss: 2.057638145262195

Epoch: 5| Step: 7
Training loss: 1.1710268259048462
Validation loss: 2.032252618061599

Epoch: 5| Step: 8
Training loss: 1.8536933660507202
Validation loss: 2.0264505891389746

Epoch: 5| Step: 9
Training loss: 1.6211140155792236
Validation loss: 2.016978112600183

Epoch: 5| Step: 10
Training loss: 1.8646236658096313
Validation loss: 2.0197815446443457

Epoch: 491| Step: 0
Training loss: 1.3536341190338135
Validation loss: 2.113728480954324

Epoch: 5| Step: 1
Training loss: 1.4993994235992432
Validation loss: 1.955424210076691

Epoch: 5| Step: 2
Training loss: 1.8173103332519531
Validation loss: 1.9334082757273028

Epoch: 5| Step: 3
Training loss: 1.4515409469604492
Validation loss: 1.9612274413467736

Epoch: 5| Step: 4
Training loss: 2.0349202156066895
Validation loss: 2.024905648282779

Epoch: 5| Step: 5
Training loss: 1.3047685623168945
Validation loss: 2.0526357850720807

Epoch: 5| Step: 6
Training loss: 2.0482258796691895
Validation loss: 2.0473049148436515

Epoch: 5| Step: 7
Training loss: 2.406322717666626
Validation loss: 2.001480471703314

Epoch: 5| Step: 8
Training loss: 1.5167267322540283
Validation loss: 2.029223603586997

Epoch: 5| Step: 9
Training loss: 1.3335278034210205
Validation loss: 2.0190440762427544

Epoch: 5| Step: 10
Training loss: 1.7453992366790771
Validation loss: 2.014757207644883

Epoch: 492| Step: 0
Training loss: 1.9433037042617798
Validation loss: 2.0074415155636367

Epoch: 5| Step: 1
Training loss: 1.8169177770614624
Validation loss: 2.0308286131069226

Epoch: 5| Step: 2
Training loss: 2.2746357917785645
Validation loss: 2.0086244665166384

Epoch: 5| Step: 3
Training loss: 1.7788217067718506
Validation loss: 1.9813764479852491

Epoch: 5| Step: 4
Training loss: 1.7447582483291626
Validation loss: 2.055472579053653

Epoch: 5| Step: 5
Training loss: 1.3686631917953491
Validation loss: 2.0410956323787732

Epoch: 5| Step: 6
Training loss: 1.585882544517517
Validation loss: 2.04425234435707

Epoch: 5| Step: 7
Training loss: 1.4473416805267334
Validation loss: 2.0689927480554067

Epoch: 5| Step: 8
Training loss: 1.419329285621643
Validation loss: 2.01629816075807

Epoch: 5| Step: 9
Training loss: 1.076291799545288
Validation loss: 2.0866863061023015

Epoch: 5| Step: 10
Training loss: 2.1129953861236572
Validation loss: 2.072717812753493

Epoch: 493| Step: 0
Training loss: 1.5982208251953125
Validation loss: 2.0067821292467016

Epoch: 5| Step: 1
Training loss: 2.099632740020752
Validation loss: 2.0002361074570687

Epoch: 5| Step: 2
Training loss: 1.4612354040145874
Validation loss: 1.9812186789768997

Epoch: 5| Step: 3
Training loss: 1.7148278951644897
Validation loss: 2.1237380261062295

Epoch: 5| Step: 4
Training loss: 1.1663504838943481
Validation loss: 1.9796845413023425

Epoch: 5| Step: 5
Training loss: 1.6217855215072632
Validation loss: 2.0142029844304568

Epoch: 5| Step: 6
Training loss: 1.5449901819229126
Validation loss: 2.0489693764717347

Epoch: 5| Step: 7
Training loss: 2.288242816925049
Validation loss: 2.074244640206778

Epoch: 5| Step: 8
Training loss: 1.5932652950286865
Validation loss: 2.0522064162838842

Epoch: 5| Step: 9
Training loss: 2.310539960861206
Validation loss: 2.1304023227384015

Epoch: 5| Step: 10
Training loss: 1.3076542615890503
Validation loss: 2.0655579592591975

Epoch: 494| Step: 0
Training loss: 1.4254063367843628
Validation loss: 2.1021190792001705

Epoch: 5| Step: 1
Training loss: 2.0037217140197754
Validation loss: 2.0291860436880462

Epoch: 5| Step: 2
Training loss: 1.6412098407745361
Validation loss: 2.065581767789779

Epoch: 5| Step: 3
Training loss: 1.1395471096038818
Validation loss: 1.9563003227274904

Epoch: 5| Step: 4
Training loss: 1.9076509475708008
Validation loss: 2.0478505293528237

Epoch: 5| Step: 5
Training loss: 1.785387396812439
Validation loss: 1.9691333014477965

Epoch: 5| Step: 6
Training loss: 1.7594764232635498
Validation loss: 2.0193910765391525

Epoch: 5| Step: 7
Training loss: 2.0823521614074707
Validation loss: 2.0469275161784184

Epoch: 5| Step: 8
Training loss: 1.2949038743972778
Validation loss: 2.068154614458802

Epoch: 5| Step: 9
Training loss: 1.8817142248153687
Validation loss: 2.055597013042819

Epoch: 5| Step: 10
Training loss: 1.9692413806915283
Validation loss: 2.0769024830992504

Epoch: 495| Step: 0
Training loss: 1.7186168432235718
Validation loss: 2.0110181198325208

Epoch: 5| Step: 1
Training loss: 1.4877437353134155
Validation loss: 1.9422515899904313

Epoch: 5| Step: 2
Training loss: 1.6282087564468384
Validation loss: 2.09811060402983

Epoch: 5| Step: 3
Training loss: 1.9057197570800781
Validation loss: 2.0423510407888763

Epoch: 5| Step: 4
Training loss: 1.494512915611267
Validation loss: 1.9756318035946097

Epoch: 5| Step: 5
Training loss: 1.3183406591415405
Validation loss: 1.9948267782888105

Epoch: 5| Step: 6
Training loss: 2.01963472366333
Validation loss: 2.049206021011517

Epoch: 5| Step: 7
Training loss: 1.65119206905365
Validation loss: 2.0563116996519026

Epoch: 5| Step: 8
Training loss: 1.8516418933868408
Validation loss: 2.0534032339690835

Epoch: 5| Step: 9
Training loss: 1.9052789211273193
Validation loss: 2.0688332255168627

Epoch: 5| Step: 10
Training loss: 1.363690972328186
Validation loss: 2.1352399741449664

Epoch: 496| Step: 0
Training loss: 1.6317484378814697
Validation loss: 2.0017904902017243

Epoch: 5| Step: 1
Training loss: 1.6084556579589844
Validation loss: 2.123007637198253

Epoch: 5| Step: 2
Training loss: 1.9632787704467773
Validation loss: 2.0757476693840435

Epoch: 5| Step: 3
Training loss: 1.6144516468048096
Validation loss: 2.0801826561650922

Epoch: 5| Step: 4
Training loss: 2.0539474487304688
Validation loss: 2.0474019127507366

Epoch: 5| Step: 5
Training loss: 1.0391210317611694
Validation loss: 1.9870861076539563

Epoch: 5| Step: 6
Training loss: 1.3435848951339722
Validation loss: 2.0374128190420007

Epoch: 5| Step: 7
Training loss: 1.5735313892364502
Validation loss: 2.0147171097417034

Epoch: 5| Step: 8
Training loss: 1.5630806684494019
Validation loss: 2.0670482830334733

Epoch: 5| Step: 9
Training loss: 1.6822834014892578
Validation loss: 2.1261220721788305

Epoch: 5| Step: 10
Training loss: 2.0431346893310547
Validation loss: 2.0478893992721394

Epoch: 497| Step: 0
Training loss: 1.1127557754516602
Validation loss: 2.058127225086253

Epoch: 5| Step: 1
Training loss: 1.6537721157073975
Validation loss: 2.0156578428001812

Epoch: 5| Step: 2
Training loss: 1.809553861618042
Validation loss: 2.021135614764306

Epoch: 5| Step: 3
Training loss: 1.0967838764190674
Validation loss: 2.045690971036111

Epoch: 5| Step: 4
Training loss: 2.1395161151885986
Validation loss: 2.0688334459899576

Epoch: 5| Step: 5
Training loss: 2.332280397415161
Validation loss: 2.0304755985095935

Epoch: 5| Step: 6
Training loss: 1.4464666843414307
Validation loss: 2.076327969951014

Epoch: 5| Step: 7
Training loss: 1.713751196861267
Validation loss: 2.0664318146244174

Epoch: 5| Step: 8
Training loss: 1.8498378992080688
Validation loss: 2.0108782732358543

Epoch: 5| Step: 9
Training loss: 1.7280542850494385
Validation loss: 2.0063723492366012

Epoch: 5| Step: 10
Training loss: 1.4177625179290771
Validation loss: 2.075511722154515

Epoch: 498| Step: 0
Training loss: 1.7296758890151978
Validation loss: 2.009571603549424

Epoch: 5| Step: 1
Training loss: 1.694000244140625
Validation loss: 2.1130150005381596

Epoch: 5| Step: 2
Training loss: 1.3640187978744507
Validation loss: 2.0780455271402993

Epoch: 5| Step: 3
Training loss: 1.6450601816177368
Validation loss: 2.036120363461074

Epoch: 5| Step: 4
Training loss: 1.7274261713027954
Validation loss: 2.054908962659938

Epoch: 5| Step: 5
Training loss: 1.2663894891738892
Validation loss: 2.0428327360460834

Epoch: 5| Step: 6
Training loss: 1.8845446109771729
Validation loss: 2.0859086898065384

Epoch: 5| Step: 7
Training loss: 2.344644546508789
Validation loss: 2.1265622185122584

Epoch: 5| Step: 8
Training loss: 1.6917976140975952
Validation loss: 2.05250556238236

Epoch: 5| Step: 9
Training loss: 1.9587860107421875
Validation loss: 2.0583534881632817

Epoch: 5| Step: 10
Training loss: 1.6453505754470825
Validation loss: 2.042870501036285

Epoch: 499| Step: 0
Training loss: 1.2029452323913574
Validation loss: 2.097173031940255

Epoch: 5| Step: 1
Training loss: 2.0326271057128906
Validation loss: 2.047261103507011

Epoch: 5| Step: 2
Training loss: 1.6435832977294922
Validation loss: 2.0333950083742858

Epoch: 5| Step: 3
Training loss: 1.7063833475112915
Validation loss: 2.0270863989348054

Epoch: 5| Step: 4
Training loss: 1.7422230243682861
Validation loss: 2.0486563533864994

Epoch: 5| Step: 5
Training loss: 1.8038603067398071
Validation loss: 2.0493963841469056

Epoch: 5| Step: 6
Training loss: 1.7177597284317017
Validation loss: 2.0380388229124007

Epoch: 5| Step: 7
Training loss: 1.712486982345581
Validation loss: 2.0300406948212655

Epoch: 5| Step: 8
Training loss: 1.6891626119613647
Validation loss: 2.0257405632285663

Epoch: 5| Step: 9
Training loss: 1.8180310726165771
Validation loss: 1.9981692580766575

Epoch: 5| Step: 10
Training loss: 1.3952932357788086
Validation loss: 2.100565820611933

Epoch: 500| Step: 0
Training loss: 1.488879919052124
Validation loss: 2.066893007165642

Epoch: 5| Step: 1
Training loss: 1.5050703287124634
Validation loss: 2.0045915188327914

Epoch: 5| Step: 2
Training loss: 1.792109489440918
Validation loss: 2.083678524981263

Epoch: 5| Step: 3
Training loss: 1.7640857696533203
Validation loss: 2.0517099698384604

Epoch: 5| Step: 4
Training loss: 1.4031436443328857
Validation loss: 1.9745320158620034

Epoch: 5| Step: 5
Training loss: 1.6740381717681885
Validation loss: 2.0133885388733237

Epoch: 5| Step: 6
Training loss: 1.6365330219268799
Validation loss: 1.9650315725675194

Epoch: 5| Step: 7
Training loss: 1.7551815509796143
Validation loss: 2.1091817694325603

Epoch: 5| Step: 8
Training loss: 1.594892144203186
Validation loss: 2.0694405058378815

Epoch: 5| Step: 9
Training loss: 1.7369476556777954
Validation loss: 1.9948891029563

Epoch: 5| Step: 10
Training loss: 1.9496551752090454
Validation loss: 1.9963283077363045

Epoch: 501| Step: 0
Training loss: 1.8921394348144531
Validation loss: 2.06989077983364

Epoch: 5| Step: 1
Training loss: 2.009854793548584
Validation loss: 2.0224924228524648

Epoch: 5| Step: 2
Training loss: 2.0332210063934326
Validation loss: 2.024508507021012

Epoch: 5| Step: 3
Training loss: 1.7299137115478516
Validation loss: 1.9654765398271623

Epoch: 5| Step: 4
Training loss: 1.7421281337738037
Validation loss: 2.0596651377216464

Epoch: 5| Step: 5
Training loss: 1.6877237558364868
Validation loss: 2.089828416865359

Epoch: 5| Step: 6
Training loss: 1.6696584224700928
Validation loss: 2.096173970930038

Epoch: 5| Step: 7
Training loss: 1.6750290393829346
Validation loss: 2.07188965043714

Epoch: 5| Step: 8
Training loss: 1.4138656854629517
Validation loss: 2.1258894525548464

Epoch: 5| Step: 9
Training loss: 1.4444091320037842
Validation loss: 2.085292670034593

Epoch: 5| Step: 10
Training loss: 1.823317050933838
Validation loss: 1.975589383033014

Epoch: 502| Step: 0
Training loss: 1.8001453876495361
Validation loss: 2.0540756461440877

Epoch: 5| Step: 1
Training loss: 1.58645761013031
Validation loss: 2.0791021034281743

Epoch: 5| Step: 2
Training loss: 1.7216031551361084
Validation loss: 2.06371573991673

Epoch: 5| Step: 3
Training loss: 1.5961247682571411
Validation loss: 2.0930906777740805

Epoch: 5| Step: 4
Training loss: 1.5395286083221436
Validation loss: 2.0139985430625176

Epoch: 5| Step: 5
Training loss: 1.589396357536316
Validation loss: 2.0804610944563344

Epoch: 5| Step: 6
Training loss: 1.5644137859344482
Validation loss: 2.035199470417474

Epoch: 5| Step: 7
Training loss: 1.9132969379425049
Validation loss: 2.064990484586326

Epoch: 5| Step: 8
Training loss: 1.144856572151184
Validation loss: 1.9798913104559785

Epoch: 5| Step: 9
Training loss: 1.811671257019043
Validation loss: 2.051111659696025

Epoch: 5| Step: 10
Training loss: 2.464210033416748
Validation loss: 2.0494562554103073

Epoch: 503| Step: 0
Training loss: 1.6545804738998413
Validation loss: 1.948184008239418

Epoch: 5| Step: 1
Training loss: 1.8186843395233154
Validation loss: 1.9322717651244132

Epoch: 5| Step: 2
Training loss: 1.7560272216796875
Validation loss: 2.0029416263744397

Epoch: 5| Step: 3
Training loss: 1.2439062595367432
Validation loss: 2.092456934272602

Epoch: 5| Step: 4
Training loss: 1.700634241104126
Validation loss: 1.9968392387513192

Epoch: 5| Step: 5
Training loss: 1.4333531856536865
Validation loss: 2.073225241835399

Epoch: 5| Step: 6
Training loss: 1.2840726375579834
Validation loss: 1.9732980010330037

Epoch: 5| Step: 7
Training loss: 2.0023202896118164
Validation loss: 2.0617002261582242

Epoch: 5| Step: 8
Training loss: 2.5220916271209717
Validation loss: 1.9868306729101366

Epoch: 5| Step: 9
Training loss: 1.710172414779663
Validation loss: 2.0358600795909925

Epoch: 5| Step: 10
Training loss: 1.6867347955703735
Validation loss: 2.0527083912203388

Epoch: 504| Step: 0
Training loss: 1.8965795040130615
Validation loss: 2.0131364535259944

Epoch: 5| Step: 1
Training loss: 1.452846884727478
Validation loss: 2.0488977701433244

Epoch: 5| Step: 2
Training loss: 2.056478977203369
Validation loss: 2.0517356549539874

Epoch: 5| Step: 3
Training loss: 1.8756601810455322
Validation loss: 2.061676758591847

Epoch: 5| Step: 4
Training loss: 1.4039567708969116
Validation loss: 2.0371835180508193

Epoch: 5| Step: 5
Training loss: 1.484666109085083
Validation loss: 2.067951681793377

Epoch: 5| Step: 6
Training loss: 1.7979423999786377
Validation loss: 2.030419503488848

Epoch: 5| Step: 7
Training loss: 1.032449722290039
Validation loss: 2.048596712850755

Epoch: 5| Step: 8
Training loss: 1.0925829410552979
Validation loss: 2.045663014534981

Epoch: 5| Step: 9
Training loss: 1.960304856300354
Validation loss: 2.0027077633847474

Epoch: 5| Step: 10
Training loss: 2.546754837036133
Validation loss: 2.1136320611482025

Epoch: 505| Step: 0
Training loss: 1.3989033699035645
Validation loss: 2.0213636326533493

Epoch: 5| Step: 1
Training loss: 1.907171607017517
Validation loss: 2.0902329439757974

Epoch: 5| Step: 2
Training loss: 1.3730002641677856
Validation loss: 2.0389506663045576

Epoch: 5| Step: 3
Training loss: 2.031816005706787
Validation loss: 2.043013943138943

Epoch: 5| Step: 4
Training loss: 1.801949143409729
Validation loss: 2.0366173277619066

Epoch: 5| Step: 5
Training loss: 1.6102383136749268
Validation loss: 2.139187502604659

Epoch: 5| Step: 6
Training loss: 1.670436143875122
Validation loss: 2.026077748626791

Epoch: 5| Step: 7
Training loss: 1.752902626991272
Validation loss: 2.0507917378538396

Epoch: 5| Step: 8
Training loss: 1.3691223859786987
Validation loss: 2.082050105576874

Epoch: 5| Step: 9
Training loss: 1.013697862625122
Validation loss: 2.0203939945467058

Epoch: 5| Step: 10
Training loss: 2.4524362087249756
Validation loss: 2.0693705851031887

Epoch: 506| Step: 0
Training loss: 1.292486548423767
Validation loss: 2.022118878620927

Epoch: 5| Step: 1
Training loss: 1.4686391353607178
Validation loss: 2.044257337047208

Epoch: 5| Step: 2
Training loss: 1.5458604097366333
Validation loss: 2.0366681250192786

Epoch: 5| Step: 3
Training loss: 2.0040652751922607
Validation loss: 2.029719075848979

Epoch: 5| Step: 4
Training loss: 1.8342723846435547
Validation loss: 2.014685735907606

Epoch: 5| Step: 5
Training loss: 1.3613497018814087
Validation loss: 1.962166170920095

Epoch: 5| Step: 6
Training loss: 1.7102863788604736
Validation loss: 2.0891812232232865

Epoch: 5| Step: 7
Training loss: 1.6370790004730225
Validation loss: 2.0221184376747376

Epoch: 5| Step: 8
Training loss: 1.8609416484832764
Validation loss: 1.981906456332053

Epoch: 5| Step: 9
Training loss: 1.3940078020095825
Validation loss: 2.095027037846145

Epoch: 5| Step: 10
Training loss: 2.262824535369873
Validation loss: 1.9464734113344582

Epoch: 507| Step: 0
Training loss: 1.2512753009796143
Validation loss: 1.9969163992071663

Epoch: 5| Step: 1
Training loss: 1.413392424583435
Validation loss: 2.0525478868074316

Epoch: 5| Step: 2
Training loss: 1.8179737329483032
Validation loss: 2.0013230821137786

Epoch: 5| Step: 3
Training loss: 1.7114055156707764
Validation loss: 2.0528836634851273

Epoch: 5| Step: 4
Training loss: 1.9399915933609009
Validation loss: 1.9986529888645295

Epoch: 5| Step: 5
Training loss: 1.6507902145385742
Validation loss: 2.0247445285961194

Epoch: 5| Step: 6
Training loss: 1.881140947341919
Validation loss: 2.0258125592303533

Epoch: 5| Step: 7
Training loss: 1.9968230724334717
Validation loss: 2.004154484759095

Epoch: 5| Step: 8
Training loss: 1.182985782623291
Validation loss: 2.1112059111236245

Epoch: 5| Step: 9
Training loss: 1.874029517173767
Validation loss: 2.0995393081377913

Epoch: 5| Step: 10
Training loss: 1.9520174264907837
Validation loss: 2.0573874596626527

Epoch: 508| Step: 0
Training loss: 1.5327155590057373
Validation loss: 2.0666098107573805

Epoch: 5| Step: 1
Training loss: 1.7291972637176514
Validation loss: 2.073752586559583

Epoch: 5| Step: 2
Training loss: 1.6429897546768188
Validation loss: 2.0577824167025986

Epoch: 5| Step: 3
Training loss: 1.3236232995986938
Validation loss: 2.0825711604087584

Epoch: 5| Step: 4
Training loss: 1.946621298789978
Validation loss: 2.131191440807876

Epoch: 5| Step: 5
Training loss: 1.6121212244033813
Validation loss: 2.0152937250752605

Epoch: 5| Step: 6
Training loss: 2.008796215057373
Validation loss: 2.00745217774504

Epoch: 5| Step: 7
Training loss: 1.820807695388794
Validation loss: 2.129571389126521

Epoch: 5| Step: 8
Training loss: 1.4772940874099731
Validation loss: 2.0239309751859276

Epoch: 5| Step: 9
Training loss: 1.871877670288086
Validation loss: 2.054688471619801

Epoch: 5| Step: 10
Training loss: 1.3214753866195679
Validation loss: 2.010474702363373

Epoch: 509| Step: 0
Training loss: 1.6385555267333984
Validation loss: 2.075893038062639

Epoch: 5| Step: 1
Training loss: 1.4586046934127808
Validation loss: 2.080927619370081

Epoch: 5| Step: 2
Training loss: 1.6735919713974
Validation loss: 2.0317444955149004

Epoch: 5| Step: 3
Training loss: 1.7180824279785156
Validation loss: 1.9784128678742277

Epoch: 5| Step: 4
Training loss: 1.333936333656311
Validation loss: 2.045068866463118

Epoch: 5| Step: 5
Training loss: 1.9347174167633057
Validation loss: 1.9815036801881687

Epoch: 5| Step: 6
Training loss: 1.7154808044433594
Validation loss: 2.081808452965111

Epoch: 5| Step: 7
Training loss: 1.656532645225525
Validation loss: 2.0756975912278697

Epoch: 5| Step: 8
Training loss: 1.686253547668457
Validation loss: 2.076038119613483

Epoch: 5| Step: 9
Training loss: 1.540984034538269
Validation loss: 2.138850014696839

Epoch: 5| Step: 10
Training loss: 2.0950090885162354
Validation loss: 1.9852964878082275

Epoch: 510| Step: 0
Training loss: 2.102181911468506
Validation loss: 2.0031425042818953

Epoch: 5| Step: 1
Training loss: 1.776544213294983
Validation loss: 2.1289586046690583

Epoch: 5| Step: 2
Training loss: 1.7110230922698975
Validation loss: 2.050954617479796

Epoch: 5| Step: 3
Training loss: 1.3260635137557983
Validation loss: 2.0487124227708384

Epoch: 5| Step: 4
Training loss: 1.5945498943328857
Validation loss: 2.0475246239733953

Epoch: 5| Step: 5
Training loss: 2.0233359336853027
Validation loss: 2.0616042537073933

Epoch: 5| Step: 6
Training loss: 1.5519968271255493
Validation loss: 2.002178406202665

Epoch: 5| Step: 7
Training loss: 1.5246576070785522
Validation loss: 2.0477735893700713

Epoch: 5| Step: 8
Training loss: 1.2434453964233398
Validation loss: 2.0325213696367

Epoch: 5| Step: 9
Training loss: 1.5944265127182007
Validation loss: 2.045324343507008

Epoch: 5| Step: 10
Training loss: 1.781440258026123
Validation loss: 2.022797241005846

Epoch: 511| Step: 0
Training loss: 1.7120158672332764
Validation loss: 2.0508437669405373

Epoch: 5| Step: 1
Training loss: 1.8456863164901733
Validation loss: 2.0521901704931773

Epoch: 5| Step: 2
Training loss: 1.827387809753418
Validation loss: 1.969734412367626

Epoch: 5| Step: 3
Training loss: 1.741123914718628
Validation loss: 2.063837097537133

Epoch: 5| Step: 4
Training loss: 1.2060576677322388
Validation loss: 2.05168011624326

Epoch: 5| Step: 5
Training loss: 1.1215336322784424
Validation loss: 1.9410248007825626

Epoch: 5| Step: 6
Training loss: 1.9362776279449463
Validation loss: 2.0187052321690384

Epoch: 5| Step: 7
Training loss: 1.9174559116363525
Validation loss: 2.079900469831241

Epoch: 5| Step: 8
Training loss: 2.021738290786743
Validation loss: 2.015653557674859

Epoch: 5| Step: 9
Training loss: 1.4743220806121826
Validation loss: 2.0970943576546124

Epoch: 5| Step: 10
Training loss: 1.3335413932800293
Validation loss: 2.033171711429473

Epoch: 512| Step: 0
Training loss: 1.926129937171936
Validation loss: 1.9861192754519883

Epoch: 5| Step: 1
Training loss: 1.3764123916625977
Validation loss: 2.053734601184886

Epoch: 5| Step: 2
Training loss: 1.3295255899429321
Validation loss: 2.038729034444337

Epoch: 5| Step: 3
Training loss: 1.5840842723846436
Validation loss: 1.950830667249618

Epoch: 5| Step: 4
Training loss: 1.9356073141098022
Validation loss: 2.0081818398608955

Epoch: 5| Step: 5
Training loss: 1.5579617023468018
Validation loss: 1.9812068144480388

Epoch: 5| Step: 6
Training loss: 1.3639354705810547
Validation loss: 2.0034084909705707

Epoch: 5| Step: 7
Training loss: 2.2144315242767334
Validation loss: 2.0447127601151824

Epoch: 5| Step: 8
Training loss: 1.1623578071594238
Validation loss: 1.9645925183450021

Epoch: 5| Step: 9
Training loss: 2.0049357414245605
Validation loss: 2.0459280526766213

Epoch: 5| Step: 10
Training loss: 1.8269431591033936
Validation loss: 2.030289508963144

Epoch: 513| Step: 0
Training loss: 1.8022323846817017
Validation loss: 1.9898253371638637

Epoch: 5| Step: 1
Training loss: 1.468442678451538
Validation loss: 2.04849761532199

Epoch: 5| Step: 2
Training loss: 2.5047783851623535
Validation loss: 1.9944595188222907

Epoch: 5| Step: 3
Training loss: 1.4932262897491455
Validation loss: 2.064281253404515

Epoch: 5| Step: 4
Training loss: 1.1822011470794678
Validation loss: 2.019608525819676

Epoch: 5| Step: 5
Training loss: 1.5239930152893066
Validation loss: 2.051010911182691

Epoch: 5| Step: 6
Training loss: 1.6385211944580078
Validation loss: 2.097278271951983

Epoch: 5| Step: 7
Training loss: 2.0265822410583496
Validation loss: 2.029924217090812

Epoch: 5| Step: 8
Training loss: 1.9945199489593506
Validation loss: 2.0400573771487

Epoch: 5| Step: 9
Training loss: 1.2088655233383179
Validation loss: 1.9728634165179344

Epoch: 5| Step: 10
Training loss: 1.360620379447937
Validation loss: 1.936637096507575

Epoch: 514| Step: 0
Training loss: 1.4827487468719482
Validation loss: 2.036382785407446

Epoch: 5| Step: 1
Training loss: 1.2871654033660889
Validation loss: 2.0799211507202475

Epoch: 5| Step: 2
Training loss: 1.6399974822998047
Validation loss: 2.001570088889009

Epoch: 5| Step: 3
Training loss: 1.8142154216766357
Validation loss: 2.0293589650943713

Epoch: 5| Step: 4
Training loss: 1.369317650794983
Validation loss: 2.0736047862678446

Epoch: 5| Step: 5
Training loss: 2.67160964012146
Validation loss: 2.036621465477892

Epoch: 5| Step: 6
Training loss: 1.5743248462677002
Validation loss: 2.056411163781279

Epoch: 5| Step: 7
Training loss: 1.4742834568023682
Validation loss: 1.997513791566254

Epoch: 5| Step: 8
Training loss: 1.5417966842651367
Validation loss: 2.1163801557274273

Epoch: 5| Step: 9
Training loss: 1.82257878780365
Validation loss: 2.0859199211161625

Epoch: 5| Step: 10
Training loss: 1.2126671075820923
Validation loss: 1.9645027832318378

Epoch: 515| Step: 0
Training loss: 2.1767032146453857
Validation loss: 1.9869039879050305

Epoch: 5| Step: 1
Training loss: 1.3396722078323364
Validation loss: 1.9979956278236963

Epoch: 5| Step: 2
Training loss: 1.5125041007995605
Validation loss: 2.0432117190412296

Epoch: 5| Step: 3
Training loss: 1.4147824048995972
Validation loss: 2.0047893485715313

Epoch: 5| Step: 4
Training loss: 1.332383155822754
Validation loss: 1.9808429646235641

Epoch: 5| Step: 5
Training loss: 1.4390175342559814
Validation loss: 2.0494554734999135

Epoch: 5| Step: 6
Training loss: 1.602309226989746
Validation loss: 2.0348456059732745

Epoch: 5| Step: 7
Training loss: 2.050388813018799
Validation loss: 2.011614053480087

Epoch: 5| Step: 8
Training loss: 1.8558076620101929
Validation loss: 2.0376162272627636

Epoch: 5| Step: 9
Training loss: 1.7183849811553955
Validation loss: 2.0001176352142007

Epoch: 5| Step: 10
Training loss: 1.558594822883606
Validation loss: 2.0620871551575197

Epoch: 516| Step: 0
Training loss: 1.2160369157791138
Validation loss: 1.9519800011829664

Epoch: 5| Step: 1
Training loss: 1.6183884143829346
Validation loss: 2.066298327138347

Epoch: 5| Step: 2
Training loss: 1.7112900018692017
Validation loss: 2.0037904170251664

Epoch: 5| Step: 3
Training loss: 2.4961936473846436
Validation loss: 2.0005967591398504

Epoch: 5| Step: 4
Training loss: 2.0395171642303467
Validation loss: 1.9949732557419808

Epoch: 5| Step: 5
Training loss: 1.4591234922409058
Validation loss: 2.0082166066733738

Epoch: 5| Step: 6
Training loss: 1.2552449703216553
Validation loss: 2.0328042366171397

Epoch: 5| Step: 7
Training loss: 1.3076438903808594
Validation loss: 1.993826566203948

Epoch: 5| Step: 8
Training loss: 1.7198807001113892
Validation loss: 2.084768388860969

Epoch: 5| Step: 9
Training loss: 1.5512056350708008
Validation loss: 2.0567500745096514

Epoch: 5| Step: 10
Training loss: 1.8875458240509033
Validation loss: 2.1159558373112834

Epoch: 517| Step: 0
Training loss: 1.9018688201904297
Validation loss: 2.0731223219184467

Epoch: 5| Step: 1
Training loss: 2.2072997093200684
Validation loss: 2.0628591275984243

Epoch: 5| Step: 2
Training loss: 1.593201994895935
Validation loss: 2.0994260336763118

Epoch: 5| Step: 3
Training loss: 2.217064619064331
Validation loss: 2.0864830581090783

Epoch: 5| Step: 4
Training loss: 1.4195924997329712
Validation loss: 2.0604568258408578

Epoch: 5| Step: 5
Training loss: 1.1338317394256592
Validation loss: 2.05168899156714

Epoch: 5| Step: 6
Training loss: 1.7218736410140991
Validation loss: 2.083830278406861

Epoch: 5| Step: 7
Training loss: 1.2211947441101074
Validation loss: 2.079456936928534

Epoch: 5| Step: 8
Training loss: 1.701398253440857
Validation loss: 2.0886294700766124

Epoch: 5| Step: 9
Training loss: 1.2383041381835938
Validation loss: 2.0371094506273986

Epoch: 5| Step: 10
Training loss: 1.6764845848083496
Validation loss: 2.0933175894521896

Epoch: 518| Step: 0
Training loss: 1.4988033771514893
Validation loss: 1.9489340333528415

Epoch: 5| Step: 1
Training loss: 2.046557903289795
Validation loss: 1.981903519681705

Epoch: 5| Step: 2
Training loss: 1.803346872329712
Validation loss: 2.0426284677238873

Epoch: 5| Step: 3
Training loss: 1.3335129022598267
Validation loss: 2.0291864359250633

Epoch: 5| Step: 4
Training loss: 1.8713817596435547
Validation loss: 2.017416866876746

Epoch: 5| Step: 5
Training loss: 1.8801113367080688
Validation loss: 2.074535805691955

Epoch: 5| Step: 6
Training loss: 2.0019690990448
Validation loss: 2.089248582880984

Epoch: 5| Step: 7
Training loss: 1.7299251556396484
Validation loss: 2.064897947413947

Epoch: 5| Step: 8
Training loss: 1.4966562986373901
Validation loss: 2.0251837904735277

Epoch: 5| Step: 9
Training loss: 1.3428033590316772
Validation loss: 2.0470572466491372

Epoch: 5| Step: 10
Training loss: 1.583388328552246
Validation loss: 1.9721277029283586

Epoch: 519| Step: 0
Training loss: 1.8960981369018555
Validation loss: 2.0250142953729116

Epoch: 5| Step: 1
Training loss: 1.5086522102355957
Validation loss: 2.020366153409404

Epoch: 5| Step: 2
Training loss: 0.9666863679885864
Validation loss: 2.042110320060484

Epoch: 5| Step: 3
Training loss: 1.626974105834961
Validation loss: 2.072252881142401

Epoch: 5| Step: 4
Training loss: 1.5577045679092407
Validation loss: 1.9881751639868623

Epoch: 5| Step: 5
Training loss: 1.7022340297698975
Validation loss: 2.012880702172556

Epoch: 5| Step: 6
Training loss: 1.7813804149627686
Validation loss: 2.006693419589791

Epoch: 5| Step: 7
Training loss: 1.7406517267227173
Validation loss: 2.010654831445345

Epoch: 5| Step: 8
Training loss: 1.9434840679168701
Validation loss: 2.046182063318068

Epoch: 5| Step: 9
Training loss: 1.594494104385376
Validation loss: 2.0955183352193525

Epoch: 5| Step: 10
Training loss: 1.613189458847046
Validation loss: 2.0590144511192077

Epoch: 520| Step: 0
Training loss: 1.5163034200668335
Validation loss: 1.9763605184452508

Epoch: 5| Step: 1
Training loss: 2.0107626914978027
Validation loss: 2.077984940621161

Epoch: 5| Step: 2
Training loss: 1.333406686782837
Validation loss: 2.014443500067598

Epoch: 5| Step: 3
Training loss: 1.1183273792266846
Validation loss: 2.027370831017853

Epoch: 5| Step: 4
Training loss: 1.4419400691986084
Validation loss: 2.04673271794473

Epoch: 5| Step: 5
Training loss: 1.4088548421859741
Validation loss: 2.0466647840315297

Epoch: 5| Step: 6
Training loss: 2.602968692779541
Validation loss: 1.969574023318547

Epoch: 5| Step: 7
Training loss: 1.5578892230987549
Validation loss: 2.0056106646855674

Epoch: 5| Step: 8
Training loss: 1.6993505954742432
Validation loss: 1.9940610906129241

Epoch: 5| Step: 9
Training loss: 1.4519098997116089
Validation loss: 1.992063872275814

Epoch: 5| Step: 10
Training loss: 1.4445067644119263
Validation loss: 2.0127687338859803

Epoch: 521| Step: 0
Training loss: 2.30820894241333
Validation loss: 1.9610909236374723

Epoch: 5| Step: 1
Training loss: 1.953453779220581
Validation loss: 2.112107066697972

Epoch: 5| Step: 2
Training loss: 1.4551565647125244
Validation loss: 2.0005360136749926

Epoch: 5| Step: 3
Training loss: 1.500036597251892
Validation loss: 2.0556358342529624

Epoch: 5| Step: 4
Training loss: 2.049518585205078
Validation loss: 2.0234689443342146

Epoch: 5| Step: 5
Training loss: 1.409531593322754
Validation loss: 2.033479121423537

Epoch: 5| Step: 6
Training loss: 1.7801614999771118
Validation loss: 2.0178892407366025

Epoch: 5| Step: 7
Training loss: 1.27741539478302
Validation loss: 1.9879973062904932

Epoch: 5| Step: 8
Training loss: 1.1321684122085571
Validation loss: 2.0519593351630756

Epoch: 5| Step: 9
Training loss: 1.8528854846954346
Validation loss: 2.017847189339258

Epoch: 5| Step: 10
Training loss: 1.4848549365997314
Validation loss: 2.076078909699635

Epoch: 522| Step: 0
Training loss: 1.734731674194336
Validation loss: 2.0981744091997863

Epoch: 5| Step: 1
Training loss: 1.5393095016479492
Validation loss: 2.0353302442899315

Epoch: 5| Step: 2
Training loss: 1.6278022527694702
Validation loss: 2.076256485395534

Epoch: 5| Step: 3
Training loss: 1.6038051843643188
Validation loss: 2.0930263893578642

Epoch: 5| Step: 4
Training loss: 1.4375722408294678
Validation loss: 2.145407692078621

Epoch: 5| Step: 5
Training loss: 1.772743582725525
Validation loss: 2.010770874638711

Epoch: 5| Step: 6
Training loss: 1.338749647140503
Validation loss: 1.99622755922297

Epoch: 5| Step: 7
Training loss: 1.4189317226409912
Validation loss: 2.023330186002998

Epoch: 5| Step: 8
Training loss: 1.571489930152893
Validation loss: 2.023711471147435

Epoch: 5| Step: 9
Training loss: 1.7319672107696533
Validation loss: 1.979345183218679

Epoch: 5| Step: 10
Training loss: 2.016615867614746
Validation loss: 2.0679214154520342

Epoch: 523| Step: 0
Training loss: 1.629600167274475
Validation loss: 2.051889850247291

Epoch: 5| Step: 1
Training loss: 1.7443727254867554
Validation loss: 1.9696691971953197

Epoch: 5| Step: 2
Training loss: 1.206072211265564
Validation loss: 2.0066106780882804

Epoch: 5| Step: 3
Training loss: 2.274242877960205
Validation loss: 2.0145986028896865

Epoch: 5| Step: 4
Training loss: 1.8949353694915771
Validation loss: 2.0537237300667712

Epoch: 5| Step: 5
Training loss: 1.6168196201324463
Validation loss: 2.0456510974514868

Epoch: 5| Step: 6
Training loss: 1.753610610961914
Validation loss: 2.0897871755784556

Epoch: 5| Step: 7
Training loss: 1.3276240825653076
Validation loss: 2.034523540927518

Epoch: 5| Step: 8
Training loss: 1.1749227046966553
Validation loss: 2.0213359043162358

Epoch: 5| Step: 9
Training loss: 1.4321410655975342
Validation loss: 2.066755384527227

Epoch: 5| Step: 10
Training loss: 1.962665319442749
Validation loss: 2.072675099936865

Epoch: 524| Step: 0
Training loss: 1.3650697469711304
Validation loss: 2.01846488829582

Epoch: 5| Step: 1
Training loss: 1.4355350732803345
Validation loss: 2.015599677639623

Epoch: 5| Step: 2
Training loss: 1.9193283319473267
Validation loss: 1.9844277853606849

Epoch: 5| Step: 3
Training loss: 1.8839633464813232
Validation loss: 2.046521084282988

Epoch: 5| Step: 4
Training loss: 1.2781263589859009
Validation loss: 2.0087110060517506

Epoch: 5| Step: 5
Training loss: 1.4502975940704346
Validation loss: 2.039531353981264

Epoch: 5| Step: 6
Training loss: 1.5145760774612427
Validation loss: 2.036803158380652

Epoch: 5| Step: 7
Training loss: 1.9775760173797607
Validation loss: 2.043748847899898

Epoch: 5| Step: 8
Training loss: 1.9070886373519897
Validation loss: 1.9825720966503184

Epoch: 5| Step: 9
Training loss: 1.7170082330703735
Validation loss: 2.0526492582854403

Epoch: 5| Step: 10
Training loss: 1.4943219423294067
Validation loss: 2.0024256283237087

Epoch: 525| Step: 0
Training loss: 1.6305469274520874
Validation loss: 2.0485918726972354

Epoch: 5| Step: 1
Training loss: 1.272354006767273
Validation loss: 2.057497560337026

Epoch: 5| Step: 2
Training loss: 1.4269638061523438
Validation loss: 2.018387912422098

Epoch: 5| Step: 3
Training loss: 1.9910545349121094
Validation loss: 2.051725374755039

Epoch: 5| Step: 4
Training loss: 1.5466667413711548
Validation loss: 1.9388124929961337

Epoch: 5| Step: 5
Training loss: 1.7358938455581665
Validation loss: 2.0163941537180254

Epoch: 5| Step: 6
Training loss: 2.2097535133361816
Validation loss: 2.0537094685339157

Epoch: 5| Step: 7
Training loss: 1.3309561014175415
Validation loss: 2.03148320926133

Epoch: 5| Step: 8
Training loss: 1.9578354358673096
Validation loss: 2.0156911932012087

Epoch: 5| Step: 9
Training loss: 1.4819961786270142
Validation loss: 2.05416359952701

Epoch: 5| Step: 10
Training loss: 1.4755713939666748
Validation loss: 2.0372489831780873

Epoch: 526| Step: 0
Training loss: 1.7280664443969727
Validation loss: 2.045075616528911

Epoch: 5| Step: 1
Training loss: 1.7822377681732178
Validation loss: 2.002603910302603

Epoch: 5| Step: 2
Training loss: 1.5011237859725952
Validation loss: 2.0396042267481485

Epoch: 5| Step: 3
Training loss: 1.811422348022461
Validation loss: 2.0444262578923214

Epoch: 5| Step: 4
Training loss: 1.8824021816253662
Validation loss: 1.9909353820226525

Epoch: 5| Step: 5
Training loss: 1.6754382848739624
Validation loss: 2.0258993666659117

Epoch: 5| Step: 6
Training loss: 1.5850540399551392
Validation loss: 2.0369938727348083

Epoch: 5| Step: 7
Training loss: 1.5506994724273682
Validation loss: 2.040272334570526

Epoch: 5| Step: 8
Training loss: 1.13796865940094
Validation loss: 2.0495762261011268

Epoch: 5| Step: 9
Training loss: 1.6151049137115479
Validation loss: 2.0169897515286683

Epoch: 5| Step: 10
Training loss: 1.7643232345581055
Validation loss: 2.012310863823019

Epoch: 527| Step: 0
Training loss: 1.2239469289779663
Validation loss: 2.0650136137521393

Epoch: 5| Step: 1
Training loss: 1.8271535634994507
Validation loss: 2.0569725856986096

Epoch: 5| Step: 2
Training loss: 2.1630847454071045
Validation loss: 1.9912015475252622

Epoch: 5| Step: 3
Training loss: 2.054743528366089
Validation loss: 1.9932077930819603

Epoch: 5| Step: 4
Training loss: 1.972818374633789
Validation loss: 2.0539552768071494

Epoch: 5| Step: 5
Training loss: 1.3399550914764404
Validation loss: 2.0538945864605647

Epoch: 5| Step: 6
Training loss: 1.457889199256897
Validation loss: 1.9998229985596032

Epoch: 5| Step: 7
Training loss: 1.7310845851898193
Validation loss: 2.0445425356588056

Epoch: 5| Step: 8
Training loss: 1.6225712299346924
Validation loss: 2.0261449775388165

Epoch: 5| Step: 9
Training loss: 1.0160558223724365
Validation loss: 1.9985270859092794

Epoch: 5| Step: 10
Training loss: 2.102487087249756
Validation loss: 2.0112597224532918

Epoch: 528| Step: 0
Training loss: 1.6001365184783936
Validation loss: 1.969419979280041

Epoch: 5| Step: 1
Training loss: 1.3701940774917603
Validation loss: 1.9869355129939255

Epoch: 5| Step: 2
Training loss: 0.9045075178146362
Validation loss: 2.025256153075926

Epoch: 5| Step: 3
Training loss: 1.644554853439331
Validation loss: 2.0052735331237956

Epoch: 5| Step: 4
Training loss: 1.7521374225616455
Validation loss: 1.9674263628580237

Epoch: 5| Step: 5
Training loss: 1.2026925086975098
Validation loss: 2.0137834702768633

Epoch: 5| Step: 6
Training loss: 2.1777639389038086
Validation loss: 2.025007438916032

Epoch: 5| Step: 7
Training loss: 1.6040757894515991
Validation loss: 2.081391070478706

Epoch: 5| Step: 8
Training loss: 2.2922635078430176
Validation loss: 2.048572555665047

Epoch: 5| Step: 9
Training loss: 1.7673527002334595
Validation loss: 2.094931076931697

Epoch: 5| Step: 10
Training loss: 1.4292709827423096
Validation loss: 2.1156807676438363

Epoch: 529| Step: 0
Training loss: 1.1610944271087646
Validation loss: 2.0536039170398506

Epoch: 5| Step: 1
Training loss: 2.1357767581939697
Validation loss: 2.044563026838405

Epoch: 5| Step: 2
Training loss: 1.698912262916565
Validation loss: 2.007638969729024

Epoch: 5| Step: 3
Training loss: 1.7032124996185303
Validation loss: 2.1484027242147796

Epoch: 5| Step: 4
Training loss: 1.742907166481018
Validation loss: 2.027953101742652

Epoch: 5| Step: 5
Training loss: 1.7101876735687256
Validation loss: 2.021302132196324

Epoch: 5| Step: 6
Training loss: 1.0439479351043701
Validation loss: 2.063657177391873

Epoch: 5| Step: 7
Training loss: 1.321652889251709
Validation loss: 2.021899095145605

Epoch: 5| Step: 8
Training loss: 2.1761348247528076
Validation loss: 2.051033466093002

Epoch: 5| Step: 9
Training loss: 1.4937896728515625
Validation loss: 2.0502911229287424

Epoch: 5| Step: 10
Training loss: 1.4369372129440308
Validation loss: 2.074230335092032

Epoch: 530| Step: 0
Training loss: 1.2350677251815796
Validation loss: 2.064224022690968

Epoch: 5| Step: 1
Training loss: 1.8681375980377197
Validation loss: 2.0384689069563344

Epoch: 5| Step: 2
Training loss: 1.8747365474700928
Validation loss: 2.0520479474016415

Epoch: 5| Step: 3
Training loss: 1.6311709880828857
Validation loss: 2.0953801319163334

Epoch: 5| Step: 4
Training loss: 1.871119737625122
Validation loss: 2.031053719982024

Epoch: 5| Step: 5
Training loss: 1.6783645153045654
Validation loss: 2.0083316039013606

Epoch: 5| Step: 6
Training loss: 2.3418049812316895
Validation loss: 2.0068635402187223

Epoch: 5| Step: 7
Training loss: 1.2679613828659058
Validation loss: 2.0122978636013564

Epoch: 5| Step: 8
Training loss: 1.3193970918655396
Validation loss: 2.04876450825763

Epoch: 5| Step: 9
Training loss: 1.0777530670166016
Validation loss: 1.9797525072610507

Epoch: 5| Step: 10
Training loss: 1.8727991580963135
Validation loss: 2.0112988000274985

Epoch: 531| Step: 0
Training loss: 1.303601861000061
Validation loss: 1.9803116501018565

Epoch: 5| Step: 1
Training loss: 1.701966643333435
Validation loss: 2.0045331754992084

Epoch: 5| Step: 2
Training loss: 1.7227741479873657
Validation loss: 2.008994802351921

Epoch: 5| Step: 3
Training loss: 1.7453515529632568
Validation loss: 2.032289133276991

Epoch: 5| Step: 4
Training loss: 1.828385353088379
Validation loss: 1.963294139472387

Epoch: 5| Step: 5
Training loss: 1.375112533569336
Validation loss: 2.0132440623416694

Epoch: 5| Step: 6
Training loss: 1.814794898033142
Validation loss: 2.041069217907485

Epoch: 5| Step: 7
Training loss: 1.6444587707519531
Validation loss: 2.035694711951799

Epoch: 5| Step: 8
Training loss: 1.8957504034042358
Validation loss: 2.0521415869394937

Epoch: 5| Step: 9
Training loss: 1.814888596534729
Validation loss: 1.9330251909071399

Epoch: 5| Step: 10
Training loss: 0.9298970699310303
Validation loss: 1.968462691512159

Epoch: 532| Step: 0
Training loss: 0.9548646807670593
Validation loss: 2.0391075098386375

Epoch: 5| Step: 1
Training loss: 1.7556612491607666
Validation loss: 2.0787199799732496

Epoch: 5| Step: 2
Training loss: 2.0232343673706055
Validation loss: 2.0091376740445375

Epoch: 5| Step: 3
Training loss: 1.3583847284317017
Validation loss: 2.0152709176463466

Epoch: 5| Step: 4
Training loss: 1.7748275995254517
Validation loss: 2.0294422193240096

Epoch: 5| Step: 5
Training loss: 2.101001739501953
Validation loss: 2.1016719059277604

Epoch: 5| Step: 6
Training loss: 1.7827831506729126
Validation loss: 2.0239224946627052

Epoch: 5| Step: 7
Training loss: 1.4829849004745483
Validation loss: 2.073514438444568

Epoch: 5| Step: 8
Training loss: 1.3735740184783936
Validation loss: 2.080252170562744

Epoch: 5| Step: 9
Training loss: 1.6076850891113281
Validation loss: 2.0756870341557327

Epoch: 5| Step: 10
Training loss: 1.5683952569961548
Validation loss: 2.0876411891752675

Epoch: 533| Step: 0
Training loss: 2.040839672088623
Validation loss: 2.108089398312312

Epoch: 5| Step: 1
Training loss: 1.4916859865188599
Validation loss: 2.07938051736483

Epoch: 5| Step: 2
Training loss: 1.0778114795684814
Validation loss: 2.0947082029875888

Epoch: 5| Step: 3
Training loss: 1.952641248703003
Validation loss: 2.086146568739286

Epoch: 5| Step: 4
Training loss: 1.5208613872528076
Validation loss: 2.074296764148179

Epoch: 5| Step: 5
Training loss: 2.141388416290283
Validation loss: 2.058219523840053

Epoch: 5| Step: 6
Training loss: 1.4012162685394287
Validation loss: 2.174546203305644

Epoch: 5| Step: 7
Training loss: 1.7567222118377686
Validation loss: 2.004082484911847

Epoch: 5| Step: 8
Training loss: 1.955863356590271
Validation loss: 2.101862386990619

Epoch: 5| Step: 9
Training loss: 1.563539743423462
Validation loss: 2.0415379731885848

Epoch: 5| Step: 10
Training loss: 1.0926669836044312
Validation loss: 2.051854743752428

Epoch: 534| Step: 0
Training loss: 0.9976728558540344
Validation loss: 2.0128228715671006

Epoch: 5| Step: 1
Training loss: 1.804623007774353
Validation loss: 2.083081526141013

Epoch: 5| Step: 2
Training loss: 1.4079197645187378
Validation loss: 2.0767671831192507

Epoch: 5| Step: 3
Training loss: 1.3979731798171997
Validation loss: 2.0509579514944427

Epoch: 5| Step: 4
Training loss: 1.5934116840362549
Validation loss: 2.0281442288429505

Epoch: 5| Step: 5
Training loss: 2.0109195709228516
Validation loss: 2.0905162519024265

Epoch: 5| Step: 6
Training loss: 1.8389127254486084
Validation loss: 2.0070257648344962

Epoch: 5| Step: 7
Training loss: 1.908103346824646
Validation loss: 1.9686908760378439

Epoch: 5| Step: 8
Training loss: 1.9814094305038452
Validation loss: 2.019485773578767

Epoch: 5| Step: 9
Training loss: 1.6639102697372437
Validation loss: 1.995579009415001

Epoch: 5| Step: 10
Training loss: 1.8054146766662598
Validation loss: 2.0279607311371834

Epoch: 535| Step: 0
Training loss: 0.9871503710746765
Validation loss: 2.053162197912893

Epoch: 5| Step: 1
Training loss: 0.9599536657333374
Validation loss: 2.0517402425889046

Epoch: 5| Step: 2
Training loss: 1.6236845254898071
Validation loss: 1.9691585738171813

Epoch: 5| Step: 3
Training loss: 1.8750989437103271
Validation loss: 1.9663832379925636

Epoch: 5| Step: 4
Training loss: 1.4219043254852295
Validation loss: 2.091042176369698

Epoch: 5| Step: 5
Training loss: 2.0923688411712646
Validation loss: 2.081776037011095

Epoch: 5| Step: 6
Training loss: 1.4495652914047241
Validation loss: 2.0130648254066386

Epoch: 5| Step: 7
Training loss: 1.456669569015503
Validation loss: 2.1254392721319713

Epoch: 5| Step: 8
Training loss: 1.838433861732483
Validation loss: 2.0389752695637364

Epoch: 5| Step: 9
Training loss: 2.112147569656372
Validation loss: 2.0304870477286716

Epoch: 5| Step: 10
Training loss: 1.7243273258209229
Validation loss: 1.9846663090490526

Epoch: 536| Step: 0
Training loss: 2.042914867401123
Validation loss: 2.0058583956892773

Epoch: 5| Step: 1
Training loss: 1.5427637100219727
Validation loss: 2.096102350501604

Epoch: 5| Step: 2
Training loss: 1.4529606103897095
Validation loss: 2.038916459647558

Epoch: 5| Step: 3
Training loss: 1.4025228023529053
Validation loss: 2.084011024044406

Epoch: 5| Step: 4
Training loss: 1.9780356884002686
Validation loss: 2.0819701956164454

Epoch: 5| Step: 5
Training loss: 1.3211569786071777
Validation loss: 1.994734121907142

Epoch: 5| Step: 6
Training loss: 1.8460638523101807
Validation loss: 2.0868103888727005

Epoch: 5| Step: 7
Training loss: 1.948213815689087
Validation loss: 2.0930942643073296

Epoch: 5| Step: 8
Training loss: 1.5404868125915527
Validation loss: 2.062292129762711

Epoch: 5| Step: 9
Training loss: 1.186448097229004
Validation loss: 1.9975296540926861

Epoch: 5| Step: 10
Training loss: 1.413055181503296
Validation loss: 2.0919761260350547

Epoch: 537| Step: 0
Training loss: 1.824306845664978
Validation loss: 2.098433663768153

Epoch: 5| Step: 1
Training loss: 1.3380995988845825
Validation loss: 2.0571160393376506

Epoch: 5| Step: 2
Training loss: 1.900385856628418
Validation loss: 2.0580390819939236

Epoch: 5| Step: 3
Training loss: 2.0817198753356934
Validation loss: 1.9931387862851542

Epoch: 5| Step: 4
Training loss: 1.5796582698822021
Validation loss: 2.09117873766089

Epoch: 5| Step: 5
Training loss: 1.3397256135940552
Validation loss: 2.0310903544067056

Epoch: 5| Step: 6
Training loss: 1.4697978496551514
Validation loss: 2.0574234301044094

Epoch: 5| Step: 7
Training loss: 1.2910221815109253
Validation loss: 2.081624082339707

Epoch: 5| Step: 8
Training loss: 2.1973674297332764
Validation loss: 2.0813888093476653

Epoch: 5| Step: 9
Training loss: 1.1703176498413086
Validation loss: 2.02147267582596

Epoch: 5| Step: 10
Training loss: 1.752252221107483
Validation loss: 2.0667153609696256

Epoch: 538| Step: 0
Training loss: 1.8129899501800537
Validation loss: 2.027889456800235

Epoch: 5| Step: 1
Training loss: 1.5299760103225708
Validation loss: 2.0481116694788777

Epoch: 5| Step: 2
Training loss: 1.6790279150009155
Validation loss: 2.0290981441415767

Epoch: 5| Step: 3
Training loss: 1.246728539466858
Validation loss: 2.0428177900211786

Epoch: 5| Step: 4
Training loss: 1.451865315437317
Validation loss: 1.9899931415434806

Epoch: 5| Step: 5
Training loss: 1.8378937244415283
Validation loss: 2.0338411715722855

Epoch: 5| Step: 6
Training loss: 1.7592719793319702
Validation loss: 2.0191436813723658

Epoch: 5| Step: 7
Training loss: 1.2940843105316162
Validation loss: 2.0016933397580217

Epoch: 5| Step: 8
Training loss: 1.8086296319961548
Validation loss: 1.9891726714308544

Epoch: 5| Step: 9
Training loss: 2.034083127975464
Validation loss: 1.9954831292552333

Epoch: 5| Step: 10
Training loss: 1.2776000499725342
Validation loss: 2.070494126248103

Epoch: 539| Step: 0
Training loss: 1.347293496131897
Validation loss: 2.0489707916013655

Epoch: 5| Step: 1
Training loss: 1.970815658569336
Validation loss: 2.137316570487074

Epoch: 5| Step: 2
Training loss: 2.065139055252075
Validation loss: 2.0421000808797856

Epoch: 5| Step: 3
Training loss: 1.4943691492080688
Validation loss: 2.03403676068911

Epoch: 5| Step: 4
Training loss: 1.0942268371582031
Validation loss: 2.0593896245443695

Epoch: 5| Step: 5
Training loss: 1.38437819480896
Validation loss: 2.008597256034933

Epoch: 5| Step: 6
Training loss: 2.1413285732269287
Validation loss: 2.0580710031652965

Epoch: 5| Step: 7
Training loss: 1.5942937135696411
Validation loss: 2.0358600206272577

Epoch: 5| Step: 8
Training loss: 1.3870174884796143
Validation loss: 2.027770855093515

Epoch: 5| Step: 9
Training loss: 1.1742850542068481
Validation loss: 2.0989579859600274

Epoch: 5| Step: 10
Training loss: 1.6829665899276733
Validation loss: 2.0739067087891283

Epoch: 540| Step: 0
Training loss: 0.9119512438774109
Validation loss: 2.0342583335855955

Epoch: 5| Step: 1
Training loss: 2.577418804168701
Validation loss: 2.117816786612234

Epoch: 5| Step: 2
Training loss: 2.1762309074401855
Validation loss: 2.0883030609417985

Epoch: 5| Step: 3
Training loss: 1.9097483158111572
Validation loss: 2.036248460892708

Epoch: 5| Step: 4
Training loss: 1.5836470127105713
Validation loss: 2.0183108545118764

Epoch: 5| Step: 5
Training loss: 1.7908709049224854
Validation loss: 2.042900764813987

Epoch: 5| Step: 6
Training loss: 1.1509668827056885
Validation loss: 2.027066710174725

Epoch: 5| Step: 7
Training loss: 1.624205231666565
Validation loss: 2.071800874125573

Epoch: 5| Step: 8
Training loss: 1.0620050430297852
Validation loss: 2.088929964650062

Epoch: 5| Step: 9
Training loss: 1.39462149143219
Validation loss: 2.0855363530497395

Epoch: 5| Step: 10
Training loss: 1.3274645805358887
Validation loss: 2.0760992393698743

Epoch: 541| Step: 0
Training loss: 1.1551063060760498
Validation loss: 2.013077697446269

Epoch: 5| Step: 1
Training loss: 1.9001102447509766
Validation loss: 1.9856888888984598

Epoch: 5| Step: 2
Training loss: 1.3560987710952759
Validation loss: 2.045089863961743

Epoch: 5| Step: 3
Training loss: 1.8100740909576416
Validation loss: 2.044508639202323

Epoch: 5| Step: 4
Training loss: 1.7162249088287354
Validation loss: 2.0327906685490764

Epoch: 5| Step: 5
Training loss: 1.5214672088623047
Validation loss: 1.946012455929992

Epoch: 5| Step: 6
Training loss: 1.960618257522583
Validation loss: 2.015179989158466

Epoch: 5| Step: 7
Training loss: 1.4276673793792725
Validation loss: 2.052139937236745

Epoch: 5| Step: 8
Training loss: 1.6238867044448853
Validation loss: 2.057292402431529

Epoch: 5| Step: 9
Training loss: 1.531896948814392
Validation loss: 2.0204272500930296

Epoch: 5| Step: 10
Training loss: 1.736960768699646
Validation loss: 2.046017749335176

Epoch: 542| Step: 0
Training loss: 1.4654687643051147
Validation loss: 2.0508044035203996

Epoch: 5| Step: 1
Training loss: 1.2462087869644165
Validation loss: 2.0428803992527786

Epoch: 5| Step: 2
Training loss: 1.8804107904434204
Validation loss: 2.013253608057576

Epoch: 5| Step: 3
Training loss: 2.5236408710479736
Validation loss: 2.07995113249748

Epoch: 5| Step: 4
Training loss: 1.33517587184906
Validation loss: 2.004896427995415

Epoch: 5| Step: 5
Training loss: 1.9914718866348267
Validation loss: 2.1214730252501783

Epoch: 5| Step: 6
Training loss: 1.495607852935791
Validation loss: 2.0654785620268954

Epoch: 5| Step: 7
Training loss: 1.1017850637435913
Validation loss: 2.1206766431049635

Epoch: 5| Step: 8
Training loss: 1.758021593093872
Validation loss: 2.0333519007570002

Epoch: 5| Step: 9
Training loss: 1.5148546695709229
Validation loss: 2.0514190709719093

Epoch: 5| Step: 10
Training loss: 1.085364818572998
Validation loss: 2.077132850564936

Epoch: 543| Step: 0
Training loss: 2.011509418487549
Validation loss: 2.0058366008984145

Epoch: 5| Step: 1
Training loss: 1.2824188470840454
Validation loss: 2.032329297834827

Epoch: 5| Step: 2
Training loss: 1.9234377145767212
Validation loss: 2.060264161837998

Epoch: 5| Step: 3
Training loss: 1.9357655048370361
Validation loss: 1.994079884662423

Epoch: 5| Step: 4
Training loss: 1.7893288135528564
Validation loss: 2.022607380344022

Epoch: 5| Step: 5
Training loss: 1.782949686050415
Validation loss: 1.9812345684215587

Epoch: 5| Step: 6
Training loss: 1.3375909328460693
Validation loss: 2.0192568443154775

Epoch: 5| Step: 7
Training loss: 1.6181905269622803
Validation loss: 2.0866288574793006

Epoch: 5| Step: 8
Training loss: 1.60675048828125
Validation loss: 2.0311873894865795

Epoch: 5| Step: 9
Training loss: 1.4517492055892944
Validation loss: 2.015449380361906

Epoch: 5| Step: 10
Training loss: 1.282721996307373
Validation loss: 2.071905897509667

Epoch: 544| Step: 0
Training loss: 1.5939439535140991
Validation loss: 2.1269555630222445

Epoch: 5| Step: 1
Training loss: 2.1685776710510254
Validation loss: 2.063900274615134

Epoch: 5| Step: 2
Training loss: 1.277824878692627
Validation loss: 2.135210285904587

Epoch: 5| Step: 3
Training loss: 2.1896796226501465
Validation loss: 2.0769648654486543

Epoch: 5| Step: 4
Training loss: 1.309281587600708
Validation loss: 2.01453733956942

Epoch: 5| Step: 5
Training loss: 1.727212905883789
Validation loss: 2.104893661314441

Epoch: 5| Step: 6
Training loss: 1.817712426185608
Validation loss: 2.0183227549317064

Epoch: 5| Step: 7
Training loss: 1.8263492584228516
Validation loss: 2.139909736571773

Epoch: 5| Step: 8
Training loss: 1.3325130939483643
Validation loss: 2.0862806150990147

Epoch: 5| Step: 9
Training loss: 1.5745024681091309
Validation loss: 2.0766831777429067

Epoch: 5| Step: 10
Training loss: 1.2681623697280884
Validation loss: 2.0410042091082503

Epoch: 545| Step: 0
Training loss: 0.9444952011108398
Validation loss: 2.015222131565053

Epoch: 5| Step: 1
Training loss: 1.9211152791976929
Validation loss: 2.0710517309045278

Epoch: 5| Step: 2
Training loss: 1.795874834060669
Validation loss: 2.044303035223356

Epoch: 5| Step: 3
Training loss: 1.7673168182373047
Validation loss: 2.0233451345915436

Epoch: 5| Step: 4
Training loss: 1.4897741079330444
Validation loss: 2.00617382859671

Epoch: 5| Step: 5
Training loss: 1.7701574563980103
Validation loss: 2.0389455544051303

Epoch: 5| Step: 6
Training loss: 1.6656992435455322
Validation loss: 1.9722072232154109

Epoch: 5| Step: 7
Training loss: 1.5695302486419678
Validation loss: 2.024259605715352

Epoch: 5| Step: 8
Training loss: 1.4485114812850952
Validation loss: 2.0078405231557865

Epoch: 5| Step: 9
Training loss: 1.939684271812439
Validation loss: 2.0761663349725867

Epoch: 5| Step: 10
Training loss: 1.6737017631530762
Validation loss: 2.0639757007680912

Epoch: 546| Step: 0
Training loss: 2.147273540496826
Validation loss: 2.0501892041134577

Epoch: 5| Step: 1
Training loss: 1.4136861562728882
Validation loss: 2.0328713104289067

Epoch: 5| Step: 2
Training loss: 1.8375097513198853
Validation loss: 2.009027845116072

Epoch: 5| Step: 3
Training loss: 1.4575726985931396
Validation loss: 2.077395286611331

Epoch: 5| Step: 4
Training loss: 1.297189474105835
Validation loss: 2.020227309196226

Epoch: 5| Step: 5
Training loss: 1.5061523914337158
Validation loss: 2.05434158027813

Epoch: 5| Step: 6
Training loss: 1.7470791339874268
Validation loss: 2.07080489589322

Epoch: 5| Step: 7
Training loss: 1.6337699890136719
Validation loss: 2.059603765446653

Epoch: 5| Step: 8
Training loss: 0.9921674728393555
Validation loss: 2.119464164139122

Epoch: 5| Step: 9
Training loss: 2.077941417694092
Validation loss: 2.067407133758709

Epoch: 5| Step: 10
Training loss: 1.3235516548156738
Validation loss: 2.081612120392502

Epoch: 547| Step: 0
Training loss: 1.2816070318222046
Validation loss: 2.0241431907940934

Epoch: 5| Step: 1
Training loss: 1.2669949531555176
Validation loss: 2.0580451244949014

Epoch: 5| Step: 2
Training loss: 1.2686718702316284
Validation loss: 2.112045536759079

Epoch: 5| Step: 3
Training loss: 1.3317601680755615
Validation loss: 2.0367377522171184

Epoch: 5| Step: 4
Training loss: 1.2306855916976929
Validation loss: 2.0086645567288963

Epoch: 5| Step: 5
Training loss: 1.652138113975525
Validation loss: 2.0349964018790954

Epoch: 5| Step: 6
Training loss: 1.79866623878479
Validation loss: 2.0704667606661395

Epoch: 5| Step: 7
Training loss: 1.8185955286026
Validation loss: 2.052860090809484

Epoch: 5| Step: 8
Training loss: 2.5260074138641357
Validation loss: 1.993845724290417

Epoch: 5| Step: 9
Training loss: 1.5947906970977783
Validation loss: 2.0135676501899638

Epoch: 5| Step: 10
Training loss: 1.5840553045272827
Validation loss: 2.0439494963615172

Epoch: 548| Step: 0
Training loss: 1.9274383783340454
Validation loss: 1.9717754548595798

Epoch: 5| Step: 1
Training loss: 1.5237922668457031
Validation loss: 2.0177354479348786

Epoch: 5| Step: 2
Training loss: 1.56041419506073
Validation loss: 1.9692944839436521

Epoch: 5| Step: 3
Training loss: 1.7844858169555664
Validation loss: 2.0287232155440957

Epoch: 5| Step: 4
Training loss: 1.6037753820419312
Validation loss: 2.053237707384171

Epoch: 5| Step: 5
Training loss: 1.2575676441192627
Validation loss: 1.9983581407095796

Epoch: 5| Step: 6
Training loss: 0.8949317932128906
Validation loss: 2.030475872819142

Epoch: 5| Step: 7
Training loss: 1.707226037979126
Validation loss: 1.9874211844577585

Epoch: 5| Step: 8
Training loss: 1.8606007099151611
Validation loss: 2.0247846572629866

Epoch: 5| Step: 9
Training loss: 1.654006004333496
Validation loss: 2.009050093671327

Epoch: 5| Step: 10
Training loss: 1.1711430549621582
Validation loss: 2.0503135650388655

Epoch: 549| Step: 0
Training loss: 1.3598737716674805
Validation loss: 2.05813035913693

Epoch: 5| Step: 1
Training loss: 1.4485540390014648
Validation loss: 1.9647927771332443

Epoch: 5| Step: 2
Training loss: 1.1864347457885742
Validation loss: 2.049952554446395

Epoch: 5| Step: 3
Training loss: 1.4710919857025146
Validation loss: 2.046013065563735

Epoch: 5| Step: 4
Training loss: 1.9818916320800781
Validation loss: 2.022597743618873

Epoch: 5| Step: 5
Training loss: 1.5199384689331055
Validation loss: 2.049838986448062

Epoch: 5| Step: 6
Training loss: 1.4798709154129028
Validation loss: 2.04326795506221

Epoch: 5| Step: 7
Training loss: 1.345544457435608
Validation loss: 2.08203560562544

Epoch: 5| Step: 8
Training loss: 1.9315102100372314
Validation loss: 2.031425719620079

Epoch: 5| Step: 9
Training loss: 1.5769551992416382
Validation loss: 1.9900275712372155

Epoch: 5| Step: 10
Training loss: 2.424813747406006
Validation loss: 2.1173804985579623

Epoch: 550| Step: 0
Training loss: 1.4418103694915771
Validation loss: 1.99236306195618

Epoch: 5| Step: 1
Training loss: 1.6780593395233154
Validation loss: 2.1173418721845074

Epoch: 5| Step: 2
Training loss: 1.5564780235290527
Validation loss: 2.0409146098680395

Epoch: 5| Step: 3
Training loss: 1.981332778930664
Validation loss: 1.9723461622832923

Epoch: 5| Step: 4
Training loss: 0.8828522562980652
Validation loss: 2.005244888285155

Epoch: 5| Step: 5
Training loss: 1.9343936443328857
Validation loss: 2.061249192043017

Epoch: 5| Step: 6
Training loss: 1.795179009437561
Validation loss: 2.0380344877960863

Epoch: 5| Step: 7
Training loss: 1.307306170463562
Validation loss: 2.0212261215333016

Epoch: 5| Step: 8
Training loss: 1.3604553937911987
Validation loss: 1.9821341960660872

Epoch: 5| Step: 9
Training loss: 1.2218053340911865
Validation loss: 2.0199219795965377

Epoch: 5| Step: 10
Training loss: 2.1206538677215576
Validation loss: 1.9869397506918958

Epoch: 551| Step: 0
Training loss: 1.061098337173462
Validation loss: 1.9925945202509563

Epoch: 5| Step: 1
Training loss: 1.7616221904754639
Validation loss: 2.0447527541909167

Epoch: 5| Step: 2
Training loss: 1.5500959157943726
Validation loss: 2.071165915458433

Epoch: 5| Step: 3
Training loss: 0.8580082654953003
Validation loss: 2.0129896863814323

Epoch: 5| Step: 4
Training loss: 1.204105019569397
Validation loss: 2.1228118301719747

Epoch: 5| Step: 5
Training loss: 1.559185266494751
Validation loss: 2.086883314194218

Epoch: 5| Step: 6
Training loss: 1.4558398723602295
Validation loss: 2.0758532324144916

Epoch: 5| Step: 7
Training loss: 1.7197086811065674
Validation loss: 2.0416002529923634

Epoch: 5| Step: 8
Training loss: 2.027724266052246
Validation loss: 2.0256285077782086

Epoch: 5| Step: 9
Training loss: 2.1661534309387207
Validation loss: 2.04041628683767

Epoch: 5| Step: 10
Training loss: 1.7277297973632812
Validation loss: 2.0651202022388415

Epoch: 552| Step: 0
Training loss: 1.2044004201889038
Validation loss: 2.0326444115690006

Epoch: 5| Step: 1
Training loss: 1.3361589908599854
Validation loss: 2.094351996657669

Epoch: 5| Step: 2
Training loss: 1.4450175762176514
Validation loss: 2.0136467551672332

Epoch: 5| Step: 3
Training loss: 1.6382049322128296
Validation loss: 2.0195787939974057

Epoch: 5| Step: 4
Training loss: 1.2494962215423584
Validation loss: 2.0464258501606603

Epoch: 5| Step: 5
Training loss: 1.9619051218032837
Validation loss: 2.074278969918528

Epoch: 5| Step: 6
Training loss: 1.4118491411209106
Validation loss: 2.091314938760573

Epoch: 5| Step: 7
Training loss: 0.9586403965950012
Validation loss: 2.0857828176149757

Epoch: 5| Step: 8
Training loss: 1.7664384841918945
Validation loss: 2.03993203947621

Epoch: 5| Step: 9
Training loss: 2.2244138717651367
Validation loss: 1.9783755553665983

Epoch: 5| Step: 10
Training loss: 1.79909348487854
Validation loss: 2.1013297778303905

Epoch: 553| Step: 0
Training loss: 1.9525302648544312
Validation loss: 2.0113000459568475

Epoch: 5| Step: 1
Training loss: 1.9332374334335327
Validation loss: 2.0304306014891593

Epoch: 5| Step: 2
Training loss: 1.1239230632781982
Validation loss: 2.066550390694731

Epoch: 5| Step: 3
Training loss: 1.4796175956726074
Validation loss: 1.9654674555665703

Epoch: 5| Step: 4
Training loss: 2.036963939666748
Validation loss: 2.054396706242715

Epoch: 5| Step: 5
Training loss: 1.5719550848007202
Validation loss: 2.0511546404131

Epoch: 5| Step: 6
Training loss: 1.6883165836334229
Validation loss: 2.094332504016097

Epoch: 5| Step: 7
Training loss: 1.4232759475708008
Validation loss: 2.0325490787465084

Epoch: 5| Step: 8
Training loss: 1.3342474699020386
Validation loss: 1.9880518118540447

Epoch: 5| Step: 9
Training loss: 1.8218895196914673
Validation loss: 2.066362654009173

Epoch: 5| Step: 10
Training loss: 1.442765712738037
Validation loss: 1.9897451734030118

Epoch: 554| Step: 0
Training loss: 2.017845392227173
Validation loss: 1.9707252671641688

Epoch: 5| Step: 1
Training loss: 1.3600915670394897
Validation loss: 1.9789614446701542

Epoch: 5| Step: 2
Training loss: 1.9269107580184937
Validation loss: 1.9927884455650084

Epoch: 5| Step: 3
Training loss: 1.4573183059692383
Validation loss: 1.996797961573447

Epoch: 5| Step: 4
Training loss: 1.7895793914794922
Validation loss: 1.9952777252402356

Epoch: 5| Step: 5
Training loss: 1.3242956399917603
Validation loss: 2.0020426627128356

Epoch: 5| Step: 6
Training loss: 1.7757313251495361
Validation loss: 1.9446616198426934

Epoch: 5| Step: 7
Training loss: 1.4287543296813965
Validation loss: 1.9845876821907618

Epoch: 5| Step: 8
Training loss: 1.431112289428711
Validation loss: 2.0332093649013068

Epoch: 5| Step: 9
Training loss: 1.5298268795013428
Validation loss: 2.0350756029928885

Epoch: 5| Step: 10
Training loss: 1.4872204065322876
Validation loss: 2.086852818407038

Epoch: 555| Step: 0
Training loss: 1.8058189153671265
Validation loss: 2.0357028322835125

Epoch: 5| Step: 1
Training loss: 1.6368663311004639
Validation loss: 2.082727181014194

Epoch: 5| Step: 2
Training loss: 2.0781540870666504
Validation loss: 2.021784177390478

Epoch: 5| Step: 3
Training loss: 1.3638023138046265
Validation loss: 2.0790907490637993

Epoch: 5| Step: 4
Training loss: 1.5085480213165283
Validation loss: 2.0787417029821746

Epoch: 5| Step: 5
Training loss: 1.022007703781128
Validation loss: 2.1300517256541918

Epoch: 5| Step: 6
Training loss: 1.2362581491470337
Validation loss: 2.045748787541543

Epoch: 5| Step: 7
Training loss: 1.7067219018936157
Validation loss: 2.0735613017953853

Epoch: 5| Step: 8
Training loss: 1.675432801246643
Validation loss: 2.0327251047216435

Epoch: 5| Step: 9
Training loss: 1.5953930616378784
Validation loss: 2.0454981096329226

Epoch: 5| Step: 10
Training loss: 1.3861929178237915
Validation loss: 2.041091872799781

Epoch: 556| Step: 0
Training loss: 1.5962995290756226
Validation loss: 2.0730230923621886

Epoch: 5| Step: 1
Training loss: 1.3059793710708618
Validation loss: 1.951879778215962

Epoch: 5| Step: 2
Training loss: 1.3831851482391357
Validation loss: 2.0156018605796238

Epoch: 5| Step: 3
Training loss: 1.4481635093688965
Validation loss: 2.0692099114899993

Epoch: 5| Step: 4
Training loss: 1.940003752708435
Validation loss: 2.0218278848996727

Epoch: 5| Step: 5
Training loss: 1.8381555080413818
Validation loss: 1.9711325142973213

Epoch: 5| Step: 6
Training loss: 1.0639184713363647
Validation loss: 2.036792770508797

Epoch: 5| Step: 7
Training loss: 2.057446241378784
Validation loss: 2.033163386006509

Epoch: 5| Step: 8
Training loss: 1.6964753866195679
Validation loss: 2.069538385637345

Epoch: 5| Step: 9
Training loss: 1.4581743478775024
Validation loss: 2.004278116328742

Epoch: 5| Step: 10
Training loss: 1.6375904083251953
Validation loss: 2.1341732958311677

Epoch: 557| Step: 0
Training loss: 1.5631157159805298
Validation loss: 2.045076052347819

Epoch: 5| Step: 1
Training loss: 1.8190860748291016
Validation loss: 2.0239032545397357

Epoch: 5| Step: 2
Training loss: 1.6153647899627686
Validation loss: 2.097568401726343

Epoch: 5| Step: 3
Training loss: 1.3977822065353394
Validation loss: 2.0523879348590808

Epoch: 5| Step: 4
Training loss: 1.3736841678619385
Validation loss: 2.0693416595458984

Epoch: 5| Step: 5
Training loss: 1.4921128749847412
Validation loss: 2.0585187442841066

Epoch: 5| Step: 6
Training loss: 1.2191495895385742
Validation loss: 2.0794679003377117

Epoch: 5| Step: 7
Training loss: 1.539552927017212
Validation loss: 1.991600896722527

Epoch: 5| Step: 8
Training loss: 1.377733826637268
Validation loss: 2.121281805858817

Epoch: 5| Step: 9
Training loss: 2.035738706588745
Validation loss: 1.9867412608156922

Epoch: 5| Step: 10
Training loss: 1.2305134534835815
Validation loss: 2.009041691339144

Epoch: 558| Step: 0
Training loss: 1.5759382247924805
Validation loss: 2.095215243677939

Epoch: 5| Step: 1
Training loss: 1.630849838256836
Validation loss: 2.019399032797865

Epoch: 5| Step: 2
Training loss: 1.1121314764022827
Validation loss: 2.0475545416596117

Epoch: 5| Step: 3
Training loss: 1.740910530090332
Validation loss: 2.064145249705161

Epoch: 5| Step: 4
Training loss: 1.5199007987976074
Validation loss: 2.1252827618711736

Epoch: 5| Step: 5
Training loss: 1.3674236536026
Validation loss: 2.0684102850575603

Epoch: 5| Step: 6
Training loss: 1.1512219905853271
Validation loss: 2.0064247244147846

Epoch: 5| Step: 7
Training loss: 1.5814131498336792
Validation loss: 2.1086577036047496

Epoch: 5| Step: 8
Training loss: 1.7799513339996338
Validation loss: 2.057271642069663

Epoch: 5| Step: 9
Training loss: 2.029761552810669
Validation loss: 2.078000876211351

Epoch: 5| Step: 10
Training loss: 1.7870404720306396
Validation loss: 2.1053832346393215

Epoch: 559| Step: 0
Training loss: 1.3805186748504639
Validation loss: 2.00275263222315

Epoch: 5| Step: 1
Training loss: 1.4140839576721191
Validation loss: 2.065680411554152

Epoch: 5| Step: 2
Training loss: 1.6723216772079468
Validation loss: 2.0527867271054174

Epoch: 5| Step: 3
Training loss: 1.1958481073379517
Validation loss: 2.0139306578584897

Epoch: 5| Step: 4
Training loss: 1.4955785274505615
Validation loss: 1.988197559951454

Epoch: 5| Step: 5
Training loss: 1.5305652618408203
Validation loss: 2.0418429374694824

Epoch: 5| Step: 6
Training loss: 1.7988612651824951
Validation loss: 2.0798864415896836

Epoch: 5| Step: 7
Training loss: 1.4213851690292358
Validation loss: 2.0441326595121816

Epoch: 5| Step: 8
Training loss: 1.8336083889007568
Validation loss: 2.0292916477367444

Epoch: 5| Step: 9
Training loss: 1.7755295038223267
Validation loss: 2.04372452920483

Epoch: 5| Step: 10
Training loss: 1.7339284420013428
Validation loss: 1.9203537074468469

Epoch: 560| Step: 0
Training loss: 1.0572545528411865
Validation loss: 2.040185293843669

Epoch: 5| Step: 1
Training loss: 1.5720336437225342
Validation loss: 2.0706202676219325

Epoch: 5| Step: 2
Training loss: 1.5771944522857666
Validation loss: 2.0110231625136508

Epoch: 5| Step: 3
Training loss: 1.5936088562011719
Validation loss: 2.036078099281557

Epoch: 5| Step: 4
Training loss: 1.8628723621368408
Validation loss: 2.0630770126978555

Epoch: 5| Step: 5
Training loss: 1.7377452850341797
Validation loss: 2.072602907816569

Epoch: 5| Step: 6
Training loss: 1.3485187292099
Validation loss: 2.053465638109433

Epoch: 5| Step: 7
Training loss: 1.5794354677200317
Validation loss: 1.9927784499301706

Epoch: 5| Step: 8
Training loss: 1.3675655126571655
Validation loss: 2.06113709685623

Epoch: 5| Step: 9
Training loss: 1.7940022945404053
Validation loss: 2.0153916471747944

Epoch: 5| Step: 10
Training loss: 1.5698601007461548
Validation loss: 2.0518733916744107

Epoch: 561| Step: 0
Training loss: 1.5097659826278687
Validation loss: 2.0299730608540196

Epoch: 5| Step: 1
Training loss: 1.5174615383148193
Validation loss: 2.029139918665732

Epoch: 5| Step: 2
Training loss: 1.65374755859375
Validation loss: 2.0327201351042716

Epoch: 5| Step: 3
Training loss: 1.5752536058425903
Validation loss: 1.974288635356452

Epoch: 5| Step: 4
Training loss: 1.0036276578903198
Validation loss: 2.060695130337951

Epoch: 5| Step: 5
Training loss: 1.8397772312164307
Validation loss: 2.141826609129547

Epoch: 5| Step: 6
Training loss: 1.6440328359603882
Validation loss: 2.082717136670184

Epoch: 5| Step: 7
Training loss: 1.1992042064666748
Validation loss: 2.033324997912171

Epoch: 5| Step: 8
Training loss: 1.3680890798568726
Validation loss: 2.0180783963972524

Epoch: 5| Step: 9
Training loss: 2.034432888031006
Validation loss: 1.9724301112595426

Epoch: 5| Step: 10
Training loss: 1.5784330368041992
Validation loss: 2.0217325636135635

Epoch: 562| Step: 0
Training loss: 1.191880226135254
Validation loss: 2.044699602229621

Epoch: 5| Step: 1
Training loss: 1.8654766082763672
Validation loss: 2.0626388672859437

Epoch: 5| Step: 2
Training loss: 1.4492117166519165
Validation loss: 2.0994857818849626

Epoch: 5| Step: 3
Training loss: 1.902336835861206
Validation loss: 2.034045127130324

Epoch: 5| Step: 4
Training loss: 1.1736021041870117
Validation loss: 2.0299112271237116

Epoch: 5| Step: 5
Training loss: 1.5034836530685425
Validation loss: 2.052989093206262

Epoch: 5| Step: 6
Training loss: 1.6401342153549194
Validation loss: 2.0678535097388813

Epoch: 5| Step: 7
Training loss: 1.221477746963501
Validation loss: 2.0452302066228722

Epoch: 5| Step: 8
Training loss: 2.177581310272217
Validation loss: 2.0343048905813568

Epoch: 5| Step: 9
Training loss: 1.465879201889038
Validation loss: 2.0578431775493007

Epoch: 5| Step: 10
Training loss: 1.6063733100891113
Validation loss: 2.0110656471662622

Epoch: 563| Step: 0
Training loss: 1.6147445440292358
Validation loss: 2.0495746891985656

Epoch: 5| Step: 1
Training loss: 1.3207274675369263
Validation loss: 2.09255374247028

Epoch: 5| Step: 2
Training loss: 1.7104034423828125
Validation loss: 2.0508854876282396

Epoch: 5| Step: 3
Training loss: 1.4282039403915405
Validation loss: 2.1013440137268393

Epoch: 5| Step: 4
Training loss: 1.567486047744751
Validation loss: 1.9851593471342517

Epoch: 5| Step: 5
Training loss: 1.696096658706665
Validation loss: 2.085042852227406

Epoch: 5| Step: 6
Training loss: 2.0001282691955566
Validation loss: 2.1062253546971146

Epoch: 5| Step: 7
Training loss: 1.5081671476364136
Validation loss: 2.0546674164392615

Epoch: 5| Step: 8
Training loss: 1.6313081979751587
Validation loss: 2.0599130712529665

Epoch: 5| Step: 9
Training loss: 1.4622331857681274
Validation loss: 2.061703787055067

Epoch: 5| Step: 10
Training loss: 1.2496554851531982
Validation loss: 2.1396130413137455

Epoch: 564| Step: 0
Training loss: 1.7110248804092407
Validation loss: 2.027702785307361

Epoch: 5| Step: 1
Training loss: 1.2349627017974854
Validation loss: 1.9851549748451478

Epoch: 5| Step: 2
Training loss: 1.5800671577453613
Validation loss: 2.0019632372804868

Epoch: 5| Step: 3
Training loss: 1.6242948770523071
Validation loss: 2.0768171792389243

Epoch: 5| Step: 4
Training loss: 1.3246757984161377
Validation loss: 2.102808916440574

Epoch: 5| Step: 5
Training loss: 1.4860925674438477
Validation loss: 1.943959500200005

Epoch: 5| Step: 6
Training loss: 1.4644883871078491
Validation loss: 2.075301718968217

Epoch: 5| Step: 7
Training loss: 2.253629684448242
Validation loss: 2.020768988517023

Epoch: 5| Step: 8
Training loss: 1.0199288129806519
Validation loss: 1.975086022448796

Epoch: 5| Step: 9
Training loss: 1.5812937021255493
Validation loss: 2.0359191561257965

Epoch: 5| Step: 10
Training loss: 1.551777958869934
Validation loss: 2.0166909835671865

Epoch: 565| Step: 0
Training loss: 1.619635820388794
Validation loss: 1.9908331081431399

Epoch: 5| Step: 1
Training loss: 1.4195959568023682
Validation loss: 2.0295084061161166

Epoch: 5| Step: 2
Training loss: 1.557108998298645
Validation loss: 2.0947592617363058

Epoch: 5| Step: 3
Training loss: 1.8227592706680298
Validation loss: 1.9745350935125863

Epoch: 5| Step: 4
Training loss: 1.6080372333526611
Validation loss: 2.004422059623144

Epoch: 5| Step: 5
Training loss: 1.5295988321304321
Validation loss: 2.041506093035462

Epoch: 5| Step: 6
Training loss: 1.6890217065811157
Validation loss: 2.0477710359839985

Epoch: 5| Step: 7
Training loss: 1.342113733291626
Validation loss: 2.039796708732523

Epoch: 5| Step: 8
Training loss: 1.9155442714691162
Validation loss: 2.0238285013424453

Epoch: 5| Step: 9
Training loss: 1.244795560836792
Validation loss: 2.0687276496682117

Epoch: 5| Step: 10
Training loss: 0.9265428781509399
Validation loss: 2.072070663975131

Epoch: 566| Step: 0
Training loss: 1.2493703365325928
Validation loss: 2.0882915309680405

Epoch: 5| Step: 1
Training loss: 1.4300496578216553
Validation loss: 2.1542820238297984

Epoch: 5| Step: 2
Training loss: 1.290652871131897
Validation loss: 2.0378606063063427

Epoch: 5| Step: 3
Training loss: 1.8333734273910522
Validation loss: 2.103942886475594

Epoch: 5| Step: 4
Training loss: 1.8524976968765259
Validation loss: 2.1043219540708806

Epoch: 5| Step: 5
Training loss: 1.542779564857483
Validation loss: 2.088091413180033

Epoch: 5| Step: 6
Training loss: 1.9316627979278564
Validation loss: 2.0846088073586904

Epoch: 5| Step: 7
Training loss: 1.389333963394165
Validation loss: 2.109761327825567

Epoch: 5| Step: 8
Training loss: 1.2747994661331177
Validation loss: 2.106807480576218

Epoch: 5| Step: 9
Training loss: 1.5678234100341797
Validation loss: 2.0128872625289427

Epoch: 5| Step: 10
Training loss: 1.6242958307266235
Validation loss: 2.041198426677335

Epoch: 567| Step: 0
Training loss: 1.3360294103622437
Validation loss: 2.1036615948523245

Epoch: 5| Step: 1
Training loss: 1.3257778882980347
Validation loss: 2.0526454423063543

Epoch: 5| Step: 2
Training loss: 1.8646554946899414
Validation loss: 2.013979650312854

Epoch: 5| Step: 3
Training loss: 1.4973421096801758
Validation loss: 1.9322356485551404

Epoch: 5| Step: 4
Training loss: 1.604454755783081
Validation loss: 2.0078557178538334

Epoch: 5| Step: 5
Training loss: 1.7249149084091187
Validation loss: 2.0469043139488465

Epoch: 5| Step: 6
Training loss: 1.7458457946777344
Validation loss: 2.0349780282666607

Epoch: 5| Step: 7
Training loss: 1.288027048110962
Validation loss: 2.1174840491305114

Epoch: 5| Step: 8
Training loss: 1.1983665227890015
Validation loss: 2.0471131160695064

Epoch: 5| Step: 9
Training loss: 1.230626106262207
Validation loss: 2.0393153916123095

Epoch: 5| Step: 10
Training loss: 2.451847791671753
Validation loss: 2.0315322452975857

Epoch: 568| Step: 0
Training loss: 1.5698916912078857
Validation loss: 2.145904071869389

Epoch: 5| Step: 1
Training loss: 1.0631253719329834
Validation loss: 2.0034297018922786

Epoch: 5| Step: 2
Training loss: 1.5152746438980103
Validation loss: 2.008343868358161

Epoch: 5| Step: 3
Training loss: 1.9674606323242188
Validation loss: 2.0765133596235708

Epoch: 5| Step: 4
Training loss: 2.004162549972534
Validation loss: 2.109865535971939

Epoch: 5| Step: 5
Training loss: 1.6498597860336304
Validation loss: 2.143592373017342

Epoch: 5| Step: 6
Training loss: 1.5799943208694458
Validation loss: 2.042703761849352

Epoch: 5| Step: 7
Training loss: 1.3240786790847778
Validation loss: 2.071872092062427

Epoch: 5| Step: 8
Training loss: 1.199324131011963
Validation loss: 2.1231064591356503

Epoch: 5| Step: 9
Training loss: 1.5491673946380615
Validation loss: 2.0523655568399737

Epoch: 5| Step: 10
Training loss: 1.7061471939086914
Validation loss: 2.137258618108688

Epoch: 569| Step: 0
Training loss: 2.046903133392334
Validation loss: 2.125240091354616

Epoch: 5| Step: 1
Training loss: 1.4219727516174316
Validation loss: 2.0639640797850904

Epoch: 5| Step: 2
Training loss: 1.0038766860961914
Validation loss: 2.1017587415633665

Epoch: 5| Step: 3
Training loss: 1.7521638870239258
Validation loss: 2.0442528135033062

Epoch: 5| Step: 4
Training loss: 1.2211811542510986
Validation loss: 2.014612918258995

Epoch: 5| Step: 5
Training loss: 1.8346256017684937
Validation loss: 2.0007538987744238

Epoch: 5| Step: 6
Training loss: 1.1364781856536865
Validation loss: 2.082087965421779

Epoch: 5| Step: 7
Training loss: 1.950758695602417
Validation loss: 2.0394443901636268

Epoch: 5| Step: 8
Training loss: 1.6093482971191406
Validation loss: 2.014786053729314

Epoch: 5| Step: 9
Training loss: 1.8240944147109985
Validation loss: 2.0549617941661547

Epoch: 5| Step: 10
Training loss: 1.384333610534668
Validation loss: 2.025631503392291

Epoch: 570| Step: 0
Training loss: 1.5271803140640259
Validation loss: 1.9537231101784656

Epoch: 5| Step: 1
Training loss: 1.1136009693145752
Validation loss: 2.042438450679984

Epoch: 5| Step: 2
Training loss: 1.7152726650238037
Validation loss: 2.0416414378791727

Epoch: 5| Step: 3
Training loss: 1.6948487758636475
Validation loss: 1.9613695298471758

Epoch: 5| Step: 4
Training loss: 1.848205804824829
Validation loss: 1.9668092138023787

Epoch: 5| Step: 5
Training loss: 1.616328239440918
Validation loss: 2.0166240174283265

Epoch: 5| Step: 6
Training loss: 1.9187676906585693
Validation loss: 2.0852456503016974

Epoch: 5| Step: 7
Training loss: 2.086644411087036
Validation loss: 2.0716523919054257

Epoch: 5| Step: 8
Training loss: 1.0854812860488892
Validation loss: 2.082952904444869

Epoch: 5| Step: 9
Training loss: 1.524190902709961
Validation loss: 2.0578254922743766

Epoch: 5| Step: 10
Training loss: 1.0155508518218994
Validation loss: 2.04455227492958

Epoch: 571| Step: 0
Training loss: 1.0533668994903564
Validation loss: 2.0864778757095337

Epoch: 5| Step: 1
Training loss: 1.377510666847229
Validation loss: 2.0770571488206104

Epoch: 5| Step: 2
Training loss: 1.9258801937103271
Validation loss: 2.0644872393659366

Epoch: 5| Step: 3
Training loss: 1.4349790811538696
Validation loss: 2.0768495349473852

Epoch: 5| Step: 4
Training loss: 1.4877561330795288
Validation loss: 2.104361921228388

Epoch: 5| Step: 5
Training loss: 1.283684492111206
Validation loss: 2.0275025239554783

Epoch: 5| Step: 6
Training loss: 1.6678969860076904
Validation loss: 2.0281332231337026

Epoch: 5| Step: 7
Training loss: 1.7393925189971924
Validation loss: 2.034698356864273

Epoch: 5| Step: 8
Training loss: 1.5394471883773804
Validation loss: 2.002927444314444

Epoch: 5| Step: 9
Training loss: 1.9333702325820923
Validation loss: 2.031834957420185

Epoch: 5| Step: 10
Training loss: 1.7963082790374756
Validation loss: 2.0197822381091375

Epoch: 572| Step: 0
Training loss: 2.0550384521484375
Validation loss: 2.0586612019487607

Epoch: 5| Step: 1
Training loss: 2.242119550704956
Validation loss: 2.077260031495043

Epoch: 5| Step: 2
Training loss: 1.0665717124938965
Validation loss: 2.047286546358498

Epoch: 5| Step: 3
Training loss: 1.891073226928711
Validation loss: 2.07553663305057

Epoch: 5| Step: 4
Training loss: 1.238297700881958
Validation loss: 2.0301325833925636

Epoch: 5| Step: 5
Training loss: 1.3728402853012085
Validation loss: 2.0233837109740063

Epoch: 5| Step: 6
Training loss: 0.9868892431259155
Validation loss: 2.0982916585860716

Epoch: 5| Step: 7
Training loss: 1.2970411777496338
Validation loss: 2.044816663188319

Epoch: 5| Step: 8
Training loss: 1.77426278591156
Validation loss: 2.0738866559920774

Epoch: 5| Step: 9
Training loss: 1.3430095911026
Validation loss: 2.072344195458197

Epoch: 5| Step: 10
Training loss: 1.3918098211288452
Validation loss: 2.0732130747969433

Epoch: 573| Step: 0
Training loss: 2.0588228702545166
Validation loss: 2.0594504187183995

Epoch: 5| Step: 1
Training loss: 1.0174404382705688
Validation loss: 1.9947785177538473

Epoch: 5| Step: 2
Training loss: 0.9600203633308411
Validation loss: 2.061540977929228

Epoch: 5| Step: 3
Training loss: 1.912607192993164
Validation loss: 2.0422741059334046

Epoch: 5| Step: 4
Training loss: 1.3310165405273438
Validation loss: 2.0867890452825897

Epoch: 5| Step: 5
Training loss: 1.35647451877594
Validation loss: 2.001336269481208

Epoch: 5| Step: 6
Training loss: 1.0495487451553345
Validation loss: 1.9947110478596022

Epoch: 5| Step: 7
Training loss: 1.3124769926071167
Validation loss: 1.9797603302104498

Epoch: 5| Step: 8
Training loss: 2.2308833599090576
Validation loss: 2.0368109749209498

Epoch: 5| Step: 9
Training loss: 1.862683892250061
Validation loss: 2.07677992825867

Epoch: 5| Step: 10
Training loss: 1.346741795539856
Validation loss: 2.052038856731948

Epoch: 574| Step: 0
Training loss: 1.4598026275634766
Validation loss: 2.0904172107737553

Epoch: 5| Step: 1
Training loss: 1.5765262842178345
Validation loss: 2.034797304420061

Epoch: 5| Step: 2
Training loss: 1.4128291606903076
Validation loss: 2.02451414703041

Epoch: 5| Step: 3
Training loss: 1.5598381757736206
Validation loss: 2.0734005538366174

Epoch: 5| Step: 4
Training loss: 1.6728595495224
Validation loss: 2.087565058021135

Epoch: 5| Step: 5
Training loss: 1.5232610702514648
Validation loss: 2.0673810897334928

Epoch: 5| Step: 6
Training loss: 1.2166073322296143
Validation loss: 1.9554456126305364

Epoch: 5| Step: 7
Training loss: 1.1196256875991821
Validation loss: 2.0570963300684446

Epoch: 5| Step: 8
Training loss: 1.4824068546295166
Validation loss: 2.010018999858569

Epoch: 5| Step: 9
Training loss: 2.391573429107666
Validation loss: 1.9987541065421155

Epoch: 5| Step: 10
Training loss: 1.1592810153961182
Validation loss: 2.0776322426334506

Epoch: 575| Step: 0
Training loss: 1.3374056816101074
Validation loss: 2.0244021672074513

Epoch: 5| Step: 1
Training loss: 1.4339416027069092
Validation loss: 2.0079035784608577

Epoch: 5| Step: 2
Training loss: 1.4111849069595337
Validation loss: 1.9932015172896846

Epoch: 5| Step: 3
Training loss: 1.7846050262451172
Validation loss: 2.124108027386409

Epoch: 5| Step: 4
Training loss: 1.556391954421997
Validation loss: 1.963826330759192

Epoch: 5| Step: 5
Training loss: 1.533810019493103
Validation loss: 2.041096338661768

Epoch: 5| Step: 6
Training loss: 1.1970384120941162
Validation loss: 2.0730290182175173

Epoch: 5| Step: 7
Training loss: 1.6610515117645264
Validation loss: 2.05062650480578

Epoch: 5| Step: 8
Training loss: 1.2568988800048828
Validation loss: 2.078144907951355

Epoch: 5| Step: 9
Training loss: 1.910488486289978
Validation loss: 2.0251033947031987

Epoch: 5| Step: 10
Training loss: 1.359470009803772
Validation loss: 2.036039178089429

Epoch: 576| Step: 0
Training loss: 1.5344804525375366
Validation loss: 2.0772784602257515

Epoch: 5| Step: 1
Training loss: 1.105914831161499
Validation loss: 2.0085464318593345

Epoch: 5| Step: 2
Training loss: 1.82648503780365
Validation loss: 2.0187725046629548

Epoch: 5| Step: 3
Training loss: 1.261650562286377
Validation loss: 2.0025941607772664

Epoch: 5| Step: 4
Training loss: 1.8224480152130127
Validation loss: 2.1074406203403266

Epoch: 5| Step: 5
Training loss: 1.3778457641601562
Validation loss: 2.003681849407893

Epoch: 5| Step: 6
Training loss: 1.9564945697784424
Validation loss: 1.999834705424565

Epoch: 5| Step: 7
Training loss: 1.3452686071395874
Validation loss: 2.002175787443756

Epoch: 5| Step: 8
Training loss: 1.6157169342041016
Validation loss: 2.017054375781808

Epoch: 5| Step: 9
Training loss: 1.4145609140396118
Validation loss: 2.0200667317195604

Epoch: 5| Step: 10
Training loss: 1.5573232173919678
Validation loss: 1.9992160079299763

Epoch: 577| Step: 0
Training loss: 0.7616328597068787
Validation loss: 2.0537775537019134

Epoch: 5| Step: 1
Training loss: 1.2004482746124268
Validation loss: 2.070244522504909

Epoch: 5| Step: 2
Training loss: 1.074798345565796
Validation loss: 2.1176168046971804

Epoch: 5| Step: 3
Training loss: 1.6965774297714233
Validation loss: 2.047468481525298

Epoch: 5| Step: 4
Training loss: 0.9825844764709473
Validation loss: 2.0527229796173754

Epoch: 5| Step: 5
Training loss: 1.9814592599868774
Validation loss: 2.0446173221834245

Epoch: 5| Step: 6
Training loss: 1.6929218769073486
Validation loss: 2.0045202342412805

Epoch: 5| Step: 7
Training loss: 1.504927635192871
Validation loss: 2.0527103870145735

Epoch: 5| Step: 8
Training loss: 1.69918954372406
Validation loss: 2.0662637602898384

Epoch: 5| Step: 9
Training loss: 2.3012404441833496
Validation loss: 2.068296581186274

Epoch: 5| Step: 10
Training loss: 1.6778082847595215
Validation loss: 1.9896975101963166

Epoch: 578| Step: 0
Training loss: 1.9748964309692383
Validation loss: 2.011119459265022

Epoch: 5| Step: 1
Training loss: 1.2810990810394287
Validation loss: 2.0088788514496176

Epoch: 5| Step: 2
Training loss: 1.7080869674682617
Validation loss: 2.0481973668580413

Epoch: 5| Step: 3
Training loss: 2.0725135803222656
Validation loss: 2.042506843484858

Epoch: 5| Step: 4
Training loss: 1.358947992324829
Validation loss: 1.9958075515685543

Epoch: 5| Step: 5
Training loss: 1.3171647787094116
Validation loss: 2.0900019625181794

Epoch: 5| Step: 6
Training loss: 1.1991875171661377
Validation loss: 2.021514779777937

Epoch: 5| Step: 7
Training loss: 1.73758864402771
Validation loss: 2.021822275653962

Epoch: 5| Step: 8
Training loss: 1.30062997341156
Validation loss: 2.049173024392897

Epoch: 5| Step: 9
Training loss: 1.1270025968551636
Validation loss: 2.026994582145445

Epoch: 5| Step: 10
Training loss: 1.128415822982788
Validation loss: 2.0716885212929017

Epoch: 579| Step: 0
Training loss: 1.428977608680725
Validation loss: 2.0120200508384296

Epoch: 5| Step: 1
Training loss: 1.5482038259506226
Validation loss: 2.0179848222322363

Epoch: 5| Step: 2
Training loss: 1.7257665395736694
Validation loss: 2.0443153740257345

Epoch: 5| Step: 3
Training loss: 1.3823928833007812
Validation loss: 2.0594947568831907

Epoch: 5| Step: 4
Training loss: 1.2910646200180054
Validation loss: 2.0308164755503335

Epoch: 5| Step: 5
Training loss: 1.695155382156372
Validation loss: 2.0104722105046755

Epoch: 5| Step: 6
Training loss: 1.4114350080490112
Validation loss: 2.0104491800390263

Epoch: 5| Step: 7
Training loss: 1.916254997253418
Validation loss: 2.07907550309294

Epoch: 5| Step: 8
Training loss: 1.6019302606582642
Validation loss: 2.0228338779941684

Epoch: 5| Step: 9
Training loss: 1.246567964553833
Validation loss: 2.0637264815709924

Epoch: 5| Step: 10
Training loss: 1.385387659072876
Validation loss: 2.06396399774859

Epoch: 580| Step: 0
Training loss: 1.3000136613845825
Validation loss: 2.013008418903556

Epoch: 5| Step: 1
Training loss: 1.9042574167251587
Validation loss: 1.98471862013622

Epoch: 5| Step: 2
Training loss: 1.3093637228012085
Validation loss: 2.007920757416756

Epoch: 5| Step: 3
Training loss: 1.3448841571807861
Validation loss: 1.9944933332422727

Epoch: 5| Step: 4
Training loss: 0.9492863416671753
Validation loss: 2.0538075547064505

Epoch: 5| Step: 5
Training loss: 1.3726285696029663
Validation loss: 2.0623821109853764

Epoch: 5| Step: 6
Training loss: 1.8078105449676514
Validation loss: 2.057978291665354

Epoch: 5| Step: 7
Training loss: 2.0533604621887207
Validation loss: 2.0910127880752727

Epoch: 5| Step: 8
Training loss: 2.2959423065185547
Validation loss: 2.068382073474187

Epoch: 5| Step: 9
Training loss: 1.272747278213501
Validation loss: 2.0310365897352978

Epoch: 5| Step: 10
Training loss: 0.9892857670783997
Validation loss: 2.1102886687042894

Epoch: 581| Step: 0
Training loss: 1.6107616424560547
Validation loss: 1.9952797966618692

Epoch: 5| Step: 1
Training loss: 1.4559932947158813
Validation loss: 2.0288376167256343

Epoch: 5| Step: 2
Training loss: 1.0987557172775269
Validation loss: 2.046331472294305

Epoch: 5| Step: 3
Training loss: 1.6005589962005615
Validation loss: 2.0683461081597114

Epoch: 5| Step: 4
Training loss: 1.5660678148269653
Validation loss: 2.069439635481886

Epoch: 5| Step: 5
Training loss: 1.7951533794403076
Validation loss: 1.967758426102259

Epoch: 5| Step: 6
Training loss: 1.081290602684021
Validation loss: 2.0710574606413483

Epoch: 5| Step: 7
Training loss: 1.5252916812896729
Validation loss: 2.08126808879196

Epoch: 5| Step: 8
Training loss: 1.410510778427124
Validation loss: 2.0284494328242477

Epoch: 5| Step: 9
Training loss: 2.273247003555298
Validation loss: 2.0793558551419165

Epoch: 5| Step: 10
Training loss: 1.4171009063720703
Validation loss: 2.086137394751272

Epoch: 582| Step: 0
Training loss: 1.4650994539260864
Validation loss: 2.0186852998630975

Epoch: 5| Step: 1
Training loss: 1.3664138317108154
Validation loss: 2.0437005540376068

Epoch: 5| Step: 2
Training loss: 1.0037939548492432
Validation loss: 2.0433811731235956

Epoch: 5| Step: 3
Training loss: 1.4211561679840088
Validation loss: 2.045921156483312

Epoch: 5| Step: 4
Training loss: 1.3344926834106445
Validation loss: 2.069917168668521

Epoch: 5| Step: 5
Training loss: 1.6899969577789307
Validation loss: 2.0386572345610587

Epoch: 5| Step: 6
Training loss: 1.2443703413009644
Validation loss: 2.0421718294902513

Epoch: 5| Step: 7
Training loss: 1.4946660995483398
Validation loss: 2.0269430119504213

Epoch: 5| Step: 8
Training loss: 1.7772266864776611
Validation loss: 2.0085879064375356

Epoch: 5| Step: 9
Training loss: 1.9420311450958252
Validation loss: 2.055504127215314

Epoch: 5| Step: 10
Training loss: 1.6231982707977295
Validation loss: 2.04127489366839

Epoch: 583| Step: 0
Training loss: 1.3254159688949585
Validation loss: 2.0887289329241683

Epoch: 5| Step: 1
Training loss: 1.3318252563476562
Validation loss: 2.088069510716264

Epoch: 5| Step: 2
Training loss: 1.2845829725265503
Validation loss: 2.0770733894840365

Epoch: 5| Step: 3
Training loss: 1.4525617361068726
Validation loss: 2.0621501809807232

Epoch: 5| Step: 4
Training loss: 1.4218063354492188
Validation loss: 2.0683772538297918

Epoch: 5| Step: 5
Training loss: 1.881714105606079
Validation loss: 2.1007363616779284

Epoch: 5| Step: 6
Training loss: 2.13215970993042
Validation loss: 2.079252753206479

Epoch: 5| Step: 7
Training loss: 1.4986553192138672
Validation loss: 2.0056454468798894

Epoch: 5| Step: 8
Training loss: 1.5346511602401733
Validation loss: 2.15325564722861

Epoch: 5| Step: 9
Training loss: 1.739648461341858
Validation loss: 1.9984198821488248

Epoch: 5| Step: 10
Training loss: 1.1362065076828003
Validation loss: 2.031470948649991

Epoch: 584| Step: 0
Training loss: 1.5648329257965088
Validation loss: 2.0517556244327175

Epoch: 5| Step: 1
Training loss: 1.7529773712158203
Validation loss: 2.0377666642588954

Epoch: 5| Step: 2
Training loss: 2.084129810333252
Validation loss: 2.0542074172727522

Epoch: 5| Step: 3
Training loss: 1.2349607944488525
Validation loss: 1.9754719734191895

Epoch: 5| Step: 4
Training loss: 1.4312121868133545
Validation loss: 2.0939119554335073

Epoch: 5| Step: 5
Training loss: 1.7868999242782593
Validation loss: 2.004678867196524

Epoch: 5| Step: 6
Training loss: 1.269935965538025
Validation loss: 2.0275873227785994

Epoch: 5| Step: 7
Training loss: 1.0081546306610107
Validation loss: 2.0039814415798394

Epoch: 5| Step: 8
Training loss: 0.9632924795150757
Validation loss: 2.1211092587440246

Epoch: 5| Step: 9
Training loss: 1.8082739114761353
Validation loss: 2.045050308268557

Epoch: 5| Step: 10
Training loss: 1.6008402109146118
Validation loss: 1.986750700140512

Epoch: 585| Step: 0
Training loss: 1.909828543663025
Validation loss: 2.046172272774481

Epoch: 5| Step: 1
Training loss: 1.7780945301055908
Validation loss: 1.970551149819487

Epoch: 5| Step: 2
Training loss: 1.8669633865356445
Validation loss: 2.0453244780981414

Epoch: 5| Step: 3
Training loss: 1.4185129404067993
Validation loss: 2.0624296537009617

Epoch: 5| Step: 4
Training loss: 1.5810271501541138
Validation loss: 2.0139039870231383

Epoch: 5| Step: 5
Training loss: 1.3181874752044678
Validation loss: 2.0644833144321235

Epoch: 5| Step: 6
Training loss: 1.0162023305892944
Validation loss: 2.095695544314641

Epoch: 5| Step: 7
Training loss: 1.2970033884048462
Validation loss: 2.048694802868751

Epoch: 5| Step: 8
Training loss: 1.3089630603790283
Validation loss: 2.031440752808766

Epoch: 5| Step: 9
Training loss: 1.6659557819366455
Validation loss: 2.0320683294726956

Epoch: 5| Step: 10
Training loss: 1.4801874160766602
Validation loss: 2.0273373178256455

Epoch: 586| Step: 0
Training loss: 1.277868390083313
Validation loss: 2.001673913771106

Epoch: 5| Step: 1
Training loss: 1.3280961513519287
Validation loss: 2.022100992100213

Epoch: 5| Step: 2
Training loss: 1.327750325202942
Validation loss: 2.017981465144824

Epoch: 5| Step: 3
Training loss: 1.5150766372680664
Validation loss: 2.0159022820893155

Epoch: 5| Step: 4
Training loss: 1.7433017492294312
Validation loss: 2.0205039337117183

Epoch: 5| Step: 5
Training loss: 1.6996217966079712
Validation loss: 2.0603605111440024

Epoch: 5| Step: 6
Training loss: 1.4265239238739014
Validation loss: 2.0930741525465444

Epoch: 5| Step: 7
Training loss: 1.6162410974502563
Validation loss: 2.0299466040826615

Epoch: 5| Step: 8
Training loss: 1.0203664302825928
Validation loss: 2.079148136159425

Epoch: 5| Step: 9
Training loss: 1.634299635887146
Validation loss: 1.9777949702355169

Epoch: 5| Step: 10
Training loss: 1.618238925933838
Validation loss: 2.069148653297014

Epoch: 587| Step: 0
Training loss: 1.2990424633026123
Validation loss: 2.0240756157905824

Epoch: 5| Step: 1
Training loss: 1.4791600704193115
Validation loss: 2.0551540210682857

Epoch: 5| Step: 2
Training loss: 0.9427887201309204
Validation loss: 2.066563908771802

Epoch: 5| Step: 3
Training loss: 2.2722067832946777
Validation loss: 2.0558458425665416

Epoch: 5| Step: 4
Training loss: 1.1767351627349854
Validation loss: 2.033831880938622

Epoch: 5| Step: 5
Training loss: 1.629486083984375
Validation loss: 2.0617290260971233

Epoch: 5| Step: 6
Training loss: 1.8191659450531006
Validation loss: 2.0528265096807994

Epoch: 5| Step: 7
Training loss: 1.4442030191421509
Validation loss: 1.9899706263695993

Epoch: 5| Step: 8
Training loss: 1.3850994110107422
Validation loss: 1.9460608651561122

Epoch: 5| Step: 9
Training loss: 1.4362602233886719
Validation loss: 2.0597249846304617

Epoch: 5| Step: 10
Training loss: 1.9846835136413574
Validation loss: 2.0515330747891496

Epoch: 588| Step: 0
Training loss: 1.3465983867645264
Validation loss: 2.0786400610400784

Epoch: 5| Step: 1
Training loss: 0.7115170359611511
Validation loss: 2.0271408378437

Epoch: 5| Step: 2
Training loss: 1.6907304525375366
Validation loss: 2.0540162004450315

Epoch: 5| Step: 3
Training loss: 1.8059959411621094
Validation loss: 2.0499195565459547

Epoch: 5| Step: 4
Training loss: 1.8681758642196655
Validation loss: 1.9835678146731468

Epoch: 5| Step: 5
Training loss: 1.3092172145843506
Validation loss: 2.038640845206476

Epoch: 5| Step: 6
Training loss: 1.6164436340332031
Validation loss: 2.1138243585504513

Epoch: 5| Step: 7
Training loss: 1.6130702495574951
Validation loss: 2.0502245733814854

Epoch: 5| Step: 8
Training loss: 1.188646912574768
Validation loss: 2.0060314529685566

Epoch: 5| Step: 9
Training loss: 1.9305734634399414
Validation loss: 2.0451512208548923

Epoch: 5| Step: 10
Training loss: 1.134535789489746
Validation loss: 2.017995108840286

Epoch: 589| Step: 0
Training loss: 1.674338936805725
Validation loss: 2.0040836052228044

Epoch: 5| Step: 1
Training loss: 1.649570107460022
Validation loss: 1.9796564707192041

Epoch: 5| Step: 2
Training loss: 1.2237837314605713
Validation loss: 2.0657328008323588

Epoch: 5| Step: 3
Training loss: 1.5744799375534058
Validation loss: 2.0695139579875494

Epoch: 5| Step: 4
Training loss: 1.5623369216918945
Validation loss: 2.0023350831001037

Epoch: 5| Step: 5
Training loss: 1.4556111097335815
Validation loss: 2.02103522259702

Epoch: 5| Step: 6
Training loss: 1.757270097732544
Validation loss: 2.0419416273793867

Epoch: 5| Step: 7
Training loss: 1.2058652639389038
Validation loss: 1.998393476650279

Epoch: 5| Step: 8
Training loss: 0.9654184579849243
Validation loss: 2.007807159936556

Epoch: 5| Step: 9
Training loss: 1.8370723724365234
Validation loss: 2.067570709413098

Epoch: 5| Step: 10
Training loss: 1.4705078601837158
Validation loss: 2.0024991471280336

Epoch: 590| Step: 0
Training loss: 1.8341424465179443
Validation loss: 2.040259534312833

Epoch: 5| Step: 1
Training loss: 1.6114838123321533
Validation loss: 2.0722981063268517

Epoch: 5| Step: 2
Training loss: 1.5331634283065796
Validation loss: 2.0789066104478735

Epoch: 5| Step: 3
Training loss: 1.5832362174987793
Validation loss: 2.092625812817645

Epoch: 5| Step: 4
Training loss: 1.696463942527771
Validation loss: 2.007618147839782

Epoch: 5| Step: 5
Training loss: 0.9714897871017456
Validation loss: 2.008484932684129

Epoch: 5| Step: 6
Training loss: 1.2619456052780151
Validation loss: 2.078466051368303

Epoch: 5| Step: 7
Training loss: 1.277202844619751
Validation loss: 2.047296670175368

Epoch: 5| Step: 8
Training loss: 0.9245807528495789
Validation loss: 2.0649469334592103

Epoch: 5| Step: 9
Training loss: 1.9135017395019531
Validation loss: 2.05061742823611

Epoch: 5| Step: 10
Training loss: 1.8609731197357178
Validation loss: 2.0585508987467778

Epoch: 591| Step: 0
Training loss: 1.418096899986267
Validation loss: 2.0766949986898773

Epoch: 5| Step: 1
Training loss: 1.5870206356048584
Validation loss: 2.0336978179152294

Epoch: 5| Step: 2
Training loss: 1.124321699142456
Validation loss: 2.0842246291457966

Epoch: 5| Step: 3
Training loss: 0.9582538604736328
Validation loss: 2.104142253116895

Epoch: 5| Step: 4
Training loss: 1.5636706352233887
Validation loss: 2.0619761456725416

Epoch: 5| Step: 5
Training loss: 1.29287588596344
Validation loss: 2.0969466137629684

Epoch: 5| Step: 6
Training loss: 2.174309730529785
Validation loss: 2.0861590549510014

Epoch: 5| Step: 7
Training loss: 1.3750522136688232
Validation loss: 2.089062257479596

Epoch: 5| Step: 8
Training loss: 2.072869062423706
Validation loss: 2.06079601728788

Epoch: 5| Step: 9
Training loss: 1.4402918815612793
Validation loss: 2.0380419761903825

Epoch: 5| Step: 10
Training loss: 1.583814263343811
Validation loss: 2.0617013938965334

Epoch: 592| Step: 0
Training loss: 2.0382556915283203
Validation loss: 2.016041230129939

Epoch: 5| Step: 1
Training loss: 1.9882276058197021
Validation loss: 2.054269325348639

Epoch: 5| Step: 2
Training loss: 1.2581297159194946
Validation loss: 2.0255375523721018

Epoch: 5| Step: 3
Training loss: 1.8415206670761108
Validation loss: 2.0600483289328952

Epoch: 5| Step: 4
Training loss: 1.312744140625
Validation loss: 2.0689016824127524

Epoch: 5| Step: 5
Training loss: 0.981425404548645
Validation loss: 2.061216018533194

Epoch: 5| Step: 6
Training loss: 1.574183702468872
Validation loss: 2.080002587328675

Epoch: 5| Step: 7
Training loss: 0.90660560131073
Validation loss: 2.070047273430773

Epoch: 5| Step: 8
Training loss: 1.1261625289916992
Validation loss: 2.1006642644123366

Epoch: 5| Step: 9
Training loss: 1.4871265888214111
Validation loss: 2.0476161382531606

Epoch: 5| Step: 10
Training loss: 2.215566873550415
Validation loss: 1.989461939821961

Epoch: 593| Step: 0
Training loss: 1.5976450443267822
Validation loss: 2.0186066730048067

Epoch: 5| Step: 1
Training loss: 1.4878756999969482
Validation loss: 1.996518281198317

Epoch: 5| Step: 2
Training loss: 1.2033671140670776
Validation loss: 2.044756095896485

Epoch: 5| Step: 3
Training loss: 1.4384329319000244
Validation loss: 2.0119494417662263

Epoch: 5| Step: 4
Training loss: 1.3029468059539795
Validation loss: 2.016969533376796

Epoch: 5| Step: 5
Training loss: 1.581813097000122
Validation loss: 1.9456703534690283

Epoch: 5| Step: 6
Training loss: 1.2601629495620728
Validation loss: 2.0009765445545153

Epoch: 5| Step: 7
Training loss: 1.6034075021743774
Validation loss: 2.0229312425018637

Epoch: 5| Step: 8
Training loss: 1.5274993181228638
Validation loss: 2.034070437954318

Epoch: 5| Step: 9
Training loss: 1.4227385520935059
Validation loss: 2.011059479046893

Epoch: 5| Step: 10
Training loss: 2.52146053314209
Validation loss: 2.0672862709209485

Epoch: 594| Step: 0
Training loss: 1.0911221504211426
Validation loss: 2.0425009906932874

Epoch: 5| Step: 1
Training loss: 1.7225732803344727
Validation loss: 2.031043647437967

Epoch: 5| Step: 2
Training loss: 1.1653902530670166
Validation loss: 2.0274955893075592

Epoch: 5| Step: 3
Training loss: 0.9151571989059448
Validation loss: 2.0676429745971516

Epoch: 5| Step: 4
Training loss: 1.953722596168518
Validation loss: 2.048625458953201

Epoch: 5| Step: 5
Training loss: 1.2380335330963135
Validation loss: 2.044650040647035

Epoch: 5| Step: 6
Training loss: 1.7405885457992554
Validation loss: 2.0801989109285417

Epoch: 5| Step: 7
Training loss: 2.525822877883911
Validation loss: 2.11173721795441

Epoch: 5| Step: 8
Training loss: 1.908715009689331
Validation loss: 2.0902988167219263

Epoch: 5| Step: 9
Training loss: 1.2647377252578735
Validation loss: 2.0560171168337584

Epoch: 5| Step: 10
Training loss: 0.7549845576286316
Validation loss: 2.0359053893755843

Epoch: 595| Step: 0
Training loss: 1.381339430809021
Validation loss: 2.071161811069776

Epoch: 5| Step: 1
Training loss: 1.5084073543548584
Validation loss: 2.039479237730785

Epoch: 5| Step: 2
Training loss: 1.741119384765625
Validation loss: 2.100950034715796

Epoch: 5| Step: 3
Training loss: 1.503648042678833
Validation loss: 2.0781859326106247

Epoch: 5| Step: 4
Training loss: 1.8784751892089844
Validation loss: 2.0026401012174544

Epoch: 5| Step: 5
Training loss: 1.544825553894043
Validation loss: 2.019889239341982

Epoch: 5| Step: 6
Training loss: 1.1267526149749756
Validation loss: 2.0549171509281283

Epoch: 5| Step: 7
Training loss: 1.124337911605835
Validation loss: 2.1059899342957364

Epoch: 5| Step: 8
Training loss: 1.5240997076034546
Validation loss: 2.044003709670036

Epoch: 5| Step: 9
Training loss: 1.0460190773010254
Validation loss: 2.0461127899026357

Epoch: 5| Step: 10
Training loss: 2.2481746673583984
Validation loss: 2.0880704566996586

Epoch: 596| Step: 0
Training loss: 1.2805938720703125
Validation loss: 2.1431622889734085

Epoch: 5| Step: 1
Training loss: 1.4430923461914062
Validation loss: 2.0542877463884253

Epoch: 5| Step: 2
Training loss: 1.2157484292984009
Validation loss: 2.030770388982629

Epoch: 5| Step: 3
Training loss: 2.025181770324707
Validation loss: 2.017565450360698

Epoch: 5| Step: 4
Training loss: 1.5489561557769775
Validation loss: 1.9685658921477616

Epoch: 5| Step: 5
Training loss: 0.8716413378715515
Validation loss: 1.9701704209850681

Epoch: 5| Step: 6
Training loss: 1.1922794580459595
Validation loss: 2.0396087592647922

Epoch: 5| Step: 7
Training loss: 1.6481029987335205
Validation loss: 2.02210114079137

Epoch: 5| Step: 8
Training loss: 1.508662462234497
Validation loss: 2.001549913037208

Epoch: 5| Step: 9
Training loss: 2.0534605979919434
Validation loss: 2.0193048369499946

Epoch: 5| Step: 10
Training loss: 1.505230188369751
Validation loss: 2.0491598831709994

Epoch: 597| Step: 0
Training loss: 1.578312635421753
Validation loss: 2.0794822336525045

Epoch: 5| Step: 1
Training loss: 0.8639823794364929
Validation loss: 2.067648337733361

Epoch: 5| Step: 2
Training loss: 1.7326977252960205
Validation loss: 2.0547797756810344

Epoch: 5| Step: 3
Training loss: 1.262768030166626
Validation loss: 2.049398091531569

Epoch: 5| Step: 4
Training loss: 1.4770889282226562
Validation loss: 2.0301810374823948

Epoch: 5| Step: 5
Training loss: 1.9773385524749756
Validation loss: 2.0134221007747035

Epoch: 5| Step: 6
Training loss: 1.7004276514053345
Validation loss: 2.1195083638673187

Epoch: 5| Step: 7
Training loss: 1.1308256387710571
Validation loss: 2.024388801666998

Epoch: 5| Step: 8
Training loss: 1.737701416015625
Validation loss: 2.012884506615259

Epoch: 5| Step: 9
Training loss: 1.5958491563796997
Validation loss: 1.9853734303546209

Epoch: 5| Step: 10
Training loss: 1.3314862251281738
Validation loss: 2.039152976005308

Epoch: 598| Step: 0
Training loss: 1.5971252918243408
Validation loss: 2.0195435170204408

Epoch: 5| Step: 1
Training loss: 1.142576813697815
Validation loss: 2.044595092855474

Epoch: 5| Step: 2
Training loss: 1.2441089153289795
Validation loss: 2.044808633865849

Epoch: 5| Step: 3
Training loss: 1.0514413118362427
Validation loss: 2.0422240136772074

Epoch: 5| Step: 4
Training loss: 1.3926092386245728
Validation loss: 2.092006826913485

Epoch: 5| Step: 5
Training loss: 1.3087091445922852
Validation loss: 2.0335556460965063

Epoch: 5| Step: 6
Training loss: 1.889931321144104
Validation loss: 1.9505381955895373

Epoch: 5| Step: 7
Training loss: 1.7044894695281982
Validation loss: 2.0257855640944613

Epoch: 5| Step: 8
Training loss: 1.6805245876312256
Validation loss: 2.022774229767502

Epoch: 5| Step: 9
Training loss: 1.502016544342041
Validation loss: 2.0196169396882415

Epoch: 5| Step: 10
Training loss: 1.1865487098693848
Validation loss: 1.9746507060143255

Epoch: 599| Step: 0
Training loss: 1.4925823211669922
Validation loss: 2.054893575688844

Epoch: 5| Step: 1
Training loss: 0.9697607755661011
Validation loss: 1.9938221798148206

Epoch: 5| Step: 2
Training loss: 0.8643317222595215
Validation loss: 2.0076333707378757

Epoch: 5| Step: 3
Training loss: 1.7632230520248413
Validation loss: 2.0379127712659937

Epoch: 5| Step: 4
Training loss: 1.4346463680267334
Validation loss: 2.0211226158244635

Epoch: 5| Step: 5
Training loss: 1.5674703121185303
Validation loss: 2.040015400096934

Epoch: 5| Step: 6
Training loss: 1.3706467151641846
Validation loss: 2.0679944689555834

Epoch: 5| Step: 7
Training loss: 1.7998939752578735
Validation loss: 2.1669380293097547

Epoch: 5| Step: 8
Training loss: 1.6720027923583984
Validation loss: 2.003069272605322

Epoch: 5| Step: 9
Training loss: 1.0383716821670532
Validation loss: 2.013869371465457

Epoch: 5| Step: 10
Training loss: 2.108642578125
Validation loss: 2.0655459793665076

Epoch: 600| Step: 0
Training loss: 1.3633151054382324
Validation loss: 2.0925556126461236

Epoch: 5| Step: 1
Training loss: 1.0416977405548096
Validation loss: 1.9868995322976062

Epoch: 5| Step: 2
Training loss: 1.268105149269104
Validation loss: 2.0466062022793676

Epoch: 5| Step: 3
Training loss: 1.7622747421264648
Validation loss: 1.9989380785214004

Epoch: 5| Step: 4
Training loss: 1.2839118242263794
Validation loss: 2.0636184446273313

Epoch: 5| Step: 5
Training loss: 2.348780393600464
Validation loss: 2.0466053652507004

Epoch: 5| Step: 6
Training loss: 1.3036080598831177
Validation loss: 2.0536584777216755

Epoch: 5| Step: 7
Training loss: 1.7117576599121094
Validation loss: 2.126991941082862

Epoch: 5| Step: 8
Training loss: 1.1856799125671387
Validation loss: 2.0835684473796556

Epoch: 5| Step: 9
Training loss: 0.85863196849823
Validation loss: 2.064388290528328

Epoch: 5| Step: 10
Training loss: 2.0031094551086426
Validation loss: 2.1007007116912515

Epoch: 601| Step: 0
Training loss: 1.645494818687439
Validation loss: 2.062546658259566

Epoch: 5| Step: 1
Training loss: 1.054260492324829
Validation loss: 1.9854751863787252

Epoch: 5| Step: 2
Training loss: 1.3301317691802979
Validation loss: 1.984010511829007

Epoch: 5| Step: 3
Training loss: 1.560936450958252
Validation loss: 2.0733430039498115

Epoch: 5| Step: 4
Training loss: 0.7315007448196411
Validation loss: 2.0728787222216205

Epoch: 5| Step: 5
Training loss: 2.123810291290283
Validation loss: 2.064703825981386

Epoch: 5| Step: 6
Training loss: 2.155493974685669
Validation loss: 1.999495001249416

Epoch: 5| Step: 7
Training loss: 1.3028875589370728
Validation loss: 2.1073647955412507

Epoch: 5| Step: 8
Training loss: 1.0889203548431396
Validation loss: 2.0770082525027695

Epoch: 5| Step: 9
Training loss: 1.5941479206085205
Validation loss: 1.9879656043103946

Epoch: 5| Step: 10
Training loss: 1.5180546045303345
Validation loss: 2.014293134853404

Epoch: 602| Step: 0
Training loss: 1.6401478052139282
Validation loss: 2.0570284602462605

Epoch: 5| Step: 1
Training loss: 1.112227439880371
Validation loss: 2.0846894069384505

Epoch: 5| Step: 2
Training loss: 1.607122778892517
Validation loss: 2.0495509998772734

Epoch: 5| Step: 3
Training loss: 1.3701536655426025
Validation loss: 2.034826442759524

Epoch: 5| Step: 4
Training loss: 1.2629014253616333
Validation loss: 2.037119896181168

Epoch: 5| Step: 5
Training loss: 1.0678248405456543
Validation loss: 2.0620453998606694

Epoch: 5| Step: 6
Training loss: 1.410737156867981
Validation loss: 2.0550411926802767

Epoch: 5| Step: 7
Training loss: 1.8503189086914062
Validation loss: 2.0503313541412354

Epoch: 5| Step: 8
Training loss: 1.701913833618164
Validation loss: 2.0808040621460124

Epoch: 5| Step: 9
Training loss: 2.024418354034424
Validation loss: 2.145752445344002

Epoch: 5| Step: 10
Training loss: 1.2656140327453613
Validation loss: 2.112369209207514

Epoch: 603| Step: 0
Training loss: 1.2324308156967163
Validation loss: 2.1117606983389905

Epoch: 5| Step: 1
Training loss: 0.9728204607963562
Validation loss: 2.0586719154029764

Epoch: 5| Step: 2
Training loss: 1.3974249362945557
Validation loss: 2.133998450412545

Epoch: 5| Step: 3
Training loss: 1.4953086376190186
Validation loss: 2.045848592635124

Epoch: 5| Step: 4
Training loss: 2.0010242462158203
Validation loss: 2.022935966009735

Epoch: 5| Step: 5
Training loss: 1.1451255083084106
Validation loss: 2.0243211292451426

Epoch: 5| Step: 6
Training loss: 1.088771104812622
Validation loss: 2.053199283538326

Epoch: 5| Step: 7
Training loss: 1.3470845222473145
Validation loss: 2.044182389013229

Epoch: 5| Step: 8
Training loss: 1.983987808227539
Validation loss: 2.055458236766118

Epoch: 5| Step: 9
Training loss: 1.7777817249298096
Validation loss: 1.9531583081009567

Epoch: 5| Step: 10
Training loss: 1.2738711833953857
Validation loss: 2.001031942265008

Epoch: 604| Step: 0
Training loss: 1.3043842315673828
Validation loss: 2.0398377615918397

Epoch: 5| Step: 1
Training loss: 1.6337244510650635
Validation loss: 2.028005406420718

Epoch: 5| Step: 2
Training loss: 1.0895694494247437
Validation loss: 1.9875001304893083

Epoch: 5| Step: 3
Training loss: 1.9804394245147705
Validation loss: 2.0741688794987176

Epoch: 5| Step: 4
Training loss: 1.155797004699707
Validation loss: 2.008803875215592

Epoch: 5| Step: 5
Training loss: 1.493349313735962
Validation loss: 2.119240883857973

Epoch: 5| Step: 6
Training loss: 1.8143665790557861
Validation loss: 2.0189766345485562

Epoch: 5| Step: 7
Training loss: 2.032019853591919
Validation loss: 2.0889379414178992

Epoch: 5| Step: 8
Training loss: 0.9044069051742554
Validation loss: 1.9629786745194466

Epoch: 5| Step: 9
Training loss: 1.07941734790802
Validation loss: 2.107981417768745

Epoch: 5| Step: 10
Training loss: 0.9455658197402954
Validation loss: 2.0315956325941187

Epoch: 605| Step: 0
Training loss: 1.4330551624298096
Validation loss: 2.08406521812562

Epoch: 5| Step: 1
Training loss: 1.5415009260177612
Validation loss: 2.0301974332460793

Epoch: 5| Step: 2
Training loss: 1.1442205905914307
Validation loss: 2.088549501152449

Epoch: 5| Step: 3
Training loss: 1.5299350023269653
Validation loss: 2.0129684043186966

Epoch: 5| Step: 4
Training loss: 1.385299801826477
Validation loss: 2.03806173288694

Epoch: 5| Step: 5
Training loss: 1.6382007598876953
Validation loss: 2.0450944733876053

Epoch: 5| Step: 6
Training loss: 1.4404693841934204
Validation loss: 2.028346562898287

Epoch: 5| Step: 7
Training loss: 1.1677117347717285
Validation loss: 2.0721148867760935

Epoch: 5| Step: 8
Training loss: 1.8179559707641602
Validation loss: 2.095917914503364

Epoch: 5| Step: 9
Training loss: 1.4859447479248047
Validation loss: 1.9975296797290925

Epoch: 5| Step: 10
Training loss: 1.2489354610443115
Validation loss: 2.0074287229968655

Epoch: 606| Step: 0
Training loss: 1.875448226928711
Validation loss: 2.055597403998016

Epoch: 5| Step: 1
Training loss: 1.477396845817566
Validation loss: 1.9968234198067778

Epoch: 5| Step: 2
Training loss: 1.1691792011260986
Validation loss: 2.0927190883185274

Epoch: 5| Step: 3
Training loss: 1.360385775566101
Validation loss: 2.0331092778072564

Epoch: 5| Step: 4
Training loss: 2.013519763946533
Validation loss: 2.0190640572578675

Epoch: 5| Step: 5
Training loss: 1.766214370727539
Validation loss: 2.0783508259763

Epoch: 5| Step: 6
Training loss: 1.7892125844955444
Validation loss: 2.066962113944433

Epoch: 5| Step: 7
Training loss: 0.9601898193359375
Validation loss: 2.0254785937647664

Epoch: 5| Step: 8
Training loss: 1.284125566482544
Validation loss: 2.066133133826717

Epoch: 5| Step: 9
Training loss: 1.681628942489624
Validation loss: 2.0295599609292965

Epoch: 5| Step: 10
Training loss: 1.0553830862045288
Validation loss: 2.0134999252134755

Epoch: 607| Step: 0
Training loss: 1.9123026132583618
Validation loss: 2.046801887532716

Epoch: 5| Step: 1
Training loss: 0.9733449816703796
Validation loss: 2.0514173174417145

Epoch: 5| Step: 2
Training loss: 1.460500955581665
Validation loss: 2.0497117209178146

Epoch: 5| Step: 3
Training loss: 1.176386833190918
Validation loss: 2.020287738051466

Epoch: 5| Step: 4
Training loss: 1.0598516464233398
Validation loss: 2.0663591738670104

Epoch: 5| Step: 5
Training loss: 1.4837195873260498
Validation loss: 1.99039109804297

Epoch: 5| Step: 6
Training loss: 1.695704698562622
Validation loss: 2.0040381736652826

Epoch: 5| Step: 7
Training loss: 1.4912916421890259
Validation loss: 2.0379229232829106

Epoch: 5| Step: 8
Training loss: 1.9405622482299805
Validation loss: 1.9727846191775413

Epoch: 5| Step: 9
Training loss: 1.5433342456817627
Validation loss: 2.0174472947274484

Epoch: 5| Step: 10
Training loss: 1.3772804737091064
Validation loss: 2.059092885704451

Epoch: 608| Step: 0
Training loss: 1.118602991104126
Validation loss: 2.055073303561057

Epoch: 5| Step: 1
Training loss: 1.535899043083191
Validation loss: 2.0358192766866376

Epoch: 5| Step: 2
Training loss: 1.3953956365585327
Validation loss: 2.0747085591798187

Epoch: 5| Step: 3
Training loss: 1.728101372718811
Validation loss: 2.0945912868745866

Epoch: 5| Step: 4
Training loss: 1.3186893463134766
Validation loss: 2.0680217114827966

Epoch: 5| Step: 5
Training loss: 1.3832931518554688
Validation loss: 2.0503039667683263

Epoch: 5| Step: 6
Training loss: 1.7533897161483765
Validation loss: 2.0837040152601016

Epoch: 5| Step: 7
Training loss: 1.0560932159423828
Validation loss: 2.0588927115163496

Epoch: 5| Step: 8
Training loss: 1.546769380569458
Validation loss: 2.0796138035353793

Epoch: 5| Step: 9
Training loss: 1.6143745183944702
Validation loss: 2.0681110979408346

Epoch: 5| Step: 10
Training loss: 1.5151643753051758
Validation loss: 2.0760741720917406

Epoch: 609| Step: 0
Training loss: 1.3073816299438477
Validation loss: 2.0556994227952856

Epoch: 5| Step: 1
Training loss: 1.6475147008895874
Validation loss: 2.122250815873505

Epoch: 5| Step: 2
Training loss: 1.2480210065841675
Validation loss: 2.078517495944936

Epoch: 5| Step: 3
Training loss: 1.708705186843872
Validation loss: 2.0566705029497863

Epoch: 5| Step: 4
Training loss: 1.8157958984375
Validation loss: 2.047145656360093

Epoch: 5| Step: 5
Training loss: 1.3562816381454468
Validation loss: 2.094585898101971

Epoch: 5| Step: 6
Training loss: 1.4412784576416016
Validation loss: 2.1215685670093825

Epoch: 5| Step: 7
Training loss: 0.9631799459457397
Validation loss: 2.0794609977353002

Epoch: 5| Step: 8
Training loss: 1.4616725444793701
Validation loss: 2.1108181374047392

Epoch: 5| Step: 9
Training loss: 1.5448366403579712
Validation loss: 2.0274396660507366

Epoch: 5| Step: 10
Training loss: 1.5353871583938599
Validation loss: 2.0484661773968766

Epoch: 610| Step: 0
Training loss: 0.7182192802429199
Validation loss: 2.0216364809261855

Epoch: 5| Step: 1
Training loss: 1.4696773290634155
Validation loss: 2.0466185538999495

Epoch: 5| Step: 2
Training loss: 1.592923879623413
Validation loss: 2.037370281834756

Epoch: 5| Step: 3
Training loss: 1.419256567955017
Validation loss: 2.11883125253903

Epoch: 5| Step: 4
Training loss: 1.5955078601837158
Validation loss: 2.0800251101934784

Epoch: 5| Step: 5
Training loss: 1.2333937883377075
Validation loss: 2.0855335766269314

Epoch: 5| Step: 6
Training loss: 1.4548203945159912
Validation loss: 2.0755593751066472

Epoch: 5| Step: 7
Training loss: 1.2844970226287842
Validation loss: 2.103798121534368

Epoch: 5| Step: 8
Training loss: 1.649011254310608
Validation loss: 2.0454709452967488

Epoch: 5| Step: 9
Training loss: 1.8262630701065063
Validation loss: 2.056441658286638

Epoch: 5| Step: 10
Training loss: 1.5278884172439575
Validation loss: 2.1754071481766237

Epoch: 611| Step: 0
Training loss: 1.9826431274414062
Validation loss: 2.0504709571920414

Epoch: 5| Step: 1
Training loss: 1.072439432144165
Validation loss: 2.1151401894066924

Epoch: 5| Step: 2
Training loss: 1.648924469947815
Validation loss: 2.045822711401088

Epoch: 5| Step: 3
Training loss: 1.058331847190857
Validation loss: 2.1038875938743673

Epoch: 5| Step: 4
Training loss: 1.6370229721069336
Validation loss: 2.017177984278689

Epoch: 5| Step: 5
Training loss: 1.6502593755722046
Validation loss: 2.018556275675374

Epoch: 5| Step: 6
Training loss: 1.7215032577514648
Validation loss: 1.985457420349121

Epoch: 5| Step: 7
Training loss: 0.9341729879379272
Validation loss: 2.0140358094246156

Epoch: 5| Step: 8
Training loss: 1.3919599056243896
Validation loss: 1.963692585627238

Epoch: 5| Step: 9
Training loss: 1.3362431526184082
Validation loss: 2.0066987532441334

Epoch: 5| Step: 10
Training loss: 1.3077267408370972
Validation loss: 2.0990882060861074

Epoch: 612| Step: 0
Training loss: 1.668291687965393
Validation loss: 2.0017374100223666

Epoch: 5| Step: 1
Training loss: 1.8429944515228271
Validation loss: 1.9797735752597931

Epoch: 5| Step: 2
Training loss: 1.0482532978057861
Validation loss: 2.028534702075425

Epoch: 5| Step: 3
Training loss: 1.7151963710784912
Validation loss: 1.9845442797548027

Epoch: 5| Step: 4
Training loss: 1.5131748914718628
Validation loss: 2.0689082812237483

Epoch: 5| Step: 5
Training loss: 1.334185004234314
Validation loss: 2.070862385534471

Epoch: 5| Step: 6
Training loss: 1.5187146663665771
Validation loss: 2.0019399389143913

Epoch: 5| Step: 7
Training loss: 0.8751662373542786
Validation loss: 2.0716340798203663

Epoch: 5| Step: 8
Training loss: 0.9691299200057983
Validation loss: 2.059026315648069

Epoch: 5| Step: 9
Training loss: 0.9257969856262207
Validation loss: 2.032032246230751

Epoch: 5| Step: 10
Training loss: 2.0013582706451416
Validation loss: 2.014997682263774

Epoch: 613| Step: 0
Training loss: 1.6220508813858032
Validation loss: 2.0445795354022773

Epoch: 5| Step: 1
Training loss: 1.457685112953186
Validation loss: 2.001792161695419

Epoch: 5| Step: 2
Training loss: 1.4186595678329468
Validation loss: 2.0719832886931715

Epoch: 5| Step: 3
Training loss: 1.4407991170883179
Validation loss: 2.02499314982404

Epoch: 5| Step: 4
Training loss: 1.731584906578064
Validation loss: 2.1381601569473103

Epoch: 5| Step: 5
Training loss: 1.4486128091812134
Validation loss: 2.0352165058094966

Epoch: 5| Step: 6
Training loss: 1.9126033782958984
Validation loss: 1.9734138493896813

Epoch: 5| Step: 7
Training loss: 1.389528512954712
Validation loss: 2.020605380817126

Epoch: 5| Step: 8
Training loss: 1.3765387535095215
Validation loss: 2.076793566826851

Epoch: 5| Step: 9
Training loss: 1.1826727390289307
Validation loss: 2.0226200396014797

Epoch: 5| Step: 10
Training loss: 1.0951430797576904
Validation loss: 2.0454401431545133

Epoch: 614| Step: 0
Training loss: 1.220828652381897
Validation loss: 2.1276716647609586

Epoch: 5| Step: 1
Training loss: 1.5270543098449707
Validation loss: 2.0704819566460064

Epoch: 5| Step: 2
Training loss: 1.7505772113800049
Validation loss: 2.121085000294511

Epoch: 5| Step: 3
Training loss: 1.1838172674179077
Validation loss: 1.981351742180445

Epoch: 5| Step: 4
Training loss: 1.2245643138885498
Validation loss: 2.0466601887056903

Epoch: 5| Step: 5
Training loss: 1.3960256576538086
Validation loss: 2.0847790241241455

Epoch: 5| Step: 6
Training loss: 1.1057069301605225
Validation loss: 2.021016664402459

Epoch: 5| Step: 7
Training loss: 2.0586652755737305
Validation loss: 2.1093336254037838

Epoch: 5| Step: 8
Training loss: 2.065702438354492
Validation loss: 2.0404477247627835

Epoch: 5| Step: 9
Training loss: 1.3354092836380005
Validation loss: 2.086090423727548

Epoch: 5| Step: 10
Training loss: 0.9733890295028687
Validation loss: 2.0687166849772134

Epoch: 615| Step: 0
Training loss: 1.107430338859558
Validation loss: 2.0549950650943223

Epoch: 5| Step: 1
Training loss: 0.9825055003166199
Validation loss: 2.0782408842476467

Epoch: 5| Step: 2
Training loss: 1.2532188892364502
Validation loss: 2.056596036880247

Epoch: 5| Step: 3
Training loss: 1.690069556236267
Validation loss: 2.034567376618744

Epoch: 5| Step: 4
Training loss: 1.8730703592300415
Validation loss: 1.9917307720389417

Epoch: 5| Step: 5
Training loss: 1.3070142269134521
Validation loss: 1.9611122903003488

Epoch: 5| Step: 6
Training loss: 1.9097955226898193
Validation loss: 2.104219881437158

Epoch: 5| Step: 7
Training loss: 1.3744457960128784
Validation loss: 2.073538305938885

Epoch: 5| Step: 8
Training loss: 1.3825737237930298
Validation loss: 2.052049470204179

Epoch: 5| Step: 9
Training loss: 1.803670883178711
Validation loss: 2.0456244714798464

Epoch: 5| Step: 10
Training loss: 1.1463700532913208
Validation loss: 2.0074235393155004

Epoch: 616| Step: 0
Training loss: 1.4437657594680786
Validation loss: 1.9807143621547247

Epoch: 5| Step: 1
Training loss: 1.1528141498565674
Validation loss: 2.03529417386619

Epoch: 5| Step: 2
Training loss: 1.2070969343185425
Validation loss: 2.1177655727632585

Epoch: 5| Step: 3
Training loss: 1.096842646598816
Validation loss: 1.9908426871863745

Epoch: 5| Step: 4
Training loss: 1.6347882747650146
Validation loss: 2.1262513309396724

Epoch: 5| Step: 5
Training loss: 1.3894412517547607
Validation loss: 2.049657662709554

Epoch: 5| Step: 6
Training loss: 2.1227102279663086
Validation loss: 2.0513967185892086

Epoch: 5| Step: 7
Training loss: 0.5998151898384094
Validation loss: 2.0860328648679998

Epoch: 5| Step: 8
Training loss: 1.6977412700653076
Validation loss: 2.0769152679750995

Epoch: 5| Step: 9
Training loss: 1.7488460540771484
Validation loss: 2.1033345268618677

Epoch: 5| Step: 10
Training loss: 1.6126810312271118
Validation loss: 2.063453939653212

Epoch: 617| Step: 0
Training loss: 1.1048115491867065
Validation loss: 1.9875374109514299

Epoch: 5| Step: 1
Training loss: 1.4116824865341187
Validation loss: 2.129186822522071

Epoch: 5| Step: 2
Training loss: 0.8881183862686157
Validation loss: 2.0648389093337522

Epoch: 5| Step: 3
Training loss: 1.4177240133285522
Validation loss: 2.0738418153537217

Epoch: 5| Step: 4
Training loss: 1.7217985391616821
Validation loss: 2.027142583682973

Epoch: 5| Step: 5
Training loss: 1.5747478008270264
Validation loss: 2.077461282412211

Epoch: 5| Step: 6
Training loss: 1.7992979288101196
Validation loss: 2.0586002949745423

Epoch: 5| Step: 7
Training loss: 1.6161549091339111
Validation loss: 2.095229514183537

Epoch: 5| Step: 8
Training loss: 1.6844761371612549
Validation loss: 2.0629024121069137

Epoch: 5| Step: 9
Training loss: 1.614206314086914
Validation loss: 2.048358081489481

Epoch: 5| Step: 10
Training loss: 0.552924633026123
Validation loss: 2.0433146774127917

Epoch: 618| Step: 0
Training loss: 1.1935691833496094
Validation loss: 2.127504394900414

Epoch: 5| Step: 1
Training loss: 1.5241305828094482
Validation loss: 2.003012575129027

Epoch: 5| Step: 2
Training loss: 1.0756093263626099
Validation loss: 1.9994517026409027

Epoch: 5| Step: 3
Training loss: 1.2808606624603271
Validation loss: 2.107624738447128

Epoch: 5| Step: 4
Training loss: 1.5187270641326904
Validation loss: 1.9642734360951248

Epoch: 5| Step: 5
Training loss: 1.7477127313613892
Validation loss: 2.086356541161896

Epoch: 5| Step: 6
Training loss: 1.7487142086029053
Validation loss: 2.0074937599961475

Epoch: 5| Step: 7
Training loss: 1.4096662998199463
Validation loss: 2.0677408761875604

Epoch: 5| Step: 8
Training loss: 1.412203073501587
Validation loss: 2.0212957423220397

Epoch: 5| Step: 9
Training loss: 1.2238786220550537
Validation loss: 2.0725640443063553

Epoch: 5| Step: 10
Training loss: 1.096082329750061
Validation loss: 2.0456547557666735

Epoch: 619| Step: 0
Training loss: 1.6227457523345947
Validation loss: 2.0568041109269664

Epoch: 5| Step: 1
Training loss: 1.5915035009384155
Validation loss: 2.0463031338107203

Epoch: 5| Step: 2
Training loss: 1.058335542678833
Validation loss: 2.131774810052687

Epoch: 5| Step: 3
Training loss: 1.3211698532104492
Validation loss: 2.0380242140062395

Epoch: 5| Step: 4
Training loss: 1.6830905675888062
Validation loss: 2.0125412120614

Epoch: 5| Step: 5
Training loss: 1.0259000062942505
Validation loss: 2.027256750291394

Epoch: 5| Step: 6
Training loss: 1.3654053211212158
Validation loss: 2.0467420265238774

Epoch: 5| Step: 7
Training loss: 1.264690637588501
Validation loss: 2.0622561029208604

Epoch: 5| Step: 8
Training loss: 1.3702738285064697
Validation loss: 2.133461190808204

Epoch: 5| Step: 9
Training loss: 1.7804527282714844
Validation loss: 2.014185820856402

Epoch: 5| Step: 10
Training loss: 1.528491497039795
Validation loss: 2.0983603718460246

Epoch: 620| Step: 0
Training loss: 1.5860251188278198
Validation loss: 2.079591494734569

Epoch: 5| Step: 1
Training loss: 1.385152816772461
Validation loss: 2.0708253473363896

Epoch: 5| Step: 2
Training loss: 0.7439947128295898
Validation loss: 2.0163124389545892

Epoch: 5| Step: 3
Training loss: 1.3275114297866821
Validation loss: 2.1672620722042617

Epoch: 5| Step: 4
Training loss: 1.5871508121490479
Validation loss: 2.083045071171176

Epoch: 5| Step: 5
Training loss: 1.559120535850525
Validation loss: 2.126832495453537

Epoch: 5| Step: 6
Training loss: 2.1765549182891846
Validation loss: 2.024515039177351

Epoch: 5| Step: 7
Training loss: 1.487797737121582
Validation loss: 2.030288146388146

Epoch: 5| Step: 8
Training loss: 1.3406094312667847
Validation loss: 2.064419024734087

Epoch: 5| Step: 9
Training loss: 1.3741823434829712
Validation loss: 2.072232106680511

Epoch: 5| Step: 10
Training loss: 1.6443120241165161
Validation loss: 2.0068026140171993

Epoch: 621| Step: 0
Training loss: 1.7793896198272705
Validation loss: 2.0318915049235025

Epoch: 5| Step: 1
Training loss: 1.8146083354949951
Validation loss: 2.110445322528962

Epoch: 5| Step: 2
Training loss: 0.9524133801460266
Validation loss: 2.101381617207681

Epoch: 5| Step: 3
Training loss: 1.6382153034210205
Validation loss: 2.1031033364675378

Epoch: 5| Step: 4
Training loss: 1.9581400156021118
Validation loss: 2.1393803114532144

Epoch: 5| Step: 5
Training loss: 1.2611541748046875
Validation loss: 2.0557020453996557

Epoch: 5| Step: 6
Training loss: 1.5430021286010742
Validation loss: 2.112342724236109

Epoch: 5| Step: 7
Training loss: 0.8830135464668274
Validation loss: 2.018352367544687

Epoch: 5| Step: 8
Training loss: 1.3654325008392334
Validation loss: 2.0832530413904498

Epoch: 5| Step: 9
Training loss: 1.2065491676330566
Validation loss: 2.1231133335380146

Epoch: 5| Step: 10
Training loss: 1.2743693590164185
Validation loss: 2.059274354288655

Epoch: 622| Step: 0
Training loss: 1.5165268182754517
Validation loss: 2.059888985849196

Epoch: 5| Step: 1
Training loss: 1.2348036766052246
Validation loss: 2.0088597177177347

Epoch: 5| Step: 2
Training loss: 2.0705912113189697
Validation loss: 1.9766001111717635

Epoch: 5| Step: 3
Training loss: 1.88336181640625
Validation loss: 2.0881574076990925

Epoch: 5| Step: 4
Training loss: 1.559709906578064
Validation loss: 2.002930566828738

Epoch: 5| Step: 5
Training loss: 1.2027240991592407
Validation loss: 1.988351406589631

Epoch: 5| Step: 6
Training loss: 1.550301194190979
Validation loss: 2.0866632679457306

Epoch: 5| Step: 7
Training loss: 1.4516184329986572
Validation loss: 2.0159959100907847

Epoch: 5| Step: 8
Training loss: 1.2680072784423828
Validation loss: 2.0231148068622877

Epoch: 5| Step: 9
Training loss: 0.7439785003662109
Validation loss: 2.0624570077465427

Epoch: 5| Step: 10
Training loss: 1.3670376539230347
Validation loss: 2.0623994693961194

Epoch: 623| Step: 0
Training loss: 1.4342414140701294
Validation loss: 2.0192979381930445

Epoch: 5| Step: 1
Training loss: 1.5714457035064697
Validation loss: 2.1081171881768013

Epoch: 5| Step: 2
Training loss: 1.5475013256072998
Validation loss: 2.064997462816136

Epoch: 5| Step: 3
Training loss: 1.2572910785675049
Validation loss: 2.015625629373776

Epoch: 5| Step: 4
Training loss: 1.3948167562484741
Validation loss: 2.109903427862352

Epoch: 5| Step: 5
Training loss: 1.3671038150787354
Validation loss: 2.1113797016041254

Epoch: 5| Step: 6
Training loss: 1.41001558303833
Validation loss: 2.0384481722308743

Epoch: 5| Step: 7
Training loss: 1.4646154642105103
Validation loss: 1.9496797156590286

Epoch: 5| Step: 8
Training loss: 1.503185749053955
Validation loss: 1.9986180156789801

Epoch: 5| Step: 9
Training loss: 1.141677737236023
Validation loss: 2.0336339499360774

Epoch: 5| Step: 10
Training loss: 1.463373064994812
Validation loss: 2.055584239703353

Epoch: 624| Step: 0
Training loss: 1.2696077823638916
Validation loss: 2.085597515106201

Epoch: 5| Step: 1
Training loss: 1.157092809677124
Validation loss: 2.0465862404915596

Epoch: 5| Step: 2
Training loss: 1.7547061443328857
Validation loss: 2.1089126756114345

Epoch: 5| Step: 3
Training loss: 1.4342912435531616
Validation loss: 2.0862270068096858

Epoch: 5| Step: 4
Training loss: 0.9149570465087891
Validation loss: 2.071585912858286

Epoch: 5| Step: 5
Training loss: 2.0419840812683105
Validation loss: 1.9961089344434841

Epoch: 5| Step: 6
Training loss: 1.599806785583496
Validation loss: 1.9753697277397237

Epoch: 5| Step: 7
Training loss: 1.3703758716583252
Validation loss: 2.0594618653738372

Epoch: 5| Step: 8
Training loss: 1.115544319152832
Validation loss: 2.0700585380677254

Epoch: 5| Step: 9
Training loss: 1.1842149496078491
Validation loss: 2.098092120180848

Epoch: 5| Step: 10
Training loss: 1.2129247188568115
Validation loss: 2.09091374181932

Epoch: 625| Step: 0
Training loss: 1.4065186977386475
Validation loss: 2.086908148181054

Epoch: 5| Step: 1
Training loss: 1.027735948562622
Validation loss: 2.0517933343046453

Epoch: 5| Step: 2
Training loss: 1.5722172260284424
Validation loss: 2.0439973749140257

Epoch: 5| Step: 3
Training loss: 1.3454997539520264
Validation loss: 2.0937951803207397

Epoch: 5| Step: 4
Training loss: 1.7790155410766602
Validation loss: 2.036758501042602

Epoch: 5| Step: 5
Training loss: 1.6056125164031982
Validation loss: 1.9934806849366875

Epoch: 5| Step: 6
Training loss: 1.129114031791687
Validation loss: 1.9753025180550032

Epoch: 5| Step: 7
Training loss: 1.355484962463379
Validation loss: 2.0698902953055596

Epoch: 5| Step: 8
Training loss: 1.811776876449585
Validation loss: 2.0884742967544065

Epoch: 5| Step: 9
Training loss: 1.2814713716506958
Validation loss: 1.9995674497337752

Epoch: 5| Step: 10
Training loss: 1.6715267896652222
Validation loss: 2.055718696245583

Epoch: 626| Step: 0
Training loss: 1.48446786403656
Validation loss: 2.117211405948926

Epoch: 5| Step: 1
Training loss: 0.8759196400642395
Validation loss: 2.0299879299697055

Epoch: 5| Step: 2
Training loss: 1.876450538635254
Validation loss: 2.0535253850362634

Epoch: 5| Step: 3
Training loss: 1.1901767253875732
Validation loss: 2.0975951161435855

Epoch: 5| Step: 4
Training loss: 1.5529570579528809
Validation loss: 2.0235980620948215

Epoch: 5| Step: 5
Training loss: 1.622521996498108
Validation loss: 2.042924701526601

Epoch: 5| Step: 6
Training loss: 1.9491355419158936
Validation loss: 2.00647969143365

Epoch: 5| Step: 7
Training loss: 1.0606648921966553
Validation loss: 2.0674820843563286

Epoch: 5| Step: 8
Training loss: 0.8035241961479187
Validation loss: 2.0851525081101285

Epoch: 5| Step: 9
Training loss: 1.5280101299285889
Validation loss: 2.0117115512970956

Epoch: 5| Step: 10
Training loss: 1.4075543880462646
Validation loss: 2.046428659910797

Epoch: 627| Step: 0
Training loss: 1.2403812408447266
Validation loss: 2.0447711483124764

Epoch: 5| Step: 1
Training loss: 1.51094651222229
Validation loss: 1.9968922445850987

Epoch: 5| Step: 2
Training loss: 1.275380253791809
Validation loss: 2.061042029370544

Epoch: 5| Step: 3
Training loss: 1.1863048076629639
Validation loss: 2.0051885266457834

Epoch: 5| Step: 4
Training loss: 1.3235490322113037
Validation loss: 2.033107646049992

Epoch: 5| Step: 5
Training loss: 1.021986722946167
Validation loss: 2.0790525021091586

Epoch: 5| Step: 6
Training loss: 1.5649678707122803
Validation loss: 2.1167330677791307

Epoch: 5| Step: 7
Training loss: 1.1706249713897705
Validation loss: 1.9547015800270984

Epoch: 5| Step: 8
Training loss: 1.902292013168335
Validation loss: 2.019939540534891

Epoch: 5| Step: 9
Training loss: 1.069369912147522
Validation loss: 2.1109189346272457

Epoch: 5| Step: 10
Training loss: 1.9724395275115967
Validation loss: 2.1330377683844617

Epoch: 628| Step: 0
Training loss: 1.2018365859985352
Validation loss: 2.067117316748506

Epoch: 5| Step: 1
Training loss: 1.0464212894439697
Validation loss: 2.0983557560110606

Epoch: 5| Step: 2
Training loss: 1.1273324489593506
Validation loss: 2.0734097880701863

Epoch: 5| Step: 3
Training loss: 1.2185767889022827
Validation loss: 2.11937221916773

Epoch: 5| Step: 4
Training loss: 1.7254183292388916
Validation loss: 2.093422700000066

Epoch: 5| Step: 5
Training loss: 1.4377652406692505
Validation loss: 2.030050946820167

Epoch: 5| Step: 6
Training loss: 1.5201318264007568
Validation loss: 2.032338883287163

Epoch: 5| Step: 7
Training loss: 1.2046209573745728
Validation loss: 2.0839077016358734

Epoch: 5| Step: 8
Training loss: 1.2510013580322266
Validation loss: 2.1014641677179644

Epoch: 5| Step: 9
Training loss: 1.5955785512924194
Validation loss: 2.067862411980988

Epoch: 5| Step: 10
Training loss: 2.2779288291931152
Validation loss: 2.106284741432436

Epoch: 629| Step: 0
Training loss: 1.4225695133209229
Validation loss: 2.1563086381522556

Epoch: 5| Step: 1
Training loss: 1.489214301109314
Validation loss: 2.036015591313762

Epoch: 5| Step: 2
Training loss: 1.0101865530014038
Validation loss: 2.0798718916472567

Epoch: 5| Step: 3
Training loss: 1.3739373683929443
Validation loss: 2.0908898845795663

Epoch: 5| Step: 4
Training loss: 1.4005606174468994
Validation loss: 2.079993176203902

Epoch: 5| Step: 5
Training loss: 1.6932485103607178
Validation loss: 2.0943167286534465

Epoch: 5| Step: 6
Training loss: 1.6093260049819946
Validation loss: 1.9852824928939983

Epoch: 5| Step: 7
Training loss: 1.2913706302642822
Validation loss: 2.0772454379707255

Epoch: 5| Step: 8
Training loss: 1.2105591297149658
Validation loss: 2.0282397706021547

Epoch: 5| Step: 9
Training loss: 1.717977523803711
Validation loss: 2.106446755829678

Epoch: 5| Step: 10
Training loss: 1.6244001388549805
Validation loss: 2.1160893696610645

Epoch: 630| Step: 0
Training loss: 1.7121464014053345
Validation loss: 2.0482705690527476

Epoch: 5| Step: 1
Training loss: 1.5934793949127197
Validation loss: 2.044266782781129

Epoch: 5| Step: 2
Training loss: 1.0213773250579834
Validation loss: 2.0811295252974316

Epoch: 5| Step: 3
Training loss: 1.9965460300445557
Validation loss: 2.0704914113526702

Epoch: 5| Step: 4
Training loss: 1.6354984045028687
Validation loss: 2.086140650574879

Epoch: 5| Step: 5
Training loss: 1.058616280555725
Validation loss: 2.0642857064482985

Epoch: 5| Step: 6
Training loss: 1.3705674409866333
Validation loss: 2.1157474069185156

Epoch: 5| Step: 7
Training loss: 1.2233206033706665
Validation loss: 2.1000507134263233

Epoch: 5| Step: 8
Training loss: 1.7084276676177979
Validation loss: 2.1408518962962653

Epoch: 5| Step: 9
Training loss: 1.080325722694397
Validation loss: 2.107594674633395

Epoch: 5| Step: 10
Training loss: 1.1550023555755615
Validation loss: 2.012278136386666

Epoch: 631| Step: 0
Training loss: 1.0266449451446533
Validation loss: 2.1437070241538425

Epoch: 5| Step: 1
Training loss: 0.8520383834838867
Validation loss: 2.112224950585314

Epoch: 5| Step: 2
Training loss: 2.0518951416015625
Validation loss: 2.0604473211432017

Epoch: 5| Step: 3
Training loss: 1.378178596496582
Validation loss: 2.0854269048219085

Epoch: 5| Step: 4
Training loss: 1.9444453716278076
Validation loss: 2.051699435839089

Epoch: 5| Step: 5
Training loss: 1.5840860605239868
Validation loss: 2.0480766398932344

Epoch: 5| Step: 6
Training loss: 1.1974908113479614
Validation loss: 2.0663515213997132

Epoch: 5| Step: 7
Training loss: 1.158801794052124
Validation loss: 2.0095346409787416

Epoch: 5| Step: 8
Training loss: 1.6592121124267578
Validation loss: 2.0164878573468936

Epoch: 5| Step: 9
Training loss: 1.1822258234024048
Validation loss: 1.993475838374066

Epoch: 5| Step: 10
Training loss: 0.954818069934845
Validation loss: 2.102798195295436

Epoch: 632| Step: 0
Training loss: 1.4448449611663818
Validation loss: 1.9620651198971657

Epoch: 5| Step: 1
Training loss: 1.4647291898727417
Validation loss: 2.0045848713126233

Epoch: 5| Step: 2
Training loss: 1.3722003698349
Validation loss: 2.022507203522549

Epoch: 5| Step: 3
Training loss: 1.4202643632888794
Validation loss: 2.0381662743065947

Epoch: 5| Step: 4
Training loss: 1.8817905187606812
Validation loss: 2.0183251160447315

Epoch: 5| Step: 5
Training loss: 1.8374817371368408
Validation loss: 2.0240283755845923

Epoch: 5| Step: 6
Training loss: 1.1881848573684692
Validation loss: 2.0296589815488426

Epoch: 5| Step: 7
Training loss: 1.4174094200134277
Validation loss: 2.009467263375559

Epoch: 5| Step: 8
Training loss: 0.8688114881515503
Validation loss: 2.0252224963198424

Epoch: 5| Step: 9
Training loss: 1.470518946647644
Validation loss: 1.9758362923899004

Epoch: 5| Step: 10
Training loss: 1.0250452756881714
Validation loss: 2.0745861530303955

Epoch: 633| Step: 0
Training loss: 1.2605644464492798
Validation loss: 2.056122887519098

Epoch: 5| Step: 1
Training loss: 1.4005905389785767
Validation loss: 1.9487039683967509

Epoch: 5| Step: 2
Training loss: 0.9032823443412781
Validation loss: 2.037082972065095

Epoch: 5| Step: 3
Training loss: 1.8429667949676514
Validation loss: 2.026982852207717

Epoch: 5| Step: 4
Training loss: 2.2147176265716553
Validation loss: 2.066826230736189

Epoch: 5| Step: 5
Training loss: 1.3746421337127686
Validation loss: 2.0828364113325715

Epoch: 5| Step: 6
Training loss: 1.283746361732483
Validation loss: 2.125582646298152

Epoch: 5| Step: 7
Training loss: 1.2480058670043945
Validation loss: 2.1638740442132436

Epoch: 5| Step: 8
Training loss: 1.0716358423233032
Validation loss: 2.082029788724838

Epoch: 5| Step: 9
Training loss: 1.278541922569275
Validation loss: 2.016881977358172

Epoch: 5| Step: 10
Training loss: 1.827368140220642
Validation loss: 2.094498351056089

Epoch: 634| Step: 0
Training loss: 2.1056318283081055
Validation loss: 2.0738800315446753

Epoch: 5| Step: 1
Training loss: 1.203855276107788
Validation loss: 2.026015099658761

Epoch: 5| Step: 2
Training loss: 1.367040753364563
Validation loss: 2.00526532178284

Epoch: 5| Step: 3
Training loss: 1.2056020498275757
Validation loss: 2.0982695266764653

Epoch: 5| Step: 4
Training loss: 0.9944992065429688
Validation loss: 2.0040815402102727

Epoch: 5| Step: 5
Training loss: 1.3316266536712646
Validation loss: 2.0187075240637666

Epoch: 5| Step: 6
Training loss: 1.7797715663909912
Validation loss: 2.022195316130115

Epoch: 5| Step: 7
Training loss: 1.7916831970214844
Validation loss: 2.0572585828842653

Epoch: 5| Step: 8
Training loss: 1.3074538707733154
Validation loss: 2.100044386361235

Epoch: 5| Step: 9
Training loss: 0.8077767491340637
Validation loss: 2.030488398767287

Epoch: 5| Step: 10
Training loss: 1.579963207244873
Validation loss: 2.0341323370574624

Epoch: 635| Step: 0
Training loss: 1.1533693075180054
Validation loss: 2.1055293506191624

Epoch: 5| Step: 1
Training loss: 1.5295392274856567
Validation loss: 2.078202057910222

Epoch: 5| Step: 2
Training loss: 1.6324608325958252
Validation loss: 2.0283918355100896

Epoch: 5| Step: 3
Training loss: 0.9446316957473755
Validation loss: 2.0394874734263264

Epoch: 5| Step: 4
Training loss: 1.7244949340820312
Validation loss: 2.011293295891054

Epoch: 5| Step: 5
Training loss: 1.0222777128219604
Validation loss: 1.9765532914028372

Epoch: 5| Step: 6
Training loss: 1.1487661600112915
Validation loss: 2.09352711964679

Epoch: 5| Step: 7
Training loss: 1.3793578147888184
Validation loss: 2.042114496231079

Epoch: 5| Step: 8
Training loss: 1.80940842628479
Validation loss: 2.084038321689893

Epoch: 5| Step: 9
Training loss: 1.5440150499343872
Validation loss: 2.038703885129703

Epoch: 5| Step: 10
Training loss: 1.539811611175537
Validation loss: 2.0613865390900643

Epoch: 636| Step: 0
Training loss: 1.249915599822998
Validation loss: 2.1056684294054584

Epoch: 5| Step: 1
Training loss: 1.3731482028961182
Validation loss: 2.045885342423634

Epoch: 5| Step: 2
Training loss: 1.7280988693237305
Validation loss: 2.033262095143718

Epoch: 5| Step: 3
Training loss: 1.6034209728240967
Validation loss: 2.1306033595915763

Epoch: 5| Step: 4
Training loss: 1.914428949356079
Validation loss: 2.0198829532951437

Epoch: 5| Step: 5
Training loss: 0.9567036628723145
Validation loss: 2.130474535367822

Epoch: 5| Step: 6
Training loss: 1.763789176940918
Validation loss: 2.0433783646552794

Epoch: 5| Step: 7
Training loss: 1.2534863948822021
Validation loss: 2.110055608134116

Epoch: 5| Step: 8
Training loss: 1.0550791025161743
Validation loss: 2.065508234885431

Epoch: 5| Step: 9
Training loss: 0.9446398615837097
Validation loss: 2.0665731712054183

Epoch: 5| Step: 10
Training loss: 1.453080177307129
Validation loss: 2.0752952073210027

Epoch: 637| Step: 0
Training loss: 1.436659812927246
Validation loss: 2.0684342602247834

Epoch: 5| Step: 1
Training loss: 1.25583815574646
Validation loss: 2.081648431798463

Epoch: 5| Step: 2
Training loss: 1.199012041091919
Validation loss: 2.100108269722231

Epoch: 5| Step: 3
Training loss: 1.0608203411102295
Validation loss: 2.085909519144284

Epoch: 5| Step: 4
Training loss: 1.8712526559829712
Validation loss: 2.111170171409525

Epoch: 5| Step: 5
Training loss: 1.432989478111267
Validation loss: 2.062802936441155

Epoch: 5| Step: 6
Training loss: 1.211599588394165
Validation loss: 1.977536304022676

Epoch: 5| Step: 7
Training loss: 1.2007405757904053
Validation loss: 2.0049205249355686

Epoch: 5| Step: 8
Training loss: 1.9376132488250732
Validation loss: 2.0848715843692904

Epoch: 5| Step: 9
Training loss: 1.3845250606536865
Validation loss: 2.02710804118905

Epoch: 5| Step: 10
Training loss: 1.3591265678405762
Validation loss: 2.0817320116104616

Epoch: 638| Step: 0
Training loss: 1.6835196018218994
Validation loss: 2.099561469529265

Epoch: 5| Step: 1
Training loss: 1.8470427989959717
Validation loss: 2.0447528375092374

Epoch: 5| Step: 2
Training loss: 1.0122822523117065
Validation loss: 2.0336820899799304

Epoch: 5| Step: 3
Training loss: 1.3002437353134155
Validation loss: 2.149233493753659

Epoch: 5| Step: 4
Training loss: 1.2500680685043335
Validation loss: 2.091206084015549

Epoch: 5| Step: 5
Training loss: 1.0753793716430664
Validation loss: 2.0593708817676832

Epoch: 5| Step: 6
Training loss: 1.9296777248382568
Validation loss: 2.0209117448458107

Epoch: 5| Step: 7
Training loss: 1.3303277492523193
Validation loss: 2.0590037838105233

Epoch: 5| Step: 8
Training loss: 1.1837635040283203
Validation loss: 2.0214008490244546

Epoch: 5| Step: 9
Training loss: 1.5261346101760864
Validation loss: 2.09337910913652

Epoch: 5| Step: 10
Training loss: 1.2045025825500488
Validation loss: 2.077818086070399

Epoch: 639| Step: 0
Training loss: 1.2210696935653687
Validation loss: 2.058012911068496

Epoch: 5| Step: 1
Training loss: 1.094699501991272
Validation loss: 2.077409350743858

Epoch: 5| Step: 2
Training loss: 1.058083176612854
Validation loss: 2.085028076684603

Epoch: 5| Step: 3
Training loss: 1.479637861251831
Validation loss: 2.120702942212423

Epoch: 5| Step: 4
Training loss: 1.0859264135360718
Validation loss: 1.9736445706377748

Epoch: 5| Step: 5
Training loss: 1.3889459371566772
Validation loss: 2.060332839206983

Epoch: 5| Step: 6
Training loss: 1.5591340065002441
Validation loss: 2.119600442148024

Epoch: 5| Step: 7
Training loss: 1.5529712438583374
Validation loss: 2.073485161668511

Epoch: 5| Step: 8
Training loss: 1.3463995456695557
Validation loss: 2.059254357891698

Epoch: 5| Step: 9
Training loss: 1.4555784463882446
Validation loss: 2.015691962293399

Epoch: 5| Step: 10
Training loss: 1.2333773374557495
Validation loss: 2.0356360712359027

Epoch: 640| Step: 0
Training loss: 1.4062979221343994
Validation loss: 2.060339097053774

Epoch: 5| Step: 1
Training loss: 1.8604682683944702
Validation loss: 2.064899162579608

Epoch: 5| Step: 2
Training loss: 1.5241788625717163
Validation loss: 2.1211574692879953

Epoch: 5| Step: 3
Training loss: 1.1152530908584595
Validation loss: 2.035152783957861

Epoch: 5| Step: 4
Training loss: 1.3347442150115967
Validation loss: 2.052904684056518

Epoch: 5| Step: 5
Training loss: 1.8057124614715576
Validation loss: 2.0487099488576255

Epoch: 5| Step: 6
Training loss: 1.790387749671936
Validation loss: 2.1108600811291764

Epoch: 5| Step: 7
Training loss: 0.8469675183296204
Validation loss: 2.0495511767684773

Epoch: 5| Step: 8
Training loss: 1.190140724182129
Validation loss: 1.9541093149492819

Epoch: 5| Step: 9
Training loss: 1.0944039821624756
Validation loss: 2.0665650393373225

Epoch: 5| Step: 10
Training loss: 1.5795907974243164
Validation loss: 2.114439816885097

Epoch: 641| Step: 0
Training loss: 1.3948519229888916
Validation loss: 1.9959490145406416

Epoch: 5| Step: 1
Training loss: 0.995012104511261
Validation loss: 2.0839224182149416

Epoch: 5| Step: 2
Training loss: 1.5171229839324951
Validation loss: 2.0625003781369937

Epoch: 5| Step: 3
Training loss: 1.593684196472168
Validation loss: 2.0360439285155265

Epoch: 5| Step: 4
Training loss: 1.2591068744659424
Validation loss: 2.1128011518909084

Epoch: 5| Step: 5
Training loss: 1.1802570819854736
Validation loss: 2.0526579797908826

Epoch: 5| Step: 6
Training loss: 1.8103094100952148
Validation loss: 2.0394522118312057

Epoch: 5| Step: 7
Training loss: 1.4140466451644897
Validation loss: 1.9881407419840496

Epoch: 5| Step: 8
Training loss: 1.281294584274292
Validation loss: 2.0495358846520864

Epoch: 5| Step: 9
Training loss: 1.013458013534546
Validation loss: 2.0089063823864026

Epoch: 5| Step: 10
Training loss: 1.6179252862930298
Validation loss: 1.9804364045461018

Epoch: 642| Step: 0
Training loss: 1.346076488494873
Validation loss: 2.0937222485901206

Epoch: 5| Step: 1
Training loss: 1.2172154188156128
Validation loss: 2.0686470334247877

Epoch: 5| Step: 2
Training loss: 1.2384237051010132
Validation loss: 2.062439718554097

Epoch: 5| Step: 3
Training loss: 1.0680277347564697
Validation loss: 2.1007871422716367

Epoch: 5| Step: 4
Training loss: 2.0788655281066895
Validation loss: 2.069477888845628

Epoch: 5| Step: 5
Training loss: 1.5720430612564087
Validation loss: 2.098828201652855

Epoch: 5| Step: 6
Training loss: 1.5869991779327393
Validation loss: 2.0211078992453952

Epoch: 5| Step: 7
Training loss: 1.782785415649414
Validation loss: 2.1066043094922136

Epoch: 5| Step: 8
Training loss: 1.3209348917007446
Validation loss: 2.026811397203835

Epoch: 5| Step: 9
Training loss: 1.2702457904815674
Validation loss: 2.128122382266547

Epoch: 5| Step: 10
Training loss: 0.8446009755134583
Validation loss: 2.1344278474007883

Epoch: 643| Step: 0
Training loss: 1.2384002208709717
Validation loss: 2.115790269708121

Epoch: 5| Step: 1
Training loss: 1.322933554649353
Validation loss: 2.17845090358488

Epoch: 5| Step: 2
Training loss: 1.4618160724639893
Validation loss: 2.1272735313702653

Epoch: 5| Step: 3
Training loss: 1.060702919960022
Validation loss: 2.086783596264419

Epoch: 5| Step: 4
Training loss: 1.0744750499725342
Validation loss: 2.116704284503896

Epoch: 5| Step: 5
Training loss: 1.8753364086151123
Validation loss: 2.122683842976888

Epoch: 5| Step: 6
Training loss: 2.0664010047912598
Validation loss: 2.0731055685268935

Epoch: 5| Step: 7
Training loss: 1.5641483068466187
Validation loss: 2.0607652612911758

Epoch: 5| Step: 8
Training loss: 0.855954647064209
Validation loss: 2.0914600959388157

Epoch: 5| Step: 9
Training loss: 1.4124892950057983
Validation loss: 2.1456349652300597

Epoch: 5| Step: 10
Training loss: 1.6155059337615967
Validation loss: 2.0756102608096216

Epoch: 644| Step: 0
Training loss: 1.0816619396209717
Validation loss: 2.106787976398263

Epoch: 5| Step: 1
Training loss: 1.0814955234527588
Validation loss: 2.1656405887296124

Epoch: 5| Step: 2
Training loss: 1.2525287866592407
Validation loss: 2.017567680728051

Epoch: 5| Step: 3
Training loss: 1.718869924545288
Validation loss: 2.0384554247702322

Epoch: 5| Step: 4
Training loss: 1.083520531654358
Validation loss: 2.0846128976473244

Epoch: 5| Step: 5
Training loss: 1.025107741355896
Validation loss: 2.047903201913321

Epoch: 5| Step: 6
Training loss: 1.2469068765640259
Validation loss: 2.0125106996105564

Epoch: 5| Step: 7
Training loss: 1.6546199321746826
Validation loss: 2.0252126493761615

Epoch: 5| Step: 8
Training loss: 1.8232990503311157
Validation loss: 2.0367208219343618

Epoch: 5| Step: 9
Training loss: 1.6285276412963867
Validation loss: 2.125575319413216

Epoch: 5| Step: 10
Training loss: 1.344852089881897
Validation loss: 2.102968700470463

Epoch: 645| Step: 0
Training loss: 1.139209270477295
Validation loss: 2.04189803267038

Epoch: 5| Step: 1
Training loss: 2.1006534099578857
Validation loss: 2.0392080455697994

Epoch: 5| Step: 2
Training loss: 1.1098682880401611
Validation loss: 2.033031512332219

Epoch: 5| Step: 3
Training loss: 1.5213264226913452
Validation loss: 2.081768076906922

Epoch: 5| Step: 4
Training loss: 1.4929454326629639
Validation loss: 2.004560257798882

Epoch: 5| Step: 5
Training loss: 1.3468430042266846
Validation loss: 1.9944353142092306

Epoch: 5| Step: 6
Training loss: 1.318693995475769
Validation loss: 2.126002465524981

Epoch: 5| Step: 7
Training loss: 1.3513435125350952
Validation loss: 2.0335818067673714

Epoch: 5| Step: 8
Training loss: 1.461646318435669
Validation loss: 2.027876474524057

Epoch: 5| Step: 9
Training loss: 0.8564308285713196
Validation loss: 2.081620377878989

Epoch: 5| Step: 10
Training loss: 1.4751019477844238
Validation loss: 1.9849738997797812

Epoch: 646| Step: 0
Training loss: 1.3343822956085205
Validation loss: 2.127233182230303

Epoch: 5| Step: 1
Training loss: 1.622624397277832
Validation loss: 2.0308175151066115

Epoch: 5| Step: 2
Training loss: 1.53938889503479
Validation loss: 2.041330147815007

Epoch: 5| Step: 3
Training loss: 1.2933743000030518
Validation loss: 2.1025801845776138

Epoch: 5| Step: 4
Training loss: 1.5975347757339478
Validation loss: 2.092451808273151

Epoch: 5| Step: 5
Training loss: 1.4350172281265259
Validation loss: 2.1085674044906453

Epoch: 5| Step: 6
Training loss: 1.4618785381317139
Validation loss: 2.0442073268275105

Epoch: 5| Step: 7
Training loss: 0.8613008260726929
Validation loss: 2.088759104410807

Epoch: 5| Step: 8
Training loss: 1.4761841297149658
Validation loss: 2.0635494634669316

Epoch: 5| Step: 9
Training loss: 0.9853681325912476
Validation loss: 2.0414379104491203

Epoch: 5| Step: 10
Training loss: 1.4592229127883911
Validation loss: 2.0529006245315715

Epoch: 647| Step: 0
Training loss: 1.5869354009628296
Validation loss: 2.0852983972077728

Epoch: 5| Step: 1
Training loss: 1.2862697839736938
Validation loss: 1.97943946238487

Epoch: 5| Step: 2
Training loss: 1.1859614849090576
Validation loss: 2.1228146655585176

Epoch: 5| Step: 3
Training loss: 1.051336646080017
Validation loss: 2.0549195351139193

Epoch: 5| Step: 4
Training loss: 1.1250571012496948
Validation loss: 2.086742449832219

Epoch: 5| Step: 5
Training loss: 1.5811537504196167
Validation loss: 2.078922453747001

Epoch: 5| Step: 6
Training loss: 1.0296293497085571
Validation loss: 2.0114991511068037

Epoch: 5| Step: 7
Training loss: 1.3498125076293945
Validation loss: 2.010039892247928

Epoch: 5| Step: 8
Training loss: 1.319165825843811
Validation loss: 2.0321028732484385

Epoch: 5| Step: 9
Training loss: 2.0217039585113525
Validation loss: 2.017679988697011

Epoch: 5| Step: 10
Training loss: 1.4893444776535034
Validation loss: 1.9960881638270553

Epoch: 648| Step: 0
Training loss: 1.334653615951538
Validation loss: 2.0268282531410136

Epoch: 5| Step: 1
Training loss: 1.7838709354400635
Validation loss: 2.0038980027680755

Epoch: 5| Step: 2
Training loss: 1.2762367725372314
Validation loss: 2.017041103814238

Epoch: 5| Step: 3
Training loss: 1.4853471517562866
Validation loss: 2.0493242740631104

Epoch: 5| Step: 4
Training loss: 0.9910480380058289
Validation loss: 1.9896729056553175

Epoch: 5| Step: 5
Training loss: 1.3025712966918945
Validation loss: 2.090944033797069

Epoch: 5| Step: 6
Training loss: 1.9388628005981445
Validation loss: 1.9944033571468887

Epoch: 5| Step: 7
Training loss: 1.2013099193572998
Validation loss: 2.1049410373933855

Epoch: 5| Step: 8
Training loss: 1.4557198286056519
Validation loss: 2.1276333729426065

Epoch: 5| Step: 9
Training loss: 1.3610613346099854
Validation loss: 2.106820168033723

Epoch: 5| Step: 10
Training loss: 1.1363164186477661
Validation loss: 2.0332403106074177

Epoch: 649| Step: 0
Training loss: 1.4481747150421143
Validation loss: 2.0930503363250406

Epoch: 5| Step: 1
Training loss: 1.3401700258255005
Validation loss: 2.0685969591140747

Epoch: 5| Step: 2
Training loss: 1.5393702983856201
Validation loss: 2.1168264753075055

Epoch: 5| Step: 3
Training loss: 1.6215622425079346
Validation loss: 2.076367014197893

Epoch: 5| Step: 4
Training loss: 1.837377905845642
Validation loss: 2.1024073528987106

Epoch: 5| Step: 5
Training loss: 1.3907620906829834
Validation loss: 2.0308023703995572

Epoch: 5| Step: 6
Training loss: 0.9959400296211243
Validation loss: 2.0027219890266337

Epoch: 5| Step: 7
Training loss: 1.423807144165039
Validation loss: 2.0370388159187893

Epoch: 5| Step: 8
Training loss: 1.1486934423446655
Validation loss: 2.020234851426976

Epoch: 5| Step: 9
Training loss: 1.0401662588119507
Validation loss: 2.145516303277785

Epoch: 5| Step: 10
Training loss: 1.3471529483795166
Validation loss: 2.0518713484528246

Epoch: 650| Step: 0
Training loss: 1.5025783777236938
Validation loss: 2.0721801814212593

Epoch: 5| Step: 1
Training loss: 1.6289781332015991
Validation loss: 2.004885309485979

Epoch: 5| Step: 2
Training loss: 1.0712170600891113
Validation loss: 1.9824493918367612

Epoch: 5| Step: 3
Training loss: 1.041203498840332
Validation loss: 2.1198319978611444

Epoch: 5| Step: 4
Training loss: 1.2628393173217773
Validation loss: 2.07959512869517

Epoch: 5| Step: 5
Training loss: 1.6645110845565796
Validation loss: 2.1374184162386003

Epoch: 5| Step: 6
Training loss: 1.1876137256622314
Validation loss: 2.0542441926976687

Epoch: 5| Step: 7
Training loss: 1.3857396841049194
Validation loss: 2.1042378384579896

Epoch: 5| Step: 8
Training loss: 1.671120047569275
Validation loss: 2.0968222002829275

Epoch: 5| Step: 9
Training loss: 1.4914419651031494
Validation loss: 2.0200080153762654

Epoch: 5| Step: 10
Training loss: 1.2894978523254395
Validation loss: 2.150958864919601

Epoch: 651| Step: 0
Training loss: 1.651942253112793
Validation loss: 2.100527399329729

Epoch: 5| Step: 1
Training loss: 1.1326866149902344
Validation loss: 2.1183026016399427

Epoch: 5| Step: 2
Training loss: 1.579116702079773
Validation loss: 2.0823738959527787

Epoch: 5| Step: 3
Training loss: 1.4075348377227783
Validation loss: 2.1041906238884054

Epoch: 5| Step: 4
Training loss: 1.0942152738571167
Validation loss: 2.0509730987651373

Epoch: 5| Step: 5
Training loss: 1.5465296506881714
Validation loss: 2.0624309714122484

Epoch: 5| Step: 6
Training loss: 1.70638906955719
Validation loss: 2.0313777269855624

Epoch: 5| Step: 7
Training loss: 1.3290473222732544
Validation loss: 1.9765489703865462

Epoch: 5| Step: 8
Training loss: 0.8224077224731445
Validation loss: 2.001273778177077

Epoch: 5| Step: 9
Training loss: 0.9325237274169922
Validation loss: 2.053436276733234

Epoch: 5| Step: 10
Training loss: 1.6627638339996338
Validation loss: 2.0393975755219818

Epoch: 652| Step: 0
Training loss: 1.4914296865463257
Validation loss: 2.114822854277908

Epoch: 5| Step: 1
Training loss: 1.2442688941955566
Validation loss: 2.0805662255133353

Epoch: 5| Step: 2
Training loss: 1.4442622661590576
Validation loss: 2.0383164690386866

Epoch: 5| Step: 3
Training loss: 2.111661911010742
Validation loss: 2.0242502381724696

Epoch: 5| Step: 4
Training loss: 1.255555510520935
Validation loss: 2.0515527468855663

Epoch: 5| Step: 5
Training loss: 1.3371028900146484
Validation loss: 2.05173667400114

Epoch: 5| Step: 6
Training loss: 1.7224029302597046
Validation loss: 2.0528548584189465

Epoch: 5| Step: 7
Training loss: 1.3154857158660889
Validation loss: 2.024602702868882

Epoch: 5| Step: 8
Training loss: 0.9029825329780579
Validation loss: 2.0824830121891473

Epoch: 5| Step: 9
Training loss: 1.3101909160614014
Validation loss: 2.0722981499087427

Epoch: 5| Step: 10
Training loss: 1.152446985244751
Validation loss: 2.1002670321413266

Epoch: 653| Step: 0
Training loss: 1.4970777034759521
Validation loss: 2.1087559858957925

Epoch: 5| Step: 1
Training loss: 1.1938396692276
Validation loss: 2.0977274781914166

Epoch: 5| Step: 2
Training loss: 0.6638307571411133
Validation loss: 2.0769368525474303

Epoch: 5| Step: 3
Training loss: 1.3774217367172241
Validation loss: 2.0736069704896662

Epoch: 5| Step: 4
Training loss: 1.4223440885543823
Validation loss: 2.0936813341673983

Epoch: 5| Step: 5
Training loss: 1.6722402572631836
Validation loss: 2.0955823954715522

Epoch: 5| Step: 6
Training loss: 1.0149873495101929
Validation loss: 2.067262872572868

Epoch: 5| Step: 7
Training loss: 1.7794058322906494
Validation loss: 1.9866069414282357

Epoch: 5| Step: 8
Training loss: 1.2032188177108765
Validation loss: 2.086677784560829

Epoch: 5| Step: 9
Training loss: 1.5357556343078613
Validation loss: 2.0440965429429085

Epoch: 5| Step: 10
Training loss: 1.4738826751708984
Validation loss: 2.0713813381810344

Epoch: 654| Step: 0
Training loss: 1.5236276388168335
Validation loss: 2.0671417328619186

Epoch: 5| Step: 1
Training loss: 1.0965526103973389
Validation loss: 2.092287045653148

Epoch: 5| Step: 2
Training loss: 0.9291973114013672
Validation loss: 2.126045716706143

Epoch: 5| Step: 3
Training loss: 0.9724637866020203
Validation loss: 2.0838479303544566

Epoch: 5| Step: 4
Training loss: 1.0355584621429443
Validation loss: 2.077795937497129

Epoch: 5| Step: 5
Training loss: 1.6322399377822876
Validation loss: 1.987646718179026

Epoch: 5| Step: 6
Training loss: 1.3426754474639893
Validation loss: 2.0385847706948557

Epoch: 5| Step: 7
Training loss: 1.7260758876800537
Validation loss: 2.078694564039989

Epoch: 5| Step: 8
Training loss: 1.308355689048767
Validation loss: 2.096066613351145

Epoch: 5| Step: 9
Training loss: 1.562280297279358
Validation loss: 2.0679203592320925

Epoch: 5| Step: 10
Training loss: 1.4779670238494873
Validation loss: 2.062377714341687

Epoch: 655| Step: 0
Training loss: 1.1143946647644043
Validation loss: 2.0195280454492055

Epoch: 5| Step: 1
Training loss: 1.5190598964691162
Validation loss: 2.0193841918822257

Epoch: 5| Step: 2
Training loss: 0.9312264323234558
Validation loss: 2.0660457585447576

Epoch: 5| Step: 3
Training loss: 2.1111512184143066
Validation loss: 2.040502006007779

Epoch: 5| Step: 4
Training loss: 0.9773421287536621
Validation loss: 2.057623653001683

Epoch: 5| Step: 5
Training loss: 1.6675478219985962
Validation loss: 2.0772984181680987

Epoch: 5| Step: 6
Training loss: 1.5793750286102295
Validation loss: 2.024552465766989

Epoch: 5| Step: 7
Training loss: 1.018018364906311
Validation loss: 2.0650756333463933

Epoch: 5| Step: 8
Training loss: 1.3960747718811035
Validation loss: 2.040200484696255

Epoch: 5| Step: 9
Training loss: 0.9821575880050659
Validation loss: 2.0450088875268095

Epoch: 5| Step: 10
Training loss: 2.0832912921905518
Validation loss: 2.0619179664119596

Epoch: 656| Step: 0
Training loss: 1.7746435403823853
Validation loss: 2.0520378953667096

Epoch: 5| Step: 1
Training loss: 1.4138672351837158
Validation loss: 2.0723741310898975

Epoch: 5| Step: 2
Training loss: 1.1289414167404175
Validation loss: 2.078686220671541

Epoch: 5| Step: 3
Training loss: 1.4285719394683838
Validation loss: 2.056152041240405

Epoch: 5| Step: 4
Training loss: 1.0306718349456787
Validation loss: 2.077190581188407

Epoch: 5| Step: 5
Training loss: 1.3730770349502563
Validation loss: 2.053904425713324

Epoch: 5| Step: 6
Training loss: 1.1019856929779053
Validation loss: 2.1693458992947816

Epoch: 5| Step: 7
Training loss: 1.81369948387146
Validation loss: 2.0819875629999305

Epoch: 5| Step: 8
Training loss: 1.2488412857055664
Validation loss: 2.05220139667552

Epoch: 5| Step: 9
Training loss: 1.3496928215026855
Validation loss: 1.982808005425238

Epoch: 5| Step: 10
Training loss: 1.2671549320220947
Validation loss: 2.0591925626159995

Epoch: 657| Step: 0
Training loss: 1.4706649780273438
Validation loss: 2.0747726296865814

Epoch: 5| Step: 1
Training loss: 1.353193759918213
Validation loss: 2.113323748752635

Epoch: 5| Step: 2
Training loss: 1.5283358097076416
Validation loss: 2.068123035533454

Epoch: 5| Step: 3
Training loss: 1.702014684677124
Validation loss: 2.0177101986382597

Epoch: 5| Step: 4
Training loss: 2.174377679824829
Validation loss: 2.026340807637861

Epoch: 5| Step: 5
Training loss: 1.0009009838104248
Validation loss: 2.0687781264705043

Epoch: 5| Step: 6
Training loss: 1.472080945968628
Validation loss: 2.0624708885787637

Epoch: 5| Step: 7
Training loss: 1.1115386486053467
Validation loss: 2.08527470660466

Epoch: 5| Step: 8
Training loss: 1.3597571849822998
Validation loss: 2.004960924066523

Epoch: 5| Step: 9
Training loss: 1.3396509885787964
Validation loss: 1.9878410203482515

Epoch: 5| Step: 10
Training loss: 0.7178863883018494
Validation loss: 2.020031811088644

Epoch: 658| Step: 0
Training loss: 1.3531893491744995
Validation loss: 2.0325974264452533

Epoch: 5| Step: 1
Training loss: 1.6321319341659546
Validation loss: 2.0543869695355816

Epoch: 5| Step: 2
Training loss: 1.2997782230377197
Validation loss: 2.0651683730463826

Epoch: 5| Step: 3
Training loss: 1.2756531238555908
Validation loss: 2.0674968201627015

Epoch: 5| Step: 4
Training loss: 1.2965247631072998
Validation loss: 2.0775826515689975

Epoch: 5| Step: 5
Training loss: 1.618090033531189
Validation loss: 2.092060842821675

Epoch: 5| Step: 6
Training loss: 0.9784738421440125
Validation loss: 2.0793299726260606

Epoch: 5| Step: 7
Training loss: 1.2241315841674805
Validation loss: 2.0683687630520073

Epoch: 5| Step: 8
Training loss: 1.8864930868148804
Validation loss: 2.1064611686173307

Epoch: 5| Step: 9
Training loss: 1.392592430114746
Validation loss: 2.042050145005667

Epoch: 5| Step: 10
Training loss: 0.9090980887413025
Validation loss: 2.1158491539698776

Epoch: 659| Step: 0
Training loss: 1.35621178150177
Validation loss: 2.111317011617845

Epoch: 5| Step: 1
Training loss: 1.2803218364715576
Validation loss: 2.0310850374160276

Epoch: 5| Step: 2
Training loss: 1.2975707054138184
Validation loss: 2.0647948224057435

Epoch: 5| Step: 3
Training loss: 1.3158903121948242
Validation loss: 2.022607958444985

Epoch: 5| Step: 4
Training loss: 1.8212066888809204
Validation loss: 2.0873905445939753

Epoch: 5| Step: 5
Training loss: 0.9711629152297974
Validation loss: 2.0427493805526407

Epoch: 5| Step: 6
Training loss: 1.6720685958862305
Validation loss: 2.102289431838579

Epoch: 5| Step: 7
Training loss: 1.4965931177139282
Validation loss: 2.036879671517239

Epoch: 5| Step: 8
Training loss: 1.0374354124069214
Validation loss: 2.053315503622896

Epoch: 5| Step: 9
Training loss: 1.1781551837921143
Validation loss: 2.0110006204215427

Epoch: 5| Step: 10
Training loss: 1.6321412324905396
Validation loss: 2.0045910881411646

Epoch: 660| Step: 0
Training loss: 1.0233027935028076
Validation loss: 2.069329236143379

Epoch: 5| Step: 1
Training loss: 1.3679918050765991
Validation loss: 1.9712132766682615

Epoch: 5| Step: 2
Training loss: 1.0520532131195068
Validation loss: 2.037775970274402

Epoch: 5| Step: 3
Training loss: 1.4404058456420898
Validation loss: 2.1102099213548886

Epoch: 5| Step: 4
Training loss: 1.3169002532958984
Validation loss: 2.021476517441452

Epoch: 5| Step: 5
Training loss: 1.6044143438339233
Validation loss: 2.049963208936876

Epoch: 5| Step: 6
Training loss: 1.6805435419082642
Validation loss: 2.0257114120709

Epoch: 5| Step: 7
Training loss: 1.2599726915359497
Validation loss: 2.1817399776110085

Epoch: 5| Step: 8
Training loss: 1.937543511390686
Validation loss: 2.035191717968192

Epoch: 5| Step: 9
Training loss: 1.0327788591384888
Validation loss: 2.0666927265864548

Epoch: 5| Step: 10
Training loss: 1.0189226865768433
Validation loss: 2.0904698641069475

Epoch: 661| Step: 0
Training loss: 1.0940823554992676
Validation loss: 2.013123530213551

Epoch: 5| Step: 1
Training loss: 1.5964189767837524
Validation loss: 2.0099458797003633

Epoch: 5| Step: 2
Training loss: 1.3440361022949219
Validation loss: 2.115883599045456

Epoch: 5| Step: 3
Training loss: 0.9824859499931335
Validation loss: 2.042047826192712

Epoch: 5| Step: 4
Training loss: 1.8273780345916748
Validation loss: 1.9944409452458864

Epoch: 5| Step: 5
Training loss: 1.715745210647583
Validation loss: 2.0500841474020355

Epoch: 5| Step: 6
Training loss: 1.2250075340270996
Validation loss: 2.065008560816447

Epoch: 5| Step: 7
Training loss: 1.2820745706558228
Validation loss: 2.0224309941773773

Epoch: 5| Step: 8
Training loss: 1.5398533344268799
Validation loss: 2.0786311857161985

Epoch: 5| Step: 9
Training loss: 1.0723594427108765
Validation loss: 2.054132197492866

Epoch: 5| Step: 10
Training loss: 1.2334736585617065
Validation loss: 2.049223308922142

Epoch: 662| Step: 0
Training loss: 1.0212767124176025
Validation loss: 2.001776223541588

Epoch: 5| Step: 1
Training loss: 1.1501622200012207
Validation loss: 2.0311267863037767

Epoch: 5| Step: 2
Training loss: 1.6330397129058838
Validation loss: 2.0429986317952475

Epoch: 5| Step: 3
Training loss: 1.2373249530792236
Validation loss: 2.0238533443020237

Epoch: 5| Step: 4
Training loss: 1.122287392616272
Validation loss: 2.0568826493396553

Epoch: 5| Step: 5
Training loss: 1.5990196466445923
Validation loss: 2.0565922375648253

Epoch: 5| Step: 6
Training loss: 1.1871864795684814
Validation loss: 2.147868953725343

Epoch: 5| Step: 7
Training loss: 2.3056492805480957
Validation loss: 2.007354400491202

Epoch: 5| Step: 8
Training loss: 0.8162788152694702
Validation loss: 2.0572010047974123

Epoch: 5| Step: 9
Training loss: 1.602052927017212
Validation loss: 2.123780591513521

Epoch: 5| Step: 10
Training loss: 1.1596533060073853
Validation loss: 2.0117540615861134

Epoch: 663| Step: 0
Training loss: 1.3079097270965576
Validation loss: 2.024847895868363

Epoch: 5| Step: 1
Training loss: 1.1428018808364868
Validation loss: 2.030754639256385

Epoch: 5| Step: 2
Training loss: 1.5427778959274292
Validation loss: 2.0606176109724146

Epoch: 5| Step: 3
Training loss: 1.2984453439712524
Validation loss: 2.040066444745628

Epoch: 5| Step: 4
Training loss: 1.2962678670883179
Validation loss: 2.010193914495489

Epoch: 5| Step: 5
Training loss: 0.8479059934616089
Validation loss: 1.993097266843242

Epoch: 5| Step: 6
Training loss: 1.1582647562026978
Validation loss: 2.118764759391867

Epoch: 5| Step: 7
Training loss: 1.951500654220581
Validation loss: 2.1130540127395303

Epoch: 5| Step: 8
Training loss: 1.2373191118240356
Validation loss: 2.0731173920375046

Epoch: 5| Step: 9
Training loss: 1.2897050380706787
Validation loss: 2.015954835440523

Epoch: 5| Step: 10
Training loss: 1.7199138402938843
Validation loss: 2.026572262087176

Epoch: 664| Step: 0
Training loss: 1.61501145362854
Validation loss: 1.9849362680988927

Epoch: 5| Step: 1
Training loss: 1.361153244972229
Validation loss: 2.0271107086571316

Epoch: 5| Step: 2
Training loss: 1.6434848308563232
Validation loss: 2.079675959002587

Epoch: 5| Step: 3
Training loss: 0.9444349408149719
Validation loss: 1.9860992059912732

Epoch: 5| Step: 4
Training loss: 1.2118853330612183
Validation loss: 2.049824076314126

Epoch: 5| Step: 5
Training loss: 1.8248933553695679
Validation loss: 2.054233563843594

Epoch: 5| Step: 6
Training loss: 1.2591744661331177
Validation loss: 2.1243555776534544

Epoch: 5| Step: 7
Training loss: 0.7269530296325684
Validation loss: 2.0565847478887087

Epoch: 5| Step: 8
Training loss: 1.644068717956543
Validation loss: 2.1005018295780307

Epoch: 5| Step: 9
Training loss: 0.9696367383003235
Validation loss: 2.10515494115891

Epoch: 5| Step: 10
Training loss: 1.6688400506973267
Validation loss: 2.1016248246674896

Epoch: 665| Step: 0
Training loss: 1.8814576864242554
Validation loss: 2.1123308622708885

Epoch: 5| Step: 1
Training loss: 1.1535742282867432
Validation loss: 2.1059600230186217

Epoch: 5| Step: 2
Training loss: 1.566592812538147
Validation loss: 2.0730816792416316

Epoch: 5| Step: 3
Training loss: 1.1248998641967773
Validation loss: 2.060380235795052

Epoch: 5| Step: 4
Training loss: 1.3136961460113525
Validation loss: 2.0390598953411145

Epoch: 5| Step: 5
Training loss: 0.8874239921569824
Validation loss: 2.06441895679761

Epoch: 5| Step: 6
Training loss: 1.1992839574813843
Validation loss: 2.069132492106448

Epoch: 5| Step: 7
Training loss: 1.5645701885223389
Validation loss: 2.113091271410706

Epoch: 5| Step: 8
Training loss: 1.1835089921951294
Validation loss: 2.008310453866118

Epoch: 5| Step: 9
Training loss: 1.4947277307510376
Validation loss: 2.044790783236104

Epoch: 5| Step: 10
Training loss: 1.3608390092849731
Validation loss: 2.0146282206299486

Epoch: 666| Step: 0
Training loss: 1.497795820236206
Validation loss: 2.075227952772571

Epoch: 5| Step: 1
Training loss: 1.0327928066253662
Validation loss: 2.0367579793417327

Epoch: 5| Step: 2
Training loss: 1.5030714273452759
Validation loss: 2.097687175196986

Epoch: 5| Step: 3
Training loss: 1.1116538047790527
Validation loss: 2.0600956563026673

Epoch: 5| Step: 4
Training loss: 1.4518547058105469
Validation loss: 1.994673026505337

Epoch: 5| Step: 5
Training loss: 0.9222939610481262
Validation loss: 2.1600109364396785

Epoch: 5| Step: 6
Training loss: 0.9275246858596802
Validation loss: 2.1022173486730105

Epoch: 5| Step: 7
Training loss: 1.8002128601074219
Validation loss: 2.0302529796477287

Epoch: 5| Step: 8
Training loss: 1.1290067434310913
Validation loss: 2.041403485882667

Epoch: 5| Step: 9
Training loss: 1.4072597026824951
Validation loss: 2.04867120199306

Epoch: 5| Step: 10
Training loss: 1.7232333421707153
Validation loss: 1.9842049588439286

Epoch: 667| Step: 0
Training loss: 1.1755419969558716
Validation loss: 2.068771476386696

Epoch: 5| Step: 1
Training loss: 1.4758632183074951
Validation loss: 2.0888726326727096

Epoch: 5| Step: 2
Training loss: 1.637859582901001
Validation loss: 2.038866235363868

Epoch: 5| Step: 3
Training loss: 1.8487972021102905
Validation loss: 2.03363569705717

Epoch: 5| Step: 4
Training loss: 0.9833399057388306
Validation loss: 2.069211088201051

Epoch: 5| Step: 5
Training loss: 1.3251397609710693
Validation loss: 2.00804235858302

Epoch: 5| Step: 6
Training loss: 1.2052005529403687
Validation loss: 2.081887278505551

Epoch: 5| Step: 7
Training loss: 1.0882536172866821
Validation loss: 1.973388889784454

Epoch: 5| Step: 8
Training loss: 0.8371065258979797
Validation loss: 2.035552872124539

Epoch: 5| Step: 9
Training loss: 1.8582735061645508
Validation loss: 2.1319160269152735

Epoch: 5| Step: 10
Training loss: 1.4577058553695679
Validation loss: 1.987054044200528

Epoch: 668| Step: 0
Training loss: 1.3195436000823975
Validation loss: 2.0460762400780954

Epoch: 5| Step: 1
Training loss: 1.5012521743774414
Validation loss: 2.0601077823228735

Epoch: 5| Step: 2
Training loss: 1.4855027198791504
Validation loss: 2.0001426255831154

Epoch: 5| Step: 3
Training loss: 0.8013885617256165
Validation loss: 2.0289500823584934

Epoch: 5| Step: 4
Training loss: 1.3011101484298706
Validation loss: 1.9993083553929483

Epoch: 5| Step: 5
Training loss: 0.9279192686080933
Validation loss: 2.070371038170271

Epoch: 5| Step: 6
Training loss: 0.9396018981933594
Validation loss: 2.0799723568783013

Epoch: 5| Step: 7
Training loss: 1.6172984838485718
Validation loss: 1.9877195845368087

Epoch: 5| Step: 8
Training loss: 1.6043485403060913
Validation loss: 2.0262257514461393

Epoch: 5| Step: 9
Training loss: 1.3663787841796875
Validation loss: 2.137013440491051

Epoch: 5| Step: 10
Training loss: 1.5004663467407227
Validation loss: 2.1189362951504287

Epoch: 669| Step: 0
Training loss: 1.7916526794433594
Validation loss: 2.0585246009211384

Epoch: 5| Step: 1
Training loss: 0.9842341542243958
Validation loss: 2.1267680762916483

Epoch: 5| Step: 2
Training loss: 1.729872703552246
Validation loss: 2.020575446467246

Epoch: 5| Step: 3
Training loss: 1.2849385738372803
Validation loss: 2.12054810472714

Epoch: 5| Step: 4
Training loss: 1.7306737899780273
Validation loss: 2.093905984714467

Epoch: 5| Step: 5
Training loss: 1.1143567562103271
Validation loss: 2.007337752208915

Epoch: 5| Step: 6
Training loss: 0.7189594507217407
Validation loss: 2.0611868853210122

Epoch: 5| Step: 7
Training loss: 1.7811939716339111
Validation loss: 2.0834828525461178

Epoch: 5| Step: 8
Training loss: 1.3617204427719116
Validation loss: 2.086657356190425

Epoch: 5| Step: 9
Training loss: 1.365679144859314
Validation loss: 2.0881443985046877

Epoch: 5| Step: 10
Training loss: 0.9731871485710144
Validation loss: 2.065718530326761

Epoch: 670| Step: 0
Training loss: 1.078808069229126
Validation loss: 2.065605987784683

Epoch: 5| Step: 1
Training loss: 1.4348331689834595
Validation loss: 2.0714779823057112

Epoch: 5| Step: 2
Training loss: 1.4195390939712524
Validation loss: 2.081988101364464

Epoch: 5| Step: 3
Training loss: 0.8783255815505981
Validation loss: 2.062618286378922

Epoch: 5| Step: 4
Training loss: 1.6551544666290283
Validation loss: 2.075131990576303

Epoch: 5| Step: 5
Training loss: 1.5325411558151245
Validation loss: 2.075479079318303

Epoch: 5| Step: 6
Training loss: 1.4658010005950928
Validation loss: 2.0526072479063466

Epoch: 5| Step: 7
Training loss: 1.3114609718322754
Validation loss: 2.1352378501687

Epoch: 5| Step: 8
Training loss: 1.5917446613311768
Validation loss: 2.059313956127372

Epoch: 5| Step: 9
Training loss: 1.310544729232788
Validation loss: 2.045426325131488

Epoch: 5| Step: 10
Training loss: 0.7245252132415771
Validation loss: 2.072757749147313

Epoch: 671| Step: 0
Training loss: 0.9401383399963379
Validation loss: 2.104744815057324

Epoch: 5| Step: 1
Training loss: 1.5386977195739746
Validation loss: 2.0816803183606876

Epoch: 5| Step: 2
Training loss: 0.9308745265007019
Validation loss: 2.049140404629451

Epoch: 5| Step: 3
Training loss: 0.9542086720466614
Validation loss: 2.1049574613571167

Epoch: 5| Step: 4
Training loss: 1.619909644126892
Validation loss: 2.1149224312074724

Epoch: 5| Step: 5
Training loss: 1.5093681812286377
Validation loss: 2.033532475912443

Epoch: 5| Step: 6
Training loss: 0.9509394764900208
Validation loss: 2.0675583039560625

Epoch: 5| Step: 7
Training loss: 1.5107635259628296
Validation loss: 2.0704941121480798

Epoch: 5| Step: 8
Training loss: 1.8602235317230225
Validation loss: 2.0853688755343036

Epoch: 5| Step: 9
Training loss: 1.7285754680633545
Validation loss: 2.0976723112085813

Epoch: 5| Step: 10
Training loss: 1.3361703157424927
Validation loss: 2.0802093090549594

Epoch: 672| Step: 0
Training loss: 1.0704776048660278
Validation loss: 2.0554364035206456

Epoch: 5| Step: 1
Training loss: 1.924829125404358
Validation loss: 2.0702470784546225

Epoch: 5| Step: 2
Training loss: 0.9482375979423523
Validation loss: 2.091272682271978

Epoch: 5| Step: 3
Training loss: 1.6697027683258057
Validation loss: 2.0834374696977678

Epoch: 5| Step: 4
Training loss: 0.8270570039749146
Validation loss: 2.0571623784239574

Epoch: 5| Step: 5
Training loss: 1.5301408767700195
Validation loss: 1.9983724522334274

Epoch: 5| Step: 6
Training loss: 1.1955430507659912
Validation loss: 2.028978934852026

Epoch: 5| Step: 7
Training loss: 1.7451175451278687
Validation loss: 2.05188879787281

Epoch: 5| Step: 8
Training loss: 1.485433578491211
Validation loss: 2.0666396912708076

Epoch: 5| Step: 9
Training loss: 1.0463430881500244
Validation loss: 2.018964566210265

Epoch: 5| Step: 10
Training loss: 1.3697190284729004
Validation loss: 2.107597097273796

Epoch: 673| Step: 0
Training loss: 1.9801082611083984
Validation loss: 2.010298800724809

Epoch: 5| Step: 1
Training loss: 1.4296238422393799
Validation loss: 1.971448116405036

Epoch: 5| Step: 2
Training loss: 1.029048204421997
Validation loss: 2.035545946449362

Epoch: 5| Step: 3
Training loss: 1.5275617837905884
Validation loss: 2.054768386707511

Epoch: 5| Step: 4
Training loss: 1.18233323097229
Validation loss: 2.0100703021531463

Epoch: 5| Step: 5
Training loss: 1.8396326303482056
Validation loss: 2.039544226020895

Epoch: 5| Step: 6
Training loss: 1.0640604496002197
Validation loss: 1.9544236147275535

Epoch: 5| Step: 7
Training loss: 1.3312207460403442
Validation loss: 2.0470399343839256

Epoch: 5| Step: 8
Training loss: 0.9525823593139648
Validation loss: 2.1135176830394293

Epoch: 5| Step: 9
Training loss: 0.9639915227890015
Validation loss: 2.08173470599677

Epoch: 5| Step: 10
Training loss: 1.0541621446609497
Validation loss: 2.01510254926579

Epoch: 674| Step: 0
Training loss: 1.3251683712005615
Validation loss: 2.0049823561022357

Epoch: 5| Step: 1
Training loss: 1.6717199087142944
Validation loss: 2.024604143634919

Epoch: 5| Step: 2
Training loss: 1.1105090379714966
Validation loss: 2.1001482240615355

Epoch: 5| Step: 3
Training loss: 1.6530907154083252
Validation loss: 2.034912842576222

Epoch: 5| Step: 4
Training loss: 1.004359483718872
Validation loss: 2.048295182566489

Epoch: 5| Step: 5
Training loss: 1.610055685043335
Validation loss: 2.0570792844218593

Epoch: 5| Step: 6
Training loss: 1.3435484170913696
Validation loss: 2.0595949554956086

Epoch: 5| Step: 7
Training loss: 1.1246243715286255
Validation loss: 2.0409940981095835

Epoch: 5| Step: 8
Training loss: 1.01166570186615
Validation loss: 2.0257625695197814

Epoch: 5| Step: 9
Training loss: 1.4878120422363281
Validation loss: 2.0783008811294392

Epoch: 5| Step: 10
Training loss: 1.1823164224624634
Validation loss: 2.1574172255813435

Epoch: 675| Step: 0
Training loss: 0.8040937185287476
Validation loss: 2.063180249224427

Epoch: 5| Step: 1
Training loss: 1.6779658794403076
Validation loss: 2.0009502698016424

Epoch: 5| Step: 2
Training loss: 1.7944145202636719
Validation loss: 2.166346493587699

Epoch: 5| Step: 3
Training loss: 1.4149798154830933
Validation loss: 2.009468622105096

Epoch: 5| Step: 4
Training loss: 1.2207300662994385
Validation loss: 2.0549312996607956

Epoch: 5| Step: 5
Training loss: 1.3314778804779053
Validation loss: 2.0591351139929985

Epoch: 5| Step: 6
Training loss: 1.40542471408844
Validation loss: 2.004196991202652

Epoch: 5| Step: 7
Training loss: 1.3071788549423218
Validation loss: 2.060623374036563

Epoch: 5| Step: 8
Training loss: 1.6157636642456055
Validation loss: 2.089953348200808

Epoch: 5| Step: 9
Training loss: 1.0402787923812866
Validation loss: 2.079198670643632

Epoch: 5| Step: 10
Training loss: 1.0401703119277954
Validation loss: 2.090383073335053

Epoch: 676| Step: 0
Training loss: 0.7952178120613098
Validation loss: 2.03243508133837

Epoch: 5| Step: 1
Training loss: 1.5927022695541382
Validation loss: 2.0875378424121487

Epoch: 5| Step: 2
Training loss: 1.1654263734817505
Validation loss: 2.0202461135002876

Epoch: 5| Step: 3
Training loss: 1.2738956212997437
Validation loss: 1.9763348653752317

Epoch: 5| Step: 4
Training loss: 1.0895140171051025
Validation loss: 2.107294331314743

Epoch: 5| Step: 5
Training loss: 1.3852598667144775
Validation loss: 2.091603943096694

Epoch: 5| Step: 6
Training loss: 1.2913343906402588
Validation loss: 2.1003007119701755

Epoch: 5| Step: 7
Training loss: 1.6960842609405518
Validation loss: 2.084593439614901

Epoch: 5| Step: 8
Training loss: 1.6509506702423096
Validation loss: 2.0722273524089525

Epoch: 5| Step: 9
Training loss: 1.430112600326538
Validation loss: 1.9789707532493017

Epoch: 5| Step: 10
Training loss: 1.2332494258880615
Validation loss: 2.1127888412885767

Epoch: 677| Step: 0
Training loss: 1.2017033100128174
Validation loss: 2.081559141476949

Epoch: 5| Step: 1
Training loss: 1.6083574295043945
Validation loss: 2.0710803219067153

Epoch: 5| Step: 2
Training loss: 1.2747732400894165
Validation loss: 2.0306564659200688

Epoch: 5| Step: 3
Training loss: 1.3659294843673706
Validation loss: 2.071154796948997

Epoch: 5| Step: 4
Training loss: 1.6194026470184326
Validation loss: 2.0667627396122104

Epoch: 5| Step: 5
Training loss: 1.3480358123779297
Validation loss: 2.09626095269316

Epoch: 5| Step: 6
Training loss: 1.103351354598999
Validation loss: 2.040877734461138

Epoch: 5| Step: 7
Training loss: 0.7961487770080566
Validation loss: 2.1184955463614514

Epoch: 5| Step: 8
Training loss: 1.1232268810272217
Validation loss: 2.0845677237356863

Epoch: 5| Step: 9
Training loss: 1.8396936655044556
Validation loss: 2.0112798034503894

Epoch: 5| Step: 10
Training loss: 1.0222676992416382
Validation loss: 2.069742839823487

Epoch: 678| Step: 0
Training loss: 1.4323514699935913
Validation loss: 2.05176906688239

Epoch: 5| Step: 1
Training loss: 1.8165180683135986
Validation loss: 2.0719959607688327

Epoch: 5| Step: 2
Training loss: 0.8407019376754761
Validation loss: 2.1376335646516536

Epoch: 5| Step: 3
Training loss: 1.3402470350265503
Validation loss: 2.0939632218371154

Epoch: 5| Step: 4
Training loss: 1.3216224908828735
Validation loss: 1.9863761073799544

Epoch: 5| Step: 5
Training loss: 1.1167017221450806
Validation loss: 2.109308878580729

Epoch: 5| Step: 6
Training loss: 1.6336790323257446
Validation loss: 2.048713912246048

Epoch: 5| Step: 7
Training loss: 0.9941970109939575
Validation loss: 2.017981142126104

Epoch: 5| Step: 8
Training loss: 1.1865732669830322
Validation loss: 2.0237660126019548

Epoch: 5| Step: 9
Training loss: 1.4174920320510864
Validation loss: 2.0219227575486705

Epoch: 5| Step: 10
Training loss: 1.4121545553207397
Validation loss: 2.0213515553423154

Epoch: 679| Step: 0
Training loss: 2.181687831878662
Validation loss: 2.0577211149277224

Epoch: 5| Step: 1
Training loss: 1.0914454460144043
Validation loss: 1.9896797031484625

Epoch: 5| Step: 2
Training loss: 1.1815463304519653
Validation loss: 1.9847699390944613

Epoch: 5| Step: 3
Training loss: 1.6146284341812134
Validation loss: 1.9964251966886624

Epoch: 5| Step: 4
Training loss: 0.8664779663085938
Validation loss: 2.00642143910931

Epoch: 5| Step: 5
Training loss: 1.0916550159454346
Validation loss: 2.0652215532077256

Epoch: 5| Step: 6
Training loss: 1.5364782810211182
Validation loss: 2.024538729780464

Epoch: 5| Step: 7
Training loss: 1.5572960376739502
Validation loss: 2.019520551927628

Epoch: 5| Step: 8
Training loss: 1.4292420148849487
Validation loss: 2.042715077759117

Epoch: 5| Step: 9
Training loss: 0.9038994908332825
Validation loss: 2.082426295485548

Epoch: 5| Step: 10
Training loss: 0.6243024468421936
Validation loss: 2.0999196806261615

Epoch: 680| Step: 0
Training loss: 1.5180509090423584
Validation loss: 2.0029923428771315

Epoch: 5| Step: 1
Training loss: 1.2281568050384521
Validation loss: 2.0769417478192236

Epoch: 5| Step: 2
Training loss: 1.0739048719406128
Validation loss: 2.0339178423727713

Epoch: 5| Step: 3
Training loss: 1.1470614671707153
Validation loss: 2.1486595728064097

Epoch: 5| Step: 4
Training loss: 1.3515361547470093
Validation loss: 2.1012278372241604

Epoch: 5| Step: 5
Training loss: 1.2467331886291504
Validation loss: 2.1144670927396385

Epoch: 5| Step: 6
Training loss: 2.0040135383605957
Validation loss: 2.116657136588968

Epoch: 5| Step: 7
Training loss: 1.3764303922653198
Validation loss: 2.0929213236736994

Epoch: 5| Step: 8
Training loss: 1.280827283859253
Validation loss: 2.0188691769876788

Epoch: 5| Step: 9
Training loss: 1.1424754858016968
Validation loss: 2.078637989618445

Epoch: 5| Step: 10
Training loss: 1.056869387626648
Validation loss: 2.0621910454124532

Epoch: 681| Step: 0
Training loss: 1.4750585556030273
Validation loss: 2.0228995174489994

Epoch: 5| Step: 1
Training loss: 1.3577476739883423
Validation loss: 2.044042738535071

Epoch: 5| Step: 2
Training loss: 1.1938899755477905
Validation loss: 1.9924490144175868

Epoch: 5| Step: 3
Training loss: 1.3325444459915161
Validation loss: 2.0155292454586236

Epoch: 5| Step: 4
Training loss: 1.3406803607940674
Validation loss: 2.023697773615519

Epoch: 5| Step: 5
Training loss: 1.3156709671020508
Validation loss: 2.0216770274664766

Epoch: 5| Step: 6
Training loss: 1.4427616596221924
Validation loss: 2.101140882379265

Epoch: 5| Step: 7
Training loss: 1.5427664518356323
Validation loss: 2.0591170454537995

Epoch: 5| Step: 8
Training loss: 1.2527555227279663
Validation loss: 2.0987066453503025

Epoch: 5| Step: 9
Training loss: 1.0181735754013062
Validation loss: 2.041089516814037

Epoch: 5| Step: 10
Training loss: 1.1193560361862183
Validation loss: 2.020962198575338

Epoch: 682| Step: 0
Training loss: 0.9347231984138489
Validation loss: 1.986838395877551

Epoch: 5| Step: 1
Training loss: 1.0239917039871216
Validation loss: 2.0510776119847454

Epoch: 5| Step: 2
Training loss: 1.087514877319336
Validation loss: 2.0590396311975296

Epoch: 5| Step: 3
Training loss: 1.0862367153167725
Validation loss: 2.020596674693528

Epoch: 5| Step: 4
Training loss: 1.7735668420791626
Validation loss: 2.0895731718309465

Epoch: 5| Step: 5
Training loss: 1.366736650466919
Validation loss: 2.065140119162939

Epoch: 5| Step: 6
Training loss: 1.5766903162002563
Validation loss: 2.018840875676883

Epoch: 5| Step: 7
Training loss: 1.6697769165039062
Validation loss: 1.9758161947291384

Epoch: 5| Step: 8
Training loss: 1.462208867073059
Validation loss: 2.0698654677278254

Epoch: 5| Step: 9
Training loss: 1.3425441980361938
Validation loss: 2.07508292377636

Epoch: 5| Step: 10
Training loss: 0.7482408881187439
Validation loss: 2.0610884235751246

Epoch: 683| Step: 0
Training loss: 0.9299243688583374
Validation loss: 2.027109730628229

Epoch: 5| Step: 1
Training loss: 1.561044692993164
Validation loss: 2.0202017753354964

Epoch: 5| Step: 2
Training loss: 1.3298118114471436
Validation loss: 2.091904863234489

Epoch: 5| Step: 3
Training loss: 1.7847964763641357
Validation loss: 2.0057395248002905

Epoch: 5| Step: 4
Training loss: 0.8676942586898804
Validation loss: 2.087991012040005

Epoch: 5| Step: 5
Training loss: 1.5692622661590576
Validation loss: 2.0132588122480657

Epoch: 5| Step: 6
Training loss: 1.7265170812606812
Validation loss: 2.037065908473025

Epoch: 5| Step: 7
Training loss: 1.0396502017974854
Validation loss: 2.024481201684603

Epoch: 5| Step: 8
Training loss: 1.3053910732269287
Validation loss: 2.0800897177829536

Epoch: 5| Step: 9
Training loss: 0.9691907167434692
Validation loss: 2.0563457217267764

Epoch: 5| Step: 10
Training loss: 1.4199615716934204
Validation loss: 2.0426997215517106

Epoch: 684| Step: 0
Training loss: 1.4039758443832397
Validation loss: 2.0249290158671718

Epoch: 5| Step: 1
Training loss: 1.4877493381500244
Validation loss: 2.069408380857078

Epoch: 5| Step: 2
Training loss: 1.6108696460723877
Validation loss: 2.0215477687056347

Epoch: 5| Step: 3
Training loss: 0.6731098294258118
Validation loss: 2.0853274612016577

Epoch: 5| Step: 4
Training loss: 1.7629541158676147
Validation loss: 2.058926587463707

Epoch: 5| Step: 5
Training loss: 1.473504662513733
Validation loss: 2.0583658474747852

Epoch: 5| Step: 6
Training loss: 0.9405811429023743
Validation loss: 2.03646513723558

Epoch: 5| Step: 7
Training loss: 1.5895192623138428
Validation loss: 2.0624491860789638

Epoch: 5| Step: 8
Training loss: 1.4053313732147217
Validation loss: 1.992448131243388

Epoch: 5| Step: 9
Training loss: 0.9155594706535339
Validation loss: 2.0624895749553556

Epoch: 5| Step: 10
Training loss: 0.8090766668319702
Validation loss: 2.0992695157245924

Epoch: 685| Step: 0
Training loss: 1.727460265159607
Validation loss: 2.0730829110709568

Epoch: 5| Step: 1
Training loss: 1.2784397602081299
Validation loss: 2.0762234682677896

Epoch: 5| Step: 2
Training loss: 1.3190157413482666
Validation loss: 2.10076299277685

Epoch: 5| Step: 3
Training loss: 1.1979619264602661
Validation loss: 2.074815914195071

Epoch: 5| Step: 4
Training loss: 0.7426877617835999
Validation loss: 2.0025254782810005

Epoch: 5| Step: 5
Training loss: 1.3718740940093994
Validation loss: 2.052869019969817

Epoch: 5| Step: 6
Training loss: 1.6983051300048828
Validation loss: 2.0466935019339285

Epoch: 5| Step: 7
Training loss: 0.9539695978164673
Validation loss: 2.0783702276086293

Epoch: 5| Step: 8
Training loss: 1.227310299873352
Validation loss: 2.033884613744674

Epoch: 5| Step: 9
Training loss: 1.7324514389038086
Validation loss: 2.0518629935479935

Epoch: 5| Step: 10
Training loss: 0.8310362696647644
Validation loss: 2.126177280179916

Epoch: 686| Step: 0
Training loss: 1.2737081050872803
Validation loss: 2.044269116975928

Epoch: 5| Step: 1
Training loss: 1.2608463764190674
Validation loss: 1.995581542291949

Epoch: 5| Step: 2
Training loss: 1.463910460472107
Validation loss: 1.9648458380852976

Epoch: 5| Step: 3
Training loss: 1.062403678894043
Validation loss: 2.0421387700624365

Epoch: 5| Step: 4
Training loss: 1.2929350137710571
Validation loss: 2.123658472491849

Epoch: 5| Step: 5
Training loss: 1.2165741920471191
Validation loss: 2.1105792894158313

Epoch: 5| Step: 6
Training loss: 1.1624066829681396
Validation loss: 2.005067676626226

Epoch: 5| Step: 7
Training loss: 1.6656726598739624
Validation loss: 1.9994957062505907

Epoch: 5| Step: 8
Training loss: 1.0533418655395508
Validation loss: 2.0395056650202763

Epoch: 5| Step: 9
Training loss: 1.517101526260376
Validation loss: 2.092122821397679

Epoch: 5| Step: 10
Training loss: 1.5679441690444946
Validation loss: 2.0572251004557454

Epoch: 687| Step: 0
Training loss: 1.2160372734069824
Validation loss: 2.041543981080414

Epoch: 5| Step: 1
Training loss: 1.3759804964065552
Validation loss: 2.0100596412535636

Epoch: 5| Step: 2
Training loss: 1.7630946636199951
Validation loss: 2.0724884745895222

Epoch: 5| Step: 3
Training loss: 1.3663339614868164
Validation loss: 2.0004652213024836

Epoch: 5| Step: 4
Training loss: 1.340552568435669
Validation loss: 2.055478888173257

Epoch: 5| Step: 5
Training loss: 1.1764051914215088
Validation loss: 2.0149391684480893

Epoch: 5| Step: 6
Training loss: 0.783331573009491
Validation loss: 2.066270979501868

Epoch: 5| Step: 7
Training loss: 1.2799948453903198
Validation loss: 2.049431635487464

Epoch: 5| Step: 8
Training loss: 1.4420596361160278
Validation loss: 2.076357715873308

Epoch: 5| Step: 9
Training loss: 1.1645792722702026
Validation loss: 2.0371073933057886

Epoch: 5| Step: 10
Training loss: 0.7970426082611084
Validation loss: 2.008938653494722

Epoch: 688| Step: 0
Training loss: 1.1804330348968506
Validation loss: 2.048288030009116

Epoch: 5| Step: 1
Training loss: 1.242828130722046
Validation loss: 2.054958857515807

Epoch: 5| Step: 2
Training loss: 1.4529085159301758
Validation loss: 2.0088380511089037

Epoch: 5| Step: 3
Training loss: 1.1719815731048584
Validation loss: 2.0603797589578936

Epoch: 5| Step: 4
Training loss: 1.537771224975586
Validation loss: 2.033977996918463

Epoch: 5| Step: 5
Training loss: 1.4294452667236328
Validation loss: 2.08759541280808

Epoch: 5| Step: 6
Training loss: 1.043556571006775
Validation loss: 2.0873555470538396

Epoch: 5| Step: 7
Training loss: 1.7393964529037476
Validation loss: 2.101878153380527

Epoch: 5| Step: 8
Training loss: 1.2862679958343506
Validation loss: 2.1042738012088242

Epoch: 5| Step: 9
Training loss: 0.9824008941650391
Validation loss: 2.036369172475671

Epoch: 5| Step: 10
Training loss: 1.144276738166809
Validation loss: 2.055157297401018

Epoch: 689| Step: 0
Training loss: 1.1607892513275146
Validation loss: 2.1352552188340055

Epoch: 5| Step: 1
Training loss: 1.102489948272705
Validation loss: 2.025366110186423

Epoch: 5| Step: 2
Training loss: 1.2529661655426025
Validation loss: 2.0172200177305486

Epoch: 5| Step: 3
Training loss: 1.58542799949646
Validation loss: 2.0515636756855953

Epoch: 5| Step: 4
Training loss: 0.997066855430603
Validation loss: 2.0038710717231996

Epoch: 5| Step: 5
Training loss: 1.3057477474212646
Validation loss: 2.005613088607788

Epoch: 5| Step: 6
Training loss: 1.25113844871521
Validation loss: 2.005166212717692

Epoch: 5| Step: 7
Training loss: 1.5493555068969727
Validation loss: 2.030195325933477

Epoch: 5| Step: 8
Training loss: 1.4688994884490967
Validation loss: 2.020171111629855

Epoch: 5| Step: 9
Training loss: 1.3027207851409912
Validation loss: 2.0435799873003395

Epoch: 5| Step: 10
Training loss: 1.3043179512023926
Validation loss: 2.039489883248524

Epoch: 690| Step: 0
Training loss: 1.3426506519317627
Validation loss: 2.062874050550563

Epoch: 5| Step: 1
Training loss: 1.131969690322876
Validation loss: 2.038474928948187

Epoch: 5| Step: 2
Training loss: 1.2302415370941162
Validation loss: 2.138783848413857

Epoch: 5| Step: 3
Training loss: 1.1623213291168213
Validation loss: 2.0359415956722793

Epoch: 5| Step: 4
Training loss: 1.0633996725082397
Validation loss: 2.108506284734254

Epoch: 5| Step: 5
Training loss: 1.948632001876831
Validation loss: 1.982734299475147

Epoch: 5| Step: 6
Training loss: 1.723435401916504
Validation loss: 1.9720439513524373

Epoch: 5| Step: 7
Training loss: 1.4958016872406006
Validation loss: 2.0732302537528415

Epoch: 5| Step: 8
Training loss: 1.271126389503479
Validation loss: 2.003822531751407

Epoch: 5| Step: 9
Training loss: 1.366379976272583
Validation loss: 2.100787414017544

Epoch: 5| Step: 10
Training loss: 1.1244630813598633
Validation loss: 2.077424023741035

Epoch: 691| Step: 0
Training loss: 1.310652732849121
Validation loss: 2.080661746763414

Epoch: 5| Step: 1
Training loss: 1.4331860542297363
Validation loss: 2.129542253350699

Epoch: 5| Step: 2
Training loss: 1.1515910625457764
Validation loss: 2.1954995893662974

Epoch: 5| Step: 3
Training loss: 1.4863512516021729
Validation loss: 2.139134145552112

Epoch: 5| Step: 4
Training loss: 1.06563138961792
Validation loss: 2.120430520785752

Epoch: 5| Step: 5
Training loss: 1.0416401624679565
Validation loss: 2.191869612663023

Epoch: 5| Step: 6
Training loss: 1.2099087238311768
Validation loss: 2.065931858554963

Epoch: 5| Step: 7
Training loss: 1.4782769680023193
Validation loss: 2.028629018414405

Epoch: 5| Step: 8
Training loss: 1.4306888580322266
Validation loss: 2.1556751548603015

Epoch: 5| Step: 9
Training loss: 1.4116885662078857
Validation loss: 2.133598037945327

Epoch: 5| Step: 10
Training loss: 1.8168878555297852
Validation loss: 2.102921252609581

Epoch: 692| Step: 0
Training loss: 1.5525929927825928
Validation loss: 2.050200746905419

Epoch: 5| Step: 1
Training loss: 1.4463268518447876
Validation loss: 2.054033533219368

Epoch: 5| Step: 2
Training loss: 1.7226556539535522
Validation loss: 2.081043322881063

Epoch: 5| Step: 3
Training loss: 1.4927148818969727
Validation loss: 2.0962118256476616

Epoch: 5| Step: 4
Training loss: 1.2590713500976562
Validation loss: 2.099348400228767

Epoch: 5| Step: 5
Training loss: 1.0279818773269653
Validation loss: 2.0452445989014

Epoch: 5| Step: 6
Training loss: 0.952816367149353
Validation loss: 2.0507110652103218

Epoch: 5| Step: 7
Training loss: 1.2616593837738037
Validation loss: 2.020796965527278

Epoch: 5| Step: 8
Training loss: 1.297127366065979
Validation loss: 2.0814912985729914

Epoch: 5| Step: 9
Training loss: 1.0832033157348633
Validation loss: 2.048286960970971

Epoch: 5| Step: 10
Training loss: 1.1310052871704102
Validation loss: 2.1155145578486945

Epoch: 693| Step: 0
Training loss: 0.6693533658981323
Validation loss: 2.069460074106852

Epoch: 5| Step: 1
Training loss: 1.359779953956604
Validation loss: 2.062827785809835

Epoch: 5| Step: 2
Training loss: 1.5350016355514526
Validation loss: 2.0002217523513304

Epoch: 5| Step: 3
Training loss: 1.0723161697387695
Validation loss: 2.073204501982658

Epoch: 5| Step: 4
Training loss: 1.360138177871704
Validation loss: 2.0549729588211223

Epoch: 5| Step: 5
Training loss: 1.0792624950408936
Validation loss: 2.068250915055634

Epoch: 5| Step: 6
Training loss: 1.1423115730285645
Validation loss: 2.052193062279814

Epoch: 5| Step: 7
Training loss: 1.7832235097885132
Validation loss: 2.147969812475225

Epoch: 5| Step: 8
Training loss: 1.1006155014038086
Validation loss: 1.9583226839701335

Epoch: 5| Step: 9
Training loss: 1.1966111660003662
Validation loss: 2.076471056989444

Epoch: 5| Step: 10
Training loss: 1.3892297744750977
Validation loss: 2.0522020478402414

Epoch: 694| Step: 0
Training loss: 1.1455187797546387
Validation loss: 2.0730738409103884

Epoch: 5| Step: 1
Training loss: 1.1817173957824707
Validation loss: 2.146281942244499

Epoch: 5| Step: 2
Training loss: 1.6718521118164062
Validation loss: 2.068598021743118

Epoch: 5| Step: 3
Training loss: 1.2186529636383057
Validation loss: 2.0948680113720637

Epoch: 5| Step: 4
Training loss: 1.5103795528411865
Validation loss: 2.067302037310857

Epoch: 5| Step: 5
Training loss: 1.3848521709442139
Validation loss: 2.0330377304425804

Epoch: 5| Step: 6
Training loss: 1.0670397281646729
Validation loss: 2.0634500095921178

Epoch: 5| Step: 7
Training loss: 0.9824978709220886
Validation loss: 2.1163287214053574

Epoch: 5| Step: 8
Training loss: 1.5233638286590576
Validation loss: 2.0859138299060125

Epoch: 5| Step: 9
Training loss: 1.2770792245864868
Validation loss: 2.0135097683116956

Epoch: 5| Step: 10
Training loss: 1.0415676832199097
Validation loss: 2.0876971085866294

Epoch: 695| Step: 0
Training loss: 1.6078506708145142
Validation loss: 2.055345268659694

Epoch: 5| Step: 1
Training loss: 1.4433283805847168
Validation loss: 2.1316257138406076

Epoch: 5| Step: 2
Training loss: 1.3894511461257935
Validation loss: 1.997956532304005

Epoch: 5| Step: 3
Training loss: 1.2318248748779297
Validation loss: 2.0923382389929985

Epoch: 5| Step: 4
Training loss: 1.3790907859802246
Validation loss: 2.0116298378154798

Epoch: 5| Step: 5
Training loss: 1.4902945756912231
Validation loss: 2.044559412105109

Epoch: 5| Step: 6
Training loss: 0.8029719591140747
Validation loss: 1.9737999746876378

Epoch: 5| Step: 7
Training loss: 1.5015089511871338
Validation loss: 2.024280722423266

Epoch: 5| Step: 8
Training loss: 1.0056512355804443
Validation loss: 2.0458791922497492

Epoch: 5| Step: 9
Training loss: 1.1250741481781006
Validation loss: 2.058539116254417

Epoch: 5| Step: 10
Training loss: 1.3822195529937744
Validation loss: 2.11775791516868

Epoch: 696| Step: 0
Training loss: 0.8034502267837524
Validation loss: 2.0427318721689205

Epoch: 5| Step: 1
Training loss: 0.8628606796264648
Validation loss: 2.0514448765785462

Epoch: 5| Step: 2
Training loss: 2.1404471397399902
Validation loss: 2.067551674381379

Epoch: 5| Step: 3
Training loss: 1.359496831893921
Validation loss: 2.0981299005528933

Epoch: 5| Step: 4
Training loss: 1.7294206619262695
Validation loss: 2.013847743311236

Epoch: 5| Step: 5
Training loss: 1.274559736251831
Validation loss: 2.0968873744369834

Epoch: 5| Step: 6
Training loss: 1.701041579246521
Validation loss: 2.0185497589008783

Epoch: 5| Step: 7
Training loss: 0.9870065450668335
Validation loss: 2.0202578178016086

Epoch: 5| Step: 8
Training loss: 0.8232433199882507
Validation loss: 2.020752469698588

Epoch: 5| Step: 9
Training loss: 1.2846250534057617
Validation loss: 1.9899007863895868

Epoch: 5| Step: 10
Training loss: 1.0302873849868774
Validation loss: 2.0388846166672243

Epoch: 697| Step: 0
Training loss: 1.2781398296356201
Validation loss: 2.104996532522222

Epoch: 5| Step: 1
Training loss: 1.0619748830795288
Validation loss: 2.0425547989465858

Epoch: 5| Step: 2
Training loss: 1.0881539583206177
Validation loss: 2.1136822444136425

Epoch: 5| Step: 3
Training loss: 1.3860176801681519
Validation loss: 2.056217498676751

Epoch: 5| Step: 4
Training loss: 0.8893994092941284
Validation loss: 2.150847816980013

Epoch: 5| Step: 5
Training loss: 1.0677316188812256
Validation loss: 2.1671455931919876

Epoch: 5| Step: 6
Training loss: 1.4237542152404785
Validation loss: 2.0810389928920294

Epoch: 5| Step: 7
Training loss: 1.3337332010269165
Validation loss: 2.012401005273224

Epoch: 5| Step: 8
Training loss: 1.2690937519073486
Validation loss: 2.0904060051005375

Epoch: 5| Step: 9
Training loss: 2.0754196643829346
Validation loss: 2.089575288116291

Epoch: 5| Step: 10
Training loss: 1.4407662153244019
Validation loss: 2.069339595815187

Epoch: 698| Step: 0
Training loss: 0.9978605508804321
Validation loss: 2.039768394603524

Epoch: 5| Step: 1
Training loss: 1.2032901048660278
Validation loss: 2.098423960388348

Epoch: 5| Step: 2
Training loss: 1.6071621179580688
Validation loss: 2.0452522334232124

Epoch: 5| Step: 3
Training loss: 1.0291101932525635
Validation loss: 2.0829856036811747

Epoch: 5| Step: 4
Training loss: 1.1180164813995361
Validation loss: 2.131427787965344

Epoch: 5| Step: 5
Training loss: 1.323608160018921
Validation loss: 2.0007106437478015

Epoch: 5| Step: 6
Training loss: 1.3090852499008179
Validation loss: 2.0792884454932263

Epoch: 5| Step: 7
Training loss: 1.4247239828109741
Validation loss: 2.033097090259675

Epoch: 5| Step: 8
Training loss: 1.1249324083328247
Validation loss: 2.0499470387735674

Epoch: 5| Step: 9
Training loss: 1.321495771408081
Validation loss: 2.006995106256136

Epoch: 5| Step: 10
Training loss: 1.5523996353149414
Validation loss: 2.039862422532933

Epoch: 699| Step: 0
Training loss: 1.3780673742294312
Validation loss: 2.0976775384718374

Epoch: 5| Step: 1
Training loss: 1.232940673828125
Validation loss: 2.0687389771143594

Epoch: 5| Step: 2
Training loss: 1.2963815927505493
Validation loss: 1.949927600481177

Epoch: 5| Step: 3
Training loss: 1.3774425983428955
Validation loss: 2.0692666781845914

Epoch: 5| Step: 4
Training loss: 1.2773668766021729
Validation loss: 2.0606836759915916

Epoch: 5| Step: 5
Training loss: 1.3443567752838135
Validation loss: 1.978545541404396

Epoch: 5| Step: 6
Training loss: 1.5252875089645386
Validation loss: 2.096525953662011

Epoch: 5| Step: 7
Training loss: 1.667865514755249
Validation loss: 2.0282820552907963

Epoch: 5| Step: 8
Training loss: 1.1040256023406982
Validation loss: 2.0760580429466824

Epoch: 5| Step: 9
Training loss: 0.9826563000679016
Validation loss: 2.089217934557187

Epoch: 5| Step: 10
Training loss: 1.340764045715332
Validation loss: 2.096365051884805

Epoch: 700| Step: 0
Training loss: 1.3378914594650269
Validation loss: 2.052447021648448

Epoch: 5| Step: 1
Training loss: 1.5367435216903687
Validation loss: 2.1279519373370754

Epoch: 5| Step: 2
Training loss: 1.2881319522857666
Validation loss: 2.1128541397792038

Epoch: 5| Step: 3
Training loss: 0.8522919416427612
Validation loss: 2.0742379221864926

Epoch: 5| Step: 4
Training loss: 0.9923674464225769
Validation loss: 2.0858172908906014

Epoch: 5| Step: 5
Training loss: 1.3385926485061646
Validation loss: 2.0972314009102444

Epoch: 5| Step: 6
Training loss: 1.7231509685516357
Validation loss: 2.1325965748038342

Epoch: 5| Step: 7
Training loss: 1.5202518701553345
Validation loss: 2.0709952897922967

Epoch: 5| Step: 8
Training loss: 0.8807042837142944
Validation loss: 2.058454933986869

Epoch: 5| Step: 9
Training loss: 1.0538207292556763
Validation loss: 2.1420950466586697

Epoch: 5| Step: 10
Training loss: 1.4038732051849365
Validation loss: 2.080718009702621

Testing loss: 2.0409131579928927
