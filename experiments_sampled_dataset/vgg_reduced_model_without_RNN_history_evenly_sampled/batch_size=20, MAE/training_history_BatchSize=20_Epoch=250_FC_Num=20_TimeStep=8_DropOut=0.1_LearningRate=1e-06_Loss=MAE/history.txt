Epoch: 1| Step: 0
Training loss: 6.9112067222595215
Validation loss: 7.60065496096047

Epoch: 5| Step: 1
Training loss: 7.034555912017822
Validation loss: 7.595566688045379

Epoch: 5| Step: 2
Training loss: 7.467255592346191
Validation loss: 7.5908099092463015

Epoch: 5| Step: 3
Training loss: 7.958319664001465
Validation loss: 7.5852469372492966

Epoch: 5| Step: 4
Training loss: 7.1308488845825195
Validation loss: 7.583401023700673

Epoch: 5| Step: 5
Training loss: 8.085554122924805
Validation loss: 7.57898610638034

Epoch: 5| Step: 6
Training loss: 6.769364833831787
Validation loss: 7.575531195568782

Epoch: 5| Step: 7
Training loss: 6.514821529388428
Validation loss: 7.5708602525854625

Epoch: 5| Step: 8
Training loss: 7.91610860824585
Validation loss: 7.5666419562473095

Epoch: 5| Step: 9
Training loss: 7.579319000244141
Validation loss: 7.563576359902659

Epoch: 5| Step: 10
Training loss: 7.842713356018066
Validation loss: 7.56096435875021

Epoch: 2| Step: 0
Training loss: 6.664676666259766
Validation loss: 7.556527635102631

Epoch: 5| Step: 1
Training loss: 6.9862060546875
Validation loss: 7.554184713671284

Epoch: 5| Step: 2
Training loss: 7.2578253746032715
Validation loss: 7.550748763545867

Epoch: 5| Step: 3
Training loss: 8.136866569519043
Validation loss: 7.546198403963479

Epoch: 5| Step: 4
Training loss: 6.933128356933594
Validation loss: 7.5439101906232935

Epoch: 5| Step: 5
Training loss: 7.783164978027344
Validation loss: 7.542630016162831

Epoch: 5| Step: 6
Training loss: 7.3538689613342285
Validation loss: 7.539287295392764

Epoch: 5| Step: 7
Training loss: 7.765358924865723
Validation loss: 7.5365620377243205

Epoch: 5| Step: 8
Training loss: 6.840764045715332
Validation loss: 7.53265324459281

Epoch: 5| Step: 9
Training loss: 7.516446113586426
Validation loss: 7.52853060794133

Epoch: 5| Step: 10
Training loss: 7.479358673095703
Validation loss: 7.5277001934666785

Epoch: 3| Step: 0
Training loss: 8.089983940124512
Validation loss: 7.52577176145328

Epoch: 5| Step: 1
Training loss: 7.147714138031006
Validation loss: 7.523044273417483

Epoch: 5| Step: 2
Training loss: 7.376246452331543
Validation loss: 7.517484828989993

Epoch: 5| Step: 3
Training loss: 7.757924556732178
Validation loss: 7.51769297610047

Epoch: 5| Step: 4
Training loss: 7.8578596115112305
Validation loss: 7.512237671882875

Epoch: 5| Step: 5
Training loss: 7.7215166091918945
Validation loss: 7.513313467784594

Epoch: 5| Step: 6
Training loss: 6.407569885253906
Validation loss: 7.509348218159009

Epoch: 5| Step: 7
Training loss: 7.415295600891113
Validation loss: 7.508136533921765

Epoch: 5| Step: 8
Training loss: 7.042508125305176
Validation loss: 7.505844844284878

Epoch: 5| Step: 9
Training loss: 6.5476179122924805
Validation loss: 7.503165383492747

Epoch: 5| Step: 10
Training loss: 6.966424942016602
Validation loss: 7.499669428794615

Epoch: 4| Step: 0
Training loss: 7.973682403564453
Validation loss: 7.498244952130062

Epoch: 5| Step: 1
Training loss: 8.065500259399414
Validation loss: 7.496897512866605

Epoch: 5| Step: 2
Training loss: 6.982375144958496
Validation loss: 7.493038777382143

Epoch: 5| Step: 3
Training loss: 7.191304683685303
Validation loss: 7.492566247140208

Epoch: 5| Step: 4
Training loss: 6.735433101654053
Validation loss: 7.488396490773847

Epoch: 5| Step: 5
Training loss: 6.682924747467041
Validation loss: 7.485548998719903

Epoch: 5| Step: 6
Training loss: 7.931972503662109
Validation loss: 7.485661937344458

Epoch: 5| Step: 7
Training loss: 7.1031293869018555
Validation loss: 7.482668763847761

Epoch: 5| Step: 8
Training loss: 6.954560279846191
Validation loss: 7.478854471637357

Epoch: 5| Step: 9
Training loss: 7.620907783508301
Validation loss: 7.476869193456507

Epoch: 5| Step: 10
Training loss: 6.739136695861816
Validation loss: 7.474258633070095

Epoch: 5| Step: 0
Training loss: 7.752516746520996
Validation loss: 7.473296309030184

Epoch: 5| Step: 1
Training loss: 7.0218305587768555
Validation loss: 7.469137555809431

Epoch: 5| Step: 2
Training loss: 7.3206987380981445
Validation loss: 7.467926558627878

Epoch: 5| Step: 3
Training loss: 6.927620887756348
Validation loss: 7.464232526799684

Epoch: 5| Step: 4
Training loss: 8.07468032836914
Validation loss: 7.460844896172964

Epoch: 5| Step: 5
Training loss: 6.716156959533691
Validation loss: 7.4579579445623585

Epoch: 5| Step: 6
Training loss: 7.55185604095459
Validation loss: 7.455485784879294

Epoch: 5| Step: 7
Training loss: 7.9604363441467285
Validation loss: 7.450772695643927

Epoch: 5| Step: 8
Training loss: 6.952113151550293
Validation loss: 7.448744804628434

Epoch: 5| Step: 9
Training loss: 6.777859687805176
Validation loss: 7.4480870513505835

Epoch: 5| Step: 10
Training loss: 6.6052985191345215
Validation loss: 7.442789959651168

Epoch: 6| Step: 0
Training loss: 6.35708475112915
Validation loss: 7.438725379205519

Epoch: 5| Step: 1
Training loss: 7.60799503326416
Validation loss: 7.437349001566569

Epoch: 5| Step: 2
Training loss: 7.590889930725098
Validation loss: 7.431790997905116

Epoch: 5| Step: 3
Training loss: 7.095726013183594
Validation loss: 7.432494681368592

Epoch: 5| Step: 4
Training loss: 7.42239236831665
Validation loss: 7.428597265674222

Epoch: 5| Step: 5
Training loss: 6.833505153656006
Validation loss: 7.425022156007828

Epoch: 5| Step: 6
Training loss: 7.3513665199279785
Validation loss: 7.422860996697539

Epoch: 5| Step: 7
Training loss: 6.405223846435547
Validation loss: 7.419079098650204

Epoch: 5| Step: 8
Training loss: 7.6368279457092285
Validation loss: 7.416101183942569

Epoch: 5| Step: 9
Training loss: 8.144796371459961
Validation loss: 7.413783719462733

Epoch: 5| Step: 10
Training loss: 6.902886867523193
Validation loss: 7.408288268632786

Epoch: 7| Step: 0
Training loss: 8.161251068115234
Validation loss: 7.4083048605149795

Epoch: 5| Step: 1
Training loss: 7.1233110427856445
Validation loss: 7.403059790211339

Epoch: 5| Step: 2
Training loss: 8.06823444366455
Validation loss: 7.397088819934476

Epoch: 5| Step: 3
Training loss: 7.801095008850098
Validation loss: 7.394273429788569

Epoch: 5| Step: 4
Training loss: 7.93612003326416
Validation loss: 7.389853021149994

Epoch: 5| Step: 5
Training loss: 7.140402793884277
Validation loss: 7.3899770962294715

Epoch: 5| Step: 6
Training loss: 7.778401851654053
Validation loss: 7.383557499095958

Epoch: 5| Step: 7
Training loss: 6.407189846038818
Validation loss: 7.380759582724623

Epoch: 5| Step: 8
Training loss: 6.1920366287231445
Validation loss: 7.375993472273632

Epoch: 5| Step: 9
Training loss: 5.711309432983398
Validation loss: 7.372984722096433

Epoch: 5| Step: 10
Training loss: 6.535336971282959
Validation loss: 7.3663681091800814

Epoch: 8| Step: 0
Training loss: 8.43722915649414
Validation loss: 7.362986559508949

Epoch: 5| Step: 1
Training loss: 6.494345188140869
Validation loss: 7.359957859080325

Epoch: 5| Step: 2
Training loss: 7.161747932434082
Validation loss: 7.3557519297445975

Epoch: 5| Step: 3
Training loss: 6.488104343414307
Validation loss: 7.350471527345719

Epoch: 5| Step: 4
Training loss: 7.945204257965088
Validation loss: 7.34533659104378

Epoch: 5| Step: 5
Training loss: 6.628934383392334
Validation loss: 7.3396056800760245

Epoch: 5| Step: 6
Training loss: 6.6777448654174805
Validation loss: 7.337070557378953

Epoch: 5| Step: 7
Training loss: 7.025738716125488
Validation loss: 7.331971794046382

Epoch: 5| Step: 8
Training loss: 7.339694976806641
Validation loss: 7.328483232887843

Epoch: 5| Step: 9
Training loss: 6.13663387298584
Validation loss: 7.321200909153108

Epoch: 5| Step: 10
Training loss: 8.25422477722168
Validation loss: 7.317361657337476

Epoch: 9| Step: 0
Training loss: 6.811166286468506
Validation loss: 7.313180077460505

Epoch: 5| Step: 1
Training loss: 6.9876389503479
Validation loss: 7.306166659119309

Epoch: 5| Step: 2
Training loss: 7.012232780456543
Validation loss: 7.303985708503313

Epoch: 5| Step: 3
Training loss: 7.701054573059082
Validation loss: 7.296963968584614

Epoch: 5| Step: 4
Training loss: 7.523190498352051
Validation loss: 7.293299705751481

Epoch: 5| Step: 5
Training loss: 6.695562839508057
Validation loss: 7.285740657519269

Epoch: 5| Step: 6
Training loss: 7.014179229736328
Validation loss: 7.27986289096135

Epoch: 5| Step: 7
Training loss: 6.309549808502197
Validation loss: 7.273419364806144

Epoch: 5| Step: 8
Training loss: 7.971805572509766
Validation loss: 7.270575979704498

Epoch: 5| Step: 9
Training loss: 6.475858211517334
Validation loss: 7.26760398187945

Epoch: 5| Step: 10
Training loss: 7.346965312957764
Validation loss: 7.258340240806661

Epoch: 10| Step: 0
Training loss: 7.73998498916626
Validation loss: 7.249734852903632

Epoch: 5| Step: 1
Training loss: 6.454653263092041
Validation loss: 7.247515668151199

Epoch: 5| Step: 2
Training loss: 6.678200721740723
Validation loss: 7.239046117310883

Epoch: 5| Step: 3
Training loss: 6.7122802734375
Validation loss: 7.232463380341889

Epoch: 5| Step: 4
Training loss: 7.166956901550293
Validation loss: 7.225895943180207

Epoch: 5| Step: 5
Training loss: 6.6536736488342285
Validation loss: 7.221571819756621

Epoch: 5| Step: 6
Training loss: 7.301558494567871
Validation loss: 7.216090468950169

Epoch: 5| Step: 7
Training loss: 7.289827823638916
Validation loss: 7.2089078195633425

Epoch: 5| Step: 8
Training loss: 7.614340305328369
Validation loss: 7.1991142354985715

Epoch: 5| Step: 9
Training loss: 6.481820583343506
Validation loss: 7.195988773017802

Epoch: 5| Step: 10
Training loss: 6.977867603302002
Validation loss: 7.184671463504914

Epoch: 11| Step: 0
Training loss: 6.2799296379089355
Validation loss: 7.180231325088009

Epoch: 5| Step: 1
Training loss: 7.482702732086182
Validation loss: 7.171990286919378

Epoch: 5| Step: 2
Training loss: 6.854540824890137
Validation loss: 7.160749773825368

Epoch: 5| Step: 3
Training loss: 7.193819522857666
Validation loss: 7.15212183613931

Epoch: 5| Step: 4
Training loss: 6.940522193908691
Validation loss: 7.145547697621007

Epoch: 5| Step: 5
Training loss: 6.726043701171875
Validation loss: 7.139949762693015

Epoch: 5| Step: 6
Training loss: 6.962146759033203
Validation loss: 7.129890708513157

Epoch: 5| Step: 7
Training loss: 6.797162055969238
Validation loss: 7.1212684672365905

Epoch: 5| Step: 8
Training loss: 6.105389595031738
Validation loss: 7.112923022239439

Epoch: 5| Step: 9
Training loss: 7.125280857086182
Validation loss: 7.103657840400614

Epoch: 5| Step: 10
Training loss: 7.804284572601318
Validation loss: 7.097180407534363

Epoch: 12| Step: 0
Training loss: 7.328765869140625
Validation loss: 7.085051736524028

Epoch: 5| Step: 1
Training loss: 6.392947196960449
Validation loss: 7.082095356397732

Epoch: 5| Step: 2
Training loss: 5.991213321685791
Validation loss: 7.070289129851966

Epoch: 5| Step: 3
Training loss: 6.810729026794434
Validation loss: 7.056050895362772

Epoch: 5| Step: 4
Training loss: 5.591482639312744
Validation loss: 7.0469766278420725

Epoch: 5| Step: 5
Training loss: 6.71450662612915
Validation loss: 7.037858363120787

Epoch: 5| Step: 6
Training loss: 7.75930118560791
Validation loss: 7.020427739748391

Epoch: 5| Step: 7
Training loss: 7.112127780914307
Validation loss: 7.014681129045384

Epoch: 5| Step: 8
Training loss: 8.175751686096191
Validation loss: 7.005318826244723

Epoch: 5| Step: 9
Training loss: 6.863503932952881
Validation loss: 6.995010099103374

Epoch: 5| Step: 10
Training loss: 6.110973358154297
Validation loss: 6.981148837715067

Epoch: 13| Step: 0
Training loss: 6.420143127441406
Validation loss: 6.96934005778323

Epoch: 5| Step: 1
Training loss: 6.853686332702637
Validation loss: 6.957506943774479

Epoch: 5| Step: 2
Training loss: 6.475381374359131
Validation loss: 6.952296410837481

Epoch: 5| Step: 3
Training loss: 6.9854416847229
Validation loss: 6.9367414905178935

Epoch: 5| Step: 4
Training loss: 6.652671813964844
Validation loss: 6.930263339832265

Epoch: 5| Step: 5
Training loss: 6.713045597076416
Validation loss: 6.915295908527989

Epoch: 5| Step: 6
Training loss: 6.699832916259766
Validation loss: 6.905928693791871

Epoch: 5| Step: 7
Training loss: 6.827568054199219
Validation loss: 6.887581404819284

Epoch: 5| Step: 8
Training loss: 6.435830116271973
Validation loss: 6.876354494402485

Epoch: 5| Step: 9
Training loss: 7.15773868560791
Validation loss: 6.871196172570669

Epoch: 5| Step: 10
Training loss: 6.28735876083374
Validation loss: 6.850781645826114

Epoch: 14| Step: 0
Training loss: 6.0395283699035645
Validation loss: 6.84381111719275

Epoch: 5| Step: 1
Training loss: 7.862285614013672
Validation loss: 6.827818239888837

Epoch: 5| Step: 2
Training loss: 6.594013214111328
Validation loss: 6.820520811183478

Epoch: 5| Step: 3
Training loss: 7.100644588470459
Validation loss: 6.8035639844914915

Epoch: 5| Step: 4
Training loss: 5.583161354064941
Validation loss: 6.784947118451519

Epoch: 5| Step: 5
Training loss: 6.300283908843994
Validation loss: 6.776163055050757

Epoch: 5| Step: 6
Training loss: 7.085145473480225
Validation loss: 6.7682115903464695

Epoch: 5| Step: 7
Training loss: 5.658303737640381
Validation loss: 6.749526223828716

Epoch: 5| Step: 8
Training loss: 7.365666389465332
Validation loss: 6.736787006419192

Epoch: 5| Step: 9
Training loss: 6.381688117980957
Validation loss: 6.719873530890352

Epoch: 5| Step: 10
Training loss: 6.001993656158447
Validation loss: 6.706298371796967

Epoch: 15| Step: 0
Training loss: 5.430856704711914
Validation loss: 6.698509600854689

Epoch: 5| Step: 1
Training loss: 7.2395734786987305
Validation loss: 6.680182928680091

Epoch: 5| Step: 2
Training loss: 7.194240570068359
Validation loss: 6.664804658582134

Epoch: 5| Step: 3
Training loss: 5.677006721496582
Validation loss: 6.646408742473971

Epoch: 5| Step: 4
Training loss: 5.76470422744751
Validation loss: 6.635848834950437

Epoch: 5| Step: 5
Training loss: 6.308930397033691
Validation loss: 6.623230836724722

Epoch: 5| Step: 6
Training loss: 7.207525730133057
Validation loss: 6.604197322681386

Epoch: 5| Step: 7
Training loss: 5.788729190826416
Validation loss: 6.588353392898395

Epoch: 5| Step: 8
Training loss: 6.661872863769531
Validation loss: 6.575253025177987

Epoch: 5| Step: 9
Training loss: 6.563900947570801
Validation loss: 6.558298598053635

Epoch: 5| Step: 10
Training loss: 6.426403999328613
Validation loss: 6.539286987755888

Epoch: 16| Step: 0
Training loss: 6.761192321777344
Validation loss: 6.52700618005568

Epoch: 5| Step: 1
Training loss: 6.3402204513549805
Validation loss: 6.505486985688568

Epoch: 5| Step: 2
Training loss: 5.778695583343506
Validation loss: 6.48875565682688

Epoch: 5| Step: 3
Training loss: 6.816579341888428
Validation loss: 6.472004075204173

Epoch: 5| Step: 4
Training loss: 6.15615177154541
Validation loss: 6.459003284413328

Epoch: 5| Step: 5
Training loss: 6.609435081481934
Validation loss: 6.441157382021668

Epoch: 5| Step: 6
Training loss: 6.192095756530762
Validation loss: 6.421398034659765

Epoch: 5| Step: 7
Training loss: 5.671983242034912
Validation loss: 6.410360690086119

Epoch: 5| Step: 8
Training loss: 6.437619686126709
Validation loss: 6.385879855002126

Epoch: 5| Step: 9
Training loss: 6.329270839691162
Validation loss: 6.370387779769077

Epoch: 5| Step: 10
Training loss: 4.949731826782227
Validation loss: 6.347262628616825

Epoch: 17| Step: 0
Training loss: 5.173313617706299
Validation loss: 6.332832136461811

Epoch: 5| Step: 1
Training loss: 5.533660888671875
Validation loss: 6.313130040322581

Epoch: 5| Step: 2
Training loss: 5.264538764953613
Validation loss: 6.293743179690454

Epoch: 5| Step: 3
Training loss: 5.466207027435303
Validation loss: 6.276275516838155

Epoch: 5| Step: 4
Training loss: 6.234745979309082
Validation loss: 6.257169436382991

Epoch: 5| Step: 5
Training loss: 6.663714408874512
Validation loss: 6.231705829661379

Epoch: 5| Step: 6
Training loss: 5.72976016998291
Validation loss: 6.211089964835875

Epoch: 5| Step: 7
Training loss: 5.429656028747559
Validation loss: 6.197752368065618

Epoch: 5| Step: 8
Training loss: 8.065539360046387
Validation loss: 6.173880520687308

Epoch: 5| Step: 9
Training loss: 6.395636081695557
Validation loss: 6.154842945837205

Epoch: 5| Step: 10
Training loss: 5.971442222595215
Validation loss: 6.128092509444042

Epoch: 18| Step: 0
Training loss: 5.647228240966797
Validation loss: 6.108900629064088

Epoch: 5| Step: 1
Training loss: 6.83165979385376
Validation loss: 6.092750098115655

Epoch: 5| Step: 2
Training loss: 5.832367897033691
Validation loss: 6.072668378071119

Epoch: 5| Step: 3
Training loss: 5.681368350982666
Validation loss: 6.040663334631151

Epoch: 5| Step: 4
Training loss: 6.135374069213867
Validation loss: 6.024190584818522

Epoch: 5| Step: 5
Training loss: 6.96164608001709
Validation loss: 6.004573319547919

Epoch: 5| Step: 6
Training loss: 6.834107398986816
Validation loss: 5.9789280276144705

Epoch: 5| Step: 7
Training loss: 4.440291404724121
Validation loss: 5.954633153894896

Epoch: 5| Step: 8
Training loss: 5.378139972686768
Validation loss: 5.928412914276123

Epoch: 5| Step: 9
Training loss: 4.760138511657715
Validation loss: 5.906139917271112

Epoch: 5| Step: 10
Training loss: 4.544488430023193
Validation loss: 5.872626622517903

Epoch: 19| Step: 0
Training loss: 4.536585807800293
Validation loss: 5.857540843307331

Epoch: 5| Step: 1
Training loss: 5.888967514038086
Validation loss: 5.8310244211586575

Epoch: 5| Step: 2
Training loss: 6.501065254211426
Validation loss: 5.810568727472777

Epoch: 5| Step: 3
Training loss: 4.346391201019287
Validation loss: 5.78350180451588

Epoch: 5| Step: 4
Training loss: 6.605608940124512
Validation loss: 5.75523518490535

Epoch: 5| Step: 5
Training loss: 4.454405307769775
Validation loss: 5.729451415359333

Epoch: 5| Step: 6
Training loss: 5.679124355316162
Validation loss: 5.712902376728673

Epoch: 5| Step: 7
Training loss: 5.839951515197754
Validation loss: 5.68118320485597

Epoch: 5| Step: 8
Training loss: 5.790740966796875
Validation loss: 5.646386500327818

Epoch: 5| Step: 9
Training loss: 5.449648380279541
Validation loss: 5.615506105525519

Epoch: 5| Step: 10
Training loss: 5.086193561553955
Validation loss: 5.593260713802871

Epoch: 20| Step: 0
Training loss: 4.673844814300537
Validation loss: 5.559705272797616

Epoch: 5| Step: 1
Training loss: 5.5026445388793945
Validation loss: 5.5393334716878915

Epoch: 5| Step: 2
Training loss: 5.191799163818359
Validation loss: 5.505569627208095

Epoch: 5| Step: 3
Training loss: 5.85175085067749
Validation loss: 5.482082725853048

Epoch: 5| Step: 4
Training loss: 4.716076850891113
Validation loss: 5.448969987130934

Epoch: 5| Step: 5
Training loss: 4.946608543395996
Validation loss: 5.423484530500186

Epoch: 5| Step: 6
Training loss: 5.0135369300842285
Validation loss: 5.39079624606717

Epoch: 5| Step: 7
Training loss: 5.013422012329102
Validation loss: 5.363513551732545

Epoch: 5| Step: 8
Training loss: 5.752628803253174
Validation loss: 5.3229984519302205

Epoch: 5| Step: 9
Training loss: 5.169032096862793
Validation loss: 5.2989383051472325

Epoch: 5| Step: 10
Training loss: 4.677943706512451
Validation loss: 5.255661451688376

Epoch: 21| Step: 0
Training loss: 5.870345592498779
Validation loss: 5.232417024591918

Epoch: 5| Step: 1
Training loss: 5.0169677734375
Validation loss: 5.187403801948793

Epoch: 5| Step: 2
Training loss: 5.213196754455566
Validation loss: 5.163874041649603

Epoch: 5| Step: 3
Training loss: 5.262015342712402
Validation loss: 5.128597641503939

Epoch: 5| Step: 4
Training loss: 4.095076560974121
Validation loss: 5.098487833494781

Epoch: 5| Step: 5
Training loss: 3.285215377807617
Validation loss: 5.0633922597413425

Epoch: 5| Step: 6
Training loss: 4.97076940536499
Validation loss: 5.0144016153068955

Epoch: 5| Step: 7
Training loss: 4.956362724304199
Validation loss: 4.991656349551294

Epoch: 5| Step: 8
Training loss: 5.272214412689209
Validation loss: 4.951630689764536

Epoch: 5| Step: 9
Training loss: 4.4995317459106445
Validation loss: 4.912108580271403

Epoch: 5| Step: 10
Training loss: 4.16393518447876
Validation loss: 4.8974035222043275

Epoch: 22| Step: 0
Training loss: 4.052787780761719
Validation loss: 4.841551350009057

Epoch: 5| Step: 1
Training loss: 4.095498561859131
Validation loss: 4.813551984807496

Epoch: 5| Step: 2
Training loss: 4.69401216506958
Validation loss: 4.771452365383025

Epoch: 5| Step: 3
Training loss: 3.915695905685425
Validation loss: 4.739435759923792

Epoch: 5| Step: 4
Training loss: 5.031738758087158
Validation loss: 4.6968939791443525

Epoch: 5| Step: 5
Training loss: 5.339613914489746
Validation loss: 4.666286007050545

Epoch: 5| Step: 6
Training loss: 3.8865134716033936
Validation loss: 4.631209819547592

Epoch: 5| Step: 7
Training loss: 4.68540096282959
Validation loss: 4.584595736636911

Epoch: 5| Step: 8
Training loss: 3.615767002105713
Validation loss: 4.5552623348851355

Epoch: 5| Step: 9
Training loss: 4.46143102645874
Validation loss: 4.524225117057882

Epoch: 5| Step: 10
Training loss: 4.789198398590088
Validation loss: 4.474259596998974

Epoch: 23| Step: 0
Training loss: 4.2671217918396
Validation loss: 4.4387273429542455

Epoch: 5| Step: 1
Training loss: 4.322783470153809
Validation loss: 4.388929864411713

Epoch: 5| Step: 2
Training loss: 3.970613479614258
Validation loss: 4.35184916116858

Epoch: 5| Step: 3
Training loss: 4.378054618835449
Validation loss: 4.315431387193741

Epoch: 5| Step: 4
Training loss: 3.0881199836730957
Validation loss: 4.271480821794079

Epoch: 5| Step: 5
Training loss: 4.13430643081665
Validation loss: 4.240893512643794

Epoch: 5| Step: 6
Training loss: 4.509799003601074
Validation loss: 4.190118517926944

Epoch: 5| Step: 7
Training loss: 3.972482204437256
Validation loss: 4.1716515889731784

Epoch: 5| Step: 8
Training loss: 4.700915813446045
Validation loss: 4.118859793550225

Epoch: 5| Step: 9
Training loss: 2.6589369773864746
Validation loss: 4.070281677348639

Epoch: 5| Step: 10
Training loss: 4.25160026550293
Validation loss: 4.0371730917243545

Epoch: 24| Step: 0
Training loss: 3.754241466522217
Validation loss: 4.025549755301527

Epoch: 5| Step: 1
Training loss: 3.747586488723755
Validation loss: 3.9851383650174705

Epoch: 5| Step: 2
Training loss: 4.079511642456055
Validation loss: 3.9338064783362934

Epoch: 5| Step: 3
Training loss: 3.843883514404297
Validation loss: 3.9062142269585722

Epoch: 5| Step: 4
Training loss: 3.949651002883911
Validation loss: 3.855567055363809

Epoch: 5| Step: 5
Training loss: 3.7670745849609375
Validation loss: 3.831128881823632

Epoch: 5| Step: 6
Training loss: 2.676628828048706
Validation loss: 3.782785564340571

Epoch: 5| Step: 7
Training loss: 4.313013076782227
Validation loss: 3.744025609826529

Epoch: 5| Step: 8
Training loss: 3.0624899864196777
Validation loss: 3.720593462708176

Epoch: 5| Step: 9
Training loss: 3.241453170776367
Validation loss: 3.6711373124071347

Epoch: 5| Step: 10
Training loss: 3.8571908473968506
Validation loss: 3.6294338446791454

Epoch: 25| Step: 0
Training loss: 4.107697486877441
Validation loss: 3.6077122226838143

Epoch: 5| Step: 1
Training loss: 3.0072262287139893
Validation loss: 3.5645031698288454

Epoch: 5| Step: 2
Training loss: 3.6029109954833984
Validation loss: 3.5219328788018998

Epoch: 5| Step: 3
Training loss: 3.0661227703094482
Validation loss: 3.47626095433389

Epoch: 5| Step: 4
Training loss: 3.392369508743286
Validation loss: 3.446905994928011

Epoch: 5| Step: 5
Training loss: 2.5323333740234375
Validation loss: 3.429089525694488

Epoch: 5| Step: 6
Training loss: 3.5308761596679688
Validation loss: 3.389702438026346

Epoch: 5| Step: 7
Training loss: 3.4830050468444824
Validation loss: 3.3517585723630843

Epoch: 5| Step: 8
Training loss: 2.6985793113708496
Validation loss: 3.345106271005446

Epoch: 5| Step: 9
Training loss: 3.6247448921203613
Validation loss: 3.29017900395137

Epoch: 5| Step: 10
Training loss: 3.552804708480835
Validation loss: 3.2434742758350987

Epoch: 26| Step: 0
Training loss: 3.870962619781494
Validation loss: 3.226034166992352

Epoch: 5| Step: 1
Training loss: 3.4413199424743652
Validation loss: 3.1879189296435286

Epoch: 5| Step: 2
Training loss: 2.399890422821045
Validation loss: 3.1658310890197754

Epoch: 5| Step: 3
Training loss: 3.6614317893981934
Validation loss: 3.1447061928369666

Epoch: 5| Step: 4
Training loss: 2.7031843662261963
Validation loss: 3.100976221023067

Epoch: 5| Step: 5
Training loss: 2.9125418663024902
Validation loss: 3.1010611877646497

Epoch: 5| Step: 6
Training loss: 3.280376434326172
Validation loss: 3.0633502621804514

Epoch: 5| Step: 7
Training loss: 3.538590908050537
Validation loss: 3.0455467136957313

Epoch: 5| Step: 8
Training loss: 2.58011531829834
Validation loss: 2.9927341758563952

Epoch: 5| Step: 9
Training loss: 3.0500261783599854
Validation loss: 2.9797578280971897

Epoch: 5| Step: 10
Training loss: 2.563208818435669
Validation loss: 2.968353671412314

Epoch: 27| Step: 0
Training loss: 3.0825443267822266
Validation loss: 2.913389439223915

Epoch: 5| Step: 1
Training loss: 3.091599941253662
Validation loss: 2.9158339679882093

Epoch: 5| Step: 2
Training loss: 2.0999577045440674
Validation loss: 2.8858328019419024

Epoch: 5| Step: 3
Training loss: 2.9011635780334473
Validation loss: 2.862561438673286

Epoch: 5| Step: 4
Training loss: 3.5580291748046875
Validation loss: 2.835737059193273

Epoch: 5| Step: 5
Training loss: 3.613649845123291
Validation loss: 2.8464571686201197

Epoch: 5| Step: 6
Training loss: 2.8289010524749756
Validation loss: 2.805439959290207

Epoch: 5| Step: 7
Training loss: 2.571767568588257
Validation loss: 2.7758898658137166

Epoch: 5| Step: 8
Training loss: 2.770176649093628
Validation loss: 2.7849059386919905

Epoch: 5| Step: 9
Training loss: 3.455469846725464
Validation loss: 2.759759085152739

Epoch: 5| Step: 10
Training loss: 1.9284464120864868
Validation loss: 2.743223974781652

Epoch: 28| Step: 0
Training loss: 2.6672136783599854
Validation loss: 2.7159777149077384

Epoch: 5| Step: 1
Training loss: 3.622138500213623
Validation loss: 2.66450067745742

Epoch: 5| Step: 2
Training loss: 2.8001644611358643
Validation loss: 2.6649521294460503

Epoch: 5| Step: 3
Training loss: 2.546480178833008
Validation loss: 2.6461503941525697

Epoch: 5| Step: 4
Training loss: 2.628479242324829
Validation loss: 2.6278497224212973

Epoch: 5| Step: 5
Training loss: 2.8264613151550293
Validation loss: 2.6042564761254097

Epoch: 5| Step: 6
Training loss: 2.9016292095184326
Validation loss: 2.5779094978045394

Epoch: 5| Step: 7
Training loss: 2.206618070602417
Validation loss: 2.5579557470096055

Epoch: 5| Step: 8
Training loss: 2.95563006401062
Validation loss: 2.5583578296886977

Epoch: 5| Step: 9
Training loss: 3.272106885910034
Validation loss: 2.5345744573941795

Epoch: 5| Step: 10
Training loss: 2.0557198524475098
Validation loss: 2.5032887240891815

Epoch: 29| Step: 0
Training loss: 2.852905511856079
Validation loss: 2.51753895513473

Epoch: 5| Step: 1
Training loss: 2.161437511444092
Validation loss: 2.521644397448468

Epoch: 5| Step: 2
Training loss: 2.955322742462158
Validation loss: 2.5091345412756807

Epoch: 5| Step: 3
Training loss: 3.4709649085998535
Validation loss: 2.493350334064935

Epoch: 5| Step: 4
Training loss: 2.7210984230041504
Validation loss: 2.4915074327940583

Epoch: 5| Step: 5
Training loss: 2.462618589401245
Validation loss: 2.4757422990696405

Epoch: 5| Step: 6
Training loss: 3.48834490776062
Validation loss: 2.46863143931153

Epoch: 5| Step: 7
Training loss: 2.1721088886260986
Validation loss: 2.4916182820514967

Epoch: 5| Step: 8
Training loss: 2.026956558227539
Validation loss: 2.465920158611831

Epoch: 5| Step: 9
Training loss: 2.5834169387817383
Validation loss: 2.417770924106721

Epoch: 5| Step: 10
Training loss: 2.509824275970459
Validation loss: 2.45363179842631

Epoch: 30| Step: 0
Training loss: 3.364487886428833
Validation loss: 2.4461201185821206

Epoch: 5| Step: 1
Training loss: 2.945263624191284
Validation loss: 2.422841723247241

Epoch: 5| Step: 2
Training loss: 2.408188581466675
Validation loss: 2.420560318936584

Epoch: 5| Step: 3
Training loss: 2.6741576194763184
Validation loss: 2.3969751686178227

Epoch: 5| Step: 4
Training loss: 2.1119532585144043
Validation loss: 2.399535322702059

Epoch: 5| Step: 5
Training loss: 2.455512762069702
Validation loss: 2.4067611002152964

Epoch: 5| Step: 6
Training loss: 2.219820022583008
Validation loss: 2.4007043274500037

Epoch: 5| Step: 7
Training loss: 2.6785380840301514
Validation loss: 2.3991682785813526

Epoch: 5| Step: 8
Training loss: 2.532285213470459
Validation loss: 2.369608893189379

Epoch: 5| Step: 9
Training loss: 2.7088534832000732
Validation loss: 2.4149303615734143

Epoch: 5| Step: 10
Training loss: 3.185687303543091
Validation loss: 2.3703351764268774

Epoch: 31| Step: 0
Training loss: 2.26487135887146
Validation loss: 2.387048098348802

Epoch: 5| Step: 1
Training loss: 2.70298433303833
Validation loss: 2.373156083527432

Epoch: 5| Step: 2
Training loss: 2.828822374343872
Validation loss: 2.364976103587817

Epoch: 5| Step: 3
Training loss: 2.993569850921631
Validation loss: 2.3886358763581965

Epoch: 5| Step: 4
Training loss: 2.587871789932251
Validation loss: 2.3707859234143327

Epoch: 5| Step: 5
Training loss: 2.86647367477417
Validation loss: 2.344768952297908

Epoch: 5| Step: 6
Training loss: 2.66418719291687
Validation loss: 2.3771133269033125

Epoch: 5| Step: 7
Training loss: 2.6193606853485107
Validation loss: 2.3780104549982215

Epoch: 5| Step: 8
Training loss: 2.7579383850097656
Validation loss: 2.34830823252278

Epoch: 5| Step: 9
Training loss: 2.489419460296631
Validation loss: 2.343607912781418

Epoch: 5| Step: 10
Training loss: 2.0575101375579834
Validation loss: 2.3429262381727978

Epoch: 32| Step: 0
Training loss: 2.90944504737854
Validation loss: 2.3355467114397275

Epoch: 5| Step: 1
Training loss: 2.110684633255005
Validation loss: 2.351954067907026

Epoch: 5| Step: 2
Training loss: 2.988102436065674
Validation loss: 2.357529692752387

Epoch: 5| Step: 3
Training loss: 2.0881550312042236
Validation loss: 2.3650052829455306

Epoch: 5| Step: 4
Training loss: 2.543145179748535
Validation loss: 2.3707909199499313

Epoch: 5| Step: 5
Training loss: 1.956519365310669
Validation loss: 2.3361601573164745

Epoch: 5| Step: 6
Training loss: 2.929356336593628
Validation loss: 2.3482193690474316

Epoch: 5| Step: 7
Training loss: 3.059763193130493
Validation loss: 2.3447344674858996

Epoch: 5| Step: 8
Training loss: 3.2285590171813965
Validation loss: 2.341269311084542

Epoch: 5| Step: 9
Training loss: 2.307227373123169
Validation loss: 2.342494664653655

Epoch: 5| Step: 10
Training loss: 2.816801071166992
Validation loss: 2.318717574560514

Epoch: 33| Step: 0
Training loss: 2.327031135559082
Validation loss: 2.317312926374456

Epoch: 5| Step: 1
Training loss: 2.437398910522461
Validation loss: 2.311716487330775

Epoch: 5| Step: 2
Training loss: 3.0356128215789795
Validation loss: 2.3470788745469946

Epoch: 5| Step: 3
Training loss: 3.019684076309204
Validation loss: 2.3330494498693817

Epoch: 5| Step: 4
Training loss: 2.3517251014709473
Validation loss: 2.3485031153566096

Epoch: 5| Step: 5
Training loss: 2.914219617843628
Validation loss: 2.348993029645694

Epoch: 5| Step: 6
Training loss: 2.1446125507354736
Validation loss: 2.345984246141167

Epoch: 5| Step: 7
Training loss: 1.6916344165802002
Validation loss: 2.328605084009068

Epoch: 5| Step: 8
Training loss: 3.1967849731445312
Validation loss: 2.3203068343541955

Epoch: 5| Step: 9
Training loss: 3.2034192085266113
Validation loss: 2.3455404389289116

Epoch: 5| Step: 10
Training loss: 2.408400058746338
Validation loss: 2.348513586546785

Epoch: 34| Step: 0
Training loss: 2.8845858573913574
Validation loss: 2.342963754489858

Epoch: 5| Step: 1
Training loss: 2.4439139366149902
Validation loss: 2.3419176686194634

Epoch: 5| Step: 2
Training loss: 2.9427382946014404
Validation loss: 2.325728993262014

Epoch: 5| Step: 3
Training loss: 2.550346612930298
Validation loss: 2.343185019749467

Epoch: 5| Step: 4
Training loss: 2.4362728595733643
Validation loss: 2.3158436116351875

Epoch: 5| Step: 5
Training loss: 2.9690310955047607
Validation loss: 2.3115157260689685

Epoch: 5| Step: 6
Training loss: 2.86497163772583
Validation loss: 2.313758437351514

Epoch: 5| Step: 7
Training loss: 2.496544361114502
Validation loss: 2.2721347552473827

Epoch: 5| Step: 8
Training loss: 2.839824676513672
Validation loss: 2.319211459928943

Epoch: 5| Step: 9
Training loss: 2.421018123626709
Validation loss: 2.3120572490076863

Epoch: 5| Step: 10
Training loss: 1.567158818244934
Validation loss: 2.3239576355103524

Epoch: 35| Step: 0
Training loss: 2.7425053119659424
Validation loss: 2.321061231756723

Epoch: 5| Step: 1
Training loss: 3.544292449951172
Validation loss: 2.3448722644518782

Epoch: 5| Step: 2
Training loss: 2.245257616043091
Validation loss: 2.3144467722985054

Epoch: 5| Step: 3
Training loss: 2.733727216720581
Validation loss: 2.32157906921961

Epoch: 5| Step: 4
Training loss: 3.1762895584106445
Validation loss: 2.351267642872308

Epoch: 5| Step: 5
Training loss: 2.4599082469940186
Validation loss: 2.3386105029813704

Epoch: 5| Step: 6
Training loss: 2.4250831604003906
Validation loss: 2.3226153671100573

Epoch: 5| Step: 7
Training loss: 2.6083900928497314
Validation loss: 2.3169215776587047

Epoch: 5| Step: 8
Training loss: 1.6325085163116455
Validation loss: 2.3346394979825584

Epoch: 5| Step: 9
Training loss: 3.0377166271209717
Validation loss: 2.317578600298974

Epoch: 5| Step: 10
Training loss: 2.1790859699249268
Validation loss: 2.3051390019796227

Epoch: 36| Step: 0
Training loss: 2.801663637161255
Validation loss: 2.3313974052347164

Epoch: 5| Step: 1
Training loss: 2.281933307647705
Validation loss: 2.346914314454602

Epoch: 5| Step: 2
Training loss: 2.583116054534912
Validation loss: 2.295415101512786

Epoch: 5| Step: 3
Training loss: 2.70478892326355
Validation loss: 2.3068205694998465

Epoch: 5| Step: 4
Training loss: 2.3401436805725098
Validation loss: 2.3320310910542807

Epoch: 5| Step: 5
Training loss: 2.869846820831299
Validation loss: 2.324913053102391

Epoch: 5| Step: 6
Training loss: 2.5914154052734375
Validation loss: 2.3512071460805912

Epoch: 5| Step: 7
Training loss: 2.4820663928985596
Validation loss: 2.3232663703221146

Epoch: 5| Step: 8
Training loss: 2.3933682441711426
Validation loss: 2.313394727245454

Epoch: 5| Step: 9
Training loss: 2.7524049282073975
Validation loss: 2.2963250888291227

Epoch: 5| Step: 10
Training loss: 2.578719139099121
Validation loss: 2.3172684561821724

Epoch: 37| Step: 0
Training loss: 2.1494202613830566
Validation loss: 2.328197838157736

Epoch: 5| Step: 1
Training loss: 2.3278088569641113
Validation loss: 2.3121611661808465

Epoch: 5| Step: 2
Training loss: 2.414555072784424
Validation loss: 2.324730475743612

Epoch: 5| Step: 3
Training loss: 2.5985288619995117
Validation loss: 2.310491200416319

Epoch: 5| Step: 4
Training loss: 1.978122353553772
Validation loss: 2.309254543755644

Epoch: 5| Step: 5
Training loss: 2.904313325881958
Validation loss: 2.2944821465399956

Epoch: 5| Step: 6
Training loss: 2.301576614379883
Validation loss: 2.296704876807428

Epoch: 5| Step: 7
Training loss: 3.4053966999053955
Validation loss: 2.3242280149972565

Epoch: 5| Step: 8
Training loss: 2.4080233573913574
Validation loss: 2.26942511527769

Epoch: 5| Step: 9
Training loss: 2.783066511154175
Validation loss: 2.2697316036429456

Epoch: 5| Step: 10
Training loss: 3.3318092823028564
Validation loss: 2.2926401194705757

Epoch: 38| Step: 0
Training loss: 2.3683958053588867
Validation loss: 2.297871915243005

Epoch: 5| Step: 1
Training loss: 2.869591474533081
Validation loss: 2.3153714185119956

Epoch: 5| Step: 2
Training loss: 1.7634557485580444
Validation loss: 2.293445410266999

Epoch: 5| Step: 3
Training loss: 2.8044941425323486
Validation loss: 2.2802050498224076

Epoch: 5| Step: 4
Training loss: 2.2698512077331543
Validation loss: 2.2923518534629577

Epoch: 5| Step: 5
Training loss: 3.119178056716919
Validation loss: 2.2870593378620763

Epoch: 5| Step: 6
Training loss: 2.418247938156128
Validation loss: 2.3326144538899904

Epoch: 5| Step: 7
Training loss: 2.4568612575531006
Validation loss: 2.2869614324262066

Epoch: 5| Step: 8
Training loss: 2.399264335632324
Validation loss: 2.2983613924313615

Epoch: 5| Step: 9
Training loss: 2.5360889434814453
Validation loss: 2.2934508810761156

Epoch: 5| Step: 10
Training loss: 3.5160555839538574
Validation loss: 2.3236147690844793

Epoch: 39| Step: 0
Training loss: 2.288142681121826
Validation loss: 2.29186927118609

Epoch: 5| Step: 1
Training loss: 2.0915801525115967
Validation loss: 2.2686912705821376

Epoch: 5| Step: 2
Training loss: 2.7269482612609863
Validation loss: 2.300436918453504

Epoch: 5| Step: 3
Training loss: 2.3219399452209473
Validation loss: 2.2969872336233816

Epoch: 5| Step: 4
Training loss: 2.305438995361328
Validation loss: 2.284976120918028

Epoch: 5| Step: 5
Training loss: 3.405384063720703
Validation loss: 2.2943572716046403

Epoch: 5| Step: 6
Training loss: 3.076779842376709
Validation loss: 2.296896001344086

Epoch: 5| Step: 7
Training loss: 2.462980031967163
Validation loss: 2.323898923012518

Epoch: 5| Step: 8
Training loss: 2.2360951900482178
Validation loss: 2.305072863896688

Epoch: 5| Step: 9
Training loss: 2.968538284301758
Validation loss: 2.2888862984154814

Epoch: 5| Step: 10
Training loss: 2.4156742095947266
Validation loss: 2.2836029862844818

Epoch: 40| Step: 0
Training loss: 2.8520913124084473
Validation loss: 2.2686254952543523

Epoch: 5| Step: 1
Training loss: 2.595301628112793
Validation loss: 2.2828921502636326

Epoch: 5| Step: 2
Training loss: 2.3201258182525635
Validation loss: 2.288769111838392

Epoch: 5| Step: 3
Training loss: 2.452725648880005
Validation loss: 2.266483268430156

Epoch: 5| Step: 4
Training loss: 2.779446840286255
Validation loss: 2.2720040223931752

Epoch: 5| Step: 5
Training loss: 2.661782741546631
Validation loss: 2.282663342773273

Epoch: 5| Step: 6
Training loss: 2.803875207901001
Validation loss: 2.29792687969823

Epoch: 5| Step: 7
Training loss: 1.8993850946426392
Validation loss: 2.2788276313453593

Epoch: 5| Step: 8
Training loss: 2.4672131538391113
Validation loss: 2.2722370342541764

Epoch: 5| Step: 9
Training loss: 2.7921290397644043
Validation loss: 2.288287006398683

Epoch: 5| Step: 10
Training loss: 2.50870943069458
Validation loss: 2.293181191208542

Epoch: 41| Step: 0
Training loss: 2.2469825744628906
Validation loss: 2.2688846511225544

Epoch: 5| Step: 1
Training loss: 2.4021363258361816
Validation loss: 2.3109398939276256

Epoch: 5| Step: 2
Training loss: 2.7972655296325684
Validation loss: 2.2815873802349134

Epoch: 5| Step: 3
Training loss: 1.601439118385315
Validation loss: 2.283165665083034

Epoch: 5| Step: 4
Training loss: 2.383523941040039
Validation loss: 2.280033875537175

Epoch: 5| Step: 5
Training loss: 2.334399700164795
Validation loss: 2.279663274365087

Epoch: 5| Step: 6
Training loss: 2.9086456298828125
Validation loss: 2.279705698772143

Epoch: 5| Step: 7
Training loss: 2.745023012161255
Validation loss: 2.2687951313552035

Epoch: 5| Step: 8
Training loss: 2.8568997383117676
Validation loss: 2.2854458721735145

Epoch: 5| Step: 9
Training loss: 3.050415515899658
Validation loss: 2.281872364782518

Epoch: 5| Step: 10
Training loss: 2.763526439666748
Validation loss: 2.2767454911303777

Epoch: 42| Step: 0
Training loss: 2.4011147022247314
Validation loss: 2.2959462673433366

Epoch: 5| Step: 1
Training loss: 2.7785332202911377
Validation loss: 2.287309579951789

Epoch: 5| Step: 2
Training loss: 2.1458091735839844
Validation loss: 2.2679302948777393

Epoch: 5| Step: 3
Training loss: 3.0493876934051514
Validation loss: 2.288044907713449

Epoch: 5| Step: 4
Training loss: 2.7843568325042725
Validation loss: 2.282768121329687

Epoch: 5| Step: 5
Training loss: 2.3996081352233887
Validation loss: 2.278457005818685

Epoch: 5| Step: 6
Training loss: 2.4102389812469482
Validation loss: 2.2847265889567714

Epoch: 5| Step: 7
Training loss: 2.7527825832366943
Validation loss: 2.25984356223896

Epoch: 5| Step: 8
Training loss: 2.2707695960998535
Validation loss: 2.2579536079078593

Epoch: 5| Step: 9
Training loss: 2.172792434692383
Validation loss: 2.2299000524705455

Epoch: 5| Step: 10
Training loss: 2.882333993911743
Validation loss: 2.2676849006324686

Epoch: 43| Step: 0
Training loss: 2.886502742767334
Validation loss: 2.2728797338342153

Epoch: 5| Step: 1
Training loss: 2.3221981525421143
Validation loss: 2.2475136480023785

Epoch: 5| Step: 2
Training loss: 1.7705157995224
Validation loss: 2.2714440079145533

Epoch: 5| Step: 3
Training loss: 1.6877124309539795
Validation loss: 2.2962022314789476

Epoch: 5| Step: 4
Training loss: 2.5804250240325928
Validation loss: 2.2566718926993747

Epoch: 5| Step: 5
Training loss: 2.417846202850342
Validation loss: 2.224302604634275

Epoch: 5| Step: 6
Training loss: 3.0958683490753174
Validation loss: 2.247963079842188

Epoch: 5| Step: 7
Training loss: 3.1202328205108643
Validation loss: 2.2671806991741223

Epoch: 5| Step: 8
Training loss: 2.753288984298706
Validation loss: 2.275911392704133

Epoch: 5| Step: 9
Training loss: 3.128354549407959
Validation loss: 2.2290949924017793

Epoch: 5| Step: 10
Training loss: 2.1491153240203857
Validation loss: 2.2661895982680784

Epoch: 44| Step: 0
Training loss: 2.630993366241455
Validation loss: 2.255140050765007

Epoch: 5| Step: 1
Training loss: 2.0756728649139404
Validation loss: 2.25565577578801

Epoch: 5| Step: 2
Training loss: 2.862447500228882
Validation loss: 2.243994064228509

Epoch: 5| Step: 3
Training loss: 2.9501354694366455
Validation loss: 2.23445709290043

Epoch: 5| Step: 4
Training loss: 2.7710070610046387
Validation loss: 2.2685455404302126

Epoch: 5| Step: 5
Training loss: 2.873755693435669
Validation loss: 2.2746113449014644

Epoch: 5| Step: 6
Training loss: 2.0750534534454346
Validation loss: 2.2569805550318893

Epoch: 5| Step: 7
Training loss: 2.26235294342041
Validation loss: 2.260378281275431

Epoch: 5| Step: 8
Training loss: 2.2443034648895264
Validation loss: 2.2213576237360635

Epoch: 5| Step: 9
Training loss: 2.5709452629089355
Validation loss: 2.2574536005655923

Epoch: 5| Step: 10
Training loss: 2.4072113037109375
Validation loss: 2.2256605573879775

Epoch: 45| Step: 0
Training loss: 2.0400352478027344
Validation loss: 2.2608559054713093

Epoch: 5| Step: 1
Training loss: 1.7521709203720093
Validation loss: 2.2218828560203634

Epoch: 5| Step: 2
Training loss: 2.43473482131958
Validation loss: 2.2563252243944394

Epoch: 5| Step: 3
Training loss: 1.9751383066177368
Validation loss: 2.22615619115932

Epoch: 5| Step: 4
Training loss: 2.785245418548584
Validation loss: 2.264071604256989

Epoch: 5| Step: 5
Training loss: 2.6569995880126953
Validation loss: 2.202569978211516

Epoch: 5| Step: 6
Training loss: 2.7986395359039307
Validation loss: 2.22956225948949

Epoch: 5| Step: 7
Training loss: 2.391507625579834
Validation loss: 2.2487908768397507

Epoch: 5| Step: 8
Training loss: 2.7320332527160645
Validation loss: 2.2529369631121234

Epoch: 5| Step: 9
Training loss: 2.8818442821502686
Validation loss: 2.221205037127259

Epoch: 5| Step: 10
Training loss: 3.3849213123321533
Validation loss: 2.24207144142479

Epoch: 46| Step: 0
Training loss: 2.3693270683288574
Validation loss: 2.2183812202945834

Epoch: 5| Step: 1
Training loss: 2.7839276790618896
Validation loss: 2.2516550312760057

Epoch: 5| Step: 2
Training loss: 3.231484889984131
Validation loss: 2.2119932918138403

Epoch: 5| Step: 3
Training loss: 2.494004487991333
Validation loss: 2.265345755443778

Epoch: 5| Step: 4
Training loss: 2.782224178314209
Validation loss: 2.240108049044045

Epoch: 5| Step: 5
Training loss: 2.5920073986053467
Validation loss: 2.2555787883779055

Epoch: 5| Step: 6
Training loss: 1.8069446086883545
Validation loss: 2.22356947903992

Epoch: 5| Step: 7
Training loss: 2.603564739227295
Validation loss: 2.2714487839770574

Epoch: 5| Step: 8
Training loss: 3.016096591949463
Validation loss: 2.2308549227253085

Epoch: 5| Step: 9
Training loss: 1.9103931188583374
Validation loss: 2.239844487559411

Epoch: 5| Step: 10
Training loss: 2.218518018722534
Validation loss: 2.266698770625617

Epoch: 47| Step: 0
Training loss: 2.744551181793213
Validation loss: 2.2214738399751726

Epoch: 5| Step: 1
Training loss: 2.122741222381592
Validation loss: 2.238378063324959

Epoch: 5| Step: 2
Training loss: 1.7639309167861938
Validation loss: 2.261003294298726

Epoch: 5| Step: 3
Training loss: 2.719996690750122
Validation loss: 2.2244009497345134

Epoch: 5| Step: 4
Training loss: 2.1787521839141846
Validation loss: 2.2506725865025676

Epoch: 5| Step: 5
Training loss: 2.323089361190796
Validation loss: 2.254585830114221

Epoch: 5| Step: 6
Training loss: 2.4012341499328613
Validation loss: 2.2365926850226616

Epoch: 5| Step: 7
Training loss: 2.8997206687927246
Validation loss: 2.2395104477482457

Epoch: 5| Step: 8
Training loss: 2.8354504108428955
Validation loss: 2.241420971449985

Epoch: 5| Step: 9
Training loss: 2.6938223838806152
Validation loss: 2.2116844025991296

Epoch: 5| Step: 10
Training loss: 2.904461145401001
Validation loss: 2.233459262437718

Epoch: 48| Step: 0
Training loss: 2.009622097015381
Validation loss: 2.2330714887188328

Epoch: 5| Step: 1
Training loss: 2.4338366985321045
Validation loss: 2.234329846597487

Epoch: 5| Step: 2
Training loss: 2.7494215965270996
Validation loss: 2.2286842382082375

Epoch: 5| Step: 3
Training loss: 2.701415538787842
Validation loss: 2.27184114661268

Epoch: 5| Step: 4
Training loss: 2.097938060760498
Validation loss: 2.2048755204805763

Epoch: 5| Step: 5
Training loss: 2.5271682739257812
Validation loss: 2.2467177837125716

Epoch: 5| Step: 6
Training loss: 3.530869960784912
Validation loss: 2.242641761738767

Epoch: 5| Step: 7
Training loss: 2.0227675437927246
Validation loss: 2.2188650843917683

Epoch: 5| Step: 8
Training loss: 2.547687292098999
Validation loss: 2.2455680472876436

Epoch: 5| Step: 9
Training loss: 2.678318500518799
Validation loss: 2.2225069486966698

Epoch: 5| Step: 10
Training loss: 2.187152147293091
Validation loss: 2.2474646696480374

Epoch: 49| Step: 0
Training loss: 2.497591733932495
Validation loss: 2.203453892020769

Epoch: 5| Step: 1
Training loss: 2.232044219970703
Validation loss: 2.2232364121303765

Epoch: 5| Step: 2
Training loss: 2.2255725860595703
Validation loss: 2.184284920333534

Epoch: 5| Step: 3
Training loss: 2.4660768508911133
Validation loss: 2.2112426501448437

Epoch: 5| Step: 4
Training loss: 2.311872959136963
Validation loss: 2.2263911398508216

Epoch: 5| Step: 5
Training loss: 2.373469352722168
Validation loss: 2.2205479683414584

Epoch: 5| Step: 6
Training loss: 3.0327095985412598
Validation loss: 2.2363259253963346

Epoch: 5| Step: 7
Training loss: 2.7920515537261963
Validation loss: 2.205015605495822

Epoch: 5| Step: 8
Training loss: 3.089601516723633
Validation loss: 2.201267123222351

Epoch: 5| Step: 9
Training loss: 2.581746816635132
Validation loss: 2.2228838320701354

Epoch: 5| Step: 10
Training loss: 2.0148887634277344
Validation loss: 2.200983694804612

Epoch: 50| Step: 0
Training loss: 2.0543928146362305
Validation loss: 2.211944774914813

Epoch: 5| Step: 1
Training loss: 2.4493255615234375
Validation loss: 2.2212698510898057

Epoch: 5| Step: 2
Training loss: 2.4659392833709717
Validation loss: 2.2391711717010825

Epoch: 5| Step: 3
Training loss: 2.9244637489318848
Validation loss: 2.242174917651761

Epoch: 5| Step: 4
Training loss: 2.634732961654663
Validation loss: 2.237627980529621

Epoch: 5| Step: 5
Training loss: 2.478172779083252
Validation loss: 2.205948219504408

Epoch: 5| Step: 6
Training loss: 2.7795872688293457
Validation loss: 2.2447563832806003

Epoch: 5| Step: 7
Training loss: 2.330808639526367
Validation loss: 2.208079412419309

Epoch: 5| Step: 8
Training loss: 2.8042261600494385
Validation loss: 2.2062102774138093

Epoch: 5| Step: 9
Training loss: 2.2025816440582275
Validation loss: 2.208157334276425

Epoch: 5| Step: 10
Training loss: 2.221220016479492
Validation loss: 2.2222180058879237

Epoch: 51| Step: 0
Training loss: 1.9943526983261108
Validation loss: 2.207533223654634

Epoch: 5| Step: 1
Training loss: 2.4777724742889404
Validation loss: 2.2132657663796538

Epoch: 5| Step: 2
Training loss: 2.3650143146514893
Validation loss: 2.216807185962636

Epoch: 5| Step: 3
Training loss: 2.837139129638672
Validation loss: 2.2266160903438443

Epoch: 5| Step: 4
Training loss: 2.8942904472351074
Validation loss: 2.2351328916447137

Epoch: 5| Step: 5
Training loss: 2.8947689533233643
Validation loss: 2.2232345124726653

Epoch: 5| Step: 6
Training loss: 2.2338051795959473
Validation loss: 2.2168067347618843

Epoch: 5| Step: 7
Training loss: 2.4491424560546875
Validation loss: 2.21982644706644

Epoch: 5| Step: 8
Training loss: 2.803711414337158
Validation loss: 2.2238947371000886

Epoch: 5| Step: 9
Training loss: 2.163012981414795
Validation loss: 2.195835032770711

Epoch: 5| Step: 10
Training loss: 2.393362045288086
Validation loss: 2.2253946335084978

Epoch: 52| Step: 0
Training loss: 2.889810085296631
Validation loss: 2.2109548686653056

Epoch: 5| Step: 1
Training loss: 3.375542402267456
Validation loss: 2.2101035861558813

Epoch: 5| Step: 2
Training loss: 2.3293182849884033
Validation loss: 2.1950682235020462

Epoch: 5| Step: 3
Training loss: 1.6256014108657837
Validation loss: 2.225242535273234

Epoch: 5| Step: 4
Training loss: 2.4910025596618652
Validation loss: 2.2297012908484346

Epoch: 5| Step: 5
Training loss: 2.5873332023620605
Validation loss: 2.177359224647604

Epoch: 5| Step: 6
Training loss: 2.414855480194092
Validation loss: 2.1918837370411044

Epoch: 5| Step: 7
Training loss: 2.3745455741882324
Validation loss: 2.2293321419787664

Epoch: 5| Step: 8
Training loss: 2.3565516471862793
Validation loss: 2.2009578853525142

Epoch: 5| Step: 9
Training loss: 2.3977982997894287
Validation loss: 2.2092021511447046

Epoch: 5| Step: 10
Training loss: 2.604797601699829
Validation loss: 2.2048720518747964

Epoch: 53| Step: 0
Training loss: 3.204322338104248
Validation loss: 2.2043633666089786

Epoch: 5| Step: 1
Training loss: 2.1419312953948975
Validation loss: 2.198428568019662

Epoch: 5| Step: 2
Training loss: 2.475559949874878
Validation loss: 2.171300163833044

Epoch: 5| Step: 3
Training loss: 2.1522066593170166
Validation loss: 2.1782493616945002

Epoch: 5| Step: 4
Training loss: 2.7797229290008545
Validation loss: 2.2015132750234296

Epoch: 5| Step: 5
Training loss: 2.5220494270324707
Validation loss: 2.2240813393746652

Epoch: 5| Step: 6
Training loss: 2.720066547393799
Validation loss: 2.190864063078357

Epoch: 5| Step: 7
Training loss: 2.1793787479400635
Validation loss: 2.203823531827619

Epoch: 5| Step: 8
Training loss: 1.8995698690414429
Validation loss: 2.195935103201097

Epoch: 5| Step: 9
Training loss: 2.310455799102783
Validation loss: 2.1812599012928624

Epoch: 5| Step: 10
Training loss: 3.0987794399261475
Validation loss: 2.225550777168684

Epoch: 54| Step: 0
Training loss: 2.2386221885681152
Validation loss: 2.174237762728045

Epoch: 5| Step: 1
Training loss: 2.470424175262451
Validation loss: 2.182482701475902

Epoch: 5| Step: 2
Training loss: 3.3787903785705566
Validation loss: 2.199458929800218

Epoch: 5| Step: 3
Training loss: 1.7917499542236328
Validation loss: 2.206000174245527

Epoch: 5| Step: 4
Training loss: 2.533512592315674
Validation loss: 2.190125867884646

Epoch: 5| Step: 5
Training loss: 2.494391918182373
Validation loss: 2.199188217040031

Epoch: 5| Step: 6
Training loss: 2.7936623096466064
Validation loss: 2.2157780572932255

Epoch: 5| Step: 7
Training loss: 2.584005832672119
Validation loss: 2.231778290963942

Epoch: 5| Step: 8
Training loss: 2.254607677459717
Validation loss: 2.2209057179830407

Epoch: 5| Step: 9
Training loss: 2.8777074813842773
Validation loss: 2.21118402224715

Epoch: 5| Step: 10
Training loss: 1.9797683954238892
Validation loss: 2.2162207531672653

Epoch: 55| Step: 0
Training loss: 2.8256771564483643
Validation loss: 2.218081389704058

Epoch: 5| Step: 1
Training loss: 2.717029333114624
Validation loss: 2.217151834118751

Epoch: 5| Step: 2
Training loss: 1.7423489093780518
Validation loss: 2.2041245109291485

Epoch: 5| Step: 3
Training loss: 1.7961549758911133
Validation loss: 2.214768055946596

Epoch: 5| Step: 4
Training loss: 2.659658432006836
Validation loss: 2.171101616274926

Epoch: 5| Step: 5
Training loss: 3.290102481842041
Validation loss: 2.2172801648416827

Epoch: 5| Step: 6
Training loss: 2.1121737957000732
Validation loss: 2.1862666683812297

Epoch: 5| Step: 7
Training loss: 2.3946826457977295
Validation loss: 2.1936009737753097

Epoch: 5| Step: 8
Training loss: 3.0542006492614746
Validation loss: 2.1794577901081373

Epoch: 5| Step: 9
Training loss: 2.3006012439727783
Validation loss: 2.1775328126004947

Epoch: 5| Step: 10
Training loss: 2.050917863845825
Validation loss: 2.187711454206897

Epoch: 56| Step: 0
Training loss: 2.8221991062164307
Validation loss: 2.1749431958762546

Epoch: 5| Step: 1
Training loss: 1.9500243663787842
Validation loss: 2.187634834679224

Epoch: 5| Step: 2
Training loss: 2.713951349258423
Validation loss: 2.213966208119546

Epoch: 5| Step: 3
Training loss: 2.0549511909484863
Validation loss: 2.1948713589740056

Epoch: 5| Step: 4
Training loss: 2.5201408863067627
Validation loss: 2.1917650827797512

Epoch: 5| Step: 5
Training loss: 3.2225005626678467
Validation loss: 2.1982794807803248

Epoch: 5| Step: 6
Training loss: 2.615095615386963
Validation loss: 2.1635802945783063

Epoch: 5| Step: 7
Training loss: 2.68015456199646
Validation loss: 2.218092591531815

Epoch: 5| Step: 8
Training loss: 2.7016470432281494
Validation loss: 2.2206629155784525

Epoch: 5| Step: 9
Training loss: 1.5575025081634521
Validation loss: 2.1834289386708248

Epoch: 5| Step: 10
Training loss: 2.181791067123413
Validation loss: 2.1793827497830955

Epoch: 57| Step: 0
Training loss: 2.0984833240509033
Validation loss: 2.171972692653697

Epoch: 5| Step: 1
Training loss: 2.9987428188323975
Validation loss: 2.1987383160539853

Epoch: 5| Step: 2
Training loss: 2.7386374473571777
Validation loss: 2.157795557411768

Epoch: 5| Step: 3
Training loss: 3.3144619464874268
Validation loss: 2.1996439759449293

Epoch: 5| Step: 4
Training loss: 1.9430166482925415
Validation loss: 2.1881274741183043

Epoch: 5| Step: 5
Training loss: 2.5670828819274902
Validation loss: 2.1768309531673307

Epoch: 5| Step: 6
Training loss: 2.6950879096984863
Validation loss: 2.2005020033928657

Epoch: 5| Step: 7
Training loss: 1.8224103450775146
Validation loss: 2.208704084478399

Epoch: 5| Step: 8
Training loss: 2.8586273193359375
Validation loss: 2.2023509010191886

Epoch: 5| Step: 9
Training loss: 1.842039704322815
Validation loss: 2.141141532569803

Epoch: 5| Step: 10
Training loss: 2.2630109786987305
Validation loss: 2.1795548982517694

Epoch: 58| Step: 0
Training loss: 2.2530055046081543
Validation loss: 2.1940185613529657

Epoch: 5| Step: 1
Training loss: 2.628455877304077
Validation loss: 2.1426627366773543

Epoch: 5| Step: 2
Training loss: 3.130190372467041
Validation loss: 2.1559350823843353

Epoch: 5| Step: 3
Training loss: 2.6042139530181885
Validation loss: 2.167153985269608

Epoch: 5| Step: 4
Training loss: 2.768761157989502
Validation loss: 2.1637600775687926

Epoch: 5| Step: 5
Training loss: 2.1300549507141113
Validation loss: 2.1653632810038905

Epoch: 5| Step: 6
Training loss: 2.474198579788208
Validation loss: 2.19555006488677

Epoch: 5| Step: 7
Training loss: 2.276975154876709
Validation loss: 2.1310958529031403

Epoch: 5| Step: 8
Training loss: 2.4439663887023926
Validation loss: 2.1819138462825487

Epoch: 5| Step: 9
Training loss: 2.070190668106079
Validation loss: 2.218550261630807

Epoch: 5| Step: 10
Training loss: 2.1552560329437256
Validation loss: 2.1452256607752975

Epoch: 59| Step: 0
Training loss: 2.570847749710083
Validation loss: 2.1624180501507175

Epoch: 5| Step: 1
Training loss: 2.2573189735412598
Validation loss: 2.161915793213793

Epoch: 5| Step: 2
Training loss: 2.0663344860076904
Validation loss: 2.154282000757033

Epoch: 5| Step: 3
Training loss: 1.9589293003082275
Validation loss: 2.1902388218910462

Epoch: 5| Step: 4
Training loss: 2.456118106842041
Validation loss: 2.149221279287851

Epoch: 5| Step: 5
Training loss: 2.252419948577881
Validation loss: 2.1633931693210395

Epoch: 5| Step: 6
Training loss: 1.7365890741348267
Validation loss: 2.1557542970103603

Epoch: 5| Step: 7
Training loss: 3.174253463745117
Validation loss: 2.140274355488439

Epoch: 5| Step: 8
Training loss: 2.8083465099334717
Validation loss: 2.170496433011947

Epoch: 5| Step: 9
Training loss: 2.5308382511138916
Validation loss: 2.174288554858136

Epoch: 5| Step: 10
Training loss: 3.0071818828582764
Validation loss: 2.1675039286254556

Epoch: 60| Step: 0
Training loss: 2.8634185791015625
Validation loss: 2.196488025367901

Epoch: 5| Step: 1
Training loss: 2.342245578765869
Validation loss: 2.1665429389604958

Epoch: 5| Step: 2
Training loss: 1.8727247714996338
Validation loss: 2.17871448814228

Epoch: 5| Step: 3
Training loss: 2.016357183456421
Validation loss: 2.1847661182444584

Epoch: 5| Step: 4
Training loss: 2.2837817668914795
Validation loss: 2.157579586070071

Epoch: 5| Step: 5
Training loss: 2.901106357574463
Validation loss: 2.1557642182996197

Epoch: 5| Step: 6
Training loss: 1.835750937461853
Validation loss: 2.153413516218944

Epoch: 5| Step: 7
Training loss: 3.0058395862579346
Validation loss: 2.164642830048838

Epoch: 5| Step: 8
Training loss: 2.385854721069336
Validation loss: 2.1523510743212957

Epoch: 5| Step: 9
Training loss: 2.3165366649627686
Validation loss: 2.151048944842431

Epoch: 5| Step: 10
Training loss: 2.9063992500305176
Validation loss: 2.1690762350636144

Epoch: 61| Step: 0
Training loss: 1.918292760848999
Validation loss: 2.1488090471554826

Epoch: 5| Step: 1
Training loss: 1.8435112237930298
Validation loss: 2.2018490811829925

Epoch: 5| Step: 2
Training loss: 3.4846084117889404
Validation loss: 2.159039374320738

Epoch: 5| Step: 3
Training loss: 2.49815034866333
Validation loss: 2.1631005925516926

Epoch: 5| Step: 4
Training loss: 2.5363714694976807
Validation loss: 2.194201692458122

Epoch: 5| Step: 5
Training loss: 2.8818235397338867
Validation loss: 2.147404768133676

Epoch: 5| Step: 6
Training loss: 1.985110878944397
Validation loss: 2.1488463006993777

Epoch: 5| Step: 7
Training loss: 2.09985613822937
Validation loss: 2.1593485468177387

Epoch: 5| Step: 8
Training loss: 2.3844337463378906
Validation loss: 2.173245644056669

Epoch: 5| Step: 9
Training loss: 2.387817859649658
Validation loss: 2.1616899762102353

Epoch: 5| Step: 10
Training loss: 2.7674810886383057
Validation loss: 2.166197810121762

Epoch: 62| Step: 0
Training loss: 2.5269806385040283
Validation loss: 2.1693774666837466

Epoch: 5| Step: 1
Training loss: 1.995826005935669
Validation loss: 2.1498063482264036

Epoch: 5| Step: 2
Training loss: 2.0846359729766846
Validation loss: 2.16863574007506

Epoch: 5| Step: 3
Training loss: 2.5604827404022217
Validation loss: 2.152477487441032

Epoch: 5| Step: 4
Training loss: 2.848240375518799
Validation loss: 2.168216638667609

Epoch: 5| Step: 5
Training loss: 2.4946885108947754
Validation loss: 2.2105137930121472

Epoch: 5| Step: 6
Training loss: 2.376452684402466
Validation loss: 2.111777509412458

Epoch: 5| Step: 7
Training loss: 3.030647039413452
Validation loss: 2.135836132111088

Epoch: 5| Step: 8
Training loss: 2.0700297355651855
Validation loss: 2.1815780644775717

Epoch: 5| Step: 9
Training loss: 1.9865801334381104
Validation loss: 2.1577923118427234

Epoch: 5| Step: 10
Training loss: 3.1064579486846924
Validation loss: 2.1776396343784947

Epoch: 63| Step: 0
Training loss: 2.292573928833008
Validation loss: 2.1639269449377574

Epoch: 5| Step: 1
Training loss: 2.644411087036133
Validation loss: 2.146521936180771

Epoch: 5| Step: 2
Training loss: 2.7637810707092285
Validation loss: 2.154671174223705

Epoch: 5| Step: 3
Training loss: 2.4537811279296875
Validation loss: 2.1638182517020934

Epoch: 5| Step: 4
Training loss: 2.4842841625213623
Validation loss: 2.192091980288106

Epoch: 5| Step: 5
Training loss: 1.8288768529891968
Validation loss: 2.1580161279247654

Epoch: 5| Step: 6
Training loss: 2.1526081562042236
Validation loss: 2.1422756384777766

Epoch: 5| Step: 7
Training loss: 2.5434038639068604
Validation loss: 2.1322978286332983

Epoch: 5| Step: 8
Training loss: 3.1829657554626465
Validation loss: 2.1356183969846336

Epoch: 5| Step: 9
Training loss: 1.9403804540634155
Validation loss: 2.1726685390677503

Epoch: 5| Step: 10
Training loss: 2.490839958190918
Validation loss: 2.1853890162642284

Epoch: 64| Step: 0
Training loss: 2.519707202911377
Validation loss: 2.1721211351374143

Epoch: 5| Step: 1
Training loss: 2.439807653427124
Validation loss: 2.123835881551107

Epoch: 5| Step: 2
Training loss: 2.9370944499969482
Validation loss: 2.13665251065326

Epoch: 5| Step: 3
Training loss: 2.1805832386016846
Validation loss: 2.146488710116315

Epoch: 5| Step: 4
Training loss: 3.0244407653808594
Validation loss: 2.1618400799330844

Epoch: 5| Step: 5
Training loss: 2.0698459148406982
Validation loss: 2.1569891206679808

Epoch: 5| Step: 6
Training loss: 2.582566261291504
Validation loss: 2.169955866311186

Epoch: 5| Step: 7
Training loss: 2.9812567234039307
Validation loss: 2.1352575209832962

Epoch: 5| Step: 8
Training loss: 1.9094337224960327
Validation loss: 2.123724934875324

Epoch: 5| Step: 9
Training loss: 1.7523081302642822
Validation loss: 2.104519574872909

Epoch: 5| Step: 10
Training loss: 2.060502767562866
Validation loss: 2.1345307814177645

Epoch: 65| Step: 0
Training loss: 2.4548661708831787
Validation loss: 2.1498340663089546

Epoch: 5| Step: 1
Training loss: 2.8171727657318115
Validation loss: 2.0702305583543676

Epoch: 5| Step: 2
Training loss: 2.464855432510376
Validation loss: 2.150141013565884

Epoch: 5| Step: 3
Training loss: 3.0880203247070312
Validation loss: 2.093402854857906

Epoch: 5| Step: 4
Training loss: 2.6655662059783936
Validation loss: 2.138157859925301

Epoch: 5| Step: 5
Training loss: 2.026594877243042
Validation loss: 2.1405742014608076

Epoch: 5| Step: 6
Training loss: 2.578941822052002
Validation loss: 2.146496189537869

Epoch: 5| Step: 7
Training loss: 1.6227811574935913
Validation loss: 2.127049075659885

Epoch: 5| Step: 8
Training loss: 2.5393173694610596
Validation loss: 2.1214681158783617

Epoch: 5| Step: 9
Training loss: 1.886715292930603
Validation loss: 2.1588552228866087

Epoch: 5| Step: 10
Training loss: 2.3140511512756348
Validation loss: 2.180292380753384

Epoch: 66| Step: 0
Training loss: 2.3036952018737793
Validation loss: 2.0989279311190367

Epoch: 5| Step: 1
Training loss: 2.636082410812378
Validation loss: 2.121341377176264

Epoch: 5| Step: 2
Training loss: 2.4719138145446777
Validation loss: 2.18404213587443

Epoch: 5| Step: 3
Training loss: 2.5908255577087402
Validation loss: 2.1676391504144155

Epoch: 5| Step: 4
Training loss: 2.4524624347686768
Validation loss: 2.119290633868146

Epoch: 5| Step: 5
Training loss: 2.381279468536377
Validation loss: 2.1679526836641374

Epoch: 5| Step: 6
Training loss: 2.4340062141418457
Validation loss: 2.1366021248602096

Epoch: 5| Step: 7
Training loss: 2.534694194793701
Validation loss: 2.1080103663988012

Epoch: 5| Step: 8
Training loss: 2.6935882568359375
Validation loss: 2.126081565374969

Epoch: 5| Step: 9
Training loss: 2.2167487144470215
Validation loss: 2.154923044225221

Epoch: 5| Step: 10
Training loss: 1.5153716802597046
Validation loss: 2.1430672419968473

Epoch: 67| Step: 0
Training loss: 2.3172607421875
Validation loss: 2.131364244286732

Epoch: 5| Step: 1
Training loss: 2.5070462226867676
Validation loss: 2.1370078850817937

Epoch: 5| Step: 2
Training loss: 2.5887339115142822
Validation loss: 2.153443233941191

Epoch: 5| Step: 3
Training loss: 2.2404143810272217
Validation loss: 2.1456461260395665

Epoch: 5| Step: 4
Training loss: 1.7219159603118896
Validation loss: 2.1181707894930275

Epoch: 5| Step: 5
Training loss: 1.8875179290771484
Validation loss: 2.1176042851581367

Epoch: 5| Step: 6
Training loss: 2.329240322113037
Validation loss: 2.189841998520718

Epoch: 5| Step: 7
Training loss: 2.7854599952697754
Validation loss: 2.138629795402609

Epoch: 5| Step: 8
Training loss: 2.7732017040252686
Validation loss: 2.1780109636245237

Epoch: 5| Step: 9
Training loss: 2.730947256088257
Validation loss: 2.133663251835813

Epoch: 5| Step: 10
Training loss: 2.3111939430236816
Validation loss: 2.119460880115468

Epoch: 68| Step: 0
Training loss: 3.3535048961639404
Validation loss: 2.1382815299495572

Epoch: 5| Step: 1
Training loss: 2.846076726913452
Validation loss: 2.1309779126157045

Epoch: 5| Step: 2
Training loss: 2.6141457557678223
Validation loss: 2.1159273809002292

Epoch: 5| Step: 3
Training loss: 3.018165111541748
Validation loss: 2.147504937264227

Epoch: 5| Step: 4
Training loss: 1.851320505142212
Validation loss: 2.122958178161293

Epoch: 5| Step: 5
Training loss: 1.890760064125061
Validation loss: 2.161100302973101

Epoch: 5| Step: 6
Training loss: 2.4442121982574463
Validation loss: 2.1333034384635186

Epoch: 5| Step: 7
Training loss: 1.8466390371322632
Validation loss: 2.1062607252469627

Epoch: 5| Step: 8
Training loss: 2.4572739601135254
Validation loss: 2.153611916367726

Epoch: 5| Step: 9
Training loss: 2.099700450897217
Validation loss: 2.123729814765274

Epoch: 5| Step: 10
Training loss: 1.9376612901687622
Validation loss: 2.1099054941567044

Epoch: 69| Step: 0
Training loss: 2.477344512939453
Validation loss: 2.12530186868483

Epoch: 5| Step: 1
Training loss: 2.5366063117980957
Validation loss: 2.125575106631043

Epoch: 5| Step: 2
Training loss: 2.022658109664917
Validation loss: 2.1139483092933573

Epoch: 5| Step: 3
Training loss: 2.5352163314819336
Validation loss: 2.1599062899107575

Epoch: 5| Step: 4
Training loss: 1.8330297470092773
Validation loss: 2.1429636683515323

Epoch: 5| Step: 5
Training loss: 2.422288656234741
Validation loss: 2.1021901792095554

Epoch: 5| Step: 6
Training loss: 2.3308537006378174
Validation loss: 2.0990948548880954

Epoch: 5| Step: 7
Training loss: 2.8853976726531982
Validation loss: 2.1354013566047914

Epoch: 5| Step: 8
Training loss: 2.8603060245513916
Validation loss: 2.1289875071535826

Epoch: 5| Step: 9
Training loss: 2.4773850440979004
Validation loss: 2.144182647428205

Epoch: 5| Step: 10
Training loss: 1.9784348011016846
Validation loss: 2.100467251193139

Epoch: 70| Step: 0
Training loss: 2.303375720977783
Validation loss: 2.116046997808641

Epoch: 5| Step: 1
Training loss: 2.349461793899536
Validation loss: 2.146724973955462

Epoch: 5| Step: 2
Training loss: 2.5566654205322266
Validation loss: 2.1027785219171995

Epoch: 5| Step: 3
Training loss: 2.2121126651763916
Validation loss: 2.187559167544047

Epoch: 5| Step: 4
Training loss: 2.8723766803741455
Validation loss: 2.1452684274283786

Epoch: 5| Step: 5
Training loss: 1.7497262954711914
Validation loss: 2.117364498876756

Epoch: 5| Step: 6
Training loss: 1.823929786682129
Validation loss: 2.1386816117071334

Epoch: 5| Step: 7
Training loss: 2.5160269737243652
Validation loss: 2.108654950254707

Epoch: 5| Step: 8
Training loss: 2.5305609703063965
Validation loss: 2.1134289298006284

Epoch: 5| Step: 9
Training loss: 3.0991992950439453
Validation loss: 2.1098946871296054

Epoch: 5| Step: 10
Training loss: 2.1288673877716064
Validation loss: 2.121405780956309

Epoch: 71| Step: 0
Training loss: 2.783062219619751
Validation loss: 2.0784683073720625

Epoch: 5| Step: 1
Training loss: 2.4155802726745605
Validation loss: 2.106256256821335

Epoch: 5| Step: 2
Training loss: 2.3733036518096924
Validation loss: 2.1225417813947125

Epoch: 5| Step: 3
Training loss: 1.8981822729110718
Validation loss: 2.117450370583483

Epoch: 5| Step: 4
Training loss: 2.454476833343506
Validation loss: 2.1397747942196426

Epoch: 5| Step: 5
Training loss: 2.785168409347534
Validation loss: 2.1232313994438416

Epoch: 5| Step: 6
Training loss: 2.2951178550720215
Validation loss: 2.108679545822964

Epoch: 5| Step: 7
Training loss: 2.3918747901916504
Validation loss: 2.1112022886994066

Epoch: 5| Step: 8
Training loss: 1.7657136917114258
Validation loss: 2.13507483595161

Epoch: 5| Step: 9
Training loss: 2.5027308464050293
Validation loss: 2.1046525509126726

Epoch: 5| Step: 10
Training loss: 2.419950246810913
Validation loss: 2.1287821595386793

Epoch: 72| Step: 0
Training loss: 2.2319159507751465
Validation loss: 2.1538620738572973

Epoch: 5| Step: 1
Training loss: 2.387112855911255
Validation loss: 2.1228071002550024

Epoch: 5| Step: 2
Training loss: 2.3730359077453613
Validation loss: 2.102539365009595

Epoch: 5| Step: 3
Training loss: 1.8205629587173462
Validation loss: 2.1776686586359495

Epoch: 5| Step: 4
Training loss: 2.8803677558898926
Validation loss: 2.1502349581769717

Epoch: 5| Step: 5
Training loss: 2.3272652626037598
Validation loss: 2.1157175635778778

Epoch: 5| Step: 6
Training loss: 2.3274054527282715
Validation loss: 2.107549867322368

Epoch: 5| Step: 7
Training loss: 2.898958206176758
Validation loss: 2.120066632506668

Epoch: 5| Step: 8
Training loss: 2.4271512031555176
Validation loss: 2.15638312216728

Epoch: 5| Step: 9
Training loss: 2.4919486045837402
Validation loss: 2.147969571493005

Epoch: 5| Step: 10
Training loss: 1.9177863597869873
Validation loss: 2.1196126104683004

Epoch: 73| Step: 0
Training loss: 2.1456496715545654
Validation loss: 2.1149591579232165

Epoch: 5| Step: 1
Training loss: 2.8822920322418213
Validation loss: 2.1226946282130417

Epoch: 5| Step: 2
Training loss: 2.949592351913452
Validation loss: 2.1227960227638163

Epoch: 5| Step: 3
Training loss: 2.119875907897949
Validation loss: 2.101628600910146

Epoch: 5| Step: 4
Training loss: 1.7393696308135986
Validation loss: 2.1112132290358185

Epoch: 5| Step: 5
Training loss: 2.0597424507141113
Validation loss: 2.140593469783824

Epoch: 5| Step: 6
Training loss: 2.994004011154175
Validation loss: 2.0832442032393588

Epoch: 5| Step: 7
Training loss: 2.216371536254883
Validation loss: 2.08330278242788

Epoch: 5| Step: 8
Training loss: 2.4424519538879395
Validation loss: 2.1824512481689453

Epoch: 5| Step: 9
Training loss: 2.5437095165252686
Validation loss: 2.100986208966983

Epoch: 5| Step: 10
Training loss: 1.9931398630142212
Validation loss: 2.1190903340616534

Epoch: 74| Step: 0
Training loss: 2.642526626586914
Validation loss: 2.095456325879661

Epoch: 5| Step: 1
Training loss: 2.368795871734619
Validation loss: 2.1233115760228967

Epoch: 5| Step: 2
Training loss: 2.0344913005828857
Validation loss: 2.104471404065368

Epoch: 5| Step: 3
Training loss: 2.2391912937164307
Validation loss: 2.1412492182946976

Epoch: 5| Step: 4
Training loss: 2.0025463104248047
Validation loss: 2.1002631828349125

Epoch: 5| Step: 5
Training loss: 2.582242727279663
Validation loss: 2.0800682011471

Epoch: 5| Step: 6
Training loss: 2.021688938140869
Validation loss: 2.116950153022684

Epoch: 5| Step: 7
Training loss: 2.033191680908203
Validation loss: 2.124984049027966

Epoch: 5| Step: 8
Training loss: 3.6652674674987793
Validation loss: 2.1281267648102133

Epoch: 5| Step: 9
Training loss: 2.1857171058654785
Validation loss: 2.1128025362568517

Epoch: 5| Step: 10
Training loss: 2.344691753387451
Validation loss: 2.1035599400920253

Epoch: 75| Step: 0
Training loss: 2.3814423084259033
Validation loss: 2.078456304406607

Epoch: 5| Step: 1
Training loss: 2.7343597412109375
Validation loss: 2.1321977056482786

Epoch: 5| Step: 2
Training loss: 2.625936508178711
Validation loss: 2.104162892987651

Epoch: 5| Step: 3
Training loss: 2.158777952194214
Validation loss: 2.0870101028873074

Epoch: 5| Step: 4
Training loss: 2.2601819038391113
Validation loss: 2.109148028076336

Epoch: 5| Step: 5
Training loss: 2.505974769592285
Validation loss: 2.1507531186585784

Epoch: 5| Step: 6
Training loss: 1.98549485206604
Validation loss: 2.1181401360419487

Epoch: 5| Step: 7
Training loss: 2.187704563140869
Validation loss: 2.123777498481094

Epoch: 5| Step: 8
Training loss: 2.4039320945739746
Validation loss: 2.139622042256017

Epoch: 5| Step: 9
Training loss: 2.719881772994995
Validation loss: 2.1177486860623924

Epoch: 5| Step: 10
Training loss: 1.9304324388504028
Validation loss: 2.1484571503054712

Epoch: 76| Step: 0
Training loss: 2.5131068229675293
Validation loss: 2.1186587759243545

Epoch: 5| Step: 1
Training loss: 2.901122570037842
Validation loss: 2.120864068308184

Epoch: 5| Step: 2
Training loss: 2.2633957862854004
Validation loss: 2.193348220599595

Epoch: 5| Step: 3
Training loss: 2.0197110176086426
Validation loss: 2.1288427768215055

Epoch: 5| Step: 4
Training loss: 2.229966402053833
Validation loss: 2.140502219559044

Epoch: 5| Step: 5
Training loss: 1.9744617938995361
Validation loss: 2.133630883309149

Epoch: 5| Step: 6
Training loss: 2.3867268562316895
Validation loss: 2.108294339590175

Epoch: 5| Step: 7
Training loss: 2.3412349224090576
Validation loss: 2.1482229873698246

Epoch: 5| Step: 8
Training loss: 2.7080588340759277
Validation loss: 2.173405057640486

Epoch: 5| Step: 9
Training loss: 2.434113025665283
Validation loss: 2.1392791630119405

Epoch: 5| Step: 10
Training loss: 2.190903425216675
Validation loss: 2.1391448154244372

Epoch: 77| Step: 0
Training loss: 2.4057140350341797
Validation loss: 2.135612080174108

Epoch: 5| Step: 1
Training loss: 1.847245454788208
Validation loss: 2.2134332118495816

Epoch: 5| Step: 2
Training loss: 2.197882890701294
Validation loss: 2.179225121774981

Epoch: 5| Step: 3
Training loss: 2.8736863136291504
Validation loss: 2.1291272512046238

Epoch: 5| Step: 4
Training loss: 2.3688695430755615
Validation loss: 2.10582499606635

Epoch: 5| Step: 5
Training loss: 3.0968432426452637
Validation loss: 2.1052187424834057

Epoch: 5| Step: 6
Training loss: 1.7595049142837524
Validation loss: 2.1353078478126117

Epoch: 5| Step: 7
Training loss: 2.1619908809661865
Validation loss: 2.1175286616048505

Epoch: 5| Step: 8
Training loss: 2.462104320526123
Validation loss: 2.1507718165715537

Epoch: 5| Step: 9
Training loss: 2.725158214569092
Validation loss: 2.119072280904298

Epoch: 5| Step: 10
Training loss: 2.159881591796875
Validation loss: 2.1261669794718423

Epoch: 78| Step: 0
Training loss: 1.9157474040985107
Validation loss: 2.113044003004669

Epoch: 5| Step: 1
Training loss: 2.3876821994781494
Validation loss: 2.0804609662743023

Epoch: 5| Step: 2
Training loss: 2.8246898651123047
Validation loss: 2.095663365497384

Epoch: 5| Step: 3
Training loss: 2.7772796154022217
Validation loss: 2.143036057872157

Epoch: 5| Step: 4
Training loss: 2.0900120735168457
Validation loss: 2.089294436157391

Epoch: 5| Step: 5
Training loss: 2.7779593467712402
Validation loss: 2.103031027701593

Epoch: 5| Step: 6
Training loss: 2.124608278274536
Validation loss: 2.0917478838274555

Epoch: 5| Step: 7
Training loss: 2.3373584747314453
Validation loss: 2.1396658241107898

Epoch: 5| Step: 8
Training loss: 2.5734193325042725
Validation loss: 2.1281113214390253

Epoch: 5| Step: 9
Training loss: 2.0544631481170654
Validation loss: 2.10646842756579

Epoch: 5| Step: 10
Training loss: 1.9973503351211548
Validation loss: 2.1044512000135196

Epoch: 79| Step: 0
Training loss: 2.6220574378967285
Validation loss: 2.1154068567419566

Epoch: 5| Step: 1
Training loss: 2.1947426795959473
Validation loss: 2.1031908617224744

Epoch: 5| Step: 2
Training loss: 1.8993256092071533
Validation loss: 2.1320675265404487

Epoch: 5| Step: 3
Training loss: 3.177070140838623
Validation loss: 2.127629178826527

Epoch: 5| Step: 4
Training loss: 2.0443055629730225
Validation loss: 2.103091005356081

Epoch: 5| Step: 5
Training loss: 2.1295900344848633
Validation loss: 2.1365910627508677

Epoch: 5| Step: 6
Training loss: 2.169816255569458
Validation loss: 2.1134787682564027

Epoch: 5| Step: 7
Training loss: 2.7899482250213623
Validation loss: 2.1202390142666396

Epoch: 5| Step: 8
Training loss: 2.2050929069519043
Validation loss: 2.150610489230002

Epoch: 5| Step: 9
Training loss: 2.356232166290283
Validation loss: 2.073171264381819

Epoch: 5| Step: 10
Training loss: 2.1193339824676514
Validation loss: 2.1017589005090858

Epoch: 80| Step: 0
Training loss: 2.3916666507720947
Validation loss: 2.084604832433885

Epoch: 5| Step: 1
Training loss: 2.106388568878174
Validation loss: 2.1002272611023276

Epoch: 5| Step: 2
Training loss: 1.9566634893417358
Validation loss: 2.1446946474813644

Epoch: 5| Step: 3
Training loss: 2.7915799617767334
Validation loss: 2.113963616791592

Epoch: 5| Step: 4
Training loss: 2.9146809577941895
Validation loss: 2.076195773258004

Epoch: 5| Step: 5
Training loss: 2.039255380630493
Validation loss: 2.1104086496496715

Epoch: 5| Step: 6
Training loss: 1.7415720224380493
Validation loss: 2.1712972169281333

Epoch: 5| Step: 7
Training loss: 1.9366123676300049
Validation loss: 2.082019685417093

Epoch: 5| Step: 8
Training loss: 2.3733601570129395
Validation loss: 2.1142937303871236

Epoch: 5| Step: 9
Training loss: 2.930259943008423
Validation loss: 2.1516918828410487

Epoch: 5| Step: 10
Training loss: 2.717456579208374
Validation loss: 2.1712026352523477

Epoch: 81| Step: 0
Training loss: 2.9785408973693848
Validation loss: 2.121725429770767

Epoch: 5| Step: 1
Training loss: 2.0794901847839355
Validation loss: 2.165078250310754

Epoch: 5| Step: 2
Training loss: 2.171617031097412
Validation loss: 2.1092045281523015

Epoch: 5| Step: 3
Training loss: 2.7451744079589844
Validation loss: 2.1674255312130017

Epoch: 5| Step: 4
Training loss: 2.2030115127563477
Validation loss: 2.0707460539315337

Epoch: 5| Step: 5
Training loss: 1.6682958602905273
Validation loss: 2.1257532322278587

Epoch: 5| Step: 6
Training loss: 2.5650787353515625
Validation loss: 2.1156785629128896

Epoch: 5| Step: 7
Training loss: 2.15659761428833
Validation loss: 2.1179864098948817

Epoch: 5| Step: 8
Training loss: 2.188882827758789
Validation loss: 2.1153460048860118

Epoch: 5| Step: 9
Training loss: 2.9084339141845703
Validation loss: 2.0991300280376146

Epoch: 5| Step: 10
Training loss: 2.42684268951416
Validation loss: 2.1322052324971845

Epoch: 82| Step: 0
Training loss: 2.2372615337371826
Validation loss: 2.1331440094978578

Epoch: 5| Step: 1
Training loss: 1.5916379690170288
Validation loss: 2.1515875465126446

Epoch: 5| Step: 2
Training loss: 2.682305097579956
Validation loss: 2.081892631387198

Epoch: 5| Step: 3
Training loss: 2.6958320140838623
Validation loss: 2.125879313356133

Epoch: 5| Step: 4
Training loss: 1.9698251485824585
Validation loss: 2.1182566817088793

Epoch: 5| Step: 5
Training loss: 2.518221616744995
Validation loss: 2.150315261656238

Epoch: 5| Step: 6
Training loss: 1.678370714187622
Validation loss: 2.0911863388553744

Epoch: 5| Step: 7
Training loss: 3.031165361404419
Validation loss: 2.1227504361060356

Epoch: 5| Step: 8
Training loss: 2.2355494499206543
Validation loss: 2.1015225738607426

Epoch: 5| Step: 9
Training loss: 2.580315351486206
Validation loss: 2.116475684668428

Epoch: 5| Step: 10
Training loss: 2.7028772830963135
Validation loss: 2.08849028618105

Epoch: 83| Step: 0
Training loss: 2.577164888381958
Validation loss: 2.0880989618198846

Epoch: 5| Step: 1
Training loss: 2.5356578826904297
Validation loss: 2.1119606212903093

Epoch: 5| Step: 2
Training loss: 2.1001980304718018
Validation loss: 2.101952357958722

Epoch: 5| Step: 3
Training loss: 2.547400951385498
Validation loss: 2.1535269675716275

Epoch: 5| Step: 4
Training loss: 1.4364529848098755
Validation loss: 2.1256932981552614

Epoch: 5| Step: 5
Training loss: 2.953930377960205
Validation loss: 2.1161424036948913

Epoch: 5| Step: 6
Training loss: 2.0508275032043457
Validation loss: 2.1145928662310363

Epoch: 5| Step: 7
Training loss: 2.01509428024292
Validation loss: 2.1222561149186987

Epoch: 5| Step: 8
Training loss: 2.6860923767089844
Validation loss: 2.106126226404662

Epoch: 5| Step: 9
Training loss: 2.4072413444519043
Validation loss: 2.1145700536748415

Epoch: 5| Step: 10
Training loss: 2.005145788192749
Validation loss: 2.1154308088364138

Epoch: 84| Step: 0
Training loss: 2.2243220806121826
Validation loss: 2.1098453614019577

Epoch: 5| Step: 1
Training loss: 2.2826244831085205
Validation loss: 2.1033027018270185

Epoch: 5| Step: 2
Training loss: 3.0108695030212402
Validation loss: 2.104809150900892

Epoch: 5| Step: 3
Training loss: 2.42946195602417
Validation loss: 2.1016145239594164

Epoch: 5| Step: 4
Training loss: 2.1943695545196533
Validation loss: 2.08001462874874

Epoch: 5| Step: 5
Training loss: 3.154200315475464
Validation loss: 2.0868252426065426

Epoch: 5| Step: 6
Training loss: 1.86765456199646
Validation loss: 2.1387330973020164

Epoch: 5| Step: 7
Training loss: 1.4899542331695557
Validation loss: 2.1131692753043225

Epoch: 5| Step: 8
Training loss: 2.666318893432617
Validation loss: 2.14180007801261

Epoch: 5| Step: 9
Training loss: 1.9797273874282837
Validation loss: 2.171813570043092

Epoch: 5| Step: 10
Training loss: 2.3197855949401855
Validation loss: 2.162488175976661

Epoch: 85| Step: 0
Training loss: 2.895765781402588
Validation loss: 2.123811052691552

Epoch: 5| Step: 1
Training loss: 1.8158760070800781
Validation loss: 2.165255054350822

Epoch: 5| Step: 2
Training loss: 1.238040566444397
Validation loss: 2.164409586178359

Epoch: 5| Step: 3
Training loss: 2.7700042724609375
Validation loss: 2.1030718024059007

Epoch: 5| Step: 4
Training loss: 3.208983898162842
Validation loss: 2.110167831502935

Epoch: 5| Step: 5
Training loss: 3.1182734966278076
Validation loss: 2.164279842889437

Epoch: 5| Step: 6
Training loss: 1.9301913976669312
Validation loss: 2.144922434642751

Epoch: 5| Step: 7
Training loss: 2.014594554901123
Validation loss: 2.1687497477377615

Epoch: 5| Step: 8
Training loss: 2.325835704803467
Validation loss: 2.106136122057515

Epoch: 5| Step: 9
Training loss: 2.209526777267456
Validation loss: 2.144752699841735

Epoch: 5| Step: 10
Training loss: 2.348879814147949
Validation loss: 2.1568063741089194

Epoch: 86| Step: 0
Training loss: 2.620582103729248
Validation loss: 2.1159499563196653

Epoch: 5| Step: 1
Training loss: 2.814450979232788
Validation loss: 2.161233648177116

Epoch: 5| Step: 2
Training loss: 2.179615020751953
Validation loss: 2.1523247508592505

Epoch: 5| Step: 3
Training loss: 2.0307116508483887
Validation loss: 2.1039465652999056

Epoch: 5| Step: 4
Training loss: 1.7937091588974
Validation loss: 2.1020131495691117

Epoch: 5| Step: 5
Training loss: 2.019348621368408
Validation loss: 2.181102998795048

Epoch: 5| Step: 6
Training loss: 2.246847152709961
Validation loss: 2.1431152128404185

Epoch: 5| Step: 7
Training loss: 2.7445995807647705
Validation loss: 2.097542048782431

Epoch: 5| Step: 8
Training loss: 2.3272438049316406
Validation loss: 2.135683221201743

Epoch: 5| Step: 9
Training loss: 2.4575233459472656
Validation loss: 2.1337758982053368

Epoch: 5| Step: 10
Training loss: 2.28633713722229
Validation loss: 2.1729674505931076

Epoch: 87| Step: 0
Training loss: 2.0521719455718994
Validation loss: 2.127725303813975

Epoch: 5| Step: 1
Training loss: 1.4894970655441284
Validation loss: 2.1200575918279667

Epoch: 5| Step: 2
Training loss: 2.413503885269165
Validation loss: 2.146976904202533

Epoch: 5| Step: 3
Training loss: 2.547556161880493
Validation loss: 2.115089710040759

Epoch: 5| Step: 4
Training loss: 2.1544785499572754
Validation loss: 2.155447580481088

Epoch: 5| Step: 5
Training loss: 2.4860804080963135
Validation loss: 2.082267310029717

Epoch: 5| Step: 6
Training loss: 2.328535318374634
Validation loss: 2.1356047532891713

Epoch: 5| Step: 7
Training loss: 2.527705192565918
Validation loss: 2.1192173880915486

Epoch: 5| Step: 8
Training loss: 2.0376505851745605
Validation loss: 2.076735827230638

Epoch: 5| Step: 9
Training loss: 2.633129119873047
Validation loss: 2.1067232611358806

Epoch: 5| Step: 10
Training loss: 2.904482841491699
Validation loss: 2.1587219622827347

Epoch: 88| Step: 0
Training loss: 2.2466564178466797
Validation loss: 2.089628511859525

Epoch: 5| Step: 1
Training loss: 2.295745372772217
Validation loss: 2.096335772545107

Epoch: 5| Step: 2
Training loss: 1.8367538452148438
Validation loss: 2.1141454506945867

Epoch: 5| Step: 3
Training loss: 2.0847156047821045
Validation loss: 2.0738925677473827

Epoch: 5| Step: 4
Training loss: 2.497271776199341
Validation loss: 2.1279569261817524

Epoch: 5| Step: 5
Training loss: 1.928431510925293
Validation loss: 2.091619319813226

Epoch: 5| Step: 6
Training loss: 3.0123982429504395
Validation loss: 2.0941009316393124

Epoch: 5| Step: 7
Training loss: 1.9557781219482422
Validation loss: 2.0903231661806823

Epoch: 5| Step: 8
Training loss: 2.6643333435058594
Validation loss: 2.117683115825858

Epoch: 5| Step: 9
Training loss: 2.3411765098571777
Validation loss: 2.109330568262326

Epoch: 5| Step: 10
Training loss: 2.571723699569702
Validation loss: 2.131929269400976

Epoch: 89| Step: 0
Training loss: 1.9824762344360352
Validation loss: 2.0958583226767917

Epoch: 5| Step: 1
Training loss: 2.665055513381958
Validation loss: 2.10398413929888

Epoch: 5| Step: 2
Training loss: 2.222957134246826
Validation loss: 2.0905470207173336

Epoch: 5| Step: 3
Training loss: 1.908816933631897
Validation loss: 2.0859508578495314

Epoch: 5| Step: 4
Training loss: 2.1218197345733643
Validation loss: 2.110189140483897

Epoch: 5| Step: 5
Training loss: 1.9553184509277344
Validation loss: 2.106902305797864

Epoch: 5| Step: 6
Training loss: 2.51758074760437
Validation loss: 2.097424002103908

Epoch: 5| Step: 7
Training loss: 3.373109817504883
Validation loss: 2.163264528397591

Epoch: 5| Step: 8
Training loss: 2.1509361267089844
Validation loss: 2.1525732278823853

Epoch: 5| Step: 9
Training loss: 2.381190776824951
Validation loss: 2.146904173717704

Epoch: 5| Step: 10
Training loss: 2.308603286743164
Validation loss: 2.1170407469554613

Epoch: 90| Step: 0
Training loss: 2.1254079341888428
Validation loss: 2.158433783438898

Epoch: 5| Step: 1
Training loss: 1.9097797870635986
Validation loss: 2.0784992018053607

Epoch: 5| Step: 2
Training loss: 1.9371020793914795
Validation loss: 2.1190621827238347

Epoch: 5| Step: 3
Training loss: 2.4793481826782227
Validation loss: 2.0981676757976575

Epoch: 5| Step: 4
Training loss: 2.543884754180908
Validation loss: 2.124523788370112

Epoch: 5| Step: 5
Training loss: 2.604315996170044
Validation loss: 2.1113692329775904

Epoch: 5| Step: 6
Training loss: 2.569462776184082
Validation loss: 2.0874443848927817

Epoch: 5| Step: 7
Training loss: 2.502126693725586
Validation loss: 2.1054563560793476

Epoch: 5| Step: 8
Training loss: 1.9447351694107056
Validation loss: 2.1090230685408398

Epoch: 5| Step: 9
Training loss: 2.1031031608581543
Validation loss: 2.110340597809002

Epoch: 5| Step: 10
Training loss: 2.8033783435821533
Validation loss: 2.0868368764077463

Epoch: 91| Step: 0
Training loss: 2.142742395401001
Validation loss: 2.118987601290467

Epoch: 5| Step: 1
Training loss: 2.234837532043457
Validation loss: 2.1350243950402863

Epoch: 5| Step: 2
Training loss: 1.9420738220214844
Validation loss: 2.1080102920532227

Epoch: 5| Step: 3
Training loss: 2.2411327362060547
Validation loss: 2.1193494976207776

Epoch: 5| Step: 4
Training loss: 2.1885128021240234
Validation loss: 2.077655884527391

Epoch: 5| Step: 5
Training loss: 1.9874480962753296
Validation loss: 2.085708964255548

Epoch: 5| Step: 6
Training loss: 2.3254687786102295
Validation loss: 2.169988783456946

Epoch: 5| Step: 7
Training loss: 3.146526575088501
Validation loss: 2.066502571105957

Epoch: 5| Step: 8
Training loss: 2.1040139198303223
Validation loss: 2.0693280773778118

Epoch: 5| Step: 9
Training loss: 2.5481958389282227
Validation loss: 2.08541154092358

Epoch: 5| Step: 10
Training loss: 2.6322457790374756
Validation loss: 2.125827443215155

Epoch: 92| Step: 0
Training loss: 2.7350499629974365
Validation loss: 2.022176101643552

Epoch: 5| Step: 1
Training loss: 1.7167857885360718
Validation loss: 2.0886872673547394

Epoch: 5| Step: 2
Training loss: 2.149810552597046
Validation loss: 2.125565436578566

Epoch: 5| Step: 3
Training loss: 1.9871717691421509
Validation loss: 2.0891497019798524

Epoch: 5| Step: 4
Training loss: 3.107405662536621
Validation loss: 2.13304038329791

Epoch: 5| Step: 5
Training loss: 2.4585041999816895
Validation loss: 2.112407248507264

Epoch: 5| Step: 6
Training loss: 2.2552382946014404
Validation loss: 2.14136194029162

Epoch: 5| Step: 7
Training loss: 2.335081100463867
Validation loss: 2.085782681742022

Epoch: 5| Step: 8
Training loss: 2.3720970153808594
Validation loss: 2.127002485336796

Epoch: 5| Step: 9
Training loss: 2.6824047565460205
Validation loss: 2.1010468441952943

Epoch: 5| Step: 10
Training loss: 2.1506409645080566
Validation loss: 2.160686372428812

Epoch: 93| Step: 0
Training loss: 3.3807663917541504
Validation loss: 2.1558882562063073

Epoch: 5| Step: 1
Training loss: 2.4745686054229736
Validation loss: 2.134568084952652

Epoch: 5| Step: 2
Training loss: 2.0665218830108643
Validation loss: 2.1747215050523

Epoch: 5| Step: 3
Training loss: 2.323077440261841
Validation loss: 2.1388914790204776

Epoch: 5| Step: 4
Training loss: 1.9986648559570312
Validation loss: 2.0419799063795354

Epoch: 5| Step: 5
Training loss: 2.083981990814209
Validation loss: 2.0866828323692403

Epoch: 5| Step: 6
Training loss: 2.212144613265991
Validation loss: 2.13124656420882

Epoch: 5| Step: 7
Training loss: 1.9792003631591797
Validation loss: 2.093767532738306

Epoch: 5| Step: 8
Training loss: 2.2357780933380127
Validation loss: 2.061935519659391

Epoch: 5| Step: 9
Training loss: 2.8368306159973145
Validation loss: 2.155352538631808

Epoch: 5| Step: 10
Training loss: 2.0111501216888428
Validation loss: 2.0811663609679028

Epoch: 94| Step: 0
Training loss: 2.166227340698242
Validation loss: 2.106848006607384

Epoch: 5| Step: 1
Training loss: 2.37260103225708
Validation loss: 2.1390278262476765

Epoch: 5| Step: 2
Training loss: 2.375898599624634
Validation loss: 2.079671052194411

Epoch: 5| Step: 3
Training loss: 2.7383453845977783
Validation loss: 2.1147855366429975

Epoch: 5| Step: 4
Training loss: 1.839930772781372
Validation loss: 2.1343241814644105

Epoch: 5| Step: 5
Training loss: 1.6675770282745361
Validation loss: 2.1572902382061048

Epoch: 5| Step: 6
Training loss: 3.595813035964966
Validation loss: 2.104477192765923

Epoch: 5| Step: 7
Training loss: 2.372854232788086
Validation loss: 2.1163898693617953

Epoch: 5| Step: 8
Training loss: 1.82355535030365
Validation loss: 2.123191331022529

Epoch: 5| Step: 9
Training loss: 1.7133758068084717
Validation loss: 2.1244110753459315

Epoch: 5| Step: 10
Training loss: 2.230999708175659
Validation loss: 2.1069249799174647

Epoch: 95| Step: 0
Training loss: 2.2075746059417725
Validation loss: 2.11225446321631

Epoch: 5| Step: 1
Training loss: 2.2115395069122314
Validation loss: 2.0731505309381792

Epoch: 5| Step: 2
Training loss: 2.6008594036102295
Validation loss: 2.0917591741008144

Epoch: 5| Step: 3
Training loss: 2.170290470123291
Validation loss: 2.1125821823714883

Epoch: 5| Step: 4
Training loss: 2.249376058578491
Validation loss: 2.1401417921948176

Epoch: 5| Step: 5
Training loss: 2.5413670539855957
Validation loss: 2.136678336769022

Epoch: 5| Step: 6
Training loss: 2.4370596408843994
Validation loss: 2.1076208929861746

Epoch: 5| Step: 7
Training loss: 2.441641092300415
Validation loss: 2.1075324473842496

Epoch: 5| Step: 8
Training loss: 1.8601207733154297
Validation loss: 2.1365440301997687

Epoch: 5| Step: 9
Training loss: 2.4048774242401123
Validation loss: 2.1330849021993656

Epoch: 5| Step: 10
Training loss: 2.0020220279693604
Validation loss: 2.0846359473402782

Epoch: 96| Step: 0
Training loss: 2.4004454612731934
Validation loss: 2.1189745139050227

Epoch: 5| Step: 1
Training loss: 2.55381178855896
Validation loss: 2.1333308937729045

Epoch: 5| Step: 2
Training loss: 1.7368253469467163
Validation loss: 2.1178062679947063

Epoch: 5| Step: 3
Training loss: 1.852280616760254
Validation loss: 2.1172593152651222

Epoch: 5| Step: 4
Training loss: 2.4578914642333984
Validation loss: 2.1524466327441636

Epoch: 5| Step: 5
Training loss: 2.4187216758728027
Validation loss: 2.146835345093922

Epoch: 5| Step: 6
Training loss: 2.719001531600952
Validation loss: 2.1949509061792845

Epoch: 5| Step: 7
Training loss: 2.1699209213256836
Validation loss: 2.1355504271804646

Epoch: 5| Step: 8
Training loss: 2.2392797470092773
Validation loss: 2.154434327156313

Epoch: 5| Step: 9
Training loss: 2.7081596851348877
Validation loss: 2.133337366965509

Epoch: 5| Step: 10
Training loss: 2.3118152618408203
Validation loss: 2.1145609501869447

Epoch: 97| Step: 0
Training loss: 2.3516271114349365
Validation loss: 2.1521593729654946

Epoch: 5| Step: 1
Training loss: 2.1066908836364746
Validation loss: 2.147671911024278

Epoch: 5| Step: 2
Training loss: 2.4790008068084717
Validation loss: 2.1604285291446153

Epoch: 5| Step: 3
Training loss: 2.662686824798584
Validation loss: 2.155223141434372

Epoch: 5| Step: 4
Training loss: 1.8453502655029297
Validation loss: 2.0955268388153403

Epoch: 5| Step: 5
Training loss: 2.748751401901245
Validation loss: 2.138862148407967

Epoch: 5| Step: 6
Training loss: 1.9625263214111328
Validation loss: 2.122927483691964

Epoch: 5| Step: 7
Training loss: 2.073596239089966
Validation loss: 2.1287316545363395

Epoch: 5| Step: 8
Training loss: 2.661801815032959
Validation loss: 2.150013945435965

Epoch: 5| Step: 9
Training loss: 2.2440342903137207
Validation loss: 2.1038651415096816

Epoch: 5| Step: 10
Training loss: 1.8648502826690674
Validation loss: 2.0946366120410222

Epoch: 98| Step: 0
Training loss: 2.693615436553955
Validation loss: 2.0581583694745134

Epoch: 5| Step: 1
Training loss: 3.083759307861328
Validation loss: 2.1140101032872356

Epoch: 5| Step: 2
Training loss: 2.4685909748077393
Validation loss: 2.102519727522327

Epoch: 5| Step: 3
Training loss: 2.0884616374969482
Validation loss: 2.126776438887401

Epoch: 5| Step: 4
Training loss: 2.89115834236145
Validation loss: 2.102510121560866

Epoch: 5| Step: 5
Training loss: 1.9537864923477173
Validation loss: 2.1159367292158064

Epoch: 5| Step: 6
Training loss: 2.2187106609344482
Validation loss: 2.105621225090437

Epoch: 5| Step: 7
Training loss: 1.7128403186798096
Validation loss: 2.139399036284416

Epoch: 5| Step: 8
Training loss: 1.9662580490112305
Validation loss: 2.087121812246179

Epoch: 5| Step: 9
Training loss: 2.057365894317627
Validation loss: 2.141051261655746

Epoch: 5| Step: 10
Training loss: 2.1740517616271973
Validation loss: 2.088055759347895

Epoch: 99| Step: 0
Training loss: 2.3211982250213623
Validation loss: 2.098161115441271

Epoch: 5| Step: 1
Training loss: 3.0775513648986816
Validation loss: 2.1275671118049213

Epoch: 5| Step: 2
Training loss: 2.2976951599121094
Validation loss: 2.093924137853807

Epoch: 5| Step: 3
Training loss: 2.0086910724639893
Validation loss: 2.106338426630984

Epoch: 5| Step: 4
Training loss: 2.9790244102478027
Validation loss: 2.0913526165869927

Epoch: 5| Step: 5
Training loss: 2.3045334815979004
Validation loss: 2.065041270307315

Epoch: 5| Step: 6
Training loss: 2.242183208465576
Validation loss: 2.0650098862186557

Epoch: 5| Step: 7
Training loss: 1.2978839874267578
Validation loss: 2.1116824009085216

Epoch: 5| Step: 8
Training loss: 2.203827142715454
Validation loss: 2.065660167765874

Epoch: 5| Step: 9
Training loss: 2.0052247047424316
Validation loss: 2.0970423593316028

Epoch: 5| Step: 10
Training loss: 2.7537930011749268
Validation loss: 2.059175358023695

Epoch: 100| Step: 0
Training loss: 2.1850953102111816
Validation loss: 2.1242347481430217

Epoch: 5| Step: 1
Training loss: 2.6608636379241943
Validation loss: 2.098123574769625

Epoch: 5| Step: 2
Training loss: 1.7565984725952148
Validation loss: 2.1135928656465266

Epoch: 5| Step: 3
Training loss: 2.036353588104248
Validation loss: 2.085569498359516

Epoch: 5| Step: 4
Training loss: 2.5499682426452637
Validation loss: 2.0989622685217086

Epoch: 5| Step: 5
Training loss: 1.7686569690704346
Validation loss: 2.093280728145312

Epoch: 5| Step: 6
Training loss: 2.680342197418213
Validation loss: 2.1170883435075

Epoch: 5| Step: 7
Training loss: 2.334744930267334
Validation loss: 2.0880827211564585

Epoch: 5| Step: 8
Training loss: 2.6441099643707275
Validation loss: 2.129819990486227

Epoch: 5| Step: 9
Training loss: 1.926801323890686
Validation loss: 2.1214051720916585

Epoch: 5| Step: 10
Training loss: 2.177225351333618
Validation loss: 2.1216537567877

Epoch: 101| Step: 0
Training loss: 2.0623888969421387
Validation loss: 2.1323268951908236

Epoch: 5| Step: 1
Training loss: 2.5846667289733887
Validation loss: 2.1361288691079743

Epoch: 5| Step: 2
Training loss: 2.8921422958374023
Validation loss: 2.0903729802818707

Epoch: 5| Step: 3
Training loss: 2.1672940254211426
Validation loss: 2.1444838713574153

Epoch: 5| Step: 4
Training loss: 2.763650894165039
Validation loss: 2.135903581496208

Epoch: 5| Step: 5
Training loss: 2.9271247386932373
Validation loss: 2.111254994587232

Epoch: 5| Step: 6
Training loss: 2.0200886726379395
Validation loss: 2.0928759254435056

Epoch: 5| Step: 7
Training loss: 2.099613904953003
Validation loss: 2.1268274630269697

Epoch: 5| Step: 8
Training loss: 1.5467742681503296
Validation loss: 2.109910362510271

Epoch: 5| Step: 9
Training loss: 2.1218128204345703
Validation loss: 2.1455690476202194

Epoch: 5| Step: 10
Training loss: 1.3936630487442017
Validation loss: 2.114234948670992

Epoch: 102| Step: 0
Training loss: 2.565089225769043
Validation loss: 2.0845905427009828

Epoch: 5| Step: 1
Training loss: 2.242640733718872
Validation loss: 2.139661060866489

Epoch: 5| Step: 2
Training loss: 2.47636079788208
Validation loss: 2.1461140724920456

Epoch: 5| Step: 3
Training loss: 2.127197742462158
Validation loss: 2.09860493803537

Epoch: 5| Step: 4
Training loss: 2.289086103439331
Validation loss: 2.1114727540682723

Epoch: 5| Step: 5
Training loss: 1.9406028985977173
Validation loss: 2.060729243422067

Epoch: 5| Step: 6
Training loss: 2.249563455581665
Validation loss: 2.1374132299935944

Epoch: 5| Step: 7
Training loss: 1.769781470298767
Validation loss: 2.099512189947149

Epoch: 5| Step: 8
Training loss: 2.5578505992889404
Validation loss: 2.1109400769715667

Epoch: 5| Step: 9
Training loss: 2.0163190364837646
Validation loss: 2.082919610443936

Epoch: 5| Step: 10
Training loss: 2.5757336616516113
Validation loss: 2.1297317192118657

Epoch: 103| Step: 0
Training loss: 2.603775978088379
Validation loss: 2.110498453981133

Epoch: 5| Step: 1
Training loss: 2.07993745803833
Validation loss: 2.15460717293524

Epoch: 5| Step: 2
Training loss: 2.4046120643615723
Validation loss: 2.1342222934128134

Epoch: 5| Step: 3
Training loss: 2.4117066860198975
Validation loss: 2.1748060616113807

Epoch: 5| Step: 4
Training loss: 2.2066433429718018
Validation loss: 2.1022054367167975

Epoch: 5| Step: 5
Training loss: 2.738253116607666
Validation loss: 2.1162359945235716

Epoch: 5| Step: 6
Training loss: 2.034651279449463
Validation loss: 2.122971832111318

Epoch: 5| Step: 7
Training loss: 2.2793726921081543
Validation loss: 2.103259817246468

Epoch: 5| Step: 8
Training loss: 2.6435680389404297
Validation loss: 2.128292432395361

Epoch: 5| Step: 9
Training loss: 1.6983671188354492
Validation loss: 2.1203425879119546

Epoch: 5| Step: 10
Training loss: 1.6034003496170044
Validation loss: 2.1674735828112532

Epoch: 104| Step: 0
Training loss: 2.1934854984283447
Validation loss: 2.1414021984223397

Epoch: 5| Step: 1
Training loss: 2.017232894897461
Validation loss: 2.130845962032195

Epoch: 5| Step: 2
Training loss: 2.345215320587158
Validation loss: 2.1820804239601217

Epoch: 5| Step: 3
Training loss: 1.9317271709442139
Validation loss: 2.11310734287385

Epoch: 5| Step: 4
Training loss: 2.810697555541992
Validation loss: 2.136528281755345

Epoch: 5| Step: 5
Training loss: 2.1705756187438965
Validation loss: 2.148698749080781

Epoch: 5| Step: 6
Training loss: 2.2116427421569824
Validation loss: 2.114126943772839

Epoch: 5| Step: 7
Training loss: 2.0697672367095947
Validation loss: 2.0819107947811

Epoch: 5| Step: 8
Training loss: 2.117858648300171
Validation loss: 2.117956502463228

Epoch: 5| Step: 9
Training loss: 2.4743399620056152
Validation loss: 2.1755034987644484

Epoch: 5| Step: 10
Training loss: 2.542586088180542
Validation loss: 2.0921999203261508

Epoch: 105| Step: 0
Training loss: 1.506216287612915
Validation loss: 2.0992885610108734

Epoch: 5| Step: 1
Training loss: 1.8986728191375732
Validation loss: 2.1031811673154115

Epoch: 5| Step: 2
Training loss: 2.8758416175842285
Validation loss: 2.116480476112776

Epoch: 5| Step: 3
Training loss: 3.02925181388855
Validation loss: 2.137486825707138

Epoch: 5| Step: 4
Training loss: 2.2714126110076904
Validation loss: 2.1136457740619616

Epoch: 5| Step: 5
Training loss: 1.7257839441299438
Validation loss: 2.1494958964727258

Epoch: 5| Step: 6
Training loss: 2.1470324993133545
Validation loss: 2.088782315613121

Epoch: 5| Step: 7
Training loss: 2.1809253692626953
Validation loss: 2.0987033510720856

Epoch: 5| Step: 8
Training loss: 2.679466724395752
Validation loss: 2.1091164081327376

Epoch: 5| Step: 9
Training loss: 2.1415140628814697
Validation loss: 2.1336637709730413

Epoch: 5| Step: 10
Training loss: 2.482980728149414
Validation loss: 2.1064234933545514

Epoch: 106| Step: 0
Training loss: 1.8484338521957397
Validation loss: 2.116993873350082

Epoch: 5| Step: 1
Training loss: 1.5228631496429443
Validation loss: 2.1050551283744072

Epoch: 5| Step: 2
Training loss: 2.143653154373169
Validation loss: 2.1189929336629887

Epoch: 5| Step: 3
Training loss: 1.9451382160186768
Validation loss: 2.14414967003689

Epoch: 5| Step: 4
Training loss: 2.832998752593994
Validation loss: 2.151938020542104

Epoch: 5| Step: 5
Training loss: 2.6398205757141113
Validation loss: 2.1319795962302917

Epoch: 5| Step: 6
Training loss: 2.6647579669952393
Validation loss: 2.146701955026196

Epoch: 5| Step: 7
Training loss: 1.9825751781463623
Validation loss: 2.126139224216502

Epoch: 5| Step: 8
Training loss: 2.507955551147461
Validation loss: 2.1333337009594007

Epoch: 5| Step: 9
Training loss: 2.967294216156006
Validation loss: 2.1262574195861816

Epoch: 5| Step: 10
Training loss: 2.0002267360687256
Validation loss: 2.1033393836790517

Epoch: 107| Step: 0
Training loss: 2.1377029418945312
Validation loss: 2.1064896275920253

Epoch: 5| Step: 1
Training loss: 1.9795001745224
Validation loss: 2.172713933452483

Epoch: 5| Step: 2
Training loss: 3.0559628009796143
Validation loss: 2.1267151217306814

Epoch: 5| Step: 3
Training loss: 2.21694016456604
Validation loss: 2.1228364001038256

Epoch: 5| Step: 4
Training loss: 1.9094493389129639
Validation loss: 2.1243623969375447

Epoch: 5| Step: 5
Training loss: 2.284149646759033
Validation loss: 2.083676238213816

Epoch: 5| Step: 6
Training loss: 2.081493377685547
Validation loss: 2.125528226616562

Epoch: 5| Step: 7
Training loss: 2.5814735889434814
Validation loss: 2.1288864356215282

Epoch: 5| Step: 8
Training loss: 1.7994353771209717
Validation loss: 2.1159249467234456

Epoch: 5| Step: 9
Training loss: 1.9727394580841064
Validation loss: 2.096993156658706

Epoch: 5| Step: 10
Training loss: 2.973696231842041
Validation loss: 2.1197201949293896

Epoch: 108| Step: 0
Training loss: 2.6327526569366455
Validation loss: 2.1266979197020173

Epoch: 5| Step: 1
Training loss: 2.5988173484802246
Validation loss: 2.147106905137339

Epoch: 5| Step: 2
Training loss: 2.3877177238464355
Validation loss: 2.11021266957765

Epoch: 5| Step: 3
Training loss: 2.250936985015869
Validation loss: 2.1480087054673063

Epoch: 5| Step: 4
Training loss: 2.393798589706421
Validation loss: 2.073487707363662

Epoch: 5| Step: 5
Training loss: 2.1642329692840576
Validation loss: 2.0752731113023657

Epoch: 5| Step: 6
Training loss: 1.933389663696289
Validation loss: 2.0471731667877524

Epoch: 5| Step: 7
Training loss: 2.010399103164673
Validation loss: 2.101732180964562

Epoch: 5| Step: 8
Training loss: 1.6709215641021729
Validation loss: 2.099240411994278

Epoch: 5| Step: 9
Training loss: 2.133800983428955
Validation loss: 2.1032539593276156

Epoch: 5| Step: 10
Training loss: 2.752162218093872
Validation loss: 2.1620658584820327

Epoch: 109| Step: 0
Training loss: 1.7704378366470337
Validation loss: 2.1140874995980212

Epoch: 5| Step: 1
Training loss: 2.453494071960449
Validation loss: 2.048366395376062

Epoch: 5| Step: 2
Training loss: 2.5833170413970947
Validation loss: 2.12112093997258

Epoch: 5| Step: 3
Training loss: 2.055710554122925
Validation loss: 2.0866430369756555

Epoch: 5| Step: 4
Training loss: 2.3793647289276123
Validation loss: 2.0799739078808854

Epoch: 5| Step: 5
Training loss: 2.7429585456848145
Validation loss: 2.131015782715172

Epoch: 5| Step: 6
Training loss: 1.7452232837677002
Validation loss: 2.1721488198926373

Epoch: 5| Step: 7
Training loss: 1.8046430349349976
Validation loss: 2.1537515860731884

Epoch: 5| Step: 8
Training loss: 2.7054171562194824
Validation loss: 2.074113325406146

Epoch: 5| Step: 9
Training loss: 2.2398080825805664
Validation loss: 2.1681925327547136

Epoch: 5| Step: 10
Training loss: 2.247838258743286
Validation loss: 2.149890922730969

Epoch: 110| Step: 0
Training loss: 1.941786527633667
Validation loss: 2.1272369469365766

Epoch: 5| Step: 1
Training loss: 2.0915064811706543
Validation loss: 2.12149550068763

Epoch: 5| Step: 2
Training loss: 1.4258270263671875
Validation loss: 2.1326773730657433

Epoch: 5| Step: 3
Training loss: 2.6107242107391357
Validation loss: 2.146384428906184

Epoch: 5| Step: 4
Training loss: 2.5311827659606934
Validation loss: 2.113363604391775

Epoch: 5| Step: 5
Training loss: 2.487231731414795
Validation loss: 2.1575100985906457

Epoch: 5| Step: 6
Training loss: 2.465381622314453
Validation loss: 2.1932753183508433

Epoch: 5| Step: 7
Training loss: 2.0687108039855957
Validation loss: 2.131397170405234

Epoch: 5| Step: 8
Training loss: 2.675942897796631
Validation loss: 2.0859976045546995

Epoch: 5| Step: 9
Training loss: 1.9053884744644165
Validation loss: 2.1610979239145913

Epoch: 5| Step: 10
Training loss: 2.495512008666992
Validation loss: 2.0852724480372604

Epoch: 111| Step: 0
Training loss: 3.0711722373962402
Validation loss: 2.1413755596324964

Epoch: 5| Step: 1
Training loss: 1.8212484121322632
Validation loss: 2.1068871303271224

Epoch: 5| Step: 2
Training loss: 2.072599172592163
Validation loss: 2.115955647601876

Epoch: 5| Step: 3
Training loss: 2.2822940349578857
Validation loss: 2.134774987415601

Epoch: 5| Step: 4
Training loss: 2.45151948928833
Validation loss: 2.0958717625628234

Epoch: 5| Step: 5
Training loss: 1.7800052165985107
Validation loss: 2.078176639413321

Epoch: 5| Step: 6
Training loss: 2.2202682495117188
Validation loss: 2.078935933369462

Epoch: 5| Step: 7
Training loss: 2.1076738834381104
Validation loss: 2.0703323477058

Epoch: 5| Step: 8
Training loss: 2.066175937652588
Validation loss: 2.068195853182065

Epoch: 5| Step: 9
Training loss: 2.3345227241516113
Validation loss: 2.148720787417504

Epoch: 5| Step: 10
Training loss: 2.5856528282165527
Validation loss: 2.0705208932199786

Epoch: 112| Step: 0
Training loss: 2.000908374786377
Validation loss: 2.133432213978101

Epoch: 5| Step: 1
Training loss: 2.168980121612549
Validation loss: 2.1185375221313967

Epoch: 5| Step: 2
Training loss: 2.9353859424591064
Validation loss: 2.0817617447145524

Epoch: 5| Step: 3
Training loss: 1.5441837310791016
Validation loss: 2.1077539946443293

Epoch: 5| Step: 4
Training loss: 2.486933946609497
Validation loss: 2.142236832649477

Epoch: 5| Step: 5
Training loss: 1.992940902709961
Validation loss: 2.1272421165179183

Epoch: 5| Step: 6
Training loss: 2.7538905143737793
Validation loss: 2.1389968446505967

Epoch: 5| Step: 7
Training loss: 2.979142427444458
Validation loss: 2.076200069919709

Epoch: 5| Step: 8
Training loss: 2.2728707790374756
Validation loss: 2.12518475901696

Epoch: 5| Step: 9
Training loss: 1.9935121536254883
Validation loss: 2.1447892765845022

Epoch: 5| Step: 10
Training loss: 1.8017609119415283
Validation loss: 2.1046968403682915

Epoch: 113| Step: 0
Training loss: 1.6301040649414062
Validation loss: 2.076195316929971

Epoch: 5| Step: 1
Training loss: 2.5941028594970703
Validation loss: 2.0980240862856627

Epoch: 5| Step: 2
Training loss: 2.583311080932617
Validation loss: 2.1305887417126725

Epoch: 5| Step: 3
Training loss: 1.6925411224365234
Validation loss: 2.108950771311278

Epoch: 5| Step: 4
Training loss: 2.916114330291748
Validation loss: 2.072882285682104

Epoch: 5| Step: 5
Training loss: 2.397021770477295
Validation loss: 2.1156889982120965

Epoch: 5| Step: 6
Training loss: 1.5393646955490112
Validation loss: 2.105604474262525

Epoch: 5| Step: 7
Training loss: 2.5131421089172363
Validation loss: 2.1347884439652964

Epoch: 5| Step: 8
Training loss: 1.8568878173828125
Validation loss: 2.087169724126016

Epoch: 5| Step: 9
Training loss: 2.204829216003418
Validation loss: 2.1120263273997972

Epoch: 5| Step: 10
Training loss: 2.8895506858825684
Validation loss: 2.114672453172745

Epoch: 114| Step: 0
Training loss: 2.3581786155700684
Validation loss: 2.121220291301768

Epoch: 5| Step: 1
Training loss: 2.0615763664245605
Validation loss: 2.1753468026397047

Epoch: 5| Step: 2
Training loss: 2.028200626373291
Validation loss: 2.1032448942943285

Epoch: 5| Step: 3
Training loss: 2.4976069927215576
Validation loss: 2.1029227228574854

Epoch: 5| Step: 4
Training loss: 2.1482810974121094
Validation loss: 2.1121625400358632

Epoch: 5| Step: 5
Training loss: 2.564457654953003
Validation loss: 2.0944333653296194

Epoch: 5| Step: 6
Training loss: 2.5765604972839355
Validation loss: 2.1101717026002946

Epoch: 5| Step: 7
Training loss: 2.4503402709960938
Validation loss: 2.0653544164473012

Epoch: 5| Step: 8
Training loss: 1.988836646080017
Validation loss: 2.0825829172647126

Epoch: 5| Step: 9
Training loss: 1.774709939956665
Validation loss: 2.100873435697248

Epoch: 5| Step: 10
Training loss: 2.0780887603759766
Validation loss: 2.119496609575005

Epoch: 115| Step: 0
Training loss: 1.9397685527801514
Validation loss: 2.079276959101359

Epoch: 5| Step: 1
Training loss: 2.193638324737549
Validation loss: 2.13604857331963

Epoch: 5| Step: 2
Training loss: 2.033714771270752
Validation loss: 2.1027984208958124

Epoch: 5| Step: 3
Training loss: 1.8355858325958252
Validation loss: 2.157627272349532

Epoch: 5| Step: 4
Training loss: 3.016007900238037
Validation loss: 2.1354899124432634

Epoch: 5| Step: 5
Training loss: 2.0655345916748047
Validation loss: 2.1086702885166293

Epoch: 5| Step: 6
Training loss: 1.6971702575683594
Validation loss: 2.0946929608621905

Epoch: 5| Step: 7
Training loss: 2.5121567249298096
Validation loss: 2.0956844950235016

Epoch: 5| Step: 8
Training loss: 2.058847665786743
Validation loss: 2.1123654996195147

Epoch: 5| Step: 9
Training loss: 2.6852126121520996
Validation loss: 2.136501166128343

Epoch: 5| Step: 10
Training loss: 2.754505157470703
Validation loss: 2.1206273237864175

Epoch: 116| Step: 0
Training loss: 2.8738465309143066
Validation loss: 2.1198285702736146

Epoch: 5| Step: 1
Training loss: 2.4275059700012207
Validation loss: 2.1288886390706545

Epoch: 5| Step: 2
Training loss: 2.332205295562744
Validation loss: 2.119344126793646

Epoch: 5| Step: 3
Training loss: 2.029151201248169
Validation loss: 2.1668742984853764

Epoch: 5| Step: 4
Training loss: 2.000565528869629
Validation loss: 2.1044705657548803

Epoch: 5| Step: 5
Training loss: 1.2279369831085205
Validation loss: 2.1148587580650084

Epoch: 5| Step: 6
Training loss: 2.330655574798584
Validation loss: 2.1367309952294953

Epoch: 5| Step: 7
Training loss: 2.9619693756103516
Validation loss: 2.134655393579955

Epoch: 5| Step: 8
Training loss: 2.03324556350708
Validation loss: 2.1703534049372517

Epoch: 5| Step: 9
Training loss: 2.3124032020568848
Validation loss: 2.1574245345207954

Epoch: 5| Step: 10
Training loss: 2.151851177215576
Validation loss: 2.1506383457491474

Epoch: 117| Step: 0
Training loss: 2.470062732696533
Validation loss: 2.158254288857983

Epoch: 5| Step: 1
Training loss: 2.6906135082244873
Validation loss: 2.1951338142477055

Epoch: 5| Step: 2
Training loss: 1.8625990152359009
Validation loss: 2.160801038947157

Epoch: 5| Step: 3
Training loss: 2.4105257987976074
Validation loss: 2.1189088257410194

Epoch: 5| Step: 4
Training loss: 2.451348066329956
Validation loss: 2.118304537188622

Epoch: 5| Step: 5
Training loss: 3.02573823928833
Validation loss: 2.133254974119125

Epoch: 5| Step: 6
Training loss: 2.1429314613342285
Validation loss: 2.1889289399628997

Epoch: 5| Step: 7
Training loss: 2.269378185272217
Validation loss: 2.154997633349511

Epoch: 5| Step: 8
Training loss: 2.098543167114258
Validation loss: 2.1530660647217945

Epoch: 5| Step: 9
Training loss: 1.763573408126831
Validation loss: 2.066987365804693

Epoch: 5| Step: 10
Training loss: 1.5515682697296143
Validation loss: 2.142089054148684

Epoch: 118| Step: 0
Training loss: 2.0236563682556152
Validation loss: 2.097488259756437

Epoch: 5| Step: 1
Training loss: 2.283844232559204
Validation loss: 2.088835102255626

Epoch: 5| Step: 2
Training loss: 1.9264951944351196
Validation loss: 2.1144784419767317

Epoch: 5| Step: 3
Training loss: 2.3192837238311768
Validation loss: 2.1580394288545013

Epoch: 5| Step: 4
Training loss: 1.9960768222808838
Validation loss: 2.1086779153475197

Epoch: 5| Step: 5
Training loss: 2.468245506286621
Validation loss: 2.152749123111848

Epoch: 5| Step: 6
Training loss: 2.8764593601226807
Validation loss: 2.089818985231461

Epoch: 5| Step: 7
Training loss: 2.084329605102539
Validation loss: 2.159768945427351

Epoch: 5| Step: 8
Training loss: 2.1222245693206787
Validation loss: 2.1109387977148897

Epoch: 5| Step: 9
Training loss: 2.421431064605713
Validation loss: 2.0889129228489374

Epoch: 5| Step: 10
Training loss: 2.2297372817993164
Validation loss: 2.1513731120735087

Epoch: 119| Step: 0
Training loss: 1.8752769231796265
Validation loss: 2.0742511582630936

Epoch: 5| Step: 1
Training loss: 2.2291603088378906
Validation loss: 2.1051418704371296

Epoch: 5| Step: 2
Training loss: 2.0307068824768066
Validation loss: 2.1178512137423278

Epoch: 5| Step: 3
Training loss: 2.5014920234680176
Validation loss: 2.1426835636938772

Epoch: 5| Step: 4
Training loss: 1.9857566356658936
Validation loss: 2.1131225862810687

Epoch: 5| Step: 5
Training loss: 2.51206636428833
Validation loss: 2.1448969623093963

Epoch: 5| Step: 6
Training loss: 2.202475070953369
Validation loss: 2.096187558225406

Epoch: 5| Step: 7
Training loss: 2.480360269546509
Validation loss: 2.1389865926516953

Epoch: 5| Step: 8
Training loss: 2.3872029781341553
Validation loss: 2.08206122280449

Epoch: 5| Step: 9
Training loss: 2.187737226486206
Validation loss: 2.0943246272302445

Epoch: 5| Step: 10
Training loss: 2.369873046875
Validation loss: 2.110972609571231

Epoch: 120| Step: 0
Training loss: 2.5254299640655518
Validation loss: 2.138843935023072

Epoch: 5| Step: 1
Training loss: 2.361586809158325
Validation loss: 2.0868696012804584

Epoch: 5| Step: 2
Training loss: 1.7682136297225952
Validation loss: 2.1367467193193335

Epoch: 5| Step: 3
Training loss: 2.377753734588623
Validation loss: 2.1269133270427747

Epoch: 5| Step: 4
Training loss: 1.9497308731079102
Validation loss: 2.090678116326691

Epoch: 5| Step: 5
Training loss: 2.8001813888549805
Validation loss: 2.106784261682982

Epoch: 5| Step: 6
Training loss: 1.5671584606170654
Validation loss: 2.1031423204688617

Epoch: 5| Step: 7
Training loss: 2.1794886589050293
Validation loss: 2.107257627671765

Epoch: 5| Step: 8
Training loss: 1.9807188510894775
Validation loss: 2.1153914415708153

Epoch: 5| Step: 9
Training loss: 2.579852342605591
Validation loss: 2.0705426072561615

Epoch: 5| Step: 10
Training loss: 2.135533094406128
Validation loss: 2.0347333518407678

Epoch: 121| Step: 0
Training loss: 1.7971760034561157
Validation loss: 2.131177963749055

Epoch: 5| Step: 1
Training loss: 2.120978593826294
Validation loss: 2.1032541028914915

Epoch: 5| Step: 2
Training loss: 2.6197497844696045
Validation loss: 2.1296800464712162

Epoch: 5| Step: 3
Training loss: 2.183138847351074
Validation loss: 2.0975134680348058

Epoch: 5| Step: 4
Training loss: 1.9445979595184326
Validation loss: 2.1522925566601496

Epoch: 5| Step: 5
Training loss: 2.6905579566955566
Validation loss: 2.1341258159247776

Epoch: 5| Step: 6
Training loss: 1.8371963500976562
Validation loss: 2.1311330423560193

Epoch: 5| Step: 7
Training loss: 2.201667308807373
Validation loss: 2.0746601166263705

Epoch: 5| Step: 8
Training loss: 2.6979706287384033
Validation loss: 2.0860051262763237

Epoch: 5| Step: 9
Training loss: 2.366720676422119
Validation loss: 2.0983751794343353

Epoch: 5| Step: 10
Training loss: 2.215468168258667
Validation loss: 2.100114104568317

Epoch: 122| Step: 0
Training loss: 2.9210495948791504
Validation loss: 2.1132497851566603

Epoch: 5| Step: 1
Training loss: 2.0748372077941895
Validation loss: 2.1355587179942797

Epoch: 5| Step: 2
Training loss: 1.6888118982315063
Validation loss: 2.162266282625096

Epoch: 5| Step: 3
Training loss: 2.4556937217712402
Validation loss: 2.1178723586502897

Epoch: 5| Step: 4
Training loss: 2.6540451049804688
Validation loss: 2.163976087365099

Epoch: 5| Step: 5
Training loss: 2.3771870136260986
Validation loss: 2.136153995349843

Epoch: 5| Step: 6
Training loss: 2.424438714981079
Validation loss: 2.1485552185325214

Epoch: 5| Step: 7
Training loss: 1.7104028463363647
Validation loss: 2.0838721054856495

Epoch: 5| Step: 8
Training loss: 2.007099151611328
Validation loss: 2.1360606096124135

Epoch: 5| Step: 9
Training loss: 2.093634843826294
Validation loss: 2.1199248375431186

Epoch: 5| Step: 10
Training loss: 2.2883126735687256
Validation loss: 2.1086740045137304

Epoch: 123| Step: 0
Training loss: 2.4716789722442627
Validation loss: 2.151433954956711

Epoch: 5| Step: 1
Training loss: 2.319761276245117
Validation loss: 2.1646064071245092

Epoch: 5| Step: 2
Training loss: 2.521045207977295
Validation loss: 2.063485815960874

Epoch: 5| Step: 3
Training loss: 2.0952742099761963
Validation loss: 2.1323429948540142

Epoch: 5| Step: 4
Training loss: 2.250836133956909
Validation loss: 2.10703541386512

Epoch: 5| Step: 5
Training loss: 2.0005738735198975
Validation loss: 2.1563118888485815

Epoch: 5| Step: 6
Training loss: 2.2889816761016846
Validation loss: 2.1074197830692416

Epoch: 5| Step: 7
Training loss: 2.333892345428467
Validation loss: 2.1481151811538206

Epoch: 5| Step: 8
Training loss: 2.481933116912842
Validation loss: 2.080307255509079

Epoch: 5| Step: 9
Training loss: 1.7525014877319336
Validation loss: 2.1471120990732664

Epoch: 5| Step: 10
Training loss: 1.7316890954971313
Validation loss: 2.109852043531274

Epoch: 124| Step: 0
Training loss: 1.9577369689941406
Validation loss: 2.137585364362245

Epoch: 5| Step: 1
Training loss: 1.8762493133544922
Validation loss: 2.077691146122512

Epoch: 5| Step: 2
Training loss: 1.9965217113494873
Validation loss: 2.1175478889096166

Epoch: 5| Step: 3
Training loss: 2.7647762298583984
Validation loss: 2.120970049212056

Epoch: 5| Step: 4
Training loss: 2.8507728576660156
Validation loss: 2.0927015735257055

Epoch: 5| Step: 5
Training loss: 1.8284425735473633
Validation loss: 2.117214149044406

Epoch: 5| Step: 6
Training loss: 2.3305602073669434
Validation loss: 2.145316231635309

Epoch: 5| Step: 7
Training loss: 2.3537631034851074
Validation loss: 2.16900953426156

Epoch: 5| Step: 8
Training loss: 2.2855618000030518
Validation loss: 2.155320539269396

Epoch: 5| Step: 9
Training loss: 2.3596644401550293
Validation loss: 2.0582847274759764

Epoch: 5| Step: 10
Training loss: 2.023660659790039
Validation loss: 2.1055952067016275

Epoch: 125| Step: 0
Training loss: 1.8992960453033447
Validation loss: 2.1308380096189437

Epoch: 5| Step: 1
Training loss: 2.9525253772735596
Validation loss: 2.146827854135985

Epoch: 5| Step: 2
Training loss: 2.0568344593048096
Validation loss: 2.182893729978992

Epoch: 5| Step: 3
Training loss: 2.2559151649475098
Validation loss: 2.1037225338720504

Epoch: 5| Step: 4
Training loss: 2.532959222793579
Validation loss: 2.1590468729695966

Epoch: 5| Step: 5
Training loss: 2.212562084197998
Validation loss: 2.1470393121883435

Epoch: 5| Step: 6
Training loss: 1.980170488357544
Validation loss: 2.2107536946573565

Epoch: 5| Step: 7
Training loss: 2.313169240951538
Validation loss: 2.143386661365468

Epoch: 5| Step: 8
Training loss: 2.308208465576172
Validation loss: 2.139023047621532

Epoch: 5| Step: 9
Training loss: 1.7377408742904663
Validation loss: 2.186576457433803

Epoch: 5| Step: 10
Training loss: 2.193004846572876
Validation loss: 2.1652333044236705

Epoch: 126| Step: 0
Training loss: 2.0150437355041504
Validation loss: 2.154767692729991

Epoch: 5| Step: 1
Training loss: 2.273411273956299
Validation loss: 2.1553904138585573

Epoch: 5| Step: 2
Training loss: 2.390157461166382
Validation loss: 2.1316112959256737

Epoch: 5| Step: 3
Training loss: 2.8020942211151123
Validation loss: 2.1749387530870337

Epoch: 5| Step: 4
Training loss: 2.193138837814331
Validation loss: 2.147280244417088

Epoch: 5| Step: 5
Training loss: 1.751335859298706
Validation loss: 2.1345953120980212

Epoch: 5| Step: 6
Training loss: 2.647529125213623
Validation loss: 2.1430997976692776

Epoch: 5| Step: 7
Training loss: 1.9572232961654663
Validation loss: 2.115050951639811

Epoch: 5| Step: 8
Training loss: 1.9839051961898804
Validation loss: 2.1540373756039526

Epoch: 5| Step: 9
Training loss: 2.4073755741119385
Validation loss: 2.148991774487239

Epoch: 5| Step: 10
Training loss: 2.2099266052246094
Validation loss: 2.0929861991636214

Epoch: 127| Step: 0
Training loss: 3.084437847137451
Validation loss: 2.0964097874138945

Epoch: 5| Step: 1
Training loss: 2.302743434906006
Validation loss: 2.0839082758913756

Epoch: 5| Step: 2
Training loss: 2.3748581409454346
Validation loss: 2.145387126553443

Epoch: 5| Step: 3
Training loss: 1.801032304763794
Validation loss: 2.173184638382286

Epoch: 5| Step: 4
Training loss: 2.1709587574005127
Validation loss: 2.08049843388219

Epoch: 5| Step: 5
Training loss: 2.1562633514404297
Validation loss: 2.0750856040626444

Epoch: 5| Step: 6
Training loss: 2.2273430824279785
Validation loss: 2.1331505057632283

Epoch: 5| Step: 7
Training loss: 2.2664196491241455
Validation loss: 2.131451686223348

Epoch: 5| Step: 8
Training loss: 1.9148943424224854
Validation loss: 2.1383618590652302

Epoch: 5| Step: 9
Training loss: 2.119316577911377
Validation loss: 2.143606521750009

Epoch: 5| Step: 10
Training loss: 1.9478225708007812
Validation loss: 2.1205601692199707

Epoch: 128| Step: 0
Training loss: 2.3234753608703613
Validation loss: 2.140666240005083

Epoch: 5| Step: 1
Training loss: 2.6509876251220703
Validation loss: 2.11676779870064

Epoch: 5| Step: 2
Training loss: 2.120771884918213
Validation loss: 2.113788938009611

Epoch: 5| Step: 3
Training loss: 2.199927568435669
Validation loss: 2.1504755148323635

Epoch: 5| Step: 4
Training loss: 1.6808173656463623
Validation loss: 2.189031813734321

Epoch: 5| Step: 5
Training loss: 2.5068752765655518
Validation loss: 2.156152694456039

Epoch: 5| Step: 6
Training loss: 2.7183940410614014
Validation loss: 2.1658285510155464

Epoch: 5| Step: 7
Training loss: 1.7475287914276123
Validation loss: 2.141936486767184

Epoch: 5| Step: 8
Training loss: 2.6375534534454346
Validation loss: 2.215255980850548

Epoch: 5| Step: 9
Training loss: 1.6330440044403076
Validation loss: 2.078123543852119

Epoch: 5| Step: 10
Training loss: 2.4859635829925537
Validation loss: 2.184584102322978

Epoch: 129| Step: 0
Training loss: 1.991615653038025
Validation loss: 2.157388253878522

Epoch: 5| Step: 1
Training loss: 2.3082029819488525
Validation loss: 2.1004903213952177

Epoch: 5| Step: 2
Training loss: 1.922943115234375
Validation loss: 2.1450635976688837

Epoch: 5| Step: 3
Training loss: 2.193112373352051
Validation loss: 2.118538010504938

Epoch: 5| Step: 4
Training loss: 2.4542648792266846
Validation loss: 2.1455635255382908

Epoch: 5| Step: 5
Training loss: 2.2313618659973145
Validation loss: 2.0745237053081556

Epoch: 5| Step: 6
Training loss: 2.424891710281372
Validation loss: 2.163430513874177

Epoch: 5| Step: 7
Training loss: 1.4599087238311768
Validation loss: 2.1302795243519608

Epoch: 5| Step: 8
Training loss: 2.919419765472412
Validation loss: 2.1451456059691725

Epoch: 5| Step: 9
Training loss: 2.1448235511779785
Validation loss: 2.1388966165563112

Epoch: 5| Step: 10
Training loss: 2.152303695678711
Validation loss: 2.151662952156477

Epoch: 130| Step: 0
Training loss: 2.575108766555786
Validation loss: 2.1577064350087154

Epoch: 5| Step: 1
Training loss: 3.0115630626678467
Validation loss: 2.140573655405352

Epoch: 5| Step: 2
Training loss: 2.15195894241333
Validation loss: 2.1826908408954577

Epoch: 5| Step: 3
Training loss: 1.8092498779296875
Validation loss: 2.068218920820503

Epoch: 5| Step: 4
Training loss: 2.228196859359741
Validation loss: 2.113896399415949

Epoch: 5| Step: 5
Training loss: 1.6718374490737915
Validation loss: 2.132918982095616

Epoch: 5| Step: 6
Training loss: 2.7352538108825684
Validation loss: 2.135625687978601

Epoch: 5| Step: 7
Training loss: 2.3215129375457764
Validation loss: 2.1598127926549604

Epoch: 5| Step: 8
Training loss: 2.429255247116089
Validation loss: 2.0802533344555925

Epoch: 5| Step: 9
Training loss: 1.4663159847259521
Validation loss: 2.0735327941115185

Epoch: 5| Step: 10
Training loss: 2.257399559020996
Validation loss: 2.113093573559997

Epoch: 131| Step: 0
Training loss: 1.7670215368270874
Validation loss: 2.082642109163346

Epoch: 5| Step: 1
Training loss: 2.4669060707092285
Validation loss: 2.1328109695065405

Epoch: 5| Step: 2
Training loss: 2.0267231464385986
Validation loss: 2.08750347680943

Epoch: 5| Step: 3
Training loss: 2.765254259109497
Validation loss: 2.141703674870153

Epoch: 5| Step: 4
Training loss: 2.4765467643737793
Validation loss: 2.1045655012130737

Epoch: 5| Step: 5
Training loss: 1.9764353036880493
Validation loss: 2.1701444272072083

Epoch: 5| Step: 6
Training loss: 2.432863712310791
Validation loss: 2.143725677203107

Epoch: 5| Step: 7
Training loss: 1.852789282798767
Validation loss: 2.1122439984352357

Epoch: 5| Step: 8
Training loss: 2.051146984100342
Validation loss: 2.1139188222987677

Epoch: 5| Step: 9
Training loss: 2.861694812774658
Validation loss: 2.128348114669964

Epoch: 5| Step: 10
Training loss: 1.6961863040924072
Validation loss: 2.131812592988373

Epoch: 132| Step: 0
Training loss: 2.602813243865967
Validation loss: 2.078837611341989

Epoch: 5| Step: 1
Training loss: 2.0123960971832275
Validation loss: 2.1145075008433354

Epoch: 5| Step: 2
Training loss: 2.1143765449523926
Validation loss: 2.064314955024309

Epoch: 5| Step: 3
Training loss: 2.0115208625793457
Validation loss: 2.1206771917240594

Epoch: 5| Step: 4
Training loss: 2.5489342212677
Validation loss: 2.066138284180754

Epoch: 5| Step: 5
Training loss: 2.386956214904785
Validation loss: 2.128332479025728

Epoch: 5| Step: 6
Training loss: 2.435107707977295
Validation loss: 2.102709472820323

Epoch: 5| Step: 7
Training loss: 2.310159921646118
Validation loss: 2.1273392041524253

Epoch: 5| Step: 8
Training loss: 1.9598109722137451
Validation loss: 2.0560719954070223

Epoch: 5| Step: 9
Training loss: 1.8289283514022827
Validation loss: 2.1558621365536927

Epoch: 5| Step: 10
Training loss: 2.2724380493164062
Validation loss: 2.100913324663716

Epoch: 133| Step: 0
Training loss: 1.9074409008026123
Validation loss: 2.1767363215005524

Epoch: 5| Step: 1
Training loss: 1.9508216381072998
Validation loss: 2.106775829868932

Epoch: 5| Step: 2
Training loss: 2.3015284538269043
Validation loss: 2.0963670361426567

Epoch: 5| Step: 3
Training loss: 2.712287425994873
Validation loss: 2.112388586485258

Epoch: 5| Step: 4
Training loss: 2.167848587036133
Validation loss: 2.1242806911468506

Epoch: 5| Step: 5
Training loss: 2.2375998497009277
Validation loss: 2.0964863005504815

Epoch: 5| Step: 6
Training loss: 2.072143077850342
Validation loss: 2.101373634030742

Epoch: 5| Step: 7
Training loss: 2.0349457263946533
Validation loss: 2.118795843534572

Epoch: 5| Step: 8
Training loss: 2.879237651824951
Validation loss: 2.085124090153684

Epoch: 5| Step: 9
Training loss: 1.8553282022476196
Validation loss: 2.1793214531355005

Epoch: 5| Step: 10
Training loss: 2.240723133087158
Validation loss: 2.100431337151476

Epoch: 134| Step: 0
Training loss: 1.934973955154419
Validation loss: 2.126020698137181

Epoch: 5| Step: 1
Training loss: 1.835801362991333
Validation loss: 2.123665189230314

Epoch: 5| Step: 2
Training loss: 2.422783851623535
Validation loss: 2.1348803466366184

Epoch: 5| Step: 3
Training loss: 1.9313865900039673
Validation loss: 2.141884047497985

Epoch: 5| Step: 4
Training loss: 1.8610318899154663
Validation loss: 2.118275180939705

Epoch: 5| Step: 5
Training loss: 2.377824068069458
Validation loss: 2.1585812876301427

Epoch: 5| Step: 6
Training loss: 2.1056418418884277
Validation loss: 2.1875812879172702

Epoch: 5| Step: 7
Training loss: 1.875719428062439
Validation loss: 2.201205130546324

Epoch: 5| Step: 8
Training loss: 2.848869800567627
Validation loss: 2.1594799282730266

Epoch: 5| Step: 9
Training loss: 1.955815315246582
Validation loss: 2.1358479940763084

Epoch: 5| Step: 10
Training loss: 3.081197500228882
Validation loss: 2.1595062427623297

Epoch: 135| Step: 0
Training loss: 2.2150886058807373
Validation loss: 2.1412655281764206

Epoch: 5| Step: 1
Training loss: 2.218501567840576
Validation loss: 2.171644264651883

Epoch: 5| Step: 2
Training loss: 2.7152493000030518
Validation loss: 2.144786263024935

Epoch: 5| Step: 3
Training loss: 1.648657202720642
Validation loss: 2.091743928129955

Epoch: 5| Step: 4
Training loss: 2.1242575645446777
Validation loss: 2.1282224039877615

Epoch: 5| Step: 5
Training loss: 2.4120116233825684
Validation loss: 2.1030625591995897

Epoch: 5| Step: 6
Training loss: 2.027519464492798
Validation loss: 2.142625593370007

Epoch: 5| Step: 7
Training loss: 2.552902936935425
Validation loss: 2.1783466813384846

Epoch: 5| Step: 8
Training loss: 2.2473464012145996
Validation loss: 2.119737850722446

Epoch: 5| Step: 9
Training loss: 1.7444849014282227
Validation loss: 2.116553152761152

Epoch: 5| Step: 10
Training loss: 2.767036199569702
Validation loss: 2.1171669537021267

Epoch: 136| Step: 0
Training loss: 2.519075870513916
Validation loss: 2.135825090510871

Epoch: 5| Step: 1
Training loss: 1.5726234912872314
Validation loss: 2.1615881202041463

Epoch: 5| Step: 2
Training loss: 2.5080809593200684
Validation loss: 2.1380078766935613

Epoch: 5| Step: 3
Training loss: 1.903841257095337
Validation loss: 2.1668013885457027

Epoch: 5| Step: 4
Training loss: 2.5139319896698
Validation loss: 2.1269526814901702

Epoch: 5| Step: 5
Training loss: 1.8259471654891968
Validation loss: 2.1286758274160404

Epoch: 5| Step: 6
Training loss: 2.890070676803589
Validation loss: 2.115115498983732

Epoch: 5| Step: 7
Training loss: 2.465500593185425
Validation loss: 2.1453307290231027

Epoch: 5| Step: 8
Training loss: 1.7929073572158813
Validation loss: 2.1439549897306707

Epoch: 5| Step: 9
Training loss: 3.0337328910827637
Validation loss: 2.155876128904281

Epoch: 5| Step: 10
Training loss: 1.4555044174194336
Validation loss: 2.1083242867582586

Epoch: 137| Step: 0
Training loss: 1.989314317703247
Validation loss: 2.1374013859738588

Epoch: 5| Step: 1
Training loss: 2.4724647998809814
Validation loss: 2.180185725612025

Epoch: 5| Step: 2
Training loss: 1.7706129550933838
Validation loss: 2.1407988404714935

Epoch: 5| Step: 3
Training loss: 2.1959946155548096
Validation loss: 2.2073549121938725

Epoch: 5| Step: 4
Training loss: 2.6804890632629395
Validation loss: 2.098757266998291

Epoch: 5| Step: 5
Training loss: 1.9777101278305054
Validation loss: 2.1631180599171627

Epoch: 5| Step: 6
Training loss: 1.5430055856704712
Validation loss: 2.183714597455917

Epoch: 5| Step: 7
Training loss: 2.3611247539520264
Validation loss: 2.101749940585065

Epoch: 5| Step: 8
Training loss: 2.3077614307403564
Validation loss: 2.137334806944734

Epoch: 5| Step: 9
Training loss: 2.3675789833068848
Validation loss: 2.12026342140731

Epoch: 5| Step: 10
Training loss: 2.49125599861145
Validation loss: 2.130266454912001

Epoch: 138| Step: 0
Training loss: 1.5401058197021484
Validation loss: 2.141012768591604

Epoch: 5| Step: 1
Training loss: 2.1701955795288086
Validation loss: 2.1105663122669345

Epoch: 5| Step: 2
Training loss: 1.956080675125122
Validation loss: 2.1569246527969197

Epoch: 5| Step: 3
Training loss: 2.6588263511657715
Validation loss: 2.10992709923816

Epoch: 5| Step: 4
Training loss: 2.1882190704345703
Validation loss: 2.0724560253081785

Epoch: 5| Step: 5
Training loss: 2.36543345451355
Validation loss: 2.052046260526103

Epoch: 5| Step: 6
Training loss: 1.8083360195159912
Validation loss: 2.0777310338071597

Epoch: 5| Step: 7
Training loss: 2.8802361488342285
Validation loss: 2.098806506843977

Epoch: 5| Step: 8
Training loss: 2.6737473011016846
Validation loss: 2.1073287994630876

Epoch: 5| Step: 9
Training loss: 2.1412947177886963
Validation loss: 2.092752548956102

Epoch: 5| Step: 10
Training loss: 2.3200204372406006
Validation loss: 2.070408095595657

Epoch: 139| Step: 0
Training loss: 1.8089653253555298
Validation loss: 2.1094910893388974

Epoch: 5| Step: 1
Training loss: 2.0997354984283447
Validation loss: 2.1439413896170993

Epoch: 5| Step: 2
Training loss: 2.2159669399261475
Validation loss: 2.100875216145669

Epoch: 5| Step: 3
Training loss: 2.254271984100342
Validation loss: 2.135297611195554

Epoch: 5| Step: 4
Training loss: 2.0050222873687744
Validation loss: 2.088381903145903

Epoch: 5| Step: 5
Training loss: 2.3093864917755127
Validation loss: 2.117258375690829

Epoch: 5| Step: 6
Training loss: 2.0580084323883057
Validation loss: 2.1004189342580815

Epoch: 5| Step: 7
Training loss: 2.0721676349639893
Validation loss: 2.0745108409594466

Epoch: 5| Step: 8
Training loss: 2.573685646057129
Validation loss: 2.148504885294104

Epoch: 5| Step: 9
Training loss: 2.306886911392212
Validation loss: 2.1107867968979703

Epoch: 5| Step: 10
Training loss: 2.527632474899292
Validation loss: 2.1193287193134265

Epoch: 140| Step: 0
Training loss: 1.7439018487930298
Validation loss: 2.102338993421165

Epoch: 5| Step: 1
Training loss: 1.6722633838653564
Validation loss: 2.123420323095014

Epoch: 5| Step: 2
Training loss: 3.2186057567596436
Validation loss: 2.127217568377013

Epoch: 5| Step: 3
Training loss: 2.159572124481201
Validation loss: 2.1373943231439076

Epoch: 5| Step: 4
Training loss: 2.086237668991089
Validation loss: 2.135877001670099

Epoch: 5| Step: 5
Training loss: 2.237496852874756
Validation loss: 2.1411546276461695

Epoch: 5| Step: 6
Training loss: 2.436800718307495
Validation loss: 2.142826477686564

Epoch: 5| Step: 7
Training loss: 2.3769760131835938
Validation loss: 2.159865181933167

Epoch: 5| Step: 8
Training loss: 1.9195556640625
Validation loss: 2.1640420370204474

Epoch: 5| Step: 9
Training loss: 2.372145652770996
Validation loss: 2.1329270562817975

Epoch: 5| Step: 10
Training loss: 2.264511823654175
Validation loss: 2.1228855130493

Epoch: 141| Step: 0
Training loss: 2.3241844177246094
Validation loss: 2.0850619398137575

Epoch: 5| Step: 1
Training loss: 2.069782018661499
Validation loss: 2.1204832112917336

Epoch: 5| Step: 2
Training loss: 1.6260181665420532
Validation loss: 2.153411255087904

Epoch: 5| Step: 3
Training loss: 2.5211057662963867
Validation loss: 2.114617560499458

Epoch: 5| Step: 4
Training loss: 2.848330020904541
Validation loss: 2.160299192192734

Epoch: 5| Step: 5
Training loss: 2.1991188526153564
Validation loss: 2.163078288878164

Epoch: 5| Step: 6
Training loss: 2.3501334190368652
Validation loss: 2.1285864691580496

Epoch: 5| Step: 7
Training loss: 1.858502745628357
Validation loss: 2.1809988021850586

Epoch: 5| Step: 8
Training loss: 2.0319643020629883
Validation loss: 2.1508318070442445

Epoch: 5| Step: 9
Training loss: 1.9212620258331299
Validation loss: 2.1142063243414766

Epoch: 5| Step: 10
Training loss: 2.130502700805664
Validation loss: 2.1346295751551145

Epoch: 142| Step: 0
Training loss: 1.9477148056030273
Validation loss: 2.1172264891286052

Epoch: 5| Step: 1
Training loss: 2.538567066192627
Validation loss: 2.1542534905095256

Epoch: 5| Step: 2
Training loss: 2.527787446975708
Validation loss: 2.1400963978100846

Epoch: 5| Step: 3
Training loss: 1.709075689315796
Validation loss: 2.081380272424349

Epoch: 5| Step: 4
Training loss: 1.9769401550292969
Validation loss: 2.1154105189026042

Epoch: 5| Step: 5
Training loss: 1.9521911144256592
Validation loss: 2.137147277914068

Epoch: 5| Step: 6
Training loss: 2.173546314239502
Validation loss: 2.1680341330907678

Epoch: 5| Step: 7
Training loss: 2.0150139331817627
Validation loss: 2.1022232347919094

Epoch: 5| Step: 8
Training loss: 2.245847702026367
Validation loss: 2.099637882683867

Epoch: 5| Step: 9
Training loss: 2.941494941711426
Validation loss: 2.1773484996570054

Epoch: 5| Step: 10
Training loss: 1.872558355331421
Validation loss: 2.1424526758091424

Epoch: 143| Step: 0
Training loss: 1.9146932363510132
Validation loss: 2.1078701942197737

Epoch: 5| Step: 1
Training loss: 3.0489540100097656
Validation loss: 2.100939678889449

Epoch: 5| Step: 2
Training loss: 1.8018081188201904
Validation loss: 2.1484833250763598

Epoch: 5| Step: 3
Training loss: 1.6072431802749634
Validation loss: 2.080814774318408

Epoch: 5| Step: 4
Training loss: 2.613041877746582
Validation loss: 2.109843305362168

Epoch: 5| Step: 5
Training loss: 2.3749489784240723
Validation loss: 2.1150108075911

Epoch: 5| Step: 6
Training loss: 2.335125684738159
Validation loss: 2.1549084032735517

Epoch: 5| Step: 7
Training loss: 1.9385162591934204
Validation loss: 2.1466748163264286

Epoch: 5| Step: 8
Training loss: 1.9881995916366577
Validation loss: 2.116703446193408

Epoch: 5| Step: 9
Training loss: 2.1901917457580566
Validation loss: 2.1261058340790453

Epoch: 5| Step: 10
Training loss: 2.3636651039123535
Validation loss: 2.0980256090882006

Epoch: 144| Step: 0
Training loss: 2.3742835521698
Validation loss: 2.1853575142480994

Epoch: 5| Step: 1
Training loss: 2.084205150604248
Validation loss: 2.0742186987271873

Epoch: 5| Step: 2
Training loss: 1.6544444561004639
Validation loss: 2.166882276535034

Epoch: 5| Step: 3
Training loss: 2.2962822914123535
Validation loss: 2.1397364062647664

Epoch: 5| Step: 4
Training loss: 2.4314780235290527
Validation loss: 2.1563627540424304

Epoch: 5| Step: 5
Training loss: 2.1978020668029785
Validation loss: 2.179523165507983

Epoch: 5| Step: 6
Training loss: 2.4190280437469482
Validation loss: 2.0826146166811705

Epoch: 5| Step: 7
Training loss: 2.3019447326660156
Validation loss: 2.147503543925542

Epoch: 5| Step: 8
Training loss: 1.9108002185821533
Validation loss: 2.179223032407863

Epoch: 5| Step: 9
Training loss: 2.2665927410125732
Validation loss: 2.136608326306907

Epoch: 5| Step: 10
Training loss: 2.295578956604004
Validation loss: 2.137532082937097

Epoch: 145| Step: 0
Training loss: 2.2943623065948486
Validation loss: 2.175843349067114

Epoch: 5| Step: 1
Training loss: 2.3892390727996826
Validation loss: 2.1675350127681607

Epoch: 5| Step: 2
Training loss: 2.1608808040618896
Validation loss: 2.1200923060858123

Epoch: 5| Step: 3
Training loss: 1.6900663375854492
Validation loss: 2.1725848285100793

Epoch: 5| Step: 4
Training loss: 2.4702444076538086
Validation loss: 2.122283204909294

Epoch: 5| Step: 5
Training loss: 1.935824990272522
Validation loss: 2.166146734709381

Epoch: 5| Step: 6
Training loss: 1.8156492710113525
Validation loss: 2.167364446065759

Epoch: 5| Step: 7
Training loss: 1.8509485721588135
Validation loss: 2.1144673311582176

Epoch: 5| Step: 8
Training loss: 2.930445909500122
Validation loss: 2.157834178657942

Epoch: 5| Step: 9
Training loss: 1.933624505996704
Validation loss: 2.100198217617568

Epoch: 5| Step: 10
Training loss: 2.4535789489746094
Validation loss: 2.0971766876918014

Epoch: 146| Step: 0
Training loss: 1.6930828094482422
Validation loss: 2.109238347699565

Epoch: 5| Step: 1
Training loss: 1.6996126174926758
Validation loss: 2.128142187672277

Epoch: 5| Step: 2
Training loss: 2.5556554794311523
Validation loss: 2.1396232625489593

Epoch: 5| Step: 3
Training loss: 1.7886070013046265
Validation loss: 2.094315113559846

Epoch: 5| Step: 4
Training loss: 1.9844595193862915
Validation loss: 2.1311190538508917

Epoch: 5| Step: 5
Training loss: 1.904933214187622
Validation loss: 2.1434851948932936

Epoch: 5| Step: 6
Training loss: 2.4342379570007324
Validation loss: 2.130517549412225

Epoch: 5| Step: 7
Training loss: 2.1787991523742676
Validation loss: 2.1808342651654313

Epoch: 5| Step: 8
Training loss: 2.4865622520446777
Validation loss: 2.1315480573202974

Epoch: 5| Step: 9
Training loss: 2.7669034004211426
Validation loss: 2.197676186920494

Epoch: 5| Step: 10
Training loss: 2.4173293113708496
Validation loss: 2.1553922750616588

Epoch: 147| Step: 0
Training loss: 2.2264745235443115
Validation loss: 2.1251926114482265

Epoch: 5| Step: 1
Training loss: 2.1999852657318115
Validation loss: 2.093362844118508

Epoch: 5| Step: 2
Training loss: 1.959668755531311
Validation loss: 2.164551863106348

Epoch: 5| Step: 3
Training loss: 2.3135159015655518
Validation loss: 2.1263771377583986

Epoch: 5| Step: 4
Training loss: 2.2837600708007812
Validation loss: 2.1496390604203746

Epoch: 5| Step: 5
Training loss: 1.9246532917022705
Validation loss: 2.1475421292807466

Epoch: 5| Step: 6
Training loss: 2.1613643169403076
Validation loss: 2.072277428001486

Epoch: 5| Step: 7
Training loss: 1.5360019207000732
Validation loss: 2.1531764435511764

Epoch: 5| Step: 8
Training loss: 1.8871841430664062
Validation loss: 2.086507749813859

Epoch: 5| Step: 9
Training loss: 2.6822943687438965
Validation loss: 2.1176651664959487

Epoch: 5| Step: 10
Training loss: 3.036797523498535
Validation loss: 2.129976649438181

Epoch: 148| Step: 0
Training loss: 1.8605396747589111
Validation loss: 2.1044155756632485

Epoch: 5| Step: 1
Training loss: 2.1505730152130127
Validation loss: 2.1256677950582197

Epoch: 5| Step: 2
Training loss: 2.5725531578063965
Validation loss: 2.1194210975400862

Epoch: 5| Step: 3
Training loss: 1.764487862586975
Validation loss: 2.1206837520804456

Epoch: 5| Step: 4
Training loss: 2.5424141883850098
Validation loss: 2.132657863760507

Epoch: 5| Step: 5
Training loss: 2.3543529510498047
Validation loss: 2.159073316922752

Epoch: 5| Step: 6
Training loss: 1.970625877380371
Validation loss: 2.1029255659349504

Epoch: 5| Step: 7
Training loss: 1.7356748580932617
Validation loss: 2.125952346350557

Epoch: 5| Step: 8
Training loss: 1.6830158233642578
Validation loss: 2.101918407665786

Epoch: 5| Step: 9
Training loss: 2.9036366939544678
Validation loss: 2.1176893634180867

Epoch: 5| Step: 10
Training loss: 2.5927233695983887
Validation loss: 2.078122080013316

Epoch: 149| Step: 0
Training loss: 2.2647135257720947
Validation loss: 2.1221336010963685

Epoch: 5| Step: 1
Training loss: 2.4911673069000244
Validation loss: 2.125032168562694

Epoch: 5| Step: 2
Training loss: 2.3720154762268066
Validation loss: 2.150131174313125

Epoch: 5| Step: 3
Training loss: 2.4885032176971436
Validation loss: 2.133727641515834

Epoch: 5| Step: 4
Training loss: 2.0251567363739014
Validation loss: 2.154026134039766

Epoch: 5| Step: 5
Training loss: 1.9477689266204834
Validation loss: 2.1087405040699947

Epoch: 5| Step: 6
Training loss: 1.5115439891815186
Validation loss: 2.1127709445133003

Epoch: 5| Step: 7
Training loss: 2.5076746940612793
Validation loss: 2.1620484885349067

Epoch: 5| Step: 8
Training loss: 2.5598673820495605
Validation loss: 2.1113612433915496

Epoch: 5| Step: 9
Training loss: 2.0144202709198
Validation loss: 2.0827344822627243

Epoch: 5| Step: 10
Training loss: 1.91619873046875
Validation loss: 2.1617053477994856

Epoch: 150| Step: 0
Training loss: 1.4937760829925537
Validation loss: 2.0931286504191737

Epoch: 5| Step: 1
Training loss: 1.8462717533111572
Validation loss: 2.092862735512436

Epoch: 5| Step: 2
Training loss: 3.3192379474639893
Validation loss: 2.1277252525411625

Epoch: 5| Step: 3
Training loss: 2.104238986968994
Validation loss: 2.1261349416548208

Epoch: 5| Step: 4
Training loss: 1.732108473777771
Validation loss: 2.0886727161304925

Epoch: 5| Step: 5
Training loss: 2.4329187870025635
Validation loss: 2.163991388454232

Epoch: 5| Step: 6
Training loss: 2.086064577102661
Validation loss: 2.119171090023492

Epoch: 5| Step: 7
Training loss: 2.3834729194641113
Validation loss: 2.1292556819095405

Epoch: 5| Step: 8
Training loss: 2.115783929824829
Validation loss: 2.1389181562649306

Epoch: 5| Step: 9
Training loss: 2.0405185222625732
Validation loss: 2.1801443894704184

Epoch: 5| Step: 10
Training loss: 2.339783191680908
Validation loss: 2.1138455508857645

Epoch: 151| Step: 0
Training loss: 2.283691167831421
Validation loss: 2.19435179105369

Epoch: 5| Step: 1
Training loss: 1.985480546951294
Validation loss: 2.154320575857675

Epoch: 5| Step: 2
Training loss: 2.000028133392334
Validation loss: 2.1419299764017903

Epoch: 5| Step: 3
Training loss: 2.6806931495666504
Validation loss: 2.1445973624465284

Epoch: 5| Step: 4
Training loss: 2.7713463306427
Validation loss: 2.1836933730750956

Epoch: 5| Step: 5
Training loss: 1.8454790115356445
Validation loss: 2.1754756332725607

Epoch: 5| Step: 6
Training loss: 2.065670967102051
Validation loss: 2.138902751348352

Epoch: 5| Step: 7
Training loss: 2.2315664291381836
Validation loss: 2.138058588068972

Epoch: 5| Step: 8
Training loss: 2.218890905380249
Validation loss: 2.1344135294678392

Epoch: 5| Step: 9
Training loss: 1.8512327671051025
Validation loss: 2.1586978999517297

Epoch: 5| Step: 10
Training loss: 2.0810861587524414
Validation loss: 2.1188357581374464

Epoch: 152| Step: 0
Training loss: 2.53397274017334
Validation loss: 2.1547760066165718

Epoch: 5| Step: 1
Training loss: 2.358105182647705
Validation loss: 2.078076462591848

Epoch: 5| Step: 2
Training loss: 2.0992698669433594
Validation loss: 2.1290563024500364

Epoch: 5| Step: 3
Training loss: 2.050036907196045
Validation loss: 2.104098698144318

Epoch: 5| Step: 4
Training loss: 2.020777940750122
Validation loss: 2.0781446272327053

Epoch: 5| Step: 5
Training loss: 2.0918116569519043
Validation loss: 2.116208851978343

Epoch: 5| Step: 6
Training loss: 2.4212801456451416
Validation loss: 2.1268197336504535

Epoch: 5| Step: 7
Training loss: 2.2225332260131836
Validation loss: 2.1246362399029475

Epoch: 5| Step: 8
Training loss: 2.4153761863708496
Validation loss: 2.1328667107448784

Epoch: 5| Step: 9
Training loss: 1.5855392217636108
Validation loss: 2.1877468862841205

Epoch: 5| Step: 10
Training loss: 2.1412413120269775
Validation loss: 2.1069788420072166

Epoch: 153| Step: 0
Training loss: 2.3739795684814453
Validation loss: 2.0501230352668354

Epoch: 5| Step: 1
Training loss: 2.5809855461120605
Validation loss: 2.086152409994474

Epoch: 5| Step: 2
Training loss: 1.1813430786132812
Validation loss: 2.1017167311842724

Epoch: 5| Step: 3
Training loss: 2.502429485321045
Validation loss: 2.1377556682914816

Epoch: 5| Step: 4
Training loss: 1.9775848388671875
Validation loss: 2.1323247596781743

Epoch: 5| Step: 5
Training loss: 2.4847798347473145
Validation loss: 2.024751586298789

Epoch: 5| Step: 6
Training loss: 1.960883378982544
Validation loss: 2.0696633105636923

Epoch: 5| Step: 7
Training loss: 2.2523303031921387
Validation loss: 2.130649902487314

Epoch: 5| Step: 8
Training loss: 2.109248638153076
Validation loss: 2.042223358667025

Epoch: 5| Step: 9
Training loss: 2.3256735801696777
Validation loss: 2.083290321852571

Epoch: 5| Step: 10
Training loss: 2.3233749866485596
Validation loss: 2.04469520174047

Epoch: 154| Step: 0
Training loss: 2.11973237991333
Validation loss: 2.124586166874055

Epoch: 5| Step: 1
Training loss: 3.1039326190948486
Validation loss: 2.133603024226363

Epoch: 5| Step: 2
Training loss: 2.0664570331573486
Validation loss: 2.11862656634341

Epoch: 5| Step: 3
Training loss: 2.2836203575134277
Validation loss: 2.1102654190473658

Epoch: 5| Step: 4
Training loss: 1.8909279108047485
Validation loss: 2.131443856864847

Epoch: 5| Step: 5
Training loss: 1.8083187341690063
Validation loss: 2.127126052815427

Epoch: 5| Step: 6
Training loss: 1.6622352600097656
Validation loss: 2.1330160197391304

Epoch: 5| Step: 7
Training loss: 1.6527084112167358
Validation loss: 2.096563075178413

Epoch: 5| Step: 8
Training loss: 2.443540334701538
Validation loss: 2.1416142422665834

Epoch: 5| Step: 9
Training loss: 2.9060049057006836
Validation loss: 2.164797834170762

Epoch: 5| Step: 10
Training loss: 2.5313336849212646
Validation loss: 2.1180480885249313

Epoch: 155| Step: 0
Training loss: 2.0553717613220215
Validation loss: 2.155112539568255

Epoch: 5| Step: 1
Training loss: 1.963678002357483
Validation loss: 2.122931149698073

Epoch: 5| Step: 2
Training loss: 2.211660385131836
Validation loss: 2.122102860481508

Epoch: 5| Step: 3
Training loss: 1.9427862167358398
Validation loss: 2.1316923543971074

Epoch: 5| Step: 4
Training loss: 2.4815125465393066
Validation loss: 2.125169669428179

Epoch: 5| Step: 5
Training loss: 2.2139110565185547
Validation loss: 2.0901366087698166

Epoch: 5| Step: 6
Training loss: 2.0799596309661865
Validation loss: 2.1279987558241813

Epoch: 5| Step: 7
Training loss: 2.1526870727539062
Validation loss: 2.0930171166696856

Epoch: 5| Step: 8
Training loss: 2.508866310119629
Validation loss: 2.143806299855632

Epoch: 5| Step: 9
Training loss: 2.0969302654266357
Validation loss: 2.12358178887316

Epoch: 5| Step: 10
Training loss: 2.18102765083313
Validation loss: 2.061827794198067

Epoch: 156| Step: 0
Training loss: 2.0274481773376465
Validation loss: 2.0903825118977535

Epoch: 5| Step: 1
Training loss: 3.048919677734375
Validation loss: 2.1398257004317416

Epoch: 5| Step: 2
Training loss: 1.5714439153671265
Validation loss: 2.1039124047884377

Epoch: 5| Step: 3
Training loss: 2.875952959060669
Validation loss: 2.0913034728778306

Epoch: 5| Step: 4
Training loss: 2.5960428714752197
Validation loss: 2.1006871782323366

Epoch: 5| Step: 5
Training loss: 1.5317617654800415
Validation loss: 2.0727017874358804

Epoch: 5| Step: 6
Training loss: 2.3810102939605713
Validation loss: 2.11794271520389

Epoch: 5| Step: 7
Training loss: 2.090700149536133
Validation loss: 2.1501283261083786

Epoch: 5| Step: 8
Training loss: 1.3323556184768677
Validation loss: 2.1439830487774265

Epoch: 5| Step: 9
Training loss: 2.1384081840515137
Validation loss: 2.1169481123647382

Epoch: 5| Step: 10
Training loss: 2.4236886501312256
Validation loss: 2.1095839905482467

Epoch: 157| Step: 0
Training loss: 2.102508068084717
Validation loss: 2.1110109206168883

Epoch: 5| Step: 1
Training loss: 3.0563788414001465
Validation loss: 2.0887712483764975

Epoch: 5| Step: 2
Training loss: 2.1320338249206543
Validation loss: 2.1088736134190715

Epoch: 5| Step: 3
Training loss: 2.1368966102600098
Validation loss: 2.1275183129054245

Epoch: 5| Step: 4
Training loss: 2.2338318824768066
Validation loss: 2.142981477963027

Epoch: 5| Step: 5
Training loss: 1.8010997772216797
Validation loss: 2.0685762077249508

Epoch: 5| Step: 6
Training loss: 3.026639699935913
Validation loss: 2.0897053774966987

Epoch: 5| Step: 7
Training loss: 1.9791374206542969
Validation loss: 2.0749338647370696

Epoch: 5| Step: 8
Training loss: 2.325275182723999
Validation loss: 2.141012381481868

Epoch: 5| Step: 9
Training loss: 1.8143768310546875
Validation loss: 2.1366914651727162

Epoch: 5| Step: 10
Training loss: 1.6596256494522095
Validation loss: 2.129777672470257

Epoch: 158| Step: 0
Training loss: 1.5909459590911865
Validation loss: 2.1421290187425512

Epoch: 5| Step: 1
Training loss: 2.4855518341064453
Validation loss: 2.2028860661291305

Epoch: 5| Step: 2
Training loss: 1.9946753978729248
Validation loss: 2.1218926316948346

Epoch: 5| Step: 3
Training loss: 2.609562397003174
Validation loss: 2.129648939255745

Epoch: 5| Step: 4
Training loss: 2.231492519378662
Validation loss: 2.170671298939695

Epoch: 5| Step: 5
Training loss: 2.4240078926086426
Validation loss: 2.129719208645564

Epoch: 5| Step: 6
Training loss: 2.1968414783477783
Validation loss: 2.105238147961196

Epoch: 5| Step: 7
Training loss: 2.1375863552093506
Validation loss: 2.151555561250256

Epoch: 5| Step: 8
Training loss: 2.211446762084961
Validation loss: 2.1308274294740412

Epoch: 5| Step: 9
Training loss: 1.6078529357910156
Validation loss: 2.158755579302388

Epoch: 5| Step: 10
Training loss: 2.297783374786377
Validation loss: 2.1554196009071926

Epoch: 159| Step: 0
Training loss: 2.047572612762451
Validation loss: 2.171523978633265

Epoch: 5| Step: 1
Training loss: 1.6776583194732666
Validation loss: 2.112666146729582

Epoch: 5| Step: 2
Training loss: 1.8510468006134033
Validation loss: 2.166450935025369

Epoch: 5| Step: 3
Training loss: 1.9619038105010986
Validation loss: 2.1191533457848335

Epoch: 5| Step: 4
Training loss: 2.774454116821289
Validation loss: 2.1632382177537486

Epoch: 5| Step: 5
Training loss: 1.794091820716858
Validation loss: 2.0793771974502073

Epoch: 5| Step: 6
Training loss: 2.367082118988037
Validation loss: 2.1553304156949444

Epoch: 5| Step: 7
Training loss: 2.2430102825164795
Validation loss: 2.1158101699685536

Epoch: 5| Step: 8
Training loss: 2.0521340370178223
Validation loss: 2.135792919384536

Epoch: 5| Step: 9
Training loss: 2.6646595001220703
Validation loss: 2.129060945203227

Epoch: 5| Step: 10
Training loss: 2.461225748062134
Validation loss: 2.1018493790780344

Epoch: 160| Step: 0
Training loss: 2.3697776794433594
Validation loss: 2.127600214814627

Epoch: 5| Step: 1
Training loss: 1.7970138788223267
Validation loss: 2.108508409992341

Epoch: 5| Step: 2
Training loss: 2.306609630584717
Validation loss: 2.1030585817111436

Epoch: 5| Step: 3
Training loss: 2.2137553691864014
Validation loss: 2.129675457554479

Epoch: 5| Step: 4
Training loss: 2.0556437969207764
Validation loss: 2.1184924520472044

Epoch: 5| Step: 5
Training loss: 2.4013984203338623
Validation loss: 2.0574602619294198

Epoch: 5| Step: 6
Training loss: 2.045013904571533
Validation loss: 2.1580149717228387

Epoch: 5| Step: 7
Training loss: 2.3655428886413574
Validation loss: 2.151843968258109

Epoch: 5| Step: 8
Training loss: 2.2413978576660156
Validation loss: 2.10634179781842

Epoch: 5| Step: 9
Training loss: 2.2087554931640625
Validation loss: 2.141784168058826

Epoch: 5| Step: 10
Training loss: 2.1055376529693604
Validation loss: 2.2070384205028577

Epoch: 161| Step: 0
Training loss: 2.4869227409362793
Validation loss: 2.1212559566702893

Epoch: 5| Step: 1
Training loss: 3.039337635040283
Validation loss: 2.1363990486309095

Epoch: 5| Step: 2
Training loss: 1.6192138195037842
Validation loss: 2.0737997562654558

Epoch: 5| Step: 3
Training loss: 1.5872671604156494
Validation loss: 2.116267196593746

Epoch: 5| Step: 4
Training loss: 2.2658095359802246
Validation loss: 2.1018854546290573

Epoch: 5| Step: 5
Training loss: 2.147160768508911
Validation loss: 2.148264636275589

Epoch: 5| Step: 6
Training loss: 2.747580051422119
Validation loss: 2.106299416993254

Epoch: 5| Step: 7
Training loss: 1.7360702753067017
Validation loss: 2.1472038248533845

Epoch: 5| Step: 8
Training loss: 2.3498799800872803
Validation loss: 2.120971736087594

Epoch: 5| Step: 9
Training loss: 1.8669860363006592
Validation loss: 2.1327030889449583

Epoch: 5| Step: 10
Training loss: 2.146996259689331
Validation loss: 2.0910627303584928

Epoch: 162| Step: 0
Training loss: 2.351594924926758
Validation loss: 2.0898023215673303

Epoch: 5| Step: 1
Training loss: 1.679844856262207
Validation loss: 2.1409512142981253

Epoch: 5| Step: 2
Training loss: 1.667152762413025
Validation loss: 2.0722857572699107

Epoch: 5| Step: 3
Training loss: 2.1519103050231934
Validation loss: 2.0980981767818494

Epoch: 5| Step: 4
Training loss: 1.8529541492462158
Validation loss: 2.1273783714540544

Epoch: 5| Step: 5
Training loss: 2.334304094314575
Validation loss: 2.1549251259014173

Epoch: 5| Step: 6
Training loss: 2.4960103034973145
Validation loss: 2.1623141816867295

Epoch: 5| Step: 7
Training loss: 1.871606469154358
Validation loss: 2.1150499966836747

Epoch: 5| Step: 8
Training loss: 2.5004143714904785
Validation loss: 2.1086081830404138

Epoch: 5| Step: 9
Training loss: 2.244051933288574
Validation loss: 2.18109994037177

Epoch: 5| Step: 10
Training loss: 2.6279594898223877
Validation loss: 2.1508134923955446

Epoch: 163| Step: 0
Training loss: 2.155907154083252
Validation loss: 2.106017597260014

Epoch: 5| Step: 1
Training loss: 1.8584442138671875
Validation loss: 2.1198935611273653

Epoch: 5| Step: 2
Training loss: 2.2489349842071533
Validation loss: 2.081894757927105

Epoch: 5| Step: 3
Training loss: 2.850109338760376
Validation loss: 2.151237577520391

Epoch: 5| Step: 4
Training loss: 2.1752524375915527
Validation loss: 2.142610634526899

Epoch: 5| Step: 5
Training loss: 1.9511072635650635
Validation loss: 2.1476782521893902

Epoch: 5| Step: 6
Training loss: 2.479499340057373
Validation loss: 2.1093338471586986

Epoch: 5| Step: 7
Training loss: 1.905600905418396
Validation loss: 2.121392253906496

Epoch: 5| Step: 8
Training loss: 1.9426124095916748
Validation loss: 2.129149635632833

Epoch: 5| Step: 9
Training loss: 1.9610344171524048
Validation loss: 2.083371780251944

Epoch: 5| Step: 10
Training loss: 2.4925363063812256
Validation loss: 2.0777310338071597

Epoch: 164| Step: 0
Training loss: 2.6159005165100098
Validation loss: 2.1703997863236295

Epoch: 5| Step: 1
Training loss: 2.733520984649658
Validation loss: 2.0996387363761984

Epoch: 5| Step: 2
Training loss: 1.6707502603530884
Validation loss: 2.0735131540606098

Epoch: 5| Step: 3
Training loss: 1.9858278036117554
Validation loss: 2.078216334824921

Epoch: 5| Step: 4
Training loss: 1.817365288734436
Validation loss: 2.1053118526294665

Epoch: 5| Step: 5
Training loss: 2.1994175910949707
Validation loss: 2.1523585986065608

Epoch: 5| Step: 6
Training loss: 2.353717565536499
Validation loss: 2.062395062497867

Epoch: 5| Step: 7
Training loss: 1.6848863363265991
Validation loss: 2.1147539025993756

Epoch: 5| Step: 8
Training loss: 2.02093243598938
Validation loss: 2.161666977790094

Epoch: 5| Step: 9
Training loss: 2.530064105987549
Validation loss: 2.0987257547275995

Epoch: 5| Step: 10
Training loss: 2.1868879795074463
Validation loss: 2.110460163444601

Epoch: 165| Step: 0
Training loss: 2.7197585105895996
Validation loss: 2.164963532519597

Epoch: 5| Step: 1
Training loss: 2.3065478801727295
Validation loss: 2.129757014654016

Epoch: 5| Step: 2
Training loss: 2.0412254333496094
Validation loss: 2.1426019642942693

Epoch: 5| Step: 3
Training loss: 2.4416613578796387
Validation loss: 2.127475505234093

Epoch: 5| Step: 4
Training loss: 2.024989128112793
Validation loss: 2.1196214460557505

Epoch: 5| Step: 5
Training loss: 1.9063743352890015
Validation loss: 2.1297472369286323

Epoch: 5| Step: 6
Training loss: 2.0067079067230225
Validation loss: 2.156700293223063

Epoch: 5| Step: 7
Training loss: 1.7611042261123657
Validation loss: 2.11173814599232

Epoch: 5| Step: 8
Training loss: 2.1494951248168945
Validation loss: 2.1022615945467384

Epoch: 5| Step: 9
Training loss: 2.36991286277771
Validation loss: 2.140980302646596

Epoch: 5| Step: 10
Training loss: 2.2843053340911865
Validation loss: 2.125588120952729

Epoch: 166| Step: 0
Training loss: 2.4949960708618164
Validation loss: 2.055456587063369

Epoch: 5| Step: 1
Training loss: 2.3911054134368896
Validation loss: 2.0929241282965547

Epoch: 5| Step: 2
Training loss: 2.3980209827423096
Validation loss: 2.0901582023148895

Epoch: 5| Step: 3
Training loss: 2.418182134628296
Validation loss: 2.1136991913600633

Epoch: 5| Step: 4
Training loss: 2.2099215984344482
Validation loss: 2.07663062567352

Epoch: 5| Step: 5
Training loss: 1.935469388961792
Validation loss: 2.0827781141445203

Epoch: 5| Step: 6
Training loss: 2.1442155838012695
Validation loss: 2.111124603979049

Epoch: 5| Step: 7
Training loss: 1.6510555744171143
Validation loss: 2.1451404069059636

Epoch: 5| Step: 8
Training loss: 1.7477281093597412
Validation loss: 2.100995521391592

Epoch: 5| Step: 9
Training loss: 1.59450364112854
Validation loss: 2.104627836135126

Epoch: 5| Step: 10
Training loss: 3.021700620651245
Validation loss: 2.137585736090137

Epoch: 167| Step: 0
Training loss: 1.6843593120574951
Validation loss: 2.1847704507971324

Epoch: 5| Step: 1
Training loss: 2.020691394805908
Validation loss: 2.153244362082533

Epoch: 5| Step: 2
Training loss: 2.3697924613952637
Validation loss: 2.1095094450058474

Epoch: 5| Step: 3
Training loss: 2.2947213649749756
Validation loss: 2.1216672723011305

Epoch: 5| Step: 4
Training loss: 1.9920845031738281
Validation loss: 2.135205107350503

Epoch: 5| Step: 5
Training loss: 2.2075812816619873
Validation loss: 2.141333585144371

Epoch: 5| Step: 6
Training loss: 1.6670968532562256
Validation loss: 2.1057552188955326

Epoch: 5| Step: 7
Training loss: 2.257493019104004
Validation loss: 2.15696745534097

Epoch: 5| Step: 8
Training loss: 2.77168607711792
Validation loss: 2.104178777305029

Epoch: 5| Step: 9
Training loss: 2.3550028800964355
Validation loss: 2.158466787748439

Epoch: 5| Step: 10
Training loss: 1.8823511600494385
Validation loss: 2.1207809012423278

Epoch: 168| Step: 0
Training loss: 1.8993799686431885
Validation loss: 2.1124227046966553

Epoch: 5| Step: 1
Training loss: 1.9138762950897217
Validation loss: 2.142147719219167

Epoch: 5| Step: 2
Training loss: 2.115086078643799
Validation loss: 2.141314411676058

Epoch: 5| Step: 3
Training loss: 2.616752862930298
Validation loss: 2.1043783977467525

Epoch: 5| Step: 4
Training loss: 2.4386346340179443
Validation loss: 2.1075752986374723

Epoch: 5| Step: 5
Training loss: 2.574312686920166
Validation loss: 2.1309162621857016

Epoch: 5| Step: 6
Training loss: 2.0524487495422363
Validation loss: 2.118702401397049

Epoch: 5| Step: 7
Training loss: 2.1437766551971436
Validation loss: 2.118194282695811

Epoch: 5| Step: 8
Training loss: 1.9959779977798462
Validation loss: 2.063816484584603

Epoch: 5| Step: 9
Training loss: 1.9788458347320557
Validation loss: 2.104014724813482

Epoch: 5| Step: 10
Training loss: 1.6595255136489868
Validation loss: 2.093203539489418

Epoch: 169| Step: 0
Training loss: 3.118741512298584
Validation loss: 2.0741751886183217

Epoch: 5| Step: 1
Training loss: 2.4867262840270996
Validation loss: 2.075699742122363

Epoch: 5| Step: 2
Training loss: 2.2701125144958496
Validation loss: 2.1436708537481164

Epoch: 5| Step: 3
Training loss: 2.2398762702941895
Validation loss: 2.1330432250935543

Epoch: 5| Step: 4
Training loss: 1.9372707605361938
Validation loss: 2.1368932723999023

Epoch: 5| Step: 5
Training loss: 1.9329652786254883
Validation loss: 2.1283281721094602

Epoch: 5| Step: 6
Training loss: 2.0093510150909424
Validation loss: 2.1927531688444075

Epoch: 5| Step: 7
Training loss: 2.0994505882263184
Validation loss: 2.13588261347945

Epoch: 5| Step: 8
Training loss: 1.7275984287261963
Validation loss: 2.230113854972265

Epoch: 5| Step: 9
Training loss: 1.655535340309143
Validation loss: 2.1440491112329627

Epoch: 5| Step: 10
Training loss: 2.370882987976074
Validation loss: 2.1843394617880545

Epoch: 170| Step: 0
Training loss: 1.9392116069793701
Validation loss: 2.1747785447746195

Epoch: 5| Step: 1
Training loss: 2.3406102657318115
Validation loss: 2.169254869543096

Epoch: 5| Step: 2
Training loss: 1.9114892482757568
Validation loss: 2.161529661506735

Epoch: 5| Step: 3
Training loss: 3.1831583976745605
Validation loss: 2.168155906020954

Epoch: 5| Step: 4
Training loss: 1.880048394203186
Validation loss: 2.1848627956964637

Epoch: 5| Step: 5
Training loss: 2.330461025238037
Validation loss: 2.1593376321177327

Epoch: 5| Step: 6
Training loss: 2.2036640644073486
Validation loss: 2.183903832589426

Epoch: 5| Step: 7
Training loss: 1.4129565954208374
Validation loss: 2.1733839011961416

Epoch: 5| Step: 8
Training loss: 2.589902400970459
Validation loss: 2.1729787421482865

Epoch: 5| Step: 9
Training loss: 2.1925387382507324
Validation loss: 2.1948047927630845

Epoch: 5| Step: 10
Training loss: 1.9428369998931885
Validation loss: 2.086612888561782

Epoch: 171| Step: 0
Training loss: 1.6991046667099
Validation loss: 2.1320298307685444

Epoch: 5| Step: 1
Training loss: 2.399576187133789
Validation loss: 2.1441007993554555

Epoch: 5| Step: 2
Training loss: 1.558245301246643
Validation loss: 2.0947558290214947

Epoch: 5| Step: 3
Training loss: 2.2063381671905518
Validation loss: 2.080955050324881

Epoch: 5| Step: 4
Training loss: 2.5214710235595703
Validation loss: 2.1041664269662674

Epoch: 5| Step: 5
Training loss: 1.3220442533493042
Validation loss: 2.1608414675599787

Epoch: 5| Step: 6
Training loss: 2.699490785598755
Validation loss: 2.0939576459187332

Epoch: 5| Step: 7
Training loss: 2.1560277938842773
Validation loss: 2.0793940764601513

Epoch: 5| Step: 8
Training loss: 2.0194380283355713
Validation loss: 2.1018786084267402

Epoch: 5| Step: 9
Training loss: 2.2431719303131104
Validation loss: 2.026353842468672

Epoch: 5| Step: 10
Training loss: 2.498788833618164
Validation loss: 2.1261110126331286

Epoch: 172| Step: 0
Training loss: 2.1027579307556152
Validation loss: 2.120279663352556

Epoch: 5| Step: 1
Training loss: 2.1149234771728516
Validation loss: 2.0907863186251734

Epoch: 5| Step: 2
Training loss: 2.1501076221466064
Validation loss: 2.142704850883894

Epoch: 5| Step: 3
Training loss: 1.8960365056991577
Validation loss: 2.0597133969747894

Epoch: 5| Step: 4
Training loss: 1.9870226383209229
Validation loss: 2.1001008736189974

Epoch: 5| Step: 5
Training loss: 2.006441354751587
Validation loss: 2.0760777381158646

Epoch: 5| Step: 6
Training loss: 2.0485682487487793
Validation loss: 2.0842954471547115

Epoch: 5| Step: 7
Training loss: 2.364957332611084
Validation loss: 2.120922186041391

Epoch: 5| Step: 8
Training loss: 2.8516640663146973
Validation loss: 2.051347014724567

Epoch: 5| Step: 9
Training loss: 1.7105352878570557
Validation loss: 2.1181445352492796

Epoch: 5| Step: 10
Training loss: 2.308459758758545
Validation loss: 2.0976857575037147

Epoch: 173| Step: 0
Training loss: 2.515544891357422
Validation loss: 2.1136579282822145

Epoch: 5| Step: 1
Training loss: 2.4223458766937256
Validation loss: 2.1804735532370945

Epoch: 5| Step: 2
Training loss: 2.038139820098877
Validation loss: 2.101898926560597

Epoch: 5| Step: 3
Training loss: 1.810840368270874
Validation loss: 2.119926127054358

Epoch: 5| Step: 4
Training loss: 2.5017881393432617
Validation loss: 2.1216096749869724

Epoch: 5| Step: 5
Training loss: 2.2244482040405273
Validation loss: 2.1670189134536253

Epoch: 5| Step: 6
Training loss: 2.2666234970092773
Validation loss: 2.1472307238527524

Epoch: 5| Step: 7
Training loss: 2.295595645904541
Validation loss: 2.1286993411279496

Epoch: 5| Step: 8
Training loss: 1.3707358837127686
Validation loss: 2.179392353180916

Epoch: 5| Step: 9
Training loss: 2.2130165100097656
Validation loss: 2.085111261695944

Epoch: 5| Step: 10
Training loss: 1.6766066551208496
Validation loss: 2.110942922612672

Epoch: 174| Step: 0
Training loss: 2.040173292160034
Validation loss: 2.1598701733414845

Epoch: 5| Step: 1
Training loss: 2.106537342071533
Validation loss: 2.1402968052894837

Epoch: 5| Step: 2
Training loss: 1.9554904699325562
Validation loss: 2.1581646755177486

Epoch: 5| Step: 3
Training loss: 2.5475878715515137
Validation loss: 2.1236625743168656

Epoch: 5| Step: 4
Training loss: 1.6986557245254517
Validation loss: 2.1589248667481127

Epoch: 5| Step: 5
Training loss: 2.810812473297119
Validation loss: 2.0769584435288624

Epoch: 5| Step: 6
Training loss: 1.884966254234314
Validation loss: 2.1403390925417662

Epoch: 5| Step: 7
Training loss: 2.151947021484375
Validation loss: 2.1406939670603764

Epoch: 5| Step: 8
Training loss: 2.1834309101104736
Validation loss: 2.178501823897003

Epoch: 5| Step: 9
Training loss: 2.1870102882385254
Validation loss: 2.0778049602303454

Epoch: 5| Step: 10
Training loss: 1.9496231079101562
Validation loss: 2.1508549567191833

Epoch: 175| Step: 0
Training loss: 2.6144347190856934
Validation loss: 2.1653000629076393

Epoch: 5| Step: 1
Training loss: 1.425647258758545
Validation loss: 2.107209864483085

Epoch: 5| Step: 2
Training loss: 2.1961398124694824
Validation loss: 2.143710818341983

Epoch: 5| Step: 3
Training loss: 2.31611704826355
Validation loss: 2.135633514773461

Epoch: 5| Step: 4
Training loss: 2.4417152404785156
Validation loss: 2.1067277308433288

Epoch: 5| Step: 5
Training loss: 1.940924048423767
Validation loss: 2.1165228454015588

Epoch: 5| Step: 6
Training loss: 2.29295015335083
Validation loss: 2.1391188124174714

Epoch: 5| Step: 7
Training loss: 1.8469715118408203
Validation loss: 2.1213208526693363

Epoch: 5| Step: 8
Training loss: 1.8586305379867554
Validation loss: 2.1103208526488273

Epoch: 5| Step: 9
Training loss: 2.1850943565368652
Validation loss: 2.1218856765377905

Epoch: 5| Step: 10
Training loss: 2.4564266204833984
Validation loss: 2.186464353274274

Epoch: 176| Step: 0
Training loss: 1.8957322835922241
Validation loss: 2.1303583524560414

Epoch: 5| Step: 1
Training loss: 1.9843227863311768
Validation loss: 2.095061920022452

Epoch: 5| Step: 2
Training loss: 2.0017006397247314
Validation loss: 2.1477911215956493

Epoch: 5| Step: 3
Training loss: 1.5577987432479858
Validation loss: 2.098691012269707

Epoch: 5| Step: 4
Training loss: 1.922832727432251
Validation loss: 2.130104204659821

Epoch: 5| Step: 5
Training loss: 1.8628994226455688
Validation loss: 2.1094588413033435

Epoch: 5| Step: 6
Training loss: 3.1900815963745117
Validation loss: 2.09141957118947

Epoch: 5| Step: 7
Training loss: 2.045686721801758
Validation loss: 2.1343818890151156

Epoch: 5| Step: 8
Training loss: 2.415320873260498
Validation loss: 2.098559323177543

Epoch: 5| Step: 9
Training loss: 2.5894742012023926
Validation loss: 2.0851978717311734

Epoch: 5| Step: 10
Training loss: 1.9330350160598755
Validation loss: 2.0907502546105334

Epoch: 177| Step: 0
Training loss: 2.1825942993164062
Validation loss: 2.0772962467644804

Epoch: 5| Step: 1
Training loss: 2.098867177963257
Validation loss: 2.129594384983022

Epoch: 5| Step: 2
Training loss: 2.5640969276428223
Validation loss: 2.1117495311203824

Epoch: 5| Step: 3
Training loss: 1.9746465682983398
Validation loss: 2.124531240873439

Epoch: 5| Step: 4
Training loss: 2.162412166595459
Validation loss: 2.087580180937244

Epoch: 5| Step: 5
Training loss: 2.236355781555176
Validation loss: 2.1038723568762503

Epoch: 5| Step: 6
Training loss: 2.232682466506958
Validation loss: 2.1064959341479885

Epoch: 5| Step: 7
Training loss: 1.4074453115463257
Validation loss: 2.119120563230207

Epoch: 5| Step: 8
Training loss: 2.11734938621521
Validation loss: 2.1383800275864138

Epoch: 5| Step: 9
Training loss: 1.6798893213272095
Validation loss: 2.1293979511466077

Epoch: 5| Step: 10
Training loss: 2.673252820968628
Validation loss: 2.0989971365979923

Epoch: 178| Step: 0
Training loss: 2.7848613262176514
Validation loss: 2.0789418156429003

Epoch: 5| Step: 1
Training loss: 2.317904233932495
Validation loss: 2.082616183065599

Epoch: 5| Step: 2
Training loss: 1.3232495784759521
Validation loss: 2.0696869178484847

Epoch: 5| Step: 3
Training loss: 1.997205138206482
Validation loss: 2.0851161582495576

Epoch: 5| Step: 4
Training loss: 1.894527792930603
Validation loss: 2.0947545728375836

Epoch: 5| Step: 5
Training loss: 2.2496609687805176
Validation loss: 2.123764499541252

Epoch: 5| Step: 6
Training loss: 1.8884925842285156
Validation loss: 2.072802851277013

Epoch: 5| Step: 7
Training loss: 1.9354817867279053
Validation loss: 2.0906775612984934

Epoch: 5| Step: 8
Training loss: 2.702791690826416
Validation loss: 2.147275663191272

Epoch: 5| Step: 9
Training loss: 1.963444471359253
Validation loss: 2.1420290649578138

Epoch: 5| Step: 10
Training loss: 2.323725938796997
Validation loss: 2.1131227657359135

Epoch: 179| Step: 0
Training loss: 1.7265310287475586
Validation loss: 2.113451652629401

Epoch: 5| Step: 1
Training loss: 2.3569822311401367
Validation loss: 2.1838621657381774

Epoch: 5| Step: 2
Training loss: 2.030125856399536
Validation loss: 2.1944261007411505

Epoch: 5| Step: 3
Training loss: 2.1590089797973633
Validation loss: 2.0942976487580167

Epoch: 5| Step: 4
Training loss: 1.9352277517318726
Validation loss: 2.1148057624857914

Epoch: 5| Step: 5
Training loss: 2.029684543609619
Validation loss: 2.1076655631424277

Epoch: 5| Step: 6
Training loss: 2.4511890411376953
Validation loss: 2.1122418295952583

Epoch: 5| Step: 7
Training loss: 1.912031888961792
Validation loss: 2.104914983113607

Epoch: 5| Step: 8
Training loss: 2.2907814979553223
Validation loss: 2.137413460721252

Epoch: 5| Step: 9
Training loss: 2.1000783443450928
Validation loss: 2.147102452093555

Epoch: 5| Step: 10
Training loss: 2.8277828693389893
Validation loss: 2.098398623927947

Epoch: 180| Step: 0
Training loss: 2.702902317047119
Validation loss: 2.1424256729823288

Epoch: 5| Step: 1
Training loss: 2.3315815925598145
Validation loss: 2.1547664442370014

Epoch: 5| Step: 2
Training loss: 2.559776544570923
Validation loss: 2.1689175482719176

Epoch: 5| Step: 3
Training loss: 1.9615131616592407
Validation loss: 2.139807895947528

Epoch: 5| Step: 4
Training loss: 1.9839175939559937
Validation loss: 2.0769358924640122

Epoch: 5| Step: 5
Training loss: 1.7434275150299072
Validation loss: 2.0560105974956224

Epoch: 5| Step: 6
Training loss: 2.0208003520965576
Validation loss: 2.1521484236563406

Epoch: 5| Step: 7
Training loss: 2.366051197052002
Validation loss: 2.1577496310716033

Epoch: 5| Step: 8
Training loss: 1.8877573013305664
Validation loss: 2.1667118880056564

Epoch: 5| Step: 9
Training loss: 2.104822874069214
Validation loss: 2.143090312198926

Epoch: 5| Step: 10
Training loss: 2.3701300621032715
Validation loss: 2.13388212778235

Epoch: 181| Step: 0
Training loss: 2.2027015686035156
Validation loss: 2.1207947243926344

Epoch: 5| Step: 1
Training loss: 1.6020195484161377
Validation loss: 2.1492871046066284

Epoch: 5| Step: 2
Training loss: 1.6781408786773682
Validation loss: 2.11664649363487

Epoch: 5| Step: 3
Training loss: 1.611859679222107
Validation loss: 2.0621765403337378

Epoch: 5| Step: 4
Training loss: 2.293663740158081
Validation loss: 2.137232570238011

Epoch: 5| Step: 5
Training loss: 2.247194290161133
Validation loss: 2.0549855219420565

Epoch: 5| Step: 6
Training loss: 2.2506556510925293
Validation loss: 2.119870775489397

Epoch: 5| Step: 7
Training loss: 2.1703176498413086
Validation loss: 2.0837438901265464

Epoch: 5| Step: 8
Training loss: 2.5001022815704346
Validation loss: 2.056554143146802

Epoch: 5| Step: 9
Training loss: 1.8911468982696533
Validation loss: 2.1321653076397475

Epoch: 5| Step: 10
Training loss: 2.946748971939087
Validation loss: 2.0943017057193223

Epoch: 182| Step: 0
Training loss: 1.6697279214859009
Validation loss: 2.0907830679288475

Epoch: 5| Step: 1
Training loss: 2.2894158363342285
Validation loss: 2.019901303834813

Epoch: 5| Step: 2
Training loss: 1.9312410354614258
Validation loss: 2.1364106465411443

Epoch: 5| Step: 3
Training loss: 2.0841782093048096
Validation loss: 2.0933132107539842

Epoch: 5| Step: 4
Training loss: 2.082862377166748
Validation loss: 2.06016452850834

Epoch: 5| Step: 5
Training loss: 2.0128562450408936
Validation loss: 2.0975855435094526

Epoch: 5| Step: 6
Training loss: 2.1848907470703125
Validation loss: 2.123153437850296

Epoch: 5| Step: 7
Training loss: 2.5992672443389893
Validation loss: 2.1666083258967244

Epoch: 5| Step: 8
Training loss: 2.41556978225708
Validation loss: 2.0535654714030604

Epoch: 5| Step: 9
Training loss: 1.946118950843811
Validation loss: 2.0858825586175405

Epoch: 5| Step: 10
Training loss: 2.396545886993408
Validation loss: 2.118680759142804

Epoch: 183| Step: 0
Training loss: 2.280405044555664
Validation loss: 2.065338025810898

Epoch: 5| Step: 1
Training loss: 1.8245865106582642
Validation loss: 2.1539563030324955

Epoch: 5| Step: 2
Training loss: 2.392354965209961
Validation loss: 2.1595061107348372

Epoch: 5| Step: 3
Training loss: 2.6505074501037598
Validation loss: 2.1368238849024617

Epoch: 5| Step: 4
Training loss: 1.64583420753479
Validation loss: 2.1574695161593858

Epoch: 5| Step: 5
Training loss: 1.8854544162750244
Validation loss: 2.184576997192957

Epoch: 5| Step: 6
Training loss: 3.036221981048584
Validation loss: 2.1094406932912846

Epoch: 5| Step: 7
Training loss: 2.223351240158081
Validation loss: 2.130731651859899

Epoch: 5| Step: 8
Training loss: 1.4851930141448975
Validation loss: 2.0851982332045034

Epoch: 5| Step: 9
Training loss: 2.0669143199920654
Validation loss: 2.109088800286734

Epoch: 5| Step: 10
Training loss: 2.7563366889953613
Validation loss: 2.1130861954022477

Epoch: 184| Step: 0
Training loss: 2.0831785202026367
Validation loss: 2.160699911015008

Epoch: 5| Step: 1
Training loss: 2.2792627811431885
Validation loss: 2.146159064385199

Epoch: 5| Step: 2
Training loss: 2.0075976848602295
Validation loss: 2.1209167588141655

Epoch: 5| Step: 3
Training loss: 1.4923455715179443
Validation loss: 2.0600619521192325

Epoch: 5| Step: 4
Training loss: 2.1060028076171875
Validation loss: 2.1375401942960677

Epoch: 5| Step: 5
Training loss: 1.8781101703643799
Validation loss: 2.117355952980698

Epoch: 5| Step: 6
Training loss: 2.636363983154297
Validation loss: 2.0602249406999156

Epoch: 5| Step: 7
Training loss: 2.8850321769714355
Validation loss: 2.089820308070029

Epoch: 5| Step: 8
Training loss: 2.2440555095672607
Validation loss: 2.075861500155541

Epoch: 5| Step: 9
Training loss: 1.7201168537139893
Validation loss: 2.0750024677604757

Epoch: 5| Step: 10
Training loss: 1.9921122789382935
Validation loss: 2.1085223895247265

Epoch: 185| Step: 0
Training loss: 1.6530052423477173
Validation loss: 2.057990816331679

Epoch: 5| Step: 1
Training loss: 2.6539664268493652
Validation loss: 2.0932451973679247

Epoch: 5| Step: 2
Training loss: 2.128119945526123
Validation loss: 2.0268207493648736

Epoch: 5| Step: 3
Training loss: 1.9080188274383545
Validation loss: 2.1031149664232807

Epoch: 5| Step: 4
Training loss: 2.359774112701416
Validation loss: 2.0783550021468953

Epoch: 5| Step: 5
Training loss: 2.82944393157959
Validation loss: 1.9991253678516676

Epoch: 5| Step: 6
Training loss: 1.4524296522140503
Validation loss: 2.1237232108269968

Epoch: 5| Step: 7
Training loss: 2.577972650527954
Validation loss: 2.0511135644810174

Epoch: 5| Step: 8
Training loss: 1.479061245918274
Validation loss: 2.0930029448642524

Epoch: 5| Step: 9
Training loss: 2.1470015048980713
Validation loss: 2.106629956153131

Epoch: 5| Step: 10
Training loss: 2.000633478164673
Validation loss: 2.0637647285256335

Epoch: 186| Step: 0
Training loss: 2.530634880065918
Validation loss: 2.1319274389615623

Epoch: 5| Step: 1
Training loss: 1.5429738759994507
Validation loss: 2.0486054946017522

Epoch: 5| Step: 2
Training loss: 2.1080570220947266
Validation loss: 2.0772429127846994

Epoch: 5| Step: 3
Training loss: 2.1268181800842285
Validation loss: 2.1323078934864332

Epoch: 5| Step: 4
Training loss: 2.2880191802978516
Validation loss: 2.115587890789073

Epoch: 5| Step: 5
Training loss: 1.5647192001342773
Validation loss: 2.099285917897378

Epoch: 5| Step: 6
Training loss: 2.4976367950439453
Validation loss: 2.1534875349331926

Epoch: 5| Step: 7
Training loss: 2.2144596576690674
Validation loss: 2.145951783785256

Epoch: 5| Step: 8
Training loss: 2.0657103061676025
Validation loss: 2.144319265119491

Epoch: 5| Step: 9
Training loss: 2.1474640369415283
Validation loss: 2.1293092850715882

Epoch: 5| Step: 10
Training loss: 2.204871654510498
Validation loss: 2.161935323028154

Epoch: 187| Step: 0
Training loss: 2.2423102855682373
Validation loss: 2.1465306269225253

Epoch: 5| Step: 1
Training loss: 2.0350639820098877
Validation loss: 2.119106351688344

Epoch: 5| Step: 2
Training loss: 1.929358720779419
Validation loss: 2.193385806134952

Epoch: 5| Step: 3
Training loss: 2.2046196460723877
Validation loss: 2.104985652431365

Epoch: 5| Step: 4
Training loss: 2.1261987686157227
Validation loss: 2.102530256394417

Epoch: 5| Step: 5
Training loss: 2.0282177925109863
Validation loss: 2.0924231390799246

Epoch: 5| Step: 6
Training loss: 2.2820022106170654
Validation loss: 2.1178396286502963

Epoch: 5| Step: 7
Training loss: 2.116034746170044
Validation loss: 2.0895330047094696

Epoch: 5| Step: 8
Training loss: 2.28080415725708
Validation loss: 2.100810771347374

Epoch: 5| Step: 9
Training loss: 2.13023042678833
Validation loss: 2.1317673498584377

Epoch: 5| Step: 10
Training loss: 1.9235765933990479
Validation loss: 2.0959813312817643

Epoch: 188| Step: 0
Training loss: 1.986688256263733
Validation loss: 2.1227284887785554

Epoch: 5| Step: 1
Training loss: 1.9393348693847656
Validation loss: 2.128013951804048

Epoch: 5| Step: 2
Training loss: 1.6001724004745483
Validation loss: 2.1088595826138734

Epoch: 5| Step: 3
Training loss: 2.5484495162963867
Validation loss: 2.1513411460384244

Epoch: 5| Step: 4
Training loss: 1.6629273891448975
Validation loss: 2.104056271173621

Epoch: 5| Step: 5
Training loss: 2.0976104736328125
Validation loss: 2.120051742881857

Epoch: 5| Step: 6
Training loss: 2.571784496307373
Validation loss: 2.1107057909811697

Epoch: 5| Step: 7
Training loss: 1.745880126953125
Validation loss: 2.112091295180782

Epoch: 5| Step: 8
Training loss: 2.676659107208252
Validation loss: 2.055513765222283

Epoch: 5| Step: 9
Training loss: 2.3083269596099854
Validation loss: 2.080566575450282

Epoch: 5| Step: 10
Training loss: 2.3740947246551514
Validation loss: 2.17010147084472

Epoch: 189| Step: 0
Training loss: 1.7223953008651733
Validation loss: 2.1655500819606166

Epoch: 5| Step: 1
Training loss: 2.1334095001220703
Validation loss: 2.0979977576963362

Epoch: 5| Step: 2
Training loss: 2.19134521484375
Validation loss: 2.0841732832693283

Epoch: 5| Step: 3
Training loss: 2.0647473335266113
Validation loss: 2.0743863749247726

Epoch: 5| Step: 4
Training loss: 2.5351548194885254
Validation loss: 2.0831276447542253

Epoch: 5| Step: 5
Training loss: 2.3208823204040527
Validation loss: 2.1286332991815384

Epoch: 5| Step: 6
Training loss: 2.122267246246338
Validation loss: 2.094392434243233

Epoch: 5| Step: 7
Training loss: 2.132922410964966
Validation loss: 2.1200282650609172

Epoch: 5| Step: 8
Training loss: 1.7751405239105225
Validation loss: 2.1548741607255835

Epoch: 5| Step: 9
Training loss: 2.0843424797058105
Validation loss: 2.133582535610404

Epoch: 5| Step: 10
Training loss: 1.9973595142364502
Validation loss: 2.0601880306838662

Epoch: 190| Step: 0
Training loss: 2.2521004676818848
Validation loss: 2.128600505090529

Epoch: 5| Step: 1
Training loss: 2.1886374950408936
Validation loss: 2.1575486070366314

Epoch: 5| Step: 2
Training loss: 2.8754851818084717
Validation loss: 2.124811590358775

Epoch: 5| Step: 3
Training loss: 2.39774751663208
Validation loss: 2.06987952545125

Epoch: 5| Step: 4
Training loss: 1.4909197092056274
Validation loss: 2.0682212742426063

Epoch: 5| Step: 5
Training loss: 1.9801028966903687
Validation loss: 2.1175940254683137

Epoch: 5| Step: 6
Training loss: 2.9939064979553223
Validation loss: 2.1042527229555192

Epoch: 5| Step: 7
Training loss: 1.8943023681640625
Validation loss: 2.1083777002108994

Epoch: 5| Step: 8
Training loss: 1.6408945322036743
Validation loss: 2.0661920193702943

Epoch: 5| Step: 9
Training loss: 1.5067962408065796
Validation loss: 2.133572100311197

Epoch: 5| Step: 10
Training loss: 1.6403847932815552
Validation loss: 2.104479346224057

Epoch: 191| Step: 0
Training loss: 2.1767821311950684
Validation loss: 2.107879929645087

Epoch: 5| Step: 1
Training loss: 1.5407350063323975
Validation loss: 2.1211339312215007

Epoch: 5| Step: 2
Training loss: 2.774898052215576
Validation loss: 2.083943292658816

Epoch: 5| Step: 3
Training loss: 2.200756311416626
Validation loss: 2.0870667529362503

Epoch: 5| Step: 4
Training loss: 2.741881847381592
Validation loss: 2.168696759849466

Epoch: 5| Step: 5
Training loss: 2.108769655227661
Validation loss: 2.122618927750536

Epoch: 5| Step: 6
Training loss: 1.6638818979263306
Validation loss: 2.0347713398677048

Epoch: 5| Step: 7
Training loss: 1.7767612934112549
Validation loss: 2.16963779798118

Epoch: 5| Step: 8
Training loss: 1.9995396137237549
Validation loss: 2.1120799908074

Epoch: 5| Step: 9
Training loss: 1.824135422706604
Validation loss: 2.0917711950117543

Epoch: 5| Step: 10
Training loss: 2.435663938522339
Validation loss: 2.1182711765330327

Epoch: 192| Step: 0
Training loss: 2.099107265472412
Validation loss: 2.076637867958315

Epoch: 5| Step: 1
Training loss: 1.611034631729126
Validation loss: 2.090393868825769

Epoch: 5| Step: 2
Training loss: 2.0346388816833496
Validation loss: 2.099066049821915

Epoch: 5| Step: 3
Training loss: 1.6330738067626953
Validation loss: 2.099630637835431

Epoch: 5| Step: 4
Training loss: 2.121716260910034
Validation loss: 2.119370299000894

Epoch: 5| Step: 5
Training loss: 2.2855353355407715
Validation loss: 2.1028185595748243

Epoch: 5| Step: 6
Training loss: 2.51953125
Validation loss: 2.0642403146272064

Epoch: 5| Step: 7
Training loss: 2.6006386280059814
Validation loss: 2.029847998772898

Epoch: 5| Step: 8
Training loss: 2.812471389770508
Validation loss: 2.109540903440086

Epoch: 5| Step: 9
Training loss: 1.9029594659805298
Validation loss: 2.132830194247666

Epoch: 5| Step: 10
Training loss: 1.536414384841919
Validation loss: 2.0951300820996686

Epoch: 193| Step: 0
Training loss: 1.8374792337417603
Validation loss: 2.0845598995044665

Epoch: 5| Step: 1
Training loss: 1.9008862972259521
Validation loss: 2.1220525362158336

Epoch: 5| Step: 2
Training loss: 2.474522113800049
Validation loss: 2.100559993456769

Epoch: 5| Step: 3
Training loss: 2.0137953758239746
Validation loss: 2.1001689600688156

Epoch: 5| Step: 4
Training loss: 1.2095894813537598
Validation loss: 2.1081607905767297

Epoch: 5| Step: 5
Training loss: 2.4024341106414795
Validation loss: 2.1483422325503443

Epoch: 5| Step: 6
Training loss: 1.9458917379379272
Validation loss: 2.142821196586855

Epoch: 5| Step: 7
Training loss: 2.310006618499756
Validation loss: 2.1197474413020636

Epoch: 5| Step: 8
Training loss: 2.2330470085144043
Validation loss: 2.141402534259263

Epoch: 5| Step: 9
Training loss: 1.9619264602661133
Validation loss: 2.144535550507166

Epoch: 5| Step: 10
Training loss: 2.9569778442382812
Validation loss: 2.136319532189318

Epoch: 194| Step: 0
Training loss: 1.4911233186721802
Validation loss: 2.1698410869926534

Epoch: 5| Step: 1
Training loss: 2.333604574203491
Validation loss: 2.119431023956627

Epoch: 5| Step: 2
Training loss: 2.053617000579834
Validation loss: 2.098019230750299

Epoch: 5| Step: 3
Training loss: 2.3925631046295166
Validation loss: 2.137578700178413

Epoch: 5| Step: 4
Training loss: 2.1561689376831055
Validation loss: 2.1272695013271865

Epoch: 5| Step: 5
Training loss: 2.0632543563842773
Validation loss: 2.095231777878218

Epoch: 5| Step: 6
Training loss: 1.980545997619629
Validation loss: 2.1033819093499133

Epoch: 5| Step: 7
Training loss: 2.2618579864501953
Validation loss: 2.044962893250168

Epoch: 5| Step: 8
Training loss: 2.3510427474975586
Validation loss: 2.0862042211717173

Epoch: 5| Step: 9
Training loss: 2.330993175506592
Validation loss: 2.132325539024927

Epoch: 5| Step: 10
Training loss: 1.975145936012268
Validation loss: 2.079157872866559

Epoch: 195| Step: 0
Training loss: 1.977819800376892
Validation loss: 2.163546226357901

Epoch: 5| Step: 1
Training loss: 1.9444679021835327
Validation loss: 2.1049146267675583

Epoch: 5| Step: 2
Training loss: 2.1123745441436768
Validation loss: 2.125791172827444

Epoch: 5| Step: 3
Training loss: 2.3175816535949707
Validation loss: 2.148066184853995

Epoch: 5| Step: 4
Training loss: 2.525113582611084
Validation loss: 2.130077641497376

Epoch: 5| Step: 5
Training loss: 1.91667902469635
Validation loss: 2.1218847741362867

Epoch: 5| Step: 6
Training loss: 2.2877964973449707
Validation loss: 2.17498480760923

Epoch: 5| Step: 7
Training loss: 1.9072881937026978
Validation loss: 2.1182777522712626

Epoch: 5| Step: 8
Training loss: 2.115177869796753
Validation loss: 2.143087548594321

Epoch: 5| Step: 9
Training loss: 1.719463586807251
Validation loss: 2.199377716228526

Epoch: 5| Step: 10
Training loss: 2.4652493000030518
Validation loss: 2.162058012459868

Epoch: 196| Step: 0
Training loss: 2.8161940574645996
Validation loss: 2.2068890345993863

Epoch: 5| Step: 1
Training loss: 1.0475242137908936
Validation loss: 2.1645769739663727

Epoch: 5| Step: 2
Training loss: 2.3778655529022217
Validation loss: 2.158445583876743

Epoch: 5| Step: 3
Training loss: 2.077009916305542
Validation loss: 2.1224285415423814

Epoch: 5| Step: 4
Training loss: 2.1327719688415527
Validation loss: 2.2125010798054356

Epoch: 5| Step: 5
Training loss: 2.165761709213257
Validation loss: 2.1239862339470976

Epoch: 5| Step: 6
Training loss: 1.7191627025604248
Validation loss: 2.2233466640595467

Epoch: 5| Step: 7
Training loss: 1.5943111181259155
Validation loss: 2.1494724083972234

Epoch: 5| Step: 8
Training loss: 2.2287373542785645
Validation loss: 2.1496400192219722

Epoch: 5| Step: 9
Training loss: 2.563256025314331
Validation loss: 2.1287590534456315

Epoch: 5| Step: 10
Training loss: 2.284405469894409
Validation loss: 2.12328218003755

Epoch: 197| Step: 0
Training loss: 2.761223316192627
Validation loss: 2.1519989505890877

Epoch: 5| Step: 1
Training loss: 1.35798978805542
Validation loss: 2.150687938095421

Epoch: 5| Step: 2
Training loss: 2.234806537628174
Validation loss: 2.1221514158351447

Epoch: 5| Step: 3
Training loss: 2.6751935482025146
Validation loss: 2.101388462128178

Epoch: 5| Step: 4
Training loss: 1.7916911840438843
Validation loss: 2.110324037972317

Epoch: 5| Step: 5
Training loss: 1.4240391254425049
Validation loss: 2.1600922102569253

Epoch: 5| Step: 6
Training loss: 2.761842966079712
Validation loss: 2.1022629558399157

Epoch: 5| Step: 7
Training loss: 1.4707905054092407
Validation loss: 2.098506563453264

Epoch: 5| Step: 8
Training loss: 2.1474721431732178
Validation loss: 2.080931555840277

Epoch: 5| Step: 9
Training loss: 2.6020865440368652
Validation loss: 2.1259860979613436

Epoch: 5| Step: 10
Training loss: 2.1537277698516846
Validation loss: 2.1340479209858882

Epoch: 198| Step: 0
Training loss: 2.354308843612671
Validation loss: 2.122538887044435

Epoch: 5| Step: 1
Training loss: 2.089691162109375
Validation loss: 2.103058062573915

Epoch: 5| Step: 2
Training loss: 1.639264464378357
Validation loss: 2.1123220484743834

Epoch: 5| Step: 3
Training loss: 2.853271961212158
Validation loss: 2.1129518683238695

Epoch: 5| Step: 4
Training loss: 2.268362045288086
Validation loss: 2.09994061018831

Epoch: 5| Step: 5
Training loss: 2.1707382202148438
Validation loss: 2.119307174477526

Epoch: 5| Step: 6
Training loss: 2.3630192279815674
Validation loss: 2.0703148508584626

Epoch: 5| Step: 7
Training loss: 2.071716547012329
Validation loss: 2.1629749908242175

Epoch: 5| Step: 8
Training loss: 1.7333118915557861
Validation loss: 2.1048366523558095

Epoch: 5| Step: 9
Training loss: 1.8183425664901733
Validation loss: 2.1353169846278366

Epoch: 5| Step: 10
Training loss: 1.695406198501587
Validation loss: 2.086319979800973

Epoch: 199| Step: 0
Training loss: 1.7969194650650024
Validation loss: 2.141370096514302

Epoch: 5| Step: 1
Training loss: 2.400449752807617
Validation loss: 2.1297368875113865

Epoch: 5| Step: 2
Training loss: 2.817765235900879
Validation loss: 2.1047364024705786

Epoch: 5| Step: 3
Training loss: 2.4606518745422363
Validation loss: 2.108215193594656

Epoch: 5| Step: 4
Training loss: 1.7884657382965088
Validation loss: 2.1537623687457015

Epoch: 5| Step: 5
Training loss: 1.962205171585083
Validation loss: 2.18066749008753

Epoch: 5| Step: 6
Training loss: 1.8236637115478516
Validation loss: 2.1073556689805883

Epoch: 5| Step: 7
Training loss: 2.1792588233947754
Validation loss: 2.1084316802281204

Epoch: 5| Step: 8
Training loss: 1.4145126342773438
Validation loss: 2.0725994956108833

Epoch: 5| Step: 9
Training loss: 2.2007663249969482
Validation loss: 2.1130488944310013

Epoch: 5| Step: 10
Training loss: 2.2753376960754395
Validation loss: 2.0865184081498014

Epoch: 200| Step: 0
Training loss: 1.5227515697479248
Validation loss: 2.0460692169845744

Epoch: 5| Step: 1
Training loss: 2.7214930057525635
Validation loss: 2.0813567202578307

Epoch: 5| Step: 2
Training loss: 2.203432559967041
Validation loss: 2.1719607947975077

Epoch: 5| Step: 3
Training loss: 1.9339878559112549
Validation loss: 2.148323799974175

Epoch: 5| Step: 4
Training loss: 1.5650559663772583
Validation loss: 2.1729078959393244

Epoch: 5| Step: 5
Training loss: 2.0131990909576416
Validation loss: 2.1776048880751415

Epoch: 5| Step: 6
Training loss: 1.904174566268921
Validation loss: 2.1297731604627383

Epoch: 5| Step: 7
Training loss: 2.4798812866210938
Validation loss: 2.191656170352813

Epoch: 5| Step: 8
Training loss: 1.7434543371200562
Validation loss: 2.1552634316106

Epoch: 5| Step: 9
Training loss: 2.3887295722961426
Validation loss: 2.1233655098945863

Epoch: 5| Step: 10
Training loss: 2.3748083114624023
Validation loss: 2.153982595730853

Epoch: 201| Step: 0
Training loss: 2.2759461402893066
Validation loss: 2.1808321475982666

Epoch: 5| Step: 1
Training loss: 2.321348190307617
Validation loss: 2.174030621846517

Epoch: 5| Step: 2
Training loss: 2.2188942432403564
Validation loss: 2.2122495969136557

Epoch: 5| Step: 3
Training loss: 2.443441867828369
Validation loss: 2.1808426226339033

Epoch: 5| Step: 4
Training loss: 1.8925902843475342
Validation loss: 2.1212937114059285

Epoch: 5| Step: 5
Training loss: 1.4499599933624268
Validation loss: 2.148080748896445

Epoch: 5| Step: 6
Training loss: 2.082003355026245
Validation loss: 2.115969363079276

Epoch: 5| Step: 7
Training loss: 2.0802390575408936
Validation loss: 2.0714727909334245

Epoch: 5| Step: 8
Training loss: 2.252511501312256
Validation loss: 2.085457874882606

Epoch: 5| Step: 9
Training loss: 1.845546007156372
Validation loss: 2.0641341465775684

Epoch: 5| Step: 10
Training loss: 2.3444995880126953
Validation loss: 2.1107834128923315

Epoch: 202| Step: 0
Training loss: 2.3794476985931396
Validation loss: 2.1810419251841884

Epoch: 5| Step: 1
Training loss: 2.031184673309326
Validation loss: 2.1406279917686217

Epoch: 5| Step: 2
Training loss: 2.0312297344207764
Validation loss: 2.1360662726945776

Epoch: 5| Step: 3
Training loss: 2.1057121753692627
Validation loss: 2.100056204744565

Epoch: 5| Step: 4
Training loss: 2.4151782989501953
Validation loss: 2.0857599473768667

Epoch: 5| Step: 5
Training loss: 1.8462474346160889
Validation loss: 2.064319820814235

Epoch: 5| Step: 6
Training loss: 1.9633309841156006
Validation loss: 2.1834193686003327

Epoch: 5| Step: 7
Training loss: 1.6448026895523071
Validation loss: 2.1069197500905683

Epoch: 5| Step: 8
Training loss: 2.324373483657837
Validation loss: 2.1484479609356133

Epoch: 5| Step: 9
Training loss: 1.9961779117584229
Validation loss: 2.118411930658484

Epoch: 5| Step: 10
Training loss: 2.291233777999878
Validation loss: 2.107403443705651

Epoch: 203| Step: 0
Training loss: 2.428168535232544
Validation loss: 2.099097039109917

Epoch: 5| Step: 1
Training loss: 1.9628398418426514
Validation loss: 2.1275587594637306

Epoch: 5| Step: 2
Training loss: 1.9845234155654907
Validation loss: 2.181085673711633

Epoch: 5| Step: 3
Training loss: 1.932904601097107
Validation loss: 2.1701926800512497

Epoch: 5| Step: 4
Training loss: 1.9612900018692017
Validation loss: 2.1798207221492643

Epoch: 5| Step: 5
Training loss: 2.0040783882141113
Validation loss: 2.091161193386201

Epoch: 5| Step: 6
Training loss: 2.1930630207061768
Validation loss: 2.1559184802475797

Epoch: 5| Step: 7
Training loss: 2.329951047897339
Validation loss: 2.1591345571702525

Epoch: 5| Step: 8
Training loss: 1.636810064315796
Validation loss: 2.1678971654625347

Epoch: 5| Step: 9
Training loss: 2.186115264892578
Validation loss: 2.1201201023594027

Epoch: 5| Step: 10
Training loss: 2.4960763454437256
Validation loss: 2.1837122363428914

Epoch: 204| Step: 0
Training loss: 2.2966666221618652
Validation loss: 2.201512800749912

Epoch: 5| Step: 1
Training loss: 2.098666191101074
Validation loss: 2.1833760097462642

Epoch: 5| Step: 2
Training loss: 1.6042547225952148
Validation loss: 2.1131629892574844

Epoch: 5| Step: 3
Training loss: 1.8816258907318115
Validation loss: 2.0997955606829737

Epoch: 5| Step: 4
Training loss: 1.9100170135498047
Validation loss: 2.1505993514932613

Epoch: 5| Step: 5
Training loss: 1.8458703756332397
Validation loss: 2.215289047969285

Epoch: 5| Step: 6
Training loss: 2.6076369285583496
Validation loss: 2.114032463360858

Epoch: 5| Step: 7
Training loss: 2.214977979660034
Validation loss: 2.149220851159865

Epoch: 5| Step: 8
Training loss: 2.505078077316284
Validation loss: 2.1338902340140393

Epoch: 5| Step: 9
Training loss: 1.9168713092803955
Validation loss: 2.09873898824056

Epoch: 5| Step: 10
Training loss: 1.863648772239685
Validation loss: 2.0465527875449068

Epoch: 205| Step: 0
Training loss: 1.7522189617156982
Validation loss: 2.162074778669624

Epoch: 5| Step: 1
Training loss: 2.3982019424438477
Validation loss: 2.1013017008381505

Epoch: 5| Step: 2
Training loss: 2.460148334503174
Validation loss: 2.1156301088230585

Epoch: 5| Step: 3
Training loss: 2.0962252616882324
Validation loss: 2.1370715338696717

Epoch: 5| Step: 4
Training loss: 2.22063946723938
Validation loss: 2.0925225865456367

Epoch: 5| Step: 5
Training loss: 2.7924017906188965
Validation loss: 2.1109938390793337

Epoch: 5| Step: 6
Training loss: 1.9282575845718384
Validation loss: 2.115295253774171

Epoch: 5| Step: 7
Training loss: 1.4749888181686401
Validation loss: 2.1268864472707114

Epoch: 5| Step: 8
Training loss: 1.9246078729629517
Validation loss: 2.1295818577530565

Epoch: 5| Step: 9
Training loss: 1.6372219324111938
Validation loss: 2.114797774181571

Epoch: 5| Step: 10
Training loss: 2.7653605937957764
Validation loss: 2.0588594149517756

Epoch: 206| Step: 0
Training loss: 2.1013331413269043
Validation loss: 2.089335710771622

Epoch: 5| Step: 1
Training loss: 1.4792773723602295
Validation loss: 2.1591390102140364

Epoch: 5| Step: 2
Training loss: 1.8006254434585571
Validation loss: 2.1426333496647496

Epoch: 5| Step: 3
Training loss: 2.4540631771087646
Validation loss: 2.0599470164186213

Epoch: 5| Step: 4
Training loss: 2.3418824672698975
Validation loss: 2.1031847948669107

Epoch: 5| Step: 5
Training loss: 2.1770827770233154
Validation loss: 2.1240010902445805

Epoch: 5| Step: 6
Training loss: 1.6543598175048828
Validation loss: 2.1371400971566477

Epoch: 5| Step: 7
Training loss: 1.7454843521118164
Validation loss: 2.1056615550030946

Epoch: 5| Step: 8
Training loss: 2.651819944381714
Validation loss: 2.1152514821739605

Epoch: 5| Step: 9
Training loss: 2.2473526000976562
Validation loss: 2.051212751737205

Epoch: 5| Step: 10
Training loss: 2.4769062995910645
Validation loss: 2.1130622522805327

Epoch: 207| Step: 0
Training loss: 2.818969488143921
Validation loss: 2.1312839369620047

Epoch: 5| Step: 1
Training loss: 2.1652894020080566
Validation loss: 2.1628995992804088

Epoch: 5| Step: 2
Training loss: 1.7415568828582764
Validation loss: 2.068776217840051

Epoch: 5| Step: 3
Training loss: 1.7206112146377563
Validation loss: 2.0975897260891494

Epoch: 5| Step: 4
Training loss: 1.9700820446014404
Validation loss: 2.038086022100141

Epoch: 5| Step: 5
Training loss: 2.4135680198669434
Validation loss: 2.110960929624496

Epoch: 5| Step: 6
Training loss: 2.230684518814087
Validation loss: 2.155813447890743

Epoch: 5| Step: 7
Training loss: 1.772671103477478
Validation loss: 2.0977540323811192

Epoch: 5| Step: 8
Training loss: 2.061613082885742
Validation loss: 2.0643426064522035

Epoch: 5| Step: 9
Training loss: 1.934657335281372
Validation loss: 2.100313707064557

Epoch: 5| Step: 10
Training loss: 1.7186657190322876
Validation loss: 2.073138106253839

Epoch: 208| Step: 0
Training loss: 1.7332980632781982
Validation loss: 2.114255343714068

Epoch: 5| Step: 1
Training loss: 2.150914430618286
Validation loss: 2.180665176401856

Epoch: 5| Step: 2
Training loss: 2.3237524032592773
Validation loss: 2.120446156429988

Epoch: 5| Step: 3
Training loss: 2.0442357063293457
Validation loss: 2.1409494210315008

Epoch: 5| Step: 4
Training loss: 1.9874279499053955
Validation loss: 2.1337244023558912

Epoch: 5| Step: 5
Training loss: 2.0251495838165283
Validation loss: 2.1204221402445147

Epoch: 5| Step: 6
Training loss: 1.6081997156143188
Validation loss: 2.1386856981503066

Epoch: 5| Step: 7
Training loss: 2.165846109390259
Validation loss: 2.088913422758861

Epoch: 5| Step: 8
Training loss: 2.723402976989746
Validation loss: 2.187964565010481

Epoch: 5| Step: 9
Training loss: 1.9909789562225342
Validation loss: 2.1180517801674466

Epoch: 5| Step: 10
Training loss: 2.6161296367645264
Validation loss: 2.134003173920416

Epoch: 209| Step: 0
Training loss: 1.8577772378921509
Validation loss: 2.1357519267707743

Epoch: 5| Step: 1
Training loss: 2.174898147583008
Validation loss: 2.158256205179358

Epoch: 5| Step: 2
Training loss: 1.945844292640686
Validation loss: 2.137818246759394

Epoch: 5| Step: 3
Training loss: 2.3125767707824707
Validation loss: 2.1700892422788884

Epoch: 5| Step: 4
Training loss: 2.0318455696105957
Validation loss: 2.138146415833504

Epoch: 5| Step: 5
Training loss: 1.7944129705429077
Validation loss: 2.087665573243172

Epoch: 5| Step: 6
Training loss: 2.130195140838623
Validation loss: 2.1649322073946715

Epoch: 5| Step: 7
Training loss: 2.550572633743286
Validation loss: 2.128993765000374

Epoch: 5| Step: 8
Training loss: 1.6195799112319946
Validation loss: 2.10432174897963

Epoch: 5| Step: 9
Training loss: 2.303006649017334
Validation loss: 2.152292010604694

Epoch: 5| Step: 10
Training loss: 2.4956421852111816
Validation loss: 2.143724121073241

Epoch: 210| Step: 0
Training loss: 1.8036428689956665
Validation loss: 2.099063878418297

Epoch: 5| Step: 1
Training loss: 1.850464105606079
Validation loss: 2.07528938529312

Epoch: 5| Step: 2
Training loss: 2.1162781715393066
Validation loss: 2.105109764683631

Epoch: 5| Step: 3
Training loss: 1.7298310995101929
Validation loss: 2.109778858000232

Epoch: 5| Step: 4
Training loss: 2.209221363067627
Validation loss: 2.1580570692657144

Epoch: 5| Step: 5
Training loss: 2.3106179237365723
Validation loss: 2.1202210457094255

Epoch: 5| Step: 6
Training loss: 1.849169135093689
Validation loss: 2.0956366703074467

Epoch: 5| Step: 7
Training loss: 2.0643744468688965
Validation loss: 2.117776846372953

Epoch: 5| Step: 8
Training loss: 2.5740742683410645
Validation loss: 2.094486144281203

Epoch: 5| Step: 9
Training loss: 2.281548023223877
Validation loss: 2.129671142947289

Epoch: 5| Step: 10
Training loss: 1.996233344078064
Validation loss: 2.150964570301835

Epoch: 211| Step: 0
Training loss: 2.0714402198791504
Validation loss: 2.1137610455994964

Epoch: 5| Step: 1
Training loss: 1.5426890850067139
Validation loss: 2.1185516144639704

Epoch: 5| Step: 2
Training loss: 1.2891075611114502
Validation loss: 2.0715803792399745

Epoch: 5| Step: 3
Training loss: 1.932913064956665
Validation loss: 2.047858049792628

Epoch: 5| Step: 4
Training loss: 2.150742769241333
Validation loss: 2.078344545056743

Epoch: 5| Step: 5
Training loss: 2.43837833404541
Validation loss: 2.112335257632758

Epoch: 5| Step: 6
Training loss: 2.0295958518981934
Validation loss: 2.1229574398327897

Epoch: 5| Step: 7
Training loss: 2.630980968475342
Validation loss: 2.088981164399014

Epoch: 5| Step: 8
Training loss: 2.1003835201263428
Validation loss: 2.055373962207507

Epoch: 5| Step: 9
Training loss: 2.836834669113159
Validation loss: 2.1152217259971042

Epoch: 5| Step: 10
Training loss: 2.200590133666992
Validation loss: 2.0847995383765108

Epoch: 212| Step: 0
Training loss: 1.7990423440933228
Validation loss: 2.1685457537251134

Epoch: 5| Step: 1
Training loss: 2.0679783821105957
Validation loss: 2.1777185317008727

Epoch: 5| Step: 2
Training loss: 2.1807665824890137
Validation loss: 2.114096636413246

Epoch: 5| Step: 3
Training loss: 1.8792064189910889
Validation loss: 2.095250847519085

Epoch: 5| Step: 4
Training loss: 1.9385207891464233
Validation loss: 2.0970313818224016

Epoch: 5| Step: 5
Training loss: 2.2835116386413574
Validation loss: 2.1004264098341747

Epoch: 5| Step: 6
Training loss: 1.9512150287628174
Validation loss: 2.170023161877868

Epoch: 5| Step: 7
Training loss: 1.750387191772461
Validation loss: 2.1204019079926195

Epoch: 5| Step: 8
Training loss: 2.4495162963867188
Validation loss: 2.1497595592211654

Epoch: 5| Step: 9
Training loss: 2.752373456954956
Validation loss: 2.0952615878915273

Epoch: 5| Step: 10
Training loss: 1.6048266887664795
Validation loss: 2.1647998697014263

Epoch: 213| Step: 0
Training loss: 1.2288062572479248
Validation loss: 2.1497040640923286

Epoch: 5| Step: 1
Training loss: 2.270779848098755
Validation loss: 2.1478890449770036

Epoch: 5| Step: 2
Training loss: 2.1450490951538086
Validation loss: 2.139446220090312

Epoch: 5| Step: 3
Training loss: 2.318984031677246
Validation loss: 2.1148103167933803

Epoch: 5| Step: 4
Training loss: 1.828084945678711
Validation loss: 2.1014525787804716

Epoch: 5| Step: 5
Training loss: 2.026953935623169
Validation loss: 2.172108245152299

Epoch: 5| Step: 6
Training loss: 1.9644721746444702
Validation loss: 2.120879239933465

Epoch: 5| Step: 7
Training loss: 2.6193857192993164
Validation loss: 2.131815596293378

Epoch: 5| Step: 8
Training loss: 2.015334129333496
Validation loss: 2.099709726149036

Epoch: 5| Step: 9
Training loss: 2.3118269443511963
Validation loss: 2.1687289758395125

Epoch: 5| Step: 10
Training loss: 2.3680124282836914
Validation loss: 2.099606316576722

Epoch: 214| Step: 0
Training loss: 2.186762571334839
Validation loss: 2.0826487233561854

Epoch: 5| Step: 1
Training loss: 1.6855825185775757
Validation loss: 2.108065758982012

Epoch: 5| Step: 2
Training loss: 2.567922353744507
Validation loss: 2.070137923763644

Epoch: 5| Step: 3
Training loss: 1.4854867458343506
Validation loss: 2.10320702163122

Epoch: 5| Step: 4
Training loss: 1.7631639242172241
Validation loss: 2.1063777041691605

Epoch: 5| Step: 5
Training loss: 1.945467233657837
Validation loss: 2.1131625201112483

Epoch: 5| Step: 6
Training loss: 2.3445074558258057
Validation loss: 2.152871137024254

Epoch: 5| Step: 7
Training loss: 2.128803014755249
Validation loss: 2.098969490297379

Epoch: 5| Step: 8
Training loss: 2.022035598754883
Validation loss: 2.0793740236631004

Epoch: 5| Step: 9
Training loss: 2.6627533435821533
Validation loss: 2.087080268449681

Epoch: 5| Step: 10
Training loss: 2.178560495376587
Validation loss: 2.1198383877354283

Epoch: 215| Step: 0
Training loss: 2.244215250015259
Validation loss: 2.0809946342181136

Epoch: 5| Step: 1
Training loss: 1.901179552078247
Validation loss: 2.1257449042412544

Epoch: 5| Step: 2
Training loss: 1.859747290611267
Validation loss: 2.123121428233321

Epoch: 5| Step: 3
Training loss: 1.6983287334442139
Validation loss: 2.120003605401644

Epoch: 5| Step: 4
Training loss: 2.257823944091797
Validation loss: 2.087507160761023

Epoch: 5| Step: 5
Training loss: 2.204017162322998
Validation loss: 2.1257536667649464

Epoch: 5| Step: 6
Training loss: 2.3295063972473145
Validation loss: 2.1379073307078373

Epoch: 5| Step: 7
Training loss: 2.2584075927734375
Validation loss: 2.147082767178935

Epoch: 5| Step: 8
Training loss: 2.34293532371521
Validation loss: 2.1684338097931235

Epoch: 5| Step: 9
Training loss: 2.107971668243408
Validation loss: 2.1266106687566286

Epoch: 5| Step: 10
Training loss: 1.8607492446899414
Validation loss: 2.1167232797991846

Epoch: 216| Step: 0
Training loss: 1.9707187414169312
Validation loss: 2.0988951921463013

Epoch: 5| Step: 1
Training loss: 1.7411870956420898
Validation loss: 2.102263237840386

Epoch: 5| Step: 2
Training loss: 1.6076138019561768
Validation loss: 2.079856321375857

Epoch: 5| Step: 3
Training loss: 2.532166004180908
Validation loss: 2.130967592680326

Epoch: 5| Step: 4
Training loss: 2.494962215423584
Validation loss: 2.1685829957326255

Epoch: 5| Step: 5
Training loss: 1.9360030889511108
Validation loss: 2.1426500299925446

Epoch: 5| Step: 6
Training loss: 2.2850704193115234
Validation loss: 2.1098598049532984

Epoch: 5| Step: 7
Training loss: 1.9281558990478516
Validation loss: 2.1244643131891885

Epoch: 5| Step: 8
Training loss: 2.3177828788757324
Validation loss: 2.108138621494334

Epoch: 5| Step: 9
Training loss: 1.930039644241333
Validation loss: 2.11199317824456

Epoch: 5| Step: 10
Training loss: 1.971070408821106
Validation loss: 2.14703691902981

Epoch: 217| Step: 0
Training loss: 1.986915946006775
Validation loss: 2.137426914707307

Epoch: 5| Step: 1
Training loss: 2.059040069580078
Validation loss: 2.1446499132340953

Epoch: 5| Step: 2
Training loss: 2.185723066329956
Validation loss: 2.0559952515427784

Epoch: 5| Step: 3
Training loss: 2.162311553955078
Validation loss: 2.1385635188830796

Epoch: 5| Step: 4
Training loss: 2.13797664642334
Validation loss: 2.1379404862721763

Epoch: 5| Step: 5
Training loss: 1.745889663696289
Validation loss: 2.1203469678919804

Epoch: 5| Step: 6
Training loss: 2.5223026275634766
Validation loss: 2.123442643432207

Epoch: 5| Step: 7
Training loss: 1.946944236755371
Validation loss: 2.0513301639146704

Epoch: 5| Step: 8
Training loss: 2.1275899410247803
Validation loss: 2.1002981906296103

Epoch: 5| Step: 9
Training loss: 1.5578196048736572
Validation loss: 2.0721354074375604

Epoch: 5| Step: 10
Training loss: 2.599058151245117
Validation loss: 2.0582313101778746

Epoch: 218| Step: 0
Training loss: 2.4938528537750244
Validation loss: 2.1369900729066584

Epoch: 5| Step: 1
Training loss: 1.8051866292953491
Validation loss: 2.14901993607962

Epoch: 5| Step: 2
Training loss: 2.1367783546447754
Validation loss: 2.1091592593859603

Epoch: 5| Step: 3
Training loss: 2.3980913162231445
Validation loss: 2.111784601724276

Epoch: 5| Step: 4
Training loss: 2.273663282394409
Validation loss: 2.1483558659912436

Epoch: 5| Step: 5
Training loss: 2.8109688758850098
Validation loss: 2.0974036852518716

Epoch: 5| Step: 6
Training loss: 1.4561978578567505
Validation loss: 2.1546586175118723

Epoch: 5| Step: 7
Training loss: 1.6855201721191406
Validation loss: 2.053637545595887

Epoch: 5| Step: 8
Training loss: 2.4478511810302734
Validation loss: 2.0283612358954644

Epoch: 5| Step: 9
Training loss: 1.5523560047149658
Validation loss: 2.0846194721037343

Epoch: 5| Step: 10
Training loss: 1.795674443244934
Validation loss: 2.149385872707572

Epoch: 219| Step: 0
Training loss: 1.4414780139923096
Validation loss: 2.115376798055505

Epoch: 5| Step: 1
Training loss: 1.420090913772583
Validation loss: 2.11534276957153

Epoch: 5| Step: 2
Training loss: 2.2064762115478516
Validation loss: 2.1700916956829768

Epoch: 5| Step: 3
Training loss: 2.20698881149292
Validation loss: 2.056511514930315

Epoch: 5| Step: 4
Training loss: 2.0960910320281982
Validation loss: 2.1354210594648957

Epoch: 5| Step: 5
Training loss: 1.9603335857391357
Validation loss: 2.184500589165636

Epoch: 5| Step: 6
Training loss: 2.249596118927002
Validation loss: 2.1215297534901607

Epoch: 5| Step: 7
Training loss: 2.3134162425994873
Validation loss: 2.1515680897620415

Epoch: 5| Step: 8
Training loss: 2.1825428009033203
Validation loss: 2.1523165984820296

Epoch: 5| Step: 9
Training loss: 2.0763680934906006
Validation loss: 2.175453188598797

Epoch: 5| Step: 10
Training loss: 2.9729907512664795
Validation loss: 2.16722543521594

Epoch: 220| Step: 0
Training loss: 1.8886083364486694
Validation loss: 2.1208549314929592

Epoch: 5| Step: 1
Training loss: 1.7931267023086548
Validation loss: 2.118449503375638

Epoch: 5| Step: 2
Training loss: 2.115659236907959
Validation loss: 2.1219684180393013

Epoch: 5| Step: 3
Training loss: 1.7742290496826172
Validation loss: 2.11131283544725

Epoch: 5| Step: 4
Training loss: 1.9992246627807617
Validation loss: 2.1122224484720538

Epoch: 5| Step: 5
Training loss: 2.4607582092285156
Validation loss: 2.1116846940850698

Epoch: 5| Step: 6
Training loss: 1.9984372854232788
Validation loss: 2.129498397150347

Epoch: 5| Step: 7
Training loss: 1.9994316101074219
Validation loss: 2.192008638894686

Epoch: 5| Step: 8
Training loss: 2.1872506141662598
Validation loss: 2.113068357590706

Epoch: 5| Step: 9
Training loss: 2.6227517127990723
Validation loss: 2.140283243630522

Epoch: 5| Step: 10
Training loss: 2.494903802871704
Validation loss: 2.1278631071890555

Epoch: 221| Step: 0
Training loss: 1.5609370470046997
Validation loss: 2.142187759440432

Epoch: 5| Step: 1
Training loss: 2.339508056640625
Validation loss: 2.158941991867558

Epoch: 5| Step: 2
Training loss: 2.1102683544158936
Validation loss: 2.182505110258697

Epoch: 5| Step: 3
Training loss: 1.8976867198944092
Validation loss: 2.17758842309316

Epoch: 5| Step: 4
Training loss: 1.8573875427246094
Validation loss: 2.1585634549458823

Epoch: 5| Step: 5
Training loss: 2.163796901702881
Validation loss: 2.0747013809860393

Epoch: 5| Step: 6
Training loss: 1.9986003637313843
Validation loss: 2.0921993229978826

Epoch: 5| Step: 7
Training loss: 2.0486419200897217
Validation loss: 2.2095954469455186

Epoch: 5| Step: 8
Training loss: 1.8467661142349243
Validation loss: 2.142550837609076

Epoch: 5| Step: 9
Training loss: 2.404599666595459
Validation loss: 2.145106073348753

Epoch: 5| Step: 10
Training loss: 2.9842190742492676
Validation loss: 2.1309444314690045

Epoch: 222| Step: 0
Training loss: 1.8404645919799805
Validation loss: 2.147788252881778

Epoch: 5| Step: 1
Training loss: 1.9100522994995117
Validation loss: 2.0872851674274733

Epoch: 5| Step: 2
Training loss: 1.7339376211166382
Validation loss: 2.094392479106944

Epoch: 5| Step: 3
Training loss: 2.0707099437713623
Validation loss: 2.109312367695634

Epoch: 5| Step: 4
Training loss: 1.6063241958618164
Validation loss: 2.113618249534279

Epoch: 5| Step: 5
Training loss: 2.450106382369995
Validation loss: 2.072950554150407

Epoch: 5| Step: 6
Training loss: 2.249800205230713
Validation loss: 2.1110247924763668

Epoch: 5| Step: 7
Training loss: 2.3552448749542236
Validation loss: 2.0891208494863203

Epoch: 5| Step: 8
Training loss: 2.557828187942505
Validation loss: 2.1145685949633197

Epoch: 5| Step: 9
Training loss: 2.1601221561431885
Validation loss: 2.118309082523469

Epoch: 5| Step: 10
Training loss: 1.7201284170150757
Validation loss: 2.1080531535610074

Epoch: 223| Step: 0
Training loss: 1.6888965368270874
Validation loss: 2.117573545825097

Epoch: 5| Step: 1
Training loss: 2.0783889293670654
Validation loss: 2.124449792728629

Epoch: 5| Step: 2
Training loss: 1.7053840160369873
Validation loss: 2.1467043802302372

Epoch: 5| Step: 3
Training loss: 2.322927951812744
Validation loss: 2.0899499693224506

Epoch: 5| Step: 4
Training loss: 1.8330914974212646
Validation loss: 2.1659695948323896

Epoch: 5| Step: 5
Training loss: 1.9859100580215454
Validation loss: 2.0704664338019585

Epoch: 5| Step: 6
Training loss: 2.7707934379577637
Validation loss: 2.1126883235028995

Epoch: 5| Step: 7
Training loss: 1.9067211151123047
Validation loss: 2.1123449289670555

Epoch: 5| Step: 8
Training loss: 2.2437124252319336
Validation loss: 2.1137937576540056

Epoch: 5| Step: 9
Training loss: 2.6773223876953125
Validation loss: 2.1476921983944472

Epoch: 5| Step: 10
Training loss: 1.6239486932754517
Validation loss: 2.1506677007162445

Epoch: 224| Step: 0
Training loss: 2.368825912475586
Validation loss: 2.129467566808065

Epoch: 5| Step: 1
Training loss: 1.7651383876800537
Validation loss: 2.1302978172097156

Epoch: 5| Step: 2
Training loss: 1.9979417324066162
Validation loss: 2.1703440655944166

Epoch: 5| Step: 3
Training loss: 2.5791356563568115
Validation loss: 2.1604793148656047

Epoch: 5| Step: 4
Training loss: 2.298306941986084
Validation loss: 2.161447207132975

Epoch: 5| Step: 5
Training loss: 2.334984302520752
Validation loss: 2.098334309875324

Epoch: 5| Step: 6
Training loss: 1.9298229217529297
Validation loss: 2.1208605689387166

Epoch: 5| Step: 7
Training loss: 1.9165327548980713
Validation loss: 2.1825943928892895

Epoch: 5| Step: 8
Training loss: 1.9757477045059204
Validation loss: 2.1149636263488443

Epoch: 5| Step: 9
Training loss: 1.9364551305770874
Validation loss: 2.1720924403077815

Epoch: 5| Step: 10
Training loss: 1.3752899169921875
Validation loss: 2.146989876224149

Epoch: 225| Step: 0
Training loss: 1.7465975284576416
Validation loss: 2.1158476901310745

Epoch: 5| Step: 1
Training loss: 2.4223361015319824
Validation loss: 2.1568490305254535

Epoch: 5| Step: 2
Training loss: 1.2066116333007812
Validation loss: 2.069035836445388

Epoch: 5| Step: 3
Training loss: 2.2420504093170166
Validation loss: 2.114668853821293

Epoch: 5| Step: 4
Training loss: 1.8201204538345337
Validation loss: 2.0748224873696604

Epoch: 5| Step: 5
Training loss: 2.019131898880005
Validation loss: 2.1175497039671867

Epoch: 5| Step: 6
Training loss: 2.5952138900756836
Validation loss: 2.067505295558642

Epoch: 5| Step: 7
Training loss: 2.191410779953003
Validation loss: 2.0654921941859747

Epoch: 5| Step: 8
Training loss: 1.6890003681182861
Validation loss: 2.1039212262758644

Epoch: 5| Step: 9
Training loss: 2.17397403717041
Validation loss: 2.135176484302808

Epoch: 5| Step: 10
Training loss: 2.021341562271118
Validation loss: 2.1521262686739684

Epoch: 226| Step: 0
Training loss: 1.9703056812286377
Validation loss: 2.146723021743118

Epoch: 5| Step: 1
Training loss: 1.9689362049102783
Validation loss: 2.0979651943329842

Epoch: 5| Step: 2
Training loss: 2.323214530944824
Validation loss: 2.129578915975427

Epoch: 5| Step: 3
Training loss: 1.8388515710830688
Validation loss: 2.093316916496523

Epoch: 5| Step: 4
Training loss: 1.6892149448394775
Validation loss: 2.1389027872393207

Epoch: 5| Step: 5
Training loss: 2.2149531841278076
Validation loss: 2.188457001921951

Epoch: 5| Step: 6
Training loss: 2.401581287384033
Validation loss: 2.1007116046003116

Epoch: 5| Step: 7
Training loss: 1.7664334774017334
Validation loss: 2.1172116238583802

Epoch: 5| Step: 8
Training loss: 2.775940418243408
Validation loss: 2.1180917832159225

Epoch: 5| Step: 9
Training loss: 1.438923716545105
Validation loss: 2.157579811670447

Epoch: 5| Step: 10
Training loss: 1.7413063049316406
Validation loss: 2.200089244432347

Epoch: 227| Step: 0
Training loss: 1.8476793766021729
Validation loss: 2.120151171120264

Epoch: 5| Step: 1
Training loss: 1.4328219890594482
Validation loss: 2.1521843171888784

Epoch: 5| Step: 2
Training loss: 2.079261064529419
Validation loss: 2.124548860775527

Epoch: 5| Step: 3
Training loss: 2.3258957862854004
Validation loss: 2.1179477143031296

Epoch: 5| Step: 4
Training loss: 2.471579074859619
Validation loss: 2.115341653106033

Epoch: 5| Step: 5
Training loss: 2.601699113845825
Validation loss: 2.13123252314906

Epoch: 5| Step: 6
Training loss: 1.8181949853897095
Validation loss: 2.1465903289856447

Epoch: 5| Step: 7
Training loss: 1.87602961063385
Validation loss: 2.1245808037378455

Epoch: 5| Step: 8
Training loss: 2.005323886871338
Validation loss: 2.064648046288439

Epoch: 5| Step: 9
Training loss: 2.043942451477051
Validation loss: 2.118519716365363

Epoch: 5| Step: 10
Training loss: 2.155184745788574
Validation loss: 2.1095944655838834

Epoch: 228| Step: 0
Training loss: 2.1487364768981934
Validation loss: 2.1144374391084075

Epoch: 5| Step: 1
Training loss: 2.257652997970581
Validation loss: 2.0698716050835064

Epoch: 5| Step: 2
Training loss: 1.4726377725601196
Validation loss: 2.1924387947205575

Epoch: 5| Step: 3
Training loss: 1.8919998407363892
Validation loss: 2.1366757321101364

Epoch: 5| Step: 4
Training loss: 2.0699031352996826
Validation loss: 2.134066935508482

Epoch: 5| Step: 5
Training loss: 2.3059191703796387
Validation loss: 2.155567815226893

Epoch: 5| Step: 6
Training loss: 1.9504787921905518
Validation loss: 2.1660695909171976

Epoch: 5| Step: 7
Training loss: 2.1561670303344727
Validation loss: 2.1545418193263393

Epoch: 5| Step: 8
Training loss: 2.2310662269592285
Validation loss: 2.0903187003186954

Epoch: 5| Step: 9
Training loss: 2.588075637817383
Validation loss: 2.144055874116959

Epoch: 5| Step: 10
Training loss: 1.9022549390792847
Validation loss: 2.0576776971099195

Epoch: 229| Step: 0
Training loss: 2.2691009044647217
Validation loss: 2.164748066215105

Epoch: 5| Step: 1
Training loss: 1.8512423038482666
Validation loss: 2.098821824596774

Epoch: 5| Step: 2
Training loss: 2.288870334625244
Validation loss: 2.165944701881819

Epoch: 5| Step: 3
Training loss: 2.328629732131958
Validation loss: 2.0633792185014292

Epoch: 5| Step: 4
Training loss: 1.6201021671295166
Validation loss: 2.191667074798256

Epoch: 5| Step: 5
Training loss: 1.6329028606414795
Validation loss: 2.105126121992706

Epoch: 5| Step: 6
Training loss: 2.4842028617858887
Validation loss: 2.1727205553362445

Epoch: 5| Step: 7
Training loss: 1.912289023399353
Validation loss: 2.0988646681590746

Epoch: 5| Step: 8
Training loss: 2.2354931831359863
Validation loss: 2.125672545484317

Epoch: 5| Step: 9
Training loss: 2.4195003509521484
Validation loss: 2.127881150091848

Epoch: 5| Step: 10
Training loss: 1.339839220046997
Validation loss: 2.1039061392507246

Epoch: 230| Step: 0
Training loss: 1.4394766092300415
Validation loss: 2.123337802066598

Epoch: 5| Step: 1
Training loss: 2.152878761291504
Validation loss: 2.138588551552065

Epoch: 5| Step: 2
Training loss: 2.088959217071533
Validation loss: 2.1624415741171887

Epoch: 5| Step: 3
Training loss: 1.6214911937713623
Validation loss: 2.0829551822395733

Epoch: 5| Step: 4
Training loss: 2.8387131690979004
Validation loss: 2.137575175172539

Epoch: 5| Step: 5
Training loss: 2.2802233695983887
Validation loss: 2.1628262765945925

Epoch: 5| Step: 6
Training loss: 1.9070221185684204
Validation loss: 2.1381952813876572

Epoch: 5| Step: 7
Training loss: 2.245476722717285
Validation loss: 2.1422923585420013

Epoch: 5| Step: 8
Training loss: 2.038465976715088
Validation loss: 2.0870033566669752

Epoch: 5| Step: 9
Training loss: 2.049808979034424
Validation loss: 2.1049222997439805

Epoch: 5| Step: 10
Training loss: 2.1465892791748047
Validation loss: 2.0651713327694963

Epoch: 231| Step: 0
Training loss: 1.8489100933074951
Validation loss: 2.0946822179261075

Epoch: 5| Step: 1
Training loss: 2.504261016845703
Validation loss: 2.056871671830454

Epoch: 5| Step: 2
Training loss: 1.8429120779037476
Validation loss: 2.0899313547277965

Epoch: 5| Step: 3
Training loss: 1.5369133949279785
Validation loss: 2.090865901721421

Epoch: 5| Step: 4
Training loss: 1.7854284048080444
Validation loss: 2.164606358415337

Epoch: 5| Step: 5
Training loss: 1.7114858627319336
Validation loss: 2.1042413121910504

Epoch: 5| Step: 6
Training loss: 1.7985038757324219
Validation loss: 2.179889923782759

Epoch: 5| Step: 7
Training loss: 2.453644275665283
Validation loss: 2.1305183697772283

Epoch: 5| Step: 8
Training loss: 2.267209529876709
Validation loss: 2.110162955458446

Epoch: 5| Step: 9
Training loss: 2.5893607139587402
Validation loss: 2.1606954951440134

Epoch: 5| Step: 10
Training loss: 2.716923236846924
Validation loss: 2.1778162807546635

Epoch: 232| Step: 0
Training loss: 2.005871534347534
Validation loss: 2.1514614807662142

Epoch: 5| Step: 1
Training loss: 2.4904866218566895
Validation loss: 2.124568723863171

Epoch: 5| Step: 2
Training loss: 1.7138309478759766
Validation loss: 2.1337066606808732

Epoch: 5| Step: 3
Training loss: 1.930710792541504
Validation loss: 2.1176936780252764

Epoch: 5| Step: 4
Training loss: 2.451526165008545
Validation loss: 2.0820748036907566

Epoch: 5| Step: 5
Training loss: 1.6082366704940796
Validation loss: 2.0851905140825497

Epoch: 5| Step: 6
Training loss: 1.9675624370574951
Validation loss: 2.0477166739843224

Epoch: 5| Step: 7
Training loss: 2.7794086933135986
Validation loss: 2.1410092538402927

Epoch: 5| Step: 8
Training loss: 1.8073513507843018
Validation loss: 2.138573383772245

Epoch: 5| Step: 9
Training loss: 2.1028242111206055
Validation loss: 2.095254954471383

Epoch: 5| Step: 10
Training loss: 1.9184659719467163
Validation loss: 2.165336214086061

Epoch: 233| Step: 0
Training loss: 1.8074805736541748
Validation loss: 2.116167664527893

Epoch: 5| Step: 1
Training loss: 2.250023126602173
Validation loss: 2.1355793501741145

Epoch: 5| Step: 2
Training loss: 1.6869319677352905
Validation loss: 2.1503587333104943

Epoch: 5| Step: 3
Training loss: 2.1814675331115723
Validation loss: 2.110168371149289

Epoch: 5| Step: 4
Training loss: 2.570244312286377
Validation loss: 2.1267890417447655

Epoch: 5| Step: 5
Training loss: 1.2173649072647095
Validation loss: 2.121543515113092

Epoch: 5| Step: 6
Training loss: 2.498893976211548
Validation loss: 2.1428988620799077

Epoch: 5| Step: 7
Training loss: 2.6933505535125732
Validation loss: 2.1713926792144775

Epoch: 5| Step: 8
Training loss: 1.8488426208496094
Validation loss: 2.1394300396724413

Epoch: 5| Step: 9
Training loss: 1.9137556552886963
Validation loss: 2.121118773696243

Epoch: 5| Step: 10
Training loss: 1.8710896968841553
Validation loss: 2.1178965555724276

Epoch: 234| Step: 0
Training loss: 2.042031764984131
Validation loss: 2.124046890966354

Epoch: 5| Step: 1
Training loss: 2.1142232418060303
Validation loss: 2.077908477475566

Epoch: 5| Step: 2
Training loss: 2.20642352104187
Validation loss: 2.140818499749707

Epoch: 5| Step: 3
Training loss: 1.4939686059951782
Validation loss: 2.166150527615701

Epoch: 5| Step: 4
Training loss: 1.9352449178695679
Validation loss: 2.110633760370234

Epoch: 5| Step: 5
Training loss: 2.5724129676818848
Validation loss: 2.16990343986019

Epoch: 5| Step: 6
Training loss: 1.9132163524627686
Validation loss: 2.1092386784092074

Epoch: 5| Step: 7
Training loss: 2.870816707611084
Validation loss: 2.1894422218363774

Epoch: 5| Step: 8
Training loss: 2.022468090057373
Validation loss: 2.136419875647432

Epoch: 5| Step: 9
Training loss: 1.6634197235107422
Validation loss: 2.1878925946451004

Epoch: 5| Step: 10
Training loss: 1.696360468864441
Validation loss: 2.1311719725208897

Epoch: 235| Step: 0
Training loss: 2.0545401573181152
Validation loss: 2.179400472230809

Epoch: 5| Step: 1
Training loss: 2.3324363231658936
Validation loss: 2.113624154880483

Epoch: 5| Step: 2
Training loss: 1.8235572576522827
Validation loss: 2.1558150065842496

Epoch: 5| Step: 3
Training loss: 2.0723650455474854
Validation loss: 2.075143068067489

Epoch: 5| Step: 4
Training loss: 2.22782039642334
Validation loss: 2.1658695103019796

Epoch: 5| Step: 5
Training loss: 2.09100341796875
Validation loss: 2.032824106113885

Epoch: 5| Step: 6
Training loss: 1.4245082139968872
Validation loss: 2.0820660052760953

Epoch: 5| Step: 7
Training loss: 2.4598729610443115
Validation loss: 2.102702389481247

Epoch: 5| Step: 8
Training loss: 2.3195641040802
Validation loss: 2.0609180901640203

Epoch: 5| Step: 9
Training loss: 1.4089456796646118
Validation loss: 2.162661413992605

Epoch: 5| Step: 10
Training loss: 2.3797383308410645
Validation loss: 2.0989600560998403

Epoch: 236| Step: 0
Training loss: 1.9486360549926758
Validation loss: 2.1359201477419947

Epoch: 5| Step: 1
Training loss: 1.5873048305511475
Validation loss: 2.144055304988738

Epoch: 5| Step: 2
Training loss: 1.6198856830596924
Validation loss: 2.119863534486422

Epoch: 5| Step: 3
Training loss: 2.7750868797302246
Validation loss: 2.1492736749751593

Epoch: 5| Step: 4
Training loss: 2.157665252685547
Validation loss: 2.12572144949308

Epoch: 5| Step: 5
Training loss: 1.6274185180664062
Validation loss: 2.095005004636703

Epoch: 5| Step: 6
Training loss: 2.2189338207244873
Validation loss: 2.0852854892771733

Epoch: 5| Step: 7
Training loss: 1.8632291555404663
Validation loss: 2.1567343896435154

Epoch: 5| Step: 8
Training loss: 2.0498034954071045
Validation loss: 2.124340416282736

Epoch: 5| Step: 9
Training loss: 2.7306759357452393
Validation loss: 2.116718117908765

Epoch: 5| Step: 10
Training loss: 1.9741854667663574
Validation loss: 2.0678668893793577

Epoch: 237| Step: 0
Training loss: 2.298435688018799
Validation loss: 2.067292897931991

Epoch: 5| Step: 1
Training loss: 1.507960557937622
Validation loss: 2.0823393034678634

Epoch: 5| Step: 2
Training loss: 2.2705912590026855
Validation loss: 2.1808384567178707

Epoch: 5| Step: 3
Training loss: 2.0797533988952637
Validation loss: 2.1493790252234346

Epoch: 5| Step: 4
Training loss: 2.0681121349334717
Validation loss: 2.122581852379666

Epoch: 5| Step: 5
Training loss: 1.9723193645477295
Validation loss: 2.115755317031696

Epoch: 5| Step: 6
Training loss: 1.9595426321029663
Validation loss: 2.109731601130578

Epoch: 5| Step: 7
Training loss: 2.4952378273010254
Validation loss: 2.1566583161712973

Epoch: 5| Step: 8
Training loss: 1.9884605407714844
Validation loss: 2.0756357767248668

Epoch: 5| Step: 9
Training loss: 2.0037002563476562
Validation loss: 2.1879941981325866

Epoch: 5| Step: 10
Training loss: 1.7173962593078613
Validation loss: 2.22583237771065

Epoch: 238| Step: 0
Training loss: 1.8026288747787476
Validation loss: 2.0823925669475267

Epoch: 5| Step: 1
Training loss: 1.9661540985107422
Validation loss: 2.1731208139850247

Epoch: 5| Step: 2
Training loss: 2.4339263439178467
Validation loss: 2.139816229061414

Epoch: 5| Step: 3
Training loss: 1.9928035736083984
Validation loss: 2.1452748608845535

Epoch: 5| Step: 4
Training loss: 1.7392566204071045
Validation loss: 2.157345517989128

Epoch: 5| Step: 5
Training loss: 1.963881254196167
Validation loss: 2.1894654022750033

Epoch: 5| Step: 6
Training loss: 1.674115538597107
Validation loss: 2.1862667927178006

Epoch: 5| Step: 7
Training loss: 2.0814263820648193
Validation loss: 2.203836956331807

Epoch: 5| Step: 8
Training loss: 2.272404193878174
Validation loss: 2.153259931072112

Epoch: 5| Step: 9
Training loss: 2.267876625061035
Validation loss: 2.185105244318644

Epoch: 5| Step: 10
Training loss: 2.4406979084014893
Validation loss: 2.1548775126857143

Epoch: 239| Step: 0
Training loss: 2.9359993934631348
Validation loss: 2.1700391820681992

Epoch: 5| Step: 1
Training loss: 2.1728057861328125
Validation loss: 2.137084076481481

Epoch: 5| Step: 2
Training loss: 1.7421047687530518
Validation loss: 2.1272333514305855

Epoch: 5| Step: 3
Training loss: 1.6927330493927002
Validation loss: 2.1535678973761936

Epoch: 5| Step: 4
Training loss: 2.103346347808838
Validation loss: 2.081321076680255

Epoch: 5| Step: 5
Training loss: 2.273489236831665
Validation loss: 2.1534344662902174

Epoch: 5| Step: 6
Training loss: 1.9667942523956299
Validation loss: 2.1623594273803053

Epoch: 5| Step: 7
Training loss: 1.944655179977417
Validation loss: 2.1247479787436863

Epoch: 5| Step: 8
Training loss: 1.839101791381836
Validation loss: 2.1055203765951176

Epoch: 5| Step: 9
Training loss: 1.935778021812439
Validation loss: 2.1786021750460387

Epoch: 5| Step: 10
Training loss: 2.1120660305023193
Validation loss: 2.132094430667098

Epoch: 240| Step: 0
Training loss: 1.549257516860962
Validation loss: 2.1327073779157413

Epoch: 5| Step: 1
Training loss: 1.7091213464736938
Validation loss: 2.137108906622856

Epoch: 5| Step: 2
Training loss: 1.665631890296936
Validation loss: 2.1145124153424333

Epoch: 5| Step: 3
Training loss: 2.5371954441070557
Validation loss: 2.125553569486064

Epoch: 5| Step: 4
Training loss: 1.8468059301376343
Validation loss: 2.201384746900169

Epoch: 5| Step: 5
Training loss: 2.2047712802886963
Validation loss: 2.141757707442007

Epoch: 5| Step: 6
Training loss: 2.114454984664917
Validation loss: 2.1561727626349336

Epoch: 5| Step: 7
Training loss: 2.0749287605285645
Validation loss: 2.1005714144758

Epoch: 5| Step: 8
Training loss: 2.049121379852295
Validation loss: 2.167286983100317

Epoch: 5| Step: 9
Training loss: 2.5033156871795654
Validation loss: 2.135555927471448

Epoch: 5| Step: 10
Training loss: 1.8429561853408813
Validation loss: 2.1036232261247534

Epoch: 241| Step: 0
Training loss: 2.014414072036743
Validation loss: 2.1194761824864212

Epoch: 5| Step: 1
Training loss: 2.2812485694885254
Validation loss: 2.078652192187566

Epoch: 5| Step: 2
Training loss: 2.1174449920654297
Validation loss: 2.11915260489269

Epoch: 5| Step: 3
Training loss: 2.0101585388183594
Validation loss: 2.108577125815935

Epoch: 5| Step: 4
Training loss: 2.060983180999756
Validation loss: 2.116989722815893

Epoch: 5| Step: 5
Training loss: 2.031266689300537
Validation loss: 2.137584319678686

Epoch: 5| Step: 6
Training loss: 2.2381720542907715
Validation loss: 2.1480942080097813

Epoch: 5| Step: 7
Training loss: 2.1563944816589355
Validation loss: 2.1249408311741327

Epoch: 5| Step: 8
Training loss: 2.165088653564453
Validation loss: 2.136968071742724

Epoch: 5| Step: 9
Training loss: 1.8152081966400146
Validation loss: 2.082062400797362

Epoch: 5| Step: 10
Training loss: 1.6873326301574707
Validation loss: 2.1463256497536936

Epoch: 242| Step: 0
Training loss: 1.893284797668457
Validation loss: 2.15152068291941

Epoch: 5| Step: 1
Training loss: 2.1833596229553223
Validation loss: 2.149216266088588

Epoch: 5| Step: 2
Training loss: 1.838732361793518
Validation loss: 2.1686255290944088

Epoch: 5| Step: 3
Training loss: 2.0757086277008057
Validation loss: 2.1303552299417476

Epoch: 5| Step: 4
Training loss: 1.4843273162841797
Validation loss: 2.113687415276804

Epoch: 5| Step: 5
Training loss: 2.0948753356933594
Validation loss: 2.137955729679395

Epoch: 5| Step: 6
Training loss: 1.9784786701202393
Validation loss: 2.199756976096861

Epoch: 5| Step: 7
Training loss: 1.9674466848373413
Validation loss: 2.210751541199223

Epoch: 5| Step: 8
Training loss: 2.1695215702056885
Validation loss: 2.1979645593191988

Epoch: 5| Step: 9
Training loss: 2.5763461589813232
Validation loss: 2.1522528356121433

Epoch: 5| Step: 10
Training loss: 2.3167226314544678
Validation loss: 2.1220267049727903

Epoch: 243| Step: 0
Training loss: 2.1746249198913574
Validation loss: 2.114398674298358

Epoch: 5| Step: 1
Training loss: 2.012873649597168
Validation loss: 2.1852729294889714

Epoch: 5| Step: 2
Training loss: 2.300577402114868
Validation loss: 2.1587461912503807

Epoch: 5| Step: 3
Training loss: 2.2605395317077637
Validation loss: 2.134658667349046

Epoch: 5| Step: 4
Training loss: 1.9500315189361572
Validation loss: 2.127971089014443

Epoch: 5| Step: 5
Training loss: 1.9418251514434814
Validation loss: 2.0781368171015093

Epoch: 5| Step: 6
Training loss: 1.3427708148956299
Validation loss: 2.0757747645019204

Epoch: 5| Step: 7
Training loss: 1.6699937582015991
Validation loss: 2.1312103553484847

Epoch: 5| Step: 8
Training loss: 2.2539467811584473
Validation loss: 2.111131655272617

Epoch: 5| Step: 9
Training loss: 2.0609030723571777
Validation loss: 2.091143492729433

Epoch: 5| Step: 10
Training loss: 2.785024642944336
Validation loss: 2.1457009366763535

Epoch: 244| Step: 0
Training loss: 2.4004950523376465
Validation loss: 2.054521925987736

Epoch: 5| Step: 1
Training loss: 1.534247875213623
Validation loss: 2.1093285955408567

Epoch: 5| Step: 2
Training loss: 1.8347294330596924
Validation loss: 2.1046396070911038

Epoch: 5| Step: 3
Training loss: 2.0489370822906494
Validation loss: 2.0995462927767026

Epoch: 5| Step: 4
Training loss: 1.722292184829712
Validation loss: 2.137567677805501

Epoch: 5| Step: 5
Training loss: 2.2437145709991455
Validation loss: 2.1527148933820826

Epoch: 5| Step: 6
Training loss: 1.9159672260284424
Validation loss: 2.0814520710258075

Epoch: 5| Step: 7
Training loss: 2.464372396469116
Validation loss: 2.1536714466669227

Epoch: 5| Step: 8
Training loss: 2.529323101043701
Validation loss: 2.148737862545957

Epoch: 5| Step: 9
Training loss: 1.594622254371643
Validation loss: 2.0906508186812043

Epoch: 5| Step: 10
Training loss: 2.0004703998565674
Validation loss: 2.1107104286070792

Epoch: 245| Step: 0
Training loss: 2.4404990673065186
Validation loss: 2.154591178381315

Epoch: 5| Step: 1
Training loss: 1.738938570022583
Validation loss: 2.1082321879684285

Epoch: 5| Step: 2
Training loss: 1.391330361366272
Validation loss: 2.105535089328725

Epoch: 5| Step: 3
Training loss: 2.934579610824585
Validation loss: 2.1623155173435005

Epoch: 5| Step: 4
Training loss: 1.7892087697982788
Validation loss: 2.1293448145671556

Epoch: 5| Step: 5
Training loss: 2.1732125282287598
Validation loss: 2.1036474025377663

Epoch: 5| Step: 6
Training loss: 1.7594817876815796
Validation loss: 2.1865638199672905

Epoch: 5| Step: 7
Training loss: 2.0598928928375244
Validation loss: 2.1038167527926865

Epoch: 5| Step: 8
Training loss: 2.1819045543670654
Validation loss: 2.1254592864744124

Epoch: 5| Step: 9
Training loss: 2.1210780143737793
Validation loss: 2.090942104657491

Epoch: 5| Step: 10
Training loss: 2.048649787902832
Validation loss: 2.1259390282374557

Epoch: 246| Step: 0
Training loss: 1.3199059963226318
Validation loss: 2.0667268537705943

Epoch: 5| Step: 1
Training loss: 2.0987164974212646
Validation loss: 2.0943023415021997

Epoch: 5| Step: 2
Training loss: 1.929919958114624
Validation loss: 2.1270255734843593

Epoch: 5| Step: 3
Training loss: 2.715991973876953
Validation loss: 2.1070591198500765

Epoch: 5| Step: 4
Training loss: 2.278296947479248
Validation loss: 2.06390961780343

Epoch: 5| Step: 5
Training loss: 2.3890433311462402
Validation loss: 2.121174843080582

Epoch: 5| Step: 6
Training loss: 1.927456259727478
Validation loss: 2.109789793209363

Epoch: 5| Step: 7
Training loss: 2.126000165939331
Validation loss: 2.1152481699502594

Epoch: 5| Step: 8
Training loss: 1.2881759405136108
Validation loss: 2.1177294472212433

Epoch: 5| Step: 9
Training loss: 2.7241897583007812
Validation loss: 2.0939363920560448

Epoch: 5| Step: 10
Training loss: 2.050663948059082
Validation loss: 2.1701921955231698

Epoch: 247| Step: 0
Training loss: 2.238774538040161
Validation loss: 2.2158981830843034

Epoch: 5| Step: 1
Training loss: 2.224963426589966
Validation loss: 2.1636748006266933

Epoch: 5| Step: 2
Training loss: 2.033201217651367
Validation loss: 2.108155469740591

Epoch: 5| Step: 3
Training loss: 1.8383067846298218
Validation loss: 2.0853747603713826

Epoch: 5| Step: 4
Training loss: 2.7987821102142334
Validation loss: 2.130337260102713

Epoch: 5| Step: 5
Training loss: 1.5635143518447876
Validation loss: 2.1048185081892115

Epoch: 5| Step: 6
Training loss: 1.375026822090149
Validation loss: 2.1153511026854157

Epoch: 5| Step: 7
Training loss: 1.5130345821380615
Validation loss: 2.1113250691403627

Epoch: 5| Step: 8
Training loss: 2.329113721847534
Validation loss: 2.082695048342469

Epoch: 5| Step: 9
Training loss: 2.2031960487365723
Validation loss: 2.065892880962741

Epoch: 5| Step: 10
Training loss: 2.244128704071045
Validation loss: 2.0727998530992897

Epoch: 248| Step: 0
Training loss: 2.347299098968506
Validation loss: 2.1423475844885713

Epoch: 5| Step: 1
Training loss: 2.853989362716675
Validation loss: 2.110637593012984

Epoch: 5| Step: 2
Training loss: 2.504744052886963
Validation loss: 2.155917021536058

Epoch: 5| Step: 3
Training loss: 1.6897728443145752
Validation loss: 2.10377921083922

Epoch: 5| Step: 4
Training loss: 1.5638070106506348
Validation loss: 2.1264360591929448

Epoch: 5| Step: 5
Training loss: 2.1132304668426514
Validation loss: 2.0943529439228836

Epoch: 5| Step: 6
Training loss: 1.2574580907821655
Validation loss: 2.1305865626181326

Epoch: 5| Step: 7
Training loss: 1.9548676013946533
Validation loss: 2.2025314838655534

Epoch: 5| Step: 8
Training loss: 1.6507043838500977
Validation loss: 2.1427319331835677

Epoch: 5| Step: 9
Training loss: 2.3414947986602783
Validation loss: 2.1076823639613327

Epoch: 5| Step: 10
Training loss: 1.963807463645935
Validation loss: 2.106774381411973

Epoch: 249| Step: 0
Training loss: 1.764559030532837
Validation loss: 2.1600670096694783

Epoch: 5| Step: 1
Training loss: 1.727749228477478
Validation loss: 2.1179076869000673

Epoch: 5| Step: 2
Training loss: 1.9183346033096313
Validation loss: 2.1429861924981557

Epoch: 5| Step: 3
Training loss: 2.471583843231201
Validation loss: 2.1299919313000095

Epoch: 5| Step: 4
Training loss: 1.6771389245986938
Validation loss: 2.127082763179656

Epoch: 5| Step: 5
Training loss: 1.8704646825790405
Validation loss: 2.103947424119519

Epoch: 5| Step: 6
Training loss: 1.4188995361328125
Validation loss: 2.1518760727297876

Epoch: 5| Step: 7
Training loss: 2.143813371658325
Validation loss: 2.0704163992276756

Epoch: 5| Step: 8
Training loss: 2.555079460144043
Validation loss: 2.1209733934812647

Epoch: 5| Step: 9
Training loss: 2.5722739696502686
Validation loss: 2.1119746444045857

Epoch: 5| Step: 10
Training loss: 1.7895585298538208
Validation loss: 2.16733734069332

Epoch: 250| Step: 0
Training loss: 1.2436034679412842
Validation loss: 2.1168555803196405

Epoch: 5| Step: 1
Training loss: 2.197584629058838
Validation loss: 2.1188831585709766

Epoch: 5| Step: 2
Training loss: 2.3697235584259033
Validation loss: 2.16586995381181

Epoch: 5| Step: 3
Training loss: 1.6460247039794922
Validation loss: 2.1414462417684574

Epoch: 5| Step: 4
Training loss: 1.8985084295272827
Validation loss: 2.1099298231063353

Epoch: 5| Step: 5
Training loss: 2.2004809379577637
Validation loss: 2.139372020639399

Epoch: 5| Step: 6
Training loss: 1.8269418478012085
Validation loss: 2.1416137115929716

Epoch: 5| Step: 7
Training loss: 2.1810975074768066
Validation loss: 2.136353604255184

Epoch: 5| Step: 8
Training loss: 1.9429008960723877
Validation loss: 2.0719022648308867

Epoch: 5| Step: 9
Training loss: 2.5046279430389404
Validation loss: 2.1341454008574128

Epoch: 5| Step: 10
Training loss: 2.5364291667938232
Validation loss: 2.138033022162735

Testing loss: 2.07643371158176
