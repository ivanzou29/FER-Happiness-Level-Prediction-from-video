Epoch: 1| Step: 0
Training loss: 7.820183753967285
Validation loss: 8.68748394135506

Epoch: 5| Step: 1
Training loss: 7.652782440185547
Validation loss: 8.679898262023926

Epoch: 5| Step: 2
Training loss: 8.901997566223145
Validation loss: 8.679007776321903

Epoch: 5| Step: 3
Training loss: 8.629953384399414
Validation loss: 8.671198947455293

Epoch: 5| Step: 4
Training loss: 8.448434829711914
Validation loss: 8.669417924778436

Epoch: 5| Step: 5
Training loss: 7.96973180770874
Validation loss: 8.662979125976562

Epoch: 5| Step: 6
Training loss: 9.42109489440918
Validation loss: 8.657444092535204

Epoch: 5| Step: 7
Training loss: 8.88917350769043
Validation loss: 8.65467987265638

Epoch: 5| Step: 8
Training loss: 7.966666221618652
Validation loss: 8.647356546053322

Epoch: 5| Step: 9
Training loss: 9.059895515441895
Validation loss: 8.643159825314758

Epoch: 5| Step: 10
Training loss: 8.260845184326172
Validation loss: 8.638680252977597

Epoch: 2| Step: 0
Training loss: 8.349803924560547
Validation loss: 8.636354128519693

Epoch: 5| Step: 1
Training loss: 9.224383354187012
Validation loss: 8.632209695795531

Epoch: 5| Step: 2
Training loss: 8.126459121704102
Validation loss: 8.625968676741405

Epoch: 5| Step: 3
Training loss: 8.26190185546875
Validation loss: 8.624150204402143

Epoch: 5| Step: 4
Training loss: 8.485503196716309
Validation loss: 8.61421073380337

Epoch: 5| Step: 5
Training loss: 9.60011100769043
Validation loss: 8.61098382293537

Epoch: 5| Step: 6
Training loss: 7.7862443923950195
Validation loss: 8.60841933629846

Epoch: 5| Step: 7
Training loss: 8.032423973083496
Validation loss: 8.60497304444672

Epoch: 5| Step: 8
Training loss: 8.953316688537598
Validation loss: 8.598287961816276

Epoch: 5| Step: 9
Training loss: 7.884315490722656
Validation loss: 8.595096998317267

Epoch: 5| Step: 10
Training loss: 7.660335063934326
Validation loss: 8.587547415046282

Epoch: 3| Step: 0
Training loss: 8.064729690551758
Validation loss: 8.587972764045961

Epoch: 5| Step: 1
Training loss: 8.525064468383789
Validation loss: 8.578840727447181

Epoch: 5| Step: 2
Training loss: 8.666269302368164
Validation loss: 8.57480916669292

Epoch: 5| Step: 3
Training loss: 8.358296394348145
Validation loss: 8.569087346394857

Epoch: 5| Step: 4
Training loss: 7.6219940185546875
Validation loss: 8.567061526800996

Epoch: 5| Step: 5
Training loss: 8.863194465637207
Validation loss: 8.56236211715206

Epoch: 5| Step: 6
Training loss: 8.816917419433594
Validation loss: 8.556082376869776

Epoch: 5| Step: 7
Training loss: 8.063166618347168
Validation loss: 8.552168605148152

Epoch: 5| Step: 8
Training loss: 8.298897743225098
Validation loss: 8.551825954068091

Epoch: 5| Step: 9
Training loss: 8.18637466430664
Validation loss: 8.542352050863286

Epoch: 5| Step: 10
Training loss: 8.45556926727295
Validation loss: 8.539869975018245

Epoch: 4| Step: 0
Training loss: 8.206511497497559
Validation loss: 8.535741303556708

Epoch: 5| Step: 1
Training loss: 8.642072677612305
Validation loss: 8.531048631155363

Epoch: 5| Step: 2
Training loss: 8.109231948852539
Validation loss: 8.527227196642148

Epoch: 5| Step: 3
Training loss: 7.191783905029297
Validation loss: 8.523419354551582

Epoch: 5| Step: 4
Training loss: 8.88548755645752
Validation loss: 8.515515665854178

Epoch: 5| Step: 5
Training loss: 9.916358947753906
Validation loss: 8.510868016109672

Epoch: 5| Step: 6
Training loss: 7.857696533203125
Validation loss: 8.509180253551852

Epoch: 5| Step: 7
Training loss: 7.322781562805176
Validation loss: 8.505594714995354

Epoch: 5| Step: 8
Training loss: 8.018010139465332
Validation loss: 8.497146924336752

Epoch: 5| Step: 9
Training loss: 8.529423713684082
Validation loss: 8.490935581986623

Epoch: 5| Step: 10
Training loss: 8.689800262451172
Validation loss: 8.491759577105123

Epoch: 5| Step: 0
Training loss: 8.556252479553223
Validation loss: 8.480392384272749

Epoch: 5| Step: 1
Training loss: 8.537324905395508
Validation loss: 8.47811665586246

Epoch: 5| Step: 2
Training loss: 9.368001937866211
Validation loss: 8.469837086175078

Epoch: 5| Step: 3
Training loss: 8.495147705078125
Validation loss: 8.467151385481639

Epoch: 5| Step: 4
Training loss: 8.682188034057617
Validation loss: 8.464279062004499

Epoch: 5| Step: 5
Training loss: 8.307869911193848
Validation loss: 8.460272009654712

Epoch: 5| Step: 6
Training loss: 8.277792930603027
Validation loss: 8.456372486647739

Epoch: 5| Step: 7
Training loss: 7.892370700836182
Validation loss: 8.449863387692359

Epoch: 5| Step: 8
Training loss: 7.406190395355225
Validation loss: 8.4437469667004

Epoch: 5| Step: 9
Training loss: 8.367281913757324
Validation loss: 8.440227785418111

Epoch: 5| Step: 10
Training loss: 6.570156574249268
Validation loss: 8.438554404884256

Epoch: 6| Step: 0
Training loss: 8.3316068649292
Validation loss: 8.429038273390903

Epoch: 5| Step: 1
Training loss: 8.790553092956543
Validation loss: 8.425066107062884

Epoch: 5| Step: 2
Training loss: 7.782268524169922
Validation loss: 8.41893083305769

Epoch: 5| Step: 3
Training loss: 8.42249584197998
Validation loss: 8.413164651522072

Epoch: 5| Step: 4
Training loss: 8.695727348327637
Validation loss: 8.41244851389239

Epoch: 5| Step: 5
Training loss: 7.957322597503662
Validation loss: 8.399304143844113

Epoch: 5| Step: 6
Training loss: 7.537466526031494
Validation loss: 8.39943802741266

Epoch: 5| Step: 7
Training loss: 8.927803993225098
Validation loss: 8.392299036825857

Epoch: 5| Step: 8
Training loss: 8.160473823547363
Validation loss: 8.386791593285016

Epoch: 5| Step: 9
Training loss: 7.99017333984375
Validation loss: 8.382478560170819

Epoch: 5| Step: 10
Training loss: 7.354282379150391
Validation loss: 8.37213852585003

Epoch: 7| Step: 0
Training loss: 8.255728721618652
Validation loss: 8.366315359710365

Epoch: 5| Step: 1
Training loss: 7.892630100250244
Validation loss: 8.364530953027868

Epoch: 5| Step: 2
Training loss: 7.623371124267578
Validation loss: 8.358904961616762

Epoch: 5| Step: 3
Training loss: 8.17802619934082
Validation loss: 8.352247135613554

Epoch: 5| Step: 4
Training loss: 7.716965675354004
Validation loss: 8.346668602317893

Epoch: 5| Step: 5
Training loss: 9.53164291381836
Validation loss: 8.342051721388295

Epoch: 5| Step: 6
Training loss: 8.439878463745117
Validation loss: 8.331679005776682

Epoch: 5| Step: 7
Training loss: 8.637629508972168
Validation loss: 8.325969008989231

Epoch: 5| Step: 8
Training loss: 7.439768314361572
Validation loss: 8.322329152014948

Epoch: 5| Step: 9
Training loss: 7.5106401443481445
Validation loss: 8.315364632555234

Epoch: 5| Step: 10
Training loss: 8.12319564819336
Validation loss: 8.309731134804347

Epoch: 8| Step: 0
Training loss: 7.637087345123291
Validation loss: 8.301937723672518

Epoch: 5| Step: 1
Training loss: 7.989396095275879
Validation loss: 8.297362850558374

Epoch: 5| Step: 2
Training loss: 8.43401050567627
Validation loss: 8.287174624781455

Epoch: 5| Step: 3
Training loss: 7.397757530212402
Validation loss: 8.281673344232702

Epoch: 5| Step: 4
Training loss: 8.044288635253906
Validation loss: 8.270996770551127

Epoch: 5| Step: 5
Training loss: 8.246770858764648
Validation loss: 8.26165383861911

Epoch: 5| Step: 6
Training loss: 8.577371597290039
Validation loss: 8.264180634611396

Epoch: 5| Step: 7
Training loss: 7.875202178955078
Validation loss: 8.252676215223087

Epoch: 5| Step: 8
Training loss: 8.187113761901855
Validation loss: 8.24784073778378

Epoch: 5| Step: 9
Training loss: 7.983555793762207
Validation loss: 8.237681722128263

Epoch: 5| Step: 10
Training loss: 8.16040325164795
Validation loss: 8.230940111221805

Epoch: 9| Step: 0
Training loss: 6.971644401550293
Validation loss: 8.223280604167652

Epoch: 5| Step: 1
Training loss: 8.268610000610352
Validation loss: 8.213515727750716

Epoch: 5| Step: 2
Training loss: 7.925636291503906
Validation loss: 8.20612314695953

Epoch: 5| Step: 3
Training loss: 8.838689804077148
Validation loss: 8.198831389027257

Epoch: 5| Step: 4
Training loss: 7.615363121032715
Validation loss: 8.192968901767525

Epoch: 5| Step: 5
Training loss: 7.795835971832275
Validation loss: 8.179181970575804

Epoch: 5| Step: 6
Training loss: 8.529162406921387
Validation loss: 8.17547998120708

Epoch: 5| Step: 7
Training loss: 8.450543403625488
Validation loss: 8.166575113932291

Epoch: 5| Step: 8
Training loss: 7.738790035247803
Validation loss: 8.158100179446642

Epoch: 5| Step: 9
Training loss: 7.317413330078125
Validation loss: 8.153122584025065

Epoch: 5| Step: 10
Training loss: 8.152610778808594
Validation loss: 8.142702584625573

Epoch: 10| Step: 0
Training loss: 8.002820014953613
Validation loss: 8.134413216703681

Epoch: 5| Step: 1
Training loss: 5.746872425079346
Validation loss: 8.122673788378316

Epoch: 5| Step: 2
Training loss: 8.888895034790039
Validation loss: 8.116963704427084

Epoch: 5| Step: 3
Training loss: 8.855620384216309
Validation loss: 8.106944740459483

Epoch: 5| Step: 4
Training loss: 7.991208076477051
Validation loss: 8.095178957908384

Epoch: 5| Step: 5
Training loss: 7.011177062988281
Validation loss: 8.090523371132472

Epoch: 5| Step: 6
Training loss: 8.182352066040039
Validation loss: 8.083705297080419

Epoch: 5| Step: 7
Training loss: 7.467680931091309
Validation loss: 8.079321661303121

Epoch: 5| Step: 8
Training loss: 8.230812072753906
Validation loss: 8.064618120911302

Epoch: 5| Step: 9
Training loss: 8.451780319213867
Validation loss: 8.057325906650995

Epoch: 5| Step: 10
Training loss: 7.668727874755859
Validation loss: 8.045951576643093

Epoch: 11| Step: 0
Training loss: 8.610153198242188
Validation loss: 8.038445764972318

Epoch: 5| Step: 1
Training loss: 7.3138298988342285
Validation loss: 8.027204349476804

Epoch: 5| Step: 2
Training loss: 7.636759281158447
Validation loss: 8.01332885988297

Epoch: 5| Step: 3
Training loss: 7.763247489929199
Validation loss: 8.005324968727686

Epoch: 5| Step: 4
Training loss: 7.757224082946777
Validation loss: 7.99885533958353

Epoch: 5| Step: 5
Training loss: 7.866686820983887
Validation loss: 7.9851919399794715

Epoch: 5| Step: 6
Training loss: 7.285855293273926
Validation loss: 7.983422545976536

Epoch: 5| Step: 7
Training loss: 8.62078857421875
Validation loss: 7.96593657360282

Epoch: 5| Step: 8
Training loss: 7.557975769042969
Validation loss: 7.959094611547327

Epoch: 5| Step: 9
Training loss: 7.3598432540893555
Validation loss: 7.950581673652895

Epoch: 5| Step: 10
Training loss: 7.572024345397949
Validation loss: 7.940371862021825

Epoch: 12| Step: 0
Training loss: 8.654855728149414
Validation loss: 7.927793302843647

Epoch: 5| Step: 1
Training loss: 7.109087944030762
Validation loss: 7.919905929155247

Epoch: 5| Step: 2
Training loss: 7.88653039932251
Validation loss: 7.908761670512538

Epoch: 5| Step: 3
Training loss: 7.172950744628906
Validation loss: 7.895684549885411

Epoch: 5| Step: 4
Training loss: 8.307256698608398
Validation loss: 7.884921279004825

Epoch: 5| Step: 5
Training loss: 8.37431526184082
Validation loss: 7.876333821204401

Epoch: 5| Step: 6
Training loss: 6.746950626373291
Validation loss: 7.8621702450577935

Epoch: 5| Step: 7
Training loss: 7.710558891296387
Validation loss: 7.849603950336415

Epoch: 5| Step: 8
Training loss: 7.392172813415527
Validation loss: 7.844707447995422

Epoch: 5| Step: 9
Training loss: 6.8876752853393555
Validation loss: 7.82717768351237

Epoch: 5| Step: 10
Training loss: 7.866844654083252
Validation loss: 7.824093464882143

Epoch: 13| Step: 0
Training loss: 6.931378364562988
Validation loss: 7.81081804665186

Epoch: 5| Step: 1
Training loss: 6.876195430755615
Validation loss: 7.796733322963919

Epoch: 5| Step: 2
Training loss: 6.665892601013184
Validation loss: 7.785031041791362

Epoch: 5| Step: 3
Training loss: 8.040056228637695
Validation loss: 7.767737019446589

Epoch: 5| Step: 4
Training loss: 7.511100769042969
Validation loss: 7.7622503157584894

Epoch: 5| Step: 5
Training loss: 7.702430725097656
Validation loss: 7.747277634118193

Epoch: 5| Step: 6
Training loss: 8.084280014038086
Validation loss: 7.731488884136241

Epoch: 5| Step: 7
Training loss: 7.095115661621094
Validation loss: 7.7229385119612495

Epoch: 5| Step: 8
Training loss: 7.4587202072143555
Validation loss: 7.7145226591376845

Epoch: 5| Step: 9
Training loss: 8.585051536560059
Validation loss: 7.699926653215962

Epoch: 5| Step: 10
Training loss: 7.723170757293701
Validation loss: 7.690027965012417

Epoch: 14| Step: 0
Training loss: 6.932614803314209
Validation loss: 7.6785146959366335

Epoch: 5| Step: 1
Training loss: 8.33605670928955
Validation loss: 7.664123740247501

Epoch: 5| Step: 2
Training loss: 6.7115044593811035
Validation loss: 7.658263401318622

Epoch: 5| Step: 3
Training loss: 6.44610595703125
Validation loss: 7.632300935765748

Epoch: 5| Step: 4
Training loss: 8.154213905334473
Validation loss: 7.620907998854114

Epoch: 5| Step: 5
Training loss: 7.959031581878662
Validation loss: 7.600279115861462

Epoch: 5| Step: 6
Training loss: 7.260098457336426
Validation loss: 7.597438412327921

Epoch: 5| Step: 7
Training loss: 7.140699863433838
Validation loss: 7.591742515563965

Epoch: 5| Step: 8
Training loss: 6.2069993019104
Validation loss: 7.577243312712638

Epoch: 5| Step: 9
Training loss: 8.188619613647461
Validation loss: 7.567652635676886

Epoch: 5| Step: 10
Training loss: 7.779963970184326
Validation loss: 7.543470372435867

Epoch: 15| Step: 0
Training loss: 7.2737884521484375
Validation loss: 7.533580846683954

Epoch: 5| Step: 1
Training loss: 6.062291145324707
Validation loss: 7.512832733892625

Epoch: 5| Step: 2
Training loss: 6.948359489440918
Validation loss: 7.506031908014769

Epoch: 5| Step: 3
Training loss: 7.011284828186035
Validation loss: 7.489751764523086

Epoch: 5| Step: 4
Training loss: 6.633993625640869
Validation loss: 7.479386642415037

Epoch: 5| Step: 5
Training loss: 6.52658224105835
Validation loss: 7.451798603098879

Epoch: 5| Step: 6
Training loss: 7.5843610763549805
Validation loss: 7.441824287496587

Epoch: 5| Step: 7
Training loss: 7.357369899749756
Validation loss: 7.42722527698804

Epoch: 5| Step: 8
Training loss: 8.528512954711914
Validation loss: 7.4081398030763035

Epoch: 5| Step: 9
Training loss: 8.041175842285156
Validation loss: 7.392028793211906

Epoch: 5| Step: 10
Training loss: 7.3968095779418945
Validation loss: 7.382129520498296

Epoch: 16| Step: 0
Training loss: 7.757632255554199
Validation loss: 7.370692550495106

Epoch: 5| Step: 1
Training loss: 7.035878658294678
Validation loss: 7.354748438763362

Epoch: 5| Step: 2
Training loss: 6.862471103668213
Validation loss: 7.334809118701566

Epoch: 5| Step: 3
Training loss: 7.976607322692871
Validation loss: 7.320618003927251

Epoch: 5| Step: 4
Training loss: 6.34802770614624
Validation loss: 7.309811945884459

Epoch: 5| Step: 5
Training loss: 7.2209601402282715
Validation loss: 7.291440917599585

Epoch: 5| Step: 6
Training loss: 7.61370325088501
Validation loss: 7.277667742903515

Epoch: 5| Step: 7
Training loss: 7.0106916427612305
Validation loss: 7.258782853362381

Epoch: 5| Step: 8
Training loss: 5.3512468338012695
Validation loss: 7.232013702392578

Epoch: 5| Step: 9
Training loss: 6.622557163238525
Validation loss: 7.228873529741841

Epoch: 5| Step: 10
Training loss: 7.707772731781006
Validation loss: 7.200491459138932

Epoch: 17| Step: 0
Training loss: 6.686395168304443
Validation loss: 7.193181930049773

Epoch: 5| Step: 1
Training loss: 8.119275093078613
Validation loss: 7.166918175194853

Epoch: 5| Step: 2
Training loss: 6.4292893409729
Validation loss: 7.15225003868021

Epoch: 5| Step: 3
Training loss: 6.4340009689331055
Validation loss: 7.1414709706460275

Epoch: 5| Step: 4
Training loss: 6.4603729248046875
Validation loss: 7.119322474284838

Epoch: 5| Step: 5
Training loss: 6.555168151855469
Validation loss: 7.104591877229752

Epoch: 5| Step: 6
Training loss: 7.599726676940918
Validation loss: 7.087513359644079

Epoch: 5| Step: 7
Training loss: 7.1445488929748535
Validation loss: 7.06773470294091

Epoch: 5| Step: 8
Training loss: 6.467321872711182
Validation loss: 7.055758932585357

Epoch: 5| Step: 9
Training loss: 7.616425514221191
Validation loss: 7.026195849141767

Epoch: 5| Step: 10
Training loss: 5.743671894073486
Validation loss: 7.00797297364922

Epoch: 18| Step: 0
Training loss: 6.888733863830566
Validation loss: 7.002006238506686

Epoch: 5| Step: 1
Training loss: 7.613700866699219
Validation loss: 6.982191075560867

Epoch: 5| Step: 2
Training loss: 6.500391483306885
Validation loss: 6.961520307807512

Epoch: 5| Step: 3
Training loss: 7.367927551269531
Validation loss: 6.930065995903425

Epoch: 5| Step: 4
Training loss: 6.250271320343018
Validation loss: 6.926424503326416

Epoch: 5| Step: 5
Training loss: 6.54019832611084
Validation loss: 6.90063642173685

Epoch: 5| Step: 6
Training loss: 6.239307403564453
Validation loss: 6.872512473854967

Epoch: 5| Step: 7
Training loss: 6.825356483459473
Validation loss: 6.850461072819208

Epoch: 5| Step: 8
Training loss: 4.987797737121582
Validation loss: 6.840315229149275

Epoch: 5| Step: 9
Training loss: 6.903665065765381
Validation loss: 6.8054124514261884

Epoch: 5| Step: 10
Training loss: 7.05709981918335
Validation loss: 6.794381746681788

Epoch: 19| Step: 0
Training loss: 6.535914421081543
Validation loss: 6.7776629386409635

Epoch: 5| Step: 1
Training loss: 5.907685279846191
Validation loss: 6.7616006943487355

Epoch: 5| Step: 2
Training loss: 7.271615505218506
Validation loss: 6.746667482519663

Epoch: 5| Step: 3
Training loss: 7.334100246429443
Validation loss: 6.7066478113974295

Epoch: 5| Step: 4
Training loss: 6.532449245452881
Validation loss: 6.696133413622456

Epoch: 5| Step: 5
Training loss: 6.763085842132568
Validation loss: 6.66545432613742

Epoch: 5| Step: 6
Training loss: 5.608501434326172
Validation loss: 6.644169766415832

Epoch: 5| Step: 7
Training loss: 6.502606391906738
Validation loss: 6.6224566839074575

Epoch: 5| Step: 8
Training loss: 5.280914306640625
Validation loss: 6.606968551553706

Epoch: 5| Step: 9
Training loss: 6.405940055847168
Validation loss: 6.574801675734982

Epoch: 5| Step: 10
Training loss: 6.400661468505859
Validation loss: 6.5587158305670625

Epoch: 20| Step: 0
Training loss: 5.513209342956543
Validation loss: 6.542825601434195

Epoch: 5| Step: 1
Training loss: 5.635901927947998
Validation loss: 6.507119568445349

Epoch: 5| Step: 2
Training loss: 6.322726249694824
Validation loss: 6.493047134850615

Epoch: 5| Step: 3
Training loss: 5.760930061340332
Validation loss: 6.470440987617739

Epoch: 5| Step: 4
Training loss: 6.134548187255859
Validation loss: 6.432690230748987

Epoch: 5| Step: 5
Training loss: 6.457518100738525
Validation loss: 6.4135715166727705

Epoch: 5| Step: 6
Training loss: 6.475789546966553
Validation loss: 6.390052826173844

Epoch: 5| Step: 7
Training loss: 6.659510612487793
Validation loss: 6.3681465066889285

Epoch: 5| Step: 8
Training loss: 6.053385257720947
Validation loss: 6.323421160380046

Epoch: 5| Step: 9
Training loss: 5.603424072265625
Validation loss: 6.313773047539495

Epoch: 5| Step: 10
Training loss: 7.113807678222656
Validation loss: 6.298150477870818

Epoch: 21| Step: 0
Training loss: 5.611991882324219
Validation loss: 6.262282638139622

Epoch: 5| Step: 1
Training loss: 6.090185642242432
Validation loss: 6.224166403534592

Epoch: 5| Step: 2
Training loss: 5.808411598205566
Validation loss: 6.200162651718304

Epoch: 5| Step: 3
Training loss: 5.982481956481934
Validation loss: 6.178675384931667

Epoch: 5| Step: 4
Training loss: 4.956873893737793
Validation loss: 6.148434541558706

Epoch: 5| Step: 5
Training loss: 5.746419429779053
Validation loss: 6.107964623358942

Epoch: 5| Step: 6
Training loss: 7.2449631690979
Validation loss: 6.095670064290364

Epoch: 5| Step: 7
Training loss: 6.093777656555176
Validation loss: 6.069356641461773

Epoch: 5| Step: 8
Training loss: 5.162257194519043
Validation loss: 6.041283110136627

Epoch: 5| Step: 9
Training loss: 6.059834003448486
Validation loss: 5.998999775096935

Epoch: 5| Step: 10
Training loss: 5.403456211090088
Validation loss: 5.976110442992179

Epoch: 22| Step: 0
Training loss: 6.016477108001709
Validation loss: 5.946667614803519

Epoch: 5| Step: 1
Training loss: 6.045639991760254
Validation loss: 5.925987023179249

Epoch: 5| Step: 2
Training loss: 6.055215358734131
Validation loss: 5.864176652764761

Epoch: 5| Step: 3
Training loss: 4.944443702697754
Validation loss: 5.854149444128877

Epoch: 5| Step: 4
Training loss: 5.872422695159912
Validation loss: 5.8261164747258665

Epoch: 5| Step: 5
Training loss: 5.781178951263428
Validation loss: 5.804913269576206

Epoch: 5| Step: 6
Training loss: 5.195221900939941
Validation loss: 5.748609112155053

Epoch: 5| Step: 7
Training loss: 5.200638771057129
Validation loss: 5.722578002560523

Epoch: 5| Step: 8
Training loss: 5.435944557189941
Validation loss: 5.701481280788299

Epoch: 5| Step: 9
Training loss: 3.8508124351501465
Validation loss: 5.644815383418914

Epoch: 5| Step: 10
Training loss: 6.261814594268799
Validation loss: 5.620584877588415

Epoch: 23| Step: 0
Training loss: 5.782592296600342
Validation loss: 5.570553661674581

Epoch: 5| Step: 1
Training loss: 4.633824348449707
Validation loss: 5.561170034511115

Epoch: 5| Step: 2
Training loss: 4.38760232925415
Validation loss: 5.51098459510393

Epoch: 5| Step: 3
Training loss: 5.7606964111328125
Validation loss: 5.453438743468253

Epoch: 5| Step: 4
Training loss: 5.808950901031494
Validation loss: 5.450400352478027

Epoch: 5| Step: 5
Training loss: 5.438933849334717
Validation loss: 5.402393720483267

Epoch: 5| Step: 6
Training loss: 4.549715995788574
Validation loss: 5.369277410609747

Epoch: 5| Step: 7
Training loss: 4.1913743019104
Validation loss: 5.294944219691779

Epoch: 5| Step: 8
Training loss: 4.7394843101501465
Validation loss: 5.288823266183177

Epoch: 5| Step: 9
Training loss: 5.459630012512207
Validation loss: 5.244049385029783

Epoch: 5| Step: 10
Training loss: 5.550539016723633
Validation loss: 5.221733134279969

Epoch: 24| Step: 0
Training loss: 4.001151084899902
Validation loss: 5.183958940608527

Epoch: 5| Step: 1
Training loss: 5.565589904785156
Validation loss: 5.108696927306473

Epoch: 5| Step: 2
Training loss: 5.1252241134643555
Validation loss: 5.068658849244477

Epoch: 5| Step: 3
Training loss: 3.8984007835388184
Validation loss: 5.054717658668436

Epoch: 5| Step: 4
Training loss: 4.055001258850098
Validation loss: 5.006038686280609

Epoch: 5| Step: 5
Training loss: 5.618808269500732
Validation loss: 4.956968707423056

Epoch: 5| Step: 6
Training loss: 5.800399303436279
Validation loss: 4.907001813252767

Epoch: 5| Step: 7
Training loss: 3.5669760704040527
Validation loss: 4.872127855977705

Epoch: 5| Step: 8
Training loss: 4.729287147521973
Validation loss: 4.825055568448959

Epoch: 5| Step: 9
Training loss: 4.422248363494873
Validation loss: 4.78278797929005

Epoch: 5| Step: 10
Training loss: 4.435057640075684
Validation loss: 4.718840681096559

Epoch: 25| Step: 0
Training loss: 4.9566216468811035
Validation loss: 4.683219366176154

Epoch: 5| Step: 1
Training loss: 4.387896537780762
Validation loss: 4.642865893661335

Epoch: 5| Step: 2
Training loss: 3.5030598640441895
Validation loss: 4.600409087314401

Epoch: 5| Step: 3
Training loss: 4.774509429931641
Validation loss: 4.5499415551462485

Epoch: 5| Step: 4
Training loss: 4.526199817657471
Validation loss: 4.520396012131886

Epoch: 5| Step: 5
Training loss: 3.7531356811523438
Validation loss: 4.457838004635226

Epoch: 5| Step: 6
Training loss: 3.661757230758667
Validation loss: 4.439959749098747

Epoch: 5| Step: 7
Training loss: 4.516866683959961
Validation loss: 4.3908896497500844

Epoch: 5| Step: 8
Training loss: 4.443271636962891
Validation loss: 4.339777064579789

Epoch: 5| Step: 9
Training loss: 3.592536449432373
Validation loss: 4.281871057325794

Epoch: 5| Step: 10
Training loss: 4.164952278137207
Validation loss: 4.238772289727324

Epoch: 26| Step: 0
Training loss: 3.9176228046417236
Validation loss: 4.211449756417223

Epoch: 5| Step: 1
Training loss: 4.275713920593262
Validation loss: 4.151600289088424

Epoch: 5| Step: 2
Training loss: 4.105055809020996
Validation loss: 4.091976686190534

Epoch: 5| Step: 3
Training loss: 3.7860496044158936
Validation loss: 4.080137370735087

Epoch: 5| Step: 4
Training loss: 4.086959362030029
Validation loss: 4.022831214371548

Epoch: 5| Step: 5
Training loss: 2.6377265453338623
Validation loss: 3.9685397404496388

Epoch: 5| Step: 6
Training loss: 3.3101139068603516
Validation loss: 3.9443119008054017

Epoch: 5| Step: 7
Training loss: 3.8184807300567627
Validation loss: 3.9122864405314126

Epoch: 5| Step: 8
Training loss: 3.9713070392608643
Validation loss: 3.87051914071524

Epoch: 5| Step: 9
Training loss: 3.9767143726348877
Validation loss: 3.8185435033613637

Epoch: 5| Step: 10
Training loss: 3.402721643447876
Validation loss: 3.7487565548189226

Epoch: 27| Step: 0
Training loss: 4.514208793640137
Validation loss: 3.7443508076411423

Epoch: 5| Step: 1
Training loss: 3.087063789367676
Validation loss: 3.671033828489242

Epoch: 5| Step: 2
Training loss: 3.6784210205078125
Validation loss: 3.6601067102083595

Epoch: 5| Step: 3
Training loss: 2.69801664352417
Validation loss: 3.5861929411529214

Epoch: 5| Step: 4
Training loss: 2.815561056137085
Validation loss: 3.5613224557650986

Epoch: 5| Step: 5
Training loss: 3.1485471725463867
Validation loss: 3.5644911719906713

Epoch: 5| Step: 6
Training loss: 3.4116432666778564
Validation loss: 3.4827012272291284

Epoch: 5| Step: 7
Training loss: 3.2180418968200684
Validation loss: 3.4616013931971725

Epoch: 5| Step: 8
Training loss: 3.7673563957214355
Validation loss: 3.4211488077717442

Epoch: 5| Step: 9
Training loss: 2.8737361431121826
Validation loss: 3.361224905137093

Epoch: 5| Step: 10
Training loss: 4.062672138214111
Validation loss: 3.3097915546868437

Epoch: 28| Step: 0
Training loss: 3.0942680835723877
Validation loss: 3.3209406483557915

Epoch: 5| Step: 1
Training loss: 4.104977607727051
Validation loss: 3.261180208575341

Epoch: 5| Step: 2
Training loss: 3.049049139022827
Validation loss: 3.2340913357273227

Epoch: 5| Step: 3
Training loss: 3.6094486713409424
Validation loss: 3.167359841767178

Epoch: 5| Step: 4
Training loss: 2.9136815071105957
Validation loss: 3.169572112380817

Epoch: 5| Step: 5
Training loss: 2.969432830810547
Validation loss: 3.1270271347415064

Epoch: 5| Step: 6
Training loss: 3.3160133361816406
Validation loss: 3.108764740728563

Epoch: 5| Step: 7
Training loss: 3.4368793964385986
Validation loss: 3.0480258721177296

Epoch: 5| Step: 8
Training loss: 2.6844921112060547
Validation loss: 3.049499509155109

Epoch: 5| Step: 9
Training loss: 2.5750842094421387
Validation loss: 3.017412765051729

Epoch: 5| Step: 10
Training loss: 1.9882179498672485
Validation loss: 2.9905683891747588

Epoch: 29| Step: 0
Training loss: 3.135288715362549
Validation loss: 3.027039166419737

Epoch: 5| Step: 1
Training loss: 2.148953676223755
Validation loss: 2.9306123205410537

Epoch: 5| Step: 2
Training loss: 2.84242582321167
Validation loss: 2.929136060899304

Epoch: 5| Step: 3
Training loss: 2.351897716522217
Validation loss: 2.9062971607331307

Epoch: 5| Step: 4
Training loss: 3.2571873664855957
Validation loss: 2.8605945725594797

Epoch: 5| Step: 5
Training loss: 2.981203556060791
Validation loss: 2.8497073317086823

Epoch: 5| Step: 6
Training loss: 2.765101909637451
Validation loss: 2.83773628357918

Epoch: 5| Step: 7
Training loss: 3.227715253829956
Validation loss: 2.83221326592148

Epoch: 5| Step: 8
Training loss: 3.246906280517578
Validation loss: 2.8016356268236713

Epoch: 5| Step: 9
Training loss: 3.0268263816833496
Validation loss: 2.7428836822509766

Epoch: 5| Step: 10
Training loss: 2.4669198989868164
Validation loss: 2.724503727369411

Epoch: 30| Step: 0
Training loss: 2.5927977561950684
Validation loss: 2.681279813089678

Epoch: 5| Step: 1
Training loss: 2.9006848335266113
Validation loss: 2.676661737503544

Epoch: 5| Step: 2
Training loss: 2.635409116744995
Validation loss: 2.7456064865153325

Epoch: 5| Step: 3
Training loss: 2.4609482288360596
Validation loss: 2.6495491432887253

Epoch: 5| Step: 4
Training loss: 2.3988609313964844
Validation loss: 2.670072655523977

Epoch: 5| Step: 5
Training loss: 2.4619388580322266
Validation loss: 2.6635167393633115

Epoch: 5| Step: 6
Training loss: 3.0204660892486572
Validation loss: 2.634088641853743

Epoch: 5| Step: 7
Training loss: 3.5621001720428467
Validation loss: 2.662537177403768

Epoch: 5| Step: 8
Training loss: 2.8438518047332764
Validation loss: 2.5791251197937997

Epoch: 5| Step: 9
Training loss: 1.915839433670044
Validation loss: 2.579456083236202

Epoch: 5| Step: 10
Training loss: 2.9758942127227783
Validation loss: 2.5334531825075866

Epoch: 31| Step: 0
Training loss: 3.11555814743042
Validation loss: 2.5923118078580467

Epoch: 5| Step: 1
Training loss: 2.033759593963623
Validation loss: 2.555597948771651

Epoch: 5| Step: 2
Training loss: 2.3315577507019043
Validation loss: 2.524138032749135

Epoch: 5| Step: 3
Training loss: 3.0660853385925293
Validation loss: 2.5195185522879324

Epoch: 5| Step: 4
Training loss: 1.9905064105987549
Validation loss: 2.5240181107674875

Epoch: 5| Step: 5
Training loss: 3.644247531890869
Validation loss: 2.47475585117135

Epoch: 5| Step: 6
Training loss: 2.3353967666625977
Validation loss: 2.4539642782621485

Epoch: 5| Step: 7
Training loss: 2.2331581115722656
Validation loss: 2.4575216436898835

Epoch: 5| Step: 8
Training loss: 2.2943477630615234
Validation loss: 2.4387652732992686

Epoch: 5| Step: 9
Training loss: 2.240079402923584
Validation loss: 2.4725242404527563

Epoch: 5| Step: 10
Training loss: 3.5065197944641113
Validation loss: 2.420086811947566

Epoch: 32| Step: 0
Training loss: 2.900362253189087
Validation loss: 2.429966584328682

Epoch: 5| Step: 1
Training loss: 2.9910261631011963
Validation loss: 2.4127892242964877

Epoch: 5| Step: 2
Training loss: 2.927976369857788
Validation loss: 2.395151433124337

Epoch: 5| Step: 3
Training loss: 2.4287445545196533
Validation loss: 2.362096760862617

Epoch: 5| Step: 4
Training loss: 3.0892443656921387
Validation loss: 2.3765657204453663

Epoch: 5| Step: 5
Training loss: 2.57285737991333
Validation loss: 2.3839439922763455

Epoch: 5| Step: 6
Training loss: 2.392721176147461
Validation loss: 2.3742441233768257

Epoch: 5| Step: 7
Training loss: 2.656221389770508
Validation loss: 2.3954212332284577

Epoch: 5| Step: 8
Training loss: 2.155036687850952
Validation loss: 2.363527915811026

Epoch: 5| Step: 9
Training loss: 1.8117033243179321
Validation loss: 2.3420874021386586

Epoch: 5| Step: 10
Training loss: 2.342705726623535
Validation loss: 2.3744558288205053

Epoch: 33| Step: 0
Training loss: 2.256484270095825
Validation loss: 2.388470195954846

Epoch: 5| Step: 1
Training loss: 1.9401315450668335
Validation loss: 2.3837443090254262

Epoch: 5| Step: 2
Training loss: 2.3989157676696777
Validation loss: 2.3598591319976316

Epoch: 5| Step: 3
Training loss: 2.698011875152588
Validation loss: 2.341810243104094

Epoch: 5| Step: 4
Training loss: 2.3172130584716797
Validation loss: 2.354025792050105

Epoch: 5| Step: 5
Training loss: 2.7515058517456055
Validation loss: 2.370456367410639

Epoch: 5| Step: 6
Training loss: 2.757631540298462
Validation loss: 2.3343718359547276

Epoch: 5| Step: 7
Training loss: 2.3847098350524902
Validation loss: 2.368821187685895

Epoch: 5| Step: 8
Training loss: 3.0359599590301514
Validation loss: 2.3436013601159535

Epoch: 5| Step: 9
Training loss: 2.8516147136688232
Validation loss: 2.3676749557577152

Epoch: 5| Step: 10
Training loss: 2.3382065296173096
Validation loss: 2.328222781099299

Epoch: 34| Step: 0
Training loss: 2.2614548206329346
Validation loss: 2.352875819770239

Epoch: 5| Step: 1
Training loss: 3.05674409866333
Validation loss: 2.3126326863483717

Epoch: 5| Step: 2
Training loss: 2.5608971118927
Validation loss: 2.370363240600914

Epoch: 5| Step: 3
Training loss: 2.2944397926330566
Validation loss: 2.3151556702070337

Epoch: 5| Step: 4
Training loss: 2.0362515449523926
Validation loss: 2.336743043315026

Epoch: 5| Step: 5
Training loss: 2.742525577545166
Validation loss: 2.337753003643405

Epoch: 5| Step: 6
Training loss: 2.408858299255371
Validation loss: 2.337953849505353

Epoch: 5| Step: 7
Training loss: 1.758723258972168
Validation loss: 2.353568048887355

Epoch: 5| Step: 8
Training loss: 3.138335704803467
Validation loss: 2.3402950532974733

Epoch: 5| Step: 9
Training loss: 3.7238292694091797
Validation loss: 2.3099926440946517

Epoch: 5| Step: 10
Training loss: 1.9496383666992188
Validation loss: 2.33704052945619

Epoch: 35| Step: 0
Training loss: 1.980255365371704
Validation loss: 2.390216783810687

Epoch: 5| Step: 1
Training loss: 2.771878719329834
Validation loss: 2.3662617975665676

Epoch: 5| Step: 2
Training loss: 2.810863494873047
Validation loss: 2.34770066507401

Epoch: 5| Step: 3
Training loss: 1.8910675048828125
Validation loss: 2.306261247204196

Epoch: 5| Step: 4
Training loss: 2.3606104850769043
Validation loss: 2.328392526154877

Epoch: 5| Step: 5
Training loss: 1.9712473154067993
Validation loss: 2.314164356518817

Epoch: 5| Step: 6
Training loss: 2.8686375617980957
Validation loss: 2.349035079761218

Epoch: 5| Step: 7
Training loss: 2.7912821769714355
Validation loss: 2.352085216071016

Epoch: 5| Step: 8
Training loss: 2.574894428253174
Validation loss: 2.3374364170976865

Epoch: 5| Step: 9
Training loss: 2.7453324794769287
Validation loss: 2.2991857528686523

Epoch: 5| Step: 10
Training loss: 2.8893489837646484
Validation loss: 2.3717070112946215

Epoch: 36| Step: 0
Training loss: 2.612332820892334
Validation loss: 2.3201675953403598

Epoch: 5| Step: 1
Training loss: 2.1117939949035645
Validation loss: 2.32881873525599

Epoch: 5| Step: 2
Training loss: 2.8038487434387207
Validation loss: 2.3292508150941584

Epoch: 5| Step: 3
Training loss: 1.7858644723892212
Validation loss: 2.3217680710618214

Epoch: 5| Step: 4
Training loss: 2.3807764053344727
Validation loss: 2.350987667678505

Epoch: 5| Step: 5
Training loss: 2.748129367828369
Validation loss: 2.2818775382093204

Epoch: 5| Step: 6
Training loss: 2.655106782913208
Validation loss: 2.3499113949396278

Epoch: 5| Step: 7
Training loss: 2.8746001720428467
Validation loss: 2.3538909112253497

Epoch: 5| Step: 8
Training loss: 2.125342845916748
Validation loss: 2.320705388181953

Epoch: 5| Step: 9
Training loss: 2.8197929859161377
Validation loss: 2.3008387011866414

Epoch: 5| Step: 10
Training loss: 2.5743331909179688
Validation loss: 2.377597435828178

Epoch: 37| Step: 0
Training loss: 1.9556812047958374
Validation loss: 2.3393038959913355

Epoch: 5| Step: 1
Training loss: 2.953767776489258
Validation loss: 2.329047523519044

Epoch: 5| Step: 2
Training loss: 1.8757070302963257
Validation loss: 2.327873312016969

Epoch: 5| Step: 3
Training loss: 2.138211488723755
Validation loss: 2.3462910575251423

Epoch: 5| Step: 4
Training loss: 3.2222678661346436
Validation loss: 2.33773478897669

Epoch: 5| Step: 5
Training loss: 2.227045774459839
Validation loss: 2.3212504309992634

Epoch: 5| Step: 6
Training loss: 2.4432928562164307
Validation loss: 2.3325065515374623

Epoch: 5| Step: 7
Training loss: 3.1780662536621094
Validation loss: 2.3224230299713793

Epoch: 5| Step: 8
Training loss: 2.1391139030456543
Validation loss: 2.327413102631928

Epoch: 5| Step: 9
Training loss: 2.9966511726379395
Validation loss: 2.352960830093712

Epoch: 5| Step: 10
Training loss: 2.002023935317993
Validation loss: 2.2582789672318326

Epoch: 38| Step: 0
Training loss: 2.035224676132202
Validation loss: 2.3428667591464136

Epoch: 5| Step: 1
Training loss: 1.950778603553772
Validation loss: 2.294306080828431

Epoch: 5| Step: 2
Training loss: 2.617694139480591
Validation loss: 2.2797851383045153

Epoch: 5| Step: 3
Training loss: 3.419191837310791
Validation loss: 2.281548148842268

Epoch: 5| Step: 4
Training loss: 1.827573537826538
Validation loss: 2.268448314359111

Epoch: 5| Step: 5
Training loss: 2.940333366394043
Validation loss: 2.320778772395144

Epoch: 5| Step: 6
Training loss: 2.3685338497161865
Validation loss: 2.3347135871969242

Epoch: 5| Step: 7
Training loss: 3.212653398513794
Validation loss: 2.3182154496510825

Epoch: 5| Step: 8
Training loss: 1.8586204051971436
Validation loss: 2.27293994093454

Epoch: 5| Step: 9
Training loss: 2.2035059928894043
Validation loss: 2.373058149891515

Epoch: 5| Step: 10
Training loss: 2.515589714050293
Validation loss: 2.2942355448199856

Epoch: 39| Step: 0
Training loss: 2.0051729679107666
Validation loss: 2.253068895750148

Epoch: 5| Step: 1
Training loss: 3.0563108921051025
Validation loss: 2.2763045808320403

Epoch: 5| Step: 2
Training loss: 2.2868309020996094
Validation loss: 2.276343430242231

Epoch: 5| Step: 3
Training loss: 3.0030884742736816
Validation loss: 2.322204439870773

Epoch: 5| Step: 4
Training loss: 2.8149211406707764
Validation loss: 2.289268103978967

Epoch: 5| Step: 5
Training loss: 2.659162998199463
Validation loss: 2.3197972543777956

Epoch: 5| Step: 6
Training loss: 2.790280818939209
Validation loss: 2.337720000615684

Epoch: 5| Step: 7
Training loss: 2.4338622093200684
Validation loss: 2.321120059618386

Epoch: 5| Step: 8
Training loss: 2.3078103065490723
Validation loss: 2.3059229056040444

Epoch: 5| Step: 9
Training loss: 2.0183207988739014
Validation loss: 2.3247070799591723

Epoch: 5| Step: 10
Training loss: 1.9818766117095947
Validation loss: 2.3662834116207656

Epoch: 40| Step: 0
Training loss: 1.9052717685699463
Validation loss: 2.319623016542004

Epoch: 5| Step: 1
Training loss: 2.286973476409912
Validation loss: 2.286907519063642

Epoch: 5| Step: 2
Training loss: 1.9627681970596313
Validation loss: 2.295104076785426

Epoch: 5| Step: 3
Training loss: 1.916145920753479
Validation loss: 2.2875790198644004

Epoch: 5| Step: 4
Training loss: 3.3912901878356934
Validation loss: 2.3041674603698072

Epoch: 5| Step: 5
Training loss: 2.6364309787750244
Validation loss: 2.230468523117804

Epoch: 5| Step: 6
Training loss: 2.4290950298309326
Validation loss: 2.3187008186053206

Epoch: 5| Step: 7
Training loss: 2.2698652744293213
Validation loss: 2.2759274372490506

Epoch: 5| Step: 8
Training loss: 2.3947558403015137
Validation loss: 2.307923100327933

Epoch: 5| Step: 9
Training loss: 3.1419239044189453
Validation loss: 2.302218201339886

Epoch: 5| Step: 10
Training loss: 2.2614803314208984
Validation loss: 2.2747845393355175

Epoch: 41| Step: 0
Training loss: 2.051840305328369
Validation loss: 2.271762744072945

Epoch: 5| Step: 1
Training loss: 3.2251296043395996
Validation loss: 2.2784299799191055

Epoch: 5| Step: 2
Training loss: 2.1093125343322754
Validation loss: 2.1894950738517185

Epoch: 5| Step: 3
Training loss: 2.8078198432922363
Validation loss: 2.3204372749533704

Epoch: 5| Step: 4
Training loss: 2.8888163566589355
Validation loss: 2.308228959319412

Epoch: 5| Step: 5
Training loss: 2.930473804473877
Validation loss: 2.3053818313024377

Epoch: 5| Step: 6
Training loss: 2.1595494747161865
Validation loss: 2.2699921656680364

Epoch: 5| Step: 7
Training loss: 1.7844455242156982
Validation loss: 2.2871167121394986

Epoch: 5| Step: 8
Training loss: 2.575653553009033
Validation loss: 2.3321867450591056

Epoch: 5| Step: 9
Training loss: 2.1030173301696777
Validation loss: 2.341672702502179

Epoch: 5| Step: 10
Training loss: 2.2429723739624023
Validation loss: 2.315296898606003

Epoch: 42| Step: 0
Training loss: 2.3759140968322754
Validation loss: 2.3156401008687992

Epoch: 5| Step: 1
Training loss: 2.178743839263916
Validation loss: 2.274142711393295

Epoch: 5| Step: 2
Training loss: 2.567777156829834
Validation loss: 2.350330146410132

Epoch: 5| Step: 3
Training loss: 2.0312373638153076
Validation loss: 2.2762272921941613

Epoch: 5| Step: 4
Training loss: 2.25242280960083
Validation loss: 2.2973239062934794

Epoch: 5| Step: 5
Training loss: 3.091939687728882
Validation loss: 2.260177368758827

Epoch: 5| Step: 6
Training loss: 1.7326771020889282
Validation loss: 2.3190943092428227

Epoch: 5| Step: 7
Training loss: 2.2880568504333496
Validation loss: 2.229301534673219

Epoch: 5| Step: 8
Training loss: 2.720696210861206
Validation loss: 2.2705883056886735

Epoch: 5| Step: 9
Training loss: 2.7731151580810547
Validation loss: 2.2969728797994633

Epoch: 5| Step: 10
Training loss: 2.8154830932617188
Validation loss: 2.3680739172043337

Epoch: 43| Step: 0
Training loss: 2.1046977043151855
Validation loss: 2.3278671387703187

Epoch: 5| Step: 1
Training loss: 2.1255111694335938
Validation loss: 2.2643370987266622

Epoch: 5| Step: 2
Training loss: 2.4780590534210205
Validation loss: 2.2661585218162945

Epoch: 5| Step: 3
Training loss: 2.776292085647583
Validation loss: 2.2830160689610306

Epoch: 5| Step: 4
Training loss: 2.007551431655884
Validation loss: 2.2528520912252445

Epoch: 5| Step: 5
Training loss: 2.7482666969299316
Validation loss: 2.331742094409081

Epoch: 5| Step: 6
Training loss: 1.9502118825912476
Validation loss: 2.282114259658321

Epoch: 5| Step: 7
Training loss: 2.5640060901641846
Validation loss: 2.2781533912945817

Epoch: 5| Step: 8
Training loss: 2.78029203414917
Validation loss: 2.316030876610869

Epoch: 5| Step: 9
Training loss: 2.5630195140838623
Validation loss: 2.2851361869483866

Epoch: 5| Step: 10
Training loss: 2.1428489685058594
Validation loss: 2.290399407827726

Epoch: 44| Step: 0
Training loss: 1.991225242614746
Validation loss: 2.3037214843175744

Epoch: 5| Step: 1
Training loss: 2.57639217376709
Validation loss: 2.2896816640771847

Epoch: 5| Step: 2
Training loss: 2.901841402053833
Validation loss: 2.310811822132398

Epoch: 5| Step: 3
Training loss: 2.108659029006958
Validation loss: 2.3249192494218067

Epoch: 5| Step: 4
Training loss: 2.360276460647583
Validation loss: 2.3168872684560795

Epoch: 5| Step: 5
Training loss: 3.076594114303589
Validation loss: 2.265215999336653

Epoch: 5| Step: 6
Training loss: 2.5143983364105225
Validation loss: 2.3055611554012505

Epoch: 5| Step: 7
Training loss: 2.5780742168426514
Validation loss: 2.3391506902633177

Epoch: 5| Step: 8
Training loss: 1.6710472106933594
Validation loss: 2.2966072661902315

Epoch: 5| Step: 9
Training loss: 2.4700241088867188
Validation loss: 2.3019957785965293

Epoch: 5| Step: 10
Training loss: 2.369904041290283
Validation loss: 2.2982227417730514

Epoch: 45| Step: 0
Training loss: 2.6062240600585938
Validation loss: 2.292035961663851

Epoch: 5| Step: 1
Training loss: 2.977191209793091
Validation loss: 2.3628001059255292

Epoch: 5| Step: 2
Training loss: 2.469076156616211
Validation loss: 2.3656197414603284

Epoch: 5| Step: 3
Training loss: 1.8178606033325195
Validation loss: 2.2828831672668457

Epoch: 5| Step: 4
Training loss: 1.7994976043701172
Validation loss: 2.288904059317804

Epoch: 5| Step: 5
Training loss: 2.4233250617980957
Validation loss: 2.3129758629747617

Epoch: 5| Step: 6
Training loss: 2.2183406352996826
Validation loss: 2.3023301734719226

Epoch: 5| Step: 7
Training loss: 2.579702138900757
Validation loss: 2.3213344517574517

Epoch: 5| Step: 8
Training loss: 2.4527430534362793
Validation loss: 2.356112434018043

Epoch: 5| Step: 9
Training loss: 3.1145033836364746
Validation loss: 2.24520307202493

Epoch: 5| Step: 10
Training loss: 2.0375494956970215
Validation loss: 2.3172331702324653

Epoch: 46| Step: 0
Training loss: 2.4967379570007324
Validation loss: 2.289182770636774

Epoch: 5| Step: 1
Training loss: 2.9028215408325195
Validation loss: 2.276591730374162

Epoch: 5| Step: 2
Training loss: 2.920264482498169
Validation loss: 2.209855592379006

Epoch: 5| Step: 3
Training loss: 2.2583744525909424
Validation loss: 2.273704082735123

Epoch: 5| Step: 4
Training loss: 1.761007308959961
Validation loss: 2.2811079871269966

Epoch: 5| Step: 5
Training loss: 1.9109983444213867
Validation loss: 2.301383715803905

Epoch: 5| Step: 6
Training loss: 2.296461820602417
Validation loss: 2.230579332638812

Epoch: 5| Step: 7
Training loss: 2.4984636306762695
Validation loss: 2.2841925851760374

Epoch: 5| Step: 8
Training loss: 2.898122787475586
Validation loss: 2.273375559878606

Epoch: 5| Step: 9
Training loss: 2.6084139347076416
Validation loss: 2.233655703965054

Epoch: 5| Step: 10
Training loss: 2.2213053703308105
Validation loss: 2.238113628920688

Epoch: 47| Step: 0
Training loss: 1.4985688924789429
Validation loss: 2.3278947235435568

Epoch: 5| Step: 1
Training loss: 2.2452640533447266
Validation loss: 2.2279421232079946

Epoch: 5| Step: 2
Training loss: 2.8953254222869873
Validation loss: 2.3185162569886897

Epoch: 5| Step: 3
Training loss: 1.990363359451294
Validation loss: 2.218961279879334

Epoch: 5| Step: 4
Training loss: 2.5246095657348633
Validation loss: 2.3748603790037093

Epoch: 5| Step: 5
Training loss: 2.403921365737915
Validation loss: 2.2756678699165263

Epoch: 5| Step: 6
Training loss: 2.732018232345581
Validation loss: 2.2894798132681076

Epoch: 5| Step: 7
Training loss: 2.10252046585083
Validation loss: 2.2790926964052263

Epoch: 5| Step: 8
Training loss: 2.440011501312256
Validation loss: 2.3064213388709613

Epoch: 5| Step: 9
Training loss: 2.721418857574463
Validation loss: 2.3541292195679038

Epoch: 5| Step: 10
Training loss: 2.4416277408599854
Validation loss: 2.3193209171295166

Epoch: 48| Step: 0
Training loss: 2.842664957046509
Validation loss: 2.2995780642314623

Epoch: 5| Step: 1
Training loss: 2.495368480682373
Validation loss: 2.2773061055009083

Epoch: 5| Step: 2
Training loss: 1.7572243213653564
Validation loss: 2.2875340369439896

Epoch: 5| Step: 3
Training loss: 3.0305538177490234
Validation loss: 2.3299883616867887

Epoch: 5| Step: 4
Training loss: 2.6672801971435547
Validation loss: 2.2821171655449817

Epoch: 5| Step: 5
Training loss: 2.0938212871551514
Validation loss: 2.2838624395349973

Epoch: 5| Step: 6
Training loss: 2.3179943561553955
Validation loss: 2.31767290125611

Epoch: 5| Step: 7
Training loss: 2.8295788764953613
Validation loss: 2.329450112517162

Epoch: 5| Step: 8
Training loss: 1.832425832748413
Validation loss: 2.253352448504458

Epoch: 5| Step: 9
Training loss: 1.7220550775527954
Validation loss: 2.272063950056671

Epoch: 5| Step: 10
Training loss: 2.615480422973633
Validation loss: 2.2816822016110985

Epoch: 49| Step: 0
Training loss: 2.2598214149475098
Validation loss: 2.279913056281305

Epoch: 5| Step: 1
Training loss: 2.282632827758789
Validation loss: 2.305569903824919

Epoch: 5| Step: 2
Training loss: 2.667081356048584
Validation loss: 2.3471161601363972

Epoch: 5| Step: 3
Training loss: 2.1143581867218018
Validation loss: 2.283293321568479

Epoch: 5| Step: 4
Training loss: 2.0664050579071045
Validation loss: 2.3153283903675694

Epoch: 5| Step: 5
Training loss: 2.129499673843384
Validation loss: 2.3017520468722106

Epoch: 5| Step: 6
Training loss: 2.6180341243743896
Validation loss: 2.269323088789499

Epoch: 5| Step: 7
Training loss: 2.1903128623962402
Validation loss: 2.21786089610028

Epoch: 5| Step: 8
Training loss: 2.946005344390869
Validation loss: 2.2840093771616616

Epoch: 5| Step: 9
Training loss: 3.2182629108428955
Validation loss: 2.229812378524452

Epoch: 5| Step: 10
Training loss: 2.1446337699890137
Validation loss: 2.331830850211523

Epoch: 50| Step: 0
Training loss: 2.258509874343872
Validation loss: 2.2180922069857196

Epoch: 5| Step: 1
Training loss: 2.2525315284729004
Validation loss: 2.2592560142599125

Epoch: 5| Step: 2
Training loss: 2.0389463901519775
Validation loss: 2.242462735022268

Epoch: 5| Step: 3
Training loss: 2.044173002243042
Validation loss: 2.2095447586428736

Epoch: 5| Step: 4
Training loss: 2.3455488681793213
Validation loss: 2.2368139477186304

Epoch: 5| Step: 5
Training loss: 2.268653154373169
Validation loss: 2.2974851233984834

Epoch: 5| Step: 6
Training loss: 2.4030351638793945
Validation loss: 2.2938341889330136

Epoch: 5| Step: 7
Training loss: 2.64518404006958
Validation loss: 2.2627118377275366

Epoch: 5| Step: 8
Training loss: 2.3124492168426514
Validation loss: 2.2749249806968113

Epoch: 5| Step: 9
Training loss: 3.6531882286071777
Validation loss: 2.2885814430893108

Epoch: 5| Step: 10
Training loss: 1.7667396068572998
Validation loss: 2.290973062156349

Epoch: 51| Step: 0
Training loss: 2.4818756580352783
Validation loss: 2.302509251461234

Epoch: 5| Step: 1
Training loss: 2.1502320766448975
Validation loss: 2.2539057834174043

Epoch: 5| Step: 2
Training loss: 2.4987549781799316
Validation loss: 2.248894545339769

Epoch: 5| Step: 3
Training loss: 2.7640414237976074
Validation loss: 2.262355660879484

Epoch: 5| Step: 4
Training loss: 1.6891920566558838
Validation loss: 2.2920971096202893

Epoch: 5| Step: 5
Training loss: 2.1954407691955566
Validation loss: 2.2653968885380733

Epoch: 5| Step: 6
Training loss: 1.9958572387695312
Validation loss: 2.2873200396055817

Epoch: 5| Step: 7
Training loss: 2.704561710357666
Validation loss: 2.2930379144607054

Epoch: 5| Step: 8
Training loss: 2.8479819297790527
Validation loss: 2.2543739029156264

Epoch: 5| Step: 9
Training loss: 2.2132911682128906
Validation loss: 2.3178019908166703

Epoch: 5| Step: 10
Training loss: 2.4191534519195557
Validation loss: 2.286867908252183

Epoch: 52| Step: 0
Training loss: 2.7604589462280273
Validation loss: 2.3293630307720554

Epoch: 5| Step: 1
Training loss: 2.835204601287842
Validation loss: 2.263248651258407

Epoch: 5| Step: 2
Training loss: 1.987023949623108
Validation loss: 2.347977868972286

Epoch: 5| Step: 3
Training loss: 2.476837635040283
Validation loss: 2.3308463737528813

Epoch: 5| Step: 4
Training loss: 2.1157188415527344
Validation loss: 2.2676273315183577

Epoch: 5| Step: 5
Training loss: 2.7360732555389404
Validation loss: 2.308259456388412

Epoch: 5| Step: 6
Training loss: 2.490675449371338
Validation loss: 2.3419643217517483

Epoch: 5| Step: 7
Training loss: 2.0430119037628174
Validation loss: 2.201012431934316

Epoch: 5| Step: 8
Training loss: 2.0482845306396484
Validation loss: 2.3192586514257614

Epoch: 5| Step: 9
Training loss: 2.25396466255188
Validation loss: 2.230630482396772

Epoch: 5| Step: 10
Training loss: 2.6139461994171143
Validation loss: 2.33595569287577

Epoch: 53| Step: 0
Training loss: 1.6450350284576416
Validation loss: 2.2491809642443092

Epoch: 5| Step: 1
Training loss: 2.565164566040039
Validation loss: 2.3422566575388752

Epoch: 5| Step: 2
Training loss: 2.2038817405700684
Validation loss: 2.298289293883949

Epoch: 5| Step: 3
Training loss: 2.084885835647583
Validation loss: 2.2537013843495357

Epoch: 5| Step: 4
Training loss: 2.3285632133483887
Validation loss: 2.346824020467779

Epoch: 5| Step: 5
Training loss: 2.3805503845214844
Validation loss: 2.3542536330479447

Epoch: 5| Step: 6
Training loss: 2.536285400390625
Validation loss: 2.292398847559447

Epoch: 5| Step: 7
Training loss: 3.3301804065704346
Validation loss: 2.304954400626562

Epoch: 5| Step: 8
Training loss: 2.5528922080993652
Validation loss: 2.3101574297874206

Epoch: 5| Step: 9
Training loss: 2.1313090324401855
Validation loss: 2.3141371050188617

Epoch: 5| Step: 10
Training loss: 2.111588954925537
Validation loss: 2.3617621980687624

Epoch: 54| Step: 0
Training loss: 2.4887490272521973
Validation loss: 2.2531282901763916

Epoch: 5| Step: 1
Training loss: 2.234964370727539
Validation loss: 2.3092500804572977

Epoch: 5| Step: 2
Training loss: 2.6193454265594482
Validation loss: 2.3086580614889822

Epoch: 5| Step: 3
Training loss: 2.31174898147583
Validation loss: 2.2386560875882386

Epoch: 5| Step: 4
Training loss: 1.7496440410614014
Validation loss: 2.3340772198092554

Epoch: 5| Step: 5
Training loss: 2.4891200065612793
Validation loss: 2.316349742233112

Epoch: 5| Step: 6
Training loss: 2.23420786857605
Validation loss: 2.2721988026813795

Epoch: 5| Step: 7
Training loss: 1.866244912147522
Validation loss: 2.371010036878688

Epoch: 5| Step: 8
Training loss: 2.816901683807373
Validation loss: 2.2720835747257357

Epoch: 5| Step: 9
Training loss: 2.6497368812561035
Validation loss: 2.365061172875025

Epoch: 5| Step: 10
Training loss: 2.1812942028045654
Validation loss: 2.275790153011199

Epoch: 55| Step: 0
Training loss: 2.2306911945343018
Validation loss: 2.2995084870246147

Epoch: 5| Step: 1
Training loss: 2.206125497817993
Validation loss: 2.2083004789967693

Epoch: 5| Step: 2
Training loss: 2.2452054023742676
Validation loss: 2.315706427379321

Epoch: 5| Step: 3
Training loss: 2.6596133708953857
Validation loss: 2.295335764526039

Epoch: 5| Step: 4
Training loss: 3.065455436706543
Validation loss: 2.240291526240687

Epoch: 5| Step: 5
Training loss: 2.7901408672332764
Validation loss: 2.2022922013395574

Epoch: 5| Step: 6
Training loss: 1.8268429040908813
Validation loss: 2.30975176442054

Epoch: 5| Step: 7
Training loss: 2.7251229286193848
Validation loss: 2.2925933714835875

Epoch: 5| Step: 8
Training loss: 2.1211633682250977
Validation loss: 2.3561371782774567

Epoch: 5| Step: 9
Training loss: 2.1657321453094482
Validation loss: 2.311717167977364

Epoch: 5| Step: 10
Training loss: 2.3954055309295654
Validation loss: 2.389763434727987

Epoch: 56| Step: 0
Training loss: 2.0970473289489746
Validation loss: 2.2926016981883715

Epoch: 5| Step: 1
Training loss: 1.9568824768066406
Validation loss: 2.2467149919079197

Epoch: 5| Step: 2
Training loss: 2.355821371078491
Validation loss: 2.365498547912926

Epoch: 5| Step: 3
Training loss: 2.0455322265625
Validation loss: 2.369784785855201

Epoch: 5| Step: 4
Training loss: 2.5809741020202637
Validation loss: 2.250238025060264

Epoch: 5| Step: 5
Training loss: 2.3313629627227783
Validation loss: 2.265149816390007

Epoch: 5| Step: 6
Training loss: 2.59529972076416
Validation loss: 2.3233915759671118

Epoch: 5| Step: 7
Training loss: 2.581979751586914
Validation loss: 2.2504830719322286

Epoch: 5| Step: 8
Training loss: 1.984484314918518
Validation loss: 2.274800862035444

Epoch: 5| Step: 9
Training loss: 2.499347686767578
Validation loss: 2.236001299273583

Epoch: 5| Step: 10
Training loss: 2.4818570613861084
Validation loss: 2.267819107219737

Epoch: 57| Step: 0
Training loss: 2.4560546875
Validation loss: 2.295355068740024

Epoch: 5| Step: 1
Training loss: 2.3719241619110107
Validation loss: 2.334473894488427

Epoch: 5| Step: 2
Training loss: 2.378138303756714
Validation loss: 2.290385118094824

Epoch: 5| Step: 3
Training loss: 2.9434990882873535
Validation loss: 2.2655154684538483

Epoch: 5| Step: 4
Training loss: 2.6131503582000732
Validation loss: 2.2723450891433226

Epoch: 5| Step: 5
Training loss: 2.513676166534424
Validation loss: 2.263877445651639

Epoch: 5| Step: 6
Training loss: 2.453336477279663
Validation loss: 2.292579686769875

Epoch: 5| Step: 7
Training loss: 2.0475239753723145
Validation loss: 2.273874649437525

Epoch: 5| Step: 8
Training loss: 2.2369112968444824
Validation loss: 2.33712294537534

Epoch: 5| Step: 9
Training loss: 2.224529981613159
Validation loss: 2.2484364817219396

Epoch: 5| Step: 10
Training loss: 1.6241986751556396
Validation loss: 2.321807917728219

Epoch: 58| Step: 0
Training loss: 1.7022396326065063
Validation loss: 2.284743715358037

Epoch: 5| Step: 1
Training loss: 2.506103992462158
Validation loss: 2.232646096137262

Epoch: 5| Step: 2
Training loss: 2.3524861335754395
Validation loss: 2.3609059677329114

Epoch: 5| Step: 3
Training loss: 2.421008825302124
Validation loss: 2.270950275082742

Epoch: 5| Step: 4
Training loss: 2.36688494682312
Validation loss: 2.360753256787536

Epoch: 5| Step: 5
Training loss: 2.9764318466186523
Validation loss: 2.3031178546208206

Epoch: 5| Step: 6
Training loss: 2.632749080657959
Validation loss: 2.2631513764781337

Epoch: 5| Step: 7
Training loss: 2.4925730228424072
Validation loss: 2.253947052904355

Epoch: 5| Step: 8
Training loss: 2.7898454666137695
Validation loss: 2.4031049846321024

Epoch: 5| Step: 9
Training loss: 1.9116954803466797
Validation loss: 2.323480242042131

Epoch: 5| Step: 10
Training loss: 2.253326416015625
Validation loss: 2.2597173080649426

Epoch: 59| Step: 0
Training loss: 2.5081164836883545
Validation loss: 2.2893526913017355

Epoch: 5| Step: 1
Training loss: 2.3464040756225586
Validation loss: 2.2176583120899815

Epoch: 5| Step: 2
Training loss: 2.7192494869232178
Validation loss: 2.296212903914913

Epoch: 5| Step: 3
Training loss: 2.6438050270080566
Validation loss: 2.3567407515741166

Epoch: 5| Step: 4
Training loss: 2.2973480224609375
Validation loss: 2.2947634035541165

Epoch: 5| Step: 5
Training loss: 1.8709523677825928
Validation loss: 2.287779502971198

Epoch: 5| Step: 6
Training loss: 1.870397925376892
Validation loss: 2.253965116316272

Epoch: 5| Step: 7
Training loss: 2.8707332611083984
Validation loss: 2.265120667795981

Epoch: 5| Step: 8
Training loss: 2.1600329875946045
Validation loss: 2.2029497097897273

Epoch: 5| Step: 9
Training loss: 2.567523241043091
Validation loss: 2.2927821528527046

Epoch: 5| Step: 10
Training loss: 1.8805136680603027
Validation loss: 2.3113712700464393

Epoch: 60| Step: 0
Training loss: 2.1668643951416016
Validation loss: 2.3432961458800943

Epoch: 5| Step: 1
Training loss: 1.8412847518920898
Validation loss: 2.359800295163226

Epoch: 5| Step: 2
Training loss: 2.242530345916748
Validation loss: 2.3157712797964773

Epoch: 5| Step: 3
Training loss: 2.5344903469085693
Validation loss: 2.374385222311943

Epoch: 5| Step: 4
Training loss: 2.428802967071533
Validation loss: 2.2488861929985786

Epoch: 5| Step: 5
Training loss: 3.052663803100586
Validation loss: 2.261087750875822

Epoch: 5| Step: 6
Training loss: 2.1504745483398438
Validation loss: 2.303820102445541

Epoch: 5| Step: 7
Training loss: 2.6144633293151855
Validation loss: 2.2922988937747095

Epoch: 5| Step: 8
Training loss: 2.3804469108581543
Validation loss: 2.2654328884616977

Epoch: 5| Step: 9
Training loss: 2.3175196647644043
Validation loss: 2.270472688059653

Epoch: 5| Step: 10
Training loss: 2.058412551879883
Validation loss: 2.3582881394252984

Epoch: 61| Step: 0
Training loss: 3.0596907138824463
Validation loss: 2.3578376308564217

Epoch: 5| Step: 1
Training loss: 2.2072253227233887
Validation loss: 2.2900864898517566

Epoch: 5| Step: 2
Training loss: 2.4174282550811768
Validation loss: 2.295002532261674

Epoch: 5| Step: 3
Training loss: 2.748548984527588
Validation loss: 2.210163039545859

Epoch: 5| Step: 4
Training loss: 2.522247314453125
Validation loss: 2.2837932520015265

Epoch: 5| Step: 5
Training loss: 2.501166582107544
Validation loss: 2.306570581210557

Epoch: 5| Step: 6
Training loss: 2.39324688911438
Validation loss: 2.2666321762146486

Epoch: 5| Step: 7
Training loss: 2.134735107421875
Validation loss: 2.283172635621922

Epoch: 5| Step: 8
Training loss: 1.7983171939849854
Validation loss: 2.27775437601151

Epoch: 5| Step: 9
Training loss: 2.5064194202423096
Validation loss: 2.335694561722458

Epoch: 5| Step: 10
Training loss: 1.7200682163238525
Validation loss: 2.2301443212775776

Epoch: 62| Step: 0
Training loss: 2.050302028656006
Validation loss: 2.2494761969453547

Epoch: 5| Step: 1
Training loss: 1.953139066696167
Validation loss: 2.2845556992356495

Epoch: 5| Step: 2
Training loss: 2.8336033821105957
Validation loss: 2.299081051221458

Epoch: 5| Step: 3
Training loss: 2.381807565689087
Validation loss: 2.2605171665068595

Epoch: 5| Step: 4
Training loss: 2.745023727416992
Validation loss: 2.3155001722356325

Epoch: 5| Step: 5
Training loss: 2.254948616027832
Validation loss: 2.3449084707485732

Epoch: 5| Step: 6
Training loss: 1.9717092514038086
Validation loss: 2.2957819892514135

Epoch: 5| Step: 7
Training loss: 1.866640329360962
Validation loss: 2.3207742552603445

Epoch: 5| Step: 8
Training loss: 2.3091318607330322
Validation loss: 2.3416757865618636

Epoch: 5| Step: 9
Training loss: 2.3848133087158203
Validation loss: 2.2658069210667766

Epoch: 5| Step: 10
Training loss: 2.7052316665649414
Validation loss: 2.254758532329272

Epoch: 63| Step: 0
Training loss: 2.8559670448303223
Validation loss: 2.2410638024730067

Epoch: 5| Step: 1
Training loss: 2.8016979694366455
Validation loss: 2.2265304198829075

Epoch: 5| Step: 2
Training loss: 2.371628761291504
Validation loss: 2.2842174242901545

Epoch: 5| Step: 3
Training loss: 2.8312199115753174
Validation loss: 2.3037032260689685

Epoch: 5| Step: 4
Training loss: 1.5076533555984497
Validation loss: 2.2842385871436006

Epoch: 5| Step: 5
Training loss: 1.9506022930145264
Validation loss: 2.302545473139773

Epoch: 5| Step: 6
Training loss: 3.198798656463623
Validation loss: 2.2618759421892065

Epoch: 5| Step: 7
Training loss: 2.716282367706299
Validation loss: 2.311558982377411

Epoch: 5| Step: 8
Training loss: 1.4916373491287231
Validation loss: 2.2746614974032164

Epoch: 5| Step: 9
Training loss: 2.2602293491363525
Validation loss: 2.2794283026008197

Epoch: 5| Step: 10
Training loss: 1.6809453964233398
Validation loss: 2.3386679310952463

Epoch: 64| Step: 0
Training loss: 3.228623628616333
Validation loss: 2.343266748612927

Epoch: 5| Step: 1
Training loss: 1.93359375
Validation loss: 2.2667533300256215

Epoch: 5| Step: 2
Training loss: 2.450281858444214
Validation loss: 2.2673256807429816

Epoch: 5| Step: 3
Training loss: 1.7906830310821533
Validation loss: 2.3590488049291793

Epoch: 5| Step: 4
Training loss: 2.536780834197998
Validation loss: 2.3102723654880317

Epoch: 5| Step: 5
Training loss: 2.4501266479492188
Validation loss: 2.2923913271196428

Epoch: 5| Step: 6
Training loss: 2.33742094039917
Validation loss: 2.3279665336813977

Epoch: 5| Step: 7
Training loss: 1.8171987533569336
Validation loss: 2.2957474852121003

Epoch: 5| Step: 8
Training loss: 2.0449225902557373
Validation loss: 2.2908971835208196

Epoch: 5| Step: 9
Training loss: 2.7866766452789307
Validation loss: 2.245131577214887

Epoch: 5| Step: 10
Training loss: 1.8849891424179077
Validation loss: 2.2573143538608345

Epoch: 65| Step: 0
Training loss: 2.2785937786102295
Validation loss: 2.3709869820584535

Epoch: 5| Step: 1
Training loss: 1.6643116474151611
Validation loss: 2.2838042602744153

Epoch: 5| Step: 2
Training loss: 2.710670232772827
Validation loss: 2.240762966935353

Epoch: 5| Step: 3
Training loss: 2.8264379501342773
Validation loss: 2.2696527332387944

Epoch: 5| Step: 4
Training loss: 2.2594456672668457
Validation loss: 2.362877981637114

Epoch: 5| Step: 5
Training loss: 1.6631654500961304
Validation loss: 2.340067207172353

Epoch: 5| Step: 6
Training loss: 2.69003963470459
Validation loss: 2.2429081650190454

Epoch: 5| Step: 7
Training loss: 2.407957077026367
Validation loss: 2.275388812506071

Epoch: 5| Step: 8
Training loss: 2.2095723152160645
Validation loss: 2.3050259979822303

Epoch: 5| Step: 9
Training loss: 2.737381935119629
Validation loss: 2.2622581835716002

Epoch: 5| Step: 10
Training loss: 2.438112258911133
Validation loss: 2.309055107896046

Epoch: 66| Step: 0
Training loss: 2.9261746406555176
Validation loss: 2.3443354637392106

Epoch: 5| Step: 1
Training loss: 2.624011278152466
Validation loss: 2.3632612471939414

Epoch: 5| Step: 2
Training loss: 2.5840487480163574
Validation loss: 2.3228594180076354

Epoch: 5| Step: 3
Training loss: 2.3645107746124268
Validation loss: 2.2877774712859944

Epoch: 5| Step: 4
Training loss: 2.2316129207611084
Validation loss: 2.254781310276319

Epoch: 5| Step: 5
Training loss: 1.839911699295044
Validation loss: 2.358216929179366

Epoch: 5| Step: 6
Training loss: 3.285322666168213
Validation loss: 2.272191536041998

Epoch: 5| Step: 7
Training loss: 1.7189689874649048
Validation loss: 2.363280819308373

Epoch: 5| Step: 8
Training loss: 2.4800984859466553
Validation loss: 2.318381186454527

Epoch: 5| Step: 9
Training loss: 1.9900696277618408
Validation loss: 2.2642199967497136

Epoch: 5| Step: 10
Training loss: 1.6062995195388794
Validation loss: 2.3294180311182493

Epoch: 67| Step: 0
Training loss: 2.7141406536102295
Validation loss: 2.312020483837333

Epoch: 5| Step: 1
Training loss: 2.3462226390838623
Validation loss: 2.27661253816338

Epoch: 5| Step: 2
Training loss: 2.230177879333496
Validation loss: 2.3002264807301183

Epoch: 5| Step: 3
Training loss: 1.8079723119735718
Validation loss: 2.4003084218630226

Epoch: 5| Step: 4
Training loss: 1.9911575317382812
Validation loss: 2.244911127193

Epoch: 5| Step: 5
Training loss: 3.101491928100586
Validation loss: 2.257824379910705

Epoch: 5| Step: 6
Training loss: 2.4460177421569824
Validation loss: 2.323428999993109

Epoch: 5| Step: 7
Training loss: 2.8140625953674316
Validation loss: 2.329075728693316

Epoch: 5| Step: 8
Training loss: 1.9831174612045288
Validation loss: 2.295157153119323

Epoch: 5| Step: 9
Training loss: 1.954856276512146
Validation loss: 2.2496619557821624

Epoch: 5| Step: 10
Training loss: 2.4495034217834473
Validation loss: 2.2588131863583802

Epoch: 68| Step: 0
Training loss: 1.879590630531311
Validation loss: 2.2497916811256

Epoch: 5| Step: 1
Training loss: 2.363454818725586
Validation loss: 2.281069863227106

Epoch: 5| Step: 2
Training loss: 2.0833797454833984
Validation loss: 2.2888718856278287

Epoch: 5| Step: 3
Training loss: 3.3111424446105957
Validation loss: 2.296651250572615

Epoch: 5| Step: 4
Training loss: 2.3446033000946045
Validation loss: 2.3366158752031225

Epoch: 5| Step: 5
Training loss: 3.0893795490264893
Validation loss: 2.3416897891670145

Epoch: 5| Step: 6
Training loss: 1.945447564125061
Validation loss: 2.307881852631928

Epoch: 5| Step: 7
Training loss: 2.49759840965271
Validation loss: 2.236650948883385

Epoch: 5| Step: 8
Training loss: 2.3200511932373047
Validation loss: 2.2401458294160905

Epoch: 5| Step: 9
Training loss: 2.4748599529266357
Validation loss: 2.252526269164137

Epoch: 5| Step: 10
Training loss: 1.2663018703460693
Validation loss: 2.2804556405672463

Epoch: 69| Step: 0
Training loss: 2.9164462089538574
Validation loss: 2.2807845043879684

Epoch: 5| Step: 1
Training loss: 2.343843460083008
Validation loss: 2.279491474551539

Epoch: 5| Step: 2
Training loss: 1.817628264427185
Validation loss: 2.2309596359088855

Epoch: 5| Step: 3
Training loss: 2.2879738807678223
Validation loss: 2.2559160942672403

Epoch: 5| Step: 4
Training loss: 2.0498976707458496
Validation loss: 2.294822228852139

Epoch: 5| Step: 5
Training loss: 2.626962184906006
Validation loss: 2.263052196912868

Epoch: 5| Step: 6
Training loss: 2.109886884689331
Validation loss: 2.3248232333890853

Epoch: 5| Step: 7
Training loss: 2.5629513263702393
Validation loss: 2.2218293938585507

Epoch: 5| Step: 8
Training loss: 2.777433395385742
Validation loss: 2.2894638866506596

Epoch: 5| Step: 9
Training loss: 1.8588520288467407
Validation loss: 2.2955512846669843

Epoch: 5| Step: 10
Training loss: 2.3122427463531494
Validation loss: 2.232746147340344

Epoch: 70| Step: 0
Training loss: 2.965930938720703
Validation loss: 2.2711781750443163

Epoch: 5| Step: 1
Training loss: 2.0525944232940674
Validation loss: 2.372878369464669

Epoch: 5| Step: 2
Training loss: 2.2402255535125732
Validation loss: 2.3006669962277977

Epoch: 5| Step: 3
Training loss: 2.5867185592651367
Validation loss: 2.2758464633777575

Epoch: 5| Step: 4
Training loss: 2.113131046295166
Validation loss: 2.2465204141473256

Epoch: 5| Step: 5
Training loss: 3.1929633617401123
Validation loss: 2.294901551738862

Epoch: 5| Step: 6
Training loss: 1.8801002502441406
Validation loss: 2.2962211639650407

Epoch: 5| Step: 7
Training loss: 2.1271562576293945
Validation loss: 2.2702763336960987

Epoch: 5| Step: 8
Training loss: 2.462146043777466
Validation loss: 2.254577188081639

Epoch: 5| Step: 9
Training loss: 2.290987730026245
Validation loss: 2.2815445853817846

Epoch: 5| Step: 10
Training loss: 1.4627667665481567
Validation loss: 2.3063832380438365

Epoch: 71| Step: 0
Training loss: 2.4561092853546143
Validation loss: 2.227844835609518

Epoch: 5| Step: 1
Training loss: 2.0896546840667725
Validation loss: 2.2358587608542493

Epoch: 5| Step: 2
Training loss: 2.1939492225646973
Validation loss: 2.353543758392334

Epoch: 5| Step: 3
Training loss: 2.5784730911254883
Validation loss: 2.2922306470973517

Epoch: 5| Step: 4
Training loss: 1.8540008068084717
Validation loss: 2.370398606023481

Epoch: 5| Step: 5
Training loss: 3.0003280639648438
Validation loss: 2.2994837196924354

Epoch: 5| Step: 6
Training loss: 1.8232053518295288
Validation loss: 2.308797609421515

Epoch: 5| Step: 7
Training loss: 2.515974521636963
Validation loss: 2.352676555674563

Epoch: 5| Step: 8
Training loss: 2.4752564430236816
Validation loss: 2.3975632139431533

Epoch: 5| Step: 9
Training loss: 2.204089879989624
Validation loss: 2.320386850705711

Epoch: 5| Step: 10
Training loss: 2.5089778900146484
Validation loss: 2.3389267536901657

Epoch: 72| Step: 0
Training loss: 2.2060303688049316
Validation loss: 2.3331816811715402

Epoch: 5| Step: 1
Training loss: 2.8982620239257812
Validation loss: 2.2976342837015786

Epoch: 5| Step: 2
Training loss: 1.6318718194961548
Validation loss: 2.3042453899178454

Epoch: 5| Step: 3
Training loss: 1.9501739740371704
Validation loss: 2.295402016690982

Epoch: 5| Step: 4
Training loss: 2.03355073928833
Validation loss: 2.302268987060875

Epoch: 5| Step: 5
Training loss: 3.143177032470703
Validation loss: 2.2796279807244577

Epoch: 5| Step: 6
Training loss: 2.068608522415161
Validation loss: 2.333587126065326

Epoch: 5| Step: 7
Training loss: 2.076446056365967
Validation loss: 2.3200776948723743

Epoch: 5| Step: 8
Training loss: 2.2182228565216064
Validation loss: 2.339124233491959

Epoch: 5| Step: 9
Training loss: 2.9971110820770264
Validation loss: 2.3678410912072785

Epoch: 5| Step: 10
Training loss: 2.1277356147766113
Validation loss: 2.3701257218596754

Epoch: 73| Step: 0
Training loss: 2.40222430229187
Validation loss: 2.2454921583975516

Epoch: 5| Step: 1
Training loss: 1.79641854763031
Validation loss: 2.2811559400250836

Epoch: 5| Step: 2
Training loss: 1.7470067739486694
Validation loss: 2.311935568368563

Epoch: 5| Step: 3
Training loss: 2.6533896923065186
Validation loss: 2.26799673931573

Epoch: 5| Step: 4
Training loss: 3.363905668258667
Validation loss: 2.258897146871013

Epoch: 5| Step: 5
Training loss: 1.820935606956482
Validation loss: 2.239143597182407

Epoch: 5| Step: 6
Training loss: 2.590273380279541
Validation loss: 2.3341009206669305

Epoch: 5| Step: 7
Training loss: 2.0297272205352783
Validation loss: 2.278637029791391

Epoch: 5| Step: 8
Training loss: 2.825268030166626
Validation loss: 2.2698326033930623

Epoch: 5| Step: 9
Training loss: 2.241515636444092
Validation loss: 2.289828056930214

Epoch: 5| Step: 10
Training loss: 2.0941507816314697
Validation loss: 2.331084971786827

Epoch: 74| Step: 0
Training loss: 1.9157469272613525
Validation loss: 2.3171342931767946

Epoch: 5| Step: 1
Training loss: 1.8502715826034546
Validation loss: 2.2694531140788907

Epoch: 5| Step: 2
Training loss: 2.0852112770080566
Validation loss: 2.2888316672335387

Epoch: 5| Step: 3
Training loss: 2.1023545265197754
Validation loss: 2.286847624727475

Epoch: 5| Step: 4
Training loss: 2.1135001182556152
Validation loss: 2.328818598101216

Epoch: 5| Step: 5
Training loss: 2.6554603576660156
Validation loss: 2.223740205969862

Epoch: 5| Step: 6
Training loss: 2.8989357948303223
Validation loss: 2.2112962712523756

Epoch: 5| Step: 7
Training loss: 2.4690215587615967
Validation loss: 2.285838824446483

Epoch: 5| Step: 8
Training loss: 3.7092227935791016
Validation loss: 2.3042162515783824

Epoch: 5| Step: 9
Training loss: 1.6889874935150146
Validation loss: 2.259007194990753

Epoch: 5| Step: 10
Training loss: 1.9514389038085938
Validation loss: 2.221094310924571

Epoch: 75| Step: 0
Training loss: 2.4014945030212402
Validation loss: 2.3743725412635395

Epoch: 5| Step: 1
Training loss: 1.4939262866973877
Validation loss: 2.1797434796569166

Epoch: 5| Step: 2
Training loss: 2.6635677814483643
Validation loss: 2.2438091180657826

Epoch: 5| Step: 3
Training loss: 2.9515531063079834
Validation loss: 2.296043170395718

Epoch: 5| Step: 4
Training loss: 2.297637462615967
Validation loss: 2.2897654707713793

Epoch: 5| Step: 5
Training loss: 1.889809250831604
Validation loss: 2.1936539680727067

Epoch: 5| Step: 6
Training loss: 2.0572216510772705
Validation loss: 2.390372404488184

Epoch: 5| Step: 7
Training loss: 2.385366916656494
Validation loss: 2.2347715490607807

Epoch: 5| Step: 8
Training loss: 2.5279293060302734
Validation loss: 2.2860320768048688

Epoch: 5| Step: 9
Training loss: 2.2867398262023926
Validation loss: 2.2436525488412506

Epoch: 5| Step: 10
Training loss: 2.921706438064575
Validation loss: 2.3758948310728996

Epoch: 76| Step: 0
Training loss: 2.9471375942230225
Validation loss: 2.3026027781988985

Epoch: 5| Step: 1
Training loss: 2.585697889328003
Validation loss: 2.2741563397069133

Epoch: 5| Step: 2
Training loss: 2.778787612915039
Validation loss: 2.2394685104329097

Epoch: 5| Step: 3
Training loss: 2.705817699432373
Validation loss: 2.308249424862605

Epoch: 5| Step: 4
Training loss: 2.1812777519226074
Validation loss: 2.21732896630482

Epoch: 5| Step: 5
Training loss: 1.8555467128753662
Validation loss: 2.2743550782562583

Epoch: 5| Step: 6
Training loss: 2.0240628719329834
Validation loss: 2.282426872561055

Epoch: 5| Step: 7
Training loss: 2.0412511825561523
Validation loss: 2.293431564043927

Epoch: 5| Step: 8
Training loss: 1.8151180744171143
Validation loss: 2.2537458904327883

Epoch: 5| Step: 9
Training loss: 2.1579651832580566
Validation loss: 2.2956946229421966

Epoch: 5| Step: 10
Training loss: 1.9520014524459839
Validation loss: 2.2203217962736725

Epoch: 77| Step: 0
Training loss: 2.8868744373321533
Validation loss: 2.2748325358154955

Epoch: 5| Step: 1
Training loss: 1.9061483144760132
Validation loss: 2.2065682513739473

Epoch: 5| Step: 2
Training loss: 1.7870252132415771
Validation loss: 2.273493956494075

Epoch: 5| Step: 3
Training loss: 2.3885483741760254
Validation loss: 2.330463340205531

Epoch: 5| Step: 4
Training loss: 2.098477602005005
Validation loss: 2.219640503647507

Epoch: 5| Step: 5
Training loss: 1.9509084224700928
Validation loss: 2.234153155357607

Epoch: 5| Step: 6
Training loss: 1.9467318058013916
Validation loss: 2.339494514208968

Epoch: 5| Step: 7
Training loss: 2.470402240753174
Validation loss: 2.1716636970479

Epoch: 5| Step: 8
Training loss: 3.0523123741149902
Validation loss: 2.276316124905822

Epoch: 5| Step: 9
Training loss: 2.384432315826416
Validation loss: 2.27213962616459

Epoch: 5| Step: 10
Training loss: 2.7578659057617188
Validation loss: 2.166231019522554

Epoch: 78| Step: 0
Training loss: 2.3798022270202637
Validation loss: 2.1721095987545547

Epoch: 5| Step: 1
Training loss: 2.27639102935791
Validation loss: 2.2716426400728125

Epoch: 5| Step: 2
Training loss: 1.9425379037857056
Validation loss: 2.255349405350224

Epoch: 5| Step: 3
Training loss: 2.7590854167938232
Validation loss: 2.2647865856847456

Epoch: 5| Step: 4
Training loss: 2.2884793281555176
Validation loss: 2.177902644680392

Epoch: 5| Step: 5
Training loss: 2.047245979309082
Validation loss: 2.243972170737482

Epoch: 5| Step: 6
Training loss: 2.083523988723755
Validation loss: 2.2290293837106354

Epoch: 5| Step: 7
Training loss: 2.326740264892578
Validation loss: 2.2577408180441907

Epoch: 5| Step: 8
Training loss: 2.2338707447052
Validation loss: 2.2232555958532516

Epoch: 5| Step: 9
Training loss: 2.816070556640625
Validation loss: 2.272966597669868

Epoch: 5| Step: 10
Training loss: 2.230752944946289
Validation loss: 2.2234115036585

Epoch: 79| Step: 0
Training loss: 2.731799840927124
Validation loss: 2.2855206586981334

Epoch: 5| Step: 1
Training loss: 2.2916812896728516
Validation loss: 2.2201836788526146

Epoch: 5| Step: 2
Training loss: 2.3946423530578613
Validation loss: 2.2431799468173774

Epoch: 5| Step: 3
Training loss: 1.5862089395523071
Validation loss: 2.310510213657092

Epoch: 5| Step: 4
Training loss: 2.391165256500244
Validation loss: 2.1847189318749214

Epoch: 5| Step: 5
Training loss: 2.4112420082092285
Validation loss: 2.228386663621472

Epoch: 5| Step: 6
Training loss: 3.546858310699463
Validation loss: 2.290669229722792

Epoch: 5| Step: 7
Training loss: 1.7414186000823975
Validation loss: 2.2263373200611403

Epoch: 5| Step: 8
Training loss: 1.6071109771728516
Validation loss: 2.195325174639302

Epoch: 5| Step: 9
Training loss: 2.2287466526031494
Validation loss: 2.300599951897898

Epoch: 5| Step: 10
Training loss: 2.408663034439087
Validation loss: 2.229959059787053

Epoch: 80| Step: 0
Training loss: 2.360469102859497
Validation loss: 2.276032970797631

Epoch: 5| Step: 1
Training loss: 2.942870616912842
Validation loss: 2.2538667622432915

Epoch: 5| Step: 2
Training loss: 2.3363094329833984
Validation loss: 2.267871674670968

Epoch: 5| Step: 3
Training loss: 2.64007830619812
Validation loss: 2.206553651440528

Epoch: 5| Step: 4
Training loss: 2.5548946857452393
Validation loss: 2.2252199470355944

Epoch: 5| Step: 5
Training loss: 2.353868007659912
Validation loss: 2.319481143387415

Epoch: 5| Step: 6
Training loss: 2.164349317550659
Validation loss: 2.2220926951336604

Epoch: 5| Step: 7
Training loss: 1.5181653499603271
Validation loss: 2.2310614201330368

Epoch: 5| Step: 8
Training loss: 2.4305789470672607
Validation loss: 2.3050523483625023

Epoch: 5| Step: 9
Training loss: 2.0689563751220703
Validation loss: 2.3009734025565525

Epoch: 5| Step: 10
Training loss: 1.8532984256744385
Validation loss: 2.288810376198061

Epoch: 81| Step: 0
Training loss: 2.0674190521240234
Validation loss: 2.255502841805899

Epoch: 5| Step: 1
Training loss: 2.4765608310699463
Validation loss: 2.225669063547606

Epoch: 5| Step: 2
Training loss: 2.3368453979492188
Validation loss: 2.267753178073514

Epoch: 5| Step: 3
Training loss: 1.788015365600586
Validation loss: 2.2435403716179634

Epoch: 5| Step: 4
Training loss: 2.254099130630493
Validation loss: 2.2452654274561072

Epoch: 5| Step: 5
Training loss: 1.7228056192398071
Validation loss: 2.262159562879993

Epoch: 5| Step: 6
Training loss: 2.7222180366516113
Validation loss: 2.2615538412524807

Epoch: 5| Step: 7
Training loss: 2.424872875213623
Validation loss: 2.2606108316811184

Epoch: 5| Step: 8
Training loss: 2.1552674770355225
Validation loss: 2.2969854698386243

Epoch: 5| Step: 9
Training loss: 2.3786253929138184
Validation loss: 2.270332908117643

Epoch: 5| Step: 10
Training loss: 3.055692195892334
Validation loss: 2.285529733985983

Epoch: 82| Step: 0
Training loss: 2.5456156730651855
Validation loss: 2.2252271316384755

Epoch: 5| Step: 1
Training loss: 2.3944268226623535
Validation loss: 2.1909748508084204

Epoch: 5| Step: 2
Training loss: 1.9485864639282227
Validation loss: 2.2193577110126452

Epoch: 5| Step: 3
Training loss: 2.586484670639038
Validation loss: 2.2894832485465595

Epoch: 5| Step: 4
Training loss: 2.271517276763916
Validation loss: 2.2227905052964405

Epoch: 5| Step: 5
Training loss: 2.1387264728546143
Validation loss: 2.2737953457781064

Epoch: 5| Step: 6
Training loss: 2.4104104042053223
Validation loss: 2.2607568745972006

Epoch: 5| Step: 7
Training loss: 1.946415662765503
Validation loss: 2.2959161573840725

Epoch: 5| Step: 8
Training loss: 1.940844178199768
Validation loss: 2.305587282744787

Epoch: 5| Step: 9
Training loss: 2.891742706298828
Validation loss: 2.1982760339654903

Epoch: 5| Step: 10
Training loss: 2.0866072177886963
Validation loss: 2.241212062938239

Epoch: 83| Step: 0
Training loss: 2.2811310291290283
Validation loss: 2.2448055987717

Epoch: 5| Step: 1
Training loss: 2.318669319152832
Validation loss: 2.228764760878778

Epoch: 5| Step: 2
Training loss: 2.4448065757751465
Validation loss: 2.2758905951694777

Epoch: 5| Step: 3
Training loss: 2.185762405395508
Validation loss: 2.2536297587938208

Epoch: 5| Step: 4
Training loss: 1.9805402755737305
Validation loss: 2.2995967095898044

Epoch: 5| Step: 5
Training loss: 1.9946272373199463
Validation loss: 2.2115189977871474

Epoch: 5| Step: 6
Training loss: 2.535984516143799
Validation loss: 2.2467189604236233

Epoch: 5| Step: 7
Training loss: 2.310521125793457
Validation loss: 2.270293140924105

Epoch: 5| Step: 8
Training loss: 2.5762171745300293
Validation loss: 2.228320760111655

Epoch: 5| Step: 9
Training loss: 2.0966734886169434
Validation loss: 2.271939810886178

Epoch: 5| Step: 10
Training loss: 2.1157150268554688
Validation loss: 2.3244847866796676

Epoch: 84| Step: 0
Training loss: 2.1327099800109863
Validation loss: 2.273512642870667

Epoch: 5| Step: 1
Training loss: 2.322937250137329
Validation loss: 2.2789182547600038

Epoch: 5| Step: 2
Training loss: 1.9314113855361938
Validation loss: 2.2865276311033513

Epoch: 5| Step: 3
Training loss: 2.2856552600860596
Validation loss: 2.317179992634763

Epoch: 5| Step: 4
Training loss: 2.3316636085510254
Validation loss: 2.2831640294803086

Epoch: 5| Step: 5
Training loss: 1.5324175357818604
Validation loss: 2.3264947578471196

Epoch: 5| Step: 6
Training loss: 2.56245493888855
Validation loss: 2.3392593309443486

Epoch: 5| Step: 7
Training loss: 2.299959659576416
Validation loss: 2.2836226032626246

Epoch: 5| Step: 8
Training loss: 2.8626532554626465
Validation loss: 2.319901534306106

Epoch: 5| Step: 9
Training loss: 2.732513427734375
Validation loss: 2.3065434989108833

Epoch: 5| Step: 10
Training loss: 1.7022114992141724
Validation loss: 2.2867039557426208

Epoch: 85| Step: 0
Training loss: 2.0375514030456543
Validation loss: 2.309675888348651

Epoch: 5| Step: 1
Training loss: 2.162717580795288
Validation loss: 2.2414343972359934

Epoch: 5| Step: 2
Training loss: 2.5974974632263184
Validation loss: 2.302835761859853

Epoch: 5| Step: 3
Training loss: 2.1670353412628174
Validation loss: 2.2973701851342314

Epoch: 5| Step: 4
Training loss: 1.8380467891693115
Validation loss: 2.230893192752715

Epoch: 5| Step: 5
Training loss: 1.915578842163086
Validation loss: 2.3129845716620006

Epoch: 5| Step: 6
Training loss: 1.8049240112304688
Validation loss: 2.2794186005028347

Epoch: 5| Step: 7
Training loss: 2.8363311290740967
Validation loss: 2.265180021203974

Epoch: 5| Step: 8
Training loss: 3.141125440597534
Validation loss: 2.247569464868115

Epoch: 5| Step: 9
Training loss: 2.2287778854370117
Validation loss: 2.2516076795516478

Epoch: 5| Step: 10
Training loss: 2.7051193714141846
Validation loss: 2.2329532741218485

Epoch: 86| Step: 0
Training loss: 2.326183795928955
Validation loss: 2.2562737695632444

Epoch: 5| Step: 1
Training loss: 1.824231505393982
Validation loss: 2.276816250175558

Epoch: 5| Step: 2
Training loss: 2.2103216648101807
Validation loss: 2.240655924684258

Epoch: 5| Step: 3
Training loss: 2.1703062057495117
Validation loss: 2.2501928626850085

Epoch: 5| Step: 4
Training loss: 2.4691433906555176
Validation loss: 2.340640410300224

Epoch: 5| Step: 5
Training loss: 3.0984206199645996
Validation loss: 2.219146497787968

Epoch: 5| Step: 6
Training loss: 2.071322441101074
Validation loss: 2.2453440158597884

Epoch: 5| Step: 7
Training loss: 2.0547268390655518
Validation loss: 2.28475921897478

Epoch: 5| Step: 8
Training loss: 2.747061252593994
Validation loss: 2.2330268018989154

Epoch: 5| Step: 9
Training loss: 2.254450798034668
Validation loss: 2.207877698765006

Epoch: 5| Step: 10
Training loss: 2.0979764461517334
Validation loss: 2.18819954318385

Epoch: 87| Step: 0
Training loss: 2.0378594398498535
Validation loss: 2.237967892359662

Epoch: 5| Step: 1
Training loss: 2.0172722339630127
Validation loss: 2.169398543655231

Epoch: 5| Step: 2
Training loss: 2.1014645099639893
Validation loss: 2.264380572944559

Epoch: 5| Step: 3
Training loss: 1.74588942527771
Validation loss: 2.2684657266063075

Epoch: 5| Step: 4
Training loss: 3.0018436908721924
Validation loss: 2.2232255346031597

Epoch: 5| Step: 5
Training loss: 2.31487774848938
Validation loss: 2.289558313226187

Epoch: 5| Step: 6
Training loss: 2.04353666305542
Validation loss: 2.2374942302703857

Epoch: 5| Step: 7
Training loss: 2.906104564666748
Validation loss: 2.2841289735609487

Epoch: 5| Step: 8
Training loss: 2.4846866130828857
Validation loss: 2.24067400604166

Epoch: 5| Step: 9
Training loss: 2.191230058670044
Validation loss: 2.2647693311014483

Epoch: 5| Step: 10
Training loss: 2.146597146987915
Validation loss: 2.221202504250311

Epoch: 88| Step: 0
Training loss: 2.542240858078003
Validation loss: 2.2509696022156747

Epoch: 5| Step: 1
Training loss: 2.4072329998016357
Validation loss: 2.2970274238176245

Epoch: 5| Step: 2
Training loss: 2.2100393772125244
Validation loss: 2.2851125963272585

Epoch: 5| Step: 3
Training loss: 2.047417163848877
Validation loss: 2.284895953311715

Epoch: 5| Step: 4
Training loss: 2.006767749786377
Validation loss: 2.281567429983488

Epoch: 5| Step: 5
Training loss: 2.1679065227508545
Validation loss: 2.132846963021063

Epoch: 5| Step: 6
Training loss: 1.5533897876739502
Validation loss: 2.2651238210739626

Epoch: 5| Step: 7
Training loss: 2.655975818634033
Validation loss: 2.260915481916038

Epoch: 5| Step: 8
Training loss: 2.391890287399292
Validation loss: 2.2890333514059744

Epoch: 5| Step: 9
Training loss: 2.0680534839630127
Validation loss: 2.2172321747708064

Epoch: 5| Step: 10
Training loss: 2.1473968029022217
Validation loss: 2.3075478282026065

Epoch: 89| Step: 0
Training loss: 1.9094669818878174
Validation loss: 2.2984674592171945

Epoch: 5| Step: 1
Training loss: 2.0290496349334717
Validation loss: 2.2636170105267595

Epoch: 5| Step: 2
Training loss: 2.092094659805298
Validation loss: 2.2060470042690152

Epoch: 5| Step: 3
Training loss: 2.1677193641662598
Validation loss: 2.2479357014420214

Epoch: 5| Step: 4
Training loss: 1.8497467041015625
Validation loss: 2.2396955579839726

Epoch: 5| Step: 5
Training loss: 2.414979934692383
Validation loss: 2.324278188008134

Epoch: 5| Step: 6
Training loss: 2.8592851161956787
Validation loss: 2.3187704265758557

Epoch: 5| Step: 7
Training loss: 2.614763021469116
Validation loss: 2.274210876034152

Epoch: 5| Step: 8
Training loss: 2.4149715900421143
Validation loss: 2.328581153705556

Epoch: 5| Step: 9
Training loss: 2.0744118690490723
Validation loss: 2.2951291914909118

Epoch: 5| Step: 10
Training loss: 2.6095564365386963
Validation loss: 2.2612452301927792

Epoch: 90| Step: 0
Training loss: 2.2585721015930176
Validation loss: 2.334683972020303

Epoch: 5| Step: 1
Training loss: 1.891790747642517
Validation loss: 2.26113373233426

Epoch: 5| Step: 2
Training loss: 2.283475160598755
Validation loss: 2.2934302027507494

Epoch: 5| Step: 3
Training loss: 1.849077582359314
Validation loss: 2.2834936752114245

Epoch: 5| Step: 4
Training loss: 3.1761486530303955
Validation loss: 2.323537257409865

Epoch: 5| Step: 5
Training loss: 2.1494243144989014
Validation loss: 2.273036736314015

Epoch: 5| Step: 6
Training loss: 1.8396522998809814
Validation loss: 2.3429047369187876

Epoch: 5| Step: 7
Training loss: 2.980616807937622
Validation loss: 2.3029649026932253

Epoch: 5| Step: 8
Training loss: 2.459768772125244
Validation loss: 2.290531148192703

Epoch: 5| Step: 9
Training loss: 2.521735668182373
Validation loss: 2.2285135843420543

Epoch: 5| Step: 10
Training loss: 1.5716572999954224
Validation loss: 2.268699292213686

Epoch: 91| Step: 0
Training loss: 2.1946299076080322
Validation loss: 2.221634308497111

Epoch: 5| Step: 1
Training loss: 2.122616767883301
Validation loss: 2.338418386315787

Epoch: 5| Step: 2
Training loss: 3.1074256896972656
Validation loss: 2.200691907636581

Epoch: 5| Step: 3
Training loss: 1.7611854076385498
Validation loss: 2.198466465037356

Epoch: 5| Step: 4
Training loss: 2.316586971282959
Validation loss: 2.1973877286398285

Epoch: 5| Step: 5
Training loss: 2.3390674591064453
Validation loss: 2.304311070390927

Epoch: 5| Step: 6
Training loss: 2.0694003105163574
Validation loss: 2.217822374836091

Epoch: 5| Step: 7
Training loss: 1.4787534475326538
Validation loss: 2.2613037375993628

Epoch: 5| Step: 8
Training loss: 2.5367467403411865
Validation loss: 2.226724527215445

Epoch: 5| Step: 9
Training loss: 2.6179909706115723
Validation loss: 2.2910136663785545

Epoch: 5| Step: 10
Training loss: 2.404898166656494
Validation loss: 2.278854085553077

Epoch: 92| Step: 0
Training loss: 1.831580400466919
Validation loss: 2.3171768470477034

Epoch: 5| Step: 1
Training loss: 2.848330020904541
Validation loss: 2.2704367355633805

Epoch: 5| Step: 2
Training loss: 2.2729227542877197
Validation loss: 2.241705051032446

Epoch: 5| Step: 3
Training loss: 2.3428587913513184
Validation loss: 2.275345140887845

Epoch: 5| Step: 4
Training loss: 1.6397457122802734
Validation loss: 2.2324070494662047

Epoch: 5| Step: 5
Training loss: 2.257983922958374
Validation loss: 2.2746163927098757

Epoch: 5| Step: 6
Training loss: 2.4331166744232178
Validation loss: 2.2793953239276843

Epoch: 5| Step: 7
Training loss: 2.2152040004730225
Validation loss: 2.238282278019895

Epoch: 5| Step: 8
Training loss: 2.648275375366211
Validation loss: 2.2939016229362896

Epoch: 5| Step: 9
Training loss: 1.9580252170562744
Validation loss: 2.3305999284149497

Epoch: 5| Step: 10
Training loss: 3.0144217014312744
Validation loss: 2.205977955172139

Epoch: 93| Step: 0
Training loss: 2.5057692527770996
Validation loss: 2.2989688111889746

Epoch: 5| Step: 1
Training loss: 1.4198691844940186
Validation loss: 2.234495169372969

Epoch: 5| Step: 2
Training loss: 1.7562904357910156
Validation loss: 2.2419715119946386

Epoch: 5| Step: 3
Training loss: 1.7679321765899658
Validation loss: 2.256057793094266

Epoch: 5| Step: 4
Training loss: 2.42073130607605
Validation loss: 2.255910611921741

Epoch: 5| Step: 5
Training loss: 2.326508045196533
Validation loss: 2.2806249818494244

Epoch: 5| Step: 6
Training loss: 1.6761449575424194
Validation loss: 2.2521341103379444

Epoch: 5| Step: 7
Training loss: 2.9030022621154785
Validation loss: 2.262442209387338

Epoch: 5| Step: 8
Training loss: 2.551598310470581
Validation loss: 2.2130730459767003

Epoch: 5| Step: 9
Training loss: 2.770902156829834
Validation loss: 2.298208148248734

Epoch: 5| Step: 10
Training loss: 2.621382236480713
Validation loss: 2.268449496197444

Epoch: 94| Step: 0
Training loss: 2.541757583618164
Validation loss: 2.286231435755248

Epoch: 5| Step: 1
Training loss: 1.992893934249878
Validation loss: 2.2534482068912958

Epoch: 5| Step: 2
Training loss: 2.2415218353271484
Validation loss: 2.261077783441031

Epoch: 5| Step: 3
Training loss: 1.8831560611724854
Validation loss: 2.1990311312419113

Epoch: 5| Step: 4
Training loss: 1.959249496459961
Validation loss: 2.2752701261992097

Epoch: 5| Step: 5
Training loss: 2.824591875076294
Validation loss: 2.3439559526340936

Epoch: 5| Step: 6
Training loss: 2.126258134841919
Validation loss: 2.314701659705049

Epoch: 5| Step: 7
Training loss: 2.589003801345825
Validation loss: 2.211500051201031

Epoch: 5| Step: 8
Training loss: 1.7234166860580444
Validation loss: 2.158272192042361

Epoch: 5| Step: 9
Training loss: 2.616342067718506
Validation loss: 2.250981265498746

Epoch: 5| Step: 10
Training loss: 2.32047700881958
Validation loss: 2.212909319067514

Epoch: 95| Step: 0
Training loss: 2.5043046474456787
Validation loss: 2.1575266776546353

Epoch: 5| Step: 1
Training loss: 1.3351309299468994
Validation loss: 2.2170962159351637

Epoch: 5| Step: 2
Training loss: 2.2841992378234863
Validation loss: 2.2768372284468783

Epoch: 5| Step: 3
Training loss: 1.9996227025985718
Validation loss: 2.232694702763711

Epoch: 5| Step: 4
Training loss: 2.4584765434265137
Validation loss: 2.2664522406875447

Epoch: 5| Step: 5
Training loss: 2.2220113277435303
Validation loss: 2.2117918486236245

Epoch: 5| Step: 6
Training loss: 1.5994242429733276
Validation loss: 2.326778814356814

Epoch: 5| Step: 7
Training loss: 2.934464931488037
Validation loss: 2.302810271581014

Epoch: 5| Step: 8
Training loss: 2.4510059356689453
Validation loss: 2.319964813929732

Epoch: 5| Step: 9
Training loss: 2.553715705871582
Validation loss: 2.257593362562118

Epoch: 5| Step: 10
Training loss: 2.5487663745880127
Validation loss: 2.204367859389192

Epoch: 96| Step: 0
Training loss: 2.509056806564331
Validation loss: 2.178408025413431

Epoch: 5| Step: 1
Training loss: 2.8962223529815674
Validation loss: 2.1789580045207853

Epoch: 5| Step: 2
Training loss: 2.6459720134735107
Validation loss: 2.3090455250073503

Epoch: 5| Step: 3
Training loss: 2.0331342220306396
Validation loss: 2.166494138779179

Epoch: 5| Step: 4
Training loss: 2.393425464630127
Validation loss: 2.2294134452778804

Epoch: 5| Step: 5
Training loss: 2.4242780208587646
Validation loss: 2.2593663405346613

Epoch: 5| Step: 6
Training loss: 2.0866479873657227
Validation loss: 2.2577871122667865

Epoch: 5| Step: 7
Training loss: 1.2267194986343384
Validation loss: 2.2557691912497244

Epoch: 5| Step: 8
Training loss: 1.782627820968628
Validation loss: 2.295317398604526

Epoch: 5| Step: 9
Training loss: 2.523516893386841
Validation loss: 2.276698929007335

Epoch: 5| Step: 10
Training loss: 2.156780958175659
Validation loss: 2.2027664440934376

Epoch: 97| Step: 0
Training loss: 2.6010355949401855
Validation loss: 2.2338306032201296

Epoch: 5| Step: 1
Training loss: 1.774291753768921
Validation loss: 2.283539825870145

Epoch: 5| Step: 2
Training loss: 2.91286563873291
Validation loss: 2.2394631908785914

Epoch: 5| Step: 3
Training loss: 2.768315553665161
Validation loss: 2.1961650784297655

Epoch: 5| Step: 4
Training loss: 2.0767674446105957
Validation loss: 2.232118096402896

Epoch: 5| Step: 5
Training loss: 2.036618709564209
Validation loss: 2.21714662736462

Epoch: 5| Step: 6
Training loss: 2.680492877960205
Validation loss: 2.349645827406196

Epoch: 5| Step: 7
Training loss: 1.9116710424423218
Validation loss: 2.236136269825761

Epoch: 5| Step: 8
Training loss: 2.1789915561676025
Validation loss: 2.2587969277494695

Epoch: 5| Step: 9
Training loss: 1.8906917572021484
Validation loss: 2.2338123013896327

Epoch: 5| Step: 10
Training loss: 2.159193992614746
Validation loss: 2.2957565194817

Epoch: 98| Step: 0
Training loss: 2.96679425239563
Validation loss: 2.288401872880997

Epoch: 5| Step: 1
Training loss: 2.4614691734313965
Validation loss: 2.216948950162498

Epoch: 5| Step: 2
Training loss: 2.541717052459717
Validation loss: 2.3578476700731503

Epoch: 5| Step: 3
Training loss: 2.2154650688171387
Validation loss: 2.2233600847182737

Epoch: 5| Step: 4
Training loss: 2.3375604152679443
Validation loss: 2.219651088919691

Epoch: 5| Step: 5
Training loss: 1.834271788597107
Validation loss: 2.2459636119104203

Epoch: 5| Step: 6
Training loss: 2.212634563446045
Validation loss: 2.2326117779618952

Epoch: 5| Step: 7
Training loss: 1.963097333908081
Validation loss: 2.235872266113117

Epoch: 5| Step: 8
Training loss: 2.6400015354156494
Validation loss: 2.2020113878352667

Epoch: 5| Step: 9
Training loss: 1.4645373821258545
Validation loss: 2.157366430887612

Epoch: 5| Step: 10
Training loss: 2.3513500690460205
Validation loss: 2.2261650562286377

Epoch: 99| Step: 0
Training loss: 1.8715927600860596
Validation loss: 2.2434132996425835

Epoch: 5| Step: 1
Training loss: 2.408191204071045
Validation loss: 2.2115987821291854

Epoch: 5| Step: 2
Training loss: 2.3619909286499023
Validation loss: 2.2573370138804116

Epoch: 5| Step: 3
Training loss: 2.192844867706299
Validation loss: 2.2307023156073784

Epoch: 5| Step: 4
Training loss: 2.3283143043518066
Validation loss: 2.2202497451536116

Epoch: 5| Step: 5
Training loss: 1.9537551403045654
Validation loss: 2.2569602433071343

Epoch: 5| Step: 6
Training loss: 1.9627578258514404
Validation loss: 2.2339932405820457

Epoch: 5| Step: 7
Training loss: 3.1058130264282227
Validation loss: 2.244236410305064

Epoch: 5| Step: 8
Training loss: 2.236823558807373
Validation loss: 2.190806593946231

Epoch: 5| Step: 9
Training loss: 2.671238660812378
Validation loss: 2.2320416640209895

Epoch: 5| Step: 10
Training loss: 1.892956256866455
Validation loss: 2.2615460183030818

Epoch: 100| Step: 0
Training loss: 2.414395809173584
Validation loss: 2.2785445618373092

Epoch: 5| Step: 1
Training loss: 2.2080395221710205
Validation loss: 2.153909762700399

Epoch: 5| Step: 2
Training loss: 1.8184566497802734
Validation loss: 2.1932100275511384

Epoch: 5| Step: 3
Training loss: 2.7911438941955566
Validation loss: 2.2659187855259066

Epoch: 5| Step: 4
Training loss: 2.241187334060669
Validation loss: 2.1871593588141987

Epoch: 5| Step: 5
Training loss: 1.6669151782989502
Validation loss: 2.255021869495351

Epoch: 5| Step: 6
Training loss: 2.0675058364868164
Validation loss: 2.2202061273718394

Epoch: 5| Step: 7
Training loss: 1.9826056957244873
Validation loss: 2.259765819836688

Epoch: 5| Step: 8
Training loss: 2.0540659427642822
Validation loss: 2.1800781065417874

Epoch: 5| Step: 9
Training loss: 1.9122062921524048
Validation loss: 2.2401110920854794

Epoch: 5| Step: 10
Training loss: 3.40075421333313
Validation loss: 2.2247068651260866

Epoch: 101| Step: 0
Training loss: 1.8813167810440063
Validation loss: 2.283664834114813

Epoch: 5| Step: 1
Training loss: 2.295896053314209
Validation loss: 2.2444765234506256

Epoch: 5| Step: 2
Training loss: 1.8648006916046143
Validation loss: 2.258882032927646

Epoch: 5| Step: 3
Training loss: 2.336578845977783
Validation loss: 2.2497018127031225

Epoch: 5| Step: 4
Training loss: 2.491428852081299
Validation loss: 2.2795310892084593

Epoch: 5| Step: 5
Training loss: 2.4930176734924316
Validation loss: 2.2320537387683825

Epoch: 5| Step: 6
Training loss: 2.3398187160491943
Validation loss: 2.28931551466706

Epoch: 5| Step: 7
Training loss: 2.9257450103759766
Validation loss: 2.2355459402966242

Epoch: 5| Step: 8
Training loss: 2.1939315795898438
Validation loss: 2.244023512768489

Epoch: 5| Step: 9
Training loss: 1.8496806621551514
Validation loss: 2.271535514503397

Epoch: 5| Step: 10
Training loss: 2.0914103984832764
Validation loss: 2.2190637703864806

Epoch: 102| Step: 0
Training loss: 2.1074295043945312
Validation loss: 2.2147549659975114

Epoch: 5| Step: 1
Training loss: 2.4548442363739014
Validation loss: 2.27891771511365

Epoch: 5| Step: 2
Training loss: 2.299978494644165
Validation loss: 2.19319906157832

Epoch: 5| Step: 3
Training loss: 2.310215473175049
Validation loss: 2.225714910414911

Epoch: 5| Step: 4
Training loss: 2.252655267715454
Validation loss: 2.189350128173828

Epoch: 5| Step: 5
Training loss: 1.6970951557159424
Validation loss: 2.300290448691255

Epoch: 5| Step: 6
Training loss: 2.2932770252227783
Validation loss: 2.203809875313954

Epoch: 5| Step: 7
Training loss: 2.7492077350616455
Validation loss: 2.280920881097035

Epoch: 5| Step: 8
Training loss: 1.5170007944107056
Validation loss: 2.2581556330444994

Epoch: 5| Step: 9
Training loss: 2.430060863494873
Validation loss: 2.2508832844354774

Epoch: 5| Step: 10
Training loss: 2.5647835731506348
Validation loss: 2.252454828190547

Epoch: 103| Step: 0
Training loss: 2.345353364944458
Validation loss: 2.252677535498014

Epoch: 5| Step: 1
Training loss: 2.196671485900879
Validation loss: 2.185607969119985

Epoch: 5| Step: 2
Training loss: 1.8862850666046143
Validation loss: 2.279427272017284

Epoch: 5| Step: 3
Training loss: 2.58663010597229
Validation loss: 2.252951337445167

Epoch: 5| Step: 4
Training loss: 2.4015514850616455
Validation loss: 2.2169927755991616

Epoch: 5| Step: 5
Training loss: 2.173267126083374
Validation loss: 2.2414248246018604

Epoch: 5| Step: 6
Training loss: 2.4750657081604004
Validation loss: 2.180905560011505

Epoch: 5| Step: 7
Training loss: 2.3590667247772217
Validation loss: 2.2998629411061606

Epoch: 5| Step: 8
Training loss: 1.8008053302764893
Validation loss: 2.290030748613419

Epoch: 5| Step: 9
Training loss: 1.7530059814453125
Validation loss: 2.3040892078030493

Epoch: 5| Step: 10
Training loss: 3.0151453018188477
Validation loss: 2.216532217558994

Epoch: 104| Step: 0
Training loss: 2.4007153511047363
Validation loss: 2.230303930979903

Epoch: 5| Step: 1
Training loss: 2.0853512287139893
Validation loss: 2.331534460026731

Epoch: 5| Step: 2
Training loss: 1.9584583044052124
Validation loss: 2.261199853753531

Epoch: 5| Step: 3
Training loss: 2.1335091590881348
Validation loss: 2.347348964342507

Epoch: 5| Step: 4
Training loss: 2.825705051422119
Validation loss: 2.2468150636201263

Epoch: 5| Step: 5
Training loss: 2.5298960208892822
Validation loss: 2.244390418452601

Epoch: 5| Step: 6
Training loss: 2.0022969245910645
Validation loss: 2.2163096884245514

Epoch: 5| Step: 7
Training loss: 2.002361536026001
Validation loss: 2.2226345077637704

Epoch: 5| Step: 8
Training loss: 1.7616914510726929
Validation loss: 2.3057670747080157

Epoch: 5| Step: 9
Training loss: 2.453439235687256
Validation loss: 2.2205641295320246

Epoch: 5| Step: 10
Training loss: 2.987447738647461
Validation loss: 2.258265620918684

Epoch: 105| Step: 0
Training loss: 1.5898754596710205
Validation loss: 2.2451253949954944

Epoch: 5| Step: 1
Training loss: 2.277738094329834
Validation loss: 2.2865247854622464

Epoch: 5| Step: 2
Training loss: 2.016796350479126
Validation loss: 2.2598039181001726

Epoch: 5| Step: 3
Training loss: 2.7518978118896484
Validation loss: 2.2239545417088333

Epoch: 5| Step: 4
Training loss: 3.099562406539917
Validation loss: 2.2252609165765906

Epoch: 5| Step: 5
Training loss: 1.8110997676849365
Validation loss: 2.2600619023846042

Epoch: 5| Step: 6
Training loss: 2.5652518272399902
Validation loss: 2.254307628959738

Epoch: 5| Step: 7
Training loss: 2.5137438774108887
Validation loss: 2.252602918173677

Epoch: 5| Step: 8
Training loss: 1.6714614629745483
Validation loss: 2.2082986370209725

Epoch: 5| Step: 9
Training loss: 2.6216378211975098
Validation loss: 2.301076655746788

Epoch: 5| Step: 10
Training loss: 1.6358011960983276
Validation loss: 2.177971229758314

Epoch: 106| Step: 0
Training loss: 2.4327025413513184
Validation loss: 2.2569550121984174

Epoch: 5| Step: 1
Training loss: 2.0755937099456787
Validation loss: 2.2437455884871946

Epoch: 5| Step: 2
Training loss: 1.3083974123001099
Validation loss: 2.24821049679992

Epoch: 5| Step: 3
Training loss: 2.5938661098480225
Validation loss: 2.2400475727614535

Epoch: 5| Step: 4
Training loss: 2.0620014667510986
Validation loss: 2.276244250676965

Epoch: 5| Step: 5
Training loss: 1.7355304956436157
Validation loss: 2.2643938218393633

Epoch: 5| Step: 6
Training loss: 1.984108328819275
Validation loss: 2.2203587126988236

Epoch: 5| Step: 7
Training loss: 3.2417073249816895
Validation loss: 2.2281843334115963

Epoch: 5| Step: 8
Training loss: 1.9084761142730713
Validation loss: 2.266011045825097

Epoch: 5| Step: 9
Training loss: 3.1219842433929443
Validation loss: 2.2810428142547607

Epoch: 5| Step: 10
Training loss: 1.7179523706436157
Validation loss: 2.2521297700943483

Epoch: 107| Step: 0
Training loss: 2.2000679969787598
Validation loss: 2.2436085234406176

Epoch: 5| Step: 1
Training loss: 2.3089852333068848
Validation loss: 2.215628557307746

Epoch: 5| Step: 2
Training loss: 2.118765354156494
Validation loss: 2.232762300839988

Epoch: 5| Step: 3
Training loss: 2.487152576446533
Validation loss: 2.1933185003137075

Epoch: 5| Step: 4
Training loss: 2.0158255100250244
Validation loss: 2.30448680667467

Epoch: 5| Step: 5
Training loss: 2.410606861114502
Validation loss: 2.1776736295351418

Epoch: 5| Step: 6
Training loss: 1.6798652410507202
Validation loss: 2.229976600216281

Epoch: 5| Step: 7
Training loss: 2.139195442199707
Validation loss: 2.2543423765449115

Epoch: 5| Step: 8
Training loss: 2.4380805492401123
Validation loss: 2.236345734647525

Epoch: 5| Step: 9
Training loss: 1.9347070455551147
Validation loss: 2.1976995929594962

Epoch: 5| Step: 10
Training loss: 2.588124990463257
Validation loss: 2.2725429996367423

Epoch: 108| Step: 0
Training loss: 2.1684422492980957
Validation loss: 2.2345415469138854

Epoch: 5| Step: 1
Training loss: 2.6162688732147217
Validation loss: 2.197650586405108

Epoch: 5| Step: 2
Training loss: 2.586475133895874
Validation loss: 2.2014932170990975

Epoch: 5| Step: 3
Training loss: 2.3372509479522705
Validation loss: 2.293276766295074

Epoch: 5| Step: 4
Training loss: 2.018601417541504
Validation loss: 2.336251494705036

Epoch: 5| Step: 5
Training loss: 2.218744993209839
Validation loss: 2.2058766580397084

Epoch: 5| Step: 6
Training loss: 2.5778651237487793
Validation loss: 2.275982206867587

Epoch: 5| Step: 7
Training loss: 2.285205602645874
Validation loss: 2.254891013586393

Epoch: 5| Step: 8
Training loss: 1.7966152429580688
Validation loss: 2.2372875931442424

Epoch: 5| Step: 9
Training loss: 2.360140562057495
Validation loss: 2.2118109913282495

Epoch: 5| Step: 10
Training loss: 1.6447913646697998
Validation loss: 2.2402143273302304

Epoch: 109| Step: 0
Training loss: 2.3378281593322754
Validation loss: 2.218448431261124

Epoch: 5| Step: 1
Training loss: 2.625453233718872
Validation loss: 2.2718189044665267

Epoch: 5| Step: 2
Training loss: 2.6282896995544434
Validation loss: 2.354093708017821

Epoch: 5| Step: 3
Training loss: 1.8248612880706787
Validation loss: 2.195396725849439

Epoch: 5| Step: 4
Training loss: 2.2518041133880615
Validation loss: 2.1481491442649596

Epoch: 5| Step: 5
Training loss: 1.1108057498931885
Validation loss: 2.3012274016616163

Epoch: 5| Step: 6
Training loss: 2.7791249752044678
Validation loss: 2.206794866951563

Epoch: 5| Step: 7
Training loss: 1.9879300594329834
Validation loss: 2.289399782816569

Epoch: 5| Step: 8
Training loss: 2.460756778717041
Validation loss: 2.2581597271785943

Epoch: 5| Step: 9
Training loss: 2.269806385040283
Validation loss: 2.217965410601708

Epoch: 5| Step: 10
Training loss: 2.1527483463287354
Validation loss: 2.2165368026302708

Epoch: 110| Step: 0
Training loss: 2.001391887664795
Validation loss: 2.212202428489603

Epoch: 5| Step: 1
Training loss: 1.8764604330062866
Validation loss: 2.209529120434997

Epoch: 5| Step: 2
Training loss: 2.303337574005127
Validation loss: 2.212745302466936

Epoch: 5| Step: 3
Training loss: 2.1416690349578857
Validation loss: 2.2265595492496284

Epoch: 5| Step: 4
Training loss: 2.645329713821411
Validation loss: 2.1697353342527985

Epoch: 5| Step: 5
Training loss: 2.2563724517822266
Validation loss: 2.1682203867102183

Epoch: 5| Step: 6
Training loss: 2.125000476837158
Validation loss: 2.2168152639942784

Epoch: 5| Step: 7
Training loss: 2.329350233078003
Validation loss: 2.176965029008927

Epoch: 5| Step: 8
Training loss: 2.6913466453552246
Validation loss: 2.1698536411408456

Epoch: 5| Step: 9
Training loss: 2.087740659713745
Validation loss: 2.29816492783126

Epoch: 5| Step: 10
Training loss: 1.7921137809753418
Validation loss: 2.070547834519417

Epoch: 111| Step: 0
Training loss: 1.7086416482925415
Validation loss: 2.2579705792088665

Epoch: 5| Step: 1
Training loss: 2.241093397140503
Validation loss: 2.26531615308536

Epoch: 5| Step: 2
Training loss: 2.6151909828186035
Validation loss: 2.244669992436645

Epoch: 5| Step: 3
Training loss: 2.51493501663208
Validation loss: 2.144692685014458

Epoch: 5| Step: 4
Training loss: 1.7946052551269531
Validation loss: 2.164616956505724

Epoch: 5| Step: 5
Training loss: 1.955341100692749
Validation loss: 2.28162222011115

Epoch: 5| Step: 6
Training loss: 2.5983059406280518
Validation loss: 2.1985760927200317

Epoch: 5| Step: 7
Training loss: 1.9824053049087524
Validation loss: 2.1946543749942573

Epoch: 5| Step: 8
Training loss: 3.089925527572632
Validation loss: 2.163248126224805

Epoch: 5| Step: 9
Training loss: 1.407606840133667
Validation loss: 2.30065260394927

Epoch: 5| Step: 10
Training loss: 2.6577091217041016
Validation loss: 2.321895008446068

Epoch: 112| Step: 0
Training loss: 2.7051894664764404
Validation loss: 2.2497881984197967

Epoch: 5| Step: 1
Training loss: 2.5051865577697754
Validation loss: 2.2187737264940814

Epoch: 5| Step: 2
Training loss: 2.5807993412017822
Validation loss: 2.258503665206253

Epoch: 5| Step: 3
Training loss: 1.8759727478027344
Validation loss: 2.2090625993667112

Epoch: 5| Step: 4
Training loss: 1.8433119058609009
Validation loss: 2.257297408196234

Epoch: 5| Step: 5
Training loss: 2.142035961151123
Validation loss: 2.2376146162709882

Epoch: 5| Step: 6
Training loss: 1.816872000694275
Validation loss: 2.117105371208601

Epoch: 5| Step: 7
Training loss: 1.9435672760009766
Validation loss: 2.2681007949254846

Epoch: 5| Step: 8
Training loss: 2.123997926712036
Validation loss: 2.304300597918931

Epoch: 5| Step: 9
Training loss: 1.9809211492538452
Validation loss: 2.1784406464586974

Epoch: 5| Step: 10
Training loss: 2.7130486965179443
Validation loss: 2.20081284610174

Epoch: 113| Step: 0
Training loss: 2.6481070518493652
Validation loss: 2.1967320442199707

Epoch: 5| Step: 1
Training loss: 2.7675867080688477
Validation loss: 2.3255836681653093

Epoch: 5| Step: 2
Training loss: 2.2124218940734863
Validation loss: 2.2606058953910746

Epoch: 5| Step: 3
Training loss: 2.1097898483276367
Validation loss: 2.2749000813371394

Epoch: 5| Step: 4
Training loss: 1.9730041027069092
Validation loss: 2.1871869871693272

Epoch: 5| Step: 5
Training loss: 2.96838641166687
Validation loss: 2.294271166606616

Epoch: 5| Step: 6
Training loss: 2.119450569152832
Validation loss: 2.200288277800365

Epoch: 5| Step: 7
Training loss: 1.9039287567138672
Validation loss: 2.225475449715891

Epoch: 5| Step: 8
Training loss: 1.6547129154205322
Validation loss: 2.2593665674168575

Epoch: 5| Step: 9
Training loss: 1.992121696472168
Validation loss: 2.3163665802248063

Epoch: 5| Step: 10
Training loss: 2.1326398849487305
Validation loss: 2.2998527506346345

Epoch: 114| Step: 0
Training loss: 1.8901039361953735
Validation loss: 2.2771639465003886

Epoch: 5| Step: 1
Training loss: 2.161532163619995
Validation loss: 2.2236429798987603

Epoch: 5| Step: 2
Training loss: 2.064702033996582
Validation loss: 2.219298942114717

Epoch: 5| Step: 3
Training loss: 2.6025185585021973
Validation loss: 2.2238763122148413

Epoch: 5| Step: 4
Training loss: 3.0545315742492676
Validation loss: 2.2095215192405124

Epoch: 5| Step: 5
Training loss: 2.2812957763671875
Validation loss: 2.3130651033052834

Epoch: 5| Step: 6
Training loss: 1.9715652465820312
Validation loss: 2.2281060244447444

Epoch: 5| Step: 7
Training loss: 2.205204486846924
Validation loss: 2.287418468024141

Epoch: 5| Step: 8
Training loss: 2.0563740730285645
Validation loss: 2.230310106790194

Epoch: 5| Step: 9
Training loss: 2.23579478263855
Validation loss: 2.177246573150799

Epoch: 5| Step: 10
Training loss: 2.038065195083618
Validation loss: 2.3015844719384306

Epoch: 115| Step: 0
Training loss: 1.7135868072509766
Validation loss: 2.2468662159417265

Epoch: 5| Step: 1
Training loss: 2.187145233154297
Validation loss: 2.238144208026189

Epoch: 5| Step: 2
Training loss: 2.2944092750549316
Validation loss: 2.2250736759554957

Epoch: 5| Step: 3
Training loss: 1.7747081518173218
Validation loss: 2.204238704455796

Epoch: 5| Step: 4
Training loss: 1.7558071613311768
Validation loss: 2.282684664572439

Epoch: 5| Step: 5
Training loss: 2.170320987701416
Validation loss: 2.2689439942759853

Epoch: 5| Step: 6
Training loss: 2.209719181060791
Validation loss: 2.26471443586452

Epoch: 5| Step: 7
Training loss: 2.23633074760437
Validation loss: 2.2052805628827823

Epoch: 5| Step: 8
Training loss: 2.3457541465759277
Validation loss: 2.2316673160881124

Epoch: 5| Step: 9
Training loss: 3.038419723510742
Validation loss: 2.2042320979538785

Epoch: 5| Step: 10
Training loss: 2.2798986434936523
Validation loss: 2.276597756211476

Epoch: 116| Step: 0
Training loss: 2.6478352546691895
Validation loss: 2.2131865204021497

Epoch: 5| Step: 1
Training loss: 2.1771044731140137
Validation loss: 2.217981974283854

Epoch: 5| Step: 2
Training loss: 2.0674967765808105
Validation loss: 2.1331128458822928

Epoch: 5| Step: 3
Training loss: 2.46254563331604
Validation loss: 2.2201536650298745

Epoch: 5| Step: 4
Training loss: 2.6709353923797607
Validation loss: 2.224547193896386

Epoch: 5| Step: 5
Training loss: 1.8642528057098389
Validation loss: 2.17127501580023

Epoch: 5| Step: 6
Training loss: 1.7811346054077148
Validation loss: 2.187957207361857

Epoch: 5| Step: 7
Training loss: 2.267925262451172
Validation loss: 2.22012310899714

Epoch: 5| Step: 8
Training loss: 2.0289769172668457
Validation loss: 2.296081881369314

Epoch: 5| Step: 9
Training loss: 2.4313416481018066
Validation loss: 2.1863557446387505

Epoch: 5| Step: 10
Training loss: 2.2695698738098145
Validation loss: 2.19772994390098

Epoch: 117| Step: 0
Training loss: 2.160244941711426
Validation loss: 2.2264839218508814

Epoch: 5| Step: 1
Training loss: 2.73944354057312
Validation loss: 2.196843868942671

Epoch: 5| Step: 2
Training loss: 2.20253324508667
Validation loss: 2.19762078408272

Epoch: 5| Step: 3
Training loss: 2.0140650272369385
Validation loss: 2.3072169467967045

Epoch: 5| Step: 4
Training loss: 2.27121901512146
Validation loss: 2.2940925449453373

Epoch: 5| Step: 5
Training loss: 2.081695079803467
Validation loss: 2.1932840014016755

Epoch: 5| Step: 6
Training loss: 1.8186781406402588
Validation loss: 2.2525952990337084

Epoch: 5| Step: 7
Training loss: 2.4823334217071533
Validation loss: 2.2678990351256503

Epoch: 5| Step: 8
Training loss: 1.946793794631958
Validation loss: 2.230192712558213

Epoch: 5| Step: 9
Training loss: 2.3547046184539795
Validation loss: 2.262166661600913

Epoch: 5| Step: 10
Training loss: 2.7311394214630127
Validation loss: 2.268625100453695

Epoch: 118| Step: 0
Training loss: 2.606067180633545
Validation loss: 2.191495427521326

Epoch: 5| Step: 1
Training loss: 1.5845247507095337
Validation loss: 2.2474655156494467

Epoch: 5| Step: 2
Training loss: 3.026933431625366
Validation loss: 2.281107989690637

Epoch: 5| Step: 3
Training loss: 1.6614010334014893
Validation loss: 2.192624730448569

Epoch: 5| Step: 4
Training loss: 2.375033140182495
Validation loss: 2.271533017517418

Epoch: 5| Step: 5
Training loss: 2.299152374267578
Validation loss: 2.290484195114464

Epoch: 5| Step: 6
Training loss: 1.5291846990585327
Validation loss: 2.1715921791650916

Epoch: 5| Step: 7
Training loss: 2.0578174591064453
Validation loss: 2.2533141836043327

Epoch: 5| Step: 8
Training loss: 2.0112438201904297
Validation loss: 2.1520010681562525

Epoch: 5| Step: 9
Training loss: 2.9619193077087402
Validation loss: 2.35548887970627

Epoch: 5| Step: 10
Training loss: 2.697821855545044
Validation loss: 2.195575062946607

Epoch: 119| Step: 0
Training loss: 1.9890416860580444
Validation loss: 2.257888755490703

Epoch: 5| Step: 1
Training loss: 2.445681095123291
Validation loss: 2.3254220562596477

Epoch: 5| Step: 2
Training loss: 2.0189461708068848
Validation loss: 2.2425488477112143

Epoch: 5| Step: 3
Training loss: 2.1970770359039307
Validation loss: 2.1823201999869397

Epoch: 5| Step: 4
Training loss: 2.266801118850708
Validation loss: 2.23429637570535

Epoch: 5| Step: 5
Training loss: 2.44085431098938
Validation loss: 2.135580637121713

Epoch: 5| Step: 6
Training loss: 1.8732242584228516
Validation loss: 2.179592445332517

Epoch: 5| Step: 7
Training loss: 2.921506404876709
Validation loss: 2.263167388977543

Epoch: 5| Step: 8
Training loss: 1.9954439401626587
Validation loss: 2.26731417768745

Epoch: 5| Step: 9
Training loss: 2.5315451622009277
Validation loss: 2.1909640835177515

Epoch: 5| Step: 10
Training loss: 2.1102190017700195
Validation loss: 2.1672172930932816

Epoch: 120| Step: 0
Training loss: 2.292680263519287
Validation loss: 2.2581967666584957

Epoch: 5| Step: 1
Training loss: 2.6267104148864746
Validation loss: 2.2019759839580906

Epoch: 5| Step: 2
Training loss: 2.0712995529174805
Validation loss: 2.232892874748476

Epoch: 5| Step: 3
Training loss: 2.2731661796569824
Validation loss: 2.2549021936232045

Epoch: 5| Step: 4
Training loss: 2.051663637161255
Validation loss: 2.217138454478274

Epoch: 5| Step: 5
Training loss: 1.8669395446777344
Validation loss: 2.2417045177951938

Epoch: 5| Step: 6
Training loss: 2.1730682849884033
Validation loss: 2.1812425569821428

Epoch: 5| Step: 7
Training loss: 2.1128249168395996
Validation loss: 2.1502690392155803

Epoch: 5| Step: 8
Training loss: 1.8548543453216553
Validation loss: 2.210756363407258

Epoch: 5| Step: 9
Training loss: 2.3486790657043457
Validation loss: 2.1866728823672057

Epoch: 5| Step: 10
Training loss: 2.511655569076538
Validation loss: 2.158619003911172

Epoch: 121| Step: 0
Training loss: 2.3823065757751465
Validation loss: 2.2503229110471663

Epoch: 5| Step: 1
Training loss: 1.8788360357284546
Validation loss: 2.1964053876938356

Epoch: 5| Step: 2
Training loss: 1.9797970056533813
Validation loss: 2.2787669525351575

Epoch: 5| Step: 3
Training loss: 2.049886465072632
Validation loss: 2.1395743059855636

Epoch: 5| Step: 4
Training loss: 2.5531973838806152
Validation loss: 2.2279360807070168

Epoch: 5| Step: 5
Training loss: 2.4706459045410156
Validation loss: 2.123559856927523

Epoch: 5| Step: 6
Training loss: 2.682690382003784
Validation loss: 2.2708872082412883

Epoch: 5| Step: 7
Training loss: 1.5242773294448853
Validation loss: 2.178519692472232

Epoch: 5| Step: 8
Training loss: 2.100515365600586
Validation loss: 2.2715416364772345

Epoch: 5| Step: 9
Training loss: 2.2052104473114014
Validation loss: 2.2395788879804712

Epoch: 5| Step: 10
Training loss: 2.477607011795044
Validation loss: 2.2105170372993714

Epoch: 122| Step: 0
Training loss: 2.6388509273529053
Validation loss: 2.224556202529579

Epoch: 5| Step: 1
Training loss: 2.323482036590576
Validation loss: 2.257718188788301

Epoch: 5| Step: 2
Training loss: 1.7695728540420532
Validation loss: 2.232923892236525

Epoch: 5| Step: 3
Training loss: 2.173307418823242
Validation loss: 2.1737975112853514

Epoch: 5| Step: 4
Training loss: 2.0241382122039795
Validation loss: 2.237574879841138

Epoch: 5| Step: 5
Training loss: 2.6035685539245605
Validation loss: 2.1984053222081994

Epoch: 5| Step: 6
Training loss: 1.614423394203186
Validation loss: 2.2084927033352595

Epoch: 5| Step: 7
Training loss: 1.972188949584961
Validation loss: 2.232837132228318

Epoch: 5| Step: 8
Training loss: 2.75679087638855
Validation loss: 2.3441255874531244

Epoch: 5| Step: 9
Training loss: 2.4987564086914062
Validation loss: 2.2167710232478317

Epoch: 5| Step: 10
Training loss: 2.1361727714538574
Validation loss: 2.1719478138031496

Epoch: 123| Step: 0
Training loss: 2.5879006385803223
Validation loss: 2.2298120503784506

Epoch: 5| Step: 1
Training loss: 1.9861472845077515
Validation loss: 2.19282393558051

Epoch: 5| Step: 2
Training loss: 2.5037083625793457
Validation loss: 2.271738806078511

Epoch: 5| Step: 3
Training loss: 2.1084394454956055
Validation loss: 2.2017769723810177

Epoch: 5| Step: 4
Training loss: 1.9683711528778076
Validation loss: 2.2199756560787076

Epoch: 5| Step: 5
Training loss: 2.658268451690674
Validation loss: 2.265232168218141

Epoch: 5| Step: 6
Training loss: 1.7683013677597046
Validation loss: 2.240073178404121

Epoch: 5| Step: 7
Training loss: 1.721970796585083
Validation loss: 2.2576096032255437

Epoch: 5| Step: 8
Training loss: 2.0832605361938477
Validation loss: 2.119414947366202

Epoch: 5| Step: 9
Training loss: 2.2504804134368896
Validation loss: 2.2167630759618615

Epoch: 5| Step: 10
Training loss: 2.760239601135254
Validation loss: 2.1959997761634087

Epoch: 124| Step: 0
Training loss: 2.3691554069519043
Validation loss: 2.2512577592685656

Epoch: 5| Step: 1
Training loss: 2.4286084175109863
Validation loss: 2.2380376477395334

Epoch: 5| Step: 2
Training loss: 2.2830398082733154
Validation loss: 2.2235875373245566

Epoch: 5| Step: 3
Training loss: 1.9292755126953125
Validation loss: 2.1987038504692817

Epoch: 5| Step: 4
Training loss: 2.5390398502349854
Validation loss: 2.2141628009016796

Epoch: 5| Step: 5
Training loss: 1.8499492406845093
Validation loss: 2.2176631163525324

Epoch: 5| Step: 6
Training loss: 1.810490369796753
Validation loss: 2.166490788100868

Epoch: 5| Step: 7
Training loss: 2.176696300506592
Validation loss: 2.204431136449178

Epoch: 5| Step: 8
Training loss: 1.7002904415130615
Validation loss: 2.177579192705052

Epoch: 5| Step: 9
Training loss: 2.1412863731384277
Validation loss: 2.1860515943137546

Epoch: 5| Step: 10
Training loss: 3.102503776550293
Validation loss: 2.2439501516280638

Epoch: 125| Step: 0
Training loss: 2.082960844039917
Validation loss: 2.2189130347262145

Epoch: 5| Step: 1
Training loss: 2.284728765487671
Validation loss: 2.14928404490153

Epoch: 5| Step: 2
Training loss: 2.2872395515441895
Validation loss: 2.228228957422318

Epoch: 5| Step: 3
Training loss: 2.361372709274292
Validation loss: 2.2389630066451205

Epoch: 5| Step: 4
Training loss: 2.203129291534424
Validation loss: 2.209040113674697

Epoch: 5| Step: 5
Training loss: 3.1117234230041504
Validation loss: 2.1210503103912517

Epoch: 5| Step: 6
Training loss: 2.355210781097412
Validation loss: 2.229181774200932

Epoch: 5| Step: 7
Training loss: 2.4652814865112305
Validation loss: 2.2150574448288127

Epoch: 5| Step: 8
Training loss: 1.8189136981964111
Validation loss: 2.170860298218266

Epoch: 5| Step: 9
Training loss: 1.8156168460845947
Validation loss: 2.294950141701647

Epoch: 5| Step: 10
Training loss: 1.4389969110488892
Validation loss: 2.1986912604301208

Epoch: 126| Step: 0
Training loss: 2.643378973007202
Validation loss: 2.1648400932229976

Epoch: 5| Step: 1
Training loss: 2.5511443614959717
Validation loss: 2.1831191252636653

Epoch: 5| Step: 2
Training loss: 2.2697978019714355
Validation loss: 2.168988388071778

Epoch: 5| Step: 3
Training loss: 2.438383102416992
Validation loss: 2.1435969029703448

Epoch: 5| Step: 4
Training loss: 2.5942981243133545
Validation loss: 2.1763456303586244

Epoch: 5| Step: 5
Training loss: 2.4142205715179443
Validation loss: 2.1319524985487743

Epoch: 5| Step: 6
Training loss: 2.105386972427368
Validation loss: 2.1911659215086248

Epoch: 5| Step: 7
Training loss: 1.852359414100647
Validation loss: 2.1318504592423797

Epoch: 5| Step: 8
Training loss: 2.115604877471924
Validation loss: 2.1740916826391734

Epoch: 5| Step: 9
Training loss: 1.8272711038589478
Validation loss: 2.238111102452842

Epoch: 5| Step: 10
Training loss: 1.946465253829956
Validation loss: 2.1631715066971315

Epoch: 127| Step: 0
Training loss: 1.9727426767349243
Validation loss: 2.2403775748386177

Epoch: 5| Step: 1
Training loss: 1.3806285858154297
Validation loss: 2.233397017243088

Epoch: 5| Step: 2
Training loss: 2.8241710662841797
Validation loss: 2.24680761624408

Epoch: 5| Step: 3
Training loss: 2.072270393371582
Validation loss: 2.174490790213308

Epoch: 5| Step: 4
Training loss: 2.2265114784240723
Validation loss: 2.174600152559178

Epoch: 5| Step: 5
Training loss: 2.154649496078491
Validation loss: 2.1456207831700644

Epoch: 5| Step: 6
Training loss: 2.4333157539367676
Validation loss: 2.2023252799946773

Epoch: 5| Step: 7
Training loss: 2.238781690597534
Validation loss: 2.216242198021181

Epoch: 5| Step: 8
Training loss: 2.006737232208252
Validation loss: 2.150469264676494

Epoch: 5| Step: 9
Training loss: 2.5995726585388184
Validation loss: 2.208017346679523

Epoch: 5| Step: 10
Training loss: 2.1794376373291016
Validation loss: 2.1609313590552217

Epoch: 128| Step: 0
Training loss: 2.034075975418091
Validation loss: 2.1711686118956535

Epoch: 5| Step: 1
Training loss: 2.277653455734253
Validation loss: 2.15213882025852

Epoch: 5| Step: 2
Training loss: 2.72589111328125
Validation loss: 2.1759338327633437

Epoch: 5| Step: 3
Training loss: 2.254685878753662
Validation loss: 2.199405038228599

Epoch: 5| Step: 4
Training loss: 2.4855077266693115
Validation loss: 2.2007932457872617

Epoch: 5| Step: 5
Training loss: 2.438910722732544
Validation loss: 2.1750324682522844

Epoch: 5| Step: 6
Training loss: 2.5262274742126465
Validation loss: 2.158785243188181

Epoch: 5| Step: 7
Training loss: 1.9905061721801758
Validation loss: 2.1353746306511665

Epoch: 5| Step: 8
Training loss: 1.8290727138519287
Validation loss: 2.252298003883772

Epoch: 5| Step: 9
Training loss: 1.828118920326233
Validation loss: 2.146226757316179

Epoch: 5| Step: 10
Training loss: 1.6983479261398315
Validation loss: 2.2509339419744347

Epoch: 129| Step: 0
Training loss: 2.422609567642212
Validation loss: 2.183555174899358

Epoch: 5| Step: 1
Training loss: 1.9731714725494385
Validation loss: 2.2607933411034207

Epoch: 5| Step: 2
Training loss: 2.3065783977508545
Validation loss: 2.1711015650021133

Epoch: 5| Step: 3
Training loss: 1.6869618892669678
Validation loss: 2.1919496264508975

Epoch: 5| Step: 4
Training loss: 2.3437581062316895
Validation loss: 2.1749228956878826

Epoch: 5| Step: 5
Training loss: 2.277987480163574
Validation loss: 2.2320161275966193

Epoch: 5| Step: 6
Training loss: 1.7044904232025146
Validation loss: 2.1695204127219414

Epoch: 5| Step: 7
Training loss: 2.9874298572540283
Validation loss: 2.2123020874556674

Epoch: 5| Step: 8
Training loss: 2.084094762802124
Validation loss: 2.2114463006296465

Epoch: 5| Step: 9
Training loss: 1.8377355337142944
Validation loss: 2.235343446013748

Epoch: 5| Step: 10
Training loss: 2.9783966541290283
Validation loss: 2.098320896907519

Epoch: 130| Step: 0
Training loss: 2.577214002609253
Validation loss: 2.1484842813143166

Epoch: 5| Step: 1
Training loss: 1.8106708526611328
Validation loss: 2.2668715189861994

Epoch: 5| Step: 2
Training loss: 2.486680507659912
Validation loss: 2.234898544126941

Epoch: 5| Step: 3
Training loss: 2.2904446125030518
Validation loss: 2.109169554966752

Epoch: 5| Step: 4
Training loss: 2.023231029510498
Validation loss: 2.195024845420673

Epoch: 5| Step: 5
Training loss: 1.6905704736709595
Validation loss: 2.2266743593318488

Epoch: 5| Step: 6
Training loss: 2.2440695762634277
Validation loss: 2.2700027240219938

Epoch: 5| Step: 7
Training loss: 2.0670037269592285
Validation loss: 2.247477818560857

Epoch: 5| Step: 8
Training loss: 1.9089577198028564
Validation loss: 2.1745853936800392

Epoch: 5| Step: 9
Training loss: 2.329436779022217
Validation loss: 2.173855379063596

Epoch: 5| Step: 10
Training loss: 2.384438991546631
Validation loss: 2.2418098577889065

Epoch: 131| Step: 0
Training loss: 1.9738130569458008
Validation loss: 2.2077290011990454

Epoch: 5| Step: 1
Training loss: 2.2260894775390625
Validation loss: 2.241363876609392

Epoch: 5| Step: 2
Training loss: 1.7553058862686157
Validation loss: 2.2099541515432377

Epoch: 5| Step: 3
Training loss: 1.8907592296600342
Validation loss: 2.1610345660999255

Epoch: 5| Step: 4
Training loss: 2.338364362716675
Validation loss: 2.2098384903323267

Epoch: 5| Step: 5
Training loss: 2.0156891345977783
Validation loss: 2.173675239727061

Epoch: 5| Step: 6
Training loss: 2.4095377922058105
Validation loss: 2.2248117564826884

Epoch: 5| Step: 7
Training loss: 2.294727087020874
Validation loss: 2.2671684206172986

Epoch: 5| Step: 8
Training loss: 2.74697208404541
Validation loss: 2.1231651870153283

Epoch: 5| Step: 9
Training loss: 2.044772148132324
Validation loss: 2.282388035969068

Epoch: 5| Step: 10
Training loss: 2.908797025680542
Validation loss: 2.320230817282072

Epoch: 132| Step: 0
Training loss: 1.6129567623138428
Validation loss: 2.202218040343254

Epoch: 5| Step: 1
Training loss: 2.554810047149658
Validation loss: 2.258826240416496

Epoch: 5| Step: 2
Training loss: 2.4109103679656982
Validation loss: 2.2277727780803556

Epoch: 5| Step: 3
Training loss: 2.1674304008483887
Validation loss: 2.2397306580697336

Epoch: 5| Step: 4
Training loss: 1.9393432140350342
Validation loss: 2.1890191288404566

Epoch: 5| Step: 5
Training loss: 2.039405345916748
Validation loss: 2.1962996734085904

Epoch: 5| Step: 6
Training loss: 2.067213296890259
Validation loss: 2.2458004259294078

Epoch: 5| Step: 7
Training loss: 2.2157416343688965
Validation loss: 2.1873127055424515

Epoch: 5| Step: 8
Training loss: 2.380107879638672
Validation loss: 2.2161380475567234

Epoch: 5| Step: 9
Training loss: 2.506877899169922
Validation loss: 2.133668548317366

Epoch: 5| Step: 10
Training loss: 1.6605942249298096
Validation loss: 2.182234497480495

Epoch: 133| Step: 0
Training loss: 2.918856143951416
Validation loss: 2.1989618911538074

Epoch: 5| Step: 1
Training loss: 1.7385715246200562
Validation loss: 2.1520925106540805

Epoch: 5| Step: 2
Training loss: 3.062469959259033
Validation loss: 2.1955365211732927

Epoch: 5| Step: 3
Training loss: 2.284613847732544
Validation loss: 2.215886841538132

Epoch: 5| Step: 4
Training loss: 2.586878776550293
Validation loss: 2.168842415655813

Epoch: 5| Step: 5
Training loss: 1.6359542608261108
Validation loss: 2.18848753488192

Epoch: 5| Step: 6
Training loss: 1.8157079219818115
Validation loss: 2.103750072499757

Epoch: 5| Step: 7
Training loss: 1.974612832069397
Validation loss: 2.2698264147645686

Epoch: 5| Step: 8
Training loss: 1.6679121255874634
Validation loss: 2.245935309317804

Epoch: 5| Step: 9
Training loss: 1.869518518447876
Validation loss: 2.190053504000428

Epoch: 5| Step: 10
Training loss: 2.7433717250823975
Validation loss: 2.136552820923508

Epoch: 134| Step: 0
Training loss: 2.720116376876831
Validation loss: 2.1604070176360426

Epoch: 5| Step: 1
Training loss: 1.7140487432479858
Validation loss: 2.19481151078337

Epoch: 5| Step: 2
Training loss: 2.189558506011963
Validation loss: 2.1661636726830595

Epoch: 5| Step: 3
Training loss: 2.5030713081359863
Validation loss: 2.2496456946096113

Epoch: 5| Step: 4
Training loss: 2.238978147506714
Validation loss: 2.257398920674478

Epoch: 5| Step: 5
Training loss: 2.656275510787964
Validation loss: 2.173625043643418

Epoch: 5| Step: 6
Training loss: 2.3456308841705322
Validation loss: 2.1608297363404305

Epoch: 5| Step: 7
Training loss: 2.2101426124572754
Validation loss: 2.2539766142445226

Epoch: 5| Step: 8
Training loss: 2.205761432647705
Validation loss: 2.1905797040590675

Epoch: 5| Step: 9
Training loss: 1.7470238208770752
Validation loss: 2.1247687570510374

Epoch: 5| Step: 10
Training loss: 1.6907110214233398
Validation loss: 2.14172536839721

Epoch: 135| Step: 0
Training loss: 2.2530014514923096
Validation loss: 2.188216940049202

Epoch: 5| Step: 1
Training loss: 2.596996784210205
Validation loss: 2.21672712602923

Epoch: 5| Step: 2
Training loss: 1.3812650442123413
Validation loss: 2.258206581556669

Epoch: 5| Step: 3
Training loss: 1.9855501651763916
Validation loss: 2.1860642074256815

Epoch: 5| Step: 4
Training loss: 1.8086624145507812
Validation loss: 2.168136276224608

Epoch: 5| Step: 5
Training loss: 2.62962007522583
Validation loss: 2.2211591556508052

Epoch: 5| Step: 6
Training loss: 1.9600870609283447
Validation loss: 2.221727540416102

Epoch: 5| Step: 7
Training loss: 2.0416340827941895
Validation loss: 2.232680038739276

Epoch: 5| Step: 8
Training loss: 2.463644027709961
Validation loss: 2.2729568840355

Epoch: 5| Step: 9
Training loss: 2.0659518241882324
Validation loss: 2.19638503238719

Epoch: 5| Step: 10
Training loss: 3.0879459381103516
Validation loss: 2.155144355630362

Epoch: 136| Step: 0
Training loss: 2.555915117263794
Validation loss: 2.157455708390923

Epoch: 5| Step: 1
Training loss: 2.0537993907928467
Validation loss: 2.182302482666508

Epoch: 5| Step: 2
Training loss: 1.7140096426010132
Validation loss: 2.2518978195805706

Epoch: 5| Step: 3
Training loss: 1.930371880531311
Validation loss: 2.2041386686345583

Epoch: 5| Step: 4
Training loss: 2.3073017597198486
Validation loss: 2.135879603765344

Epoch: 5| Step: 5
Training loss: 1.8720347881317139
Validation loss: 2.121709974863196

Epoch: 5| Step: 6
Training loss: 2.141439914703369
Validation loss: 2.135293729843632

Epoch: 5| Step: 7
Training loss: 2.4233601093292236
Validation loss: 2.2173553666760846

Epoch: 5| Step: 8
Training loss: 2.1308655738830566
Validation loss: 2.1167816603055565

Epoch: 5| Step: 9
Training loss: 2.1587719917297363
Validation loss: 2.1110062227454236

Epoch: 5| Step: 10
Training loss: 2.332869291305542
Validation loss: 2.1398395722912205

Epoch: 137| Step: 0
Training loss: 2.922947406768799
Validation loss: 2.198795162221437

Epoch: 5| Step: 1
Training loss: 1.7356958389282227
Validation loss: 2.1789219969062397

Epoch: 5| Step: 2
Training loss: 1.8657283782958984
Validation loss: 2.1821963325623543

Epoch: 5| Step: 3
Training loss: 2.0153517723083496
Validation loss: 2.1237285508904407

Epoch: 5| Step: 4
Training loss: 2.0311741828918457
Validation loss: 2.186758610510057

Epoch: 5| Step: 5
Training loss: 2.3997275829315186
Validation loss: 2.1890177444745134

Epoch: 5| Step: 6
Training loss: 1.7900898456573486
Validation loss: 2.2074957227194183

Epoch: 5| Step: 7
Training loss: 2.4604058265686035
Validation loss: 2.151609609203954

Epoch: 5| Step: 8
Training loss: 2.4086644649505615
Validation loss: 2.0619282491745485

Epoch: 5| Step: 9
Training loss: 2.4550139904022217
Validation loss: 2.1669083513239378

Epoch: 5| Step: 10
Training loss: 2.6641058921813965
Validation loss: 2.2010641636386996

Epoch: 138| Step: 0
Training loss: 2.2086148262023926
Validation loss: 2.143793236824774

Epoch: 5| Step: 1
Training loss: 1.8377145528793335
Validation loss: 2.1285345118532897

Epoch: 5| Step: 2
Training loss: 2.0023887157440186
Validation loss: 2.1907202530932683

Epoch: 5| Step: 3
Training loss: 2.2177040576934814
Validation loss: 2.064714397153547

Epoch: 5| Step: 4
Training loss: 1.9293235540390015
Validation loss: 2.1482610369241364

Epoch: 5| Step: 5
Training loss: 1.7221300601959229
Validation loss: 2.1361047734496412

Epoch: 5| Step: 6
Training loss: 2.409278392791748
Validation loss: 2.186530731057608

Epoch: 5| Step: 7
Training loss: 2.1911733150482178
Validation loss: 2.1844522619760163

Epoch: 5| Step: 8
Training loss: 2.2786567211151123
Validation loss: 2.2571361603275424

Epoch: 5| Step: 9
Training loss: 2.653749465942383
Validation loss: 2.2285384721653436

Epoch: 5| Step: 10
Training loss: 2.6284377574920654
Validation loss: 2.1877984128972536

Epoch: 139| Step: 0
Training loss: 1.877746820449829
Validation loss: 2.2378998853827037

Epoch: 5| Step: 1
Training loss: 2.273513078689575
Validation loss: 2.2382950680230254

Epoch: 5| Step: 2
Training loss: 2.419487714767456
Validation loss: 2.1547833386287896

Epoch: 5| Step: 3
Training loss: 1.8964321613311768
Validation loss: 2.204387531485609

Epoch: 5| Step: 4
Training loss: 1.9117648601531982
Validation loss: 2.164181295261588

Epoch: 5| Step: 5
Training loss: 2.5381903648376465
Validation loss: 2.2396530541040565

Epoch: 5| Step: 6
Training loss: 1.7885684967041016
Validation loss: 2.251679153852565

Epoch: 5| Step: 7
Training loss: 2.52717924118042
Validation loss: 2.1490146626708326

Epoch: 5| Step: 8
Training loss: 1.7806698083877563
Validation loss: 2.1381167724568355

Epoch: 5| Step: 9
Training loss: 2.5832858085632324
Validation loss: 2.176355787502822

Epoch: 5| Step: 10
Training loss: 2.1694250106811523
Validation loss: 2.2637958885521017

Epoch: 140| Step: 0
Training loss: 2.402822256088257
Validation loss: 2.2346742306986163

Epoch: 5| Step: 1
Training loss: 1.9009231328964233
Validation loss: 2.219896819001885

Epoch: 5| Step: 2
Training loss: 1.8235502243041992
Validation loss: 2.1431463662014214

Epoch: 5| Step: 3
Training loss: 2.55961275100708
Validation loss: 2.1925904020186393

Epoch: 5| Step: 4
Training loss: 2.509409189224243
Validation loss: 2.268580836634482

Epoch: 5| Step: 5
Training loss: 1.8003132343292236
Validation loss: 2.195050134453722

Epoch: 5| Step: 6
Training loss: 1.901497483253479
Validation loss: 2.161896954300583

Epoch: 5| Step: 7
Training loss: 1.979758858680725
Validation loss: 2.2053104344234673

Epoch: 5| Step: 8
Training loss: 2.1572890281677246
Validation loss: 2.2284677977203042

Epoch: 5| Step: 9
Training loss: 2.2946906089782715
Validation loss: 2.1954299660139185

Epoch: 5| Step: 10
Training loss: 2.1269161701202393
Validation loss: 2.1553501582914785

Epoch: 141| Step: 0
Training loss: 2.2293436527252197
Validation loss: 2.1713770397247805

Epoch: 5| Step: 1
Training loss: 2.067446708679199
Validation loss: 2.2338428548587266

Epoch: 5| Step: 2
Training loss: 2.229332447052002
Validation loss: 2.1799242599036104

Epoch: 5| Step: 3
Training loss: 2.6517770290374756
Validation loss: 2.2522668864137385

Epoch: 5| Step: 4
Training loss: 2.1077933311462402
Validation loss: 2.185678010345787

Epoch: 5| Step: 5
Training loss: 2.2645888328552246
Validation loss: 2.230570767515449

Epoch: 5| Step: 6
Training loss: 1.6561553478240967
Validation loss: 2.195001894427884

Epoch: 5| Step: 7
Training loss: 3.0161712169647217
Validation loss: 2.175193161092779

Epoch: 5| Step: 8
Training loss: 1.4695993661880493
Validation loss: 2.1631229923617457

Epoch: 5| Step: 9
Training loss: 2.322505474090576
Validation loss: 2.163211614854874

Epoch: 5| Step: 10
Training loss: 2.0129144191741943
Validation loss: 2.142647830388879

Epoch: 142| Step: 0
Training loss: 2.0034737586975098
Validation loss: 2.1457152981911936

Epoch: 5| Step: 1
Training loss: 2.1029999256134033
Validation loss: 2.1511041246434695

Epoch: 5| Step: 2
Training loss: 2.0210530757904053
Validation loss: 2.2277002539685977

Epoch: 5| Step: 3
Training loss: 2.1006827354431152
Validation loss: 2.2873547307906614

Epoch: 5| Step: 4
Training loss: 2.4466075897216797
Validation loss: 2.1189777492195048

Epoch: 5| Step: 5
Training loss: 2.5696909427642822
Validation loss: 2.1511880326014694

Epoch: 5| Step: 6
Training loss: 2.3401997089385986
Validation loss: 2.1431441794159594

Epoch: 5| Step: 7
Training loss: 2.302649736404419
Validation loss: 2.1981906557595856

Epoch: 5| Step: 8
Training loss: 2.1093251705169678
Validation loss: 2.183447322537822

Epoch: 5| Step: 9
Training loss: 2.2436881065368652
Validation loss: 2.2428695796638407

Epoch: 5| Step: 10
Training loss: 2.0260868072509766
Validation loss: 2.2195480767116753

Epoch: 143| Step: 0
Training loss: 2.2091403007507324
Validation loss: 2.1962510308911725

Epoch: 5| Step: 1
Training loss: 2.5851709842681885
Validation loss: 2.0363923888052664

Epoch: 5| Step: 2
Training loss: 2.330976963043213
Validation loss: 2.0976868829419537

Epoch: 5| Step: 3
Training loss: 2.0713539123535156
Validation loss: 2.196298991480181

Epoch: 5| Step: 4
Training loss: 1.807081937789917
Validation loss: 2.2111139233394335

Epoch: 5| Step: 5
Training loss: 2.323051929473877
Validation loss: 2.18676834465355

Epoch: 5| Step: 6
Training loss: 2.2297089099884033
Validation loss: 2.1715958810621694

Epoch: 5| Step: 7
Training loss: 2.0674452781677246
Validation loss: 2.1677948967103036

Epoch: 5| Step: 8
Training loss: 1.9022575616836548
Validation loss: 2.0649598593352945

Epoch: 5| Step: 9
Training loss: 2.2846896648406982
Validation loss: 2.1462233258831884

Epoch: 5| Step: 10
Training loss: 2.317180871963501
Validation loss: 2.20944796839068

Epoch: 144| Step: 0
Training loss: 2.0800411701202393
Validation loss: 2.047357060575998

Epoch: 5| Step: 1
Training loss: 2.1002488136291504
Validation loss: 2.2280421603110527

Epoch: 5| Step: 2
Training loss: 1.9835374355316162
Validation loss: 2.1646593309217885

Epoch: 5| Step: 3
Training loss: 2.387491464614868
Validation loss: 2.1614371499707623

Epoch: 5| Step: 4
Training loss: 2.66618013381958
Validation loss: 2.1715779381413616

Epoch: 5| Step: 5
Training loss: 2.250392436981201
Validation loss: 2.1696099081347064

Epoch: 5| Step: 6
Training loss: 2.3994364738464355
Validation loss: 2.218748761761573

Epoch: 5| Step: 7
Training loss: 2.152712345123291
Validation loss: 2.1803510547966085

Epoch: 5| Step: 8
Training loss: 1.9704748392105103
Validation loss: 2.0652735643489386

Epoch: 5| Step: 9
Training loss: 2.111923933029175
Validation loss: 2.147589965533185

Epoch: 5| Step: 10
Training loss: 2.033234119415283
Validation loss: 2.213894651782128

Epoch: 145| Step: 0
Training loss: 1.8467819690704346
Validation loss: 2.159855778499316

Epoch: 5| Step: 1
Training loss: 2.2542030811309814
Validation loss: 2.1983685519105647

Epoch: 5| Step: 2
Training loss: 2.3884997367858887
Validation loss: 2.1291520185368036

Epoch: 5| Step: 3
Training loss: 2.0074524879455566
Validation loss: 2.2461985490655385

Epoch: 5| Step: 4
Training loss: 2.9166061878204346
Validation loss: 2.2312044661532164

Epoch: 5| Step: 5
Training loss: 1.9001922607421875
Validation loss: 2.196661139047274

Epoch: 5| Step: 6
Training loss: 1.9336906671524048
Validation loss: 2.2101296558175036

Epoch: 5| Step: 7
Training loss: 2.0274832248687744
Validation loss: 2.1360309611084642

Epoch: 5| Step: 8
Training loss: 1.9928138256072998
Validation loss: 2.155414447989515

Epoch: 5| Step: 9
Training loss: 2.3289151191711426
Validation loss: 2.157607123415957

Epoch: 5| Step: 10
Training loss: 2.1183974742889404
Validation loss: 2.164053540075979

Epoch: 146| Step: 0
Training loss: 2.0876879692077637
Validation loss: 2.1887025320401756

Epoch: 5| Step: 1
Training loss: 2.1950185298919678
Validation loss: 2.1936736850328344

Epoch: 5| Step: 2
Training loss: 2.5317225456237793
Validation loss: 2.2069362414780485

Epoch: 5| Step: 3
Training loss: 1.728725790977478
Validation loss: 2.1659501624363724

Epoch: 5| Step: 4
Training loss: 2.212069034576416
Validation loss: 2.207798227187126

Epoch: 5| Step: 5
Training loss: 2.0616602897644043
Validation loss: 2.0796536476381364

Epoch: 5| Step: 6
Training loss: 1.5268937349319458
Validation loss: 2.2298693374920915

Epoch: 5| Step: 7
Training loss: 2.2800087928771973
Validation loss: 2.1228846875570153

Epoch: 5| Step: 8
Training loss: 2.687594175338745
Validation loss: 2.169210731342275

Epoch: 5| Step: 9
Training loss: 2.476921558380127
Validation loss: 2.08003552498356

Epoch: 5| Step: 10
Training loss: 2.0411338806152344
Validation loss: 2.1413528662855907

Epoch: 147| Step: 0
Training loss: 2.234269380569458
Validation loss: 2.19604318629029

Epoch: 5| Step: 1
Training loss: 1.558983564376831
Validation loss: 2.1897782997418473

Epoch: 5| Step: 2
Training loss: 1.8993059396743774
Validation loss: 2.191959019630186

Epoch: 5| Step: 3
Training loss: 2.3229258060455322
Validation loss: 2.2488354380412767

Epoch: 5| Step: 4
Training loss: 2.4516282081604004
Validation loss: 2.139007060758529

Epoch: 5| Step: 5
Training loss: 2.5566790103912354
Validation loss: 2.1580417694584018

Epoch: 5| Step: 6
Training loss: 2.2258706092834473
Validation loss: 2.135493507949255

Epoch: 5| Step: 7
Training loss: 2.148800849914551
Validation loss: 2.1937546665950487

Epoch: 5| Step: 8
Training loss: 1.8497775793075562
Validation loss: 2.089671934804609

Epoch: 5| Step: 9
Training loss: 2.5080392360687256
Validation loss: 2.1515052703119095

Epoch: 5| Step: 10
Training loss: 2.223417282104492
Validation loss: 2.1959368490403697

Epoch: 148| Step: 0
Training loss: 2.19920015335083
Validation loss: 2.2340433136109383

Epoch: 5| Step: 1
Training loss: 2.0474679470062256
Validation loss: 2.14702025792932

Epoch: 5| Step: 2
Training loss: 2.265167474746704
Validation loss: 2.1349537782771613

Epoch: 5| Step: 3
Training loss: 2.01835560798645
Validation loss: 2.215471451000501

Epoch: 5| Step: 4
Training loss: 2.5479331016540527
Validation loss: 2.154437102297301

Epoch: 5| Step: 5
Training loss: 2.043086528778076
Validation loss: 2.0794535016500824

Epoch: 5| Step: 6
Training loss: 2.118058681488037
Validation loss: 2.1744210079152095

Epoch: 5| Step: 7
Training loss: 2.152723789215088
Validation loss: 2.175788767876164

Epoch: 5| Step: 8
Training loss: 2.304283857345581
Validation loss: 2.207805661744969

Epoch: 5| Step: 9
Training loss: 2.0842342376708984
Validation loss: 2.1763461815413607

Epoch: 5| Step: 10
Training loss: 2.036073923110962
Validation loss: 2.16437174940622

Epoch: 149| Step: 0
Training loss: 2.109260082244873
Validation loss: 2.157894770304362

Epoch: 5| Step: 1
Training loss: 2.417346477508545
Validation loss: 2.143787553233485

Epoch: 5| Step: 2
Training loss: 1.874283790588379
Validation loss: 2.172234507017238

Epoch: 5| Step: 3
Training loss: 2.68001127243042
Validation loss: 2.163194041098318

Epoch: 5| Step: 4
Training loss: 1.9787334203720093
Validation loss: 2.2043349178888465

Epoch: 5| Step: 5
Training loss: 2.0079407691955566
Validation loss: 2.143739572135351

Epoch: 5| Step: 6
Training loss: 1.9994627237319946
Validation loss: 2.212332421733487

Epoch: 5| Step: 7
Training loss: 2.1206467151641846
Validation loss: 2.1859034235759447

Epoch: 5| Step: 8
Training loss: 2.2263176441192627
Validation loss: 2.2155790944253244

Epoch: 5| Step: 9
Training loss: 2.2926547527313232
Validation loss: 2.198308462737709

Epoch: 5| Step: 10
Training loss: 2.321910858154297
Validation loss: 2.16462278878817

Epoch: 150| Step: 0
Training loss: 2.395224094390869
Validation loss: 2.1429860835434287

Epoch: 5| Step: 1
Training loss: 2.415938138961792
Validation loss: 2.110884471606183

Epoch: 5| Step: 2
Training loss: 2.1836204528808594
Validation loss: 2.0720931842762935

Epoch: 5| Step: 3
Training loss: 2.316697120666504
Validation loss: 2.1303494848230833

Epoch: 5| Step: 4
Training loss: 1.9993011951446533
Validation loss: 2.237470872940556

Epoch: 5| Step: 5
Training loss: 2.4622883796691895
Validation loss: 2.1611923812538065

Epoch: 5| Step: 6
Training loss: 2.0539042949676514
Validation loss: 2.1932489743796726

Epoch: 5| Step: 7
Training loss: 2.245675563812256
Validation loss: 2.1668532227957122

Epoch: 5| Step: 8
Training loss: 1.8083534240722656
Validation loss: 2.1532589440704673

Epoch: 5| Step: 9
Training loss: 1.9586158990859985
Validation loss: 2.187890834705804

Epoch: 5| Step: 10
Training loss: 2.24023699760437
Validation loss: 2.1835147488501763

Epoch: 151| Step: 0
Training loss: 1.5848095417022705
Validation loss: 2.076757630994243

Epoch: 5| Step: 1
Training loss: 2.850342273712158
Validation loss: 2.119757265172979

Epoch: 5| Step: 2
Training loss: 2.082127809524536
Validation loss: 2.166679702779298

Epoch: 5| Step: 3
Training loss: 1.2962311506271362
Validation loss: 2.2768511823428574

Epoch: 5| Step: 4
Training loss: 1.8893907070159912
Validation loss: 2.1424589618559806

Epoch: 5| Step: 5
Training loss: 2.748502492904663
Validation loss: 2.161029318327545

Epoch: 5| Step: 6
Training loss: 2.153805732727051
Validation loss: 2.136307365150862

Epoch: 5| Step: 7
Training loss: 2.2478432655334473
Validation loss: 2.2320453915544736

Epoch: 5| Step: 8
Training loss: 1.449105978012085
Validation loss: 2.209293055277999

Epoch: 5| Step: 9
Training loss: 3.126347303390503
Validation loss: 2.279123754911525

Epoch: 5| Step: 10
Training loss: 2.583906650543213
Validation loss: 2.1563871265739523

Epoch: 152| Step: 0
Training loss: 2.6150028705596924
Validation loss: 2.1727660830302904

Epoch: 5| Step: 1
Training loss: 1.5634864568710327
Validation loss: 2.1638973720612062

Epoch: 5| Step: 2
Training loss: 2.2000715732574463
Validation loss: 2.187560353227841

Epoch: 5| Step: 3
Training loss: 1.6634852886199951
Validation loss: 2.18225718954558

Epoch: 5| Step: 4
Training loss: 2.799741506576538
Validation loss: 2.1214725740494265

Epoch: 5| Step: 5
Training loss: 2.2532241344451904
Validation loss: 2.186820286576466

Epoch: 5| Step: 6
Training loss: 1.8201309442520142
Validation loss: 2.1796268750262517

Epoch: 5| Step: 7
Training loss: 2.234926700592041
Validation loss: 2.169684656204716

Epoch: 5| Step: 8
Training loss: 1.8262567520141602
Validation loss: 2.2013700572393273

Epoch: 5| Step: 9
Training loss: 1.9314991235733032
Validation loss: 2.196982679828521

Epoch: 5| Step: 10
Training loss: 2.3685333728790283
Validation loss: 2.226249561514906

Epoch: 153| Step: 0
Training loss: 1.978633165359497
Validation loss: 2.1380319082608787

Epoch: 5| Step: 1
Training loss: 2.2639997005462646
Validation loss: 2.1673761901035102

Epoch: 5| Step: 2
Training loss: 1.9729936122894287
Validation loss: 2.0676562222101356

Epoch: 5| Step: 3
Training loss: 2.0403788089752197
Validation loss: 2.1695050219053864

Epoch: 5| Step: 4
Training loss: 2.4664180278778076
Validation loss: 2.195154854046401

Epoch: 5| Step: 5
Training loss: 2.8937010765075684
Validation loss: 2.097911653980132

Epoch: 5| Step: 6
Training loss: 2.127598285675049
Validation loss: 2.1858460621167253

Epoch: 5| Step: 7
Training loss: 2.6807336807250977
Validation loss: 2.151977789017462

Epoch: 5| Step: 8
Training loss: 2.140599489212036
Validation loss: 2.1444916135521344

Epoch: 5| Step: 9
Training loss: 1.9169700145721436
Validation loss: 2.1153330110734507

Epoch: 5| Step: 10
Training loss: 1.8834490776062012
Validation loss: 2.1505365269158476

Epoch: 154| Step: 0
Training loss: 1.933009386062622
Validation loss: 2.160463850985291

Epoch: 5| Step: 1
Training loss: 1.9055910110473633
Validation loss: 2.1842156648635864

Epoch: 5| Step: 2
Training loss: 2.2940545082092285
Validation loss: 2.2173726840685775

Epoch: 5| Step: 3
Training loss: 1.8999515771865845
Validation loss: 2.1017826616123156

Epoch: 5| Step: 4
Training loss: 1.9651705026626587
Validation loss: 2.10203726573657

Epoch: 5| Step: 5
Training loss: 2.654874086380005
Validation loss: 2.1582801290737685

Epoch: 5| Step: 6
Training loss: 1.8951927423477173
Validation loss: 2.219882521578061

Epoch: 5| Step: 7
Training loss: 2.229785442352295
Validation loss: 2.164882331766108

Epoch: 5| Step: 8
Training loss: 1.9712674617767334
Validation loss: 2.251800965237361

Epoch: 5| Step: 9
Training loss: 2.5584716796875
Validation loss: 2.1236022159617436

Epoch: 5| Step: 10
Training loss: 2.088829517364502
Validation loss: 2.3043246205135057

Epoch: 155| Step: 0
Training loss: 2.4280776977539062
Validation loss: 2.2335746570300032

Epoch: 5| Step: 1
Training loss: 2.41495943069458
Validation loss: 2.1751544411464403

Epoch: 5| Step: 2
Training loss: 2.3832080364227295
Validation loss: 2.1734053832228466

Epoch: 5| Step: 3
Training loss: 2.379204273223877
Validation loss: 2.1666082566784275

Epoch: 5| Step: 4
Training loss: 2.059765577316284
Validation loss: 2.1512031285993514

Epoch: 5| Step: 5
Training loss: 1.7321691513061523
Validation loss: 2.1916547154867523

Epoch: 5| Step: 6
Training loss: 2.3886337280273438
Validation loss: 2.1490042619807745

Epoch: 5| Step: 7
Training loss: 2.121307373046875
Validation loss: 2.2476919286994526

Epoch: 5| Step: 8
Training loss: 1.9189687967300415
Validation loss: 2.180966910495553

Epoch: 5| Step: 9
Training loss: 2.385105848312378
Validation loss: 2.1052557499177995

Epoch: 5| Step: 10
Training loss: 1.8356236219406128
Validation loss: 2.1962339724263837

Epoch: 156| Step: 0
Training loss: 2.098259449005127
Validation loss: 2.144484910913693

Epoch: 5| Step: 1
Training loss: 1.635104775428772
Validation loss: 2.1838306150128766

Epoch: 5| Step: 2
Training loss: 1.7218093872070312
Validation loss: 2.218036492665609

Epoch: 5| Step: 3
Training loss: 2.393162250518799
Validation loss: 2.119410963468654

Epoch: 5| Step: 4
Training loss: 2.5550360679626465
Validation loss: 2.1946299947718138

Epoch: 5| Step: 5
Training loss: 1.8824676275253296
Validation loss: 2.0651330127510974

Epoch: 5| Step: 6
Training loss: 2.1748321056365967
Validation loss: 2.069569738962317

Epoch: 5| Step: 7
Training loss: 2.6674745082855225
Validation loss: 2.2005343257739978

Epoch: 5| Step: 8
Training loss: 1.9823535680770874
Validation loss: 2.199858219392838

Epoch: 5| Step: 9
Training loss: 2.3151021003723145
Validation loss: 2.174117103699715

Epoch: 5| Step: 10
Training loss: 2.3847692012786865
Validation loss: 2.095931245434669

Epoch: 157| Step: 0
Training loss: 2.3357391357421875
Validation loss: 2.1427224246404504

Epoch: 5| Step: 1
Training loss: 1.4712632894515991
Validation loss: 2.171819802253477

Epoch: 5| Step: 2
Training loss: 1.6891483068466187
Validation loss: 2.186231456777101

Epoch: 5| Step: 3
Training loss: 2.6159863471984863
Validation loss: 2.140667018070016

Epoch: 5| Step: 4
Training loss: 1.9346965551376343
Validation loss: 2.1199477680267824

Epoch: 5| Step: 5
Training loss: 2.721052646636963
Validation loss: 2.206510959133025

Epoch: 5| Step: 6
Training loss: 2.577742576599121
Validation loss: 2.1943487351940525

Epoch: 5| Step: 7
Training loss: 2.330549716949463
Validation loss: 2.185314360485282

Epoch: 5| Step: 8
Training loss: 2.625920534133911
Validation loss: 2.0742624370000695

Epoch: 5| Step: 9
Training loss: 1.5864653587341309
Validation loss: 2.0798660734648347

Epoch: 5| Step: 10
Training loss: 1.7940418720245361
Validation loss: 2.1594115572590984

Epoch: 158| Step: 0
Training loss: 2.281399726867676
Validation loss: 2.1541894789664977

Epoch: 5| Step: 1
Training loss: 1.9902251958847046
Validation loss: 2.20591648163334

Epoch: 5| Step: 2
Training loss: 1.6617157459259033
Validation loss: 2.0888627600926224

Epoch: 5| Step: 3
Training loss: 2.2375426292419434
Validation loss: 2.1017341306132655

Epoch: 5| Step: 4
Training loss: 1.9295501708984375
Validation loss: 2.096627249512621

Epoch: 5| Step: 5
Training loss: 2.1655056476593018
Validation loss: 2.088500440761607

Epoch: 5| Step: 6
Training loss: 1.9223382472991943
Validation loss: 2.2163863925523657

Epoch: 5| Step: 7
Training loss: 2.186339855194092
Validation loss: 2.1350806989977436

Epoch: 5| Step: 8
Training loss: 2.3946731090545654
Validation loss: 2.1747100865969093

Epoch: 5| Step: 9
Training loss: 2.4024059772491455
Validation loss: 2.156052074124736

Epoch: 5| Step: 10
Training loss: 2.4230618476867676
Validation loss: 2.072228635511091

Epoch: 159| Step: 0
Training loss: 2.1829731464385986
Validation loss: 2.2068337343072377

Epoch: 5| Step: 1
Training loss: 1.610396385192871
Validation loss: 2.1508753453531573

Epoch: 5| Step: 2
Training loss: 1.8001823425292969
Validation loss: 2.1673289140065513

Epoch: 5| Step: 3
Training loss: 2.1273670196533203
Validation loss: 2.116569258833444

Epoch: 5| Step: 4
Training loss: 2.553799867630005
Validation loss: 2.152056714539887

Epoch: 5| Step: 5
Training loss: 2.2966349124908447
Validation loss: 2.0775099915842854

Epoch: 5| Step: 6
Training loss: 1.9056589603424072
Validation loss: 2.129406880306941

Epoch: 5| Step: 7
Training loss: 2.1007964611053467
Validation loss: 2.1510664160533617

Epoch: 5| Step: 8
Training loss: 1.5861142873764038
Validation loss: 2.1421686346812914

Epoch: 5| Step: 9
Training loss: 2.474252700805664
Validation loss: 2.201884477369247

Epoch: 5| Step: 10
Training loss: 2.8659889698028564
Validation loss: 2.244113431181959

Epoch: 160| Step: 0
Training loss: 2.302891492843628
Validation loss: 2.204651491616362

Epoch: 5| Step: 1
Training loss: 2.1716060638427734
Validation loss: 2.1607153390043523

Epoch: 5| Step: 2
Training loss: 2.2516846656799316
Validation loss: 2.1908137772672918

Epoch: 5| Step: 3
Training loss: 2.3883681297302246
Validation loss: 2.119263208040627

Epoch: 5| Step: 4
Training loss: 2.56516695022583
Validation loss: 2.1120854949438446

Epoch: 5| Step: 5
Training loss: 2.0567703247070312
Validation loss: 2.112511199007752

Epoch: 5| Step: 6
Training loss: 1.6969082355499268
Validation loss: 2.1301218027709634

Epoch: 5| Step: 7
Training loss: 2.257479190826416
Validation loss: 2.0837220837993007

Epoch: 5| Step: 8
Training loss: 1.9511611461639404
Validation loss: 2.0698049504269838

Epoch: 5| Step: 9
Training loss: 2.282881736755371
Validation loss: 2.166912296766876

Epoch: 5| Step: 10
Training loss: 1.906925916671753
Validation loss: 2.154562020814547

Epoch: 161| Step: 0
Training loss: 2.0742430686950684
Validation loss: 2.1862998521456154

Epoch: 5| Step: 1
Training loss: 1.940097451210022
Validation loss: 2.188501569532579

Epoch: 5| Step: 2
Training loss: 1.7807973623275757
Validation loss: 2.213455520650392

Epoch: 5| Step: 3
Training loss: 2.4146852493286133
Validation loss: 2.1613525293206655

Epoch: 5| Step: 4
Training loss: 2.6269280910491943
Validation loss: 2.1270264258948703

Epoch: 5| Step: 5
Training loss: 2.011709213256836
Validation loss: 2.23099527435918

Epoch: 5| Step: 6
Training loss: 2.3871591091156006
Validation loss: 2.17763949466008

Epoch: 5| Step: 7
Training loss: 1.563844919204712
Validation loss: 2.1577148052953903

Epoch: 5| Step: 8
Training loss: 1.8361666202545166
Validation loss: 2.1734160889861402

Epoch: 5| Step: 9
Training loss: 2.2499499320983887
Validation loss: 2.158923310618247

Epoch: 5| Step: 10
Training loss: 2.288036346435547
Validation loss: 2.137861027512499

Epoch: 162| Step: 0
Training loss: 2.8587403297424316
Validation loss: 2.222772072720271

Epoch: 5| Step: 1
Training loss: 2.164328098297119
Validation loss: 2.191600929024399

Epoch: 5| Step: 2
Training loss: 2.715689182281494
Validation loss: 2.2152713524397982

Epoch: 5| Step: 3
Training loss: 1.6256458759307861
Validation loss: 2.212603927940451

Epoch: 5| Step: 4
Training loss: 1.6671087741851807
Validation loss: 2.2999413654368412

Epoch: 5| Step: 5
Training loss: 1.8636806011199951
Validation loss: 2.3181581497192383

Epoch: 5| Step: 6
Training loss: 1.7260395288467407
Validation loss: 2.2059793574835664

Epoch: 5| Step: 7
Training loss: 1.6928186416625977
Validation loss: 2.276722956729192

Epoch: 5| Step: 8
Training loss: 2.4331672191619873
Validation loss: 2.2336967324697845

Epoch: 5| Step: 9
Training loss: 2.323190927505493
Validation loss: 2.2799679335727485

Epoch: 5| Step: 10
Training loss: 2.32879376411438
Validation loss: 2.1857886442574124

Epoch: 163| Step: 0
Training loss: 1.5729777812957764
Validation loss: 2.1356413902774936

Epoch: 5| Step: 1
Training loss: 1.9356591701507568
Validation loss: 2.1998314190936346

Epoch: 5| Step: 2
Training loss: 1.822283148765564
Validation loss: 2.154736613714567

Epoch: 5| Step: 3
Training loss: 1.7813069820404053
Validation loss: 2.149256803656137

Epoch: 5| Step: 4
Training loss: 2.31555438041687
Validation loss: 2.189747264308314

Epoch: 5| Step: 5
Training loss: 2.4670798778533936
Validation loss: 2.11362624168396

Epoch: 5| Step: 6
Training loss: 2.8537211418151855
Validation loss: 2.293524895944903

Epoch: 5| Step: 7
Training loss: 2.0708365440368652
Validation loss: 2.2087494865540536

Epoch: 5| Step: 8
Training loss: 1.5812467336654663
Validation loss: 2.099899136891929

Epoch: 5| Step: 9
Training loss: 2.9143118858337402
Validation loss: 2.199839897053216

Epoch: 5| Step: 10
Training loss: 2.5247385501861572
Validation loss: 2.169022278119159

Epoch: 164| Step: 0
Training loss: 3.0715625286102295
Validation loss: 2.2194562496677523

Epoch: 5| Step: 1
Training loss: 1.8991647958755493
Validation loss: 2.2031882834690872

Epoch: 5| Step: 2
Training loss: 1.9415559768676758
Validation loss: 2.124843530757453

Epoch: 5| Step: 3
Training loss: 2.4015300273895264
Validation loss: 2.2340778381593767

Epoch: 5| Step: 4
Training loss: 2.173870086669922
Validation loss: 2.0656745074897684

Epoch: 5| Step: 5
Training loss: 1.3871498107910156
Validation loss: 2.136720400984569

Epoch: 5| Step: 6
Training loss: 1.5284894704818726
Validation loss: 2.1030529775927143

Epoch: 5| Step: 7
Training loss: 2.3285436630249023
Validation loss: 2.168574761318904

Epoch: 5| Step: 8
Training loss: 2.5578784942626953
Validation loss: 2.132847552658409

Epoch: 5| Step: 9
Training loss: 2.1309494972229004
Validation loss: 2.1829774302821003

Epoch: 5| Step: 10
Training loss: 2.0746407508850098
Validation loss: 2.1704820766243884

Epoch: 165| Step: 0
Training loss: 2.191635847091675
Validation loss: 2.1704989633252545

Epoch: 5| Step: 1
Training loss: 2.5151267051696777
Validation loss: 2.12865125748419

Epoch: 5| Step: 2
Training loss: 1.8544862270355225
Validation loss: 2.2178563840927614

Epoch: 5| Step: 3
Training loss: 2.505791664123535
Validation loss: 2.091367562611898

Epoch: 5| Step: 4
Training loss: 2.5215036869049072
Validation loss: 2.203788700924125

Epoch: 5| Step: 5
Training loss: 2.3939778804779053
Validation loss: 2.17996883392334

Epoch: 5| Step: 6
Training loss: 1.8617527484893799
Validation loss: 2.2055947037153345

Epoch: 5| Step: 7
Training loss: 2.1219584941864014
Validation loss: 2.1943457331708682

Epoch: 5| Step: 8
Training loss: 1.7555484771728516
Validation loss: 2.1940339662695445

Epoch: 5| Step: 9
Training loss: 1.9097061157226562
Validation loss: 2.143508311240904

Epoch: 5| Step: 10
Training loss: 2.0613036155700684
Validation loss: 2.169315500925946

Epoch: 166| Step: 0
Training loss: 2.5018744468688965
Validation loss: 2.164262717769992

Epoch: 5| Step: 1
Training loss: 2.674161195755005
Validation loss: 2.0613307286334295

Epoch: 5| Step: 2
Training loss: 1.7750835418701172
Validation loss: 2.086998931823238

Epoch: 5| Step: 3
Training loss: 2.017595052719116
Validation loss: 2.1159829144836753

Epoch: 5| Step: 4
Training loss: 2.332798480987549
Validation loss: 2.2171114772878666

Epoch: 5| Step: 5
Training loss: 1.981218695640564
Validation loss: 2.1711573575132634

Epoch: 5| Step: 6
Training loss: 2.202141284942627
Validation loss: 2.11348133958796

Epoch: 5| Step: 7
Training loss: 2.6968202590942383
Validation loss: 2.261465172613821

Epoch: 5| Step: 8
Training loss: 1.4796345233917236
Validation loss: 2.256710551118338

Epoch: 5| Step: 9
Training loss: 1.9595019817352295
Validation loss: 2.2030595425636537

Epoch: 5| Step: 10
Training loss: 2.3765902519226074
Validation loss: 2.122276621480142

Epoch: 167| Step: 0
Training loss: 2.168048620223999
Validation loss: 2.163516377889982

Epoch: 5| Step: 1
Training loss: 2.546853542327881
Validation loss: 2.1329564304761988

Epoch: 5| Step: 2
Training loss: 2.7044029235839844
Validation loss: 2.208903771574779

Epoch: 5| Step: 3
Training loss: 1.9083757400512695
Validation loss: 2.2134297534983647

Epoch: 5| Step: 4
Training loss: 1.3847543001174927
Validation loss: 2.151324518265263

Epoch: 5| Step: 5
Training loss: 1.7352497577667236
Validation loss: 2.1730919704642346

Epoch: 5| Step: 6
Training loss: 2.426252841949463
Validation loss: 2.283275347883983

Epoch: 5| Step: 7
Training loss: 2.2138068675994873
Validation loss: 2.145233634979494

Epoch: 5| Step: 8
Training loss: 1.9144798517227173
Validation loss: 2.101877781652635

Epoch: 5| Step: 9
Training loss: 2.2962393760681152
Validation loss: 2.097015832060127

Epoch: 5| Step: 10
Training loss: 2.1236326694488525
Validation loss: 2.114177055256341

Epoch: 168| Step: 0
Training loss: 1.7618099451065063
Validation loss: 2.194578619413478

Epoch: 5| Step: 1
Training loss: 1.7803901433944702
Validation loss: 2.0635748371001212

Epoch: 5| Step: 2
Training loss: 2.799975633621216
Validation loss: 2.1311172823752127

Epoch: 5| Step: 3
Training loss: 1.9532272815704346
Validation loss: 2.2200690238706526

Epoch: 5| Step: 4
Training loss: 2.16933012008667
Validation loss: 2.1755200791102585

Epoch: 5| Step: 5
Training loss: 1.9742504358291626
Validation loss: 2.0771413721064085

Epoch: 5| Step: 6
Training loss: 1.9626773595809937
Validation loss: 2.196411627595143

Epoch: 5| Step: 7
Training loss: 2.2349281311035156
Validation loss: 2.161115336161788

Epoch: 5| Step: 8
Training loss: 1.8800573348999023
Validation loss: 2.1732318350063857

Epoch: 5| Step: 9
Training loss: 1.6507165431976318
Validation loss: 2.135956935985114

Epoch: 5| Step: 10
Training loss: 2.7680277824401855
Validation loss: 2.0626797188994703

Epoch: 169| Step: 0
Training loss: 2.6987595558166504
Validation loss: 2.1541859693424676

Epoch: 5| Step: 1
Training loss: 1.4642537832260132
Validation loss: 2.157270901946611

Epoch: 5| Step: 2
Training loss: 2.697049617767334
Validation loss: 2.222286048755851

Epoch: 5| Step: 3
Training loss: 2.0160722732543945
Validation loss: 2.1891169573671077

Epoch: 5| Step: 4
Training loss: 2.1586453914642334
Validation loss: 2.1022158886796687

Epoch: 5| Step: 5
Training loss: 1.8557376861572266
Validation loss: 2.055921523801742

Epoch: 5| Step: 6
Training loss: 2.0833723545074463
Validation loss: 2.1370983354506956

Epoch: 5| Step: 7
Training loss: 2.1689934730529785
Validation loss: 2.209714907471852

Epoch: 5| Step: 8
Training loss: 1.9486385583877563
Validation loss: 2.1139537852297545

Epoch: 5| Step: 9
Training loss: 2.061068296432495
Validation loss: 2.2116152266020417

Epoch: 5| Step: 10
Training loss: 1.8438483476638794
Validation loss: 2.181796843005765

Epoch: 170| Step: 0
Training loss: 2.1578691005706787
Validation loss: 2.0660402031355005

Epoch: 5| Step: 1
Training loss: 1.5665619373321533
Validation loss: 2.144943161677289

Epoch: 5| Step: 2
Training loss: 2.252903699874878
Validation loss: 2.139411803214781

Epoch: 5| Step: 3
Training loss: 1.8784908056259155
Validation loss: 2.201334653362151

Epoch: 5| Step: 4
Training loss: 2.811858654022217
Validation loss: 2.132586315114011

Epoch: 5| Step: 5
Training loss: 2.428595781326294
Validation loss: 2.2185247969883743

Epoch: 5| Step: 6
Training loss: 3.043924331665039
Validation loss: 2.2935084604447886

Epoch: 5| Step: 7
Training loss: 1.7749649286270142
Validation loss: 2.154980574884722

Epoch: 5| Step: 8
Training loss: 1.9769903421401978
Validation loss: 2.1983614685714885

Epoch: 5| Step: 9
Training loss: 1.9158189296722412
Validation loss: 2.2657799464400097

Epoch: 5| Step: 10
Training loss: 1.7742433547973633
Validation loss: 2.2272206352603052

Epoch: 171| Step: 0
Training loss: 2.1675069332122803
Validation loss: 2.2507772317496677

Epoch: 5| Step: 1
Training loss: 2.175250768661499
Validation loss: 2.2016161244402648

Epoch: 5| Step: 2
Training loss: 1.7747529745101929
Validation loss: 2.1687847875779673

Epoch: 5| Step: 3
Training loss: 2.267216205596924
Validation loss: 2.2048474921975085

Epoch: 5| Step: 4
Training loss: 1.7963244915008545
Validation loss: 2.1119542916615806

Epoch: 5| Step: 5
Training loss: 2.0341219902038574
Validation loss: 2.2671953401257916

Epoch: 5| Step: 6
Training loss: 2.0524213314056396
Validation loss: 2.1749061948509625

Epoch: 5| Step: 7
Training loss: 2.238961696624756
Validation loss: 2.1497089888459895

Epoch: 5| Step: 8
Training loss: 1.889683485031128
Validation loss: 2.175367752710978

Epoch: 5| Step: 9
Training loss: 2.147453784942627
Validation loss: 2.1405164990373837

Epoch: 5| Step: 10
Training loss: 2.7787351608276367
Validation loss: 2.1275043205548356

Epoch: 172| Step: 0
Training loss: 1.7650737762451172
Validation loss: 2.162500391724289

Epoch: 5| Step: 1
Training loss: 1.7412984371185303
Validation loss: 2.1941027525932557

Epoch: 5| Step: 2
Training loss: 2.0006117820739746
Validation loss: 2.3104695966166835

Epoch: 5| Step: 3
Training loss: 2.7325515747070312
Validation loss: 2.156999618776383

Epoch: 5| Step: 4
Training loss: 2.0105884075164795
Validation loss: 2.1617878303732923

Epoch: 5| Step: 5
Training loss: 1.7028003931045532
Validation loss: 2.2492665552323863

Epoch: 5| Step: 6
Training loss: 2.207017660140991
Validation loss: 2.2222662843683714

Epoch: 5| Step: 7
Training loss: 2.694627285003662
Validation loss: 2.20326034228007

Epoch: 5| Step: 8
Training loss: 2.032052516937256
Validation loss: 2.2066466449409403

Epoch: 5| Step: 9
Training loss: 2.1518912315368652
Validation loss: 2.188600445306429

Epoch: 5| Step: 10
Training loss: 1.5341581106185913
Validation loss: 2.232579964463429

Epoch: 173| Step: 0
Training loss: 2.1259560585021973
Validation loss: 2.191860419447704

Epoch: 5| Step: 1
Training loss: 2.567533016204834
Validation loss: 2.196105800649171

Epoch: 5| Step: 2
Training loss: 1.661184310913086
Validation loss: 2.2558015572127474

Epoch: 5| Step: 3
Training loss: 2.917870283126831
Validation loss: 2.2574725279244046

Epoch: 5| Step: 4
Training loss: 1.7298305034637451
Validation loss: 2.2170854409535727

Epoch: 5| Step: 5
Training loss: 2.3440933227539062
Validation loss: 2.2308485495146884

Epoch: 5| Step: 6
Training loss: 2.7926650047302246
Validation loss: 2.224883105165215

Epoch: 5| Step: 7
Training loss: 1.4033215045928955
Validation loss: 2.2333068065745856

Epoch: 5| Step: 8
Training loss: 2.514551877975464
Validation loss: 2.166462823908816

Epoch: 5| Step: 9
Training loss: 2.0693211555480957
Validation loss: 2.2523666735618346

Epoch: 5| Step: 10
Training loss: 1.7093106508255005
Validation loss: 2.207886536916097

Epoch: 174| Step: 0
Training loss: 2.6077141761779785
Validation loss: 2.2166085038133847

Epoch: 5| Step: 1
Training loss: 2.1179516315460205
Validation loss: 2.202600822653822

Epoch: 5| Step: 2
Training loss: 1.8256618976593018
Validation loss: 2.1500154682385024

Epoch: 5| Step: 3
Training loss: 1.9579139947891235
Validation loss: 2.1759744946674635

Epoch: 5| Step: 4
Training loss: 2.7562129497528076
Validation loss: 2.0714347939337454

Epoch: 5| Step: 5
Training loss: 2.386531352996826
Validation loss: 2.1836514421688613

Epoch: 5| Step: 6
Training loss: 1.1903403997421265
Validation loss: 2.1931212602123136

Epoch: 5| Step: 7
Training loss: 1.854560136795044
Validation loss: 2.1789581775665283

Epoch: 5| Step: 8
Training loss: 1.8900505304336548
Validation loss: 2.1313748974953928

Epoch: 5| Step: 9
Training loss: 2.1003012657165527
Validation loss: 2.136610524628752

Epoch: 5| Step: 10
Training loss: 3.0690975189208984
Validation loss: 2.13586760592717

Epoch: 175| Step: 0
Training loss: 2.0113515853881836
Validation loss: 2.1683808911231255

Epoch: 5| Step: 1
Training loss: 2.251966953277588
Validation loss: 2.1595711631159626

Epoch: 5| Step: 2
Training loss: 1.8785642385482788
Validation loss: 2.1478920841729767

Epoch: 5| Step: 3
Training loss: 2.0867087841033936
Validation loss: 2.173692801947235

Epoch: 5| Step: 4
Training loss: 1.4722245931625366
Validation loss: 2.0771073590042772

Epoch: 5| Step: 5
Training loss: 1.7389891147613525
Validation loss: 2.1960659950010237

Epoch: 5| Step: 6
Training loss: 2.3661205768585205
Validation loss: 2.130369331247063

Epoch: 5| Step: 7
Training loss: 2.8703339099884033
Validation loss: 2.0834372838338218

Epoch: 5| Step: 8
Training loss: 1.9661033153533936
Validation loss: 2.1366687769530923

Epoch: 5| Step: 9
Training loss: 2.3875932693481445
Validation loss: 2.161974145520118

Epoch: 5| Step: 10
Training loss: 2.497586488723755
Validation loss: 2.072152655611756

Epoch: 176| Step: 0
Training loss: 2.052795886993408
Validation loss: 2.1758393420968005

Epoch: 5| Step: 1
Training loss: 1.9549306631088257
Validation loss: 2.1559660498813917

Epoch: 5| Step: 2
Training loss: 2.845820665359497
Validation loss: 2.110869376890121

Epoch: 5| Step: 3
Training loss: 2.214830160140991
Validation loss: 2.127735432758126

Epoch: 5| Step: 4
Training loss: 2.275986433029175
Validation loss: 2.1367561868442

Epoch: 5| Step: 5
Training loss: 1.757836937904358
Validation loss: 2.138647366595525

Epoch: 5| Step: 6
Training loss: 1.978509545326233
Validation loss: 2.2351663240822415

Epoch: 5| Step: 7
Training loss: 1.8253206014633179
Validation loss: 2.17584704583691

Epoch: 5| Step: 8
Training loss: 2.4286468029022217
Validation loss: 2.1852335083869194

Epoch: 5| Step: 9
Training loss: 1.6822547912597656
Validation loss: 2.2847949561252388

Epoch: 5| Step: 10
Training loss: 2.2971482276916504
Validation loss: 2.1153940462297007

Epoch: 177| Step: 0
Training loss: 1.4746954441070557
Validation loss: 2.2213489086397233

Epoch: 5| Step: 1
Training loss: 2.2368245124816895
Validation loss: 2.1565353075663247

Epoch: 5| Step: 2
Training loss: 2.1651298999786377
Validation loss: 2.312866066091804

Epoch: 5| Step: 3
Training loss: 1.9849494695663452
Validation loss: 2.128618154474484

Epoch: 5| Step: 4
Training loss: 1.9297094345092773
Validation loss: 2.1628985302422636

Epoch: 5| Step: 5
Training loss: 2.578993320465088
Validation loss: 2.2068294684092202

Epoch: 5| Step: 6
Training loss: 2.2469077110290527
Validation loss: 2.19846514988971

Epoch: 5| Step: 7
Training loss: 2.2839176654815674
Validation loss: 2.1558176932796353

Epoch: 5| Step: 8
Training loss: 1.7753328084945679
Validation loss: 2.202038626517019

Epoch: 5| Step: 9
Training loss: 2.5264594554901123
Validation loss: 2.1372531460177515

Epoch: 5| Step: 10
Training loss: 1.7202847003936768
Validation loss: 2.2003135604243123

Epoch: 178| Step: 0
Training loss: 2.0582950115203857
Validation loss: 2.1189165679357385

Epoch: 5| Step: 1
Training loss: 2.395129442214966
Validation loss: 2.150488425326604

Epoch: 5| Step: 2
Training loss: 2.274294853210449
Validation loss: 2.175957772039598

Epoch: 5| Step: 3
Training loss: 2.5677037239074707
Validation loss: 2.051530081738708

Epoch: 5| Step: 4
Training loss: 2.4998810291290283
Validation loss: 2.1736931211204937

Epoch: 5| Step: 5
Training loss: 2.011079788208008
Validation loss: 2.112114344873736

Epoch: 5| Step: 6
Training loss: 2.1352620124816895
Validation loss: 2.1104137743673017

Epoch: 5| Step: 7
Training loss: 1.4373950958251953
Validation loss: 2.1747609082088677

Epoch: 5| Step: 8
Training loss: 1.731275200843811
Validation loss: 2.105159213466029

Epoch: 5| Step: 9
Training loss: 1.712506890296936
Validation loss: 2.1192881099639402

Epoch: 5| Step: 10
Training loss: 2.2839717864990234
Validation loss: 2.1716958092105005

Epoch: 179| Step: 0
Training loss: 2.2304158210754395
Validation loss: 2.1548574932159914

Epoch: 5| Step: 1
Training loss: 2.3498854637145996
Validation loss: 2.074995526703455

Epoch: 5| Step: 2
Training loss: 2.2942957878112793
Validation loss: 2.227704837758054

Epoch: 5| Step: 3
Training loss: 1.979288101196289
Validation loss: 2.163343773093275

Epoch: 5| Step: 4
Training loss: 2.0999999046325684
Validation loss: 2.107687445097072

Epoch: 5| Step: 5
Training loss: 2.2064826488494873
Validation loss: 2.141227219694404

Epoch: 5| Step: 6
Training loss: 2.132659435272217
Validation loss: 2.158863870046472

Epoch: 5| Step: 7
Training loss: 1.8988237380981445
Validation loss: 2.103739059099587

Epoch: 5| Step: 8
Training loss: 2.146216869354248
Validation loss: 2.1469425757726035

Epoch: 5| Step: 9
Training loss: 2.0921707153320312
Validation loss: 2.159515985878565

Epoch: 5| Step: 10
Training loss: 1.9403096437454224
Validation loss: 2.1714744132052184

Epoch: 180| Step: 0
Training loss: 2.5127367973327637
Validation loss: 2.1424892243518623

Epoch: 5| Step: 1
Training loss: 2.003962993621826
Validation loss: 2.125715583883306

Epoch: 5| Step: 2
Training loss: 2.4287428855895996
Validation loss: 2.188434621339203

Epoch: 5| Step: 3
Training loss: 1.7102235555648804
Validation loss: 2.1808031015498663

Epoch: 5| Step: 4
Training loss: 1.6159985065460205
Validation loss: 2.1979026602160547

Epoch: 5| Step: 5
Training loss: 1.7776155471801758
Validation loss: 2.211622776523713

Epoch: 5| Step: 6
Training loss: 2.3822274208068848
Validation loss: 2.1380542837163454

Epoch: 5| Step: 7
Training loss: 2.4066359996795654
Validation loss: 2.1042246036632086

Epoch: 5| Step: 8
Training loss: 1.4875848293304443
Validation loss: 2.133021711021341

Epoch: 5| Step: 9
Training loss: 1.612346887588501
Validation loss: 2.1097187111454625

Epoch: 5| Step: 10
Training loss: 2.540670156478882
Validation loss: 2.0431605154468166

Epoch: 181| Step: 0
Training loss: 2.4848179817199707
Validation loss: 2.0829731674604517

Epoch: 5| Step: 1
Training loss: 1.9420019388198853
Validation loss: 2.1690586100342455

Epoch: 5| Step: 2
Training loss: 2.275456190109253
Validation loss: 2.099041069707563

Epoch: 5| Step: 3
Training loss: 2.253068685531616
Validation loss: 2.063577307167874

Epoch: 5| Step: 4
Training loss: 1.906423807144165
Validation loss: 2.1897109503387124

Epoch: 5| Step: 5
Training loss: 1.8511219024658203
Validation loss: 2.079240878423055

Epoch: 5| Step: 6
Training loss: 2.269232988357544
Validation loss: 2.051727403876602

Epoch: 5| Step: 7
Training loss: 2.1262545585632324
Validation loss: 2.081221383105042

Epoch: 5| Step: 8
Training loss: 2.0817527770996094
Validation loss: 2.0725925942902923

Epoch: 5| Step: 9
Training loss: 1.3728570938110352
Validation loss: 2.153921209355836

Epoch: 5| Step: 10
Training loss: 2.423266887664795
Validation loss: 2.1343270168509534

Epoch: 182| Step: 0
Training loss: 2.0277624130249023
Validation loss: 2.0869780253338557

Epoch: 5| Step: 1
Training loss: 2.2088449001312256
Validation loss: 2.1419110862157678

Epoch: 5| Step: 2
Training loss: 2.301445245742798
Validation loss: 2.1498942811002015

Epoch: 5| Step: 3
Training loss: 1.5406529903411865
Validation loss: 2.1487793281514156

Epoch: 5| Step: 4
Training loss: 2.1958584785461426
Validation loss: 2.148701613949191

Epoch: 5| Step: 5
Training loss: 2.431645393371582
Validation loss: 2.2414558497808312

Epoch: 5| Step: 6
Training loss: 2.265336275100708
Validation loss: 2.158202850690452

Epoch: 5| Step: 7
Training loss: 2.370460271835327
Validation loss: 2.19251351459052

Epoch: 5| Step: 8
Training loss: 2.109257221221924
Validation loss: 2.2193054217164234

Epoch: 5| Step: 9
Training loss: 2.513631820678711
Validation loss: 2.2752225014471237

Epoch: 5| Step: 10
Training loss: 2.094686985015869
Validation loss: 2.213715760938583

Epoch: 183| Step: 0
Training loss: 1.6644405126571655
Validation loss: 2.2201889586705033

Epoch: 5| Step: 1
Training loss: 2.5531868934631348
Validation loss: 2.178066953536003

Epoch: 5| Step: 2
Training loss: 1.4163057804107666
Validation loss: 2.145484692306929

Epoch: 5| Step: 3
Training loss: 1.7020021677017212
Validation loss: 2.189853124721076

Epoch: 5| Step: 4
Training loss: 2.4570558071136475
Validation loss: 2.1852888958428496

Epoch: 5| Step: 5
Training loss: 1.9750397205352783
Validation loss: 2.1476980537496586

Epoch: 5| Step: 6
Training loss: 2.850674629211426
Validation loss: 2.1536246384343793

Epoch: 5| Step: 7
Training loss: 2.6463184356689453
Validation loss: 2.10916502757739

Epoch: 5| Step: 8
Training loss: 1.6814438104629517
Validation loss: 2.2092115417603524

Epoch: 5| Step: 9
Training loss: 2.1372833251953125
Validation loss: 2.1547710844265517

Epoch: 5| Step: 10
Training loss: 2.1806247234344482
Validation loss: 2.094929100364767

Epoch: 184| Step: 0
Training loss: 1.94660222530365
Validation loss: 2.130680953302691

Epoch: 5| Step: 1
Training loss: 2.138838768005371
Validation loss: 2.1452864831493748

Epoch: 5| Step: 2
Training loss: 2.3529491424560547
Validation loss: 2.0478805867574548

Epoch: 5| Step: 3
Training loss: 2.242180824279785
Validation loss: 2.12456851877192

Epoch: 5| Step: 4
Training loss: 1.916925072669983
Validation loss: 2.1537489045050835

Epoch: 5| Step: 5
Training loss: 1.974302887916565
Validation loss: 2.100809338272259

Epoch: 5| Step: 6
Training loss: 2.130398988723755
Validation loss: 2.0254545339974026

Epoch: 5| Step: 7
Training loss: 2.1227781772613525
Validation loss: 2.1369643595910843

Epoch: 5| Step: 8
Training loss: 2.082456111907959
Validation loss: 2.124648130068215

Epoch: 5| Step: 9
Training loss: 2.100057363510132
Validation loss: 2.216170698083857

Epoch: 5| Step: 10
Training loss: 2.4752631187438965
Validation loss: 2.151856607006442

Epoch: 185| Step: 0
Training loss: 1.4445030689239502
Validation loss: 2.2082745144444127

Epoch: 5| Step: 1
Training loss: 1.9424116611480713
Validation loss: 2.147043429395204

Epoch: 5| Step: 2
Training loss: 2.194511890411377
Validation loss: 2.1281658218752955

Epoch: 5| Step: 3
Training loss: 2.0737438201904297
Validation loss: 2.1802330068362656

Epoch: 5| Step: 4
Training loss: 2.1330909729003906
Validation loss: 2.1908186122935307

Epoch: 5| Step: 5
Training loss: 1.962052583694458
Validation loss: 2.2102338678093365

Epoch: 5| Step: 6
Training loss: 2.103846549987793
Validation loss: 2.2120419599676646

Epoch: 5| Step: 7
Training loss: 1.9717509746551514
Validation loss: 2.2898206762088242

Epoch: 5| Step: 8
Training loss: 2.031369686126709
Validation loss: 2.1610985443156254

Epoch: 5| Step: 9
Training loss: 2.3724892139434814
Validation loss: 2.1987282127462406

Epoch: 5| Step: 10
Training loss: 2.6885173320770264
Validation loss: 2.174438786763017

Epoch: 186| Step: 0
Training loss: 1.4710975885391235
Validation loss: 2.1412776208692983

Epoch: 5| Step: 1
Training loss: 1.8648639917373657
Validation loss: 2.131310212996698

Epoch: 5| Step: 2
Training loss: 1.9899349212646484
Validation loss: 2.1687245061320644

Epoch: 5| Step: 3
Training loss: 2.1166493892669678
Validation loss: 2.1660930405380907

Epoch: 5| Step: 4
Training loss: 1.9035089015960693
Validation loss: 2.1973921381017214

Epoch: 5| Step: 5
Training loss: 1.6409711837768555
Validation loss: 2.2025465913998183

Epoch: 5| Step: 6
Training loss: 2.7095417976379395
Validation loss: 2.1359505397017284

Epoch: 5| Step: 7
Training loss: 1.6701076030731201
Validation loss: 2.1854378972002255

Epoch: 5| Step: 8
Training loss: 2.0032906532287598
Validation loss: 2.226472605941116

Epoch: 5| Step: 9
Training loss: 2.12272310256958
Validation loss: 2.1893951264760827

Epoch: 5| Step: 10
Training loss: 3.140068769454956
Validation loss: 2.1446505746533795

Epoch: 187| Step: 0
Training loss: 2.90763783454895
Validation loss: 2.1421117269864647

Epoch: 5| Step: 1
Training loss: 1.965850830078125
Validation loss: 2.215806484222412

Epoch: 5| Step: 2
Training loss: 1.8197304010391235
Validation loss: 2.133393274840488

Epoch: 5| Step: 3
Training loss: 1.9321825504302979
Validation loss: 2.130362843954435

Epoch: 5| Step: 4
Training loss: 1.992066740989685
Validation loss: 2.143115679423014

Epoch: 5| Step: 5
Training loss: 1.4299004077911377
Validation loss: 2.148525490555712

Epoch: 5| Step: 6
Training loss: 2.0526511669158936
Validation loss: 2.119906994604295

Epoch: 5| Step: 7
Training loss: 2.7025341987609863
Validation loss: 2.09009051322937

Epoch: 5| Step: 8
Training loss: 2.4680709838867188
Validation loss: 2.1096229578859065

Epoch: 5| Step: 9
Training loss: 2.5159287452697754
Validation loss: 2.2219788464166785

Epoch: 5| Step: 10
Training loss: 1.7100481986999512
Validation loss: 2.2237342249962593

Epoch: 188| Step: 0
Training loss: 2.1746177673339844
Validation loss: 2.1633345568051903

Epoch: 5| Step: 1
Training loss: 1.753612756729126
Validation loss: 2.1255966130123345

Epoch: 5| Step: 2
Training loss: 2.1852424144744873
Validation loss: 2.0615127061002996

Epoch: 5| Step: 3
Training loss: 2.4024226665496826
Validation loss: 2.126531982934603

Epoch: 5| Step: 4
Training loss: 2.0677175521850586
Validation loss: 2.172216089822913

Epoch: 5| Step: 5
Training loss: 2.051459550857544
Validation loss: 2.163186429649271

Epoch: 5| Step: 6
Training loss: 2.252032995223999
Validation loss: 2.1651315612177693

Epoch: 5| Step: 7
Training loss: 2.3435051441192627
Validation loss: 2.165436501144081

Epoch: 5| Step: 8
Training loss: 2.0729644298553467
Validation loss: 2.197140521900628

Epoch: 5| Step: 9
Training loss: 1.8703267574310303
Validation loss: 2.213451830289697

Epoch: 5| Step: 10
Training loss: 2.186692476272583
Validation loss: 2.1646569390450754

Epoch: 189| Step: 0
Training loss: 1.9781954288482666
Validation loss: 2.200354345383183

Epoch: 5| Step: 1
Training loss: 1.6849693059921265
Validation loss: 2.201370655849416

Epoch: 5| Step: 2
Training loss: 2.1322684288024902
Validation loss: 2.1700338471320366

Epoch: 5| Step: 3
Training loss: 2.1104063987731934
Validation loss: 2.1035517108055855

Epoch: 5| Step: 4
Training loss: 2.449885606765747
Validation loss: 2.0969206081923617

Epoch: 5| Step: 5
Training loss: 2.087961196899414
Validation loss: 2.172738559784428

Epoch: 5| Step: 6
Training loss: 2.041529417037964
Validation loss: 2.1742067824127855

Epoch: 5| Step: 7
Training loss: 2.264127016067505
Validation loss: 2.116728613453527

Epoch: 5| Step: 8
Training loss: 1.648983359336853
Validation loss: 2.1309966066832184

Epoch: 5| Step: 9
Training loss: 2.7322890758514404
Validation loss: 2.2276123236584406

Epoch: 5| Step: 10
Training loss: 1.6196601390838623
Validation loss: 2.1525581165026595

Epoch: 190| Step: 0
Training loss: 1.9477876424789429
Validation loss: 2.1276848546920286

Epoch: 5| Step: 1
Training loss: 1.8615386486053467
Validation loss: 2.1641343434651694

Epoch: 5| Step: 2
Training loss: 1.904364824295044
Validation loss: 2.225330801420314

Epoch: 5| Step: 3
Training loss: 2.1082587242126465
Validation loss: 2.138548251121275

Epoch: 5| Step: 4
Training loss: 2.483515977859497
Validation loss: 2.149022181828817

Epoch: 5| Step: 5
Training loss: 2.2056660652160645
Validation loss: 2.2250060932610625

Epoch: 5| Step: 6
Training loss: 1.5672601461410522
Validation loss: 2.092265787944999

Epoch: 5| Step: 7
Training loss: 2.4384732246398926
Validation loss: 2.141942436977099

Epoch: 5| Step: 8
Training loss: 2.264059543609619
Validation loss: 2.194352796000819

Epoch: 5| Step: 9
Training loss: 2.227599859237671
Validation loss: 2.1108465707430275

Epoch: 5| Step: 10
Training loss: 2.2701833248138428
Validation loss: 2.0992015100294545

Epoch: 191| Step: 0
Training loss: 1.8815631866455078
Validation loss: 2.145756111350111

Epoch: 5| Step: 1
Training loss: 1.6667327880859375
Validation loss: 2.137551410223848

Epoch: 5| Step: 2
Training loss: 2.45586895942688
Validation loss: 2.093683554280189

Epoch: 5| Step: 3
Training loss: 1.8073982000350952
Validation loss: 2.178021172041534

Epoch: 5| Step: 4
Training loss: 1.949054479598999
Validation loss: 2.151738465473216

Epoch: 5| Step: 5
Training loss: 1.8204714059829712
Validation loss: 2.1607066944081295

Epoch: 5| Step: 6
Training loss: 2.021470546722412
Validation loss: 2.2021837426770117

Epoch: 5| Step: 7
Training loss: 2.41021990776062
Validation loss: 2.185371491216844

Epoch: 5| Step: 8
Training loss: 2.3905556201934814
Validation loss: 2.1765265310964277

Epoch: 5| Step: 9
Training loss: 2.5896077156066895
Validation loss: 2.1572192022877354

Epoch: 5| Step: 10
Training loss: 1.8649365901947021
Validation loss: 2.165469406753458

Epoch: 192| Step: 0
Training loss: 2.2092347145080566
Validation loss: 2.0913456075934955

Epoch: 5| Step: 1
Training loss: 1.7489897012710571
Validation loss: 2.2160550650729927

Epoch: 5| Step: 2
Training loss: 2.1648926734924316
Validation loss: 2.1777007092711744

Epoch: 5| Step: 3
Training loss: 2.3719394207000732
Validation loss: 2.1037070520462526

Epoch: 5| Step: 4
Training loss: 1.942283272743225
Validation loss: 2.167211042937412

Epoch: 5| Step: 5
Training loss: 1.9140784740447998
Validation loss: 2.1859619527734737

Epoch: 5| Step: 6
Training loss: 1.7982991933822632
Validation loss: 2.14073577491186

Epoch: 5| Step: 7
Training loss: 2.369196891784668
Validation loss: 2.22441206952577

Epoch: 5| Step: 8
Training loss: 2.193470001220703
Validation loss: 2.247681097317767

Epoch: 5| Step: 9
Training loss: 1.718030571937561
Validation loss: 2.09766823117451

Epoch: 5| Step: 10
Training loss: 2.2108335494995117
Validation loss: 2.1900463540066957

Epoch: 193| Step: 0
Training loss: 2.040316104888916
Validation loss: 2.129009590354017

Epoch: 5| Step: 1
Training loss: 2.507894992828369
Validation loss: 2.265986465638684

Epoch: 5| Step: 2
Training loss: 2.2350311279296875
Validation loss: 2.1877663135528564

Epoch: 5| Step: 3
Training loss: 2.115999698638916
Validation loss: 2.1510791547836794

Epoch: 5| Step: 4
Training loss: 2.163102149963379
Validation loss: 2.1387773188211585

Epoch: 5| Step: 5
Training loss: 2.1549229621887207
Validation loss: 2.0452930824730986

Epoch: 5| Step: 6
Training loss: 1.7574317455291748
Validation loss: 2.203404905975506

Epoch: 5| Step: 7
Training loss: 1.6793105602264404
Validation loss: 2.1620797341869724

Epoch: 5| Step: 8
Training loss: 1.8222919702529907
Validation loss: 2.2105614857007096

Epoch: 5| Step: 9
Training loss: 2.1343801021575928
Validation loss: 2.166823069254557

Epoch: 5| Step: 10
Training loss: 2.37023663520813
Validation loss: 2.1052950146377727

Epoch: 194| Step: 0
Training loss: 1.799156904220581
Validation loss: 2.197978311969388

Epoch: 5| Step: 1
Training loss: 1.700211763381958
Validation loss: 2.1686160436240574

Epoch: 5| Step: 2
Training loss: 2.74670672416687
Validation loss: 2.053687854479718

Epoch: 5| Step: 3
Training loss: 2.0476603507995605
Validation loss: 2.119310180346171

Epoch: 5| Step: 4
Training loss: 2.1932272911071777
Validation loss: 2.14368603562796

Epoch: 5| Step: 5
Training loss: 1.7589190006256104
Validation loss: 2.0230252717130925

Epoch: 5| Step: 6
Training loss: 2.5632007122039795
Validation loss: 2.130378166834513

Epoch: 5| Step: 7
Training loss: 2.454401969909668
Validation loss: 2.070912871309506

Epoch: 5| Step: 8
Training loss: 2.126246213912964
Validation loss: 2.143031358718872

Epoch: 5| Step: 9
Training loss: 1.386238932609558
Validation loss: 2.1039578478823424

Epoch: 5| Step: 10
Training loss: 2.3696467876434326
Validation loss: 2.137139735683318

Epoch: 195| Step: 0
Training loss: 2.052432060241699
Validation loss: 2.1797482429012174

Epoch: 5| Step: 1
Training loss: 2.0066165924072266
Validation loss: 2.0392392732763804

Epoch: 5| Step: 2
Training loss: 2.135331630706787
Validation loss: 2.185264916830165

Epoch: 5| Step: 3
Training loss: 3.2685647010803223
Validation loss: 2.1729891325837825

Epoch: 5| Step: 4
Training loss: 2.556539297103882
Validation loss: 2.221678040360892

Epoch: 5| Step: 5
Training loss: 1.8180744647979736
Validation loss: 2.1533038077815885

Epoch: 5| Step: 6
Training loss: 2.2110989093780518
Validation loss: 2.160375432301593

Epoch: 5| Step: 7
Training loss: 1.3680585622787476
Validation loss: 2.2230702113079768

Epoch: 5| Step: 8
Training loss: 1.8244736194610596
Validation loss: 2.1731799238471576

Epoch: 5| Step: 9
Training loss: 2.017479419708252
Validation loss: 2.1148906548817954

Epoch: 5| Step: 10
Training loss: 1.8546109199523926
Validation loss: 2.2527582953053136

Epoch: 196| Step: 0
Training loss: 1.9031782150268555
Validation loss: 2.2416821500306487

Epoch: 5| Step: 1
Training loss: 2.1468136310577393
Validation loss: 2.2373839373229654

Epoch: 5| Step: 2
Training loss: 2.358116626739502
Validation loss: 2.162440685815709

Epoch: 5| Step: 3
Training loss: 2.0225958824157715
Validation loss: 2.1353644811978905

Epoch: 5| Step: 4
Training loss: 2.0835978984832764
Validation loss: 2.1459653300623738

Epoch: 5| Step: 5
Training loss: 2.160102128982544
Validation loss: 2.1741802564231296

Epoch: 5| Step: 6
Training loss: 1.9945729970932007
Validation loss: 2.159805905434393

Epoch: 5| Step: 7
Training loss: 2.157676935195923
Validation loss: 2.233331762334352

Epoch: 5| Step: 8
Training loss: 2.5317320823669434
Validation loss: 2.125442152382225

Epoch: 5| Step: 9
Training loss: 1.7457151412963867
Validation loss: 2.148672601228119

Epoch: 5| Step: 10
Training loss: 2.344212770462036
Validation loss: 2.1610347019728793

Epoch: 197| Step: 0
Training loss: 1.6351410150527954
Validation loss: 2.1828195510372037

Epoch: 5| Step: 1
Training loss: 2.7156643867492676
Validation loss: 2.18358439014804

Epoch: 5| Step: 2
Training loss: 2.037794351577759
Validation loss: 2.154692678041356

Epoch: 5| Step: 3
Training loss: 1.7465425729751587
Validation loss: 2.0053219128680486

Epoch: 5| Step: 4
Training loss: 1.7024043798446655
Validation loss: 2.1228668330818095

Epoch: 5| Step: 5
Training loss: 1.9156519174575806
Validation loss: 2.112385344761674

Epoch: 5| Step: 6
Training loss: 2.3442904949188232
Validation loss: 2.151001607218096

Epoch: 5| Step: 7
Training loss: 2.2394614219665527
Validation loss: 2.151144891656855

Epoch: 5| Step: 8
Training loss: 2.348601818084717
Validation loss: 2.1892853552295315

Epoch: 5| Step: 9
Training loss: 1.718314528465271
Validation loss: 2.1520739793777466

Epoch: 5| Step: 10
Training loss: 1.8787012100219727
Validation loss: 2.1052921766875894

Epoch: 198| Step: 0
Training loss: 1.9076175689697266
Validation loss: 2.0856640723443802

Epoch: 5| Step: 1
Training loss: 2.627025842666626
Validation loss: 2.0978983948307652

Epoch: 5| Step: 2
Training loss: 2.1048288345336914
Validation loss: 2.0398710773837183

Epoch: 5| Step: 3
Training loss: 2.366598606109619
Validation loss: 2.1268514484487553

Epoch: 5| Step: 4
Training loss: 2.0671706199645996
Validation loss: 2.0964600604067565

Epoch: 5| Step: 5
Training loss: 1.8246877193450928
Validation loss: 2.1314850135516097

Epoch: 5| Step: 6
Training loss: 1.5664197206497192
Validation loss: 2.0571416244711926

Epoch: 5| Step: 7
Training loss: 1.8628278970718384
Validation loss: 2.1525471415570987

Epoch: 5| Step: 8
Training loss: 1.991864800453186
Validation loss: 2.082367067695946

Epoch: 5| Step: 9
Training loss: 1.565047025680542
Validation loss: 2.076365291431386

Epoch: 5| Step: 10
Training loss: 2.656336545944214
Validation loss: 2.133751412873627

Epoch: 199| Step: 0
Training loss: 2.425288200378418
Validation loss: 2.190816589581069

Epoch: 5| Step: 1
Training loss: 1.6548612117767334
Validation loss: 2.146299400637227

Epoch: 5| Step: 2
Training loss: 1.901210069656372
Validation loss: 2.1513574072109756

Epoch: 5| Step: 3
Training loss: 2.03153133392334
Validation loss: 2.110367105853173

Epoch: 5| Step: 4
Training loss: 1.877476453781128
Validation loss: 2.039140339820616

Epoch: 5| Step: 5
Training loss: 2.130380153656006
Validation loss: 2.0639000349147345

Epoch: 5| Step: 6
Training loss: 1.6823484897613525
Validation loss: 2.1716363250568347

Epoch: 5| Step: 7
Training loss: 2.449948787689209
Validation loss: 2.191290973335184

Epoch: 5| Step: 8
Training loss: 2.7296974658966064
Validation loss: 2.1741105305251254

Epoch: 5| Step: 9
Training loss: 1.7965314388275146
Validation loss: 2.19003265519296

Epoch: 5| Step: 10
Training loss: 2.2845771312713623
Validation loss: 2.1520772800650647

Epoch: 200| Step: 0
Training loss: 2.425429582595825
Validation loss: 2.2001823456056657

Epoch: 5| Step: 1
Training loss: 2.139336109161377
Validation loss: 2.169773586334721

Epoch: 5| Step: 2
Training loss: 1.7621482610702515
Validation loss: 2.125957214704124

Epoch: 5| Step: 3
Training loss: 1.61871337890625
Validation loss: 2.258928334841164

Epoch: 5| Step: 4
Training loss: 2.016043186187744
Validation loss: 2.1062018307306434

Epoch: 5| Step: 5
Training loss: 2.3078761100769043
Validation loss: 2.111270257221755

Epoch: 5| Step: 6
Training loss: 2.337599515914917
Validation loss: 2.165616960935695

Epoch: 5| Step: 7
Training loss: 1.7778310775756836
Validation loss: 2.2671026568258963

Epoch: 5| Step: 8
Training loss: 2.8376383781433105
Validation loss: 2.112017595639793

Epoch: 5| Step: 9
Training loss: 1.553898811340332
Validation loss: 2.165167675223402

Epoch: 5| Step: 10
Training loss: 2.257697343826294
Validation loss: 2.1586172837083057

Epoch: 201| Step: 0
Training loss: 2.0902585983276367
Validation loss: 2.1854533879987654

Epoch: 5| Step: 1
Training loss: 2.7882907390594482
Validation loss: 2.193592615025018

Epoch: 5| Step: 2
Training loss: 1.9590816497802734
Validation loss: 2.057837957976967

Epoch: 5| Step: 3
Training loss: 1.2872872352600098
Validation loss: 2.1595399405366633

Epoch: 5| Step: 4
Training loss: 2.0107810497283936
Validation loss: 2.121729568768573

Epoch: 5| Step: 5
Training loss: 1.504281759262085
Validation loss: 2.1463471586986254

Epoch: 5| Step: 6
Training loss: 1.4868439435958862
Validation loss: 2.120933618596805

Epoch: 5| Step: 7
Training loss: 2.2162938117980957
Validation loss: 2.124047202448691

Epoch: 5| Step: 8
Training loss: 2.6051344871520996
Validation loss: 2.1057828780143493

Epoch: 5| Step: 9
Training loss: 2.1804847717285156
Validation loss: 2.079812583102975

Epoch: 5| Step: 10
Training loss: 2.1305572986602783
Validation loss: 2.067372250300582

Epoch: 202| Step: 0
Training loss: 2.032926082611084
Validation loss: 2.0598684869786745

Epoch: 5| Step: 1
Training loss: 2.3215384483337402
Validation loss: 2.1617517625131915

Epoch: 5| Step: 2
Training loss: 1.8955367803573608
Validation loss: 2.1963734729315645

Epoch: 5| Step: 3
Training loss: 1.5244085788726807
Validation loss: 2.16776708890033

Epoch: 5| Step: 4
Training loss: 2.5835978984832764
Validation loss: 2.2139870787179596

Epoch: 5| Step: 5
Training loss: 2.1235053539276123
Validation loss: 2.16369261792911

Epoch: 5| Step: 6
Training loss: 2.0133111476898193
Validation loss: 2.0995406617400465

Epoch: 5| Step: 7
Training loss: 1.8712940216064453
Validation loss: 2.1730399388138966

Epoch: 5| Step: 8
Training loss: 2.4706077575683594
Validation loss: 2.0520776189783567

Epoch: 5| Step: 9
Training loss: 1.9572746753692627
Validation loss: 2.1106689668470815

Epoch: 5| Step: 10
Training loss: 2.020885944366455
Validation loss: 2.1633135516156434

Epoch: 203| Step: 0
Training loss: 1.9463615417480469
Validation loss: 2.1252656521335727

Epoch: 5| Step: 1
Training loss: 1.6277875900268555
Validation loss: 2.142304410216629

Epoch: 5| Step: 2
Training loss: 2.0516064167022705
Validation loss: 2.0048825317813503

Epoch: 5| Step: 3
Training loss: 1.7404972314834595
Validation loss: 2.130662948854508

Epoch: 5| Step: 4
Training loss: 2.1009790897369385
Validation loss: 2.1672409529327066

Epoch: 5| Step: 5
Training loss: 1.88410222530365
Validation loss: 2.1138783526676956

Epoch: 5| Step: 6
Training loss: 2.66241192817688
Validation loss: 2.1145428560113393

Epoch: 5| Step: 7
Training loss: 2.581099033355713
Validation loss: 2.164533207493444

Epoch: 5| Step: 8
Training loss: 1.6545436382293701
Validation loss: 2.1002151299548406

Epoch: 5| Step: 9
Training loss: 1.5822885036468506
Validation loss: 2.1487670970219437

Epoch: 5| Step: 10
Training loss: 2.675527811050415
Validation loss: 2.0892490904818297

Epoch: 204| Step: 0
Training loss: 1.8150672912597656
Validation loss: 2.0926329102567447

Epoch: 5| Step: 1
Training loss: 2.0186169147491455
Validation loss: 2.104117283257105

Epoch: 5| Step: 2
Training loss: 2.3698244094848633
Validation loss: 2.0366526444753013

Epoch: 5| Step: 3
Training loss: 2.199967861175537
Validation loss: 2.1697680155436196

Epoch: 5| Step: 4
Training loss: 2.751415491104126
Validation loss: 2.1205800515349194

Epoch: 5| Step: 5
Training loss: 1.8963247537612915
Validation loss: 2.171086008830737

Epoch: 5| Step: 6
Training loss: 2.0485737323760986
Validation loss: 2.041256614910659

Epoch: 5| Step: 7
Training loss: 2.167292833328247
Validation loss: 2.1161921280686573

Epoch: 5| Step: 8
Training loss: 1.7033913135528564
Validation loss: 2.1278631917891966

Epoch: 5| Step: 9
Training loss: 2.481646776199341
Validation loss: 2.160092200002363

Epoch: 5| Step: 10
Training loss: 1.4306309223175049
Validation loss: 2.1543856820752545

Epoch: 205| Step: 0
Training loss: 1.8311150074005127
Validation loss: 2.082103486984007

Epoch: 5| Step: 1
Training loss: 1.7246792316436768
Validation loss: 2.0724995969444193

Epoch: 5| Step: 2
Training loss: 2.3958985805511475
Validation loss: 2.1926643540782313

Epoch: 5| Step: 3
Training loss: 1.9726979732513428
Validation loss: 2.2165731717181463

Epoch: 5| Step: 4
Training loss: 2.4207606315612793
Validation loss: 2.063869078954061

Epoch: 5| Step: 5
Training loss: 1.851027488708496
Validation loss: 2.1764306458093787

Epoch: 5| Step: 6
Training loss: 2.350670576095581
Validation loss: 2.2095545773865073

Epoch: 5| Step: 7
Training loss: 2.090294122695923
Validation loss: 2.1165061381555375

Epoch: 5| Step: 8
Training loss: 2.499379873275757
Validation loss: 2.126691843873711

Epoch: 5| Step: 9
Training loss: 1.4917856454849243
Validation loss: 2.1217663723935365

Epoch: 5| Step: 10
Training loss: 1.5762077569961548
Validation loss: 2.0821017411447342

Epoch: 206| Step: 0
Training loss: 2.05729341506958
Validation loss: 2.1763231703030166

Epoch: 5| Step: 1
Training loss: 1.8864809274673462
Validation loss: 2.057992068670129

Epoch: 5| Step: 2
Training loss: 2.117351770401001
Validation loss: 2.14511453208103

Epoch: 5| Step: 3
Training loss: 2.1953206062316895
Validation loss: 2.058374676653134

Epoch: 5| Step: 4
Training loss: 2.5306150913238525
Validation loss: 2.0253029395175237

Epoch: 5| Step: 5
Training loss: 1.9353306293487549
Validation loss: 2.22772793616018

Epoch: 5| Step: 6
Training loss: 1.8031162023544312
Validation loss: 2.1397312994926208

Epoch: 5| Step: 7
Training loss: 1.9583183526992798
Validation loss: 2.147482632308878

Epoch: 5| Step: 8
Training loss: 1.9516193866729736
Validation loss: 2.1711771283098447

Epoch: 5| Step: 9
Training loss: 2.100642681121826
Validation loss: 2.089811812164963

Epoch: 5| Step: 10
Training loss: 2.482748508453369
Validation loss: 2.1108832410586778

Epoch: 207| Step: 0
Training loss: 1.4691336154937744
Validation loss: 2.129424477136263

Epoch: 5| Step: 1
Training loss: 2.6562771797180176
Validation loss: 2.1666904495608423

Epoch: 5| Step: 2
Training loss: 2.342992067337036
Validation loss: 2.1750533093688307

Epoch: 5| Step: 3
Training loss: 1.621206521987915
Validation loss: 2.0256807804107666

Epoch: 5| Step: 4
Training loss: 2.1350619792938232
Validation loss: 2.1155787719193326

Epoch: 5| Step: 5
Training loss: 2.0994904041290283
Validation loss: 2.1819481670215564

Epoch: 5| Step: 6
Training loss: 2.3561012744903564
Validation loss: 2.1141696463349047

Epoch: 5| Step: 7
Training loss: 2.1262784004211426
Validation loss: 2.2069273956360353

Epoch: 5| Step: 8
Training loss: 2.2293524742126465
Validation loss: 2.1640651046588855

Epoch: 5| Step: 9
Training loss: 2.3162648677825928
Validation loss: 2.1389110549803703

Epoch: 5| Step: 10
Training loss: 1.6000683307647705
Validation loss: 2.0575914959753714

Epoch: 208| Step: 0
Training loss: 2.907993793487549
Validation loss: 2.193369011725149

Epoch: 5| Step: 1
Training loss: 1.963817834854126
Validation loss: 2.1322770708350727

Epoch: 5| Step: 2
Training loss: 1.7464869022369385
Validation loss: 2.0557269383502264

Epoch: 5| Step: 3
Training loss: 2.0623583793640137
Validation loss: 2.1699872939817366

Epoch: 5| Step: 4
Training loss: 1.7714283466339111
Validation loss: 2.1913667750614945

Epoch: 5| Step: 5
Training loss: 2.154632568359375
Validation loss: 2.125094808557982

Epoch: 5| Step: 6
Training loss: 1.6492305994033813
Validation loss: 2.170066559186546

Epoch: 5| Step: 7
Training loss: 2.726181745529175
Validation loss: 2.1001008813099196

Epoch: 5| Step: 8
Training loss: 2.4661097526550293
Validation loss: 2.200898511435396

Epoch: 5| Step: 9
Training loss: 1.8224111795425415
Validation loss: 2.1806146919086413

Epoch: 5| Step: 10
Training loss: 1.9019759893417358
Validation loss: 2.1131508606736378

Epoch: 209| Step: 0
Training loss: 1.8565746545791626
Validation loss: 2.1856928358795824

Epoch: 5| Step: 1
Training loss: 2.2840991020202637
Validation loss: 2.1976514554792836

Epoch: 5| Step: 2
Training loss: 2.022921323776245
Validation loss: 2.0638050725383144

Epoch: 5| Step: 3
Training loss: 2.2657523155212402
Validation loss: 2.137289108768586

Epoch: 5| Step: 4
Training loss: 1.6978524923324585
Validation loss: 2.1480011337546894

Epoch: 5| Step: 5
Training loss: 2.4302427768707275
Validation loss: 2.1319162102155786

Epoch: 5| Step: 6
Training loss: 2.1739110946655273
Validation loss: 2.2358305787527435

Epoch: 5| Step: 7
Training loss: 1.5755136013031006
Validation loss: 2.054438375657605

Epoch: 5| Step: 8
Training loss: 2.02188777923584
Validation loss: 2.084014597759452

Epoch: 5| Step: 9
Training loss: 2.1824769973754883
Validation loss: 2.1595259635679183

Epoch: 5| Step: 10
Training loss: 2.4790420532226562
Validation loss: 2.1375960098799838

Epoch: 210| Step: 0
Training loss: 2.1654982566833496
Validation loss: 2.102308691188853

Epoch: 5| Step: 1
Training loss: 1.304810881614685
Validation loss: 2.114382738708168

Epoch: 5| Step: 2
Training loss: 1.7787240743637085
Validation loss: 2.1616530482487013

Epoch: 5| Step: 3
Training loss: 2.3791983127593994
Validation loss: 2.060472208966491

Epoch: 5| Step: 4
Training loss: 2.502990245819092
Validation loss: 2.145006723301385

Epoch: 5| Step: 5
Training loss: 2.2115848064422607
Validation loss: 2.183809144522554

Epoch: 5| Step: 6
Training loss: 2.2581796646118164
Validation loss: 2.097799434456774

Epoch: 5| Step: 7
Training loss: 1.819801688194275
Validation loss: 2.084357503921755

Epoch: 5| Step: 8
Training loss: 2.440289258956909
Validation loss: 2.177307164797219

Epoch: 5| Step: 9
Training loss: 1.5867676734924316
Validation loss: 2.2090519282125656

Epoch: 5| Step: 10
Training loss: 2.486989974975586
Validation loss: 2.0767197493583924

Epoch: 211| Step: 0
Training loss: 1.579239845275879
Validation loss: 2.0572821081325574

Epoch: 5| Step: 1
Training loss: 2.0593385696411133
Validation loss: 2.128962891076201

Epoch: 5| Step: 2
Training loss: 2.3442766666412354
Validation loss: 2.0570546055352814

Epoch: 5| Step: 3
Training loss: 2.140326976776123
Validation loss: 2.1556288350012993

Epoch: 5| Step: 4
Training loss: 1.6160211563110352
Validation loss: 2.059017754370166

Epoch: 5| Step: 5
Training loss: 2.1682486534118652
Validation loss: 2.1445428363738523

Epoch: 5| Step: 6
Training loss: 2.1690571308135986
Validation loss: 2.130734369318972

Epoch: 5| Step: 7
Training loss: 1.5026075839996338
Validation loss: 2.1549288508712605

Epoch: 5| Step: 8
Training loss: 2.1871089935302734
Validation loss: 2.032816938174668

Epoch: 5| Step: 9
Training loss: 2.6379141807556152
Validation loss: 2.073388999508273

Epoch: 5| Step: 10
Training loss: 2.6632802486419678
Validation loss: 2.131080298013585

Epoch: 212| Step: 0
Training loss: 1.94184148311615
Validation loss: 2.1269980528021373

Epoch: 5| Step: 1
Training loss: 2.179046154022217
Validation loss: 2.1173377370321624

Epoch: 5| Step: 2
Training loss: 1.971022367477417
Validation loss: 2.0602843223079557

Epoch: 5| Step: 3
Training loss: 1.9749215841293335
Validation loss: 2.113547243097777

Epoch: 5| Step: 4
Training loss: 2.4342525005340576
Validation loss: 2.118472380022849

Epoch: 5| Step: 5
Training loss: 2.1183927059173584
Validation loss: 2.1101463071761595

Epoch: 5| Step: 6
Training loss: 2.474010944366455
Validation loss: 2.1334047009868007

Epoch: 5| Step: 7
Training loss: 1.6581566333770752
Validation loss: 2.074280901621747

Epoch: 5| Step: 8
Training loss: 2.2646965980529785
Validation loss: 2.072435414919289

Epoch: 5| Step: 9
Training loss: 2.0323400497436523
Validation loss: 2.140058514892414

Epoch: 5| Step: 10
Training loss: 1.719490885734558
Validation loss: 2.0558545076718895

Epoch: 213| Step: 0
Training loss: 2.2801568508148193
Validation loss: 2.2283065498516126

Epoch: 5| Step: 1
Training loss: 1.2677191495895386
Validation loss: 2.156410571067564

Epoch: 5| Step: 2
Training loss: 1.4691424369812012
Validation loss: 2.1202235426954044

Epoch: 5| Step: 3
Training loss: 1.879630446434021
Validation loss: 2.2072443475005445

Epoch: 5| Step: 4
Training loss: 2.1828975677490234
Validation loss: 2.1654759965917116

Epoch: 5| Step: 5
Training loss: 2.3392586708068848
Validation loss: 2.1468373665245633

Epoch: 5| Step: 6
Training loss: 2.670745849609375
Validation loss: 2.187892093453356

Epoch: 5| Step: 7
Training loss: 1.9654693603515625
Validation loss: 2.1183906075774983

Epoch: 5| Step: 8
Training loss: 1.8922548294067383
Validation loss: 2.1274261551518596

Epoch: 5| Step: 9
Training loss: 2.2084388732910156
Validation loss: 2.191557417633713

Epoch: 5| Step: 10
Training loss: 2.3559370040893555
Validation loss: 2.162983899475426

Epoch: 214| Step: 0
Training loss: 1.6897811889648438
Validation loss: 2.068035307750907

Epoch: 5| Step: 1
Training loss: 1.751381278038025
Validation loss: 2.259793912210772

Epoch: 5| Step: 2
Training loss: 2.11203670501709
Validation loss: 2.0301122101404334

Epoch: 5| Step: 3
Training loss: 2.1850922107696533
Validation loss: 2.083010773504934

Epoch: 5| Step: 4
Training loss: 1.9862505197525024
Validation loss: 2.1574597640704085

Epoch: 5| Step: 5
Training loss: 1.696298599243164
Validation loss: 2.024652406733523

Epoch: 5| Step: 6
Training loss: 2.2731692790985107
Validation loss: 2.148203226827806

Epoch: 5| Step: 7
Training loss: 2.0027880668640137
Validation loss: 2.1052391503446843

Epoch: 5| Step: 8
Training loss: 2.5545341968536377
Validation loss: 2.1302517896057456

Epoch: 5| Step: 9
Training loss: 2.3267602920532227
Validation loss: 2.131271703268892

Epoch: 5| Step: 10
Training loss: 2.0207881927490234
Validation loss: 2.108454768375684

Epoch: 215| Step: 0
Training loss: 2.3482820987701416
Validation loss: 2.073125349578037

Epoch: 5| Step: 1
Training loss: 2.7478113174438477
Validation loss: 2.1502594024904313

Epoch: 5| Step: 2
Training loss: 1.6818313598632812
Validation loss: 2.1573321152758855

Epoch: 5| Step: 3
Training loss: 2.248258590698242
Validation loss: 2.111127176592427

Epoch: 5| Step: 4
Training loss: 1.8408960103988647
Validation loss: 2.107785271060082

Epoch: 5| Step: 5
Training loss: 1.784507393836975
Validation loss: 2.145446474834155

Epoch: 5| Step: 6
Training loss: 2.0464606285095215
Validation loss: 2.1387098860997025

Epoch: 5| Step: 7
Training loss: 2.507706880569458
Validation loss: 2.1592266303236767

Epoch: 5| Step: 8
Training loss: 1.7207374572753906
Validation loss: 2.169522116261144

Epoch: 5| Step: 9
Training loss: 1.6745326519012451
Validation loss: 2.2016984647320164

Epoch: 5| Step: 10
Training loss: 2.35591197013855
Validation loss: 2.112058065270865

Epoch: 216| Step: 0
Training loss: 2.12532901763916
Validation loss: 2.1615184814699235

Epoch: 5| Step: 1
Training loss: 2.0899147987365723
Validation loss: 2.233224525246569

Epoch: 5| Step: 2
Training loss: 1.6136906147003174
Validation loss: 2.096078641953007

Epoch: 5| Step: 3
Training loss: 2.49918794631958
Validation loss: 2.0835741617346324

Epoch: 5| Step: 4
Training loss: 2.40494704246521
Validation loss: 2.2336480694432415

Epoch: 5| Step: 5
Training loss: 2.2334868907928467
Validation loss: 2.1971510071908273

Epoch: 5| Step: 6
Training loss: 1.8871543407440186
Validation loss: 2.225984696419008

Epoch: 5| Step: 7
Training loss: 2.2005271911621094
Validation loss: 2.1285231344161497

Epoch: 5| Step: 8
Training loss: 1.9350343942642212
Validation loss: 2.0561765265721146

Epoch: 5| Step: 9
Training loss: 1.971914291381836
Validation loss: 2.0936653998590287

Epoch: 5| Step: 10
Training loss: 2.0784010887145996
Validation loss: 2.1634137784281084

Epoch: 217| Step: 0
Training loss: 1.9910438060760498
Validation loss: 2.134525332399594

Epoch: 5| Step: 1
Training loss: 1.7290347814559937
Validation loss: 2.1295651005160425

Epoch: 5| Step: 2
Training loss: 2.6346592903137207
Validation loss: 2.0721242017643426

Epoch: 5| Step: 3
Training loss: 1.6017215251922607
Validation loss: 2.1481198649252615

Epoch: 5| Step: 4
Training loss: 2.7515082359313965
Validation loss: 2.0708159759480465

Epoch: 5| Step: 5
Training loss: 1.959794282913208
Validation loss: 2.2383414724821686

Epoch: 5| Step: 6
Training loss: 1.5936933755874634
Validation loss: 2.1005134685065157

Epoch: 5| Step: 7
Training loss: 1.6723238229751587
Validation loss: 2.1571773559816423

Epoch: 5| Step: 8
Training loss: 2.225562810897827
Validation loss: 2.0930998145893054

Epoch: 5| Step: 9
Training loss: 1.8062574863433838
Validation loss: 2.1220306965612594

Epoch: 5| Step: 10
Training loss: 2.209243059158325
Validation loss: 2.139468446854622

Epoch: 218| Step: 0
Training loss: 1.8939979076385498
Validation loss: 2.2001023061813845

Epoch: 5| Step: 1
Training loss: 2.3299288749694824
Validation loss: 2.1678032259787283

Epoch: 5| Step: 2
Training loss: 1.5775201320648193
Validation loss: 2.1952142689817693

Epoch: 5| Step: 3
Training loss: 1.952000617980957
Validation loss: 2.18118961908484

Epoch: 5| Step: 4
Training loss: 2.1673929691314697
Validation loss: 2.0807507063752864

Epoch: 5| Step: 5
Training loss: 2.495041847229004
Validation loss: 2.024594289000316

Epoch: 5| Step: 6
Training loss: 2.0011112689971924
Validation loss: 2.124872398632829

Epoch: 5| Step: 7
Training loss: 2.2036776542663574
Validation loss: 2.0810258593610538

Epoch: 5| Step: 8
Training loss: 1.8852460384368896
Validation loss: 2.2151841732763473

Epoch: 5| Step: 9
Training loss: 2.025454044342041
Validation loss: 2.153062148760724

Epoch: 5| Step: 10
Training loss: 1.7295868396759033
Validation loss: 2.096069630756173

Epoch: 219| Step: 0
Training loss: 1.7106075286865234
Validation loss: 2.223543454242009

Epoch: 5| Step: 1
Training loss: 2.006432056427002
Validation loss: 2.1443115690703034

Epoch: 5| Step: 2
Training loss: 2.3232181072235107
Validation loss: 2.190923934341759

Epoch: 5| Step: 3
Training loss: 2.0088064670562744
Validation loss: 2.1585100645660074

Epoch: 5| Step: 4
Training loss: 2.813070297241211
Validation loss: 2.1792061457069973

Epoch: 5| Step: 5
Training loss: 1.9877891540527344
Validation loss: 2.147693316141764

Epoch: 5| Step: 6
Training loss: 1.630515456199646
Validation loss: 2.1092303978499545

Epoch: 5| Step: 7
Training loss: 1.927772879600525
Validation loss: 2.1198638908324705

Epoch: 5| Step: 8
Training loss: 2.8537683486938477
Validation loss: 2.136660829667122

Epoch: 5| Step: 9
Training loss: 1.361886739730835
Validation loss: 2.0608487283029864

Epoch: 5| Step: 10
Training loss: 1.724953055381775
Validation loss: 2.162370269016553

Epoch: 220| Step: 0
Training loss: 1.6530389785766602
Validation loss: 2.1014668992770615

Epoch: 5| Step: 1
Training loss: 1.9759674072265625
Validation loss: 2.0977353203681206

Epoch: 5| Step: 2
Training loss: 2.68812894821167
Validation loss: 2.105063102578604

Epoch: 5| Step: 3
Training loss: 1.7781693935394287
Validation loss: 2.063450618456769

Epoch: 5| Step: 4
Training loss: 2.1665961742401123
Validation loss: 2.0462071011143346

Epoch: 5| Step: 5
Training loss: 2.247056245803833
Validation loss: 2.2007789150361092

Epoch: 5| Step: 6
Training loss: 2.001929521560669
Validation loss: 2.1079692456030075

Epoch: 5| Step: 7
Training loss: 2.2378368377685547
Validation loss: 2.19286117117892

Epoch: 5| Step: 8
Training loss: 2.3840932846069336
Validation loss: 2.1078006067583637

Epoch: 5| Step: 9
Training loss: 1.9603389501571655
Validation loss: 2.052595488486751

Epoch: 5| Step: 10
Training loss: 1.9790194034576416
Validation loss: 2.133155163898263

Epoch: 221| Step: 0
Training loss: 2.328829288482666
Validation loss: 2.083608942647134

Epoch: 5| Step: 1
Training loss: 1.8360122442245483
Validation loss: 2.1410802372040285

Epoch: 5| Step: 2
Training loss: 1.9635661840438843
Validation loss: 2.181150831202025

Epoch: 5| Step: 3
Training loss: 2.0854058265686035
Validation loss: 2.0552937984466553

Epoch: 5| Step: 4
Training loss: 2.292623996734619
Validation loss: 2.131863840164677

Epoch: 5| Step: 5
Training loss: 1.5642468929290771
Validation loss: 2.1351746474542925

Epoch: 5| Step: 6
Training loss: 2.0153956413269043
Validation loss: 2.1119816867254113

Epoch: 5| Step: 7
Training loss: 1.7687742710113525
Validation loss: 2.1844436609616844

Epoch: 5| Step: 8
Training loss: 1.883115530014038
Validation loss: 2.1122626925027497

Epoch: 5| Step: 9
Training loss: 2.0572099685668945
Validation loss: 2.110068163564128

Epoch: 5| Step: 10
Training loss: 2.414689064025879
Validation loss: 2.1085827581344114

Epoch: 222| Step: 0
Training loss: 2.5437002182006836
Validation loss: 2.244428062951693

Epoch: 5| Step: 1
Training loss: 1.6497236490249634
Validation loss: 2.1265425938431934

Epoch: 5| Step: 2
Training loss: 2.29215931892395
Validation loss: 2.1311964578525995

Epoch: 5| Step: 3
Training loss: 2.153244733810425
Validation loss: 2.115311244482635

Epoch: 5| Step: 4
Training loss: 2.0100936889648438
Validation loss: 2.1484256534166235

Epoch: 5| Step: 5
Training loss: 1.9124548435211182
Validation loss: 2.186938601155435

Epoch: 5| Step: 6
Training loss: 1.8856960535049438
Validation loss: 2.1207648220882622

Epoch: 5| Step: 7
Training loss: 2.2296676635742188
Validation loss: 2.07829729459619

Epoch: 5| Step: 8
Training loss: 2.199707269668579
Validation loss: 2.1580444228264595

Epoch: 5| Step: 9
Training loss: 2.492753505706787
Validation loss: 2.1830817602014028

Epoch: 5| Step: 10
Training loss: 1.6147106885910034
Validation loss: 2.224207492284877

Epoch: 223| Step: 0
Training loss: 1.8140558004379272
Validation loss: 2.08907130969468

Epoch: 5| Step: 1
Training loss: 2.1047675609588623
Validation loss: 2.012174424304757

Epoch: 5| Step: 2
Training loss: 1.399181604385376
Validation loss: 2.141041842840051

Epoch: 5| Step: 3
Training loss: 2.2328763008117676
Validation loss: 2.122984396514072

Epoch: 5| Step: 4
Training loss: 2.5742931365966797
Validation loss: 2.218862651496805

Epoch: 5| Step: 5
Training loss: 1.341036081314087
Validation loss: 2.1288429152581

Epoch: 5| Step: 6
Training loss: 1.634149193763733
Validation loss: 2.090317885080973

Epoch: 5| Step: 7
Training loss: 2.2582101821899414
Validation loss: 2.138853657630182

Epoch: 5| Step: 8
Training loss: 2.4039242267608643
Validation loss: 2.1284631682980444

Epoch: 5| Step: 9
Training loss: 2.5484232902526855
Validation loss: 2.083813545524433

Epoch: 5| Step: 10
Training loss: 2.2413976192474365
Validation loss: 2.233078936094879

Epoch: 224| Step: 0
Training loss: 2.2188634872436523
Validation loss: 2.0205333745607765

Epoch: 5| Step: 1
Training loss: 2.271519184112549
Validation loss: 2.1100694966572586

Epoch: 5| Step: 2
Training loss: 1.3580201864242554
Validation loss: 2.112559664633966

Epoch: 5| Step: 3
Training loss: 2.071446657180786
Validation loss: 2.1300607855601976

Epoch: 5| Step: 4
Training loss: 2.334789514541626
Validation loss: 2.187982100312428

Epoch: 5| Step: 5
Training loss: 2.0548224449157715
Validation loss: 2.20660747251203

Epoch: 5| Step: 6
Training loss: 2.1997148990631104
Validation loss: 2.102615971719065

Epoch: 5| Step: 7
Training loss: 2.3295090198516846
Validation loss: 2.075667364622957

Epoch: 5| Step: 8
Training loss: 1.8724168539047241
Validation loss: 2.105298290970505

Epoch: 5| Step: 9
Training loss: 2.00518798828125
Validation loss: 2.080272259250764

Epoch: 5| Step: 10
Training loss: 1.365161418914795
Validation loss: 2.156041355543239

Epoch: 225| Step: 0
Training loss: 2.2903618812561035
Validation loss: 2.0788995758179696

Epoch: 5| Step: 1
Training loss: 2.317918300628662
Validation loss: 2.2056982773606495

Epoch: 5| Step: 2
Training loss: 1.6606957912445068
Validation loss: 1.9823551895797893

Epoch: 5| Step: 3
Training loss: 1.9240972995758057
Validation loss: 2.1681957962692424

Epoch: 5| Step: 4
Training loss: 2.583630084991455
Validation loss: 2.165720772999589

Epoch: 5| Step: 5
Training loss: 2.1156044006347656
Validation loss: 2.132075373844434

Epoch: 5| Step: 6
Training loss: 1.9451723098754883
Validation loss: 2.158325687531502

Epoch: 5| Step: 7
Training loss: 1.9726121425628662
Validation loss: 2.08196924835123

Epoch: 5| Step: 8
Training loss: 2.0752196311950684
Validation loss: 2.101415514945984

Epoch: 5| Step: 9
Training loss: 1.5084095001220703
Validation loss: 2.121100725666169

Epoch: 5| Step: 10
Training loss: 2.0809166431427
Validation loss: 2.1328247131839877

Epoch: 226| Step: 0
Training loss: 2.379298210144043
Validation loss: 2.1862181361003588

Epoch: 5| Step: 1
Training loss: 1.605942726135254
Validation loss: 2.123826176889481

Epoch: 5| Step: 2
Training loss: 1.8725353479385376
Validation loss: 2.071080012988019

Epoch: 5| Step: 3
Training loss: 2.3237969875335693
Validation loss: 2.181805346601753

Epoch: 5| Step: 4
Training loss: 2.1401846408843994
Validation loss: 2.124912938764018

Epoch: 5| Step: 5
Training loss: 2.248303174972534
Validation loss: 2.184843486355197

Epoch: 5| Step: 6
Training loss: 2.068772315979004
Validation loss: 2.165334277255561

Epoch: 5| Step: 7
Training loss: 1.8739206790924072
Validation loss: 2.0980173362198697

Epoch: 5| Step: 8
Training loss: 1.673707365989685
Validation loss: 2.15549272875632

Epoch: 5| Step: 9
Training loss: 2.3129448890686035
Validation loss: 2.1843166505136797

Epoch: 5| Step: 10
Training loss: 1.8054616451263428
Validation loss: 2.1467267902948524

Epoch: 227| Step: 0
Training loss: 2.055506467819214
Validation loss: 2.103298297492407

Epoch: 5| Step: 1
Training loss: 2.2532196044921875
Validation loss: 2.1708630361864643

Epoch: 5| Step: 2
Training loss: 2.049690008163452
Validation loss: 2.0694213374968498

Epoch: 5| Step: 3
Training loss: 1.9138247966766357
Validation loss: 2.102633535221059

Epoch: 5| Step: 4
Training loss: 1.4521751403808594
Validation loss: 2.1476422766203522

Epoch: 5| Step: 5
Training loss: 1.9778101444244385
Validation loss: 2.182075067233014

Epoch: 5| Step: 6
Training loss: 2.2184810638427734
Validation loss: 2.092218236256671

Epoch: 5| Step: 7
Training loss: 2.433145046234131
Validation loss: 2.144134762466595

Epoch: 5| Step: 8
Training loss: 2.3998308181762695
Validation loss: 2.092522269936018

Epoch: 5| Step: 9
Training loss: 1.9378173351287842
Validation loss: 2.083482603872976

Epoch: 5| Step: 10
Training loss: 1.8988558053970337
Validation loss: 2.057813393172397

Epoch: 228| Step: 0
Training loss: 1.5136414766311646
Validation loss: 2.093176746881136

Epoch: 5| Step: 1
Training loss: 2.1135735511779785
Validation loss: 2.092773698991345

Epoch: 5| Step: 2
Training loss: 1.7491047382354736
Validation loss: 2.090357368992221

Epoch: 5| Step: 3
Training loss: 2.027763843536377
Validation loss: 2.251201283547186

Epoch: 5| Step: 4
Training loss: 1.9058204889297485
Validation loss: 2.1138979773367605

Epoch: 5| Step: 5
Training loss: 1.7391420602798462
Validation loss: 2.1290100877003004

Epoch: 5| Step: 6
Training loss: 2.629943370819092
Validation loss: 2.2207268232940347

Epoch: 5| Step: 7
Training loss: 2.5586771965026855
Validation loss: 2.1059449872662945

Epoch: 5| Step: 8
Training loss: 1.876085877418518
Validation loss: 2.0617816704575733

Epoch: 5| Step: 9
Training loss: 2.528010606765747
Validation loss: 2.184332514321932

Epoch: 5| Step: 10
Training loss: 1.862565279006958
Validation loss: 2.092733988197901

Epoch: 229| Step: 0
Training loss: 1.57145094871521
Validation loss: 2.149105461694861

Epoch: 5| Step: 1
Training loss: 2.467508316040039
Validation loss: 2.1619159175503637

Epoch: 5| Step: 2
Training loss: 1.6765187978744507
Validation loss: 2.1056828985932055

Epoch: 5| Step: 3
Training loss: 2.5201618671417236
Validation loss: 2.0359887102598786

Epoch: 5| Step: 4
Training loss: 2.1607186794281006
Validation loss: 2.2032330138708955

Epoch: 5| Step: 5
Training loss: 1.842911720275879
Validation loss: 2.0349671571485457

Epoch: 5| Step: 6
Training loss: 2.4409873485565186
Validation loss: 2.1943365079100414

Epoch: 5| Step: 7
Training loss: 1.3729544878005981
Validation loss: 2.139135237663023

Epoch: 5| Step: 8
Training loss: 1.887404203414917
Validation loss: 2.1746829453335015

Epoch: 5| Step: 9
Training loss: 2.5465385913848877
Validation loss: 2.1758983353132844

Epoch: 5| Step: 10
Training loss: 1.8617982864379883
Validation loss: 2.134155334964875

Epoch: 230| Step: 0
Training loss: 2.462958812713623
Validation loss: 2.116812693175449

Epoch: 5| Step: 1
Training loss: 1.9914602041244507
Validation loss: 2.1768566254646546

Epoch: 5| Step: 2
Training loss: 1.8904615640640259
Validation loss: 2.1084302535621067

Epoch: 5| Step: 3
Training loss: 1.933631181716919
Validation loss: 2.0985279788253126

Epoch: 5| Step: 4
Training loss: 2.7288403511047363
Validation loss: 2.051092468282228

Epoch: 5| Step: 5
Training loss: 2.3473353385925293
Validation loss: 2.0728785722486434

Epoch: 5| Step: 6
Training loss: 1.2099604606628418
Validation loss: 2.065958320453603

Epoch: 5| Step: 7
Training loss: 2.3270044326782227
Validation loss: 2.0722295391944145

Epoch: 5| Step: 8
Training loss: 1.6087744235992432
Validation loss: 2.2127718412747948

Epoch: 5| Step: 9
Training loss: 2.5774013996124268
Validation loss: 2.1977469664747997

Epoch: 5| Step: 10
Training loss: 1.8427884578704834
Validation loss: 2.0842832519162084

Epoch: 231| Step: 0
Training loss: 1.497357726097107
Validation loss: 2.0219808624636744

Epoch: 5| Step: 1
Training loss: 1.9001260995864868
Validation loss: 2.0100919943983837

Epoch: 5| Step: 2
Training loss: 2.066995620727539
Validation loss: 2.1123920153546076

Epoch: 5| Step: 3
Training loss: 2.088439702987671
Validation loss: 2.1302390649754512

Epoch: 5| Step: 4
Training loss: 2.16538667678833
Validation loss: 2.077584425608317

Epoch: 5| Step: 5
Training loss: 2.03969407081604
Validation loss: 2.0986789682860016

Epoch: 5| Step: 6
Training loss: 2.216118335723877
Validation loss: 2.071553417431411

Epoch: 5| Step: 7
Training loss: 2.459564447402954
Validation loss: 2.1381887466676774

Epoch: 5| Step: 8
Training loss: 1.6276166439056396
Validation loss: 2.2280062706239763

Epoch: 5| Step: 9
Training loss: 1.6228729486465454
Validation loss: 2.102926725982338

Epoch: 5| Step: 10
Training loss: 1.8978567123413086
Validation loss: 2.1159562474937847

Epoch: 232| Step: 0
Training loss: 1.8685486316680908
Validation loss: 2.1084731906972904

Epoch: 5| Step: 1
Training loss: 2.7481939792633057
Validation loss: 2.0564391741188626

Epoch: 5| Step: 2
Training loss: 1.721319556236267
Validation loss: 2.0081050190874326

Epoch: 5| Step: 3
Training loss: 1.842626929283142
Validation loss: 2.0903041644762923

Epoch: 5| Step: 4
Training loss: 1.7678921222686768
Validation loss: 2.068499861225005

Epoch: 5| Step: 5
Training loss: 2.5146148204803467
Validation loss: 1.9485832234864593

Epoch: 5| Step: 6
Training loss: 2.1246814727783203
Validation loss: 2.052023959416215

Epoch: 5| Step: 7
Training loss: 2.3136324882507324
Validation loss: 2.1508448534114386

Epoch: 5| Step: 8
Training loss: 2.0203487873077393
Validation loss: 2.057279391955304

Epoch: 5| Step: 9
Training loss: 2.1247570514678955
Validation loss: 2.1912147229717625

Epoch: 5| Step: 10
Training loss: 1.4348400831222534
Validation loss: 2.1308687040882726

Epoch: 233| Step: 0
Training loss: 1.7200229167938232
Validation loss: 2.0892850519508444

Epoch: 5| Step: 1
Training loss: 2.431063175201416
Validation loss: 2.140370879122006

Epoch: 5| Step: 2
Training loss: 1.9929726123809814
Validation loss: 2.1744164036166285

Epoch: 5| Step: 3
Training loss: 1.9516092538833618
Validation loss: 2.1095796733774166

Epoch: 5| Step: 4
Training loss: 2.615692138671875
Validation loss: 2.1040234053006737

Epoch: 5| Step: 5
Training loss: 1.4564217329025269
Validation loss: 2.109729941173266

Epoch: 5| Step: 6
Training loss: 2.3914434909820557
Validation loss: 2.0762287621857016

Epoch: 5| Step: 7
Training loss: 2.5887203216552734
Validation loss: 2.162709746309506

Epoch: 5| Step: 8
Training loss: 1.6597929000854492
Validation loss: 2.1957659682919903

Epoch: 5| Step: 9
Training loss: 1.7723299264907837
Validation loss: 2.0930989224423646

Epoch: 5| Step: 10
Training loss: 2.0281059741973877
Validation loss: 2.103997985521952

Epoch: 234| Step: 0
Training loss: 1.8116035461425781
Validation loss: 2.210428471206337

Epoch: 5| Step: 1
Training loss: 1.3739744424819946
Validation loss: 2.134358822658498

Epoch: 5| Step: 2
Training loss: 2.462712287902832
Validation loss: 2.221342496974494

Epoch: 5| Step: 3
Training loss: 1.9699596166610718
Validation loss: 2.179954913354689

Epoch: 5| Step: 4
Training loss: 2.3031539916992188
Validation loss: 2.1758402342437417

Epoch: 5| Step: 5
Training loss: 2.130147933959961
Validation loss: 2.145992761017174

Epoch: 5| Step: 6
Training loss: 2.453207492828369
Validation loss: 2.061288636217835

Epoch: 5| Step: 7
Training loss: 2.3225228786468506
Validation loss: 2.0505263574661745

Epoch: 5| Step: 8
Training loss: 1.6150833368301392
Validation loss: 2.0793623565345682

Epoch: 5| Step: 9
Training loss: 2.2186856269836426
Validation loss: 2.182452401807231

Epoch: 5| Step: 10
Training loss: 2.1197292804718018
Validation loss: 2.1580649921970982

Epoch: 235| Step: 0
Training loss: 1.997962236404419
Validation loss: 2.1014828746036818

Epoch: 5| Step: 1
Training loss: 2.2879958152770996
Validation loss: 2.1412846298627954

Epoch: 5| Step: 2
Training loss: 2.021090507507324
Validation loss: 2.058390550715949

Epoch: 5| Step: 3
Training loss: 1.8505042791366577
Validation loss: 2.073624462209722

Epoch: 5| Step: 4
Training loss: 2.004467487335205
Validation loss: 2.1506951816620363

Epoch: 5| Step: 5
Training loss: 1.7345168590545654
Validation loss: 2.0483999970138713

Epoch: 5| Step: 6
Training loss: 2.1051993370056152
Validation loss: 2.0541890180239113

Epoch: 5| Step: 7
Training loss: 2.238499164581299
Validation loss: 2.0213585515176096

Epoch: 5| Step: 8
Training loss: 2.253690719604492
Validation loss: 2.12591649639991

Epoch: 5| Step: 9
Training loss: 2.1327309608459473
Validation loss: 2.1065695311433528

Epoch: 5| Step: 10
Training loss: 1.9798431396484375
Validation loss: 2.1163061793132494

Epoch: 236| Step: 0
Training loss: 1.8503007888793945
Validation loss: 2.1389521386033747

Epoch: 5| Step: 1
Training loss: 2.0642881393432617
Validation loss: 2.166124273371953

Epoch: 5| Step: 2
Training loss: 3.170607089996338
Validation loss: 2.1064549953706804

Epoch: 5| Step: 3
Training loss: 1.3006364107131958
Validation loss: 2.188471983837825

Epoch: 5| Step: 4
Training loss: 1.3600349426269531
Validation loss: 2.1495224160532795

Epoch: 5| Step: 5
Training loss: 2.8638336658477783
Validation loss: 2.0998554704009846

Epoch: 5| Step: 6
Training loss: 1.3923914432525635
Validation loss: 2.1258499494162937

Epoch: 5| Step: 7
Training loss: 2.572237491607666
Validation loss: 2.1849242820534656

Epoch: 5| Step: 8
Training loss: 1.5670109987258911
Validation loss: 2.1243031717115834

Epoch: 5| Step: 9
Training loss: 2.406350612640381
Validation loss: 2.127203392726119

Epoch: 5| Step: 10
Training loss: 1.7219951152801514
Validation loss: 2.045398400675866

Epoch: 237| Step: 0
Training loss: 2.2981343269348145
Validation loss: 2.1941229553632837

Epoch: 5| Step: 1
Training loss: 2.330562114715576
Validation loss: 2.1357963777357534

Epoch: 5| Step: 2
Training loss: 1.696939468383789
Validation loss: 2.1066452303240375

Epoch: 5| Step: 3
Training loss: 1.918378472328186
Validation loss: 2.1458443313516598

Epoch: 5| Step: 4
Training loss: 2.1505560874938965
Validation loss: 2.1328601657703357

Epoch: 5| Step: 5
Training loss: 1.2453327178955078
Validation loss: 2.1523732908310427

Epoch: 5| Step: 6
Training loss: 1.7659533023834229
Validation loss: 2.094875048565608

Epoch: 5| Step: 7
Training loss: 1.8072316646575928
Validation loss: 2.21115174857519

Epoch: 5| Step: 8
Training loss: 2.026446580886841
Validation loss: 2.126585850151636

Epoch: 5| Step: 9
Training loss: 1.994118332862854
Validation loss: 2.158072607491606

Epoch: 5| Step: 10
Training loss: 2.9200198650360107
Validation loss: 2.1210627863484044

Epoch: 238| Step: 0
Training loss: 2.149178981781006
Validation loss: 2.135306822356357

Epoch: 5| Step: 1
Training loss: 2.0527424812316895
Validation loss: 2.219010603043341

Epoch: 5| Step: 2
Training loss: 1.947156548500061
Validation loss: 2.1270818838509182

Epoch: 5| Step: 3
Training loss: 1.6503610610961914
Validation loss: 2.1228974275691535

Epoch: 5| Step: 4
Training loss: 1.9212589263916016
Validation loss: 2.1648698211998068

Epoch: 5| Step: 5
Training loss: 2.219804525375366
Validation loss: 2.0638158552108274

Epoch: 5| Step: 6
Training loss: 2.0579400062561035
Validation loss: 2.1959577927025418

Epoch: 5| Step: 7
Training loss: 1.8104305267333984
Validation loss: 2.195354271960515

Epoch: 5| Step: 8
Training loss: 1.889923095703125
Validation loss: 2.0983513478309876

Epoch: 5| Step: 9
Training loss: 2.8397696018218994
Validation loss: 2.1398374803604616

Epoch: 5| Step: 10
Training loss: 2.230646848678589
Validation loss: 2.112353091598839

Epoch: 239| Step: 0
Training loss: 2.3360085487365723
Validation loss: 2.205790550478043

Epoch: 5| Step: 1
Training loss: 2.818984270095825
Validation loss: 2.1355047354134182

Epoch: 5| Step: 2
Training loss: 2.539630889892578
Validation loss: 2.0895980788815405

Epoch: 5| Step: 3
Training loss: 2.235063314437866
Validation loss: 2.0150019712345575

Epoch: 5| Step: 4
Training loss: 1.7720838785171509
Validation loss: 2.1783445547985774

Epoch: 5| Step: 5
Training loss: 1.8353166580200195
Validation loss: 2.119109087092902

Epoch: 5| Step: 6
Training loss: 2.1753792762756348
Validation loss: 2.0777627127144926

Epoch: 5| Step: 7
Training loss: 1.497198462486267
Validation loss: 2.1946913785831903

Epoch: 5| Step: 8
Training loss: 2.057724714279175
Validation loss: 2.1334656182155816

Epoch: 5| Step: 9
Training loss: 1.4127118587493896
Validation loss: 2.1116760597434094

Epoch: 5| Step: 10
Training loss: 2.191178321838379
Validation loss: 2.1572689215342202

Epoch: 240| Step: 0
Training loss: 2.4004595279693604
Validation loss: 2.1690027303593133

Epoch: 5| Step: 1
Training loss: 1.2959988117218018
Validation loss: 2.1105151355907483

Epoch: 5| Step: 2
Training loss: 1.9133743047714233
Validation loss: 2.104316294834178

Epoch: 5| Step: 3
Training loss: 1.4127976894378662
Validation loss: 2.149652824606947

Epoch: 5| Step: 4
Training loss: 1.7346378564834595
Validation loss: 2.258188091298585

Epoch: 5| Step: 5
Training loss: 2.608705520629883
Validation loss: 2.1185521438557613

Epoch: 5| Step: 6
Training loss: 2.6654093265533447
Validation loss: 2.081460770740304

Epoch: 5| Step: 7
Training loss: 1.9219729900360107
Validation loss: 2.108662159212174

Epoch: 5| Step: 8
Training loss: 1.8762657642364502
Validation loss: 2.135361047201259

Epoch: 5| Step: 9
Training loss: 2.844268560409546
Validation loss: 2.1015240248813423

Epoch: 5| Step: 10
Training loss: 1.751694679260254
Validation loss: 2.0475278721060803

Epoch: 241| Step: 0
Training loss: 2.1588878631591797
Validation loss: 2.1226081463598434

Epoch: 5| Step: 1
Training loss: 1.735256552696228
Validation loss: 2.0719919691803637

Epoch: 5| Step: 2
Training loss: 1.98770010471344
Validation loss: 2.0828193849132908

Epoch: 5| Step: 3
Training loss: 1.6077148914337158
Validation loss: 2.0807046762076755

Epoch: 5| Step: 4
Training loss: 2.2602639198303223
Validation loss: 2.0760436545136156

Epoch: 5| Step: 5
Training loss: 2.455862045288086
Validation loss: 2.070397662860091

Epoch: 5| Step: 6
Training loss: 2.113557815551758
Validation loss: 2.122626999373077

Epoch: 5| Step: 7
Training loss: 2.238999128341675
Validation loss: 2.157585584989158

Epoch: 5| Step: 8
Training loss: 1.765398383140564
Validation loss: 2.1295618626379196

Epoch: 5| Step: 9
Training loss: 2.221869945526123
Validation loss: 2.1565749004322994

Epoch: 5| Step: 10
Training loss: 1.9115244150161743
Validation loss: 2.0654954730823474

Epoch: 242| Step: 0
Training loss: 1.7874313592910767
Validation loss: 2.192974844286519

Epoch: 5| Step: 1
Training loss: 2.3053946495056152
Validation loss: 2.1438588839705273

Epoch: 5| Step: 2
Training loss: 1.9076646566390991
Validation loss: 2.0415748473136657

Epoch: 5| Step: 3
Training loss: 1.8257949352264404
Validation loss: 2.173047088807629

Epoch: 5| Step: 4
Training loss: 2.019683599472046
Validation loss: 2.0755807404877036

Epoch: 5| Step: 5
Training loss: 1.8097426891326904
Validation loss: 2.094770005954209

Epoch: 5| Step: 6
Training loss: 2.1718850135803223
Validation loss: 2.107471796774095

Epoch: 5| Step: 7
Training loss: 1.7168128490447998
Validation loss: 2.1021190766365296

Epoch: 5| Step: 8
Training loss: 2.0106911659240723
Validation loss: 2.049026394403109

Epoch: 5| Step: 9
Training loss: 2.172764301300049
Validation loss: 2.224446024945987

Epoch: 5| Step: 10
Training loss: 2.73591685295105
Validation loss: 2.177568135722991

Epoch: 243| Step: 0
Training loss: 2.044273853302002
Validation loss: 2.114571758495864

Epoch: 5| Step: 1
Training loss: 2.794445514678955
Validation loss: 2.1658223854598178

Epoch: 5| Step: 2
Training loss: 2.1001758575439453
Validation loss: 2.1155956150383077

Epoch: 5| Step: 3
Training loss: 1.7221736907958984
Validation loss: 2.1113693342413953

Epoch: 5| Step: 4
Training loss: 2.7689261436462402
Validation loss: 2.153432728141867

Epoch: 5| Step: 5
Training loss: 2.205148696899414
Validation loss: 2.123946351389731

Epoch: 5| Step: 6
Training loss: 2.179994583129883
Validation loss: 2.1002342982958724

Epoch: 5| Step: 7
Training loss: 1.8527469635009766
Validation loss: 2.0891252025481193

Epoch: 5| Step: 8
Training loss: 1.9605038166046143
Validation loss: 2.031450189569945

Epoch: 5| Step: 9
Training loss: 1.4658924341201782
Validation loss: 2.112811562835529

Epoch: 5| Step: 10
Training loss: 1.9292083978652954
Validation loss: 2.0944437057741228

Epoch: 244| Step: 0
Training loss: 1.4818437099456787
Validation loss: 2.106502934168744

Epoch: 5| Step: 1
Training loss: 1.8952128887176514
Validation loss: 2.162520129193542

Epoch: 5| Step: 2
Training loss: 2.2935824394226074
Validation loss: 2.1556823535632064

Epoch: 5| Step: 3
Training loss: 1.9150316715240479
Validation loss: 2.154499548737721

Epoch: 5| Step: 4
Training loss: 2.0462875366210938
Validation loss: 2.0770973159420874

Epoch: 5| Step: 5
Training loss: 1.8587658405303955
Validation loss: 2.0898574962410876

Epoch: 5| Step: 6
Training loss: 2.4319310188293457
Validation loss: 2.0926629035703597

Epoch: 5| Step: 7
Training loss: 2.309014320373535
Validation loss: 2.178435879368936

Epoch: 5| Step: 8
Training loss: 2.148421287536621
Validation loss: 2.1211042814357306

Epoch: 5| Step: 9
Training loss: 2.6052114963531494
Validation loss: 2.1667523166184783

Epoch: 5| Step: 10
Training loss: 1.4588724374771118
Validation loss: 2.1136275632407076

Epoch: 245| Step: 0
Training loss: 1.467879295349121
Validation loss: 2.0914321458467873

Epoch: 5| Step: 1
Training loss: 2.2934250831604004
Validation loss: 2.1321816495669785

Epoch: 5| Step: 2
Training loss: 2.732468843460083
Validation loss: 2.089559298689647

Epoch: 5| Step: 3
Training loss: 1.7364833354949951
Validation loss: 2.1044298923143776

Epoch: 5| Step: 4
Training loss: 1.9199683666229248
Validation loss: 2.170292031380438

Epoch: 5| Step: 5
Training loss: 1.9001390933990479
Validation loss: 2.203482876541794

Epoch: 5| Step: 6
Training loss: 2.097644090652466
Validation loss: 2.170191216212447

Epoch: 5| Step: 7
Training loss: 1.361814022064209
Validation loss: 2.1282942948802823

Epoch: 5| Step: 8
Training loss: 2.4701931476593018
Validation loss: 2.080536816709785

Epoch: 5| Step: 9
Training loss: 2.5590996742248535
Validation loss: 2.0911765483117875

Epoch: 5| Step: 10
Training loss: 1.9719444513320923
Validation loss: 2.1311786572138467

Epoch: 246| Step: 0
Training loss: 1.9319610595703125
Validation loss: 2.045866531710471

Epoch: 5| Step: 1
Training loss: 1.6216211318969727
Validation loss: 2.100680628130513

Epoch: 5| Step: 2
Training loss: 2.2518677711486816
Validation loss: 2.1459436249989334

Epoch: 5| Step: 3
Training loss: 1.848499059677124
Validation loss: 2.1685504810784453

Epoch: 5| Step: 4
Training loss: 2.22409987449646
Validation loss: 2.2015517424511653

Epoch: 5| Step: 5
Training loss: 1.8450084924697876
Validation loss: 2.1307675966652493

Epoch: 5| Step: 6
Training loss: 2.317984104156494
Validation loss: 2.202243415258264

Epoch: 5| Step: 7
Training loss: 1.7402160167694092
Validation loss: 2.0453674485606532

Epoch: 5| Step: 8
Training loss: 1.91933274269104
Validation loss: 2.07753554467232

Epoch: 5| Step: 9
Training loss: 2.2368292808532715
Validation loss: 2.1234150612226097

Epoch: 5| Step: 10
Training loss: 2.1611692905426025
Validation loss: 2.0883661085559475

Epoch: 247| Step: 0
Training loss: 1.4659974575042725
Validation loss: 2.1437283779985163

Epoch: 5| Step: 1
Training loss: 1.5123703479766846
Validation loss: 2.032134671365061

Epoch: 5| Step: 2
Training loss: 2.026108741760254
Validation loss: 2.166525980477692

Epoch: 5| Step: 3
Training loss: 2.377042770385742
Validation loss: 2.137449545245017

Epoch: 5| Step: 4
Training loss: 1.1572887897491455
Validation loss: 2.0538106246661116

Epoch: 5| Step: 5
Training loss: 2.3409957885742188
Validation loss: 2.1681546600916053

Epoch: 5| Step: 6
Training loss: 2.421327590942383
Validation loss: 2.176612933476766

Epoch: 5| Step: 7
Training loss: 1.7119970321655273
Validation loss: 2.1331275060612667

Epoch: 5| Step: 8
Training loss: 2.1520209312438965
Validation loss: 2.210558719532464

Epoch: 5| Step: 9
Training loss: 1.8572406768798828
Validation loss: 2.0246893000859085

Epoch: 5| Step: 10
Training loss: 2.454847574234009
Validation loss: 2.224713624164622

Epoch: 248| Step: 0
Training loss: 2.1643614768981934
Validation loss: 2.2293804691683863

Epoch: 5| Step: 1
Training loss: 2.5318453311920166
Validation loss: 2.145903989832888

Epoch: 5| Step: 2
Training loss: 1.638942003250122
Validation loss: 2.2385014052032144

Epoch: 5| Step: 3
Training loss: 2.0096638202667236
Validation loss: 2.084710631319272

Epoch: 5| Step: 4
Training loss: 1.3429571390151978
Validation loss: 2.1468938281459193

Epoch: 5| Step: 5
Training loss: 2.118314027786255
Validation loss: 2.174391536302464

Epoch: 5| Step: 6
Training loss: 1.3112258911132812
Validation loss: 2.0955191094388246

Epoch: 5| Step: 7
Training loss: 2.4317612648010254
Validation loss: 2.1146175912631455

Epoch: 5| Step: 8
Training loss: 2.4953300952911377
Validation loss: 2.154286338436988

Epoch: 5| Step: 9
Training loss: 1.9418060779571533
Validation loss: 2.194703689185522

Epoch: 5| Step: 10
Training loss: 2.346269130706787
Validation loss: 2.1609193407079226

Epoch: 249| Step: 0
Training loss: 2.237139940261841
Validation loss: 2.171543913502847

Epoch: 5| Step: 1
Training loss: 2.053462266921997
Validation loss: 2.087129166049342

Epoch: 5| Step: 2
Training loss: 2.914217472076416
Validation loss: 2.1930569115505425

Epoch: 5| Step: 3
Training loss: 1.191589117050171
Validation loss: 2.1846740143273466

Epoch: 5| Step: 4
Training loss: 1.902650237083435
Validation loss: 2.1583063140992196

Epoch: 5| Step: 5
Training loss: 2.0637717247009277
Validation loss: 2.1812457423056326

Epoch: 5| Step: 6
Training loss: 1.7360283136367798
Validation loss: 2.0862437909649265

Epoch: 5| Step: 7
Training loss: 1.4672471284866333
Validation loss: 2.097838335139777

Epoch: 5| Step: 8
Training loss: 2.2481586933135986
Validation loss: 2.1441205419519895

Epoch: 5| Step: 9
Training loss: 1.8846489191055298
Validation loss: 2.0240559334396035

Epoch: 5| Step: 10
Training loss: 2.0909836292266846
Validation loss: 2.088885598285224

Epoch: 250| Step: 0
Training loss: 2.1193931102752686
Validation loss: 2.0098097196189304

Epoch: 5| Step: 1
Training loss: 2.708392381668091
Validation loss: 2.032343811886285

Epoch: 5| Step: 2
Training loss: 1.9833202362060547
Validation loss: 2.1580291768556

Epoch: 5| Step: 3
Training loss: 2.0163629055023193
Validation loss: 2.036203557445157

Epoch: 5| Step: 4
Training loss: 1.5800304412841797
Validation loss: 2.1412991887779644

Epoch: 5| Step: 5
Training loss: 1.9288556575775146
Validation loss: 2.0937032007401988

Epoch: 5| Step: 6
Training loss: 2.0405845642089844
Validation loss: 2.1509411065809187

Epoch: 5| Step: 7
Training loss: 1.5528388023376465
Validation loss: 2.174829098486131

Epoch: 5| Step: 8
Training loss: 2.2240889072418213
Validation loss: 2.190535331285128

Epoch: 5| Step: 9
Training loss: 1.8987528085708618
Validation loss: 2.131995811257311

Epoch: 5| Step: 10
Training loss: 2.296924352645874
Validation loss: 2.1950544772609586

Epoch: 251| Step: 0
Training loss: 1.2746978998184204
Validation loss: 2.179469249581778

Epoch: 5| Step: 1
Training loss: 1.6713768243789673
Validation loss: 2.0242425485323836

Epoch: 5| Step: 2
Training loss: 2.3784825801849365
Validation loss: 2.1145892809796076

Epoch: 5| Step: 3
Training loss: 2.7411468029022217
Validation loss: 2.2298081280082784

Epoch: 5| Step: 4
Training loss: 1.6118625402450562
Validation loss: 2.1810880681519866

Epoch: 5| Step: 5
Training loss: 2.148247718811035
Validation loss: 2.1005177767046037

Epoch: 5| Step: 6
Training loss: 3.0549468994140625
Validation loss: 2.121481398100494

Epoch: 5| Step: 7
Training loss: 1.5072664022445679
Validation loss: 2.1749781895709295

Epoch: 5| Step: 8
Training loss: 1.9427640438079834
Validation loss: 2.149182096604378

Epoch: 5| Step: 9
Training loss: 1.9565178155899048
Validation loss: 2.0388587367150093

Epoch: 5| Step: 10
Training loss: 1.8669707775115967
Validation loss: 2.225949587360505

Epoch: 252| Step: 0
Training loss: 1.8731677532196045
Validation loss: 2.077660729808192

Epoch: 5| Step: 1
Training loss: 2.3686108589172363
Validation loss: 2.0797309247396325

Epoch: 5| Step: 2
Training loss: 2.0434088706970215
Validation loss: 2.062465367778655

Epoch: 5| Step: 3
Training loss: 1.8576217889785767
Validation loss: 2.1447178317654516

Epoch: 5| Step: 4
Training loss: 2.4786839485168457
Validation loss: 2.06594156706205

Epoch: 5| Step: 5
Training loss: 1.9388244152069092
Validation loss: 2.085159073593796

Epoch: 5| Step: 6
Training loss: 2.3185343742370605
Validation loss: 2.1345588878918718

Epoch: 5| Step: 7
Training loss: 2.8445849418640137
Validation loss: 2.1288635025742235

Epoch: 5| Step: 8
Training loss: 1.6577507257461548
Validation loss: 2.039162572994027

Epoch: 5| Step: 9
Training loss: 1.5519754886627197
Validation loss: 2.126188960126651

Epoch: 5| Step: 10
Training loss: 1.6637024879455566
Validation loss: 2.1286650319253244

Epoch: 253| Step: 0
Training loss: 1.8931686878204346
Validation loss: 2.1298845057846396

Epoch: 5| Step: 1
Training loss: 1.8408771753311157
Validation loss: 2.098358587552142

Epoch: 5| Step: 2
Training loss: 2.033564329147339
Validation loss: 2.1004268046348327

Epoch: 5| Step: 3
Training loss: 2.017948627471924
Validation loss: 2.144972055189071

Epoch: 5| Step: 4
Training loss: 2.3354992866516113
Validation loss: 2.074332965317593

Epoch: 5| Step: 5
Training loss: 2.0129382610321045
Validation loss: 2.17357172120002

Epoch: 5| Step: 6
Training loss: 1.9395568370819092
Validation loss: 2.032774240739884

Epoch: 5| Step: 7
Training loss: 2.653944492340088
Validation loss: 2.0916239125754243

Epoch: 5| Step: 8
Training loss: 1.9916633367538452
Validation loss: 2.0458583408786404

Epoch: 5| Step: 9
Training loss: 1.9155811071395874
Validation loss: 2.1945102227631437

Epoch: 5| Step: 10
Training loss: 1.8642692565917969
Validation loss: 2.1379502870703257

Epoch: 254| Step: 0
Training loss: 1.604455590248108
Validation loss: 2.04627808191443

Epoch: 5| Step: 1
Training loss: 1.947934865951538
Validation loss: 2.1457119141855547

Epoch: 5| Step: 2
Training loss: 1.3149563074111938
Validation loss: 2.158477283293201

Epoch: 5| Step: 3
Training loss: 1.7237894535064697
Validation loss: 2.0258119901021323

Epoch: 5| Step: 4
Training loss: 1.640581727027893
Validation loss: 2.155111975567315

Epoch: 5| Step: 5
Training loss: 2.288790225982666
Validation loss: 2.1145285714057183

Epoch: 5| Step: 6
Training loss: 2.0271193981170654
Validation loss: 2.1726289538926977

Epoch: 5| Step: 7
Training loss: 1.7007873058319092
Validation loss: 2.1333091848640033

Epoch: 5| Step: 8
Training loss: 2.4909136295318604
Validation loss: 2.1266525381354877

Epoch: 5| Step: 9
Training loss: 2.5338361263275146
Validation loss: 2.0289308922265166

Epoch: 5| Step: 10
Training loss: 2.424429416656494
Validation loss: 2.135000228881836

Epoch: 255| Step: 0
Training loss: 1.969604253768921
Validation loss: 2.189442712773559

Epoch: 5| Step: 1
Training loss: 1.7727878093719482
Validation loss: 2.1512549000401653

Epoch: 5| Step: 2
Training loss: 1.3744533061981201
Validation loss: 2.0777317477810766

Epoch: 5| Step: 3
Training loss: 1.5049299001693726
Validation loss: 2.1809312399997505

Epoch: 5| Step: 4
Training loss: 2.0683693885803223
Validation loss: 2.144071590515875

Epoch: 5| Step: 5
Training loss: 2.3324344158172607
Validation loss: 1.9003836518974715

Epoch: 5| Step: 6
Training loss: 2.3191075325012207
Validation loss: 2.117728805029264

Epoch: 5| Step: 7
Training loss: 2.3923165798187256
Validation loss: 2.1056762600457795

Epoch: 5| Step: 8
Training loss: 2.560472011566162
Validation loss: 2.1759513039742746

Epoch: 5| Step: 9
Training loss: 1.7610830068588257
Validation loss: 2.140002171198527

Epoch: 5| Step: 10
Training loss: 2.160980701446533
Validation loss: 2.1300967226746264

Epoch: 256| Step: 0
Training loss: 2.638988733291626
Validation loss: 2.1867512374795894

Epoch: 5| Step: 1
Training loss: 1.1485704183578491
Validation loss: 2.1034087365673435

Epoch: 5| Step: 2
Training loss: 1.8266757726669312
Validation loss: 2.2178597604074786

Epoch: 5| Step: 3
Training loss: 1.678330421447754
Validation loss: 2.167135118156351

Epoch: 5| Step: 4
Training loss: 2.519838809967041
Validation loss: 2.171470038352474

Epoch: 5| Step: 5
Training loss: 1.7458164691925049
Validation loss: 2.117429771730977

Epoch: 5| Step: 6
Training loss: 2.503188133239746
Validation loss: 2.135130554117182

Epoch: 5| Step: 7
Training loss: 1.9550374746322632
Validation loss: 2.300549663523192

Epoch: 5| Step: 8
Training loss: 1.9168027639389038
Validation loss: 2.10743647749706

Epoch: 5| Step: 9
Training loss: 1.8421971797943115
Validation loss: 2.0880663753837667

Epoch: 5| Step: 10
Training loss: 2.1009230613708496
Validation loss: 2.1467041738571657

Epoch: 257| Step: 0
Training loss: 2.128084421157837
Validation loss: 2.145557358700742

Epoch: 5| Step: 1
Training loss: 2.123447895050049
Validation loss: 2.178459405899048

Epoch: 5| Step: 2
Training loss: 1.9831435680389404
Validation loss: 2.092417747743668

Epoch: 5| Step: 3
Training loss: 2.4003446102142334
Validation loss: 2.1240846649292977

Epoch: 5| Step: 4
Training loss: 1.9471607208251953
Validation loss: 2.070045466064125

Epoch: 5| Step: 5
Training loss: 1.9088590145111084
Validation loss: 2.1848693970711

Epoch: 5| Step: 6
Training loss: 1.4522267580032349
Validation loss: 2.1627112332210747

Epoch: 5| Step: 7
Training loss: 2.029905319213867
Validation loss: 2.159364918226837

Epoch: 5| Step: 8
Training loss: 2.2519900798797607
Validation loss: 2.059815281180925

Epoch: 5| Step: 9
Training loss: 2.232928514480591
Validation loss: 2.099497172140306

Epoch: 5| Step: 10
Training loss: 1.8965880870819092
Validation loss: 2.0860467431365803

Epoch: 258| Step: 0
Training loss: 2.5833683013916016
Validation loss: 2.0789883893023253

Epoch: 5| Step: 1
Training loss: 2.2252445220947266
Validation loss: 1.9818379161178425

Epoch: 5| Step: 2
Training loss: 1.977407693862915
Validation loss: 2.1678141445241947

Epoch: 5| Step: 3
Training loss: 2.1704905033111572
Validation loss: 2.0801779903391355

Epoch: 5| Step: 4
Training loss: 2.4435181617736816
Validation loss: 2.1062332763466785

Epoch: 5| Step: 5
Training loss: 1.5527002811431885
Validation loss: 2.0368938779318206

Epoch: 5| Step: 6
Training loss: 2.003448486328125
Validation loss: 2.154167362438735

Epoch: 5| Step: 7
Training loss: 2.1070713996887207
Validation loss: 2.1612833648599605

Epoch: 5| Step: 8
Training loss: 2.4542291164398193
Validation loss: 2.0976570678013626

Epoch: 5| Step: 9
Training loss: 1.8760464191436768
Validation loss: 2.1929575140758226

Epoch: 5| Step: 10
Training loss: 1.7307922840118408
Validation loss: 2.0459457725606938

Epoch: 259| Step: 0
Training loss: 2.444885730743408
Validation loss: 2.076511013892389

Epoch: 5| Step: 1
Training loss: 2.1229095458984375
Validation loss: 2.072698088102443

Epoch: 5| Step: 2
Training loss: 1.9981800317764282
Validation loss: 2.2004073409624

Epoch: 5| Step: 3
Training loss: 1.773572564125061
Validation loss: 2.121539359451622

Epoch: 5| Step: 4
Training loss: 1.890554428100586
Validation loss: 2.080235840171896

Epoch: 5| Step: 5
Training loss: 2.1803581714630127
Validation loss: 2.137897760637345

Epoch: 5| Step: 6
Training loss: 2.116645336151123
Validation loss: 2.0636598602417977

Epoch: 5| Step: 7
Training loss: 1.9009954929351807
Validation loss: 2.1201193050671647

Epoch: 5| Step: 8
Training loss: 1.8911561965942383
Validation loss: 2.095750601060929

Epoch: 5| Step: 9
Training loss: 1.7689216136932373
Validation loss: 2.0311411708913822

Epoch: 5| Step: 10
Training loss: 1.8361740112304688
Validation loss: 2.083961538089219

Epoch: 260| Step: 0
Training loss: 1.4504755735397339
Validation loss: 2.1004612509922316

Epoch: 5| Step: 1
Training loss: 2.4947004318237305
Validation loss: 2.0390686168465564

Epoch: 5| Step: 2
Training loss: 2.0917530059814453
Validation loss: 2.029247764618166

Epoch: 5| Step: 3
Training loss: 1.9177711009979248
Validation loss: 2.0887207087650093

Epoch: 5| Step: 4
Training loss: 2.1236488819122314
Validation loss: 2.068053598045021

Epoch: 5| Step: 5
Training loss: 2.657043218612671
Validation loss: 2.137213450606151

Epoch: 5| Step: 6
Training loss: 1.5610460042953491
Validation loss: 2.144417598683347

Epoch: 5| Step: 7
Training loss: 1.3781278133392334
Validation loss: 2.063961628944643

Epoch: 5| Step: 8
Training loss: 1.9332422018051147
Validation loss: 2.039756081437552

Epoch: 5| Step: 9
Training loss: 1.756898283958435
Validation loss: 2.186927186545505

Epoch: 5| Step: 10
Training loss: 2.2392730712890625
Validation loss: 2.0754403862901913

Epoch: 261| Step: 0
Training loss: 1.815585732460022
Validation loss: 2.0379811397162815

Epoch: 5| Step: 1
Training loss: 1.9848312139511108
Validation loss: 2.0132974322124193

Epoch: 5| Step: 2
Training loss: 2.0879111289978027
Validation loss: 2.116410045213597

Epoch: 5| Step: 3
Training loss: 2.2411293983459473
Validation loss: 2.1861112758677494

Epoch: 5| Step: 4
Training loss: 2.373321533203125
Validation loss: 2.127646493655379

Epoch: 5| Step: 5
Training loss: 1.4405304193496704
Validation loss: 2.087974431694195

Epoch: 5| Step: 6
Training loss: 2.3309686183929443
Validation loss: 2.1095139647042878

Epoch: 5| Step: 7
Training loss: 1.769649863243103
Validation loss: 2.127955872525451

Epoch: 5| Step: 8
Training loss: 1.2066936492919922
Validation loss: 2.185527922004782

Epoch: 5| Step: 9
Training loss: 2.401378870010376
Validation loss: 2.101743475083382

Epoch: 5| Step: 10
Training loss: 2.004617691040039
Validation loss: 2.1848273251646306

Epoch: 262| Step: 0
Training loss: 1.9566786289215088
Validation loss: 2.1923757342882055

Epoch: 5| Step: 1
Training loss: 2.4829070568084717
Validation loss: 2.1956363916397095

Epoch: 5| Step: 2
Training loss: 2.4138216972351074
Validation loss: 2.1556557532279723

Epoch: 5| Step: 3
Training loss: 1.8194024562835693
Validation loss: 2.188482681910197

Epoch: 5| Step: 4
Training loss: 2.7219552993774414
Validation loss: 2.095548995079533

Epoch: 5| Step: 5
Training loss: 1.909621238708496
Validation loss: 2.1231389250806583

Epoch: 5| Step: 6
Training loss: 1.5285284519195557
Validation loss: 2.1391026537905455

Epoch: 5| Step: 7
Training loss: 1.4403117895126343
Validation loss: 2.1281641837089293

Epoch: 5| Step: 8
Training loss: 2.3305132389068604
Validation loss: 2.1752039232561664

Epoch: 5| Step: 9
Training loss: 2.0556788444519043
Validation loss: 2.1160302546716507

Epoch: 5| Step: 10
Training loss: 1.459833025932312
Validation loss: 2.1628334137701217

Epoch: 263| Step: 0
Training loss: 2.125105619430542
Validation loss: 2.15033406724212

Epoch: 5| Step: 1
Training loss: 2.6076693534851074
Validation loss: 2.1448805242456417

Epoch: 5| Step: 2
Training loss: 2.0731711387634277
Validation loss: 2.1332715557467554

Epoch: 5| Step: 3
Training loss: 2.128293514251709
Validation loss: 2.1728684568917878

Epoch: 5| Step: 4
Training loss: 2.173293113708496
Validation loss: 2.159246301138273

Epoch: 5| Step: 5
Training loss: 1.6194404363632202
Validation loss: 2.0646013534197243

Epoch: 5| Step: 6
Training loss: 1.8494484424591064
Validation loss: 2.14910223150766

Epoch: 5| Step: 7
Training loss: 2.0791919231414795
Validation loss: 2.1363578983532485

Epoch: 5| Step: 8
Training loss: 1.32698655128479
Validation loss: 2.0983551830373783

Epoch: 5| Step: 9
Training loss: 2.185600757598877
Validation loss: 2.1544368677241827

Epoch: 5| Step: 10
Training loss: 2.158720016479492
Validation loss: 2.0193582222025883

Epoch: 264| Step: 0
Training loss: 1.5702913999557495
Validation loss: 2.108408525425901

Epoch: 5| Step: 1
Training loss: 2.1456007957458496
Validation loss: 2.018524210940125

Epoch: 5| Step: 2
Training loss: 2.0341992378234863
Validation loss: 2.102371087638281

Epoch: 5| Step: 3
Training loss: 2.1733620166778564
Validation loss: 2.1863365814250004

Epoch: 5| Step: 4
Training loss: 1.6828556060791016
Validation loss: 2.216323385956467

Epoch: 5| Step: 5
Training loss: 1.9639867544174194
Validation loss: 2.1814227796369985

Epoch: 5| Step: 6
Training loss: 2.5838277339935303
Validation loss: 2.1215638460651522

Epoch: 5| Step: 7
Training loss: 1.8632217645645142
Validation loss: 2.2102993611366517

Epoch: 5| Step: 8
Training loss: 1.8908612728118896
Validation loss: 2.0690424044926963

Epoch: 5| Step: 9
Training loss: 2.610384464263916
Validation loss: 2.2746265498540734

Epoch: 5| Step: 10
Training loss: 1.4679090976715088
Validation loss: 2.167725791213333

Epoch: 265| Step: 0
Training loss: 1.9195762872695923
Validation loss: 2.1955180693698186

Epoch: 5| Step: 1
Training loss: 2.7958643436431885
Validation loss: 2.0904270756629204

Epoch: 5| Step: 2
Training loss: 2.1974048614501953
Validation loss: 2.0970473251035138

Epoch: 5| Step: 3
Training loss: 2.763728380203247
Validation loss: 2.1055132624923543

Epoch: 5| Step: 4
Training loss: 1.660192847251892
Validation loss: 2.0553263618100073

Epoch: 5| Step: 5
Training loss: 1.8108056783676147
Validation loss: 2.123388272459789

Epoch: 5| Step: 6
Training loss: 2.16497802734375
Validation loss: 2.1387135123693817

Epoch: 5| Step: 7
Training loss: 1.920133352279663
Validation loss: 2.1038820961470246

Epoch: 5| Step: 8
Training loss: 1.7235939502716064
Validation loss: 2.1749207947843816

Epoch: 5| Step: 9
Training loss: 1.6246674060821533
Validation loss: 2.052666134731744

Epoch: 5| Step: 10
Training loss: 1.5438753366470337
Validation loss: 2.106049173621721

Epoch: 266| Step: 0
Training loss: 2.667569160461426
Validation loss: 2.1344559064475437

Epoch: 5| Step: 1
Training loss: 1.5840352773666382
Validation loss: 2.129681617982926

Epoch: 5| Step: 2
Training loss: 1.4885826110839844
Validation loss: 2.1102222781027518

Epoch: 5| Step: 3
Training loss: 1.9543908834457397
Validation loss: 2.0999014198139148

Epoch: 5| Step: 4
Training loss: 2.0875632762908936
Validation loss: 2.0972328186035156

Epoch: 5| Step: 5
Training loss: 2.0277328491210938
Validation loss: 2.109199636725969

Epoch: 5| Step: 6
Training loss: 1.8470284938812256
Validation loss: 2.0697769131711734

Epoch: 5| Step: 7
Training loss: 1.2645848989486694
Validation loss: 2.142872755245496

Epoch: 5| Step: 8
Training loss: 2.320854902267456
Validation loss: 2.0924689615926435

Epoch: 5| Step: 9
Training loss: 1.9085029363632202
Validation loss: 2.1621112080030542

Epoch: 5| Step: 10
Training loss: 2.6187167167663574
Validation loss: 2.0629333373039

Epoch: 267| Step: 0
Training loss: 1.6771141290664673
Validation loss: 2.1092529963421565

Epoch: 5| Step: 1
Training loss: 2.2144298553466797
Validation loss: 2.068185370455506

Epoch: 5| Step: 2
Training loss: 2.6490092277526855
Validation loss: 2.0193406510096725

Epoch: 5| Step: 3
Training loss: 1.880316138267517
Validation loss: 2.0805725692420878

Epoch: 5| Step: 4
Training loss: 1.5975819826126099
Validation loss: 2.080383162344656

Epoch: 5| Step: 5
Training loss: 1.4604861736297607
Validation loss: 2.0628968233703286

Epoch: 5| Step: 6
Training loss: 2.2309112548828125
Validation loss: 2.156938352892476

Epoch: 5| Step: 7
Training loss: 1.4002964496612549
Validation loss: 2.072404052621575

Epoch: 5| Step: 8
Training loss: 2.3091793060302734
Validation loss: 2.0710247972960114

Epoch: 5| Step: 9
Training loss: 2.7444701194763184
Validation loss: 2.049799188490837

Epoch: 5| Step: 10
Training loss: 1.784971833229065
Validation loss: 2.096099120314403

Epoch: 268| Step: 0
Training loss: 1.7626368999481201
Validation loss: 2.148086605533477

Epoch: 5| Step: 1
Training loss: 1.6975347995758057
Validation loss: 2.0772741686913276

Epoch: 5| Step: 2
Training loss: 2.0761818885803223
Validation loss: 2.023097158760153

Epoch: 5| Step: 3
Training loss: 2.5948874950408936
Validation loss: 2.0842343376528834

Epoch: 5| Step: 4
Training loss: 1.4586148262023926
Validation loss: 2.0948347455711773

Epoch: 5| Step: 5
Training loss: 2.0663411617279053
Validation loss: 2.098457444098688

Epoch: 5| Step: 6
Training loss: 1.6831047534942627
Validation loss: 2.0936074103078535

Epoch: 5| Step: 7
Training loss: 2.1528568267822266
Validation loss: 2.2653422509470293

Epoch: 5| Step: 8
Training loss: 1.5834572315216064
Validation loss: 2.1659512084017516

Epoch: 5| Step: 9
Training loss: 2.6699976921081543
Validation loss: 2.2094935422302573

Epoch: 5| Step: 10
Training loss: 2.1713597774505615
Validation loss: 2.1262240332941853

Epoch: 269| Step: 0
Training loss: 1.8974964618682861
Validation loss: 2.188847998137115

Epoch: 5| Step: 1
Training loss: 1.6277049779891968
Validation loss: 2.236836116801026

Epoch: 5| Step: 2
Training loss: 1.3502147197723389
Validation loss: 2.0935135426059848

Epoch: 5| Step: 3
Training loss: 1.9838249683380127
Validation loss: 2.066174384086363

Epoch: 5| Step: 4
Training loss: 2.260251760482788
Validation loss: 2.0665534952635407

Epoch: 5| Step: 5
Training loss: 1.4006097316741943
Validation loss: 2.1392745112860077

Epoch: 5| Step: 6
Training loss: 2.438701629638672
Validation loss: 2.0512339017724477

Epoch: 5| Step: 7
Training loss: 2.8177695274353027
Validation loss: 2.105260337552717

Epoch: 5| Step: 8
Training loss: 1.7290468215942383
Validation loss: 2.13939901192983

Epoch: 5| Step: 9
Training loss: 1.5129172801971436
Validation loss: 2.0730593614680792

Epoch: 5| Step: 10
Training loss: 2.21378231048584
Validation loss: 2.0762789813421105

Epoch: 270| Step: 0
Training loss: 1.9772316217422485
Validation loss: 2.049164133687173

Epoch: 5| Step: 1
Training loss: 1.7017371654510498
Validation loss: 2.159113504553354

Epoch: 5| Step: 2
Training loss: 2.013777494430542
Validation loss: 2.006015213586951

Epoch: 5| Step: 3
Training loss: 2.217103958129883
Validation loss: 2.0234652078279884

Epoch: 5| Step: 4
Training loss: 2.2744863033294678
Validation loss: 2.112802323474679

Epoch: 5| Step: 5
Training loss: 1.801039457321167
Validation loss: 2.0962796326606505

Epoch: 5| Step: 6
Training loss: 1.664764404296875
Validation loss: 2.076667106279763

Epoch: 5| Step: 7
Training loss: 2.447885513305664
Validation loss: 2.075402425181481

Epoch: 5| Step: 8
Training loss: 1.9454914331436157
Validation loss: 2.0519257450616486

Epoch: 5| Step: 9
Training loss: 1.7906982898712158
Validation loss: 2.1133171102052093

Epoch: 5| Step: 10
Training loss: 1.7249115705490112
Validation loss: 2.0651172309793453

Epoch: 271| Step: 0
Training loss: 1.9896879196166992
Validation loss: 2.0629184733154955

Epoch: 5| Step: 1
Training loss: 1.0837500095367432
Validation loss: 2.111314273649646

Epoch: 5| Step: 2
Training loss: 1.5838253498077393
Validation loss: 2.0752344567288636

Epoch: 5| Step: 3
Training loss: 1.959954857826233
Validation loss: 2.1417645074987925

Epoch: 5| Step: 4
Training loss: 2.3262553215026855
Validation loss: 2.151667018090525

Epoch: 5| Step: 5
Training loss: 1.566068410873413
Validation loss: 2.1375492183111047

Epoch: 5| Step: 6
Training loss: 2.3607609272003174
Validation loss: 2.0786339621390066

Epoch: 5| Step: 7
Training loss: 2.1679587364196777
Validation loss: 2.1263584680454706

Epoch: 5| Step: 8
Training loss: 1.8265254497528076
Validation loss: 2.1239764087943622

Epoch: 5| Step: 9
Training loss: 2.5719752311706543
Validation loss: 2.0454265404773015

Epoch: 5| Step: 10
Training loss: 2.4156200885772705
Validation loss: 2.1666374116815548

Epoch: 272| Step: 0
Training loss: 1.771545171737671
Validation loss: 2.057336148395333

Epoch: 5| Step: 1
Training loss: 1.3613958358764648
Validation loss: 2.079979156935087

Epoch: 5| Step: 2
Training loss: 2.225383758544922
Validation loss: 2.189212309416904

Epoch: 5| Step: 3
Training loss: 1.9570834636688232
Validation loss: 2.1253739339049145

Epoch: 5| Step: 4
Training loss: 1.8146169185638428
Validation loss: 2.0786071874762095

Epoch: 5| Step: 5
Training loss: 2.6716835498809814
Validation loss: 2.119145652299286

Epoch: 5| Step: 6
Training loss: 2.1532392501831055
Validation loss: 2.193204464450959

Epoch: 5| Step: 7
Training loss: 2.104969024658203
Validation loss: 2.0968921479358467

Epoch: 5| Step: 8
Training loss: 2.084090232849121
Validation loss: 2.1704296950371034

Epoch: 5| Step: 9
Training loss: 1.7245954275131226
Validation loss: 2.0496080178086475

Epoch: 5| Step: 10
Training loss: 1.0169013738632202
Validation loss: 1.952833011586179

Epoch: 273| Step: 0
Training loss: 1.8126966953277588
Validation loss: 2.101178252568809

Epoch: 5| Step: 1
Training loss: 1.8740030527114868
Validation loss: 2.072792007077125

Epoch: 5| Step: 2
Training loss: 1.6705303192138672
Validation loss: 2.1534475716211463

Epoch: 5| Step: 3
Training loss: 2.0152792930603027
Validation loss: 2.1773174270506828

Epoch: 5| Step: 4
Training loss: 2.2781729698181152
Validation loss: 2.0550025765613844

Epoch: 5| Step: 5
Training loss: 2.1037516593933105
Validation loss: 2.12283359419915

Epoch: 5| Step: 6
Training loss: 2.3910326957702637
Validation loss: 2.1002432761653775

Epoch: 5| Step: 7
Training loss: 1.399547815322876
Validation loss: 2.027829074090527

Epoch: 5| Step: 8
Training loss: 1.8854337930679321
Validation loss: 2.1605880439922376

Epoch: 5| Step: 9
Training loss: 2.2650859355926514
Validation loss: 2.087193025055752

Epoch: 5| Step: 10
Training loss: 1.670872688293457
Validation loss: 2.0776394285181516

Epoch: 274| Step: 0
Training loss: 1.6775665283203125
Validation loss: 2.109753934285974

Epoch: 5| Step: 1
Training loss: 1.6647288799285889
Validation loss: 2.08952506126896

Epoch: 5| Step: 2
Training loss: 1.589863896369934
Validation loss: 2.0182418746332966

Epoch: 5| Step: 3
Training loss: 2.1444573402404785
Validation loss: 2.1322231420906643

Epoch: 5| Step: 4
Training loss: 1.8149839639663696
Validation loss: 2.0980862686710973

Epoch: 5| Step: 5
Training loss: 1.6437690258026123
Validation loss: 2.1669871140551824

Epoch: 5| Step: 6
Training loss: 1.7419073581695557
Validation loss: 2.1085498307340886

Epoch: 5| Step: 7
Training loss: 2.0351951122283936
Validation loss: 1.999536898828322

Epoch: 5| Step: 8
Training loss: 2.610940456390381
Validation loss: 2.1286484041521625

Epoch: 5| Step: 9
Training loss: 1.91812264919281
Validation loss: 2.107385345684585

Epoch: 5| Step: 10
Training loss: 2.492374897003174
Validation loss: 1.989381064650833

Epoch: 275| Step: 0
Training loss: 2.2377142906188965
Validation loss: 2.094144444311819

Epoch: 5| Step: 1
Training loss: 1.4984757900238037
Validation loss: 2.1248904479447233

Epoch: 5| Step: 2
Training loss: 1.9885238409042358
Validation loss: 2.003486115445373

Epoch: 5| Step: 3
Training loss: 1.3663685321807861
Validation loss: 2.1246141208115445

Epoch: 5| Step: 4
Training loss: 1.9198919534683228
Validation loss: 2.098574374311714

Epoch: 5| Step: 5
Training loss: 2.442021369934082
Validation loss: 2.112411452877906

Epoch: 5| Step: 6
Training loss: 1.248742699623108
Validation loss: 2.0792003139372794

Epoch: 5| Step: 7
Training loss: 2.0328450202941895
Validation loss: 2.1387432647007767

Epoch: 5| Step: 8
Training loss: 2.410757541656494
Validation loss: 2.0853739912791918

Epoch: 5| Step: 9
Training loss: 2.2018377780914307
Validation loss: 2.1094304938470163

Epoch: 5| Step: 10
Training loss: 1.9665329456329346
Validation loss: 2.0938288473313853

Epoch: 276| Step: 0
Training loss: 2.1988391876220703
Validation loss: 2.1127345459435576

Epoch: 5| Step: 1
Training loss: 2.141979455947876
Validation loss: 2.0494084973489084

Epoch: 5| Step: 2
Training loss: 1.7908884286880493
Validation loss: 2.1020984136930077

Epoch: 5| Step: 3
Training loss: 1.898246169090271
Validation loss: 2.1619288459900887

Epoch: 5| Step: 4
Training loss: 1.7841618061065674
Validation loss: 2.1232796458787817

Epoch: 5| Step: 5
Training loss: 1.8315989971160889
Validation loss: 2.083819858489498

Epoch: 5| Step: 6
Training loss: 2.4453089237213135
Validation loss: 2.0993838899879047

Epoch: 5| Step: 7
Training loss: 2.8347315788269043
Validation loss: 2.1310027107115714

Epoch: 5| Step: 8
Training loss: 1.9856271743774414
Validation loss: 2.0601596704093357

Epoch: 5| Step: 9
Training loss: 1.6042258739471436
Validation loss: 2.1017724903680945

Epoch: 5| Step: 10
Training loss: 1.1113723516464233
Validation loss: 2.0725929147453717

Epoch: 277| Step: 0
Training loss: 1.825487732887268
Validation loss: 2.148764815381778

Epoch: 5| Step: 1
Training loss: 1.687951683998108
Validation loss: 2.0725511133029895

Epoch: 5| Step: 2
Training loss: 2.3403995037078857
Validation loss: 2.1891023112881567

Epoch: 5| Step: 3
Training loss: 2.0140163898468018
Validation loss: 2.0905686424624537

Epoch: 5| Step: 4
Training loss: 1.5665775537490845
Validation loss: 1.9871198156828522

Epoch: 5| Step: 5
Training loss: 2.0287985801696777
Validation loss: 2.077085192485522

Epoch: 5| Step: 6
Training loss: 2.677253246307373
Validation loss: 2.0917062785035823

Epoch: 5| Step: 7
Training loss: 1.542557954788208
Validation loss: 2.17510881475223

Epoch: 5| Step: 8
Training loss: 2.7336394786834717
Validation loss: 2.0461976681986163

Epoch: 5| Step: 9
Training loss: 1.973639726638794
Validation loss: 2.0608925832215177

Epoch: 5| Step: 10
Training loss: 1.6118508577346802
Validation loss: 2.042276026100241

Epoch: 278| Step: 0
Training loss: 2.2007033824920654
Validation loss: 2.199697409906695

Epoch: 5| Step: 1
Training loss: 1.55800199508667
Validation loss: 2.125833431879679

Epoch: 5| Step: 2
Training loss: 2.7412471771240234
Validation loss: 2.197016759585309

Epoch: 5| Step: 3
Training loss: 2.0983970165252686
Validation loss: 2.196338527946062

Epoch: 5| Step: 4
Training loss: 1.3488038778305054
Validation loss: 2.1740104741947626

Epoch: 5| Step: 5
Training loss: 2.1421403884887695
Validation loss: 2.104015652851392

Epoch: 5| Step: 6
Training loss: 2.250157594680786
Validation loss: 2.0583979801465104

Epoch: 5| Step: 7
Training loss: 2.0649032592773438
Validation loss: 2.1386195998038016

Epoch: 5| Step: 8
Training loss: 1.985499620437622
Validation loss: 2.1028589253784506

Epoch: 5| Step: 9
Training loss: 1.7620971202850342
Validation loss: 2.097518144115325

Epoch: 5| Step: 10
Training loss: 1.3653284311294556
Validation loss: 2.154454461989864

Epoch: 279| Step: 0
Training loss: 1.8208500146865845
Validation loss: 1.952628106199285

Epoch: 5| Step: 1
Training loss: 2.3644983768463135
Validation loss: 2.144434339256697

Epoch: 5| Step: 2
Training loss: 1.6690750122070312
Validation loss: 2.146565947481381

Epoch: 5| Step: 3
Training loss: 1.9743865728378296
Validation loss: 2.0625835464846705

Epoch: 5| Step: 4
Training loss: 1.9835420846939087
Validation loss: 1.9450999729094967

Epoch: 5| Step: 5
Training loss: 1.9618160724639893
Validation loss: 2.118545798845189

Epoch: 5| Step: 6
Training loss: 1.9519531726837158
Validation loss: 1.9214245606494207

Epoch: 5| Step: 7
Training loss: 2.0499842166900635
Validation loss: 2.0467947247207805

Epoch: 5| Step: 8
Training loss: 1.6256992816925049
Validation loss: 2.069745663673647

Epoch: 5| Step: 9
Training loss: 1.7970304489135742
Validation loss: 2.0238341259699997

Epoch: 5| Step: 10
Training loss: 2.0977978706359863
Validation loss: 2.0888277561433855

Epoch: 280| Step: 0
Training loss: 2.0446534156799316
Validation loss: 2.1873563463969896

Epoch: 5| Step: 1
Training loss: 1.9707199335098267
Validation loss: 2.0973358103024062

Epoch: 5| Step: 2
Training loss: 2.1160902976989746
Validation loss: 2.031658472553376

Epoch: 5| Step: 3
Training loss: 2.1196322441101074
Validation loss: 1.9788432082822245

Epoch: 5| Step: 4
Training loss: 1.6629139184951782
Validation loss: 2.0423574562995666

Epoch: 5| Step: 5
Training loss: 2.293220043182373
Validation loss: 2.103062983482115

Epoch: 5| Step: 6
Training loss: 1.790014624595642
Validation loss: 2.1181939404497863

Epoch: 5| Step: 7
Training loss: 2.202061653137207
Validation loss: 2.0758758949977096

Epoch: 5| Step: 8
Training loss: 1.8807264566421509
Validation loss: 2.1609407291617444

Epoch: 5| Step: 9
Training loss: 1.4966787099838257
Validation loss: 2.112880015885958

Epoch: 5| Step: 10
Training loss: 2.146768808364868
Validation loss: 2.087909443404085

Epoch: 281| Step: 0
Training loss: 1.9812793731689453
Validation loss: 2.0980743438966813

Epoch: 5| Step: 1
Training loss: 2.0046627521514893
Validation loss: 2.1748564576589935

Epoch: 5| Step: 2
Training loss: 1.3883694410324097
Validation loss: 2.037634523965979

Epoch: 5| Step: 3
Training loss: 1.985337495803833
Validation loss: 2.1598088561847644

Epoch: 5| Step: 4
Training loss: 1.8861238956451416
Validation loss: 2.0978006342405915

Epoch: 5| Step: 5
Training loss: 1.6606594324111938
Validation loss: 2.0788796794029976

Epoch: 5| Step: 6
Training loss: 3.021854877471924
Validation loss: 2.043071282807217

Epoch: 5| Step: 7
Training loss: 1.3100883960723877
Validation loss: 2.085584539239125

Epoch: 5| Step: 8
Training loss: 1.8838402032852173
Validation loss: 2.1640064767611924

Epoch: 5| Step: 9
Training loss: 1.980242133140564
Validation loss: 2.125171479358468

Epoch: 5| Step: 10
Training loss: 2.265030860900879
Validation loss: 2.122176734350061

Epoch: 282| Step: 0
Training loss: 2.752470016479492
Validation loss: 2.040659091805899

Epoch: 5| Step: 1
Training loss: 1.9696356058120728
Validation loss: 2.127898358529614

Epoch: 5| Step: 2
Training loss: 2.003441333770752
Validation loss: 2.0122594628282773

Epoch: 5| Step: 3
Training loss: 1.9516284465789795
Validation loss: 2.083886082454394

Epoch: 5| Step: 4
Training loss: 1.3735278844833374
Validation loss: 2.1429663550469185

Epoch: 5| Step: 5
Training loss: 1.8263152837753296
Validation loss: 2.0862014575671126

Epoch: 5| Step: 6
Training loss: 1.241835594177246
Validation loss: 2.0220619965625066

Epoch: 5| Step: 7
Training loss: 2.210132122039795
Validation loss: 2.084135922052527

Epoch: 5| Step: 8
Training loss: 2.406083345413208
Validation loss: 2.0043260435904227

Epoch: 5| Step: 9
Training loss: 2.2385051250457764
Validation loss: 2.0377357275255266

Epoch: 5| Step: 10
Training loss: 2.087191343307495
Validation loss: 1.9493309131232641

Epoch: 283| Step: 0
Training loss: 2.0261311531066895
Validation loss: 2.0739553692520305

Epoch: 5| Step: 1
Training loss: 1.811736822128296
Validation loss: 2.152895542883104

Epoch: 5| Step: 2
Training loss: 1.1432098150253296
Validation loss: 2.167872154584495

Epoch: 5| Step: 3
Training loss: 2.0786995887756348
Validation loss: 2.047456528550835

Epoch: 5| Step: 4
Training loss: 2.3982625007629395
Validation loss: 2.04473804402095

Epoch: 5| Step: 5
Training loss: 2.469569444656372
Validation loss: 2.0760003366777973

Epoch: 5| Step: 6
Training loss: 1.749219536781311
Validation loss: 2.0647966861724854

Epoch: 5| Step: 7
Training loss: 2.077887535095215
Validation loss: 2.080937466313762

Epoch: 5| Step: 8
Training loss: 1.7255771160125732
Validation loss: 2.099104086558024

Epoch: 5| Step: 9
Training loss: 1.8027782440185547
Validation loss: 2.1047891980858258

Epoch: 5| Step: 10
Training loss: 1.9333244562149048
Validation loss: 2.1448457343603975

Epoch: 284| Step: 0
Training loss: 1.8665268421173096
Validation loss: 2.189036879488217

Epoch: 5| Step: 1
Training loss: 2.296964645385742
Validation loss: 2.0821591192676174

Epoch: 5| Step: 2
Training loss: 1.849239706993103
Validation loss: 2.092070086027986

Epoch: 5| Step: 3
Training loss: 2.0600996017456055
Validation loss: 2.1209828443424676

Epoch: 5| Step: 4
Training loss: 1.8131564855575562
Validation loss: 2.136274673605478

Epoch: 5| Step: 5
Training loss: 2.457207441329956
Validation loss: 2.119267268847394

Epoch: 5| Step: 6
Training loss: 1.7309091091156006
Validation loss: 2.159882294234409

Epoch: 5| Step: 7
Training loss: 1.843634009361267
Validation loss: 2.11702549329368

Epoch: 5| Step: 8
Training loss: 1.5990349054336548
Validation loss: 2.086591923108665

Epoch: 5| Step: 9
Training loss: 1.88533616065979
Validation loss: 2.023326699451734

Epoch: 5| Step: 10
Training loss: 2.6734824180603027
Validation loss: 2.0666138882278116

Epoch: 285| Step: 0
Training loss: 2.3349061012268066
Validation loss: 2.0736528250478927

Epoch: 5| Step: 1
Training loss: 2.2472012042999268
Validation loss: 2.0830836270445134

Epoch: 5| Step: 2
Training loss: 2.045579671859741
Validation loss: 2.1115863054029402

Epoch: 5| Step: 3
Training loss: 2.6128647327423096
Validation loss: 2.109928315685641

Epoch: 5| Step: 4
Training loss: 1.3213260173797607
Validation loss: 2.1727678455332273

Epoch: 5| Step: 5
Training loss: 2.2047557830810547
Validation loss: 2.0455081334678074

Epoch: 5| Step: 6
Training loss: 1.7194416522979736
Validation loss: 2.0141564415347193

Epoch: 5| Step: 7
Training loss: 1.3010857105255127
Validation loss: 2.1562091124955045

Epoch: 5| Step: 8
Training loss: 2.018359422683716
Validation loss: 2.1213413861490067

Epoch: 5| Step: 9
Training loss: 1.572166085243225
Validation loss: 2.1037193831577095

Epoch: 5| Step: 10
Training loss: 1.9122637510299683
Validation loss: 2.0860672214979767

Epoch: 286| Step: 0
Training loss: 2.942556619644165
Validation loss: 2.1009245559733403

Epoch: 5| Step: 1
Training loss: 2.285525321960449
Validation loss: 2.001317999696219

Epoch: 5| Step: 2
Training loss: 2.1147067546844482
Validation loss: 2.050479365933326

Epoch: 5| Step: 3
Training loss: 2.1486942768096924
Validation loss: 2.0911164899026193

Epoch: 5| Step: 4
Training loss: 1.4518678188323975
Validation loss: 2.146395642270324

Epoch: 5| Step: 5
Training loss: 1.9396175146102905
Validation loss: 2.07390538466874

Epoch: 5| Step: 6
Training loss: 1.6740515232086182
Validation loss: 2.025974355718141

Epoch: 5| Step: 7
Training loss: 1.7394130229949951
Validation loss: 2.1238919522172663

Epoch: 5| Step: 8
Training loss: 1.7821769714355469
Validation loss: 2.082254221362452

Epoch: 5| Step: 9
Training loss: 2.0234010219573975
Validation loss: 2.1071399424665715

Epoch: 5| Step: 10
Training loss: 1.6538118124008179
Validation loss: 2.0045995917371524

Epoch: 287| Step: 0
Training loss: 2.2966790199279785
Validation loss: 2.0851895091354207

Epoch: 5| Step: 1
Training loss: 2.0486342906951904
Validation loss: 2.138958322104587

Epoch: 5| Step: 2
Training loss: 1.3322762250900269
Validation loss: 2.099501176546979

Epoch: 5| Step: 3
Training loss: 1.955129861831665
Validation loss: 2.1485890778162147

Epoch: 5| Step: 4
Training loss: 1.8501392602920532
Validation loss: 2.139272080954685

Epoch: 5| Step: 5
Training loss: 1.3272805213928223
Validation loss: 2.128594926608506

Epoch: 5| Step: 6
Training loss: 2.1270852088928223
Validation loss: 2.1333208942926056

Epoch: 5| Step: 7
Training loss: 2.73313570022583
Validation loss: 2.1017300698064987

Epoch: 5| Step: 8
Training loss: 2.4347548484802246
Validation loss: 2.1568545500437417

Epoch: 5| Step: 9
Training loss: 2.3342409133911133
Validation loss: 2.119365947220915

Epoch: 5| Step: 10
Training loss: 1.8309106826782227
Validation loss: 2.025654887640348

Epoch: 288| Step: 0
Training loss: 2.0698609352111816
Validation loss: 2.10992814776718

Epoch: 5| Step: 1
Training loss: 2.5952441692352295
Validation loss: 2.1340439268337783

Epoch: 5| Step: 2
Training loss: 1.6194216012954712
Validation loss: 2.0378289504717757

Epoch: 5| Step: 3
Training loss: 2.096045970916748
Validation loss: 2.0363194301564205

Epoch: 5| Step: 4
Training loss: 2.0535857677459717
Validation loss: 1.9836616234112812

Epoch: 5| Step: 5
Training loss: 2.5258264541625977
Validation loss: 2.0371121975683395

Epoch: 5| Step: 6
Training loss: 1.2997169494628906
Validation loss: 2.053869519182431

Epoch: 5| Step: 7
Training loss: 1.8088741302490234
Validation loss: 2.06785653227119

Epoch: 5| Step: 8
Training loss: 2.0064005851745605
Validation loss: 2.101455873058688

Epoch: 5| Step: 9
Training loss: 1.4046719074249268
Validation loss: 1.9973391281661166

Epoch: 5| Step: 10
Training loss: 2.5843846797943115
Validation loss: 2.1071541642629974

Epoch: 289| Step: 0
Training loss: 1.7398340702056885
Validation loss: 2.0097930354456746

Epoch: 5| Step: 1
Training loss: 1.9246082305908203
Validation loss: 2.1083739085863997

Epoch: 5| Step: 2
Training loss: 1.598480463027954
Validation loss: 1.9659016619446457

Epoch: 5| Step: 3
Training loss: 2.5738296508789062
Validation loss: 1.9552782812426168

Epoch: 5| Step: 4
Training loss: 2.2116193771362305
Validation loss: 2.158223844343616

Epoch: 5| Step: 5
Training loss: 1.5389297008514404
Validation loss: 2.0985368887583413

Epoch: 5| Step: 6
Training loss: 1.7540146112442017
Validation loss: 2.1324279154500654

Epoch: 5| Step: 7
Training loss: 1.7607446908950806
Validation loss: 2.1719690035748225

Epoch: 5| Step: 8
Training loss: 2.063772439956665
Validation loss: 2.059072208660905

Epoch: 5| Step: 9
Training loss: 2.9364452362060547
Validation loss: 2.1276277444695912

Epoch: 5| Step: 10
Training loss: 1.6172289848327637
Validation loss: 2.1066241161797636

Epoch: 290| Step: 0
Training loss: 1.9025529623031616
Validation loss: 2.0923324144014748

Epoch: 5| Step: 1
Training loss: 2.1861889362335205
Validation loss: 2.0743516055486535

Epoch: 5| Step: 2
Training loss: 2.2019147872924805
Validation loss: 2.1689599290970834

Epoch: 5| Step: 3
Training loss: 2.014774799346924
Validation loss: 2.160107909992177

Epoch: 5| Step: 4
Training loss: 1.8561798334121704
Validation loss: 2.1212684134001374

Epoch: 5| Step: 5
Training loss: 1.7961757183074951
Validation loss: 2.075834370428516

Epoch: 5| Step: 6
Training loss: 1.76474928855896
Validation loss: 2.0741438840025213

Epoch: 5| Step: 7
Training loss: 1.484311819076538
Validation loss: 2.1108446223761446

Epoch: 5| Step: 8
Training loss: 2.0684142112731934
Validation loss: 2.1165161619904223

Epoch: 5| Step: 9
Training loss: 2.390939235687256
Validation loss: 1.9997874485549105

Epoch: 5| Step: 10
Training loss: 1.9725217819213867
Validation loss: 2.0844447023125103

Epoch: 291| Step: 0
Training loss: 2.0868849754333496
Validation loss: 2.0315637332136913

Epoch: 5| Step: 1
Training loss: 1.6939903497695923
Validation loss: 1.9897812848450036

Epoch: 5| Step: 2
Training loss: 1.5053809881210327
Validation loss: 2.0965579043152514

Epoch: 5| Step: 3
Training loss: 1.7751270532608032
Validation loss: 1.991238792737325

Epoch: 5| Step: 4
Training loss: 2.3035078048706055
Validation loss: 2.0989822969641736

Epoch: 5| Step: 5
Training loss: 2.0724735260009766
Validation loss: 2.107220149809314

Epoch: 5| Step: 6
Training loss: 2.2697527408599854
Validation loss: 2.068697647381854

Epoch: 5| Step: 7
Training loss: 2.142929792404175
Validation loss: 2.065802833085419

Epoch: 5| Step: 8
Training loss: 1.8035606145858765
Validation loss: 2.1276967717755224

Epoch: 5| Step: 9
Training loss: 2.205688238143921
Validation loss: 2.066763767632105

Epoch: 5| Step: 10
Training loss: 1.4226727485656738
Validation loss: 2.0971250559694026

Epoch: 292| Step: 0
Training loss: 2.3095970153808594
Validation loss: 2.0747223054209063

Epoch: 5| Step: 1
Training loss: 1.0208771228790283
Validation loss: 2.1024296078630673

Epoch: 5| Step: 2
Training loss: 1.6162697076797485
Validation loss: 2.1465696929603495

Epoch: 5| Step: 3
Training loss: 2.1880340576171875
Validation loss: 2.1105854383078952

Epoch: 5| Step: 4
Training loss: 1.999850869178772
Validation loss: 2.2007873032682683

Epoch: 5| Step: 5
Training loss: 2.3545470237731934
Validation loss: 2.1712821978394703

Epoch: 5| Step: 6
Training loss: 2.5423126220703125
Validation loss: 2.0595741425791094

Epoch: 5| Step: 7
Training loss: 2.3094191551208496
Validation loss: 2.19997452920483

Epoch: 5| Step: 8
Training loss: 1.978939414024353
Validation loss: 2.115811114670128

Epoch: 5| Step: 9
Training loss: 2.06783127784729
Validation loss: 2.177991872192711

Epoch: 5| Step: 10
Training loss: 2.2224395275115967
Validation loss: 2.1149006607711955

Epoch: 293| Step: 0
Training loss: 2.194756031036377
Validation loss: 2.144550177358812

Epoch: 5| Step: 1
Training loss: 1.4217623472213745
Validation loss: 2.1870476994463193

Epoch: 5| Step: 2
Training loss: 1.8946603536605835
Validation loss: 2.1126464977059314

Epoch: 5| Step: 3
Training loss: 1.677152395248413
Validation loss: 2.0488175012732066

Epoch: 5| Step: 4
Training loss: 1.9846429824829102
Validation loss: 2.1095346186750676

Epoch: 5| Step: 5
Training loss: 1.7908799648284912
Validation loss: 2.1316411956664054

Epoch: 5| Step: 6
Training loss: 2.118007183074951
Validation loss: 2.09107542550692

Epoch: 5| Step: 7
Training loss: 1.568882703781128
Validation loss: 2.061808024683306

Epoch: 5| Step: 8
Training loss: 2.107764720916748
Validation loss: 2.18296294571251

Epoch: 5| Step: 9
Training loss: 2.4583163261413574
Validation loss: 2.097553483901485

Epoch: 5| Step: 10
Training loss: 2.0557894706726074
Validation loss: 1.9651000666361984

Epoch: 294| Step: 0
Training loss: 1.763143539428711
Validation loss: 2.009545442878559

Epoch: 5| Step: 1
Training loss: 2.7508556842803955
Validation loss: 2.000983476638794

Epoch: 5| Step: 2
Training loss: 1.6753685474395752
Validation loss: 2.1141715716290217

Epoch: 5| Step: 3
Training loss: 2.4262948036193848
Validation loss: 2.076216851511309

Epoch: 5| Step: 4
Training loss: 1.4423576593399048
Validation loss: 2.135459969120641

Epoch: 5| Step: 5
Training loss: 1.8180434703826904
Validation loss: 2.059748597042535

Epoch: 5| Step: 6
Training loss: 1.553604006767273
Validation loss: 2.088453459483321

Epoch: 5| Step: 7
Training loss: 2.1212611198425293
Validation loss: 2.201844976794335

Epoch: 5| Step: 8
Training loss: 1.8894426822662354
Validation loss: 2.1007756879252772

Epoch: 5| Step: 9
Training loss: 1.9503185749053955
Validation loss: 2.1820058784177228

Epoch: 5| Step: 10
Training loss: 2.545048475265503
Validation loss: 2.1216551103899555

Epoch: 295| Step: 0
Training loss: 1.7376524209976196
Validation loss: 2.120272651795418

Epoch: 5| Step: 1
Training loss: 2.431501626968384
Validation loss: 2.111744135938665

Epoch: 5| Step: 2
Training loss: 1.7468159198760986
Validation loss: 2.11787788714132

Epoch: 5| Step: 3
Training loss: 2.5816731452941895
Validation loss: 2.072897413725494

Epoch: 5| Step: 4
Training loss: 1.763332724571228
Validation loss: 2.014213072356357

Epoch: 5| Step: 5
Training loss: 2.199921131134033
Validation loss: 2.0572069191163584

Epoch: 5| Step: 6
Training loss: 1.5815213918685913
Validation loss: 2.1016245708670667

Epoch: 5| Step: 7
Training loss: 2.184882402420044
Validation loss: 2.1257479626645326

Epoch: 5| Step: 8
Training loss: 2.471648693084717
Validation loss: 2.1335689662605204

Epoch: 5| Step: 9
Training loss: 1.4146842956542969
Validation loss: 2.1067599737516014

Epoch: 5| Step: 10
Training loss: 2.1989011764526367
Validation loss: 2.0873954116657214

Epoch: 296| Step: 0
Training loss: 1.6738007068634033
Validation loss: 2.0453203083366476

Epoch: 5| Step: 1
Training loss: 2.1801464557647705
Validation loss: 2.0867900489478983

Epoch: 5| Step: 2
Training loss: 2.4078824520111084
Validation loss: 2.105361828240015

Epoch: 5| Step: 3
Training loss: 2.3138039112091064
Validation loss: 2.0224967143868886

Epoch: 5| Step: 4
Training loss: 2.0932223796844482
Validation loss: 2.1210021062563826

Epoch: 5| Step: 5
Training loss: 2.227501153945923
Validation loss: 2.111510005048526

Epoch: 5| Step: 6
Training loss: 2.458610773086548
Validation loss: 2.1687126467304845

Epoch: 5| Step: 7
Training loss: 1.7168447971343994
Validation loss: 2.0063986086076304

Epoch: 5| Step: 8
Training loss: 1.5696697235107422
Validation loss: 2.071151195033904

Epoch: 5| Step: 9
Training loss: 1.3239052295684814
Validation loss: 2.1061762430334605

Epoch: 5| Step: 10
Training loss: 1.7478989362716675
Validation loss: 2.053316039423789

Epoch: 297| Step: 0
Training loss: 2.152855634689331
Validation loss: 2.0685516416385608

Epoch: 5| Step: 1
Training loss: 2.081968307495117
Validation loss: 2.0900856423121628

Epoch: 5| Step: 2
Training loss: 2.4003758430480957
Validation loss: 2.1382275819778442

Epoch: 5| Step: 3
Training loss: 1.7696748971939087
Validation loss: 2.028990111043376

Epoch: 5| Step: 4
Training loss: 2.136786937713623
Validation loss: 2.072835414640365

Epoch: 5| Step: 5
Training loss: 1.7519391775131226
Validation loss: 2.078094882349814

Epoch: 5| Step: 6
Training loss: 1.9779918193817139
Validation loss: 2.1182995816712737

Epoch: 5| Step: 7
Training loss: 2.0409252643585205
Validation loss: 2.0594400346920056

Epoch: 5| Step: 8
Training loss: 1.1246227025985718
Validation loss: 2.136390907790071

Epoch: 5| Step: 9
Training loss: 2.1463727951049805
Validation loss: 2.105486028937883

Epoch: 5| Step: 10
Training loss: 1.807054877281189
Validation loss: 2.157907078343053

Epoch: 298| Step: 0
Training loss: 1.912113904953003
Validation loss: 2.0760058613233667

Epoch: 5| Step: 1
Training loss: 1.8481674194335938
Validation loss: 2.262957006372431

Epoch: 5| Step: 2
Training loss: 1.573263168334961
Validation loss: 2.043989960865308

Epoch: 5| Step: 3
Training loss: 1.964956521987915
Validation loss: 2.1483797027218725

Epoch: 5| Step: 4
Training loss: 1.7200877666473389
Validation loss: 2.128101735986689

Epoch: 5| Step: 5
Training loss: 1.3464138507843018
Validation loss: 2.012464625861055

Epoch: 5| Step: 6
Training loss: 2.126884937286377
Validation loss: 2.1338135991045224

Epoch: 5| Step: 7
Training loss: 1.783124327659607
Validation loss: 2.1421066586689284

Epoch: 5| Step: 8
Training loss: 2.8481881618499756
Validation loss: 2.0675314882750153

Epoch: 5| Step: 9
Training loss: 2.363940715789795
Validation loss: 2.0772462198811192

Epoch: 5| Step: 10
Training loss: 1.659066081047058
Validation loss: 2.1571710955712105

Epoch: 299| Step: 0
Training loss: 2.5618064403533936
Validation loss: 2.0431335844019407

Epoch: 5| Step: 1
Training loss: 2.5516505241394043
Validation loss: 2.1497124471972064

Epoch: 5| Step: 2
Training loss: 1.7329553365707397
Validation loss: 2.0170341448117326

Epoch: 5| Step: 3
Training loss: 1.6137317419052124
Validation loss: 2.060634366927608

Epoch: 5| Step: 4
Training loss: 2.0764434337615967
Validation loss: 2.2187136757758354

Epoch: 5| Step: 5
Training loss: 1.600979208946228
Validation loss: 2.096851953896143

Epoch: 5| Step: 6
Training loss: 2.1155178546905518
Validation loss: 2.085883609710201

Epoch: 5| Step: 7
Training loss: 1.6500358581542969
Validation loss: 2.0665876557750087

Epoch: 5| Step: 8
Training loss: 1.3487459421157837
Validation loss: 2.045457463110647

Epoch: 5| Step: 9
Training loss: 2.0830178260803223
Validation loss: 2.1489505844731487

Epoch: 5| Step: 10
Training loss: 1.671980619430542
Validation loss: 2.168419732842394

Epoch: 300| Step: 0
Training loss: 1.7046163082122803
Validation loss: 2.0838669038588002

Epoch: 5| Step: 1
Training loss: 1.446771264076233
Validation loss: 2.0298816683471843

Epoch: 5| Step: 2
Training loss: 1.9456255435943604
Validation loss: 2.1057542549666537

Epoch: 5| Step: 3
Training loss: 1.278930425643921
Validation loss: 2.1224423480290238

Epoch: 5| Step: 4
Training loss: 2.253540515899658
Validation loss: 2.1173246227284914

Epoch: 5| Step: 5
Training loss: 2.3924448490142822
Validation loss: 2.0673987339901667

Epoch: 5| Step: 6
Training loss: 2.5006096363067627
Validation loss: 2.1138587587623188

Epoch: 5| Step: 7
Training loss: 1.8080390691757202
Validation loss: 2.05785463189566

Epoch: 5| Step: 8
Training loss: 2.0023560523986816
Validation loss: 2.1474054872348742

Epoch: 5| Step: 9
Training loss: 2.119878053665161
Validation loss: 2.1535188126307663

Epoch: 5| Step: 10
Training loss: 2.4653894901275635
Validation loss: 2.0017641975033666

Epoch: 301| Step: 0
Training loss: 1.5991899967193604
Validation loss: 2.0562587720091625

Epoch: 5| Step: 1
Training loss: 1.3137162923812866
Validation loss: 2.0521216289971465

Epoch: 5| Step: 2
Training loss: 1.7766304016113281
Validation loss: 2.2140158402022494

Epoch: 5| Step: 3
Training loss: 1.925342321395874
Validation loss: 2.1008538046190814

Epoch: 5| Step: 4
Training loss: 2.0389480590820312
Validation loss: 2.042216057418495

Epoch: 5| Step: 5
Training loss: 2.6471261978149414
Validation loss: 2.1134693032951763

Epoch: 5| Step: 6
Training loss: 1.8346357345581055
Validation loss: 2.176969425652617

Epoch: 5| Step: 7
Training loss: 1.379526972770691
Validation loss: 2.0102308898843746

Epoch: 5| Step: 8
Training loss: 2.8479504585266113
Validation loss: 2.063503392281071

Epoch: 5| Step: 9
Training loss: 2.156531572341919
Validation loss: 2.1939298183687272

Epoch: 5| Step: 10
Training loss: 1.987553358078003
Validation loss: 2.174618000625282

Epoch: 302| Step: 0
Training loss: 1.6995251178741455
Validation loss: 2.065117464270643

Epoch: 5| Step: 1
Training loss: 2.1715919971466064
Validation loss: 2.1522014499992452

Epoch: 5| Step: 2
Training loss: 2.052354097366333
Validation loss: 2.1019429775976364

Epoch: 5| Step: 3
Training loss: 2.1998260021209717
Validation loss: 1.9958613098308604

Epoch: 5| Step: 4
Training loss: 1.7507469654083252
Validation loss: 2.1317973252265685

Epoch: 5| Step: 5
Training loss: 1.4141595363616943
Validation loss: 2.137847092843825

Epoch: 5| Step: 6
Training loss: 1.8968054056167603
Validation loss: 2.147024528954619

Epoch: 5| Step: 7
Training loss: 2.4953486919403076
Validation loss: 2.129850882355885

Epoch: 5| Step: 8
Training loss: 2.331894874572754
Validation loss: 2.1720575260859665

Epoch: 5| Step: 9
Training loss: 1.8550751209259033
Validation loss: 2.2129418439762567

Epoch: 5| Step: 10
Training loss: 1.9014999866485596
Validation loss: 2.177754702106599

Epoch: 303| Step: 0
Training loss: 1.3522331714630127
Validation loss: 2.1151334701045865

Epoch: 5| Step: 1
Training loss: 1.8876301050186157
Validation loss: 2.105881162869033

Epoch: 5| Step: 2
Training loss: 2.1424334049224854
Validation loss: 2.079965965722197

Epoch: 5| Step: 3
Training loss: 2.9349284172058105
Validation loss: 2.029315492158295

Epoch: 5| Step: 4
Training loss: 1.342054009437561
Validation loss: 2.0663990923153457

Epoch: 5| Step: 5
Training loss: 1.9506009817123413
Validation loss: 2.091503063837687

Epoch: 5| Step: 6
Training loss: 1.7564067840576172
Validation loss: 2.110528960022875

Epoch: 5| Step: 7
Training loss: 2.0579752922058105
Validation loss: 2.094268916755594

Epoch: 5| Step: 8
Training loss: 1.7964214086532593
Validation loss: 1.995952586973867

Epoch: 5| Step: 9
Training loss: 2.1367099285125732
Validation loss: 2.059176973117295

Epoch: 5| Step: 10
Training loss: 2.0265157222747803
Validation loss: 2.0235503617153374

Epoch: 304| Step: 0
Training loss: 2.113116502761841
Validation loss: 2.1129822820745487

Epoch: 5| Step: 1
Training loss: 1.4306058883666992
Validation loss: 2.1164564265999743

Epoch: 5| Step: 2
Training loss: 1.9686920642852783
Validation loss: 2.16220348881137

Epoch: 5| Step: 3
Training loss: 1.685681939125061
Validation loss: 2.135117248822284

Epoch: 5| Step: 4
Training loss: 1.6257922649383545
Validation loss: 2.009961925527101

Epoch: 5| Step: 5
Training loss: 2.3803906440734863
Validation loss: 2.0906316670038367

Epoch: 5| Step: 6
Training loss: 1.8281081914901733
Validation loss: 2.0721195013292375

Epoch: 5| Step: 7
Training loss: 2.5629844665527344
Validation loss: 2.0934207593241045

Epoch: 5| Step: 8
Training loss: 2.3388023376464844
Validation loss: 2.0255541596361386

Epoch: 5| Step: 9
Training loss: 2.1455252170562744
Validation loss: 2.064811001541794

Epoch: 5| Step: 10
Training loss: 1.8728898763656616
Validation loss: 2.157488376863541

Epoch: 305| Step: 0
Training loss: 1.9298721551895142
Validation loss: 2.09086020787557

Epoch: 5| Step: 1
Training loss: 1.9094213247299194
Validation loss: 2.1585346703888266

Epoch: 5| Step: 2
Training loss: 1.604265570640564
Validation loss: 2.1035639803896666

Epoch: 5| Step: 3
Training loss: 2.488513946533203
Validation loss: 2.2133494115644887

Epoch: 5| Step: 4
Training loss: 1.936918020248413
Validation loss: 2.14024882419135

Epoch: 5| Step: 5
Training loss: 1.7330474853515625
Validation loss: 2.1700892576607327

Epoch: 5| Step: 6
Training loss: 1.738620400428772
Validation loss: 2.0786353420185786

Epoch: 5| Step: 7
Training loss: 2.129821300506592
Validation loss: 2.1311307901977212

Epoch: 5| Step: 8
Training loss: 1.3073209524154663
Validation loss: 2.079142855059716

Epoch: 5| Step: 9
Training loss: 1.5585527420043945
Validation loss: 2.1825243939635572

Epoch: 5| Step: 10
Training loss: 2.5691170692443848
Validation loss: 2.1543166355420182

Epoch: 306| Step: 0
Training loss: 2.048366069793701
Validation loss: 2.156093179538686

Epoch: 5| Step: 1
Training loss: 1.9497203826904297
Validation loss: 2.1452026110823437

Epoch: 5| Step: 2
Training loss: 1.7587330341339111
Validation loss: 2.110829617387505

Epoch: 5| Step: 3
Training loss: 2.6863741874694824
Validation loss: 2.010892847532867

Epoch: 5| Step: 4
Training loss: 1.9031299352645874
Validation loss: 2.1081209131466445

Epoch: 5| Step: 5
Training loss: 2.3361799716949463
Validation loss: 2.123683580788233

Epoch: 5| Step: 6
Training loss: 2.1248955726623535
Validation loss: 2.0385677378664733

Epoch: 5| Step: 7
Training loss: 1.3854976892471313
Validation loss: 2.025126054722776

Epoch: 5| Step: 8
Training loss: 2.116326332092285
Validation loss: 2.098518176745343

Epoch: 5| Step: 9
Training loss: 1.8817440271377563
Validation loss: 2.1665388845628306

Epoch: 5| Step: 10
Training loss: 1.5709590911865234
Validation loss: 2.054949334872666

Epoch: 307| Step: 0
Training loss: 2.314134359359741
Validation loss: 2.098805086587065

Epoch: 5| Step: 1
Training loss: 1.7154724597930908
Validation loss: 2.10209164568173

Epoch: 5| Step: 2
Training loss: 2.3795523643493652
Validation loss: 2.1325419051672823

Epoch: 5| Step: 3
Training loss: 2.277026653289795
Validation loss: 2.0729071581235496

Epoch: 5| Step: 4
Training loss: 2.146353244781494
Validation loss: 2.0873755767781246

Epoch: 5| Step: 5
Training loss: 2.7514543533325195
Validation loss: 2.054867567554597

Epoch: 5| Step: 6
Training loss: 1.3376057147979736
Validation loss: 1.964744601198422

Epoch: 5| Step: 7
Training loss: 0.8501458168029785
Validation loss: 2.0908329691938174

Epoch: 5| Step: 8
Training loss: 1.951798439025879
Validation loss: 2.077660393971269

Epoch: 5| Step: 9
Training loss: 2.1426472663879395
Validation loss: 2.0017393173709994

Epoch: 5| Step: 10
Training loss: 1.3939846754074097
Validation loss: 2.1315913738742953

Epoch: 308| Step: 0
Training loss: 3.146174669265747
Validation loss: 2.0808241290430867

Epoch: 5| Step: 1
Training loss: 1.5219839811325073
Validation loss: 2.069359875494434

Epoch: 5| Step: 2
Training loss: 1.2868335247039795
Validation loss: 2.0399740998462965

Epoch: 5| Step: 3
Training loss: 1.9121205806732178
Validation loss: 2.1200348382355063

Epoch: 5| Step: 4
Training loss: 1.736975073814392
Validation loss: 2.068170278303085

Epoch: 5| Step: 5
Training loss: 1.358013391494751
Validation loss: 2.050324260547597

Epoch: 5| Step: 6
Training loss: 2.0788471698760986
Validation loss: 2.101559172394455

Epoch: 5| Step: 7
Training loss: 1.8866729736328125
Validation loss: 2.130142101677515

Epoch: 5| Step: 8
Training loss: 1.7760915756225586
Validation loss: 2.02622244563154

Epoch: 5| Step: 9
Training loss: 2.0685863494873047
Validation loss: 2.044108321589808

Epoch: 5| Step: 10
Training loss: 2.371082067489624
Validation loss: 2.0751214796496975

Epoch: 309| Step: 0
Training loss: 1.9998109340667725
Validation loss: 2.08429451398952

Epoch: 5| Step: 1
Training loss: 2.236069917678833
Validation loss: 2.1299746228802587

Epoch: 5| Step: 2
Training loss: 1.6428295373916626
Validation loss: 2.1096083323160806

Epoch: 5| Step: 3
Training loss: 1.909480333328247
Validation loss: 2.147071639696757

Epoch: 5| Step: 4
Training loss: 2.065460205078125
Validation loss: 2.063438125835952

Epoch: 5| Step: 5
Training loss: 1.2731359004974365
Validation loss: 2.0903773564164356

Epoch: 5| Step: 6
Training loss: 1.705949068069458
Validation loss: 2.101445885114772

Epoch: 5| Step: 7
Training loss: 2.245612144470215
Validation loss: 2.062888462056396

Epoch: 5| Step: 8
Training loss: 1.7762367725372314
Validation loss: 2.0645665353344334

Epoch: 5| Step: 9
Training loss: 2.4223241806030273
Validation loss: 2.13253475645537

Epoch: 5| Step: 10
Training loss: 1.9296300411224365
Validation loss: 2.112337335463493

Epoch: 310| Step: 0
Training loss: 1.534558892250061
Validation loss: 2.1065012562659478

Epoch: 5| Step: 1
Training loss: 2.142864465713501
Validation loss: 2.1644726876289613

Epoch: 5| Step: 2
Training loss: 1.3561416864395142
Validation loss: 2.1603010828777025

Epoch: 5| Step: 3
Training loss: 2.049668073654175
Validation loss: 2.013092440943564

Epoch: 5| Step: 4
Training loss: 2.0201029777526855
Validation loss: 2.12407692786186

Epoch: 5| Step: 5
Training loss: 2.0119452476501465
Validation loss: 2.1902862812883113

Epoch: 5| Step: 6
Training loss: 1.7785663604736328
Validation loss: 2.07037777029058

Epoch: 5| Step: 7
Training loss: 2.1727404594421387
Validation loss: 2.152915854607859

Epoch: 5| Step: 8
Training loss: 1.9400622844696045
Validation loss: 2.1029752941541773

Epoch: 5| Step: 9
Training loss: 2.068169116973877
Validation loss: 2.1725191506006385

Epoch: 5| Step: 10
Training loss: 2.446390151977539
Validation loss: 2.108086247597971

Epoch: 311| Step: 0
Training loss: 1.7255523204803467
Validation loss: 2.0729003311485372

Epoch: 5| Step: 1
Training loss: 1.9720258712768555
Validation loss: 2.1127812144576863

Epoch: 5| Step: 2
Training loss: 2.5809404850006104
Validation loss: 2.028374514272136

Epoch: 5| Step: 3
Training loss: 2.3154096603393555
Validation loss: 2.041934855522648

Epoch: 5| Step: 4
Training loss: 1.9055668115615845
Validation loss: 2.1224889550157773

Epoch: 5| Step: 5
Training loss: 1.6134306192398071
Validation loss: 2.0145620787015526

Epoch: 5| Step: 6
Training loss: 2.068598508834839
Validation loss: 2.0891645108499834

Epoch: 5| Step: 7
Training loss: 1.4802188873291016
Validation loss: 2.0479348756933726

Epoch: 5| Step: 8
Training loss: 1.8557430505752563
Validation loss: 2.0846977503068986

Epoch: 5| Step: 9
Training loss: 1.8698021173477173
Validation loss: 2.1364316171215427

Epoch: 5| Step: 10
Training loss: 2.0387446880340576
Validation loss: 2.0238760184216242

Epoch: 312| Step: 0
Training loss: 1.9920291900634766
Validation loss: 2.0722079917948735

Epoch: 5| Step: 1
Training loss: 1.692152738571167
Validation loss: 1.9785519774242113

Epoch: 5| Step: 2
Training loss: 2.1075289249420166
Validation loss: 2.0857575965184036

Epoch: 5| Step: 3
Training loss: 1.9333744049072266
Validation loss: 2.1191516512183735

Epoch: 5| Step: 4
Training loss: 1.8559095859527588
Validation loss: 2.0775173658965738

Epoch: 5| Step: 5
Training loss: 1.5080177783966064
Validation loss: 2.0783671768762733

Epoch: 5| Step: 6
Training loss: 2.3041224479675293
Validation loss: 2.0586622389413978

Epoch: 5| Step: 7
Training loss: 1.573312520980835
Validation loss: 2.113398833941388

Epoch: 5| Step: 8
Training loss: 2.2273755073547363
Validation loss: 2.0955702412512993

Epoch: 5| Step: 9
Training loss: 1.9786818027496338
Validation loss: 2.172294642335625

Epoch: 5| Step: 10
Training loss: 2.1131229400634766
Validation loss: 2.0264369415980514

Epoch: 313| Step: 0
Training loss: 2.023355007171631
Validation loss: 2.1379349411174817

Epoch: 5| Step: 1
Training loss: 2.1151230335235596
Validation loss: 2.1123145177800167

Epoch: 5| Step: 2
Training loss: 2.022630453109741
Validation loss: 2.1529086559049544

Epoch: 5| Step: 3
Training loss: 1.5095874071121216
Validation loss: 2.0363522960293676

Epoch: 5| Step: 4
Training loss: 1.9090003967285156
Validation loss: 2.1604284817172634

Epoch: 5| Step: 5
Training loss: 1.7449451684951782
Validation loss: 2.173414300846797

Epoch: 5| Step: 6
Training loss: 2.2362570762634277
Validation loss: 2.125078062857351

Epoch: 5| Step: 7
Training loss: 2.3625566959381104
Validation loss: 2.075714113891766

Epoch: 5| Step: 8
Training loss: 2.192784070968628
Validation loss: 2.2600052484902005

Epoch: 5| Step: 9
Training loss: 1.270117998123169
Validation loss: 2.0208852765380696

Epoch: 5| Step: 10
Training loss: 1.972845196723938
Validation loss: 2.218884632151614

Epoch: 314| Step: 0
Training loss: 1.652178406715393
Validation loss: 2.1388987238689134

Epoch: 5| Step: 1
Training loss: 1.6666374206542969
Validation loss: 2.062950000968031

Epoch: 5| Step: 2
Training loss: 1.854088544845581
Validation loss: 2.057080453441989

Epoch: 5| Step: 3
Training loss: 2.719696283340454
Validation loss: 2.051848121868667

Epoch: 5| Step: 4
Training loss: 1.273175835609436
Validation loss: 2.153442354612453

Epoch: 5| Step: 5
Training loss: 2.030728340148926
Validation loss: 2.1309179952067714

Epoch: 5| Step: 6
Training loss: 2.458972215652466
Validation loss: 2.1334285223355858

Epoch: 5| Step: 7
Training loss: 1.9883630275726318
Validation loss: 2.041119994655732

Epoch: 5| Step: 8
Training loss: 2.024610996246338
Validation loss: 2.0910488020989204

Epoch: 5| Step: 9
Training loss: 1.843697190284729
Validation loss: 2.1183861468427923

Epoch: 5| Step: 10
Training loss: 1.714913249015808
Validation loss: 2.077320309095485

Epoch: 315| Step: 0
Training loss: 1.648929238319397
Validation loss: 2.082501467838082

Epoch: 5| Step: 1
Training loss: 1.782006025314331
Validation loss: 2.116458585185389

Epoch: 5| Step: 2
Training loss: 1.2968534231185913
Validation loss: 2.181223689868886

Epoch: 5| Step: 3
Training loss: 2.0991051197052
Validation loss: 2.1112728477806173

Epoch: 5| Step: 4
Training loss: 1.7732326984405518
Validation loss: 2.2019550979778333

Epoch: 5| Step: 5
Training loss: 2.007120132446289
Validation loss: 2.1193278143482823

Epoch: 5| Step: 6
Training loss: 1.8296153545379639
Validation loss: 2.1999261635606007

Epoch: 5| Step: 7
Training loss: 2.340327262878418
Validation loss: 2.1562930178898636

Epoch: 5| Step: 8
Training loss: 2.149000644683838
Validation loss: 2.2758288896212013

Epoch: 5| Step: 9
Training loss: 2.114159345626831
Validation loss: 2.1764381765037455

Epoch: 5| Step: 10
Training loss: 2.489652395248413
Validation loss: 2.2866585946852163

Epoch: 316| Step: 0
Training loss: 1.7888187170028687
Validation loss: 2.1741412711399857

Epoch: 5| Step: 1
Training loss: 1.8783127069473267
Validation loss: 2.187794105980986

Epoch: 5| Step: 2
Training loss: 1.8141224384307861
Validation loss: 2.1434075601639284

Epoch: 5| Step: 3
Training loss: 2.6253974437713623
Validation loss: 2.06653921322156

Epoch: 5| Step: 4
Training loss: 1.9667766094207764
Validation loss: 2.1072906165994625

Epoch: 5| Step: 5
Training loss: 1.609191656112671
Validation loss: 2.160871990265385

Epoch: 5| Step: 6
Training loss: 1.9219051599502563
Validation loss: 2.1140499807173208

Epoch: 5| Step: 7
Training loss: 2.2694008350372314
Validation loss: 2.1432620145941295

Epoch: 5| Step: 8
Training loss: 1.9950854778289795
Validation loss: 2.0887479474467616

Epoch: 5| Step: 9
Training loss: 2.2957682609558105
Validation loss: 2.028456372599448

Epoch: 5| Step: 10
Training loss: 1.6651952266693115
Validation loss: 2.144921015667659

Epoch: 317| Step: 0
Training loss: 1.6920980215072632
Validation loss: 2.1472390108211066

Epoch: 5| Step: 1
Training loss: 2.274674892425537
Validation loss: 2.0928583491233086

Epoch: 5| Step: 2
Training loss: 2.261732816696167
Validation loss: 2.047135260797316

Epoch: 5| Step: 3
Training loss: 1.943113088607788
Validation loss: 2.102736980684342

Epoch: 5| Step: 4
Training loss: 1.794950246810913
Validation loss: 2.169936172423824

Epoch: 5| Step: 5
Training loss: 1.4996917247772217
Validation loss: 2.058373874233615

Epoch: 5| Step: 6
Training loss: 1.7255933284759521
Validation loss: 2.1450824442730156

Epoch: 5| Step: 7
Training loss: 1.7670323848724365
Validation loss: 2.157756579819546

Epoch: 5| Step: 8
Training loss: 2.1736176013946533
Validation loss: 2.1406616754429315

Epoch: 5| Step: 9
Training loss: 1.7799571752548218
Validation loss: 2.154543512610979

Epoch: 5| Step: 10
Training loss: 1.859984040260315
Validation loss: 2.167402216183242

Epoch: 318| Step: 0
Training loss: 1.5127031803131104
Validation loss: 2.063396833276236

Epoch: 5| Step: 1
Training loss: 1.8255176544189453
Validation loss: 2.047077149473211

Epoch: 5| Step: 2
Training loss: 1.4436750411987305
Validation loss: 2.097858844264861

Epoch: 5| Step: 3
Training loss: 1.5070394277572632
Validation loss: 2.126683473587036

Epoch: 5| Step: 4
Training loss: 2.1274166107177734
Validation loss: 2.121754912919896

Epoch: 5| Step: 5
Training loss: 1.8280105590820312
Validation loss: 2.140976316185408

Epoch: 5| Step: 6
Training loss: 1.758156180381775
Validation loss: 2.06022830676007

Epoch: 5| Step: 7
Training loss: 1.9659160375595093
Validation loss: 2.119490317119065

Epoch: 5| Step: 8
Training loss: 2.2770543098449707
Validation loss: 2.082337619155966

Epoch: 5| Step: 9
Training loss: 2.299879550933838
Validation loss: 2.0956926422734417

Epoch: 5| Step: 10
Training loss: 2.2813806533813477
Validation loss: 2.1199787162965342

Epoch: 319| Step: 0
Training loss: 2.0482585430145264
Validation loss: 2.061516320833596

Epoch: 5| Step: 1
Training loss: 1.4755384922027588
Validation loss: 2.1190273223384732

Epoch: 5| Step: 2
Training loss: 1.702692985534668
Validation loss: 2.0677596548552155

Epoch: 5| Step: 3
Training loss: 1.6012178659439087
Validation loss: 2.128536585838564

Epoch: 5| Step: 4
Training loss: 2.4612300395965576
Validation loss: 2.1177460762762252

Epoch: 5| Step: 5
Training loss: 2.0677883625030518
Validation loss: 2.134148674626504

Epoch: 5| Step: 6
Training loss: 1.7382686138153076
Validation loss: 2.063861277795607

Epoch: 5| Step: 7
Training loss: 2.0333995819091797
Validation loss: 1.9818783754943519

Epoch: 5| Step: 8
Training loss: 1.8056151866912842
Validation loss: 2.0666008354515157

Epoch: 5| Step: 9
Training loss: 2.087844133377075
Validation loss: 2.1069195219265517

Epoch: 5| Step: 10
Training loss: 2.177031993865967
Validation loss: 2.119636792008595

Epoch: 320| Step: 0
Training loss: 1.8744866847991943
Validation loss: 2.024607014912431

Epoch: 5| Step: 1
Training loss: 1.8397483825683594
Validation loss: 2.153689113996362

Epoch: 5| Step: 2
Training loss: 2.3330678939819336
Validation loss: 2.1281018385323147

Epoch: 5| Step: 3
Training loss: 1.9322811365127563
Validation loss: 2.1050411603784047

Epoch: 5| Step: 4
Training loss: 1.6892249584197998
Validation loss: 2.0250852902730307

Epoch: 5| Step: 5
Training loss: 1.8369922637939453
Validation loss: 1.9947563371350687

Epoch: 5| Step: 6
Training loss: 1.834393858909607
Validation loss: 2.077157599951631

Epoch: 5| Step: 7
Training loss: 2.1011078357696533
Validation loss: 2.0553516085429857

Epoch: 5| Step: 8
Training loss: 1.7279107570648193
Validation loss: 2.1205204327901206

Epoch: 5| Step: 9
Training loss: 1.3528263568878174
Validation loss: 2.0095838603153022

Epoch: 5| Step: 10
Training loss: 2.223799705505371
Validation loss: 2.1665775827182236

Epoch: 321| Step: 0
Training loss: 1.9949522018432617
Validation loss: 2.0927029732734925

Epoch: 5| Step: 1
Training loss: 1.8860336542129517
Validation loss: 2.0909870055414017

Epoch: 5| Step: 2
Training loss: 2.0957884788513184
Validation loss: 2.0699562231699624

Epoch: 5| Step: 3
Training loss: 1.719072699546814
Validation loss: 2.1900484741375013

Epoch: 5| Step: 4
Training loss: 1.9575309753417969
Validation loss: 2.2152588316189346

Epoch: 5| Step: 5
Training loss: 1.6668363809585571
Validation loss: 2.0534238328215895

Epoch: 5| Step: 6
Training loss: 1.4551212787628174
Validation loss: 2.141529652380174

Epoch: 5| Step: 7
Training loss: 2.3795998096466064
Validation loss: 2.0755910463230585

Epoch: 5| Step: 8
Training loss: 1.841202974319458
Validation loss: 2.0401240061688166

Epoch: 5| Step: 9
Training loss: 1.7216209173202515
Validation loss: 2.0806608533346527

Epoch: 5| Step: 10
Training loss: 2.2354724407196045
Validation loss: 2.0149855690617717

Epoch: 322| Step: 0
Training loss: 2.2267351150512695
Validation loss: 2.1532326718812347

Epoch: 5| Step: 1
Training loss: 2.1739883422851562
Validation loss: 2.1116719399729083

Epoch: 5| Step: 2
Training loss: 1.9497168064117432
Validation loss: 2.0901517432223082

Epoch: 5| Step: 3
Training loss: 1.4137108325958252
Validation loss: 2.1020146223806564

Epoch: 5| Step: 4
Training loss: 1.814382791519165
Validation loss: 2.1076125226994997

Epoch: 5| Step: 5
Training loss: 1.6804109811782837
Validation loss: 2.0108382855692217

Epoch: 5| Step: 6
Training loss: 1.254249095916748
Validation loss: 2.082401067979874

Epoch: 5| Step: 7
Training loss: 1.9818300008773804
Validation loss: 2.1269338002768894

Epoch: 5| Step: 8
Training loss: 2.4938154220581055
Validation loss: 2.156120582293439

Epoch: 5| Step: 9
Training loss: 2.346404552459717
Validation loss: 2.0710801475791523

Epoch: 5| Step: 10
Training loss: 1.932188630104065
Validation loss: 2.052512485493896

Epoch: 323| Step: 0
Training loss: 2.70829176902771
Validation loss: 2.0845907221558275

Epoch: 5| Step: 1
Training loss: 1.162458896636963
Validation loss: 2.053395694301974

Epoch: 5| Step: 2
Training loss: 2.1606295108795166
Validation loss: 1.9654416422690115

Epoch: 5| Step: 3
Training loss: 1.381369948387146
Validation loss: 2.1313527168766147

Epoch: 5| Step: 4
Training loss: 1.7867475748062134
Validation loss: 2.081728103340313

Epoch: 5| Step: 5
Training loss: 1.4015802145004272
Validation loss: 2.1113761355800014

Epoch: 5| Step: 6
Training loss: 1.7437824010849
Validation loss: 2.188141084486438

Epoch: 5| Step: 7
Training loss: 2.6291279792785645
Validation loss: 2.0326823393503823

Epoch: 5| Step: 8
Training loss: 2.3142318725585938
Validation loss: 2.0923494446662163

Epoch: 5| Step: 9
Training loss: 1.8339166641235352
Validation loss: 2.157169608659642

Epoch: 5| Step: 10
Training loss: 2.023731231689453
Validation loss: 2.1350915175612255

Epoch: 324| Step: 0
Training loss: 1.8528385162353516
Validation loss: 2.063108436522945

Epoch: 5| Step: 1
Training loss: 2.1961007118225098
Validation loss: 1.9600551230933076

Epoch: 5| Step: 2
Training loss: 1.7894243001937866
Validation loss: 2.151364186758636

Epoch: 5| Step: 3
Training loss: 2.1973774433135986
Validation loss: 2.129082022174712

Epoch: 5| Step: 4
Training loss: 1.5853245258331299
Validation loss: 2.0487988597603253

Epoch: 5| Step: 5
Training loss: 2.014371395111084
Validation loss: 2.0904376455532607

Epoch: 5| Step: 6
Training loss: 1.9416115283966064
Validation loss: 2.0200503897923294

Epoch: 5| Step: 7
Training loss: 1.4939247369766235
Validation loss: 2.014951782841836

Epoch: 5| Step: 8
Training loss: 1.9432045221328735
Validation loss: 2.1168876514639905

Epoch: 5| Step: 9
Training loss: 1.7170801162719727
Validation loss: 2.075246000802645

Epoch: 5| Step: 10
Training loss: 2.1701552867889404
Validation loss: 2.0078957491023566

Epoch: 325| Step: 0
Training loss: 1.652793526649475
Validation loss: 2.0828957326950563

Epoch: 5| Step: 1
Training loss: 1.7966127395629883
Validation loss: 2.1007771222822127

Epoch: 5| Step: 2
Training loss: 1.9235217571258545
Validation loss: 2.137837697100896

Epoch: 5| Step: 3
Training loss: 2.1853108406066895
Validation loss: 2.0350007523772535

Epoch: 5| Step: 4
Training loss: 1.9443442821502686
Validation loss: 2.1637101352855725

Epoch: 5| Step: 5
Training loss: 1.4819068908691406
Validation loss: 2.135498995422035

Epoch: 5| Step: 6
Training loss: 2.106313705444336
Validation loss: 2.125693528882919

Epoch: 5| Step: 7
Training loss: 2.791727066040039
Validation loss: 2.126791956604168

Epoch: 5| Step: 8
Training loss: 1.8614721298217773
Validation loss: 2.0690319538116455

Epoch: 5| Step: 9
Training loss: 1.7006981372833252
Validation loss: 2.07367229846216

Epoch: 5| Step: 10
Training loss: 1.8836725950241089
Validation loss: 2.0349829299475557

Epoch: 326| Step: 0
Training loss: 2.2432141304016113
Validation loss: 2.0834207996245353

Epoch: 5| Step: 1
Training loss: 1.5044753551483154
Validation loss: 2.087309580977245

Epoch: 5| Step: 2
Training loss: 1.6579478979110718
Validation loss: 2.068906121356513

Epoch: 5| Step: 3
Training loss: 2.0064055919647217
Validation loss: 2.1473712011050154

Epoch: 5| Step: 4
Training loss: 1.35356867313385
Validation loss: 2.089995294488886

Epoch: 5| Step: 5
Training loss: 2.373901844024658
Validation loss: 2.1022292106382308

Epoch: 5| Step: 6
Training loss: 2.1587226390838623
Validation loss: 2.1230997244517007

Epoch: 5| Step: 7
Training loss: 2.3889079093933105
Validation loss: 2.1366188731244815

Epoch: 5| Step: 8
Training loss: 2.274669647216797
Validation loss: 2.135960581482098

Epoch: 5| Step: 9
Training loss: 1.6029717922210693
Validation loss: 2.085959621655044

Epoch: 5| Step: 10
Training loss: 1.9960848093032837
Validation loss: 2.1815567708784536

Epoch: 327| Step: 0
Training loss: 1.80129075050354
Validation loss: 2.109752126919326

Epoch: 5| Step: 1
Training loss: 2.1311001777648926
Validation loss: 2.056610494531611

Epoch: 5| Step: 2
Training loss: 1.9757537841796875
Validation loss: 2.103022954797232

Epoch: 5| Step: 3
Training loss: 2.0367956161499023
Validation loss: 2.0534686785872265

Epoch: 5| Step: 4
Training loss: 2.041515350341797
Validation loss: 2.0981903319717734

Epoch: 5| Step: 5
Training loss: 1.9879226684570312
Validation loss: 2.03424213522224

Epoch: 5| Step: 6
Training loss: 1.670190453529358
Validation loss: 2.0541880233313448

Epoch: 5| Step: 7
Training loss: 2.2211813926696777
Validation loss: 2.029099475952887

Epoch: 5| Step: 8
Training loss: 2.2776858806610107
Validation loss: 2.0622167061733943

Epoch: 5| Step: 9
Training loss: 1.5323625802993774
Validation loss: 2.1000367082575315

Epoch: 5| Step: 10
Training loss: 1.8454413414001465
Validation loss: 2.048548585625105

Epoch: 328| Step: 0
Training loss: 1.5899680852890015
Validation loss: 2.0275564116816365

Epoch: 5| Step: 1
Training loss: 1.7422679662704468
Validation loss: 2.0882321993509927

Epoch: 5| Step: 2
Training loss: 1.6151094436645508
Validation loss: 2.1066450688146774

Epoch: 5| Step: 3
Training loss: 2.273076295852661
Validation loss: 2.0883442971014206

Epoch: 5| Step: 4
Training loss: 1.7634201049804688
Validation loss: 2.075793425242106

Epoch: 5| Step: 5
Training loss: 1.9127495288848877
Validation loss: 2.094954293261292

Epoch: 5| Step: 6
Training loss: 2.1998281478881836
Validation loss: 2.1291745644743725

Epoch: 5| Step: 7
Training loss: 2.2176215648651123
Validation loss: 2.0731509680389077

Epoch: 5| Step: 8
Training loss: 2.336188793182373
Validation loss: 2.0426931445316603

Epoch: 5| Step: 9
Training loss: 2.0369133949279785
Validation loss: 2.046438099235617

Epoch: 5| Step: 10
Training loss: 1.6277745962142944
Validation loss: 2.1092578288047545

Epoch: 329| Step: 0
Training loss: 1.0974009037017822
Validation loss: 2.106358979337959

Epoch: 5| Step: 1
Training loss: 2.1589465141296387
Validation loss: 2.106419760693786

Epoch: 5| Step: 2
Training loss: 2.0602784156799316
Validation loss: 2.133667307515298

Epoch: 5| Step: 3
Training loss: 1.9543310403823853
Validation loss: 2.119959949165262

Epoch: 5| Step: 4
Training loss: 1.5946840047836304
Validation loss: 2.038013933807291

Epoch: 5| Step: 5
Training loss: 1.4725520610809326
Validation loss: 2.1409020039343063

Epoch: 5| Step: 6
Training loss: 2.1069135665893555
Validation loss: 2.063932239368398

Epoch: 5| Step: 7
Training loss: 1.8003342151641846
Validation loss: 2.0173862518802768

Epoch: 5| Step: 8
Training loss: 1.7189327478408813
Validation loss: 2.1345361253266693

Epoch: 5| Step: 9
Training loss: 1.7090625762939453
Validation loss: 2.120570425064333

Epoch: 5| Step: 10
Training loss: 2.697439670562744
Validation loss: 2.0714502360231135

Epoch: 330| Step: 0
Training loss: 1.7637929916381836
Validation loss: 2.1169899073980187

Epoch: 5| Step: 1
Training loss: 1.893428087234497
Validation loss: 2.0306524025496615

Epoch: 5| Step: 2
Training loss: 2.0344176292419434
Validation loss: 2.1236413755724506

Epoch: 5| Step: 3
Training loss: 1.7701520919799805
Validation loss: 2.086851022576773

Epoch: 5| Step: 4
Training loss: 1.7710106372833252
Validation loss: 2.10891939363172

Epoch: 5| Step: 5
Training loss: 1.9429467916488647
Validation loss: 2.0629085212625484

Epoch: 5| Step: 6
Training loss: 1.961381196975708
Validation loss: 2.182487286547179

Epoch: 5| Step: 7
Training loss: 2.037086009979248
Validation loss: 2.127204356654998

Epoch: 5| Step: 8
Training loss: 1.907764196395874
Validation loss: 2.137087948860661

Epoch: 5| Step: 9
Training loss: 2.1062114238739014
Validation loss: 2.1378513971964517

Epoch: 5| Step: 10
Training loss: 2.2020089626312256
Validation loss: 2.0848497088237474

Epoch: 331| Step: 0
Training loss: 1.635729432106018
Validation loss: 2.0564226565822477

Epoch: 5| Step: 1
Training loss: 2.150993824005127
Validation loss: 2.063115614716725

Epoch: 5| Step: 2
Training loss: 1.7968616485595703
Validation loss: 2.199609641105898

Epoch: 5| Step: 3
Training loss: 1.4578922986984253
Validation loss: 2.0908608128947597

Epoch: 5| Step: 4
Training loss: 1.196361780166626
Validation loss: 2.1103408259730183

Epoch: 5| Step: 5
Training loss: 1.9248355627059937
Validation loss: 2.0870912305770384

Epoch: 5| Step: 6
Training loss: 2.373448133468628
Validation loss: 2.0900409324194795

Epoch: 5| Step: 7
Training loss: 2.233557939529419
Validation loss: 2.086438645598709

Epoch: 5| Step: 8
Training loss: 1.6963227987289429
Validation loss: 2.132231044512923

Epoch: 5| Step: 9
Training loss: 2.1344006061553955
Validation loss: 2.1034590531420965

Epoch: 5| Step: 10
Training loss: 2.185622215270996
Validation loss: 2.0571373803641206

Epoch: 332| Step: 0
Training loss: 1.2174218893051147
Validation loss: 2.014766343178288

Epoch: 5| Step: 1
Training loss: 1.7691802978515625
Validation loss: 2.110707588093255

Epoch: 5| Step: 2
Training loss: 2.192810535430908
Validation loss: 2.0089046391107703

Epoch: 5| Step: 3
Training loss: 1.8939990997314453
Validation loss: 2.083609345138714

Epoch: 5| Step: 4
Training loss: 1.9325767755508423
Validation loss: 2.1505340786390406

Epoch: 5| Step: 5
Training loss: 1.7174100875854492
Validation loss: 2.1644572673305387

Epoch: 5| Step: 6
Training loss: 1.8253586292266846
Validation loss: 2.0366625503827165

Epoch: 5| Step: 7
Training loss: 2.293531656265259
Validation loss: 2.113918319825203

Epoch: 5| Step: 8
Training loss: 2.1507105827331543
Validation loss: 2.1351819243482364

Epoch: 5| Step: 9
Training loss: 1.6886451244354248
Validation loss: 2.145870416395126

Epoch: 5| Step: 10
Training loss: 2.306459426879883
Validation loss: 2.1091802299663587

Epoch: 333| Step: 0
Training loss: 2.081714153289795
Validation loss: 2.104447798062396

Epoch: 5| Step: 1
Training loss: 2.2932331562042236
Validation loss: 2.1506276284494708

Epoch: 5| Step: 2
Training loss: 1.1156697273254395
Validation loss: 2.1218580968918337

Epoch: 5| Step: 3
Training loss: 1.6020128726959229
Validation loss: 2.131324935984868

Epoch: 5| Step: 4
Training loss: 2.0202205181121826
Validation loss: 2.002661992144841

Epoch: 5| Step: 5
Training loss: 1.6807514429092407
Validation loss: 2.167934861234439

Epoch: 5| Step: 6
Training loss: 2.158857583999634
Validation loss: 2.176686579181302

Epoch: 5| Step: 7
Training loss: 2.042276620864868
Validation loss: 2.165376219698178

Epoch: 5| Step: 8
Training loss: 1.5874744653701782
Validation loss: 2.0899975825381536

Epoch: 5| Step: 9
Training loss: 2.0918869972229004
Validation loss: 2.174252635689192

Epoch: 5| Step: 10
Training loss: 2.221609115600586
Validation loss: 2.139566518927133

Epoch: 334| Step: 0
Training loss: 1.532973289489746
Validation loss: 2.149039101857011

Epoch: 5| Step: 1
Training loss: 1.4212223291397095
Validation loss: 2.147009734184511

Epoch: 5| Step: 2
Training loss: 2.137328624725342
Validation loss: 2.0802822984674925

Epoch: 5| Step: 3
Training loss: 2.3251991271972656
Validation loss: 2.1157006332951207

Epoch: 5| Step: 4
Training loss: 2.134615898132324
Validation loss: 2.0767231654095393

Epoch: 5| Step: 5
Training loss: 1.7720304727554321
Validation loss: 2.084781862074329

Epoch: 5| Step: 6
Training loss: 2.569852113723755
Validation loss: 2.1339066323413642

Epoch: 5| Step: 7
Training loss: 1.6294358968734741
Validation loss: 2.093465030834239

Epoch: 5| Step: 8
Training loss: 2.368040084838867
Validation loss: 2.125550716154037

Epoch: 5| Step: 9
Training loss: 1.6502211093902588
Validation loss: 2.112149808996467

Epoch: 5| Step: 10
Training loss: 1.5281206369400024
Validation loss: 2.008847944198116

Epoch: 335| Step: 0
Training loss: 2.154243230819702
Validation loss: 2.042504555435591

Epoch: 5| Step: 1
Training loss: 1.9190394878387451
Validation loss: 2.1345179875691733

Epoch: 5| Step: 2
Training loss: 1.7213287353515625
Validation loss: 2.036296083081153

Epoch: 5| Step: 3
Training loss: 1.8251197338104248
Validation loss: 2.0069597562154136

Epoch: 5| Step: 4
Training loss: 1.7785961627960205
Validation loss: 2.0074214704575075

Epoch: 5| Step: 5
Training loss: 1.9933254718780518
Validation loss: 2.072716828315489

Epoch: 5| Step: 6
Training loss: 2.5476672649383545
Validation loss: 2.1082752673856673

Epoch: 5| Step: 7
Training loss: 1.4241738319396973
Validation loss: 2.0865807725537207

Epoch: 5| Step: 8
Training loss: 2.0159642696380615
Validation loss: 2.1405160709093978

Epoch: 5| Step: 9
Training loss: 1.850524663925171
Validation loss: 2.096026095010901

Epoch: 5| Step: 10
Training loss: 1.1707712411880493
Validation loss: 2.1383496599812664

Epoch: 336| Step: 0
Training loss: 1.6675786972045898
Validation loss: 2.0382558120194303

Epoch: 5| Step: 1
Training loss: 1.9961658716201782
Validation loss: 2.1171329470090967

Epoch: 5| Step: 2
Training loss: 1.7248834371566772
Validation loss: 2.098072754439487

Epoch: 5| Step: 3
Training loss: 1.881872534751892
Validation loss: 2.0634758677533878

Epoch: 5| Step: 4
Training loss: 1.9882056713104248
Validation loss: 2.1234721137631323

Epoch: 5| Step: 5
Training loss: 1.4187450408935547
Validation loss: 2.0826833248138428

Epoch: 5| Step: 6
Training loss: 1.821531057357788
Validation loss: 2.129200279071767

Epoch: 5| Step: 7
Training loss: 1.9995629787445068
Validation loss: 2.0743387411999445

Epoch: 5| Step: 8
Training loss: 1.3872286081314087
Validation loss: 2.0927345496352

Epoch: 5| Step: 9
Training loss: 2.535099983215332
Validation loss: 2.0549799601236978

Epoch: 5| Step: 10
Training loss: 2.4539449214935303
Validation loss: 2.0992465878045685

Epoch: 337| Step: 0
Training loss: 1.719444990158081
Validation loss: 2.0424964991948937

Epoch: 5| Step: 1
Training loss: 1.9040939807891846
Validation loss: 2.059155293690261

Epoch: 5| Step: 2
Training loss: 2.23604154586792
Validation loss: 2.1475925958284767

Epoch: 5| Step: 3
Training loss: 1.7424430847167969
Validation loss: 2.0875932401226414

Epoch: 5| Step: 4
Training loss: 1.746324896812439
Validation loss: 2.2206376342363257

Epoch: 5| Step: 5
Training loss: 1.7483415603637695
Validation loss: 2.1319475084222774

Epoch: 5| Step: 6
Training loss: 1.6475231647491455
Validation loss: 2.1365565100023822

Epoch: 5| Step: 7
Training loss: 2.1852641105651855
Validation loss: 2.0527078656740088

Epoch: 5| Step: 8
Training loss: 1.849450707435608
Validation loss: 2.0961547923344437

Epoch: 5| Step: 9
Training loss: 2.4552698135375977
Validation loss: 2.1523227294286094

Epoch: 5| Step: 10
Training loss: 1.8910778760910034
Validation loss: 2.016752612206244

Epoch: 338| Step: 0
Training loss: 2.090453624725342
Validation loss: 2.0159960575001215

Epoch: 5| Step: 1
Training loss: 2.267979383468628
Validation loss: 2.04752153735007

Epoch: 5| Step: 2
Training loss: 1.9077270030975342
Validation loss: 2.048477166442461

Epoch: 5| Step: 3
Training loss: 1.2823010683059692
Validation loss: 2.061226464086963

Epoch: 5| Step: 4
Training loss: 2.0825557708740234
Validation loss: 2.0608540888755553

Epoch: 5| Step: 5
Training loss: 1.777825951576233
Validation loss: 2.07777048823654

Epoch: 5| Step: 6
Training loss: 1.2527759075164795
Validation loss: 1.9941562234714467

Epoch: 5| Step: 7
Training loss: 2.147616147994995
Validation loss: 2.0647367136452788

Epoch: 5| Step: 8
Training loss: 1.6969051361083984
Validation loss: 2.1218206920931415

Epoch: 5| Step: 9
Training loss: 2.0169930458068848
Validation loss: 2.094086447069722

Epoch: 5| Step: 10
Training loss: 2.823603630065918
Validation loss: 2.1176440215879873

Epoch: 339| Step: 0
Training loss: 1.842952013015747
Validation loss: 2.08906642852291

Epoch: 5| Step: 1
Training loss: 2.1287081241607666
Validation loss: 2.153469343339243

Epoch: 5| Step: 2
Training loss: 1.6871061325073242
Validation loss: 2.073269392854424

Epoch: 5| Step: 3
Training loss: 1.6719242334365845
Validation loss: 2.064150994823825

Epoch: 5| Step: 4
Training loss: 2.135601758956909
Validation loss: 2.116132777224305

Epoch: 5| Step: 5
Training loss: 1.7876272201538086
Validation loss: 2.036211504731127

Epoch: 5| Step: 6
Training loss: 2.3679535388946533
Validation loss: 2.1499968062164965

Epoch: 5| Step: 7
Training loss: 2.014185905456543
Validation loss: 2.162038272426974

Epoch: 5| Step: 8
Training loss: 1.6422631740570068
Validation loss: 2.1128760832612232

Epoch: 5| Step: 9
Training loss: 1.9876270294189453
Validation loss: 2.082427227368919

Epoch: 5| Step: 10
Training loss: 1.9963040351867676
Validation loss: 2.2359334755969305

Epoch: 340| Step: 0
Training loss: 2.3933768272399902
Validation loss: 2.0450124304781676

Epoch: 5| Step: 1
Training loss: 2.1007301807403564
Validation loss: 2.01837267157852

Epoch: 5| Step: 2
Training loss: 1.3620498180389404
Validation loss: 2.1196306341437885

Epoch: 5| Step: 3
Training loss: 2.3556981086730957
Validation loss: 2.073292604056738

Epoch: 5| Step: 4
Training loss: 1.6035163402557373
Validation loss: 2.1547351396212013

Epoch: 5| Step: 5
Training loss: 1.5013786554336548
Validation loss: 2.0727097065218034

Epoch: 5| Step: 6
Training loss: 1.6326420307159424
Validation loss: 2.0649424329880746

Epoch: 5| Step: 7
Training loss: 1.8030824661254883
Validation loss: 2.055889665439565

Epoch: 5| Step: 8
Training loss: 1.9682247638702393
Validation loss: 2.1571084812123287

Epoch: 5| Step: 9
Training loss: 1.5027743577957153
Validation loss: 2.1102129144053303

Epoch: 5| Step: 10
Training loss: 2.378455877304077
Validation loss: 2.05905706010839

Epoch: 341| Step: 0
Training loss: 1.3411056995391846
Validation loss: 2.055441002691946

Epoch: 5| Step: 1
Training loss: 2.112475872039795
Validation loss: 2.0996556589680333

Epoch: 5| Step: 2
Training loss: 2.4762654304504395
Validation loss: 2.04352927977039

Epoch: 5| Step: 3
Training loss: 1.3311725854873657
Validation loss: 2.105619228014382

Epoch: 5| Step: 4
Training loss: 2.4955663681030273
Validation loss: 2.0987506015326387

Epoch: 5| Step: 5
Training loss: 2.018033266067505
Validation loss: 2.047167739560527

Epoch: 5| Step: 6
Training loss: 2.0045785903930664
Validation loss: 2.1365744042140182

Epoch: 5| Step: 7
Training loss: 1.4730033874511719
Validation loss: 2.072402556737264

Epoch: 5| Step: 8
Training loss: 1.5323853492736816
Validation loss: 2.082889133884061

Epoch: 5| Step: 9
Training loss: 2.051011562347412
Validation loss: 2.0651838189812115

Epoch: 5| Step: 10
Training loss: 1.8891558647155762
Validation loss: 2.1029189735330562

Epoch: 342| Step: 0
Training loss: 1.6005100011825562
Validation loss: 2.0258694284705707

Epoch: 5| Step: 1
Training loss: 2.4728920459747314
Validation loss: 2.1518084695262294

Epoch: 5| Step: 2
Training loss: 1.9420232772827148
Validation loss: 2.1588929263494347

Epoch: 5| Step: 3
Training loss: 1.7298290729522705
Validation loss: 2.088940651186051

Epoch: 5| Step: 4
Training loss: 2.0839076042175293
Validation loss: 2.038454342913884

Epoch: 5| Step: 5
Training loss: 2.270129680633545
Validation loss: 2.0940044156966673

Epoch: 5| Step: 6
Training loss: 1.6019461154937744
Validation loss: 2.111378538993097

Epoch: 5| Step: 7
Training loss: 1.9705902338027954
Validation loss: 2.1794324382658927

Epoch: 5| Step: 8
Training loss: 2.116157054901123
Validation loss: 2.1227466393542547

Epoch: 5| Step: 9
Training loss: 1.5546560287475586
Validation loss: 2.033815178819882

Epoch: 5| Step: 10
Training loss: 1.6177315711975098
Validation loss: 2.064675948953116

Epoch: 343| Step: 0
Training loss: 1.5898098945617676
Validation loss: 2.067407306804452

Epoch: 5| Step: 1
Training loss: 2.0686872005462646
Validation loss: 2.0962848970966954

Epoch: 5| Step: 2
Training loss: 2.435181140899658
Validation loss: 2.022665451931697

Epoch: 5| Step: 3
Training loss: 2.2377712726593018
Validation loss: 2.1980086667563326

Epoch: 5| Step: 4
Training loss: 2.203342914581299
Validation loss: 2.079855813775011

Epoch: 5| Step: 5
Training loss: 2.0476183891296387
Validation loss: 2.0232378923764793

Epoch: 5| Step: 6
Training loss: 1.8748929500579834
Validation loss: 2.07298961506095

Epoch: 5| Step: 7
Training loss: 1.6303291320800781
Validation loss: 2.2258170330396263

Epoch: 5| Step: 8
Training loss: 1.8905439376831055
Validation loss: 2.1751466566516506

Epoch: 5| Step: 9
Training loss: 1.635449767112732
Validation loss: 2.1801668290169007

Epoch: 5| Step: 10
Training loss: 1.4775259494781494
Validation loss: 2.108515311312932

Epoch: 344| Step: 0
Training loss: 1.622939109802246
Validation loss: 2.0739347921904696

Epoch: 5| Step: 1
Training loss: 1.4235035181045532
Validation loss: 2.1647996312828472

Epoch: 5| Step: 2
Training loss: 1.9134705066680908
Validation loss: 2.0905893041241552

Epoch: 5| Step: 3
Training loss: 1.8976306915283203
Validation loss: 2.04035976881622

Epoch: 5| Step: 4
Training loss: 1.9884742498397827
Validation loss: 2.08847084224865

Epoch: 5| Step: 5
Training loss: 2.2185423374176025
Validation loss: 2.110504364454618

Epoch: 5| Step: 6
Training loss: 1.635054588317871
Validation loss: 2.03620724011493

Epoch: 5| Step: 7
Training loss: 1.2136993408203125
Validation loss: 2.1412291898522327

Epoch: 5| Step: 8
Training loss: 2.495537519454956
Validation loss: 2.0028949309420843

Epoch: 5| Step: 9
Training loss: 2.290972948074341
Validation loss: 2.0257444240713633

Epoch: 5| Step: 10
Training loss: 1.2161073684692383
Validation loss: 2.0598157785272084

Epoch: 345| Step: 0
Training loss: 2.0502963066101074
Validation loss: 1.974880123651156

Epoch: 5| Step: 1
Training loss: 1.5409643650054932
Validation loss: 2.017761816260635

Epoch: 5| Step: 2
Training loss: 1.727927803993225
Validation loss: 2.0236543993796072

Epoch: 5| Step: 3
Training loss: 1.8994886875152588
Validation loss: 2.184272389258108

Epoch: 5| Step: 4
Training loss: 1.8701038360595703
Validation loss: 2.1043255200950046

Epoch: 5| Step: 5
Training loss: 2.4370169639587402
Validation loss: 2.009048181195413

Epoch: 5| Step: 6
Training loss: 1.9367573261260986
Validation loss: 2.1531579443203506

Epoch: 5| Step: 7
Training loss: 1.469557762145996
Validation loss: 2.090285162771902

Epoch: 5| Step: 8
Training loss: 2.3106749057769775
Validation loss: 2.0257568090192732

Epoch: 5| Step: 9
Training loss: 1.80038583278656
Validation loss: 2.106837016279979

Epoch: 5| Step: 10
Training loss: 1.6415207386016846
Validation loss: 2.089029642843431

Epoch: 346| Step: 0
Training loss: 1.4952504634857178
Validation loss: 2.086710617106448

Epoch: 5| Step: 1
Training loss: 2.091463804244995
Validation loss: 2.066970512431155

Epoch: 5| Step: 2
Training loss: 2.22566294670105
Validation loss: 2.0200497488821707

Epoch: 5| Step: 3
Training loss: 2.2087759971618652
Validation loss: 2.094351130147134

Epoch: 5| Step: 4
Training loss: 2.2454304695129395
Validation loss: 2.0426975886027017

Epoch: 5| Step: 5
Training loss: 1.543576955795288
Validation loss: 2.1231991142354985

Epoch: 5| Step: 6
Training loss: 1.8019206523895264
Validation loss: 1.9948526326046194

Epoch: 5| Step: 7
Training loss: 1.9101539850234985
Validation loss: 2.063485642915131

Epoch: 5| Step: 8
Training loss: 2.225132465362549
Validation loss: 2.079299306356779

Epoch: 5| Step: 9
Training loss: 1.2393137216567993
Validation loss: 2.172944805955374

Epoch: 5| Step: 10
Training loss: 2.1110472679138184
Validation loss: 2.10918854641658

Epoch: 347| Step: 0
Training loss: 1.8385889530181885
Validation loss: 2.168427603219145

Epoch: 5| Step: 1
Training loss: 2.1458253860473633
Validation loss: 2.0999199421175065

Epoch: 5| Step: 2
Training loss: 1.8560988903045654
Validation loss: 2.082686183273151

Epoch: 5| Step: 3
Training loss: 2.1175637245178223
Validation loss: 2.143837167370704

Epoch: 5| Step: 4
Training loss: 1.9834579229354858
Validation loss: 2.141016862725699

Epoch: 5| Step: 5
Training loss: 2.1354594230651855
Validation loss: 2.1377854167774157

Epoch: 5| Step: 6
Training loss: 1.5206855535507202
Validation loss: 2.1581560616852133

Epoch: 5| Step: 7
Training loss: 1.3705940246582031
Validation loss: 2.043291171391805

Epoch: 5| Step: 8
Training loss: 2.007514476776123
Validation loss: 2.1251253069088025

Epoch: 5| Step: 9
Training loss: 2.3615634441375732
Validation loss: 2.160264761217179

Epoch: 5| Step: 10
Training loss: 2.0560529232025146
Validation loss: 2.1815251893894647

Epoch: 348| Step: 0
Training loss: 2.311586856842041
Validation loss: 2.15764013285278

Epoch: 5| Step: 1
Training loss: 1.3266528844833374
Validation loss: 1.9674671952442457

Epoch: 5| Step: 2
Training loss: 1.4793728590011597
Validation loss: 2.041505877689649

Epoch: 5| Step: 3
Training loss: 1.9720776081085205
Validation loss: 2.11039149889382

Epoch: 5| Step: 4
Training loss: 1.5633996725082397
Validation loss: 2.047300964273432

Epoch: 5| Step: 5
Training loss: 2.376401901245117
Validation loss: 2.069449870817123

Epoch: 5| Step: 6
Training loss: 1.45126211643219
Validation loss: 2.0626163636484454

Epoch: 5| Step: 7
Training loss: 2.413992404937744
Validation loss: 2.137731916160994

Epoch: 5| Step: 8
Training loss: 1.7214924097061157
Validation loss: 2.074520423848142

Epoch: 5| Step: 9
Training loss: 1.961423635482788
Validation loss: 2.074948513379661

Epoch: 5| Step: 10
Training loss: 1.7989598512649536
Validation loss: 2.1500326946217525

Epoch: 349| Step: 0
Training loss: 1.4157121181488037
Validation loss: 2.1782414195358113

Epoch: 5| Step: 1
Training loss: 1.477782130241394
Validation loss: 2.128455828594905

Epoch: 5| Step: 2
Training loss: 1.784410834312439
Validation loss: 2.04748809465798

Epoch: 5| Step: 3
Training loss: 1.7636997699737549
Validation loss: 2.0596951694898706

Epoch: 5| Step: 4
Training loss: 2.21050763130188
Validation loss: 2.1000793518558627

Epoch: 5| Step: 5
Training loss: 2.0366058349609375
Validation loss: 1.9990771688440794

Epoch: 5| Step: 6
Training loss: 1.9309511184692383
Validation loss: 2.0851122692067134

Epoch: 5| Step: 7
Training loss: 2.234353542327881
Validation loss: 2.1099109470203357

Epoch: 5| Step: 8
Training loss: 2.314180850982666
Validation loss: 2.0640954920040664

Epoch: 5| Step: 9
Training loss: 1.8028093576431274
Validation loss: 2.1256472808058544

Epoch: 5| Step: 10
Training loss: 2.0276732444763184
Validation loss: 2.1701322114595802

Epoch: 350| Step: 0
Training loss: 2.212653160095215
Validation loss: 2.2064863379283617

Epoch: 5| Step: 1
Training loss: 1.826171875
Validation loss: 2.0674923594279955

Epoch: 5| Step: 2
Training loss: 1.6194242238998413
Validation loss: 2.0378521168103783

Epoch: 5| Step: 3
Training loss: 2.518306255340576
Validation loss: 2.1346968630308747

Epoch: 5| Step: 4
Training loss: 1.7512000799179077
Validation loss: 2.041326662545563

Epoch: 5| Step: 5
Training loss: 1.7702001333236694
Validation loss: 2.1106868725951

Epoch: 5| Step: 6
Training loss: 1.6301828622817993
Validation loss: 2.0691677960016395

Epoch: 5| Step: 7
Training loss: 1.533686876296997
Validation loss: 2.072580382388125

Epoch: 5| Step: 8
Training loss: 1.8127378225326538
Validation loss: 2.1139446868691394

Epoch: 5| Step: 9
Training loss: 2.195629835128784
Validation loss: 2.1666852992068053

Epoch: 5| Step: 10
Training loss: 1.7846364974975586
Validation loss: 2.108805061668478

Epoch: 351| Step: 0
Training loss: 1.8979488611221313
Validation loss: 2.0901345463209253

Epoch: 5| Step: 1
Training loss: 1.3765206336975098
Validation loss: 2.167683006614767

Epoch: 5| Step: 2
Training loss: 1.7677028179168701
Validation loss: 2.1362145998144664

Epoch: 5| Step: 3
Training loss: 2.2302613258361816
Validation loss: 2.077275240293113

Epoch: 5| Step: 4
Training loss: 1.4102120399475098
Validation loss: 2.035932679330149

Epoch: 5| Step: 5
Training loss: 1.7790496349334717
Validation loss: 2.050407078958327

Epoch: 5| Step: 6
Training loss: 2.0773558616638184
Validation loss: 2.0260817978971746

Epoch: 5| Step: 7
Training loss: 1.3889182806015015
Validation loss: 2.103424382466142

Epoch: 5| Step: 8
Training loss: 1.6532237529754639
Validation loss: 2.170564277197725

Epoch: 5| Step: 9
Training loss: 2.036729097366333
Validation loss: 2.0980730415672384

Epoch: 5| Step: 10
Training loss: 2.096473455429077
Validation loss: 2.05525775365932

Epoch: 352| Step: 0
Training loss: 2.080110549926758
Validation loss: 2.183386292508853

Epoch: 5| Step: 1
Training loss: 1.643583059310913
Validation loss: 2.1556215337527695

Epoch: 5| Step: 2
Training loss: 1.6103382110595703
Validation loss: 2.0060210971422094

Epoch: 5| Step: 3
Training loss: 1.9174890518188477
Validation loss: 2.1255470219478814

Epoch: 5| Step: 4
Training loss: 1.7192662954330444
Validation loss: 2.070625739712869

Epoch: 5| Step: 5
Training loss: 2.8071413040161133
Validation loss: 2.0774780319583033

Epoch: 5| Step: 6
Training loss: 2.0179150104522705
Validation loss: 2.1140680274655743

Epoch: 5| Step: 7
Training loss: 1.7488796710968018
Validation loss: 2.1109558484887563

Epoch: 5| Step: 8
Training loss: 2.349703311920166
Validation loss: 2.07807562428136

Epoch: 5| Step: 9
Training loss: 1.564561128616333
Validation loss: 2.104894830334571

Epoch: 5| Step: 10
Training loss: 1.4272561073303223
Validation loss: 2.0542566173820087

Epoch: 353| Step: 0
Training loss: 2.0939183235168457
Validation loss: 2.0709553687803206

Epoch: 5| Step: 1
Training loss: 2.038977861404419
Validation loss: 2.0963393565147155

Epoch: 5| Step: 2
Training loss: 1.6513898372650146
Validation loss: 2.1109930507598387

Epoch: 5| Step: 3
Training loss: 1.751821517944336
Validation loss: 2.1105917705002653

Epoch: 5| Step: 4
Training loss: 1.7747291326522827
Validation loss: 2.0576944505014727

Epoch: 5| Step: 5
Training loss: 2.240427255630493
Validation loss: 2.1594913544193393

Epoch: 5| Step: 6
Training loss: 2.379497766494751
Validation loss: 2.11289821645265

Epoch: 5| Step: 7
Training loss: 1.625017523765564
Validation loss: 2.0688899345295404

Epoch: 5| Step: 8
Training loss: 1.5462615489959717
Validation loss: 1.9907585344006937

Epoch: 5| Step: 9
Training loss: 1.842058539390564
Validation loss: 2.0453153220556115

Epoch: 5| Step: 10
Training loss: 1.329395055770874
Validation loss: 2.135010273225846

Epoch: 354| Step: 0
Training loss: 1.670627236366272
Validation loss: 2.0255515690772765

Epoch: 5| Step: 1
Training loss: 1.3705984354019165
Validation loss: 2.1089240671485983

Epoch: 5| Step: 2
Training loss: 1.7992699146270752
Validation loss: 2.0214307077469362

Epoch: 5| Step: 3
Training loss: 1.750436544418335
Validation loss: 2.096882991893317

Epoch: 5| Step: 4
Training loss: 2.0935397148132324
Validation loss: 2.1341476837793985

Epoch: 5| Step: 5
Training loss: 2.3314220905303955
Validation loss: 2.013305514089523

Epoch: 5| Step: 6
Training loss: 1.692915678024292
Validation loss: 2.033667943810904

Epoch: 5| Step: 7
Training loss: 2.2999637126922607
Validation loss: 2.0401205888358493

Epoch: 5| Step: 8
Training loss: 1.8987398147583008
Validation loss: 2.099558348296791

Epoch: 5| Step: 9
Training loss: 2.4848570823669434
Validation loss: 2.074645821766187

Epoch: 5| Step: 10
Training loss: 0.9921526312828064
Validation loss: 1.9872476926413916

Epoch: 355| Step: 0
Training loss: 1.9119154214859009
Validation loss: 2.087712880103819

Epoch: 5| Step: 1
Training loss: 2.444368839263916
Validation loss: 2.1065986643555346

Epoch: 5| Step: 2
Training loss: 1.7459862232208252
Validation loss: 2.0544890383238434

Epoch: 5| Step: 3
Training loss: 1.5612680912017822
Validation loss: 2.1039531077108076

Epoch: 5| Step: 4
Training loss: 2.118985891342163
Validation loss: 2.0951311383196103

Epoch: 5| Step: 5
Training loss: 2.4536948204040527
Validation loss: 2.0936348310080906

Epoch: 5| Step: 6
Training loss: 1.4792511463165283
Validation loss: 2.0550881675494614

Epoch: 5| Step: 7
Training loss: 2.0595099925994873
Validation loss: 2.0960783830253025

Epoch: 5| Step: 8
Training loss: 1.999987006187439
Validation loss: 2.123158998386834

Epoch: 5| Step: 9
Training loss: 1.3538169860839844
Validation loss: 2.0548209836406093

Epoch: 5| Step: 10
Training loss: 1.5088287591934204
Validation loss: 2.007063568279307

Epoch: 356| Step: 0
Training loss: 1.466681957244873
Validation loss: 2.0300695332147742

Epoch: 5| Step: 1
Training loss: 1.548034906387329
Validation loss: 2.061837968005929

Epoch: 5| Step: 2
Training loss: 1.292523741722107
Validation loss: 2.0204958813164824

Epoch: 5| Step: 3
Training loss: 1.4248920679092407
Validation loss: 2.1185491777235463

Epoch: 5| Step: 4
Training loss: 2.436829090118408
Validation loss: 2.0595610090481338

Epoch: 5| Step: 5
Training loss: 0.9714497327804565
Validation loss: 2.042879425069337

Epoch: 5| Step: 6
Training loss: 1.99784255027771
Validation loss: 2.0905195769443305

Epoch: 5| Step: 7
Training loss: 2.7215614318847656
Validation loss: 2.0954682929541475

Epoch: 5| Step: 8
Training loss: 1.9282795190811157
Validation loss: 2.0295954942703247

Epoch: 5| Step: 9
Training loss: 2.17038893699646
Validation loss: 2.114303192784709

Epoch: 5| Step: 10
Training loss: 1.9297665357589722
Validation loss: 2.122149413631808

Epoch: 357| Step: 0
Training loss: 1.5317802429199219
Validation loss: 2.033324441602153

Epoch: 5| Step: 1
Training loss: 2.1681389808654785
Validation loss: 2.0981349201612574

Epoch: 5| Step: 2
Training loss: 2.601708173751831
Validation loss: 2.113840095458492

Epoch: 5| Step: 3
Training loss: 2.044528007507324
Validation loss: 2.137568432797668

Epoch: 5| Step: 4
Training loss: 1.4651212692260742
Validation loss: 2.129088060830229

Epoch: 5| Step: 5
Training loss: 2.067272186279297
Validation loss: 2.098796654773015

Epoch: 5| Step: 6
Training loss: 1.4788877964019775
Validation loss: 2.086603755592018

Epoch: 5| Step: 7
Training loss: 2.1786062717437744
Validation loss: 2.0940063332998626

Epoch: 5| Step: 8
Training loss: 1.620965600013733
Validation loss: 2.0084464088562997

Epoch: 5| Step: 9
Training loss: 1.991855263710022
Validation loss: 2.055005934930617

Epoch: 5| Step: 10
Training loss: 1.4357376098632812
Validation loss: 2.0195200135630946

Epoch: 358| Step: 0
Training loss: 2.2742159366607666
Validation loss: 2.142669198333576

Epoch: 5| Step: 1
Training loss: 2.2338547706604004
Validation loss: 2.0704980024727444

Epoch: 5| Step: 2
Training loss: 1.7706868648529053
Validation loss: 2.2075623876305035

Epoch: 5| Step: 3
Training loss: 2.210094690322876
Validation loss: 2.0055794074971187

Epoch: 5| Step: 4
Training loss: 1.4306427240371704
Validation loss: 2.17477152680838

Epoch: 5| Step: 5
Training loss: 1.1146267652511597
Validation loss: 2.131106650957497

Epoch: 5| Step: 6
Training loss: 2.618453025817871
Validation loss: 2.0947018695133988

Epoch: 5| Step: 7
Training loss: 1.2839410305023193
Validation loss: 2.1191139221191406

Epoch: 5| Step: 8
Training loss: 2.0088050365448
Validation loss: 2.0992479516613867

Epoch: 5| Step: 9
Training loss: 2.1204075813293457
Validation loss: 2.1420210535808275

Epoch: 5| Step: 10
Training loss: 1.6324101686477661
Validation loss: 2.132976631964407

Epoch: 359| Step: 0
Training loss: 1.9502977132797241
Validation loss: 2.0906261039036576

Epoch: 5| Step: 1
Training loss: 1.8361326456069946
Validation loss: 2.022151224074825

Epoch: 5| Step: 2
Training loss: 1.4382705688476562
Validation loss: 2.109166401688771

Epoch: 5| Step: 3
Training loss: 1.5768747329711914
Validation loss: 2.121205424749723

Epoch: 5| Step: 4
Training loss: 1.9875848293304443
Validation loss: 2.097953757932109

Epoch: 5| Step: 5
Training loss: 2.526595115661621
Validation loss: 2.13714107390373

Epoch: 5| Step: 6
Training loss: 1.3128440380096436
Validation loss: 2.129847011258525

Epoch: 5| Step: 7
Training loss: 1.4794772863388062
Validation loss: 2.1212717961239558

Epoch: 5| Step: 8
Training loss: 1.48583984375
Validation loss: 1.9899387897983674

Epoch: 5| Step: 9
Training loss: 2.3434605598449707
Validation loss: 1.97573483374811

Epoch: 5| Step: 10
Training loss: 2.321592092514038
Validation loss: 2.1500131212255007

Epoch: 360| Step: 0
Training loss: 2.258348226547241
Validation loss: 2.0986444770648913

Epoch: 5| Step: 1
Training loss: 1.6595203876495361
Validation loss: 2.132814945713166

Epoch: 5| Step: 2
Training loss: 2.045815944671631
Validation loss: 2.1364483012947986

Epoch: 5| Step: 3
Training loss: 1.9102163314819336
Validation loss: 2.110711928336851

Epoch: 5| Step: 4
Training loss: 1.252048134803772
Validation loss: 2.1563080549240112

Epoch: 5| Step: 5
Training loss: 2.0291152000427246
Validation loss: 2.098596244729975

Epoch: 5| Step: 6
Training loss: 1.651123046875
Validation loss: 2.0475448972435406

Epoch: 5| Step: 7
Training loss: 1.4466814994812012
Validation loss: 2.02595567446883

Epoch: 5| Step: 8
Training loss: 1.982802152633667
Validation loss: 2.1559031086583293

Epoch: 5| Step: 9
Training loss: 1.7996037006378174
Validation loss: 2.06758790375084

Epoch: 5| Step: 10
Training loss: 2.016024589538574
Validation loss: 2.122973236986386

Epoch: 361| Step: 0
Training loss: 1.6547348499298096
Validation loss: 2.072701782308599

Epoch: 5| Step: 1
Training loss: 1.3824962377548218
Validation loss: 2.1419630806933165

Epoch: 5| Step: 2
Training loss: 2.0016062259674072
Validation loss: 2.1538240909576416

Epoch: 5| Step: 3
Training loss: 2.4623188972473145
Validation loss: 2.1312765229132866

Epoch: 5| Step: 4
Training loss: 1.764491319656372
Validation loss: 2.088844612080564

Epoch: 5| Step: 5
Training loss: 1.568193793296814
Validation loss: 2.195656709773566

Epoch: 5| Step: 6
Training loss: 2.4615466594696045
Validation loss: 2.2219928849127983

Epoch: 5| Step: 7
Training loss: 1.9623359441757202
Validation loss: 2.124038473252327

Epoch: 5| Step: 8
Training loss: 1.4040364027023315
Validation loss: 2.2439680535306215

Epoch: 5| Step: 9
Training loss: 2.2257626056671143
Validation loss: 2.1846674821710073

Epoch: 5| Step: 10
Training loss: 2.053098201751709
Validation loss: 2.2038185186283563

Epoch: 362| Step: 0
Training loss: 1.583146333694458
Validation loss: 2.1007774145372453

Epoch: 5| Step: 1
Training loss: 1.515472650527954
Validation loss: 2.0293071116170576

Epoch: 5| Step: 2
Training loss: 2.510615348815918
Validation loss: 2.117707911358085

Epoch: 5| Step: 3
Training loss: 1.4905251264572144
Validation loss: 2.0755548784809728

Epoch: 5| Step: 4
Training loss: 1.9787172079086304
Validation loss: 2.106063499245592

Epoch: 5| Step: 5
Training loss: 2.145632743835449
Validation loss: 2.0722998393479215

Epoch: 5| Step: 6
Training loss: 2.0213096141815186
Validation loss: 2.1013784434205744

Epoch: 5| Step: 7
Training loss: 1.5689027309417725
Validation loss: 2.1911204066327823

Epoch: 5| Step: 8
Training loss: 2.0299930572509766
Validation loss: 2.0205966323934574

Epoch: 5| Step: 9
Training loss: 1.8479878902435303
Validation loss: 1.9923218065692532

Epoch: 5| Step: 10
Training loss: 1.7698934078216553
Validation loss: 2.0520282663324827

Epoch: 363| Step: 0
Training loss: 1.6405082941055298
Validation loss: 2.034001447821176

Epoch: 5| Step: 1
Training loss: 2.2013537883758545
Validation loss: 2.099661232322775

Epoch: 5| Step: 2
Training loss: 2.4839701652526855
Validation loss: 2.061060315819197

Epoch: 5| Step: 3
Training loss: 1.2775304317474365
Validation loss: 2.078668753306071

Epoch: 5| Step: 4
Training loss: 2.1126301288604736
Validation loss: 2.1637549989966938

Epoch: 5| Step: 5
Training loss: 2.5990452766418457
Validation loss: 2.1501638415039226

Epoch: 5| Step: 6
Training loss: 1.652458906173706
Validation loss: 2.1404581018673476

Epoch: 5| Step: 7
Training loss: 1.8196070194244385
Validation loss: 2.1876735828256093

Epoch: 5| Step: 8
Training loss: 1.1368564367294312
Validation loss: 2.2594925870177565

Epoch: 5| Step: 9
Training loss: 2.3350789546966553
Validation loss: 2.1012126899534658

Epoch: 5| Step: 10
Training loss: 1.4121731519699097
Validation loss: 2.2006525660073883

Epoch: 364| Step: 0
Training loss: 2.590519905090332
Validation loss: 2.1925381306679017

Epoch: 5| Step: 1
Training loss: 1.560481071472168
Validation loss: 2.2612457775300547

Epoch: 5| Step: 2
Training loss: 1.9195258617401123
Validation loss: 2.2057359346779446

Epoch: 5| Step: 3
Training loss: 1.9301990270614624
Validation loss: 2.1506807727198445

Epoch: 5| Step: 4
Training loss: 1.4967329502105713
Validation loss: 2.185196066415438

Epoch: 5| Step: 5
Training loss: 1.8126379251480103
Validation loss: 2.09125288327535

Epoch: 5| Step: 6
Training loss: 1.4197344779968262
Validation loss: 2.16994075493146

Epoch: 5| Step: 7
Training loss: 1.0426626205444336
Validation loss: 2.0772289460705173

Epoch: 5| Step: 8
Training loss: 2.177964687347412
Validation loss: 2.192621395152102

Epoch: 5| Step: 9
Training loss: 2.1266350746154785
Validation loss: 2.089449505652151

Epoch: 5| Step: 10
Training loss: 2.3045406341552734
Validation loss: 2.2297447817299956

Epoch: 365| Step: 0
Training loss: 1.797459363937378
Validation loss: 2.0672734065722396

Epoch: 5| Step: 1
Training loss: 1.8535120487213135
Validation loss: 2.060590758118578

Epoch: 5| Step: 2
Training loss: 2.023974895477295
Validation loss: 2.1097297924821095

Epoch: 5| Step: 3
Training loss: 1.587517261505127
Validation loss: 2.051720852492958

Epoch: 5| Step: 4
Training loss: 1.9201472997665405
Validation loss: 2.137488562573669

Epoch: 5| Step: 5
Training loss: 1.6264441013336182
Validation loss: 2.097491072070214

Epoch: 5| Step: 6
Training loss: 1.5209071636199951
Validation loss: 2.1372551174574

Epoch: 5| Step: 7
Training loss: 1.234334945678711
Validation loss: 2.0332996332517235

Epoch: 5| Step: 8
Training loss: 1.9798200130462646
Validation loss: 2.059972675897742

Epoch: 5| Step: 9
Training loss: 2.2413136959075928
Validation loss: 2.1136930193952335

Epoch: 5| Step: 10
Training loss: 1.9339301586151123
Validation loss: 2.1149823691255305

Epoch: 366| Step: 0
Training loss: 1.6826988458633423
Validation loss: 2.093890013233308

Epoch: 5| Step: 1
Training loss: 2.027228832244873
Validation loss: 2.08108929921222

Epoch: 5| Step: 2
Training loss: 1.655066728591919
Validation loss: 2.1298343699465514

Epoch: 5| Step: 3
Training loss: 1.248091459274292
Validation loss: 2.0177229399322183

Epoch: 5| Step: 4
Training loss: 1.5987915992736816
Validation loss: 2.105860928053497

Epoch: 5| Step: 5
Training loss: 2.005244016647339
Validation loss: 2.1152312050583544

Epoch: 5| Step: 6
Training loss: 1.807496428489685
Validation loss: 2.136118177444704

Epoch: 5| Step: 7
Training loss: 2.5449225902557373
Validation loss: 2.0490620110624578

Epoch: 5| Step: 8
Training loss: 1.9901167154312134
Validation loss: 2.1093068507409867

Epoch: 5| Step: 9
Training loss: 2.124882221221924
Validation loss: 2.16198407706394

Epoch: 5| Step: 10
Training loss: 2.137381076812744
Validation loss: 2.079401126471899

Epoch: 367| Step: 0
Training loss: 1.6100502014160156
Validation loss: 2.094172639231528

Epoch: 5| Step: 1
Training loss: 2.061399459838867
Validation loss: 2.074458911854734

Epoch: 5| Step: 2
Training loss: 1.562803864479065
Validation loss: 2.1519649656870032

Epoch: 5| Step: 3
Training loss: 2.6233091354370117
Validation loss: 2.1507440587525726

Epoch: 5| Step: 4
Training loss: 1.9072349071502686
Validation loss: 2.0308545674047163

Epoch: 5| Step: 5
Training loss: 1.210921049118042
Validation loss: 2.1323620273220922

Epoch: 5| Step: 6
Training loss: 1.8754737377166748
Validation loss: 2.1444126200932327

Epoch: 5| Step: 7
Training loss: 1.852349877357483
Validation loss: 2.1128325205977245

Epoch: 5| Step: 8
Training loss: 1.7850124835968018
Validation loss: 2.15894942386176

Epoch: 5| Step: 9
Training loss: 2.3897814750671387
Validation loss: 2.0658581038957

Epoch: 5| Step: 10
Training loss: 0.9734933376312256
Validation loss: 2.0468141109712663

Epoch: 368| Step: 0
Training loss: 1.524933099746704
Validation loss: 2.0430398769276117

Epoch: 5| Step: 1
Training loss: 2.4132041931152344
Validation loss: 2.0890744988636305

Epoch: 5| Step: 2
Training loss: 1.4506698846817017
Validation loss: 2.061569160030734

Epoch: 5| Step: 3
Training loss: 1.5766011476516724
Validation loss: 1.9942855091505154

Epoch: 5| Step: 4
Training loss: 1.8903154134750366
Validation loss: 2.0616579055786133

Epoch: 5| Step: 5
Training loss: 1.5418787002563477
Validation loss: 2.0291758993620514

Epoch: 5| Step: 6
Training loss: 1.6759506464004517
Validation loss: 2.10964810591872

Epoch: 5| Step: 7
Training loss: 2.815871000289917
Validation loss: 2.083829577251147

Epoch: 5| Step: 8
Training loss: 1.7502638101577759
Validation loss: 2.201064976312781

Epoch: 5| Step: 9
Training loss: 1.6750164031982422
Validation loss: 2.202985082903216

Epoch: 5| Step: 10
Training loss: 2.086137533187866
Validation loss: 2.168711443101206

Epoch: 369| Step: 0
Training loss: 1.613650918006897
Validation loss: 2.0815442736430834

Epoch: 5| Step: 1
Training loss: 1.8744971752166748
Validation loss: 2.1783094995765278

Epoch: 5| Step: 2
Training loss: 1.654821753501892
Validation loss: 2.0491821637717624

Epoch: 5| Step: 3
Training loss: 1.2588177919387817
Validation loss: 2.061432910221879

Epoch: 5| Step: 4
Training loss: 1.6549361944198608
Validation loss: 2.075030411443403

Epoch: 5| Step: 5
Training loss: 1.6975562572479248
Validation loss: 2.0800759651327647

Epoch: 5| Step: 6
Training loss: 2.041011333465576
Validation loss: 2.0611791905536445

Epoch: 5| Step: 7
Training loss: 1.458439826965332
Validation loss: 2.060588477760233

Epoch: 5| Step: 8
Training loss: 1.9586284160614014
Validation loss: 2.138074544168288

Epoch: 5| Step: 9
Training loss: 2.554581880569458
Validation loss: 2.018724787619806

Epoch: 5| Step: 10
Training loss: 1.9863039255142212
Validation loss: 2.0664009586457284

Epoch: 370| Step: 0
Training loss: 1.9393384456634521
Validation loss: 2.097731431325277

Epoch: 5| Step: 1
Training loss: 2.330057144165039
Validation loss: 2.1042613983154297

Epoch: 5| Step: 2
Training loss: 1.847219467163086
Validation loss: 2.0392720058400142

Epoch: 5| Step: 3
Training loss: 1.6330797672271729
Validation loss: 2.030332937035509

Epoch: 5| Step: 4
Training loss: 2.139662742614746
Validation loss: 2.0673480290238575

Epoch: 5| Step: 5
Training loss: 1.5764793157577515
Validation loss: 2.0303140750495334

Epoch: 5| Step: 6
Training loss: 1.9638690948486328
Validation loss: 2.10347944049425

Epoch: 5| Step: 7
Training loss: 1.8659961223602295
Validation loss: 2.0798636495426135

Epoch: 5| Step: 8
Training loss: 1.747955560684204
Validation loss: 2.017750834905973

Epoch: 5| Step: 9
Training loss: 1.666595220565796
Validation loss: 2.143302373988654

Epoch: 5| Step: 10
Training loss: 1.5207147598266602
Validation loss: 2.0003097313706593

Epoch: 371| Step: 0
Training loss: 1.766026258468628
Validation loss: 2.0456691762452484

Epoch: 5| Step: 1
Training loss: 2.1718831062316895
Validation loss: 1.9405778479832474

Epoch: 5| Step: 2
Training loss: 1.804567575454712
Validation loss: 2.0339630291026127

Epoch: 5| Step: 3
Training loss: 1.484848976135254
Validation loss: 2.0859705299459477

Epoch: 5| Step: 4
Training loss: 1.7342329025268555
Validation loss: 2.1033848306184173

Epoch: 5| Step: 5
Training loss: 1.5363320112228394
Validation loss: 2.086424817321121

Epoch: 5| Step: 6
Training loss: 1.513669729232788
Validation loss: 2.086066525469544

Epoch: 5| Step: 7
Training loss: 2.2136738300323486
Validation loss: 2.0313988706117034

Epoch: 5| Step: 8
Training loss: 1.774183988571167
Validation loss: 2.0082115704013455

Epoch: 5| Step: 9
Training loss: 1.6952298879623413
Validation loss: 2.032129467174571

Epoch: 5| Step: 10
Training loss: 2.2725656032562256
Validation loss: 2.0727662886342695

Epoch: 372| Step: 0
Training loss: 1.9148343801498413
Validation loss: 2.1253026044496925

Epoch: 5| Step: 1
Training loss: 1.8508377075195312
Validation loss: 2.0428610540205434

Epoch: 5| Step: 2
Training loss: 2.027860403060913
Validation loss: 2.0929993391036987

Epoch: 5| Step: 3
Training loss: 1.4637887477874756
Validation loss: 2.0704807658349313

Epoch: 5| Step: 4
Training loss: 1.278214454650879
Validation loss: 2.035763740539551

Epoch: 5| Step: 5
Training loss: 1.8807109594345093
Validation loss: 2.055045384232716

Epoch: 5| Step: 6
Training loss: 2.3699216842651367
Validation loss: 2.0734879111730926

Epoch: 5| Step: 7
Training loss: 1.48201584815979
Validation loss: 2.133743178459906

Epoch: 5| Step: 8
Training loss: 1.709133505821228
Validation loss: 2.077246553154402

Epoch: 5| Step: 9
Training loss: 1.97161066532135
Validation loss: 2.0531930205642537

Epoch: 5| Step: 10
Training loss: 1.9171432256698608
Validation loss: 2.081608710750457

Epoch: 373| Step: 0
Training loss: 1.4313666820526123
Validation loss: 2.142649874892286

Epoch: 5| Step: 1
Training loss: 1.7448749542236328
Validation loss: 2.0670800337227444

Epoch: 5| Step: 2
Training loss: 1.7708568572998047
Validation loss: 2.1143203743042482

Epoch: 5| Step: 3
Training loss: 1.5293861627578735
Validation loss: 2.1551940979496127

Epoch: 5| Step: 4
Training loss: 1.9458644390106201
Validation loss: 2.054913616949512

Epoch: 5| Step: 5
Training loss: 1.8414905071258545
Validation loss: 2.0783703557906614

Epoch: 5| Step: 6
Training loss: 1.7274386882781982
Validation loss: 2.0317408000269244

Epoch: 5| Step: 7
Training loss: 2.197521209716797
Validation loss: 2.0658533278331963

Epoch: 5| Step: 8
Training loss: 2.0019240379333496
Validation loss: 2.1839218678012973

Epoch: 5| Step: 9
Training loss: 1.5221904516220093
Validation loss: 2.0742169836516022

Epoch: 5| Step: 10
Training loss: 2.090848207473755
Validation loss: 2.1367574943009244

Epoch: 374| Step: 0
Training loss: 2.1584861278533936
Validation loss: 2.127730505440825

Epoch: 5| Step: 1
Training loss: 1.6378729343414307
Validation loss: 2.0256025355349303

Epoch: 5| Step: 2
Training loss: 2.1142051219940186
Validation loss: 2.1491820889134563

Epoch: 5| Step: 3
Training loss: 1.3169898986816406
Validation loss: 2.145885024019467

Epoch: 5| Step: 4
Training loss: 1.825669288635254
Validation loss: 2.205797254398305

Epoch: 5| Step: 5
Training loss: 2.4510092735290527
Validation loss: 2.0853976895732265

Epoch: 5| Step: 6
Training loss: 1.2407751083374023
Validation loss: 2.11601484078233

Epoch: 5| Step: 7
Training loss: 2.028698682785034
Validation loss: 2.1335777723661034

Epoch: 5| Step: 8
Training loss: 1.5370618104934692
Validation loss: 2.047037870653214

Epoch: 5| Step: 9
Training loss: 1.5921686887741089
Validation loss: 2.09512690062164

Epoch: 5| Step: 10
Training loss: 2.174935817718506
Validation loss: 2.0576796416313416

Epoch: 375| Step: 0
Training loss: 1.2139389514923096
Validation loss: 2.062428779499505

Epoch: 5| Step: 1
Training loss: 2.099416971206665
Validation loss: 2.0563518821552234

Epoch: 5| Step: 2
Training loss: 2.071850299835205
Validation loss: 2.167412248990869

Epoch: 5| Step: 3
Training loss: 1.5941787958145142
Validation loss: 2.0941605952478226

Epoch: 5| Step: 4
Training loss: 1.9130823612213135
Validation loss: 2.104536594883088

Epoch: 5| Step: 5
Training loss: 1.9065685272216797
Validation loss: 2.058693274374931

Epoch: 5| Step: 6
Training loss: 2.035248041152954
Validation loss: 2.164169196159609

Epoch: 5| Step: 7
Training loss: 1.8156267404556274
Validation loss: 2.1416379815788678

Epoch: 5| Step: 8
Training loss: 2.116337299346924
Validation loss: 2.053080963832076

Epoch: 5| Step: 9
Training loss: 1.012721300125122
Validation loss: 1.9612702810636131

Epoch: 5| Step: 10
Training loss: 2.3614256381988525
Validation loss: 2.123683996098016

Epoch: 376| Step: 0
Training loss: 1.671578049659729
Validation loss: 1.9929879698702084

Epoch: 5| Step: 1
Training loss: 1.7252336740493774
Validation loss: 2.11422658735706

Epoch: 5| Step: 2
Training loss: 1.3700249195098877
Validation loss: 2.0201188953973914

Epoch: 5| Step: 3
Training loss: 1.9521347284317017
Validation loss: 2.1109750629753194

Epoch: 5| Step: 4
Training loss: 2.2872672080993652
Validation loss: 2.0397904098674817

Epoch: 5| Step: 5
Training loss: 1.375265121459961
Validation loss: 2.0953152653991536

Epoch: 5| Step: 6
Training loss: 1.6584835052490234
Validation loss: 2.091445853633265

Epoch: 5| Step: 7
Training loss: 2.2820749282836914
Validation loss: 2.075068212324573

Epoch: 5| Step: 8
Training loss: 1.4144787788391113
Validation loss: 2.082099694077687

Epoch: 5| Step: 9
Training loss: 2.0710151195526123
Validation loss: 2.0340063533475323

Epoch: 5| Step: 10
Training loss: 2.0924072265625
Validation loss: 2.1746331748142036

Epoch: 377| Step: 0
Training loss: 1.3528039455413818
Validation loss: 2.0580637557532198

Epoch: 5| Step: 1
Training loss: 2.433250665664673
Validation loss: 2.0660216475045807

Epoch: 5| Step: 2
Training loss: 1.8257042169570923
Validation loss: 2.0766237269165697

Epoch: 5| Step: 3
Training loss: 1.813232421875
Validation loss: 2.0357576262566353

Epoch: 5| Step: 4
Training loss: 2.263251781463623
Validation loss: 2.1080676714579263

Epoch: 5| Step: 5
Training loss: 1.4281055927276611
Validation loss: 1.9427380331100956

Epoch: 5| Step: 6
Training loss: 1.5948776006698608
Validation loss: 2.2067938389316684

Epoch: 5| Step: 7
Training loss: 1.873003602027893
Validation loss: 2.108082696955691

Epoch: 5| Step: 8
Training loss: 1.4017083644866943
Validation loss: 2.1033230302154378

Epoch: 5| Step: 9
Training loss: 1.5792378187179565
Validation loss: 2.062641336071876

Epoch: 5| Step: 10
Training loss: 2.012852668762207
Validation loss: 2.0927300376276814

Epoch: 378| Step: 0
Training loss: 1.6567127704620361
Validation loss: 2.031234843756563

Epoch: 5| Step: 1
Training loss: 1.6875444650650024
Validation loss: 2.098776714776152

Epoch: 5| Step: 2
Training loss: 1.44264817237854
Validation loss: 2.1459572725398566

Epoch: 5| Step: 3
Training loss: 1.8793747425079346
Validation loss: 2.0674069953221146

Epoch: 5| Step: 4
Training loss: 1.7240715026855469
Validation loss: 2.040939550245962

Epoch: 5| Step: 5
Training loss: 2.178410768508911
Validation loss: 2.003071674736597

Epoch: 5| Step: 6
Training loss: 1.5472252368927002
Validation loss: 2.0456284887047222

Epoch: 5| Step: 7
Training loss: 1.5836942195892334
Validation loss: 2.032288441094019

Epoch: 5| Step: 8
Training loss: 1.7563040256500244
Validation loss: 1.9961443588297854

Epoch: 5| Step: 9
Training loss: 1.7297039031982422
Validation loss: 2.0688173501722273

Epoch: 5| Step: 10
Training loss: 2.462026596069336
Validation loss: 2.057367564529501

Epoch: 379| Step: 0
Training loss: 1.8849605321884155
Validation loss: 2.0731807677976546

Epoch: 5| Step: 1
Training loss: 2.302744150161743
Validation loss: 2.060215337302095

Epoch: 5| Step: 2
Training loss: 1.3743482828140259
Validation loss: 2.092092066682795

Epoch: 5| Step: 3
Training loss: 1.407128095626831
Validation loss: 2.0407249209701375

Epoch: 5| Step: 4
Training loss: 2.209817409515381
Validation loss: 2.070302801747476

Epoch: 5| Step: 5
Training loss: 1.8537765741348267
Validation loss: 2.1718432454652685

Epoch: 5| Step: 6
Training loss: 1.9886127710342407
Validation loss: 2.1008238407873336

Epoch: 5| Step: 7
Training loss: 2.005690336227417
Validation loss: 2.143603737636279

Epoch: 5| Step: 8
Training loss: 1.3840481042861938
Validation loss: 2.1476840793445544

Epoch: 5| Step: 9
Training loss: 2.135430097579956
Validation loss: 2.1681938312386952

Epoch: 5| Step: 10
Training loss: 2.017855167388916
Validation loss: 2.170945744360647

Epoch: 380| Step: 0
Training loss: 1.3596638441085815
Validation loss: 2.1216351614203504

Epoch: 5| Step: 1
Training loss: 1.8844302892684937
Validation loss: 2.163573525285208

Epoch: 5| Step: 2
Training loss: 1.4008082151412964
Validation loss: 2.1106029069551857

Epoch: 5| Step: 3
Training loss: 2.145547389984131
Validation loss: 2.0278936214344476

Epoch: 5| Step: 4
Training loss: 1.9425270557403564
Validation loss: 2.183203148585494

Epoch: 5| Step: 5
Training loss: 1.522071123123169
Validation loss: 2.0495748827534337

Epoch: 5| Step: 6
Training loss: 1.969675064086914
Validation loss: 2.13866735658338

Epoch: 5| Step: 7
Training loss: 1.4104070663452148
Validation loss: 2.0496540056761874

Epoch: 5| Step: 8
Training loss: 2.0318126678466797
Validation loss: 2.029022087333023

Epoch: 5| Step: 9
Training loss: 2.416222095489502
Validation loss: 2.095651070276896

Epoch: 5| Step: 10
Training loss: 1.4835588932037354
Validation loss: 2.0152615065215738

Epoch: 381| Step: 0
Training loss: 1.511285424232483
Validation loss: 2.082152544811208

Epoch: 5| Step: 1
Training loss: 2.2882046699523926
Validation loss: 2.0609633896940496

Epoch: 5| Step: 2
Training loss: 2.1509275436401367
Validation loss: 2.074312294683149

Epoch: 5| Step: 3
Training loss: 1.9511991739273071
Validation loss: 2.158401071384389

Epoch: 5| Step: 4
Training loss: 1.2148263454437256
Validation loss: 2.1519062403709657

Epoch: 5| Step: 5
Training loss: 1.3308533430099487
Validation loss: 2.092226005369617

Epoch: 5| Step: 6
Training loss: 2.951550006866455
Validation loss: 2.0547922298472416

Epoch: 5| Step: 7
Training loss: 1.7281601428985596
Validation loss: 2.1095397818473076

Epoch: 5| Step: 8
Training loss: 1.8971742391586304
Validation loss: 2.081033996356431

Epoch: 5| Step: 9
Training loss: 1.3851066827774048
Validation loss: 2.039631617966519

Epoch: 5| Step: 10
Training loss: 1.9091684818267822
Validation loss: 2.0551245738101263

Epoch: 382| Step: 0
Training loss: 1.890758752822876
Validation loss: 2.08362070463037

Epoch: 5| Step: 1
Training loss: 2.19291090965271
Validation loss: 2.0551746378662767

Epoch: 5| Step: 2
Training loss: 1.7597434520721436
Validation loss: 2.067738913720654

Epoch: 5| Step: 3
Training loss: 2.1107585430145264
Validation loss: 2.0677126505041636

Epoch: 5| Step: 4
Training loss: 1.8537604808807373
Validation loss: 2.203854380115386

Epoch: 5| Step: 5
Training loss: 1.8689788579940796
Validation loss: 2.069581377890802

Epoch: 5| Step: 6
Training loss: 1.5522186756134033
Validation loss: 2.0852639841777023

Epoch: 5| Step: 7
Training loss: 1.576717495918274
Validation loss: 2.118724476906561

Epoch: 5| Step: 8
Training loss: 2.311546802520752
Validation loss: 2.0680997538310226

Epoch: 5| Step: 9
Training loss: 1.5085866451263428
Validation loss: 2.0525772058835594

Epoch: 5| Step: 10
Training loss: 1.86111319065094
Validation loss: 2.1084927000025266

Epoch: 383| Step: 0
Training loss: 1.7282215356826782
Validation loss: 2.1072516889982325

Epoch: 5| Step: 1
Training loss: 1.7684805393218994
Validation loss: 2.0170404334222116

Epoch: 5| Step: 2
Training loss: 2.0691792964935303
Validation loss: 2.11309649098304

Epoch: 5| Step: 3
Training loss: 2.172783851623535
Validation loss: 2.1440791929921796

Epoch: 5| Step: 4
Training loss: 1.701615333557129
Validation loss: 2.030317034772647

Epoch: 5| Step: 5
Training loss: 1.8703495264053345
Validation loss: 2.025836815116226

Epoch: 5| Step: 6
Training loss: 1.8361200094223022
Validation loss: 2.127372723753734

Epoch: 5| Step: 7
Training loss: 1.8366838693618774
Validation loss: 2.078330309160294

Epoch: 5| Step: 8
Training loss: 1.7690505981445312
Validation loss: 2.10289087090441

Epoch: 5| Step: 9
Training loss: 1.9510364532470703
Validation loss: 1.9739176880928777

Epoch: 5| Step: 10
Training loss: 1.336089849472046
Validation loss: 2.023710585409595

Epoch: 384| Step: 0
Training loss: 2.3243770599365234
Validation loss: 2.030814299019434

Epoch: 5| Step: 1
Training loss: 1.9763376712799072
Validation loss: 2.0036150101692445

Epoch: 5| Step: 2
Training loss: 1.3682069778442383
Validation loss: 2.13441022493506

Epoch: 5| Step: 3
Training loss: 1.333552360534668
Validation loss: 2.0503267062607633

Epoch: 5| Step: 4
Training loss: 1.9845516681671143
Validation loss: 2.0942054333225375

Epoch: 5| Step: 5
Training loss: 2.0803592205047607
Validation loss: 2.10277372278193

Epoch: 5| Step: 6
Training loss: 2.324862003326416
Validation loss: 2.115361293156942

Epoch: 5| Step: 7
Training loss: 1.5931156873703003
Validation loss: 2.1592327010247017

Epoch: 5| Step: 8
Training loss: 1.721550703048706
Validation loss: 2.0823334070944015

Epoch: 5| Step: 9
Training loss: 2.2644460201263428
Validation loss: 2.0203334990368096

Epoch: 5| Step: 10
Training loss: 1.633554458618164
Validation loss: 2.101311873364192

Epoch: 385| Step: 0
Training loss: 1.5963170528411865
Validation loss: 2.1017931558752574

Epoch: 5| Step: 1
Training loss: 1.6511472463607788
Validation loss: 2.029756628057008

Epoch: 5| Step: 2
Training loss: 1.8630971908569336
Validation loss: 2.145340806694441

Epoch: 5| Step: 3
Training loss: 1.5769888162612915
Validation loss: 1.996931109377133

Epoch: 5| Step: 4
Training loss: 1.506164312362671
Validation loss: 2.137121614589486

Epoch: 5| Step: 5
Training loss: 1.6850833892822266
Validation loss: 2.0887951043344315

Epoch: 5| Step: 6
Training loss: 2.0299508571624756
Validation loss: 2.034423120560185

Epoch: 5| Step: 7
Training loss: 1.626527190208435
Validation loss: 2.041466192532611

Epoch: 5| Step: 8
Training loss: 2.3664302825927734
Validation loss: 2.049047782856931

Epoch: 5| Step: 9
Training loss: 2.0375473499298096
Validation loss: 2.1744616775102514

Epoch: 5| Step: 10
Training loss: 1.698552131652832
Validation loss: 2.0527546200700986

Epoch: 386| Step: 0
Training loss: 2.1151838302612305
Validation loss: 2.096657814518098

Epoch: 5| Step: 1
Training loss: 2.074878215789795
Validation loss: 2.2500041736069547

Epoch: 5| Step: 2
Training loss: 2.239367961883545
Validation loss: 2.212269836856473

Epoch: 5| Step: 3
Training loss: 2.0591647624969482
Validation loss: 2.0844692824989237

Epoch: 5| Step: 4
Training loss: 1.5333497524261475
Validation loss: 2.0584544648406324

Epoch: 5| Step: 5
Training loss: 2.199883222579956
Validation loss: 2.1351604077123825

Epoch: 5| Step: 6
Training loss: 1.9268745183944702
Validation loss: 2.127706471309867

Epoch: 5| Step: 7
Training loss: 1.5873762369155884
Validation loss: 2.1225945552190146

Epoch: 5| Step: 8
Training loss: 1.4009227752685547
Validation loss: 2.093688811025312

Epoch: 5| Step: 9
Training loss: 1.4121588468551636
Validation loss: 2.0806901634380384

Epoch: 5| Step: 10
Training loss: 1.7666915655136108
Validation loss: 2.090433855210581

Epoch: 387| Step: 0
Training loss: 1.9590072631835938
Validation loss: 2.060182361192601

Epoch: 5| Step: 1
Training loss: 2.044482469558716
Validation loss: 2.160695513089498

Epoch: 5| Step: 2
Training loss: 1.7253671884536743
Validation loss: 2.114168838788104

Epoch: 5| Step: 3
Training loss: 2.0074567794799805
Validation loss: 2.161230792281448

Epoch: 5| Step: 4
Training loss: 1.9535043239593506
Validation loss: 2.108504136403402

Epoch: 5| Step: 5
Training loss: 1.2075237035751343
Validation loss: 2.2218551994651876

Epoch: 5| Step: 6
Training loss: 1.6366256475448608
Validation loss: 2.1417985090645413

Epoch: 5| Step: 7
Training loss: 2.0740034580230713
Validation loss: 2.185275541838779

Epoch: 5| Step: 8
Training loss: 1.8745733499526978
Validation loss: 2.131503035945277

Epoch: 5| Step: 9
Training loss: 2.4129459857940674
Validation loss: 2.0834649250071537

Epoch: 5| Step: 10
Training loss: 1.5213754177093506
Validation loss: 2.1937087171821186

Epoch: 388| Step: 0
Training loss: 2.4365921020507812
Validation loss: 2.014549022079796

Epoch: 5| Step: 1
Training loss: 1.5916311740875244
Validation loss: 2.085402532290387

Epoch: 5| Step: 2
Training loss: 1.6773169040679932
Validation loss: 2.108275886504881

Epoch: 5| Step: 3
Training loss: 1.3031810522079468
Validation loss: 2.085433021668465

Epoch: 5| Step: 4
Training loss: 1.5148504972457886
Validation loss: 2.0124184162386003

Epoch: 5| Step: 5
Training loss: 2.289280652999878
Validation loss: 2.174302242135489

Epoch: 5| Step: 6
Training loss: 1.5829534530639648
Validation loss: 1.9603874888471378

Epoch: 5| Step: 7
Training loss: 2.07747745513916
Validation loss: 2.0529567990251767

Epoch: 5| Step: 8
Training loss: 2.271196126937866
Validation loss: 2.1020877668934483

Epoch: 5| Step: 9
Training loss: 1.4517351388931274
Validation loss: 2.1688836825791227

Epoch: 5| Step: 10
Training loss: 1.3442548513412476
Validation loss: 2.1583885044179936

Epoch: 389| Step: 0
Training loss: 1.957362174987793
Validation loss: 2.016090149520546

Epoch: 5| Step: 1
Training loss: 2.37068247795105
Validation loss: 2.06339733446798

Epoch: 5| Step: 2
Training loss: 1.6956813335418701
Validation loss: 2.113688579169653

Epoch: 5| Step: 3
Training loss: 1.8434206247329712
Validation loss: 2.112283096518568

Epoch: 5| Step: 4
Training loss: 1.6891692876815796
Validation loss: 2.0720384813124135

Epoch: 5| Step: 5
Training loss: 1.8385286331176758
Validation loss: 2.065114480192943

Epoch: 5| Step: 6
Training loss: 1.297095537185669
Validation loss: 2.12410218228576

Epoch: 5| Step: 7
Training loss: 1.8470020294189453
Validation loss: 1.994689308187013

Epoch: 5| Step: 8
Training loss: 2.3374857902526855
Validation loss: 2.0998475102968115

Epoch: 5| Step: 9
Training loss: 1.4813176393508911
Validation loss: 2.1607608769529607

Epoch: 5| Step: 10
Training loss: 1.6830114126205444
Validation loss: 2.0696410555993356

Epoch: 390| Step: 0
Training loss: 1.7010211944580078
Validation loss: 2.05709421250128

Epoch: 5| Step: 1
Training loss: 1.6003402471542358
Validation loss: 2.116098129621116

Epoch: 5| Step: 2
Training loss: 2.2749621868133545
Validation loss: 2.0945730619533087

Epoch: 5| Step: 3
Training loss: 1.646988868713379
Validation loss: 2.10952853643766

Epoch: 5| Step: 4
Training loss: 1.820947289466858
Validation loss: 2.126285082550459

Epoch: 5| Step: 5
Training loss: 1.8439706563949585
Validation loss: 1.965767805294324

Epoch: 5| Step: 6
Training loss: 2.000854969024658
Validation loss: 2.098087618427892

Epoch: 5| Step: 7
Training loss: 2.2609825134277344
Validation loss: 2.1193321751010035

Epoch: 5| Step: 8
Training loss: 1.8975433111190796
Validation loss: 2.1917136612758843

Epoch: 5| Step: 9
Training loss: 1.4957867860794067
Validation loss: 2.0822442552094818

Epoch: 5| Step: 10
Training loss: 2.000455141067505
Validation loss: 2.0363908736936507

Epoch: 391| Step: 0
Training loss: 1.9962927103042603
Validation loss: 2.1537236475175425

Epoch: 5| Step: 1
Training loss: 1.9823356866836548
Validation loss: 2.0344560710332726

Epoch: 5| Step: 2
Training loss: 2.050711154937744
Validation loss: 2.0960321208482147

Epoch: 5| Step: 3
Training loss: 2.0830862522125244
Validation loss: 2.1913768655510357

Epoch: 5| Step: 4
Training loss: 1.6067655086517334
Validation loss: 2.1696892246123283

Epoch: 5| Step: 5
Training loss: 1.7264678478240967
Validation loss: 2.096306532941839

Epoch: 5| Step: 6
Training loss: 1.6770715713500977
Validation loss: 2.1832540701794367

Epoch: 5| Step: 7
Training loss: 1.4817755222320557
Validation loss: 2.0959407719232703

Epoch: 5| Step: 8
Training loss: 2.281461715698242
Validation loss: 2.1284942396225466

Epoch: 5| Step: 9
Training loss: 2.103972911834717
Validation loss: 2.099759622286725

Epoch: 5| Step: 10
Training loss: 1.6107388734817505
Validation loss: 2.1353583412785686

Epoch: 392| Step: 0
Training loss: 2.169640302658081
Validation loss: 2.1335556584019817

Epoch: 5| Step: 1
Training loss: 2.2901084423065186
Validation loss: 2.105379145632508

Epoch: 5| Step: 2
Training loss: 1.5726535320281982
Validation loss: 2.0759144316437426

Epoch: 5| Step: 3
Training loss: 1.955727219581604
Validation loss: 1.9870361666525564

Epoch: 5| Step: 4
Training loss: 1.7570301294326782
Validation loss: 2.0447421509732484

Epoch: 5| Step: 5
Training loss: 1.9133352041244507
Validation loss: 2.139904047853203

Epoch: 5| Step: 6
Training loss: 1.4868037700653076
Validation loss: 2.170801367810977

Epoch: 5| Step: 7
Training loss: 1.7646366357803345
Validation loss: 2.118004204124533

Epoch: 5| Step: 8
Training loss: 1.4424251317977905
Validation loss: 2.016134176203

Epoch: 5| Step: 9
Training loss: 1.6059755086898804
Validation loss: 2.121994568455604

Epoch: 5| Step: 10
Training loss: 1.3388537168502808
Validation loss: 2.0642211719225814

Epoch: 393| Step: 0
Training loss: 2.272830009460449
Validation loss: 2.1198180439651653

Epoch: 5| Step: 1
Training loss: 1.8705766201019287
Validation loss: 2.0940044490239953

Epoch: 5| Step: 2
Training loss: 2.4141087532043457
Validation loss: 2.1033475475926555

Epoch: 5| Step: 3
Training loss: 1.584496259689331
Validation loss: 2.0783958896513908

Epoch: 5| Step: 4
Training loss: 1.4363685846328735
Validation loss: 2.088771758540984

Epoch: 5| Step: 5
Training loss: 1.4896095991134644
Validation loss: 2.031788960579903

Epoch: 5| Step: 6
Training loss: 1.9444243907928467
Validation loss: 2.114345399282312

Epoch: 5| Step: 7
Training loss: 2.3675949573516846
Validation loss: 2.102782282778012

Epoch: 5| Step: 8
Training loss: 1.8720130920410156
Validation loss: 2.12878115330973

Epoch: 5| Step: 9
Training loss: 1.0951030254364014
Validation loss: 2.0934609110637377

Epoch: 5| Step: 10
Training loss: 1.709930181503296
Validation loss: 2.073686045985068

Epoch: 394| Step: 0
Training loss: 2.0835928916931152
Validation loss: 2.07033791336962

Epoch: 5| Step: 1
Training loss: 1.7157375812530518
Validation loss: 2.1054992342507965

Epoch: 5| Step: 2
Training loss: 2.0899996757507324
Validation loss: 2.0550502115680325

Epoch: 5| Step: 3
Training loss: 1.737573266029358
Validation loss: 2.1879908730906825

Epoch: 5| Step: 4
Training loss: 1.4256737232208252
Validation loss: 2.077263903874223

Epoch: 5| Step: 5
Training loss: 1.7115204334259033
Validation loss: 2.110629044553285

Epoch: 5| Step: 6
Training loss: 2.0848546028137207
Validation loss: 2.0662484207460956

Epoch: 5| Step: 7
Training loss: 1.792803168296814
Validation loss: 2.036055296979925

Epoch: 5| Step: 8
Training loss: 1.0896918773651123
Validation loss: 1.9938601806599607

Epoch: 5| Step: 9
Training loss: 2.4461841583251953
Validation loss: 1.9658015684414936

Epoch: 5| Step: 10
Training loss: 1.5055540800094604
Validation loss: 1.9998603892582718

Epoch: 395| Step: 0
Training loss: 1.599336862564087
Validation loss: 2.0102313615942515

Epoch: 5| Step: 1
Training loss: 2.1579182147979736
Validation loss: 1.95644030263347

Epoch: 5| Step: 2
Training loss: 1.705644965171814
Validation loss: 2.0401653576922674

Epoch: 5| Step: 3
Training loss: 1.7413303852081299
Validation loss: 2.0103471638053976

Epoch: 5| Step: 4
Training loss: 1.6999118328094482
Validation loss: 2.0513546928282707

Epoch: 5| Step: 5
Training loss: 1.5383827686309814
Validation loss: 2.0534181928121917

Epoch: 5| Step: 6
Training loss: 1.7618716955184937
Validation loss: 1.9979647436449606

Epoch: 5| Step: 7
Training loss: 1.7622125148773193
Validation loss: 2.1041784209589802

Epoch: 5| Step: 8
Training loss: 1.9509608745574951
Validation loss: 2.073308447355865

Epoch: 5| Step: 9
Training loss: 2.1722967624664307
Validation loss: 2.062337465183709

Epoch: 5| Step: 10
Training loss: 2.001516342163086
Validation loss: 2.106852344287339

Epoch: 396| Step: 0
Training loss: 2.0365304946899414
Validation loss: 2.152008507841377

Epoch: 5| Step: 1
Training loss: 1.7195463180541992
Validation loss: 2.1062156205536215

Epoch: 5| Step: 2
Training loss: 1.565060019493103
Validation loss: 2.1213091227316085

Epoch: 5| Step: 3
Training loss: 2.263033151626587
Validation loss: 2.0532930358763664

Epoch: 5| Step: 4
Training loss: 1.6729156970977783
Validation loss: 2.094147615535285

Epoch: 5| Step: 5
Training loss: 1.880454659461975
Validation loss: 2.122564451668852

Epoch: 5| Step: 6
Training loss: 1.9953094720840454
Validation loss: 2.02561842754323

Epoch: 5| Step: 7
Training loss: 1.669938325881958
Validation loss: 2.0575129780718076

Epoch: 5| Step: 8
Training loss: 1.9813032150268555
Validation loss: 2.1279299669368292

Epoch: 5| Step: 9
Training loss: 1.648716926574707
Validation loss: 2.053651846865172

Epoch: 5| Step: 10
Training loss: 1.5273637771606445
Validation loss: 2.1612796373264764

Epoch: 397| Step: 0
Training loss: 1.6531085968017578
Validation loss: 2.064136505126953

Epoch: 5| Step: 1
Training loss: 1.998491644859314
Validation loss: 2.0353202948006253

Epoch: 5| Step: 2
Training loss: 1.5483800172805786
Validation loss: 2.143225077659853

Epoch: 5| Step: 3
Training loss: 2.051712989807129
Validation loss: 2.0435861849015757

Epoch: 5| Step: 4
Training loss: 1.3957161903381348
Validation loss: 2.010830648483769

Epoch: 5| Step: 5
Training loss: 1.5167872905731201
Validation loss: 2.067638143416374

Epoch: 5| Step: 6
Training loss: 1.9249279499053955
Validation loss: 2.1006730653906382

Epoch: 5| Step: 7
Training loss: 2.2377471923828125
Validation loss: 2.119960331147717

Epoch: 5| Step: 8
Training loss: 1.9745715856552124
Validation loss: 2.0046324281282324

Epoch: 5| Step: 9
Training loss: 1.4389355182647705
Validation loss: 2.058997110653949

Epoch: 5| Step: 10
Training loss: 1.9270741939544678
Validation loss: 2.0734569795670046

Epoch: 398| Step: 0
Training loss: 1.4188127517700195
Validation loss: 2.095211846854097

Epoch: 5| Step: 1
Training loss: 1.628061056137085
Validation loss: 2.0841064030124294

Epoch: 5| Step: 2
Training loss: 1.847041130065918
Validation loss: 2.075289983903208

Epoch: 5| Step: 3
Training loss: 2.0690789222717285
Validation loss: 2.027868950238792

Epoch: 5| Step: 4
Training loss: 2.2846732139587402
Validation loss: 1.945437615917575

Epoch: 5| Step: 5
Training loss: 2.008002519607544
Validation loss: 1.93943912624031

Epoch: 5| Step: 6
Training loss: 2.00080943107605
Validation loss: 2.0381063299794353

Epoch: 5| Step: 7
Training loss: 1.9465923309326172
Validation loss: 2.0687849726728214

Epoch: 5| Step: 8
Training loss: 1.5196254253387451
Validation loss: 2.0927051472407516

Epoch: 5| Step: 9
Training loss: 1.4322681427001953
Validation loss: 2.1504244881291545

Epoch: 5| Step: 10
Training loss: 1.4270588159561157
Validation loss: 2.06603152777559

Epoch: 399| Step: 0
Training loss: 1.299785852432251
Validation loss: 2.066353779967113

Epoch: 5| Step: 1
Training loss: 1.9271799325942993
Validation loss: 2.05033298718032

Epoch: 5| Step: 2
Training loss: 1.7205874919891357
Validation loss: 2.1429815753813712

Epoch: 5| Step: 3
Training loss: 1.3534643650054932
Validation loss: 2.0457536225677817

Epoch: 5| Step: 4
Training loss: 1.5648576021194458
Validation loss: 1.985296969772667

Epoch: 5| Step: 5
Training loss: 1.7504408359527588
Validation loss: 2.191275429982011

Epoch: 5| Step: 6
Training loss: 1.9332475662231445
Validation loss: 2.0351196207026

Epoch: 5| Step: 7
Training loss: 1.5227938890457153
Validation loss: 2.097207958980273

Epoch: 5| Step: 8
Training loss: 1.667528748512268
Validation loss: 2.080520961874275

Epoch: 5| Step: 9
Training loss: 2.036113739013672
Validation loss: 2.0413261510992564

Epoch: 5| Step: 10
Training loss: 2.551298141479492
Validation loss: 2.0876895407194733

Epoch: 400| Step: 0
Training loss: 1.8579511642456055
Validation loss: 2.0880937409657303

Epoch: 5| Step: 1
Training loss: 2.0935616493225098
Validation loss: 2.0570325107984644

Epoch: 5| Step: 2
Training loss: 1.6111657619476318
Validation loss: 2.135780340881758

Epoch: 5| Step: 3
Training loss: 1.7215979099273682
Validation loss: 2.0430287879000426

Epoch: 5| Step: 4
Training loss: 2.157205104827881
Validation loss: 2.1361226650976364

Epoch: 5| Step: 5
Training loss: 1.4311403036117554
Validation loss: 2.0266432146872244

Epoch: 5| Step: 6
Training loss: 1.389031171798706
Validation loss: 2.001271795201045

Epoch: 5| Step: 7
Training loss: 2.1938223838806152
Validation loss: 2.036420460670225

Epoch: 5| Step: 8
Training loss: 2.091571092605591
Validation loss: 2.0961344780460482

Epoch: 5| Step: 9
Training loss: 1.6488841772079468
Validation loss: 2.0595799158978205

Epoch: 5| Step: 10
Training loss: 1.5962183475494385
Validation loss: 2.053555239913284

Epoch: 401| Step: 0
Training loss: 1.8611303567886353
Validation loss: 2.034206936436315

Epoch: 5| Step: 1
Training loss: 1.7746187448501587
Validation loss: 2.061447828046737

Epoch: 5| Step: 2
Training loss: 1.5778852701187134
Validation loss: 2.068842461032252

Epoch: 5| Step: 3
Training loss: 1.8649075031280518
Validation loss: 2.161869934810105

Epoch: 5| Step: 4
Training loss: 1.670395851135254
Validation loss: 2.0194197111232306

Epoch: 5| Step: 5
Training loss: 1.6185191869735718
Validation loss: 2.1222264330874205

Epoch: 5| Step: 6
Training loss: 1.8445816040039062
Validation loss: 2.1019528758141304

Epoch: 5| Step: 7
Training loss: 1.717633843421936
Validation loss: 2.0492790091422295

Epoch: 5| Step: 8
Training loss: 1.8923496007919312
Validation loss: 2.064507452390527

Epoch: 5| Step: 9
Training loss: 1.9994115829467773
Validation loss: 2.0575959374827724

Epoch: 5| Step: 10
Training loss: 2.109473705291748
Validation loss: 2.0638705838111138

Epoch: 402| Step: 0
Training loss: 1.6804640293121338
Validation loss: 2.1029042915631364

Epoch: 5| Step: 1
Training loss: 1.9075543880462646
Validation loss: 2.068288245508748

Epoch: 5| Step: 2
Training loss: 1.662989616394043
Validation loss: 2.022671873851489

Epoch: 5| Step: 3
Training loss: 2.081465244293213
Validation loss: 2.0362109381665467

Epoch: 5| Step: 4
Training loss: 1.6669038534164429
Validation loss: 2.1309018955435803

Epoch: 5| Step: 5
Training loss: 1.9484888315200806
Validation loss: 2.053894845388269

Epoch: 5| Step: 6
Training loss: 1.2328565120697021
Validation loss: 2.143530853333012

Epoch: 5| Step: 7
Training loss: 1.402484655380249
Validation loss: 2.0108740406651653

Epoch: 5| Step: 8
Training loss: 1.9154096841812134
Validation loss: 2.1106222086055304

Epoch: 5| Step: 9
Training loss: 1.5090281963348389
Validation loss: 2.0481825951606996

Epoch: 5| Step: 10
Training loss: 2.266885995864868
Validation loss: 2.1445488365747596

Epoch: 403| Step: 0
Training loss: 1.8202396631240845
Validation loss: 2.0652134136487077

Epoch: 5| Step: 1
Training loss: 1.3898446559906006
Validation loss: 2.1181652751020206

Epoch: 5| Step: 2
Training loss: 1.187944769859314
Validation loss: 2.092711628124278

Epoch: 5| Step: 3
Training loss: 1.6312910318374634
Validation loss: 2.0182449394656765

Epoch: 5| Step: 4
Training loss: 1.9997211694717407
Validation loss: 2.0319464719423683

Epoch: 5| Step: 5
Training loss: 1.2679836750030518
Validation loss: 2.082258075796148

Epoch: 5| Step: 6
Training loss: 2.449738025665283
Validation loss: 2.078753081701135

Epoch: 5| Step: 7
Training loss: 1.6019256114959717
Validation loss: 2.098485929991609

Epoch: 5| Step: 8
Training loss: 2.3692398071289062
Validation loss: 2.0071417535504987

Epoch: 5| Step: 9
Training loss: 2.105304002761841
Validation loss: 2.0577918919183875

Epoch: 5| Step: 10
Training loss: 1.8267450332641602
Validation loss: 2.0694684123480194

Epoch: 404| Step: 0
Training loss: 1.6093387603759766
Validation loss: 2.0919088343138337

Epoch: 5| Step: 1
Training loss: 2.1738452911376953
Validation loss: 2.014228097854122

Epoch: 5| Step: 2
Training loss: 1.7034289836883545
Validation loss: 2.0531457137036067

Epoch: 5| Step: 3
Training loss: 1.6496397256851196
Validation loss: 2.094102647996718

Epoch: 5| Step: 4
Training loss: 1.735166311264038
Validation loss: 2.0717576998536305

Epoch: 5| Step: 5
Training loss: 1.8328378200531006
Validation loss: 2.15192642647733

Epoch: 5| Step: 6
Training loss: 1.6966145038604736
Validation loss: 2.1158674737458587

Epoch: 5| Step: 7
Training loss: 2.1476988792419434
Validation loss: 2.1254675670336654

Epoch: 5| Step: 8
Training loss: 1.865382432937622
Validation loss: 2.0786025344684558

Epoch: 5| Step: 9
Training loss: 2.1135525703430176
Validation loss: 2.0333991486539125

Epoch: 5| Step: 10
Training loss: 0.983153760433197
Validation loss: 2.126079096589037

Epoch: 405| Step: 0
Training loss: 2.0440237522125244
Validation loss: 2.049882176101849

Epoch: 5| Step: 1
Training loss: 2.234759569168091
Validation loss: 2.1102058708026843

Epoch: 5| Step: 2
Training loss: 1.513397216796875
Validation loss: 2.1464140158827587

Epoch: 5| Step: 3
Training loss: 1.1993420124053955
Validation loss: 2.0728337495557723

Epoch: 5| Step: 4
Training loss: 1.694056749343872
Validation loss: 2.155003624577676

Epoch: 5| Step: 5
Training loss: 1.6458526849746704
Validation loss: 2.118176051365432

Epoch: 5| Step: 6
Training loss: 2.162010669708252
Validation loss: 2.030025374504828

Epoch: 5| Step: 7
Training loss: 1.9374701976776123
Validation loss: 2.106868995133267

Epoch: 5| Step: 8
Training loss: 1.4645851850509644
Validation loss: 2.2087967729055755

Epoch: 5| Step: 9
Training loss: 1.6300623416900635
Validation loss: 2.1420880094651253

Epoch: 5| Step: 10
Training loss: 1.8174384832382202
Validation loss: 2.0682283357907365

Epoch: 406| Step: 0
Training loss: 1.6099485158920288
Validation loss: 2.1185671847353698

Epoch: 5| Step: 1
Training loss: 1.2596861124038696
Validation loss: 2.055146663419662

Epoch: 5| Step: 2
Training loss: 1.6756842136383057
Validation loss: 2.08000769153718

Epoch: 5| Step: 3
Training loss: 2.209656238555908
Validation loss: 2.010666679310542

Epoch: 5| Step: 4
Training loss: 1.937321662902832
Validation loss: 1.970017574166739

Epoch: 5| Step: 5
Training loss: 2.1297340393066406
Validation loss: 2.0229795338005148

Epoch: 5| Step: 6
Training loss: 1.601091742515564
Validation loss: 2.0216848247794696

Epoch: 5| Step: 7
Training loss: 2.1029629707336426
Validation loss: 2.073117948347522

Epoch: 5| Step: 8
Training loss: 1.0747549533843994
Validation loss: 2.106470655369502

Epoch: 5| Step: 9
Training loss: 2.0411410331726074
Validation loss: 2.172861747844245

Epoch: 5| Step: 10
Training loss: 1.7110649347305298
Validation loss: 2.123489918247346

Epoch: 407| Step: 0
Training loss: 2.1709651947021484
Validation loss: 1.9933597169896609

Epoch: 5| Step: 1
Training loss: 1.6198879480361938
Validation loss: 2.1336824329950477

Epoch: 5| Step: 2
Training loss: 2.3176944255828857
Validation loss: 2.0525795875057096

Epoch: 5| Step: 3
Training loss: 2.2922420501708984
Validation loss: 2.040553372393372

Epoch: 5| Step: 4
Training loss: 1.6472219228744507
Validation loss: 1.9987445826171546

Epoch: 5| Step: 5
Training loss: 1.750035285949707
Validation loss: 2.02454182153107

Epoch: 5| Step: 6
Training loss: 1.6426112651824951
Validation loss: 2.1273441904334613

Epoch: 5| Step: 7
Training loss: 1.8835384845733643
Validation loss: 2.051072318066833

Epoch: 5| Step: 8
Training loss: 1.5954124927520752
Validation loss: 2.1480377463884253

Epoch: 5| Step: 9
Training loss: 1.7219547033309937
Validation loss: 2.0506307745492585

Epoch: 5| Step: 10
Training loss: 1.7575764656066895
Validation loss: 2.119417639188869

Epoch: 408| Step: 0
Training loss: 1.8240864276885986
Validation loss: 2.138099347391436

Epoch: 5| Step: 1
Training loss: 2.0584332942962646
Validation loss: 2.0834163260716263

Epoch: 5| Step: 2
Training loss: 1.5628966093063354
Validation loss: 2.0789942023574666

Epoch: 5| Step: 3
Training loss: 2.3368868827819824
Validation loss: 2.1533554292494252

Epoch: 5| Step: 4
Training loss: 1.7119601964950562
Validation loss: 2.213222147316061

Epoch: 5| Step: 5
Training loss: 1.5108287334442139
Validation loss: 2.0833765152961976

Epoch: 5| Step: 6
Training loss: 1.4190146923065186
Validation loss: 2.1154101125655638

Epoch: 5| Step: 7
Training loss: 1.6875728368759155
Validation loss: 1.9637783086428078

Epoch: 5| Step: 8
Training loss: 2.2277016639709473
Validation loss: 2.1670365282284316

Epoch: 5| Step: 9
Training loss: 1.4314044713974
Validation loss: 2.000010100744104

Epoch: 5| Step: 10
Training loss: 1.8293465375900269
Validation loss: 2.0868666325846026

Epoch: 409| Step: 0
Training loss: 1.6774314641952515
Validation loss: 2.136637515919183

Epoch: 5| Step: 1
Training loss: 1.716355562210083
Validation loss: 1.966353298515402

Epoch: 5| Step: 2
Training loss: 2.3414387702941895
Validation loss: 2.132927679246472

Epoch: 5| Step: 3
Training loss: 1.8916606903076172
Validation loss: 2.025356518324985

Epoch: 5| Step: 4
Training loss: 1.3209959268569946
Validation loss: 2.1730698257364254

Epoch: 5| Step: 5
Training loss: 2.55399489402771
Validation loss: 2.0886362111696632

Epoch: 5| Step: 6
Training loss: 1.5391899347305298
Validation loss: 1.9885804409621863

Epoch: 5| Step: 7
Training loss: 1.8424208164215088
Validation loss: 2.135905868263655

Epoch: 5| Step: 8
Training loss: 1.1584014892578125
Validation loss: 2.1381440495931976

Epoch: 5| Step: 9
Training loss: 1.6838276386260986
Validation loss: 2.093241055806478

Epoch: 5| Step: 10
Training loss: 1.7483493089675903
Validation loss: 2.06966951201039

Epoch: 410| Step: 0
Training loss: 2.250875473022461
Validation loss: 2.1708541967535533

Epoch: 5| Step: 1
Training loss: 1.8006130456924438
Validation loss: 2.105492518794152

Epoch: 5| Step: 2
Training loss: 1.701271414756775
Validation loss: 2.141166043537919

Epoch: 5| Step: 3
Training loss: 1.8012233972549438
Validation loss: 2.0078392515900316

Epoch: 5| Step: 4
Training loss: 1.4520900249481201
Validation loss: 2.0209315182060323

Epoch: 5| Step: 5
Training loss: 1.6682484149932861
Validation loss: 2.026872722051477

Epoch: 5| Step: 6
Training loss: 2.0542547702789307
Validation loss: 2.133866387028848

Epoch: 5| Step: 7
Training loss: 1.5231354236602783
Validation loss: 2.1097353068731164

Epoch: 5| Step: 8
Training loss: 1.328392744064331
Validation loss: 2.0548047506681053

Epoch: 5| Step: 9
Training loss: 1.845442533493042
Validation loss: 2.139010795982935

Epoch: 5| Step: 10
Training loss: 2.196460485458374
Validation loss: 2.104993361298756

Epoch: 411| Step: 0
Training loss: 1.563375473022461
Validation loss: 2.166305057464107

Epoch: 5| Step: 1
Training loss: 1.865288496017456
Validation loss: 2.0479655329899122

Epoch: 5| Step: 2
Training loss: 1.4255248308181763
Validation loss: 2.072071442040064

Epoch: 5| Step: 3
Training loss: 1.93534255027771
Validation loss: 2.1035641098535187

Epoch: 5| Step: 4
Training loss: 1.840955376625061
Validation loss: 2.1706617288692023

Epoch: 5| Step: 5
Training loss: 1.9622399806976318
Validation loss: 2.1546703205313733

Epoch: 5| Step: 6
Training loss: 1.1826592683792114
Validation loss: 2.066817598958169

Epoch: 5| Step: 7
Training loss: 2.02504825592041
Validation loss: 2.03979463987453

Epoch: 5| Step: 8
Training loss: 2.1852505207061768
Validation loss: 2.005787364898189

Epoch: 5| Step: 9
Training loss: 1.6375917196273804
Validation loss: 2.1214239828048216

Epoch: 5| Step: 10
Training loss: 1.908046007156372
Validation loss: 2.106649947422807

Epoch: 412| Step: 0
Training loss: 1.6281988620758057
Validation loss: 2.0852237081014984

Epoch: 5| Step: 1
Training loss: 2.401798725128174
Validation loss: 2.0542874041424004

Epoch: 5| Step: 2
Training loss: 2.031322956085205
Validation loss: 2.0508563851797454

Epoch: 5| Step: 3
Training loss: 1.7826836109161377
Validation loss: 2.0275617773814867

Epoch: 5| Step: 4
Training loss: 1.6699079275131226
Validation loss: 2.0336678989471926

Epoch: 5| Step: 5
Training loss: 1.6059376001358032
Validation loss: 2.146832496889176

Epoch: 5| Step: 6
Training loss: 1.3535053730010986
Validation loss: 2.0891280392164826

Epoch: 5| Step: 7
Training loss: 1.803235411643982
Validation loss: 2.0730831956350677

Epoch: 5| Step: 8
Training loss: 1.4043104648590088
Validation loss: 2.1208307922527356

Epoch: 5| Step: 9
Training loss: 1.778153657913208
Validation loss: 2.0035168663147958

Epoch: 5| Step: 10
Training loss: 1.933105230331421
Validation loss: 2.0492546327652468

Epoch: 413| Step: 0
Training loss: 1.3543775081634521
Validation loss: 2.081845209162722

Epoch: 5| Step: 1
Training loss: 1.5066059827804565
Validation loss: 2.084728871622393

Epoch: 5| Step: 2
Training loss: 1.981001615524292
Validation loss: 2.069876109400103

Epoch: 5| Step: 3
Training loss: 1.8335239887237549
Validation loss: 2.0086332521130963

Epoch: 5| Step: 4
Training loss: 1.387810230255127
Validation loss: 2.148679579457929

Epoch: 5| Step: 5
Training loss: 2.0706355571746826
Validation loss: 2.01551103720101

Epoch: 5| Step: 6
Training loss: 1.7956950664520264
Validation loss: 2.0196446577707925

Epoch: 5| Step: 7
Training loss: 1.935511827468872
Validation loss: 2.0764845109754995

Epoch: 5| Step: 8
Training loss: 1.5006039142608643
Validation loss: 2.120192027861072

Epoch: 5| Step: 9
Training loss: 2.0214028358459473
Validation loss: 2.0691026641476538

Epoch: 5| Step: 10
Training loss: 2.6172468662261963
Validation loss: 2.0414885884972027

Epoch: 414| Step: 0
Training loss: 0.9477105140686035
Validation loss: 2.15921845487369

Epoch: 5| Step: 1
Training loss: 1.6589301824569702
Validation loss: 2.0339316873140234

Epoch: 5| Step: 2
Training loss: 2.1378273963928223
Validation loss: 2.0918590022671606

Epoch: 5| Step: 3
Training loss: 2.188321352005005
Validation loss: 2.1166742411992883

Epoch: 5| Step: 4
Training loss: 1.8835792541503906
Validation loss: 2.040861701452604

Epoch: 5| Step: 5
Training loss: 1.8081080913543701
Validation loss: 1.9395958274923346

Epoch: 5| Step: 6
Training loss: 1.948569655418396
Validation loss: 2.0619922004720217

Epoch: 5| Step: 7
Training loss: 1.732744574546814
Validation loss: 2.010191317527525

Epoch: 5| Step: 8
Training loss: 2.3360931873321533
Validation loss: 2.0137183332955964

Epoch: 5| Step: 9
Training loss: 1.8757139444351196
Validation loss: 2.12430138485406

Epoch: 5| Step: 10
Training loss: 0.9786376953125
Validation loss: 2.113544782002767

Epoch: 415| Step: 0
Training loss: 1.6130478382110596
Validation loss: 2.0598118843570834

Epoch: 5| Step: 1
Training loss: 1.930432915687561
Validation loss: 2.0346205542164464

Epoch: 5| Step: 2
Training loss: 1.9898525476455688
Validation loss: 2.0625036442151634

Epoch: 5| Step: 3
Training loss: 1.8727829456329346
Validation loss: 2.0876743383305048

Epoch: 5| Step: 4
Training loss: 1.7666298151016235
Validation loss: 2.108279228210449

Epoch: 5| Step: 5
Training loss: 1.931174874305725
Validation loss: 2.1276356302281862

Epoch: 5| Step: 6
Training loss: 2.201247453689575
Validation loss: 2.1957666374021962

Epoch: 5| Step: 7
Training loss: 1.9723670482635498
Validation loss: 2.1401106362701743

Epoch: 5| Step: 8
Training loss: 1.4612665176391602
Validation loss: 2.024443011130056

Epoch: 5| Step: 9
Training loss: 1.8006761074066162
Validation loss: 2.1067543183603594

Epoch: 5| Step: 10
Training loss: 1.3501609563827515
Validation loss: 2.1350587285974973

Epoch: 416| Step: 0
Training loss: 2.2730138301849365
Validation loss: 2.0152318964722338

Epoch: 5| Step: 1
Training loss: 1.7632131576538086
Validation loss: 2.1083865422074513

Epoch: 5| Step: 2
Training loss: 1.356501817703247
Validation loss: 2.026080193058137

Epoch: 5| Step: 3
Training loss: 1.5641556978225708
Validation loss: 2.091076816281965

Epoch: 5| Step: 4
Training loss: 2.292375087738037
Validation loss: 2.0296642857213176

Epoch: 5| Step: 5
Training loss: 1.7078250646591187
Validation loss: 2.0348669252087994

Epoch: 5| Step: 6
Training loss: 1.9438196420669556
Validation loss: 2.0429572905263593

Epoch: 5| Step: 7
Training loss: 1.9093879461288452
Validation loss: 2.1270673044266237

Epoch: 5| Step: 8
Training loss: 1.4572993516921997
Validation loss: 1.9916423418188607

Epoch: 5| Step: 9
Training loss: 1.6896299123764038
Validation loss: 2.070534126732939

Epoch: 5| Step: 10
Training loss: 2.1386749744415283
Validation loss: 1.9927766015452724

Epoch: 417| Step: 0
Training loss: 1.199209451675415
Validation loss: 2.006516445067621

Epoch: 5| Step: 1
Training loss: 1.9610576629638672
Validation loss: 2.0954147667013188

Epoch: 5| Step: 2
Training loss: 2.200761318206787
Validation loss: 2.0705767293130197

Epoch: 5| Step: 3
Training loss: 1.3319194316864014
Validation loss: 2.0740890246565624

Epoch: 5| Step: 4
Training loss: 1.6325448751449585
Validation loss: 1.970914129287966

Epoch: 5| Step: 5
Training loss: 1.5519342422485352
Validation loss: 2.1749833617159116

Epoch: 5| Step: 6
Training loss: 1.9677743911743164
Validation loss: 1.990178931143976

Epoch: 5| Step: 7
Training loss: 1.4907859563827515
Validation loss: 1.9957303116398473

Epoch: 5| Step: 8
Training loss: 1.6007277965545654
Validation loss: 1.990378325985324

Epoch: 5| Step: 9
Training loss: 1.4852176904678345
Validation loss: 2.2127526216609503

Epoch: 5| Step: 10
Training loss: 2.2292563915252686
Validation loss: 2.054431305136732

Epoch: 418| Step: 0
Training loss: 1.5418285131454468
Validation loss: 2.015699073832522

Epoch: 5| Step: 1
Training loss: 2.19250750541687
Validation loss: 2.00949848980032

Epoch: 5| Step: 2
Training loss: 2.149646759033203
Validation loss: 2.0417007143779466

Epoch: 5| Step: 3
Training loss: 1.6058193445205688
Validation loss: 2.0399868872857865

Epoch: 5| Step: 4
Training loss: 1.2888147830963135
Validation loss: 2.1454532915546047

Epoch: 5| Step: 5
Training loss: 1.556591272354126
Validation loss: 2.01710666507803

Epoch: 5| Step: 6
Training loss: 1.957193374633789
Validation loss: 2.1271217176991124

Epoch: 5| Step: 7
Training loss: 1.6500526666641235
Validation loss: 2.033571252258875

Epoch: 5| Step: 8
Training loss: 1.5786867141723633
Validation loss: 2.0496775373335807

Epoch: 5| Step: 9
Training loss: 1.7596290111541748
Validation loss: 2.08324545814145

Epoch: 5| Step: 10
Training loss: 2.0218026638031006
Validation loss: 2.0347086229631977

Epoch: 419| Step: 0
Training loss: 1.9278676509857178
Validation loss: 1.9787784212379045

Epoch: 5| Step: 1
Training loss: 1.6222188472747803
Validation loss: 2.080277419859363

Epoch: 5| Step: 2
Training loss: 1.8746109008789062
Validation loss: 2.046388191561545

Epoch: 5| Step: 3
Training loss: 1.5120279788970947
Validation loss: 2.0872992187417965

Epoch: 5| Step: 4
Training loss: 1.9273483753204346
Validation loss: 1.9702362937311972

Epoch: 5| Step: 5
Training loss: 2.2982163429260254
Validation loss: 2.0447083596260316

Epoch: 5| Step: 6
Training loss: 1.5941756963729858
Validation loss: 1.9958320945821784

Epoch: 5| Step: 7
Training loss: 1.8251793384552002
Validation loss: 2.033954543452109

Epoch: 5| Step: 8
Training loss: 2.0462868213653564
Validation loss: 2.080180605252584

Epoch: 5| Step: 9
Training loss: 1.9798336029052734
Validation loss: 2.0527378512967016

Epoch: 5| Step: 10
Training loss: 1.3035155534744263
Validation loss: 2.1159215088813537

Epoch: 420| Step: 0
Training loss: 1.7848832607269287
Validation loss: 2.073244934440941

Epoch: 5| Step: 1
Training loss: 1.602196455001831
Validation loss: 2.044744332631429

Epoch: 5| Step: 2
Training loss: 2.112668991088867
Validation loss: 2.0159649631028533

Epoch: 5| Step: 3
Training loss: 1.1626732349395752
Validation loss: 2.060578651325677

Epoch: 5| Step: 4
Training loss: 1.6753501892089844
Validation loss: 2.080391671067925

Epoch: 5| Step: 5
Training loss: 1.4265546798706055
Validation loss: 2.084282241841798

Epoch: 5| Step: 6
Training loss: 1.850076675415039
Validation loss: 2.001959946847731

Epoch: 5| Step: 7
Training loss: 2.300686836242676
Validation loss: 1.975690669910882

Epoch: 5| Step: 8
Training loss: 1.568414330482483
Validation loss: 2.029727574317686

Epoch: 5| Step: 9
Training loss: 1.6797195672988892
Validation loss: 2.0438933564770605

Epoch: 5| Step: 10
Training loss: 2.0618865489959717
Validation loss: 2.08688614701712

Epoch: 421| Step: 0
Training loss: 1.4987571239471436
Validation loss: 2.0528033561603998

Epoch: 5| Step: 1
Training loss: 1.5754319429397583
Validation loss: 2.107767790876409

Epoch: 5| Step: 2
Training loss: 1.8956718444824219
Validation loss: 2.1258651851325907

Epoch: 5| Step: 3
Training loss: 1.9319404363632202
Validation loss: 2.0250247396448606

Epoch: 5| Step: 4
Training loss: 1.0538746118545532
Validation loss: 2.085282107835175

Epoch: 5| Step: 5
Training loss: 1.8051059246063232
Validation loss: 2.0613881182926956

Epoch: 5| Step: 6
Training loss: 1.7109479904174805
Validation loss: 2.02395805235832

Epoch: 5| Step: 7
Training loss: 1.8620716333389282
Validation loss: 2.1217395592761297

Epoch: 5| Step: 8
Training loss: 1.6276495456695557
Validation loss: 2.0137258037444083

Epoch: 5| Step: 9
Training loss: 1.900184988975525
Validation loss: 2.0196409225463867

Epoch: 5| Step: 10
Training loss: 2.5084035396575928
Validation loss: 2.039661575389165

Epoch: 422| Step: 0
Training loss: 1.920408844947815
Validation loss: 2.1049437215251308

Epoch: 5| Step: 1
Training loss: 1.8167378902435303
Validation loss: 2.0839353299910024

Epoch: 5| Step: 2
Training loss: 1.402821660041809
Validation loss: 2.0308312882659254

Epoch: 5| Step: 3
Training loss: 2.037736415863037
Validation loss: 2.056289619015109

Epoch: 5| Step: 4
Training loss: 1.7089478969573975
Validation loss: 1.9614036083221436

Epoch: 5| Step: 5
Training loss: 1.6258277893066406
Validation loss: 2.1258841355641684

Epoch: 5| Step: 6
Training loss: 1.6985280513763428
Validation loss: 2.058421278512606

Epoch: 5| Step: 7
Training loss: 1.9325990676879883
Validation loss: 2.1579934704688286

Epoch: 5| Step: 8
Training loss: 2.013892650604248
Validation loss: 2.1104040197146836

Epoch: 5| Step: 9
Training loss: 1.9975160360336304
Validation loss: 2.1475530580807756

Epoch: 5| Step: 10
Training loss: 1.3940562009811401
Validation loss: 2.14655133985704

Epoch: 423| Step: 0
Training loss: 1.2482995986938477
Validation loss: 2.1019165144171765

Epoch: 5| Step: 1
Training loss: 1.8078041076660156
Validation loss: 2.1342534916375273

Epoch: 5| Step: 2
Training loss: 1.6846673488616943
Validation loss: 2.109969236517465

Epoch: 5| Step: 3
Training loss: 2.558037519454956
Validation loss: 2.0308969379753194

Epoch: 5| Step: 4
Training loss: 1.6492664813995361
Validation loss: 2.1372102088825677

Epoch: 5| Step: 5
Training loss: 1.2589035034179688
Validation loss: 2.096623255360511

Epoch: 5| Step: 6
Training loss: 1.7388805150985718
Validation loss: 2.106298428709789

Epoch: 5| Step: 7
Training loss: 2.1624603271484375
Validation loss: 2.1063638989643385

Epoch: 5| Step: 8
Training loss: 1.233835220336914
Validation loss: 2.0444649611749957

Epoch: 5| Step: 9
Training loss: 1.6664730310440063
Validation loss: 2.0600613547909643

Epoch: 5| Step: 10
Training loss: 1.6520166397094727
Validation loss: 2.1558363335106963

Epoch: 424| Step: 0
Training loss: 1.5463908910751343
Validation loss: 1.9619682219720656

Epoch: 5| Step: 1
Training loss: 1.5244340896606445
Validation loss: 2.0975639845735286

Epoch: 5| Step: 2
Training loss: 2.0465595722198486
Validation loss: 2.015994446251982

Epoch: 5| Step: 3
Training loss: 1.7983840703964233
Validation loss: 2.085492190494332

Epoch: 5| Step: 4
Training loss: 1.7548564672470093
Validation loss: 2.1855715167137886

Epoch: 5| Step: 5
Training loss: 1.8924707174301147
Validation loss: 2.0702195244450725

Epoch: 5| Step: 6
Training loss: 2.149658203125
Validation loss: 2.140127690889502

Epoch: 5| Step: 7
Training loss: 1.3547693490982056
Validation loss: 2.1070409538925334

Epoch: 5| Step: 8
Training loss: 1.8934967517852783
Validation loss: 2.0356215482117026

Epoch: 5| Step: 9
Training loss: 1.8315092325210571
Validation loss: 2.202521842013123

Epoch: 5| Step: 10
Training loss: 1.7148619890213013
Validation loss: 2.0267155311440908

Epoch: 425| Step: 0
Training loss: 1.7223949432373047
Validation loss: 2.1312547140224005

Epoch: 5| Step: 1
Training loss: 1.1387255191802979
Validation loss: 2.2359532669026363

Epoch: 5| Step: 2
Training loss: 1.3518754243850708
Validation loss: 2.0877370398531676

Epoch: 5| Step: 3
Training loss: 1.884093999862671
Validation loss: 2.0546392779196463

Epoch: 5| Step: 4
Training loss: 2.481703281402588
Validation loss: 2.17404201082004

Epoch: 5| Step: 5
Training loss: 1.5408891439437866
Validation loss: 2.0538885029413367

Epoch: 5| Step: 6
Training loss: 1.8952707052230835
Validation loss: 2.0659712924752185

Epoch: 5| Step: 7
Training loss: 2.395106554031372
Validation loss: 2.1648220939020955

Epoch: 5| Step: 8
Training loss: 1.8515613079071045
Validation loss: 2.108872475162629

Epoch: 5| Step: 9
Training loss: 1.6675808429718018
Validation loss: 2.196713218124964

Epoch: 5| Step: 10
Training loss: 1.4789748191833496
Validation loss: 2.0984394627232708

Epoch: 426| Step: 0
Training loss: 1.809258222579956
Validation loss: 2.06464187688725

Epoch: 5| Step: 1
Training loss: 1.8561804294586182
Validation loss: 2.0193714877610565

Epoch: 5| Step: 2
Training loss: 1.6955957412719727
Validation loss: 2.1114754548636814

Epoch: 5| Step: 3
Training loss: 2.259525775909424
Validation loss: 2.1673796510183685

Epoch: 5| Step: 4
Training loss: 2.169658899307251
Validation loss: 2.1264859117487425

Epoch: 5| Step: 5
Training loss: 1.5058923959732056
Validation loss: 2.0908215315111223

Epoch: 5| Step: 6
Training loss: 1.5071834325790405
Validation loss: 2.174940057980117

Epoch: 5| Step: 7
Training loss: 2.0225794315338135
Validation loss: 2.0884566935159827

Epoch: 5| Step: 8
Training loss: 1.4901068210601807
Validation loss: 2.037476654975645

Epoch: 5| Step: 9
Training loss: 1.4894115924835205
Validation loss: 2.068023940568329

Epoch: 5| Step: 10
Training loss: 1.6362022161483765
Validation loss: 2.155825057337361

Epoch: 427| Step: 0
Training loss: 1.7558122873306274
Validation loss: 2.0914573925797657

Epoch: 5| Step: 1
Training loss: 1.8919528722763062
Validation loss: 2.1869578053874354

Epoch: 5| Step: 2
Training loss: 2.003316879272461
Validation loss: 2.1153976507084344

Epoch: 5| Step: 3
Training loss: 1.741135597229004
Validation loss: 2.137890185079267

Epoch: 5| Step: 4
Training loss: 1.4755016565322876
Validation loss: 2.043135045677103

Epoch: 5| Step: 5
Training loss: 1.8602819442749023
Validation loss: 2.0753111429111932

Epoch: 5| Step: 6
Training loss: 1.6553913354873657
Validation loss: 1.9899612908722253

Epoch: 5| Step: 7
Training loss: 1.8063628673553467
Validation loss: 2.1369379656289214

Epoch: 5| Step: 8
Training loss: 1.7994464635849
Validation loss: 2.1143599928066297

Epoch: 5| Step: 9
Training loss: 1.4257383346557617
Validation loss: 2.0837380693804834

Epoch: 5| Step: 10
Training loss: 2.2238495349884033
Validation loss: 2.138322171344552

Epoch: 428| Step: 0
Training loss: 1.466531753540039
Validation loss: 2.1357813240379415

Epoch: 5| Step: 1
Training loss: 1.9039125442504883
Validation loss: 2.1342776693323606

Epoch: 5| Step: 2
Training loss: 2.4260945320129395
Validation loss: 2.010134102195822

Epoch: 5| Step: 3
Training loss: 1.8111774921417236
Validation loss: 2.0840110624990156

Epoch: 5| Step: 4
Training loss: 1.4508172273635864
Validation loss: 2.0648830424072924

Epoch: 5| Step: 5
Training loss: 1.874866247177124
Validation loss: 2.056599937459474

Epoch: 5| Step: 6
Training loss: 1.917588233947754
Validation loss: 2.050099306209113

Epoch: 5| Step: 7
Training loss: 1.3639593124389648
Validation loss: 2.116802515522126

Epoch: 5| Step: 8
Training loss: 2.276927947998047
Validation loss: 2.0475686724467943

Epoch: 5| Step: 9
Training loss: 1.624564528465271
Validation loss: 1.9506045490182855

Epoch: 5| Step: 10
Training loss: 1.7245149612426758
Validation loss: 2.1739697892178773

Epoch: 429| Step: 0
Training loss: 1.970436453819275
Validation loss: 2.1450177264469925

Epoch: 5| Step: 1
Training loss: 1.7427995204925537
Validation loss: 2.197233792274229

Epoch: 5| Step: 2
Training loss: 1.9311764240264893
Validation loss: 2.0145888290097638

Epoch: 5| Step: 3
Training loss: 1.9400581121444702
Validation loss: 1.9998337530320691

Epoch: 5| Step: 4
Training loss: 1.6464290618896484
Validation loss: 2.095244369199199

Epoch: 5| Step: 5
Training loss: 1.6960722208023071
Validation loss: 2.1759720104996876

Epoch: 5| Step: 6
Training loss: 1.7463184595108032
Validation loss: 1.9972845623570104

Epoch: 5| Step: 7
Training loss: 1.7433643341064453
Validation loss: 2.155156071468066

Epoch: 5| Step: 8
Training loss: 2.157203197479248
Validation loss: 2.08139625159643

Epoch: 5| Step: 9
Training loss: 1.7134205102920532
Validation loss: 2.0458656459726314

Epoch: 5| Step: 10
Training loss: 1.1558557748794556
Validation loss: 2.034663499042552

Epoch: 430| Step: 0
Training loss: 1.5508638620376587
Validation loss: 2.038330799789839

Epoch: 5| Step: 1
Training loss: 1.6634324789047241
Validation loss: 2.1156244008771834

Epoch: 5| Step: 2
Training loss: 1.6717478036880493
Validation loss: 2.124006958417995

Epoch: 5| Step: 3
Training loss: 1.568895697593689
Validation loss: 2.1190866065281693

Epoch: 5| Step: 4
Training loss: 1.7441085577011108
Validation loss: 2.0858046726513932

Epoch: 5| Step: 5
Training loss: 1.5393116474151611
Validation loss: 2.086309914947838

Epoch: 5| Step: 6
Training loss: 2.3685340881347656
Validation loss: 2.1312762844947075

Epoch: 5| Step: 7
Training loss: 2.196509838104248
Validation loss: 2.143596590206187

Epoch: 5| Step: 8
Training loss: 1.8270204067230225
Validation loss: 2.0807407107404483

Epoch: 5| Step: 9
Training loss: 1.9138681888580322
Validation loss: 2.0804022665946715

Epoch: 5| Step: 10
Training loss: 1.6477352380752563
Validation loss: 2.045018793434225

Epoch: 431| Step: 0
Training loss: 1.5460541248321533
Validation loss: 2.0281890925540718

Epoch: 5| Step: 1
Training loss: 1.6362035274505615
Validation loss: 2.060449138764412

Epoch: 5| Step: 2
Training loss: 1.4618134498596191
Validation loss: 2.019097625568349

Epoch: 5| Step: 3
Training loss: 1.601617455482483
Validation loss: 2.0557441198697655

Epoch: 5| Step: 4
Training loss: 1.8691589832305908
Validation loss: 2.187252011350406

Epoch: 5| Step: 5
Training loss: 1.735411286354065
Validation loss: 2.1111400717048237

Epoch: 5| Step: 6
Training loss: 1.6823174953460693
Validation loss: 2.0391300519307456

Epoch: 5| Step: 7
Training loss: 2.1512818336486816
Validation loss: 2.1464253138470393

Epoch: 5| Step: 8
Training loss: 1.5592129230499268
Validation loss: 2.1165020952942553

Epoch: 5| Step: 9
Training loss: 1.7388479709625244
Validation loss: 2.1259475343970844

Epoch: 5| Step: 10
Training loss: 2.2759969234466553
Validation loss: 2.10471111471935

Epoch: 432| Step: 0
Training loss: 2.014791965484619
Validation loss: 2.064820155020683

Epoch: 5| Step: 1
Training loss: 1.569117546081543
Validation loss: 2.1007142784774944

Epoch: 5| Step: 2
Training loss: 1.3631536960601807
Validation loss: 1.9865242511995378

Epoch: 5| Step: 3
Training loss: 2.0069758892059326
Validation loss: 2.067604875051847

Epoch: 5| Step: 4
Training loss: 1.9123668670654297
Validation loss: 2.065833350663544

Epoch: 5| Step: 5
Training loss: 1.5003132820129395
Validation loss: 2.0267083849958194

Epoch: 5| Step: 6
Training loss: 1.6003926992416382
Validation loss: 2.0783310885070474

Epoch: 5| Step: 7
Training loss: 2.481759548187256
Validation loss: 2.0813294738851567

Epoch: 5| Step: 8
Training loss: 1.421486496925354
Validation loss: 2.1650851541949856

Epoch: 5| Step: 9
Training loss: 1.6829965114593506
Validation loss: 2.0639513641275387

Epoch: 5| Step: 10
Training loss: 1.4327296018600464
Validation loss: 2.154557743380147

Epoch: 433| Step: 0
Training loss: 1.7386013269424438
Validation loss: 2.155047027013635

Epoch: 5| Step: 1
Training loss: 1.4519416093826294
Validation loss: 2.0228291955045474

Epoch: 5| Step: 2
Training loss: 1.7715152502059937
Validation loss: 2.1501268315058883

Epoch: 5| Step: 3
Training loss: 1.5814529657363892
Validation loss: 2.0868526261339904

Epoch: 5| Step: 4
Training loss: 2.0733580589294434
Validation loss: 2.076835952779298

Epoch: 5| Step: 5
Training loss: 2.1708991527557373
Validation loss: 2.117662537482477

Epoch: 5| Step: 6
Training loss: 1.7000477313995361
Validation loss: 2.0161680739413024

Epoch: 5| Step: 7
Training loss: 1.9279762506484985
Validation loss: 2.0120934414607223

Epoch: 5| Step: 8
Training loss: 1.2885501384735107
Validation loss: 2.1208056813927105

Epoch: 5| Step: 9
Training loss: 1.6240087747573853
Validation loss: 2.0402568911993377

Epoch: 5| Step: 10
Training loss: 1.2539972066879272
Validation loss: 2.0257953943744784

Epoch: 434| Step: 0
Training loss: 1.7751615047454834
Validation loss: 2.1781227024652625

Epoch: 5| Step: 1
Training loss: 1.985653281211853
Validation loss: 2.103496361804265

Epoch: 5| Step: 2
Training loss: 1.816087007522583
Validation loss: 2.09560138692138

Epoch: 5| Step: 3
Training loss: 1.768256425857544
Validation loss: 2.0752641975238757

Epoch: 5| Step: 4
Training loss: 1.6947696208953857
Validation loss: 2.088117443105226

Epoch: 5| Step: 5
Training loss: 2.2513036727905273
Validation loss: 2.0759232736402944

Epoch: 5| Step: 6
Training loss: 1.3790961503982544
Validation loss: 2.078760931568761

Epoch: 5| Step: 7
Training loss: 1.948322057723999
Validation loss: 2.0088959868236254

Epoch: 5| Step: 8
Training loss: 1.8908889293670654
Validation loss: 2.0653639172994964

Epoch: 5| Step: 9
Training loss: 1.5300281047821045
Validation loss: 2.144384199573148

Epoch: 5| Step: 10
Training loss: 1.42985999584198
Validation loss: 1.9828799463087512

Epoch: 435| Step: 0
Training loss: 1.527036428451538
Validation loss: 2.0355592748170257

Epoch: 5| Step: 1
Training loss: 1.2012672424316406
Validation loss: 2.045183386853946

Epoch: 5| Step: 2
Training loss: 2.859724521636963
Validation loss: 2.089593836056289

Epoch: 5| Step: 3
Training loss: 1.5288101434707642
Validation loss: 2.0532668354690715

Epoch: 5| Step: 4
Training loss: 1.6237666606903076
Validation loss: 2.0587795062731673

Epoch: 5| Step: 5
Training loss: 1.5775668621063232
Validation loss: 2.1404233158275647

Epoch: 5| Step: 6
Training loss: 2.7014265060424805
Validation loss: 2.0511365834102837

Epoch: 5| Step: 7
Training loss: 1.2720822095870972
Validation loss: 2.2040344284426783

Epoch: 5| Step: 8
Training loss: 1.2227791547775269
Validation loss: 2.0335580469459615

Epoch: 5| Step: 9
Training loss: 1.4651460647583008
Validation loss: 2.140038962005287

Epoch: 5| Step: 10
Training loss: 2.2010457515716553
Validation loss: 2.0602346825343307

Epoch: 436| Step: 0
Training loss: 1.2021331787109375
Validation loss: 2.114160071137131

Epoch: 5| Step: 1
Training loss: 2.525599956512451
Validation loss: 2.197082927150111

Epoch: 5| Step: 2
Training loss: 1.6307373046875
Validation loss: 2.034537505078059

Epoch: 5| Step: 3
Training loss: 1.5388586521148682
Validation loss: 2.145160549430437

Epoch: 5| Step: 4
Training loss: 1.6902663707733154
Validation loss: 2.1459294749844458

Epoch: 5| Step: 5
Training loss: 2.1249969005584717
Validation loss: 2.0712472943849463

Epoch: 5| Step: 6
Training loss: 1.6285146474838257
Validation loss: 2.223891568440263

Epoch: 5| Step: 7
Training loss: 1.689743995666504
Validation loss: 2.177607064606041

Epoch: 5| Step: 8
Training loss: 2.0683746337890625
Validation loss: 2.1722203198299614

Epoch: 5| Step: 9
Training loss: 1.871883749961853
Validation loss: 2.1614846491044566

Epoch: 5| Step: 10
Training loss: 1.625482439994812
Validation loss: 2.081886656822697

Epoch: 437| Step: 0
Training loss: 1.313320279121399
Validation loss: 2.0583397880677254

Epoch: 5| Step: 1
Training loss: 1.475888967514038
Validation loss: 2.173079349661386

Epoch: 5| Step: 2
Training loss: 1.2795612812042236
Validation loss: 1.9776674957685574

Epoch: 5| Step: 3
Training loss: 1.5549509525299072
Validation loss: 2.0650860648001395

Epoch: 5| Step: 4
Training loss: 1.3703501224517822
Validation loss: 1.9851696580968878

Epoch: 5| Step: 5
Training loss: 2.0649938583374023
Validation loss: 2.0862369921899613

Epoch: 5| Step: 6
Training loss: 2.1813366413116455
Validation loss: 2.120161671792307

Epoch: 5| Step: 7
Training loss: 2.399384021759033
Validation loss: 2.159701798551826

Epoch: 5| Step: 8
Training loss: 1.9236400127410889
Validation loss: 2.0509422979047223

Epoch: 5| Step: 9
Training loss: 1.4523471593856812
Validation loss: 1.9868183776896486

Epoch: 5| Step: 10
Training loss: 2.1141533851623535
Validation loss: 2.0490724143161567

Epoch: 438| Step: 0
Training loss: 1.916438102722168
Validation loss: 2.0699269438302643

Epoch: 5| Step: 1
Training loss: 1.5394151210784912
Validation loss: 2.1502859028436805

Epoch: 5| Step: 2
Training loss: 1.9927489757537842
Validation loss: 2.0874865798540014

Epoch: 5| Step: 3
Training loss: 1.2724835872650146
Validation loss: 2.1509528390822874

Epoch: 5| Step: 4
Training loss: 1.2493369579315186
Validation loss: 2.1506258608192526

Epoch: 5| Step: 5
Training loss: 1.923147201538086
Validation loss: 2.1068488038996214

Epoch: 5| Step: 6
Training loss: 1.2325059175491333
Validation loss: 2.0497482566423315

Epoch: 5| Step: 7
Training loss: 1.9370319843292236
Validation loss: 2.1011447573220856

Epoch: 5| Step: 8
Training loss: 2.4314424991607666
Validation loss: 2.1281652912016837

Epoch: 5| Step: 9
Training loss: 2.191671133041382
Validation loss: 1.9509380812286048

Epoch: 5| Step: 10
Training loss: 1.5913753509521484
Validation loss: 2.142089800168109

Epoch: 439| Step: 0
Training loss: 1.842877745628357
Validation loss: 2.0312086946220806

Epoch: 5| Step: 1
Training loss: 1.6662324666976929
Validation loss: 2.0719048335988033

Epoch: 5| Step: 2
Training loss: 2.0061869621276855
Validation loss: 2.012932462076987

Epoch: 5| Step: 3
Training loss: 1.894313097000122
Validation loss: 2.125208382965416

Epoch: 5| Step: 4
Training loss: 1.6963602304458618
Validation loss: 1.9698626892541045

Epoch: 5| Step: 5
Training loss: 1.6905170679092407
Validation loss: 2.1344570498312674

Epoch: 5| Step: 6
Training loss: 1.412307620048523
Validation loss: 2.0282567983032553

Epoch: 5| Step: 7
Training loss: 1.8420575857162476
Validation loss: 2.142820019875803

Epoch: 5| Step: 8
Training loss: 1.972926378250122
Validation loss: 2.0808579742267566

Epoch: 5| Step: 9
Training loss: 1.809678316116333
Validation loss: 2.1015712163781606

Epoch: 5| Step: 10
Training loss: 1.8340318202972412
Validation loss: 2.1113336291364444

Epoch: 440| Step: 0
Training loss: 1.9988734722137451
Validation loss: 2.1071309415243005

Epoch: 5| Step: 1
Training loss: 1.3683414459228516
Validation loss: 2.0469523078651837

Epoch: 5| Step: 2
Training loss: 1.5092639923095703
Validation loss: 2.0813166928547684

Epoch: 5| Step: 3
Training loss: 2.455597400665283
Validation loss: 2.069348450629942

Epoch: 5| Step: 4
Training loss: 1.5033975839614868
Validation loss: 2.1070352446648384

Epoch: 5| Step: 5
Training loss: 1.5585711002349854
Validation loss: 2.1095249986135833

Epoch: 5| Step: 6
Training loss: 2.0396695137023926
Validation loss: 2.1840190784905547

Epoch: 5| Step: 7
Training loss: 2.0898680686950684
Validation loss: 2.0152800954798216

Epoch: 5| Step: 8
Training loss: 1.5941094160079956
Validation loss: 2.0824696851033035

Epoch: 5| Step: 9
Training loss: 1.4198179244995117
Validation loss: 2.1579854539645615

Epoch: 5| Step: 10
Training loss: 1.8690381050109863
Validation loss: 2.0750574681066696

Epoch: 441| Step: 0
Training loss: 1.4432179927825928
Validation loss: 2.085472527370658

Epoch: 5| Step: 1
Training loss: 1.8918365240097046
Validation loss: 2.122371437729046

Epoch: 5| Step: 2
Training loss: 1.8116455078125
Validation loss: 2.0852884566912087

Epoch: 5| Step: 3
Training loss: 1.7439483404159546
Validation loss: 2.0872798555640766

Epoch: 5| Step: 4
Training loss: 2.2521138191223145
Validation loss: 2.0210522708072456

Epoch: 5| Step: 5
Training loss: 1.240944743156433
Validation loss: 2.0655954319943666

Epoch: 5| Step: 6
Training loss: 1.3184607028961182
Validation loss: 2.0246963654795

Epoch: 5| Step: 7
Training loss: 1.677178978919983
Validation loss: 2.0444479937194497

Epoch: 5| Step: 8
Training loss: 2.339279890060425
Validation loss: 2.04638409614563

Epoch: 5| Step: 9
Training loss: 1.734300971031189
Validation loss: 2.109954377656342

Epoch: 5| Step: 10
Training loss: 1.8917564153671265
Validation loss: 2.0121627392307406

Epoch: 442| Step: 0
Training loss: 1.3132230043411255
Validation loss: 2.0440369677800003

Epoch: 5| Step: 1
Training loss: 1.6746101379394531
Validation loss: 1.963981338726577

Epoch: 5| Step: 2
Training loss: 1.4213073253631592
Validation loss: 2.076902392090008

Epoch: 5| Step: 3
Training loss: 1.4899590015411377
Validation loss: 1.996277597642714

Epoch: 5| Step: 4
Training loss: 2.5983715057373047
Validation loss: 2.0886502676112677

Epoch: 5| Step: 5
Training loss: 2.118806838989258
Validation loss: 2.1568169952720724

Epoch: 5| Step: 6
Training loss: 1.5959665775299072
Validation loss: 2.0741078212697017

Epoch: 5| Step: 7
Training loss: 1.7431221008300781
Validation loss: 2.037069856479604

Epoch: 5| Step: 8
Training loss: 1.809322714805603
Validation loss: 1.947041831990724

Epoch: 5| Step: 9
Training loss: 1.6539732217788696
Validation loss: 2.045747956921977

Epoch: 5| Step: 10
Training loss: 1.410974383354187
Validation loss: 2.1047705758002495

Epoch: 443| Step: 0
Training loss: 1.3147461414337158
Validation loss: 2.130298296610514

Epoch: 5| Step: 1
Training loss: 1.4615240097045898
Validation loss: 2.0891414791025142

Epoch: 5| Step: 2
Training loss: 2.2860934734344482
Validation loss: 2.1030855127560195

Epoch: 5| Step: 3
Training loss: 1.5282890796661377
Validation loss: 2.088497038810484

Epoch: 5| Step: 4
Training loss: 2.26314377784729
Validation loss: 2.057141001506518

Epoch: 5| Step: 5
Training loss: 1.78677237033844
Validation loss: 2.0744509081686697

Epoch: 5| Step: 6
Training loss: 1.9486210346221924
Validation loss: 2.031688651730937

Epoch: 5| Step: 7
Training loss: 2.044774055480957
Validation loss: 2.128934616683632

Epoch: 5| Step: 8
Training loss: 1.5239872932434082
Validation loss: 2.1337684867202595

Epoch: 5| Step: 9
Training loss: 1.5125621557235718
Validation loss: 2.074701378422399

Epoch: 5| Step: 10
Training loss: 1.8365610837936401
Validation loss: 2.0156595809485323

Epoch: 444| Step: 0
Training loss: 1.2619560956954956
Validation loss: 2.0541093746821084

Epoch: 5| Step: 1
Training loss: 1.7726949453353882
Validation loss: 2.151123486539369

Epoch: 5| Step: 2
Training loss: 1.298742651939392
Validation loss: 2.068433556505429

Epoch: 5| Step: 3
Training loss: 1.9023107290267944
Validation loss: 2.0069828546175392

Epoch: 5| Step: 4
Training loss: 2.15329647064209
Validation loss: 2.060918629810374

Epoch: 5| Step: 5
Training loss: 2.0724360942840576
Validation loss: 2.031129143571341

Epoch: 5| Step: 6
Training loss: 2.029632568359375
Validation loss: 2.057855406115132

Epoch: 5| Step: 7
Training loss: 1.3972458839416504
Validation loss: 2.0230588656599804

Epoch: 5| Step: 8
Training loss: 1.7258529663085938
Validation loss: 1.9995947448156213

Epoch: 5| Step: 9
Training loss: 1.8387811183929443
Validation loss: 2.0519849715694303

Epoch: 5| Step: 10
Training loss: 1.3789197206497192
Validation loss: 1.9829398380812777

Epoch: 445| Step: 0
Training loss: 1.4395780563354492
Validation loss: 2.155121044446063

Epoch: 5| Step: 1
Training loss: 1.3409640789031982
Validation loss: 2.1327887709422777

Epoch: 5| Step: 2
Training loss: 1.7634904384613037
Validation loss: 2.1192909645777878

Epoch: 5| Step: 3
Training loss: 2.316526174545288
Validation loss: 2.0727719158254643

Epoch: 5| Step: 4
Training loss: 1.570753812789917
Validation loss: 2.1609257062276206

Epoch: 5| Step: 5
Training loss: 1.4186302423477173
Validation loss: 2.2097973298001032

Epoch: 5| Step: 6
Training loss: 1.4747384786605835
Validation loss: 2.186702295016217

Epoch: 5| Step: 7
Training loss: 1.4618256092071533
Validation loss: 2.109952660017116

Epoch: 5| Step: 8
Training loss: 1.7370293140411377
Validation loss: 2.0293085152103054

Epoch: 5| Step: 9
Training loss: 2.265711545944214
Validation loss: 2.108426886220132

Epoch: 5| Step: 10
Training loss: 1.8492769002914429
Validation loss: 2.1081648847108245

Epoch: 446| Step: 0
Training loss: 1.8619410991668701
Validation loss: 2.0303253409683064

Epoch: 5| Step: 1
Training loss: 2.0245096683502197
Validation loss: 2.0691555392357612

Epoch: 5| Step: 2
Training loss: 1.4659589529037476
Validation loss: 2.011748868932006

Epoch: 5| Step: 3
Training loss: 1.6970808506011963
Validation loss: 2.051067413822297

Epoch: 5| Step: 4
Training loss: 1.8031704425811768
Validation loss: 2.0944626562057005

Epoch: 5| Step: 5
Training loss: 1.645228624343872
Validation loss: 2.1221410433451333

Epoch: 5| Step: 6
Training loss: 2.328709363937378
Validation loss: 2.019736677087763

Epoch: 5| Step: 7
Training loss: 1.4081722497940063
Validation loss: 2.028098854967343

Epoch: 5| Step: 8
Training loss: 2.0561635494232178
Validation loss: 2.0005001150151736

Epoch: 5| Step: 9
Training loss: 1.608955979347229
Validation loss: 2.055034250341436

Epoch: 5| Step: 10
Training loss: 0.9997016787528992
Validation loss: 1.9379422062186784

Epoch: 447| Step: 0
Training loss: 1.8671032190322876
Validation loss: 2.153358177472186

Epoch: 5| Step: 1
Training loss: 1.7382948398590088
Validation loss: 2.0248054086521106

Epoch: 5| Step: 2
Training loss: 2.0337119102478027
Validation loss: 2.159877195153185

Epoch: 5| Step: 3
Training loss: 2.025425434112549
Validation loss: 2.123919387017527

Epoch: 5| Step: 4
Training loss: 1.6821510791778564
Validation loss: 2.0881150691739974

Epoch: 5| Step: 5
Training loss: 1.7028331756591797
Validation loss: 2.2067066443863737

Epoch: 5| Step: 6
Training loss: 1.4041804075241089
Validation loss: 2.128029715630316

Epoch: 5| Step: 7
Training loss: 1.5544450283050537
Validation loss: 2.180552023713307

Epoch: 5| Step: 8
Training loss: 1.3412975072860718
Validation loss: 2.1142445712961178

Epoch: 5| Step: 9
Training loss: 2.04809832572937
Validation loss: 2.0879001489249607

Epoch: 5| Step: 10
Training loss: 1.3778194189071655
Validation loss: 2.000268631083991

Epoch: 448| Step: 0
Training loss: 1.498485803604126
Validation loss: 2.1171533343612507

Epoch: 5| Step: 1
Training loss: 1.5859794616699219
Validation loss: 2.0891923340418006

Epoch: 5| Step: 2
Training loss: 2.646643877029419
Validation loss: 2.1389782864560365

Epoch: 5| Step: 3
Training loss: 1.6949354410171509
Validation loss: 2.1095344123019966

Epoch: 5| Step: 4
Training loss: 1.9043077230453491
Validation loss: 2.042016380576677

Epoch: 5| Step: 5
Training loss: 1.4970672130584717
Validation loss: 2.1740749625749487

Epoch: 5| Step: 6
Training loss: 1.6369800567626953
Validation loss: 2.0320200176649195

Epoch: 5| Step: 7
Training loss: 1.6537752151489258
Validation loss: 2.0725861185340473

Epoch: 5| Step: 8
Training loss: 1.6076576709747314
Validation loss: 2.013400395711263

Epoch: 5| Step: 9
Training loss: 1.121546983718872
Validation loss: 2.12028213982941

Epoch: 5| Step: 10
Training loss: 1.8314306735992432
Validation loss: 2.0607250480241674

Epoch: 449| Step: 0
Training loss: 1.4420626163482666
Validation loss: 2.151921058213839

Epoch: 5| Step: 1
Training loss: 1.4881469011306763
Validation loss: 2.1263000144753406

Epoch: 5| Step: 2
Training loss: 2.271601676940918
Validation loss: 2.0896458497611423

Epoch: 5| Step: 3
Training loss: 2.2939817905426025
Validation loss: 2.061607918431682

Epoch: 5| Step: 4
Training loss: 1.766904592514038
Validation loss: 1.9693175310729651

Epoch: 5| Step: 5
Training loss: 1.6619905233383179
Validation loss: 2.1260193701713317

Epoch: 5| Step: 6
Training loss: 1.7311830520629883
Validation loss: 2.0465431649197816

Epoch: 5| Step: 7
Training loss: 1.4742616415023804
Validation loss: 2.064626698852867

Epoch: 5| Step: 8
Training loss: 1.003063678741455
Validation loss: 2.123270073244649

Epoch: 5| Step: 9
Training loss: 2.156935214996338
Validation loss: 2.101906571336972

Epoch: 5| Step: 10
Training loss: 2.0849225521087646
Validation loss: 2.126199637689898

Epoch: 450| Step: 0
Training loss: 1.1087273359298706
Validation loss: 2.1248421002459783

Epoch: 5| Step: 1
Training loss: 1.4907269477844238
Validation loss: 2.087804158528646

Epoch: 5| Step: 2
Training loss: 1.8457343578338623
Validation loss: 2.008860784192239

Epoch: 5| Step: 3
Training loss: 1.7415235042572021
Validation loss: 2.0042275715899724

Epoch: 5| Step: 4
Training loss: 1.8104915618896484
Validation loss: 2.1306866445849018

Epoch: 5| Step: 5
Training loss: 1.5294262170791626
Validation loss: 2.1557839326961066

Epoch: 5| Step: 6
Training loss: 2.038660764694214
Validation loss: 2.0999230518135974

Epoch: 5| Step: 7
Training loss: 2.1778156757354736
Validation loss: 2.033035701321017

Epoch: 5| Step: 8
Training loss: 1.9218002557754517
Validation loss: 2.06469214347101

Epoch: 5| Step: 9
Training loss: 1.7015053033828735
Validation loss: 1.9577425346579602

Epoch: 5| Step: 10
Training loss: 1.9983901977539062
Validation loss: 2.0204129949692757

Epoch: 451| Step: 0
Training loss: 1.8113782405853271
Validation loss: 2.0137896063507243

Epoch: 5| Step: 1
Training loss: 1.4084311723709106
Validation loss: 2.0589416232160342

Epoch: 5| Step: 2
Training loss: 1.7721965312957764
Validation loss: 2.1328070907182592

Epoch: 5| Step: 3
Training loss: 2.0585906505584717
Validation loss: 2.012950474216092

Epoch: 5| Step: 4
Training loss: 1.348156213760376
Validation loss: 2.035306663923366

Epoch: 5| Step: 5
Training loss: 1.5081754922866821
Validation loss: 2.0797468949389715

Epoch: 5| Step: 6
Training loss: 1.9002126455307007
Validation loss: 2.0995676453395555

Epoch: 5| Step: 7
Training loss: 1.054136872291565
Validation loss: 2.083851219505392

Epoch: 5| Step: 8
Training loss: 1.751115083694458
Validation loss: 2.003227126213812

Epoch: 5| Step: 9
Training loss: 2.0096030235290527
Validation loss: 2.136888434810023

Epoch: 5| Step: 10
Training loss: 2.118701219558716
Validation loss: 2.0377669590775684

Epoch: 452| Step: 0
Training loss: 1.7081880569458008
Validation loss: 2.097145116457375

Epoch: 5| Step: 1
Training loss: 2.404845952987671
Validation loss: 2.071370582426748

Epoch: 5| Step: 2
Training loss: 1.7037150859832764
Validation loss: 2.0342357735480032

Epoch: 5| Step: 3
Training loss: 2.0345120429992676
Validation loss: 2.1445706839202554

Epoch: 5| Step: 4
Training loss: 1.9423573017120361
Validation loss: 2.185307636055895

Epoch: 5| Step: 5
Training loss: 1.6996548175811768
Validation loss: 2.047384564594556

Epoch: 5| Step: 6
Training loss: 1.3507698774337769
Validation loss: 2.036705006835281

Epoch: 5| Step: 7
Training loss: 1.5055650472640991
Validation loss: 2.107903704848341

Epoch: 5| Step: 8
Training loss: 1.3724405765533447
Validation loss: 2.128841215564359

Epoch: 5| Step: 9
Training loss: 1.304394006729126
Validation loss: 2.0553153855826265

Epoch: 5| Step: 10
Training loss: 1.3270454406738281
Validation loss: 2.0811213062655542

Epoch: 453| Step: 0
Training loss: 1.8064161539077759
Validation loss: 2.0434354659049743

Epoch: 5| Step: 1
Training loss: 1.640162706375122
Validation loss: 2.089801780639156

Epoch: 5| Step: 2
Training loss: 1.941197395324707
Validation loss: 2.0329267594122116

Epoch: 5| Step: 3
Training loss: 1.2994743585586548
Validation loss: 2.110884965107005

Epoch: 5| Step: 4
Training loss: 1.4828521013259888
Validation loss: 2.0936642616025862

Epoch: 5| Step: 5
Training loss: 2.1025242805480957
Validation loss: 2.101618133565431

Epoch: 5| Step: 6
Training loss: 1.2304649353027344
Validation loss: 2.02993336672424

Epoch: 5| Step: 7
Training loss: 1.7071254253387451
Validation loss: 2.033145099557856

Epoch: 5| Step: 8
Training loss: 1.6467092037200928
Validation loss: 2.1169871502025153

Epoch: 5| Step: 9
Training loss: 2.1373910903930664
Validation loss: 2.0289652732110794

Epoch: 5| Step: 10
Training loss: 1.9309016466140747
Validation loss: 2.081467032432556

Epoch: 454| Step: 0
Training loss: 1.7448545694351196
Validation loss: 2.1320097625896497

Epoch: 5| Step: 1
Training loss: 1.8555721044540405
Validation loss: 2.0888343754635064

Epoch: 5| Step: 2
Training loss: 1.8762143850326538
Validation loss: 2.0807176969384633

Epoch: 5| Step: 3
Training loss: 1.5529409646987915
Validation loss: 2.0718843167827976

Epoch: 5| Step: 4
Training loss: 1.7138105630874634
Validation loss: 1.985249952603412

Epoch: 5| Step: 5
Training loss: 1.5909998416900635
Validation loss: 2.0259058680585635

Epoch: 5| Step: 6
Training loss: 2.026282548904419
Validation loss: 2.1754943863038094

Epoch: 5| Step: 7
Training loss: 1.7896541357040405
Validation loss: 2.0716907388420513

Epoch: 5| Step: 8
Training loss: 1.9386669397354126
Validation loss: 2.091561564835169

Epoch: 5| Step: 9
Training loss: 1.7754358053207397
Validation loss: 2.037036959842969

Epoch: 5| Step: 10
Training loss: 1.6290658712387085
Validation loss: 2.128631353378296

Epoch: 455| Step: 0
Training loss: 1.4207605123519897
Validation loss: 2.0600997606913247

Epoch: 5| Step: 1
Training loss: 1.6929867267608643
Validation loss: 2.005729925247931

Epoch: 5| Step: 2
Training loss: 1.347495198249817
Validation loss: 2.0918880508792017

Epoch: 5| Step: 3
Training loss: 1.2322207689285278
Validation loss: 2.2078059027271886

Epoch: 5| Step: 4
Training loss: 1.667426347732544
Validation loss: 2.0785889830640567

Epoch: 5| Step: 5
Training loss: 2.2164466381073
Validation loss: 2.0532240457432245

Epoch: 5| Step: 6
Training loss: 1.566528558731079
Validation loss: 2.0752336543093444

Epoch: 5| Step: 7
Training loss: 1.2814099788665771
Validation loss: 2.0977612182658207

Epoch: 5| Step: 8
Training loss: 1.780003547668457
Validation loss: 2.027767542869814

Epoch: 5| Step: 9
Training loss: 1.9357894659042358
Validation loss: 2.0828450649015364

Epoch: 5| Step: 10
Training loss: 1.8033740520477295
Validation loss: 2.0184056169243267

Epoch: 456| Step: 0
Training loss: 1.5099154710769653
Validation loss: 2.025261758476175

Epoch: 5| Step: 1
Training loss: 1.6884057521820068
Validation loss: 2.0676688327584216

Epoch: 5| Step: 2
Training loss: 2.085402488708496
Validation loss: 2.0013193622712167

Epoch: 5| Step: 3
Training loss: 1.7215722799301147
Validation loss: 2.0773727278555594

Epoch: 5| Step: 4
Training loss: 1.3705577850341797
Validation loss: 2.099223547084357

Epoch: 5| Step: 5
Training loss: 2.3620493412017822
Validation loss: 1.958011447742421

Epoch: 5| Step: 6
Training loss: 1.827418327331543
Validation loss: 2.1444878296185563

Epoch: 5| Step: 7
Training loss: 1.2538464069366455
Validation loss: 2.018474522457328

Epoch: 5| Step: 8
Training loss: 1.4874764680862427
Validation loss: 2.1818690633261077

Epoch: 5| Step: 9
Training loss: 1.656521201133728
Validation loss: 2.0672116446238693

Epoch: 5| Step: 10
Training loss: 1.713219404220581
Validation loss: 1.9887936320356143

Epoch: 457| Step: 0
Training loss: 1.9170299768447876
Validation loss: 2.1702413405141523

Epoch: 5| Step: 1
Training loss: 1.2495516538619995
Validation loss: 2.0414287351792857

Epoch: 5| Step: 2
Training loss: 1.5244861841201782
Validation loss: 2.0134597260464906

Epoch: 5| Step: 3
Training loss: 1.855364441871643
Validation loss: 2.027389008511779

Epoch: 5| Step: 4
Training loss: 1.8512680530548096
Validation loss: 2.166393039047077

Epoch: 5| Step: 5
Training loss: 2.0165743827819824
Validation loss: 2.0139281416452057

Epoch: 5| Step: 6
Training loss: 1.6257832050323486
Validation loss: 2.1439108848571777

Epoch: 5| Step: 7
Training loss: 1.4568355083465576
Validation loss: 1.990270476187429

Epoch: 5| Step: 8
Training loss: 1.9703792333602905
Validation loss: 2.04542980142819

Epoch: 5| Step: 9
Training loss: 2.0632243156433105
Validation loss: 2.1075701611016386

Epoch: 5| Step: 10
Training loss: 1.3771424293518066
Validation loss: 1.966343577190112

Epoch: 458| Step: 0
Training loss: 1.1248308420181274
Validation loss: 2.061909068015314

Epoch: 5| Step: 1
Training loss: 2.3079288005828857
Validation loss: 1.9533640953802294

Epoch: 5| Step: 2
Training loss: 1.5071358680725098
Validation loss: 2.0234536663178475

Epoch: 5| Step: 3
Training loss: 1.678083062171936
Validation loss: 1.9770868914101714

Epoch: 5| Step: 4
Training loss: 1.9702653884887695
Validation loss: 2.0835652633379866

Epoch: 5| Step: 5
Training loss: 1.4948878288269043
Validation loss: 2.017007530376475

Epoch: 5| Step: 6
Training loss: 1.8922277688980103
Validation loss: 2.0465105823291245

Epoch: 5| Step: 7
Training loss: 1.8250453472137451
Validation loss: 2.1294857148201234

Epoch: 5| Step: 8
Training loss: 1.7048416137695312
Validation loss: 2.018962901125672

Epoch: 5| Step: 9
Training loss: 1.312718391418457
Validation loss: 2.029702078911566

Epoch: 5| Step: 10
Training loss: 2.11924409866333
Validation loss: 2.043237478502335

Epoch: 459| Step: 0
Training loss: 2.0364315509796143
Validation loss: 2.0646511918754986

Epoch: 5| Step: 1
Training loss: 1.4574123620986938
Validation loss: 2.1066223959768973

Epoch: 5| Step: 2
Training loss: 2.1145224571228027
Validation loss: 1.9561942021052043

Epoch: 5| Step: 3
Training loss: 1.4482377767562866
Validation loss: 2.0701981565003753

Epoch: 5| Step: 4
Training loss: 1.4817607402801514
Validation loss: 2.0619907238150157

Epoch: 5| Step: 5
Training loss: 2.436229705810547
Validation loss: 2.0300366276053974

Epoch: 5| Step: 6
Training loss: 1.290665864944458
Validation loss: 2.0123166512417536

Epoch: 5| Step: 7
Training loss: 1.3898663520812988
Validation loss: 2.0888531592584427

Epoch: 5| Step: 8
Training loss: 1.5632436275482178
Validation loss: 1.972588780105755

Epoch: 5| Step: 9
Training loss: 2.1818995475769043
Validation loss: 2.1224292068071264

Epoch: 5| Step: 10
Training loss: 1.6006593704223633
Validation loss: 2.0393026157092025

Epoch: 460| Step: 0
Training loss: 1.320042610168457
Validation loss: 2.079766860572241

Epoch: 5| Step: 1
Training loss: 2.3217220306396484
Validation loss: 2.022471715045232

Epoch: 5| Step: 2
Training loss: 1.5503113269805908
Validation loss: 2.176540505501532

Epoch: 5| Step: 3
Training loss: 2.073057174682617
Validation loss: 2.064824443991466

Epoch: 5| Step: 4
Training loss: 2.0215048789978027
Validation loss: 2.1206587001841557

Epoch: 5| Step: 5
Training loss: 1.3269994258880615
Validation loss: 2.0912444899159093

Epoch: 5| Step: 6
Training loss: 1.742770791053772
Validation loss: 2.112283819465227

Epoch: 5| Step: 7
Training loss: 1.6826694011688232
Validation loss: 2.0774277243562924

Epoch: 5| Step: 8
Training loss: 1.7637138366699219
Validation loss: 2.0977118733108684

Epoch: 5| Step: 9
Training loss: 1.662631630897522
Validation loss: 2.0684214074124574

Epoch: 5| Step: 10
Training loss: 1.680628776550293
Validation loss: 2.0706497802529285

Epoch: 461| Step: 0
Training loss: 1.8578145503997803
Validation loss: 2.054915466616231

Epoch: 5| Step: 1
Training loss: 1.3287851810455322
Validation loss: 2.006397775424424

Epoch: 5| Step: 2
Training loss: 1.6034736633300781
Validation loss: 2.114739018101846

Epoch: 5| Step: 3
Training loss: 2.2190089225769043
Validation loss: 2.0367978067808252

Epoch: 5| Step: 4
Training loss: 1.3950828313827515
Validation loss: 2.079102147010065

Epoch: 5| Step: 5
Training loss: 2.134269952774048
Validation loss: 2.0797506352906585

Epoch: 5| Step: 6
Training loss: 2.2551050186157227
Validation loss: 2.098366973220661

Epoch: 5| Step: 7
Training loss: 1.5624496936798096
Validation loss: 2.01743717603786

Epoch: 5| Step: 8
Training loss: 1.4389816522598267
Validation loss: 2.0686616525855115

Epoch: 5| Step: 9
Training loss: 1.7229554653167725
Validation loss: 1.9960520293122979

Epoch: 5| Step: 10
Training loss: 1.0882084369659424
Validation loss: 2.1334657566521757

Epoch: 462| Step: 0
Training loss: 1.2888813018798828
Validation loss: 2.108162499243213

Epoch: 5| Step: 1
Training loss: 1.8082164525985718
Validation loss: 2.0937288884193666

Epoch: 5| Step: 2
Training loss: 1.178815245628357
Validation loss: 2.0908272458660986

Epoch: 5| Step: 3
Training loss: 1.6280038356781006
Validation loss: 2.222118987832018

Epoch: 5| Step: 4
Training loss: 1.6427940130233765
Validation loss: 2.0953799883524575

Epoch: 5| Step: 5
Training loss: 2.4803314208984375
Validation loss: 2.028751197681632

Epoch: 5| Step: 6
Training loss: 1.9519904851913452
Validation loss: 2.132418268470354

Epoch: 5| Step: 7
Training loss: 2.0509448051452637
Validation loss: 2.1224219696496123

Epoch: 5| Step: 8
Training loss: 1.5460189580917358
Validation loss: 2.053890610253939

Epoch: 5| Step: 9
Training loss: 1.9775779247283936
Validation loss: 2.0412043845781715

Epoch: 5| Step: 10
Training loss: 1.7709909677505493
Validation loss: 2.066441429558621

Epoch: 463| Step: 0
Training loss: 2.076957941055298
Validation loss: 2.12441405429635

Epoch: 5| Step: 1
Training loss: 1.869852066040039
Validation loss: 2.127193498355086

Epoch: 5| Step: 2
Training loss: 1.9718888998031616
Validation loss: 2.042634561497678

Epoch: 5| Step: 3
Training loss: 1.4423943758010864
Validation loss: 2.11235700884173

Epoch: 5| Step: 4
Training loss: 1.6087605953216553
Validation loss: 2.058808265193816

Epoch: 5| Step: 5
Training loss: 1.707058310508728
Validation loss: 2.033205388694681

Epoch: 5| Step: 6
Training loss: 1.5536125898361206
Validation loss: 2.1459675219751175

Epoch: 5| Step: 7
Training loss: 1.7879356145858765
Validation loss: 2.0498767283654984

Epoch: 5| Step: 8
Training loss: 2.180415630340576
Validation loss: 2.076530969271096

Epoch: 5| Step: 9
Training loss: 1.4468953609466553
Validation loss: 2.047141677589827

Epoch: 5| Step: 10
Training loss: 1.2724812030792236
Validation loss: 2.02868208577556

Epoch: 464| Step: 0
Training loss: 2.1228156089782715
Validation loss: 2.0848125270617905

Epoch: 5| Step: 1
Training loss: 1.6321189403533936
Validation loss: 2.049279620570521

Epoch: 5| Step: 2
Training loss: 1.2947958707809448
Validation loss: 2.121734521722281

Epoch: 5| Step: 3
Training loss: 1.7858619689941406
Validation loss: 2.1174232113745903

Epoch: 5| Step: 4
Training loss: 1.7951723337173462
Validation loss: 2.0813798635236678

Epoch: 5| Step: 5
Training loss: 1.7038068771362305
Validation loss: 2.142237251804721

Epoch: 5| Step: 6
Training loss: 2.2037408351898193
Validation loss: 2.104734919404471

Epoch: 5| Step: 7
Training loss: 1.4535490274429321
Validation loss: 2.0371397259414836

Epoch: 5| Step: 8
Training loss: 1.5692898035049438
Validation loss: 2.120593355547997

Epoch: 5| Step: 9
Training loss: 1.8560253381729126
Validation loss: 2.0727167411517073

Epoch: 5| Step: 10
Training loss: 1.7683998346328735
Validation loss: 2.1170657950062908

Epoch: 465| Step: 0
Training loss: 1.15199875831604
Validation loss: 2.0661703655796666

Epoch: 5| Step: 1
Training loss: 1.610266923904419
Validation loss: 2.1242778352511826

Epoch: 5| Step: 2
Training loss: 1.9603042602539062
Validation loss: 2.0665121693764963

Epoch: 5| Step: 3
Training loss: 2.4587631225585938
Validation loss: 2.121452259761031

Epoch: 5| Step: 4
Training loss: 1.434844732284546
Validation loss: 1.9972400139736872

Epoch: 5| Step: 5
Training loss: 1.8212909698486328
Validation loss: 2.065322901612969

Epoch: 5| Step: 6
Training loss: 1.9903459548950195
Validation loss: 2.0229408792270127

Epoch: 5| Step: 7
Training loss: 1.7271387577056885
Validation loss: 2.0667141355494016

Epoch: 5| Step: 8
Training loss: 1.4602506160736084
Validation loss: 2.053469081078806

Epoch: 5| Step: 9
Training loss: 1.7313919067382812
Validation loss: 1.9963040556958926

Epoch: 5| Step: 10
Training loss: 1.7715530395507812
Validation loss: 2.075707866299537

Epoch: 466| Step: 0
Training loss: 1.6252238750457764
Validation loss: 2.0456626261434248

Epoch: 5| Step: 1
Training loss: 1.612769365310669
Validation loss: 2.1108386029479322

Epoch: 5| Step: 2
Training loss: 1.9702008962631226
Validation loss: 1.9978407659838278

Epoch: 5| Step: 3
Training loss: 1.8026809692382812
Validation loss: 2.07277621376899

Epoch: 5| Step: 4
Training loss: 1.5843051671981812
Validation loss: 2.0927231234888874

Epoch: 5| Step: 5
Training loss: 1.7528979778289795
Validation loss: 2.1172539444379908

Epoch: 5| Step: 6
Training loss: 1.5664753913879395
Validation loss: 2.0678412119547525

Epoch: 5| Step: 7
Training loss: 1.2841366529464722
Validation loss: 2.0284311989302277

Epoch: 5| Step: 8
Training loss: 2.220198154449463
Validation loss: 2.0858206748962402

Epoch: 5| Step: 9
Training loss: 1.3605865240097046
Validation loss: 2.0551505870716547

Epoch: 5| Step: 10
Training loss: 2.096698522567749
Validation loss: 2.1595191699202343

Epoch: 467| Step: 0
Training loss: 2.534285068511963
Validation loss: 2.115844908580985

Epoch: 5| Step: 1
Training loss: 2.1069042682647705
Validation loss: 2.054096539815267

Epoch: 5| Step: 2
Training loss: 1.5728724002838135
Validation loss: 2.1138421386800785

Epoch: 5| Step: 3
Training loss: 2.0721824169158936
Validation loss: 2.106968800226847

Epoch: 5| Step: 4
Training loss: 1.581892490386963
Validation loss: 2.08193398931975

Epoch: 5| Step: 5
Training loss: 1.6887671947479248
Validation loss: 2.16937659248229

Epoch: 5| Step: 6
Training loss: 1.2757360935211182
Validation loss: 2.114320367895147

Epoch: 5| Step: 7
Training loss: 2.0395803451538086
Validation loss: 2.049001257906678

Epoch: 5| Step: 8
Training loss: 1.3582990169525146
Validation loss: 1.9962240957444715

Epoch: 5| Step: 9
Training loss: 1.3982055187225342
Validation loss: 1.9864879961936706

Epoch: 5| Step: 10
Training loss: 1.5393784046173096
Validation loss: 2.025895236640848

Epoch: 468| Step: 0
Training loss: 1.8701359033584595
Validation loss: 2.1428650450962845

Epoch: 5| Step: 1
Training loss: 1.555732011795044
Validation loss: 2.052416714288855

Epoch: 5| Step: 2
Training loss: 1.9821326732635498
Validation loss: 1.9651838092393772

Epoch: 5| Step: 3
Training loss: 1.7311404943466187
Validation loss: 1.95672228259425

Epoch: 5| Step: 4
Training loss: 1.689220666885376
Validation loss: 2.029370771941318

Epoch: 5| Step: 5
Training loss: 1.6505473852157593
Validation loss: 2.130977030723326

Epoch: 5| Step: 6
Training loss: 1.6438699960708618
Validation loss: 2.1690312585523053

Epoch: 5| Step: 7
Training loss: 1.940567970275879
Validation loss: 2.1122057360987507

Epoch: 5| Step: 8
Training loss: 1.6832530498504639
Validation loss: 2.2568791681720364

Epoch: 5| Step: 9
Training loss: 1.1787770986557007
Validation loss: 2.1038813860185686

Epoch: 5| Step: 10
Training loss: 1.480895757675171
Validation loss: 2.0475061811426634

Epoch: 469| Step: 0
Training loss: 1.656764268875122
Validation loss: 2.1288367022750196

Epoch: 5| Step: 1
Training loss: 2.53739595413208
Validation loss: 2.0946564892286896

Epoch: 5| Step: 2
Training loss: 1.741913080215454
Validation loss: 2.137966502097345

Epoch: 5| Step: 3
Training loss: 1.444270133972168
Validation loss: 2.118156753560548

Epoch: 5| Step: 4
Training loss: 1.5976874828338623
Validation loss: 2.044186140901299

Epoch: 5| Step: 5
Training loss: 1.6522048711776733
Validation loss: 2.0857933240552105

Epoch: 5| Step: 6
Training loss: 1.5666062831878662
Validation loss: 2.035958815646428

Epoch: 5| Step: 7
Training loss: 1.4595948457717896
Validation loss: 2.077267413498253

Epoch: 5| Step: 8
Training loss: 1.882874846458435
Validation loss: 2.040218566053657

Epoch: 5| Step: 9
Training loss: 1.236924648284912
Validation loss: 2.0589321069819952

Epoch: 5| Step: 10
Training loss: 1.9526609182357788
Validation loss: 2.0545999029631257

Epoch: 470| Step: 0
Training loss: 2.049121141433716
Validation loss: 2.173088050657703

Epoch: 5| Step: 1
Training loss: 1.2273696660995483
Validation loss: 2.144377951980919

Epoch: 5| Step: 2
Training loss: 1.8291854858398438
Validation loss: 2.013208891755791

Epoch: 5| Step: 3
Training loss: 2.01452374458313
Validation loss: 2.1442297556067027

Epoch: 5| Step: 4
Training loss: 1.8536838293075562
Validation loss: 2.1143446712083716

Epoch: 5| Step: 5
Training loss: 0.905929446220398
Validation loss: 2.058649229746993

Epoch: 5| Step: 6
Training loss: 1.7478891611099243
Validation loss: 2.0697490463974657

Epoch: 5| Step: 7
Training loss: 1.4619262218475342
Validation loss: 2.072279900632879

Epoch: 5| Step: 8
Training loss: 1.627899408340454
Validation loss: 1.9715186370316373

Epoch: 5| Step: 9
Training loss: 1.9251976013183594
Validation loss: 2.139302538287255

Epoch: 5| Step: 10
Training loss: 1.1891340017318726
Validation loss: 2.1344383814001597

Epoch: 471| Step: 0
Training loss: 1.3945244550704956
Validation loss: 2.0830759130498415

Epoch: 5| Step: 1
Training loss: 1.7812786102294922
Validation loss: 2.099075096909718

Epoch: 5| Step: 2
Training loss: 1.6310932636260986
Validation loss: 2.1292756013972785

Epoch: 5| Step: 3
Training loss: 1.6526178121566772
Validation loss: 2.2426130617818525

Epoch: 5| Step: 4
Training loss: 1.5391879081726074
Validation loss: 2.107803749781783

Epoch: 5| Step: 5
Training loss: 1.9151699542999268
Validation loss: 2.0550229767317414

Epoch: 5| Step: 6
Training loss: 1.7443031072616577
Validation loss: 2.0893035409271077

Epoch: 5| Step: 7
Training loss: 1.0029325485229492
Validation loss: 2.0613333922560497

Epoch: 5| Step: 8
Training loss: 2.6035099029541016
Validation loss: 2.086285178379346

Epoch: 5| Step: 9
Training loss: 1.9188363552093506
Validation loss: 2.046134676984561

Epoch: 5| Step: 10
Training loss: 1.6073607206344604
Validation loss: 2.1055252449486845

Epoch: 472| Step: 0
Training loss: 1.5863841772079468
Validation loss: 1.9797001474647111

Epoch: 5| Step: 1
Training loss: 1.7081701755523682
Validation loss: 2.061003638852027

Epoch: 5| Step: 2
Training loss: 1.920959711074829
Validation loss: 2.1417155035080446

Epoch: 5| Step: 3
Training loss: 1.8106577396392822
Validation loss: 2.146196816557197

Epoch: 5| Step: 4
Training loss: 1.8574806451797485
Validation loss: 2.0850414306886735

Epoch: 5| Step: 5
Training loss: 2.1820311546325684
Validation loss: 2.047135180042636

Epoch: 5| Step: 6
Training loss: 1.3114326000213623
Validation loss: 2.0585691851954304

Epoch: 5| Step: 7
Training loss: 1.899959921836853
Validation loss: 2.0286502556134294

Epoch: 5| Step: 8
Training loss: 1.547358512878418
Validation loss: 1.9792327252767419

Epoch: 5| Step: 9
Training loss: 1.246604323387146
Validation loss: 2.0354467412476898

Epoch: 5| Step: 10
Training loss: 1.2521461248397827
Validation loss: 2.080589589252267

Epoch: 473| Step: 0
Training loss: 2.0123424530029297
Validation loss: 2.158126702872656

Epoch: 5| Step: 1
Training loss: 1.3046033382415771
Validation loss: 2.070202176288892

Epoch: 5| Step: 2
Training loss: 1.2353274822235107
Validation loss: 2.135030310641053

Epoch: 5| Step: 3
Training loss: 1.5479543209075928
Validation loss: 2.0409928893530243

Epoch: 5| Step: 4
Training loss: 1.8811962604522705
Validation loss: 2.0042316426513014

Epoch: 5| Step: 5
Training loss: 1.9049110412597656
Validation loss: 2.0388753465426865

Epoch: 5| Step: 6
Training loss: 1.6011507511138916
Validation loss: 2.103361498924994

Epoch: 5| Step: 7
Training loss: 1.4884577989578247
Validation loss: 2.173428771316364

Epoch: 5| Step: 8
Training loss: 1.5739392042160034
Validation loss: 2.0405385724959837

Epoch: 5| Step: 9
Training loss: 2.6644089221954346
Validation loss: 2.1539518845978605

Epoch: 5| Step: 10
Training loss: 1.4579671621322632
Validation loss: 2.1462483111248223

Epoch: 474| Step: 0
Training loss: 1.424644112586975
Validation loss: 2.082606287412746

Epoch: 5| Step: 1
Training loss: 1.561331033706665
Validation loss: 2.0783995710393435

Epoch: 5| Step: 2
Training loss: 1.7385879755020142
Validation loss: 2.0540929238001504

Epoch: 5| Step: 3
Training loss: 1.6853593587875366
Validation loss: 2.090217485222765

Epoch: 5| Step: 4
Training loss: 1.8638126850128174
Validation loss: 2.1477621242564213

Epoch: 5| Step: 5
Training loss: 2.1685574054718018
Validation loss: 1.9956915699025637

Epoch: 5| Step: 6
Training loss: 1.3702423572540283
Validation loss: 2.120671478650903

Epoch: 5| Step: 7
Training loss: 1.206683874130249
Validation loss: 2.1164359097839682

Epoch: 5| Step: 8
Training loss: 1.7819550037384033
Validation loss: 2.08307433512903

Epoch: 5| Step: 9
Training loss: 1.2769075632095337
Validation loss: 2.072146100382651

Epoch: 5| Step: 10
Training loss: 1.9449673891067505
Validation loss: 2.091360738200526

Epoch: 475| Step: 0
Training loss: 2.51499605178833
Validation loss: 2.0648062280429307

Epoch: 5| Step: 1
Training loss: 1.808347463607788
Validation loss: 1.9976320676906134

Epoch: 5| Step: 2
Training loss: 1.709947943687439
Validation loss: 2.0838578003709034

Epoch: 5| Step: 3
Training loss: 1.176382303237915
Validation loss: 2.063934754299861

Epoch: 5| Step: 4
Training loss: 2.1437973976135254
Validation loss: 2.1203466999915337

Epoch: 5| Step: 5
Training loss: 1.4733059406280518
Validation loss: 2.02498609019864

Epoch: 5| Step: 6
Training loss: 1.7205207347869873
Validation loss: 2.0945684012546333

Epoch: 5| Step: 7
Training loss: 1.564110517501831
Validation loss: 2.0874646632902083

Epoch: 5| Step: 8
Training loss: 1.1944458484649658
Validation loss: 1.9728037413730417

Epoch: 5| Step: 9
Training loss: 1.282902717590332
Validation loss: 2.1652221936051563

Epoch: 5| Step: 10
Training loss: 1.566298484802246
Validation loss: 2.1109333076784687

Epoch: 476| Step: 0
Training loss: 1.8800872564315796
Validation loss: 1.9880718877238612

Epoch: 5| Step: 1
Training loss: 1.5434260368347168
Validation loss: 2.106107552846273

Epoch: 5| Step: 2
Training loss: 1.8844540119171143
Validation loss: 2.050306640645509

Epoch: 5| Step: 3
Training loss: 1.8299405574798584
Validation loss: 2.132453718493062

Epoch: 5| Step: 4
Training loss: 1.728063941001892
Validation loss: 2.0543570518493652

Epoch: 5| Step: 5
Training loss: 1.2319211959838867
Validation loss: 2.0887478423374954

Epoch: 5| Step: 6
Training loss: 1.666415810585022
Validation loss: 2.0723524785810903

Epoch: 5| Step: 7
Training loss: 1.6631120443344116
Validation loss: 2.000745193932646

Epoch: 5| Step: 8
Training loss: 1.9031941890716553
Validation loss: 2.0311555208698397

Epoch: 5| Step: 9
Training loss: 1.5999114513397217
Validation loss: 2.102044036311488

Epoch: 5| Step: 10
Training loss: 1.6938995122909546
Validation loss: 2.110504441363837

Epoch: 477| Step: 0
Training loss: 1.6168479919433594
Validation loss: 2.028824762631488

Epoch: 5| Step: 1
Training loss: 1.9190670251846313
Validation loss: 2.106002820435391

Epoch: 5| Step: 2
Training loss: 1.5639564990997314
Validation loss: 1.9910797111449703

Epoch: 5| Step: 3
Training loss: 1.5285450220108032
Validation loss: 2.130155005762654

Epoch: 5| Step: 4
Training loss: 1.9367034435272217
Validation loss: 2.0499453813798967

Epoch: 5| Step: 5
Training loss: 1.6624138355255127
Validation loss: 2.053959228659189

Epoch: 5| Step: 6
Training loss: 1.1943949460983276
Validation loss: 2.008742524731544

Epoch: 5| Step: 7
Training loss: 1.630157709121704
Validation loss: 2.147014820447532

Epoch: 5| Step: 8
Training loss: 2.0092272758483887
Validation loss: 2.1311227352388444

Epoch: 5| Step: 9
Training loss: 1.9936729669570923
Validation loss: 2.131033794854277

Epoch: 5| Step: 10
Training loss: 1.7707387208938599
Validation loss: 2.071874395493538

Epoch: 478| Step: 0
Training loss: 1.7133487462997437
Validation loss: 2.067498909529819

Epoch: 5| Step: 1
Training loss: 2.400386095046997
Validation loss: 2.0058346358678674

Epoch: 5| Step: 2
Training loss: 1.2723944187164307
Validation loss: 2.177719582793533

Epoch: 5| Step: 3
Training loss: 1.3321502208709717
Validation loss: 1.9458967460099088

Epoch: 5| Step: 4
Training loss: 1.8295698165893555
Validation loss: 2.070432263035928

Epoch: 5| Step: 5
Training loss: 2.6280879974365234
Validation loss: 1.9971635982554445

Epoch: 5| Step: 6
Training loss: 1.3604238033294678
Validation loss: 2.072976363602505

Epoch: 5| Step: 7
Training loss: 1.0053131580352783
Validation loss: 1.9954805861237228

Epoch: 5| Step: 8
Training loss: 1.8008302450180054
Validation loss: 2.062036862937353

Epoch: 5| Step: 9
Training loss: 1.5066030025482178
Validation loss: 2.168008412084272

Epoch: 5| Step: 10
Training loss: 1.8401389122009277
Validation loss: 2.0935966148171374

Epoch: 479| Step: 0
Training loss: 1.8745136260986328
Validation loss: 2.1090038719997612

Epoch: 5| Step: 1
Training loss: 1.4357976913452148
Validation loss: 2.0696765017765824

Epoch: 5| Step: 2
Training loss: 1.4258614778518677
Validation loss: 2.0894338802624772

Epoch: 5| Step: 3
Training loss: 1.1344499588012695
Validation loss: 2.10456887496415

Epoch: 5| Step: 4
Training loss: 2.089207172393799
Validation loss: 2.1027668419704644

Epoch: 5| Step: 5
Training loss: 1.4339590072631836
Validation loss: 2.144498263635943

Epoch: 5| Step: 6
Training loss: 1.9725803136825562
Validation loss: 2.1087814197745374

Epoch: 5| Step: 7
Training loss: 1.6007318496704102
Validation loss: 2.017859443541496

Epoch: 5| Step: 8
Training loss: 2.0796332359313965
Validation loss: 2.013360740036093

Epoch: 5| Step: 9
Training loss: 1.4422909021377563
Validation loss: 2.154354296704774

Epoch: 5| Step: 10
Training loss: 2.1034328937530518
Validation loss: 2.1314449797394457

Epoch: 480| Step: 0
Training loss: 1.5091357231140137
Validation loss: 2.029848890919839

Epoch: 5| Step: 1
Training loss: 1.540188193321228
Validation loss: 2.0655249318768902

Epoch: 5| Step: 2
Training loss: 1.898776650428772
Validation loss: 2.0652056509448635

Epoch: 5| Step: 3
Training loss: 1.9325039386749268
Validation loss: 2.0726781519510413

Epoch: 5| Step: 4
Training loss: 1.454024076461792
Validation loss: 1.979702115058899

Epoch: 5| Step: 5
Training loss: 1.628363013267517
Validation loss: 2.1029240867143035

Epoch: 5| Step: 6
Training loss: 1.8992767333984375
Validation loss: 2.000278575446016

Epoch: 5| Step: 7
Training loss: 1.7771472930908203
Validation loss: 2.0971788514044976

Epoch: 5| Step: 8
Training loss: 1.680189847946167
Validation loss: 2.0979230583354993

Epoch: 5| Step: 9
Training loss: 1.2043821811676025
Validation loss: 2.107972309153567

Epoch: 5| Step: 10
Training loss: 1.1418472528457642
Validation loss: 2.046135658858925

Epoch: 481| Step: 0
Training loss: 2.1976282596588135
Validation loss: 2.0064800759797454

Epoch: 5| Step: 1
Training loss: 1.0040736198425293
Validation loss: 2.135318784303563

Epoch: 5| Step: 2
Training loss: 1.5267937183380127
Validation loss: 2.0408224367326304

Epoch: 5| Step: 3
Training loss: 1.892017126083374
Validation loss: 2.026402237594769

Epoch: 5| Step: 4
Training loss: 1.5094325542449951
Validation loss: 2.040029715466243

Epoch: 5| Step: 5
Training loss: 1.9337854385375977
Validation loss: 2.136257443376767

Epoch: 5| Step: 6
Training loss: 1.4296704530715942
Validation loss: 2.005835125523229

Epoch: 5| Step: 7
Training loss: 1.812137246131897
Validation loss: 2.147721154715425

Epoch: 5| Step: 8
Training loss: 1.6432170867919922
Validation loss: 2.040218266107703

Epoch: 5| Step: 9
Training loss: 1.63818359375
Validation loss: 2.111244470842423

Epoch: 5| Step: 10
Training loss: 1.6936784982681274
Validation loss: 2.0993821351758895

Epoch: 482| Step: 0
Training loss: 2.166205883026123
Validation loss: 1.9972994045544696

Epoch: 5| Step: 1
Training loss: 1.365455985069275
Validation loss: 2.0775260848383748

Epoch: 5| Step: 2
Training loss: 1.4832452535629272
Validation loss: 2.0713363719242874

Epoch: 5| Step: 3
Training loss: 1.624780297279358
Validation loss: 2.0942088955192157

Epoch: 5| Step: 4
Training loss: 1.6207069158554077
Validation loss: 2.115307290066955

Epoch: 5| Step: 5
Training loss: 2.448547840118408
Validation loss: 2.052412627845682

Epoch: 5| Step: 6
Training loss: 1.528641939163208
Validation loss: 2.2082558639587893

Epoch: 5| Step: 7
Training loss: 1.3263823986053467
Validation loss: 2.0356951041888167

Epoch: 5| Step: 8
Training loss: 1.79575514793396
Validation loss: 2.0651001045780797

Epoch: 5| Step: 9
Training loss: 1.1984838247299194
Validation loss: 1.9869253750770324

Epoch: 5| Step: 10
Training loss: 1.7111761569976807
Validation loss: 2.0728149285880466

Epoch: 483| Step: 0
Training loss: 1.144980788230896
Validation loss: 2.0933487069222236

Epoch: 5| Step: 1
Training loss: 1.515576720237732
Validation loss: 2.0525832150572088

Epoch: 5| Step: 2
Training loss: 2.4452097415924072
Validation loss: 1.9886394264877483

Epoch: 5| Step: 3
Training loss: 1.6119539737701416
Validation loss: 2.185127612083189

Epoch: 5| Step: 4
Training loss: 1.5652953386306763
Validation loss: 2.0897723295355357

Epoch: 5| Step: 5
Training loss: 1.5753473043441772
Validation loss: 2.067216391204506

Epoch: 5| Step: 6
Training loss: 1.5857268571853638
Validation loss: 2.0058540631366033

Epoch: 5| Step: 7
Training loss: 1.8156681060791016
Validation loss: 1.9880056458134805

Epoch: 5| Step: 8
Training loss: 1.2154479026794434
Validation loss: 2.098398203490883

Epoch: 5| Step: 9
Training loss: 1.668981909751892
Validation loss: 2.103371779123942

Epoch: 5| Step: 10
Training loss: 2.0786349773406982
Validation loss: 2.1026163126832698

Epoch: 484| Step: 0
Training loss: 1.5199613571166992
Validation loss: 2.0833905409741145

Epoch: 5| Step: 1
Training loss: 1.1184402704238892
Validation loss: 2.0743703816526677

Epoch: 5| Step: 2
Training loss: 2.004523754119873
Validation loss: 1.9708491038250666

Epoch: 5| Step: 3
Training loss: 1.4806116819381714
Validation loss: 2.0440611249657086

Epoch: 5| Step: 4
Training loss: 1.7879154682159424
Validation loss: 2.074442248190603

Epoch: 5| Step: 5
Training loss: 1.9553592205047607
Validation loss: 2.082626182545898

Epoch: 5| Step: 6
Training loss: 1.3090234994888306
Validation loss: 2.03885619871078

Epoch: 5| Step: 7
Training loss: 2.174900531768799
Validation loss: 2.064218421136179

Epoch: 5| Step: 8
Training loss: 1.8604711294174194
Validation loss: 2.080949652579523

Epoch: 5| Step: 9
Training loss: 1.3473275899887085
Validation loss: 2.2280635000557028

Epoch: 5| Step: 10
Training loss: 1.753035545349121
Validation loss: 2.158768384687362

Epoch: 485| Step: 0
Training loss: 2.453047037124634
Validation loss: 2.065673000069075

Epoch: 5| Step: 1
Training loss: 1.4664829969406128
Validation loss: 2.0904686425321843

Epoch: 5| Step: 2
Training loss: 1.2688887119293213
Validation loss: 2.105847804777084

Epoch: 5| Step: 3
Training loss: 1.4462782144546509
Validation loss: 2.1003792632010674

Epoch: 5| Step: 4
Training loss: 1.2662626504898071
Validation loss: 2.1106169505785872

Epoch: 5| Step: 5
Training loss: 1.8854742050170898
Validation loss: 1.991873260467283

Epoch: 5| Step: 6
Training loss: 1.4179340600967407
Validation loss: 2.1842349472866265

Epoch: 5| Step: 7
Training loss: 1.7826446294784546
Validation loss: 2.0722628434499106

Epoch: 5| Step: 8
Training loss: 1.7723709344863892
Validation loss: 2.060219927500653

Epoch: 5| Step: 9
Training loss: 2.0300936698913574
Validation loss: 2.1092233914200977

Epoch: 5| Step: 10
Training loss: 1.776421308517456
Validation loss: 2.1740448295429187

Epoch: 486| Step: 0
Training loss: 2.3105127811431885
Validation loss: 2.0551302202286257

Epoch: 5| Step: 1
Training loss: 1.271916389465332
Validation loss: 2.084548855340609

Epoch: 5| Step: 2
Training loss: 1.0012552738189697
Validation loss: 2.0583512847141554

Epoch: 5| Step: 3
Training loss: 1.7095673084259033
Validation loss: 2.1038290428858932

Epoch: 5| Step: 4
Training loss: 1.765899658203125
Validation loss: 1.9511785250838085

Epoch: 5| Step: 5
Training loss: 1.0628859996795654
Validation loss: 2.072508014658446

Epoch: 5| Step: 6
Training loss: 1.5606253147125244
Validation loss: 2.057053883870443

Epoch: 5| Step: 7
Training loss: 1.7890269756317139
Validation loss: 2.0766449384791876

Epoch: 5| Step: 8
Training loss: 1.4305731058120728
Validation loss: 1.995284806015671

Epoch: 5| Step: 9
Training loss: 1.7403671741485596
Validation loss: 2.068078144904106

Epoch: 5| Step: 10
Training loss: 2.199803113937378
Validation loss: 2.037498950958252

Epoch: 487| Step: 0
Training loss: 1.374858021736145
Validation loss: 2.0828176698377057

Epoch: 5| Step: 1
Training loss: 1.760035514831543
Validation loss: 2.047658187086864

Epoch: 5| Step: 2
Training loss: 1.51027512550354
Validation loss: 2.143921157365204

Epoch: 5| Step: 3
Training loss: 1.862969994544983
Validation loss: 2.0330139437029437

Epoch: 5| Step: 4
Training loss: 1.894878625869751
Validation loss: 2.0384258967573925

Epoch: 5| Step: 5
Training loss: 1.551450490951538
Validation loss: 2.1071510673851095

Epoch: 5| Step: 6
Training loss: 1.615041732788086
Validation loss: 2.132645886431458

Epoch: 5| Step: 7
Training loss: 1.627450704574585
Validation loss: 2.1847978714973695

Epoch: 5| Step: 8
Training loss: 1.48409104347229
Validation loss: 2.1517528692881265

Epoch: 5| Step: 9
Training loss: 2.118474006652832
Validation loss: 2.1113322524614233

Epoch: 5| Step: 10
Training loss: 1.8504109382629395
Validation loss: 2.152378761640159

Epoch: 488| Step: 0
Training loss: 1.6096988916397095
Validation loss: 2.140733721435711

Epoch: 5| Step: 1
Training loss: 1.2731170654296875
Validation loss: 2.015518720431994

Epoch: 5| Step: 2
Training loss: 1.688637137413025
Validation loss: 2.0244052230670886

Epoch: 5| Step: 3
Training loss: 1.25344717502594
Validation loss: 2.034599006816905

Epoch: 5| Step: 4
Training loss: 2.120539665222168
Validation loss: 2.0698375855722735

Epoch: 5| Step: 5
Training loss: 1.6681861877441406
Validation loss: 2.0710652387270363

Epoch: 5| Step: 6
Training loss: 2.0066609382629395
Validation loss: 2.041394425976661

Epoch: 5| Step: 7
Training loss: 1.2825981378555298
Validation loss: 2.077732571991541

Epoch: 5| Step: 8
Training loss: 2.5325801372528076
Validation loss: 2.0265164939306115

Epoch: 5| Step: 9
Training loss: 1.1997417211532593
Validation loss: 2.014307261795126

Epoch: 5| Step: 10
Training loss: 1.7666829824447632
Validation loss: 2.0419832147577757

Epoch: 489| Step: 0
Training loss: 1.5703036785125732
Validation loss: 2.054939503310829

Epoch: 5| Step: 1
Training loss: 1.6768087148666382
Validation loss: 2.060795589159894

Epoch: 5| Step: 2
Training loss: 1.8688570261001587
Validation loss: 2.067746880233929

Epoch: 5| Step: 3
Training loss: 1.4565509557724
Validation loss: 2.0659454817413003

Epoch: 5| Step: 4
Training loss: 1.696032166481018
Validation loss: 2.0866899003264723

Epoch: 5| Step: 5
Training loss: 1.7246755361557007
Validation loss: 2.061686549135434

Epoch: 5| Step: 6
Training loss: 1.238890528678894
Validation loss: 2.1347901410953973

Epoch: 5| Step: 7
Training loss: 1.430580735206604
Validation loss: 2.094816533468103

Epoch: 5| Step: 8
Training loss: 2.1523354053497314
Validation loss: 2.0611088916819584

Epoch: 5| Step: 9
Training loss: 1.5665351152420044
Validation loss: 2.0262477128736434

Epoch: 5| Step: 10
Training loss: 1.8087224960327148
Validation loss: 2.072396970564319

Epoch: 490| Step: 0
Training loss: 1.3922405242919922
Validation loss: 2.067721166918355

Epoch: 5| Step: 1
Training loss: 1.7432925701141357
Validation loss: 2.0472805653848956

Epoch: 5| Step: 2
Training loss: 2.227261781692505
Validation loss: 2.066137065169632

Epoch: 5| Step: 3
Training loss: 1.2773711681365967
Validation loss: 2.0923309531263126

Epoch: 5| Step: 4
Training loss: 1.1476666927337646
Validation loss: 2.131844315477597

Epoch: 5| Step: 5
Training loss: 1.513369083404541
Validation loss: 2.095390537733673

Epoch: 5| Step: 6
Training loss: 1.8851165771484375
Validation loss: 2.1154835531788487

Epoch: 5| Step: 7
Training loss: 1.9174091815948486
Validation loss: 2.0093092751759354

Epoch: 5| Step: 8
Training loss: 1.7815498113632202
Validation loss: 2.0299580276653333

Epoch: 5| Step: 9
Training loss: 1.3557844161987305
Validation loss: 2.040038166507598

Epoch: 5| Step: 10
Training loss: 1.9617208242416382
Validation loss: 2.1211619274590605

Epoch: 491| Step: 0
Training loss: 2.5246825218200684
Validation loss: 2.08332375941738

Epoch: 5| Step: 1
Training loss: 1.5597399473190308
Validation loss: 2.0722253655874603

Epoch: 5| Step: 2
Training loss: 1.045000433921814
Validation loss: 2.0033771555910826

Epoch: 5| Step: 3
Training loss: 2.0157864093780518
Validation loss: 2.0243060845200733

Epoch: 5| Step: 4
Training loss: 1.5322091579437256
Validation loss: 2.057630382558351

Epoch: 5| Step: 5
Training loss: 1.7575187683105469
Validation loss: 2.0737407348489247

Epoch: 5| Step: 6
Training loss: 1.306036353111267
Validation loss: 2.025501534502993

Epoch: 5| Step: 7
Training loss: 2.070526599884033
Validation loss: 2.092133561770121

Epoch: 5| Step: 8
Training loss: 1.6874077320098877
Validation loss: 2.0703367469131306

Epoch: 5| Step: 9
Training loss: 1.3468818664550781
Validation loss: 2.0768070285038283

Epoch: 5| Step: 10
Training loss: 1.2608338594436646
Validation loss: 2.026528626359919

Epoch: 492| Step: 0
Training loss: 1.491166591644287
Validation loss: 2.079870980273011

Epoch: 5| Step: 1
Training loss: 1.4525467157363892
Validation loss: 2.0800111857793664

Epoch: 5| Step: 2
Training loss: 1.485562801361084
Validation loss: 2.0787780823246127

Epoch: 5| Step: 3
Training loss: 1.853301763534546
Validation loss: 2.1499907880701046

Epoch: 5| Step: 4
Training loss: 1.6469297409057617
Validation loss: 2.1763017613400697

Epoch: 5| Step: 5
Training loss: 1.1615177392959595
Validation loss: 2.0789116710744877

Epoch: 5| Step: 6
Training loss: 1.175511121749878
Validation loss: 2.0385690401959162

Epoch: 5| Step: 7
Training loss: 2.1349825859069824
Validation loss: 2.2083171003608295

Epoch: 5| Step: 8
Training loss: 2.648031234741211
Validation loss: 2.049587813756799

Epoch: 5| Step: 9
Training loss: 1.1343281269073486
Validation loss: 2.077175558254283

Epoch: 5| Step: 10
Training loss: 1.1322529315948486
Validation loss: 2.0979948172005276

Epoch: 493| Step: 0
Training loss: 1.3948657512664795
Validation loss: 2.008343518421214

Epoch: 5| Step: 1
Training loss: 2.0838687419891357
Validation loss: 2.121079606394614

Epoch: 5| Step: 2
Training loss: 1.757110357284546
Validation loss: 2.0366803523032897

Epoch: 5| Step: 3
Training loss: 1.5988705158233643
Validation loss: 1.9908759978509718

Epoch: 5| Step: 4
Training loss: 1.328160285949707
Validation loss: 2.0298790342064312

Epoch: 5| Step: 5
Training loss: 1.8076705932617188
Validation loss: 2.1319257828497116

Epoch: 5| Step: 6
Training loss: 1.3169491291046143
Validation loss: 2.025347344336971

Epoch: 5| Step: 7
Training loss: 2.069143295288086
Validation loss: 2.132219209465929

Epoch: 5| Step: 8
Training loss: 1.3882272243499756
Validation loss: 2.0390259450481785

Epoch: 5| Step: 9
Training loss: 1.4976789951324463
Validation loss: 2.0833647994584936

Epoch: 5| Step: 10
Training loss: 1.5470621585845947
Validation loss: 1.9831601317210863

Epoch: 494| Step: 0
Training loss: 2.06253719329834
Validation loss: 2.103958293955813

Epoch: 5| Step: 1
Training loss: 1.2049962282180786
Validation loss: 2.0524884885357273

Epoch: 5| Step: 2
Training loss: 1.3249584436416626
Validation loss: 1.9400964116537442

Epoch: 5| Step: 3
Training loss: 2.0936481952667236
Validation loss: 2.0353278101131482

Epoch: 5| Step: 4
Training loss: 1.7867799997329712
Validation loss: 2.06950593122872

Epoch: 5| Step: 5
Training loss: 1.3982430696487427
Validation loss: 2.1338577244871404

Epoch: 5| Step: 6
Training loss: 2.3305013179779053
Validation loss: 2.11595049981148

Epoch: 5| Step: 7
Training loss: 1.3628045320510864
Validation loss: 2.1298913340414725

Epoch: 5| Step: 8
Training loss: 1.383507490158081
Validation loss: 2.107484990550626

Epoch: 5| Step: 9
Training loss: 1.8540105819702148
Validation loss: 2.1706892533968856

Epoch: 5| Step: 10
Training loss: 1.5504605770111084
Validation loss: 2.030330991232267

Epoch: 495| Step: 0
Training loss: 1.144897699356079
Validation loss: 2.0584002130775043

Epoch: 5| Step: 1
Training loss: 1.5128318071365356
Validation loss: 2.0810370522160686

Epoch: 5| Step: 2
Training loss: 1.1582762002944946
Validation loss: 2.0721114912340717

Epoch: 5| Step: 3
Training loss: 1.757134199142456
Validation loss: 2.056489964967133

Epoch: 5| Step: 4
Training loss: 1.673112154006958
Validation loss: 2.1003397331442883

Epoch: 5| Step: 5
Training loss: 2.2287919521331787
Validation loss: 2.082057870844359

Epoch: 5| Step: 6
Training loss: 1.5166370868682861
Validation loss: 2.039759517997824

Epoch: 5| Step: 7
Training loss: 1.8399772644042969
Validation loss: 1.9899451796726515

Epoch: 5| Step: 8
Training loss: 2.0690219402313232
Validation loss: 2.0137794402337845

Epoch: 5| Step: 9
Training loss: 1.6222540140151978
Validation loss: 2.116646792299004

Epoch: 5| Step: 10
Training loss: 1.7509185075759888
Validation loss: 2.075619965471247

Epoch: 496| Step: 0
Training loss: 1.4131263494491577
Validation loss: 2.046970784023244

Epoch: 5| Step: 1
Training loss: 2.1042137145996094
Validation loss: 1.9288961374631493

Epoch: 5| Step: 2
Training loss: 1.4102518558502197
Validation loss: 2.0836525232561174

Epoch: 5| Step: 3
Training loss: 1.2002859115600586
Validation loss: 2.0613853751972155

Epoch: 5| Step: 4
Training loss: 1.6451873779296875
Validation loss: 2.110567605623635

Epoch: 5| Step: 5
Training loss: 1.46328866481781
Validation loss: 1.9660734591945526

Epoch: 5| Step: 6
Training loss: 2.067354202270508
Validation loss: 2.027216011478055

Epoch: 5| Step: 7
Training loss: 1.8565704822540283
Validation loss: 2.0705990637502363

Epoch: 5| Step: 8
Training loss: 1.6259281635284424
Validation loss: 2.070008782930272

Epoch: 5| Step: 9
Training loss: 1.4529656171798706
Validation loss: 2.0358536576712005

Epoch: 5| Step: 10
Training loss: 2.240241765975952
Validation loss: 2.0379288863110285

Epoch: 497| Step: 0
Training loss: 1.202699065208435
Validation loss: 2.052521695372879

Epoch: 5| Step: 1
Training loss: 1.7881845235824585
Validation loss: 2.090313243609603

Epoch: 5| Step: 2
Training loss: 1.8652164936065674
Validation loss: 2.069738459843461

Epoch: 5| Step: 3
Training loss: 1.6485979557037354
Validation loss: 2.121212746507378

Epoch: 5| Step: 4
Training loss: 1.4120914936065674
Validation loss: 2.126957262715986

Epoch: 5| Step: 5
Training loss: 1.5297155380249023
Validation loss: 2.147520537017494

Epoch: 5| Step: 6
Training loss: 1.9768257141113281
Validation loss: 1.987061890222693

Epoch: 5| Step: 7
Training loss: 1.1868197917938232
Validation loss: 1.963670313999217

Epoch: 5| Step: 8
Training loss: 1.4509198665618896
Validation loss: 2.0173287058389313

Epoch: 5| Step: 9
Training loss: 1.5274527072906494
Validation loss: 2.0880705284815964

Epoch: 5| Step: 10
Training loss: 2.1554367542266846
Validation loss: 2.003662663121377

Epoch: 498| Step: 0
Training loss: 1.8318980932235718
Validation loss: 2.0561802053964264

Epoch: 5| Step: 1
Training loss: 1.871330976486206
Validation loss: 2.0842860103935323

Epoch: 5| Step: 2
Training loss: 1.331709861755371
Validation loss: 1.9885142939065092

Epoch: 5| Step: 3
Training loss: 1.178261637687683
Validation loss: 2.041236096812833

Epoch: 5| Step: 4
Training loss: 1.8964347839355469
Validation loss: 2.009271352521835

Epoch: 5| Step: 5
Training loss: 1.3209731578826904
Validation loss: 1.9995191994533743

Epoch: 5| Step: 6
Training loss: 0.9555867314338684
Validation loss: 2.0989461714221584

Epoch: 5| Step: 7
Training loss: 1.9956769943237305
Validation loss: 2.026135306204519

Epoch: 5| Step: 8
Training loss: 1.8497730493545532
Validation loss: 1.9959005604508102

Epoch: 5| Step: 9
Training loss: 1.8619804382324219
Validation loss: 1.9338138936668314

Epoch: 5| Step: 10
Training loss: 1.3063318729400635
Validation loss: 2.053703769560783

Epoch: 499| Step: 0
Training loss: 2.113640546798706
Validation loss: 2.0423430012118433

Epoch: 5| Step: 1
Training loss: 2.438220977783203
Validation loss: 2.142765837330972

Epoch: 5| Step: 2
Training loss: 1.4227955341339111
Validation loss: 2.188580330982003

Epoch: 5| Step: 3
Training loss: 1.3598905801773071
Validation loss: 2.114977882754418

Epoch: 5| Step: 4
Training loss: 2.0451292991638184
Validation loss: 2.0447973256470053

Epoch: 5| Step: 5
Training loss: 1.4429576396942139
Validation loss: 2.0845513830902758

Epoch: 5| Step: 6
Training loss: 1.8228776454925537
Validation loss: 2.0599498902597735

Epoch: 5| Step: 7
Training loss: 1.5082145929336548
Validation loss: 2.0439874779793525

Epoch: 5| Step: 8
Training loss: 1.5616943836212158
Validation loss: 2.0491893676019486

Epoch: 5| Step: 9
Training loss: 1.556701421737671
Validation loss: 1.9887514511744182

Epoch: 5| Step: 10
Training loss: 1.59965980052948
Validation loss: 2.0022624051699074

Epoch: 500| Step: 0
Training loss: 1.5952574014663696
Validation loss: 2.055039403259113

Epoch: 5| Step: 1
Training loss: 1.5465971231460571
Validation loss: 1.9473111296212802

Epoch: 5| Step: 2
Training loss: 1.9109575748443604
Validation loss: 2.105162328289401

Epoch: 5| Step: 3
Training loss: 1.4961862564086914
Validation loss: 2.0408291329619703

Epoch: 5| Step: 4
Training loss: 2.218026638031006
Validation loss: 2.033691818996142

Epoch: 5| Step: 5
Training loss: 1.4261304140090942
Validation loss: 2.09494407843518

Epoch: 5| Step: 6
Training loss: 1.46294105052948
Validation loss: 2.0406367368595575

Epoch: 5| Step: 7
Training loss: 1.5294780731201172
Validation loss: 2.0293502320525465

Epoch: 5| Step: 8
Training loss: 1.48063325881958
Validation loss: 2.0736944034535396

Epoch: 5| Step: 9
Training loss: 1.9234342575073242
Validation loss: 2.0071302511358775

Epoch: 5| Step: 10
Training loss: 1.8482404947280884
Validation loss: 2.0825536609977804

Epoch: 501| Step: 0
Training loss: 1.5800201892852783
Validation loss: 2.089802086994212

Epoch: 5| Step: 1
Training loss: 1.3090178966522217
Validation loss: 2.1093862620733117

Epoch: 5| Step: 2
Training loss: 1.9070628881454468
Validation loss: 1.9825529988094042

Epoch: 5| Step: 3
Training loss: 2.19551420211792
Validation loss: 2.022775965352212

Epoch: 5| Step: 4
Training loss: 1.6638085842132568
Validation loss: 1.9886935795507124

Epoch: 5| Step: 5
Training loss: 1.6950048208236694
Validation loss: 2.02755469147877

Epoch: 5| Step: 6
Training loss: 2.0690956115722656
Validation loss: 1.993352477268506

Epoch: 5| Step: 7
Training loss: 2.233705997467041
Validation loss: 2.059160073598226

Epoch: 5| Step: 8
Training loss: 1.2112725973129272
Validation loss: 1.962333490771632

Epoch: 5| Step: 9
Training loss: 1.3998992443084717
Validation loss: 2.050594805389322

Epoch: 5| Step: 10
Training loss: 1.2724652290344238
Validation loss: 2.0281964604572584

Epoch: 502| Step: 0
Training loss: 1.9573971033096313
Validation loss: 1.9699575465212587

Epoch: 5| Step: 1
Training loss: 1.4553793668746948
Validation loss: 2.1296208468816613

Epoch: 5| Step: 2
Training loss: 1.763330101966858
Validation loss: 2.1343425807132514

Epoch: 5| Step: 3
Training loss: 1.6275866031646729
Validation loss: 2.0589967402078773

Epoch: 5| Step: 4
Training loss: 1.0909688472747803
Validation loss: 2.1620778550383863

Epoch: 5| Step: 5
Training loss: 1.4436931610107422
Validation loss: 2.1141054732825166

Epoch: 5| Step: 6
Training loss: 1.8311569690704346
Validation loss: 2.1603990216409006

Epoch: 5| Step: 7
Training loss: 1.7823078632354736
Validation loss: 2.1797698646463375

Epoch: 5| Step: 8
Training loss: 1.699735403060913
Validation loss: 2.0443241916677004

Epoch: 5| Step: 9
Training loss: 1.290968894958496
Validation loss: 2.137476969790715

Epoch: 5| Step: 10
Training loss: 1.4735580682754517
Validation loss: 2.1526209154436664

Epoch: 503| Step: 0
Training loss: 1.540331482887268
Validation loss: 2.0088750470069145

Epoch: 5| Step: 1
Training loss: 1.5339679718017578
Validation loss: 2.070513859871895

Epoch: 5| Step: 2
Training loss: 1.4911372661590576
Validation loss: 2.0637223400095457

Epoch: 5| Step: 3
Training loss: 1.5203394889831543
Validation loss: 2.0442017304000033

Epoch: 5| Step: 4
Training loss: 1.7683185338974
Validation loss: 2.0765342789311565

Epoch: 5| Step: 5
Training loss: 1.5268558263778687
Validation loss: 2.1157905901632

Epoch: 5| Step: 6
Training loss: 1.4998931884765625
Validation loss: 2.110297786292209

Epoch: 5| Step: 7
Training loss: 2.140505790710449
Validation loss: 2.1594715605499926

Epoch: 5| Step: 8
Training loss: 1.642011046409607
Validation loss: 2.1556460729209324

Epoch: 5| Step: 9
Training loss: 1.4947257041931152
Validation loss: 2.1454712908755065

Epoch: 5| Step: 10
Training loss: 1.7449055910110474
Validation loss: 2.0981181436969387

Epoch: 504| Step: 0
Training loss: 1.4885456562042236
Validation loss: 2.0601634005064606

Epoch: 5| Step: 1
Training loss: 1.147834300994873
Validation loss: 2.007409667456022

Epoch: 5| Step: 2
Training loss: 2.044084072113037
Validation loss: 2.075563751241212

Epoch: 5| Step: 3
Training loss: 1.7587426900863647
Validation loss: 2.075548994925714

Epoch: 5| Step: 4
Training loss: 2.0454487800598145
Validation loss: 2.0971859539708784

Epoch: 5| Step: 5
Training loss: 1.4267699718475342
Validation loss: 2.1274996111469884

Epoch: 5| Step: 6
Training loss: 1.2830463647842407
Validation loss: 2.064041514550486

Epoch: 5| Step: 7
Training loss: 1.5395416021347046
Validation loss: 2.0928913060054986

Epoch: 5| Step: 8
Training loss: 1.7848072052001953
Validation loss: 2.0659564541232203

Epoch: 5| Step: 9
Training loss: 2.108769178390503
Validation loss: 2.037750191585992

Epoch: 5| Step: 10
Training loss: 1.8060789108276367
Validation loss: 2.0379623200303767

Epoch: 505| Step: 0
Training loss: 1.1926467418670654
Validation loss: 2.086301465188303

Epoch: 5| Step: 1
Training loss: 1.3796238899230957
Validation loss: 2.085490160090949

Epoch: 5| Step: 2
Training loss: 1.4099273681640625
Validation loss: 2.118954268834924

Epoch: 5| Step: 3
Training loss: 1.6401832103729248
Validation loss: 2.073520721927766

Epoch: 5| Step: 4
Training loss: 1.3584785461425781
Validation loss: 2.108198881149292

Epoch: 5| Step: 5
Training loss: 2.3083348274230957
Validation loss: 2.096212053811678

Epoch: 5| Step: 6
Training loss: 1.004927635192871
Validation loss: 2.046260751703734

Epoch: 5| Step: 7
Training loss: 2.2072794437408447
Validation loss: 1.942125396061969

Epoch: 5| Step: 8
Training loss: 1.7222106456756592
Validation loss: 2.0507287543307067

Epoch: 5| Step: 9
Training loss: 2.1057662963867188
Validation loss: 2.056322552824533

Epoch: 5| Step: 10
Training loss: 1.682661533355713
Validation loss: 2.0602846107175274

Epoch: 506| Step: 0
Training loss: 1.66398024559021
Validation loss: 2.0900990962982178

Epoch: 5| Step: 1
Training loss: 1.7897300720214844
Validation loss: 2.172200177305488

Epoch: 5| Step: 2
Training loss: 1.5092661380767822
Validation loss: 2.1385053780771073

Epoch: 5| Step: 3
Training loss: 1.7040584087371826
Validation loss: 2.202468761833765

Epoch: 5| Step: 4
Training loss: 1.0804067850112915
Validation loss: 2.1210867897156747

Epoch: 5| Step: 5
Training loss: 2.154387950897217
Validation loss: 2.0221981284438924

Epoch: 5| Step: 6
Training loss: 1.663735032081604
Validation loss: 2.0238039544833604

Epoch: 5| Step: 7
Training loss: 1.3073326349258423
Validation loss: 2.059863375079247

Epoch: 5| Step: 8
Training loss: 1.1529470682144165
Validation loss: 2.210575826706425

Epoch: 5| Step: 9
Training loss: 1.6281750202178955
Validation loss: 2.167425504294775

Epoch: 5| Step: 10
Training loss: 2.3322970867156982
Validation loss: 2.1029475722261655

Epoch: 507| Step: 0
Training loss: 1.4549076557159424
Validation loss: 2.153525285823371

Epoch: 5| Step: 1
Training loss: 1.6007130146026611
Validation loss: 2.1607110705426944

Epoch: 5| Step: 2
Training loss: 1.5495924949645996
Validation loss: 2.0682665801817373

Epoch: 5| Step: 3
Training loss: 1.1482880115509033
Validation loss: 2.0957603505862656

Epoch: 5| Step: 4
Training loss: 2.181037664413452
Validation loss: 2.1247882022652576

Epoch: 5| Step: 5
Training loss: 1.6586437225341797
Validation loss: 2.080919886148104

Epoch: 5| Step: 6
Training loss: 1.4786808490753174
Validation loss: 2.121202056125928

Epoch: 5| Step: 7
Training loss: 1.3493187427520752
Validation loss: 2.053640671955642

Epoch: 5| Step: 8
Training loss: 2.311594009399414
Validation loss: 2.0273845041951826

Epoch: 5| Step: 9
Training loss: 1.02730393409729
Validation loss: 2.1348732440702376

Epoch: 5| Step: 10
Training loss: 1.7241462469100952
Validation loss: 2.1063065746779084

Epoch: 508| Step: 0
Training loss: 1.520868182182312
Validation loss: 2.02984558638706

Epoch: 5| Step: 1
Training loss: 1.3167625665664673
Validation loss: 2.040766824958145

Epoch: 5| Step: 2
Training loss: 2.0414204597473145
Validation loss: 2.024604623035718

Epoch: 5| Step: 3
Training loss: 1.6519321203231812
Validation loss: 2.0957391108236005

Epoch: 5| Step: 4
Training loss: 1.3148813247680664
Validation loss: 2.0711107792392855

Epoch: 5| Step: 5
Training loss: 1.3304698467254639
Validation loss: 1.995330072218372

Epoch: 5| Step: 6
Training loss: 1.831047773361206
Validation loss: 1.9488572638521913

Epoch: 5| Step: 7
Training loss: 1.715135931968689
Validation loss: 2.174358111555858

Epoch: 5| Step: 8
Training loss: 1.8154850006103516
Validation loss: 2.091116146374774

Epoch: 5| Step: 9
Training loss: 2.0290961265563965
Validation loss: 2.135529769364224

Epoch: 5| Step: 10
Training loss: 1.527571678161621
Validation loss: 2.1247008897924937

Epoch: 509| Step: 0
Training loss: 1.610812783241272
Validation loss: 2.123419245084127

Epoch: 5| Step: 1
Training loss: 1.4334722757339478
Validation loss: 2.0903393888986237

Epoch: 5| Step: 2
Training loss: 1.9709056615829468
Validation loss: 2.0126597509589246

Epoch: 5| Step: 3
Training loss: 1.8916146755218506
Validation loss: 2.226115513873357

Epoch: 5| Step: 4
Training loss: 1.5932660102844238
Validation loss: 2.019958287157038

Epoch: 5| Step: 5
Training loss: 1.6068041324615479
Validation loss: 2.0707326268637054

Epoch: 5| Step: 6
Training loss: 1.7354940176010132
Validation loss: 2.118984842813143

Epoch: 5| Step: 7
Training loss: 1.0074694156646729
Validation loss: 2.1445158015015306

Epoch: 5| Step: 8
Training loss: 1.8660475015640259
Validation loss: 2.0910529346876245

Epoch: 5| Step: 9
Training loss: 1.9002430438995361
Validation loss: 2.1295535359331357

Epoch: 5| Step: 10
Training loss: 1.5342624187469482
Validation loss: 2.0863814405215684

Epoch: 510| Step: 0
Training loss: 1.2523908615112305
Validation loss: 2.0290627171916347

Epoch: 5| Step: 1
Training loss: 1.7761032581329346
Validation loss: 2.0191582005511046

Epoch: 5| Step: 2
Training loss: 1.1578007936477661
Validation loss: 1.967996274271319

Epoch: 5| Step: 3
Training loss: 1.0290195941925049
Validation loss: 2.1710338618165705

Epoch: 5| Step: 4
Training loss: 1.5349891185760498
Validation loss: 2.1238221289009176

Epoch: 5| Step: 5
Training loss: 1.594359040260315
Validation loss: 2.0511705977942354

Epoch: 5| Step: 6
Training loss: 2.3163466453552246
Validation loss: 1.9983120387600315

Epoch: 5| Step: 7
Training loss: 1.4906994104385376
Validation loss: 2.128592050203713

Epoch: 5| Step: 8
Training loss: 1.2261221408843994
Validation loss: 2.1645606384482434

Epoch: 5| Step: 9
Training loss: 1.7824205160140991
Validation loss: 2.103529025149602

Epoch: 5| Step: 10
Training loss: 1.996928095817566
Validation loss: 2.0727267060228574

Epoch: 511| Step: 0
Training loss: 1.5773231983184814
Validation loss: 2.0686467693698023

Epoch: 5| Step: 1
Training loss: 2.0299782752990723
Validation loss: 2.091239707444304

Epoch: 5| Step: 2
Training loss: 1.3957757949829102
Validation loss: 2.0440835440030662

Epoch: 5| Step: 3
Training loss: 1.3625043630599976
Validation loss: 2.0597993840453444

Epoch: 5| Step: 4
Training loss: 2.0422024726867676
Validation loss: 2.0506183485830984

Epoch: 5| Step: 5
Training loss: 1.7581007480621338
Validation loss: 2.1140890018914336

Epoch: 5| Step: 6
Training loss: 1.378633737564087
Validation loss: 2.0259140614540345

Epoch: 5| Step: 7
Training loss: 2.234830617904663
Validation loss: 2.021065245392502

Epoch: 5| Step: 8
Training loss: 1.3931748867034912
Validation loss: 2.127755908555882

Epoch: 5| Step: 9
Training loss: 1.5924580097198486
Validation loss: 2.1598860679134244

Epoch: 5| Step: 10
Training loss: 1.0126910209655762
Validation loss: 2.019026581959058

Epoch: 512| Step: 0
Training loss: 2.39532470703125
Validation loss: 2.0399867180855042

Epoch: 5| Step: 1
Training loss: 1.1862808465957642
Validation loss: 2.118454702438847

Epoch: 5| Step: 2
Training loss: 1.6067603826522827
Validation loss: 2.0650559458681332

Epoch: 5| Step: 3
Training loss: 1.9932464361190796
Validation loss: 2.0288370552883355

Epoch: 5| Step: 4
Training loss: 1.3461989164352417
Validation loss: 2.091583113516531

Epoch: 5| Step: 5
Training loss: 1.5682884454727173
Validation loss: 2.030968241794135

Epoch: 5| Step: 6
Training loss: 1.4518753290176392
Validation loss: 2.0548211451499694

Epoch: 5| Step: 7
Training loss: 1.74626886844635
Validation loss: 2.0208846907461844

Epoch: 5| Step: 8
Training loss: 1.6519674062728882
Validation loss: 2.044617731084106

Epoch: 5| Step: 9
Training loss: 1.109175443649292
Validation loss: 2.067327259689249

Epoch: 5| Step: 10
Training loss: 1.5285868644714355
Validation loss: 2.126023655296654

Epoch: 513| Step: 0
Training loss: 1.7280848026275635
Validation loss: 2.006261502542803

Epoch: 5| Step: 1
Training loss: 1.9327913522720337
Validation loss: 2.004583863801854

Epoch: 5| Step: 2
Training loss: 1.6741621494293213
Validation loss: 2.0693340198968047

Epoch: 5| Step: 3
Training loss: 1.4715102910995483
Validation loss: 2.164963012100548

Epoch: 5| Step: 4
Training loss: 1.335909128189087
Validation loss: 2.1560458752416793

Epoch: 5| Step: 5
Training loss: 1.3406888246536255
Validation loss: 2.0983204585249706

Epoch: 5| Step: 6
Training loss: 1.660247802734375
Validation loss: 2.084245688171797

Epoch: 5| Step: 7
Training loss: 1.7133915424346924
Validation loss: 2.0764758022882606

Epoch: 5| Step: 8
Training loss: 1.627073884010315
Validation loss: 2.1230587702925487

Epoch: 5| Step: 9
Training loss: 1.2305594682693481
Validation loss: 2.0861564208102483

Epoch: 5| Step: 10
Training loss: 1.331727385520935
Validation loss: 2.0847671326770576

Epoch: 514| Step: 0
Training loss: 1.597515344619751
Validation loss: 2.188018342500092

Epoch: 5| Step: 1
Training loss: 1.374799132347107
Validation loss: 2.1518005709494314

Epoch: 5| Step: 2
Training loss: 1.7079204320907593
Validation loss: 2.042786593078285

Epoch: 5| Step: 3
Training loss: 1.6846994161605835
Validation loss: 2.082043242710893

Epoch: 5| Step: 4
Training loss: 1.5750048160552979
Validation loss: 2.1969139063230125

Epoch: 5| Step: 5
Training loss: 1.493544340133667
Validation loss: 2.073654818278487

Epoch: 5| Step: 6
Training loss: 2.200809955596924
Validation loss: 2.130986764866819

Epoch: 5| Step: 7
Training loss: 1.6611751317977905
Validation loss: 2.0575285278340822

Epoch: 5| Step: 8
Training loss: 1.2851516008377075
Validation loss: 2.037742466054937

Epoch: 5| Step: 9
Training loss: 2.072641611099243
Validation loss: 2.0458285654744794

Epoch: 5| Step: 10
Training loss: 1.4092261791229248
Validation loss: 2.095536990832257

Epoch: 515| Step: 0
Training loss: 1.3787819147109985
Validation loss: 1.989499322829708

Epoch: 5| Step: 1
Training loss: 1.867161512374878
Validation loss: 1.988670837494635

Epoch: 5| Step: 2
Training loss: 1.6995763778686523
Validation loss: 2.044241927003348

Epoch: 5| Step: 3
Training loss: 1.1821789741516113
Validation loss: 2.1282708119320612

Epoch: 5| Step: 4
Training loss: 1.8314012289047241
Validation loss: 2.119696572262754

Epoch: 5| Step: 5
Training loss: 2.0016212463378906
Validation loss: 2.011568852650222

Epoch: 5| Step: 6
Training loss: 1.8648369312286377
Validation loss: 2.1635833914561937

Epoch: 5| Step: 7
Training loss: 1.2670965194702148
Validation loss: 2.0758485999158633

Epoch: 5| Step: 8
Training loss: 1.7520864009857178
Validation loss: 2.111426612382294

Epoch: 5| Step: 9
Training loss: 1.4678689241409302
Validation loss: 2.1398147318952825

Epoch: 5| Step: 10
Training loss: 1.6832735538482666
Validation loss: 2.0461676005394227

Epoch: 516| Step: 0
Training loss: 1.5743510723114014
Validation loss: 2.1518217735393073

Epoch: 5| Step: 1
Training loss: 1.810856819152832
Validation loss: 2.1367128049173663

Epoch: 5| Step: 2
Training loss: 1.9072580337524414
Validation loss: 2.0454135505102014

Epoch: 5| Step: 3
Training loss: 1.215604543685913
Validation loss: 2.098914941151937

Epoch: 5| Step: 4
Training loss: 2.2389018535614014
Validation loss: 2.028917717677291

Epoch: 5| Step: 5
Training loss: 1.4423872232437134
Validation loss: 2.14447642654501

Epoch: 5| Step: 6
Training loss: 1.3448996543884277
Validation loss: 2.0826126375506

Epoch: 5| Step: 7
Training loss: 1.2780230045318604
Validation loss: 2.00241845269357

Epoch: 5| Step: 8
Training loss: 1.4598479270935059
Validation loss: 2.1474055961896013

Epoch: 5| Step: 9
Training loss: 1.766334891319275
Validation loss: 1.9523893966469714

Epoch: 5| Step: 10
Training loss: 1.8625686168670654
Validation loss: 2.0821400380903676

Epoch: 517| Step: 0
Training loss: 1.1498088836669922
Validation loss: 1.9904927540850896

Epoch: 5| Step: 1
Training loss: 1.508506417274475
Validation loss: 2.0575305467010825

Epoch: 5| Step: 2
Training loss: 2.1102986335754395
Validation loss: 2.075635956179711

Epoch: 5| Step: 3
Training loss: 1.2639645338058472
Validation loss: 2.144778897685389

Epoch: 5| Step: 4
Training loss: 1.7263062000274658
Validation loss: 2.029009234520697

Epoch: 5| Step: 5
Training loss: 1.4735488891601562
Validation loss: 2.032061061551494

Epoch: 5| Step: 6
Training loss: 2.2194759845733643
Validation loss: 2.119694432904643

Epoch: 5| Step: 7
Training loss: 1.5051851272583008
Validation loss: 2.145913944449476

Epoch: 5| Step: 8
Training loss: 1.5121129751205444
Validation loss: 2.1505740201601418

Epoch: 5| Step: 9
Training loss: 1.5985462665557861
Validation loss: 2.0352001420913206

Epoch: 5| Step: 10
Training loss: 1.6923296451568604
Validation loss: 2.061508124874484

Epoch: 518| Step: 0
Training loss: 1.5833399295806885
Validation loss: 2.0498540068185456

Epoch: 5| Step: 1
Training loss: 1.48984694480896
Validation loss: 2.0852618063649824

Epoch: 5| Step: 2
Training loss: 1.9512345790863037
Validation loss: 2.1425511760096394

Epoch: 5| Step: 3
Training loss: 1.5635877847671509
Validation loss: 2.0817179526052167

Epoch: 5| Step: 4
Training loss: 1.2646530866622925
Validation loss: 2.0739926625323553

Epoch: 5| Step: 5
Training loss: 2.1093802452087402
Validation loss: 2.1485674432528916

Epoch: 5| Step: 6
Training loss: 1.0066914558410645
Validation loss: 2.029630563592398

Epoch: 5| Step: 7
Training loss: 1.1901479959487915
Validation loss: 1.990863710321406

Epoch: 5| Step: 8
Training loss: 1.5479786396026611
Validation loss: 2.133673805062489

Epoch: 5| Step: 9
Training loss: 1.538720726966858
Validation loss: 2.028995197306397

Epoch: 5| Step: 10
Training loss: 1.8163654804229736
Validation loss: 2.0188935713101457

Epoch: 519| Step: 0
Training loss: 1.4351999759674072
Validation loss: 1.9999037045304493

Epoch: 5| Step: 1
Training loss: 1.6344016790390015
Validation loss: 1.9768951144269717

Epoch: 5| Step: 2
Training loss: 1.7036272287368774
Validation loss: 2.026949373624658

Epoch: 5| Step: 3
Training loss: 1.638513207435608
Validation loss: 2.014661165975755

Epoch: 5| Step: 4
Training loss: 1.4281646013259888
Validation loss: 2.052165239087997

Epoch: 5| Step: 5
Training loss: 1.553359866142273
Validation loss: 1.9680137403549687

Epoch: 5| Step: 6
Training loss: 1.6724891662597656
Validation loss: 2.0616340252660934

Epoch: 5| Step: 7
Training loss: 1.6750431060791016
Validation loss: 2.036030384802049

Epoch: 5| Step: 8
Training loss: 1.8209655284881592
Validation loss: 2.1305358191972137

Epoch: 5| Step: 9
Training loss: 2.024183750152588
Validation loss: 2.1125693833956154

Epoch: 5| Step: 10
Training loss: 1.6662664413452148
Validation loss: 2.157246720406317

Epoch: 520| Step: 0
Training loss: 1.317091941833496
Validation loss: 2.0345155923597273

Epoch: 5| Step: 1
Training loss: 1.5433794260025024
Validation loss: 2.0382430002253544

Epoch: 5| Step: 2
Training loss: 2.218092203140259
Validation loss: 2.075520110386674

Epoch: 5| Step: 3
Training loss: 1.2317593097686768
Validation loss: 2.0795488588271605

Epoch: 5| Step: 4
Training loss: 2.022620439529419
Validation loss: 2.13846178208628

Epoch: 5| Step: 5
Training loss: 1.583108901977539
Validation loss: 2.0795853868607552

Epoch: 5| Step: 6
Training loss: 1.2408841848373413
Validation loss: 2.118505326650476

Epoch: 5| Step: 7
Training loss: 1.9593044519424438
Validation loss: 2.118765031137774

Epoch: 5| Step: 8
Training loss: 1.2891477346420288
Validation loss: 2.065095822016398

Epoch: 5| Step: 9
Training loss: 1.8663593530654907
Validation loss: 2.1249050119871735

Epoch: 5| Step: 10
Training loss: 1.5303032398223877
Validation loss: 2.044652485078381

Epoch: 521| Step: 0
Training loss: 1.0739212036132812
Validation loss: 2.069060834505225

Epoch: 5| Step: 1
Training loss: 1.593617558479309
Validation loss: 1.993863897938882

Epoch: 5| Step: 2
Training loss: 2.205404043197632
Validation loss: 2.0643488950626825

Epoch: 5| Step: 3
Training loss: 1.3563450574874878
Validation loss: 2.0942549167140836

Epoch: 5| Step: 4
Training loss: 1.4512908458709717
Validation loss: 2.0821147247027327

Epoch: 5| Step: 5
Training loss: 1.7179460525512695
Validation loss: 2.0566111251872075

Epoch: 5| Step: 6
Training loss: 1.6562618017196655
Validation loss: 2.046570484356214

Epoch: 5| Step: 7
Training loss: 1.8870513439178467
Validation loss: 2.0424185004285587

Epoch: 5| Step: 8
Training loss: 1.5116856098175049
Validation loss: 2.0763044946937153

Epoch: 5| Step: 9
Training loss: 2.2003445625305176
Validation loss: 2.026090964194267

Epoch: 5| Step: 10
Training loss: 1.0061883926391602
Validation loss: 2.0495576217610347

Epoch: 522| Step: 0
Training loss: 1.6863298416137695
Validation loss: 2.1331408741653606

Epoch: 5| Step: 1
Training loss: 1.669450044631958
Validation loss: 2.0787344953065277

Epoch: 5| Step: 2
Training loss: 1.404278039932251
Validation loss: 2.104546029080627

Epoch: 5| Step: 3
Training loss: 1.467577338218689
Validation loss: 2.0680875444924958

Epoch: 5| Step: 4
Training loss: 1.4967246055603027
Validation loss: 2.1106828771611696

Epoch: 5| Step: 5
Training loss: 1.3718708753585815
Validation loss: 2.045220331479144

Epoch: 5| Step: 6
Training loss: 1.6678545475006104
Validation loss: 2.0059719418966644

Epoch: 5| Step: 7
Training loss: 1.198270320892334
Validation loss: 2.091795805961855

Epoch: 5| Step: 8
Training loss: 1.4350817203521729
Validation loss: 2.0747425812546925

Epoch: 5| Step: 9
Training loss: 1.7505123615264893
Validation loss: 2.0481549373237034

Epoch: 5| Step: 10
Training loss: 2.3352818489074707
Validation loss: 2.03689585193511

Epoch: 523| Step: 0
Training loss: 1.7072899341583252
Validation loss: 2.1204846187304427

Epoch: 5| Step: 1
Training loss: 1.6609522104263306
Validation loss: 2.087517367896213

Epoch: 5| Step: 2
Training loss: 1.2078028917312622
Validation loss: 2.012729655029953

Epoch: 5| Step: 3
Training loss: 1.595934510231018
Validation loss: 2.04156461838753

Epoch: 5| Step: 4
Training loss: 1.7059237957000732
Validation loss: 2.156457152417911

Epoch: 5| Step: 5
Training loss: 1.6961616277694702
Validation loss: 2.026435711050546

Epoch: 5| Step: 6
Training loss: 1.0840623378753662
Validation loss: 1.932543590504636

Epoch: 5| Step: 7
Training loss: 1.9218772649765015
Validation loss: 2.0650380067927863

Epoch: 5| Step: 8
Training loss: 1.96877920627594
Validation loss: 2.105219505166495

Epoch: 5| Step: 9
Training loss: 1.5583891868591309
Validation loss: 2.0825932602728567

Epoch: 5| Step: 10
Training loss: 1.4088112115859985
Validation loss: 2.085758698883877

Epoch: 524| Step: 0
Training loss: 1.5130033493041992
Validation loss: 2.0472584616753364

Epoch: 5| Step: 1
Training loss: 1.476571798324585
Validation loss: 2.130946054253527

Epoch: 5| Step: 2
Training loss: 1.2354323863983154
Validation loss: 2.025471712953301

Epoch: 5| Step: 3
Training loss: 2.128704071044922
Validation loss: 2.01298491672803

Epoch: 5| Step: 4
Training loss: 1.1059858798980713
Validation loss: 2.1365338602373676

Epoch: 5| Step: 5
Training loss: 1.6732628345489502
Validation loss: 2.0623848784354424

Epoch: 5| Step: 6
Training loss: 1.4188464879989624
Validation loss: 2.1292851765950522

Epoch: 5| Step: 7
Training loss: 1.9777864217758179
Validation loss: 2.184691475283715

Epoch: 5| Step: 8
Training loss: 1.071153998374939
Validation loss: 2.1713823708154822

Epoch: 5| Step: 9
Training loss: 1.0920252799987793
Validation loss: 2.006393501835485

Epoch: 5| Step: 10
Training loss: 2.6577060222625732
Validation loss: 2.1987716869641374

Epoch: 525| Step: 0
Training loss: 1.3082640171051025
Validation loss: 2.056619110927787

Epoch: 5| Step: 1
Training loss: 1.423300862312317
Validation loss: 2.187113715756324

Epoch: 5| Step: 2
Training loss: 1.6008762121200562
Validation loss: 1.9759967378390733

Epoch: 5| Step: 3
Training loss: 1.5913606882095337
Validation loss: 2.131976863389374

Epoch: 5| Step: 4
Training loss: 1.73050057888031
Validation loss: 2.1195546606535554

Epoch: 5| Step: 5
Training loss: 1.8944027423858643
Validation loss: 2.094594109442926

Epoch: 5| Step: 6
Training loss: 1.516080617904663
Validation loss: 2.0656433118286954

Epoch: 5| Step: 7
Training loss: 1.5860415697097778
Validation loss: 2.136313403806379

Epoch: 5| Step: 8
Training loss: 2.1747851371765137
Validation loss: 2.108448618201799

Epoch: 5| Step: 9
Training loss: 1.3307616710662842
Validation loss: 2.035875020488616

Epoch: 5| Step: 10
Training loss: 1.557765007019043
Validation loss: 2.0415437554800384

Epoch: 526| Step: 0
Training loss: 1.456319808959961
Validation loss: 1.9570783607421383

Epoch: 5| Step: 1
Training loss: 1.3493090867996216
Validation loss: 2.0875484840844267

Epoch: 5| Step: 2
Training loss: 1.3254477977752686
Validation loss: 2.0966463396626134

Epoch: 5| Step: 3
Training loss: 1.6864486932754517
Validation loss: 2.025373371698523

Epoch: 5| Step: 4
Training loss: 1.665403962135315
Validation loss: 1.9681328137715657

Epoch: 5| Step: 5
Training loss: 1.7828563451766968
Validation loss: 2.099856093365659

Epoch: 5| Step: 6
Training loss: 1.9764047861099243
Validation loss: 1.9117356756682038

Epoch: 5| Step: 7
Training loss: 1.684577226638794
Validation loss: 2.0306568799480313

Epoch: 5| Step: 8
Training loss: 1.5049411058425903
Validation loss: 2.0472160603410456

Epoch: 5| Step: 9
Training loss: 2.1216185092926025
Validation loss: 2.0638376756380965

Epoch: 5| Step: 10
Training loss: 1.1743788719177246
Validation loss: 2.0308277581327703

Epoch: 527| Step: 0
Training loss: 1.1295264959335327
Validation loss: 2.132703479900155

Epoch: 5| Step: 1
Training loss: 1.4051496982574463
Validation loss: 2.093359135812329

Epoch: 5| Step: 2
Training loss: 1.6696422100067139
Validation loss: 2.069065019648562

Epoch: 5| Step: 3
Training loss: 1.9839540719985962
Validation loss: 1.9882765123921056

Epoch: 5| Step: 4
Training loss: 0.9248594045639038
Validation loss: 2.04714624856108

Epoch: 5| Step: 5
Training loss: 2.3046560287475586
Validation loss: 2.1787442161190893

Epoch: 5| Step: 6
Training loss: 1.6104700565338135
Validation loss: 2.148745593204293

Epoch: 5| Step: 7
Training loss: 1.341680884361267
Validation loss: 2.0664875379172702

Epoch: 5| Step: 8
Training loss: 2.0676798820495605
Validation loss: 2.1721387140212522

Epoch: 5| Step: 9
Training loss: 1.9205524921417236
Validation loss: 2.037070220516574

Epoch: 5| Step: 10
Training loss: 1.3164982795715332
Validation loss: 2.055399984441778

Epoch: 528| Step: 0
Training loss: 1.447927474975586
Validation loss: 1.9864811102549236

Epoch: 5| Step: 1
Training loss: 1.436875581741333
Validation loss: 2.027148808843346

Epoch: 5| Step: 2
Training loss: 1.267983078956604
Validation loss: 1.9794169984838015

Epoch: 5| Step: 3
Training loss: 1.322780966758728
Validation loss: 1.9349133891444052

Epoch: 5| Step: 4
Training loss: 1.781855583190918
Validation loss: 2.0427659275711223

Epoch: 5| Step: 5
Training loss: 2.0608134269714355
Validation loss: 1.9608292092559159

Epoch: 5| Step: 6
Training loss: 1.8354030847549438
Validation loss: 2.0907730633212673

Epoch: 5| Step: 7
Training loss: 1.6201969385147095
Validation loss: 1.990856380872829

Epoch: 5| Step: 8
Training loss: 1.1122996807098389
Validation loss: 2.085951153950025

Epoch: 5| Step: 9
Training loss: 1.8204524517059326
Validation loss: 2.0132783715442946

Epoch: 5| Step: 10
Training loss: 1.7357875108718872
Validation loss: 1.9989614845604025

Epoch: 529| Step: 0
Training loss: 1.6516883373260498
Validation loss: 2.0379592141797467

Epoch: 5| Step: 1
Training loss: 1.6387478113174438
Validation loss: 2.0537810274349746

Epoch: 5| Step: 2
Training loss: 1.4034481048583984
Validation loss: 2.0369879558522213

Epoch: 5| Step: 3
Training loss: 1.12955641746521
Validation loss: 1.9985500868930612

Epoch: 5| Step: 4
Training loss: 1.285930871963501
Validation loss: 2.115190871300236

Epoch: 5| Step: 5
Training loss: 1.2187325954437256
Validation loss: 2.120636083746469

Epoch: 5| Step: 6
Training loss: 2.0698413848876953
Validation loss: 2.1166577800627677

Epoch: 5| Step: 7
Training loss: 1.9011424779891968
Validation loss: 2.086081492003574

Epoch: 5| Step: 8
Training loss: 1.3867583274841309
Validation loss: 2.1271556039010324

Epoch: 5| Step: 9
Training loss: 1.667353868484497
Validation loss: 2.102683315994919

Epoch: 5| Step: 10
Training loss: 1.9086995124816895
Validation loss: 2.087721775936824

Epoch: 530| Step: 0
Training loss: 1.3513809442520142
Validation loss: 2.0218422412872314

Epoch: 5| Step: 1
Training loss: 1.740117073059082
Validation loss: 2.109625772763324

Epoch: 5| Step: 2
Training loss: 1.6564035415649414
Validation loss: 2.0196751830398396

Epoch: 5| Step: 3
Training loss: 1.7831170558929443
Validation loss: 2.1347936071375364

Epoch: 5| Step: 4
Training loss: 1.1987053155899048
Validation loss: 2.029362855419036

Epoch: 5| Step: 5
Training loss: 1.3989622592926025
Validation loss: 1.9813156076656875

Epoch: 5| Step: 6
Training loss: 1.5916796922683716
Validation loss: 2.100084194573023

Epoch: 5| Step: 7
Training loss: 0.8166366815567017
Validation loss: 2.130216847183884

Epoch: 5| Step: 8
Training loss: 2.197436809539795
Validation loss: 2.1228425400231474

Epoch: 5| Step: 9
Training loss: 1.8700532913208008
Validation loss: 2.08206356212657

Epoch: 5| Step: 10
Training loss: 1.8810635805130005
Validation loss: 2.1379357614824848

Epoch: 531| Step: 0
Training loss: 1.9943567514419556
Validation loss: 2.1296097501631706

Epoch: 5| Step: 1
Training loss: 1.3260962963104248
Validation loss: 2.136493639279437

Epoch: 5| Step: 2
Training loss: 1.5174239873886108
Validation loss: 2.073430356159005

Epoch: 5| Step: 3
Training loss: 1.5890864133834839
Validation loss: 2.1634967814209642

Epoch: 5| Step: 4
Training loss: 1.4135396480560303
Validation loss: 2.057897920249611

Epoch: 5| Step: 5
Training loss: 1.270920991897583
Validation loss: 2.067322882272864

Epoch: 5| Step: 6
Training loss: 1.992028832435608
Validation loss: 2.0129479387755036

Epoch: 5| Step: 7
Training loss: 1.3771607875823975
Validation loss: 2.0135489663770123

Epoch: 5| Step: 8
Training loss: 1.754370093345642
Validation loss: 2.0586988874661025

Epoch: 5| Step: 9
Training loss: 1.846073865890503
Validation loss: 2.061306389429236

Epoch: 5| Step: 10
Training loss: 1.5052070617675781
Validation loss: 2.005255106956728

Epoch: 532| Step: 0
Training loss: 2.310001850128174
Validation loss: 2.1388580158192623

Epoch: 5| Step: 1
Training loss: 1.6019588708877563
Validation loss: 2.0985517232648787

Epoch: 5| Step: 2
Training loss: 0.7808977365493774
Validation loss: 2.0398597230193434

Epoch: 5| Step: 3
Training loss: 1.7803303003311157
Validation loss: 2.1292572816212973

Epoch: 5| Step: 4
Training loss: 1.2036546468734741
Validation loss: 2.0896999015603015

Epoch: 5| Step: 5
Training loss: 1.909764051437378
Validation loss: 1.9559053272329352

Epoch: 5| Step: 6
Training loss: 2.2399230003356934
Validation loss: 2.10778146918102

Epoch: 5| Step: 7
Training loss: 1.322940468788147
Validation loss: 2.053817625968687

Epoch: 5| Step: 8
Training loss: 1.317401647567749
Validation loss: 2.033482414419933

Epoch: 5| Step: 9
Training loss: 1.3681889772415161
Validation loss: 2.067436028552312

Epoch: 5| Step: 10
Training loss: 1.8283575773239136
Validation loss: 2.0996654828389487

Epoch: 533| Step: 0
Training loss: 1.6579639911651611
Validation loss: 2.1585089481005104

Epoch: 5| Step: 1
Training loss: 1.1051690578460693
Validation loss: 2.0920254799627487

Epoch: 5| Step: 2
Training loss: 1.782030701637268
Validation loss: 2.0711736627804336

Epoch: 5| Step: 3
Training loss: 1.4245553016662598
Validation loss: 2.1418691066003617

Epoch: 5| Step: 4
Training loss: 1.8292509317398071
Validation loss: 2.134949525197347

Epoch: 5| Step: 5
Training loss: 1.4327638149261475
Validation loss: 2.148278667721697

Epoch: 5| Step: 6
Training loss: 1.8843262195587158
Validation loss: 2.185714203824279

Epoch: 5| Step: 7
Training loss: 1.9007031917572021
Validation loss: 2.089594841003418

Epoch: 5| Step: 8
Training loss: 1.1919338703155518
Validation loss: 2.190338683384721

Epoch: 5| Step: 9
Training loss: 1.6970560550689697
Validation loss: 2.1194498974789857

Epoch: 5| Step: 10
Training loss: 1.613944172859192
Validation loss: 2.071420254245881

Epoch: 534| Step: 0
Training loss: 0.9309091567993164
Validation loss: 2.0314931946416057

Epoch: 5| Step: 1
Training loss: 1.444181203842163
Validation loss: 2.1394855001921296

Epoch: 5| Step: 2
Training loss: 1.1921336650848389
Validation loss: 2.1263229077862156

Epoch: 5| Step: 3
Training loss: 1.6680803298950195
Validation loss: 1.9969005930808283

Epoch: 5| Step: 4
Training loss: 1.8947422504425049
Validation loss: 2.077753870717941

Epoch: 5| Step: 5
Training loss: 2.182795524597168
Validation loss: 1.9848068401377688

Epoch: 5| Step: 6
Training loss: 1.4050509929656982
Validation loss: 2.07417377092505

Epoch: 5| Step: 7
Training loss: 2.012315273284912
Validation loss: 2.0630730916095037

Epoch: 5| Step: 8
Training loss: 1.7378768920898438
Validation loss: 2.124085336603144

Epoch: 5| Step: 9
Training loss: 1.3518186807632446
Validation loss: 2.0898915875342583

Epoch: 5| Step: 10
Training loss: 1.6634182929992676
Validation loss: 2.127290610344179

Epoch: 535| Step: 0
Training loss: 1.2145662307739258
Validation loss: 2.059673996381862

Epoch: 5| Step: 1
Training loss: 1.5057487487792969
Validation loss: 2.0759359610977994

Epoch: 5| Step: 2
Training loss: 1.339551568031311
Validation loss: 2.05438567233342

Epoch: 5| Step: 3
Training loss: 1.4644324779510498
Validation loss: 2.072414508429907

Epoch: 5| Step: 4
Training loss: 1.8130733966827393
Validation loss: 2.1165956015227945

Epoch: 5| Step: 5
Training loss: 2.0685348510742188
Validation loss: 1.9854807058970134

Epoch: 5| Step: 6
Training loss: 1.4217560291290283
Validation loss: 1.9986112169040147

Epoch: 5| Step: 7
Training loss: 1.6244884729385376
Validation loss: 2.0048268507885676

Epoch: 5| Step: 8
Training loss: 1.872086763381958
Validation loss: 2.0566729153356245

Epoch: 5| Step: 9
Training loss: 1.7531465291976929
Validation loss: 2.0611663902959516

Epoch: 5| Step: 10
Training loss: 1.2268892526626587
Validation loss: 2.0463437213692615

Epoch: 536| Step: 0
Training loss: 1.1556980609893799
Validation loss: 2.120547389471403

Epoch: 5| Step: 1
Training loss: 2.1672449111938477
Validation loss: 2.053305046532744

Epoch: 5| Step: 2
Training loss: 1.7496010065078735
Validation loss: 2.121355110599149

Epoch: 5| Step: 3
Training loss: 1.3809348344802856
Validation loss: 2.139513764330136

Epoch: 5| Step: 4
Training loss: 1.5230743885040283
Validation loss: 2.1583974951057026

Epoch: 5| Step: 5
Training loss: 1.9564958810806274
Validation loss: 2.0645379917595976

Epoch: 5| Step: 6
Training loss: 1.2954124212265015
Validation loss: 2.065379981071718

Epoch: 5| Step: 7
Training loss: 1.6453897953033447
Validation loss: 2.1048524533548663

Epoch: 5| Step: 8
Training loss: 1.6976251602172852
Validation loss: 2.0698065142477713

Epoch: 5| Step: 9
Training loss: 1.2241382598876953
Validation loss: 2.049136192567887

Epoch: 5| Step: 10
Training loss: 1.8793004751205444
Validation loss: 2.0608017739429267

Epoch: 537| Step: 0
Training loss: 1.522383689880371
Validation loss: 2.0481916140484553

Epoch: 5| Step: 1
Training loss: 1.1238118410110474
Validation loss: 1.9684076629659182

Epoch: 5| Step: 2
Training loss: 1.4748437404632568
Validation loss: 2.0955864024418656

Epoch: 5| Step: 3
Training loss: 1.2991632223129272
Validation loss: 2.0580821742293653

Epoch: 5| Step: 4
Training loss: 1.496941328048706
Validation loss: 2.146408991147113

Epoch: 5| Step: 5
Training loss: 1.8587541580200195
Validation loss: 2.1252560461721113

Epoch: 5| Step: 6
Training loss: 1.5559475421905518
Validation loss: 2.077724326041437

Epoch: 5| Step: 7
Training loss: 2.1276021003723145
Validation loss: 2.114882124367581

Epoch: 5| Step: 8
Training loss: 1.4066050052642822
Validation loss: 2.110921234212896

Epoch: 5| Step: 9
Training loss: 1.824806571006775
Validation loss: 2.1390028538242465

Epoch: 5| Step: 10
Training loss: 2.5038444995880127
Validation loss: 2.1259575479774067

Epoch: 538| Step: 0
Training loss: 2.0175328254699707
Validation loss: 2.0364969712431713

Epoch: 5| Step: 1
Training loss: 1.9348522424697876
Validation loss: 1.9875920459788332

Epoch: 5| Step: 2
Training loss: 1.6191984415054321
Validation loss: 2.043426085543889

Epoch: 5| Step: 3
Training loss: 1.1439508199691772
Validation loss: 1.9353293744466638

Epoch: 5| Step: 4
Training loss: 1.3632018566131592
Validation loss: 1.9895254181277366

Epoch: 5| Step: 5
Training loss: 2.338414430618286
Validation loss: 2.087228200768912

Epoch: 5| Step: 6
Training loss: 1.5263631343841553
Validation loss: 2.029017327934183

Epoch: 5| Step: 7
Training loss: 1.1325855255126953
Validation loss: 1.9788686126791022

Epoch: 5| Step: 8
Training loss: 2.3405025005340576
Validation loss: 2.0862181750676965

Epoch: 5| Step: 9
Training loss: 1.298072338104248
Validation loss: 2.104757442269274

Epoch: 5| Step: 10
Training loss: 0.9257308840751648
Validation loss: 2.0614866005477084

Epoch: 539| Step: 0
Training loss: 1.8565740585327148
Validation loss: 2.058089763887467

Epoch: 5| Step: 1
Training loss: 1.5637019872665405
Validation loss: 2.015578349431356

Epoch: 5| Step: 2
Training loss: 1.3267837762832642
Validation loss: 2.0467825141004337

Epoch: 5| Step: 3
Training loss: 2.09861421585083
Validation loss: 2.046546352806912

Epoch: 5| Step: 4
Training loss: 1.4315367937088013
Validation loss: 2.1282726410896546

Epoch: 5| Step: 5
Training loss: 1.276476502418518
Validation loss: 2.058186642585262

Epoch: 5| Step: 6
Training loss: 1.3059335947036743
Validation loss: 2.1099809677370134

Epoch: 5| Step: 7
Training loss: 1.4278703927993774
Validation loss: 2.062824736359299

Epoch: 5| Step: 8
Training loss: 1.3516076803207397
Validation loss: 2.012780060050308

Epoch: 5| Step: 9
Training loss: 2.044863224029541
Validation loss: 2.0527804820768294

Epoch: 5| Step: 10
Training loss: 1.2566057443618774
Validation loss: 2.104366115344468

Epoch: 540| Step: 0
Training loss: 1.3680360317230225
Validation loss: 1.97677105985662

Epoch: 5| Step: 1
Training loss: 1.478794813156128
Validation loss: 2.1294698997210433

Epoch: 5| Step: 2
Training loss: 1.8662374019622803
Validation loss: 2.0663476156932052

Epoch: 5| Step: 3
Training loss: 1.7904212474822998
Validation loss: 2.0642127580540155

Epoch: 5| Step: 4
Training loss: 2.117250919342041
Validation loss: 2.08986755083966

Epoch: 5| Step: 5
Training loss: 1.7832720279693604
Validation loss: 2.020607756030175

Epoch: 5| Step: 6
Training loss: 1.81559157371521
Validation loss: 2.0215502400552072

Epoch: 5| Step: 7
Training loss: 1.5171407461166382
Validation loss: 1.9597792240881151

Epoch: 5| Step: 8
Training loss: 1.4040319919586182
Validation loss: 2.052544075955627

Epoch: 5| Step: 9
Training loss: 1.4053921699523926
Validation loss: 2.151959690996396

Epoch: 5| Step: 10
Training loss: 1.0877447128295898
Validation loss: 1.9414510368019022

Epoch: 541| Step: 0
Training loss: 1.3875207901000977
Validation loss: 1.9843925942656815

Epoch: 5| Step: 1
Training loss: 1.201011061668396
Validation loss: 2.105736441509698

Epoch: 5| Step: 2
Training loss: 1.4731029272079468
Validation loss: 2.169293870208084

Epoch: 5| Step: 3
Training loss: 1.807976484298706
Validation loss: 2.079499604881451

Epoch: 5| Step: 4
Training loss: 1.6869094371795654
Validation loss: 2.1617615453658567

Epoch: 5| Step: 5
Training loss: 1.3177096843719482
Validation loss: 2.1470455533714703

Epoch: 5| Step: 6
Training loss: 1.4638230800628662
Validation loss: 2.074382271817935

Epoch: 5| Step: 7
Training loss: 1.9204273223876953
Validation loss: 2.1058145338489163

Epoch: 5| Step: 8
Training loss: 1.5851869583129883
Validation loss: 2.0410777317580355

Epoch: 5| Step: 9
Training loss: 1.8526932001113892
Validation loss: 2.0671970792995986

Epoch: 5| Step: 10
Training loss: 1.5009455680847168
Validation loss: 2.1223866093543267

Epoch: 542| Step: 0
Training loss: 1.2475192546844482
Validation loss: 2.10406526442497

Epoch: 5| Step: 1
Training loss: 0.9491998553276062
Validation loss: 2.1021142339193695

Epoch: 5| Step: 2
Training loss: 1.7036190032958984
Validation loss: 2.1220280816478114

Epoch: 5| Step: 3
Training loss: 1.7949192523956299
Validation loss: 2.091552786929633

Epoch: 5| Step: 4
Training loss: 2.0663862228393555
Validation loss: 2.0575117757243495

Epoch: 5| Step: 5
Training loss: 1.5978569984436035
Validation loss: 2.101502582591067

Epoch: 5| Step: 6
Training loss: 1.5504090785980225
Validation loss: 1.951570298082085

Epoch: 5| Step: 7
Training loss: 1.6698936223983765
Validation loss: 1.9371847888474822

Epoch: 5| Step: 8
Training loss: 1.0232746601104736
Validation loss: 2.1008382048658145

Epoch: 5| Step: 9
Training loss: 1.8526437282562256
Validation loss: 2.0036434973439863

Epoch: 5| Step: 10
Training loss: 1.6431007385253906
Validation loss: 2.1171049289805914

Epoch: 543| Step: 0
Training loss: 1.643703818321228
Validation loss: 2.1184055933388333

Epoch: 5| Step: 1
Training loss: 1.8944015502929688
Validation loss: 2.03520990187122

Epoch: 5| Step: 2
Training loss: 1.607409119606018
Validation loss: 2.1658214779310327

Epoch: 5| Step: 3
Training loss: 1.1519218683242798
Validation loss: 2.06516634520664

Epoch: 5| Step: 4
Training loss: 1.5286645889282227
Validation loss: 2.1780488593603975

Epoch: 5| Step: 5
Training loss: 1.6048202514648438
Validation loss: 1.9456414048389723

Epoch: 5| Step: 6
Training loss: 1.7786319255828857
Validation loss: 2.0274406594614827

Epoch: 5| Step: 7
Training loss: 1.2349534034729004
Validation loss: 2.0437182752034997

Epoch: 5| Step: 8
Training loss: 2.0531649589538574
Validation loss: 2.0315605799357095

Epoch: 5| Step: 9
Training loss: 1.2840180397033691
Validation loss: 1.9927104826896422

Epoch: 5| Step: 10
Training loss: 1.6336199045181274
Validation loss: 2.1388934889147357

Epoch: 544| Step: 0
Training loss: 1.4148019552230835
Validation loss: 2.0295645293369087

Epoch: 5| Step: 1
Training loss: 1.2765071392059326
Validation loss: 2.1408143069154475

Epoch: 5| Step: 2
Training loss: 1.7702852487564087
Validation loss: 2.114228261414395

Epoch: 5| Step: 3
Training loss: 1.2381880283355713
Validation loss: 2.1107004342540616

Epoch: 5| Step: 4
Training loss: 1.6573562622070312
Validation loss: 2.131985825877036

Epoch: 5| Step: 5
Training loss: 1.0484051704406738
Validation loss: 2.0625993026200162

Epoch: 5| Step: 6
Training loss: 1.912428617477417
Validation loss: 2.1604069599541287

Epoch: 5| Step: 7
Training loss: 1.9104171991348267
Validation loss: 2.1488581447191137

Epoch: 5| Step: 8
Training loss: 1.9365577697753906
Validation loss: 2.1307044516327562

Epoch: 5| Step: 9
Training loss: 1.9825042486190796
Validation loss: 2.162718488324073

Epoch: 5| Step: 10
Training loss: 1.7178947925567627
Validation loss: 2.0193001698422175

Epoch: 545| Step: 0
Training loss: 1.602865219116211
Validation loss: 2.1128143110582904

Epoch: 5| Step: 1
Training loss: 1.3193143606185913
Validation loss: 1.9608969521778885

Epoch: 5| Step: 2
Training loss: 1.0986287593841553
Validation loss: 2.0373482819526427

Epoch: 5| Step: 3
Training loss: 1.388836145401001
Validation loss: 2.0988481288315146

Epoch: 5| Step: 4
Training loss: 0.8355770111083984
Validation loss: 2.0082052958908903

Epoch: 5| Step: 5
Training loss: 2.1306450366973877
Validation loss: 2.0623519574442217

Epoch: 5| Step: 6
Training loss: 1.356771469116211
Validation loss: 2.0651099066580496

Epoch: 5| Step: 7
Training loss: 2.215294361114502
Validation loss: 2.021736575711158

Epoch: 5| Step: 8
Training loss: 1.5966641902923584
Validation loss: 2.0947851019520916

Epoch: 5| Step: 9
Training loss: 1.41153085231781
Validation loss: 2.09757056800268

Epoch: 5| Step: 10
Training loss: 1.988102674484253
Validation loss: 2.04584942325469

Epoch: 546| Step: 0
Training loss: 1.698678970336914
Validation loss: 2.1153162653728197

Epoch: 5| Step: 1
Training loss: 1.306519865989685
Validation loss: 2.0697043403502433

Epoch: 5| Step: 2
Training loss: 1.3557497262954712
Validation loss: 2.0581105063038487

Epoch: 5| Step: 3
Training loss: 1.7622171640396118
Validation loss: 2.089645657488095

Epoch: 5| Step: 4
Training loss: 1.3512042760849
Validation loss: 2.0992597943993023

Epoch: 5| Step: 5
Training loss: 1.3735196590423584
Validation loss: 2.0137878515387095

Epoch: 5| Step: 6
Training loss: 2.095445156097412
Validation loss: 2.1186758754073933

Epoch: 5| Step: 7
Training loss: 1.1597334146499634
Validation loss: 2.092131503166691

Epoch: 5| Step: 8
Training loss: 1.9604628086090088
Validation loss: 2.082822345918225

Epoch: 5| Step: 9
Training loss: 1.8357512950897217
Validation loss: 2.158493020201242

Epoch: 5| Step: 10
Training loss: 1.4652551412582397
Validation loss: 2.0471429837647306

Epoch: 547| Step: 0
Training loss: 1.9302985668182373
Validation loss: 2.0239868830609065

Epoch: 5| Step: 1
Training loss: 1.4529420137405396
Validation loss: 1.957649383493649

Epoch: 5| Step: 2
Training loss: 2.0077028274536133
Validation loss: 2.1062780170030493

Epoch: 5| Step: 3
Training loss: 1.6440858840942383
Validation loss: 2.0293451163076583

Epoch: 5| Step: 4
Training loss: 1.5420029163360596
Validation loss: 2.065285021258939

Epoch: 5| Step: 5
Training loss: 1.762340784072876
Validation loss: 2.1683773302262828

Epoch: 5| Step: 6
Training loss: 1.7048076391220093
Validation loss: 2.025268534178375

Epoch: 5| Step: 7
Training loss: 1.6269115209579468
Validation loss: 2.1575148438894622

Epoch: 5| Step: 8
Training loss: 1.5921812057495117
Validation loss: 2.2427319724072694

Epoch: 5| Step: 9
Training loss: 1.6142336130142212
Validation loss: 2.114121006381127

Epoch: 5| Step: 10
Training loss: 1.4985295534133911
Validation loss: 2.086854165600192

Epoch: 548| Step: 0
Training loss: 1.7967544794082642
Validation loss: 2.0712762237876974

Epoch: 5| Step: 1
Training loss: 1.449603796005249
Validation loss: 2.0952400289556032

Epoch: 5| Step: 2
Training loss: 1.943251371383667
Validation loss: 2.0230252383857645

Epoch: 5| Step: 3
Training loss: 0.984332263469696
Validation loss: 1.9883758816667783

Epoch: 5| Step: 4
Training loss: 2.1555519104003906
Validation loss: 2.047592291267969

Epoch: 5| Step: 5
Training loss: 1.9363219738006592
Validation loss: 2.0934500784002323

Epoch: 5| Step: 6
Training loss: 1.5572446584701538
Validation loss: 2.04115185558155

Epoch: 5| Step: 7
Training loss: 1.1535007953643799
Validation loss: 2.089500520818977

Epoch: 5| Step: 8
Training loss: 1.9270740747451782
Validation loss: 2.0469709032325336

Epoch: 5| Step: 9
Training loss: 1.295555830001831
Validation loss: 2.1713831424713135

Epoch: 5| Step: 10
Training loss: 1.4752700328826904
Validation loss: 2.0456215745659283

Epoch: 549| Step: 0
Training loss: 1.8279876708984375
Validation loss: 2.0451851019295315

Epoch: 5| Step: 1
Training loss: 2.087191581726074
Validation loss: 2.117071590115947

Epoch: 5| Step: 2
Training loss: 1.300081491470337
Validation loss: 2.0206135216579644

Epoch: 5| Step: 3
Training loss: 1.5741667747497559
Validation loss: 1.9803020800313642

Epoch: 5| Step: 4
Training loss: 1.253274917602539
Validation loss: 2.0943993342820035

Epoch: 5| Step: 5
Training loss: 0.9856061935424805
Validation loss: 1.977538731790358

Epoch: 5| Step: 6
Training loss: 1.3855669498443604
Validation loss: 2.0515655112522904

Epoch: 5| Step: 7
Training loss: 1.3439934253692627
Validation loss: 2.0490126494438416

Epoch: 5| Step: 8
Training loss: 2.145118236541748
Validation loss: 2.0566322329223796

Epoch: 5| Step: 9
Training loss: 1.4175257682800293
Validation loss: 2.082824648067515

Epoch: 5| Step: 10
Training loss: 1.425181269645691
Validation loss: 2.188657991347774

Epoch: 550| Step: 0
Training loss: 1.9200016260147095
Validation loss: 2.042402660974892

Epoch: 5| Step: 1
Training loss: 1.5654436349868774
Validation loss: 2.042132228933355

Epoch: 5| Step: 2
Training loss: 1.4779391288757324
Validation loss: 2.0572498113878313

Epoch: 5| Step: 3
Training loss: 1.7006546258926392
Validation loss: 2.0282175387105634

Epoch: 5| Step: 4
Training loss: 1.7312781810760498
Validation loss: 2.117421055352816

Epoch: 5| Step: 5
Training loss: 1.3961131572723389
Validation loss: 2.043109929689797

Epoch: 5| Step: 6
Training loss: 1.4825966358184814
Validation loss: 2.0565845376701763

Epoch: 5| Step: 7
Training loss: 1.5031825304031372
Validation loss: 2.0051590370875534

Epoch: 5| Step: 8
Training loss: 1.9771372079849243
Validation loss: 2.0907450747746292

Epoch: 5| Step: 9
Training loss: 0.9956775903701782
Validation loss: 1.9971294774804065

Epoch: 5| Step: 10
Training loss: 1.425964117050171
Validation loss: 2.1022534062785487

Epoch: 551| Step: 0
Training loss: 1.693487524986267
Validation loss: 2.161796518551406

Epoch: 5| Step: 1
Training loss: 1.2631840705871582
Validation loss: 2.0808993180592856

Epoch: 5| Step: 2
Training loss: 1.3572971820831299
Validation loss: 2.052587625800922

Epoch: 5| Step: 3
Training loss: 1.5811426639556885
Validation loss: 2.063265759457824

Epoch: 5| Step: 4
Training loss: 1.7318789958953857
Validation loss: 2.1683669679908344

Epoch: 5| Step: 5
Training loss: 1.1284602880477905
Validation loss: 2.0793098019015406

Epoch: 5| Step: 6
Training loss: 1.167943000793457
Validation loss: 2.224035736053221

Epoch: 5| Step: 7
Training loss: 1.829311728477478
Validation loss: 2.1305599187010076

Epoch: 5| Step: 8
Training loss: 2.2568793296813965
Validation loss: 2.115068947115252

Epoch: 5| Step: 9
Training loss: 1.6130218505859375
Validation loss: 2.0841622980692054

Epoch: 5| Step: 10
Training loss: 1.406341791152954
Validation loss: 2.0776046822147984

Epoch: 552| Step: 0
Training loss: 0.9936926960945129
Validation loss: 2.074650481183042

Epoch: 5| Step: 1
Training loss: 1.5631115436553955
Validation loss: 2.1136108982947563

Epoch: 5| Step: 2
Training loss: 0.8060808181762695
Validation loss: 2.0742594567678307

Epoch: 5| Step: 3
Training loss: 1.6719154119491577
Validation loss: 2.045609777973544

Epoch: 5| Step: 4
Training loss: 2.1094682216644287
Validation loss: 2.074032086198048

Epoch: 5| Step: 5
Training loss: 2.039966583251953
Validation loss: 2.023672911428636

Epoch: 5| Step: 6
Training loss: 1.3200500011444092
Validation loss: 1.9671481963126891

Epoch: 5| Step: 7
Training loss: 1.8329172134399414
Validation loss: 2.1551565534325055

Epoch: 5| Step: 8
Training loss: 1.8725051879882812
Validation loss: 2.0616714198102235

Epoch: 5| Step: 9
Training loss: 1.4330265522003174
Validation loss: 2.0520305684817735

Epoch: 5| Step: 10
Training loss: 1.9881255626678467
Validation loss: 2.0272835557178785

Epoch: 553| Step: 0
Training loss: 1.777410864830017
Validation loss: 1.9746238236786218

Epoch: 5| Step: 1
Training loss: 1.8139724731445312
Validation loss: 2.015981753667196

Epoch: 5| Step: 2
Training loss: 1.5533157587051392
Validation loss: 2.111205641941358

Epoch: 5| Step: 3
Training loss: 1.958930253982544
Validation loss: 2.0730296796368015

Epoch: 5| Step: 4
Training loss: 1.5489816665649414
Validation loss: 2.0321989995177074

Epoch: 5| Step: 5
Training loss: 1.4032466411590576
Validation loss: 2.0637785542395806

Epoch: 5| Step: 6
Training loss: 1.8950153589248657
Validation loss: 2.070518873071158

Epoch: 5| Step: 7
Training loss: 1.4739350080490112
Validation loss: 1.943067459649937

Epoch: 5| Step: 8
Training loss: 1.648565649986267
Validation loss: 2.085695057786921

Epoch: 5| Step: 9
Training loss: 1.3776403665542603
Validation loss: 2.0515649908332416

Epoch: 5| Step: 10
Training loss: 1.0606623888015747
Validation loss: 2.05900401197454

Epoch: 554| Step: 0
Training loss: 1.3011934757232666
Validation loss: 2.0494703592792636

Epoch: 5| Step: 1
Training loss: 1.5958740711212158
Validation loss: 2.096381684785248

Epoch: 5| Step: 2
Training loss: 1.3622992038726807
Validation loss: 2.09155358037641

Epoch: 5| Step: 3
Training loss: 1.5952203273773193
Validation loss: 1.9785176297669769

Epoch: 5| Step: 4
Training loss: 1.3208709955215454
Validation loss: 1.9787585940412296

Epoch: 5| Step: 5
Training loss: 1.6648842096328735
Validation loss: 1.9597270360556982

Epoch: 5| Step: 6
Training loss: 1.8659305572509766
Validation loss: 2.0785528575220416

Epoch: 5| Step: 7
Training loss: 1.2732954025268555
Validation loss: 1.9707447175056703

Epoch: 5| Step: 8
Training loss: 1.6461155414581299
Validation loss: 2.0195013835865963

Epoch: 5| Step: 9
Training loss: 1.7759100198745728
Validation loss: 2.0778409845085553

Epoch: 5| Step: 10
Training loss: 1.624328851699829
Validation loss: 2.0388405053846297

Epoch: 555| Step: 0
Training loss: 1.7537214756011963
Validation loss: 2.029453731352283

Epoch: 5| Step: 1
Training loss: 1.9617713689804077
Validation loss: 2.089341909654679

Epoch: 5| Step: 2
Training loss: 0.7547626495361328
Validation loss: 2.0466050973502536

Epoch: 5| Step: 3
Training loss: 1.8538318872451782
Validation loss: 2.036066929499308

Epoch: 5| Step: 4
Training loss: 1.4967930316925049
Validation loss: 2.07011406652389

Epoch: 5| Step: 5
Training loss: 1.4122302532196045
Validation loss: 1.9991066686568721

Epoch: 5| Step: 6
Training loss: 1.594484806060791
Validation loss: 1.944066983397289

Epoch: 5| Step: 7
Training loss: 1.4612493515014648
Validation loss: 2.053621124195796

Epoch: 5| Step: 8
Training loss: 1.4616963863372803
Validation loss: 2.095329967878198

Epoch: 5| Step: 9
Training loss: 1.814521074295044
Validation loss: 2.0286391217221498

Epoch: 5| Step: 10
Training loss: 1.48367178440094
Validation loss: 2.044443904712636

Epoch: 556| Step: 0
Training loss: 1.4050663709640503
Validation loss: 2.150723074072151

Epoch: 5| Step: 1
Training loss: 1.7309068441390991
Validation loss: 2.0053114455233336

Epoch: 5| Step: 2
Training loss: 1.1261640787124634
Validation loss: 2.099645878679009

Epoch: 5| Step: 3
Training loss: 1.8016605377197266
Validation loss: 2.111878195116597

Epoch: 5| Step: 4
Training loss: 1.6612937450408936
Validation loss: 2.0980920983899023

Epoch: 5| Step: 5
Training loss: 1.9120855331420898
Validation loss: 2.0386569781969954

Epoch: 5| Step: 6
Training loss: 1.5725418329238892
Validation loss: 2.087831369010351

Epoch: 5| Step: 7
Training loss: 1.83005690574646
Validation loss: 2.0102766277969524

Epoch: 5| Step: 8
Training loss: 1.5944122076034546
Validation loss: 2.124422559174158

Epoch: 5| Step: 9
Training loss: 1.357722520828247
Validation loss: 2.13453911453165

Epoch: 5| Step: 10
Training loss: 1.530766487121582
Validation loss: 2.1756401395285003

Epoch: 557| Step: 0
Training loss: 1.6305828094482422
Validation loss: 2.013784016332319

Epoch: 5| Step: 1
Training loss: 1.771161675453186
Validation loss: 2.033944037652785

Epoch: 5| Step: 2
Training loss: 1.3259608745574951
Validation loss: 1.9964026622874762

Epoch: 5| Step: 3
Training loss: 1.603992223739624
Validation loss: 2.16186329882632

Epoch: 5| Step: 4
Training loss: 1.122092366218567
Validation loss: 2.1019439415265153

Epoch: 5| Step: 5
Training loss: 1.0364280939102173
Validation loss: 2.087817774024061

Epoch: 5| Step: 6
Training loss: 2.2788002490997314
Validation loss: 2.0428390605475313

Epoch: 5| Step: 7
Training loss: 1.8695389032363892
Validation loss: 2.1391772275329917

Epoch: 5| Step: 8
Training loss: 1.3467165231704712
Validation loss: 2.031102239444692

Epoch: 5| Step: 9
Training loss: 1.6081651449203491
Validation loss: 2.1547144741140385

Epoch: 5| Step: 10
Training loss: 1.6118288040161133
Validation loss: 2.112828531572896

Epoch: 558| Step: 0
Training loss: 1.8243404626846313
Validation loss: 2.1450261454428396

Epoch: 5| Step: 1
Training loss: 1.5316321849822998
Validation loss: 2.212299777615455

Epoch: 5| Step: 2
Training loss: 1.438493251800537
Validation loss: 2.068206680718289

Epoch: 5| Step: 3
Training loss: 1.5731675624847412
Validation loss: 2.06449858860303

Epoch: 5| Step: 4
Training loss: 1.8914213180541992
Validation loss: 2.0780972767901678

Epoch: 5| Step: 5
Training loss: 1.528482437133789
Validation loss: 2.046645848981796

Epoch: 5| Step: 6
Training loss: 2.4092788696289062
Validation loss: 2.114965582406649

Epoch: 5| Step: 7
Training loss: 1.0620102882385254
Validation loss: 2.0129059014781827

Epoch: 5| Step: 8
Training loss: 1.201605200767517
Validation loss: 2.033733417910914

Epoch: 5| Step: 9
Training loss: 1.3272894620895386
Validation loss: 2.0673195482582174

Epoch: 5| Step: 10
Training loss: 1.4076309204101562
Validation loss: 2.1124824016324935

Epoch: 559| Step: 0
Training loss: 1.169148564338684
Validation loss: 2.007105688894949

Epoch: 5| Step: 1
Training loss: 0.88134765625
Validation loss: 2.1385749129838842

Epoch: 5| Step: 2
Training loss: 1.9450500011444092
Validation loss: 1.9656762820418163

Epoch: 5| Step: 3
Training loss: 1.5291337966918945
Validation loss: 2.1384221507656958

Epoch: 5| Step: 4
Training loss: 1.350205421447754
Validation loss: 2.0898749430974326

Epoch: 5| Step: 5
Training loss: 1.350595235824585
Validation loss: 2.1063457381340767

Epoch: 5| Step: 6
Training loss: 2.345343828201294
Validation loss: 2.0741580763170795

Epoch: 5| Step: 7
Training loss: 1.6466376781463623
Validation loss: 2.181733028863066

Epoch: 5| Step: 8
Training loss: 1.5589439868927002
Validation loss: 2.0041272922228743

Epoch: 5| Step: 9
Training loss: 1.277207612991333
Validation loss: 1.972270732284874

Epoch: 5| Step: 10
Training loss: 1.5093601942062378
Validation loss: 2.0673904034399215

Epoch: 560| Step: 0
Training loss: 1.296623706817627
Validation loss: 2.115923135511337

Epoch: 5| Step: 1
Training loss: 1.632677674293518
Validation loss: 2.1142460697440693

Epoch: 5| Step: 2
Training loss: 1.2103980779647827
Validation loss: 2.0692261906080347

Epoch: 5| Step: 3
Training loss: 1.528745412826538
Validation loss: 2.0847247082700013

Epoch: 5| Step: 4
Training loss: 1.6822834014892578
Validation loss: 2.0740934956458306

Epoch: 5| Step: 5
Training loss: 1.9127025604248047
Validation loss: 2.0818984662332842

Epoch: 5| Step: 6
Training loss: 1.9228283166885376
Validation loss: 2.0274626362708306

Epoch: 5| Step: 7
Training loss: 1.512964129447937
Validation loss: 2.0955093958044566

Epoch: 5| Step: 8
Training loss: 1.408754825592041
Validation loss: 2.0961487805971535

Epoch: 5| Step: 9
Training loss: 1.0737907886505127
Validation loss: 2.095393321847403

Epoch: 5| Step: 10
Training loss: 2.240488290786743
Validation loss: 2.170619390344107

Epoch: 561| Step: 0
Training loss: 1.7654869556427002
Validation loss: 2.116661106386492

Epoch: 5| Step: 1
Training loss: 1.7979360818862915
Validation loss: 1.9992213146660918

Epoch: 5| Step: 2
Training loss: 1.5607439279556274
Validation loss: 2.0910283263011644

Epoch: 5| Step: 3
Training loss: 1.334734320640564
Validation loss: 2.100184771322435

Epoch: 5| Step: 4
Training loss: 1.1526482105255127
Validation loss: 2.1111975536551526

Epoch: 5| Step: 5
Training loss: 1.4603538513183594
Validation loss: 2.0138053791497343

Epoch: 5| Step: 6
Training loss: 1.1322333812713623
Validation loss: 2.020697952598654

Epoch: 5| Step: 7
Training loss: 1.711350679397583
Validation loss: 2.0654399484716435

Epoch: 5| Step: 8
Training loss: 2.2381680011749268
Validation loss: 2.091770407974079

Epoch: 5| Step: 9
Training loss: 1.2343477010726929
Validation loss: 2.06626969768155

Epoch: 5| Step: 10
Training loss: 1.4180057048797607
Validation loss: 1.9910840603613085

Epoch: 562| Step: 0
Training loss: 1.554749608039856
Validation loss: 2.110747023295331

Epoch: 5| Step: 1
Training loss: 1.8766565322875977
Validation loss: 2.1144495600013324

Epoch: 5| Step: 2
Training loss: 1.2929235696792603
Validation loss: 2.0257247865840955

Epoch: 5| Step: 3
Training loss: 1.8608955144882202
Validation loss: 2.1811838624297932

Epoch: 5| Step: 4
Training loss: 1.7121984958648682
Validation loss: 2.0161333109742854

Epoch: 5| Step: 5
Training loss: 1.280789852142334
Validation loss: 2.1246343761362056

Epoch: 5| Step: 6
Training loss: 1.4451268911361694
Validation loss: 2.1222387565079557

Epoch: 5| Step: 7
Training loss: 1.6752967834472656
Validation loss: 1.984135978965349

Epoch: 5| Step: 8
Training loss: 0.989459216594696
Validation loss: 1.99274657874979

Epoch: 5| Step: 9
Training loss: 1.5995787382125854
Validation loss: 2.0753619568322295

Epoch: 5| Step: 10
Training loss: 1.432389259338379
Validation loss: 2.0838705032102522

Epoch: 563| Step: 0
Training loss: 1.0802907943725586
Validation loss: 2.1198910974687144

Epoch: 5| Step: 1
Training loss: 0.9721018075942993
Validation loss: 2.0005368122490506

Epoch: 5| Step: 2
Training loss: 1.5378563404083252
Validation loss: 2.0433652298424834

Epoch: 5| Step: 3
Training loss: 1.681133508682251
Validation loss: 1.9162889244735881

Epoch: 5| Step: 4
Training loss: 2.0101027488708496
Validation loss: 2.1155163780335458

Epoch: 5| Step: 5
Training loss: 1.2056763172149658
Validation loss: 2.030140079477782

Epoch: 5| Step: 6
Training loss: 1.954751968383789
Validation loss: 2.041127880414327

Epoch: 5| Step: 7
Training loss: 1.568428635597229
Validation loss: 2.0199476954757527

Epoch: 5| Step: 8
Training loss: 1.2847588062286377
Validation loss: 2.0423487027486167

Epoch: 5| Step: 9
Training loss: 1.7552400827407837
Validation loss: 2.0439686723934707

Epoch: 5| Step: 10
Training loss: 1.79570734500885
Validation loss: 2.089624915071713

Epoch: 564| Step: 0
Training loss: 2.051846981048584
Validation loss: 2.0354530196036063

Epoch: 5| Step: 1
Training loss: 1.3883270025253296
Validation loss: 2.09841888694353

Epoch: 5| Step: 2
Training loss: 1.0667057037353516
Validation loss: 2.0212637865415184

Epoch: 5| Step: 3
Training loss: 1.7108821868896484
Validation loss: 1.9920482981589533

Epoch: 5| Step: 4
Training loss: 1.8875080347061157
Validation loss: 2.024585282930764

Epoch: 5| Step: 5
Training loss: 0.9189260601997375
Validation loss: 2.0498061539024435

Epoch: 5| Step: 6
Training loss: 1.0855791568756104
Validation loss: 2.0620506732694563

Epoch: 5| Step: 7
Training loss: 2.3144967555999756
Validation loss: 2.0525066160386607

Epoch: 5| Step: 8
Training loss: 1.1242212057113647
Validation loss: 2.071834969264205

Epoch: 5| Step: 9
Training loss: 1.8395664691925049
Validation loss: 2.056655163406044

Epoch: 5| Step: 10
Training loss: 1.702007532119751
Validation loss: 2.0400436821804253

Epoch: 565| Step: 0
Training loss: 1.6495459079742432
Validation loss: 2.1146659979256253

Epoch: 5| Step: 1
Training loss: 1.3331397771835327
Validation loss: 2.0131920922187065

Epoch: 5| Step: 2
Training loss: 1.3775180578231812
Validation loss: 2.1654843617511053

Epoch: 5| Step: 3
Training loss: 1.6054770946502686
Validation loss: 2.064749825385309

Epoch: 5| Step: 4
Training loss: 1.559981107711792
Validation loss: 2.073417268773561

Epoch: 5| Step: 5
Training loss: 1.8819568157196045
Validation loss: 1.9848384511086248

Epoch: 5| Step: 6
Training loss: 1.3673397302627563
Validation loss: 2.0898614519385883

Epoch: 5| Step: 7
Training loss: 1.546154260635376
Validation loss: 2.072594029929048

Epoch: 5| Step: 8
Training loss: 1.4120529890060425
Validation loss: 2.0468491072295816

Epoch: 5| Step: 9
Training loss: 1.5385085344314575
Validation loss: 2.099170761723672

Epoch: 5| Step: 10
Training loss: 1.540806770324707
Validation loss: 2.003049753045523

Epoch: 566| Step: 0
Training loss: 1.4069697856903076
Validation loss: 2.0516430972724833

Epoch: 5| Step: 1
Training loss: 1.3594815731048584
Validation loss: 2.1068414026691067

Epoch: 5| Step: 2
Training loss: 1.427485704421997
Validation loss: 2.0203046273159724

Epoch: 5| Step: 3
Training loss: 1.2739444971084595
Validation loss: 2.125078455094368

Epoch: 5| Step: 4
Training loss: 1.1085224151611328
Validation loss: 1.9692672042436496

Epoch: 5| Step: 5
Training loss: 1.3099355697631836
Validation loss: 2.073289148269161

Epoch: 5| Step: 6
Training loss: 1.7380177974700928
Validation loss: 2.091492922075333

Epoch: 5| Step: 7
Training loss: 1.7183996438980103
Validation loss: 2.0951893380893174

Epoch: 5| Step: 8
Training loss: 2.0438265800476074
Validation loss: 2.0794672094365603

Epoch: 5| Step: 9
Training loss: 1.6809158325195312
Validation loss: 2.111893161650627

Epoch: 5| Step: 10
Training loss: 1.3429064750671387
Validation loss: 2.0928904715404717

Epoch: 567| Step: 0
Training loss: 1.9718118906021118
Validation loss: 1.96327805519104

Epoch: 5| Step: 1
Training loss: 1.6959835290908813
Validation loss: 2.0077058743405085

Epoch: 5| Step: 2
Training loss: 1.2720073461532593
Validation loss: 2.095115310402327

Epoch: 5| Step: 3
Training loss: 1.573625922203064
Validation loss: 2.1340026983650784

Epoch: 5| Step: 4
Training loss: 1.0681073665618896
Validation loss: 2.0238604391774824

Epoch: 5| Step: 5
Training loss: 1.5958890914916992
Validation loss: 2.0687365531921387

Epoch: 5| Step: 6
Training loss: 1.594507098197937
Validation loss: 1.9833689505054104

Epoch: 5| Step: 7
Training loss: 1.459429144859314
Validation loss: 2.0187421883306196

Epoch: 5| Step: 8
Training loss: 1.3148298263549805
Validation loss: 2.047456987442509

Epoch: 5| Step: 9
Training loss: 1.2036411762237549
Validation loss: 2.027482783922585

Epoch: 5| Step: 10
Training loss: 1.5825176239013672
Validation loss: 1.9687142333676737

Epoch: 568| Step: 0
Training loss: 1.4043911695480347
Validation loss: 2.0516023097499723

Epoch: 5| Step: 1
Training loss: 1.3046430349349976
Validation loss: 2.053367401963921

Epoch: 5| Step: 2
Training loss: 1.8397150039672852
Validation loss: 2.096753966423773

Epoch: 5| Step: 3
Training loss: 2.057000160217285
Validation loss: 2.007368492823775

Epoch: 5| Step: 4
Training loss: 1.4707828760147095
Validation loss: 2.071103513881724

Epoch: 5| Step: 5
Training loss: 1.7994225025177002
Validation loss: 2.0800374707868023

Epoch: 5| Step: 6
Training loss: 1.2643797397613525
Validation loss: 2.0630647649047194

Epoch: 5| Step: 7
Training loss: 1.7258485555648804
Validation loss: 1.9782522160519835

Epoch: 5| Step: 8
Training loss: 1.2948497533798218
Validation loss: 1.9924918707980905

Epoch: 5| Step: 9
Training loss: 1.5251061916351318
Validation loss: 2.11136197018367

Epoch: 5| Step: 10
Training loss: 1.3066825866699219
Validation loss: 2.022391924294092

Epoch: 569| Step: 0
Training loss: 1.416747808456421
Validation loss: 2.006383717700999

Epoch: 5| Step: 1
Training loss: 0.9994131922721863
Validation loss: 2.0795091352155133

Epoch: 5| Step: 2
Training loss: 1.4767152070999146
Validation loss: 1.9795981991675593

Epoch: 5| Step: 3
Training loss: 1.893768310546875
Validation loss: 2.113644169222924

Epoch: 5| Step: 4
Training loss: 1.8942477703094482
Validation loss: 2.015780084876604

Epoch: 5| Step: 5
Training loss: 1.6099716424942017
Validation loss: 2.071631408506824

Epoch: 5| Step: 6
Training loss: 1.6893142461776733
Validation loss: 2.1423135239590883

Epoch: 5| Step: 7
Training loss: 1.5224695205688477
Validation loss: 2.0608984244767057

Epoch: 5| Step: 8
Training loss: 1.4557387828826904
Validation loss: 2.220684415550642

Epoch: 5| Step: 9
Training loss: 2.146503448486328
Validation loss: 2.128496967336183

Epoch: 5| Step: 10
Training loss: 1.6003828048706055
Validation loss: 2.0482368687147736

Epoch: 570| Step: 0
Training loss: 1.5168242454528809
Validation loss: 2.110982382169334

Epoch: 5| Step: 1
Training loss: 1.5316184759140015
Validation loss: 2.025897559299264

Epoch: 5| Step: 2
Training loss: 1.6960811614990234
Validation loss: 2.0267502671928814

Epoch: 5| Step: 3
Training loss: 1.4761290550231934
Validation loss: 2.141748594981368

Epoch: 5| Step: 4
Training loss: 1.5981786251068115
Validation loss: 2.125105389984705

Epoch: 5| Step: 5
Training loss: 0.9265586137771606
Validation loss: 2.042227045182259

Epoch: 5| Step: 6
Training loss: 1.9930505752563477
Validation loss: 2.0701612746843727

Epoch: 5| Step: 7
Training loss: 1.6074756383895874
Validation loss: 2.110359363658454

Epoch: 5| Step: 8
Training loss: 1.7500190734863281
Validation loss: 2.007683179711783

Epoch: 5| Step: 9
Training loss: 0.9257099032402039
Validation loss: 2.0984955872258833

Epoch: 5| Step: 10
Training loss: 1.383122444152832
Validation loss: 2.0008616293630292

Epoch: 571| Step: 0
Training loss: 1.5278594493865967
Validation loss: 2.0900892801182245

Epoch: 5| Step: 1
Training loss: 1.5210167169570923
Validation loss: 2.1134920068966445

Epoch: 5| Step: 2
Training loss: 1.3826857805252075
Validation loss: 2.050846133180844

Epoch: 5| Step: 3
Training loss: 1.5695374011993408
Validation loss: 2.0821760649322183

Epoch: 5| Step: 4
Training loss: 1.2029398679733276
Validation loss: 2.111292900577668

Epoch: 5| Step: 5
Training loss: 1.538200855255127
Validation loss: 2.0582752279056016

Epoch: 5| Step: 6
Training loss: 1.4606887102127075
Validation loss: 2.062936750791406

Epoch: 5| Step: 7
Training loss: 1.771524429321289
Validation loss: 2.1012570242727957

Epoch: 5| Step: 8
Training loss: 1.3979278802871704
Validation loss: 2.113731353513656

Epoch: 5| Step: 9
Training loss: 2.3647279739379883
Validation loss: 2.21312875645135

Epoch: 5| Step: 10
Training loss: 1.6322002410888672
Validation loss: 2.137941083600444

Epoch: 572| Step: 0
Training loss: 2.1439406871795654
Validation loss: 2.1317584770981983

Epoch: 5| Step: 1
Training loss: 1.8521900177001953
Validation loss: 2.1006155090947307

Epoch: 5| Step: 2
Training loss: 1.3933491706848145
Validation loss: 2.2823284108151674

Epoch: 5| Step: 3
Training loss: 1.7152681350708008
Validation loss: 2.0894273122151694

Epoch: 5| Step: 4
Training loss: 1.3353880643844604
Validation loss: 2.0504603667925765

Epoch: 5| Step: 5
Training loss: 1.5313482284545898
Validation loss: 2.0848716433330248

Epoch: 5| Step: 6
Training loss: 1.740918755531311
Validation loss: 2.0629527491907917

Epoch: 5| Step: 7
Training loss: 1.0919028520584106
Validation loss: 2.029288358585809

Epoch: 5| Step: 8
Training loss: 1.3580458164215088
Validation loss: 2.103834903368386

Epoch: 5| Step: 9
Training loss: 1.8816449642181396
Validation loss: 2.078261003699354

Epoch: 5| Step: 10
Training loss: 1.3476948738098145
Validation loss: 1.968039184488276

Epoch: 573| Step: 0
Training loss: 1.6782722473144531
Validation loss: 1.9349035780916932

Epoch: 5| Step: 1
Training loss: 1.3738900423049927
Validation loss: 2.180384156524494

Epoch: 5| Step: 2
Training loss: 0.9148609042167664
Validation loss: 2.005712984710611

Epoch: 5| Step: 3
Training loss: 1.4156086444854736
Validation loss: 2.033961708827685

Epoch: 5| Step: 4
Training loss: 1.7717853784561157
Validation loss: 2.128777543703715

Epoch: 5| Step: 5
Training loss: 1.4484353065490723
Validation loss: 2.0622249585326

Epoch: 5| Step: 6
Training loss: 1.39402174949646
Validation loss: 2.076788899719074

Epoch: 5| Step: 7
Training loss: 1.3245842456817627
Validation loss: 2.119601777804795

Epoch: 5| Step: 8
Training loss: 1.7260162830352783
Validation loss: 2.0751251225830405

Epoch: 5| Step: 9
Training loss: 1.7928028106689453
Validation loss: 2.0260935470622075

Epoch: 5| Step: 10
Training loss: 2.1330032348632812
Validation loss: 2.079983195950908

Epoch: 574| Step: 0
Training loss: 1.5446147918701172
Validation loss: 2.0405900016907723

Epoch: 5| Step: 1
Training loss: 1.456775426864624
Validation loss: 2.1311519825330345

Epoch: 5| Step: 2
Training loss: 1.8581178188323975
Validation loss: 2.1236289829336186

Epoch: 5| Step: 3
Training loss: 0.7986358404159546
Validation loss: 1.9990151877044349

Epoch: 5| Step: 4
Training loss: 1.3782751560211182
Validation loss: 2.07472046472693

Epoch: 5| Step: 5
Training loss: 1.4429229497909546
Validation loss: 2.020024686731318

Epoch: 5| Step: 6
Training loss: 1.5235755443572998
Validation loss: 2.0375972127401702

Epoch: 5| Step: 7
Training loss: 1.1654449701309204
Validation loss: 2.039658183692604

Epoch: 5| Step: 8
Training loss: 1.6539932489395142
Validation loss: 2.1423418009152977

Epoch: 5| Step: 9
Training loss: 2.288480520248413
Validation loss: 2.0052256648258497

Epoch: 5| Step: 10
Training loss: 1.5126572847366333
Validation loss: 2.09244663869181

Epoch: 575| Step: 0
Training loss: 1.1314373016357422
Validation loss: 2.0851598657587522

Epoch: 5| Step: 1
Training loss: 1.2657400369644165
Validation loss: 2.0035401967263993

Epoch: 5| Step: 2
Training loss: 1.7773993015289307
Validation loss: 2.1257324398204847

Epoch: 5| Step: 3
Training loss: 1.6777833700180054
Validation loss: 2.1231948996102936

Epoch: 5| Step: 4
Training loss: 1.6911442279815674
Validation loss: 1.9560022879672307

Epoch: 5| Step: 5
Training loss: 1.3084453344345093
Validation loss: 2.0376448503104587

Epoch: 5| Step: 6
Training loss: 1.9566015005111694
Validation loss: 1.9625805372832923

Epoch: 5| Step: 7
Training loss: 2.1045985221862793
Validation loss: 2.1230896698531283

Epoch: 5| Step: 8
Training loss: 1.739511251449585
Validation loss: 2.210059319773028

Epoch: 5| Step: 9
Training loss: 1.4896762371063232
Validation loss: 2.0039908501409713

Epoch: 5| Step: 10
Training loss: 1.210931658744812
Validation loss: 2.014389322650048

Epoch: 576| Step: 0
Training loss: 1.5271990299224854
Validation loss: 2.0095831988960184

Epoch: 5| Step: 1
Training loss: 1.3131039142608643
Validation loss: 2.020891199829758

Epoch: 5| Step: 2
Training loss: 1.5729154348373413
Validation loss: 2.05363065965714

Epoch: 5| Step: 3
Training loss: 1.6970726251602173
Validation loss: 2.064190923526723

Epoch: 5| Step: 4
Training loss: 1.5461950302124023
Validation loss: 2.114889714025682

Epoch: 5| Step: 5
Training loss: 0.9715152978897095
Validation loss: 2.1130042896475842

Epoch: 5| Step: 6
Training loss: 1.2991077899932861
Validation loss: 2.0969219951219458

Epoch: 5| Step: 7
Training loss: 1.7378017902374268
Validation loss: 2.0535419000092374

Epoch: 5| Step: 8
Training loss: 2.2811031341552734
Validation loss: 2.12037496412954

Epoch: 5| Step: 9
Training loss: 1.2799121141433716
Validation loss: 1.9642683485502839

Epoch: 5| Step: 10
Training loss: 2.0620017051696777
Validation loss: 2.097613779447412

Epoch: 577| Step: 0
Training loss: 1.1143100261688232
Validation loss: 2.101661612910609

Epoch: 5| Step: 1
Training loss: 2.4164206981658936
Validation loss: 2.0786558299936275

Epoch: 5| Step: 2
Training loss: 1.569603681564331
Validation loss: 2.107059314686765

Epoch: 5| Step: 3
Training loss: 1.3873974084854126
Validation loss: 2.0037191606337026

Epoch: 5| Step: 4
Training loss: 1.424100637435913
Validation loss: 2.009286677965554

Epoch: 5| Step: 5
Training loss: 1.7577797174453735
Validation loss: 2.0148593687242076

Epoch: 5| Step: 6
Training loss: 1.0216214656829834
Validation loss: 2.0743255051233436

Epoch: 5| Step: 7
Training loss: 1.1997554302215576
Validation loss: 2.017821360659856

Epoch: 5| Step: 8
Training loss: 2.0655455589294434
Validation loss: 2.1615823699582006

Epoch: 5| Step: 9
Training loss: 0.9807529449462891
Validation loss: 1.9668641987667288

Epoch: 5| Step: 10
Training loss: 1.880309820175171
Validation loss: 1.892536719640096

Epoch: 578| Step: 0
Training loss: 1.3549798727035522
Validation loss: 2.1501584796495337

Epoch: 5| Step: 1
Training loss: 1.4391475915908813
Validation loss: 2.0815817540691746

Epoch: 5| Step: 2
Training loss: 1.64833664894104
Validation loss: 2.1077764085544053

Epoch: 5| Step: 3
Training loss: 1.3675893545150757
Validation loss: 1.9976330495649768

Epoch: 5| Step: 4
Training loss: 1.7482242584228516
Validation loss: 2.0508903841818533

Epoch: 5| Step: 5
Training loss: 1.7682254314422607
Validation loss: 2.094660802554059

Epoch: 5| Step: 6
Training loss: 1.752091407775879
Validation loss: 2.2092613661161034

Epoch: 5| Step: 7
Training loss: 1.8058907985687256
Validation loss: 2.071557988402664

Epoch: 5| Step: 8
Training loss: 1.389657735824585
Validation loss: 2.059317368333058

Epoch: 5| Step: 9
Training loss: 1.3283008337020874
Validation loss: 2.1088520711468113

Epoch: 5| Step: 10
Training loss: 1.669657588005066
Validation loss: 2.0710165321186023

Epoch: 579| Step: 0
Training loss: 1.9943838119506836
Validation loss: 2.1305397441310268

Epoch: 5| Step: 1
Training loss: 1.5924360752105713
Validation loss: 2.1716448158346195

Epoch: 5| Step: 2
Training loss: 1.324064016342163
Validation loss: 2.1667300526813795

Epoch: 5| Step: 3
Training loss: 1.2239863872528076
Validation loss: 2.065342841609832

Epoch: 5| Step: 4
Training loss: 1.4173883199691772
Validation loss: 1.9925511306332004

Epoch: 5| Step: 5
Training loss: 1.957666039466858
Validation loss: 2.1214892043862292

Epoch: 5| Step: 6
Training loss: 1.088590383529663
Validation loss: 2.0897254738756406

Epoch: 5| Step: 7
Training loss: 1.8196029663085938
Validation loss: 2.124158932316688

Epoch: 5| Step: 8
Training loss: 1.7628434896469116
Validation loss: 2.090097188949585

Epoch: 5| Step: 9
Training loss: 1.5996848344802856
Validation loss: 2.1093168104848554

Epoch: 5| Step: 10
Training loss: 1.2135603427886963
Validation loss: 2.1153825790651384

Epoch: 580| Step: 0
Training loss: 1.7921810150146484
Validation loss: 2.0703144791305705

Epoch: 5| Step: 1
Training loss: 2.0068509578704834
Validation loss: 2.1214584894077753

Epoch: 5| Step: 2
Training loss: 1.4698435068130493
Validation loss: 2.0513818828008508

Epoch: 5| Step: 3
Training loss: 1.2836871147155762
Validation loss: 2.038384852870818

Epoch: 5| Step: 4
Training loss: 1.6348003149032593
Validation loss: 1.969544372250957

Epoch: 5| Step: 5
Training loss: 1.204458475112915
Validation loss: 2.0334289214944326

Epoch: 5| Step: 6
Training loss: 1.2586438655853271
Validation loss: 2.0223906091464463

Epoch: 5| Step: 7
Training loss: 1.0641621351242065
Validation loss: 2.102184489209165

Epoch: 5| Step: 8
Training loss: 1.3765239715576172
Validation loss: 2.0134560754222255

Epoch: 5| Step: 9
Training loss: 1.5509573221206665
Validation loss: 2.0850489780467045

Epoch: 5| Step: 10
Training loss: 1.115122675895691
Validation loss: 2.063851782070693

Epoch: 581| Step: 0
Training loss: 1.0614041090011597
Validation loss: 2.0964533795592604

Epoch: 5| Step: 1
Training loss: 1.3695852756500244
Validation loss: 2.084157766834382

Epoch: 5| Step: 2
Training loss: 1.5421905517578125
Validation loss: 2.0990803510912004

Epoch: 5| Step: 3
Training loss: 1.9535328149795532
Validation loss: 2.057584503645538

Epoch: 5| Step: 4
Training loss: 1.155203938484192
Validation loss: 2.0302033962741977

Epoch: 5| Step: 5
Training loss: 1.8994232416152954
Validation loss: 2.077105829792638

Epoch: 5| Step: 6
Training loss: 1.2546409368515015
Validation loss: 2.0787982415127497

Epoch: 5| Step: 7
Training loss: 1.9650955200195312
Validation loss: 2.0397691675411758

Epoch: 5| Step: 8
Training loss: 1.3924601078033447
Validation loss: 2.016037050113883

Epoch: 5| Step: 9
Training loss: 1.905160665512085
Validation loss: 2.054219212583316

Epoch: 5| Step: 10
Training loss: 1.201525092124939
Validation loss: 1.9740924437840779

Epoch: 582| Step: 0
Training loss: 2.027615785598755
Validation loss: 2.1377134476938555

Epoch: 5| Step: 1
Training loss: 1.4950244426727295
Validation loss: 2.035444918499198

Epoch: 5| Step: 2
Training loss: 1.7697441577911377
Validation loss: 2.125338764600856

Epoch: 5| Step: 3
Training loss: 2.0766851902008057
Validation loss: 2.0833499021427606

Epoch: 5| Step: 4
Training loss: 1.0322883129119873
Validation loss: 2.1089984165724887

Epoch: 5| Step: 5
Training loss: 0.9304662942886353
Validation loss: 2.030599473625101

Epoch: 5| Step: 6
Training loss: 1.1852777004241943
Validation loss: 2.137525402089601

Epoch: 5| Step: 7
Training loss: 1.4543087482452393
Validation loss: 2.0986596973993445

Epoch: 5| Step: 8
Training loss: 1.5481138229370117
Validation loss: 2.0942112925232097

Epoch: 5| Step: 9
Training loss: 1.243119478225708
Validation loss: 2.0065542985034246

Epoch: 5| Step: 10
Training loss: 1.9298696517944336
Validation loss: 2.1057764355854323

Epoch: 583| Step: 0
Training loss: 1.9057018756866455
Validation loss: 2.218407371992706

Epoch: 5| Step: 1
Training loss: 1.1548192501068115
Validation loss: 2.0116862943095546

Epoch: 5| Step: 2
Training loss: 1.6651535034179688
Validation loss: 2.0625296895222

Epoch: 5| Step: 3
Training loss: 1.4177377223968506
Validation loss: 2.1478031694248156

Epoch: 5| Step: 4
Training loss: 1.5682836771011353
Validation loss: 2.071103629245553

Epoch: 5| Step: 5
Training loss: 1.308273196220398
Validation loss: 1.9852686248799807

Epoch: 5| Step: 6
Training loss: 1.6203781366348267
Validation loss: 2.0215890446016864

Epoch: 5| Step: 7
Training loss: 1.5041831731796265
Validation loss: 2.122381792273573

Epoch: 5| Step: 8
Training loss: 1.510162353515625
Validation loss: 2.1067304175387145

Epoch: 5| Step: 9
Training loss: 1.0180778503417969
Validation loss: 2.0958850358122136

Epoch: 5| Step: 10
Training loss: 1.8712692260742188
Validation loss: 2.064123438250634

Epoch: 584| Step: 0
Training loss: 1.094602346420288
Validation loss: 2.074827935106011

Epoch: 5| Step: 1
Training loss: 1.677011489868164
Validation loss: 2.0306790221122

Epoch: 5| Step: 2
Training loss: 1.6072781085968018
Validation loss: 1.9978891572644633

Epoch: 5| Step: 3
Training loss: 1.5955309867858887
Validation loss: 2.0643609851919194

Epoch: 5| Step: 4
Training loss: 1.5946459770202637
Validation loss: 2.098964878307876

Epoch: 5| Step: 5
Training loss: 1.6872549057006836
Validation loss: 2.1141634743700743

Epoch: 5| Step: 6
Training loss: 1.4551976919174194
Validation loss: 2.127378002289803

Epoch: 5| Step: 7
Training loss: 1.483046293258667
Validation loss: 2.0983823191735054

Epoch: 5| Step: 8
Training loss: 1.7453367710113525
Validation loss: 2.0471526012625745

Epoch: 5| Step: 9
Training loss: 1.6961185932159424
Validation loss: 2.026576289566614

Epoch: 5| Step: 10
Training loss: 1.5994412899017334
Validation loss: 2.1240671962820072

Epoch: 585| Step: 0
Training loss: 1.656471610069275
Validation loss: 2.0783167680104575

Epoch: 5| Step: 1
Training loss: 1.9029877185821533
Validation loss: 2.064424491697742

Epoch: 5| Step: 2
Training loss: 1.6243089437484741
Validation loss: 2.1184564239235333

Epoch: 5| Step: 3
Training loss: 1.3924996852874756
Validation loss: 2.101685967496646

Epoch: 5| Step: 4
Training loss: 1.8436607122421265
Validation loss: 2.0825803100421862

Epoch: 5| Step: 5
Training loss: 1.8499523401260376
Validation loss: 2.052526876490603

Epoch: 5| Step: 6
Training loss: 1.554999828338623
Validation loss: 2.107869311045575

Epoch: 5| Step: 7
Training loss: 1.1258132457733154
Validation loss: 2.0917222307574366

Epoch: 5| Step: 8
Training loss: 0.9964491128921509
Validation loss: 2.0499372918118715

Epoch: 5| Step: 9
Training loss: 1.3012593984603882
Validation loss: 2.024001189457473

Epoch: 5| Step: 10
Training loss: 1.5968501567840576
Validation loss: 2.1357293974968696

Epoch: 586| Step: 0
Training loss: 1.7270517349243164
Validation loss: 2.107682098624527

Epoch: 5| Step: 1
Training loss: 1.926409125328064
Validation loss: 2.015610118066111

Epoch: 5| Step: 2
Training loss: 1.5509073734283447
Validation loss: 1.9921562389660907

Epoch: 5| Step: 3
Training loss: 1.2060339450836182
Validation loss: 2.0998085942319644

Epoch: 5| Step: 4
Training loss: 1.3727009296417236
Validation loss: 2.024596525776771

Epoch: 5| Step: 5
Training loss: 1.1428674459457397
Validation loss: 2.05918986182059

Epoch: 5| Step: 6
Training loss: 1.520015835762024
Validation loss: 2.1294207675482637

Epoch: 5| Step: 7
Training loss: 1.5766738653182983
Validation loss: 2.0867664019266763

Epoch: 5| Step: 8
Training loss: 1.9184868335723877
Validation loss: 2.053884406243601

Epoch: 5| Step: 9
Training loss: 1.3596550226211548
Validation loss: 2.0350519431534635

Epoch: 5| Step: 10
Training loss: 1.4494524002075195
Validation loss: 2.0865978553730953

Epoch: 587| Step: 0
Training loss: 1.576351523399353
Validation loss: 2.040320811733123

Epoch: 5| Step: 1
Training loss: 1.236616849899292
Validation loss: 2.0876703762239024

Epoch: 5| Step: 2
Training loss: 1.3551859855651855
Validation loss: 2.031024243241997

Epoch: 5| Step: 3
Training loss: 1.5910134315490723
Validation loss: 2.1445176152772802

Epoch: 5| Step: 4
Training loss: 1.0652633905410767
Validation loss: 2.086546205705212

Epoch: 5| Step: 5
Training loss: 1.6372549533843994
Validation loss: 2.0034465764158513

Epoch: 5| Step: 6
Training loss: 1.2717299461364746
Validation loss: 1.9537368826968695

Epoch: 5| Step: 7
Training loss: 1.3118152618408203
Validation loss: 2.1026911479170605

Epoch: 5| Step: 8
Training loss: 1.401940107345581
Validation loss: 2.1050215216093164

Epoch: 5| Step: 9
Training loss: 1.5403990745544434
Validation loss: 2.0751421374659382

Epoch: 5| Step: 10
Training loss: 2.024496078491211
Validation loss: 2.0331383161647345

Epoch: 588| Step: 0
Training loss: 1.4263540506362915
Validation loss: 2.0918892275902534

Epoch: 5| Step: 1
Training loss: 1.391721248626709
Validation loss: 2.065803953396377

Epoch: 5| Step: 2
Training loss: 0.758802056312561
Validation loss: 2.0415564070465746

Epoch: 5| Step: 3
Training loss: 2.133904457092285
Validation loss: 2.1711473977693947

Epoch: 5| Step: 4
Training loss: 1.8561947345733643
Validation loss: 2.0984871989937237

Epoch: 5| Step: 5
Training loss: 1.4168543815612793
Validation loss: 2.0122520654432234

Epoch: 5| Step: 6
Training loss: 1.8770555257797241
Validation loss: 2.0061479806900024

Epoch: 5| Step: 7
Training loss: 1.1031978130340576
Validation loss: 1.8872384948115195

Epoch: 5| Step: 8
Training loss: 1.305271863937378
Validation loss: 2.079512466666519

Epoch: 5| Step: 9
Training loss: 1.427524209022522
Validation loss: 2.0358583978427354

Epoch: 5| Step: 10
Training loss: 1.6787906885147095
Validation loss: 2.110035901428551

Epoch: 589| Step: 0
Training loss: 1.956127405166626
Validation loss: 2.143402422628095

Epoch: 5| Step: 1
Training loss: 2.1951191425323486
Validation loss: 2.1304683839121172

Epoch: 5| Step: 2
Training loss: 1.494168996810913
Validation loss: 2.03400251173204

Epoch: 5| Step: 3
Training loss: 1.590613603591919
Validation loss: 2.0418382101161505

Epoch: 5| Step: 4
Training loss: 1.4453469514846802
Validation loss: 2.152143896266978

Epoch: 5| Step: 5
Training loss: 1.6228625774383545
Validation loss: 2.0167900721232095

Epoch: 5| Step: 6
Training loss: 1.4923374652862549
Validation loss: 2.06765962800672

Epoch: 5| Step: 7
Training loss: 1.0218994617462158
Validation loss: 2.1530178336686987

Epoch: 5| Step: 8
Training loss: 1.2711172103881836
Validation loss: 2.008454445869692

Epoch: 5| Step: 9
Training loss: 1.0285791158676147
Validation loss: 2.078286478596349

Epoch: 5| Step: 10
Training loss: 2.004408597946167
Validation loss: 2.09372345478304

Epoch: 590| Step: 0
Training loss: 1.6032283306121826
Validation loss: 2.0254001155976327

Epoch: 5| Step: 1
Training loss: 1.5024750232696533
Validation loss: 2.085874278058288

Epoch: 5| Step: 2
Training loss: 1.1445262432098389
Validation loss: 2.0698874599190167

Epoch: 5| Step: 3
Training loss: 1.4831643104553223
Validation loss: 2.1154397828604585

Epoch: 5| Step: 4
Training loss: 1.9680168628692627
Validation loss: 2.0465177592410835

Epoch: 5| Step: 5
Training loss: 1.5274564027786255
Validation loss: 2.1141035044065086

Epoch: 5| Step: 6
Training loss: 1.1318423748016357
Validation loss: 2.0455464188770582

Epoch: 5| Step: 7
Training loss: 1.296886920928955
Validation loss: 2.1302838838228615

Epoch: 5| Step: 8
Training loss: 1.439287781715393
Validation loss: 2.013251498181333

Epoch: 5| Step: 9
Training loss: 1.7852036952972412
Validation loss: 2.0523075749797206

Epoch: 5| Step: 10
Training loss: 1.3836613893508911
Validation loss: 2.034106500687138

Epoch: 591| Step: 0
Training loss: 1.6622388362884521
Validation loss: 2.0804077194583033

Epoch: 5| Step: 1
Training loss: 1.4093053340911865
Validation loss: 2.062748139904391

Epoch: 5| Step: 2
Training loss: 1.4954659938812256
Validation loss: 2.0968671652578537

Epoch: 5| Step: 3
Training loss: 1.48448646068573
Validation loss: 2.040287576695924

Epoch: 5| Step: 4
Training loss: 1.7604739665985107
Validation loss: 2.062661596523818

Epoch: 5| Step: 5
Training loss: 0.8905420303344727
Validation loss: 2.0586656511470838

Epoch: 5| Step: 6
Training loss: 1.589867115020752
Validation loss: 2.0448172015528523

Epoch: 5| Step: 7
Training loss: 1.7183822393417358
Validation loss: 2.0678658716140257

Epoch: 5| Step: 8
Training loss: 1.8959922790527344
Validation loss: 2.0598355980329615

Epoch: 5| Step: 9
Training loss: 1.4469603300094604
Validation loss: 2.0185144460329445

Epoch: 5| Step: 10
Training loss: 1.0099055767059326
Validation loss: 2.0731015538656585

Epoch: 592| Step: 0
Training loss: 1.2945102453231812
Validation loss: 2.0589754376360165

Epoch: 5| Step: 1
Training loss: 1.3610632419586182
Validation loss: 2.0295948930965957

Epoch: 5| Step: 2
Training loss: 1.4640510082244873
Validation loss: 2.004784434072433

Epoch: 5| Step: 3
Training loss: 1.9348993301391602
Validation loss: 2.04537276042405

Epoch: 5| Step: 4
Training loss: 1.5916526317596436
Validation loss: 2.053501457296392

Epoch: 5| Step: 5
Training loss: 1.7964599132537842
Validation loss: 2.1385414318371843

Epoch: 5| Step: 6
Training loss: 1.680471658706665
Validation loss: 2.041839445790937

Epoch: 5| Step: 7
Training loss: 1.6123616695404053
Validation loss: 1.9744957467561126

Epoch: 5| Step: 8
Training loss: 0.6767545342445374
Validation loss: 2.0130607979272

Epoch: 5| Step: 9
Training loss: 1.0210319757461548
Validation loss: 2.0765219234651133

Epoch: 5| Step: 10
Training loss: 2.0010669231414795
Validation loss: 2.0200054248174033

Epoch: 593| Step: 0
Training loss: 1.631955862045288
Validation loss: 2.053765763518631

Epoch: 5| Step: 1
Training loss: 0.7585725784301758
Validation loss: 2.0598368208895446

Epoch: 5| Step: 2
Training loss: 1.4953312873840332
Validation loss: 2.000477119158673

Epoch: 5| Step: 3
Training loss: 1.6251943111419678
Validation loss: 2.0528716066832184

Epoch: 5| Step: 4
Training loss: 1.4411014318466187
Validation loss: 2.01879689257632

Epoch: 5| Step: 5
Training loss: 1.5460865497589111
Validation loss: 1.9867152988269765

Epoch: 5| Step: 6
Training loss: 2.010399341583252
Validation loss: 2.027629429294217

Epoch: 5| Step: 7
Training loss: 1.321742296218872
Validation loss: 2.0980054152909147

Epoch: 5| Step: 8
Training loss: 1.6571338176727295
Validation loss: 2.0899448856230705

Epoch: 5| Step: 9
Training loss: 1.4908541440963745
Validation loss: 2.0562702891647175

Epoch: 5| Step: 10
Training loss: 1.179255723953247
Validation loss: 2.04899844302926

Epoch: 594| Step: 0
Training loss: 1.3621238470077515
Validation loss: 2.080740608194823

Epoch: 5| Step: 1
Training loss: 1.5083355903625488
Validation loss: 1.9719795027086813

Epoch: 5| Step: 2
Training loss: 1.7881568670272827
Validation loss: 2.0332580253642094

Epoch: 5| Step: 3
Training loss: 1.3890551328659058
Validation loss: 2.0634196676233763

Epoch: 5| Step: 4
Training loss: 2.231074094772339
Validation loss: 2.031059709928369

Epoch: 5| Step: 5
Training loss: 1.3787884712219238
Validation loss: 2.0182819956092426

Epoch: 5| Step: 6
Training loss: 1.3936119079589844
Validation loss: 2.066604511712187

Epoch: 5| Step: 7
Training loss: 1.5996989011764526
Validation loss: 2.0081655261337117

Epoch: 5| Step: 8
Training loss: 1.3768484592437744
Validation loss: 1.9937830868587698

Epoch: 5| Step: 9
Training loss: 1.4692468643188477
Validation loss: 2.052179044292819

Epoch: 5| Step: 10
Training loss: 1.6756263971328735
Validation loss: 2.019463885215021

Epoch: 595| Step: 0
Training loss: 1.1911823749542236
Validation loss: 2.0985857953307447

Epoch: 5| Step: 1
Training loss: 1.3270299434661865
Validation loss: 2.130075413693664

Epoch: 5| Step: 2
Training loss: 1.5646756887435913
Validation loss: 2.0495886174581384

Epoch: 5| Step: 3
Training loss: 1.9690635204315186
Validation loss: 2.00600673819101

Epoch: 5| Step: 4
Training loss: 0.9416543245315552
Validation loss: 2.1086583457967287

Epoch: 5| Step: 5
Training loss: 1.4242537021636963
Validation loss: 2.109587379681167

Epoch: 5| Step: 6
Training loss: 1.3204842805862427
Validation loss: 2.100414886269518

Epoch: 5| Step: 7
Training loss: 1.537116527557373
Validation loss: 2.0580940297854844

Epoch: 5| Step: 8
Training loss: 1.7203400135040283
Validation loss: 2.0818594066045617

Epoch: 5| Step: 9
Training loss: 1.732114553451538
Validation loss: 2.113798677280385

Epoch: 5| Step: 10
Training loss: 2.2354471683502197
Validation loss: 2.1010245866672967

Epoch: 596| Step: 0
Training loss: 1.052415132522583
Validation loss: 2.1384668055401055

Epoch: 5| Step: 1
Training loss: 1.3813620805740356
Validation loss: 2.051444927851359

Epoch: 5| Step: 2
Training loss: 1.4261033535003662
Validation loss: 2.1099442230757846

Epoch: 5| Step: 3
Training loss: 1.6205646991729736
Validation loss: 2.0881330377312115

Epoch: 5| Step: 4
Training loss: 1.7629505395889282
Validation loss: 2.1509353935077624

Epoch: 5| Step: 5
Training loss: 1.342313289642334
Validation loss: 1.9971246821905977

Epoch: 5| Step: 6
Training loss: 1.1422216892242432
Validation loss: 2.0180502553139963

Epoch: 5| Step: 7
Training loss: 2.017392635345459
Validation loss: 2.0322831625579507

Epoch: 5| Step: 8
Training loss: 1.387373685836792
Validation loss: 2.004268487294515

Epoch: 5| Step: 9
Training loss: 1.3923159837722778
Validation loss: 2.016464667935525

Epoch: 5| Step: 10
Training loss: 1.905353307723999
Validation loss: 2.043396331930673

Epoch: 597| Step: 0
Training loss: 1.5900574922561646
Validation loss: 2.119566548255182

Epoch: 5| Step: 1
Training loss: 1.5830938816070557
Validation loss: 1.99445774093751

Epoch: 5| Step: 2
Training loss: 1.097637414932251
Validation loss: 2.115907202484787

Epoch: 5| Step: 3
Training loss: 1.409502625465393
Validation loss: 1.9892243492987849

Epoch: 5| Step: 4
Training loss: 1.598975419998169
Validation loss: 2.055313979425738

Epoch: 5| Step: 5
Training loss: 1.3072866201400757
Validation loss: 2.11208350043143

Epoch: 5| Step: 6
Training loss: 1.4585325717926025
Validation loss: 2.1520987479917464

Epoch: 5| Step: 7
Training loss: 1.373073697090149
Validation loss: 2.1626695202242945

Epoch: 5| Step: 8
Training loss: 1.5128777027130127
Validation loss: 1.9642384090731222

Epoch: 5| Step: 9
Training loss: 1.3856128454208374
Validation loss: 2.051103622682633

Epoch: 5| Step: 10
Training loss: 1.5520658493041992
Validation loss: 2.093374329228555

Epoch: 598| Step: 0
Training loss: 1.4399971961975098
Validation loss: 2.044262683519753

Epoch: 5| Step: 1
Training loss: 2.080249309539795
Validation loss: 1.99532062520263

Epoch: 5| Step: 2
Training loss: 1.501216173171997
Validation loss: 2.080141536651119

Epoch: 5| Step: 3
Training loss: 1.024182915687561
Validation loss: 2.074300789063977

Epoch: 5| Step: 4
Training loss: 1.3066928386688232
Validation loss: 2.12878071108172

Epoch: 5| Step: 5
Training loss: 1.1020636558532715
Validation loss: 2.0698033250788206

Epoch: 5| Step: 6
Training loss: 1.2156589031219482
Validation loss: 2.0904903732320315

Epoch: 5| Step: 7
Training loss: 2.264709949493408
Validation loss: 2.1241001441914547

Epoch: 5| Step: 8
Training loss: 1.324977159500122
Validation loss: 2.03839002373398

Epoch: 5| Step: 9
Training loss: 1.429995059967041
Validation loss: 2.073627584724016

Epoch: 5| Step: 10
Training loss: 1.681950569152832
Validation loss: 2.0683197552157986

Epoch: 599| Step: 0
Training loss: 1.3532050848007202
Validation loss: 2.146532209970618

Epoch: 5| Step: 1
Training loss: 1.8996378183364868
Validation loss: 2.1083406889310448

Epoch: 5| Step: 2
Training loss: 1.8055751323699951
Validation loss: 2.0481735583274596

Epoch: 5| Step: 3
Training loss: 1.9521602392196655
Validation loss: 2.0520717418322

Epoch: 5| Step: 4
Training loss: 1.7002265453338623
Validation loss: 2.1343631513657106

Epoch: 5| Step: 5
Training loss: 1.2834444046020508
Validation loss: 2.013428759831254

Epoch: 5| Step: 6
Training loss: 1.9208675622940063
Validation loss: 2.1132607921477287

Epoch: 5| Step: 7
Training loss: 1.5154855251312256
Validation loss: 1.922299397889004

Epoch: 5| Step: 8
Training loss: 1.3300656080245972
Validation loss: 2.0295479477092786

Epoch: 5| Step: 9
Training loss: 1.166571021080017
Validation loss: 1.9510891924622238

Epoch: 5| Step: 10
Training loss: 0.7821022272109985
Validation loss: 2.077318246646594

Epoch: 600| Step: 0
Training loss: 1.462265968322754
Validation loss: 2.0223779601435505

Epoch: 5| Step: 1
Training loss: 1.3118007183074951
Validation loss: 1.9786840972080026

Epoch: 5| Step: 2
Training loss: 1.4037995338439941
Validation loss: 2.1096730052783923

Epoch: 5| Step: 3
Training loss: 1.288740873336792
Validation loss: 2.115799396268783

Epoch: 5| Step: 4
Training loss: 1.556459665298462
Validation loss: 2.0771013254760415

Epoch: 5| Step: 5
Training loss: 1.6544097661972046
Validation loss: 2.0540154621165287

Epoch: 5| Step: 6
Training loss: 2.1595683097839355
Validation loss: 2.0579748794596684

Epoch: 5| Step: 7
Training loss: 1.245793342590332
Validation loss: 2.0328158742638043

Epoch: 5| Step: 8
Training loss: 1.1374602317810059
Validation loss: 2.0150727738616285

Epoch: 5| Step: 9
Training loss: 1.4840866327285767
Validation loss: 1.9808491096701673

Epoch: 5| Step: 10
Training loss: 1.7211706638336182
Validation loss: 2.0445732839645876

Epoch: 601| Step: 0
Training loss: 1.430019497871399
Validation loss: 2.0511007437141995

Epoch: 5| Step: 1
Training loss: 0.8810219764709473
Validation loss: 2.0522296095407135

Epoch: 5| Step: 2
Training loss: 1.4510624408721924
Validation loss: 2.04444444564081

Epoch: 5| Step: 3
Training loss: 1.3249719142913818
Validation loss: 2.027156109450966

Epoch: 5| Step: 4
Training loss: 1.7524213790893555
Validation loss: 2.144740237984606

Epoch: 5| Step: 5
Training loss: 1.517439603805542
Validation loss: 2.0631353919224074

Epoch: 5| Step: 6
Training loss: 1.912872314453125
Validation loss: 1.9747032196291032

Epoch: 5| Step: 7
Training loss: 1.77732253074646
Validation loss: 2.0042467245491604

Epoch: 5| Step: 8
Training loss: 1.4497636556625366
Validation loss: 2.055201530456543

Epoch: 5| Step: 9
Training loss: 1.5153038501739502
Validation loss: 2.1330661184044293

Epoch: 5| Step: 10
Training loss: 1.5469788312911987
Validation loss: 2.1138360551608506

Epoch: 602| Step: 0
Training loss: 1.381709337234497
Validation loss: 2.0583136722605717

Epoch: 5| Step: 1
Training loss: 1.7939255237579346
Validation loss: 1.9488247338161673

Epoch: 5| Step: 2
Training loss: 1.519034743309021
Validation loss: 2.1082590267222416

Epoch: 5| Step: 3
Training loss: 1.5280344486236572
Validation loss: 2.0534228278744604

Epoch: 5| Step: 4
Training loss: 1.4859631061553955
Validation loss: 2.1304202951410764

Epoch: 5| Step: 5
Training loss: 1.737728476524353
Validation loss: 2.045339548459617

Epoch: 5| Step: 6
Training loss: 1.503480315208435
Validation loss: 2.03792384875718

Epoch: 5| Step: 7
Training loss: 1.772085428237915
Validation loss: 2.0744001468022666

Epoch: 5| Step: 8
Training loss: 0.5931729078292847
Validation loss: 2.1405979253912486

Epoch: 5| Step: 9
Training loss: 1.4255270957946777
Validation loss: 2.013529113543931

Epoch: 5| Step: 10
Training loss: 1.7387200593948364
Validation loss: 2.0249169923925914

Epoch: 603| Step: 0
Training loss: 1.5308858156204224
Validation loss: 2.0791970094045005

Epoch: 5| Step: 1
Training loss: 2.009054183959961
Validation loss: 2.1050445559204265

Epoch: 5| Step: 2
Training loss: 1.6499264240264893
Validation loss: 2.1528914436217277

Epoch: 5| Step: 3
Training loss: 1.5696648359298706
Validation loss: 2.093446500839726

Epoch: 5| Step: 4
Training loss: 2.044720411300659
Validation loss: 2.059694584979806

Epoch: 5| Step: 5
Training loss: 1.286362886428833
Validation loss: 2.076171725027023

Epoch: 5| Step: 6
Training loss: 1.0535277128219604
Validation loss: 2.1307571024023075

Epoch: 5| Step: 7
Training loss: 1.1520795822143555
Validation loss: 2.06631899392733

Epoch: 5| Step: 8
Training loss: 1.168276071548462
Validation loss: 2.071037087389218

Epoch: 5| Step: 9
Training loss: 1.9501466751098633
Validation loss: 1.970797356738839

Epoch: 5| Step: 10
Training loss: 1.469541072845459
Validation loss: 2.039905401968187

Epoch: 604| Step: 0
Training loss: 1.4643213748931885
Validation loss: 2.050362721566231

Epoch: 5| Step: 1
Training loss: 1.22783625125885
Validation loss: 2.0551991078161422

Epoch: 5| Step: 2
Training loss: 1.1180309057235718
Validation loss: 2.065453678049067

Epoch: 5| Step: 3
Training loss: 2.043534755706787
Validation loss: 2.05268979841663

Epoch: 5| Step: 4
Training loss: 1.7376219034194946
Validation loss: 2.111163003470308

Epoch: 5| Step: 5
Training loss: 1.5105630159378052
Validation loss: 1.9464449344142791

Epoch: 5| Step: 6
Training loss: 1.274321436882019
Validation loss: 1.9771164745412848

Epoch: 5| Step: 7
Training loss: 1.63546884059906
Validation loss: 2.0349559322480233

Epoch: 5| Step: 8
Training loss: 1.2469810247421265
Validation loss: 2.016963202466247

Epoch: 5| Step: 9
Training loss: 1.4910600185394287
Validation loss: 2.0975238456520984

Epoch: 5| Step: 10
Training loss: 1.7321544885635376
Validation loss: 2.082169494321269

Epoch: 605| Step: 0
Training loss: 1.2631819248199463
Validation loss: 2.0136575006669566

Epoch: 5| Step: 1
Training loss: 1.1933882236480713
Validation loss: 2.105048438554169

Epoch: 5| Step: 2
Training loss: 2.1633009910583496
Validation loss: 2.1368610653825986

Epoch: 5| Step: 3
Training loss: 1.4977991580963135
Validation loss: 2.1173027253920034

Epoch: 5| Step: 4
Training loss: 2.5428640842437744
Validation loss: 2.184233719302762

Epoch: 5| Step: 5
Training loss: 1.436254858970642
Validation loss: 2.1994044114184637

Epoch: 5| Step: 6
Training loss: 1.6575008630752563
Validation loss: 2.1647425133694886

Epoch: 5| Step: 7
Training loss: 1.6336368322372437
Validation loss: 2.0445861560042187

Epoch: 5| Step: 8
Training loss: 0.7263716459274292
Validation loss: 2.1040494083076395

Epoch: 5| Step: 9
Training loss: 1.1451610326766968
Validation loss: 2.0177251203085786

Epoch: 5| Step: 10
Training loss: 1.1811599731445312
Validation loss: 2.0420605713321316

Epoch: 606| Step: 0
Training loss: 1.408296823501587
Validation loss: 2.0713555607744443

Epoch: 5| Step: 1
Training loss: 0.9737658500671387
Validation loss: 2.126894945739418

Epoch: 5| Step: 2
Training loss: 2.1357929706573486
Validation loss: 2.031421103785115

Epoch: 5| Step: 3
Training loss: 1.5456589460372925
Validation loss: 2.031321984465404

Epoch: 5| Step: 4
Training loss: 1.3730767965316772
Validation loss: 2.0439819417974

Epoch: 5| Step: 5
Training loss: 1.6650909185409546
Validation loss: 2.0250685163723525

Epoch: 5| Step: 6
Training loss: 1.3581560850143433
Validation loss: 2.0755747774595856

Epoch: 5| Step: 7
Training loss: 1.1745188236236572
Validation loss: 2.074991815833635

Epoch: 5| Step: 8
Training loss: 1.7689087390899658
Validation loss: 2.000612724211908

Epoch: 5| Step: 9
Training loss: 1.5334676504135132
Validation loss: 1.9713819308947491

Epoch: 5| Step: 10
Training loss: 1.3391436338424683
Validation loss: 2.0324454948466313

Epoch: 607| Step: 0
Training loss: 0.9946688413619995
Validation loss: 2.070464805890155

Epoch: 5| Step: 1
Training loss: 1.7589061260223389
Validation loss: 2.013379753276866

Epoch: 5| Step: 2
Training loss: 0.8482038378715515
Validation loss: 2.03210626622682

Epoch: 5| Step: 3
Training loss: 1.1259874105453491
Validation loss: 2.0481403950721986

Epoch: 5| Step: 4
Training loss: 1.4500821828842163
Validation loss: 2.149281550479192

Epoch: 5| Step: 5
Training loss: 1.7576515674591064
Validation loss: 2.24379930444943

Epoch: 5| Step: 6
Training loss: 1.2651774883270264
Validation loss: 2.1500652861851517

Epoch: 5| Step: 7
Training loss: 1.835994005203247
Validation loss: 2.0962501418206

Epoch: 5| Step: 8
Training loss: 1.734347939491272
Validation loss: 2.1353212607804166

Epoch: 5| Step: 9
Training loss: 1.541935682296753
Validation loss: 2.0428457144768006

Epoch: 5| Step: 10
Training loss: 1.7687309980392456
Validation loss: 2.0966651798576437

Epoch: 608| Step: 0
Training loss: 2.2196080684661865
Validation loss: 2.0444517725257465

Epoch: 5| Step: 1
Training loss: 1.0737406015396118
Validation loss: 2.0253376576208297

Epoch: 5| Step: 2
Training loss: 1.3654221296310425
Validation loss: 2.084402045895976

Epoch: 5| Step: 3
Training loss: 0.9214555621147156
Validation loss: 1.9721245201685096

Epoch: 5| Step: 4
Training loss: 1.7404359579086304
Validation loss: 1.9751566430573821

Epoch: 5| Step: 5
Training loss: 1.7415565252304077
Validation loss: 2.0349834042210735

Epoch: 5| Step: 6
Training loss: 1.432418942451477
Validation loss: 2.0592850664610505

Epoch: 5| Step: 7
Training loss: 1.0258054733276367
Validation loss: 2.1008447857313257

Epoch: 5| Step: 8
Training loss: 1.466997504234314
Validation loss: 2.075155301760602

Epoch: 5| Step: 9
Training loss: 1.5585540533065796
Validation loss: 1.9854233828924035

Epoch: 5| Step: 10
Training loss: 1.6317237615585327
Validation loss: 2.076651011743853

Epoch: 609| Step: 0
Training loss: 1.3559706211090088
Validation loss: 1.967000679303241

Epoch: 5| Step: 1
Training loss: 1.1104656457901
Validation loss: 2.052797903296768

Epoch: 5| Step: 2
Training loss: 1.2349458932876587
Validation loss: 2.0706435172788558

Epoch: 5| Step: 3
Training loss: 1.2475934028625488
Validation loss: 2.115112994306831

Epoch: 5| Step: 4
Training loss: 1.8366382122039795
Validation loss: 2.102684708051784

Epoch: 5| Step: 5
Training loss: 1.5137286186218262
Validation loss: 2.043873436989323

Epoch: 5| Step: 6
Training loss: 1.7216322422027588
Validation loss: 2.1269638743451846

Epoch: 5| Step: 7
Training loss: 1.405185341835022
Validation loss: 2.0290826289884505

Epoch: 5| Step: 8
Training loss: 1.6656911373138428
Validation loss: 2.0190811798136723

Epoch: 5| Step: 9
Training loss: 1.6859928369522095
Validation loss: 2.029277160603513

Epoch: 5| Step: 10
Training loss: 1.234317421913147
Validation loss: 2.092364631673341

Epoch: 610| Step: 0
Training loss: 1.2548717260360718
Validation loss: 2.0217475737294843

Epoch: 5| Step: 1
Training loss: 1.243238091468811
Validation loss: 2.1395495181442588

Epoch: 5| Step: 2
Training loss: 1.8384701013565063
Validation loss: 1.9843777636046052

Epoch: 5| Step: 3
Training loss: 1.9987834692001343
Validation loss: 2.1030319044666905

Epoch: 5| Step: 4
Training loss: 1.2060779333114624
Validation loss: 2.0478917757670083

Epoch: 5| Step: 5
Training loss: 1.6130897998809814
Validation loss: 2.1672250916880946

Epoch: 5| Step: 6
Training loss: 1.2541030645370483
Validation loss: 2.0367221704093357

Epoch: 5| Step: 7
Training loss: 1.0823899507522583
Validation loss: 2.146214703077911

Epoch: 5| Step: 8
Training loss: 1.7665977478027344
Validation loss: 2.0518603119798886

Epoch: 5| Step: 9
Training loss: 1.5487436056137085
Validation loss: 2.0648546398326917

Epoch: 5| Step: 10
Training loss: 1.4754632711410522
Validation loss: 2.035723004289853

Epoch: 611| Step: 0
Training loss: 1.0647976398468018
Validation loss: 2.074181083709963

Epoch: 5| Step: 1
Training loss: 1.0167948007583618
Validation loss: 2.040882131104828

Epoch: 5| Step: 2
Training loss: 1.1628806591033936
Validation loss: 2.037837105412637

Epoch: 5| Step: 3
Training loss: 1.6432291269302368
Validation loss: 2.020766737640545

Epoch: 5| Step: 4
Training loss: 1.4182744026184082
Validation loss: 2.0331230830120783

Epoch: 5| Step: 5
Training loss: 2.265617847442627
Validation loss: 2.1509943085332073

Epoch: 5| Step: 6
Training loss: 1.6180436611175537
Validation loss: 2.1376085089099024

Epoch: 5| Step: 7
Training loss: 1.6125692129135132
Validation loss: 2.1049453520005748

Epoch: 5| Step: 8
Training loss: 1.7022323608398438
Validation loss: 2.0225293303048737

Epoch: 5| Step: 9
Training loss: 1.2496469020843506
Validation loss: 2.011879256976548

Epoch: 5| Step: 10
Training loss: 1.3021717071533203
Validation loss: 2.1689179584544194

Epoch: 612| Step: 0
Training loss: 1.4811122417449951
Validation loss: 2.1170996363444994

Epoch: 5| Step: 1
Training loss: 0.9366701245307922
Validation loss: 1.964873429267637

Epoch: 5| Step: 2
Training loss: 1.9517028331756592
Validation loss: 1.982001248226371

Epoch: 5| Step: 3
Training loss: 1.2292671203613281
Validation loss: 2.15472218554507

Epoch: 5| Step: 4
Training loss: 1.6490405797958374
Validation loss: 2.100822828149283

Epoch: 5| Step: 5
Training loss: 1.12651789188385
Validation loss: 2.0311196875828568

Epoch: 5| Step: 6
Training loss: 1.7162494659423828
Validation loss: 2.028409065738801

Epoch: 5| Step: 7
Training loss: 1.8392314910888672
Validation loss: 2.1577041200412217

Epoch: 5| Step: 8
Training loss: 1.553561806678772
Validation loss: 1.992856050050387

Epoch: 5| Step: 9
Training loss: 1.2132186889648438
Validation loss: 2.148822735714656

Epoch: 5| Step: 10
Training loss: 1.170830488204956
Validation loss: 2.139793478032594

Epoch: 613| Step: 0
Training loss: 1.9218155145645142
Validation loss: 2.121458940608527

Epoch: 5| Step: 1
Training loss: 1.7006886005401611
Validation loss: 2.1298003555625997

Epoch: 5| Step: 2
Training loss: 1.0634751319885254
Validation loss: 2.0365208733466362

Epoch: 5| Step: 3
Training loss: 1.0901336669921875
Validation loss: 1.979125968871578

Epoch: 5| Step: 4
Training loss: 1.558591604232788
Validation loss: 2.0189297635068177

Epoch: 5| Step: 5
Training loss: 1.4605283737182617
Validation loss: 2.1046009230357345

Epoch: 5| Step: 6
Training loss: 2.3535704612731934
Validation loss: 1.9979258134800901

Epoch: 5| Step: 7
Training loss: 1.375855803489685
Validation loss: 2.0918326480414278

Epoch: 5| Step: 8
Training loss: 1.2784204483032227
Validation loss: 1.9686296370721632

Epoch: 5| Step: 9
Training loss: 0.9621517062187195
Validation loss: 2.032164901815435

Epoch: 5| Step: 10
Training loss: 1.0806804895401
Validation loss: 2.0173517427136822

Epoch: 614| Step: 0
Training loss: 1.7093511819839478
Validation loss: 2.065710154912805

Epoch: 5| Step: 1
Training loss: 1.2161872386932373
Validation loss: 2.1058629866569274

Epoch: 5| Step: 2
Training loss: 1.9751646518707275
Validation loss: 1.999558912810459

Epoch: 5| Step: 3
Training loss: 1.3908592462539673
Validation loss: 2.0024669196016047

Epoch: 5| Step: 4
Training loss: 1.5678582191467285
Validation loss: 2.1250666392746793

Epoch: 5| Step: 5
Training loss: 1.3143519163131714
Validation loss: 2.016649491043501

Epoch: 5| Step: 6
Training loss: 1.7379575967788696
Validation loss: 2.090930595192858

Epoch: 5| Step: 7
Training loss: 1.1943182945251465
Validation loss: 2.034245373100363

Epoch: 5| Step: 8
Training loss: 1.0908286571502686
Validation loss: 2.0275608839527255

Epoch: 5| Step: 9
Training loss: 1.0683895349502563
Validation loss: 2.059146220966052

Epoch: 5| Step: 10
Training loss: 1.4954427480697632
Validation loss: 2.061686732435739

Epoch: 615| Step: 0
Training loss: 1.4286867380142212
Validation loss: 2.0938989590573054

Epoch: 5| Step: 1
Training loss: 2.170658588409424
Validation loss: 2.0511204965652956

Epoch: 5| Step: 2
Training loss: 1.188966989517212
Validation loss: 2.074762358460375

Epoch: 5| Step: 3
Training loss: 1.47529137134552
Validation loss: 2.083270093446137

Epoch: 5| Step: 4
Training loss: 1.5159084796905518
Validation loss: 2.044983571575534

Epoch: 5| Step: 5
Training loss: 1.3298413753509521
Validation loss: 2.120554203628212

Epoch: 5| Step: 6
Training loss: 0.9196880459785461
Validation loss: 2.060835894717965

Epoch: 5| Step: 7
Training loss: 1.3160265684127808
Validation loss: 1.9845451385744157

Epoch: 5| Step: 8
Training loss: 1.4814528226852417
Validation loss: 2.0431655196733374

Epoch: 5| Step: 9
Training loss: 1.430967926979065
Validation loss: 2.0774354165600193

Epoch: 5| Step: 10
Training loss: 1.79212486743927
Validation loss: 2.134762117939611

Epoch: 616| Step: 0
Training loss: 1.541117548942566
Validation loss: 2.0441521598446752

Epoch: 5| Step: 1
Training loss: 1.622389554977417
Validation loss: 2.181183881657098

Epoch: 5| Step: 2
Training loss: 1.1832646131515503
Validation loss: 2.003116511529492

Epoch: 5| Step: 3
Training loss: 1.8529255390167236
Validation loss: 2.1618925550932526

Epoch: 5| Step: 4
Training loss: 1.7805017232894897
Validation loss: 2.001016720648735

Epoch: 5| Step: 5
Training loss: 1.179253339767456
Validation loss: 2.0213212172190347

Epoch: 5| Step: 6
Training loss: 1.4404611587524414
Validation loss: 2.063647452221122

Epoch: 5| Step: 7
Training loss: 1.4780526161193848
Validation loss: 1.9918383436818277

Epoch: 5| Step: 8
Training loss: 1.4589718580245972
Validation loss: 2.149498229385704

Epoch: 5| Step: 9
Training loss: 1.5863103866577148
Validation loss: 2.119466062515013

Epoch: 5| Step: 10
Training loss: 1.4796454906463623
Validation loss: 2.034110079529465

Epoch: 617| Step: 0
Training loss: 1.2718582153320312
Validation loss: 2.041400847896453

Epoch: 5| Step: 1
Training loss: 1.3797221183776855
Validation loss: 2.0069011462632047

Epoch: 5| Step: 2
Training loss: 0.9268693923950195
Validation loss: 2.033659588906073

Epoch: 5| Step: 3
Training loss: 1.4625400304794312
Validation loss: 2.1808126459839525

Epoch: 5| Step: 4
Training loss: 1.2231042385101318
Validation loss: 2.1127686910731818

Epoch: 5| Step: 5
Training loss: 2.180502414703369
Validation loss: 2.128049647936257

Epoch: 5| Step: 6
Training loss: 1.0221303701400757
Validation loss: 2.0413471332160373

Epoch: 5| Step: 7
Training loss: 1.5919398069381714
Validation loss: 2.156969416526056

Epoch: 5| Step: 8
Training loss: 1.3509594202041626
Validation loss: 2.0990156589015836

Epoch: 5| Step: 9
Training loss: 1.2326080799102783
Validation loss: 2.0848596326766478

Epoch: 5| Step: 10
Training loss: 2.3293471336364746
Validation loss: 2.0762781379043416

Epoch: 618| Step: 0
Training loss: 1.4274370670318604
Validation loss: 2.131583503497544

Epoch: 5| Step: 1
Training loss: 1.1005443334579468
Validation loss: 2.192683304509809

Epoch: 5| Step: 2
Training loss: 1.5242664813995361
Validation loss: 2.05976838450278

Epoch: 5| Step: 3
Training loss: 1.4481871128082275
Validation loss: 2.132537841796875

Epoch: 5| Step: 4
Training loss: 1.1902987957000732
Validation loss: 2.048358049443973

Epoch: 5| Step: 5
Training loss: 1.8087726831436157
Validation loss: 2.0436544520880586

Epoch: 5| Step: 6
Training loss: 1.4596107006072998
Validation loss: 2.108232803242181

Epoch: 5| Step: 7
Training loss: 1.3448665142059326
Validation loss: 2.1246862411499023

Epoch: 5| Step: 8
Training loss: 1.7694404125213623
Validation loss: 2.027061764911939

Epoch: 5| Step: 9
Training loss: 1.0486427545547485
Validation loss: 2.1863081711594776

Epoch: 5| Step: 10
Training loss: 1.3517512083053589
Validation loss: 2.1564433831040577

Epoch: 619| Step: 0
Training loss: 1.2134873867034912
Validation loss: 2.070678216154857

Epoch: 5| Step: 1
Training loss: 1.1035544872283936
Validation loss: 1.9714574019114177

Epoch: 5| Step: 2
Training loss: 1.3809993267059326
Validation loss: 2.102418094552973

Epoch: 5| Step: 3
Training loss: 1.5354418754577637
Validation loss: 2.0796015595877044

Epoch: 5| Step: 4
Training loss: 1.6157236099243164
Validation loss: 2.1033508726345596

Epoch: 5| Step: 5
Training loss: 1.1127718687057495
Validation loss: 1.9933280842278593

Epoch: 5| Step: 6
Training loss: 1.9348952770233154
Validation loss: 2.019545831987935

Epoch: 5| Step: 7
Training loss: 1.3948520421981812
Validation loss: 2.112476004067288

Epoch: 5| Step: 8
Training loss: 0.9160655736923218
Validation loss: 2.2039779411849154

Epoch: 5| Step: 9
Training loss: 2.358529806137085
Validation loss: 1.993495911680242

Epoch: 5| Step: 10
Training loss: 1.173281192779541
Validation loss: 2.0301200523171374

Epoch: 620| Step: 0
Training loss: 1.863742470741272
Validation loss: 2.091481021655503

Epoch: 5| Step: 1
Training loss: 1.770127534866333
Validation loss: 2.0771548491652294

Epoch: 5| Step: 2
Training loss: 1.639227271080017
Validation loss: 2.023157500451611

Epoch: 5| Step: 3
Training loss: 1.2197847366333008
Validation loss: 1.9959334506783435

Epoch: 5| Step: 4
Training loss: 1.5362284183502197
Validation loss: 2.104092328779159

Epoch: 5| Step: 5
Training loss: 1.0633624792099
Validation loss: 2.09438411138391

Epoch: 5| Step: 6
Training loss: 1.1512129306793213
Validation loss: 2.00505353302084

Epoch: 5| Step: 7
Training loss: 1.5001535415649414
Validation loss: 1.9802758245057956

Epoch: 5| Step: 8
Training loss: 1.4780713319778442
Validation loss: 2.0308703017491165

Epoch: 5| Step: 9
Training loss: 1.623155951499939
Validation loss: 1.9984658200253722

Epoch: 5| Step: 10
Training loss: 1.2892966270446777
Validation loss: 2.016941705057698

Epoch: 621| Step: 0
Training loss: 1.4962023496627808
Validation loss: 2.033881461748513

Epoch: 5| Step: 1
Training loss: 1.0968538522720337
Validation loss: 1.9647258289398686

Epoch: 5| Step: 2
Training loss: 1.6867250204086304
Validation loss: 2.2108533869507494

Epoch: 5| Step: 3
Training loss: 1.9204972982406616
Validation loss: 2.0591892055285874

Epoch: 5| Step: 4
Training loss: 0.8366590738296509
Validation loss: 2.0079616167212047

Epoch: 5| Step: 5
Training loss: 1.691091537475586
Validation loss: 2.177503575560867

Epoch: 5| Step: 6
Training loss: 1.7704904079437256
Validation loss: 2.02684590893407

Epoch: 5| Step: 7
Training loss: 2.041006326675415
Validation loss: 2.0828352205214964

Epoch: 5| Step: 8
Training loss: 1.4923450946807861
Validation loss: 2.054760040775422

Epoch: 5| Step: 9
Training loss: 1.615106225013733
Validation loss: 2.0476371267790436

Epoch: 5| Step: 10
Training loss: 1.1132010221481323
Validation loss: 2.109152691338652

Epoch: 622| Step: 0
Training loss: 1.521934151649475
Validation loss: 2.0918579819381877

Epoch: 5| Step: 1
Training loss: 1.539711594581604
Validation loss: 1.982095951675087

Epoch: 5| Step: 2
Training loss: 1.8218326568603516
Validation loss: 2.189457780571394

Epoch: 5| Step: 3
Training loss: 1.878612756729126
Validation loss: 1.9689690797559676

Epoch: 5| Step: 4
Training loss: 1.2027562856674194
Validation loss: 1.992210288201609

Epoch: 5| Step: 5
Training loss: 1.6945781707763672
Validation loss: 2.0704377107722785

Epoch: 5| Step: 6
Training loss: 1.2444065809249878
Validation loss: 2.0301663606397566

Epoch: 5| Step: 7
Training loss: 0.9538158178329468
Validation loss: 1.9854122438738424

Epoch: 5| Step: 8
Training loss: 1.896664023399353
Validation loss: 2.025831742953229

Epoch: 5| Step: 9
Training loss: 1.457363247871399
Validation loss: 2.102588717655469

Epoch: 5| Step: 10
Training loss: 1.2368614673614502
Validation loss: 2.0769537777029057

Epoch: 623| Step: 0
Training loss: 1.2405805587768555
Validation loss: 2.1294226146513417

Epoch: 5| Step: 1
Training loss: 1.964551329612732
Validation loss: 2.086659731403474

Epoch: 5| Step: 2
Training loss: 1.7422683238983154
Validation loss: 2.0459742802445606

Epoch: 5| Step: 3
Training loss: 1.1733334064483643
Validation loss: 2.127553504000428

Epoch: 5| Step: 4
Training loss: 1.332726001739502
Validation loss: 2.0413711224832842

Epoch: 5| Step: 5
Training loss: 1.3837602138519287
Validation loss: 2.1703971124464467

Epoch: 5| Step: 6
Training loss: 1.8315986394882202
Validation loss: 2.091689968621859

Epoch: 5| Step: 7
Training loss: 1.3211944103240967
Validation loss: 2.088356589758268

Epoch: 5| Step: 8
Training loss: 1.746726632118225
Validation loss: 2.0105005002790883

Epoch: 5| Step: 9
Training loss: 1.4481408596038818
Validation loss: 2.053467499312534

Epoch: 5| Step: 10
Training loss: 1.139673113822937
Validation loss: 2.019392100713586

Epoch: 624| Step: 0
Training loss: 1.5102726221084595
Validation loss: 2.0110892403510308

Epoch: 5| Step: 1
Training loss: 1.7499717473983765
Validation loss: 2.171290536080637

Epoch: 5| Step: 2
Training loss: 1.3532958030700684
Validation loss: 2.118561606253347

Epoch: 5| Step: 3
Training loss: 1.3715059757232666
Validation loss: 1.9878161325249621

Epoch: 5| Step: 4
Training loss: 1.4227116107940674
Validation loss: 2.138018331220073

Epoch: 5| Step: 5
Training loss: 1.1439893245697021
Validation loss: 2.103856932732367

Epoch: 5| Step: 6
Training loss: 1.1377089023590088
Validation loss: 2.020102982879967

Epoch: 5| Step: 7
Training loss: 1.8314329385757446
Validation loss: 2.1248711257852535

Epoch: 5| Step: 8
Training loss: 1.7839057445526123
Validation loss: 2.1391530293290333

Epoch: 5| Step: 9
Training loss: 1.417557954788208
Validation loss: 1.9961421515351983

Epoch: 5| Step: 10
Training loss: 1.5711445808410645
Validation loss: 2.136900947939965

Epoch: 625| Step: 0
Training loss: 1.216159701347351
Validation loss: 2.127166191736857

Epoch: 5| Step: 1
Training loss: 1.238835334777832
Validation loss: 2.028301603050642

Epoch: 5| Step: 2
Training loss: 1.1150717735290527
Validation loss: 2.1525450111717306

Epoch: 5| Step: 3
Training loss: 1.608759880065918
Validation loss: 2.0802934118496474

Epoch: 5| Step: 4
Training loss: 2.019793748855591
Validation loss: 2.0729701339557605

Epoch: 5| Step: 5
Training loss: 1.27361261844635
Validation loss: 2.069067124397524

Epoch: 5| Step: 6
Training loss: 1.362628698348999
Validation loss: 2.0445575957657187

Epoch: 5| Step: 7
Training loss: 1.7057586908340454
Validation loss: 2.1123157624275453

Epoch: 5| Step: 8
Training loss: 1.198055386543274
Validation loss: 2.044956995594886

Epoch: 5| Step: 9
Training loss: 1.8054189682006836
Validation loss: 2.054529288763641

Epoch: 5| Step: 10
Training loss: 1.6885781288146973
Validation loss: 2.0648269550774687

Epoch: 626| Step: 0
Training loss: 1.3678102493286133
Validation loss: 2.021252865432411

Epoch: 5| Step: 1
Training loss: 1.2653838396072388
Validation loss: 2.133577049419444

Epoch: 5| Step: 2
Training loss: 1.564489722251892
Validation loss: 2.1275756692373626

Epoch: 5| Step: 3
Training loss: 1.3831291198730469
Validation loss: 2.112990553661059

Epoch: 5| Step: 4
Training loss: 1.533743143081665
Validation loss: 2.154774422286659

Epoch: 5| Step: 5
Training loss: 1.6928396224975586
Validation loss: 2.0218679789573915

Epoch: 5| Step: 6
Training loss: 1.5034806728363037
Validation loss: 2.1550432174436507

Epoch: 5| Step: 7
Training loss: 1.3803751468658447
Validation loss: 2.083251678815452

Epoch: 5| Step: 8
Training loss: 1.524906039237976
Validation loss: 2.081464067582161

Epoch: 5| Step: 9
Training loss: 1.4724210500717163
Validation loss: 2.1049821556255384

Epoch: 5| Step: 10
Training loss: 1.7094513177871704
Validation loss: 2.132198097885296

Epoch: 627| Step: 0
Training loss: 1.7173452377319336
Validation loss: 2.0431346239582187

Epoch: 5| Step: 1
Training loss: 1.2090381383895874
Validation loss: 2.0907126434387697

Epoch: 5| Step: 2
Training loss: 1.656378149986267
Validation loss: 2.12300338668208

Epoch: 5| Step: 3
Training loss: 2.0496134757995605
Validation loss: 2.0830881762248215

Epoch: 5| Step: 4
Training loss: 1.784781813621521
Validation loss: 1.99790479547234

Epoch: 5| Step: 5
Training loss: 1.3401323556900024
Validation loss: 2.1677386709438857

Epoch: 5| Step: 6
Training loss: 1.1917861700057983
Validation loss: 2.0779584915407243

Epoch: 5| Step: 7
Training loss: 1.264910101890564
Validation loss: 2.1050128526585077

Epoch: 5| Step: 8
Training loss: 0.9381333589553833
Validation loss: 1.9995720001959032

Epoch: 5| Step: 9
Training loss: 1.2545645236968994
Validation loss: 2.0890621344248452

Epoch: 5| Step: 10
Training loss: 1.2559529542922974
Validation loss: 2.071973369967553

Epoch: 628| Step: 0
Training loss: 1.619227647781372
Validation loss: 2.046845859096896

Epoch: 5| Step: 1
Training loss: 1.2480473518371582
Validation loss: 2.0418118123085267

Epoch: 5| Step: 2
Training loss: 1.2128194570541382
Validation loss: 2.0373404513123217

Epoch: 5| Step: 3
Training loss: 1.820478081703186
Validation loss: 2.0842547519232637

Epoch: 5| Step: 4
Training loss: 0.9686548113822937
Validation loss: 1.968319437837088

Epoch: 5| Step: 5
Training loss: 1.8574192523956299
Validation loss: 2.043684244155884

Epoch: 5| Step: 6
Training loss: 1.302841067314148
Validation loss: 2.044773926017105

Epoch: 5| Step: 7
Training loss: 1.4439260959625244
Validation loss: 2.1321466911223625

Epoch: 5| Step: 8
Training loss: 1.5770747661590576
Validation loss: 2.05439926731971

Epoch: 5| Step: 9
Training loss: 0.9396932721138
Validation loss: 2.0722445082920853

Epoch: 5| Step: 10
Training loss: 1.5319359302520752
Validation loss: 2.1297277378779587

Epoch: 629| Step: 0
Training loss: 1.9239813089370728
Validation loss: 2.052949989995649

Epoch: 5| Step: 1
Training loss: 1.4155395030975342
Validation loss: 1.97905449328884

Epoch: 5| Step: 2
Training loss: 1.3303521871566772
Validation loss: 2.0113890017232587

Epoch: 5| Step: 3
Training loss: 2.366973876953125
Validation loss: 2.1034728301468717

Epoch: 5| Step: 4
Training loss: 1.6957803964614868
Validation loss: 2.1286654241623415

Epoch: 5| Step: 5
Training loss: 1.2816768884658813
Validation loss: 2.1098421491602415

Epoch: 5| Step: 6
Training loss: 0.9625660181045532
Validation loss: 2.0312468672311432

Epoch: 5| Step: 7
Training loss: 1.3620197772979736
Validation loss: 2.0626371970740696

Epoch: 5| Step: 8
Training loss: 1.3340619802474976
Validation loss: 2.0776920292967107

Epoch: 5| Step: 9
Training loss: 1.332633376121521
Validation loss: 2.1211426822088097

Epoch: 5| Step: 10
Training loss: 1.0400197505950928
Validation loss: 2.0306089257681244

Epoch: 630| Step: 0
Training loss: 1.336667776107788
Validation loss: 1.9456607910894579

Epoch: 5| Step: 1
Training loss: 1.2555633783340454
Validation loss: 2.06383619769927

Epoch: 5| Step: 2
Training loss: 1.4859416484832764
Validation loss: 2.0963044269110567

Epoch: 5| Step: 3
Training loss: 1.4498506784439087
Validation loss: 2.0535883621502946

Epoch: 5| Step: 4
Training loss: 1.1754415035247803
Validation loss: 2.0700388800713325

Epoch: 5| Step: 5
Training loss: 2.264552354812622
Validation loss: 2.1440314862035934

Epoch: 5| Step: 6
Training loss: 1.4251536130905151
Validation loss: 2.0657093166023173

Epoch: 5| Step: 7
Training loss: 1.2828670740127563
Validation loss: 2.0746264893521547

Epoch: 5| Step: 8
Training loss: 1.3575643301010132
Validation loss: 2.0397753715515137

Epoch: 5| Step: 9
Training loss: 1.3631222248077393
Validation loss: 2.1485292783347507

Epoch: 5| Step: 10
Training loss: 1.4986101388931274
Validation loss: 2.00401908095165

Epoch: 631| Step: 0
Training loss: 1.5563573837280273
Validation loss: 2.0390475949933453

Epoch: 5| Step: 1
Training loss: 0.9496347308158875
Validation loss: 2.132606299974585

Epoch: 5| Step: 2
Training loss: 1.407710313796997
Validation loss: 2.1296258126535723

Epoch: 5| Step: 3
Training loss: 1.0617254972457886
Validation loss: 2.0884172121683755

Epoch: 5| Step: 4
Training loss: 1.3618896007537842
Validation loss: 2.100561084285859

Epoch: 5| Step: 5
Training loss: 1.6593071222305298
Validation loss: 2.06008925232836

Epoch: 5| Step: 6
Training loss: 1.5617080926895142
Validation loss: 2.0180996079598703

Epoch: 5| Step: 7
Training loss: 1.5608869791030884
Validation loss: 2.077649049861457

Epoch: 5| Step: 8
Training loss: 1.9231462478637695
Validation loss: 2.0759425214541856

Epoch: 5| Step: 9
Training loss: 1.8347294330596924
Validation loss: 2.0545168371610742

Epoch: 5| Step: 10
Training loss: 1.5247881412506104
Validation loss: 2.0021973604797036

Epoch: 632| Step: 0
Training loss: 1.2356784343719482
Validation loss: 2.0450805400007512

Epoch: 5| Step: 1
Training loss: 1.801661729812622
Validation loss: 1.9193332682373703

Epoch: 5| Step: 2
Training loss: 1.8423049449920654
Validation loss: 2.058639775040329

Epoch: 5| Step: 3
Training loss: 1.8636109828948975
Validation loss: 2.1260362350812523

Epoch: 5| Step: 4
Training loss: 1.4576795101165771
Validation loss: 2.0188515775947162

Epoch: 5| Step: 5
Training loss: 1.0780918598175049
Validation loss: 2.020909570878552

Epoch: 5| Step: 6
Training loss: 1.6640207767486572
Validation loss: 2.131012770437425

Epoch: 5| Step: 7
Training loss: 1.1617310047149658
Validation loss: 2.0886009303472375

Epoch: 5| Step: 8
Training loss: 1.1730159521102905
Validation loss: 2.030878693826737

Epoch: 5| Step: 9
Training loss: 1.542328953742981
Validation loss: 2.0739082469735095

Epoch: 5| Step: 10
Training loss: 1.1014320850372314
Validation loss: 2.046978376244986

Epoch: 633| Step: 0
Training loss: 1.4113118648529053
Validation loss: 2.0777202062709357

Epoch: 5| Step: 1
Training loss: 1.4080898761749268
Validation loss: 2.075746695200602

Epoch: 5| Step: 2
Training loss: 1.5346935987472534
Validation loss: 2.1244947038671023

Epoch: 5| Step: 3
Training loss: 1.6359037160873413
Validation loss: 2.1023481212636477

Epoch: 5| Step: 4
Training loss: 1.2692664861679077
Validation loss: 2.0889664234653598

Epoch: 5| Step: 5
Training loss: 2.1334033012390137
Validation loss: 2.0700478630681194

Epoch: 5| Step: 6
Training loss: 1.5274277925491333
Validation loss: 2.0467646391161027

Epoch: 5| Step: 7
Training loss: 1.5175944566726685
Validation loss: 2.0659476390448948

Epoch: 5| Step: 8
Training loss: 1.135574460029602
Validation loss: 2.057650534055566

Epoch: 5| Step: 9
Training loss: 1.4383578300476074
Validation loss: 2.03432422684085

Epoch: 5| Step: 10
Training loss: 1.0383380651474
Validation loss: 2.076152681022562

Epoch: 634| Step: 0
Training loss: 0.9788699150085449
Validation loss: 1.9749288328232304

Epoch: 5| Step: 1
Training loss: 1.1707779169082642
Validation loss: 1.9843178641411565

Epoch: 5| Step: 2
Training loss: 1.2611896991729736
Validation loss: 1.988689563607657

Epoch: 5| Step: 3
Training loss: 1.213341474533081
Validation loss: 2.102535358039282

Epoch: 5| Step: 4
Training loss: 1.9058698415756226
Validation loss: 1.9941219296506656

Epoch: 5| Step: 5
Training loss: 1.8227039575576782
Validation loss: 2.121345712292579

Epoch: 5| Step: 6
Training loss: 1.2619960308074951
Validation loss: 2.0860653487584924

Epoch: 5| Step: 7
Training loss: 1.5948137044906616
Validation loss: 2.028304308973333

Epoch: 5| Step: 8
Training loss: 1.7938964366912842
Validation loss: 2.081951813031268

Epoch: 5| Step: 9
Training loss: 1.2432230710983276
Validation loss: 2.02976220269357

Epoch: 5| Step: 10
Training loss: 1.9128310680389404
Validation loss: 2.0839886972981114

Epoch: 635| Step: 0
Training loss: 2.0088729858398438
Validation loss: 2.0688073660737727

Epoch: 5| Step: 1
Training loss: 1.2281453609466553
Validation loss: 2.1334081080652054

Epoch: 5| Step: 2
Training loss: 0.8257464170455933
Validation loss: 2.0488865413973407

Epoch: 5| Step: 3
Training loss: 1.5274264812469482
Validation loss: 1.9689694655838834

Epoch: 5| Step: 4
Training loss: 0.90919429063797
Validation loss: 2.011179872738418

Epoch: 5| Step: 5
Training loss: 1.1751543283462524
Validation loss: 1.9355820622495425

Epoch: 5| Step: 6
Training loss: 1.2786080837249756
Validation loss: 2.0807192787047355

Epoch: 5| Step: 7
Training loss: 2.073641538619995
Validation loss: 2.063880943482922

Epoch: 5| Step: 8
Training loss: 1.7940456867218018
Validation loss: 1.9762516303728985

Epoch: 5| Step: 9
Training loss: 1.6614410877227783
Validation loss: 2.0884013406692015

Epoch: 5| Step: 10
Training loss: 1.2052515745162964
Validation loss: 1.967553674533803

Epoch: 636| Step: 0
Training loss: 1.702641248703003
Validation loss: 2.0687378362942765

Epoch: 5| Step: 1
Training loss: 1.6460225582122803
Validation loss: 2.06548079880335

Epoch: 5| Step: 2
Training loss: 1.4661047458648682
Validation loss: 1.999548017337758

Epoch: 5| Step: 3
Training loss: 1.3119468688964844
Validation loss: 2.1123455621862925

Epoch: 5| Step: 4
Training loss: 1.6139265298843384
Validation loss: 2.06799707745993

Epoch: 5| Step: 5
Training loss: 1.6292120218276978
Validation loss: 2.029893820003797

Epoch: 5| Step: 6
Training loss: 1.0268614292144775
Validation loss: 2.0369353960919123

Epoch: 5| Step: 7
Training loss: 1.0166743993759155
Validation loss: 1.976447178471473

Epoch: 5| Step: 8
Training loss: 1.3867881298065186
Validation loss: 2.0708017836334887

Epoch: 5| Step: 9
Training loss: 1.2808059453964233
Validation loss: 1.9868266146670106

Epoch: 5| Step: 10
Training loss: 1.3816642761230469
Validation loss: 2.037538304123827

Epoch: 637| Step: 0
Training loss: 2.103179454803467
Validation loss: 1.9791818434192288

Epoch: 5| Step: 1
Training loss: 1.2814544439315796
Validation loss: 2.0328643116899716

Epoch: 5| Step: 2
Training loss: 1.2326565980911255
Validation loss: 2.1032910167530017

Epoch: 5| Step: 3
Training loss: 1.413866639137268
Validation loss: 2.051704865629955

Epoch: 5| Step: 4
Training loss: 1.4175597429275513
Validation loss: 1.979800296086137

Epoch: 5| Step: 5
Training loss: 1.949126958847046
Validation loss: 2.086936625101233

Epoch: 5| Step: 6
Training loss: 1.6193015575408936
Validation loss: 1.9704575692453692

Epoch: 5| Step: 7
Training loss: 1.761357069015503
Validation loss: 2.053738751719075

Epoch: 5| Step: 8
Training loss: 1.3417223691940308
Validation loss: 2.0900701630500054

Epoch: 5| Step: 9
Training loss: 1.1556426286697388
Validation loss: 2.0033647860250166

Epoch: 5| Step: 10
Training loss: 1.2145943641662598
Validation loss: 2.1106840231085338

Epoch: 638| Step: 0
Training loss: 1.3839330673217773
Validation loss: 1.99117366216516

Epoch: 5| Step: 1
Training loss: 1.2765522003173828
Validation loss: 2.018144670353141

Epoch: 5| Step: 2
Training loss: 1.5836507081985474
Validation loss: 2.148792644982697

Epoch: 5| Step: 3
Training loss: 1.7305965423583984
Validation loss: 2.038285243895746

Epoch: 5| Step: 4
Training loss: 1.7967274188995361
Validation loss: 1.9956508772347563

Epoch: 5| Step: 5
Training loss: 1.6368011236190796
Validation loss: 1.981157027265077

Epoch: 5| Step: 6
Training loss: 1.2079732418060303
Validation loss: 1.984505316262604

Epoch: 5| Step: 7
Training loss: 1.1170912981033325
Validation loss: 2.0349276988737044

Epoch: 5| Step: 8
Training loss: 1.0651992559432983
Validation loss: 2.0763729977351364

Epoch: 5| Step: 9
Training loss: 1.7672011852264404
Validation loss: 2.005385378355621

Epoch: 5| Step: 10
Training loss: 1.3350383043289185
Validation loss: 2.0416553943387923

Epoch: 639| Step: 0
Training loss: 1.2570946216583252
Validation loss: 2.0672623854811474

Epoch: 5| Step: 1
Training loss: 1.5562167167663574
Validation loss: 2.095261827591927

Epoch: 5| Step: 2
Training loss: 1.6104624271392822
Validation loss: 2.1164287854266424

Epoch: 5| Step: 3
Training loss: 1.4541962146759033
Validation loss: 2.114140846396005

Epoch: 5| Step: 4
Training loss: 1.4524877071380615
Validation loss: 2.050887559049873

Epoch: 5| Step: 5
Training loss: 1.4506003856658936
Validation loss: 2.0637024269309094

Epoch: 5| Step: 6
Training loss: 1.3275115489959717
Validation loss: 2.187097531492992

Epoch: 5| Step: 7
Training loss: 1.7071590423583984
Validation loss: 2.0443175967021654

Epoch: 5| Step: 8
Training loss: 1.274268388748169
Validation loss: 2.2408886391629457

Epoch: 5| Step: 9
Training loss: 1.2668209075927734
Validation loss: 2.0627841026552263

Epoch: 5| Step: 10
Training loss: 1.7136871814727783
Validation loss: 1.9470659455945414

Epoch: 640| Step: 0
Training loss: 1.262741208076477
Validation loss: 2.0161649591179303

Epoch: 5| Step: 1
Training loss: 1.176772117614746
Validation loss: 2.0289596678108297

Epoch: 5| Step: 2
Training loss: 2.2357335090637207
Validation loss: 2.0190645443495883

Epoch: 5| Step: 3
Training loss: 0.9809218645095825
Validation loss: 2.067835025889899

Epoch: 5| Step: 4
Training loss: 1.4860035181045532
Validation loss: 1.9836764617632794

Epoch: 5| Step: 5
Training loss: 1.6077255010604858
Validation loss: 2.002976576487223

Epoch: 5| Step: 6
Training loss: 1.6281951665878296
Validation loss: 2.0421340080999557

Epoch: 5| Step: 7
Training loss: 1.4247629642486572
Validation loss: 1.980328506039035

Epoch: 5| Step: 8
Training loss: 1.5521628856658936
Validation loss: 2.067886603775845

Epoch: 5| Step: 9
Training loss: 1.253429889678955
Validation loss: 2.0086035023453417

Epoch: 5| Step: 10
Training loss: 1.3744308948516846
Validation loss: 2.0161599689914333

Epoch: 641| Step: 0
Training loss: 1.6405162811279297
Validation loss: 2.12457626353028

Epoch: 5| Step: 1
Training loss: 1.5136687755584717
Validation loss: 2.08276540745971

Epoch: 5| Step: 2
Training loss: 1.6190803050994873
Validation loss: 2.111603775332051

Epoch: 5| Step: 3
Training loss: 1.7695070505142212
Validation loss: 2.0192374721650155

Epoch: 5| Step: 4
Training loss: 1.3469669818878174
Validation loss: 2.0493727550711682

Epoch: 5| Step: 5
Training loss: 1.3006588220596313
Validation loss: 2.0260169531709407

Epoch: 5| Step: 6
Training loss: 1.3919442892074585
Validation loss: 2.040920880533034

Epoch: 5| Step: 7
Training loss: 1.1568711996078491
Validation loss: 2.1193755775369625

Epoch: 5| Step: 8
Training loss: 1.539867639541626
Validation loss: 2.046488756774574

Epoch: 5| Step: 9
Training loss: 1.4168057441711426
Validation loss: 2.0824267454044794

Epoch: 5| Step: 10
Training loss: 1.564121961593628
Validation loss: 2.02436335368823

Epoch: 642| Step: 0
Training loss: 1.9177109003067017
Validation loss: 1.99169078693595

Epoch: 5| Step: 1
Training loss: 1.4730851650238037
Validation loss: 1.942083635637837

Epoch: 5| Step: 2
Training loss: 1.1851747035980225
Validation loss: 2.0458841836580666

Epoch: 5| Step: 3
Training loss: 1.238331913948059
Validation loss: 2.060555511905301

Epoch: 5| Step: 4
Training loss: 1.6968482732772827
Validation loss: 2.025938162239649

Epoch: 5| Step: 5
Training loss: 1.1610891819000244
Validation loss: 1.9911456851549045

Epoch: 5| Step: 6
Training loss: 1.4075711965560913
Validation loss: 2.1550032272133777

Epoch: 5| Step: 7
Training loss: 1.4153733253479004
Validation loss: 2.039987566650555

Epoch: 5| Step: 8
Training loss: 1.6107378005981445
Validation loss: 2.019937853659353

Epoch: 5| Step: 9
Training loss: 1.3553625345230103
Validation loss: 2.1102492655477216

Epoch: 5| Step: 10
Training loss: 1.608993411064148
Validation loss: 2.120460278244429

Epoch: 643| Step: 0
Training loss: 1.522586464881897
Validation loss: 2.064905453753728

Epoch: 5| Step: 1
Training loss: 2.51121187210083
Validation loss: 2.1261797348658242

Epoch: 5| Step: 2
Training loss: 1.0422576665878296
Validation loss: 2.054576068796137

Epoch: 5| Step: 3
Training loss: 1.1799485683441162
Validation loss: 2.0657154667762017

Epoch: 5| Step: 4
Training loss: 1.3908907175064087
Validation loss: 1.947922009293751

Epoch: 5| Step: 5
Training loss: 1.4360768795013428
Validation loss: 2.070512297332928

Epoch: 5| Step: 6
Training loss: 1.429297685623169
Validation loss: 1.9490431944529216

Epoch: 5| Step: 7
Training loss: 1.4073965549468994
Validation loss: 2.1619957108651437

Epoch: 5| Step: 8
Training loss: 1.0620810985565186
Validation loss: 2.1252524006751274

Epoch: 5| Step: 9
Training loss: 0.9876035451889038
Validation loss: 2.0715661920526975

Epoch: 5| Step: 10
Training loss: 1.6563159227371216
Validation loss: 2.0753457520597722

Epoch: 644| Step: 0
Training loss: 1.0156301259994507
Validation loss: 2.1323474684069232

Epoch: 5| Step: 1
Training loss: 1.5887792110443115
Validation loss: 2.018075253373833

Epoch: 5| Step: 2
Training loss: 1.4660592079162598
Validation loss: 2.1100966404843073

Epoch: 5| Step: 3
Training loss: 1.7197644710540771
Validation loss: 2.16563743416981

Epoch: 5| Step: 4
Training loss: 1.4496171474456787
Validation loss: 2.066899193230496

Epoch: 5| Step: 5
Training loss: 1.6879554986953735
Validation loss: 2.0748521256190475

Epoch: 5| Step: 6
Training loss: 1.176844596862793
Validation loss: 2.06700970280555

Epoch: 5| Step: 7
Training loss: 0.9117898941040039
Validation loss: 2.0824207721217984

Epoch: 5| Step: 8
Training loss: 1.7190910577774048
Validation loss: 2.1018542076951716

Epoch: 5| Step: 9
Training loss: 1.9234731197357178
Validation loss: 2.098014775142875

Epoch: 5| Step: 10
Training loss: 1.036879062652588
Validation loss: 2.170975172391502

Epoch: 645| Step: 0
Training loss: 1.237463116645813
Validation loss: 2.0290392701343825

Epoch: 5| Step: 1
Training loss: 1.6543877124786377
Validation loss: 2.0709294375552925

Epoch: 5| Step: 2
Training loss: 1.4534200429916382
Validation loss: 2.0307312703901723

Epoch: 5| Step: 3
Training loss: 1.46056067943573
Validation loss: 1.9791868527730305

Epoch: 5| Step: 4
Training loss: 1.3790252208709717
Validation loss: 2.060801689342786

Epoch: 5| Step: 5
Training loss: 1.4047048091888428
Validation loss: 2.1289793445217993

Epoch: 5| Step: 6
Training loss: 1.3762439489364624
Validation loss: 1.9907185249431159

Epoch: 5| Step: 7
Training loss: 1.4607301950454712
Validation loss: 1.984514879923995

Epoch: 5| Step: 8
Training loss: 1.4234850406646729
Validation loss: 2.060896097972829

Epoch: 5| Step: 9
Training loss: 1.3125908374786377
Validation loss: 2.0651582620477162

Epoch: 5| Step: 10
Training loss: 1.9280970096588135
Validation loss: 2.0806759044688237

Epoch: 646| Step: 0
Training loss: 1.7091163396835327
Validation loss: 2.1144292739129837

Epoch: 5| Step: 1
Training loss: 1.4277141094207764
Validation loss: 2.101224822382773

Epoch: 5| Step: 2
Training loss: 1.0097148418426514
Validation loss: 2.017098364009652

Epoch: 5| Step: 3
Training loss: 1.9678863286972046
Validation loss: 2.0199937000069568

Epoch: 5| Step: 4
Training loss: 1.6878725290298462
Validation loss: 2.1722955139734412

Epoch: 5| Step: 5
Training loss: 0.9681280851364136
Validation loss: 2.122365249100552

Epoch: 5| Step: 6
Training loss: 1.8459193706512451
Validation loss: 2.17126041330317

Epoch: 5| Step: 7
Training loss: 1.2401378154754639
Validation loss: 2.0878214989939043

Epoch: 5| Step: 8
Training loss: 1.393824815750122
Validation loss: 2.1268495257182787

Epoch: 5| Step: 9
Training loss: 1.5623562335968018
Validation loss: 2.0672521642459336

Epoch: 5| Step: 10
Training loss: 0.7692580223083496
Validation loss: 2.06228837402918

Epoch: 647| Step: 0
Training loss: 1.1213104724884033
Validation loss: 2.049512791377242

Epoch: 5| Step: 1
Training loss: 1.1180633306503296
Validation loss: 2.0599210467389835

Epoch: 5| Step: 2
Training loss: 1.303885817527771
Validation loss: 2.0221122195643764

Epoch: 5| Step: 3
Training loss: 2.3382480144500732
Validation loss: 1.958763458395517

Epoch: 5| Step: 4
Training loss: 1.590102195739746
Validation loss: 1.9980006640957249

Epoch: 5| Step: 5
Training loss: 1.258202314376831
Validation loss: 2.0604335646475516

Epoch: 5| Step: 6
Training loss: 1.0273154973983765
Validation loss: 2.0330853487855647

Epoch: 5| Step: 7
Training loss: 1.5027424097061157
Validation loss: 1.9823915240585164

Epoch: 5| Step: 8
Training loss: 1.2995754480361938
Validation loss: 2.04968197243188

Epoch: 5| Step: 9
Training loss: 1.7542078495025635
Validation loss: 2.0414714915778047

Epoch: 5| Step: 10
Training loss: 1.6206159591674805
Validation loss: 1.9809824792287682

Epoch: 648| Step: 0
Training loss: 1.3220783472061157
Validation loss: 1.9599183118471535

Epoch: 5| Step: 1
Training loss: 1.342161774635315
Validation loss: 2.0959839820861816

Epoch: 5| Step: 2
Training loss: 1.8791797161102295
Validation loss: 1.9437859263471378

Epoch: 5| Step: 3
Training loss: 1.5915006399154663
Validation loss: 2.0665438200837825

Epoch: 5| Step: 4
Training loss: 0.7692301869392395
Validation loss: 2.06900478178455

Epoch: 5| Step: 5
Training loss: 1.885972023010254
Validation loss: 2.068166585378749

Epoch: 5| Step: 6
Training loss: 1.517003059387207
Validation loss: 2.0170858572888117

Epoch: 5| Step: 7
Training loss: 1.3054072856903076
Validation loss: 1.950391387426725

Epoch: 5| Step: 8
Training loss: 1.0904872417449951
Validation loss: 2.0720500279498357

Epoch: 5| Step: 9
Training loss: 1.557282567024231
Validation loss: 2.124306155789283

Epoch: 5| Step: 10
Training loss: 1.4434294700622559
Validation loss: 2.085421710885981

Epoch: 649| Step: 0
Training loss: 1.4716287851333618
Validation loss: 2.202488330102736

Epoch: 5| Step: 1
Training loss: 1.2542637586593628
Validation loss: 2.1056832254573865

Epoch: 5| Step: 2
Training loss: 1.065964937210083
Validation loss: 2.037473537588632

Epoch: 5| Step: 3
Training loss: 1.9688822031021118
Validation loss: 2.0064435107733614

Epoch: 5| Step: 4
Training loss: 1.707511305809021
Validation loss: 2.045913709107266

Epoch: 5| Step: 5
Training loss: 1.291473388671875
Validation loss: 1.9659368350941648

Epoch: 5| Step: 6
Training loss: 2.099888324737549
Validation loss: 2.0379754548431723

Epoch: 5| Step: 7
Training loss: 1.3825373649597168
Validation loss: 2.1390387909386748

Epoch: 5| Step: 8
Training loss: 1.5794870853424072
Validation loss: 2.0631016967117146

Epoch: 5| Step: 9
Training loss: 1.4450129270553589
Validation loss: 2.028323483723466

Epoch: 5| Step: 10
Training loss: 1.1388006210327148
Validation loss: 2.0364268325990245

Epoch: 650| Step: 0
Training loss: 1.2487061023712158
Validation loss: 1.914053169629907

Epoch: 5| Step: 1
Training loss: 1.4026200771331787
Validation loss: 1.9564494932851484

Epoch: 5| Step: 2
Training loss: 1.8079090118408203
Validation loss: 1.977709065201462

Epoch: 5| Step: 3
Training loss: 1.7491276264190674
Validation loss: 2.0026431596407326

Epoch: 5| Step: 4
Training loss: 1.44378662109375
Validation loss: 2.0797159415419384

Epoch: 5| Step: 5
Training loss: 1.3407241106033325
Validation loss: 2.0277811211924397

Epoch: 5| Step: 6
Training loss: 1.3070707321166992
Validation loss: 2.1223297067867812

Epoch: 5| Step: 7
Training loss: 1.651724100112915
Validation loss: 2.02539457813386

Epoch: 5| Step: 8
Training loss: 0.862169086933136
Validation loss: 2.0952587845504924

Epoch: 5| Step: 9
Training loss: 1.383603811264038
Validation loss: 2.0806892738547376

Epoch: 5| Step: 10
Training loss: 1.2970792055130005
Validation loss: 2.0677149539352744

Testing loss: 1.9895158741209242
