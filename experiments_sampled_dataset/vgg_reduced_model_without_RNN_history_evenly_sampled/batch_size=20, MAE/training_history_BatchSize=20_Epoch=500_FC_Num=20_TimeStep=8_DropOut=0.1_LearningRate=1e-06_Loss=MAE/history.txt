Epoch: 1| Step: 0
Training loss: 3.5718274116516113
Validation loss: 2.9348857530983548

Epoch: 5| Step: 1
Training loss: 3.181619644165039
Validation loss: 2.9317812611979823

Epoch: 5| Step: 2
Training loss: 2.9307703971862793
Validation loss: 2.9309533308911067

Epoch: 5| Step: 3
Training loss: 3.475682020187378
Validation loss: 2.927413050846387

Epoch: 5| Step: 4
Training loss: 2.4350974559783936
Validation loss: 2.925292771349671

Epoch: 5| Step: 5
Training loss: 2.404021978378296
Validation loss: 2.9233646239003828

Epoch: 5| Step: 6
Training loss: 2.267677068710327
Validation loss: 2.9209920462741645

Epoch: 5| Step: 7
Training loss: 3.7603492736816406
Validation loss: 2.9188970955469276

Epoch: 5| Step: 8
Training loss: 3.3636879920959473
Validation loss: 2.916573835957435

Epoch: 5| Step: 9
Training loss: 2.7116360664367676
Validation loss: 2.9145866876007407

Epoch: 5| Step: 10
Training loss: 3.102137804031372
Validation loss: 2.9141357201401905

Epoch: 2| Step: 0
Training loss: 2.8388283252716064
Validation loss: 2.9122833333989626

Epoch: 5| Step: 1
Training loss: 3.0030481815338135
Validation loss: 2.906259811052712

Epoch: 5| Step: 2
Training loss: 2.893279552459717
Validation loss: 2.9057769621572187

Epoch: 5| Step: 3
Training loss: 3.4784882068634033
Validation loss: 2.9046520443372827

Epoch: 5| Step: 4
Training loss: 3.114701271057129
Validation loss: 2.9022304729748796

Epoch: 5| Step: 5
Training loss: 3.050899028778076
Validation loss: 2.9016918828410487

Epoch: 5| Step: 6
Training loss: 3.607344150543213
Validation loss: 2.897472950720018

Epoch: 5| Step: 7
Training loss: 3.022730588912964
Validation loss: 2.8968522138493036

Epoch: 5| Step: 8
Training loss: 2.525625228881836
Validation loss: 2.8958673784809728

Epoch: 5| Step: 9
Training loss: 2.4598982334136963
Validation loss: 2.893344115185481

Epoch: 5| Step: 10
Training loss: 3.0359740257263184
Validation loss: 2.890955017459008

Epoch: 3| Step: 0
Training loss: 2.7469661235809326
Validation loss: 2.8903586300470496

Epoch: 5| Step: 1
Training loss: 3.105825185775757
Validation loss: 2.8901073496828795

Epoch: 5| Step: 2
Training loss: 2.381749391555786
Validation loss: 2.8835183548670944

Epoch: 5| Step: 3
Training loss: 2.5328292846679688
Validation loss: 2.884833966532061

Epoch: 5| Step: 4
Training loss: 3.416506290435791
Validation loss: 2.882227954044137

Epoch: 5| Step: 5
Training loss: 3.7040069103240967
Validation loss: 2.8809225584871028

Epoch: 5| Step: 6
Training loss: 2.5575945377349854
Validation loss: 2.876636476926906

Epoch: 5| Step: 7
Training loss: 3.522451400756836
Validation loss: 2.8772318875917824

Epoch: 5| Step: 8
Training loss: 3.0292916297912598
Validation loss: 2.8728811330692743

Epoch: 5| Step: 9
Training loss: 2.863537549972534
Validation loss: 2.8703856263109433

Epoch: 5| Step: 10
Training loss: 2.9921910762786865
Validation loss: 2.8724249434727493

Epoch: 4| Step: 0
Training loss: 2.95354962348938
Validation loss: 2.8697199975290606

Epoch: 5| Step: 1
Training loss: 3.0712060928344727
Validation loss: 2.8665845291588896

Epoch: 5| Step: 2
Training loss: 3.139801025390625
Validation loss: 2.863754964643909

Epoch: 5| Step: 3
Training loss: 3.365880250930786
Validation loss: 2.8631600538889566

Epoch: 5| Step: 4
Training loss: 3.3581089973449707
Validation loss: 2.8588736288009153

Epoch: 5| Step: 5
Training loss: 2.234241008758545
Validation loss: 2.859428721089517

Epoch: 5| Step: 6
Training loss: 2.7833054065704346
Validation loss: 2.855927974947037

Epoch: 5| Step: 7
Training loss: 2.6981475353240967
Validation loss: 2.8553228557750745

Epoch: 5| Step: 8
Training loss: 3.456963300704956
Validation loss: 2.852788499606553

Epoch: 5| Step: 9
Training loss: 3.3302078247070312
Validation loss: 2.8514871546017226

Epoch: 5| Step: 10
Training loss: 2.18933367729187
Validation loss: 2.8478596595025834

Epoch: 5| Step: 0
Training loss: 2.629451274871826
Validation loss: 2.8477016674574984

Epoch: 5| Step: 1
Training loss: 2.4724578857421875
Validation loss: 2.844981262760778

Epoch: 5| Step: 2
Training loss: 2.562530040740967
Validation loss: 2.8416992490009596

Epoch: 5| Step: 3
Training loss: 2.903237819671631
Validation loss: 2.841267598572598

Epoch: 5| Step: 4
Training loss: 2.925240993499756
Validation loss: 2.83906913060014

Epoch: 5| Step: 5
Training loss: 3.045959949493408
Validation loss: 2.8375540574391684

Epoch: 5| Step: 6
Training loss: 3.5318005084991455
Validation loss: 2.834762445060156

Epoch: 5| Step: 7
Training loss: 2.7357826232910156
Validation loss: 2.833487859336279

Epoch: 5| Step: 8
Training loss: 3.429297685623169
Validation loss: 2.831061360656574

Epoch: 5| Step: 9
Training loss: 3.0435593128204346
Validation loss: 2.8294290086274505

Epoch: 5| Step: 10
Training loss: 3.2621140480041504
Validation loss: 2.8259505584675777

Epoch: 6| Step: 0
Training loss: 3.3012306690216064
Validation loss: 2.8265842186507357

Epoch: 5| Step: 1
Training loss: 2.840167760848999
Validation loss: 2.825182491733182

Epoch: 5| Step: 2
Training loss: 2.892789363861084
Validation loss: 2.8188199330401678

Epoch: 5| Step: 3
Training loss: 3.153071403503418
Validation loss: 2.8165690257985103

Epoch: 5| Step: 4
Training loss: 2.858097553253174
Validation loss: 2.8152389885276876

Epoch: 5| Step: 5
Training loss: 3.0612096786499023
Validation loss: 2.813618149808658

Epoch: 5| Step: 6
Training loss: 1.7741702795028687
Validation loss: 2.8125359089143815

Epoch: 5| Step: 7
Training loss: 3.1150877475738525
Validation loss: 2.8098991968298472

Epoch: 5| Step: 8
Training loss: 3.2913334369659424
Validation loss: 2.805915927374235

Epoch: 5| Step: 9
Training loss: 2.701850652694702
Validation loss: 2.804567201163179

Epoch: 5| Step: 10
Training loss: 3.432790756225586
Validation loss: 2.801337339544809

Epoch: 7| Step: 0
Training loss: 2.610776662826538
Validation loss: 2.7998933587023007

Epoch: 5| Step: 1
Training loss: 2.387908697128296
Validation loss: 2.7966939505710395

Epoch: 5| Step: 2
Training loss: 3.1761722564697266
Validation loss: 2.7964168338365454

Epoch: 5| Step: 3
Training loss: 2.314391851425171
Validation loss: 2.7935701083111506

Epoch: 5| Step: 4
Training loss: 2.6731691360473633
Validation loss: 2.7897666090278217

Epoch: 5| Step: 5
Training loss: 2.3444950580596924
Validation loss: 2.7916986275744695

Epoch: 5| Step: 6
Training loss: 3.4096083641052246
Validation loss: 2.7882941487014934

Epoch: 5| Step: 7
Training loss: 3.326249599456787
Validation loss: 2.7863877665612007

Epoch: 5| Step: 8
Training loss: 4.199082374572754
Validation loss: 2.7837517415323565

Epoch: 5| Step: 9
Training loss: 2.59444260597229
Validation loss: 2.7785284237195085

Epoch: 5| Step: 10
Training loss: 3.1169629096984863
Validation loss: 2.7782632215048677

Epoch: 8| Step: 0
Training loss: 2.6564290523529053
Validation loss: 2.7737706245914584

Epoch: 5| Step: 1
Training loss: 3.039693593978882
Validation loss: 2.7740200745162142

Epoch: 5| Step: 2
Training loss: 2.9093568325042725
Validation loss: 2.771705524895781

Epoch: 5| Step: 3
Training loss: 2.8880364894866943
Validation loss: 2.7657051547881095

Epoch: 5| Step: 4
Training loss: 3.099976062774658
Validation loss: 2.7659793412813576

Epoch: 5| Step: 5
Training loss: 3.0239429473876953
Validation loss: 2.7602796708383868

Epoch: 5| Step: 6
Training loss: 2.783508777618408
Validation loss: 2.757629309931109

Epoch: 5| Step: 7
Training loss: 3.2968201637268066
Validation loss: 2.7568347402798232

Epoch: 5| Step: 8
Training loss: 2.5302493572235107
Validation loss: 2.752790274158601

Epoch: 5| Step: 9
Training loss: 2.9643771648406982
Validation loss: 2.7505630011199624

Epoch: 5| Step: 10
Training loss: 2.705454111099243
Validation loss: 2.7448878903542795

Epoch: 9| Step: 0
Training loss: 3.060126781463623
Validation loss: 2.74518149129806

Epoch: 5| Step: 1
Training loss: 2.843841075897217
Validation loss: 2.739935831357074

Epoch: 5| Step: 2
Training loss: 2.84989333152771
Validation loss: 2.737686718663862

Epoch: 5| Step: 3
Training loss: 2.9835586547851562
Validation loss: 2.7348887843470417

Epoch: 5| Step: 4
Training loss: 3.4500198364257812
Validation loss: 2.732564708238007

Epoch: 5| Step: 5
Training loss: 2.402374744415283
Validation loss: 2.7300411834511706

Epoch: 5| Step: 6
Training loss: 2.6060619354248047
Validation loss: 2.72497744201332

Epoch: 5| Step: 7
Training loss: 2.918064594268799
Validation loss: 2.720125534201181

Epoch: 5| Step: 8
Training loss: 2.7728447914123535
Validation loss: 2.721027417849469

Epoch: 5| Step: 9
Training loss: 2.6462254524230957
Validation loss: 2.7140083159169843

Epoch: 5| Step: 10
Training loss: 3.220951795578003
Validation loss: 2.712102151686145

Epoch: 10| Step: 0
Training loss: 3.0733516216278076
Validation loss: 2.708317202906455

Epoch: 5| Step: 1
Training loss: 2.0921216011047363
Validation loss: 2.707141166092247

Epoch: 5| Step: 2
Training loss: 2.987560987472534
Validation loss: 2.70581583053835

Epoch: 5| Step: 3
Training loss: 2.609253168106079
Validation loss: 2.7019022049442416

Epoch: 5| Step: 4
Training loss: 2.2664332389831543
Validation loss: 2.694779098674815

Epoch: 5| Step: 5
Training loss: 2.274188280105591
Validation loss: 2.696799960187686

Epoch: 5| Step: 6
Training loss: 2.1452529430389404
Validation loss: 2.6906512680874077

Epoch: 5| Step: 7
Training loss: 3.587416172027588
Validation loss: 2.6887364374694003

Epoch: 5| Step: 8
Training loss: 3.5449225902557373
Validation loss: 2.686312654966949

Epoch: 5| Step: 9
Training loss: 3.346607208251953
Validation loss: 2.683049478838521

Epoch: 5| Step: 10
Training loss: 3.604471206665039
Validation loss: 2.6779087615269486

Epoch: 11| Step: 0
Training loss: 3.0534000396728516
Validation loss: 2.672495029305899

Epoch: 5| Step: 1
Training loss: 3.2747364044189453
Validation loss: 2.6709840451517413

Epoch: 5| Step: 2
Training loss: 2.828286647796631
Validation loss: 2.6680292467917166

Epoch: 5| Step: 3
Training loss: 2.9042556285858154
Validation loss: 2.665638013552594

Epoch: 5| Step: 4
Training loss: 3.294595241546631
Validation loss: 2.660376223184729

Epoch: 5| Step: 5
Training loss: 2.7232677936553955
Validation loss: 2.6548768320391254

Epoch: 5| Step: 6
Training loss: 2.2550601959228516
Validation loss: 2.6479935235874628

Epoch: 5| Step: 7
Training loss: 2.8786072731018066
Validation loss: 2.6433724587963474

Epoch: 5| Step: 8
Training loss: 2.3106837272644043
Validation loss: 2.64344387156989

Epoch: 5| Step: 9
Training loss: 2.990767002105713
Validation loss: 2.634840355124525

Epoch: 5| Step: 10
Training loss: 2.598055362701416
Validation loss: 2.633643845076202

Epoch: 12| Step: 0
Training loss: 2.4461095333099365
Validation loss: 2.6282929887053785

Epoch: 5| Step: 1
Training loss: 1.9200729131698608
Validation loss: 2.6287686440252487

Epoch: 5| Step: 2
Training loss: 2.7358944416046143
Validation loss: 2.6172128723513697

Epoch: 5| Step: 3
Training loss: 3.3656253814697266
Validation loss: 2.6171709183723695

Epoch: 5| Step: 4
Training loss: 3.517058849334717
Validation loss: 2.6106632063465733

Epoch: 5| Step: 5
Training loss: 2.5160555839538574
Validation loss: 2.6045590216113674

Epoch: 5| Step: 6
Training loss: 2.359154224395752
Validation loss: 2.6006094307027836

Epoch: 5| Step: 7
Training loss: 2.9629392623901367
Validation loss: 2.598848371095555

Epoch: 5| Step: 8
Training loss: 3.1728713512420654
Validation loss: 2.5959323580547045

Epoch: 5| Step: 9
Training loss: 3.226332902908325
Validation loss: 2.5905572214434223

Epoch: 5| Step: 10
Training loss: 2.533838987350464
Validation loss: 2.5825442908912577

Epoch: 13| Step: 0
Training loss: 2.931551218032837
Validation loss: 2.5804384677640853

Epoch: 5| Step: 1
Training loss: 2.6874709129333496
Validation loss: 2.5762489970012377

Epoch: 5| Step: 2
Training loss: 2.0590946674346924
Validation loss: 2.5699122772421887

Epoch: 5| Step: 3
Training loss: 2.672510862350464
Validation loss: 2.5684186771351802

Epoch: 5| Step: 4
Training loss: 1.9801552295684814
Validation loss: 2.564381527644332

Epoch: 5| Step: 5
Training loss: 3.0122530460357666
Validation loss: 2.5571879340756323

Epoch: 5| Step: 6
Training loss: 3.7881436347961426
Validation loss: 2.557723335040513

Epoch: 5| Step: 7
Training loss: 2.873244047164917
Validation loss: 2.555583287310857

Epoch: 5| Step: 8
Training loss: 3.326977252960205
Validation loss: 2.5492060440842823

Epoch: 5| Step: 9
Training loss: 2.510890245437622
Validation loss: 2.5454007912707586

Epoch: 5| Step: 10
Training loss: 2.5478429794311523
Validation loss: 2.538370939993089

Epoch: 14| Step: 0
Training loss: 2.710207462310791
Validation loss: 2.533066018935173

Epoch: 5| Step: 1
Training loss: 3.6585373878479004
Validation loss: 2.5306126392015846

Epoch: 5| Step: 2
Training loss: 2.866880416870117
Validation loss: 2.5222828080577235

Epoch: 5| Step: 3
Training loss: 2.4297537803649902
Validation loss: 2.5186564512150262

Epoch: 5| Step: 4
Training loss: 2.36456298828125
Validation loss: 2.5139643248691352

Epoch: 5| Step: 5
Training loss: 2.6937050819396973
Validation loss: 2.5097041719703266

Epoch: 5| Step: 6
Training loss: 3.0287070274353027
Validation loss: 2.505722133062219

Epoch: 5| Step: 7
Training loss: 2.514451265335083
Validation loss: 2.4983082509809926

Epoch: 5| Step: 8
Training loss: 2.9581377506256104
Validation loss: 2.4934157581739527

Epoch: 5| Step: 9
Training loss: 2.197833299636841
Validation loss: 2.489117637757332

Epoch: 5| Step: 10
Training loss: 2.6620054244995117
Validation loss: 2.4890623887379966

Epoch: 15| Step: 0
Training loss: 2.4709553718566895
Validation loss: 2.4810829470234532

Epoch: 5| Step: 1
Training loss: 3.148672580718994
Validation loss: 2.475107269902383

Epoch: 5| Step: 2
Training loss: 2.395942211151123
Validation loss: 2.466269446957496

Epoch: 5| Step: 3
Training loss: 2.5832602977752686
Validation loss: 2.4665471456384145

Epoch: 5| Step: 4
Training loss: 3.576578140258789
Validation loss: 2.4625074786524617

Epoch: 5| Step: 5
Training loss: 1.9506174325942993
Validation loss: 2.4497277685391006

Epoch: 5| Step: 6
Training loss: 2.2036640644073486
Validation loss: 2.4494027822248396

Epoch: 5| Step: 7
Training loss: 2.7882134914398193
Validation loss: 2.441724810549008

Epoch: 5| Step: 8
Training loss: 2.9546449184417725
Validation loss: 2.4360193283327165

Epoch: 5| Step: 9
Training loss: 2.9089882373809814
Validation loss: 2.435214727155624

Epoch: 5| Step: 10
Training loss: 2.73474383354187
Validation loss: 2.424998801241639

Epoch: 16| Step: 0
Training loss: 2.8885464668273926
Validation loss: 2.4158945570709887

Epoch: 5| Step: 1
Training loss: 3.081049919128418
Validation loss: 2.409412791652064

Epoch: 5| Step: 2
Training loss: 2.763807773590088
Validation loss: 2.405045606756723

Epoch: 5| Step: 3
Training loss: 3.056980848312378
Validation loss: 2.3967225474696003

Epoch: 5| Step: 4
Training loss: 2.4071707725524902
Validation loss: 2.3924041666010374

Epoch: 5| Step: 5
Training loss: 3.4388630390167236
Validation loss: 2.386521108688847

Epoch: 5| Step: 6
Training loss: 2.0684168338775635
Validation loss: 2.373820553543747

Epoch: 5| Step: 7
Training loss: 2.2988626956939697
Validation loss: 2.3705226836665982

Epoch: 5| Step: 8
Training loss: 2.363356828689575
Validation loss: 2.3599037816447597

Epoch: 5| Step: 9
Training loss: 3.094747543334961
Validation loss: 2.351830013336674

Epoch: 5| Step: 10
Training loss: 1.7892439365386963
Validation loss: 2.353240389977732

Epoch: 17| Step: 0
Training loss: 2.875683546066284
Validation loss: 2.3426162248016684

Epoch: 5| Step: 1
Training loss: 2.7177233695983887
Validation loss: 2.3378394188419467

Epoch: 5| Step: 2
Training loss: 2.4328930377960205
Validation loss: 2.3309414950750207

Epoch: 5| Step: 3
Training loss: 2.328153133392334
Validation loss: 2.327164706363473

Epoch: 5| Step: 4
Training loss: 2.0381340980529785
Validation loss: 2.322972556596161

Epoch: 5| Step: 5
Training loss: 3.250563144683838
Validation loss: 2.317797496754636

Epoch: 5| Step: 6
Training loss: 2.6538939476013184
Validation loss: 2.309574862962128

Epoch: 5| Step: 7
Training loss: 2.6775479316711426
Validation loss: 2.307302172465991

Epoch: 5| Step: 8
Training loss: 2.3508284091949463
Validation loss: 2.2979844539396224

Epoch: 5| Step: 9
Training loss: 2.6791014671325684
Validation loss: 2.29504543735135

Epoch: 5| Step: 10
Training loss: 2.886033773422241
Validation loss: 2.2878891216811312

Epoch: 18| Step: 0
Training loss: 2.6370387077331543
Validation loss: 2.283651090437366

Epoch: 5| Step: 1
Training loss: 1.8282047510147095
Validation loss: 2.2819304620065997

Epoch: 5| Step: 2
Training loss: 3.139331579208374
Validation loss: 2.2802062496062248

Epoch: 5| Step: 3
Training loss: 3.4246983528137207
Validation loss: 2.2765650646660918

Epoch: 5| Step: 4
Training loss: 2.72208571434021
Validation loss: 2.2695609677222466

Epoch: 5| Step: 5
Training loss: 2.9235570430755615
Validation loss: 2.2666988167711484

Epoch: 5| Step: 6
Training loss: 2.257420778274536
Validation loss: 2.256533066431681

Epoch: 5| Step: 7
Training loss: 2.135089874267578
Validation loss: 2.252432155352767

Epoch: 5| Step: 8
Training loss: 2.1912503242492676
Validation loss: 2.2552327033012145

Epoch: 5| Step: 9
Training loss: 2.4328606128692627
Validation loss: 2.24360853369518

Epoch: 5| Step: 10
Training loss: 2.7519686222076416
Validation loss: 2.2325878912402737

Epoch: 19| Step: 0
Training loss: 2.1474876403808594
Validation loss: 2.2310942885696248

Epoch: 5| Step: 1
Training loss: 2.3489067554473877
Validation loss: 2.2167311637632308

Epoch: 5| Step: 2
Training loss: 2.525383710861206
Validation loss: 2.215672646799395

Epoch: 5| Step: 3
Training loss: 2.3811237812042236
Validation loss: 2.207579271767729

Epoch: 5| Step: 4
Training loss: 2.3100953102111816
Validation loss: 2.2061182786059637

Epoch: 5| Step: 5
Training loss: 2.4224658012390137
Validation loss: 2.2106669692582983

Epoch: 5| Step: 6
Training loss: 2.8095996379852295
Validation loss: 2.1994875067023822

Epoch: 5| Step: 7
Training loss: 2.8362197875976562
Validation loss: 2.1995648325130506

Epoch: 5| Step: 8
Training loss: 2.7829036712646484
Validation loss: 2.185476838901479

Epoch: 5| Step: 9
Training loss: 3.0035834312438965
Validation loss: 2.185894722579628

Epoch: 5| Step: 10
Training loss: 2.5460915565490723
Validation loss: 2.1834271466860207

Epoch: 20| Step: 0
Training loss: 2.5986931324005127
Validation loss: 2.1708545889905704

Epoch: 5| Step: 1
Training loss: 2.771801471710205
Validation loss: 2.1739744627347557

Epoch: 5| Step: 2
Training loss: 2.4852688312530518
Validation loss: 2.1720335073368524

Epoch: 5| Step: 3
Training loss: 1.965031385421753
Validation loss: 2.1658127538619505

Epoch: 5| Step: 4
Training loss: 2.5799918174743652
Validation loss: 2.1583125796369327

Epoch: 5| Step: 5
Training loss: 2.8500821590423584
Validation loss: 2.151799709566178

Epoch: 5| Step: 6
Training loss: 2.96855092048645
Validation loss: 2.1511150944617485

Epoch: 5| Step: 7
Training loss: 3.1839632987976074
Validation loss: 2.145903387377339

Epoch: 5| Step: 8
Training loss: 1.839381456375122
Validation loss: 2.150460822607881

Epoch: 5| Step: 9
Training loss: 2.3114380836486816
Validation loss: 2.1434450790446293

Epoch: 5| Step: 10
Training loss: 2.1327922344207764
Validation loss: 2.1316513220469155

Epoch: 21| Step: 0
Training loss: 2.8438022136688232
Validation loss: 2.1276769330424647

Epoch: 5| Step: 1
Training loss: 2.071274518966675
Validation loss: 2.127458574951336

Epoch: 5| Step: 2
Training loss: 2.0458691120147705
Validation loss: 2.122303719161659

Epoch: 5| Step: 3
Training loss: 2.4392809867858887
Validation loss: 2.12478450036818

Epoch: 5| Step: 4
Training loss: 2.7032132148742676
Validation loss: 2.1181274985754364

Epoch: 5| Step: 5
Training loss: 2.6832714080810547
Validation loss: 2.1160499434317313

Epoch: 5| Step: 6
Training loss: 2.2773661613464355
Validation loss: 2.1035383106559835

Epoch: 5| Step: 7
Training loss: 2.3211309909820557
Validation loss: 2.1073887617357316

Epoch: 5| Step: 8
Training loss: 3.1472458839416504
Validation loss: 2.1094055573145547

Epoch: 5| Step: 9
Training loss: 2.084353446960449
Validation loss: 2.09621819244918

Epoch: 5| Step: 10
Training loss: 2.8710381984710693
Validation loss: 2.0938509202772573

Epoch: 22| Step: 0
Training loss: 2.268843173980713
Validation loss: 2.0848686797644502

Epoch: 5| Step: 1
Training loss: 2.7002058029174805
Validation loss: 2.081102266106554

Epoch: 5| Step: 2
Training loss: 2.4366462230682373
Validation loss: 2.084851381599262

Epoch: 5| Step: 3
Training loss: 2.815807819366455
Validation loss: 2.0759380120103077

Epoch: 5| Step: 4
Training loss: 2.655914783477783
Validation loss: 2.074899081260927

Epoch: 5| Step: 5
Training loss: 2.2355010509490967
Validation loss: 2.080018012754379

Epoch: 5| Step: 6
Training loss: 2.428990602493286
Validation loss: 2.0790805073194605

Epoch: 5| Step: 7
Training loss: 2.496927499771118
Validation loss: 2.0725525604781283

Epoch: 5| Step: 8
Training loss: 2.1189169883728027
Validation loss: 2.060458162779449

Epoch: 5| Step: 9
Training loss: 2.694833278656006
Validation loss: 2.073188986829532

Epoch: 5| Step: 10
Training loss: 2.2817704677581787
Validation loss: 2.0598544407916326

Epoch: 23| Step: 0
Training loss: 2.5104434490203857
Validation loss: 2.05767838416561

Epoch: 5| Step: 1
Training loss: 2.514932632446289
Validation loss: 2.0473902635676886

Epoch: 5| Step: 2
Training loss: 2.7312607765197754
Validation loss: 2.048853394805744

Epoch: 5| Step: 3
Training loss: 2.391113519668579
Validation loss: 2.05282631099865

Epoch: 5| Step: 4
Training loss: 2.1442770957946777
Validation loss: 2.0456122454776557

Epoch: 5| Step: 5
Training loss: 2.9730117321014404
Validation loss: 2.0444710434124036

Epoch: 5| Step: 6
Training loss: 2.754936933517456
Validation loss: 2.027079866778466

Epoch: 5| Step: 7
Training loss: 2.459005832672119
Validation loss: 2.0298165890478317

Epoch: 5| Step: 8
Training loss: 2.2950692176818848
Validation loss: 2.0322723978309223

Epoch: 5| Step: 9
Training loss: 2.1892333030700684
Validation loss: 2.0196992287071804

Epoch: 5| Step: 10
Training loss: 2.0028882026672363
Validation loss: 2.0263555921534055

Epoch: 24| Step: 0
Training loss: 2.7633426189422607
Validation loss: 2.0172424803497973

Epoch: 5| Step: 1
Training loss: 2.4843435287475586
Validation loss: 2.0188688385871147

Epoch: 5| Step: 2
Training loss: 1.752724051475525
Validation loss: 2.0160219361705165

Epoch: 5| Step: 3
Training loss: 2.662684679031372
Validation loss: 2.0093234174995014

Epoch: 5| Step: 4
Training loss: 2.6653072834014893
Validation loss: 2.0024147033691406

Epoch: 5| Step: 5
Training loss: 2.957907199859619
Validation loss: 2.0257935280440957

Epoch: 5| Step: 6
Training loss: 2.7681734561920166
Validation loss: 2.0054621799017793

Epoch: 5| Step: 7
Training loss: 2.34376859664917
Validation loss: 1.9984909103762718

Epoch: 5| Step: 8
Training loss: 2.0261082649230957
Validation loss: 1.999688550990115

Epoch: 5| Step: 9
Training loss: 2.2993435859680176
Validation loss: 1.9977931104680544

Epoch: 5| Step: 10
Training loss: 2.1505610942840576
Validation loss: 2.0089137682350735

Epoch: 25| Step: 0
Training loss: 2.480747699737549
Validation loss: 1.9967469784521288

Epoch: 5| Step: 1
Training loss: 1.8354133367538452
Validation loss: 2.0012151220793366

Epoch: 5| Step: 2
Training loss: 1.8491836786270142
Validation loss: 1.9906609853108723

Epoch: 5| Step: 3
Training loss: 2.9817423820495605
Validation loss: 1.9933708303718156

Epoch: 5| Step: 4
Training loss: 2.8512794971466064
Validation loss: 1.9889438741950578

Epoch: 5| Step: 5
Training loss: 2.378114938735962
Validation loss: 2.0004522992718603

Epoch: 5| Step: 6
Training loss: 2.581604242324829
Validation loss: 1.9904727089789607

Epoch: 5| Step: 7
Training loss: 2.9373626708984375
Validation loss: 1.991894886057864

Epoch: 5| Step: 8
Training loss: 2.235395908355713
Validation loss: 1.9919228810136036

Epoch: 5| Step: 9
Training loss: 2.3559908866882324
Validation loss: 1.9890391442083544

Epoch: 5| Step: 10
Training loss: 2.293281078338623
Validation loss: 1.9969509058101202

Epoch: 26| Step: 0
Training loss: 2.7590346336364746
Validation loss: 1.9878235478555002

Epoch: 5| Step: 1
Training loss: 2.299858570098877
Validation loss: 1.9830764057815715

Epoch: 5| Step: 2
Training loss: 1.9571678638458252
Validation loss: 1.9862162015771354

Epoch: 5| Step: 3
Training loss: 2.696277141571045
Validation loss: 1.9885626351961525

Epoch: 5| Step: 4
Training loss: 2.4924583435058594
Validation loss: 1.9981401158917336

Epoch: 5| Step: 5
Training loss: 2.592622995376587
Validation loss: 1.992484599031428

Epoch: 5| Step: 6
Training loss: 2.168196201324463
Validation loss: 1.989913635356452

Epoch: 5| Step: 7
Training loss: 2.4513754844665527
Validation loss: 1.9897209880172566

Epoch: 5| Step: 8
Training loss: 2.9002339839935303
Validation loss: 1.9840142457715926

Epoch: 5| Step: 9
Training loss: 1.8919198513031006
Validation loss: 1.9771826010878368

Epoch: 5| Step: 10
Training loss: 2.569040060043335
Validation loss: 1.986225143555672

Epoch: 27| Step: 0
Training loss: 1.9783575534820557
Validation loss: 1.979546941736693

Epoch: 5| Step: 1
Training loss: 2.4979565143585205
Validation loss: 1.9973999454129128

Epoch: 5| Step: 2
Training loss: 2.4702441692352295
Validation loss: 1.9722312752918532

Epoch: 5| Step: 3
Training loss: 2.613770008087158
Validation loss: 1.9782686233520508

Epoch: 5| Step: 4
Training loss: 2.0023369789123535
Validation loss: 1.9798389045141076

Epoch: 5| Step: 5
Training loss: 2.60392689704895
Validation loss: 1.9885385600469445

Epoch: 5| Step: 6
Training loss: 2.0889945030212402
Validation loss: 1.9770541601283576

Epoch: 5| Step: 7
Training loss: 2.486262083053589
Validation loss: 1.9840177771865681

Epoch: 5| Step: 8
Training loss: 2.422830104827881
Validation loss: 1.988791145304198

Epoch: 5| Step: 9
Training loss: 2.734656572341919
Validation loss: 1.9769093862143896

Epoch: 5| Step: 10
Training loss: 2.907917022705078
Validation loss: 1.9779666739125406

Epoch: 28| Step: 0
Training loss: 2.723130464553833
Validation loss: 1.9761419309082853

Epoch: 5| Step: 1
Training loss: 2.249131441116333
Validation loss: 1.979040563747447

Epoch: 5| Step: 2
Training loss: 2.7581896781921387
Validation loss: 1.9859470705832205

Epoch: 5| Step: 3
Training loss: 2.485010862350464
Validation loss: 1.974954899921212

Epoch: 5| Step: 4
Training loss: 2.851503849029541
Validation loss: 1.981879513750794

Epoch: 5| Step: 5
Training loss: 2.6353116035461426
Validation loss: 1.9786469667188582

Epoch: 5| Step: 6
Training loss: 2.423502206802368
Validation loss: 1.969113322996324

Epoch: 5| Step: 7
Training loss: 1.7891641855239868
Validation loss: 1.978707823702084

Epoch: 5| Step: 8
Training loss: 2.1928577423095703
Validation loss: 1.9766080879396009

Epoch: 5| Step: 9
Training loss: 2.6838736534118652
Validation loss: 1.9681697327603576

Epoch: 5| Step: 10
Training loss: 1.9155794382095337
Validation loss: 1.974765964733657

Epoch: 29| Step: 0
Training loss: 2.2333145141601562
Validation loss: 1.9815466506506807

Epoch: 5| Step: 1
Training loss: 2.2783329486846924
Validation loss: 1.963918311621553

Epoch: 5| Step: 2
Training loss: 1.5489152669906616
Validation loss: 1.973064886626377

Epoch: 5| Step: 3
Training loss: 2.404982328414917
Validation loss: 1.9779086292430919

Epoch: 5| Step: 4
Training loss: 2.3754425048828125
Validation loss: 1.97115013804487

Epoch: 5| Step: 5
Training loss: 2.296757459640503
Validation loss: 1.982031391512963

Epoch: 5| Step: 6
Training loss: 2.6048266887664795
Validation loss: 1.9796299370386268

Epoch: 5| Step: 7
Training loss: 2.7182211875915527
Validation loss: 1.953932019972032

Epoch: 5| Step: 8
Training loss: 3.0677647590637207
Validation loss: 1.979828549969581

Epoch: 5| Step: 9
Training loss: 2.686292886734009
Validation loss: 1.9745062179462884

Epoch: 5| Step: 10
Training loss: 2.5222229957580566
Validation loss: 1.9771267432038502

Epoch: 30| Step: 0
Training loss: 2.2862796783447266
Validation loss: 1.9726154535047469

Epoch: 5| Step: 1
Training loss: 2.8491194248199463
Validation loss: 1.9688153612998225

Epoch: 5| Step: 2
Training loss: 2.3378307819366455
Validation loss: 1.9621750923895067

Epoch: 5| Step: 3
Training loss: 2.8853695392608643
Validation loss: 1.977236674677941

Epoch: 5| Step: 4
Training loss: 1.9643608331680298
Validation loss: 1.9747039502666843

Epoch: 5| Step: 5
Training loss: 3.0001888275146484
Validation loss: 1.982109328751923

Epoch: 5| Step: 6
Training loss: 2.0753324031829834
Validation loss: 1.9879683781695623

Epoch: 5| Step: 7
Training loss: 2.3144078254699707
Validation loss: 1.9794404211864676

Epoch: 5| Step: 8
Training loss: 1.8817641735076904
Validation loss: 1.976844092851044

Epoch: 5| Step: 9
Training loss: 2.6488537788391113
Validation loss: 1.987146617263876

Epoch: 5| Step: 10
Training loss: 2.437534809112549
Validation loss: 1.9873730392866238

Epoch: 31| Step: 0
Training loss: 2.417414665222168
Validation loss: 1.9695229017606346

Epoch: 5| Step: 1
Training loss: 2.3503527641296387
Validation loss: 1.9767905191708637

Epoch: 5| Step: 2
Training loss: 2.4005494117736816
Validation loss: 1.9881526154856528

Epoch: 5| Step: 3
Training loss: 2.2856953144073486
Validation loss: 1.9779486079369821

Epoch: 5| Step: 4
Training loss: 2.9432520866394043
Validation loss: 1.9818862920166345

Epoch: 5| Step: 5
Training loss: 2.5738117694854736
Validation loss: 1.9751721300104612

Epoch: 5| Step: 6
Training loss: 1.7197608947753906
Validation loss: 1.9840354124704997

Epoch: 5| Step: 7
Training loss: 3.0040528774261475
Validation loss: 1.979762069640621

Epoch: 5| Step: 8
Training loss: 2.118831157684326
Validation loss: 1.9679086349343742

Epoch: 5| Step: 9
Training loss: 2.1454973220825195
Validation loss: 1.983218877546249

Epoch: 5| Step: 10
Training loss: 2.730806589126587
Validation loss: 1.9743242776522072

Epoch: 32| Step: 0
Training loss: 2.2019753456115723
Validation loss: 1.9803384683465446

Epoch: 5| Step: 1
Training loss: 2.7320942878723145
Validation loss: 1.9850936756339124

Epoch: 5| Step: 2
Training loss: 2.1871509552001953
Validation loss: 1.980901138756865

Epoch: 5| Step: 3
Training loss: 2.7560744285583496
Validation loss: 1.9703925937734625

Epoch: 5| Step: 4
Training loss: 2.4307849407196045
Validation loss: 1.9803553781201761

Epoch: 5| Step: 5
Training loss: 2.4935479164123535
Validation loss: 1.9815655087911954

Epoch: 5| Step: 6
Training loss: 2.4490442276000977
Validation loss: 1.9699387063262284

Epoch: 5| Step: 7
Training loss: 2.1320865154266357
Validation loss: 1.980000013946205

Epoch: 5| Step: 8
Training loss: 2.2397637367248535
Validation loss: 1.971671676123014

Epoch: 5| Step: 9
Training loss: 2.386545181274414
Validation loss: 1.973233651089412

Epoch: 5| Step: 10
Training loss: 2.5797641277313232
Validation loss: 1.9574775747073594

Epoch: 33| Step: 0
Training loss: 2.1461262702941895
Validation loss: 1.974621570238503

Epoch: 5| Step: 1
Training loss: 3.1060500144958496
Validation loss: 1.9816548157763738

Epoch: 5| Step: 2
Training loss: 2.2991995811462402
Validation loss: 1.9763931330814157

Epoch: 5| Step: 3
Training loss: 2.0405001640319824
Validation loss: 1.9788420213166105

Epoch: 5| Step: 4
Training loss: 1.7997944355010986
Validation loss: 1.9838391042524768

Epoch: 5| Step: 5
Training loss: 2.152531147003174
Validation loss: 1.9781906732948877

Epoch: 5| Step: 6
Training loss: 2.307302236557007
Validation loss: 1.98064588474971

Epoch: 5| Step: 7
Training loss: 2.5349202156066895
Validation loss: 1.972062664647256

Epoch: 5| Step: 8
Training loss: 2.989506959915161
Validation loss: 1.9835489629417338

Epoch: 5| Step: 9
Training loss: 2.7116284370422363
Validation loss: 1.9757795897863244

Epoch: 5| Step: 10
Training loss: 2.4967520236968994
Validation loss: 1.9807667052874

Epoch: 34| Step: 0
Training loss: 2.6225242614746094
Validation loss: 1.9718346890582834

Epoch: 5| Step: 1
Training loss: 2.404562473297119
Validation loss: 1.971099635606171

Epoch: 5| Step: 2
Training loss: 2.4760594367980957
Validation loss: 1.9746142151535198

Epoch: 5| Step: 3
Training loss: 2.1513891220092773
Validation loss: 1.9895846177172918

Epoch: 5| Step: 4
Training loss: 2.190918445587158
Validation loss: 1.982212471705611

Epoch: 5| Step: 5
Training loss: 2.027395486831665
Validation loss: 1.96996130353661

Epoch: 5| Step: 6
Training loss: 2.0156383514404297
Validation loss: 1.9718649130995556

Epoch: 5| Step: 7
Training loss: 2.7608914375305176
Validation loss: 1.9716926146579046

Epoch: 5| Step: 8
Training loss: 2.4996838569641113
Validation loss: 1.9832392815620667

Epoch: 5| Step: 9
Training loss: 2.7514872550964355
Validation loss: 1.9762583496750041

Epoch: 5| Step: 10
Training loss: 2.676154851913452
Validation loss: 1.9798732983168734

Epoch: 35| Step: 0
Training loss: 2.54128360748291
Validation loss: 1.9851410850401847

Epoch: 5| Step: 1
Training loss: 2.0136990547180176
Validation loss: 1.977640926197011

Epoch: 5| Step: 2
Training loss: 2.4025352001190186
Validation loss: 1.9809730629767142

Epoch: 5| Step: 3
Training loss: 2.709105968475342
Validation loss: 1.9805187768833612

Epoch: 5| Step: 4
Training loss: 2.2244019508361816
Validation loss: 1.9781656316531602

Epoch: 5| Step: 5
Training loss: 2.6898787021636963
Validation loss: 1.9793947486467258

Epoch: 5| Step: 6
Training loss: 2.0359652042388916
Validation loss: 1.9681618290562783

Epoch: 5| Step: 7
Training loss: 2.765969753265381
Validation loss: 1.9740563861785396

Epoch: 5| Step: 8
Training loss: 2.707562208175659
Validation loss: 1.9777101201395835

Epoch: 5| Step: 9
Training loss: 2.3949084281921387
Validation loss: 1.9739998771298317

Epoch: 5| Step: 10
Training loss: 1.9659337997436523
Validation loss: 1.976766360703335

Epoch: 36| Step: 0
Training loss: 2.5490376949310303
Validation loss: 1.9797895185409053

Epoch: 5| Step: 1
Training loss: 1.7854957580566406
Validation loss: 1.9744093674485401

Epoch: 5| Step: 2
Training loss: 2.364114761352539
Validation loss: 1.9741045992861512

Epoch: 5| Step: 3
Training loss: 2.6889138221740723
Validation loss: 1.9751621215574202

Epoch: 5| Step: 4
Training loss: 2.273482084274292
Validation loss: 1.9761708436473724

Epoch: 5| Step: 5
Training loss: 2.5997400283813477
Validation loss: 1.9659963602660804

Epoch: 5| Step: 6
Training loss: 2.7350852489471436
Validation loss: 1.981276342945714

Epoch: 5| Step: 7
Training loss: 2.160933017730713
Validation loss: 1.9722330595857354

Epoch: 5| Step: 8
Training loss: 2.485182762145996
Validation loss: 1.977451237299109

Epoch: 5| Step: 9
Training loss: 2.063502073287964
Validation loss: 1.9773147798353625

Epoch: 5| Step: 10
Training loss: 2.704169750213623
Validation loss: 1.9778032251583633

Epoch: 37| Step: 0
Training loss: 2.0534443855285645
Validation loss: 1.9693245836483535

Epoch: 5| Step: 1
Training loss: 2.7452709674835205
Validation loss: 1.9788315911446848

Epoch: 5| Step: 2
Training loss: 2.2829787731170654
Validation loss: 1.9849416645624305

Epoch: 5| Step: 3
Training loss: 2.1233713626861572
Validation loss: 1.9830404212397914

Epoch: 5| Step: 4
Training loss: 2.1142995357513428
Validation loss: 1.9786625792903285

Epoch: 5| Step: 5
Training loss: 2.3421568870544434
Validation loss: 1.9876408910238614

Epoch: 5| Step: 6
Training loss: 2.740206480026245
Validation loss: 1.9844208994219381

Epoch: 5| Step: 7
Training loss: 2.030668020248413
Validation loss: 1.972419100423013

Epoch: 5| Step: 8
Training loss: 2.6258342266082764
Validation loss: 1.9752432479653308

Epoch: 5| Step: 9
Training loss: 2.7300355434417725
Validation loss: 1.9648461008584628

Epoch: 5| Step: 10
Training loss: 2.601881980895996
Validation loss: 1.9764128423506213

Epoch: 38| Step: 0
Training loss: 1.9833685159683228
Validation loss: 1.969616461825627

Epoch: 5| Step: 1
Training loss: 2.054248332977295
Validation loss: 1.9771909713745117

Epoch: 5| Step: 2
Training loss: 2.0618467330932617
Validation loss: 1.975692747741617

Epoch: 5| Step: 3
Training loss: 2.4716992378234863
Validation loss: 1.9792101742118917

Epoch: 5| Step: 4
Training loss: 2.931844711303711
Validation loss: 1.9684204478417673

Epoch: 5| Step: 5
Training loss: 2.535396099090576
Validation loss: 1.9831763185480589

Epoch: 5| Step: 6
Training loss: 2.517158031463623
Validation loss: 1.9834626361887941

Epoch: 5| Step: 7
Training loss: 2.9642162322998047
Validation loss: 1.9836643562521985

Epoch: 5| Step: 8
Training loss: 2.3049120903015137
Validation loss: 1.978771476335423

Epoch: 5| Step: 9
Training loss: 2.4770960807800293
Validation loss: 1.982523779715261

Epoch: 5| Step: 10
Training loss: 2.0215954780578613
Validation loss: 1.985463721777803

Epoch: 39| Step: 0
Training loss: 2.3051254749298096
Validation loss: 1.9713223723955051

Epoch: 5| Step: 1
Training loss: 2.5295615196228027
Validation loss: 1.9762465505189792

Epoch: 5| Step: 2
Training loss: 2.6055195331573486
Validation loss: 1.9674462464547926

Epoch: 5| Step: 3
Training loss: 2.755155086517334
Validation loss: 1.9713698023109025

Epoch: 5| Step: 4
Training loss: 2.729182481765747
Validation loss: 1.9791340520305019

Epoch: 5| Step: 5
Training loss: 2.3891758918762207
Validation loss: 1.9764005009846022

Epoch: 5| Step: 6
Training loss: 2.3654286861419678
Validation loss: 1.9757487850804483

Epoch: 5| Step: 7
Training loss: 2.2083077430725098
Validation loss: 1.9684359886312996

Epoch: 5| Step: 8
Training loss: 2.1508865356445312
Validation loss: 1.9890648139420377

Epoch: 5| Step: 9
Training loss: 2.03743577003479
Validation loss: 1.9823428353955668

Epoch: 5| Step: 10
Training loss: 2.2377758026123047
Validation loss: 1.9775560363646476

Epoch: 40| Step: 0
Training loss: 2.050877094268799
Validation loss: 1.9798859165560814

Epoch: 5| Step: 1
Training loss: 2.6048808097839355
Validation loss: 1.9813395289964573

Epoch: 5| Step: 2
Training loss: 2.5250511169433594
Validation loss: 1.9716053470488517

Epoch: 5| Step: 3
Training loss: 1.7425838708877563
Validation loss: 1.9663854440053303

Epoch: 5| Step: 4
Training loss: 2.448892116546631
Validation loss: 1.9523692105406074

Epoch: 5| Step: 5
Training loss: 2.400850296020508
Validation loss: 1.9750011441528157

Epoch: 5| Step: 6
Training loss: 2.946833848953247
Validation loss: 1.9669283154190227

Epoch: 5| Step: 7
Training loss: 2.804246425628662
Validation loss: 1.975455589191888

Epoch: 5| Step: 8
Training loss: 2.25077486038208
Validation loss: 1.9645498350102415

Epoch: 5| Step: 9
Training loss: 2.6933436393737793
Validation loss: 1.9748861635884931

Epoch: 5| Step: 10
Training loss: 1.803803563117981
Validation loss: 1.9643310603275095

Epoch: 41| Step: 0
Training loss: 2.1339478492736816
Validation loss: 1.965780109487554

Epoch: 5| Step: 1
Training loss: 2.8902392387390137
Validation loss: 1.969647845914287

Epoch: 5| Step: 2
Training loss: 2.3209853172302246
Validation loss: 1.9679620163415068

Epoch: 5| Step: 3
Training loss: 3.0189201831817627
Validation loss: 1.9608105459520895

Epoch: 5| Step: 4
Training loss: 2.2579827308654785
Validation loss: 1.9685913875538816

Epoch: 5| Step: 5
Training loss: 1.7442371845245361
Validation loss: 1.9610035804010206

Epoch: 5| Step: 6
Training loss: 2.8752474784851074
Validation loss: 1.9625966779647335

Epoch: 5| Step: 7
Training loss: 2.746683120727539
Validation loss: 1.977260402453843

Epoch: 5| Step: 8
Training loss: 2.387934446334839
Validation loss: 1.9664858605272026

Epoch: 5| Step: 9
Training loss: 1.9662578105926514
Validation loss: 1.9573933360397175

Epoch: 5| Step: 10
Training loss: 1.8437391519546509
Validation loss: 1.9632932806527743

Epoch: 42| Step: 0
Training loss: 2.6270909309387207
Validation loss: 1.961207487249887

Epoch: 5| Step: 1
Training loss: 2.580955743789673
Validation loss: 1.9755326829930788

Epoch: 5| Step: 2
Training loss: 2.366364002227783
Validation loss: 1.9706209833903978

Epoch: 5| Step: 3
Training loss: 1.980489730834961
Validation loss: 1.969801252888095

Epoch: 5| Step: 4
Training loss: 2.2382450103759766
Validation loss: 1.9588523795527797

Epoch: 5| Step: 5
Training loss: 2.3757784366607666
Validation loss: 1.9713677039710424

Epoch: 5| Step: 6
Training loss: 2.3126959800720215
Validation loss: 1.9733762856452697

Epoch: 5| Step: 7
Training loss: 2.6703295707702637
Validation loss: 1.9676389168667536

Epoch: 5| Step: 8
Training loss: 2.780484914779663
Validation loss: 1.965372472681025

Epoch: 5| Step: 9
Training loss: 2.1535239219665527
Validation loss: 1.9599067857188563

Epoch: 5| Step: 10
Training loss: 2.113372325897217
Validation loss: 1.9682888407861032

Epoch: 43| Step: 0
Training loss: 2.6566197872161865
Validation loss: 1.9775054864985968

Epoch: 5| Step: 1
Training loss: 1.7323389053344727
Validation loss: 1.9640849956902124

Epoch: 5| Step: 2
Training loss: 2.671165943145752
Validation loss: 1.9708031633848786

Epoch: 5| Step: 3
Training loss: 2.8401124477386475
Validation loss: 1.9683517858546267

Epoch: 5| Step: 4
Training loss: 2.361288070678711
Validation loss: 1.9695904921459895

Epoch: 5| Step: 5
Training loss: 2.974001407623291
Validation loss: 1.9695165182954522

Epoch: 5| Step: 6
Training loss: 2.5937206745147705
Validation loss: 1.9757239933936828

Epoch: 5| Step: 7
Training loss: 1.9525333642959595
Validation loss: 1.9804520017357283

Epoch: 5| Step: 8
Training loss: 2.327274799346924
Validation loss: 1.978201957159145

Epoch: 5| Step: 9
Training loss: 1.6871229410171509
Validation loss: 1.978785764786505

Epoch: 5| Step: 10
Training loss: 2.295034170150757
Validation loss: 1.9694853136616368

Epoch: 44| Step: 0
Training loss: 1.6549164056777954
Validation loss: 1.9731581159817275

Epoch: 5| Step: 1
Training loss: 1.783564805984497
Validation loss: 1.9693973128513624

Epoch: 5| Step: 2
Training loss: 2.2584450244903564
Validation loss: 1.9755525255715976

Epoch: 5| Step: 3
Training loss: 2.4649529457092285
Validation loss: 1.9632726023274083

Epoch: 5| Step: 4
Training loss: 2.545651912689209
Validation loss: 1.9752820255935832

Epoch: 5| Step: 5
Training loss: 2.809187173843384
Validation loss: 1.9669945778385285

Epoch: 5| Step: 6
Training loss: 2.8880984783172607
Validation loss: 1.978706226553968

Epoch: 5| Step: 7
Training loss: 2.3832240104675293
Validation loss: 1.9754345417022705

Epoch: 5| Step: 8
Training loss: 2.3353121280670166
Validation loss: 1.9779207270632508

Epoch: 5| Step: 9
Training loss: 2.191200017929077
Validation loss: 1.9778766990989767

Epoch: 5| Step: 10
Training loss: 3.0379629135131836
Validation loss: 1.9882928850830242

Epoch: 45| Step: 0
Training loss: 2.0922000408172607
Validation loss: 1.973021149635315

Epoch: 5| Step: 1
Training loss: 2.5228946208953857
Validation loss: 1.972240537725469

Epoch: 5| Step: 2
Training loss: 2.7034287452697754
Validation loss: 1.9734052406844271

Epoch: 5| Step: 3
Training loss: 2.5979232788085938
Validation loss: 1.980870077686925

Epoch: 5| Step: 4
Training loss: 1.8633296489715576
Validation loss: 1.9665110726510324

Epoch: 5| Step: 5
Training loss: 2.4432952404022217
Validation loss: 1.9876407782236736

Epoch: 5| Step: 6
Training loss: 2.9411818981170654
Validation loss: 1.980251307128578

Epoch: 5| Step: 7
Training loss: 2.2499542236328125
Validation loss: 1.977022529930197

Epoch: 5| Step: 8
Training loss: 1.8210188150405884
Validation loss: 1.9810412519721574

Epoch: 5| Step: 9
Training loss: 2.608272075653076
Validation loss: 1.9694110680651922

Epoch: 5| Step: 10
Training loss: 2.281092882156372
Validation loss: 1.9753711351784327

Epoch: 46| Step: 0
Training loss: 2.474306106567383
Validation loss: 1.9767626241971088

Epoch: 5| Step: 1
Training loss: 2.3500468730926514
Validation loss: 1.9774271031861663

Epoch: 5| Step: 2
Training loss: 2.0420565605163574
Validation loss: 1.9630515088317215

Epoch: 5| Step: 3
Training loss: 2.0101253986358643
Validation loss: 1.9762209923036638

Epoch: 5| Step: 4
Training loss: 2.3437960147857666
Validation loss: 1.9572822842546689

Epoch: 5| Step: 5
Training loss: 2.131837844848633
Validation loss: 1.9735156848866453

Epoch: 5| Step: 6
Training loss: 2.380349636077881
Validation loss: 1.9622957898724465

Epoch: 5| Step: 7
Training loss: 2.5703072547912598
Validation loss: 1.9586195574011853

Epoch: 5| Step: 8
Training loss: 3.004498243331909
Validation loss: 1.964145291236139

Epoch: 5| Step: 9
Training loss: 2.6204593181610107
Validation loss: 1.9746265411376953

Epoch: 5| Step: 10
Training loss: 2.130230188369751
Validation loss: 1.9595924269768499

Epoch: 47| Step: 0
Training loss: 1.9071943759918213
Validation loss: 1.9646070618783273

Epoch: 5| Step: 1
Training loss: 2.381530284881592
Validation loss: 1.9797646358448973

Epoch: 5| Step: 2
Training loss: 1.9591903686523438
Validation loss: 1.9591827520760157

Epoch: 5| Step: 3
Training loss: 2.5181081295013428
Validation loss: 1.9720322214147097

Epoch: 5| Step: 4
Training loss: 2.409916400909424
Validation loss: 1.9666956624677103

Epoch: 5| Step: 5
Training loss: 2.9728798866271973
Validation loss: 1.9795890623523342

Epoch: 5| Step: 6
Training loss: 2.5346717834472656
Validation loss: 1.9758009987492715

Epoch: 5| Step: 7
Training loss: 2.559166193008423
Validation loss: 1.969263006282109

Epoch: 5| Step: 8
Training loss: 2.743016481399536
Validation loss: 1.9753352313913324

Epoch: 5| Step: 9
Training loss: 2.1372809410095215
Validation loss: 1.9686197491102322

Epoch: 5| Step: 10
Training loss: 1.7821155786514282
Validation loss: 1.980732749867183

Epoch: 48| Step: 0
Training loss: 2.4883508682250977
Validation loss: 1.9710155405024046

Epoch: 5| Step: 1
Training loss: 2.206836223602295
Validation loss: 1.9713427494930964

Epoch: 5| Step: 2
Training loss: 1.9633878469467163
Validation loss: 1.9746699051190448

Epoch: 5| Step: 3
Training loss: 2.719453811645508
Validation loss: 1.9770753152908818

Epoch: 5| Step: 4
Training loss: 2.2756123542785645
Validation loss: 1.970874801758797

Epoch: 5| Step: 5
Training loss: 2.4703922271728516
Validation loss: 1.9664405533062514

Epoch: 5| Step: 6
Training loss: 2.319305896759033
Validation loss: 1.9514150042687692

Epoch: 5| Step: 7
Training loss: 2.1709861755371094
Validation loss: 1.952852556782384

Epoch: 5| Step: 8
Training loss: 2.9339542388916016
Validation loss: 1.955984559110416

Epoch: 5| Step: 9
Training loss: 2.3302836418151855
Validation loss: 1.9616589302657752

Epoch: 5| Step: 10
Training loss: 2.0842976570129395
Validation loss: 1.9531936184052499

Epoch: 49| Step: 0
Training loss: 2.2924818992614746
Validation loss: 1.9488245799977293

Epoch: 5| Step: 1
Training loss: 1.8968727588653564
Validation loss: 1.9547019004821777

Epoch: 5| Step: 2
Training loss: 2.4392409324645996
Validation loss: 1.968223682013891

Epoch: 5| Step: 3
Training loss: 2.446530342102051
Validation loss: 1.9583189423366258

Epoch: 5| Step: 4
Training loss: 2.2453770637512207
Validation loss: 1.9565017454085811

Epoch: 5| Step: 5
Training loss: 2.4297356605529785
Validation loss: 1.9690178543008783

Epoch: 5| Step: 6
Training loss: 2.4625799655914307
Validation loss: 1.9443925670398179

Epoch: 5| Step: 7
Training loss: 2.6856651306152344
Validation loss: 1.95951509475708

Epoch: 5| Step: 8
Training loss: 2.1350455284118652
Validation loss: 1.9529458220287035

Epoch: 5| Step: 9
Training loss: 2.6701316833496094
Validation loss: 1.9567743347537132

Epoch: 5| Step: 10
Training loss: 2.1900177001953125
Validation loss: 1.9619679040806268

Epoch: 50| Step: 0
Training loss: 1.820519208908081
Validation loss: 1.9532486777151785

Epoch: 5| Step: 1
Training loss: 2.4974608421325684
Validation loss: 1.952950398127238

Epoch: 5| Step: 2
Training loss: 2.4816253185272217
Validation loss: 1.9537142169091009

Epoch: 5| Step: 3
Training loss: 2.1892871856689453
Validation loss: 1.952214261536957

Epoch: 5| Step: 4
Training loss: 2.6355502605438232
Validation loss: 1.950042506699921

Epoch: 5| Step: 5
Training loss: 2.8905417919158936
Validation loss: 1.9471108451966317

Epoch: 5| Step: 6
Training loss: 2.31662654876709
Validation loss: 1.9440301028631066

Epoch: 5| Step: 7
Training loss: 2.3690812587738037
Validation loss: 1.9645863399710706

Epoch: 5| Step: 8
Training loss: 2.258279800415039
Validation loss: 1.951921191266788

Epoch: 5| Step: 9
Training loss: 1.9248584508895874
Validation loss: 1.9602334242995068

Epoch: 5| Step: 10
Training loss: 2.637242078781128
Validation loss: 1.9462195852751374

Epoch: 51| Step: 0
Training loss: 1.9692652225494385
Validation loss: 1.9462151476131972

Epoch: 5| Step: 1
Training loss: 2.8655343055725098
Validation loss: 1.9579972708097069

Epoch: 5| Step: 2
Training loss: 2.1971611976623535
Validation loss: 1.952551011116274

Epoch: 5| Step: 3
Training loss: 2.0877418518066406
Validation loss: 1.9599137818941506

Epoch: 5| Step: 4
Training loss: 1.9502471685409546
Validation loss: 1.9564577635898386

Epoch: 5| Step: 5
Training loss: 2.7224838733673096
Validation loss: 1.9560175480381135

Epoch: 5| Step: 6
Training loss: 2.249809741973877
Validation loss: 1.9547554728805379

Epoch: 5| Step: 7
Training loss: 2.620389938354492
Validation loss: 1.9555315061282086

Epoch: 5| Step: 8
Training loss: 2.6459529399871826
Validation loss: 1.9480853426840998

Epoch: 5| Step: 9
Training loss: 2.387512683868408
Validation loss: 1.9392631874289563

Epoch: 5| Step: 10
Training loss: 2.1317038536071777
Validation loss: 1.9455241721163514

Epoch: 52| Step: 0
Training loss: 2.1639723777770996
Validation loss: 1.9474894346729401

Epoch: 5| Step: 1
Training loss: 2.05277419090271
Validation loss: 1.9469882057559105

Epoch: 5| Step: 2
Training loss: 1.984302282333374
Validation loss: 1.9513834932798981

Epoch: 5| Step: 3
Training loss: 2.360551118850708
Validation loss: 1.9500234998682493

Epoch: 5| Step: 4
Training loss: 2.4262442588806152
Validation loss: 1.9486162239505398

Epoch: 5| Step: 5
Training loss: 2.6427884101867676
Validation loss: 1.9608187316566386

Epoch: 5| Step: 6
Training loss: 2.4383578300476074
Validation loss: 1.9565460348642

Epoch: 5| Step: 7
Training loss: 2.532830238342285
Validation loss: 1.9489836667173652

Epoch: 5| Step: 8
Training loss: 2.0798451900482178
Validation loss: 1.9488113772484563

Epoch: 5| Step: 9
Training loss: 2.6063616275787354
Validation loss: 1.9451628423506213

Epoch: 5| Step: 10
Training loss: 2.5787839889526367
Validation loss: 1.957855361764149

Epoch: 53| Step: 0
Training loss: 2.4847300052642822
Validation loss: 1.9627060813288535

Epoch: 5| Step: 1
Training loss: 2.2102115154266357
Validation loss: 1.9391465033254316

Epoch: 5| Step: 2
Training loss: 1.9613574743270874
Validation loss: 1.9613088587278962

Epoch: 5| Step: 3
Training loss: 2.5183510780334473
Validation loss: 1.9606695085443475

Epoch: 5| Step: 4
Training loss: 2.4999852180480957
Validation loss: 1.9490342909289944

Epoch: 5| Step: 5
Training loss: 2.6509785652160645
Validation loss: 1.9446107584943053

Epoch: 5| Step: 6
Training loss: 2.7039122581481934
Validation loss: 1.9459413815570135

Epoch: 5| Step: 7
Training loss: 1.7332090139389038
Validation loss: 1.9405888895834646

Epoch: 5| Step: 8
Training loss: 2.3097407817840576
Validation loss: 1.9478452436385616

Epoch: 5| Step: 9
Training loss: 2.3030011653900146
Validation loss: 1.9501875433870541

Epoch: 5| Step: 10
Training loss: 2.432529926300049
Validation loss: 1.9354727216946181

Epoch: 54| Step: 0
Training loss: 2.2729907035827637
Validation loss: 1.9652243660342308

Epoch: 5| Step: 1
Training loss: 2.323554277420044
Validation loss: 1.9568462551281016

Epoch: 5| Step: 2
Training loss: 1.7699453830718994
Validation loss: 1.937662213079391

Epoch: 5| Step: 3
Training loss: 2.3554465770721436
Validation loss: 1.9395833246169552

Epoch: 5| Step: 4
Training loss: 2.2907776832580566
Validation loss: 1.949178321387178

Epoch: 5| Step: 5
Training loss: 2.5831422805786133
Validation loss: 1.9531325089034213

Epoch: 5| Step: 6
Training loss: 2.4007110595703125
Validation loss: 1.9490140202224895

Epoch: 5| Step: 7
Training loss: 2.250231981277466
Validation loss: 1.9519513806989115

Epoch: 5| Step: 8
Training loss: 2.2796452045440674
Validation loss: 1.951187902881253

Epoch: 5| Step: 9
Training loss: 2.6348607540130615
Validation loss: 1.9615990525932723

Epoch: 5| Step: 10
Training loss: 2.5867462158203125
Validation loss: 1.9632927397246003

Epoch: 55| Step: 0
Training loss: 2.2626490592956543
Validation loss: 1.9569159784624655

Epoch: 5| Step: 1
Training loss: 2.246913194656372
Validation loss: 1.969919281621133

Epoch: 5| Step: 2
Training loss: 2.082874059677124
Validation loss: 1.960283084582257

Epoch: 5| Step: 3
Training loss: 2.1991782188415527
Validation loss: 1.9408008411366453

Epoch: 5| Step: 4
Training loss: 2.5435924530029297
Validation loss: 1.949983560910789

Epoch: 5| Step: 5
Training loss: 1.9620201587677002
Validation loss: 1.9591549840024722

Epoch: 5| Step: 6
Training loss: 2.265907049179077
Validation loss: 1.9505273398532663

Epoch: 5| Step: 7
Training loss: 2.4422953128814697
Validation loss: 1.957597815862266

Epoch: 5| Step: 8
Training loss: 2.863231658935547
Validation loss: 1.947202156948787

Epoch: 5| Step: 9
Training loss: 2.190150737762451
Validation loss: 1.9461298040164414

Epoch: 5| Step: 10
Training loss: 2.6743366718292236
Validation loss: 1.946071086391326

Epoch: 56| Step: 0
Training loss: 2.123471260070801
Validation loss: 1.945599550841957

Epoch: 5| Step: 1
Training loss: 3.0132875442504883
Validation loss: 1.9547707278241393

Epoch: 5| Step: 2
Training loss: 2.6061882972717285
Validation loss: 1.9438230747817664

Epoch: 5| Step: 3
Training loss: 2.2135462760925293
Validation loss: 1.9495388025878577

Epoch: 5| Step: 4
Training loss: 2.5096402168273926
Validation loss: 1.946743872857863

Epoch: 5| Step: 5
Training loss: 2.5986878871917725
Validation loss: 1.9544020199006604

Epoch: 5| Step: 6
Training loss: 1.9086217880249023
Validation loss: 1.9651643973524853

Epoch: 5| Step: 7
Training loss: 2.373363494873047
Validation loss: 1.9557551337826637

Epoch: 5| Step: 8
Training loss: 2.2427945137023926
Validation loss: 1.9612918951178109

Epoch: 5| Step: 9
Training loss: 2.306790351867676
Validation loss: 1.9609984403015466

Epoch: 5| Step: 10
Training loss: 1.6317481994628906
Validation loss: 1.9522477298654535

Epoch: 57| Step: 0
Training loss: 2.604670524597168
Validation loss: 1.9552088129904963

Epoch: 5| Step: 1
Training loss: 2.9374442100524902
Validation loss: 1.9408111444083593

Epoch: 5| Step: 2
Training loss: 2.444060802459717
Validation loss: 1.9542080433137956

Epoch: 5| Step: 3
Training loss: 2.38801646232605
Validation loss: 1.9619987062228623

Epoch: 5| Step: 4
Training loss: 1.9410922527313232
Validation loss: 1.9480211350225634

Epoch: 5| Step: 5
Training loss: 2.0829670429229736
Validation loss: 1.9529996918093773

Epoch: 5| Step: 6
Training loss: 2.0445945262908936
Validation loss: 1.9563167095184326

Epoch: 5| Step: 7
Training loss: 1.9833686351776123
Validation loss: 1.951154822944313

Epoch: 5| Step: 8
Training loss: 1.925986886024475
Validation loss: 1.9577926871597127

Epoch: 5| Step: 9
Training loss: 2.816704511642456
Validation loss: 1.9478932196094143

Epoch: 5| Step: 10
Training loss: 2.359431743621826
Validation loss: 1.9529660478714974

Epoch: 58| Step: 0
Training loss: 2.1613881587982178
Validation loss: 1.9337003525867258

Epoch: 5| Step: 1
Training loss: 2.2993366718292236
Validation loss: 1.9592599253500662

Epoch: 5| Step: 2
Training loss: 2.1052346229553223
Validation loss: 1.9513954475361814

Epoch: 5| Step: 3
Training loss: 2.3399815559387207
Validation loss: 1.9466936793378604

Epoch: 5| Step: 4
Training loss: 1.9531223773956299
Validation loss: 1.9575134823399205

Epoch: 5| Step: 5
Training loss: 2.2111032009124756
Validation loss: 1.952020586177867

Epoch: 5| Step: 6
Training loss: 2.7904727458953857
Validation loss: 1.9519516857721473

Epoch: 5| Step: 7
Training loss: 2.1384425163269043
Validation loss: 1.9381004892369753

Epoch: 5| Step: 8
Training loss: 2.7090368270874023
Validation loss: 1.9410872843957716

Epoch: 5| Step: 9
Training loss: 2.5516960620880127
Validation loss: 1.9461545328940115

Epoch: 5| Step: 10
Training loss: 2.219745397567749
Validation loss: 1.9472139727684759

Epoch: 59| Step: 0
Training loss: 2.4386420249938965
Validation loss: 1.949013566458097

Epoch: 5| Step: 1
Training loss: 1.9406957626342773
Validation loss: 1.9479078579974431

Epoch: 5| Step: 2
Training loss: 2.1255111694335938
Validation loss: 1.9538246329112718

Epoch: 5| Step: 3
Training loss: 2.6619534492492676
Validation loss: 1.9638273344245007

Epoch: 5| Step: 4
Training loss: 2.713804244995117
Validation loss: 1.9443330457133632

Epoch: 5| Step: 5
Training loss: 2.4692695140838623
Validation loss: 1.9605488546432988

Epoch: 5| Step: 6
Training loss: 2.434849977493286
Validation loss: 1.9514030192487983

Epoch: 5| Step: 7
Training loss: 1.8789373636245728
Validation loss: 1.9492126485352874

Epoch: 5| Step: 8
Training loss: 2.044832229614258
Validation loss: 1.9702455048920007

Epoch: 5| Step: 9
Training loss: 1.8326749801635742
Validation loss: 1.9459210441958519

Epoch: 5| Step: 10
Training loss: 3.0101633071899414
Validation loss: 1.949807023489347

Epoch: 60| Step: 0
Training loss: 2.088956594467163
Validation loss: 1.944305271230718

Epoch: 5| Step: 1
Training loss: 2.3775229454040527
Validation loss: 1.9492424970032067

Epoch: 5| Step: 2
Training loss: 2.072287082672119
Validation loss: 1.9443081655809957

Epoch: 5| Step: 3
Training loss: 2.0102219581604004
Validation loss: 1.947650158277122

Epoch: 5| Step: 4
Training loss: 2.094327211380005
Validation loss: 1.951198834244923

Epoch: 5| Step: 5
Training loss: 2.8772377967834473
Validation loss: 1.9614968761321037

Epoch: 5| Step: 6
Training loss: 2.2693235874176025
Validation loss: 1.946152158962783

Epoch: 5| Step: 7
Training loss: 2.4206840991973877
Validation loss: 1.9702492478073284

Epoch: 5| Step: 8
Training loss: 2.3771557807922363
Validation loss: 1.9511090145316174

Epoch: 5| Step: 9
Training loss: 2.8548076152801514
Validation loss: 1.9535261789957683

Epoch: 5| Step: 10
Training loss: 1.8807752132415771
Validation loss: 1.9616325106672061

Epoch: 61| Step: 0
Training loss: 2.0972087383270264
Validation loss: 1.9530066713210075

Epoch: 5| Step: 1
Training loss: 1.8786160945892334
Validation loss: 1.9499440372631114

Epoch: 5| Step: 2
Training loss: 1.7920475006103516
Validation loss: 1.9483075859726116

Epoch: 5| Step: 3
Training loss: 1.9429941177368164
Validation loss: 1.9475162900904173

Epoch: 5| Step: 4
Training loss: 2.7910678386688232
Validation loss: 1.9417662799999278

Epoch: 5| Step: 5
Training loss: 2.847801923751831
Validation loss: 1.9595536083303473

Epoch: 5| Step: 6
Training loss: 2.7592363357543945
Validation loss: 1.946435837335484

Epoch: 5| Step: 7
Training loss: 1.6514670848846436
Validation loss: 1.955527958049569

Epoch: 5| Step: 8
Training loss: 2.1024622917175293
Validation loss: 1.9437906152458602

Epoch: 5| Step: 9
Training loss: 2.6333768367767334
Validation loss: 1.957001442550331

Epoch: 5| Step: 10
Training loss: 3.000171422958374
Validation loss: 1.9544066511174685

Epoch: 62| Step: 0
Training loss: 2.3678269386291504
Validation loss: 1.9604971767753683

Epoch: 5| Step: 1
Training loss: 1.9803259372711182
Validation loss: 1.9597864920093166

Epoch: 5| Step: 2
Training loss: 2.615495204925537
Validation loss: 1.946546846820462

Epoch: 5| Step: 3
Training loss: 1.8955310583114624
Validation loss: 1.9746989139946558

Epoch: 5| Step: 4
Training loss: 2.5991039276123047
Validation loss: 1.9649762107479958

Epoch: 5| Step: 5
Training loss: 2.4419710636138916
Validation loss: 1.963017967439467

Epoch: 5| Step: 6
Training loss: 2.4474101066589355
Validation loss: 1.955220155818488

Epoch: 5| Step: 7
Training loss: 2.758096694946289
Validation loss: 1.9665420580935735

Epoch: 5| Step: 8
Training loss: 2.5219027996063232
Validation loss: 1.965095325182843

Epoch: 5| Step: 9
Training loss: 2.1783597469329834
Validation loss: 1.9695954168996503

Epoch: 5| Step: 10
Training loss: 1.5059170722961426
Validation loss: 1.9663667345559726

Epoch: 63| Step: 0
Training loss: 1.9370040893554688
Validation loss: 1.9645397791298487

Epoch: 5| Step: 1
Training loss: 2.6693267822265625
Validation loss: 1.9573376717105988

Epoch: 5| Step: 2
Training loss: 1.8931543827056885
Validation loss: 1.9535485647057975

Epoch: 5| Step: 3
Training loss: 2.2726049423217773
Validation loss: 1.9371736793107883

Epoch: 5| Step: 4
Training loss: 2.368863582611084
Validation loss: 1.9450116708714476

Epoch: 5| Step: 5
Training loss: 1.8415018320083618
Validation loss: 1.9507298597725489

Epoch: 5| Step: 6
Training loss: 2.3743045330047607
Validation loss: 1.93623399478133

Epoch: 5| Step: 7
Training loss: 2.0649356842041016
Validation loss: 1.9461854811637633

Epoch: 5| Step: 8
Training loss: 2.460970163345337
Validation loss: 1.9343981255767166

Epoch: 5| Step: 9
Training loss: 2.6612277030944824
Validation loss: 1.9619669991154824

Epoch: 5| Step: 10
Training loss: 2.8269267082214355
Validation loss: 1.9380033336659914

Epoch: 64| Step: 0
Training loss: 2.575754165649414
Validation loss: 1.9480917428129463

Epoch: 5| Step: 1
Training loss: 2.3902041912078857
Validation loss: 1.940018084741408

Epoch: 5| Step: 2
Training loss: 2.076183795928955
Validation loss: 1.9448201540977723

Epoch: 5| Step: 3
Training loss: 2.544386625289917
Validation loss: 1.9395953583460983

Epoch: 5| Step: 4
Training loss: 2.1159768104553223
Validation loss: 1.935525757010265

Epoch: 5| Step: 5
Training loss: 2.320070266723633
Validation loss: 1.9452501073960335

Epoch: 5| Step: 6
Training loss: 1.8272836208343506
Validation loss: 1.9428608302147157

Epoch: 5| Step: 7
Training loss: 2.2478866577148438
Validation loss: 1.9388351414793281

Epoch: 5| Step: 8
Training loss: 2.2765870094299316
Validation loss: 1.9464658511582242

Epoch: 5| Step: 9
Training loss: 2.1633291244506836
Validation loss: 1.9471832039535686

Epoch: 5| Step: 10
Training loss: 2.6559524536132812
Validation loss: 1.9502887815557501

Epoch: 65| Step: 0
Training loss: 2.210599899291992
Validation loss: 1.9412751607997443

Epoch: 5| Step: 1
Training loss: 1.9982925653457642
Validation loss: 1.9509494227747763

Epoch: 5| Step: 2
Training loss: 1.8677908182144165
Validation loss: 1.9410727357351651

Epoch: 5| Step: 3
Training loss: 3.1886096000671387
Validation loss: 1.9480184098725677

Epoch: 5| Step: 4
Training loss: 2.3796257972717285
Validation loss: 1.9435365482043194

Epoch: 5| Step: 5
Training loss: 1.9728329181671143
Validation loss: 1.929513172436786

Epoch: 5| Step: 6
Training loss: 2.206362247467041
Validation loss: 1.9490334731276318

Epoch: 5| Step: 7
Training loss: 1.9258308410644531
Validation loss: 1.9231297777545067

Epoch: 5| Step: 8
Training loss: 2.5306148529052734
Validation loss: 1.9394149985364688

Epoch: 5| Step: 9
Training loss: 2.901432514190674
Validation loss: 1.9436362353704308

Epoch: 5| Step: 10
Training loss: 1.8277003765106201
Validation loss: 1.937317080395196

Epoch: 66| Step: 0
Training loss: 2.391449451446533
Validation loss: 1.9378861688798474

Epoch: 5| Step: 1
Training loss: 2.428502321243286
Validation loss: 1.9403062392306585

Epoch: 5| Step: 2
Training loss: 2.333908796310425
Validation loss: 1.9389913953760618

Epoch: 5| Step: 3
Training loss: 2.2604033946990967
Validation loss: 1.9343312107106692

Epoch: 5| Step: 4
Training loss: 2.052945613861084
Validation loss: 1.9244066925459011

Epoch: 5| Step: 5
Training loss: 2.4982399940490723
Validation loss: 1.9361527376277472

Epoch: 5| Step: 6
Training loss: 2.2661688327789307
Validation loss: 1.939506141088342

Epoch: 5| Step: 7
Training loss: 2.395967960357666
Validation loss: 1.9287928176182572

Epoch: 5| Step: 8
Training loss: 1.5485517978668213
Validation loss: 1.932027562972038

Epoch: 5| Step: 9
Training loss: 2.726396083831787
Validation loss: 1.9397527402447117

Epoch: 5| Step: 10
Training loss: 2.10888409614563
Validation loss: 1.930576427008516

Epoch: 67| Step: 0
Training loss: 2.4442646503448486
Validation loss: 1.9252395604246406

Epoch: 5| Step: 1
Training loss: 1.848219871520996
Validation loss: 1.9305938354102514

Epoch: 5| Step: 2
Training loss: 2.8655848503112793
Validation loss: 1.940599609446782

Epoch: 5| Step: 3
Training loss: 1.7492212057113647
Validation loss: 1.9396328951722832

Epoch: 5| Step: 4
Training loss: 1.7369129657745361
Validation loss: 1.9371264237229542

Epoch: 5| Step: 5
Training loss: 2.66654896736145
Validation loss: 1.9384392499923706

Epoch: 5| Step: 6
Training loss: 2.1940367221832275
Validation loss: 1.95114339423436

Epoch: 5| Step: 7
Training loss: 2.2026569843292236
Validation loss: 1.9598408540089924

Epoch: 5| Step: 8
Training loss: 2.879391670227051
Validation loss: 1.9510662376239736

Epoch: 5| Step: 9
Training loss: 1.885589599609375
Validation loss: 1.9446683058174707

Epoch: 5| Step: 10
Training loss: 2.59920334815979
Validation loss: 1.94614323236609

Epoch: 68| Step: 0
Training loss: 2.4506144523620605
Validation loss: 1.9464979517844416

Epoch: 5| Step: 1
Training loss: 2.195263385772705
Validation loss: 1.9531145634189728

Epoch: 5| Step: 2
Training loss: 1.4107744693756104
Validation loss: 1.9284448367293163

Epoch: 5| Step: 3
Training loss: 2.776477098464966
Validation loss: 1.9484446164100402

Epoch: 5| Step: 4
Training loss: 2.4782145023345947
Validation loss: 1.946839108262011

Epoch: 5| Step: 5
Training loss: 2.2555887699127197
Validation loss: 1.9400577288801952

Epoch: 5| Step: 6
Training loss: 2.3357372283935547
Validation loss: 1.9404616278986777

Epoch: 5| Step: 7
Training loss: 2.2531704902648926
Validation loss: 1.9307086890743625

Epoch: 5| Step: 8
Training loss: 2.0415139198303223
Validation loss: 1.9467698950921335

Epoch: 5| Step: 9
Training loss: 2.271050214767456
Validation loss: 1.950308535688667

Epoch: 5| Step: 10
Training loss: 2.471179485321045
Validation loss: 1.937636116499542

Epoch: 69| Step: 0
Training loss: 1.74209725856781
Validation loss: 1.9444253983036164

Epoch: 5| Step: 1
Training loss: 2.395934581756592
Validation loss: 1.9543758182115452

Epoch: 5| Step: 2
Training loss: 2.1444947719573975
Validation loss: 1.9599098095329859

Epoch: 5| Step: 3
Training loss: 2.202213764190674
Validation loss: 1.940721837423181

Epoch: 5| Step: 4
Training loss: 2.4128336906433105
Validation loss: 1.9540523816180486

Epoch: 5| Step: 5
Training loss: 2.518965244293213
Validation loss: 1.9399224532547819

Epoch: 5| Step: 6
Training loss: 2.8710341453552246
Validation loss: 1.9405158860709077

Epoch: 5| Step: 7
Training loss: 2.3323588371276855
Validation loss: 1.9295077926369124

Epoch: 5| Step: 8
Training loss: 1.8123782873153687
Validation loss: 1.95379420890603

Epoch: 5| Step: 9
Training loss: 2.159111499786377
Validation loss: 1.9365446490626181

Epoch: 5| Step: 10
Training loss: 2.2361838817596436
Validation loss: 1.940521119743265

Epoch: 70| Step: 0
Training loss: 2.316906690597534
Validation loss: 1.9648395417838969

Epoch: 5| Step: 1
Training loss: 2.38560152053833
Validation loss: 1.934463700940532

Epoch: 5| Step: 2
Training loss: 2.392850875854492
Validation loss: 1.9483988387610323

Epoch: 5| Step: 3
Training loss: 2.229830741882324
Validation loss: 1.9388223899308072

Epoch: 5| Step: 4
Training loss: 1.943393349647522
Validation loss: 1.9598386967053978

Epoch: 5| Step: 5
Training loss: 2.498171091079712
Validation loss: 1.9407489607411046

Epoch: 5| Step: 6
Training loss: 2.176272392272949
Validation loss: 1.945185189606041

Epoch: 5| Step: 7
Training loss: 2.1131043434143066
Validation loss: 1.9375139513323385

Epoch: 5| Step: 8
Training loss: 2.4246768951416016
Validation loss: 1.9461300629441456

Epoch: 5| Step: 9
Training loss: 2.4391398429870605
Validation loss: 1.934871538992851

Epoch: 5| Step: 10
Training loss: 1.9267504215240479
Validation loss: 1.9323014495193318

Epoch: 71| Step: 0
Training loss: 2.2543511390686035
Validation loss: 1.9549094041188557

Epoch: 5| Step: 1
Training loss: 1.7749288082122803
Validation loss: 1.941434698720132

Epoch: 5| Step: 2
Training loss: 2.191526412963867
Validation loss: 1.9367951321345505

Epoch: 5| Step: 3
Training loss: 2.2343802452087402
Validation loss: 1.9378251696145663

Epoch: 5| Step: 4
Training loss: 1.919938087463379
Validation loss: 1.9332413750310098

Epoch: 5| Step: 5
Training loss: 2.515956401824951
Validation loss: 1.9359776050813737

Epoch: 5| Step: 6
Training loss: 2.278473138809204
Validation loss: 1.9285566704247588

Epoch: 5| Step: 7
Training loss: 2.3252556324005127
Validation loss: 1.9347556226996965

Epoch: 5| Step: 8
Training loss: 2.8290317058563232
Validation loss: 1.9324177144676127

Epoch: 5| Step: 9
Training loss: 1.944130301475525
Validation loss: 1.9327374607004144

Epoch: 5| Step: 10
Training loss: 2.493039131164551
Validation loss: 1.9383792338832733

Epoch: 72| Step: 0
Training loss: 2.2462306022644043
Validation loss: 1.9382925264296993

Epoch: 5| Step: 1
Training loss: 2.0068156719207764
Validation loss: 1.9190970761801607

Epoch: 5| Step: 2
Training loss: 2.272160291671753
Validation loss: 1.9175115375108616

Epoch: 5| Step: 3
Training loss: 2.3985867500305176
Validation loss: 1.9102714651374406

Epoch: 5| Step: 4
Training loss: 1.5317951440811157
Validation loss: 1.9329393089458506

Epoch: 5| Step: 5
Training loss: 2.0188536643981934
Validation loss: 1.9224528471628826

Epoch: 5| Step: 6
Training loss: 2.4974448680877686
Validation loss: 1.9167797206550516

Epoch: 5| Step: 7
Training loss: 2.4940667152404785
Validation loss: 1.938990358383425

Epoch: 5| Step: 8
Training loss: 1.9375898838043213
Validation loss: 1.9175698526443974

Epoch: 5| Step: 9
Training loss: 2.321500539779663
Validation loss: 1.9274603051524009

Epoch: 5| Step: 10
Training loss: 3.0475306510925293
Validation loss: 1.9273899421896985

Epoch: 73| Step: 0
Training loss: 2.317671775817871
Validation loss: 1.9232724584558958

Epoch: 5| Step: 1
Training loss: 2.385100841522217
Validation loss: 1.9267441354772097

Epoch: 5| Step: 2
Training loss: 2.197222948074341
Validation loss: 1.915584461663359

Epoch: 5| Step: 3
Training loss: 2.5448317527770996
Validation loss: 1.942110123172883

Epoch: 5| Step: 4
Training loss: 2.3950047492980957
Validation loss: 1.9236823333206998

Epoch: 5| Step: 5
Training loss: 2.283975601196289
Validation loss: 1.9493955527582476

Epoch: 5| Step: 6
Training loss: 1.7135404348373413
Validation loss: 1.9431976438850485

Epoch: 5| Step: 7
Training loss: 1.7945079803466797
Validation loss: 1.9526847088208763

Epoch: 5| Step: 8
Training loss: 2.553422451019287
Validation loss: 1.940492348004413

Epoch: 5| Step: 9
Training loss: 2.3467888832092285
Validation loss: 1.9472624486492527

Epoch: 5| Step: 10
Training loss: 2.1462719440460205
Validation loss: 1.9310557893527451

Epoch: 74| Step: 0
Training loss: 1.6405506134033203
Validation loss: 1.9091173628325104

Epoch: 5| Step: 1
Training loss: 2.6411209106445312
Validation loss: 1.9328391833971905

Epoch: 5| Step: 2
Training loss: 2.3236539363861084
Validation loss: 1.944437688396823

Epoch: 5| Step: 3
Training loss: 2.392465114593506
Validation loss: 1.9275220119824974

Epoch: 5| Step: 4
Training loss: 1.9617421627044678
Validation loss: 1.9293491994180987

Epoch: 5| Step: 5
Training loss: 1.772094488143921
Validation loss: 1.9245259364446003

Epoch: 5| Step: 6
Training loss: 2.3847451210021973
Validation loss: 1.9208394673562819

Epoch: 5| Step: 7
Training loss: 2.7848169803619385
Validation loss: 1.9104827744986421

Epoch: 5| Step: 8
Training loss: 2.4287266731262207
Validation loss: 1.914240324369041

Epoch: 5| Step: 9
Training loss: 2.2054150104522705
Validation loss: 1.9219443605792137

Epoch: 5| Step: 10
Training loss: 2.089261293411255
Validation loss: 1.9136034122077368

Epoch: 75| Step: 0
Training loss: 1.7886139154434204
Validation loss: 1.9464120018866755

Epoch: 5| Step: 1
Training loss: 2.65498423576355
Validation loss: 1.9408923631073327

Epoch: 5| Step: 2
Training loss: 2.227783203125
Validation loss: 1.9219002518602597

Epoch: 5| Step: 3
Training loss: 2.267401933670044
Validation loss: 1.9240258034839426

Epoch: 5| Step: 4
Training loss: 2.329738140106201
Validation loss: 1.9406776018040155

Epoch: 5| Step: 5
Training loss: 2.0852160453796387
Validation loss: 1.9502899134030907

Epoch: 5| Step: 6
Training loss: 1.9043457508087158
Validation loss: 1.9442523192333918

Epoch: 5| Step: 7
Training loss: 2.472332000732422
Validation loss: 1.9449489603760421

Epoch: 5| Step: 8
Training loss: 2.598360776901245
Validation loss: 1.9462314369857951

Epoch: 5| Step: 9
Training loss: 2.182676315307617
Validation loss: 1.9550531282219836

Epoch: 5| Step: 10
Training loss: 2.0420501232147217
Validation loss: 1.958533440866778

Epoch: 76| Step: 0
Training loss: 2.2762093544006348
Validation loss: 1.955946022464383

Epoch: 5| Step: 1
Training loss: 2.7430813312530518
Validation loss: 1.9465619723002117

Epoch: 5| Step: 2
Training loss: 2.6616358757019043
Validation loss: 1.9388335186948058

Epoch: 5| Step: 3
Training loss: 1.8967876434326172
Validation loss: 1.9478103537713327

Epoch: 5| Step: 4
Training loss: 2.2506585121154785
Validation loss: 1.9479464010525775

Epoch: 5| Step: 5
Training loss: 1.8499698638916016
Validation loss: 1.9404177499073807

Epoch: 5| Step: 6
Training loss: 2.8360233306884766
Validation loss: 1.935015231050471

Epoch: 5| Step: 7
Training loss: 2.0567471981048584
Validation loss: 1.9310791851371847

Epoch: 5| Step: 8
Training loss: 1.7797653675079346
Validation loss: 1.9414886838646346

Epoch: 5| Step: 9
Training loss: 1.9683027267456055
Validation loss: 1.924783081136724

Epoch: 5| Step: 10
Training loss: 2.2802011966705322
Validation loss: 1.939362746413036

Epoch: 77| Step: 0
Training loss: 2.0465450286865234
Validation loss: 1.9333245113331785

Epoch: 5| Step: 1
Training loss: 2.552858829498291
Validation loss: 1.9417178656465264

Epoch: 5| Step: 2
Training loss: 2.334512710571289
Validation loss: 1.9401032206832722

Epoch: 5| Step: 3
Training loss: 1.9073034524917603
Validation loss: 1.9390673765572168

Epoch: 5| Step: 4
Training loss: 2.196302890777588
Validation loss: 1.9594171008756083

Epoch: 5| Step: 5
Training loss: 2.3176379203796387
Validation loss: 1.9469588956525248

Epoch: 5| Step: 6
Training loss: 2.239042282104492
Validation loss: 1.9354024497411584

Epoch: 5| Step: 7
Training loss: 1.9827674627304077
Validation loss: 1.9419870645769182

Epoch: 5| Step: 8
Training loss: 2.4032492637634277
Validation loss: 1.9479134300703644

Epoch: 5| Step: 9
Training loss: 2.3100664615631104
Validation loss: 1.9379447121773996

Epoch: 5| Step: 10
Training loss: 2.2066140174865723
Validation loss: 1.9271066060630224

Epoch: 78| Step: 0
Training loss: 2.4219157695770264
Validation loss: 1.9406463740974345

Epoch: 5| Step: 1
Training loss: 1.7594070434570312
Validation loss: 1.923593799273173

Epoch: 5| Step: 2
Training loss: 2.675295352935791
Validation loss: 1.9415604017114128

Epoch: 5| Step: 3
Training loss: 2.311951160430908
Validation loss: 1.9458558815781788

Epoch: 5| Step: 4
Training loss: 2.309724807739258
Validation loss: 1.943435933000298

Epoch: 5| Step: 5
Training loss: 2.0134851932525635
Validation loss: 1.9397500817493727

Epoch: 5| Step: 6
Training loss: 2.513728141784668
Validation loss: 1.9521230805304743

Epoch: 5| Step: 7
Training loss: 2.0998895168304443
Validation loss: 1.931304734240296

Epoch: 5| Step: 8
Training loss: 2.024158239364624
Validation loss: 1.92424609199647

Epoch: 5| Step: 9
Training loss: 1.8637605905532837
Validation loss: 1.9186579604302683

Epoch: 5| Step: 10
Training loss: 2.5328376293182373
Validation loss: 1.9214743132232337

Epoch: 79| Step: 0
Training loss: 2.327518939971924
Validation loss: 1.9334349401535527

Epoch: 5| Step: 1
Training loss: 2.121920585632324
Validation loss: 1.92752496786015

Epoch: 5| Step: 2
Training loss: 2.244694948196411
Validation loss: 1.9290448491291334

Epoch: 5| Step: 3
Training loss: 1.8008677959442139
Validation loss: 1.921578532905989

Epoch: 5| Step: 4
Training loss: 2.218679666519165
Validation loss: 1.9234806658119283

Epoch: 5| Step: 5
Training loss: 2.592766046524048
Validation loss: 1.9218017055142311

Epoch: 5| Step: 6
Training loss: 2.1127071380615234
Validation loss: 1.9050957592584754

Epoch: 5| Step: 7
Training loss: 2.5156149864196777
Validation loss: 1.9410883111338462

Epoch: 5| Step: 8
Training loss: 2.6596498489379883
Validation loss: 1.9197934699314896

Epoch: 5| Step: 9
Training loss: 2.01094388961792
Validation loss: 1.9371605355252501

Epoch: 5| Step: 10
Training loss: 1.6950287818908691
Validation loss: 1.912882843325215

Epoch: 80| Step: 0
Training loss: 2.079406261444092
Validation loss: 1.927103316912087

Epoch: 5| Step: 1
Training loss: 2.2756173610687256
Validation loss: 1.9435884708999305

Epoch: 5| Step: 2
Training loss: 2.4936375617980957
Validation loss: 1.9416997278890302

Epoch: 5| Step: 3
Training loss: 2.487973690032959
Validation loss: 1.9171288116003877

Epoch: 5| Step: 4
Training loss: 2.2039601802825928
Validation loss: 1.9285334861406715

Epoch: 5| Step: 5
Training loss: 1.6508963108062744
Validation loss: 1.9177739120298816

Epoch: 5| Step: 6
Training loss: 1.8824924230575562
Validation loss: 1.9348210737269411

Epoch: 5| Step: 7
Training loss: 2.613798141479492
Validation loss: 1.9385842302794098

Epoch: 5| Step: 8
Training loss: 2.497230052947998
Validation loss: 1.91368269407621

Epoch: 5| Step: 9
Training loss: 2.248784303665161
Validation loss: 1.9267817569035355

Epoch: 5| Step: 10
Training loss: 1.7247982025146484
Validation loss: 1.9335175419366488

Epoch: 81| Step: 0
Training loss: 1.8058834075927734
Validation loss: 1.9248385224291074

Epoch: 5| Step: 1
Training loss: 2.3643953800201416
Validation loss: 1.9455734375984437

Epoch: 5| Step: 2
Training loss: 1.9640264511108398
Validation loss: 1.9276426299925773

Epoch: 5| Step: 3
Training loss: 1.9644572734832764
Validation loss: 1.9332114675993561

Epoch: 5| Step: 4
Training loss: 2.2137398719787598
Validation loss: 1.9324971219544769

Epoch: 5| Step: 5
Training loss: 2.537945508956909
Validation loss: 1.925761656094623

Epoch: 5| Step: 6
Training loss: 2.538440704345703
Validation loss: 1.9227981567382812

Epoch: 5| Step: 7
Training loss: 1.8770215511322021
Validation loss: 1.9356135642656715

Epoch: 5| Step: 8
Training loss: 2.6480586528778076
Validation loss: 1.9278699967168993

Epoch: 5| Step: 9
Training loss: 1.9300076961517334
Validation loss: 1.9284999088574482

Epoch: 5| Step: 10
Training loss: 2.5875535011291504
Validation loss: 1.9345911933529762

Epoch: 82| Step: 0
Training loss: 1.9793694019317627
Validation loss: 1.9312553149397655

Epoch: 5| Step: 1
Training loss: 2.0919277667999268
Validation loss: 1.9526380723522556

Epoch: 5| Step: 2
Training loss: 2.326049327850342
Validation loss: 1.9218940273407967

Epoch: 5| Step: 3
Training loss: 2.255232334136963
Validation loss: 1.9535502913177654

Epoch: 5| Step: 4
Training loss: 2.5407490730285645
Validation loss: 1.9664530190088416

Epoch: 5| Step: 5
Training loss: 1.8045669794082642
Validation loss: 1.971543001872237

Epoch: 5| Step: 6
Training loss: 2.3983840942382812
Validation loss: 1.9578880904823222

Epoch: 5| Step: 7
Training loss: 2.1387767791748047
Validation loss: 1.9534482468840897

Epoch: 5| Step: 8
Training loss: 2.538081645965576
Validation loss: 1.9514926723254624

Epoch: 5| Step: 9
Training loss: 2.3521761894226074
Validation loss: 1.955484724813892

Epoch: 5| Step: 10
Training loss: 1.8051958084106445
Validation loss: 1.9417312068323935

Epoch: 83| Step: 0
Training loss: 2.0635972023010254
Validation loss: 1.9508958619127992

Epoch: 5| Step: 1
Training loss: 2.088956832885742
Validation loss: 1.9422056944139543

Epoch: 5| Step: 2
Training loss: 1.8846921920776367
Validation loss: 1.95518236519188

Epoch: 5| Step: 3
Training loss: 2.3675107955932617
Validation loss: 1.9460500658199351

Epoch: 5| Step: 4
Training loss: 1.8481899499893188
Validation loss: 1.9446415747365644

Epoch: 5| Step: 5
Training loss: 2.155761241912842
Validation loss: 1.9359402502736738

Epoch: 5| Step: 6
Training loss: 2.9060885906219482
Validation loss: 1.9296053096812258

Epoch: 5| Step: 7
Training loss: 2.540193557739258
Validation loss: 1.93533294944353

Epoch: 5| Step: 8
Training loss: 2.3908498287200928
Validation loss: 1.9268891580643193

Epoch: 5| Step: 9
Training loss: 2.2401866912841797
Validation loss: 1.9493511851115892

Epoch: 5| Step: 10
Training loss: 1.7927528619766235
Validation loss: 1.9383939184168333

Epoch: 84| Step: 0
Training loss: 2.203209400177002
Validation loss: 1.9452228828143048

Epoch: 5| Step: 1
Training loss: 1.5717626810073853
Validation loss: 1.937748985905801

Epoch: 5| Step: 2
Training loss: 1.925347924232483
Validation loss: 1.9213971399491834

Epoch: 5| Step: 3
Training loss: 2.311614513397217
Validation loss: 1.9318008269033125

Epoch: 5| Step: 4
Training loss: 2.536055326461792
Validation loss: 1.9245269298553467

Epoch: 5| Step: 5
Training loss: 2.88486647605896
Validation loss: 1.9318239022326726

Epoch: 5| Step: 6
Training loss: 2.3906631469726562
Validation loss: 1.9360201589522823

Epoch: 5| Step: 7
Training loss: 1.6995683908462524
Validation loss: 1.9441337059902888

Epoch: 5| Step: 8
Training loss: 2.2614173889160156
Validation loss: 1.9428577807641798

Epoch: 5| Step: 9
Training loss: 1.809593915939331
Validation loss: 1.9637601785762335

Epoch: 5| Step: 10
Training loss: 2.7092154026031494
Validation loss: 1.9545789687864241

Epoch: 85| Step: 0
Training loss: 2.3151698112487793
Validation loss: 1.9472669747567946

Epoch: 5| Step: 1
Training loss: 1.5154989957809448
Validation loss: 1.9323998523014847

Epoch: 5| Step: 2
Training loss: 2.5664145946502686
Validation loss: 1.9300988797218568

Epoch: 5| Step: 3
Training loss: 2.0529515743255615
Validation loss: 1.9300302895166541

Epoch: 5| Step: 4
Training loss: 2.301413059234619
Validation loss: 1.9293071762208016

Epoch: 5| Step: 5
Training loss: 2.5920634269714355
Validation loss: 1.9095578821756507

Epoch: 5| Step: 6
Training loss: 2.271853446960449
Validation loss: 1.930798049895994

Epoch: 5| Step: 7
Training loss: 2.1454148292541504
Validation loss: 1.918024601474885

Epoch: 5| Step: 8
Training loss: 2.395564556121826
Validation loss: 1.924732441543251

Epoch: 5| Step: 9
Training loss: 1.8346726894378662
Validation loss: 1.9328364121016635

Epoch: 5| Step: 10
Training loss: 2.2359158992767334
Validation loss: 1.915082130380856

Epoch: 86| Step: 0
Training loss: 1.9319034814834595
Validation loss: 1.93259939711581

Epoch: 5| Step: 1
Training loss: 1.7260128259658813
Validation loss: 1.9120892619573941

Epoch: 5| Step: 2
Training loss: 2.306734561920166
Validation loss: 1.9326816502437796

Epoch: 5| Step: 3
Training loss: 2.303417921066284
Validation loss: 1.927555307265251

Epoch: 5| Step: 4
Training loss: 2.6186776161193848
Validation loss: 1.9226925347440986

Epoch: 5| Step: 5
Training loss: 2.14461612701416
Validation loss: 1.9476706520203622

Epoch: 5| Step: 6
Training loss: 1.9158738851547241
Validation loss: 1.9405131006753573

Epoch: 5| Step: 7
Training loss: 2.317262887954712
Validation loss: 1.9161241310898975

Epoch: 5| Step: 8
Training loss: 2.39250111579895
Validation loss: 1.9571107100414973

Epoch: 5| Step: 9
Training loss: 2.048081636428833
Validation loss: 1.9436155288450179

Epoch: 5| Step: 10
Training loss: 2.5106000900268555
Validation loss: 1.9354631593150478

Epoch: 87| Step: 0
Training loss: 1.9707648754119873
Validation loss: 1.9529436865160543

Epoch: 5| Step: 1
Training loss: 2.038769006729126
Validation loss: 1.9677199189380934

Epoch: 5| Step: 2
Training loss: 2.3069539070129395
Validation loss: 1.9447286872453586

Epoch: 5| Step: 3
Training loss: 3.118431806564331
Validation loss: 1.9406282235217351

Epoch: 5| Step: 4
Training loss: 1.8221698999404907
Validation loss: 1.943393321447475

Epoch: 5| Step: 5
Training loss: 2.2799479961395264
Validation loss: 1.9480427862495504

Epoch: 5| Step: 6
Training loss: 2.290921211242676
Validation loss: 1.9416173427335677

Epoch: 5| Step: 7
Training loss: 2.643540143966675
Validation loss: 1.950719638537335

Epoch: 5| Step: 8
Training loss: 2.242405652999878
Validation loss: 1.9518222629383046

Epoch: 5| Step: 9
Training loss: 1.4184813499450684
Validation loss: 1.9622416265549198

Epoch: 5| Step: 10
Training loss: 1.9747260808944702
Validation loss: 1.9661268970017791

Epoch: 88| Step: 0
Training loss: 1.8777029514312744
Validation loss: 1.9470810403106034

Epoch: 5| Step: 1
Training loss: 2.871359348297119
Validation loss: 1.9315102741282473

Epoch: 5| Step: 2
Training loss: 2.254560947418213
Validation loss: 1.9516267930307696

Epoch: 5| Step: 3
Training loss: 1.4664605855941772
Validation loss: 1.9514898023297709

Epoch: 5| Step: 4
Training loss: 2.4170539379119873
Validation loss: 1.9630148039069226

Epoch: 5| Step: 5
Training loss: 1.746168851852417
Validation loss: 1.952786184126331

Epoch: 5| Step: 6
Training loss: 2.214000940322876
Validation loss: 1.9438298158748175

Epoch: 5| Step: 7
Training loss: 2.6247785091400146
Validation loss: 1.9473707983570714

Epoch: 5| Step: 8
Training loss: 2.250532865524292
Validation loss: 1.9220255574872416

Epoch: 5| Step: 9
Training loss: 1.9012718200683594
Validation loss: 1.9641261959588656

Epoch: 5| Step: 10
Training loss: 2.4745876789093018
Validation loss: 1.9317419836598058

Epoch: 89| Step: 0
Training loss: 2.2562546730041504
Validation loss: 1.9483959713289816

Epoch: 5| Step: 1
Training loss: 2.02327036857605
Validation loss: 1.9520595983792377

Epoch: 5| Step: 2
Training loss: 1.8471218347549438
Validation loss: 1.9528722096514959

Epoch: 5| Step: 3
Training loss: 2.1368460655212402
Validation loss: 1.9362745784944104

Epoch: 5| Step: 4
Training loss: 2.7540993690490723
Validation loss: 1.9210874072967037

Epoch: 5| Step: 5
Training loss: 1.8284151554107666
Validation loss: 1.9330703596914969

Epoch: 5| Step: 6
Training loss: 2.1213414669036865
Validation loss: 1.9262604803167365

Epoch: 5| Step: 7
Training loss: 2.2802300453186035
Validation loss: 1.9249728161801574

Epoch: 5| Step: 8
Training loss: 1.8042974472045898
Validation loss: 1.9182659656770769

Epoch: 5| Step: 9
Training loss: 2.0722784996032715
Validation loss: 1.9547850137115808

Epoch: 5| Step: 10
Training loss: 2.984065532684326
Validation loss: 1.9426900673938055

Epoch: 90| Step: 0
Training loss: 2.082695245742798
Validation loss: 1.944059702657884

Epoch: 5| Step: 1
Training loss: 2.299431324005127
Validation loss: 1.957854534990044

Epoch: 5| Step: 2
Training loss: 1.846090316772461
Validation loss: 1.934407111137144

Epoch: 5| Step: 3
Training loss: 2.265589475631714
Validation loss: 1.938348759887039

Epoch: 5| Step: 4
Training loss: 2.2138943672180176
Validation loss: 1.962107766059137

Epoch: 5| Step: 5
Training loss: 2.3508682250976562
Validation loss: 1.931108881068486

Epoch: 5| Step: 6
Training loss: 1.3749070167541504
Validation loss: 1.9445347965404551

Epoch: 5| Step: 7
Training loss: 2.213120937347412
Validation loss: 1.9339644780722998

Epoch: 5| Step: 8
Training loss: 2.821117877960205
Validation loss: 1.9373837068516722

Epoch: 5| Step: 9
Training loss: 2.091426372528076
Validation loss: 1.9436031067243187

Epoch: 5| Step: 10
Training loss: 2.4848220348358154
Validation loss: 1.9314094410147717

Epoch: 91| Step: 0
Training loss: 1.7868406772613525
Validation loss: 1.959659722543532

Epoch: 5| Step: 1
Training loss: 2.2804551124572754
Validation loss: 1.9498181266169394

Epoch: 5| Step: 2
Training loss: 2.1460771560668945
Validation loss: 1.959341231212821

Epoch: 5| Step: 3
Training loss: 1.9759753942489624
Validation loss: 1.9464852835542412

Epoch: 5| Step: 4
Training loss: 2.4482054710388184
Validation loss: 1.9618116912021433

Epoch: 5| Step: 5
Training loss: 2.4207682609558105
Validation loss: 1.9488337937221731

Epoch: 5| Step: 6
Training loss: 1.6284115314483643
Validation loss: 1.9597789523422078

Epoch: 5| Step: 7
Training loss: 2.1682991981506348
Validation loss: 1.9597615195858864

Epoch: 5| Step: 8
Training loss: 2.516019105911255
Validation loss: 1.9709686925334315

Epoch: 5| Step: 9
Training loss: 2.164077043533325
Validation loss: 1.945041537284851

Epoch: 5| Step: 10
Training loss: 2.5662882328033447
Validation loss: 1.9792981250311739

Epoch: 92| Step: 0
Training loss: 2.6717429161071777
Validation loss: 1.957211148354315

Epoch: 5| Step: 1
Training loss: 2.483454704284668
Validation loss: 1.9624678088772682

Epoch: 5| Step: 2
Training loss: 1.612572431564331
Validation loss: 1.9507522698371642

Epoch: 5| Step: 3
Training loss: 2.1982107162475586
Validation loss: 1.9610466521273378

Epoch: 5| Step: 4
Training loss: 2.667539119720459
Validation loss: 1.9478000440905172

Epoch: 5| Step: 5
Training loss: 2.692007541656494
Validation loss: 1.963705429466822

Epoch: 5| Step: 6
Training loss: 2.0129003524780273
Validation loss: 1.9510896962176087

Epoch: 5| Step: 7
Training loss: 1.6399933099746704
Validation loss: 1.9596346257835306

Epoch: 5| Step: 8
Training loss: 2.1320557594299316
Validation loss: 1.949578462108489

Epoch: 5| Step: 9
Training loss: 1.6725311279296875
Validation loss: 1.9421381745287167

Epoch: 5| Step: 10
Training loss: 2.1530933380126953
Validation loss: 1.9531865017388457

Epoch: 93| Step: 0
Training loss: 1.789899468421936
Validation loss: 1.9461555570684455

Epoch: 5| Step: 1
Training loss: 2.04616379737854
Validation loss: 1.946954814336633

Epoch: 5| Step: 2
Training loss: 2.468287944793701
Validation loss: 1.9320721946736819

Epoch: 5| Step: 3
Training loss: 2.173931121826172
Validation loss: 1.9294866887472009

Epoch: 5| Step: 4
Training loss: 1.8677904605865479
Validation loss: 1.9183552175439813

Epoch: 5| Step: 5
Training loss: 2.2005045413970947
Validation loss: 1.9292494532882527

Epoch: 5| Step: 6
Training loss: 2.6682915687561035
Validation loss: 1.9310556124615412

Epoch: 5| Step: 7
Training loss: 2.383244037628174
Validation loss: 1.9483222730698124

Epoch: 5| Step: 8
Training loss: 2.080387592315674
Validation loss: 1.919849241933515

Epoch: 5| Step: 9
Training loss: 2.092430353164673
Validation loss: 1.9269580738518828

Epoch: 5| Step: 10
Training loss: 2.0739643573760986
Validation loss: 1.926600315237558

Epoch: 94| Step: 0
Training loss: 2.0416719913482666
Validation loss: 1.9446752686654367

Epoch: 5| Step: 1
Training loss: 1.8349769115447998
Validation loss: 1.9442712235194382

Epoch: 5| Step: 2
Training loss: 1.740139365196228
Validation loss: 1.9427028035604825

Epoch: 5| Step: 3
Training loss: 2.1790928840637207
Validation loss: 1.9351415711064492

Epoch: 5| Step: 4
Training loss: 2.7542402744293213
Validation loss: 1.9430547580924085

Epoch: 5| Step: 5
Training loss: 2.213134765625
Validation loss: 1.928425096696423

Epoch: 5| Step: 6
Training loss: 2.2506184577941895
Validation loss: 1.9293993288470852

Epoch: 5| Step: 7
Training loss: 2.3221447467803955
Validation loss: 1.9134520946010467

Epoch: 5| Step: 8
Training loss: 1.8414366245269775
Validation loss: 1.9413442457875898

Epoch: 5| Step: 9
Training loss: 2.3908820152282715
Validation loss: 1.9310268138044624

Epoch: 5| Step: 10
Training loss: 2.3998169898986816
Validation loss: 1.929328244219544

Epoch: 95| Step: 0
Training loss: 2.734837055206299
Validation loss: 1.9380171862981652

Epoch: 5| Step: 1
Training loss: 2.627880811691284
Validation loss: 1.9268292547554098

Epoch: 5| Step: 2
Training loss: 2.1542365550994873
Validation loss: 1.9424112599383119

Epoch: 5| Step: 3
Training loss: 1.7020397186279297
Validation loss: 1.9381991509468324

Epoch: 5| Step: 4
Training loss: 2.3142573833465576
Validation loss: 1.9255194407637402

Epoch: 5| Step: 5
Training loss: 1.5951299667358398
Validation loss: 1.9432238353196012

Epoch: 5| Step: 6
Training loss: 1.7818078994750977
Validation loss: 1.919165120329908

Epoch: 5| Step: 7
Training loss: 1.9125820398330688
Validation loss: 1.9360136447414276

Epoch: 5| Step: 8
Training loss: 2.7871594429016113
Validation loss: 1.9447162305155108

Epoch: 5| Step: 9
Training loss: 1.8274238109588623
Validation loss: 1.9189233087724256

Epoch: 5| Step: 10
Training loss: 2.5186431407928467
Validation loss: 1.9402824550546625

Epoch: 96| Step: 0
Training loss: 2.3258345127105713
Validation loss: 1.923198389750655

Epoch: 5| Step: 1
Training loss: 2.382962226867676
Validation loss: 1.9241239101656022

Epoch: 5| Step: 2
Training loss: 2.019186496734619
Validation loss: 1.92617166555056

Epoch: 5| Step: 3
Training loss: 1.6721969842910767
Validation loss: 1.9470943853419314

Epoch: 5| Step: 4
Training loss: 2.2808356285095215
Validation loss: 1.9453581943306872

Epoch: 5| Step: 5
Training loss: 1.8962781429290771
Validation loss: 1.9443525319458337

Epoch: 5| Step: 6
Training loss: 2.296977996826172
Validation loss: 1.9339701578181276

Epoch: 5| Step: 7
Training loss: 2.63020658493042
Validation loss: 1.9688389480754893

Epoch: 5| Step: 8
Training loss: 2.398036241531372
Validation loss: 1.9549042742739442

Epoch: 5| Step: 9
Training loss: 2.3624415397644043
Validation loss: 1.9676678770331926

Epoch: 5| Step: 10
Training loss: 1.3341349363327026
Validation loss: 1.9802581366672312

Epoch: 97| Step: 0
Training loss: 1.8205369710922241
Validation loss: 1.9748321117893342

Epoch: 5| Step: 1
Training loss: 2.4169669151306152
Validation loss: 1.9752821871029433

Epoch: 5| Step: 2
Training loss: 1.7980353832244873
Validation loss: 1.9838657648332658

Epoch: 5| Step: 3
Training loss: 1.7274658679962158
Validation loss: 1.9636125923484884

Epoch: 5| Step: 4
Training loss: 2.095949649810791
Validation loss: 1.9510159415583457

Epoch: 5| Step: 5
Training loss: 2.623812675476074
Validation loss: 1.9813747277823828

Epoch: 5| Step: 6
Training loss: 2.822679042816162
Validation loss: 1.9534682676356325

Epoch: 5| Step: 7
Training loss: 2.02547025680542
Validation loss: 1.9486919744040376

Epoch: 5| Step: 8
Training loss: 1.813265085220337
Validation loss: 1.9375353577316448

Epoch: 5| Step: 9
Training loss: 2.301095724105835
Validation loss: 1.951825285470614

Epoch: 5| Step: 10
Training loss: 2.3706588745117188
Validation loss: 1.9607006785690144

Epoch: 98| Step: 0
Training loss: 1.7978746891021729
Validation loss: 1.9531590861658896

Epoch: 5| Step: 1
Training loss: 2.558029890060425
Validation loss: 1.9517476058775378

Epoch: 5| Step: 2
Training loss: 1.5391662120819092
Validation loss: 1.960747467574253

Epoch: 5| Step: 3
Training loss: 2.337522268295288
Validation loss: 1.950898584499154

Epoch: 5| Step: 4
Training loss: 1.9600369930267334
Validation loss: 1.9548924917815833

Epoch: 5| Step: 5
Training loss: 2.14924693107605
Validation loss: 1.9637711381399503

Epoch: 5| Step: 6
Training loss: 2.9848787784576416
Validation loss: 1.9643670769147976

Epoch: 5| Step: 7
Training loss: 1.9619487524032593
Validation loss: 1.9452574137718446

Epoch: 5| Step: 8
Training loss: 1.9295107126235962
Validation loss: 1.9439062328748806

Epoch: 5| Step: 9
Training loss: 2.5777862071990967
Validation loss: 1.9608257880774878

Epoch: 5| Step: 10
Training loss: 1.9891514778137207
Validation loss: 1.9469291266574655

Epoch: 99| Step: 0
Training loss: 1.9177364110946655
Validation loss: 1.95665225162301

Epoch: 5| Step: 1
Training loss: 2.008277177810669
Validation loss: 1.97217607754533

Epoch: 5| Step: 2
Training loss: 2.2206504344940186
Validation loss: 1.967495834955605

Epoch: 5| Step: 3
Training loss: 2.4975640773773193
Validation loss: 1.9427631003882295

Epoch: 5| Step: 4
Training loss: 1.8574225902557373
Validation loss: 1.9654744722509896

Epoch: 5| Step: 5
Training loss: 1.795668601989746
Validation loss: 1.9383919662044895

Epoch: 5| Step: 6
Training loss: 1.9255523681640625
Validation loss: 1.9422376412217335

Epoch: 5| Step: 7
Training loss: 1.845536470413208
Validation loss: 1.959297037893726

Epoch: 5| Step: 8
Training loss: 2.48785400390625
Validation loss: 1.9531606422957553

Epoch: 5| Step: 9
Training loss: 2.8565266132354736
Validation loss: 1.9502997090739589

Epoch: 5| Step: 10
Training loss: 2.3919870853424072
Validation loss: 1.9524310814437045

Epoch: 100| Step: 0
Training loss: 2.0607082843780518
Validation loss: 1.9534790900445753

Epoch: 5| Step: 1
Training loss: 2.415339946746826
Validation loss: 1.9476978202019968

Epoch: 5| Step: 2
Training loss: 2.0516598224639893
Validation loss: 1.9553185406551565

Epoch: 5| Step: 3
Training loss: 2.5797500610351562
Validation loss: 1.9315279632486322

Epoch: 5| Step: 4
Training loss: 2.202981472015381
Validation loss: 1.9528470859732678

Epoch: 5| Step: 5
Training loss: 2.757416248321533
Validation loss: 1.9365063354533205

Epoch: 5| Step: 6
Training loss: 1.9336131811141968
Validation loss: 1.943347309225349

Epoch: 5| Step: 7
Training loss: 1.969738245010376
Validation loss: 1.9435896078745525

Epoch: 5| Step: 8
Training loss: 1.8977206945419312
Validation loss: 1.958222395630293

Epoch: 5| Step: 9
Training loss: 1.6548080444335938
Validation loss: 1.9460840609765822

Epoch: 5| Step: 10
Training loss: 2.3794050216674805
Validation loss: 1.9359075971828994

Epoch: 101| Step: 0
Training loss: 2.0374913215637207
Validation loss: 1.9445966853890368

Epoch: 5| Step: 1
Training loss: 2.225520372390747
Validation loss: 1.9601631254278205

Epoch: 5| Step: 2
Training loss: 1.6134687662124634
Validation loss: 1.950151522954305

Epoch: 5| Step: 3
Training loss: 2.0102086067199707
Validation loss: 1.9431837835619528

Epoch: 5| Step: 4
Training loss: 2.206813097000122
Validation loss: 1.9750433045048867

Epoch: 5| Step: 5
Training loss: 2.4539124965667725
Validation loss: 1.9657648994076637

Epoch: 5| Step: 6
Training loss: 2.2281556129455566
Validation loss: 1.9753104576500513

Epoch: 5| Step: 7
Training loss: 2.327747344970703
Validation loss: 1.9884440142621276

Epoch: 5| Step: 8
Training loss: 2.583496332168579
Validation loss: 1.991287298099969

Epoch: 5| Step: 9
Training loss: 2.195706844329834
Validation loss: 1.9713809849113546

Epoch: 5| Step: 10
Training loss: 1.9668525457382202
Validation loss: 1.9635968387767833

Epoch: 102| Step: 0
Training loss: 2.4234871864318848
Validation loss: 1.981319014744092

Epoch: 5| Step: 1
Training loss: 2.3659701347351074
Validation loss: 1.9788257524531374

Epoch: 5| Step: 2
Training loss: 2.1139845848083496
Validation loss: 1.9768115346149733

Epoch: 5| Step: 3
Training loss: 2.161713123321533
Validation loss: 1.9725813301660682

Epoch: 5| Step: 4
Training loss: 2.2208237648010254
Validation loss: 1.9720818791338193

Epoch: 5| Step: 5
Training loss: 2.4701104164123535
Validation loss: 1.9704441985776346

Epoch: 5| Step: 6
Training loss: 1.8460686206817627
Validation loss: 1.9729272524515789

Epoch: 5| Step: 7
Training loss: 1.9790751934051514
Validation loss: 1.968631270111248

Epoch: 5| Step: 8
Training loss: 2.1960034370422363
Validation loss: 1.9835983719877017

Epoch: 5| Step: 9
Training loss: 1.9540942907333374
Validation loss: 1.9614188696748467

Epoch: 5| Step: 10
Training loss: 1.9031628370285034
Validation loss: 1.973494037505119

Epoch: 103| Step: 0
Training loss: 1.9246177673339844
Validation loss: 1.952976192197492

Epoch: 5| Step: 1
Training loss: 2.424165725708008
Validation loss: 1.9507763321681688

Epoch: 5| Step: 2
Training loss: 2.5859971046447754
Validation loss: 1.9662798245747883

Epoch: 5| Step: 3
Training loss: 2.2281274795532227
Validation loss: 1.9620544628430439

Epoch: 5| Step: 4
Training loss: 1.9713369607925415
Validation loss: 1.9668272169687415

Epoch: 5| Step: 5
Training loss: 2.27951979637146
Validation loss: 1.9588766956842074

Epoch: 5| Step: 6
Training loss: 1.640223741531372
Validation loss: 1.9399474487509778

Epoch: 5| Step: 7
Training loss: 2.0075602531433105
Validation loss: 1.9524349333137594

Epoch: 5| Step: 8
Training loss: 2.1500887870788574
Validation loss: 1.9592865000488937

Epoch: 5| Step: 9
Training loss: 2.119788885116577
Validation loss: 1.951429836211666

Epoch: 5| Step: 10
Training loss: 2.3348445892333984
Validation loss: 1.9447861666320472

Epoch: 104| Step: 0
Training loss: 2.0962910652160645
Validation loss: 1.94247785434928

Epoch: 5| Step: 1
Training loss: 2.5277419090270996
Validation loss: 1.9425310896288963

Epoch: 5| Step: 2
Training loss: 2.4669101238250732
Validation loss: 1.9442035869885517

Epoch: 5| Step: 3
Training loss: 2.2488186359405518
Validation loss: 1.9495082183550763

Epoch: 5| Step: 4
Training loss: 2.9496867656707764
Validation loss: 1.946793790786497

Epoch: 5| Step: 5
Training loss: 1.8805691003799438
Validation loss: 1.9548699355894519

Epoch: 5| Step: 6
Training loss: 1.7158759832382202
Validation loss: 1.9474901537741385

Epoch: 5| Step: 7
Training loss: 2.186023235321045
Validation loss: 1.9624975009631085

Epoch: 5| Step: 8
Training loss: 1.8671817779541016
Validation loss: 1.9489276985968313

Epoch: 5| Step: 9
Training loss: 1.9026310443878174
Validation loss: 1.9744464787103797

Epoch: 5| Step: 10
Training loss: 1.8132190704345703
Validation loss: 1.9561468708899714

Epoch: 105| Step: 0
Training loss: 2.511427402496338
Validation loss: 1.9663712388725691

Epoch: 5| Step: 1
Training loss: 1.922485113143921
Validation loss: 1.9529029502663562

Epoch: 5| Step: 2
Training loss: 2.498589277267456
Validation loss: 1.9499592268338768

Epoch: 5| Step: 3
Training loss: 1.7446565628051758
Validation loss: 1.946898598824778

Epoch: 5| Step: 4
Training loss: 2.0638718605041504
Validation loss: 1.9450077856740644

Epoch: 5| Step: 5
Training loss: 2.038287878036499
Validation loss: 1.9478156771711124

Epoch: 5| Step: 6
Training loss: 2.0691840648651123
Validation loss: 1.9527056858103762

Epoch: 5| Step: 7
Training loss: 2.457188367843628
Validation loss: 1.9736510553667623

Epoch: 5| Step: 8
Training loss: 2.2390217781066895
Validation loss: 1.983867658081875

Epoch: 5| Step: 9
Training loss: 1.9989782571792603
Validation loss: 1.964146001364595

Epoch: 5| Step: 10
Training loss: 1.9892535209655762
Validation loss: 1.9761037249718942

Epoch: 106| Step: 0
Training loss: 2.3539376258850098
Validation loss: 1.968882167211143

Epoch: 5| Step: 1
Training loss: 2.3951163291931152
Validation loss: 1.9611762236523371

Epoch: 5| Step: 2
Training loss: 1.9641458988189697
Validation loss: 1.9865462318543465

Epoch: 5| Step: 3
Training loss: 2.002570152282715
Validation loss: 1.972294924079731

Epoch: 5| Step: 4
Training loss: 2.156033992767334
Validation loss: 1.9774801705473213

Epoch: 5| Step: 5
Training loss: 2.034763813018799
Validation loss: 1.9705084190573743

Epoch: 5| Step: 6
Training loss: 2.2491865158081055
Validation loss: 1.978474138885416

Epoch: 5| Step: 7
Training loss: 2.6691417694091797
Validation loss: 1.965223386723508

Epoch: 5| Step: 8
Training loss: 1.8667736053466797
Validation loss: 1.9699091936952324

Epoch: 5| Step: 9
Training loss: 1.8152856826782227
Validation loss: 1.9704749571379794

Epoch: 5| Step: 10
Training loss: 1.9808520078659058
Validation loss: 1.9688163624014905

Epoch: 107| Step: 0
Training loss: 2.9045417308807373
Validation loss: 1.9738888240629626

Epoch: 5| Step: 1
Training loss: 2.075268268585205
Validation loss: 1.9598795854917137

Epoch: 5| Step: 2
Training loss: 2.0793392658233643
Validation loss: 1.969709046425358

Epoch: 5| Step: 3
Training loss: 2.281125068664551
Validation loss: 1.9672677363118818

Epoch: 5| Step: 4
Training loss: 1.585744857788086
Validation loss: 1.9584853200502292

Epoch: 5| Step: 5
Training loss: 2.195648670196533
Validation loss: 1.9637538156201761

Epoch: 5| Step: 6
Training loss: 1.813028335571289
Validation loss: 1.96343945687817

Epoch: 5| Step: 7
Training loss: 2.305104970932007
Validation loss: 1.9571730244544245

Epoch: 5| Step: 8
Training loss: 1.8223011493682861
Validation loss: 1.9543024634802213

Epoch: 5| Step: 9
Training loss: 1.8903210163116455
Validation loss: 1.9590387062359882

Epoch: 5| Step: 10
Training loss: 2.594634771347046
Validation loss: 1.958636450511153

Epoch: 108| Step: 0
Training loss: 2.6347248554229736
Validation loss: 1.9566486535533782

Epoch: 5| Step: 1
Training loss: 2.5257840156555176
Validation loss: 1.9685894571324831

Epoch: 5| Step: 2
Training loss: 2.458557605743408
Validation loss: 1.9703535290174587

Epoch: 5| Step: 3
Training loss: 2.093658208847046
Validation loss: 1.9416281010514946

Epoch: 5| Step: 4
Training loss: 1.8167266845703125
Validation loss: 1.9637322554024317

Epoch: 5| Step: 5
Training loss: 1.9703811407089233
Validation loss: 1.9534795181725615

Epoch: 5| Step: 6
Training loss: 1.5143487453460693
Validation loss: 1.9569296670216385

Epoch: 5| Step: 7
Training loss: 1.9050954580307007
Validation loss: 1.9669436075354134

Epoch: 5| Step: 8
Training loss: 2.1177501678466797
Validation loss: 1.9732537833593224

Epoch: 5| Step: 9
Training loss: 2.2550902366638184
Validation loss: 1.9720884599993307

Epoch: 5| Step: 10
Training loss: 2.2159290313720703
Validation loss: 1.985235600061314

Epoch: 109| Step: 0
Training loss: 2.4968409538269043
Validation loss: 1.9558468070081485

Epoch: 5| Step: 1
Training loss: 2.3721001148223877
Validation loss: 1.9506086303341774

Epoch: 5| Step: 2
Training loss: 1.9453939199447632
Validation loss: 1.9567672475691764

Epoch: 5| Step: 3
Training loss: 2.2024011611938477
Validation loss: 1.9546138855718798

Epoch: 5| Step: 4
Training loss: 2.7661495208740234
Validation loss: 1.9528599528856174

Epoch: 5| Step: 5
Training loss: 1.7342488765716553
Validation loss: 1.9441067172634987

Epoch: 5| Step: 6
Training loss: 1.6232099533081055
Validation loss: 1.92377059946778

Epoch: 5| Step: 7
Training loss: 2.2676281929016113
Validation loss: 1.953543182342283

Epoch: 5| Step: 8
Training loss: 1.9023653268814087
Validation loss: 1.9445880510473763

Epoch: 5| Step: 9
Training loss: 2.1916086673736572
Validation loss: 1.9324165313474593

Epoch: 5| Step: 10
Training loss: 2.0762548446655273
Validation loss: 1.933786803676236

Epoch: 110| Step: 0
Training loss: 1.9770593643188477
Validation loss: 1.9320663508548532

Epoch: 5| Step: 1
Training loss: 2.4003987312316895
Validation loss: 1.9445992926115632

Epoch: 5| Step: 2
Training loss: 2.377047061920166
Validation loss: 1.9381652365448654

Epoch: 5| Step: 3
Training loss: 1.4264705181121826
Validation loss: 1.9446712450314594

Epoch: 5| Step: 4
Training loss: 2.173285961151123
Validation loss: 1.9418411049791562

Epoch: 5| Step: 5
Training loss: 2.8015480041503906
Validation loss: 1.9284357627232869

Epoch: 5| Step: 6
Training loss: 2.192962884902954
Validation loss: 1.9306068856229064

Epoch: 5| Step: 7
Training loss: 2.393284559249878
Validation loss: 1.9515533190901562

Epoch: 5| Step: 8
Training loss: 1.691036581993103
Validation loss: 1.9671851742652156

Epoch: 5| Step: 9
Training loss: 2.1571788787841797
Validation loss: 1.9657637765330653

Epoch: 5| Step: 10
Training loss: 1.7556620836257935
Validation loss: 1.9761387084120063

Epoch: 111| Step: 0
Training loss: 1.6606605052947998
Validation loss: 1.9641719505351076

Epoch: 5| Step: 1
Training loss: 1.9284509420394897
Validation loss: 1.970937116171724

Epoch: 5| Step: 2
Training loss: 2.831650495529175
Validation loss: 1.9678779161104591

Epoch: 5| Step: 3
Training loss: 1.8640127182006836
Validation loss: 1.9609756367180937

Epoch: 5| Step: 4
Training loss: 2.0788817405700684
Validation loss: 1.9624802502252723

Epoch: 5| Step: 5
Training loss: 1.8822139501571655
Validation loss: 1.9549798286089333

Epoch: 5| Step: 6
Training loss: 2.7299485206604004
Validation loss: 1.953614504106583

Epoch: 5| Step: 7
Training loss: 1.8242419958114624
Validation loss: 1.9244311278866184

Epoch: 5| Step: 8
Training loss: 2.2964391708374023
Validation loss: 1.9421476830718338

Epoch: 5| Step: 9
Training loss: 2.1883716583251953
Validation loss: 1.9713724966972106

Epoch: 5| Step: 10
Training loss: 2.132800579071045
Validation loss: 1.9452582431095902

Epoch: 112| Step: 0
Training loss: 2.2252161502838135
Validation loss: 1.9532937490811912

Epoch: 5| Step: 1
Training loss: 1.9114618301391602
Validation loss: 1.956216791624664

Epoch: 5| Step: 2
Training loss: 1.7390635013580322
Validation loss: 1.958414880178308

Epoch: 5| Step: 3
Training loss: 2.1986708641052246
Validation loss: 1.9586698880759619

Epoch: 5| Step: 4
Training loss: 2.903027057647705
Validation loss: 1.9560394492200626

Epoch: 5| Step: 5
Training loss: 2.2477798461914062
Validation loss: 1.9606343674403366

Epoch: 5| Step: 6
Training loss: 2.5385851860046387
Validation loss: 1.9632967620767572

Epoch: 5| Step: 7
Training loss: 1.7733125686645508
Validation loss: 1.9917597475872244

Epoch: 5| Step: 8
Training loss: 1.6252692937850952
Validation loss: 1.9853445945247528

Epoch: 5| Step: 9
Training loss: 2.260830879211426
Validation loss: 1.9576117120763308

Epoch: 5| Step: 10
Training loss: 1.9791381359100342
Validation loss: 1.9795024612898469

Epoch: 113| Step: 0
Training loss: 2.2080299854278564
Validation loss: 1.9723602507704048

Epoch: 5| Step: 1
Training loss: 1.9002145528793335
Validation loss: 1.9706075563225696

Epoch: 5| Step: 2
Training loss: 2.9335169792175293
Validation loss: 1.9629754225413005

Epoch: 5| Step: 3
Training loss: 2.40093994140625
Validation loss: 1.9682311216990154

Epoch: 5| Step: 4
Training loss: 1.4304319620132446
Validation loss: 1.9539556016204178

Epoch: 5| Step: 5
Training loss: 2.006883144378662
Validation loss: 1.9793387946262155

Epoch: 5| Step: 6
Training loss: 2.1377525329589844
Validation loss: 1.964175634486701

Epoch: 5| Step: 7
Training loss: 1.8363876342773438
Validation loss: 1.9345964462526384

Epoch: 5| Step: 8
Training loss: 2.297736167907715
Validation loss: 1.946810540332589

Epoch: 5| Step: 9
Training loss: 2.3465054035186768
Validation loss: 1.9481620532210155

Epoch: 5| Step: 10
Training loss: 1.914433240890503
Validation loss: 1.9301155869678785

Epoch: 114| Step: 0
Training loss: 2.1328604221343994
Validation loss: 1.9536351567955428

Epoch: 5| Step: 1
Training loss: 2.8945343494415283
Validation loss: 1.9495297837001022

Epoch: 5| Step: 2
Training loss: 1.870300531387329
Validation loss: 1.9491330962027273

Epoch: 5| Step: 3
Training loss: 2.411916732788086
Validation loss: 1.9498536522670458

Epoch: 5| Step: 4
Training loss: 2.123291492462158
Validation loss: 1.949662769994428

Epoch: 5| Step: 5
Training loss: 1.8093513250350952
Validation loss: 1.955408211677305

Epoch: 5| Step: 6
Training loss: 1.9290821552276611
Validation loss: 1.9332641786144626

Epoch: 5| Step: 7
Training loss: 1.9806352853775024
Validation loss: 1.9660956577588153

Epoch: 5| Step: 8
Training loss: 2.0953094959259033
Validation loss: 1.9476090656813754

Epoch: 5| Step: 9
Training loss: 2.1357789039611816
Validation loss: 1.9435686026850054

Epoch: 5| Step: 10
Training loss: 2.0837533473968506
Validation loss: 1.924776296461782

Epoch: 115| Step: 0
Training loss: 1.753419280052185
Validation loss: 1.952275037765503

Epoch: 5| Step: 1
Training loss: 2.6415581703186035
Validation loss: 1.946735038552233

Epoch: 5| Step: 2
Training loss: 1.4597560167312622
Validation loss: 1.9530307426247546

Epoch: 5| Step: 3
Training loss: 1.635063886642456
Validation loss: 1.9618394964484758

Epoch: 5| Step: 4
Training loss: 1.9787193536758423
Validation loss: 1.9683534945211103

Epoch: 5| Step: 5
Training loss: 2.375218629837036
Validation loss: 1.9658296479973743

Epoch: 5| Step: 6
Training loss: 2.754833221435547
Validation loss: 1.945740020403298

Epoch: 5| Step: 7
Training loss: 2.027651786804199
Validation loss: 1.970617248165992

Epoch: 5| Step: 8
Training loss: 2.248178482055664
Validation loss: 1.958830577070995

Epoch: 5| Step: 9
Training loss: 2.3168416023254395
Validation loss: 1.976210376267792

Epoch: 5| Step: 10
Training loss: 2.0725817680358887
Validation loss: 1.9702657448348178

Epoch: 116| Step: 0
Training loss: 2.2566237449645996
Validation loss: 1.9541248762479393

Epoch: 5| Step: 1
Training loss: 2.2763993740081787
Validation loss: 1.9810420108097855

Epoch: 5| Step: 2
Training loss: 2.055838108062744
Validation loss: 1.9624422442528509

Epoch: 5| Step: 3
Training loss: 1.9734814167022705
Validation loss: 1.9724213243812643

Epoch: 5| Step: 4
Training loss: 1.8719167709350586
Validation loss: 1.9953804387841174

Epoch: 5| Step: 5
Training loss: 2.3197884559631348
Validation loss: 1.975669135329544

Epoch: 5| Step: 6
Training loss: 2.1861019134521484
Validation loss: 1.9964639268895632

Epoch: 5| Step: 7
Training loss: 2.1102750301361084
Validation loss: 1.9746823887671194

Epoch: 5| Step: 8
Training loss: 1.5970642566680908
Validation loss: 1.998817615611579

Epoch: 5| Step: 9
Training loss: 2.4394257068634033
Validation loss: 1.984848036560961

Epoch: 5| Step: 10
Training loss: 2.04457426071167
Validation loss: 1.9660905945685603

Epoch: 117| Step: 0
Training loss: 2.032688617706299
Validation loss: 1.9658821641757924

Epoch: 5| Step: 1
Training loss: 2.659080982208252
Validation loss: 1.9982632437059957

Epoch: 5| Step: 2
Training loss: 1.8940902948379517
Validation loss: 1.9904044174378919

Epoch: 5| Step: 3
Training loss: 2.3743016719818115
Validation loss: 1.9716639377737557

Epoch: 5| Step: 4
Training loss: 1.8010389804840088
Validation loss: 1.9601809568302606

Epoch: 5| Step: 5
Training loss: 2.2687487602233887
Validation loss: 1.9558930704670567

Epoch: 5| Step: 6
Training loss: 1.6630160808563232
Validation loss: 1.97070473881178

Epoch: 5| Step: 7
Training loss: 1.9343944787979126
Validation loss: 1.9486761490503948

Epoch: 5| Step: 8
Training loss: 2.5935776233673096
Validation loss: 1.9677860788119736

Epoch: 5| Step: 9
Training loss: 2.600095272064209
Validation loss: 1.9451499267290997

Epoch: 5| Step: 10
Training loss: 1.5511964559555054
Validation loss: 1.9562376917049449

Epoch: 118| Step: 0
Training loss: 1.670875906944275
Validation loss: 1.9422437939592587

Epoch: 5| Step: 1
Training loss: 1.9485492706298828
Validation loss: 1.9717096718408729

Epoch: 5| Step: 2
Training loss: 2.518441677093506
Validation loss: 1.9579476425724645

Epoch: 5| Step: 3
Training loss: 2.638944149017334
Validation loss: 1.9796778899367138

Epoch: 5| Step: 4
Training loss: 1.6164615154266357
Validation loss: 1.97220016038546

Epoch: 5| Step: 5
Training loss: 2.6034722328186035
Validation loss: 1.9629978261968142

Epoch: 5| Step: 6
Training loss: 1.9920482635498047
Validation loss: 1.9571594743318455

Epoch: 5| Step: 7
Training loss: 1.8345038890838623
Validation loss: 1.9645399611483338

Epoch: 5| Step: 8
Training loss: 2.194066286087036
Validation loss: 1.9754712966180616

Epoch: 5| Step: 9
Training loss: 1.9962852001190186
Validation loss: 1.9594440050022577

Epoch: 5| Step: 10
Training loss: 2.2415950298309326
Validation loss: 1.9629658332435034

Epoch: 119| Step: 0
Training loss: 2.0781991481781006
Validation loss: 1.959817668443085

Epoch: 5| Step: 1
Training loss: 2.0315940380096436
Validation loss: 1.9706294408408545

Epoch: 5| Step: 2
Training loss: 2.0808160305023193
Validation loss: 1.9580816479139431

Epoch: 5| Step: 3
Training loss: 2.7248375415802
Validation loss: 1.9604407407904183

Epoch: 5| Step: 4
Training loss: 2.169616222381592
Validation loss: 1.9653095314579625

Epoch: 5| Step: 5
Training loss: 1.3122879266738892
Validation loss: 1.9644527012302029

Epoch: 5| Step: 6
Training loss: 1.7991983890533447
Validation loss: 1.9653811916228263

Epoch: 5| Step: 7
Training loss: 2.1570088863372803
Validation loss: 1.977038014319635

Epoch: 5| Step: 8
Training loss: 2.2794361114501953
Validation loss: 1.9495004261693647

Epoch: 5| Step: 9
Training loss: 2.2213971614837646
Validation loss: 1.9680476265568887

Epoch: 5| Step: 10
Training loss: 2.3556127548217773
Validation loss: 1.9647997861267419

Epoch: 120| Step: 0
Training loss: 2.395840883255005
Validation loss: 1.9544160750604445

Epoch: 5| Step: 1
Training loss: 1.8793319463729858
Validation loss: 1.9708512098558488

Epoch: 5| Step: 2
Training loss: 2.335766315460205
Validation loss: 1.9717618188550394

Epoch: 5| Step: 3
Training loss: 2.235243082046509
Validation loss: 1.9692302032183575

Epoch: 5| Step: 4
Training loss: 1.980531096458435
Validation loss: 1.9572962099506008

Epoch: 5| Step: 5
Training loss: 2.6535756587982178
Validation loss: 1.9655413243078417

Epoch: 5| Step: 6
Training loss: 1.8472232818603516
Validation loss: 1.9723990912078528

Epoch: 5| Step: 7
Training loss: 1.892507791519165
Validation loss: 1.9486544260414698

Epoch: 5| Step: 8
Training loss: 2.110084056854248
Validation loss: 1.9709676593862555

Epoch: 5| Step: 9
Training loss: 1.694228172302246
Validation loss: 1.9676098836365568

Epoch: 5| Step: 10
Training loss: 2.150852680206299
Validation loss: 1.974167175190423

Epoch: 121| Step: 0
Training loss: 2.0357062816619873
Validation loss: 1.960135332999691

Epoch: 5| Step: 1
Training loss: 2.278420925140381
Validation loss: 1.9696793017848846

Epoch: 5| Step: 2
Training loss: 2.5452396869659424
Validation loss: 1.9765642368665306

Epoch: 5| Step: 3
Training loss: 2.2328808307647705
Validation loss: 1.966582211115027

Epoch: 5| Step: 4
Training loss: 1.3875216245651245
Validation loss: 1.9611462072659565

Epoch: 5| Step: 5
Training loss: 2.302729845046997
Validation loss: 1.9661015515686364

Epoch: 5| Step: 6
Training loss: 2.4640090465545654
Validation loss: 1.9592150193388744

Epoch: 5| Step: 7
Training loss: 1.8426895141601562
Validation loss: 1.9549496840405207

Epoch: 5| Step: 8
Training loss: 2.403425931930542
Validation loss: 1.9924436192358694

Epoch: 5| Step: 9
Training loss: 1.663299560546875
Validation loss: 1.9700054635283768

Epoch: 5| Step: 10
Training loss: 2.059157133102417
Validation loss: 1.9831255328270696

Epoch: 122| Step: 0
Training loss: 1.9534000158309937
Validation loss: 1.9577618183628205

Epoch: 5| Step: 1
Training loss: 1.9025903940200806
Validation loss: 1.9604839073714388

Epoch: 5| Step: 2
Training loss: 2.9161269664764404
Validation loss: 1.9580595788135324

Epoch: 5| Step: 3
Training loss: 1.7994648218154907
Validation loss: 1.9653860599763933

Epoch: 5| Step: 4
Training loss: 2.7047483921051025
Validation loss: 1.9725141371450117

Epoch: 5| Step: 5
Training loss: 1.6974680423736572
Validation loss: 1.953766410068799

Epoch: 5| Step: 6
Training loss: 2.043644428253174
Validation loss: 1.9580821811511953

Epoch: 5| Step: 7
Training loss: 1.9376987218856812
Validation loss: 1.9767779675863122

Epoch: 5| Step: 8
Training loss: 2.3258278369903564
Validation loss: 1.9549517964804044

Epoch: 5| Step: 9
Training loss: 2.183910846710205
Validation loss: 1.9821774716018348

Epoch: 5| Step: 10
Training loss: 1.698265790939331
Validation loss: 1.9824633393236386

Epoch: 123| Step: 0
Training loss: 1.4942430257797241
Validation loss: 1.9686263376666653

Epoch: 5| Step: 1
Training loss: 2.550248622894287
Validation loss: 1.9796014165365567

Epoch: 5| Step: 2
Training loss: 2.323059320449829
Validation loss: 1.9764391658126668

Epoch: 5| Step: 3
Training loss: 2.5943336486816406
Validation loss: 1.9800964939978816

Epoch: 5| Step: 4
Training loss: 1.7428289651870728
Validation loss: 1.9773793194883613

Epoch: 5| Step: 5
Training loss: 2.5030179023742676
Validation loss: 1.966657575740609

Epoch: 5| Step: 6
Training loss: 1.969374656677246
Validation loss: 1.9860300299941853

Epoch: 5| Step: 7
Training loss: 2.06744647026062
Validation loss: 1.9699541022700648

Epoch: 5| Step: 8
Training loss: 1.215595006942749
Validation loss: 1.9719749778829596

Epoch: 5| Step: 9
Training loss: 2.3242225646972656
Validation loss: 1.952941753531015

Epoch: 5| Step: 10
Training loss: 2.2998507022857666
Validation loss: 1.9620718558629353

Epoch: 124| Step: 0
Training loss: 2.253622055053711
Validation loss: 1.98785331813238

Epoch: 5| Step: 1
Training loss: 2.2338433265686035
Validation loss: 1.9563611271560832

Epoch: 5| Step: 2
Training loss: 1.800602674484253
Validation loss: 1.9667549312755626

Epoch: 5| Step: 3
Training loss: 1.7459452152252197
Validation loss: 1.9726814044419156

Epoch: 5| Step: 4
Training loss: 2.4534695148468018
Validation loss: 1.9557212104079544

Epoch: 5| Step: 5
Training loss: 2.2483439445495605
Validation loss: 1.9670017265504407

Epoch: 5| Step: 6
Training loss: 2.138953447341919
Validation loss: 1.952606475481423

Epoch: 5| Step: 7
Training loss: 2.0410032272338867
Validation loss: 1.952721453482105

Epoch: 5| Step: 8
Training loss: 1.7988859415054321
Validation loss: 1.9724518586230535

Epoch: 5| Step: 9
Training loss: 2.346261978149414
Validation loss: 1.9526129358558244

Epoch: 5| Step: 10
Training loss: 2.0555198192596436
Validation loss: 1.9627817676913353

Epoch: 125| Step: 0
Training loss: 1.687356948852539
Validation loss: 1.964384243052493

Epoch: 5| Step: 1
Training loss: 1.9752641916275024
Validation loss: 1.9478983712452713

Epoch: 5| Step: 2
Training loss: 1.9543359279632568
Validation loss: 1.9824441543189428

Epoch: 5| Step: 3
Training loss: 2.016753673553467
Validation loss: 1.9438808912871985

Epoch: 5| Step: 4
Training loss: 1.6257671117782593
Validation loss: 1.9612047467180478

Epoch: 5| Step: 5
Training loss: 1.9778110980987549
Validation loss: 1.9730830487384592

Epoch: 5| Step: 6
Training loss: 3.0072295665740967
Validation loss: 1.9694352098690566

Epoch: 5| Step: 7
Training loss: 1.8550876379013062
Validation loss: 1.976280584130236

Epoch: 5| Step: 8
Training loss: 2.630389451980591
Validation loss: 1.9831048711653678

Epoch: 5| Step: 9
Training loss: 2.1718459129333496
Validation loss: 1.9906357052505657

Epoch: 5| Step: 10
Training loss: 2.090547561645508
Validation loss: 1.983885527938925

Epoch: 126| Step: 0
Training loss: 2.1685166358947754
Validation loss: 2.004215250733078

Epoch: 5| Step: 1
Training loss: 1.5617109537124634
Validation loss: 1.9854041812240437

Epoch: 5| Step: 2
Training loss: 2.303046703338623
Validation loss: 2.002761721611023

Epoch: 5| Step: 3
Training loss: 1.720725417137146
Validation loss: 2.012887029237645

Epoch: 5| Step: 4
Training loss: 1.6844959259033203
Validation loss: 1.98498583609058

Epoch: 5| Step: 5
Training loss: 2.1567583084106445
Validation loss: 1.9893652726245183

Epoch: 5| Step: 6
Training loss: 2.0146687030792236
Validation loss: 1.994190856974612

Epoch: 5| Step: 7
Training loss: 1.76432204246521
Validation loss: 1.99615204206077

Epoch: 5| Step: 8
Training loss: 2.3234753608703613
Validation loss: 1.9945586394238215

Epoch: 5| Step: 9
Training loss: 2.7905821800231934
Validation loss: 1.9906381125091224

Epoch: 5| Step: 10
Training loss: 2.483043670654297
Validation loss: 1.9841320053223641

Epoch: 127| Step: 0
Training loss: 2.056819438934326
Validation loss: 1.9698299643813924

Epoch: 5| Step: 1
Training loss: 2.18792724609375
Validation loss: 1.998021223211801

Epoch: 5| Step: 2
Training loss: 2.5850958824157715
Validation loss: 1.972631190412788

Epoch: 5| Step: 3
Training loss: 2.0028457641601562
Validation loss: 1.986466469303254

Epoch: 5| Step: 4
Training loss: 2.0631725788116455
Validation loss: 1.9524144280341365

Epoch: 5| Step: 5
Training loss: 1.3510162830352783
Validation loss: 1.9744562218266148

Epoch: 5| Step: 6
Training loss: 2.0642364025115967
Validation loss: 1.960168867982844

Epoch: 5| Step: 7
Training loss: 2.1993792057037354
Validation loss: 1.9690384146987752

Epoch: 5| Step: 8
Training loss: 2.029897689819336
Validation loss: 1.957048685319962

Epoch: 5| Step: 9
Training loss: 2.3935387134552
Validation loss: 1.9242218015014485

Epoch: 5| Step: 10
Training loss: 2.0885889530181885
Validation loss: 1.9386321857411375

Epoch: 128| Step: 0
Training loss: 1.9918138980865479
Validation loss: 1.9695686422368532

Epoch: 5| Step: 1
Training loss: 2.3262288570404053
Validation loss: 1.979616770180323

Epoch: 5| Step: 2
Training loss: 1.9376106262207031
Validation loss: 1.9599482756789013

Epoch: 5| Step: 3
Training loss: 2.1605281829833984
Validation loss: 1.9408905480497627

Epoch: 5| Step: 4
Training loss: 2.0317959785461426
Validation loss: 1.9560624591765865

Epoch: 5| Step: 5
Training loss: 1.7490360736846924
Validation loss: 1.9425977519763413

Epoch: 5| Step: 6
Training loss: 2.525357723236084
Validation loss: 1.9584024247302805

Epoch: 5| Step: 7
Training loss: 1.76082444190979
Validation loss: 1.9572452293929232

Epoch: 5| Step: 8
Training loss: 2.1711151599884033
Validation loss: 1.924678885808555

Epoch: 5| Step: 9
Training loss: 2.3044159412384033
Validation loss: 1.9565635727297874

Epoch: 5| Step: 10
Training loss: 2.069376230239868
Validation loss: 1.9661866131649222

Epoch: 129| Step: 0
Training loss: 2.337031126022339
Validation loss: 1.9717747190947175

Epoch: 5| Step: 1
Training loss: 2.49583101272583
Validation loss: 1.956072066419868

Epoch: 5| Step: 2
Training loss: 1.8329174518585205
Validation loss: 1.9619259680471113

Epoch: 5| Step: 3
Training loss: 1.9078975915908813
Validation loss: 1.9638487985057216

Epoch: 5| Step: 4
Training loss: 2.3545801639556885
Validation loss: 1.960437633657968

Epoch: 5| Step: 5
Training loss: 1.7999029159545898
Validation loss: 1.977881884062162

Epoch: 5| Step: 6
Training loss: 2.703566789627075
Validation loss: 1.969945615337741

Epoch: 5| Step: 7
Training loss: 1.4738876819610596
Validation loss: 1.960404465275426

Epoch: 5| Step: 8
Training loss: 1.9937822818756104
Validation loss: 1.9626801590765677

Epoch: 5| Step: 9
Training loss: 1.5920743942260742
Validation loss: 1.9766919612884521

Epoch: 5| Step: 10
Training loss: 2.450867176055908
Validation loss: 1.967294591729359

Epoch: 130| Step: 0
Training loss: 2.182030439376831
Validation loss: 1.9852139719070927

Epoch: 5| Step: 1
Training loss: 2.4128353595733643
Validation loss: 1.9634817441304524

Epoch: 5| Step: 2
Training loss: 1.9666016101837158
Validation loss: 1.968946196699655

Epoch: 5| Step: 3
Training loss: 2.355260133743286
Validation loss: 1.974874832296884

Epoch: 5| Step: 4
Training loss: 1.721954584121704
Validation loss: 1.940666579431103

Epoch: 5| Step: 5
Training loss: 1.9522721767425537
Validation loss: 1.950572693219749

Epoch: 5| Step: 6
Training loss: 2.458709239959717
Validation loss: 1.9641899601105721

Epoch: 5| Step: 7
Training loss: 2.1390960216522217
Validation loss: 1.9590503656735985

Epoch: 5| Step: 8
Training loss: 1.5929291248321533
Validation loss: 1.945158564916221

Epoch: 5| Step: 9
Training loss: 2.19514799118042
Validation loss: 1.9732822154157905

Epoch: 5| Step: 10
Training loss: 2.1236860752105713
Validation loss: 1.9476814295655938

Epoch: 131| Step: 0
Training loss: 2.3649649620056152
Validation loss: 1.9535692443129837

Epoch: 5| Step: 1
Training loss: 2.212989091873169
Validation loss: 1.9633923166541642

Epoch: 5| Step: 2
Training loss: 2.0687994956970215
Validation loss: 1.948634495017349

Epoch: 5| Step: 3
Training loss: 2.4488942623138428
Validation loss: 1.9758686378437986

Epoch: 5| Step: 4
Training loss: 2.047995090484619
Validation loss: 1.9772755843336864

Epoch: 5| Step: 5
Training loss: 2.358743190765381
Validation loss: 1.9635645548502605

Epoch: 5| Step: 6
Training loss: 1.7552474737167358
Validation loss: 1.9802999624641993

Epoch: 5| Step: 7
Training loss: 1.7475488185882568
Validation loss: 1.9926043043854416

Epoch: 5| Step: 8
Training loss: 2.7104694843292236
Validation loss: 1.9646391740409277

Epoch: 5| Step: 9
Training loss: 1.7425930500030518
Validation loss: 1.9709115502654866

Epoch: 5| Step: 10
Training loss: 1.313025712966919
Validation loss: 1.9626383140522947

Epoch: 132| Step: 0
Training loss: 2.313408851623535
Validation loss: 1.9867316856179187

Epoch: 5| Step: 1
Training loss: 2.224827527999878
Validation loss: 1.9749446709950764

Epoch: 5| Step: 2
Training loss: 2.6048178672790527
Validation loss: 1.9654681016040105

Epoch: 5| Step: 3
Training loss: 1.9006227254867554
Validation loss: 1.9652960441445793

Epoch: 5| Step: 4
Training loss: 1.9484608173370361
Validation loss: 1.9826761996874245

Epoch: 5| Step: 5
Training loss: 1.8264713287353516
Validation loss: 1.9809079093317832

Epoch: 5| Step: 6
Training loss: 2.3993124961853027
Validation loss: 1.9944528097747474

Epoch: 5| Step: 7
Training loss: 2.19120454788208
Validation loss: 1.9859235799440773

Epoch: 5| Step: 8
Training loss: 1.6772964000701904
Validation loss: 2.0022708780022076

Epoch: 5| Step: 9
Training loss: 2.197838306427002
Validation loss: 1.9902468701844573

Epoch: 5| Step: 10
Training loss: 1.4689923524856567
Validation loss: 2.0015116276279574

Epoch: 133| Step: 0
Training loss: 2.297300338745117
Validation loss: 1.980793115913227

Epoch: 5| Step: 1
Training loss: 2.44423246383667
Validation loss: 1.978580908108783

Epoch: 5| Step: 2
Training loss: 2.365644931793213
Validation loss: 1.9832615775446738

Epoch: 5| Step: 3
Training loss: 1.890305519104004
Validation loss: 1.966475438046199

Epoch: 5| Step: 4
Training loss: 2.4957830905914307
Validation loss: 1.9804644892292638

Epoch: 5| Step: 5
Training loss: 1.9077718257904053
Validation loss: 1.9831694300456713

Epoch: 5| Step: 6
Training loss: 1.8517669439315796
Validation loss: 1.9744585842214606

Epoch: 5| Step: 7
Training loss: 1.818582534790039
Validation loss: 1.9736806090160082

Epoch: 5| Step: 8
Training loss: 2.378896713256836
Validation loss: 1.9630574782689412

Epoch: 5| Step: 9
Training loss: 1.4689735174179077
Validation loss: 1.9250414679127354

Epoch: 5| Step: 10
Training loss: 1.9457725286483765
Validation loss: 1.9648896930038289

Epoch: 134| Step: 0
Training loss: 1.9521147012710571
Validation loss: 1.9762031762830672

Epoch: 5| Step: 1
Training loss: 2.033167600631714
Validation loss: 1.953502401228874

Epoch: 5| Step: 2
Training loss: 1.9934628009796143
Validation loss: 1.96328015224908

Epoch: 5| Step: 3
Training loss: 2.1082966327667236
Validation loss: 1.9715395960756528

Epoch: 5| Step: 4
Training loss: 1.9504369497299194
Validation loss: 1.9390629209497923

Epoch: 5| Step: 5
Training loss: 1.86870539188385
Validation loss: 1.947604630583076

Epoch: 5| Step: 6
Training loss: 2.6229636669158936
Validation loss: 1.9371503642810288

Epoch: 5| Step: 7
Training loss: 2.1162335872650146
Validation loss: 1.9483656549966464

Epoch: 5| Step: 8
Training loss: 1.9263355731964111
Validation loss: 1.9479349197879914

Epoch: 5| Step: 9
Training loss: 2.105211019515991
Validation loss: 1.952268253090561

Epoch: 5| Step: 10
Training loss: 2.30600643157959
Validation loss: 1.95262869070935

Epoch: 135| Step: 0
Training loss: 1.6975603103637695
Validation loss: 1.957865717590496

Epoch: 5| Step: 1
Training loss: 1.86648690700531
Validation loss: 1.9278633645785752

Epoch: 5| Step: 2
Training loss: 2.191516160964966
Validation loss: 1.9512978241007815

Epoch: 5| Step: 3
Training loss: 2.8642544746398926
Validation loss: 1.9578414194045528

Epoch: 5| Step: 4
Training loss: 1.918077826499939
Validation loss: 1.9450389057077386

Epoch: 5| Step: 5
Training loss: 2.3887877464294434
Validation loss: 1.955729425594371

Epoch: 5| Step: 6
Training loss: 1.8146476745605469
Validation loss: 1.9265195221029303

Epoch: 5| Step: 7
Training loss: 2.258971691131592
Validation loss: 1.9457221749008342

Epoch: 5| Step: 8
Training loss: 1.5614912509918213
Validation loss: 1.9710437046584262

Epoch: 5| Step: 9
Training loss: 2.0155441761016846
Validation loss: 1.9382083326257684

Epoch: 5| Step: 10
Training loss: 2.397221565246582
Validation loss: 1.977350482376673

Epoch: 136| Step: 0
Training loss: 2.157780408859253
Validation loss: 1.9710059396682247

Epoch: 5| Step: 1
Training loss: 1.861351728439331
Validation loss: 1.9620390912537933

Epoch: 5| Step: 2
Training loss: 2.2297251224517822
Validation loss: 1.970286633378716

Epoch: 5| Step: 3
Training loss: 2.362151861190796
Validation loss: 1.9690034261313818

Epoch: 5| Step: 4
Training loss: 2.5247836112976074
Validation loss: 1.9544427176957488

Epoch: 5| Step: 5
Training loss: 1.6127898693084717
Validation loss: 1.9696847674667195

Epoch: 5| Step: 6
Training loss: 2.139984369277954
Validation loss: 1.9609900418148245

Epoch: 5| Step: 7
Training loss: 1.4169046878814697
Validation loss: 1.9583549153420232

Epoch: 5| Step: 8
Training loss: 2.1285488605499268
Validation loss: 1.971048749903197

Epoch: 5| Step: 9
Training loss: 2.076751470565796
Validation loss: 1.9689934817693566

Epoch: 5| Step: 10
Training loss: 2.2429661750793457
Validation loss: 1.9698042959295294

Epoch: 137| Step: 0
Training loss: 2.126309871673584
Validation loss: 1.9748207933159285

Epoch: 5| Step: 1
Training loss: 2.551837921142578
Validation loss: 1.9719521281539754

Epoch: 5| Step: 2
Training loss: 2.6186702251434326
Validation loss: 1.9866657526262346

Epoch: 5| Step: 3
Training loss: 2.2198290824890137
Validation loss: 1.979139983013112

Epoch: 5| Step: 4
Training loss: 2.308722734451294
Validation loss: 2.0270486198445803

Epoch: 5| Step: 5
Training loss: 1.9111382961273193
Validation loss: 2.0047771943512784

Epoch: 5| Step: 6
Training loss: 1.3636753559112549
Validation loss: 2.0106233781383884

Epoch: 5| Step: 7
Training loss: 1.5736494064331055
Validation loss: 2.0047608049966956

Epoch: 5| Step: 8
Training loss: 2.0403213500976562
Validation loss: 2.004084038478072

Epoch: 5| Step: 9
Training loss: 1.86318838596344
Validation loss: 1.9960540545884

Epoch: 5| Step: 10
Training loss: 2.2656471729278564
Validation loss: 1.9913965104728617

Epoch: 138| Step: 0
Training loss: 2.10621976852417
Validation loss: 1.973030274914157

Epoch: 5| Step: 1
Training loss: 1.8698307275772095
Validation loss: 1.942510671513055

Epoch: 5| Step: 2
Training loss: 1.5153683423995972
Validation loss: 1.9617399938644902

Epoch: 5| Step: 3
Training loss: 1.7473758459091187
Validation loss: 1.9662901381010651

Epoch: 5| Step: 4
Training loss: 1.530778408050537
Validation loss: 1.9658396641413372

Epoch: 5| Step: 5
Training loss: 2.0160586833953857
Validation loss: 1.958460586045378

Epoch: 5| Step: 6
Training loss: 2.5463006496429443
Validation loss: 1.959483487631685

Epoch: 5| Step: 7
Training loss: 2.1198086738586426
Validation loss: 1.9436200575162006

Epoch: 5| Step: 8
Training loss: 2.405259609222412
Validation loss: 1.970118986662998

Epoch: 5| Step: 9
Training loss: 2.8538169860839844
Validation loss: 1.977231861442648

Epoch: 5| Step: 10
Training loss: 1.9107455015182495
Validation loss: 1.972048004468282

Epoch: 139| Step: 0
Training loss: 1.7505697011947632
Validation loss: 1.9616507048247962

Epoch: 5| Step: 1
Training loss: 1.8936046361923218
Validation loss: 1.9624589720079977

Epoch: 5| Step: 2
Training loss: 1.7952091693878174
Validation loss: 1.9450757606055147

Epoch: 5| Step: 3
Training loss: 2.444059371948242
Validation loss: 1.968463961796094

Epoch: 5| Step: 4
Training loss: 2.565295696258545
Validation loss: 1.9749087954080233

Epoch: 5| Step: 5
Training loss: 1.9605270624160767
Validation loss: 1.950792968914073

Epoch: 5| Step: 6
Training loss: 2.039447784423828
Validation loss: 1.9620096683502197

Epoch: 5| Step: 7
Training loss: 2.442791700363159
Validation loss: 1.946549819361779

Epoch: 5| Step: 8
Training loss: 2.1051926612854004
Validation loss: 1.9485802240269159

Epoch: 5| Step: 9
Training loss: 2.0981287956237793
Validation loss: 1.9662055507782967

Epoch: 5| Step: 10
Training loss: 1.7603325843811035
Validation loss: 1.953663727288605

Epoch: 140| Step: 0
Training loss: 2.0834362506866455
Validation loss: 1.952038485516784

Epoch: 5| Step: 1
Training loss: 1.8835761547088623
Validation loss: 1.9487985180270286

Epoch: 5| Step: 2
Training loss: 2.2597899436950684
Validation loss: 1.9814071270727343

Epoch: 5| Step: 3
Training loss: 2.1256775856018066
Validation loss: 1.9557623735038183

Epoch: 5| Step: 4
Training loss: 1.9149000644683838
Validation loss: 1.9794043802445935

Epoch: 5| Step: 5
Training loss: 2.290350914001465
Validation loss: 1.967233460436585

Epoch: 5| Step: 6
Training loss: 1.8416023254394531
Validation loss: 1.988549909284038

Epoch: 5| Step: 7
Training loss: 2.338381767272949
Validation loss: 1.9536209952446721

Epoch: 5| Step: 8
Training loss: 1.9633382558822632
Validation loss: 1.9925733894430182

Epoch: 5| Step: 9
Training loss: 2.1361939907073975
Validation loss: 1.9667750007362776

Epoch: 5| Step: 10
Training loss: 1.8327996730804443
Validation loss: 1.9715948450949885

Epoch: 141| Step: 0
Training loss: 2.3800289630889893
Validation loss: 1.9775201633412351

Epoch: 5| Step: 1
Training loss: 2.3050923347473145
Validation loss: 1.965847207653907

Epoch: 5| Step: 2
Training loss: 2.0755105018615723
Validation loss: 1.9776086602159726

Epoch: 5| Step: 3
Training loss: 1.9601142406463623
Validation loss: 1.9779949277959845

Epoch: 5| Step: 4
Training loss: 1.4328677654266357
Validation loss: 1.964087555485387

Epoch: 5| Step: 5
Training loss: 2.1832566261291504
Validation loss: 1.965093235815725

Epoch: 5| Step: 6
Training loss: 1.9468361139297485
Validation loss: 1.962227948250309

Epoch: 5| Step: 7
Training loss: 2.1561522483825684
Validation loss: 1.9680054251865675

Epoch: 5| Step: 8
Training loss: 2.146671772003174
Validation loss: 1.972075944305748

Epoch: 5| Step: 9
Training loss: 1.8857815265655518
Validation loss: 1.9657357367136146

Epoch: 5| Step: 10
Training loss: 2.212219476699829
Validation loss: 1.9776972596363356

Epoch: 142| Step: 0
Training loss: 2.7348053455352783
Validation loss: 1.970896049212384

Epoch: 5| Step: 1
Training loss: 1.833636999130249
Validation loss: 1.9793264340328913

Epoch: 5| Step: 2
Training loss: 2.4377479553222656
Validation loss: 1.9636206050072946

Epoch: 5| Step: 3
Training loss: 1.913874626159668
Validation loss: 2.000493677713538

Epoch: 5| Step: 4
Training loss: 1.1095198392868042
Validation loss: 1.9896244002926735

Epoch: 5| Step: 5
Training loss: 2.8677945137023926
Validation loss: 1.9647377998598161

Epoch: 5| Step: 6
Training loss: 2.006514310836792
Validation loss: 1.9764109375656291

Epoch: 5| Step: 7
Training loss: 1.9857962131500244
Validation loss: 2.0099243143553376

Epoch: 5| Step: 8
Training loss: 1.54380464553833
Validation loss: 1.9794149142439648

Epoch: 5| Step: 9
Training loss: 1.695122480392456
Validation loss: 1.949941142912834

Epoch: 5| Step: 10
Training loss: 2.5052545070648193
Validation loss: 1.9579970849457609

Epoch: 143| Step: 0
Training loss: 2.093952178955078
Validation loss: 1.98044192406439

Epoch: 5| Step: 1
Training loss: 1.9839372634887695
Validation loss: 1.970144658960322

Epoch: 5| Step: 2
Training loss: 1.9796359539031982
Validation loss: 1.9496347263295164

Epoch: 5| Step: 3
Training loss: 2.111732006072998
Validation loss: 1.9443999810885357

Epoch: 5| Step: 4
Training loss: 2.34039306640625
Validation loss: 1.9474367992852324

Epoch: 5| Step: 5
Training loss: 2.075469970703125
Validation loss: 1.9635756977142826

Epoch: 5| Step: 6
Training loss: 2.206958055496216
Validation loss: 1.9634123438148088

Epoch: 5| Step: 7
Training loss: 2.2479281425476074
Validation loss: 1.9707143281095771

Epoch: 5| Step: 8
Training loss: 1.9703404903411865
Validation loss: 1.961827366582809

Epoch: 5| Step: 9
Training loss: 1.4331177473068237
Validation loss: 1.9688677608325917

Epoch: 5| Step: 10
Training loss: 2.125671148300171
Validation loss: 1.969466701630623

Epoch: 144| Step: 0
Training loss: 1.9257370233535767
Validation loss: 1.9649317033829228

Epoch: 5| Step: 1
Training loss: 1.999991774559021
Validation loss: 1.9748356662770754

Epoch: 5| Step: 2
Training loss: 1.8852100372314453
Validation loss: 1.9528630471998645

Epoch: 5| Step: 3
Training loss: 2.020822048187256
Validation loss: 1.9554285080202165

Epoch: 5| Step: 4
Training loss: 2.0812432765960693
Validation loss: 1.9566932262912873

Epoch: 5| Step: 5
Training loss: 2.384350299835205
Validation loss: 1.956815056903388

Epoch: 5| Step: 6
Training loss: 2.1291184425354004
Validation loss: 1.979433141728883

Epoch: 5| Step: 7
Training loss: 2.2772879600524902
Validation loss: 1.9716298964715773

Epoch: 5| Step: 8
Training loss: 1.9980484247207642
Validation loss: 1.959813884509507

Epoch: 5| Step: 9
Training loss: 1.6714674234390259
Validation loss: 1.9536678688500517

Epoch: 5| Step: 10
Training loss: 2.282557249069214
Validation loss: 1.9837052770840224

Epoch: 145| Step: 0
Training loss: 2.102512836456299
Validation loss: 1.9784143329948507

Epoch: 5| Step: 1
Training loss: 2.0859782695770264
Validation loss: 1.9546834307332193

Epoch: 5| Step: 2
Training loss: 1.9985929727554321
Validation loss: 1.9584086928316342

Epoch: 5| Step: 3
Training loss: 1.6349998712539673
Validation loss: 1.9822807824739845

Epoch: 5| Step: 4
Training loss: 1.8609596490859985
Validation loss: 1.9779019996684084

Epoch: 5| Step: 5
Training loss: 2.4453768730163574
Validation loss: 1.9584512492661834

Epoch: 5| Step: 6
Training loss: 2.4391865730285645
Validation loss: 1.970909692907846

Epoch: 5| Step: 7
Training loss: 1.9730304479599
Validation loss: 1.9610242394990818

Epoch: 5| Step: 8
Training loss: 1.476884126663208
Validation loss: 1.9568027629647204

Epoch: 5| Step: 9
Training loss: 2.381819009780884
Validation loss: 1.9652177069776802

Epoch: 5| Step: 10
Training loss: 1.9234817028045654
Validation loss: 1.9718619802946686

Epoch: 146| Step: 0
Training loss: 2.309849262237549
Validation loss: 1.9816032558359125

Epoch: 5| Step: 1
Training loss: 1.5617057085037231
Validation loss: 1.9732660170524352

Epoch: 5| Step: 2
Training loss: 1.8392913341522217
Validation loss: 1.9775778811465028

Epoch: 5| Step: 3
Training loss: 2.0026769638061523
Validation loss: 1.9771124444982058

Epoch: 5| Step: 4
Training loss: 2.0612893104553223
Validation loss: 1.9617166621710664

Epoch: 5| Step: 5
Training loss: 2.581080198287964
Validation loss: 1.9679469600800545

Epoch: 5| Step: 6
Training loss: 1.4104937314987183
Validation loss: 1.9664053365748415

Epoch: 5| Step: 7
Training loss: 2.0865371227264404
Validation loss: 1.9793691763313868

Epoch: 5| Step: 8
Training loss: 2.526993751525879
Validation loss: 1.9650128913182083

Epoch: 5| Step: 9
Training loss: 2.2640464305877686
Validation loss: 1.9774910557654597

Epoch: 5| Step: 10
Training loss: 1.8406767845153809
Validation loss: 1.958638891097038

Epoch: 147| Step: 0
Training loss: 2.664605140686035
Validation loss: 1.9645511052941764

Epoch: 5| Step: 1
Training loss: 2.4852135181427
Validation loss: 1.9698064314421786

Epoch: 5| Step: 2
Training loss: 2.0542964935302734
Validation loss: 1.970657463996641

Epoch: 5| Step: 3
Training loss: 2.0264337062835693
Validation loss: 1.9682343903408255

Epoch: 5| Step: 4
Training loss: 1.3636738061904907
Validation loss: 1.9700373911088513

Epoch: 5| Step: 5
Training loss: 2.252822160720825
Validation loss: 1.9903730115582865

Epoch: 5| Step: 6
Training loss: 2.3804306983947754
Validation loss: 1.9873943380130235

Epoch: 5| Step: 7
Training loss: 1.7439861297607422
Validation loss: 1.969016857044671

Epoch: 5| Step: 8
Training loss: 1.7103214263916016
Validation loss: 1.9832897365734141

Epoch: 5| Step: 9
Training loss: 2.230797529220581
Validation loss: 1.9773176485492336

Epoch: 5| Step: 10
Training loss: 1.5417051315307617
Validation loss: 1.967770036830697

Epoch: 148| Step: 0
Training loss: 2.1533265113830566
Validation loss: 1.9759279463880806

Epoch: 5| Step: 1
Training loss: 1.7420613765716553
Validation loss: 1.9571873167509675

Epoch: 5| Step: 2
Training loss: 1.6177146434783936
Validation loss: 2.000722357021865

Epoch: 5| Step: 3
Training loss: 2.0162079334259033
Validation loss: 1.9790030141030588

Epoch: 5| Step: 4
Training loss: 1.2819926738739014
Validation loss: 1.968308743610177

Epoch: 5| Step: 5
Training loss: 2.0945448875427246
Validation loss: 1.958176633363129

Epoch: 5| Step: 6
Training loss: 2.479470729827881
Validation loss: 1.9728955876442693

Epoch: 5| Step: 7
Training loss: 1.991687536239624
Validation loss: 1.9673712650934856

Epoch: 5| Step: 8
Training loss: 2.1101226806640625
Validation loss: 1.9440631379363358

Epoch: 5| Step: 9
Training loss: 2.5213706493377686
Validation loss: 1.9547680372832923

Epoch: 5| Step: 10
Training loss: 2.5969338417053223
Validation loss: 1.9794656833012898

Epoch: 149| Step: 0
Training loss: 2.1872212886810303
Validation loss: 1.9960297076932845

Epoch: 5| Step: 1
Training loss: 2.06415057182312
Validation loss: 1.9631514395436933

Epoch: 5| Step: 2
Training loss: 1.827613115310669
Validation loss: 1.9644448218807098

Epoch: 5| Step: 3
Training loss: 1.8603652715682983
Validation loss: 1.9675835999109412

Epoch: 5| Step: 4
Training loss: 1.6317106485366821
Validation loss: 1.9667175790315032

Epoch: 5| Step: 5
Training loss: 2.6032042503356934
Validation loss: 1.9448561591486777

Epoch: 5| Step: 6
Training loss: 2.1779797077178955
Validation loss: 2.009848020410025

Epoch: 5| Step: 7
Training loss: 2.046199321746826
Validation loss: 1.9695101630303167

Epoch: 5| Step: 8
Training loss: 2.04860258102417
Validation loss: 1.966604184078914

Epoch: 5| Step: 9
Training loss: 2.0571227073669434
Validation loss: 1.9757384638632498

Epoch: 5| Step: 10
Training loss: 1.9642529487609863
Validation loss: 1.969340879430053

Epoch: 150| Step: 0
Training loss: 1.9464269876480103
Validation loss: 1.9695305798643379

Epoch: 5| Step: 1
Training loss: 1.633426308631897
Validation loss: 1.9797407606596589

Epoch: 5| Step: 2
Training loss: 1.9568780660629272
Validation loss: 1.9812517768593245

Epoch: 5| Step: 3
Training loss: 1.6877753734588623
Validation loss: 1.9750842432821951

Epoch: 5| Step: 4
Training loss: 2.0432701110839844
Validation loss: 1.984429770900357

Epoch: 5| Step: 5
Training loss: 2.1314444541931152
Validation loss: 1.9712900987235449

Epoch: 5| Step: 6
Training loss: 1.9623992443084717
Validation loss: 1.949804711085494

Epoch: 5| Step: 7
Training loss: 2.324960470199585
Validation loss: 1.972236746100969

Epoch: 5| Step: 8
Training loss: 2.2122726440429688
Validation loss: 1.9728318978381414

Epoch: 5| Step: 9
Training loss: 2.433683395385742
Validation loss: 1.9584909895414948

Epoch: 5| Step: 10
Training loss: 2.1486406326293945
Validation loss: 1.968576895293369

Epoch: 151| Step: 0
Training loss: 2.2848753929138184
Validation loss: 1.9727569536496234

Epoch: 5| Step: 1
Training loss: 1.787243127822876
Validation loss: 1.9618224482382498

Epoch: 5| Step: 2
Training loss: 2.517436981201172
Validation loss: 1.9818704435902257

Epoch: 5| Step: 3
Training loss: 2.4714043140411377
Validation loss: 1.9593604546721264

Epoch: 5| Step: 4
Training loss: 2.3155150413513184
Validation loss: 1.9590505682012087

Epoch: 5| Step: 5
Training loss: 1.3257451057434082
Validation loss: 1.9653018828361266

Epoch: 5| Step: 6
Training loss: 1.4501374959945679
Validation loss: 1.9577273040689447

Epoch: 5| Step: 7
Training loss: 1.921064019203186
Validation loss: 1.9598533902117001

Epoch: 5| Step: 8
Training loss: 2.0375583171844482
Validation loss: 1.9719884036689677

Epoch: 5| Step: 9
Training loss: 2.1163086891174316
Validation loss: 1.954029203743063

Epoch: 5| Step: 10
Training loss: 2.323063611984253
Validation loss: 1.9682447653944775

Epoch: 152| Step: 0
Training loss: 1.7103703022003174
Validation loss: 1.967508928750151

Epoch: 5| Step: 1
Training loss: 2.0955772399902344
Validation loss: 1.9553121776990994

Epoch: 5| Step: 2
Training loss: 2.651930093765259
Validation loss: 1.969744982257966

Epoch: 5| Step: 3
Training loss: 2.0061898231506348
Validation loss: 1.978141620594968

Epoch: 5| Step: 4
Training loss: 1.7511653900146484
Validation loss: 1.972805223157329

Epoch: 5| Step: 5
Training loss: 2.139953374862671
Validation loss: 1.9733521861414756

Epoch: 5| Step: 6
Training loss: 2.094726085662842
Validation loss: 1.9817494602613552

Epoch: 5| Step: 7
Training loss: 2.399113416671753
Validation loss: 1.98966432386829

Epoch: 5| Step: 8
Training loss: 2.080103635787964
Validation loss: 1.9632282936444847

Epoch: 5| Step: 9
Training loss: 1.2695385217666626
Validation loss: 1.957692055292027

Epoch: 5| Step: 10
Training loss: 2.158933639526367
Validation loss: 1.9488596275288572

Epoch: 153| Step: 0
Training loss: 1.3941271305084229
Validation loss: 1.9460698148255706

Epoch: 5| Step: 1
Training loss: 1.9774125814437866
Validation loss: 1.9684155910245833

Epoch: 5| Step: 2
Training loss: 1.9638055562973022
Validation loss: 1.9750766036331013

Epoch: 5| Step: 3
Training loss: 2.429555892944336
Validation loss: 1.936171644477434

Epoch: 5| Step: 4
Training loss: 1.8361732959747314
Validation loss: 1.9684083718125538

Epoch: 5| Step: 5
Training loss: 2.467827320098877
Validation loss: 1.9638735966015888

Epoch: 5| Step: 6
Training loss: 2.2393856048583984
Validation loss: 1.98219621053306

Epoch: 5| Step: 7
Training loss: 1.3742735385894775
Validation loss: 1.96659807748692

Epoch: 5| Step: 8
Training loss: 1.3506885766983032
Validation loss: 1.9678789210575882

Epoch: 5| Step: 9
Training loss: 2.272669553756714
Validation loss: 1.9926290486448555

Epoch: 5| Step: 10
Training loss: 3.075394868850708
Validation loss: 1.9681745088228615

Epoch: 154| Step: 0
Training loss: 1.8729385137557983
Validation loss: 1.9738270890328191

Epoch: 5| Step: 1
Training loss: 1.8624513149261475
Validation loss: 1.9686304471826042

Epoch: 5| Step: 2
Training loss: 2.3503048419952393
Validation loss: 1.9731552229132703

Epoch: 5| Step: 3
Training loss: 1.9071143865585327
Validation loss: 1.9815364114699825

Epoch: 5| Step: 4
Training loss: 1.8631255626678467
Validation loss: 1.9774701069760066

Epoch: 5| Step: 5
Training loss: 1.7479658126831055
Validation loss: 1.9855431356737692

Epoch: 5| Step: 6
Training loss: 2.2606420516967773
Validation loss: 1.9873155778454197

Epoch: 5| Step: 7
Training loss: 2.5552525520324707
Validation loss: 1.9714659990802887

Epoch: 5| Step: 8
Training loss: 1.7112305164337158
Validation loss: 1.9643993723777033

Epoch: 5| Step: 9
Training loss: 1.841833472251892
Validation loss: 1.976738847712035

Epoch: 5| Step: 10
Training loss: 2.3314707279205322
Validation loss: 1.9604705379855247

Epoch: 155| Step: 0
Training loss: 1.5466984510421753
Validation loss: 1.955608876802588

Epoch: 5| Step: 1
Training loss: 1.412703275680542
Validation loss: 1.934094855862279

Epoch: 5| Step: 2
Training loss: 2.008045196533203
Validation loss: 1.9541247070476573

Epoch: 5| Step: 3
Training loss: 2.2978591918945312
Validation loss: 1.9758076962604318

Epoch: 5| Step: 4
Training loss: 2.0338993072509766
Validation loss: 1.9454942557119554

Epoch: 5| Step: 5
Training loss: 2.2944207191467285
Validation loss: 1.9597379417829617

Epoch: 5| Step: 6
Training loss: 1.72585928440094
Validation loss: 1.9711796788759128

Epoch: 5| Step: 7
Training loss: 1.8842607736587524
Validation loss: 1.9642359543872137

Epoch: 5| Step: 8
Training loss: 2.415297746658325
Validation loss: 1.9614452136460172

Epoch: 5| Step: 9
Training loss: 2.2493808269500732
Validation loss: 1.9713117935324227

Epoch: 5| Step: 10
Training loss: 2.494471788406372
Validation loss: 1.9505799560136692

Epoch: 156| Step: 0
Training loss: 1.7755126953125
Validation loss: 1.9635075535825504

Epoch: 5| Step: 1
Training loss: 1.9074976444244385
Validation loss: 1.9773165666928856

Epoch: 5| Step: 2
Training loss: 1.8545624017715454
Validation loss: 1.9546799736638223

Epoch: 5| Step: 3
Training loss: 2.095057964324951
Validation loss: 1.966208892483865

Epoch: 5| Step: 4
Training loss: 2.693279981613159
Validation loss: 1.9927695066698137

Epoch: 5| Step: 5
Training loss: 1.7061221599578857
Validation loss: 1.9615428345177763

Epoch: 5| Step: 6
Training loss: 2.3445494174957275
Validation loss: 1.9725860523921188

Epoch: 5| Step: 7
Training loss: 2.1371359825134277
Validation loss: 1.9410174213429934

Epoch: 5| Step: 8
Training loss: 1.8421058654785156
Validation loss: 1.9654508149752052

Epoch: 5| Step: 9
Training loss: 1.5656654834747314
Validation loss: 1.9678799465138426

Epoch: 5| Step: 10
Training loss: 2.2928836345672607
Validation loss: 1.9751204380425074

Epoch: 157| Step: 0
Training loss: 1.539311170578003
Validation loss: 1.9988133868863505

Epoch: 5| Step: 1
Training loss: 1.9026530981063843
Validation loss: 1.9980084255177488

Epoch: 5| Step: 2
Training loss: 2.104712963104248
Validation loss: 1.9657358943775136

Epoch: 5| Step: 3
Training loss: 2.0879273414611816
Validation loss: 1.9836107556537916

Epoch: 5| Step: 4
Training loss: 2.392953395843506
Validation loss: 1.9858447351763326

Epoch: 5| Step: 5
Training loss: 1.928465485572815
Validation loss: 1.9765593198037916

Epoch: 5| Step: 6
Training loss: 2.00121808052063
Validation loss: 1.9709027198053175

Epoch: 5| Step: 7
Training loss: 1.9231185913085938
Validation loss: 1.9806363954338977

Epoch: 5| Step: 8
Training loss: 1.9028542041778564
Validation loss: 1.986963713040916

Epoch: 5| Step: 9
Training loss: 2.282140016555786
Validation loss: 1.973490971390919

Epoch: 5| Step: 10
Training loss: 2.269976854324341
Validation loss: 1.9870619286773026

Epoch: 158| Step: 0
Training loss: 1.9574527740478516
Validation loss: 1.978444818527468

Epoch: 5| Step: 1
Training loss: 2.4972894191741943
Validation loss: 1.9689737455819243

Epoch: 5| Step: 2
Training loss: 1.8988902568817139
Validation loss: 1.9851305356589697

Epoch: 5| Step: 3
Training loss: 1.622011423110962
Validation loss: 1.974762378200408

Epoch: 5| Step: 4
Training loss: 2.1731414794921875
Validation loss: 1.9957024692207255

Epoch: 5| Step: 5
Training loss: 1.899977445602417
Validation loss: 2.0055388148112963

Epoch: 5| Step: 6
Training loss: 2.106187105178833
Validation loss: 1.9688225741027503

Epoch: 5| Step: 7
Training loss: 2.444986581802368
Validation loss: 1.9796742726397771

Epoch: 5| Step: 8
Training loss: 1.7819242477416992
Validation loss: 1.9931900065432313

Epoch: 5| Step: 9
Training loss: 1.6516005992889404
Validation loss: 1.9804592645296486

Epoch: 5| Step: 10
Training loss: 2.0703465938568115
Validation loss: 1.9827080311313752

Epoch: 159| Step: 0
Training loss: 1.8069854974746704
Validation loss: 1.9836767514546711

Epoch: 5| Step: 1
Training loss: 1.6070419549942017
Validation loss: 1.9726770231800694

Epoch: 5| Step: 2
Training loss: 1.9988893270492554
Validation loss: 1.9576815610290856

Epoch: 5| Step: 3
Training loss: 2.544480800628662
Validation loss: 1.9407794988283547

Epoch: 5| Step: 4
Training loss: 2.12263822555542
Validation loss: 1.9595360461101736

Epoch: 5| Step: 5
Training loss: 1.850604772567749
Validation loss: 1.964873852268342

Epoch: 5| Step: 6
Training loss: 2.3926076889038086
Validation loss: 1.9747831359986336

Epoch: 5| Step: 7
Training loss: 2.0732030868530273
Validation loss: 1.9842941350834344

Epoch: 5| Step: 8
Training loss: 2.229452610015869
Validation loss: 1.9749647058466429

Epoch: 5| Step: 9
Training loss: 1.4699664115905762
Validation loss: 1.9784275049804358

Epoch: 5| Step: 10
Training loss: 2.0632083415985107
Validation loss: 1.963577942181659

Epoch: 160| Step: 0
Training loss: 1.8242981433868408
Validation loss: 1.9676035040168351

Epoch: 5| Step: 1
Training loss: 2.194629669189453
Validation loss: 1.966847171065628

Epoch: 5| Step: 2
Training loss: 2.6654727458953857
Validation loss: 1.9919375322198356

Epoch: 5| Step: 3
Training loss: 2.358452320098877
Validation loss: 1.993993277190834

Epoch: 5| Step: 4
Training loss: 2.272829055786133
Validation loss: 1.9908945496364305

Epoch: 5| Step: 5
Training loss: 1.7090473175048828
Validation loss: 1.9699174306725944

Epoch: 5| Step: 6
Training loss: 2.2409677505493164
Validation loss: 1.9778051914707306

Epoch: 5| Step: 7
Training loss: 1.1782244443893433
Validation loss: 1.97875347188724

Epoch: 5| Step: 8
Training loss: 1.589189052581787
Validation loss: 1.9697375964092951

Epoch: 5| Step: 9
Training loss: 2.400580644607544
Validation loss: 1.9502244944213538

Epoch: 5| Step: 10
Training loss: 1.7587889432907104
Validation loss: 1.9742445099738337

Epoch: 161| Step: 0
Training loss: 1.7679202556610107
Validation loss: 1.976225386383713

Epoch: 5| Step: 1
Training loss: 1.606553316116333
Validation loss: 1.9426193391123125

Epoch: 5| Step: 2
Training loss: 1.8272815942764282
Validation loss: 1.9742275540546705

Epoch: 5| Step: 3
Training loss: 2.065509796142578
Validation loss: 1.9613010447512391

Epoch: 5| Step: 4
Training loss: 2.6036133766174316
Validation loss: 1.972206582305252

Epoch: 5| Step: 5
Training loss: 1.9537750482559204
Validation loss: 1.994260803345711

Epoch: 5| Step: 6
Training loss: 2.04547381401062
Validation loss: 1.9670010484674925

Epoch: 5| Step: 7
Training loss: 2.171156167984009
Validation loss: 1.9710196474547028

Epoch: 5| Step: 8
Training loss: 2.391677141189575
Validation loss: 1.9702222270350302

Epoch: 5| Step: 9
Training loss: 2.2190849781036377
Validation loss: 1.9624322101634035

Epoch: 5| Step: 10
Training loss: 1.3218237161636353
Validation loss: 1.97181732936572

Epoch: 162| Step: 0
Training loss: 1.9688724279403687
Validation loss: 1.965303700457337

Epoch: 5| Step: 1
Training loss: 1.7716624736785889
Validation loss: 1.9621486253635858

Epoch: 5| Step: 2
Training loss: 1.8685210943222046
Validation loss: 1.9594810291003155

Epoch: 5| Step: 3
Training loss: 2.2591049671173096
Validation loss: 1.980508860721383

Epoch: 5| Step: 4
Training loss: 1.67401921749115
Validation loss: 1.977896055867595

Epoch: 5| Step: 5
Training loss: 2.122143507003784
Validation loss: 1.9714076288284794

Epoch: 5| Step: 6
Training loss: 1.9011863470077515
Validation loss: 1.9596181274742208

Epoch: 5| Step: 7
Training loss: 1.8560552597045898
Validation loss: 1.9465579755844609

Epoch: 5| Step: 8
Training loss: 2.2430427074432373
Validation loss: 1.9709632217243154

Epoch: 5| Step: 9
Training loss: 2.205252170562744
Validation loss: 1.9677416381015573

Epoch: 5| Step: 10
Training loss: 2.220769166946411
Validation loss: 1.9767796621527722

Epoch: 163| Step: 0
Training loss: 1.9195594787597656
Validation loss: 1.9724252262423116

Epoch: 5| Step: 1
Training loss: 2.2521939277648926
Validation loss: 1.9648472288603425

Epoch: 5| Step: 2
Training loss: 2.1786205768585205
Validation loss: 1.9658197177353727

Epoch: 5| Step: 3
Training loss: 2.1983237266540527
Validation loss: 1.9588418904171194

Epoch: 5| Step: 4
Training loss: 1.7363210916519165
Validation loss: 1.9571195533198695

Epoch: 5| Step: 5
Training loss: 2.0999953746795654
Validation loss: 1.962008119911276

Epoch: 5| Step: 6
Training loss: 1.7208287715911865
Validation loss: 1.9876037605347172

Epoch: 5| Step: 7
Training loss: 1.731050729751587
Validation loss: 1.9707047721391082

Epoch: 5| Step: 8
Training loss: 1.963661789894104
Validation loss: 1.9564624524885608

Epoch: 5| Step: 9
Training loss: 2.0430309772491455
Validation loss: 1.9601543923859954

Epoch: 5| Step: 10
Training loss: 2.1733648777008057
Validation loss: 1.948198349245133

Epoch: 164| Step: 0
Training loss: 2.4442968368530273
Validation loss: 1.9769681807487243

Epoch: 5| Step: 1
Training loss: 2.531926393508911
Validation loss: 1.9697659707838489

Epoch: 5| Step: 2
Training loss: 1.4254820346832275
Validation loss: 1.9535118072263655

Epoch: 5| Step: 3
Training loss: 1.705491304397583
Validation loss: 1.9770375041551487

Epoch: 5| Step: 4
Training loss: 1.8953231573104858
Validation loss: 1.9554421119792487

Epoch: 5| Step: 5
Training loss: 2.5117053985595703
Validation loss: 1.986365742580865

Epoch: 5| Step: 6
Training loss: 1.5193241834640503
Validation loss: 1.9754724451290664

Epoch: 5| Step: 7
Training loss: 2.0861968994140625
Validation loss: 1.9809957409417758

Epoch: 5| Step: 8
Training loss: 2.296499252319336
Validation loss: 1.9997980825362667

Epoch: 5| Step: 9
Training loss: 1.8156814575195312
Validation loss: 1.9634725380969305

Epoch: 5| Step: 10
Training loss: 1.8684453964233398
Validation loss: 1.9967826335660872

Epoch: 165| Step: 0
Training loss: 1.7793285846710205
Validation loss: 1.9636909384881296

Epoch: 5| Step: 1
Training loss: 2.2260661125183105
Validation loss: 1.967200615072763

Epoch: 5| Step: 2
Training loss: 2.0889453887939453
Validation loss: 1.9790422698502899

Epoch: 5| Step: 3
Training loss: 2.377331495285034
Validation loss: 1.996764003589589

Epoch: 5| Step: 4
Training loss: 1.3685203790664673
Validation loss: 1.9691691834439513

Epoch: 5| Step: 5
Training loss: 1.540184497833252
Validation loss: 1.9619110553495345

Epoch: 5| Step: 6
Training loss: 2.480407238006592
Validation loss: 1.9667312342633483

Epoch: 5| Step: 7
Training loss: 1.9322681427001953
Validation loss: 1.9661557212952645

Epoch: 5| Step: 8
Training loss: 1.7108453512191772
Validation loss: 1.9828721297684537

Epoch: 5| Step: 9
Training loss: 2.2032980918884277
Validation loss: 1.9673883504765008

Epoch: 5| Step: 10
Training loss: 2.2747230529785156
Validation loss: 1.9600463554423342

Epoch: 166| Step: 0
Training loss: 2.3605921268463135
Validation loss: 1.9858200075805827

Epoch: 5| Step: 1
Training loss: 2.0949015617370605
Validation loss: 1.980950128647589

Epoch: 5| Step: 2
Training loss: 2.423381805419922
Validation loss: 1.9651253325964815

Epoch: 5| Step: 3
Training loss: 2.2518229484558105
Validation loss: 1.9778286757007721

Epoch: 5| Step: 4
Training loss: 1.8435258865356445
Validation loss: 1.9904376255568637

Epoch: 5| Step: 5
Training loss: 2.200768232345581
Validation loss: 1.9764811056916431

Epoch: 5| Step: 6
Training loss: 2.0912234783172607
Validation loss: 1.974655415422173

Epoch: 5| Step: 7
Training loss: 1.827951192855835
Validation loss: 1.9764241864604335

Epoch: 5| Step: 8
Training loss: 1.284467339515686
Validation loss: 1.9885113264924736

Epoch: 5| Step: 9
Training loss: 1.9482837915420532
Validation loss: 1.9839604746910833

Epoch: 5| Step: 10
Training loss: 1.7125452756881714
Validation loss: 1.9756198775383733

Epoch: 167| Step: 0
Training loss: 1.515465497970581
Validation loss: 1.9838916665764266

Epoch: 5| Step: 1
Training loss: 2.474748134613037
Validation loss: 1.978156082091793

Epoch: 5| Step: 2
Training loss: 2.4873101711273193
Validation loss: 1.9586429352401404

Epoch: 5| Step: 3
Training loss: 2.522509813308716
Validation loss: 1.9859292494353427

Epoch: 5| Step: 4
Training loss: 1.8873554468154907
Validation loss: 1.9689832425886584

Epoch: 5| Step: 5
Training loss: 2.017162322998047
Validation loss: 1.9711515160017117

Epoch: 5| Step: 6
Training loss: 1.4797011613845825
Validation loss: 1.983006667065364

Epoch: 5| Step: 7
Training loss: 1.4633550643920898
Validation loss: 1.966719578671199

Epoch: 5| Step: 8
Training loss: 1.9810736179351807
Validation loss: 1.96335385435371

Epoch: 5| Step: 9
Training loss: 1.859379529953003
Validation loss: 1.9771460474178355

Epoch: 5| Step: 10
Training loss: 2.265669584274292
Validation loss: 1.9743788447431339

Epoch: 168| Step: 0
Training loss: 1.246564269065857
Validation loss: 1.9894360701243083

Epoch: 5| Step: 1
Training loss: 2.211268186569214
Validation loss: 1.9670667135587303

Epoch: 5| Step: 2
Training loss: 2.3458149433135986
Validation loss: 1.9899785326373192

Epoch: 5| Step: 3
Training loss: 1.8161605596542358
Validation loss: 1.959397533888458

Epoch: 5| Step: 4
Training loss: 1.793205976486206
Validation loss: 1.9785803594896871

Epoch: 5| Step: 5
Training loss: 2.3436779975891113
Validation loss: 1.9660747743421985

Epoch: 5| Step: 6
Training loss: 1.7907822132110596
Validation loss: 1.9735674140273884

Epoch: 5| Step: 7
Training loss: 1.8834460973739624
Validation loss: 1.9633333311286023

Epoch: 5| Step: 8
Training loss: 1.889776587486267
Validation loss: 1.9759692543296403

Epoch: 5| Step: 9
Training loss: 2.330557107925415
Validation loss: 1.9817842616829822

Epoch: 5| Step: 10
Training loss: 2.3666255474090576
Validation loss: 1.9642288915572628

Epoch: 169| Step: 0
Training loss: 1.9757969379425049
Validation loss: 1.9638138509565783

Epoch: 5| Step: 1
Training loss: 1.6348772048950195
Validation loss: 1.9565911139211347

Epoch: 5| Step: 2
Training loss: 2.3141651153564453
Validation loss: 1.9777211014942457

Epoch: 5| Step: 3
Training loss: 1.4511463642120361
Validation loss: 1.9949163993199666

Epoch: 5| Step: 4
Training loss: 1.6418430805206299
Validation loss: 1.9712343215942383

Epoch: 5| Step: 5
Training loss: 2.2023894786834717
Validation loss: 1.9783394798155753

Epoch: 5| Step: 6
Training loss: 2.0853114128112793
Validation loss: 1.9727845550865255

Epoch: 5| Step: 7
Training loss: 2.040288209915161
Validation loss: 1.9552290221696258

Epoch: 5| Step: 8
Training loss: 2.5128142833709717
Validation loss: 1.9485312866908249

Epoch: 5| Step: 9
Training loss: 1.7422195672988892
Validation loss: 1.966508565410491

Epoch: 5| Step: 10
Training loss: 2.534640312194824
Validation loss: 1.9526169633352628

Epoch: 170| Step: 0
Training loss: 2.1606240272521973
Validation loss: 1.9719748727736934

Epoch: 5| Step: 1
Training loss: 1.9636205434799194
Validation loss: 1.9708349140741492

Epoch: 5| Step: 2
Training loss: 2.080794095993042
Validation loss: 1.96772595631179

Epoch: 5| Step: 3
Training loss: 1.7764804363250732
Validation loss: 1.9816074999429847

Epoch: 5| Step: 4
Training loss: 1.40108323097229
Validation loss: 1.9832582563482306

Epoch: 5| Step: 5
Training loss: 2.4071013927459717
Validation loss: 1.958598727821022

Epoch: 5| Step: 6
Training loss: 2.419527292251587
Validation loss: 1.9819300020894697

Epoch: 5| Step: 7
Training loss: 1.8311678171157837
Validation loss: 1.974314167935361

Epoch: 5| Step: 8
Training loss: 1.7987626791000366
Validation loss: 1.9379489383389872

Epoch: 5| Step: 9
Training loss: 2.1109492778778076
Validation loss: 2.009709444097293

Epoch: 5| Step: 10
Training loss: 1.991614580154419
Validation loss: 1.997823489609585

Epoch: 171| Step: 0
Training loss: 1.8396027088165283
Validation loss: 2.0093805405401413

Epoch: 5| Step: 1
Training loss: 2.439164638519287
Validation loss: 1.9660819012631652

Epoch: 5| Step: 2
Training loss: 1.7943055629730225
Validation loss: 1.9622152697655462

Epoch: 5| Step: 3
Training loss: 2.1625285148620605
Validation loss: 1.983919184695008

Epoch: 5| Step: 4
Training loss: 1.8221670389175415
Validation loss: 1.9828660449674052

Epoch: 5| Step: 5
Training loss: 1.6739250421524048
Validation loss: 1.9533085105239705

Epoch: 5| Step: 6
Training loss: 2.2203691005706787
Validation loss: 1.9814435076969925

Epoch: 5| Step: 7
Training loss: 2.0249404907226562
Validation loss: 1.9585068097678564

Epoch: 5| Step: 8
Training loss: 1.648229956626892
Validation loss: 1.9784274255075762

Epoch: 5| Step: 9
Training loss: 1.6920216083526611
Validation loss: 1.966973949504155

Epoch: 5| Step: 10
Training loss: 2.7773993015289307
Validation loss: 1.9841130061816143

Epoch: 172| Step: 0
Training loss: 1.5748530626296997
Validation loss: 1.9828745934271044

Epoch: 5| Step: 1
Training loss: 1.3505754470825195
Validation loss: 1.93141689608174

Epoch: 5| Step: 2
Training loss: 1.7819812297821045
Validation loss: 1.9859205112662366

Epoch: 5| Step: 3
Training loss: 2.159576416015625
Validation loss: 1.978586519918134

Epoch: 5| Step: 4
Training loss: 1.8311645984649658
Validation loss: 2.0064982560373124

Epoch: 5| Step: 5
Training loss: 2.7246463298797607
Validation loss: 1.9903227898382372

Epoch: 5| Step: 6
Training loss: 2.697885513305664
Validation loss: 1.9786170259598763

Epoch: 5| Step: 7
Training loss: 1.7064030170440674
Validation loss: 1.9788511389045305

Epoch: 5| Step: 8
Training loss: 2.0132062435150146
Validation loss: 1.9779059412658855

Epoch: 5| Step: 9
Training loss: 1.798893690109253
Validation loss: 1.9891662443837812

Epoch: 5| Step: 10
Training loss: 2.07879376411438
Validation loss: 1.968268281670027

Epoch: 173| Step: 0
Training loss: 2.4001293182373047
Validation loss: 1.9922497144309423

Epoch: 5| Step: 1
Training loss: 2.0070552825927734
Validation loss: 1.9838490332326582

Epoch: 5| Step: 2
Training loss: 2.092647075653076
Validation loss: 1.967902765479139

Epoch: 5| Step: 3
Training loss: 1.8081562519073486
Validation loss: 1.954345344215311

Epoch: 5| Step: 4
Training loss: 2.077533721923828
Validation loss: 1.99244527534772

Epoch: 5| Step: 5
Training loss: 1.8515125513076782
Validation loss: 1.9888975389542118

Epoch: 5| Step: 6
Training loss: 1.62644362449646
Validation loss: 1.9730095145522908

Epoch: 5| Step: 7
Training loss: 1.5469715595245361
Validation loss: 1.983197335273989

Epoch: 5| Step: 8
Training loss: 2.211263656616211
Validation loss: 1.9845616266291628

Epoch: 5| Step: 9
Training loss: 2.2489583492279053
Validation loss: 1.962654967461863

Epoch: 5| Step: 10
Training loss: 1.8091710805892944
Validation loss: 1.9826540511141542

Epoch: 174| Step: 0
Training loss: 1.7660150527954102
Validation loss: 1.9806888411121983

Epoch: 5| Step: 1
Training loss: 2.1996448040008545
Validation loss: 1.991546856459751

Epoch: 5| Step: 2
Training loss: 1.8784477710723877
Validation loss: 1.9950930098051667

Epoch: 5| Step: 3
Training loss: 2.103710174560547
Validation loss: 1.974740303972716

Epoch: 5| Step: 4
Training loss: 2.1115736961364746
Validation loss: 1.991955969923286

Epoch: 5| Step: 5
Training loss: 1.9837688207626343
Validation loss: 1.975114571150913

Epoch: 5| Step: 6
Training loss: 1.6365540027618408
Validation loss: 1.965240264451632

Epoch: 5| Step: 7
Training loss: 1.859323501586914
Validation loss: 1.9692146470469813

Epoch: 5| Step: 8
Training loss: 2.5600666999816895
Validation loss: 1.996375294141872

Epoch: 5| Step: 9
Training loss: 1.8528865575790405
Validation loss: 1.9653653149963708

Epoch: 5| Step: 10
Training loss: 2.0220279693603516
Validation loss: 1.9794500130479054

Epoch: 175| Step: 0
Training loss: 2.1309351921081543
Validation loss: 1.9535011091539938

Epoch: 5| Step: 1
Training loss: 2.40818452835083
Validation loss: 1.9712817643278389

Epoch: 5| Step: 2
Training loss: 1.7167307138442993
Validation loss: 1.9643541356568694

Epoch: 5| Step: 3
Training loss: 1.9797999858856201
Validation loss: 1.9727515225769372

Epoch: 5| Step: 4
Training loss: 1.480794072151184
Validation loss: 1.9626083938024377

Epoch: 5| Step: 5
Training loss: 2.346289873123169
Validation loss: 1.982251742834686

Epoch: 5| Step: 6
Training loss: 1.5296142101287842
Validation loss: 1.9708006535806963

Epoch: 5| Step: 7
Training loss: 2.7487075328826904
Validation loss: 1.9592037649564846

Epoch: 5| Step: 8
Training loss: 1.8961684703826904
Validation loss: 1.9589354030547603

Epoch: 5| Step: 9
Training loss: 2.1200833320617676
Validation loss: 1.9675266153068953

Epoch: 5| Step: 10
Training loss: 1.1510504484176636
Validation loss: 1.9653444674707228

Epoch: 176| Step: 0
Training loss: 2.4445738792419434
Validation loss: 1.967971585130179

Epoch: 5| Step: 1
Training loss: 1.1064932346343994
Validation loss: 1.9799362049307874

Epoch: 5| Step: 2
Training loss: 1.708190679550171
Validation loss: 1.9694130497594033

Epoch: 5| Step: 3
Training loss: 2.017346143722534
Validation loss: 1.984134699708672

Epoch: 5| Step: 4
Training loss: 1.9288676977157593
Validation loss: 1.9820630037656395

Epoch: 5| Step: 5
Training loss: 2.139345407485962
Validation loss: 1.965395676192417

Epoch: 5| Step: 6
Training loss: 1.7217273712158203
Validation loss: 1.9814866242870208

Epoch: 5| Step: 7
Training loss: 2.479613780975342
Validation loss: 1.9961768965567313

Epoch: 5| Step: 8
Training loss: 2.102900266647339
Validation loss: 1.9624845597051805

Epoch: 5| Step: 9
Training loss: 2.1575019359588623
Validation loss: 1.9707215088669972

Epoch: 5| Step: 10
Training loss: 1.740234375
Validation loss: 1.9989247193900488

Epoch: 177| Step: 0
Training loss: 2.3180203437805176
Validation loss: 1.9906388149466565

Epoch: 5| Step: 1
Training loss: 1.9365959167480469
Validation loss: 1.9794861270535378

Epoch: 5| Step: 2
Training loss: 2.1673171520233154
Validation loss: 1.9825387231765255

Epoch: 5| Step: 3
Training loss: 1.5497353076934814
Validation loss: 1.9725425499741749

Epoch: 5| Step: 4
Training loss: 1.8954353332519531
Validation loss: 1.9822176887143044

Epoch: 5| Step: 5
Training loss: 1.9264647960662842
Validation loss: 1.9939978430348058

Epoch: 5| Step: 6
Training loss: 1.5133733749389648
Validation loss: 1.962480350207257

Epoch: 5| Step: 7
Training loss: 2.1373374462127686
Validation loss: 1.9912933149645407

Epoch: 5| Step: 8
Training loss: 1.9903888702392578
Validation loss: 1.9639671682029642

Epoch: 5| Step: 9
Training loss: 2.044834613800049
Validation loss: 1.9819934239951513

Epoch: 5| Step: 10
Training loss: 2.24371075630188
Validation loss: 1.958893532394081

Epoch: 178| Step: 0
Training loss: 2.34559965133667
Validation loss: 1.9690788048569874

Epoch: 5| Step: 1
Training loss: 1.6911275386810303
Validation loss: 1.964912683733048

Epoch: 5| Step: 2
Training loss: 2.473668098449707
Validation loss: 1.984415054321289

Epoch: 5| Step: 3
Training loss: 2.040463447570801
Validation loss: 1.9630831556935464

Epoch: 5| Step: 4
Training loss: 1.7334716320037842
Validation loss: 2.001457634792533

Epoch: 5| Step: 5
Training loss: 1.753096342086792
Validation loss: 1.9818451763481222

Epoch: 5| Step: 6
Training loss: 1.8201862573623657
Validation loss: 1.9725225830590853

Epoch: 5| Step: 7
Training loss: 2.080336093902588
Validation loss: 1.9510080942543604

Epoch: 5| Step: 8
Training loss: 2.1639912128448486
Validation loss: 1.99905312830402

Epoch: 5| Step: 9
Training loss: 2.1958203315734863
Validation loss: 1.9873985346927439

Epoch: 5| Step: 10
Training loss: 1.4463567733764648
Validation loss: 1.995391620102749

Epoch: 179| Step: 0
Training loss: 2.815664529800415
Validation loss: 1.9849210298189552

Epoch: 5| Step: 1
Training loss: 2.952442169189453
Validation loss: 1.971253889863209

Epoch: 5| Step: 2
Training loss: 2.1528284549713135
Validation loss: 1.9886210208298059

Epoch: 5| Step: 3
Training loss: 1.4188258647918701
Validation loss: 1.9771930043415358

Epoch: 5| Step: 4
Training loss: 1.7437412738800049
Validation loss: 1.9763809096428655

Epoch: 5| Step: 5
Training loss: 1.632696509361267
Validation loss: 1.9637819772125573

Epoch: 5| Step: 6
Training loss: 1.8762775659561157
Validation loss: 2.0045390718726703

Epoch: 5| Step: 7
Training loss: 1.7082430124282837
Validation loss: 1.9651589034706034

Epoch: 5| Step: 8
Training loss: 1.603329062461853
Validation loss: 1.9720359451027327

Epoch: 5| Step: 9
Training loss: 2.1214406490325928
Validation loss: 1.9928936625039706

Epoch: 5| Step: 10
Training loss: 1.5734717845916748
Validation loss: 2.008112374172416

Epoch: 180| Step: 0
Training loss: 1.7051708698272705
Validation loss: 1.9862517579909293

Epoch: 5| Step: 1
Training loss: 1.8145170211791992
Validation loss: 1.991537154361766

Epoch: 5| Step: 2
Training loss: 1.9149703979492188
Validation loss: 1.9950966245384627

Epoch: 5| Step: 3
Training loss: 2.3102900981903076
Validation loss: 1.997843421915526

Epoch: 5| Step: 4
Training loss: 1.8694292306900024
Validation loss: 2.001418446981779

Epoch: 5| Step: 5
Training loss: 2.1976451873779297
Validation loss: 1.9805535770231677

Epoch: 5| Step: 6
Training loss: 1.9592256546020508
Validation loss: 1.9646398713511806

Epoch: 5| Step: 7
Training loss: 2.2334659099578857
Validation loss: 1.9954561251465992

Epoch: 5| Step: 8
Training loss: 1.7212378978729248
Validation loss: 2.0091745289423133

Epoch: 5| Step: 9
Training loss: 1.8891208171844482
Validation loss: 2.0023011622890348

Epoch: 5| Step: 10
Training loss: 1.761156439781189
Validation loss: 1.961858041824833

Epoch: 181| Step: 0
Training loss: 2.1835639476776123
Validation loss: 1.9676669361770793

Epoch: 5| Step: 1
Training loss: 2.4075756072998047
Validation loss: 1.983655188673286

Epoch: 5| Step: 2
Training loss: 1.8101507425308228
Validation loss: 1.980589715383386

Epoch: 5| Step: 3
Training loss: 1.7013952732086182
Validation loss: 1.9847502926344514

Epoch: 5| Step: 4
Training loss: 1.8164043426513672
Validation loss: 1.9842936121007448

Epoch: 5| Step: 5
Training loss: 2.202538251876831
Validation loss: 1.9900350775769962

Epoch: 5| Step: 6
Training loss: 1.9984747171401978
Validation loss: 1.9845034768504481

Epoch: 5| Step: 7
Training loss: 1.9848105907440186
Validation loss: 1.9619537963662097

Epoch: 5| Step: 8
Training loss: 1.5085976123809814
Validation loss: 1.9528500777418896

Epoch: 5| Step: 9
Training loss: 1.6805799007415771
Validation loss: 1.988915556220598

Epoch: 5| Step: 10
Training loss: 2.267190933227539
Validation loss: 1.9756067465710383

Epoch: 182| Step: 0
Training loss: 2.351954936981201
Validation loss: 1.9740048736654303

Epoch: 5| Step: 1
Training loss: 1.9822165966033936
Validation loss: 1.9892476912467711

Epoch: 5| Step: 2
Training loss: 1.46897292137146
Validation loss: 1.9635500702806699

Epoch: 5| Step: 3
Training loss: 1.6618220806121826
Validation loss: 1.986843062985328

Epoch: 5| Step: 4
Training loss: 1.9271665811538696
Validation loss: 1.9850626094366914

Epoch: 5| Step: 5
Training loss: 2.194045305252075
Validation loss: 1.9839377582714122

Epoch: 5| Step: 6
Training loss: 2.324026107788086
Validation loss: 1.9590201377868652

Epoch: 5| Step: 7
Training loss: 1.8565791845321655
Validation loss: 1.9902073247458345

Epoch: 5| Step: 8
Training loss: 2.187551498413086
Validation loss: 1.967646268106276

Epoch: 5| Step: 9
Training loss: 1.6154295206069946
Validation loss: 1.9995810242109402

Epoch: 5| Step: 10
Training loss: 1.9891657829284668
Validation loss: 1.9899710506521247

Epoch: 183| Step: 0
Training loss: 2.405430316925049
Validation loss: 1.98678679620066

Epoch: 5| Step: 1
Training loss: 2.099838972091675
Validation loss: 1.9831633362718808

Epoch: 5| Step: 2
Training loss: 2.050687313079834
Validation loss: 1.9676220250386063

Epoch: 5| Step: 3
Training loss: 1.7210760116577148
Validation loss: 1.996909329968114

Epoch: 5| Step: 4
Training loss: 1.8918876647949219
Validation loss: 1.9840829205769364

Epoch: 5| Step: 5
Training loss: 2.123093605041504
Validation loss: 1.9727384249369304

Epoch: 5| Step: 6
Training loss: 1.6899654865264893
Validation loss: 1.9604672437073083

Epoch: 5| Step: 7
Training loss: 1.8177207708358765
Validation loss: 1.9962789281722038

Epoch: 5| Step: 8
Training loss: 2.1207199096679688
Validation loss: 1.9902958305933143

Epoch: 5| Step: 9
Training loss: 2.210710048675537
Validation loss: 1.9669401273932507

Epoch: 5| Step: 10
Training loss: 1.7262424230575562
Validation loss: 1.9854605851634857

Epoch: 184| Step: 0
Training loss: 2.2294514179229736
Validation loss: 1.9795428219661917

Epoch: 5| Step: 1
Training loss: 2.2803523540496826
Validation loss: 1.969496036088595

Epoch: 5| Step: 2
Training loss: 1.3335942029953003
Validation loss: 1.9922096985642628

Epoch: 5| Step: 3
Training loss: 1.8954139947891235
Validation loss: 1.9814854129668205

Epoch: 5| Step: 4
Training loss: 2.5901124477386475
Validation loss: 1.9814321302598523

Epoch: 5| Step: 5
Training loss: 2.2051990032196045
Validation loss: 1.9980849027633667

Epoch: 5| Step: 6
Training loss: 1.1412413120269775
Validation loss: 1.9961702631365867

Epoch: 5| Step: 7
Training loss: 1.7623987197875977
Validation loss: 1.9854616606107323

Epoch: 5| Step: 8
Training loss: 2.118997573852539
Validation loss: 1.984101180107363

Epoch: 5| Step: 9
Training loss: 1.6917794942855835
Validation loss: 1.9848166447813793

Epoch: 5| Step: 10
Training loss: 2.4680919647216797
Validation loss: 1.9826180396541473

Epoch: 185| Step: 0
Training loss: 2.0840041637420654
Validation loss: 1.9732220531791769

Epoch: 5| Step: 1
Training loss: 1.956705093383789
Validation loss: 1.9928608222674298

Epoch: 5| Step: 2
Training loss: 1.9305264949798584
Validation loss: 1.9563428689074773

Epoch: 5| Step: 3
Training loss: 1.5896638631820679
Validation loss: 1.9477185369819723

Epoch: 5| Step: 4
Training loss: 2.4703404903411865
Validation loss: 1.9932055883510138

Epoch: 5| Step: 5
Training loss: 2.438930034637451
Validation loss: 1.9506743569527902

Epoch: 5| Step: 6
Training loss: 1.943023920059204
Validation loss: 1.9952493906021118

Epoch: 5| Step: 7
Training loss: 1.5258278846740723
Validation loss: 1.978295926124819

Epoch: 5| Step: 8
Training loss: 1.640364408493042
Validation loss: 1.9713155966933056

Epoch: 5| Step: 9
Training loss: 2.0538361072540283
Validation loss: 1.9919363208996352

Epoch: 5| Step: 10
Training loss: 1.930729866027832
Validation loss: 1.957974095498362

Epoch: 186| Step: 0
Training loss: 2.020156145095825
Validation loss: 1.977976014537196

Epoch: 5| Step: 1
Training loss: 2.4425723552703857
Validation loss: 1.9756783041902768

Epoch: 5| Step: 2
Training loss: 1.2270638942718506
Validation loss: 1.9635416230847758

Epoch: 5| Step: 3
Training loss: 2.396747350692749
Validation loss: 1.9781535876694547

Epoch: 5| Step: 4
Training loss: 2.3353374004364014
Validation loss: 1.9880722081789406

Epoch: 5| Step: 5
Training loss: 1.9894825220108032
Validation loss: 1.9806673629309541

Epoch: 5| Step: 6
Training loss: 2.0227413177490234
Validation loss: 1.9878448171000327

Epoch: 5| Step: 7
Training loss: 1.8208519220352173
Validation loss: 2.0013353132432505

Epoch: 5| Step: 8
Training loss: 1.9972747564315796
Validation loss: 1.9945836631200646

Epoch: 5| Step: 9
Training loss: 1.8384902477264404
Validation loss: 2.024433451314126

Epoch: 5| Step: 10
Training loss: 1.4278095960617065
Validation loss: 1.9739921246805499

Epoch: 187| Step: 0
Training loss: 2.1575512886047363
Validation loss: 1.9873919794636388

Epoch: 5| Step: 1
Training loss: 1.8881762027740479
Validation loss: 1.9741957303016417

Epoch: 5| Step: 2
Training loss: 1.7546260356903076
Validation loss: 1.9940968931362193

Epoch: 5| Step: 3
Training loss: 1.8774868249893188
Validation loss: 1.9798549311135405

Epoch: 5| Step: 4
Training loss: 1.5686107873916626
Validation loss: 1.9977596498304797

Epoch: 5| Step: 5
Training loss: 1.638257622718811
Validation loss: 1.9929964952571417

Epoch: 5| Step: 6
Training loss: 2.007037878036499
Validation loss: 1.9619826155324136

Epoch: 5| Step: 7
Training loss: 2.4834280014038086
Validation loss: 1.969389324547142

Epoch: 5| Step: 8
Training loss: 2.1641182899475098
Validation loss: 1.9889354590446717

Epoch: 5| Step: 9
Training loss: 2.3483753204345703
Validation loss: 1.9781762323071879

Epoch: 5| Step: 10
Training loss: 1.487962245941162
Validation loss: 2.0031274595568256

Epoch: 188| Step: 0
Training loss: 2.090343475341797
Validation loss: 1.9678045216427054

Epoch: 5| Step: 1
Training loss: 1.8005577325820923
Validation loss: 1.9792153091840847

Epoch: 5| Step: 2
Training loss: 1.526005744934082
Validation loss: 1.9812744894335348

Epoch: 5| Step: 3
Training loss: 2.150109052658081
Validation loss: 1.9733657131912887

Epoch: 5| Step: 4
Training loss: 1.9401633739471436
Validation loss: 1.9667275003207627

Epoch: 5| Step: 5
Training loss: 1.4306061267852783
Validation loss: 1.966523793435866

Epoch: 5| Step: 6
Training loss: 1.9825565814971924
Validation loss: 1.9674392836068266

Epoch: 5| Step: 7
Training loss: 2.4795422554016113
Validation loss: 1.9827865618531422

Epoch: 5| Step: 8
Training loss: 1.9743945598602295
Validation loss: 1.9834277706761514

Epoch: 5| Step: 9
Training loss: 1.9931824207305908
Validation loss: 2.001399593968545

Epoch: 5| Step: 10
Training loss: 2.2736711502075195
Validation loss: 1.965063097656414

Epoch: 189| Step: 0
Training loss: 1.8705867528915405
Validation loss: 2.001652973954396

Epoch: 5| Step: 1
Training loss: 1.5846951007843018
Validation loss: 1.9832121146622526

Epoch: 5| Step: 2
Training loss: 2.1147568225860596
Validation loss: 1.9794522459788988

Epoch: 5| Step: 3
Training loss: 1.8428640365600586
Validation loss: 1.967445312007781

Epoch: 5| Step: 4
Training loss: 1.7920494079589844
Validation loss: 1.964498512206539

Epoch: 5| Step: 5
Training loss: 2.16634202003479
Validation loss: 1.984347749781865

Epoch: 5| Step: 6
Training loss: 2.3536009788513184
Validation loss: 1.9726440803979033

Epoch: 5| Step: 7
Training loss: 2.2983298301696777
Validation loss: 1.9870201349258423

Epoch: 5| Step: 8
Training loss: 1.7257163524627686
Validation loss: 1.9925957238802345

Epoch: 5| Step: 9
Training loss: 2.1122288703918457
Validation loss: 1.9770479343270744

Epoch: 5| Step: 10
Training loss: 1.4007155895233154
Validation loss: 1.994570086079259

Epoch: 190| Step: 0
Training loss: 1.7779910564422607
Validation loss: 2.0123802397840764

Epoch: 5| Step: 1
Training loss: 1.6252782344818115
Validation loss: 2.016661112026502

Epoch: 5| Step: 2
Training loss: 2.0397815704345703
Validation loss: 1.9967109182829499

Epoch: 5| Step: 3
Training loss: 1.8239580392837524
Validation loss: 1.9860995918191888

Epoch: 5| Step: 4
Training loss: 1.52120840549469
Validation loss: 2.008897342989522

Epoch: 5| Step: 5
Training loss: 2.1933906078338623
Validation loss: 1.9754451192835325

Epoch: 5| Step: 6
Training loss: 1.9930274486541748
Validation loss: 1.9980403812982703

Epoch: 5| Step: 7
Training loss: 2.154318332672119
Validation loss: 2.0066150926774546

Epoch: 5| Step: 8
Training loss: 2.039212465286255
Validation loss: 2.003116197483514

Epoch: 5| Step: 9
Training loss: 2.500082015991211
Validation loss: 1.9991713211100588

Epoch: 5| Step: 10
Training loss: 1.6801064014434814
Validation loss: 1.9706668840941561

Epoch: 191| Step: 0
Training loss: 2.05698823928833
Validation loss: 1.991476357624095

Epoch: 5| Step: 1
Training loss: 2.101501941680908
Validation loss: 1.9795121326241443

Epoch: 5| Step: 2
Training loss: 2.093113899230957
Validation loss: 2.0048153643967

Epoch: 5| Step: 3
Training loss: 1.8569755554199219
Validation loss: 2.0034543263014926

Epoch: 5| Step: 4
Training loss: 1.3487350940704346
Validation loss: 1.9911449750264485

Epoch: 5| Step: 5
Training loss: 1.7186062335968018
Validation loss: 1.9897683128233878

Epoch: 5| Step: 6
Training loss: 2.177894353866577
Validation loss: 1.980966821793587

Epoch: 5| Step: 7
Training loss: 2.071354389190674
Validation loss: 1.9887150743956208

Epoch: 5| Step: 8
Training loss: 2.3410675525665283
Validation loss: 1.9746371315371605

Epoch: 5| Step: 9
Training loss: 1.8878600597381592
Validation loss: 1.9896877183709094

Epoch: 5| Step: 10
Training loss: 1.742844820022583
Validation loss: 1.9766628562763173

Epoch: 192| Step: 0
Training loss: 1.586625337600708
Validation loss: 1.9664842274881178

Epoch: 5| Step: 1
Training loss: 1.613256812095642
Validation loss: 1.9785672964588288

Epoch: 5| Step: 2
Training loss: 1.8792070150375366
Validation loss: 1.9671854229383572

Epoch: 5| Step: 3
Training loss: 2.15991473197937
Validation loss: 1.9720354105836602

Epoch: 5| Step: 4
Training loss: 1.8948085308074951
Validation loss: 1.9815560886936803

Epoch: 5| Step: 5
Training loss: 1.944087266921997
Validation loss: 1.9635213857055993

Epoch: 5| Step: 6
Training loss: 2.0225181579589844
Validation loss: 1.9898577351723947

Epoch: 5| Step: 7
Training loss: 1.9184377193450928
Validation loss: 1.9781021123291345

Epoch: 5| Step: 8
Training loss: 2.0768046379089355
Validation loss: 1.9651599289268575

Epoch: 5| Step: 9
Training loss: 2.4319941997528076
Validation loss: 1.9848499554459766

Epoch: 5| Step: 10
Training loss: 1.672855257987976
Validation loss: 1.9875437751893075

Epoch: 193| Step: 0
Training loss: 1.6555036306381226
Validation loss: 1.9668670162077873

Epoch: 5| Step: 1
Training loss: 1.6271412372589111
Validation loss: 1.9618252041519328

Epoch: 5| Step: 2
Training loss: 2.2043654918670654
Validation loss: 1.9569050291533112

Epoch: 5| Step: 3
Training loss: 1.424414873123169
Validation loss: 1.9771271290317658

Epoch: 5| Step: 4
Training loss: 1.988176703453064
Validation loss: 1.992837284200935

Epoch: 5| Step: 5
Training loss: 1.9471251964569092
Validation loss: 1.9951226044726629

Epoch: 5| Step: 6
Training loss: 1.5145888328552246
Validation loss: 1.9922415492355183

Epoch: 5| Step: 7
Training loss: 1.7953550815582275
Validation loss: 1.993095185167046

Epoch: 5| Step: 8
Training loss: 2.3687071800231934
Validation loss: 1.9963074473924534

Epoch: 5| Step: 9
Training loss: 2.539916515350342
Validation loss: 1.9840284137315647

Epoch: 5| Step: 10
Training loss: 2.226813316345215
Validation loss: 1.9949489460196546

Epoch: 194| Step: 0
Training loss: 2.5085301399230957
Validation loss: 1.975260951185739

Epoch: 5| Step: 1
Training loss: 1.6060240268707275
Validation loss: 1.9941474929932625

Epoch: 5| Step: 2
Training loss: 2.0777502059936523
Validation loss: 2.008163780294439

Epoch: 5| Step: 3
Training loss: 1.343116283416748
Validation loss: 1.9865834815527803

Epoch: 5| Step: 4
Training loss: 2.214876174926758
Validation loss: 1.9669177621923468

Epoch: 5| Step: 5
Training loss: 1.9941999912261963
Validation loss: 1.9821361726330173

Epoch: 5| Step: 6
Training loss: 2.3263468742370605
Validation loss: 1.9497678433695147

Epoch: 5| Step: 7
Training loss: 2.202500820159912
Validation loss: 1.9845341379924486

Epoch: 5| Step: 8
Training loss: 1.251455307006836
Validation loss: 1.96804609862707

Epoch: 5| Step: 9
Training loss: 1.7450908422470093
Validation loss: 1.9756166627330165

Epoch: 5| Step: 10
Training loss: 2.03629732131958
Validation loss: 1.9983997626971173

Epoch: 195| Step: 0
Training loss: 1.584964632987976
Validation loss: 2.010429815579486

Epoch: 5| Step: 1
Training loss: 1.9615150690078735
Validation loss: 1.984801071946339

Epoch: 5| Step: 2
Training loss: 2.2713615894317627
Validation loss: 1.9856025736819032

Epoch: 5| Step: 3
Training loss: 1.8757396936416626
Validation loss: 1.993549362305672

Epoch: 5| Step: 4
Training loss: 2.001556634902954
Validation loss: 1.979623963755946

Epoch: 5| Step: 5
Training loss: 1.9464012384414673
Validation loss: 1.9775108137438375

Epoch: 5| Step: 6
Training loss: 1.4675593376159668
Validation loss: 2.004501017191077

Epoch: 5| Step: 7
Training loss: 1.8454917669296265
Validation loss: 1.9635440175251295

Epoch: 5| Step: 8
Training loss: 2.0470337867736816
Validation loss: 1.9565723275625577

Epoch: 5| Step: 9
Training loss: 1.9887926578521729
Validation loss: 1.9813837389792166

Epoch: 5| Step: 10
Training loss: 2.3950729370117188
Validation loss: 1.9686350771175918

Epoch: 196| Step: 0
Training loss: 2.09702730178833
Validation loss: 1.9705444023173342

Epoch: 5| Step: 1
Training loss: 1.9320690631866455
Validation loss: 1.956192470365955

Epoch: 5| Step: 2
Training loss: 2.119513988494873
Validation loss: 1.9845807475428427

Epoch: 5| Step: 3
Training loss: 1.9927520751953125
Validation loss: 1.9885710029191868

Epoch: 5| Step: 4
Training loss: 1.7065969705581665
Validation loss: 1.9720551019073815

Epoch: 5| Step: 5
Training loss: 1.852036714553833
Validation loss: 1.9860313220690655

Epoch: 5| Step: 6
Training loss: 1.807293176651001
Validation loss: 1.9964596481733425

Epoch: 5| Step: 7
Training loss: 1.9567787647247314
Validation loss: 1.9680491737140122

Epoch: 5| Step: 8
Training loss: 1.6352494955062866
Validation loss: 1.9791699968358523

Epoch: 5| Step: 9
Training loss: 2.3785743713378906
Validation loss: 1.993787988539665

Epoch: 5| Step: 10
Training loss: 1.6406069993972778
Validation loss: 1.9653860138308616

Epoch: 197| Step: 0
Training loss: 2.396273136138916
Validation loss: 1.9830636926876601

Epoch: 5| Step: 1
Training loss: 1.5278522968292236
Validation loss: 1.981406065725511

Epoch: 5| Step: 2
Training loss: 1.6753981113433838
Validation loss: 2.0076327003458494

Epoch: 5| Step: 3
Training loss: 1.5826456546783447
Validation loss: 1.9965806699568225

Epoch: 5| Step: 4
Training loss: 2.336827278137207
Validation loss: 2.002136035632062

Epoch: 5| Step: 5
Training loss: 1.8159984350204468
Validation loss: 1.9585090683352562

Epoch: 5| Step: 6
Training loss: 2.1256916522979736
Validation loss: 1.9761368548998268

Epoch: 5| Step: 7
Training loss: 1.6640713214874268
Validation loss: 1.9943524804166568

Epoch: 5| Step: 8
Training loss: 2.059229850769043
Validation loss: 2.0009581619693386

Epoch: 5| Step: 9
Training loss: 1.828558325767517
Validation loss: 1.9843601539570799

Epoch: 5| Step: 10
Training loss: 2.194150924682617
Validation loss: 1.9779867882369666

Epoch: 198| Step: 0
Training loss: 1.742099404335022
Validation loss: 1.979377455608819

Epoch: 5| Step: 1
Training loss: 1.9399633407592773
Validation loss: 1.9730104246447164

Epoch: 5| Step: 2
Training loss: 1.6051461696624756
Validation loss: 1.9812512013220018

Epoch: 5| Step: 3
Training loss: 2.560476303100586
Validation loss: 1.9826348699549192

Epoch: 5| Step: 4
Training loss: 1.9239628314971924
Validation loss: 1.9506400092955558

Epoch: 5| Step: 5
Training loss: 1.730696678161621
Validation loss: 2.0089002988671743

Epoch: 5| Step: 6
Training loss: 2.628269672393799
Validation loss: 1.9782885377125075

Epoch: 5| Step: 7
Training loss: 1.9441133737564087
Validation loss: 1.9913830244412987

Epoch: 5| Step: 8
Training loss: 1.8694251775741577
Validation loss: 1.9838708703235914

Epoch: 5| Step: 9
Training loss: 1.01970636844635
Validation loss: 1.9763403631025744

Epoch: 5| Step: 10
Training loss: 2.3090627193450928
Validation loss: 1.9863736552576865

Epoch: 199| Step: 0
Training loss: 2.2572035789489746
Validation loss: 1.975193364645845

Epoch: 5| Step: 1
Training loss: 1.995086669921875
Validation loss: 1.9688099597090034

Epoch: 5| Step: 2
Training loss: 1.3300018310546875
Validation loss: 2.000044556074245

Epoch: 5| Step: 3
Training loss: 2.461884021759033
Validation loss: 1.9743751607915407

Epoch: 5| Step: 4
Training loss: 1.5085484981536865
Validation loss: 1.9820441071705153

Epoch: 5| Step: 5
Training loss: 1.6621894836425781
Validation loss: 1.9883024513080556

Epoch: 5| Step: 6
Training loss: 1.6501216888427734
Validation loss: 1.9968128024890859

Epoch: 5| Step: 7
Training loss: 2.6721394062042236
Validation loss: 1.9896446325445687

Epoch: 5| Step: 8
Training loss: 1.434638261795044
Validation loss: 2.006799723512383

Epoch: 5| Step: 9
Training loss: 2.0936741828918457
Validation loss: 2.005510678855322

Epoch: 5| Step: 10
Training loss: 2.0565433502197266
Validation loss: 1.9604988610872658

Epoch: 200| Step: 0
Training loss: 1.441636323928833
Validation loss: 1.9733220890004148

Epoch: 5| Step: 1
Training loss: 1.820185661315918
Validation loss: 1.9873176992580455

Epoch: 5| Step: 2
Training loss: 2.159207582473755
Validation loss: 1.9768738772279473

Epoch: 5| Step: 3
Training loss: 2.2283377647399902
Validation loss: 1.960795666581841

Epoch: 5| Step: 4
Training loss: 1.7614333629608154
Validation loss: 1.9846014822683027

Epoch: 5| Step: 5
Training loss: 2.4206295013427734
Validation loss: 1.9801868648939236

Epoch: 5| Step: 6
Training loss: 2.2660701274871826
Validation loss: 1.9642194560779038

Epoch: 5| Step: 7
Training loss: 2.4784653186798096
Validation loss: 1.9717579221212735

Epoch: 5| Step: 8
Training loss: 1.556363821029663
Validation loss: 1.9510317207664571

Epoch: 5| Step: 9
Training loss: 1.8220611810684204
Validation loss: 1.962369785513929

Epoch: 5| Step: 10
Training loss: 1.425459861755371
Validation loss: 1.9542085432237195

Epoch: 201| Step: 0
Training loss: 2.007082223892212
Validation loss: 1.9613838003527733

Epoch: 5| Step: 1
Training loss: 1.9889214038848877
Validation loss: 1.9619570098897463

Epoch: 5| Step: 2
Training loss: 2.22542667388916
Validation loss: 2.0003502144608447

Epoch: 5| Step: 3
Training loss: 1.8702409267425537
Validation loss: 2.011517272200636

Epoch: 5| Step: 4
Training loss: 2.279182195663452
Validation loss: 1.9928861459096272

Epoch: 5| Step: 5
Training loss: 1.9666591882705688
Validation loss: 1.9920987441975584

Epoch: 5| Step: 6
Training loss: 1.6458740234375
Validation loss: 2.00450050446295

Epoch: 5| Step: 7
Training loss: 1.605605125427246
Validation loss: 2.0227078314750426

Epoch: 5| Step: 8
Training loss: 1.4891904592514038
Validation loss: 2.010926080006425

Epoch: 5| Step: 9
Training loss: 2.1616644859313965
Validation loss: 2.020995739967592

Epoch: 5| Step: 10
Training loss: 2.1498539447784424
Validation loss: 2.0087380742514007

Epoch: 202| Step: 0
Training loss: 1.9441192150115967
Validation loss: 2.0138874848683677

Epoch: 5| Step: 1
Training loss: 1.784075379371643
Validation loss: 1.9916260037370908

Epoch: 5| Step: 2
Training loss: 1.9741483926773071
Validation loss: 2.0138734181722007

Epoch: 5| Step: 3
Training loss: 2.0095880031585693
Validation loss: 1.9883700827116608

Epoch: 5| Step: 4
Training loss: 1.4367399215698242
Validation loss: 1.9932080750824304

Epoch: 5| Step: 5
Training loss: 2.323718786239624
Validation loss: 1.97225946123882

Epoch: 5| Step: 6
Training loss: 1.7262970209121704
Validation loss: 1.980904899617677

Epoch: 5| Step: 7
Training loss: 1.5254900455474854
Validation loss: 1.9856144036016157

Epoch: 5| Step: 8
Training loss: 1.885205864906311
Validation loss: 1.9800487077364357

Epoch: 5| Step: 9
Training loss: 2.1967952251434326
Validation loss: 1.9819212229021135

Epoch: 5| Step: 10
Training loss: 2.248929977416992
Validation loss: 1.994790070800371

Epoch: 203| Step: 0
Training loss: 1.4131100177764893
Validation loss: 1.9544694257038895

Epoch: 5| Step: 1
Training loss: 2.041405200958252
Validation loss: 1.9602642892509379

Epoch: 5| Step: 2
Training loss: 2.088371992111206
Validation loss: 1.9662571760915941

Epoch: 5| Step: 3
Training loss: 1.4494268894195557
Validation loss: 1.9896345177004415

Epoch: 5| Step: 4
Training loss: 1.7159955501556396
Validation loss: 1.9901250741815055

Epoch: 5| Step: 5
Training loss: 2.0312247276306152
Validation loss: 1.9683303448461718

Epoch: 5| Step: 6
Training loss: 1.6303651332855225
Validation loss: 1.9873091943802372

Epoch: 5| Step: 7
Training loss: 1.8124780654907227
Validation loss: 1.982590147244033

Epoch: 5| Step: 8
Training loss: 2.1318321228027344
Validation loss: 2.0259804546192126

Epoch: 5| Step: 9
Training loss: 2.8080832958221436
Validation loss: 1.967398033347181

Epoch: 5| Step: 10
Training loss: 2.0559401512145996
Validation loss: 1.9917193433289886

Epoch: 204| Step: 0
Training loss: 2.0656890869140625
Validation loss: 1.980832548551662

Epoch: 5| Step: 1
Training loss: 1.912125825881958
Validation loss: 1.98339049021403

Epoch: 5| Step: 2
Training loss: 2.1278204917907715
Validation loss: 1.9593590946607693

Epoch: 5| Step: 3
Training loss: 2.041213274002075
Validation loss: 1.9999520573564755

Epoch: 5| Step: 4
Training loss: 0.5903791189193726
Validation loss: 1.9929100941586237

Epoch: 5| Step: 5
Training loss: 1.3697236776351929
Validation loss: 2.0093888621176443

Epoch: 5| Step: 6
Training loss: 2.2857518196105957
Validation loss: 1.98204678873862

Epoch: 5| Step: 7
Training loss: 2.5623109340667725
Validation loss: 1.991655340758703

Epoch: 5| Step: 8
Training loss: 1.7659518718719482
Validation loss: 1.9953685640006937

Epoch: 5| Step: 9
Training loss: 2.3444604873657227
Validation loss: 1.9836655457814534

Epoch: 5| Step: 10
Training loss: 2.0191380977630615
Validation loss: 1.9695947721440306

Epoch: 205| Step: 0
Training loss: 1.5283706188201904
Validation loss: 1.9893466759753484

Epoch: 5| Step: 1
Training loss: 1.8239291906356812
Validation loss: 1.980415064801452

Epoch: 5| Step: 2
Training loss: 2.1078712940216064
Validation loss: 1.9648902531593078

Epoch: 5| Step: 3
Training loss: 2.036341905593872
Validation loss: 1.9808353788109236

Epoch: 5| Step: 4
Training loss: 2.4052047729492188
Validation loss: 1.9815242111041982

Epoch: 5| Step: 5
Training loss: 1.5581309795379639
Validation loss: 1.9799952994110763

Epoch: 5| Step: 6
Training loss: 1.7797876596450806
Validation loss: 1.994336457662685

Epoch: 5| Step: 7
Training loss: 1.8129953145980835
Validation loss: 1.963772786560879

Epoch: 5| Step: 8
Training loss: 1.8578113317489624
Validation loss: 1.9856446020064815

Epoch: 5| Step: 9
Training loss: 2.8193440437316895
Validation loss: 1.9924640745245001

Epoch: 5| Step: 10
Training loss: 1.386622667312622
Validation loss: 1.9587878950180546

Epoch: 206| Step: 0
Training loss: 1.4132654666900635
Validation loss: 1.990690718414963

Epoch: 5| Step: 1
Training loss: 1.921953558921814
Validation loss: 1.9920705377414663

Epoch: 5| Step: 2
Training loss: 1.969651222229004
Validation loss: 1.977828820546468

Epoch: 5| Step: 3
Training loss: 2.77644681930542
Validation loss: 1.9916968678915372

Epoch: 5| Step: 4
Training loss: 1.6006309986114502
Validation loss: 1.9894761911002539

Epoch: 5| Step: 5
Training loss: 2.016780138015747
Validation loss: 2.0044109129136607

Epoch: 5| Step: 6
Training loss: 2.106703519821167
Validation loss: 2.0144966879198627

Epoch: 5| Step: 7
Training loss: 1.7121241092681885
Validation loss: 2.019596811263792

Epoch: 5| Step: 8
Training loss: 1.5222365856170654
Validation loss: 2.017579404256677

Epoch: 5| Step: 9
Training loss: 1.912782907485962
Validation loss: 1.9902638055944954

Epoch: 5| Step: 10
Training loss: 2.15889310836792
Validation loss: 2.0225677451779767

Epoch: 207| Step: 0
Training loss: 2.2043051719665527
Validation loss: 2.0071986567589546

Epoch: 5| Step: 1
Training loss: 2.3463337421417236
Validation loss: 1.986854478877078

Epoch: 5| Step: 2
Training loss: 1.1600817441940308
Validation loss: 2.007087093527599

Epoch: 5| Step: 3
Training loss: 2.0120627880096436
Validation loss: 1.9987260705681258

Epoch: 5| Step: 4
Training loss: 1.8353116512298584
Validation loss: 2.0139935144814114

Epoch: 5| Step: 5
Training loss: 1.7603057622909546
Validation loss: 2.0095261450736754

Epoch: 5| Step: 6
Training loss: 2.158829927444458
Validation loss: 1.9997600137546498

Epoch: 5| Step: 7
Training loss: 2.2743191719055176
Validation loss: 1.9922004886852798

Epoch: 5| Step: 8
Training loss: 1.7246383428573608
Validation loss: 2.0179420773701002

Epoch: 5| Step: 9
Training loss: 1.2860119342803955
Validation loss: 1.9722612134871944

Epoch: 5| Step: 10
Training loss: 2.4242401123046875
Validation loss: 1.997800096388786

Epoch: 208| Step: 0
Training loss: 1.8380310535430908
Validation loss: 1.9986815837121779

Epoch: 5| Step: 1
Training loss: 2.173989772796631
Validation loss: 1.9822679488889632

Epoch: 5| Step: 2
Training loss: 1.2840771675109863
Validation loss: 1.9841797313382548

Epoch: 5| Step: 3
Training loss: 1.8464914560317993
Validation loss: 1.9560238212667487

Epoch: 5| Step: 4
Training loss: 1.629477858543396
Validation loss: 1.9769810732974802

Epoch: 5| Step: 5
Training loss: 2.320746421813965
Validation loss: 1.9783582995014806

Epoch: 5| Step: 6
Training loss: 2.126758098602295
Validation loss: 1.9957001452804894

Epoch: 5| Step: 7
Training loss: 1.6740802526474
Validation loss: 1.9936687792501142

Epoch: 5| Step: 8
Training loss: 1.7058464288711548
Validation loss: 1.9909287883389382

Epoch: 5| Step: 9
Training loss: 2.2241904735565186
Validation loss: 1.982529555597613

Epoch: 5| Step: 10
Training loss: 2.2362027168273926
Validation loss: 1.9863747089139876

Epoch: 209| Step: 0
Training loss: 2.1749191284179688
Validation loss: 1.9946014112041843

Epoch: 5| Step: 1
Training loss: 1.8673181533813477
Validation loss: 1.9891678799865067

Epoch: 5| Step: 2
Training loss: 1.8320541381835938
Validation loss: 1.996635663893915

Epoch: 5| Step: 3
Training loss: 2.4608652591705322
Validation loss: 1.9849422900907454

Epoch: 5| Step: 4
Training loss: 2.042478084564209
Validation loss: 1.9987116834168792

Epoch: 5| Step: 5
Training loss: 1.5440406799316406
Validation loss: 1.9863714966722714

Epoch: 5| Step: 6
Training loss: 2.2967793941497803
Validation loss: 2.0081002225158033

Epoch: 5| Step: 7
Training loss: 1.2179925441741943
Validation loss: 1.9981234227457354

Epoch: 5| Step: 8
Training loss: 2.0521488189697266
Validation loss: 2.0020480719945764

Epoch: 5| Step: 9
Training loss: 2.2269577980041504
Validation loss: 1.9895052089486072

Epoch: 5| Step: 10
Training loss: 1.2435052394866943
Validation loss: 2.022626059029692

Epoch: 210| Step: 0
Training loss: 2.1262319087982178
Validation loss: 1.997448367457236

Epoch: 5| Step: 1
Training loss: 2.1337757110595703
Validation loss: 1.997970127290295

Epoch: 5| Step: 2
Training loss: 1.6737972497940063
Validation loss: 2.0154522875303864

Epoch: 5| Step: 3
Training loss: 2.1273584365844727
Validation loss: 2.009485749788182

Epoch: 5| Step: 4
Training loss: 2.5657718181610107
Validation loss: 1.9677353546183596

Epoch: 5| Step: 5
Training loss: 2.0739667415618896
Validation loss: 2.0047740603006012

Epoch: 5| Step: 6
Training loss: 1.4151932001113892
Validation loss: 1.9711655224523237

Epoch: 5| Step: 7
Training loss: 1.624829649925232
Validation loss: 1.9935244411550543

Epoch: 5| Step: 8
Training loss: 1.585152268409729
Validation loss: 1.9842088209685458

Epoch: 5| Step: 9
Training loss: 1.7774053812026978
Validation loss: 1.9869959521037277

Epoch: 5| Step: 10
Training loss: 1.7165935039520264
Validation loss: 1.975202642461305

Epoch: 211| Step: 0
Training loss: 1.4145759344100952
Validation loss: 1.9841720314436062

Epoch: 5| Step: 1
Training loss: 2.060426712036133
Validation loss: 1.9784133472750265

Epoch: 5| Step: 2
Training loss: 1.7629255056381226
Validation loss: 2.0402743265192997

Epoch: 5| Step: 3
Training loss: 2.076592445373535
Validation loss: 2.0053791717816423

Epoch: 5| Step: 4
Training loss: 1.5444648265838623
Validation loss: 1.988971430768249

Epoch: 5| Step: 5
Training loss: 1.5594267845153809
Validation loss: 1.9982843898957776

Epoch: 5| Step: 6
Training loss: 2.116682291030884
Validation loss: 1.9742777501383135

Epoch: 5| Step: 7
Training loss: 2.025768756866455
Validation loss: 1.9578312725149176

Epoch: 5| Step: 8
Training loss: 2.052407741546631
Validation loss: 2.0009246795408187

Epoch: 5| Step: 9
Training loss: 2.582594394683838
Validation loss: 1.9814834876727032

Epoch: 5| Step: 10
Training loss: 1.7663583755493164
Validation loss: 1.9939493030630133

Epoch: 212| Step: 0
Training loss: 1.9093348979949951
Validation loss: 1.9746299661615843

Epoch: 5| Step: 1
Training loss: 1.9011694192886353
Validation loss: 1.9881310719315723

Epoch: 5| Step: 2
Training loss: 2.5703773498535156
Validation loss: 1.9993614535177908

Epoch: 5| Step: 3
Training loss: 1.7631362676620483
Validation loss: 2.011630501798404

Epoch: 5| Step: 4
Training loss: 1.9337704181671143
Validation loss: 2.0021875212269444

Epoch: 5| Step: 5
Training loss: 1.8116235733032227
Validation loss: 2.012864244881497

Epoch: 5| Step: 6
Training loss: 1.5895147323608398
Validation loss: 1.9911748093943442

Epoch: 5| Step: 7
Training loss: 2.078278064727783
Validation loss: 2.0072601636250815

Epoch: 5| Step: 8
Training loss: 1.7949702739715576
Validation loss: 2.005238021573713

Epoch: 5| Step: 9
Training loss: 2.0843777656555176
Validation loss: 1.9920195635928903

Epoch: 5| Step: 10
Training loss: 1.4834177494049072
Validation loss: 1.9821240030309206

Epoch: 213| Step: 0
Training loss: 1.6975253820419312
Validation loss: 1.9718633364605647

Epoch: 5| Step: 1
Training loss: 1.7851731777191162
Validation loss: 1.9942555119914394

Epoch: 5| Step: 2
Training loss: 1.7735216617584229
Validation loss: 1.9915293134668821

Epoch: 5| Step: 3
Training loss: 2.7798988819122314
Validation loss: 1.9663706492352229

Epoch: 5| Step: 4
Training loss: 1.1033059358596802
Validation loss: 1.983949104944865

Epoch: 5| Step: 5
Training loss: 2.1060099601745605
Validation loss: 1.9780662739148704

Epoch: 5| Step: 6
Training loss: 1.9588794708251953
Validation loss: 1.9795579923096525

Epoch: 5| Step: 7
Training loss: 1.7825733423233032
Validation loss: 1.9869560054553452

Epoch: 5| Step: 8
Training loss: 1.8700110912322998
Validation loss: 1.9501141130283315

Epoch: 5| Step: 9
Training loss: 1.5835692882537842
Validation loss: 1.9469267040170648

Epoch: 5| Step: 10
Training loss: 2.390084743499756
Validation loss: 1.999416560255071

Epoch: 214| Step: 0
Training loss: 1.883697509765625
Validation loss: 1.9830606573371476

Epoch: 5| Step: 1
Training loss: 1.8181053400039673
Validation loss: 1.972957694402305

Epoch: 5| Step: 2
Training loss: 1.2352715730667114
Validation loss: 1.9583290212897844

Epoch: 5| Step: 3
Training loss: 2.1033389568328857
Validation loss: 1.9487882301371584

Epoch: 5| Step: 4
Training loss: 1.9958553314208984
Validation loss: 1.9906083332595004

Epoch: 5| Step: 5
Training loss: 1.8415257930755615
Validation loss: 1.976937686243365

Epoch: 5| Step: 6
Training loss: 2.2176122665405273
Validation loss: 2.0133295430931994

Epoch: 5| Step: 7
Training loss: 1.8331966400146484
Validation loss: 1.9907210514109621

Epoch: 5| Step: 8
Training loss: 1.9031788110733032
Validation loss: 1.9899533128225675

Epoch: 5| Step: 9
Training loss: 1.9583609104156494
Validation loss: 1.9710879659139982

Epoch: 5| Step: 10
Training loss: 1.9396851062774658
Validation loss: 1.976711057847546

Epoch: 215| Step: 0
Training loss: 2.5290026664733887
Validation loss: 2.005846486296705

Epoch: 5| Step: 1
Training loss: 2.3293144702911377
Validation loss: 1.9881092297133578

Epoch: 5| Step: 2
Training loss: 1.5570690631866455
Validation loss: 1.99016063187712

Epoch: 5| Step: 3
Training loss: 1.7567832469940186
Validation loss: 2.004855562281865

Epoch: 5| Step: 4
Training loss: 1.4949665069580078
Validation loss: 1.9680474073656145

Epoch: 5| Step: 5
Training loss: 1.2845999002456665
Validation loss: 2.0060940865547425

Epoch: 5| Step: 6
Training loss: 1.9650437831878662
Validation loss: 1.9952139700612714

Epoch: 5| Step: 7
Training loss: 2.3020026683807373
Validation loss: 1.988041590618831

Epoch: 5| Step: 8
Training loss: 1.923976182937622
Validation loss: 1.9852202976903608

Epoch: 5| Step: 9
Training loss: 1.556229829788208
Validation loss: 2.0147196862005416

Epoch: 5| Step: 10
Training loss: 2.2200047969818115
Validation loss: 2.00742966898026

Epoch: 216| Step: 0
Training loss: 2.0903124809265137
Validation loss: 1.976603490050121

Epoch: 5| Step: 1
Training loss: 1.9413201808929443
Validation loss: 1.9999624426646898

Epoch: 5| Step: 2
Training loss: 2.159996747970581
Validation loss: 2.0139224401084324

Epoch: 5| Step: 3
Training loss: 1.4405536651611328
Validation loss: 1.9781222151171776

Epoch: 5| Step: 4
Training loss: 1.7593295574188232
Validation loss: 1.9765642881393433

Epoch: 5| Step: 5
Training loss: 1.5247232913970947
Validation loss: 1.9787429019968996

Epoch: 5| Step: 6
Training loss: 2.0616610050201416
Validation loss: 1.9624431825453235

Epoch: 5| Step: 7
Training loss: 1.8949940204620361
Validation loss: 1.985688191588207

Epoch: 5| Step: 8
Training loss: 2.3314855098724365
Validation loss: 1.9654334822008688

Epoch: 5| Step: 9
Training loss: 2.077294111251831
Validation loss: 1.980150632960822

Epoch: 5| Step: 10
Training loss: 1.6033580303192139
Validation loss: 2.0031475328630015

Epoch: 217| Step: 0
Training loss: 2.0871660709381104
Validation loss: 1.9436649007181968

Epoch: 5| Step: 1
Training loss: 2.2678184509277344
Validation loss: 1.9723942946362238

Epoch: 5| Step: 2
Training loss: 2.2900257110595703
Validation loss: 2.0146273284830074

Epoch: 5| Step: 3
Training loss: 2.4076015949249268
Validation loss: 1.9829364848393265

Epoch: 5| Step: 4
Training loss: 2.0040268898010254
Validation loss: 1.9876374044725973

Epoch: 5| Step: 5
Training loss: 1.4319216012954712
Validation loss: 1.9746238262422624

Epoch: 5| Step: 6
Training loss: 1.8505792617797852
Validation loss: 1.9884241998836558

Epoch: 5| Step: 7
Training loss: 1.9655952453613281
Validation loss: 1.9864011426125803

Epoch: 5| Step: 8
Training loss: 0.940104603767395
Validation loss: 1.9823913240945468

Epoch: 5| Step: 9
Training loss: 2.0313243865966797
Validation loss: 1.99214477949245

Epoch: 5| Step: 10
Training loss: 1.4399055242538452
Validation loss: 1.9970355290238575

Epoch: 218| Step: 0
Training loss: 1.7325546741485596
Validation loss: 1.9961137002514255

Epoch: 5| Step: 1
Training loss: 1.9311130046844482
Validation loss: 1.9746614399776663

Epoch: 5| Step: 2
Training loss: 1.655954360961914
Validation loss: 1.9972500711359003

Epoch: 5| Step: 3
Training loss: 1.953592300415039
Validation loss: 1.9971394910607287

Epoch: 5| Step: 4
Training loss: 1.8058544397354126
Validation loss: 1.9648081346224713

Epoch: 5| Step: 5
Training loss: 1.753143548965454
Validation loss: 1.9841674835451188

Epoch: 5| Step: 6
Training loss: 2.0090434551239014
Validation loss: 1.9961822558474798

Epoch: 5| Step: 7
Training loss: 1.8974510431289673
Validation loss: 1.9957309871591546

Epoch: 5| Step: 8
Training loss: 2.272007942199707
Validation loss: 1.9993920236505487

Epoch: 5| Step: 9
Training loss: 1.8391920328140259
Validation loss: 1.9829469406476585

Epoch: 5| Step: 10
Training loss: 1.989971399307251
Validation loss: 1.9553513501280098

Epoch: 219| Step: 0
Training loss: 1.73944890499115
Validation loss: 1.9982125400215067

Epoch: 5| Step: 1
Training loss: 2.20743989944458
Validation loss: 1.9909274834458546

Epoch: 5| Step: 2
Training loss: 1.544801115989685
Validation loss: 1.9990695163767824

Epoch: 5| Step: 3
Training loss: 1.847801923751831
Validation loss: 1.9957984096260482

Epoch: 5| Step: 4
Training loss: 1.5201679468154907
Validation loss: 1.9850644949943788

Epoch: 5| Step: 5
Training loss: 2.3765392303466797
Validation loss: 2.0395675628416

Epoch: 5| Step: 6
Training loss: 1.941955804824829
Validation loss: 1.964965504984702

Epoch: 5| Step: 7
Training loss: 1.3851280212402344
Validation loss: 1.967720393211611

Epoch: 5| Step: 8
Training loss: 1.709124207496643
Validation loss: 1.985539977268506

Epoch: 5| Step: 9
Training loss: 2.1927433013916016
Validation loss: 2.01295716275451

Epoch: 5| Step: 10
Training loss: 2.449270009994507
Validation loss: 1.9926052324233516

Epoch: 220| Step: 0
Training loss: 2.0100605487823486
Validation loss: 1.9559418334755847

Epoch: 5| Step: 1
Training loss: 1.6934547424316406
Validation loss: 1.995054002731077

Epoch: 5| Step: 2
Training loss: 1.9110097885131836
Validation loss: 1.9866391689546647

Epoch: 5| Step: 3
Training loss: 2.0212368965148926
Validation loss: 1.992611285178892

Epoch: 5| Step: 4
Training loss: 1.6572548151016235
Validation loss: 1.9997492451821604

Epoch: 5| Step: 5
Training loss: 2.198249101638794
Validation loss: 2.009137499716974

Epoch: 5| Step: 6
Training loss: 2.0972065925598145
Validation loss: 2.006317659090924

Epoch: 5| Step: 7
Training loss: 1.665419578552246
Validation loss: 2.01149764368611

Epoch: 5| Step: 8
Training loss: 1.7586431503295898
Validation loss: 2.00091113070006

Epoch: 5| Step: 9
Training loss: 2.0241191387176514
Validation loss: 2.0096903270290745

Epoch: 5| Step: 10
Training loss: 1.7366682291030884
Validation loss: 2.000159735320717

Epoch: 221| Step: 0
Training loss: 2.180025815963745
Validation loss: 2.0030593846433904

Epoch: 5| Step: 1
Training loss: 1.7361685037612915
Validation loss: 1.9819821619218396

Epoch: 5| Step: 2
Training loss: 2.184173107147217
Validation loss: 2.0156652363397742

Epoch: 5| Step: 3
Training loss: 1.7348970174789429
Validation loss: 2.0262826078681537

Epoch: 5| Step: 4
Training loss: 1.3456720113754272
Validation loss: 1.9955035307074105

Epoch: 5| Step: 5
Training loss: 2.6232547760009766
Validation loss: 1.9921516872221423

Epoch: 5| Step: 6
Training loss: 2.1062049865722656
Validation loss: 2.0174594335658576

Epoch: 5| Step: 7
Training loss: 1.5013372898101807
Validation loss: 2.0153238516981884

Epoch: 5| Step: 8
Training loss: 1.9465258121490479
Validation loss: 1.9875178003823886

Epoch: 5| Step: 9
Training loss: 1.540863037109375
Validation loss: 1.9910914936373312

Epoch: 5| Step: 10
Training loss: 1.9627463817596436
Validation loss: 2.0002400695636706

Epoch: 222| Step: 0
Training loss: 1.812262773513794
Validation loss: 1.9863448732642717

Epoch: 5| Step: 1
Training loss: 1.6271216869354248
Validation loss: 1.9832142463294409

Epoch: 5| Step: 2
Training loss: 1.5589611530303955
Validation loss: 1.9998984798308341

Epoch: 5| Step: 3
Training loss: 1.6338192224502563
Validation loss: 1.9846353710338633

Epoch: 5| Step: 4
Training loss: 2.1550467014312744
Validation loss: 1.9839215945172053

Epoch: 5| Step: 5
Training loss: 1.9140970706939697
Validation loss: 1.9731610064865441

Epoch: 5| Step: 6
Training loss: 1.7098338603973389
Validation loss: 2.010378206929853

Epoch: 5| Step: 7
Training loss: 1.9708322286605835
Validation loss: 1.9919961588357085

Epoch: 5| Step: 8
Training loss: 1.8576467037200928
Validation loss: 1.9933266537163847

Epoch: 5| Step: 9
Training loss: 2.5938775539398193
Validation loss: 1.9806081556504773

Epoch: 5| Step: 10
Training loss: 1.965010643005371
Validation loss: 1.9690766795989005

Epoch: 223| Step: 0
Training loss: 1.7433000802993774
Validation loss: 2.0028150619999057

Epoch: 5| Step: 1
Training loss: 1.7835410833358765
Validation loss: 1.9736616303843837

Epoch: 5| Step: 2
Training loss: 2.277529239654541
Validation loss: 1.9893581739035986

Epoch: 5| Step: 3
Training loss: 1.2199214696884155
Validation loss: 2.000079867660358

Epoch: 5| Step: 4
Training loss: 1.4296056032180786
Validation loss: 1.9816157484567294

Epoch: 5| Step: 5
Training loss: 2.634162425994873
Validation loss: 2.01540098908127

Epoch: 5| Step: 6
Training loss: 1.6119931936264038
Validation loss: 2.0146867049637662

Epoch: 5| Step: 7
Training loss: 2.2271437644958496
Validation loss: 2.0132516866089194

Epoch: 5| Step: 8
Training loss: 1.6229394674301147
Validation loss: 1.9855204269450197

Epoch: 5| Step: 9
Training loss: 2.4452080726623535
Validation loss: 2.0159093526101883

Epoch: 5| Step: 10
Training loss: 1.6807116270065308
Validation loss: 2.0015990464918074

Epoch: 224| Step: 0
Training loss: 2.2574288845062256
Validation loss: 1.990205225124154

Epoch: 5| Step: 1
Training loss: 0.9333171844482422
Validation loss: 1.9910914064735494

Epoch: 5| Step: 2
Training loss: 3.105015516281128
Validation loss: 2.0237706040823333

Epoch: 5| Step: 3
Training loss: 1.8614448308944702
Validation loss: 1.9864633762708275

Epoch: 5| Step: 4
Training loss: 2.170980930328369
Validation loss: 1.974710177349788

Epoch: 5| Step: 5
Training loss: 1.5940314531326294
Validation loss: 1.9951020979112195

Epoch: 5| Step: 6
Training loss: 1.7881650924682617
Validation loss: 1.9891158278270433

Epoch: 5| Step: 7
Training loss: 1.7462007999420166
Validation loss: 1.9849970366365166

Epoch: 5| Step: 8
Training loss: 1.9307234287261963
Validation loss: 2.0296852204107467

Epoch: 5| Step: 9
Training loss: 1.4889085292816162
Validation loss: 1.9882724874763078

Epoch: 5| Step: 10
Training loss: 1.8803489208221436
Validation loss: 1.9957408430755779

Epoch: 225| Step: 0
Training loss: 2.3030083179473877
Validation loss: 1.9803517633868801

Epoch: 5| Step: 1
Training loss: 1.4870541095733643
Validation loss: 2.000342906162303

Epoch: 5| Step: 2
Training loss: 1.2782223224639893
Validation loss: 1.9830367795882686

Epoch: 5| Step: 3
Training loss: 1.6517102718353271
Validation loss: 1.9945692810960995

Epoch: 5| Step: 4
Training loss: 1.7733112573623657
Validation loss: 2.0065132238531627

Epoch: 5| Step: 5
Training loss: 1.662759780883789
Validation loss: 1.9940321189101025

Epoch: 5| Step: 6
Training loss: 1.8105449676513672
Validation loss: 1.9792245357267317

Epoch: 5| Step: 7
Training loss: 2.2352547645568848
Validation loss: 2.0008999506632485

Epoch: 5| Step: 8
Training loss: 1.945840835571289
Validation loss: 2.0113468080438595

Epoch: 5| Step: 9
Training loss: 2.496931314468384
Validation loss: 1.982223008268623

Epoch: 5| Step: 10
Training loss: 1.957556962966919
Validation loss: 1.9850067297617595

Epoch: 226| Step: 0
Training loss: 1.981589913368225
Validation loss: 1.9733080966498262

Epoch: 5| Step: 1
Training loss: 1.8303245306015015
Validation loss: 2.0106076694303945

Epoch: 5| Step: 2
Training loss: 1.3920958042144775
Validation loss: 1.9742804496519026

Epoch: 5| Step: 3
Training loss: 1.583993673324585
Validation loss: 1.9568425596401255

Epoch: 5| Step: 4
Training loss: 1.9056590795516968
Validation loss: 1.9754130532664638

Epoch: 5| Step: 5
Training loss: 1.9722397327423096
Validation loss: 1.9933058331089635

Epoch: 5| Step: 6
Training loss: 1.8448015451431274
Validation loss: 1.9945348731933101

Epoch: 5| Step: 7
Training loss: 2.4169116020202637
Validation loss: 1.999429633540492

Epoch: 5| Step: 8
Training loss: 2.3483197689056396
Validation loss: 1.986445398740871

Epoch: 5| Step: 9
Training loss: 1.7482506036758423
Validation loss: 1.9750641930487849

Epoch: 5| Step: 10
Training loss: 1.567400336265564
Validation loss: 1.9926382777511433

Epoch: 227| Step: 0
Training loss: 1.6844966411590576
Validation loss: 1.9857703280705277

Epoch: 5| Step: 1
Training loss: 2.0982394218444824
Validation loss: 1.97998902105516

Epoch: 5| Step: 2
Training loss: 2.283228874206543
Validation loss: 2.013227714005337

Epoch: 5| Step: 3
Training loss: 1.8607336282730103
Validation loss: 1.9586397422257291

Epoch: 5| Step: 4
Training loss: 2.5194687843322754
Validation loss: 2.0019360793534147

Epoch: 5| Step: 5
Training loss: 1.440382957458496
Validation loss: 1.993839152397648

Epoch: 5| Step: 6
Training loss: 1.7227693796157837
Validation loss: 1.9827042279704925

Epoch: 5| Step: 7
Training loss: 1.617793321609497
Validation loss: 2.013102512205801

Epoch: 5| Step: 8
Training loss: 1.7545478343963623
Validation loss: 2.047539193143127

Epoch: 5| Step: 9
Training loss: 1.9328422546386719
Validation loss: 1.9994700288259855

Epoch: 5| Step: 10
Training loss: 1.6259397268295288
Validation loss: 1.9954417495317356

Epoch: 228| Step: 0
Training loss: 1.918826699256897
Validation loss: 1.979584668272285

Epoch: 5| Step: 1
Training loss: 1.9791959524154663
Validation loss: 2.0144036405829975

Epoch: 5| Step: 2
Training loss: 1.4169448614120483
Validation loss: 2.0174807733105076

Epoch: 5| Step: 3
Training loss: 1.3299330472946167
Validation loss: 1.9871333542690481

Epoch: 5| Step: 4
Training loss: 2.2332210540771484
Validation loss: 2.005804516935861

Epoch: 5| Step: 5
Training loss: 1.9374849796295166
Validation loss: 2.0274324981115197

Epoch: 5| Step: 6
Training loss: 2.2126660346984863
Validation loss: 2.0096010110711537

Epoch: 5| Step: 7
Training loss: 1.8789443969726562
Validation loss: 2.0419752777263684

Epoch: 5| Step: 8
Training loss: 1.9268391132354736
Validation loss: 1.978239240184907

Epoch: 5| Step: 9
Training loss: 1.9243065118789673
Validation loss: 1.9852560092044134

Epoch: 5| Step: 10
Training loss: 1.8431528806686401
Validation loss: 1.9930647996164137

Epoch: 229| Step: 0
Training loss: 2.0246472358703613
Validation loss: 1.998354329857775

Epoch: 5| Step: 1
Training loss: 2.771122932434082
Validation loss: 1.9838371020491405

Epoch: 5| Step: 2
Training loss: 1.2579892873764038
Validation loss: 1.992568260879927

Epoch: 5| Step: 3
Training loss: 2.2005481719970703
Validation loss: 1.9833986477185321

Epoch: 5| Step: 4
Training loss: 2.0017237663269043
Validation loss: 1.9888111006829046

Epoch: 5| Step: 5
Training loss: 1.3162946701049805
Validation loss: 2.0034533290452856

Epoch: 5| Step: 6
Training loss: 2.004119873046875
Validation loss: 2.0020796419471822

Epoch: 5| Step: 7
Training loss: 1.6613067388534546
Validation loss: 2.0080618319972867

Epoch: 5| Step: 8
Training loss: 1.1624953746795654
Validation loss: 2.012898847620974

Epoch: 5| Step: 9
Training loss: 1.53611159324646
Validation loss: 2.0026928711962957

Epoch: 5| Step: 10
Training loss: 2.3436439037323
Validation loss: 1.9848388420638217

Epoch: 230| Step: 0
Training loss: 2.2084879875183105
Validation loss: 2.0070860796077277

Epoch: 5| Step: 1
Training loss: 2.132509708404541
Validation loss: 1.9999429961686492

Epoch: 5| Step: 2
Training loss: 1.8822664022445679
Validation loss: 1.9918412598230506

Epoch: 5| Step: 3
Training loss: 1.6211941242218018
Validation loss: 1.9906198670787196

Epoch: 5| Step: 4
Training loss: 1.4044625759124756
Validation loss: 1.9977010706419587

Epoch: 5| Step: 5
Training loss: 1.7799415588378906
Validation loss: 2.0234799641434864

Epoch: 5| Step: 6
Training loss: 1.8523311614990234
Validation loss: 2.0037072345774662

Epoch: 5| Step: 7
Training loss: 2.0617053508758545
Validation loss: 2.0046886449219077

Epoch: 5| Step: 8
Training loss: 2.1065022945404053
Validation loss: 2.04513612357519

Epoch: 5| Step: 9
Training loss: 1.9270045757293701
Validation loss: 1.9984494511799147

Epoch: 5| Step: 10
Training loss: 1.7009578943252563
Validation loss: 2.0138452796525854

Epoch: 231| Step: 0
Training loss: 1.5293292999267578
Validation loss: 2.014064686272734

Epoch: 5| Step: 1
Training loss: 1.4639856815338135
Validation loss: 1.9687061091904998

Epoch: 5| Step: 2
Training loss: 1.9670000076293945
Validation loss: 1.9989266626296505

Epoch: 5| Step: 3
Training loss: 1.4441015720367432
Validation loss: 2.000130485462886

Epoch: 5| Step: 4
Training loss: 2.606588363647461
Validation loss: 1.968989336362449

Epoch: 5| Step: 5
Training loss: 2.129385471343994
Validation loss: 1.981862711650069

Epoch: 5| Step: 6
Training loss: 2.0107581615448
Validation loss: 1.978723149145803

Epoch: 5| Step: 7
Training loss: 1.9393250942230225
Validation loss: 2.015417880909417

Epoch: 5| Step: 8
Training loss: 1.9305839538574219
Validation loss: 2.0045235336467786

Epoch: 5| Step: 9
Training loss: 1.9271303415298462
Validation loss: 1.9976817548915904

Epoch: 5| Step: 10
Training loss: 1.606675148010254
Validation loss: 2.007224270092544

Epoch: 232| Step: 0
Training loss: 1.6187002658843994
Validation loss: 1.982451900359123

Epoch: 5| Step: 1
Training loss: 1.8494250774383545
Validation loss: 1.9919660206763976

Epoch: 5| Step: 2
Training loss: 1.7552669048309326
Validation loss: 2.000811994716685

Epoch: 5| Step: 3
Training loss: 1.8869502544403076
Validation loss: 2.0043962386346634

Epoch: 5| Step: 4
Training loss: 1.911206841468811
Validation loss: 2.02159442440156

Epoch: 5| Step: 5
Training loss: 1.8393115997314453
Validation loss: 1.9862480701938752

Epoch: 5| Step: 6
Training loss: 1.7018859386444092
Validation loss: 1.9925697349732923

Epoch: 5| Step: 7
Training loss: 1.680508017539978
Validation loss: 2.0002346795092345

Epoch: 5| Step: 8
Training loss: 1.4914274215698242
Validation loss: 1.9947128808626564

Epoch: 5| Step: 9
Training loss: 2.4024391174316406
Validation loss: 1.9930417883780696

Epoch: 5| Step: 10
Training loss: 2.375997304916382
Validation loss: 2.0010992198862056

Epoch: 233| Step: 0
Training loss: 1.9531238079071045
Validation loss: 1.9983551322772939

Epoch: 5| Step: 1
Training loss: 1.71354079246521
Validation loss: 2.0204803430905907

Epoch: 5| Step: 2
Training loss: 1.3846118450164795
Validation loss: 2.020597296376382

Epoch: 5| Step: 3
Training loss: 1.6965038776397705
Validation loss: 1.9955750255174534

Epoch: 5| Step: 4
Training loss: 2.2216830253601074
Validation loss: 1.994223028100947

Epoch: 5| Step: 5
Training loss: 2.3755505084991455
Validation loss: 2.0047728143712527

Epoch: 5| Step: 6
Training loss: 1.5015199184417725
Validation loss: 2.0273491861999675

Epoch: 5| Step: 7
Training loss: 1.6966760158538818
Validation loss: 2.0537612233110654

Epoch: 5| Step: 8
Training loss: 1.8632166385650635
Validation loss: 1.9893269000514862

Epoch: 5| Step: 9
Training loss: 1.9995620250701904
Validation loss: 2.0061491010009602

Epoch: 5| Step: 10
Training loss: 1.9879686832427979
Validation loss: 1.9929345679539505

Epoch: 234| Step: 0
Training loss: 1.8402179479599
Validation loss: 1.974218371093914

Epoch: 5| Step: 1
Training loss: 2.2362029552459717
Validation loss: 2.025362135261618

Epoch: 5| Step: 2
Training loss: 1.6947529315948486
Validation loss: 2.0136975780610116

Epoch: 5| Step: 3
Training loss: 1.6155388355255127
Validation loss: 2.0016928013934883

Epoch: 5| Step: 4
Training loss: 2.340625047683716
Validation loss: 1.9857000945716776

Epoch: 5| Step: 5
Training loss: 1.322591781616211
Validation loss: 1.9755830354588007

Epoch: 5| Step: 6
Training loss: 1.9464174509048462
Validation loss: 1.9658722416047127

Epoch: 5| Step: 7
Training loss: 1.8960586786270142
Validation loss: 1.9956313333203715

Epoch: 5| Step: 8
Training loss: 2.111135482788086
Validation loss: 2.0150883428512083

Epoch: 5| Step: 9
Training loss: 1.7179683446884155
Validation loss: 1.9794198748885945

Epoch: 5| Step: 10
Training loss: 1.5418024063110352
Validation loss: 2.002325556611502

Epoch: 235| Step: 0
Training loss: 1.944300651550293
Validation loss: 1.9659977728320706

Epoch: 5| Step: 1
Training loss: 1.8172674179077148
Validation loss: 1.992155909538269

Epoch: 5| Step: 2
Training loss: 1.9125945568084717
Validation loss: 1.9722797691181142

Epoch: 5| Step: 3
Training loss: 1.4648973941802979
Validation loss: 2.0172284162172707

Epoch: 5| Step: 4
Training loss: 1.849369764328003
Validation loss: 2.0370335578918457

Epoch: 5| Step: 5
Training loss: 1.3915358781814575
Validation loss: 2.011563877905569

Epoch: 5| Step: 6
Training loss: 1.8975051641464233
Validation loss: 1.9945372894246092

Epoch: 5| Step: 7
Training loss: 1.53483247756958
Validation loss: 2.0076177466300225

Epoch: 5| Step: 8
Training loss: 2.7238733768463135
Validation loss: 2.0332207038838375

Epoch: 5| Step: 9
Training loss: 1.9866222143173218
Validation loss: 2.033425474679598

Epoch: 5| Step: 10
Training loss: 1.8311082124710083
Validation loss: 2.0285112793727587

Epoch: 236| Step: 0
Training loss: 2.083212375640869
Validation loss: 2.0051233768463135

Epoch: 5| Step: 1
Training loss: 1.9431883096694946
Validation loss: 2.035498970298357

Epoch: 5| Step: 2
Training loss: 2.1114654541015625
Validation loss: 1.998396841428613

Epoch: 5| Step: 3
Training loss: 1.6064074039459229
Validation loss: 2.024385101051741

Epoch: 5| Step: 4
Training loss: 1.5355240106582642
Validation loss: 2.0049767263474

Epoch: 5| Step: 5
Training loss: 2.0517783164978027
Validation loss: 2.021395265415151

Epoch: 5| Step: 6
Training loss: 1.403727650642395
Validation loss: 1.9953480894847582

Epoch: 5| Step: 7
Training loss: 2.032944917678833
Validation loss: 1.9949118347578152

Epoch: 5| Step: 8
Training loss: 1.4093831777572632
Validation loss: 1.9699659988444338

Epoch: 5| Step: 9
Training loss: 2.0932586193084717
Validation loss: 1.9702137413845267

Epoch: 5| Step: 10
Training loss: 2.2015371322631836
Validation loss: 1.9866386126446467

Epoch: 237| Step: 0
Training loss: 2.288874864578247
Validation loss: 1.9819833924693446

Epoch: 5| Step: 1
Training loss: 1.8717228174209595
Validation loss: 2.0048036190771286

Epoch: 5| Step: 2
Training loss: 1.8999818563461304
Validation loss: 1.9786842638446438

Epoch: 5| Step: 3
Training loss: 1.8287327289581299
Validation loss: 2.0042080827938613

Epoch: 5| Step: 4
Training loss: 2.1854076385498047
Validation loss: 1.995698328941099

Epoch: 5| Step: 5
Training loss: 1.663446068763733
Validation loss: 1.9837644536008117

Epoch: 5| Step: 6
Training loss: 1.8286514282226562
Validation loss: 1.9679207340363534

Epoch: 5| Step: 7
Training loss: 1.5322462320327759
Validation loss: 1.9976525921975412

Epoch: 5| Step: 8
Training loss: 1.23512864112854
Validation loss: 1.988005930377591

Epoch: 5| Step: 9
Training loss: 2.2112233638763428
Validation loss: 1.9980700477477042

Epoch: 5| Step: 10
Training loss: 1.6695191860198975
Validation loss: 2.0222630423884236

Epoch: 238| Step: 0
Training loss: 2.5670275688171387
Validation loss: 2.017105907522222

Epoch: 5| Step: 1
Training loss: 1.7272841930389404
Validation loss: 2.0247161337124404

Epoch: 5| Step: 2
Training loss: 1.9924951791763306
Validation loss: 2.0219550158387873

Epoch: 5| Step: 3
Training loss: 1.8322594165802002
Validation loss: 2.0065871105399182

Epoch: 5| Step: 4
Training loss: 1.8158308267593384
Validation loss: 2.006968298266011

Epoch: 5| Step: 5
Training loss: 2.048389434814453
Validation loss: 2.009227342503045

Epoch: 5| Step: 6
Training loss: 2.4106717109680176
Validation loss: 1.9892530415647773

Epoch: 5| Step: 7
Training loss: 1.2297961711883545
Validation loss: 2.001993898422487

Epoch: 5| Step: 8
Training loss: 1.3528305292129517
Validation loss: 2.011981051455262

Epoch: 5| Step: 9
Training loss: 1.8094526529312134
Validation loss: 2.0127018241472143

Epoch: 5| Step: 10
Training loss: 1.6802352666854858
Validation loss: 2.0134767986113027

Epoch: 239| Step: 0
Training loss: 1.6639047861099243
Validation loss: 2.0120918763581144

Epoch: 5| Step: 1
Training loss: 1.6021554470062256
Validation loss: 2.0212645658882717

Epoch: 5| Step: 2
Training loss: 2.048818349838257
Validation loss: 2.020922867200708

Epoch: 5| Step: 3
Training loss: 1.8712860345840454
Validation loss: 2.0031667101767754

Epoch: 5| Step: 4
Training loss: 1.9722697734832764
Validation loss: 2.0021298136762393

Epoch: 5| Step: 5
Training loss: 2.5928966999053955
Validation loss: 2.016581637884981

Epoch: 5| Step: 6
Training loss: 2.368100643157959
Validation loss: 2.0165329569129535

Epoch: 5| Step: 7
Training loss: 1.4738694429397583
Validation loss: 1.999054011478219

Epoch: 5| Step: 8
Training loss: 0.8879410028457642
Validation loss: 1.996155358129932

Epoch: 5| Step: 9
Training loss: 1.6297855377197266
Validation loss: 1.970635626905708

Epoch: 5| Step: 10
Training loss: 2.159226417541504
Validation loss: 2.0113460479244107

Epoch: 240| Step: 0
Training loss: 1.941653847694397
Validation loss: 2.0057842398202546

Epoch: 5| Step: 1
Training loss: 2.09786319732666
Validation loss: 1.981073764062697

Epoch: 5| Step: 2
Training loss: 1.5145924091339111
Validation loss: 1.9851134028486026

Epoch: 5| Step: 3
Training loss: 1.9912875890731812
Validation loss: 2.0348333953529276

Epoch: 5| Step: 4
Training loss: 1.373790979385376
Validation loss: 2.0059333206504903

Epoch: 5| Step: 5
Training loss: 1.9262158870697021
Validation loss: 2.0102133174096384

Epoch: 5| Step: 6
Training loss: 1.4400043487548828
Validation loss: 1.985336753629869

Epoch: 5| Step: 7
Training loss: 1.8189175128936768
Validation loss: 2.004436810811361

Epoch: 5| Step: 8
Training loss: 1.9714288711547852
Validation loss: 1.9967211433636245

Epoch: 5| Step: 9
Training loss: 2.4262843132019043
Validation loss: 2.0148742019489245

Epoch: 5| Step: 10
Training loss: 1.8981738090515137
Validation loss: 2.0305996210344377

Epoch: 241| Step: 0
Training loss: 2.2092483043670654
Validation loss: 2.0187636818937076

Epoch: 5| Step: 1
Training loss: 1.59846031665802
Validation loss: 2.00321670886009

Epoch: 5| Step: 2
Training loss: 1.8192180395126343
Validation loss: 2.0405991872151694

Epoch: 5| Step: 3
Training loss: 0.9618778228759766
Validation loss: 2.013972395209856

Epoch: 5| Step: 4
Training loss: 1.7664493322372437
Validation loss: 2.0145475518318916

Epoch: 5| Step: 5
Training loss: 2.1227927207946777
Validation loss: 2.025644048567741

Epoch: 5| Step: 6
Training loss: 1.9225647449493408
Validation loss: 2.0370788087127027

Epoch: 5| Step: 7
Training loss: 2.033137559890747
Validation loss: 2.0261844999046734

Epoch: 5| Step: 8
Training loss: 2.7051291465759277
Validation loss: 2.00718012163716

Epoch: 5| Step: 9
Training loss: 0.9820165634155273
Validation loss: 2.014073032204823

Epoch: 5| Step: 10
Training loss: 1.9495651721954346
Validation loss: 2.035814872352026

Epoch: 242| Step: 0
Training loss: 1.9654111862182617
Validation loss: 2.0057989628084245

Epoch: 5| Step: 1
Training loss: 2.125349283218384
Validation loss: 2.0201905158258255

Epoch: 5| Step: 2
Training loss: 2.205354690551758
Validation loss: 2.008881938072943

Epoch: 5| Step: 3
Training loss: 1.8515803813934326
Validation loss: 2.0359490238210207

Epoch: 5| Step: 4
Training loss: 1.3300846815109253
Validation loss: 2.008420226394489

Epoch: 5| Step: 5
Training loss: 1.9755580425262451
Validation loss: 2.017730474472046

Epoch: 5| Step: 6
Training loss: 2.0343079566955566
Validation loss: 2.0028778045408187

Epoch: 5| Step: 7
Training loss: 1.4047406911849976
Validation loss: 1.9985604645103536

Epoch: 5| Step: 8
Training loss: 1.7463476657867432
Validation loss: 1.9988031592420352

Epoch: 5| Step: 9
Training loss: 1.9886353015899658
Validation loss: 2.004220957397133

Epoch: 5| Step: 10
Training loss: 1.371635913848877
Validation loss: 1.9899114383164274

Epoch: 243| Step: 0
Training loss: 1.5459500551223755
Validation loss: 1.9777879689329414

Epoch: 5| Step: 1
Training loss: 1.8274781703948975
Validation loss: 1.9910614259781376

Epoch: 5| Step: 2
Training loss: 1.5112162828445435
Validation loss: 1.997309741153512

Epoch: 5| Step: 3
Training loss: 2.413156270980835
Validation loss: 2.0138910380742883

Epoch: 5| Step: 4
Training loss: 1.7207801342010498
Validation loss: 2.004983257221919

Epoch: 5| Step: 5
Training loss: 1.9163821935653687
Validation loss: 1.9960217245163456

Epoch: 5| Step: 6
Training loss: 1.50907301902771
Validation loss: 2.010644071845598

Epoch: 5| Step: 7
Training loss: 2.380734920501709
Validation loss: 2.0088379408723567

Epoch: 5| Step: 8
Training loss: 2.2318882942199707
Validation loss: 2.037027034708249

Epoch: 5| Step: 9
Training loss: 1.5364638566970825
Validation loss: 2.021317308948886

Epoch: 5| Step: 10
Training loss: 1.5112786293029785
Validation loss: 2.03100791669661

Epoch: 244| Step: 0
Training loss: 1.9684333801269531
Validation loss: 1.9932824539881882

Epoch: 5| Step: 1
Training loss: 1.379836082458496
Validation loss: 2.015017524842293

Epoch: 5| Step: 2
Training loss: 1.956885576248169
Validation loss: 2.002775083306015

Epoch: 5| Step: 3
Training loss: 1.3901716470718384
Validation loss: 2.025191640341154

Epoch: 5| Step: 4
Training loss: 1.4961683750152588
Validation loss: 2.0313921769460044

Epoch: 5| Step: 5
Training loss: 2.195060968399048
Validation loss: 2.0287610305252897

Epoch: 5| Step: 6
Training loss: 1.7952121496200562
Validation loss: 2.002028088415823

Epoch: 5| Step: 7
Training loss: 2.175982713699341
Validation loss: 2.011781777105024

Epoch: 5| Step: 8
Training loss: 2.083829879760742
Validation loss: 1.9887379023336595

Epoch: 5| Step: 9
Training loss: 1.5167852640151978
Validation loss: 2.019595892198624

Epoch: 5| Step: 10
Training loss: 2.0626165866851807
Validation loss: 2.028530623323174

Epoch: 245| Step: 0
Training loss: 1.9713242053985596
Validation loss: 2.042491164258731

Epoch: 5| Step: 1
Training loss: 1.7361100912094116
Validation loss: 1.9854462390304894

Epoch: 5| Step: 2
Training loss: 1.992959976196289
Validation loss: 1.9992122778328516

Epoch: 5| Step: 3
Training loss: 1.6089832782745361
Validation loss: 2.0265894295066915

Epoch: 5| Step: 4
Training loss: 1.7013146877288818
Validation loss: 2.0018917931023466

Epoch: 5| Step: 5
Training loss: 2.1331334114074707
Validation loss: 2.0108647423405803

Epoch: 5| Step: 6
Training loss: 1.6867120265960693
Validation loss: 2.0422928640919347

Epoch: 5| Step: 7
Training loss: 1.4995752573013306
Validation loss: 2.0253132133073706

Epoch: 5| Step: 8
Training loss: 2.394709825515747
Validation loss: 2.018840892340547

Epoch: 5| Step: 9
Training loss: 1.5054712295532227
Validation loss: 2.017222294243433

Epoch: 5| Step: 10
Training loss: 1.8570128679275513
Validation loss: 2.006538962805143

Epoch: 246| Step: 0
Training loss: 1.606030821800232
Validation loss: 2.004029013777292

Epoch: 5| Step: 1
Training loss: 1.8620210886001587
Validation loss: 2.041326727918399

Epoch: 5| Step: 2
Training loss: 1.8469451665878296
Validation loss: 1.9998817725848126

Epoch: 5| Step: 3
Training loss: 1.7908353805541992
Validation loss: 1.9977601971677554

Epoch: 5| Step: 4
Training loss: 1.7771759033203125
Validation loss: 2.0281487049595004

Epoch: 5| Step: 5
Training loss: 1.6823726892471313
Validation loss: 2.0018544068900486

Epoch: 5| Step: 6
Training loss: 2.0135886669158936
Validation loss: 1.998450795809428

Epoch: 5| Step: 7
Training loss: 1.9008737802505493
Validation loss: 1.9867242049145442

Epoch: 5| Step: 8
Training loss: 2.458008289337158
Validation loss: 2.004178129216676

Epoch: 5| Step: 9
Training loss: 1.184983491897583
Validation loss: 2.0277759875020673

Epoch: 5| Step: 10
Training loss: 2.0041823387145996
Validation loss: 1.9943786590330062

Epoch: 247| Step: 0
Training loss: 2.0853781700134277
Validation loss: 2.013053217241841

Epoch: 5| Step: 1
Training loss: 1.5107358694076538
Validation loss: 2.0032912262024416

Epoch: 5| Step: 2
Training loss: 1.9905214309692383
Validation loss: 2.0000321929172804

Epoch: 5| Step: 3
Training loss: 1.1860116720199585
Validation loss: 2.0381704068952993

Epoch: 5| Step: 4
Training loss: 1.6707355976104736
Validation loss: 2.027984610167883

Epoch: 5| Step: 5
Training loss: 1.7293850183486938
Validation loss: 2.0068586077741397

Epoch: 5| Step: 6
Training loss: 1.5908873081207275
Validation loss: 2.029024693273729

Epoch: 5| Step: 7
Training loss: 2.5610005855560303
Validation loss: 2.0428535117897937

Epoch: 5| Step: 8
Training loss: 1.7135528326034546
Validation loss: 2.0200233972200783

Epoch: 5| Step: 9
Training loss: 2.2086634635925293
Validation loss: 2.05408380621223

Epoch: 5| Step: 10
Training loss: 2.013765335083008
Validation loss: 2.05750846990975

Epoch: 248| Step: 0
Training loss: 1.2180275917053223
Validation loss: 2.0567039751237437

Epoch: 5| Step: 1
Training loss: 1.5650272369384766
Validation loss: 2.0416267379637687

Epoch: 5| Step: 2
Training loss: 1.9783775806427002
Validation loss: 2.044579800739083

Epoch: 5| Step: 3
Training loss: 2.0556209087371826
Validation loss: 2.041640891823717

Epoch: 5| Step: 4
Training loss: 2.026610851287842
Validation loss: 2.063451691340375

Epoch: 5| Step: 5
Training loss: 1.8412158489227295
Validation loss: 2.0330572230841524

Epoch: 5| Step: 6
Training loss: 2.3467140197753906
Validation loss: 2.0232354107723443

Epoch: 5| Step: 7
Training loss: 1.5624784231185913
Validation loss: 2.0170777997662945

Epoch: 5| Step: 8
Training loss: 1.8513805866241455
Validation loss: 2.0233158552518455

Epoch: 5| Step: 9
Training loss: 1.603054404258728
Validation loss: 2.032437216851019

Epoch: 5| Step: 10
Training loss: 1.8633317947387695
Validation loss: 2.0275721370532946

Epoch: 249| Step: 0
Training loss: 1.5561386346817017
Validation loss: 1.9916574954986572

Epoch: 5| Step: 1
Training loss: 2.652625322341919
Validation loss: 2.0195637056904454

Epoch: 5| Step: 2
Training loss: 1.4896732568740845
Validation loss: 2.0109868511076896

Epoch: 5| Step: 3
Training loss: 1.8058830499649048
Validation loss: 2.0018111454543246

Epoch: 5| Step: 4
Training loss: 1.9738235473632812
Validation loss: 1.9952101066548338

Epoch: 5| Step: 5
Training loss: 2.0785763263702393
Validation loss: 1.9988426264896189

Epoch: 5| Step: 6
Training loss: 1.5892486572265625
Validation loss: 1.986046955149661

Epoch: 5| Step: 7
Training loss: 2.115185499191284
Validation loss: 1.980706782751186

Epoch: 5| Step: 8
Training loss: 1.7592395544052124
Validation loss: 1.9882582746526247

Epoch: 5| Step: 9
Training loss: 1.781808853149414
Validation loss: 1.9941819790870912

Epoch: 5| Step: 10
Training loss: 1.1472593545913696
Validation loss: 2.0420770901505665

Epoch: 250| Step: 0
Training loss: 1.5694471597671509
Validation loss: 2.010369413642473

Epoch: 5| Step: 1
Training loss: 1.2967195510864258
Validation loss: 1.983460622449075

Epoch: 5| Step: 2
Training loss: 2.386308193206787
Validation loss: 2.0291532444697555

Epoch: 5| Step: 3
Training loss: 2.5270564556121826
Validation loss: 1.9952298364331644

Epoch: 5| Step: 4
Training loss: 2.3208110332489014
Validation loss: 2.022304606694047

Epoch: 5| Step: 5
Training loss: 1.9166139364242554
Validation loss: 2.049795468648275

Epoch: 5| Step: 6
Training loss: 1.1143200397491455
Validation loss: 2.0440499372379755

Epoch: 5| Step: 7
Training loss: 1.4714813232421875
Validation loss: 2.0275234765903924

Epoch: 5| Step: 8
Training loss: 2.0590076446533203
Validation loss: 2.0189623832702637

Epoch: 5| Step: 9
Training loss: 1.4866863489151
Validation loss: 2.023795609833092

Epoch: 5| Step: 10
Training loss: 2.0269336700439453
Validation loss: 2.0344797308726976

Epoch: 251| Step: 0
Training loss: 2.0647990703582764
Validation loss: 2.04163481086813

Epoch: 5| Step: 1
Training loss: 1.2485988140106201
Validation loss: 2.0260848383749686

Epoch: 5| Step: 2
Training loss: 2.1723217964172363
Validation loss: 2.026087312288182

Epoch: 5| Step: 3
Training loss: 1.957058310508728
Validation loss: 2.0139648017062934

Epoch: 5| Step: 4
Training loss: 2.0806961059570312
Validation loss: 2.060715635617574

Epoch: 5| Step: 5
Training loss: 1.5370099544525146
Validation loss: 2.0257680723744054

Epoch: 5| Step: 6
Training loss: 1.8066654205322266
Validation loss: 2.0451806411948255

Epoch: 5| Step: 7
Training loss: 1.9811875820159912
Validation loss: 2.014509854778167

Epoch: 5| Step: 8
Training loss: 1.8064066171646118
Validation loss: 2.033981196341976

Epoch: 5| Step: 9
Training loss: 1.7714359760284424
Validation loss: 1.9888002000829226

Epoch: 5| Step: 10
Training loss: 1.5596716403961182
Validation loss: 1.992653428867299

Epoch: 252| Step: 0
Training loss: 1.6543220281600952
Validation loss: 2.0216135312152166

Epoch: 5| Step: 1
Training loss: 1.8471473455429077
Validation loss: 2.006060314434831

Epoch: 5| Step: 2
Training loss: 1.721927285194397
Validation loss: 2.02143358671537

Epoch: 5| Step: 3
Training loss: 1.379045009613037
Validation loss: 2.0104032280624553

Epoch: 5| Step: 4
Training loss: 1.5665781497955322
Validation loss: 2.0558413279953824

Epoch: 5| Step: 5
Training loss: 2.3083794116973877
Validation loss: 2.0511479070109706

Epoch: 5| Step: 6
Training loss: 1.6225337982177734
Validation loss: 2.019129219875541

Epoch: 5| Step: 7
Training loss: 2.2575736045837402
Validation loss: 2.024634381776215

Epoch: 5| Step: 8
Training loss: 1.578916311264038
Validation loss: 2.043175866526942

Epoch: 5| Step: 9
Training loss: 1.7443853616714478
Validation loss: 2.0241236686706543

Epoch: 5| Step: 10
Training loss: 2.2718374729156494
Validation loss: 2.0294266387980473

Epoch: 253| Step: 0
Training loss: 1.3924528360366821
Validation loss: 2.060497501845001

Epoch: 5| Step: 1
Training loss: 1.0875850915908813
Validation loss: 2.0386431832467355

Epoch: 5| Step: 2
Training loss: 2.0334160327911377
Validation loss: 2.0203973823978054

Epoch: 5| Step: 3
Training loss: 1.7982215881347656
Validation loss: 2.036744681737756

Epoch: 5| Step: 4
Training loss: 1.9519290924072266
Validation loss: 2.041548717406488

Epoch: 5| Step: 5
Training loss: 2.2229385375976562
Validation loss: 2.05257523188027

Epoch: 5| Step: 6
Training loss: 1.1790335178375244
Validation loss: 2.0200428014160483

Epoch: 5| Step: 7
Training loss: 1.8724149465560913
Validation loss: 2.014524298329507

Epoch: 5| Step: 8
Training loss: 1.9843873977661133
Validation loss: 2.026793114600643

Epoch: 5| Step: 9
Training loss: 2.350429058074951
Validation loss: 2.0294674160659953

Epoch: 5| Step: 10
Training loss: 2.0274620056152344
Validation loss: 2.007736059927171

Epoch: 254| Step: 0
Training loss: 1.6154476404190063
Validation loss: 2.0338750552105647

Epoch: 5| Step: 1
Training loss: 1.7250919342041016
Validation loss: 1.9872670891464397

Epoch: 5| Step: 2
Training loss: 1.9350143671035767
Validation loss: 1.9701197711370324

Epoch: 5| Step: 3
Training loss: 2.304888963699341
Validation loss: 2.013957138984434

Epoch: 5| Step: 4
Training loss: 1.603069543838501
Validation loss: 2.008240302403768

Epoch: 5| Step: 5
Training loss: 1.6572402715682983
Validation loss: 1.9732051485328264

Epoch: 5| Step: 6
Training loss: 1.6005966663360596
Validation loss: 2.0366943420902377

Epoch: 5| Step: 7
Training loss: 1.7111772298812866
Validation loss: 2.007398856583462

Epoch: 5| Step: 8
Training loss: 1.4967515468597412
Validation loss: 2.004861377900647

Epoch: 5| Step: 9
Training loss: 1.5411649942398071
Validation loss: 1.999604464859091

Epoch: 5| Step: 10
Training loss: 2.48453426361084
Validation loss: 2.0271204825370543

Epoch: 255| Step: 0
Training loss: 1.4118211269378662
Validation loss: 2.0107455817602014

Epoch: 5| Step: 1
Training loss: 1.8971704244613647
Validation loss: 2.0173985368462017

Epoch: 5| Step: 2
Training loss: 2.2096996307373047
Validation loss: 1.9997064067471413

Epoch: 5| Step: 3
Training loss: 1.4228432178497314
Validation loss: 1.9697137596786662

Epoch: 5| Step: 4
Training loss: 2.2092392444610596
Validation loss: 1.9805543089425692

Epoch: 5| Step: 5
Training loss: 1.362758755683899
Validation loss: 1.9930590403977262

Epoch: 5| Step: 6
Training loss: 1.3398540019989014
Validation loss: 2.004363247143325

Epoch: 5| Step: 7
Training loss: 1.8614108562469482
Validation loss: 2.0126477056933987

Epoch: 5| Step: 8
Training loss: 2.101602077484131
Validation loss: 2.0213532499087754

Epoch: 5| Step: 9
Training loss: 2.113184690475464
Validation loss: 2.015687986086774

Epoch: 5| Step: 10
Training loss: 1.7624541521072388
Validation loss: 2.0443419897428123

Epoch: 256| Step: 0
Training loss: 2.2183239459991455
Validation loss: 2.0171667222053773

Epoch: 5| Step: 1
Training loss: 1.618756890296936
Validation loss: 2.01203917431575

Epoch: 5| Step: 2
Training loss: 1.3367643356323242
Validation loss: 2.0326067286152996

Epoch: 5| Step: 3
Training loss: 1.3194246292114258
Validation loss: 2.019910499613772

Epoch: 5| Step: 4
Training loss: 2.3406691551208496
Validation loss: 2.0293630233374973

Epoch: 5| Step: 5
Training loss: 2.209378719329834
Validation loss: 2.0007853661814043

Epoch: 5| Step: 6
Training loss: 1.251948595046997
Validation loss: 2.007535555029428

Epoch: 5| Step: 7
Training loss: 1.7321550846099854
Validation loss: 2.0140297976873254

Epoch: 5| Step: 8
Training loss: 1.7749732732772827
Validation loss: 2.003403764899059

Epoch: 5| Step: 9
Training loss: 2.125166416168213
Validation loss: 2.0320630124820176

Epoch: 5| Step: 10
Training loss: 1.690030813217163
Validation loss: 2.019654607260099

Epoch: 257| Step: 0
Training loss: 1.702815055847168
Validation loss: 2.010036083959764

Epoch: 5| Step: 1
Training loss: 1.8250528573989868
Validation loss: 2.002558833809309

Epoch: 5| Step: 2
Training loss: 1.6114318370819092
Validation loss: 1.9778024265843053

Epoch: 5| Step: 3
Training loss: 2.284149169921875
Validation loss: 2.0071429706388906

Epoch: 5| Step: 4
Training loss: 2.1412081718444824
Validation loss: 2.029863903599401

Epoch: 5| Step: 5
Training loss: 2.0246448516845703
Validation loss: 1.9788058803927513

Epoch: 5| Step: 6
Training loss: 1.430239200592041
Validation loss: 2.0039234776650705

Epoch: 5| Step: 7
Training loss: 1.2505199909210205
Validation loss: 1.9896794826753679

Epoch: 5| Step: 8
Training loss: 1.8795980215072632
Validation loss: 2.00033555235914

Epoch: 5| Step: 9
Training loss: 1.899560570716858
Validation loss: 2.048869989251578

Epoch: 5| Step: 10
Training loss: 2.076131820678711
Validation loss: 2.0261399361395065

Epoch: 258| Step: 0
Training loss: 1.7502524852752686
Validation loss: 2.026151187958256

Epoch: 5| Step: 1
Training loss: 1.6994686126708984
Validation loss: 2.0266417354665776

Epoch: 5| Step: 2
Training loss: 2.4599220752716064
Validation loss: 2.043130087596114

Epoch: 5| Step: 3
Training loss: 1.6991136074066162
Validation loss: 2.0713957035413353

Epoch: 5| Step: 4
Training loss: 1.4775341749191284
Validation loss: 2.02546174551851

Epoch: 5| Step: 5
Training loss: 2.3807175159454346
Validation loss: 2.0281277010517735

Epoch: 5| Step: 6
Training loss: 1.128812551498413
Validation loss: 2.0400935039725354

Epoch: 5| Step: 7
Training loss: 1.4542913436889648
Validation loss: 2.0248687062212216

Epoch: 5| Step: 8
Training loss: 2.2623391151428223
Validation loss: 2.0478324146680933

Epoch: 5| Step: 9
Training loss: 1.5001108646392822
Validation loss: 2.045083451014693

Epoch: 5| Step: 10
Training loss: 2.009464740753174
Validation loss: 2.023388813900691

Epoch: 259| Step: 0
Training loss: 1.6649329662322998
Validation loss: 2.0009910175877232

Epoch: 5| Step: 1
Training loss: 1.6281030178070068
Validation loss: 2.0412913830049577

Epoch: 5| Step: 2
Training loss: 1.9348504543304443
Validation loss: 2.048666483612471

Epoch: 5| Step: 3
Training loss: 1.9157501459121704
Validation loss: 2.0174580697090394

Epoch: 5| Step: 4
Training loss: 2.0096638202667236
Validation loss: 2.0364108495814826

Epoch: 5| Step: 5
Training loss: 1.6495075225830078
Validation loss: 2.014671339783617

Epoch: 5| Step: 6
Training loss: 1.4145375490188599
Validation loss: 2.0178120700261926

Epoch: 5| Step: 7
Training loss: 1.8736289739608765
Validation loss: 2.039823737195743

Epoch: 5| Step: 8
Training loss: 1.975902795791626
Validation loss: 2.0027887129014537

Epoch: 5| Step: 9
Training loss: 1.9874134063720703
Validation loss: 2.0294511036206315

Epoch: 5| Step: 10
Training loss: 1.6395286321640015
Validation loss: 2.0276145858149373

Epoch: 260| Step: 0
Training loss: 2.1375784873962402
Validation loss: 2.006104891659111

Epoch: 5| Step: 1
Training loss: 1.9550418853759766
Validation loss: 2.0191058612638906

Epoch: 5| Step: 2
Training loss: 1.8350245952606201
Validation loss: 2.0298221380479875

Epoch: 5| Step: 3
Training loss: 1.9343643188476562
Validation loss: 2.0241891901980162

Epoch: 5| Step: 4
Training loss: 1.2707574367523193
Validation loss: 2.024164665129877

Epoch: 5| Step: 5
Training loss: 1.9664242267608643
Validation loss: 2.0256991591504825

Epoch: 5| Step: 6
Training loss: 1.4936076402664185
Validation loss: 2.0065975214845393

Epoch: 5| Step: 7
Training loss: 1.3481576442718506
Validation loss: 1.9878147878954489

Epoch: 5| Step: 8
Training loss: 1.8629930019378662
Validation loss: 2.0095200359180407

Epoch: 5| Step: 9
Training loss: 1.9851667881011963
Validation loss: 1.9957655783622497

Epoch: 5| Step: 10
Training loss: 2.080824851989746
Validation loss: 2.016756575594666

Epoch: 261| Step: 0
Training loss: 1.8551076650619507
Validation loss: 2.0235648975577405

Epoch: 5| Step: 1
Training loss: 1.3764959573745728
Validation loss: 2.012413486357658

Epoch: 5| Step: 2
Training loss: 1.556081771850586
Validation loss: 2.0267155221713486

Epoch: 5| Step: 3
Training loss: 1.841928482055664
Validation loss: 2.0454989966525825

Epoch: 5| Step: 4
Training loss: 1.9023311138153076
Validation loss: 2.041512111181854

Epoch: 5| Step: 5
Training loss: 1.985088586807251
Validation loss: 2.0669206855117634

Epoch: 5| Step: 6
Training loss: 1.9248769283294678
Validation loss: 2.0401492657199984

Epoch: 5| Step: 7
Training loss: 1.9167664051055908
Validation loss: 2.025584195249824

Epoch: 5| Step: 8
Training loss: 1.4028356075286865
Validation loss: 2.053789956595308

Epoch: 5| Step: 9
Training loss: 2.1085939407348633
Validation loss: 2.0515178416364934

Epoch: 5| Step: 10
Training loss: 1.9518450498580933
Validation loss: 2.0201867498377317

Epoch: 262| Step: 0
Training loss: 1.7999169826507568
Validation loss: 2.027075598316808

Epoch: 5| Step: 1
Training loss: 1.645525574684143
Validation loss: 2.020461336258919

Epoch: 5| Step: 2
Training loss: 1.5046193599700928
Validation loss: 2.0356969653919177

Epoch: 5| Step: 3
Training loss: 1.8209892511367798
Validation loss: 2.021699410612865

Epoch: 5| Step: 4
Training loss: 1.6752878427505493
Validation loss: 2.019765623154179

Epoch: 5| Step: 5
Training loss: 1.7055213451385498
Validation loss: 2.0090147372215026

Epoch: 5| Step: 6
Training loss: 1.750597596168518
Validation loss: 2.0295554925036687

Epoch: 5| Step: 7
Training loss: 2.0863170623779297
Validation loss: 2.0351311955400693

Epoch: 5| Step: 8
Training loss: 1.7658488750457764
Validation loss: 2.040275599366875

Epoch: 5| Step: 9
Training loss: 2.242436408996582
Validation loss: 2.0366427180587605

Epoch: 5| Step: 10
Training loss: 1.8581581115722656
Validation loss: 2.0332581266280143

Epoch: 263| Step: 0
Training loss: 1.701422929763794
Validation loss: 2.036627015759868

Epoch: 5| Step: 1
Training loss: 2.0797576904296875
Validation loss: 2.003561004515617

Epoch: 5| Step: 2
Training loss: 2.154445171356201
Validation loss: 2.024676722864951

Epoch: 5| Step: 3
Training loss: 1.7206112146377563
Validation loss: 2.003668854313512

Epoch: 5| Step: 4
Training loss: 1.7345279455184937
Validation loss: 1.998386852202877

Epoch: 5| Step: 5
Training loss: 1.4978049993515015
Validation loss: 1.9818563230576054

Epoch: 5| Step: 6
Training loss: 1.6460554599761963
Validation loss: 1.9987075444190734

Epoch: 5| Step: 7
Training loss: 1.2964167594909668
Validation loss: 1.9915806644706315

Epoch: 5| Step: 8
Training loss: 2.287795305252075
Validation loss: 2.029999745789395

Epoch: 5| Step: 9
Training loss: 1.4637130498886108
Validation loss: 2.015690116472142

Epoch: 5| Step: 10
Training loss: 2.2438430786132812
Validation loss: 2.033776903665194

Epoch: 264| Step: 0
Training loss: 1.62164306640625
Validation loss: 2.018750121516566

Epoch: 5| Step: 1
Training loss: 1.81485116481781
Validation loss: 2.016501865079326

Epoch: 5| Step: 2
Training loss: 1.5277377367019653
Validation loss: 2.024233079725696

Epoch: 5| Step: 3
Training loss: 1.7039241790771484
Validation loss: 1.987333067001835

Epoch: 5| Step: 4
Training loss: 1.6743360757827759
Validation loss: 2.0464027927767847

Epoch: 5| Step: 5
Training loss: 1.4590299129486084
Validation loss: 2.023743357709659

Epoch: 5| Step: 6
Training loss: 1.6466203927993774
Validation loss: 2.0150205153290943

Epoch: 5| Step: 7
Training loss: 1.5509932041168213
Validation loss: 2.0234347056317072

Epoch: 5| Step: 8
Training loss: 2.6726324558258057
Validation loss: 2.0074077947165376

Epoch: 5| Step: 9
Training loss: 2.281312942504883
Validation loss: 1.9747234826446862

Epoch: 5| Step: 10
Training loss: 1.7019294500350952
Validation loss: 2.0170986511374034

Epoch: 265| Step: 0
Training loss: 2.689527750015259
Validation loss: 2.0331558155757126

Epoch: 5| Step: 1
Training loss: 1.6226856708526611
Validation loss: 2.029316420196205

Epoch: 5| Step: 2
Training loss: 1.5573184490203857
Validation loss: 2.0108801331571353

Epoch: 5| Step: 3
Training loss: 1.5259406566619873
Validation loss: 2.0683711267286733

Epoch: 5| Step: 4
Training loss: 1.3934483528137207
Validation loss: 2.0600749215772076

Epoch: 5| Step: 5
Training loss: 1.7337672710418701
Validation loss: 2.0256895185798727

Epoch: 5| Step: 6
Training loss: 1.620571494102478
Validation loss: 2.0227545768983903

Epoch: 5| Step: 7
Training loss: 2.1156787872314453
Validation loss: 2.034030971988555

Epoch: 5| Step: 8
Training loss: 1.618983507156372
Validation loss: 2.0293524508835166

Epoch: 5| Step: 9
Training loss: 2.0253915786743164
Validation loss: 2.0246223531743532

Epoch: 5| Step: 10
Training loss: 1.859959602355957
Validation loss: 2.0258128745581514

Epoch: 266| Step: 0
Training loss: 1.099247694015503
Validation loss: 2.003226372503465

Epoch: 5| Step: 1
Training loss: 1.8736861944198608
Validation loss: 2.0252117264655327

Epoch: 5| Step: 2
Training loss: 1.459188461303711
Validation loss: 2.0342558276268745

Epoch: 5| Step: 3
Training loss: 2.288888692855835
Validation loss: 2.041852525485459

Epoch: 5| Step: 4
Training loss: 2.1335630416870117
Validation loss: 2.0482767448630383

Epoch: 5| Step: 5
Training loss: 1.3440186977386475
Validation loss: 2.019213991780435

Epoch: 5| Step: 6
Training loss: 1.7173471450805664
Validation loss: 2.03270378933158

Epoch: 5| Step: 7
Training loss: 1.7075064182281494
Validation loss: 1.9899527488216278

Epoch: 5| Step: 8
Training loss: 1.9237463474273682
Validation loss: 2.05351964248124

Epoch: 5| Step: 9
Training loss: 2.224135637283325
Validation loss: 2.034341992870454

Epoch: 5| Step: 10
Training loss: 1.6830919981002808
Validation loss: 2.0297475399509555

Epoch: 267| Step: 0
Training loss: 1.2817659378051758
Validation loss: 2.0585730768019155

Epoch: 5| Step: 1
Training loss: 2.206879138946533
Validation loss: 2.050901189927132

Epoch: 5| Step: 2
Training loss: 1.6086124181747437
Validation loss: 2.0275715384432065

Epoch: 5| Step: 3
Training loss: 1.669441819190979
Validation loss: 2.042571900993265

Epoch: 5| Step: 4
Training loss: 1.6836334466934204
Validation loss: 2.0347527355276127

Epoch: 5| Step: 5
Training loss: 2.103607654571533
Validation loss: 2.0315727867105955

Epoch: 5| Step: 6
Training loss: 1.4722309112548828
Validation loss: 2.0505165053952124

Epoch: 5| Step: 7
Training loss: 1.8584411144256592
Validation loss: 2.021065224883377

Epoch: 5| Step: 8
Training loss: 1.7656536102294922
Validation loss: 2.0332809366205686

Epoch: 5| Step: 9
Training loss: 1.3395715951919556
Validation loss: 2.032135449429994

Epoch: 5| Step: 10
Training loss: 2.5107767581939697
Validation loss: 2.026994453963413

Epoch: 268| Step: 0
Training loss: 2.3212273120880127
Validation loss: 2.0064801439162223

Epoch: 5| Step: 1
Training loss: 2.034884214401245
Validation loss: 2.0142075272016626

Epoch: 5| Step: 2
Training loss: 1.5257285833358765
Validation loss: 2.014831740369079

Epoch: 5| Step: 3
Training loss: 1.1645429134368896
Validation loss: 2.005043419458533

Epoch: 5| Step: 4
Training loss: 1.6308529376983643
Validation loss: 2.0418783157102522

Epoch: 5| Step: 5
Training loss: 1.9084326028823853
Validation loss: 2.001297220107048

Epoch: 5| Step: 6
Training loss: 1.802011251449585
Validation loss: 2.0177536279924455

Epoch: 5| Step: 7
Training loss: 2.3980965614318848
Validation loss: 2.003628211636697

Epoch: 5| Step: 8
Training loss: 1.350592017173767
Validation loss: 2.0092759568204164

Epoch: 5| Step: 9
Training loss: 1.0933730602264404
Validation loss: 2.0026288263259397

Epoch: 5| Step: 10
Training loss: 2.3595025539398193
Validation loss: 2.0178222784432034

Epoch: 269| Step: 0
Training loss: 2.193692922592163
Validation loss: 1.9943425706637803

Epoch: 5| Step: 1
Training loss: 1.9898821115493774
Validation loss: 2.0261299943411224

Epoch: 5| Step: 2
Training loss: 1.6066014766693115
Validation loss: 2.014048848100888

Epoch: 5| Step: 3
Training loss: 2.203469753265381
Validation loss: 2.0251476995406614

Epoch: 5| Step: 4
Training loss: 1.9644759893417358
Validation loss: 2.0354305057115454

Epoch: 5| Step: 5
Training loss: 1.7177642583847046
Validation loss: 2.0535113106491747

Epoch: 5| Step: 6
Training loss: 2.103970766067505
Validation loss: 2.0531497950194986

Epoch: 5| Step: 7
Training loss: 1.7266416549682617
Validation loss: 2.0503835101281442

Epoch: 5| Step: 8
Training loss: 1.3669668436050415
Validation loss: 2.055049700121726

Epoch: 5| Step: 9
Training loss: 1.287950873374939
Validation loss: 2.063162362703713

Epoch: 5| Step: 10
Training loss: 1.2298054695129395
Validation loss: 2.0101920904651767

Epoch: 270| Step: 0
Training loss: 1.7900583744049072
Validation loss: 2.0379687842502388

Epoch: 5| Step: 1
Training loss: 1.5360467433929443
Validation loss: 2.0366792512196366

Epoch: 5| Step: 2
Training loss: 1.657297134399414
Validation loss: 2.020646074766754

Epoch: 5| Step: 3
Training loss: 2.3437438011169434
Validation loss: 2.0221611504913657

Epoch: 5| Step: 4
Training loss: 2.3601584434509277
Validation loss: 1.996177291357389

Epoch: 5| Step: 5
Training loss: 1.4905496835708618
Validation loss: 2.044497561711137

Epoch: 5| Step: 6
Training loss: 2.042609691619873
Validation loss: 2.004802550038984

Epoch: 5| Step: 7
Training loss: 2.108053684234619
Validation loss: 2.0285239245301936

Epoch: 5| Step: 8
Training loss: 1.4073631763458252
Validation loss: 2.0336617064732376

Epoch: 5| Step: 9
Training loss: 1.4653035402297974
Validation loss: 2.038923273804367

Epoch: 5| Step: 10
Training loss: 1.3415663242340088
Validation loss: 2.0315071075193343

Epoch: 271| Step: 0
Training loss: 1.2848855257034302
Validation loss: 2.0494755442424486

Epoch: 5| Step: 1
Training loss: 1.671091079711914
Validation loss: 2.0328256289164224

Epoch: 5| Step: 2
Training loss: 1.1800868511199951
Validation loss: 2.0558654210900746

Epoch: 5| Step: 3
Training loss: 1.906658411026001
Validation loss: 2.0944608616572555

Epoch: 5| Step: 4
Training loss: 2.0471553802490234
Validation loss: 2.0321370940054617

Epoch: 5| Step: 5
Training loss: 1.7692991495132446
Validation loss: 2.053221730775731

Epoch: 5| Step: 6
Training loss: 1.8392736911773682
Validation loss: 2.024005764274187

Epoch: 5| Step: 7
Training loss: 2.0162878036499023
Validation loss: 2.0649284111556185

Epoch: 5| Step: 8
Training loss: 2.091625690460205
Validation loss: 2.0117761563229304

Epoch: 5| Step: 9
Training loss: 1.9377939701080322
Validation loss: 2.05329034661734

Epoch: 5| Step: 10
Training loss: 1.852716326713562
Validation loss: 2.0201151922184932

Epoch: 272| Step: 0
Training loss: 1.3908650875091553
Validation loss: 2.0224460914570797

Epoch: 5| Step: 1
Training loss: 1.6766688823699951
Validation loss: 2.0176568877312446

Epoch: 5| Step: 2
Training loss: 1.8941659927368164
Validation loss: 2.0463743773839806

Epoch: 5| Step: 3
Training loss: 1.891526222229004
Validation loss: 2.0668395629493137

Epoch: 5| Step: 4
Training loss: 2.290945529937744
Validation loss: 2.037086268906952

Epoch: 5| Step: 5
Training loss: 1.5865799188613892
Validation loss: 2.040055667200396

Epoch: 5| Step: 6
Training loss: 1.4859861135482788
Validation loss: 2.038691477109027

Epoch: 5| Step: 7
Training loss: 1.6698482036590576
Validation loss: 2.024309858199089

Epoch: 5| Step: 8
Training loss: 1.6769959926605225
Validation loss: 2.0313037313440794

Epoch: 5| Step: 9
Training loss: 1.8982998132705688
Validation loss: 2.007768956563806

Epoch: 5| Step: 10
Training loss: 1.6974661350250244
Validation loss: 2.037615745298324

Epoch: 273| Step: 0
Training loss: 1.9889106750488281
Validation loss: 2.01439848766532

Epoch: 5| Step: 1
Training loss: 1.3015730381011963
Validation loss: 2.0206411320676088

Epoch: 5| Step: 2
Training loss: 1.6595147848129272
Validation loss: 2.0266042345313617

Epoch: 5| Step: 3
Training loss: 1.7382867336273193
Validation loss: 2.045183459917704

Epoch: 5| Step: 4
Training loss: 1.8727028369903564
Validation loss: 2.0357834498087564

Epoch: 5| Step: 5
Training loss: 2.3446338176727295
Validation loss: 2.0421665560814644

Epoch: 5| Step: 6
Training loss: 1.5359609127044678
Validation loss: 2.0335708049035843

Epoch: 5| Step: 7
Training loss: 2.1946213245391846
Validation loss: 2.0372017634812223

Epoch: 5| Step: 8
Training loss: 1.8930473327636719
Validation loss: 2.0342038741675754

Epoch: 5| Step: 9
Training loss: 1.2128983736038208
Validation loss: 2.064377764219879

Epoch: 5| Step: 10
Training loss: 1.7529046535491943
Validation loss: 2.0656962189623105

Epoch: 274| Step: 0
Training loss: 1.7903884649276733
Validation loss: 2.030552766656363

Epoch: 5| Step: 1
Training loss: 1.8282982110977173
Validation loss: 2.031936244298053

Epoch: 5| Step: 2
Training loss: 1.9362983703613281
Validation loss: 2.0216808639546877

Epoch: 5| Step: 3
Training loss: 1.1945507526397705
Validation loss: 2.026574302745122

Epoch: 5| Step: 4
Training loss: 1.5279254913330078
Validation loss: 1.991217464529058

Epoch: 5| Step: 5
Training loss: 1.4798622131347656
Validation loss: 2.0378316371671614

Epoch: 5| Step: 6
Training loss: 1.9468952417373657
Validation loss: 2.054488815287108

Epoch: 5| Step: 7
Training loss: 1.8614757061004639
Validation loss: 2.0147803739834855

Epoch: 5| Step: 8
Training loss: 1.792920708656311
Validation loss: 2.0283528245905393

Epoch: 5| Step: 9
Training loss: 2.0032150745391846
Validation loss: 2.0200522099771807

Epoch: 5| Step: 10
Training loss: 2.0796234607696533
Validation loss: 2.028263456077986

Epoch: 275| Step: 0
Training loss: 2.022617816925049
Validation loss: 2.030280864366921

Epoch: 5| Step: 1
Training loss: 1.5561926364898682
Validation loss: 2.056255699485861

Epoch: 5| Step: 2
Training loss: 2.1526989936828613
Validation loss: 2.0572648843129477

Epoch: 5| Step: 3
Training loss: 2.1308019161224365
Validation loss: 2.046800559566867

Epoch: 5| Step: 4
Training loss: 1.5776488780975342
Validation loss: 2.0228956617334837

Epoch: 5| Step: 5
Training loss: 1.640784502029419
Validation loss: 2.0541285596868044

Epoch: 5| Step: 6
Training loss: 1.527343988418579
Validation loss: 2.0646653059990174

Epoch: 5| Step: 7
Training loss: 1.8320553302764893
Validation loss: 2.0277057540032173

Epoch: 5| Step: 8
Training loss: 1.769700050354004
Validation loss: 2.036812054213657

Epoch: 5| Step: 9
Training loss: 1.355273962020874
Validation loss: 2.046990800929326

Epoch: 5| Step: 10
Training loss: 1.8861833810806274
Validation loss: 2.0095094737186225

Epoch: 276| Step: 0
Training loss: 1.8435900211334229
Validation loss: 2.0043409973062496

Epoch: 5| Step: 1
Training loss: 1.7623722553253174
Validation loss: 2.0051549070624897

Epoch: 5| Step: 2
Training loss: 1.7911643981933594
Validation loss: 2.087429849050378

Epoch: 5| Step: 3
Training loss: 1.4976987838745117
Validation loss: 2.040662165611021

Epoch: 5| Step: 4
Training loss: 1.9418704509735107
Validation loss: 2.018471260224619

Epoch: 5| Step: 5
Training loss: 1.4357335567474365
Validation loss: 2.0237674482407106

Epoch: 5| Step: 6
Training loss: 1.8251800537109375
Validation loss: 2.032664119556386

Epoch: 5| Step: 7
Training loss: 1.9492849111557007
Validation loss: 2.007855910126881

Epoch: 5| Step: 8
Training loss: 1.6909692287445068
Validation loss: 2.0197495875820035

Epoch: 5| Step: 9
Training loss: 1.410513162612915
Validation loss: 2.0077199679549023

Epoch: 5| Step: 10
Training loss: 2.229234218597412
Validation loss: 2.0533826838257494

Epoch: 277| Step: 0
Training loss: 1.6442286968231201
Validation loss: 2.03765598932902

Epoch: 5| Step: 1
Training loss: 1.6105525493621826
Validation loss: 2.0467390834644275

Epoch: 5| Step: 2
Training loss: 1.7538578510284424
Validation loss: 2.0385321083889214

Epoch: 5| Step: 3
Training loss: 1.6811739206314087
Validation loss: 2.023844685605777

Epoch: 5| Step: 4
Training loss: 1.7931883335113525
Validation loss: 2.0262158557932866

Epoch: 5| Step: 5
Training loss: 2.338411808013916
Validation loss: 2.0357186384098505

Epoch: 5| Step: 6
Training loss: 1.6619226932525635
Validation loss: 2.044559327504968

Epoch: 5| Step: 7
Training loss: 1.3829845190048218
Validation loss: 2.021822947327809

Epoch: 5| Step: 8
Training loss: 1.7070839405059814
Validation loss: 2.0180708080209713

Epoch: 5| Step: 9
Training loss: 2.161072254180908
Validation loss: 2.024819589430286

Epoch: 5| Step: 10
Training loss: 1.4877731800079346
Validation loss: 2.037657344213096

Epoch: 278| Step: 0
Training loss: 2.315886974334717
Validation loss: 2.057806912288871

Epoch: 5| Step: 1
Training loss: 1.8793919086456299
Validation loss: 2.0278406220097698

Epoch: 5| Step: 2
Training loss: 1.6021493673324585
Validation loss: 2.0445598325421734

Epoch: 5| Step: 3
Training loss: 1.3483575582504272
Validation loss: 2.0823594780378443

Epoch: 5| Step: 4
Training loss: 1.7741806507110596
Validation loss: 2.0365256942728514

Epoch: 5| Step: 5
Training loss: 2.1307156085968018
Validation loss: 2.0440560643390944

Epoch: 5| Step: 6
Training loss: 1.5635440349578857
Validation loss: 2.070788816739154

Epoch: 5| Step: 7
Training loss: 1.9587500095367432
Validation loss: 2.0399971905575005

Epoch: 5| Step: 8
Training loss: 1.755074143409729
Validation loss: 2.080676273633075

Epoch: 5| Step: 9
Training loss: 1.5687391757965088
Validation loss: 2.0643403914666947

Epoch: 5| Step: 10
Training loss: 1.6297792196273804
Validation loss: 2.0497163803346696

Epoch: 279| Step: 0
Training loss: 1.432239294052124
Validation loss: 2.040223998408164

Epoch: 5| Step: 1
Training loss: 1.5776665210723877
Validation loss: 2.037117700422964

Epoch: 5| Step: 2
Training loss: 1.281743049621582
Validation loss: 2.0129958686008247

Epoch: 5| Step: 3
Training loss: 1.603447675704956
Validation loss: 2.019240956152639

Epoch: 5| Step: 4
Training loss: 2.0820813179016113
Validation loss: 2.0314414911372687

Epoch: 5| Step: 5
Training loss: 1.9816827774047852
Validation loss: 2.0293219115144465

Epoch: 5| Step: 6
Training loss: 1.8592230081558228
Validation loss: 2.0134157237186225

Epoch: 5| Step: 7
Training loss: 2.047295570373535
Validation loss: 2.036403427841843

Epoch: 5| Step: 8
Training loss: 1.9724185466766357
Validation loss: 2.0486073109411422

Epoch: 5| Step: 9
Training loss: 1.7364113330841064
Validation loss: 2.0021521070952057

Epoch: 5| Step: 10
Training loss: 1.6309722661972046
Validation loss: 2.0744296658423638

Epoch: 280| Step: 0
Training loss: 1.8365166187286377
Validation loss: 2.0457376023774505

Epoch: 5| Step: 1
Training loss: 1.4911432266235352
Validation loss: 2.051452441882062

Epoch: 5| Step: 2
Training loss: 1.2751789093017578
Validation loss: 2.0523022169707925

Epoch: 5| Step: 3
Training loss: 1.5751641988754272
Validation loss: 2.0597581607039257

Epoch: 5| Step: 4
Training loss: 1.9674739837646484
Validation loss: 2.061590535666353

Epoch: 5| Step: 5
Training loss: 1.651235818862915
Validation loss: 2.011800974927923

Epoch: 5| Step: 6
Training loss: 1.568632960319519
Validation loss: 2.0622431411538074

Epoch: 5| Step: 7
Training loss: 1.701276421546936
Validation loss: 2.0398497376390683

Epoch: 5| Step: 8
Training loss: 1.847132682800293
Validation loss: 2.0304451450224845

Epoch: 5| Step: 9
Training loss: 2.1816086769104004
Validation loss: 2.0281181796904533

Epoch: 5| Step: 10
Training loss: 1.8994412422180176
Validation loss: 2.0435390126320625

Epoch: 281| Step: 0
Training loss: 1.0552616119384766
Validation loss: 2.0765934913389144

Epoch: 5| Step: 1
Training loss: 1.8882625102996826
Validation loss: 2.0244920804936397

Epoch: 5| Step: 2
Training loss: 1.8891689777374268
Validation loss: 2.0701032274512836

Epoch: 5| Step: 3
Training loss: 1.3964606523513794
Validation loss: 2.008480166876188

Epoch: 5| Step: 4
Training loss: 1.6548595428466797
Validation loss: 2.0436005464164158

Epoch: 5| Step: 5
Training loss: 1.8252500295639038
Validation loss: 2.0108811624588503

Epoch: 5| Step: 6
Training loss: 1.510853886604309
Validation loss: 2.018555038718767

Epoch: 5| Step: 7
Training loss: 2.1361594200134277
Validation loss: 2.043860138103526

Epoch: 5| Step: 8
Training loss: 1.552207350730896
Validation loss: 2.0555479911065873

Epoch: 5| Step: 9
Training loss: 1.9670556783676147
Validation loss: 2.0256084524175173

Epoch: 5| Step: 10
Training loss: 2.191704511642456
Validation loss: 2.032584482623685

Epoch: 282| Step: 0
Training loss: 2.462298631668091
Validation loss: 2.040912530755484

Epoch: 5| Step: 1
Training loss: 1.7429593801498413
Validation loss: 2.0461121348924536

Epoch: 5| Step: 2
Training loss: 2.0581653118133545
Validation loss: 2.0507652016096216

Epoch: 5| Step: 3
Training loss: 1.7967827320098877
Validation loss: 2.051413889854185

Epoch: 5| Step: 4
Training loss: 1.1620995998382568
Validation loss: 2.065678006859236

Epoch: 5| Step: 5
Training loss: 1.419605016708374
Validation loss: 2.048704352430118

Epoch: 5| Step: 6
Training loss: 1.3840758800506592
Validation loss: 2.059449031788816

Epoch: 5| Step: 7
Training loss: 1.7071548700332642
Validation loss: 2.0771783474952943

Epoch: 5| Step: 8
Training loss: 1.9161548614501953
Validation loss: 2.042790792321646

Epoch: 5| Step: 9
Training loss: 1.771182656288147
Validation loss: 2.0448177975993

Epoch: 5| Step: 10
Training loss: 1.6136263608932495
Validation loss: 2.065614079916349

Epoch: 283| Step: 0
Training loss: 1.9941202402114868
Validation loss: 2.014287699935257

Epoch: 5| Step: 1
Training loss: 1.7952020168304443
Validation loss: 2.044403008235398

Epoch: 5| Step: 2
Training loss: 1.409783959388733
Validation loss: 2.0191826166645175

Epoch: 5| Step: 3
Training loss: 1.9627063274383545
Validation loss: 2.0885610939354025

Epoch: 5| Step: 4
Training loss: 1.3645353317260742
Validation loss: 2.0565991683672835

Epoch: 5| Step: 5
Training loss: 1.8029333353042603
Validation loss: 1.9974899163810156

Epoch: 5| Step: 6
Training loss: 1.2608766555786133
Validation loss: 2.0445365059760308

Epoch: 5| Step: 7
Training loss: 1.763362169265747
Validation loss: 2.026871581231394

Epoch: 5| Step: 8
Training loss: 2.068183183670044
Validation loss: 2.041016121064463

Epoch: 5| Step: 9
Training loss: 1.6315218210220337
Validation loss: 2.013985913286927

Epoch: 5| Step: 10
Training loss: 2.000993251800537
Validation loss: 2.0168963452821136

Epoch: 284| Step: 0
Training loss: 1.8946298360824585
Validation loss: 2.0416626853327595

Epoch: 5| Step: 1
Training loss: 1.3534339666366577
Validation loss: 2.0062518376176075

Epoch: 5| Step: 2
Training loss: 1.4691522121429443
Validation loss: 2.0133080700392365

Epoch: 5| Step: 3
Training loss: 2.1354026794433594
Validation loss: 2.0338732196438696

Epoch: 5| Step: 4
Training loss: 2.0624451637268066
Validation loss: 2.0090900403197094

Epoch: 5| Step: 5
Training loss: 1.960524559020996
Validation loss: 2.0272690583300847

Epoch: 5| Step: 6
Training loss: 1.7353910207748413
Validation loss: 2.014147150901056

Epoch: 5| Step: 7
Training loss: 1.3574596643447876
Validation loss: 2.0150645150933215

Epoch: 5| Step: 8
Training loss: 1.536889910697937
Validation loss: 2.014735060353433

Epoch: 5| Step: 9
Training loss: 1.6303346157073975
Validation loss: 2.020854239822716

Epoch: 5| Step: 10
Training loss: 1.937947392463684
Validation loss: 2.0341277148133967

Epoch: 285| Step: 0
Training loss: 1.7910394668579102
Validation loss: 2.0403414105856292

Epoch: 5| Step: 1
Training loss: 1.938012719154358
Validation loss: 2.016617364780877

Epoch: 5| Step: 2
Training loss: 1.9554170370101929
Validation loss: 2.0564357055130826

Epoch: 5| Step: 3
Training loss: 1.9416440725326538
Validation loss: 2.0809363190845778

Epoch: 5| Step: 4
Training loss: 1.628963828086853
Validation loss: 2.0897427963954147

Epoch: 5| Step: 5
Training loss: 1.524214744567871
Validation loss: 2.0870011134814193

Epoch: 5| Step: 6
Training loss: 1.651742696762085
Validation loss: 2.0548607328886628

Epoch: 5| Step: 7
Training loss: 1.9195642471313477
Validation loss: 2.0647568113060406

Epoch: 5| Step: 8
Training loss: 1.2942063808441162
Validation loss: 2.0647412884619927

Epoch: 5| Step: 9
Training loss: 1.8581393957138062
Validation loss: 2.080520878555954

Epoch: 5| Step: 10
Training loss: 1.8363938331604004
Validation loss: 2.027237061531313

Epoch: 286| Step: 0
Training loss: 2.1520042419433594
Validation loss: 2.0134732723236084

Epoch: 5| Step: 1
Training loss: 1.5817220211029053
Validation loss: 2.0225583814805552

Epoch: 5| Step: 2
Training loss: 1.6808273792266846
Validation loss: 1.989288935097315

Epoch: 5| Step: 3
Training loss: 2.071812152862549
Validation loss: 2.0251295874195714

Epoch: 5| Step: 4
Training loss: 1.4200907945632935
Validation loss: 2.0151567536015667

Epoch: 5| Step: 5
Training loss: 1.6568034887313843
Validation loss: 2.022862080604799

Epoch: 5| Step: 6
Training loss: 1.389294981956482
Validation loss: 2.0180955727895102

Epoch: 5| Step: 7
Training loss: 1.4013376235961914
Validation loss: 2.0019880828037055

Epoch: 5| Step: 8
Training loss: 1.436434030532837
Validation loss: 2.0339365377221057

Epoch: 5| Step: 9
Training loss: 2.2880630493164062
Validation loss: 2.055150665262694

Epoch: 5| Step: 10
Training loss: 2.1903584003448486
Validation loss: 2.0485077404206797

Epoch: 287| Step: 0
Training loss: 1.7168489694595337
Validation loss: 2.0667758628886235

Epoch: 5| Step: 1
Training loss: 1.147185206413269
Validation loss: 2.0747867668828657

Epoch: 5| Step: 2
Training loss: 2.0096993446350098
Validation loss: 2.0242736185750654

Epoch: 5| Step: 3
Training loss: 1.3855947256088257
Validation loss: 2.0778126665340957

Epoch: 5| Step: 4
Training loss: 1.9209197759628296
Validation loss: 2.0652295133118987

Epoch: 5| Step: 5
Training loss: 2.1063599586486816
Validation loss: 2.065778063189599

Epoch: 5| Step: 6
Training loss: 1.7558317184448242
Validation loss: 2.038747742611875

Epoch: 5| Step: 7
Training loss: 1.904341697692871
Validation loss: 2.0324437900256087

Epoch: 5| Step: 8
Training loss: 1.4648563861846924
Validation loss: 2.0616877181555635

Epoch: 5| Step: 9
Training loss: 1.9157129526138306
Validation loss: 2.0644548657119914

Epoch: 5| Step: 10
Training loss: 1.738855004310608
Validation loss: 2.0815839382909958

Epoch: 288| Step: 0
Training loss: 1.6962476968765259
Validation loss: 2.0339800286036667

Epoch: 5| Step: 1
Training loss: 1.8245384693145752
Validation loss: 2.023908443348382

Epoch: 5| Step: 2
Training loss: 1.9526563882827759
Validation loss: 2.0666699024938766

Epoch: 5| Step: 3
Training loss: 2.0029563903808594
Validation loss: 2.0358998801118586

Epoch: 5| Step: 4
Training loss: 1.9803190231323242
Validation loss: 2.0379344442839264

Epoch: 5| Step: 5
Training loss: 1.323338270187378
Validation loss: 2.024867416709982

Epoch: 5| Step: 6
Training loss: 1.4309875965118408
Validation loss: 2.0104023320700533

Epoch: 5| Step: 7
Training loss: 2.5418825149536133
Validation loss: 2.0355969680252897

Epoch: 5| Step: 8
Training loss: 1.4995025396347046
Validation loss: 2.0650802966087096

Epoch: 5| Step: 9
Training loss: 1.355576992034912
Validation loss: 2.041103160509499

Epoch: 5| Step: 10
Training loss: 1.3854103088378906
Validation loss: 2.0345512256827405

Epoch: 289| Step: 0
Training loss: 1.7023718357086182
Validation loss: 2.029122042399581

Epoch: 5| Step: 1
Training loss: 0.96686190366745
Validation loss: 2.0526678946710404

Epoch: 5| Step: 2
Training loss: 1.574676275253296
Validation loss: 2.0370426972707114

Epoch: 5| Step: 3
Training loss: 2.1243643760681152
Validation loss: 2.0600649772151822

Epoch: 5| Step: 4
Training loss: 1.7157799005508423
Validation loss: 2.069329043870331

Epoch: 5| Step: 5
Training loss: 1.828909158706665
Validation loss: 2.035309640310144

Epoch: 5| Step: 6
Training loss: 1.9532787799835205
Validation loss: 2.0500087276581795

Epoch: 5| Step: 7
Training loss: 1.851831078529358
Validation loss: 2.06926465547213

Epoch: 5| Step: 8
Training loss: 1.7582504749298096
Validation loss: 2.0394540755979476

Epoch: 5| Step: 9
Training loss: 2.246997356414795
Validation loss: 2.059925304946079

Epoch: 5| Step: 10
Training loss: 1.2569859027862549
Validation loss: 2.0540033002053537

Epoch: 290| Step: 0
Training loss: 1.508857250213623
Validation loss: 2.0259002472764704

Epoch: 5| Step: 1
Training loss: 1.9010772705078125
Validation loss: 2.056118913876113

Epoch: 5| Step: 2
Training loss: 1.2559900283813477
Validation loss: 2.0269498286708707

Epoch: 5| Step: 3
Training loss: 1.7497529983520508
Validation loss: 2.042865494246124

Epoch: 5| Step: 4
Training loss: 1.919037103652954
Validation loss: 2.0292415259986796

Epoch: 5| Step: 5
Training loss: 2.0932040214538574
Validation loss: 2.032973366398965

Epoch: 5| Step: 6
Training loss: 1.7458889484405518
Validation loss: 2.016605979652815

Epoch: 5| Step: 7
Training loss: 1.6511623859405518
Validation loss: 2.0852215302887784

Epoch: 5| Step: 8
Training loss: 1.2456269264221191
Validation loss: 2.0744274559841362

Epoch: 5| Step: 9
Training loss: 1.9900569915771484
Validation loss: 2.0342265072689263

Epoch: 5| Step: 10
Training loss: 1.8357294797897339
Validation loss: 2.049133910927721

Epoch: 291| Step: 0
Training loss: 1.4701271057128906
Validation loss: 2.0276754030617337

Epoch: 5| Step: 1
Training loss: 1.69599187374115
Validation loss: 2.0597291428555726

Epoch: 5| Step: 2
Training loss: 1.7529096603393555
Validation loss: 2.0496946611712055

Epoch: 5| Step: 3
Training loss: 1.336498737335205
Validation loss: 2.009288077713341

Epoch: 5| Step: 4
Training loss: 1.5338647365570068
Validation loss: 2.05479367574056

Epoch: 5| Step: 5
Training loss: 2.345102310180664
Validation loss: 2.0130614747283277

Epoch: 5| Step: 6
Training loss: 1.8792448043823242
Validation loss: 2.0173607308377504

Epoch: 5| Step: 7
Training loss: 1.2632824182510376
Validation loss: 2.0090121633263043

Epoch: 5| Step: 8
Training loss: 1.8050655126571655
Validation loss: 2.04160148866715

Epoch: 5| Step: 9
Training loss: 1.8280341625213623
Validation loss: 2.0392547627931

Epoch: 5| Step: 10
Training loss: 2.0305488109588623
Validation loss: 2.0452928389272382

Epoch: 292| Step: 0
Training loss: 2.1882030963897705
Validation loss: 2.017621245435489

Epoch: 5| Step: 1
Training loss: 1.4138119220733643
Validation loss: 2.056367835690898

Epoch: 5| Step: 2
Training loss: 1.08719003200531
Validation loss: 2.0361240781763548

Epoch: 5| Step: 3
Training loss: 1.64599609375
Validation loss: 2.0543055867636077

Epoch: 5| Step: 4
Training loss: 1.965336799621582
Validation loss: 2.04479076913608

Epoch: 5| Step: 5
Training loss: 1.6587352752685547
Validation loss: 2.0042928470078336

Epoch: 5| Step: 6
Training loss: 1.6005710363388062
Validation loss: 2.0534365164336337

Epoch: 5| Step: 7
Training loss: 2.0907740592956543
Validation loss: 2.0321132521475516

Epoch: 5| Step: 8
Training loss: 1.7939281463623047
Validation loss: 2.024927344373477

Epoch: 5| Step: 9
Training loss: 2.1328365802764893
Validation loss: 2.0176914763706986

Epoch: 5| Step: 10
Training loss: 1.1704775094985962
Validation loss: 1.9990353122834237

Epoch: 293| Step: 0
Training loss: 1.453181266784668
Validation loss: 2.0466329884785477

Epoch: 5| Step: 1
Training loss: 1.673234224319458
Validation loss: 2.0647051090835244

Epoch: 5| Step: 2
Training loss: 1.3734568357467651
Validation loss: 2.070189014557869

Epoch: 5| Step: 3
Training loss: 1.5053926706314087
Validation loss: 2.084472120449107

Epoch: 5| Step: 4
Training loss: 1.9170777797698975
Validation loss: 2.0793831220237156

Epoch: 5| Step: 5
Training loss: 1.877519965171814
Validation loss: 2.0763040563111663

Epoch: 5| Step: 6
Training loss: 1.6141586303710938
Validation loss: 2.0424229444996005

Epoch: 5| Step: 7
Training loss: 2.0936198234558105
Validation loss: 2.093163323658769

Epoch: 5| Step: 8
Training loss: 2.0814597606658936
Validation loss: 2.073236729509087

Epoch: 5| Step: 9
Training loss: 1.5005431175231934
Validation loss: 2.0903623206641084

Epoch: 5| Step: 10
Training loss: 1.9038245677947998
Validation loss: 2.088657271477484

Epoch: 294| Step: 0
Training loss: 1.5858571529388428
Validation loss: 2.062660824867987

Epoch: 5| Step: 1
Training loss: 1.7615458965301514
Validation loss: 2.051306647639121

Epoch: 5| Step: 2
Training loss: 1.2729558944702148
Validation loss: 2.024810255214732

Epoch: 5| Step: 3
Training loss: 1.095196008682251
Validation loss: 2.06035275613108

Epoch: 5| Step: 4
Training loss: 2.29178786277771
Validation loss: 2.0407638934350785

Epoch: 5| Step: 5
Training loss: 1.8368656635284424
Validation loss: 2.0535040132461058

Epoch: 5| Step: 6
Training loss: 2.1667582988739014
Validation loss: 2.045168048592024

Epoch: 5| Step: 7
Training loss: 1.8922513723373413
Validation loss: 2.046248283437503

Epoch: 5| Step: 8
Training loss: 2.1599574089050293
Validation loss: 2.027248772241736

Epoch: 5| Step: 9
Training loss: 1.1523804664611816
Validation loss: 2.0346365205703245

Epoch: 5| Step: 10
Training loss: 1.9792490005493164
Validation loss: 2.0105633761293147

Epoch: 295| Step: 0
Training loss: 1.888636827468872
Validation loss: 2.0182336991833103

Epoch: 5| Step: 1
Training loss: 1.640038251876831
Validation loss: 1.9962573012998026

Epoch: 5| Step: 2
Training loss: 1.653609275817871
Validation loss: 2.0496043710298437

Epoch: 5| Step: 3
Training loss: 1.4962166547775269
Validation loss: 2.0163475287857877

Epoch: 5| Step: 4
Training loss: 1.544389009475708
Validation loss: 2.005555106747535

Epoch: 5| Step: 5
Training loss: 2.34067964553833
Validation loss: 2.0266166271701938

Epoch: 5| Step: 6
Training loss: 1.6340208053588867
Validation loss: 2.031308368969989

Epoch: 5| Step: 7
Training loss: 2.3961880207061768
Validation loss: 2.0421130926378313

Epoch: 5| Step: 8
Training loss: 1.6633098125457764
Validation loss: 2.0325667960669405

Epoch: 5| Step: 9
Training loss: 1.335252046585083
Validation loss: 2.0780693715618503

Epoch: 5| Step: 10
Training loss: 1.1712545156478882
Validation loss: 2.05488944310014

Epoch: 296| Step: 0
Training loss: 1.621262550354004
Validation loss: 2.077047678732103

Epoch: 5| Step: 1
Training loss: 1.2371346950531006
Validation loss: 2.076693298996136

Epoch: 5| Step: 2
Training loss: 2.023648738861084
Validation loss: 2.0812573407285955

Epoch: 5| Step: 3
Training loss: 1.8404899835586548
Validation loss: 2.0492782336409374

Epoch: 5| Step: 4
Training loss: 1.7520841360092163
Validation loss: 2.0542066353623585

Epoch: 5| Step: 5
Training loss: 1.3490580320358276
Validation loss: 2.061984415977232

Epoch: 5| Step: 6
Training loss: 2.0454049110412598
Validation loss: 2.0491035317861908

Epoch: 5| Step: 7
Training loss: 1.2779839038848877
Validation loss: 2.0476938332280805

Epoch: 5| Step: 8
Training loss: 2.1105713844299316
Validation loss: 2.041454320312828

Epoch: 5| Step: 9
Training loss: 1.9857137203216553
Validation loss: 2.058533565972441

Epoch: 5| Step: 10
Training loss: 1.4456100463867188
Validation loss: 2.0510524447246263

Epoch: 297| Step: 0
Training loss: 1.7493534088134766
Validation loss: 2.029787987791082

Epoch: 5| Step: 1
Training loss: 2.0199029445648193
Validation loss: 2.030890780110513

Epoch: 5| Step: 2
Training loss: 1.6254926919937134
Validation loss: 2.001458091120566

Epoch: 5| Step: 3
Training loss: 2.165727376937866
Validation loss: 2.0540221660367903

Epoch: 5| Step: 4
Training loss: 1.387844204902649
Validation loss: 2.02262774462341

Epoch: 5| Step: 5
Training loss: 1.3904502391815186
Validation loss: 2.0053026060904227

Epoch: 5| Step: 6
Training loss: 2.022712230682373
Validation loss: 2.015699895479346

Epoch: 5| Step: 7
Training loss: 2.1002533435821533
Validation loss: 2.0114863021399385

Epoch: 5| Step: 8
Training loss: 1.1127243041992188
Validation loss: 2.013128517776407

Epoch: 5| Step: 9
Training loss: 1.787168264389038
Validation loss: 2.0453517616436048

Epoch: 5| Step: 10
Training loss: 1.7424670457839966
Validation loss: 2.0204395863317672

Epoch: 298| Step: 0
Training loss: 1.5497766733169556
Validation loss: 2.034079986233865

Epoch: 5| Step: 1
Training loss: 1.8948320150375366
Validation loss: 2.0539913023671796

Epoch: 5| Step: 2
Training loss: 1.8545869588851929
Validation loss: 2.0528152245347218

Epoch: 5| Step: 3
Training loss: 1.2842490673065186
Validation loss: 2.1061197314211118

Epoch: 5| Step: 4
Training loss: 0.9748716354370117
Validation loss: 2.0727965293392057

Epoch: 5| Step: 5
Training loss: 2.055232048034668
Validation loss: 2.0709242564375683

Epoch: 5| Step: 6
Training loss: 1.95760977268219
Validation loss: 2.087019387111869

Epoch: 5| Step: 7
Training loss: 1.915342092514038
Validation loss: 2.0870904999394573

Epoch: 5| Step: 8
Training loss: 1.8460546731948853
Validation loss: 2.0330478042684574

Epoch: 5| Step: 9
Training loss: 1.5374047756195068
Validation loss: 2.0965886192937053

Epoch: 5| Step: 10
Training loss: 2.1226422786712646
Validation loss: 2.0444529992277904

Epoch: 299| Step: 0
Training loss: 1.5691120624542236
Validation loss: 2.071333336573775

Epoch: 5| Step: 1
Training loss: 1.8000438213348389
Validation loss: 2.0485512671932096

Epoch: 5| Step: 2
Training loss: 1.9152225255966187
Validation loss: 2.0043936211575746

Epoch: 5| Step: 3
Training loss: 1.623030424118042
Validation loss: 2.045775144330917

Epoch: 5| Step: 4
Training loss: 1.566835641860962
Validation loss: 2.03100727065917

Epoch: 5| Step: 5
Training loss: 1.45402193069458
Validation loss: 2.040147235316615

Epoch: 5| Step: 6
Training loss: 1.6259979009628296
Validation loss: 2.033121972955683

Epoch: 5| Step: 7
Training loss: 2.0720722675323486
Validation loss: 2.0390853599835466

Epoch: 5| Step: 8
Training loss: 1.6533825397491455
Validation loss: 2.0256343195515294

Epoch: 5| Step: 9
Training loss: 1.5524985790252686
Validation loss: 2.0283506711324057

Epoch: 5| Step: 10
Training loss: 1.9704538583755493
Validation loss: 2.0470087464137743

Epoch: 300| Step: 0
Training loss: 1.7520068883895874
Validation loss: 2.0392757897735923

Epoch: 5| Step: 1
Training loss: 1.1563633680343628
Validation loss: 2.0128501410125406

Epoch: 5| Step: 2
Training loss: 1.4446070194244385
Validation loss: 2.033282938823905

Epoch: 5| Step: 3
Training loss: 1.7850230932235718
Validation loss: 2.029811482275686

Epoch: 5| Step: 4
Training loss: 1.9217042922973633
Validation loss: 1.9990063226351173

Epoch: 5| Step: 5
Training loss: 1.3398348093032837
Validation loss: 2.0057964427496797

Epoch: 5| Step: 6
Training loss: 2.133936882019043
Validation loss: 2.021709124247233

Epoch: 5| Step: 7
Training loss: 2.009894609451294
Validation loss: 2.0184585791762157

Epoch: 5| Step: 8
Training loss: 1.5359392166137695
Validation loss: 2.0344362387093167

Epoch: 5| Step: 9
Training loss: 1.8600330352783203
Validation loss: 2.015002924908874

Epoch: 5| Step: 10
Training loss: 1.506141185760498
Validation loss: 2.0145072116646716

Epoch: 301| Step: 0
Training loss: 1.2811399698257446
Validation loss: 2.0360359504658687

Epoch: 5| Step: 1
Training loss: 2.106391191482544
Validation loss: 2.067491228862475

Epoch: 5| Step: 2
Training loss: 2.1263129711151123
Validation loss: 2.107314678930467

Epoch: 5| Step: 3
Training loss: 1.6578468084335327
Validation loss: 2.0742777624437885

Epoch: 5| Step: 4
Training loss: 2.2481837272644043
Validation loss: 2.130825506743564

Epoch: 5| Step: 5
Training loss: 2.06825590133667
Validation loss: 2.0488475548323763

Epoch: 5| Step: 6
Training loss: 0.9731402397155762
Validation loss: 2.0973232843542613

Epoch: 5| Step: 7
Training loss: 1.6274147033691406
Validation loss: 2.0606161086790022

Epoch: 5| Step: 8
Training loss: 1.7347644567489624
Validation loss: 2.063266695186656

Epoch: 5| Step: 9
Training loss: 1.3931025266647339
Validation loss: 2.0681805405565488

Epoch: 5| Step: 10
Training loss: 1.591888427734375
Validation loss: 2.0334110618919454

Epoch: 302| Step: 0
Training loss: 1.8280541896820068
Validation loss: 2.0514165265585786

Epoch: 5| Step: 1
Training loss: 1.8451011180877686
Validation loss: 2.0301925290015435

Epoch: 5| Step: 2
Training loss: 1.4095741510391235
Validation loss: 2.040331873842465

Epoch: 5| Step: 3
Training loss: 1.965663194656372
Validation loss: 2.042088108678018

Epoch: 5| Step: 4
Training loss: 1.4184476137161255
Validation loss: 2.017684298176919

Epoch: 5| Step: 5
Training loss: 1.7044646739959717
Validation loss: 2.0559667425770916

Epoch: 5| Step: 6
Training loss: 1.5078985691070557
Validation loss: 2.0495517305148545

Epoch: 5| Step: 7
Training loss: 1.5501996278762817
Validation loss: 2.0321292761833436

Epoch: 5| Step: 8
Training loss: 2.0158400535583496
Validation loss: 2.0410483062908216

Epoch: 5| Step: 9
Training loss: 1.6659069061279297
Validation loss: 2.054186923529512

Epoch: 5| Step: 10
Training loss: 1.7286911010742188
Validation loss: 2.0622367435886013

Epoch: 303| Step: 0
Training loss: 1.491827368736267
Validation loss: 2.051700794568626

Epoch: 5| Step: 1
Training loss: 1.309718132019043
Validation loss: 2.044543412423903

Epoch: 5| Step: 2
Training loss: 1.6158349514007568
Validation loss: 2.039505430447158

Epoch: 5| Step: 3
Training loss: 1.7931983470916748
Validation loss: 2.045492858015081

Epoch: 5| Step: 4
Training loss: 1.7207320928573608
Validation loss: 2.050147223216231

Epoch: 5| Step: 5
Training loss: 1.710701584815979
Validation loss: 2.036601722881358

Epoch: 5| Step: 6
Training loss: 2.2801754474639893
Validation loss: 2.0597523386760423

Epoch: 5| Step: 7
Training loss: 1.5139316320419312
Validation loss: 2.0446374929079445

Epoch: 5| Step: 8
Training loss: 1.555118203163147
Validation loss: 2.0743566751480103

Epoch: 5| Step: 9
Training loss: 2.3234245777130127
Validation loss: 2.0691129494738836

Epoch: 5| Step: 10
Training loss: 1.513019323348999
Validation loss: 2.0731851439322195

Epoch: 304| Step: 0
Training loss: 2.1383790969848633
Validation loss: 2.0570509177382275

Epoch: 5| Step: 1
Training loss: 1.6480121612548828
Validation loss: 2.042259206054031

Epoch: 5| Step: 2
Training loss: 1.5236225128173828
Validation loss: 2.0407151996448474

Epoch: 5| Step: 3
Training loss: 1.5668513774871826
Validation loss: 2.0742460361091037

Epoch: 5| Step: 4
Training loss: 1.6302671432495117
Validation loss: 2.0663397491619153

Epoch: 5| Step: 5
Training loss: 1.060373306274414
Validation loss: 2.0377382898843415

Epoch: 5| Step: 6
Training loss: 1.7054942846298218
Validation loss: 2.0659202247537594

Epoch: 5| Step: 7
Training loss: 1.8131183385849
Validation loss: 2.0616212493629864

Epoch: 5| Step: 8
Training loss: 1.978003740310669
Validation loss: 2.0482551718270905

Epoch: 5| Step: 9
Training loss: 1.4780155420303345
Validation loss: 2.052094680006786

Epoch: 5| Step: 10
Training loss: 2.310481548309326
Validation loss: 2.045152591120812

Epoch: 305| Step: 0
Training loss: 1.5022048950195312
Validation loss: 2.0655696315150105

Epoch: 5| Step: 1
Training loss: 1.622928261756897
Validation loss: 2.047811008268787

Epoch: 5| Step: 2
Training loss: 1.9347158670425415
Validation loss: 2.0779405255471506

Epoch: 5| Step: 3
Training loss: 1.826112985610962
Validation loss: 2.0677401070953696

Epoch: 5| Step: 4
Training loss: 1.5559805631637573
Validation loss: 2.0177745934455626

Epoch: 5| Step: 5
Training loss: 1.664767861366272
Validation loss: 2.079854048708434

Epoch: 5| Step: 6
Training loss: 2.5304818153381348
Validation loss: 2.062677588514102

Epoch: 5| Step: 7
Training loss: 1.468004584312439
Validation loss: 2.0874648940178657

Epoch: 5| Step: 8
Training loss: 1.7417733669281006
Validation loss: 2.0630522671566216

Epoch: 5| Step: 9
Training loss: 1.7351322174072266
Validation loss: 2.023089470401887

Epoch: 5| Step: 10
Training loss: 1.0671781301498413
Validation loss: 2.049447810778054

Epoch: 306| Step: 0
Training loss: 2.079624891281128
Validation loss: 2.0852449337641397

Epoch: 5| Step: 1
Training loss: 1.8245270252227783
Validation loss: 2.0715721653353785

Epoch: 5| Step: 2
Training loss: 1.343601942062378
Validation loss: 2.048113989573653

Epoch: 5| Step: 3
Training loss: 1.8419463634490967
Validation loss: 2.0436852324393486

Epoch: 5| Step: 4
Training loss: 1.532564401626587
Validation loss: 2.0531141142691336

Epoch: 5| Step: 5
Training loss: 1.3656883239746094
Validation loss: 2.0400511551928777

Epoch: 5| Step: 6
Training loss: 1.2376512289047241
Validation loss: 2.051321057863133

Epoch: 5| Step: 7
Training loss: 1.7122936248779297
Validation loss: 2.0305286774071316

Epoch: 5| Step: 8
Training loss: 1.9160560369491577
Validation loss: 2.058532238006592

Epoch: 5| Step: 9
Training loss: 1.9764076471328735
Validation loss: 2.0345705170785227

Epoch: 5| Step: 10
Training loss: 1.6706308126449585
Validation loss: 2.052638933222781

Epoch: 307| Step: 0
Training loss: 1.6329816579818726
Validation loss: 2.0673292900926326

Epoch: 5| Step: 1
Training loss: 2.0021698474884033
Validation loss: 2.041065841592768

Epoch: 5| Step: 2
Training loss: 2.2155375480651855
Validation loss: 2.0289659115575973

Epoch: 5| Step: 3
Training loss: 1.4440991878509521
Validation loss: 2.032090663909912

Epoch: 5| Step: 4
Training loss: 1.2095277309417725
Validation loss: 2.0089774067683885

Epoch: 5| Step: 5
Training loss: 1.6751024723052979
Validation loss: 2.0340398819215837

Epoch: 5| Step: 6
Training loss: 2.441915512084961
Validation loss: 2.0137850148703462

Epoch: 5| Step: 7
Training loss: 1.1486670970916748
Validation loss: 2.024162059189171

Epoch: 5| Step: 8
Training loss: 1.5053927898406982
Validation loss: 2.0441221037218646

Epoch: 5| Step: 9
Training loss: 1.8089975118637085
Validation loss: 2.0533521585567023

Epoch: 5| Step: 10
Training loss: 1.5395938158035278
Validation loss: 2.0512221808074624

Epoch: 308| Step: 0
Training loss: 1.6720478534698486
Validation loss: 2.08236752786944

Epoch: 5| Step: 1
Training loss: 1.015175223350525
Validation loss: 2.0510799730977705

Epoch: 5| Step: 2
Training loss: 2.1369149684906006
Validation loss: 2.071698991201257

Epoch: 5| Step: 3
Training loss: 1.2338292598724365
Validation loss: 2.0828613594014156

Epoch: 5| Step: 4
Training loss: 1.987500548362732
Validation loss: 2.091783341541085

Epoch: 5| Step: 5
Training loss: 2.197265386581421
Validation loss: 2.0579246577396186

Epoch: 5| Step: 6
Training loss: 1.7011127471923828
Validation loss: 2.0564743280410767

Epoch: 5| Step: 7
Training loss: 1.7778308391571045
Validation loss: 2.055471824061486

Epoch: 5| Step: 8
Training loss: 1.7001619338989258
Validation loss: 2.0570897543302147

Epoch: 5| Step: 9
Training loss: 1.8315646648406982
Validation loss: 2.0952753469508183

Epoch: 5| Step: 10
Training loss: 1.394932746887207
Validation loss: 2.100161105073908

Epoch: 309| Step: 0
Training loss: 1.774916648864746
Validation loss: 2.060864148601409

Epoch: 5| Step: 1
Training loss: 1.2264467477798462
Validation loss: 2.03991537965754

Epoch: 5| Step: 2
Training loss: 1.8082656860351562
Validation loss: 2.034530883194298

Epoch: 5| Step: 3
Training loss: 1.9254286289215088
Validation loss: 2.0257721190811484

Epoch: 5| Step: 4
Training loss: 1.4027050733566284
Validation loss: 2.017685305687689

Epoch: 5| Step: 5
Training loss: 2.258845806121826
Validation loss: 2.0598111357740176

Epoch: 5| Step: 6
Training loss: 1.6154855489730835
Validation loss: 1.9992403086795603

Epoch: 5| Step: 7
Training loss: 1.3343942165374756
Validation loss: 2.0348859307586507

Epoch: 5| Step: 8
Training loss: 1.4136842489242554
Validation loss: 1.999945504691011

Epoch: 5| Step: 9
Training loss: 1.8870071172714233
Validation loss: 2.006507169815802

Epoch: 5| Step: 10
Training loss: 1.9459396600723267
Validation loss: 2.004443942859609

Epoch: 310| Step: 0
Training loss: 2.080845594406128
Validation loss: 2.046826772792365

Epoch: 5| Step: 1
Training loss: 1.5439999103546143
Validation loss: 2.044246191619545

Epoch: 5| Step: 2
Training loss: 2.017606496810913
Validation loss: 2.0585347093561643

Epoch: 5| Step: 3
Training loss: 1.9330335855484009
Validation loss: 2.0369713806336924

Epoch: 5| Step: 4
Training loss: 2.018174886703491
Validation loss: 2.07479759698273

Epoch: 5| Step: 5
Training loss: 1.6361141204833984
Validation loss: 2.0467913202060166

Epoch: 5| Step: 6
Training loss: 1.9573183059692383
Validation loss: 2.081234719163628

Epoch: 5| Step: 7
Training loss: 1.4741742610931396
Validation loss: 2.070632973024922

Epoch: 5| Step: 8
Training loss: 0.9783096313476562
Validation loss: 2.078044576029624

Epoch: 5| Step: 9
Training loss: 1.5818288326263428
Validation loss: 2.0546852824508504

Epoch: 5| Step: 10
Training loss: 1.2938547134399414
Validation loss: 2.06321987541773

Epoch: 311| Step: 0
Training loss: 1.719873070716858
Validation loss: 2.062451454900926

Epoch: 5| Step: 1
Training loss: 2.0524380207061768
Validation loss: 2.0463481744130454

Epoch: 5| Step: 2
Training loss: 1.5817577838897705
Validation loss: 2.0577516171240036

Epoch: 5| Step: 3
Training loss: 1.1856467723846436
Validation loss: 2.0387861523576962

Epoch: 5| Step: 4
Training loss: 1.390249252319336
Validation loss: 1.9908368792585147

Epoch: 5| Step: 5
Training loss: 1.8417457342147827
Validation loss: 2.050560356468283

Epoch: 5| Step: 6
Training loss: 1.356809377670288
Validation loss: 2.0452970638070056

Epoch: 5| Step: 7
Training loss: 1.6232322454452515
Validation loss: 2.0436123173723937

Epoch: 5| Step: 8
Training loss: 1.7937666177749634
Validation loss: 2.009166185573865

Epoch: 5| Step: 9
Training loss: 2.243481159210205
Validation loss: 2.025443741070327

Epoch: 5| Step: 10
Training loss: 1.8085668087005615
Validation loss: 2.0479793317856325

Epoch: 312| Step: 0
Training loss: 2.215635061264038
Validation loss: 2.067904382623652

Epoch: 5| Step: 1
Training loss: 1.7482719421386719
Validation loss: 1.990712042777769

Epoch: 5| Step: 2
Training loss: 2.1931025981903076
Validation loss: 2.034516989543874

Epoch: 5| Step: 3
Training loss: 1.5132248401641846
Validation loss: 2.027719202861991

Epoch: 5| Step: 4
Training loss: 1.5725892782211304
Validation loss: 2.0106198531325146

Epoch: 5| Step: 5
Training loss: 1.4138898849487305
Validation loss: 2.019020608676377

Epoch: 5| Step: 6
Training loss: 2.0271215438842773
Validation loss: 2.0471318832007785

Epoch: 5| Step: 7
Training loss: 1.269436240196228
Validation loss: 2.0684106567854523

Epoch: 5| Step: 8
Training loss: 1.4369868040084839
Validation loss: 2.000448775547807

Epoch: 5| Step: 9
Training loss: 1.8049730062484741
Validation loss: 2.077231898102709

Epoch: 5| Step: 10
Training loss: 1.0344783067703247
Validation loss: 2.089133726653232

Epoch: 313| Step: 0
Training loss: 1.4993531703948975
Validation loss: 2.033280849456787

Epoch: 5| Step: 1
Training loss: 2.1692512035369873
Validation loss: 2.0947611331939697

Epoch: 5| Step: 2
Training loss: 1.6382808685302734
Validation loss: 2.0769483671393445

Epoch: 5| Step: 3
Training loss: 1.5585861206054688
Validation loss: 2.0563885114526235

Epoch: 5| Step: 4
Training loss: 1.665374517440796
Validation loss: 2.0581461024540726

Epoch: 5| Step: 5
Training loss: 1.8600002527236938
Validation loss: 2.055788469570939

Epoch: 5| Step: 6
Training loss: 1.7052360773086548
Validation loss: 2.080219381599016

Epoch: 5| Step: 7
Training loss: 1.492849588394165
Validation loss: 2.0434503811661915

Epoch: 5| Step: 8
Training loss: 1.3479888439178467
Validation loss: 2.068656430449537

Epoch: 5| Step: 9
Training loss: 1.6522343158721924
Validation loss: 2.051482782568983

Epoch: 5| Step: 10
Training loss: 1.7368650436401367
Validation loss: 2.0348341618814776

Epoch: 314| Step: 0
Training loss: 1.9589141607284546
Validation loss: 2.0458131785033853

Epoch: 5| Step: 1
Training loss: 1.541231393814087
Validation loss: 2.035126583550566

Epoch: 5| Step: 2
Training loss: 2.1179726123809814
Validation loss: 2.0365152051371913

Epoch: 5| Step: 3
Training loss: 1.8086696863174438
Validation loss: 2.0300069227013537

Epoch: 5| Step: 4
Training loss: 1.4032118320465088
Validation loss: 2.049916082812894

Epoch: 5| Step: 5
Training loss: 1.624720811843872
Validation loss: 2.0725448798107844

Epoch: 5| Step: 6
Training loss: 1.9764347076416016
Validation loss: 2.0404915348176034

Epoch: 5| Step: 7
Training loss: 1.2448691129684448
Validation loss: 2.054300541518837

Epoch: 5| Step: 8
Training loss: 1.567670226097107
Validation loss: 2.029939123379287

Epoch: 5| Step: 9
Training loss: 1.7742935419082642
Validation loss: 2.024108135572044

Epoch: 5| Step: 10
Training loss: 1.6350919008255005
Validation loss: 2.015214107369864

Epoch: 315| Step: 0
Training loss: 1.6946386098861694
Validation loss: 2.0444912141369236

Epoch: 5| Step: 1
Training loss: 1.5409897565841675
Validation loss: 2.058965354837397

Epoch: 5| Step: 2
Training loss: 2.0573344230651855
Validation loss: 2.0698168880196026

Epoch: 5| Step: 3
Training loss: 1.6125131845474243
Validation loss: 2.0628130359034382

Epoch: 5| Step: 4
Training loss: 2.243804931640625
Validation loss: 2.027747093990285

Epoch: 5| Step: 5
Training loss: 1.470416784286499
Validation loss: 2.031056152876987

Epoch: 5| Step: 6
Training loss: 1.9883060455322266
Validation loss: 2.0449662041920487

Epoch: 5| Step: 7
Training loss: 1.7721188068389893
Validation loss: 2.0607357255874144

Epoch: 5| Step: 8
Training loss: 1.5821168422698975
Validation loss: 2.0604323879365

Epoch: 5| Step: 9
Training loss: 1.4638214111328125
Validation loss: 2.098145341360441

Epoch: 5| Step: 10
Training loss: 0.9256421327590942
Validation loss: 2.0537489832088514

Epoch: 316| Step: 0
Training loss: 1.466246485710144
Validation loss: 2.046939129470497

Epoch: 5| Step: 1
Training loss: 1.5530284643173218
Validation loss: 2.0461929844271753

Epoch: 5| Step: 2
Training loss: 1.9120614528656006
Validation loss: 2.042293581911313

Epoch: 5| Step: 3
Training loss: 1.4458974599838257
Validation loss: 2.0181653473966863

Epoch: 5| Step: 4
Training loss: 1.7911840677261353
Validation loss: 2.0223457313353017

Epoch: 5| Step: 5
Training loss: 1.6900848150253296
Validation loss: 2.006639657482024

Epoch: 5| Step: 6
Training loss: 1.9292939901351929
Validation loss: 2.016670952561081

Epoch: 5| Step: 7
Training loss: 2.001101016998291
Validation loss: 2.025808166432124

Epoch: 5| Step: 8
Training loss: 1.649670958518982
Validation loss: 2.029732649044324

Epoch: 5| Step: 9
Training loss: 1.4515008926391602
Validation loss: 2.037064383106847

Epoch: 5| Step: 10
Training loss: 1.4955462217330933
Validation loss: 2.056632714886819

Epoch: 317| Step: 0
Training loss: 1.5919164419174194
Validation loss: 2.0557901731101413

Epoch: 5| Step: 1
Training loss: 1.7434637546539307
Validation loss: 2.053946231001167

Epoch: 5| Step: 2
Training loss: 1.4800517559051514
Validation loss: 2.0581635557195193

Epoch: 5| Step: 3
Training loss: 1.1550248861312866
Validation loss: 2.067886943458229

Epoch: 5| Step: 4
Training loss: 1.9484084844589233
Validation loss: 2.082361493059384

Epoch: 5| Step: 5
Training loss: 1.6931051015853882
Validation loss: 2.0717301496895413

Epoch: 5| Step: 6
Training loss: 2.1027865409851074
Validation loss: 2.0916878484910533

Epoch: 5| Step: 7
Training loss: 1.872074842453003
Validation loss: 2.0649418318143455

Epoch: 5| Step: 8
Training loss: 1.9756696224212646
Validation loss: 2.0905274216846754

Epoch: 5| Step: 9
Training loss: 1.42118501663208
Validation loss: 2.05376584042785

Epoch: 5| Step: 10
Training loss: 1.319769263267517
Validation loss: 2.0575074393262147

Epoch: 318| Step: 0
Training loss: 1.637367606163025
Validation loss: 2.0347517254532024

Epoch: 5| Step: 1
Training loss: 1.2778750658035278
Validation loss: 2.080672656336138

Epoch: 5| Step: 2
Training loss: 1.6649150848388672
Validation loss: 2.031066753531015

Epoch: 5| Step: 3
Training loss: 1.5205950736999512
Validation loss: 2.006270052284323

Epoch: 5| Step: 4
Training loss: 1.4830116033554077
Validation loss: 2.0161934847472818

Epoch: 5| Step: 5
Training loss: 1.033968210220337
Validation loss: 2.0314431331490956

Epoch: 5| Step: 6
Training loss: 2.343000888824463
Validation loss: 2.0101754857647802

Epoch: 5| Step: 7
Training loss: 2.045551300048828
Validation loss: 2.022422061171583

Epoch: 5| Step: 8
Training loss: 1.4993377923965454
Validation loss: 2.0589699206813687

Epoch: 5| Step: 9
Training loss: 1.9774820804595947
Validation loss: 2.0309748662415372

Epoch: 5| Step: 10
Training loss: 2.1558475494384766
Validation loss: 2.021640964733657

Epoch: 319| Step: 0
Training loss: 1.518524408340454
Validation loss: 2.0524965819492134

Epoch: 5| Step: 1
Training loss: 1.6821600198745728
Validation loss: 2.014937940464225

Epoch: 5| Step: 2
Training loss: 1.58548903465271
Validation loss: 2.080714343696512

Epoch: 5| Step: 3
Training loss: 1.3492473363876343
Validation loss: 2.039734730156519

Epoch: 5| Step: 4
Training loss: 1.6642487049102783
Validation loss: 2.054340242057718

Epoch: 5| Step: 5
Training loss: 1.438704252243042
Validation loss: 2.05408380364859

Epoch: 5| Step: 6
Training loss: 1.9930617809295654
Validation loss: 2.038415233294169

Epoch: 5| Step: 7
Training loss: 2.2198333740234375
Validation loss: 2.0609518122929398

Epoch: 5| Step: 8
Training loss: 1.3986632823944092
Validation loss: 2.0756515277329313

Epoch: 5| Step: 9
Training loss: 1.9491914510726929
Validation loss: 2.02450123909981

Epoch: 5| Step: 10
Training loss: 1.478947401046753
Validation loss: 2.037692650671928

Epoch: 320| Step: 0
Training loss: 1.4679592847824097
Validation loss: 2.0751957303734234

Epoch: 5| Step: 1
Training loss: 1.35042405128479
Validation loss: 2.0290227026067753

Epoch: 5| Step: 2
Training loss: 1.5736920833587646
Validation loss: 2.0786767557103145

Epoch: 5| Step: 3
Training loss: 1.8035774230957031
Validation loss: 2.0371195705988074

Epoch: 5| Step: 4
Training loss: 2.319272041320801
Validation loss: 2.0665844114877845

Epoch: 5| Step: 5
Training loss: 1.7882471084594727
Validation loss: 2.0415982277162614

Epoch: 5| Step: 6
Training loss: 1.9762051105499268
Validation loss: 2.072675944656454

Epoch: 5| Step: 7
Training loss: 1.7901893854141235
Validation loss: 2.0528555031745666

Epoch: 5| Step: 8
Training loss: 1.5975459814071655
Validation loss: 2.0582269981343257

Epoch: 5| Step: 9
Training loss: 1.2196111679077148
Validation loss: 2.0156301375358336

Epoch: 5| Step: 10
Training loss: 1.5529747009277344
Validation loss: 2.0397967036052416

Epoch: 321| Step: 0
Training loss: 0.9735156893730164
Validation loss: 2.016451370331549

Epoch: 5| Step: 1
Training loss: 1.8647511005401611
Validation loss: 2.0425768590742543

Epoch: 5| Step: 2
Training loss: 1.3610268831253052
Validation loss: 2.044046401977539

Epoch: 5| Step: 3
Training loss: 1.845542311668396
Validation loss: 2.081777262431319

Epoch: 5| Step: 4
Training loss: 2.0003089904785156
Validation loss: 2.042195922584944

Epoch: 5| Step: 5
Training loss: 2.333923816680908
Validation loss: 2.0602316600020214

Epoch: 5| Step: 6
Training loss: 1.5458530187606812
Validation loss: 2.0523998122061453

Epoch: 5| Step: 7
Training loss: 1.8630971908569336
Validation loss: 2.079607222669868

Epoch: 5| Step: 8
Training loss: 1.8922102451324463
Validation loss: 2.083325498847551

Epoch: 5| Step: 9
Training loss: 1.177086591720581
Validation loss: 2.0735808444279495

Epoch: 5| Step: 10
Training loss: 1.388784646987915
Validation loss: 2.0658213348798853

Epoch: 322| Step: 0
Training loss: 1.673447847366333
Validation loss: 2.0402179071980138

Epoch: 5| Step: 1
Training loss: 1.5225870609283447
Validation loss: 2.0452836790392475

Epoch: 5| Step: 2
Training loss: 1.5757181644439697
Validation loss: 2.0560173937069472

Epoch: 5| Step: 3
Training loss: 1.4264028072357178
Validation loss: 2.044928991666404

Epoch: 5| Step: 4
Training loss: 1.5992664098739624
Validation loss: 2.021818850630073

Epoch: 5| Step: 5
Training loss: 1.2339141368865967
Validation loss: 2.0538843677889917

Epoch: 5| Step: 6
Training loss: 1.734702706336975
Validation loss: 2.0635912341456257

Epoch: 5| Step: 7
Training loss: 1.451220989227295
Validation loss: 2.0596728760709047

Epoch: 5| Step: 8
Training loss: 2.0816264152526855
Validation loss: 2.0430922533876155

Epoch: 5| Step: 9
Training loss: 2.4266042709350586
Validation loss: 2.0188635959420154

Epoch: 5| Step: 10
Training loss: 1.6761962175369263
Validation loss: 2.022315421412068

Epoch: 323| Step: 0
Training loss: 1.2735850811004639
Validation loss: 2.0337200985159924

Epoch: 5| Step: 1
Training loss: 2.0264382362365723
Validation loss: 2.038435561682588

Epoch: 5| Step: 2
Training loss: 1.8910043239593506
Validation loss: 2.042701223845123

Epoch: 5| Step: 3
Training loss: 1.3849194049835205
Validation loss: 2.0529641412919566

Epoch: 5| Step: 4
Training loss: 1.7686748504638672
Validation loss: 2.0680700681542836

Epoch: 5| Step: 5
Training loss: 2.054234504699707
Validation loss: 2.0928317154607465

Epoch: 5| Step: 6
Training loss: 1.585548758506775
Validation loss: 2.0610711702736477

Epoch: 5| Step: 7
Training loss: 1.1155049800872803
Validation loss: 2.0224699961241854

Epoch: 5| Step: 8
Training loss: 1.4868115186691284
Validation loss: 2.0969220181947112

Epoch: 5| Step: 9
Training loss: 1.915848970413208
Validation loss: 2.070335218983312

Epoch: 5| Step: 10
Training loss: 1.9798787832260132
Validation loss: 2.070669745886198

Epoch: 324| Step: 0
Training loss: 1.2284029722213745
Validation loss: 2.0823821098573747

Epoch: 5| Step: 1
Training loss: 1.7649948596954346
Validation loss: 2.0841202197536344

Epoch: 5| Step: 2
Training loss: 1.8242685794830322
Validation loss: 2.047125647144933

Epoch: 5| Step: 3
Training loss: 2.20076322555542
Validation loss: 2.0604573219053206

Epoch: 5| Step: 4
Training loss: 1.4566638469696045
Validation loss: 2.0566752905486734

Epoch: 5| Step: 5
Training loss: 1.5863924026489258
Validation loss: 2.027779377916808

Epoch: 5| Step: 6
Training loss: 1.5584322214126587
Validation loss: 2.064049918164489

Epoch: 5| Step: 7
Training loss: 1.6989666223526
Validation loss: 2.040036937241913

Epoch: 5| Step: 8
Training loss: 1.7359756231307983
Validation loss: 2.0195101384193666

Epoch: 5| Step: 9
Training loss: 1.5242046117782593
Validation loss: 2.0432121317873717

Epoch: 5| Step: 10
Training loss: 1.745477318763733
Validation loss: 2.0317701498667398

Epoch: 325| Step: 0
Training loss: 1.7078559398651123
Validation loss: 2.0160440962801696

Epoch: 5| Step: 1
Training loss: 1.520263910293579
Validation loss: 2.03866760705107

Epoch: 5| Step: 2
Training loss: 2.0763416290283203
Validation loss: 2.057140488778391

Epoch: 5| Step: 3
Training loss: 2.151731014251709
Validation loss: 2.0293637885842273

Epoch: 5| Step: 4
Training loss: 1.1830252408981323
Validation loss: 2.0528821188916444

Epoch: 5| Step: 5
Training loss: 2.1402242183685303
Validation loss: 2.053546456880467

Epoch: 5| Step: 6
Training loss: 1.4777767658233643
Validation loss: 2.049690559346189

Epoch: 5| Step: 7
Training loss: 1.7306067943572998
Validation loss: 2.0724729286727084

Epoch: 5| Step: 8
Training loss: 1.3459713459014893
Validation loss: 2.0997504726532967

Epoch: 5| Step: 9
Training loss: 1.3581808805465698
Validation loss: 2.077239872306906

Epoch: 5| Step: 10
Training loss: 1.387190818786621
Validation loss: 2.050826705912108

Epoch: 326| Step: 0
Training loss: 1.3724225759506226
Validation loss: 2.0576830628097698

Epoch: 5| Step: 1
Training loss: 1.7559856176376343
Validation loss: 2.0343673331763155

Epoch: 5| Step: 2
Training loss: 2.4442296028137207
Validation loss: 2.0823865962284867

Epoch: 5| Step: 3
Training loss: 1.8060510158538818
Validation loss: 2.051477027195756

Epoch: 5| Step: 4
Training loss: 1.4862703084945679
Validation loss: 2.0204724522047144

Epoch: 5| Step: 5
Training loss: 1.377826452255249
Validation loss: 2.06848697123989

Epoch: 5| Step: 6
Training loss: 2.0719826221466064
Validation loss: 2.063781325535108

Epoch: 5| Step: 7
Training loss: 1.3866404294967651
Validation loss: 2.0509029537118892

Epoch: 5| Step: 8
Training loss: 1.3460553884506226
Validation loss: 2.0217739535916235

Epoch: 5| Step: 9
Training loss: 2.0040555000305176
Validation loss: 2.0405458327262633

Epoch: 5| Step: 10
Training loss: 1.2009531259536743
Validation loss: 2.010977422037432

Epoch: 327| Step: 0
Training loss: 1.744060754776001
Validation loss: 2.0155094977348083

Epoch: 5| Step: 1
Training loss: 1.4695460796356201
Validation loss: 2.0524007940805085

Epoch: 5| Step: 2
Training loss: 1.7300529479980469
Validation loss: 2.016476361982284

Epoch: 5| Step: 3
Training loss: 1.7140588760375977
Validation loss: 2.0744768150391115

Epoch: 5| Step: 4
Training loss: 1.3451398611068726
Validation loss: 2.0508380871947094

Epoch: 5| Step: 5
Training loss: 2.017914295196533
Validation loss: 2.081010182698568

Epoch: 5| Step: 6
Training loss: 1.6261409521102905
Validation loss: 2.080301495008571

Epoch: 5| Step: 7
Training loss: 1.5415350198745728
Validation loss: 2.069562627423194

Epoch: 5| Step: 8
Training loss: 1.521819829940796
Validation loss: 2.0809825312706733

Epoch: 5| Step: 9
Training loss: 1.6928844451904297
Validation loss: 2.056332677923223

Epoch: 5| Step: 10
Training loss: 1.6916487216949463
Validation loss: 2.0413551304929998

Epoch: 328| Step: 0
Training loss: 2.1024372577667236
Validation loss: 2.040223817671499

Epoch: 5| Step: 1
Training loss: 1.0926464796066284
Validation loss: 2.049743495961671

Epoch: 5| Step: 2
Training loss: 1.9658899307250977
Validation loss: 2.059951078507208

Epoch: 5| Step: 3
Training loss: 1.535870909690857
Validation loss: 2.0552841822306314

Epoch: 5| Step: 4
Training loss: 0.8206442594528198
Validation loss: 2.0469373246674896

Epoch: 5| Step: 5
Training loss: 1.6088340282440186
Validation loss: 2.036362805674153

Epoch: 5| Step: 6
Training loss: 1.9704090356826782
Validation loss: 2.0605227255052134

Epoch: 5| Step: 7
Training loss: 1.8309948444366455
Validation loss: 2.049610035393828

Epoch: 5| Step: 8
Training loss: 1.753627061843872
Validation loss: 2.036487256326983

Epoch: 5| Step: 9
Training loss: 1.5958940982818604
Validation loss: 2.060643340951653

Epoch: 5| Step: 10
Training loss: 2.073909044265747
Validation loss: 2.0456058184305825

Epoch: 329| Step: 0
Training loss: 1.7232621908187866
Validation loss: 2.042171116798155

Epoch: 5| Step: 1
Training loss: 1.5229060649871826
Validation loss: 2.0668698151906333

Epoch: 5| Step: 2
Training loss: 1.6495084762573242
Validation loss: 2.030287568287183

Epoch: 5| Step: 3
Training loss: 1.1005382537841797
Validation loss: 2.0284781917448966

Epoch: 5| Step: 4
Training loss: 1.7350149154663086
Validation loss: 2.0248285390997447

Epoch: 5| Step: 5
Training loss: 2.141453266143799
Validation loss: 2.0788092536310994

Epoch: 5| Step: 6
Training loss: 1.4962190389633179
Validation loss: 2.07403701479717

Epoch: 5| Step: 7
Training loss: 1.4738256931304932
Validation loss: 2.0434626238320464

Epoch: 5| Step: 8
Training loss: 2.422203779220581
Validation loss: 2.034617711138982

Epoch: 5| Step: 9
Training loss: 1.5822794437408447
Validation loss: 2.064286134576285

Epoch: 5| Step: 10
Training loss: 1.188231348991394
Validation loss: 2.052477385408135

Epoch: 330| Step: 0
Training loss: 2.438453435897827
Validation loss: 2.0510847055783836

Epoch: 5| Step: 1
Training loss: 1.1471021175384521
Validation loss: 2.0427526684217554

Epoch: 5| Step: 2
Training loss: 1.5459797382354736
Validation loss: 2.0502652237492223

Epoch: 5| Step: 3
Training loss: 1.49735426902771
Validation loss: 2.0592451505763556

Epoch: 5| Step: 4
Training loss: 1.605346918106079
Validation loss: 2.0517080983807965

Epoch: 5| Step: 5
Training loss: 1.6608426570892334
Validation loss: 2.04148405982602

Epoch: 5| Step: 6
Training loss: 1.2667131423950195
Validation loss: 2.0548072002267324

Epoch: 5| Step: 7
Training loss: 1.7162091732025146
Validation loss: 2.078267820419804

Epoch: 5| Step: 8
Training loss: 1.2209367752075195
Validation loss: 2.0534768771099787

Epoch: 5| Step: 9
Training loss: 2.1244430541992188
Validation loss: 2.048801273427984

Epoch: 5| Step: 10
Training loss: 1.8302966356277466
Validation loss: 2.0487829408337994

Epoch: 331| Step: 0
Training loss: 1.6417739391326904
Validation loss: 2.0599260740382697

Epoch: 5| Step: 1
Training loss: 1.1343634128570557
Validation loss: 2.0525160348543556

Epoch: 5| Step: 2
Training loss: 1.812948226928711
Validation loss: 2.0844381752834527

Epoch: 5| Step: 3
Training loss: 1.7932796478271484
Validation loss: 2.051895341565532

Epoch: 5| Step: 4
Training loss: 1.0748157501220703
Validation loss: 2.0520080750988376

Epoch: 5| Step: 5
Training loss: 1.4664568901062012
Validation loss: 2.0630823822431665

Epoch: 5| Step: 6
Training loss: 1.5665273666381836
Validation loss: 2.0347073270428564

Epoch: 5| Step: 7
Training loss: 1.8960472345352173
Validation loss: 2.0470190253309024

Epoch: 5| Step: 8
Training loss: 1.9121030569076538
Validation loss: 2.0006637880879063

Epoch: 5| Step: 9
Training loss: 1.7910741567611694
Validation loss: 2.065943218046619

Epoch: 5| Step: 10
Training loss: 2.0279834270477295
Validation loss: 2.055903060461885

Epoch: 332| Step: 0
Training loss: 1.0691652297973633
Validation loss: 2.039178597029819

Epoch: 5| Step: 1
Training loss: 1.2309653759002686
Validation loss: 2.0336325565973916

Epoch: 5| Step: 2
Training loss: 1.5533682107925415
Validation loss: 2.0517904476452897

Epoch: 5| Step: 3
Training loss: 1.619102120399475
Validation loss: 2.053400465237197

Epoch: 5| Step: 4
Training loss: 2.1797356605529785
Validation loss: 2.0465866570831626

Epoch: 5| Step: 5
Training loss: 2.117894411087036
Validation loss: 2.043702064021941

Epoch: 5| Step: 6
Training loss: 1.1890079975128174
Validation loss: 2.042572666239995

Epoch: 5| Step: 7
Training loss: 1.6149206161499023
Validation loss: 2.046033159379036

Epoch: 5| Step: 8
Training loss: 2.1137592792510986
Validation loss: 2.033844450468658

Epoch: 5| Step: 9
Training loss: 1.5685175657272339
Validation loss: 2.0498871341828377

Epoch: 5| Step: 10
Training loss: 1.8259756565093994
Validation loss: 2.049720351414014

Epoch: 333| Step: 0
Training loss: 1.8667484521865845
Validation loss: 2.028881993345035

Epoch: 5| Step: 1
Training loss: 1.4031217098236084
Validation loss: 2.0564427965430805

Epoch: 5| Step: 2
Training loss: 1.7419334650039673
Validation loss: 2.0748503720888527

Epoch: 5| Step: 3
Training loss: 1.3400810956954956
Validation loss: 2.0843349195295766

Epoch: 5| Step: 4
Training loss: 1.436060905456543
Validation loss: 2.0555267385257188

Epoch: 5| Step: 5
Training loss: 1.4806071519851685
Validation loss: 2.0611507584971767

Epoch: 5| Step: 6
Training loss: 2.0080513954162598
Validation loss: 2.071582687798367

Epoch: 5| Step: 7
Training loss: 1.6096279621124268
Validation loss: 2.0531491336002143

Epoch: 5| Step: 8
Training loss: 2.0019447803497314
Validation loss: 2.085065018746161

Epoch: 5| Step: 9
Training loss: 1.6627442836761475
Validation loss: 2.043398190570134

Epoch: 5| Step: 10
Training loss: 1.4555389881134033
Validation loss: 2.0545142773658998

Epoch: 334| Step: 0
Training loss: 1.5042908191680908
Validation loss: 2.067106303348336

Epoch: 5| Step: 1
Training loss: 1.2621207237243652
Validation loss: 2.019213104760775

Epoch: 5| Step: 2
Training loss: 2.4234821796417236
Validation loss: 2.0422658343468942

Epoch: 5| Step: 3
Training loss: 1.586067795753479
Validation loss: 2.0634896191217567

Epoch: 5| Step: 4
Training loss: 1.2909793853759766
Validation loss: 2.0123613649798977

Epoch: 5| Step: 5
Training loss: 1.3285765647888184
Validation loss: 2.0646151355517808

Epoch: 5| Step: 6
Training loss: 1.7481590509414673
Validation loss: 2.0229355212180846

Epoch: 5| Step: 7
Training loss: 1.7394866943359375
Validation loss: 2.0285071314022107

Epoch: 5| Step: 8
Training loss: 1.8374614715576172
Validation loss: 2.033986065977363

Epoch: 5| Step: 9
Training loss: 1.696068525314331
Validation loss: 2.031890226948646

Epoch: 5| Step: 10
Training loss: 1.631206750869751
Validation loss: 2.0250318806658507

Epoch: 335| Step: 0
Training loss: 1.398698329925537
Validation loss: 2.0476907145592476

Epoch: 5| Step: 1
Training loss: 1.272686243057251
Validation loss: 2.0632484023289015

Epoch: 5| Step: 2
Training loss: 1.5609863996505737
Validation loss: 2.06963151244707

Epoch: 5| Step: 3
Training loss: 1.8916614055633545
Validation loss: 2.0736328965874127

Epoch: 5| Step: 4
Training loss: 1.2259948253631592
Validation loss: 2.078861632654744

Epoch: 5| Step: 5
Training loss: 1.8573157787322998
Validation loss: 2.0728268469533613

Epoch: 5| Step: 6
Training loss: 1.938929796218872
Validation loss: 2.0926543102469495

Epoch: 5| Step: 7
Training loss: 1.9711815118789673
Validation loss: 2.0808426513466785

Epoch: 5| Step: 8
Training loss: 1.8070951700210571
Validation loss: 2.0708670949423187

Epoch: 5| Step: 9
Training loss: 1.2959492206573486
Validation loss: 2.07936111316886

Epoch: 5| Step: 10
Training loss: 2.0683035850524902
Validation loss: 2.1093039397270448

Epoch: 336| Step: 0
Training loss: 2.2951762676239014
Validation loss: 2.0566577885740545

Epoch: 5| Step: 1
Training loss: 1.4433432817459106
Validation loss: 2.0882557643357145

Epoch: 5| Step: 2
Training loss: 1.5160341262817383
Validation loss: 2.0964389462624826

Epoch: 5| Step: 3
Training loss: 2.093543529510498
Validation loss: 2.046679619819887

Epoch: 5| Step: 4
Training loss: 1.585327386856079
Validation loss: 2.0633988559886975

Epoch: 5| Step: 5
Training loss: 1.1823607683181763
Validation loss: 2.042915495493079

Epoch: 5| Step: 6
Training loss: 2.1112053394317627
Validation loss: 2.052270888000406

Epoch: 5| Step: 7
Training loss: 1.4404098987579346
Validation loss: 2.044183287569272

Epoch: 5| Step: 8
Training loss: 1.4533824920654297
Validation loss: 2.0594892937649965

Epoch: 5| Step: 9
Training loss: 1.0534794330596924
Validation loss: 2.039313785491451

Epoch: 5| Step: 10
Training loss: 1.8165677785873413
Validation loss: 2.0407722662853938

Epoch: 337| Step: 0
Training loss: 1.4381353855133057
Validation loss: 2.031023197276618

Epoch: 5| Step: 1
Training loss: 1.22604501247406
Validation loss: 2.0326623301352225

Epoch: 5| Step: 2
Training loss: 1.8251216411590576
Validation loss: 2.0295736969158216

Epoch: 5| Step: 3
Training loss: 1.787613868713379
Validation loss: 2.0513056221828667

Epoch: 5| Step: 4
Training loss: 2.0043044090270996
Validation loss: 2.0669571507361626

Epoch: 5| Step: 5
Training loss: 1.4267522096633911
Validation loss: 2.031861379582395

Epoch: 5| Step: 6
Training loss: 1.435772180557251
Validation loss: 2.05236344440009

Epoch: 5| Step: 7
Training loss: 1.9130029678344727
Validation loss: 2.0581687035099154

Epoch: 5| Step: 8
Training loss: 1.9031168222427368
Validation loss: 2.0712198570210445

Epoch: 5| Step: 9
Training loss: 1.4291865825653076
Validation loss: 2.068742290619881

Epoch: 5| Step: 10
Training loss: 1.4599997997283936
Validation loss: 2.0470368682697253

Epoch: 338| Step: 0
Training loss: 2.290350914001465
Validation loss: 2.096931508792344

Epoch: 5| Step: 1
Training loss: 1.1424939632415771
Validation loss: 2.0552723907655284

Epoch: 5| Step: 2
Training loss: 1.363422155380249
Validation loss: 2.0492063235211115

Epoch: 5| Step: 3
Training loss: 1.5916264057159424
Validation loss: 2.0615123753906577

Epoch: 5| Step: 4
Training loss: 1.5792862176895142
Validation loss: 2.0260931240615023

Epoch: 5| Step: 5
Training loss: 1.5336880683898926
Validation loss: 2.0682045746875066

Epoch: 5| Step: 6
Training loss: 1.9222431182861328
Validation loss: 2.0375662055066837

Epoch: 5| Step: 7
Training loss: 1.2914364337921143
Validation loss: 2.050180906890541

Epoch: 5| Step: 8
Training loss: 2.43446683883667
Validation loss: 2.039442070068852

Epoch: 5| Step: 9
Training loss: 1.3324434757232666
Validation loss: 2.0180263057831795

Epoch: 5| Step: 10
Training loss: 1.6253339052200317
Validation loss: 2.0420546762404905

Epoch: 339| Step: 0
Training loss: 1.7273788452148438
Validation loss: 2.063783730230024

Epoch: 5| Step: 1
Training loss: 1.7821584939956665
Validation loss: 2.061396357833698

Epoch: 5| Step: 2
Training loss: 2.1048240661621094
Validation loss: 2.032942489911151

Epoch: 5| Step: 3
Training loss: 1.6478900909423828
Validation loss: 2.047762972052379

Epoch: 5| Step: 4
Training loss: 1.07843017578125
Validation loss: 2.0361697622524795

Epoch: 5| Step: 5
Training loss: 2.034843921661377
Validation loss: 2.020568396455498

Epoch: 5| Step: 6
Training loss: 1.3819169998168945
Validation loss: 2.0257235778275358

Epoch: 5| Step: 7
Training loss: 1.7192319631576538
Validation loss: 2.0188486832444386

Epoch: 5| Step: 8
Training loss: 1.3693021535873413
Validation loss: 2.018236073114539

Epoch: 5| Step: 9
Training loss: 1.5898977518081665
Validation loss: 2.016415460135347

Epoch: 5| Step: 10
Training loss: 1.4302668571472168
Validation loss: 2.0368655420118764

Epoch: 340| Step: 0
Training loss: 1.6774215698242188
Validation loss: 2.046640570445727

Epoch: 5| Step: 1
Training loss: 1.9701917171478271
Validation loss: 2.030767927887619

Epoch: 5| Step: 2
Training loss: 1.787245750427246
Validation loss: 2.0119187524241786

Epoch: 5| Step: 3
Training loss: 2.0421314239501953
Validation loss: 2.08628341972187

Epoch: 5| Step: 4
Training loss: 1.359653115272522
Validation loss: 2.0448481395680416

Epoch: 5| Step: 5
Training loss: 1.409131646156311
Validation loss: 2.0229971883117512

Epoch: 5| Step: 6
Training loss: 1.9521019458770752
Validation loss: 2.0431559406301028

Epoch: 5| Step: 7
Training loss: 1.0232113599777222
Validation loss: 2.066585312607468

Epoch: 5| Step: 8
Training loss: 1.7906780242919922
Validation loss: 2.094797871446097

Epoch: 5| Step: 9
Training loss: 1.188312292098999
Validation loss: 2.05037417463077

Epoch: 5| Step: 10
Training loss: 1.6595349311828613
Validation loss: 2.082994835351103

Epoch: 341| Step: 0
Training loss: 1.6600494384765625
Validation loss: 2.047729079441358

Epoch: 5| Step: 1
Training loss: 1.8047831058502197
Validation loss: 2.0847895247961885

Epoch: 5| Step: 2
Training loss: 1.5160356760025024
Validation loss: 2.079665268621137

Epoch: 5| Step: 3
Training loss: 2.034132242202759
Validation loss: 2.0503129984742854

Epoch: 5| Step: 4
Training loss: 1.638612985610962
Validation loss: 2.0634183665757537

Epoch: 5| Step: 5
Training loss: 1.4888604879379272
Validation loss: 2.0388068614467496

Epoch: 5| Step: 6
Training loss: 1.9636600017547607
Validation loss: 2.062147640412854

Epoch: 5| Step: 7
Training loss: 1.0126230716705322
Validation loss: 2.0743746398597636

Epoch: 5| Step: 8
Training loss: 1.4881722927093506
Validation loss: 2.093705966908445

Epoch: 5| Step: 9
Training loss: 1.6707239151000977
Validation loss: 2.0505053727857527

Epoch: 5| Step: 10
Training loss: 1.7455480098724365
Validation loss: 2.027152997191234

Epoch: 342| Step: 0
Training loss: 1.5147342681884766
Validation loss: 2.0728469612777873

Epoch: 5| Step: 1
Training loss: 1.8203758001327515
Validation loss: 2.0991195427474154

Epoch: 5| Step: 2
Training loss: 1.9407262802124023
Validation loss: 2.0853964756893855

Epoch: 5| Step: 3
Training loss: 1.7242920398712158
Validation loss: 2.074829270762782

Epoch: 5| Step: 4
Training loss: 1.1124340295791626
Validation loss: 2.0636080388099916

Epoch: 5| Step: 5
Training loss: 1.6449730396270752
Validation loss: 2.0624219909791024

Epoch: 5| Step: 6
Training loss: 1.6489566564559937
Validation loss: 2.0546296283762944

Epoch: 5| Step: 7
Training loss: 1.8792216777801514
Validation loss: 2.0253308434640207

Epoch: 5| Step: 8
Training loss: 1.4365895986557007
Validation loss: 2.0294147409418577

Epoch: 5| Step: 9
Training loss: 1.2622560262680054
Validation loss: 2.0459241046700427

Epoch: 5| Step: 10
Training loss: 1.9417210817337036
Validation loss: 2.029090642929077

Epoch: 343| Step: 0
Training loss: 1.3816022872924805
Validation loss: 2.051492221893803

Epoch: 5| Step: 1
Training loss: 1.641437292098999
Validation loss: 2.058823739328692

Epoch: 5| Step: 2
Training loss: 1.4259512424468994
Validation loss: 2.0445969720040598

Epoch: 5| Step: 3
Training loss: 1.9472029209136963
Validation loss: 2.040826041211364

Epoch: 5| Step: 4
Training loss: 1.9662151336669922
Validation loss: 2.0642627157190794

Epoch: 5| Step: 5
Training loss: 1.946118950843811
Validation loss: 2.031737321166582

Epoch: 5| Step: 6
Training loss: 1.4659963846206665
Validation loss: 2.065435163436397

Epoch: 5| Step: 7
Training loss: 1.8355443477630615
Validation loss: 2.031092636046871

Epoch: 5| Step: 8
Training loss: 1.029266357421875
Validation loss: 2.025632519875803

Epoch: 5| Step: 9
Training loss: 1.8718944787979126
Validation loss: 2.054947571087909

Epoch: 5| Step: 10
Training loss: 1.23809814453125
Validation loss: 2.085965823101741

Epoch: 344| Step: 0
Training loss: 1.6113420724868774
Validation loss: 2.0522447529659478

Epoch: 5| Step: 1
Training loss: 1.5591919422149658
Validation loss: 2.0320433544856247

Epoch: 5| Step: 2
Training loss: 1.6937038898468018
Validation loss: 2.0325258829260386

Epoch: 5| Step: 3
Training loss: 1.6662906408309937
Validation loss: 2.039469022904673

Epoch: 5| Step: 4
Training loss: 1.6754207611083984
Validation loss: 2.062160693189149

Epoch: 5| Step: 5
Training loss: 1.5734472274780273
Validation loss: 2.0515970491593882

Epoch: 5| Step: 6
Training loss: 1.1545755863189697
Validation loss: 2.034918636404058

Epoch: 5| Step: 7
Training loss: 1.7286872863769531
Validation loss: 2.0676338570092314

Epoch: 5| Step: 8
Training loss: 1.3572173118591309
Validation loss: 2.063780580797503

Epoch: 5| Step: 9
Training loss: 1.8078997135162354
Validation loss: 2.0347345003517727

Epoch: 5| Step: 10
Training loss: 2.0610036849975586
Validation loss: 2.0458211950076524

Epoch: 345| Step: 0
Training loss: 1.9141649007797241
Validation loss: 2.0534665892201085

Epoch: 5| Step: 1
Training loss: 1.6366374492645264
Validation loss: 2.09655285778866

Epoch: 5| Step: 2
Training loss: 1.6620609760284424
Validation loss: 2.08836870039663

Epoch: 5| Step: 3
Training loss: 1.4749025106430054
Validation loss: 2.051091371044036

Epoch: 5| Step: 4
Training loss: 1.905358076095581
Validation loss: 2.0751228999066096

Epoch: 5| Step: 5
Training loss: 1.1859149932861328
Validation loss: 2.0540002738275835

Epoch: 5| Step: 6
Training loss: 1.4919904470443726
Validation loss: 2.070656976392192

Epoch: 5| Step: 7
Training loss: 1.5183212757110596
Validation loss: 2.0141626391359555

Epoch: 5| Step: 8
Training loss: 1.7796214818954468
Validation loss: 2.0390169364149853

Epoch: 5| Step: 9
Training loss: 1.4370616674423218
Validation loss: 2.049657949837305

Epoch: 5| Step: 10
Training loss: 2.0980300903320312
Validation loss: 2.028443682578302

Epoch: 346| Step: 0
Training loss: 1.3166108131408691
Validation loss: 2.073721129407165

Epoch: 5| Step: 1
Training loss: 1.6767826080322266
Validation loss: 2.0520686667452575

Epoch: 5| Step: 2
Training loss: 1.3937560319900513
Validation loss: 2.0309085961311095

Epoch: 5| Step: 3
Training loss: 1.6067180633544922
Validation loss: 2.0336489126246464

Epoch: 5| Step: 4
Training loss: 1.7189191579818726
Validation loss: 2.04039861566277

Epoch: 5| Step: 5
Training loss: 1.896880865097046
Validation loss: 2.0267769085463656

Epoch: 5| Step: 6
Training loss: 2.1332032680511475
Validation loss: 2.0376940593924573

Epoch: 5| Step: 7
Training loss: 0.9277103543281555
Validation loss: 2.0310023638509933

Epoch: 5| Step: 8
Training loss: 1.713660478591919
Validation loss: 2.033473695478132

Epoch: 5| Step: 9
Training loss: 1.8403825759887695
Validation loss: 2.0584523780371553

Epoch: 5| Step: 10
Training loss: 1.7282798290252686
Validation loss: 2.040663503831433

Epoch: 347| Step: 0
Training loss: 1.6204731464385986
Validation loss: 2.0757903732279295

Epoch: 5| Step: 1
Training loss: 2.1275908946990967
Validation loss: 2.0579491981896023

Epoch: 5| Step: 2
Training loss: 2.2336039543151855
Validation loss: 2.01713913999578

Epoch: 5| Step: 3
Training loss: 2.3113417625427246
Validation loss: 2.0291371037883144

Epoch: 5| Step: 4
Training loss: 1.3361364603042603
Validation loss: 2.02851927152244

Epoch: 5| Step: 5
Training loss: 1.5918042659759521
Validation loss: 2.062822054791194

Epoch: 5| Step: 6
Training loss: 1.7845178842544556
Validation loss: 2.0347571757531937

Epoch: 5| Step: 7
Training loss: 1.0634406805038452
Validation loss: 2.0753362345439132

Epoch: 5| Step: 8
Training loss: 1.1368852853775024
Validation loss: 2.06230067694059

Epoch: 5| Step: 9
Training loss: 1.612881064414978
Validation loss: 2.041220639341621

Epoch: 5| Step: 10
Training loss: 1.0621254444122314
Validation loss: 2.0555766192815637

Epoch: 348| Step: 0
Training loss: 1.6484363079071045
Validation loss: 2.029255382476314

Epoch: 5| Step: 1
Training loss: 1.7249152660369873
Validation loss: 2.045928485931889

Epoch: 5| Step: 2
Training loss: 1.8918726444244385
Validation loss: 2.019030378710839

Epoch: 5| Step: 3
Training loss: 1.641919732093811
Validation loss: 2.0376023938578944

Epoch: 5| Step: 4
Training loss: 1.5843957662582397
Validation loss: 2.0600502106451217

Epoch: 5| Step: 5
Training loss: 1.2814419269561768
Validation loss: 2.058153357557071

Epoch: 5| Step: 6
Training loss: 1.9282805919647217
Validation loss: 2.032328064723681

Epoch: 5| Step: 7
Training loss: 1.339282512664795
Validation loss: 2.017078526558415

Epoch: 5| Step: 8
Training loss: 1.6563104391098022
Validation loss: 2.0468692292449293

Epoch: 5| Step: 9
Training loss: 1.26859450340271
Validation loss: 2.0620393650506132

Epoch: 5| Step: 10
Training loss: 1.704608678817749
Validation loss: 2.0341307963094404

Epoch: 349| Step: 0
Training loss: 2.186671733856201
Validation loss: 2.037611811391769

Epoch: 5| Step: 1
Training loss: 1.5823824405670166
Validation loss: 2.0696581461096324

Epoch: 5| Step: 2
Training loss: 1.8407459259033203
Validation loss: 2.0436232397633214

Epoch: 5| Step: 3
Training loss: 1.09537672996521
Validation loss: 2.054626421261859

Epoch: 5| Step: 4
Training loss: 1.1975734233856201
Validation loss: 2.0570820608446674

Epoch: 5| Step: 5
Training loss: 1.4309009313583374
Validation loss: 2.0155761549549718

Epoch: 5| Step: 6
Training loss: 1.2839775085449219
Validation loss: 2.0274292781788814

Epoch: 5| Step: 7
Training loss: 1.7161544561386108
Validation loss: 2.050504378093186

Epoch: 5| Step: 8
Training loss: 1.6567795276641846
Validation loss: 2.0524889781910884

Epoch: 5| Step: 9
Training loss: 1.939257025718689
Validation loss: 2.066399533261535

Epoch: 5| Step: 10
Training loss: 1.8932629823684692
Validation loss: 2.0080057933766353

Epoch: 350| Step: 0
Training loss: 1.5059605836868286
Validation loss: 2.0457230024440314

Epoch: 5| Step: 1
Training loss: 1.6502087116241455
Validation loss: 2.049999939498081

Epoch: 5| Step: 2
Training loss: 1.5280673503875732
Validation loss: 2.0278565447817565

Epoch: 5| Step: 3
Training loss: 1.6377179622650146
Validation loss: 2.076219675361469

Epoch: 5| Step: 4
Training loss: 1.7653967142105103
Validation loss: 2.1091384451876403

Epoch: 5| Step: 5
Training loss: 1.679199457168579
Validation loss: 2.0748558493070703

Epoch: 5| Step: 6
Training loss: 1.3096938133239746
Validation loss: 2.043604102185977

Epoch: 5| Step: 7
Training loss: 1.7165237665176392
Validation loss: 2.0595554844025643

Epoch: 5| Step: 8
Training loss: 1.764444351196289
Validation loss: 2.0816486753443235

Epoch: 5| Step: 9
Training loss: 1.7250038385391235
Validation loss: 2.034352115405503

Epoch: 5| Step: 10
Training loss: 1.5400232076644897
Validation loss: 2.079457288147301

Epoch: 351| Step: 0
Training loss: 1.84711492061615
Validation loss: 2.0743141828044767

Epoch: 5| Step: 1
Training loss: 1.0503859519958496
Validation loss: 2.0749284016188754

Epoch: 5| Step: 2
Training loss: 1.3025678396224976
Validation loss: 2.06362461146488

Epoch: 5| Step: 3
Training loss: 1.3738725185394287
Validation loss: 2.024637217162758

Epoch: 5| Step: 4
Training loss: 1.9918466806411743
Validation loss: 2.011372664923309

Epoch: 5| Step: 5
Training loss: 1.2272404432296753
Validation loss: 2.0472780965989634

Epoch: 5| Step: 6
Training loss: 1.9935672283172607
Validation loss: 2.0570608133910806

Epoch: 5| Step: 7
Training loss: 1.598597764968872
Validation loss: 2.014001679676835

Epoch: 5| Step: 8
Training loss: 1.8177337646484375
Validation loss: 2.008451851465369

Epoch: 5| Step: 9
Training loss: 1.9229762554168701
Validation loss: 2.0297266898616666

Epoch: 5| Step: 10
Training loss: 1.4521113634109497
Validation loss: 2.051790455336212

Epoch: 352| Step: 0
Training loss: 1.4243112802505493
Validation loss: 2.0530438320611113

Epoch: 5| Step: 1
Training loss: 1.421052098274231
Validation loss: 2.025082124176846

Epoch: 5| Step: 2
Training loss: 1.7464427947998047
Validation loss: 1.98565770605559

Epoch: 5| Step: 3
Training loss: 1.5972614288330078
Validation loss: 2.068140801563058

Epoch: 5| Step: 4
Training loss: 1.0391839742660522
Validation loss: 2.0444627820804553

Epoch: 5| Step: 5
Training loss: 2.283566474914551
Validation loss: 2.071799426950434

Epoch: 5| Step: 6
Training loss: 1.2881510257720947
Validation loss: 2.0845112826234553

Epoch: 5| Step: 7
Training loss: 1.7139146327972412
Validation loss: 2.039527790520781

Epoch: 5| Step: 8
Training loss: 1.682700753211975
Validation loss: 2.044467085151262

Epoch: 5| Step: 9
Training loss: 1.9079999923706055
Validation loss: 2.0464064959556825

Epoch: 5| Step: 10
Training loss: 1.8685946464538574
Validation loss: 2.0509064043721845

Epoch: 353| Step: 0
Training loss: 1.7712770700454712
Validation loss: 2.0554376327863304

Epoch: 5| Step: 1
Training loss: 1.4652683734893799
Validation loss: 2.0614096836377214

Epoch: 5| Step: 2
Training loss: 1.6134765148162842
Validation loss: 2.0864338080088296

Epoch: 5| Step: 3
Training loss: 1.3451545238494873
Validation loss: 2.0360435208966656

Epoch: 5| Step: 4
Training loss: 1.7697570323944092
Validation loss: 2.07854369378859

Epoch: 5| Step: 5
Training loss: 1.6809486150741577
Validation loss: 2.03085438025895

Epoch: 5| Step: 6
Training loss: 1.5226733684539795
Validation loss: 2.073608094646085

Epoch: 5| Step: 7
Training loss: 1.8450008630752563
Validation loss: 2.037332598881055

Epoch: 5| Step: 8
Training loss: 2.0755598545074463
Validation loss: 2.070490990915606

Epoch: 5| Step: 9
Training loss: 1.3360910415649414
Validation loss: 2.009393899671493

Epoch: 5| Step: 10
Training loss: 1.390902042388916
Validation loss: 2.0496219704228062

Epoch: 354| Step: 0
Training loss: 1.2418946027755737
Validation loss: 2.0851120307881343

Epoch: 5| Step: 1
Training loss: 1.448639154434204
Validation loss: 2.053923929891279

Epoch: 5| Step: 2
Training loss: 1.6515462398529053
Validation loss: 2.0604932436379055

Epoch: 5| Step: 3
Training loss: 1.7246841192245483
Validation loss: 2.0510537406449676

Epoch: 5| Step: 4
Training loss: 1.7518314123153687
Validation loss: 2.0528571810773624

Epoch: 5| Step: 5
Training loss: 1.5040652751922607
Validation loss: 2.044983612593784

Epoch: 5| Step: 6
Training loss: 1.770381212234497
Validation loss: 2.0511495400500555

Epoch: 5| Step: 7
Training loss: 1.1107324361801147
Validation loss: 2.0378473830479447

Epoch: 5| Step: 8
Training loss: 1.9242775440216064
Validation loss: 2.055880779861122

Epoch: 5| Step: 9
Training loss: 1.7194862365722656
Validation loss: 2.052345424570063

Epoch: 5| Step: 10
Training loss: 1.731628179550171
Validation loss: 2.069051683589976

Epoch: 355| Step: 0
Training loss: 1.1168453693389893
Validation loss: 2.0217907838923956

Epoch: 5| Step: 1
Training loss: 1.5865962505340576
Validation loss: 2.0411287097520727

Epoch: 5| Step: 2
Training loss: 1.8461730480194092
Validation loss: 2.0133683860942884

Epoch: 5| Step: 3
Training loss: 1.4199130535125732
Validation loss: 2.0276048516714447

Epoch: 5| Step: 4
Training loss: 1.6626523733139038
Validation loss: 2.0161167754921863

Epoch: 5| Step: 5
Training loss: 1.5861237049102783
Validation loss: 2.0392444941305343

Epoch: 5| Step: 6
Training loss: 1.6170326471328735
Validation loss: 2.033404593826622

Epoch: 5| Step: 7
Training loss: 1.9914824962615967
Validation loss: 2.0373243670309744

Epoch: 5| Step: 8
Training loss: 1.3772741556167603
Validation loss: 2.03297253834304

Epoch: 5| Step: 9
Training loss: 1.7409744262695312
Validation loss: 2.0618488301513014

Epoch: 5| Step: 10
Training loss: 1.6713721752166748
Validation loss: 2.0393672796987716

Epoch: 356| Step: 0
Training loss: 1.481075406074524
Validation loss: 2.0396892806535125

Epoch: 5| Step: 1
Training loss: 2.0316920280456543
Validation loss: 2.0317104554945424

Epoch: 5| Step: 2
Training loss: 1.0057097673416138
Validation loss: 2.0276688760326755

Epoch: 5| Step: 3
Training loss: 1.5825672149658203
Validation loss: 2.027437089591898

Epoch: 5| Step: 4
Training loss: 2.2375407218933105
Validation loss: 2.029086323194606

Epoch: 5| Step: 5
Training loss: 2.105686902999878
Validation loss: 2.003153480509276

Epoch: 5| Step: 6
Training loss: 1.6930392980575562
Validation loss: 2.033868041089786

Epoch: 5| Step: 7
Training loss: 1.1595708131790161
Validation loss: 2.0348088600302257

Epoch: 5| Step: 8
Training loss: 1.3053053617477417
Validation loss: 2.0119881860671507

Epoch: 5| Step: 9
Training loss: 1.8009710311889648
Validation loss: 2.0383356258433354

Epoch: 5| Step: 10
Training loss: 1.207206130027771
Validation loss: 2.0381919824948875

Epoch: 357| Step: 0
Training loss: 1.8533620834350586
Validation loss: 2.036305703142638

Epoch: 5| Step: 1
Training loss: 1.500817894935608
Validation loss: 2.0682173339269494

Epoch: 5| Step: 2
Training loss: 1.561524748802185
Validation loss: 2.0084219017336444

Epoch: 5| Step: 3
Training loss: 1.768838882446289
Validation loss: 2.044248625796328

Epoch: 5| Step: 4
Training loss: 1.3724088668823242
Validation loss: 2.0466793557649017

Epoch: 5| Step: 5
Training loss: 1.610467553138733
Validation loss: 2.0604398532580306

Epoch: 5| Step: 6
Training loss: 1.571338176727295
Validation loss: 2.045630319144136

Epoch: 5| Step: 7
Training loss: 1.3236287832260132
Validation loss: 2.049519233806159

Epoch: 5| Step: 8
Training loss: 1.7158282995224
Validation loss: 2.0800024706830262

Epoch: 5| Step: 9
Training loss: 1.7078735828399658
Validation loss: 2.096311723032305

Epoch: 5| Step: 10
Training loss: 1.8582197427749634
Validation loss: 2.08275576560728

Epoch: 358| Step: 0
Training loss: 0.9363889694213867
Validation loss: 2.0901653894814114

Epoch: 5| Step: 1
Training loss: 1.9795806407928467
Validation loss: 2.081827950733964

Epoch: 5| Step: 2
Training loss: 1.6519559621810913
Validation loss: 2.053216456085123

Epoch: 5| Step: 3
Training loss: 1.6386638879776
Validation loss: 2.0606614158999537

Epoch: 5| Step: 4
Training loss: 1.4874516725540161
Validation loss: 2.076744282117454

Epoch: 5| Step: 5
Training loss: 1.9428167343139648
Validation loss: 2.053642064012507

Epoch: 5| Step: 6
Training loss: 1.4668190479278564
Validation loss: 2.057771708375664

Epoch: 5| Step: 7
Training loss: 1.316210389137268
Validation loss: 2.044782575740609

Epoch: 5| Step: 8
Training loss: 1.643943428993225
Validation loss: 2.028069652536864

Epoch: 5| Step: 9
Training loss: 1.8694738149642944
Validation loss: 2.0222295150961926

Epoch: 5| Step: 10
Training loss: 1.521222710609436
Validation loss: 2.0478536775035243

Epoch: 359| Step: 0
Training loss: 1.337494134902954
Validation loss: 2.0524815115877377

Epoch: 5| Step: 1
Training loss: 1.6819655895233154
Validation loss: 2.0480353729699248

Epoch: 5| Step: 2
Training loss: 1.8128516674041748
Validation loss: 2.0324585219865203

Epoch: 5| Step: 3
Training loss: 1.690076470375061
Validation loss: 2.0436371052136986

Epoch: 5| Step: 4
Training loss: 1.4733059406280518
Validation loss: 2.0592569510142007

Epoch: 5| Step: 5
Training loss: 1.4197509288787842
Validation loss: 2.0681300368360294

Epoch: 5| Step: 6
Training loss: 1.57558274269104
Validation loss: 2.0370542439081336

Epoch: 5| Step: 7
Training loss: 1.702239751815796
Validation loss: 2.082706577034407

Epoch: 5| Step: 8
Training loss: 1.7813184261322021
Validation loss: 2.074907104174296

Epoch: 5| Step: 9
Training loss: 1.9053030014038086
Validation loss: 2.0748058647237797

Epoch: 5| Step: 10
Training loss: 1.3850728273391724
Validation loss: 2.0386156343644664

Epoch: 360| Step: 0
Training loss: 1.8409526348114014
Validation loss: 2.0393072789715183

Epoch: 5| Step: 1
Training loss: 1.7449012994766235
Validation loss: 2.057681880971437

Epoch: 5| Step: 2
Training loss: 1.5124815702438354
Validation loss: 2.044491124409501

Epoch: 5| Step: 3
Training loss: 1.5879305601119995
Validation loss: 2.03317411996985

Epoch: 5| Step: 4
Training loss: 1.742166519165039
Validation loss: 2.01598600674701

Epoch: 5| Step: 5
Training loss: 1.7683351039886475
Validation loss: 2.085102688881659

Epoch: 5| Step: 6
Training loss: 1.2579188346862793
Validation loss: 2.0603314343319146

Epoch: 5| Step: 7
Training loss: 1.4763758182525635
Validation loss: 2.0541149788005377

Epoch: 5| Step: 8
Training loss: 1.7164878845214844
Validation loss: 2.0553039812272593

Epoch: 5| Step: 9
Training loss: 1.2055720090866089
Validation loss: 2.0897848503563994

Epoch: 5| Step: 10
Training loss: 1.5609768629074097
Validation loss: 2.0878128582431423

Epoch: 361| Step: 0
Training loss: 1.5221022367477417
Validation loss: 2.05362876256307

Epoch: 5| Step: 1
Training loss: 2.1354641914367676
Validation loss: 2.0308462137817056

Epoch: 5| Step: 2
Training loss: 1.539757490158081
Validation loss: 2.0739098005397345

Epoch: 5| Step: 3
Training loss: 1.8454463481903076
Validation loss: 2.0554919999132872

Epoch: 5| Step: 4
Training loss: 1.2411634922027588
Validation loss: 2.0527279787166144

Epoch: 5| Step: 5
Training loss: 1.9970436096191406
Validation loss: 2.046210701747607

Epoch: 5| Step: 6
Training loss: 2.0349650382995605
Validation loss: 2.028233312791394

Epoch: 5| Step: 7
Training loss: 1.8577477931976318
Validation loss: 2.0394781379289526

Epoch: 5| Step: 8
Training loss: 1.2217199802398682
Validation loss: 2.013457282896965

Epoch: 5| Step: 9
Training loss: 1.1820708513259888
Validation loss: 2.0423853884461107

Epoch: 5| Step: 10
Training loss: 1.0235518217086792
Validation loss: 2.0370913244062856

Epoch: 362| Step: 0
Training loss: 1.40666663646698
Validation loss: 2.0622486452902518

Epoch: 5| Step: 1
Training loss: 1.3683335781097412
Validation loss: 2.0301989509213354

Epoch: 5| Step: 2
Training loss: 1.3539711236953735
Validation loss: 2.0492602984110513

Epoch: 5| Step: 3
Training loss: 1.569736123085022
Validation loss: 2.0369281653435

Epoch: 5| Step: 4
Training loss: 0.9551035165786743
Validation loss: 2.001770216931579

Epoch: 5| Step: 5
Training loss: 1.8615710735321045
Validation loss: 2.045560357391193

Epoch: 5| Step: 6
Training loss: 1.5519309043884277
Validation loss: 2.046343747005668

Epoch: 5| Step: 7
Training loss: 1.70025634765625
Validation loss: 2.034757729499571

Epoch: 5| Step: 8
Training loss: 1.6368391513824463
Validation loss: 2.027370306753343

Epoch: 5| Step: 9
Training loss: 1.9889625310897827
Validation loss: 2.023613191420032

Epoch: 5| Step: 10
Training loss: 1.973682165145874
Validation loss: 2.0313857704080562

Epoch: 363| Step: 0
Training loss: 1.6249048709869385
Validation loss: 2.0573315107694237

Epoch: 5| Step: 1
Training loss: 1.8007179498672485
Validation loss: 2.05567047672887

Epoch: 5| Step: 2
Training loss: 2.022606372833252
Validation loss: 2.061863419830158

Epoch: 5| Step: 3
Training loss: 1.5780487060546875
Validation loss: 2.0342422941679597

Epoch: 5| Step: 4
Training loss: 1.8383800983428955
Validation loss: 2.0336007507898475

Epoch: 5| Step: 5
Training loss: 1.7965786457061768
Validation loss: 2.0294601301993094

Epoch: 5| Step: 6
Training loss: 1.5254278182983398
Validation loss: 2.0702679105984267

Epoch: 5| Step: 7
Training loss: 1.7234747409820557
Validation loss: 2.065301631086616

Epoch: 5| Step: 8
Training loss: 1.3479920625686646
Validation loss: 2.022528406112425

Epoch: 5| Step: 9
Training loss: 1.5608412027359009
Validation loss: 2.045484483882945

Epoch: 5| Step: 10
Training loss: 0.8320454955101013
Validation loss: 2.0525271995093233

Epoch: 364| Step: 0
Training loss: 1.44863760471344
Validation loss: 2.0128281475395284

Epoch: 5| Step: 1
Training loss: 1.6296672821044922
Validation loss: 2.0420755199206773

Epoch: 5| Step: 2
Training loss: 1.72037672996521
Validation loss: 2.0148093956773

Epoch: 5| Step: 3
Training loss: 1.1581147909164429
Validation loss: 2.05178024179192

Epoch: 5| Step: 4
Training loss: 1.5239053964614868
Validation loss: 2.029619745028916

Epoch: 5| Step: 5
Training loss: 2.053121328353882
Validation loss: 2.056305544350737

Epoch: 5| Step: 6
Training loss: 1.7437684535980225
Validation loss: 2.061232811661177

Epoch: 5| Step: 7
Training loss: 1.884169340133667
Validation loss: 2.062598487382294

Epoch: 5| Step: 8
Training loss: 1.4036654233932495
Validation loss: 2.02788979776444

Epoch: 5| Step: 9
Training loss: 1.5440200567245483
Validation loss: 2.0267543510724138

Epoch: 5| Step: 10
Training loss: 1.698683500289917
Validation loss: 2.018866700510825

Epoch: 365| Step: 0
Training loss: 1.3370212316513062
Validation loss: 2.026827214866556

Epoch: 5| Step: 1
Training loss: 1.2672512531280518
Validation loss: 2.060916369961154

Epoch: 5| Step: 2
Training loss: 1.3344850540161133
Validation loss: 2.0461762643629506

Epoch: 5| Step: 3
Training loss: 1.3543689250946045
Validation loss: 2.064451443251743

Epoch: 5| Step: 4
Training loss: 1.93280029296875
Validation loss: 2.0685527132403467

Epoch: 5| Step: 5
Training loss: 1.912377953529358
Validation loss: 2.1142427011202742

Epoch: 5| Step: 6
Training loss: 1.900530219078064
Validation loss: 2.0724620357636483

Epoch: 5| Step: 7
Training loss: 1.3293098211288452
Validation loss: 2.0972583973279564

Epoch: 5| Step: 8
Training loss: 2.1238510608673096
Validation loss: 2.067486395118057

Epoch: 5| Step: 9
Training loss: 1.2839515209197998
Validation loss: 2.064576345105325

Epoch: 5| Step: 10
Training loss: 1.930091381072998
Validation loss: 2.0974419322065128

Epoch: 366| Step: 0
Training loss: 0.9994428753852844
Validation loss: 2.099720137093657

Epoch: 5| Step: 1
Training loss: 1.6455466747283936
Validation loss: 2.0520138727721347

Epoch: 5| Step: 2
Training loss: 1.8617140054702759
Validation loss: 2.074154387238205

Epoch: 5| Step: 3
Training loss: 2.0175719261169434
Validation loss: 2.071986413771106

Epoch: 5| Step: 4
Training loss: 0.988620400428772
Validation loss: 2.038292210589173

Epoch: 5| Step: 5
Training loss: 1.6914913654327393
Validation loss: 2.0353516891438472

Epoch: 5| Step: 6
Training loss: 1.9075464010238647
Validation loss: 2.0540154954438568

Epoch: 5| Step: 7
Training loss: 1.2428245544433594
Validation loss: 2.0111035608476207

Epoch: 5| Step: 8
Training loss: 1.8192203044891357
Validation loss: 2.014217840727939

Epoch: 5| Step: 9
Training loss: 1.5574638843536377
Validation loss: 2.032725175221761

Epoch: 5| Step: 10
Training loss: 1.5726240873336792
Validation loss: 2.0308066234793714

Epoch: 367| Step: 0
Training loss: 1.8128852844238281
Validation loss: 2.0340319218174105

Epoch: 5| Step: 1
Training loss: 1.868419885635376
Validation loss: 2.0306959613676994

Epoch: 5| Step: 2
Training loss: 1.5185283422470093
Validation loss: 2.030980354996138

Epoch: 5| Step: 3
Training loss: 1.1496498584747314
Validation loss: 2.0437068016298356

Epoch: 5| Step: 4
Training loss: 1.7497265338897705
Validation loss: 2.0422282167660293

Epoch: 5| Step: 5
Training loss: 1.507253885269165
Validation loss: 2.040465936865858

Epoch: 5| Step: 6
Training loss: 1.3099451065063477
Validation loss: 2.0352359074418263

Epoch: 5| Step: 7
Training loss: 1.8825538158416748
Validation loss: 2.0359195509264545

Epoch: 5| Step: 8
Training loss: 1.5625947713851929
Validation loss: 2.000435943244606

Epoch: 5| Step: 9
Training loss: 1.7375917434692383
Validation loss: 2.046543372574673

Epoch: 5| Step: 10
Training loss: 1.3376222848892212
Validation loss: 2.0551357935833674

Epoch: 368| Step: 0
Training loss: 1.4569921493530273
Validation loss: 2.061518144863908

Epoch: 5| Step: 1
Training loss: 1.079024076461792
Validation loss: 2.070374578557989

Epoch: 5| Step: 2
Training loss: 1.4582712650299072
Validation loss: 2.027871313915458

Epoch: 5| Step: 3
Training loss: 2.0968565940856934
Validation loss: 2.0474644194367113

Epoch: 5| Step: 4
Training loss: 1.446429967880249
Validation loss: 2.0913408366582726

Epoch: 5| Step: 5
Training loss: 1.8879413604736328
Validation loss: 2.0401007654846355

Epoch: 5| Step: 6
Training loss: 1.9261143207550049
Validation loss: 2.0673003119807087

Epoch: 5| Step: 7
Training loss: 1.2732279300689697
Validation loss: 2.045505092990014

Epoch: 5| Step: 8
Training loss: 1.8020241260528564
Validation loss: 2.0508458998895462

Epoch: 5| Step: 9
Training loss: 1.9255352020263672
Validation loss: 2.027948805080947

Epoch: 5| Step: 10
Training loss: 0.97138911485672
Validation loss: 2.0818866350317515

Epoch: 369| Step: 0
Training loss: 1.184030294418335
Validation loss: 2.0601309114886868

Epoch: 5| Step: 1
Training loss: 1.592466115951538
Validation loss: 2.0148824145717006

Epoch: 5| Step: 2
Training loss: 1.34488844871521
Validation loss: 2.0256390520321426

Epoch: 5| Step: 3
Training loss: 2.0980334281921387
Validation loss: 2.064305228571738

Epoch: 5| Step: 4
Training loss: 1.4929744005203247
Validation loss: 2.036984528264692

Epoch: 5| Step: 5
Training loss: 2.1691205501556396
Validation loss: 2.034469228918834

Epoch: 5| Step: 6
Training loss: 1.4937829971313477
Validation loss: 2.034502080691758

Epoch: 5| Step: 7
Training loss: 1.3602797985076904
Validation loss: 2.0624241495645173

Epoch: 5| Step: 8
Training loss: 1.6977752447128296
Validation loss: 2.0584275184139127

Epoch: 5| Step: 9
Training loss: 1.7111923694610596
Validation loss: 2.020675946307439

Epoch: 5| Step: 10
Training loss: 1.1835050582885742
Validation loss: 2.0566893751903246

Epoch: 370| Step: 0
Training loss: 1.85297429561615
Validation loss: 2.015584966187836

Epoch: 5| Step: 1
Training loss: 0.9867412447929382
Validation loss: 2.082520669506442

Epoch: 5| Step: 2
Training loss: 2.3057801723480225
Validation loss: 2.032257890188566

Epoch: 5| Step: 3
Training loss: 1.6370069980621338
Validation loss: 2.0006816617904173

Epoch: 5| Step: 4
Training loss: 1.4409396648406982
Validation loss: 2.050044321244763

Epoch: 5| Step: 5
Training loss: 1.6332597732543945
Validation loss: 2.0426833232243857

Epoch: 5| Step: 6
Training loss: 1.5504578351974487
Validation loss: 2.036839303149972

Epoch: 5| Step: 7
Training loss: 1.4502977132797241
Validation loss: 2.0141988890145415

Epoch: 5| Step: 8
Training loss: 1.0388678312301636
Validation loss: 2.0375324404367836

Epoch: 5| Step: 9
Training loss: 1.8430496454238892
Validation loss: 2.039915438621275

Epoch: 5| Step: 10
Training loss: 1.7741470336914062
Validation loss: 2.0417981993767524

Epoch: 371| Step: 0
Training loss: 1.4329726696014404
Validation loss: 2.0390283343612507

Epoch: 5| Step: 1
Training loss: 1.2525196075439453
Validation loss: 2.0259063359229796

Epoch: 5| Step: 2
Training loss: 1.7098417282104492
Validation loss: 2.047179783544233

Epoch: 5| Step: 3
Training loss: 1.5623142719268799
Validation loss: 2.004203504131686

Epoch: 5| Step: 4
Training loss: 2.089540958404541
Validation loss: 2.0203621015753797

Epoch: 5| Step: 5
Training loss: 1.5154849290847778
Validation loss: 2.0233125186735585

Epoch: 5| Step: 6
Training loss: 1.0084117650985718
Validation loss: 2.055638018474784

Epoch: 5| Step: 7
Training loss: 1.9215447902679443
Validation loss: 2.026313227991904

Epoch: 5| Step: 8
Training loss: 1.3007848262786865
Validation loss: 2.0339303811391196

Epoch: 5| Step: 9
Training loss: 1.5079295635223389
Validation loss: 2.023789473759231

Epoch: 5| Step: 10
Training loss: 2.05712628364563
Validation loss: 2.0370949186304563

Epoch: 372| Step: 0
Training loss: 1.283794641494751
Validation loss: 2.051171338686379

Epoch: 5| Step: 1
Training loss: 1.7861419916152954
Validation loss: 2.03924641301555

Epoch: 5| Step: 2
Training loss: 1.6301758289337158
Validation loss: 2.059469228149742

Epoch: 5| Step: 3
Training loss: 1.389962911605835
Validation loss: 2.041308609388208

Epoch: 5| Step: 4
Training loss: 1.3936512470245361
Validation loss: 2.0675870821040165

Epoch: 5| Step: 5
Training loss: 1.1477540731430054
Validation loss: 2.047131863973474

Epoch: 5| Step: 6
Training loss: 1.5942747592926025
Validation loss: 2.0308546327775523

Epoch: 5| Step: 7
Training loss: 1.9676234722137451
Validation loss: 2.0328382304919663

Epoch: 5| Step: 8
Training loss: 1.1404262781143188
Validation loss: 2.0508774788148942

Epoch: 5| Step: 9
Training loss: 1.7564637660980225
Validation loss: 2.063520316154726

Epoch: 5| Step: 10
Training loss: 1.9821975231170654
Validation loss: 2.0090512460277927

Epoch: 373| Step: 0
Training loss: 1.8206104040145874
Validation loss: 2.001484840146957

Epoch: 5| Step: 1
Training loss: 0.8992680311203003
Validation loss: 2.048367687450942

Epoch: 5| Step: 2
Training loss: 1.498889684677124
Validation loss: 2.035937898902483

Epoch: 5| Step: 3
Training loss: 1.7552894353866577
Validation loss: 2.0060555242723033

Epoch: 5| Step: 4
Training loss: 1.3797458410263062
Validation loss: 2.0164291499763407

Epoch: 5| Step: 5
Training loss: 2.327685832977295
Validation loss: 2.013159780092137

Epoch: 5| Step: 6
Training loss: 2.0255212783813477
Validation loss: 2.018079550035538

Epoch: 5| Step: 7
Training loss: 1.7876198291778564
Validation loss: 2.056313596745973

Epoch: 5| Step: 8
Training loss: 1.0730488300323486
Validation loss: 2.0453349838974657

Epoch: 5| Step: 9
Training loss: 1.1094245910644531
Validation loss: 2.031324044350655

Epoch: 5| Step: 10
Training loss: 1.7970976829528809
Validation loss: 2.056140658675983

Epoch: 374| Step: 0
Training loss: 0.8979588747024536
Validation loss: 2.040793329156855

Epoch: 5| Step: 1
Training loss: 1.742600679397583
Validation loss: 2.059761885673769

Epoch: 5| Step: 2
Training loss: 1.4336611032485962
Validation loss: 2.0342109972430813

Epoch: 5| Step: 3
Training loss: 1.8032798767089844
Validation loss: 2.0346389855107954

Epoch: 5| Step: 4
Training loss: 1.8038883209228516
Validation loss: 2.019333034433344

Epoch: 5| Step: 5
Training loss: 1.975303292274475
Validation loss: 2.042939615505998

Epoch: 5| Step: 6
Training loss: 1.5596784353256226
Validation loss: 2.0393046204761793

Epoch: 5| Step: 7
Training loss: 1.7982046604156494
Validation loss: 2.0158150824167396

Epoch: 5| Step: 8
Training loss: 1.6073980331420898
Validation loss: 2.0514260697108444

Epoch: 5| Step: 9
Training loss: 1.6787662506103516
Validation loss: 2.0175570852013043

Epoch: 5| Step: 10
Training loss: 0.9585434198379517
Validation loss: 2.0363715771705873

Epoch: 375| Step: 0
Training loss: 1.9301446676254272
Validation loss: 2.0202092996207615

Epoch: 5| Step: 1
Training loss: 1.234022855758667
Validation loss: 2.058967927450775

Epoch: 5| Step: 2
Training loss: 1.4267305135726929
Validation loss: 2.026371645671065

Epoch: 5| Step: 3
Training loss: 1.5658931732177734
Validation loss: 2.0173681551410305

Epoch: 5| Step: 4
Training loss: 1.4898042678833008
Validation loss: 2.056389647145425

Epoch: 5| Step: 5
Training loss: 1.9798622131347656
Validation loss: 2.026752446287422

Epoch: 5| Step: 6
Training loss: 1.4657491445541382
Validation loss: 2.0167389556925785

Epoch: 5| Step: 7
Training loss: 1.8227736949920654
Validation loss: 2.0643235329658753

Epoch: 5| Step: 8
Training loss: 1.5004713535308838
Validation loss: 2.037824753792055

Epoch: 5| Step: 9
Training loss: 1.6354055404663086
Validation loss: 2.0771609967754734

Epoch: 5| Step: 10
Training loss: 1.468153715133667
Validation loss: 2.072642199454769

Epoch: 376| Step: 0
Training loss: 1.6249334812164307
Validation loss: 2.034826809360135

Epoch: 5| Step: 1
Training loss: 2.0521063804626465
Validation loss: 2.0765604485747633

Epoch: 5| Step: 2
Training loss: 1.5542978048324585
Validation loss: 2.070978065972687

Epoch: 5| Step: 3
Training loss: 1.7232887744903564
Validation loss: 2.0768276645291235

Epoch: 5| Step: 4
Training loss: 2.0299453735351562
Validation loss: 2.076065876150644

Epoch: 5| Step: 5
Training loss: 1.6567096710205078
Validation loss: 2.0059229045785885

Epoch: 5| Step: 6
Training loss: 0.8744567036628723
Validation loss: 2.039700925991099

Epoch: 5| Step: 7
Training loss: 1.2058160305023193
Validation loss: 2.0361396779296217

Epoch: 5| Step: 8
Training loss: 1.6008437871932983
Validation loss: 2.0205793675555976

Epoch: 5| Step: 9
Training loss: 1.535754919052124
Validation loss: 2.0381634927565053

Epoch: 5| Step: 10
Training loss: 1.5674351453781128
Validation loss: 2.061445140069531

Epoch: 377| Step: 0
Training loss: 1.337209701538086
Validation loss: 2.0689141186334754

Epoch: 5| Step: 1
Training loss: 1.5683610439300537
Validation loss: 2.0797238452460176

Epoch: 5| Step: 2
Training loss: 1.7728183269500732
Validation loss: 2.045895436758636

Epoch: 5| Step: 3
Training loss: 1.7605934143066406
Validation loss: 2.0242483423602198

Epoch: 5| Step: 4
Training loss: 1.9663217067718506
Validation loss: 2.050819420045422

Epoch: 5| Step: 5
Training loss: 2.153249502182007
Validation loss: 2.0371497651582122

Epoch: 5| Step: 6
Training loss: 1.0396325588226318
Validation loss: 2.0671873656652306

Epoch: 5| Step: 7
Training loss: 1.3467761278152466
Validation loss: 2.0237783821680213

Epoch: 5| Step: 8
Training loss: 1.1615530252456665
Validation loss: 2.020746607934275

Epoch: 5| Step: 9
Training loss: 1.596116065979004
Validation loss: 2.0253271505396855

Epoch: 5| Step: 10
Training loss: 1.738322138786316
Validation loss: 2.0273319405894124

Epoch: 378| Step: 0
Training loss: 1.796496033668518
Validation loss: 2.0328674854770785

Epoch: 5| Step: 1
Training loss: 1.8669273853302002
Validation loss: 2.034404339328889

Epoch: 5| Step: 2
Training loss: 1.2153805494308472
Validation loss: 2.0015528637875795

Epoch: 5| Step: 3
Training loss: 2.4815680980682373
Validation loss: 2.0434605101103425

Epoch: 5| Step: 4
Training loss: 1.398110270500183
Validation loss: 2.0397133545209

Epoch: 5| Step: 5
Training loss: 1.4839112758636475
Validation loss: 2.034437143674461

Epoch: 5| Step: 6
Training loss: 1.37921142578125
Validation loss: 2.0767884177546345

Epoch: 5| Step: 7
Training loss: 0.9107198715209961
Validation loss: 2.0822982147175777

Epoch: 5| Step: 8
Training loss: 1.4149277210235596
Validation loss: 2.0380523230439875

Epoch: 5| Step: 9
Training loss: 1.7545585632324219
Validation loss: 2.083471336672383

Epoch: 5| Step: 10
Training loss: 1.697614312171936
Validation loss: 2.1066558591781126

Epoch: 379| Step: 0
Training loss: 1.5646719932556152
Validation loss: 2.066532431110259

Epoch: 5| Step: 1
Training loss: 1.9637657403945923
Validation loss: 2.07649653445008

Epoch: 5| Step: 2
Training loss: 1.5415661334991455
Validation loss: 2.0749493286173832

Epoch: 5| Step: 3
Training loss: 1.2156740427017212
Validation loss: 2.054439669014305

Epoch: 5| Step: 4
Training loss: 1.4137165546417236
Validation loss: 2.075234300346785

Epoch: 5| Step: 5
Training loss: 1.585211992263794
Validation loss: 2.048623401631591

Epoch: 5| Step: 6
Training loss: 1.7414344549179077
Validation loss: 2.0364154205527356

Epoch: 5| Step: 7
Training loss: 1.5415699481964111
Validation loss: 2.048350020121503

Epoch: 5| Step: 8
Training loss: 1.3508775234222412
Validation loss: 2.0235515038172402

Epoch: 5| Step: 9
Training loss: 1.8613916635513306
Validation loss: 2.049150918119697

Epoch: 5| Step: 10
Training loss: 1.595627784729004
Validation loss: 2.0445945006544872

Epoch: 380| Step: 0
Training loss: 2.1325340270996094
Validation loss: 2.0484492983869327

Epoch: 5| Step: 1
Training loss: 0.9342136383056641
Validation loss: 2.0434080990411903

Epoch: 5| Step: 2
Training loss: 1.838087797164917
Validation loss: 2.0592707946736324

Epoch: 5| Step: 3
Training loss: 1.4722551107406616
Validation loss: 2.0562691842356036

Epoch: 5| Step: 4
Training loss: 1.212335228919983
Validation loss: 2.0378220465875443

Epoch: 5| Step: 5
Training loss: 1.5179082155227661
Validation loss: 2.009796896288472

Epoch: 5| Step: 6
Training loss: 1.43242609500885
Validation loss: 2.02129727537914

Epoch: 5| Step: 7
Training loss: 1.9845832586288452
Validation loss: 2.013505102485739

Epoch: 5| Step: 8
Training loss: 1.3757750988006592
Validation loss: 2.0564735858671126

Epoch: 5| Step: 9
Training loss: 1.4742536544799805
Validation loss: 2.069619958118726

Epoch: 5| Step: 10
Training loss: 1.7556473016738892
Validation loss: 2.078218383173789

Epoch: 381| Step: 0
Training loss: 1.4875867366790771
Validation loss: 2.0693886959424583

Epoch: 5| Step: 1
Training loss: 1.425546646118164
Validation loss: 2.0438678854255268

Epoch: 5| Step: 2
Training loss: 1.092642068862915
Validation loss: 2.0964911496767433

Epoch: 5| Step: 3
Training loss: 1.8688949346542358
Validation loss: 2.105853772932483

Epoch: 5| Step: 4
Training loss: 1.4948797225952148
Validation loss: 2.071086396453201

Epoch: 5| Step: 5
Training loss: 1.5747250318527222
Validation loss: 2.00431917559716

Epoch: 5| Step: 6
Training loss: 1.3927615880966187
Validation loss: 2.024114603637367

Epoch: 5| Step: 7
Training loss: 1.7549209594726562
Validation loss: 2.035708781211607

Epoch: 5| Step: 8
Training loss: 2.0209810733795166
Validation loss: 2.0587298088176276

Epoch: 5| Step: 9
Training loss: 1.1480804681777954
Validation loss: 2.0455943358841764

Epoch: 5| Step: 10
Training loss: 2.254953622817993
Validation loss: 2.0139896600477156

Epoch: 382| Step: 0
Training loss: 1.7392499446868896
Validation loss: 2.040296244364913

Epoch: 5| Step: 1
Training loss: 1.6384143829345703
Validation loss: 2.019345529617802

Epoch: 5| Step: 2
Training loss: 1.9870388507843018
Validation loss: 2.0462418448540474

Epoch: 5| Step: 3
Training loss: 1.646409273147583
Validation loss: 2.0572413347100698

Epoch: 5| Step: 4
Training loss: 1.5758545398712158
Validation loss: 2.0247170540594284

Epoch: 5| Step: 5
Training loss: 1.7197563648223877
Validation loss: 2.06672360820155

Epoch: 5| Step: 6
Training loss: 1.44829261302948
Validation loss: 2.0845659214963197

Epoch: 5| Step: 7
Training loss: 1.1329526901245117
Validation loss: 2.0155934236382924

Epoch: 5| Step: 8
Training loss: 1.7784016132354736
Validation loss: 2.031692434382695

Epoch: 5| Step: 9
Training loss: 1.257000207901001
Validation loss: 2.103643731404376

Epoch: 5| Step: 10
Training loss: 1.1624447107315063
Validation loss: 2.072000329212476

Epoch: 383| Step: 0
Training loss: 1.8673003911972046
Validation loss: 2.0593938545514177

Epoch: 5| Step: 1
Training loss: 1.7120864391326904
Validation loss: 2.0358004570007324

Epoch: 5| Step: 2
Training loss: 1.7136898040771484
Validation loss: 2.046916179759528

Epoch: 5| Step: 3
Training loss: 1.2861801385879517
Validation loss: 2.064637017506425

Epoch: 5| Step: 4
Training loss: 1.5647623538970947
Validation loss: 2.0923412769071517

Epoch: 5| Step: 5
Training loss: 1.2628192901611328
Validation loss: 2.072772511871912

Epoch: 5| Step: 6
Training loss: 1.5988932847976685
Validation loss: 2.0396741231282554

Epoch: 5| Step: 7
Training loss: 1.3820483684539795
Validation loss: 2.0263508673637145

Epoch: 5| Step: 8
Training loss: 1.848189115524292
Validation loss: 2.0809700706953644

Epoch: 5| Step: 9
Training loss: 1.5049550533294678
Validation loss: 2.020031959779801

Epoch: 5| Step: 10
Training loss: 1.4046648740768433
Validation loss: 2.036611105806084

Epoch: 384| Step: 0
Training loss: 1.1092474460601807
Validation loss: 2.0774915833627023

Epoch: 5| Step: 1
Training loss: 1.3883028030395508
Validation loss: 2.0568742585438553

Epoch: 5| Step: 2
Training loss: 1.8538637161254883
Validation loss: 2.02292267481486

Epoch: 5| Step: 3
Training loss: 2.115992307662964
Validation loss: 2.0395707315014255

Epoch: 5| Step: 4
Training loss: 1.5210810899734497
Validation loss: 2.020107001386663

Epoch: 5| Step: 5
Training loss: 1.8520259857177734
Validation loss: 2.0391980627531647

Epoch: 5| Step: 6
Training loss: 1.5508501529693604
Validation loss: 2.0092938894866617

Epoch: 5| Step: 7
Training loss: 1.7168071269989014
Validation loss: 2.0468353866249003

Epoch: 5| Step: 8
Training loss: 1.3391965627670288
Validation loss: 2.0120329882508967

Epoch: 5| Step: 9
Training loss: 1.1476480960845947
Validation loss: 2.0411915907295803

Epoch: 5| Step: 10
Training loss: 1.374119758605957
Validation loss: 2.0548163767783874

Epoch: 385| Step: 0
Training loss: 1.8232139348983765
Validation loss: 2.0710501363200526

Epoch: 5| Step: 1
Training loss: 1.3063206672668457
Validation loss: 2.0570848770039056

Epoch: 5| Step: 2
Training loss: 1.3806877136230469
Validation loss: 2.0608151394833802

Epoch: 5| Step: 3
Training loss: 1.8517239093780518
Validation loss: 2.062419299156435

Epoch: 5| Step: 4
Training loss: 1.2997808456420898
Validation loss: 2.0487270701316094

Epoch: 5| Step: 5
Training loss: 2.075735569000244
Validation loss: 2.0352542836179017

Epoch: 5| Step: 6
Training loss: 1.684513807296753
Validation loss: 1.9960942242735176

Epoch: 5| Step: 7
Training loss: 1.1711533069610596
Validation loss: 2.0327446050541376

Epoch: 5| Step: 8
Training loss: 1.0710790157318115
Validation loss: 2.0242222137348627

Epoch: 5| Step: 9
Training loss: 2.2457292079925537
Validation loss: 2.024615228817027

Epoch: 5| Step: 10
Training loss: 1.2429392337799072
Validation loss: 2.038219000703545

Epoch: 386| Step: 0
Training loss: 1.8701156377792358
Validation loss: 2.051457740927255

Epoch: 5| Step: 1
Training loss: 1.433450698852539
Validation loss: 2.0286416135808474

Epoch: 5| Step: 2
Training loss: 2.094815731048584
Validation loss: 2.0396256805748068

Epoch: 5| Step: 3
Training loss: 1.357142686843872
Validation loss: 2.053986486568246

Epoch: 5| Step: 4
Training loss: 1.9214591979980469
Validation loss: 2.033136826689525

Epoch: 5| Step: 5
Training loss: 1.696773886680603
Validation loss: 2.0223003036232403

Epoch: 5| Step: 6
Training loss: 1.015500783920288
Validation loss: 2.036099741535802

Epoch: 5| Step: 7
Training loss: 1.1090679168701172
Validation loss: 2.030681769053141

Epoch: 5| Step: 8
Training loss: 1.3959581851959229
Validation loss: 2.0317196858826505

Epoch: 5| Step: 9
Training loss: 1.4299447536468506
Validation loss: 2.0128848578340266

Epoch: 5| Step: 10
Training loss: 1.8089767694473267
Validation loss: 2.0309939192187403

Epoch: 387| Step: 0
Training loss: 2.24228835105896
Validation loss: 2.057776105019354

Epoch: 5| Step: 1
Training loss: 1.629174828529358
Validation loss: 2.086054701958933

Epoch: 5| Step: 2
Training loss: 1.1449053287506104
Validation loss: 2.0689102577906784

Epoch: 5| Step: 3
Training loss: 1.154683232307434
Validation loss: 2.0587766426865772

Epoch: 5| Step: 4
Training loss: 1.6631038188934326
Validation loss: 2.0235818970587944

Epoch: 5| Step: 5
Training loss: 1.58571457862854
Validation loss: 2.0446315862799205

Epoch: 5| Step: 6
Training loss: 1.499880075454712
Validation loss: 2.0289942295320573

Epoch: 5| Step: 7
Training loss: 1.0525368452072144
Validation loss: 2.0576246156487414

Epoch: 5| Step: 8
Training loss: 2.197066307067871
Validation loss: 2.0507553700477845

Epoch: 5| Step: 9
Training loss: 1.794738531112671
Validation loss: 2.0317279766964655

Epoch: 5| Step: 10
Training loss: 1.047674536705017
Validation loss: 2.018699889541954

Epoch: 388| Step: 0
Training loss: 1.3378320932388306
Validation loss: 2.036990609220279

Epoch: 5| Step: 1
Training loss: 1.3164517879486084
Validation loss: 2.0094469055052726

Epoch: 5| Step: 2
Training loss: 1.548473596572876
Validation loss: 2.0273540019989014

Epoch: 5| Step: 3
Training loss: 1.827628493309021
Validation loss: 2.0291127479204567

Epoch: 5| Step: 4
Training loss: 1.7858924865722656
Validation loss: 2.0340348828223442

Epoch: 5| Step: 5
Training loss: 1.0795632600784302
Validation loss: 2.0252140157966205

Epoch: 5| Step: 6
Training loss: 1.8513818979263306
Validation loss: 2.0513783911223054

Epoch: 5| Step: 7
Training loss: 1.7686710357666016
Validation loss: 2.0460704680412047

Epoch: 5| Step: 8
Training loss: 1.8292278051376343
Validation loss: 2.061660708919648

Epoch: 5| Step: 9
Training loss: 1.6065223217010498
Validation loss: 2.03984857502804

Epoch: 5| Step: 10
Training loss: 1.4433972835540771
Validation loss: 2.0443002946915163

Epoch: 389| Step: 0
Training loss: 1.6028099060058594
Validation loss: 2.0082267099811184

Epoch: 5| Step: 1
Training loss: 1.5366584062576294
Validation loss: 2.037766948823006

Epoch: 5| Step: 2
Training loss: 1.6588191986083984
Validation loss: 2.0230937926999983

Epoch: 5| Step: 3
Training loss: 2.122368574142456
Validation loss: 2.0575218046865156

Epoch: 5| Step: 4
Training loss: 1.9012199640274048
Validation loss: 2.042757999512457

Epoch: 5| Step: 5
Training loss: 1.0324881076812744
Validation loss: 2.035668191089425

Epoch: 5| Step: 6
Training loss: 1.8487260341644287
Validation loss: 2.079679089207803

Epoch: 5| Step: 7
Training loss: 1.3631800413131714
Validation loss: 2.0699757196569957

Epoch: 5| Step: 8
Training loss: 1.4949973821640015
Validation loss: 2.064090415995608

Epoch: 5| Step: 9
Training loss: 1.5153683423995972
Validation loss: 2.067377516018447

Epoch: 5| Step: 10
Training loss: 1.1053792238235474
Validation loss: 2.0472830469890306

Epoch: 390| Step: 0
Training loss: 2.079944133758545
Validation loss: 2.0251158642512497

Epoch: 5| Step: 1
Training loss: 1.3367021083831787
Validation loss: 2.0307819112654655

Epoch: 5| Step: 2
Training loss: 2.0748355388641357
Validation loss: 2.0645536068947083

Epoch: 5| Step: 3
Training loss: 0.9005529284477234
Validation loss: 2.0274028880621797

Epoch: 5| Step: 4
Training loss: 1.5195069313049316
Validation loss: 2.0816829358377764

Epoch: 5| Step: 5
Training loss: 1.467581033706665
Validation loss: 2.0569550157875143

Epoch: 5| Step: 6
Training loss: 1.2661532163619995
Validation loss: 2.0195329381573583

Epoch: 5| Step: 7
Training loss: 1.362504005432129
Validation loss: 2.012160647299982

Epoch: 5| Step: 8
Training loss: 1.6938930749893188
Validation loss: 2.00932575297612

Epoch: 5| Step: 9
Training loss: 1.9235074520111084
Validation loss: 2.0726612537137923

Epoch: 5| Step: 10
Training loss: 1.1261295080184937
Validation loss: 2.059803419215705

Epoch: 391| Step: 0
Training loss: 1.4748905897140503
Validation loss: 2.0490869834858882

Epoch: 5| Step: 1
Training loss: 1.1321192979812622
Validation loss: 2.0835232978226035

Epoch: 5| Step: 2
Training loss: 1.5697132349014282
Validation loss: 2.0613840779950543

Epoch: 5| Step: 3
Training loss: 1.4888274669647217
Validation loss: 2.0369993473893855

Epoch: 5| Step: 4
Training loss: 1.5472185611724854
Validation loss: 2.0102088810295187

Epoch: 5| Step: 5
Training loss: 1.6818231344223022
Validation loss: 1.9969287815914358

Epoch: 5| Step: 6
Training loss: 1.2168104648590088
Validation loss: 2.0138404292445027

Epoch: 5| Step: 7
Training loss: 2.008134365081787
Validation loss: 2.058463555510326

Epoch: 5| Step: 8
Training loss: 1.75411856174469
Validation loss: 2.0247648005844443

Epoch: 5| Step: 9
Training loss: 1.6315749883651733
Validation loss: 2.034708402490103

Epoch: 5| Step: 10
Training loss: 1.3460193872451782
Validation loss: 2.051812905137257

Epoch: 392| Step: 0
Training loss: 1.503649115562439
Validation loss: 2.0651544588868336

Epoch: 5| Step: 1
Training loss: 1.7430912256240845
Validation loss: 2.0616619484398955

Epoch: 5| Step: 2
Training loss: 1.6851842403411865
Validation loss: 2.1014432599467616

Epoch: 5| Step: 3
Training loss: 1.0574270486831665
Validation loss: 2.0318268499066754

Epoch: 5| Step: 4
Training loss: 1.3221747875213623
Validation loss: 2.044240438809959

Epoch: 5| Step: 5
Training loss: 1.5695439577102661
Validation loss: 2.0367810392892487

Epoch: 5| Step: 6
Training loss: 1.9206184148788452
Validation loss: 2.058833973382109

Epoch: 5| Step: 7
Training loss: 1.45820951461792
Validation loss: 2.028124399082635

Epoch: 5| Step: 8
Training loss: 1.753379225730896
Validation loss: 2.0565869013468423

Epoch: 5| Step: 9
Training loss: 1.3686974048614502
Validation loss: 2.0615577966936174

Epoch: 5| Step: 10
Training loss: 1.6756714582443237
Validation loss: 2.0243245478599303

Epoch: 393| Step: 0
Training loss: 1.2794501781463623
Validation loss: 2.030620344223515

Epoch: 5| Step: 1
Training loss: 0.8666955232620239
Validation loss: 2.0336103118875974

Epoch: 5| Step: 2
Training loss: 2.2805874347686768
Validation loss: 2.0231315858902468

Epoch: 5| Step: 3
Training loss: 1.6543552875518799
Validation loss: 2.0623505961510444

Epoch: 5| Step: 4
Training loss: 1.7518119812011719
Validation loss: 1.98767654613782

Epoch: 5| Step: 5
Training loss: 1.4890046119689941
Validation loss: 2.049838383992513

Epoch: 5| Step: 6
Training loss: 1.3616068363189697
Validation loss: 2.0312734368026897

Epoch: 5| Step: 7
Training loss: 1.558761477470398
Validation loss: 2.0251361426486763

Epoch: 5| Step: 8
Training loss: 1.7641334533691406
Validation loss: 2.0232693738834833

Epoch: 5| Step: 9
Training loss: 1.6370033025741577
Validation loss: 2.0275804919581257

Epoch: 5| Step: 10
Training loss: 1.3505038022994995
Validation loss: 2.022301455979706

Epoch: 394| Step: 0
Training loss: 1.4397640228271484
Validation loss: 2.0727056200786302

Epoch: 5| Step: 1
Training loss: 1.6531391143798828
Validation loss: 2.059887724538003

Epoch: 5| Step: 2
Training loss: 2.080396890640259
Validation loss: 2.084176399374521

Epoch: 5| Step: 3
Training loss: 1.5266245603561401
Validation loss: 2.06773583222461

Epoch: 5| Step: 4
Training loss: 1.4476693868637085
Validation loss: 2.11183786648576

Epoch: 5| Step: 5
Training loss: 1.184773325920105
Validation loss: 2.0865558783213296

Epoch: 5| Step: 6
Training loss: 2.042684555053711
Validation loss: 2.0692101909268286

Epoch: 5| Step: 7
Training loss: 1.3215758800506592
Validation loss: 2.0926323847104142

Epoch: 5| Step: 8
Training loss: 1.5516901016235352
Validation loss: 2.068960794838526

Epoch: 5| Step: 9
Training loss: 1.0704591274261475
Validation loss: 2.048549423935593

Epoch: 5| Step: 10
Training loss: 1.788857340812683
Validation loss: 2.083664213457415

Epoch: 395| Step: 0
Training loss: 1.5316760540008545
Validation loss: 2.017264964759991

Epoch: 5| Step: 1
Training loss: 1.9327268600463867
Validation loss: 2.0610223585559475

Epoch: 5| Step: 2
Training loss: 1.2298740148544312
Validation loss: 2.0243923612820205

Epoch: 5| Step: 3
Training loss: 1.4753408432006836
Validation loss: 2.0182576871687368

Epoch: 5| Step: 4
Training loss: 0.9198988080024719
Validation loss: 2.0053325314675607

Epoch: 5| Step: 5
Training loss: 1.9167522192001343
Validation loss: 2.0161155628901657

Epoch: 5| Step: 6
Training loss: 2.1184701919555664
Validation loss: 2.017029329012799

Epoch: 5| Step: 7
Training loss: 1.7394813299179077
Validation loss: 2.0117438634236655

Epoch: 5| Step: 8
Training loss: 1.4555792808532715
Validation loss: 1.9851880547820882

Epoch: 5| Step: 9
Training loss: 1.160308599472046
Validation loss: 2.0169308954669583

Epoch: 5| Step: 10
Training loss: 1.5448932647705078
Validation loss: 2.054907996167419

Epoch: 396| Step: 0
Training loss: 1.7671836614608765
Validation loss: 2.018032858448644

Epoch: 5| Step: 1
Training loss: 1.5456753969192505
Validation loss: 2.02362185524356

Epoch: 5| Step: 2
Training loss: 1.8051254749298096
Validation loss: 2.0387644511397167

Epoch: 5| Step: 3
Training loss: 1.8568713665008545
Validation loss: 1.9990120831356253

Epoch: 5| Step: 4
Training loss: 0.7812591791152954
Validation loss: 2.0619944475030385

Epoch: 5| Step: 5
Training loss: 1.6210620403289795
Validation loss: 2.070058174030755

Epoch: 5| Step: 6
Training loss: 1.1394551992416382
Validation loss: 2.0730341813897573

Epoch: 5| Step: 7
Training loss: 1.8334976434707642
Validation loss: 2.0704126537487073

Epoch: 5| Step: 8
Training loss: 1.5159623622894287
Validation loss: 2.0928097771060084

Epoch: 5| Step: 9
Training loss: 1.6321748495101929
Validation loss: 2.0658216604622464

Epoch: 5| Step: 10
Training loss: 1.3141207695007324
Validation loss: 2.045204198488625

Epoch: 397| Step: 0
Training loss: 1.5765254497528076
Validation loss: 2.0519927035095873

Epoch: 5| Step: 1
Training loss: 1.7816082239151
Validation loss: 2.089052502826978

Epoch: 5| Step: 2
Training loss: 1.5027319192886353
Validation loss: 2.048970535237302

Epoch: 5| Step: 3
Training loss: 1.2272679805755615
Validation loss: 2.0721513789187194

Epoch: 5| Step: 4
Training loss: 1.962261438369751
Validation loss: 2.051945727358582

Epoch: 5| Step: 5
Training loss: 1.2849791049957275
Validation loss: 2.0597448438726444

Epoch: 5| Step: 6
Training loss: 1.3220189809799194
Validation loss: 2.0448867351778093

Epoch: 5| Step: 7
Training loss: 1.4651658535003662
Validation loss: 2.0565426285548876

Epoch: 5| Step: 8
Training loss: 1.244713544845581
Validation loss: 2.0454662025615735

Epoch: 5| Step: 9
Training loss: 1.7182865142822266
Validation loss: 2.0520981229761595

Epoch: 5| Step: 10
Training loss: 2.0821969509124756
Validation loss: 2.026597915157195

Epoch: 398| Step: 0
Training loss: 1.2924073934555054
Validation loss: 2.0377217672204457

Epoch: 5| Step: 1
Training loss: 1.421673059463501
Validation loss: 2.0460652753870976

Epoch: 5| Step: 2
Training loss: 2.1073458194732666
Validation loss: 2.0176932619464014

Epoch: 5| Step: 3
Training loss: 1.1430892944335938
Validation loss: 2.03454993360786

Epoch: 5| Step: 4
Training loss: 1.725917100906372
Validation loss: 2.0619187765224005

Epoch: 5| Step: 5
Training loss: 1.1924232244491577
Validation loss: 2.055210333998485

Epoch: 5| Step: 6
Training loss: 1.738152265548706
Validation loss: 2.02494974290171

Epoch: 5| Step: 7
Training loss: 1.4072577953338623
Validation loss: 2.0310327365834224

Epoch: 5| Step: 8
Training loss: 1.4653427600860596
Validation loss: 2.028814682396509

Epoch: 5| Step: 9
Training loss: 1.7562233209609985
Validation loss: 2.056328761962152

Epoch: 5| Step: 10
Training loss: 1.8369096517562866
Validation loss: 2.071434200450938

Epoch: 399| Step: 0
Training loss: 1.6406104564666748
Validation loss: 2.068359205799718

Epoch: 5| Step: 1
Training loss: 1.6819734573364258
Validation loss: 2.084492047627767

Epoch: 5| Step: 2
Training loss: 1.1872392892837524
Validation loss: 2.0495146141257337

Epoch: 5| Step: 3
Training loss: 1.4179832935333252
Validation loss: 2.046309756976302

Epoch: 5| Step: 4
Training loss: 1.774942398071289
Validation loss: 2.025178449128264

Epoch: 5| Step: 5
Training loss: 1.5972461700439453
Validation loss: 2.0456604829398533

Epoch: 5| Step: 6
Training loss: 1.242527723312378
Validation loss: 2.0366248789653985

Epoch: 5| Step: 7
Training loss: 1.9062068462371826
Validation loss: 2.0490571401452504

Epoch: 5| Step: 8
Training loss: 1.7066247463226318
Validation loss: 2.040882497705439

Epoch: 5| Step: 9
Training loss: 1.3541206121444702
Validation loss: 2.023700466720007

Epoch: 5| Step: 10
Training loss: 1.4444924592971802
Validation loss: 2.036319130210466

Epoch: 400| Step: 0
Training loss: 1.674371361732483
Validation loss: 2.0662648831644366

Epoch: 5| Step: 1
Training loss: 1.3085654973983765
Validation loss: 2.026751959195701

Epoch: 5| Step: 2
Training loss: 1.9886525869369507
Validation loss: 2.0332348423619426

Epoch: 5| Step: 3
Training loss: 1.2008955478668213
Validation loss: 2.0396211839491323

Epoch: 5| Step: 4
Training loss: 1.4766008853912354
Validation loss: 2.077806294605296

Epoch: 5| Step: 5
Training loss: 1.3382279872894287
Validation loss: 2.032419438003212

Epoch: 5| Step: 6
Training loss: 1.1657811403274536
Validation loss: 2.023976707971224

Epoch: 5| Step: 7
Training loss: 2.2085459232330322
Validation loss: 2.0345079155378443

Epoch: 5| Step: 8
Training loss: 1.4197800159454346
Validation loss: 2.016227058185044

Epoch: 5| Step: 9
Training loss: 1.1993690729141235
Validation loss: 2.036614998694389

Epoch: 5| Step: 10
Training loss: 1.900258183479309
Validation loss: 2.047600285981291

Epoch: 401| Step: 0
Training loss: 1.6788966655731201
Validation loss: 2.02165763737053

Epoch: 5| Step: 1
Training loss: 1.491552710533142
Validation loss: 2.024971705611034

Epoch: 5| Step: 2
Training loss: 1.6379482746124268
Validation loss: 2.0643288422656316

Epoch: 5| Step: 3
Training loss: 1.6370207071304321
Validation loss: 2.0008889167539534

Epoch: 5| Step: 4
Training loss: 1.5883376598358154
Validation loss: 1.9884931284894225

Epoch: 5| Step: 5
Training loss: 1.6343574523925781
Validation loss: 2.03507496464637

Epoch: 5| Step: 6
Training loss: 1.3054932355880737
Validation loss: 2.0232798207190728

Epoch: 5| Step: 7
Training loss: 1.3383378982543945
Validation loss: 2.0603714642986173

Epoch: 5| Step: 8
Training loss: 0.9480701684951782
Validation loss: 2.041998735038183

Epoch: 5| Step: 9
Training loss: 1.8892338275909424
Validation loss: 2.0194216620537544

Epoch: 5| Step: 10
Training loss: 1.603296160697937
Validation loss: 2.0801909392879856

Epoch: 402| Step: 0
Training loss: 1.7129628658294678
Validation loss: 2.0769696415111585

Epoch: 5| Step: 1
Training loss: 1.308762788772583
Validation loss: 2.035357031770932

Epoch: 5| Step: 2
Training loss: 1.9813095331192017
Validation loss: 2.103125459404402

Epoch: 5| Step: 3
Training loss: 1.7729604244232178
Validation loss: 2.041719695573212

Epoch: 5| Step: 4
Training loss: 1.8278214931488037
Validation loss: 2.046698060086978

Epoch: 5| Step: 5
Training loss: 1.5618889331817627
Validation loss: 2.0458259236428047

Epoch: 5| Step: 6
Training loss: 1.959097146987915
Validation loss: 2.051178455352783

Epoch: 5| Step: 7
Training loss: 1.3222296237945557
Validation loss: 2.0647928048205633

Epoch: 5| Step: 8
Training loss: 1.6039413213729858
Validation loss: 2.0176163770819224

Epoch: 5| Step: 9
Training loss: 1.1846041679382324
Validation loss: 2.0359411239624023

Epoch: 5| Step: 10
Training loss: 0.6218894124031067
Validation loss: 2.036584791316781

Epoch: 403| Step: 0
Training loss: 1.7522761821746826
Validation loss: 2.025389584161902

Epoch: 5| Step: 1
Training loss: 1.849792718887329
Validation loss: 2.066640600081413

Epoch: 5| Step: 2
Training loss: 1.22090744972229
Validation loss: 2.0144978928309616

Epoch: 5| Step: 3
Training loss: 1.3554292917251587
Validation loss: 2.0275812020865818

Epoch: 5| Step: 4
Training loss: 1.8058544397354126
Validation loss: 2.051099210657099

Epoch: 5| Step: 5
Training loss: 1.5059220790863037
Validation loss: 2.0657784618357176

Epoch: 5| Step: 6
Training loss: 1.7072536945343018
Validation loss: 2.0732378626382477

Epoch: 5| Step: 7
Training loss: 1.1159645318984985
Validation loss: 2.012578820669523

Epoch: 5| Step: 8
Training loss: 1.4508812427520752
Validation loss: 2.0319264473453647

Epoch: 5| Step: 9
Training loss: 1.2048310041427612
Validation loss: 2.0690519937904934

Epoch: 5| Step: 10
Training loss: 1.8781574964523315
Validation loss: 2.0494120351729856

Epoch: 404| Step: 0
Training loss: 1.543884515762329
Validation loss: 2.0380769621941353

Epoch: 5| Step: 1
Training loss: 1.3272227048873901
Validation loss: 2.037943673390214

Epoch: 5| Step: 2
Training loss: 1.246606707572937
Validation loss: 2.030495220615018

Epoch: 5| Step: 3
Training loss: 1.4145228862762451
Validation loss: 2.0411294096259662

Epoch: 5| Step: 4
Training loss: 1.5089712142944336
Validation loss: 2.037122466230905

Epoch: 5| Step: 5
Training loss: 1.3841787576675415
Validation loss: 2.033405201409453

Epoch: 5| Step: 6
Training loss: 2.005664348602295
Validation loss: 2.0461470978234404

Epoch: 5| Step: 7
Training loss: 1.5294373035430908
Validation loss: 2.014191448047597

Epoch: 5| Step: 8
Training loss: 1.5445200204849243
Validation loss: 2.0620668729146323

Epoch: 5| Step: 9
Training loss: 1.8733103275299072
Validation loss: 2.077130194633238

Epoch: 5| Step: 10
Training loss: 1.149167537689209
Validation loss: 2.08399659972037

Epoch: 405| Step: 0
Training loss: 1.7292064428329468
Validation loss: 2.0592318093904884

Epoch: 5| Step: 1
Training loss: 0.9112974405288696
Validation loss: 2.0512177482728036

Epoch: 5| Step: 2
Training loss: 1.276727318763733
Validation loss: 2.062578978077058

Epoch: 5| Step: 3
Training loss: 1.8644357919692993
Validation loss: 2.03268402238046

Epoch: 5| Step: 4
Training loss: 1.2879068851470947
Validation loss: 2.038585214204686

Epoch: 5| Step: 5
Training loss: 1.3111069202423096
Validation loss: 2.047185028752973

Epoch: 5| Step: 6
Training loss: 1.702409029006958
Validation loss: 2.0136962629133657

Epoch: 5| Step: 7
Training loss: 1.7399917840957642
Validation loss: 1.98833340983237

Epoch: 5| Step: 8
Training loss: 1.9210370779037476
Validation loss: 2.013543704504608

Epoch: 5| Step: 9
Training loss: 1.4193623065948486
Validation loss: 2.0357268600053686

Epoch: 5| Step: 10
Training loss: 1.8412795066833496
Validation loss: 2.0124869808073966

Epoch: 406| Step: 0
Training loss: 1.4930999279022217
Validation loss: 2.0309454394925024

Epoch: 5| Step: 1
Training loss: 1.2842636108398438
Validation loss: 2.0527069453270204

Epoch: 5| Step: 2
Training loss: 0.8380537033081055
Validation loss: 1.9919488968387726

Epoch: 5| Step: 3
Training loss: 1.7862449884414673
Validation loss: 1.9938833200803368

Epoch: 5| Step: 4
Training loss: 1.7284072637557983
Validation loss: 2.013445611922972

Epoch: 5| Step: 5
Training loss: 1.4300378561019897
Validation loss: 2.017700042775882

Epoch: 5| Step: 6
Training loss: 1.7150570154190063
Validation loss: 2.015593619756801

Epoch: 5| Step: 7
Training loss: 1.336761713027954
Validation loss: 2.0115780932928926

Epoch: 5| Step: 8
Training loss: 1.4737014770507812
Validation loss: 2.036497646762479

Epoch: 5| Step: 9
Training loss: 1.7883304357528687
Validation loss: 2.0008322192776586

Epoch: 5| Step: 10
Training loss: 2.0017311573028564
Validation loss: 2.030958362804946

Epoch: 407| Step: 0
Training loss: 1.460858941078186
Validation loss: 2.0504382938467045

Epoch: 5| Step: 1
Training loss: 1.543800711631775
Validation loss: 2.0177533190737487

Epoch: 5| Step: 2
Training loss: 1.1859873533248901
Validation loss: 2.068787419667808

Epoch: 5| Step: 3
Training loss: 1.6701055765151978
Validation loss: 2.075241961786824

Epoch: 5| Step: 4
Training loss: 2.193565845489502
Validation loss: 2.053929603228005

Epoch: 5| Step: 5
Training loss: 1.373470664024353
Validation loss: 2.056108356803976

Epoch: 5| Step: 6
Training loss: 1.0062021017074585
Validation loss: 2.0745140211556548

Epoch: 5| Step: 7
Training loss: 1.3441612720489502
Validation loss: 2.0414652773129043

Epoch: 5| Step: 8
Training loss: 1.9186973571777344
Validation loss: 2.049711106925882

Epoch: 5| Step: 9
Training loss: 1.9064487218856812
Validation loss: 2.0906405295095136

Epoch: 5| Step: 10
Training loss: 1.2456544637680054
Validation loss: 2.032677271032846

Epoch: 408| Step: 0
Training loss: 2.0769131183624268
Validation loss: 2.039531438581405

Epoch: 5| Step: 1
Training loss: 1.5356605052947998
Validation loss: 2.0079406756226734

Epoch: 5| Step: 2
Training loss: 1.1561683416366577
Validation loss: 2.0375652928506174

Epoch: 5| Step: 3
Training loss: 1.5557409524917603
Validation loss: 2.0114730429905716

Epoch: 5| Step: 4
Training loss: 1.3442293405532837
Validation loss: 2.024525416794644

Epoch: 5| Step: 5
Training loss: 1.2960294485092163
Validation loss: 2.0077326131123368

Epoch: 5| Step: 6
Training loss: 1.1950819492340088
Validation loss: 2.0263079366376324

Epoch: 5| Step: 7
Training loss: 1.8392221927642822
Validation loss: 2.0473130518390286

Epoch: 5| Step: 8
Training loss: 1.5392167568206787
Validation loss: 2.067711381502049

Epoch: 5| Step: 9
Training loss: 1.7120134830474854
Validation loss: 2.036031461531116

Epoch: 5| Step: 10
Training loss: 1.408341646194458
Validation loss: 2.0701592968356226

Epoch: 409| Step: 0
Training loss: 1.3990676403045654
Validation loss: 2.0543499659466486

Epoch: 5| Step: 1
Training loss: 1.745449423789978
Validation loss: 2.1187524744259414

Epoch: 5| Step: 2
Training loss: 1.4995372295379639
Validation loss: 2.0317626255814747

Epoch: 5| Step: 3
Training loss: 1.1681067943572998
Validation loss: 2.1023709184379986

Epoch: 5| Step: 4
Training loss: 1.7545630931854248
Validation loss: 2.0791819800612745

Epoch: 5| Step: 5
Training loss: 1.1576793193817139
Validation loss: 2.1099477775635256

Epoch: 5| Step: 6
Training loss: 1.838616132736206
Validation loss: 2.094171900903025

Epoch: 5| Step: 7
Training loss: 1.2904598712921143
Validation loss: 2.0460133860188146

Epoch: 5| Step: 8
Training loss: 1.7630847692489624
Validation loss: 2.0462793022073726

Epoch: 5| Step: 9
Training loss: 1.8472633361816406
Validation loss: 2.1099612815405733

Epoch: 5| Step: 10
Training loss: 1.4435476064682007
Validation loss: 2.0401992131305

Epoch: 410| Step: 0
Training loss: 1.5520226955413818
Validation loss: 2.039573420760452

Epoch: 5| Step: 1
Training loss: 1.3293555974960327
Validation loss: 2.046059055994916

Epoch: 5| Step: 2
Training loss: 1.8848793506622314
Validation loss: 2.016931503049789

Epoch: 5| Step: 3
Training loss: 1.4362430572509766
Validation loss: 2.024306902321436

Epoch: 5| Step: 4
Training loss: 2.074552059173584
Validation loss: 2.0431857634616155

Epoch: 5| Step: 5
Training loss: 2.1999096870422363
Validation loss: 2.0266500544804398

Epoch: 5| Step: 6
Training loss: 0.9797874689102173
Validation loss: 2.019952702265914

Epoch: 5| Step: 7
Training loss: 1.7923481464385986
Validation loss: 2.022743655789283

Epoch: 5| Step: 8
Training loss: 1.42917799949646
Validation loss: 2.01405377926365

Epoch: 5| Step: 9
Training loss: 1.1266001462936401
Validation loss: 2.018084792680638

Epoch: 5| Step: 10
Training loss: 0.97243332862854
Validation loss: 2.064602774958457

Epoch: 411| Step: 0
Training loss: 0.9573698043823242
Validation loss: 2.054454867557813

Epoch: 5| Step: 1
Training loss: 2.0082573890686035
Validation loss: 2.0519816516548075

Epoch: 5| Step: 2
Training loss: 1.8665506839752197
Validation loss: 2.004486007075156

Epoch: 5| Step: 3
Training loss: 1.3083128929138184
Validation loss: 2.0470216325534287

Epoch: 5| Step: 4
Training loss: 1.3664982318878174
Validation loss: 2.057818139753034

Epoch: 5| Step: 5
Training loss: 1.345229148864746
Validation loss: 2.04036525500718

Epoch: 5| Step: 6
Training loss: 1.7526648044586182
Validation loss: 2.065165629950903

Epoch: 5| Step: 7
Training loss: 1.2575206756591797
Validation loss: 2.0505017977888866

Epoch: 5| Step: 8
Training loss: 1.700876235961914
Validation loss: 2.0731867949167886

Epoch: 5| Step: 9
Training loss: 1.6331253051757812
Validation loss: 2.037195458207079

Epoch: 5| Step: 10
Training loss: 1.5845552682876587
Validation loss: 2.037037016243063

Epoch: 412| Step: 0
Training loss: 1.468563437461853
Validation loss: 2.0687214315578504

Epoch: 5| Step: 1
Training loss: 1.6639306545257568
Validation loss: 2.0467628894313687

Epoch: 5| Step: 2
Training loss: 1.4210093021392822
Validation loss: 2.0664778524829495

Epoch: 5| Step: 3
Training loss: 1.4517700672149658
Validation loss: 2.067776726138207

Epoch: 5| Step: 4
Training loss: 1.3478457927703857
Validation loss: 2.0090094971400436

Epoch: 5| Step: 5
Training loss: 1.2487671375274658
Validation loss: 2.0310600624289563

Epoch: 5| Step: 6
Training loss: 1.4179569482803345
Validation loss: 2.0384225614609255

Epoch: 5| Step: 7
Training loss: 1.7408740520477295
Validation loss: 2.0707632469874557

Epoch: 5| Step: 8
Training loss: 1.0347864627838135
Validation loss: 2.053794273766138

Epoch: 5| Step: 9
Training loss: 2.4199910163879395
Validation loss: 2.038667719851258

Epoch: 5| Step: 10
Training loss: 1.4061778783798218
Validation loss: 2.054005079371955

Epoch: 413| Step: 0
Training loss: 1.4248591661453247
Validation loss: 2.0789071001032347

Epoch: 5| Step: 1
Training loss: 1.6384022235870361
Validation loss: 2.0538649559020996

Epoch: 5| Step: 2
Training loss: 1.7602155208587646
Validation loss: 2.0381219848509757

Epoch: 5| Step: 3
Training loss: 1.7260210514068604
Validation loss: 2.037021739508516

Epoch: 5| Step: 4
Training loss: 1.6433483362197876
Validation loss: 2.0386019137597855

Epoch: 5| Step: 5
Training loss: 1.3211915493011475
Validation loss: 2.037060614555113

Epoch: 5| Step: 6
Training loss: 1.4135606288909912
Validation loss: 2.0335678426168298

Epoch: 5| Step: 7
Training loss: 1.5584335327148438
Validation loss: 2.0330073192555416

Epoch: 5| Step: 8
Training loss: 1.4847891330718994
Validation loss: 2.022965697832005

Epoch: 5| Step: 9
Training loss: 1.3516675233840942
Validation loss: 1.9947614503163162

Epoch: 5| Step: 10
Training loss: 1.4124373197555542
Validation loss: 2.0387461800729074

Epoch: 414| Step: 0
Training loss: 1.5766093730926514
Validation loss: 2.040273020344396

Epoch: 5| Step: 1
Training loss: 1.594175934791565
Validation loss: 2.055162299063898

Epoch: 5| Step: 2
Training loss: 1.1302707195281982
Validation loss: 2.0344191379444574

Epoch: 5| Step: 3
Training loss: 1.5033562183380127
Validation loss: 2.037028108873675

Epoch: 5| Step: 4
Training loss: 1.6639127731323242
Validation loss: 2.070614391757596

Epoch: 5| Step: 5
Training loss: 1.1940754652023315
Validation loss: 2.088263298875542

Epoch: 5| Step: 6
Training loss: 1.3664370775222778
Validation loss: 2.0702026146714405

Epoch: 5| Step: 7
Training loss: 1.3238976001739502
Validation loss: 2.0521827641353814

Epoch: 5| Step: 8
Training loss: 1.6192996501922607
Validation loss: 2.042125495531226

Epoch: 5| Step: 9
Training loss: 1.8374297618865967
Validation loss: 2.0713581744060723

Epoch: 5| Step: 10
Training loss: 1.8817322254180908
Validation loss: 2.0705429302748812

Epoch: 415| Step: 0
Training loss: 1.80343496799469
Validation loss: 2.05416472752889

Epoch: 5| Step: 1
Training loss: 1.6850707530975342
Validation loss: 2.042341196408836

Epoch: 5| Step: 2
Training loss: 1.2034350633621216
Validation loss: 2.019396217920447

Epoch: 5| Step: 3
Training loss: 1.8055015802383423
Validation loss: 1.9979965071524344

Epoch: 5| Step: 4
Training loss: 1.6944122314453125
Validation loss: 2.029074110010619

Epoch: 5| Step: 5
Training loss: 1.4428249597549438
Validation loss: 2.0380866425011748

Epoch: 5| Step: 6
Training loss: 1.0070321559906006
Validation loss: 2.037620541869953

Epoch: 5| Step: 7
Training loss: 1.2963449954986572
Validation loss: 2.029793826482629

Epoch: 5| Step: 8
Training loss: 1.6417316198349
Validation loss: 2.022308039408858

Epoch: 5| Step: 9
Training loss: 1.3418056964874268
Validation loss: 2.0623131644341255

Epoch: 5| Step: 10
Training loss: 1.5904988050460815
Validation loss: 2.032381729413104

Epoch: 416| Step: 0
Training loss: 1.148455262184143
Validation loss: 2.0722286470474733

Epoch: 5| Step: 1
Training loss: 1.0300344228744507
Validation loss: 2.047709103553526

Epoch: 5| Step: 2
Training loss: 1.565987229347229
Validation loss: 2.0331837797677643

Epoch: 5| Step: 3
Training loss: 1.830320119857788
Validation loss: 2.046522840376823

Epoch: 5| Step: 4
Training loss: 2.0099854469299316
Validation loss: 2.0556689064989806

Epoch: 5| Step: 5
Training loss: 1.4823110103607178
Validation loss: 2.0392993393764702

Epoch: 5| Step: 6
Training loss: 1.2416616678237915
Validation loss: 2.0368376995927546

Epoch: 5| Step: 7
Training loss: 1.2932811975479126
Validation loss: 2.019457649159175

Epoch: 5| Step: 8
Training loss: 2.0709481239318848
Validation loss: 2.024017163502273

Epoch: 5| Step: 9
Training loss: 1.6308534145355225
Validation loss: 2.0154916804323912

Epoch: 5| Step: 10
Training loss: 1.2135685682296753
Validation loss: 2.012151297702584

Epoch: 417| Step: 0
Training loss: 1.5335487127304077
Validation loss: 2.0327332417170205

Epoch: 5| Step: 1
Training loss: 1.55599844455719
Validation loss: 2.0363177727627497

Epoch: 5| Step: 2
Training loss: 1.4422290325164795
Validation loss: 2.02964642483701

Epoch: 5| Step: 3
Training loss: 1.0255464315414429
Validation loss: 2.0071557106510287

Epoch: 5| Step: 4
Training loss: 2.437638521194458
Validation loss: 2.0287916327035553

Epoch: 5| Step: 5
Training loss: 1.9495394229888916
Validation loss: 2.00524555483172

Epoch: 5| Step: 6
Training loss: 1.3740622997283936
Validation loss: 2.027804602858841

Epoch: 5| Step: 7
Training loss: 1.1204392910003662
Validation loss: 2.068108420218191

Epoch: 5| Step: 8
Training loss: 1.2157999277114868
Validation loss: 2.069957064044091

Epoch: 5| Step: 9
Training loss: 1.1046109199523926
Validation loss: 2.0326077258715065

Epoch: 5| Step: 10
Training loss: 1.5902594327926636
Validation loss: 2.0585301717122397

Epoch: 418| Step: 0
Training loss: 1.1855229139328003
Validation loss: 2.037790854771932

Epoch: 5| Step: 1
Training loss: 1.3381969928741455
Validation loss: 2.030566318060762

Epoch: 5| Step: 2
Training loss: 2.260204792022705
Validation loss: 2.0303959449132285

Epoch: 5| Step: 3
Training loss: 1.118469476699829
Validation loss: 2.0507346417314265

Epoch: 5| Step: 4
Training loss: 1.586247444152832
Validation loss: 2.035319697472357

Epoch: 5| Step: 5
Training loss: 1.5167356729507446
Validation loss: 2.026708363204874

Epoch: 5| Step: 6
Training loss: 1.1416116952896118
Validation loss: 2.08154784992177

Epoch: 5| Step: 7
Training loss: 1.9128879308700562
Validation loss: 2.068050479376188

Epoch: 5| Step: 8
Training loss: 1.7942168712615967
Validation loss: 2.0766396573794785

Epoch: 5| Step: 9
Training loss: 1.4456415176391602
Validation loss: 2.0210209482459613

Epoch: 5| Step: 10
Training loss: 1.1814271211624146
Validation loss: 2.045959976411635

Epoch: 419| Step: 0
Training loss: 1.3410313129425049
Validation loss: 2.0361755189075263

Epoch: 5| Step: 1
Training loss: 1.4344313144683838
Validation loss: 2.0374077186789563

Epoch: 5| Step: 2
Training loss: 1.9525916576385498
Validation loss: 2.0115642752698673

Epoch: 5| Step: 3
Training loss: 1.469454050064087
Validation loss: 2.0319324372917094

Epoch: 5| Step: 4
Training loss: 1.2418463230133057
Validation loss: 2.0317211779215003

Epoch: 5| Step: 5
Training loss: 1.160090684890747
Validation loss: 1.996978598256265

Epoch: 5| Step: 6
Training loss: 1.5843669176101685
Validation loss: 2.02206023662321

Epoch: 5| Step: 7
Training loss: 1.9335769414901733
Validation loss: 1.9891132462409236

Epoch: 5| Step: 8
Training loss: 1.8119844198226929
Validation loss: 2.0378716427792787

Epoch: 5| Step: 9
Training loss: 0.9705113172531128
Validation loss: 1.9997504834205873

Epoch: 5| Step: 10
Training loss: 1.5497201681137085
Validation loss: 2.0561815718168854

Epoch: 420| Step: 0
Training loss: 1.1524845361709595
Validation loss: 2.029892844538535

Epoch: 5| Step: 1
Training loss: 1.2024465799331665
Validation loss: 2.04536416838246

Epoch: 5| Step: 2
Training loss: 1.2874771356582642
Validation loss: 2.0603998322640695

Epoch: 5| Step: 3
Training loss: 1.513922929763794
Validation loss: 1.972378448773456

Epoch: 5| Step: 4
Training loss: 1.8236067295074463
Validation loss: 2.03894668368883

Epoch: 5| Step: 5
Training loss: 1.4865758419036865
Validation loss: 2.0510123827124156

Epoch: 5| Step: 6
Training loss: 1.6055481433868408
Validation loss: 2.0758575265125563

Epoch: 5| Step: 7
Training loss: 1.8236240148544312
Validation loss: 2.0458367075971378

Epoch: 5| Step: 8
Training loss: 1.562468409538269
Validation loss: 2.033636405903806

Epoch: 5| Step: 9
Training loss: 1.4301694631576538
Validation loss: 2.0484688666559037

Epoch: 5| Step: 10
Training loss: 1.4241193532943726
Validation loss: 2.0544493582940873

Epoch: 421| Step: 0
Training loss: 1.5284265279769897
Validation loss: 2.038187775560605

Epoch: 5| Step: 1
Training loss: 1.9360383749008179
Validation loss: 2.008848662017494

Epoch: 5| Step: 2
Training loss: 1.426485300064087
Validation loss: 2.067362339265885

Epoch: 5| Step: 3
Training loss: 1.706878423690796
Validation loss: 2.031267717320432

Epoch: 5| Step: 4
Training loss: 1.1459438800811768
Validation loss: 2.064572283016738

Epoch: 5| Step: 5
Training loss: 1.5171597003936768
Validation loss: 2.043755356983472

Epoch: 5| Step: 6
Training loss: 1.2001276016235352
Validation loss: 2.0112364061417116

Epoch: 5| Step: 7
Training loss: 1.3554490804672241
Validation loss: 2.0281915767218477

Epoch: 5| Step: 8
Training loss: 1.5925484895706177
Validation loss: 2.0067260367895967

Epoch: 5| Step: 9
Training loss: 1.6515474319458008
Validation loss: 2.0425755362356863

Epoch: 5| Step: 10
Training loss: 1.3946247100830078
Validation loss: 2.0281748899849514

Epoch: 422| Step: 0
Training loss: 1.4449740648269653
Validation loss: 2.0327910018223587

Epoch: 5| Step: 1
Training loss: 1.581261396408081
Validation loss: 1.9931023197789346

Epoch: 5| Step: 2
Training loss: 1.9335603713989258
Validation loss: 2.0577033014707666

Epoch: 5| Step: 3
Training loss: 1.1180623769760132
Validation loss: 2.0223636601560857

Epoch: 5| Step: 4
Training loss: 1.0891304016113281
Validation loss: 2.0637673870209725

Epoch: 5| Step: 5
Training loss: 1.8586562871932983
Validation loss: 2.07917712068045

Epoch: 5| Step: 6
Training loss: 0.8932543992996216
Validation loss: 2.0279569292581208

Epoch: 5| Step: 7
Training loss: 1.503186821937561
Validation loss: 2.0288940488651233

Epoch: 5| Step: 8
Training loss: 1.642401933670044
Validation loss: 2.0202792049736105

Epoch: 5| Step: 9
Training loss: 1.6707508563995361
Validation loss: 2.0274195286535446

Epoch: 5| Step: 10
Training loss: 1.61137855052948
Validation loss: 2.0602043341564875

Epoch: 423| Step: 0
Training loss: 1.7122611999511719
Validation loss: 2.0346745752519175

Epoch: 5| Step: 1
Training loss: 1.0408471822738647
Validation loss: 2.0293121414799846

Epoch: 5| Step: 2
Training loss: 1.746808648109436
Validation loss: 2.030063734259657

Epoch: 5| Step: 3
Training loss: 1.420350193977356
Validation loss: 2.0701610965113484

Epoch: 5| Step: 4
Training loss: 1.3971612453460693
Validation loss: 2.054830410147226

Epoch: 5| Step: 5
Training loss: 1.4206860065460205
Validation loss: 2.0533039774945987

Epoch: 5| Step: 6
Training loss: 1.6691694259643555
Validation loss: 2.047414323335053

Epoch: 5| Step: 7
Training loss: 1.2339955568313599
Validation loss: 2.0282603899637857

Epoch: 5| Step: 8
Training loss: 1.6362282037734985
Validation loss: 2.0688255897132297

Epoch: 5| Step: 9
Training loss: 1.7149677276611328
Validation loss: 2.0482440456267326

Epoch: 5| Step: 10
Training loss: 1.490340232849121
Validation loss: 2.006635776130102

Epoch: 424| Step: 0
Training loss: 1.7721242904663086
Validation loss: 2.0324323254246868

Epoch: 5| Step: 1
Training loss: 1.6027889251708984
Validation loss: 2.057220733293923

Epoch: 5| Step: 2
Training loss: 1.0383179187774658
Validation loss: 2.070937380995802

Epoch: 5| Step: 3
Training loss: 2.135852813720703
Validation loss: 2.028893957855881

Epoch: 5| Step: 4
Training loss: 1.2181096076965332
Validation loss: 2.03615657232141

Epoch: 5| Step: 5
Training loss: 1.1882485151290894
Validation loss: 2.024528157326483

Epoch: 5| Step: 6
Training loss: 1.6662819385528564
Validation loss: 2.0312604519628708

Epoch: 5| Step: 7
Training loss: 1.376258373260498
Validation loss: 2.062575323607332

Epoch: 5| Step: 8
Training loss: 1.4589874744415283
Validation loss: 2.018787363524078

Epoch: 5| Step: 9
Training loss: 1.637041687965393
Validation loss: 2.0497270527706353

Epoch: 5| Step: 10
Training loss: 1.3879241943359375
Validation loss: 2.0650607719216296

Epoch: 425| Step: 0
Training loss: 1.2626878023147583
Validation loss: 2.0201863768280193

Epoch: 5| Step: 1
Training loss: 1.2426159381866455
Validation loss: 2.028651083669355

Epoch: 5| Step: 2
Training loss: 1.620724081993103
Validation loss: 2.01104917833882

Epoch: 5| Step: 3
Training loss: 1.061177134513855
Validation loss: 1.9983855511552544

Epoch: 5| Step: 4
Training loss: 1.4116649627685547
Validation loss: 2.0205145036020586

Epoch: 5| Step: 5
Training loss: 1.7325775623321533
Validation loss: 2.027608322840865

Epoch: 5| Step: 6
Training loss: 1.428152322769165
Validation loss: 2.031026073681411

Epoch: 5| Step: 7
Training loss: 1.4992612600326538
Validation loss: 2.043517852342257

Epoch: 5| Step: 8
Training loss: 1.867645263671875
Validation loss: 2.0367373574164604

Epoch: 5| Step: 9
Training loss: 1.6664060354232788
Validation loss: 2.031901192921464

Epoch: 5| Step: 10
Training loss: 1.4891453981399536
Validation loss: 2.0175173615896576

Epoch: 426| Step: 0
Training loss: 1.2916905879974365
Validation loss: 2.0466125549808627

Epoch: 5| Step: 1
Training loss: 1.6351525783538818
Validation loss: 2.04647361206752

Epoch: 5| Step: 2
Training loss: 1.2949405908584595
Validation loss: 2.1050438701465564

Epoch: 5| Step: 3
Training loss: 1.5529927015304565
Validation loss: 2.04116298819101

Epoch: 5| Step: 4
Training loss: 1.837193489074707
Validation loss: 2.048427072904443

Epoch: 5| Step: 5
Training loss: 1.9647585153579712
Validation loss: 2.070651090273293

Epoch: 5| Step: 6
Training loss: 1.036106824874878
Validation loss: 2.0302185114993843

Epoch: 5| Step: 7
Training loss: 1.5867326259613037
Validation loss: 2.029307125717081

Epoch: 5| Step: 8
Training loss: 1.0932509899139404
Validation loss: 2.0431449874754875

Epoch: 5| Step: 9
Training loss: 1.5894486904144287
Validation loss: 2.0909638738119476

Epoch: 5| Step: 10
Training loss: 1.1995420455932617
Validation loss: 2.0242976616787653

Epoch: 427| Step: 0
Training loss: 1.913106918334961
Validation loss: 2.0375588734944663

Epoch: 5| Step: 1
Training loss: 1.8874428272247314
Validation loss: 2.050576917586788

Epoch: 5| Step: 2
Training loss: 1.0462236404418945
Validation loss: 2.065023245350007

Epoch: 5| Step: 3
Training loss: 1.6846965551376343
Validation loss: 2.0796679706983667

Epoch: 5| Step: 4
Training loss: 1.1486895084381104
Validation loss: 2.0728399625388523

Epoch: 5| Step: 5
Training loss: 1.6040617227554321
Validation loss: 2.053947628185313

Epoch: 5| Step: 6
Training loss: 1.2884576320648193
Validation loss: 2.057277960162009

Epoch: 5| Step: 7
Training loss: 1.1641252040863037
Validation loss: 2.102136065883021

Epoch: 5| Step: 8
Training loss: 1.7295141220092773
Validation loss: 2.0716501961472216

Epoch: 5| Step: 9
Training loss: 1.866742730140686
Validation loss: 2.0856972048359532

Epoch: 5| Step: 10
Training loss: 0.8761000633239746
Validation loss: 2.0840390664274975

Epoch: 428| Step: 0
Training loss: 1.8934853076934814
Validation loss: 2.0463523467381797

Epoch: 5| Step: 1
Training loss: 1.5254629850387573
Validation loss: 2.0555332578638548

Epoch: 5| Step: 2
Training loss: 1.7620385885238647
Validation loss: 2.0394727119835476

Epoch: 5| Step: 3
Training loss: 0.8659974932670593
Validation loss: 2.0400480916423183

Epoch: 5| Step: 4
Training loss: 1.3881757259368896
Validation loss: 2.035240650177002

Epoch: 5| Step: 5
Training loss: 2.1221492290496826
Validation loss: 2.0550894942334903

Epoch: 5| Step: 6
Training loss: 0.981114387512207
Validation loss: 2.032752395958029

Epoch: 5| Step: 7
Training loss: 1.173685073852539
Validation loss: 2.047572353834747

Epoch: 5| Step: 8
Training loss: 1.6504135131835938
Validation loss: 2.007513934566129

Epoch: 5| Step: 9
Training loss: 1.535622239112854
Validation loss: 1.9857698781515962

Epoch: 5| Step: 10
Training loss: 1.3470335006713867
Validation loss: 2.0309346798927552

Epoch: 429| Step: 0
Training loss: 1.1995737552642822
Validation loss: 2.048269614096611

Epoch: 5| Step: 1
Training loss: 1.4029017686843872
Validation loss: 2.0180520831897693

Epoch: 5| Step: 2
Training loss: 1.4875816106796265
Validation loss: 2.03465090515793

Epoch: 5| Step: 3
Training loss: 2.0308144092559814
Validation loss: 2.004973553842114

Epoch: 5| Step: 4
Training loss: 1.031736135482788
Validation loss: 2.024590890894654

Epoch: 5| Step: 5
Training loss: 1.5466023683547974
Validation loss: 2.056744121736096

Epoch: 5| Step: 6
Training loss: 2.01460599899292
Validation loss: 2.039634871226485

Epoch: 5| Step: 7
Training loss: 1.3241097927093506
Validation loss: 2.0455741715687576

Epoch: 5| Step: 8
Training loss: 1.6124531030654907
Validation loss: 2.042382171077113

Epoch: 5| Step: 9
Training loss: 1.5241092443466187
Validation loss: 2.046231551836896

Epoch: 5| Step: 10
Training loss: 1.1991422176361084
Validation loss: 2.0592414076610277

Epoch: 430| Step: 0
Training loss: 1.3651173114776611
Validation loss: 2.102734129915955

Epoch: 5| Step: 1
Training loss: 1.8197864294052124
Validation loss: 2.0708823601404824

Epoch: 5| Step: 2
Training loss: 1.0605394840240479
Validation loss: 2.0772899222630326

Epoch: 5| Step: 3
Training loss: 1.3849478960037231
Validation loss: 2.0320078224264164

Epoch: 5| Step: 4
Training loss: 1.4755651950836182
Validation loss: 2.037849392942203

Epoch: 5| Step: 5
Training loss: 1.455741286277771
Validation loss: 2.0370227060010357

Epoch: 5| Step: 6
Training loss: 1.2984977960586548
Validation loss: 2.018410744205598

Epoch: 5| Step: 7
Training loss: 1.6407579183578491
Validation loss: 2.066155274709066

Epoch: 5| Step: 8
Training loss: 1.4317244291305542
Validation loss: 2.0449767753642094

Epoch: 5| Step: 9
Training loss: 2.0990521907806396
Validation loss: 2.0245000790524226

Epoch: 5| Step: 10
Training loss: 1.2438950538635254
Validation loss: 2.0279525185144074

Epoch: 431| Step: 0
Training loss: 1.4103095531463623
Validation loss: 1.9914315772312943

Epoch: 5| Step: 1
Training loss: 1.2008203268051147
Validation loss: 2.0137866056093605

Epoch: 5| Step: 2
Training loss: 1.8583942651748657
Validation loss: 2.0135830140882924

Epoch: 5| Step: 3
Training loss: 1.1580572128295898
Validation loss: 2.0197500259645524

Epoch: 5| Step: 4
Training loss: 1.5000208616256714
Validation loss: 2.0635148120182816

Epoch: 5| Step: 5
Training loss: 1.221819281578064
Validation loss: 2.0454402303182952

Epoch: 5| Step: 6
Training loss: 1.5569546222686768
Validation loss: 2.0530703759962514

Epoch: 5| Step: 7
Training loss: 1.6103079319000244
Validation loss: 2.046543103392406

Epoch: 5| Step: 8
Training loss: 1.973839521408081
Validation loss: 2.014594634373983

Epoch: 5| Step: 9
Training loss: 0.9871162176132202
Validation loss: 2.052069030782228

Epoch: 5| Step: 10
Training loss: 1.8466951847076416
Validation loss: 2.0642037289116972

Epoch: 432| Step: 0
Training loss: 1.6098926067352295
Validation loss: 2.0901686555595806

Epoch: 5| Step: 1
Training loss: 1.771211862564087
Validation loss: 2.0393567944085724

Epoch: 5| Step: 2
Training loss: 1.5280168056488037
Validation loss: 2.0077429702205043

Epoch: 5| Step: 3
Training loss: 1.7281574010849
Validation loss: 2.0673550367355347

Epoch: 5| Step: 4
Training loss: 1.14585280418396
Validation loss: 2.067250846534647

Epoch: 5| Step: 5
Training loss: 1.8337503671646118
Validation loss: 2.0325467612153743

Epoch: 5| Step: 6
Training loss: 1.322213053703308
Validation loss: 2.0656961805077008

Epoch: 5| Step: 7
Training loss: 1.263097882270813
Validation loss: 2.0493513550809634

Epoch: 5| Step: 8
Training loss: 1.383472204208374
Validation loss: 2.0207790559337986

Epoch: 5| Step: 9
Training loss: 1.4496009349822998
Validation loss: 2.029727384608279

Epoch: 5| Step: 10
Training loss: 1.2744206190109253
Validation loss: 2.0059820657135337

Epoch: 433| Step: 0
Training loss: 1.127879023551941
Validation loss: 2.003541697737991

Epoch: 5| Step: 1
Training loss: 1.4183943271636963
Validation loss: 2.0263857662036853

Epoch: 5| Step: 2
Training loss: 1.5686615705490112
Validation loss: 2.10053849733004

Epoch: 5| Step: 3
Training loss: 1.101849913597107
Validation loss: 2.0342991903264034

Epoch: 5| Step: 4
Training loss: 1.2239890098571777
Validation loss: 2.0357676603460826

Epoch: 5| Step: 5
Training loss: 1.7643187046051025
Validation loss: 2.0125854066623154

Epoch: 5| Step: 6
Training loss: 2.097169876098633
Validation loss: 1.9951355457305908

Epoch: 5| Step: 7
Training loss: 1.4788964986801147
Validation loss: 2.0129784448172456

Epoch: 5| Step: 8
Training loss: 1.2608317136764526
Validation loss: 2.0542494955883233

Epoch: 5| Step: 9
Training loss: 1.6887264251708984
Validation loss: 1.9717258637951267

Epoch: 5| Step: 10
Training loss: 1.400111198425293
Validation loss: 2.063764302961288

Epoch: 434| Step: 0
Training loss: 1.5950000286102295
Validation loss: 2.0256235496972197

Epoch: 5| Step: 1
Training loss: 1.0242639780044556
Validation loss: 2.0093076562368744

Epoch: 5| Step: 2
Training loss: 1.0481324195861816
Validation loss: 2.0491997888011317

Epoch: 5| Step: 3
Training loss: 1.6367651224136353
Validation loss: 2.000075896581014

Epoch: 5| Step: 4
Training loss: 1.380473017692566
Validation loss: 2.0259808699289956

Epoch: 5| Step: 5
Training loss: 2.1513936519622803
Validation loss: 2.029116197298932

Epoch: 5| Step: 6
Training loss: 1.7378876209259033
Validation loss: 2.022776255043604

Epoch: 5| Step: 7
Training loss: 1.0884006023406982
Validation loss: 2.0499360612643662

Epoch: 5| Step: 8
Training loss: 1.6594387292861938
Validation loss: 2.0111800829569497

Epoch: 5| Step: 9
Training loss: 1.5591388940811157
Validation loss: 2.0709568185191

Epoch: 5| Step: 10
Training loss: 1.429179310798645
Validation loss: 2.036411367436891

Epoch: 435| Step: 0
Training loss: 0.9815003275871277
Validation loss: 2.0421975710058726

Epoch: 5| Step: 1
Training loss: 1.5487686395645142
Validation loss: 2.0087680944832425

Epoch: 5| Step: 2
Training loss: 1.6010143756866455
Validation loss: 2.0529847529626664

Epoch: 5| Step: 3
Training loss: 1.413930892944336
Validation loss: 2.032648519803119

Epoch: 5| Step: 4
Training loss: 1.575958013534546
Validation loss: 2.0581068018431306

Epoch: 5| Step: 5
Training loss: 1.4992780685424805
Validation loss: 2.0854503621337233

Epoch: 5| Step: 6
Training loss: 1.3085671663284302
Validation loss: 2.0527542816695346

Epoch: 5| Step: 7
Training loss: 1.497841238975525
Validation loss: 2.0529948203794417

Epoch: 5| Step: 8
Training loss: 1.4911905527114868
Validation loss: 2.066676478232107

Epoch: 5| Step: 9
Training loss: 1.9341001510620117
Validation loss: 2.0397556443368234

Epoch: 5| Step: 10
Training loss: 1.2463619709014893
Validation loss: 2.0362711542396137

Epoch: 436| Step: 0
Training loss: 1.4175626039505005
Validation loss: 2.0107320636831303

Epoch: 5| Step: 1
Training loss: 1.829082727432251
Validation loss: 2.02476252278974

Epoch: 5| Step: 2
Training loss: 1.3458083868026733
Validation loss: 2.0023048462406283

Epoch: 5| Step: 3
Training loss: 1.6494321823120117
Validation loss: 1.9928099904009091

Epoch: 5| Step: 4
Training loss: 1.300554871559143
Validation loss: 2.031177592533891

Epoch: 5| Step: 5
Training loss: 1.2641758918762207
Validation loss: 2.0506209391419605

Epoch: 5| Step: 6
Training loss: 1.8339723348617554
Validation loss: 2.017686443944131

Epoch: 5| Step: 7
Training loss: 1.221538782119751
Validation loss: 2.0321703469881447

Epoch: 5| Step: 8
Training loss: 0.9431301355361938
Validation loss: 2.0179492209547307

Epoch: 5| Step: 9
Training loss: 1.4178985357284546
Validation loss: 2.0432585170192104

Epoch: 5| Step: 10
Training loss: 1.8420822620391846
Validation loss: 2.0368445970678843

Epoch: 437| Step: 0
Training loss: 1.1054023504257202
Validation loss: 2.079434161545128

Epoch: 5| Step: 1
Training loss: 1.2987860441207886
Validation loss: 2.050512129260648

Epoch: 5| Step: 2
Training loss: 1.401239037513733
Validation loss: 2.0655076273026003

Epoch: 5| Step: 3
Training loss: 2.277508020401001
Validation loss: 2.049036387474306

Epoch: 5| Step: 4
Training loss: 1.601962685585022
Validation loss: 2.0390800045382593

Epoch: 5| Step: 5
Training loss: 1.6953632831573486
Validation loss: 2.0637724527748684

Epoch: 5| Step: 6
Training loss: 1.1463134288787842
Validation loss: 2.0873692176675283

Epoch: 5| Step: 7
Training loss: 1.0024224519729614
Validation loss: 2.0710346903852237

Epoch: 5| Step: 8
Training loss: 1.831480622291565
Validation loss: 2.026055484689692

Epoch: 5| Step: 9
Training loss: 1.6616008281707764
Validation loss: 2.0699677877528693

Epoch: 5| Step: 10
Training loss: 1.04664945602417
Validation loss: 2.012626886367798

Epoch: 438| Step: 0
Training loss: 1.3412336111068726
Validation loss: 2.0188930291001514

Epoch: 5| Step: 1
Training loss: 1.4472100734710693
Validation loss: 2.020857331573322

Epoch: 5| Step: 2
Training loss: 1.5870882272720337
Validation loss: 1.997276044660999

Epoch: 5| Step: 3
Training loss: 1.7407310009002686
Validation loss: 2.0245704522696872

Epoch: 5| Step: 4
Training loss: 1.5998982191085815
Validation loss: 2.0059621128984677

Epoch: 5| Step: 5
Training loss: 1.562625527381897
Validation loss: 2.058552271576338

Epoch: 5| Step: 6
Training loss: 1.3458689451217651
Validation loss: 2.057424645270071

Epoch: 5| Step: 7
Training loss: 1.1662757396697998
Validation loss: 2.0553687105896654

Epoch: 5| Step: 8
Training loss: 1.6111568212509155
Validation loss: 2.05260205781588

Epoch: 5| Step: 9
Training loss: 1.794556975364685
Validation loss: 2.0631347189667406

Epoch: 5| Step: 10
Training loss: 1.0909138917922974
Validation loss: 2.0378027808281685

Epoch: 439| Step: 0
Training loss: 1.4475088119506836
Validation loss: 2.0329411645089426

Epoch: 5| Step: 1
Training loss: 1.0688786506652832
Validation loss: 2.0465601618571947

Epoch: 5| Step: 2
Training loss: 1.4884767532348633
Validation loss: 2.02126209966598

Epoch: 5| Step: 3
Training loss: 1.232006549835205
Validation loss: 2.031970270218388

Epoch: 5| Step: 4
Training loss: 1.2877165079116821
Validation loss: 2.002296563117735

Epoch: 5| Step: 5
Training loss: 1.6343390941619873
Validation loss: 1.9956504260340044

Epoch: 5| Step: 6
Training loss: 1.2967314720153809
Validation loss: 2.025040436816472

Epoch: 5| Step: 7
Training loss: 1.347163438796997
Validation loss: 2.0519895143406366

Epoch: 5| Step: 8
Training loss: 1.7452623844146729
Validation loss: 2.019211498639917

Epoch: 5| Step: 9
Training loss: 1.1480834484100342
Validation loss: 2.0477189966427383

Epoch: 5| Step: 10
Training loss: 2.490795135498047
Validation loss: 2.0248826062807472

Epoch: 440| Step: 0
Training loss: 1.603309988975525
Validation loss: 2.022367310780351

Epoch: 5| Step: 1
Training loss: 1.7733443975448608
Validation loss: 2.0472184252995316

Epoch: 5| Step: 2
Training loss: 1.1444189548492432
Validation loss: 2.0623440101582515

Epoch: 5| Step: 3
Training loss: 1.6800594329833984
Validation loss: 2.0520359880180767

Epoch: 5| Step: 4
Training loss: 1.5865519046783447
Validation loss: 2.0422299241506927

Epoch: 5| Step: 5
Training loss: 1.159070611000061
Validation loss: 2.0223299649453934

Epoch: 5| Step: 6
Training loss: 1.8647091388702393
Validation loss: 2.06557136197244

Epoch: 5| Step: 7
Training loss: 1.3030614852905273
Validation loss: 1.9977484864573325

Epoch: 5| Step: 8
Training loss: 1.752349853515625
Validation loss: 2.0360112600429083

Epoch: 5| Step: 9
Training loss: 0.9890872240066528
Validation loss: 2.049496866041614

Epoch: 5| Step: 10
Training loss: 1.2245993614196777
Validation loss: 1.9815718614926903

Epoch: 441| Step: 0
Training loss: 1.3080710172653198
Validation loss: 2.0182535391981884

Epoch: 5| Step: 1
Training loss: 1.531214952468872
Validation loss: 2.0239000499889417

Epoch: 5| Step: 2
Training loss: 1.6929798126220703
Validation loss: 2.085624623042281

Epoch: 5| Step: 3
Training loss: 1.3311207294464111
Validation loss: 2.003776340074437

Epoch: 5| Step: 4
Training loss: 1.2956167459487915
Validation loss: 2.021696902090503

Epoch: 5| Step: 5
Training loss: 1.738091230392456
Validation loss: 2.0023750964031426

Epoch: 5| Step: 6
Training loss: 1.5814213752746582
Validation loss: 2.0322945540951145

Epoch: 5| Step: 7
Training loss: 1.2022777795791626
Validation loss: 2.030105677984094

Epoch: 5| Step: 8
Training loss: 1.5782746076583862
Validation loss: 2.012855878440283

Epoch: 5| Step: 9
Training loss: 1.4953839778900146
Validation loss: 2.0285703815439695

Epoch: 5| Step: 10
Training loss: 1.6868276596069336
Validation loss: 2.0360302361108924

Epoch: 442| Step: 0
Training loss: 1.786964774131775
Validation loss: 2.035272290629725

Epoch: 5| Step: 1
Training loss: 1.7349437475204468
Validation loss: 2.077229248580112

Epoch: 5| Step: 2
Training loss: 1.2448370456695557
Validation loss: 2.122207321146483

Epoch: 5| Step: 3
Training loss: 1.5091989040374756
Validation loss: 2.0586579897070445

Epoch: 5| Step: 4
Training loss: 1.4595345258712769
Validation loss: 2.1046230382816766

Epoch: 5| Step: 5
Training loss: 1.3938764333724976
Validation loss: 2.0327990926722044

Epoch: 5| Step: 6
Training loss: 1.219948649406433
Validation loss: 2.0303616562197284

Epoch: 5| Step: 7
Training loss: 1.5817855596542358
Validation loss: 2.0226894886262956

Epoch: 5| Step: 8
Training loss: 1.4039092063903809
Validation loss: 2.03271472325889

Epoch: 5| Step: 9
Training loss: 1.174013614654541
Validation loss: 2.0286899587159515

Epoch: 5| Step: 10
Training loss: 1.691642165184021
Validation loss: 2.0497936997362363

Epoch: 443| Step: 0
Training loss: 1.351628065109253
Validation loss: 1.9985067306026336

Epoch: 5| Step: 1
Training loss: 2.005629062652588
Validation loss: 2.0358904946234917

Epoch: 5| Step: 2
Training loss: 1.1564452648162842
Validation loss: 2.0014848068196285

Epoch: 5| Step: 3
Training loss: 1.706385850906372
Validation loss: 2.0395810911732335

Epoch: 5| Step: 4
Training loss: 1.690982460975647
Validation loss: 2.067130399006669

Epoch: 5| Step: 5
Training loss: 1.4784311056137085
Validation loss: 2.0192183909877652

Epoch: 5| Step: 6
Training loss: 1.4411739110946655
Validation loss: 2.0458781488480104

Epoch: 5| Step: 7
Training loss: 1.0887283086776733
Validation loss: 2.0075093110402427

Epoch: 5| Step: 8
Training loss: 1.2080131769180298
Validation loss: 2.0408288022523284

Epoch: 5| Step: 9
Training loss: 1.2539132833480835
Validation loss: 2.0170004521646807

Epoch: 5| Step: 10
Training loss: 1.5546170473098755
Validation loss: 2.0197460933398177

Epoch: 444| Step: 0
Training loss: 1.2938672304153442
Validation loss: 2.0348834914545857

Epoch: 5| Step: 1
Training loss: 0.8414070010185242
Validation loss: 2.0225787265326387

Epoch: 5| Step: 2
Training loss: 1.8367935419082642
Validation loss: 2.0328019203678256

Epoch: 5| Step: 3
Training loss: 2.0816867351531982
Validation loss: 2.0264808516348563

Epoch: 5| Step: 4
Training loss: 1.5991594791412354
Validation loss: 2.0096464798014653

Epoch: 5| Step: 5
Training loss: 1.658582091331482
Validation loss: 2.0297277409543275

Epoch: 5| Step: 6
Training loss: 1.3310619592666626
Validation loss: 2.0143574309605423

Epoch: 5| Step: 7
Training loss: 1.502616286277771
Validation loss: 2.0565993990949405

Epoch: 5| Step: 8
Training loss: 1.326289415359497
Validation loss: 2.0408221983140513

Epoch: 5| Step: 9
Training loss: 1.185331106185913
Validation loss: 2.012930086863938

Epoch: 5| Step: 10
Training loss: 1.456260085105896
Validation loss: 2.054376417590726

Epoch: 445| Step: 0
Training loss: 1.2153109312057495
Validation loss: 2.055738486269469

Epoch: 5| Step: 1
Training loss: 1.2891366481781006
Validation loss: 2.058602789396881

Epoch: 5| Step: 2
Training loss: 1.4155536890029907
Validation loss: 2.0843091087956584

Epoch: 5| Step: 3
Training loss: 1.2796270847320557
Validation loss: 2.0512631580393803

Epoch: 5| Step: 4
Training loss: 1.598247766494751
Validation loss: 2.045812006919615

Epoch: 5| Step: 5
Training loss: 1.6531028747558594
Validation loss: 2.023612868401312

Epoch: 5| Step: 6
Training loss: 1.9011363983154297
Validation loss: 2.0430945555369058

Epoch: 5| Step: 7
Training loss: 1.6097023487091064
Validation loss: 2.019232007765001

Epoch: 5| Step: 8
Training loss: 1.157151460647583
Validation loss: 2.0648593518041793

Epoch: 5| Step: 9
Training loss: 1.414902687072754
Validation loss: 2.027037589780746

Epoch: 5| Step: 10
Training loss: 1.4190493822097778
Validation loss: 2.034125179372808

Epoch: 446| Step: 0
Training loss: 1.315773367881775
Validation loss: 2.0172148776310745

Epoch: 5| Step: 1
Training loss: 2.088064193725586
Validation loss: 2.030076492217279

Epoch: 5| Step: 2
Training loss: 1.3724381923675537
Validation loss: 2.018513807686426

Epoch: 5| Step: 3
Training loss: 0.9648427963256836
Validation loss: 2.041062007668198

Epoch: 5| Step: 4
Training loss: 1.5018987655639648
Validation loss: 1.9920460959916473

Epoch: 5| Step: 5
Training loss: 2.0773379802703857
Validation loss: 2.019114064913924

Epoch: 5| Step: 6
Training loss: 1.4398800134658813
Validation loss: 2.035912468869199

Epoch: 5| Step: 7
Training loss: 1.4689624309539795
Validation loss: 2.0284357442650744

Epoch: 5| Step: 8
Training loss: 1.5551515817642212
Validation loss: 2.034808684420842

Epoch: 5| Step: 9
Training loss: 1.283247709274292
Validation loss: 2.0183940177322715

Epoch: 5| Step: 10
Training loss: 0.7213705778121948
Validation loss: 2.017499716051163

Epoch: 447| Step: 0
Training loss: 1.1987669467926025
Validation loss: 2.0338988124683337

Epoch: 5| Step: 1
Training loss: 1.5810564756393433
Validation loss: 2.0365509435694706

Epoch: 5| Step: 2
Training loss: 1.5334618091583252
Validation loss: 2.0470373797160324

Epoch: 5| Step: 3
Training loss: 1.3621023893356323
Validation loss: 2.0182046992804414

Epoch: 5| Step: 4
Training loss: 1.6307920217514038
Validation loss: 2.0447572431256695

Epoch: 5| Step: 5
Training loss: 1.3483952283859253
Validation loss: 2.047349770863851

Epoch: 5| Step: 6
Training loss: 1.1871602535247803
Validation loss: 2.024115588075371

Epoch: 5| Step: 7
Training loss: 1.453338384628296
Validation loss: 2.059689969144842

Epoch: 5| Step: 8
Training loss: 1.9179493188858032
Validation loss: 2.041917621448476

Epoch: 5| Step: 9
Training loss: 1.4237502813339233
Validation loss: 2.061386428853517

Epoch: 5| Step: 10
Training loss: 1.2905439138412476
Validation loss: 2.0607677172589045

Epoch: 448| Step: 0
Training loss: 1.5332486629486084
Validation loss: 2.046708873523179

Epoch: 5| Step: 1
Training loss: 1.7225303649902344
Validation loss: 2.0793857715463124

Epoch: 5| Step: 2
Training loss: 1.5903782844543457
Validation loss: 2.0363552198615125

Epoch: 5| Step: 3
Training loss: 1.0397688150405884
Validation loss: 2.0697406158652356

Epoch: 5| Step: 4
Training loss: 1.4120173454284668
Validation loss: 2.0271520050623084

Epoch: 5| Step: 5
Training loss: 1.4248340129852295
Validation loss: 2.0525874373733357

Epoch: 5| Step: 6
Training loss: 1.5826445817947388
Validation loss: 2.0127561271831556

Epoch: 5| Step: 7
Training loss: 1.1590852737426758
Validation loss: 2.0246039923801216

Epoch: 5| Step: 8
Training loss: 1.2051002979278564
Validation loss: 2.0031543841926

Epoch: 5| Step: 9
Training loss: 1.43606698513031
Validation loss: 2.0154771625354724

Epoch: 5| Step: 10
Training loss: 1.8485872745513916
Validation loss: 2.0613695447162916

Epoch: 449| Step: 0
Training loss: 1.5346189737319946
Validation loss: 2.0426874135130193

Epoch: 5| Step: 1
Training loss: 1.4750499725341797
Validation loss: 2.0673860208962553

Epoch: 5| Step: 2
Training loss: 1.1333603858947754
Validation loss: 2.008953188055305

Epoch: 5| Step: 3
Training loss: 1.5186947584152222
Validation loss: 2.0372568894458074

Epoch: 5| Step: 4
Training loss: 1.5451767444610596
Validation loss: 2.034614747570407

Epoch: 5| Step: 5
Training loss: 1.197678565979004
Validation loss: 2.058198400723037

Epoch: 5| Step: 6
Training loss: 1.5247374773025513
Validation loss: 2.015622264595442

Epoch: 5| Step: 7
Training loss: 1.637211561203003
Validation loss: 1.9952969986905333

Epoch: 5| Step: 8
Training loss: 1.6201794147491455
Validation loss: 2.0090796742387997

Epoch: 5| Step: 9
Training loss: 1.2843072414398193
Validation loss: 2.0365179751508977

Epoch: 5| Step: 10
Training loss: 1.4133988618850708
Validation loss: 2.0435478712922786

Epoch: 450| Step: 0
Training loss: 1.3000743389129639
Validation loss: 2.045440064963474

Epoch: 5| Step: 1
Training loss: 1.7228367328643799
Validation loss: 2.0192842278429257

Epoch: 5| Step: 2
Training loss: 1.306051254272461
Validation loss: 2.0362629031622284

Epoch: 5| Step: 3
Training loss: 1.1068729162216187
Validation loss: 2.0406283229909916

Epoch: 5| Step: 4
Training loss: 1.5373632907867432
Validation loss: 2.065189843536705

Epoch: 5| Step: 5
Training loss: 1.3829675912857056
Validation loss: 2.0732152692733274

Epoch: 5| Step: 6
Training loss: 1.6900049448013306
Validation loss: 2.0542484880775533

Epoch: 5| Step: 7
Training loss: 1.9343335628509521
Validation loss: 2.0728936400464786

Epoch: 5| Step: 8
Training loss: 1.7454525232315063
Validation loss: 2.09163902395515

Epoch: 5| Step: 9
Training loss: 0.988426685333252
Validation loss: 2.083785669777983

Epoch: 5| Step: 10
Training loss: 1.4952356815338135
Validation loss: 2.0393546191594933

Epoch: 451| Step: 0
Training loss: 1.577562928199768
Validation loss: 2.035997936802526

Epoch: 5| Step: 1
Training loss: 1.8310925960540771
Validation loss: 2.0528217746365454

Epoch: 5| Step: 2
Training loss: 0.8118681907653809
Validation loss: 2.002722783755231

Epoch: 5| Step: 3
Training loss: 1.7249151468276978
Validation loss: 2.0880617544215214

Epoch: 5| Step: 4
Training loss: 1.7237024307250977
Validation loss: 2.0595744963615172

Epoch: 5| Step: 5
Training loss: 1.5936118364334106
Validation loss: 2.001778878191466

Epoch: 5| Step: 6
Training loss: 1.137817621231079
Validation loss: 2.0252415159697175

Epoch: 5| Step: 7
Training loss: 1.452373743057251
Validation loss: 2.021980874000057

Epoch: 5| Step: 8
Training loss: 1.5573917627334595
Validation loss: 2.0040943148315593

Epoch: 5| Step: 9
Training loss: 1.6360933780670166
Validation loss: 2.0545289452357958

Epoch: 5| Step: 10
Training loss: 0.7210679650306702
Validation loss: 2.035539614256992

Epoch: 452| Step: 0
Training loss: 2.192638397216797
Validation loss: 2.04707940419515

Epoch: 5| Step: 1
Training loss: 1.7518211603164673
Validation loss: 2.0340826870292745

Epoch: 5| Step: 2
Training loss: 1.5899358987808228
Validation loss: 2.0238540877578077

Epoch: 5| Step: 3
Training loss: 0.7427009344100952
Validation loss: 2.0422544838279806

Epoch: 5| Step: 4
Training loss: 1.5652345418930054
Validation loss: 2.0557974897405153

Epoch: 5| Step: 5
Training loss: 1.4449794292449951
Validation loss: 2.0134002367655435

Epoch: 5| Step: 6
Training loss: 1.1797473430633545
Validation loss: 1.9881144697948168

Epoch: 5| Step: 7
Training loss: 1.8765588998794556
Validation loss: 2.024964404362504

Epoch: 5| Step: 8
Training loss: 1.0678608417510986
Validation loss: 2.018722600834344

Epoch: 5| Step: 9
Training loss: 1.285529375076294
Validation loss: 2.0419939487211165

Epoch: 5| Step: 10
Training loss: 1.2349803447723389
Validation loss: 2.0366731677004086

Epoch: 453| Step: 0
Training loss: 1.2041982412338257
Validation loss: 2.0650273702477895

Epoch: 5| Step: 1
Training loss: 1.2107062339782715
Validation loss: 2.0505816269946355

Epoch: 5| Step: 2
Training loss: 2.239234685897827
Validation loss: 2.0695425592442995

Epoch: 5| Step: 3
Training loss: 1.886792540550232
Validation loss: 2.0393364109018797

Epoch: 5| Step: 4
Training loss: 1.5523484945297241
Validation loss: 2.0511615673700967

Epoch: 5| Step: 5
Training loss: 1.5422661304473877
Validation loss: 2.0573024647210234

Epoch: 5| Step: 6
Training loss: 1.210876226425171
Validation loss: 2.0005319759409916

Epoch: 5| Step: 7
Training loss: 1.5964049100875854
Validation loss: 2.06116234999831

Epoch: 5| Step: 8
Training loss: 1.0410019159317017
Validation loss: 2.0306080566939486

Epoch: 5| Step: 9
Training loss: 1.2985873222351074
Validation loss: 2.026249808649863

Epoch: 5| Step: 10
Training loss: 1.0966532230377197
Validation loss: 2.061895555065524

Epoch: 454| Step: 0
Training loss: 1.2371981143951416
Validation loss: 2.0133821707899853

Epoch: 5| Step: 1
Training loss: 1.594972014427185
Validation loss: 2.024226147641418

Epoch: 5| Step: 2
Training loss: 1.1016358137130737
Validation loss: 1.9825772393134333

Epoch: 5| Step: 3
Training loss: 1.1085186004638672
Validation loss: 2.0297689284047773

Epoch: 5| Step: 4
Training loss: 1.3403313159942627
Validation loss: 2.0331144435431368

Epoch: 5| Step: 5
Training loss: 1.1964668035507202
Validation loss: 2.0273965661243727

Epoch: 5| Step: 6
Training loss: 1.5176470279693604
Validation loss: 2.0543975791623517

Epoch: 5| Step: 7
Training loss: 1.5720288753509521
Validation loss: 2.0288172204007386

Epoch: 5| Step: 8
Training loss: 1.805690050125122
Validation loss: 2.072307382860491

Epoch: 5| Step: 9
Training loss: 1.6454277038574219
Validation loss: 2.0371080137068227

Epoch: 5| Step: 10
Training loss: 1.6682195663452148
Validation loss: 2.0329558759607296

Epoch: 455| Step: 0
Training loss: 1.7802371978759766
Validation loss: 2.0128782667139524

Epoch: 5| Step: 1
Training loss: 1.6885144710540771
Validation loss: 2.003061250973773

Epoch: 5| Step: 2
Training loss: 1.6512725353240967
Validation loss: 2.050703940852996

Epoch: 5| Step: 3
Training loss: 1.0723180770874023
Validation loss: 2.048581611725592

Epoch: 5| Step: 4
Training loss: 1.700445532798767
Validation loss: 2.0464127166296846

Epoch: 5| Step: 5
Training loss: 1.7002813816070557
Validation loss: 2.010529000272033

Epoch: 5| Step: 6
Training loss: 1.351559042930603
Validation loss: 1.9923491452329902

Epoch: 5| Step: 7
Training loss: 1.5553613901138306
Validation loss: 2.023532857177078

Epoch: 5| Step: 8
Training loss: 1.4980251789093018
Validation loss: 2.0655701955159507

Epoch: 5| Step: 9
Training loss: 0.799338161945343
Validation loss: 2.082593587137038

Epoch: 5| Step: 10
Training loss: 0.8819224834442139
Validation loss: 2.0527164090064263

Epoch: 456| Step: 0
Training loss: 1.4269717931747437
Validation loss: 2.0267975330352783

Epoch: 5| Step: 1
Training loss: 1.152034044265747
Validation loss: 2.047964847216042

Epoch: 5| Step: 2
Training loss: 1.154273271560669
Validation loss: 2.0809365446849535

Epoch: 5| Step: 3
Training loss: 1.2848401069641113
Validation loss: 2.023703367479386

Epoch: 5| Step: 4
Training loss: 1.713888168334961
Validation loss: 2.0642269939504643

Epoch: 5| Step: 5
Training loss: 1.0327357053756714
Validation loss: 2.0391946095292286

Epoch: 5| Step: 6
Training loss: 1.4645450115203857
Validation loss: 2.065247586978379

Epoch: 5| Step: 7
Training loss: 1.5547152757644653
Validation loss: 2.04086636471492

Epoch: 5| Step: 8
Training loss: 2.3410303592681885
Validation loss: 1.9868698709754533

Epoch: 5| Step: 9
Training loss: 1.4139199256896973
Validation loss: 2.042853673299154

Epoch: 5| Step: 10
Training loss: 1.1982421875
Validation loss: 2.042447508022349

Epoch: 457| Step: 0
Training loss: 1.0907437801361084
Validation loss: 2.0332628962814168

Epoch: 5| Step: 1
Training loss: 1.335426926612854
Validation loss: 2.0390641791846162

Epoch: 5| Step: 2
Training loss: 1.7900196313858032
Validation loss: 1.9754282095099007

Epoch: 5| Step: 3
Training loss: 1.548466444015503
Validation loss: 2.0179828597653295

Epoch: 5| Step: 4
Training loss: 1.73285710811615
Validation loss: 2.0139778916553785

Epoch: 5| Step: 5
Training loss: 1.4557263851165771
Validation loss: 2.0030231783466954

Epoch: 5| Step: 6
Training loss: 2.2602734565734863
Validation loss: 2.0320516658085648

Epoch: 5| Step: 7
Training loss: 0.9993935823440552
Validation loss: 2.0163823148255706

Epoch: 5| Step: 8
Training loss: 1.3241034746170044
Validation loss: 2.011617002948638

Epoch: 5| Step: 9
Training loss: 1.0650211572647095
Validation loss: 2.087103215597009

Epoch: 5| Step: 10
Training loss: 1.400465488433838
Validation loss: 2.039827287838023

Epoch: 458| Step: 0
Training loss: 1.3557931184768677
Validation loss: 2.0650178745228756

Epoch: 5| Step: 1
Training loss: 1.164923071861267
Validation loss: 2.054769016081287

Epoch: 5| Step: 2
Training loss: 1.3876724243164062
Validation loss: 2.074141190898034

Epoch: 5| Step: 3
Training loss: 0.7919788360595703
Validation loss: 2.048142771567068

Epoch: 5| Step: 4
Training loss: 1.2673269510269165
Validation loss: 2.0328011743484007

Epoch: 5| Step: 5
Training loss: 2.015453815460205
Validation loss: 1.9969322822427238

Epoch: 5| Step: 6
Training loss: 1.0933748483657837
Validation loss: 2.0843674546928814

Epoch: 5| Step: 7
Training loss: 1.94353449344635
Validation loss: 2.016084260838006

Epoch: 5| Step: 8
Training loss: 1.7602760791778564
Validation loss: 2.048275206678657

Epoch: 5| Step: 9
Training loss: 1.2755677700042725
Validation loss: 2.0569946483899186

Epoch: 5| Step: 10
Training loss: 1.8883512020111084
Validation loss: 2.028142475312756

Epoch: 459| Step: 0
Training loss: 1.0043494701385498
Validation loss: 2.0661699054061726

Epoch: 5| Step: 1
Training loss: 1.1028854846954346
Validation loss: 2.0323763073131604

Epoch: 5| Step: 2
Training loss: 2.0966525077819824
Validation loss: 2.0179878460463656

Epoch: 5| Step: 3
Training loss: 1.0440393686294556
Validation loss: 2.0243804659894717

Epoch: 5| Step: 4
Training loss: 1.1704744100570679
Validation loss: 2.009870239483413

Epoch: 5| Step: 5
Training loss: 2.3303120136260986
Validation loss: 2.0206258463603195

Epoch: 5| Step: 6
Training loss: 1.4246301651000977
Validation loss: 2.000499633050734

Epoch: 5| Step: 7
Training loss: 1.4071338176727295
Validation loss: 2.014612918258995

Epoch: 5| Step: 8
Training loss: 1.0225266218185425
Validation loss: 2.0361351300311346

Epoch: 5| Step: 9
Training loss: 1.3290445804595947
Validation loss: 2.0314270296404437

Epoch: 5| Step: 10
Training loss: 1.971393346786499
Validation loss: 2.0157898908020346

Epoch: 460| Step: 0
Training loss: 1.2654234170913696
Validation loss: 2.023376146952311

Epoch: 5| Step: 1
Training loss: 1.380797028541565
Validation loss: 2.0513060182653446

Epoch: 5| Step: 2
Training loss: 1.9331514835357666
Validation loss: 2.0619799936971357

Epoch: 5| Step: 3
Training loss: 1.1469902992248535
Validation loss: 2.030505585414107

Epoch: 5| Step: 4
Training loss: 1.4965999126434326
Validation loss: 2.099271289763912

Epoch: 5| Step: 5
Training loss: 1.5826539993286133
Validation loss: 2.080022983653571

Epoch: 5| Step: 6
Training loss: 1.0722301006317139
Validation loss: 2.0498304918248165

Epoch: 5| Step: 7
Training loss: 2.0528149604797363
Validation loss: 2.029578758824256

Epoch: 5| Step: 8
Training loss: 1.5358383655548096
Validation loss: 2.0787812202207503

Epoch: 5| Step: 9
Training loss: 1.5069974660873413
Validation loss: 2.039164391897058

Epoch: 5| Step: 10
Training loss: 0.7848368883132935
Validation loss: 2.031251891966789

Epoch: 461| Step: 0
Training loss: 1.9065948724746704
Validation loss: 2.0480485090645413

Epoch: 5| Step: 1
Training loss: 1.5762859582901
Validation loss: 2.0191646365709204

Epoch: 5| Step: 2
Training loss: 1.4630377292633057
Validation loss: 2.0000160124994095

Epoch: 5| Step: 3
Training loss: 1.4879519939422607
Validation loss: 2.0453936310224634

Epoch: 5| Step: 4
Training loss: 1.5792019367218018
Validation loss: 2.0049983891107703

Epoch: 5| Step: 5
Training loss: 1.3309941291809082
Validation loss: 2.0226986664597706

Epoch: 5| Step: 6
Training loss: 1.407366156578064
Validation loss: 2.0314275398049304

Epoch: 5| Step: 7
Training loss: 1.3381346464157104
Validation loss: 2.0417850555912143

Epoch: 5| Step: 8
Training loss: 1.3851159811019897
Validation loss: 2.0495658446383733

Epoch: 5| Step: 9
Training loss: 1.080310583114624
Validation loss: 1.968698775896462

Epoch: 5| Step: 10
Training loss: 1.430620551109314
Validation loss: 2.0107952779339207

Epoch: 462| Step: 0
Training loss: 1.434800386428833
Validation loss: 2.0315454570196008

Epoch: 5| Step: 1
Training loss: 1.8394603729248047
Validation loss: 2.0002071754906767

Epoch: 5| Step: 2
Training loss: 1.4958219528198242
Validation loss: 2.024223591691704

Epoch: 5| Step: 3
Training loss: 1.1769644021987915
Validation loss: 2.0135541756947837

Epoch: 5| Step: 4
Training loss: 1.607330560684204
Validation loss: 2.0265487496570875

Epoch: 5| Step: 5
Training loss: 1.0979647636413574
Validation loss: 2.064822571251982

Epoch: 5| Step: 6
Training loss: 1.457247018814087
Validation loss: 2.049022252841662

Epoch: 5| Step: 7
Training loss: 1.8162485361099243
Validation loss: 2.070281513275639

Epoch: 5| Step: 8
Training loss: 1.0956850051879883
Validation loss: 2.038627742439188

Epoch: 5| Step: 9
Training loss: 1.2776023149490356
Validation loss: 2.0445081905652116

Epoch: 5| Step: 10
Training loss: 1.6189906597137451
Validation loss: 2.0573447417187434

Epoch: 463| Step: 0
Training loss: 0.95880126953125
Validation loss: 2.0608636794551725

Epoch: 5| Step: 1
Training loss: 1.672294020652771
Validation loss: 2.0481311967295985

Epoch: 5| Step: 2
Training loss: 1.842952013015747
Validation loss: 2.0198134453065935

Epoch: 5| Step: 3
Training loss: 1.8832515478134155
Validation loss: 2.0026879566971973

Epoch: 5| Step: 4
Training loss: 1.6154263019561768
Validation loss: 2.0408146945379113

Epoch: 5| Step: 5
Training loss: 1.1038706302642822
Validation loss: 1.9886873152948195

Epoch: 5| Step: 6
Training loss: 1.1975958347320557
Validation loss: 1.9734823050037507

Epoch: 5| Step: 7
Training loss: 1.250888705253601
Validation loss: 2.0599025064899075

Epoch: 5| Step: 8
Training loss: 1.0463087558746338
Validation loss: 2.0208504353800127

Epoch: 5| Step: 9
Training loss: 1.5135066509246826
Validation loss: 2.0200261813338085

Epoch: 5| Step: 10
Training loss: 1.9760226011276245
Validation loss: 1.973365601672921

Epoch: 464| Step: 0
Training loss: 1.0514857769012451
Validation loss: 2.0292749327998005

Epoch: 5| Step: 1
Training loss: 1.6965545415878296
Validation loss: 2.114479798142628

Epoch: 5| Step: 2
Training loss: 1.4941047430038452
Validation loss: 2.032306231478209

Epoch: 5| Step: 3
Training loss: 1.6031417846679688
Validation loss: 2.039884264751147

Epoch: 5| Step: 4
Training loss: 2.1636836528778076
Validation loss: 2.0879367525859545

Epoch: 5| Step: 5
Training loss: 1.366544246673584
Validation loss: 2.1053630792966453

Epoch: 5| Step: 6
Training loss: 1.506630778312683
Validation loss: 2.1061034202575684

Epoch: 5| Step: 7
Training loss: 1.3559218645095825
Validation loss: 2.074893569433561

Epoch: 5| Step: 8
Training loss: 1.4285987615585327
Validation loss: 2.0436794680933796

Epoch: 5| Step: 9
Training loss: 1.3092039823532104
Validation loss: 2.0676491286164973

Epoch: 5| Step: 10
Training loss: 0.9830704927444458
Validation loss: 2.0435426606926868

Epoch: 465| Step: 0
Training loss: 1.0210093259811401
Validation loss: 2.0537798097056728

Epoch: 5| Step: 1
Training loss: 1.238615870475769
Validation loss: 2.009680392921612

Epoch: 5| Step: 2
Training loss: 1.7626320123672485
Validation loss: 2.0072200208581905

Epoch: 5| Step: 3
Training loss: 1.2038602828979492
Validation loss: 2.015412951028475

Epoch: 5| Step: 4
Training loss: 1.3604522943496704
Validation loss: 2.019266305431243

Epoch: 5| Step: 5
Training loss: 1.7738252878189087
Validation loss: 2.047064527388542

Epoch: 5| Step: 6
Training loss: 1.4212497472763062
Validation loss: 1.999360776716663

Epoch: 5| Step: 7
Training loss: 1.0227309465408325
Validation loss: 1.9944882008337206

Epoch: 5| Step: 8
Training loss: 1.5146162509918213
Validation loss: 2.022920144501553

Epoch: 5| Step: 9
Training loss: 1.2144137620925903
Validation loss: 2.008770114632063

Epoch: 5| Step: 10
Training loss: 2.2455620765686035
Validation loss: 2.057311309281216

Epoch: 466| Step: 0
Training loss: 1.1581103801727295
Validation loss: 2.026617528289877

Epoch: 5| Step: 1
Training loss: 1.0976282358169556
Validation loss: 2.0462752516551683

Epoch: 5| Step: 2
Training loss: 1.5621923208236694
Validation loss: 2.065157401946283

Epoch: 5| Step: 3
Training loss: 1.5041345357894897
Validation loss: 2.0633641724945395

Epoch: 5| Step: 4
Training loss: 1.3868951797485352
Validation loss: 2.0563103434860066

Epoch: 5| Step: 5
Training loss: 1.1977431774139404
Validation loss: 2.0442113927615586

Epoch: 5| Step: 6
Training loss: 1.5902010202407837
Validation loss: 2.0294890326838337

Epoch: 5| Step: 7
Training loss: 1.4364726543426514
Validation loss: 2.061322327583067

Epoch: 5| Step: 8
Training loss: 1.5383272171020508
Validation loss: 2.061567041181749

Epoch: 5| Step: 9
Training loss: 1.1760696172714233
Validation loss: 2.005487386898328

Epoch: 5| Step: 10
Training loss: 2.220984935760498
Validation loss: 2.022473230156847

Epoch: 467| Step: 0
Training loss: 1.242826223373413
Validation loss: 2.007384752714506

Epoch: 5| Step: 1
Training loss: 1.7191922664642334
Validation loss: 1.9843481381734211

Epoch: 5| Step: 2
Training loss: 1.4258077144622803
Validation loss: 2.06070291098728

Epoch: 5| Step: 3
Training loss: 1.4457015991210938
Validation loss: 2.0270809409438924

Epoch: 5| Step: 4
Training loss: 1.403469443321228
Validation loss: 2.029838864521314

Epoch: 5| Step: 5
Training loss: 1.5718977451324463
Validation loss: 2.026635067437285

Epoch: 5| Step: 6
Training loss: 1.3323032855987549
Validation loss: 2.047876304195773

Epoch: 5| Step: 7
Training loss: 1.6866832971572876
Validation loss: 2.0889989099194928

Epoch: 5| Step: 8
Training loss: 1.3353551626205444
Validation loss: 2.0457769055520334

Epoch: 5| Step: 9
Training loss: 1.2958234548568726
Validation loss: 2.0448321232231716

Epoch: 5| Step: 10
Training loss: 1.5512864589691162
Validation loss: 2.0427414730031

Epoch: 468| Step: 0
Training loss: 1.6664555072784424
Validation loss: 2.0208410396370837

Epoch: 5| Step: 1
Training loss: 1.3693267107009888
Validation loss: 1.9921618200117541

Epoch: 5| Step: 2
Training loss: 1.0379449129104614
Validation loss: 2.0618267597690707

Epoch: 5| Step: 3
Training loss: 1.3082034587860107
Validation loss: 2.0268420750094998

Epoch: 5| Step: 4
Training loss: 1.4482885599136353
Validation loss: 2.0293907580837125

Epoch: 5| Step: 5
Training loss: 1.3641676902770996
Validation loss: 2.0368158830109464

Epoch: 5| Step: 6
Training loss: 1.4662320613861084
Validation loss: 2.0419971430173485

Epoch: 5| Step: 7
Training loss: 1.9196579456329346
Validation loss: 2.0401553377028434

Epoch: 5| Step: 8
Training loss: 1.6327297687530518
Validation loss: 1.9788355186421385

Epoch: 5| Step: 9
Training loss: 1.167533278465271
Validation loss: 1.969962038019652

Epoch: 5| Step: 10
Training loss: 1.2827152013778687
Validation loss: 2.0092373483924457

Epoch: 469| Step: 0
Training loss: 1.1638591289520264
Validation loss: 2.0342557276448896

Epoch: 5| Step: 1
Training loss: 1.2069652080535889
Validation loss: 2.0168896516164145

Epoch: 5| Step: 2
Training loss: 1.679022192955017
Validation loss: 2.0369865919954036

Epoch: 5| Step: 3
Training loss: 0.8954576253890991
Validation loss: 1.9942525509865052

Epoch: 5| Step: 4
Training loss: 1.286007285118103
Validation loss: 2.039348094694076

Epoch: 5| Step: 5
Training loss: 1.633591890335083
Validation loss: 2.074904359796996

Epoch: 5| Step: 6
Training loss: 1.601976752281189
Validation loss: 2.061011222101027

Epoch: 5| Step: 7
Training loss: 1.7334398031234741
Validation loss: 2.053885213790401

Epoch: 5| Step: 8
Training loss: 1.6326453685760498
Validation loss: 2.0886118988836966

Epoch: 5| Step: 9
Training loss: 1.5618112087249756
Validation loss: 2.109749697869824

Epoch: 5| Step: 10
Training loss: 1.244148850440979
Validation loss: 2.09168162140795

Epoch: 470| Step: 0
Training loss: 1.6520729064941406
Validation loss: 2.076771077289376

Epoch: 5| Step: 1
Training loss: 1.130326271057129
Validation loss: 2.013884593081731

Epoch: 5| Step: 2
Training loss: 1.164882779121399
Validation loss: 2.0256978645119617

Epoch: 5| Step: 3
Training loss: 1.0264149904251099
Validation loss: 2.043629624510324

Epoch: 5| Step: 4
Training loss: 1.6140117645263672
Validation loss: 2.0280291521421043

Epoch: 5| Step: 5
Training loss: 1.7945778369903564
Validation loss: 2.041611517629316

Epoch: 5| Step: 6
Training loss: 1.2113574743270874
Validation loss: 2.0201551491214382

Epoch: 5| Step: 7
Training loss: 1.5002691745758057
Validation loss: 2.0269889293178434

Epoch: 5| Step: 8
Training loss: 1.5123926401138306
Validation loss: 1.9995869590390114

Epoch: 5| Step: 9
Training loss: 1.4468994140625
Validation loss: 2.040076909526702

Epoch: 5| Step: 10
Training loss: 1.491553783416748
Validation loss: 2.02196769304173

Epoch: 471| Step: 0
Training loss: 1.5660947561264038
Validation loss: 2.061611447283017

Epoch: 5| Step: 1
Training loss: 1.7651474475860596
Validation loss: 1.9746006278581516

Epoch: 5| Step: 2
Training loss: 1.2493252754211426
Validation loss: 2.0293113711059734

Epoch: 5| Step: 3
Training loss: 1.097701907157898
Validation loss: 2.0310478518086095

Epoch: 5| Step: 4
Training loss: 1.4687578678131104
Validation loss: 2.049093900188323

Epoch: 5| Step: 5
Training loss: 1.605068564414978
Validation loss: 2.0179774222835416

Epoch: 5| Step: 6
Training loss: 1.5356956720352173
Validation loss: 2.0614800248094785

Epoch: 5| Step: 7
Training loss: 1.197458267211914
Validation loss: 2.0168851293543333

Epoch: 5| Step: 8
Training loss: 1.3846007585525513
Validation loss: 2.0583036971348587

Epoch: 5| Step: 9
Training loss: 1.1174894571304321
Validation loss: 2.0149262156537784

Epoch: 5| Step: 10
Training loss: 1.4841394424438477
Validation loss: 2.038149409396674

Epoch: 472| Step: 0
Training loss: 1.3612098693847656
Validation loss: 2.0536310659941805

Epoch: 5| Step: 1
Training loss: 1.3575897216796875
Validation loss: 2.012925555629115

Epoch: 5| Step: 2
Training loss: 1.2124742269515991
Validation loss: 2.043679944930538

Epoch: 5| Step: 3
Training loss: 1.6936609745025635
Validation loss: 2.0485267562250935

Epoch: 5| Step: 4
Training loss: 1.3095152378082275
Validation loss: 2.01638763694353

Epoch: 5| Step: 5
Training loss: 1.2932407855987549
Validation loss: 2.0333103082513295

Epoch: 5| Step: 6
Training loss: 1.418182373046875
Validation loss: 2.009244680404663

Epoch: 5| Step: 7
Training loss: 1.7207962274551392
Validation loss: 2.0040266334369616

Epoch: 5| Step: 8
Training loss: 1.8575408458709717
Validation loss: 2.023339186945269

Epoch: 5| Step: 9
Training loss: 0.8889514207839966
Validation loss: 2.00583057249746

Epoch: 5| Step: 10
Training loss: 1.3561475276947021
Validation loss: 2.0392917176728607

Epoch: 473| Step: 0
Training loss: 1.706425428390503
Validation loss: 2.0801458384401057

Epoch: 5| Step: 1
Training loss: 1.4917854070663452
Validation loss: 2.0585805651962117

Epoch: 5| Step: 2
Training loss: 1.1198657751083374
Validation loss: 2.0613271959366335

Epoch: 5| Step: 3
Training loss: 1.0574787855148315
Validation loss: 2.042448651406073

Epoch: 5| Step: 4
Training loss: 1.2886359691619873
Validation loss: 2.028996424008441

Epoch: 5| Step: 5
Training loss: 1.6178566217422485
Validation loss: 2.0293848347920243

Epoch: 5| Step: 6
Training loss: 1.964145302772522
Validation loss: 2.0001264361925024

Epoch: 5| Step: 7
Training loss: 1.3995062112808228
Validation loss: 2.0331401965951406

Epoch: 5| Step: 8
Training loss: 1.397015929222107
Validation loss: 2.0027229170645438

Epoch: 5| Step: 9
Training loss: 1.244928002357483
Validation loss: 2.0336191936205794

Epoch: 5| Step: 10
Training loss: 1.3126587867736816
Validation loss: 2.0551358781835085

Epoch: 474| Step: 0
Training loss: 1.7619483470916748
Validation loss: 2.0217815240224204

Epoch: 5| Step: 1
Training loss: 1.6169935464859009
Validation loss: 2.0214062044697423

Epoch: 5| Step: 2
Training loss: 1.0084559917449951
Validation loss: 2.0527335264349498

Epoch: 5| Step: 3
Training loss: 1.431867003440857
Validation loss: 2.0256843733531174

Epoch: 5| Step: 4
Training loss: 1.5070782899856567
Validation loss: 2.011148429686023

Epoch: 5| Step: 5
Training loss: 1.49006187915802
Validation loss: 1.9950181822622977

Epoch: 5| Step: 6
Training loss: 1.3261446952819824
Validation loss: 2.021804842897641

Epoch: 5| Step: 7
Training loss: 1.468724012374878
Validation loss: 2.0165057233584824

Epoch: 5| Step: 8
Training loss: 1.6146752834320068
Validation loss: 2.0188617744753437

Epoch: 5| Step: 9
Training loss: 1.1426911354064941
Validation loss: 2.0112753401520433

Epoch: 5| Step: 10
Training loss: 1.3496118783950806
Validation loss: 2.059843401755056

Epoch: 475| Step: 0
Training loss: 1.5394032001495361
Validation loss: 2.0276530993882047

Epoch: 5| Step: 1
Training loss: 2.010690212249756
Validation loss: 2.050355721545476

Epoch: 5| Step: 2
Training loss: 0.8928963541984558
Validation loss: 2.0822859297516527

Epoch: 5| Step: 3
Training loss: 0.7820450663566589
Validation loss: 2.0629594531110538

Epoch: 5| Step: 4
Training loss: 1.6553142070770264
Validation loss: 2.063974570202571

Epoch: 5| Step: 5
Training loss: 1.874732255935669
Validation loss: 1.991621014892414

Epoch: 5| Step: 6
Training loss: 1.7783963680267334
Validation loss: 2.034425607291601

Epoch: 5| Step: 7
Training loss: 1.1581881046295166
Validation loss: 2.064482501758042

Epoch: 5| Step: 8
Training loss: 1.327680230140686
Validation loss: 2.050001491782486

Epoch: 5| Step: 9
Training loss: 0.9365269541740417
Validation loss: 2.0477030225979385

Epoch: 5| Step: 10
Training loss: 1.4146568775177002
Validation loss: 2.043323004117576

Epoch: 476| Step: 0
Training loss: 1.505934476852417
Validation loss: 2.053772036747266

Epoch: 5| Step: 1
Training loss: 1.4698299169540405
Validation loss: 2.0424379276972946

Epoch: 5| Step: 2
Training loss: 1.2893123626708984
Validation loss: 2.0443738352867866

Epoch: 5| Step: 3
Training loss: 1.1031821966171265
Validation loss: 1.9943251596984042

Epoch: 5| Step: 4
Training loss: 1.5877530574798584
Validation loss: 2.086255919548773

Epoch: 5| Step: 5
Training loss: 1.6924797296524048
Validation loss: 2.0566545122413227

Epoch: 5| Step: 6
Training loss: 1.3114991188049316
Validation loss: 2.0204946469235163

Epoch: 5| Step: 7
Training loss: 1.3026673793792725
Validation loss: 2.0235481351934452

Epoch: 5| Step: 8
Training loss: 1.614809274673462
Validation loss: 2.012861692777244

Epoch: 5| Step: 9
Training loss: 1.3253357410430908
Validation loss: 2.0426438264949347

Epoch: 5| Step: 10
Training loss: 1.1918489933013916
Validation loss: 2.0157728349008868

Epoch: 477| Step: 0
Training loss: 1.3413803577423096
Validation loss: 2.0458039827244257

Epoch: 5| Step: 1
Training loss: 0.8223782777786255
Validation loss: 2.045977238685854

Epoch: 5| Step: 2
Training loss: 1.4261780977249146
Validation loss: 2.0674777723127797

Epoch: 5| Step: 3
Training loss: 1.615469217300415
Validation loss: 2.0632776893595213

Epoch: 5| Step: 4
Training loss: 1.610074758529663
Validation loss: 2.0888905384207286

Epoch: 5| Step: 5
Training loss: 1.0857250690460205
Validation loss: 2.0492469085160123

Epoch: 5| Step: 6
Training loss: 1.6907374858856201
Validation loss: 2.0784271481216594

Epoch: 5| Step: 7
Training loss: 1.5791242122650146
Validation loss: 2.077224459699405

Epoch: 5| Step: 8
Training loss: 0.9190799593925476
Validation loss: 2.0246737567327355

Epoch: 5| Step: 9
Training loss: 1.9676872491836548
Validation loss: 2.027336118041828

Epoch: 5| Step: 10
Training loss: 1.4330798387527466
Validation loss: 2.0092614799417476

Epoch: 478| Step: 0
Training loss: 1.476763367652893
Validation loss: 2.007580239285705

Epoch: 5| Step: 1
Training loss: 2.080686092376709
Validation loss: 2.037996776642338

Epoch: 5| Step: 2
Training loss: 0.8497352600097656
Validation loss: 2.0320402358167913

Epoch: 5| Step: 3
Training loss: 1.5997910499572754
Validation loss: 2.0441654651395735

Epoch: 5| Step: 4
Training loss: 1.1114609241485596
Validation loss: 2.048326059054303

Epoch: 5| Step: 5
Training loss: 1.6164897680282593
Validation loss: 2.0146927487465645

Epoch: 5| Step: 6
Training loss: 1.050649881362915
Validation loss: 2.026730296432331

Epoch: 5| Step: 7
Training loss: 0.9831789135932922
Validation loss: 2.0379361157776206

Epoch: 5| Step: 8
Training loss: 1.5545769929885864
Validation loss: 2.0201493719572663

Epoch: 5| Step: 9
Training loss: 1.0498781204223633
Validation loss: 2.044218019772601

Epoch: 5| Step: 10
Training loss: 2.0673015117645264
Validation loss: 2.0612098606683875

Epoch: 479| Step: 0
Training loss: 1.145642638206482
Validation loss: 2.0148452212733607

Epoch: 5| Step: 1
Training loss: 1.0462907552719116
Validation loss: 2.0638034779538392

Epoch: 5| Step: 2
Training loss: 1.1513460874557495
Validation loss: 2.025957821517862

Epoch: 5| Step: 3
Training loss: 2.250544548034668
Validation loss: 2.046660843715873

Epoch: 5| Step: 4
Training loss: 1.6349990367889404
Validation loss: 2.0925821642721854

Epoch: 5| Step: 5
Training loss: 1.9197170734405518
Validation loss: 2.0363593755229825

Epoch: 5| Step: 6
Training loss: 1.1491180658340454
Validation loss: 2.067700957739225

Epoch: 5| Step: 7
Training loss: 1.3215935230255127
Validation loss: 2.0728195636503157

Epoch: 5| Step: 8
Training loss: 1.3781044483184814
Validation loss: 2.0287758265772173

Epoch: 5| Step: 9
Training loss: 1.321868658065796
Validation loss: 2.0129176801250828

Epoch: 5| Step: 10
Training loss: 1.0276576280593872
Validation loss: 2.084241162064255

Epoch: 480| Step: 0
Training loss: 1.3958454132080078
Validation loss: 2.0328877536199426

Epoch: 5| Step: 1
Training loss: 1.9977861642837524
Validation loss: 2.080654002005054

Epoch: 5| Step: 2
Training loss: 1.714630365371704
Validation loss: 2.0597398358006633

Epoch: 5| Step: 3
Training loss: 1.3647539615631104
Validation loss: 1.991695612989446

Epoch: 5| Step: 4
Training loss: 1.1368751525878906
Validation loss: 2.011020665527672

Epoch: 5| Step: 5
Training loss: 1.804242730140686
Validation loss: 2.015603606418897

Epoch: 5| Step: 6
Training loss: 1.1057976484298706
Validation loss: 2.058003535834692

Epoch: 5| Step: 7
Training loss: 1.316194772720337
Validation loss: 2.0485533770694526

Epoch: 5| Step: 8
Training loss: 0.6026865839958191
Validation loss: 2.0605751570834907

Epoch: 5| Step: 9
Training loss: 1.650437593460083
Validation loss: 2.0122606421029694

Epoch: 5| Step: 10
Training loss: 1.3307586908340454
Validation loss: 1.9819155944290983

Epoch: 481| Step: 0
Training loss: 1.572685956954956
Validation loss: 1.9780226676694808

Epoch: 5| Step: 1
Training loss: 1.0594959259033203
Validation loss: 2.020191031117593

Epoch: 5| Step: 2
Training loss: 1.5774343013763428
Validation loss: 2.034579033492714

Epoch: 5| Step: 3
Training loss: 1.2620270252227783
Validation loss: 2.0200239907028856

Epoch: 5| Step: 4
Training loss: 1.0296955108642578
Validation loss: 2.0249815705001994

Epoch: 5| Step: 5
Training loss: 1.6364772319793701
Validation loss: 1.9963104699247627

Epoch: 5| Step: 6
Training loss: 1.3870441913604736
Validation loss: 2.0134379504829325

Epoch: 5| Step: 7
Training loss: 1.3389151096343994
Validation loss: 2.0205604440422467

Epoch: 5| Step: 8
Training loss: 1.7762172222137451
Validation loss: 2.0107513986608034

Epoch: 5| Step: 9
Training loss: 1.3869874477386475
Validation loss: 2.070903075638638

Epoch: 5| Step: 10
Training loss: 1.5374727249145508
Validation loss: 2.060637608651192

Epoch: 482| Step: 0
Training loss: 1.2949881553649902
Validation loss: 2.0236963072130756

Epoch: 5| Step: 1
Training loss: 2.09033203125
Validation loss: 2.0616173487837597

Epoch: 5| Step: 2
Training loss: 0.8311300277709961
Validation loss: 2.0597694996864564

Epoch: 5| Step: 3
Training loss: 1.289831519126892
Validation loss: 2.0434758509359052

Epoch: 5| Step: 4
Training loss: 1.5018465518951416
Validation loss: 2.0276810340983893

Epoch: 5| Step: 5
Training loss: 1.275141954421997
Validation loss: 2.003327379944504

Epoch: 5| Step: 6
Training loss: 1.5707260370254517
Validation loss: 2.010360265290865

Epoch: 5| Step: 7
Training loss: 1.3661677837371826
Validation loss: 2.0192042140550512

Epoch: 5| Step: 8
Training loss: 1.3089656829833984
Validation loss: 2.005759823706842

Epoch: 5| Step: 9
Training loss: 1.1841952800750732
Validation loss: 2.0272149808945192

Epoch: 5| Step: 10
Training loss: 1.5156949758529663
Validation loss: 2.012697030139226

Epoch: 483| Step: 0
Training loss: 1.4313958883285522
Validation loss: 2.003308424385645

Epoch: 5| Step: 1
Training loss: 1.387776255607605
Validation loss: 2.047425575153802

Epoch: 5| Step: 2
Training loss: 1.5492979288101196
Validation loss: 1.9860093516688193

Epoch: 5| Step: 3
Training loss: 1.3629446029663086
Validation loss: 2.011158010011078

Epoch: 5| Step: 4
Training loss: 1.3850959539413452
Validation loss: 2.0430980267063266

Epoch: 5| Step: 5
Training loss: 1.3062584400177002
Validation loss: 2.0280247272983676

Epoch: 5| Step: 6
Training loss: 1.5603611469268799
Validation loss: 2.008409082248647

Epoch: 5| Step: 7
Training loss: 1.5108277797698975
Validation loss: 2.0330532007319952

Epoch: 5| Step: 8
Training loss: 1.0161707401275635
Validation loss: 2.004792700531662

Epoch: 5| Step: 9
Training loss: 1.0018436908721924
Validation loss: 2.0098655377664874

Epoch: 5| Step: 10
Training loss: 1.573729157447815
Validation loss: 2.019053841149935

Epoch: 484| Step: 0
Training loss: 1.2575467824935913
Validation loss: 2.035236350951656

Epoch: 5| Step: 1
Training loss: 1.4846559762954712
Validation loss: 2.0591378519611974

Epoch: 5| Step: 2
Training loss: 1.2998530864715576
Validation loss: 2.058228854210146

Epoch: 5| Step: 3
Training loss: 1.6414244174957275
Validation loss: 2.043393931081218

Epoch: 5| Step: 4
Training loss: 0.9364549517631531
Validation loss: 2.08725651361609

Epoch: 5| Step: 5
Training loss: 1.6580308675765991
Validation loss: 2.040463932098881

Epoch: 5| Step: 6
Training loss: 1.4652049541473389
Validation loss: 2.0505775097877748

Epoch: 5| Step: 7
Training loss: 1.2039871215820312
Validation loss: 2.018263493814776

Epoch: 5| Step: 8
Training loss: 1.208083152770996
Validation loss: 2.006475164044288

Epoch: 5| Step: 9
Training loss: 1.1458745002746582
Validation loss: 2.031815448114949

Epoch: 5| Step: 10
Training loss: 1.8982012271881104
Validation loss: 2.009850994233162

Epoch: 485| Step: 0
Training loss: 1.6058681011199951
Validation loss: 1.9838845088917723

Epoch: 5| Step: 1
Training loss: 1.17319917678833
Validation loss: 2.031693950776131

Epoch: 5| Step: 2
Training loss: 1.2969309091567993
Validation loss: 1.9894521121055848

Epoch: 5| Step: 3
Training loss: 0.7002291679382324
Validation loss: 1.9767949196600145

Epoch: 5| Step: 4
Training loss: 1.4325538873672485
Validation loss: 2.093719249130577

Epoch: 5| Step: 5
Training loss: 1.1880261898040771
Validation loss: 2.0719152419797835

Epoch: 5| Step: 6
Training loss: 1.4070355892181396
Validation loss: 2.080461555911649

Epoch: 5| Step: 7
Training loss: 1.408315658569336
Validation loss: 2.0582903585126324

Epoch: 5| Step: 8
Training loss: 1.8822791576385498
Validation loss: 2.048171451014857

Epoch: 5| Step: 9
Training loss: 0.9846118092536926
Validation loss: 2.062897810371973

Epoch: 5| Step: 10
Training loss: 2.2507290840148926
Validation loss: 2.079090272226641

Epoch: 486| Step: 0
Training loss: 1.2225733995437622
Validation loss: 2.039135520176221

Epoch: 5| Step: 1
Training loss: 1.2948267459869385
Validation loss: 2.0143252841887938

Epoch: 5| Step: 2
Training loss: 1.4235477447509766
Validation loss: 2.0192037359360726

Epoch: 5| Step: 3
Training loss: 1.2517077922821045
Validation loss: 2.021075826819225

Epoch: 5| Step: 4
Training loss: 1.881800651550293
Validation loss: 1.991531390015797

Epoch: 5| Step: 5
Training loss: 1.1993507146835327
Validation loss: 2.031928280348419

Epoch: 5| Step: 6
Training loss: 1.5642039775848389
Validation loss: 2.017688751220703

Epoch: 5| Step: 7
Training loss: 1.3688158988952637
Validation loss: 2.01957300145139

Epoch: 5| Step: 8
Training loss: 1.3175568580627441
Validation loss: 2.0055095111170123

Epoch: 5| Step: 9
Training loss: 1.071939468383789
Validation loss: 2.0234467085971626

Epoch: 5| Step: 10
Training loss: 1.4188780784606934
Validation loss: 2.0800519348472677

Epoch: 487| Step: 0
Training loss: 1.6192439794540405
Validation loss: 2.050152809389176

Epoch: 5| Step: 1
Training loss: 1.74741530418396
Validation loss: 2.0052186776232976

Epoch: 5| Step: 2
Training loss: 0.6950403451919556
Validation loss: 2.0425441931652766

Epoch: 5| Step: 3
Training loss: 1.4586620330810547
Validation loss: 2.0094396555295555

Epoch: 5| Step: 4
Training loss: 1.2542921304702759
Validation loss: 2.013265743050524

Epoch: 5| Step: 5
Training loss: 2.0118584632873535
Validation loss: 2.0101812552380305

Epoch: 5| Step: 6
Training loss: 1.493316888809204
Validation loss: 2.006761961085822

Epoch: 5| Step: 7
Training loss: 1.0601955652236938
Validation loss: 2.046558590345485

Epoch: 5| Step: 8
Training loss: 1.3079675436019897
Validation loss: 2.068146439008815

Epoch: 5| Step: 9
Training loss: 1.830275535583496
Validation loss: 2.009257347353043

Epoch: 5| Step: 10
Training loss: 0.7082799673080444
Validation loss: 2.0486830383218746

Epoch: 488| Step: 0
Training loss: 1.5414676666259766
Validation loss: 2.0414961832825855

Epoch: 5| Step: 1
Training loss: 1.3542401790618896
Validation loss: 2.0215588128694923

Epoch: 5| Step: 2
Training loss: 1.6162999868392944
Validation loss: 2.0183109109119703

Epoch: 5| Step: 3
Training loss: 1.507289171218872
Validation loss: 2.0154731414651357

Epoch: 5| Step: 4
Training loss: 1.2279636859893799
Validation loss: 2.0305705480678107

Epoch: 5| Step: 5
Training loss: 0.9994668960571289
Validation loss: 1.9867503694308701

Epoch: 5| Step: 6
Training loss: 1.1447551250457764
Validation loss: 2.025138041024567

Epoch: 5| Step: 7
Training loss: 1.037025809288025
Validation loss: 2.033158189506941

Epoch: 5| Step: 8
Training loss: 1.039808988571167
Validation loss: 2.0178935322710263

Epoch: 5| Step: 9
Training loss: 1.8135173320770264
Validation loss: 2.0041536695213726

Epoch: 5| Step: 10
Training loss: 1.935808777809143
Validation loss: 2.014809382859097

Epoch: 489| Step: 0
Training loss: 1.3478667736053467
Validation loss: 2.0016389149491505

Epoch: 5| Step: 1
Training loss: 1.7372472286224365
Validation loss: 2.0302189268091673

Epoch: 5| Step: 2
Training loss: 1.5582722425460815
Validation loss: 2.0286741436168714

Epoch: 5| Step: 3
Training loss: 1.313166618347168
Validation loss: 2.0189133010884768

Epoch: 5| Step: 4
Training loss: 1.1080009937286377
Validation loss: 1.9724381675002396

Epoch: 5| Step: 5
Training loss: 1.446669340133667
Validation loss: 2.018229753740372

Epoch: 5| Step: 6
Training loss: 1.4582362174987793
Validation loss: 2.0610056692554104

Epoch: 5| Step: 7
Training loss: 1.191895842552185
Validation loss: 2.032825896816869

Epoch: 5| Step: 8
Training loss: 1.51707923412323
Validation loss: 2.033517519632975

Epoch: 5| Step: 9
Training loss: 1.6124293804168701
Validation loss: 2.0517473297734417

Epoch: 5| Step: 10
Training loss: 0.762636661529541
Validation loss: 2.078933027482802

Epoch: 490| Step: 0
Training loss: 1.0853346586227417
Validation loss: 2.0631085749595397

Epoch: 5| Step: 1
Training loss: 1.6530721187591553
Validation loss: 2.069701571618357

Epoch: 5| Step: 2
Training loss: 1.3063995838165283
Validation loss: 2.0950080040962464

Epoch: 5| Step: 3
Training loss: 1.1697821617126465
Validation loss: 2.055943677502294

Epoch: 5| Step: 4
Training loss: 1.4765815734863281
Validation loss: 2.077892391912399

Epoch: 5| Step: 5
Training loss: 1.7372729778289795
Validation loss: 2.039281857910977

Epoch: 5| Step: 6
Training loss: 1.7062898874282837
Validation loss: 2.0197935732462073

Epoch: 5| Step: 7
Training loss: 1.6406818628311157
Validation loss: 2.0297962914231005

Epoch: 5| Step: 8
Training loss: 1.4885607957839966
Validation loss: 2.0412951092566214

Epoch: 5| Step: 9
Training loss: 1.1385818719863892
Validation loss: 2.022680071092421

Epoch: 5| Step: 10
Training loss: 0.7371153831481934
Validation loss: 2.027327314499886

Epoch: 491| Step: 0
Training loss: 0.92433100938797
Validation loss: 1.9654581367328603

Epoch: 5| Step: 1
Training loss: 1.6535375118255615
Validation loss: 2.0268056264487644

Epoch: 5| Step: 2
Training loss: 1.6257820129394531
Validation loss: 2.0164191479324014

Epoch: 5| Step: 3
Training loss: 1.2819803953170776
Validation loss: 2.0335744504005677

Epoch: 5| Step: 4
Training loss: 1.2784746885299683
Validation loss: 1.9843810014827277

Epoch: 5| Step: 5
Training loss: 1.0767983198165894
Validation loss: 2.0041158173673894

Epoch: 5| Step: 6
Training loss: 1.6226590871810913
Validation loss: 2.021060279620591

Epoch: 5| Step: 7
Training loss: 1.3311574459075928
Validation loss: 2.0897964713394

Epoch: 5| Step: 8
Training loss: 1.6916675567626953
Validation loss: 2.0557042193669144

Epoch: 5| Step: 9
Training loss: 0.9965553283691406
Validation loss: 2.0507980328734203

Epoch: 5| Step: 10
Training loss: 1.6475920677185059
Validation loss: 2.046334466626567

Epoch: 492| Step: 0
Training loss: 1.038521409034729
Validation loss: 2.072777639153183

Epoch: 5| Step: 1
Training loss: 1.5426081418991089
Validation loss: 2.0477581870171333

Epoch: 5| Step: 2
Training loss: 1.2294507026672363
Validation loss: 2.0313428268637708

Epoch: 5| Step: 3
Training loss: 1.1110429763793945
Validation loss: 2.0728127161661782

Epoch: 5| Step: 4
Training loss: 1.433245062828064
Validation loss: 2.018073393452552

Epoch: 5| Step: 5
Training loss: 1.300652265548706
Validation loss: 2.048823029764237

Epoch: 5| Step: 6
Training loss: 1.4552608728408813
Validation loss: 1.9907970466921407

Epoch: 5| Step: 7
Training loss: 1.7545801401138306
Validation loss: 2.0328054133281914

Epoch: 5| Step: 8
Training loss: 1.2995426654815674
Validation loss: 2.0299955696187992

Epoch: 5| Step: 9
Training loss: 1.6415138244628906
Validation loss: 2.020999821283484

Epoch: 5| Step: 10
Training loss: 1.3576197624206543
Validation loss: 2.0655893048932477

Epoch: 493| Step: 0
Training loss: 1.510507345199585
Validation loss: 2.0093136641287033

Epoch: 5| Step: 1
Training loss: 1.2923070192337036
Validation loss: 1.9892256644464308

Epoch: 5| Step: 2
Training loss: 1.6102901697158813
Validation loss: 2.009956953346088

Epoch: 5| Step: 3
Training loss: 1.7279878854751587
Validation loss: 2.0385405684030182

Epoch: 5| Step: 4
Training loss: 1.7572357654571533
Validation loss: 2.043781795809346

Epoch: 5| Step: 5
Training loss: 0.7572053670883179
Validation loss: 2.0222669827040805

Epoch: 5| Step: 6
Training loss: 1.612117052078247
Validation loss: 2.002253652900778

Epoch: 5| Step: 7
Training loss: 1.0141642093658447
Validation loss: 2.0279489153174945

Epoch: 5| Step: 8
Training loss: 1.1006896495819092
Validation loss: 2.050460982066329

Epoch: 5| Step: 9
Training loss: 1.2556695938110352
Validation loss: 2.0385509793476393

Epoch: 5| Step: 10
Training loss: 1.6212224960327148
Validation loss: 2.037975998334987

Epoch: 494| Step: 0
Training loss: 1.4454439878463745
Validation loss: 2.0283427597374044

Epoch: 5| Step: 1
Training loss: 1.6436278820037842
Validation loss: 2.019914629638836

Epoch: 5| Step: 2
Training loss: 1.1005467176437378
Validation loss: 2.088640470658579

Epoch: 5| Step: 3
Training loss: 1.2119957208633423
Validation loss: 2.021639798277168

Epoch: 5| Step: 4
Training loss: 1.4992847442626953
Validation loss: 2.0848259874569472

Epoch: 5| Step: 5
Training loss: 1.2294193506240845
Validation loss: 2.03619017652286

Epoch: 5| Step: 6
Training loss: 1.0045045614242554
Validation loss: 2.0406880301813923

Epoch: 5| Step: 7
Training loss: 1.6119182109832764
Validation loss: 2.0233949358745287

Epoch: 5| Step: 8
Training loss: 1.6641048192977905
Validation loss: 1.9711187270379835

Epoch: 5| Step: 9
Training loss: 1.3340779542922974
Validation loss: 2.0455603291911464

Epoch: 5| Step: 10
Training loss: 1.1120718717575073
Validation loss: 1.997345994877559

Epoch: 495| Step: 0
Training loss: 1.6063902378082275
Validation loss: 2.0289507630050823

Epoch: 5| Step: 1
Training loss: 1.1217272281646729
Validation loss: 1.98355072288103

Epoch: 5| Step: 2
Training loss: 1.7840391397476196
Validation loss: 2.01445637595269

Epoch: 5| Step: 3
Training loss: 1.0350221395492554
Validation loss: 2.0119249718163603

Epoch: 5| Step: 4
Training loss: 1.2032297849655151
Validation loss: 1.9963991039542741

Epoch: 5| Step: 5
Training loss: 1.3496057987213135
Validation loss: 2.0286262240461124

Epoch: 5| Step: 6
Training loss: 1.530290126800537
Validation loss: 2.0213769392300676

Epoch: 5| Step: 7
Training loss: 1.7932405471801758
Validation loss: 2.026178013893866

Epoch: 5| Step: 8
Training loss: 1.1599102020263672
Validation loss: 2.0545629378288024

Epoch: 5| Step: 9
Training loss: 1.2750244140625
Validation loss: 2.0215859425965177

Epoch: 5| Step: 10
Training loss: 1.0713465213775635
Validation loss: 2.0333754016507055

Epoch: 496| Step: 0
Training loss: 1.390688180923462
Validation loss: 2.0204945841143207

Epoch: 5| Step: 1
Training loss: 0.8598734140396118
Validation loss: 2.043457502959877

Epoch: 5| Step: 2
Training loss: 1.0943349599838257
Validation loss: 2.0221503614097514

Epoch: 5| Step: 3
Training loss: 1.7184793949127197
Validation loss: 2.0443638191428235

Epoch: 5| Step: 4
Training loss: 1.343299150466919
Validation loss: 2.036319717284172

Epoch: 5| Step: 5
Training loss: 1.3427525758743286
Validation loss: 2.0477234522501626

Epoch: 5| Step: 6
Training loss: 1.4197362661361694
Validation loss: 2.006921168296568

Epoch: 5| Step: 7
Training loss: 1.2770304679870605
Validation loss: 2.0243833218851397

Epoch: 5| Step: 8
Training loss: 1.6528637409210205
Validation loss: 2.0430335754989297

Epoch: 5| Step: 9
Training loss: 1.6633144617080688
Validation loss: 2.006816161576138

Epoch: 5| Step: 10
Training loss: 1.2136861085891724
Validation loss: 2.039363222737466

Epoch: 497| Step: 0
Training loss: 1.2175573110580444
Validation loss: 2.0206756155977965

Epoch: 5| Step: 1
Training loss: 1.8051002025604248
Validation loss: 1.9897786853133992

Epoch: 5| Step: 2
Training loss: 1.5601394176483154
Validation loss: 2.0160123378999772

Epoch: 5| Step: 3
Training loss: 1.5180318355560303
Validation loss: 2.0328984927105647

Epoch: 5| Step: 4
Training loss: 1.37419855594635
Validation loss: 2.0833193486736667

Epoch: 5| Step: 5
Training loss: 0.9213247299194336
Validation loss: 2.059772155618155

Epoch: 5| Step: 6
Training loss: 1.3630071878433228
Validation loss: 2.0500992639090425

Epoch: 5| Step: 7
Training loss: 1.0390338897705078
Validation loss: 2.017441302217463

Epoch: 5| Step: 8
Training loss: 1.4611142873764038
Validation loss: 1.977139534488801

Epoch: 5| Step: 9
Training loss: 1.322381615638733
Validation loss: 1.9866666922005274

Epoch: 5| Step: 10
Training loss: 1.7149063348770142
Validation loss: 2.025293896275182

Epoch: 498| Step: 0
Training loss: 0.7766687870025635
Validation loss: 2.0480860356361634

Epoch: 5| Step: 1
Training loss: 1.6192176342010498
Validation loss: 2.027974964469992

Epoch: 5| Step: 2
Training loss: 1.260910153388977
Validation loss: 2.028893998874131

Epoch: 5| Step: 3
Training loss: 1.430961012840271
Validation loss: 2.0538829347138763

Epoch: 5| Step: 4
Training loss: 1.4070667028427124
Validation loss: 2.1049024212744927

Epoch: 5| Step: 5
Training loss: 1.4864569902420044
Validation loss: 2.0719963094239593

Epoch: 5| Step: 6
Training loss: 1.1206341981887817
Validation loss: 2.0627254132301576

Epoch: 5| Step: 7
Training loss: 2.0879483222961426
Validation loss: 2.0334177376121603

Epoch: 5| Step: 8
Training loss: 1.5755038261413574
Validation loss: 2.0507477137350265

Epoch: 5| Step: 9
Training loss: 1.3403208255767822
Validation loss: 2.0486176654856694

Epoch: 5| Step: 10
Training loss: 1.1431602239608765
Validation loss: 2.0553531800546954

Epoch: 499| Step: 0
Training loss: 1.094714641571045
Validation loss: 2.037126946192916

Epoch: 5| Step: 1
Training loss: 1.3456697463989258
Validation loss: 2.0348653972789807

Epoch: 5| Step: 2
Training loss: 1.400846242904663
Validation loss: 2.0215954306305095

Epoch: 5| Step: 3
Training loss: 1.6006858348846436
Validation loss: 2.0138286172702746

Epoch: 5| Step: 4
Training loss: 1.5469861030578613
Validation loss: 2.040389140446981

Epoch: 5| Step: 5
Training loss: 1.8691784143447876
Validation loss: 1.9869219039076118

Epoch: 5| Step: 6
Training loss: 1.2890520095825195
Validation loss: 2.0364739177047566

Epoch: 5| Step: 7
Training loss: 1.254258155822754
Validation loss: 2.020672652029222

Epoch: 5| Step: 8
Training loss: 1.1995842456817627
Validation loss: 2.0629005406492498

Epoch: 5| Step: 9
Training loss: 1.3637745380401611
Validation loss: 2.01333366158188

Epoch: 5| Step: 10
Training loss: 0.9780066013336182
Validation loss: 2.0358271829543577

Epoch: 500| Step: 0
Training loss: 1.3583333492279053
Validation loss: 2.025087236076273

Epoch: 5| Step: 1
Training loss: 1.4079798460006714
Validation loss: 2.02061556231591

Epoch: 5| Step: 2
Training loss: 1.9514741897583008
Validation loss: 2.0306964740958264

Epoch: 5| Step: 3
Training loss: 1.2384068965911865
Validation loss: 2.012199162155069

Epoch: 5| Step: 4
Training loss: 1.4717332124710083
Validation loss: 2.006130944016159

Epoch: 5| Step: 5
Training loss: 1.646044373512268
Validation loss: 2.0242872545796056

Epoch: 5| Step: 6
Training loss: 0.9512616991996765
Validation loss: 1.995161142400516

Epoch: 5| Step: 7
Training loss: 1.2007205486297607
Validation loss: 2.0483435789744058

Epoch: 5| Step: 8
Training loss: 1.462165117263794
Validation loss: 1.9995653731848604

Epoch: 5| Step: 9
Training loss: 1.130333662033081
Validation loss: 2.0329811855029036

Epoch: 5| Step: 10
Training loss: 1.302384376525879
Validation loss: 2.037220331930345

Testing loss: 2.078060852156745
