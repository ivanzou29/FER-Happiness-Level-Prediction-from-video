Epoch: 1| Step: 0
Training loss: 2.9287514686584473
Validation loss: 3.0311596034675516

Epoch: 5| Step: 1
Training loss: 3.280933380126953
Validation loss: 3.02827448486

Epoch: 5| Step: 2
Training loss: 2.844231128692627
Validation loss: 3.0298875583115445

Epoch: 5| Step: 3
Training loss: 3.279508590698242
Validation loss: 3.0275995192989225

Epoch: 5| Step: 4
Training loss: 3.005617380142212
Validation loss: 3.024272531591436

Epoch: 5| Step: 5
Training loss: 3.22764253616333
Validation loss: 3.020570601186445

Epoch: 5| Step: 6
Training loss: 3.351142168045044
Validation loss: 3.021171490351359

Epoch: 5| Step: 7
Training loss: 3.1357367038726807
Validation loss: 3.0205622334634104

Epoch: 5| Step: 8
Training loss: 2.8095154762268066
Validation loss: 3.018462554101021

Epoch: 5| Step: 9
Training loss: 2.6581838130950928
Validation loss: 3.01484182829498

Epoch: 5| Step: 10
Training loss: 3.461134195327759
Validation loss: 3.015405411361366

Epoch: 2| Step: 0
Training loss: 2.616337776184082
Validation loss: 3.010549137669225

Epoch: 5| Step: 1
Training loss: 3.7940590381622314
Validation loss: 3.0104739537803074

Epoch: 5| Step: 2
Training loss: 3.4281222820281982
Validation loss: 3.0080727710518786

Epoch: 5| Step: 3
Training loss: 2.0886282920837402
Validation loss: 3.0075461210743075

Epoch: 5| Step: 4
Training loss: 2.9571852684020996
Validation loss: 3.0031495837755102

Epoch: 5| Step: 5
Training loss: 2.6268763542175293
Validation loss: 3.0059746337193314

Epoch: 5| Step: 6
Training loss: 3.316140651702881
Validation loss: 3.0008719762166343

Epoch: 5| Step: 7
Training loss: 2.9550368785858154
Validation loss: 2.9968019044527443

Epoch: 5| Step: 8
Training loss: 3.3323655128479004
Validation loss: 2.9953742847647717

Epoch: 5| Step: 9
Training loss: 2.412493944168091
Validation loss: 2.991909373191095

Epoch: 5| Step: 10
Training loss: 4.403629779815674
Validation loss: 2.989270815285303

Epoch: 3| Step: 0
Training loss: 3.1849513053894043
Validation loss: 2.99121678772793

Epoch: 5| Step: 1
Training loss: 3.592341661453247
Validation loss: 2.9863025680665047

Epoch: 5| Step: 2
Training loss: 2.754019260406494
Validation loss: 2.98111976603026

Epoch: 5| Step: 3
Training loss: 2.327695369720459
Validation loss: 2.979892658930953

Epoch: 5| Step: 4
Training loss: 2.8089075088500977
Validation loss: 2.975915619122085

Epoch: 5| Step: 5
Training loss: 2.415648937225342
Validation loss: 2.9767330051750265

Epoch: 5| Step: 6
Training loss: 3.1607303619384766
Validation loss: 2.9701784426166165

Epoch: 5| Step: 7
Training loss: 2.4255149364471436
Validation loss: 2.9664580693808933

Epoch: 5| Step: 8
Training loss: 3.5708446502685547
Validation loss: 2.966397839207803

Epoch: 5| Step: 9
Training loss: 4.100926876068115
Validation loss: 2.965839696186845

Epoch: 5| Step: 10
Training loss: 3.219867467880249
Validation loss: 2.961163996368326

Epoch: 4| Step: 0
Training loss: 3.3785488605499268
Validation loss: 2.9590662833183043

Epoch: 5| Step: 1
Training loss: 2.8501479625701904
Validation loss: 2.9541832939271004

Epoch: 5| Step: 2
Training loss: 3.602174758911133
Validation loss: 2.9524723765670613

Epoch: 5| Step: 3
Training loss: 2.8094208240509033
Validation loss: 2.949472229967835

Epoch: 5| Step: 4
Training loss: 2.5608291625976562
Validation loss: 2.948782833673621

Epoch: 5| Step: 5
Training loss: 3.4402058124542236
Validation loss: 2.9463574527412333

Epoch: 5| Step: 6
Training loss: 2.5665698051452637
Validation loss: 2.9380610681349233

Epoch: 5| Step: 7
Training loss: 3.3560452461242676
Validation loss: 2.9349177550244074

Epoch: 5| Step: 8
Training loss: 2.6589548587799072
Validation loss: 2.9328132085902716

Epoch: 5| Step: 9
Training loss: 3.2887306213378906
Validation loss: 2.930158325420913

Epoch: 5| Step: 10
Training loss: 2.729738712310791
Validation loss: 2.926327282382596

Epoch: 5| Step: 0
Training loss: 3.0042028427124023
Validation loss: 2.922969566878452

Epoch: 5| Step: 1
Training loss: 2.749725818634033
Validation loss: 2.9198757833050144

Epoch: 5| Step: 2
Training loss: 2.6202893257141113
Validation loss: 2.917820776662519

Epoch: 5| Step: 3
Training loss: 3.6325626373291016
Validation loss: 2.9193826413923696

Epoch: 5| Step: 4
Training loss: 3.409419298171997
Validation loss: 2.91166353225708

Epoch: 5| Step: 5
Training loss: 2.693223476409912
Validation loss: 2.907917179087157

Epoch: 5| Step: 6
Training loss: 3.396448850631714
Validation loss: 2.908645009481779

Epoch: 5| Step: 7
Training loss: 2.9913582801818848
Validation loss: 2.901561034623013

Epoch: 5| Step: 8
Training loss: 2.8794796466827393
Validation loss: 2.896682590566656

Epoch: 5| Step: 9
Training loss: 3.0995171070098877
Validation loss: 2.9000302155812583

Epoch: 5| Step: 10
Training loss: 2.4534759521484375
Validation loss: 2.8901440994713896

Epoch: 6| Step: 0
Training loss: 2.5497450828552246
Validation loss: 2.8873290887442966

Epoch: 5| Step: 1
Training loss: 2.767413377761841
Validation loss: 2.885788602213706

Epoch: 5| Step: 2
Training loss: 3.102839708328247
Validation loss: 2.8825285742359776

Epoch: 5| Step: 3
Training loss: 3.3006439208984375
Validation loss: 2.8809195205729496

Epoch: 5| Step: 4
Training loss: 3.2086358070373535
Validation loss: 2.877485139395601

Epoch: 5| Step: 5
Training loss: 2.4232101440429688
Validation loss: 2.8737475795130574

Epoch: 5| Step: 6
Training loss: 2.826434373855591
Validation loss: 2.8715132756899764

Epoch: 5| Step: 7
Training loss: 3.511704206466675
Validation loss: 2.8749949957734797

Epoch: 5| Step: 8
Training loss: 2.878000497817993
Validation loss: 2.860362970700828

Epoch: 5| Step: 9
Training loss: 2.9778892993927
Validation loss: 2.8632480200900825

Epoch: 5| Step: 10
Training loss: 3.246586799621582
Validation loss: 2.855178648425687

Epoch: 7| Step: 0
Training loss: 2.4891343116760254
Validation loss: 2.8549958044482815

Epoch: 5| Step: 1
Training loss: 3.1655726432800293
Validation loss: 2.848751876943855

Epoch: 5| Step: 2
Training loss: 3.0166738033294678
Validation loss: 2.8464667617633777

Epoch: 5| Step: 3
Training loss: 2.362179756164551
Validation loss: 2.8448612920699583

Epoch: 5| Step: 4
Training loss: 3.1947853565216064
Validation loss: 2.8424904577193724

Epoch: 5| Step: 5
Training loss: 3.204925060272217
Validation loss: 2.8359084642061623

Epoch: 5| Step: 6
Training loss: 2.946406841278076
Validation loss: 2.8322944512931247

Epoch: 5| Step: 7
Training loss: 2.8847782611846924
Validation loss: 2.8270903120758715

Epoch: 5| Step: 8
Training loss: 3.225379228591919
Validation loss: 2.8238517776612313

Epoch: 5| Step: 9
Training loss: 2.4185643196105957
Validation loss: 2.8202782087428595

Epoch: 5| Step: 10
Training loss: 3.5854830741882324
Validation loss: 2.8187131189530894

Epoch: 8| Step: 0
Training loss: 2.7208540439605713
Validation loss: 2.8149257116420294

Epoch: 5| Step: 1
Training loss: 3.098069906234741
Validation loss: 2.8104190775143203

Epoch: 5| Step: 2
Training loss: 2.6473028659820557
Validation loss: 2.8055907808324343

Epoch: 5| Step: 3
Training loss: 2.3560657501220703
Validation loss: 2.8000410551665933

Epoch: 5| Step: 4
Training loss: 3.7880187034606934
Validation loss: 2.7964875518634753

Epoch: 5| Step: 5
Training loss: 3.1002283096313477
Validation loss: 2.7911006276325514

Epoch: 5| Step: 6
Training loss: 3.001800537109375
Validation loss: 2.7912332883445163

Epoch: 5| Step: 7
Training loss: 2.2085447311401367
Validation loss: 2.784982322364725

Epoch: 5| Step: 8
Training loss: 2.893662452697754
Validation loss: 2.7738930435590845

Epoch: 5| Step: 9
Training loss: 2.754058837890625
Validation loss: 2.7745498508535404

Epoch: 5| Step: 10
Training loss: 3.6458663940429688
Validation loss: 2.7726286072884836

Epoch: 9| Step: 0
Training loss: 2.9623191356658936
Validation loss: 2.766042829841696

Epoch: 5| Step: 1
Training loss: 2.9522836208343506
Validation loss: 2.759161505647885

Epoch: 5| Step: 2
Training loss: 3.408576250076294
Validation loss: 2.7568223553319133

Epoch: 5| Step: 3
Training loss: 3.4111931324005127
Validation loss: 2.7571775297964773

Epoch: 5| Step: 4
Training loss: 3.1814663410186768
Validation loss: 2.746634739701466

Epoch: 5| Step: 5
Training loss: 2.175999879837036
Validation loss: 2.7440474930629937

Epoch: 5| Step: 6
Training loss: 3.195143461227417
Validation loss: 2.7397973409263034

Epoch: 5| Step: 7
Training loss: 2.2980117797851562
Validation loss: 2.732222000757853

Epoch: 5| Step: 8
Training loss: 2.671978712081909
Validation loss: 2.7285366776168987

Epoch: 5| Step: 9
Training loss: 2.5836501121520996
Validation loss: 2.72458629967064

Epoch: 5| Step: 10
Training loss: 2.9655323028564453
Validation loss: 2.721075504056869

Epoch: 10| Step: 0
Training loss: 2.664137363433838
Validation loss: 2.7110009859966975

Epoch: 5| Step: 1
Training loss: 2.807910919189453
Validation loss: 2.713749203630673

Epoch: 5| Step: 2
Training loss: 2.2708029747009277
Validation loss: 2.7061484654744468

Epoch: 5| Step: 3
Training loss: 3.8229103088378906
Validation loss: 2.6955531258736887

Epoch: 5| Step: 4
Training loss: 2.717912197113037
Validation loss: 2.6984873510176137

Epoch: 5| Step: 5
Training loss: 2.526639461517334
Validation loss: 2.692464631090882

Epoch: 5| Step: 6
Training loss: 2.6932146549224854
Validation loss: 2.682656159964941

Epoch: 5| Step: 7
Training loss: 3.4944396018981934
Validation loss: 2.6775863914079565

Epoch: 5| Step: 8
Training loss: 2.818167209625244
Validation loss: 2.682417079966555

Epoch: 5| Step: 9
Training loss: 2.8486316204071045
Validation loss: 2.673006121830274

Epoch: 5| Step: 10
Training loss: 2.668409585952759
Validation loss: 2.667225689016363

Epoch: 11| Step: 0
Training loss: 2.4587244987487793
Validation loss: 2.6629274686177573

Epoch: 5| Step: 1
Training loss: 3.2829291820526123
Validation loss: 2.6573497890144266

Epoch: 5| Step: 2
Training loss: 2.8440804481506348
Validation loss: 2.6565520481396745

Epoch: 5| Step: 3
Training loss: 2.8115267753601074
Validation loss: 2.6524988887130574

Epoch: 5| Step: 4
Training loss: 2.735626459121704
Validation loss: 2.6404181244552776

Epoch: 5| Step: 5
Training loss: 2.6722629070281982
Validation loss: 2.6394104752489316

Epoch: 5| Step: 6
Training loss: 2.4197945594787598
Validation loss: 2.63112780099274

Epoch: 5| Step: 7
Training loss: 3.0341384410858154
Validation loss: 2.630035441408875

Epoch: 5| Step: 8
Training loss: 2.6508922576904297
Validation loss: 2.61801173610072

Epoch: 5| Step: 9
Training loss: 2.8238353729248047
Validation loss: 2.6220836947041173

Epoch: 5| Step: 10
Training loss: 3.252368211746216
Validation loss: 2.612748033256941

Epoch: 12| Step: 0
Training loss: 2.4764206409454346
Validation loss: 2.61378082665064

Epoch: 5| Step: 1
Training loss: 3.1699776649475098
Validation loss: 2.5992154972527617

Epoch: 5| Step: 2
Training loss: 2.835451364517212
Validation loss: 2.596504560080908

Epoch: 5| Step: 3
Training loss: 3.659872531890869
Validation loss: 2.5880799242245254

Epoch: 5| Step: 4
Training loss: 2.364936113357544
Validation loss: 2.5889883631019184

Epoch: 5| Step: 5
Training loss: 2.3977742195129395
Validation loss: 2.5824539558861845

Epoch: 5| Step: 6
Training loss: 1.9048755168914795
Validation loss: 2.572062743607388

Epoch: 5| Step: 7
Training loss: 2.8512988090515137
Validation loss: 2.5651005673152145

Epoch: 5| Step: 8
Training loss: 2.530694007873535
Validation loss: 2.558338524192892

Epoch: 5| Step: 9
Training loss: 2.8265159130096436
Validation loss: 2.5593673388163247

Epoch: 5| Step: 10
Training loss: 3.621443510055542
Validation loss: 2.5592619270406742

Epoch: 13| Step: 0
Training loss: 2.959324836730957
Validation loss: 2.550783036857523

Epoch: 5| Step: 1
Training loss: 2.548941135406494
Validation loss: 2.5407041785537556

Epoch: 5| Step: 2
Training loss: 2.2412219047546387
Validation loss: 2.5355977653175272

Epoch: 5| Step: 3
Training loss: 2.9697184562683105
Validation loss: 2.5298122552133377

Epoch: 5| Step: 4
Training loss: 2.790118455886841
Validation loss: 2.527608807368945

Epoch: 5| Step: 5
Training loss: 2.6547598838806152
Validation loss: 2.5240198437885573

Epoch: 5| Step: 6
Training loss: 2.6432409286499023
Validation loss: 2.513014085831181

Epoch: 5| Step: 7
Training loss: 2.573643684387207
Validation loss: 2.4960059119809057

Epoch: 5| Step: 8
Training loss: 2.845555543899536
Validation loss: 2.500390263013942

Epoch: 5| Step: 9
Training loss: 3.094689130783081
Validation loss: 2.4906062926015546

Epoch: 5| Step: 10
Training loss: 2.8025074005126953
Validation loss: 2.4854355486490394

Epoch: 14| Step: 0
Training loss: 2.6107945442199707
Validation loss: 2.4759704989771687

Epoch: 5| Step: 1
Training loss: 2.670741558074951
Validation loss: 2.471449554607432

Epoch: 5| Step: 2
Training loss: 3.1322994232177734
Validation loss: 2.4697941657035583

Epoch: 5| Step: 3
Training loss: 2.4073917865753174
Validation loss: 2.4553302334200953

Epoch: 5| Step: 4
Training loss: 3.0362730026245117
Validation loss: 2.448598328457084

Epoch: 5| Step: 5
Training loss: 2.5082476139068604
Validation loss: 2.442109569426506

Epoch: 5| Step: 6
Training loss: 2.8369784355163574
Validation loss: 2.4411811367157967

Epoch: 5| Step: 7
Training loss: 2.7639453411102295
Validation loss: 2.4412762298378894

Epoch: 5| Step: 8
Training loss: 2.934420108795166
Validation loss: 2.4286696680130495

Epoch: 5| Step: 9
Training loss: 2.3400397300720215
Validation loss: 2.4302284127922467

Epoch: 5| Step: 10
Training loss: 2.408738613128662
Validation loss: 2.4088278765319497

Epoch: 15| Step: 0
Training loss: 2.420258045196533
Validation loss: 2.4118734610977994

Epoch: 5| Step: 1
Training loss: 2.576216220855713
Validation loss: 2.402980096878544

Epoch: 5| Step: 2
Training loss: 2.1061768531799316
Validation loss: 2.388162951315603

Epoch: 5| Step: 3
Training loss: 2.575136661529541
Validation loss: 2.385695726640763

Epoch: 5| Step: 4
Training loss: 3.006253480911255
Validation loss: 2.3846065818622546

Epoch: 5| Step: 5
Training loss: 2.95292329788208
Validation loss: 2.3770030570286576

Epoch: 5| Step: 6
Training loss: 3.187649726867676
Validation loss: 2.3670482558588826

Epoch: 5| Step: 7
Training loss: 2.460787534713745
Validation loss: 2.3622381712800715

Epoch: 5| Step: 8
Training loss: 2.5582010746002197
Validation loss: 2.356560904492614

Epoch: 5| Step: 9
Training loss: 2.6238064765930176
Validation loss: 2.3465413713967926

Epoch: 5| Step: 10
Training loss: 2.7364487648010254
Validation loss: 2.3496953595069145

Epoch: 16| Step: 0
Training loss: 2.7167747020721436
Validation loss: 2.3335176180767756

Epoch: 5| Step: 1
Training loss: 2.6184945106506348
Validation loss: 2.326513574969384

Epoch: 5| Step: 2
Training loss: 2.7706544399261475
Validation loss: 2.3210029140595467

Epoch: 5| Step: 3
Training loss: 2.314734697341919
Validation loss: 2.313221759693597

Epoch: 5| Step: 4
Training loss: 2.674647092819214
Validation loss: 2.307676355044047

Epoch: 5| Step: 5
Training loss: 2.8085625171661377
Validation loss: 2.2959984387120893

Epoch: 5| Step: 6
Training loss: 3.0042107105255127
Validation loss: 2.2947422458279516

Epoch: 5| Step: 7
Training loss: 2.0401015281677246
Validation loss: 2.2837869095545944

Epoch: 5| Step: 8
Training loss: 2.822702407836914
Validation loss: 2.275178829828898

Epoch: 5| Step: 9
Training loss: 2.479332685470581
Validation loss: 2.271741097973239

Epoch: 5| Step: 10
Training loss: 2.5267624855041504
Validation loss: 2.2594768462642545

Epoch: 17| Step: 0
Training loss: 2.8070003986358643
Validation loss: 2.261236339487055

Epoch: 5| Step: 1
Training loss: 2.5769739151000977
Validation loss: 2.2400244333410777

Epoch: 5| Step: 2
Training loss: 2.291085720062256
Validation loss: 2.2521367047422673

Epoch: 5| Step: 3
Training loss: 2.407616138458252
Validation loss: 2.2445409092851865

Epoch: 5| Step: 4
Training loss: 3.086905002593994
Validation loss: 2.23220133525069

Epoch: 5| Step: 5
Training loss: 1.8185237646102905
Validation loss: 2.2215009863658617

Epoch: 5| Step: 6
Training loss: 2.668799877166748
Validation loss: 2.215845236214258

Epoch: 5| Step: 7
Training loss: 2.9103941917419434
Validation loss: 2.212429338885892

Epoch: 5| Step: 8
Training loss: 2.607835054397583
Validation loss: 2.211478361519434

Epoch: 5| Step: 9
Training loss: 2.3288791179656982
Validation loss: 2.200378458987

Epoch: 5| Step: 10
Training loss: 2.757474184036255
Validation loss: 2.197626333082876

Epoch: 18| Step: 0
Training loss: 2.29350209236145
Validation loss: 2.1923671614739204

Epoch: 5| Step: 1
Training loss: 2.6095919609069824
Validation loss: 2.1955915804832213

Epoch: 5| Step: 2
Training loss: 2.4261372089385986
Validation loss: 2.1841752195871003

Epoch: 5| Step: 3
Training loss: 2.581491708755493
Validation loss: 2.175303510440293

Epoch: 5| Step: 4
Training loss: 2.6673622131347656
Validation loss: 2.1799849117955854

Epoch: 5| Step: 5
Training loss: 2.4313066005706787
Validation loss: 2.1737379207405993

Epoch: 5| Step: 6
Training loss: 2.520937919616699
Validation loss: 2.1784374713897705

Epoch: 5| Step: 7
Training loss: 2.519789218902588
Validation loss: 2.1633263634097193

Epoch: 5| Step: 8
Training loss: 2.944139003753662
Validation loss: 2.163960700394005

Epoch: 5| Step: 9
Training loss: 2.489041805267334
Validation loss: 2.151014607439759

Epoch: 5| Step: 10
Training loss: 2.316551923751831
Validation loss: 2.143327825812883

Epoch: 19| Step: 0
Training loss: 1.9849519729614258
Validation loss: 2.150234713349291

Epoch: 5| Step: 1
Training loss: 2.4699385166168213
Validation loss: 2.145076039016888

Epoch: 5| Step: 2
Training loss: 2.611008405685425
Validation loss: 2.1417551079104022

Epoch: 5| Step: 3
Training loss: 3.008934736251831
Validation loss: 2.1369605577120216

Epoch: 5| Step: 4
Training loss: 2.3174915313720703
Validation loss: 2.1288989372150873

Epoch: 5| Step: 5
Training loss: 2.6246752738952637
Validation loss: 2.1262302526863675

Epoch: 5| Step: 6
Training loss: 2.4016995429992676
Validation loss: 2.1254709651393275

Epoch: 5| Step: 7
Training loss: 2.7455227375030518
Validation loss: 2.1173548672788884

Epoch: 5| Step: 8
Training loss: 2.7420461177825928
Validation loss: 2.1076460525553715

Epoch: 5| Step: 9
Training loss: 2.4755265712738037
Validation loss: 2.106302258788898

Epoch: 5| Step: 10
Training loss: 2.090691328048706
Validation loss: 2.1143225123805385

Epoch: 20| Step: 0
Training loss: 2.441824436187744
Validation loss: 2.103162750121086

Epoch: 5| Step: 1
Training loss: 2.9193546772003174
Validation loss: 2.09974253818553

Epoch: 5| Step: 2
Training loss: 2.4420270919799805
Validation loss: 2.1134413032121557

Epoch: 5| Step: 3
Training loss: 2.5185799598693848
Validation loss: 2.10378764008963

Epoch: 5| Step: 4
Training loss: 2.3126418590545654
Validation loss: 2.1118079962268954

Epoch: 5| Step: 5
Training loss: 2.9501922130584717
Validation loss: 2.0931487237253497

Epoch: 5| Step: 6
Training loss: 2.422592878341675
Validation loss: 2.0885856548945108

Epoch: 5| Step: 7
Training loss: 2.1904358863830566
Validation loss: 2.0782815179517193

Epoch: 5| Step: 8
Training loss: 2.8216419219970703
Validation loss: 2.0825113955364434

Epoch: 5| Step: 9
Training loss: 2.0150575637817383
Validation loss: 2.0830407091366347

Epoch: 5| Step: 10
Training loss: 2.219205141067505
Validation loss: 2.0811372918467366

Epoch: 21| Step: 0
Training loss: 2.47898530960083
Validation loss: 2.0691148299042896

Epoch: 5| Step: 1
Training loss: 2.4765429496765137
Validation loss: 2.074024277348672

Epoch: 5| Step: 2
Training loss: 2.4281442165374756
Validation loss: 2.0653589335821008

Epoch: 5| Step: 3
Training loss: 2.2147445678710938
Validation loss: 2.0618503311628937

Epoch: 5| Step: 4
Training loss: 2.7289772033691406
Validation loss: 2.059815287590027

Epoch: 5| Step: 5
Training loss: 2.0137131214141846
Validation loss: 2.0618342186814997

Epoch: 5| Step: 6
Training loss: 2.9930412769317627
Validation loss: 2.0518740761664604

Epoch: 5| Step: 7
Training loss: 2.6949541568756104
Validation loss: 2.059913904436173

Epoch: 5| Step: 8
Training loss: 2.106346607208252
Validation loss: 2.05120756805584

Epoch: 5| Step: 9
Training loss: 2.329861640930176
Validation loss: 2.0432986572224605

Epoch: 5| Step: 10
Training loss: 2.793983221054077
Validation loss: 2.0359497121585313

Epoch: 22| Step: 0
Training loss: 1.911381483078003
Validation loss: 2.0483173478034233

Epoch: 5| Step: 1
Training loss: 2.4556972980499268
Validation loss: 2.040524891627732

Epoch: 5| Step: 2
Training loss: 2.1759960651397705
Validation loss: 2.036905029768585

Epoch: 5| Step: 3
Training loss: 2.191549301147461
Validation loss: 2.028746181918729

Epoch: 5| Step: 4
Training loss: 2.798060894012451
Validation loss: 2.040901284064016

Epoch: 5| Step: 5
Training loss: 2.0868358612060547
Validation loss: 2.034610939282243

Epoch: 5| Step: 6
Training loss: 2.833251476287842
Validation loss: 2.036785674351518

Epoch: 5| Step: 7
Training loss: 3.1322274208068848
Validation loss: 2.025705305478906

Epoch: 5| Step: 8
Training loss: 2.3546252250671387
Validation loss: 2.0397566633839763

Epoch: 5| Step: 9
Training loss: 2.5291826725006104
Validation loss: 2.0316620026865313

Epoch: 5| Step: 10
Training loss: 2.676184892654419
Validation loss: 2.034739027741135

Epoch: 23| Step: 0
Training loss: 1.5891592502593994
Validation loss: 2.0188009687649306

Epoch: 5| Step: 1
Training loss: 2.362501621246338
Validation loss: 2.025349142730877

Epoch: 5| Step: 2
Training loss: 2.4973862171173096
Validation loss: 2.0389454492958645

Epoch: 5| Step: 3
Training loss: 2.9288127422332764
Validation loss: 2.0274257839366956

Epoch: 5| Step: 4
Training loss: 2.7892847061157227
Validation loss: 2.0301599374381443

Epoch: 5| Step: 5
Training loss: 2.3778507709503174
Validation loss: 2.023261467615763

Epoch: 5| Step: 6
Training loss: 2.329519271850586
Validation loss: 2.0139122573278283

Epoch: 5| Step: 7
Training loss: 2.9860782623291016
Validation loss: 2.015718113991522

Epoch: 5| Step: 8
Training loss: 1.951486349105835
Validation loss: 2.0244723878880984

Epoch: 5| Step: 9
Training loss: 2.475651264190674
Validation loss: 2.024775802448232

Epoch: 5| Step: 10
Training loss: 2.7836437225341797
Validation loss: 2.0323846160724597

Epoch: 24| Step: 0
Training loss: 2.164094924926758
Validation loss: 2.007439658205996

Epoch: 5| Step: 1
Training loss: 2.7688915729522705
Validation loss: 2.0246360865972375

Epoch: 5| Step: 2
Training loss: 2.8428032398223877
Validation loss: 2.0163555786173832

Epoch: 5| Step: 3
Training loss: 2.173854351043701
Validation loss: 2.01575711465651

Epoch: 5| Step: 4
Training loss: 2.4950690269470215
Validation loss: 2.022526425700034

Epoch: 5| Step: 5
Training loss: 2.0414958000183105
Validation loss: 2.0201715897488337

Epoch: 5| Step: 6
Training loss: 2.4791736602783203
Validation loss: 2.0239200874041487

Epoch: 5| Step: 7
Training loss: 2.1477274894714355
Validation loss: 2.0262668824964956

Epoch: 5| Step: 8
Training loss: 2.611752986907959
Validation loss: 2.0239802829680906

Epoch: 5| Step: 9
Training loss: 2.559844732284546
Validation loss: 2.012972431798135

Epoch: 5| Step: 10
Training loss: 2.669168710708618
Validation loss: 2.0124416094954296

Epoch: 25| Step: 0
Training loss: 2.316328525543213
Validation loss: 2.0367500166739188

Epoch: 5| Step: 1
Training loss: 3.055208683013916
Validation loss: 2.0142164050891833

Epoch: 5| Step: 2
Training loss: 2.589876174926758
Validation loss: 2.005737094468968

Epoch: 5| Step: 3
Training loss: 2.5765182971954346
Validation loss: 2.0168135935260403

Epoch: 5| Step: 4
Training loss: 2.13148832321167
Validation loss: 2.0225912511989637

Epoch: 5| Step: 5
Training loss: 2.091829299926758
Validation loss: 2.026602796328965

Epoch: 5| Step: 6
Training loss: 2.674281120300293
Validation loss: 2.017566655271797

Epoch: 5| Step: 7
Training loss: 2.3359286785125732
Validation loss: 2.017057116313647

Epoch: 5| Step: 8
Training loss: 2.5544486045837402
Validation loss: 2.020921581534929

Epoch: 5| Step: 9
Training loss: 1.9321739673614502
Validation loss: 2.0196444219158542

Epoch: 5| Step: 10
Training loss: 2.609489917755127
Validation loss: 2.0323675422258276

Epoch: 26| Step: 0
Training loss: 2.2876486778259277
Validation loss: 2.0232930875593618

Epoch: 5| Step: 1
Training loss: 2.597618818283081
Validation loss: 2.0093073139908495

Epoch: 5| Step: 2
Training loss: 1.953314185142517
Validation loss: 2.0155270638004428

Epoch: 5| Step: 3
Training loss: 2.2583134174346924
Validation loss: 2.019100263554563

Epoch: 5| Step: 4
Training loss: 3.0571296215057373
Validation loss: 2.021906732231058

Epoch: 5| Step: 5
Training loss: 2.6618142127990723
Validation loss: 2.0009944797844015

Epoch: 5| Step: 6
Training loss: 2.6421327590942383
Validation loss: 2.013479230224445

Epoch: 5| Step: 7
Training loss: 2.446988821029663
Validation loss: 2.000145503269729

Epoch: 5| Step: 8
Training loss: 2.574547529220581
Validation loss: 2.025083088105725

Epoch: 5| Step: 9
Training loss: 2.2489991188049316
Validation loss: 2.001320649218816

Epoch: 5| Step: 10
Training loss: 2.2191221714019775
Validation loss: 2.0137566187048472

Epoch: 27| Step: 0
Training loss: 2.606658935546875
Validation loss: 2.003869274611114

Epoch: 5| Step: 1
Training loss: 2.2066593170166016
Validation loss: 2.010678514357536

Epoch: 5| Step: 2
Training loss: 2.2157955169677734
Validation loss: 1.994532282634448

Epoch: 5| Step: 3
Training loss: 2.6466472148895264
Validation loss: 2.004309428635464

Epoch: 5| Step: 4
Training loss: 2.861722230911255
Validation loss: 1.9996496861980808

Epoch: 5| Step: 5
Training loss: 1.6794904470443726
Validation loss: 2.0077779626333587

Epoch: 5| Step: 6
Training loss: 2.2949490547180176
Validation loss: 2.000519029555782

Epoch: 5| Step: 7
Training loss: 2.357011079788208
Validation loss: 2.02410654611485

Epoch: 5| Step: 8
Training loss: 2.9949450492858887
Validation loss: 2.0085985763098604

Epoch: 5| Step: 9
Training loss: 2.9478936195373535
Validation loss: 2.008271357064606

Epoch: 5| Step: 10
Training loss: 1.9987698793411255
Validation loss: 2.0082918969533776

Epoch: 28| Step: 0
Training loss: 2.0456409454345703
Validation loss: 2.010182079448495

Epoch: 5| Step: 1
Training loss: 2.7031776905059814
Validation loss: 2.0265907843907676

Epoch: 5| Step: 2
Training loss: 2.6903481483459473
Validation loss: 2.009805228120537

Epoch: 5| Step: 3
Training loss: 2.8602728843688965
Validation loss: 2.011935277651715

Epoch: 5| Step: 4
Training loss: 2.4177463054656982
Validation loss: 2.012751475457222

Epoch: 5| Step: 5
Training loss: 1.7300355434417725
Validation loss: 2.0167036338519027

Epoch: 5| Step: 6
Training loss: 2.3109114170074463
Validation loss: 2.0064068417395315

Epoch: 5| Step: 7
Training loss: 2.7151803970336914
Validation loss: 2.006210231011914

Epoch: 5| Step: 8
Training loss: 2.5245845317840576
Validation loss: 1.9940414018528436

Epoch: 5| Step: 9
Training loss: 2.1894173622131348
Validation loss: 2.01521050160931

Epoch: 5| Step: 10
Training loss: 2.648775339126587
Validation loss: 2.023999616663943

Epoch: 29| Step: 0
Training loss: 2.4724884033203125
Validation loss: 2.0099085172017417

Epoch: 5| Step: 1
Training loss: 2.476278781890869
Validation loss: 2.0148814698701263

Epoch: 5| Step: 2
Training loss: 2.0415279865264893
Validation loss: 2.011568227121907

Epoch: 5| Step: 3
Training loss: 3.1240978240966797
Validation loss: 2.009771911046838

Epoch: 5| Step: 4
Training loss: 2.496196985244751
Validation loss: 2.007557556193362

Epoch: 5| Step: 5
Training loss: 2.192619562149048
Validation loss: 2.0129640717660227

Epoch: 5| Step: 6
Training loss: 2.4843714237213135
Validation loss: 2.0033956984037995

Epoch: 5| Step: 7
Training loss: 2.489147901535034
Validation loss: 2.025150224726687

Epoch: 5| Step: 8
Training loss: 2.230491876602173
Validation loss: 2.0138815500402965

Epoch: 5| Step: 9
Training loss: 2.339298963546753
Validation loss: 2.003604358242404

Epoch: 5| Step: 10
Training loss: 2.380110740661621
Validation loss: 2.006738552483179

Epoch: 30| Step: 0
Training loss: 2.1964495182037354
Validation loss: 1.99762467158738

Epoch: 5| Step: 1
Training loss: 2.1185905933380127
Validation loss: 2.0132399271893244

Epoch: 5| Step: 2
Training loss: 2.5358777046203613
Validation loss: 2.009588139031523

Epoch: 5| Step: 3
Training loss: 2.8315742015838623
Validation loss: 1.9968861841386365

Epoch: 5| Step: 4
Training loss: 2.8293137550354004
Validation loss: 2.002199112728078

Epoch: 5| Step: 5
Training loss: 2.424339771270752
Validation loss: 2.016006264635312

Epoch: 5| Step: 6
Training loss: 2.114762544631958
Validation loss: 2.00706462706289

Epoch: 5| Step: 7
Training loss: 1.9736560583114624
Validation loss: 1.9962216102948753

Epoch: 5| Step: 8
Training loss: 3.1874892711639404
Validation loss: 2.013208963537729

Epoch: 5| Step: 9
Training loss: 2.1660683155059814
Validation loss: 2.017523491254417

Epoch: 5| Step: 10
Training loss: 2.2859039306640625
Validation loss: 2.00889677129766

Epoch: 31| Step: 0
Training loss: 2.6879563331604004
Validation loss: 2.020385079486396

Epoch: 5| Step: 1
Training loss: 2.8158154487609863
Validation loss: 2.0079519030868367

Epoch: 5| Step: 2
Training loss: 2.4859519004821777
Validation loss: 2.0166382430702128

Epoch: 5| Step: 3
Training loss: 2.3887686729431152
Validation loss: 2.011109282893519

Epoch: 5| Step: 4
Training loss: 2.436061143875122
Validation loss: 2.0261158122811267

Epoch: 5| Step: 5
Training loss: 2.4670250415802
Validation loss: 2.010847391620759

Epoch: 5| Step: 6
Training loss: 2.116018295288086
Validation loss: 2.0161948383495374

Epoch: 5| Step: 7
Training loss: 2.31510066986084
Validation loss: 2.020008694741034

Epoch: 5| Step: 8
Training loss: 2.517592668533325
Validation loss: 2.0135847419820805

Epoch: 5| Step: 9
Training loss: 2.5125629901885986
Validation loss: 2.0239467274758125

Epoch: 5| Step: 10
Training loss: 2.031510353088379
Validation loss: 2.02650769295231

Epoch: 32| Step: 0
Training loss: 2.046323776245117
Validation loss: 2.0176866259626163

Epoch: 5| Step: 1
Training loss: 3.270146608352661
Validation loss: 2.0084506516815512

Epoch: 5| Step: 2
Training loss: 2.785033702850342
Validation loss: 2.0165660560771985

Epoch: 5| Step: 3
Training loss: 2.0830020904541016
Validation loss: 1.999453430534691

Epoch: 5| Step: 4
Training loss: 2.310558319091797
Validation loss: 2.021366060421031

Epoch: 5| Step: 5
Training loss: 2.2612900733947754
Validation loss: 2.007918914159139

Epoch: 5| Step: 6
Training loss: 2.453400135040283
Validation loss: 2.0240447521209717

Epoch: 5| Step: 7
Training loss: 1.859413504600525
Validation loss: 2.0273571655314457

Epoch: 5| Step: 8
Training loss: 2.7428627014160156
Validation loss: 2.0166882366262455

Epoch: 5| Step: 9
Training loss: 2.1151275634765625
Validation loss: 2.0222195425341205

Epoch: 5| Step: 10
Training loss: 2.848478317260742
Validation loss: 2.021660840639504

Epoch: 33| Step: 0
Training loss: 2.7059326171875
Validation loss: 2.009584225634093

Epoch: 5| Step: 1
Training loss: 2.612769603729248
Validation loss: 2.0228592708546627

Epoch: 5| Step: 2
Training loss: 2.2660624980926514
Validation loss: 2.0145235241100354

Epoch: 5| Step: 3
Training loss: 2.352700710296631
Validation loss: 2.0147071961433656

Epoch: 5| Step: 4
Training loss: 2.521333694458008
Validation loss: 2.005263638752763

Epoch: 5| Step: 5
Training loss: 2.9251351356506348
Validation loss: 2.001171681188768

Epoch: 5| Step: 6
Training loss: 2.180058002471924
Validation loss: 2.004651424705341

Epoch: 5| Step: 7
Training loss: 1.8022563457489014
Validation loss: 1.9970696280079503

Epoch: 5| Step: 8
Training loss: 1.9117183685302734
Validation loss: 2.0053682596452775

Epoch: 5| Step: 9
Training loss: 2.790372371673584
Validation loss: 1.9901770199498823

Epoch: 5| Step: 10
Training loss: 2.5923593044281006
Validation loss: 2.0029853197836105

Epoch: 34| Step: 0
Training loss: 2.1863951683044434
Validation loss: 2.0063018747555312

Epoch: 5| Step: 1
Training loss: 2.1388461589813232
Validation loss: 1.996476270819223

Epoch: 5| Step: 2
Training loss: 2.5448904037475586
Validation loss: 2.006319801012675

Epoch: 5| Step: 3
Training loss: 2.2552504539489746
Validation loss: 1.9989733926711544

Epoch: 5| Step: 4
Training loss: 2.3864212036132812
Validation loss: 2.0040127436319985

Epoch: 5| Step: 5
Training loss: 2.838840961456299
Validation loss: 1.9896325603608163

Epoch: 5| Step: 6
Training loss: 2.0362062454223633
Validation loss: 1.9840622794243596

Epoch: 5| Step: 7
Training loss: 2.6672935485839844
Validation loss: 2.0085028320230465

Epoch: 5| Step: 8
Training loss: 2.3526694774627686
Validation loss: 1.998267380140161

Epoch: 5| Step: 9
Training loss: 2.6314857006073
Validation loss: 1.995699490270307

Epoch: 5| Step: 10
Training loss: 2.604794979095459
Validation loss: 2.0067121264755086

Epoch: 35| Step: 0
Training loss: 1.916312575340271
Validation loss: 2.0015186648215018

Epoch: 5| Step: 1
Training loss: 2.1491401195526123
Validation loss: 1.998071619259414

Epoch: 5| Step: 2
Training loss: 2.7635910511016846
Validation loss: 1.9991960833149571

Epoch: 5| Step: 3
Training loss: 2.2853729724884033
Validation loss: 2.008749779834542

Epoch: 5| Step: 4
Training loss: 2.5579705238342285
Validation loss: 2.0026288378623223

Epoch: 5| Step: 5
Training loss: 2.2226691246032715
Validation loss: 2.012296227998631

Epoch: 5| Step: 6
Training loss: 2.7234959602355957
Validation loss: 2.0190843920553885

Epoch: 5| Step: 7
Training loss: 3.0801846981048584
Validation loss: 1.9957199686317033

Epoch: 5| Step: 8
Training loss: 2.0803940296173096
Validation loss: 1.998069865729219

Epoch: 5| Step: 9
Training loss: 1.9407237768173218
Validation loss: 2.009540407888351

Epoch: 5| Step: 10
Training loss: 3.0755553245544434
Validation loss: 2.0038663059152584

Epoch: 36| Step: 0
Training loss: 2.777536153793335
Validation loss: 2.008641342962942

Epoch: 5| Step: 1
Training loss: 2.6028566360473633
Validation loss: 1.9985043335986394

Epoch: 5| Step: 2
Training loss: 2.0903942584991455
Validation loss: 2.0024437635175643

Epoch: 5| Step: 3
Training loss: 2.1138527393341064
Validation loss: 2.006054659043589

Epoch: 5| Step: 4
Training loss: 2.528566837310791
Validation loss: 2.002542772600728

Epoch: 5| Step: 5
Training loss: 2.421501636505127
Validation loss: 2.0041328604503343

Epoch: 5| Step: 6
Training loss: 2.4641871452331543
Validation loss: 1.998933635732179

Epoch: 5| Step: 7
Training loss: 2.2064785957336426
Validation loss: 1.9955679344874557

Epoch: 5| Step: 8
Training loss: 1.9013302326202393
Validation loss: 2.001666938104937

Epoch: 5| Step: 9
Training loss: 2.800706386566162
Validation loss: 1.992290222516624

Epoch: 5| Step: 10
Training loss: 2.771512985229492
Validation loss: 2.0017235612356536

Epoch: 37| Step: 0
Training loss: 2.5080389976501465
Validation loss: 1.9951285418643747

Epoch: 5| Step: 1
Training loss: 2.3156216144561768
Validation loss: 1.98866061241396

Epoch: 5| Step: 2
Training loss: 1.7236793041229248
Validation loss: 1.994602672515377

Epoch: 5| Step: 3
Training loss: 2.191214084625244
Validation loss: 2.0081018427366852

Epoch: 5| Step: 4
Training loss: 2.573086977005005
Validation loss: 1.995835401678598

Epoch: 5| Step: 5
Training loss: 2.794511079788208
Validation loss: 1.9874963504011913

Epoch: 5| Step: 6
Training loss: 2.71930193901062
Validation loss: 1.9983261016107374

Epoch: 5| Step: 7
Training loss: 2.548388957977295
Validation loss: 1.9893567331375615

Epoch: 5| Step: 8
Training loss: 2.4531211853027344
Validation loss: 2.0070203709345993

Epoch: 5| Step: 9
Training loss: 2.192011594772339
Validation loss: 1.9901113381949804

Epoch: 5| Step: 10
Training loss: 2.6170027256011963
Validation loss: 2.006448430399741

Epoch: 38| Step: 0
Training loss: 2.3878469467163086
Validation loss: 1.9996397584997199

Epoch: 5| Step: 1
Training loss: 2.6237006187438965
Validation loss: 1.998568804033341

Epoch: 5| Step: 2
Training loss: 2.89825701713562
Validation loss: 2.0042934135724138

Epoch: 5| Step: 3
Training loss: 2.3504223823547363
Validation loss: 1.995450988892586

Epoch: 5| Step: 4
Training loss: 1.9708877801895142
Validation loss: 2.011080816227903

Epoch: 5| Step: 5
Training loss: 2.182124614715576
Validation loss: 1.9973379206913773

Epoch: 5| Step: 6
Training loss: 2.37716007232666
Validation loss: 1.993910381870885

Epoch: 5| Step: 7
Training loss: 2.3624672889709473
Validation loss: 2.009926447304346

Epoch: 5| Step: 8
Training loss: 2.318434238433838
Validation loss: 1.9966792624483827

Epoch: 5| Step: 9
Training loss: 2.605705499649048
Validation loss: 1.988161930473902

Epoch: 5| Step: 10
Training loss: 2.435126781463623
Validation loss: 1.9942226166366248

Epoch: 39| Step: 0
Training loss: 2.537482738494873
Validation loss: 2.01029214807736

Epoch: 5| Step: 1
Training loss: 2.4571969509124756
Validation loss: 2.000750410941339

Epoch: 5| Step: 2
Training loss: 2.5370161533355713
Validation loss: 1.9961889200313117

Epoch: 5| Step: 3
Training loss: 2.7059836387634277
Validation loss: 1.995177266418293

Epoch: 5| Step: 4
Training loss: 2.6759543418884277
Validation loss: 1.9891154368718464

Epoch: 5| Step: 5
Training loss: 2.224627733230591
Validation loss: 2.0040709228925806

Epoch: 5| Step: 6
Training loss: 2.305288791656494
Validation loss: 1.9973775507301412

Epoch: 5| Step: 7
Training loss: 2.3164641857147217
Validation loss: 2.000193288249354

Epoch: 5| Step: 8
Training loss: 2.051252841949463
Validation loss: 2.0156124202154015

Epoch: 5| Step: 9
Training loss: 1.9576143026351929
Validation loss: 2.0060433162155973

Epoch: 5| Step: 10
Training loss: 2.8791675567626953
Validation loss: 2.000271245997439

Epoch: 40| Step: 0
Training loss: 2.2375271320343018
Validation loss: 1.9989160542847009

Epoch: 5| Step: 1
Training loss: 2.790414810180664
Validation loss: 2.004060831121219

Epoch: 5| Step: 2
Training loss: 2.431060314178467
Validation loss: 2.005631564765848

Epoch: 5| Step: 3
Training loss: 1.9576982259750366
Validation loss: 2.0000557796929472

Epoch: 5| Step: 4
Training loss: 2.825284481048584
Validation loss: 1.9976017834037862

Epoch: 5| Step: 5
Training loss: 2.2873141765594482
Validation loss: 1.9982063078111219

Epoch: 5| Step: 6
Training loss: 2.5866565704345703
Validation loss: 2.006154655128397

Epoch: 5| Step: 7
Training loss: 2.025460720062256
Validation loss: 1.9991926788001932

Epoch: 5| Step: 8
Training loss: 2.5757317543029785
Validation loss: 1.9964883712030226

Epoch: 5| Step: 9
Training loss: 1.9936765432357788
Validation loss: 2.0045061560087305

Epoch: 5| Step: 10
Training loss: 2.8345627784729004
Validation loss: 2.0012145401329122

Epoch: 41| Step: 0
Training loss: 2.361685276031494
Validation loss: 1.999758848579981

Epoch: 5| Step: 1
Training loss: 2.4042274951934814
Validation loss: 2.008010402802498

Epoch: 5| Step: 2
Training loss: 2.8897323608398438
Validation loss: 1.9932247618193268

Epoch: 5| Step: 3
Training loss: 2.252319574356079
Validation loss: 2.002161534883643

Epoch: 5| Step: 4
Training loss: 2.750000238418579
Validation loss: 2.001856796203121

Epoch: 5| Step: 5
Training loss: 1.979469656944275
Validation loss: 1.9902242563104118

Epoch: 5| Step: 6
Training loss: 2.129727602005005
Validation loss: 1.9961830210942093

Epoch: 5| Step: 7
Training loss: 2.468538284301758
Validation loss: 2.0122020911144953

Epoch: 5| Step: 8
Training loss: 2.4592604637145996
Validation loss: 1.9824747347062635

Epoch: 5| Step: 9
Training loss: 2.131865978240967
Validation loss: 2.0119864838097685

Epoch: 5| Step: 10
Training loss: 2.50295352935791
Validation loss: 1.991275598925929

Epoch: 42| Step: 0
Training loss: 2.315432071685791
Validation loss: 2.0152500457661127

Epoch: 5| Step: 1
Training loss: 1.9772312641143799
Validation loss: 1.9979352694685741

Epoch: 5| Step: 2
Training loss: 2.6895506381988525
Validation loss: 1.999572192468951

Epoch: 5| Step: 3
Training loss: 2.323939800262451
Validation loss: 2.005652250782136

Epoch: 5| Step: 4
Training loss: 2.5144357681274414
Validation loss: 1.9928046182919574

Epoch: 5| Step: 5
Training loss: 2.947296380996704
Validation loss: 2.00512546108615

Epoch: 5| Step: 6
Training loss: 2.2309212684631348
Validation loss: 2.0009120766834547

Epoch: 5| Step: 7
Training loss: 2.394594669342041
Validation loss: 1.989319706475863

Epoch: 5| Step: 8
Training loss: 2.305299758911133
Validation loss: 2.0020441867971934

Epoch: 5| Step: 9
Training loss: 2.239046812057495
Validation loss: 2.0024922252983175

Epoch: 5| Step: 10
Training loss: 2.493067979812622
Validation loss: 1.9957371988604147

Epoch: 43| Step: 0
Training loss: 1.9677845239639282
Validation loss: 2.005933427041577

Epoch: 5| Step: 1
Training loss: 2.38266921043396
Validation loss: 2.002289172141783

Epoch: 5| Step: 2
Training loss: 2.198951005935669
Validation loss: 1.9969964668314943

Epoch: 5| Step: 3
Training loss: 2.1785542964935303
Validation loss: 1.9969413434305499

Epoch: 5| Step: 4
Training loss: 2.3619723320007324
Validation loss: 1.9842391219190372

Epoch: 5| Step: 5
Training loss: 2.922150135040283
Validation loss: 1.979967660801385

Epoch: 5| Step: 6
Training loss: 2.1617984771728516
Validation loss: 1.9829234923085859

Epoch: 5| Step: 7
Training loss: 2.710115671157837
Validation loss: 1.9945419501232844

Epoch: 5| Step: 8
Training loss: 2.554030656814575
Validation loss: 2.002505833102811

Epoch: 5| Step: 9
Training loss: 2.54705810546875
Validation loss: 1.9853561027075655

Epoch: 5| Step: 10
Training loss: 2.392503499984741
Validation loss: 1.981173748611122

Epoch: 44| Step: 0
Training loss: 2.5977776050567627
Validation loss: 1.9865711581322454

Epoch: 5| Step: 1
Training loss: 2.6660830974578857
Validation loss: 1.9785171747207642

Epoch: 5| Step: 2
Training loss: 2.5941643714904785
Validation loss: 1.9819100082561534

Epoch: 5| Step: 3
Training loss: 2.3405144214630127
Validation loss: 1.9863539408611994

Epoch: 5| Step: 4
Training loss: 1.9262502193450928
Validation loss: 1.9833122479018344

Epoch: 5| Step: 5
Training loss: 2.0849032402038574
Validation loss: 1.9870190876786427

Epoch: 5| Step: 6
Training loss: 2.2645671367645264
Validation loss: 1.9890057502254364

Epoch: 5| Step: 7
Training loss: 2.310110569000244
Validation loss: 1.989653210486135

Epoch: 5| Step: 8
Training loss: 2.5510616302490234
Validation loss: 1.990057655560073

Epoch: 5| Step: 9
Training loss: 2.7326793670654297
Validation loss: 1.9853270258954776

Epoch: 5| Step: 10
Training loss: 2.2590410709381104
Validation loss: 1.982156321566592

Epoch: 45| Step: 0
Training loss: 2.4288249015808105
Validation loss: 1.985193653773236

Epoch: 5| Step: 1
Training loss: 2.2219951152801514
Validation loss: 1.9903266737538

Epoch: 5| Step: 2
Training loss: 2.421077251434326
Validation loss: 1.985130786895752

Epoch: 5| Step: 3
Training loss: 2.240495443344116
Validation loss: 1.9937417481535225

Epoch: 5| Step: 4
Training loss: 2.4179298877716064
Validation loss: 1.9886530471104447

Epoch: 5| Step: 5
Training loss: 2.4576895236968994
Validation loss: 1.9833072911026657

Epoch: 5| Step: 6
Training loss: 2.659729480743408
Validation loss: 1.9883700980935046

Epoch: 5| Step: 7
Training loss: 2.5150814056396484
Validation loss: 2.0003294380762244

Epoch: 5| Step: 8
Training loss: 2.3448550701141357
Validation loss: 2.0002576881839382

Epoch: 5| Step: 9
Training loss: 2.409419298171997
Validation loss: 2.002024307045885

Epoch: 5| Step: 10
Training loss: 2.100037097930908
Validation loss: 2.00141022282262

Epoch: 46| Step: 0
Training loss: 2.4400877952575684
Validation loss: 1.9969099260145617

Epoch: 5| Step: 1
Training loss: 2.0454862117767334
Validation loss: 1.998672890406783

Epoch: 5| Step: 2
Training loss: 2.03226900100708
Validation loss: 1.9836912462788243

Epoch: 5| Step: 3
Training loss: 2.750519275665283
Validation loss: 2.0100196151323217

Epoch: 5| Step: 4
Training loss: 2.674185276031494
Validation loss: 2.0101400421511744

Epoch: 5| Step: 5
Training loss: 2.7371020317077637
Validation loss: 1.9989403268342376

Epoch: 5| Step: 6
Training loss: 2.32060170173645
Validation loss: 1.9990027745564778

Epoch: 5| Step: 7
Training loss: 2.2552895545959473
Validation loss: 2.0134998854770454

Epoch: 5| Step: 8
Training loss: 1.752179503440857
Validation loss: 2.0075031583027174

Epoch: 5| Step: 9
Training loss: 2.461007833480835
Validation loss: 1.9914448645807081

Epoch: 5| Step: 10
Training loss: 2.899707555770874
Validation loss: 2.010654713517876

Epoch: 47| Step: 0
Training loss: 2.5816402435302734
Validation loss: 2.0088167575097855

Epoch: 5| Step: 1
Training loss: 2.2048003673553467
Validation loss: 1.9989892641703289

Epoch: 5| Step: 2
Training loss: 2.7363243103027344
Validation loss: 2.004340584560107

Epoch: 5| Step: 3
Training loss: 2.384509563446045
Validation loss: 2.0061622383773967

Epoch: 5| Step: 4
Training loss: 1.8253206014633179
Validation loss: 2.0033485658707155

Epoch: 5| Step: 5
Training loss: 2.3953166007995605
Validation loss: 1.9949706510830951

Epoch: 5| Step: 6
Training loss: 2.5814669132232666
Validation loss: 2.003696785178236

Epoch: 5| Step: 7
Training loss: 2.370816469192505
Validation loss: 1.994669501499463

Epoch: 5| Step: 8
Training loss: 2.872002124786377
Validation loss: 2.00229916521298

Epoch: 5| Step: 9
Training loss: 2.6935527324676514
Validation loss: 2.0053459213626

Epoch: 5| Step: 10
Training loss: 1.480825662612915
Validation loss: 1.9945315366150231

Epoch: 48| Step: 0
Training loss: 2.362675428390503
Validation loss: 2.0011833829264485

Epoch: 5| Step: 1
Training loss: 2.465965986251831
Validation loss: 1.993638987182289

Epoch: 5| Step: 2
Training loss: 2.1847763061523438
Validation loss: 1.996608123984388

Epoch: 5| Step: 3
Training loss: 2.4431405067443848
Validation loss: 1.999782371264632

Epoch: 5| Step: 4
Training loss: 2.657224178314209
Validation loss: 1.97674048203294

Epoch: 5| Step: 5
Training loss: 2.457239866256714
Validation loss: 1.9928931036303121

Epoch: 5| Step: 6
Training loss: 2.049598455429077
Validation loss: 1.9955899894878428

Epoch: 5| Step: 7
Training loss: 2.0940616130828857
Validation loss: 1.987888281063367

Epoch: 5| Step: 8
Training loss: 2.352159023284912
Validation loss: 1.9944603545691377

Epoch: 5| Step: 9
Training loss: 2.7175540924072266
Validation loss: 1.9776348401141424

Epoch: 5| Step: 10
Training loss: 2.5173451900482178
Validation loss: 1.9815040352523967

Epoch: 49| Step: 0
Training loss: 2.110895872116089
Validation loss: 1.9740500911589591

Epoch: 5| Step: 1
Training loss: 2.439835786819458
Validation loss: 1.9900224516468663

Epoch: 5| Step: 2
Training loss: 2.3990533351898193
Validation loss: 1.9771802874021633

Epoch: 5| Step: 3
Training loss: 2.2771658897399902
Validation loss: 1.9877431213214833

Epoch: 5| Step: 4
Training loss: 2.6891028881073
Validation loss: 1.993249672715382

Epoch: 5| Step: 5
Training loss: 2.601581573486328
Validation loss: 1.975833377530498

Epoch: 5| Step: 6
Training loss: 1.7418744564056396
Validation loss: 1.9782436637468235

Epoch: 5| Step: 7
Training loss: 2.2935523986816406
Validation loss: 1.991534169002246

Epoch: 5| Step: 8
Training loss: 2.9912052154541016
Validation loss: 1.9725508779607794

Epoch: 5| Step: 9
Training loss: 2.159111976623535
Validation loss: 1.9844405907456593

Epoch: 5| Step: 10
Training loss: 2.5025532245635986
Validation loss: 1.987261583728175

Epoch: 50| Step: 0
Training loss: 2.390491485595703
Validation loss: 1.9781486090793405

Epoch: 5| Step: 1
Training loss: 2.0012409687042236
Validation loss: 1.9989521170175204

Epoch: 5| Step: 2
Training loss: 2.3293545246124268
Validation loss: 1.9882160348276938

Epoch: 5| Step: 3
Training loss: 2.4339871406555176
Validation loss: 1.9818372880258868

Epoch: 5| Step: 4
Training loss: 1.7211730480194092
Validation loss: 1.9840130523968769

Epoch: 5| Step: 5
Training loss: 2.5401108264923096
Validation loss: 1.9884744151946037

Epoch: 5| Step: 6
Training loss: 2.4031882286071777
Validation loss: 1.9853865561946746

Epoch: 5| Step: 7
Training loss: 2.7793338298797607
Validation loss: 1.9884025666021532

Epoch: 5| Step: 8
Training loss: 2.8057780265808105
Validation loss: 2.0007346189150246

Epoch: 5| Step: 9
Training loss: 2.49517822265625
Validation loss: 2.000694599202884

Epoch: 5| Step: 10
Training loss: 2.259298086166382
Validation loss: 2.003578797463448

Epoch: 51| Step: 0
Training loss: 2.754351854324341
Validation loss: 1.9894607131199171

Epoch: 5| Step: 1
Training loss: 2.1046395301818848
Validation loss: 1.9985323529089651

Epoch: 5| Step: 2
Training loss: 2.343809127807617
Validation loss: 1.988398689095692

Epoch: 5| Step: 3
Training loss: 2.276763916015625
Validation loss: 1.9886611584694154

Epoch: 5| Step: 4
Training loss: 2.1929519176483154
Validation loss: 1.9986723148694603

Epoch: 5| Step: 5
Training loss: 2.182717800140381
Validation loss: 1.9953369145752282

Epoch: 5| Step: 6
Training loss: 2.4108316898345947
Validation loss: 1.9974080824082898

Epoch: 5| Step: 7
Training loss: 2.609973192214966
Validation loss: 1.9947434779136413

Epoch: 5| Step: 8
Training loss: 1.816490888595581
Validation loss: 1.9858748874356669

Epoch: 5| Step: 9
Training loss: 2.6476142406463623
Validation loss: 2.0017181724630375

Epoch: 5| Step: 10
Training loss: 2.834014892578125
Validation loss: 2.003236242519912

Epoch: 52| Step: 0
Training loss: 2.289201498031616
Validation loss: 2.0061670657127135

Epoch: 5| Step: 1
Training loss: 2.2003254890441895
Validation loss: 1.9970569097867577

Epoch: 5| Step: 2
Training loss: 2.6400184631347656
Validation loss: 2.010204815095471

Epoch: 5| Step: 3
Training loss: 2.184950828552246
Validation loss: 1.9952517401787542

Epoch: 5| Step: 4
Training loss: 2.230146646499634
Validation loss: 1.9950238812354304

Epoch: 5| Step: 5
Training loss: 2.8435282707214355
Validation loss: 1.9931664005402596

Epoch: 5| Step: 6
Training loss: 1.888091802597046
Validation loss: 1.9811588692408737

Epoch: 5| Step: 7
Training loss: 1.760266900062561
Validation loss: 1.9956856261017502

Epoch: 5| Step: 8
Training loss: 2.990596055984497
Validation loss: 1.9897144866246048

Epoch: 5| Step: 9
Training loss: 2.323000192642212
Validation loss: 1.99991318743716

Epoch: 5| Step: 10
Training loss: 2.8067984580993652
Validation loss: 1.9801941635788127

Epoch: 53| Step: 0
Training loss: 2.383861541748047
Validation loss: 1.9783573073725547

Epoch: 5| Step: 1
Training loss: 2.182457447052002
Validation loss: 1.9823668618356027

Epoch: 5| Step: 2
Training loss: 1.8597275018692017
Validation loss: 2.002125281159596

Epoch: 5| Step: 3
Training loss: 2.35487699508667
Validation loss: 2.000365577718263

Epoch: 5| Step: 4
Training loss: 2.1871893405914307
Validation loss: 2.001492968169592

Epoch: 5| Step: 5
Training loss: 2.581042528152466
Validation loss: 1.9951272177439865

Epoch: 5| Step: 6
Training loss: 2.8167614936828613
Validation loss: 2.003103131889015

Epoch: 5| Step: 7
Training loss: 3.0242667198181152
Validation loss: 1.9921048289986067

Epoch: 5| Step: 8
Training loss: 2.4038734436035156
Validation loss: 1.992141694150945

Epoch: 5| Step: 9
Training loss: 1.9811662435531616
Validation loss: 2.002908916883571

Epoch: 5| Step: 10
Training loss: 2.289483070373535
Validation loss: 2.0007256359182377

Epoch: 54| Step: 0
Training loss: 2.4736087322235107
Validation loss: 2.0005894963459303

Epoch: 5| Step: 1
Training loss: 2.0102591514587402
Validation loss: 1.992021906760431

Epoch: 5| Step: 2
Training loss: 2.035900831222534
Validation loss: 1.9862866094035487

Epoch: 5| Step: 3
Training loss: 2.9806323051452637
Validation loss: 1.9950658326507897

Epoch: 5| Step: 4
Training loss: 2.296468496322632
Validation loss: 1.9983641832105574

Epoch: 5| Step: 5
Training loss: 2.3225274085998535
Validation loss: 1.99219823011788

Epoch: 5| Step: 6
Training loss: 2.563838481903076
Validation loss: 1.9901399881609025

Epoch: 5| Step: 7
Training loss: 2.157625436782837
Validation loss: 1.9967482756542903

Epoch: 5| Step: 8
Training loss: 2.5166895389556885
Validation loss: 2.0134115834389963

Epoch: 5| Step: 9
Training loss: 2.460803747177124
Validation loss: 1.9867924298009565

Epoch: 5| Step: 10
Training loss: 2.2746639251708984
Validation loss: 1.9879223762019989

Epoch: 55| Step: 0
Training loss: 2.920097827911377
Validation loss: 1.9846693751632527

Epoch: 5| Step: 1
Training loss: 1.9326250553131104
Validation loss: 1.9898767112403788

Epoch: 5| Step: 2
Training loss: 2.0018362998962402
Validation loss: 1.982074474775663

Epoch: 5| Step: 3
Training loss: 2.9046471118927
Validation loss: 1.9866316190329931

Epoch: 5| Step: 4
Training loss: 1.5362961292266846
Validation loss: 1.989708339014361

Epoch: 5| Step: 5
Training loss: 2.8787426948547363
Validation loss: 1.9704920322664323

Epoch: 5| Step: 6
Training loss: 2.416254758834839
Validation loss: 1.9962584780108543

Epoch: 5| Step: 7
Training loss: 1.9269533157348633
Validation loss: 1.9847135543823242

Epoch: 5| Step: 8
Training loss: 2.836972713470459
Validation loss: 1.9884573054570023

Epoch: 5| Step: 9
Training loss: 2.3808975219726562
Validation loss: 1.9842395628652265

Epoch: 5| Step: 10
Training loss: 2.240422487258911
Validation loss: 1.9797341759486864

Epoch: 56| Step: 0
Training loss: 2.36433744430542
Validation loss: 1.9758617275504655

Epoch: 5| Step: 1
Training loss: 2.78926420211792
Validation loss: 1.9723149461130942

Epoch: 5| Step: 2
Training loss: 2.689694881439209
Validation loss: 1.9759769631970314

Epoch: 5| Step: 3
Training loss: 2.2605745792388916
Validation loss: 1.992219101998114

Epoch: 5| Step: 4
Training loss: 2.3989219665527344
Validation loss: 1.9738774914895334

Epoch: 5| Step: 5
Training loss: 1.8078218698501587
Validation loss: 1.9818406181950723

Epoch: 5| Step: 6
Training loss: 2.0266380310058594
Validation loss: 1.9916309054179857

Epoch: 5| Step: 7
Training loss: 2.1280014514923096
Validation loss: 1.9839239069210586

Epoch: 5| Step: 8
Training loss: 2.0530335903167725
Validation loss: 1.9917758998050485

Epoch: 5| Step: 9
Training loss: 2.5449090003967285
Validation loss: 1.994751722581925

Epoch: 5| Step: 10
Training loss: 3.0248749256134033
Validation loss: 1.9887317867689236

Epoch: 57| Step: 0
Training loss: 2.9755473136901855
Validation loss: 1.9918472920694659

Epoch: 5| Step: 1
Training loss: 2.0611913204193115
Validation loss: 1.9892752465381418

Epoch: 5| Step: 2
Training loss: 2.557943105697632
Validation loss: 1.969878690217131

Epoch: 5| Step: 3
Training loss: 2.5218286514282227
Validation loss: 1.9886676598620672

Epoch: 5| Step: 4
Training loss: 1.9481796026229858
Validation loss: 1.9844183396267634

Epoch: 5| Step: 5
Training loss: 2.892965078353882
Validation loss: 1.9919244089434225

Epoch: 5| Step: 6
Training loss: 1.7961161136627197
Validation loss: 2.0008982022603354

Epoch: 5| Step: 7
Training loss: 2.434081554412842
Validation loss: 1.9939442001363283

Epoch: 5| Step: 8
Training loss: 2.2025973796844482
Validation loss: 1.9807869362574753

Epoch: 5| Step: 9
Training loss: 2.0085673332214355
Validation loss: 1.9952571994514876

Epoch: 5| Step: 10
Training loss: 2.575632095336914
Validation loss: 1.98416430206709

Epoch: 58| Step: 0
Training loss: 1.8687245845794678
Validation loss: 1.9618062806385819

Epoch: 5| Step: 1
Training loss: 2.204981803894043
Validation loss: 1.998869316552275

Epoch: 5| Step: 2
Training loss: 2.4943625926971436
Validation loss: 1.980775406283717

Epoch: 5| Step: 3
Training loss: 1.6742286682128906
Validation loss: 1.9944446176610968

Epoch: 5| Step: 4
Training loss: 2.740011692047119
Validation loss: 1.9808664693627307

Epoch: 5| Step: 5
Training loss: 2.6957383155822754
Validation loss: 1.9985606285833544

Epoch: 5| Step: 6
Training loss: 2.154015064239502
Validation loss: 1.983924606794952

Epoch: 5| Step: 7
Training loss: 2.0395286083221436
Validation loss: 1.9912543296813965

Epoch: 5| Step: 8
Training loss: 2.8097920417785645
Validation loss: 2.003658137013835

Epoch: 5| Step: 9
Training loss: 2.8408796787261963
Validation loss: 1.995512653422612

Epoch: 5| Step: 10
Training loss: 2.4259064197540283
Validation loss: 2.0039814800344486

Epoch: 59| Step: 0
Training loss: 2.262291669845581
Validation loss: 1.9941198915563605

Epoch: 5| Step: 1
Training loss: 2.6673076152801514
Validation loss: 1.981857161368093

Epoch: 5| Step: 2
Training loss: 2.602745532989502
Validation loss: 2.0082208776986725

Epoch: 5| Step: 3
Training loss: 2.248353958129883
Validation loss: 1.983652263559321

Epoch: 5| Step: 4
Training loss: 2.6894595623016357
Validation loss: 1.986877675979368

Epoch: 5| Step: 5
Training loss: 2.3724334239959717
Validation loss: 1.998130980358329

Epoch: 5| Step: 6
Training loss: 2.156716823577881
Validation loss: 1.9839899770675167

Epoch: 5| Step: 7
Training loss: 2.086451530456543
Validation loss: 1.9711250207757438

Epoch: 5| Step: 8
Training loss: 2.4825572967529297
Validation loss: 1.9987781329821515

Epoch: 5| Step: 9
Training loss: 2.340334415435791
Validation loss: 1.9881690330402826

Epoch: 5| Step: 10
Training loss: 1.8918116092681885
Validation loss: 1.9855873636020127

Epoch: 60| Step: 0
Training loss: 2.4137909412384033
Validation loss: 1.9942711130265267

Epoch: 5| Step: 1
Training loss: 1.962012529373169
Validation loss: 1.9743960724082044

Epoch: 5| Step: 2
Training loss: 2.4016928672790527
Validation loss: 1.9879933852021412

Epoch: 5| Step: 3
Training loss: 2.4675071239471436
Validation loss: 1.9952134932241132

Epoch: 5| Step: 4
Training loss: 2.501765727996826
Validation loss: 1.9936971382428241

Epoch: 5| Step: 5
Training loss: 2.3087518215179443
Validation loss: 1.98883056640625

Epoch: 5| Step: 6
Training loss: 2.311577558517456
Validation loss: 1.9958736101786296

Epoch: 5| Step: 7
Training loss: 2.1605780124664307
Validation loss: 1.9886845081083235

Epoch: 5| Step: 8
Training loss: 2.588580369949341
Validation loss: 1.9939245049671461

Epoch: 5| Step: 9
Training loss: 2.8803186416625977
Validation loss: 1.9875139728669198

Epoch: 5| Step: 10
Training loss: 1.8333947658538818
Validation loss: 1.9967523979884323

Epoch: 61| Step: 0
Training loss: 1.8777379989624023
Validation loss: 1.9996165178155387

Epoch: 5| Step: 1
Training loss: 2.569974422454834
Validation loss: 1.9860619473200973

Epoch: 5| Step: 2
Training loss: 2.441697597503662
Validation loss: 1.978261306721677

Epoch: 5| Step: 3
Training loss: 2.3870530128479004
Validation loss: 1.987124616099942

Epoch: 5| Step: 4
Training loss: 3.484226942062378
Validation loss: 2.003266990825694

Epoch: 5| Step: 5
Training loss: 2.328782796859741
Validation loss: 1.9991623650314987

Epoch: 5| Step: 6
Training loss: 2.7313828468322754
Validation loss: 2.0028710826750724

Epoch: 5| Step: 7
Training loss: 1.5794367790222168
Validation loss: 2.0005538335410495

Epoch: 5| Step: 8
Training loss: 2.014843225479126
Validation loss: 1.9860503519735029

Epoch: 5| Step: 9
Training loss: 2.0118327140808105
Validation loss: 1.9997109533638082

Epoch: 5| Step: 10
Training loss: 2.3753743171691895
Validation loss: 1.998109386813256

Epoch: 62| Step: 0
Training loss: 2.013669490814209
Validation loss: 1.998878889186408

Epoch: 5| Step: 1
Training loss: 2.247934103012085
Validation loss: 1.9967863367449852

Epoch: 5| Step: 2
Training loss: 2.499577522277832
Validation loss: 1.9935702418768277

Epoch: 5| Step: 3
Training loss: 2.1021475791931152
Validation loss: 2.004871222280687

Epoch: 5| Step: 4
Training loss: 2.49574875831604
Validation loss: 1.992907508727043

Epoch: 5| Step: 5
Training loss: 2.6930956840515137
Validation loss: 1.9930013110560756

Epoch: 5| Step: 6
Training loss: 2.8564553260803223
Validation loss: 1.9959725333798317

Epoch: 5| Step: 7
Training loss: 2.2310757637023926
Validation loss: 1.9875235647283576

Epoch: 5| Step: 8
Training loss: 2.3166589736938477
Validation loss: 1.9797694811256983

Epoch: 5| Step: 9
Training loss: 1.9808495044708252
Validation loss: 1.9900059584648377

Epoch: 5| Step: 10
Training loss: 2.2417569160461426
Validation loss: 1.9869982016983854

Epoch: 63| Step: 0
Training loss: 2.298074245452881
Validation loss: 1.9752972356734737

Epoch: 5| Step: 1
Training loss: 2.14676833152771
Validation loss: 1.9874789189266902

Epoch: 5| Step: 2
Training loss: 2.346294403076172
Validation loss: 1.9990206046770977

Epoch: 5| Step: 3
Training loss: 2.275505781173706
Validation loss: 1.9926140859562864

Epoch: 5| Step: 4
Training loss: 2.1932358741760254
Validation loss: 1.9795258301560597

Epoch: 5| Step: 5
Training loss: 2.5586769580841064
Validation loss: 1.9896722044996036

Epoch: 5| Step: 6
Training loss: 2.738180637359619
Validation loss: 1.992249176066409

Epoch: 5| Step: 7
Training loss: 2.4672634601593018
Validation loss: 1.9945856781416043

Epoch: 5| Step: 8
Training loss: 1.9979407787322998
Validation loss: 1.9878672912556639

Epoch: 5| Step: 9
Training loss: 2.157440662384033
Validation loss: 1.9856676927176855

Epoch: 5| Step: 10
Training loss: 2.603638172149658
Validation loss: 1.9923621736547

Epoch: 64| Step: 0
Training loss: 2.3870155811309814
Validation loss: 1.9665598305322791

Epoch: 5| Step: 1
Training loss: 1.9821571111679077
Validation loss: 1.9969431610517605

Epoch: 5| Step: 2
Training loss: 2.4940617084503174
Validation loss: 1.9938098717761297

Epoch: 5| Step: 3
Training loss: 1.7988300323486328
Validation loss: 1.9634029262809343

Epoch: 5| Step: 4
Training loss: 2.462568759918213
Validation loss: 1.9717637787583053

Epoch: 5| Step: 5
Training loss: 2.6109063625335693
Validation loss: 1.9838022724274667

Epoch: 5| Step: 6
Training loss: 2.2042365074157715
Validation loss: 1.9771596872678368

Epoch: 5| Step: 7
Training loss: 3.4349796772003174
Validation loss: 1.990476482657976

Epoch: 5| Step: 8
Training loss: 1.9482225179672241
Validation loss: 1.9844458103179932

Epoch: 5| Step: 9
Training loss: 2.3932032585144043
Validation loss: 1.97183846786458

Epoch: 5| Step: 10
Training loss: 2.0118470191955566
Validation loss: 1.9721607405652282

Epoch: 65| Step: 0
Training loss: 2.6552469730377197
Validation loss: 1.976969785587762

Epoch: 5| Step: 1
Training loss: 2.591890335083008
Validation loss: 1.984277754701594

Epoch: 5| Step: 2
Training loss: 2.5240514278411865
Validation loss: 1.9778312534414313

Epoch: 5| Step: 3
Training loss: 2.278820753097534
Validation loss: 1.9789008632782967

Epoch: 5| Step: 4
Training loss: 2.363569498062134
Validation loss: 1.9863697918512488

Epoch: 5| Step: 5
Training loss: 2.5057082176208496
Validation loss: 1.9764785061600387

Epoch: 5| Step: 6
Training loss: 1.7009891271591187
Validation loss: 1.9875976731700282

Epoch: 5| Step: 7
Training loss: 2.0774168968200684
Validation loss: 1.982616029759889

Epoch: 5| Step: 8
Training loss: 2.649162769317627
Validation loss: 1.9700655168102634

Epoch: 5| Step: 9
Training loss: 2.1075124740600586
Validation loss: 1.9678079543575164

Epoch: 5| Step: 10
Training loss: 2.158921241760254
Validation loss: 1.970828817736718

Epoch: 66| Step: 0
Training loss: 2.7286548614501953
Validation loss: 1.9597906938163183

Epoch: 5| Step: 1
Training loss: 2.3789470195770264
Validation loss: 1.9818019623397498

Epoch: 5| Step: 2
Training loss: 2.0554003715515137
Validation loss: 1.9831225590039325

Epoch: 5| Step: 3
Training loss: 1.756113052368164
Validation loss: 1.982520648228225

Epoch: 5| Step: 4
Training loss: 2.4775664806365967
Validation loss: 1.9855900169700704

Epoch: 5| Step: 5
Training loss: 2.656609535217285
Validation loss: 1.9693065689456077

Epoch: 5| Step: 6
Training loss: 2.5423781871795654
Validation loss: 1.9810729308794903

Epoch: 5| Step: 7
Training loss: 2.454129695892334
Validation loss: 1.9692917075208438

Epoch: 5| Step: 8
Training loss: 2.2686572074890137
Validation loss: 1.9929179145443825

Epoch: 5| Step: 9
Training loss: 1.9532495737075806
Validation loss: 1.9773038228352864

Epoch: 5| Step: 10
Training loss: 2.388059616088867
Validation loss: 1.976340119556714

Epoch: 67| Step: 0
Training loss: 2.2485737800598145
Validation loss: 1.9803939583480998

Epoch: 5| Step: 1
Training loss: 2.090616464614868
Validation loss: 1.9815128541761828

Epoch: 5| Step: 2
Training loss: 2.572822093963623
Validation loss: 1.9646820547760173

Epoch: 5| Step: 3
Training loss: 2.2571587562561035
Validation loss: 1.9780071320072297

Epoch: 5| Step: 4
Training loss: 2.448160171508789
Validation loss: 1.9802579302941599

Epoch: 5| Step: 5
Training loss: 2.134909152984619
Validation loss: 1.9874733327537455

Epoch: 5| Step: 6
Training loss: 2.5027880668640137
Validation loss: 1.9829245882649575

Epoch: 5| Step: 7
Training loss: 2.3147659301757812
Validation loss: 1.970815263768678

Epoch: 5| Step: 8
Training loss: 2.471306800842285
Validation loss: 1.979173409041538

Epoch: 5| Step: 9
Training loss: 2.330862522125244
Validation loss: 1.9684588960421983

Epoch: 5| Step: 10
Training loss: 2.265155553817749
Validation loss: 1.9629991259626163

Epoch: 68| Step: 0
Training loss: 2.0059542655944824
Validation loss: 1.9596501191457112

Epoch: 5| Step: 1
Training loss: 2.076735019683838
Validation loss: 1.9849064119400517

Epoch: 5| Step: 2
Training loss: 2.213179588317871
Validation loss: 1.9720553787805701

Epoch: 5| Step: 3
Training loss: 2.4520392417907715
Validation loss: 1.9692977974491734

Epoch: 5| Step: 4
Training loss: 1.918674111366272
Validation loss: 1.9866228821457073

Epoch: 5| Step: 5
Training loss: 2.753429889678955
Validation loss: 1.9853922244041198

Epoch: 5| Step: 6
Training loss: 2.2924938201904297
Validation loss: 1.9808999107730003

Epoch: 5| Step: 7
Training loss: 2.4573991298675537
Validation loss: 1.9651497307644095

Epoch: 5| Step: 8
Training loss: 2.7527709007263184
Validation loss: 1.9741122043260964

Epoch: 5| Step: 9
Training loss: 2.1082382202148438
Validation loss: 1.9783033401735368

Epoch: 5| Step: 10
Training loss: 2.5001068115234375
Validation loss: 1.9747140766471944

Epoch: 69| Step: 0
Training loss: 2.5391011238098145
Validation loss: 1.983876225768879

Epoch: 5| Step: 1
Training loss: 2.456879138946533
Validation loss: 1.977229433674966

Epoch: 5| Step: 2
Training loss: 1.8586933612823486
Validation loss: 1.9891197681427002

Epoch: 5| Step: 3
Training loss: 2.257310390472412
Validation loss: 1.9862945707895423

Epoch: 5| Step: 4
Training loss: 2.18835186958313
Validation loss: 1.9788829536848171

Epoch: 5| Step: 5
Training loss: 2.079827070236206
Validation loss: 1.9553456742276427

Epoch: 5| Step: 6
Training loss: 3.1503517627716064
Validation loss: 1.9712017787400113

Epoch: 5| Step: 7
Training loss: 2.1391243934631348
Validation loss: 1.9929596685594129

Epoch: 5| Step: 8
Training loss: 2.2139618396759033
Validation loss: 1.9792791233267835

Epoch: 5| Step: 9
Training loss: 2.372407913208008
Validation loss: 1.9792899559902888

Epoch: 5| Step: 10
Training loss: 2.164241313934326
Validation loss: 1.959623577774212

Epoch: 70| Step: 0
Training loss: 1.6442899703979492
Validation loss: 1.9693132972204557

Epoch: 5| Step: 1
Training loss: 1.7799476385116577
Validation loss: 1.9753319242949128

Epoch: 5| Step: 2
Training loss: 2.086064577102661
Validation loss: 1.9755020885057346

Epoch: 5| Step: 3
Training loss: 2.8791027069091797
Validation loss: 1.9876861136446717

Epoch: 5| Step: 4
Training loss: 1.9197295904159546
Validation loss: 1.9707978899760912

Epoch: 5| Step: 5
Training loss: 2.6460795402526855
Validation loss: 1.9700167999472669

Epoch: 5| Step: 6
Training loss: 2.2068276405334473
Validation loss: 1.97979304739224

Epoch: 5| Step: 7
Training loss: 2.8222930431365967
Validation loss: 1.983200506497455

Epoch: 5| Step: 8
Training loss: 2.515585422515869
Validation loss: 1.9831756750742595

Epoch: 5| Step: 9
Training loss: 2.5181713104248047
Validation loss: 1.9685599829560967

Epoch: 5| Step: 10
Training loss: 2.452167510986328
Validation loss: 1.9786976075941516

Epoch: 71| Step: 0
Training loss: 2.469250440597534
Validation loss: 1.972554700348967

Epoch: 5| Step: 1
Training loss: 3.132136821746826
Validation loss: 1.9752511414148475

Epoch: 5| Step: 2
Training loss: 2.4767932891845703
Validation loss: 1.9686720204609696

Epoch: 5| Step: 3
Training loss: 2.2543447017669678
Validation loss: 1.9894453735761746

Epoch: 5| Step: 4
Training loss: 1.9415981769561768
Validation loss: 1.983231234294112

Epoch: 5| Step: 5
Training loss: 1.6199833154678345
Validation loss: 1.9942246611400316

Epoch: 5| Step: 6
Training loss: 2.0047402381896973
Validation loss: 1.9773583309624785

Epoch: 5| Step: 7
Training loss: 2.6210904121398926
Validation loss: 1.9848313741786505

Epoch: 5| Step: 8
Training loss: 2.2454512119293213
Validation loss: 1.985807244495679

Epoch: 5| Step: 9
Training loss: 2.3336188793182373
Validation loss: 1.97875581249114

Epoch: 5| Step: 10
Training loss: 2.354757308959961
Validation loss: 1.9845194457679667

Epoch: 72| Step: 0
Training loss: 2.877251148223877
Validation loss: 1.9794299487144715

Epoch: 5| Step: 1
Training loss: 2.2975094318389893
Validation loss: 1.9775814497342674

Epoch: 5| Step: 2
Training loss: 2.1834158897399902
Validation loss: 1.988990524763702

Epoch: 5| Step: 3
Training loss: 2.3213894367218018
Validation loss: 1.9847576272103093

Epoch: 5| Step: 4
Training loss: 1.7528423070907593
Validation loss: 1.9816286871510167

Epoch: 5| Step: 5
Training loss: 2.094118356704712
Validation loss: 1.9904746419639998

Epoch: 5| Step: 6
Training loss: 2.0817055702209473
Validation loss: 1.9671555872886413

Epoch: 5| Step: 7
Training loss: 2.243391513824463
Validation loss: 1.9769829357824018

Epoch: 5| Step: 8
Training loss: 2.6112685203552246
Validation loss: 1.9662554546069073

Epoch: 5| Step: 9
Training loss: 2.8016936779022217
Validation loss: 1.964169603522106

Epoch: 5| Step: 10
Training loss: 2.159601926803589
Validation loss: 1.9747786150183728

Epoch: 73| Step: 0
Training loss: 1.979397177696228
Validation loss: 1.9677645083396667

Epoch: 5| Step: 1
Training loss: 2.2735562324523926
Validation loss: 1.9621708803279425

Epoch: 5| Step: 2
Training loss: 2.156106472015381
Validation loss: 1.9708387761987665

Epoch: 5| Step: 3
Training loss: 2.4705400466918945
Validation loss: 1.9637455850519159

Epoch: 5| Step: 4
Training loss: 2.6600520610809326
Validation loss: 1.9568949899365824

Epoch: 5| Step: 5
Training loss: 2.138597011566162
Validation loss: 1.9563711009999758

Epoch: 5| Step: 6
Training loss: 2.5733258724212646
Validation loss: 1.9680075671083184

Epoch: 5| Step: 7
Training loss: 1.9721988439559937
Validation loss: 1.9621484766724289

Epoch: 5| Step: 8
Training loss: 2.1247451305389404
Validation loss: 1.9626573042203022

Epoch: 5| Step: 9
Training loss: 2.5217983722686768
Validation loss: 1.966550624498757

Epoch: 5| Step: 10
Training loss: 2.4905970096588135
Validation loss: 1.969951029746763

Epoch: 74| Step: 0
Training loss: 2.3156051635742188
Validation loss: 1.9554983954275809

Epoch: 5| Step: 1
Training loss: 2.825821876525879
Validation loss: 1.97833598813703

Epoch: 5| Step: 2
Training loss: 2.6630606651306152
Validation loss: 1.9610823687686716

Epoch: 5| Step: 3
Training loss: 1.8791126012802124
Validation loss: 1.9581537297976914

Epoch: 5| Step: 4
Training loss: 2.434553384780884
Validation loss: 1.9713235849975257

Epoch: 5| Step: 5
Training loss: 1.5749003887176514
Validation loss: 1.965705571636077

Epoch: 5| Step: 6
Training loss: 2.528366804122925
Validation loss: 1.9630079602682462

Epoch: 5| Step: 7
Training loss: 2.1013171672821045
Validation loss: 1.9624583592978857

Epoch: 5| Step: 8
Training loss: 2.1580758094787598
Validation loss: 1.9522473581375615

Epoch: 5| Step: 9
Training loss: 2.470440149307251
Validation loss: 1.9721145527337187

Epoch: 5| Step: 10
Training loss: 2.445380926132202
Validation loss: 1.9693302723669237

Epoch: 75| Step: 0
Training loss: 2.583383083343506
Validation loss: 1.9584698151516657

Epoch: 5| Step: 1
Training loss: 2.9678821563720703
Validation loss: 1.9678228478277884

Epoch: 5| Step: 2
Training loss: 2.0891504287719727
Validation loss: 1.9636250618965394

Epoch: 5| Step: 3
Training loss: 2.1568214893341064
Validation loss: 1.9693710547621532

Epoch: 5| Step: 4
Training loss: 2.7350151538848877
Validation loss: 1.969242501002486

Epoch: 5| Step: 5
Training loss: 2.2608916759490967
Validation loss: 1.970677565502864

Epoch: 5| Step: 6
Training loss: 1.5281864404678345
Validation loss: 1.9703680763962448

Epoch: 5| Step: 7
Training loss: 2.4561362266540527
Validation loss: 1.9634623796709123

Epoch: 5| Step: 8
Training loss: 2.5008928775787354
Validation loss: 1.966550645007882

Epoch: 5| Step: 9
Training loss: 2.3589489459991455
Validation loss: 1.9678038550961403

Epoch: 5| Step: 10
Training loss: 1.519834280014038
Validation loss: 1.9669963198323404

Epoch: 76| Step: 0
Training loss: 2.1003336906433105
Validation loss: 1.976191197672198

Epoch: 5| Step: 1
Training loss: 2.058074951171875
Validation loss: 1.9605251255855765

Epoch: 5| Step: 2
Training loss: 2.466900587081909
Validation loss: 1.9593214732344433

Epoch: 5| Step: 3
Training loss: 2.2656216621398926
Validation loss: 1.976785558526234

Epoch: 5| Step: 4
Training loss: 2.8146884441375732
Validation loss: 1.9805403294101838

Epoch: 5| Step: 5
Training loss: 2.441614866256714
Validation loss: 1.9758737317977413

Epoch: 5| Step: 6
Training loss: 2.3097567558288574
Validation loss: 1.9666816713989421

Epoch: 5| Step: 7
Training loss: 1.908738136291504
Validation loss: 1.9758080385064567

Epoch: 5| Step: 8
Training loss: 2.2119648456573486
Validation loss: 1.958774092376873

Epoch: 5| Step: 9
Training loss: 2.623262882232666
Validation loss: 1.974315607419578

Epoch: 5| Step: 10
Training loss: 1.9344375133514404
Validation loss: 1.9642055778093235

Epoch: 77| Step: 0
Training loss: 1.9244563579559326
Validation loss: 1.9581986883635163

Epoch: 5| Step: 1
Training loss: 1.9763696193695068
Validation loss: 1.9680458755903347

Epoch: 5| Step: 2
Training loss: 2.360051393508911
Validation loss: 1.975043939005944

Epoch: 5| Step: 3
Training loss: 2.7313570976257324
Validation loss: 1.9581370827972249

Epoch: 5| Step: 4
Training loss: 1.986583948135376
Validation loss: 1.956941835341915

Epoch: 5| Step: 5
Training loss: 2.42177677154541
Validation loss: 1.9609722886034238

Epoch: 5| Step: 6
Training loss: 2.523097515106201
Validation loss: 1.971715828423859

Epoch: 5| Step: 7
Training loss: 2.384215831756592
Validation loss: 1.9662378577775852

Epoch: 5| Step: 8
Training loss: 2.9123058319091797
Validation loss: 1.9676878221573368

Epoch: 5| Step: 9
Training loss: 1.5704760551452637
Validation loss: 1.957108647592606

Epoch: 5| Step: 10
Training loss: 2.3654518127441406
Validation loss: 1.9612146128890335

Epoch: 78| Step: 0
Training loss: 2.172071933746338
Validation loss: 1.9669041505423925

Epoch: 5| Step: 1
Training loss: 2.263683795928955
Validation loss: 1.9666169279365129

Epoch: 5| Step: 2
Training loss: 1.4830248355865479
Validation loss: 1.959875592621424

Epoch: 5| Step: 3
Training loss: 2.0815958976745605
Validation loss: 1.9597421371808617

Epoch: 5| Step: 4
Training loss: 2.3064703941345215
Validation loss: 1.9642355006228212

Epoch: 5| Step: 5
Training loss: 2.503323793411255
Validation loss: 1.9782144292708366

Epoch: 5| Step: 6
Training loss: 2.9365291595458984
Validation loss: 1.956966007909467

Epoch: 5| Step: 7
Training loss: 2.517699718475342
Validation loss: 1.950844040480993

Epoch: 5| Step: 8
Training loss: 1.9345687627792358
Validation loss: 1.9608956383120628

Epoch: 5| Step: 9
Training loss: 2.814079999923706
Validation loss: 1.961476210624941

Epoch: 5| Step: 10
Training loss: 2.0709824562072754
Validation loss: 1.9595939267066218

Epoch: 79| Step: 0
Training loss: 2.0410943031311035
Validation loss: 1.9576325480655958

Epoch: 5| Step: 1
Training loss: 2.4527430534362793
Validation loss: 1.9567296043519051

Epoch: 5| Step: 2
Training loss: 2.364107608795166
Validation loss: 1.9573097511004376

Epoch: 5| Step: 3
Training loss: 2.567143678665161
Validation loss: 1.969409922117828

Epoch: 5| Step: 4
Training loss: 2.4420294761657715
Validation loss: 1.944724714884194

Epoch: 5| Step: 5
Training loss: 3.101245403289795
Validation loss: 1.9463236408848916

Epoch: 5| Step: 6
Training loss: 1.2121517658233643
Validation loss: 1.959889933627139

Epoch: 5| Step: 7
Training loss: 1.9472668170928955
Validation loss: 1.9759715449425481

Epoch: 5| Step: 8
Training loss: 1.8222625255584717
Validation loss: 1.945881958930723

Epoch: 5| Step: 9
Training loss: 2.5803308486938477
Validation loss: 1.9708150471410444

Epoch: 5| Step: 10
Training loss: 2.6255245208740234
Validation loss: 1.9622835215701853

Epoch: 80| Step: 0
Training loss: 2.4528796672821045
Validation loss: 1.9656077149093791

Epoch: 5| Step: 1
Training loss: 2.331099510192871
Validation loss: 1.9772406252481605

Epoch: 5| Step: 2
Training loss: 1.7947899103164673
Validation loss: 1.9657464155586817

Epoch: 5| Step: 3
Training loss: 2.207127332687378
Validation loss: 1.946553522540677

Epoch: 5| Step: 4
Training loss: 3.0832858085632324
Validation loss: 1.9610123403610722

Epoch: 5| Step: 5
Training loss: 1.7871897220611572
Validation loss: 1.959334627274544

Epoch: 5| Step: 6
Training loss: 2.088341236114502
Validation loss: 1.9488081150157477

Epoch: 5| Step: 7
Training loss: 2.434072494506836
Validation loss: 1.9637481820198797

Epoch: 5| Step: 8
Training loss: 2.346386432647705
Validation loss: 1.9408109136807021

Epoch: 5| Step: 9
Training loss: 2.002906322479248
Validation loss: 1.9651902555137553

Epoch: 5| Step: 10
Training loss: 2.5729517936706543
Validation loss: 1.9533278429380028

Epoch: 81| Step: 0
Training loss: 2.3885657787323
Validation loss: 1.9536340710937337

Epoch: 5| Step: 1
Training loss: 2.3892242908477783
Validation loss: 1.9533789004048994

Epoch: 5| Step: 2
Training loss: 2.063716411590576
Validation loss: 1.963234337427283

Epoch: 5| Step: 3
Training loss: 2.5014395713806152
Validation loss: 1.9455614474511915

Epoch: 5| Step: 4
Training loss: 2.5710976123809814
Validation loss: 1.9529785366468533

Epoch: 5| Step: 5
Training loss: 2.3700294494628906
Validation loss: 1.9544122308813117

Epoch: 5| Step: 6
Training loss: 2.057384967803955
Validation loss: 1.9651286294383388

Epoch: 5| Step: 7
Training loss: 1.9306726455688477
Validation loss: 1.9540626361805906

Epoch: 5| Step: 8
Training loss: 2.077098846435547
Validation loss: 1.959273947182522

Epoch: 5| Step: 9
Training loss: 2.255451202392578
Validation loss: 1.9625802334918772

Epoch: 5| Step: 10
Training loss: 2.505647897720337
Validation loss: 1.952734597267643

Epoch: 82| Step: 0
Training loss: 1.8867428302764893
Validation loss: 1.9558928833212903

Epoch: 5| Step: 1
Training loss: 2.384213924407959
Validation loss: 1.968307646371985

Epoch: 5| Step: 2
Training loss: 1.8030248880386353
Validation loss: 1.955224496062084

Epoch: 5| Step: 3
Training loss: 1.9565222263336182
Validation loss: 1.9450592892144316

Epoch: 5| Step: 4
Training loss: 2.5800909996032715
Validation loss: 1.9618307300793227

Epoch: 5| Step: 5
Training loss: 2.3647754192352295
Validation loss: 1.9517454678012478

Epoch: 5| Step: 6
Training loss: 2.4492123126983643
Validation loss: 1.9690893542382024

Epoch: 5| Step: 7
Training loss: 2.8837215900421143
Validation loss: 1.9453622833375008

Epoch: 5| Step: 8
Training loss: 2.2265336513519287
Validation loss: 1.9513016029070782

Epoch: 5| Step: 9
Training loss: 2.108949661254883
Validation loss: 1.956686976135418

Epoch: 5| Step: 10
Training loss: 2.377615451812744
Validation loss: 1.9415771756120908

Epoch: 83| Step: 0
Training loss: 2.4241878986358643
Validation loss: 1.9601017839165145

Epoch: 5| Step: 1
Training loss: 1.5161534547805786
Validation loss: 1.9421677884235178

Epoch: 5| Step: 2
Training loss: 2.4704222679138184
Validation loss: 1.969075172178207

Epoch: 5| Step: 3
Training loss: 2.377653121948242
Validation loss: 1.9662149529303274

Epoch: 5| Step: 4
Training loss: 2.360067844390869
Validation loss: 1.9593398122377292

Epoch: 5| Step: 5
Training loss: 2.885122776031494
Validation loss: 1.9740377215928928

Epoch: 5| Step: 6
Training loss: 2.4846084117889404
Validation loss: 1.971937479511384

Epoch: 5| Step: 7
Training loss: 2.143841505050659
Validation loss: 1.965542277982158

Epoch: 5| Step: 8
Training loss: 1.9960594177246094
Validation loss: 1.9840792532890075

Epoch: 5| Step: 9
Training loss: 1.8283522129058838
Validation loss: 1.9692131575717722

Epoch: 5| Step: 10
Training loss: 2.7535390853881836
Validation loss: 1.9609502002757082

Epoch: 84| Step: 0
Training loss: 1.8291476964950562
Validation loss: 1.9541576908480736

Epoch: 5| Step: 1
Training loss: 2.1072001457214355
Validation loss: 1.9500851938801427

Epoch: 5| Step: 2
Training loss: 2.734436511993408
Validation loss: 1.9518429733091784

Epoch: 5| Step: 3
Training loss: 2.165050506591797
Validation loss: 1.9801259874015726

Epoch: 5| Step: 4
Training loss: 2.310945987701416
Validation loss: 1.959595025226634

Epoch: 5| Step: 5
Training loss: 2.085509777069092
Validation loss: 1.9648536584710563

Epoch: 5| Step: 6
Training loss: 2.247954845428467
Validation loss: 1.9611345260374007

Epoch: 5| Step: 7
Training loss: 2.275508403778076
Validation loss: 1.9550901638564242

Epoch: 5| Step: 8
Training loss: 1.7538923025131226
Validation loss: 1.9596643396603164

Epoch: 5| Step: 9
Training loss: 2.909493923187256
Validation loss: 1.9529488343064503

Epoch: 5| Step: 10
Training loss: 2.5120584964752197
Validation loss: 1.9656149520668933

Epoch: 85| Step: 0
Training loss: 2.4025182723999023
Validation loss: 1.9561166558214413

Epoch: 5| Step: 1
Training loss: 2.4636504650115967
Validation loss: 1.9466798100420224

Epoch: 5| Step: 2
Training loss: 2.7120018005371094
Validation loss: 1.9573976737196728

Epoch: 5| Step: 3
Training loss: 2.000608444213867
Validation loss: 1.9528484113754765

Epoch: 5| Step: 4
Training loss: 2.264411449432373
Validation loss: 1.9469467209231468

Epoch: 5| Step: 5
Training loss: 2.427415132522583
Validation loss: 1.9475916944524294

Epoch: 5| Step: 6
Training loss: 1.927064299583435
Validation loss: 1.956288267207402

Epoch: 5| Step: 7
Training loss: 1.8439314365386963
Validation loss: 1.9421802413079046

Epoch: 5| Step: 8
Training loss: 2.220911979675293
Validation loss: 1.9485590919371574

Epoch: 5| Step: 9
Training loss: 2.6371493339538574
Validation loss: 1.9539977914543563

Epoch: 5| Step: 10
Training loss: 1.8719186782836914
Validation loss: 1.9547241067373624

Epoch: 86| Step: 0
Training loss: 1.9451820850372314
Validation loss: 1.9453591287776988

Epoch: 5| Step: 1
Training loss: 2.8075623512268066
Validation loss: 1.9608578143581268

Epoch: 5| Step: 2
Training loss: 2.377431869506836
Validation loss: 1.9485625605429373

Epoch: 5| Step: 3
Training loss: 1.9914028644561768
Validation loss: 1.9351960407790316

Epoch: 5| Step: 4
Training loss: 2.1614716053009033
Validation loss: 1.9548122344478485

Epoch: 5| Step: 5
Training loss: 2.38655161857605
Validation loss: 1.9415056013291883

Epoch: 5| Step: 6
Training loss: 1.8631231784820557
Validation loss: 1.9372279849103702

Epoch: 5| Step: 7
Training loss: 2.7052345275878906
Validation loss: 1.9375189453042962

Epoch: 5| Step: 8
Training loss: 2.2718429565429688
Validation loss: 1.944912797661238

Epoch: 5| Step: 9
Training loss: 2.0578269958496094
Validation loss: 1.9645725578390143

Epoch: 5| Step: 10
Training loss: 2.262436866760254
Validation loss: 1.9536650655090169

Epoch: 87| Step: 0
Training loss: 2.3857522010803223
Validation loss: 1.9441416878854074

Epoch: 5| Step: 1
Training loss: 3.0019233226776123
Validation loss: 1.9362001829249884

Epoch: 5| Step: 2
Training loss: 2.195136785507202
Validation loss: 1.9447978337605794

Epoch: 5| Step: 3
Training loss: 2.4150540828704834
Validation loss: 1.9414833156011437

Epoch: 5| Step: 4
Training loss: 2.1147732734680176
Validation loss: 1.947398744603639

Epoch: 5| Step: 5
Training loss: 3.2115769386291504
Validation loss: 1.9360962157608361

Epoch: 5| Step: 6
Training loss: 1.988104224205017
Validation loss: 1.938849461975918

Epoch: 5| Step: 7
Training loss: 1.9013826847076416
Validation loss: 1.932129257468767

Epoch: 5| Step: 8
Training loss: 1.4647092819213867
Validation loss: 1.9370687956451087

Epoch: 5| Step: 9
Training loss: 1.7436145544052124
Validation loss: 1.9498100370489142

Epoch: 5| Step: 10
Training loss: 2.331986427307129
Validation loss: 1.9366101552081365

Epoch: 88| Step: 0
Training loss: 2.184626817703247
Validation loss: 1.9428017600890128

Epoch: 5| Step: 1
Training loss: 2.2668862342834473
Validation loss: 1.9368312538311045

Epoch: 5| Step: 2
Training loss: 2.4647483825683594
Validation loss: 1.9342049642275738

Epoch: 5| Step: 3
Training loss: 2.440826416015625
Validation loss: 1.9412368253995014

Epoch: 5| Step: 4
Training loss: 2.465172290802002
Validation loss: 1.9382961591084797

Epoch: 5| Step: 5
Training loss: 2.372663974761963
Validation loss: 1.9301464608920518

Epoch: 5| Step: 6
Training loss: 1.774009108543396
Validation loss: 1.9360175081478652

Epoch: 5| Step: 7
Training loss: 2.18994402885437
Validation loss: 1.9304008381341093

Epoch: 5| Step: 8
Training loss: 2.095655918121338
Validation loss: 1.9357757619632188

Epoch: 5| Step: 9
Training loss: 1.870234727859497
Validation loss: 1.9391257801363546

Epoch: 5| Step: 10
Training loss: 2.48892879486084
Validation loss: 1.9280040981949016

Epoch: 89| Step: 0
Training loss: 1.9518229961395264
Validation loss: 1.937287430609426

Epoch: 5| Step: 1
Training loss: 2.2864503860473633
Validation loss: 1.9490419023780412

Epoch: 5| Step: 2
Training loss: 1.7467867136001587
Validation loss: 1.938433793283278

Epoch: 5| Step: 3
Training loss: 2.146852731704712
Validation loss: 1.9444053596065891

Epoch: 5| Step: 4
Training loss: 2.401538848876953
Validation loss: 1.9550433287056543

Epoch: 5| Step: 5
Training loss: 2.4719865322113037
Validation loss: 1.9404245743187525

Epoch: 5| Step: 6
Training loss: 2.8122105598449707
Validation loss: 1.948576304220384

Epoch: 5| Step: 7
Training loss: 2.0602805614471436
Validation loss: 1.9461794976265199

Epoch: 5| Step: 8
Training loss: 2.338488817214966
Validation loss: 1.9590204492692025

Epoch: 5| Step: 9
Training loss: 2.6191697120666504
Validation loss: 1.9348423634805987

Epoch: 5| Step: 10
Training loss: 1.642653465270996
Validation loss: 1.9468530967671385

Epoch: 90| Step: 0
Training loss: 2.277773380279541
Validation loss: 1.9543044451744325

Epoch: 5| Step: 1
Training loss: 2.7523601055145264
Validation loss: 1.9522026508085188

Epoch: 5| Step: 2
Training loss: 1.9447662830352783
Validation loss: 1.9500621339326263

Epoch: 5| Step: 3
Training loss: 2.0674707889556885
Validation loss: 1.92953662718496

Epoch: 5| Step: 4
Training loss: 2.1034693717956543
Validation loss: 1.932341073148994

Epoch: 5| Step: 5
Training loss: 2.8550338745117188
Validation loss: 1.944849544955838

Epoch: 5| Step: 6
Training loss: 1.7451854944229126
Validation loss: 1.941989826899703

Epoch: 5| Step: 7
Training loss: 1.900259256362915
Validation loss: 1.9301238239452403

Epoch: 5| Step: 8
Training loss: 2.677736759185791
Validation loss: 1.9409801549808954

Epoch: 5| Step: 9
Training loss: 2.135141372680664
Validation loss: 1.9473013595868183

Epoch: 5| Step: 10
Training loss: 2.221879243850708
Validation loss: 1.9539080691593949

Epoch: 91| Step: 0
Training loss: 2.35697603225708
Validation loss: 1.9356126605823476

Epoch: 5| Step: 1
Training loss: 2.0240349769592285
Validation loss: 1.9204135582011232

Epoch: 5| Step: 2
Training loss: 2.2241101264953613
Validation loss: 1.9579723547863703

Epoch: 5| Step: 3
Training loss: 2.3752098083496094
Validation loss: 1.9257302745696037

Epoch: 5| Step: 4
Training loss: 2.0867443084716797
Validation loss: 1.9241927528894076

Epoch: 5| Step: 5
Training loss: 2.605996608734131
Validation loss: 1.9246371587117512

Epoch: 5| Step: 6
Training loss: 1.5573816299438477
Validation loss: 1.929352783387707

Epoch: 5| Step: 7
Training loss: 2.7947421073913574
Validation loss: 1.950045294659112

Epoch: 5| Step: 8
Training loss: 2.0270495414733887
Validation loss: 1.9478816140082575

Epoch: 5| Step: 9
Training loss: 2.581529378890991
Validation loss: 1.9408840889571815

Epoch: 5| Step: 10
Training loss: 1.8892642259597778
Validation loss: 1.9341220266075545

Epoch: 92| Step: 0
Training loss: 1.9748032093048096
Validation loss: 1.9283584215307747

Epoch: 5| Step: 1
Training loss: 2.362539529800415
Validation loss: 1.945208937891068

Epoch: 5| Step: 2
Training loss: 1.7485460042953491
Validation loss: 1.9308753167429278

Epoch: 5| Step: 3
Training loss: 1.7100884914398193
Validation loss: 1.924359078048378

Epoch: 5| Step: 4
Training loss: 2.495298385620117
Validation loss: 1.9329610614366428

Epoch: 5| Step: 5
Training loss: 2.091787815093994
Validation loss: 1.93792708458439

Epoch: 5| Step: 6
Training loss: 2.126730442047119
Validation loss: 1.9260261135716592

Epoch: 5| Step: 7
Training loss: 2.094580888748169
Validation loss: 1.935482136664852

Epoch: 5| Step: 8
Training loss: 2.5480551719665527
Validation loss: 1.936647702288884

Epoch: 5| Step: 9
Training loss: 2.8524351119995117
Validation loss: 1.9274047856689782

Epoch: 5| Step: 10
Training loss: 2.7172248363494873
Validation loss: 1.9247295318111297

Epoch: 93| Step: 0
Training loss: 2.327775478363037
Validation loss: 1.9480790886827695

Epoch: 5| Step: 1
Training loss: 2.299607753753662
Validation loss: 1.9508890272468649

Epoch: 5| Step: 2
Training loss: 2.268853187561035
Validation loss: 1.952559409602996

Epoch: 5| Step: 3
Training loss: 2.4568564891815186
Validation loss: 1.9278627813503306

Epoch: 5| Step: 4
Training loss: 2.3914780616760254
Validation loss: 1.9367550521768548

Epoch: 5| Step: 5
Training loss: 1.5387989282608032
Validation loss: 1.934075746484982

Epoch: 5| Step: 6
Training loss: 1.5128610134124756
Validation loss: 1.9304142639201174

Epoch: 5| Step: 7
Training loss: 2.6406030654907227
Validation loss: 1.9569913879517586

Epoch: 5| Step: 8
Training loss: 2.3291056156158447
Validation loss: 1.9367236129699215

Epoch: 5| Step: 9
Training loss: 2.1457207202911377
Validation loss: 1.9374940369718818

Epoch: 5| Step: 10
Training loss: 2.5355923175811768
Validation loss: 1.947428705871746

Epoch: 94| Step: 0
Training loss: 2.0049471855163574
Validation loss: 1.9518795782519924

Epoch: 5| Step: 1
Training loss: 2.9383416175842285
Validation loss: 1.9623137392023557

Epoch: 5| Step: 2
Training loss: 2.625136137008667
Validation loss: 1.9325669298889816

Epoch: 5| Step: 3
Training loss: 1.9986908435821533
Validation loss: 1.9579569242333854

Epoch: 5| Step: 4
Training loss: 1.6563256978988647
Validation loss: 1.9331737718274515

Epoch: 5| Step: 5
Training loss: 2.4920132160186768
Validation loss: 1.9391769850125877

Epoch: 5| Step: 6
Training loss: 2.2414212226867676
Validation loss: 1.9409170150756836

Epoch: 5| Step: 7
Training loss: 1.8729299306869507
Validation loss: 1.9381548102184007

Epoch: 5| Step: 8
Training loss: 2.139218807220459
Validation loss: 1.95216271826016

Epoch: 5| Step: 9
Training loss: 1.7236617803573608
Validation loss: 1.9485150921729304

Epoch: 5| Step: 10
Training loss: 2.926862955093384
Validation loss: 1.9520733689749112

Epoch: 95| Step: 0
Training loss: 1.8951154947280884
Validation loss: 1.9428237394620014

Epoch: 5| Step: 1
Training loss: 2.3578262329101562
Validation loss: 1.9412309879897742

Epoch: 5| Step: 2
Training loss: 2.0713911056518555
Validation loss: 1.943859911734058

Epoch: 5| Step: 3
Training loss: 2.622620105743408
Validation loss: 1.9481429887074295

Epoch: 5| Step: 4
Training loss: 2.2009363174438477
Validation loss: 1.9502576217856458

Epoch: 5| Step: 5
Training loss: 2.2831501960754395
Validation loss: 1.946582999280704

Epoch: 5| Step: 6
Training loss: 1.874108076095581
Validation loss: 1.9406837340324157

Epoch: 5| Step: 7
Training loss: 2.2532403469085693
Validation loss: 1.9363875081462245

Epoch: 5| Step: 8
Training loss: 2.256352424621582
Validation loss: 1.9359655854522542

Epoch: 5| Step: 9
Training loss: 2.49735951423645
Validation loss: 1.9362493638069398

Epoch: 5| Step: 10
Training loss: 1.9419867992401123
Validation loss: 1.9558110032030331

Epoch: 96| Step: 0
Training loss: 2.0344061851501465
Validation loss: 1.940701255234339

Epoch: 5| Step: 1
Training loss: 2.602280616760254
Validation loss: 1.9537427656112178

Epoch: 5| Step: 2
Training loss: 1.8841352462768555
Validation loss: 1.9335310856501262

Epoch: 5| Step: 3
Training loss: 2.228018045425415
Validation loss: 1.948482290390999

Epoch: 5| Step: 4
Training loss: 2.830265522003174
Validation loss: 1.9507390029968754

Epoch: 5| Step: 5
Training loss: 1.8856576681137085
Validation loss: 1.931970545040664

Epoch: 5| Step: 6
Training loss: 2.020106792449951
Validation loss: 1.921804516546188

Epoch: 5| Step: 7
Training loss: 2.5483341217041016
Validation loss: 1.940998581147963

Epoch: 5| Step: 8
Training loss: 1.9381515979766846
Validation loss: 1.9475121190471034

Epoch: 5| Step: 9
Training loss: 2.18479323387146
Validation loss: 1.924354499386203

Epoch: 5| Step: 10
Training loss: 2.3505613803863525
Validation loss: 1.9275583554339666

Epoch: 97| Step: 0
Training loss: 2.5663464069366455
Validation loss: 1.939816427487199

Epoch: 5| Step: 1
Training loss: 1.8682094812393188
Validation loss: 1.9185270647848807

Epoch: 5| Step: 2
Training loss: 2.0482590198516846
Validation loss: 1.90924701639401

Epoch: 5| Step: 3
Training loss: 1.6433308124542236
Validation loss: 1.9264786948439896

Epoch: 5| Step: 4
Training loss: 2.3313791751861572
Validation loss: 1.9327133919603081

Epoch: 5| Step: 5
Training loss: 2.287602424621582
Validation loss: 1.9195446301532049

Epoch: 5| Step: 6
Training loss: 2.9724483489990234
Validation loss: 1.9237705123039983

Epoch: 5| Step: 7
Training loss: 2.243860960006714
Validation loss: 1.9284215934814946

Epoch: 5| Step: 8
Training loss: 2.3852436542510986
Validation loss: 1.902446759644375

Epoch: 5| Step: 9
Training loss: 2.146479368209839
Validation loss: 1.9125449477985341

Epoch: 5| Step: 10
Training loss: 1.848387360572815
Validation loss: 1.9395252350837953

Epoch: 98| Step: 0
Training loss: 2.389467239379883
Validation loss: 1.9313491672597907

Epoch: 5| Step: 1
Training loss: 2.3996167182922363
Validation loss: 1.930435703646752

Epoch: 5| Step: 2
Training loss: 1.9319603443145752
Validation loss: 1.9248662315389162

Epoch: 5| Step: 3
Training loss: 1.8786617517471313
Validation loss: 1.9264820673132454

Epoch: 5| Step: 4
Training loss: 2.4385218620300293
Validation loss: 1.9255100219480452

Epoch: 5| Step: 5
Training loss: 2.5899665355682373
Validation loss: 1.9420655940168647

Epoch: 5| Step: 6
Training loss: 2.160773277282715
Validation loss: 1.9438322410788587

Epoch: 5| Step: 7
Training loss: 1.6513086557388306
Validation loss: 1.9384732451490176

Epoch: 5| Step: 8
Training loss: 2.4428277015686035
Validation loss: 1.9360619027127501

Epoch: 5| Step: 9
Training loss: 2.18574857711792
Validation loss: 1.9321142678619714

Epoch: 5| Step: 10
Training loss: 2.2340362071990967
Validation loss: 1.959486444791158

Epoch: 99| Step: 0
Training loss: 2.537769317626953
Validation loss: 1.9249843448720954

Epoch: 5| Step: 1
Training loss: 1.6118767261505127
Validation loss: 1.9410678750725203

Epoch: 5| Step: 2
Training loss: 2.4377148151397705
Validation loss: 1.9325285521886681

Epoch: 5| Step: 3
Training loss: 2.266270637512207
Validation loss: 1.940414474856469

Epoch: 5| Step: 4
Training loss: 2.0382397174835205
Validation loss: 1.9339261106265488

Epoch: 5| Step: 5
Training loss: 2.0794320106506348
Validation loss: 1.9458454808881205

Epoch: 5| Step: 6
Training loss: 2.4138712882995605
Validation loss: 1.9336873818469305

Epoch: 5| Step: 7
Training loss: 2.6741745471954346
Validation loss: 1.95701091776612

Epoch: 5| Step: 8
Training loss: 1.8071397542953491
Validation loss: 1.9331086733007943

Epoch: 5| Step: 9
Training loss: 2.269439220428467
Validation loss: 1.9437445107326712

Epoch: 5| Step: 10
Training loss: 2.0487303733825684
Validation loss: 1.9507317953212286

Epoch: 100| Step: 0
Training loss: 2.093686103820801
Validation loss: 1.9370337019684494

Epoch: 5| Step: 1
Training loss: 2.224046230316162
Validation loss: 1.9564318323648104

Epoch: 5| Step: 2
Training loss: 2.609954357147217
Validation loss: 1.9282414003085064

Epoch: 5| Step: 3
Training loss: 2.1551783084869385
Validation loss: 1.9068252322494343

Epoch: 5| Step: 4
Training loss: 1.8171956539154053
Validation loss: 1.9347107833431614

Epoch: 5| Step: 5
Training loss: 2.555302143096924
Validation loss: 1.929668523932016

Epoch: 5| Step: 6
Training loss: 2.1093947887420654
Validation loss: 1.9414433599800192

Epoch: 5| Step: 7
Training loss: 1.9763052463531494
Validation loss: 1.918670577387656

Epoch: 5| Step: 8
Training loss: 2.148527145385742
Validation loss: 1.9257499684569657

Epoch: 5| Step: 9
Training loss: 2.61749005317688
Validation loss: 1.9212961760900353

Epoch: 5| Step: 10
Training loss: 1.7458610534667969
Validation loss: 1.9107716147617628

Epoch: 101| Step: 0
Training loss: 2.6676089763641357
Validation loss: 1.9194024019343878

Epoch: 5| Step: 1
Training loss: 1.8554773330688477
Validation loss: 1.9416654994410854

Epoch: 5| Step: 2
Training loss: 2.89152193069458
Validation loss: 1.9283941381721086

Epoch: 5| Step: 3
Training loss: 1.8435916900634766
Validation loss: 1.9368100499594083

Epoch: 5| Step: 4
Training loss: 2.23246693611145
Validation loss: 1.9412703924281622

Epoch: 5| Step: 5
Training loss: 2.101369857788086
Validation loss: 1.9225741599195747

Epoch: 5| Step: 6
Training loss: 1.333847999572754
Validation loss: 1.9473043129008303

Epoch: 5| Step: 7
Training loss: 2.1948676109313965
Validation loss: 1.9405555366187968

Epoch: 5| Step: 8
Training loss: 2.482302188873291
Validation loss: 1.9429255390679965

Epoch: 5| Step: 9
Training loss: 2.16867733001709
Validation loss: 1.9380679668918732

Epoch: 5| Step: 10
Training loss: 2.404423236846924
Validation loss: 1.9632504806723645

Epoch: 102| Step: 0
Training loss: 2.285463333129883
Validation loss: 1.9399232761834257

Epoch: 5| Step: 1
Training loss: 2.3085949420928955
Validation loss: 1.9429161061522782

Epoch: 5| Step: 2
Training loss: 1.9176435470581055
Validation loss: 1.9738206709584882

Epoch: 5| Step: 3
Training loss: 2.5264363288879395
Validation loss: 1.9443843774898077

Epoch: 5| Step: 4
Training loss: 2.365870952606201
Validation loss: 1.9645695429976269

Epoch: 5| Step: 5
Training loss: 1.8233087062835693
Validation loss: 1.9639398679938367

Epoch: 5| Step: 6
Training loss: 1.8564720153808594
Validation loss: 1.9543317107744114

Epoch: 5| Step: 7
Training loss: 2.6195569038391113
Validation loss: 1.9409958803525535

Epoch: 5| Step: 8
Training loss: 2.1427793502807617
Validation loss: 1.9539539057721373

Epoch: 5| Step: 9
Training loss: 1.9684200286865234
Validation loss: 1.9631765093854678

Epoch: 5| Step: 10
Training loss: 2.2834677696228027
Validation loss: 1.970784314217106

Epoch: 103| Step: 0
Training loss: 2.129478931427002
Validation loss: 1.9617822811167727

Epoch: 5| Step: 1
Training loss: 2.6528537273406982
Validation loss: 1.9599895477294922

Epoch: 5| Step: 2
Training loss: 2.0893917083740234
Validation loss: 1.9549929672671902

Epoch: 5| Step: 3
Training loss: 2.337984800338745
Validation loss: 1.9679347674051921

Epoch: 5| Step: 4
Training loss: 2.102665424346924
Validation loss: 1.9550820191701253

Epoch: 5| Step: 5
Training loss: 1.8781036138534546
Validation loss: 1.9675469026770642

Epoch: 5| Step: 6
Training loss: 2.411250591278076
Validation loss: 1.9573525972263788

Epoch: 5| Step: 7
Training loss: 2.076413631439209
Validation loss: 1.9628528202733686

Epoch: 5| Step: 8
Training loss: 1.5968718528747559
Validation loss: 1.9380233159629248

Epoch: 5| Step: 9
Training loss: 3.2370619773864746
Validation loss: 1.950653645300096

Epoch: 5| Step: 10
Training loss: 1.5488234758377075
Validation loss: 1.9549181768971104

Epoch: 104| Step: 0
Training loss: 1.873811960220337
Validation loss: 1.9524968119077786

Epoch: 5| Step: 1
Training loss: 2.2074081897735596
Validation loss: 1.940295248903254

Epoch: 5| Step: 2
Training loss: 2.239403486251831
Validation loss: 1.9431967530199277

Epoch: 5| Step: 3
Training loss: 2.362746000289917
Validation loss: 1.946635341131559

Epoch: 5| Step: 4
Training loss: 1.9504209756851196
Validation loss: 1.9405259983513945

Epoch: 5| Step: 5
Training loss: 2.076392650604248
Validation loss: 1.9609228949392996

Epoch: 5| Step: 6
Training loss: 2.140885829925537
Validation loss: 1.9380216624147149

Epoch: 5| Step: 7
Training loss: 2.259545087814331
Validation loss: 1.926409382973948

Epoch: 5| Step: 8
Training loss: 2.172156810760498
Validation loss: 1.9306874352116739

Epoch: 5| Step: 9
Training loss: 2.3572964668273926
Validation loss: 1.9394262567643197

Epoch: 5| Step: 10
Training loss: 2.529608726501465
Validation loss: 1.923886195305855

Epoch: 105| Step: 0
Training loss: 1.9205052852630615
Validation loss: 1.9493170079364572

Epoch: 5| Step: 1
Training loss: 2.374716281890869
Validation loss: 1.9288739081351989

Epoch: 5| Step: 2
Training loss: 1.8729126453399658
Validation loss: 1.930372384286696

Epoch: 5| Step: 3
Training loss: 2.4779319763183594
Validation loss: 1.9449035531731063

Epoch: 5| Step: 4
Training loss: 2.523425579071045
Validation loss: 1.9320705911164642

Epoch: 5| Step: 5
Training loss: 1.6591697931289673
Validation loss: 1.9421572762150918

Epoch: 5| Step: 6
Training loss: 1.9432731866836548
Validation loss: 1.9380690641300653

Epoch: 5| Step: 7
Training loss: 2.4821879863739014
Validation loss: 1.9362357918934157

Epoch: 5| Step: 8
Training loss: 2.0218825340270996
Validation loss: 1.9447868383058937

Epoch: 5| Step: 9
Training loss: 2.041774034500122
Validation loss: 1.9319295934451524

Epoch: 5| Step: 10
Training loss: 2.852315902709961
Validation loss: 1.9393125016202208

Epoch: 106| Step: 0
Training loss: 1.7911741733551025
Validation loss: 1.9434367790017077

Epoch: 5| Step: 1
Training loss: 2.1878817081451416
Validation loss: 1.9419614935433993

Epoch: 5| Step: 2
Training loss: 1.8582775592803955
Validation loss: 1.9532894165285173

Epoch: 5| Step: 3
Training loss: 1.997428297996521
Validation loss: 1.9449081164534374

Epoch: 5| Step: 4
Training loss: 2.527942419052124
Validation loss: 1.935551820262786

Epoch: 5| Step: 5
Training loss: 1.8436176776885986
Validation loss: 1.9492095055118683

Epoch: 5| Step: 6
Training loss: 2.605966806411743
Validation loss: 1.9452522505996048

Epoch: 5| Step: 7
Training loss: 2.313504695892334
Validation loss: 1.937265674273173

Epoch: 5| Step: 8
Training loss: 2.824643611907959
Validation loss: 1.935273496053552

Epoch: 5| Step: 9
Training loss: 2.2486393451690674
Validation loss: 1.959400382093204

Epoch: 5| Step: 10
Training loss: 1.8279058933258057
Validation loss: 1.9487089521141463

Epoch: 107| Step: 0
Training loss: 2.1273701190948486
Validation loss: 1.9476248436076666

Epoch: 5| Step: 1
Training loss: 1.9524719715118408
Validation loss: 1.9588788145331926

Epoch: 5| Step: 2
Training loss: 1.866946816444397
Validation loss: 1.9666421439058037

Epoch: 5| Step: 3
Training loss: 2.0822994709014893
Validation loss: 1.9683493721869685

Epoch: 5| Step: 4
Training loss: 2.3025522232055664
Validation loss: 1.9590209453336653

Epoch: 5| Step: 5
Training loss: 2.2383995056152344
Validation loss: 1.9488413103165165

Epoch: 5| Step: 6
Training loss: 2.2985620498657227
Validation loss: 1.9638741208660988

Epoch: 5| Step: 7
Training loss: 2.958561897277832
Validation loss: 1.9497687124436902

Epoch: 5| Step: 8
Training loss: 2.3323380947113037
Validation loss: 1.9446210028022848

Epoch: 5| Step: 9
Training loss: 1.9757966995239258
Validation loss: 1.966854787641956

Epoch: 5| Step: 10
Training loss: 1.8928049802780151
Validation loss: 1.9675183834568146

Epoch: 108| Step: 0
Training loss: 2.4938182830810547
Validation loss: 1.9314971546972952

Epoch: 5| Step: 1
Training loss: 1.8330574035644531
Validation loss: 1.9678980112075806

Epoch: 5| Step: 2
Training loss: 2.085719585418701
Validation loss: 1.939125044371492

Epoch: 5| Step: 3
Training loss: 2.431692600250244
Validation loss: 1.9417240594023017

Epoch: 5| Step: 4
Training loss: 1.9851573705673218
Validation loss: 1.9328213814766175

Epoch: 5| Step: 5
Training loss: 2.182415008544922
Validation loss: 1.9281444370105703

Epoch: 5| Step: 6
Training loss: 2.293410539627075
Validation loss: 1.937332184084

Epoch: 5| Step: 7
Training loss: 2.4185972213745117
Validation loss: 1.9292510991455407

Epoch: 5| Step: 8
Training loss: 1.7192519903182983
Validation loss: 1.934955217505014

Epoch: 5| Step: 9
Training loss: 2.358044147491455
Validation loss: 1.9350152912960257

Epoch: 5| Step: 10
Training loss: 2.1212425231933594
Validation loss: 1.9373872715939757

Epoch: 109| Step: 0
Training loss: 2.0754523277282715
Validation loss: 1.9397072381870721

Epoch: 5| Step: 1
Training loss: 1.8179244995117188
Validation loss: 1.9494016132047098

Epoch: 5| Step: 2
Training loss: 2.1183552742004395
Validation loss: 1.942407879778134

Epoch: 5| Step: 3
Training loss: 2.5724594593048096
Validation loss: 1.9505201796049714

Epoch: 5| Step: 4
Training loss: 1.9303302764892578
Validation loss: 1.9495977432497087

Epoch: 5| Step: 5
Training loss: 2.021308422088623
Validation loss: 1.957747643993747

Epoch: 5| Step: 6
Training loss: 2.4434573650360107
Validation loss: 1.943442484383942

Epoch: 5| Step: 7
Training loss: 1.7139461040496826
Validation loss: 1.9350827047901769

Epoch: 5| Step: 8
Training loss: 2.946800947189331
Validation loss: 1.9492031335830688

Epoch: 5| Step: 9
Training loss: 2.12622332572937
Validation loss: 1.944569323652534

Epoch: 5| Step: 10
Training loss: 2.0612566471099854
Validation loss: 1.9399858713150024

Epoch: 110| Step: 0
Training loss: 2.4210028648376465
Validation loss: 1.9513172590604393

Epoch: 5| Step: 1
Training loss: 2.2620692253112793
Validation loss: 1.9365247795658727

Epoch: 5| Step: 2
Training loss: 2.2807140350341797
Validation loss: 1.9428332005777667

Epoch: 5| Step: 3
Training loss: 2.095292329788208
Validation loss: 1.951976640250093

Epoch: 5| Step: 4
Training loss: 2.071722984313965
Validation loss: 1.968034634026148

Epoch: 5| Step: 5
Training loss: 1.9526866674423218
Validation loss: 1.9420415944950555

Epoch: 5| Step: 6
Training loss: 2.119819402694702
Validation loss: 1.9358464107718518

Epoch: 5| Step: 7
Training loss: 2.586092472076416
Validation loss: 1.941445336546949

Epoch: 5| Step: 8
Training loss: 1.825635313987732
Validation loss: 1.9461966458187308

Epoch: 5| Step: 9
Training loss: 1.892310380935669
Validation loss: 1.9238525257315686

Epoch: 5| Step: 10
Training loss: 2.390732765197754
Validation loss: 1.9300557695409304

Epoch: 111| Step: 0
Training loss: 2.049534320831299
Validation loss: 1.9421153850452875

Epoch: 5| Step: 1
Training loss: 2.173988103866577
Validation loss: 1.932686162251298

Epoch: 5| Step: 2
Training loss: 1.889120101928711
Validation loss: 1.9341707306523477

Epoch: 5| Step: 3
Training loss: 2.1596333980560303
Validation loss: 1.944300416977175

Epoch: 5| Step: 4
Training loss: 2.212663173675537
Validation loss: 1.9602908088314919

Epoch: 5| Step: 5
Training loss: 1.8769752979278564
Validation loss: 1.9215022671607234

Epoch: 5| Step: 6
Training loss: 2.373962879180908
Validation loss: 1.957944018866426

Epoch: 5| Step: 7
Training loss: 2.3065123558044434
Validation loss: 1.955177871129846

Epoch: 5| Step: 8
Training loss: 2.5728378295898438
Validation loss: 1.96115416865195

Epoch: 5| Step: 9
Training loss: 1.8466812372207642
Validation loss: 1.9422320486396871

Epoch: 5| Step: 10
Training loss: 2.3711981773376465
Validation loss: 1.950173670245755

Epoch: 112| Step: 0
Training loss: 1.9216785430908203
Validation loss: 1.948188094682591

Epoch: 5| Step: 1
Training loss: 2.8030388355255127
Validation loss: 1.9483826929523098

Epoch: 5| Step: 2
Training loss: 2.3741114139556885
Validation loss: 1.9451366727070143

Epoch: 5| Step: 3
Training loss: 1.4636001586914062
Validation loss: 1.970670606500359

Epoch: 5| Step: 4
Training loss: 1.7799209356307983
Validation loss: 1.9708519443388908

Epoch: 5| Step: 5
Training loss: 1.8829931020736694
Validation loss: 1.971296384770383

Epoch: 5| Step: 6
Training loss: 2.1100525856018066
Validation loss: 1.958548056182041

Epoch: 5| Step: 7
Training loss: 2.3623363971710205
Validation loss: 1.9609659256473664

Epoch: 5| Step: 8
Training loss: 1.9703794717788696
Validation loss: 1.9755339135405838

Epoch: 5| Step: 9
Training loss: 2.648993968963623
Validation loss: 1.9621829871208436

Epoch: 5| Step: 10
Training loss: 2.521472454071045
Validation loss: 1.9627587103074597

Epoch: 113| Step: 0
Training loss: 2.8460845947265625
Validation loss: 1.9698619688710859

Epoch: 5| Step: 1
Training loss: 1.6847909688949585
Validation loss: 1.9645495440370293

Epoch: 5| Step: 2
Training loss: 1.4802334308624268
Validation loss: 1.9668200272385792

Epoch: 5| Step: 3
Training loss: 1.8374464511871338
Validation loss: 1.945612447236174

Epoch: 5| Step: 4
Training loss: 2.5268936157226562
Validation loss: 1.9434347665438088

Epoch: 5| Step: 5
Training loss: 2.2406914234161377
Validation loss: 1.9701839403439594

Epoch: 5| Step: 6
Training loss: 2.4393045902252197
Validation loss: 1.9622390500960811

Epoch: 5| Step: 7
Training loss: 2.213893413543701
Validation loss: 1.9590449922828264

Epoch: 5| Step: 8
Training loss: 2.144838333129883
Validation loss: 1.9337031764368857

Epoch: 5| Step: 9
Training loss: 2.103248357772827
Validation loss: 1.9453063549533967

Epoch: 5| Step: 10
Training loss: 2.3245606422424316
Validation loss: 1.9389449934805594

Epoch: 114| Step: 0
Training loss: 1.9792267084121704
Validation loss: 1.9308216635898878

Epoch: 5| Step: 1
Training loss: 2.027693510055542
Validation loss: 1.9596329914626254

Epoch: 5| Step: 2
Training loss: 2.211076259613037
Validation loss: 1.9276954820079188

Epoch: 5| Step: 3
Training loss: 2.5583510398864746
Validation loss: 1.929913338794503

Epoch: 5| Step: 4
Training loss: 1.9651235342025757
Validation loss: 1.9491552896397089

Epoch: 5| Step: 5
Training loss: 2.4197468757629395
Validation loss: 1.9486086342924385

Epoch: 5| Step: 6
Training loss: 2.4614315032958984
Validation loss: 1.942608142411837

Epoch: 5| Step: 7
Training loss: 1.8656409978866577
Validation loss: 1.934922020922425

Epoch: 5| Step: 8
Training loss: 2.0850796699523926
Validation loss: 1.9553787733918877

Epoch: 5| Step: 9
Training loss: 2.2511799335479736
Validation loss: 1.9479706082292783

Epoch: 5| Step: 10
Training loss: 1.7718912363052368
Validation loss: 1.9426916645419212

Epoch: 115| Step: 0
Training loss: 1.9905033111572266
Validation loss: 1.9466847681230115

Epoch: 5| Step: 1
Training loss: 2.7376809120178223
Validation loss: 1.9462153027134557

Epoch: 5| Step: 2
Training loss: 1.8866932392120361
Validation loss: 1.9568331920972435

Epoch: 5| Step: 3
Training loss: 2.7242472171783447
Validation loss: 1.971277577902681

Epoch: 5| Step: 4
Training loss: 2.138026714324951
Validation loss: 1.9478173281556816

Epoch: 5| Step: 5
Training loss: 2.142922878265381
Validation loss: 1.954411281052456

Epoch: 5| Step: 6
Training loss: 1.9343105554580688
Validation loss: 1.9610256289923063

Epoch: 5| Step: 7
Training loss: 1.8778183460235596
Validation loss: 1.9694218968832364

Epoch: 5| Step: 8
Training loss: 2.689514636993408
Validation loss: 1.9588484969190372

Epoch: 5| Step: 9
Training loss: 1.690948724746704
Validation loss: 1.9655820118483676

Epoch: 5| Step: 10
Training loss: 1.9936007261276245
Validation loss: 1.946420838755946

Epoch: 116| Step: 0
Training loss: 2.625772476196289
Validation loss: 1.9571333610883324

Epoch: 5| Step: 1
Training loss: 2.291247606277466
Validation loss: 1.963991747107557

Epoch: 5| Step: 2
Training loss: 1.9391753673553467
Validation loss: 1.9760089689685452

Epoch: 5| Step: 3
Training loss: 2.2947661876678467
Validation loss: 1.9591983236292356

Epoch: 5| Step: 4
Training loss: 1.9088271856307983
Validation loss: 1.956377242201118

Epoch: 5| Step: 5
Training loss: 2.1150565147399902
Validation loss: 1.9465602790155718

Epoch: 5| Step: 6
Training loss: 2.358374834060669
Validation loss: 1.960157940464635

Epoch: 5| Step: 7
Training loss: 1.5171459913253784
Validation loss: 1.9568545638874013

Epoch: 5| Step: 8
Training loss: 2.3422887325286865
Validation loss: 1.9465774874533377

Epoch: 5| Step: 9
Training loss: 2.326625347137451
Validation loss: 1.9660188587762977

Epoch: 5| Step: 10
Training loss: 1.8712539672851562
Validation loss: 1.9732609359166955

Epoch: 117| Step: 0
Training loss: 1.5834532976150513
Validation loss: 1.9388840429244503

Epoch: 5| Step: 1
Training loss: 1.8162428140640259
Validation loss: 1.954422273943501

Epoch: 5| Step: 2
Training loss: 2.2431139945983887
Validation loss: 1.9694561253311813

Epoch: 5| Step: 3
Training loss: 2.1039814949035645
Validation loss: 1.9507431061037126

Epoch: 5| Step: 4
Training loss: 2.1364660263061523
Validation loss: 1.9497140710071852

Epoch: 5| Step: 5
Training loss: 2.217629909515381
Validation loss: 1.981804096570579

Epoch: 5| Step: 6
Training loss: 2.7269392013549805
Validation loss: 1.947532541008406

Epoch: 5| Step: 7
Training loss: 2.0458860397338867
Validation loss: 1.9589444911608132

Epoch: 5| Step: 8
Training loss: 2.3760154247283936
Validation loss: 1.952211009558811

Epoch: 5| Step: 9
Training loss: 2.077613115310669
Validation loss: 1.9602856225864862

Epoch: 5| Step: 10
Training loss: 2.421154260635376
Validation loss: 1.9487967542422715

Epoch: 118| Step: 0
Training loss: 1.9585907459259033
Validation loss: 1.9503743571619834

Epoch: 5| Step: 1
Training loss: 1.9719613790512085
Validation loss: 1.9522117748055408

Epoch: 5| Step: 2
Training loss: 1.9676601886749268
Validation loss: 1.9512614242492183

Epoch: 5| Step: 3
Training loss: 2.6074061393737793
Validation loss: 1.9498937950339368

Epoch: 5| Step: 4
Training loss: 1.6923894882202148
Validation loss: 1.9417821925173524

Epoch: 5| Step: 5
Training loss: 2.607750415802002
Validation loss: 1.9283855666396439

Epoch: 5| Step: 6
Training loss: 2.3576436042785645
Validation loss: 1.9413900093365741

Epoch: 5| Step: 7
Training loss: 2.3686654567718506
Validation loss: 1.9500285233220747

Epoch: 5| Step: 8
Training loss: 2.4456839561462402
Validation loss: 1.9407954574913107

Epoch: 5| Step: 9
Training loss: 1.4008538722991943
Validation loss: 1.9427738676788986

Epoch: 5| Step: 10
Training loss: 2.2724618911743164
Validation loss: 1.9446106008304063

Epoch: 119| Step: 0
Training loss: 1.9177215099334717
Validation loss: 1.9583311875661213

Epoch: 5| Step: 1
Training loss: 2.0429153442382812
Validation loss: 1.942181848710583

Epoch: 5| Step: 2
Training loss: 2.371116876602173
Validation loss: 1.9519978133581017

Epoch: 5| Step: 3
Training loss: 2.330167293548584
Validation loss: 1.962792778527865

Epoch: 5| Step: 4
Training loss: 2.2988505363464355
Validation loss: 1.9760677224846297

Epoch: 5| Step: 5
Training loss: 2.321268081665039
Validation loss: 1.9470219086575251

Epoch: 5| Step: 6
Training loss: 1.8857128620147705
Validation loss: 1.9587689343319143

Epoch: 5| Step: 7
Training loss: 2.2900195121765137
Validation loss: 1.9608464946029007

Epoch: 5| Step: 8
Training loss: 1.977301001548767
Validation loss: 1.9450462133653703

Epoch: 5| Step: 9
Training loss: 1.8146226406097412
Validation loss: 1.9745814646444013

Epoch: 5| Step: 10
Training loss: 2.4737648963928223
Validation loss: 1.9357934510836037

Epoch: 120| Step: 0
Training loss: 1.5680100917816162
Validation loss: 1.9592804485751736

Epoch: 5| Step: 1
Training loss: 1.6080518960952759
Validation loss: 1.9448265952448691

Epoch: 5| Step: 2
Training loss: 2.1808125972747803
Validation loss: 1.9638462861378987

Epoch: 5| Step: 3
Training loss: 2.5886874198913574
Validation loss: 1.9753876091331564

Epoch: 5| Step: 4
Training loss: 2.7717459201812744
Validation loss: 1.9542854370609406

Epoch: 5| Step: 5
Training loss: 2.435626745223999
Validation loss: 1.9630216296001146

Epoch: 5| Step: 6
Training loss: 2.4168026447296143
Validation loss: 1.9664686879804056

Epoch: 5| Step: 7
Training loss: 2.353198766708374
Validation loss: 1.9711219341524187

Epoch: 5| Step: 8
Training loss: 2.22381591796875
Validation loss: 1.9613089497371385

Epoch: 5| Step: 9
Training loss: 1.9232925176620483
Validation loss: 1.9706942522397606

Epoch: 5| Step: 10
Training loss: 1.4529035091400146
Validation loss: 1.9470086430990567

Epoch: 121| Step: 0
Training loss: 1.7767095565795898
Validation loss: 1.9505734776937833

Epoch: 5| Step: 1
Training loss: 2.267791748046875
Validation loss: 1.9662121124165033

Epoch: 5| Step: 2
Training loss: 2.393012285232544
Validation loss: 1.9736970445161224

Epoch: 5| Step: 3
Training loss: 1.8856483697891235
Validation loss: 1.975197394688924

Epoch: 5| Step: 4
Training loss: 2.1678035259246826
Validation loss: 1.966977785992366

Epoch: 5| Step: 5
Training loss: 2.424746036529541
Validation loss: 1.954474138957198

Epoch: 5| Step: 6
Training loss: 2.5339035987854004
Validation loss: 1.9615057937560543

Epoch: 5| Step: 7
Training loss: 2.1371724605560303
Validation loss: 1.9765581366836384

Epoch: 5| Step: 8
Training loss: 1.5972793102264404
Validation loss: 1.9713868146301599

Epoch: 5| Step: 9
Training loss: 2.2325778007507324
Validation loss: 1.942512253279327

Epoch: 5| Step: 10
Training loss: 2.092506170272827
Validation loss: 1.9563145163238689

Epoch: 122| Step: 0
Training loss: 2.0954041481018066
Validation loss: 1.952797725636472

Epoch: 5| Step: 1
Training loss: 2.05549955368042
Validation loss: 1.9593523625404603

Epoch: 5| Step: 2
Training loss: 2.091308355331421
Validation loss: 1.9708298983112458

Epoch: 5| Step: 3
Training loss: 1.9314197301864624
Validation loss: 1.9869425732602355

Epoch: 5| Step: 4
Training loss: 2.5048296451568604
Validation loss: 1.9681457934841033

Epoch: 5| Step: 5
Training loss: 2.3477649688720703
Validation loss: 1.973149041975698

Epoch: 5| Step: 6
Training loss: 1.8105261325836182
Validation loss: 1.9525023224533244

Epoch: 5| Step: 7
Training loss: 2.411738395690918
Validation loss: 1.9479508746054865

Epoch: 5| Step: 8
Training loss: 2.1953415870666504
Validation loss: 1.9674751040756062

Epoch: 5| Step: 9
Training loss: 1.7867136001586914
Validation loss: 1.9501783629899383

Epoch: 5| Step: 10
Training loss: 2.149965286254883
Validation loss: 1.9637349369705364

Epoch: 123| Step: 0
Training loss: 1.746071219444275
Validation loss: 1.9736621379852295

Epoch: 5| Step: 1
Training loss: 1.9123649597167969
Validation loss: 1.9571122610440819

Epoch: 5| Step: 2
Training loss: 1.5934264659881592
Validation loss: 1.9796043083231936

Epoch: 5| Step: 3
Training loss: 2.0203685760498047
Validation loss: 1.953753835411482

Epoch: 5| Step: 4
Training loss: 2.511848211288452
Validation loss: 1.9670809904734294

Epoch: 5| Step: 5
Training loss: 2.058145046234131
Validation loss: 1.9655282625588038

Epoch: 5| Step: 6
Training loss: 2.6757867336273193
Validation loss: 1.965279879108552

Epoch: 5| Step: 7
Training loss: 1.9920819997787476
Validation loss: 1.959902908212395

Epoch: 5| Step: 8
Training loss: 2.812767505645752
Validation loss: 1.9785196601703603

Epoch: 5| Step: 9
Training loss: 2.281686305999756
Validation loss: 1.9443450025332871

Epoch: 5| Step: 10
Training loss: 1.701462984085083
Validation loss: 1.9502133041299798

Epoch: 124| Step: 0
Training loss: 2.1818346977233887
Validation loss: 1.948132074007424

Epoch: 5| Step: 1
Training loss: 2.076812982559204
Validation loss: 1.9503452829135361

Epoch: 5| Step: 2
Training loss: 2.3723654747009277
Validation loss: 1.9505045606243996

Epoch: 5| Step: 3
Training loss: 2.1848058700561523
Validation loss: 1.9419553536240772

Epoch: 5| Step: 4
Training loss: 2.2619736194610596
Validation loss: 1.9436897770051034

Epoch: 5| Step: 5
Training loss: 1.6860263347625732
Validation loss: 1.9550182486093173

Epoch: 5| Step: 6
Training loss: 2.425198793411255
Validation loss: 1.97117030748757

Epoch: 5| Step: 7
Training loss: 1.7803547382354736
Validation loss: 1.9676912907631166

Epoch: 5| Step: 8
Training loss: 2.0902323722839355
Validation loss: 1.984159759295884

Epoch: 5| Step: 9
Training loss: 1.911353349685669
Validation loss: 1.9658497636036207

Epoch: 5| Step: 10
Training loss: 2.489708423614502
Validation loss: 1.9848717335731751

Epoch: 125| Step: 0
Training loss: 1.9202266931533813
Validation loss: 1.9671429690494333

Epoch: 5| Step: 1
Training loss: 2.2228736877441406
Validation loss: 1.977888971246699

Epoch: 5| Step: 2
Training loss: 1.8774747848510742
Validation loss: 1.9569535422068771

Epoch: 5| Step: 3
Training loss: 1.9832788705825806
Validation loss: 1.9759515113728021

Epoch: 5| Step: 4
Training loss: 2.6162946224212646
Validation loss: 1.9708597685701104

Epoch: 5| Step: 5
Training loss: 1.5949357748031616
Validation loss: 1.9614166059801657

Epoch: 5| Step: 6
Training loss: 2.492668867111206
Validation loss: 1.9641113652977893

Epoch: 5| Step: 7
Training loss: 1.797677755355835
Validation loss: 1.9627911826615692

Epoch: 5| Step: 8
Training loss: 2.177802085876465
Validation loss: 1.9682449499766033

Epoch: 5| Step: 9
Training loss: 2.3242347240448
Validation loss: 1.9442570183866767

Epoch: 5| Step: 10
Training loss: 2.398292064666748
Validation loss: 1.969385818768573

Epoch: 126| Step: 0
Training loss: 1.6499325037002563
Validation loss: 1.9950664325426983

Epoch: 5| Step: 1
Training loss: 2.880514621734619
Validation loss: 1.9850768901968514

Epoch: 5| Step: 2
Training loss: 2.2277674674987793
Validation loss: 1.9776004975841892

Epoch: 5| Step: 3
Training loss: 2.452521324157715
Validation loss: 1.9807564520066785

Epoch: 5| Step: 4
Training loss: 1.9221760034561157
Validation loss: 1.9740987772582679

Epoch: 5| Step: 5
Training loss: 1.584890604019165
Validation loss: 1.956479726299163

Epoch: 5| Step: 6
Training loss: 1.815474271774292
Validation loss: 1.9594906465981596

Epoch: 5| Step: 7
Training loss: 2.050194263458252
Validation loss: 1.9676884169219642

Epoch: 5| Step: 8
Training loss: 2.0977706909179688
Validation loss: 1.9852704143011441

Epoch: 5| Step: 9
Training loss: 2.6093780994415283
Validation loss: 1.972276541494554

Epoch: 5| Step: 10
Training loss: 2.063882827758789
Validation loss: 1.9697835342858427

Epoch: 127| Step: 0
Training loss: 2.198739528656006
Validation loss: 1.970250847519085

Epoch: 5| Step: 1
Training loss: 2.0146892070770264
Validation loss: 1.9658890872873285

Epoch: 5| Step: 2
Training loss: 1.669820785522461
Validation loss: 1.9759606533153082

Epoch: 5| Step: 3
Training loss: 2.034580945968628
Validation loss: 1.9562203691851707

Epoch: 5| Step: 4
Training loss: 2.08052659034729
Validation loss: 1.9695247501455329

Epoch: 5| Step: 5
Training loss: 1.8842004537582397
Validation loss: 1.9637577905449817

Epoch: 5| Step: 6
Training loss: 2.664632797241211
Validation loss: 1.942991695096416

Epoch: 5| Step: 7
Training loss: 2.303088665008545
Validation loss: 1.926926548762988

Epoch: 5| Step: 8
Training loss: 2.409914255142212
Validation loss: 1.9681665564096102

Epoch: 5| Step: 9
Training loss: 2.2033379077911377
Validation loss: 1.9261136580539007

Epoch: 5| Step: 10
Training loss: 1.8870320320129395
Validation loss: 1.9489801006932412

Epoch: 128| Step: 0
Training loss: 2.3845086097717285
Validation loss: 1.9708487628608622

Epoch: 5| Step: 1
Training loss: 1.8866888284683228
Validation loss: 1.9568001608694754

Epoch: 5| Step: 2
Training loss: 1.5964468717575073
Validation loss: 1.9493621254480014

Epoch: 5| Step: 3
Training loss: 1.7864201068878174
Validation loss: 1.9504469338283743

Epoch: 5| Step: 4
Training loss: 1.9087556600570679
Validation loss: 1.960162906236546

Epoch: 5| Step: 5
Training loss: 2.558856964111328
Validation loss: 1.987171955006097

Epoch: 5| Step: 6
Training loss: 2.041658401489258
Validation loss: 1.9843065789950791

Epoch: 5| Step: 7
Training loss: 2.2028541564941406
Validation loss: 1.9578022110846736

Epoch: 5| Step: 8
Training loss: 1.9504797458648682
Validation loss: 1.9809108062457013

Epoch: 5| Step: 9
Training loss: 2.5529065132141113
Validation loss: 1.9643063878500333

Epoch: 5| Step: 10
Training loss: 2.5517165660858154
Validation loss: 1.9527033144427883

Epoch: 129| Step: 0
Training loss: 2.067403554916382
Validation loss: 1.9658790108978108

Epoch: 5| Step: 1
Training loss: 2.059992551803589
Validation loss: 1.9569297426490373

Epoch: 5| Step: 2
Training loss: 2.379615068435669
Validation loss: 1.9432457211197063

Epoch: 5| Step: 3
Training loss: 2.006147861480713
Validation loss: 1.974589506785075

Epoch: 5| Step: 4
Training loss: 1.861789345741272
Validation loss: 1.976365820054085

Epoch: 5| Step: 5
Training loss: 2.611485004425049
Validation loss: 1.9808299156927294

Epoch: 5| Step: 6
Training loss: 2.2210304737091064
Validation loss: 1.9638557895537345

Epoch: 5| Step: 7
Training loss: 2.298354387283325
Validation loss: 1.9754559737379833

Epoch: 5| Step: 8
Training loss: 2.268268585205078
Validation loss: 1.973884706856102

Epoch: 5| Step: 9
Training loss: 1.708632469177246
Validation loss: 1.9753289594445178

Epoch: 5| Step: 10
Training loss: 1.8504273891448975
Validation loss: 1.9829322535504577

Epoch: 130| Step: 0
Training loss: 2.405796527862549
Validation loss: 1.9875525530948435

Epoch: 5| Step: 1
Training loss: 2.30670428276062
Validation loss: 1.9729578623207666

Epoch: 5| Step: 2
Training loss: 2.1970629692077637
Validation loss: 1.9713594477663758

Epoch: 5| Step: 3
Training loss: 2.525036096572876
Validation loss: 1.9825650568931334

Epoch: 5| Step: 4
Training loss: 1.8454220294952393
Validation loss: 1.9720989170894827

Epoch: 5| Step: 5
Training loss: 1.8741881847381592
Validation loss: 1.9573544353567145

Epoch: 5| Step: 6
Training loss: 2.3677449226379395
Validation loss: 1.952734064030391

Epoch: 5| Step: 7
Training loss: 1.6366136074066162
Validation loss: 1.9538260634227465

Epoch: 5| Step: 8
Training loss: 2.119978904724121
Validation loss: 1.9441047894057406

Epoch: 5| Step: 9
Training loss: 2.0204429626464844
Validation loss: 1.962674243475801

Epoch: 5| Step: 10
Training loss: 2.051804304122925
Validation loss: 1.9898700021928357

Epoch: 131| Step: 0
Training loss: 2.5682735443115234
Validation loss: 1.9426462163207352

Epoch: 5| Step: 1
Training loss: 2.0041351318359375
Validation loss: 1.9853563116442772

Epoch: 5| Step: 2
Training loss: 2.328120708465576
Validation loss: 1.9477451514172297

Epoch: 5| Step: 3
Training loss: 1.7074239253997803
Validation loss: 1.9638807645408056

Epoch: 5| Step: 4
Training loss: 1.9614547491073608
Validation loss: 1.9576353757612166

Epoch: 5| Step: 5
Training loss: 1.8332741260528564
Validation loss: 1.976055819501159

Epoch: 5| Step: 6
Training loss: 2.2697322368621826
Validation loss: 1.9653467183472009

Epoch: 5| Step: 7
Training loss: 2.1232926845550537
Validation loss: 1.9861188165603145

Epoch: 5| Step: 8
Training loss: 2.084820032119751
Validation loss: 1.9696090657223937

Epoch: 5| Step: 9
Training loss: 2.1844818592071533
Validation loss: 1.9859860353572394

Epoch: 5| Step: 10
Training loss: 2.183053970336914
Validation loss: 2.0056688170279227

Epoch: 132| Step: 0
Training loss: 1.955444574356079
Validation loss: 1.96871679957195

Epoch: 5| Step: 1
Training loss: 2.102201461791992
Validation loss: 1.98305138849443

Epoch: 5| Step: 2
Training loss: 2.216264247894287
Validation loss: 1.9724450444662442

Epoch: 5| Step: 3
Training loss: 1.6840873956680298
Validation loss: 1.9719194609631774

Epoch: 5| Step: 4
Training loss: 1.9188086986541748
Validation loss: 1.974851082730037

Epoch: 5| Step: 5
Training loss: 2.2480597496032715
Validation loss: 1.9852905004255232

Epoch: 5| Step: 6
Training loss: 1.920244812965393
Validation loss: 1.9735365695850824

Epoch: 5| Step: 7
Training loss: 2.221749782562256
Validation loss: 1.9574172496795654

Epoch: 5| Step: 8
Training loss: 2.7304508686065674
Validation loss: 1.9627362912701023

Epoch: 5| Step: 9
Training loss: 2.084407091140747
Validation loss: 1.989940312600905

Epoch: 5| Step: 10
Training loss: 2.181424140930176
Validation loss: 1.990350733521164

Epoch: 133| Step: 0
Training loss: 2.5098977088928223
Validation loss: 1.9784634831131145

Epoch: 5| Step: 1
Training loss: 2.436361312866211
Validation loss: 1.9848335968550814

Epoch: 5| Step: 2
Training loss: 2.2396457195281982
Validation loss: 1.9640897294526458

Epoch: 5| Step: 3
Training loss: 2.2788960933685303
Validation loss: 1.9596629655489357

Epoch: 5| Step: 4
Training loss: 1.5352178812026978
Validation loss: 1.9726353614561019

Epoch: 5| Step: 5
Training loss: 2.2672343254089355
Validation loss: 1.9743165610938944

Epoch: 5| Step: 6
Training loss: 1.9496440887451172
Validation loss: 1.9704666278695548

Epoch: 5| Step: 7
Training loss: 1.9688552618026733
Validation loss: 1.9820722879902009

Epoch: 5| Step: 8
Training loss: 2.1460559368133545
Validation loss: 1.9805899102200744

Epoch: 5| Step: 9
Training loss: 2.1697089672088623
Validation loss: 1.9844821601785638

Epoch: 5| Step: 10
Training loss: 1.6937341690063477
Validation loss: 1.9723279732529835

Epoch: 134| Step: 0
Training loss: 2.3579869270324707
Validation loss: 1.9948936867457565

Epoch: 5| Step: 1
Training loss: 2.039762020111084
Validation loss: 1.983394702275594

Epoch: 5| Step: 2
Training loss: 1.9308475255966187
Validation loss: 1.9480443436612365

Epoch: 5| Step: 3
Training loss: 1.6934871673583984
Validation loss: 1.9804514454257103

Epoch: 5| Step: 4
Training loss: 2.2302327156066895
Validation loss: 1.9630573744414954

Epoch: 5| Step: 5
Training loss: 2.3916401863098145
Validation loss: 1.981695080316195

Epoch: 5| Step: 6
Training loss: 1.6637645959854126
Validation loss: 1.9761155331006615

Epoch: 5| Step: 7
Training loss: 2.3316800594329834
Validation loss: 1.9756625672822357

Epoch: 5| Step: 8
Training loss: 2.2405190467834473
Validation loss: 1.9767308542805333

Epoch: 5| Step: 9
Training loss: 2.2113800048828125
Validation loss: 1.9785992176302019

Epoch: 5| Step: 10
Training loss: 1.9857895374298096
Validation loss: 1.982252420917634

Epoch: 135| Step: 0
Training loss: 2.203282594680786
Validation loss: 1.9648204080520137

Epoch: 5| Step: 1
Training loss: 2.081577777862549
Validation loss: 1.9777362487649406

Epoch: 5| Step: 2
Training loss: 1.5333200693130493
Validation loss: 1.9714519951933174

Epoch: 5| Step: 3
Training loss: 2.2798259258270264
Validation loss: 1.9823975691231348

Epoch: 5| Step: 4
Training loss: 1.8055660724639893
Validation loss: 1.978665296749402

Epoch: 5| Step: 5
Training loss: 1.5118728876113892
Validation loss: 1.9753409508735902

Epoch: 5| Step: 6
Training loss: 2.949169158935547
Validation loss: 1.9757222975454023

Epoch: 5| Step: 7
Training loss: 2.0529277324676514
Validation loss: 1.9688190119240874

Epoch: 5| Step: 8
Training loss: 2.0677874088287354
Validation loss: 1.9894345755218177

Epoch: 5| Step: 9
Training loss: 2.5563061237335205
Validation loss: 1.9789559430973505

Epoch: 5| Step: 10
Training loss: 2.2261898517608643
Validation loss: 1.9998681775985225

Epoch: 136| Step: 0
Training loss: 2.4725208282470703
Validation loss: 1.983714634372342

Epoch: 5| Step: 1
Training loss: 1.784174919128418
Validation loss: 1.9549115139950988

Epoch: 5| Step: 2
Training loss: 2.309471845626831
Validation loss: 1.9631585485191756

Epoch: 5| Step: 3
Training loss: 2.012119770050049
Validation loss: 1.9802217342520272

Epoch: 5| Step: 4
Training loss: 1.8038803339004517
Validation loss: 1.9724560424845705

Epoch: 5| Step: 5
Training loss: 2.656996488571167
Validation loss: 1.9897890424215665

Epoch: 5| Step: 6
Training loss: 2.1289281845092773
Validation loss: 1.9912674683396534

Epoch: 5| Step: 7
Training loss: 2.052626132965088
Validation loss: 1.9726633897391699

Epoch: 5| Step: 8
Training loss: 1.9027535915374756
Validation loss: 1.991668705017336

Epoch: 5| Step: 9
Training loss: 1.8146530389785767
Validation loss: 1.9800309852887226

Epoch: 5| Step: 10
Training loss: 2.057563543319702
Validation loss: 1.965022312697544

Epoch: 137| Step: 0
Training loss: 1.7479581832885742
Validation loss: 1.9747539412590764

Epoch: 5| Step: 1
Training loss: 1.740581750869751
Validation loss: 1.975935947510504

Epoch: 5| Step: 2
Training loss: 2.048581600189209
Validation loss: 1.9615860151988205

Epoch: 5| Step: 3
Training loss: 1.8450186252593994
Validation loss: 1.9770162964379916

Epoch: 5| Step: 4
Training loss: 2.3604979515075684
Validation loss: 1.9735634455116846

Epoch: 5| Step: 5
Training loss: 2.886854887008667
Validation loss: 1.968527788756996

Epoch: 5| Step: 6
Training loss: 2.106504440307617
Validation loss: 1.9874721752699984

Epoch: 5| Step: 7
Training loss: 2.215454578399658
Validation loss: 1.9808919647688508

Epoch: 5| Step: 8
Training loss: 1.8937591314315796
Validation loss: 1.979915698369344

Epoch: 5| Step: 9
Training loss: 2.133965253829956
Validation loss: 1.952025080239901

Epoch: 5| Step: 10
Training loss: 2.0518581867218018
Validation loss: 1.9500308152168029

Epoch: 138| Step: 0
Training loss: 1.4972721338272095
Validation loss: 1.9844929108055689

Epoch: 5| Step: 1
Training loss: 2.2414872646331787
Validation loss: 1.985870357482664

Epoch: 5| Step: 2
Training loss: 1.801436185836792
Validation loss: 1.9591735844971032

Epoch: 5| Step: 3
Training loss: 1.9269771575927734
Validation loss: 1.9592727435532438

Epoch: 5| Step: 4
Training loss: 2.2085511684417725
Validation loss: 1.965619159001176

Epoch: 5| Step: 5
Training loss: 2.0138447284698486
Validation loss: 1.9647143399843605

Epoch: 5| Step: 6
Training loss: 1.8320443630218506
Validation loss: 1.972102206240418

Epoch: 5| Step: 7
Training loss: 2.6344945430755615
Validation loss: 1.9692110297500447

Epoch: 5| Step: 8
Training loss: 2.845853328704834
Validation loss: 1.9692507328525666

Epoch: 5| Step: 9
Training loss: 2.062683582305908
Validation loss: 1.9758027368976223

Epoch: 5| Step: 10
Training loss: 1.9960851669311523
Validation loss: 1.992814520353912

Epoch: 139| Step: 0
Training loss: 2.109541177749634
Validation loss: 1.9720995733814854

Epoch: 5| Step: 1
Training loss: 2.522656202316284
Validation loss: 1.9606334970843406

Epoch: 5| Step: 2
Training loss: 1.4644145965576172
Validation loss: 1.97887590623671

Epoch: 5| Step: 3
Training loss: 2.2427847385406494
Validation loss: 1.973189737207146

Epoch: 5| Step: 4
Training loss: 2.2575206756591797
Validation loss: 1.9757631055770382

Epoch: 5| Step: 5
Training loss: 2.3566343784332275
Validation loss: 1.978801591421968

Epoch: 5| Step: 6
Training loss: 1.914323091506958
Validation loss: 1.9675907011955016

Epoch: 5| Step: 7
Training loss: 1.8466765880584717
Validation loss: 1.9778954572575067

Epoch: 5| Step: 8
Training loss: 1.8218189477920532
Validation loss: 1.9711463246294247

Epoch: 5| Step: 9
Training loss: 2.3689351081848145
Validation loss: 1.9742943292023034

Epoch: 5| Step: 10
Training loss: 2.0661661624908447
Validation loss: 1.9778692427501883

Epoch: 140| Step: 0
Training loss: 2.471543788909912
Validation loss: 1.970801681600591

Epoch: 5| Step: 1
Training loss: 1.9331022500991821
Validation loss: 1.963289007063835

Epoch: 5| Step: 2
Training loss: 1.6750673055648804
Validation loss: 1.9819105530297885

Epoch: 5| Step: 3
Training loss: 1.926051378250122
Validation loss: 1.9586553958154493

Epoch: 5| Step: 4
Training loss: 2.441253185272217
Validation loss: 1.9561199629178612

Epoch: 5| Step: 5
Training loss: 2.5006909370422363
Validation loss: 1.9887243906656902

Epoch: 5| Step: 6
Training loss: 1.7803798913955688
Validation loss: 1.9671153458215858

Epoch: 5| Step: 7
Training loss: 1.3691415786743164
Validation loss: 1.9673756232825659

Epoch: 5| Step: 8
Training loss: 1.6227519512176514
Validation loss: 1.9829459677460373

Epoch: 5| Step: 9
Training loss: 2.7641148567199707
Validation loss: 1.951316443822717

Epoch: 5| Step: 10
Training loss: 2.488976001739502
Validation loss: 1.9496834265288485

Epoch: 141| Step: 0
Training loss: 1.9841922521591187
Validation loss: 1.9730115616193382

Epoch: 5| Step: 1
Training loss: 2.1370913982391357
Validation loss: 1.9736623949902032

Epoch: 5| Step: 2
Training loss: 2.1349074840545654
Validation loss: 1.974405611715009

Epoch: 5| Step: 3
Training loss: 1.8256237506866455
Validation loss: 1.9875800160951511

Epoch: 5| Step: 4
Training loss: 1.6281421184539795
Validation loss: 1.9657648071166007

Epoch: 5| Step: 5
Training loss: 2.159719944000244
Validation loss: 1.988180387404657

Epoch: 5| Step: 6
Training loss: 2.2040836811065674
Validation loss: 1.9977787489532142

Epoch: 5| Step: 7
Training loss: 1.917506456375122
Validation loss: 2.0060154955874205

Epoch: 5| Step: 8
Training loss: 1.6492960453033447
Validation loss: 1.9801567536528393

Epoch: 5| Step: 9
Training loss: 3.2327780723571777
Validation loss: 1.966038260408627

Epoch: 5| Step: 10
Training loss: 2.1883962154388428
Validation loss: 1.9942666715191257

Epoch: 142| Step: 0
Training loss: 1.8603328466415405
Validation loss: 1.9917484201410764

Epoch: 5| Step: 1
Training loss: 2.11368989944458
Validation loss: 1.9892850729726976

Epoch: 5| Step: 2
Training loss: 1.9263942241668701
Validation loss: 1.9897518619414298

Epoch: 5| Step: 3
Training loss: 2.295567274093628
Validation loss: 2.0184644845224198

Epoch: 5| Step: 4
Training loss: 1.946642518043518
Validation loss: 1.980048821818444

Epoch: 5| Step: 5
Training loss: 2.5088748931884766
Validation loss: 1.9727900643502512

Epoch: 5| Step: 6
Training loss: 1.9646797180175781
Validation loss: 1.9894674836948354

Epoch: 5| Step: 7
Training loss: 1.9276325702667236
Validation loss: 1.9683658076870827

Epoch: 5| Step: 8
Training loss: 2.1472058296203613
Validation loss: 1.977161443361672

Epoch: 5| Step: 9
Training loss: 1.9008861780166626
Validation loss: 1.9747590121402536

Epoch: 5| Step: 10
Training loss: 2.3560500144958496
Validation loss: 1.9835706680051741

Epoch: 143| Step: 0
Training loss: 1.9848724603652954
Validation loss: 1.9783292816531273

Epoch: 5| Step: 1
Training loss: 1.8014854192733765
Validation loss: 1.9926815930233206

Epoch: 5| Step: 2
Training loss: 2.110250949859619
Validation loss: 1.9908023547100764

Epoch: 5| Step: 3
Training loss: 1.346210241317749
Validation loss: 2.0073627835960797

Epoch: 5| Step: 4
Training loss: 2.101004123687744
Validation loss: 1.9684224320996193

Epoch: 5| Step: 5
Training loss: 2.413440227508545
Validation loss: 2.014819445148591

Epoch: 5| Step: 6
Training loss: 2.726459503173828
Validation loss: 1.9918703866261307

Epoch: 5| Step: 7
Training loss: 2.0691423416137695
Validation loss: 2.003721134636992

Epoch: 5| Step: 8
Training loss: 2.2928688526153564
Validation loss: 1.9774499554787912

Epoch: 5| Step: 9
Training loss: 2.2952828407287598
Validation loss: 1.981135775966029

Epoch: 5| Step: 10
Training loss: 1.790418028831482
Validation loss: 1.9966718740360712

Epoch: 144| Step: 0
Training loss: 2.0799458026885986
Validation loss: 1.9613870010581067

Epoch: 5| Step: 1
Training loss: 2.230717420578003
Validation loss: 1.9873206923084874

Epoch: 5| Step: 2
Training loss: 1.9428069591522217
Validation loss: 1.99141905384679

Epoch: 5| Step: 3
Training loss: 1.7892881631851196
Validation loss: 1.9747534721128401

Epoch: 5| Step: 4
Training loss: 1.957924246788025
Validation loss: 1.9731952823618406

Epoch: 5| Step: 5
Training loss: 2.570887327194214
Validation loss: 1.9710537695115613

Epoch: 5| Step: 6
Training loss: 2.046133279800415
Validation loss: 1.9538248687662103

Epoch: 5| Step: 7
Training loss: 1.86772882938385
Validation loss: 1.9749083313890683

Epoch: 5| Step: 8
Training loss: 2.8997561931610107
Validation loss: 1.9606665949667654

Epoch: 5| Step: 9
Training loss: 1.754250168800354
Validation loss: 1.9734386833765174

Epoch: 5| Step: 10
Training loss: 1.5002368688583374
Validation loss: 1.9609014090671335

Epoch: 145| Step: 0
Training loss: 2.3809351921081543
Validation loss: 1.9711291533644482

Epoch: 5| Step: 1
Training loss: 2.6090824604034424
Validation loss: 1.972380861159294

Epoch: 5| Step: 2
Training loss: 2.2252936363220215
Validation loss: 1.9779638577533025

Epoch: 5| Step: 3
Training loss: 2.042083263397217
Validation loss: 1.9819485295203425

Epoch: 5| Step: 4
Training loss: 1.871002435684204
Validation loss: 1.9794068451850646

Epoch: 5| Step: 5
Training loss: 1.7010595798492432
Validation loss: 1.9637209433381275

Epoch: 5| Step: 6
Training loss: 2.616555690765381
Validation loss: 1.9879970883810392

Epoch: 5| Step: 7
Training loss: 2.427849292755127
Validation loss: 1.9743704129290838

Epoch: 5| Step: 8
Training loss: 1.6720631122589111
Validation loss: 1.9419279906057543

Epoch: 5| Step: 9
Training loss: 1.3887455463409424
Validation loss: 1.9743071512509418

Epoch: 5| Step: 10
Training loss: 1.8822342157363892
Validation loss: 1.984587033589681

Epoch: 146| Step: 0
Training loss: 1.9819145202636719
Validation loss: 1.979019429094048

Epoch: 5| Step: 1
Training loss: 2.399927854537964
Validation loss: 1.9628109496126893

Epoch: 5| Step: 2
Training loss: 2.644007921218872
Validation loss: 1.9677568943269792

Epoch: 5| Step: 3
Training loss: 1.4564249515533447
Validation loss: 1.9771255857201033

Epoch: 5| Step: 4
Training loss: 2.0775856971740723
Validation loss: 1.9829098716858895

Epoch: 5| Step: 5
Training loss: 1.6125719547271729
Validation loss: 1.9736755406984718

Epoch: 5| Step: 6
Training loss: 1.8976386785507202
Validation loss: 1.9556253699846164

Epoch: 5| Step: 7
Training loss: 2.265185832977295
Validation loss: 1.971381987294843

Epoch: 5| Step: 8
Training loss: 2.371199607849121
Validation loss: 1.9828355568711475

Epoch: 5| Step: 9
Training loss: 2.405942916870117
Validation loss: 1.9894768550831785

Epoch: 5| Step: 10
Training loss: 1.8051347732543945
Validation loss: 1.982644401570802

Epoch: 147| Step: 0
Training loss: 1.7895853519439697
Validation loss: 1.980748943103257

Epoch: 5| Step: 1
Training loss: 1.4790410995483398
Validation loss: 1.9822503648778445

Epoch: 5| Step: 2
Training loss: 1.9034487009048462
Validation loss: 1.9833674456483574

Epoch: 5| Step: 3
Training loss: 2.7004647254943848
Validation loss: 1.9683952716089064

Epoch: 5| Step: 4
Training loss: 2.3155689239501953
Validation loss: 1.9849423823818084

Epoch: 5| Step: 5
Training loss: 1.5803238153457642
Validation loss: 1.9943560015770696

Epoch: 5| Step: 6
Training loss: 2.633695125579834
Validation loss: 1.9931093518451979

Epoch: 5| Step: 7
Training loss: 2.008605480194092
Validation loss: 2.0124072592745543

Epoch: 5| Step: 8
Training loss: 2.346578598022461
Validation loss: 1.9968701536937425

Epoch: 5| Step: 9
Training loss: 1.8212001323699951
Validation loss: 2.0127164766352665

Epoch: 5| Step: 10
Training loss: 2.223071813583374
Validation loss: 1.9818615554481425

Epoch: 148| Step: 0
Training loss: 1.5391862392425537
Validation loss: 1.978807230149546

Epoch: 5| Step: 1
Training loss: 1.7468916177749634
Validation loss: 2.0102263804404967

Epoch: 5| Step: 2
Training loss: 2.208280086517334
Validation loss: 2.0062110629133

Epoch: 5| Step: 3
Training loss: 2.743286371231079
Validation loss: 1.9684469546041181

Epoch: 5| Step: 4
Training loss: 2.108891725540161
Validation loss: 1.980930168141601

Epoch: 5| Step: 5
Training loss: 2.1055455207824707
Validation loss: 1.9753860453123688

Epoch: 5| Step: 6
Training loss: 1.846954345703125
Validation loss: 1.961230521560997

Epoch: 5| Step: 7
Training loss: 2.169121503829956
Validation loss: 1.9976356619147844

Epoch: 5| Step: 8
Training loss: 2.4306623935699463
Validation loss: 1.9752844149066555

Epoch: 5| Step: 9
Training loss: 2.000941514968872
Validation loss: 1.9685923925010107

Epoch: 5| Step: 10
Training loss: 1.9049931764602661
Validation loss: 1.9707442355412308

Epoch: 149| Step: 0
Training loss: 2.1656036376953125
Validation loss: 1.9837719650678738

Epoch: 5| Step: 1
Training loss: 2.3338284492492676
Validation loss: 1.9673006252575946

Epoch: 5| Step: 2
Training loss: 1.6870145797729492
Validation loss: 1.9464641976100143

Epoch: 5| Step: 3
Training loss: 1.912197470664978
Validation loss: 2.000117278868152

Epoch: 5| Step: 4
Training loss: 2.0427322387695312
Validation loss: 1.976914300713488

Epoch: 5| Step: 5
Training loss: 1.8023830652236938
Validation loss: 1.9829108266420261

Epoch: 5| Step: 6
Training loss: 1.6209923028945923
Validation loss: 1.9980709552764893

Epoch: 5| Step: 7
Training loss: 2.2298412322998047
Validation loss: 1.978732648716178

Epoch: 5| Step: 8
Training loss: 2.278872489929199
Validation loss: 1.9643176345415012

Epoch: 5| Step: 9
Training loss: 2.453101396560669
Validation loss: 1.9910297547617266

Epoch: 5| Step: 10
Training loss: 2.1964008808135986
Validation loss: 1.9957460024023568

Epoch: 150| Step: 0
Training loss: 2.039752960205078
Validation loss: 1.9947359433738134

Epoch: 5| Step: 1
Training loss: 2.428874969482422
Validation loss: 1.9619172606416928

Epoch: 5| Step: 2
Training loss: 2.0255017280578613
Validation loss: 1.9913137164167178

Epoch: 5| Step: 3
Training loss: 2.0873310565948486
Validation loss: 1.9961176508216447

Epoch: 5| Step: 4
Training loss: 1.7663787603378296
Validation loss: 1.998768465493315

Epoch: 5| Step: 5
Training loss: 1.6689941883087158
Validation loss: 1.983925409214471

Epoch: 5| Step: 6
Training loss: 2.1940815448760986
Validation loss: 1.9803802941435127

Epoch: 5| Step: 7
Training loss: 2.0598292350769043
Validation loss: 1.9921200813785676

Epoch: 5| Step: 8
Training loss: 2.2113852500915527
Validation loss: 2.0040875788657897

Epoch: 5| Step: 9
Training loss: 1.936866044998169
Validation loss: 1.9913355073621195

Epoch: 5| Step: 10
Training loss: 2.5899081230163574
Validation loss: 1.9709845255779963

Epoch: 151| Step: 0
Training loss: 1.52419114112854
Validation loss: 1.984548104706631

Epoch: 5| Step: 1
Training loss: 2.1651711463928223
Validation loss: 2.004162117999087

Epoch: 5| Step: 2
Training loss: 1.7136144638061523
Validation loss: 1.9807336791869132

Epoch: 5| Step: 3
Training loss: 2.4810900688171387
Validation loss: 1.9914611924079157

Epoch: 5| Step: 4
Training loss: 2.153224468231201
Validation loss: 1.9941465970008605

Epoch: 5| Step: 5
Training loss: 1.7643550634384155
Validation loss: 1.978839200030091

Epoch: 5| Step: 6
Training loss: 2.4337050914764404
Validation loss: 1.9690494280989452

Epoch: 5| Step: 7
Training loss: 1.8621807098388672
Validation loss: 1.9818118605562436

Epoch: 5| Step: 8
Training loss: 2.374088764190674
Validation loss: 1.9614031109758603

Epoch: 5| Step: 9
Training loss: 1.4486443996429443
Validation loss: 1.9960497245993665

Epoch: 5| Step: 10
Training loss: 2.8454766273498535
Validation loss: 1.9543229905507897

Epoch: 152| Step: 0
Training loss: 2.049384355545044
Validation loss: 1.983322787028487

Epoch: 5| Step: 1
Training loss: 2.242042064666748
Validation loss: 1.9893969976773827

Epoch: 5| Step: 2
Training loss: 2.510983467102051
Validation loss: 1.9975319113782657

Epoch: 5| Step: 3
Training loss: 1.836032509803772
Validation loss: 1.9835911168847034

Epoch: 5| Step: 4
Training loss: 1.5489650964736938
Validation loss: 1.957983414332072

Epoch: 5| Step: 5
Training loss: 1.8758947849273682
Validation loss: 1.9833595034896687

Epoch: 5| Step: 6
Training loss: 2.7727644443511963
Validation loss: 1.9845464050128896

Epoch: 5| Step: 7
Training loss: 2.3850083351135254
Validation loss: 1.9857189655303955

Epoch: 5| Step: 8
Training loss: 1.969312071800232
Validation loss: 1.977869592687135

Epoch: 5| Step: 9
Training loss: 1.5860992670059204
Validation loss: 1.9909858959977345

Epoch: 5| Step: 10
Training loss: 1.9540412425994873
Validation loss: 1.9778682070393716

Epoch: 153| Step: 0
Training loss: 2.6725006103515625
Validation loss: 1.9938698327669533

Epoch: 5| Step: 1
Training loss: 1.7925697565078735
Validation loss: 1.9686858936022686

Epoch: 5| Step: 2
Training loss: 2.200585126876831
Validation loss: 1.9860783238564768

Epoch: 5| Step: 3
Training loss: 1.7135694026947021
Validation loss: 1.9809709672004945

Epoch: 5| Step: 4
Training loss: 1.5794378519058228
Validation loss: 1.967896266650128

Epoch: 5| Step: 5
Training loss: 2.0600409507751465
Validation loss: 1.9881600577344176

Epoch: 5| Step: 6
Training loss: 2.3220081329345703
Validation loss: 1.9926896890004475

Epoch: 5| Step: 7
Training loss: 2.044497489929199
Validation loss: 1.9965007753782376

Epoch: 5| Step: 8
Training loss: 1.9687764644622803
Validation loss: 1.99163346393134

Epoch: 5| Step: 9
Training loss: 2.225482225418091
Validation loss: 2.017752860182075

Epoch: 5| Step: 10
Training loss: 2.0488224029541016
Validation loss: 1.9913653173754293

Epoch: 154| Step: 0
Training loss: 1.7314765453338623
Validation loss: 1.9922962611721409

Epoch: 5| Step: 1
Training loss: 1.6709585189819336
Validation loss: 1.9764635473169305

Epoch: 5| Step: 2
Training loss: 2.1656296253204346
Validation loss: 1.996231282910993

Epoch: 5| Step: 3
Training loss: 2.512267589569092
Validation loss: 1.9922314087549846

Epoch: 5| Step: 4
Training loss: 2.2791614532470703
Validation loss: 1.9767580724531604

Epoch: 5| Step: 5
Training loss: 1.6934407949447632
Validation loss: 1.9848306102137412

Epoch: 5| Step: 6
Training loss: 2.002270221710205
Validation loss: 1.9838648201316915

Epoch: 5| Step: 7
Training loss: 2.103498935699463
Validation loss: 1.993895943446826

Epoch: 5| Step: 8
Training loss: 1.7967649698257446
Validation loss: 1.995130169776178

Epoch: 5| Step: 9
Training loss: 2.559542655944824
Validation loss: 1.9608614560096496

Epoch: 5| Step: 10
Training loss: 2.0350100994110107
Validation loss: 1.9703665189845587

Epoch: 155| Step: 0
Training loss: 1.9497864246368408
Validation loss: 1.9790365401134695

Epoch: 5| Step: 1
Training loss: 2.17688250541687
Validation loss: 1.9873888928403136

Epoch: 5| Step: 2
Training loss: 1.9822807312011719
Validation loss: 2.003142213308683

Epoch: 5| Step: 3
Training loss: 2.4818902015686035
Validation loss: 2.003485797553934

Epoch: 5| Step: 4
Training loss: 1.8633320331573486
Validation loss: 1.9696718672270417

Epoch: 5| Step: 5
Training loss: 2.3511104583740234
Validation loss: 1.9860621831750358

Epoch: 5| Step: 6
Training loss: 2.0156502723693848
Validation loss: 1.9969843767022575

Epoch: 5| Step: 7
Training loss: 2.2011466026306152
Validation loss: 1.9949592928732596

Epoch: 5| Step: 8
Training loss: 2.1161646842956543
Validation loss: 1.9545351843680105

Epoch: 5| Step: 9
Training loss: 1.5187804698944092
Validation loss: 1.985902100481013

Epoch: 5| Step: 10
Training loss: 2.172776699066162
Validation loss: 2.0082364607882757

Epoch: 156| Step: 0
Training loss: 2.2099709510803223
Validation loss: 1.9795910235374206

Epoch: 5| Step: 1
Training loss: 1.6808252334594727
Validation loss: 1.984234784239082

Epoch: 5| Step: 2
Training loss: 2.1845791339874268
Validation loss: 1.9740501962682253

Epoch: 5| Step: 3
Training loss: 2.0894837379455566
Validation loss: 2.0010477342913227

Epoch: 5| Step: 4
Training loss: 2.473921298980713
Validation loss: 1.9845959268590456

Epoch: 5| Step: 5
Training loss: 2.1998238563537598
Validation loss: 1.9569142044231456

Epoch: 5| Step: 6
Training loss: 2.219874143600464
Validation loss: 1.981957317680441

Epoch: 5| Step: 7
Training loss: 1.623529076576233
Validation loss: 1.982538023302632

Epoch: 5| Step: 8
Training loss: 1.6229791641235352
Validation loss: 1.9883767712500788

Epoch: 5| Step: 9
Training loss: 1.746551513671875
Validation loss: 1.954878273830619

Epoch: 5| Step: 10
Training loss: 2.2895114421844482
Validation loss: 1.9631194811995312

Epoch: 157| Step: 0
Training loss: 1.7740427255630493
Validation loss: 1.9891793522783505

Epoch: 5| Step: 1
Training loss: 2.4550328254699707
Validation loss: 1.9981386751256964

Epoch: 5| Step: 2
Training loss: 2.3000097274780273
Validation loss: 1.9963780167282268

Epoch: 5| Step: 3
Training loss: 1.883232831954956
Validation loss: 1.9819138408989034

Epoch: 5| Step: 4
Training loss: 2.096071481704712
Validation loss: 1.954165171551448

Epoch: 5| Step: 5
Training loss: 2.107300043106079
Validation loss: 1.9828363644179476

Epoch: 5| Step: 6
Training loss: 2.1928203105926514
Validation loss: 1.9609639465167958

Epoch: 5| Step: 7
Training loss: 1.4023942947387695
Validation loss: 1.9913432572477607

Epoch: 5| Step: 8
Training loss: 2.0161471366882324
Validation loss: 2.0095173235862487

Epoch: 5| Step: 9
Training loss: 2.079543352127075
Validation loss: 1.983184173542966

Epoch: 5| Step: 10
Training loss: 2.1458375453948975
Validation loss: 1.9799233559639222

Epoch: 158| Step: 0
Training loss: 1.9794178009033203
Validation loss: 1.9868562606073195

Epoch: 5| Step: 1
Training loss: 2.135033369064331
Validation loss: 1.9991104987359816

Epoch: 5| Step: 2
Training loss: 1.5696913003921509
Validation loss: 1.9835310059209024

Epoch: 5| Step: 3
Training loss: 2.2444539070129395
Validation loss: 1.9912648175352363

Epoch: 5| Step: 4
Training loss: 2.0723631381988525
Validation loss: 2.0135432994493874

Epoch: 5| Step: 5
Training loss: 2.47965669631958
Validation loss: 1.9822440455036778

Epoch: 5| Step: 6
Training loss: 1.652714729309082
Validation loss: 1.9876562472312682

Epoch: 5| Step: 7
Training loss: 2.540113925933838
Validation loss: 2.0090283398987143

Epoch: 5| Step: 8
Training loss: 1.8762414455413818
Validation loss: 1.9811734384106052

Epoch: 5| Step: 9
Training loss: 2.2803239822387695
Validation loss: 1.990308146322927

Epoch: 5| Step: 10
Training loss: 1.6117526292800903
Validation loss: 1.9895275895313551

Epoch: 159| Step: 0
Training loss: 1.9113986492156982
Validation loss: 1.9747666569166287

Epoch: 5| Step: 1
Training loss: 1.845314383506775
Validation loss: 1.9839034285596622

Epoch: 5| Step: 2
Training loss: 2.924325466156006
Validation loss: 2.0121735424123783

Epoch: 5| Step: 3
Training loss: 1.8419082164764404
Validation loss: 1.973545673072979

Epoch: 5| Step: 4
Training loss: 2.332345724105835
Validation loss: 2.00698096136893

Epoch: 5| Step: 5
Training loss: 2.1398189067840576
Validation loss: 2.0028451437591226

Epoch: 5| Step: 6
Training loss: 1.9371448755264282
Validation loss: 1.9965762117857575

Epoch: 5| Step: 7
Training loss: 1.936316728591919
Validation loss: 1.9773125366498066

Epoch: 5| Step: 8
Training loss: 2.2954094409942627
Validation loss: 2.0246071302762596

Epoch: 5| Step: 9
Training loss: 1.609012246131897
Validation loss: 1.99163394845942

Epoch: 5| Step: 10
Training loss: 1.7543829679489136
Validation loss: 1.9949507046771306

Epoch: 160| Step: 0
Training loss: 2.343198776245117
Validation loss: 2.0026021170359787

Epoch: 5| Step: 1
Training loss: 1.9767318964004517
Validation loss: 1.9908583061669463

Epoch: 5| Step: 2
Training loss: 1.8655792474746704
Validation loss: 1.980420430501302

Epoch: 5| Step: 3
Training loss: 2.167609930038452
Validation loss: 1.9780124977070799

Epoch: 5| Step: 4
Training loss: 1.7405688762664795
Validation loss: 1.9783858099291403

Epoch: 5| Step: 5
Training loss: 1.950453758239746
Validation loss: 1.9872726701921033

Epoch: 5| Step: 6
Training loss: 2.080704927444458
Validation loss: 2.0221444791363132

Epoch: 5| Step: 7
Training loss: 2.6392931938171387
Validation loss: 1.9776668035855858

Epoch: 5| Step: 8
Training loss: 1.9205195903778076
Validation loss: 2.006492939046634

Epoch: 5| Step: 9
Training loss: 2.207287073135376
Validation loss: 1.9922781631510744

Epoch: 5| Step: 10
Training loss: 1.5674620866775513
Validation loss: 1.9910034287360407

Epoch: 161| Step: 0
Training loss: 1.8914527893066406
Validation loss: 1.9861510620322278

Epoch: 5| Step: 1
Training loss: 1.9334217309951782
Validation loss: 1.9635712972251318

Epoch: 5| Step: 2
Training loss: 2.3093886375427246
Validation loss: 1.9619993086784118

Epoch: 5| Step: 3
Training loss: 1.9278976917266846
Validation loss: 1.9774609791335238

Epoch: 5| Step: 4
Training loss: 2.1077780723571777
Validation loss: 1.9899552009438957

Epoch: 5| Step: 5
Training loss: 1.914088249206543
Validation loss: 1.9520502692909651

Epoch: 5| Step: 6
Training loss: 2.0643069744110107
Validation loss: 1.9803070278577908

Epoch: 5| Step: 7
Training loss: 1.5090868473052979
Validation loss: 1.9824117793831775

Epoch: 5| Step: 8
Training loss: 2.708538055419922
Validation loss: 1.9699806577415877

Epoch: 5| Step: 9
Training loss: 1.8028419017791748
Validation loss: 1.9741921232592674

Epoch: 5| Step: 10
Training loss: 2.2638051509857178
Validation loss: 1.9986844960079397

Epoch: 162| Step: 0
Training loss: 1.7952568531036377
Validation loss: 1.948315699895223

Epoch: 5| Step: 1
Training loss: 2.136484384536743
Validation loss: 1.9633495525647235

Epoch: 5| Step: 2
Training loss: 1.7931582927703857
Validation loss: 1.982928450389575

Epoch: 5| Step: 3
Training loss: 2.0227417945861816
Validation loss: 1.9837374212921306

Epoch: 5| Step: 4
Training loss: 1.934653878211975
Validation loss: 2.0052256481621855

Epoch: 5| Step: 5
Training loss: 2.016160488128662
Validation loss: 2.0032047994675173

Epoch: 5| Step: 6
Training loss: 2.0253467559814453
Validation loss: 1.9866716592542586

Epoch: 5| Step: 7
Training loss: 1.8461072444915771
Validation loss: 1.9962405927719609

Epoch: 5| Step: 8
Training loss: 2.2881596088409424
Validation loss: 1.9824711648366784

Epoch: 5| Step: 9
Training loss: 2.7174808979034424
Validation loss: 1.9758243124972108

Epoch: 5| Step: 10
Training loss: 1.6266039609909058
Validation loss: 1.9924993809833322

Epoch: 163| Step: 0
Training loss: 2.56355881690979
Validation loss: 1.9578217793536443

Epoch: 5| Step: 1
Training loss: 1.8839534521102905
Validation loss: 1.9904824636315788

Epoch: 5| Step: 2
Training loss: 1.576493263244629
Validation loss: 1.9660938721831127

Epoch: 5| Step: 3
Training loss: 1.878198266029358
Validation loss: 1.9915547563183693

Epoch: 5| Step: 4
Training loss: 1.3671945333480835
Validation loss: 1.9768204714662285

Epoch: 5| Step: 5
Training loss: 2.729740858078003
Validation loss: 1.9677829178430701

Epoch: 5| Step: 6
Training loss: 1.8390626907348633
Validation loss: 1.9755323471561554

Epoch: 5| Step: 7
Training loss: 2.067033529281616
Validation loss: 1.9673149098632157

Epoch: 5| Step: 8
Training loss: 2.2701573371887207
Validation loss: 2.003653294296675

Epoch: 5| Step: 9
Training loss: 2.1496503353118896
Validation loss: 1.992848773156443

Epoch: 5| Step: 10
Training loss: 1.9721583127975464
Validation loss: 2.0057023084291847

Epoch: 164| Step: 0
Training loss: 1.819617509841919
Validation loss: 1.9846989480398034

Epoch: 5| Step: 1
Training loss: 2.191981792449951
Validation loss: 1.9834065309134863

Epoch: 5| Step: 2
Training loss: 1.6850650310516357
Validation loss: 1.9759585280572214

Epoch: 5| Step: 3
Training loss: 2.2477707862854004
Validation loss: 1.9915063253013037

Epoch: 5| Step: 4
Training loss: 2.174252986907959
Validation loss: 1.9845324382987073

Epoch: 5| Step: 5
Training loss: 1.8606185913085938
Validation loss: 2.0016996681049304

Epoch: 5| Step: 6
Training loss: 2.5322532653808594
Validation loss: 2.008067554043185

Epoch: 5| Step: 7
Training loss: 2.1049327850341797
Validation loss: 1.9985799609973867

Epoch: 5| Step: 8
Training loss: 2.3539023399353027
Validation loss: 2.0137774457213697

Epoch: 5| Step: 9
Training loss: 1.261551022529602
Validation loss: 2.0021123757926365

Epoch: 5| Step: 10
Training loss: 2.0554733276367188
Validation loss: 1.999339117798754

Epoch: 165| Step: 0
Training loss: 2.5090994834899902
Validation loss: 2.0121135839851956

Epoch: 5| Step: 1
Training loss: 1.9720373153686523
Validation loss: 1.9801589417201217

Epoch: 5| Step: 2
Training loss: 1.7350059747695923
Validation loss: 1.9961392648758427

Epoch: 5| Step: 3
Training loss: 2.3335213661193848
Validation loss: 1.9993899483834543

Epoch: 5| Step: 4
Training loss: 2.182189464569092
Validation loss: 1.994487254850326

Epoch: 5| Step: 5
Training loss: 1.9605486392974854
Validation loss: 2.0032736844913934

Epoch: 5| Step: 6
Training loss: 1.6757051944732666
Validation loss: 1.9649160574841242

Epoch: 5| Step: 7
Training loss: 1.495516061782837
Validation loss: 1.968130596222416

Epoch: 5| Step: 8
Training loss: 2.3031187057495117
Validation loss: 1.993439036030923

Epoch: 5| Step: 9
Training loss: 1.7963314056396484
Validation loss: 1.950723550652945

Epoch: 5| Step: 10
Training loss: 2.2993202209472656
Validation loss: 1.9970645622540546

Epoch: 166| Step: 0
Training loss: 2.013641357421875
Validation loss: 1.9674704100496025

Epoch: 5| Step: 1
Training loss: 1.7327358722686768
Validation loss: 1.9628089371547903

Epoch: 5| Step: 2
Training loss: 1.8830543756484985
Validation loss: 1.9623539857966925

Epoch: 5| Step: 3
Training loss: 2.2256181240081787
Validation loss: 1.9973260202715475

Epoch: 5| Step: 4
Training loss: 2.0534701347351074
Validation loss: 1.9679429454188193

Epoch: 5| Step: 5
Training loss: 2.5712332725524902
Validation loss: 1.9822343344329505

Epoch: 5| Step: 6
Training loss: 1.4710161685943604
Validation loss: 1.9547620281096427

Epoch: 5| Step: 7
Training loss: 2.2686984539031982
Validation loss: 2.0087166588793517

Epoch: 5| Step: 8
Training loss: 1.945587158203125
Validation loss: 1.9936749922331942

Epoch: 5| Step: 9
Training loss: 2.0572593212127686
Validation loss: 1.9910847756170458

Epoch: 5| Step: 10
Training loss: 2.1928350925445557
Validation loss: 1.9786309311466832

Epoch: 167| Step: 0
Training loss: 2.3052852153778076
Validation loss: 1.9944777283617245

Epoch: 5| Step: 1
Training loss: 1.9647471904754639
Validation loss: 1.9912300084226875

Epoch: 5| Step: 2
Training loss: 1.818565011024475
Validation loss: 2.008210269353723

Epoch: 5| Step: 3
Training loss: 2.3333702087402344
Validation loss: 1.9993390011531051

Epoch: 5| Step: 4
Training loss: 1.5788153409957886
Validation loss: 1.9869910029954807

Epoch: 5| Step: 5
Training loss: 1.7498972415924072
Validation loss: 2.006928083717182

Epoch: 5| Step: 6
Training loss: 2.258666515350342
Validation loss: 2.002478168856713

Epoch: 5| Step: 7
Training loss: 2.9749577045440674
Validation loss: 2.026310674605831

Epoch: 5| Step: 8
Training loss: 1.3924379348754883
Validation loss: 2.0124168152450235

Epoch: 5| Step: 9
Training loss: 1.6426382064819336
Validation loss: 2.0100454976481776

Epoch: 5| Step: 10
Training loss: 2.4975521564483643
Validation loss: 2.0054605263535694

Epoch: 168| Step: 0
Training loss: 2.3404011726379395
Validation loss: 2.021399509522223

Epoch: 5| Step: 1
Training loss: 1.963460922241211
Validation loss: 1.9961384240017142

Epoch: 5| Step: 2
Training loss: 1.8054803609848022
Validation loss: 1.964350679869293

Epoch: 5| Step: 3
Training loss: 1.7381280660629272
Validation loss: 2.013819679137199

Epoch: 5| Step: 4
Training loss: 2.54390025138855
Validation loss: 1.9933541602985834

Epoch: 5| Step: 5
Training loss: 2.6066014766693115
Validation loss: 1.969134037212659

Epoch: 5| Step: 6
Training loss: 2.0381112098693848
Validation loss: 1.968401526892057

Epoch: 5| Step: 7
Training loss: 1.3589369058609009
Validation loss: 1.9981187030833254

Epoch: 5| Step: 8
Training loss: 2.031968593597412
Validation loss: 1.9864866528459775

Epoch: 5| Step: 9
Training loss: 1.9314521551132202
Validation loss: 1.9666288065653976

Epoch: 5| Step: 10
Training loss: 1.818304181098938
Validation loss: 1.971992051729592

Epoch: 169| Step: 0
Training loss: 2.1232805252075195
Validation loss: 1.9723650050419632

Epoch: 5| Step: 1
Training loss: 1.835557222366333
Validation loss: 1.9819467170264131

Epoch: 5| Step: 2
Training loss: 2.318091630935669
Validation loss: 1.9710409205446962

Epoch: 5| Step: 3
Training loss: 1.987842321395874
Validation loss: 1.9742701694529543

Epoch: 5| Step: 4
Training loss: 2.2225193977355957
Validation loss: 1.9985221098828059

Epoch: 5| Step: 5
Training loss: 2.01747465133667
Validation loss: 2.0159706056758924

Epoch: 5| Step: 6
Training loss: 1.6424150466918945
Validation loss: 1.9952444594393495

Epoch: 5| Step: 7
Training loss: 2.2365288734436035
Validation loss: 2.003263699111118

Epoch: 5| Step: 8
Training loss: 1.3396531343460083
Validation loss: 1.9925576435622347

Epoch: 5| Step: 9
Training loss: 2.020442485809326
Validation loss: 2.0214018565352245

Epoch: 5| Step: 10
Training loss: 2.501793384552002
Validation loss: 1.9865974969761346

Epoch: 170| Step: 0
Training loss: 2.08569598197937
Validation loss: 1.9875646688604867

Epoch: 5| Step: 1
Training loss: 1.7109912633895874
Validation loss: 2.0032963688655565

Epoch: 5| Step: 2
Training loss: 1.6409788131713867
Validation loss: 1.9866686944038636

Epoch: 5| Step: 3
Training loss: 2.041584014892578
Validation loss: 1.9862443195876254

Epoch: 5| Step: 4
Training loss: 2.184519052505493
Validation loss: 2.001332982893913

Epoch: 5| Step: 5
Training loss: 1.790020227432251
Validation loss: 2.0028901766705256

Epoch: 5| Step: 6
Training loss: 1.6668055057525635
Validation loss: 1.9930291380933536

Epoch: 5| Step: 7
Training loss: 1.9794288873672485
Validation loss: 1.9757500233188752

Epoch: 5| Step: 8
Training loss: 2.657695770263672
Validation loss: 1.9707071319703133

Epoch: 5| Step: 9
Training loss: 2.209164619445801
Validation loss: 2.0224071702649518

Epoch: 5| Step: 10
Training loss: 2.2825217247009277
Validation loss: 1.9581036029323455

Epoch: 171| Step: 0
Training loss: 1.5604033470153809
Validation loss: 1.9992332778951174

Epoch: 5| Step: 1
Training loss: 2.046949625015259
Validation loss: 1.999198268818599

Epoch: 5| Step: 2
Training loss: 2.5179247856140137
Validation loss: 1.970482446814096

Epoch: 5| Step: 3
Training loss: 2.17433500289917
Validation loss: 2.0003316338344286

Epoch: 5| Step: 4
Training loss: 2.2089550495147705
Validation loss: 1.973569372648834

Epoch: 5| Step: 5
Training loss: 2.0734944343566895
Validation loss: 2.0001341142962055

Epoch: 5| Step: 6
Training loss: 1.870654821395874
Validation loss: 1.9958244549330844

Epoch: 5| Step: 7
Training loss: 2.149306297302246
Validation loss: 1.987638686292915

Epoch: 5| Step: 8
Training loss: 2.101763963699341
Validation loss: 1.975984013208779

Epoch: 5| Step: 9
Training loss: 1.374738097190857
Validation loss: 1.9947553603879866

Epoch: 5| Step: 10
Training loss: 2.1249794960021973
Validation loss: 1.99575000937267

Epoch: 172| Step: 0
Training loss: 1.6496025323867798
Validation loss: 1.9930281690371934

Epoch: 5| Step: 1
Training loss: 2.187526226043701
Validation loss: 2.0097705600082234

Epoch: 5| Step: 2
Training loss: 2.3673806190490723
Validation loss: 1.9764011354856594

Epoch: 5| Step: 3
Training loss: 2.4335060119628906
Validation loss: 2.0043500508031538

Epoch: 5| Step: 4
Training loss: 2.1956334114074707
Validation loss: 1.9985026313412575

Epoch: 5| Step: 5
Training loss: 1.272063136100769
Validation loss: 2.0049499491209626

Epoch: 5| Step: 6
Training loss: 2.0387558937072754
Validation loss: 2.003906698637111

Epoch: 5| Step: 7
Training loss: 2.055222272872925
Validation loss: 1.9943620261325632

Epoch: 5| Step: 8
Training loss: 1.8128902912139893
Validation loss: 1.9747451736081032

Epoch: 5| Step: 9
Training loss: 1.9333860874176025
Validation loss: 1.9970024965142692

Epoch: 5| Step: 10
Training loss: 2.2268121242523193
Validation loss: 1.9833789769039358

Epoch: 173| Step: 0
Training loss: 1.9788410663604736
Validation loss: 2.000939876802506

Epoch: 5| Step: 1
Training loss: 2.542536973953247
Validation loss: 1.99937351288334

Epoch: 5| Step: 2
Training loss: 1.8827965259552002
Validation loss: 1.9987534348682692

Epoch: 5| Step: 3
Training loss: 1.7865688800811768
Validation loss: 1.9853659752876527

Epoch: 5| Step: 4
Training loss: 2.462390422821045
Validation loss: 1.9724664329200663

Epoch: 5| Step: 5
Training loss: 2.366943597793579
Validation loss: 1.9919612830685032

Epoch: 5| Step: 6
Training loss: 1.4307739734649658
Validation loss: 1.950086805128282

Epoch: 5| Step: 7
Training loss: 1.8546642065048218
Validation loss: 2.0047817499406877

Epoch: 5| Step: 8
Training loss: 1.4445499181747437
Validation loss: 1.992145751112251

Epoch: 5| Step: 9
Training loss: 2.0577943325042725
Validation loss: 1.9893785689466743

Epoch: 5| Step: 10
Training loss: 2.194009780883789
Validation loss: 1.9750135893462806

Epoch: 174| Step: 0
Training loss: 2.2103679180145264
Validation loss: 1.978780197840865

Epoch: 5| Step: 1
Training loss: 1.6306850910186768
Validation loss: 2.0056911360832954

Epoch: 5| Step: 2
Training loss: 2.236523389816284
Validation loss: 1.9887327276250368

Epoch: 5| Step: 3
Training loss: 2.3968002796173096
Validation loss: 1.9935619497811923

Epoch: 5| Step: 4
Training loss: 1.9268087148666382
Validation loss: 1.985756734366058

Epoch: 5| Step: 5
Training loss: 2.0717275142669678
Validation loss: 1.9840980524657874

Epoch: 5| Step: 6
Training loss: 1.8104660511016846
Validation loss: 1.9585556932674941

Epoch: 5| Step: 7
Training loss: 2.0019099712371826
Validation loss: 1.993205456323521

Epoch: 5| Step: 8
Training loss: 1.9511677026748657
Validation loss: 1.985715135451286

Epoch: 5| Step: 9
Training loss: 1.8372294902801514
Validation loss: 1.9709212331361667

Epoch: 5| Step: 10
Training loss: 1.8331958055496216
Validation loss: 1.9744437586876653

Epoch: 175| Step: 0
Training loss: 2.3951821327209473
Validation loss: 1.9853795049011067

Epoch: 5| Step: 1
Training loss: 2.2275803089141846
Validation loss: 1.9764882005671018

Epoch: 5| Step: 2
Training loss: 2.0127289295196533
Validation loss: 2.0164984938918904

Epoch: 5| Step: 3
Training loss: 1.4120172262191772
Validation loss: 1.9774989415240545

Epoch: 5| Step: 4
Training loss: 2.0753726959228516
Validation loss: 1.9661881180219754

Epoch: 5| Step: 5
Training loss: 2.322028636932373
Validation loss: 1.9984449455814977

Epoch: 5| Step: 6
Training loss: 1.6147531270980835
Validation loss: 1.9561049989474717

Epoch: 5| Step: 7
Training loss: 1.7776590585708618
Validation loss: 1.9838533965490197

Epoch: 5| Step: 8
Training loss: 1.3103561401367188
Validation loss: 1.993301345456031

Epoch: 5| Step: 9
Training loss: 2.354816198348999
Validation loss: 2.005852608270543

Epoch: 5| Step: 10
Training loss: 2.552480459213257
Validation loss: 1.987160821114817

Testing loss: 2.060994333691067
