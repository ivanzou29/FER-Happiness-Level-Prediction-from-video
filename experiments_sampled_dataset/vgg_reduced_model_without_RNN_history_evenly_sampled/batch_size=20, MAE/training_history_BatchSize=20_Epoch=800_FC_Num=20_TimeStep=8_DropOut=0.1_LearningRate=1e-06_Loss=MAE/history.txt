Epoch: 1| Step: 0
Training loss: 3.350548267364502
Validation loss: 3.4062802253230924

Epoch: 5| Step: 1
Training loss: 3.2690842151641846
Validation loss: 3.405834677398846

Epoch: 5| Step: 2
Training loss: 3.5912697315216064
Validation loss: 3.4036784889877483

Epoch: 5| Step: 3
Training loss: 3.0892491340637207
Validation loss: 3.4017292581578737

Epoch: 5| Step: 4
Training loss: 3.1776504516601562
Validation loss: 3.4012752732922955

Epoch: 5| Step: 5
Training loss: 2.8325257301330566
Validation loss: 3.400718294164186

Epoch: 5| Step: 6
Training loss: 2.77668833732605
Validation loss: 3.3988697016110985

Epoch: 5| Step: 7
Training loss: 3.1234402656555176
Validation loss: 3.3969380317195768

Epoch: 5| Step: 8
Training loss: 3.7944884300231934
Validation loss: 3.393839615647511

Epoch: 5| Step: 9
Training loss: 4.734978675842285
Validation loss: 3.394928352807158

Epoch: 5| Step: 10
Training loss: 3.1011877059936523
Validation loss: 3.3936965619364092

Epoch: 2| Step: 0
Training loss: 2.881331205368042
Validation loss: 3.3910251919941237

Epoch: 5| Step: 1
Training loss: 3.662889003753662
Validation loss: 3.3877580191499446

Epoch: 5| Step: 2
Training loss: 3.4538779258728027
Validation loss: 3.3886045332877868

Epoch: 5| Step: 3
Training loss: 3.2897238731384277
Validation loss: 3.38483004928917

Epoch: 5| Step: 4
Training loss: 3.786175489425659
Validation loss: 3.3834346289275796

Epoch: 5| Step: 5
Training loss: 3.210142135620117
Validation loss: 3.38041413727627

Epoch: 5| Step: 6
Training loss: 2.5019710063934326
Validation loss: 3.3801695300686743

Epoch: 5| Step: 7
Training loss: 3.3890380859375
Validation loss: 3.379790852146764

Epoch: 5| Step: 8
Training loss: 3.463710308074951
Validation loss: 3.376412304498816

Epoch: 5| Step: 9
Training loss: 3.1748597621917725
Validation loss: 3.374087574661419

Epoch: 5| Step: 10
Training loss: 3.993391990661621
Validation loss: 3.3734073228733514

Epoch: 3| Step: 0
Training loss: 3.3150200843811035
Validation loss: 3.3687350365423385

Epoch: 5| Step: 1
Training loss: 3.9094085693359375
Validation loss: 3.36880664671621

Epoch: 5| Step: 2
Training loss: 3.3716208934783936
Validation loss: 3.366141608966294

Epoch: 5| Step: 3
Training loss: 3.7877326011657715
Validation loss: 3.366075328601304

Epoch: 5| Step: 4
Training loss: 3.0251801013946533
Validation loss: 3.361309720623878

Epoch: 5| Step: 5
Training loss: 1.8606761693954468
Validation loss: 3.360511346529889

Epoch: 5| Step: 6
Training loss: 3.615680694580078
Validation loss: 3.357903854821318

Epoch: 5| Step: 7
Training loss: 3.5246639251708984
Validation loss: 3.3553530631526822

Epoch: 5| Step: 8
Training loss: 2.714709997177124
Validation loss: 3.3537496828263804

Epoch: 5| Step: 9
Training loss: 4.601558685302734
Validation loss: 3.350681668968611

Epoch: 5| Step: 10
Training loss: 2.681957960128784
Validation loss: 3.3489685314957813

Epoch: 4| Step: 0
Training loss: 3.2928824424743652
Validation loss: 3.348252888648741

Epoch: 5| Step: 1
Training loss: 2.7969279289245605
Validation loss: 3.346114748267717

Epoch: 5| Step: 2
Training loss: 3.60386323928833
Validation loss: 3.3419275437631915

Epoch: 5| Step: 3
Training loss: 4.718749046325684
Validation loss: 3.3416430463073072

Epoch: 5| Step: 4
Training loss: 4.372834205627441
Validation loss: 3.3383265336354575

Epoch: 5| Step: 5
Training loss: 2.868168354034424
Validation loss: 3.3348372879848687

Epoch: 5| Step: 6
Training loss: 3.2681617736816406
Validation loss: 3.33341226526486

Epoch: 5| Step: 7
Training loss: 3.3053088188171387
Validation loss: 3.3300475176944526

Epoch: 5| Step: 8
Training loss: 2.998816967010498
Validation loss: 3.3255267758523264

Epoch: 5| Step: 9
Training loss: 2.3430399894714355
Validation loss: 3.325877848491874

Epoch: 5| Step: 10
Training loss: 2.610358953475952
Validation loss: 3.323793570200602

Epoch: 5| Step: 0
Training loss: 2.1611337661743164
Validation loss: 3.3194510808555027

Epoch: 5| Step: 1
Training loss: 3.5873589515686035
Validation loss: 3.3179857884683917

Epoch: 5| Step: 2
Training loss: 3.308018207550049
Validation loss: 3.317682158562445

Epoch: 5| Step: 3
Training loss: 3.4269440174102783
Validation loss: 3.311978481149161

Epoch: 5| Step: 4
Training loss: 3.034809112548828
Validation loss: 3.3108574574993503

Epoch: 5| Step: 5
Training loss: 2.483391046524048
Validation loss: 3.310321338715092

Epoch: 5| Step: 6
Training loss: 2.474395751953125
Validation loss: 3.30542448002805

Epoch: 5| Step: 7
Training loss: 3.8465332984924316
Validation loss: 3.3026631955177552

Epoch: 5| Step: 8
Training loss: 4.193178176879883
Validation loss: 3.30190949286184

Epoch: 5| Step: 9
Training loss: 3.8027775287628174
Validation loss: 3.2988103564067552

Epoch: 5| Step: 10
Training loss: 3.773805856704712
Validation loss: 3.2947746758819907

Epoch: 6| Step: 0
Training loss: 2.95719575881958
Validation loss: 3.293634501836633

Epoch: 5| Step: 1
Training loss: 3.1231181621551514
Validation loss: 3.2904499320573706

Epoch: 5| Step: 2
Training loss: 3.257413864135742
Validation loss: 3.2884489797776744

Epoch: 5| Step: 3
Training loss: 3.2807235717773438
Validation loss: 3.285682983295892

Epoch: 5| Step: 4
Training loss: 3.0808873176574707
Validation loss: 3.2813224920662503

Epoch: 5| Step: 5
Training loss: 2.5708374977111816
Validation loss: 3.280050875038229

Epoch: 5| Step: 6
Training loss: 3.092024326324463
Validation loss: 3.2755789013319117

Epoch: 5| Step: 7
Training loss: 4.486367225646973
Validation loss: 3.2736031393851004

Epoch: 5| Step: 8
Training loss: 3.1474146842956543
Validation loss: 3.2716123775769304

Epoch: 5| Step: 9
Training loss: 2.8348355293273926
Validation loss: 3.26807741965017

Epoch: 5| Step: 10
Training loss: 4.064042091369629
Validation loss: 3.2649231777396253

Epoch: 7| Step: 0
Training loss: 3.1725997924804688
Validation loss: 3.262055168869675

Epoch: 5| Step: 1
Training loss: 3.1223158836364746
Validation loss: 3.2605028870285198

Epoch: 5| Step: 2
Training loss: 4.004585266113281
Validation loss: 3.2558173466754217

Epoch: 5| Step: 3
Training loss: 3.1011343002319336
Validation loss: 3.2524866493799354

Epoch: 5| Step: 4
Training loss: 2.7869434356689453
Validation loss: 3.2523947223540275

Epoch: 5| Step: 5
Training loss: 3.833597183227539
Validation loss: 3.24970672463858

Epoch: 5| Step: 6
Training loss: 3.5851287841796875
Validation loss: 3.2458581309164725

Epoch: 5| Step: 7
Training loss: 3.6504149436950684
Validation loss: 3.2409147036972867

Epoch: 5| Step: 8
Training loss: 2.792417526245117
Validation loss: 3.2390730714285247

Epoch: 5| Step: 9
Training loss: 2.584446668624878
Validation loss: 3.2355277820300032

Epoch: 5| Step: 10
Training loss: 2.82958984375
Validation loss: 3.23161805060602

Epoch: 8| Step: 0
Training loss: 3.7833855152130127
Validation loss: 3.2275788886572725

Epoch: 5| Step: 1
Training loss: 2.951420545578003
Validation loss: 3.2252275097754692

Epoch: 5| Step: 2
Training loss: 2.2387099266052246
Validation loss: 3.222590469544934

Epoch: 5| Step: 3
Training loss: 3.335108518600464
Validation loss: 3.2209440559469242

Epoch: 5| Step: 4
Training loss: 3.459473133087158
Validation loss: 3.215824701452768

Epoch: 5| Step: 5
Training loss: 3.987605571746826
Validation loss: 3.2106913571716635

Epoch: 5| Step: 6
Training loss: 3.330033779144287
Validation loss: 3.2078236149203394

Epoch: 5| Step: 7
Training loss: 3.330670118331909
Validation loss: 3.2054557261928434

Epoch: 5| Step: 8
Training loss: 2.853844404220581
Validation loss: 3.2021767144562094

Epoch: 5| Step: 9
Training loss: 2.5645017623901367
Validation loss: 3.1980371680310977

Epoch: 5| Step: 10
Training loss: 3.4178035259246826
Validation loss: 3.194994198378696

Epoch: 9| Step: 0
Training loss: 4.268715858459473
Validation loss: 3.190409565484652

Epoch: 5| Step: 1
Training loss: 2.8008792400360107
Validation loss: 3.1886628161194506

Epoch: 5| Step: 2
Training loss: 2.7097411155700684
Validation loss: 3.1828677013356197

Epoch: 5| Step: 3
Training loss: 3.0284440517425537
Validation loss: 3.1819244174547094

Epoch: 5| Step: 4
Training loss: 3.3219616413116455
Validation loss: 3.1778948153218916

Epoch: 5| Step: 5
Training loss: 4.159948348999023
Validation loss: 3.1736227978942213

Epoch: 5| Step: 6
Training loss: 2.964336633682251
Validation loss: 3.1695471091936995

Epoch: 5| Step: 7
Training loss: 3.191193103790283
Validation loss: 3.1646329638778523

Epoch: 5| Step: 8
Training loss: 3.4374499320983887
Validation loss: 3.1608510350668304

Epoch: 5| Step: 9
Training loss: 2.954899311065674
Validation loss: 3.1588756115205827

Epoch: 5| Step: 10
Training loss: 1.8884692192077637
Validation loss: 3.154077714489352

Epoch: 10| Step: 0
Training loss: 2.3966755867004395
Validation loss: 3.149974533306655

Epoch: 5| Step: 1
Training loss: 2.6148576736450195
Validation loss: 3.146690350706859

Epoch: 5| Step: 2
Training loss: 3.5980000495910645
Validation loss: 3.1422005161162345

Epoch: 5| Step: 3
Training loss: 3.352743148803711
Validation loss: 3.139769697702059

Epoch: 5| Step: 4
Training loss: 2.602043628692627
Validation loss: 3.1373304679829586

Epoch: 5| Step: 5
Training loss: 3.2463154792785645
Validation loss: 3.1311160236276607

Epoch: 5| Step: 6
Training loss: 3.4845738410949707
Validation loss: 3.1286406875938497

Epoch: 5| Step: 7
Training loss: 3.392970323562622
Validation loss: 3.125043794672976

Epoch: 5| Step: 8
Training loss: 3.7031216621398926
Validation loss: 3.1196836245957242

Epoch: 5| Step: 9
Training loss: 3.319305419921875
Validation loss: 3.1145680642897084

Epoch: 5| Step: 10
Training loss: 2.7922303676605225
Validation loss: 3.110218583896596

Epoch: 11| Step: 0
Training loss: 3.4453556537628174
Validation loss: 3.1050666147662747

Epoch: 5| Step: 1
Training loss: 2.9666454792022705
Validation loss: 3.099274666078629

Epoch: 5| Step: 2
Training loss: 3.123488664627075
Validation loss: 3.0986247421592794

Epoch: 5| Step: 3
Training loss: 4.053837776184082
Validation loss: 3.0928498083545315

Epoch: 5| Step: 4
Training loss: 2.5376973152160645
Validation loss: 3.089349159630396

Epoch: 5| Step: 5
Training loss: 2.6285011768341064
Validation loss: 3.0818567070909726

Epoch: 5| Step: 6
Training loss: 3.058856248855591
Validation loss: 3.0751928334595053

Epoch: 5| Step: 7
Training loss: 3.7759766578674316
Validation loss: 3.075839155463762

Epoch: 5| Step: 8
Training loss: 2.9715054035186768
Validation loss: 3.0690614818244852

Epoch: 5| Step: 9
Training loss: 2.7998738288879395
Validation loss: 3.063183584520894

Epoch: 5| Step: 10
Training loss: 2.7453181743621826
Validation loss: 3.0591749145138647

Epoch: 12| Step: 0
Training loss: 2.9368033409118652
Validation loss: 3.0524502518356487

Epoch: 5| Step: 1
Training loss: 2.4268860816955566
Validation loss: 3.0428246554508003

Epoch: 5| Step: 2
Training loss: 3.5648467540740967
Validation loss: 3.040928715018816

Epoch: 5| Step: 3
Training loss: 2.8897762298583984
Validation loss: 3.038628098785236

Epoch: 5| Step: 4
Training loss: 4.03678035736084
Validation loss: 3.0303696483694096

Epoch: 5| Step: 5
Training loss: 3.0349934101104736
Validation loss: 3.0276394044199297

Epoch: 5| Step: 6
Training loss: 2.439124345779419
Validation loss: 3.021038378438642

Epoch: 5| Step: 7
Training loss: 3.487659454345703
Validation loss: 3.016671960071851

Epoch: 5| Step: 8
Training loss: 2.376145839691162
Validation loss: 3.01100468379195

Epoch: 5| Step: 9
Training loss: 3.1817545890808105
Validation loss: 3.003699694910357

Epoch: 5| Step: 10
Training loss: 3.4015297889709473
Validation loss: 3.0001905656629995

Epoch: 13| Step: 0
Training loss: 2.182147979736328
Validation loss: 2.9921364912422757

Epoch: 5| Step: 1
Training loss: 2.68607234954834
Validation loss: 2.9909404272674234

Epoch: 5| Step: 2
Training loss: 2.9001147747039795
Validation loss: 2.9807273418672624

Epoch: 5| Step: 3
Training loss: 3.7171473503112793
Validation loss: 2.9787224825992378

Epoch: 5| Step: 4
Training loss: 2.790684223175049
Validation loss: 2.9694586594899497

Epoch: 5| Step: 5
Training loss: 3.3703532218933105
Validation loss: 2.9655328412209787

Epoch: 5| Step: 6
Training loss: 3.432720184326172
Validation loss: 2.9582706728289203

Epoch: 5| Step: 7
Training loss: 2.9480252265930176
Validation loss: 2.950771403569047

Epoch: 5| Step: 8
Training loss: 3.7131245136260986
Validation loss: 2.945042012840189

Epoch: 5| Step: 9
Training loss: 2.4175429344177246
Validation loss: 2.9390868448442027

Epoch: 5| Step: 10
Training loss: 3.1074581146240234
Validation loss: 2.9305012226104736

Epoch: 14| Step: 0
Training loss: 3.1349151134490967
Validation loss: 2.922450896232359

Epoch: 5| Step: 1
Training loss: 3.0744121074676514
Validation loss: 2.9247791049300984

Epoch: 5| Step: 2
Training loss: 2.5063343048095703
Validation loss: 2.9161216699948875

Epoch: 5| Step: 3
Training loss: 2.971524715423584
Validation loss: 2.909782632704704

Epoch: 5| Step: 4
Training loss: 3.2365851402282715
Validation loss: 2.903906686331636

Epoch: 5| Step: 5
Training loss: 2.7818362712860107
Validation loss: 2.893364949892926

Epoch: 5| Step: 6
Training loss: 3.474924087524414
Validation loss: 2.8893534162993073

Epoch: 5| Step: 7
Training loss: 3.007750988006592
Validation loss: 2.8806894620259604

Epoch: 5| Step: 8
Training loss: 3.0142087936401367
Validation loss: 2.877432320707588

Epoch: 5| Step: 9
Training loss: 2.9160125255584717
Validation loss: 2.8683759525258052

Epoch: 5| Step: 10
Training loss: 2.5632898807525635
Validation loss: 2.865801085707962

Epoch: 15| Step: 0
Training loss: 2.9761931896209717
Validation loss: 2.8591062945704304

Epoch: 5| Step: 1
Training loss: 3.402182102203369
Validation loss: 2.84994408135773

Epoch: 5| Step: 2
Training loss: 2.778456211090088
Validation loss: 2.8451850645003782

Epoch: 5| Step: 3
Training loss: 2.5831189155578613
Validation loss: 2.838891185739989

Epoch: 5| Step: 4
Training loss: 2.64729380607605
Validation loss: 2.833042093502578

Epoch: 5| Step: 5
Training loss: 3.1125588417053223
Validation loss: 2.823920921612811

Epoch: 5| Step: 6
Training loss: 3.188261032104492
Validation loss: 2.8189107705188055

Epoch: 5| Step: 7
Training loss: 3.045469284057617
Validation loss: 2.808280198804794

Epoch: 5| Step: 8
Training loss: 3.077897548675537
Validation loss: 2.8006969805686706

Epoch: 5| Step: 9
Training loss: 2.7950782775878906
Validation loss: 2.796988328297933

Epoch: 5| Step: 10
Training loss: 2.5603508949279785
Validation loss: 2.787942432588147

Epoch: 16| Step: 0
Training loss: 3.000861644744873
Validation loss: 2.780475021690451

Epoch: 5| Step: 1
Training loss: 2.6948764324188232
Validation loss: 2.7734112662653767

Epoch: 5| Step: 2
Training loss: 3.2561516761779785
Validation loss: 2.7668544553941294

Epoch: 5| Step: 3
Training loss: 2.5466055870056152
Validation loss: 2.757782538731893

Epoch: 5| Step: 4
Training loss: 2.2196667194366455
Validation loss: 2.7484282396172963

Epoch: 5| Step: 5
Training loss: 3.545386552810669
Validation loss: 2.7374392940152075

Epoch: 5| Step: 6
Training loss: 4.162998199462891
Validation loss: 2.7270281237940632

Epoch: 5| Step: 7
Training loss: 2.4010379314422607
Validation loss: 2.722830392981088

Epoch: 5| Step: 8
Training loss: 2.5539193153381348
Validation loss: 2.7032753344505065

Epoch: 5| Step: 9
Training loss: 2.1920814514160156
Validation loss: 2.7023231393547467

Epoch: 5| Step: 10
Training loss: 3.0495877265930176
Validation loss: 2.693929849132415

Epoch: 17| Step: 0
Training loss: 2.5770976543426514
Validation loss: 2.6833988338388424

Epoch: 5| Step: 1
Training loss: 3.1689841747283936
Validation loss: 2.6730428177823304

Epoch: 5| Step: 2
Training loss: 3.202552080154419
Validation loss: 2.664774748586839

Epoch: 5| Step: 3
Training loss: 2.8685243129730225
Validation loss: 2.6561034135921027

Epoch: 5| Step: 4
Training loss: 2.281106948852539
Validation loss: 2.6440931212517524

Epoch: 5| Step: 5
Training loss: 2.855107069015503
Validation loss: 2.6330473756277435

Epoch: 5| Step: 6
Training loss: 2.8133342266082764
Validation loss: 2.6280837264112247

Epoch: 5| Step: 7
Training loss: 3.800837755203247
Validation loss: 2.616680201663766

Epoch: 5| Step: 8
Training loss: 2.722852945327759
Validation loss: 2.600752807432605

Epoch: 5| Step: 9
Training loss: 2.150435209274292
Validation loss: 2.593260875312231

Epoch: 5| Step: 10
Training loss: 2.373385190963745
Validation loss: 2.586303029009091

Epoch: 18| Step: 0
Training loss: 2.87389874458313
Validation loss: 2.5707189318954304

Epoch: 5| Step: 1
Training loss: 3.07893705368042
Validation loss: 2.559673692590447

Epoch: 5| Step: 2
Training loss: 2.1267244815826416
Validation loss: 2.546190283631766

Epoch: 5| Step: 3
Training loss: 2.7690963745117188
Validation loss: 2.537151792997955

Epoch: 5| Step: 4
Training loss: 2.3798491954803467
Validation loss: 2.531000344983993

Epoch: 5| Step: 5
Training loss: 2.8056113719940186
Validation loss: 2.5254355989476687

Epoch: 5| Step: 6
Training loss: 3.7126033306121826
Validation loss: 2.5131266501642044

Epoch: 5| Step: 7
Training loss: 2.5207619667053223
Validation loss: 2.507722125258497

Epoch: 5| Step: 8
Training loss: 2.6930739879608154
Validation loss: 2.495499218663862

Epoch: 5| Step: 9
Training loss: 2.693284749984741
Validation loss: 2.4757525203048543

Epoch: 5| Step: 10
Training loss: 2.3639631271362305
Validation loss: 2.4748869147351993

Epoch: 19| Step: 0
Training loss: 3.06667423248291
Validation loss: 2.4496173128004997

Epoch: 5| Step: 1
Training loss: 2.1490988731384277
Validation loss: 2.4518777478125786

Epoch: 5| Step: 2
Training loss: 2.653961658477783
Validation loss: 2.442935218093216

Epoch: 5| Step: 3
Training loss: 2.8176417350769043
Validation loss: 2.4329284032185874

Epoch: 5| Step: 4
Training loss: 2.340208053588867
Validation loss: 2.41742108714196

Epoch: 5| Step: 5
Training loss: 2.2587227821350098
Validation loss: 2.4172914617805072

Epoch: 5| Step: 6
Training loss: 3.0702357292175293
Validation loss: 2.405082970537165

Epoch: 5| Step: 7
Training loss: 2.404888153076172
Validation loss: 2.393522142082132

Epoch: 5| Step: 8
Training loss: 2.556075096130371
Validation loss: 2.387688280433737

Epoch: 5| Step: 9
Training loss: 3.14243221282959
Validation loss: 2.3845254913453133

Epoch: 5| Step: 10
Training loss: 2.8386170864105225
Validation loss: 2.36184290916689

Epoch: 20| Step: 0
Training loss: 2.3954274654388428
Validation loss: 2.3522869694617485

Epoch: 5| Step: 1
Training loss: 2.980332851409912
Validation loss: 2.333350976308187

Epoch: 5| Step: 2
Training loss: 2.2875871658325195
Validation loss: 2.3321354876282396

Epoch: 5| Step: 3
Training loss: 2.7288060188293457
Validation loss: 2.320728781402752

Epoch: 5| Step: 4
Training loss: 2.7289607524871826
Validation loss: 2.313974170274632

Epoch: 5| Step: 5
Training loss: 3.1079940795898438
Validation loss: 2.2985390950274724

Epoch: 5| Step: 6
Training loss: 2.2071704864501953
Validation loss: 2.2993622236354376

Epoch: 5| Step: 7
Training loss: 2.747232437133789
Validation loss: 2.2890573855369323

Epoch: 5| Step: 8
Training loss: 2.6650569438934326
Validation loss: 2.2658793618602138

Epoch: 5| Step: 9
Training loss: 2.516862154006958
Validation loss: 2.257497734920953

Epoch: 5| Step: 10
Training loss: 2.1413707733154297
Validation loss: 2.2521867700802383

Epoch: 21| Step: 0
Training loss: 2.746474027633667
Validation loss: 2.2445144217501403

Epoch: 5| Step: 1
Training loss: 2.1461081504821777
Validation loss: 2.2366812024065243

Epoch: 5| Step: 2
Training loss: 2.8017499446868896
Validation loss: 2.2203933244110434

Epoch: 5| Step: 3
Training loss: 2.9767448902130127
Validation loss: 2.2207407284808416

Epoch: 5| Step: 4
Training loss: 2.763324499130249
Validation loss: 2.210447367801461

Epoch: 5| Step: 5
Training loss: 2.8122341632843018
Validation loss: 2.2025651290852535

Epoch: 5| Step: 6
Training loss: 2.4189298152923584
Validation loss: 2.192203774247118

Epoch: 5| Step: 7
Training loss: 2.73776912689209
Validation loss: 2.1763227344841085

Epoch: 5| Step: 8
Training loss: 2.552253246307373
Validation loss: 2.1764874176312516

Epoch: 5| Step: 9
Training loss: 2.1196823120117188
Validation loss: 2.177654844458385

Epoch: 5| Step: 10
Training loss: 1.5053468942642212
Validation loss: 2.170357293980096

Epoch: 22| Step: 0
Training loss: 2.6516342163085938
Validation loss: 2.1620619399573213

Epoch: 5| Step: 1
Training loss: 2.3421566486358643
Validation loss: 2.1385169734237013

Epoch: 5| Step: 2
Training loss: 2.109180212020874
Validation loss: 2.134325183847899

Epoch: 5| Step: 3
Training loss: 2.4112095832824707
Validation loss: 2.1484286246761197

Epoch: 5| Step: 4
Training loss: 2.3382017612457275
Validation loss: 2.142655711020193

Epoch: 5| Step: 5
Training loss: 2.7446608543395996
Validation loss: 2.1370165476235012

Epoch: 5| Step: 6
Training loss: 2.851876974105835
Validation loss: 2.1138948753315914

Epoch: 5| Step: 7
Training loss: 2.214047908782959
Validation loss: 2.129186749458313

Epoch: 5| Step: 8
Training loss: 2.273421049118042
Validation loss: 2.12294961303793

Epoch: 5| Step: 9
Training loss: 2.6073012351989746
Validation loss: 2.104175776563665

Epoch: 5| Step: 10
Training loss: 2.598823308944702
Validation loss: 2.1090745028629097

Epoch: 23| Step: 0
Training loss: 2.6150176525115967
Validation loss: 2.110361815780722

Epoch: 5| Step: 1
Training loss: 2.4798927307128906
Validation loss: 2.097768883551321

Epoch: 5| Step: 2
Training loss: 2.5776939392089844
Validation loss: 2.099247040287141

Epoch: 5| Step: 3
Training loss: 2.6830852031707764
Validation loss: 2.0977384736461024

Epoch: 5| Step: 4
Training loss: 2.8406453132629395
Validation loss: 2.1015461644818707

Epoch: 5| Step: 5
Training loss: 2.6004223823547363
Validation loss: 2.0974017676486763

Epoch: 5| Step: 6
Training loss: 1.8822405338287354
Validation loss: 2.079997096010434

Epoch: 5| Step: 7
Training loss: 1.9383471012115479
Validation loss: 2.061507192991113

Epoch: 5| Step: 8
Training loss: 2.2673027515411377
Validation loss: 2.0721943557903333

Epoch: 5| Step: 9
Training loss: 2.500112771987915
Validation loss: 2.0666426240756945

Epoch: 5| Step: 10
Training loss: 2.435361862182617
Validation loss: 2.0802734974891908

Epoch: 24| Step: 0
Training loss: 2.591017484664917
Validation loss: 2.0720053129298712

Epoch: 5| Step: 1
Training loss: 2.385401487350464
Validation loss: 2.0710929004094933

Epoch: 5| Step: 2
Training loss: 2.9911575317382812
Validation loss: 2.0579634520315353

Epoch: 5| Step: 3
Training loss: 2.118053674697876
Validation loss: 2.0585349400838218

Epoch: 5| Step: 4
Training loss: 1.767735242843628
Validation loss: 2.061863286520845

Epoch: 5| Step: 5
Training loss: 2.348358154296875
Validation loss: 2.0478255697475967

Epoch: 5| Step: 6
Training loss: 2.240227460861206
Validation loss: 2.039178813657453

Epoch: 5| Step: 7
Training loss: 2.2479147911071777
Validation loss: 2.0506091797223656

Epoch: 5| Step: 8
Training loss: 2.583448886871338
Validation loss: 2.0530791641563497

Epoch: 5| Step: 9
Training loss: 2.9457428455352783
Validation loss: 2.033198029764237

Epoch: 5| Step: 10
Training loss: 2.549661636352539
Validation loss: 2.0479375290614303

Epoch: 25| Step: 0
Training loss: 2.1756861209869385
Validation loss: 2.037803050010435

Epoch: 5| Step: 1
Training loss: 2.778303623199463
Validation loss: 2.033739197638727

Epoch: 5| Step: 2
Training loss: 2.6489574909210205
Validation loss: 2.0386446240127727

Epoch: 5| Step: 3
Training loss: 2.5608391761779785
Validation loss: 2.0439760146602506

Epoch: 5| Step: 4
Training loss: 2.0333850383758545
Validation loss: 2.0352484667172996

Epoch: 5| Step: 5
Training loss: 2.1703288555145264
Validation loss: 2.0357961923845354

Epoch: 5| Step: 6
Training loss: 2.3714261054992676
Validation loss: 2.0260998100362797

Epoch: 5| Step: 7
Training loss: 1.592527151107788
Validation loss: 2.0387475413660847

Epoch: 5| Step: 8
Training loss: 3.5971367359161377
Validation loss: 2.0452812974170973

Epoch: 5| Step: 9
Training loss: 2.4206156730651855
Validation loss: 2.0436167896434827

Epoch: 5| Step: 10
Training loss: 2.327545642852783
Validation loss: 2.049468860831312

Epoch: 26| Step: 0
Training loss: 2.226989507675171
Validation loss: 2.047920819251768

Epoch: 5| Step: 1
Training loss: 2.4099771976470947
Validation loss: 2.0162145706915084

Epoch: 5| Step: 2
Training loss: 2.5482826232910156
Validation loss: 2.032148197133054

Epoch: 5| Step: 3
Training loss: 2.859501838684082
Validation loss: 2.0305981328410487

Epoch: 5| Step: 4
Training loss: 2.294698715209961
Validation loss: 2.0378722067802184

Epoch: 5| Step: 5
Training loss: 1.8690738677978516
Validation loss: 2.0433543600061888

Epoch: 5| Step: 6
Training loss: 2.7191689014434814
Validation loss: 2.047459865129122

Epoch: 5| Step: 7
Training loss: 2.084052085876465
Validation loss: 2.0344818074216127

Epoch: 5| Step: 8
Training loss: 2.912459135055542
Validation loss: 2.0332478041289956

Epoch: 5| Step: 9
Training loss: 2.2518675327301025
Validation loss: 2.0378952616004535

Epoch: 5| Step: 10
Training loss: 2.3610291481018066
Validation loss: 2.0388831195010932

Epoch: 27| Step: 0
Training loss: 2.9902548789978027
Validation loss: 2.046149993455538

Epoch: 5| Step: 1
Training loss: 2.0549724102020264
Validation loss: 2.032492418443003

Epoch: 5| Step: 2
Training loss: 2.541882038116455
Validation loss: 2.035863750724382

Epoch: 5| Step: 3
Training loss: 2.130675792694092
Validation loss: 2.04145077736147

Epoch: 5| Step: 4
Training loss: 1.9287707805633545
Validation loss: 2.0374311823998728

Epoch: 5| Step: 5
Training loss: 2.3509082794189453
Validation loss: 2.0393068187980243

Epoch: 5| Step: 6
Training loss: 2.724205493927002
Validation loss: 2.0555987114547403

Epoch: 5| Step: 7
Training loss: 2.7929394245147705
Validation loss: 2.042936732692103

Epoch: 5| Step: 8
Training loss: 2.1771926879882812
Validation loss: 2.040276422295519

Epoch: 5| Step: 9
Training loss: 2.163735866546631
Validation loss: 2.0502823334868236

Epoch: 5| Step: 10
Training loss: 2.782587766647339
Validation loss: 2.031867583592733

Epoch: 28| Step: 0
Training loss: 2.576404571533203
Validation loss: 2.0355058229097756

Epoch: 5| Step: 1
Training loss: 2.5822157859802246
Validation loss: 2.033331504432104

Epoch: 5| Step: 2
Training loss: 2.0079827308654785
Validation loss: 2.0442214012145996

Epoch: 5| Step: 3
Training loss: 2.405569076538086
Validation loss: 2.046681668168755

Epoch: 5| Step: 4
Training loss: 2.5282375812530518
Validation loss: 2.0562901612251037

Epoch: 5| Step: 5
Training loss: 2.374105453491211
Validation loss: 2.0501529657712547

Epoch: 5| Step: 6
Training loss: 1.7245641946792603
Validation loss: 2.0493770889056626

Epoch: 5| Step: 7
Training loss: 2.1722636222839355
Validation loss: 2.0525823690557994

Epoch: 5| Step: 8
Training loss: 2.3176093101501465
Validation loss: 2.0612634458849506

Epoch: 5| Step: 9
Training loss: 3.0179104804992676
Validation loss: 2.04169495900472

Epoch: 5| Step: 10
Training loss: 2.867276430130005
Validation loss: 2.041275232068954

Epoch: 29| Step: 0
Training loss: 2.4690592288970947
Validation loss: 2.0400222680901967

Epoch: 5| Step: 1
Training loss: 2.1696019172668457
Validation loss: 2.0291392636555496

Epoch: 5| Step: 2
Training loss: 2.655515193939209
Validation loss: 2.032677153105377

Epoch: 5| Step: 3
Training loss: 2.3324873447418213
Validation loss: 2.03445940889338

Epoch: 5| Step: 4
Training loss: 2.3262243270874023
Validation loss: 2.0260238673097346

Epoch: 5| Step: 5
Training loss: 2.771284580230713
Validation loss: 2.0233005336535874

Epoch: 5| Step: 6
Training loss: 2.2888710498809814
Validation loss: 2.0395277610389133

Epoch: 5| Step: 7
Training loss: 2.704723596572876
Validation loss: 2.032032602576799

Epoch: 5| Step: 8
Training loss: 1.72454833984375
Validation loss: 2.04022479057312

Epoch: 5| Step: 9
Training loss: 2.8499186038970947
Validation loss: 2.040004822515672

Epoch: 5| Step: 10
Training loss: 2.192913055419922
Validation loss: 2.0356371505286104

Epoch: 30| Step: 0
Training loss: 2.264751434326172
Validation loss: 2.0364282592650382

Epoch: 5| Step: 1
Training loss: 2.8059780597686768
Validation loss: 2.0420087293912004

Epoch: 5| Step: 2
Training loss: 2.4275705814361572
Validation loss: 2.0343272109185495

Epoch: 5| Step: 3
Training loss: 2.0586960315704346
Validation loss: 2.0324961587946904

Epoch: 5| Step: 4
Training loss: 2.4163970947265625
Validation loss: 2.0279805147519676

Epoch: 5| Step: 5
Training loss: 2.329315423965454
Validation loss: 2.0429414856818413

Epoch: 5| Step: 6
Training loss: 2.801238536834717
Validation loss: 2.0277774923591205

Epoch: 5| Step: 7
Training loss: 2.573707103729248
Validation loss: 2.0301534052818053

Epoch: 5| Step: 8
Training loss: 2.162682294845581
Validation loss: 2.021768646855508

Epoch: 5| Step: 9
Training loss: 2.3994736671447754
Validation loss: 2.0278300675012733

Epoch: 5| Step: 10
Training loss: 2.0127646923065186
Validation loss: 2.0322604871565297

Epoch: 31| Step: 0
Training loss: 2.1342453956604004
Validation loss: 2.0245201664586223

Epoch: 5| Step: 1
Training loss: 1.9476401805877686
Validation loss: 2.050607063437021

Epoch: 5| Step: 2
Training loss: 2.3132128715515137
Validation loss: 2.028673537315861

Epoch: 5| Step: 3
Training loss: 2.2355284690856934
Validation loss: 2.036588707277852

Epoch: 5| Step: 4
Training loss: 2.4100348949432373
Validation loss: 2.048713573845484

Epoch: 5| Step: 5
Training loss: 1.9179054498672485
Validation loss: 2.0443398119300924

Epoch: 5| Step: 6
Training loss: 3.0146117210388184
Validation loss: 2.028452947575559

Epoch: 5| Step: 7
Training loss: 2.457390546798706
Validation loss: 2.0138976676489717

Epoch: 5| Step: 8
Training loss: 2.2223734855651855
Validation loss: 2.023042801887758

Epoch: 5| Step: 9
Training loss: 2.702465772628784
Validation loss: 2.037500632706509

Epoch: 5| Step: 10
Training loss: 3.03349232673645
Validation loss: 2.0380038702359764

Epoch: 32| Step: 0
Training loss: 2.620298385620117
Validation loss: 2.0402627324545257

Epoch: 5| Step: 1
Training loss: 2.2754130363464355
Validation loss: 2.0417262456750356

Epoch: 5| Step: 2
Training loss: 2.5865392684936523
Validation loss: 2.0414129277711273

Epoch: 5| Step: 3
Training loss: 1.992936372756958
Validation loss: 2.0354117155075073

Epoch: 5| Step: 4
Training loss: 2.1132891178131104
Validation loss: 2.018361596650975

Epoch: 5| Step: 5
Training loss: 2.0237338542938232
Validation loss: 2.050034676828692

Epoch: 5| Step: 6
Training loss: 2.497530460357666
Validation loss: 2.036280455127839

Epoch: 5| Step: 7
Training loss: 2.7197160720825195
Validation loss: 2.0464800891055854

Epoch: 5| Step: 8
Training loss: 2.5100181102752686
Validation loss: 2.037065577763383

Epoch: 5| Step: 9
Training loss: 2.309741973876953
Validation loss: 2.027571967853013

Epoch: 5| Step: 10
Training loss: 2.692673444747925
Validation loss: 2.023812088915097

Epoch: 33| Step: 0
Training loss: 2.473287582397461
Validation loss: 2.0426763283309115

Epoch: 5| Step: 1
Training loss: 2.4905552864074707
Validation loss: 2.0292206220729376

Epoch: 5| Step: 2
Training loss: 2.5270111560821533
Validation loss: 2.0433261830319642

Epoch: 5| Step: 3
Training loss: 1.976055383682251
Validation loss: 2.028166227443244

Epoch: 5| Step: 4
Training loss: 1.7336511611938477
Validation loss: 2.027066200010238

Epoch: 5| Step: 5
Training loss: 2.459486722946167
Validation loss: 2.023271127413678

Epoch: 5| Step: 6
Training loss: 2.35542631149292
Validation loss: 2.0227338626820552

Epoch: 5| Step: 7
Training loss: 2.382434129714966
Validation loss: 2.0314150676932385

Epoch: 5| Step: 8
Training loss: 2.589988946914673
Validation loss: 2.027637476562172

Epoch: 5| Step: 9
Training loss: 2.3868908882141113
Validation loss: 2.0084325728877896

Epoch: 5| Step: 10
Training loss: 3.054535150527954
Validation loss: 2.031828390654697

Epoch: 34| Step: 0
Training loss: 2.226785659790039
Validation loss: 2.0254082846385177

Epoch: 5| Step: 1
Training loss: 2.821887493133545
Validation loss: 2.030778887451336

Epoch: 5| Step: 2
Training loss: 2.093806266784668
Validation loss: 2.0263389284892748

Epoch: 5| Step: 3
Training loss: 2.829134702682495
Validation loss: 2.023688144581292

Epoch: 5| Step: 4
Training loss: 2.543971061706543
Validation loss: 1.9973278148199922

Epoch: 5| Step: 5
Training loss: 1.7870384454727173
Validation loss: 2.0202566269905335

Epoch: 5| Step: 6
Training loss: 2.768364191055298
Validation loss: 2.03890331586202

Epoch: 5| Step: 7
Training loss: 2.58063006401062
Validation loss: 2.0306033998407345

Epoch: 5| Step: 8
Training loss: 1.9523303508758545
Validation loss: 2.0152462156870032

Epoch: 5| Step: 9
Training loss: 2.579298734664917
Validation loss: 2.0095100095195155

Epoch: 5| Step: 10
Training loss: 1.9270306825637817
Validation loss: 2.024209307086083

Epoch: 35| Step: 0
Training loss: 2.5964713096618652
Validation loss: 2.0375595118409846

Epoch: 5| Step: 1
Training loss: 2.342219829559326
Validation loss: 2.0231483931182535

Epoch: 5| Step: 2
Training loss: 2.1093289852142334
Validation loss: 2.017258649231285

Epoch: 5| Step: 3
Training loss: 1.8380016088485718
Validation loss: 2.0191598130810644

Epoch: 5| Step: 4
Training loss: 2.817782402038574
Validation loss: 2.0262906987179994

Epoch: 5| Step: 5
Training loss: 2.492680072784424
Validation loss: 2.0341880231775264

Epoch: 5| Step: 6
Training loss: 2.5760180950164795
Validation loss: 2.0081531898949736

Epoch: 5| Step: 7
Training loss: 2.2132797241210938
Validation loss: 2.0252387164741434

Epoch: 5| Step: 8
Training loss: 2.35630202293396
Validation loss: 2.0162091588461273

Epoch: 5| Step: 9
Training loss: 2.3504087924957275
Validation loss: 2.011383984678535

Epoch: 5| Step: 10
Training loss: 2.451913833618164
Validation loss: 2.0298701268370434

Epoch: 36| Step: 0
Training loss: 2.4800238609313965
Validation loss: 2.019715739834693

Epoch: 5| Step: 1
Training loss: 2.120007038116455
Validation loss: 2.0269520616018646

Epoch: 5| Step: 2
Training loss: 2.1862432956695557
Validation loss: 2.0380362977263746

Epoch: 5| Step: 3
Training loss: 2.510659694671631
Validation loss: 2.0159997863154255

Epoch: 5| Step: 4
Training loss: 2.1966772079467773
Validation loss: 2.011719040973212

Epoch: 5| Step: 5
Training loss: 2.469118595123291
Validation loss: 2.0147773168420278

Epoch: 5| Step: 6
Training loss: 2.6397109031677246
Validation loss: 2.0012861015976116

Epoch: 5| Step: 7
Training loss: 2.5371439456939697
Validation loss: 2.035122027961157

Epoch: 5| Step: 8
Training loss: 1.9949795007705688
Validation loss: 2.0179817394543718

Epoch: 5| Step: 9
Training loss: 2.3894333839416504
Validation loss: 2.0151190168114117

Epoch: 5| Step: 10
Training loss: 2.6653316020965576
Validation loss: 2.0092747365274737

Epoch: 37| Step: 0
Training loss: 1.7554740905761719
Validation loss: 2.016905294951572

Epoch: 5| Step: 1
Training loss: 2.3505780696868896
Validation loss: 2.0069868538969304

Epoch: 5| Step: 2
Training loss: 1.7815158367156982
Validation loss: 2.001004353646309

Epoch: 5| Step: 3
Training loss: 2.1679275035858154
Validation loss: 2.004141593492159

Epoch: 5| Step: 4
Training loss: 2.5526061058044434
Validation loss: 2.0134600747016167

Epoch: 5| Step: 5
Training loss: 2.061485528945923
Validation loss: 1.9995189379620295

Epoch: 5| Step: 6
Training loss: 2.63091778755188
Validation loss: 2.0147843540355725

Epoch: 5| Step: 7
Training loss: 2.6688642501831055
Validation loss: 2.0055172584390126

Epoch: 5| Step: 8
Training loss: 2.6743102073669434
Validation loss: 1.987851760720694

Epoch: 5| Step: 9
Training loss: 2.585838556289673
Validation loss: 2.001222966819681

Epoch: 5| Step: 10
Training loss: 2.8888792991638184
Validation loss: 2.014818984975097

Epoch: 38| Step: 0
Training loss: 2.403714895248413
Validation loss: 2.026684081682595

Epoch: 5| Step: 1
Training loss: 2.4533398151397705
Validation loss: 2.014719755418839

Epoch: 5| Step: 2
Training loss: 1.9955570697784424
Validation loss: 2.008313350780036

Epoch: 5| Step: 3
Training loss: 2.3234755992889404
Validation loss: 2.0103074632665163

Epoch: 5| Step: 4
Training loss: 2.1090707778930664
Validation loss: 2.0166860254861976

Epoch: 5| Step: 5
Training loss: 2.2422070503234863
Validation loss: 2.0083446566776564

Epoch: 5| Step: 6
Training loss: 2.157808780670166
Validation loss: 2.0075012919723347

Epoch: 5| Step: 7
Training loss: 2.1823971271514893
Validation loss: 2.0288402149754186

Epoch: 5| Step: 8
Training loss: 2.758571147918701
Validation loss: 2.020539012006534

Epoch: 5| Step: 9
Training loss: 2.4554076194763184
Validation loss: 2.021634372331763

Epoch: 5| Step: 10
Training loss: 3.080878496170044
Validation loss: 2.0329606635596162

Epoch: 39| Step: 0
Training loss: 2.749314308166504
Validation loss: 1.9994944551939606

Epoch: 5| Step: 1
Training loss: 2.6238503456115723
Validation loss: 2.01728142205105

Epoch: 5| Step: 2
Training loss: 2.4168381690979004
Validation loss: 2.0258964953884

Epoch: 5| Step: 3
Training loss: 1.7104002237319946
Validation loss: 2.017542810850246

Epoch: 5| Step: 4
Training loss: 2.9856035709381104
Validation loss: 2.018615681638

Epoch: 5| Step: 5
Training loss: 2.3206310272216797
Validation loss: 2.0340745936157885

Epoch: 5| Step: 6
Training loss: 2.018014907836914
Validation loss: 2.0336535156414075

Epoch: 5| Step: 7
Training loss: 2.331865072250366
Validation loss: 2.030467361532232

Epoch: 5| Step: 8
Training loss: 2.2997817993164062
Validation loss: 2.0203860498243764

Epoch: 5| Step: 9
Training loss: 2.4925801753997803
Validation loss: 2.007580505904331

Epoch: 5| Step: 10
Training loss: 2.065458297729492
Validation loss: 2.0234703684365876

Epoch: 40| Step: 0
Training loss: 2.1508190631866455
Validation loss: 2.031903689907443

Epoch: 5| Step: 1
Training loss: 2.3129165172576904
Validation loss: 2.015016817277478

Epoch: 5| Step: 2
Training loss: 2.5623748302459717
Validation loss: 2.017779293880668

Epoch: 5| Step: 3
Training loss: 2.3308839797973633
Validation loss: 2.008549551809988

Epoch: 5| Step: 4
Training loss: 2.6776180267333984
Validation loss: 2.0259669109057357

Epoch: 5| Step: 5
Training loss: 2.2981643676757812
Validation loss: 2.0330681147113925

Epoch: 5| Step: 6
Training loss: 1.8132919073104858
Validation loss: 2.025210952246061

Epoch: 5| Step: 7
Training loss: 2.2008583545684814
Validation loss: 2.0203516252579226

Epoch: 5| Step: 8
Training loss: 2.4111227989196777
Validation loss: 2.023196651089576

Epoch: 5| Step: 9
Training loss: 2.6444263458251953
Validation loss: 2.0316915819721837

Epoch: 5| Step: 10
Training loss: 2.6616265773773193
Validation loss: 2.0108634694930045

Epoch: 41| Step: 0
Training loss: 2.153463363647461
Validation loss: 2.0207419433901386

Epoch: 5| Step: 1
Training loss: 2.4988255500793457
Validation loss: 2.00714470237814

Epoch: 5| Step: 2
Training loss: 3.1930928230285645
Validation loss: 2.014069302107698

Epoch: 5| Step: 3
Training loss: 1.6333940029144287
Validation loss: 2.021323230958754

Epoch: 5| Step: 4
Training loss: 2.35482120513916
Validation loss: 2.0115765320357455

Epoch: 5| Step: 5
Training loss: 2.3197546005249023
Validation loss: 2.01074360006599

Epoch: 5| Step: 6
Training loss: 2.730936050415039
Validation loss: 2.0039764001805294

Epoch: 5| Step: 7
Training loss: 2.4571380615234375
Validation loss: 2.029486484425042

Epoch: 5| Step: 8
Training loss: 2.2593371868133545
Validation loss: 2.016882529822729

Epoch: 5| Step: 9
Training loss: 2.178879499435425
Validation loss: 2.005744759754468

Epoch: 5| Step: 10
Training loss: 2.148409605026245
Validation loss: 2.000752252917136

Epoch: 42| Step: 0
Training loss: 2.103602886199951
Validation loss: 2.0117968000391477

Epoch: 5| Step: 1
Training loss: 2.5316193103790283
Validation loss: 2.0079767524555163

Epoch: 5| Step: 2
Training loss: 2.5659708976745605
Validation loss: 1.984995795834449

Epoch: 5| Step: 3
Training loss: 2.0112528800964355
Validation loss: 1.9926163278600222

Epoch: 5| Step: 4
Training loss: 2.3204851150512695
Validation loss: 1.9974940361515168

Epoch: 5| Step: 5
Training loss: 2.097160816192627
Validation loss: 1.9843735271884548

Epoch: 5| Step: 6
Training loss: 2.6411025524139404
Validation loss: 2.0055363614072084

Epoch: 5| Step: 7
Training loss: 2.6639134883880615
Validation loss: 2.0139236706559376

Epoch: 5| Step: 8
Training loss: 2.5071310997009277
Validation loss: 2.0080725531424246

Epoch: 5| Step: 9
Training loss: 2.2132728099823
Validation loss: 1.9987502610811623

Epoch: 5| Step: 10
Training loss: 2.217250347137451
Validation loss: 2.0094723675840642

Epoch: 43| Step: 0
Training loss: 1.980543851852417
Validation loss: 2.0036468031585857

Epoch: 5| Step: 1
Training loss: 2.34162974357605
Validation loss: 1.9919397010598132

Epoch: 5| Step: 2
Training loss: 2.047638416290283
Validation loss: 2.006351363274359

Epoch: 5| Step: 3
Training loss: 2.6650402545928955
Validation loss: 2.0027354878763997

Epoch: 5| Step: 4
Training loss: 2.425553798675537
Validation loss: 2.0057111350438928

Epoch: 5| Step: 5
Training loss: 3.0140414237976074
Validation loss: 1.9937340905589442

Epoch: 5| Step: 6
Training loss: 2.9820399284362793
Validation loss: 1.9988389797108148

Epoch: 5| Step: 7
Training loss: 2.719939708709717
Validation loss: 1.9861476831538702

Epoch: 5| Step: 8
Training loss: 1.7561681270599365
Validation loss: 2.012870345064389

Epoch: 5| Step: 9
Training loss: 1.939764380455017
Validation loss: 1.99886485966303

Epoch: 5| Step: 10
Training loss: 1.645463466644287
Validation loss: 2.010119638135356

Epoch: 44| Step: 0
Training loss: 2.2621941566467285
Validation loss: 2.0207659800847373

Epoch: 5| Step: 1
Training loss: 2.149592876434326
Validation loss: 2.01050559166939

Epoch: 5| Step: 2
Training loss: 2.7048888206481934
Validation loss: 2.0104758739471436

Epoch: 5| Step: 3
Training loss: 2.1139330863952637
Validation loss: 2.0090179289540937

Epoch: 5| Step: 4
Training loss: 2.2959201335906982
Validation loss: 2.0171326078394407

Epoch: 5| Step: 5
Training loss: 2.6709790229797363
Validation loss: 2.0046833228039485

Epoch: 5| Step: 6
Training loss: 2.7605233192443848
Validation loss: 2.0136155979607695

Epoch: 5| Step: 7
Training loss: 1.574890375137329
Validation loss: 1.9959265032122213

Epoch: 5| Step: 8
Training loss: 1.9891564846038818
Validation loss: 1.986594255252551

Epoch: 5| Step: 9
Training loss: 2.168470859527588
Validation loss: 2.0091145448787238

Epoch: 5| Step: 10
Training loss: 3.206587791442871
Validation loss: 2.001469591612457

Epoch: 45| Step: 0
Training loss: 2.3345234394073486
Validation loss: 2.0082851148420766

Epoch: 5| Step: 1
Training loss: 1.6721839904785156
Validation loss: 2.0097121756563903

Epoch: 5| Step: 2
Training loss: 2.3231101036071777
Validation loss: 2.0135656890048774

Epoch: 5| Step: 3
Training loss: 2.3320701122283936
Validation loss: 2.0107319713920675

Epoch: 5| Step: 4
Training loss: 2.6256155967712402
Validation loss: 2.014200691253908

Epoch: 5| Step: 5
Training loss: 2.1183602809906006
Validation loss: 2.0052673201407156

Epoch: 5| Step: 6
Training loss: 2.0842864513397217
Validation loss: 2.020710035036969

Epoch: 5| Step: 7
Training loss: 2.4517738819122314
Validation loss: 2.0128946970867854

Epoch: 5| Step: 8
Training loss: 2.4770431518554688
Validation loss: 2.0328417337068947

Epoch: 5| Step: 9
Training loss: 2.851044178009033
Validation loss: 2.017284575329032

Epoch: 5| Step: 10
Training loss: 2.584019899368286
Validation loss: 2.025408003919868

Epoch: 46| Step: 0
Training loss: 2.22479248046875
Validation loss: 2.018166721508067

Epoch: 5| Step: 1
Training loss: 2.673025608062744
Validation loss: 2.008753042067251

Epoch: 5| Step: 2
Training loss: 1.8592087030410767
Validation loss: 2.0098123896506523

Epoch: 5| Step: 3
Training loss: 2.5528125762939453
Validation loss: 2.028821591408022

Epoch: 5| Step: 4
Training loss: 1.3996341228485107
Validation loss: 2.0098125268054265

Epoch: 5| Step: 5
Training loss: 2.782999277114868
Validation loss: 2.008194549109346

Epoch: 5| Step: 6
Training loss: 2.6089205741882324
Validation loss: 2.0177448693142144

Epoch: 5| Step: 7
Training loss: 2.4288172721862793
Validation loss: 2.029992231758692

Epoch: 5| Step: 8
Training loss: 1.9023780822753906
Validation loss: 2.0309124890194146

Epoch: 5| Step: 9
Training loss: 2.4334487915039062
Validation loss: 2.0127015203557987

Epoch: 5| Step: 10
Training loss: 2.9006049633026123
Validation loss: 2.0093558680626655

Epoch: 47| Step: 0
Training loss: 2.310058832168579
Validation loss: 2.037307959730907

Epoch: 5| Step: 1
Training loss: 1.9472401142120361
Validation loss: 2.0347804895011325

Epoch: 5| Step: 2
Training loss: 2.3858532905578613
Validation loss: 2.0233987223717476

Epoch: 5| Step: 3
Training loss: 2.4424214363098145
Validation loss: 2.0215864950610745

Epoch: 5| Step: 4
Training loss: 2.5561530590057373
Validation loss: 2.0113818030203543

Epoch: 5| Step: 5
Training loss: 2.4885687828063965
Validation loss: 2.016209715156145

Epoch: 5| Step: 6
Training loss: 2.515174627304077
Validation loss: 2.0114143022926907

Epoch: 5| Step: 7
Training loss: 2.411097288131714
Validation loss: 2.012654974896421

Epoch: 5| Step: 8
Training loss: 2.2617270946502686
Validation loss: 2.0146770605476956

Epoch: 5| Step: 9
Training loss: 2.775214910507202
Validation loss: 2.0104827932132188

Epoch: 5| Step: 10
Training loss: 1.479262351989746
Validation loss: 2.012389841900077

Epoch: 48| Step: 0
Training loss: 2.4430365562438965
Validation loss: 2.007042060616196

Epoch: 5| Step: 1
Training loss: 2.7188596725463867
Validation loss: 2.004199463834045

Epoch: 5| Step: 2
Training loss: 2.484306812286377
Validation loss: 2.0263892745458953

Epoch: 5| Step: 3
Training loss: 2.178879737854004
Validation loss: 2.011626165400269

Epoch: 5| Step: 4
Training loss: 2.475649118423462
Validation loss: 2.018289953149775

Epoch: 5| Step: 5
Training loss: 2.532888650894165
Validation loss: 2.0108762120687835

Epoch: 5| Step: 6
Training loss: 2.2635040283203125
Validation loss: 2.0139153683057396

Epoch: 5| Step: 7
Training loss: 2.503182888031006
Validation loss: 2.028139944999449

Epoch: 5| Step: 8
Training loss: 1.9509471654891968
Validation loss: 2.009765285317616

Epoch: 5| Step: 9
Training loss: 1.9693152904510498
Validation loss: 2.020177638658913

Epoch: 5| Step: 10
Training loss: 2.2036187648773193
Validation loss: 2.037373940149943

Epoch: 49| Step: 0
Training loss: 2.3962485790252686
Validation loss: 2.0087976019869567

Epoch: 5| Step: 1
Training loss: 1.8312705755233765
Validation loss: 2.013791170171512

Epoch: 5| Step: 2
Training loss: 2.836712598800659
Validation loss: 2.019133278118667

Epoch: 5| Step: 3
Training loss: 2.52752685546875
Validation loss: 2.006360198861809

Epoch: 5| Step: 4
Training loss: 2.1171743869781494
Validation loss: 2.0191315989340506

Epoch: 5| Step: 5
Training loss: 2.244541645050049
Validation loss: 1.9993932311252882

Epoch: 5| Step: 6
Training loss: 2.0927085876464844
Validation loss: 2.001077678895766

Epoch: 5| Step: 7
Training loss: 2.5265610218048096
Validation loss: 2.021528067127351

Epoch: 5| Step: 8
Training loss: 2.0892391204833984
Validation loss: 2.0139110280621435

Epoch: 5| Step: 9
Training loss: 2.7564163208007812
Validation loss: 1.9979722910029913

Epoch: 5| Step: 10
Training loss: 2.266601324081421
Validation loss: 1.9990332652163763

Epoch: 50| Step: 0
Training loss: 2.575451612472534
Validation loss: 2.0044956027820544

Epoch: 5| Step: 1
Training loss: 2.1492416858673096
Validation loss: 2.0006956131227556

Epoch: 5| Step: 2
Training loss: 1.7058982849121094
Validation loss: 2.0160815151788856

Epoch: 5| Step: 3
Training loss: 2.3745906352996826
Validation loss: 2.0116857444086382

Epoch: 5| Step: 4
Training loss: 3.3621273040771484
Validation loss: 1.9941733883273216

Epoch: 5| Step: 5
Training loss: 2.810656785964966
Validation loss: 1.9978023921289751

Epoch: 5| Step: 6
Training loss: 1.5553232431411743
Validation loss: 2.012959045748557

Epoch: 5| Step: 7
Training loss: 2.1470375061035156
Validation loss: 2.016656042427145

Epoch: 5| Step: 8
Training loss: 1.8553597927093506
Validation loss: 2.0072276489709013

Epoch: 5| Step: 9
Training loss: 2.2593307495117188
Validation loss: 2.002546041242538

Epoch: 5| Step: 10
Training loss: 2.805490016937256
Validation loss: 2.0114742684107956

Epoch: 51| Step: 0
Training loss: 1.91592538356781
Validation loss: 2.0035193043370403

Epoch: 5| Step: 1
Training loss: 2.8316383361816406
Validation loss: 2.004099328030822

Epoch: 5| Step: 2
Training loss: 2.572338104248047
Validation loss: 2.02453439722779

Epoch: 5| Step: 3
Training loss: 2.053046703338623
Validation loss: 2.0061500341661516

Epoch: 5| Step: 4
Training loss: 2.2571520805358887
Validation loss: 2.018868147685964

Epoch: 5| Step: 5
Training loss: 2.164900064468384
Validation loss: 2.0003763629544165

Epoch: 5| Step: 6
Training loss: 1.6690762042999268
Validation loss: 2.008853684189499

Epoch: 5| Step: 7
Training loss: 2.6038711071014404
Validation loss: 1.9917477869218396

Epoch: 5| Step: 8
Training loss: 2.385439395904541
Validation loss: 1.9798263785659627

Epoch: 5| Step: 9
Training loss: 3.026454448699951
Validation loss: 1.995724771612434

Epoch: 5| Step: 10
Training loss: 2.128614664077759
Validation loss: 1.9906023522858978

Epoch: 52| Step: 0
Training loss: 2.0601367950439453
Validation loss: 2.00566372307398

Epoch: 5| Step: 1
Training loss: 1.9362242221832275
Validation loss: 1.995714485004384

Epoch: 5| Step: 2
Training loss: 2.179577589035034
Validation loss: 2.0091402325578915

Epoch: 5| Step: 3
Training loss: 2.45643949508667
Validation loss: 2.0227150122324624

Epoch: 5| Step: 4
Training loss: 2.7619237899780273
Validation loss: 1.9957502529185305

Epoch: 5| Step: 5
Training loss: 2.090636730194092
Validation loss: 2.011419368046586

Epoch: 5| Step: 6
Training loss: 1.9235188961029053
Validation loss: 2.0083517054075837

Epoch: 5| Step: 7
Training loss: 2.616870880126953
Validation loss: 1.9977606650321715

Epoch: 5| Step: 8
Training loss: 2.2714638710021973
Validation loss: 1.996122698630056

Epoch: 5| Step: 9
Training loss: 2.887307643890381
Validation loss: 2.0215650822526667

Epoch: 5| Step: 10
Training loss: 2.379361867904663
Validation loss: 1.9929944725446804

Epoch: 53| Step: 0
Training loss: 2.3979172706604004
Validation loss: 1.9816821826401578

Epoch: 5| Step: 1
Training loss: 2.181175708770752
Validation loss: 1.9934753025731733

Epoch: 5| Step: 2
Training loss: 2.595757007598877
Validation loss: 1.9922924733931018

Epoch: 5| Step: 3
Training loss: 2.516207695007324
Validation loss: 2.0030172358277025

Epoch: 5| Step: 4
Training loss: 2.3605308532714844
Validation loss: 2.003313138920774

Epoch: 5| Step: 5
Training loss: 2.3364577293395996
Validation loss: 2.000607777667302

Epoch: 5| Step: 6
Training loss: 1.9894520044326782
Validation loss: 2.0179439103731545

Epoch: 5| Step: 7
Training loss: 2.535231828689575
Validation loss: 2.008074604054933

Epoch: 5| Step: 8
Training loss: 2.347184658050537
Validation loss: 1.9886219552768174

Epoch: 5| Step: 9
Training loss: 2.0576229095458984
Validation loss: 1.9906884931748914

Epoch: 5| Step: 10
Training loss: 2.2320213317871094
Validation loss: 2.0100684653046312

Epoch: 54| Step: 0
Training loss: 2.8129591941833496
Validation loss: 1.9965428947120585

Epoch: 5| Step: 1
Training loss: 2.2372121810913086
Validation loss: 2.0100063457283923

Epoch: 5| Step: 2
Training loss: 2.379626750946045
Validation loss: 2.009325385093689

Epoch: 5| Step: 3
Training loss: 1.559056282043457
Validation loss: 2.0210146724536853

Epoch: 5| Step: 4
Training loss: 2.7357029914855957
Validation loss: 1.999468759823871

Epoch: 5| Step: 5
Training loss: 2.422717332839966
Validation loss: 2.008108769693682

Epoch: 5| Step: 6
Training loss: 1.8769047260284424
Validation loss: 2.011406167860954

Epoch: 5| Step: 7
Training loss: 2.0517094135284424
Validation loss: 2.023674375267439

Epoch: 5| Step: 8
Training loss: 2.5506527423858643
Validation loss: 2.0050117841330906

Epoch: 5| Step: 9
Training loss: 2.695075273513794
Validation loss: 2.026603196256904

Epoch: 5| Step: 10
Training loss: 2.0452613830566406
Validation loss: 2.0392037514717347

Epoch: 55| Step: 0
Training loss: 2.2649569511413574
Validation loss: 2.017759539747751

Epoch: 5| Step: 1
Training loss: 2.8696370124816895
Validation loss: 2.015021374148707

Epoch: 5| Step: 2
Training loss: 2.1640512943267822
Validation loss: 2.019331462921635

Epoch: 5| Step: 3
Training loss: 2.0617988109588623
Validation loss: 1.997723380724589

Epoch: 5| Step: 4
Training loss: 2.1354432106018066
Validation loss: 2.0255295832951865

Epoch: 5| Step: 5
Training loss: 2.147542715072632
Validation loss: 2.0133476616233907

Epoch: 5| Step: 6
Training loss: 2.1174392700195312
Validation loss: 2.0226481140300794

Epoch: 5| Step: 7
Training loss: 2.131728410720825
Validation loss: 2.023291159701604

Epoch: 5| Step: 8
Training loss: 2.063551902770996
Validation loss: 1.9966581995769213

Epoch: 5| Step: 9
Training loss: 2.4961466789245605
Validation loss: 1.9856686053737518

Epoch: 5| Step: 10
Training loss: 3.0557897090911865
Validation loss: 2.0241320081936416

Epoch: 56| Step: 0
Training loss: 2.4176461696624756
Validation loss: 2.0475974980221

Epoch: 5| Step: 1
Training loss: 2.108915328979492
Validation loss: 2.005652425109699

Epoch: 5| Step: 2
Training loss: 1.4202200174331665
Validation loss: 2.0037112569296234

Epoch: 5| Step: 3
Training loss: 2.530878782272339
Validation loss: 2.0033461804031045

Epoch: 5| Step: 4
Training loss: 2.699897050857544
Validation loss: 1.9905040699948546

Epoch: 5| Step: 5
Training loss: 2.3846449851989746
Validation loss: 1.9965558603245726

Epoch: 5| Step: 6
Training loss: 2.4673171043395996
Validation loss: 2.0149617989857993

Epoch: 5| Step: 7
Training loss: 2.827955484390259
Validation loss: 2.0094176287292154

Epoch: 5| Step: 8
Training loss: 2.3906784057617188
Validation loss: 2.003305450562508

Epoch: 5| Step: 9
Training loss: 2.152165174484253
Validation loss: 1.9910032787630636

Epoch: 5| Step: 10
Training loss: 1.8841979503631592
Validation loss: 1.989531901574904

Epoch: 57| Step: 0
Training loss: 2.6830132007598877
Validation loss: 1.9936841226393176

Epoch: 5| Step: 1
Training loss: 2.2998340129852295
Validation loss: 2.008962667116555

Epoch: 5| Step: 2
Training loss: 2.4706854820251465
Validation loss: 2.0006713687732653

Epoch: 5| Step: 3
Training loss: 2.2317070960998535
Validation loss: 1.996667605574413

Epoch: 5| Step: 4
Training loss: 1.7443917989730835
Validation loss: 1.9803867673361173

Epoch: 5| Step: 5
Training loss: 2.137166976928711
Validation loss: 1.9854544362714213

Epoch: 5| Step: 6
Training loss: 2.595048189163208
Validation loss: 1.985810786165217

Epoch: 5| Step: 7
Training loss: 2.376957416534424
Validation loss: 2.0066162052974907

Epoch: 5| Step: 8
Training loss: 2.434959888458252
Validation loss: 1.9858119487762451

Epoch: 5| Step: 9
Training loss: 1.9244426488876343
Validation loss: 2.0139886794551725

Epoch: 5| Step: 10
Training loss: 2.5204687118530273
Validation loss: 1.9874352460266442

Epoch: 58| Step: 0
Training loss: 2.527782440185547
Validation loss: 1.9880250577003724

Epoch: 5| Step: 1
Training loss: 2.2899930477142334
Validation loss: 1.9981660753168085

Epoch: 5| Step: 2
Training loss: 1.8324788808822632
Validation loss: 1.9729557447536017

Epoch: 5| Step: 3
Training loss: 2.398092746734619
Validation loss: 1.9910086072901243

Epoch: 5| Step: 4
Training loss: 1.7914377450942993
Validation loss: 1.997835764320948

Epoch: 5| Step: 5
Training loss: 2.701962947845459
Validation loss: 1.9944779629348426

Epoch: 5| Step: 6
Training loss: 2.151167392730713
Validation loss: 1.986780560144814

Epoch: 5| Step: 7
Training loss: 1.9646717309951782
Validation loss: 1.972148109507817

Epoch: 5| Step: 8
Training loss: 2.346339702606201
Validation loss: 1.987188131578507

Epoch: 5| Step: 9
Training loss: 2.615199565887451
Validation loss: 1.9852484310826948

Epoch: 5| Step: 10
Training loss: 2.7118213176727295
Validation loss: 2.000214669012254

Epoch: 59| Step: 0
Training loss: 2.3549277782440186
Validation loss: 1.9844667732074697

Epoch: 5| Step: 1
Training loss: 2.3066725730895996
Validation loss: 1.999671705307499

Epoch: 5| Step: 2
Training loss: 2.127861976623535
Validation loss: 1.994022282220984

Epoch: 5| Step: 3
Training loss: 2.4937431812286377
Validation loss: 1.9937743525351248

Epoch: 5| Step: 4
Training loss: 2.9933133125305176
Validation loss: 1.9969217931070635

Epoch: 5| Step: 5
Training loss: 2.882573366165161
Validation loss: 1.9655168466670538

Epoch: 5| Step: 6
Training loss: 1.6630958318710327
Validation loss: 1.9905826712167392

Epoch: 5| Step: 7
Training loss: 2.2419934272766113
Validation loss: 2.0112337886646228

Epoch: 5| Step: 8
Training loss: 1.7455295324325562
Validation loss: 1.9694024478235552

Epoch: 5| Step: 9
Training loss: 2.2077152729034424
Validation loss: 1.9789164027860087

Epoch: 5| Step: 10
Training loss: 2.3338277339935303
Validation loss: 1.9877922650306457

Epoch: 60| Step: 0
Training loss: 2.0389790534973145
Validation loss: 1.9852868459557975

Epoch: 5| Step: 1
Training loss: 2.042409658432007
Validation loss: 1.9869892981744581

Epoch: 5| Step: 2
Training loss: 2.677269458770752
Validation loss: 1.9812565080581173

Epoch: 5| Step: 3
Training loss: 2.4669198989868164
Validation loss: 1.9847490915688135

Epoch: 5| Step: 4
Training loss: 2.962270498275757
Validation loss: 1.9827719875561294

Epoch: 5| Step: 5
Training loss: 2.652085542678833
Validation loss: 1.9827574376137025

Epoch: 5| Step: 6
Training loss: 2.1053600311279297
Validation loss: 1.9729691923305552

Epoch: 5| Step: 7
Training loss: 1.814335584640503
Validation loss: 1.9910903412808654

Epoch: 5| Step: 8
Training loss: 2.2994279861450195
Validation loss: 1.98174367027898

Epoch: 5| Step: 9
Training loss: 1.7862526178359985
Validation loss: 2.0035694619660736

Epoch: 5| Step: 10
Training loss: 2.37420916557312
Validation loss: 1.9931066151588195

Epoch: 61| Step: 0
Training loss: 2.449735164642334
Validation loss: 1.9855049335828392

Epoch: 5| Step: 1
Training loss: 2.8504538536071777
Validation loss: 1.992585805154616

Epoch: 5| Step: 2
Training loss: 1.9799118041992188
Validation loss: 1.9721920105718798

Epoch: 5| Step: 3
Training loss: 1.7708393335342407
Validation loss: 1.97703307162049

Epoch: 5| Step: 4
Training loss: 2.0532312393188477
Validation loss: 1.9832120108348068

Epoch: 5| Step: 5
Training loss: 2.941754102706909
Validation loss: 1.9878369710778678

Epoch: 5| Step: 6
Training loss: 1.8208420276641846
Validation loss: 1.9820849126385105

Epoch: 5| Step: 7
Training loss: 2.716813802719116
Validation loss: 1.9934190396339662

Epoch: 5| Step: 8
Training loss: 2.0444412231445312
Validation loss: 1.959785969026627

Epoch: 5| Step: 9
Training loss: 2.3766257762908936
Validation loss: 1.9731760973571448

Epoch: 5| Step: 10
Training loss: 2.3070380687713623
Validation loss: 1.9749011070497575

Epoch: 62| Step: 0
Training loss: 2.0473523139953613
Validation loss: 1.9758302037433912

Epoch: 5| Step: 1
Training loss: 2.100116729736328
Validation loss: 1.9949870160830918

Epoch: 5| Step: 2
Training loss: 2.6933138370513916
Validation loss: 1.9756011642435545

Epoch: 5| Step: 3
Training loss: 2.8512043952941895
Validation loss: 1.9785200088254866

Epoch: 5| Step: 4
Training loss: 2.4444313049316406
Validation loss: 1.9867447037850656

Epoch: 5| Step: 5
Training loss: 1.8785117864608765
Validation loss: 1.9852916950820594

Epoch: 5| Step: 6
Training loss: 2.121791362762451
Validation loss: 2.003447186562323

Epoch: 5| Step: 7
Training loss: 1.7819955348968506
Validation loss: 1.9969754526692052

Epoch: 5| Step: 8
Training loss: 2.1674141883850098
Validation loss: 1.988639167560044

Epoch: 5| Step: 9
Training loss: 2.8786118030548096
Validation loss: 2.0093664738439743

Epoch: 5| Step: 10
Training loss: 2.26134991645813
Validation loss: 1.9927320531619492

Epoch: 63| Step: 0
Training loss: 2.1089932918548584
Validation loss: 1.9890827440446424

Epoch: 5| Step: 1
Training loss: 2.4581897258758545
Validation loss: 1.9925819443118187

Epoch: 5| Step: 2
Training loss: 2.4125640392303467
Validation loss: 1.989288862033557

Epoch: 5| Step: 3
Training loss: 2.309797763824463
Validation loss: 1.9936434863716044

Epoch: 5| Step: 4
Training loss: 2.37971568107605
Validation loss: 1.9918869541537376

Epoch: 5| Step: 5
Training loss: 2.3122482299804688
Validation loss: 1.9841534732490458

Epoch: 5| Step: 6
Training loss: 2.1491994857788086
Validation loss: 1.9832336902618408

Epoch: 5| Step: 7
Training loss: 2.5741474628448486
Validation loss: 1.9847251394743561

Epoch: 5| Step: 8
Training loss: 1.7299487590789795
Validation loss: 1.9882810282450851

Epoch: 5| Step: 9
Training loss: 1.9615538120269775
Validation loss: 2.000047210724123

Epoch: 5| Step: 10
Training loss: 2.9849905967712402
Validation loss: 1.9847786862363097

Epoch: 64| Step: 0
Training loss: 2.2828657627105713
Validation loss: 1.993766474467452

Epoch: 5| Step: 1
Training loss: 1.7156035900115967
Validation loss: 1.9817024366829985

Epoch: 5| Step: 2
Training loss: 2.347533941268921
Validation loss: 1.9699957268212431

Epoch: 5| Step: 3
Training loss: 2.3159749507904053
Validation loss: 1.9814967878403202

Epoch: 5| Step: 4
Training loss: 2.1183245182037354
Validation loss: 1.9824030783868605

Epoch: 5| Step: 5
Training loss: 2.637756824493408
Validation loss: 2.001340332851615

Epoch: 5| Step: 6
Training loss: 2.6087443828582764
Validation loss: 1.9955686471795524

Epoch: 5| Step: 7
Training loss: 2.1409618854522705
Validation loss: 1.9799653509611725

Epoch: 5| Step: 8
Training loss: 1.7641093730926514
Validation loss: 1.9765454210260862

Epoch: 5| Step: 9
Training loss: 2.918245315551758
Validation loss: 1.9618744286157752

Epoch: 5| Step: 10
Training loss: 2.2861135005950928
Validation loss: 1.9553945423454366

Epoch: 65| Step: 0
Training loss: 1.8572075366973877
Validation loss: 1.9557165689365839

Epoch: 5| Step: 1
Training loss: 1.909263253211975
Validation loss: 1.968017420461101

Epoch: 5| Step: 2
Training loss: 2.303739309310913
Validation loss: 1.9895072521701935

Epoch: 5| Step: 3
Training loss: 2.7378437519073486
Validation loss: 1.972123658785256

Epoch: 5| Step: 4
Training loss: 2.6515486240386963
Validation loss: 1.9778851180948236

Epoch: 5| Step: 5
Training loss: 2.495210886001587
Validation loss: 1.9959442000235281

Epoch: 5| Step: 6
Training loss: 3.111124038696289
Validation loss: 1.972641832085066

Epoch: 5| Step: 7
Training loss: 1.6498212814331055
Validation loss: 1.971980151309762

Epoch: 5| Step: 8
Training loss: 1.7895946502685547
Validation loss: 1.9720339082902478

Epoch: 5| Step: 9
Training loss: 2.756260395050049
Validation loss: 1.9766771408819384

Epoch: 5| Step: 10
Training loss: 1.6717387437820435
Validation loss: 1.9795562631340438

Epoch: 66| Step: 0
Training loss: 2.5170018672943115
Validation loss: 1.9802794635936778

Epoch: 5| Step: 1
Training loss: 2.2093491554260254
Validation loss: 1.9856494319054387

Epoch: 5| Step: 2
Training loss: 1.9508920907974243
Validation loss: 1.9883204224289104

Epoch: 5| Step: 3
Training loss: 1.9097187519073486
Validation loss: 1.979454440455283

Epoch: 5| Step: 4
Training loss: 2.4307830333709717
Validation loss: 1.9884926234522173

Epoch: 5| Step: 5
Training loss: 1.8829238414764404
Validation loss: 1.9783520813911193

Epoch: 5| Step: 6
Training loss: 2.6600475311279297
Validation loss: 1.9752153119733256

Epoch: 5| Step: 7
Training loss: 2.7860889434814453
Validation loss: 1.9992634327180925

Epoch: 5| Step: 8
Training loss: 2.457723617553711
Validation loss: 1.9608183368559806

Epoch: 5| Step: 9
Training loss: 1.8034532070159912
Validation loss: 1.984687384738717

Epoch: 5| Step: 10
Training loss: 2.417325258255005
Validation loss: 1.9878209637057396

Epoch: 67| Step: 0
Training loss: 2.8237431049346924
Validation loss: 1.987224067411115

Epoch: 5| Step: 1
Training loss: 1.9529285430908203
Validation loss: 1.9658536552101054

Epoch: 5| Step: 2
Training loss: 1.9182227849960327
Validation loss: 1.9898765292218936

Epoch: 5| Step: 3
Training loss: 2.1450068950653076
Validation loss: 1.9796021548650597

Epoch: 5| Step: 4
Training loss: 2.3576769828796387
Validation loss: 1.9952724415768859

Epoch: 5| Step: 5
Training loss: 1.7493255138397217
Validation loss: 1.9871574037818498

Epoch: 5| Step: 6
Training loss: 2.196958065032959
Validation loss: 1.9910804430643718

Epoch: 5| Step: 7
Training loss: 2.361771821975708
Validation loss: 1.972039771336381

Epoch: 5| Step: 8
Training loss: 2.4696712493896484
Validation loss: 1.9832789333917762

Epoch: 5| Step: 9
Training loss: 2.1241469383239746
Validation loss: 1.996734688358922

Epoch: 5| Step: 10
Training loss: 2.9104950428009033
Validation loss: 1.9899463576655234

Epoch: 68| Step: 0
Training loss: 2.303377151489258
Validation loss: 1.9874453493343887

Epoch: 5| Step: 1
Training loss: 1.9912185668945312
Validation loss: 1.9912410166955763

Epoch: 5| Step: 2
Training loss: 2.117563247680664
Validation loss: 1.9847953960459719

Epoch: 5| Step: 3
Training loss: 2.5393588542938232
Validation loss: 1.974179874184311

Epoch: 5| Step: 4
Training loss: 2.0365357398986816
Validation loss: 1.9956289850255495

Epoch: 5| Step: 5
Training loss: 2.5242679119110107
Validation loss: 1.9666607187640281

Epoch: 5| Step: 6
Training loss: 2.4301507472991943
Validation loss: 1.9915409729044924

Epoch: 5| Step: 7
Training loss: 2.275373935699463
Validation loss: 1.9790074286922332

Epoch: 5| Step: 8
Training loss: 1.9302880764007568
Validation loss: 1.9718222515557402

Epoch: 5| Step: 9
Training loss: 2.728985071182251
Validation loss: 1.9562012059714204

Epoch: 5| Step: 10
Training loss: 2.0921216011047363
Validation loss: 1.9752396921957693

Epoch: 69| Step: 0
Training loss: 2.240190267562866
Validation loss: 1.9618801839890019

Epoch: 5| Step: 1
Training loss: 2.6465537548065186
Validation loss: 1.977473525590794

Epoch: 5| Step: 2
Training loss: 2.3968491554260254
Validation loss: 1.9530392526298441

Epoch: 5| Step: 3
Training loss: 1.8588463068008423
Validation loss: 1.9669555874281033

Epoch: 5| Step: 4
Training loss: 1.6961427927017212
Validation loss: 1.9822538437381867

Epoch: 5| Step: 5
Training loss: 2.1418042182922363
Validation loss: 1.9616649907122377

Epoch: 5| Step: 6
Training loss: 2.3608922958374023
Validation loss: 1.9784730249835598

Epoch: 5| Step: 7
Training loss: 2.2370362281799316
Validation loss: 1.9726971964682303

Epoch: 5| Step: 8
Training loss: 2.3652431964874268
Validation loss: 1.966259853814238

Epoch: 5| Step: 9
Training loss: 2.274552822113037
Validation loss: 1.9953057842869912

Epoch: 5| Step: 10
Training loss: 2.643942356109619
Validation loss: 1.9736113522642402

Epoch: 70| Step: 0
Training loss: 2.5943799018859863
Validation loss: 1.9659093144119426

Epoch: 5| Step: 1
Training loss: 2.4437663555145264
Validation loss: 1.9789744346372542

Epoch: 5| Step: 2
Training loss: 2.9128386974334717
Validation loss: 1.9723786359192224

Epoch: 5| Step: 3
Training loss: 1.8715183734893799
Validation loss: 1.9915438980184577

Epoch: 5| Step: 4
Training loss: 2.39634370803833
Validation loss: 1.9655209536193519

Epoch: 5| Step: 5
Training loss: 2.176851987838745
Validation loss: 1.9678038756052654

Epoch: 5| Step: 6
Training loss: 2.1146297454833984
Validation loss: 1.9732703342232654

Epoch: 5| Step: 7
Training loss: 1.9977773427963257
Validation loss: 1.9791165257012973

Epoch: 5| Step: 8
Training loss: 2.0072383880615234
Validation loss: 1.9725551143769295

Epoch: 5| Step: 9
Training loss: 2.054478406906128
Validation loss: 1.961863204997073

Epoch: 5| Step: 10
Training loss: 2.435509204864502
Validation loss: 1.9873597545008506

Epoch: 71| Step: 0
Training loss: 2.2015540599823
Validation loss: 1.9962645705028246

Epoch: 5| Step: 1
Training loss: 1.9467613697052002
Validation loss: 1.981505887482756

Epoch: 5| Step: 2
Training loss: 2.3830859661102295
Validation loss: 1.9674008982155913

Epoch: 5| Step: 3
Training loss: 2.171823024749756
Validation loss: 1.9872692426045735

Epoch: 5| Step: 4
Training loss: 2.7196545600891113
Validation loss: 1.967095007178604

Epoch: 5| Step: 5
Training loss: 2.074505090713501
Validation loss: 1.9677375721675094

Epoch: 5| Step: 6
Training loss: 2.3553624153137207
Validation loss: 1.978154625943912

Epoch: 5| Step: 7
Training loss: 2.3143489360809326
Validation loss: 1.9730916253982052

Epoch: 5| Step: 8
Training loss: 2.173731803894043
Validation loss: 1.9729017673000213

Epoch: 5| Step: 9
Training loss: 2.563016414642334
Validation loss: 1.9556657088700162

Epoch: 5| Step: 10
Training loss: 1.9309051036834717
Validation loss: 1.9725449521054503

Epoch: 72| Step: 0
Training loss: 1.8959776163101196
Validation loss: 1.9670644806277366

Epoch: 5| Step: 1
Training loss: 2.525078773498535
Validation loss: 1.9596358678674186

Epoch: 5| Step: 2
Training loss: 2.668339967727661
Validation loss: 1.9561285203503025

Epoch: 5| Step: 3
Training loss: 2.4142935276031494
Validation loss: 1.9638345959366008

Epoch: 5| Step: 4
Training loss: 2.995274782180786
Validation loss: 1.9713442992138606

Epoch: 5| Step: 5
Training loss: 0.9001021385192871
Validation loss: 1.972534566797236

Epoch: 5| Step: 6
Training loss: 1.7341381311416626
Validation loss: 1.9590555416640414

Epoch: 5| Step: 7
Training loss: 2.3527820110321045
Validation loss: 1.9387296412580757

Epoch: 5| Step: 8
Training loss: 2.507925033569336
Validation loss: 1.9595932793873612

Epoch: 5| Step: 9
Training loss: 2.8781795501708984
Validation loss: 1.9762640255753712

Epoch: 5| Step: 10
Training loss: 1.788565754890442
Validation loss: 1.9790282685269591

Epoch: 73| Step: 0
Training loss: 1.7546459436416626
Validation loss: 1.9637612719689646

Epoch: 5| Step: 1
Training loss: 2.2825167179107666
Validation loss: 1.9623499903627621

Epoch: 5| Step: 2
Training loss: 2.257023572921753
Validation loss: 1.9748348600120955

Epoch: 5| Step: 3
Training loss: 2.4927070140838623
Validation loss: 1.9690261822874828

Epoch: 5| Step: 4
Training loss: 1.6779371500015259
Validation loss: 1.9859949145265805

Epoch: 5| Step: 5
Training loss: 3.109182119369507
Validation loss: 1.9716271905488865

Epoch: 5| Step: 6
Training loss: 1.9301445484161377
Validation loss: 1.971210249008671

Epoch: 5| Step: 7
Training loss: 2.1668355464935303
Validation loss: 1.980686733799596

Epoch: 5| Step: 8
Training loss: 2.3354291915893555
Validation loss: 1.986099781528596

Epoch: 5| Step: 9
Training loss: 2.6301987171173096
Validation loss: 1.9769102437521822

Epoch: 5| Step: 10
Training loss: 2.073878288269043
Validation loss: 1.9589575913644606

Epoch: 74| Step: 0
Training loss: 2.2525136470794678
Validation loss: 1.991772892654583

Epoch: 5| Step: 1
Training loss: 2.597001314163208
Validation loss: 1.94338954905028

Epoch: 5| Step: 2
Training loss: 1.8021281957626343
Validation loss: 1.9915014928387058

Epoch: 5| Step: 3
Training loss: 2.265310764312744
Validation loss: 1.9878742220581218

Epoch: 5| Step: 4
Training loss: 2.0874617099761963
Validation loss: 1.9901349006160614

Epoch: 5| Step: 5
Training loss: 2.191680431365967
Validation loss: 1.9769873234533495

Epoch: 5| Step: 6
Training loss: 2.359100818634033
Validation loss: 1.9948571830667474

Epoch: 5| Step: 7
Training loss: 2.3671417236328125
Validation loss: 1.9836231470108032

Epoch: 5| Step: 8
Training loss: 1.8601154088974
Validation loss: 1.9770143596074914

Epoch: 5| Step: 9
Training loss: 2.6183667182922363
Validation loss: 1.998107071845762

Epoch: 5| Step: 10
Training loss: 2.3436617851257324
Validation loss: 1.9623274059705837

Epoch: 75| Step: 0
Training loss: 2.773815155029297
Validation loss: 1.9745878019640524

Epoch: 5| Step: 1
Training loss: 2.716723680496216
Validation loss: 1.9829771390525244

Epoch: 5| Step: 2
Training loss: 1.9283685684204102
Validation loss: 1.9566205727156771

Epoch: 5| Step: 3
Training loss: 1.8441050052642822
Validation loss: 1.9732476101126721

Epoch: 5| Step: 4
Training loss: 2.1677448749542236
Validation loss: 1.9617287292275378

Epoch: 5| Step: 5
Training loss: 2.7607955932617188
Validation loss: 1.9586522451011084

Epoch: 5| Step: 6
Training loss: 2.305872917175293
Validation loss: 1.9442956947511243

Epoch: 5| Step: 7
Training loss: 2.25187349319458
Validation loss: 1.9641559944357923

Epoch: 5| Step: 8
Training loss: 2.2019202709198
Validation loss: 1.9483671316536524

Epoch: 5| Step: 9
Training loss: 1.9578914642333984
Validation loss: 1.9556563567089778

Epoch: 5| Step: 10
Training loss: 1.8055812120437622
Validation loss: 1.9670246313976985

Epoch: 76| Step: 0
Training loss: 2.215254306793213
Validation loss: 1.9558129541335567

Epoch: 5| Step: 1
Training loss: 2.2263131141662598
Validation loss: 1.9644721143989152

Epoch: 5| Step: 2
Training loss: 2.024552822113037
Validation loss: 1.9671249248648202

Epoch: 5| Step: 3
Training loss: 2.006277561187744
Validation loss: 1.9528079417444044

Epoch: 5| Step: 4
Training loss: 2.749420642852783
Validation loss: 1.9642740423961351

Epoch: 5| Step: 5
Training loss: 2.188377857208252
Validation loss: 1.9450607402350313

Epoch: 5| Step: 6
Training loss: 2.2910542488098145
Validation loss: 1.9599199230952928

Epoch: 5| Step: 7
Training loss: 2.189465045928955
Validation loss: 1.959365706289968

Epoch: 5| Step: 8
Training loss: 2.346510887145996
Validation loss: 1.9619289393066077

Epoch: 5| Step: 9
Training loss: 2.3465213775634766
Validation loss: 1.986325736968748

Epoch: 5| Step: 10
Training loss: 1.9819378852844238
Validation loss: 1.9848551955274356

Epoch: 77| Step: 0
Training loss: 2.453132152557373
Validation loss: 1.9839335205734416

Epoch: 5| Step: 1
Training loss: 2.140566110610962
Validation loss: 1.9855857843993812

Epoch: 5| Step: 2
Training loss: 2.260918617248535
Validation loss: 1.9722240817162298

Epoch: 5| Step: 3
Training loss: 3.0052802562713623
Validation loss: 1.974534450038787

Epoch: 5| Step: 4
Training loss: 2.0852162837982178
Validation loss: 1.9602769190265286

Epoch: 5| Step: 5
Training loss: 2.2574760913848877
Validation loss: 1.9971887898701493

Epoch: 5| Step: 6
Training loss: 2.0787174701690674
Validation loss: 1.9525052232127036

Epoch: 5| Step: 7
Training loss: 1.9276307821273804
Validation loss: 1.9748027798950032

Epoch: 5| Step: 8
Training loss: 1.9087390899658203
Validation loss: 1.992128300410445

Epoch: 5| Step: 9
Training loss: 2.076343059539795
Validation loss: 1.9812041995345906

Epoch: 5| Step: 10
Training loss: 2.6187243461608887
Validation loss: 1.966597585267918

Epoch: 78| Step: 0
Training loss: 2.549095392227173
Validation loss: 1.9783952941176712

Epoch: 5| Step: 1
Training loss: 1.9481010437011719
Validation loss: 1.977011953630755

Epoch: 5| Step: 2
Training loss: 1.8942334651947021
Validation loss: 1.9573148412089194

Epoch: 5| Step: 3
Training loss: 2.048311948776245
Validation loss: 1.9786406652901762

Epoch: 5| Step: 4
Training loss: 2.309124231338501
Validation loss: 1.9890038672313894

Epoch: 5| Step: 5
Training loss: 2.291154146194458
Validation loss: 1.9888746148796492

Epoch: 5| Step: 6
Training loss: 2.2698709964752197
Validation loss: 1.9946069858407462

Epoch: 5| Step: 7
Training loss: 2.413309335708618
Validation loss: 1.9624091066339964

Epoch: 5| Step: 8
Training loss: 2.59904408454895
Validation loss: 1.9740056478849022

Epoch: 5| Step: 9
Training loss: 2.277008056640625
Validation loss: 1.9600397976495887

Epoch: 5| Step: 10
Training loss: 2.2398462295532227
Validation loss: 1.9567904933806388

Epoch: 79| Step: 0
Training loss: 2.1406993865966797
Validation loss: 1.9440040255105624

Epoch: 5| Step: 1
Training loss: 2.305601119995117
Validation loss: 1.975045096489691

Epoch: 5| Step: 2
Training loss: 1.7043167352676392
Validation loss: 1.9677601623278793

Epoch: 5| Step: 3
Training loss: 2.070873260498047
Validation loss: 1.980061992522209

Epoch: 5| Step: 4
Training loss: 2.368170738220215
Validation loss: 1.9805134124653314

Epoch: 5| Step: 5
Training loss: 2.302572250366211
Validation loss: 1.9630492374461184

Epoch: 5| Step: 6
Training loss: 2.8487651348114014
Validation loss: 1.9676406332241592

Epoch: 5| Step: 7
Training loss: 1.7738354206085205
Validation loss: 1.9612266261090514

Epoch: 5| Step: 8
Training loss: 2.295478105545044
Validation loss: 1.9817764810336533

Epoch: 5| Step: 9
Training loss: 2.3515305519104004
Validation loss: 1.9837515354156494

Epoch: 5| Step: 10
Training loss: 2.3080692291259766
Validation loss: 1.9874682093179354

Epoch: 80| Step: 0
Training loss: 2.433274745941162
Validation loss: 1.967472235361735

Epoch: 5| Step: 1
Training loss: 1.7838197946548462
Validation loss: 1.9701422183744368

Epoch: 5| Step: 2
Training loss: 1.8809726238250732
Validation loss: 1.995489606293299

Epoch: 5| Step: 3
Training loss: 1.9749767780303955
Validation loss: 1.9863655515896377

Epoch: 5| Step: 4
Training loss: 1.9497668743133545
Validation loss: 1.9737413108989756

Epoch: 5| Step: 5
Training loss: 2.013610363006592
Validation loss: 1.9862372311212684

Epoch: 5| Step: 6
Training loss: 1.9162992238998413
Validation loss: 1.9786452131886636

Epoch: 5| Step: 7
Training loss: 2.962307929992676
Validation loss: 1.9889089933005712

Epoch: 5| Step: 8
Training loss: 2.7653145790100098
Validation loss: 1.974953152800119

Epoch: 5| Step: 9
Training loss: 2.602494955062866
Validation loss: 1.992992244740968

Epoch: 5| Step: 10
Training loss: 2.5045108795166016
Validation loss: 1.987827157461515

Epoch: 81| Step: 0
Training loss: 2.3013529777526855
Validation loss: 1.993043698290343

Epoch: 5| Step: 1
Training loss: 1.948390007019043
Validation loss: 1.9780375803670576

Epoch: 5| Step: 2
Training loss: 1.866885781288147
Validation loss: 1.9735539292776456

Epoch: 5| Step: 3
Training loss: 1.8233217000961304
Validation loss: 1.9708712690620012

Epoch: 5| Step: 4
Training loss: 2.0985968112945557
Validation loss: 1.9541665815537976

Epoch: 5| Step: 5
Training loss: 2.2621517181396484
Validation loss: 1.9735798271753455

Epoch: 5| Step: 6
Training loss: 2.1891894340515137
Validation loss: 1.9774047354216218

Epoch: 5| Step: 7
Training loss: 2.1980159282684326
Validation loss: 1.973943107871599

Epoch: 5| Step: 8
Training loss: 3.1684765815734863
Validation loss: 1.9892827285233365

Epoch: 5| Step: 9
Training loss: 2.848332643508911
Validation loss: 1.9749272613115207

Epoch: 5| Step: 10
Training loss: 1.7400931119918823
Validation loss: 1.9791555353390273

Epoch: 82| Step: 0
Training loss: 2.253012180328369
Validation loss: 1.9857940353373045

Epoch: 5| Step: 1
Training loss: 2.348289728164673
Validation loss: 1.9756966662663284

Epoch: 5| Step: 2
Training loss: 2.619079828262329
Validation loss: 1.9773345070500528

Epoch: 5| Step: 3
Training loss: 1.9229466915130615
Validation loss: 1.9667367730089413

Epoch: 5| Step: 4
Training loss: 2.195061206817627
Validation loss: 1.9855791163700882

Epoch: 5| Step: 5
Training loss: 2.2546303272247314
Validation loss: 1.987196539037971

Epoch: 5| Step: 6
Training loss: 2.0309579372406006
Validation loss: 1.9786572751178537

Epoch: 5| Step: 7
Training loss: 2.438133716583252
Validation loss: 1.9587111473083496

Epoch: 5| Step: 8
Training loss: 1.8627738952636719
Validation loss: 1.97808486928222

Epoch: 5| Step: 9
Training loss: 2.077763080596924
Validation loss: 1.9773654373743201

Epoch: 5| Step: 10
Training loss: 2.494302749633789
Validation loss: 1.9744536671587216

Epoch: 83| Step: 0
Training loss: 1.8151321411132812
Validation loss: 1.9656032593019548

Epoch: 5| Step: 1
Training loss: 2.339569330215454
Validation loss: 1.9662127110265917

Epoch: 5| Step: 2
Training loss: 2.1940298080444336
Validation loss: 1.96482680689904

Epoch: 5| Step: 3
Training loss: 2.34639310836792
Validation loss: 1.9595507690983434

Epoch: 5| Step: 4
Training loss: 2.2304458618164062
Validation loss: 1.9581128576750397

Epoch: 5| Step: 5
Training loss: 2.293875217437744
Validation loss: 1.9717897920198337

Epoch: 5| Step: 6
Training loss: 2.580129384994507
Validation loss: 1.9705793831938057

Epoch: 5| Step: 7
Training loss: 2.058053731918335
Validation loss: 1.9750068367168467

Epoch: 5| Step: 8
Training loss: 1.8280893564224243
Validation loss: 1.9421556688124133

Epoch: 5| Step: 9
Training loss: 2.3355727195739746
Validation loss: 1.9567610961134716

Epoch: 5| Step: 10
Training loss: 2.4288840293884277
Validation loss: 1.9588971881456272

Epoch: 84| Step: 0
Training loss: 2.9123873710632324
Validation loss: 1.9509811465458204

Epoch: 5| Step: 1
Training loss: 1.9082571268081665
Validation loss: 1.9606969382173272

Epoch: 5| Step: 2
Training loss: 1.8688253164291382
Validation loss: 1.9636649085629372

Epoch: 5| Step: 3
Training loss: 2.43851900100708
Validation loss: 1.9568581581115723

Epoch: 5| Step: 4
Training loss: 2.137028217315674
Validation loss: 1.9647284118078088

Epoch: 5| Step: 5
Training loss: 2.325843095779419
Validation loss: 1.9554824508646482

Epoch: 5| Step: 6
Training loss: 1.5139189958572388
Validation loss: 1.9707634038822626

Epoch: 5| Step: 7
Training loss: 1.865146279335022
Validation loss: 1.9634536543200094

Epoch: 5| Step: 8
Training loss: 2.6776695251464844
Validation loss: 1.9676600220382854

Epoch: 5| Step: 9
Training loss: 2.430847644805908
Validation loss: 1.9665926887143044

Epoch: 5| Step: 10
Training loss: 2.447965145111084
Validation loss: 1.9911206345404349

Epoch: 85| Step: 0
Training loss: 1.7696607112884521
Validation loss: 1.9577444189338273

Epoch: 5| Step: 1
Training loss: 2.3177237510681152
Validation loss: 1.9656980229962258

Epoch: 5| Step: 2
Training loss: 2.3925163745880127
Validation loss: 1.9562956312651276

Epoch: 5| Step: 3
Training loss: 2.4172301292419434
Validation loss: 1.978496354113343

Epoch: 5| Step: 4
Training loss: 2.617565155029297
Validation loss: 1.9504467082279984

Epoch: 5| Step: 5
Training loss: 1.7862440347671509
Validation loss: 1.9633745608791229

Epoch: 5| Step: 6
Training loss: 2.485379219055176
Validation loss: 1.9677985765600716

Epoch: 5| Step: 7
Training loss: 1.9997947216033936
Validation loss: 1.9425383806228638

Epoch: 5| Step: 8
Training loss: 2.2781167030334473
Validation loss: 1.964957929426624

Epoch: 5| Step: 9
Training loss: 2.257713794708252
Validation loss: 1.9767432341011621

Epoch: 5| Step: 10
Training loss: 1.9833935499191284
Validation loss: 1.975493291372894

Epoch: 86| Step: 0
Training loss: 2.3008980751037598
Validation loss: 1.9671762463867024

Epoch: 5| Step: 1
Training loss: 2.805861711502075
Validation loss: 1.9766203741873465

Epoch: 5| Step: 2
Training loss: 2.572206497192383
Validation loss: 1.9757080103761406

Epoch: 5| Step: 3
Training loss: 2.58546781539917
Validation loss: 1.9513255908925047

Epoch: 5| Step: 4
Training loss: 2.25268816947937
Validation loss: 1.9510262115027315

Epoch: 5| Step: 5
Training loss: 1.50163733959198
Validation loss: 1.9828724643235565

Epoch: 5| Step: 6
Training loss: 1.948103904724121
Validation loss: 1.958773510430449

Epoch: 5| Step: 7
Training loss: 2.577970504760742
Validation loss: 1.9682107381923224

Epoch: 5| Step: 8
Training loss: 1.621603012084961
Validation loss: 1.9568353314553537

Epoch: 5| Step: 9
Training loss: 2.368197202682495
Validation loss: 1.943115036974671

Epoch: 5| Step: 10
Training loss: 1.86196768283844
Validation loss: 1.9742166598637898

Epoch: 87| Step: 0
Training loss: 1.8112258911132812
Validation loss: 1.927290088386946

Epoch: 5| Step: 1
Training loss: 2.4011921882629395
Validation loss: 1.9464685647718367

Epoch: 5| Step: 2
Training loss: 2.543712615966797
Validation loss: 1.971191652359501

Epoch: 5| Step: 3
Training loss: 2.217700481414795
Validation loss: 1.9481052326899704

Epoch: 5| Step: 4
Training loss: 1.7157455682754517
Validation loss: 1.9600621372140863

Epoch: 5| Step: 5
Training loss: 1.4607820510864258
Validation loss: 1.9507204012204242

Epoch: 5| Step: 6
Training loss: 2.734349012374878
Validation loss: 1.9409066041310628

Epoch: 5| Step: 7
Training loss: 2.380308151245117
Validation loss: 1.9589596922679613

Epoch: 5| Step: 8
Training loss: 2.1583991050720215
Validation loss: 1.9499105279163649

Epoch: 5| Step: 9
Training loss: 2.3964591026306152
Validation loss: 1.9618598517551218

Epoch: 5| Step: 10
Training loss: 2.6817450523376465
Validation loss: 1.9556686391112625

Epoch: 88| Step: 0
Training loss: 1.921274185180664
Validation loss: 1.9513404933355187

Epoch: 5| Step: 1
Training loss: 1.7412192821502686
Validation loss: 1.9513339406700545

Epoch: 5| Step: 2
Training loss: 1.6148960590362549
Validation loss: 1.9662990954614454

Epoch: 5| Step: 3
Training loss: 2.1100668907165527
Validation loss: 1.974019028807199

Epoch: 5| Step: 4
Training loss: 2.627802848815918
Validation loss: 1.96257354879892

Epoch: 5| Step: 5
Training loss: 2.4788105487823486
Validation loss: 1.9645974777078117

Epoch: 5| Step: 6
Training loss: 1.83321213722229
Validation loss: 1.9766557075644051

Epoch: 5| Step: 7
Training loss: 2.768695831298828
Validation loss: 1.9700709478829497

Epoch: 5| Step: 8
Training loss: 2.727940797805786
Validation loss: 1.978006641070048

Epoch: 5| Step: 9
Training loss: 2.6921546459198
Validation loss: 1.9550180845363165

Epoch: 5| Step: 10
Training loss: 1.7540656328201294
Validation loss: 1.9690644894876788

Epoch: 89| Step: 0
Training loss: 2.4589030742645264
Validation loss: 1.9841746258479294

Epoch: 5| Step: 1
Training loss: 2.196476936340332
Validation loss: 1.9471616437358241

Epoch: 5| Step: 2
Training loss: 2.8848140239715576
Validation loss: 1.966196875418386

Epoch: 5| Step: 3
Training loss: 1.6778790950775146
Validation loss: 1.9778040826961558

Epoch: 5| Step: 4
Training loss: 2.032890796661377
Validation loss: 1.980128583087716

Epoch: 5| Step: 5
Training loss: 2.317504405975342
Validation loss: 1.980344239101615

Epoch: 5| Step: 6
Training loss: 1.7777080535888672
Validation loss: 1.952030340830485

Epoch: 5| Step: 7
Training loss: 2.1728546619415283
Validation loss: 1.9854198758320143

Epoch: 5| Step: 8
Training loss: 1.9003963470458984
Validation loss: 1.9787670079097952

Epoch: 5| Step: 9
Training loss: 2.5908427238464355
Validation loss: 1.958449085553487

Epoch: 5| Step: 10
Training loss: 2.391941785812378
Validation loss: 1.9761992128946448

Epoch: 90| Step: 0
Training loss: 2.2298197746276855
Validation loss: 1.979632234060636

Epoch: 5| Step: 1
Training loss: 1.83464777469635
Validation loss: 1.97764713533463

Epoch: 5| Step: 2
Training loss: 1.9863017797470093
Validation loss: 1.9703145462979552

Epoch: 5| Step: 3
Training loss: 2.7611358165740967
Validation loss: 1.9563078418854745

Epoch: 5| Step: 4
Training loss: 1.9739162921905518
Validation loss: 1.9523566205014464

Epoch: 5| Step: 5
Training loss: 2.35681414604187
Validation loss: 1.9693869621522966

Epoch: 5| Step: 6
Training loss: 2.5510263442993164
Validation loss: 1.9680954000001312

Epoch: 5| Step: 7
Training loss: 1.8643871545791626
Validation loss: 1.9805880156896447

Epoch: 5| Step: 8
Training loss: 2.247129440307617
Validation loss: 1.961682419623098

Epoch: 5| Step: 9
Training loss: 2.2156288623809814
Validation loss: 1.9875252298129502

Epoch: 5| Step: 10
Training loss: 2.237119436264038
Validation loss: 1.9760003294996036

Epoch: 91| Step: 0
Training loss: 2.315412998199463
Validation loss: 1.9725288242422125

Epoch: 5| Step: 1
Training loss: 1.8207018375396729
Validation loss: 1.9859958053917013

Epoch: 5| Step: 2
Training loss: 2.540452003479004
Validation loss: 1.95755127937563

Epoch: 5| Step: 3
Training loss: 1.9536383152008057
Validation loss: 1.9538967840133175

Epoch: 5| Step: 4
Training loss: 1.8254188299179077
Validation loss: 1.9629290385912823

Epoch: 5| Step: 5
Training loss: 1.7426013946533203
Validation loss: 1.9640030322536346

Epoch: 5| Step: 6
Training loss: 2.140617847442627
Validation loss: 1.9807833548515075

Epoch: 5| Step: 7
Training loss: 2.4265217781066895
Validation loss: 1.9607323241490189

Epoch: 5| Step: 8
Training loss: 2.5599615573883057
Validation loss: 1.9664670703231648

Epoch: 5| Step: 9
Training loss: 2.8193700313568115
Validation loss: 1.970847104185371

Epoch: 5| Step: 10
Training loss: 2.067345142364502
Validation loss: 1.961698955105197

Epoch: 92| Step: 0
Training loss: 2.016568183898926
Validation loss: 1.9575412863044328

Epoch: 5| Step: 1
Training loss: 2.210123300552368
Validation loss: 1.9728999945425219

Epoch: 5| Step: 2
Training loss: 1.7075550556182861
Validation loss: 1.9556579641116563

Epoch: 5| Step: 3
Training loss: 2.1576168537139893
Validation loss: 1.9601712508868145

Epoch: 5| Step: 4
Training loss: 2.233172655105591
Validation loss: 1.958496065549953

Epoch: 5| Step: 5
Training loss: 3.153118848800659
Validation loss: 1.9464039494914394

Epoch: 5| Step: 6
Training loss: 1.986525535583496
Validation loss: 1.973731106327426

Epoch: 5| Step: 7
Training loss: 2.090668201446533
Validation loss: 1.9783581969558552

Epoch: 5| Step: 8
Training loss: 2.6640546321868896
Validation loss: 1.9587622457934963

Epoch: 5| Step: 9
Training loss: 1.9304519891738892
Validation loss: 1.9854408951215847

Epoch: 5| Step: 10
Training loss: 2.1298234462738037
Validation loss: 1.9517123109550887

Epoch: 93| Step: 0
Training loss: 2.8611819744110107
Validation loss: 1.960211823063512

Epoch: 5| Step: 1
Training loss: 1.842189073562622
Validation loss: 1.9575461726034842

Epoch: 5| Step: 2
Training loss: 2.2158148288726807
Validation loss: 1.9649854859998148

Epoch: 5| Step: 3
Training loss: 2.106778383255005
Validation loss: 1.9735262393951416

Epoch: 5| Step: 4
Training loss: 2.3307337760925293
Validation loss: 1.9612941126669607

Epoch: 5| Step: 5
Training loss: 1.9410979747772217
Validation loss: 1.9739794961867794

Epoch: 5| Step: 6
Training loss: 2.105309009552002
Validation loss: 1.992488194537419

Epoch: 5| Step: 7
Training loss: 2.3177294731140137
Validation loss: 1.9828503452321535

Epoch: 5| Step: 8
Training loss: 2.1093907356262207
Validation loss: 1.994578202565511

Epoch: 5| Step: 9
Training loss: 2.0990383625030518
Validation loss: 1.9815910195791593

Epoch: 5| Step: 10
Training loss: 2.4439563751220703
Validation loss: 1.9647436834150744

Epoch: 94| Step: 0
Training loss: 3.094189167022705
Validation loss: 1.9801755976933304

Epoch: 5| Step: 1
Training loss: 2.216245412826538
Validation loss: 1.9777302895822833

Epoch: 5| Step: 2
Training loss: 1.8171600103378296
Validation loss: 1.9843353917521815

Epoch: 5| Step: 3
Training loss: 2.2501602172851562
Validation loss: 1.9738268518960604

Epoch: 5| Step: 4
Training loss: 2.616828203201294
Validation loss: 1.9741149897216468

Epoch: 5| Step: 5
Training loss: 2.1647047996520996
Validation loss: 1.9580311044569938

Epoch: 5| Step: 6
Training loss: 1.7387014627456665
Validation loss: 1.9822550922311761

Epoch: 5| Step: 7
Training loss: 2.2739510536193848
Validation loss: 1.9539059913286598

Epoch: 5| Step: 8
Training loss: 2.073960781097412
Validation loss: 1.9583547884418118

Epoch: 5| Step: 9
Training loss: 1.7579584121704102
Validation loss: 1.964929489679234

Epoch: 5| Step: 10
Training loss: 2.3742284774780273
Validation loss: 1.9811586820951073

Epoch: 95| Step: 0
Training loss: 2.4069864749908447
Validation loss: 1.9915759307081982

Epoch: 5| Step: 1
Training loss: 2.1413562297821045
Validation loss: 1.9670822979301534

Epoch: 5| Step: 2
Training loss: 1.9949754476547241
Validation loss: 1.9721019575672765

Epoch: 5| Step: 3
Training loss: 1.9633852243423462
Validation loss: 1.9716711300675587

Epoch: 5| Step: 4
Training loss: 2.026298761367798
Validation loss: 1.9670566384510328

Epoch: 5| Step: 5
Training loss: 1.8580360412597656
Validation loss: 1.9683962637378323

Epoch: 5| Step: 6
Training loss: 2.4562716484069824
Validation loss: 1.978526815291374

Epoch: 5| Step: 7
Training loss: 1.9798234701156616
Validation loss: 1.987413296135523

Epoch: 5| Step: 8
Training loss: 2.403113842010498
Validation loss: 1.962129774913993

Epoch: 5| Step: 9
Training loss: 2.6723599433898926
Validation loss: 1.9632229035900486

Epoch: 5| Step: 10
Training loss: 2.43157696723938
Validation loss: 1.956977044382403

Epoch: 96| Step: 0
Training loss: 2.8624331951141357
Validation loss: 1.9685823968661729

Epoch: 5| Step: 1
Training loss: 1.6650021076202393
Validation loss: 1.9643518873440322

Epoch: 5| Step: 2
Training loss: 2.2322025299072266
Validation loss: 1.9665080757551296

Epoch: 5| Step: 3
Training loss: 2.5625643730163574
Validation loss: 1.9552358863174275

Epoch: 5| Step: 4
Training loss: 1.8719146251678467
Validation loss: 1.9770682832246185

Epoch: 5| Step: 5
Training loss: 3.144845485687256
Validation loss: 1.9743896171610842

Epoch: 5| Step: 6
Training loss: 2.1627519130706787
Validation loss: 1.9689992858517555

Epoch: 5| Step: 7
Training loss: 2.386780261993408
Validation loss: 1.963974924497707

Epoch: 5| Step: 8
Training loss: 1.6268304586410522
Validation loss: 1.9577489732414164

Epoch: 5| Step: 9
Training loss: 1.9464356899261475
Validation loss: 1.9679548496841102

Epoch: 5| Step: 10
Training loss: 1.660143494606018
Validation loss: 1.9500594472372403

Epoch: 97| Step: 0
Training loss: 1.9297444820404053
Validation loss: 1.9931424753640288

Epoch: 5| Step: 1
Training loss: 1.7897207736968994
Validation loss: 1.9663394497286888

Epoch: 5| Step: 2
Training loss: 2.2964999675750732
Validation loss: 1.9459367029128536

Epoch: 5| Step: 3
Training loss: 2.0640368461608887
Validation loss: 1.9814206900135163

Epoch: 5| Step: 4
Training loss: 2.104780912399292
Validation loss: 1.978906621215164

Epoch: 5| Step: 5
Training loss: 3.0213637351989746
Validation loss: 1.9841412857014646

Epoch: 5| Step: 6
Training loss: 2.508305072784424
Validation loss: 1.991125718239815

Epoch: 5| Step: 7
Training loss: 1.9405139684677124
Validation loss: 1.9913556396320302

Epoch: 5| Step: 8
Training loss: 2.3861782550811768
Validation loss: 1.9984316518229823

Epoch: 5| Step: 9
Training loss: 1.9904916286468506
Validation loss: 1.9867738818609586

Epoch: 5| Step: 10
Training loss: 2.229901075363159
Validation loss: 1.9972197599308465

Epoch: 98| Step: 0
Training loss: 2.4827656745910645
Validation loss: 1.9963556797273698

Epoch: 5| Step: 1
Training loss: 2.0702497959136963
Validation loss: 1.986327378980575

Epoch: 5| Step: 2
Training loss: 2.239809513092041
Validation loss: 1.979245388379661

Epoch: 5| Step: 3
Training loss: 2.3534462451934814
Validation loss: 1.9794049929547053

Epoch: 5| Step: 4
Training loss: 1.9738763570785522
Validation loss: 1.9931328335115988

Epoch: 5| Step: 5
Training loss: 1.999866247177124
Validation loss: 1.9857037580141457

Epoch: 5| Step: 6
Training loss: 2.6824097633361816
Validation loss: 1.962844740959906

Epoch: 5| Step: 7
Training loss: 1.5743886232376099
Validation loss: 1.992165985927787

Epoch: 5| Step: 8
Training loss: 2.733023166656494
Validation loss: 1.9760437344992032

Epoch: 5| Step: 9
Training loss: 1.722303032875061
Validation loss: 1.9869643180601058

Epoch: 5| Step: 10
Training loss: 2.329397201538086
Validation loss: 1.9926080421734882

Epoch: 99| Step: 0
Training loss: 3.110212802886963
Validation loss: 1.9808960383938206

Epoch: 5| Step: 1
Training loss: 1.9784873723983765
Validation loss: 1.988979499827149

Epoch: 5| Step: 2
Training loss: 2.2199244499206543
Validation loss: 1.96753905921854

Epoch: 5| Step: 3
Training loss: 1.9480578899383545
Validation loss: 1.982886101609917

Epoch: 5| Step: 4
Training loss: 2.355895519256592
Validation loss: 2.0005011558532715

Epoch: 5| Step: 5
Training loss: 1.8472747802734375
Validation loss: 2.0008647288045576

Epoch: 5| Step: 6
Training loss: 1.999576210975647
Validation loss: 1.9994686726600892

Epoch: 5| Step: 7
Training loss: 2.285095453262329
Validation loss: 2.02445484745887

Epoch: 5| Step: 8
Training loss: 1.9872407913208008
Validation loss: 2.0018615415019374

Epoch: 5| Step: 9
Training loss: 2.0406010150909424
Validation loss: 2.0042454709288893

Epoch: 5| Step: 10
Training loss: 2.569842576980591
Validation loss: 1.9943849373889226

Epoch: 100| Step: 0
Training loss: 2.1874992847442627
Validation loss: 1.9904509923791374

Epoch: 5| Step: 1
Training loss: 2.681199312210083
Validation loss: 2.01005805436001

Epoch: 5| Step: 2
Training loss: 2.47187876701355
Validation loss: 1.9897199805064867

Epoch: 5| Step: 3
Training loss: 1.8768863677978516
Validation loss: 1.987721630322036

Epoch: 5| Step: 4
Training loss: 2.294631242752075
Validation loss: 1.968896944035766

Epoch: 5| Step: 5
Training loss: 2.3771719932556152
Validation loss: 1.9709531017529067

Epoch: 5| Step: 6
Training loss: 2.3730576038360596
Validation loss: 1.982507182705787

Epoch: 5| Step: 7
Training loss: 2.325562000274658
Validation loss: 1.9674173273066038

Epoch: 5| Step: 8
Training loss: 1.5981738567352295
Validation loss: 1.9607790695723666

Epoch: 5| Step: 9
Training loss: 1.602069616317749
Validation loss: 1.9791976713365125

Epoch: 5| Step: 10
Training loss: 2.374415397644043
Validation loss: 1.9668669764713576

Epoch: 101| Step: 0
Training loss: 1.914995551109314
Validation loss: 1.972439060929001

Epoch: 5| Step: 1
Training loss: 1.8036972284317017
Validation loss: 1.9810672934337328

Epoch: 5| Step: 2
Training loss: 2.066066265106201
Validation loss: 1.9483892058813443

Epoch: 5| Step: 3
Training loss: 2.8737339973449707
Validation loss: 1.965777866301998

Epoch: 5| Step: 4
Training loss: 2.3110880851745605
Validation loss: 1.9632614645906674

Epoch: 5| Step: 5
Training loss: 1.6729323863983154
Validation loss: 1.9476017234145955

Epoch: 5| Step: 6
Training loss: 2.6301445960998535
Validation loss: 1.9659111166513095

Epoch: 5| Step: 7
Training loss: 2.4176571369171143
Validation loss: 1.9595730496991066

Epoch: 5| Step: 8
Training loss: 2.345705509185791
Validation loss: 1.967082872185656

Epoch: 5| Step: 9
Training loss: 2.2127087116241455
Validation loss: 1.9660881757736206

Epoch: 5| Step: 10
Training loss: 1.8721789121627808
Validation loss: 1.9833202259514922

Epoch: 102| Step: 0
Training loss: 1.807765007019043
Validation loss: 1.964118762682843

Epoch: 5| Step: 1
Training loss: 2.3400309085845947
Validation loss: 1.9947484116400442

Epoch: 5| Step: 2
Training loss: 2.5013880729675293
Validation loss: 1.98015082651569

Epoch: 5| Step: 3
Training loss: 2.2743947505950928
Validation loss: 2.0013246382436445

Epoch: 5| Step: 4
Training loss: 2.195404529571533
Validation loss: 1.989043285769801

Epoch: 5| Step: 5
Training loss: 2.6531152725219727
Validation loss: 1.9744742762657903

Epoch: 5| Step: 6
Training loss: 1.959755301475525
Validation loss: 1.982066991508648

Epoch: 5| Step: 7
Training loss: 2.154597282409668
Validation loss: 1.9949489293559906

Epoch: 5| Step: 8
Training loss: 1.6762981414794922
Validation loss: 1.986068833258844

Epoch: 5| Step: 9
Training loss: 2.083329677581787
Validation loss: 1.9998653524665422

Epoch: 5| Step: 10
Training loss: 2.68778657913208
Validation loss: 2.009892399593066

Epoch: 103| Step: 0
Training loss: 1.9807195663452148
Validation loss: 1.9618546097509322

Epoch: 5| Step: 1
Training loss: 2.1853835582733154
Validation loss: 1.9702427694874425

Epoch: 5| Step: 2
Training loss: 1.8204262256622314
Validation loss: 1.959699184663834

Epoch: 5| Step: 3
Training loss: 2.2230687141418457
Validation loss: 1.98469163269125

Epoch: 5| Step: 4
Training loss: 1.90180242061615
Validation loss: 1.9944506716984574

Epoch: 5| Step: 5
Training loss: 2.889604091644287
Validation loss: 1.9741196632385254

Epoch: 5| Step: 6
Training loss: 2.1075751781463623
Validation loss: 1.9685305805616482

Epoch: 5| Step: 7
Training loss: 2.2594377994537354
Validation loss: 1.9636692436792518

Epoch: 5| Step: 8
Training loss: 2.825199842453003
Validation loss: 1.9629744945033905

Epoch: 5| Step: 9
Training loss: 1.5320405960083008
Validation loss: 2.004131886266893

Epoch: 5| Step: 10
Training loss: 2.4130382537841797
Validation loss: 1.990368486732565

Epoch: 104| Step: 0
Training loss: 1.9899189472198486
Validation loss: 1.9838218740237656

Epoch: 5| Step: 1
Training loss: 2.168618679046631
Validation loss: 1.9702874601528209

Epoch: 5| Step: 2
Training loss: 2.637577772140503
Validation loss: 1.988861123720805

Epoch: 5| Step: 3
Training loss: 1.6805490255355835
Validation loss: 1.9715710904008599

Epoch: 5| Step: 4
Training loss: 2.334908962249756
Validation loss: 1.996315162668946

Epoch: 5| Step: 5
Training loss: 2.095517873764038
Validation loss: 1.981185846431281

Epoch: 5| Step: 6
Training loss: 2.346787214279175
Validation loss: 1.989838441212972

Epoch: 5| Step: 7
Training loss: 2.588906764984131
Validation loss: 1.9759560451712659

Epoch: 5| Step: 8
Training loss: 2.183652877807617
Validation loss: 1.977217931901255

Epoch: 5| Step: 9
Training loss: 1.8737903833389282
Validation loss: 2.008390574045079

Epoch: 5| Step: 10
Training loss: 2.164332866668701
Validation loss: 1.990965900882598

Epoch: 105| Step: 0
Training loss: 2.1113624572753906
Validation loss: 2.0002239455458937

Epoch: 5| Step: 1
Training loss: 2.354180335998535
Validation loss: 1.9852743071894492

Epoch: 5| Step: 2
Training loss: 2.6267762184143066
Validation loss: 1.9950670298709665

Epoch: 5| Step: 3
Training loss: 2.2795591354370117
Validation loss: 1.9894108208276893

Epoch: 5| Step: 4
Training loss: 1.8338489532470703
Validation loss: 1.9900686048692273

Epoch: 5| Step: 5
Training loss: 1.9469791650772095
Validation loss: 1.9651944047661238

Epoch: 5| Step: 6
Training loss: 1.786932349205017
Validation loss: 1.981338627876774

Epoch: 5| Step: 7
Training loss: 2.5562520027160645
Validation loss: 1.9952793775066253

Epoch: 5| Step: 8
Training loss: 2.4653544425964355
Validation loss: 1.9676311708265735

Epoch: 5| Step: 9
Training loss: 2.1392054557800293
Validation loss: 1.986226111330012

Epoch: 5| Step: 10
Training loss: 1.8338537216186523
Validation loss: 1.9763202577508905

Epoch: 106| Step: 0
Training loss: 1.9298032522201538
Validation loss: 1.9925011293862456

Epoch: 5| Step: 1
Training loss: 2.283989906311035
Validation loss: 1.9744804930943314

Epoch: 5| Step: 2
Training loss: 1.9459682703018188
Validation loss: 1.9849167511027346

Epoch: 5| Step: 3
Training loss: 2.810675859451294
Validation loss: 1.9881338932180916

Epoch: 5| Step: 4
Training loss: 2.3506267070770264
Validation loss: 1.9923341312716085

Epoch: 5| Step: 5
Training loss: 1.9558985233306885
Validation loss: 1.9886805985563545

Epoch: 5| Step: 6
Training loss: 2.443739414215088
Validation loss: 1.9878291237738825

Epoch: 5| Step: 7
Training loss: 2.1715240478515625
Validation loss: 1.9767703766463904

Epoch: 5| Step: 8
Training loss: 2.0154263973236084
Validation loss: 1.9819616758695213

Epoch: 5| Step: 9
Training loss: 2.327333450317383
Validation loss: 1.9979651563911027

Epoch: 5| Step: 10
Training loss: 1.8390979766845703
Validation loss: 1.9875440366806523

Epoch: 107| Step: 0
Training loss: 2.789299488067627
Validation loss: 1.9857539515341482

Epoch: 5| Step: 1
Training loss: 2.328702688217163
Validation loss: 1.9839034490687872

Epoch: 5| Step: 2
Training loss: 2.17551851272583
Validation loss: 1.978053585175545

Epoch: 5| Step: 3
Training loss: 1.6958582401275635
Validation loss: 2.003835380718272

Epoch: 5| Step: 4
Training loss: 1.9600454568862915
Validation loss: 1.982772486184233

Epoch: 5| Step: 5
Training loss: 2.253786563873291
Validation loss: 1.9637738273989769

Epoch: 5| Step: 6
Training loss: 2.140584945678711
Validation loss: 1.991124576137912

Epoch: 5| Step: 7
Training loss: 2.2819907665252686
Validation loss: 1.9794750854533205

Epoch: 5| Step: 8
Training loss: 2.10062575340271
Validation loss: 1.9807892255885626

Epoch: 5| Step: 9
Training loss: 2.332524061203003
Validation loss: 1.9739082731226438

Epoch: 5| Step: 10
Training loss: 1.987364649772644
Validation loss: 1.9812882754110521

Epoch: 108| Step: 0
Training loss: 1.529683232307434
Validation loss: 1.9961479248539094

Epoch: 5| Step: 1
Training loss: 2.1504220962524414
Validation loss: 1.9882658655925463

Epoch: 5| Step: 2
Training loss: 1.9152523279190063
Validation loss: 1.9872182646105367

Epoch: 5| Step: 3
Training loss: 2.8703267574310303
Validation loss: 1.9805576211662703

Epoch: 5| Step: 4
Training loss: 2.5230648517608643
Validation loss: 1.9949594313098538

Epoch: 5| Step: 5
Training loss: 2.6914114952087402
Validation loss: 1.9807339945147115

Epoch: 5| Step: 6
Training loss: 2.0692551136016846
Validation loss: 2.005204064871675

Epoch: 5| Step: 7
Training loss: 2.1066365242004395
Validation loss: 1.9827268713264055

Epoch: 5| Step: 8
Training loss: 2.450373888015747
Validation loss: 1.9895237838068316

Epoch: 5| Step: 9
Training loss: 1.9120376110076904
Validation loss: 1.988794372927758

Epoch: 5| Step: 10
Training loss: 1.650231957435608
Validation loss: 1.9712804158528645

Epoch: 109| Step: 0
Training loss: 1.8820117712020874
Validation loss: 1.984238911700505

Epoch: 5| Step: 1
Training loss: 2.152731418609619
Validation loss: 1.9782109773287209

Epoch: 5| Step: 2
Training loss: 2.0049540996551514
Validation loss: 1.9816454046516008

Epoch: 5| Step: 3
Training loss: 2.043485164642334
Validation loss: 1.9773257675991263

Epoch: 5| Step: 4
Training loss: 2.1563472747802734
Validation loss: 1.97613948904058

Epoch: 5| Step: 5
Training loss: 2.1190531253814697
Validation loss: 1.9685655922018073

Epoch: 5| Step: 6
Training loss: 2.41642427444458
Validation loss: 1.9668790384005475

Epoch: 5| Step: 7
Training loss: 3.486980438232422
Validation loss: 1.957982394003099

Epoch: 5| Step: 8
Training loss: 1.7576587200164795
Validation loss: 1.9807690420458395

Epoch: 5| Step: 9
Training loss: 1.997018575668335
Validation loss: 1.9862625906544347

Epoch: 5| Step: 10
Training loss: 1.9638135433197021
Validation loss: 1.9791297092232654

Epoch: 110| Step: 0
Training loss: 2.516287088394165
Validation loss: 1.968736643432289

Epoch: 5| Step: 1
Training loss: 2.6021411418914795
Validation loss: 1.9792544072674167

Epoch: 5| Step: 2
Training loss: 2.5385220050811768
Validation loss: 1.9818568562948575

Epoch: 5| Step: 3
Training loss: 2.0893661975860596
Validation loss: 1.9633548259735107

Epoch: 5| Step: 4
Training loss: 2.2190520763397217
Validation loss: 1.9786540795398015

Epoch: 5| Step: 5
Training loss: 1.7411912679672241
Validation loss: 1.961017043359818

Epoch: 5| Step: 6
Training loss: 1.7089179754257202
Validation loss: 1.968404128987302

Epoch: 5| Step: 7
Training loss: 1.9553190469741821
Validation loss: 1.976666986301381

Epoch: 5| Step: 8
Training loss: 2.1909263134002686
Validation loss: 1.9700152694538076

Epoch: 5| Step: 9
Training loss: 2.523791790008545
Validation loss: 2.004076098883024

Epoch: 5| Step: 10
Training loss: 1.9143198728561401
Validation loss: 1.979050451709378

Epoch: 111| Step: 0
Training loss: 1.8545141220092773
Validation loss: 1.9944301523188108

Epoch: 5| Step: 1
Training loss: 2.2294907569885254
Validation loss: 1.984675794519404

Epoch: 5| Step: 2
Training loss: 2.5418789386749268
Validation loss: 1.9896538770327004

Epoch: 5| Step: 3
Training loss: 2.148171901702881
Validation loss: 1.979244016831921

Epoch: 5| Step: 4
Training loss: 2.18803071975708
Validation loss: 1.9745769628914454

Epoch: 5| Step: 5
Training loss: 2.0235323905944824
Validation loss: 1.9838850677654307

Epoch: 5| Step: 6
Training loss: 2.3969407081604004
Validation loss: 2.000698140872422

Epoch: 5| Step: 7
Training loss: 2.289093494415283
Validation loss: 1.9692190847089213

Epoch: 5| Step: 8
Training loss: 2.7116081714630127
Validation loss: 2.000845145153743

Epoch: 5| Step: 9
Training loss: 1.4110825061798096
Validation loss: 1.9950605489874398

Epoch: 5| Step: 10
Training loss: 2.1466264724731445
Validation loss: 1.9881530269499748

Epoch: 112| Step: 0
Training loss: 2.25420880317688
Validation loss: 1.995112915192881

Epoch: 5| Step: 1
Training loss: 2.510648012161255
Validation loss: 1.990798770740468

Epoch: 5| Step: 2
Training loss: 2.0065388679504395
Validation loss: 2.0022289547868954

Epoch: 5| Step: 3
Training loss: 1.859224557876587
Validation loss: 1.9785613449670936

Epoch: 5| Step: 4
Training loss: 1.8140159845352173
Validation loss: 1.993134831869474

Epoch: 5| Step: 5
Training loss: 1.9130210876464844
Validation loss: 1.99572479596702

Epoch: 5| Step: 6
Training loss: 2.0521702766418457
Validation loss: 1.9895055319673272

Epoch: 5| Step: 7
Training loss: 2.3791584968566895
Validation loss: 1.9795870550217167

Epoch: 5| Step: 8
Training loss: 2.034330368041992
Validation loss: 1.970061397039762

Epoch: 5| Step: 9
Training loss: 2.677912712097168
Validation loss: 1.9830143297872236

Epoch: 5| Step: 10
Training loss: 2.47890305519104
Validation loss: 1.991594144093093

Epoch: 113| Step: 0
Training loss: 2.1284384727478027
Validation loss: 1.978530183915169

Epoch: 5| Step: 1
Training loss: 2.0573811531066895
Validation loss: 1.9834215923022198

Epoch: 5| Step: 2
Training loss: 2.1386096477508545
Validation loss: 1.9902514180829447

Epoch: 5| Step: 3
Training loss: 2.3089046478271484
Validation loss: 1.9766216560076642

Epoch: 5| Step: 4
Training loss: 2.6730780601501465
Validation loss: 1.997057371242072

Epoch: 5| Step: 5
Training loss: 2.5004944801330566
Validation loss: 1.976597600085761

Epoch: 5| Step: 6
Training loss: 2.6167314052581787
Validation loss: 1.9984590545777352

Epoch: 5| Step: 7
Training loss: 1.6682285070419312
Validation loss: 1.970832691397718

Epoch: 5| Step: 8
Training loss: 1.6118656396865845
Validation loss: 2.009637135331349

Epoch: 5| Step: 9
Training loss: 2.3423216342926025
Validation loss: 1.9713286392150386

Epoch: 5| Step: 10
Training loss: 1.9273529052734375
Validation loss: 1.982767569121494

Epoch: 114| Step: 0
Training loss: 2.253012180328369
Validation loss: 1.997887901080552

Epoch: 5| Step: 1
Training loss: 2.5858492851257324
Validation loss: 1.98051623118821

Epoch: 5| Step: 2
Training loss: 1.9103631973266602
Validation loss: 1.9777652704587547

Epoch: 5| Step: 3
Training loss: 2.112985134124756
Validation loss: 1.9759610288886613

Epoch: 5| Step: 4
Training loss: 2.042855739593506
Validation loss: 1.972710745308989

Epoch: 5| Step: 5
Training loss: 1.7584927082061768
Validation loss: 1.981864618998702

Epoch: 5| Step: 6
Training loss: 2.227264881134033
Validation loss: 1.9876178682491343

Epoch: 5| Step: 7
Training loss: 2.494814395904541
Validation loss: 1.9691557550943026

Epoch: 5| Step: 8
Training loss: 2.002457618713379
Validation loss: 1.9759274221235705

Epoch: 5| Step: 9
Training loss: 2.163248300552368
Validation loss: 1.9696506761735486

Epoch: 5| Step: 10
Training loss: 2.3038582801818848
Validation loss: 1.9838331284061554

Epoch: 115| Step: 0
Training loss: 2.500239610671997
Validation loss: 1.9681138761581913

Epoch: 5| Step: 1
Training loss: 2.27850604057312
Validation loss: 1.9879072327767648

Epoch: 5| Step: 2
Training loss: 1.9900243282318115
Validation loss: 1.9608110330438102

Epoch: 5| Step: 3
Training loss: 1.7497637271881104
Validation loss: 1.9711260975048106

Epoch: 5| Step: 4
Training loss: 2.924854278564453
Validation loss: 1.9511396385008288

Epoch: 5| Step: 5
Training loss: 2.3732361793518066
Validation loss: 1.9593493938446045

Epoch: 5| Step: 6
Training loss: 1.959869623184204
Validation loss: 1.9619815157305809

Epoch: 5| Step: 7
Training loss: 2.376681327819824
Validation loss: 1.9649084691078431

Epoch: 5| Step: 8
Training loss: 2.341960906982422
Validation loss: 1.9704757249483498

Epoch: 5| Step: 9
Training loss: 1.5447014570236206
Validation loss: 1.9827359696870208

Epoch: 5| Step: 10
Training loss: 1.6412177085876465
Validation loss: 1.9758136810794953

Epoch: 116| Step: 0
Training loss: 2.6154496669769287
Validation loss: 1.9561468042353147

Epoch: 5| Step: 1
Training loss: 2.6818766593933105
Validation loss: 1.9826154503771054

Epoch: 5| Step: 2
Training loss: 1.3504277467727661
Validation loss: 1.985275742828205

Epoch: 5| Step: 3
Training loss: 2.012068510055542
Validation loss: 1.9703157614636164

Epoch: 5| Step: 4
Training loss: 1.5222941637039185
Validation loss: 1.9738683982561993

Epoch: 5| Step: 5
Training loss: 2.4146971702575684
Validation loss: 1.9865184496807795

Epoch: 5| Step: 6
Training loss: 1.8098793029785156
Validation loss: 1.9802958542300808

Epoch: 5| Step: 7
Training loss: 2.617938995361328
Validation loss: 1.9882292234769432

Epoch: 5| Step: 8
Training loss: 2.341207981109619
Validation loss: 1.9649006141129362

Epoch: 5| Step: 9
Training loss: 2.039881706237793
Validation loss: 1.984923339659168

Epoch: 5| Step: 10
Training loss: 2.377120018005371
Validation loss: 1.9949097223179315

Epoch: 117| Step: 0
Training loss: 2.353663921356201
Validation loss: 1.9907106007299116

Epoch: 5| Step: 1
Training loss: 2.8821418285369873
Validation loss: 1.9887983414434618

Epoch: 5| Step: 2
Training loss: 1.735408067703247
Validation loss: 1.9918858671701083

Epoch: 5| Step: 3
Training loss: 1.6782090663909912
Validation loss: 1.981732694051599

Epoch: 5| Step: 4
Training loss: 1.6983642578125
Validation loss: 2.008415545186689

Epoch: 5| Step: 5
Training loss: 2.845067262649536
Validation loss: 1.9906111968460904

Epoch: 5| Step: 6
Training loss: 2.0698723793029785
Validation loss: 1.9912128025485623

Epoch: 5| Step: 7
Training loss: 2.410393476486206
Validation loss: 2.0197158628894436

Epoch: 5| Step: 8
Training loss: 2.392756938934326
Validation loss: 2.028685105744229

Epoch: 5| Step: 9
Training loss: 1.8755992650985718
Validation loss: 2.0080831666146555

Epoch: 5| Step: 10
Training loss: 1.9050641059875488
Validation loss: 1.9968707817856983

Epoch: 118| Step: 0
Training loss: 2.3850464820861816
Validation loss: 1.9932709227326095

Epoch: 5| Step: 1
Training loss: 2.7849507331848145
Validation loss: 1.9954896306478849

Epoch: 5| Step: 2
Training loss: 2.267885208129883
Validation loss: 1.9939383511902184

Epoch: 5| Step: 3
Training loss: 1.7164760828018188
Validation loss: 2.000897411377199

Epoch: 5| Step: 4
Training loss: 2.3914923667907715
Validation loss: 1.9716871118032804

Epoch: 5| Step: 5
Training loss: 2.3597359657287598
Validation loss: 1.9620457003193517

Epoch: 5| Step: 6
Training loss: 2.4312777519226074
Validation loss: 1.966506697798288

Epoch: 5| Step: 7
Training loss: 1.5343801975250244
Validation loss: 1.9733064802744056

Epoch: 5| Step: 8
Training loss: 1.8252195119857788
Validation loss: 1.96188554199793

Epoch: 5| Step: 9
Training loss: 2.042905807495117
Validation loss: 1.9995412698356054

Epoch: 5| Step: 10
Training loss: 2.122601270675659
Validation loss: 1.992529740897558

Epoch: 119| Step: 0
Training loss: 2.949427604675293
Validation loss: 1.9735575542655042

Epoch: 5| Step: 1
Training loss: 1.9354913234710693
Validation loss: 1.9806652658729142

Epoch: 5| Step: 2
Training loss: 2.2422451972961426
Validation loss: 1.9893361829942273

Epoch: 5| Step: 3
Training loss: 2.085224151611328
Validation loss: 1.9845706121895903

Epoch: 5| Step: 4
Training loss: 2.0637764930725098
Validation loss: 1.98919117066168

Epoch: 5| Step: 5
Training loss: 2.633240222930908
Validation loss: 1.9786989906782746

Epoch: 5| Step: 6
Training loss: 2.3416988849639893
Validation loss: 1.9614721216181272

Epoch: 5| Step: 7
Training loss: 2.109023332595825
Validation loss: 1.9704029175543016

Epoch: 5| Step: 8
Training loss: 1.0483275651931763
Validation loss: 1.9606455218407415

Epoch: 5| Step: 9
Training loss: 2.5215258598327637
Validation loss: 1.9886754225659113

Epoch: 5| Step: 10
Training loss: 1.6438698768615723
Validation loss: 2.000289003054301

Epoch: 120| Step: 0
Training loss: 1.8652164936065674
Validation loss: 1.983873228872976

Epoch: 5| Step: 1
Training loss: 2.143333911895752
Validation loss: 2.00571067999768

Epoch: 5| Step: 2
Training loss: 1.8712142705917358
Validation loss: 1.964616601185132

Epoch: 5| Step: 3
Training loss: 1.5940563678741455
Validation loss: 1.9947233981983636

Epoch: 5| Step: 4
Training loss: 2.4671902656555176
Validation loss: 1.9963260453234437

Epoch: 5| Step: 5
Training loss: 1.8959019184112549
Validation loss: 1.9945235021652714

Epoch: 5| Step: 6
Training loss: 2.420473098754883
Validation loss: 1.9833457700667843

Epoch: 5| Step: 7
Training loss: 2.4427943229675293
Validation loss: 1.9804158492754864

Epoch: 5| Step: 8
Training loss: 2.5767369270324707
Validation loss: 1.9704377138486473

Epoch: 5| Step: 9
Training loss: 2.10567045211792
Validation loss: 1.9766958234130696

Epoch: 5| Step: 10
Training loss: 2.4379353523254395
Validation loss: 2.0038423845844884

Epoch: 121| Step: 0
Training loss: 2.054666042327881
Validation loss: 1.9537716680957424

Epoch: 5| Step: 1
Training loss: 2.3255202770233154
Validation loss: 1.9713901806903142

Epoch: 5| Step: 2
Training loss: 1.7085233926773071
Validation loss: 1.9772815024980934

Epoch: 5| Step: 3
Training loss: 2.080946445465088
Validation loss: 1.961978304770685

Epoch: 5| Step: 4
Training loss: 3.0296988487243652
Validation loss: 1.992984119281974

Epoch: 5| Step: 5
Training loss: 2.3082518577575684
Validation loss: 1.966262343109295

Epoch: 5| Step: 6
Training loss: 2.266244411468506
Validation loss: 2.003621247506911

Epoch: 5| Step: 7
Training loss: 2.1011128425598145
Validation loss: 1.9963149498867732

Epoch: 5| Step: 8
Training loss: 1.740299940109253
Validation loss: 2.0074754017655567

Epoch: 5| Step: 9
Training loss: 1.795785903930664
Validation loss: 2.0106038303785425

Epoch: 5| Step: 10
Training loss: 2.352309226989746
Validation loss: 1.991888323137837

Epoch: 122| Step: 0
Training loss: 2.4811038970947266
Validation loss: 1.9794077078501384

Epoch: 5| Step: 1
Training loss: 2.1890854835510254
Validation loss: 1.9888313983076362

Epoch: 5| Step: 2
Training loss: 2.2413928508758545
Validation loss: 1.990785159090514

Epoch: 5| Step: 3
Training loss: 1.8807697296142578
Validation loss: 2.0089475429186257

Epoch: 5| Step: 4
Training loss: 1.980018973350525
Validation loss: 1.9927646985618017

Epoch: 5| Step: 5
Training loss: 2.245741605758667
Validation loss: 2.0063075070740073

Epoch: 5| Step: 6
Training loss: 2.5121686458587646
Validation loss: 1.9907260915284515

Epoch: 5| Step: 7
Training loss: 2.0162296295166016
Validation loss: 1.9923347926908923

Epoch: 5| Step: 8
Training loss: 2.5191519260406494
Validation loss: 1.9845325523807156

Epoch: 5| Step: 9
Training loss: 1.6306216716766357
Validation loss: 2.026521426375194

Epoch: 5| Step: 10
Training loss: 2.1488325595855713
Validation loss: 1.9792323894398187

Epoch: 123| Step: 0
Training loss: 2.1550934314727783
Validation loss: 1.980840841929118

Epoch: 5| Step: 1
Training loss: 2.526700973510742
Validation loss: 1.9917773508256482

Epoch: 5| Step: 2
Training loss: 2.0299220085144043
Validation loss: 1.99254850674701

Epoch: 5| Step: 3
Training loss: 2.1256988048553467
Validation loss: 1.9858573021427277

Epoch: 5| Step: 4
Training loss: 2.241830825805664
Validation loss: 1.9941302345645042

Epoch: 5| Step: 5
Training loss: 1.942182183265686
Validation loss: 1.9703549287652458

Epoch: 5| Step: 6
Training loss: 2.7741427421569824
Validation loss: 1.9672417179230721

Epoch: 5| Step: 7
Training loss: 1.9508335590362549
Validation loss: 1.9878564867922055

Epoch: 5| Step: 8
Training loss: 1.5488086938858032
Validation loss: 1.9729297135465889

Epoch: 5| Step: 9
Training loss: 2.273967981338501
Validation loss: 1.9879585645532096

Epoch: 5| Step: 10
Training loss: 2.225123643875122
Validation loss: 2.0049862387359783

Epoch: 124| Step: 0
Training loss: 1.865740180015564
Validation loss: 1.9959754161937262

Epoch: 5| Step: 1
Training loss: 1.519620418548584
Validation loss: 1.9987826629351544

Epoch: 5| Step: 2
Training loss: 2.145348072052002
Validation loss: 1.9963356410303423

Epoch: 5| Step: 3
Training loss: 1.6228187084197998
Validation loss: 2.0123048418311664

Epoch: 5| Step: 4
Training loss: 2.4239039421081543
Validation loss: 1.9886430053300754

Epoch: 5| Step: 5
Training loss: 2.5486361980438232
Validation loss: 2.0211450643436883

Epoch: 5| Step: 6
Training loss: 2.2391066551208496
Validation loss: 2.00265178116419

Epoch: 5| Step: 7
Training loss: 2.6213271617889404
Validation loss: 1.9962297626720962

Epoch: 5| Step: 8
Training loss: 2.0851032733917236
Validation loss: 2.0154075186739684

Epoch: 5| Step: 9
Training loss: 2.2900137901306152
Validation loss: 2.0033856540597896

Epoch: 5| Step: 10
Training loss: 2.2547831535339355
Validation loss: 1.988184408474994

Epoch: 125| Step: 0
Training loss: 2.695087432861328
Validation loss: 2.004966462812116

Epoch: 5| Step: 1
Training loss: 1.8126468658447266
Validation loss: 1.997975423771848

Epoch: 5| Step: 2
Training loss: 1.8947505950927734
Validation loss: 1.9780858101383332

Epoch: 5| Step: 3
Training loss: 2.1446709632873535
Validation loss: 1.9933913779515091

Epoch: 5| Step: 4
Training loss: 1.635266661643982
Validation loss: 1.9960582217862528

Epoch: 5| Step: 5
Training loss: 1.9209047555923462
Validation loss: 1.9826391794348275

Epoch: 5| Step: 6
Training loss: 2.1402716636657715
Validation loss: 1.9925979991112985

Epoch: 5| Step: 7
Training loss: 2.4093337059020996
Validation loss: 1.968808771461569

Epoch: 5| Step: 8
Training loss: 2.283339262008667
Validation loss: 1.9976362925703808

Epoch: 5| Step: 9
Training loss: 2.4529154300689697
Validation loss: 1.9926938997801913

Epoch: 5| Step: 10
Training loss: 2.3135313987731934
Validation loss: 1.9799609825175295

Epoch: 126| Step: 0
Training loss: 2.7199363708496094
Validation loss: 2.001084466134348

Epoch: 5| Step: 1
Training loss: 1.994086503982544
Validation loss: 1.9730988728102816

Epoch: 5| Step: 2
Training loss: 2.4058609008789062
Validation loss: 2.00236705938975

Epoch: 5| Step: 3
Training loss: 2.346911907196045
Validation loss: 1.984184709928369

Epoch: 5| Step: 4
Training loss: 1.7284595966339111
Validation loss: 1.997087340201101

Epoch: 5| Step: 5
Training loss: 2.05013370513916
Validation loss: 1.9750922649137435

Epoch: 5| Step: 6
Training loss: 1.9622180461883545
Validation loss: 1.9847430439405545

Epoch: 5| Step: 7
Training loss: 2.179286241531372
Validation loss: 1.9856198859471146

Epoch: 5| Step: 8
Training loss: 2.5820720195770264
Validation loss: 1.9810481994382796

Epoch: 5| Step: 9
Training loss: 1.8323519229888916
Validation loss: 1.9909882635198615

Epoch: 5| Step: 10
Training loss: 1.7778773307800293
Validation loss: 2.001624043269824

Epoch: 127| Step: 0
Training loss: 1.529623031616211
Validation loss: 1.996510257003128

Epoch: 5| Step: 1
Training loss: 2.64058780670166
Validation loss: 2.0026148288480696

Epoch: 5| Step: 2
Training loss: 2.32877779006958
Validation loss: 2.0063001699345087

Epoch: 5| Step: 3
Training loss: 2.44728946685791
Validation loss: 1.9965229547151955

Epoch: 5| Step: 4
Training loss: 2.2667911052703857
Validation loss: 2.006495064304721

Epoch: 5| Step: 5
Training loss: 2.1185810565948486
Validation loss: 1.9847698506488596

Epoch: 5| Step: 6
Training loss: 2.74853515625
Validation loss: 1.9944845386730727

Epoch: 5| Step: 7
Training loss: 1.3709661960601807
Validation loss: 1.9821746503153155

Epoch: 5| Step: 8
Training loss: 1.6289069652557373
Validation loss: 1.9830134837858138

Epoch: 5| Step: 9
Training loss: 2.21003794670105
Validation loss: 1.979999114108342

Epoch: 5| Step: 10
Training loss: 2.349064826965332
Validation loss: 1.9970788776233632

Epoch: 128| Step: 0
Training loss: 2.072749137878418
Validation loss: 1.9898076441980177

Epoch: 5| Step: 1
Training loss: 2.3056418895721436
Validation loss: 2.0080379901393766

Epoch: 5| Step: 2
Training loss: 1.8564687967300415
Validation loss: 2.0030268853710544

Epoch: 5| Step: 3
Training loss: 2.444831132888794
Validation loss: 1.9830239870214974

Epoch: 5| Step: 4
Training loss: 3.255350112915039
Validation loss: 1.998470406378469

Epoch: 5| Step: 5
Training loss: 2.5612845420837402
Validation loss: 2.002936842621014

Epoch: 5| Step: 6
Training loss: 1.9834665060043335
Validation loss: 1.9848548391813874

Epoch: 5| Step: 7
Training loss: 1.6155980825424194
Validation loss: 1.9903318689715477

Epoch: 5| Step: 8
Training loss: 1.3424761295318604
Validation loss: 2.0117402743267756

Epoch: 5| Step: 9
Training loss: 1.8400062322616577
Validation loss: 1.9808323934514036

Epoch: 5| Step: 10
Training loss: 2.272292137145996
Validation loss: 1.9922331763852028

Epoch: 129| Step: 0
Training loss: 2.652106761932373
Validation loss: 2.0121169474817093

Epoch: 5| Step: 1
Training loss: 2.2531845569610596
Validation loss: 1.9940449422405613

Epoch: 5| Step: 2
Training loss: 2.0756382942199707
Validation loss: 2.0089928168122486

Epoch: 5| Step: 3
Training loss: 2.0223536491394043
Validation loss: 2.009950791635821

Epoch: 5| Step: 4
Training loss: 2.1172168254852295
Validation loss: 2.0089827224772465

Epoch: 5| Step: 5
Training loss: 1.5241655111312866
Validation loss: 1.9966782857013006

Epoch: 5| Step: 6
Training loss: 2.323194742202759
Validation loss: 1.987433168195909

Epoch: 5| Step: 7
Training loss: 2.247288465499878
Validation loss: 2.0127820071353706

Epoch: 5| Step: 8
Training loss: 1.941396713256836
Validation loss: 2.005968870655183

Epoch: 5| Step: 9
Training loss: 1.6124727725982666
Validation loss: 2.0052734241690686

Epoch: 5| Step: 10
Training loss: 2.882181167602539
Validation loss: 2.027123466614754

Epoch: 130| Step: 0
Training loss: 2.42201566696167
Validation loss: 2.017763845382198

Epoch: 5| Step: 1
Training loss: 2.3854923248291016
Validation loss: 2.011626269227715

Epoch: 5| Step: 2
Training loss: 2.1752264499664307
Validation loss: 1.99992996902876

Epoch: 5| Step: 3
Training loss: 1.9053955078125
Validation loss: 2.012297612364574

Epoch: 5| Step: 4
Training loss: 2.729062795639038
Validation loss: 1.9931957478164344

Epoch: 5| Step: 5
Training loss: 1.3668625354766846
Validation loss: 2.0078889195637037

Epoch: 5| Step: 6
Training loss: 2.053144693374634
Validation loss: 2.0080369082830285

Epoch: 5| Step: 7
Training loss: 2.4832088947296143
Validation loss: 1.998768332184002

Epoch: 5| Step: 8
Training loss: 1.4786460399627686
Validation loss: 2.0098355649619974

Epoch: 5| Step: 9
Training loss: 2.013576030731201
Validation loss: 1.9978307165125364

Epoch: 5| Step: 10
Training loss: 2.7577321529388428
Validation loss: 1.9927091393419492

Epoch: 131| Step: 0
Training loss: 2.08707594871521
Validation loss: 1.9945560296376545

Epoch: 5| Step: 1
Training loss: 1.933476448059082
Validation loss: 1.9866782772925593

Epoch: 5| Step: 2
Training loss: 2.355025053024292
Validation loss: 1.9770418443987448

Epoch: 5| Step: 3
Training loss: 2.07558012008667
Validation loss: 1.9917747141212545

Epoch: 5| Step: 4
Training loss: 1.8736228942871094
Validation loss: 1.9999874971246208

Epoch: 5| Step: 5
Training loss: 1.8520958423614502
Validation loss: 1.9812696646618586

Epoch: 5| Step: 6
Training loss: 2.2408223152160645
Validation loss: 1.9797682185326853

Epoch: 5| Step: 7
Training loss: 2.402082920074463
Validation loss: 1.9878497098081855

Epoch: 5| Step: 8
Training loss: 2.285118579864502
Validation loss: 1.9947915320755334

Epoch: 5| Step: 9
Training loss: 2.160384178161621
Validation loss: 1.9670943060228903

Epoch: 5| Step: 10
Training loss: 2.4049229621887207
Validation loss: 1.964605091720499

Epoch: 132| Step: 0
Training loss: 2.043327808380127
Validation loss: 1.937174206138939

Epoch: 5| Step: 1
Training loss: 2.802497625350952
Validation loss: 1.9529703970878356

Epoch: 5| Step: 2
Training loss: 2.07270884513855
Validation loss: 1.948928617661999

Epoch: 5| Step: 3
Training loss: 1.8733854293823242
Validation loss: 1.9501582730200984

Epoch: 5| Step: 4
Training loss: 1.658609390258789
Validation loss: 1.9311181460657427

Epoch: 5| Step: 5
Training loss: 2.5310192108154297
Validation loss: 1.9316938064431632

Epoch: 5| Step: 6
Training loss: 2.129917860031128
Validation loss: 1.973142759774321

Epoch: 5| Step: 7
Training loss: 1.837036371231079
Validation loss: 1.9642530333611272

Epoch: 5| Step: 8
Training loss: 1.9574518203735352
Validation loss: 1.9528151545473325

Epoch: 5| Step: 9
Training loss: 2.598402261734009
Validation loss: 1.9599825028450257

Epoch: 5| Step: 10
Training loss: 2.2826333045959473
Validation loss: 1.9848289976837814

Epoch: 133| Step: 0
Training loss: 1.6983550786972046
Validation loss: 1.9762515611546014

Epoch: 5| Step: 1
Training loss: 1.9969863891601562
Validation loss: 1.9669714422636135

Epoch: 5| Step: 2
Training loss: 2.500957727432251
Validation loss: 1.9984190912656887

Epoch: 5| Step: 3
Training loss: 2.2693843841552734
Validation loss: 1.9519728229891868

Epoch: 5| Step: 4
Training loss: 2.283112049102783
Validation loss: 1.9974443181868522

Epoch: 5| Step: 5
Training loss: 2.5259833335876465
Validation loss: 1.9615087893701368

Epoch: 5| Step: 6
Training loss: 2.39701771736145
Validation loss: 1.9868717501240392

Epoch: 5| Step: 7
Training loss: 1.923767328262329
Validation loss: 2.0093539555867515

Epoch: 5| Step: 8
Training loss: 1.78719961643219
Validation loss: 1.9896719327536962

Epoch: 5| Step: 9
Training loss: 2.1962082386016846
Validation loss: 2.0095093609184347

Epoch: 5| Step: 10
Training loss: 2.1169373989105225
Validation loss: 2.0051500425543836

Epoch: 134| Step: 0
Training loss: 1.9114545583724976
Validation loss: 1.9974208724114202

Epoch: 5| Step: 1
Training loss: 1.8221838474273682
Validation loss: 2.024699100884058

Epoch: 5| Step: 2
Training loss: 2.200836181640625
Validation loss: 1.9897893372402395

Epoch: 5| Step: 3
Training loss: 2.085514545440674
Validation loss: 1.9953473921745055

Epoch: 5| Step: 4
Training loss: 2.1174659729003906
Validation loss: 2.0074747993100073

Epoch: 5| Step: 5
Training loss: 2.401639223098755
Validation loss: 2.0130133833936465

Epoch: 5| Step: 6
Training loss: 2.2104063034057617
Validation loss: 1.9923430873501686

Epoch: 5| Step: 7
Training loss: 2.776268482208252
Validation loss: 1.9984530582222888

Epoch: 5| Step: 8
Training loss: 1.8400261402130127
Validation loss: 1.9995495311675533

Epoch: 5| Step: 9
Training loss: 2.1241047382354736
Validation loss: 1.986582706051488

Epoch: 5| Step: 10
Training loss: 2.2174556255340576
Validation loss: 1.9967688386158278

Epoch: 135| Step: 0
Training loss: 1.7310079336166382
Validation loss: 1.9829396752900974

Epoch: 5| Step: 1
Training loss: 2.2016024589538574
Validation loss: 1.9795649833576654

Epoch: 5| Step: 2
Training loss: 1.2618299722671509
Validation loss: 1.9804572674535936

Epoch: 5| Step: 3
Training loss: 1.8823802471160889
Validation loss: 1.9784448518547961

Epoch: 5| Step: 4
Training loss: 2.7554006576538086
Validation loss: 1.9848024383667977

Epoch: 5| Step: 5
Training loss: 1.9013713598251343
Validation loss: 2.002363681793213

Epoch: 5| Step: 6
Training loss: 2.4230740070343018
Validation loss: 1.9773925530013217

Epoch: 5| Step: 7
Training loss: 2.861569881439209
Validation loss: 1.9899481470866869

Epoch: 5| Step: 8
Training loss: 2.473543167114258
Validation loss: 1.9676887117406374

Epoch: 5| Step: 9
Training loss: 1.6731936931610107
Validation loss: 1.984797554631387

Epoch: 5| Step: 10
Training loss: 2.388706684112549
Validation loss: 2.006311588389899

Epoch: 136| Step: 0
Training loss: 2.63704252243042
Validation loss: 1.9965175813244236

Epoch: 5| Step: 1
Training loss: 1.9284690618515015
Validation loss: 1.9921815754264913

Epoch: 5| Step: 2
Training loss: 1.945962905883789
Validation loss: 2.0051906288311048

Epoch: 5| Step: 3
Training loss: 1.8951278924942017
Validation loss: 1.9975296515290455

Epoch: 5| Step: 4
Training loss: 2.0551671981811523
Validation loss: 1.9937145222899735

Epoch: 5| Step: 5
Training loss: 2.270601987838745
Validation loss: 1.9918548573729813

Epoch: 5| Step: 6
Training loss: 2.0632612705230713
Validation loss: 1.9933090517597813

Epoch: 5| Step: 7
Training loss: 1.8971284627914429
Validation loss: 1.9787459014564432

Epoch: 5| Step: 8
Training loss: 2.339846611022949
Validation loss: 1.9921220976819274

Epoch: 5| Step: 9
Training loss: 1.879520058631897
Validation loss: 1.9809202737705682

Epoch: 5| Step: 10
Training loss: 2.6134026050567627
Validation loss: 1.9992849339721024

Epoch: 137| Step: 0
Training loss: 1.663216233253479
Validation loss: 2.0081685922479116

Epoch: 5| Step: 1
Training loss: 2.1694674491882324
Validation loss: 1.9914010724713724

Epoch: 5| Step: 2
Training loss: 2.005042791366577
Validation loss: 1.9985494382919804

Epoch: 5| Step: 3
Training loss: 2.127652406692505
Validation loss: 1.986398809699602

Epoch: 5| Step: 4
Training loss: 2.4700143337249756
Validation loss: 1.9896207458229476

Epoch: 5| Step: 5
Training loss: 2.1354496479034424
Validation loss: 2.0155463385325607

Epoch: 5| Step: 6
Training loss: 2.1257376670837402
Validation loss: 2.021819619722264

Epoch: 5| Step: 7
Training loss: 1.7808802127838135
Validation loss: 2.005732455561238

Epoch: 5| Step: 8
Training loss: 2.227524518966675
Validation loss: 1.9926255544026692

Epoch: 5| Step: 9
Training loss: 2.873809337615967
Validation loss: 2.0062389168688046

Epoch: 5| Step: 10
Training loss: 1.9842214584350586
Validation loss: 1.99949860829179

Epoch: 138| Step: 0
Training loss: 2.4681756496429443
Validation loss: 1.9990943221635715

Epoch: 5| Step: 1
Training loss: 1.6018092632293701
Validation loss: 2.0139301002666516

Epoch: 5| Step: 2
Training loss: 2.4930872917175293
Validation loss: 2.0015246342587214

Epoch: 5| Step: 3
Training loss: 3.291400194168091
Validation loss: 1.9965407489448466

Epoch: 5| Step: 4
Training loss: 1.719874382019043
Validation loss: 2.0083309732457644

Epoch: 5| Step: 5
Training loss: 1.5328447818756104
Validation loss: 2.018080085836431

Epoch: 5| Step: 6
Training loss: 2.357764720916748
Validation loss: 1.9930308634235012

Epoch: 5| Step: 7
Training loss: 1.6779911518096924
Validation loss: 1.9977772287143174

Epoch: 5| Step: 8
Training loss: 1.9331061840057373
Validation loss: 2.0087877217159478

Epoch: 5| Step: 9
Training loss: 2.26002836227417
Validation loss: 2.0007968948733423

Epoch: 5| Step: 10
Training loss: 2.0896663665771484
Validation loss: 2.001920266817975

Epoch: 139| Step: 0
Training loss: 2.1587958335876465
Validation loss: 1.9922777311776274

Epoch: 5| Step: 1
Training loss: 2.1962978839874268
Validation loss: 2.012790197967201

Epoch: 5| Step: 2
Training loss: 1.5171853303909302
Validation loss: 2.0127284219188075

Epoch: 5| Step: 3
Training loss: 2.064410448074341
Validation loss: 2.0171952145074004

Epoch: 5| Step: 4
Training loss: 2.0331215858459473
Validation loss: 1.9825568660613029

Epoch: 5| Step: 5
Training loss: 2.4505465030670166
Validation loss: 1.9969636330040552

Epoch: 5| Step: 6
Training loss: 2.649653196334839
Validation loss: 2.001467543263589

Epoch: 5| Step: 7
Training loss: 2.7526471614837646
Validation loss: 1.971945943370942

Epoch: 5| Step: 8
Training loss: 2.068981409072876
Validation loss: 1.9998593227837675

Epoch: 5| Step: 9
Training loss: 1.8939567804336548
Validation loss: 2.0055175878668345

Epoch: 5| Step: 10
Training loss: 1.582363486289978
Validation loss: 1.990648352971641

Epoch: 140| Step: 0
Training loss: 2.14589524269104
Validation loss: 1.9857157661068825

Epoch: 5| Step: 1
Training loss: 2.1621041297912598
Validation loss: 1.97978522059738

Epoch: 5| Step: 2
Training loss: 2.35776948928833
Validation loss: 1.9828050521112257

Epoch: 5| Step: 3
Training loss: 2.2877697944641113
Validation loss: 1.9773640837720645

Epoch: 5| Step: 4
Training loss: 1.146496057510376
Validation loss: 1.988550942431214

Epoch: 5| Step: 5
Training loss: 2.255845546722412
Validation loss: 1.9910750824918029

Epoch: 5| Step: 6
Training loss: 1.555238127708435
Validation loss: 1.993780912891511

Epoch: 5| Step: 7
Training loss: 2.384638547897339
Validation loss: 1.970612564394551

Epoch: 5| Step: 8
Training loss: 2.1944289207458496
Validation loss: 1.9898107872214368

Epoch: 5| Step: 9
Training loss: 2.530338764190674
Validation loss: 1.9939303269950293

Epoch: 5| Step: 10
Training loss: 2.3406734466552734
Validation loss: 2.0057199411494757

Epoch: 141| Step: 0
Training loss: 2.430654525756836
Validation loss: 1.97742247837846

Epoch: 5| Step: 1
Training loss: 1.7023389339447021
Validation loss: 1.978861565230995

Epoch: 5| Step: 2
Training loss: 1.8368504047393799
Validation loss: 1.9845995415923416

Epoch: 5| Step: 3
Training loss: 1.9487285614013672
Validation loss: 1.9880137879361388

Epoch: 5| Step: 4
Training loss: 2.3294870853424072
Validation loss: 1.9994816574999081

Epoch: 5| Step: 5
Training loss: 2.106992483139038
Validation loss: 2.014184287799302

Epoch: 5| Step: 6
Training loss: 1.7263879776000977
Validation loss: 1.9911422344946093

Epoch: 5| Step: 7
Training loss: 2.517002582550049
Validation loss: 1.9789594834850681

Epoch: 5| Step: 8
Training loss: 2.751025438308716
Validation loss: 2.000631199088148

Epoch: 5| Step: 9
Training loss: 2.298017978668213
Validation loss: 1.977268829140612

Epoch: 5| Step: 10
Training loss: 1.7765161991119385
Validation loss: 1.9893123103726296

Epoch: 142| Step: 0
Training loss: 2.4400665760040283
Validation loss: 2.0119296594332625

Epoch: 5| Step: 1
Training loss: 2.0866782665252686
Validation loss: 1.9930851062138875

Epoch: 5| Step: 2
Training loss: 1.8845069408416748
Validation loss: 1.9862599590773224

Epoch: 5| Step: 3
Training loss: 2.411172389984131
Validation loss: 1.9898287480877292

Epoch: 5| Step: 4
Training loss: 2.345383405685425
Validation loss: 1.979500373204549

Epoch: 5| Step: 5
Training loss: 2.224182367324829
Validation loss: 2.009657303492228

Epoch: 5| Step: 6
Training loss: 2.2343995571136475
Validation loss: 2.0031107292380383

Epoch: 5| Step: 7
Training loss: 1.7802883386611938
Validation loss: 1.9969582083404704

Epoch: 5| Step: 8
Training loss: 2.1211190223693848
Validation loss: 1.9961469096522177

Epoch: 5| Step: 9
Training loss: 2.213651657104492
Validation loss: 1.969000667654058

Epoch: 5| Step: 10
Training loss: 1.6002473831176758
Validation loss: 1.9986022890255015

Epoch: 143| Step: 0
Training loss: 2.1813254356384277
Validation loss: 2.0005196397022535

Epoch: 5| Step: 1
Training loss: 1.8208039999008179
Validation loss: 1.9980118120870283

Epoch: 5| Step: 2
Training loss: 2.0011470317840576
Validation loss: 2.0360441823159494

Epoch: 5| Step: 3
Training loss: 2.7045738697052
Validation loss: 1.97783786507063

Epoch: 5| Step: 4
Training loss: 2.219379425048828
Validation loss: 1.9958224168387793

Epoch: 5| Step: 5
Training loss: 1.9330451488494873
Validation loss: 2.007602139185834

Epoch: 5| Step: 6
Training loss: 2.6855804920196533
Validation loss: 1.9914868852143646

Epoch: 5| Step: 7
Training loss: 2.485567569732666
Validation loss: 1.9993414237935057

Epoch: 5| Step: 8
Training loss: 1.681097388267517
Validation loss: 2.0163847554114556

Epoch: 5| Step: 9
Training loss: 1.5325849056243896
Validation loss: 1.9917780148085726

Epoch: 5| Step: 10
Training loss: 2.0058770179748535
Validation loss: 1.9878708085706156

Epoch: 144| Step: 0
Training loss: 2.0386574268341064
Validation loss: 2.0204441855030675

Epoch: 5| Step: 1
Training loss: 1.8823330402374268
Validation loss: 2.006042067722608

Epoch: 5| Step: 2
Training loss: 2.6687822341918945
Validation loss: 2.0051631568580546

Epoch: 5| Step: 3
Training loss: 1.9445921182632446
Validation loss: 1.9909929460094822

Epoch: 5| Step: 4
Training loss: 2.097600221633911
Validation loss: 1.9911034850664036

Epoch: 5| Step: 5
Training loss: 1.9839279651641846
Validation loss: 1.9995766660218597

Epoch: 5| Step: 6
Training loss: 2.0305731296539307
Validation loss: 2.0003840666945263

Epoch: 5| Step: 7
Training loss: 2.8671231269836426
Validation loss: 2.006746909951651

Epoch: 5| Step: 8
Training loss: 2.3341901302337646
Validation loss: 1.9892671287700694

Epoch: 5| Step: 9
Training loss: 2.050550937652588
Validation loss: 1.9911001702790618

Epoch: 5| Step: 10
Training loss: 1.4530960321426392
Validation loss: 1.9876921010273758

Epoch: 145| Step: 0
Training loss: 2.0677337646484375
Validation loss: 1.9737176356777069

Epoch: 5| Step: 1
Training loss: 1.7149770259857178
Validation loss: 1.9981743328032955

Epoch: 5| Step: 2
Training loss: 2.5567469596862793
Validation loss: 1.9951010827095277

Epoch: 5| Step: 3
Training loss: 2.52707839012146
Validation loss: 2.0074888980516823

Epoch: 5| Step: 4
Training loss: 2.4637486934661865
Validation loss: 1.9901609600231212

Epoch: 5| Step: 5
Training loss: 1.7585134506225586
Validation loss: 2.0134087326706096

Epoch: 5| Step: 6
Training loss: 1.961543083190918
Validation loss: 2.016527583522181

Epoch: 5| Step: 7
Training loss: 2.550142288208008
Validation loss: 2.0121357030765985

Epoch: 5| Step: 8
Training loss: 1.8104737997055054
Validation loss: 2.03149595568257

Epoch: 5| Step: 9
Training loss: 1.7945289611816406
Validation loss: 2.016147496879742

Epoch: 5| Step: 10
Training loss: 2.135725736618042
Validation loss: 2.0277334182493147

Epoch: 146| Step: 0
Training loss: 1.85736083984375
Validation loss: 1.9920100845316404

Epoch: 5| Step: 1
Training loss: 1.9781465530395508
Validation loss: 2.012225740699358

Epoch: 5| Step: 2
Training loss: 2.0385894775390625
Validation loss: 2.004592295615904

Epoch: 5| Step: 3
Training loss: 2.2009289264678955
Validation loss: 2.0095451057598157

Epoch: 5| Step: 4
Training loss: 2.6038196086883545
Validation loss: 2.0092315520009687

Epoch: 5| Step: 5
Training loss: 1.6165046691894531
Validation loss: 1.9922779567780033

Epoch: 5| Step: 6
Training loss: 1.720449447631836
Validation loss: 2.005697898967292

Epoch: 5| Step: 7
Training loss: 2.3503947257995605
Validation loss: 1.9980676686891945

Epoch: 5| Step: 8
Training loss: 2.7256388664245605
Validation loss: 1.9985288202121694

Epoch: 5| Step: 9
Training loss: 2.245584011077881
Validation loss: 1.9956420544655091

Epoch: 5| Step: 10
Training loss: 1.9728330373764038
Validation loss: 1.9803530272617136

Epoch: 147| Step: 0
Training loss: 1.7544384002685547
Validation loss: 1.9840218264569518

Epoch: 5| Step: 1
Training loss: 2.0793392658233643
Validation loss: 1.9863600115622244

Epoch: 5| Step: 2
Training loss: 2.051865577697754
Validation loss: 1.992964829168012

Epoch: 5| Step: 3
Training loss: 2.034531354904175
Validation loss: 1.9852330607752646

Epoch: 5| Step: 4
Training loss: 1.695835828781128
Validation loss: 1.9899986892618158

Epoch: 5| Step: 5
Training loss: 2.7298178672790527
Validation loss: 1.9852853410987443

Epoch: 5| Step: 6
Training loss: 2.2697196006774902
Validation loss: 2.002429855767117

Epoch: 5| Step: 7
Training loss: 2.3911914825439453
Validation loss: 1.976379753440939

Epoch: 5| Step: 8
Training loss: 2.5680975914001465
Validation loss: 1.9683827020788704

Epoch: 5| Step: 9
Training loss: 1.890753149986267
Validation loss: 1.9875186438201575

Epoch: 5| Step: 10
Training loss: 1.75187349319458
Validation loss: 1.977414656710881

Epoch: 148| Step: 0
Training loss: 1.5720512866973877
Validation loss: 1.9737886972324823

Epoch: 5| Step: 1
Training loss: 1.9287853240966797
Validation loss: 2.0097394015199397

Epoch: 5| Step: 2
Training loss: 2.3428611755371094
Validation loss: 1.9765411935826784

Epoch: 5| Step: 3
Training loss: 2.1778318881988525
Validation loss: 1.9971727376343102

Epoch: 5| Step: 4
Training loss: 2.057586193084717
Validation loss: 1.9688684401973602

Epoch: 5| Step: 5
Training loss: 2.192944049835205
Validation loss: 2.001291669825072

Epoch: 5| Step: 6
Training loss: 2.3711600303649902
Validation loss: 1.9562505432354507

Epoch: 5| Step: 7
Training loss: 2.343865394592285
Validation loss: 1.9697429992819344

Epoch: 5| Step: 8
Training loss: 2.3478145599365234
Validation loss: 1.9637343114422214

Epoch: 5| Step: 9
Training loss: 2.307425022125244
Validation loss: 1.9655939122681976

Epoch: 5| Step: 10
Training loss: 1.7067453861236572
Validation loss: 1.9715377476907545

Epoch: 149| Step: 0
Training loss: 2.1285793781280518
Validation loss: 1.9583540283223635

Epoch: 5| Step: 1
Training loss: 2.017533540725708
Validation loss: 1.977131369293377

Epoch: 5| Step: 2
Training loss: 2.8513967990875244
Validation loss: 1.9827721695746146

Epoch: 5| Step: 3
Training loss: 1.751213788986206
Validation loss: 1.9780710820228822

Epoch: 5| Step: 4
Training loss: 1.217588186264038
Validation loss: 1.9787163926709084

Epoch: 5| Step: 5
Training loss: 2.4352915287017822
Validation loss: 1.9897333447651198

Epoch: 5| Step: 6
Training loss: 1.9968467950820923
Validation loss: 1.9643187112705682

Epoch: 5| Step: 7
Training loss: 1.9939956665039062
Validation loss: 1.988350745170347

Epoch: 5| Step: 8
Training loss: 2.6756999492645264
Validation loss: 1.9900184036583028

Epoch: 5| Step: 9
Training loss: 2.0053555965423584
Validation loss: 1.9920081553920623

Epoch: 5| Step: 10
Training loss: 2.099816083908081
Validation loss: 1.967232975908505

Epoch: 150| Step: 0
Training loss: 2.0521655082702637
Validation loss: 1.9771260881936679

Epoch: 5| Step: 1
Training loss: 2.406881809234619
Validation loss: 2.0150473374192432

Epoch: 5| Step: 2
Training loss: 2.228715181350708
Validation loss: 1.989369648759083

Epoch: 5| Step: 3
Training loss: 2.3019866943359375
Validation loss: 1.98001318464997

Epoch: 5| Step: 4
Training loss: 1.798378348350525
Validation loss: 2.0043127844410558

Epoch: 5| Step: 5
Training loss: 2.220820903778076
Validation loss: 1.9946339745675363

Epoch: 5| Step: 6
Training loss: 2.5470452308654785
Validation loss: 1.9890725330639911

Epoch: 5| Step: 7
Training loss: 1.8938194513320923
Validation loss: 1.9981030238571988

Epoch: 5| Step: 8
Training loss: 2.1156327724456787
Validation loss: 1.9900763342457433

Epoch: 5| Step: 9
Training loss: 1.4522333145141602
Validation loss: 2.026663416175432

Epoch: 5| Step: 10
Training loss: 2.2679176330566406
Validation loss: 1.9992735334621963

Epoch: 151| Step: 0
Training loss: 1.6358387470245361
Validation loss: 2.002182763109925

Epoch: 5| Step: 1
Training loss: 2.588345766067505
Validation loss: 2.0105861412581576

Epoch: 5| Step: 2
Training loss: 2.1935880184173584
Validation loss: 1.9999068193538214

Epoch: 5| Step: 3
Training loss: 2.3053176403045654
Validation loss: 1.998503141505744

Epoch: 5| Step: 4
Training loss: 2.045490264892578
Validation loss: 1.993780138672039

Epoch: 5| Step: 5
Training loss: 1.7202203273773193
Validation loss: 2.0112090572234123

Epoch: 5| Step: 6
Training loss: 1.8274682760238647
Validation loss: 1.995404642115357

Epoch: 5| Step: 7
Training loss: 2.082099437713623
Validation loss: 2.0014212977501655

Epoch: 5| Step: 8
Training loss: 1.694756269454956
Validation loss: 2.0103006029641755

Epoch: 5| Step: 9
Training loss: 2.9668593406677246
Validation loss: 1.9837743774537118

Epoch: 5| Step: 10
Training loss: 2.336446762084961
Validation loss: 2.004752251409715

Epoch: 152| Step: 0
Training loss: 2.5007920265197754
Validation loss: 1.993318312911577

Epoch: 5| Step: 1
Training loss: 1.9586553573608398
Validation loss: 1.9854761400530416

Epoch: 5| Step: 2
Training loss: 1.8376438617706299
Validation loss: 2.005796536322563

Epoch: 5| Step: 3
Training loss: 1.8657420873641968
Validation loss: 2.021587660235743

Epoch: 5| Step: 4
Training loss: 1.7476593255996704
Validation loss: 2.0000091470697874

Epoch: 5| Step: 5
Training loss: 2.2263388633728027
Validation loss: 2.0165681057078864

Epoch: 5| Step: 6
Training loss: 1.8574764728546143
Validation loss: 2.026844396386095

Epoch: 5| Step: 7
Training loss: 1.9701656103134155
Validation loss: 2.0001370432556316

Epoch: 5| Step: 8
Training loss: 2.0984084606170654
Validation loss: 2.012866181711997

Epoch: 5| Step: 9
Training loss: 2.7043538093566895
Validation loss: 2.0115956465403237

Epoch: 5| Step: 10
Training loss: 2.399012327194214
Validation loss: 1.9836645972344182

Epoch: 153| Step: 0
Training loss: 2.019686460494995
Validation loss: 1.9972888859369422

Epoch: 5| Step: 1
Training loss: 2.540067672729492
Validation loss: 2.0200259198424635

Epoch: 5| Step: 2
Training loss: 2.114208221435547
Validation loss: 2.0361848492776193

Epoch: 5| Step: 3
Training loss: 1.5073071718215942
Validation loss: 2.0197630569499028

Epoch: 5| Step: 4
Training loss: 2.515165328979492
Validation loss: 2.004631245008079

Epoch: 5| Step: 5
Training loss: 1.9544150829315186
Validation loss: 2.000884641883194

Epoch: 5| Step: 6
Training loss: 1.9039642810821533
Validation loss: 1.9795163216129426

Epoch: 5| Step: 7
Training loss: 1.3300195932388306
Validation loss: 1.989138477592058

Epoch: 5| Step: 8
Training loss: 2.170518398284912
Validation loss: 2.010042243106391

Epoch: 5| Step: 9
Training loss: 1.942461371421814
Validation loss: 2.003957907358805

Epoch: 5| Step: 10
Training loss: 3.250328540802002
Validation loss: 1.9889741815546507

Epoch: 154| Step: 0
Training loss: 1.8108494281768799
Validation loss: 1.998752942649267

Epoch: 5| Step: 1
Training loss: 1.9594752788543701
Validation loss: 1.9913889387602448

Epoch: 5| Step: 2
Training loss: 1.9860624074935913
Validation loss: 1.9882614202396844

Epoch: 5| Step: 3
Training loss: 2.1180484294891357
Validation loss: 1.9965011432606687

Epoch: 5| Step: 4
Training loss: 2.0543715953826904
Validation loss: 1.997090583206505

Epoch: 5| Step: 5
Training loss: 2.345055103302002
Validation loss: 1.977891058050176

Epoch: 5| Step: 6
Training loss: 2.327143669128418
Validation loss: 2.013989169110534

Epoch: 5| Step: 7
Training loss: 2.2351880073547363
Validation loss: 1.9945245148033224

Epoch: 5| Step: 8
Training loss: 1.8301407098770142
Validation loss: 1.9978633157668575

Epoch: 5| Step: 9
Training loss: 2.5738582611083984
Validation loss: 1.9752691509903118

Epoch: 5| Step: 10
Training loss: 2.020641565322876
Validation loss: 1.995209732363301

Epoch: 155| Step: 0
Training loss: 1.8735910654067993
Validation loss: 1.9853268079860236

Epoch: 5| Step: 1
Training loss: 2.45082688331604
Validation loss: 1.985825773208372

Epoch: 5| Step: 2
Training loss: 2.4420039653778076
Validation loss: 2.0008219749696794

Epoch: 5| Step: 3
Training loss: 1.9413788318634033
Validation loss: 1.9996227615623063

Epoch: 5| Step: 4
Training loss: 2.074687957763672
Validation loss: 1.992023532108594

Epoch: 5| Step: 5
Training loss: 2.40126371383667
Validation loss: 1.9771767188143987

Epoch: 5| Step: 6
Training loss: 2.6263747215270996
Validation loss: 1.9614191478298557

Epoch: 5| Step: 7
Training loss: 1.997693657875061
Validation loss: 1.98738694190979

Epoch: 5| Step: 8
Training loss: 2.264857769012451
Validation loss: 1.9971099361296623

Epoch: 5| Step: 9
Training loss: 1.1823948621749878
Validation loss: 1.9991521168780584

Epoch: 5| Step: 10
Training loss: 1.9967765808105469
Validation loss: 2.0081469397391043

Epoch: 156| Step: 0
Training loss: 1.9633347988128662
Validation loss: 1.9939650604801793

Epoch: 5| Step: 1
Training loss: 2.4829978942871094
Validation loss: 2.010463337744436

Epoch: 5| Step: 2
Training loss: 2.87868070602417
Validation loss: 1.991047869446457

Epoch: 5| Step: 3
Training loss: 1.9813731908798218
Validation loss: 1.9986708279578917

Epoch: 5| Step: 4
Training loss: 2.1619818210601807
Validation loss: 2.0200688890231553

Epoch: 5| Step: 5
Training loss: 1.7317206859588623
Validation loss: 2.009843081556341

Epoch: 5| Step: 6
Training loss: 1.675286054611206
Validation loss: 2.0386477452452465

Epoch: 5| Step: 7
Training loss: 2.0432448387145996
Validation loss: 2.0191223083003873

Epoch: 5| Step: 8
Training loss: 2.1909563541412354
Validation loss: 2.0268012285232544

Epoch: 5| Step: 9
Training loss: 2.0351033210754395
Validation loss: 2.0172340959630986

Epoch: 5| Step: 10
Training loss: 1.9128451347351074
Validation loss: 1.9951103400158625

Epoch: 157| Step: 0
Training loss: 2.5202131271362305
Validation loss: 2.0180859129915953

Epoch: 5| Step: 1
Training loss: 2.449904203414917
Validation loss: 2.003020119923417

Epoch: 5| Step: 2
Training loss: 2.7379586696624756
Validation loss: 1.994349310475011

Epoch: 5| Step: 3
Training loss: 1.4593182802200317
Validation loss: 2.0114949672452864

Epoch: 5| Step: 4
Training loss: 1.7076399326324463
Validation loss: 2.0066520526844966

Epoch: 5| Step: 5
Training loss: 2.1501259803771973
Validation loss: 1.9860895449115383

Epoch: 5| Step: 6
Training loss: 1.7933794260025024
Validation loss: 1.9982336336566555

Epoch: 5| Step: 7
Training loss: 2.279176712036133
Validation loss: 2.004381315682524

Epoch: 5| Step: 8
Training loss: 1.6212642192840576
Validation loss: 2.011449795897289

Epoch: 5| Step: 9
Training loss: 2.1535091400146484
Validation loss: 2.0093473901030836

Epoch: 5| Step: 10
Training loss: 2.3458502292633057
Validation loss: 2.004905510974187

Epoch: 158| Step: 0
Training loss: 2.269284725189209
Validation loss: 1.9639871056361864

Epoch: 5| Step: 1
Training loss: 2.531670093536377
Validation loss: 1.9830297705947713

Epoch: 5| Step: 2
Training loss: 1.8833370208740234
Validation loss: 1.9897757422539495

Epoch: 5| Step: 3
Training loss: 2.1933836936950684
Validation loss: 1.9917649222958473

Epoch: 5| Step: 4
Training loss: 2.171783447265625
Validation loss: 1.9976645233810588

Epoch: 5| Step: 5
Training loss: 1.6123253107070923
Validation loss: 2.00394146801323

Epoch: 5| Step: 6
Training loss: 2.1418232917785645
Validation loss: 2.01327585276737

Epoch: 5| Step: 7
Training loss: 1.8430023193359375
Validation loss: 2.009387266251349

Epoch: 5| Step: 8
Training loss: 2.2123286724090576
Validation loss: 1.9901438887401293

Epoch: 5| Step: 9
Training loss: 1.7775119543075562
Validation loss: 2.0035736201911845

Epoch: 5| Step: 10
Training loss: 2.6370208263397217
Validation loss: 2.005466612436438

Epoch: 159| Step: 0
Training loss: 2.0976834297180176
Validation loss: 2.005835989470123

Epoch: 5| Step: 1
Training loss: 2.563316822052002
Validation loss: 2.0009748140970864

Epoch: 5| Step: 2
Training loss: 1.367042899131775
Validation loss: 1.994723395634723

Epoch: 5| Step: 3
Training loss: 1.6745325326919556
Validation loss: 1.9778107853345974

Epoch: 5| Step: 4
Training loss: 2.33699107170105
Validation loss: 2.0120077876634497

Epoch: 5| Step: 5
Training loss: 2.753829002380371
Validation loss: 1.9693119449000205

Epoch: 5| Step: 6
Training loss: 1.9520601034164429
Validation loss: 1.9907495052583757

Epoch: 5| Step: 7
Training loss: 1.7121906280517578
Validation loss: 2.003157182406354

Epoch: 5| Step: 8
Training loss: 1.9043395519256592
Validation loss: 1.990605362000004

Epoch: 5| Step: 9
Training loss: 2.5235893726348877
Validation loss: 2.0174648748931063

Epoch: 5| Step: 10
Training loss: 2.095806837081909
Validation loss: 2.022849016292121

Epoch: 160| Step: 0
Training loss: 2.184893846511841
Validation loss: 1.9817701885777135

Epoch: 5| Step: 1
Training loss: 1.9245141744613647
Validation loss: 1.9926070628627655

Epoch: 5| Step: 2
Training loss: 1.9682420492172241
Validation loss: 1.9886913376469766

Epoch: 5| Step: 3
Training loss: 2.774014949798584
Validation loss: 2.013286511103312

Epoch: 5| Step: 4
Training loss: 1.6733325719833374
Validation loss: 2.0273291603211434

Epoch: 5| Step: 5
Training loss: 2.2624411582946777
Validation loss: 1.9986506585151917

Epoch: 5| Step: 6
Training loss: 1.6734936237335205
Validation loss: 2.02876813180985

Epoch: 5| Step: 7
Training loss: 2.113693952560425
Validation loss: 2.00213949782874

Epoch: 5| Step: 8
Training loss: 2.310516357421875
Validation loss: 1.9950044693485383

Epoch: 5| Step: 9
Training loss: 2.3555755615234375
Validation loss: 2.022293963739949

Epoch: 5| Step: 10
Training loss: 1.8320775032043457
Validation loss: 1.9861127894411805

Epoch: 161| Step: 0
Training loss: 2.187471866607666
Validation loss: 2.0166040287222913

Epoch: 5| Step: 1
Training loss: 1.5514569282531738
Validation loss: 2.0211794248191257

Epoch: 5| Step: 2
Training loss: 2.058173656463623
Validation loss: 1.9850427002035163

Epoch: 5| Step: 3
Training loss: 2.025773525238037
Validation loss: 1.9934688537351546

Epoch: 5| Step: 4
Training loss: 1.8336803913116455
Validation loss: 1.9839711061087988

Epoch: 5| Step: 5
Training loss: 2.4213857650756836
Validation loss: 2.0168036312185307

Epoch: 5| Step: 6
Training loss: 2.2607879638671875
Validation loss: 1.9972054496888192

Epoch: 5| Step: 7
Training loss: 2.281292200088501
Validation loss: 1.992988806898876

Epoch: 5| Step: 8
Training loss: 2.0101542472839355
Validation loss: 1.9919496736218851

Epoch: 5| Step: 9
Training loss: 2.1753621101379395
Validation loss: 1.9956376424399755

Epoch: 5| Step: 10
Training loss: 2.362306594848633
Validation loss: 2.007150214205506

Epoch: 162| Step: 0
Training loss: 2.5742568969726562
Validation loss: 1.9880740360547138

Epoch: 5| Step: 1
Training loss: 1.7167160511016846
Validation loss: 1.9926622606092883

Epoch: 5| Step: 2
Training loss: 1.9822533130645752
Validation loss: 1.9950194833099202

Epoch: 5| Step: 3
Training loss: 1.5511720180511475
Validation loss: 2.001148485368298

Epoch: 5| Step: 4
Training loss: 2.9012036323547363
Validation loss: 2.0107898199430077

Epoch: 5| Step: 5
Training loss: 1.8742849826812744
Validation loss: 2.0060130075741838

Epoch: 5| Step: 6
Training loss: 2.2556703090667725
Validation loss: 2.007729088106463

Epoch: 5| Step: 7
Training loss: 1.3580163717269897
Validation loss: 2.0137670283676474

Epoch: 5| Step: 8
Training loss: 2.5685195922851562
Validation loss: 1.9939207671790995

Epoch: 5| Step: 9
Training loss: 2.2211289405822754
Validation loss: 1.9988776445388794

Epoch: 5| Step: 10
Training loss: 2.1995606422424316
Validation loss: 1.9909958993234942

Epoch: 163| Step: 0
Training loss: 1.6879041194915771
Validation loss: 1.99577485874135

Epoch: 5| Step: 1
Training loss: 2.4599368572235107
Validation loss: 1.9977959830273864

Epoch: 5| Step: 2
Training loss: 2.0678391456604004
Validation loss: 2.001727477196724

Epoch: 5| Step: 3
Training loss: 1.7796735763549805
Validation loss: 1.9904246073897167

Epoch: 5| Step: 4
Training loss: 2.061601161956787
Validation loss: 1.9881513349471553

Epoch: 5| Step: 5
Training loss: 1.7749592065811157
Validation loss: 1.9648996142930881

Epoch: 5| Step: 6
Training loss: 2.279308795928955
Validation loss: 1.9921184598758657

Epoch: 5| Step: 7
Training loss: 2.015655040740967
Validation loss: 1.996859062102533

Epoch: 5| Step: 8
Training loss: 2.815129041671753
Validation loss: 1.9923475993576871

Epoch: 5| Step: 9
Training loss: 2.358942747116089
Validation loss: 1.978917101378082

Epoch: 5| Step: 10
Training loss: 1.6795529127120972
Validation loss: 2.0134248656611287

Epoch: 164| Step: 0
Training loss: 2.698146104812622
Validation loss: 2.008799114534932

Epoch: 5| Step: 1
Training loss: 2.2339065074920654
Validation loss: 1.9816049068204817

Epoch: 5| Step: 2
Training loss: 1.5640857219696045
Validation loss: 2.0080252898636686

Epoch: 5| Step: 3
Training loss: 2.268433094024658
Validation loss: 2.003210973995988

Epoch: 5| Step: 4
Training loss: 1.74163019657135
Validation loss: 1.992607988337035

Epoch: 5| Step: 5
Training loss: 2.4012451171875
Validation loss: 2.0140148644806235

Epoch: 5| Step: 6
Training loss: 1.7361361980438232
Validation loss: 1.9976307192156393

Epoch: 5| Step: 7
Training loss: 2.059792995452881
Validation loss: 1.9979306715790943

Epoch: 5| Step: 8
Training loss: 1.9090051651000977
Validation loss: 1.9978697940867434

Epoch: 5| Step: 9
Training loss: 2.2324838638305664
Validation loss: 1.9930278152547858

Epoch: 5| Step: 10
Training loss: 2.123800039291382
Validation loss: 1.986610399779453

Epoch: 165| Step: 0
Training loss: 2.0620148181915283
Validation loss: 2.0026821974785096

Epoch: 5| Step: 1
Training loss: 2.36397123336792
Validation loss: 2.0047129264441867

Epoch: 5| Step: 2
Training loss: 2.2825710773468018
Validation loss: 1.9705065963088826

Epoch: 5| Step: 3
Training loss: 1.7620723247528076
Validation loss: 2.0081790121652747

Epoch: 5| Step: 4
Training loss: 1.9969850778579712
Validation loss: 1.9983027365899855

Epoch: 5| Step: 5
Training loss: 2.236158609390259
Validation loss: 1.9811614431360716

Epoch: 5| Step: 6
Training loss: 2.2748665809631348
Validation loss: 2.0046503082398446

Epoch: 5| Step: 7
Training loss: 2.360776424407959
Validation loss: 1.9940535842731435

Epoch: 5| Step: 8
Training loss: 1.795127272605896
Validation loss: 1.9739290539936354

Epoch: 5| Step: 9
Training loss: 1.7994630336761475
Validation loss: 2.0016515203701553

Epoch: 5| Step: 10
Training loss: 2.023350238800049
Validation loss: 2.000037926499562

Epoch: 166| Step: 0
Training loss: 1.884108543395996
Validation loss: 2.0165932998862317

Epoch: 5| Step: 1
Training loss: 2.321582317352295
Validation loss: 1.996304714551536

Epoch: 5| Step: 2
Training loss: 1.9319791793823242
Validation loss: 1.972491325870637

Epoch: 5| Step: 3
Training loss: 2.131922483444214
Validation loss: 1.9686730651445286

Epoch: 5| Step: 4
Training loss: 2.0248751640319824
Validation loss: 1.9894128358492287

Epoch: 5| Step: 5
Training loss: 1.7265510559082031
Validation loss: 1.999401137393008

Epoch: 5| Step: 6
Training loss: 1.906232476234436
Validation loss: 1.9946919884732974

Epoch: 5| Step: 7
Training loss: 2.1073760986328125
Validation loss: 1.9713396000605758

Epoch: 5| Step: 8
Training loss: 2.0601353645324707
Validation loss: 1.974200310245637

Epoch: 5| Step: 9
Training loss: 2.666724681854248
Validation loss: 1.9897974332173665

Epoch: 5| Step: 10
Training loss: 2.3766062259674072
Validation loss: 2.0082834766757105

Epoch: 167| Step: 0
Training loss: 2.0876049995422363
Validation loss: 1.9919606152401175

Epoch: 5| Step: 1
Training loss: 2.691502332687378
Validation loss: 1.9909892107850762

Epoch: 5| Step: 2
Training loss: 1.3615652322769165
Validation loss: 1.9833269055171678

Epoch: 5| Step: 3
Training loss: 1.8532482385635376
Validation loss: 1.9800325952550417

Epoch: 5| Step: 4
Training loss: 2.420757532119751
Validation loss: 1.9851116723911737

Epoch: 5| Step: 5
Training loss: 2.0242371559143066
Validation loss: 1.9791840635320193

Epoch: 5| Step: 6
Training loss: 1.8829482793807983
Validation loss: 1.9864244794332853

Epoch: 5| Step: 7
Training loss: 2.1267991065979004
Validation loss: 1.981628179550171

Epoch: 5| Step: 8
Training loss: 2.16458797454834
Validation loss: 1.971897622590424

Epoch: 5| Step: 9
Training loss: 2.3398277759552
Validation loss: 1.9825209648378435

Epoch: 5| Step: 10
Training loss: 1.974241852760315
Validation loss: 1.987834943238125

Epoch: 168| Step: 0
Training loss: 2.366269588470459
Validation loss: 1.9757493336995442

Epoch: 5| Step: 1
Training loss: 2.179810047149658
Validation loss: 2.00402892533169

Epoch: 5| Step: 2
Training loss: 1.644290566444397
Validation loss: 1.9909356870958883

Epoch: 5| Step: 3
Training loss: 2.831587314605713
Validation loss: 1.9882916635082615

Epoch: 5| Step: 4
Training loss: 2.2233479022979736
Validation loss: 1.9869476928505847

Epoch: 5| Step: 5
Training loss: 2.068272113800049
Validation loss: 1.9919688714447843

Epoch: 5| Step: 6
Training loss: 1.6984455585479736
Validation loss: 1.99953753717484

Epoch: 5| Step: 7
Training loss: 2.070026397705078
Validation loss: 2.002101318810576

Epoch: 5| Step: 8
Training loss: 2.1888415813446045
Validation loss: 1.9780154676847561

Epoch: 5| Step: 9
Training loss: 1.7911255359649658
Validation loss: 1.9998371421649892

Epoch: 5| Step: 10
Training loss: 1.781945824623108
Validation loss: 2.003290340464602

Epoch: 169| Step: 0
Training loss: 1.574860692024231
Validation loss: 2.00160841659833

Epoch: 5| Step: 1
Training loss: 1.7110950946807861
Validation loss: 1.9880955398723643

Epoch: 5| Step: 2
Training loss: 2.154273509979248
Validation loss: 1.990179286208204

Epoch: 5| Step: 3
Training loss: 2.076540231704712
Validation loss: 1.9903644592531267

Epoch: 5| Step: 4
Training loss: 2.5949459075927734
Validation loss: 1.9811785003190399

Epoch: 5| Step: 5
Training loss: 1.8442528247833252
Validation loss: 1.9798634513731925

Epoch: 5| Step: 6
Training loss: 1.590592384338379
Validation loss: 1.999125442197246

Epoch: 5| Step: 7
Training loss: 1.866278886795044
Validation loss: 1.9727103133355417

Epoch: 5| Step: 8
Training loss: 2.454561710357666
Validation loss: 1.9885482659903906

Epoch: 5| Step: 9
Training loss: 2.6521711349487305
Validation loss: 2.000162401506978

Epoch: 5| Step: 10
Training loss: 2.4238107204437256
Validation loss: 1.9704017472523514

Epoch: 170| Step: 0
Training loss: 2.832061767578125
Validation loss: 1.979752730297786

Epoch: 5| Step: 1
Training loss: 2.05666446685791
Validation loss: 1.9735045676590295

Epoch: 5| Step: 2
Training loss: 2.023979902267456
Validation loss: 1.9815383688096078

Epoch: 5| Step: 3
Training loss: 1.5967488288879395
Validation loss: 2.0028902202524166

Epoch: 5| Step: 4
Training loss: 2.4094481468200684
Validation loss: 1.9885578309336016

Epoch: 5| Step: 5
Training loss: 1.7850873470306396
Validation loss: 1.9650645948225451

Epoch: 5| Step: 6
Training loss: 2.2549450397491455
Validation loss: 1.988788022789904

Epoch: 5| Step: 7
Training loss: 2.2204861640930176
Validation loss: 1.9684406429208734

Epoch: 5| Step: 8
Training loss: 1.8990437984466553
Validation loss: 1.9710334077958138

Epoch: 5| Step: 9
Training loss: 1.933314561843872
Validation loss: 1.9792995273426015

Epoch: 5| Step: 10
Training loss: 1.780041217803955
Validation loss: 1.9856189168909544

Epoch: 171| Step: 0
Training loss: 1.93813157081604
Validation loss: 1.9796031418667044

Epoch: 5| Step: 1
Training loss: 1.8268928527832031
Validation loss: 1.9884024845656527

Epoch: 5| Step: 2
Training loss: 2.4595086574554443
Validation loss: 1.969152735125634

Epoch: 5| Step: 3
Training loss: 2.231285333633423
Validation loss: 1.9894222879922518

Epoch: 5| Step: 4
Training loss: 2.0364506244659424
Validation loss: 1.988428520899947

Epoch: 5| Step: 5
Training loss: 2.044586181640625
Validation loss: 1.9964339604941748

Epoch: 5| Step: 6
Training loss: 1.4842764139175415
Validation loss: 1.9802058601892123

Epoch: 5| Step: 7
Training loss: 2.2034666538238525
Validation loss: 1.973094577430397

Epoch: 5| Step: 8
Training loss: 1.9783862829208374
Validation loss: 1.9874036081375615

Epoch: 5| Step: 9
Training loss: 2.3798305988311768
Validation loss: 1.9990388988166727

Epoch: 5| Step: 10
Training loss: 2.2711174488067627
Validation loss: 1.99071196586855

Epoch: 172| Step: 0
Training loss: 2.0117435455322266
Validation loss: 1.992135376058599

Epoch: 5| Step: 1
Training loss: 1.9435899257659912
Validation loss: 2.0068297027259745

Epoch: 5| Step: 2
Training loss: 1.6479480266571045
Validation loss: 1.998947230718469

Epoch: 5| Step: 3
Training loss: 2.2046005725860596
Validation loss: 1.9848510552478094

Epoch: 5| Step: 4
Training loss: 2.0313496589660645
Validation loss: 1.999352926849037

Epoch: 5| Step: 5
Training loss: 2.3087029457092285
Validation loss: 1.9847569619455645

Epoch: 5| Step: 6
Training loss: 1.9836161136627197
Validation loss: 2.0098045461921283

Epoch: 5| Step: 7
Training loss: 2.448767900466919
Validation loss: 2.023379886022178

Epoch: 5| Step: 8
Training loss: 2.163424253463745
Validation loss: 2.0021073843843196

Epoch: 5| Step: 9
Training loss: 1.9175140857696533
Validation loss: 2.0043632215069187

Epoch: 5| Step: 10
Training loss: 2.151615619659424
Validation loss: 1.9943984439296107

Epoch: 173| Step: 0
Training loss: 1.923492193222046
Validation loss: 2.0099415394567672

Epoch: 5| Step: 1
Training loss: 2.3033175468444824
Validation loss: 2.00852862352966

Epoch: 5| Step: 2
Training loss: 2.457484006881714
Validation loss: 2.0172026003560712

Epoch: 5| Step: 3
Training loss: 2.391864538192749
Validation loss: 2.016173324277324

Epoch: 5| Step: 4
Training loss: 2.204801082611084
Validation loss: 2.020377580837537

Epoch: 5| Step: 5
Training loss: 2.0525784492492676
Validation loss: 2.0167677838315248

Epoch: 5| Step: 6
Training loss: 2.1438825130462646
Validation loss: 2.0030947513477777

Epoch: 5| Step: 7
Training loss: 1.6458733081817627
Validation loss: 2.0037305047435146

Epoch: 5| Step: 8
Training loss: 2.005692481994629
Validation loss: 1.9965693617379794

Epoch: 5| Step: 9
Training loss: 1.6989037990570068
Validation loss: 2.0123178561528525

Epoch: 5| Step: 10
Training loss: 1.8746259212493896
Validation loss: 1.9830579244962303

Epoch: 174| Step: 0
Training loss: 2.080275774002075
Validation loss: 1.9888748943164785

Epoch: 5| Step: 1
Training loss: 1.6835601329803467
Validation loss: 1.979800367868075

Epoch: 5| Step: 2
Training loss: 2.493116855621338
Validation loss: 1.9855474630991619

Epoch: 5| Step: 3
Training loss: 1.7192710638046265
Validation loss: 1.9947953519000803

Epoch: 5| Step: 4
Training loss: 2.394423723220825
Validation loss: 1.9928994486408849

Epoch: 5| Step: 5
Training loss: 2.2477035522460938
Validation loss: 1.97628205309632

Epoch: 5| Step: 6
Training loss: 1.4068095684051514
Validation loss: 2.0097462438767955

Epoch: 5| Step: 7
Training loss: 2.495344877243042
Validation loss: 2.0064905561426634

Epoch: 5| Step: 8
Training loss: 1.3407093286514282
Validation loss: 1.9921037163785709

Epoch: 5| Step: 9
Training loss: 2.303593873977661
Validation loss: 1.9943172906034736

Epoch: 5| Step: 10
Training loss: 2.8829915523529053
Validation loss: 1.9778166201806837

Epoch: 175| Step: 0
Training loss: 2.2986111640930176
Validation loss: 1.995711903418264

Epoch: 5| Step: 1
Training loss: 2.7166781425476074
Validation loss: 2.017987907573741

Epoch: 5| Step: 2
Training loss: 1.6352545022964478
Validation loss: 1.9863699636151713

Epoch: 5| Step: 3
Training loss: 2.6598422527313232
Validation loss: 2.0067808102535944

Epoch: 5| Step: 4
Training loss: 2.019392490386963
Validation loss: 1.9802145778491933

Epoch: 5| Step: 5
Training loss: 2.163123607635498
Validation loss: 1.987904380726558

Epoch: 5| Step: 6
Training loss: 1.4594829082489014
Validation loss: 1.9839309928237752

Epoch: 5| Step: 7
Training loss: 2.135673761367798
Validation loss: 1.991303777181974

Epoch: 5| Step: 8
Training loss: 2.477731704711914
Validation loss: 1.996876698668285

Epoch: 5| Step: 9
Training loss: 1.3629471063613892
Validation loss: 1.9948459799571703

Epoch: 5| Step: 10
Training loss: 1.9435144662857056
Validation loss: 2.0245058997984855

Epoch: 176| Step: 0
Training loss: 1.647448182106018
Validation loss: 1.9992419327459028

Epoch: 5| Step: 1
Training loss: 2.488337278366089
Validation loss: 2.00625229266382

Epoch: 5| Step: 2
Training loss: 2.0398566722869873
Validation loss: 1.9697417930890155

Epoch: 5| Step: 3
Training loss: 1.5760447978973389
Validation loss: 2.0016906607535576

Epoch: 5| Step: 4
Training loss: 1.6695703268051147
Validation loss: 1.9798274706768733

Epoch: 5| Step: 5
Training loss: 2.2329933643341064
Validation loss: 2.00010524770265

Epoch: 5| Step: 6
Training loss: 2.3055777549743652
Validation loss: 2.0001989180041897

Epoch: 5| Step: 7
Training loss: 2.2404491901397705
Validation loss: 1.9666205042151994

Epoch: 5| Step: 8
Training loss: 2.0878653526306152
Validation loss: 1.9756815125865321

Epoch: 5| Step: 9
Training loss: 2.1844966411590576
Validation loss: 1.9985150444892146

Epoch: 5| Step: 10
Training loss: 2.189326763153076
Validation loss: 1.994299998847387

Epoch: 177| Step: 0
Training loss: 1.8128429651260376
Validation loss: 1.97358718738761

Epoch: 5| Step: 1
Training loss: 2.471328020095825
Validation loss: 1.9818224727466542

Epoch: 5| Step: 2
Training loss: 1.9917339086532593
Validation loss: 1.9812054300820956

Epoch: 5| Step: 3
Training loss: 1.898796796798706
Validation loss: 2.0028361171804447

Epoch: 5| Step: 4
Training loss: 2.1369121074676514
Validation loss: 2.0225792225971015

Epoch: 5| Step: 5
Training loss: 2.1083922386169434
Validation loss: 1.9760395814013738

Epoch: 5| Step: 6
Training loss: 2.1452584266662598
Validation loss: 2.006438283510106

Epoch: 5| Step: 7
Training loss: 2.1486449241638184
Validation loss: 1.9889109634583997

Epoch: 5| Step: 8
Training loss: 1.5627148151397705
Validation loss: 2.0155472422158844

Epoch: 5| Step: 9
Training loss: 2.232673168182373
Validation loss: 2.001153161448817

Epoch: 5| Step: 10
Training loss: 2.1252684593200684
Validation loss: 2.0094972938619633

Epoch: 178| Step: 0
Training loss: 1.9773807525634766
Validation loss: 1.9733519951502483

Epoch: 5| Step: 1
Training loss: 1.6759637594223022
Validation loss: 1.9585374222006848

Epoch: 5| Step: 2
Training loss: 1.6623623371124268
Validation loss: 2.0029629148462766

Epoch: 5| Step: 3
Training loss: 2.0804121494293213
Validation loss: 1.976707608469071

Epoch: 5| Step: 4
Training loss: 1.9636625051498413
Validation loss: 1.994547705496511

Epoch: 5| Step: 5
Training loss: 1.9277775287628174
Validation loss: 1.9762309238474856

Epoch: 5| Step: 6
Training loss: 2.1642346382141113
Validation loss: 1.9839431278167232

Epoch: 5| Step: 7
Training loss: 2.790149211883545
Validation loss: 1.9650831401989024

Epoch: 5| Step: 8
Training loss: 2.606978178024292
Validation loss: 2.0008338958986345

Epoch: 5| Step: 9
Training loss: 1.8335473537445068
Validation loss: 1.9769813732434345

Epoch: 5| Step: 10
Training loss: 2.2014710903167725
Validation loss: 1.9945612979191605

Epoch: 179| Step: 0
Training loss: 2.0089428424835205
Validation loss: 1.9803395437937912

Epoch: 5| Step: 1
Training loss: 1.5087774991989136
Validation loss: 1.9974406316716184

Epoch: 5| Step: 2
Training loss: 1.9159431457519531
Validation loss: 1.9858230852311658

Epoch: 5| Step: 3
Training loss: 1.7631111145019531
Validation loss: 2.0114995202710553

Epoch: 5| Step: 4
Training loss: 2.631544828414917
Validation loss: 1.9985315850985947

Epoch: 5| Step: 5
Training loss: 2.3343613147735596
Validation loss: 2.0018942535564466

Epoch: 5| Step: 6
Training loss: 2.24021053314209
Validation loss: 1.9877948735349922

Epoch: 5| Step: 7
Training loss: 2.0140063762664795
Validation loss: 1.975349639051704

Epoch: 5| Step: 8
Training loss: 2.4226181507110596
Validation loss: 1.9982900696416055

Epoch: 5| Step: 9
Training loss: 2.023421049118042
Validation loss: 1.9991267650358138

Epoch: 5| Step: 10
Training loss: 1.8220183849334717
Validation loss: 1.9925298101158553

Epoch: 180| Step: 0
Training loss: 1.8001865148544312
Validation loss: 1.992034371181201

Epoch: 5| Step: 1
Training loss: 1.553364872932434
Validation loss: 1.987756859871649

Epoch: 5| Step: 2
Training loss: 2.333650588989258
Validation loss: 2.0016329083391415

Epoch: 5| Step: 3
Training loss: 1.7946323156356812
Validation loss: 2.0025250014438423

Epoch: 5| Step: 4
Training loss: 2.9287986755371094
Validation loss: 1.9903960702239827

Epoch: 5| Step: 5
Training loss: 2.0420315265655518
Validation loss: 1.971853494644165

Epoch: 5| Step: 6
Training loss: 1.5984728336334229
Validation loss: 1.9938542612137333

Epoch: 5| Step: 7
Training loss: 1.8504629135131836
Validation loss: 1.9764805147724767

Epoch: 5| Step: 8
Training loss: 2.517864465713501
Validation loss: 1.997960364946755

Epoch: 5| Step: 9
Training loss: 2.0214171409606934
Validation loss: 1.9828500786135275

Epoch: 5| Step: 10
Training loss: 2.302807331085205
Validation loss: 1.9914923009052072

Epoch: 181| Step: 0
Training loss: 1.6577640771865845
Validation loss: 2.0008099950769895

Epoch: 5| Step: 1
Training loss: 1.7752739191055298
Validation loss: 1.9878393732091433

Epoch: 5| Step: 2
Training loss: 2.5383667945861816
Validation loss: 1.9831543558387346

Epoch: 5| Step: 3
Training loss: 2.406036376953125
Validation loss: 1.9881458923380861

Epoch: 5| Step: 4
Training loss: 1.4861438274383545
Validation loss: 2.0019444496400896

Epoch: 5| Step: 5
Training loss: 2.1832308769226074
Validation loss: 2.029812559004753

Epoch: 5| Step: 6
Training loss: 2.3272595405578613
Validation loss: 2.006611935554012

Epoch: 5| Step: 7
Training loss: 2.1821913719177246
Validation loss: 1.9775962445043749

Epoch: 5| Step: 8
Training loss: 2.337625026702881
Validation loss: 1.9988545320367301

Epoch: 5| Step: 9
Training loss: 1.9748233556747437
Validation loss: 2.013191520526845

Epoch: 5| Step: 10
Training loss: 1.6517376899719238
Validation loss: 1.9886654858948083

Epoch: 182| Step: 0
Training loss: 1.9568283557891846
Validation loss: 2.0154174502177904

Epoch: 5| Step: 1
Training loss: 2.0066263675689697
Validation loss: 1.9891664789568992

Epoch: 5| Step: 2
Training loss: 1.7414966821670532
Validation loss: 1.9887254904675227

Epoch: 5| Step: 3
Training loss: 2.0501043796539307
Validation loss: 2.0089125633239746

Epoch: 5| Step: 4
Training loss: 2.710942506790161
Validation loss: 1.9956001632957048

Epoch: 5| Step: 5
Training loss: 2.5901756286621094
Validation loss: 1.969584870082076

Epoch: 5| Step: 6
Training loss: 2.127363681793213
Validation loss: 2.024422866041942

Epoch: 5| Step: 7
Training loss: 1.6766102313995361
Validation loss: 2.001395886944186

Epoch: 5| Step: 8
Training loss: 1.8888046741485596
Validation loss: 2.0052096279718543

Epoch: 5| Step: 9
Training loss: 2.3027541637420654
Validation loss: 1.993204855149792

Epoch: 5| Step: 10
Training loss: 1.5703818798065186
Validation loss: 2.000458450727565

Epoch: 183| Step: 0
Training loss: 2.4568185806274414
Validation loss: 1.9828001222302836

Epoch: 5| Step: 1
Training loss: 1.5814374685287476
Validation loss: 1.9780417962740826

Epoch: 5| Step: 2
Training loss: 2.2020881175994873
Validation loss: 2.0137618228953373

Epoch: 5| Step: 3
Training loss: 2.3203892707824707
Validation loss: 2.0088009142106578

Epoch: 5| Step: 4
Training loss: 1.7776196002960205
Validation loss: 1.9819363804273709

Epoch: 5| Step: 5
Training loss: 2.4277143478393555
Validation loss: 1.9978528638039865

Epoch: 5| Step: 6
Training loss: 2.210825204849243
Validation loss: 2.003382254672307

Epoch: 5| Step: 7
Training loss: 2.472504138946533
Validation loss: 1.9994039573977072

Epoch: 5| Step: 8
Training loss: 1.4649103879928589
Validation loss: 1.988213937769654

Epoch: 5| Step: 9
Training loss: 1.8074455261230469
Validation loss: 1.9922611995409893

Epoch: 5| Step: 10
Training loss: 1.9831702709197998
Validation loss: 1.9983939034964449

Epoch: 184| Step: 0
Training loss: 1.6574122905731201
Validation loss: 1.9822245233802385

Epoch: 5| Step: 1
Training loss: 2.471285343170166
Validation loss: 2.0188595146261235

Epoch: 5| Step: 2
Training loss: 2.1928603649139404
Validation loss: 1.9917997775539276

Epoch: 5| Step: 3
Training loss: 2.0529866218566895
Validation loss: 2.006752719161331

Epoch: 5| Step: 4
Training loss: 1.8906276226043701
Validation loss: 1.9896748232585129

Epoch: 5| Step: 5
Training loss: 2.2724921703338623
Validation loss: 1.9875428650968818

Epoch: 5| Step: 6
Training loss: 2.354529619216919
Validation loss: 1.9822883144501717

Epoch: 5| Step: 7
Training loss: 1.6524473428726196
Validation loss: 2.0074201873553696

Epoch: 5| Step: 8
Training loss: 2.508747100830078
Validation loss: 2.0009762779358895

Epoch: 5| Step: 9
Training loss: 1.6993423700332642
Validation loss: 2.003846400527544

Epoch: 5| Step: 10
Training loss: 1.7727024555206299
Validation loss: 1.9770036589714788

Epoch: 185| Step: 0
Training loss: 1.8752079010009766
Validation loss: 1.982659503977786

Epoch: 5| Step: 1
Training loss: 1.4918651580810547
Validation loss: 1.9997155691987725

Epoch: 5| Step: 2
Training loss: 2.073275327682495
Validation loss: 1.9749805811912782

Epoch: 5| Step: 3
Training loss: 2.0014376640319824
Validation loss: 1.9839636715509559

Epoch: 5| Step: 4
Training loss: 2.280153751373291
Validation loss: 2.0006367852610927

Epoch: 5| Step: 5
Training loss: 2.3221869468688965
Validation loss: 2.0159186009437806

Epoch: 5| Step: 6
Training loss: 2.0529799461364746
Validation loss: 1.9934673206780547

Epoch: 5| Step: 7
Training loss: 2.2532622814178467
Validation loss: 2.0077960388634795

Epoch: 5| Step: 8
Training loss: 2.088833808898926
Validation loss: 2.0065493968225296

Epoch: 5| Step: 9
Training loss: 2.0585715770721436
Validation loss: 2.0104940988684215

Epoch: 5| Step: 10
Training loss: 2.100525379180908
Validation loss: 2.0070171907383907

Epoch: 186| Step: 0
Training loss: 1.8039032220840454
Validation loss: 1.9928427844919183

Epoch: 5| Step: 1
Training loss: 2.3730850219726562
Validation loss: 2.005978872699122

Epoch: 5| Step: 2
Training loss: 1.9009793996810913
Validation loss: 2.0040069792860296

Epoch: 5| Step: 3
Training loss: 2.4172329902648926
Validation loss: 2.002695124636414

Epoch: 5| Step: 4
Training loss: 1.7788944244384766
Validation loss: 1.9689335079603298

Epoch: 5| Step: 5
Training loss: 2.0037055015563965
Validation loss: 1.9901726604789816

Epoch: 5| Step: 6
Training loss: 2.161771297454834
Validation loss: 1.9865372796212473

Epoch: 5| Step: 7
Training loss: 1.9056756496429443
Validation loss: 2.0094920550623248

Epoch: 5| Step: 8
Training loss: 1.7540283203125
Validation loss: 1.9977644489657493

Epoch: 5| Step: 9
Training loss: 2.6897530555725098
Validation loss: 2.001600229611961

Epoch: 5| Step: 10
Training loss: 1.8124868869781494
Validation loss: 2.0062155057025213

Epoch: 187| Step: 0
Training loss: 1.7105439901351929
Validation loss: 1.9654924254263602

Epoch: 5| Step: 1
Training loss: 1.552427053451538
Validation loss: 1.9931914139819402

Epoch: 5| Step: 2
Training loss: 1.9963939189910889
Validation loss: 1.9735138493199502

Epoch: 5| Step: 3
Training loss: 1.6895334720611572
Validation loss: 1.9785561279584003

Epoch: 5| Step: 4
Training loss: 1.9885879755020142
Validation loss: 2.0169402835189656

Epoch: 5| Step: 5
Training loss: 2.7680985927581787
Validation loss: 1.9728868007659912

Epoch: 5| Step: 6
Training loss: 2.459616184234619
Validation loss: 1.9838148086301741

Epoch: 5| Step: 7
Training loss: 1.7441164255142212
Validation loss: 1.990146565180953

Epoch: 5| Step: 8
Training loss: 1.390052318572998
Validation loss: 2.012426850616291

Epoch: 5| Step: 9
Training loss: 2.4502615928649902
Validation loss: 1.997695320396013

Epoch: 5| Step: 10
Training loss: 2.6920359134674072
Validation loss: 2.0119006069757606

Epoch: 188| Step: 0
Training loss: 1.5924444198608398
Validation loss: 2.0001613837416454

Epoch: 5| Step: 1
Training loss: 2.285081148147583
Validation loss: 1.987146290399695

Epoch: 5| Step: 2
Training loss: 1.8640060424804688
Validation loss: 1.9992808706016951

Epoch: 5| Step: 3
Training loss: 1.7465366125106812
Validation loss: 1.992958386739095

Epoch: 5| Step: 4
Training loss: 2.0261402130126953
Validation loss: 1.9858487665012319

Epoch: 5| Step: 5
Training loss: 1.4419515132904053
Validation loss: 1.9925650653018747

Epoch: 5| Step: 6
Training loss: 2.572464942932129
Validation loss: 1.9858390605577858

Epoch: 5| Step: 7
Training loss: 2.500044584274292
Validation loss: 1.9738595165232176

Epoch: 5| Step: 8
Training loss: 2.3046443462371826
Validation loss: 1.9975386716986214

Epoch: 5| Step: 9
Training loss: 1.9335237741470337
Validation loss: 1.9810860938923334

Epoch: 5| Step: 10
Training loss: 2.1911942958831787
Validation loss: 1.9770153132818078

Epoch: 189| Step: 0
Training loss: 2.0617763996124268
Validation loss: 2.0072889545912385

Epoch: 5| Step: 1
Training loss: 1.6998107433319092
Validation loss: 1.9617752887869393

Epoch: 5| Step: 2
Training loss: 1.6588252782821655
Validation loss: 1.9938848980011479

Epoch: 5| Step: 3
Training loss: 2.6210083961486816
Validation loss: 1.9791679613051876

Epoch: 5| Step: 4
Training loss: 2.5390236377716064
Validation loss: 2.014341272333617

Epoch: 5| Step: 5
Training loss: 1.8186848163604736
Validation loss: 1.9936110768266904

Epoch: 5| Step: 6
Training loss: 1.7784452438354492
Validation loss: 2.026118979659132

Epoch: 5| Step: 7
Training loss: 2.2330644130706787
Validation loss: 1.9847982057961084

Epoch: 5| Step: 8
Training loss: 2.2657718658447266
Validation loss: 1.9822710996033044

Epoch: 5| Step: 9
Training loss: 2.0984206199645996
Validation loss: 1.996606606309132

Epoch: 5| Step: 10
Training loss: 1.787453055381775
Validation loss: 2.024637758090932

Epoch: 190| Step: 0
Training loss: 1.8474245071411133
Validation loss: 1.9922910954362603

Epoch: 5| Step: 1
Training loss: 2.511878252029419
Validation loss: 2.0199729075995823

Epoch: 5| Step: 2
Training loss: 2.538687229156494
Validation loss: 1.9892310314281012

Epoch: 5| Step: 3
Training loss: 1.3624022006988525
Validation loss: 2.0181656973336333

Epoch: 5| Step: 4
Training loss: 1.735703468322754
Validation loss: 2.002206954904782

Epoch: 5| Step: 5
Training loss: 2.106041193008423
Validation loss: 1.999961668445218

Epoch: 5| Step: 6
Training loss: 2.3969154357910156
Validation loss: 1.9976144913704164

Epoch: 5| Step: 7
Training loss: 2.309448719024658
Validation loss: 1.9932197960474158

Epoch: 5| Step: 8
Training loss: 2.0325369834899902
Validation loss: 1.9923962290569017

Epoch: 5| Step: 9
Training loss: 1.3827095031738281
Validation loss: 2.0090813867507444

Epoch: 5| Step: 10
Training loss: 2.219926118850708
Validation loss: 2.0206033722046883

Epoch: 191| Step: 0
Training loss: 1.9389352798461914
Validation loss: 2.000176332330191

Epoch: 5| Step: 1
Training loss: 2.0914313793182373
Validation loss: 2.002406599701092

Epoch: 5| Step: 2
Training loss: 1.9071041345596313
Validation loss: 1.9802999317005117

Epoch: 5| Step: 3
Training loss: 2.296347141265869
Validation loss: 2.007831763195735

Epoch: 5| Step: 4
Training loss: 2.109597682952881
Validation loss: 1.998964786529541

Epoch: 5| Step: 5
Training loss: 1.4026840925216675
Validation loss: 2.0144125492342058

Epoch: 5| Step: 6
Training loss: 2.428572654724121
Validation loss: 2.013546515536565

Epoch: 5| Step: 7
Training loss: 2.120824098587036
Validation loss: 1.9989774586052023

Epoch: 5| Step: 8
Training loss: 1.7628437280654907
Validation loss: 2.0140262726814515

Epoch: 5| Step: 9
Training loss: 2.032865047454834
Validation loss: 1.9999690453211467

Epoch: 5| Step: 10
Training loss: 2.478041887283325
Validation loss: 2.0011914212216615

Epoch: 192| Step: 0
Training loss: 2.0931296348571777
Validation loss: 2.0058468234154487

Epoch: 5| Step: 1
Training loss: 2.1622090339660645
Validation loss: 2.011139376189119

Epoch: 5| Step: 2
Training loss: 2.775392770767212
Validation loss: 2.0074540415117816

Epoch: 5| Step: 3
Training loss: 1.4531710147857666
Validation loss: 2.0008662528889154

Epoch: 5| Step: 4
Training loss: 1.7542304992675781
Validation loss: 2.0268312449096353

Epoch: 5| Step: 5
Training loss: 2.7226388454437256
Validation loss: 2.005094596134719

Epoch: 5| Step: 6
Training loss: 1.9631893634796143
Validation loss: 1.984192317531955

Epoch: 5| Step: 7
Training loss: 1.9893913269042969
Validation loss: 2.006718458667878

Epoch: 5| Step: 8
Training loss: 1.7856743335723877
Validation loss: 1.9992677370707195

Epoch: 5| Step: 9
Training loss: 1.7648866176605225
Validation loss: 2.013693776181949

Epoch: 5| Step: 10
Training loss: 1.8969275951385498
Validation loss: 1.9973168552562754

Epoch: 193| Step: 0
Training loss: 3.1019997596740723
Validation loss: 1.988616176830825

Epoch: 5| Step: 1
Training loss: 2.088047504425049
Validation loss: 2.001736625548332

Epoch: 5| Step: 2
Training loss: 1.614304780960083
Validation loss: 1.9546085249993108

Epoch: 5| Step: 3
Training loss: 1.9892432689666748
Validation loss: 1.9701801743558658

Epoch: 5| Step: 4
Training loss: 1.6655809879302979
Validation loss: 1.9966579932038502

Epoch: 5| Step: 5
Training loss: 2.268829345703125
Validation loss: 1.9914706112236105

Epoch: 5| Step: 6
Training loss: 2.416604995727539
Validation loss: 1.9948171518182243

Epoch: 5| Step: 7
Training loss: 1.707909345626831
Validation loss: 1.98254777795525

Epoch: 5| Step: 8
Training loss: 1.9570659399032593
Validation loss: 1.9692031914188015

Epoch: 5| Step: 9
Training loss: 1.6390870809555054
Validation loss: 1.9941208875307472

Epoch: 5| Step: 10
Training loss: 1.8953828811645508
Validation loss: 1.980513975184451

Epoch: 194| Step: 0
Training loss: 1.751132607460022
Validation loss: 2.002246727225601

Epoch: 5| Step: 1
Training loss: 1.96515691280365
Validation loss: 1.9942574924038303

Epoch: 5| Step: 2
Training loss: 2.542513370513916
Validation loss: 2.0106082500949984

Epoch: 5| Step: 3
Training loss: 2.053800106048584
Validation loss: 2.0138429518668883

Epoch: 5| Step: 4
Training loss: 1.6438086032867432
Validation loss: 1.9905586537494455

Epoch: 5| Step: 5
Training loss: 1.7158008813858032
Validation loss: 2.0030549803087787

Epoch: 5| Step: 6
Training loss: 2.16049861907959
Validation loss: 2.011875493552095

Epoch: 5| Step: 7
Training loss: 2.004840850830078
Validation loss: 2.016336876858947

Epoch: 5| Step: 8
Training loss: 2.644211769104004
Validation loss: 2.0059205819201726

Epoch: 5| Step: 9
Training loss: 1.7443876266479492
Validation loss: 2.046924985865111

Epoch: 5| Step: 10
Training loss: 2.2940762042999268
Validation loss: 2.0272670561267483

Epoch: 195| Step: 0
Training loss: 1.8462550640106201
Validation loss: 2.0299331026692546

Epoch: 5| Step: 1
Training loss: 2.568891763687134
Validation loss: 2.0081131201918407

Epoch: 5| Step: 2
Training loss: 2.1639952659606934
Validation loss: 2.0233654001707673

Epoch: 5| Step: 3
Training loss: 1.1470911502838135
Validation loss: 2.0259403054432203

Epoch: 5| Step: 4
Training loss: 2.2846341133117676
Validation loss: 2.0039966516597296

Epoch: 5| Step: 5
Training loss: 1.912247896194458
Validation loss: 1.9862724529799594

Epoch: 5| Step: 6
Training loss: 2.4003703594207764
Validation loss: 2.0006469270234466

Epoch: 5| Step: 7
Training loss: 2.6868960857391357
Validation loss: 2.017738808867752

Epoch: 5| Step: 8
Training loss: 2.034644842147827
Validation loss: 2.035487623624904

Epoch: 5| Step: 9
Training loss: 1.3246376514434814
Validation loss: 1.9691951377417451

Epoch: 5| Step: 10
Training loss: 1.9287183284759521
Validation loss: 1.9839059947639384

Epoch: 196| Step: 0
Training loss: 2.397778272628784
Validation loss: 1.9881228862270233

Epoch: 5| Step: 1
Training loss: 1.4760184288024902
Validation loss: 2.0049087873069187

Epoch: 5| Step: 2
Training loss: 1.8650833368301392
Validation loss: 1.9977185187801239

Epoch: 5| Step: 3
Training loss: 2.9347758293151855
Validation loss: 1.994014693844703

Epoch: 5| Step: 4
Training loss: 1.818304419517517
Validation loss: 1.9554497067646315

Epoch: 5| Step: 5
Training loss: 1.9970676898956299
Validation loss: 1.9927034531870196

Epoch: 5| Step: 6
Training loss: 2.602886915206909
Validation loss: 1.9765265269946026

Epoch: 5| Step: 7
Training loss: 1.9933357238769531
Validation loss: 1.9987278112801172

Epoch: 5| Step: 8
Training loss: 1.893040418624878
Validation loss: 1.9952269113191994

Epoch: 5| Step: 9
Training loss: 1.6568260192871094
Validation loss: 2.002049622997161

Epoch: 5| Step: 10
Training loss: 1.7223788499832153
Validation loss: 1.9738922734414377

Epoch: 197| Step: 0
Training loss: 2.0729784965515137
Validation loss: 1.9971664336419874

Epoch: 5| Step: 1
Training loss: 2.299947738647461
Validation loss: 1.9877159518580283

Epoch: 5| Step: 2
Training loss: 2.1072518825531006
Validation loss: 1.987414562573997

Epoch: 5| Step: 3
Training loss: 1.9199100732803345
Validation loss: 1.9791022334047543

Epoch: 5| Step: 4
Training loss: 1.8689486980438232
Validation loss: 1.9687204642962384

Epoch: 5| Step: 5
Training loss: 2.1547276973724365
Validation loss: 1.9885899302779988

Epoch: 5| Step: 6
Training loss: 2.045074939727783
Validation loss: 1.9640919649472801

Epoch: 5| Step: 7
Training loss: 1.63405442237854
Validation loss: 1.9737926272935764

Epoch: 5| Step: 8
Training loss: 2.521270990371704
Validation loss: 1.9585804682905956

Epoch: 5| Step: 9
Training loss: 1.75705885887146
Validation loss: 1.9723790153380363

Epoch: 5| Step: 10
Training loss: 2.0482497215270996
Validation loss: 1.9596271207255702

Epoch: 198| Step: 0
Training loss: 2.011868953704834
Validation loss: 1.9894183886948453

Epoch: 5| Step: 1
Training loss: 1.8128420114517212
Validation loss: 1.9678874002989901

Epoch: 5| Step: 2
Training loss: 1.7829334735870361
Validation loss: 1.9947261451393046

Epoch: 5| Step: 3
Training loss: 2.2341132164001465
Validation loss: 1.9804509929431382

Epoch: 5| Step: 4
Training loss: 1.6344916820526123
Validation loss: 1.9957337943456506

Epoch: 5| Step: 5
Training loss: 1.727285385131836
Validation loss: 1.9865190623908915

Epoch: 5| Step: 6
Training loss: 1.868525505065918
Validation loss: 1.9906805792162496

Epoch: 5| Step: 7
Training loss: 2.163729190826416
Validation loss: 2.0029684292372836

Epoch: 5| Step: 8
Training loss: 2.300330638885498
Validation loss: 2.0119636520262687

Epoch: 5| Step: 9
Training loss: 2.577091932296753
Validation loss: 2.001842555179391

Epoch: 5| Step: 10
Training loss: 2.1538467407226562
Validation loss: 2.0055578934249056

Epoch: 199| Step: 0
Training loss: 1.7750318050384521
Validation loss: 2.000036980516167

Epoch: 5| Step: 1
Training loss: 2.4581375122070312
Validation loss: 2.0049302142153502

Epoch: 5| Step: 2
Training loss: 1.9984407424926758
Validation loss: 2.0182226191284838

Epoch: 5| Step: 3
Training loss: 2.1726598739624023
Validation loss: 2.006814287554833

Epoch: 5| Step: 4
Training loss: 2.1246485710144043
Validation loss: 2.0085968817434003

Epoch: 5| Step: 5
Training loss: 2.78003191947937
Validation loss: 2.04946151087361

Epoch: 5| Step: 6
Training loss: 1.9921600818634033
Validation loss: 1.9963558027821202

Epoch: 5| Step: 7
Training loss: 2.275695323944092
Validation loss: 2.0283900922344578

Epoch: 5| Step: 8
Training loss: 1.7227671146392822
Validation loss: 2.0216368552177184

Epoch: 5| Step: 9
Training loss: 1.5314061641693115
Validation loss: 1.9844901010554323

Epoch: 5| Step: 10
Training loss: 1.515063762664795
Validation loss: 2.005759052051011

Epoch: 200| Step: 0
Training loss: 2.2836270332336426
Validation loss: 2.012382020232498

Epoch: 5| Step: 1
Training loss: 2.028439998626709
Validation loss: 2.0437305178693546

Epoch: 5| Step: 2
Training loss: 2.2836174964904785
Validation loss: 2.007129661498531

Epoch: 5| Step: 3
Training loss: 1.388763666152954
Validation loss: 1.9899315808409004

Epoch: 5| Step: 4
Training loss: 2.599043369293213
Validation loss: 1.998656940716569

Epoch: 5| Step: 5
Training loss: 1.7980129718780518
Validation loss: 1.9977415441184916

Epoch: 5| Step: 6
Training loss: 1.6488511562347412
Validation loss: 1.9911196975297825

Epoch: 5| Step: 7
Training loss: 1.5671173334121704
Validation loss: 1.9949026633334417

Epoch: 5| Step: 8
Training loss: 2.2115530967712402
Validation loss: 1.9996982800063265

Epoch: 5| Step: 9
Training loss: 2.295274496078491
Validation loss: 1.9856652367499568

Epoch: 5| Step: 10
Training loss: 2.1516308784484863
Validation loss: 1.9983120900328442

Epoch: 201| Step: 0
Training loss: 1.9061599969863892
Validation loss: 1.9917425135130524

Epoch: 5| Step: 1
Training loss: 2.179349422454834
Validation loss: 1.9903710426822785

Epoch: 5| Step: 2
Training loss: 2.198927879333496
Validation loss: 1.9838228328253633

Epoch: 5| Step: 3
Training loss: 1.2891768217086792
Validation loss: 1.9925588869279431

Epoch: 5| Step: 4
Training loss: 2.7431797981262207
Validation loss: 2.004814047967234

Epoch: 5| Step: 5
Training loss: 2.376906156539917
Validation loss: 2.004014274125458

Epoch: 5| Step: 6
Training loss: 2.185042142868042
Validation loss: 1.9791690021432855

Epoch: 5| Step: 7
Training loss: 2.0218091011047363
Validation loss: 1.9949925945651146

Epoch: 5| Step: 8
Training loss: 1.7782821655273438
Validation loss: 1.9888361653973978

Epoch: 5| Step: 9
Training loss: 1.4341773986816406
Validation loss: 1.966423571750682

Epoch: 5| Step: 10
Training loss: 2.196636199951172
Validation loss: 1.995364035329511

Epoch: 202| Step: 0
Training loss: 1.6154693365097046
Validation loss: 2.0065306309730775

Epoch: 5| Step: 1
Training loss: 2.0849945545196533
Validation loss: 1.9741001564969298

Epoch: 5| Step: 2
Training loss: 1.9626481533050537
Validation loss: 2.0068983467676307

Epoch: 5| Step: 3
Training loss: 1.986271619796753
Validation loss: 1.989206834505963

Epoch: 5| Step: 4
Training loss: 2.0802340507507324
Validation loss: 1.9961100932090514

Epoch: 5| Step: 5
Training loss: 2.3536157608032227
Validation loss: 1.9972507133278796

Epoch: 5| Step: 6
Training loss: 1.6767911911010742
Validation loss: 1.9967973296360304

Epoch: 5| Step: 7
Training loss: 2.1032814979553223
Validation loss: 2.011374100562065

Epoch: 5| Step: 8
Training loss: 1.7282345294952393
Validation loss: 1.988509790871733

Epoch: 5| Step: 9
Training loss: 2.6535542011260986
Validation loss: 2.0117511582630936

Epoch: 5| Step: 10
Training loss: 1.6934043169021606
Validation loss: 1.9782920447728967

Epoch: 203| Step: 0
Training loss: 2.0952279567718506
Validation loss: 1.9896918176322855

Epoch: 5| Step: 1
Training loss: 1.6780933141708374
Validation loss: 1.9973321191726192

Epoch: 5| Step: 2
Training loss: 2.0443615913391113
Validation loss: 2.0179014359751055

Epoch: 5| Step: 3
Training loss: 1.7749115228652954
Validation loss: 2.0080797390271257

Epoch: 5| Step: 4
Training loss: 2.068708658218384
Validation loss: 2.009539588805168

Epoch: 5| Step: 5
Training loss: 1.8549877405166626
Validation loss: 2.0073500423021216

Epoch: 5| Step: 6
Training loss: 2.496849298477173
Validation loss: 2.0182467276050198

Epoch: 5| Step: 7
Training loss: 1.756386160850525
Validation loss: 2.0123689892471477

Epoch: 5| Step: 8
Training loss: 1.9564937353134155
Validation loss: 1.9963671815010808

Epoch: 5| Step: 9
Training loss: 2.779175043106079
Validation loss: 2.020017559810351

Epoch: 5| Step: 10
Training loss: 1.7368146181106567
Validation loss: 2.0191594644259383

Epoch: 204| Step: 0
Training loss: 1.6875253915786743
Validation loss: 2.0104054750934726

Epoch: 5| Step: 1
Training loss: 1.943984031677246
Validation loss: 2.007407044851652

Epoch: 5| Step: 2
Training loss: 2.03723406791687
Validation loss: 1.9909980553452686

Epoch: 5| Step: 3
Training loss: 1.6118313074111938
Validation loss: 2.0298717534670265

Epoch: 5| Step: 4
Training loss: 2.1259682178497314
Validation loss: 1.9875542322794597

Epoch: 5| Step: 5
Training loss: 1.6841217279434204
Validation loss: 2.008187650352396

Epoch: 5| Step: 6
Training loss: 2.117502212524414
Validation loss: 2.0206530427420013

Epoch: 5| Step: 7
Training loss: 2.901869773864746
Validation loss: 2.001831127751258

Epoch: 5| Step: 8
Training loss: 2.3061916828155518
Validation loss: 2.002986558022038

Epoch: 5| Step: 9
Training loss: 1.6279417276382446
Validation loss: 2.0079029413961593

Epoch: 5| Step: 10
Training loss: 2.266995429992676
Validation loss: 1.9994604074826805

Epoch: 205| Step: 0
Training loss: 2.127959728240967
Validation loss: 1.999395703756681

Epoch: 5| Step: 1
Training loss: 2.0344173908233643
Validation loss: 1.9941606829243321

Epoch: 5| Step: 2
Training loss: 2.0858302116394043
Validation loss: 1.9946732085238221

Epoch: 5| Step: 3
Training loss: 2.5301880836486816
Validation loss: 1.9877248758910804

Epoch: 5| Step: 4
Training loss: 2.4421918392181396
Validation loss: 2.002513021551153

Epoch: 5| Step: 5
Training loss: 1.5538928508758545
Validation loss: 2.0075991281899075

Epoch: 5| Step: 6
Training loss: 1.803955078125
Validation loss: 1.9947119528247463

Epoch: 5| Step: 7
Training loss: 1.788496732711792
Validation loss: 1.9945632847406531

Epoch: 5| Step: 8
Training loss: 1.6430572271347046
Validation loss: 1.9938370002213346

Epoch: 5| Step: 9
Training loss: 2.271977663040161
Validation loss: 1.9800119041114725

Epoch: 5| Step: 10
Training loss: 1.9730585813522339
Validation loss: 1.98476162264424

Epoch: 206| Step: 0
Training loss: 2.3567981719970703
Validation loss: 2.012083045897945

Epoch: 5| Step: 1
Training loss: 1.9793907403945923
Validation loss: 1.9885095575804352

Epoch: 5| Step: 2
Training loss: 2.3254408836364746
Validation loss: 1.9796678507199852

Epoch: 5| Step: 3
Training loss: 2.139765501022339
Validation loss: 1.9897870850819412

Epoch: 5| Step: 4
Training loss: 1.9743579626083374
Validation loss: 1.9715967934618714

Epoch: 5| Step: 5
Training loss: 2.195955753326416
Validation loss: 2.02494643580529

Epoch: 5| Step: 6
Training loss: 1.7601991891860962
Validation loss: 1.9741399698359992

Epoch: 5| Step: 7
Training loss: 1.906121015548706
Validation loss: 2.0064381296916673

Epoch: 5| Step: 8
Training loss: 1.8706270456314087
Validation loss: 2.0114466349283853

Epoch: 5| Step: 9
Training loss: 2.028174877166748
Validation loss: 2.015157438093616

Epoch: 5| Step: 10
Training loss: 1.571319580078125
Validation loss: 1.9758161934473182

Epoch: 207| Step: 0
Training loss: 2.4373717308044434
Validation loss: 1.994559666161896

Epoch: 5| Step: 1
Training loss: 1.1968061923980713
Validation loss: 2.012125845878355

Epoch: 5| Step: 2
Training loss: 2.0789361000061035
Validation loss: 1.9982651805364957

Epoch: 5| Step: 3
Training loss: 1.8429203033447266
Validation loss: 2.014610025190538

Epoch: 5| Step: 4
Training loss: 2.7939376831054688
Validation loss: 1.9942773183186848

Epoch: 5| Step: 5
Training loss: 1.6727864742279053
Validation loss: 1.9909679428223641

Epoch: 5| Step: 6
Training loss: 2.363476276397705
Validation loss: 2.0066210839056198

Epoch: 5| Step: 7
Training loss: 2.2132949829101562
Validation loss: 2.028602715461485

Epoch: 5| Step: 8
Training loss: 1.8520714044570923
Validation loss: 2.009389420991303

Epoch: 5| Step: 9
Training loss: 1.5045474767684937
Validation loss: 2.0068161872125443

Epoch: 5| Step: 10
Training loss: 2.3215184211730957
Validation loss: 1.9910090841272825

Epoch: 208| Step: 0
Training loss: 2.1521155834198
Validation loss: 1.9999603686794158

Epoch: 5| Step: 1
Training loss: 1.569606065750122
Validation loss: 2.0050045303119126

Epoch: 5| Step: 2
Training loss: 1.7256174087524414
Validation loss: 2.0249396677940124

Epoch: 5| Step: 3
Training loss: 1.8348007202148438
Validation loss: 1.9984881967626593

Epoch: 5| Step: 4
Training loss: 2.485074520111084
Validation loss: 1.9886303076180079

Epoch: 5| Step: 5
Training loss: 2.688638687133789
Validation loss: 1.993047825751766

Epoch: 5| Step: 6
Training loss: 1.7912029027938843
Validation loss: 2.0031163205382643

Epoch: 5| Step: 7
Training loss: 1.7248932123184204
Validation loss: 2.0043673041046306

Epoch: 5| Step: 8
Training loss: 2.26173734664917
Validation loss: 1.975941285010307

Epoch: 5| Step: 9
Training loss: 1.6427198648452759
Validation loss: 1.9900200546428721

Epoch: 5| Step: 10
Training loss: 2.223078489303589
Validation loss: 2.000836358275465

Epoch: 209| Step: 0
Training loss: 2.2067363262176514
Validation loss: 1.9735369041401853

Epoch: 5| Step: 1
Training loss: 1.7088220119476318
Validation loss: 1.9810093346462454

Epoch: 5| Step: 2
Training loss: 1.2618215084075928
Validation loss: 1.9975245768024075

Epoch: 5| Step: 3
Training loss: 1.9102942943572998
Validation loss: 2.004208316085159

Epoch: 5| Step: 4
Training loss: 2.4963371753692627
Validation loss: 1.9963871445707095

Epoch: 5| Step: 5
Training loss: 2.4151034355163574
Validation loss: 2.0077982166761994

Epoch: 5| Step: 6
Training loss: 1.875462532043457
Validation loss: 1.9824673514212332

Epoch: 5| Step: 7
Training loss: 2.238407850265503
Validation loss: 2.0015377729169783

Epoch: 5| Step: 8
Training loss: 2.0697021484375
Validation loss: 2.0070644629898893

Epoch: 5| Step: 9
Training loss: 1.8230469226837158
Validation loss: 1.990754178775254

Epoch: 5| Step: 10
Training loss: 1.960154414176941
Validation loss: 1.997170543157926

Epoch: 210| Step: 0
Training loss: 2.5266854763031006
Validation loss: 1.984170498386506

Epoch: 5| Step: 1
Training loss: 1.710256814956665
Validation loss: 1.9963144615132322

Epoch: 5| Step: 2
Training loss: 2.1572365760803223
Validation loss: 1.9953796120100125

Epoch: 5| Step: 3
Training loss: 1.9770967960357666
Validation loss: 2.0019949225969214

Epoch: 5| Step: 4
Training loss: 2.2306668758392334
Validation loss: 1.9841838523905764

Epoch: 5| Step: 5
Training loss: 1.2332477569580078
Validation loss: 1.9778814264523086

Epoch: 5| Step: 6
Training loss: 1.8456720113754272
Validation loss: 1.9894507162032589

Epoch: 5| Step: 7
Training loss: 1.8821853399276733
Validation loss: 2.0075701052142727

Epoch: 5| Step: 8
Training loss: 1.9776875972747803
Validation loss: 1.9659937145889446

Epoch: 5| Step: 9
Training loss: 1.9666900634765625
Validation loss: 2.007468218444496

Epoch: 5| Step: 10
Training loss: 2.6272330284118652
Validation loss: 1.967780379838841

Epoch: 211| Step: 0
Training loss: 2.2762813568115234
Validation loss: 1.9929793060466807

Epoch: 5| Step: 1
Training loss: 2.80611252784729
Validation loss: 1.9918157195532193

Epoch: 5| Step: 2
Training loss: 1.656720519065857
Validation loss: 2.003617248227519

Epoch: 5| Step: 3
Training loss: 2.4712576866149902
Validation loss: 1.9855127847322853

Epoch: 5| Step: 4
Training loss: 1.9258620738983154
Validation loss: 1.9966584943955945

Epoch: 5| Step: 5
Training loss: 1.738747000694275
Validation loss: 1.9831107303660402

Epoch: 5| Step: 6
Training loss: 1.910265326499939
Validation loss: 2.0347265479385213

Epoch: 5| Step: 7
Training loss: 1.513624668121338
Validation loss: 1.9818873302910918

Epoch: 5| Step: 8
Training loss: 1.9991567134857178
Validation loss: 2.0094285447110414

Epoch: 5| Step: 9
Training loss: 1.958807349205017
Validation loss: 2.0067840596681

Epoch: 5| Step: 10
Training loss: 2.0494792461395264
Validation loss: 1.9788584068257322

Epoch: 212| Step: 0
Training loss: 2.4039900302886963
Validation loss: 2.0298558383859615

Epoch: 5| Step: 1
Training loss: 1.5085288286209106
Validation loss: 2.02140151557102

Epoch: 5| Step: 2
Training loss: 2.059126377105713
Validation loss: 1.9987760077240646

Epoch: 5| Step: 3
Training loss: 2.485319137573242
Validation loss: 2.0043988791845178

Epoch: 5| Step: 4
Training loss: 1.6696878671646118
Validation loss: 1.999789599449404

Epoch: 5| Step: 5
Training loss: 2.2582974433898926
Validation loss: 1.9807635776458248

Epoch: 5| Step: 6
Training loss: 1.4993102550506592
Validation loss: 2.0114164044780116

Epoch: 5| Step: 7
Training loss: 1.6062142848968506
Validation loss: 1.9884031741849837

Epoch: 5| Step: 8
Training loss: 2.3704895973205566
Validation loss: 2.014267921447754

Epoch: 5| Step: 9
Training loss: 2.051570415496826
Validation loss: 2.0154486215242775

Epoch: 5| Step: 10
Training loss: 2.1626360416412354
Validation loss: 2.0436332071981123

Epoch: 213| Step: 0
Training loss: 1.9576590061187744
Validation loss: 1.9974753933568155

Epoch: 5| Step: 1
Training loss: 1.8699827194213867
Validation loss: 2.003559447103931

Epoch: 5| Step: 2
Training loss: 2.168513774871826
Validation loss: 2.011959519437564

Epoch: 5| Step: 3
Training loss: 1.8116929531097412
Validation loss: 1.9990506787453928

Epoch: 5| Step: 4
Training loss: 2.345970630645752
Validation loss: 2.0057014111549623

Epoch: 5| Step: 5
Training loss: 2.26424503326416
Validation loss: 1.990408279562509

Epoch: 5| Step: 6
Training loss: 2.1167755126953125
Validation loss: 2.0067270366094445

Epoch: 5| Step: 7
Training loss: 2.1799137592315674
Validation loss: 1.9925455008783648

Epoch: 5| Step: 8
Training loss: 1.6123374700546265
Validation loss: 1.9693340921914706

Epoch: 5| Step: 9
Training loss: 1.7756483554840088
Validation loss: 1.9974226784962479

Epoch: 5| Step: 10
Training loss: 1.958978295326233
Validation loss: 1.9965442137051654

Epoch: 214| Step: 0
Training loss: 2.01562237739563
Validation loss: 2.0035047479855117

Epoch: 5| Step: 1
Training loss: 2.367331027984619
Validation loss: 2.0004538925745154

Epoch: 5| Step: 2
Training loss: 1.6152927875518799
Validation loss: 1.996668836121918

Epoch: 5| Step: 3
Training loss: 1.7255096435546875
Validation loss: 2.0133752361420663

Epoch: 5| Step: 4
Training loss: 2.044851303100586
Validation loss: 2.0011166834062144

Epoch: 5| Step: 5
Training loss: 2.2650089263916016
Validation loss: 2.0007907767449655

Epoch: 5| Step: 6
Training loss: 1.8128445148468018
Validation loss: 1.9923783194634221

Epoch: 5| Step: 7
Training loss: 2.016566038131714
Validation loss: 2.0091162253451604

Epoch: 5| Step: 8
Training loss: 2.053723096847534
Validation loss: 1.9867005143114316

Epoch: 5| Step: 9
Training loss: 1.8458411693572998
Validation loss: 1.9951734696665118

Epoch: 5| Step: 10
Training loss: 2.3405888080596924
Validation loss: 2.008770212050407

Epoch: 215| Step: 0
Training loss: 2.357630968093872
Validation loss: 1.9972590169598978

Epoch: 5| Step: 1
Training loss: 2.107067108154297
Validation loss: 1.9868132222083308

Epoch: 5| Step: 2
Training loss: 1.7310802936553955
Validation loss: 1.9824457348033946

Epoch: 5| Step: 3
Training loss: 1.5987017154693604
Validation loss: 1.9929109696419007

Epoch: 5| Step: 4
Training loss: 1.7841269969940186
Validation loss: 2.0268139634081113

Epoch: 5| Step: 5
Training loss: 1.9454046487808228
Validation loss: 1.982372199335406

Epoch: 5| Step: 6
Training loss: 2.0580341815948486
Validation loss: 1.9955195380795387

Epoch: 5| Step: 7
Training loss: 1.9589054584503174
Validation loss: 2.0173752910347393

Epoch: 5| Step: 8
Training loss: 1.9253807067871094
Validation loss: 2.0185608363920644

Epoch: 5| Step: 9
Training loss: 2.082537889480591
Validation loss: 1.996518483725927

Epoch: 5| Step: 10
Training loss: 2.443631410598755
Validation loss: 2.0054463981300272

Epoch: 216| Step: 0
Training loss: 2.476484775543213
Validation loss: 1.9893415384395148

Epoch: 5| Step: 1
Training loss: 2.472378969192505
Validation loss: 1.9801597479851014

Epoch: 5| Step: 2
Training loss: 1.6935793161392212
Validation loss: 2.0112044298520653

Epoch: 5| Step: 3
Training loss: 1.6558802127838135
Validation loss: 2.0066056174616658

Epoch: 5| Step: 4
Training loss: 2.0438356399536133
Validation loss: 2.0055345796769664

Epoch: 5| Step: 5
Training loss: 1.7101637125015259
Validation loss: 2.0025217635657198

Epoch: 5| Step: 6
Training loss: 1.5216466188430786
Validation loss: 1.9832185096638177

Epoch: 5| Step: 7
Training loss: 1.8957207202911377
Validation loss: 2.0191318450435514

Epoch: 5| Step: 8
Training loss: 1.8801276683807373
Validation loss: 2.0079190936139835

Epoch: 5| Step: 9
Training loss: 2.4812214374542236
Validation loss: 1.9995762199483893

Epoch: 5| Step: 10
Training loss: 2.234240770339966
Validation loss: 1.987150179442539

Epoch: 217| Step: 0
Training loss: 1.9564902782440186
Validation loss: 2.003286111739374

Epoch: 5| Step: 1
Training loss: 1.9765241146087646
Validation loss: 1.9999530687127063

Epoch: 5| Step: 2
Training loss: 2.0223891735076904
Validation loss: 1.9903241677950787

Epoch: 5| Step: 3
Training loss: 1.4377012252807617
Validation loss: 2.008733739135086

Epoch: 5| Step: 4
Training loss: 2.0028395652770996
Validation loss: 2.0170292431308376

Epoch: 5| Step: 5
Training loss: 1.685896873474121
Validation loss: 2.002323054498242

Epoch: 5| Step: 6
Training loss: 1.934360146522522
Validation loss: 2.002474033704368

Epoch: 5| Step: 7
Training loss: 2.3539206981658936
Validation loss: 1.9992457397522465

Epoch: 5| Step: 8
Training loss: 2.4908831119537354
Validation loss: 1.9885851619064168

Epoch: 5| Step: 9
Training loss: 1.7849371433258057
Validation loss: 2.0054869254430137

Epoch: 5| Step: 10
Training loss: 2.4411568641662598
Validation loss: 1.9872111684532576

Epoch: 218| Step: 0
Training loss: 1.7149755954742432
Validation loss: 1.9907939921143234

Epoch: 5| Step: 1
Training loss: 2.0128021240234375
Validation loss: 1.9854017432017992

Epoch: 5| Step: 2
Training loss: 1.9871889352798462
Validation loss: 1.9846224964305919

Epoch: 5| Step: 3
Training loss: 2.004892349243164
Validation loss: 1.9956257471474268

Epoch: 5| Step: 4
Training loss: 1.5289924144744873
Validation loss: 1.985933446115063

Epoch: 5| Step: 5
Training loss: 1.3831993341445923
Validation loss: 1.9759481363399054

Epoch: 5| Step: 6
Training loss: 1.6182482242584229
Validation loss: 1.9959074169076898

Epoch: 5| Step: 7
Training loss: 2.153160572052002
Validation loss: 2.001737492058867

Epoch: 5| Step: 8
Training loss: 2.961923122406006
Validation loss: 1.984479073555239

Epoch: 5| Step: 9
Training loss: 2.1594362258911133
Validation loss: 2.0075917936140493

Epoch: 5| Step: 10
Training loss: 2.5039713382720947
Validation loss: 1.9901119201414046

Epoch: 219| Step: 0
Training loss: 1.8907455205917358
Validation loss: 2.0021194193952825

Epoch: 5| Step: 1
Training loss: 2.1867151260375977
Validation loss: 1.990195059007214

Epoch: 5| Step: 2
Training loss: 1.5365090370178223
Validation loss: 1.9843898434792795

Epoch: 5| Step: 3
Training loss: 2.052370071411133
Validation loss: 1.9938005516605992

Epoch: 5| Step: 4
Training loss: 1.438543677330017
Validation loss: 2.012506959258869

Epoch: 5| Step: 5
Training loss: 2.2848563194274902
Validation loss: 2.0045117998635895

Epoch: 5| Step: 6
Training loss: 2.0532119274139404
Validation loss: 2.0133335282725673

Epoch: 5| Step: 7
Training loss: 2.3520262241363525
Validation loss: 2.0169494703251827

Epoch: 5| Step: 8
Training loss: 1.8942184448242188
Validation loss: 1.9999834273451118

Epoch: 5| Step: 9
Training loss: 2.3043410778045654
Validation loss: 2.0027001006628877

Epoch: 5| Step: 10
Training loss: 1.7942991256713867
Validation loss: 1.9880626419539094

Epoch: 220| Step: 0
Training loss: 2.1270244121551514
Validation loss: 1.9956551751782816

Epoch: 5| Step: 1
Training loss: 2.4462807178497314
Validation loss: 1.9913615616418983

Epoch: 5| Step: 2
Training loss: 1.6837536096572876
Validation loss: 1.997026554999813

Epoch: 5| Step: 3
Training loss: 1.683837890625
Validation loss: 1.9965832489793018

Epoch: 5| Step: 4
Training loss: 2.130101203918457
Validation loss: 1.999036499249038

Epoch: 5| Step: 5
Training loss: 1.8739814758300781
Validation loss: 2.015352882364745

Epoch: 5| Step: 6
Training loss: 1.9099693298339844
Validation loss: 1.9935827332158242

Epoch: 5| Step: 7
Training loss: 1.7745544910430908
Validation loss: 1.9957889792739705

Epoch: 5| Step: 8
Training loss: 2.2395405769348145
Validation loss: 1.9697580875888947

Epoch: 5| Step: 9
Training loss: 1.9426181316375732
Validation loss: 1.9707593584573397

Epoch: 5| Step: 10
Training loss: 2.1800332069396973
Validation loss: 1.9639010198654667

Epoch: 221| Step: 0
Training loss: 2.3188068866729736
Validation loss: 1.986059558007025

Epoch: 5| Step: 1
Training loss: 2.4254984855651855
Validation loss: 2.0028276212753786

Epoch: 5| Step: 2
Training loss: 1.5349171161651611
Validation loss: 1.9810855952642297

Epoch: 5| Step: 3
Training loss: 1.3952693939208984
Validation loss: 1.97626539199583

Epoch: 5| Step: 4
Training loss: 1.7505658864974976
Validation loss: 2.0019624489609913

Epoch: 5| Step: 5
Training loss: 1.7617963552474976
Validation loss: 1.9805363378217142

Epoch: 5| Step: 6
Training loss: 2.3963851928710938
Validation loss: 1.9945347462930987

Epoch: 5| Step: 7
Training loss: 2.324284076690674
Validation loss: 1.9852980926472654

Epoch: 5| Step: 8
Training loss: 1.7634189128875732
Validation loss: 1.982650802981469

Epoch: 5| Step: 9
Training loss: 1.6978250741958618
Validation loss: 1.9843750999819847

Epoch: 5| Step: 10
Training loss: 2.486767530441284
Validation loss: 1.989017758318173

Epoch: 222| Step: 0
Training loss: 1.504590392112732
Validation loss: 1.999949191206245

Epoch: 5| Step: 1
Training loss: 2.1442055702209473
Validation loss: 1.986672729574224

Epoch: 5| Step: 2
Training loss: 1.5427839756011963
Validation loss: 2.011396643935993

Epoch: 5| Step: 3
Training loss: 2.1203770637512207
Validation loss: 2.0117597297955583

Epoch: 5| Step: 4
Training loss: 1.6561561822891235
Validation loss: 2.0022108888113372

Epoch: 5| Step: 5
Training loss: 2.3537867069244385
Validation loss: 1.9970511133952806

Epoch: 5| Step: 6
Training loss: 1.9306697845458984
Validation loss: 2.0140207044539915

Epoch: 5| Step: 7
Training loss: 1.1040558815002441
Validation loss: 2.0033991644459386

Epoch: 5| Step: 8
Training loss: 1.9710330963134766
Validation loss: 2.009015547331943

Epoch: 5| Step: 9
Training loss: 3.133310317993164
Validation loss: 2.0287431798955446

Epoch: 5| Step: 10
Training loss: 2.492044448852539
Validation loss: 2.0104661423672914

Epoch: 223| Step: 0
Training loss: 2.0689632892608643
Validation loss: 2.001219146995134

Epoch: 5| Step: 1
Training loss: 1.9736785888671875
Validation loss: 2.0205090366384035

Epoch: 5| Step: 2
Training loss: 1.617892861366272
Validation loss: 1.9871375753033547

Epoch: 5| Step: 3
Training loss: 1.4868260622024536
Validation loss: 1.9891103147178568

Epoch: 5| Step: 4
Training loss: 1.5290037393569946
Validation loss: 1.9840843382702078

Epoch: 5| Step: 5
Training loss: 2.426518201828003
Validation loss: 1.9828809192103725

Epoch: 5| Step: 6
Training loss: 2.0511581897735596
Validation loss: 1.970438011230961

Epoch: 5| Step: 7
Training loss: 2.5944809913635254
Validation loss: 1.9998424847920735

Epoch: 5| Step: 8
Training loss: 1.3436224460601807
Validation loss: 1.9871922205853205

Epoch: 5| Step: 9
Training loss: 2.162137269973755
Validation loss: 1.9914238260638328

Epoch: 5| Step: 10
Training loss: 2.6300737857818604
Validation loss: 1.9921842146945257

Epoch: 224| Step: 0
Training loss: 1.5259714126586914
Validation loss: 1.9610316317568544

Epoch: 5| Step: 1
Training loss: 2.7836053371429443
Validation loss: 1.9885868539092362

Epoch: 5| Step: 2
Training loss: 1.5093978643417358
Validation loss: 2.020959670825671

Epoch: 5| Step: 3
Training loss: 2.455411434173584
Validation loss: 1.9984283472902031

Epoch: 5| Step: 4
Training loss: 2.4793906211853027
Validation loss: 1.9908110941610029

Epoch: 5| Step: 5
Training loss: 1.3925492763519287
Validation loss: 2.0032633299468667

Epoch: 5| Step: 6
Training loss: 1.9104821681976318
Validation loss: 1.969990030411751

Epoch: 5| Step: 7
Training loss: 2.0911993980407715
Validation loss: 2.0060327155615694

Epoch: 5| Step: 8
Training loss: 1.5822515487670898
Validation loss: 1.9965030326638171

Epoch: 5| Step: 9
Training loss: 2.2277276515960693
Validation loss: 2.0014029754105436

Epoch: 5| Step: 10
Training loss: 1.901759386062622
Validation loss: 1.9567264831194313

Epoch: 225| Step: 0
Training loss: 1.6511586904525757
Validation loss: 1.9804560868970809

Epoch: 5| Step: 1
Training loss: 2.2003633975982666
Validation loss: 2.025066121931999

Epoch: 5| Step: 2
Training loss: 1.3095555305480957
Validation loss: 1.9771651452587498

Epoch: 5| Step: 3
Training loss: 1.8240745067596436
Validation loss: 2.0397560237556376

Epoch: 5| Step: 4
Training loss: 2.01934814453125
Validation loss: 2.002947835512059

Epoch: 5| Step: 5
Training loss: 2.0084948539733887
Validation loss: 2.0128653164832824

Epoch: 5| Step: 6
Training loss: 2.2634129524230957
Validation loss: 2.0022158802196546

Epoch: 5| Step: 7
Training loss: 2.7576510906219482
Validation loss: 1.9918136468497656

Epoch: 5| Step: 8
Training loss: 2.3114476203918457
Validation loss: 2.0065410342267764

Epoch: 5| Step: 9
Training loss: 1.6955883502960205
Validation loss: 1.997444127195625

Epoch: 5| Step: 10
Training loss: 1.7823809385299683
Validation loss: 2.025048114920175

Epoch: 226| Step: 0
Training loss: 2.0956273078918457
Validation loss: 2.0210847213704097

Epoch: 5| Step: 1
Training loss: 1.4996955394744873
Validation loss: 1.9937185561785133

Epoch: 5| Step: 2
Training loss: 1.735578179359436
Validation loss: 2.011718157799013

Epoch: 5| Step: 3
Training loss: 2.1606738567352295
Validation loss: 1.9942428168430124

Epoch: 5| Step: 4
Training loss: 1.7032334804534912
Validation loss: 1.990574618821503

Epoch: 5| Step: 5
Training loss: 1.7260735034942627
Validation loss: 1.996732509264382

Epoch: 5| Step: 6
Training loss: 2.325960159301758
Validation loss: 1.9810112855767692

Epoch: 5| Step: 7
Training loss: 2.1564102172851562
Validation loss: 2.0071932526044947

Epoch: 5| Step: 8
Training loss: 2.2588391304016113
Validation loss: 1.9919461075977614

Epoch: 5| Step: 9
Training loss: 2.0315701961517334
Validation loss: 1.9797274681829637

Epoch: 5| Step: 10
Training loss: 2.0642144680023193
Validation loss: 1.9769758780797322

Epoch: 227| Step: 0
Training loss: 1.77632737159729
Validation loss: 1.9844383091054938

Epoch: 5| Step: 1
Training loss: 1.6833419799804688
Validation loss: 1.9842086427955217

Epoch: 5| Step: 2
Training loss: 1.5943419933319092
Validation loss: 2.0090970223949802

Epoch: 5| Step: 3
Training loss: 2.1328375339508057
Validation loss: 1.977812022291204

Epoch: 5| Step: 4
Training loss: 2.0567145347595215
Validation loss: 1.978078467871553

Epoch: 5| Step: 5
Training loss: 2.292691946029663
Validation loss: 2.0188062126918505

Epoch: 5| Step: 6
Training loss: 2.0398049354553223
Validation loss: 1.9866436553257767

Epoch: 5| Step: 7
Training loss: 2.3658881187438965
Validation loss: 1.9898671565517303

Epoch: 5| Step: 8
Training loss: 1.5538818836212158
Validation loss: 1.9887102957694762

Epoch: 5| Step: 9
Training loss: 1.7403690814971924
Validation loss: 2.0068434130760933

Epoch: 5| Step: 10
Training loss: 2.59717059135437
Validation loss: 1.9883165744043165

Epoch: 228| Step: 0
Training loss: 1.7469837665557861
Validation loss: 1.9829750932672972

Epoch: 5| Step: 1
Training loss: 1.9882309436798096
Validation loss: 2.023258947557019

Epoch: 5| Step: 2
Training loss: 2.5496177673339844
Validation loss: 2.0245582134492937

Epoch: 5| Step: 3
Training loss: 1.772573471069336
Validation loss: 2.00877933989289

Epoch: 5| Step: 4
Training loss: 2.0220346450805664
Validation loss: 2.0032537086035616

Epoch: 5| Step: 5
Training loss: 2.198819637298584
Validation loss: 1.991659156737789

Epoch: 5| Step: 6
Training loss: 1.512737512588501
Validation loss: 1.9869199978407992

Epoch: 5| Step: 7
Training loss: 1.7552540302276611
Validation loss: 2.003826287484938

Epoch: 5| Step: 8
Training loss: 2.3345236778259277
Validation loss: 2.0170044027349

Epoch: 5| Step: 9
Training loss: 2.2801456451416016
Validation loss: 1.9912412499868741

Epoch: 5| Step: 10
Training loss: 1.5077756643295288
Validation loss: 2.024839726827478

Epoch: 229| Step: 0
Training loss: 1.4507708549499512
Validation loss: 1.9935671308989167

Epoch: 5| Step: 1
Training loss: 2.0626673698425293
Validation loss: 2.003745194404356

Epoch: 5| Step: 2
Training loss: 2.1326661109924316
Validation loss: 1.9970190537873136

Epoch: 5| Step: 3
Training loss: 2.0919222831726074
Validation loss: 2.013946012784076

Epoch: 5| Step: 4
Training loss: 1.9722557067871094
Validation loss: 2.002951168244885

Epoch: 5| Step: 5
Training loss: 1.661891222000122
Validation loss: 2.000746013015829

Epoch: 5| Step: 6
Training loss: 1.8163623809814453
Validation loss: 2.030982586645311

Epoch: 5| Step: 7
Training loss: 2.14943528175354
Validation loss: 2.0098171567404144

Epoch: 5| Step: 8
Training loss: 2.2718193531036377
Validation loss: 2.0287062711613153

Epoch: 5| Step: 9
Training loss: 2.3450748920440674
Validation loss: 2.0288831700560865

Epoch: 5| Step: 10
Training loss: 1.9440220594406128
Validation loss: 1.9921705825354463

Epoch: 230| Step: 0
Training loss: 2.1606593132019043
Validation loss: 2.017870622296487

Epoch: 5| Step: 1
Training loss: 2.0446653366088867
Validation loss: 1.9970689755614086

Epoch: 5| Step: 2
Training loss: 1.7636051177978516
Validation loss: 2.0156418520917176

Epoch: 5| Step: 3
Training loss: 2.3668036460876465
Validation loss: 1.9975999657825758

Epoch: 5| Step: 4
Training loss: 1.6818954944610596
Validation loss: 2.0085483981717016

Epoch: 5| Step: 5
Training loss: 1.823904037475586
Validation loss: 1.983186347510225

Epoch: 5| Step: 6
Training loss: 2.164921998977661
Validation loss: 1.9768057587326213

Epoch: 5| Step: 7
Training loss: 1.4226295948028564
Validation loss: 1.9897637008338847

Epoch: 5| Step: 8
Training loss: 1.84371018409729
Validation loss: 2.0083202713279316

Epoch: 5| Step: 9
Training loss: 1.8305009603500366
Validation loss: 1.9870899095330188

Epoch: 5| Step: 10
Training loss: 2.703766345977783
Validation loss: 1.9992726438788957

Epoch: 231| Step: 0
Training loss: 1.8394161462783813
Validation loss: 1.9723622029827488

Epoch: 5| Step: 1
Training loss: 1.887610673904419
Validation loss: 1.9815862588984992

Epoch: 5| Step: 2
Training loss: 1.5733180046081543
Validation loss: 2.001715895950153

Epoch: 5| Step: 3
Training loss: 2.0841617584228516
Validation loss: 2.0077258181828324

Epoch: 5| Step: 4
Training loss: 2.2937023639678955
Validation loss: 1.997404929130308

Epoch: 5| Step: 5
Training loss: 1.9908212423324585
Validation loss: 1.9840080250975907

Epoch: 5| Step: 6
Training loss: 1.9418246746063232
Validation loss: 2.0076203397525254

Epoch: 5| Step: 7
Training loss: 2.36845064163208
Validation loss: 2.016617492962909

Epoch: 5| Step: 8
Training loss: 1.8456007242202759
Validation loss: 1.9809450718664354

Epoch: 5| Step: 9
Training loss: 2.073693037033081
Validation loss: 2.030529514435799

Epoch: 5| Step: 10
Training loss: 1.8750451803207397
Validation loss: 2.0006289661571546

Epoch: 232| Step: 0
Training loss: 1.8101675510406494
Validation loss: 2.0272628735470515

Epoch: 5| Step: 1
Training loss: 2.1688761711120605
Validation loss: 1.9987317977413055

Epoch: 5| Step: 2
Training loss: 1.5324466228485107
Validation loss: 2.0064642736988683

Epoch: 5| Step: 3
Training loss: 2.0471951961517334
Validation loss: 2.0003906885782876

Epoch: 5| Step: 4
Training loss: 1.6511256694793701
Validation loss: 1.9809428863627936

Epoch: 5| Step: 5
Training loss: 2.3968918323516846
Validation loss: 2.008591995444349

Epoch: 5| Step: 6
Training loss: 1.829493522644043
Validation loss: 1.9773747203170613

Epoch: 5| Step: 7
Training loss: 1.7418228387832642
Validation loss: 1.9804861699381182

Epoch: 5| Step: 8
Training loss: 2.2398488521575928
Validation loss: 2.0025916843004126

Epoch: 5| Step: 9
Training loss: 1.6803728342056274
Validation loss: 1.9857049244706348

Epoch: 5| Step: 10
Training loss: 2.716115951538086
Validation loss: 1.9788560892945977

Epoch: 233| Step: 0
Training loss: 2.115382671356201
Validation loss: 1.984299413619503

Epoch: 5| Step: 1
Training loss: 2.0177626609802246
Validation loss: 1.996481187881962

Epoch: 5| Step: 2
Training loss: 2.1893508434295654
Validation loss: 1.987778894362911

Epoch: 5| Step: 3
Training loss: 2.5227487087249756
Validation loss: 2.011908044097244

Epoch: 5| Step: 4
Training loss: 1.9854377508163452
Validation loss: 1.9985661070833924

Epoch: 5| Step: 5
Training loss: 1.7811203002929688
Validation loss: 1.9804623126983643

Epoch: 5| Step: 6
Training loss: 1.5356907844543457
Validation loss: 2.0096152008220716

Epoch: 5| Step: 7
Training loss: 2.217930793762207
Validation loss: 2.0024451568562496

Epoch: 5| Step: 8
Training loss: 1.9575904607772827
Validation loss: 1.990919659214635

Epoch: 5| Step: 9
Training loss: 1.5935522317886353
Validation loss: 2.012021026303691

Epoch: 5| Step: 10
Training loss: 1.6554967164993286
Validation loss: 1.9864570761239657

Epoch: 234| Step: 0
Training loss: 1.7392135858535767
Validation loss: 2.0234454588223527

Epoch: 5| Step: 1
Training loss: 1.686468482017517
Validation loss: 2.0049746574894076

Epoch: 5| Step: 2
Training loss: 2.0541653633117676
Validation loss: 2.01104832977377

Epoch: 5| Step: 3
Training loss: 2.2500133514404297
Validation loss: 2.0092679762071177

Epoch: 5| Step: 4
Training loss: 1.97431218624115
Validation loss: 1.9935113447968678

Epoch: 5| Step: 5
Training loss: 2.132838487625122
Validation loss: 2.000675952562722

Epoch: 5| Step: 6
Training loss: 2.1071488857269287
Validation loss: 1.9912924407630839

Epoch: 5| Step: 7
Training loss: 2.2588448524475098
Validation loss: 1.9781047349335046

Epoch: 5| Step: 8
Training loss: 1.9170383214950562
Validation loss: 2.0096119706348707

Epoch: 5| Step: 9
Training loss: 1.992626428604126
Validation loss: 2.0020233649079517

Epoch: 5| Step: 10
Training loss: 1.533408761024475
Validation loss: 2.004700131313775

Epoch: 235| Step: 0
Training loss: 2.4172451496124268
Validation loss: 2.022955690660784

Epoch: 5| Step: 1
Training loss: 1.6272847652435303
Validation loss: 2.0108981568326234

Epoch: 5| Step: 2
Training loss: 2.1240382194519043
Validation loss: 2.010752216462166

Epoch: 5| Step: 3
Training loss: 2.06676983833313
Validation loss: 2.004993598948243

Epoch: 5| Step: 4
Training loss: 2.002673864364624
Validation loss: 2.0207303134343957

Epoch: 5| Step: 5
Training loss: 1.8080898523330688
Validation loss: 2.0023674234267204

Epoch: 5| Step: 6
Training loss: 1.9879162311553955
Validation loss: 2.0014835032083655

Epoch: 5| Step: 7
Training loss: 2.044370651245117
Validation loss: 2.0108078923276675

Epoch: 5| Step: 8
Training loss: 1.6381076574325562
Validation loss: 2.012041671301729

Epoch: 5| Step: 9
Training loss: 2.105666399002075
Validation loss: 2.0177373578471522

Epoch: 5| Step: 10
Training loss: 1.6647166013717651
Validation loss: 1.992754319662689

Epoch: 236| Step: 0
Training loss: 1.6467559337615967
Validation loss: 2.011084057951486

Epoch: 5| Step: 1
Training loss: 2.2536368370056152
Validation loss: 2.015256620222522

Epoch: 5| Step: 2
Training loss: 2.204033136367798
Validation loss: 1.9968674413619503

Epoch: 5| Step: 3
Training loss: 1.815638780593872
Validation loss: 2.0014437667785154

Epoch: 5| Step: 4
Training loss: 2.1504127979278564
Validation loss: 1.9914265806956957

Epoch: 5| Step: 5
Training loss: 1.8214013576507568
Validation loss: 2.0179398200845204

Epoch: 5| Step: 6
Training loss: 2.1973094940185547
Validation loss: 2.005570004063268

Epoch: 5| Step: 7
Training loss: 2.223644733428955
Validation loss: 1.9581605683090866

Epoch: 5| Step: 8
Training loss: 1.5270378589630127
Validation loss: 1.9921640990882792

Epoch: 5| Step: 9
Training loss: 1.6589443683624268
Validation loss: 2.015151627602116

Epoch: 5| Step: 10
Training loss: 2.1507129669189453
Validation loss: 1.9646316266828967

Epoch: 237| Step: 0
Training loss: 1.7270596027374268
Validation loss: 1.9774860925571893

Epoch: 5| Step: 1
Training loss: 2.245400905609131
Validation loss: 2.0123108817685034

Epoch: 5| Step: 2
Training loss: 1.841179609298706
Validation loss: 2.008749996462176

Epoch: 5| Step: 3
Training loss: 2.1451175212860107
Validation loss: 2.0163729344644854

Epoch: 5| Step: 4
Training loss: 2.1058056354522705
Validation loss: 1.9841385374787033

Epoch: 5| Step: 5
Training loss: 2.3548412322998047
Validation loss: 1.9945568653845018

Epoch: 5| Step: 6
Training loss: 1.9075605869293213
Validation loss: 1.995347822866132

Epoch: 5| Step: 7
Training loss: 2.00687837600708
Validation loss: 1.983311378827659

Epoch: 5| Step: 8
Training loss: 1.3639652729034424
Validation loss: 1.9974291670706965

Epoch: 5| Step: 9
Training loss: 2.1695680618286133
Validation loss: 2.010128785205144

Epoch: 5| Step: 10
Training loss: 1.4740633964538574
Validation loss: 2.000052730242411

Epoch: 238| Step: 0
Training loss: 2.028507947921753
Validation loss: 1.979557386008642

Epoch: 5| Step: 1
Training loss: 1.6958167552947998
Validation loss: 1.9810854542639948

Epoch: 5| Step: 2
Training loss: 1.9560972452163696
Validation loss: 1.98545584242831

Epoch: 5| Step: 3
Training loss: 2.6579604148864746
Validation loss: 2.0015351080125376

Epoch: 5| Step: 4
Training loss: 1.7877864837646484
Validation loss: 1.995999264460738

Epoch: 5| Step: 5
Training loss: 1.4537214040756226
Validation loss: 2.0107275465483307

Epoch: 5| Step: 6
Training loss: 1.627181053161621
Validation loss: 1.9989376119388047

Epoch: 5| Step: 7
Training loss: 1.9857089519500732
Validation loss: 1.994204298142464

Epoch: 5| Step: 8
Training loss: 2.0271036624908447
Validation loss: 2.0202599545960784

Epoch: 5| Step: 9
Training loss: 2.1152610778808594
Validation loss: 1.9982065693024667

Epoch: 5| Step: 10
Training loss: 2.140882730484009
Validation loss: 1.99880697009384

Epoch: 239| Step: 0
Training loss: 1.167074203491211
Validation loss: 1.9876368814899075

Epoch: 5| Step: 1
Training loss: 2.098475694656372
Validation loss: 2.010010173243861

Epoch: 5| Step: 2
Training loss: 1.8585561513900757
Validation loss: 2.02147779926177

Epoch: 5| Step: 3
Training loss: 1.8149302005767822
Validation loss: 1.9869574218667962

Epoch: 5| Step: 4
Training loss: 1.9224483966827393
Validation loss: 2.0085067467022966

Epoch: 5| Step: 5
Training loss: 2.2923686504364014
Validation loss: 1.9955173666759203

Epoch: 5| Step: 6
Training loss: 2.2416508197784424
Validation loss: 2.005930551918604

Epoch: 5| Step: 7
Training loss: 1.7934449911117554
Validation loss: 2.0011135685828423

Epoch: 5| Step: 8
Training loss: 1.8054635524749756
Validation loss: 1.9990195740935623

Epoch: 5| Step: 9
Training loss: 2.387115716934204
Validation loss: 2.01770463297444

Epoch: 5| Step: 10
Training loss: 2.0291168689727783
Validation loss: 2.0234022691685665

Epoch: 240| Step: 0
Training loss: 1.6801379919052124
Validation loss: 2.031269265759376

Epoch: 5| Step: 1
Training loss: 2.145263433456421
Validation loss: 2.0046267842733734

Epoch: 5| Step: 2
Training loss: 1.8933322429656982
Validation loss: 2.01276554599885

Epoch: 5| Step: 3
Training loss: 1.9630286693572998
Validation loss: 2.0092538351653726

Epoch: 5| Step: 4
Training loss: 1.827483892440796
Validation loss: 2.016055143007668

Epoch: 5| Step: 5
Training loss: 2.353440761566162
Validation loss: 2.032630225663544

Epoch: 5| Step: 6
Training loss: 1.7463328838348389
Validation loss: 1.9812454741488221

Epoch: 5| Step: 7
Training loss: 1.9948012828826904
Validation loss: 2.0186959774263444

Epoch: 5| Step: 8
Training loss: 2.5044798851013184
Validation loss: 1.9961238958502328

Epoch: 5| Step: 9
Training loss: 2.0826382637023926
Validation loss: 1.993697568934451

Epoch: 5| Step: 10
Training loss: 1.321082353591919
Validation loss: 2.0101441375670897

Epoch: 241| Step: 0
Training loss: 2.027949333190918
Validation loss: 1.9990037743763258

Epoch: 5| Step: 1
Training loss: 1.5850839614868164
Validation loss: 2.016517141813873

Epoch: 5| Step: 2
Training loss: 2.2401814460754395
Validation loss: 1.9962341529066845

Epoch: 5| Step: 3
Training loss: 1.6773847341537476
Validation loss: 2.0060799711494037

Epoch: 5| Step: 4
Training loss: 2.555591106414795
Validation loss: 2.001298683945851

Epoch: 5| Step: 5
Training loss: 2.1768460273742676
Validation loss: 2.008585309469572

Epoch: 5| Step: 6
Training loss: 2.1042613983154297
Validation loss: 2.035985697982132

Epoch: 5| Step: 7
Training loss: 2.2510900497436523
Validation loss: 2.0261722969752487

Epoch: 5| Step: 8
Training loss: 1.6556522846221924
Validation loss: 2.010755629949672

Epoch: 5| Step: 9
Training loss: 1.2963006496429443
Validation loss: 2.019265910630585

Epoch: 5| Step: 10
Training loss: 1.8042612075805664
Validation loss: 2.0098868980202624

Epoch: 242| Step: 0
Training loss: 2.0757431983947754
Validation loss: 1.9943342670317619

Epoch: 5| Step: 1
Training loss: 2.1036057472229004
Validation loss: 1.995318801172318

Epoch: 5| Step: 2
Training loss: 1.902166724205017
Validation loss: 2.019832921284501

Epoch: 5| Step: 3
Training loss: 2.511362075805664
Validation loss: 2.0207421574541318

Epoch: 5| Step: 4
Training loss: 1.2266826629638672
Validation loss: 1.985555641112789

Epoch: 5| Step: 5
Training loss: 1.5442945957183838
Validation loss: 2.0283264139647126

Epoch: 5| Step: 6
Training loss: 1.8097327947616577
Validation loss: 1.9921895509125085

Epoch: 5| Step: 7
Training loss: 2.068629741668701
Validation loss: 2.018408703547652

Epoch: 5| Step: 8
Training loss: 2.1489081382751465
Validation loss: 1.9938576503466534

Epoch: 5| Step: 9
Training loss: 1.5007625818252563
Validation loss: 2.0089347695791595

Epoch: 5| Step: 10
Training loss: 2.4686310291290283
Validation loss: 1.9862862953575708

Epoch: 243| Step: 0
Training loss: 2.7944836616516113
Validation loss: 1.9833087869869765

Epoch: 5| Step: 1
Training loss: 1.9038689136505127
Validation loss: 2.0235973891391548

Epoch: 5| Step: 2
Training loss: 1.8251298666000366
Validation loss: 1.9949484076551212

Epoch: 5| Step: 3
Training loss: 1.8153247833251953
Validation loss: 2.0024955426493

Epoch: 5| Step: 4
Training loss: 1.7071006298065186
Validation loss: 1.9819522724356702

Epoch: 5| Step: 5
Training loss: 1.930214285850525
Validation loss: 2.0117974191583614

Epoch: 5| Step: 6
Training loss: 2.084088087081909
Validation loss: 1.9970586710078742

Epoch: 5| Step: 7
Training loss: 2.1252102851867676
Validation loss: 2.019159968181323

Epoch: 5| Step: 8
Training loss: 1.436134696006775
Validation loss: 1.9929525544566493

Epoch: 5| Step: 9
Training loss: 1.9499177932739258
Validation loss: 1.984798659560501

Epoch: 5| Step: 10
Training loss: 1.873440146446228
Validation loss: 2.027204954495994

Epoch: 244| Step: 0
Training loss: 1.5093508958816528
Validation loss: 2.016927365333803

Epoch: 5| Step: 1
Training loss: 2.283174991607666
Validation loss: 2.0371733121974493

Epoch: 5| Step: 2
Training loss: 1.7403380870819092
Validation loss: 2.014400379632109

Epoch: 5| Step: 3
Training loss: 1.1776974201202393
Validation loss: 2.005792425524804

Epoch: 5| Step: 4
Training loss: 2.0632805824279785
Validation loss: 2.009253890283646

Epoch: 5| Step: 5
Training loss: 1.7413585186004639
Validation loss: 1.9827256382152598

Epoch: 5| Step: 6
Training loss: 3.142202854156494
Validation loss: 2.0064449387211956

Epoch: 5| Step: 7
Training loss: 2.5885441303253174
Validation loss: 2.007354459454936

Epoch: 5| Step: 8
Training loss: 2.034060001373291
Validation loss: 2.0340228157658733

Epoch: 5| Step: 9
Training loss: 1.4849915504455566
Validation loss: 2.016972000880908

Epoch: 5| Step: 10
Training loss: 1.6000829935073853
Validation loss: 2.010282777970837

Epoch: 245| Step: 0
Training loss: 2.450648307800293
Validation loss: 1.9993675870280112

Epoch: 5| Step: 1
Training loss: 2.3271381855010986
Validation loss: 2.013948179060413

Epoch: 5| Step: 2
Training loss: 1.919501543045044
Validation loss: 1.9883224412959108

Epoch: 5| Step: 3
Training loss: 1.5605928897857666
Validation loss: 2.013209245538199

Epoch: 5| Step: 4
Training loss: 1.5315552949905396
Validation loss: 2.0184781474451863

Epoch: 5| Step: 5
Training loss: 2.390439748764038
Validation loss: 2.0276058309821674

Epoch: 5| Step: 6
Training loss: 1.4125583171844482
Validation loss: 2.008357765854046

Epoch: 5| Step: 7
Training loss: 1.4994502067565918
Validation loss: 2.0402920681943177

Epoch: 5| Step: 8
Training loss: 1.612839937210083
Validation loss: 2.003876469468558

Epoch: 5| Step: 9
Training loss: 2.476724863052368
Validation loss: 2.022273914788359

Epoch: 5| Step: 10
Training loss: 2.0114827156066895
Validation loss: 2.0132976911401235

Epoch: 246| Step: 0
Training loss: 1.9667034149169922
Validation loss: 2.0156654439946657

Epoch: 5| Step: 1
Training loss: 2.0444793701171875
Validation loss: 2.0094039978519564

Epoch: 5| Step: 2
Training loss: 1.5738978385925293
Validation loss: 1.9670550515574794

Epoch: 5| Step: 3
Training loss: 1.3775732517242432
Validation loss: 1.9961862435904882

Epoch: 5| Step: 4
Training loss: 1.9001973867416382
Validation loss: 2.0047657899959113

Epoch: 5| Step: 5
Training loss: 1.768418312072754
Validation loss: 2.0137082876697665

Epoch: 5| Step: 6
Training loss: 2.0731348991394043
Validation loss: 2.00963100951205

Epoch: 5| Step: 7
Training loss: 2.4389781951904297
Validation loss: 2.0083180794151883

Epoch: 5| Step: 8
Training loss: 2.1331543922424316
Validation loss: 1.9479608599857619

Epoch: 5| Step: 9
Training loss: 2.333319902420044
Validation loss: 1.9822672336332259

Epoch: 5| Step: 10
Training loss: 1.591109275817871
Validation loss: 1.98882633127192

Epoch: 247| Step: 0
Training loss: 1.518399953842163
Validation loss: 2.03085692210864

Epoch: 5| Step: 1
Training loss: 2.109142780303955
Validation loss: 2.0123010822521743

Epoch: 5| Step: 2
Training loss: 2.173450469970703
Validation loss: 2.002245165968454

Epoch: 5| Step: 3
Training loss: 2.0470030307769775
Validation loss: 2.004682352465968

Epoch: 5| Step: 4
Training loss: 1.7793872356414795
Validation loss: 2.0046135020512406

Epoch: 5| Step: 5
Training loss: 2.0174336433410645
Validation loss: 1.9963344425283454

Epoch: 5| Step: 6
Training loss: 1.7929397821426392
Validation loss: 1.9961658677747172

Epoch: 5| Step: 7
Training loss: 2.3757965564727783
Validation loss: 1.9901234475515222

Epoch: 5| Step: 8
Training loss: 2.1670241355895996
Validation loss: 1.9965352460902224

Epoch: 5| Step: 9
Training loss: 1.3382933139801025
Validation loss: 1.9744113196608841

Epoch: 5| Step: 10
Training loss: 1.9535181522369385
Validation loss: 1.9975370027685677

Epoch: 248| Step: 0
Training loss: 1.8770525455474854
Validation loss: 2.0003690604240663

Epoch: 5| Step: 1
Training loss: 1.9555842876434326
Validation loss: 1.9974912494741461

Epoch: 5| Step: 2
Training loss: 1.7341159582138062
Validation loss: 1.9967708344100623

Epoch: 5| Step: 3
Training loss: 2.361502170562744
Validation loss: 1.977021542928552

Epoch: 5| Step: 4
Training loss: 2.0515658855438232
Validation loss: 2.003467336777718

Epoch: 5| Step: 5
Training loss: 1.810551404953003
Validation loss: 1.9813472763184579

Epoch: 5| Step: 6
Training loss: 2.1735827922821045
Validation loss: 1.9956212325762677

Epoch: 5| Step: 7
Training loss: 1.7456963062286377
Validation loss: 1.973083024383873

Epoch: 5| Step: 8
Training loss: 2.146026611328125
Validation loss: 2.0035686300646876

Epoch: 5| Step: 9
Training loss: 1.3560177087783813
Validation loss: 2.0315643664329284

Epoch: 5| Step: 10
Training loss: 2.169895648956299
Validation loss: 2.0165080306350545

Epoch: 249| Step: 0
Training loss: 1.4086228609085083
Validation loss: 2.036572902433334

Epoch: 5| Step: 1
Training loss: 1.8416179418563843
Validation loss: 2.0316952607964955

Epoch: 5| Step: 2
Training loss: 2.1515395641326904
Validation loss: 2.025825672252204

Epoch: 5| Step: 3
Training loss: 2.1636874675750732
Validation loss: 2.029812756405082

Epoch: 5| Step: 4
Training loss: 1.494294285774231
Validation loss: 2.02137747374914

Epoch: 5| Step: 5
Training loss: 1.9288861751556396
Validation loss: 2.040511364577919

Epoch: 5| Step: 6
Training loss: 2.3409717082977295
Validation loss: 1.9881451604186848

Epoch: 5| Step: 7
Training loss: 2.497514247894287
Validation loss: 2.000685968706685

Epoch: 5| Step: 8
Training loss: 1.5356382131576538
Validation loss: 2.0188429893985873

Epoch: 5| Step: 9
Training loss: 1.890367865562439
Validation loss: 1.9934340266771213

Epoch: 5| Step: 10
Training loss: 2.14764666557312
Validation loss: 2.008474667867025

Epoch: 250| Step: 0
Training loss: 1.9625781774520874
Validation loss: 2.005715404787371

Epoch: 5| Step: 1
Training loss: 2.396893262863159
Validation loss: 2.0200091126144573

Epoch: 5| Step: 2
Training loss: 1.5859779119491577
Validation loss: 2.025533030110021

Epoch: 5| Step: 3
Training loss: 1.9077491760253906
Validation loss: 2.019194831130325

Epoch: 5| Step: 4
Training loss: 1.6387494802474976
Validation loss: 2.0022930842573925

Epoch: 5| Step: 5
Training loss: 2.1801390647888184
Validation loss: 2.00564314985788

Epoch: 5| Step: 6
Training loss: 2.2964110374450684
Validation loss: 1.9938235103443105

Epoch: 5| Step: 7
Training loss: 1.771142601966858
Validation loss: 1.996359730279574

Epoch: 5| Step: 8
Training loss: 1.5245120525360107
Validation loss: 1.9945012318190707

Epoch: 5| Step: 9
Training loss: 2.359963893890381
Validation loss: 1.9971569712444017

Epoch: 5| Step: 10
Training loss: 1.804234504699707
Validation loss: 2.0376217096082625

Epoch: 251| Step: 0
Training loss: 2.171966314315796
Validation loss: 2.0275273810150805

Epoch: 5| Step: 1
Training loss: 1.404367208480835
Validation loss: 2.0163204746861614

Epoch: 5| Step: 2
Training loss: 1.833313226699829
Validation loss: 2.0137029155608146

Epoch: 5| Step: 3
Training loss: 2.249472141265869
Validation loss: 2.0270967509156916

Epoch: 5| Step: 4
Training loss: 1.97307550907135
Validation loss: 2.0268004107218918

Epoch: 5| Step: 5
Training loss: 1.7918052673339844
Validation loss: 1.978711251289614

Epoch: 5| Step: 6
Training loss: 1.5513392686843872
Validation loss: 1.9711321105239212

Epoch: 5| Step: 7
Training loss: 1.7991135120391846
Validation loss: 1.9985719009112286

Epoch: 5| Step: 8
Training loss: 1.9142478704452515
Validation loss: 2.002310081194806

Epoch: 5| Step: 9
Training loss: 2.3285746574401855
Validation loss: 2.0289991568493586

Epoch: 5| Step: 10
Training loss: 2.021279811859131
Validation loss: 1.9963054144254295

Epoch: 252| Step: 0
Training loss: 1.9211742877960205
Validation loss: 2.004152305664555

Epoch: 5| Step: 1
Training loss: 1.3644088506698608
Validation loss: 2.0100948003030594

Epoch: 5| Step: 2
Training loss: 1.8401867151260376
Validation loss: 2.0138170437146257

Epoch: 5| Step: 3
Training loss: 2.294661045074463
Validation loss: 2.022733340981186

Epoch: 5| Step: 4
Training loss: 1.8091589212417603
Validation loss: 2.007554610570272

Epoch: 5| Step: 5
Training loss: 1.8416473865509033
Validation loss: 2.049708172839175

Epoch: 5| Step: 6
Training loss: 2.3722951412200928
Validation loss: 2.018418253109019

Epoch: 5| Step: 7
Training loss: 1.8125711679458618
Validation loss: 2.0133809351151988

Epoch: 5| Step: 8
Training loss: 2.0599234104156494
Validation loss: 2.036968331183157

Epoch: 5| Step: 9
Training loss: 1.9846426248550415
Validation loss: 2.02689762525661

Epoch: 5| Step: 10
Training loss: 1.7321492433547974
Validation loss: 2.0034524048528364

Epoch: 253| Step: 0
Training loss: 2.1230087280273438
Validation loss: 2.0105134582006805

Epoch: 5| Step: 1
Training loss: 2.2706587314605713
Validation loss: 2.0116488215743855

Epoch: 5| Step: 2
Training loss: 1.8426179885864258
Validation loss: 2.002477762519672

Epoch: 5| Step: 3
Training loss: 1.614243745803833
Validation loss: 2.009157875532745

Epoch: 5| Step: 4
Training loss: 1.8783586025238037
Validation loss: 2.025083557251961

Epoch: 5| Step: 5
Training loss: 2.044473171234131
Validation loss: 2.0144828570786344

Epoch: 5| Step: 6
Training loss: 2.0230677127838135
Validation loss: 2.014463206773163

Epoch: 5| Step: 7
Training loss: 2.2078590393066406
Validation loss: 2.007636340715552

Epoch: 5| Step: 8
Training loss: 1.8716920614242554
Validation loss: 2.011883469038112

Epoch: 5| Step: 9
Training loss: 1.777853012084961
Validation loss: 2.001177854435418

Epoch: 5| Step: 10
Training loss: 1.556843876838684
Validation loss: 2.0222766348110732

Epoch: 254| Step: 0
Training loss: 1.369707465171814
Validation loss: 1.994409094574631

Epoch: 5| Step: 1
Training loss: 2.377537250518799
Validation loss: 2.0111066538800477

Epoch: 5| Step: 2
Training loss: 2.0457050800323486
Validation loss: 2.016482312192199

Epoch: 5| Step: 3
Training loss: 1.6526081562042236
Validation loss: 1.9950262141484085

Epoch: 5| Step: 4
Training loss: 2.0133862495422363
Validation loss: 1.9920896599369664

Epoch: 5| Step: 5
Training loss: 1.558456540107727
Validation loss: 2.0243783266313615

Epoch: 5| Step: 6
Training loss: 2.170016288757324
Validation loss: 1.9958574412971415

Epoch: 5| Step: 7
Training loss: 2.1921393871307373
Validation loss: 2.0065240142165974

Epoch: 5| Step: 8
Training loss: 1.8736155033111572
Validation loss: 2.0050586218475015

Epoch: 5| Step: 9
Training loss: 1.9887539148330688
Validation loss: 2.0006439506366687

Epoch: 5| Step: 10
Training loss: 1.834863543510437
Validation loss: 2.0196230821712042

Epoch: 255| Step: 0
Training loss: 1.6186800003051758
Validation loss: 2.0200573808403424

Epoch: 5| Step: 1
Training loss: 2.050724506378174
Validation loss: 1.975914393701861

Epoch: 5| Step: 2
Training loss: 1.0922532081604004
Validation loss: 2.0299740286283594

Epoch: 5| Step: 3
Training loss: 1.832439661026001
Validation loss: 1.978855199711297

Epoch: 5| Step: 4
Training loss: 2.226317882537842
Validation loss: 2.01963181905849

Epoch: 5| Step: 5
Training loss: 1.5326120853424072
Validation loss: 2.016428170665618

Epoch: 5| Step: 6
Training loss: 1.898468255996704
Validation loss: 2.0091832222477084

Epoch: 5| Step: 7
Training loss: 1.8448264598846436
Validation loss: 2.002312188507408

Epoch: 5| Step: 8
Training loss: 2.3932812213897705
Validation loss: 1.997991987453994

Epoch: 5| Step: 9
Training loss: 2.4287376403808594
Validation loss: 2.0223410642275246

Epoch: 5| Step: 10
Training loss: 2.4688706398010254
Validation loss: 2.0437507039757183

Epoch: 256| Step: 0
Training loss: 2.2245826721191406
Validation loss: 2.0436975109961724

Epoch: 5| Step: 1
Training loss: 1.5319610834121704
Validation loss: 1.9995977417115243

Epoch: 5| Step: 2
Training loss: 2.0459659099578857
Validation loss: 2.014599600145894

Epoch: 5| Step: 3
Training loss: 1.6841237545013428
Validation loss: 1.9972204726229432

Epoch: 5| Step: 4
Training loss: 1.8658348321914673
Validation loss: 2.0183573461348012

Epoch: 5| Step: 5
Training loss: 1.9797382354736328
Validation loss: 1.9786763601405646

Epoch: 5| Step: 6
Training loss: 2.253347396850586
Validation loss: 1.991172803345547

Epoch: 5| Step: 7
Training loss: 1.8633142709732056
Validation loss: 2.0076468631785405

Epoch: 5| Step: 8
Training loss: 1.2744359970092773
Validation loss: 2.0591507598917973

Epoch: 5| Step: 9
Training loss: 2.094460964202881
Validation loss: 2.0187255644029185

Epoch: 5| Step: 10
Training loss: 2.397625207901001
Validation loss: 1.9907903825083086

Epoch: 257| Step: 0
Training loss: 1.5986521244049072
Validation loss: 1.9976331969743133

Epoch: 5| Step: 1
Training loss: 2.179877519607544
Validation loss: 1.986264726167084

Epoch: 5| Step: 2
Training loss: 1.9758214950561523
Validation loss: 2.0079927470094416

Epoch: 5| Step: 3
Training loss: 2.318765878677368
Validation loss: 1.989488386338757

Epoch: 5| Step: 4
Training loss: 1.6976001262664795
Validation loss: 2.000901687529779

Epoch: 5| Step: 5
Training loss: 1.4510530233383179
Validation loss: 2.0042519787306428

Epoch: 5| Step: 6
Training loss: 1.7257674932479858
Validation loss: 2.031301267685429

Epoch: 5| Step: 7
Training loss: 1.9818837642669678
Validation loss: 1.9985961785880468

Epoch: 5| Step: 8
Training loss: 2.0045368671417236
Validation loss: 2.0129502627157394

Epoch: 5| Step: 9
Training loss: 2.2832698822021484
Validation loss: 1.9953862121028285

Epoch: 5| Step: 10
Training loss: 1.9129458665847778
Validation loss: 2.0121732706664712

Epoch: 258| Step: 0
Training loss: 2.209174871444702
Validation loss: 2.020453573555075

Epoch: 5| Step: 1
Training loss: 2.2118096351623535
Validation loss: 2.000275229894987

Epoch: 5| Step: 2
Training loss: 1.6012046337127686
Validation loss: 2.0407175863942792

Epoch: 5| Step: 3
Training loss: 2.121837615966797
Validation loss: 1.9942908235775527

Epoch: 5| Step: 4
Training loss: 1.9966968297958374
Validation loss: 2.0155677628773514

Epoch: 5| Step: 5
Training loss: 1.4409376382827759
Validation loss: 2.01389354659665

Epoch: 5| Step: 6
Training loss: 2.345120668411255
Validation loss: 2.0287824792246663

Epoch: 5| Step: 7
Training loss: 1.7112058401107788
Validation loss: 2.026558473546018

Epoch: 5| Step: 8
Training loss: 1.8046901226043701
Validation loss: 2.0081580146666496

Epoch: 5| Step: 9
Training loss: 1.8940578699111938
Validation loss: 2.0068060723684167

Epoch: 5| Step: 10
Training loss: 1.5845094919204712
Validation loss: 2.0256705053390993

Epoch: 259| Step: 0
Training loss: 1.6889946460723877
Validation loss: 2.007259084332374

Epoch: 5| Step: 1
Training loss: 1.7213701009750366
Validation loss: 2.0061744771977907

Epoch: 5| Step: 2
Training loss: 2.033215045928955
Validation loss: 1.9948007355454147

Epoch: 5| Step: 3
Training loss: 1.9551975727081299
Validation loss: 2.0262119513685986

Epoch: 5| Step: 4
Training loss: 1.8472245931625366
Validation loss: 2.0295200655537267

Epoch: 5| Step: 5
Training loss: 2.0566506385803223
Validation loss: 1.9789152427386212

Epoch: 5| Step: 6
Training loss: 2.071237564086914
Validation loss: 2.013909314268379

Epoch: 5| Step: 7
Training loss: 1.9698158502578735
Validation loss: 1.9930549565181936

Epoch: 5| Step: 8
Training loss: 2.1899054050445557
Validation loss: 2.0131179568588093

Epoch: 5| Step: 9
Training loss: 2.105440139770508
Validation loss: 1.9945603660357896

Epoch: 5| Step: 10
Training loss: 1.428402066230774
Validation loss: 2.0169601440429688

Epoch: 260| Step: 0
Training loss: 1.5475594997406006
Validation loss: 2.0095390619770175

Epoch: 5| Step: 1
Training loss: 1.9722493886947632
Validation loss: 2.00577570930604

Epoch: 5| Step: 2
Training loss: 2.1723086833953857
Validation loss: 2.028071875213295

Epoch: 5| Step: 3
Training loss: 1.6799514293670654
Validation loss: 2.0134209227818314

Epoch: 5| Step: 4
Training loss: 2.2507541179656982
Validation loss: 2.028926485328264

Epoch: 5| Step: 5
Training loss: 1.7097612619400024
Validation loss: 2.051959914545859

Epoch: 5| Step: 6
Training loss: 1.8680254220962524
Validation loss: 2.0388817607715564

Epoch: 5| Step: 7
Training loss: 2.2387900352478027
Validation loss: 2.0290265108949397

Epoch: 5| Step: 8
Training loss: 1.6814517974853516
Validation loss: 2.031905927965718

Epoch: 5| Step: 9
Training loss: 2.1047139167785645
Validation loss: 2.0341747409553936

Epoch: 5| Step: 10
Training loss: 1.8947858810424805
Validation loss: 2.02514418478935

Epoch: 261| Step: 0
Training loss: 1.7521183490753174
Validation loss: 2.0179264032712547

Epoch: 5| Step: 1
Training loss: 2.0946075916290283
Validation loss: 1.9998367319824875

Epoch: 5| Step: 2
Training loss: 2.015747547149658
Validation loss: 1.9993424697588849

Epoch: 5| Step: 3
Training loss: 1.5453135967254639
Validation loss: 2.0010824741855746

Epoch: 5| Step: 4
Training loss: 1.855359435081482
Validation loss: 1.9970362635068997

Epoch: 5| Step: 5
Training loss: 1.5978543758392334
Validation loss: 2.015395720799764

Epoch: 5| Step: 6
Training loss: 1.7868133783340454
Validation loss: 2.0098974550923994

Epoch: 5| Step: 7
Training loss: 2.5095882415771484
Validation loss: 2.023401633385689

Epoch: 5| Step: 8
Training loss: 2.5576205253601074
Validation loss: 2.018372720287692

Epoch: 5| Step: 9
Training loss: 1.6785876750946045
Validation loss: 1.9973437632283857

Epoch: 5| Step: 10
Training loss: 1.3906556367874146
Validation loss: 1.9936001569994035

Epoch: 262| Step: 0
Training loss: 1.8745206594467163
Validation loss: 2.0012580194780902

Epoch: 5| Step: 1
Training loss: 2.096165418624878
Validation loss: 2.0293286461983957

Epoch: 5| Step: 2
Training loss: 1.1783201694488525
Validation loss: 2.010811275051486

Epoch: 5| Step: 3
Training loss: 2.0643227100372314
Validation loss: 2.0178964227758427

Epoch: 5| Step: 4
Training loss: 1.6645876169204712
Validation loss: 2.0019564423509824

Epoch: 5| Step: 5
Training loss: 1.961008071899414
Validation loss: 2.042989433452647

Epoch: 5| Step: 6
Training loss: 1.6005254983901978
Validation loss: 2.0209423367695143

Epoch: 5| Step: 7
Training loss: 2.023310422897339
Validation loss: 2.0145333761809976

Epoch: 5| Step: 8
Training loss: 2.281006336212158
Validation loss: 2.032446445957307

Epoch: 5| Step: 9
Training loss: 2.018990993499756
Validation loss: 2.0135346471622424

Epoch: 5| Step: 10
Training loss: 2.206451892852783
Validation loss: 2.035876512527466

Epoch: 263| Step: 0
Training loss: 2.300443649291992
Validation loss: 2.011390504016671

Epoch: 5| Step: 1
Training loss: 1.47774338722229
Validation loss: 2.029289141778023

Epoch: 5| Step: 2
Training loss: 1.534265160560608
Validation loss: 2.034295617893178

Epoch: 5| Step: 3
Training loss: 1.3955106735229492
Validation loss: 2.0095389414859075

Epoch: 5| Step: 4
Training loss: 2.256632089614868
Validation loss: 2.0353325310573784

Epoch: 5| Step: 5
Training loss: 1.7416355609893799
Validation loss: 2.0404498064389793

Epoch: 5| Step: 6
Training loss: 1.8288371562957764
Validation loss: 2.023643180888186

Epoch: 5| Step: 7
Training loss: 2.0169525146484375
Validation loss: 2.033217965915639

Epoch: 5| Step: 8
Training loss: 2.319239377975464
Validation loss: 2.006872146360336

Epoch: 5| Step: 9
Training loss: 1.83382248878479
Validation loss: 2.0230858287503644

Epoch: 5| Step: 10
Training loss: 2.314166784286499
Validation loss: 2.0104951653429257

Epoch: 264| Step: 0
Training loss: 1.8970940113067627
Validation loss: 1.992763679514649

Epoch: 5| Step: 1
Training loss: 2.0192980766296387
Validation loss: 1.98433978326859

Epoch: 5| Step: 2
Training loss: 1.8413810729980469
Validation loss: 2.012351638527327

Epoch: 5| Step: 3
Training loss: 1.4341130256652832
Validation loss: 1.9956512425535469

Epoch: 5| Step: 4
Training loss: 1.6340312957763672
Validation loss: 1.9769535333879533

Epoch: 5| Step: 5
Training loss: 1.9778858423233032
Validation loss: 1.9906216667544456

Epoch: 5| Step: 6
Training loss: 1.7003196477890015
Validation loss: 2.0214967343115036

Epoch: 5| Step: 7
Training loss: 1.9394645690917969
Validation loss: 2.000602595267757

Epoch: 5| Step: 8
Training loss: 2.2328176498413086
Validation loss: 1.970392314336633

Epoch: 5| Step: 9
Training loss: 2.1334803104400635
Validation loss: 2.0270966227336595

Epoch: 5| Step: 10
Training loss: 2.0583667755126953
Validation loss: 2.0174324461208877

Epoch: 265| Step: 0
Training loss: 1.98441481590271
Validation loss: 2.02422575284076

Epoch: 5| Step: 1
Training loss: 2.4338228702545166
Validation loss: 2.0004966015456827

Epoch: 5| Step: 2
Training loss: 2.312229633331299
Validation loss: 2.0060121884910007

Epoch: 5| Step: 3
Training loss: 2.102060079574585
Validation loss: 2.0066422083044566

Epoch: 5| Step: 4
Training loss: 2.439460277557373
Validation loss: 2.003932815726085

Epoch: 5| Step: 5
Training loss: 1.5443366765975952
Validation loss: 2.009409341760861

Epoch: 5| Step: 6
Training loss: 1.3604869842529297
Validation loss: 2.00004824771676

Epoch: 5| Step: 7
Training loss: 1.6882374286651611
Validation loss: 2.005262983742581

Epoch: 5| Step: 8
Training loss: 1.903620958328247
Validation loss: 2.00635947719697

Epoch: 5| Step: 9
Training loss: 1.789707899093628
Validation loss: 2.0239014574276504

Epoch: 5| Step: 10
Training loss: 1.127586007118225
Validation loss: 1.9944561450712142

Epoch: 266| Step: 0
Training loss: 1.6699459552764893
Validation loss: 2.0397301925125944

Epoch: 5| Step: 1
Training loss: 1.778476357460022
Validation loss: 2.0163753878685737

Epoch: 5| Step: 2
Training loss: 2.7026326656341553
Validation loss: 2.0030124802743234

Epoch: 5| Step: 3
Training loss: 1.731122612953186
Validation loss: 2.0104692751361477

Epoch: 5| Step: 4
Training loss: 1.921886682510376
Validation loss: 1.9965466786456365

Epoch: 5| Step: 5
Training loss: 1.7770618200302124
Validation loss: 2.000020014342441

Epoch: 5| Step: 6
Training loss: 1.6524206399917603
Validation loss: 2.0028393883858957

Epoch: 5| Step: 7
Training loss: 2.2720370292663574
Validation loss: 2.039504502409248

Epoch: 5| Step: 8
Training loss: 1.658879280090332
Validation loss: 2.013049901172679

Epoch: 5| Step: 9
Training loss: 1.771664023399353
Validation loss: 2.0242440059620845

Epoch: 5| Step: 10
Training loss: 2.05914306640625
Validation loss: 2.024102487871724

Epoch: 267| Step: 0
Training loss: 1.8428291082382202
Validation loss: 2.022791559978198

Epoch: 5| Step: 1
Training loss: 1.8162263631820679
Validation loss: 2.021968241660826

Epoch: 5| Step: 2
Training loss: 1.742628812789917
Validation loss: 2.0237798024249334

Epoch: 5| Step: 3
Training loss: 2.2714309692382812
Validation loss: 2.0393777214070803

Epoch: 5| Step: 4
Training loss: 1.9477684497833252
Validation loss: 2.003562331199646

Epoch: 5| Step: 5
Training loss: 1.717415452003479
Validation loss: 1.999685392584852

Epoch: 5| Step: 6
Training loss: 2.643639087677002
Validation loss: 2.01865001263157

Epoch: 5| Step: 7
Training loss: 1.8839702606201172
Validation loss: 2.031653174790003

Epoch: 5| Step: 8
Training loss: 1.5829493999481201
Validation loss: 2.006525347309728

Epoch: 5| Step: 9
Training loss: 1.3537098169326782
Validation loss: 2.043056244491249

Epoch: 5| Step: 10
Training loss: 2.054094076156616
Validation loss: 2.009058469085283

Epoch: 268| Step: 0
Training loss: 1.8352947235107422
Validation loss: 2.0014726474720943

Epoch: 5| Step: 1
Training loss: 2.372333526611328
Validation loss: 2.0271732884068645

Epoch: 5| Step: 2
Training loss: 2.3736696243286133
Validation loss: 1.9965783729348132

Epoch: 5| Step: 3
Training loss: 1.8828357458114624
Validation loss: 2.014153165201987

Epoch: 5| Step: 4
Training loss: 1.3944602012634277
Validation loss: 2.000799596950572

Epoch: 5| Step: 5
Training loss: 1.0902254581451416
Validation loss: 2.0163566156100203

Epoch: 5| Step: 6
Training loss: 2.495156764984131
Validation loss: 2.012536241162208

Epoch: 5| Step: 7
Training loss: 1.826127290725708
Validation loss: 1.994363764280914

Epoch: 5| Step: 8
Training loss: 2.1366915702819824
Validation loss: 2.001634931051603

Epoch: 5| Step: 9
Training loss: 2.046109676361084
Validation loss: 2.025606788614745

Epoch: 5| Step: 10
Training loss: 1.369002342224121
Validation loss: 2.0278877237791657

Epoch: 269| Step: 0
Training loss: 2.3409957885742188
Validation loss: 2.009514634327222

Epoch: 5| Step: 1
Training loss: 1.9229390621185303
Validation loss: 2.01920049805795

Epoch: 5| Step: 2
Training loss: 1.9749252796173096
Validation loss: 1.9827494352094588

Epoch: 5| Step: 3
Training loss: 1.4561021327972412
Validation loss: 2.0317619667258313

Epoch: 5| Step: 4
Training loss: 1.5437242984771729
Validation loss: 2.005076869841545

Epoch: 5| Step: 5
Training loss: 1.507595181465149
Validation loss: 1.9744309584299724

Epoch: 5| Step: 6
Training loss: 1.8727855682373047
Validation loss: 2.021122814506613

Epoch: 5| Step: 7
Training loss: 1.3615641593933105
Validation loss: 2.003711765812289

Epoch: 5| Step: 8
Training loss: 2.324821949005127
Validation loss: 2.025683269705824

Epoch: 5| Step: 9
Training loss: 2.4286677837371826
Validation loss: 2.014439340560667

Epoch: 5| Step: 10
Training loss: 1.852562665939331
Validation loss: 2.0064332280107724

Epoch: 270| Step: 0
Training loss: 1.9502321481704712
Validation loss: 2.01035984100834

Epoch: 5| Step: 1
Training loss: 1.9847497940063477
Validation loss: 2.056626921058983

Epoch: 5| Step: 2
Training loss: 1.6146007776260376
Validation loss: 2.0345392919355825

Epoch: 5| Step: 3
Training loss: 1.3827190399169922
Validation loss: 2.002261289986231

Epoch: 5| Step: 4
Training loss: 1.9305191040039062
Validation loss: 2.0602728371979087

Epoch: 5| Step: 5
Training loss: 2.353041648864746
Validation loss: 2.0358552599465973

Epoch: 5| Step: 6
Training loss: 1.5875167846679688
Validation loss: 2.039356485489876

Epoch: 5| Step: 7
Training loss: 1.9734585285186768
Validation loss: 2.053726762853643

Epoch: 5| Step: 8
Training loss: 1.9306789636611938
Validation loss: 2.0523636802550285

Epoch: 5| Step: 9
Training loss: 2.272146463394165
Validation loss: 2.0478100751035955

Epoch: 5| Step: 10
Training loss: 1.8721846342086792
Validation loss: 2.0641851168806835

Epoch: 271| Step: 0
Training loss: 1.7432628870010376
Validation loss: 2.057074251995292

Epoch: 5| Step: 1
Training loss: 2.1380372047424316
Validation loss: 2.0224639574686685

Epoch: 5| Step: 2
Training loss: 1.4408222436904907
Validation loss: 2.029400884464223

Epoch: 5| Step: 3
Training loss: 2.3839516639709473
Validation loss: 2.0187170851615166

Epoch: 5| Step: 4
Training loss: 1.7542293071746826
Validation loss: 2.002007458799629

Epoch: 5| Step: 5
Training loss: 1.8107408285140991
Validation loss: 2.020986559570477

Epoch: 5| Step: 6
Training loss: 1.9428411722183228
Validation loss: 1.9944050542769893

Epoch: 5| Step: 7
Training loss: 1.781873106956482
Validation loss: 2.011760688597156

Epoch: 5| Step: 8
Training loss: 1.8483320474624634
Validation loss: 2.033775888463502

Epoch: 5| Step: 9
Training loss: 2.109745502471924
Validation loss: 2.0179228359653103

Epoch: 5| Step: 10
Training loss: 1.615718960762024
Validation loss: 2.0048602832260953

Epoch: 272| Step: 0
Training loss: 1.9768288135528564
Validation loss: 2.021469921194097

Epoch: 5| Step: 1
Training loss: 1.711244821548462
Validation loss: 2.033817934733565

Epoch: 5| Step: 2
Training loss: 1.8940492868423462
Validation loss: 2.0183179993783273

Epoch: 5| Step: 3
Training loss: 1.932421088218689
Validation loss: 2.0154214315516974

Epoch: 5| Step: 4
Training loss: 2.431797504425049
Validation loss: 1.9769439722902031

Epoch: 5| Step: 5
Training loss: 1.4257084131240845
Validation loss: 2.0069850824212514

Epoch: 5| Step: 6
Training loss: 2.055644989013672
Validation loss: 2.0230096194051925

Epoch: 5| Step: 7
Training loss: 1.389100193977356
Validation loss: 2.0467355276948664

Epoch: 5| Step: 8
Training loss: 1.6602697372436523
Validation loss: 2.0304473394988687

Epoch: 5| Step: 9
Training loss: 2.1240737438201904
Validation loss: 2.0422125785581526

Epoch: 5| Step: 10
Training loss: 2.108010768890381
Validation loss: 2.0513469480699107

Epoch: 273| Step: 0
Training loss: 1.4174712896347046
Validation loss: 2.0153959438364994

Epoch: 5| Step: 1
Training loss: 1.632158875465393
Validation loss: 2.0446124089661466

Epoch: 5| Step: 2
Training loss: 2.206258773803711
Validation loss: 2.034001483712145

Epoch: 5| Step: 3
Training loss: 2.095834732055664
Validation loss: 2.0210900768156974

Epoch: 5| Step: 4
Training loss: 1.742095708847046
Validation loss: 2.039066222406203

Epoch: 5| Step: 5
Training loss: 1.339934229850769
Validation loss: 2.055160310960585

Epoch: 5| Step: 6
Training loss: 1.8162873983383179
Validation loss: 2.049899419148763

Epoch: 5| Step: 7
Training loss: 2.153799533843994
Validation loss: 2.0236871473250853

Epoch: 5| Step: 8
Training loss: 1.8417508602142334
Validation loss: 2.021210088524767

Epoch: 5| Step: 9
Training loss: 2.499563455581665
Validation loss: 2.0474484248827864

Epoch: 5| Step: 10
Training loss: 2.0013387203216553
Validation loss: 2.040913877948638

Epoch: 274| Step: 0
Training loss: 1.8035860061645508
Validation loss: 1.9969047961696502

Epoch: 5| Step: 1
Training loss: 2.1526002883911133
Validation loss: 2.001104126694382

Epoch: 5| Step: 2
Training loss: 1.683779001235962
Validation loss: 2.0339788211289274

Epoch: 5| Step: 3
Training loss: 1.7298250198364258
Validation loss: 2.00035164945869

Epoch: 5| Step: 4
Training loss: 2.1160519123077393
Validation loss: 1.997010374581942

Epoch: 5| Step: 5
Training loss: 1.3348908424377441
Validation loss: 1.996961521845992

Epoch: 5| Step: 6
Training loss: 1.8128764629364014
Validation loss: 2.0239171340901363

Epoch: 5| Step: 7
Training loss: 1.7267341613769531
Validation loss: 2.005925783547022

Epoch: 5| Step: 8
Training loss: 2.4519600868225098
Validation loss: 2.0051917888784923

Epoch: 5| Step: 9
Training loss: 2.000859022140503
Validation loss: 2.0523009261777325

Epoch: 5| Step: 10
Training loss: 2.039384126663208
Validation loss: 2.035882144845942

Epoch: 275| Step: 0
Training loss: 1.7265625
Validation loss: 2.020121092437416

Epoch: 5| Step: 1
Training loss: 1.6228220462799072
Validation loss: 2.0023601619146203

Epoch: 5| Step: 2
Training loss: 2.3822021484375
Validation loss: 2.0016782437601397

Epoch: 5| Step: 3
Training loss: 2.2627062797546387
Validation loss: 1.9712092132978543

Epoch: 5| Step: 4
Training loss: 1.997659683227539
Validation loss: 2.0107733934156355

Epoch: 5| Step: 5
Training loss: 1.6121327877044678
Validation loss: 1.982062275691699

Epoch: 5| Step: 6
Training loss: 1.6808960437774658
Validation loss: 2.05953207067264

Epoch: 5| Step: 7
Training loss: 1.7198727130889893
Validation loss: 2.036578437333466

Epoch: 5| Step: 8
Training loss: 1.753015160560608
Validation loss: 2.0402491682319233

Epoch: 5| Step: 9
Training loss: 2.059262990951538
Validation loss: 2.034140940635435

Epoch: 5| Step: 10
Training loss: 1.949525237083435
Validation loss: 2.027197108473829

Epoch: 276| Step: 0
Training loss: 1.6680700778961182
Validation loss: 2.063254141038464

Epoch: 5| Step: 1
Training loss: 1.7233070135116577
Validation loss: 2.0454561146356727

Epoch: 5| Step: 2
Training loss: 2.0865836143493652
Validation loss: 2.0410104874641664

Epoch: 5| Step: 3
Training loss: 2.3576316833496094
Validation loss: 2.020919524213319

Epoch: 5| Step: 4
Training loss: 1.7705341577529907
Validation loss: 2.0344529267280334

Epoch: 5| Step: 5
Training loss: 1.6851673126220703
Validation loss: 2.024680660616967

Epoch: 5| Step: 6
Training loss: 1.861133337020874
Validation loss: 2.03469423068467

Epoch: 5| Step: 7
Training loss: 1.885136604309082
Validation loss: 2.053266720105243

Epoch: 5| Step: 8
Training loss: 1.6416966915130615
Validation loss: 2.056419095685405

Epoch: 5| Step: 9
Training loss: 1.719034194946289
Validation loss: 2.047030800132341

Epoch: 5| Step: 10
Training loss: 2.0230889320373535
Validation loss: 2.041086228944922

Epoch: 277| Step: 0
Training loss: 1.6402595043182373
Validation loss: 2.0389641920725503

Epoch: 5| Step: 1
Training loss: 1.3625459671020508
Validation loss: 2.028966675522507

Epoch: 5| Step: 2
Training loss: 2.284949779510498
Validation loss: 2.023411855902723

Epoch: 5| Step: 3
Training loss: 2.0845377445220947
Validation loss: 2.0172836960002942

Epoch: 5| Step: 4
Training loss: 1.932422399520874
Validation loss: 2.038350215522192

Epoch: 5| Step: 5
Training loss: 1.777212142944336
Validation loss: 1.9941541405134304

Epoch: 5| Step: 6
Training loss: 1.827964186668396
Validation loss: 2.0085418967790503

Epoch: 5| Step: 7
Training loss: 1.651900053024292
Validation loss: 2.068465639186162

Epoch: 5| Step: 8
Training loss: 2.0868911743164062
Validation loss: 2.0096278318794827

Epoch: 5| Step: 9
Training loss: 1.9625282287597656
Validation loss: 2.022055325969573

Epoch: 5| Step: 10
Training loss: 1.9690884351730347
Validation loss: 2.0320558842792305

Epoch: 278| Step: 0
Training loss: 1.491377830505371
Validation loss: 1.9964452276947677

Epoch: 5| Step: 1
Training loss: 1.6906547546386719
Validation loss: 2.0143969084626887

Epoch: 5| Step: 2
Training loss: 2.1467556953430176
Validation loss: 2.0243324848913375

Epoch: 5| Step: 3
Training loss: 1.1428905725479126
Validation loss: 2.0055019035134265

Epoch: 5| Step: 4
Training loss: 2.029169797897339
Validation loss: 2.016253523929145

Epoch: 5| Step: 5
Training loss: 2.2703518867492676
Validation loss: 1.9759188211092384

Epoch: 5| Step: 6
Training loss: 1.993941068649292
Validation loss: 2.0198937039221487

Epoch: 5| Step: 7
Training loss: 1.594589352607727
Validation loss: 2.0274058362489105

Epoch: 5| Step: 8
Training loss: 2.029928684234619
Validation loss: 2.0291018588568575

Epoch: 5| Step: 9
Training loss: 1.9705660343170166
Validation loss: 2.017339100119888

Epoch: 5| Step: 10
Training loss: 2.522251844406128
Validation loss: 1.9894394105480564

Epoch: 279| Step: 0
Training loss: 1.9288060665130615
Validation loss: 2.00616927044366

Epoch: 5| Step: 1
Training loss: 2.21431040763855
Validation loss: 2.016350611563652

Epoch: 5| Step: 2
Training loss: 1.9231666326522827
Validation loss: 2.0490483135305424

Epoch: 5| Step: 3
Training loss: 1.6541023254394531
Validation loss: 2.027512235026206

Epoch: 5| Step: 4
Training loss: 2.009521007537842
Validation loss: 2.022170038633449

Epoch: 5| Step: 5
Training loss: 1.9078174829483032
Validation loss: 2.0242488448337843

Epoch: 5| Step: 6
Training loss: 2.4405760765075684
Validation loss: 2.031174131619033

Epoch: 5| Step: 7
Training loss: 1.8266105651855469
Validation loss: 2.03966950344783

Epoch: 5| Step: 8
Training loss: 1.3271700143814087
Validation loss: 2.0314339027609876

Epoch: 5| Step: 9
Training loss: 1.3975106477737427
Validation loss: 2.036923844327209

Epoch: 5| Step: 10
Training loss: 1.7456029653549194
Validation loss: 2.024370055044851

Epoch: 280| Step: 0
Training loss: 1.726828932762146
Validation loss: 2.029511720903458

Epoch: 5| Step: 1
Training loss: 1.170663595199585
Validation loss: 2.0304245000244467

Epoch: 5| Step: 2
Training loss: 2.2595252990722656
Validation loss: 2.0372104696048203

Epoch: 5| Step: 3
Training loss: 1.8944002389907837
Validation loss: 2.031358952163368

Epoch: 5| Step: 4
Training loss: 1.3223049640655518
Validation loss: 2.0651441799697055

Epoch: 5| Step: 5
Training loss: 2.363035202026367
Validation loss: 2.0131984987566547

Epoch: 5| Step: 6
Training loss: 1.9965120553970337
Validation loss: 2.032654035475946

Epoch: 5| Step: 7
Training loss: 1.8921034336090088
Validation loss: 2.0312226228816535

Epoch: 5| Step: 8
Training loss: 2.071915864944458
Validation loss: 2.0204787279969905

Epoch: 5| Step: 9
Training loss: 1.816258192062378
Validation loss: 2.006875052246996

Epoch: 5| Step: 10
Training loss: 1.9652280807495117
Validation loss: 2.0092676403701946

Epoch: 281| Step: 0
Training loss: 1.294877052307129
Validation loss: 2.0150060499868085

Epoch: 5| Step: 1
Training loss: 2.356398105621338
Validation loss: 2.021627333856398

Epoch: 5| Step: 2
Training loss: 2.0031039714813232
Validation loss: 2.043284543098942

Epoch: 5| Step: 3
Training loss: 2.452181816101074
Validation loss: 2.008719908293857

Epoch: 5| Step: 4
Training loss: 2.3021137714385986
Validation loss: 2.0364348311578073

Epoch: 5| Step: 5
Training loss: 1.578701138496399
Validation loss: 2.02831970748081

Epoch: 5| Step: 6
Training loss: 1.696083664894104
Validation loss: 2.0351729764733264

Epoch: 5| Step: 7
Training loss: 1.6378624439239502
Validation loss: 2.0667202267595517

Epoch: 5| Step: 8
Training loss: 2.1319327354431152
Validation loss: 2.051450837043024

Epoch: 5| Step: 9
Training loss: 1.4588139057159424
Validation loss: 2.047420335072343

Epoch: 5| Step: 10
Training loss: 1.542859435081482
Validation loss: 2.051806280689855

Epoch: 282| Step: 0
Training loss: 1.9855327606201172
Validation loss: 2.0310068566312074

Epoch: 5| Step: 1
Training loss: 2.151824951171875
Validation loss: 2.073761861811402

Epoch: 5| Step: 2
Training loss: 1.465917944908142
Validation loss: 2.0665733942421536

Epoch: 5| Step: 3
Training loss: 2.0969057083129883
Validation loss: 2.0738357215799312

Epoch: 5| Step: 4
Training loss: 1.7725775241851807
Validation loss: 2.0185392595106557

Epoch: 5| Step: 5
Training loss: 0.8762351274490356
Validation loss: 2.0472863694672943

Epoch: 5| Step: 6
Training loss: 1.9227453470230103
Validation loss: 2.010464588801066

Epoch: 5| Step: 7
Training loss: 2.5505053997039795
Validation loss: 2.0350685068356094

Epoch: 5| Step: 8
Training loss: 1.7908029556274414
Validation loss: 2.023819487581971

Epoch: 5| Step: 9
Training loss: 2.0271716117858887
Validation loss: 2.0420554068780716

Epoch: 5| Step: 10
Training loss: 1.7394137382507324
Validation loss: 2.023070227715277

Epoch: 283| Step: 0
Training loss: 1.8763889074325562
Validation loss: 1.9911113605704358

Epoch: 5| Step: 1
Training loss: 1.549424409866333
Validation loss: 2.0368787909066803

Epoch: 5| Step: 2
Training loss: 1.9688899517059326
Validation loss: 1.9978208131687616

Epoch: 5| Step: 3
Training loss: 1.8096567392349243
Validation loss: 2.0162433725531383

Epoch: 5| Step: 4
Training loss: 2.295539379119873
Validation loss: 2.0354831757084018

Epoch: 5| Step: 5
Training loss: 1.6936962604522705
Validation loss: 2.0493805549478017

Epoch: 5| Step: 6
Training loss: 1.671700119972229
Validation loss: 2.034862364492109

Epoch: 5| Step: 7
Training loss: 2.226651191711426
Validation loss: 2.0078892823188537

Epoch: 5| Step: 8
Training loss: 2.0540108680725098
Validation loss: 2.022358147046899

Epoch: 5| Step: 9
Training loss: 1.4035011529922485
Validation loss: 2.010092173853228

Epoch: 5| Step: 10
Training loss: 1.901740550994873
Validation loss: 2.0458912798153457

Epoch: 284| Step: 0
Training loss: 1.8444551229476929
Validation loss: 2.01856509588098

Epoch: 5| Step: 1
Training loss: 1.3910921812057495
Validation loss: 2.027554263350784

Epoch: 5| Step: 2
Training loss: 2.0416855812072754
Validation loss: 2.032727277407082

Epoch: 5| Step: 3
Training loss: 1.9657890796661377
Validation loss: 2.0130937484002884

Epoch: 5| Step: 4
Training loss: 2.0277099609375
Validation loss: 2.0366558733806817

Epoch: 5| Step: 5
Training loss: 1.9813063144683838
Validation loss: 2.034862523437828

Epoch: 5| Step: 6
Training loss: 2.187201976776123
Validation loss: 2.0378507221898725

Epoch: 5| Step: 7
Training loss: 1.4845428466796875
Validation loss: 2.0423432652668287

Epoch: 5| Step: 8
Training loss: 1.8217071294784546
Validation loss: 2.0406707089434386

Epoch: 5| Step: 9
Training loss: 1.469687581062317
Validation loss: 2.037216824869956

Epoch: 5| Step: 10
Training loss: 2.196704149246216
Validation loss: 2.032737188441779

Epoch: 285| Step: 0
Training loss: 1.7508556842803955
Validation loss: 2.0238025598628546

Epoch: 5| Step: 1
Training loss: 1.4879652261734009
Validation loss: 2.0167765296915525

Epoch: 5| Step: 2
Training loss: 2.228684186935425
Validation loss: 2.013357489339767

Epoch: 5| Step: 3
Training loss: 1.6800581216812134
Validation loss: 2.0459756543559413

Epoch: 5| Step: 4
Training loss: 2.3225860595703125
Validation loss: 2.0504050280458186

Epoch: 5| Step: 5
Training loss: 1.5777056217193604
Validation loss: 2.025837508581018

Epoch: 5| Step: 6
Training loss: 1.397530198097229
Validation loss: 2.007628663893669

Epoch: 5| Step: 7
Training loss: 1.7192814350128174
Validation loss: 2.004531838560617

Epoch: 5| Step: 8
Training loss: 2.0459327697753906
Validation loss: 2.024210232560353

Epoch: 5| Step: 9
Training loss: 2.58329439163208
Validation loss: 2.013028537073443

Epoch: 5| Step: 10
Training loss: 1.6874536275863647
Validation loss: 2.0408742940554054

Epoch: 286| Step: 0
Training loss: 1.9493621587753296
Validation loss: 2.0145388021264026

Epoch: 5| Step: 1
Training loss: 2.1534478664398193
Validation loss: 2.0409893489653066

Epoch: 5| Step: 2
Training loss: 2.12251615524292
Validation loss: 2.0300244131395893

Epoch: 5| Step: 3
Training loss: 1.7422869205474854
Validation loss: 2.0252301436598583

Epoch: 5| Step: 4
Training loss: 2.052748680114746
Validation loss: 2.0315014393098894

Epoch: 5| Step: 5
Training loss: 1.4350292682647705
Validation loss: 2.046793387782189

Epoch: 5| Step: 6
Training loss: 1.5268528461456299
Validation loss: 2.0348862858228784

Epoch: 5| Step: 7
Training loss: 1.5489091873168945
Validation loss: 2.0188058012275287

Epoch: 5| Step: 8
Training loss: 1.8333055973052979
Validation loss: 2.0061070111490067

Epoch: 5| Step: 9
Training loss: 1.9564361572265625
Validation loss: 2.038758118947347

Epoch: 5| Step: 10
Training loss: 1.937469482421875
Validation loss: 2.022196110858712

Epoch: 287| Step: 0
Training loss: 1.2611643075942993
Validation loss: 2.0354086224750807

Epoch: 5| Step: 1
Training loss: 2.137040138244629
Validation loss: 2.0055118324936076

Epoch: 5| Step: 2
Training loss: 1.7766139507293701
Validation loss: 2.0463457171634962

Epoch: 5| Step: 3
Training loss: 1.8439044952392578
Validation loss: 2.035779321065513

Epoch: 5| Step: 4
Training loss: 1.7482101917266846
Validation loss: 2.013020328296128

Epoch: 5| Step: 5
Training loss: 1.7763166427612305
Validation loss: 2.0061671515946746

Epoch: 5| Step: 6
Training loss: 1.7431323528289795
Validation loss: 2.00947767432018

Epoch: 5| Step: 7
Training loss: 1.6684634685516357
Validation loss: 2.0179846389319307

Epoch: 5| Step: 8
Training loss: 1.8394834995269775
Validation loss: 2.042445828837733

Epoch: 5| Step: 9
Training loss: 1.8081920146942139
Validation loss: 2.016486099971238

Epoch: 5| Step: 10
Training loss: 2.7228927612304688
Validation loss: 2.0156892191979194

Epoch: 288| Step: 0
Training loss: 1.7921676635742188
Validation loss: 2.021921529564806

Epoch: 5| Step: 1
Training loss: 1.6368080377578735
Validation loss: 2.0180455689789145

Epoch: 5| Step: 2
Training loss: 1.6858463287353516
Validation loss: 2.006844700023692

Epoch: 5| Step: 3
Training loss: 1.7672741413116455
Validation loss: 2.02888088328864

Epoch: 5| Step: 4
Training loss: 2.0253913402557373
Validation loss: 2.009639242643951

Epoch: 5| Step: 5
Training loss: 1.8520492315292358
Validation loss: 2.014206204363095

Epoch: 5| Step: 6
Training loss: 1.620192527770996
Validation loss: 1.9917849968838435

Epoch: 5| Step: 7
Training loss: 1.7579435110092163
Validation loss: 1.9885992721844745

Epoch: 5| Step: 8
Training loss: 1.7143710851669312
Validation loss: 2.0269406418646536

Epoch: 5| Step: 9
Training loss: 2.2403082847595215
Validation loss: 2.025771382034466

Epoch: 5| Step: 10
Training loss: 2.0282363891601562
Validation loss: 2.0258023533769833

Epoch: 289| Step: 0
Training loss: 2.212815999984741
Validation loss: 2.0272793128926265

Epoch: 5| Step: 1
Training loss: 1.9590122699737549
Validation loss: 2.036729799803867

Epoch: 5| Step: 2
Training loss: 1.700852394104004
Validation loss: 2.0184509856726534

Epoch: 5| Step: 3
Training loss: 2.4553253650665283
Validation loss: 2.0100706136354836

Epoch: 5| Step: 4
Training loss: 1.695077896118164
Validation loss: 2.022815706909344

Epoch: 5| Step: 5
Training loss: 1.5284370183944702
Validation loss: 2.033927244524802

Epoch: 5| Step: 6
Training loss: 1.818134069442749
Validation loss: 2.041028074038926

Epoch: 5| Step: 7
Training loss: 1.68450927734375
Validation loss: 2.0361381397452405

Epoch: 5| Step: 8
Training loss: 1.4267470836639404
Validation loss: 2.031702090335149

Epoch: 5| Step: 9
Training loss: 2.103855609893799
Validation loss: 2.024808294029646

Epoch: 5| Step: 10
Training loss: 1.6952639818191528
Validation loss: 2.0375222980335193

Epoch: 290| Step: 0
Training loss: 2.163142681121826
Validation loss: 2.028134669027021

Epoch: 5| Step: 1
Training loss: 1.773397445678711
Validation loss: 2.0333030146937214

Epoch: 5| Step: 2
Training loss: 1.7144200801849365
Validation loss: 2.062352370190364

Epoch: 5| Step: 3
Training loss: 1.5266177654266357
Validation loss: 2.060571485950101

Epoch: 5| Step: 4
Training loss: 1.9303287267684937
Validation loss: 1.998085766710261

Epoch: 5| Step: 5
Training loss: 2.378511667251587
Validation loss: 2.0074710820310857

Epoch: 5| Step: 6
Training loss: 1.9178413152694702
Validation loss: 2.0196440886425715

Epoch: 5| Step: 7
Training loss: 1.7709318399429321
Validation loss: 2.0505471127007597

Epoch: 5| Step: 8
Training loss: 2.0041728019714355
Validation loss: 2.044620067842545

Epoch: 5| Step: 9
Training loss: 1.3428739309310913
Validation loss: 2.059460619444488

Epoch: 5| Step: 10
Training loss: 1.8433908224105835
Validation loss: 2.0362592345924786

Epoch: 291| Step: 0
Training loss: 1.657888412475586
Validation loss: 2.052229212176415

Epoch: 5| Step: 1
Training loss: 2.370321750640869
Validation loss: 2.0297306737592145

Epoch: 5| Step: 2
Training loss: 1.9934669733047485
Validation loss: 2.041505226524927

Epoch: 5| Step: 3
Training loss: 1.7075620889663696
Validation loss: 2.0181078410917714

Epoch: 5| Step: 4
Training loss: 1.833583116531372
Validation loss: 2.0325511373499388

Epoch: 5| Step: 5
Training loss: 1.8043267726898193
Validation loss: 1.9886806805928547

Epoch: 5| Step: 6
Training loss: 1.7944730520248413
Validation loss: 2.0032288643621627

Epoch: 5| Step: 7
Training loss: 2.2856996059417725
Validation loss: 2.020415708582888

Epoch: 5| Step: 8
Training loss: 1.3029779195785522
Validation loss: 2.0313253697528633

Epoch: 5| Step: 9
Training loss: 1.7149524688720703
Validation loss: 2.0262183232973983

Epoch: 5| Step: 10
Training loss: 1.7890175580978394
Validation loss: 2.0339103411602717

Epoch: 292| Step: 0
Training loss: 1.6927427053451538
Validation loss: 2.0577828653397097

Epoch: 5| Step: 1
Training loss: 1.4734458923339844
Validation loss: 2.020299016788442

Epoch: 5| Step: 2
Training loss: 1.8632681369781494
Validation loss: 2.035980732210221

Epoch: 5| Step: 3
Training loss: 1.8681503534317017
Validation loss: 2.0153819181585826

Epoch: 5| Step: 4
Training loss: 1.6318271160125732
Validation loss: 2.0458127837027273

Epoch: 5| Step: 5
Training loss: 2.2593650817871094
Validation loss: 2.038782624788182

Epoch: 5| Step: 6
Training loss: 2.0756731033325195
Validation loss: 2.0432353301714827

Epoch: 5| Step: 7
Training loss: 2.1266086101531982
Validation loss: 2.0767026485935336

Epoch: 5| Step: 8
Training loss: 1.796219825744629
Validation loss: 2.056764869279759

Epoch: 5| Step: 9
Training loss: 1.6800127029418945
Validation loss: 2.0048274711896013

Epoch: 5| Step: 10
Training loss: 1.7588506937026978
Validation loss: 2.0351599518970778

Epoch: 293| Step: 0
Training loss: 1.682427167892456
Validation loss: 2.0490414199008735

Epoch: 5| Step: 1
Training loss: 1.4425792694091797
Validation loss: 2.044173668789607

Epoch: 5| Step: 2
Training loss: 1.8073537349700928
Validation loss: 2.0466122358076033

Epoch: 5| Step: 3
Training loss: 1.9941036701202393
Validation loss: 2.038089047196091

Epoch: 5| Step: 4
Training loss: 1.6689765453338623
Validation loss: 2.039339916680449

Epoch: 5| Step: 5
Training loss: 1.2033296823501587
Validation loss: 2.0561396460379324

Epoch: 5| Step: 6
Training loss: 1.3976162672042847
Validation loss: 1.999710100953297

Epoch: 5| Step: 7
Training loss: 2.8211066722869873
Validation loss: 2.032172461991669

Epoch: 5| Step: 8
Training loss: 1.9378511905670166
Validation loss: 2.0471688188532347

Epoch: 5| Step: 9
Training loss: 2.1996710300445557
Validation loss: 2.036092474896421

Epoch: 5| Step: 10
Training loss: 2.0431723594665527
Validation loss: 2.0463736288009153

Epoch: 294| Step: 0
Training loss: 1.9017452001571655
Validation loss: 2.0350522213084723

Epoch: 5| Step: 1
Training loss: 1.6419963836669922
Validation loss: 2.041876264797744

Epoch: 5| Step: 2
Training loss: 1.6531589031219482
Validation loss: 2.054206214925294

Epoch: 5| Step: 3
Training loss: 2.1995341777801514
Validation loss: 2.011794941399687

Epoch: 5| Step: 4
Training loss: 1.7782018184661865
Validation loss: 2.034505892825383

Epoch: 5| Step: 5
Training loss: 1.6608126163482666
Validation loss: 2.010185239135578

Epoch: 5| Step: 6
Training loss: 2.324028253555298
Validation loss: 2.019104455107002

Epoch: 5| Step: 7
Training loss: 1.5766981840133667
Validation loss: 2.0476275413267073

Epoch: 5| Step: 8
Training loss: 1.9616937637329102
Validation loss: 2.0132116758695213

Epoch: 5| Step: 9
Training loss: 1.887510895729065
Validation loss: 2.0322798580251713

Epoch: 5| Step: 10
Training loss: 1.533595323562622
Validation loss: 2.020955588227959

Epoch: 295| Step: 0
Training loss: 1.6691982746124268
Validation loss: 2.0141179625706007

Epoch: 5| Step: 1
Training loss: 1.3447661399841309
Validation loss: 2.040431685345147

Epoch: 5| Step: 2
Training loss: 1.610038161277771
Validation loss: 2.0362554237406743

Epoch: 5| Step: 3
Training loss: 2.271162509918213
Validation loss: 2.0088913286885908

Epoch: 5| Step: 4
Training loss: 2.14085054397583
Validation loss: 2.035074785191526

Epoch: 5| Step: 5
Training loss: 1.9497261047363281
Validation loss: 2.032527938965828

Epoch: 5| Step: 6
Training loss: 1.8616504669189453
Validation loss: 2.0248390500263502

Epoch: 5| Step: 7
Training loss: 1.7975006103515625
Validation loss: 2.0495623311688824

Epoch: 5| Step: 8
Training loss: 1.974802017211914
Validation loss: 2.0415653669705955

Epoch: 5| Step: 9
Training loss: 1.615136742591858
Validation loss: 2.0563854735384703

Epoch: 5| Step: 10
Training loss: 1.744626760482788
Validation loss: 2.0347277631041822

Epoch: 296| Step: 0
Training loss: 1.5729914903640747
Validation loss: 2.004139341333861

Epoch: 5| Step: 1
Training loss: 1.615235686302185
Validation loss: 2.006564094174293

Epoch: 5| Step: 2
Training loss: 1.8670740127563477
Validation loss: 1.9907062668954172

Epoch: 5| Step: 3
Training loss: 1.580775499343872
Validation loss: 2.024409758147373

Epoch: 5| Step: 4
Training loss: 1.7249618768692017
Validation loss: 2.0416073645314863

Epoch: 5| Step: 5
Training loss: 1.8415549993515015
Validation loss: 2.0508310564102663

Epoch: 5| Step: 6
Training loss: 1.9133093357086182
Validation loss: 2.0251384165979203

Epoch: 5| Step: 7
Training loss: 2.0985729694366455
Validation loss: 1.9957770045085619

Epoch: 5| Step: 8
Training loss: 2.2036843299865723
Validation loss: 2.037338182490359

Epoch: 5| Step: 9
Training loss: 2.2370548248291016
Validation loss: 2.0411929392045542

Epoch: 5| Step: 10
Training loss: 1.2161808013916016
Validation loss: 2.0272817163057226

Epoch: 297| Step: 0
Training loss: 1.8460090160369873
Validation loss: 2.0349747609066706

Epoch: 5| Step: 1
Training loss: 1.9414751529693604
Validation loss: 2.0202815455775105

Epoch: 5| Step: 2
Training loss: 1.5718421936035156
Validation loss: 2.0460823094973

Epoch: 5| Step: 3
Training loss: 1.4303252696990967
Validation loss: 2.061728113441057

Epoch: 5| Step: 4
Training loss: 1.8500473499298096
Validation loss: 2.0786502681752688

Epoch: 5| Step: 5
Training loss: 1.9824092388153076
Validation loss: 2.0767409955301592

Epoch: 5| Step: 6
Training loss: 1.857459306716919
Validation loss: 2.08227478560581

Epoch: 5| Step: 7
Training loss: 1.545518159866333
Validation loss: 2.032315533648255

Epoch: 5| Step: 8
Training loss: 2.453876495361328
Validation loss: 2.021578500347753

Epoch: 5| Step: 9
Training loss: 1.952871322631836
Validation loss: 2.0257447368355206

Epoch: 5| Step: 10
Training loss: 1.6247577667236328
Validation loss: 2.052708787302817

Epoch: 298| Step: 0
Training loss: 2.1637043952941895
Validation loss: 2.0625222729098414

Epoch: 5| Step: 1
Training loss: 1.5995913743972778
Validation loss: 2.0371235609054565

Epoch: 5| Step: 2
Training loss: 1.5888140201568604
Validation loss: 2.0450735681800434

Epoch: 5| Step: 3
Training loss: 1.414804220199585
Validation loss: 2.052779748875608

Epoch: 5| Step: 4
Training loss: 1.5023380517959595
Validation loss: 2.0416873373011106

Epoch: 5| Step: 5
Training loss: 1.8106157779693604
Validation loss: 2.0131501831034178

Epoch: 5| Step: 6
Training loss: 2.3079495429992676
Validation loss: 2.0330544235885784

Epoch: 5| Step: 7
Training loss: 1.8979421854019165
Validation loss: 2.0277261682735976

Epoch: 5| Step: 8
Training loss: 2.205043315887451
Validation loss: 2.042592340900052

Epoch: 5| Step: 9
Training loss: 1.800722360610962
Validation loss: 2.0270845031225555

Epoch: 5| Step: 10
Training loss: 1.581298589706421
Validation loss: 2.0199569040729153

Epoch: 299| Step: 0
Training loss: 2.143436908721924
Validation loss: 2.0431970306622085

Epoch: 5| Step: 1
Training loss: 1.3869563341140747
Validation loss: 2.013555142187303

Epoch: 5| Step: 2
Training loss: 1.475569486618042
Validation loss: 2.0494319674789265

Epoch: 5| Step: 3
Training loss: 1.6893056631088257
Validation loss: 2.0322357659698813

Epoch: 5| Step: 4
Training loss: 2.270146131515503
Validation loss: 2.046955006096953

Epoch: 5| Step: 5
Training loss: 1.4885705709457397
Validation loss: 2.0339903523845058

Epoch: 5| Step: 6
Training loss: 1.6952497959136963
Validation loss: 2.04167269122216

Epoch: 5| Step: 7
Training loss: 1.9687461853027344
Validation loss: 2.0307759687464726

Epoch: 5| Step: 8
Training loss: 2.334346055984497
Validation loss: 2.040997500060707

Epoch: 5| Step: 9
Training loss: 1.9811267852783203
Validation loss: 2.069470574778895

Epoch: 5| Step: 10
Training loss: 1.455883502960205
Validation loss: 2.06755926019402

Epoch: 300| Step: 0
Training loss: 1.9062092304229736
Validation loss: 2.037032717017717

Epoch: 5| Step: 1
Training loss: 1.7025024890899658
Validation loss: 2.0315142831494732

Epoch: 5| Step: 2
Training loss: 2.110640048980713
Validation loss: 2.019003543802487

Epoch: 5| Step: 3
Training loss: 2.6723990440368652
Validation loss: 2.061698034245481

Epoch: 5| Step: 4
Training loss: 1.1695582866668701
Validation loss: 2.025544592129287

Epoch: 5| Step: 5
Training loss: 1.666516900062561
Validation loss: 2.044456128151186

Epoch: 5| Step: 6
Training loss: 1.776435136795044
Validation loss: 2.0489858068445677

Epoch: 5| Step: 7
Training loss: 1.5231865644454956
Validation loss: 2.0466762281233266

Epoch: 5| Step: 8
Training loss: 1.6268272399902344
Validation loss: 2.046422186718192

Epoch: 5| Step: 9
Training loss: 1.9302394390106201
Validation loss: 2.0520492215310373

Epoch: 5| Step: 10
Training loss: 1.7720896005630493
Validation loss: 2.024616397837157

Epoch: 301| Step: 0
Training loss: 1.975045919418335
Validation loss: 2.0577432455555087

Epoch: 5| Step: 1
Training loss: 1.6919790506362915
Validation loss: 2.0295246519068235

Epoch: 5| Step: 2
Training loss: 2.1173348426818848
Validation loss: 2.0317777651612476

Epoch: 5| Step: 3
Training loss: 1.9219671487808228
Validation loss: 2.03563327686761

Epoch: 5| Step: 4
Training loss: 1.8917726278305054
Validation loss: 2.0671867145005094

Epoch: 5| Step: 5
Training loss: 1.6999574899673462
Validation loss: 2.021739839225687

Epoch: 5| Step: 6
Training loss: 1.333786129951477
Validation loss: 2.029717670973911

Epoch: 5| Step: 7
Training loss: 1.342810034751892
Validation loss: 2.049714143558215

Epoch: 5| Step: 8
Training loss: 2.2878735065460205
Validation loss: 2.027880007220853

Epoch: 5| Step: 9
Training loss: 1.8635568618774414
Validation loss: 2.014053434453985

Epoch: 5| Step: 10
Training loss: 1.8169431686401367
Validation loss: 2.0505823909595446

Epoch: 302| Step: 0
Training loss: 1.9994239807128906
Validation loss: 2.036723167665543

Epoch: 5| Step: 1
Training loss: 1.2219064235687256
Validation loss: 2.02520328439692

Epoch: 5| Step: 2
Training loss: 1.9037033319473267
Validation loss: 2.047548746549955

Epoch: 5| Step: 3
Training loss: 1.990713119506836
Validation loss: 2.0474866820919897

Epoch: 5| Step: 4
Training loss: 2.0531344413757324
Validation loss: 2.042144952281829

Epoch: 5| Step: 5
Training loss: 1.6135507822036743
Validation loss: 2.0384938819434053

Epoch: 5| Step: 6
Training loss: 1.9609750509262085
Validation loss: 2.0723895616428827

Epoch: 5| Step: 7
Training loss: 1.4620742797851562
Validation loss: 2.0394606795362247

Epoch: 5| Step: 8
Training loss: 1.809200644493103
Validation loss: 2.0372917036856375

Epoch: 5| Step: 9
Training loss: 1.7979233264923096
Validation loss: 2.0350291062426824

Epoch: 5| Step: 10
Training loss: 2.2063651084899902
Validation loss: 2.062188281807848

Epoch: 303| Step: 0
Training loss: 2.0386948585510254
Validation loss: 2.039312316525367

Epoch: 5| Step: 1
Training loss: 1.580928921699524
Validation loss: 2.0451104602506085

Epoch: 5| Step: 2
Training loss: 1.6827179193496704
Validation loss: 2.041166010723319

Epoch: 5| Step: 3
Training loss: 1.962904691696167
Validation loss: 2.0211043204030683

Epoch: 5| Step: 4
Training loss: 1.8197959661483765
Validation loss: 2.0481242659271404

Epoch: 5| Step: 5
Training loss: 1.8973671197891235
Validation loss: 2.0390215560954106

Epoch: 5| Step: 6
Training loss: 1.5446354150772095
Validation loss: 2.042129503783359

Epoch: 5| Step: 7
Training loss: 1.4640603065490723
Validation loss: 2.0629878851675216

Epoch: 5| Step: 8
Training loss: 2.0570132732391357
Validation loss: 2.0296651560773133

Epoch: 5| Step: 9
Training loss: 1.5097612142562866
Validation loss: 2.0343470547788884

Epoch: 5| Step: 10
Training loss: 2.538930892944336
Validation loss: 2.03577152375252

Epoch: 304| Step: 0
Training loss: 1.4069435596466064
Validation loss: 1.9845221465633762

Epoch: 5| Step: 1
Training loss: 2.402128219604492
Validation loss: 2.0095443520494687

Epoch: 5| Step: 2
Training loss: 1.7060960531234741
Validation loss: 2.056544837131295

Epoch: 5| Step: 3
Training loss: 2.33056640625
Validation loss: 2.0236415324672574

Epoch: 5| Step: 4
Training loss: 1.1945078372955322
Validation loss: 2.041467370525483

Epoch: 5| Step: 5
Training loss: 2.90392804145813
Validation loss: 2.0132230840703493

Epoch: 5| Step: 6
Training loss: 1.509594202041626
Validation loss: 2.0180714950766614

Epoch: 5| Step: 7
Training loss: 1.636884331703186
Validation loss: 2.0293015613350818

Epoch: 5| Step: 8
Training loss: 1.613226294517517
Validation loss: 2.002289652824402

Epoch: 5| Step: 9
Training loss: 1.8629738092422485
Validation loss: 2.0356380349846295

Epoch: 5| Step: 10
Training loss: 1.2714160680770874
Validation loss: 2.046216139229395

Epoch: 305| Step: 0
Training loss: 1.630639672279358
Validation loss: 2.0375508236628708

Epoch: 5| Step: 1
Training loss: 2.4524683952331543
Validation loss: 2.0449210418167936

Epoch: 5| Step: 2
Training loss: 1.6089664697647095
Validation loss: 2.035963794236542

Epoch: 5| Step: 3
Training loss: 2.1545238494873047
Validation loss: 2.018989439933531

Epoch: 5| Step: 4
Training loss: 1.6606677770614624
Validation loss: 2.046965488823511

Epoch: 5| Step: 5
Training loss: 1.7614275217056274
Validation loss: 2.0499672171890095

Epoch: 5| Step: 6
Training loss: 1.774675726890564
Validation loss: 2.0473353952489872

Epoch: 5| Step: 7
Training loss: 1.3389606475830078
Validation loss: 2.066220329653832

Epoch: 5| Step: 8
Training loss: 1.8645292520523071
Validation loss: 2.053711801446894

Epoch: 5| Step: 9
Training loss: 1.8817428350448608
Validation loss: 2.061324381059216

Epoch: 5| Step: 10
Training loss: 1.779168725013733
Validation loss: 2.072674684627082

Epoch: 306| Step: 0
Training loss: 1.3106305599212646
Validation loss: 2.0642321853227514

Epoch: 5| Step: 1
Training loss: 1.5817872285842896
Validation loss: 2.0366355706286687

Epoch: 5| Step: 2
Training loss: 2.092374324798584
Validation loss: 2.084042179969049

Epoch: 5| Step: 3
Training loss: 1.4883824586868286
Validation loss: 2.061536701776648

Epoch: 5| Step: 4
Training loss: 2.0960710048675537
Validation loss: 2.07539213344615

Epoch: 5| Step: 5
Training loss: 2.076108932495117
Validation loss: 2.06801244648554

Epoch: 5| Step: 6
Training loss: 1.911630392074585
Validation loss: 2.055971036675156

Epoch: 5| Step: 7
Training loss: 1.6818695068359375
Validation loss: 2.056571214429794

Epoch: 5| Step: 8
Training loss: 1.9585069417953491
Validation loss: 2.0475822135966313

Epoch: 5| Step: 9
Training loss: 1.545738935470581
Validation loss: 2.044460286376297

Epoch: 5| Step: 10
Training loss: 2.0176877975463867
Validation loss: 2.036758497197141

Epoch: 307| Step: 0
Training loss: 1.2748456001281738
Validation loss: 2.0324880358993367

Epoch: 5| Step: 1
Training loss: 1.4902942180633545
Validation loss: 2.0389771499941425

Epoch: 5| Step: 2
Training loss: 1.7032346725463867
Validation loss: 2.0521342113453853

Epoch: 5| Step: 3
Training loss: 2.0546669960021973
Validation loss: 2.0584367603384037

Epoch: 5| Step: 4
Training loss: 2.0385336875915527
Validation loss: 2.0439391828352407

Epoch: 5| Step: 5
Training loss: 2.13087797164917
Validation loss: 2.0416649310819563

Epoch: 5| Step: 6
Training loss: 1.987026572227478
Validation loss: 2.0179556005744526

Epoch: 5| Step: 7
Training loss: 1.2698132991790771
Validation loss: 2.0028183101325907

Epoch: 5| Step: 8
Training loss: 1.6806821823120117
Validation loss: 2.0328248495696695

Epoch: 5| Step: 9
Training loss: 2.5178980827331543
Validation loss: 2.0388669185740973

Epoch: 5| Step: 10
Training loss: 1.460160732269287
Validation loss: 2.054039091192266

Epoch: 308| Step: 0
Training loss: 1.8394237756729126
Validation loss: 2.0660990040789367

Epoch: 5| Step: 1
Training loss: 1.3073105812072754
Validation loss: 2.036771930674071

Epoch: 5| Step: 2
Training loss: 1.2326306104660034
Validation loss: 2.033478654840941

Epoch: 5| Step: 3
Training loss: 2.054208278656006
Validation loss: 2.041219166530076

Epoch: 5| Step: 4
Training loss: 1.8349628448486328
Validation loss: 2.022520572908463

Epoch: 5| Step: 5
Training loss: 1.567691445350647
Validation loss: 2.0727355762194564

Epoch: 5| Step: 6
Training loss: 2.04978346824646
Validation loss: 2.0464020416300785

Epoch: 5| Step: 7
Training loss: 2.055325984954834
Validation loss: 2.0291567066664338

Epoch: 5| Step: 8
Training loss: 1.9828894138336182
Validation loss: 2.034714944901005

Epoch: 5| Step: 9
Training loss: 1.7928482294082642
Validation loss: 2.0394966551052627

Epoch: 5| Step: 10
Training loss: 2.0998952388763428
Validation loss: 2.072387259493592

Epoch: 309| Step: 0
Training loss: 2.037785768508911
Validation loss: 2.0271664639954925

Epoch: 5| Step: 1
Training loss: 1.9124046564102173
Validation loss: 2.0699129002068632

Epoch: 5| Step: 2
Training loss: 1.5054528713226318
Validation loss: 2.069370836339971

Epoch: 5| Step: 3
Training loss: 1.7785489559173584
Validation loss: 2.0327210810876664

Epoch: 5| Step: 4
Training loss: 1.6969776153564453
Validation loss: 2.0505967306834396

Epoch: 5| Step: 5
Training loss: 2.1229052543640137
Validation loss: 2.0443602761914654

Epoch: 5| Step: 6
Training loss: 1.6162973642349243
Validation loss: 2.061849738961907

Epoch: 5| Step: 7
Training loss: 1.6124563217163086
Validation loss: 2.0404749839536604

Epoch: 5| Step: 8
Training loss: 1.8324283361434937
Validation loss: 2.0555346524843605

Epoch: 5| Step: 9
Training loss: 1.7111495733261108
Validation loss: 2.044842327794721

Epoch: 5| Step: 10
Training loss: 1.7520296573638916
Validation loss: 2.019928882198949

Epoch: 310| Step: 0
Training loss: 1.6425386667251587
Validation loss: 2.0321644826601912

Epoch: 5| Step: 1
Training loss: 1.7500253915786743
Validation loss: 2.0483580193211957

Epoch: 5| Step: 2
Training loss: 1.7929474115371704
Validation loss: 2.0147557489333616

Epoch: 5| Step: 3
Training loss: 1.8007307052612305
Validation loss: 2.025789258300617

Epoch: 5| Step: 4
Training loss: 1.8562538623809814
Validation loss: 2.0183863191194433

Epoch: 5| Step: 5
Training loss: 2.2278759479522705
Validation loss: 2.0552327773904286

Epoch: 5| Step: 6
Training loss: 1.9872105121612549
Validation loss: 2.020611460490893

Epoch: 5| Step: 7
Training loss: 2.34243106842041
Validation loss: 2.0293359628287693

Epoch: 5| Step: 8
Training loss: 1.5665918588638306
Validation loss: 2.047503161173995

Epoch: 5| Step: 9
Training loss: 1.0595413446426392
Validation loss: 2.068636873716949

Epoch: 5| Step: 10
Training loss: 1.8334449529647827
Validation loss: 2.0379661411367436

Epoch: 311| Step: 0
Training loss: 1.6163549423217773
Validation loss: 2.045898691300423

Epoch: 5| Step: 1
Training loss: 2.0348000526428223
Validation loss: 2.0236228781361736

Epoch: 5| Step: 2
Training loss: 0.8150681257247925
Validation loss: 2.03955775947981

Epoch: 5| Step: 3
Training loss: 2.088914155960083
Validation loss: 2.027570346350311

Epoch: 5| Step: 4
Training loss: 2.3869071006774902
Validation loss: 2.010321981163435

Epoch: 5| Step: 5
Training loss: 1.9780476093292236
Validation loss: 2.0199269966412614

Epoch: 5| Step: 6
Training loss: 1.5960118770599365
Validation loss: 2.0220244328180947

Epoch: 5| Step: 7
Training loss: 1.3897916078567505
Validation loss: 2.0412245373572073

Epoch: 5| Step: 8
Training loss: 1.8872734308242798
Validation loss: 2.0350497717498452

Epoch: 5| Step: 9
Training loss: 1.9025732278823853
Validation loss: 2.0164088715789137

Epoch: 5| Step: 10
Training loss: 2.021385908126831
Validation loss: 2.0351412039931103

Epoch: 312| Step: 0
Training loss: 1.5400681495666504
Validation loss: 1.9991544600455993

Epoch: 5| Step: 1
Training loss: 1.3467365503311157
Validation loss: 2.0451807142585836

Epoch: 5| Step: 2
Training loss: 2.0282294750213623
Validation loss: 2.0388093289508613

Epoch: 5| Step: 3
Training loss: 2.3177762031555176
Validation loss: 2.044815908196152

Epoch: 5| Step: 4
Training loss: 1.7096408605575562
Validation loss: 2.076080242792765

Epoch: 5| Step: 5
Training loss: 2.3853535652160645
Validation loss: 2.0420884534876835

Epoch: 5| Step: 6
Training loss: 1.5713410377502441
Validation loss: 2.0565821816844325

Epoch: 5| Step: 7
Training loss: 1.8406823873519897
Validation loss: 2.047074249995652

Epoch: 5| Step: 8
Training loss: 1.5205129384994507
Validation loss: 2.032347015155259

Epoch: 5| Step: 9
Training loss: 1.582522988319397
Validation loss: 2.0698225062380553

Epoch: 5| Step: 10
Training loss: 1.7431106567382812
Validation loss: 2.0546777850838116

Epoch: 313| Step: 0
Training loss: 2.242932081222534
Validation loss: 2.057493717439713

Epoch: 5| Step: 1
Training loss: 1.4886244535446167
Validation loss: 2.0853515850600375

Epoch: 5| Step: 2
Training loss: 1.9285987615585327
Validation loss: 2.0842971353120703

Epoch: 5| Step: 3
Training loss: 1.2328059673309326
Validation loss: 2.040947378322642

Epoch: 5| Step: 4
Training loss: 2.0927090644836426
Validation loss: 2.049394493461937

Epoch: 5| Step: 5
Training loss: 1.3644005060195923
Validation loss: 2.017926319952934

Epoch: 5| Step: 6
Training loss: 1.7164013385772705
Validation loss: 2.026655089470648

Epoch: 5| Step: 7
Training loss: 2.6697146892547607
Validation loss: 2.0095621975519324

Epoch: 5| Step: 8
Training loss: 1.690049409866333
Validation loss: 2.0325544803373274

Epoch: 5| Step: 9
Training loss: 1.693633794784546
Validation loss: 2.032474128148889

Epoch: 5| Step: 10
Training loss: 1.5174049139022827
Validation loss: 2.0317849241277224

Epoch: 314| Step: 0
Training loss: 1.9555809497833252
Validation loss: 1.9992917981199039

Epoch: 5| Step: 1
Training loss: 2.059551954269409
Validation loss: 2.027211648161693

Epoch: 5| Step: 2
Training loss: 1.2904081344604492
Validation loss: 2.0542970588130336

Epoch: 5| Step: 3
Training loss: 1.923179268836975
Validation loss: 2.0446386952554025

Epoch: 5| Step: 4
Training loss: 1.7206681966781616
Validation loss: 2.0369508317721787

Epoch: 5| Step: 5
Training loss: 2.2495856285095215
Validation loss: 2.0320710161680817

Epoch: 5| Step: 6
Training loss: 2.079049587249756
Validation loss: 2.0321890090101506

Epoch: 5| Step: 7
Training loss: 1.3592089414596558
Validation loss: 2.058456467043969

Epoch: 5| Step: 8
Training loss: 2.027219533920288
Validation loss: 2.065271318599742

Epoch: 5| Step: 9
Training loss: 1.1261403560638428
Validation loss: 1.9972892474102717

Epoch: 5| Step: 10
Training loss: 1.8656129837036133
Validation loss: 2.0580612664581626

Epoch: 315| Step: 0
Training loss: 2.058370590209961
Validation loss: 2.0425333566563104

Epoch: 5| Step: 1
Training loss: 1.496027946472168
Validation loss: 2.065430354046565

Epoch: 5| Step: 2
Training loss: 1.537119746208191
Validation loss: 2.013619348567019

Epoch: 5| Step: 3
Training loss: 1.546008586883545
Validation loss: 2.0229762100404307

Epoch: 5| Step: 4
Training loss: 1.6924502849578857
Validation loss: 2.051200661607968

Epoch: 5| Step: 5
Training loss: 1.8118184804916382
Validation loss: 2.022545963205317

Epoch: 5| Step: 6
Training loss: 1.7655155658721924
Validation loss: 2.041377789230757

Epoch: 5| Step: 7
Training loss: 1.797216773033142
Validation loss: 2.042503768397916

Epoch: 5| Step: 8
Training loss: 1.9552764892578125
Validation loss: 2.013464095771954

Epoch: 5| Step: 9
Training loss: 1.2871724367141724
Validation loss: 2.0371122052592616

Epoch: 5| Step: 10
Training loss: 2.8120481967926025
Validation loss: 2.028610449965282

Epoch: 316| Step: 0
Training loss: 1.5460174083709717
Validation loss: 2.0597073672920145

Epoch: 5| Step: 1
Training loss: 1.699728012084961
Validation loss: 2.03574441453462

Epoch: 5| Step: 2
Training loss: 1.782422661781311
Validation loss: 2.0224623910842405

Epoch: 5| Step: 3
Training loss: 2.3019254207611084
Validation loss: 2.0389812646373624

Epoch: 5| Step: 4
Training loss: 1.3724136352539062
Validation loss: 2.0184521803291897

Epoch: 5| Step: 5
Training loss: 2.339869976043701
Validation loss: 2.0093016701359905

Epoch: 5| Step: 6
Training loss: 1.6419540643692017
Validation loss: 2.0540141469688824

Epoch: 5| Step: 7
Training loss: 1.9658209085464478
Validation loss: 2.062004223946602

Epoch: 5| Step: 8
Training loss: 1.555074691772461
Validation loss: 2.0461983475633847

Epoch: 5| Step: 9
Training loss: 1.908456563949585
Validation loss: 2.068842234150056

Epoch: 5| Step: 10
Training loss: 1.5343818664550781
Validation loss: 2.0315256913503013

Epoch: 317| Step: 0
Training loss: 1.9464279413223267
Validation loss: 2.0314357652459094

Epoch: 5| Step: 1
Training loss: 1.2832527160644531
Validation loss: 2.036604340358447

Epoch: 5| Step: 2
Training loss: 1.5664281845092773
Validation loss: 2.059233700075457

Epoch: 5| Step: 3
Training loss: 1.3868900537490845
Validation loss: 2.0351601826247347

Epoch: 5| Step: 4
Training loss: 1.2541394233703613
Validation loss: 2.0443830977204027

Epoch: 5| Step: 5
Training loss: 1.8058046102523804
Validation loss: 2.0567356694129204

Epoch: 5| Step: 6
Training loss: 1.7086191177368164
Validation loss: 2.0501635382252354

Epoch: 5| Step: 7
Training loss: 1.6960817575454712
Validation loss: 2.081186488110532

Epoch: 5| Step: 8
Training loss: 2.8831474781036377
Validation loss: 2.0496085215640325

Epoch: 5| Step: 9
Training loss: 2.029109477996826
Validation loss: 2.0454410263287124

Epoch: 5| Step: 10
Training loss: 2.0618896484375
Validation loss: 2.038025691945066

Epoch: 318| Step: 0
Training loss: 2.1173157691955566
Validation loss: 2.033552985037527

Epoch: 5| Step: 1
Training loss: 1.5367982387542725
Validation loss: 2.066083695298882

Epoch: 5| Step: 2
Training loss: 1.8943004608154297
Validation loss: 2.0485568572116155

Epoch: 5| Step: 3
Training loss: 1.9970462322235107
Validation loss: 2.036801107468144

Epoch: 5| Step: 4
Training loss: 1.6114418506622314
Validation loss: 2.0531795819600425

Epoch: 5| Step: 5
Training loss: 1.3296433687210083
Validation loss: 2.023945503337409

Epoch: 5| Step: 6
Training loss: 2.133235454559326
Validation loss: 2.0577519965428177

Epoch: 5| Step: 7
Training loss: 1.8251034021377563
Validation loss: 2.045199130171089

Epoch: 5| Step: 8
Training loss: 1.745347261428833
Validation loss: 2.0455206158340618

Epoch: 5| Step: 9
Training loss: 1.7725114822387695
Validation loss: 2.055067373860267

Epoch: 5| Step: 10
Training loss: 1.662261962890625
Validation loss: 2.0533049862871886

Epoch: 319| Step: 0
Training loss: 2.1283092498779297
Validation loss: 2.031061790322745

Epoch: 5| Step: 1
Training loss: 2.10125732421875
Validation loss: 2.0240657073195263

Epoch: 5| Step: 2
Training loss: 1.7162710428237915
Validation loss: 2.040941096121265

Epoch: 5| Step: 3
Training loss: 1.721276879310608
Validation loss: 2.03386490960275

Epoch: 5| Step: 4
Training loss: 1.0612058639526367
Validation loss: 2.0453562877511464

Epoch: 5| Step: 5
Training loss: 2.1973495483398438
Validation loss: 2.0369053553509455

Epoch: 5| Step: 6
Training loss: 1.715248465538025
Validation loss: 2.0376184986483667

Epoch: 5| Step: 7
Training loss: 1.7415281534194946
Validation loss: 2.0558650083439325

Epoch: 5| Step: 8
Training loss: 1.4805734157562256
Validation loss: 2.03960560342317

Epoch: 5| Step: 9
Training loss: 1.6835410594940186
Validation loss: 2.0307620033141105

Epoch: 5| Step: 10
Training loss: 1.7562015056610107
Validation loss: 2.0557568868001304

Epoch: 320| Step: 0
Training loss: 1.7841497659683228
Validation loss: 2.042608902018557

Epoch: 5| Step: 1
Training loss: 1.9110368490219116
Validation loss: 2.0047385282413934

Epoch: 5| Step: 2
Training loss: 1.330891728401184
Validation loss: 2.0201393160768735

Epoch: 5| Step: 3
Training loss: 1.5797927379608154
Validation loss: 2.028028134376772

Epoch: 5| Step: 4
Training loss: 1.5852572917938232
Validation loss: 2.0388521353403726

Epoch: 5| Step: 5
Training loss: 2.1928133964538574
Validation loss: 2.0241279012413433

Epoch: 5| Step: 6
Training loss: 1.669904351234436
Validation loss: 2.0662911092081377

Epoch: 5| Step: 7
Training loss: 1.7253837585449219
Validation loss: 2.0470715838093914

Epoch: 5| Step: 8
Training loss: 1.850748062133789
Validation loss: 2.0527990018167803

Epoch: 5| Step: 9
Training loss: 1.5895586013793945
Validation loss: 2.0193827267616027

Epoch: 5| Step: 10
Training loss: 2.338386058807373
Validation loss: 2.0594499585449055

Epoch: 321| Step: 0
Training loss: 1.8506839275360107
Validation loss: 2.0281675374636086

Epoch: 5| Step: 1
Training loss: 2.0852115154266357
Validation loss: 2.0442156432777323

Epoch: 5| Step: 2
Training loss: 2.304006338119507
Validation loss: 2.0256088805455033

Epoch: 5| Step: 3
Training loss: 0.8720887899398804
Validation loss: 2.0527214029783845

Epoch: 5| Step: 4
Training loss: 1.442476749420166
Validation loss: 2.0515593713329685

Epoch: 5| Step: 5
Training loss: 1.7839750051498413
Validation loss: 2.0512060375623804

Epoch: 5| Step: 6
Training loss: 1.7157796621322632
Validation loss: 2.0718800893393894

Epoch: 5| Step: 7
Training loss: 1.709212303161621
Validation loss: 2.052051713389735

Epoch: 5| Step: 8
Training loss: 2.1334567070007324
Validation loss: 2.076163435495028

Epoch: 5| Step: 9
Training loss: 1.9251067638397217
Validation loss: 2.0744687152165238

Epoch: 5| Step: 10
Training loss: 1.800156593322754
Validation loss: 2.078152007954095

Epoch: 322| Step: 0
Training loss: 2.0044524669647217
Validation loss: 2.0331884584119244

Epoch: 5| Step: 1
Training loss: 1.4100961685180664
Validation loss: 2.055500953428207

Epoch: 5| Step: 2
Training loss: 2.036374568939209
Validation loss: 2.034061401121078

Epoch: 5| Step: 3
Training loss: 2.0731823444366455
Validation loss: 2.047312805729528

Epoch: 5| Step: 4
Training loss: 1.373745083808899
Validation loss: 2.038824281384868

Epoch: 5| Step: 5
Training loss: 1.8182926177978516
Validation loss: 2.04265768553621

Epoch: 5| Step: 6
Training loss: 1.9962551593780518
Validation loss: 2.057165748329573

Epoch: 5| Step: 7
Training loss: 1.5797845125198364
Validation loss: 2.018411180024506

Epoch: 5| Step: 8
Training loss: 1.5433814525604248
Validation loss: 2.0567584345417638

Epoch: 5| Step: 9
Training loss: 2.102555751800537
Validation loss: 2.0180507962421705

Epoch: 5| Step: 10
Training loss: 1.217529058456421
Validation loss: 2.0521752757410847

Epoch: 323| Step: 0
Training loss: 2.1642746925354004
Validation loss: 2.0418690789130425

Epoch: 5| Step: 1
Training loss: 1.8781805038452148
Validation loss: 2.01154334827136

Epoch: 5| Step: 2
Training loss: 1.3099696636199951
Validation loss: 2.04866002708353

Epoch: 5| Step: 3
Training loss: 1.4866656064987183
Validation loss: 2.0599936605781637

Epoch: 5| Step: 4
Training loss: 1.4481747150421143
Validation loss: 2.0328437128374652

Epoch: 5| Step: 5
Training loss: 1.9744561910629272
Validation loss: 2.0438519370171333

Epoch: 5| Step: 6
Training loss: 1.7734096050262451
Validation loss: 2.037815788740753

Epoch: 5| Step: 7
Training loss: 1.7204784154891968
Validation loss: 2.007590483593684

Epoch: 5| Step: 8
Training loss: 1.5081716775894165
Validation loss: 2.028704462512847

Epoch: 5| Step: 9
Training loss: 1.592437744140625
Validation loss: 2.00943075969655

Epoch: 5| Step: 10
Training loss: 2.474336624145508
Validation loss: 2.0655334162455734

Epoch: 324| Step: 0
Training loss: 1.5519269704818726
Validation loss: 2.060111412438013

Epoch: 5| Step: 1
Training loss: 1.7718864679336548
Validation loss: 2.0334981410734114

Epoch: 5| Step: 2
Training loss: 1.5897165536880493
Validation loss: 2.029609114893021

Epoch: 5| Step: 3
Training loss: 1.5305774211883545
Validation loss: 2.053937783805273

Epoch: 5| Step: 4
Training loss: 1.9003283977508545
Validation loss: 2.0608056847767164

Epoch: 5| Step: 5
Training loss: 1.4644006490707397
Validation loss: 2.0261848318961357

Epoch: 5| Step: 6
Training loss: 1.7738292217254639
Validation loss: 2.033733066692147

Epoch: 5| Step: 7
Training loss: 2.2628235816955566
Validation loss: 2.0552612081650765

Epoch: 5| Step: 8
Training loss: 1.9107478857040405
Validation loss: 2.06535255652602

Epoch: 5| Step: 9
Training loss: 1.8604583740234375
Validation loss: 2.0595408126872075

Epoch: 5| Step: 10
Training loss: 1.6141880750656128
Validation loss: 2.039683968790116

Epoch: 325| Step: 0
Training loss: 1.5891450643539429
Validation loss: 2.011035778189218

Epoch: 5| Step: 1
Training loss: 1.7969181537628174
Validation loss: 2.0086554942592496

Epoch: 5| Step: 2
Training loss: 1.1640722751617432
Validation loss: 2.0305571940637406

Epoch: 5| Step: 3
Training loss: 1.9990192651748657
Validation loss: 2.0273201721970753

Epoch: 5| Step: 4
Training loss: 1.8074676990509033
Validation loss: 2.06509405310436

Epoch: 5| Step: 5
Training loss: 2.063642978668213
Validation loss: 2.039017008196923

Epoch: 5| Step: 6
Training loss: 1.2617619037628174
Validation loss: 2.0400231999735676

Epoch: 5| Step: 7
Training loss: 1.7974042892456055
Validation loss: 2.039603001327925

Epoch: 5| Step: 8
Training loss: 2.1673436164855957
Validation loss: 2.03567180069544

Epoch: 5| Step: 9
Training loss: 1.9450057744979858
Validation loss: 2.0297138767857708

Epoch: 5| Step: 10
Training loss: 2.004537582397461
Validation loss: 2.0551007742522867

Epoch: 326| Step: 0
Training loss: 1.182373285293579
Validation loss: 2.063397066567534

Epoch: 5| Step: 1
Training loss: 1.8234784603118896
Validation loss: 2.028407818527632

Epoch: 5| Step: 2
Training loss: 1.9284435510635376
Validation loss: 2.045331285845849

Epoch: 5| Step: 3
Training loss: 2.090500593185425
Validation loss: 2.083099975380846

Epoch: 5| Step: 4
Training loss: 1.9123417139053345
Validation loss: 2.060257952700379

Epoch: 5| Step: 5
Training loss: 1.62765634059906
Validation loss: 2.0545783632545063

Epoch: 5| Step: 6
Training loss: 1.9470655918121338
Validation loss: 2.0235103458486576

Epoch: 5| Step: 7
Training loss: 1.4382058382034302
Validation loss: 2.018182848089485

Epoch: 5| Step: 8
Training loss: 1.7655998468399048
Validation loss: 2.01738953334029

Epoch: 5| Step: 9
Training loss: 1.3856279850006104
Validation loss: 2.021893965300693

Epoch: 5| Step: 10
Training loss: 2.351292371749878
Validation loss: 2.027884429500949

Epoch: 327| Step: 0
Training loss: 1.2941993474960327
Validation loss: 2.0165747147734447

Epoch: 5| Step: 1
Training loss: 1.9927375316619873
Validation loss: 2.0404094572990172

Epoch: 5| Step: 2
Training loss: 1.8366613388061523
Validation loss: 2.0323727976891304

Epoch: 5| Step: 3
Training loss: 1.966925024986267
Validation loss: 2.058665894692944

Epoch: 5| Step: 4
Training loss: 2.051262617111206
Validation loss: 2.035625878200736

Epoch: 5| Step: 5
Training loss: 1.8753182888031006
Validation loss: 2.0271795834264448

Epoch: 5| Step: 6
Training loss: 1.3493525981903076
Validation loss: 2.052443837606779

Epoch: 5| Step: 7
Training loss: 1.515661358833313
Validation loss: 2.0824725320262294

Epoch: 5| Step: 8
Training loss: 1.921177864074707
Validation loss: 2.0586596278734106

Epoch: 5| Step: 9
Training loss: 1.7165124416351318
Validation loss: 2.075832643816548

Epoch: 5| Step: 10
Training loss: 1.6033923625946045
Validation loss: 2.0307003067385767

Epoch: 328| Step: 0
Training loss: 1.4311139583587646
Validation loss: 2.0353715804315384

Epoch: 5| Step: 1
Training loss: 1.5065667629241943
Validation loss: 2.0661794421493367

Epoch: 5| Step: 2
Training loss: 1.6016161441802979
Validation loss: 2.0673585912232757

Epoch: 5| Step: 3
Training loss: 2.056185245513916
Validation loss: 2.0591650419337775

Epoch: 5| Step: 4
Training loss: 1.514243245124817
Validation loss: 2.0345454241639827

Epoch: 5| Step: 5
Training loss: 1.926194190979004
Validation loss: 2.0239720523998304

Epoch: 5| Step: 6
Training loss: 1.8493785858154297
Validation loss: 2.052579618269397

Epoch: 5| Step: 7
Training loss: 1.558829665184021
Validation loss: 2.0356014415781987

Epoch: 5| Step: 8
Training loss: 2.2550902366638184
Validation loss: 2.027576185041858

Epoch: 5| Step: 9
Training loss: 1.9412381649017334
Validation loss: 2.0272415414933236

Epoch: 5| Step: 10
Training loss: 1.6351394653320312
Validation loss: 2.0839195379646878

Epoch: 329| Step: 0
Training loss: 1.2740190029144287
Validation loss: 2.0213069479952575

Epoch: 5| Step: 1
Training loss: 1.610006332397461
Validation loss: 2.0303007556546118

Epoch: 5| Step: 2
Training loss: 1.3935577869415283
Validation loss: 2.046717974447435

Epoch: 5| Step: 3
Training loss: 1.5151331424713135
Validation loss: 2.046490628232238

Epoch: 5| Step: 4
Training loss: 2.0603420734405518
Validation loss: 2.069050064650915

Epoch: 5| Step: 5
Training loss: 2.158051013946533
Validation loss: 2.0524444221168436

Epoch: 5| Step: 6
Training loss: 2.5248355865478516
Validation loss: 2.0441064270593787

Epoch: 5| Step: 7
Training loss: 2.3960065841674805
Validation loss: 2.0505033180277836

Epoch: 5| Step: 8
Training loss: 1.384903907775879
Validation loss: 2.0504381810465167

Epoch: 5| Step: 9
Training loss: 1.2554519176483154
Validation loss: 2.033527271721953

Epoch: 5| Step: 10
Training loss: 1.7402642965316772
Validation loss: 2.024455672951155

Epoch: 330| Step: 0
Training loss: 1.6031444072723389
Validation loss: 2.0722253655874603

Epoch: 5| Step: 1
Training loss: 2.0796523094177246
Validation loss: 2.025835488432197

Epoch: 5| Step: 2
Training loss: 1.6072132587432861
Validation loss: 2.0288802282784575

Epoch: 5| Step: 3
Training loss: 1.1309001445770264
Validation loss: 2.0467080249581286

Epoch: 5| Step: 4
Training loss: 1.9870214462280273
Validation loss: 2.0518381262338288

Epoch: 5| Step: 5
Training loss: 2.105520486831665
Validation loss: 2.0468383527571157

Epoch: 5| Step: 6
Training loss: 1.623640775680542
Validation loss: 2.0582219618622974

Epoch: 5| Step: 7
Training loss: 1.8133634328842163
Validation loss: 2.044796920591785

Epoch: 5| Step: 8
Training loss: 1.601723074913025
Validation loss: 2.050272085333383

Epoch: 5| Step: 9
Training loss: 2.0458874702453613
Validation loss: 2.0257830606993807

Epoch: 5| Step: 10
Training loss: 1.768685221672058
Validation loss: 2.048823174609933

Epoch: 331| Step: 0
Training loss: 1.9313900470733643
Validation loss: 2.0291562823839087

Epoch: 5| Step: 1
Training loss: 1.3586446046829224
Validation loss: 2.0383589754822435

Epoch: 5| Step: 2
Training loss: 1.4295071363449097
Validation loss: 2.0515630142663115

Epoch: 5| Step: 3
Training loss: 1.6045427322387695
Validation loss: 2.0244892540798394

Epoch: 5| Step: 4
Training loss: 2.235610246658325
Validation loss: 2.0498537081544117

Epoch: 5| Step: 5
Training loss: 1.30178964138031
Validation loss: 1.992454453181195

Epoch: 5| Step: 6
Training loss: 1.7552061080932617
Validation loss: 2.025282382965088

Epoch: 5| Step: 7
Training loss: 1.843441367149353
Validation loss: 2.0525507465485604

Epoch: 5| Step: 8
Training loss: 2.1676135063171387
Validation loss: 2.014151978236373

Epoch: 5| Step: 9
Training loss: 1.552412748336792
Validation loss: 2.0686258026348647

Epoch: 5| Step: 10
Training loss: 2.113189935684204
Validation loss: 2.041386447927003

Epoch: 332| Step: 0
Training loss: 1.5873082876205444
Validation loss: 2.1070354677015737

Epoch: 5| Step: 1
Training loss: 1.3498342037200928
Validation loss: 2.049084699282082

Epoch: 5| Step: 2
Training loss: 1.9491904973983765
Validation loss: 2.028438322005733

Epoch: 5| Step: 3
Training loss: 1.9951928853988647
Validation loss: 2.053648071904336

Epoch: 5| Step: 4
Training loss: 1.7281858921051025
Validation loss: 2.052635021107171

Epoch: 5| Step: 5
Training loss: 1.614696741104126
Validation loss: 2.0328592972088884

Epoch: 5| Step: 6
Training loss: 1.628862977027893
Validation loss: 2.030338115589593

Epoch: 5| Step: 7
Training loss: 1.9151079654693604
Validation loss: 2.023405939020136

Epoch: 5| Step: 8
Training loss: 1.9960451126098633
Validation loss: 2.0644236815873014

Epoch: 5| Step: 9
Training loss: 1.599432349205017
Validation loss: 2.0370417782055434

Epoch: 5| Step: 10
Training loss: 2.171513319015503
Validation loss: 2.0080580096090994

Epoch: 333| Step: 0
Training loss: 2.2307045459747314
Validation loss: 2.063561975315053

Epoch: 5| Step: 1
Training loss: 1.5553624629974365
Validation loss: 2.035810214216991

Epoch: 5| Step: 2
Training loss: 1.0593549013137817
Validation loss: 2.0354406474738993

Epoch: 5| Step: 3
Training loss: 1.5343685150146484
Validation loss: 2.03314947312878

Epoch: 5| Step: 4
Training loss: 1.4233897924423218
Validation loss: 2.053752778678812

Epoch: 5| Step: 5
Training loss: 1.6362823247909546
Validation loss: 2.056965584396034

Epoch: 5| Step: 6
Training loss: 2.2593741416931152
Validation loss: 2.0434387371104252

Epoch: 5| Step: 7
Training loss: 2.3593297004699707
Validation loss: 2.043076462643121

Epoch: 5| Step: 8
Training loss: 1.9104448556900024
Validation loss: 2.0300904755951255

Epoch: 5| Step: 9
Training loss: 1.3986785411834717
Validation loss: 2.055704398821759

Epoch: 5| Step: 10
Training loss: 1.8890851736068726
Validation loss: 2.054290365147334

Epoch: 334| Step: 0
Training loss: 2.408022403717041
Validation loss: 2.053035283601412

Epoch: 5| Step: 1
Training loss: 1.2662055492401123
Validation loss: 2.0535192181987147

Epoch: 5| Step: 2
Training loss: 1.436266303062439
Validation loss: 2.0443346218396257

Epoch: 5| Step: 3
Training loss: 1.5221593379974365
Validation loss: 2.0144036059738486

Epoch: 5| Step: 4
Training loss: 1.8903405666351318
Validation loss: 2.0456622979974233

Epoch: 5| Step: 5
Training loss: 1.63650643825531
Validation loss: 2.003758406126371

Epoch: 5| Step: 6
Training loss: 2.2524707317352295
Validation loss: 2.016106620911629

Epoch: 5| Step: 7
Training loss: 1.8901169300079346
Validation loss: 2.0451926659512263

Epoch: 5| Step: 8
Training loss: 1.5864068269729614
Validation loss: 2.027759334092499

Epoch: 5| Step: 9
Training loss: 1.8379924297332764
Validation loss: 2.0344521332812566

Epoch: 5| Step: 10
Training loss: 1.4866383075714111
Validation loss: 2.032299633949034

Epoch: 335| Step: 0
Training loss: 2.095580816268921
Validation loss: 2.021520027550318

Epoch: 5| Step: 1
Training loss: 1.365900993347168
Validation loss: 2.032695775390953

Epoch: 5| Step: 2
Training loss: 1.390689730644226
Validation loss: 2.030878548981041

Epoch: 5| Step: 3
Training loss: 1.7730648517608643
Validation loss: 2.046050594698998

Epoch: 5| Step: 4
Training loss: 1.4930541515350342
Validation loss: 2.048729265889814

Epoch: 5| Step: 5
Training loss: 2.878511905670166
Validation loss: 2.008419535493338

Epoch: 5| Step: 6
Training loss: 1.4857828617095947
Validation loss: 2.0229786416535736

Epoch: 5| Step: 7
Training loss: 2.3099656105041504
Validation loss: 2.01966812661899

Epoch: 5| Step: 8
Training loss: 1.4264042377471924
Validation loss: 2.0350790216076757

Epoch: 5| Step: 9
Training loss: 1.5936589241027832
Validation loss: 2.0174746539003108

Epoch: 5| Step: 10
Training loss: 1.3899976015090942
Validation loss: 2.021267065437891

Epoch: 336| Step: 0
Training loss: 1.3321832418441772
Validation loss: 2.036876141384084

Epoch: 5| Step: 1
Training loss: 2.018176317214966
Validation loss: 2.051774458218646

Epoch: 5| Step: 2
Training loss: 1.4040383100509644
Validation loss: 2.073529194760066

Epoch: 5| Step: 3
Training loss: 2.0584774017333984
Validation loss: 2.0380846531160417

Epoch: 5| Step: 4
Training loss: 1.8495231866836548
Validation loss: 2.0554336565797047

Epoch: 5| Step: 5
Training loss: 1.5900371074676514
Validation loss: 2.0429853880277244

Epoch: 5| Step: 6
Training loss: 1.545608639717102
Validation loss: 2.043978237336682

Epoch: 5| Step: 7
Training loss: 1.4302641153335571
Validation loss: 2.0781765445586173

Epoch: 5| Step: 8
Training loss: 1.5055363178253174
Validation loss: 2.0614234221878873

Epoch: 5| Step: 9
Training loss: 2.019493579864502
Validation loss: 2.03131365776062

Epoch: 5| Step: 10
Training loss: 2.2981555461883545
Validation loss: 2.0532348361066592

Epoch: 337| Step: 0
Training loss: 1.3880479335784912
Validation loss: 2.0383618147142473

Epoch: 5| Step: 1
Training loss: 1.8449971675872803
Validation loss: 2.0441661368134203

Epoch: 5| Step: 2
Training loss: 1.8180910348892212
Validation loss: 2.0480052296833327

Epoch: 5| Step: 3
Training loss: 1.6437543630599976
Validation loss: 2.0820678011063607

Epoch: 5| Step: 4
Training loss: 1.1216455698013306
Validation loss: 2.079127937234858

Epoch: 5| Step: 5
Training loss: 1.6422027349472046
Validation loss: 2.0664714151813137

Epoch: 5| Step: 6
Training loss: 2.0902018547058105
Validation loss: 2.046050489589732

Epoch: 5| Step: 7
Training loss: 2.409449338912964
Validation loss: 2.0503186154109176

Epoch: 5| Step: 8
Training loss: 1.2851927280426025
Validation loss: 2.034095469341483

Epoch: 5| Step: 9
Training loss: 1.3658359050750732
Validation loss: 2.0401234960043304

Epoch: 5| Step: 10
Training loss: 2.428762674331665
Validation loss: 2.0254538777053996

Epoch: 338| Step: 0
Training loss: 1.8438422679901123
Validation loss: 2.02731708429193

Epoch: 5| Step: 1
Training loss: 1.7205842733383179
Validation loss: 2.0457606213067168

Epoch: 5| Step: 2
Training loss: 2.1515374183654785
Validation loss: 2.029780290460074

Epoch: 5| Step: 3
Training loss: 1.1762149333953857
Validation loss: 2.0275877957702964

Epoch: 5| Step: 4
Training loss: 1.7567209005355835
Validation loss: 2.032857673142546

Epoch: 5| Step: 5
Training loss: 1.4144915342330933
Validation loss: 2.0485811566793792

Epoch: 5| Step: 6
Training loss: 1.445863962173462
Validation loss: 2.0510496375381306

Epoch: 5| Step: 7
Training loss: 1.2596527338027954
Validation loss: 2.0588953815480715

Epoch: 5| Step: 8
Training loss: 2.311023235321045
Validation loss: 2.016345308672997

Epoch: 5| Step: 9
Training loss: 2.3559138774871826
Validation loss: 2.0315168506355694

Epoch: 5| Step: 10
Training loss: 1.7336688041687012
Validation loss: 2.027141373644593

Epoch: 339| Step: 0
Training loss: 1.231014609336853
Validation loss: 2.027809299448485

Epoch: 5| Step: 1
Training loss: 1.233885645866394
Validation loss: 2.0640380638901905

Epoch: 5| Step: 2
Training loss: 1.6582355499267578
Validation loss: 2.0517608042686217

Epoch: 5| Step: 3
Training loss: 1.1625715494155884
Validation loss: 2.051309052334037

Epoch: 5| Step: 4
Training loss: 1.9300391674041748
Validation loss: 2.0090845195196008

Epoch: 5| Step: 5
Training loss: 2.098426103591919
Validation loss: 2.027153020264

Epoch: 5| Step: 6
Training loss: 1.7756239175796509
Validation loss: 2.0390208869852047

Epoch: 5| Step: 7
Training loss: 1.9800395965576172
Validation loss: 2.0444195321811143

Epoch: 5| Step: 8
Training loss: 1.942497968673706
Validation loss: 2.062546126304134

Epoch: 5| Step: 9
Training loss: 1.5229451656341553
Validation loss: 2.0564567581299813

Epoch: 5| Step: 10
Training loss: 2.7433481216430664
Validation loss: 2.0315115926086262

Epoch: 340| Step: 0
Training loss: 1.968425989151001
Validation loss: 2.0691379283064153

Epoch: 5| Step: 1
Training loss: 1.4892666339874268
Validation loss: 2.0519055743371286

Epoch: 5| Step: 2
Training loss: 1.9521572589874268
Validation loss: 2.046777671383273

Epoch: 5| Step: 3
Training loss: 1.4099069833755493
Validation loss: 2.0745189113001667

Epoch: 5| Step: 4
Training loss: 1.9324493408203125
Validation loss: 2.0646092853238507

Epoch: 5| Step: 5
Training loss: 1.796795129776001
Validation loss: 2.041834331327869

Epoch: 5| Step: 6
Training loss: 1.628191351890564
Validation loss: 2.0575081533001316

Epoch: 5| Step: 7
Training loss: 1.8268842697143555
Validation loss: 2.0678471672919487

Epoch: 5| Step: 8
Training loss: 1.707849144935608
Validation loss: 2.032234068839781

Epoch: 5| Step: 9
Training loss: 1.251024842262268
Validation loss: 2.041090965270996

Epoch: 5| Step: 10
Training loss: 2.077728748321533
Validation loss: 2.040300864045338

Epoch: 341| Step: 0
Training loss: 2.0247578620910645
Validation loss: 1.9901477342010827

Epoch: 5| Step: 1
Training loss: 1.3863877058029175
Validation loss: 2.0551028995103735

Epoch: 5| Step: 2
Training loss: 2.0257575511932373
Validation loss: 2.0516065705207085

Epoch: 5| Step: 3
Training loss: 1.767999291419983
Validation loss: 2.031982030919803

Epoch: 5| Step: 4
Training loss: 1.794560432434082
Validation loss: 2.0682930895077285

Epoch: 5| Step: 5
Training loss: 1.4593565464019775
Validation loss: 2.0567219462445987

Epoch: 5| Step: 6
Training loss: 1.0860271453857422
Validation loss: 2.070809248955019

Epoch: 5| Step: 7
Training loss: 2.2330660820007324
Validation loss: 2.0573794226492605

Epoch: 5| Step: 8
Training loss: 1.6159403324127197
Validation loss: 2.0611190180624686

Epoch: 5| Step: 9
Training loss: 1.6186844110488892
Validation loss: 2.0558521593770673

Epoch: 5| Step: 10
Training loss: 1.854810357093811
Validation loss: 2.0417517820994058

Epoch: 342| Step: 0
Training loss: 2.150825023651123
Validation loss: 2.0411055869953607

Epoch: 5| Step: 1
Training loss: 1.7424418926239014
Validation loss: 2.0332780922612836

Epoch: 5| Step: 2
Training loss: 1.5607436895370483
Validation loss: 2.0317705677401636

Epoch: 5| Step: 3
Training loss: 1.755044937133789
Validation loss: 2.0300529541507846

Epoch: 5| Step: 4
Training loss: 1.6986286640167236
Validation loss: 2.057479332852107

Epoch: 5| Step: 5
Training loss: 2.0170886516571045
Validation loss: 2.0485376504159745

Epoch: 5| Step: 6
Training loss: 1.5774827003479004
Validation loss: 2.031576100216117

Epoch: 5| Step: 7
Training loss: 1.711087942123413
Validation loss: 2.043045957883199

Epoch: 5| Step: 8
Training loss: 1.7043914794921875
Validation loss: 2.0164848399418656

Epoch: 5| Step: 9
Training loss: 1.5709965229034424
Validation loss: 2.0193501236618205

Epoch: 5| Step: 10
Training loss: 1.4699907302856445
Validation loss: 2.039968272691132

Epoch: 343| Step: 0
Training loss: 1.413857102394104
Validation loss: 2.0492516897057973

Epoch: 5| Step: 1
Training loss: 1.7318159341812134
Validation loss: 2.0170828603929087

Epoch: 5| Step: 2
Training loss: 2.0166358947753906
Validation loss: 2.024461547533671

Epoch: 5| Step: 3
Training loss: 1.6433442831039429
Validation loss: 2.020940298675209

Epoch: 5| Step: 4
Training loss: 1.8961610794067383
Validation loss: 2.0455438219090945

Epoch: 5| Step: 5
Training loss: 2.2331440448760986
Validation loss: 2.0266319795321395

Epoch: 5| Step: 6
Training loss: 1.8200883865356445
Validation loss: 2.0638224155672136

Epoch: 5| Step: 7
Training loss: 1.7944682836532593
Validation loss: 2.0211586670209

Epoch: 5| Step: 8
Training loss: 1.681962251663208
Validation loss: 2.0355521427687777

Epoch: 5| Step: 9
Training loss: 1.498529314994812
Validation loss: 2.0253568669801116

Epoch: 5| Step: 10
Training loss: 1.2675261497497559
Validation loss: 2.0377282006766206

Epoch: 344| Step: 0
Training loss: 1.8180558681488037
Validation loss: 2.0372128819906585

Epoch: 5| Step: 1
Training loss: 1.627008080482483
Validation loss: 2.034970991073116

Epoch: 5| Step: 2
Training loss: 1.8750479221343994
Validation loss: 2.0469796221743346

Epoch: 5| Step: 3
Training loss: 2.1162168979644775
Validation loss: 2.026433370446646

Epoch: 5| Step: 4
Training loss: 1.7626354694366455
Validation loss: 2.0144672957799767

Epoch: 5| Step: 5
Training loss: 1.2866101264953613
Validation loss: 2.04926456943635

Epoch: 5| Step: 6
Training loss: 1.3521651029586792
Validation loss: 2.038683291404478

Epoch: 5| Step: 7
Training loss: 1.423882246017456
Validation loss: 2.047566285697363

Epoch: 5| Step: 8
Training loss: 2.3433146476745605
Validation loss: 2.0203410271675355

Epoch: 5| Step: 9
Training loss: 2.0631420612335205
Validation loss: 2.0792848961327666

Epoch: 5| Step: 10
Training loss: 1.05807363986969
Validation loss: 2.0607158355815436

Epoch: 345| Step: 0
Training loss: 1.5248429775238037
Validation loss: 2.013813664836268

Epoch: 5| Step: 1
Training loss: 1.4447500705718994
Validation loss: 2.062780467412805

Epoch: 5| Step: 2
Training loss: 2.2807393074035645
Validation loss: 2.0550292538058375

Epoch: 5| Step: 3
Training loss: 1.9290716648101807
Validation loss: 2.04751823025365

Epoch: 5| Step: 4
Training loss: 1.6407594680786133
Validation loss: 2.0115867583982405

Epoch: 5| Step: 5
Training loss: 1.9004799127578735
Validation loss: 2.041453553784278

Epoch: 5| Step: 6
Training loss: 1.7746862173080444
Validation loss: 2.0329896275715162

Epoch: 5| Step: 7
Training loss: 1.8707634210586548
Validation loss: 2.0590382737498127

Epoch: 5| Step: 8
Training loss: 1.3277454376220703
Validation loss: 2.0440034725332774

Epoch: 5| Step: 9
Training loss: 2.0578396320343018
Validation loss: 2.061762620044011

Epoch: 5| Step: 10
Training loss: 1.1167879104614258
Validation loss: 2.056784595212629

Epoch: 346| Step: 0
Training loss: 1.6248931884765625
Validation loss: 2.021957992225565

Epoch: 5| Step: 1
Training loss: 1.624036431312561
Validation loss: 2.0482358317221365

Epoch: 5| Step: 2
Training loss: 1.964535117149353
Validation loss: 2.0495269208826046

Epoch: 5| Step: 3
Training loss: 1.9022802114486694
Validation loss: 2.045086190264712

Epoch: 5| Step: 4
Training loss: 1.7727077007293701
Validation loss: 2.026472763348651

Epoch: 5| Step: 5
Training loss: 1.7799577713012695
Validation loss: 2.0458607571099394

Epoch: 5| Step: 6
Training loss: 1.880880355834961
Validation loss: 2.038236173250342

Epoch: 5| Step: 7
Training loss: 2.200488328933716
Validation loss: 2.0248979650517946

Epoch: 5| Step: 8
Training loss: 1.468520164489746
Validation loss: 2.056643109167776

Epoch: 5| Step: 9
Training loss: 1.6015781164169312
Validation loss: 2.0235442679415465

Epoch: 5| Step: 10
Training loss: 0.7926759719848633
Validation loss: 2.0183293306699364

Epoch: 347| Step: 0
Training loss: 1.8725147247314453
Validation loss: 2.041103611710251

Epoch: 5| Step: 1
Training loss: 2.4185893535614014
Validation loss: 2.0016602931484098

Epoch: 5| Step: 2
Training loss: 1.3429033756256104
Validation loss: 2.027335798868569

Epoch: 5| Step: 3
Training loss: 2.202540636062622
Validation loss: 2.033873975917857

Epoch: 5| Step: 4
Training loss: 1.56233811378479
Validation loss: 2.0351179081906556

Epoch: 5| Step: 5
Training loss: 1.6184413433074951
Validation loss: 2.0301941492224254

Epoch: 5| Step: 6
Training loss: 1.1448180675506592
Validation loss: 2.0263554921714206

Epoch: 5| Step: 7
Training loss: 2.0255768299102783
Validation loss: 2.002368039982293

Epoch: 5| Step: 8
Training loss: 1.6676099300384521
Validation loss: 2.040484223314511

Epoch: 5| Step: 9
Training loss: 1.4263732433319092
Validation loss: 2.049305542822807

Epoch: 5| Step: 10
Training loss: 1.7118741273880005
Validation loss: 2.052595953787527

Epoch: 348| Step: 0
Training loss: 1.2630680799484253
Validation loss: 2.0342919083051783

Epoch: 5| Step: 1
Training loss: 1.262244462966919
Validation loss: 2.0286717517401582

Epoch: 5| Step: 2
Training loss: 1.481909990310669
Validation loss: 2.0693039266012048

Epoch: 5| Step: 3
Training loss: 2.1046886444091797
Validation loss: 2.044195126461726

Epoch: 5| Step: 4
Training loss: 2.087660312652588
Validation loss: 2.0308088307739585

Epoch: 5| Step: 5
Training loss: 1.910095453262329
Validation loss: 2.011993310784781

Epoch: 5| Step: 6
Training loss: 1.9212558269500732
Validation loss: 2.0244161211034304

Epoch: 5| Step: 7
Training loss: 1.552106261253357
Validation loss: 2.065031995055496

Epoch: 5| Step: 8
Training loss: 1.2153453826904297
Validation loss: 2.030453453781784

Epoch: 5| Step: 9
Training loss: 1.9421851634979248
Validation loss: 2.0215421338235178

Epoch: 5| Step: 10
Training loss: 2.138962507247925
Validation loss: 2.0627689002662577

Epoch: 349| Step: 0
Training loss: 1.689573884010315
Validation loss: 2.0711914249645766

Epoch: 5| Step: 1
Training loss: 1.118434190750122
Validation loss: 2.0277306136264595

Epoch: 5| Step: 2
Training loss: 1.8018821477890015
Validation loss: 2.03577192752592

Epoch: 5| Step: 3
Training loss: 1.5657684803009033
Validation loss: 2.021060662884866

Epoch: 5| Step: 4
Training loss: 1.899379014968872
Validation loss: 2.0177212069111485

Epoch: 5| Step: 5
Training loss: 1.7912712097167969
Validation loss: 2.0479264848975727

Epoch: 5| Step: 6
Training loss: 2.2779977321624756
Validation loss: 2.0538245477984027

Epoch: 5| Step: 7
Training loss: 1.9639467000961304
Validation loss: 2.0450898011525473

Epoch: 5| Step: 8
Training loss: 1.599982738494873
Validation loss: 2.0536888414813625

Epoch: 5| Step: 9
Training loss: 1.8926750421524048
Validation loss: 2.0494749225595945

Epoch: 5| Step: 10
Training loss: 1.2026840448379517
Validation loss: 2.0478034519380137

Epoch: 350| Step: 0
Training loss: 1.6088873147964478
Validation loss: 2.0318366968503563

Epoch: 5| Step: 1
Training loss: 2.295032501220703
Validation loss: 2.039607891472437

Epoch: 5| Step: 2
Training loss: 0.8907874822616577
Validation loss: 2.035566491465415

Epoch: 5| Step: 3
Training loss: 1.1859195232391357
Validation loss: 2.0715882252621394

Epoch: 5| Step: 4
Training loss: 1.7609182596206665
Validation loss: 2.0352375866264425

Epoch: 5| Step: 5
Training loss: 1.6513586044311523
Validation loss: 2.0680641333262124

Epoch: 5| Step: 6
Training loss: 1.4240939617156982
Validation loss: 2.028850560547203

Epoch: 5| Step: 7
Training loss: 2.445496082305908
Validation loss: 2.0138553829603296

Epoch: 5| Step: 8
Training loss: 1.7868674993515015
Validation loss: 2.0091792139955746

Epoch: 5| Step: 9
Training loss: 2.027562141418457
Validation loss: 2.0428232275029665

Epoch: 5| Step: 10
Training loss: 1.683194637298584
Validation loss: 2.014434681143812

Epoch: 351| Step: 0
Training loss: 1.3701053857803345
Validation loss: 2.0350433318845687

Epoch: 5| Step: 1
Training loss: 2.2226967811584473
Validation loss: 2.015730905276473

Epoch: 5| Step: 2
Training loss: 1.374624490737915
Validation loss: 2.0572455929171656

Epoch: 5| Step: 3
Training loss: 1.206111192703247
Validation loss: 2.035160315934048

Epoch: 5| Step: 4
Training loss: 2.1141209602355957
Validation loss: 2.086493963836342

Epoch: 5| Step: 5
Training loss: 1.0976773500442505
Validation loss: 2.005663961492559

Epoch: 5| Step: 6
Training loss: 1.6465537548065186
Validation loss: 2.0470030307769775

Epoch: 5| Step: 7
Training loss: 1.8687607049942017
Validation loss: 2.023161465121854

Epoch: 5| Step: 8
Training loss: 1.812196135520935
Validation loss: 2.0457799268025223

Epoch: 5| Step: 9
Training loss: 2.017897129058838
Validation loss: 2.030078372647685

Epoch: 5| Step: 10
Training loss: 2.056659460067749
Validation loss: 2.0178933194888535

Epoch: 352| Step: 0
Training loss: 1.0959913730621338
Validation loss: 2.0551593790772142

Epoch: 5| Step: 1
Training loss: 1.1930053234100342
Validation loss: 2.03180794818427

Epoch: 5| Step: 2
Training loss: 1.6461846828460693
Validation loss: 2.0730226065522883

Epoch: 5| Step: 3
Training loss: 1.6708112955093384
Validation loss: 2.0418271403158865

Epoch: 5| Step: 4
Training loss: 1.9348232746124268
Validation loss: 2.0240579881975727

Epoch: 5| Step: 5
Training loss: 1.4866422414779663
Validation loss: 2.0224275127533944

Epoch: 5| Step: 6
Training loss: 2.2945125102996826
Validation loss: 2.083171909855258

Epoch: 5| Step: 7
Training loss: 1.7227678298950195
Validation loss: 2.03454932730685

Epoch: 5| Step: 8
Training loss: 2.164691209793091
Validation loss: 2.0510097895899126

Epoch: 5| Step: 9
Training loss: 1.341406226158142
Validation loss: 2.0506673884648148

Epoch: 5| Step: 10
Training loss: 2.1489861011505127
Validation loss: 2.06390683497152

Epoch: 353| Step: 0
Training loss: 1.786547064781189
Validation loss: 2.0455106663447555

Epoch: 5| Step: 1
Training loss: 1.149876594543457
Validation loss: 2.011276307926383

Epoch: 5| Step: 2
Training loss: 1.8533579111099243
Validation loss: 2.0376652491989957

Epoch: 5| Step: 3
Training loss: 1.3924593925476074
Validation loss: 2.0418814382245465

Epoch: 5| Step: 4
Training loss: 1.82537043094635
Validation loss: 2.029076276286956

Epoch: 5| Step: 5
Training loss: 2.0915026664733887
Validation loss: 2.0344914133830736

Epoch: 5| Step: 6
Training loss: 1.7160148620605469
Validation loss: 2.0233916954327653

Epoch: 5| Step: 7
Training loss: 2.2304186820983887
Validation loss: 2.043298153467076

Epoch: 5| Step: 8
Training loss: 1.417928695678711
Validation loss: 2.0134361405526437

Epoch: 5| Step: 9
Training loss: 1.169799566268921
Validation loss: 2.024478126597661

Epoch: 5| Step: 10
Training loss: 1.9778099060058594
Validation loss: 2.0312952354390132

Epoch: 354| Step: 0
Training loss: 1.7920843362808228
Validation loss: 2.046519684535201

Epoch: 5| Step: 1
Training loss: 1.8568273782730103
Validation loss: 2.057879697891974

Epoch: 5| Step: 2
Training loss: 1.624075174331665
Validation loss: 2.0565377666104223

Epoch: 5| Step: 3
Training loss: 2.203462600708008
Validation loss: 2.04497875449478

Epoch: 5| Step: 4
Training loss: 1.799717664718628
Validation loss: 2.0435082502262567

Epoch: 5| Step: 5
Training loss: 1.6345007419586182
Validation loss: 2.062104848123366

Epoch: 5| Step: 6
Training loss: 1.1270698308944702
Validation loss: 2.055004991510863

Epoch: 5| Step: 7
Training loss: 1.4366776943206787
Validation loss: 2.0364120186016126

Epoch: 5| Step: 8
Training loss: 2.065443277359009
Validation loss: 2.0760337178425123

Epoch: 5| Step: 9
Training loss: 1.5503326654434204
Validation loss: 2.060347363513003

Epoch: 5| Step: 10
Training loss: 1.4933890104293823
Validation loss: 2.011871648091142

Epoch: 355| Step: 0
Training loss: 1.915827751159668
Validation loss: 2.0695616276033464

Epoch: 5| Step: 1
Training loss: 1.3342323303222656
Validation loss: 2.0479794484312817

Epoch: 5| Step: 2
Training loss: 1.057796835899353
Validation loss: 2.0516740481058755

Epoch: 5| Step: 3
Training loss: 1.911307692527771
Validation loss: 2.033318072236994

Epoch: 5| Step: 4
Training loss: 1.5186069011688232
Validation loss: 2.0648688590654762

Epoch: 5| Step: 5
Training loss: 1.9385004043579102
Validation loss: 2.0437983671824136

Epoch: 5| Step: 6
Training loss: 2.1827893257141113
Validation loss: 2.0393443851060766

Epoch: 5| Step: 7
Training loss: 1.8611587285995483
Validation loss: 2.0275954520830544

Epoch: 5| Step: 8
Training loss: 1.8208202123641968
Validation loss: 2.057913613575761

Epoch: 5| Step: 9
Training loss: 1.6421444416046143
Validation loss: 2.039515064608666

Epoch: 5| Step: 10
Training loss: 1.2807470560073853
Validation loss: 2.0227491727439304

Epoch: 356| Step: 0
Training loss: 1.5384318828582764
Validation loss: 2.0696869742485786

Epoch: 5| Step: 1
Training loss: 1.8920137882232666
Validation loss: 2.0378722324166247

Epoch: 5| Step: 2
Training loss: 1.9439274072647095
Validation loss: 2.0357258883855676

Epoch: 5| Step: 3
Training loss: 2.2951347827911377
Validation loss: 2.0458313418972875

Epoch: 5| Step: 4
Training loss: 1.5474357604980469
Validation loss: 2.056497235451975

Epoch: 5| Step: 5
Training loss: 1.178421139717102
Validation loss: 2.0463155854132866

Epoch: 5| Step: 6
Training loss: 1.6618211269378662
Validation loss: 2.047862557954686

Epoch: 5| Step: 7
Training loss: 2.0711545944213867
Validation loss: 2.0581672858166438

Epoch: 5| Step: 8
Training loss: 1.728685975074768
Validation loss: 2.0049059416658137

Epoch: 5| Step: 9
Training loss: 1.0975255966186523
Validation loss: 2.063354351187265

Epoch: 5| Step: 10
Training loss: 1.7021665573120117
Validation loss: 2.0183418002179874

Epoch: 357| Step: 0
Training loss: 1.6612297296524048
Validation loss: 2.047421819420271

Epoch: 5| Step: 1
Training loss: 0.8924354314804077
Validation loss: 2.027857662529074

Epoch: 5| Step: 2
Training loss: 1.8937301635742188
Validation loss: 2.029698400087254

Epoch: 5| Step: 3
Training loss: 1.536009669303894
Validation loss: 2.055943786457021

Epoch: 5| Step: 4
Training loss: 1.6649894714355469
Validation loss: 2.034354172727113

Epoch: 5| Step: 5
Training loss: 2.1339609622955322
Validation loss: 2.0396377373767156

Epoch: 5| Step: 6
Training loss: 1.8294461965560913
Validation loss: 2.0147915476111957

Epoch: 5| Step: 7
Training loss: 1.9260632991790771
Validation loss: 1.9993618995912614

Epoch: 5| Step: 8
Training loss: 2.0535049438476562
Validation loss: 2.010312363665591

Epoch: 5| Step: 9
Training loss: 1.3097947835922241
Validation loss: 2.014313578605652

Epoch: 5| Step: 10
Training loss: 1.685298204421997
Validation loss: 2.0423280731324227

Epoch: 358| Step: 0
Training loss: 2.4085230827331543
Validation loss: 2.032118293546861

Epoch: 5| Step: 1
Training loss: 1.8760850429534912
Validation loss: 2.048042557572806

Epoch: 5| Step: 2
Training loss: 1.216742753982544
Validation loss: 2.0390784971175657

Epoch: 5| Step: 3
Training loss: 1.5970280170440674
Validation loss: 2.0269570401919785

Epoch: 5| Step: 4
Training loss: 1.5908329486846924
Validation loss: 2.042652032708609

Epoch: 5| Step: 5
Training loss: 1.6229931116104126
Validation loss: 2.0377426096188125

Epoch: 5| Step: 6
Training loss: 2.044909715652466
Validation loss: 2.0280436956754295

Epoch: 5| Step: 7
Training loss: 1.8098255395889282
Validation loss: 2.0212173897732972

Epoch: 5| Step: 8
Training loss: 1.0972217321395874
Validation loss: 1.9909563923394809

Epoch: 5| Step: 9
Training loss: 1.805737853050232
Validation loss: 2.0444374443382345

Epoch: 5| Step: 10
Training loss: 1.1519795656204224
Validation loss: 2.0343049303177865

Epoch: 359| Step: 0
Training loss: 2.422048568725586
Validation loss: 2.014204902033652

Epoch: 5| Step: 1
Training loss: 1.303503394126892
Validation loss: 2.0262311966188493

Epoch: 5| Step: 2
Training loss: 1.4832501411437988
Validation loss: 2.012120677578834

Epoch: 5| Step: 3
Training loss: 1.3426496982574463
Validation loss: 2.0068825085957847

Epoch: 5| Step: 4
Training loss: 1.450985312461853
Validation loss: 2.0188652905084754

Epoch: 5| Step: 5
Training loss: 1.5719261169433594
Validation loss: 2.0551299959100704

Epoch: 5| Step: 6
Training loss: 1.5237369537353516
Validation loss: 2.0129696015388734

Epoch: 5| Step: 7
Training loss: 2.2911581993103027
Validation loss: 2.0408881659148843

Epoch: 5| Step: 8
Training loss: 1.4227149486541748
Validation loss: 2.023852054790784

Epoch: 5| Step: 9
Training loss: 1.8299229145050049
Validation loss: 2.0357751115675895

Epoch: 5| Step: 10
Training loss: 1.816192626953125
Validation loss: 2.0313457007049234

Epoch: 360| Step: 0
Training loss: 1.51613450050354
Validation loss: 2.031271464081221

Epoch: 5| Step: 1
Training loss: 1.5532113313674927
Validation loss: 2.050070366551799

Epoch: 5| Step: 2
Training loss: 1.370131015777588
Validation loss: 2.0435247728901524

Epoch: 5| Step: 3
Training loss: 1.787825584411621
Validation loss: 2.0673059084082164

Epoch: 5| Step: 4
Training loss: 1.6452680826187134
Validation loss: 2.051034954286391

Epoch: 5| Step: 5
Training loss: 1.9274215698242188
Validation loss: 2.0701720535114245

Epoch: 5| Step: 6
Training loss: 1.6200416088104248
Validation loss: 2.0187520147651754

Epoch: 5| Step: 7
Training loss: 2.0838732719421387
Validation loss: 2.0266875502883748

Epoch: 5| Step: 8
Training loss: 1.5693724155426025
Validation loss: 2.049178259347075

Epoch: 5| Step: 9
Training loss: 1.5421959161758423
Validation loss: 2.054884026127477

Epoch: 5| Step: 10
Training loss: 1.8924614191055298
Validation loss: 2.0671241949963313

Epoch: 361| Step: 0
Training loss: 1.0919643640518188
Validation loss: 2.0495184544594056

Epoch: 5| Step: 1
Training loss: 1.5460728406906128
Validation loss: 2.026316955525388

Epoch: 5| Step: 2
Training loss: 1.542065978050232
Validation loss: 2.0269897086645967

Epoch: 5| Step: 3
Training loss: 1.7968780994415283
Validation loss: 2.0114835590444584

Epoch: 5| Step: 4
Training loss: 2.05781626701355
Validation loss: 2.0213021821873163

Epoch: 5| Step: 5
Training loss: 1.389980435371399
Validation loss: 2.036050581162976

Epoch: 5| Step: 6
Training loss: 1.5226719379425049
Validation loss: 2.040113736224431

Epoch: 5| Step: 7
Training loss: 2.7804341316223145
Validation loss: 2.048698184310749

Epoch: 5| Step: 8
Training loss: 1.6055831909179688
Validation loss: 2.0428364199976765

Epoch: 5| Step: 9
Training loss: 1.538901686668396
Validation loss: 2.0427921971967145

Epoch: 5| Step: 10
Training loss: 1.540654182434082
Validation loss: 2.0369419000482045

Epoch: 362| Step: 0
Training loss: 2.13679838180542
Validation loss: 2.009865412148096

Epoch: 5| Step: 1
Training loss: 1.6866848468780518
Validation loss: 2.0134372775272658

Epoch: 5| Step: 2
Training loss: 1.0430004596710205
Validation loss: 1.9826793952654767

Epoch: 5| Step: 3
Training loss: 2.047433853149414
Validation loss: 2.0562606908941783

Epoch: 5| Step: 4
Training loss: 1.273581624031067
Validation loss: 2.048093657339773

Epoch: 5| Step: 5
Training loss: 1.2631127834320068
Validation loss: 2.023856811625983

Epoch: 5| Step: 6
Training loss: 1.8519411087036133
Validation loss: 2.0380852786443566

Epoch: 5| Step: 7
Training loss: 1.667043685913086
Validation loss: 2.0741921112101567

Epoch: 5| Step: 8
Training loss: 1.755358099937439
Validation loss: 2.0513624850139824

Epoch: 5| Step: 9
Training loss: 1.895963430404663
Validation loss: 2.020955372882146

Epoch: 5| Step: 10
Training loss: 1.9230871200561523
Validation loss: 2.0762351277053996

Epoch: 363| Step: 0
Training loss: 1.7827847003936768
Validation loss: 2.02974001566569

Epoch: 5| Step: 1
Training loss: 1.9766123294830322
Validation loss: 2.0404845911969423

Epoch: 5| Step: 2
Training loss: 1.6515166759490967
Validation loss: 2.0411198395554737

Epoch: 5| Step: 3
Training loss: 1.7972999811172485
Validation loss: 2.070085225566741

Epoch: 5| Step: 4
Training loss: 1.8164377212524414
Validation loss: 2.0526504567874375

Epoch: 5| Step: 5
Training loss: 1.9628311395645142
Validation loss: 2.0231769187476045

Epoch: 5| Step: 6
Training loss: 1.1776469945907593
Validation loss: 2.036409167833226

Epoch: 5| Step: 7
Training loss: 1.8589732646942139
Validation loss: 2.0330104289516324

Epoch: 5| Step: 8
Training loss: 1.6660921573638916
Validation loss: 2.0595646340359925

Epoch: 5| Step: 9
Training loss: 1.119858741760254
Validation loss: 2.0326493299135597

Epoch: 5| Step: 10
Training loss: 1.7957473993301392
Validation loss: 2.067696876423333

Epoch: 364| Step: 0
Training loss: 1.5402381420135498
Validation loss: 2.039913192872078

Epoch: 5| Step: 1
Training loss: 1.5172884464263916
Validation loss: 2.0852094696414087

Epoch: 5| Step: 2
Training loss: 1.352813482284546
Validation loss: 2.0240481809903215

Epoch: 5| Step: 3
Training loss: 2.2096006870269775
Validation loss: 2.014060619056866

Epoch: 5| Step: 4
Training loss: 1.4624769687652588
Validation loss: 2.0464298135490826

Epoch: 5| Step: 5
Training loss: 2.2197678089141846
Validation loss: 2.047151220101182

Epoch: 5| Step: 6
Training loss: 1.4539015293121338
Validation loss: 2.0666772550152195

Epoch: 5| Step: 7
Training loss: 1.097642183303833
Validation loss: 2.03934540799869

Epoch: 5| Step: 8
Training loss: 1.3827086687088013
Validation loss: 2.0287017412083124

Epoch: 5| Step: 9
Training loss: 1.7233197689056396
Validation loss: 2.030679109275982

Epoch: 5| Step: 10
Training loss: 2.489025115966797
Validation loss: 2.046320894713043

Epoch: 365| Step: 0
Training loss: 1.8631057739257812
Validation loss: 2.019550295286281

Epoch: 5| Step: 1
Training loss: 2.101303815841675
Validation loss: 2.003513741236861

Epoch: 5| Step: 2
Training loss: 1.1005085706710815
Validation loss: 2.0215003874994095

Epoch: 5| Step: 3
Training loss: 2.0869596004486084
Validation loss: 2.0164791358414518

Epoch: 5| Step: 4
Training loss: 1.1105016469955444
Validation loss: 2.060303600885535

Epoch: 5| Step: 5
Training loss: 1.5023667812347412
Validation loss: 2.0266774931261615

Epoch: 5| Step: 6
Training loss: 1.4538822174072266
Validation loss: 2.062532509526899

Epoch: 5| Step: 7
Training loss: 1.784765601158142
Validation loss: 2.045415473240678

Epoch: 5| Step: 8
Training loss: 1.6405051946640015
Validation loss: 2.0704635984154156

Epoch: 5| Step: 9
Training loss: 1.935917615890503
Validation loss: 2.014743753658828

Epoch: 5| Step: 10
Training loss: 2.0691909790039062
Validation loss: 2.029928530416181

Epoch: 366| Step: 0
Training loss: 2.243924856185913
Validation loss: 2.017950109256211

Epoch: 5| Step: 1
Training loss: 2.5555858612060547
Validation loss: 2.046604576931205

Epoch: 5| Step: 2
Training loss: 1.1565046310424805
Validation loss: 2.055646704089257

Epoch: 5| Step: 3
Training loss: 2.0765433311462402
Validation loss: 2.041285558413434

Epoch: 5| Step: 4
Training loss: 1.1977771520614624
Validation loss: 2.0367054247087046

Epoch: 5| Step: 5
Training loss: 2.0464096069335938
Validation loss: 2.0074271694306405

Epoch: 5| Step: 6
Training loss: 0.958758533000946
Validation loss: 2.048193452178791

Epoch: 5| Step: 7
Training loss: 1.804342269897461
Validation loss: 2.0109617428113054

Epoch: 5| Step: 8
Training loss: 1.2587273120880127
Validation loss: 2.036715199870448

Epoch: 5| Step: 9
Training loss: 1.4793188571929932
Validation loss: 2.0142149156139744

Epoch: 5| Step: 10
Training loss: 1.5348105430603027
Validation loss: 2.0101046677558654

Epoch: 367| Step: 0
Training loss: 1.9744431972503662
Validation loss: 2.031423273906913

Epoch: 5| Step: 1
Training loss: 1.4687836170196533
Validation loss: 2.0525155605808383

Epoch: 5| Step: 2
Training loss: 1.9245250225067139
Validation loss: 2.0407310634531

Epoch: 5| Step: 3
Training loss: 0.9549612998962402
Validation loss: 2.014430220409106

Epoch: 5| Step: 4
Training loss: 2.116734743118286
Validation loss: 2.033558358428299

Epoch: 5| Step: 5
Training loss: 1.0021475553512573
Validation loss: 2.071495868826425

Epoch: 5| Step: 6
Training loss: 2.3409488201141357
Validation loss: 2.061381709191107

Epoch: 5| Step: 7
Training loss: 1.0374257564544678
Validation loss: 2.034874264911939

Epoch: 5| Step: 8
Training loss: 2.004241466522217
Validation loss: 2.0106352721491167

Epoch: 5| Step: 9
Training loss: 1.5715597867965698
Validation loss: 2.0664981590804232

Epoch: 5| Step: 10
Training loss: 2.1892242431640625
Validation loss: 2.0120458679814495

Epoch: 368| Step: 0
Training loss: 1.7606289386749268
Validation loss: 2.0146634873523506

Epoch: 5| Step: 1
Training loss: 1.4012565612792969
Validation loss: 2.0375131868547007

Epoch: 5| Step: 2
Training loss: 1.7854194641113281
Validation loss: 2.040635883167226

Epoch: 5| Step: 3
Training loss: 1.3429605960845947
Validation loss: 2.0664637909140637

Epoch: 5| Step: 4
Training loss: 2.210175037384033
Validation loss: 2.0131683593155234

Epoch: 5| Step: 5
Training loss: 1.905496597290039
Validation loss: 2.0324216376068773

Epoch: 5| Step: 6
Training loss: 1.6158287525177002
Validation loss: 2.054789794388638

Epoch: 5| Step: 7
Training loss: 1.842346429824829
Validation loss: 2.016803131308607

Epoch: 5| Step: 8
Training loss: 1.0454988479614258
Validation loss: 2.0405098622845066

Epoch: 5| Step: 9
Training loss: 1.6389284133911133
Validation loss: 2.027537940650858

Epoch: 5| Step: 10
Training loss: 1.9173418283462524
Validation loss: 2.0255878638195735

Epoch: 369| Step: 0
Training loss: 1.5302555561065674
Validation loss: 2.055924415588379

Epoch: 5| Step: 1
Training loss: 1.6851810216903687
Validation loss: 2.0317014724977556

Epoch: 5| Step: 2
Training loss: 1.7201259136199951
Validation loss: 2.0257152383045485

Epoch: 5| Step: 3
Training loss: 1.5410698652267456
Validation loss: 2.057829803036105

Epoch: 5| Step: 4
Training loss: 2.1258747577667236
Validation loss: 2.038654319701656

Epoch: 5| Step: 5
Training loss: 1.559552788734436
Validation loss: 2.047113385251773

Epoch: 5| Step: 6
Training loss: 1.7703139781951904
Validation loss: 2.0400016256558

Epoch: 5| Step: 7
Training loss: 1.3505433797836304
Validation loss: 2.03734750388771

Epoch: 5| Step: 8
Training loss: 1.9684044122695923
Validation loss: 2.039288418267363

Epoch: 5| Step: 9
Training loss: 1.3931233882904053
Validation loss: 2.0046870503374326

Epoch: 5| Step: 10
Training loss: 1.555999994277954
Validation loss: 2.0321342611825592

Epoch: 370| Step: 0
Training loss: 1.4177762269973755
Validation loss: 2.0042840127022035

Epoch: 5| Step: 1
Training loss: 1.774446725845337
Validation loss: 2.049595184223626

Epoch: 5| Step: 2
Training loss: 1.4326281547546387
Validation loss: 2.019161952439175

Epoch: 5| Step: 3
Training loss: 1.7006847858428955
Validation loss: 2.025279207896161

Epoch: 5| Step: 4
Training loss: 1.7147216796875
Validation loss: 1.9880436133312922

Epoch: 5| Step: 5
Training loss: 1.9405524730682373
Validation loss: 2.024130605882214

Epoch: 5| Step: 6
Training loss: 1.763479471206665
Validation loss: 2.045073292588675

Epoch: 5| Step: 7
Training loss: 1.7219702005386353
Validation loss: 2.0416635877342633

Epoch: 5| Step: 8
Training loss: 1.8617178201675415
Validation loss: 2.012381204994776

Epoch: 5| Step: 9
Training loss: 1.055699348449707
Validation loss: 2.015592134127053

Epoch: 5| Step: 10
Training loss: 1.9036600589752197
Validation loss: 2.0421331390257804

Epoch: 371| Step: 0
Training loss: 1.5798228979110718
Validation loss: 2.0092270451207317

Epoch: 5| Step: 1
Training loss: 1.8412418365478516
Validation loss: 2.0076640190616732

Epoch: 5| Step: 2
Training loss: 1.822312593460083
Validation loss: 2.00894671358088

Epoch: 5| Step: 3
Training loss: 1.429462194442749
Validation loss: 2.048327866420951

Epoch: 5| Step: 4
Training loss: 1.9513288736343384
Validation loss: 1.993833488033664

Epoch: 5| Step: 5
Training loss: 1.6865144968032837
Validation loss: 2.0166358947753906

Epoch: 5| Step: 6
Training loss: 1.347177505493164
Validation loss: 2.0127160023617487

Epoch: 5| Step: 7
Training loss: 1.7103716135025024
Validation loss: 2.0224000305257817

Epoch: 5| Step: 8
Training loss: 2.0760130882263184
Validation loss: 2.0548221424061763

Epoch: 5| Step: 9
Training loss: 1.5232932567596436
Validation loss: 2.0264651108813543

Epoch: 5| Step: 10
Training loss: 1.3394032716751099
Validation loss: 2.036138996001213

Epoch: 372| Step: 0
Training loss: 1.5450396537780762
Validation loss: 2.0282145238691762

Epoch: 5| Step: 1
Training loss: 1.6068655252456665
Validation loss: 2.0446823232917377

Epoch: 5| Step: 2
Training loss: 1.4407987594604492
Validation loss: 2.020721943147721

Epoch: 5| Step: 3
Training loss: 1.757224678993225
Validation loss: 2.0659505423679145

Epoch: 5| Step: 4
Training loss: 2.2109248638153076
Validation loss: 2.0335945237067437

Epoch: 5| Step: 5
Training loss: 1.1016566753387451
Validation loss: 2.0456042469188733

Epoch: 5| Step: 6
Training loss: 1.703667402267456
Validation loss: 1.999884723335184

Epoch: 5| Step: 7
Training loss: 1.457402229309082
Validation loss: 2.0116646712826145

Epoch: 5| Step: 8
Training loss: 1.192232370376587
Validation loss: 2.023678864202192

Epoch: 5| Step: 9
Training loss: 2.1488959789276123
Validation loss: 2.014637721482144

Epoch: 5| Step: 10
Training loss: 2.161665916442871
Validation loss: 2.034274116639168

Epoch: 373| Step: 0
Training loss: 1.397510290145874
Validation loss: 2.041678121013026

Epoch: 5| Step: 1
Training loss: 2.0965781211853027
Validation loss: 2.0330519830026934

Epoch: 5| Step: 2
Training loss: 1.8612598180770874
Validation loss: 2.0206823669454104

Epoch: 5| Step: 3
Training loss: 1.1643693447113037
Validation loss: 2.0251231090996855

Epoch: 5| Step: 4
Training loss: 1.3811404705047607
Validation loss: 2.0149591199813353

Epoch: 5| Step: 5
Training loss: 1.7298862934112549
Validation loss: 2.034546293238158

Epoch: 5| Step: 6
Training loss: 2.1111862659454346
Validation loss: 2.019270027837446

Epoch: 5| Step: 7
Training loss: 1.7216037511825562
Validation loss: 2.0240316557627853

Epoch: 5| Step: 8
Training loss: 1.2328641414642334
Validation loss: 2.01901646583311

Epoch: 5| Step: 9
Training loss: 1.9179422855377197
Validation loss: 2.02524495381181

Epoch: 5| Step: 10
Training loss: 1.8225518465042114
Validation loss: 2.0422709526554232

Epoch: 374| Step: 0
Training loss: 1.607262372970581
Validation loss: 2.0265944439877748

Epoch: 5| Step: 1
Training loss: 1.4976831674575806
Validation loss: 2.037267577263617

Epoch: 5| Step: 2
Training loss: 2.256138563156128
Validation loss: 2.037266836371473

Epoch: 5| Step: 3
Training loss: 1.6486313343048096
Validation loss: 2.0282967244425127

Epoch: 5| Step: 4
Training loss: 1.2936336994171143
Validation loss: 2.0093160085780646

Epoch: 5| Step: 5
Training loss: 1.3762922286987305
Validation loss: 1.9994473226608769

Epoch: 5| Step: 6
Training loss: 1.9350955486297607
Validation loss: 2.005826803945726

Epoch: 5| Step: 7
Training loss: 1.871362328529358
Validation loss: 1.9997103086081884

Epoch: 5| Step: 8
Training loss: 1.6855370998382568
Validation loss: 2.0325798193613687

Epoch: 5| Step: 9
Training loss: 1.4639688730239868
Validation loss: 1.9889275232950847

Epoch: 5| Step: 10
Training loss: 2.090059995651245
Validation loss: 2.0069526728763374

Epoch: 375| Step: 0
Training loss: 1.2457528114318848
Validation loss: 2.021254562562512

Epoch: 5| Step: 1
Training loss: 1.683502435684204
Validation loss: 2.0433984905160885

Epoch: 5| Step: 2
Training loss: 1.2429397106170654
Validation loss: 2.053582940050351

Epoch: 5| Step: 3
Training loss: 1.77920663356781
Validation loss: 2.0618312974129953

Epoch: 5| Step: 4
Training loss: 1.8006179332733154
Validation loss: 2.051233174980328

Epoch: 5| Step: 5
Training loss: 1.5069154500961304
Validation loss: 2.0331543158459406

Epoch: 5| Step: 6
Training loss: 1.6161686182022095
Validation loss: 2.045194677127305

Epoch: 5| Step: 7
Training loss: 2.276914119720459
Validation loss: 2.0624093894035584

Epoch: 5| Step: 8
Training loss: 1.7169504165649414
Validation loss: 2.0638175702864126

Epoch: 5| Step: 9
Training loss: 1.7783044576644897
Validation loss: 2.043696972631639

Epoch: 5| Step: 10
Training loss: 1.6614596843719482
Validation loss: 2.0220106788860854

Epoch: 376| Step: 0
Training loss: 1.5300781726837158
Validation loss: 2.0409213958248014

Epoch: 5| Step: 1
Training loss: 1.9292978048324585
Validation loss: 2.0447221673944944

Epoch: 5| Step: 2
Training loss: 1.8952362537384033
Validation loss: 2.038514491050474

Epoch: 5| Step: 3
Training loss: 1.514939308166504
Validation loss: 2.0227544999891713

Epoch: 5| Step: 4
Training loss: 1.3515115976333618
Validation loss: 2.061242106140301

Epoch: 5| Step: 5
Training loss: 1.7516000270843506
Validation loss: 2.0446864122985513

Epoch: 5| Step: 6
Training loss: 1.1663202047348022
Validation loss: 2.025547081424344

Epoch: 5| Step: 7
Training loss: 1.5545225143432617
Validation loss: 2.0071562156882337

Epoch: 5| Step: 8
Training loss: 1.9903318881988525
Validation loss: 2.0182396135022564

Epoch: 5| Step: 9
Training loss: 1.4867174625396729
Validation loss: 2.0230442272719515

Epoch: 5| Step: 10
Training loss: 2.0818190574645996
Validation loss: 2.0193107640871437

Epoch: 377| Step: 0
Training loss: 1.376344919204712
Validation loss: 2.0523123292512793

Epoch: 5| Step: 1
Training loss: 1.8903964757919312
Validation loss: 2.011132258240895

Epoch: 5| Step: 2
Training loss: 1.7030118703842163
Validation loss: 1.997093217347258

Epoch: 5| Step: 3
Training loss: 1.868720293045044
Validation loss: 2.0024627357400875

Epoch: 5| Step: 4
Training loss: 1.362135648727417
Validation loss: 2.0317447339334795

Epoch: 5| Step: 5
Training loss: 1.8488763570785522
Validation loss: 2.028545443729688

Epoch: 5| Step: 6
Training loss: 1.7908493280410767
Validation loss: 2.04355021702346

Epoch: 5| Step: 7
Training loss: 1.5181220769882202
Validation loss: 1.991514439223915

Epoch: 5| Step: 8
Training loss: 1.6019872426986694
Validation loss: 2.0213065967764905

Epoch: 5| Step: 9
Training loss: 1.8903942108154297
Validation loss: 2.004325102734309

Epoch: 5| Step: 10
Training loss: 1.1770484447479248
Validation loss: 2.036631045802947

Epoch: 378| Step: 0
Training loss: 1.8915554285049438
Validation loss: 1.9942249328859392

Epoch: 5| Step: 1
Training loss: 1.744614839553833
Validation loss: 2.051474286663917

Epoch: 5| Step: 2
Training loss: 1.5331352949142456
Validation loss: 2.0420845785448627

Epoch: 5| Step: 3
Training loss: 1.3696649074554443
Validation loss: 2.0816904601230415

Epoch: 5| Step: 4
Training loss: 1.1838352680206299
Validation loss: 2.0545823189520065

Epoch: 5| Step: 5
Training loss: 2.5066158771514893
Validation loss: 2.034580361458563

Epoch: 5| Step: 6
Training loss: 1.8256651163101196
Validation loss: 2.0293662522428777

Epoch: 5| Step: 7
Training loss: 1.8438183069229126
Validation loss: 2.0673341443461757

Epoch: 5| Step: 8
Training loss: 1.1967133283615112
Validation loss: 2.075569345105079

Epoch: 5| Step: 9
Training loss: 1.5476661920547485
Validation loss: 2.0361980276723064

Epoch: 5| Step: 10
Training loss: 1.8926211595535278
Validation loss: 2.013294591698595

Epoch: 379| Step: 0
Training loss: 1.7663713693618774
Validation loss: 2.0234290015312935

Epoch: 5| Step: 1
Training loss: 1.7899799346923828
Validation loss: 2.032857733388101

Epoch: 5| Step: 2
Training loss: 1.2919666767120361
Validation loss: 1.9776296987328479

Epoch: 5| Step: 3
Training loss: 1.896622896194458
Validation loss: 2.0222097366086897

Epoch: 5| Step: 4
Training loss: 1.7641137838363647
Validation loss: 2.031247547877732

Epoch: 5| Step: 5
Training loss: 1.4085233211517334
Validation loss: 2.0257782167004

Epoch: 5| Step: 6
Training loss: 1.34147310256958
Validation loss: 2.002668203846101

Epoch: 5| Step: 7
Training loss: 1.4981296062469482
Validation loss: 2.0351249556387625

Epoch: 5| Step: 8
Training loss: 2.0341594219207764
Validation loss: 2.0146238009134927

Epoch: 5| Step: 9
Training loss: 1.748727798461914
Validation loss: 2.0194176397015973

Epoch: 5| Step: 10
Training loss: 1.6227971315383911
Validation loss: 2.022515118763011

Epoch: 380| Step: 0
Training loss: 2.4592537879943848
Validation loss: 2.0089344260513142

Epoch: 5| Step: 1
Training loss: 1.890316367149353
Validation loss: 2.043671041406611

Epoch: 5| Step: 2
Training loss: 1.3074486255645752
Validation loss: 2.0348002884977605

Epoch: 5| Step: 3
Training loss: 2.0033695697784424
Validation loss: 2.0793035696911555

Epoch: 5| Step: 4
Training loss: 1.7679601907730103
Validation loss: 2.0186696603734005

Epoch: 5| Step: 5
Training loss: 1.579410195350647
Validation loss: 2.0378862298944944

Epoch: 5| Step: 6
Training loss: 1.9623222351074219
Validation loss: 2.0471103011920886

Epoch: 5| Step: 7
Training loss: 1.011559247970581
Validation loss: 2.0583832699765443

Epoch: 5| Step: 8
Training loss: 1.2052946090698242
Validation loss: 2.02045815349907

Epoch: 5| Step: 9
Training loss: 1.943319320678711
Validation loss: 2.012900698569513

Epoch: 5| Step: 10
Training loss: 1.0439751148223877
Validation loss: 2.0580403856051865

Epoch: 381| Step: 0
Training loss: 1.667721152305603
Validation loss: 2.0226833615251767

Epoch: 5| Step: 1
Training loss: 1.0263599157333374
Validation loss: 2.0348837093640397

Epoch: 5| Step: 2
Training loss: 1.8443899154663086
Validation loss: 2.02361657029839

Epoch: 5| Step: 3
Training loss: 2.254035234451294
Validation loss: 2.015947823883385

Epoch: 5| Step: 4
Training loss: 1.558298110961914
Validation loss: 2.040561983662267

Epoch: 5| Step: 5
Training loss: 1.8282878398895264
Validation loss: 2.017288456680954

Epoch: 5| Step: 6
Training loss: 1.5017788410186768
Validation loss: 2.0343080310411352

Epoch: 5| Step: 7
Training loss: 1.1960420608520508
Validation loss: 2.0446577713053715

Epoch: 5| Step: 8
Training loss: 1.4273933172225952
Validation loss: 2.0142195634944464

Epoch: 5| Step: 9
Training loss: 1.3128440380096436
Validation loss: 2.0084066121808943

Epoch: 5| Step: 10
Training loss: 2.849628210067749
Validation loss: 1.9864267405643259

Epoch: 382| Step: 0
Training loss: 1.5552570819854736
Validation loss: 1.9809757112174906

Epoch: 5| Step: 1
Training loss: 1.4536588191986084
Validation loss: 2.0048145094225482

Epoch: 5| Step: 2
Training loss: 1.1608203649520874
Validation loss: 2.0197024217215915

Epoch: 5| Step: 3
Training loss: 1.3970025777816772
Validation loss: 2.020803043919225

Epoch: 5| Step: 4
Training loss: 1.9388993978500366
Validation loss: 2.0203348821209324

Epoch: 5| Step: 5
Training loss: 1.0988034009933472
Validation loss: 1.9981677019467918

Epoch: 5| Step: 6
Training loss: 2.507101535797119
Validation loss: 2.022409972324166

Epoch: 5| Step: 7
Training loss: 1.2299643754959106
Validation loss: 2.024532562942915

Epoch: 5| Step: 8
Training loss: 1.6916900873184204
Validation loss: 2.0243140920515983

Epoch: 5| Step: 9
Training loss: 1.8601634502410889
Validation loss: 2.036936357457151

Epoch: 5| Step: 10
Training loss: 2.431894302368164
Validation loss: 2.0017030290378037

Epoch: 383| Step: 0
Training loss: 0.9691171646118164
Validation loss: 2.0503664631997385

Epoch: 5| Step: 1
Training loss: 1.4685943126678467
Validation loss: 2.042549361464798

Epoch: 5| Step: 2
Training loss: 1.6846551895141602
Validation loss: 2.0563272045504664

Epoch: 5| Step: 3
Training loss: 2.0578064918518066
Validation loss: 2.026332619369671

Epoch: 5| Step: 4
Training loss: 2.151132822036743
Validation loss: 2.0786568887772097

Epoch: 5| Step: 5
Training loss: 1.4309049844741821
Validation loss: 2.061540183200631

Epoch: 5| Step: 6
Training loss: 1.4819495677947998
Validation loss: 2.0526469292179232

Epoch: 5| Step: 7
Training loss: 1.7764803171157837
Validation loss: 2.0647064537130375

Epoch: 5| Step: 8
Training loss: 1.5129234790802002
Validation loss: 2.0515836643916305

Epoch: 5| Step: 9
Training loss: 2.070072889328003
Validation loss: 2.0532488720391386

Epoch: 5| Step: 10
Training loss: 1.7403078079223633
Validation loss: 2.0591696000868276

Epoch: 384| Step: 0
Training loss: 1.9656879901885986
Validation loss: 2.025756859010266

Epoch: 5| Step: 1
Training loss: 1.4541971683502197
Validation loss: 2.0304548150749615

Epoch: 5| Step: 2
Training loss: 1.7502065896987915
Validation loss: 2.0242412256938156

Epoch: 5| Step: 3
Training loss: 1.5851556062698364
Validation loss: 2.0374291020054973

Epoch: 5| Step: 4
Training loss: 2.034691572189331
Validation loss: 2.0282242554490284

Epoch: 5| Step: 5
Training loss: 1.3498971462249756
Validation loss: 2.0216524959892355

Epoch: 5| Step: 6
Training loss: 1.9934375286102295
Validation loss: 2.043079072429288

Epoch: 5| Step: 7
Training loss: 1.1896365880966187
Validation loss: 2.0125330763478435

Epoch: 5| Step: 8
Training loss: 1.2760251760482788
Validation loss: 2.036717217455628

Epoch: 5| Step: 9
Training loss: 1.4468754529953003
Validation loss: 1.979575623748123

Epoch: 5| Step: 10
Training loss: 1.8196722269058228
Validation loss: 2.0116252424896404

Epoch: 385| Step: 0
Training loss: 1.8677711486816406
Validation loss: 1.995688756306966

Epoch: 5| Step: 1
Training loss: 1.6564791202545166
Validation loss: 2.024850926091594

Epoch: 5| Step: 2
Training loss: 1.268683671951294
Validation loss: 2.0012000581269622

Epoch: 5| Step: 3
Training loss: 1.7295961380004883
Validation loss: 2.0108177649077548

Epoch: 5| Step: 4
Training loss: 2.1713833808898926
Validation loss: 2.015499225226782

Epoch: 5| Step: 5
Training loss: 1.9667587280273438
Validation loss: 2.0572242980362265

Epoch: 5| Step: 6
Training loss: 1.0504975318908691
Validation loss: 2.008506421119936

Epoch: 5| Step: 7
Training loss: 1.4351733922958374
Validation loss: 2.0639953626099454

Epoch: 5| Step: 8
Training loss: 1.5939342975616455
Validation loss: 2.0269677151915846

Epoch: 5| Step: 9
Training loss: 1.7664282321929932
Validation loss: 2.049059569194753

Epoch: 5| Step: 10
Training loss: 1.5412858724594116
Validation loss: 2.0183670379782237

Epoch: 386| Step: 0
Training loss: 1.9651718139648438
Validation loss: 2.0476197632410194

Epoch: 5| Step: 1
Training loss: 1.325843095779419
Validation loss: 2.037217140197754

Epoch: 5| Step: 2
Training loss: 1.5176998376846313
Validation loss: 2.0547667703320904

Epoch: 5| Step: 3
Training loss: 0.9769342541694641
Validation loss: 2.026489826940721

Epoch: 5| Step: 4
Training loss: 1.9610497951507568
Validation loss: 2.0218551671633156

Epoch: 5| Step: 5
Training loss: 1.8668310642242432
Validation loss: 2.034964515316871

Epoch: 5| Step: 6
Training loss: 1.4835819005966187
Validation loss: 2.015246183641495

Epoch: 5| Step: 7
Training loss: 1.9760240316390991
Validation loss: 1.9992408214076873

Epoch: 5| Step: 8
Training loss: 1.4469802379608154
Validation loss: 2.0430325897791053

Epoch: 5| Step: 9
Training loss: 1.6775836944580078
Validation loss: 1.9946430472917454

Epoch: 5| Step: 10
Training loss: 1.5338544845581055
Validation loss: 2.0386940599769674

Epoch: 387| Step: 0
Training loss: 1.3771220445632935
Validation loss: 2.037778982552149

Epoch: 5| Step: 1
Training loss: 1.6515223979949951
Validation loss: 2.012673067790206

Epoch: 5| Step: 2
Training loss: 1.2828192710876465
Validation loss: 2.05996956107437

Epoch: 5| Step: 3
Training loss: 1.3735837936401367
Validation loss: 2.026745693657988

Epoch: 5| Step: 4
Training loss: 1.440502643585205
Validation loss: 2.0108230081937646

Epoch: 5| Step: 5
Training loss: 2.0362837314605713
Validation loss: 2.014764929330477

Epoch: 5| Step: 6
Training loss: 2.309523582458496
Validation loss: 2.0444650880752073

Epoch: 5| Step: 7
Training loss: 1.7322219610214233
Validation loss: 1.9998324442935247

Epoch: 5| Step: 8
Training loss: 1.8738858699798584
Validation loss: 2.032828461739325

Epoch: 5| Step: 9
Training loss: 1.5782757997512817
Validation loss: 2.050254306485576

Epoch: 5| Step: 10
Training loss: 1.2318195104599
Validation loss: 1.9936693509419758

Epoch: 388| Step: 0
Training loss: 1.545397162437439
Validation loss: 2.057279343246132

Epoch: 5| Step: 1
Training loss: 1.3120113611221313
Validation loss: 2.0509681214568434

Epoch: 5| Step: 2
Training loss: 2.0999960899353027
Validation loss: 2.0335361675549577

Epoch: 5| Step: 3
Training loss: 1.7040975093841553
Validation loss: 2.0856225516206477

Epoch: 5| Step: 4
Training loss: 2.3593406677246094
Validation loss: 2.0487707814862652

Epoch: 5| Step: 5
Training loss: 1.322706937789917
Validation loss: 2.0472505361803117

Epoch: 5| Step: 6
Training loss: 2.142181634902954
Validation loss: 2.042881176035891

Epoch: 5| Step: 7
Training loss: 1.6301040649414062
Validation loss: 2.041643129881992

Epoch: 5| Step: 8
Training loss: 1.4610822200775146
Validation loss: 2.0257316045863654

Epoch: 5| Step: 9
Training loss: 1.3506507873535156
Validation loss: 2.0238494796137654

Epoch: 5| Step: 10
Training loss: 1.0153353214263916
Validation loss: 2.0447288161964825

Epoch: 389| Step: 0
Training loss: 1.6159099340438843
Validation loss: 2.024230603248842

Epoch: 5| Step: 1
Training loss: 1.5279983282089233
Validation loss: 2.037954350953461

Epoch: 5| Step: 2
Training loss: 1.7418733835220337
Validation loss: 2.0348053901426253

Epoch: 5| Step: 3
Training loss: 1.704114317893982
Validation loss: 2.021145051525485

Epoch: 5| Step: 4
Training loss: 1.4350486993789673
Validation loss: 2.021784301727049

Epoch: 5| Step: 5
Training loss: 1.1436073780059814
Validation loss: 2.020182389085011

Epoch: 5| Step: 6
Training loss: 1.583387017250061
Validation loss: 2.0171687782451673

Epoch: 5| Step: 7
Training loss: 1.8620760440826416
Validation loss: 2.0578620254352527

Epoch: 5| Step: 8
Training loss: 1.2486941814422607
Validation loss: 2.0204648766466367

Epoch: 5| Step: 9
Training loss: 2.317868709564209
Validation loss: 2.005245630459119

Epoch: 5| Step: 10
Training loss: 1.6029633283615112
Validation loss: 2.0323663770511584

Epoch: 390| Step: 0
Training loss: 1.4587299823760986
Validation loss: 2.00577401473958

Epoch: 5| Step: 1
Training loss: 1.440386176109314
Validation loss: 2.0534056476367417

Epoch: 5| Step: 2
Training loss: 1.3536609411239624
Validation loss: 2.001954154301715

Epoch: 5| Step: 3
Training loss: 1.5356630086898804
Validation loss: 2.0091852821329588

Epoch: 5| Step: 4
Training loss: 1.116086721420288
Validation loss: 2.0353075817067134

Epoch: 5| Step: 5
Training loss: 1.3286197185516357
Validation loss: 2.0208784252084713

Epoch: 5| Step: 6
Training loss: 1.8054777383804321
Validation loss: 2.0025660632759013

Epoch: 5| Step: 7
Training loss: 2.026211738586426
Validation loss: 2.0232900573361303

Epoch: 5| Step: 8
Training loss: 2.2492167949676514
Validation loss: 2.030114991690523

Epoch: 5| Step: 9
Training loss: 1.7240489721298218
Validation loss: 2.040985030512656

Epoch: 5| Step: 10
Training loss: 1.993177056312561
Validation loss: 1.9977728051524009

Epoch: 391| Step: 0
Training loss: 1.5322768688201904
Validation loss: 2.013187369992656

Epoch: 5| Step: 1
Training loss: 1.895302176475525
Validation loss: 2.014830941795021

Epoch: 5| Step: 2
Training loss: 1.4557088613510132
Validation loss: 2.004043104828045

Epoch: 5| Step: 3
Training loss: 1.7732292413711548
Validation loss: 2.0382657768905803

Epoch: 5| Step: 4
Training loss: 1.6269563436508179
Validation loss: 2.022739471927766

Epoch: 5| Step: 5
Training loss: 1.8941452503204346
Validation loss: 2.0070885586482223

Epoch: 5| Step: 6
Training loss: 1.1465952396392822
Validation loss: 2.02443124658318

Epoch: 5| Step: 7
Training loss: 1.2867908477783203
Validation loss: 2.0207182515052056

Epoch: 5| Step: 8
Training loss: 2.2266647815704346
Validation loss: 2.0228601963289323

Epoch: 5| Step: 9
Training loss: 1.3473384380340576
Validation loss: 2.0012718759557253

Epoch: 5| Step: 10
Training loss: 1.7183432579040527
Validation loss: 2.017603361478416

Epoch: 392| Step: 0
Training loss: 1.6305913925170898
Validation loss: 2.0306280761636715

Epoch: 5| Step: 1
Training loss: 1.6955410242080688
Validation loss: 2.006005874244116

Epoch: 5| Step: 2
Training loss: 2.0331764221191406
Validation loss: 2.028661186977099

Epoch: 5| Step: 3
Training loss: 1.2710416316986084
Validation loss: 2.026527658585579

Epoch: 5| Step: 4
Training loss: 2.088322162628174
Validation loss: 2.049859616064256

Epoch: 5| Step: 5
Training loss: 1.4168821573257446
Validation loss: 2.0081140072115007

Epoch: 5| Step: 6
Training loss: 1.8532459735870361
Validation loss: 2.0355365058427215

Epoch: 5| Step: 7
Training loss: 1.0300815105438232
Validation loss: 2.039836602826272

Epoch: 5| Step: 8
Training loss: 1.9209362268447876
Validation loss: 2.002415741643598

Epoch: 5| Step: 9
Training loss: 1.6750694513320923
Validation loss: 2.004250116245721

Epoch: 5| Step: 10
Training loss: 1.0547040700912476
Validation loss: 2.0327956753392376

Epoch: 393| Step: 0
Training loss: 1.2944172620773315
Validation loss: 2.014740255571181

Epoch: 5| Step: 1
Training loss: 1.0896503925323486
Validation loss: 1.979063105839555

Epoch: 5| Step: 2
Training loss: 1.5512622594833374
Validation loss: 2.02751652912427

Epoch: 5| Step: 3
Training loss: 1.4495666027069092
Validation loss: 2.029484805240426

Epoch: 5| Step: 4
Training loss: 1.5618597269058228
Validation loss: 2.0172196652299617

Epoch: 5| Step: 5
Training loss: 2.0816564559936523
Validation loss: 2.0124421670872676

Epoch: 5| Step: 6
Training loss: 1.6104398965835571
Validation loss: 2.0058882031389462

Epoch: 5| Step: 7
Training loss: 1.9919843673706055
Validation loss: 1.9746547757938344

Epoch: 5| Step: 8
Training loss: 1.6298086643218994
Validation loss: 2.0006758705262215

Epoch: 5| Step: 9
Training loss: 1.8641340732574463
Validation loss: 2.022381623586019

Epoch: 5| Step: 10
Training loss: 1.7362699508666992
Validation loss: 2.0435684534811203

Epoch: 394| Step: 0
Training loss: 2.226990222930908
Validation loss: 2.0451378771053847

Epoch: 5| Step: 1
Training loss: 1.6982002258300781
Validation loss: 1.994975459191107

Epoch: 5| Step: 2
Training loss: 1.9627482891082764
Validation loss: 2.004496484674433

Epoch: 5| Step: 3
Training loss: 1.4979989528656006
Validation loss: 2.0454198955207743

Epoch: 5| Step: 4
Training loss: 1.7344257831573486
Validation loss: 1.9996753046589513

Epoch: 5| Step: 5
Training loss: 1.2305465936660767
Validation loss: 2.023058681077855

Epoch: 5| Step: 6
Training loss: 0.9914668202400208
Validation loss: 2.016757288286763

Epoch: 5| Step: 7
Training loss: 1.6683164834976196
Validation loss: 2.0266995942720802

Epoch: 5| Step: 8
Training loss: 1.4920083284378052
Validation loss: 1.990020203334029

Epoch: 5| Step: 9
Training loss: 1.180924415588379
Validation loss: 2.0290099151672853

Epoch: 5| Step: 10
Training loss: 2.2838354110717773
Validation loss: 1.985716353180588

Epoch: 395| Step: 0
Training loss: 1.051754355430603
Validation loss: 2.024173185389529

Epoch: 5| Step: 1
Training loss: 1.6859098672866821
Validation loss: 2.0101069929779216

Epoch: 5| Step: 2
Training loss: 1.9092884063720703
Validation loss: 2.007635639559838

Epoch: 5| Step: 3
Training loss: 1.721555471420288
Validation loss: 2.0279670248749437

Epoch: 5| Step: 4
Training loss: 1.6880334615707397
Validation loss: 1.9970285328485633

Epoch: 5| Step: 5
Training loss: 1.6826105117797852
Validation loss: 2.0437527010517735

Epoch: 5| Step: 6
Training loss: 1.8368284702301025
Validation loss: 2.0043351368237565

Epoch: 5| Step: 7
Training loss: 1.4157980680465698
Validation loss: 1.9786584249106787

Epoch: 5| Step: 8
Training loss: 1.6319248676300049
Validation loss: 2.0297584969510316

Epoch: 5| Step: 9
Training loss: 1.1254140138626099
Validation loss: 2.0299610809613298

Epoch: 5| Step: 10
Training loss: 2.2475295066833496
Validation loss: 2.0032530625661216

Epoch: 396| Step: 0
Training loss: 1.297778606414795
Validation loss: 2.039930215445898

Epoch: 5| Step: 1
Training loss: 2.344727039337158
Validation loss: 2.0292535481914395

Epoch: 5| Step: 2
Training loss: 1.7668170928955078
Validation loss: 2.014798216922309

Epoch: 5| Step: 3
Training loss: 1.8594852685928345
Validation loss: 2.0097958618594753

Epoch: 5| Step: 4
Training loss: 0.7742725014686584
Validation loss: 2.0024567086209535

Epoch: 5| Step: 5
Training loss: 1.4547923803329468
Validation loss: 2.029797628361692

Epoch: 5| Step: 6
Training loss: 2.0151853561401367
Validation loss: 1.989578095815515

Epoch: 5| Step: 7
Training loss: 2.250662326812744
Validation loss: 2.0391243709030973

Epoch: 5| Step: 8
Training loss: 1.4193886518478394
Validation loss: 1.999064367304566

Epoch: 5| Step: 9
Training loss: 1.408003568649292
Validation loss: 2.017335889159992

Epoch: 5| Step: 10
Training loss: 1.2596614360809326
Validation loss: 1.9907805586373934

Epoch: 397| Step: 0
Training loss: 1.8696727752685547
Validation loss: 2.013298419214064

Epoch: 5| Step: 1
Training loss: 2.3691420555114746
Validation loss: 2.019912974808806

Epoch: 5| Step: 2
Training loss: 1.5197572708129883
Validation loss: 2.0276493359637517

Epoch: 5| Step: 3
Training loss: 1.9457752704620361
Validation loss: 2.0283918406373713

Epoch: 5| Step: 4
Training loss: 1.5691440105438232
Validation loss: 2.0343685355237735

Epoch: 5| Step: 5
Training loss: 1.5068703889846802
Validation loss: 2.0205652713775635

Epoch: 5| Step: 6
Training loss: 1.081118106842041
Validation loss: 2.0072113711346864

Epoch: 5| Step: 7
Training loss: 1.5222079753875732
Validation loss: 2.0499816402312248

Epoch: 5| Step: 8
Training loss: 1.6887935400009155
Validation loss: 2.0211758587950017

Epoch: 5| Step: 9
Training loss: 1.3541349172592163
Validation loss: 1.9929940341621317

Epoch: 5| Step: 10
Training loss: 1.593757152557373
Validation loss: 1.9878734696295954

Epoch: 398| Step: 0
Training loss: 1.4498863220214844
Validation loss: 1.993696387096118

Epoch: 5| Step: 1
Training loss: 1.3602063655853271
Validation loss: 1.9691226687482608

Epoch: 5| Step: 2
Training loss: 1.997707724571228
Validation loss: 2.0044032681372856

Epoch: 5| Step: 3
Training loss: 1.3782438039779663
Validation loss: 2.0265130278884724

Epoch: 5| Step: 4
Training loss: 1.5598680973052979
Validation loss: 2.03328679197578

Epoch: 5| Step: 5
Training loss: 1.174777626991272
Validation loss: 2.0387444060335875

Epoch: 5| Step: 6
Training loss: 2.032526731491089
Validation loss: 2.0077619257793633

Epoch: 5| Step: 7
Training loss: 1.2655601501464844
Validation loss: 2.0142386074989074

Epoch: 5| Step: 8
Training loss: 2.3890206813812256
Validation loss: 1.9938360004014866

Epoch: 5| Step: 9
Training loss: 1.3051451444625854
Validation loss: 2.0030463190488916

Epoch: 5| Step: 10
Training loss: 1.7353086471557617
Validation loss: 2.0066254984947944

Epoch: 399| Step: 0
Training loss: 2.3545827865600586
Validation loss: 2.0215426209152385

Epoch: 5| Step: 1
Training loss: 1.4897880554199219
Validation loss: 1.9876260526718632

Epoch: 5| Step: 2
Training loss: 1.094725489616394
Validation loss: 2.0477501038582093

Epoch: 5| Step: 3
Training loss: 1.8976904153823853
Validation loss: 2.01398007715902

Epoch: 5| Step: 4
Training loss: 2.328435182571411
Validation loss: 1.9958332712932298

Epoch: 5| Step: 5
Training loss: 1.2213908433914185
Validation loss: 2.0122676882692563

Epoch: 5| Step: 6
Training loss: 0.9966012835502625
Validation loss: 2.009039368680728

Epoch: 5| Step: 7
Training loss: 1.5497443675994873
Validation loss: 2.0082352443407943

Epoch: 5| Step: 8
Training loss: 1.6998765468597412
Validation loss: 2.0107969878822245

Epoch: 5| Step: 9
Training loss: 1.509015679359436
Validation loss: 2.019803008725566

Epoch: 5| Step: 10
Training loss: 1.6322441101074219
Validation loss: 2.0145580691675984

Epoch: 400| Step: 0
Training loss: 1.70559823513031
Validation loss: 2.028410188613399

Epoch: 5| Step: 1
Training loss: 1.3408783674240112
Validation loss: 2.011358940473167

Epoch: 5| Step: 2
Training loss: 1.5042543411254883
Validation loss: 2.0297045143701697

Epoch: 5| Step: 3
Training loss: 1.5693668127059937
Validation loss: 2.014582828808856

Epoch: 5| Step: 4
Training loss: 1.5399199724197388
Validation loss: 1.996777916467318

Epoch: 5| Step: 5
Training loss: 2.0224902629852295
Validation loss: 2.0057195437851774

Epoch: 5| Step: 6
Training loss: 1.5859565734863281
Validation loss: 2.0149821517288045

Epoch: 5| Step: 7
Training loss: 1.6232795715332031
Validation loss: 2.026580479837233

Epoch: 5| Step: 8
Training loss: 1.9485191106796265
Validation loss: 2.052384508553372

Epoch: 5| Step: 9
Training loss: 1.470543622970581
Validation loss: 2.0445731686007593

Epoch: 5| Step: 10
Training loss: 1.3624992370605469
Validation loss: 2.0641189467522407

Epoch: 401| Step: 0
Training loss: 1.7623659372329712
Validation loss: 2.027677200173819

Epoch: 5| Step: 1
Training loss: 1.7346184253692627
Validation loss: 2.031381200718623

Epoch: 5| Step: 2
Training loss: 2.16859769821167
Validation loss: 2.022391503857028

Epoch: 5| Step: 3
Training loss: 1.930406928062439
Validation loss: 2.034434522351911

Epoch: 5| Step: 4
Training loss: 1.325570821762085
Validation loss: 2.0000544132724887

Epoch: 5| Step: 5
Training loss: 1.653441071510315
Validation loss: 2.0544362452722367

Epoch: 5| Step: 6
Training loss: 1.4359588623046875
Validation loss: 2.047556492590135

Epoch: 5| Step: 7
Training loss: 1.3015213012695312
Validation loss: 2.0553670429414317

Epoch: 5| Step: 8
Training loss: 1.6625474691390991
Validation loss: 2.047222811688659

Epoch: 5| Step: 9
Training loss: 1.4586213827133179
Validation loss: 2.04089363416036

Epoch: 5| Step: 10
Training loss: 1.3727518320083618
Validation loss: 2.049200673257151

Epoch: 402| Step: 0
Training loss: 1.1514027118682861
Validation loss: 2.042940721716932

Epoch: 5| Step: 1
Training loss: 1.958833932876587
Validation loss: 2.042209399643765

Epoch: 5| Step: 2
Training loss: 1.4829448461532593
Validation loss: 2.0335803275467246

Epoch: 5| Step: 3
Training loss: 1.7587783336639404
Validation loss: 2.030943883362637

Epoch: 5| Step: 4
Training loss: 2.2509713172912598
Validation loss: 2.0402044198846303

Epoch: 5| Step: 5
Training loss: 1.4638035297393799
Validation loss: 2.0349457110128095

Epoch: 5| Step: 6
Training loss: 1.3585656881332397
Validation loss: 2.0025763216839043

Epoch: 5| Step: 7
Training loss: 1.7765992879867554
Validation loss: 2.0071005616136777

Epoch: 5| Step: 8
Training loss: 1.3160537481307983
Validation loss: 1.9953054407591462

Epoch: 5| Step: 9
Training loss: 1.4916104078292847
Validation loss: 2.032996987783781

Epoch: 5| Step: 10
Training loss: 1.6783037185668945
Validation loss: 2.0345818111973424

Epoch: 403| Step: 0
Training loss: 2.1181607246398926
Validation loss: 2.047829871536583

Epoch: 5| Step: 1
Training loss: 1.8169581890106201
Validation loss: 2.0279667992745676

Epoch: 5| Step: 2
Training loss: 1.5209953784942627
Validation loss: 2.0296631577194377

Epoch: 5| Step: 3
Training loss: 1.3876723051071167
Validation loss: 1.9918105756082842

Epoch: 5| Step: 4
Training loss: 1.9515033960342407
Validation loss: 2.0263842331465853

Epoch: 5| Step: 5
Training loss: 1.5337998867034912
Validation loss: 2.021755788915901

Epoch: 5| Step: 6
Training loss: 1.307665228843689
Validation loss: 2.0227846471212243

Epoch: 5| Step: 7
Training loss: 1.3584121465682983
Validation loss: 2.031575841288413

Epoch: 5| Step: 8
Training loss: 1.8321549892425537
Validation loss: 2.029509393117761

Epoch: 5| Step: 9
Training loss: 1.1941791772842407
Validation loss: 2.000784940617059

Epoch: 5| Step: 10
Training loss: 1.613703727722168
Validation loss: 2.001286041352057

Epoch: 404| Step: 0
Training loss: 1.6860144138336182
Validation loss: 2.001875408234135

Epoch: 5| Step: 1
Training loss: 1.511824607849121
Validation loss: 2.0182028867865123

Epoch: 5| Step: 2
Training loss: 1.3335585594177246
Validation loss: 2.020727288338446

Epoch: 5| Step: 3
Training loss: 1.0010011196136475
Validation loss: 2.042961576933502

Epoch: 5| Step: 4
Training loss: 1.9115660190582275
Validation loss: 2.0145386931716756

Epoch: 5| Step: 5
Training loss: 2.2797439098358154
Validation loss: 2.0370487423353296

Epoch: 5| Step: 6
Training loss: 1.6812269687652588
Validation loss: 2.03861387314335

Epoch: 5| Step: 7
Training loss: 1.4659183025360107
Validation loss: 2.0042886041825816

Epoch: 5| Step: 8
Training loss: 2.392362117767334
Validation loss: 2.0392834806954987

Epoch: 5| Step: 9
Training loss: 1.2613662481307983
Validation loss: 1.992132499653806

Epoch: 5| Step: 10
Training loss: 1.231103539466858
Validation loss: 1.9986457632433983

Epoch: 405| Step: 0
Training loss: 1.9719316959381104
Validation loss: 2.010916212553619

Epoch: 5| Step: 1
Training loss: 1.19785475730896
Validation loss: 2.0418054134615007

Epoch: 5| Step: 2
Training loss: 1.2771985530853271
Validation loss: 2.047364619470412

Epoch: 5| Step: 3
Training loss: 1.805092215538025
Validation loss: 2.054286410731654

Epoch: 5| Step: 4
Training loss: 2.1252617835998535
Validation loss: 2.07724497138813

Epoch: 5| Step: 5
Training loss: 1.768690824508667
Validation loss: 2.04559306047296

Epoch: 5| Step: 6
Training loss: 1.7676687240600586
Validation loss: 2.0310022536144463

Epoch: 5| Step: 7
Training loss: 1.3369816541671753
Validation loss: 2.039876707138554

Epoch: 5| Step: 8
Training loss: 1.4645884037017822
Validation loss: 2.0247140802362913

Epoch: 5| Step: 9
Training loss: 1.4695147275924683
Validation loss: 2.068632656528104

Epoch: 5| Step: 10
Training loss: 1.5789103507995605
Validation loss: 2.076336581219909

Epoch: 406| Step: 0
Training loss: 1.9109325408935547
Validation loss: 2.070665987589026

Epoch: 5| Step: 1
Training loss: 1.490517258644104
Validation loss: 2.039406230372767

Epoch: 5| Step: 2
Training loss: 1.883932113647461
Validation loss: 2.0471171743126324

Epoch: 5| Step: 3
Training loss: 1.8682972192764282
Validation loss: 2.0440613813297723

Epoch: 5| Step: 4
Training loss: 1.0859508514404297
Validation loss: 2.0082142109512002

Epoch: 5| Step: 5
Training loss: 1.5176417827606201
Validation loss: 2.0370463812223045

Epoch: 5| Step: 6
Training loss: 1.2084856033325195
Validation loss: 2.031230216385216

Epoch: 5| Step: 7
Training loss: 1.528467059135437
Validation loss: 1.996678429265176

Epoch: 5| Step: 8
Training loss: 1.81452214717865
Validation loss: 2.008604839283933

Epoch: 5| Step: 9
Training loss: 2.0064327716827393
Validation loss: 1.9966369072596233

Epoch: 5| Step: 10
Training loss: 1.2496147155761719
Validation loss: 2.007677649938932

Epoch: 407| Step: 0
Training loss: 1.4527595043182373
Validation loss: 2.0190613859443256

Epoch: 5| Step: 1
Training loss: 1.598852515220642
Validation loss: 2.0047016259162658

Epoch: 5| Step: 2
Training loss: 1.8920652866363525
Validation loss: 2.038328925768534

Epoch: 5| Step: 3
Training loss: 1.9226903915405273
Validation loss: 2.0073848437237483

Epoch: 5| Step: 4
Training loss: 1.3409478664398193
Validation loss: 2.053532087674705

Epoch: 5| Step: 5
Training loss: 1.4459089040756226
Validation loss: 2.002131664624778

Epoch: 5| Step: 6
Training loss: 0.9586348533630371
Validation loss: 2.0525237001398557

Epoch: 5| Step: 7
Training loss: 1.8678951263427734
Validation loss: 2.0135372864302767

Epoch: 5| Step: 8
Training loss: 1.430389165878296
Validation loss: 2.051090363533266

Epoch: 5| Step: 9
Training loss: 1.950026512145996
Validation loss: 2.0061268678275486

Epoch: 5| Step: 10
Training loss: 1.685478925704956
Validation loss: 2.0439308202394875

Epoch: 408| Step: 0
Training loss: 1.6971343755722046
Validation loss: 2.0199453548718522

Epoch: 5| Step: 1
Training loss: 1.7815980911254883
Validation loss: 2.0399890535621235

Epoch: 5| Step: 2
Training loss: 1.5993530750274658
Validation loss: 2.0301624139149985

Epoch: 5| Step: 3
Training loss: 2.133110761642456
Validation loss: 2.0303997698650567

Epoch: 5| Step: 4
Training loss: 1.6336963176727295
Validation loss: 2.0467255166781846

Epoch: 5| Step: 5
Training loss: 1.1416161060333252
Validation loss: 2.0538519415804135

Epoch: 5| Step: 6
Training loss: 1.4803950786590576
Validation loss: 1.9989535347107918

Epoch: 5| Step: 7
Training loss: 1.5243587493896484
Validation loss: 2.039421389179845

Epoch: 5| Step: 8
Training loss: 1.6185438632965088
Validation loss: 2.0376477895244474

Epoch: 5| Step: 9
Training loss: 1.7742096185684204
Validation loss: 2.023310028096681

Epoch: 5| Step: 10
Training loss: 1.145885944366455
Validation loss: 2.030678008192329

Epoch: 409| Step: 0
Training loss: 1.9643547534942627
Validation loss: 2.0016250546260546

Epoch: 5| Step: 1
Training loss: 2.0663371086120605
Validation loss: 2.030289187226244

Epoch: 5| Step: 2
Training loss: 1.5402950048446655
Validation loss: 2.039319446009974

Epoch: 5| Step: 3
Training loss: 1.4391552209854126
Validation loss: 2.029481739126226

Epoch: 5| Step: 4
Training loss: 1.4441760778427124
Validation loss: 2.014523062654721

Epoch: 5| Step: 5
Training loss: 1.5641977787017822
Validation loss: 2.038173460191296

Epoch: 5| Step: 6
Training loss: 1.5103113651275635
Validation loss: 1.9961398865586968

Epoch: 5| Step: 7
Training loss: 1.2240333557128906
Validation loss: 2.0219288923407115

Epoch: 5| Step: 8
Training loss: 1.3744966983795166
Validation loss: 2.024484598508445

Epoch: 5| Step: 9
Training loss: 1.6216468811035156
Validation loss: 1.9850256007204774

Epoch: 5| Step: 10
Training loss: 1.636490821838379
Validation loss: 1.9994247459596204

Epoch: 410| Step: 0
Training loss: 0.9104375839233398
Validation loss: 2.0367655343906854

Epoch: 5| Step: 1
Training loss: 1.599483847618103
Validation loss: 2.011069950237069

Epoch: 5| Step: 2
Training loss: 2.2887184619903564
Validation loss: 2.032408695067129

Epoch: 5| Step: 3
Training loss: 1.0918991565704346
Validation loss: 2.0261314966345347

Epoch: 5| Step: 4
Training loss: 1.7058007717132568
Validation loss: 2.018058669182562

Epoch: 5| Step: 5
Training loss: 1.3126788139343262
Validation loss: 2.0111480938491

Epoch: 5| Step: 6
Training loss: 1.488986849784851
Validation loss: 2.005056591444118

Epoch: 5| Step: 7
Training loss: 1.8096988201141357
Validation loss: 2.0592393131666284

Epoch: 5| Step: 8
Training loss: 1.4302737712860107
Validation loss: 2.0274206284553773

Epoch: 5| Step: 9
Training loss: 1.8187392950057983
Validation loss: 2.0242959965941725

Epoch: 5| Step: 10
Training loss: 1.917307734489441
Validation loss: 2.0027085914406726

Epoch: 411| Step: 0
Training loss: 2.010007858276367
Validation loss: 2.01983481068765

Epoch: 5| Step: 1
Training loss: 2.0861001014709473
Validation loss: 2.029344525388492

Epoch: 5| Step: 2
Training loss: 1.6258217096328735
Validation loss: 2.037423236395723

Epoch: 5| Step: 3
Training loss: 1.16258704662323
Validation loss: 2.0369839411909862

Epoch: 5| Step: 4
Training loss: 1.3349933624267578
Validation loss: 2.058478408603258

Epoch: 5| Step: 5
Training loss: 1.7856813669204712
Validation loss: 2.0310127042954966

Epoch: 5| Step: 6
Training loss: 1.1637147665023804
Validation loss: 2.051465501067459

Epoch: 5| Step: 7
Training loss: 2.247889518737793
Validation loss: 2.0255347003218946

Epoch: 5| Step: 8
Training loss: 1.4891688823699951
Validation loss: 2.0164335825109996

Epoch: 5| Step: 9
Training loss: 1.1903116703033447
Validation loss: 2.039731200023364

Epoch: 5| Step: 10
Training loss: 1.4329172372817993
Validation loss: 2.0356295518977667

Epoch: 412| Step: 0
Training loss: 2.0189759731292725
Validation loss: 1.9850190172913253

Epoch: 5| Step: 1
Training loss: 1.0681369304656982
Validation loss: 1.98944507363022

Epoch: 5| Step: 2
Training loss: 1.8806467056274414
Validation loss: 2.010723372941376

Epoch: 5| Step: 3
Training loss: 1.6129497289657593
Validation loss: 1.9974379001125213

Epoch: 5| Step: 4
Training loss: 1.2147687673568726
Validation loss: 2.005522105001634

Epoch: 5| Step: 5
Training loss: 1.5374482870101929
Validation loss: 2.0263005866799304

Epoch: 5| Step: 6
Training loss: 2.1068661212921143
Validation loss: 2.0274773797681256

Epoch: 5| Step: 7
Training loss: 1.6840946674346924
Validation loss: 2.02556219280407

Epoch: 5| Step: 8
Training loss: 1.8587242364883423
Validation loss: 2.0248104910696707

Epoch: 5| Step: 9
Training loss: 1.591449499130249
Validation loss: 2.056923739371761

Epoch: 5| Step: 10
Training loss: 1.0602264404296875
Validation loss: 2.0298674721871652

Epoch: 413| Step: 0
Training loss: 2.053222417831421
Validation loss: 2.014086720763996

Epoch: 5| Step: 1
Training loss: 2.0136911869049072
Validation loss: 2.0224399259013515

Epoch: 5| Step: 2
Training loss: 1.5595537424087524
Validation loss: 2.0216993439582085

Epoch: 5| Step: 3
Training loss: 1.8688299655914307
Validation loss: 2.005898698683708

Epoch: 5| Step: 4
Training loss: 1.3374662399291992
Validation loss: 1.9819288920330744

Epoch: 5| Step: 5
Training loss: 1.3365271091461182
Validation loss: 2.0209322129526446

Epoch: 5| Step: 6
Training loss: 1.4362667798995972
Validation loss: 1.9972616805825183

Epoch: 5| Step: 7
Training loss: 1.554909110069275
Validation loss: 1.979967999201949

Epoch: 5| Step: 8
Training loss: 1.1922975778579712
Validation loss: 2.003053947161603

Epoch: 5| Step: 9
Training loss: 1.4690817594528198
Validation loss: 1.9930959132409864

Epoch: 5| Step: 10
Training loss: 1.3809834718704224
Validation loss: 2.016362691438326

Epoch: 414| Step: 0
Training loss: 2.0871872901916504
Validation loss: 2.0233490313253095

Epoch: 5| Step: 1
Training loss: 1.3519628047943115
Validation loss: 2.0044139085277433

Epoch: 5| Step: 2
Training loss: 1.382102608680725
Validation loss: 1.9987057767888552

Epoch: 5| Step: 3
Training loss: 2.139214277267456
Validation loss: 2.0414379040400186

Epoch: 5| Step: 4
Training loss: 1.1758840084075928
Validation loss: 2.0332837591889086

Epoch: 5| Step: 5
Training loss: 2.244079828262329
Validation loss: 1.983893681597966

Epoch: 5| Step: 6
Training loss: 1.7873332500457764
Validation loss: 1.9868511179442048

Epoch: 5| Step: 7
Training loss: 1.2874982357025146
Validation loss: 1.9884174818633704

Epoch: 5| Step: 8
Training loss: 1.5332571268081665
Validation loss: 2.0354588980315835

Epoch: 5| Step: 9
Training loss: 1.3083821535110474
Validation loss: 2.0336342088637815

Epoch: 5| Step: 10
Training loss: 1.3328144550323486
Validation loss: 2.0087980172967397

Epoch: 415| Step: 0
Training loss: 1.9848415851593018
Validation loss: 2.040743884219918

Epoch: 5| Step: 1
Training loss: 1.604241967201233
Validation loss: 1.9860415253587949

Epoch: 5| Step: 2
Training loss: 1.686933159828186
Validation loss: 1.9989973165655648

Epoch: 5| Step: 3
Training loss: 1.4891302585601807
Validation loss: 2.013774694934968

Epoch: 5| Step: 4
Training loss: 1.3744542598724365
Validation loss: 1.9828629775713849

Epoch: 5| Step: 5
Training loss: 1.108351469039917
Validation loss: 2.013212493670884

Epoch: 5| Step: 6
Training loss: 2.103581666946411
Validation loss: 2.0225595838280133

Epoch: 5| Step: 7
Training loss: 1.372029185295105
Validation loss: 1.9818477758797266

Epoch: 5| Step: 8
Training loss: 1.6450449228286743
Validation loss: 1.996829730208202

Epoch: 5| Step: 9
Training loss: 1.4457368850708008
Validation loss: 2.023265266931185

Epoch: 5| Step: 10
Training loss: 1.567801833152771
Validation loss: 1.9961868255369124

Epoch: 416| Step: 0
Training loss: 1.2368110418319702
Validation loss: 1.9866461805118028

Epoch: 5| Step: 1
Training loss: 1.5704692602157593
Validation loss: 2.023507677098756

Epoch: 5| Step: 2
Training loss: 1.1879527568817139
Validation loss: 1.9957909455863379

Epoch: 5| Step: 3
Training loss: 1.8902631998062134
Validation loss: 2.0686626280507734

Epoch: 5| Step: 4
Training loss: 1.8074674606323242
Validation loss: 2.0156478420380624

Epoch: 5| Step: 5
Training loss: 1.231391191482544
Validation loss: 2.0416091449799074

Epoch: 5| Step: 6
Training loss: 1.7337381839752197
Validation loss: 2.0092166700670795

Epoch: 5| Step: 7
Training loss: 1.8603122234344482
Validation loss: 1.984293455718666

Epoch: 5| Step: 8
Training loss: 1.8843415975570679
Validation loss: 2.023889328843804

Epoch: 5| Step: 9
Training loss: 1.1421377658843994
Validation loss: 2.064991330587736

Epoch: 5| Step: 10
Training loss: 1.8369073867797852
Validation loss: 2.038528960238221

Epoch: 417| Step: 0
Training loss: 1.3500971794128418
Validation loss: 2.047273297463694

Epoch: 5| Step: 1
Training loss: 1.1137818098068237
Validation loss: 1.9893627858931018

Epoch: 5| Step: 2
Training loss: 1.573099970817566
Validation loss: 2.0051494054896857

Epoch: 5| Step: 3
Training loss: 2.2280945777893066
Validation loss: 1.9919612446138937

Epoch: 5| Step: 4
Training loss: 1.6897550821304321
Validation loss: 2.010049552045843

Epoch: 5| Step: 5
Training loss: 1.485926628112793
Validation loss: 2.005116296070878

Epoch: 5| Step: 6
Training loss: 1.3003318309783936
Validation loss: 2.032254993274648

Epoch: 5| Step: 7
Training loss: 2.106642246246338
Validation loss: 2.0565971764185096

Epoch: 5| Step: 8
Training loss: 1.7722793817520142
Validation loss: 2.007753981057034

Epoch: 5| Step: 9
Training loss: 1.2530673742294312
Validation loss: 2.031986963364386

Epoch: 5| Step: 10
Training loss: 1.5773392915725708
Validation loss: 2.0154489804339666

Epoch: 418| Step: 0
Training loss: 1.9130207300186157
Validation loss: 1.9983655496310162

Epoch: 5| Step: 1
Training loss: 1.5430173873901367
Validation loss: 2.0077638677371445

Epoch: 5| Step: 2
Training loss: 1.4712307453155518
Validation loss: 1.9719177702421784

Epoch: 5| Step: 3
Training loss: 0.9578887820243835
Validation loss: 2.045133738107579

Epoch: 5| Step: 4
Training loss: 1.5087608098983765
Validation loss: 1.994276544099213

Epoch: 5| Step: 5
Training loss: 1.5418905019760132
Validation loss: 2.0248715903169368

Epoch: 5| Step: 6
Training loss: 1.3781769275665283
Validation loss: 2.032635990009513

Epoch: 5| Step: 7
Training loss: 1.3895866870880127
Validation loss: 2.028429603063932

Epoch: 5| Step: 8
Training loss: 1.7142184972763062
Validation loss: 2.0348582806125766

Epoch: 5| Step: 9
Training loss: 2.1970009803771973
Validation loss: 2.027173517852701

Epoch: 5| Step: 10
Training loss: 1.5095570087432861
Validation loss: 1.981010324211531

Epoch: 419| Step: 0
Training loss: 1.7499898672103882
Validation loss: 1.9711165889616935

Epoch: 5| Step: 1
Training loss: 1.4412596225738525
Validation loss: 1.999445056402555

Epoch: 5| Step: 2
Training loss: 1.4339399337768555
Validation loss: 2.0300550563361055

Epoch: 5| Step: 3
Training loss: 1.336016058921814
Validation loss: 2.0086233013419696

Epoch: 5| Step: 4
Training loss: 2.2253987789154053
Validation loss: 2.025865052336006

Epoch: 5| Step: 5
Training loss: 1.5040782690048218
Validation loss: 2.0469270047321113

Epoch: 5| Step: 6
Training loss: 1.0869170427322388
Validation loss: 2.0554272026144047

Epoch: 5| Step: 7
Training loss: 1.3384780883789062
Validation loss: 2.0328352002687353

Epoch: 5| Step: 8
Training loss: 1.750751256942749
Validation loss: 2.0072234753639466

Epoch: 5| Step: 9
Training loss: 1.4019606113433838
Validation loss: 2.059662806090488

Epoch: 5| Step: 10
Training loss: 1.932938575744629
Validation loss: 2.0095244479435745

Epoch: 420| Step: 0
Training loss: 1.9542090892791748
Validation loss: 2.011295892859018

Epoch: 5| Step: 1
Training loss: 1.2735674381256104
Validation loss: 1.9675216303076795

Epoch: 5| Step: 2
Training loss: 1.1760982275009155
Validation loss: 2.0109538519254295

Epoch: 5| Step: 3
Training loss: 1.8443515300750732
Validation loss: 2.0066300053750314

Epoch: 5| Step: 4
Training loss: 1.4097063541412354
Validation loss: 2.0111687221834735

Epoch: 5| Step: 5
Training loss: 1.2381799221038818
Validation loss: 2.0021594352619623

Epoch: 5| Step: 6
Training loss: 1.8236585855484009
Validation loss: 1.9823003110065256

Epoch: 5| Step: 7
Training loss: 1.6035356521606445
Validation loss: 1.9997055851003176

Epoch: 5| Step: 8
Training loss: 1.3988336324691772
Validation loss: 1.9874827874604093

Epoch: 5| Step: 9
Training loss: 1.5545234680175781
Validation loss: 2.001165210559804

Epoch: 5| Step: 10
Training loss: 1.9728591442108154
Validation loss: 1.994228619401173

Epoch: 421| Step: 0
Training loss: 1.7738597393035889
Validation loss: 2.010698110826554

Epoch: 5| Step: 1
Training loss: 1.8849014043807983
Validation loss: 2.0239806944324124

Epoch: 5| Step: 2
Training loss: 1.459932565689087
Validation loss: 1.9865266353853288

Epoch: 5| Step: 3
Training loss: 1.6228530406951904
Validation loss: 2.0059385171500583

Epoch: 5| Step: 4
Training loss: 1.1745892763137817
Validation loss: 2.027126673729189

Epoch: 5| Step: 5
Training loss: 1.242370367050171
Validation loss: 1.9850770837517195

Epoch: 5| Step: 6
Training loss: 2.0424296855926514
Validation loss: 1.9531143673004643

Epoch: 5| Step: 7
Training loss: 1.0665967464447021
Validation loss: 2.0045717121452413

Epoch: 5| Step: 8
Training loss: 1.850770354270935
Validation loss: 2.0229949476898357

Epoch: 5| Step: 9
Training loss: 1.276600956916809
Validation loss: 2.001017665350309

Epoch: 5| Step: 10
Training loss: 1.797111988067627
Validation loss: 2.0230897254841302

Epoch: 422| Step: 0
Training loss: 1.6837356090545654
Validation loss: 2.0156196137910247

Epoch: 5| Step: 1
Training loss: 1.432357668876648
Validation loss: 2.040277942534416

Epoch: 5| Step: 2
Training loss: 1.951668381690979
Validation loss: 2.0601678740593696

Epoch: 5| Step: 3
Training loss: 1.5327990055084229
Validation loss: 2.03718299763177

Epoch: 5| Step: 4
Training loss: 1.473081111907959
Validation loss: 2.000444055885397

Epoch: 5| Step: 5
Training loss: 1.8446018695831299
Validation loss: 2.0420313394197853

Epoch: 5| Step: 6
Training loss: 1.503486156463623
Validation loss: 2.029158294841807

Epoch: 5| Step: 7
Training loss: 1.4431382417678833
Validation loss: 2.0218663087455173

Epoch: 5| Step: 8
Training loss: 0.9668155908584595
Validation loss: 2.0104153079371296

Epoch: 5| Step: 9
Training loss: 2.034761667251587
Validation loss: 2.037534511217507

Epoch: 5| Step: 10
Training loss: 1.3903425931930542
Validation loss: 1.9842134393671507

Epoch: 423| Step: 0
Training loss: 1.3949296474456787
Validation loss: 1.9956630481186735

Epoch: 5| Step: 1
Training loss: 1.424384593963623
Validation loss: 2.008911507104033

Epoch: 5| Step: 2
Training loss: 1.6004269123077393
Validation loss: 2.03463904575635

Epoch: 5| Step: 3
Training loss: 1.391480803489685
Validation loss: 2.001725245547551

Epoch: 5| Step: 4
Training loss: 1.8234336376190186
Validation loss: 2.018553979935185

Epoch: 5| Step: 5
Training loss: 1.8465818166732788
Validation loss: 2.0359100141832904

Epoch: 5| Step: 6
Training loss: 1.2033849954605103
Validation loss: 2.00922687720227

Epoch: 5| Step: 7
Training loss: 1.8426086902618408
Validation loss: 2.0164496591014247

Epoch: 5| Step: 8
Training loss: 1.335405707359314
Validation loss: 1.9891209269082675

Epoch: 5| Step: 9
Training loss: 1.6096775531768799
Validation loss: 2.0369191708103305

Epoch: 5| Step: 10
Training loss: 1.6875284910202026
Validation loss: 2.0281373057314145

Epoch: 424| Step: 0
Training loss: 1.342615008354187
Validation loss: 2.0114836846628497

Epoch: 5| Step: 1
Training loss: 1.657554268836975
Validation loss: 2.0079299711411998

Epoch: 5| Step: 2
Training loss: 1.685692548751831
Validation loss: 2.006530233608779

Epoch: 5| Step: 3
Training loss: 1.9512983560562134
Validation loss: 2.027140817334575

Epoch: 5| Step: 4
Training loss: 1.696877121925354
Validation loss: 2.018632940066758

Epoch: 5| Step: 5
Training loss: 1.084007978439331
Validation loss: 2.006043916107506

Epoch: 5| Step: 6
Training loss: 1.8071517944335938
Validation loss: 1.99912400655849

Epoch: 5| Step: 7
Training loss: 1.3236596584320068
Validation loss: 2.027111263685329

Epoch: 5| Step: 8
Training loss: 2.0236494541168213
Validation loss: 2.010896502002593

Epoch: 5| Step: 9
Training loss: 1.5734338760375977
Validation loss: 2.02810610366124

Epoch: 5| Step: 10
Training loss: 1.125344157218933
Validation loss: 2.038155610843371

Epoch: 425| Step: 0
Training loss: 1.8179092407226562
Validation loss: 1.961179571767007

Epoch: 5| Step: 1
Training loss: 1.919073462486267
Validation loss: 2.0274640360186176

Epoch: 5| Step: 2
Training loss: 0.9539194107055664
Validation loss: 1.9856060820241128

Epoch: 5| Step: 3
Training loss: 1.6091029644012451
Validation loss: 2.0298094826359905

Epoch: 5| Step: 4
Training loss: 1.7225182056427002
Validation loss: 2.0320438005590953

Epoch: 5| Step: 5
Training loss: 1.729905366897583
Validation loss: 2.0413599732101604

Epoch: 5| Step: 6
Training loss: 1.700768232345581
Validation loss: 2.0142076361563896

Epoch: 5| Step: 7
Training loss: 1.6788963079452515
Validation loss: 1.99742538954622

Epoch: 5| Step: 8
Training loss: 1.5935370922088623
Validation loss: 2.0085290593485676

Epoch: 5| Step: 9
Training loss: 1.2851310968399048
Validation loss: 2.0095000446483655

Epoch: 5| Step: 10
Training loss: 1.0163891315460205
Validation loss: 1.9961699542178903

Epoch: 426| Step: 0
Training loss: 1.4742164611816406
Validation loss: 2.0115374134432886

Epoch: 5| Step: 1
Training loss: 1.2994436025619507
Validation loss: 2.021739423915904

Epoch: 5| Step: 2
Training loss: 1.368720293045044
Validation loss: 1.9812551980377526

Epoch: 5| Step: 3
Training loss: 1.1465842723846436
Validation loss: 1.9946717933941913

Epoch: 5| Step: 4
Training loss: 1.740462064743042
Validation loss: 1.9883674549800094

Epoch: 5| Step: 5
Training loss: 1.660360336303711
Validation loss: 1.9938125994897657

Epoch: 5| Step: 6
Training loss: 1.9940245151519775
Validation loss: 2.017040556476962

Epoch: 5| Step: 7
Training loss: 1.5717815160751343
Validation loss: 2.025757953684817

Epoch: 5| Step: 8
Training loss: 1.690672516822815
Validation loss: 2.0815187628551195

Epoch: 5| Step: 9
Training loss: 1.4945824146270752
Validation loss: 2.002489618075791

Epoch: 5| Step: 10
Training loss: 1.564076542854309
Validation loss: 2.0274376356473534

Epoch: 427| Step: 0
Training loss: 1.0130188465118408
Validation loss: 2.054451375879267

Epoch: 5| Step: 1
Training loss: 1.5579404830932617
Validation loss: 2.0127831966646257

Epoch: 5| Step: 2
Training loss: 1.369291067123413
Validation loss: 2.027240178918326

Epoch: 5| Step: 3
Training loss: 1.8673502206802368
Validation loss: 1.989146924787952

Epoch: 5| Step: 4
Training loss: 1.5510201454162598
Validation loss: 2.0227278137719757

Epoch: 5| Step: 5
Training loss: 1.6000028848648071
Validation loss: 2.0302030655645553

Epoch: 5| Step: 6
Training loss: 1.7639095783233643
Validation loss: 1.991033124667342

Epoch: 5| Step: 7
Training loss: 1.399707555770874
Validation loss: 2.0444035619817753

Epoch: 5| Step: 8
Training loss: 1.9163618087768555
Validation loss: 1.996152433015967

Epoch: 5| Step: 9
Training loss: 1.4919458627700806
Validation loss: 1.9994603985099382

Epoch: 5| Step: 10
Training loss: 1.187889814376831
Validation loss: 2.012934902662872

Epoch: 428| Step: 0
Training loss: 1.5226417779922485
Validation loss: 2.0497025200115737

Epoch: 5| Step: 1
Training loss: 2.0323822498321533
Validation loss: 1.990212860927787

Epoch: 5| Step: 2
Training loss: 1.4353654384613037
Validation loss: 2.00259716023681

Epoch: 5| Step: 3
Training loss: 1.4999001026153564
Validation loss: 2.0438320380385204

Epoch: 5| Step: 4
Training loss: 1.3969441652297974
Validation loss: 2.0173221019006546

Epoch: 5| Step: 5
Training loss: 1.9638032913208008
Validation loss: 2.008486940014747

Epoch: 5| Step: 6
Training loss: 1.1574299335479736
Validation loss: 2.0374639752090618

Epoch: 5| Step: 7
Training loss: 1.6315253973007202
Validation loss: 1.9802715034895046

Epoch: 5| Step: 8
Training loss: 1.3520443439483643
Validation loss: 2.032807127121956

Epoch: 5| Step: 9
Training loss: 1.3554362058639526
Validation loss: 1.9935406792548396

Epoch: 5| Step: 10
Training loss: 1.8138549327850342
Validation loss: 1.9953273060501262

Epoch: 429| Step: 0
Training loss: 1.7330118417739868
Validation loss: 1.963014853897915

Epoch: 5| Step: 1
Training loss: 1.4553170204162598
Validation loss: 2.0140710261560257

Epoch: 5| Step: 2
Training loss: 1.468853235244751
Validation loss: 2.0041572733591964

Epoch: 5| Step: 3
Training loss: 1.0623747110366821
Validation loss: 2.002662279272592

Epoch: 5| Step: 4
Training loss: 1.7564979791641235
Validation loss: 2.0089224256494993

Epoch: 5| Step: 5
Training loss: 1.565689206123352
Validation loss: 2.0182531674702964

Epoch: 5| Step: 6
Training loss: 1.678295373916626
Validation loss: 1.996225836456463

Epoch: 5| Step: 7
Training loss: 1.323054552078247
Validation loss: 2.008580711580092

Epoch: 5| Step: 8
Training loss: 1.552033543586731
Validation loss: 2.0084911738672564

Epoch: 5| Step: 9
Training loss: 1.791194200515747
Validation loss: 2.009271690922399

Epoch: 5| Step: 10
Training loss: 1.5244992971420288
Validation loss: 2.0321536974240373

Epoch: 430| Step: 0
Training loss: 1.3547601699829102
Validation loss: 2.0309710669261154

Epoch: 5| Step: 1
Training loss: 1.4723613262176514
Validation loss: 2.0215806576513473

Epoch: 5| Step: 2
Training loss: 2.049006938934326
Validation loss: 2.03155436823445

Epoch: 5| Step: 3
Training loss: 1.5669840574264526
Validation loss: 2.0463296341639694

Epoch: 5| Step: 4
Training loss: 0.9627544283866882
Validation loss: 2.0712531689674623

Epoch: 5| Step: 5
Training loss: 1.537810206413269
Validation loss: 2.059359860676591

Epoch: 5| Step: 6
Training loss: 2.0987250804901123
Validation loss: 2.008811602028467

Epoch: 5| Step: 7
Training loss: 1.3464444875717163
Validation loss: 2.017156699652313

Epoch: 5| Step: 8
Training loss: 1.4941998720169067
Validation loss: 2.02026605349715

Epoch: 5| Step: 9
Training loss: 1.3388664722442627
Validation loss: 2.0237058413925992

Epoch: 5| Step: 10
Training loss: 1.8472181558609009
Validation loss: 2.0352082226866033

Epoch: 431| Step: 0
Training loss: 1.6379120349884033
Validation loss: 1.9978927848159627

Epoch: 5| Step: 1
Training loss: 1.4002010822296143
Validation loss: 1.990570314468876

Epoch: 5| Step: 2
Training loss: 1.9303985834121704
Validation loss: 1.992788722438197

Epoch: 5| Step: 3
Training loss: 1.0864225625991821
Validation loss: 2.0099102797046786

Epoch: 5| Step: 4
Training loss: 1.4835729598999023
Validation loss: 1.9999568206007763

Epoch: 5| Step: 5
Training loss: 1.3970752954483032
Validation loss: 2.008016686285696

Epoch: 5| Step: 6
Training loss: 1.0467278957366943
Validation loss: 2.0453522461716847

Epoch: 5| Step: 7
Training loss: 1.8721764087677002
Validation loss: 1.989537239074707

Epoch: 5| Step: 8
Training loss: 1.685142159461975
Validation loss: 2.009020309294424

Epoch: 5| Step: 9
Training loss: 1.7020851373672485
Validation loss: 2.0223609247515277

Epoch: 5| Step: 10
Training loss: 1.8738934993743896
Validation loss: 1.9776339787308888

Epoch: 432| Step: 0
Training loss: 0.8240178823471069
Validation loss: 2.01197108017501

Epoch: 5| Step: 1
Training loss: 1.5307261943817139
Validation loss: 1.9902043163135488

Epoch: 5| Step: 2
Training loss: 1.8032362461090088
Validation loss: 1.9986914947468748

Epoch: 5| Step: 3
Training loss: 1.6833317279815674
Validation loss: 1.9935387962607927

Epoch: 5| Step: 4
Training loss: 2.2217514514923096
Validation loss: 1.9898983637491863

Epoch: 5| Step: 5
Training loss: 1.4975011348724365
Validation loss: 2.0187404232640422

Epoch: 5| Step: 6
Training loss: 0.9581806063652039
Validation loss: 1.9941566964631439

Epoch: 5| Step: 7
Training loss: 1.2558387517929077
Validation loss: 1.998932908940059

Epoch: 5| Step: 8
Training loss: 1.3195663690567017
Validation loss: 1.9965176531063613

Epoch: 5| Step: 9
Training loss: 1.7657089233398438
Validation loss: 2.000512497399443

Epoch: 5| Step: 10
Training loss: 2.163282871246338
Validation loss: 1.9944432909770677

Epoch: 433| Step: 0
Training loss: 1.3837580680847168
Validation loss: 2.0499178235248854

Epoch: 5| Step: 1
Training loss: 1.1386678218841553
Validation loss: 2.0061260115715767

Epoch: 5| Step: 2
Training loss: 2.341003894805908
Validation loss: 1.984246418040286

Epoch: 5| Step: 3
Training loss: 1.2670090198516846
Validation loss: 2.038493328197028

Epoch: 5| Step: 4
Training loss: 2.1752371788024902
Validation loss: 2.023836889574605

Epoch: 5| Step: 5
Training loss: 1.7300611734390259
Validation loss: 2.0018784076936784

Epoch: 5| Step: 6
Training loss: 1.8585288524627686
Validation loss: 2.046692696950769

Epoch: 5| Step: 7
Training loss: 1.2665897607803345
Validation loss: 1.998810128499103

Epoch: 5| Step: 8
Training loss: 1.0374802350997925
Validation loss: 2.019565938621439

Epoch: 5| Step: 9
Training loss: 1.495876669883728
Validation loss: 1.9972374618694346

Epoch: 5| Step: 10
Training loss: 1.3251516819000244
Validation loss: 2.0485097515967583

Epoch: 434| Step: 0
Training loss: 1.1894280910491943
Validation loss: 2.0106909377600557

Epoch: 5| Step: 1
Training loss: 1.1928848028182983
Validation loss: 2.0139389512359456

Epoch: 5| Step: 2
Training loss: 1.7811683416366577
Validation loss: 2.016747599006981

Epoch: 5| Step: 3
Training loss: 1.490280032157898
Validation loss: 2.0277942226779078

Epoch: 5| Step: 4
Training loss: 1.6815522909164429
Validation loss: 2.0209034463410736

Epoch: 5| Step: 5
Training loss: 1.2598354816436768
Validation loss: 1.991305879367295

Epoch: 5| Step: 6
Training loss: 2.2600929737091064
Validation loss: 2.016190416069441

Epoch: 5| Step: 7
Training loss: 1.5554345846176147
Validation loss: 2.013050686928534

Epoch: 5| Step: 8
Training loss: 1.9478495121002197
Validation loss: 2.001400360497095

Epoch: 5| Step: 9
Training loss: 1.2940123081207275
Validation loss: 2.0286086195258686

Epoch: 5| Step: 10
Training loss: 1.348188877105713
Validation loss: 2.0009963948239564

Epoch: 435| Step: 0
Training loss: 1.3362869024276733
Validation loss: 2.046356729281846

Epoch: 5| Step: 1
Training loss: 1.3251384496688843
Validation loss: 2.069831507180327

Epoch: 5| Step: 2
Training loss: 1.3494937419891357
Validation loss: 2.0324865310422835

Epoch: 5| Step: 3
Training loss: 2.051842212677002
Validation loss: 2.036661265998758

Epoch: 5| Step: 4
Training loss: 1.4504549503326416
Validation loss: 2.003511021214147

Epoch: 5| Step: 5
Training loss: 1.9302005767822266
Validation loss: 2.010807521881596

Epoch: 5| Step: 6
Training loss: 1.3880791664123535
Validation loss: 1.9621291045219666

Epoch: 5| Step: 7
Training loss: 1.2118809223175049
Validation loss: 1.9972202854771768

Epoch: 5| Step: 8
Training loss: 1.8955047130584717
Validation loss: 1.9734828254227996

Epoch: 5| Step: 9
Training loss: 1.6085376739501953
Validation loss: 1.9845795323771815

Epoch: 5| Step: 10
Training loss: 1.5764341354370117
Validation loss: 2.010177363631546

Epoch: 436| Step: 0
Training loss: 1.8508259057998657
Validation loss: 1.9846310512993925

Epoch: 5| Step: 1
Training loss: 1.367995262145996
Validation loss: 1.9863450347736318

Epoch: 5| Step: 2
Training loss: 1.1124953031539917
Validation loss: 2.001391427491301

Epoch: 5| Step: 3
Training loss: 1.7242984771728516
Validation loss: 2.041317206557079

Epoch: 5| Step: 4
Training loss: 1.7124792337417603
Validation loss: 2.048886574724669

Epoch: 5| Step: 5
Training loss: 1.943783164024353
Validation loss: 2.0059622846623903

Epoch: 5| Step: 6
Training loss: 1.5020191669464111
Validation loss: 2.037012371965634

Epoch: 5| Step: 7
Training loss: 1.586973786354065
Validation loss: 1.99194791752805

Epoch: 5| Step: 8
Training loss: 1.0577071905136108
Validation loss: 2.03752185580551

Epoch: 5| Step: 9
Training loss: 1.2642742395401
Validation loss: 1.9661009234766806

Epoch: 5| Step: 10
Training loss: 1.9737558364868164
Validation loss: 1.989856130333357

Epoch: 437| Step: 0
Training loss: 1.103585958480835
Validation loss: 2.009518092678439

Epoch: 5| Step: 1
Training loss: 1.7651355266571045
Validation loss: 2.0566036790929814

Epoch: 5| Step: 2
Training loss: 0.9263636469841003
Validation loss: 2.010639303474016

Epoch: 5| Step: 3
Training loss: 1.6976330280303955
Validation loss: 2.0273788462403

Epoch: 5| Step: 4
Training loss: 1.016083002090454
Validation loss: 2.0261959106691423

Epoch: 5| Step: 5
Training loss: 1.8117058277130127
Validation loss: 2.0134189449330813

Epoch: 5| Step: 6
Training loss: 1.5214722156524658
Validation loss: 2.0292869178197717

Epoch: 5| Step: 7
Training loss: 1.4503365755081177
Validation loss: 2.0004462606163433

Epoch: 5| Step: 8
Training loss: 1.905517339706421
Validation loss: 2.013062684766708

Epoch: 5| Step: 9
Training loss: 1.563971757888794
Validation loss: 2.0314560808161253

Epoch: 5| Step: 10
Training loss: 2.1226325035095215
Validation loss: 1.9936786236301545

Epoch: 438| Step: 0
Training loss: 1.255340576171875
Validation loss: 1.984564833743598

Epoch: 5| Step: 1
Training loss: 1.4823561906814575
Validation loss: 2.0144328827499063

Epoch: 5| Step: 2
Training loss: 1.5362818241119385
Validation loss: 2.017448945712018

Epoch: 5| Step: 3
Training loss: 1.2642675638198853
Validation loss: 2.0113428587554605

Epoch: 5| Step: 4
Training loss: 1.5527451038360596
Validation loss: 1.976308491922194

Epoch: 5| Step: 5
Training loss: 1.5674984455108643
Validation loss: 2.0142131056836856

Epoch: 5| Step: 6
Training loss: 1.1896966695785522
Validation loss: 1.98424881504428

Epoch: 5| Step: 7
Training loss: 1.644935965538025
Validation loss: 2.0211159260042253

Epoch: 5| Step: 8
Training loss: 2.3008456230163574
Validation loss: 2.0212896588028118

Epoch: 5| Step: 9
Training loss: 1.6681287288665771
Validation loss: 2.0221704872705604

Epoch: 5| Step: 10
Training loss: 1.2178891897201538
Validation loss: 2.0070415953154206

Epoch: 439| Step: 0
Training loss: 1.071448564529419
Validation loss: 2.0056617567616124

Epoch: 5| Step: 1
Training loss: 2.015495777130127
Validation loss: 2.0082670988575106

Epoch: 5| Step: 2
Training loss: 1.5284757614135742
Validation loss: 2.0263010148079164

Epoch: 5| Step: 3
Training loss: 1.2853645086288452
Validation loss: 2.0337281227111816

Epoch: 5| Step: 4
Training loss: 0.8150171041488647
Validation loss: 2.0242903078756025

Epoch: 5| Step: 5
Training loss: 1.901867151260376
Validation loss: 2.01125156751243

Epoch: 5| Step: 6
Training loss: 1.4754877090454102
Validation loss: 2.007202881638722

Epoch: 5| Step: 7
Training loss: 1.6948915719985962
Validation loss: 2.0294549465179443

Epoch: 5| Step: 8
Training loss: 1.7923446893692017
Validation loss: 1.9874151265749367

Epoch: 5| Step: 9
Training loss: 1.5846158266067505
Validation loss: 2.0021927754084268

Epoch: 5| Step: 10
Training loss: 1.5859363079071045
Validation loss: 2.018646647853236

Epoch: 440| Step: 0
Training loss: 1.3228185176849365
Validation loss: 2.0092414220174155

Epoch: 5| Step: 1
Training loss: 1.762982964515686
Validation loss: 1.990250115753502

Epoch: 5| Step: 2
Training loss: 1.6186271905899048
Validation loss: 2.001562541530978

Epoch: 5| Step: 3
Training loss: 1.8044490814208984
Validation loss: 2.028972634705164

Epoch: 5| Step: 4
Training loss: 1.3762798309326172
Validation loss: 2.048524938603883

Epoch: 5| Step: 5
Training loss: 1.7717889547348022
Validation loss: 2.0051583513136833

Epoch: 5| Step: 6
Training loss: 1.289891004562378
Validation loss: 2.0057096814596527

Epoch: 5| Step: 7
Training loss: 1.401761770248413
Validation loss: 2.024102600671912

Epoch: 5| Step: 8
Training loss: 1.57839834690094
Validation loss: 1.991941407162656

Epoch: 5| Step: 9
Training loss: 1.5185891389846802
Validation loss: 2.016000768189789

Epoch: 5| Step: 10
Training loss: 1.4078576564788818
Validation loss: 2.0007352649524646

Epoch: 441| Step: 0
Training loss: 1.0423190593719482
Validation loss: 2.0000113210370465

Epoch: 5| Step: 1
Training loss: 1.8428516387939453
Validation loss: 1.9951921996249948

Epoch: 5| Step: 2
Training loss: 1.4562695026397705
Validation loss: 1.986901339664254

Epoch: 5| Step: 3
Training loss: 1.797687292098999
Validation loss: 1.9786704894035094

Epoch: 5| Step: 4
Training loss: 1.4913753271102905
Validation loss: 1.9779450560128817

Epoch: 5| Step: 5
Training loss: 1.3638393878936768
Validation loss: 2.034501285963161

Epoch: 5| Step: 6
Training loss: 1.7439687252044678
Validation loss: 2.0243502624573244

Epoch: 5| Step: 7
Training loss: 1.4492636919021606
Validation loss: 2.0155603603650163

Epoch: 5| Step: 8
Training loss: 1.2475359439849854
Validation loss: 1.9555083705532936

Epoch: 5| Step: 9
Training loss: 1.6294806003570557
Validation loss: 2.0248351097106934

Epoch: 5| Step: 10
Training loss: 1.6318976879119873
Validation loss: 2.0160836994007068

Epoch: 442| Step: 0
Training loss: 1.421030879020691
Validation loss: 2.003477837449761

Epoch: 5| Step: 1
Training loss: 1.7096242904663086
Validation loss: 2.017486728647704

Epoch: 5| Step: 2
Training loss: 1.4664264917373657
Validation loss: 1.96961671562605

Epoch: 5| Step: 3
Training loss: 1.9866468906402588
Validation loss: 1.9631420566189675

Epoch: 5| Step: 4
Training loss: 1.2454825639724731
Validation loss: 1.9622899127262894

Epoch: 5| Step: 5
Training loss: 1.9173352718353271
Validation loss: 1.9757944665929323

Epoch: 5| Step: 6
Training loss: 1.4905956983566284
Validation loss: 2.012360139559674

Epoch: 5| Step: 7
Training loss: 1.0542199611663818
Validation loss: 1.9911783356820383

Epoch: 5| Step: 8
Training loss: 1.284905195236206
Validation loss: 1.9655665812953826

Epoch: 5| Step: 9
Training loss: 1.5250662565231323
Validation loss: 2.0001829593412337

Epoch: 5| Step: 10
Training loss: 1.8845463991165161
Validation loss: 2.012660913569953

Epoch: 443| Step: 0
Training loss: 2.07574462890625
Validation loss: 2.0131476104900403

Epoch: 5| Step: 1
Training loss: 0.9586458206176758
Validation loss: 1.9999075371731994

Epoch: 5| Step: 2
Training loss: 0.6830934286117554
Validation loss: 1.978009739229756

Epoch: 5| Step: 3
Training loss: 1.8901790380477905
Validation loss: 2.00082738425142

Epoch: 5| Step: 4
Training loss: 1.3961278200149536
Validation loss: 2.0107423515730005

Epoch: 5| Step: 5
Training loss: 1.4002879858016968
Validation loss: 2.006307427601148

Epoch: 5| Step: 6
Training loss: 1.1224581003189087
Validation loss: 1.989585163772747

Epoch: 5| Step: 7
Training loss: 2.023200273513794
Validation loss: 2.0223151458207

Epoch: 5| Step: 8
Training loss: 1.2062880992889404
Validation loss: 2.0036562822198354

Epoch: 5| Step: 9
Training loss: 2.6125128269195557
Validation loss: 1.9849649706194479

Epoch: 5| Step: 10
Training loss: 1.4923263788223267
Validation loss: 1.997467653725737

Epoch: 444| Step: 0
Training loss: 2.2308568954467773
Validation loss: 1.994788400588497

Epoch: 5| Step: 1
Training loss: 1.580798625946045
Validation loss: 2.0142366181137743

Epoch: 5| Step: 2
Training loss: 1.5838791131973267
Validation loss: 2.005308407609181

Epoch: 5| Step: 3
Training loss: 1.4579905271530151
Validation loss: 1.9726738378565798

Epoch: 5| Step: 4
Training loss: 1.2214758396148682
Validation loss: 1.9769322513252177

Epoch: 5| Step: 5
Training loss: 1.6914783716201782
Validation loss: 2.0295552874124176

Epoch: 5| Step: 6
Training loss: 1.3078809976577759
Validation loss: 2.035251126494459

Epoch: 5| Step: 7
Training loss: 1.1115484237670898
Validation loss: 2.017529523500832

Epoch: 5| Step: 8
Training loss: 1.5760496854782104
Validation loss: 1.992991219284714

Epoch: 5| Step: 9
Training loss: 1.6776649951934814
Validation loss: 2.0264170785104074

Epoch: 5| Step: 10
Training loss: 1.5304323434829712
Validation loss: 2.0308415787194365

Epoch: 445| Step: 0
Training loss: 1.8730548620224
Validation loss: 2.034369312306886

Epoch: 5| Step: 1
Training loss: 1.6094882488250732
Validation loss: 2.0156581414643155

Epoch: 5| Step: 2
Training loss: 1.7415599822998047
Validation loss: 1.9904240100614485

Epoch: 5| Step: 3
Training loss: 1.0737563371658325
Validation loss: 1.9946333836483698

Epoch: 5| Step: 4
Training loss: 1.4285013675689697
Validation loss: 1.9960629491395847

Epoch: 5| Step: 5
Training loss: 1.7135517597198486
Validation loss: 1.963571172888561

Epoch: 5| Step: 6
Training loss: 1.8043701648712158
Validation loss: 2.018660645331106

Epoch: 5| Step: 7
Training loss: 1.0329467058181763
Validation loss: 1.997815127013832

Epoch: 5| Step: 8
Training loss: 1.3775196075439453
Validation loss: 1.9902275044430968

Epoch: 5| Step: 9
Training loss: 1.7022634744644165
Validation loss: 1.9974153631476945

Epoch: 5| Step: 10
Training loss: 1.4255239963531494
Validation loss: 1.9586695189117103

Epoch: 446| Step: 0
Training loss: 1.6925379037857056
Validation loss: 1.976729013586557

Epoch: 5| Step: 1
Training loss: 1.4188404083251953
Validation loss: 1.9923828455709642

Epoch: 5| Step: 2
Training loss: 1.6617523431777954
Validation loss: 1.9658548255120554

Epoch: 5| Step: 3
Training loss: 0.8851451873779297
Validation loss: 1.970623698285831

Epoch: 5| Step: 4
Training loss: 1.2089022397994995
Validation loss: 2.00669752910573

Epoch: 5| Step: 5
Training loss: 1.8929201364517212
Validation loss: 1.985875218145309

Epoch: 5| Step: 6
Training loss: 1.4011322259902954
Validation loss: 1.9913632331355926

Epoch: 5| Step: 7
Training loss: 1.5852024555206299
Validation loss: 2.013944584836242

Epoch: 5| Step: 8
Training loss: 1.8067079782485962
Validation loss: 1.9818748274157125

Epoch: 5| Step: 9
Training loss: 1.376165747642517
Validation loss: 1.991510054116608

Epoch: 5| Step: 10
Training loss: 1.811948299407959
Validation loss: 2.0094186708491337

Epoch: 447| Step: 0
Training loss: 1.0523457527160645
Validation loss: 2.0024416292867353

Epoch: 5| Step: 1
Training loss: 1.6662561893463135
Validation loss: 2.0411428200301303

Epoch: 5| Step: 2
Training loss: 1.422443151473999
Validation loss: 2.004819308557818

Epoch: 5| Step: 3
Training loss: 1.8925325870513916
Validation loss: 1.9740294538518435

Epoch: 5| Step: 4
Training loss: 1.6284348964691162
Validation loss: 2.00095784535972

Epoch: 5| Step: 5
Training loss: 1.5315985679626465
Validation loss: 2.02879745985872

Epoch: 5| Step: 6
Training loss: 0.9224028587341309
Validation loss: 1.9980981221763037

Epoch: 5| Step: 7
Training loss: 1.4527853727340698
Validation loss: 1.9498230898252098

Epoch: 5| Step: 8
Training loss: 1.5228040218353271
Validation loss: 1.9494863863914245

Epoch: 5| Step: 9
Training loss: 1.9219681024551392
Validation loss: 2.0050209735029485

Epoch: 5| Step: 10
Training loss: 1.6444956064224243
Validation loss: 1.97662946485704

Epoch: 448| Step: 0
Training loss: 1.9931011199951172
Validation loss: 1.9846566095147082

Epoch: 5| Step: 1
Training loss: 1.542737603187561
Validation loss: 1.9558011357502272

Epoch: 5| Step: 2
Training loss: 1.212110161781311
Validation loss: 2.0409556281182075

Epoch: 5| Step: 3
Training loss: 1.266947865486145
Validation loss: 2.0034380958926294

Epoch: 5| Step: 4
Training loss: 1.7085416316986084
Validation loss: 2.018783066862373

Epoch: 5| Step: 5
Training loss: 1.6384986639022827
Validation loss: 1.9938469509924612

Epoch: 5| Step: 6
Training loss: 1.8436203002929688
Validation loss: 1.9942161088348718

Epoch: 5| Step: 7
Training loss: 1.6193945407867432
Validation loss: 1.9840081058522707

Epoch: 5| Step: 8
Training loss: 1.4893490076065063
Validation loss: 2.009528135740629

Epoch: 5| Step: 9
Training loss: 1.6475822925567627
Validation loss: 1.9914142393296765

Epoch: 5| Step: 10
Training loss: 0.6707978844642639
Validation loss: 2.0089705836388374

Epoch: 449| Step: 0
Training loss: 2.079874038696289
Validation loss: 1.9819932906858382

Epoch: 5| Step: 1
Training loss: 1.977150321006775
Validation loss: 2.0138010286515757

Epoch: 5| Step: 2
Training loss: 1.6518628597259521
Validation loss: 2.0097140112230854

Epoch: 5| Step: 3
Training loss: 1.235051155090332
Validation loss: 1.9903692994066464

Epoch: 5| Step: 4
Training loss: 1.7212679386138916
Validation loss: 2.0149594417182346

Epoch: 5| Step: 5
Training loss: 1.406995177268982
Validation loss: 1.9784002201531523

Epoch: 5| Step: 6
Training loss: 1.3091894388198853
Validation loss: 1.9937239462329495

Epoch: 5| Step: 7
Training loss: 0.7921247482299805
Validation loss: 1.98596280108216

Epoch: 5| Step: 8
Training loss: 1.4194532632827759
Validation loss: 1.9995636145273845

Epoch: 5| Step: 9
Training loss: 1.4313493967056274
Validation loss: 1.998775798787353

Epoch: 5| Step: 10
Training loss: 1.4317747354507446
Validation loss: 1.9802074868191955

Epoch: 450| Step: 0
Training loss: 1.145531415939331
Validation loss: 1.986699899037679

Epoch: 5| Step: 1
Training loss: 1.5894396305084229
Validation loss: 1.9830775043015838

Epoch: 5| Step: 2
Training loss: 1.535827398300171
Validation loss: 2.025228160683827

Epoch: 5| Step: 3
Training loss: 1.5177175998687744
Validation loss: 1.9798402837527695

Epoch: 5| Step: 4
Training loss: 1.9583324193954468
Validation loss: 1.9948402950840611

Epoch: 5| Step: 5
Training loss: 1.5000590085983276
Validation loss: 1.9651516381130423

Epoch: 5| Step: 6
Training loss: 1.8372961282730103
Validation loss: 1.993664659479613

Epoch: 5| Step: 7
Training loss: 1.3617539405822754
Validation loss: 1.9709528056524133

Epoch: 5| Step: 8
Training loss: 1.6387531757354736
Validation loss: 1.9718059160376107

Epoch: 5| Step: 9
Training loss: 1.4741389751434326
Validation loss: 1.975110415489443

Epoch: 5| Step: 10
Training loss: 1.1407443284988403
Validation loss: 1.9971431019485637

Epoch: 451| Step: 0
Training loss: 1.1893600225448608
Validation loss: 1.9742241239035

Epoch: 5| Step: 1
Training loss: 1.311964750289917
Validation loss: 1.9774244972454604

Epoch: 5| Step: 2
Training loss: 1.4723106622695923
Validation loss: 1.9869660767175819

Epoch: 5| Step: 3
Training loss: 1.2273061275482178
Validation loss: 1.9791674293497556

Epoch: 5| Step: 4
Training loss: 1.8068268299102783
Validation loss: 2.002804333163846

Epoch: 5| Step: 5
Training loss: 1.5195958614349365
Validation loss: 2.009991092066611

Epoch: 5| Step: 6
Training loss: 1.1345036029815674
Validation loss: 1.9939114919272802

Epoch: 5| Step: 7
Training loss: 2.1714835166931152
Validation loss: 2.017430095262425

Epoch: 5| Step: 8
Training loss: 1.6802756786346436
Validation loss: 2.009404120906707

Epoch: 5| Step: 9
Training loss: 1.7277120351791382
Validation loss: 2.0105813075137395

Epoch: 5| Step: 10
Training loss: 1.3574161529541016
Validation loss: 2.019723332056435

Epoch: 452| Step: 0
Training loss: 2.071913242340088
Validation loss: 2.026314676448863

Epoch: 5| Step: 1
Training loss: 1.7741539478302002
Validation loss: 2.034791799001796

Epoch: 5| Step: 2
Training loss: 1.5655771493911743
Validation loss: 2.00745802797297

Epoch: 5| Step: 3
Training loss: 1.3906350135803223
Validation loss: 2.011046653152794

Epoch: 5| Step: 4
Training loss: 1.4956623315811157
Validation loss: 1.9941432194043232

Epoch: 5| Step: 5
Training loss: 1.6302680969238281
Validation loss: 1.976456149931877

Epoch: 5| Step: 6
Training loss: 1.1380853652954102
Validation loss: 1.9965926652313561

Epoch: 5| Step: 7
Training loss: 0.9686346054077148
Validation loss: 2.006564441547599

Epoch: 5| Step: 8
Training loss: 1.5000909566879272
Validation loss: 1.958909688457366

Epoch: 5| Step: 9
Training loss: 1.478846788406372
Validation loss: 2.0053285937155447

Epoch: 5| Step: 10
Training loss: 1.8391270637512207
Validation loss: 1.9636185438402238

Epoch: 453| Step: 0
Training loss: 1.7111924886703491
Validation loss: 2.004115129029879

Epoch: 5| Step: 1
Training loss: 1.415155053138733
Validation loss: 1.9822350881432975

Epoch: 5| Step: 2
Training loss: 1.5306024551391602
Validation loss: 1.989088467372361

Epoch: 5| Step: 3
Training loss: 1.044740080833435
Validation loss: 2.0145185083471318

Epoch: 5| Step: 4
Training loss: 2.054605007171631
Validation loss: 2.0138519451182377

Epoch: 5| Step: 5
Training loss: 1.665589690208435
Validation loss: 2.034661134084066

Epoch: 5| Step: 6
Training loss: 1.4856975078582764
Validation loss: 2.0075503626177387

Epoch: 5| Step: 7
Training loss: 1.5414292812347412
Validation loss: 1.9869470237403788

Epoch: 5| Step: 8
Training loss: 1.6499383449554443
Validation loss: 2.0107484222740255

Epoch: 5| Step: 9
Training loss: 1.046740174293518
Validation loss: 2.0135595337037118

Epoch: 5| Step: 10
Training loss: 1.4815490245819092
Validation loss: 1.9940735575973347

Epoch: 454| Step: 0
Training loss: 1.3504544496536255
Validation loss: 1.9995304692176081

Epoch: 5| Step: 1
Training loss: 1.6818987131118774
Validation loss: 1.9860974639974616

Epoch: 5| Step: 2
Training loss: 1.5278961658477783
Validation loss: 1.9896708534609886

Epoch: 5| Step: 3
Training loss: 1.6518421173095703
Validation loss: 2.00761519580759

Epoch: 5| Step: 4
Training loss: 2.260216474533081
Validation loss: 1.9603548793382541

Epoch: 5| Step: 5
Training loss: 1.3512766361236572
Validation loss: 1.9876887388126825

Epoch: 5| Step: 6
Training loss: 1.180548906326294
Validation loss: 1.999145250166616

Epoch: 5| Step: 7
Training loss: 1.5092438459396362
Validation loss: 1.9920832726263231

Epoch: 5| Step: 8
Training loss: 1.3363373279571533
Validation loss: 2.0218783937474734

Epoch: 5| Step: 9
Training loss: 1.532494306564331
Validation loss: 1.9791651182277228

Epoch: 5| Step: 10
Training loss: 1.423463225364685
Validation loss: 2.0034497873757475

Epoch: 455| Step: 0
Training loss: 1.3516075611114502
Validation loss: 1.9639346317578388

Epoch: 5| Step: 1
Training loss: 1.1431386470794678
Validation loss: 2.010913669422109

Epoch: 5| Step: 2
Training loss: 1.731614112854004
Validation loss: 1.9606591296452347

Epoch: 5| Step: 3
Training loss: 1.3922841548919678
Validation loss: 2.006756031385032

Epoch: 5| Step: 4
Training loss: 1.4591463804244995
Validation loss: 2.0029392524432112

Epoch: 5| Step: 5
Training loss: 1.353266954421997
Validation loss: 2.0148909784132436

Epoch: 5| Step: 6
Training loss: 2.177401065826416
Validation loss: 2.008515557935161

Epoch: 5| Step: 7
Training loss: 1.304711103439331
Validation loss: 2.0151312658863683

Epoch: 5| Step: 8
Training loss: 1.4195327758789062
Validation loss: 2.0219024304420716

Epoch: 5| Step: 9
Training loss: 1.8099775314331055
Validation loss: 2.0217286514979538

Epoch: 5| Step: 10
Training loss: 1.455749750137329
Validation loss: 2.0188740889231362

Epoch: 456| Step: 0
Training loss: 1.606348991394043
Validation loss: 1.9948244428121915

Epoch: 5| Step: 1
Training loss: 1.4262443780899048
Validation loss: 2.0149372610994565

Epoch: 5| Step: 2
Training loss: 1.4126460552215576
Validation loss: 1.979963779449463

Epoch: 5| Step: 3
Training loss: 1.3456310033798218
Validation loss: 1.9899280442986438

Epoch: 5| Step: 4
Training loss: 1.3170541524887085
Validation loss: 2.008572592530199

Epoch: 5| Step: 5
Training loss: 1.5499417781829834
Validation loss: 2.000761846060394

Epoch: 5| Step: 6
Training loss: 1.4431816339492798
Validation loss: 1.985590196424915

Epoch: 5| Step: 7
Training loss: 1.339133620262146
Validation loss: 1.969287331386279

Epoch: 5| Step: 8
Training loss: 2.0125880241394043
Validation loss: 1.9644853838028447

Epoch: 5| Step: 9
Training loss: 2.164762020111084
Validation loss: 1.9929011201345792

Epoch: 5| Step: 10
Training loss: 1.0132479667663574
Validation loss: 1.9689039261110368

Epoch: 457| Step: 0
Training loss: 1.8584266901016235
Validation loss: 1.9764286036132483

Epoch: 5| Step: 1
Training loss: 1.028719186782837
Validation loss: 1.9817348116187639

Epoch: 5| Step: 2
Training loss: 1.6466678380966187
Validation loss: 2.0098226006313036

Epoch: 5| Step: 3
Training loss: 1.0841569900512695
Validation loss: 1.9834808585464314

Epoch: 5| Step: 4
Training loss: 1.306981086730957
Validation loss: 1.9805786148194344

Epoch: 5| Step: 5
Training loss: 2.0556485652923584
Validation loss: 1.9730160620904738

Epoch: 5| Step: 6
Training loss: 1.6442012786865234
Validation loss: 1.980125581064532

Epoch: 5| Step: 7
Training loss: 1.2038581371307373
Validation loss: 1.9883674421618063

Epoch: 5| Step: 8
Training loss: 1.6137349605560303
Validation loss: 2.029113902199653

Epoch: 5| Step: 9
Training loss: 1.4684579372406006
Validation loss: 2.011575404033866

Epoch: 5| Step: 10
Training loss: 1.4508934020996094
Validation loss: 1.9634648215386175

Epoch: 458| Step: 0
Training loss: 1.048272967338562
Validation loss: 1.9927050734079013

Epoch: 5| Step: 1
Training loss: 1.7276595830917358
Validation loss: 2.009611386124806

Epoch: 5| Step: 2
Training loss: 1.7708308696746826
Validation loss: 1.9944992167975313

Epoch: 5| Step: 3
Training loss: 0.5846872329711914
Validation loss: 1.9790466344484718

Epoch: 5| Step: 4
Training loss: 1.6390787363052368
Validation loss: 1.992101227083514

Epoch: 5| Step: 5
Training loss: 1.6032142639160156
Validation loss: 1.9919908828632806

Epoch: 5| Step: 6
Training loss: 1.5885224342346191
Validation loss: 1.9816614068964475

Epoch: 5| Step: 7
Training loss: 1.4376211166381836
Validation loss: 1.969218369453184

Epoch: 5| Step: 8
Training loss: 1.292036771774292
Validation loss: 1.979222273313871

Epoch: 5| Step: 9
Training loss: 1.8113887310028076
Validation loss: 1.9791619739224833

Epoch: 5| Step: 10
Training loss: 2.2020909786224365
Validation loss: 1.9515778710765224

Epoch: 459| Step: 0
Training loss: 1.0288817882537842
Validation loss: 1.9486146050114785

Epoch: 5| Step: 1
Training loss: 1.5770407915115356
Validation loss: 1.9813613507055468

Epoch: 5| Step: 2
Training loss: 0.9811756014823914
Validation loss: 1.9677776969889158

Epoch: 5| Step: 3
Training loss: 1.3185583353042603
Validation loss: 2.0096889311267483

Epoch: 5| Step: 4
Training loss: 1.7788985967636108
Validation loss: 2.0013674625786404

Epoch: 5| Step: 5
Training loss: 1.7157100439071655
Validation loss: 2.00351281063531

Epoch: 5| Step: 6
Training loss: 1.5873050689697266
Validation loss: 2.0370727995390534

Epoch: 5| Step: 7
Training loss: 1.6720117330551147
Validation loss: 1.9948591109245055

Epoch: 5| Step: 8
Training loss: 1.3067362308502197
Validation loss: 2.0300855944233556

Epoch: 5| Step: 9
Training loss: 1.8832439184188843
Validation loss: 2.001364507982808

Epoch: 5| Step: 10
Training loss: 2.1513137817382812
Validation loss: 1.975283048486197

Epoch: 460| Step: 0
Training loss: 1.8370319604873657
Validation loss: 2.0011826843343754

Epoch: 5| Step: 1
Training loss: 1.1970826387405396
Validation loss: 1.9714042204682545

Epoch: 5| Step: 2
Training loss: 1.3047927618026733
Validation loss: 2.0192884014498804

Epoch: 5| Step: 3
Training loss: 1.409995675086975
Validation loss: 2.027743413884153

Epoch: 5| Step: 4
Training loss: 1.3372468948364258
Validation loss: 1.998389401743489

Epoch: 5| Step: 5
Training loss: 1.9249508380889893
Validation loss: 1.9847433323501258

Epoch: 5| Step: 6
Training loss: 1.5981252193450928
Validation loss: 2.0056626053266626

Epoch: 5| Step: 7
Training loss: 1.421737551689148
Validation loss: 2.0050477545748473

Epoch: 5| Step: 8
Training loss: 1.5015032291412354
Validation loss: 2.0107010026131906

Epoch: 5| Step: 9
Training loss: 1.4616832733154297
Validation loss: 2.006261420506303

Epoch: 5| Step: 10
Training loss: 1.191771388053894
Validation loss: 2.017074845170462

Epoch: 461| Step: 0
Training loss: 1.0057560205459595
Validation loss: 1.995293277566151

Epoch: 5| Step: 1
Training loss: 2.0157063007354736
Validation loss: 2.045227545563893

Epoch: 5| Step: 2
Training loss: 1.4295194149017334
Validation loss: 1.9978988042441748

Epoch: 5| Step: 3
Training loss: 1.2086775302886963
Validation loss: 2.001733132587966

Epoch: 5| Step: 4
Training loss: 1.514366865158081
Validation loss: 1.9664575899800947

Epoch: 5| Step: 5
Training loss: 1.335724115371704
Validation loss: 1.9873378276824951

Epoch: 5| Step: 6
Training loss: 2.0692882537841797
Validation loss: 1.9827217363542127

Epoch: 5| Step: 7
Training loss: 2.0529873371124268
Validation loss: 1.9680026949092906

Epoch: 5| Step: 8
Training loss: 1.2650219202041626
Validation loss: 1.9614067462182814

Epoch: 5| Step: 9
Training loss: 1.2195556163787842
Validation loss: 2.0169217676244755

Epoch: 5| Step: 10
Training loss: 1.494835615158081
Validation loss: 1.9981895723650533

Epoch: 462| Step: 0
Training loss: 1.2949259281158447
Validation loss: 2.0139272597528275

Epoch: 5| Step: 1
Training loss: 1.0377565622329712
Validation loss: 1.9523254017676077

Epoch: 5| Step: 2
Training loss: 1.344151258468628
Validation loss: 2.0111606826064405

Epoch: 5| Step: 3
Training loss: 1.9111789464950562
Validation loss: 2.0152119641662924

Epoch: 5| Step: 4
Training loss: 2.006014347076416
Validation loss: 1.98230218502783

Epoch: 5| Step: 5
Training loss: 1.4503796100616455
Validation loss: 1.9956608677423129

Epoch: 5| Step: 6
Training loss: 1.4850664138793945
Validation loss: 2.031105245313337

Epoch: 5| Step: 7
Training loss: 1.4150131940841675
Validation loss: 1.9749764832117225

Epoch: 5| Step: 8
Training loss: 1.492553472518921
Validation loss: 2.002030490547098

Epoch: 5| Step: 9
Training loss: 1.2249785661697388
Validation loss: 2.0038874098049697

Epoch: 5| Step: 10
Training loss: 1.7170885801315308
Validation loss: 2.0051804101595314

Epoch: 463| Step: 0
Training loss: 1.29580557346344
Validation loss: 1.9639039372885099

Epoch: 5| Step: 1
Training loss: 1.7897590398788452
Validation loss: 2.0076659251284856

Epoch: 5| Step: 2
Training loss: 1.8629411458969116
Validation loss: 1.9942001206900484

Epoch: 5| Step: 3
Training loss: 1.308359146118164
Validation loss: 2.0178340763174076

Epoch: 5| Step: 4
Training loss: 1.4370708465576172
Validation loss: 1.9883207364748883

Epoch: 5| Step: 5
Training loss: 1.2270729541778564
Validation loss: 2.0246643199715564

Epoch: 5| Step: 6
Training loss: 1.5373342037200928
Validation loss: 1.9995579334997362

Epoch: 5| Step: 7
Training loss: 1.8771684169769287
Validation loss: 1.968497359624473

Epoch: 5| Step: 8
Training loss: 1.7246456146240234
Validation loss: 1.9639481165075814

Epoch: 5| Step: 9
Training loss: 1.4461654424667358
Validation loss: 2.0028512106146863

Epoch: 5| Step: 10
Training loss: 1.0491061210632324
Validation loss: 1.9527761654187274

Epoch: 464| Step: 0
Training loss: 1.2128970623016357
Validation loss: 1.9990815167785974

Epoch: 5| Step: 1
Training loss: 2.312218427658081
Validation loss: 1.968194043764504

Epoch: 5| Step: 2
Training loss: 1.1070966720581055
Validation loss: 1.9818483655170729

Epoch: 5| Step: 3
Training loss: 1.184230923652649
Validation loss: 1.9870869959554365

Epoch: 5| Step: 4
Training loss: 1.2465670108795166
Validation loss: 2.0270448141200568

Epoch: 5| Step: 5
Training loss: 1.4855343103408813
Validation loss: 1.972435579505018

Epoch: 5| Step: 6
Training loss: 1.741835594177246
Validation loss: 2.027599767972064

Epoch: 5| Step: 7
Training loss: 1.3708670139312744
Validation loss: 2.0268130199883574

Epoch: 5| Step: 8
Training loss: 1.9622634649276733
Validation loss: 1.998279256205405

Epoch: 5| Step: 9
Training loss: 1.3971604108810425
Validation loss: 2.0223937521698656

Epoch: 5| Step: 10
Training loss: 1.315853238105774
Validation loss: 2.010228592862365

Epoch: 465| Step: 0
Training loss: 2.013242244720459
Validation loss: 1.995589243468418

Epoch: 5| Step: 1
Training loss: 1.7278972864151
Validation loss: 1.9915040334065754

Epoch: 5| Step: 2
Training loss: 2.1406333446502686
Validation loss: 2.004144355814944

Epoch: 5| Step: 3
Training loss: 1.4027076959609985
Validation loss: 1.9927611325376777

Epoch: 5| Step: 4
Training loss: 1.2432126998901367
Validation loss: 1.980617518066078

Epoch: 5| Step: 5
Training loss: 0.6978558897972107
Validation loss: 1.9990310271581013

Epoch: 5| Step: 6
Training loss: 1.7917598485946655
Validation loss: 2.009746792495892

Epoch: 5| Step: 7
Training loss: 1.116849660873413
Validation loss: 1.984613710834134

Epoch: 5| Step: 8
Training loss: 1.6588335037231445
Validation loss: 1.9943907196803758

Epoch: 5| Step: 9
Training loss: 1.4994325637817383
Validation loss: 1.9965803905199933

Epoch: 5| Step: 10
Training loss: 1.1555945873260498
Validation loss: 1.9930630281407347

Epoch: 466| Step: 0
Training loss: 1.5341860055923462
Validation loss: 2.003054852126747

Epoch: 5| Step: 1
Training loss: 1.3396042585372925
Validation loss: 1.9465039417307863

Epoch: 5| Step: 2
Training loss: 1.628694772720337
Validation loss: 1.9975536472053939

Epoch: 5| Step: 3
Training loss: 2.0418810844421387
Validation loss: 2.008404883005286

Epoch: 5| Step: 4
Training loss: 1.3947279453277588
Validation loss: 1.9695886693974978

Epoch: 5| Step: 5
Training loss: 1.5175455808639526
Validation loss: 1.9902428529595817

Epoch: 5| Step: 6
Training loss: 1.4437787532806396
Validation loss: 1.9629062657715173

Epoch: 5| Step: 7
Training loss: 1.4062364101409912
Validation loss: 1.9669949854573896

Epoch: 5| Step: 8
Training loss: 1.2201982736587524
Validation loss: 1.9689651099584435

Epoch: 5| Step: 9
Training loss: 1.3525097370147705
Validation loss: 1.9848921683526808

Epoch: 5| Step: 10
Training loss: 1.3736073970794678
Validation loss: 1.9863496659904398

Epoch: 467| Step: 0
Training loss: 1.3934814929962158
Validation loss: 1.9985910448976743

Epoch: 5| Step: 1
Training loss: 1.4421908855438232
Validation loss: 2.0142691186679307

Epoch: 5| Step: 2
Training loss: 1.646424651145935
Validation loss: 1.9918421981155232

Epoch: 5| Step: 3
Training loss: 1.2658884525299072
Validation loss: 1.9832874472423265

Epoch: 5| Step: 4
Training loss: 1.5355751514434814
Validation loss: 2.0036431627888835

Epoch: 5| Step: 5
Training loss: 1.6590566635131836
Validation loss: 1.9975412250846944

Epoch: 5| Step: 6
Training loss: 1.5442248582839966
Validation loss: 1.991052899309384

Epoch: 5| Step: 7
Training loss: 1.3305466175079346
Validation loss: 1.9758212848376202

Epoch: 5| Step: 8
Training loss: 1.413050651550293
Validation loss: 1.9943591599823327

Epoch: 5| Step: 9
Training loss: 1.6365783214569092
Validation loss: 1.9935251410289476

Epoch: 5| Step: 10
Training loss: 1.5706140995025635
Validation loss: 1.9723301882384925

Epoch: 468| Step: 0
Training loss: 1.2292242050170898
Validation loss: 2.0062600463949223

Epoch: 5| Step: 1
Training loss: 1.911860704421997
Validation loss: 1.9869887393007997

Epoch: 5| Step: 2
Training loss: 1.648764967918396
Validation loss: 2.035306135813395

Epoch: 5| Step: 3
Training loss: 1.1079647541046143
Validation loss: 1.9796001757344892

Epoch: 5| Step: 4
Training loss: 2.0580430030822754
Validation loss: 1.9582581827717442

Epoch: 5| Step: 5
Training loss: 1.1534416675567627
Validation loss: 1.9729336743713708

Epoch: 5| Step: 6
Training loss: 1.2672425508499146
Validation loss: 1.988787269079557

Epoch: 5| Step: 7
Training loss: 1.6248191595077515
Validation loss: 1.9791222080107658

Epoch: 5| Step: 8
Training loss: 1.7697722911834717
Validation loss: 1.9943659933664466

Epoch: 5| Step: 9
Training loss: 1.2527797222137451
Validation loss: 2.001138625606414

Epoch: 5| Step: 10
Training loss: 1.5039281845092773
Validation loss: 1.9769215429982832

Epoch: 469| Step: 0
Training loss: 1.848175048828125
Validation loss: 2.012296530508226

Epoch: 5| Step: 1
Training loss: 1.7922141551971436
Validation loss: 1.9986496433135001

Epoch: 5| Step: 2
Training loss: 1.2672436237335205
Validation loss: 1.9809531857890468

Epoch: 5| Step: 3
Training loss: 1.3136273622512817
Validation loss: 1.9940679586061867

Epoch: 5| Step: 4
Training loss: 1.384112000465393
Validation loss: 1.9848054737173102

Epoch: 5| Step: 5
Training loss: 1.8260667324066162
Validation loss: 1.9959462663178802

Epoch: 5| Step: 6
Training loss: 1.6421703100204468
Validation loss: 1.968889594078064

Epoch: 5| Step: 7
Training loss: 1.4023792743682861
Validation loss: 1.9996274261064426

Epoch: 5| Step: 8
Training loss: 1.4678962230682373
Validation loss: 1.9989415112362112

Epoch: 5| Step: 9
Training loss: 1.476586103439331
Validation loss: 1.976726298691124

Epoch: 5| Step: 10
Training loss: 0.997418224811554
Validation loss: 2.014878316592145

Epoch: 470| Step: 0
Training loss: 1.4915167093276978
Validation loss: 2.014653895490913

Epoch: 5| Step: 1
Training loss: 1.3554069995880127
Validation loss: 2.003424075341994

Epoch: 5| Step: 2
Training loss: 1.6189823150634766
Validation loss: 1.9906896891132477

Epoch: 5| Step: 3
Training loss: 1.9768810272216797
Validation loss: 2.00156763035764

Epoch: 5| Step: 4
Training loss: 1.6137373447418213
Validation loss: 2.008328345514113

Epoch: 5| Step: 5
Training loss: 1.1096605062484741
Validation loss: 2.0035836850443194

Epoch: 5| Step: 6
Training loss: 1.4967401027679443
Validation loss: 1.9866631441218878

Epoch: 5| Step: 7
Training loss: 1.8042428493499756
Validation loss: 2.0084136045107277

Epoch: 5| Step: 8
Training loss: 1.6194813251495361
Validation loss: 2.020912854902206

Epoch: 5| Step: 9
Training loss: 0.8888663053512573
Validation loss: 2.0104058993759977

Epoch: 5| Step: 10
Training loss: 1.2813931703567505
Validation loss: 1.9692314106930968

Epoch: 471| Step: 0
Training loss: 1.457924485206604
Validation loss: 1.9990576954298123

Epoch: 5| Step: 1
Training loss: 1.4926263093948364
Validation loss: 2.0059961234369585

Epoch: 5| Step: 2
Training loss: 1.415822982788086
Validation loss: 1.9830841736126972

Epoch: 5| Step: 3
Training loss: 1.5225111246109009
Validation loss: 2.0118927007080405

Epoch: 5| Step: 4
Training loss: 1.5085055828094482
Validation loss: 2.0035913951935305

Epoch: 5| Step: 5
Training loss: 1.2856143712997437
Validation loss: 2.0176425031436387

Epoch: 5| Step: 6
Training loss: 1.6676642894744873
Validation loss: 2.0188399617389967

Epoch: 5| Step: 7
Training loss: 1.4794238805770874
Validation loss: 2.0163251558939614

Epoch: 5| Step: 8
Training loss: 1.6346614360809326
Validation loss: 1.9989274881219352

Epoch: 5| Step: 9
Training loss: 1.5124247074127197
Validation loss: 1.9873223189384706

Epoch: 5| Step: 10
Training loss: 1.4034467935562134
Validation loss: 2.013128895913401

Epoch: 472| Step: 0
Training loss: 1.288161039352417
Validation loss: 1.9797327159553446

Epoch: 5| Step: 1
Training loss: 1.3042688369750977
Validation loss: 1.9976958087695542

Epoch: 5| Step: 2
Training loss: 0.8990093469619751
Validation loss: 1.9636852100331297

Epoch: 5| Step: 3
Training loss: 1.7538642883300781
Validation loss: 1.9890845706385951

Epoch: 5| Step: 4
Training loss: 1.3095663785934448
Validation loss: 1.9649147115727907

Epoch: 5| Step: 5
Training loss: 1.6576303243637085
Validation loss: 1.969851723281286

Epoch: 5| Step: 6
Training loss: 2.0629661083221436
Validation loss: 2.0017409837374123

Epoch: 5| Step: 7
Training loss: 1.1930233240127563
Validation loss: 1.9694333486659552

Epoch: 5| Step: 8
Training loss: 1.5215797424316406
Validation loss: 2.023333796890833

Epoch: 5| Step: 9
Training loss: 1.2405589818954468
Validation loss: 1.9714225915170485

Epoch: 5| Step: 10
Training loss: 1.7994192838668823
Validation loss: 2.0165774617143857

Epoch: 473| Step: 0
Training loss: 1.4317071437835693
Validation loss: 1.9603650134096864

Epoch: 5| Step: 1
Training loss: 1.7147789001464844
Validation loss: 1.9884082181479341

Epoch: 5| Step: 2
Training loss: 1.6187999248504639
Validation loss: 2.017059877354612

Epoch: 5| Step: 3
Training loss: 1.6480792760849
Validation loss: 1.9959166588321808

Epoch: 5| Step: 4
Training loss: 1.6261122226715088
Validation loss: 2.0002328875244304

Epoch: 5| Step: 5
Training loss: 1.1435511112213135
Validation loss: 1.9755893240692795

Epoch: 5| Step: 6
Training loss: 1.4905710220336914
Validation loss: 1.9739799602057344

Epoch: 5| Step: 7
Training loss: 1.529041051864624
Validation loss: 2.0306400329835954

Epoch: 5| Step: 8
Training loss: 1.4534715414047241
Validation loss: 1.986295016863013

Epoch: 5| Step: 9
Training loss: 1.5571155548095703
Validation loss: 1.9756426349762948

Epoch: 5| Step: 10
Training loss: 1.1064543724060059
Validation loss: 1.963537569968931

Epoch: 474| Step: 0
Training loss: 1.6903162002563477
Validation loss: 2.005158101358721

Epoch: 5| Step: 1
Training loss: 1.1967012882232666
Validation loss: 2.004010268436965

Epoch: 5| Step: 2
Training loss: 1.4114453792572021
Validation loss: 1.970642848681378

Epoch: 5| Step: 3
Training loss: 1.2577344179153442
Validation loss: 2.0006509519392446

Epoch: 5| Step: 4
Training loss: 1.5652515888214111
Validation loss: 2.0033442807453934

Epoch: 5| Step: 5
Training loss: 1.278877854347229
Validation loss: 1.9956288696617208

Epoch: 5| Step: 6
Training loss: 1.8198379278182983
Validation loss: 1.995697464994205

Epoch: 5| Step: 7
Training loss: 1.406554937362671
Validation loss: 2.009676651288104

Epoch: 5| Step: 8
Training loss: 1.789804458618164
Validation loss: 2.00574077329328

Epoch: 5| Step: 9
Training loss: 1.5395702123641968
Validation loss: 2.0053711770683207

Epoch: 5| Step: 10
Training loss: 1.0075087547302246
Validation loss: 1.9835945149903655

Epoch: 475| Step: 0
Training loss: 1.5344138145446777
Validation loss: 1.9911239480459562

Epoch: 5| Step: 1
Training loss: 1.7860777378082275
Validation loss: 1.9917460513371292

Epoch: 5| Step: 2
Training loss: 1.6313527822494507
Validation loss: 2.0121112356903734

Epoch: 5| Step: 3
Training loss: 1.7118192911148071
Validation loss: 1.9755331085574241

Epoch: 5| Step: 4
Training loss: 1.2726155519485474
Validation loss: 2.034019121559717

Epoch: 5| Step: 5
Training loss: 1.7764317989349365
Validation loss: 2.006528277550974

Epoch: 5| Step: 6
Training loss: 1.2675902843475342
Validation loss: 1.9790644716191035

Epoch: 5| Step: 7
Training loss: 1.5987151861190796
Validation loss: 1.9904245663714666

Epoch: 5| Step: 8
Training loss: 1.5878627300262451
Validation loss: 2.0196831533985753

Epoch: 5| Step: 9
Training loss: 0.9858623743057251
Validation loss: 1.998524106958861

Epoch: 5| Step: 10
Training loss: 1.2100125551223755
Validation loss: 1.9413362241560412

Epoch: 476| Step: 0
Training loss: 1.4154475927352905
Validation loss: 1.9588661040029218

Epoch: 5| Step: 1
Training loss: 1.2480394840240479
Validation loss: 1.9902031165297314

Epoch: 5| Step: 2
Training loss: 1.7511014938354492
Validation loss: 1.9753289286808302

Epoch: 5| Step: 3
Training loss: 1.7334381341934204
Validation loss: 1.9614206437141664

Epoch: 5| Step: 4
Training loss: 1.3292075395584106
Validation loss: 1.9755985185664187

Epoch: 5| Step: 5
Training loss: 1.1076055765151978
Validation loss: 1.9610558709790629

Epoch: 5| Step: 6
Training loss: 1.4974219799041748
Validation loss: 1.9737254137633948

Epoch: 5| Step: 7
Training loss: 1.2353136539459229
Validation loss: 1.9859129754445886

Epoch: 5| Step: 8
Training loss: 1.3827489614486694
Validation loss: 1.9584109424262919

Epoch: 5| Step: 9
Training loss: 1.71051025390625
Validation loss: 1.9809113548647972

Epoch: 5| Step: 10
Training loss: 1.9383573532104492
Validation loss: 1.992929220199585

Epoch: 477| Step: 0
Training loss: 1.1036713123321533
Validation loss: 2.0302321180220573

Epoch: 5| Step: 1
Training loss: 1.3872578144073486
Validation loss: 1.9831081949254519

Epoch: 5| Step: 2
Training loss: 1.3480278253555298
Validation loss: 2.009914170029343

Epoch: 5| Step: 3
Training loss: 1.1608272790908813
Validation loss: 1.9892738544812767

Epoch: 5| Step: 4
Training loss: 1.186542272567749
Validation loss: 1.9961488452008975

Epoch: 5| Step: 5
Training loss: 1.689974069595337
Validation loss: 1.9790653669705955

Epoch: 5| Step: 6
Training loss: 1.5176130533218384
Validation loss: 2.002150538147137

Epoch: 5| Step: 7
Training loss: 1.6465473175048828
Validation loss: 1.9744872021418747

Epoch: 5| Step: 8
Training loss: 1.7809193134307861
Validation loss: 1.9894412986693844

Epoch: 5| Step: 9
Training loss: 2.1299986839294434
Validation loss: 2.0053370242477744

Epoch: 5| Step: 10
Training loss: 1.380028486251831
Validation loss: 1.9808770994986258

Epoch: 478| Step: 0
Training loss: 1.9289252758026123
Validation loss: 1.970534586137341

Epoch: 5| Step: 1
Training loss: 1.5565330982208252
Validation loss: 1.9687659458447528

Epoch: 5| Step: 2
Training loss: 1.1219232082366943
Validation loss: 1.9630844746866534

Epoch: 5| Step: 3
Training loss: 1.7403370141983032
Validation loss: 2.0047744679194626

Epoch: 5| Step: 4
Training loss: 1.3080402612686157
Validation loss: 1.9997726281483967

Epoch: 5| Step: 5
Training loss: 1.5176397562026978
Validation loss: 1.9555698287102483

Epoch: 5| Step: 6
Training loss: 1.9745181798934937
Validation loss: 1.9696836548466836

Epoch: 5| Step: 7
Training loss: 1.655859351158142
Validation loss: 1.9714863864324426

Epoch: 5| Step: 8
Training loss: 0.9074785113334656
Validation loss: 1.9918046869257444

Epoch: 5| Step: 9
Training loss: 1.1268686056137085
Validation loss: 2.0093561346812914

Epoch: 5| Step: 10
Training loss: 1.2581231594085693
Validation loss: 1.998230226578251

Epoch: 479| Step: 0
Training loss: 1.2342267036437988
Validation loss: 1.976269284884135

Epoch: 5| Step: 1
Training loss: 1.7632194757461548
Validation loss: 1.9985109272823538

Epoch: 5| Step: 2
Training loss: 0.9693361520767212
Validation loss: 1.9859834909439087

Epoch: 5| Step: 3
Training loss: 1.6219971179962158
Validation loss: 1.9821558306294103

Epoch: 5| Step: 4
Training loss: 1.790513277053833
Validation loss: 1.9521135232781852

Epoch: 5| Step: 5
Training loss: 0.903691291809082
Validation loss: 1.9750086017834243

Epoch: 5| Step: 6
Training loss: 1.1849555969238281
Validation loss: 1.9631207284107004

Epoch: 5| Step: 7
Training loss: 1.7678616046905518
Validation loss: 1.9728366072459886

Epoch: 5| Step: 8
Training loss: 1.9658355712890625
Validation loss: 1.9876686001336703

Epoch: 5| Step: 9
Training loss: 1.390733003616333
Validation loss: 1.975179608150195

Epoch: 5| Step: 10
Training loss: 1.4305256605148315
Validation loss: 1.9721043750803957

Epoch: 480| Step: 0
Training loss: 2.0270540714263916
Validation loss: 1.9796721037997995

Epoch: 5| Step: 1
Training loss: 1.4493119716644287
Validation loss: 1.9809659475921302

Epoch: 5| Step: 2
Training loss: 0.9935684204101562
Validation loss: 1.9881382398707892

Epoch: 5| Step: 3
Training loss: 1.5804004669189453
Validation loss: 1.9859695562752344

Epoch: 5| Step: 4
Training loss: 1.503467082977295
Validation loss: 1.9686325647497689

Epoch: 5| Step: 5
Training loss: 1.5090162754058838
Validation loss: 1.9918830292199248

Epoch: 5| Step: 6
Training loss: 1.4441031217575073
Validation loss: 2.0015056492179952

Epoch: 5| Step: 7
Training loss: 1.285110592842102
Validation loss: 1.9966163019980154

Epoch: 5| Step: 8
Training loss: 1.4008327722549438
Validation loss: 2.0061628459602274

Epoch: 5| Step: 9
Training loss: 1.4774589538574219
Validation loss: 1.9816177006690734

Epoch: 5| Step: 10
Training loss: 1.524449348449707
Validation loss: 1.982689235800056

Epoch: 481| Step: 0
Training loss: 1.5630230903625488
Validation loss: 1.9814680545560774

Epoch: 5| Step: 1
Training loss: 0.7358620762825012
Validation loss: 1.9456337126352454

Epoch: 5| Step: 2
Training loss: 0.8096753358840942
Validation loss: 1.967457430337065

Epoch: 5| Step: 3
Training loss: 2.3344779014587402
Validation loss: 1.9742500564103485

Epoch: 5| Step: 4
Training loss: 1.2899657487869263
Validation loss: 1.9907811021292081

Epoch: 5| Step: 5
Training loss: 1.932999849319458
Validation loss: 1.9848797795593098

Epoch: 5| Step: 6
Training loss: 1.644036889076233
Validation loss: 1.9826028564924836

Epoch: 5| Step: 7
Training loss: 1.4866033792495728
Validation loss: 2.0078192910840436

Epoch: 5| Step: 8
Training loss: 1.4038852453231812
Validation loss: 1.9595635014195596

Epoch: 5| Step: 9
Training loss: 1.3881311416625977
Validation loss: 2.0000870932814894

Epoch: 5| Step: 10
Training loss: 1.4432904720306396
Validation loss: 1.967880154168734

Epoch: 482| Step: 0
Training loss: 0.7382789850234985
Validation loss: 1.9892397055061914

Epoch: 5| Step: 1
Training loss: 1.2642433643341064
Validation loss: 1.9731866698111258

Epoch: 5| Step: 2
Training loss: 1.5103495121002197
Validation loss: 2.001034381569073

Epoch: 5| Step: 3
Training loss: 2.0106143951416016
Validation loss: 1.9870790025239349

Epoch: 5| Step: 4
Training loss: 1.7641289234161377
Validation loss: 1.9795165023496073

Epoch: 5| Step: 5
Training loss: 1.1465009450912476
Validation loss: 1.9863204186962498

Epoch: 5| Step: 6
Training loss: 1.6789586544036865
Validation loss: 1.968541496543474

Epoch: 5| Step: 7
Training loss: 1.7144582271575928
Validation loss: 1.97219418966642

Epoch: 5| Step: 8
Training loss: 1.5165694952011108
Validation loss: 1.9979002104010632

Epoch: 5| Step: 9
Training loss: 1.4664866924285889
Validation loss: 2.050783209903266

Epoch: 5| Step: 10
Training loss: 1.3532565832138062
Validation loss: 1.9803659954378683

Epoch: 483| Step: 0
Training loss: 1.8962970972061157
Validation loss: 1.9918634981237433

Epoch: 5| Step: 1
Training loss: 1.3871272802352905
Validation loss: 2.010762341560856

Epoch: 5| Step: 2
Training loss: 1.39670729637146
Validation loss: 2.001483819817984

Epoch: 5| Step: 3
Training loss: 1.4383376836776733
Validation loss: 2.019151718385758

Epoch: 5| Step: 4
Training loss: 1.292700171470642
Validation loss: 1.9838516968552784

Epoch: 5| Step: 5
Training loss: 1.724381685256958
Validation loss: 2.025682016085553

Epoch: 5| Step: 6
Training loss: 1.347641944885254
Validation loss: 1.9972346418647355

Epoch: 5| Step: 7
Training loss: 1.1082768440246582
Validation loss: 1.9807982662672639

Epoch: 5| Step: 8
Training loss: 1.9523471593856812
Validation loss: 2.0025082121613207

Epoch: 5| Step: 9
Training loss: 1.0488581657409668
Validation loss: 1.9948043002877185

Epoch: 5| Step: 10
Training loss: 1.546210527420044
Validation loss: 1.9868268043764177

Epoch: 484| Step: 0
Training loss: 1.5063480138778687
Validation loss: 1.9956060109599945

Epoch: 5| Step: 1
Training loss: 1.7066833972930908
Validation loss: 1.973630525732553

Epoch: 5| Step: 2
Training loss: 1.1628365516662598
Validation loss: 1.9592232986163067

Epoch: 5| Step: 3
Training loss: 1.7652755975723267
Validation loss: 1.9584168605906989

Epoch: 5| Step: 4
Training loss: 0.8291546702384949
Validation loss: 1.9916834703055761

Epoch: 5| Step: 5
Training loss: 1.6957361698150635
Validation loss: 1.9720819073338662

Epoch: 5| Step: 6
Training loss: 1.5804216861724854
Validation loss: 1.9619552909687001

Epoch: 5| Step: 7
Training loss: 1.592942476272583
Validation loss: 1.9754620341844455

Epoch: 5| Step: 8
Training loss: 1.3690484762191772
Validation loss: 2.0025896282606226

Epoch: 5| Step: 9
Training loss: 1.2502832412719727
Validation loss: 2.045479078446665

Epoch: 5| Step: 10
Training loss: 1.436458945274353
Validation loss: 1.9775782708198792

Epoch: 485| Step: 0
Training loss: 1.4427160024642944
Validation loss: 1.9922557671864827

Epoch: 5| Step: 1
Training loss: 1.2140333652496338
Validation loss: 1.9599399617923203

Epoch: 5| Step: 2
Training loss: 1.3658764362335205
Validation loss: 2.0023332988062212

Epoch: 5| Step: 3
Training loss: 1.4996247291564941
Validation loss: 1.994482353169431

Epoch: 5| Step: 4
Training loss: 1.4386916160583496
Validation loss: 1.9559438523425852

Epoch: 5| Step: 5
Training loss: 1.4442102909088135
Validation loss: 1.9943418938626525

Epoch: 5| Step: 6
Training loss: 1.3819854259490967
Validation loss: 1.9677511479264946

Epoch: 5| Step: 7
Training loss: 1.447106957435608
Validation loss: 2.010231861504175

Epoch: 5| Step: 8
Training loss: 1.5343894958496094
Validation loss: 2.008086710847834

Epoch: 5| Step: 9
Training loss: 1.285643219947815
Validation loss: 2.0031127237504527

Epoch: 5| Step: 10
Training loss: 2.0692992210388184
Validation loss: 2.0120328344324583

Epoch: 486| Step: 0
Training loss: 1.1419851779937744
Validation loss: 2.0272021537185996

Epoch: 5| Step: 1
Training loss: 1.5386682748794556
Validation loss: 1.999430380841737

Epoch: 5| Step: 2
Training loss: 1.4081780910491943
Validation loss: 2.020456502514501

Epoch: 5| Step: 3
Training loss: 1.7773163318634033
Validation loss: 1.99637819105579

Epoch: 5| Step: 4
Training loss: 1.17122220993042
Validation loss: 1.967553892443257

Epoch: 5| Step: 5
Training loss: 1.724329948425293
Validation loss: 1.961403703176847

Epoch: 5| Step: 6
Training loss: 1.7397301197052002
Validation loss: 1.9637095915373934

Epoch: 5| Step: 7
Training loss: 1.5907549858093262
Validation loss: 1.9896784315827072

Epoch: 5| Step: 8
Training loss: 1.203788161277771
Validation loss: 1.9571840968183292

Epoch: 5| Step: 9
Training loss: 1.1558372974395752
Validation loss: 2.0166834195454917

Epoch: 5| Step: 10
Training loss: 1.726139783859253
Validation loss: 1.98525232525282

Epoch: 487| Step: 0
Training loss: 1.3072865009307861
Validation loss: 1.958451614584974

Epoch: 5| Step: 1
Training loss: 1.519029140472412
Validation loss: 1.976712260195004

Epoch: 5| Step: 2
Training loss: 1.8610366582870483
Validation loss: 1.968178626029722

Epoch: 5| Step: 3
Training loss: 1.4582271575927734
Validation loss: 1.9706706026548981

Epoch: 5| Step: 4
Training loss: 1.5472853183746338
Validation loss: 1.9709978718911447

Epoch: 5| Step: 5
Training loss: 0.9807850122451782
Validation loss: 1.9531959359363844

Epoch: 5| Step: 6
Training loss: 1.7742408514022827
Validation loss: 1.9755656808935187

Epoch: 5| Step: 7
Training loss: 1.6269786357879639
Validation loss: 1.969437599182129

Epoch: 5| Step: 8
Training loss: 1.8805053234100342
Validation loss: 1.9703205426534016

Epoch: 5| Step: 9
Training loss: 1.3199012279510498
Validation loss: 2.019977154270295

Epoch: 5| Step: 10
Training loss: 0.5229607820510864
Validation loss: 1.995591253362676

Epoch: 488| Step: 0
Training loss: 1.8136100769042969
Validation loss: 2.009380208548679

Epoch: 5| Step: 1
Training loss: 1.3479530811309814
Validation loss: 1.9992048599386727

Epoch: 5| Step: 2
Training loss: 1.3350061178207397
Validation loss: 1.9809712492009646

Epoch: 5| Step: 3
Training loss: 1.4628667831420898
Validation loss: 1.9391454573600524

Epoch: 5| Step: 4
Training loss: 1.3684054613113403
Validation loss: 1.972993382843592

Epoch: 5| Step: 5
Training loss: 1.6779073476791382
Validation loss: 1.9498448089886737

Epoch: 5| Step: 6
Training loss: 1.378085732460022
Validation loss: 1.9946692502626808

Epoch: 5| Step: 7
Training loss: 1.6466554403305054
Validation loss: 1.9833573372133317

Epoch: 5| Step: 8
Training loss: 1.2244551181793213
Validation loss: 1.9705161599702732

Epoch: 5| Step: 9
Training loss: 0.9607359766960144
Validation loss: 1.9729217803606423

Epoch: 5| Step: 10
Training loss: 1.9208078384399414
Validation loss: 2.0054228933908607

Epoch: 489| Step: 0
Training loss: 1.2188565731048584
Validation loss: 1.972698059133304

Epoch: 5| Step: 1
Training loss: 1.561625361442566
Validation loss: 1.9806690818520003

Epoch: 5| Step: 2
Training loss: 1.601618766784668
Validation loss: 2.0033781195199616

Epoch: 5| Step: 3
Training loss: 1.6571556329727173
Validation loss: 1.996340520920292

Epoch: 5| Step: 4
Training loss: 1.5634351968765259
Validation loss: 2.020751950561359

Epoch: 5| Step: 5
Training loss: 1.4394677877426147
Validation loss: 2.0329628503450783

Epoch: 5| Step: 6
Training loss: 1.6588207483291626
Validation loss: 2.050389451365317

Epoch: 5| Step: 7
Training loss: 1.5287798643112183
Validation loss: 2.02811429321125

Epoch: 5| Step: 8
Training loss: 1.4986305236816406
Validation loss: 2.0259992153413835

Epoch: 5| Step: 9
Training loss: 1.5657742023468018
Validation loss: 2.0385434730078584

Epoch: 5| Step: 10
Training loss: 0.9608808159828186
Validation loss: 2.0095391222225722

Epoch: 490| Step: 0
Training loss: 1.479597568511963
Validation loss: 2.0147609890148206

Epoch: 5| Step: 1
Training loss: 1.768049955368042
Validation loss: 2.0061452337490615

Epoch: 5| Step: 2
Training loss: 1.3883888721466064
Validation loss: 1.98573649057778

Epoch: 5| Step: 3
Training loss: 1.5086383819580078
Validation loss: 2.0161677791226293

Epoch: 5| Step: 4
Training loss: 1.4572628736495972
Validation loss: 1.9499869679891935

Epoch: 5| Step: 5
Training loss: 1.8179690837860107
Validation loss: 1.9523379110520886

Epoch: 5| Step: 6
Training loss: 1.1477341651916504
Validation loss: 1.9804562458428003

Epoch: 5| Step: 7
Training loss: 0.9789457321166992
Validation loss: 1.97214263485324

Epoch: 5| Step: 8
Training loss: 1.035790205001831
Validation loss: 1.9536171062018282

Epoch: 5| Step: 9
Training loss: 1.8682754039764404
Validation loss: 1.9732165464790918

Epoch: 5| Step: 10
Training loss: 1.5491943359375
Validation loss: 2.011423449362478

Epoch: 491| Step: 0
Training loss: 1.6011390686035156
Validation loss: 2.0029972932671987

Epoch: 5| Step: 1
Training loss: 1.5728042125701904
Validation loss: 1.972930158338239

Epoch: 5| Step: 2
Training loss: 1.5747559070587158
Validation loss: 1.965926856122991

Epoch: 5| Step: 3
Training loss: 1.6416358947753906
Validation loss: 1.979711514647289

Epoch: 5| Step: 4
Training loss: 1.586751103401184
Validation loss: 1.9521908670343378

Epoch: 5| Step: 5
Training loss: 1.474554419517517
Validation loss: 1.9406889023319367

Epoch: 5| Step: 6
Training loss: 1.2348912954330444
Validation loss: 1.9891231508665188

Epoch: 5| Step: 7
Training loss: 1.5086023807525635
Validation loss: 2.000839307744016

Epoch: 5| Step: 8
Training loss: 1.1433889865875244
Validation loss: 1.9589657629689863

Epoch: 5| Step: 9
Training loss: 1.3018176555633545
Validation loss: 1.9662176614166589

Epoch: 5| Step: 10
Training loss: 1.3955848217010498
Validation loss: 1.9730026388681063

Epoch: 492| Step: 0
Training loss: 1.4577505588531494
Validation loss: 1.9405355773946291

Epoch: 5| Step: 1
Training loss: 0.9103366732597351
Validation loss: 1.9399922778529506

Epoch: 5| Step: 2
Training loss: 1.7674700021743774
Validation loss: 1.9954538704246603

Epoch: 5| Step: 3
Training loss: 1.3516474962234497
Validation loss: 1.9742950726580877

Epoch: 5| Step: 4
Training loss: 1.4697307348251343
Validation loss: 1.9595668033886982

Epoch: 5| Step: 5
Training loss: 1.1064746379852295
Validation loss: 1.9913256450365948

Epoch: 5| Step: 6
Training loss: 1.797020673751831
Validation loss: 1.934924425617341

Epoch: 5| Step: 7
Training loss: 2.092369318008423
Validation loss: 1.9741500090527278

Epoch: 5| Step: 8
Training loss: 1.6908466815948486
Validation loss: 1.9911312698036112

Epoch: 5| Step: 9
Training loss: 0.8352160453796387
Validation loss: 2.0048710402622016

Epoch: 5| Step: 10
Training loss: 1.3567278385162354
Validation loss: 1.9890164623978317

Epoch: 493| Step: 0
Training loss: 1.9617111682891846
Validation loss: 1.9868603957596647

Epoch: 5| Step: 1
Training loss: 1.4686070680618286
Validation loss: 1.9678817692623343

Epoch: 5| Step: 2
Training loss: 1.3396860361099243
Validation loss: 1.9696866517425866

Epoch: 5| Step: 3
Training loss: 1.5109716653823853
Validation loss: 1.9907504538054108

Epoch: 5| Step: 4
Training loss: 1.5717250108718872
Validation loss: 1.9669018355748986

Epoch: 5| Step: 5
Training loss: 1.5049928426742554
Validation loss: 1.9950406448815459

Epoch: 5| Step: 6
Training loss: 1.5571553707122803
Validation loss: 1.994737313639733

Epoch: 5| Step: 7
Training loss: 1.7642285823822021
Validation loss: 1.9492876965512511

Epoch: 5| Step: 8
Training loss: 1.035843849182129
Validation loss: 1.9911060230706328

Epoch: 5| Step: 9
Training loss: 1.0067899227142334
Validation loss: 1.9604097117659867

Epoch: 5| Step: 10
Training loss: 1.1782137155532837
Validation loss: 1.9786729376803163

Epoch: 494| Step: 0
Training loss: 1.6895418167114258
Validation loss: 2.004486365984845

Epoch: 5| Step: 1
Training loss: 0.947403073310852
Validation loss: 1.962293956869392

Epoch: 5| Step: 2
Training loss: 1.4115660190582275
Validation loss: 1.9840735953341249

Epoch: 5| Step: 3
Training loss: 1.749311089515686
Validation loss: 1.969592886586343

Epoch: 5| Step: 4
Training loss: 0.845140814781189
Validation loss: 1.9820841512372416

Epoch: 5| Step: 5
Training loss: 1.7128194570541382
Validation loss: 1.997167625734883

Epoch: 5| Step: 6
Training loss: 1.6245872974395752
Validation loss: 1.9555308818817139

Epoch: 5| Step: 7
Training loss: 1.3465386629104614
Validation loss: 1.9805735529109996

Epoch: 5| Step: 8
Training loss: 1.740164041519165
Validation loss: 1.9721117968200355

Epoch: 5| Step: 9
Training loss: 1.3190782070159912
Validation loss: 1.9916890872422086

Epoch: 5| Step: 10
Training loss: 1.4058647155761719
Validation loss: 1.949347578069215

Epoch: 495| Step: 0
Training loss: 1.2733144760131836
Validation loss: 1.97098591122576

Epoch: 5| Step: 1
Training loss: 1.3884164094924927
Validation loss: 1.9866104202885781

Epoch: 5| Step: 2
Training loss: 1.5170822143554688
Validation loss: 2.0186012457775813

Epoch: 5| Step: 3
Training loss: 1.5150066614151
Validation loss: 2.0104577195259834

Epoch: 5| Step: 4
Training loss: 1.0556533336639404
Validation loss: 2.008224774432439

Epoch: 5| Step: 5
Training loss: 1.659781813621521
Validation loss: 1.9859707637499737

Epoch: 5| Step: 6
Training loss: 1.6330804824829102
Validation loss: 2.021314687626336

Epoch: 5| Step: 7
Training loss: 1.9274709224700928
Validation loss: 1.965185126950664

Epoch: 5| Step: 8
Training loss: 1.2988642454147339
Validation loss: 1.9947788715362549

Epoch: 5| Step: 9
Training loss: 1.4816441535949707
Validation loss: 1.9875876095987135

Epoch: 5| Step: 10
Training loss: 1.3422483205795288
Validation loss: 1.976525568193005

Epoch: 496| Step: 0
Training loss: 1.3386155366897583
Validation loss: 1.9929849922016103

Epoch: 5| Step: 1
Training loss: 1.1060742139816284
Validation loss: 1.9849819291022517

Epoch: 5| Step: 2
Training loss: 2.1884472370147705
Validation loss: 1.9724597264361639

Epoch: 5| Step: 3
Training loss: 1.6228536367416382
Validation loss: 1.9475865569165958

Epoch: 5| Step: 4
Training loss: 0.9944007992744446
Validation loss: 1.9994248549143474

Epoch: 5| Step: 5
Training loss: 1.8840434551239014
Validation loss: 2.006755393038514

Epoch: 5| Step: 6
Training loss: 1.3640912771224976
Validation loss: 1.9808171487623645

Epoch: 5| Step: 7
Training loss: 1.276880145072937
Validation loss: 1.9929172685069423

Epoch: 5| Step: 8
Training loss: 1.219290018081665
Validation loss: 1.9690423934690413

Epoch: 5| Step: 9
Training loss: 1.317733645439148
Validation loss: 1.9869467263580651

Epoch: 5| Step: 10
Training loss: 1.626551628112793
Validation loss: 1.9587759176890056

Epoch: 497| Step: 0
Training loss: 1.4290040731430054
Validation loss: 1.9785428816272366

Epoch: 5| Step: 1
Training loss: 1.4857194423675537
Validation loss: 1.983282139224391

Epoch: 5| Step: 2
Training loss: 1.2626545429229736
Validation loss: 1.9946161239377913

Epoch: 5| Step: 3
Training loss: 1.033138394355774
Validation loss: 2.0085232257843018

Epoch: 5| Step: 4
Training loss: 1.7993218898773193
Validation loss: 1.9846284620223507

Epoch: 5| Step: 5
Training loss: 1.3231565952301025
Validation loss: 2.008520410906884

Epoch: 5| Step: 6
Training loss: 1.3388726711273193
Validation loss: 1.9940206735364852

Epoch: 5| Step: 7
Training loss: 1.1667612791061401
Validation loss: 1.9885249458333498

Epoch: 5| Step: 8
Training loss: 1.6382757425308228
Validation loss: 1.9801785522891628

Epoch: 5| Step: 9
Training loss: 1.5390660762786865
Validation loss: 1.9583118051610968

Epoch: 5| Step: 10
Training loss: 1.9205706119537354
Validation loss: 1.9631193427629368

Epoch: 498| Step: 0
Training loss: 1.736885666847229
Validation loss: 1.9928919487102057

Epoch: 5| Step: 1
Training loss: 1.811133623123169
Validation loss: 2.0069200056855396

Epoch: 5| Step: 2
Training loss: 1.697056770324707
Validation loss: 1.9931610617586362

Epoch: 5| Step: 3
Training loss: 0.9879426956176758
Validation loss: 1.9824104168081795

Epoch: 5| Step: 4
Training loss: 1.8927373886108398
Validation loss: 2.01034846485302

Epoch: 5| Step: 5
Training loss: 1.4698504209518433
Validation loss: 2.0047770238691762

Epoch: 5| Step: 6
Training loss: 1.3357652425765991
Validation loss: 2.0129914540116505

Epoch: 5| Step: 7
Training loss: 1.5474133491516113
Validation loss: 1.984281042570709

Epoch: 5| Step: 8
Training loss: 1.2032067775726318
Validation loss: 1.9770958564614738

Epoch: 5| Step: 9
Training loss: 0.9517543911933899
Validation loss: 1.9673977564739924

Epoch: 5| Step: 10
Training loss: 1.1883524656295776
Validation loss: 1.97783721903319

Epoch: 499| Step: 0
Training loss: 1.4963685274124146
Validation loss: 1.9689735930453065

Epoch: 5| Step: 1
Training loss: 1.8294744491577148
Validation loss: 2.031519970586223

Epoch: 5| Step: 2
Training loss: 1.1715888977050781
Validation loss: 1.999968901757271

Epoch: 5| Step: 3
Training loss: 1.5679357051849365
Validation loss: 1.97816296803054

Epoch: 5| Step: 4
Training loss: 1.1696817874908447
Validation loss: 1.9762200565748318

Epoch: 5| Step: 5
Training loss: 1.571681022644043
Validation loss: 1.9698480752206617

Epoch: 5| Step: 6
Training loss: 1.5118138790130615
Validation loss: 1.9657246707588114

Epoch: 5| Step: 7
Training loss: 1.3817180395126343
Validation loss: 1.9874415013097948

Epoch: 5| Step: 8
Training loss: 1.7821458578109741
Validation loss: 2.0305551585330757

Epoch: 5| Step: 9
Training loss: 1.1987794637680054
Validation loss: 1.9916568084429669

Epoch: 5| Step: 10
Training loss: 1.1978154182434082
Validation loss: 1.9801607516504103

Epoch: 500| Step: 0
Training loss: 1.688333511352539
Validation loss: 1.971589171758262

Epoch: 5| Step: 1
Training loss: 1.5177406072616577
Validation loss: 1.9893834962639758

Epoch: 5| Step: 2
Training loss: 0.9360912442207336
Validation loss: 2.0053594573851554

Epoch: 5| Step: 3
Training loss: 1.1839648485183716
Validation loss: 1.9850795576649327

Epoch: 5| Step: 4
Training loss: 1.3501898050308228
Validation loss: 2.0037581228440806

Epoch: 5| Step: 5
Training loss: 1.1517107486724854
Validation loss: 1.9716775712146555

Epoch: 5| Step: 6
Training loss: 0.8619457483291626
Validation loss: 1.9727320645445137

Epoch: 5| Step: 7
Training loss: 2.0519509315490723
Validation loss: 1.9790645004600607

Epoch: 5| Step: 8
Training loss: 1.5794063806533813
Validation loss: 1.9741055734695927

Epoch: 5| Step: 9
Training loss: 1.5765371322631836
Validation loss: 1.9828815242295623

Epoch: 5| Step: 10
Training loss: 1.992676019668579
Validation loss: 1.963349130845839

Epoch: 501| Step: 0
Training loss: 1.1611576080322266
Validation loss: 1.9790204468593802

Epoch: 5| Step: 1
Training loss: 0.901228129863739
Validation loss: 1.9897586261072466

Epoch: 5| Step: 2
Training loss: 1.138782262802124
Validation loss: 1.9770294325326079

Epoch: 5| Step: 3
Training loss: 1.3820581436157227
Validation loss: 2.022366478878965

Epoch: 5| Step: 4
Training loss: 1.406214714050293
Validation loss: 1.9562471041115381

Epoch: 5| Step: 5
Training loss: 1.8897857666015625
Validation loss: 1.9996732793828493

Epoch: 5| Step: 6
Training loss: 1.700521469116211
Validation loss: 2.003600597381592

Epoch: 5| Step: 7
Training loss: 1.7801824808120728
Validation loss: 1.9531311117192751

Epoch: 5| Step: 8
Training loss: 1.1522643566131592
Validation loss: 1.9860277868086291

Epoch: 5| Step: 9
Training loss: 2.1403496265411377
Validation loss: 1.9733922327718427

Epoch: 5| Step: 10
Training loss: 1.1384997367858887
Validation loss: 1.9547069457269484

Epoch: 502| Step: 0
Training loss: 1.5371794700622559
Validation loss: 1.9688149267627346

Epoch: 5| Step: 1
Training loss: 1.6507339477539062
Validation loss: 1.9466808354982765

Epoch: 5| Step: 2
Training loss: 1.5280492305755615
Validation loss: 1.9943613775314823

Epoch: 5| Step: 3
Training loss: 1.3093154430389404
Validation loss: 1.965018819737178

Epoch: 5| Step: 4
Training loss: 1.0883535146713257
Validation loss: 1.988732466133692

Epoch: 5| Step: 5
Training loss: 1.9785115718841553
Validation loss: 1.9925486503108856

Epoch: 5| Step: 6
Training loss: 1.3391611576080322
Validation loss: 1.959100527148093

Epoch: 5| Step: 7
Training loss: 1.451398491859436
Validation loss: 1.9492200882204118

Epoch: 5| Step: 8
Training loss: 1.3939449787139893
Validation loss: 1.9989078160255187

Epoch: 5| Step: 9
Training loss: 1.4227014780044556
Validation loss: 1.9526867174333142

Epoch: 5| Step: 10
Training loss: 1.19838547706604
Validation loss: 2.0191580851872764

Epoch: 503| Step: 0
Training loss: 1.614091157913208
Validation loss: 2.026086002267817

Epoch: 5| Step: 1
Training loss: 1.288955569267273
Validation loss: 2.0110149665545394

Epoch: 5| Step: 2
Training loss: 1.689984917640686
Validation loss: 1.9991590438350555

Epoch: 5| Step: 3
Training loss: 1.0763607025146484
Validation loss: 2.0061136727691977

Epoch: 5| Step: 4
Training loss: 1.2000539302825928
Validation loss: 2.0119106077378794

Epoch: 5| Step: 5
Training loss: 1.1570615768432617
Validation loss: 1.9823147071305143

Epoch: 5| Step: 6
Training loss: 1.5297398567199707
Validation loss: 1.9766698204061037

Epoch: 5| Step: 7
Training loss: 1.8390567302703857
Validation loss: 2.0129178877799743

Epoch: 5| Step: 8
Training loss: 0.7691197395324707
Validation loss: 1.9885627787600282

Epoch: 5| Step: 9
Training loss: 1.896977186203003
Validation loss: 1.9984013598452333

Epoch: 5| Step: 10
Training loss: 1.7926745414733887
Validation loss: 1.989856457197538

Epoch: 504| Step: 0
Training loss: 1.512292504310608
Validation loss: 2.008945477906094

Epoch: 5| Step: 1
Training loss: 1.4683884382247925
Validation loss: 1.9983654201671641

Epoch: 5| Step: 2
Training loss: 1.2588971853256226
Validation loss: 1.958772317055733

Epoch: 5| Step: 3
Training loss: 1.4059056043624878
Validation loss: 1.9366729849128312

Epoch: 5| Step: 4
Training loss: 0.8682812452316284
Validation loss: 1.9453838435552453

Epoch: 5| Step: 5
Training loss: 1.1902973651885986
Validation loss: 1.9545885696206042

Epoch: 5| Step: 6
Training loss: 1.424003005027771
Validation loss: 1.969892510803797

Epoch: 5| Step: 7
Training loss: 1.522668480873108
Validation loss: 1.9761848347161406

Epoch: 5| Step: 8
Training loss: 2.1777873039245605
Validation loss: 1.9940206876365087

Epoch: 5| Step: 9
Training loss: 1.1907484531402588
Validation loss: 1.9221778569682952

Epoch: 5| Step: 10
Training loss: 1.8794442415237427
Validation loss: 1.9761172904763171

Epoch: 505| Step: 0
Training loss: 1.3237626552581787
Validation loss: 1.975614264447202

Epoch: 5| Step: 1
Training loss: 1.2526159286499023
Validation loss: 1.979545606079922

Epoch: 5| Step: 2
Training loss: 1.2152568101882935
Validation loss: 1.9603834908495668

Epoch: 5| Step: 3
Training loss: 1.2526253461837769
Validation loss: 1.9895975205206102

Epoch: 5| Step: 4
Training loss: 1.3219177722930908
Validation loss: 2.023026002350674

Epoch: 5| Step: 5
Training loss: 1.1073459386825562
Validation loss: 2.020403080089118

Epoch: 5| Step: 6
Training loss: 1.837843656539917
Validation loss: 1.9842104258075837

Epoch: 5| Step: 7
Training loss: 1.9116722345352173
Validation loss: 1.9826407509465371

Epoch: 5| Step: 8
Training loss: 1.4935567378997803
Validation loss: 2.0064506992217033

Epoch: 5| Step: 9
Training loss: 1.413825273513794
Validation loss: 1.9825696496553318

Epoch: 5| Step: 10
Training loss: 1.8530609607696533
Validation loss: 1.9723785820827688

Epoch: 506| Step: 0
Training loss: 1.7604882717132568
Validation loss: 2.006427998183876

Epoch: 5| Step: 1
Training loss: 1.0907905101776123
Validation loss: 1.9590588846514303

Epoch: 5| Step: 2
Training loss: 1.5794633626937866
Validation loss: 1.9597084778611378

Epoch: 5| Step: 3
Training loss: 1.398474931716919
Validation loss: 1.9869345285559212

Epoch: 5| Step: 4
Training loss: 1.7123339176177979
Validation loss: 1.9791455679042365

Epoch: 5| Step: 5
Training loss: 1.8957223892211914
Validation loss: 2.0014003297334075

Epoch: 5| Step: 6
Training loss: 1.4515072107315063
Validation loss: 1.9940054429474698

Epoch: 5| Step: 7
Training loss: 1.4856798648834229
Validation loss: 1.9550359120932959

Epoch: 5| Step: 8
Training loss: 1.0472898483276367
Validation loss: 1.9580691681113294

Epoch: 5| Step: 9
Training loss: 0.9393156170845032
Validation loss: 1.954532297708655

Epoch: 5| Step: 10
Training loss: 1.551426887512207
Validation loss: 1.9730065766201224

Epoch: 507| Step: 0
Training loss: 1.6071857213974
Validation loss: 1.9786407537357782

Epoch: 5| Step: 1
Training loss: 1.567960500717163
Validation loss: 1.9814958457023866

Epoch: 5| Step: 2
Training loss: 2.0639960765838623
Validation loss: 1.9934368133544922

Epoch: 5| Step: 3
Training loss: 0.8639319539070129
Validation loss: 2.008794443581694

Epoch: 5| Step: 4
Training loss: 1.2313461303710938
Validation loss: 1.987984440659964

Epoch: 5| Step: 5
Training loss: 1.8844897747039795
Validation loss: 2.003663847523351

Epoch: 5| Step: 6
Training loss: 1.3815330266952515
Validation loss: 2.0286686240985827

Epoch: 5| Step: 7
Training loss: 1.3197990655899048
Validation loss: 1.9843769304213985

Epoch: 5| Step: 8
Training loss: 1.3166919946670532
Validation loss: 1.9923037700755621

Epoch: 5| Step: 9
Training loss: 1.157497525215149
Validation loss: 2.007360137918944

Epoch: 5| Step: 10
Training loss: 1.3623850345611572
Validation loss: 1.9866190661666214

Epoch: 508| Step: 0
Training loss: 1.1429097652435303
Validation loss: 1.961484020756137

Epoch: 5| Step: 1
Training loss: 1.5300102233886719
Validation loss: 1.9887787680472098

Epoch: 5| Step: 2
Training loss: 1.5057239532470703
Validation loss: 2.0000975516534623

Epoch: 5| Step: 3
Training loss: 1.3043699264526367
Validation loss: 2.006111929493566

Epoch: 5| Step: 4
Training loss: 1.4900720119476318
Validation loss: 1.9845261419973066

Epoch: 5| Step: 5
Training loss: 2.000272512435913
Validation loss: 1.973733812250117

Epoch: 5| Step: 6
Training loss: 0.876783013343811
Validation loss: 1.9686493450595486

Epoch: 5| Step: 7
Training loss: 0.9838177561759949
Validation loss: 1.9874126039525515

Epoch: 5| Step: 8
Training loss: 2.0454254150390625
Validation loss: 1.9930590173249603

Epoch: 5| Step: 9
Training loss: 1.6088123321533203
Validation loss: 1.9871074204803796

Epoch: 5| Step: 10
Training loss: 1.459925651550293
Validation loss: 1.988907749934863

Epoch: 509| Step: 0
Training loss: 1.602675199508667
Validation loss: 1.9951809747244722

Epoch: 5| Step: 1
Training loss: 1.172820806503296
Validation loss: 1.9618594646453857

Epoch: 5| Step: 2
Training loss: 1.865484595298767
Validation loss: 1.9708731610287902

Epoch: 5| Step: 3
Training loss: 1.3226360082626343
Validation loss: 2.0062577955184446

Epoch: 5| Step: 4
Training loss: 1.2533295154571533
Validation loss: 1.99290285828293

Epoch: 5| Step: 5
Training loss: 1.5488758087158203
Validation loss: 2.0137078608236005

Epoch: 5| Step: 6
Training loss: 1.7399753332138062
Validation loss: 2.0047575196912213

Epoch: 5| Step: 7
Training loss: 1.4020802974700928
Validation loss: 2.0223016867073635

Epoch: 5| Step: 8
Training loss: 1.3418635129928589
Validation loss: 1.9844948578906316

Epoch: 5| Step: 9
Training loss: 1.2075738906860352
Validation loss: 2.006945228063932

Epoch: 5| Step: 10
Training loss: 1.2667549848556519
Validation loss: 1.9815709539639053

Epoch: 510| Step: 0
Training loss: 2.1458590030670166
Validation loss: 2.0091639693065355

Epoch: 5| Step: 1
Training loss: 1.6251100301742554
Validation loss: 1.9981163188975344

Epoch: 5| Step: 2
Training loss: 1.0559170246124268
Validation loss: 1.9840717623310704

Epoch: 5| Step: 3
Training loss: 1.1705141067504883
Validation loss: 2.007875637341571

Epoch: 5| Step: 4
Training loss: 1.4181993007659912
Validation loss: 1.9616751311927714

Epoch: 5| Step: 5
Training loss: 1.4691574573516846
Validation loss: 1.985738488935655

Epoch: 5| Step: 6
Training loss: 1.866499662399292
Validation loss: 2.0085148580612673

Epoch: 5| Step: 7
Training loss: 1.3371098041534424
Validation loss: 1.9478296220943492

Epoch: 5| Step: 8
Training loss: 1.257184624671936
Validation loss: 1.9787141174398444

Epoch: 5| Step: 9
Training loss: 1.2157648801803589
Validation loss: 1.9916614858053063

Epoch: 5| Step: 10
Training loss: 1.0062861442565918
Validation loss: 1.9510321104398338

Epoch: 511| Step: 0
Training loss: 1.5147502422332764
Validation loss: 1.9669859434968682

Epoch: 5| Step: 1
Training loss: 1.295924186706543
Validation loss: 1.9866464138031006

Epoch: 5| Step: 2
Training loss: 1.8002398014068604
Validation loss: 1.9749204599729149

Epoch: 5| Step: 3
Training loss: 1.3543179035186768
Validation loss: 1.962701823121758

Epoch: 5| Step: 4
Training loss: 1.286647081375122
Validation loss: 1.9864820190655288

Epoch: 5| Step: 5
Training loss: 1.597984790802002
Validation loss: 2.0062414702548774

Epoch: 5| Step: 6
Training loss: 1.179298996925354
Validation loss: 1.9818322120174285

Epoch: 5| Step: 7
Training loss: 1.2764716148376465
Validation loss: 1.993041169258856

Epoch: 5| Step: 8
Training loss: 1.2664954662322998
Validation loss: 1.963648925545395

Epoch: 5| Step: 9
Training loss: 1.6024971008300781
Validation loss: 1.995984083862715

Epoch: 5| Step: 10
Training loss: 1.4214668273925781
Validation loss: 1.9691708857013333

Epoch: 512| Step: 0
Training loss: 1.0613991022109985
Validation loss: 1.9821036964334466

Epoch: 5| Step: 1
Training loss: 1.3234965801239014
Validation loss: 1.9986259565558484

Epoch: 5| Step: 2
Training loss: 1.138679027557373
Validation loss: 1.9854524673954133

Epoch: 5| Step: 3
Training loss: 1.6035373210906982
Validation loss: 1.9787417868132233

Epoch: 5| Step: 4
Training loss: 1.5609139204025269
Validation loss: 1.9683045930759882

Epoch: 5| Step: 5
Training loss: 1.1842551231384277
Validation loss: 1.9569139621591056

Epoch: 5| Step: 6
Training loss: 1.5690438747406006
Validation loss: 1.96305541582005

Epoch: 5| Step: 7
Training loss: 1.3854717016220093
Validation loss: 1.965949890434101

Epoch: 5| Step: 8
Training loss: 1.8579460382461548
Validation loss: 1.9712029016146095

Epoch: 5| Step: 9
Training loss: 1.2278481721878052
Validation loss: 1.9815883495474373

Epoch: 5| Step: 10
Training loss: 1.6260420083999634
Validation loss: 1.976457941916681

Epoch: 513| Step: 0
Training loss: 1.6685031652450562
Validation loss: 1.9862889166801208

Epoch: 5| Step: 1
Training loss: 1.6119556427001953
Validation loss: 1.978411207916916

Epoch: 5| Step: 2
Training loss: 1.6612770557403564
Validation loss: 2.0229627304179694

Epoch: 5| Step: 3
Training loss: 1.451728105545044
Validation loss: 2.022211003047164

Epoch: 5| Step: 4
Training loss: 1.230202078819275
Validation loss: 1.9937195393346971

Epoch: 5| Step: 5
Training loss: 1.2628816366195679
Validation loss: 1.997266379735803

Epoch: 5| Step: 6
Training loss: 1.1558432579040527
Validation loss: 1.9728369174465057

Epoch: 5| Step: 7
Training loss: 1.7217347621917725
Validation loss: 1.9821206420980475

Epoch: 5| Step: 8
Training loss: 1.7979869842529297
Validation loss: 1.9953158978492982

Epoch: 5| Step: 9
Training loss: 1.2966902256011963
Validation loss: 2.0015176342379664

Epoch: 5| Step: 10
Training loss: 0.6972952485084534
Validation loss: 1.9584476947784424

Epoch: 514| Step: 0
Training loss: 1.6376006603240967
Validation loss: 1.9553765045699252

Epoch: 5| Step: 1
Training loss: 1.3690131902694702
Validation loss: 1.9454522760965491

Epoch: 5| Step: 2
Training loss: 1.7283058166503906
Validation loss: 1.9439023412683958

Epoch: 5| Step: 3
Training loss: 1.0749181509017944
Validation loss: 1.9416810415124381

Epoch: 5| Step: 4
Training loss: 1.0907951593399048
Validation loss: 1.9615450700124104

Epoch: 5| Step: 5
Training loss: 1.4498889446258545
Validation loss: 1.9866139465762722

Epoch: 5| Step: 6
Training loss: 1.259252667427063
Validation loss: 1.9856868777223813

Epoch: 5| Step: 7
Training loss: 1.4129555225372314
Validation loss: 1.9603914970992713

Epoch: 5| Step: 8
Training loss: 1.5175117254257202
Validation loss: 1.9649382804029731

Epoch: 5| Step: 9
Training loss: 1.723740816116333
Validation loss: 1.9901435067576747

Epoch: 5| Step: 10
Training loss: 1.6326783895492554
Validation loss: 1.9743411951167609

Epoch: 515| Step: 0
Training loss: 2.0101945400238037
Validation loss: 1.9929907642385012

Epoch: 5| Step: 1
Training loss: 1.324657917022705
Validation loss: 2.0176559545660533

Epoch: 5| Step: 2
Training loss: 1.2933380603790283
Validation loss: 2.002934589180895

Epoch: 5| Step: 3
Training loss: 1.860333800315857
Validation loss: 2.010176835521575

Epoch: 5| Step: 4
Training loss: 1.471388578414917
Validation loss: 1.9671153894034765

Epoch: 5| Step: 5
Training loss: 1.273607611656189
Validation loss: 2.0026122677710747

Epoch: 5| Step: 6
Training loss: 1.4535229206085205
Validation loss: 1.9958519858698691

Epoch: 5| Step: 7
Training loss: 1.198408842086792
Validation loss: 1.978116484098537

Epoch: 5| Step: 8
Training loss: 1.2586381435394287
Validation loss: 1.9863507286194833

Epoch: 5| Step: 9
Training loss: 0.9703741073608398
Validation loss: 1.991750914563415

Epoch: 5| Step: 10
Training loss: 1.817614197731018
Validation loss: 1.9511320296154226

Epoch: 516| Step: 0
Training loss: 1.3431499004364014
Validation loss: 1.9851121312828475

Epoch: 5| Step: 1
Training loss: 1.8036333322525024
Validation loss: 1.972151638359152

Epoch: 5| Step: 2
Training loss: 1.1914151906967163
Validation loss: 1.9685795755796536

Epoch: 5| Step: 3
Training loss: 1.2852517366409302
Validation loss: 1.9595436614046815

Epoch: 5| Step: 4
Training loss: 1.2201958894729614
Validation loss: 1.9696498814449515

Epoch: 5| Step: 5
Training loss: 1.6824820041656494
Validation loss: 1.9704216116218156

Epoch: 5| Step: 6
Training loss: 1.2655643224716187
Validation loss: 1.9853009036792222

Epoch: 5| Step: 7
Training loss: 1.1651318073272705
Validation loss: 1.944947531146388

Epoch: 5| Step: 8
Training loss: 1.5887629985809326
Validation loss: 1.9774191712820401

Epoch: 5| Step: 9
Training loss: 1.5692068338394165
Validation loss: 1.9563677644216886

Epoch: 5| Step: 10
Training loss: 1.3399238586425781
Validation loss: 1.9461368386463453

Epoch: 517| Step: 0
Training loss: 1.492052435874939
Validation loss: 1.987616995329498

Epoch: 5| Step: 1
Training loss: 1.2657076120376587
Validation loss: 2.002024035299978

Epoch: 5| Step: 2
Training loss: 1.135432481765747
Validation loss: 2.0099845035101778

Epoch: 5| Step: 3
Training loss: 1.3790899515151978
Validation loss: 2.0133831244643017

Epoch: 5| Step: 4
Training loss: 1.6448923349380493
Validation loss: 2.0044963385469172

Epoch: 5| Step: 5
Training loss: 1.946703314781189
Validation loss: 2.009182942810879

Epoch: 5| Step: 6
Training loss: 1.4814565181732178
Validation loss: 2.015750321008826

Epoch: 5| Step: 7
Training loss: 1.2512500286102295
Validation loss: 2.01955597887757

Epoch: 5| Step: 8
Training loss: 1.5129516124725342
Validation loss: 2.0252359041603665

Epoch: 5| Step: 9
Training loss: 1.380382776260376
Validation loss: 2.015710356414959

Epoch: 5| Step: 10
Training loss: 1.229893684387207
Validation loss: 1.9741233356537358

Epoch: 518| Step: 0
Training loss: 1.5835634469985962
Validation loss: 1.9829159910960863

Epoch: 5| Step: 1
Training loss: 1.1467092037200928
Validation loss: 2.017529664501067

Epoch: 5| Step: 2
Training loss: 1.0672017335891724
Validation loss: 2.018150962809081

Epoch: 5| Step: 3
Training loss: 1.5670017004013062
Validation loss: 1.9532251486214258

Epoch: 5| Step: 4
Training loss: 1.3660099506378174
Validation loss: 1.956637232534347

Epoch: 5| Step: 5
Training loss: 1.7240521907806396
Validation loss: 1.983523145798714

Epoch: 5| Step: 6
Training loss: 1.929600477218628
Validation loss: 2.0046767509111794

Epoch: 5| Step: 7
Training loss: 1.2110137939453125
Validation loss: 1.951675126629491

Epoch: 5| Step: 8
Training loss: 1.7708944082260132
Validation loss: 1.9602429969336397

Epoch: 5| Step: 9
Training loss: 1.1371383666992188
Validation loss: 1.9502126850107664

Epoch: 5| Step: 10
Training loss: 1.0508947372436523
Validation loss: 1.9904311062187277

Epoch: 519| Step: 0
Training loss: 0.8548195958137512
Validation loss: 1.979068015211372

Epoch: 5| Step: 1
Training loss: 1.356452465057373
Validation loss: 1.9577393275435253

Epoch: 5| Step: 2
Training loss: 1.9666820764541626
Validation loss: 1.9660781147659465

Epoch: 5| Step: 3
Training loss: 1.453006386756897
Validation loss: 1.9798025200443883

Epoch: 5| Step: 4
Training loss: 0.8988431692123413
Validation loss: 1.96432239009488

Epoch: 5| Step: 5
Training loss: 0.9314213991165161
Validation loss: 1.9450342603909072

Epoch: 5| Step: 6
Training loss: 2.0418038368225098
Validation loss: 1.9876571957783034

Epoch: 5| Step: 7
Training loss: 1.6379978656768799
Validation loss: 1.9727934509195306

Epoch: 5| Step: 8
Training loss: 1.4546349048614502
Validation loss: 1.9536430374268563

Epoch: 5| Step: 9
Training loss: 1.5455971956253052
Validation loss: 2.007146543072116

Epoch: 5| Step: 10
Training loss: 1.1036367416381836
Validation loss: 1.990674190623786

Epoch: 520| Step: 0
Training loss: 1.5428743362426758
Validation loss: 2.029543774102324

Epoch: 5| Step: 1
Training loss: 1.456032395362854
Validation loss: 1.9609166909289617

Epoch: 5| Step: 2
Training loss: 1.0875619649887085
Validation loss: 1.9988952990501159

Epoch: 5| Step: 3
Training loss: 0.9782848358154297
Validation loss: 1.9828888626508816

Epoch: 5| Step: 4
Training loss: 2.116176128387451
Validation loss: 1.9456488573422996

Epoch: 5| Step: 5
Training loss: 1.4824130535125732
Validation loss: 1.982579783726764

Epoch: 5| Step: 6
Training loss: 1.7976922988891602
Validation loss: 2.0197707299263246

Epoch: 5| Step: 7
Training loss: 0.9946422576904297
Validation loss: 1.9947082547731296

Epoch: 5| Step: 8
Training loss: 0.9314934015274048
Validation loss: 1.9955755420910415

Epoch: 5| Step: 9
Training loss: 1.4626352787017822
Validation loss: 2.0112065089646207

Epoch: 5| Step: 10
Training loss: 1.7461724281311035
Validation loss: 1.94934098182186

Epoch: 521| Step: 0
Training loss: 1.0542500019073486
Validation loss: 2.0029819832053235

Epoch: 5| Step: 1
Training loss: 1.5399407148361206
Validation loss: 1.9816394698235296

Epoch: 5| Step: 2
Training loss: 1.131548523902893
Validation loss: 1.9750807926218996

Epoch: 5| Step: 3
Training loss: 1.4133052825927734
Validation loss: 1.9810645234200261

Epoch: 5| Step: 4
Training loss: 1.1934483051300049
Validation loss: 2.0064296940321564

Epoch: 5| Step: 5
Training loss: 1.952135443687439
Validation loss: 1.981630640645181

Epoch: 5| Step: 6
Training loss: 1.3796266317367554
Validation loss: 1.9732343842906337

Epoch: 5| Step: 7
Training loss: 0.8420864939689636
Validation loss: 1.9766661236363072

Epoch: 5| Step: 8
Training loss: 1.5212892293930054
Validation loss: 1.9694063304572977

Epoch: 5| Step: 9
Training loss: 1.8536611795425415
Validation loss: 1.955837813756799

Epoch: 5| Step: 10
Training loss: 1.5319324731826782
Validation loss: 1.947388356731784

Epoch: 522| Step: 0
Training loss: 1.3299545049667358
Validation loss: 1.9186872936064197

Epoch: 5| Step: 1
Training loss: 0.8990875482559204
Validation loss: 2.0312937844184136

Epoch: 5| Step: 2
Training loss: 1.3047676086425781
Validation loss: 1.9698161476401872

Epoch: 5| Step: 3
Training loss: 1.129326581954956
Validation loss: 1.945316017314952

Epoch: 5| Step: 4
Training loss: 1.1521804332733154
Validation loss: 1.977035234051366

Epoch: 5| Step: 5
Training loss: 0.9889472126960754
Validation loss: 1.984494863017913

Epoch: 5| Step: 6
Training loss: 2.0298690795898438
Validation loss: 1.9680575068278978

Epoch: 5| Step: 7
Training loss: 1.704464316368103
Validation loss: 2.0191799030509046

Epoch: 5| Step: 8
Training loss: 1.2973792552947998
Validation loss: 1.940730994747531

Epoch: 5| Step: 9
Training loss: 1.67043137550354
Validation loss: 1.9908943688997658

Epoch: 5| Step: 10
Training loss: 1.9415197372436523
Validation loss: 1.9417875838536087

Epoch: 523| Step: 0
Training loss: 1.5889595746994019
Validation loss: 1.972285113027019

Epoch: 5| Step: 1
Training loss: 1.5367825031280518
Validation loss: 1.983820176893665

Epoch: 5| Step: 2
Training loss: 1.0291082859039307
Validation loss: 1.9709614579395582

Epoch: 5| Step: 3
Training loss: 1.220349669456482
Validation loss: 1.9552761944391395

Epoch: 5| Step: 4
Training loss: 1.3903182744979858
Validation loss: 1.9639899333318074

Epoch: 5| Step: 5
Training loss: 1.737953543663025
Validation loss: 1.9606591296452347

Epoch: 5| Step: 6
Training loss: 1.1257688999176025
Validation loss: 1.9422456192713913

Epoch: 5| Step: 7
Training loss: 1.678694725036621
Validation loss: 1.966066696310556

Epoch: 5| Step: 8
Training loss: 1.3195916414260864
Validation loss: 1.9724933088466685

Epoch: 5| Step: 9
Training loss: 1.07233726978302
Validation loss: 1.9553666089170723

Epoch: 5| Step: 10
Training loss: 1.843441367149353
Validation loss: 1.977864937115741

Epoch: 524| Step: 0
Training loss: 1.4282548427581787
Validation loss: 1.9904337185685352

Epoch: 5| Step: 1
Training loss: 0.8969423174858093
Validation loss: 1.9811474559127644

Epoch: 5| Step: 2
Training loss: 1.1709020137786865
Validation loss: 1.970501015263219

Epoch: 5| Step: 3
Training loss: 1.254633903503418
Validation loss: 2.0093640255671676

Epoch: 5| Step: 4
Training loss: 2.154630184173584
Validation loss: 2.011469033456618

Epoch: 5| Step: 5
Training loss: 1.430738091468811
Validation loss: 1.985100874336817

Epoch: 5| Step: 6
Training loss: 1.4924163818359375
Validation loss: 2.0058756656544183

Epoch: 5| Step: 7
Training loss: 1.6105200052261353
Validation loss: 1.9901546278307516

Epoch: 5| Step: 8
Training loss: 1.3914378881454468
Validation loss: 1.994630302152326

Epoch: 5| Step: 9
Training loss: 1.8775923252105713
Validation loss: 1.9693889182101014

Epoch: 5| Step: 10
Training loss: 0.9129418730735779
Validation loss: 1.980205306442835

Epoch: 525| Step: 0
Training loss: 1.6276826858520508
Validation loss: 1.969025558040988

Epoch: 5| Step: 1
Training loss: 1.0089037418365479
Validation loss: 1.94445752328442

Epoch: 5| Step: 2
Training loss: 1.950321912765503
Validation loss: 1.9805568290013138

Epoch: 5| Step: 3
Training loss: 0.9988190531730652
Validation loss: 1.9365004442071403

Epoch: 5| Step: 4
Training loss: 1.0842359066009521
Validation loss: 1.9506950955237112

Epoch: 5| Step: 5
Training loss: 1.7384132146835327
Validation loss: 1.988510311290782

Epoch: 5| Step: 6
Training loss: 1.5924006700515747
Validation loss: 1.9366678550679197

Epoch: 5| Step: 7
Training loss: 1.919463872909546
Validation loss: 1.9569593168074084

Epoch: 5| Step: 8
Training loss: 1.1168599128723145
Validation loss: 1.9880406113081082

Epoch: 5| Step: 9
Training loss: 1.0166981220245361
Validation loss: 1.9394231816773773

Epoch: 5| Step: 10
Training loss: 1.396397590637207
Validation loss: 1.9423514053385744

Epoch: 526| Step: 0
Training loss: 1.0268023014068604
Validation loss: 1.987988406612027

Epoch: 5| Step: 1
Training loss: 1.2897387742996216
Validation loss: 1.982117417038128

Epoch: 5| Step: 2
Training loss: 0.9191209077835083
Validation loss: 1.9555938884776125

Epoch: 5| Step: 3
Training loss: 1.405470609664917
Validation loss: 1.9626928990887058

Epoch: 5| Step: 4
Training loss: 1.3695154190063477
Validation loss: 1.980637445244738

Epoch: 5| Step: 5
Training loss: 2.2851085662841797
Validation loss: 1.944742557823017

Epoch: 5| Step: 6
Training loss: 0.9239870309829712
Validation loss: 1.9832511691636936

Epoch: 5| Step: 7
Training loss: 1.8017278909683228
Validation loss: 1.9703663677297614

Epoch: 5| Step: 8
Training loss: 1.6967664957046509
Validation loss: 1.9588114856391825

Epoch: 5| Step: 9
Training loss: 1.3287622928619385
Validation loss: 2.0148179300369753

Epoch: 5| Step: 10
Training loss: 1.2749171257019043
Validation loss: 1.9780448969974314

Epoch: 527| Step: 0
Training loss: 1.9853347539901733
Validation loss: 2.006967775283321

Epoch: 5| Step: 1
Training loss: 1.000541090965271
Validation loss: 1.9980663778961345

Epoch: 5| Step: 2
Training loss: 1.4118276834487915
Validation loss: 2.0038064013245287

Epoch: 5| Step: 3
Training loss: 1.2436288595199585
Validation loss: 1.9861409382153583

Epoch: 5| Step: 4
Training loss: 1.45747971534729
Validation loss: 2.0253995464694117

Epoch: 5| Step: 5
Training loss: 0.7086778879165649
Validation loss: 1.9824317616801108

Epoch: 5| Step: 6
Training loss: 1.5078102350234985
Validation loss: 1.965844088985074

Epoch: 5| Step: 7
Training loss: 1.3234645128250122
Validation loss: 1.9569343136202904

Epoch: 5| Step: 8
Training loss: 1.123550295829773
Validation loss: 1.9623344739278157

Epoch: 5| Step: 9
Training loss: 1.8186582326889038
Validation loss: 2.018874083795855

Epoch: 5| Step: 10
Training loss: 1.7032630443572998
Validation loss: 2.0075114491165325

Epoch: 528| Step: 0
Training loss: 1.4905407428741455
Validation loss: 1.9767617692229569

Epoch: 5| Step: 1
Training loss: 1.2708587646484375
Validation loss: 1.9709811133723105

Epoch: 5| Step: 2
Training loss: 1.950347900390625
Validation loss: 1.97560546218708

Epoch: 5| Step: 3
Training loss: 1.015212059020996
Validation loss: 2.0142338839910363

Epoch: 5| Step: 4
Training loss: 1.6911661624908447
Validation loss: 1.971328693051492

Epoch: 5| Step: 5
Training loss: 1.265251874923706
Validation loss: 1.9893507790821854

Epoch: 5| Step: 6
Training loss: 0.947749137878418
Validation loss: 1.981300788540994

Epoch: 5| Step: 7
Training loss: 1.353376865386963
Validation loss: 1.9663410225222189

Epoch: 5| Step: 8
Training loss: 1.7092187404632568
Validation loss: 1.951104341014739

Epoch: 5| Step: 9
Training loss: 1.4914605617523193
Validation loss: 1.9558089663905482

Epoch: 5| Step: 10
Training loss: 1.1181412935256958
Validation loss: 1.9713800696916477

Epoch: 529| Step: 0
Training loss: 1.407753348350525
Validation loss: 1.9761054195383543

Epoch: 5| Step: 1
Training loss: 1.7402775287628174
Validation loss: 1.9514437593439573

Epoch: 5| Step: 2
Training loss: 1.2968227863311768
Validation loss: 1.9784171504359092

Epoch: 5| Step: 3
Training loss: 1.581018090248108
Validation loss: 1.9699927132616761

Epoch: 5| Step: 4
Training loss: 1.1603120565414429
Validation loss: 1.9572682739585958

Epoch: 5| Step: 5
Training loss: 1.214961051940918
Validation loss: 1.989900432607179

Epoch: 5| Step: 6
Training loss: 1.7966434955596924
Validation loss: 1.9667131003513132

Epoch: 5| Step: 7
Training loss: 1.8943061828613281
Validation loss: 1.9774404161719865

Epoch: 5| Step: 8
Training loss: 1.4703782796859741
Validation loss: 1.9307838639905375

Epoch: 5| Step: 9
Training loss: 0.9573691487312317
Validation loss: 1.9523400440010974

Epoch: 5| Step: 10
Training loss: 0.9062168002128601
Validation loss: 1.9681910853232107

Epoch: 530| Step: 0
Training loss: 1.5312070846557617
Validation loss: 1.9636961901059715

Epoch: 5| Step: 1
Training loss: 1.129956841468811
Validation loss: 1.9768321591038858

Epoch: 5| Step: 2
Training loss: 1.3650047779083252
Validation loss: 1.9951589671514367

Epoch: 5| Step: 3
Training loss: 1.2231690883636475
Validation loss: 1.9754811897072742

Epoch: 5| Step: 4
Training loss: 1.778085470199585
Validation loss: 1.9920707479599984

Epoch: 5| Step: 5
Training loss: 1.4192860126495361
Validation loss: 1.9768262229939944

Epoch: 5| Step: 6
Training loss: 1.3787935972213745
Validation loss: 1.9809690419063772

Epoch: 5| Step: 7
Training loss: 1.3526355028152466
Validation loss: 1.971626304811047

Epoch: 5| Step: 8
Training loss: 1.3832849264144897
Validation loss: 1.975096530811761

Epoch: 5| Step: 9
Training loss: 1.3651409149169922
Validation loss: 1.9635670294043839

Epoch: 5| Step: 10
Training loss: 1.5019117593765259
Validation loss: 1.991501526166034

Epoch: 531| Step: 0
Training loss: 1.0095106363296509
Validation loss: 1.9867595203461186

Epoch: 5| Step: 1
Training loss: 1.181289792060852
Validation loss: 1.941078556481228

Epoch: 5| Step: 2
Training loss: 2.122436046600342
Validation loss: 1.954582336128399

Epoch: 5| Step: 3
Training loss: 1.1724210977554321
Validation loss: 1.98140590037069

Epoch: 5| Step: 4
Training loss: 1.1827058792114258
Validation loss: 1.9853592303491407

Epoch: 5| Step: 5
Training loss: 1.6799907684326172
Validation loss: 1.9713146712190361

Epoch: 5| Step: 6
Training loss: 1.5580463409423828
Validation loss: 1.9147367438962382

Epoch: 5| Step: 7
Training loss: 1.3426254987716675
Validation loss: 1.9489307198473202

Epoch: 5| Step: 8
Training loss: 1.0860016345977783
Validation loss: 2.011603605362677

Epoch: 5| Step: 9
Training loss: 1.9064209461212158
Validation loss: 1.9731229043775989

Epoch: 5| Step: 10
Training loss: 1.092352271080017
Validation loss: 1.9810537599748181

Epoch: 532| Step: 0
Training loss: 1.4314956665039062
Validation loss: 1.9721629875962452

Epoch: 5| Step: 1
Training loss: 1.1083790063858032
Validation loss: 1.9580826208155642

Epoch: 5| Step: 2
Training loss: 1.4179385900497437
Validation loss: 1.9918574005044916

Epoch: 5| Step: 3
Training loss: 1.4844456911087036
Validation loss: 2.00808891173332

Epoch: 5| Step: 4
Training loss: 1.7521041631698608
Validation loss: 2.000596525848553

Epoch: 5| Step: 5
Training loss: 1.1274478435516357
Validation loss: 1.9724479183073966

Epoch: 5| Step: 6
Training loss: 1.6858211755752563
Validation loss: 2.0397559430009577

Epoch: 5| Step: 7
Training loss: 1.67496657371521
Validation loss: 1.9734795247354815

Epoch: 5| Step: 8
Training loss: 1.4809378385543823
Validation loss: 1.9566710341361262

Epoch: 5| Step: 9
Training loss: 0.7489898800849915
Validation loss: 1.9606888704402472

Epoch: 5| Step: 10
Training loss: 1.2706317901611328
Validation loss: 1.9746548219393658

Epoch: 533| Step: 0
Training loss: 1.6820634603500366
Validation loss: 1.986076170398343

Epoch: 5| Step: 1
Training loss: 2.0474631786346436
Validation loss: 1.9733530270156039

Epoch: 5| Step: 2
Training loss: 1.6885713338851929
Validation loss: 1.9963796125945223

Epoch: 5| Step: 3
Training loss: 1.4423872232437134
Validation loss: 1.966923959793583

Epoch: 5| Step: 4
Training loss: 0.9863009452819824
Validation loss: 1.9588767072205902

Epoch: 5| Step: 5
Training loss: 1.0205289125442505
Validation loss: 2.0213468766981557

Epoch: 5| Step: 6
Training loss: 1.4039218425750732
Validation loss: 1.9541693784857308

Epoch: 5| Step: 7
Training loss: 1.3323800563812256
Validation loss: 1.9793650232335573

Epoch: 5| Step: 8
Training loss: 1.3840572834014893
Validation loss: 1.9328799299014512

Epoch: 5| Step: 9
Training loss: 1.401029348373413
Validation loss: 1.9632139077750586

Epoch: 5| Step: 10
Training loss: 1.1597341299057007
Validation loss: 1.9624706032455608

Epoch: 534| Step: 0
Training loss: 1.1459214687347412
Validation loss: 1.9731206124828709

Epoch: 5| Step: 1
Training loss: 1.5749610662460327
Validation loss: 1.982156140829927

Epoch: 5| Step: 2
Training loss: 1.5662376880645752
Validation loss: 1.972103367569626

Epoch: 5| Step: 3
Training loss: 1.6577932834625244
Validation loss: 1.9661934914127472

Epoch: 5| Step: 4
Training loss: 1.169651746749878
Validation loss: 1.9541219716430993

Epoch: 5| Step: 5
Training loss: 1.3291776180267334
Validation loss: 2.0022734339519213

Epoch: 5| Step: 6
Training loss: 1.0909597873687744
Validation loss: 1.9976012668301981

Epoch: 5| Step: 7
Training loss: 1.8884632587432861
Validation loss: 1.9944488553590671

Epoch: 5| Step: 8
Training loss: 1.8172270059585571
Validation loss: 2.0251347877646007

Epoch: 5| Step: 9
Training loss: 0.6887787580490112
Validation loss: 1.9965588751659598

Epoch: 5| Step: 10
Training loss: 1.5404694080352783
Validation loss: 1.9638913613493725

Epoch: 535| Step: 0
Training loss: 0.9043973088264465
Validation loss: 1.9915755884621733

Epoch: 5| Step: 1
Training loss: 1.0929914712905884
Validation loss: 1.9604987713598436

Epoch: 5| Step: 2
Training loss: 1.357031226158142
Validation loss: 1.9626700621779247

Epoch: 5| Step: 3
Training loss: 1.8405319452285767
Validation loss: 1.9691222226747902

Epoch: 5| Step: 4
Training loss: 1.2142691612243652
Validation loss: 1.976848453603765

Epoch: 5| Step: 5
Training loss: 1.671405553817749
Validation loss: 1.9883856901558496

Epoch: 5| Step: 6
Training loss: 1.1415716409683228
Validation loss: 1.950622872639728

Epoch: 5| Step: 7
Training loss: 1.703051209449768
Validation loss: 1.9617069485366985

Epoch: 5| Step: 8
Training loss: 1.3481301069259644
Validation loss: 1.9428581999194237

Epoch: 5| Step: 9
Training loss: 1.7168018817901611
Validation loss: 1.9362862674138879

Epoch: 5| Step: 10
Training loss: 1.3989063501358032
Validation loss: 1.9498837250535206

Epoch: 536| Step: 0
Training loss: 1.862009048461914
Validation loss: 1.9401749282754877

Epoch: 5| Step: 1
Training loss: 1.5623061656951904
Validation loss: 1.9737039701912993

Epoch: 5| Step: 2
Training loss: 1.1821255683898926
Validation loss: 1.9656935289341917

Epoch: 5| Step: 3
Training loss: 1.8483104705810547
Validation loss: 1.971732121641918

Epoch: 5| Step: 4
Training loss: 1.604186773300171
Validation loss: 1.9652964902180496

Epoch: 5| Step: 5
Training loss: 1.5468437671661377
Validation loss: 1.9533508695581907

Epoch: 5| Step: 6
Training loss: 0.6652891039848328
Validation loss: 1.9939294092116817

Epoch: 5| Step: 7
Training loss: 0.8538801074028015
Validation loss: 2.0329827108690814

Epoch: 5| Step: 8
Training loss: 1.2816925048828125
Validation loss: 1.943554852598457

Epoch: 5| Step: 9
Training loss: 1.572561502456665
Validation loss: 1.981837321353215

Epoch: 5| Step: 10
Training loss: 1.6121931076049805
Validation loss: 1.9516428414211477

Epoch: 537| Step: 0
Training loss: 1.1771202087402344
Validation loss: 1.9728561780786003

Epoch: 5| Step: 1
Training loss: 1.1717389822006226
Validation loss: 1.9702289899190266

Epoch: 5| Step: 2
Training loss: 1.7930883169174194
Validation loss: 1.9869322815249044

Epoch: 5| Step: 3
Training loss: 1.340591549873352
Validation loss: 1.96293197395981

Epoch: 5| Step: 4
Training loss: 1.5790770053863525
Validation loss: 1.9396952634216638

Epoch: 5| Step: 5
Training loss: 1.9657903909683228
Validation loss: 1.9448007588745446

Epoch: 5| Step: 6
Training loss: 1.6917941570281982
Validation loss: 1.9892432997303624

Epoch: 5| Step: 7
Training loss: 1.0582164525985718
Validation loss: 1.948951755800555

Epoch: 5| Step: 8
Training loss: 1.4295237064361572
Validation loss: 1.9674491574687343

Epoch: 5| Step: 9
Training loss: 1.1129382848739624
Validation loss: 1.954248559090399

Epoch: 5| Step: 10
Training loss: 1.043342113494873
Validation loss: 1.971243139236204

Epoch: 538| Step: 0
Training loss: 1.3708593845367432
Validation loss: 1.9865047444579422

Epoch: 5| Step: 1
Training loss: 1.0153627395629883
Validation loss: 1.9965802392651957

Epoch: 5| Step: 2
Training loss: 1.6754562854766846
Validation loss: 1.9926735406280847

Epoch: 5| Step: 3
Training loss: 0.9832102656364441
Validation loss: 1.9630869357816634

Epoch: 5| Step: 4
Training loss: 1.5537049770355225
Validation loss: 1.975407354293331

Epoch: 5| Step: 5
Training loss: 1.5505541563034058
Validation loss: 1.937910714457112

Epoch: 5| Step: 6
Training loss: 1.83929443359375
Validation loss: 1.9755318344280284

Epoch: 5| Step: 7
Training loss: 1.4215474128723145
Validation loss: 1.9834675788879395

Epoch: 5| Step: 8
Training loss: 1.2401999235153198
Validation loss: 1.9742815545810166

Epoch: 5| Step: 9
Training loss: 1.4388103485107422
Validation loss: 1.965632470705176

Epoch: 5| Step: 10
Training loss: 0.9480813145637512
Validation loss: 1.9804084557358936

Epoch: 539| Step: 0
Training loss: 0.948254406452179
Validation loss: 1.979626747869676

Epoch: 5| Step: 1
Training loss: 1.4029314517974854
Validation loss: 2.005701070190758

Epoch: 5| Step: 2
Training loss: 1.4566255807876587
Validation loss: 1.9242296834145822

Epoch: 5| Step: 3
Training loss: 0.8558366894721985
Validation loss: 1.9571355376192319

Epoch: 5| Step: 4
Training loss: 1.524226427078247
Validation loss: 1.977283570074266

Epoch: 5| Step: 5
Training loss: 1.5854241847991943
Validation loss: 1.997273354120152

Epoch: 5| Step: 6
Training loss: 1.8083546161651611
Validation loss: 1.9482792859436364

Epoch: 5| Step: 7
Training loss: 1.992418646812439
Validation loss: 1.9825883917911078

Epoch: 5| Step: 8
Training loss: 1.1828755140304565
Validation loss: 1.9737913326550556

Epoch: 5| Step: 9
Training loss: 1.2166714668273926
Validation loss: 1.9697433453734203

Epoch: 5| Step: 10
Training loss: 1.1026028394699097
Validation loss: 1.9989723185057282

Epoch: 540| Step: 0
Training loss: 1.314457893371582
Validation loss: 1.9918756254257695

Epoch: 5| Step: 1
Training loss: 1.32038152217865
Validation loss: 1.979444993439541

Epoch: 5| Step: 2
Training loss: 0.5692502856254578
Validation loss: 2.001914939572734

Epoch: 5| Step: 3
Training loss: 2.0890514850616455
Validation loss: 2.0000798394603114

Epoch: 5| Step: 4
Training loss: 1.8613135814666748
Validation loss: 1.9644446193530996

Epoch: 5| Step: 5
Training loss: 1.0328482389450073
Validation loss: 1.99875553705359

Epoch: 5| Step: 6
Training loss: 1.499132752418518
Validation loss: 1.997598421189093

Epoch: 5| Step: 7
Training loss: 1.8642518520355225
Validation loss: 2.0030924761167137

Epoch: 5| Step: 8
Training loss: 1.4748708009719849
Validation loss: 1.9467716383677658

Epoch: 5| Step: 9
Training loss: 0.9556361436843872
Validation loss: 1.9557394404565134

Epoch: 5| Step: 10
Training loss: 1.1398204565048218
Validation loss: 1.959860755551246

Epoch: 541| Step: 0
Training loss: 1.9488770961761475
Validation loss: 1.9845932376000188

Epoch: 5| Step: 1
Training loss: 1.5424025058746338
Validation loss: 1.972460131491384

Epoch: 5| Step: 2
Training loss: 1.2366197109222412
Validation loss: 1.9741710744878298

Epoch: 5| Step: 3
Training loss: 1.5192348957061768
Validation loss: 1.9738653808511712

Epoch: 5| Step: 4
Training loss: 0.7257739305496216
Validation loss: 1.987068631315744

Epoch: 5| Step: 5
Training loss: 1.2978713512420654
Validation loss: 1.989674557921707

Epoch: 5| Step: 6
Training loss: 1.1905550956726074
Validation loss: 2.015303921955888

Epoch: 5| Step: 7
Training loss: 1.221540093421936
Validation loss: 2.00609153573231

Epoch: 5| Step: 8
Training loss: 1.7079896926879883
Validation loss: 1.955490614778252

Epoch: 5| Step: 9
Training loss: 1.4444137811660767
Validation loss: 1.9609335032842492

Epoch: 5| Step: 10
Training loss: 1.3696956634521484
Validation loss: 1.9869215590979463

Epoch: 542| Step: 0
Training loss: 1.5822117328643799
Validation loss: 1.9845374655979935

Epoch: 5| Step: 1
Training loss: 1.1385066509246826
Validation loss: 1.9667454509324924

Epoch: 5| Step: 2
Training loss: 1.60686457157135
Validation loss: 1.9788393564121698

Epoch: 5| Step: 3
Training loss: 0.856778621673584
Validation loss: 1.990083566275976

Epoch: 5| Step: 4
Training loss: 1.5367543697357178
Validation loss: 1.976594542944303

Epoch: 5| Step: 5
Training loss: 1.8382915258407593
Validation loss: 1.9795518895631194

Epoch: 5| Step: 6
Training loss: 1.1698167324066162
Validation loss: 1.9616800610737135

Epoch: 5| Step: 7
Training loss: 1.3421916961669922
Validation loss: 1.980880557849843

Epoch: 5| Step: 8
Training loss: 1.195034384727478
Validation loss: 1.9830781644390476

Epoch: 5| Step: 9
Training loss: 1.7606933116912842
Validation loss: 1.9423057635625203

Epoch: 5| Step: 10
Training loss: 1.5425348281860352
Validation loss: 1.9845656669268044

Epoch: 543| Step: 0
Training loss: 1.260560154914856
Validation loss: 1.9676222929390528

Epoch: 5| Step: 1
Training loss: 1.4789384603500366
Validation loss: 1.932792858410907

Epoch: 5| Step: 2
Training loss: 1.6576976776123047
Validation loss: 1.9462403866552538

Epoch: 5| Step: 3
Training loss: 1.3285080194473267
Validation loss: 1.9903799769698933

Epoch: 5| Step: 4
Training loss: 1.0158216953277588
Validation loss: 1.979244056568351

Epoch: 5| Step: 5
Training loss: 1.59457266330719
Validation loss: 1.97215852942518

Epoch: 5| Step: 6
Training loss: 1.4944196939468384
Validation loss: 1.956437014764355

Epoch: 5| Step: 7
Training loss: 1.3110233545303345
Validation loss: 1.930115266512799

Epoch: 5| Step: 8
Training loss: 1.106497049331665
Validation loss: 1.9500017396865352

Epoch: 5| Step: 9
Training loss: 1.032700777053833
Validation loss: 1.9286678850009877

Epoch: 5| Step: 10
Training loss: 2.100950002670288
Validation loss: 1.96446354158463

Epoch: 544| Step: 0
Training loss: 1.4154162406921387
Validation loss: 1.9820531004218644

Epoch: 5| Step: 1
Training loss: 1.2686808109283447
Validation loss: 1.9728583238458122

Epoch: 5| Step: 2
Training loss: 1.3176844120025635
Validation loss: 1.9467528315000637

Epoch: 5| Step: 3
Training loss: 1.4079787731170654
Validation loss: 1.985781446579964

Epoch: 5| Step: 4
Training loss: 1.169622540473938
Validation loss: 1.976387736617878

Epoch: 5| Step: 5
Training loss: 1.6885687112808228
Validation loss: 1.9910458069975658

Epoch: 5| Step: 6
Training loss: 1.2617706060409546
Validation loss: 1.986349650608596

Epoch: 5| Step: 7
Training loss: 1.1302731037139893
Validation loss: 1.9754545175901024

Epoch: 5| Step: 8
Training loss: 1.4736661911010742
Validation loss: 1.975759812580642

Epoch: 5| Step: 9
Training loss: 1.1163899898529053
Validation loss: 1.9460601704095

Epoch: 5| Step: 10
Training loss: 1.8378795385360718
Validation loss: 1.9451096775711223

Epoch: 545| Step: 0
Training loss: 1.510719656944275
Validation loss: 1.9740864076922018

Epoch: 5| Step: 1
Training loss: 1.226481318473816
Validation loss: 1.9810810730021486

Epoch: 5| Step: 2
Training loss: 1.659964919090271
Validation loss: 1.9350435759431572

Epoch: 5| Step: 3
Training loss: 1.6357157230377197
Validation loss: 1.9960029868669407

Epoch: 5| Step: 4
Training loss: 1.0365588665008545
Validation loss: 1.9512636469256492

Epoch: 5| Step: 5
Training loss: 1.3795779943466187
Validation loss: 1.9596248339581233

Epoch: 5| Step: 6
Training loss: 1.286846399307251
Validation loss: 2.0106433681262437

Epoch: 5| Step: 7
Training loss: 1.7395225763320923
Validation loss: 1.9706796382063179

Epoch: 5| Step: 8
Training loss: 1.2060623168945312
Validation loss: 1.9775369859510852

Epoch: 5| Step: 9
Training loss: 0.9492351412773132
Validation loss: 1.9537097895017235

Epoch: 5| Step: 10
Training loss: 1.3339983224868774
Validation loss: 1.9426652910888835

Epoch: 546| Step: 0
Training loss: 1.300593376159668
Validation loss: 1.9599634575587448

Epoch: 5| Step: 1
Training loss: 1.060519814491272
Validation loss: 1.9984459428377048

Epoch: 5| Step: 2
Training loss: 1.426938772201538
Validation loss: 1.9897594272449453

Epoch: 5| Step: 3
Training loss: 1.2332854270935059
Validation loss: 1.9708262207687541

Epoch: 5| Step: 4
Training loss: 1.7756036520004272
Validation loss: 1.971495150237955

Epoch: 5| Step: 5
Training loss: 1.040552020072937
Validation loss: 1.98170215980981

Epoch: 5| Step: 6
Training loss: 1.1203298568725586
Validation loss: 1.9852241085421654

Epoch: 5| Step: 7
Training loss: 1.4099886417388916
Validation loss: 1.9680926671592138

Epoch: 5| Step: 8
Training loss: 1.530869722366333
Validation loss: 1.9793846043207313

Epoch: 5| Step: 9
Training loss: 1.4646961688995361
Validation loss: 1.9751826332461448

Epoch: 5| Step: 10
Training loss: 1.6454932689666748
Validation loss: 1.9385162194569905

Epoch: 547| Step: 0
Training loss: 1.0688103437423706
Validation loss: 1.9540368382648756

Epoch: 5| Step: 1
Training loss: 1.2276997566223145
Validation loss: 1.9716177807059339

Epoch: 5| Step: 2
Training loss: 1.0354654788970947
Validation loss: 1.9669338695464595

Epoch: 5| Step: 3
Training loss: 1.796677827835083
Validation loss: 1.9724496872194353

Epoch: 5| Step: 4
Training loss: 1.8923568725585938
Validation loss: 1.99591197506074

Epoch: 5| Step: 5
Training loss: 1.661825180053711
Validation loss: 1.9737475290093371

Epoch: 5| Step: 6
Training loss: 1.2848528623580933
Validation loss: 1.9769777841465448

Epoch: 5| Step: 7
Training loss: 0.6114690899848938
Validation loss: 1.9803842344591696

Epoch: 5| Step: 8
Training loss: 1.8025214672088623
Validation loss: 2.006470987873693

Epoch: 5| Step: 9
Training loss: 1.240052342414856
Validation loss: 1.9751013581470778

Epoch: 5| Step: 10
Training loss: 1.392250895500183
Validation loss: 1.9967003483926096

Epoch: 548| Step: 0
Training loss: 1.379949927330017
Validation loss: 1.9684872550349082

Epoch: 5| Step: 1
Training loss: 1.2274812459945679
Validation loss: 1.9723326672789872

Epoch: 5| Step: 2
Training loss: 1.5965925455093384
Validation loss: 1.9860733606482064

Epoch: 5| Step: 3
Training loss: 1.1661651134490967
Validation loss: 1.9763953173032371

Epoch: 5| Step: 4
Training loss: 0.7712951898574829
Validation loss: 1.9501323110313826

Epoch: 5| Step: 5
Training loss: 1.591583013534546
Validation loss: 1.9735435926786034

Epoch: 5| Step: 6
Training loss: 1.898075819015503
Validation loss: 1.9915344253663094

Epoch: 5| Step: 7
Training loss: 1.1845426559448242
Validation loss: 2.0043157480096303

Epoch: 5| Step: 8
Training loss: 1.0502073764801025
Validation loss: 1.9594178276677285

Epoch: 5| Step: 9
Training loss: 1.3461519479751587
Validation loss: 1.9492546736553151

Epoch: 5| Step: 10
Training loss: 1.9737406969070435
Validation loss: 1.9589757534765428

Epoch: 549| Step: 0
Training loss: 1.7041667699813843
Validation loss: 1.98213993605747

Epoch: 5| Step: 1
Training loss: 1.9141470193862915
Validation loss: 1.9821544642089515

Epoch: 5| Step: 2
Training loss: 1.0004703998565674
Validation loss: 1.9418222801659697

Epoch: 5| Step: 3
Training loss: 0.8025195002555847
Validation loss: 1.9633101750445623

Epoch: 5| Step: 4
Training loss: 1.4220556020736694
Validation loss: 1.9436589184627737

Epoch: 5| Step: 5
Training loss: 1.1482092142105103
Validation loss: 1.9563245311860116

Epoch: 5| Step: 6
Training loss: 1.642190933227539
Validation loss: 1.9483673393085439

Epoch: 5| Step: 7
Training loss: 1.6173681020736694
Validation loss: 1.9502159959526473

Epoch: 5| Step: 8
Training loss: 1.391701340675354
Validation loss: 1.9531489533762778

Epoch: 5| Step: 9
Training loss: 1.618316888809204
Validation loss: 1.9913164992486276

Epoch: 5| Step: 10
Training loss: 1.0687841176986694
Validation loss: 1.962276618967774

Epoch: 550| Step: 0
Training loss: 1.1958274841308594
Validation loss: 1.9514409803575086

Epoch: 5| Step: 1
Training loss: 1.4942500591278076
Validation loss: 1.9978031753211893

Epoch: 5| Step: 2
Training loss: 1.3841567039489746
Validation loss: 1.9802951197470389

Epoch: 5| Step: 3
Training loss: 1.306549310684204
Validation loss: 2.014929694514121

Epoch: 5| Step: 4
Training loss: 1.5765939950942993
Validation loss: 1.9986813401663175

Epoch: 5| Step: 5
Training loss: 1.6274057626724243
Validation loss: 1.9652792587075183

Epoch: 5| Step: 6
Training loss: 1.1632192134857178
Validation loss: 1.9860743527771325

Epoch: 5| Step: 7
Training loss: 1.5809940099716187
Validation loss: 1.9688790357241066

Epoch: 5| Step: 8
Training loss: 1.694827675819397
Validation loss: 1.975188885965655

Epoch: 5| Step: 9
Training loss: 1.1819356679916382
Validation loss: 1.9930550283001316

Epoch: 5| Step: 10
Training loss: 0.9263399839401245
Validation loss: 1.926148565866614

Epoch: 551| Step: 0
Training loss: 1.1126610040664673
Validation loss: 1.966643182180261

Epoch: 5| Step: 1
Training loss: 0.8492388725280762
Validation loss: 1.9749486702744679

Epoch: 5| Step: 2
Training loss: 1.843132734298706
Validation loss: 2.0027511132660734

Epoch: 5| Step: 3
Training loss: 1.3820531368255615
Validation loss: 1.9617796251850743

Epoch: 5| Step: 4
Training loss: 1.2913190126419067
Validation loss: 1.999416385927508

Epoch: 5| Step: 5
Training loss: 1.6437556743621826
Validation loss: 1.9769992264368201

Epoch: 5| Step: 6
Training loss: 1.4238160848617554
Validation loss: 1.9746733609066214

Epoch: 5| Step: 7
Training loss: 1.142622470855713
Validation loss: 1.9686882329243485

Epoch: 5| Step: 8
Training loss: 1.5449566841125488
Validation loss: 1.9267144613368536

Epoch: 5| Step: 9
Training loss: 1.5825517177581787
Validation loss: 1.9604094695019465

Epoch: 5| Step: 10
Training loss: 1.2032623291015625
Validation loss: 1.9896776214722665

Epoch: 552| Step: 0
Training loss: 1.5913312435150146
Validation loss: 1.9656353560827111

Epoch: 5| Step: 1
Training loss: 1.0778311491012573
Validation loss: 1.9902323074238275

Epoch: 5| Step: 2
Training loss: 1.206839919090271
Validation loss: 1.9771544888455381

Epoch: 5| Step: 3
Training loss: 0.962934136390686
Validation loss: 1.9562944237903883

Epoch: 5| Step: 4
Training loss: 0.7982264757156372
Validation loss: 1.9462508386181248

Epoch: 5| Step: 5
Training loss: 2.2008180618286133
Validation loss: 1.985229790851634

Epoch: 5| Step: 6
Training loss: 1.2429728507995605
Validation loss: 1.9506747056079168

Epoch: 5| Step: 7
Training loss: 1.7576706409454346
Validation loss: 1.9901392536778604

Epoch: 5| Step: 8
Training loss: 1.6415081024169922
Validation loss: 1.985652465974131

Epoch: 5| Step: 9
Training loss: 1.2033017873764038
Validation loss: 1.9812337019110238

Epoch: 5| Step: 10
Training loss: 1.3025996685028076
Validation loss: 1.9632061335348314

Epoch: 553| Step: 0
Training loss: 1.180512547492981
Validation loss: 2.016611785017034

Epoch: 5| Step: 1
Training loss: 1.5436923503875732
Validation loss: 1.9621162876006095

Epoch: 5| Step: 2
Training loss: 1.2190483808517456
Validation loss: 1.9605829305546258

Epoch: 5| Step: 3
Training loss: 1.4304836988449097
Validation loss: 1.964112671472693

Epoch: 5| Step: 4
Training loss: 1.4761990308761597
Validation loss: 1.9940365052992297

Epoch: 5| Step: 5
Training loss: 1.4391471147537231
Validation loss: 1.9787089106857136

Epoch: 5| Step: 6
Training loss: 2.120889663696289
Validation loss: 1.9453276229161087

Epoch: 5| Step: 7
Training loss: 1.2337185144424438
Validation loss: 1.9482148026907316

Epoch: 5| Step: 8
Training loss: 1.06512451171875
Validation loss: 1.9716826690140592

Epoch: 5| Step: 9
Training loss: 1.3614064455032349
Validation loss: 1.9492009634612708

Epoch: 5| Step: 10
Training loss: 1.0638723373413086
Validation loss: 2.0003318581529843

Epoch: 554| Step: 0
Training loss: 1.3552191257476807
Validation loss: 1.9409631554798414

Epoch: 5| Step: 1
Training loss: 1.2085717916488647
Validation loss: 1.9884205223411642

Epoch: 5| Step: 2
Training loss: 1.9078972339630127
Validation loss: 1.9613446868875974

Epoch: 5| Step: 3
Training loss: 0.9323007464408875
Validation loss: 1.9394874367662656

Epoch: 5| Step: 4
Training loss: 1.549126148223877
Validation loss: 1.9458712967493201

Epoch: 5| Step: 5
Training loss: 1.4465365409851074
Validation loss: 1.9708984436527375

Epoch: 5| Step: 6
Training loss: 1.3303762674331665
Validation loss: 1.95150887966156

Epoch: 5| Step: 7
Training loss: 1.2252922058105469
Validation loss: 1.9537777593058925

Epoch: 5| Step: 8
Training loss: 1.3804551362991333
Validation loss: 1.9475570737674672

Epoch: 5| Step: 9
Training loss: 1.6085485219955444
Validation loss: 1.993981288325402

Epoch: 5| Step: 10
Training loss: 1.2390986680984497
Validation loss: 1.9799863856325868

Epoch: 555| Step: 0
Training loss: 1.2352054119110107
Validation loss: 1.9604803849292058

Epoch: 5| Step: 1
Training loss: 1.4059455394744873
Validation loss: 1.951057941682877

Epoch: 5| Step: 2
Training loss: 1.0981205701828003
Validation loss: 1.9822693986277427

Epoch: 5| Step: 3
Training loss: 2.0256600379943848
Validation loss: 1.9602976857974965

Epoch: 5| Step: 4
Training loss: 1.6575355529785156
Validation loss: 1.9514644556148077

Epoch: 5| Step: 5
Training loss: 1.4574928283691406
Validation loss: 1.9594831235947148

Epoch: 5| Step: 6
Training loss: 1.3558634519577026
Validation loss: 1.9828120329046761

Epoch: 5| Step: 7
Training loss: 1.1058536767959595
Validation loss: 1.9977681149718582

Epoch: 5| Step: 8
Training loss: 0.9537178874015808
Validation loss: 1.9571182394540438

Epoch: 5| Step: 9
Training loss: 1.2220215797424316
Validation loss: 1.9897642340711368

Epoch: 5| Step: 10
Training loss: 1.3443827629089355
Validation loss: 1.9786570943811888

Epoch: 556| Step: 0
Training loss: 1.4637200832366943
Validation loss: 1.95826675814967

Epoch: 5| Step: 1
Training loss: 1.8921699523925781
Validation loss: 1.9380501162621282

Epoch: 5| Step: 2
Training loss: 1.3417727947235107
Validation loss: 1.9480182393904655

Epoch: 5| Step: 3
Training loss: 1.7428518533706665
Validation loss: 1.9738342454356532

Epoch: 5| Step: 4
Training loss: 0.9027679562568665
Validation loss: 1.9564295481610041

Epoch: 5| Step: 5
Training loss: 1.1676194667816162
Validation loss: 1.949076275671682

Epoch: 5| Step: 6
Training loss: 2.0430748462677
Validation loss: 1.9598002690140919

Epoch: 5| Step: 7
Training loss: 0.8894979357719421
Validation loss: 1.965362665473774

Epoch: 5| Step: 8
Training loss: 1.6693570613861084
Validation loss: 1.9689318877394482

Epoch: 5| Step: 9
Training loss: 1.1703646183013916
Validation loss: 1.9336649243549635

Epoch: 5| Step: 10
Training loss: 0.72232985496521
Validation loss: 1.9414054668077858

Epoch: 557| Step: 0
Training loss: 1.5726292133331299
Validation loss: 1.90593473885649

Epoch: 5| Step: 1
Training loss: 2.3062026500701904
Validation loss: 1.9549680473983928

Epoch: 5| Step: 2
Training loss: 1.3100080490112305
Validation loss: 1.9856839551720569

Epoch: 5| Step: 3
Training loss: 1.2557884454727173
Validation loss: 1.9856299905366794

Epoch: 5| Step: 4
Training loss: 0.9710088968276978
Validation loss: 1.9306906653988747

Epoch: 5| Step: 5
Training loss: 1.3011748790740967
Validation loss: 1.956737273482866

Epoch: 5| Step: 6
Training loss: 1.4611561298370361
Validation loss: 1.992476168499198

Epoch: 5| Step: 7
Training loss: 0.9562966227531433
Validation loss: 1.9714653133064188

Epoch: 5| Step: 8
Training loss: 1.5136510133743286
Validation loss: 1.9853965082476217

Epoch: 5| Step: 9
Training loss: 1.1024855375289917
Validation loss: 1.9826172295437063

Epoch: 5| Step: 10
Training loss: 1.0144683122634888
Validation loss: 1.9784368814960602

Epoch: 558| Step: 0
Training loss: 1.4336830377578735
Validation loss: 1.9744212255682996

Epoch: 5| Step: 1
Training loss: 1.4186351299285889
Validation loss: 2.0061530284984137

Epoch: 5| Step: 2
Training loss: 1.525666356086731
Validation loss: 1.992225553399773

Epoch: 5| Step: 3
Training loss: 1.186424970626831
Validation loss: 1.9971181423433366

Epoch: 5| Step: 4
Training loss: 1.0785199403762817
Validation loss: 1.96684088630061

Epoch: 5| Step: 5
Training loss: 1.9956012964248657
Validation loss: 1.9651426294798493

Epoch: 5| Step: 6
Training loss: 1.029043436050415
Validation loss: 1.9510274112865489

Epoch: 5| Step: 7
Training loss: 1.2998197078704834
Validation loss: 1.9879121959850352

Epoch: 5| Step: 8
Training loss: 0.9999368786811829
Validation loss: 2.0006176617837723

Epoch: 5| Step: 9
Training loss: 0.9686276316642761
Validation loss: 1.9519734933812132

Epoch: 5| Step: 10
Training loss: 1.9019190073013306
Validation loss: 1.9555195518719253

Epoch: 559| Step: 0
Training loss: 1.1424238681793213
Validation loss: 1.9396797405776156

Epoch: 5| Step: 1
Training loss: 1.7425493001937866
Validation loss: 1.9707628629540885

Epoch: 5| Step: 2
Training loss: 1.3211318254470825
Validation loss: 1.956537877359698

Epoch: 5| Step: 3
Training loss: 1.0721321105957031
Validation loss: 1.940688879259171

Epoch: 5| Step: 4
Training loss: 0.9065220952033997
Validation loss: 1.9331508528801702

Epoch: 5| Step: 5
Training loss: 1.4179068803787231
Validation loss: 1.989366405753679

Epoch: 5| Step: 6
Training loss: 1.3014380931854248
Validation loss: 1.9350599883705057

Epoch: 5| Step: 7
Training loss: 1.4285383224487305
Validation loss: 1.9252050922762962

Epoch: 5| Step: 8
Training loss: 1.3414818048477173
Validation loss: 1.9632392211626934

Epoch: 5| Step: 9
Training loss: 1.3385916948318481
Validation loss: 1.95047245230726

Epoch: 5| Step: 10
Training loss: 1.7652044296264648
Validation loss: 1.942853412320537

Epoch: 560| Step: 0
Training loss: 1.4972199201583862
Validation loss: 1.954089226261262

Epoch: 5| Step: 1
Training loss: 1.2694621086120605
Validation loss: 1.955256788961349

Epoch: 5| Step: 2
Training loss: 1.4880269765853882
Validation loss: 1.9550430928507159

Epoch: 5| Step: 3
Training loss: 0.7869786024093628
Validation loss: 2.0248084452844437

Epoch: 5| Step: 4
Training loss: 1.3468914031982422
Validation loss: 2.000483830769857

Epoch: 5| Step: 5
Training loss: 1.313474416732788
Validation loss: 1.9834765054846322

Epoch: 5| Step: 6
Training loss: 1.358662724494934
Validation loss: 2.0044655697320097

Epoch: 5| Step: 7
Training loss: 1.8965988159179688
Validation loss: 2.0345983428339802

Epoch: 5| Step: 8
Training loss: 1.1250754594802856
Validation loss: 1.9701367629471647

Epoch: 5| Step: 9
Training loss: 1.6517508029937744
Validation loss: 1.994305565793027

Epoch: 5| Step: 10
Training loss: 1.096024513244629
Validation loss: 1.9803964502067977

Epoch: 561| Step: 0
Training loss: 1.4742615222930908
Validation loss: 1.9751898755309403

Epoch: 5| Step: 1
Training loss: 1.559632658958435
Validation loss: 1.9571090334205217

Epoch: 5| Step: 2
Training loss: 1.0069029331207275
Validation loss: 1.960119560200681

Epoch: 5| Step: 3
Training loss: 0.9575458765029907
Validation loss: 1.9733335125830866

Epoch: 5| Step: 4
Training loss: 1.6397981643676758
Validation loss: 1.9351477956259122

Epoch: 5| Step: 5
Training loss: 1.7647144794464111
Validation loss: 1.9930897297397736

Epoch: 5| Step: 6
Training loss: 1.2734726667404175
Validation loss: 1.940921465555827

Epoch: 5| Step: 7
Training loss: 1.5160470008850098
Validation loss: 1.9866604407628377

Epoch: 5| Step: 8
Training loss: 1.2115615606307983
Validation loss: 1.94883563569797

Epoch: 5| Step: 9
Training loss: 1.3212162256240845
Validation loss: 1.9577551875063168

Epoch: 5| Step: 10
Training loss: 1.1247988939285278
Validation loss: 1.9654197462143437

Epoch: 562| Step: 0
Training loss: 1.165998935699463
Validation loss: 1.9746889363053024

Epoch: 5| Step: 1
Training loss: 1.4381300210952759
Validation loss: 1.9660936055644866

Epoch: 5| Step: 2
Training loss: 1.048948049545288
Validation loss: 1.9383744065479567

Epoch: 5| Step: 3
Training loss: 2.2420833110809326
Validation loss: 2.0006937903742634

Epoch: 5| Step: 4
Training loss: 1.696141004562378
Validation loss: 1.975968817228912

Epoch: 5| Step: 5
Training loss: 1.3714863061904907
Validation loss: 2.0284412355833155

Epoch: 5| Step: 6
Training loss: 1.3362293243408203
Validation loss: 1.9688103019550283

Epoch: 5| Step: 7
Training loss: 1.4337847232818604
Validation loss: 1.9739241497490996

Epoch: 5| Step: 8
Training loss: 1.1693321466445923
Validation loss: 2.0141794937913136

Epoch: 5| Step: 9
Training loss: 1.4361449480056763
Validation loss: 2.0215011258279123

Epoch: 5| Step: 10
Training loss: 0.8608340620994568
Validation loss: 1.9572281324735252

Epoch: 563| Step: 0
Training loss: 1.286000370979309
Validation loss: 1.9778945920287923

Epoch: 5| Step: 1
Training loss: 1.5756828784942627
Validation loss: 2.000131232764131

Epoch: 5| Step: 2
Training loss: 1.2465696334838867
Validation loss: 1.925218883381095

Epoch: 5| Step: 3
Training loss: 0.9195730090141296
Validation loss: 1.973349650700887

Epoch: 5| Step: 4
Training loss: 1.6091378927230835
Validation loss: 1.9913932892584032

Epoch: 5| Step: 5
Training loss: 1.6315746307373047
Validation loss: 1.999768191768277

Epoch: 5| Step: 6
Training loss: 1.0625293254852295
Validation loss: 1.957282688028069

Epoch: 5| Step: 7
Training loss: 1.4158883094787598
Validation loss: 1.9742858268881356

Epoch: 5| Step: 8
Training loss: 1.556870698928833
Validation loss: 1.95404863613908

Epoch: 5| Step: 9
Training loss: 1.3932369947433472
Validation loss: 1.8998860877047303

Epoch: 5| Step: 10
Training loss: 1.4597563743591309
Validation loss: 1.956093006236579

Epoch: 564| Step: 0
Training loss: 1.5298289060592651
Validation loss: 1.991276269317955

Epoch: 5| Step: 1
Training loss: 0.967218279838562
Validation loss: 1.9746207127007105

Epoch: 5| Step: 2
Training loss: 1.4177789688110352
Validation loss: 1.9579099711551462

Epoch: 5| Step: 3
Training loss: 1.419049620628357
Validation loss: 2.0172313567130797

Epoch: 5| Step: 4
Training loss: 1.4250924587249756
Validation loss: 1.9942387329634799

Epoch: 5| Step: 5
Training loss: 1.3227906227111816
Validation loss: 1.9724964505882674

Epoch: 5| Step: 6
Training loss: 1.3717612028121948
Validation loss: 2.000341128277522

Epoch: 5| Step: 7
Training loss: 1.1118342876434326
Validation loss: 2.003511231432679

Epoch: 5| Step: 8
Training loss: 1.3386482000350952
Validation loss: 2.0033493426538285

Epoch: 5| Step: 9
Training loss: 1.5531895160675049
Validation loss: 1.979691800250802

Epoch: 5| Step: 10
Training loss: 1.4944241046905518
Validation loss: 1.9210256017664427

Epoch: 565| Step: 0
Training loss: 1.1521137952804565
Validation loss: 1.9538157614328528

Epoch: 5| Step: 1
Training loss: 1.5638600587844849
Validation loss: 1.968869755345006

Epoch: 5| Step: 2
Training loss: 1.595910906791687
Validation loss: 1.983025545715004

Epoch: 5| Step: 3
Training loss: 1.5452735424041748
Validation loss: 1.9294399574238768

Epoch: 5| Step: 4
Training loss: 1.074338674545288
Validation loss: 1.977797628730856

Epoch: 5| Step: 5
Training loss: 1.3828679323196411
Validation loss: 1.9464432654842254

Epoch: 5| Step: 6
Training loss: 1.1035373210906982
Validation loss: 1.9774615380071825

Epoch: 5| Step: 7
Training loss: 1.1859521865844727
Validation loss: 1.9366747153702604

Epoch: 5| Step: 8
Training loss: 1.6994003057479858
Validation loss: 1.966454513611332

Epoch: 5| Step: 9
Training loss: 1.5241281986236572
Validation loss: 1.9669836977476716

Epoch: 5| Step: 10
Training loss: 1.0459734201431274
Validation loss: 1.949389160320323

Epoch: 566| Step: 0
Training loss: 1.0579712390899658
Validation loss: 1.9639150852798133

Epoch: 5| Step: 1
Training loss: 1.5393257141113281
Validation loss: 1.9342158071456417

Epoch: 5| Step: 2
Training loss: 1.3568987846374512
Validation loss: 1.9610611136241625

Epoch: 5| Step: 3
Training loss: 1.3179411888122559
Validation loss: 1.9721664626111266

Epoch: 5| Step: 4
Training loss: 1.1520403623580933
Validation loss: 1.9812684866689867

Epoch: 5| Step: 5
Training loss: 1.2124305963516235
Validation loss: 2.0094800815787366

Epoch: 5| Step: 6
Training loss: 1.703568458557129
Validation loss: 2.005400126980197

Epoch: 5| Step: 7
Training loss: 1.6419702768325806
Validation loss: 1.9544516763379496

Epoch: 5| Step: 8
Training loss: 0.9616131782531738
Validation loss: 1.9666992490009596

Epoch: 5| Step: 9
Training loss: 1.726621389389038
Validation loss: 1.9683365642383535

Epoch: 5| Step: 10
Training loss: 1.28842294216156
Validation loss: 1.9919226451586651

Epoch: 567| Step: 0
Training loss: 1.2331030368804932
Validation loss: 1.988085428873698

Epoch: 5| Step: 1
Training loss: 1.2327203750610352
Validation loss: 1.9753526872204197

Epoch: 5| Step: 2
Training loss: 1.1545464992523193
Validation loss: 1.9332399957923478

Epoch: 5| Step: 3
Training loss: 1.6134660243988037
Validation loss: 1.966983123492169

Epoch: 5| Step: 4
Training loss: 1.3832775354385376
Validation loss: 2.015925643264606

Epoch: 5| Step: 5
Training loss: 0.7533349394798279
Validation loss: 1.9670454878960886

Epoch: 5| Step: 6
Training loss: 1.160681962966919
Validation loss: 1.9642562456028436

Epoch: 5| Step: 7
Training loss: 1.0802286863327026
Validation loss: 1.959338959827218

Epoch: 5| Step: 8
Training loss: 1.8942569494247437
Validation loss: 1.983121798884484

Epoch: 5| Step: 9
Training loss: 1.6007626056671143
Validation loss: 1.989816575921992

Epoch: 5| Step: 10
Training loss: 1.5445537567138672
Validation loss: 1.9971772932237195

Epoch: 568| Step: 0
Training loss: 1.5154203176498413
Validation loss: 2.005218349477296

Epoch: 5| Step: 1
Training loss: 1.2355245351791382
Validation loss: 1.9913915408554899

Epoch: 5| Step: 2
Training loss: 1.9052484035491943
Validation loss: 1.9898828614142634

Epoch: 5| Step: 3
Training loss: 1.607861876487732
Validation loss: 2.004471416114479

Epoch: 5| Step: 4
Training loss: 1.611545205116272
Validation loss: 1.993245627290459

Epoch: 5| Step: 5
Training loss: 1.4513288736343384
Validation loss: 1.9521763017100673

Epoch: 5| Step: 6
Training loss: 0.9452935457229614
Validation loss: 1.9644778492630168

Epoch: 5| Step: 7
Training loss: 0.8491958379745483
Validation loss: 1.9613731099713234

Epoch: 5| Step: 8
Training loss: 1.1357967853546143
Validation loss: 1.9309168861758323

Epoch: 5| Step: 9
Training loss: 1.293680191040039
Validation loss: 1.9205825482645342

Epoch: 5| Step: 10
Training loss: 1.0934277772903442
Validation loss: 1.9810556801416541

Epoch: 569| Step: 0
Training loss: 1.2089478969573975
Validation loss: 1.9579324209561912

Epoch: 5| Step: 1
Training loss: 0.890241801738739
Validation loss: 1.9464007269951604

Epoch: 5| Step: 2
Training loss: 1.372765302658081
Validation loss: 1.9514432478976507

Epoch: 5| Step: 3
Training loss: 1.4116826057434082
Validation loss: 1.9805382656794723

Epoch: 5| Step: 4
Training loss: 1.1402130126953125
Validation loss: 1.979052706431317

Epoch: 5| Step: 5
Training loss: 1.430989146232605
Validation loss: 1.9664909147447156

Epoch: 5| Step: 6
Training loss: 1.472510576248169
Validation loss: 1.9723356577657885

Epoch: 5| Step: 7
Training loss: 1.260804295539856
Validation loss: 1.9816421437007126

Epoch: 5| Step: 8
Training loss: 1.576727271080017
Validation loss: 1.985688881207538

Epoch: 5| Step: 9
Training loss: 1.8033663034439087
Validation loss: 2.0092199451179913

Epoch: 5| Step: 10
Training loss: 1.0857590436935425
Validation loss: 1.963092759091367

Epoch: 570| Step: 0
Training loss: 1.194087028503418
Validation loss: 1.9881739026756697

Epoch: 5| Step: 1
Training loss: 1.154480218887329
Validation loss: 1.9520529777772966

Epoch: 5| Step: 2
Training loss: 1.51796555519104
Validation loss: 2.0264211893081665

Epoch: 5| Step: 3
Training loss: 1.4343328475952148
Validation loss: 2.0170109182275753

Epoch: 5| Step: 4
Training loss: 0.6139034032821655
Validation loss: 1.9598269231857792

Epoch: 5| Step: 5
Training loss: 1.9691331386566162
Validation loss: 1.9562237019179969

Epoch: 5| Step: 6
Training loss: 1.0617324113845825
Validation loss: 1.980982603565339

Epoch: 5| Step: 7
Training loss: 1.6131031513214111
Validation loss: 1.9799692848677277

Epoch: 5| Step: 8
Training loss: 1.2842776775360107
Validation loss: 1.9746156674559399

Epoch: 5| Step: 9
Training loss: 1.0930054187774658
Validation loss: 1.9758946664871708

Epoch: 5| Step: 10
Training loss: 1.6014829874038696
Validation loss: 1.9806622894861365

Epoch: 571| Step: 0
Training loss: 1.8259456157684326
Validation loss: 1.957136268256813

Epoch: 5| Step: 1
Training loss: 0.9742317199707031
Validation loss: 1.9605330408260386

Epoch: 5| Step: 2
Training loss: 1.3953109979629517
Validation loss: 1.9838231763532084

Epoch: 5| Step: 3
Training loss: 1.0102546215057373
Validation loss: 1.9880801259830434

Epoch: 5| Step: 4
Training loss: 0.8636506795883179
Validation loss: 1.9432672236555366

Epoch: 5| Step: 5
Training loss: 1.645874261856079
Validation loss: 1.9467625964072444

Epoch: 5| Step: 6
Training loss: 1.1410291194915771
Validation loss: 2.0031867270828574

Epoch: 5| Step: 7
Training loss: 1.6153854131698608
Validation loss: 1.9703192108420915

Epoch: 5| Step: 8
Training loss: 1.2596818208694458
Validation loss: 1.9711673644281202

Epoch: 5| Step: 9
Training loss: 1.804071068763733
Validation loss: 1.9639453862303047

Epoch: 5| Step: 10
Training loss: 1.1407804489135742
Validation loss: 1.9816134386165167

Epoch: 572| Step: 0
Training loss: 1.8635294437408447
Validation loss: 1.9284156035351496

Epoch: 5| Step: 1
Training loss: 1.0230469703674316
Validation loss: 1.9739095651975243

Epoch: 5| Step: 2
Training loss: 1.0295161008834839
Validation loss: 1.940910226555281

Epoch: 5| Step: 3
Training loss: 1.7558904886245728
Validation loss: 2.0003455582485405

Epoch: 5| Step: 4
Training loss: 1.3172587156295776
Validation loss: 1.993460234775338

Epoch: 5| Step: 5
Training loss: 1.1434135437011719
Validation loss: 1.9824663695468698

Epoch: 5| Step: 6
Training loss: 1.2359395027160645
Validation loss: 2.01930776334578

Epoch: 5| Step: 7
Training loss: 1.300048828125
Validation loss: 2.004048130845511

Epoch: 5| Step: 8
Training loss: 1.4102585315704346
Validation loss: 2.0192655760754823

Epoch: 5| Step: 9
Training loss: 1.3240944147109985
Validation loss: 1.994439378861458

Epoch: 5| Step: 10
Training loss: 1.5173413753509521
Validation loss: 1.977903413516219

Epoch: 573| Step: 0
Training loss: 1.0426502227783203
Validation loss: 1.9781640345050442

Epoch: 5| Step: 1
Training loss: 2.0071163177490234
Validation loss: 1.9897752372167443

Epoch: 5| Step: 2
Training loss: 1.3347610235214233
Validation loss: 1.9295550559156684

Epoch: 5| Step: 3
Training loss: 1.4201124906539917
Validation loss: 1.9463809677349624

Epoch: 5| Step: 4
Training loss: 1.3571367263793945
Validation loss: 1.9807165515038274

Epoch: 5| Step: 5
Training loss: 0.9555493593215942
Validation loss: 1.9563992177286456

Epoch: 5| Step: 6
Training loss: 1.3426851034164429
Validation loss: 1.9363050435179023

Epoch: 5| Step: 7
Training loss: 1.5094341039657593
Validation loss: 1.9621045127991708

Epoch: 5| Step: 8
Training loss: 1.4671275615692139
Validation loss: 1.9509828449577413

Epoch: 5| Step: 9
Training loss: 1.5178333520889282
Validation loss: 1.9676807644546672

Epoch: 5| Step: 10
Training loss: 0.8667012453079224
Validation loss: 1.9615180748765186

Epoch: 574| Step: 0
Training loss: 1.0448856353759766
Validation loss: 1.9753705275956022

Epoch: 5| Step: 1
Training loss: 1.5236390829086304
Validation loss: 1.9778424796237741

Epoch: 5| Step: 2
Training loss: 1.0989148616790771
Validation loss: 1.9892790343171807

Epoch: 5| Step: 3
Training loss: 1.7958972454071045
Validation loss: 1.9578553245913597

Epoch: 5| Step: 4
Training loss: 1.241292119026184
Validation loss: 1.9507985961052678

Epoch: 5| Step: 5
Training loss: 1.2213231325149536
Validation loss: 1.9728474450367752

Epoch: 5| Step: 6
Training loss: 1.5805610418319702
Validation loss: 2.0038130565356185

Epoch: 5| Step: 7
Training loss: 1.1384751796722412
Validation loss: 1.9477089053841048

Epoch: 5| Step: 8
Training loss: 1.2228801250457764
Validation loss: 1.9556013922537527

Epoch: 5| Step: 9
Training loss: 1.5074471235275269
Validation loss: 1.9813641373829176

Epoch: 5| Step: 10
Training loss: 1.4829615354537964
Validation loss: 1.9520992527725876

Epoch: 575| Step: 0
Training loss: 1.6729505062103271
Validation loss: 1.9846065326403546

Epoch: 5| Step: 1
Training loss: 1.3882302045822144
Validation loss: 1.9982847564963884

Epoch: 5| Step: 2
Training loss: 1.4236472845077515
Validation loss: 1.9616918153660272

Epoch: 5| Step: 3
Training loss: 1.7422813177108765
Validation loss: 1.9781344731648762

Epoch: 5| Step: 4
Training loss: 1.3214280605316162
Validation loss: 1.9621062509475216

Epoch: 5| Step: 5
Training loss: 0.7656961679458618
Validation loss: 2.0108294256271853

Epoch: 5| Step: 6
Training loss: 2.3182320594787598
Validation loss: 1.9530717801022273

Epoch: 5| Step: 7
Training loss: 1.3427082300186157
Validation loss: 1.9887716616353681

Epoch: 5| Step: 8
Training loss: 1.0294328927993774
Validation loss: 1.9552874308760448

Epoch: 5| Step: 9
Training loss: 0.6593039035797119
Validation loss: 1.9520816879887735

Epoch: 5| Step: 10
Training loss: 0.997391402721405
Validation loss: 1.9687519945124143

Epoch: 576| Step: 0
Training loss: 1.4003393650054932
Validation loss: 1.9898492059400004

Epoch: 5| Step: 1
Training loss: 1.3538671731948853
Validation loss: 1.933216534635072

Epoch: 5| Step: 2
Training loss: 1.414489984512329
Validation loss: 1.950179769146827

Epoch: 5| Step: 3
Training loss: 1.430577039718628
Validation loss: 1.9796068578638055

Epoch: 5| Step: 4
Training loss: 0.9797601699829102
Validation loss: 1.9805302337933612

Epoch: 5| Step: 5
Training loss: 1.2447599172592163
Validation loss: 1.932364761188466

Epoch: 5| Step: 6
Training loss: 1.29068922996521
Validation loss: 1.9448414553878128

Epoch: 5| Step: 7
Training loss: 1.7693977355957031
Validation loss: 1.956624343831052

Epoch: 5| Step: 8
Training loss: 1.4527602195739746
Validation loss: 1.9459278532253799

Epoch: 5| Step: 9
Training loss: 1.238058090209961
Validation loss: 1.9635520083929903

Epoch: 5| Step: 10
Training loss: 1.0143073797225952
Validation loss: 1.9795653884128859

Epoch: 577| Step: 0
Training loss: 1.531231164932251
Validation loss: 1.9735432145416096

Epoch: 5| Step: 1
Training loss: 1.1390608549118042
Validation loss: 1.9749764165570658

Epoch: 5| Step: 2
Training loss: 1.9238574504852295
Validation loss: 1.963164032146495

Epoch: 5| Step: 3
Training loss: 0.9943750500679016
Validation loss: 1.9576429103010444

Epoch: 5| Step: 4
Training loss: 1.115652322769165
Validation loss: 2.0268763829303045

Epoch: 5| Step: 5
Training loss: 1.7268626689910889
Validation loss: 2.0295135654428953

Epoch: 5| Step: 6
Training loss: 1.197091817855835
Validation loss: 2.0060205767231603

Epoch: 5| Step: 7
Training loss: 1.1634023189544678
Validation loss: 1.975739509828629

Epoch: 5| Step: 8
Training loss: 1.2764636278152466
Validation loss: 1.9660898741855417

Epoch: 5| Step: 9
Training loss: 1.322867512702942
Validation loss: 2.00907656966999

Epoch: 5| Step: 10
Training loss: 1.4588935375213623
Validation loss: 1.9552660706222698

Epoch: 578| Step: 0
Training loss: 1.199885606765747
Validation loss: 1.952514797128657

Epoch: 5| Step: 1
Training loss: 1.3662813901901245
Validation loss: 1.9916744719269455

Epoch: 5| Step: 2
Training loss: 1.5746135711669922
Validation loss: 1.960094964632424

Epoch: 5| Step: 3
Training loss: 1.075955867767334
Validation loss: 1.9497119034490278

Epoch: 5| Step: 4
Training loss: 1.7434085607528687
Validation loss: 1.9679774417672107

Epoch: 5| Step: 5
Training loss: 1.0487234592437744
Validation loss: 1.9594057336930306

Epoch: 5| Step: 6
Training loss: 1.406488060951233
Validation loss: 1.9694408960239862

Epoch: 5| Step: 7
Training loss: 1.3292207717895508
Validation loss: 1.9688679338783346

Epoch: 5| Step: 8
Training loss: 1.6366345882415771
Validation loss: 1.9473605514854513

Epoch: 5| Step: 9
Training loss: 1.3537969589233398
Validation loss: 1.956902519349129

Epoch: 5| Step: 10
Training loss: 1.0678579807281494
Validation loss: 1.9903669434209024

Epoch: 579| Step: 0
Training loss: 1.4019112586975098
Validation loss: 1.9833137091769968

Epoch: 5| Step: 1
Training loss: 1.8077729940414429
Validation loss: 1.924490390285369

Epoch: 5| Step: 2
Training loss: 1.2596633434295654
Validation loss: 1.9821541488811534

Epoch: 5| Step: 3
Training loss: 0.7035515308380127
Validation loss: 2.0072800959310224

Epoch: 5| Step: 4
Training loss: 1.5006901025772095
Validation loss: 1.9847777928075483

Epoch: 5| Step: 5
Training loss: 1.10397207736969
Validation loss: 1.9824370902071717

Epoch: 5| Step: 6
Training loss: 1.3872944116592407
Validation loss: 1.9735997671722083

Epoch: 5| Step: 7
Training loss: 1.5752184391021729
Validation loss: 1.9628547212128997

Epoch: 5| Step: 8
Training loss: 1.8221995830535889
Validation loss: 2.00534571883499

Epoch: 5| Step: 9
Training loss: 1.0785350799560547
Validation loss: 1.961272878031577

Epoch: 5| Step: 10
Training loss: 1.043016791343689
Validation loss: 1.9737629941714707

Epoch: 580| Step: 0
Training loss: 1.287534475326538
Validation loss: 1.9751553163733533

Epoch: 5| Step: 1
Training loss: 1.3061394691467285
Validation loss: 1.9758487786016157

Epoch: 5| Step: 2
Training loss: 1.4065673351287842
Validation loss: 2.0167057270644815

Epoch: 5| Step: 3
Training loss: 1.8584880828857422
Validation loss: 1.9853964300565823

Epoch: 5| Step: 4
Training loss: 1.4396536350250244
Validation loss: 2.0058805352898053

Epoch: 5| Step: 5
Training loss: 1.5032470226287842
Validation loss: 2.0117622062724125

Epoch: 5| Step: 6
Training loss: 1.156267762184143
Validation loss: 1.9983003113859443

Epoch: 5| Step: 7
Training loss: 1.4416176080703735
Validation loss: 2.030481171864335

Epoch: 5| Step: 8
Training loss: 1.2416690587997437
Validation loss: 2.0088352464860484

Epoch: 5| Step: 9
Training loss: 0.9871765375137329
Validation loss: 1.9547152698680919

Epoch: 5| Step: 10
Training loss: 1.0495729446411133
Validation loss: 2.0073309124156995

Epoch: 581| Step: 0
Training loss: 1.18449068069458
Validation loss: 1.9786222711686166

Epoch: 5| Step: 1
Training loss: 1.049244999885559
Validation loss: 1.9486097802398026

Epoch: 5| Step: 2
Training loss: 1.5769445896148682
Validation loss: 1.996628515182003

Epoch: 5| Step: 3
Training loss: 0.7861301302909851
Validation loss: 1.947945229468807

Epoch: 5| Step: 4
Training loss: 1.6594486236572266
Validation loss: 1.9677383386960594

Epoch: 5| Step: 5
Training loss: 0.8830581903457642
Validation loss: 1.9451301174779092

Epoch: 5| Step: 6
Training loss: 1.6006361246109009
Validation loss: 1.9626914096134964

Epoch: 5| Step: 7
Training loss: 1.7116016149520874
Validation loss: 1.9187315792165778

Epoch: 5| Step: 8
Training loss: 1.5700241327285767
Validation loss: 1.9830396944476711

Epoch: 5| Step: 9
Training loss: 1.2928695678710938
Validation loss: 1.9172828210297452

Epoch: 5| Step: 10
Training loss: 1.6434285640716553
Validation loss: 1.9681839122567126

Epoch: 582| Step: 0
Training loss: 1.9930925369262695
Validation loss: 1.9756328239235827

Epoch: 5| Step: 1
Training loss: 1.4220530986785889
Validation loss: 1.9235692780504945

Epoch: 5| Step: 2
Training loss: 1.4277712106704712
Validation loss: 1.9623370939685452

Epoch: 5| Step: 3
Training loss: 1.2331193685531616
Validation loss: 1.9749102336104198

Epoch: 5| Step: 4
Training loss: 1.2069886922836304
Validation loss: 1.9855853947260047

Epoch: 5| Step: 5
Training loss: 0.9556997418403625
Validation loss: 1.983266189534177

Epoch: 5| Step: 6
Training loss: 0.9539211988449097
Validation loss: 2.0097119615923975

Epoch: 5| Step: 7
Training loss: 1.5465257167816162
Validation loss: 1.985411406845175

Epoch: 5| Step: 8
Training loss: 1.1695245504379272
Validation loss: 1.995601322061272

Epoch: 5| Step: 9
Training loss: 0.882830798625946
Validation loss: 1.9770405625784269

Epoch: 5| Step: 10
Training loss: 1.7166951894760132
Validation loss: 1.965272347132365

Epoch: 583| Step: 0
Training loss: 1.0828821659088135
Validation loss: 1.9876246067785448

Epoch: 5| Step: 1
Training loss: 1.2536375522613525
Validation loss: 1.9515464895515031

Epoch: 5| Step: 2
Training loss: 1.0167618989944458
Validation loss: 1.9853423359573528

Epoch: 5| Step: 3
Training loss: 1.4235416650772095
Validation loss: 1.961982528368632

Epoch: 5| Step: 4
Training loss: 1.3170000314712524
Validation loss: 1.9909438369094685

Epoch: 5| Step: 5
Training loss: 1.9453907012939453
Validation loss: 1.9417057088626328

Epoch: 5| Step: 6
Training loss: 1.298221230506897
Validation loss: 1.9532875232799078

Epoch: 5| Step: 7
Training loss: 1.3774715662002563
Validation loss: 1.9666785027391167

Epoch: 5| Step: 8
Training loss: 1.5535557270050049
Validation loss: 1.9764334924759404

Epoch: 5| Step: 9
Training loss: 1.542973279953003
Validation loss: 1.9435770306535947

Epoch: 5| Step: 10
Training loss: 0.8684659004211426
Validation loss: 1.9320265887885966

Epoch: 584| Step: 0
Training loss: 0.9816992878913879
Validation loss: 1.9457957642052763

Epoch: 5| Step: 1
Training loss: 1.5538498163223267
Validation loss: 1.9855263566458097

Epoch: 5| Step: 2
Training loss: 1.749441146850586
Validation loss: 1.9732663336620535

Epoch: 5| Step: 3
Training loss: 1.176343321800232
Validation loss: 1.9644300553106493

Epoch: 5| Step: 4
Training loss: 1.4281679391860962
Validation loss: 1.9706327402463524

Epoch: 5| Step: 5
Training loss: 1.3269211053848267
Validation loss: 1.9997804946796869

Epoch: 5| Step: 6
Training loss: 1.287735939025879
Validation loss: 1.9618741081606956

Epoch: 5| Step: 7
Training loss: 1.1772750616073608
Validation loss: 1.979817141768753

Epoch: 5| Step: 8
Training loss: 1.4087157249450684
Validation loss: 1.9643602832671134

Epoch: 5| Step: 9
Training loss: 1.5306282043457031
Validation loss: 1.9940674125507314

Epoch: 5| Step: 10
Training loss: 0.9018475413322449
Validation loss: 1.9643478496100313

Epoch: 585| Step: 0
Training loss: 1.6838090419769287
Validation loss: 1.9429079794114636

Epoch: 5| Step: 1
Training loss: 1.2343952655792236
Validation loss: 1.9643443143495949

Epoch: 5| Step: 2
Training loss: 0.9081541299819946
Validation loss: 1.9944256044203235

Epoch: 5| Step: 3
Training loss: 1.1108229160308838
Validation loss: 1.98505699634552

Epoch: 5| Step: 4
Training loss: 1.0120370388031006
Validation loss: 1.9569616087021366

Epoch: 5| Step: 5
Training loss: 1.4496320486068726
Validation loss: 1.9772934554725565

Epoch: 5| Step: 6
Training loss: 0.9810277223587036
Validation loss: 1.9721287783756052

Epoch: 5| Step: 7
Training loss: 2.134178638458252
Validation loss: 1.959405586283694

Epoch: 5| Step: 8
Training loss: 1.068273663520813
Validation loss: 1.9872890377557406

Epoch: 5| Step: 9
Training loss: 1.5081274509429932
Validation loss: 1.9814812739690144

Epoch: 5| Step: 10
Training loss: 1.4643913507461548
Validation loss: 1.9423570209933865

Epoch: 586| Step: 0
Training loss: 1.4771984815597534
Validation loss: 1.9654296803218063

Epoch: 5| Step: 1
Training loss: 1.080491304397583
Validation loss: 1.9814817264515867

Epoch: 5| Step: 2
Training loss: 1.6792415380477905
Validation loss: 1.9750530335210985

Epoch: 5| Step: 3
Training loss: 0.8427760004997253
Validation loss: 1.9457511478854763

Epoch: 5| Step: 4
Training loss: 0.8776851892471313
Validation loss: 1.934440153901295

Epoch: 5| Step: 5
Training loss: 0.9772083163261414
Validation loss: 1.926039893140075

Epoch: 5| Step: 6
Training loss: 1.1362029314041138
Validation loss: 1.9649179597054758

Epoch: 5| Step: 7
Training loss: 1.885226845741272
Validation loss: 1.9882693277892245

Epoch: 5| Step: 8
Training loss: 1.4680322408676147
Validation loss: 1.9400452131866126

Epoch: 5| Step: 9
Training loss: 1.4174991846084595
Validation loss: 1.9774626019180461

Epoch: 5| Step: 10
Training loss: 1.8243578672409058
Validation loss: 1.9776876229111866

Epoch: 587| Step: 0
Training loss: 0.8897541761398315
Validation loss: 1.962325652440389

Epoch: 5| Step: 1
Training loss: 1.3385103940963745
Validation loss: 1.963349869174342

Epoch: 5| Step: 2
Training loss: 1.262490153312683
Validation loss: 1.9813994822963592

Epoch: 5| Step: 3
Training loss: 1.1430999040603638
Validation loss: 2.005879312433222

Epoch: 5| Step: 4
Training loss: 1.4482371807098389
Validation loss: 1.9720513455329403

Epoch: 5| Step: 5
Training loss: 1.2455848455429077
Validation loss: 1.96192426835337

Epoch: 5| Step: 6
Training loss: 1.6602376699447632
Validation loss: 2.014670496345848

Epoch: 5| Step: 7
Training loss: 1.3629724979400635
Validation loss: 1.9905147116671327

Epoch: 5| Step: 8
Training loss: 1.0737942457199097
Validation loss: 1.9530983842829222

Epoch: 5| Step: 9
Training loss: 1.3416893482208252
Validation loss: 1.9900366478068854

Epoch: 5| Step: 10
Training loss: 1.7161344289779663
Validation loss: 1.9395182235266573

Epoch: 588| Step: 0
Training loss: 1.469653606414795
Validation loss: 1.9563648905805362

Epoch: 5| Step: 1
Training loss: 1.2773141860961914
Validation loss: 1.9481623839306574

Epoch: 5| Step: 2
Training loss: 1.3566477298736572
Validation loss: 1.9517052981161302

Epoch: 5| Step: 3
Training loss: 1.135923981666565
Validation loss: 1.9510418932924989

Epoch: 5| Step: 4
Training loss: 1.6530344486236572
Validation loss: 1.9390542071352723

Epoch: 5| Step: 5
Training loss: 0.9413469433784485
Validation loss: 1.97408111633793

Epoch: 5| Step: 6
Training loss: 1.4780241250991821
Validation loss: 1.9671498767791256

Epoch: 5| Step: 7
Training loss: 1.3804643154144287
Validation loss: 1.9562217714965984

Epoch: 5| Step: 8
Training loss: 1.4409048557281494
Validation loss: 1.9858824822210497

Epoch: 5| Step: 9
Training loss: 1.094497561454773
Validation loss: 1.9375391339743009

Epoch: 5| Step: 10
Training loss: 1.3663973808288574
Validation loss: 1.9947068550253426

Epoch: 589| Step: 0
Training loss: 1.1166274547576904
Validation loss: 1.9542338437931512

Epoch: 5| Step: 1
Training loss: 0.9803457260131836
Validation loss: 1.9577644922400033

Epoch: 5| Step: 2
Training loss: 1.2860450744628906
Validation loss: 2.0084684869294525

Epoch: 5| Step: 3
Training loss: 1.482966661453247
Validation loss: 1.9821824104555192

Epoch: 5| Step: 4
Training loss: 1.2660714387893677
Validation loss: 1.988753245722863

Epoch: 5| Step: 5
Training loss: 1.3309359550476074
Validation loss: 1.966064501834172

Epoch: 5| Step: 6
Training loss: 0.856157124042511
Validation loss: 1.9540631283995926

Epoch: 5| Step: 7
Training loss: 1.9352684020996094
Validation loss: 1.9546602631127963

Epoch: 5| Step: 8
Training loss: 1.4574861526489258
Validation loss: 1.9882466382877801

Epoch: 5| Step: 9
Training loss: 1.2938165664672852
Validation loss: 1.9514272712892102

Epoch: 5| Step: 10
Training loss: 1.6459847688674927
Validation loss: 1.9777694158656622

Epoch: 590| Step: 0
Training loss: 0.8728062510490417
Validation loss: 1.9467905708538589

Epoch: 5| Step: 1
Training loss: 1.4969958066940308
Validation loss: 1.9474702368500412

Epoch: 5| Step: 2
Training loss: 1.5043998956680298
Validation loss: 1.924380415229387

Epoch: 5| Step: 3
Training loss: 1.4220936298370361
Validation loss: 1.9634974746293918

Epoch: 5| Step: 4
Training loss: 0.8038231134414673
Validation loss: 1.9853207859941708

Epoch: 5| Step: 5
Training loss: 1.3917983770370483
Validation loss: 1.9540695387830016

Epoch: 5| Step: 6
Training loss: 1.355188250541687
Validation loss: 1.9820936187621085

Epoch: 5| Step: 7
Training loss: 1.0445448160171509
Validation loss: 1.9727816991908576

Epoch: 5| Step: 8
Training loss: 1.4943921566009521
Validation loss: 1.9510966385564497

Epoch: 5| Step: 9
Training loss: 1.4692693948745728
Validation loss: 1.9225108392776982

Epoch: 5| Step: 10
Training loss: 1.7276544570922852
Validation loss: 1.9864466523611417

Epoch: 591| Step: 0
Training loss: 1.168278694152832
Validation loss: 1.9624898228594052

Epoch: 5| Step: 1
Training loss: 1.4908206462860107
Validation loss: 1.9761035070624402

Epoch: 5| Step: 2
Training loss: 1.3581039905548096
Validation loss: 1.986046975658786

Epoch: 5| Step: 3
Training loss: 1.6620537042617798
Validation loss: 1.968477044054257

Epoch: 5| Step: 4
Training loss: 1.143705129623413
Validation loss: 1.9614901209390292

Epoch: 5| Step: 5
Training loss: 1.082996129989624
Validation loss: 1.9426349363019388

Epoch: 5| Step: 6
Training loss: 1.283412218093872
Validation loss: 1.9600685924612067

Epoch: 5| Step: 7
Training loss: 1.0128874778747559
Validation loss: 1.9503084536521667

Epoch: 5| Step: 8
Training loss: 1.9021799564361572
Validation loss: 1.95419063363024

Epoch: 5| Step: 9
Training loss: 1.222167730331421
Validation loss: 1.95984899228619

Epoch: 5| Step: 10
Training loss: 1.2401525974273682
Validation loss: 1.9463902314503987

Epoch: 592| Step: 0
Training loss: 0.7772127389907837
Validation loss: 1.9637723276692052

Epoch: 5| Step: 1
Training loss: 1.314943552017212
Validation loss: 1.9757872499445432

Epoch: 5| Step: 2
Training loss: 1.0840752124786377
Validation loss: 1.9485557989407611

Epoch: 5| Step: 3
Training loss: 1.5915722846984863
Validation loss: 1.95388198924321

Epoch: 5| Step: 4
Training loss: 1.380152940750122
Validation loss: 1.9443684572814612

Epoch: 5| Step: 5
Training loss: 1.20278000831604
Validation loss: 1.9461267507204445

Epoch: 5| Step: 6
Training loss: 1.2110601663589478
Validation loss: 2.0036800997231596

Epoch: 5| Step: 7
Training loss: 1.658034324645996
Validation loss: 1.9350940899182392

Epoch: 5| Step: 8
Training loss: 1.2312185764312744
Validation loss: 1.9597508253589753

Epoch: 5| Step: 9
Training loss: 1.5215156078338623
Validation loss: 1.954551160976451

Epoch: 5| Step: 10
Training loss: 1.3142924308776855
Validation loss: 1.9745312544607347

Epoch: 593| Step: 0
Training loss: 0.6916400194168091
Validation loss: 1.8947585128968762

Epoch: 5| Step: 1
Training loss: 1.844199538230896
Validation loss: 1.9613783385163994

Epoch: 5| Step: 2
Training loss: 1.5970286130905151
Validation loss: 1.959485246289161

Epoch: 5| Step: 3
Training loss: 1.810336709022522
Validation loss: 1.9759504025982273

Epoch: 5| Step: 4
Training loss: 0.7701378464698792
Validation loss: 1.9916079659615793

Epoch: 5| Step: 5
Training loss: 1.3253076076507568
Validation loss: 1.9872913181140859

Epoch: 5| Step: 6
Training loss: 1.3494099378585815
Validation loss: 1.9680971868576542

Epoch: 5| Step: 7
Training loss: 1.2241073846817017
Validation loss: 1.9994689520969187

Epoch: 5| Step: 8
Training loss: 1.2076947689056396
Validation loss: 2.006542598047564

Epoch: 5| Step: 9
Training loss: 1.1824127435684204
Validation loss: 1.9867460214963524

Epoch: 5| Step: 10
Training loss: 1.5517305135726929
Validation loss: 1.9773569465965353

Epoch: 594| Step: 0
Training loss: 0.8327534794807434
Validation loss: 1.9697997672583467

Epoch: 5| Step: 1
Training loss: 1.2498693466186523
Validation loss: 1.9798620644436087

Epoch: 5| Step: 2
Training loss: 1.4249897003173828
Validation loss: 1.97639294849929

Epoch: 5| Step: 3
Training loss: 1.447916030883789
Validation loss: 1.9468859895583122

Epoch: 5| Step: 4
Training loss: 1.1947510242462158
Validation loss: 1.9463593165079753

Epoch: 5| Step: 5
Training loss: 0.890316367149353
Validation loss: 1.967576757554085

Epoch: 5| Step: 6
Training loss: 1.65628182888031
Validation loss: 1.9607302347819011

Epoch: 5| Step: 7
Training loss: 1.7171270847320557
Validation loss: 1.9677683794370262

Epoch: 5| Step: 8
Training loss: 1.2171610593795776
Validation loss: 1.9668570462093558

Epoch: 5| Step: 9
Training loss: 1.32942533493042
Validation loss: 1.9881295632290583

Epoch: 5| Step: 10
Training loss: 1.4887704849243164
Validation loss: 1.976528113888156

Epoch: 595| Step: 0
Training loss: 1.0504506826400757
Validation loss: 1.9795204465107252

Epoch: 5| Step: 1
Training loss: 0.6305813789367676
Validation loss: 1.961178461710612

Epoch: 5| Step: 2
Training loss: 1.2032705545425415
Validation loss: 1.9708896093471076

Epoch: 5| Step: 3
Training loss: 1.466566801071167
Validation loss: 1.9707062936598254

Epoch: 5| Step: 4
Training loss: 1.619921326637268
Validation loss: 1.973133055112695

Epoch: 5| Step: 5
Training loss: 1.274970531463623
Validation loss: 1.9526918716328119

Epoch: 5| Step: 6
Training loss: 1.2241179943084717
Validation loss: 1.9854710435354581

Epoch: 5| Step: 7
Training loss: 1.6111217737197876
Validation loss: 1.9517761430432718

Epoch: 5| Step: 8
Training loss: 1.4871426820755005
Validation loss: 1.9393816506990822

Epoch: 5| Step: 9
Training loss: 1.3385727405548096
Validation loss: 1.9939229847282491

Epoch: 5| Step: 10
Training loss: 1.5059230327606201
Validation loss: 1.974737121212867

Epoch: 596| Step: 0
Training loss: 1.1960699558258057
Validation loss: 1.941394526471374

Epoch: 5| Step: 1
Training loss: 1.3691465854644775
Validation loss: 1.977251224620368

Epoch: 5| Step: 2
Training loss: 1.166129231452942
Validation loss: 1.9592929219686857

Epoch: 5| Step: 3
Training loss: 1.1614370346069336
Validation loss: 1.9620272113430886

Epoch: 5| Step: 4
Training loss: 1.4297221899032593
Validation loss: 1.9666327032991635

Epoch: 5| Step: 5
Training loss: 1.7007465362548828
Validation loss: 1.9709892144767187

Epoch: 5| Step: 6
Training loss: 1.2045172452926636
Validation loss: 1.985281672528995

Epoch: 5| Step: 7
Training loss: 0.90221107006073
Validation loss: 1.9474887976082422

Epoch: 5| Step: 8
Training loss: 1.2435129880905151
Validation loss: 1.9552203993643484

Epoch: 5| Step: 9
Training loss: 1.7359517812728882
Validation loss: 1.9753761855504846

Epoch: 5| Step: 10
Training loss: 1.3632221221923828
Validation loss: 1.9482963174901984

Epoch: 597| Step: 0
Training loss: 1.6199989318847656
Validation loss: 1.9416136434001308

Epoch: 5| Step: 1
Training loss: 1.2196948528289795
Validation loss: 1.9592514281631799

Epoch: 5| Step: 2
Training loss: 1.9138590097427368
Validation loss: 1.9730474333609305

Epoch: 5| Step: 3
Training loss: 1.1774832010269165
Validation loss: 1.9650444522980721

Epoch: 5| Step: 4
Training loss: 1.362756371498108
Validation loss: 1.9809010849204114

Epoch: 5| Step: 5
Training loss: 1.644840955734253
Validation loss: 1.9767534912273448

Epoch: 5| Step: 6
Training loss: 1.1480783224105835
Validation loss: 1.9459427979684645

Epoch: 5| Step: 7
Training loss: 0.6116578578948975
Validation loss: 1.9885461125322568

Epoch: 5| Step: 8
Training loss: 0.7529225945472717
Validation loss: 1.9557700759621077

Epoch: 5| Step: 9
Training loss: 1.3324964046478271
Validation loss: 1.9787803055137716

Epoch: 5| Step: 10
Training loss: 1.5167981386184692
Validation loss: 1.9763139165857786

Epoch: 598| Step: 0
Training loss: 1.3768284320831299
Validation loss: 1.9577577947288431

Epoch: 5| Step: 1
Training loss: 1.3080308437347412
Validation loss: 1.9541404836921281

Epoch: 5| Step: 2
Training loss: 0.6687256693840027
Validation loss: 1.9396875699361165

Epoch: 5| Step: 3
Training loss: 1.4977264404296875
Validation loss: 1.9642365222336144

Epoch: 5| Step: 4
Training loss: 1.803478479385376
Validation loss: 1.9495801694931523

Epoch: 5| Step: 5
Training loss: 1.594542145729065
Validation loss: 1.9438634559672365

Epoch: 5| Step: 6
Training loss: 1.3902496099472046
Validation loss: 1.9772538741429646

Epoch: 5| Step: 7
Training loss: 0.8456369638442993
Validation loss: 1.9607523410551009

Epoch: 5| Step: 8
Training loss: 1.428542137145996
Validation loss: 1.9457937671292214

Epoch: 5| Step: 9
Training loss: 1.6082260608673096
Validation loss: 1.9631372523564163

Epoch: 5| Step: 10
Training loss: 0.8406699895858765
Validation loss: 1.9137950584452639

Epoch: 599| Step: 0
Training loss: 1.2705893516540527
Validation loss: 1.9293581426784556

Epoch: 5| Step: 1
Training loss: 1.6032028198242188
Validation loss: 1.9540169854317941

Epoch: 5| Step: 2
Training loss: 0.8516441583633423
Validation loss: 1.9547625152013635

Epoch: 5| Step: 3
Training loss: 1.6649627685546875
Validation loss: 1.96455285497891

Epoch: 5| Step: 4
Training loss: 1.2414324283599854
Validation loss: 1.962823442233506

Epoch: 5| Step: 5
Training loss: 1.225496530532837
Validation loss: 1.9884169575988606

Epoch: 5| Step: 6
Training loss: 1.1659168004989624
Validation loss: 1.947264971271638

Epoch: 5| Step: 7
Training loss: 1.4711869955062866
Validation loss: 1.9531212058118594

Epoch: 5| Step: 8
Training loss: 1.2008938789367676
Validation loss: 1.9688247737064157

Epoch: 5| Step: 9
Training loss: 1.034583330154419
Validation loss: 1.9836634576961558

Epoch: 5| Step: 10
Training loss: 1.3922491073608398
Validation loss: 1.9518240908140778

Epoch: 600| Step: 0
Training loss: 1.5267473459243774
Validation loss: 1.9708108568704257

Epoch: 5| Step: 1
Training loss: 1.3810890913009644
Validation loss: 1.958698421396235

Epoch: 5| Step: 2
Training loss: 1.1438374519348145
Validation loss: 1.9570260535004318

Epoch: 5| Step: 3
Training loss: 1.2471859455108643
Validation loss: 1.9568398537174347

Epoch: 5| Step: 4
Training loss: 1.5738096237182617
Validation loss: 1.9503268208554996

Epoch: 5| Step: 5
Training loss: 1.5011711120605469
Validation loss: 1.9621196998062955

Epoch: 5| Step: 6
Training loss: 1.1636006832122803
Validation loss: 1.948559635428972

Epoch: 5| Step: 7
Training loss: 1.3754093647003174
Validation loss: 1.9666721487558017

Epoch: 5| Step: 8
Training loss: 1.374338150024414
Validation loss: 2.0002507266177925

Epoch: 5| Step: 9
Training loss: 1.062114953994751
Validation loss: 1.9667552671124857

Epoch: 5| Step: 10
Training loss: 1.0817686319351196
Validation loss: 1.9723006884257

Epoch: 601| Step: 0
Training loss: 0.9611862897872925
Validation loss: 1.9154472633074688

Epoch: 5| Step: 1
Training loss: 1.2799323797225952
Validation loss: 1.947006284549672

Epoch: 5| Step: 2
Training loss: 1.5109044313430786
Validation loss: 1.9632844950563164

Epoch: 5| Step: 3
Training loss: 1.1946403980255127
Validation loss: 1.9582815170288086

Epoch: 5| Step: 4
Training loss: 1.75078547000885
Validation loss: 2.00303304067222

Epoch: 5| Step: 5
Training loss: 1.3022407293319702
Validation loss: 1.96011511869328

Epoch: 5| Step: 6
Training loss: 0.9688977003097534
Validation loss: 1.9539383278098157

Epoch: 5| Step: 7
Training loss: 1.3936901092529297
Validation loss: 1.9406408468882244

Epoch: 5| Step: 8
Training loss: 0.769213855266571
Validation loss: 1.9638098132225774

Epoch: 5| Step: 9
Training loss: 1.7112871408462524
Validation loss: 1.9657028157223937

Epoch: 5| Step: 10
Training loss: 1.3113150596618652
Validation loss: 1.944205089281964

Epoch: 602| Step: 0
Training loss: 1.2044248580932617
Validation loss: 1.9654350588398595

Epoch: 5| Step: 1
Training loss: 1.767918586730957
Validation loss: 1.984614828581451

Epoch: 5| Step: 2
Training loss: 0.7876884341239929
Validation loss: 1.9834984310211674

Epoch: 5| Step: 3
Training loss: 0.9254598617553711
Validation loss: 1.9750811464043074

Epoch: 5| Step: 4
Training loss: 1.2182260751724243
Validation loss: 1.9669995846286896

Epoch: 5| Step: 5
Training loss: 1.6680883169174194
Validation loss: 1.9712074520767375

Epoch: 5| Step: 6
Training loss: 0.9574147462844849
Validation loss: 2.008354425430298

Epoch: 5| Step: 7
Training loss: 1.6828397512435913
Validation loss: 1.9878551319081297

Epoch: 5| Step: 8
Training loss: 1.7450788021087646
Validation loss: 1.971842550462292

Epoch: 5| Step: 9
Training loss: 1.1667311191558838
Validation loss: 1.9817190542015979

Epoch: 5| Step: 10
Training loss: 0.9759386777877808
Validation loss: 1.9375488117177

Epoch: 603| Step: 0
Training loss: 1.5092077255249023
Validation loss: 2.0175864337592997

Epoch: 5| Step: 1
Training loss: 1.1564102172851562
Validation loss: 1.9460456948126517

Epoch: 5| Step: 2
Training loss: 1.1536247730255127
Validation loss: 2.0060857162680676

Epoch: 5| Step: 3
Training loss: 1.5274975299835205
Validation loss: 1.930910953911402

Epoch: 5| Step: 4
Training loss: 1.4047605991363525
Validation loss: 2.004101635307394

Epoch: 5| Step: 5
Training loss: 1.264906644821167
Validation loss: 1.9999640141763995

Epoch: 5| Step: 6
Training loss: 1.4997942447662354
Validation loss: 1.952726359008461

Epoch: 5| Step: 7
Training loss: 0.7095697522163391
Validation loss: 1.9886922451757616

Epoch: 5| Step: 8
Training loss: 1.1000577211380005
Validation loss: 1.9935516734277048

Epoch: 5| Step: 9
Training loss: 1.4379945993423462
Validation loss: 2.0018342233473256

Epoch: 5| Step: 10
Training loss: 1.7283391952514648
Validation loss: 1.962182257765083

Epoch: 604| Step: 0
Training loss: 1.202061653137207
Validation loss: 2.0106041072517313

Epoch: 5| Step: 1
Training loss: 1.778106927871704
Validation loss: 1.9922476301911056

Epoch: 5| Step: 2
Training loss: 1.5731240510940552
Validation loss: 1.9711240427468413

Epoch: 5| Step: 3
Training loss: 1.1909650564193726
Validation loss: 1.9733444939377487

Epoch: 5| Step: 4
Training loss: 0.9502120018005371
Validation loss: 1.9820773575895576

Epoch: 5| Step: 5
Training loss: 1.2788140773773193
Validation loss: 1.984319794562555

Epoch: 5| Step: 6
Training loss: 0.7778950929641724
Validation loss: 1.9907331312856367

Epoch: 5| Step: 7
Training loss: 0.9493745565414429
Validation loss: 1.992401784466159

Epoch: 5| Step: 8
Training loss: 1.5808217525482178
Validation loss: 1.9898550177133212

Epoch: 5| Step: 9
Training loss: 1.5278902053833008
Validation loss: 1.9846697904730355

Epoch: 5| Step: 10
Training loss: 1.6526175737380981
Validation loss: 1.9995765186125232

Epoch: 605| Step: 0
Training loss: 1.2466694116592407
Validation loss: 1.9732463564924014

Epoch: 5| Step: 1
Training loss: 1.1974440813064575
Validation loss: 1.9545259552617227

Epoch: 5| Step: 2
Training loss: 1.6034504175186157
Validation loss: 1.963589031209228

Epoch: 5| Step: 3
Training loss: 1.6388273239135742
Validation loss: 1.9908155305411226

Epoch: 5| Step: 4
Training loss: 0.6525634527206421
Validation loss: 1.9699131788746003

Epoch: 5| Step: 5
Training loss: 1.6487758159637451
Validation loss: 1.9717343238092238

Epoch: 5| Step: 6
Training loss: 1.32491934299469
Validation loss: 1.9903565376035628

Epoch: 5| Step: 7
Training loss: 1.0917701721191406
Validation loss: 1.9489836744082871

Epoch: 5| Step: 8
Training loss: 1.5877596139907837
Validation loss: 1.931960359696419

Epoch: 5| Step: 9
Training loss: 1.4064254760742188
Validation loss: 1.9539603853738436

Epoch: 5| Step: 10
Training loss: 0.812847375869751
Validation loss: 1.9966907501220703

Epoch: 606| Step: 0
Training loss: 1.4945541620254517
Validation loss: 1.9650014177445443

Epoch: 5| Step: 1
Training loss: 1.2788419723510742
Validation loss: 1.9943958482434672

Epoch: 5| Step: 2
Training loss: 1.8885501623153687
Validation loss: 1.986159877110553

Epoch: 5| Step: 3
Training loss: 1.5221893787384033
Validation loss: 1.9850826314700547

Epoch: 5| Step: 4
Training loss: 1.0752065181732178
Validation loss: 1.994133128914782

Epoch: 5| Step: 5
Training loss: 1.1402931213378906
Validation loss: 2.0025289750868276

Epoch: 5| Step: 6
Training loss: 1.2390516996383667
Validation loss: 1.9887871972976192

Epoch: 5| Step: 7
Training loss: 0.934902012348175
Validation loss: 1.938974290765742

Epoch: 5| Step: 8
Training loss: 1.027830958366394
Validation loss: 2.022446042747908

Epoch: 5| Step: 9
Training loss: 1.5413424968719482
Validation loss: 1.9721167625919465

Epoch: 5| Step: 10
Training loss: 1.4056637287139893
Validation loss: 1.9593505064646404

Epoch: 607| Step: 0
Training loss: 1.7439254522323608
Validation loss: 1.938784250649073

Epoch: 5| Step: 1
Training loss: 0.7670268416404724
Validation loss: 1.9364270651212303

Epoch: 5| Step: 2
Training loss: 1.6636031866073608
Validation loss: 1.959789140250093

Epoch: 5| Step: 3
Training loss: 1.3611581325531006
Validation loss: 1.952503869610448

Epoch: 5| Step: 4
Training loss: 1.1445317268371582
Validation loss: 1.987625680943971

Epoch: 5| Step: 5
Training loss: 1.469031572341919
Validation loss: 2.0061094196893836

Epoch: 5| Step: 6
Training loss: 0.9190750122070312
Validation loss: 1.9487375956709667

Epoch: 5| Step: 7
Training loss: 1.2708752155303955
Validation loss: 1.9468519956834855

Epoch: 5| Step: 8
Training loss: 1.312565565109253
Validation loss: 1.9368115676346647

Epoch: 5| Step: 9
Training loss: 1.2555735111236572
Validation loss: 1.9755412429891608

Epoch: 5| Step: 10
Training loss: 1.1870157718658447
Validation loss: 1.9833974428074335

Epoch: 608| Step: 0
Training loss: 1.6612659692764282
Validation loss: 1.9796856346950735

Epoch: 5| Step: 1
Training loss: 1.1796131134033203
Validation loss: 1.9649635309814124

Epoch: 5| Step: 2
Training loss: 1.7127326726913452
Validation loss: 1.9694179219584311

Epoch: 5| Step: 3
Training loss: 1.5806106328964233
Validation loss: 1.9890361485942718

Epoch: 5| Step: 4
Training loss: 0.9939523935317993
Validation loss: 2.001269284115043

Epoch: 5| Step: 5
Training loss: 1.2404893636703491
Validation loss: 1.9493754474065637

Epoch: 5| Step: 6
Training loss: 0.9068937301635742
Validation loss: 1.9522387340504637

Epoch: 5| Step: 7
Training loss: 1.6928564310073853
Validation loss: 1.9711036002764137

Epoch: 5| Step: 8
Training loss: 1.261972427368164
Validation loss: 1.9376504831416632

Epoch: 5| Step: 9
Training loss: 0.9290216565132141
Validation loss: 1.9578684632496168

Epoch: 5| Step: 10
Training loss: 1.0830448865890503
Validation loss: 1.9872511125379992

Epoch: 609| Step: 0
Training loss: 1.0316274166107178
Validation loss: 1.95699938138326

Epoch: 5| Step: 1
Training loss: 1.2785170078277588
Validation loss: 1.9446599586035616

Epoch: 5| Step: 2
Training loss: 1.4042587280273438
Validation loss: 1.966307834912372

Epoch: 5| Step: 3
Training loss: 1.4676129817962646
Validation loss: 1.9540562296426425

Epoch: 5| Step: 4
Training loss: 1.386422038078308
Validation loss: 1.9331579464738087

Epoch: 5| Step: 5
Training loss: 1.2950016260147095
Validation loss: 1.9829774415621193

Epoch: 5| Step: 6
Training loss: 1.40187668800354
Validation loss: 1.9783741453642487

Epoch: 5| Step: 7
Training loss: 0.8856270909309387
Validation loss: 1.9733796222235567

Epoch: 5| Step: 8
Training loss: 0.966018557548523
Validation loss: 2.0256401172248264

Epoch: 5| Step: 9
Training loss: 1.5745761394500732
Validation loss: 1.9781308994498303

Epoch: 5| Step: 10
Training loss: 1.7214155197143555
Validation loss: 1.964555428874108

Epoch: 610| Step: 0
Training loss: 1.5623118877410889
Validation loss: 1.9817557424627326

Epoch: 5| Step: 1
Training loss: 0.8516594767570496
Validation loss: 1.9598108081407444

Epoch: 5| Step: 2
Training loss: 1.5448702573776245
Validation loss: 1.9824544152905863

Epoch: 5| Step: 3
Training loss: 1.0251004695892334
Validation loss: 2.0248472972582747

Epoch: 5| Step: 4
Training loss: 0.9771469235420227
Validation loss: 1.9741644910586778

Epoch: 5| Step: 5
Training loss: 1.2970552444458008
Validation loss: 1.984642913264613

Epoch: 5| Step: 6
Training loss: 1.4021928310394287
Validation loss: 2.001275389425216

Epoch: 5| Step: 7
Training loss: 1.589006781578064
Validation loss: 2.0066272110067387

Epoch: 5| Step: 8
Training loss: 1.2318732738494873
Validation loss: 1.961330731709798

Epoch: 5| Step: 9
Training loss: 1.120775818824768
Validation loss: 1.992525222480938

Epoch: 5| Step: 10
Training loss: 1.5822194814682007
Validation loss: 1.9625941835423952

Epoch: 611| Step: 0
Training loss: 1.1097089052200317
Validation loss: 1.9868758199035481

Epoch: 5| Step: 1
Training loss: 1.5190327167510986
Validation loss: 1.9596097635966476

Epoch: 5| Step: 2
Training loss: 0.9198784828186035
Validation loss: 1.965362653937391

Epoch: 5| Step: 3
Training loss: 1.6941936016082764
Validation loss: 1.9618272102007301

Epoch: 5| Step: 4
Training loss: 0.8465324640274048
Validation loss: 1.9351245690417547

Epoch: 5| Step: 5
Training loss: 1.1461942195892334
Validation loss: 1.9391510204602314

Epoch: 5| Step: 6
Training loss: 1.1711254119873047
Validation loss: 1.988202925651304

Epoch: 5| Step: 7
Training loss: 0.9139223098754883
Validation loss: 1.947970163437628

Epoch: 5| Step: 8
Training loss: 1.3626399040222168
Validation loss: 1.9656773690254457

Epoch: 5| Step: 9
Training loss: 1.6276161670684814
Validation loss: 1.9592402878627981

Epoch: 5| Step: 10
Training loss: 1.955224871635437
Validation loss: 1.9886640579469743

Epoch: 612| Step: 0
Training loss: 1.380160927772522
Validation loss: 1.9703029663332048

Epoch: 5| Step: 1
Training loss: 1.5553791522979736
Validation loss: 1.9840745464448006

Epoch: 5| Step: 2
Training loss: 0.9191605448722839
Validation loss: 2.020244772716235

Epoch: 5| Step: 3
Training loss: 1.3156135082244873
Validation loss: 1.9732953271558207

Epoch: 5| Step: 4
Training loss: 1.3615903854370117
Validation loss: 2.010300285072737

Epoch: 5| Step: 5
Training loss: 1.5206053256988525
Validation loss: 2.027701436832387

Epoch: 5| Step: 6
Training loss: 0.9566646814346313
Validation loss: 2.01490359152517

Epoch: 5| Step: 7
Training loss: 1.3729712963104248
Validation loss: 2.019850507859261

Epoch: 5| Step: 8
Training loss: 1.4513781070709229
Validation loss: 1.9673734262425413

Epoch: 5| Step: 9
Training loss: 1.0855016708374023
Validation loss: 2.002683001179849

Epoch: 5| Step: 10
Training loss: 1.1904573440551758
Validation loss: 1.9852289974048574

Epoch: 613| Step: 0
Training loss: 1.2454663515090942
Validation loss: 1.9524809365631433

Epoch: 5| Step: 1
Training loss: 1.1306114196777344
Validation loss: 1.9421330908293366

Epoch: 5| Step: 2
Training loss: 1.4759070873260498
Validation loss: 1.9416443827331706

Epoch: 5| Step: 3
Training loss: 1.6117722988128662
Validation loss: 1.9759195004740069

Epoch: 5| Step: 4
Training loss: 1.1281923055648804
Validation loss: 1.9921044521434332

Epoch: 5| Step: 5
Training loss: 0.8527253866195679
Validation loss: 1.970797839985099

Epoch: 5| Step: 6
Training loss: 1.1389210224151611
Validation loss: 1.983997155261296

Epoch: 5| Step: 7
Training loss: 1.5186687707901
Validation loss: 1.9706558309575564

Epoch: 5| Step: 8
Training loss: 1.284508466720581
Validation loss: 1.9695503480972782

Epoch: 5| Step: 9
Training loss: 1.5976788997650146
Validation loss: 1.9565761320052608

Epoch: 5| Step: 10
Training loss: 1.3937166929244995
Validation loss: 2.0119513516784995

Epoch: 614| Step: 0
Training loss: 1.8422629833221436
Validation loss: 1.978138836481238

Epoch: 5| Step: 1
Training loss: 1.3695200681686401
Validation loss: 1.976483468086489

Epoch: 5| Step: 2
Training loss: 1.1043418645858765
Validation loss: 1.9829662512707453

Epoch: 5| Step: 3
Training loss: 1.1648879051208496
Validation loss: 1.999144692574778

Epoch: 5| Step: 4
Training loss: 1.2308709621429443
Validation loss: 1.9864909097712526

Epoch: 5| Step: 5
Training loss: 2.0141441822052
Validation loss: 1.985754592444307

Epoch: 5| Step: 6
Training loss: 1.0892244577407837
Validation loss: 1.9858216649742537

Epoch: 5| Step: 7
Training loss: 1.1413886547088623
Validation loss: 1.9607891292982205

Epoch: 5| Step: 8
Training loss: 0.5836580991744995
Validation loss: 1.9767599080198555

Epoch: 5| Step: 9
Training loss: 1.5996534824371338
Validation loss: 1.9480873000237249

Epoch: 5| Step: 10
Training loss: 1.3419820070266724
Validation loss: 1.9517573823211014

Epoch: 615| Step: 0
Training loss: 1.041208028793335
Validation loss: 1.9877324847764866

Epoch: 5| Step: 1
Training loss: 1.5627787113189697
Validation loss: 2.008971937241093

Epoch: 5| Step: 2
Training loss: 1.0055410861968994
Validation loss: 1.9680283377247472

Epoch: 5| Step: 3
Training loss: 1.4323158264160156
Validation loss: 1.9529701637965378

Epoch: 5| Step: 4
Training loss: 1.4078348875045776
Validation loss: 1.975235080206266

Epoch: 5| Step: 5
Training loss: 1.5029408931732178
Validation loss: 1.9536293116948937

Epoch: 5| Step: 6
Training loss: 1.0548632144927979
Validation loss: 1.9648861167251424

Epoch: 5| Step: 7
Training loss: 1.183635950088501
Validation loss: 1.9565714930975309

Epoch: 5| Step: 8
Training loss: 1.1717243194580078
Validation loss: 1.9415826925667383

Epoch: 5| Step: 9
Training loss: 1.3473303318023682
Validation loss: 1.9634159098389328

Epoch: 5| Step: 10
Training loss: 1.5400944948196411
Validation loss: 1.9657832576382546

Epoch: 616| Step: 0
Training loss: 1.2193104028701782
Validation loss: 1.9525933073412987

Epoch: 5| Step: 1
Training loss: 1.6045963764190674
Validation loss: 1.9486012625437912

Epoch: 5| Step: 2
Training loss: 1.0872691869735718
Validation loss: 1.9498486044586345

Epoch: 5| Step: 3
Training loss: 1.3341240882873535
Validation loss: 1.9570078221700524

Epoch: 5| Step: 4
Training loss: 1.6725432872772217
Validation loss: 1.9579326363020046

Epoch: 5| Step: 5
Training loss: 0.645257830619812
Validation loss: 1.9725231201417985

Epoch: 5| Step: 6
Training loss: 1.445258617401123
Validation loss: 1.9547794172840733

Epoch: 5| Step: 7
Training loss: 1.2168829441070557
Validation loss: 1.9700407648599276

Epoch: 5| Step: 8
Training loss: 1.5125929117202759
Validation loss: 1.9837308519630021

Epoch: 5| Step: 9
Training loss: 0.6984771490097046
Validation loss: 1.9609584885258828

Epoch: 5| Step: 10
Training loss: 1.746394157409668
Validation loss: 1.9257679600869455

Epoch: 617| Step: 0
Training loss: 1.2683690786361694
Validation loss: 1.9645180484300018

Epoch: 5| Step: 1
Training loss: 1.9999889135360718
Validation loss: 1.937583492648217

Epoch: 5| Step: 2
Training loss: 1.458984136581421
Validation loss: 1.9816731624705817

Epoch: 5| Step: 3
Training loss: 1.2303768396377563
Validation loss: 2.0081177142358597

Epoch: 5| Step: 4
Training loss: 0.919874370098114
Validation loss: 1.9900676896495204

Epoch: 5| Step: 5
Training loss: 1.1775306463241577
Validation loss: 1.9988140803511425

Epoch: 5| Step: 6
Training loss: 1.1295477151870728
Validation loss: 2.022877912367544

Epoch: 5| Step: 7
Training loss: 1.4065542221069336
Validation loss: 1.9741055375786238

Epoch: 5| Step: 8
Training loss: 1.0647355318069458
Validation loss: 2.0017600533782796

Epoch: 5| Step: 9
Training loss: 1.507449746131897
Validation loss: 1.9613495924139535

Epoch: 5| Step: 10
Training loss: 0.9793931245803833
Validation loss: 1.9543485141569568

Epoch: 618| Step: 0
Training loss: 1.33245050907135
Validation loss: 1.9775599638621013

Epoch: 5| Step: 1
Training loss: 2.1415867805480957
Validation loss: 1.9550762663605392

Epoch: 5| Step: 2
Training loss: 1.1381456851959229
Validation loss: 1.9620490638158654

Epoch: 5| Step: 3
Training loss: 0.827721893787384
Validation loss: 1.9757969430697861

Epoch: 5| Step: 4
Training loss: 1.2184321880340576
Validation loss: 1.9501775233976302

Epoch: 5| Step: 5
Training loss: 1.2853002548217773
Validation loss: 1.910599757266301

Epoch: 5| Step: 6
Training loss: 1.6585487127304077
Validation loss: 1.9601250617734847

Epoch: 5| Step: 7
Training loss: 0.928641676902771
Validation loss: 1.9688587009265859

Epoch: 5| Step: 8
Training loss: 0.7874398231506348
Validation loss: 1.9519653858677033

Epoch: 5| Step: 9
Training loss: 1.2672348022460938
Validation loss: 1.9645167384096371

Epoch: 5| Step: 10
Training loss: 1.5526620149612427
Validation loss: 1.9694125049857683

Epoch: 619| Step: 0
Training loss: 1.4772089719772339
Validation loss: 1.974918374451258

Epoch: 5| Step: 1
Training loss: 1.0212551355361938
Validation loss: 1.9444605176166823

Epoch: 5| Step: 2
Training loss: 1.5023056268692017
Validation loss: 1.9670353012700235

Epoch: 5| Step: 3
Training loss: 1.4239860773086548
Validation loss: 1.9512277034021193

Epoch: 5| Step: 4
Training loss: 0.8433691263198853
Validation loss: 1.978374099218717

Epoch: 5| Step: 5
Training loss: 1.1156537532806396
Validation loss: 1.9666577692954772

Epoch: 5| Step: 6
Training loss: 1.4000253677368164
Validation loss: 1.9701376858577933

Epoch: 5| Step: 7
Training loss: 1.1601905822753906
Validation loss: 1.9539133194954164

Epoch: 5| Step: 8
Training loss: 1.248578667640686
Validation loss: 1.9416971565574728

Epoch: 5| Step: 9
Training loss: 1.4184648990631104
Validation loss: 1.9850881048428115

Epoch: 5| Step: 10
Training loss: 1.375536322593689
Validation loss: 2.016150806539802

Epoch: 620| Step: 0
Training loss: 1.021932601928711
Validation loss: 1.9857307044408654

Epoch: 5| Step: 1
Training loss: 1.1948705911636353
Validation loss: 1.9701511347165672

Epoch: 5| Step: 2
Training loss: 1.3419063091278076
Validation loss: 1.9958350376416278

Epoch: 5| Step: 3
Training loss: 1.4532337188720703
Validation loss: 1.9637277357039913

Epoch: 5| Step: 4
Training loss: 0.9414846301078796
Validation loss: 1.986208705491917

Epoch: 5| Step: 5
Training loss: 1.611638069152832
Validation loss: 1.9861219480473509

Epoch: 5| Step: 6
Training loss: 1.2414172887802124
Validation loss: 1.9832192082558908

Epoch: 5| Step: 7
Training loss: 1.0093823671340942
Validation loss: 1.9809652118272678

Epoch: 5| Step: 8
Training loss: 0.9908931851387024
Validation loss: 1.9840977281652472

Epoch: 5| Step: 9
Training loss: 1.8659816980361938
Validation loss: 1.9689162520952121

Epoch: 5| Step: 10
Training loss: 1.3605422973632812
Validation loss: 1.977219166294221

Epoch: 621| Step: 0
Training loss: 1.3252307176589966
Validation loss: 1.9869508563831288

Epoch: 5| Step: 1
Training loss: 1.249253749847412
Validation loss: 1.9797510998223418

Epoch: 5| Step: 2
Training loss: 1.5453084707260132
Validation loss: 1.9871011908336351

Epoch: 5| Step: 3
Training loss: 1.7833493947982788
Validation loss: 1.99451478322347

Epoch: 5| Step: 4
Training loss: 0.9970842599868774
Validation loss: 1.9689964991743847

Epoch: 5| Step: 5
Training loss: 1.4420545101165771
Validation loss: 1.9695806413568475

Epoch: 5| Step: 6
Training loss: 1.4621731042861938
Validation loss: 1.9439898075595978

Epoch: 5| Step: 7
Training loss: 1.2450158596038818
Validation loss: 1.9623620330646474

Epoch: 5| Step: 8
Training loss: 0.9097518920898438
Validation loss: 2.005162787693803

Epoch: 5| Step: 9
Training loss: 1.2261642217636108
Validation loss: 1.9843025463883595

Epoch: 5| Step: 10
Training loss: 0.8141066431999207
Validation loss: 1.9527210522723455

Epoch: 622| Step: 0
Training loss: 1.307470679283142
Validation loss: 1.9602228569728073

Epoch: 5| Step: 1
Training loss: 1.5954647064208984
Validation loss: 1.9747066472166328

Epoch: 5| Step: 2
Training loss: 1.1625200510025024
Validation loss: 2.0146112544562227

Epoch: 5| Step: 3
Training loss: 1.2587320804595947
Validation loss: 1.9854305713407454

Epoch: 5| Step: 4
Training loss: 1.1340522766113281
Validation loss: 1.9816351257344729

Epoch: 5| Step: 5
Training loss: 0.8457678556442261
Validation loss: 1.9734748384003997

Epoch: 5| Step: 6
Training loss: 0.9672340154647827
Validation loss: 1.9746988127308507

Epoch: 5| Step: 7
Training loss: 1.433366060256958
Validation loss: 1.9568867837229083

Epoch: 5| Step: 8
Training loss: 1.5262095928192139
Validation loss: 1.9832014088989587

Epoch: 5| Step: 9
Training loss: 1.340815544128418
Validation loss: 1.9992400728246218

Epoch: 5| Step: 10
Training loss: 1.2594285011291504
Validation loss: 1.981603801891368

Epoch: 623| Step: 0
Training loss: 1.1813747882843018
Validation loss: 1.9421164758743779

Epoch: 5| Step: 1
Training loss: 1.2095662355422974
Validation loss: 1.9732099374135335

Epoch: 5| Step: 2
Training loss: 1.274927020072937
Validation loss: 1.961442655132663

Epoch: 5| Step: 3
Training loss: 1.8215844631195068
Validation loss: 1.964178410909509

Epoch: 5| Step: 4
Training loss: 1.2520602941513062
Validation loss: 1.9875559640187088

Epoch: 5| Step: 5
Training loss: 1.869297742843628
Validation loss: 1.9698863285844044

Epoch: 5| Step: 6
Training loss: 1.1100242137908936
Validation loss: 1.993860931806667

Epoch: 5| Step: 7
Training loss: 1.4612172842025757
Validation loss: 1.9676613294950096

Epoch: 5| Step: 8
Training loss: 0.8389819860458374
Validation loss: 1.9687950957205989

Epoch: 5| Step: 9
Training loss: 0.9953622817993164
Validation loss: 1.9636433534724738

Epoch: 5| Step: 10
Training loss: 0.8229269981384277
Validation loss: 1.909146430671856

Epoch: 624| Step: 0
Training loss: 0.9265614748001099
Validation loss: 1.9747635164568502

Epoch: 5| Step: 1
Training loss: 1.6298271417617798
Validation loss: 1.969550568570373

Epoch: 5| Step: 2
Training loss: 1.1941118240356445
Validation loss: 1.9720580270213466

Epoch: 5| Step: 3
Training loss: 1.720041275024414
Validation loss: 1.9341864137239353

Epoch: 5| Step: 4
Training loss: 1.5170016288757324
Validation loss: 1.9418642828541417

Epoch: 5| Step: 5
Training loss: 0.8322038650512695
Validation loss: 1.9477927992420812

Epoch: 5| Step: 6
Training loss: 1.3892712593078613
Validation loss: 1.9710699473657916

Epoch: 5| Step: 7
Training loss: 1.5621442794799805
Validation loss: 1.9451619386672974

Epoch: 5| Step: 8
Training loss: 1.458828330039978
Validation loss: 1.9693958285034343

Epoch: 5| Step: 9
Training loss: 0.833831787109375
Validation loss: 1.9281998449756252

Epoch: 5| Step: 10
Training loss: 0.8792749047279358
Validation loss: 1.9968901090724493

Epoch: 625| Step: 0
Training loss: 1.5340440273284912
Validation loss: 1.9586073660081433

Epoch: 5| Step: 1
Training loss: 1.6657798290252686
Validation loss: 2.0008718787982898

Epoch: 5| Step: 2
Training loss: 0.8737985491752625
Validation loss: 1.9568616087718675

Epoch: 5| Step: 3
Training loss: 1.3645401000976562
Validation loss: 1.9854722381919943

Epoch: 5| Step: 4
Training loss: 0.9834111928939819
Validation loss: 1.9138795675769928

Epoch: 5| Step: 5
Training loss: 0.9959863424301147
Validation loss: 1.9880481625116

Epoch: 5| Step: 6
Training loss: 1.4314037561416626
Validation loss: 1.9603460732326712

Epoch: 5| Step: 7
Training loss: 1.2380635738372803
Validation loss: 1.9672751542060607

Epoch: 5| Step: 8
Training loss: 0.948189377784729
Validation loss: 1.9798666251602994

Epoch: 5| Step: 9
Training loss: 1.6535072326660156
Validation loss: 1.9516710671045447

Epoch: 5| Step: 10
Training loss: 1.4849613904953003
Validation loss: 1.9700971367538616

Epoch: 626| Step: 0
Training loss: 1.7523609399795532
Validation loss: 1.9894629422054495

Epoch: 5| Step: 1
Training loss: 1.051738977432251
Validation loss: 1.9701559902519308

Epoch: 5| Step: 2
Training loss: 1.2497715950012207
Validation loss: 1.977505737735379

Epoch: 5| Step: 3
Training loss: 0.6509174108505249
Validation loss: 1.9673046950371034

Epoch: 5| Step: 4
Training loss: 1.9142738580703735
Validation loss: 1.963368813196818

Epoch: 5| Step: 5
Training loss: 1.2800872325897217
Validation loss: 1.946959000761791

Epoch: 5| Step: 6
Training loss: 1.4434221982955933
Validation loss: 2.017142918802077

Epoch: 5| Step: 7
Training loss: 1.123887538909912
Validation loss: 2.003566885507235

Epoch: 5| Step: 8
Training loss: 0.9510955810546875
Validation loss: 1.9854079202939106

Epoch: 5| Step: 9
Training loss: 1.0144990682601929
Validation loss: 1.9703762198007235

Epoch: 5| Step: 10
Training loss: 1.6054741144180298
Validation loss: 1.971349371376858

Epoch: 627| Step: 0
Training loss: 1.512805461883545
Validation loss: 1.9427721269669072

Epoch: 5| Step: 1
Training loss: 0.7097262144088745
Validation loss: 1.952993550608235

Epoch: 5| Step: 2
Training loss: 2.111530065536499
Validation loss: 1.991966720550291

Epoch: 5| Step: 3
Training loss: 1.386948585510254
Validation loss: 1.9584344125563098

Epoch: 5| Step: 4
Training loss: 1.1933116912841797
Validation loss: 1.9442952166321457

Epoch: 5| Step: 5
Training loss: 1.2426457405090332
Validation loss: 1.9807541331937235

Epoch: 5| Step: 6
Training loss: 1.0112717151641846
Validation loss: 1.9504874778050247

Epoch: 5| Step: 7
Training loss: 1.4459558725357056
Validation loss: 1.9708582432039323

Epoch: 5| Step: 8
Training loss: 1.3436131477355957
Validation loss: 1.9482448024134482

Epoch: 5| Step: 9
Training loss: 1.2892358303070068
Validation loss: 1.9716947822160618

Epoch: 5| Step: 10
Training loss: 0.861116886138916
Validation loss: 1.955696831467331

Epoch: 628| Step: 0
Training loss: 1.5708837509155273
Validation loss: 1.9501468430283249

Epoch: 5| Step: 1
Training loss: 1.061732292175293
Validation loss: 1.9332251523130684

Epoch: 5| Step: 2
Training loss: 1.4369804859161377
Validation loss: 1.954287463618863

Epoch: 5| Step: 3
Training loss: 1.136010766029358
Validation loss: 1.9884748407589492

Epoch: 5| Step: 4
Training loss: 1.3960466384887695
Validation loss: 1.9686770490420762

Epoch: 5| Step: 5
Training loss: 1.0978453159332275
Validation loss: 1.9905190929289787

Epoch: 5| Step: 6
Training loss: 1.2044378519058228
Validation loss: 1.962995622747688

Epoch: 5| Step: 7
Training loss: 1.4555087089538574
Validation loss: 1.9830385818276355

Epoch: 5| Step: 8
Training loss: 0.9217246770858765
Validation loss: 1.988558735898746

Epoch: 5| Step: 9
Training loss: 1.386460542678833
Validation loss: 1.9702195134214175

Epoch: 5| Step: 10
Training loss: 1.4854744672775269
Validation loss: 1.9772883692095358

Epoch: 629| Step: 0
Training loss: 1.2606027126312256
Validation loss: 1.9537615288970291

Epoch: 5| Step: 1
Training loss: 0.9485846757888794
Validation loss: 1.957362715915967

Epoch: 5| Step: 2
Training loss: 1.3894479274749756
Validation loss: 2.029859762037954

Epoch: 5| Step: 3
Training loss: 1.7880918979644775
Validation loss: 1.9527600042281612

Epoch: 5| Step: 4
Training loss: 1.2806833982467651
Validation loss: 1.952760748965766

Epoch: 5| Step: 5
Training loss: 0.7612566947937012
Validation loss: 1.9432426755146315

Epoch: 5| Step: 6
Training loss: 1.5898196697235107
Validation loss: 1.9490314965607018

Epoch: 5| Step: 7
Training loss: 1.3370840549468994
Validation loss: 1.954944795177829

Epoch: 5| Step: 8
Training loss: 1.2109119892120361
Validation loss: 1.9713982459037536

Epoch: 5| Step: 9
Training loss: 1.0770432949066162
Validation loss: 2.006963660640101

Epoch: 5| Step: 10
Training loss: 1.443487286567688
Validation loss: 1.9562738428833664

Epoch: 630| Step: 0
Training loss: 1.0525195598602295
Validation loss: 1.998114675603887

Epoch: 5| Step: 1
Training loss: 1.7753921747207642
Validation loss: 1.9568592758588894

Epoch: 5| Step: 2
Training loss: 1.127055287361145
Validation loss: 1.9726642934224938

Epoch: 5| Step: 3
Training loss: 1.0701253414154053
Validation loss: 2.021269444496401

Epoch: 5| Step: 4
Training loss: 1.3548033237457275
Validation loss: 1.965922514597575

Epoch: 5| Step: 5
Training loss: 1.0434644222259521
Validation loss: 1.9986516942260086

Epoch: 5| Step: 6
Training loss: 1.587221622467041
Validation loss: 1.923002957015909

Epoch: 5| Step: 7
Training loss: 1.217918872833252
Validation loss: 1.9618099017809796

Epoch: 5| Step: 8
Training loss: 1.1192280054092407
Validation loss: 1.9978603175891343

Epoch: 5| Step: 9
Training loss: 1.6372692584991455
Validation loss: 1.9760631617679392

Epoch: 5| Step: 10
Training loss: 0.9009383320808411
Validation loss: 1.9220312526149135

Epoch: 631| Step: 0
Training loss: 1.4766590595245361
Validation loss: 1.933740121062084

Epoch: 5| Step: 1
Training loss: 1.6645876169204712
Validation loss: 1.9809070030848186

Epoch: 5| Step: 2
Training loss: 1.2784432172775269
Validation loss: 1.9930019686298985

Epoch: 5| Step: 3
Training loss: 1.3081518411636353
Validation loss: 1.9099817096546132

Epoch: 5| Step: 4
Training loss: 1.201448917388916
Validation loss: 1.9671370073031353

Epoch: 5| Step: 5
Training loss: 1.3117767572402954
Validation loss: 1.9993580836121754

Epoch: 5| Step: 6
Training loss: 0.991329550743103
Validation loss: 1.9570893420968005

Epoch: 5| Step: 7
Training loss: 1.2967904806137085
Validation loss: 1.9517259751596758

Epoch: 5| Step: 8
Training loss: 1.2509952783584595
Validation loss: 1.954211711883545

Epoch: 5| Step: 9
Training loss: 1.2268133163452148
Validation loss: 1.9592556235610799

Epoch: 5| Step: 10
Training loss: 0.7893754243850708
Validation loss: 1.929397907308353

Epoch: 632| Step: 0
Training loss: 1.0046241283416748
Validation loss: 1.9655406436612528

Epoch: 5| Step: 1
Training loss: 1.1591675281524658
Validation loss: 1.9355726113883398

Epoch: 5| Step: 2
Training loss: 1.5730854272842407
Validation loss: 1.9167990261508572

Epoch: 5| Step: 3
Training loss: 1.5676891803741455
Validation loss: 2.02099879582723

Epoch: 5| Step: 4
Training loss: 1.085659384727478
Validation loss: 1.9459286171902892

Epoch: 5| Step: 5
Training loss: 1.6848194599151611
Validation loss: 1.9971630342545048

Epoch: 5| Step: 6
Training loss: 1.0458470582962036
Validation loss: 1.9707426922295683

Epoch: 5| Step: 7
Training loss: 0.8614595532417297
Validation loss: 1.9727196719056816

Epoch: 5| Step: 8
Training loss: 1.1777842044830322
Validation loss: 1.9904824533770162

Epoch: 5| Step: 9
Training loss: 1.206294298171997
Validation loss: 1.956410358029027

Epoch: 5| Step: 10
Training loss: 1.5257295370101929
Validation loss: 2.0016076795516478

Epoch: 633| Step: 0
Training loss: 1.0952749252319336
Validation loss: 1.9631609532140917

Epoch: 5| Step: 1
Training loss: 1.7957862615585327
Validation loss: 1.921495834986369

Epoch: 5| Step: 2
Training loss: 1.3891937732696533
Validation loss: 1.9628839428706835

Epoch: 5| Step: 3
Training loss: 1.8404810428619385
Validation loss: 1.9542022341041154

Epoch: 5| Step: 4
Training loss: 1.453367829322815
Validation loss: 1.952886228920311

Epoch: 5| Step: 5
Training loss: 1.0926361083984375
Validation loss: 1.9815602533278927

Epoch: 5| Step: 6
Training loss: 0.7600527405738831
Validation loss: 1.962535653063046

Epoch: 5| Step: 7
Training loss: 1.5410311222076416
Validation loss: 1.9802095044043757

Epoch: 5| Step: 8
Training loss: 1.0845482349395752
Validation loss: 1.9536731409770187

Epoch: 5| Step: 9
Training loss: 0.9234557151794434
Validation loss: 1.9249793047546058

Epoch: 5| Step: 10
Training loss: 0.8360776305198669
Validation loss: 1.957424145872875

Epoch: 634| Step: 0
Training loss: 1.3241527080535889
Validation loss: 1.9686627413636895

Epoch: 5| Step: 1
Training loss: 0.8917274475097656
Validation loss: 1.9648012115109352

Epoch: 5| Step: 2
Training loss: 0.8208772540092468
Validation loss: 1.9727371572166361

Epoch: 5| Step: 3
Training loss: 1.3455321788787842
Validation loss: 1.9674561985077397

Epoch: 5| Step: 4
Training loss: 1.5394514799118042
Validation loss: 1.937605659166972

Epoch: 5| Step: 5
Training loss: 1.2575961351394653
Validation loss: 1.9629467918026833

Epoch: 5| Step: 6
Training loss: 1.3363687992095947
Validation loss: 1.9809885486479728

Epoch: 5| Step: 7
Training loss: 0.9082285761833191
Validation loss: 1.9433700628178094

Epoch: 5| Step: 8
Training loss: 1.3473162651062012
Validation loss: 1.9690856113228747

Epoch: 5| Step: 9
Training loss: 1.1104004383087158
Validation loss: 1.948830650698754

Epoch: 5| Step: 10
Training loss: 1.8333913087844849
Validation loss: 1.962599157005228

Epoch: 635| Step: 0
Training loss: 0.9924523234367371
Validation loss: 1.9675439814085602

Epoch: 5| Step: 1
Training loss: 0.9980789422988892
Validation loss: 1.944430314084535

Epoch: 5| Step: 2
Training loss: 1.2791070938110352
Validation loss: 1.947103836203134

Epoch: 5| Step: 3
Training loss: 1.6298223733901978
Validation loss: 1.9594579922255648

Epoch: 5| Step: 4
Training loss: 0.923902690410614
Validation loss: 1.9701407532538138

Epoch: 5| Step: 5
Training loss: 0.8908758163452148
Validation loss: 1.9796381047976914

Epoch: 5| Step: 6
Training loss: 1.2661192417144775
Validation loss: 1.9333317529770635

Epoch: 5| Step: 7
Training loss: 1.3110597133636475
Validation loss: 2.0048252536404516

Epoch: 5| Step: 8
Training loss: 1.2368552684783936
Validation loss: 1.9701023050533828

Epoch: 5| Step: 9
Training loss: 1.5587530136108398
Validation loss: 1.9628920965297247

Epoch: 5| Step: 10
Training loss: 1.4760736227035522
Validation loss: 1.9766282702005038

Epoch: 636| Step: 0
Training loss: 1.190699815750122
Validation loss: 1.953019303660239

Epoch: 5| Step: 1
Training loss: 1.673203706741333
Validation loss: 1.9819218856032177

Epoch: 5| Step: 2
Training loss: 1.149977684020996
Validation loss: 1.946929354821482

Epoch: 5| Step: 3
Training loss: 1.4776277542114258
Validation loss: 1.9559253736208844

Epoch: 5| Step: 4
Training loss: 1.1728501319885254
Validation loss: 1.9842018683751423

Epoch: 5| Step: 5
Training loss: 1.3668439388275146
Validation loss: 1.9804630023176952

Epoch: 5| Step: 6
Training loss: 1.6841840744018555
Validation loss: 1.9511140572127474

Epoch: 5| Step: 7
Training loss: 1.1111323833465576
Validation loss: 1.9886337018782092

Epoch: 5| Step: 8
Training loss: 0.8666976690292358
Validation loss: 1.9514855441226755

Epoch: 5| Step: 9
Training loss: 1.0256245136260986
Validation loss: 1.9602062009995984

Epoch: 5| Step: 10
Training loss: 1.238723874092102
Validation loss: 1.9182075249251498

Epoch: 637| Step: 0
Training loss: 0.8123211860656738
Validation loss: 1.9535611419267551

Epoch: 5| Step: 1
Training loss: 1.2255549430847168
Validation loss: 1.9679309655261297

Epoch: 5| Step: 2
Training loss: 1.2383900880813599
Validation loss: 1.9519432513944563

Epoch: 5| Step: 3
Training loss: 1.6970970630645752
Validation loss: 1.9698191945270827

Epoch: 5| Step: 4
Training loss: 1.3452279567718506
Validation loss: 1.9650112685336862

Epoch: 5| Step: 5
Training loss: 1.2395731210708618
Validation loss: 1.9402246065037225

Epoch: 5| Step: 6
Training loss: 1.4747222661972046
Validation loss: 1.9429778001641715

Epoch: 5| Step: 7
Training loss: 0.9493171572685242
Validation loss: 1.9842912663695633

Epoch: 5| Step: 8
Training loss: 0.9000197649002075
Validation loss: 1.956117832532493

Epoch: 5| Step: 9
Training loss: 1.6180320978164673
Validation loss: 1.9434516045355028

Epoch: 5| Step: 10
Training loss: 1.3348369598388672
Validation loss: 1.9669328889539164

Epoch: 638| Step: 0
Training loss: 1.6938393115997314
Validation loss: 2.002050115216163

Epoch: 5| Step: 1
Training loss: 1.0625916719436646
Validation loss: 1.960755378969254

Epoch: 5| Step: 2
Training loss: 0.8309066891670227
Validation loss: 1.9381904012413436

Epoch: 5| Step: 3
Training loss: 1.003583550453186
Validation loss: 1.9453545847246725

Epoch: 5| Step: 4
Training loss: 1.1206047534942627
Validation loss: 1.9894498407199819

Epoch: 5| Step: 5
Training loss: 1.3106619119644165
Validation loss: 1.9363491125004266

Epoch: 5| Step: 6
Training loss: 1.594539999961853
Validation loss: 1.974708495601531

Epoch: 5| Step: 7
Training loss: 1.2489893436431885
Validation loss: 1.9673387799211728

Epoch: 5| Step: 8
Training loss: 1.6983087062835693
Validation loss: 1.988834733604103

Epoch: 5| Step: 9
Training loss: 0.8215526342391968
Validation loss: 1.9690893952564528

Epoch: 5| Step: 10
Training loss: 1.1702584028244019
Validation loss: 1.9549947784792991

Epoch: 639| Step: 0
Training loss: 1.338871717453003
Validation loss: 1.9886542430488012

Epoch: 5| Step: 1
Training loss: 1.2888503074645996
Validation loss: 1.9981299690020982

Epoch: 5| Step: 2
Training loss: 1.1430000066757202
Validation loss: 1.9909680017860987

Epoch: 5| Step: 3
Training loss: 1.3671627044677734
Validation loss: 1.9458436953124179

Epoch: 5| Step: 4
Training loss: 1.6750141382217407
Validation loss: 1.909554559697387

Epoch: 5| Step: 5
Training loss: 1.5911791324615479
Validation loss: 1.9433065627210884

Epoch: 5| Step: 6
Training loss: 1.235289216041565
Validation loss: 1.9897741053694038

Epoch: 5| Step: 7
Training loss: 0.4080332815647125
Validation loss: 1.9559646652590843

Epoch: 5| Step: 8
Training loss: 1.1730495691299438
Validation loss: 1.9278495696283156

Epoch: 5| Step: 9
Training loss: 1.3287684917449951
Validation loss: 1.9230312749903689

Epoch: 5| Step: 10
Training loss: 0.9895672798156738
Validation loss: 1.9595597790133568

Epoch: 640| Step: 0
Training loss: 1.1593376398086548
Validation loss: 1.9749817079113376

Epoch: 5| Step: 1
Training loss: 1.4016165733337402
Validation loss: 1.923015530391406

Epoch: 5| Step: 2
Training loss: 1.153959035873413
Validation loss: 1.978763912313728

Epoch: 5| Step: 3
Training loss: 1.0179942846298218
Validation loss: 1.9577394659801195

Epoch: 5| Step: 4
Training loss: 0.7701689004898071
Validation loss: 1.9506927779925767

Epoch: 5| Step: 5
Training loss: 1.7397634983062744
Validation loss: 1.952537916039908

Epoch: 5| Step: 6
Training loss: 1.1463854312896729
Validation loss: 1.9813694005371423

Epoch: 5| Step: 7
Training loss: 1.0525627136230469
Validation loss: 1.9876257745168542

Epoch: 5| Step: 8
Training loss: 1.6188815832138062
Validation loss: 1.985485848560128

Epoch: 5| Step: 9
Training loss: 1.2162892818450928
Validation loss: 1.9610312856653684

Epoch: 5| Step: 10
Training loss: 1.4947333335876465
Validation loss: 1.955379847557314

Epoch: 641| Step: 0
Training loss: 1.3522590398788452
Validation loss: 1.9686641334205546

Epoch: 5| Step: 1
Training loss: 1.190040946006775
Validation loss: 1.9636973642533826

Epoch: 5| Step: 2
Training loss: 1.3334276676177979
Validation loss: 1.9637422471918085

Epoch: 5| Step: 3
Training loss: 1.2884153127670288
Validation loss: 1.9738157192866008

Epoch: 5| Step: 4
Training loss: 0.9327045679092407
Validation loss: 1.9414893773294264

Epoch: 5| Step: 5
Training loss: 0.918990969657898
Validation loss: 1.9867812036186137

Epoch: 5| Step: 6
Training loss: 1.1997053623199463
Validation loss: 1.9843117652400848

Epoch: 5| Step: 7
Training loss: 1.4442102909088135
Validation loss: 1.966220413484881

Epoch: 5| Step: 8
Training loss: 1.4494214057922363
Validation loss: 1.978652802846765

Epoch: 5| Step: 9
Training loss: 1.5533970594406128
Validation loss: 1.9557959571961434

Epoch: 5| Step: 10
Training loss: 1.3126152753829956
Validation loss: 1.9533520052509923

Epoch: 642| Step: 0
Training loss: 1.2821546792984009
Validation loss: 1.9530212353634577

Epoch: 5| Step: 1
Training loss: 1.4442837238311768
Validation loss: 1.9794185110317764

Epoch: 5| Step: 2
Training loss: 1.2077319622039795
Validation loss: 1.947619591989825

Epoch: 5| Step: 3
Training loss: 1.4406689405441284
Validation loss: 1.9804469347000122

Epoch: 5| Step: 4
Training loss: 1.009408950805664
Validation loss: 1.9693980268252793

Epoch: 5| Step: 5
Training loss: 1.6448719501495361
Validation loss: 1.9424505054309804

Epoch: 5| Step: 6
Training loss: 1.4870142936706543
Validation loss: 1.9860812002612698

Epoch: 5| Step: 7
Training loss: 0.9097970128059387
Validation loss: 1.9699560403823853

Epoch: 5| Step: 8
Training loss: 1.493119478225708
Validation loss: 1.9427277349656629

Epoch: 5| Step: 9
Training loss: 0.7969435453414917
Validation loss: 1.957236478405614

Epoch: 5| Step: 10
Training loss: 0.8463239669799805
Validation loss: 1.9497260855090233

Epoch: 643| Step: 0
Training loss: 1.0017969608306885
Validation loss: 1.9589147542112617

Epoch: 5| Step: 1
Training loss: 1.326540231704712
Validation loss: 1.9718230116751887

Epoch: 5| Step: 2
Training loss: 1.0202174186706543
Validation loss: 1.9607606446871193

Epoch: 5| Step: 3
Training loss: 1.3511512279510498
Validation loss: 1.9938091462658298

Epoch: 5| Step: 4
Training loss: 1.598901391029358
Validation loss: 1.978409985060333

Epoch: 5| Step: 5
Training loss: 1.194342017173767
Validation loss: 1.9554843543678202

Epoch: 5| Step: 6
Training loss: 0.9527593851089478
Validation loss: 2.001028573641213

Epoch: 5| Step: 7
Training loss: 0.9900051355361938
Validation loss: 1.963475784306885

Epoch: 5| Step: 8
Training loss: 1.1237480640411377
Validation loss: 2.0066260035319994

Epoch: 5| Step: 9
Training loss: 1.6893126964569092
Validation loss: 1.9909525596967308

Epoch: 5| Step: 10
Training loss: 1.4419291019439697
Validation loss: 1.954114024357129

Epoch: 644| Step: 0
Training loss: 1.1568695306777954
Validation loss: 1.966215887377339

Epoch: 5| Step: 1
Training loss: 1.1093676090240479
Validation loss: 1.951627274995209

Epoch: 5| Step: 2
Training loss: 0.8707777261734009
Validation loss: 1.9623479714957617

Epoch: 5| Step: 3
Training loss: 1.3047339916229248
Validation loss: 1.940497706013341

Epoch: 5| Step: 4
Training loss: 1.1858785152435303
Validation loss: 1.9348095309349798

Epoch: 5| Step: 5
Training loss: 1.3188350200653076
Validation loss: 1.966353621534122

Epoch: 5| Step: 6
Training loss: 1.6071021556854248
Validation loss: 1.9843879797125374

Epoch: 5| Step: 7
Training loss: 1.168600082397461
Validation loss: 1.9984468606210524

Epoch: 5| Step: 8
Training loss: 1.6062126159667969
Validation loss: 1.982659896214803

Epoch: 5| Step: 9
Training loss: 1.2955031394958496
Validation loss: 1.9753854377295381

Epoch: 5| Step: 10
Training loss: 0.9514232873916626
Validation loss: 1.9543383172763291

Epoch: 645| Step: 0
Training loss: 1.4506429433822632
Validation loss: 1.9819974694200742

Epoch: 5| Step: 1
Training loss: 1.2290700674057007
Validation loss: 1.9853623605543567

Epoch: 5| Step: 2
Training loss: 1.2198535203933716
Validation loss: 1.9850101278674217

Epoch: 5| Step: 3
Training loss: 1.6397597789764404
Validation loss: 1.9543289933153378

Epoch: 5| Step: 4
Training loss: 0.623965859413147
Validation loss: 1.9750466705650411

Epoch: 5| Step: 5
Training loss: 1.2988243103027344
Validation loss: 2.0001765399850826

Epoch: 5| Step: 6
Training loss: 0.8880239725112915
Validation loss: 1.9746544963570052

Epoch: 5| Step: 7
Training loss: 0.8299344778060913
Validation loss: 1.963885736721818

Epoch: 5| Step: 8
Training loss: 1.287660837173462
Validation loss: 1.9499036573594617

Epoch: 5| Step: 9
Training loss: 1.2656034231185913
Validation loss: 2.0088061453193746

Epoch: 5| Step: 10
Training loss: 1.8988220691680908
Validation loss: 1.9780681671634797

Epoch: 646| Step: 0
Training loss: 0.9529019594192505
Validation loss: 1.930591196142217

Epoch: 5| Step: 1
Training loss: 1.655243158340454
Validation loss: 1.9679080106878792

Epoch: 5| Step: 2
Training loss: 0.7743244767189026
Validation loss: 1.9601197076100174

Epoch: 5| Step: 3
Training loss: 1.622064232826233
Validation loss: 1.948957025363881

Epoch: 5| Step: 4
Training loss: 0.8399041295051575
Validation loss: 1.9796447856451875

Epoch: 5| Step: 5
Training loss: 1.357090950012207
Validation loss: 1.9611824302263157

Epoch: 5| Step: 6
Training loss: 1.0768643617630005
Validation loss: 1.971338919413987

Epoch: 5| Step: 7
Training loss: 1.990391492843628
Validation loss: 1.9537411915358676

Epoch: 5| Step: 8
Training loss: 1.3038169145584106
Validation loss: 1.9636113746191866

Epoch: 5| Step: 9
Training loss: 0.5956803560256958
Validation loss: 1.9424647592729138

Epoch: 5| Step: 10
Training loss: 1.6087671518325806
Validation loss: 1.96908127620656

Epoch: 647| Step: 0
Training loss: 1.3355300426483154
Validation loss: 1.9544236198548348

Epoch: 5| Step: 1
Training loss: 1.0078999996185303
Validation loss: 1.9595376599219538

Epoch: 5| Step: 2
Training loss: 1.296434998512268
Validation loss: 1.994014734862953

Epoch: 5| Step: 3
Training loss: 0.8708606958389282
Validation loss: 1.9764157379827192

Epoch: 5| Step: 4
Training loss: 0.8983331918716431
Validation loss: 1.9598328349410847

Epoch: 5| Step: 5
Training loss: 1.2577064037322998
Validation loss: 2.0312951636570755

Epoch: 5| Step: 6
Training loss: 1.1945180892944336
Validation loss: 1.979667434128382

Epoch: 5| Step: 7
Training loss: 1.6953983306884766
Validation loss: 1.9597379033283522

Epoch: 5| Step: 8
Training loss: 0.954820990562439
Validation loss: 1.9701594998759608

Epoch: 5| Step: 9
Training loss: 1.4732829332351685
Validation loss: 1.9652150254095755

Epoch: 5| Step: 10
Training loss: 1.5275802612304688
Validation loss: 1.9734767739490797

Epoch: 648| Step: 0
Training loss: 1.4447340965270996
Validation loss: 1.9539044210987706

Epoch: 5| Step: 1
Training loss: 1.5345191955566406
Validation loss: 1.9724717473471036

Epoch: 5| Step: 2
Training loss: 1.273373007774353
Validation loss: 1.9669933319091797

Epoch: 5| Step: 3
Training loss: 0.7446893453598022
Validation loss: 1.977031030962544

Epoch: 5| Step: 4
Training loss: 1.2320895195007324
Validation loss: 1.959333219835835

Epoch: 5| Step: 5
Training loss: 1.2552335262298584
Validation loss: 1.9382514030702653

Epoch: 5| Step: 6
Training loss: 0.7455659508705139
Validation loss: 1.938119642196163

Epoch: 5| Step: 7
Training loss: 0.85687655210495
Validation loss: 1.9797479285988757

Epoch: 5| Step: 8
Training loss: 1.01301109790802
Validation loss: 1.948490325481661

Epoch: 5| Step: 9
Training loss: 1.8076496124267578
Validation loss: 1.9224424362182617

Epoch: 5| Step: 10
Training loss: 1.5879114866256714
Validation loss: 1.9687638436594317

Epoch: 649| Step: 0
Training loss: 0.9392368197441101
Validation loss: 1.9850654973778674

Epoch: 5| Step: 1
Training loss: 1.8349891901016235
Validation loss: 1.94547914689587

Epoch: 5| Step: 2
Training loss: 0.9005411267280579
Validation loss: 1.9637848625900924

Epoch: 5| Step: 3
Training loss: 1.5004940032958984
Validation loss: 1.992548551610721

Epoch: 5| Step: 4
Training loss: 0.8219295740127563
Validation loss: 1.9466020420033445

Epoch: 5| Step: 5
Training loss: 1.2405751943588257
Validation loss: 1.9935259139665993

Epoch: 5| Step: 6
Training loss: 0.7789231538772583
Validation loss: 1.9432769308808029

Epoch: 5| Step: 7
Training loss: 1.5219917297363281
Validation loss: 2.0022621154785156

Epoch: 5| Step: 8
Training loss: 0.885262668132782
Validation loss: 1.9315835019593597

Epoch: 5| Step: 9
Training loss: 1.2613253593444824
Validation loss: 1.9783198948829406

Epoch: 5| Step: 10
Training loss: 1.727279782295227
Validation loss: 1.9537012064328758

Epoch: 650| Step: 0
Training loss: 1.1781219244003296
Validation loss: 1.9404884307615218

Epoch: 5| Step: 1
Training loss: 1.11153244972229
Validation loss: 1.9801050065666117

Epoch: 5| Step: 2
Training loss: 0.9782074093818665
Validation loss: 1.9705557195089196

Epoch: 5| Step: 3
Training loss: 1.0232164859771729
Validation loss: 1.9673505752317366

Epoch: 5| Step: 4
Training loss: 1.2459886074066162
Validation loss: 1.9548150980344383

Epoch: 5| Step: 5
Training loss: 1.3285715579986572
Validation loss: 1.9859304428100586

Epoch: 5| Step: 6
Training loss: 1.724254846572876
Validation loss: 1.9983836630339264

Epoch: 5| Step: 7
Training loss: 0.9854097366333008
Validation loss: 1.9859338768066899

Epoch: 5| Step: 8
Training loss: 1.2492151260375977
Validation loss: 1.9912634254783712

Epoch: 5| Step: 9
Training loss: 1.5420591831207275
Validation loss: 1.985941073586864

Epoch: 5| Step: 10
Training loss: 1.4920293092727661
Validation loss: 1.9998705002569384

Epoch: 651| Step: 0
Training loss: 1.325655460357666
Validation loss: 1.9988628190050843

Epoch: 5| Step: 1
Training loss: 1.1787117719650269
Validation loss: 1.9980776002330165

Epoch: 5| Step: 2
Training loss: 0.7177169919013977
Validation loss: 1.9937983943570046

Epoch: 5| Step: 3
Training loss: 1.4315541982650757
Validation loss: 1.977729292326076

Epoch: 5| Step: 4
Training loss: 0.9391194581985474
Validation loss: 1.9560693540880758

Epoch: 5| Step: 5
Training loss: 1.2961499691009521
Validation loss: 1.9705578281033425

Epoch: 5| Step: 6
Training loss: 1.5335299968719482
Validation loss: 1.9501615121800413

Epoch: 5| Step: 7
Training loss: 0.8369637727737427
Validation loss: 1.9787012761639011

Epoch: 5| Step: 8
Training loss: 1.2625929117202759
Validation loss: 1.9288833423327374

Epoch: 5| Step: 9
Training loss: 1.640014410018921
Validation loss: 1.9926793716287101

Epoch: 5| Step: 10
Training loss: 1.4787304401397705
Validation loss: 1.9387372603980444

Epoch: 652| Step: 0
Training loss: 0.9736750721931458
Validation loss: 1.9255849687002038

Epoch: 5| Step: 1
Training loss: 1.107558012008667
Validation loss: 2.002679750483523

Epoch: 5| Step: 2
Training loss: 1.3476073741912842
Validation loss: 1.9306063293128886

Epoch: 5| Step: 3
Training loss: 1.2621132135391235
Validation loss: 1.9632998563910042

Epoch: 5| Step: 4
Training loss: 1.320646047592163
Validation loss: 1.957088985750752

Epoch: 5| Step: 5
Training loss: 1.8239635229110718
Validation loss: 1.9264550362863848

Epoch: 5| Step: 6
Training loss: 0.8277343511581421
Validation loss: 1.941517012093657

Epoch: 5| Step: 7
Training loss: 1.2648890018463135
Validation loss: 1.9599675747656053

Epoch: 5| Step: 8
Training loss: 1.1339850425720215
Validation loss: 1.9998953066846377

Epoch: 5| Step: 9
Training loss: 1.2999982833862305
Validation loss: 1.9639311887884652

Epoch: 5| Step: 10
Training loss: 0.894097626209259
Validation loss: 1.9204919722772413

Epoch: 653| Step: 0
Training loss: 1.6668784618377686
Validation loss: 1.9995482878018451

Epoch: 5| Step: 1
Training loss: 1.0758540630340576
Validation loss: 1.9665179919171076

Epoch: 5| Step: 2
Training loss: 1.1995433568954468
Validation loss: 1.9860150660237958

Epoch: 5| Step: 3
Training loss: 1.2756767272949219
Validation loss: 1.946250266926263

Epoch: 5| Step: 4
Training loss: 1.2363934516906738
Validation loss: 1.9745293227575158

Epoch: 5| Step: 5
Training loss: 0.619357705116272
Validation loss: 2.003299984880673

Epoch: 5| Step: 6
Training loss: 0.7195695638656616
Validation loss: 1.9782842346417007

Epoch: 5| Step: 7
Training loss: 1.275112509727478
Validation loss: 1.9635174684627081

Epoch: 5| Step: 8
Training loss: 0.8020938634872437
Validation loss: 1.966550245079943

Epoch: 5| Step: 9
Training loss: 1.621778130531311
Validation loss: 1.9802084263934885

Epoch: 5| Step: 10
Training loss: 1.8565198183059692
Validation loss: 1.9640268254023727

Epoch: 654| Step: 0
Training loss: 1.4187883138656616
Validation loss: 1.9985340282481203

Epoch: 5| Step: 1
Training loss: 1.4292923212051392
Validation loss: 1.9606977585823304

Epoch: 5| Step: 2
Training loss: 1.3313905000686646
Validation loss: 1.9670599660565775

Epoch: 5| Step: 3
Training loss: 1.1606158018112183
Validation loss: 1.9866279658450876

Epoch: 5| Step: 4
Training loss: 1.4901639223098755
Validation loss: 1.9444226154717066

Epoch: 5| Step: 5
Training loss: 1.049655556678772
Validation loss: 1.9656756565135012

Epoch: 5| Step: 6
Training loss: 1.2014389038085938
Validation loss: 1.9414464017396331

Epoch: 5| Step: 7
Training loss: 1.3073753118515015
Validation loss: 1.9776313074173466

Epoch: 5| Step: 8
Training loss: 0.948370635509491
Validation loss: 1.9401971076124458

Epoch: 5| Step: 9
Training loss: 1.2794512510299683
Validation loss: 1.9663351928034136

Epoch: 5| Step: 10
Training loss: 0.6536722779273987
Validation loss: 1.9535514526469733

Epoch: 655| Step: 0
Training loss: 1.3799638748168945
Validation loss: 1.920720443930677

Epoch: 5| Step: 1
Training loss: 2.006242036819458
Validation loss: 2.0012707197537987

Epoch: 5| Step: 2
Training loss: 1.039594054222107
Validation loss: 1.9416795264008224

Epoch: 5| Step: 3
Training loss: 1.1813400983810425
Validation loss: 1.967335957352833

Epoch: 5| Step: 4
Training loss: 0.8832677006721497
Validation loss: 1.9696403318835842

Epoch: 5| Step: 5
Training loss: 1.4661803245544434
Validation loss: 1.9936992891373173

Epoch: 5| Step: 6
Training loss: 1.1420180797576904
Validation loss: 1.9532243013381958

Epoch: 5| Step: 7
Training loss: 1.1616427898406982
Validation loss: 1.9686661830512426

Epoch: 5| Step: 8
Training loss: 1.1095478534698486
Validation loss: 1.9570276993577198

Epoch: 5| Step: 9
Training loss: 0.9476582407951355
Validation loss: 1.976164920355684

Epoch: 5| Step: 10
Training loss: 0.9538743495941162
Validation loss: 1.9809557622478855

Epoch: 656| Step: 0
Training loss: 1.7720448970794678
Validation loss: 1.9958090500165058

Epoch: 5| Step: 1
Training loss: 0.7379058003425598
Validation loss: 1.9513555752333773

Epoch: 5| Step: 2
Training loss: 1.1470192670822144
Validation loss: 1.9351976417726087

Epoch: 5| Step: 3
Training loss: 1.8201431035995483
Validation loss: 2.0112122335741596

Epoch: 5| Step: 4
Training loss: 1.193577527999878
Validation loss: 1.973469316318471

Epoch: 5| Step: 5
Training loss: 1.4049110412597656
Validation loss: 1.9841218661236506

Epoch: 5| Step: 6
Training loss: 0.9614980816841125
Validation loss: 1.9618120449845509

Epoch: 5| Step: 7
Training loss: 1.337493658065796
Validation loss: 1.9324260091268888

Epoch: 5| Step: 8
Training loss: 1.0923107862472534
Validation loss: 2.012641050482309

Epoch: 5| Step: 9
Training loss: 1.107521653175354
Validation loss: 1.9623456001281738

Epoch: 5| Step: 10
Training loss: 0.8456891179084778
Validation loss: 1.9714607115714782

Epoch: 657| Step: 0
Training loss: 1.133252501487732
Validation loss: 1.9916047639744257

Epoch: 5| Step: 1
Training loss: 1.4119912385940552
Validation loss: 1.998350602324291

Epoch: 5| Step: 2
Training loss: 1.4026310443878174
Validation loss: 1.9707441214592225

Epoch: 5| Step: 3
Training loss: 1.0368432998657227
Validation loss: 1.9939807666245328

Epoch: 5| Step: 4
Training loss: 1.2492367029190063
Validation loss: 2.001739917262908

Epoch: 5| Step: 5
Training loss: 0.8503558039665222
Validation loss: 1.9822081570984216

Epoch: 5| Step: 6
Training loss: 1.411118745803833
Validation loss: 1.986968114811887

Epoch: 5| Step: 7
Training loss: 1.3321857452392578
Validation loss: 1.9758818764840402

Epoch: 5| Step: 8
Training loss: 1.3556426763534546
Validation loss: 1.9767471718531784

Epoch: 5| Step: 9
Training loss: 0.8401045799255371
Validation loss: 1.9941393970161356

Epoch: 5| Step: 10
Training loss: 1.5496078729629517
Validation loss: 1.9932587403123097

Epoch: 658| Step: 0
Training loss: 1.4403384923934937
Validation loss: 2.0151028607481267

Epoch: 5| Step: 1
Training loss: 1.1773383617401123
Validation loss: 1.991834669984797

Epoch: 5| Step: 2
Training loss: 1.114043951034546
Validation loss: 1.9971343548067155

Epoch: 5| Step: 3
Training loss: 0.9879856109619141
Validation loss: 1.955757551295783

Epoch: 5| Step: 4
Training loss: 1.4184105396270752
Validation loss: 1.9781196963402532

Epoch: 5| Step: 5
Training loss: 1.731081247329712
Validation loss: 1.9504879366966985

Epoch: 5| Step: 6
Training loss: 0.8663240671157837
Validation loss: 1.9659849084833616

Epoch: 5| Step: 7
Training loss: 1.20745849609375
Validation loss: 1.9784301762939782

Epoch: 5| Step: 8
Training loss: 0.8779458999633789
Validation loss: 2.0057938406544347

Epoch: 5| Step: 9
Training loss: 1.6488405466079712
Validation loss: 1.9729584827218005

Epoch: 5| Step: 10
Training loss: 1.0545172691345215
Validation loss: 1.981632617212111

Epoch: 659| Step: 0
Training loss: 1.536624550819397
Validation loss: 1.9459789235104796

Epoch: 5| Step: 1
Training loss: 1.0756033658981323
Validation loss: 1.966628319473677

Epoch: 5| Step: 2
Training loss: 1.4500892162322998
Validation loss: 1.9315068542316396

Epoch: 5| Step: 3
Training loss: 1.7463200092315674
Validation loss: 1.9651659688641947

Epoch: 5| Step: 4
Training loss: 0.6592499613761902
Validation loss: 1.996008808894824

Epoch: 5| Step: 5
Training loss: 1.168224811553955
Validation loss: 2.004498758623677

Epoch: 5| Step: 6
Training loss: 1.0060056447982788
Validation loss: 1.960014679098642

Epoch: 5| Step: 7
Training loss: 1.4397664070129395
Validation loss: 1.9862763010045534

Epoch: 5| Step: 8
Training loss: 0.9556872248649597
Validation loss: 2.0000851000508955

Epoch: 5| Step: 9
Training loss: 1.075238585472107
Validation loss: 2.0054221076350056

Epoch: 5| Step: 10
Training loss: 1.3700529336929321
Validation loss: 1.9657345651298441

Epoch: 660| Step: 0
Training loss: 0.8992805480957031
Validation loss: 1.9946969914179977

Epoch: 5| Step: 1
Training loss: 1.2703182697296143
Validation loss: 1.978546557887908

Epoch: 5| Step: 2
Training loss: 1.2652347087860107
Validation loss: 1.9608700839422082

Epoch: 5| Step: 3
Training loss: 1.406680941581726
Validation loss: 1.966400646394299

Epoch: 5| Step: 4
Training loss: 1.7918672561645508
Validation loss: 1.9499560799649966

Epoch: 5| Step: 5
Training loss: 0.9173510670661926
Validation loss: 1.9422599692498483

Epoch: 5| Step: 6
Training loss: 1.4589511156082153
Validation loss: 1.9773204083083777

Epoch: 5| Step: 7
Training loss: 1.3993151187896729
Validation loss: 1.9493044781428512

Epoch: 5| Step: 8
Training loss: 0.8408412933349609
Validation loss: 1.9729387234616023

Epoch: 5| Step: 9
Training loss: 0.7801434397697449
Validation loss: 1.957016223220415

Epoch: 5| Step: 10
Training loss: 1.3537606000900269
Validation loss: 1.9909912540066628

Epoch: 661| Step: 0
Training loss: 1.3265600204467773
Validation loss: 1.9923677918731526

Epoch: 5| Step: 1
Training loss: 1.359499454498291
Validation loss: 1.9433687656156478

Epoch: 5| Step: 2
Training loss: 1.2608978748321533
Validation loss: 1.9613238547437934

Epoch: 5| Step: 3
Training loss: 1.3593623638153076
Validation loss: 1.9810692494915378

Epoch: 5| Step: 4
Training loss: 1.214840054512024
Validation loss: 1.9813288386150072

Epoch: 5| Step: 5
Training loss: 1.5458885431289673
Validation loss: 1.9854656111809514

Epoch: 5| Step: 6
Training loss: 1.374418020248413
Validation loss: 1.9203852171538978

Epoch: 5| Step: 7
Training loss: 0.8983739018440247
Validation loss: 1.9845995198013962

Epoch: 5| Step: 8
Training loss: 0.8911566734313965
Validation loss: 1.947441372820126

Epoch: 5| Step: 9
Training loss: 1.135000467300415
Validation loss: 1.9741171380524993

Epoch: 5| Step: 10
Training loss: 1.2062257528305054
Validation loss: 1.9772044125423636

Epoch: 662| Step: 0
Training loss: 1.1152530908584595
Validation loss: 1.9688917347179946

Epoch: 5| Step: 1
Training loss: 1.2614328861236572
Validation loss: 1.9329797644768991

Epoch: 5| Step: 2
Training loss: 0.7996467351913452
Validation loss: 2.0321434543978785

Epoch: 5| Step: 3
Training loss: 0.9005775451660156
Validation loss: 1.9504588803937357

Epoch: 5| Step: 4
Training loss: 1.66815984249115
Validation loss: 1.9640410356624152

Epoch: 5| Step: 5
Training loss: 1.5122315883636475
Validation loss: 1.985227002892443

Epoch: 5| Step: 6
Training loss: 1.3871160745620728
Validation loss: 1.9379628486530756

Epoch: 5| Step: 7
Training loss: 1.498591661453247
Validation loss: 1.9737036535816808

Epoch: 5| Step: 8
Training loss: 0.8009454607963562
Validation loss: 1.9343677284897014

Epoch: 5| Step: 9
Training loss: 1.348676323890686
Validation loss: 1.9795893776801325

Epoch: 5| Step: 10
Training loss: 1.3075469732284546
Validation loss: 1.9387056430180867

Epoch: 663| Step: 0
Training loss: 1.418389081954956
Validation loss: 1.9305372750887306

Epoch: 5| Step: 1
Training loss: 1.2507249116897583
Validation loss: 1.9764659763664327

Epoch: 5| Step: 2
Training loss: 1.2377402782440186
Validation loss: 1.9665644245762979

Epoch: 5| Step: 3
Training loss: 0.9998064041137695
Validation loss: 1.9942883624825427

Epoch: 5| Step: 4
Training loss: 0.9988687634468079
Validation loss: 1.9705886148637342

Epoch: 5| Step: 5
Training loss: 1.276426076889038
Validation loss: 2.0055629181605514

Epoch: 5| Step: 6
Training loss: 1.019460678100586
Validation loss: 1.9829677125459075

Epoch: 5| Step: 7
Training loss: 1.5275638103485107
Validation loss: 2.012851477951132

Epoch: 5| Step: 8
Training loss: 1.7256505489349365
Validation loss: 1.9496111151992634

Epoch: 5| Step: 9
Training loss: 0.9505279660224915
Validation loss: 1.9920895176549112

Epoch: 5| Step: 10
Training loss: 1.0361276865005493
Validation loss: 1.9913709214938584

Epoch: 664| Step: 0
Training loss: 1.1822960376739502
Validation loss: 2.004606162348101

Epoch: 5| Step: 1
Training loss: 1.3072946071624756
Validation loss: 1.9965203500563098

Epoch: 5| Step: 2
Training loss: 1.6306768655776978
Validation loss: 1.9826368567764119

Epoch: 5| Step: 3
Training loss: 1.072633981704712
Validation loss: 1.967206351218685

Epoch: 5| Step: 4
Training loss: 1.15072500705719
Validation loss: 1.9574615263169812

Epoch: 5| Step: 5
Training loss: 0.9129454493522644
Validation loss: 1.9592928360867243

Epoch: 5| Step: 6
Training loss: 0.7471200227737427
Validation loss: 1.9981823275166173

Epoch: 5| Step: 7
Training loss: 1.658825159072876
Validation loss: 1.9576441818667996

Epoch: 5| Step: 8
Training loss: 0.9895884394645691
Validation loss: 1.9655560960051834

Epoch: 5| Step: 9
Training loss: 1.1382510662078857
Validation loss: 1.9845848891042894

Epoch: 5| Step: 10
Training loss: 1.6607481241226196
Validation loss: 1.964026779256841

Epoch: 665| Step: 0
Training loss: 1.440675973892212
Validation loss: 1.9582596696833128

Epoch: 5| Step: 1
Training loss: 1.4927833080291748
Validation loss: 1.9433985653743948

Epoch: 5| Step: 2
Training loss: 1.2532457113265991
Validation loss: 1.9468125399722849

Epoch: 5| Step: 3
Training loss: 1.9458754062652588
Validation loss: 1.961623466143044

Epoch: 5| Step: 4
Training loss: 1.3068647384643555
Validation loss: 1.9660415931414532

Epoch: 5| Step: 5
Training loss: 0.7075870037078857
Validation loss: 1.9624212172723585

Epoch: 5| Step: 6
Training loss: 0.7315224409103394
Validation loss: 2.0147607659780853

Epoch: 5| Step: 7
Training loss: 0.6942245364189148
Validation loss: 1.976121553810694

Epoch: 5| Step: 8
Training loss: 1.3668591976165771
Validation loss: 2.015129432883314

Epoch: 5| Step: 9
Training loss: 0.7997700572013855
Validation loss: 1.9707773257327337

Epoch: 5| Step: 10
Training loss: 1.3958048820495605
Validation loss: 1.9699344071008826

Epoch: 666| Step: 0
Training loss: 1.4023535251617432
Validation loss: 1.9736434669904812

Epoch: 5| Step: 1
Training loss: 1.076340913772583
Validation loss: 1.9508474180775304

Epoch: 5| Step: 2
Training loss: 0.9837740063667297
Validation loss: 1.945706203419675

Epoch: 5| Step: 3
Training loss: 1.1772816181182861
Validation loss: 1.9325120936157882

Epoch: 5| Step: 4
Training loss: 1.3316736221313477
Validation loss: 1.9726760259238623

Epoch: 5| Step: 5
Training loss: 1.5282409191131592
Validation loss: 1.9459234360725648

Epoch: 5| Step: 6
Training loss: 1.322952389717102
Validation loss: 1.9467583138455626

Epoch: 5| Step: 7
Training loss: 1.3850759267807007
Validation loss: 1.9439078428411996

Epoch: 5| Step: 8
Training loss: 1.2435537576675415
Validation loss: 1.9811609432261477

Epoch: 5| Step: 9
Training loss: 1.092535376548767
Validation loss: 1.9376130552702053

Epoch: 5| Step: 10
Training loss: 0.7398509979248047
Validation loss: 1.9634470888363418

Epoch: 667| Step: 0
Training loss: 1.2462856769561768
Validation loss: 1.936028467711582

Epoch: 5| Step: 1
Training loss: 1.1002357006072998
Validation loss: 1.9617063460811492

Epoch: 5| Step: 2
Training loss: 1.0043001174926758
Validation loss: 1.970096093352123

Epoch: 5| Step: 3
Training loss: 1.3975824117660522
Validation loss: 1.926560499334848

Epoch: 5| Step: 4
Training loss: 1.1406631469726562
Validation loss: 1.9351623827411282

Epoch: 5| Step: 5
Training loss: 1.1127392053604126
Validation loss: 1.9744228111800326

Epoch: 5| Step: 6
Training loss: 1.3256231546401978
Validation loss: 1.9509187334327287

Epoch: 5| Step: 7
Training loss: 0.8255326151847839
Validation loss: 1.923178998372888

Epoch: 5| Step: 8
Training loss: 1.6066251993179321
Validation loss: 1.955355849317325

Epoch: 5| Step: 9
Training loss: 1.1737966537475586
Validation loss: 1.9734980598572762

Epoch: 5| Step: 10
Training loss: 1.3968724012374878
Validation loss: 1.94768363301472

Epoch: 668| Step: 0
Training loss: 0.7390354871749878
Validation loss: 1.9747885580985778

Epoch: 5| Step: 1
Training loss: 1.572558879852295
Validation loss: 1.9728661224406252

Epoch: 5| Step: 2
Training loss: 1.195605993270874
Validation loss: 1.9774416108285227

Epoch: 5| Step: 3
Training loss: 1.4618110656738281
Validation loss: 1.9885750585986721

Epoch: 5| Step: 4
Training loss: 0.8561342358589172
Validation loss: 1.983540000454072

Epoch: 5| Step: 5
Training loss: 1.127496361732483
Validation loss: 1.9580692322023454

Epoch: 5| Step: 6
Training loss: 0.9394543766975403
Validation loss: 1.9931142996716242

Epoch: 5| Step: 7
Training loss: 1.4549672603607178
Validation loss: 1.9855171301031624

Epoch: 5| Step: 8
Training loss: 1.4296119213104248
Validation loss: 1.966922208827029

Epoch: 5| Step: 9
Training loss: 1.009613275527954
Validation loss: 1.951973133189704

Epoch: 5| Step: 10
Training loss: 1.3440241813659668
Validation loss: 1.9670784050418484

Epoch: 669| Step: 0
Training loss: 0.5967532992362976
Validation loss: 1.978787850308162

Epoch: 5| Step: 1
Training loss: 1.9689490795135498
Validation loss: 1.9484044274976176

Epoch: 5| Step: 2
Training loss: 0.7561570405960083
Validation loss: 1.9649598752298663

Epoch: 5| Step: 3
Training loss: 1.2268264293670654
Validation loss: 1.9999181096271803

Epoch: 5| Step: 4
Training loss: 1.0856425762176514
Validation loss: 1.9695214584309568

Epoch: 5| Step: 5
Training loss: 1.2176144123077393
Validation loss: 1.9972406202746975

Epoch: 5| Step: 6
Training loss: 1.373218297958374
Validation loss: 1.9594138514611028

Epoch: 5| Step: 7
Training loss: 1.0501405000686646
Validation loss: 1.9854743583227998

Epoch: 5| Step: 8
Training loss: 1.5082318782806396
Validation loss: 2.0233850838035665

Epoch: 5| Step: 9
Training loss: 1.2427237033843994
Validation loss: 2.0450636571453464

Epoch: 5| Step: 10
Training loss: 1.2653491497039795
Validation loss: 2.032566144902219

Epoch: 670| Step: 0
Training loss: 0.8546074032783508
Validation loss: 2.049693625460389

Epoch: 5| Step: 1
Training loss: 0.802020251750946
Validation loss: 1.9749841997700353

Epoch: 5| Step: 2
Training loss: 1.6257743835449219
Validation loss: 1.9930242492306618

Epoch: 5| Step: 3
Training loss: 1.4806208610534668
Validation loss: 1.94054550509299

Epoch: 5| Step: 4
Training loss: 0.824703574180603
Validation loss: 1.9889373138386717

Epoch: 5| Step: 5
Training loss: 1.211116075515747
Validation loss: 1.9362188769925026

Epoch: 5| Step: 6
Training loss: 1.5068279504776
Validation loss: 1.9919994595230266

Epoch: 5| Step: 7
Training loss: 1.6576114892959595
Validation loss: 1.9132021434845463

Epoch: 5| Step: 8
Training loss: 1.6930148601531982
Validation loss: 1.9958556031668058

Epoch: 5| Step: 9
Training loss: 0.7125728726387024
Validation loss: 2.0045457206746584

Epoch: 5| Step: 10
Training loss: 1.0271368026733398
Validation loss: 1.9373517036437988

Epoch: 671| Step: 0
Training loss: 0.8711032867431641
Validation loss: 1.9432133308020971

Epoch: 5| Step: 1
Training loss: 1.6201655864715576
Validation loss: 1.9948156854157806

Epoch: 5| Step: 2
Training loss: 1.004077434539795
Validation loss: 1.967039074949039

Epoch: 5| Step: 3
Training loss: 0.8463853597640991
Validation loss: 1.9791897727597145

Epoch: 5| Step: 4
Training loss: 1.650308609008789
Validation loss: 1.9963412297669278

Epoch: 5| Step: 5
Training loss: 1.0773873329162598
Validation loss: 2.0245444184990338

Epoch: 5| Step: 6
Training loss: 1.3099313974380493
Validation loss: 2.007540892529231

Epoch: 5| Step: 7
Training loss: 1.4986571073532104
Validation loss: 1.982303656557555

Epoch: 5| Step: 8
Training loss: 1.3994556665420532
Validation loss: 1.9725985193765292

Epoch: 5| Step: 9
Training loss: 1.0751029253005981
Validation loss: 1.970753546684019

Epoch: 5| Step: 10
Training loss: 1.0546412467956543
Validation loss: 1.9768379119134718

Epoch: 672| Step: 0
Training loss: 0.7957068681716919
Validation loss: 1.9600442276206067

Epoch: 5| Step: 1
Training loss: 1.3227593898773193
Validation loss: 1.9461094153824674

Epoch: 5| Step: 2
Training loss: 0.9413545727729797
Validation loss: 1.9863506594011862

Epoch: 5| Step: 3
Training loss: 1.393108606338501
Validation loss: 1.9602100028786609

Epoch: 5| Step: 4
Training loss: 1.5830957889556885
Validation loss: 1.9747369930308352

Epoch: 5| Step: 5
Training loss: 1.0433417558670044
Validation loss: 1.997223413118752

Epoch: 5| Step: 6
Training loss: 1.1664999723434448
Validation loss: 1.941103704514042

Epoch: 5| Step: 7
Training loss: 1.491093397140503
Validation loss: 1.9348737283419537

Epoch: 5| Step: 8
Training loss: 1.1756401062011719
Validation loss: 1.9199502365563506

Epoch: 5| Step: 9
Training loss: 1.0414199829101562
Validation loss: 1.9966060025717622

Epoch: 5| Step: 10
Training loss: 1.7845878601074219
Validation loss: 1.9822817156391759

Epoch: 673| Step: 0
Training loss: 1.1372559070587158
Validation loss: 1.9973559648759904

Epoch: 5| Step: 1
Training loss: 1.4068920612335205
Validation loss: 1.96111814437374

Epoch: 5| Step: 2
Training loss: 0.9591872096061707
Validation loss: 1.9920659667702132

Epoch: 5| Step: 3
Training loss: 1.055364966392517
Validation loss: 1.99500778413588

Epoch: 5| Step: 4
Training loss: 1.6087684631347656
Validation loss: 1.9912364034242527

Epoch: 5| Step: 5
Training loss: 1.418955683708191
Validation loss: 1.9904263686108332

Epoch: 5| Step: 6
Training loss: 1.3303605318069458
Validation loss: 1.9909290639303063

Epoch: 5| Step: 7
Training loss: 1.2407087087631226
Validation loss: 1.9995468419085267

Epoch: 5| Step: 8
Training loss: 0.8533385992050171
Validation loss: 1.9764352998425883

Epoch: 5| Step: 9
Training loss: 0.9980024099349976
Validation loss: 1.977436565583752

Epoch: 5| Step: 10
Training loss: 0.9543108344078064
Validation loss: 1.9923857322303198

Epoch: 674| Step: 0
Training loss: 1.5673631429672241
Validation loss: 1.9600605682660175

Epoch: 5| Step: 1
Training loss: 0.6809406280517578
Validation loss: 1.9619182745615642

Epoch: 5| Step: 2
Training loss: 0.45653051137924194
Validation loss: 1.9640577813630462

Epoch: 5| Step: 3
Training loss: 1.0645496845245361
Validation loss: 1.9586007146425144

Epoch: 5| Step: 4
Training loss: 1.4450469017028809
Validation loss: 1.9571936591978996

Epoch: 5| Step: 5
Training loss: 1.3361797332763672
Validation loss: 1.9464594843567058

Epoch: 5| Step: 6
Training loss: 1.2566932439804077
Validation loss: 1.9704843926173385

Epoch: 5| Step: 7
Training loss: 1.7067453861236572
Validation loss: 1.9482252815718293

Epoch: 5| Step: 8
Training loss: 1.1631739139556885
Validation loss: 1.9780021175261466

Epoch: 5| Step: 9
Training loss: 1.112286925315857
Validation loss: 1.9285431638840707

Epoch: 5| Step: 10
Training loss: 1.4784550666809082
Validation loss: 1.9608779299643733

Epoch: 675| Step: 0
Training loss: 1.1657326221466064
Validation loss: 1.9332882101817797

Epoch: 5| Step: 1
Training loss: 1.00261390209198
Validation loss: 1.9792649515213505

Epoch: 5| Step: 2
Training loss: 1.2924423217773438
Validation loss: 2.0076418538247385

Epoch: 5| Step: 3
Training loss: 1.0724244117736816
Validation loss: 2.0068992645509782

Epoch: 5| Step: 4
Training loss: 1.4391237497329712
Validation loss: 1.9781289485193068

Epoch: 5| Step: 5
Training loss: 1.4010320901870728
Validation loss: 1.994256369529232

Epoch: 5| Step: 6
Training loss: 1.0839742422103882
Validation loss: 1.9624072274854105

Epoch: 5| Step: 7
Training loss: 0.6166523098945618
Validation loss: 1.9917524912024056

Epoch: 5| Step: 8
Training loss: 1.7059943675994873
Validation loss: 1.945007134509343

Epoch: 5| Step: 9
Training loss: 1.0363011360168457
Validation loss: 1.9473274856485345

Epoch: 5| Step: 10
Training loss: 1.0271577835083008
Validation loss: 1.9485215922837615

Epoch: 676| Step: 0
Training loss: 1.389004111289978
Validation loss: 1.9753710428873699

Epoch: 5| Step: 1
Training loss: 0.9073519706726074
Validation loss: 1.9258229360785535

Epoch: 5| Step: 2
Training loss: 1.3203210830688477
Validation loss: 1.9702748393499723

Epoch: 5| Step: 3
Training loss: 1.32883882522583
Validation loss: 1.9796687403032858

Epoch: 5| Step: 4
Training loss: 1.7205007076263428
Validation loss: 2.0024162748808503

Epoch: 5| Step: 5
Training loss: 1.6258785724639893
Validation loss: 1.9749231774319884

Epoch: 5| Step: 6
Training loss: 1.1408616304397583
Validation loss: 1.9335240599929646

Epoch: 5| Step: 7
Training loss: 0.8196819424629211
Validation loss: 1.9372870793906591

Epoch: 5| Step: 8
Training loss: 1.5323576927185059
Validation loss: 1.9373342683238368

Epoch: 5| Step: 9
Training loss: 0.9125164151191711
Validation loss: 1.973402116888313

Epoch: 5| Step: 10
Training loss: 0.8032695651054382
Validation loss: 1.9680151708664433

Epoch: 677| Step: 0
Training loss: 1.6421159505844116
Validation loss: 1.988502251204624

Epoch: 5| Step: 1
Training loss: 1.155541181564331
Validation loss: 1.930829858267179

Epoch: 5| Step: 2
Training loss: 1.091681718826294
Validation loss: 1.982200772531571

Epoch: 5| Step: 3
Training loss: 1.2514718770980835
Validation loss: 2.0277745646815144

Epoch: 5| Step: 4
Training loss: 1.005081057548523
Validation loss: 1.999653805968582

Epoch: 5| Step: 5
Training loss: 1.0393109321594238
Validation loss: 1.9458092284458939

Epoch: 5| Step: 6
Training loss: 1.1038997173309326
Validation loss: 1.9448402927767845

Epoch: 5| Step: 7
Training loss: 1.244816780090332
Validation loss: 1.9312778544682327

Epoch: 5| Step: 8
Training loss: 1.169533133506775
Validation loss: 1.9654702871076521

Epoch: 5| Step: 9
Training loss: 1.0062700510025024
Validation loss: 1.9731797338813863

Epoch: 5| Step: 10
Training loss: 1.405097246170044
Validation loss: 1.9880718646510955

Epoch: 678| Step: 0
Training loss: 0.7668361067771912
Validation loss: 1.9746119668406825

Epoch: 5| Step: 1
Training loss: 1.0677194595336914
Validation loss: 1.9721461111499416

Epoch: 5| Step: 2
Training loss: 1.584620714187622
Validation loss: 1.9885939590392574

Epoch: 5| Step: 3
Training loss: 0.9745022058486938
Validation loss: 1.9868636426105295

Epoch: 5| Step: 4
Training loss: 1.3598980903625488
Validation loss: 1.9777263364484232

Epoch: 5| Step: 5
Training loss: 1.3098118305206299
Validation loss: 1.9831440589761222

Epoch: 5| Step: 6
Training loss: 1.3900450468063354
Validation loss: 1.9853052400773572

Epoch: 5| Step: 7
Training loss: 0.8959482312202454
Validation loss: 1.9850037379931378

Epoch: 5| Step: 8
Training loss: 1.4914844036102295
Validation loss: 1.9583305107649935

Epoch: 5| Step: 9
Training loss: 1.1872904300689697
Validation loss: 1.9849914094453216

Epoch: 5| Step: 10
Training loss: 1.2859947681427002
Validation loss: 1.9937391550310197

Epoch: 679| Step: 0
Training loss: 0.780585765838623
Validation loss: 1.9712878837380359

Epoch: 5| Step: 1
Training loss: 1.394660234451294
Validation loss: 1.928654041341556

Epoch: 5| Step: 2
Training loss: 1.3357810974121094
Validation loss: 1.9077650962337371

Epoch: 5| Step: 3
Training loss: 1.3564223051071167
Validation loss: 1.9783707062403362

Epoch: 5| Step: 4
Training loss: 1.2822039127349854
Validation loss: 1.9645188277767551

Epoch: 5| Step: 5
Training loss: 1.5394254922866821
Validation loss: 1.9458079466255762

Epoch: 5| Step: 6
Training loss: 1.3199243545532227
Validation loss: 1.9307820771330146

Epoch: 5| Step: 7
Training loss: 1.1800243854522705
Validation loss: 1.9638663978986843

Epoch: 5| Step: 8
Training loss: 1.024432897567749
Validation loss: 1.9647649590687086

Epoch: 5| Step: 9
Training loss: 1.2879575490951538
Validation loss: 1.9980030713542816

Epoch: 5| Step: 10
Training loss: 0.5438607335090637
Validation loss: 1.977448571112848

Epoch: 680| Step: 0
Training loss: 1.2113966941833496
Validation loss: 1.9744682337648125

Epoch: 5| Step: 1
Training loss: 0.7001457810401917
Validation loss: 1.950035818161503

Epoch: 5| Step: 2
Training loss: 1.1657871007919312
Validation loss: 1.9602662491542038

Epoch: 5| Step: 3
Training loss: 1.218639612197876
Validation loss: 1.9536004925286898

Epoch: 5| Step: 4
Training loss: 1.442914605140686
Validation loss: 1.9648692377151982

Epoch: 5| Step: 5
Training loss: 1.0796961784362793
Validation loss: 1.9709028864419589

Epoch: 5| Step: 6
Training loss: 1.2284400463104248
Validation loss: 1.979413301714005

Epoch: 5| Step: 7
Training loss: 1.0743664503097534
Validation loss: 1.9434359355639386

Epoch: 5| Step: 8
Training loss: 1.1246354579925537
Validation loss: 1.9738067311625327

Epoch: 5| Step: 9
Training loss: 1.6397979259490967
Validation loss: 1.9784972847148936

Epoch: 5| Step: 10
Training loss: 1.157485008239746
Validation loss: 1.9382839869427424

Epoch: 681| Step: 0
Training loss: 1.1237380504608154
Validation loss: 1.977896503222886

Epoch: 5| Step: 1
Training loss: 0.8840233683586121
Validation loss: 1.937364193700975

Epoch: 5| Step: 2
Training loss: 1.1935769319534302
Validation loss: 2.0075708384154947

Epoch: 5| Step: 3
Training loss: 1.4458651542663574
Validation loss: 1.9516539535214823

Epoch: 5| Step: 4
Training loss: 1.5133931636810303
Validation loss: 1.9757910710509106

Epoch: 5| Step: 5
Training loss: 1.4512325525283813
Validation loss: 1.9665843389367546

Epoch: 5| Step: 6
Training loss: 0.7593199610710144
Validation loss: 1.958322771133915

Epoch: 5| Step: 7
Training loss: 1.1427416801452637
Validation loss: 1.9765267090130878

Epoch: 5| Step: 8
Training loss: 1.1404592990875244
Validation loss: 1.9612876497289187

Epoch: 5| Step: 9
Training loss: 1.1402442455291748
Validation loss: 1.9522659547867314

Epoch: 5| Step: 10
Training loss: 1.2682498693466187
Validation loss: 1.9325757795764553

Epoch: 682| Step: 0
Training loss: 1.3599741458892822
Validation loss: 1.9346261588476037

Epoch: 5| Step: 1
Training loss: 0.9894400835037231
Validation loss: 1.9786654492860198

Epoch: 5| Step: 2
Training loss: 0.8608859181404114
Validation loss: 1.9622189934535692

Epoch: 5| Step: 3
Training loss: 1.318453073501587
Validation loss: 1.9973678870867657

Epoch: 5| Step: 4
Training loss: 1.4496753215789795
Validation loss: 1.997022339092788

Epoch: 5| Step: 5
Training loss: 1.2014756202697754
Validation loss: 1.946502370219077

Epoch: 5| Step: 6
Training loss: 0.9133279919624329
Validation loss: 1.9717576529390068

Epoch: 5| Step: 7
Training loss: 1.3764019012451172
Validation loss: 1.9473703984291322

Epoch: 5| Step: 8
Training loss: 0.9945721626281738
Validation loss: 1.9847948704996417

Epoch: 5| Step: 9
Training loss: 1.0472283363342285
Validation loss: 1.9879680243871545

Epoch: 5| Step: 10
Training loss: 1.4226573705673218
Validation loss: 1.9366099808805732

Epoch: 683| Step: 0
Training loss: 1.4415409564971924
Validation loss: 1.9569277071183728

Epoch: 5| Step: 1
Training loss: 1.1666972637176514
Validation loss: 1.9754539035981702

Epoch: 5| Step: 2
Training loss: 0.6696814298629761
Validation loss: 1.9841933045335995

Epoch: 5| Step: 3
Training loss: 1.021600365638733
Validation loss: 1.946674946815737

Epoch: 5| Step: 4
Training loss: 1.203075647354126
Validation loss: 1.9348566288589149

Epoch: 5| Step: 5
Training loss: 0.924930214881897
Validation loss: 1.9842330819817

Epoch: 5| Step: 6
Training loss: 1.2489229440689087
Validation loss: 1.9447475018039826

Epoch: 5| Step: 7
Training loss: 1.1339538097381592
Validation loss: 1.9989527925368278

Epoch: 5| Step: 8
Training loss: 1.3446044921875
Validation loss: 1.9534871014215613

Epoch: 5| Step: 9
Training loss: 1.3763971328735352
Validation loss: 1.9624737078143704

Epoch: 5| Step: 10
Training loss: 1.460065245628357
Validation loss: 1.9872750005414408

Epoch: 684| Step: 0
Training loss: 1.2524582147598267
Validation loss: 1.9763466952949442

Epoch: 5| Step: 1
Training loss: 1.6548230648040771
Validation loss: 2.022488050563361

Epoch: 5| Step: 2
Training loss: 1.1045570373535156
Validation loss: 1.9737262751466484

Epoch: 5| Step: 3
Training loss: 0.8935867547988892
Validation loss: 1.981806005201032

Epoch: 5| Step: 4
Training loss: 1.0278756618499756
Validation loss: 1.99245205233174

Epoch: 5| Step: 5
Training loss: 1.2306498289108276
Validation loss: 1.9864064442214144

Epoch: 5| Step: 6
Training loss: 1.3475497961044312
Validation loss: 1.9810928683127127

Epoch: 5| Step: 7
Training loss: 1.066251516342163
Validation loss: 1.987651740351031

Epoch: 5| Step: 8
Training loss: 1.324986457824707
Validation loss: 2.0063188511838197

Epoch: 5| Step: 9
Training loss: 1.3917958736419678
Validation loss: 1.9691623590325797

Epoch: 5| Step: 10
Training loss: 0.9331712126731873
Validation loss: 1.9578047619071057

Epoch: 685| Step: 0
Training loss: 0.8576221466064453
Validation loss: 1.9696072583557458

Epoch: 5| Step: 1
Training loss: 1.1185896396636963
Validation loss: 1.954037748357301

Epoch: 5| Step: 2
Training loss: 1.0619781017303467
Validation loss: 1.961127399116434

Epoch: 5| Step: 3
Training loss: 1.1492059230804443
Validation loss: 1.9704703695030623

Epoch: 5| Step: 4
Training loss: 1.3908741474151611
Validation loss: 1.9602618345650293

Epoch: 5| Step: 5
Training loss: 1.6136785745620728
Validation loss: 1.9610736113722607

Epoch: 5| Step: 6
Training loss: 1.3793995380401611
Validation loss: 1.9877536514753937

Epoch: 5| Step: 7
Training loss: 1.2739969491958618
Validation loss: 1.9845540779893116

Epoch: 5| Step: 8
Training loss: 1.3915231227874756
Validation loss: 1.9684430655612741

Epoch: 5| Step: 9
Training loss: 1.0745289325714111
Validation loss: 1.9625047304297005

Epoch: 5| Step: 10
Training loss: 1.3980474472045898
Validation loss: 1.971278739231889

Epoch: 686| Step: 0
Training loss: 0.7855610847473145
Validation loss: 1.9545704831359207

Epoch: 5| Step: 1
Training loss: 1.5334765911102295
Validation loss: 1.9664195660621888

Epoch: 5| Step: 2
Training loss: 1.2142901420593262
Validation loss: 1.9509546192743445

Epoch: 5| Step: 3
Training loss: 0.9283462762832642
Validation loss: 1.954205132299854

Epoch: 5| Step: 4
Training loss: 1.1489630937576294
Validation loss: 2.01273972757401

Epoch: 5| Step: 5
Training loss: 1.331907868385315
Validation loss: 1.9951678053025277

Epoch: 5| Step: 6
Training loss: 1.1238086223602295
Validation loss: 1.9936872400263304

Epoch: 5| Step: 7
Training loss: 1.0160404443740845
Validation loss: 1.976779196851997

Epoch: 5| Step: 8
Training loss: 1.7271621227264404
Validation loss: 2.0325839980956046

Epoch: 5| Step: 9
Training loss: 1.0146938562393188
Validation loss: 1.981049189003565

Epoch: 5| Step: 10
Training loss: 1.321306586265564
Validation loss: 1.9759770836881412

Epoch: 687| Step: 0
Training loss: 1.508971929550171
Validation loss: 1.9634729085430023

Epoch: 5| Step: 1
Training loss: 1.34884512424469
Validation loss: 2.0011967420578003

Epoch: 5| Step: 2
Training loss: 0.8672882318496704
Validation loss: 1.9601617269618536

Epoch: 5| Step: 3
Training loss: 1.1744366884231567
Validation loss: 1.9623872823612665

Epoch: 5| Step: 4
Training loss: 0.9901303052902222
Validation loss: 1.9387086155594035

Epoch: 5| Step: 5
Training loss: 0.7955716848373413
Validation loss: 1.9162337280088855

Epoch: 5| Step: 6
Training loss: 1.1254006624221802
Validation loss: 1.9482567694879347

Epoch: 5| Step: 7
Training loss: 1.2662837505340576
Validation loss: 1.9608849235760268

Epoch: 5| Step: 8
Training loss: 1.1190882921218872
Validation loss: 1.9341635409221853

Epoch: 5| Step: 9
Training loss: 1.5356452465057373
Validation loss: 1.9486916911217473

Epoch: 5| Step: 10
Training loss: 1.408859372138977
Validation loss: 1.9420970870602516

Epoch: 688| Step: 0
Training loss: 1.0069032907485962
Validation loss: 1.9821655827183877

Epoch: 5| Step: 1
Training loss: 0.9854369163513184
Validation loss: 1.941868641043222

Epoch: 5| Step: 2
Training loss: 0.7749136090278625
Validation loss: 1.9494806438364007

Epoch: 5| Step: 3
Training loss: 1.2502763271331787
Validation loss: 2.021699861813617

Epoch: 5| Step: 4
Training loss: 0.9033676385879517
Validation loss: 1.969115149590277

Epoch: 5| Step: 5
Training loss: 1.3177344799041748
Validation loss: 1.9461537048380861

Epoch: 5| Step: 6
Training loss: 0.7657903432846069
Validation loss: 2.017603261496431

Epoch: 5| Step: 7
Training loss: 1.2303701639175415
Validation loss: 1.9623302503298687

Epoch: 5| Step: 8
Training loss: 1.769569993019104
Validation loss: 1.929445824315471

Epoch: 5| Step: 9
Training loss: 1.7725164890289307
Validation loss: 1.9746072997329056

Epoch: 5| Step: 10
Training loss: 1.1922451257705688
Validation loss: 2.0147648857485865

Epoch: 689| Step: 0
Training loss: 0.8427339792251587
Validation loss: 1.9663140376408894

Epoch: 5| Step: 1
Training loss: 0.8686426281929016
Validation loss: 1.9415420665535876

Epoch: 5| Step: 2
Training loss: 1.1104075908660889
Validation loss: 1.9836324107262395

Epoch: 5| Step: 3
Training loss: 0.9796980619430542
Validation loss: 1.9539725998396515

Epoch: 5| Step: 4
Training loss: 1.0076218843460083
Validation loss: 1.9800524045062322

Epoch: 5| Step: 5
Training loss: 1.4189611673355103
Validation loss: 1.9791861234172698

Epoch: 5| Step: 6
Training loss: 0.9812995791435242
Validation loss: 1.97462801266742

Epoch: 5| Step: 7
Training loss: 1.822283387184143
Validation loss: 1.9698224503506896

Epoch: 5| Step: 8
Training loss: 1.4486204385757446
Validation loss: 1.9417779445648193

Epoch: 5| Step: 9
Training loss: 1.242977261543274
Validation loss: 1.9522687081367738

Epoch: 5| Step: 10
Training loss: 1.014519214630127
Validation loss: 1.9653214587960193

Epoch: 690| Step: 0
Training loss: 1.0764440298080444
Validation loss: 1.9699060352899695

Epoch: 5| Step: 1
Training loss: 1.171982765197754
Validation loss: 2.0216256418535785

Epoch: 5| Step: 2
Training loss: 1.3253732919692993
Validation loss: 1.9598393427428378

Epoch: 5| Step: 3
Training loss: 0.8787531852722168
Validation loss: 1.9865276967325518

Epoch: 5| Step: 4
Training loss: 0.887096107006073
Validation loss: 1.9899721542994182

Epoch: 5| Step: 5
Training loss: 0.8442322015762329
Validation loss: 1.9469657405730216

Epoch: 5| Step: 6
Training loss: 1.8817058801651
Validation loss: 1.9571350389911282

Epoch: 5| Step: 7
Training loss: 1.3641607761383057
Validation loss: 2.0161027818597774

Epoch: 5| Step: 8
Training loss: 1.13181471824646
Validation loss: 1.9752853967810189

Epoch: 5| Step: 9
Training loss: 1.05936861038208
Validation loss: 1.9547685935933103

Epoch: 5| Step: 10
Training loss: 1.2617675065994263
Validation loss: 1.97497764325911

Epoch: 691| Step: 0
Training loss: 1.5567604303359985
Validation loss: 1.9606675999138945

Epoch: 5| Step: 1
Training loss: 1.073409080505371
Validation loss: 1.9474711751425138

Epoch: 5| Step: 2
Training loss: 0.9141877293586731
Validation loss: 1.9913020518518263

Epoch: 5| Step: 3
Training loss: 1.4342262744903564
Validation loss: 1.990432426493655

Epoch: 5| Step: 4
Training loss: 1.4608968496322632
Validation loss: 1.9585646916461248

Epoch: 5| Step: 5
Training loss: 0.8265761137008667
Validation loss: 1.9393916617157638

Epoch: 5| Step: 6
Training loss: 0.8315137028694153
Validation loss: 1.9485457225512433

Epoch: 5| Step: 7
Training loss: 1.355261206626892
Validation loss: 1.9479270763294672

Epoch: 5| Step: 8
Training loss: 1.208207368850708
Validation loss: 1.9285499152316843

Epoch: 5| Step: 9
Training loss: 1.1270091533660889
Validation loss: 1.962438839738087

Epoch: 5| Step: 10
Training loss: 1.0226963758468628
Validation loss: 1.9899031321207683

Epoch: 692| Step: 0
Training loss: 1.1793701648712158
Validation loss: 1.9677515927181448

Epoch: 5| Step: 1
Training loss: 1.6135313510894775
Validation loss: 1.9728023493161766

Epoch: 5| Step: 2
Training loss: 1.1425894498825073
Validation loss: 1.999601048807944

Epoch: 5| Step: 3
Training loss: 0.6140604019165039
Validation loss: 1.9570852236081195

Epoch: 5| Step: 4
Training loss: 1.3482630252838135
Validation loss: 1.960167973272262

Epoch: 5| Step: 5
Training loss: 1.0899537801742554
Validation loss: 1.978366458287803

Epoch: 5| Step: 6
Training loss: 1.4761768579483032
Validation loss: 1.9772649580432522

Epoch: 5| Step: 7
Training loss: 1.2591089010238647
Validation loss: 1.9681649592614943

Epoch: 5| Step: 8
Training loss: 1.2818893194198608
Validation loss: 2.007339899257947

Epoch: 5| Step: 9
Training loss: 1.1511964797973633
Validation loss: 1.9551171513013943

Epoch: 5| Step: 10
Training loss: 0.6756868958473206
Validation loss: 1.9976489338823544

Epoch: 693| Step: 0
Training loss: 1.491127610206604
Validation loss: 1.9662087168744815

Epoch: 5| Step: 1
Training loss: 1.1181538105010986
Validation loss: 1.9753357466831003

Epoch: 5| Step: 2
Training loss: 1.1280447244644165
Validation loss: 1.9756657769603114

Epoch: 5| Step: 3
Training loss: 0.8878680467605591
Validation loss: 1.9266740352876726

Epoch: 5| Step: 4
Training loss: 0.8324639201164246
Validation loss: 1.9685115762936172

Epoch: 5| Step: 5
Training loss: 1.6060428619384766
Validation loss: 1.9556294795005553

Epoch: 5| Step: 6
Training loss: 1.285724401473999
Validation loss: 1.97063018942392

Epoch: 5| Step: 7
Training loss: 1.5406873226165771
Validation loss: 1.9942511384205153

Epoch: 5| Step: 8
Training loss: 0.6852177977561951
Validation loss: 1.9645483878351027

Epoch: 5| Step: 9
Training loss: 0.9493049383163452
Validation loss: 1.9442814345000892

Epoch: 5| Step: 10
Training loss: 0.9993336796760559
Validation loss: 1.9718401585855792

Epoch: 694| Step: 0
Training loss: 0.796795666217804
Validation loss: 1.9455350419526458

Epoch: 5| Step: 1
Training loss: 1.3359087705612183
Validation loss: 1.9699863208237516

Epoch: 5| Step: 2
Training loss: 1.1524136066436768
Validation loss: 1.949868966174382

Epoch: 5| Step: 3
Training loss: 1.4279000759124756
Validation loss: 1.9451642138983614

Epoch: 5| Step: 4
Training loss: 1.3097388744354248
Validation loss: 1.9530748628800916

Epoch: 5| Step: 5
Training loss: 1.3283495903015137
Validation loss: 1.9817814724419707

Epoch: 5| Step: 6
Training loss: 1.0936979055404663
Validation loss: 1.983905166708013

Epoch: 5| Step: 7
Training loss: 1.0738531351089478
Validation loss: 1.9365254807215866

Epoch: 5| Step: 8
Training loss: 1.3444421291351318
Validation loss: 1.9981162266064716

Epoch: 5| Step: 9
Training loss: 1.2061731815338135
Validation loss: 1.9401615153076828

Epoch: 5| Step: 10
Training loss: 0.8244842290878296
Validation loss: 1.9783684758729831

Epoch: 695| Step: 0
Training loss: 1.0771617889404297
Validation loss: 1.9816533980831024

Epoch: 5| Step: 1
Training loss: 0.8048856854438782
Validation loss: 1.958411466690802

Epoch: 5| Step: 2
Training loss: 1.1716970205307007
Validation loss: 1.9877369660203175

Epoch: 5| Step: 3
Training loss: 1.308472752571106
Validation loss: 1.9694519632606096

Epoch: 5| Step: 4
Training loss: 1.3306281566619873
Validation loss: 1.9967427458814395

Epoch: 5| Step: 5
Training loss: 1.1963751316070557
Validation loss: 1.9726271103787165

Epoch: 5| Step: 6
Training loss: 1.672523856163025
Validation loss: 1.9867967867082166

Epoch: 5| Step: 7
Training loss: 1.135457992553711
Validation loss: 2.0107362629264913

Epoch: 5| Step: 8
Training loss: 0.9084007143974304
Validation loss: 1.9508583340593564

Epoch: 5| Step: 9
Training loss: 0.9223129153251648
Validation loss: 1.9780015112251363

Epoch: 5| Step: 10
Training loss: 1.1627382040023804
Validation loss: 1.9449630039994434

Epoch: 696| Step: 0
Training loss: 0.8847430944442749
Validation loss: 1.9273341548058294

Epoch: 5| Step: 1
Training loss: 1.2595351934432983
Validation loss: 1.9492033207288353

Epoch: 5| Step: 2
Training loss: 1.0415831804275513
Validation loss: 1.972388526444794

Epoch: 5| Step: 3
Training loss: 1.5383594036102295
Validation loss: 1.956972086301414

Epoch: 5| Step: 4
Training loss: 0.7999681234359741
Validation loss: 1.9527795750607726

Epoch: 5| Step: 5
Training loss: 1.0566222667694092
Validation loss: 1.9562052231962963

Epoch: 5| Step: 6
Training loss: 1.0561922788619995
Validation loss: 1.949579285037133

Epoch: 5| Step: 7
Training loss: 0.9782794117927551
Validation loss: 1.9674398527350476

Epoch: 5| Step: 8
Training loss: 1.2664597034454346
Validation loss: 1.9418314503085228

Epoch: 5| Step: 9
Training loss: 1.4507981538772583
Validation loss: 1.9855004459299066

Epoch: 5| Step: 10
Training loss: 1.5734227895736694
Validation loss: 1.9374309214212562

Epoch: 697| Step: 0
Training loss: 1.33977210521698
Validation loss: 1.9321300060518327

Epoch: 5| Step: 1
Training loss: 1.1946697235107422
Validation loss: 1.9856360971286733

Epoch: 5| Step: 2
Training loss: 1.3318426609039307
Validation loss: 1.972735716450599

Epoch: 5| Step: 3
Training loss: 1.2856488227844238
Validation loss: 1.9634019918339227

Epoch: 5| Step: 4
Training loss: 1.0094528198242188
Validation loss: 1.936172209760194

Epoch: 5| Step: 5
Training loss: 0.9071357846260071
Validation loss: 1.991477007506996

Epoch: 5| Step: 6
Training loss: 1.1458981037139893
Validation loss: 1.9538492618068573

Epoch: 5| Step: 7
Training loss: 1.1437629461288452
Validation loss: 1.9773213991554834

Epoch: 5| Step: 8
Training loss: 1.4376147985458374
Validation loss: 1.9340418731012652

Epoch: 5| Step: 9
Training loss: 0.9245985746383667
Validation loss: 1.9640683358715427

Epoch: 5| Step: 10
Training loss: 0.786596417427063
Validation loss: 1.9606881436481272

Epoch: 698| Step: 0
Training loss: 1.3588011264801025
Validation loss: 1.9740303588169876

Epoch: 5| Step: 1
Training loss: 1.2188382148742676
Validation loss: 2.0066874950162825

Epoch: 5| Step: 2
Training loss: 0.8886411786079407
Validation loss: 1.9863203161506242

Epoch: 5| Step: 3
Training loss: 1.4466044902801514
Validation loss: 1.9632012895358506

Epoch: 5| Step: 4
Training loss: 0.7848549485206604
Validation loss: 1.9539566322039532

Epoch: 5| Step: 5
Training loss: 1.0969822406768799
Validation loss: 1.9714141750848422

Epoch: 5| Step: 6
Training loss: 1.0180906057357788
Validation loss: 2.0029522757376395

Epoch: 5| Step: 7
Training loss: 1.314268708229065
Validation loss: 1.9807710762946837

Epoch: 5| Step: 8
Training loss: 1.4390560388565063
Validation loss: 1.965129675403718

Epoch: 5| Step: 9
Training loss: 1.2766391038894653
Validation loss: 1.969577597033593

Epoch: 5| Step: 10
Training loss: 1.0511265993118286
Validation loss: 1.9332694110049997

Epoch: 699| Step: 0
Training loss: 0.890655517578125
Validation loss: 1.9918478637613275

Epoch: 5| Step: 1
Training loss: 1.303614854812622
Validation loss: 1.9514025552298433

Epoch: 5| Step: 2
Training loss: 1.6049312353134155
Validation loss: 1.9337343182615054

Epoch: 5| Step: 3
Training loss: 1.5860553979873657
Validation loss: 1.9607917801026375

Epoch: 5| Step: 4
Training loss: 1.1912981271743774
Validation loss: 1.9425270506130752

Epoch: 5| Step: 5
Training loss: 0.6001707315444946
Validation loss: 1.9581786189028012

Epoch: 5| Step: 6
Training loss: 0.836865246295929
Validation loss: 1.9841050191592144

Epoch: 5| Step: 7
Training loss: 0.8713235855102539
Validation loss: 1.946144776959573

Epoch: 5| Step: 8
Training loss: 1.1895956993103027
Validation loss: 1.9853282102974512

Epoch: 5| Step: 9
Training loss: 1.4363218545913696
Validation loss: 1.9486787255092333

Epoch: 5| Step: 10
Training loss: 1.3215636014938354
Validation loss: 1.938791351933633

Epoch: 700| Step: 0
Training loss: 0.9864867329597473
Validation loss: 1.9719727628974504

Epoch: 5| Step: 1
Training loss: 1.4504408836364746
Validation loss: 1.9876882235209148

Epoch: 5| Step: 2
Training loss: 1.2286131381988525
Validation loss: 1.9408685494494695

Epoch: 5| Step: 3
Training loss: 1.2015831470489502
Validation loss: 1.978486930170367

Epoch: 5| Step: 4
Training loss: 0.9929305911064148
Validation loss: 1.9219587477304603

Epoch: 5| Step: 5
Training loss: 0.9836667776107788
Validation loss: 1.9312667872316094

Epoch: 5| Step: 6
Training loss: 1.077758550643921
Validation loss: 1.9726482847685456

Epoch: 5| Step: 7
Training loss: 1.1152458190917969
Validation loss: 1.964111602434548

Epoch: 5| Step: 8
Training loss: 1.3396798372268677
Validation loss: 1.9622355898221333

Epoch: 5| Step: 9
Training loss: 1.8458667993545532
Validation loss: 1.9859951273087533

Epoch: 5| Step: 10
Training loss: 0.5041430592536926
Validation loss: 1.935189224058582

Epoch: 701| Step: 0
Training loss: 1.436565637588501
Validation loss: 1.9088679462350824

Epoch: 5| Step: 1
Training loss: 1.5459749698638916
Validation loss: 2.0092696656462965

Epoch: 5| Step: 2
Training loss: 0.9390565156936646
Validation loss: 1.9738678701462284

Epoch: 5| Step: 3
Training loss: 0.9432264566421509
Validation loss: 1.97045950863951

Epoch: 5| Step: 4
Training loss: 0.8517431020736694
Validation loss: 1.9846563044414725

Epoch: 5| Step: 5
Training loss: 0.6932334303855896
Validation loss: 1.9697226747389762

Epoch: 5| Step: 6
Training loss: 1.3924789428710938
Validation loss: 1.985822308448053

Epoch: 5| Step: 7
Training loss: 1.689014196395874
Validation loss: 1.975780351187593

Epoch: 5| Step: 8
Training loss: 1.0322540998458862
Validation loss: 1.962612352063579

Epoch: 5| Step: 9
Training loss: 1.360650658607483
Validation loss: 1.9660562264022006

Epoch: 5| Step: 10
Training loss: 0.6606511473655701
Validation loss: 1.9419140610643613

Epoch: 702| Step: 0
Training loss: 0.6639195084571838
Validation loss: 1.9685903877340338

Epoch: 5| Step: 1
Training loss: 1.0909268856048584
Validation loss: 1.9838749016484907

Epoch: 5| Step: 2
Training loss: 1.416928768157959
Validation loss: 1.9687819814169278

Epoch: 5| Step: 3
Training loss: 1.3999369144439697
Validation loss: 1.9580381096050303

Epoch: 5| Step: 4
Training loss: 1.0119832754135132
Validation loss: 1.9619060459957327

Epoch: 5| Step: 5
Training loss: 0.7684354186058044
Validation loss: 1.9608166102440125

Epoch: 5| Step: 6
Training loss: 0.7591484785079956
Validation loss: 1.936839457481138

Epoch: 5| Step: 7
Training loss: 1.4565073251724243
Validation loss: 1.9722369870831888

Epoch: 5| Step: 8
Training loss: 1.5558220148086548
Validation loss: 1.9527404333955498

Epoch: 5| Step: 9
Training loss: 1.1295982599258423
Validation loss: 1.9416592044215049

Epoch: 5| Step: 10
Training loss: 1.1646162271499634
Validation loss: 1.9710497240866385

Epoch: 703| Step: 0
Training loss: 1.1974163055419922
Validation loss: 1.965448720480806

Epoch: 5| Step: 1
Training loss: 1.1775398254394531
Validation loss: 1.9723680814107258

Epoch: 5| Step: 2
Training loss: 0.7316189408302307
Validation loss: 2.0216952088058635

Epoch: 5| Step: 3
Training loss: 1.5797123908996582
Validation loss: 1.9524895837230067

Epoch: 5| Step: 4
Training loss: 1.2136576175689697
Validation loss: 1.9835171250886814

Epoch: 5| Step: 5
Training loss: 0.9943447113037109
Validation loss: 1.956554974279096

Epoch: 5| Step: 6
Training loss: 1.2192238569259644
Validation loss: 1.972660533843502

Epoch: 5| Step: 7
Training loss: 0.9936566352844238
Validation loss: 1.9839936712736725

Epoch: 5| Step: 8
Training loss: 0.8618203997612
Validation loss: 1.9921869090808335

Epoch: 5| Step: 9
Training loss: 1.5680301189422607
Validation loss: 1.9473045000465967

Epoch: 5| Step: 10
Training loss: 1.2383356094360352
Validation loss: 1.9693364122862458

Epoch: 704| Step: 0
Training loss: 0.9995182156562805
Validation loss: 1.9341449353002733

Epoch: 5| Step: 1
Training loss: 1.0172797441482544
Validation loss: 1.9481629146042692

Epoch: 5| Step: 2
Training loss: 1.2570786476135254
Validation loss: 1.9246842553538661

Epoch: 5| Step: 3
Training loss: 0.9450066685676575
Validation loss: 1.9592521229097921

Epoch: 5| Step: 4
Training loss: 1.6616566181182861
Validation loss: 1.973785759300314

Epoch: 5| Step: 5
Training loss: 1.1910806894302368
Validation loss: 1.943349463965303

Epoch: 5| Step: 6
Training loss: 0.6200913786888123
Validation loss: 1.9610004130230154

Epoch: 5| Step: 7
Training loss: 0.9210136532783508
Validation loss: 1.9714355109840311

Epoch: 5| Step: 8
Training loss: 1.5249955654144287
Validation loss: 1.9782650727097706

Epoch: 5| Step: 9
Training loss: 1.4144185781478882
Validation loss: 1.9442655194190241

Epoch: 5| Step: 10
Training loss: 1.0432225465774536
Validation loss: 1.980613661068742

Epoch: 705| Step: 0
Training loss: 1.3804852962493896
Validation loss: 1.9389411505832468

Epoch: 5| Step: 1
Training loss: 1.5254120826721191
Validation loss: 1.899026023444309

Epoch: 5| Step: 2
Training loss: 0.684662938117981
Validation loss: 1.9829235999814925

Epoch: 5| Step: 3
Training loss: 0.9006282091140747
Validation loss: 1.9755646874827724

Epoch: 5| Step: 4
Training loss: 1.0061737298965454
Validation loss: 1.9787331832352506

Epoch: 5| Step: 5
Training loss: 1.3630670309066772
Validation loss: 1.9752731233514764

Epoch: 5| Step: 6
Training loss: 1.219254732131958
Validation loss: 1.967193595824703

Epoch: 5| Step: 7
Training loss: 0.5580660104751587
Validation loss: 1.9325857290657618

Epoch: 5| Step: 8
Training loss: 0.8642935752868652
Validation loss: 1.9866844582301315

Epoch: 5| Step: 9
Training loss: 1.413435935974121
Validation loss: 1.968967887663072

Epoch: 5| Step: 10
Training loss: 1.603201985359192
Validation loss: 1.9975714798896544

Epoch: 706| Step: 0
Training loss: 1.0411535501480103
Validation loss: 1.9342308608434533

Epoch: 5| Step: 1
Training loss: 0.9886887669563293
Validation loss: 1.9821555896471905

Epoch: 5| Step: 2
Training loss: 1.2246135473251343
Validation loss: 1.9674910678658435

Epoch: 5| Step: 3
Training loss: 0.6832538843154907
Validation loss: 1.947207002229588

Epoch: 5| Step: 4
Training loss: 1.0838953256607056
Validation loss: 1.9566090722237863

Epoch: 5| Step: 5
Training loss: 1.154066801071167
Validation loss: 1.9445571540504374

Epoch: 5| Step: 6
Training loss: 0.8248257637023926
Validation loss: 1.9435823963534447

Epoch: 5| Step: 7
Training loss: 1.3964427709579468
Validation loss: 1.9253763614162323

Epoch: 5| Step: 8
Training loss: 1.4692106246948242
Validation loss: 1.9473495970490158

Epoch: 5| Step: 9
Training loss: 1.1244239807128906
Validation loss: 1.9407652616500854

Epoch: 5| Step: 10
Training loss: 1.8559490442276
Validation loss: 1.9430905349792973

Epoch: 707| Step: 0
Training loss: 0.8420818448066711
Validation loss: 1.9704130964894448

Epoch: 5| Step: 1
Training loss: 1.5067421197891235
Validation loss: 1.9868461521722938

Epoch: 5| Step: 2
Training loss: 0.9422935247421265
Validation loss: 2.001138082114599

Epoch: 5| Step: 3
Training loss: 1.042515754699707
Validation loss: 2.0107256417633383

Epoch: 5| Step: 4
Training loss: 1.7022345066070557
Validation loss: 2.0501427060814312

Epoch: 5| Step: 5
Training loss: 1.2182422876358032
Validation loss: 2.0190291532906155

Epoch: 5| Step: 6
Training loss: 1.0099482536315918
Validation loss: 2.005591732199474

Epoch: 5| Step: 7
Training loss: 0.7846711874008179
Validation loss: 2.000421126683553

Epoch: 5| Step: 8
Training loss: 1.3484057188034058
Validation loss: 2.0187021609275573

Epoch: 5| Step: 9
Training loss: 1.4841623306274414
Validation loss: 1.9568255280935636

Epoch: 5| Step: 10
Training loss: 1.0621869564056396
Validation loss: 1.991880009251256

Epoch: 708| Step: 0
Training loss: 0.8900899887084961
Validation loss: 1.9515473304256317

Epoch: 5| Step: 1
Training loss: 1.5001065731048584
Validation loss: 1.9841466334558302

Epoch: 5| Step: 2
Training loss: 1.182539701461792
Validation loss: 2.0004324041387087

Epoch: 5| Step: 3
Training loss: 0.9360340237617493
Validation loss: 1.9641345854728454

Epoch: 5| Step: 4
Training loss: 1.118140459060669
Validation loss: 1.9162849046850716

Epoch: 5| Step: 5
Training loss: 0.9094647169113159
Validation loss: 1.9907296370434504

Epoch: 5| Step: 6
Training loss: 1.2350101470947266
Validation loss: 1.9791614342761297

Epoch: 5| Step: 7
Training loss: 1.6966464519500732
Validation loss: 2.0130346705836635

Epoch: 5| Step: 8
Training loss: 1.2908756732940674
Validation loss: 1.9629076091192101

Epoch: 5| Step: 9
Training loss: 0.881125271320343
Validation loss: 1.97215909342612

Epoch: 5| Step: 10
Training loss: 1.1552459001541138
Validation loss: 1.978277631985244

Epoch: 709| Step: 0
Training loss: 1.4791920185089111
Validation loss: 1.954613236970799

Epoch: 5| Step: 1
Training loss: 1.2826606035232544
Validation loss: 1.9799454904371692

Epoch: 5| Step: 2
Training loss: 1.218295693397522
Validation loss: 1.9876958439427037

Epoch: 5| Step: 3
Training loss: 1.2076369524002075
Validation loss: 1.993662021493399

Epoch: 5| Step: 4
Training loss: 1.1774927377700806
Validation loss: 1.9894476308617541

Epoch: 5| Step: 5
Training loss: 0.900397777557373
Validation loss: 1.9857182925747288

Epoch: 5| Step: 6
Training loss: 1.030165672302246
Validation loss: 1.9800286857030724

Epoch: 5| Step: 7
Training loss: 1.1670745611190796
Validation loss: 1.9977313728742703

Epoch: 5| Step: 8
Training loss: 1.3963478803634644
Validation loss: 1.9868999424801077

Epoch: 5| Step: 9
Training loss: 1.215728998184204
Validation loss: 1.9588991262579476

Epoch: 5| Step: 10
Training loss: 0.6196703314781189
Validation loss: 1.9740161536842264

Epoch: 710| Step: 0
Training loss: 0.7848725914955139
Validation loss: 1.9466436165635304

Epoch: 5| Step: 1
Training loss: 1.5461981296539307
Validation loss: 1.9427811920001943

Epoch: 5| Step: 2
Training loss: 1.3619707822799683
Validation loss: 1.944109421904369

Epoch: 5| Step: 3
Training loss: 1.0755980014801025
Validation loss: 1.9878664196178477

Epoch: 5| Step: 4
Training loss: 1.0029605627059937
Validation loss: 1.9654527889784945

Epoch: 5| Step: 5
Training loss: 1.3167855739593506
Validation loss: 1.9759650025316464

Epoch: 5| Step: 6
Training loss: 1.4873889684677124
Validation loss: 1.9752025552975234

Epoch: 5| Step: 7
Training loss: 0.7729504704475403
Validation loss: 2.0115700203885316

Epoch: 5| Step: 8
Training loss: 1.2891027927398682
Validation loss: 1.9511996546099264

Epoch: 5| Step: 9
Training loss: 1.1157335042953491
Validation loss: 1.9565096811581684

Epoch: 5| Step: 10
Training loss: 1.1769495010375977
Validation loss: 1.9308659697091708

Epoch: 711| Step: 0
Training loss: 0.9798721075057983
Validation loss: 1.9436339511666247

Epoch: 5| Step: 1
Training loss: 0.7477310299873352
Validation loss: 1.9585059381300403

Epoch: 5| Step: 2
Training loss: 1.1584464311599731
Validation loss: 1.9792057032226233

Epoch: 5| Step: 3
Training loss: 1.0099895000457764
Validation loss: 1.9486081010551863

Epoch: 5| Step: 4
Training loss: 1.0904433727264404
Validation loss: 1.9575342542381697

Epoch: 5| Step: 5
Training loss: 1.108652114868164
Validation loss: 1.9648489157358806

Epoch: 5| Step: 6
Training loss: 1.5943286418914795
Validation loss: 1.95565414685075

Epoch: 5| Step: 7
Training loss: 1.260953664779663
Validation loss: 1.9742056208272134

Epoch: 5| Step: 8
Training loss: 0.9467000961303711
Validation loss: 1.9419756730397542

Epoch: 5| Step: 9
Training loss: 1.494508981704712
Validation loss: 1.9433078791505547

Epoch: 5| Step: 10
Training loss: 1.3081058263778687
Validation loss: 1.9697476535715082

Epoch: 712| Step: 0
Training loss: 1.096712350845337
Validation loss: 1.9866970841602614

Epoch: 5| Step: 1
Training loss: 1.3981634378433228
Validation loss: 2.0230692714773197

Epoch: 5| Step: 2
Training loss: 1.7340900897979736
Validation loss: 1.995548499527798

Epoch: 5| Step: 3
Training loss: 0.9319100379943848
Validation loss: 2.0187145856118973

Epoch: 5| Step: 4
Training loss: 1.3249505758285522
Validation loss: 1.9675891681384015

Epoch: 5| Step: 5
Training loss: 1.0352239608764648
Validation loss: 1.91892889366355

Epoch: 5| Step: 6
Training loss: 0.6833301186561584
Validation loss: 1.9916756781198646

Epoch: 5| Step: 7
Training loss: 0.9980418086051941
Validation loss: 1.9822893783610354

Epoch: 5| Step: 8
Training loss: 1.1169315576553345
Validation loss: 1.94781082676303

Epoch: 5| Step: 9
Training loss: 0.9664098024368286
Validation loss: 1.996516207213043

Epoch: 5| Step: 10
Training loss: 0.9930775761604309
Validation loss: 1.9547853931303947

Epoch: 713| Step: 0
Training loss: 1.1125476360321045
Validation loss: 1.953659866445808

Epoch: 5| Step: 1
Training loss: 0.7313787341117859
Validation loss: 1.9705905170850857

Epoch: 5| Step: 2
Training loss: 1.3942387104034424
Validation loss: 1.9533162373368458

Epoch: 5| Step: 3
Training loss: 1.8673702478408813
Validation loss: 1.9805954810111754

Epoch: 5| Step: 4
Training loss: 0.7293077707290649
Validation loss: 1.9501076641903128

Epoch: 5| Step: 5
Training loss: 0.47743159532546997
Validation loss: 1.935560639186572

Epoch: 5| Step: 6
Training loss: 1.2811740636825562
Validation loss: 1.953789222624994

Epoch: 5| Step: 7
Training loss: 1.0346405506134033
Validation loss: 1.9985032414877286

Epoch: 5| Step: 8
Training loss: 1.4093854427337646
Validation loss: 1.95042541462888

Epoch: 5| Step: 9
Training loss: 1.0747404098510742
Validation loss: 1.9622048511300036

Epoch: 5| Step: 10
Training loss: 1.4056333303451538
Validation loss: 1.959556935935892

Epoch: 714| Step: 0
Training loss: 1.3569000959396362
Validation loss: 1.9548075276036416

Epoch: 5| Step: 1
Training loss: 1.0935707092285156
Validation loss: 1.931112959820737

Epoch: 5| Step: 2
Training loss: 1.2016364336013794
Validation loss: 1.9782608888482536

Epoch: 5| Step: 3
Training loss: 1.0439729690551758
Validation loss: 1.9693994060639413

Epoch: 5| Step: 4
Training loss: 0.6779956817626953
Validation loss: 1.9639599797546223

Epoch: 5| Step: 5
Training loss: 1.2528985738754272
Validation loss: 1.9800712472649031

Epoch: 5| Step: 6
Training loss: 1.3653090000152588
Validation loss: 1.9651684273955643

Epoch: 5| Step: 7
Training loss: 1.4209263324737549
Validation loss: 1.8943259946761593

Epoch: 5| Step: 8
Training loss: 1.1105849742889404
Validation loss: 1.9804554357323596

Epoch: 5| Step: 9
Training loss: 0.987947940826416
Validation loss: 1.9936187100666825

Epoch: 5| Step: 10
Training loss: 1.214828610420227
Validation loss: 1.9713572776445778

Epoch: 715| Step: 0
Training loss: 1.2987067699432373
Validation loss: 1.9430212513093026

Epoch: 5| Step: 1
Training loss: 1.249197244644165
Validation loss: 1.9373275451762701

Epoch: 5| Step: 2
Training loss: 0.869429886341095
Validation loss: 1.9737049636020456

Epoch: 5| Step: 3
Training loss: 1.1815625429153442
Validation loss: 1.9413548874598678

Epoch: 5| Step: 4
Training loss: 1.2755683660507202
Validation loss: 1.9606341905491327

Epoch: 5| Step: 5
Training loss: 1.4239352941513062
Validation loss: 1.9551743474057925

Epoch: 5| Step: 6
Training loss: 0.7179768681526184
Validation loss: 1.972706728084113

Epoch: 5| Step: 7
Training loss: 1.4898978471755981
Validation loss: 1.916537174614527

Epoch: 5| Step: 8
Training loss: 0.8673359155654907
Validation loss: 1.9325050000221498

Epoch: 5| Step: 9
Training loss: 1.005861759185791
Validation loss: 1.9646898033798381

Epoch: 5| Step: 10
Training loss: 1.0698760747909546
Validation loss: 1.930938107993013

Epoch: 716| Step: 0
Training loss: 1.1996349096298218
Validation loss: 1.9752851660533617

Epoch: 5| Step: 1
Training loss: 1.1338990926742554
Validation loss: 1.9674323681862123

Epoch: 5| Step: 2
Training loss: 0.9483779668807983
Validation loss: 1.9546001316398702

Epoch: 5| Step: 3
Training loss: 0.8841428756713867
Validation loss: 1.9979809727720035

Epoch: 5| Step: 4
Training loss: 1.6196428537368774
Validation loss: 1.9430326466919274

Epoch: 5| Step: 5
Training loss: 1.1271440982818604
Validation loss: 1.9467697246100313

Epoch: 5| Step: 6
Training loss: 1.2752503156661987
Validation loss: 1.9477217017963369

Epoch: 5| Step: 7
Training loss: 0.9864115715026855
Validation loss: 1.9647466239108835

Epoch: 5| Step: 8
Training loss: 1.1523797512054443
Validation loss: 1.966425363735486

Epoch: 5| Step: 9
Training loss: 1.1433284282684326
Validation loss: 1.9533695943893925

Epoch: 5| Step: 10
Training loss: 1.2299901247024536
Validation loss: 1.9803323976455196

Epoch: 717| Step: 0
Training loss: 1.156214952468872
Validation loss: 1.954390384817636

Epoch: 5| Step: 1
Training loss: 1.3744548559188843
Validation loss: 1.932212584762163

Epoch: 5| Step: 2
Training loss: 0.9968339800834656
Validation loss: 1.9497773339671474

Epoch: 5| Step: 3
Training loss: 1.063154935836792
Validation loss: 1.9565112052425262

Epoch: 5| Step: 4
Training loss: 0.9697738885879517
Validation loss: 2.0079989997289514

Epoch: 5| Step: 5
Training loss: 1.8248811960220337
Validation loss: 1.9846850556711997

Epoch: 5| Step: 6
Training loss: 0.7243392467498779
Validation loss: 1.9342306147339523

Epoch: 5| Step: 7
Training loss: 0.9171720743179321
Validation loss: 1.942122168438409

Epoch: 5| Step: 8
Training loss: 0.8328490257263184
Validation loss: 1.9643597500298613

Epoch: 5| Step: 9
Training loss: 1.4335321187973022
Validation loss: 1.9185197866091164

Epoch: 5| Step: 10
Training loss: 1.3256845474243164
Validation loss: 1.9383036757028231

Epoch: 718| Step: 0
Training loss: 1.2017605304718018
Validation loss: 1.9611307356947212

Epoch: 5| Step: 1
Training loss: 0.705146849155426
Validation loss: 1.9495129739084551

Epoch: 5| Step: 2
Training loss: 0.8827420473098755
Validation loss: 1.9681841583662136

Epoch: 5| Step: 3
Training loss: 0.9262582659721375
Validation loss: 1.9840451299503286

Epoch: 5| Step: 4
Training loss: 1.021559476852417
Validation loss: 1.9420391026363577

Epoch: 5| Step: 5
Training loss: 1.5031572580337524
Validation loss: 1.9674903269736999

Epoch: 5| Step: 6
Training loss: 1.2849065065383911
Validation loss: 1.9865270840224398

Epoch: 5| Step: 7
Training loss: 1.6832889318466187
Validation loss: 1.9939175933919928

Epoch: 5| Step: 8
Training loss: 1.1305497884750366
Validation loss: 2.012266364148868

Epoch: 5| Step: 9
Training loss: 1.1973326206207275
Validation loss: 1.9473308414541266

Epoch: 5| Step: 10
Training loss: 0.7491406798362732
Validation loss: 1.9844217056869178

Epoch: 719| Step: 0
Training loss: 0.6166337132453918
Validation loss: 1.9122937494708645

Epoch: 5| Step: 1
Training loss: 0.9514883756637573
Validation loss: 1.968133786673187

Epoch: 5| Step: 2
Training loss: 1.2464540004730225
Validation loss: 1.9586674039081862

Epoch: 5| Step: 3
Training loss: 0.8372389078140259
Validation loss: 1.9414032492586362

Epoch: 5| Step: 4
Training loss: 1.3929965496063232
Validation loss: 1.9255997493702879

Epoch: 5| Step: 5
Training loss: 1.2830661535263062
Validation loss: 1.9842736695402412

Epoch: 5| Step: 6
Training loss: 1.1870253086090088
Validation loss: 1.9982685427511893

Epoch: 5| Step: 7
Training loss: 0.9923609495162964
Validation loss: 1.9726723650450348

Epoch: 5| Step: 8
Training loss: 1.682371735572815
Validation loss: 1.9781289985102992

Epoch: 5| Step: 9
Training loss: 1.3097411394119263
Validation loss: 1.9882421890894573

Epoch: 5| Step: 10
Training loss: 0.8290696740150452
Validation loss: 1.995051408967664

Epoch: 720| Step: 0
Training loss: 0.9748938679695129
Validation loss: 1.9588090360805552

Epoch: 5| Step: 1
Training loss: 1.652997612953186
Validation loss: 1.9734658297672067

Epoch: 5| Step: 2
Training loss: 1.0762187242507935
Validation loss: 1.960003177324931

Epoch: 5| Step: 3
Training loss: 0.9216973185539246
Validation loss: 1.9643650144659064

Epoch: 5| Step: 4
Training loss: 0.9211139678955078
Validation loss: 1.9755243152700446

Epoch: 5| Step: 5
Training loss: 1.1625292301177979
Validation loss: 1.9910887133690618

Epoch: 5| Step: 6
Training loss: 1.0496712923049927
Validation loss: 1.946561828736336

Epoch: 5| Step: 7
Training loss: 1.4114322662353516
Validation loss: 1.9706475811619912

Epoch: 5| Step: 8
Training loss: 0.9994809031486511
Validation loss: 1.9904581769820182

Epoch: 5| Step: 9
Training loss: 1.0201032161712646
Validation loss: 2.0052742740159393

Epoch: 5| Step: 10
Training loss: 1.4031305313110352
Validation loss: 1.9739489657904512

Epoch: 721| Step: 0
Training loss: 1.299942970275879
Validation loss: 1.9669838566933908

Epoch: 5| Step: 1
Training loss: 0.9055889844894409
Validation loss: 2.0006331743732577

Epoch: 5| Step: 2
Training loss: 1.4893463850021362
Validation loss: 1.989989939556327

Epoch: 5| Step: 3
Training loss: 0.768787682056427
Validation loss: 1.985247983727404

Epoch: 5| Step: 4
Training loss: 0.851894199848175
Validation loss: 1.9599873699167722

Epoch: 5| Step: 5
Training loss: 1.0146369934082031
Validation loss: 1.9578353025579964

Epoch: 5| Step: 6
Training loss: 1.4195153713226318
Validation loss: 1.949707179941157

Epoch: 5| Step: 7
Training loss: 1.3770275115966797
Validation loss: 1.9710205408834642

Epoch: 5| Step: 8
Training loss: 0.9631443023681641
Validation loss: 1.9291888616418327

Epoch: 5| Step: 9
Training loss: 0.8923459053039551
Validation loss: 1.9516884408971316

Epoch: 5| Step: 10
Training loss: 1.5427943468093872
Validation loss: 1.9456239259371193

Epoch: 722| Step: 0
Training loss: 1.8175175189971924
Validation loss: 1.9361007264865342

Epoch: 5| Step: 1
Training loss: 1.0422521829605103
Validation loss: 1.9842759652804303

Epoch: 5| Step: 2
Training loss: 1.5374560356140137
Validation loss: 1.946057124804425

Epoch: 5| Step: 3
Training loss: 1.0078487396240234
Validation loss: 1.9621229825481292

Epoch: 5| Step: 4
Training loss: 0.9975658655166626
Validation loss: 1.949012751220375

Epoch: 5| Step: 5
Training loss: 0.9556692242622375
Validation loss: 1.968442440032959

Epoch: 5| Step: 6
Training loss: 1.3834201097488403
Validation loss: 1.9543477373738443

Epoch: 5| Step: 7
Training loss: 0.8620938062667847
Validation loss: 1.9696830754639

Epoch: 5| Step: 8
Training loss: 0.991751492023468
Validation loss: 1.9930544912174184

Epoch: 5| Step: 9
Training loss: 1.1700260639190674
Validation loss: 1.967903370498329

Epoch: 5| Step: 10
Training loss: 0.7691598534584045
Validation loss: 1.966311115090565

Epoch: 723| Step: 0
Training loss: 1.8879207372665405
Validation loss: 1.9891018406037362

Epoch: 5| Step: 1
Training loss: 1.308714747428894
Validation loss: 1.9885508116855417

Epoch: 5| Step: 2
Training loss: 1.0831106901168823
Validation loss: 1.9615072127311461

Epoch: 5| Step: 3
Training loss: 1.0220619440078735
Validation loss: 1.9546854893366497

Epoch: 5| Step: 4
Training loss: 0.9831384420394897
Validation loss: 1.9522881379691504

Epoch: 5| Step: 5
Training loss: 0.7327144742012024
Validation loss: 1.9389714822974256

Epoch: 5| Step: 6
Training loss: 1.2422401905059814
Validation loss: 1.96290038734354

Epoch: 5| Step: 7
Training loss: 1.42681884765625
Validation loss: 1.9487007689732376

Epoch: 5| Step: 8
Training loss: 0.7249666452407837
Validation loss: 1.9439200329524216

Epoch: 5| Step: 9
Training loss: 1.105534553527832
Validation loss: 1.9755848774345972

Epoch: 5| Step: 10
Training loss: 0.9063089489936829
Validation loss: 1.964631793319538

Epoch: 724| Step: 0
Training loss: 0.9785907864570618
Validation loss: 1.9662912814847884

Epoch: 5| Step: 1
Training loss: 0.8389803767204285
Validation loss: 1.9398370891489007

Epoch: 5| Step: 2
Training loss: 1.131757140159607
Validation loss: 1.9789292863620225

Epoch: 5| Step: 3
Training loss: 0.9329016804695129
Validation loss: 1.9581862316336682

Epoch: 5| Step: 4
Training loss: 1.3876721858978271
Validation loss: 1.9767758897555772

Epoch: 5| Step: 5
Training loss: 1.4327795505523682
Validation loss: 1.9638473372305594

Epoch: 5| Step: 6
Training loss: 1.3766224384307861
Validation loss: 1.9806388552470873

Epoch: 5| Step: 7
Training loss: 1.5938940048217773
Validation loss: 1.9635841820829658

Epoch: 5| Step: 8
Training loss: 0.863274097442627
Validation loss: 1.948871208775428

Epoch: 5| Step: 9
Training loss: 1.0100491046905518
Validation loss: 1.9714888372728903

Epoch: 5| Step: 10
Training loss: 0.8383111357688904
Validation loss: 1.899314913698422

Epoch: 725| Step: 0
Training loss: 1.6120007038116455
Validation loss: 1.9871617799164147

Epoch: 5| Step: 1
Training loss: 1.2802181243896484
Validation loss: 1.9625310282553396

Epoch: 5| Step: 2
Training loss: 1.6198740005493164
Validation loss: 2.0051258199958393

Epoch: 5| Step: 3
Training loss: 0.9521054029464722
Validation loss: 2.0151228366359586

Epoch: 5| Step: 4
Training loss: 1.238290548324585
Validation loss: 2.0139393909003145

Epoch: 5| Step: 5
Training loss: 0.7212322950363159
Validation loss: 1.9905733652012323

Epoch: 5| Step: 6
Training loss: 0.5943191051483154
Validation loss: 1.9939910391325593

Epoch: 5| Step: 7
Training loss: 1.159363865852356
Validation loss: 1.9929146843571817

Epoch: 5| Step: 8
Training loss: 0.9675886034965515
Validation loss: 1.9632513189828524

Epoch: 5| Step: 9
Training loss: 0.941387951374054
Validation loss: 1.9826001531334334

Epoch: 5| Step: 10
Training loss: 1.3489717245101929
Validation loss: 1.9896371518411944

Epoch: 726| Step: 0
Training loss: 0.8434494137763977
Validation loss: 1.9275387243558002

Epoch: 5| Step: 1
Training loss: 0.6987224817276001
Validation loss: 1.9359678260741695

Epoch: 5| Step: 2
Training loss: 1.035322904586792
Validation loss: 1.9744899926647064

Epoch: 5| Step: 3
Training loss: 0.8766818046569824
Validation loss: 1.9529480934143066

Epoch: 5| Step: 4
Training loss: 1.1112993955612183
Validation loss: 1.9560510599485008

Epoch: 5| Step: 5
Training loss: 1.6363130807876587
Validation loss: 1.987776082049134

Epoch: 5| Step: 6
Training loss: 1.2376726865768433
Validation loss: 1.9704460290170485

Epoch: 5| Step: 7
Training loss: 1.573286771774292
Validation loss: 1.9568339445257699

Epoch: 5| Step: 8
Training loss: 0.9928766489028931
Validation loss: 1.9302648908348494

Epoch: 5| Step: 9
Training loss: 1.314771294593811
Validation loss: 2.0053144629283617

Epoch: 5| Step: 10
Training loss: 1.4350824356079102
Validation loss: 1.9764724123862483

Epoch: 727| Step: 0
Training loss: 0.8794770240783691
Validation loss: 1.975309516793938

Epoch: 5| Step: 1
Training loss: 1.259649634361267
Validation loss: 2.0121121483464397

Epoch: 5| Step: 2
Training loss: 1.2312324047088623
Validation loss: 1.9863623470388434

Epoch: 5| Step: 3
Training loss: 1.0073400735855103
Validation loss: 1.9728767448855984

Epoch: 5| Step: 4
Training loss: 1.0587012767791748
Validation loss: 1.9616196668276222

Epoch: 5| Step: 5
Training loss: 0.9521929621696472
Validation loss: 1.969736817062542

Epoch: 5| Step: 6
Training loss: 0.7983642220497131
Validation loss: 2.0156424737745717

Epoch: 5| Step: 7
Training loss: 1.224886178970337
Validation loss: 1.942629070692165

Epoch: 5| Step: 8
Training loss: 1.3244918584823608
Validation loss: 1.9492500007793467

Epoch: 5| Step: 9
Training loss: 1.4421170949935913
Validation loss: 1.9510171926149757

Epoch: 5| Step: 10
Training loss: 1.5139806270599365
Validation loss: 1.9919214351202852

Epoch: 728| Step: 0
Training loss: 0.6618809700012207
Validation loss: 1.9813055992126465

Epoch: 5| Step: 1
Training loss: 1.1390254497528076
Validation loss: 1.9763400887930265

Epoch: 5| Step: 2
Training loss: 1.5946921110153198
Validation loss: 1.9442913224620204

Epoch: 5| Step: 3
Training loss: 0.8549388647079468
Validation loss: 1.938185848215575

Epoch: 5| Step: 4
Training loss: 1.2596410512924194
Validation loss: 1.9815673238487654

Epoch: 5| Step: 5
Training loss: 1.218231201171875
Validation loss: 1.9527539591635428

Epoch: 5| Step: 6
Training loss: 0.7589715719223022
Validation loss: 1.9476610281134163

Epoch: 5| Step: 7
Training loss: 1.200102686882019
Validation loss: 1.970414048881941

Epoch: 5| Step: 8
Training loss: 1.2048892974853516
Validation loss: 1.9570694367090862

Epoch: 5| Step: 9
Training loss: 1.1621726751327515
Validation loss: 1.9888162279641757

Epoch: 5| Step: 10
Training loss: 1.6164792776107788
Validation loss: 1.9973537293813561

Epoch: 729| Step: 0
Training loss: 0.904776930809021
Validation loss: 1.9087441582833566

Epoch: 5| Step: 1
Training loss: 1.3659213781356812
Validation loss: 1.971950227214444

Epoch: 5| Step: 2
Training loss: 1.2442591190338135
Validation loss: 1.9647020627093572

Epoch: 5| Step: 3
Training loss: 1.3490674495697021
Validation loss: 1.9590370244877313

Epoch: 5| Step: 4
Training loss: 1.5606218576431274
Validation loss: 1.9428025240539222

Epoch: 5| Step: 5
Training loss: 0.7610986232757568
Validation loss: 1.9526130614742156

Epoch: 5| Step: 6
Training loss: 1.113563060760498
Validation loss: 1.9597704795099073

Epoch: 5| Step: 7
Training loss: 1.2350542545318604
Validation loss: 1.9752856813451296

Epoch: 5| Step: 8
Training loss: 0.8363035321235657
Validation loss: 1.9496222901087936

Epoch: 5| Step: 9
Training loss: 1.2599599361419678
Validation loss: 1.956013036030595

Epoch: 5| Step: 10
Training loss: 0.9934927821159363
Validation loss: 1.9445343773852113

Epoch: 730| Step: 0
Training loss: 1.301271915435791
Validation loss: 1.9946767668570242

Epoch: 5| Step: 1
Training loss: 0.7579143643379211
Validation loss: 1.9513558469792849

Epoch: 5| Step: 2
Training loss: 1.4174575805664062
Validation loss: 1.9537282015687676

Epoch: 5| Step: 3
Training loss: 1.3308500051498413
Validation loss: 2.0059044976388254

Epoch: 5| Step: 4
Training loss: 1.3608649969100952
Validation loss: 1.9878970358961372

Epoch: 5| Step: 5
Training loss: 1.6395107507705688
Validation loss: 1.979973828920754

Epoch: 5| Step: 6
Training loss: 0.9260839223861694
Validation loss: 1.9422960999191448

Epoch: 5| Step: 7
Training loss: 0.819632351398468
Validation loss: 1.9861877451660812

Epoch: 5| Step: 8
Training loss: 1.193854808807373
Validation loss: 1.9753960178744407

Epoch: 5| Step: 9
Training loss: 0.9132444262504578
Validation loss: 1.972548859093779

Epoch: 5| Step: 10
Training loss: 0.6991351842880249
Validation loss: 1.930136110192986

Epoch: 731| Step: 0
Training loss: 1.5845162868499756
Validation loss: 1.960173919636716

Epoch: 5| Step: 1
Training loss: 1.5882773399353027
Validation loss: 1.9529267075241252

Epoch: 5| Step: 2
Training loss: 0.7338792085647583
Validation loss: 1.9896104361421318

Epoch: 5| Step: 3
Training loss: 1.0600723028182983
Validation loss: 1.983727619212161

Epoch: 5| Step: 4
Training loss: 1.1078102588653564
Validation loss: 1.9565621717001802

Epoch: 5| Step: 5
Training loss: 1.0473970174789429
Validation loss: 1.9451802751069427

Epoch: 5| Step: 6
Training loss: 0.9199793934822083
Validation loss: 1.948638528905889

Epoch: 5| Step: 7
Training loss: 1.239096999168396
Validation loss: 1.9401445337521133

Epoch: 5| Step: 8
Training loss: 1.3171288967132568
Validation loss: 1.9761336170217043

Epoch: 5| Step: 9
Training loss: 0.4396700859069824
Validation loss: 1.9402408446035078

Epoch: 5| Step: 10
Training loss: 1.314077615737915
Validation loss: 2.0139532319961058

Epoch: 732| Step: 0
Training loss: 0.9838824272155762
Validation loss: 1.9742894044486425

Epoch: 5| Step: 1
Training loss: 0.8633354306221008
Validation loss: 1.9357808738626459

Epoch: 5| Step: 2
Training loss: 0.9589077830314636
Validation loss: 1.967026783574012

Epoch: 5| Step: 3
Training loss: 1.218189001083374
Validation loss: 1.9555291104060348

Epoch: 5| Step: 4
Training loss: 1.3872791528701782
Validation loss: 1.9458806335285146

Epoch: 5| Step: 5
Training loss: 1.2544469833374023
Validation loss: 1.9325206792482765

Epoch: 5| Step: 6
Training loss: 1.4543462991714478
Validation loss: 1.9852447189310545

Epoch: 5| Step: 7
Training loss: 0.9329098463058472
Validation loss: 2.0249196278151644

Epoch: 5| Step: 8
Training loss: 1.3407846689224243
Validation loss: 1.9604364979651667

Epoch: 5| Step: 9
Training loss: 0.9359882473945618
Validation loss: 1.9682611393672165

Epoch: 5| Step: 10
Training loss: 0.989840567111969
Validation loss: 1.967164288284958

Epoch: 733| Step: 0
Training loss: 0.8487973213195801
Validation loss: 1.9692376749489897

Epoch: 5| Step: 1
Training loss: 0.9138617515563965
Validation loss: 1.9375098213072746

Epoch: 5| Step: 2
Training loss: 1.4370403289794922
Validation loss: 1.9430707923827633

Epoch: 5| Step: 3
Training loss: 0.882362961769104
Validation loss: 1.969473026132071

Epoch: 5| Step: 4
Training loss: 1.6626993417739868
Validation loss: 1.942527550522999

Epoch: 5| Step: 5
Training loss: 1.0617642402648926
Validation loss: 1.9620045436325895

Epoch: 5| Step: 6
Training loss: 1.402958631515503
Validation loss: 1.918596024154335

Epoch: 5| Step: 7
Training loss: 0.9415982961654663
Validation loss: 1.953980230516003

Epoch: 5| Step: 8
Training loss: 0.9575970768928528
Validation loss: 1.9232495241267706

Epoch: 5| Step: 9
Training loss: 0.6857365369796753
Validation loss: 1.991345977270475

Epoch: 5| Step: 10
Training loss: 1.7075769901275635
Validation loss: 1.943438700450364

Epoch: 734| Step: 0
Training loss: 1.0160763263702393
Validation loss: 1.9713390129868702

Epoch: 5| Step: 1
Training loss: 0.9457801580429077
Validation loss: 1.9581960324318177

Epoch: 5| Step: 2
Training loss: 1.7182289361953735
Validation loss: 1.9762753055941673

Epoch: 5| Step: 3
Training loss: 1.0844367742538452
Validation loss: 2.000577983035836

Epoch: 5| Step: 4
Training loss: 1.4643418788909912
Validation loss: 1.982593902977564

Epoch: 5| Step: 5
Training loss: 0.8833383321762085
Validation loss: 1.9934089952899563

Epoch: 5| Step: 6
Training loss: 1.079599142074585
Validation loss: 2.0082758806085073

Epoch: 5| Step: 7
Training loss: 1.1151618957519531
Validation loss: 1.9687855551319737

Epoch: 5| Step: 8
Training loss: 1.0296951532363892
Validation loss: 1.9833307932781916

Epoch: 5| Step: 9
Training loss: 0.944434642791748
Validation loss: 1.9773101742549608

Epoch: 5| Step: 10
Training loss: 1.154174566268921
Validation loss: 1.952826178202065

Epoch: 735| Step: 0
Training loss: 0.6993553042411804
Validation loss: 1.9520946228376

Epoch: 5| Step: 1
Training loss: 1.2420190572738647
Validation loss: 1.9397940161407634

Epoch: 5| Step: 2
Training loss: 1.0717718601226807
Validation loss: 1.9448585433344687

Epoch: 5| Step: 3
Training loss: 1.4246841669082642
Validation loss: 2.0023771601338543

Epoch: 5| Step: 4
Training loss: 0.7734976410865784
Validation loss: 1.9641808514953942

Epoch: 5| Step: 5
Training loss: 1.0738335847854614
Validation loss: 1.9500329802113194

Epoch: 5| Step: 6
Training loss: 1.0999786853790283
Validation loss: 1.954016670103996

Epoch: 5| Step: 7
Training loss: 1.4329488277435303
Validation loss: 1.9680441194964993

Epoch: 5| Step: 8
Training loss: 1.141340970993042
Validation loss: 1.9899848866206344

Epoch: 5| Step: 9
Training loss: 1.6678667068481445
Validation loss: 2.0012680740766626

Epoch: 5| Step: 10
Training loss: 0.6733039021492004
Validation loss: 1.987016552238054

Epoch: 736| Step: 0
Training loss: 1.2166703939437866
Validation loss: 1.9191979387755036

Epoch: 5| Step: 1
Training loss: 1.1733381748199463
Validation loss: 1.9404429722857732

Epoch: 5| Step: 2
Training loss: 1.300809621810913
Validation loss: 1.9900894729040002

Epoch: 5| Step: 3
Training loss: 0.8019227981567383
Validation loss: 1.9783143869010351

Epoch: 5| Step: 4
Training loss: 1.3555259704589844
Validation loss: 1.9117951329036424

Epoch: 5| Step: 5
Training loss: 0.8627663850784302
Validation loss: 1.9548529501884215

Epoch: 5| Step: 6
Training loss: 0.9347468614578247
Validation loss: 1.9741110212059432

Epoch: 5| Step: 7
Training loss: 1.0218217372894287
Validation loss: 1.9554299769863006

Epoch: 5| Step: 8
Training loss: 1.3058552742004395
Validation loss: 1.9774334866513488

Epoch: 5| Step: 9
Training loss: 0.8053907155990601
Validation loss: 1.9724671302303192

Epoch: 5| Step: 10
Training loss: 1.4358233213424683
Validation loss: 1.9460693097883655

Epoch: 737| Step: 0
Training loss: 0.8659354448318481
Validation loss: 1.9850538007674678

Epoch: 5| Step: 1
Training loss: 0.8123981356620789
Validation loss: 1.9535991184173092

Epoch: 5| Step: 2
Training loss: 1.2347609996795654
Validation loss: 1.9820324451692644

Epoch: 5| Step: 3
Training loss: 1.2655956745147705
Validation loss: 1.9751353122854745

Epoch: 5| Step: 4
Training loss: 0.7663701176643372
Validation loss: 1.9565527054571337

Epoch: 5| Step: 5
Training loss: 1.404888391494751
Validation loss: 1.9691851318523448

Epoch: 5| Step: 6
Training loss: 1.2415716648101807
Validation loss: 2.015660575641099

Epoch: 5| Step: 7
Training loss: 1.114206075668335
Validation loss: 1.9867264070818502

Epoch: 5| Step: 8
Training loss: 1.2224535942077637
Validation loss: 1.9604322218125867

Epoch: 5| Step: 9
Training loss: 1.2861555814743042
Validation loss: 1.9975478931139874

Epoch: 5| Step: 10
Training loss: 1.188123106956482
Validation loss: 1.9247374547425138

Epoch: 738| Step: 0
Training loss: 0.9998916387557983
Validation loss: 1.9654883659014137

Epoch: 5| Step: 1
Training loss: 1.205825686454773
Validation loss: 1.9638021556279992

Epoch: 5| Step: 2
Training loss: 0.7693988084793091
Validation loss: 1.9351656834284465

Epoch: 5| Step: 3
Training loss: 1.70774245262146
Validation loss: 1.9321155266095233

Epoch: 5| Step: 4
Training loss: 1.50394606590271
Validation loss: 1.9162131970928562

Epoch: 5| Step: 5
Training loss: 0.834681510925293
Validation loss: 1.9292036077027679

Epoch: 5| Step: 6
Training loss: 1.0100619792938232
Validation loss: 1.9447808547686505

Epoch: 5| Step: 7
Training loss: 1.3267661333084106
Validation loss: 1.9498951806817004

Epoch: 5| Step: 8
Training loss: 0.6024280786514282
Validation loss: 1.9651541158717165

Epoch: 5| Step: 9
Training loss: 1.1457040309906006
Validation loss: 1.9493407344305387

Epoch: 5| Step: 10
Training loss: 1.0859553813934326
Validation loss: 1.9607048733260042

Epoch: 739| Step: 0
Training loss: 1.0656893253326416
Validation loss: 1.9744648036136423

Epoch: 5| Step: 1
Training loss: 1.1345888376235962
Validation loss: 1.9756307319928241

Epoch: 5| Step: 2
Training loss: 0.9506063461303711
Validation loss: 1.9544254195305608

Epoch: 5| Step: 3
Training loss: 1.2789227962493896
Validation loss: 1.9520649704881894

Epoch: 5| Step: 4
Training loss: 0.8241666555404663
Validation loss: 1.9615183043223556

Epoch: 5| Step: 5
Training loss: 1.109741449356079
Validation loss: 1.986626491751722

Epoch: 5| Step: 6
Training loss: 1.0906246900558472
Validation loss: 1.9207886636898082

Epoch: 5| Step: 7
Training loss: 1.3956596851348877
Validation loss: 1.9510435147952008

Epoch: 5| Step: 8
Training loss: 1.4357413053512573
Validation loss: 1.938306091934122

Epoch: 5| Step: 9
Training loss: 0.9206759333610535
Validation loss: 1.97652457990954

Epoch: 5| Step: 10
Training loss: 1.061022400856018
Validation loss: 1.9647899981467956

Epoch: 740| Step: 0
Training loss: 1.2859853506088257
Validation loss: 1.9336406825691141

Epoch: 5| Step: 1
Training loss: 1.157522439956665
Validation loss: 1.9641599296241679

Epoch: 5| Step: 2
Training loss: 1.2466607093811035
Validation loss: 1.9659746962208902

Epoch: 5| Step: 3
Training loss: 1.296250581741333
Validation loss: 1.9438967461227088

Epoch: 5| Step: 4
Training loss: 1.2260112762451172
Validation loss: 1.928307206399979

Epoch: 5| Step: 5
Training loss: 0.6327823400497437
Validation loss: 1.9877835858252741

Epoch: 5| Step: 6
Training loss: 1.0796594619750977
Validation loss: 1.951764045223113

Epoch: 5| Step: 7
Training loss: 1.0919241905212402
Validation loss: 1.9636803032249532

Epoch: 5| Step: 8
Training loss: 1.104146122932434
Validation loss: 1.9535426503868514

Epoch: 5| Step: 9
Training loss: 1.243247389793396
Validation loss: 1.9665606201335948

Epoch: 5| Step: 10
Training loss: 0.894639790058136
Validation loss: 1.9811171254804056

Epoch: 741| Step: 0
Training loss: 0.5274838209152222
Validation loss: 1.9724641961436118

Epoch: 5| Step: 1
Training loss: 1.099066138267517
Validation loss: 1.959726628436837

Epoch: 5| Step: 2
Training loss: 1.138267159461975
Validation loss: 1.9613497308505479

Epoch: 5| Step: 3
Training loss: 1.640392541885376
Validation loss: 1.954197718251136

Epoch: 5| Step: 4
Training loss: 1.104744553565979
Validation loss: 1.9605505517733994

Epoch: 5| Step: 5
Training loss: 0.7599413990974426
Validation loss: 1.930324746716407

Epoch: 5| Step: 6
Training loss: 1.207567811012268
Validation loss: 1.9683807665301907

Epoch: 5| Step: 7
Training loss: 1.4731829166412354
Validation loss: 1.986506272387761

Epoch: 5| Step: 8
Training loss: 1.051742672920227
Validation loss: 1.9820671619907502

Epoch: 5| Step: 9
Training loss: 0.9604406356811523
Validation loss: 1.9755171934763591

Epoch: 5| Step: 10
Training loss: 1.0550603866577148
Validation loss: 1.9651124938841789

Epoch: 742| Step: 0
Training loss: 0.9845963716506958
Validation loss: 1.945376460270215

Epoch: 5| Step: 1
Training loss: 0.8525549173355103
Validation loss: 1.941225859426683

Epoch: 5| Step: 2
Training loss: 0.7144735455513
Validation loss: 1.9815650216994747

Epoch: 5| Step: 3
Training loss: 1.5427886247634888
Validation loss: 1.9641395871357252

Epoch: 5| Step: 4
Training loss: 0.870195209980011
Validation loss: 1.960832885516587

Epoch: 5| Step: 5
Training loss: 1.4393054246902466
Validation loss: 1.9242093050351707

Epoch: 5| Step: 6
Training loss: 1.181663155555725
Validation loss: 1.960014615007626

Epoch: 5| Step: 7
Training loss: 1.0782887935638428
Validation loss: 1.9359548771253197

Epoch: 5| Step: 8
Training loss: 0.8840866088867188
Validation loss: 1.9734180050511514

Epoch: 5| Step: 9
Training loss: 1.296492338180542
Validation loss: 1.9603327679377731

Epoch: 5| Step: 10
Training loss: 1.1384540796279907
Validation loss: 1.970077560793969

Epoch: 743| Step: 0
Training loss: 1.1141564846038818
Validation loss: 1.9495254960111392

Epoch: 5| Step: 1
Training loss: 1.2353155612945557
Validation loss: 1.9649368024641467

Epoch: 5| Step: 2
Training loss: 1.9122934341430664
Validation loss: 1.9298806716037054

Epoch: 5| Step: 3
Training loss: 0.8696966171264648
Validation loss: 1.9860433275981615

Epoch: 5| Step: 4
Training loss: 1.008331060409546
Validation loss: 1.9352186623439993

Epoch: 5| Step: 5
Training loss: 0.9024599194526672
Validation loss: 1.9657365557967976

Epoch: 5| Step: 6
Training loss: 1.0603948831558228
Validation loss: 1.9523531326683619

Epoch: 5| Step: 7
Training loss: 1.1022491455078125
Validation loss: 2.0029419442658782

Epoch: 5| Step: 8
Training loss: 0.685076117515564
Validation loss: 1.9547325898242254

Epoch: 5| Step: 9
Training loss: 0.7813268899917603
Validation loss: 1.9371460496738393

Epoch: 5| Step: 10
Training loss: 1.5528544187545776
Validation loss: 1.9379664031408166

Epoch: 744| Step: 0
Training loss: 0.7575052976608276
Validation loss: 1.9740792705166725

Epoch: 5| Step: 1
Training loss: 0.9039589166641235
Validation loss: 1.9629798243122716

Epoch: 5| Step: 2
Training loss: 0.9635503888130188
Validation loss: 1.9362275831161007

Epoch: 5| Step: 3
Training loss: 1.0614986419677734
Validation loss: 1.9756334289427726

Epoch: 5| Step: 4
Training loss: 0.9045038223266602
Validation loss: 1.9437209252388246

Epoch: 5| Step: 5
Training loss: 1.0631192922592163
Validation loss: 1.9581208741793068

Epoch: 5| Step: 6
Training loss: 1.5268971920013428
Validation loss: 1.9572858323333084

Epoch: 5| Step: 7
Training loss: 1.496972918510437
Validation loss: 1.975083807463287

Epoch: 5| Step: 8
Training loss: 1.1889421939849854
Validation loss: 1.9972026514750656

Epoch: 5| Step: 9
Training loss: 1.2704936265945435
Validation loss: 1.9761135796064973

Epoch: 5| Step: 10
Training loss: 1.234506607055664
Validation loss: 1.9774778043070147

Epoch: 745| Step: 0
Training loss: 0.7470290660858154
Validation loss: 1.9655887798596454

Epoch: 5| Step: 1
Training loss: 1.5879772901535034
Validation loss: 1.9485094726726573

Epoch: 5| Step: 2
Training loss: 0.6073342561721802
Validation loss: 1.9621469128516413

Epoch: 5| Step: 3
Training loss: 1.0963828563690186
Validation loss: 1.9584401115294425

Epoch: 5| Step: 4
Training loss: 0.6642593145370483
Validation loss: 1.9554243446678243

Epoch: 5| Step: 5
Training loss: 1.4908275604248047
Validation loss: 1.9790975662969774

Epoch: 5| Step: 6
Training loss: 1.2161391973495483
Validation loss: 1.970781792876541

Epoch: 5| Step: 7
Training loss: 1.5417697429656982
Validation loss: 1.9802443814534012

Epoch: 5| Step: 8
Training loss: 1.057848334312439
Validation loss: 1.9353400738008562

Epoch: 5| Step: 9
Training loss: 1.2145954370498657
Validation loss: 1.9512346585591633

Epoch: 5| Step: 10
Training loss: 1.169330358505249
Validation loss: 1.9555369884737077

Epoch: 746| Step: 0
Training loss: 1.1681020259857178
Validation loss: 1.9813001771127023

Epoch: 5| Step: 1
Training loss: 0.8337324261665344
Validation loss: 1.9608823496808288

Epoch: 5| Step: 2
Training loss: 1.0330491065979004
Validation loss: 1.9798257966195383

Epoch: 5| Step: 3
Training loss: 0.9957147836685181
Validation loss: 1.96242973496837

Epoch: 5| Step: 4
Training loss: 1.3995254039764404
Validation loss: 1.9515773506574734

Epoch: 5| Step: 5
Training loss: 0.839511513710022
Validation loss: 1.9708950314470517

Epoch: 5| Step: 6
Training loss: 1.227683186531067
Validation loss: 1.936140198861399

Epoch: 5| Step: 7
Training loss: 1.449696660041809
Validation loss: 1.9666349759665869

Epoch: 5| Step: 8
Training loss: 1.2154072523117065
Validation loss: 1.9695239913079046

Epoch: 5| Step: 9
Training loss: 1.0393099784851074
Validation loss: 1.9559450559718634

Epoch: 5| Step: 10
Training loss: 0.7219288945198059
Validation loss: 1.95649673861842

Epoch: 747| Step: 0
Training loss: 1.3690167665481567
Validation loss: 1.9169670804854362

Epoch: 5| Step: 1
Training loss: 1.1252869367599487
Validation loss: 1.9598747248290687

Epoch: 5| Step: 2
Training loss: 0.7946783304214478
Validation loss: 1.972401527948277

Epoch: 5| Step: 3
Training loss: 0.7079939842224121
Validation loss: 1.959128192676011

Epoch: 5| Step: 4
Training loss: 1.1723301410675049
Validation loss: 1.9272050447361444

Epoch: 5| Step: 5
Training loss: 1.4542633295059204
Validation loss: 1.9867099818362985

Epoch: 5| Step: 6
Training loss: 1.3972587585449219
Validation loss: 1.995302870709409

Epoch: 5| Step: 7
Training loss: 1.0517371892929077
Validation loss: 1.9518922887822634

Epoch: 5| Step: 8
Training loss: 1.1516844034194946
Validation loss: 1.9743809700012207

Epoch: 5| Step: 9
Training loss: 1.1016836166381836
Validation loss: 1.9106491663122689

Epoch: 5| Step: 10
Training loss: 0.7854776978492737
Validation loss: 1.9739386317550496

Epoch: 748| Step: 0
Training loss: 0.8810199499130249
Validation loss: 1.956683648529873

Epoch: 5| Step: 1
Training loss: 1.419724702835083
Validation loss: 1.9895485242207844

Epoch: 5| Step: 2
Training loss: 1.0623469352722168
Validation loss: 1.970810196732962

Epoch: 5| Step: 3
Training loss: 1.0899145603179932
Validation loss: 2.0041250310918337

Epoch: 5| Step: 4
Training loss: 1.0091042518615723
Validation loss: 1.9809553264289774

Epoch: 5| Step: 5
Training loss: 1.2131824493408203
Validation loss: 1.9408429591886458

Epoch: 5| Step: 6
Training loss: 1.1796058416366577
Validation loss: 2.013399709937393

Epoch: 5| Step: 7
Training loss: 0.9932628870010376
Validation loss: 1.984946076587964

Epoch: 5| Step: 8
Training loss: 1.055543303489685
Validation loss: 1.9806525809790498

Epoch: 5| Step: 9
Training loss: 0.6010274291038513
Validation loss: 1.965630901757107

Epoch: 5| Step: 10
Training loss: 1.70284903049469
Validation loss: 1.9710281959144018

Epoch: 749| Step: 0
Training loss: 1.5640398263931274
Validation loss: 1.9616135217810189

Epoch: 5| Step: 1
Training loss: 0.6234795451164246
Validation loss: 1.9466097713798605

Epoch: 5| Step: 2
Training loss: 1.3982508182525635
Validation loss: 1.926154269967028

Epoch: 5| Step: 3
Training loss: 1.1861423254013062
Validation loss: 1.9393249429682249

Epoch: 5| Step: 4
Training loss: 1.5140522718429565
Validation loss: 1.9312317909732941

Epoch: 5| Step: 5
Training loss: 0.9786117672920227
Validation loss: 1.9490085596679358

Epoch: 5| Step: 6
Training loss: 1.260621428489685
Validation loss: 1.9530771393929758

Epoch: 5| Step: 7
Training loss: 0.7245376110076904
Validation loss: 1.9486547798238776

Epoch: 5| Step: 8
Training loss: 0.9904535412788391
Validation loss: 1.9457199317152782

Epoch: 5| Step: 9
Training loss: 0.84931480884552
Validation loss: 1.9626185253102293

Epoch: 5| Step: 10
Training loss: 0.9953099489212036
Validation loss: 1.9558981842892145

Epoch: 750| Step: 0
Training loss: 0.9542297124862671
Validation loss: 1.9175276423013339

Epoch: 5| Step: 1
Training loss: 1.1453578472137451
Validation loss: 1.9274033602847849

Epoch: 5| Step: 2
Training loss: 0.7235175371170044
Validation loss: 1.9587968395602318

Epoch: 5| Step: 3
Training loss: 1.7742220163345337
Validation loss: 1.9797881354567826

Epoch: 5| Step: 4
Training loss: 0.808207631111145
Validation loss: 1.9604377349217732

Epoch: 5| Step: 5
Training loss: 0.505460798740387
Validation loss: 1.9769438364172494

Epoch: 5| Step: 6
Training loss: 1.235394835472107
Validation loss: 1.957626292782445

Epoch: 5| Step: 7
Training loss: 1.2782453298568726
Validation loss: 1.915950523909702

Epoch: 5| Step: 8
Training loss: 1.4233897924423218
Validation loss: 1.9259878948170652

Epoch: 5| Step: 9
Training loss: 1.121504545211792
Validation loss: 1.9448853282518284

Epoch: 5| Step: 10
Training loss: 1.0577876567840576
Validation loss: 1.9646738998351558

Epoch: 751| Step: 0
Training loss: 0.858615517616272
Validation loss: 2.001121800432923

Epoch: 5| Step: 1
Training loss: 1.1810365915298462
Validation loss: 1.9190343169755832

Epoch: 5| Step: 2
Training loss: 1.5048052072525024
Validation loss: 1.9658330025211457

Epoch: 5| Step: 3
Training loss: 0.8603830337524414
Validation loss: 1.9717095821134505

Epoch: 5| Step: 4
Training loss: 1.0129262208938599
Validation loss: 1.992385241293138

Epoch: 5| Step: 5
Training loss: 1.4326679706573486
Validation loss: 1.9404958730102868

Epoch: 5| Step: 6
Training loss: 1.3388824462890625
Validation loss: 1.9575409017583376

Epoch: 5| Step: 7
Training loss: 0.8078069686889648
Validation loss: 1.9713058535770704

Epoch: 5| Step: 8
Training loss: 0.9498425722122192
Validation loss: 1.981213560668371

Epoch: 5| Step: 9
Training loss: 0.9747346639633179
Validation loss: 1.9377776653535905

Epoch: 5| Step: 10
Training loss: 0.8995850682258606
Validation loss: 1.9397256143631474

Epoch: 752| Step: 0
Training loss: 1.2568044662475586
Validation loss: 1.910490612829885

Epoch: 5| Step: 1
Training loss: 1.2192890644073486
Validation loss: 1.9465127606545725

Epoch: 5| Step: 2
Training loss: 0.7256187796592712
Validation loss: 2.0010956487348004

Epoch: 5| Step: 3
Training loss: 0.8864059448242188
Validation loss: 1.945996428048739

Epoch: 5| Step: 4
Training loss: 1.200695276260376
Validation loss: 1.985249747512161

Epoch: 5| Step: 5
Training loss: 1.0172035694122314
Validation loss: 1.9524227188479515

Epoch: 5| Step: 6
Training loss: 1.2912826538085938
Validation loss: 1.9397169261850336

Epoch: 5| Step: 7
Training loss: 1.2318408489227295
Validation loss: 1.935701008765928

Epoch: 5| Step: 8
Training loss: 1.104892611503601
Validation loss: 1.9695604872959915

Epoch: 5| Step: 9
Training loss: 1.2146285772323608
Validation loss: 1.9124782546874015

Epoch: 5| Step: 10
Training loss: 0.9831536412239075
Validation loss: 1.943160528777748

Epoch: 753| Step: 0
Training loss: 0.7701833844184875
Validation loss: 1.9216060100063201

Epoch: 5| Step: 1
Training loss: 0.6996773481369019
Validation loss: 1.9804798505639518

Epoch: 5| Step: 2
Training loss: 0.6529105305671692
Validation loss: 1.9657394193833875

Epoch: 5| Step: 3
Training loss: 1.8245872259140015
Validation loss: 1.9616706704580655

Epoch: 5| Step: 4
Training loss: 1.0229547023773193
Validation loss: 1.9930828771283549

Epoch: 5| Step: 5
Training loss: 1.072155237197876
Validation loss: 1.9659011402437765

Epoch: 5| Step: 6
Training loss: 0.9812089800834656
Validation loss: 1.979269237928493

Epoch: 5| Step: 7
Training loss: 0.8708073496818542
Validation loss: 1.9471098710131902

Epoch: 5| Step: 8
Training loss: 1.4947720766067505
Validation loss: 1.9811366168401574

Epoch: 5| Step: 9
Training loss: 1.3879072666168213
Validation loss: 1.9375937779744465

Epoch: 5| Step: 10
Training loss: 1.1370514631271362
Validation loss: 1.9480720925074753

Epoch: 754| Step: 0
Training loss: 1.04373037815094
Validation loss: 1.9490486127074047

Epoch: 5| Step: 1
Training loss: 0.9531291723251343
Validation loss: 1.923315889091902

Epoch: 5| Step: 2
Training loss: 1.093550682067871
Validation loss: 1.9270556921600013

Epoch: 5| Step: 3
Training loss: 1.0964328050613403
Validation loss: 1.9549567827614405

Epoch: 5| Step: 4
Training loss: 1.0905405282974243
Validation loss: 1.9310304580196258

Epoch: 5| Step: 5
Training loss: 1.1530067920684814
Validation loss: 1.9694761396736227

Epoch: 5| Step: 6
Training loss: 1.1297810077667236
Validation loss: 1.9320507177742579

Epoch: 5| Step: 7
Training loss: 1.1091307401657104
Validation loss: 1.954359931330527

Epoch: 5| Step: 8
Training loss: 1.2093045711517334
Validation loss: 1.9533224362199024

Epoch: 5| Step: 9
Training loss: 1.4118458032608032
Validation loss: 1.9839226725280925

Epoch: 5| Step: 10
Training loss: 0.7186999917030334
Validation loss: 1.9538366833040792

Epoch: 755| Step: 0
Training loss: 1.07012140750885
Validation loss: 1.9808940682359921

Epoch: 5| Step: 1
Training loss: 1.3722541332244873
Validation loss: 1.9668550145241521

Epoch: 5| Step: 2
Training loss: 1.2911618947982788
Validation loss: 1.977206548055013

Epoch: 5| Step: 3
Training loss: 1.4790327548980713
Validation loss: 1.9216077148273427

Epoch: 5| Step: 4
Training loss: 1.3394198417663574
Validation loss: 1.9621322539544874

Epoch: 5| Step: 5
Training loss: 0.7163843512535095
Validation loss: 1.9417225083997172

Epoch: 5| Step: 6
Training loss: 0.8968135118484497
Validation loss: 1.9289408665831371

Epoch: 5| Step: 7
Training loss: 1.0518734455108643
Validation loss: 1.9615665738300612

Epoch: 5| Step: 8
Training loss: 1.0185295343399048
Validation loss: 1.9613507178521925

Epoch: 5| Step: 9
Training loss: 0.8202166557312012
Validation loss: 1.9677471242925173

Epoch: 5| Step: 10
Training loss: 0.4927636384963989
Validation loss: 1.9866741549584173

Epoch: 756| Step: 0
Training loss: 1.002845287322998
Validation loss: 1.9318093330629411

Epoch: 5| Step: 1
Training loss: 1.004712462425232
Validation loss: 1.941096298156246

Epoch: 5| Step: 2
Training loss: 0.97627192735672
Validation loss: 1.9216074930724276

Epoch: 5| Step: 3
Training loss: 1.1706517934799194
Validation loss: 1.9497254125533565

Epoch: 5| Step: 4
Training loss: 0.6522766351699829
Validation loss: 1.9419902998914

Epoch: 5| Step: 5
Training loss: 1.3063223361968994
Validation loss: 1.9648917977527907

Epoch: 5| Step: 6
Training loss: 1.6197776794433594
Validation loss: 1.911789462130557

Epoch: 5| Step: 7
Training loss: 0.7337024211883545
Validation loss: 1.9504083407822477

Epoch: 5| Step: 8
Training loss: 1.3084650039672852
Validation loss: 1.976219302864485

Epoch: 5| Step: 9
Training loss: 0.9994953870773315
Validation loss: 1.9501610263701408

Epoch: 5| Step: 10
Training loss: 1.3328883647918701
Validation loss: 1.9499177035465036

Epoch: 757| Step: 0
Training loss: 0.7833274006843567
Validation loss: 1.9354460341956026

Epoch: 5| Step: 1
Training loss: 0.9435417056083679
Validation loss: 1.9556358616839173

Epoch: 5| Step: 2
Training loss: 1.3550843000411987
Validation loss: 1.981187471779444

Epoch: 5| Step: 3
Training loss: 1.2571446895599365
Validation loss: 1.9724238585400324

Epoch: 5| Step: 4
Training loss: 0.8507902026176453
Validation loss: 1.9645257752428773

Epoch: 5| Step: 5
Training loss: 0.9963415265083313
Validation loss: 1.9625518450172998

Epoch: 5| Step: 6
Training loss: 0.7849615216255188
Validation loss: 1.9763268501527849

Epoch: 5| Step: 7
Training loss: 1.1704961061477661
Validation loss: 1.950853470833071

Epoch: 5| Step: 8
Training loss: 1.0330263376235962
Validation loss: 1.9782274923016947

Epoch: 5| Step: 9
Training loss: 1.4727611541748047
Validation loss: 1.9509253527528496

Epoch: 5| Step: 10
Training loss: 1.2540242671966553
Validation loss: 1.9570973227100987

Epoch: 758| Step: 0
Training loss: 0.8889392614364624
Validation loss: 1.9339235175040461

Epoch: 5| Step: 1
Training loss: 0.7790580987930298
Validation loss: 1.9273548228766328

Epoch: 5| Step: 2
Training loss: 1.2228208780288696
Validation loss: 1.922588074079124

Epoch: 5| Step: 3
Training loss: 1.1583154201507568
Validation loss: 1.9563541002171014

Epoch: 5| Step: 4
Training loss: 1.0687544345855713
Validation loss: 1.9572376653712282

Epoch: 5| Step: 5
Training loss: 1.2870008945465088
Validation loss: 1.9299977069259973

Epoch: 5| Step: 6
Training loss: 1.2075779438018799
Validation loss: 1.976799972595707

Epoch: 5| Step: 7
Training loss: 1.4006009101867676
Validation loss: 1.9658803747546287

Epoch: 5| Step: 8
Training loss: 0.9414262771606445
Validation loss: 1.9898033885545627

Epoch: 5| Step: 9
Training loss: 0.9845069646835327
Validation loss: 1.9700552596840808

Epoch: 5| Step: 10
Training loss: 1.1660131216049194
Validation loss: 1.9802735928566224

Epoch: 759| Step: 0
Training loss: 0.980406641960144
Validation loss: 1.9622378862032326

Epoch: 5| Step: 1
Training loss: 1.0992612838745117
Validation loss: 1.9289776740535614

Epoch: 5| Step: 2
Training loss: 0.8606511354446411
Validation loss: 1.9171088946762906

Epoch: 5| Step: 3
Training loss: 0.7647240161895752
Validation loss: 1.9655399002054685

Epoch: 5| Step: 4
Training loss: 0.8001102209091187
Validation loss: 1.941699149788067

Epoch: 5| Step: 5
Training loss: 1.7654606103897095
Validation loss: 1.958874983172263

Epoch: 5| Step: 6
Training loss: 0.9920545816421509
Validation loss: 1.9630369088983024

Epoch: 5| Step: 7
Training loss: 0.7799001932144165
Validation loss: 1.934042320456556

Epoch: 5| Step: 8
Training loss: 0.8218159675598145
Validation loss: 1.9480591820132347

Epoch: 5| Step: 9
Training loss: 1.3444758653640747
Validation loss: 1.9554852003692298

Epoch: 5| Step: 10
Training loss: 1.9488708972930908
Validation loss: 1.9658252244354577

Epoch: 760| Step: 0
Training loss: 1.158424973487854
Validation loss: 1.9319800202564528

Epoch: 5| Step: 1
Training loss: 1.009533166885376
Validation loss: 1.941218110822862

Epoch: 5| Step: 2
Training loss: 1.532732605934143
Validation loss: 1.958737902743842

Epoch: 5| Step: 3
Training loss: 1.0964974164962769
Validation loss: 1.9392091920298915

Epoch: 5| Step: 4
Training loss: 1.0501601696014404
Validation loss: 1.958533437021317

Epoch: 5| Step: 5
Training loss: 1.3972995281219482
Validation loss: 1.944666342068744

Epoch: 5| Step: 6
Training loss: 0.8016082048416138
Validation loss: 1.9348390666387414

Epoch: 5| Step: 7
Training loss: 0.6822742819786072
Validation loss: 1.9683733473541916

Epoch: 5| Step: 8
Training loss: 1.4070303440093994
Validation loss: 1.9509245657151746

Epoch: 5| Step: 9
Training loss: 0.6265989542007446
Validation loss: 1.9414291586927188

Epoch: 5| Step: 10
Training loss: 1.1447504758834839
Validation loss: 1.9411960109587638

Epoch: 761| Step: 0
Training loss: 1.080383539199829
Validation loss: 1.9558274540849911

Epoch: 5| Step: 1
Training loss: 1.0143816471099854
Validation loss: 1.9442290541946248

Epoch: 5| Step: 2
Training loss: 0.7827529311180115
Validation loss: 1.980991586562126

Epoch: 5| Step: 3
Training loss: 0.793981671333313
Validation loss: 1.9476238924969909

Epoch: 5| Step: 4
Training loss: 0.9770366549491882
Validation loss: 1.9516220733683596

Epoch: 5| Step: 5
Training loss: 1.1993902921676636
Validation loss: 1.9739278362643333

Epoch: 5| Step: 6
Training loss: 1.4219303131103516
Validation loss: 1.920593951338081

Epoch: 5| Step: 7
Training loss: 1.3685004711151123
Validation loss: 1.9383341868718464

Epoch: 5| Step: 8
Training loss: 1.513742208480835
Validation loss: 1.9540126656973233

Epoch: 5| Step: 9
Training loss: 0.8757050633430481
Validation loss: 1.9266952148047827

Epoch: 5| Step: 10
Training loss: 0.9509478211402893
Validation loss: 1.9744016880630164

Epoch: 762| Step: 0
Training loss: 1.082406997680664
Validation loss: 1.9495820973509101

Epoch: 5| Step: 1
Training loss: 0.8373788595199585
Validation loss: 2.004085813799212

Epoch: 5| Step: 2
Training loss: 1.5031042098999023
Validation loss: 1.98349243082026

Epoch: 5| Step: 3
Training loss: 1.6096887588500977
Validation loss: 1.9849977339467695

Epoch: 5| Step: 4
Training loss: 0.9486406445503235
Validation loss: 2.0188728673483736

Epoch: 5| Step: 5
Training loss: 1.2286007404327393
Validation loss: 1.9573402597058205

Epoch: 5| Step: 6
Training loss: 0.5020531415939331
Validation loss: 1.974005631221238

Epoch: 5| Step: 7
Training loss: 1.4782663583755493
Validation loss: 1.9699821625986407

Epoch: 5| Step: 8
Training loss: 1.2566715478897095
Validation loss: 1.939979914695986

Epoch: 5| Step: 9
Training loss: 0.547648012638092
Validation loss: 1.951279858107208

Epoch: 5| Step: 10
Training loss: 1.3156317472457886
Validation loss: 1.983386593480264

Epoch: 763| Step: 0
Training loss: 0.8507125973701477
Validation loss: 1.9452174709689232

Epoch: 5| Step: 1
Training loss: 0.9568634033203125
Validation loss: 1.942597290521027

Epoch: 5| Step: 2
Training loss: 1.053484320640564
Validation loss: 1.9493069520560644

Epoch: 5| Step: 3
Training loss: 1.891012191772461
Validation loss: 1.922212335371202

Epoch: 5| Step: 4
Training loss: 1.34705650806427
Validation loss: 1.9491100195915467

Epoch: 5| Step: 5
Training loss: 1.085605263710022
Validation loss: 1.9793944153734433

Epoch: 5| Step: 6
Training loss: 0.9743383526802063
Validation loss: 1.9478102191801994

Epoch: 5| Step: 7
Training loss: 1.0124242305755615
Validation loss: 1.9611788103657384

Epoch: 5| Step: 8
Training loss: 1.2918307781219482
Validation loss: 1.9632353744199198

Epoch: 5| Step: 9
Training loss: 0.8346518278121948
Validation loss: 1.992668733801893

Epoch: 5| Step: 10
Training loss: 0.7175561785697937
Validation loss: 1.9380085468292236

Epoch: 764| Step: 0
Training loss: 0.8033603429794312
Validation loss: 1.9519851579461047

Epoch: 5| Step: 1
Training loss: 1.1554540395736694
Validation loss: 1.9816350731798398

Epoch: 5| Step: 2
Training loss: 1.0682332515716553
Validation loss: 1.971878477322158

Epoch: 5| Step: 3
Training loss: 0.8345484733581543
Validation loss: 1.9265554874174056

Epoch: 5| Step: 4
Training loss: 1.0131146907806396
Validation loss: 1.9703497655930058

Epoch: 5| Step: 5
Training loss: 1.2457923889160156
Validation loss: 1.9668238880813762

Epoch: 5| Step: 6
Training loss: 1.0614135265350342
Validation loss: 1.9521079422325216

Epoch: 5| Step: 7
Training loss: 1.5082237720489502
Validation loss: 1.9315438168023222

Epoch: 5| Step: 8
Training loss: 0.8624003529548645
Validation loss: 1.9703728140041392

Epoch: 5| Step: 9
Training loss: 1.3098564147949219
Validation loss: 1.9168835519462504

Epoch: 5| Step: 10
Training loss: 1.1869134902954102
Validation loss: 1.9476763727844402

Epoch: 765| Step: 0
Training loss: 1.2251371145248413
Validation loss: 1.9526793149209791

Epoch: 5| Step: 1
Training loss: 1.1781424283981323
Validation loss: 1.9475964910240584

Epoch: 5| Step: 2
Training loss: 1.341138482093811
Validation loss: 1.951884646569529

Epoch: 5| Step: 3
Training loss: 0.6062132716178894
Validation loss: 1.9427440602292296

Epoch: 5| Step: 4
Training loss: 0.9592751264572144
Validation loss: 1.982370634232798

Epoch: 5| Step: 5
Training loss: 1.1659129858016968
Validation loss: 1.958366483770391

Epoch: 5| Step: 6
Training loss: 1.3191211223602295
Validation loss: 1.9582022082421087

Epoch: 5| Step: 7
Training loss: 0.707618772983551
Validation loss: 1.9793548609620781

Epoch: 5| Step: 8
Training loss: 0.9337836503982544
Validation loss: 1.9624167591012933

Epoch: 5| Step: 9
Training loss: 1.2160518169403076
Validation loss: 1.9279558222780946

Epoch: 5| Step: 10
Training loss: 1.1812505722045898
Validation loss: 1.9606903881155036

Epoch: 766| Step: 0
Training loss: 1.5275853872299194
Validation loss: 1.9843881668583039

Epoch: 5| Step: 1
Training loss: 0.9736387133598328
Validation loss: 1.940235669894885

Epoch: 5| Step: 2
Training loss: 1.0663716793060303
Validation loss: 1.9544911089763846

Epoch: 5| Step: 3
Training loss: 0.8778642416000366
Validation loss: 1.942115173544935

Epoch: 5| Step: 4
Training loss: 0.7925769090652466
Validation loss: 1.9390884625014437

Epoch: 5| Step: 5
Training loss: 1.417048692703247
Validation loss: 1.9543646971384685

Epoch: 5| Step: 6
Training loss: 1.1767381429672241
Validation loss: 1.948789345320835

Epoch: 5| Step: 7
Training loss: 1.051221251487732
Validation loss: 1.963048916991039

Epoch: 5| Step: 8
Training loss: 1.175438404083252
Validation loss: 1.9399078212758547

Epoch: 5| Step: 9
Training loss: 1.02858567237854
Validation loss: 1.967556515047627

Epoch: 5| Step: 10
Training loss: 1.0420852899551392
Validation loss: 1.9296532856520785

Epoch: 767| Step: 0
Training loss: 1.0867422819137573
Validation loss: 1.9376499242680048

Epoch: 5| Step: 1
Training loss: 0.8404132723808289
Validation loss: 1.9620676117558633

Epoch: 5| Step: 2
Training loss: 1.4204350709915161
Validation loss: 1.982312451126755

Epoch: 5| Step: 3
Training loss: 0.8419842720031738
Validation loss: 2.0057439496440272

Epoch: 5| Step: 4
Training loss: 1.2147043943405151
Validation loss: 2.0229306323553926

Epoch: 5| Step: 5
Training loss: 1.2052501440048218
Validation loss: 1.990493538559124

Epoch: 5| Step: 6
Training loss: 0.8879278302192688
Validation loss: 1.9885075015406455

Epoch: 5| Step: 7
Training loss: 1.0975837707519531
Validation loss: 2.010052691223801

Epoch: 5| Step: 8
Training loss: 1.6108694076538086
Validation loss: 1.9936620394388835

Epoch: 5| Step: 9
Training loss: 0.9477203488349915
Validation loss: 2.008019842127318

Epoch: 5| Step: 10
Training loss: 0.8342633247375488
Validation loss: 1.9609727218586912

Epoch: 768| Step: 0
Training loss: 1.3156516551971436
Validation loss: 1.9776011795125983

Epoch: 5| Step: 1
Training loss: 1.0512809753417969
Validation loss: 1.9352684341451174

Epoch: 5| Step: 2
Training loss: 1.0408855676651
Validation loss: 1.9590448666644353

Epoch: 5| Step: 3
Training loss: 1.0858519077301025
Validation loss: 1.9283662585801975

Epoch: 5| Step: 4
Training loss: 1.063796877861023
Validation loss: 1.9819469490358907

Epoch: 5| Step: 5
Training loss: 1.087325096130371
Validation loss: 1.9545803928887973

Epoch: 5| Step: 6
Training loss: 1.5060147047042847
Validation loss: 1.9153783167562177

Epoch: 5| Step: 7
Training loss: 1.5325367450714111
Validation loss: 1.9737830290230371

Epoch: 5| Step: 8
Training loss: 0.9265996217727661
Validation loss: 1.9524068409396755

Epoch: 5| Step: 9
Training loss: 0.6450319886207581
Validation loss: 1.918005484406666

Epoch: 5| Step: 10
Training loss: 0.7885918617248535
Validation loss: 1.9532359466757825

Epoch: 769| Step: 0
Training loss: 0.9161117672920227
Validation loss: 1.9452391555232387

Epoch: 5| Step: 1
Training loss: 0.7494715452194214
Validation loss: 1.9137743134652414

Epoch: 5| Step: 2
Training loss: 0.9414741396903992
Validation loss: 1.9616466824726393

Epoch: 5| Step: 3
Training loss: 1.4017561674118042
Validation loss: 1.952054844107679

Epoch: 5| Step: 4
Training loss: 0.9809222221374512
Validation loss: 1.9844911572753743

Epoch: 5| Step: 5
Training loss: 1.0401413440704346
Validation loss: 1.9690619566107308

Epoch: 5| Step: 6
Training loss: 0.838758647441864
Validation loss: 1.9432097045324181

Epoch: 5| Step: 7
Training loss: 1.2295517921447754
Validation loss: 1.9730587056888047

Epoch: 5| Step: 8
Training loss: 1.1373326778411865
Validation loss: 1.9667506999866937

Epoch: 5| Step: 9
Training loss: 1.1357669830322266
Validation loss: 1.9882749613895212

Epoch: 5| Step: 10
Training loss: 1.4961270093917847
Validation loss: 1.9346873734586982

Epoch: 770| Step: 0
Training loss: 1.1396420001983643
Validation loss: 1.985942998240071

Epoch: 5| Step: 1
Training loss: 1.1509945392608643
Validation loss: 1.9496701507158176

Epoch: 5| Step: 2
Training loss: 1.0444543361663818
Validation loss: 1.9623189869747366

Epoch: 5| Step: 3
Training loss: 1.7543280124664307
Validation loss: 1.9732334895800518

Epoch: 5| Step: 4
Training loss: 0.832110583782196
Validation loss: 1.9662240141181535

Epoch: 5| Step: 5
Training loss: 1.1413631439208984
Validation loss: 1.9550101808322373

Epoch: 5| Step: 6
Training loss: 0.6689468622207642
Validation loss: 1.9619503700605003

Epoch: 5| Step: 7
Training loss: 1.293928861618042
Validation loss: 1.9660448848560292

Epoch: 5| Step: 8
Training loss: 1.1866939067840576
Validation loss: 1.9379024377433203

Epoch: 5| Step: 9
Training loss: 0.8826783299446106
Validation loss: 1.9345511415953278

Epoch: 5| Step: 10
Training loss: 0.9990496039390564
Validation loss: 1.9377957108200237

Epoch: 771| Step: 0
Training loss: 1.2796521186828613
Validation loss: 1.8801918914241176

Epoch: 5| Step: 1
Training loss: 1.3441855907440186
Validation loss: 1.9448347630039338

Epoch: 5| Step: 2
Training loss: 0.9581226110458374
Validation loss: 1.9705287307821295

Epoch: 5| Step: 3
Training loss: 1.1577520370483398
Validation loss: 1.9283239841461182

Epoch: 5| Step: 4
Training loss: 1.280248999595642
Validation loss: 1.936740506079889

Epoch: 5| Step: 5
Training loss: 0.6697473526000977
Validation loss: 1.9474699651041338

Epoch: 5| Step: 6
Training loss: 1.2470762729644775
Validation loss: 1.9745783869938185

Epoch: 5| Step: 7
Training loss: 1.5616121292114258
Validation loss: 1.980037543081468

Epoch: 5| Step: 8
Training loss: 0.9015243649482727
Validation loss: 1.8956517660489647

Epoch: 5| Step: 9
Training loss: 0.4762977659702301
Validation loss: 1.9720940461722754

Epoch: 5| Step: 10
Training loss: 1.0560990571975708
Validation loss: 1.9819885658961471

Epoch: 772| Step: 0
Training loss: 1.3791133165359497
Validation loss: 1.9794586704623314

Epoch: 5| Step: 1
Training loss: 1.2140438556671143
Validation loss: 1.9341672671738492

Epoch: 5| Step: 2
Training loss: 1.1913936138153076
Validation loss: 1.9198591157954226

Epoch: 5| Step: 3
Training loss: 1.1926525831222534
Validation loss: 1.9648491785090456

Epoch: 5| Step: 4
Training loss: 1.6242611408233643
Validation loss: 1.987333825839463

Epoch: 5| Step: 5
Training loss: 0.6260973215103149
Validation loss: 1.926000415637929

Epoch: 5| Step: 6
Training loss: 0.7926353812217712
Validation loss: 1.9523995396911458

Epoch: 5| Step: 7
Training loss: 0.8866783380508423
Validation loss: 1.980693260828654

Epoch: 5| Step: 8
Training loss: 1.3214677572250366
Validation loss: 1.9117153921434957

Epoch: 5| Step: 9
Training loss: 0.9258154034614563
Validation loss: 1.977136330578917

Epoch: 5| Step: 10
Training loss: 0.5137065649032593
Validation loss: 1.9833936460556523

Epoch: 773| Step: 0
Training loss: 0.9973031878471375
Validation loss: 1.9532941310636458

Epoch: 5| Step: 1
Training loss: 1.196899175643921
Validation loss: 1.98539057213773

Epoch: 5| Step: 2
Training loss: 0.8169869184494019
Validation loss: 1.9406242383423673

Epoch: 5| Step: 3
Training loss: 1.0902217626571655
Validation loss: 1.9291837587151477

Epoch: 5| Step: 4
Training loss: 0.46016931533813477
Validation loss: 1.9677990841609176

Epoch: 5| Step: 5
Training loss: 1.428457260131836
Validation loss: 1.9581321170253139

Epoch: 5| Step: 6
Training loss: 1.0289967060089111
Validation loss: 1.9865171909332275

Epoch: 5| Step: 7
Training loss: 1.4624894857406616
Validation loss: 1.9386536767405849

Epoch: 5| Step: 8
Training loss: 0.8409895896911621
Validation loss: 1.9577635360020462

Epoch: 5| Step: 9
Training loss: 1.2766764163970947
Validation loss: 1.9260661653293076

Epoch: 5| Step: 10
Training loss: 1.0808056592941284
Validation loss: 2.0008479831039265

Epoch: 774| Step: 0
Training loss: 0.8283077478408813
Validation loss: 1.9773048482915407

Epoch: 5| Step: 1
Training loss: 1.1286946535110474
Validation loss: 1.9551465844595304

Epoch: 5| Step: 2
Training loss: 0.5574368238449097
Validation loss: 1.9525666159968222

Epoch: 5| Step: 3
Training loss: 1.2466367483139038
Validation loss: 1.9787337754362373

Epoch: 5| Step: 4
Training loss: 0.6212881803512573
Validation loss: 1.9673463349701257

Epoch: 5| Step: 5
Training loss: 1.101778268814087
Validation loss: 1.9879051639187721

Epoch: 5| Step: 6
Training loss: 1.43649160861969
Validation loss: 1.9664521268619004

Epoch: 5| Step: 7
Training loss: 2.0274252891540527
Validation loss: 1.9784086673490462

Epoch: 5| Step: 8
Training loss: 0.7695115208625793
Validation loss: 1.9488740621074554

Epoch: 5| Step: 9
Training loss: 1.0411961078643799
Validation loss: 1.9724894364674885

Epoch: 5| Step: 10
Training loss: 0.8595852255821228
Validation loss: 1.9747521877288818

Epoch: 775| Step: 0
Training loss: 0.9211122393608093
Validation loss: 1.9673996843317503

Epoch: 5| Step: 1
Training loss: 1.5725313425064087
Validation loss: 1.9354316662716609

Epoch: 5| Step: 2
Training loss: 1.4291032552719116
Validation loss: 1.934545822041009

Epoch: 5| Step: 3
Training loss: 1.1059801578521729
Validation loss: 1.9745981898359073

Epoch: 5| Step: 4
Training loss: 0.5545778274536133
Validation loss: 1.9686751391298027

Epoch: 5| Step: 5
Training loss: 1.047278642654419
Validation loss: 1.9564863571556665

Epoch: 5| Step: 6
Training loss: 1.0145556926727295
Validation loss: 1.941231390481354

Epoch: 5| Step: 7
Training loss: 0.6324511766433716
Validation loss: 1.9571245075553976

Epoch: 5| Step: 8
Training loss: 1.1370807886123657
Validation loss: 2.000259417359547

Epoch: 5| Step: 9
Training loss: 1.1941194534301758
Validation loss: 1.9598107837861585

Epoch: 5| Step: 10
Training loss: 1.1045198440551758
Validation loss: 1.9217301004676408

Epoch: 776| Step: 0
Training loss: 0.9122843742370605
Validation loss: 1.9556971929406608

Epoch: 5| Step: 1
Training loss: 1.115722894668579
Validation loss: 1.978829462041137

Epoch: 5| Step: 2
Training loss: 1.454097032546997
Validation loss: 1.9247898030024704

Epoch: 5| Step: 3
Training loss: 1.0494569540023804
Validation loss: 1.9660567609212731

Epoch: 5| Step: 4
Training loss: 1.2501654624938965
Validation loss: 1.990089052466936

Epoch: 5| Step: 5
Training loss: 0.897179126739502
Validation loss: 1.9684715591451174

Epoch: 5| Step: 6
Training loss: 1.0471107959747314
Validation loss: 1.9569258305334276

Epoch: 5| Step: 7
Training loss: 0.9135828018188477
Validation loss: 1.9537118711779196

Epoch: 5| Step: 8
Training loss: 0.7755239605903625
Validation loss: 1.9593076167568084

Epoch: 5| Step: 9
Training loss: 1.1635818481445312
Validation loss: 1.9520404364473076

Epoch: 5| Step: 10
Training loss: 1.068526029586792
Validation loss: 1.9466865703623781

Epoch: 777| Step: 0
Training loss: 1.0897599458694458
Validation loss: 1.9453814593694543

Epoch: 5| Step: 1
Training loss: 0.9625880122184753
Validation loss: 1.9190929435914563

Epoch: 5| Step: 2
Training loss: 1.518515944480896
Validation loss: 1.9919062404222385

Epoch: 5| Step: 3
Training loss: 0.6262593865394592
Validation loss: 1.9491327257566555

Epoch: 5| Step: 4
Training loss: 0.9945873022079468
Validation loss: 1.9581419075689008

Epoch: 5| Step: 5
Training loss: 1.3924273252487183
Validation loss: 1.9415203345719205

Epoch: 5| Step: 6
Training loss: 1.3112578392028809
Validation loss: 1.9543671281107011

Epoch: 5| Step: 7
Training loss: 0.9078456163406372
Validation loss: 1.9459272007788382

Epoch: 5| Step: 8
Training loss: 0.8925487399101257
Validation loss: 1.9172288858762352

Epoch: 5| Step: 9
Training loss: 1.1084645986557007
Validation loss: 1.956889647309498

Epoch: 5| Step: 10
Training loss: 0.9963883757591248
Validation loss: 1.962399044344502

Epoch: 778| Step: 0
Training loss: 1.156105875968933
Validation loss: 1.9537227076868857

Epoch: 5| Step: 1
Training loss: 0.8279584646224976
Validation loss: 1.9723579165756062

Epoch: 5| Step: 2
Training loss: 0.8637596964836121
Validation loss: 1.9855648779099988

Epoch: 5| Step: 3
Training loss: 1.1522386074066162
Validation loss: 1.9722434346393873

Epoch: 5| Step: 4
Training loss: 1.2925291061401367
Validation loss: 1.9421709070923507

Epoch: 5| Step: 5
Training loss: 0.9259786605834961
Validation loss: 1.9596284256186536

Epoch: 5| Step: 6
Training loss: 1.4289920330047607
Validation loss: 1.9600993151305823

Epoch: 5| Step: 7
Training loss: 0.7063322067260742
Validation loss: 1.962714159360496

Epoch: 5| Step: 8
Training loss: 1.1765108108520508
Validation loss: 1.9804478512015393

Epoch: 5| Step: 9
Training loss: 1.1420029401779175
Validation loss: 1.9538687352211244

Epoch: 5| Step: 10
Training loss: 1.0883760452270508
Validation loss: 1.9853755786854734

Epoch: 779| Step: 0
Training loss: 0.890433132648468
Validation loss: 1.984350699250416

Epoch: 5| Step: 1
Training loss: 1.1802908182144165
Validation loss: 1.9634574908082203

Epoch: 5| Step: 2
Training loss: 1.1187317371368408
Validation loss: 1.9691359842977216

Epoch: 5| Step: 3
Training loss: 1.0832000970840454
Validation loss: 1.9336679353508899

Epoch: 5| Step: 4
Training loss: 0.7809521555900574
Validation loss: 1.9658354674616167

Epoch: 5| Step: 5
Training loss: 1.4732364416122437
Validation loss: 1.9564844049433225

Epoch: 5| Step: 6
Training loss: 1.0945366621017456
Validation loss: 1.9923090152843024

Epoch: 5| Step: 7
Training loss: 0.9981427192687988
Validation loss: 1.9781041427325177

Epoch: 5| Step: 8
Training loss: 0.9679800271987915
Validation loss: 1.984896650878332

Epoch: 5| Step: 9
Training loss: 0.681663990020752
Validation loss: 1.941552326243411

Epoch: 5| Step: 10
Training loss: 1.3261940479278564
Validation loss: 1.9757948383208244

Epoch: 780| Step: 0
Training loss: 1.3069264888763428
Validation loss: 1.9475862056978288

Epoch: 5| Step: 1
Training loss: 1.0253170728683472
Validation loss: 1.9450343167910011

Epoch: 5| Step: 2
Training loss: 1.188308596611023
Validation loss: 1.9541726484093616

Epoch: 5| Step: 3
Training loss: 0.7657076120376587
Validation loss: 1.9603138674971878

Epoch: 5| Step: 4
Training loss: 0.9780213236808777
Validation loss: 1.9651202501789216

Epoch: 5| Step: 5
Training loss: 1.1478023529052734
Validation loss: 1.9419883143517278

Epoch: 5| Step: 6
Training loss: 1.3259694576263428
Validation loss: 1.9702567310743435

Epoch: 5| Step: 7
Training loss: 0.7943662405014038
Validation loss: 1.972039020189675

Epoch: 5| Step: 8
Training loss: 1.034083366394043
Validation loss: 1.9601870967495827

Epoch: 5| Step: 9
Training loss: 1.0108964443206787
Validation loss: 1.9789613216154036

Epoch: 5| Step: 10
Training loss: 1.1070809364318848
Validation loss: 1.9866017410832066

Epoch: 781| Step: 0
Training loss: 1.3804795742034912
Validation loss: 2.001303408735542

Epoch: 5| Step: 1
Training loss: 0.9217042922973633
Validation loss: 1.9923454176995061

Epoch: 5| Step: 2
Training loss: 0.8003414273262024
Validation loss: 1.973837403840916

Epoch: 5| Step: 3
Training loss: 1.5393084287643433
Validation loss: 1.9389201312936761

Epoch: 5| Step: 4
Training loss: 1.191353678703308
Validation loss: 1.954006827005776

Epoch: 5| Step: 5
Training loss: 0.956015944480896
Validation loss: 1.950641837171329

Epoch: 5| Step: 6
Training loss: 0.7059992551803589
Validation loss: 1.9550940195719402

Epoch: 5| Step: 7
Training loss: 1.0858842134475708
Validation loss: 1.9600606477388771

Epoch: 5| Step: 8
Training loss: 1.2342822551727295
Validation loss: 1.9614016843098465

Epoch: 5| Step: 9
Training loss: 0.7926304936408997
Validation loss: 1.946551110154839

Epoch: 5| Step: 10
Training loss: 0.9389591217041016
Validation loss: 1.9283152344406291

Epoch: 782| Step: 0
Training loss: 0.9360777735710144
Validation loss: 1.9756889497080157

Epoch: 5| Step: 1
Training loss: 0.9916478991508484
Validation loss: 1.9380773754530056

Epoch: 5| Step: 2
Training loss: 1.1598408222198486
Validation loss: 1.9296736460860058

Epoch: 5| Step: 3
Training loss: 1.2701609134674072
Validation loss: 1.9988200459429013

Epoch: 5| Step: 4
Training loss: 1.1033437252044678
Validation loss: 1.9287913589067356

Epoch: 5| Step: 5
Training loss: 0.968349814414978
Validation loss: 1.9535289285003499

Epoch: 5| Step: 6
Training loss: 1.2683714628219604
Validation loss: 1.9613202284741145

Epoch: 5| Step: 7
Training loss: 0.9356331825256348
Validation loss: 1.9866195981220534

Epoch: 5| Step: 8
Training loss: 1.0661582946777344
Validation loss: 1.989373194274082

Epoch: 5| Step: 9
Training loss: 1.234967589378357
Validation loss: 1.9678990379456551

Epoch: 5| Step: 10
Training loss: 1.1298176050186157
Validation loss: 1.9548836869578208

Epoch: 783| Step: 0
Training loss: 0.9135497808456421
Validation loss: 1.9695791070179274

Epoch: 5| Step: 1
Training loss: 1.0961865186691284
Validation loss: 1.9637624384254537

Epoch: 5| Step: 2
Training loss: 1.2432096004486084
Validation loss: 1.9826893883366739

Epoch: 5| Step: 3
Training loss: 1.1542551517486572
Validation loss: 1.9550058098249539

Epoch: 5| Step: 4
Training loss: 1.1258795261383057
Validation loss: 1.9689953198996923

Epoch: 5| Step: 5
Training loss: 1.102576494216919
Validation loss: 1.9362972218503234

Epoch: 5| Step: 6
Training loss: 0.7646662592887878
Validation loss: 1.9611872498707106

Epoch: 5| Step: 7
Training loss: 0.774188756942749
Validation loss: 1.9731446325138051

Epoch: 5| Step: 8
Training loss: 1.596449851989746
Validation loss: 1.9300541493200487

Epoch: 5| Step: 9
Training loss: 1.1294721364974976
Validation loss: 1.9470163365846038

Epoch: 5| Step: 10
Training loss: 0.7820566892623901
Validation loss: 1.9828916467646116

Epoch: 784| Step: 0
Training loss: 1.1859776973724365
Validation loss: 1.931489562475553

Epoch: 5| Step: 1
Training loss: 0.6801344156265259
Validation loss: 1.940782500851539

Epoch: 5| Step: 2
Training loss: 0.876529335975647
Validation loss: 1.945592802057984

Epoch: 5| Step: 3
Training loss: 1.1650502681732178
Validation loss: 1.9184767405192058

Epoch: 5| Step: 4
Training loss: 0.7225948572158813
Validation loss: 1.9276990416229411

Epoch: 5| Step: 5
Training loss: 0.730055034160614
Validation loss: 1.9708251799306562

Epoch: 5| Step: 6
Training loss: 1.0946983098983765
Validation loss: 1.9368007003620107

Epoch: 5| Step: 7
Training loss: 1.4128773212432861
Validation loss: 1.9599433752798265

Epoch: 5| Step: 8
Training loss: 1.2541439533233643
Validation loss: 1.9492048883950839

Epoch: 5| Step: 9
Training loss: 0.9226220846176147
Validation loss: 1.9223155193431403

Epoch: 5| Step: 10
Training loss: 1.6242371797561646
Validation loss: 1.9500256174354142

Epoch: 785| Step: 0
Training loss: 0.7083404064178467
Validation loss: 1.9436636496615667

Epoch: 5| Step: 1
Training loss: 1.294324517250061
Validation loss: 1.9554352375768846

Epoch: 5| Step: 2
Training loss: 1.3154385089874268
Validation loss: 1.9411438524082143

Epoch: 5| Step: 3
Training loss: 0.8505843877792358
Validation loss: 1.9474800645664174

Epoch: 5| Step: 4
Training loss: 0.8644664883613586
Validation loss: 1.9598227495788245

Epoch: 5| Step: 5
Training loss: 1.1556990146636963
Validation loss: 1.9792870911218787

Epoch: 5| Step: 6
Training loss: 1.4756826162338257
Validation loss: 1.97639678114204

Epoch: 5| Step: 7
Training loss: 0.9032966494560242
Validation loss: 1.9371278580798899

Epoch: 5| Step: 8
Training loss: 1.0996294021606445
Validation loss: 1.961069001946398

Epoch: 5| Step: 9
Training loss: 0.5469045042991638
Validation loss: 1.9422353339451615

Epoch: 5| Step: 10
Training loss: 1.1491775512695312
Validation loss: 1.955995463555859

Epoch: 786| Step: 0
Training loss: 1.4066823720932007
Validation loss: 1.9403004877028927

Epoch: 5| Step: 1
Training loss: 1.5221502780914307
Validation loss: 1.95397582105411

Epoch: 5| Step: 2
Training loss: 1.0656132698059082
Validation loss: 1.9903589807530886

Epoch: 5| Step: 3
Training loss: 1.139548659324646
Validation loss: 1.9804158133845176

Epoch: 5| Step: 4
Training loss: 1.1352641582489014
Validation loss: 1.9632490117062804

Epoch: 5| Step: 5
Training loss: 1.1309303045272827
Validation loss: 1.9718712581101285

Epoch: 5| Step: 6
Training loss: 0.9460012316703796
Validation loss: 1.9430083664514686

Epoch: 5| Step: 7
Training loss: 0.5475821495056152
Validation loss: 1.9383893154000724

Epoch: 5| Step: 8
Training loss: 0.9547807574272156
Validation loss: 1.9534114535136888

Epoch: 5| Step: 9
Training loss: 0.8739615678787231
Validation loss: 1.9622082556447675

Epoch: 5| Step: 10
Training loss: 0.6444459557533264
Validation loss: 1.9304173351615987

Epoch: 787| Step: 0
Training loss: 1.0271224975585938
Validation loss: 1.985733865409769

Epoch: 5| Step: 1
Training loss: 1.1505722999572754
Validation loss: 1.9378846742773568

Epoch: 5| Step: 2
Training loss: 1.0610079765319824
Validation loss: 1.98923965936066

Epoch: 5| Step: 3
Training loss: 0.9307162165641785
Validation loss: 1.9714666951087214

Epoch: 5| Step: 4
Training loss: 0.7628622055053711
Validation loss: 1.9162999917102117

Epoch: 5| Step: 5
Training loss: 1.4542362689971924
Validation loss: 1.9438107295702862

Epoch: 5| Step: 6
Training loss: 0.7786538004875183
Validation loss: 1.9480933322701404

Epoch: 5| Step: 7
Training loss: 1.043975591659546
Validation loss: 1.9938147452569777

Epoch: 5| Step: 8
Training loss: 1.1845462322235107
Validation loss: 1.9917603820882819

Epoch: 5| Step: 9
Training loss: 0.6807497143745422
Validation loss: 1.9345806388444797

Epoch: 5| Step: 10
Training loss: 1.3060182332992554
Validation loss: 1.9507572650909424

Epoch: 788| Step: 0
Training loss: 1.2031958103179932
Validation loss: 1.9351428554904075

Epoch: 5| Step: 1
Training loss: 1.3874564170837402
Validation loss: 1.984240931849326

Epoch: 5| Step: 2
Training loss: 0.7318354845046997
Validation loss: 1.9584270920804752

Epoch: 5| Step: 3
Training loss: 0.8523324131965637
Validation loss: 1.9314842659940001

Epoch: 5| Step: 4
Training loss: 0.858288586139679
Validation loss: 1.9652907489448466

Epoch: 5| Step: 5
Training loss: 1.1806402206420898
Validation loss: 1.9611506128823886

Epoch: 5| Step: 6
Training loss: 0.8865097165107727
Validation loss: 1.9443166614860616

Epoch: 5| Step: 7
Training loss: 0.934735119342804
Validation loss: 1.9357141410150835

Epoch: 5| Step: 8
Training loss: 1.2404234409332275
Validation loss: 1.985155737528237

Epoch: 5| Step: 9
Training loss: 0.9108247756958008
Validation loss: 1.964426504668369

Epoch: 5| Step: 10
Training loss: 1.3877344131469727
Validation loss: 1.9320463262578493

Epoch: 789| Step: 0
Training loss: 0.8088477849960327
Validation loss: 1.948492573153588

Epoch: 5| Step: 1
Training loss: 1.3752609491348267
Validation loss: 1.9580536516763831

Epoch: 5| Step: 2
Training loss: 1.4096450805664062
Validation loss: 1.9469730610488563

Epoch: 5| Step: 3
Training loss: 0.8383515477180481
Validation loss: 1.9286887978994718

Epoch: 5| Step: 4
Training loss: 0.9922224283218384
Validation loss: 1.9638345408183273

Epoch: 5| Step: 5
Training loss: 1.5378692150115967
Validation loss: 1.9006499449412029

Epoch: 5| Step: 6
Training loss: 1.2363812923431396
Validation loss: 1.9557751609433083

Epoch: 5| Step: 7
Training loss: 0.7854119539260864
Validation loss: 1.9520687441672049

Epoch: 5| Step: 8
Training loss: 1.055616021156311
Validation loss: 1.951343228740077

Epoch: 5| Step: 9
Training loss: 0.8398364186286926
Validation loss: 1.9382472320269513

Epoch: 5| Step: 10
Training loss: 0.7355490922927856
Validation loss: 1.9689198924649147

Epoch: 790| Step: 0
Training loss: 1.363105058670044
Validation loss: 1.9690188336116012

Epoch: 5| Step: 1
Training loss: 0.8533466458320618
Validation loss: 1.9275176038024247

Epoch: 5| Step: 2
Training loss: 0.8947449922561646
Validation loss: 1.9645223079189178

Epoch: 5| Step: 3
Training loss: 1.3477059602737427
Validation loss: 1.9679725836682063

Epoch: 5| Step: 4
Training loss: 1.1955615282058716
Validation loss: 1.9371723359630955

Epoch: 5| Step: 5
Training loss: 0.8935980796813965
Validation loss: 1.9378227623560096

Epoch: 5| Step: 6
Training loss: 1.4237257242202759
Validation loss: 1.9331481149119716

Epoch: 5| Step: 7
Training loss: 0.585203230381012
Validation loss: 1.9654113477276218

Epoch: 5| Step: 8
Training loss: 1.192380428314209
Validation loss: 1.9798530481194938

Epoch: 5| Step: 9
Training loss: 0.9361258745193481
Validation loss: 1.9855993127310148

Epoch: 5| Step: 10
Training loss: 1.0371488332748413
Validation loss: 2.011697320527928

Epoch: 791| Step: 0
Training loss: 0.9652225375175476
Validation loss: 1.9455589709743377

Epoch: 5| Step: 1
Training loss: 1.1626832485198975
Validation loss: 1.9327617870864047

Epoch: 5| Step: 2
Training loss: 0.9001747369766235
Validation loss: 1.9513792581455682

Epoch: 5| Step: 3
Training loss: 1.5036957263946533
Validation loss: 1.9328396333161222

Epoch: 5| Step: 4
Training loss: 1.2098870277404785
Validation loss: 2.008695335798366

Epoch: 5| Step: 5
Training loss: 1.1065396070480347
Validation loss: 1.9847118828886299

Epoch: 5| Step: 6
Training loss: 1.0737559795379639
Validation loss: 1.9816206116830148

Epoch: 5| Step: 7
Training loss: 0.6457029581069946
Validation loss: 1.911253761219722

Epoch: 5| Step: 8
Training loss: 0.863003134727478
Validation loss: 1.9835622054274364

Epoch: 5| Step: 9
Training loss: 0.9060152173042297
Validation loss: 1.940851387157235

Epoch: 5| Step: 10
Training loss: 1.1487692594528198
Validation loss: 1.9643842404888523

Epoch: 792| Step: 0
Training loss: 1.0984268188476562
Validation loss: 1.9225100778764295

Epoch: 5| Step: 1
Training loss: 0.7835473418235779
Validation loss: 1.9308206445427352

Epoch: 5| Step: 2
Training loss: 0.722191333770752
Validation loss: 1.9471021595821585

Epoch: 5| Step: 3
Training loss: 1.3043893575668335
Validation loss: 1.9312991634491952

Epoch: 5| Step: 4
Training loss: 1.29933762550354
Validation loss: 1.9184487993999193

Epoch: 5| Step: 5
Training loss: 1.2728712558746338
Validation loss: 1.9744436305056337

Epoch: 5| Step: 6
Training loss: 1.1391183137893677
Validation loss: 1.923988239739531

Epoch: 5| Step: 7
Training loss: 0.8805228471755981
Validation loss: 1.9115517216344033

Epoch: 5| Step: 8
Training loss: 1.3344390392303467
Validation loss: 1.9356577960393762

Epoch: 5| Step: 9
Training loss: 0.8311594128608704
Validation loss: 1.9456190870654198

Epoch: 5| Step: 10
Training loss: 1.0801180601119995
Validation loss: 1.93128792829411

Epoch: 793| Step: 0
Training loss: 1.0458693504333496
Validation loss: 1.9482888944687382

Epoch: 5| Step: 1
Training loss: 0.8719528317451477
Validation loss: 1.9876164890104724

Epoch: 5| Step: 2
Training loss: 1.449136734008789
Validation loss: 1.9644793361745856

Epoch: 5| Step: 3
Training loss: 0.8843225240707397
Validation loss: 1.9502325980894026

Epoch: 5| Step: 4
Training loss: 0.8358854055404663
Validation loss: 1.9937966972269037

Epoch: 5| Step: 5
Training loss: 0.9933854341506958
Validation loss: 2.0002203500399025

Epoch: 5| Step: 6
Training loss: 1.4116462469100952
Validation loss: 1.9460485981356712

Epoch: 5| Step: 7
Training loss: 1.1059657335281372
Validation loss: 1.9640322218659103

Epoch: 5| Step: 8
Training loss: 0.859294056892395
Validation loss: 1.9424112099473194

Epoch: 5| Step: 9
Training loss: 0.9815120697021484
Validation loss: 1.9134388380153204

Epoch: 5| Step: 10
Training loss: 0.6598166823387146
Validation loss: 1.989372730255127

Epoch: 794| Step: 0
Training loss: 1.2242319583892822
Validation loss: 1.9672753016153972

Epoch: 5| Step: 1
Training loss: 0.915187656879425
Validation loss: 1.9348020707407305

Epoch: 5| Step: 2
Training loss: 0.8275191187858582
Validation loss: 1.9806670296576716

Epoch: 5| Step: 3
Training loss: 0.9641563296318054
Validation loss: 1.9258650009350111

Epoch: 5| Step: 4
Training loss: 1.0017268657684326
Validation loss: 1.9428147654379568

Epoch: 5| Step: 5
Training loss: 0.6585443019866943
Validation loss: 1.925788438448342

Epoch: 5| Step: 6
Training loss: 1.7547733783721924
Validation loss: 1.9345683179875857

Epoch: 5| Step: 7
Training loss: 0.8110804557800293
Validation loss: 1.9406301988068448

Epoch: 5| Step: 8
Training loss: 0.9539891481399536
Validation loss: 1.965193833074262

Epoch: 5| Step: 9
Training loss: 1.2851625680923462
Validation loss: 1.9327774996398597

Epoch: 5| Step: 10
Training loss: 1.0976521968841553
Validation loss: 1.9907120440595893

Epoch: 795| Step: 0
Training loss: 1.0602482557296753
Validation loss: 1.9391268299471947

Epoch: 5| Step: 1
Training loss: 0.8849112391471863
Validation loss: 1.9626344096276067

Epoch: 5| Step: 2
Training loss: 1.0045865774154663
Validation loss: 1.9520000744891424

Epoch: 5| Step: 3
Training loss: 1.0617311000823975
Validation loss: 1.9482501732405795

Epoch: 5| Step: 4
Training loss: 1.762197732925415
Validation loss: 1.954850918503218

Epoch: 5| Step: 5
Training loss: 1.3117589950561523
Validation loss: 1.9640644135013703

Epoch: 5| Step: 6
Training loss: 0.6280256509780884
Validation loss: 1.9254364672527517

Epoch: 5| Step: 7
Training loss: 1.0097471475601196
Validation loss: 1.9972580940492692

Epoch: 5| Step: 8
Training loss: 1.1879189014434814
Validation loss: 1.9561188502978253

Epoch: 5| Step: 9
Training loss: 0.7886382341384888
Validation loss: 1.92447006317877

Epoch: 5| Step: 10
Training loss: 0.7491502165794373
Validation loss: 1.96042590243842

Epoch: 796| Step: 0
Training loss: 1.3088047504425049
Validation loss: 1.965847816518558

Epoch: 5| Step: 1
Training loss: 0.8442511558532715
Validation loss: 2.0034156589097876

Epoch: 5| Step: 2
Training loss: 0.781859278678894
Validation loss: 1.9341032107671101

Epoch: 5| Step: 3
Training loss: 1.0366089344024658
Validation loss: 1.9679741000616422

Epoch: 5| Step: 4
Training loss: 0.8552872538566589
Validation loss: 1.9368651707967122

Epoch: 5| Step: 5
Training loss: 1.0263407230377197
Validation loss: 1.933614711607656

Epoch: 5| Step: 6
Training loss: 1.3336660861968994
Validation loss: 1.9414455166427038

Epoch: 5| Step: 7
Training loss: 1.2180391550064087
Validation loss: 2.008829632113057

Epoch: 5| Step: 8
Training loss: 0.9339171648025513
Validation loss: 1.9568612857531476

Epoch: 5| Step: 9
Training loss: 0.9853469133377075
Validation loss: 1.9605428839242587

Epoch: 5| Step: 10
Training loss: 1.1152198314666748
Validation loss: 1.945002717356528

Epoch: 797| Step: 0
Training loss: 1.5029487609863281
Validation loss: 1.9953341419978807

Epoch: 5| Step: 1
Training loss: 1.1449551582336426
Validation loss: 1.9508633011130876

Epoch: 5| Step: 2
Training loss: 1.4441801309585571
Validation loss: 1.9671624424637004

Epoch: 5| Step: 3
Training loss: 0.8962454795837402
Validation loss: 1.9629670279000395

Epoch: 5| Step: 4
Training loss: 0.9269199371337891
Validation loss: 1.906833903763884

Epoch: 5| Step: 5
Training loss: 0.6946821212768555
Validation loss: 1.9372244406771917

Epoch: 5| Step: 6
Training loss: 1.1347626447677612
Validation loss: 1.9700164589830624

Epoch: 5| Step: 7
Training loss: 1.001268982887268
Validation loss: 1.9299574795589651

Epoch: 5| Step: 8
Training loss: 1.064819574356079
Validation loss: 1.9677230363251061

Epoch: 5| Step: 9
Training loss: 0.8869917988777161
Validation loss: 1.9288538963563981

Epoch: 5| Step: 10
Training loss: 0.6821612119674683
Validation loss: 1.9342119591210478

Epoch: 798| Step: 0
Training loss: 1.550098180770874
Validation loss: 1.9438517619204778

Epoch: 5| Step: 1
Training loss: 1.185328483581543
Validation loss: 1.949698046971393

Epoch: 5| Step: 2
Training loss: 0.61643385887146
Validation loss: 1.9538464751294864

Epoch: 5| Step: 3
Training loss: 1.0321872234344482
Validation loss: 1.9540044902473368

Epoch: 5| Step: 4
Training loss: 1.0689257383346558
Validation loss: 1.9232429663340251

Epoch: 5| Step: 5
Training loss: 0.8446653485298157
Validation loss: 1.9404365119113718

Epoch: 5| Step: 6
Training loss: 1.2084797620773315
Validation loss: 1.9650292755455099

Epoch: 5| Step: 7
Training loss: 0.5128450989723206
Validation loss: 1.968099614625336

Epoch: 5| Step: 8
Training loss: 1.297852873802185
Validation loss: 1.9175357869876328

Epoch: 5| Step: 9
Training loss: 1.0938507318496704
Validation loss: 1.9268923203150432

Epoch: 5| Step: 10
Training loss: 0.8416768312454224
Validation loss: 2.0004587096552693

Epoch: 799| Step: 0
Training loss: 1.1052260398864746
Validation loss: 1.9744961338658487

Epoch: 5| Step: 1
Training loss: 1.3785581588745117
Validation loss: 1.9417673733926588

Epoch: 5| Step: 2
Training loss: 0.7899690270423889
Validation loss: 1.9998405184797061

Epoch: 5| Step: 3
Training loss: 1.2437212467193604
Validation loss: 1.9949869904466855

Epoch: 5| Step: 4
Training loss: 0.9081088900566101
Validation loss: 1.990148821184712

Epoch: 5| Step: 5
Training loss: 1.7590105533599854
Validation loss: 1.9605955000846618

Epoch: 5| Step: 6
Training loss: 0.7649127244949341
Validation loss: 2.0021070113746067

Epoch: 5| Step: 7
Training loss: 1.0790327787399292
Validation loss: 1.9962963609285251

Epoch: 5| Step: 8
Training loss: 0.8553152084350586
Validation loss: 1.9809624430953816

Epoch: 5| Step: 9
Training loss: 0.75546795129776
Validation loss: 1.939780403208989

Epoch: 5| Step: 10
Training loss: 0.7892897725105286
Validation loss: 1.9772652695255895

Epoch: 800| Step: 0
Training loss: 1.1434311866760254
Validation loss: 1.9258487788579797

Epoch: 5| Step: 1
Training loss: 1.417596697807312
Validation loss: 1.9461237820245887

Epoch: 5| Step: 2
Training loss: 1.2933753728866577
Validation loss: 1.9162377567701443

Epoch: 5| Step: 3
Training loss: 0.7211945652961731
Validation loss: 1.9601026760634555

Epoch: 5| Step: 4
Training loss: 1.0290472507476807
Validation loss: 1.9671018033899286

Epoch: 5| Step: 5
Training loss: 1.0861330032348633
Validation loss: 1.9278890279031569

Epoch: 5| Step: 6
Training loss: 1.0642935037612915
Validation loss: 1.941451136783887

Epoch: 5| Step: 7
Training loss: 1.0578663349151611
Validation loss: 1.9399464732857161

Epoch: 5| Step: 8
Training loss: 1.0998780727386475
Validation loss: 1.9370648450748895

Epoch: 5| Step: 9
Training loss: 1.1857731342315674
Validation loss: 1.9441308616310038

Epoch: 5| Step: 10
Training loss: 0.6586475372314453
Validation loss: 1.9602150147961033

Testing loss: 2.1248848305808172
