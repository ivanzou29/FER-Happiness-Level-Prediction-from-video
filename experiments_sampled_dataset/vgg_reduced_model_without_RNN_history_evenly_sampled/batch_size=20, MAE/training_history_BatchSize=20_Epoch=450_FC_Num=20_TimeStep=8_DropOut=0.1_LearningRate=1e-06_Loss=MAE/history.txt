Epoch: 1| Step: 0
Training loss: 5.145267009735107
Validation loss: 6.360955125542097

Epoch: 5| Step: 1
Training loss: 6.286814212799072
Validation loss: 6.358787270002468

Epoch: 5| Step: 2
Training loss: 6.326506614685059
Validation loss: 6.35263374287595

Epoch: 5| Step: 3
Training loss: 6.978495121002197
Validation loss: 6.349111839007306

Epoch: 5| Step: 4
Training loss: 6.409388542175293
Validation loss: 6.342244758400866

Epoch: 5| Step: 5
Training loss: 5.850628852844238
Validation loss: 6.337780162852297

Epoch: 5| Step: 6
Training loss: 5.559670448303223
Validation loss: 6.333897708564677

Epoch: 5| Step: 7
Training loss: 7.080348014831543
Validation loss: 6.3316576557774695

Epoch: 5| Step: 8
Training loss: 6.3443193435668945
Validation loss: 6.32601983060119

Epoch: 5| Step: 9
Training loss: 6.41769552230835
Validation loss: 6.321996765751993

Epoch: 5| Step: 10
Training loss: 4.908172130584717
Validation loss: 6.3164837027108796

Epoch: 2| Step: 0
Training loss: 6.910119533538818
Validation loss: 6.315045464423395

Epoch: 5| Step: 1
Training loss: 6.014458656311035
Validation loss: 6.308508544839839

Epoch: 5| Step: 2
Training loss: 5.60854434967041
Validation loss: 6.306423171874015

Epoch: 5| Step: 3
Training loss: 6.1715898513793945
Validation loss: 6.303026922287479

Epoch: 5| Step: 4
Training loss: 5.0699076652526855
Validation loss: 6.294859004277055

Epoch: 5| Step: 5
Training loss: 6.816622257232666
Validation loss: 6.291260355262346

Epoch: 5| Step: 6
Training loss: 6.94326639175415
Validation loss: 6.286720429697344

Epoch: 5| Step: 7
Training loss: 5.15024471282959
Validation loss: 6.283408088068808

Epoch: 5| Step: 8
Training loss: 6.391551494598389
Validation loss: 6.277060406182402

Epoch: 5| Step: 9
Training loss: 6.031556129455566
Validation loss: 6.27376655865741

Epoch: 5| Step: 10
Training loss: 5.758066177368164
Validation loss: 6.271536945014872

Epoch: 3| Step: 0
Training loss: 7.037282466888428
Validation loss: 6.266155612084173

Epoch: 5| Step: 1
Training loss: 6.556284427642822
Validation loss: 6.262138064189624

Epoch: 5| Step: 2
Training loss: 5.691305160522461
Validation loss: 6.258790739120975

Epoch: 5| Step: 3
Training loss: 6.7576141357421875
Validation loss: 6.253919637331399

Epoch: 5| Step: 4
Training loss: 5.94171142578125
Validation loss: 6.247532875307145

Epoch: 5| Step: 5
Training loss: 6.925345420837402
Validation loss: 6.2461816367282665

Epoch: 5| Step: 6
Training loss: 6.270216941833496
Validation loss: 6.24163854763072

Epoch: 5| Step: 7
Training loss: 4.981020927429199
Validation loss: 6.238085341709916

Epoch: 5| Step: 8
Training loss: 5.397688865661621
Validation loss: 6.229649148961549

Epoch: 5| Step: 9
Training loss: 5.130592346191406
Validation loss: 6.224287068972024

Epoch: 5| Step: 10
Training loss: 5.633388042449951
Validation loss: 6.22291592115997

Epoch: 4| Step: 0
Training loss: 6.26477575302124
Validation loss: 6.215199583320207

Epoch: 5| Step: 1
Training loss: 6.6334638595581055
Validation loss: 6.213112190205564

Epoch: 5| Step: 2
Training loss: 7.0916032791137695
Validation loss: 6.208588548885879

Epoch: 5| Step: 3
Training loss: 5.376542091369629
Validation loss: 6.201204212762976

Epoch: 5| Step: 4
Training loss: 6.623751163482666
Validation loss: 6.196166176949778

Epoch: 5| Step: 5
Training loss: 5.052494049072266
Validation loss: 6.189634230829054

Epoch: 5| Step: 6
Training loss: 5.2880635261535645
Validation loss: 6.186082578474475

Epoch: 5| Step: 7
Training loss: 6.559795379638672
Validation loss: 6.177032316884687

Epoch: 5| Step: 8
Training loss: 5.616368293762207
Validation loss: 6.17351944215836

Epoch: 5| Step: 9
Training loss: 5.765475273132324
Validation loss: 6.168630984521681

Epoch: 5| Step: 10
Training loss: 5.439746379852295
Validation loss: 6.162305421726678

Epoch: 5| Step: 0
Training loss: 6.237170219421387
Validation loss: 6.1589998327275755

Epoch: 5| Step: 1
Training loss: 5.370166778564453
Validation loss: 6.150981641584827

Epoch: 5| Step: 2
Training loss: 5.815222263336182
Validation loss: 6.148068253711988

Epoch: 5| Step: 3
Training loss: 6.8733320236206055
Validation loss: 6.137124861440351

Epoch: 5| Step: 4
Training loss: 6.290537357330322
Validation loss: 6.130885267770418

Epoch: 5| Step: 5
Training loss: 6.731759071350098
Validation loss: 6.128846527427755

Epoch: 5| Step: 6
Training loss: 6.245082855224609
Validation loss: 6.124608121892457

Epoch: 5| Step: 7
Training loss: 6.6390204429626465
Validation loss: 6.115532039314188

Epoch: 5| Step: 8
Training loss: 5.258519172668457
Validation loss: 6.111089973039524

Epoch: 5| Step: 9
Training loss: 3.957639217376709
Validation loss: 6.099478998491841

Epoch: 5| Step: 10
Training loss: 5.593009948730469
Validation loss: 6.09109696521554

Epoch: 6| Step: 0
Training loss: 5.125943183898926
Validation loss: 6.087362402228899

Epoch: 5| Step: 1
Training loss: 5.57516622543335
Validation loss: 6.076719653221868

Epoch: 5| Step: 2
Training loss: 5.875535011291504
Validation loss: 6.074733549548734

Epoch: 5| Step: 3
Training loss: 6.189463138580322
Validation loss: 6.06724194557436

Epoch: 5| Step: 4
Training loss: 6.7193427085876465
Validation loss: 6.06025150258054

Epoch: 5| Step: 5
Training loss: 4.954698085784912
Validation loss: 6.050625114030735

Epoch: 5| Step: 6
Training loss: 4.948174953460693
Validation loss: 6.039318694863268

Epoch: 5| Step: 7
Training loss: 5.9487128257751465
Validation loss: 6.038226143006356

Epoch: 5| Step: 8
Training loss: 7.682053565979004
Validation loss: 6.028826487961636

Epoch: 5| Step: 9
Training loss: 6.0272536277771
Validation loss: 6.021764170738958

Epoch: 5| Step: 10
Training loss: 5.05028772354126
Validation loss: 6.011410861886958

Epoch: 7| Step: 0
Training loss: 5.345410346984863
Validation loss: 6.004470835449875

Epoch: 5| Step: 1
Training loss: 5.8890204429626465
Validation loss: 6.002218384896556

Epoch: 5| Step: 2
Training loss: 6.400949954986572
Validation loss: 5.994083799341674

Epoch: 5| Step: 3
Training loss: 6.362748622894287
Validation loss: 5.985741123076408

Epoch: 5| Step: 4
Training loss: 7.02683162689209
Validation loss: 5.97517761107414

Epoch: 5| Step: 5
Training loss: 5.469210624694824
Validation loss: 5.9691418165801675

Epoch: 5| Step: 6
Training loss: 4.662881374359131
Validation loss: 5.958215252045663

Epoch: 5| Step: 7
Training loss: 5.438580513000488
Validation loss: 5.951949442586591

Epoch: 5| Step: 8
Training loss: 5.617405891418457
Validation loss: 5.9436967193439445

Epoch: 5| Step: 9
Training loss: 5.125216007232666
Validation loss: 5.93991776435606

Epoch: 5| Step: 10
Training loss: 5.9622392654418945
Validation loss: 5.93072570267544

Epoch: 8| Step: 0
Training loss: 5.419350624084473
Validation loss: 5.917026627448298

Epoch: 5| Step: 1
Training loss: 5.717173099517822
Validation loss: 5.9149826982969875

Epoch: 5| Step: 2
Training loss: 5.10982608795166
Validation loss: 5.90253823290589

Epoch: 5| Step: 3
Training loss: 5.133639335632324
Validation loss: 5.896617145948513

Epoch: 5| Step: 4
Training loss: 5.959141254425049
Validation loss: 5.8879457186627135

Epoch: 5| Step: 5
Training loss: 4.429142475128174
Validation loss: 5.8745324022026475

Epoch: 5| Step: 6
Training loss: 4.72959041595459
Validation loss: 5.869412042761362

Epoch: 5| Step: 7
Training loss: 5.921898365020752
Validation loss: 5.8589733390397924

Epoch: 5| Step: 8
Training loss: 6.529285430908203
Validation loss: 5.85094686221051

Epoch: 5| Step: 9
Training loss: 6.570452690124512
Validation loss: 5.835548554697344

Epoch: 5| Step: 10
Training loss: 6.889149188995361
Validation loss: 5.829730961912421

Epoch: 9| Step: 0
Training loss: 5.512368202209473
Validation loss: 5.823948685840894

Epoch: 5| Step: 1
Training loss: 5.540560722351074
Validation loss: 5.813938920215894

Epoch: 5| Step: 2
Training loss: 6.334226131439209
Validation loss: 5.807573180044851

Epoch: 5| Step: 3
Training loss: 5.754866600036621
Validation loss: 5.792080997138895

Epoch: 5| Step: 4
Training loss: 5.6279120445251465
Validation loss: 5.785377292222874

Epoch: 5| Step: 5
Training loss: 6.113412857055664
Validation loss: 5.776872327250819

Epoch: 5| Step: 6
Training loss: 5.248106002807617
Validation loss: 5.765572701731036

Epoch: 5| Step: 7
Training loss: 6.199350357055664
Validation loss: 5.763929782375213

Epoch: 5| Step: 8
Training loss: 5.258913040161133
Validation loss: 5.743209274866247

Epoch: 5| Step: 9
Training loss: 5.058864593505859
Validation loss: 5.735269197853663

Epoch: 5| Step: 10
Training loss: 4.247570991516113
Validation loss: 5.7287345752921155

Epoch: 10| Step: 0
Training loss: 5.197286128997803
Validation loss: 5.711249279719527

Epoch: 5| Step: 1
Training loss: 6.073189735412598
Validation loss: 5.707313732434344

Epoch: 5| Step: 2
Training loss: 5.293275833129883
Validation loss: 5.693626198717343

Epoch: 5| Step: 3
Training loss: 5.118091106414795
Validation loss: 5.684704139668455

Epoch: 5| Step: 4
Training loss: 5.318996906280518
Validation loss: 5.673979728452621

Epoch: 5| Step: 5
Training loss: 5.131543159484863
Validation loss: 5.664322135269001

Epoch: 5| Step: 6
Training loss: 4.9092302322387695
Validation loss: 5.651119468032673

Epoch: 5| Step: 7
Training loss: 5.048211097717285
Validation loss: 5.6380190951849825

Epoch: 5| Step: 8
Training loss: 6.694783687591553
Validation loss: 5.63083283106486

Epoch: 5| Step: 9
Training loss: 4.576599597930908
Validation loss: 5.620362266417472

Epoch: 5| Step: 10
Training loss: 6.639435768127441
Validation loss: 5.608997473152735

Epoch: 11| Step: 0
Training loss: 5.9051737785339355
Validation loss: 5.5932106048830095

Epoch: 5| Step: 1
Training loss: 4.860288619995117
Validation loss: 5.581239623408163

Epoch: 5| Step: 2
Training loss: 3.501796007156372
Validation loss: 5.573979552074145

Epoch: 5| Step: 3
Training loss: 6.505807399749756
Validation loss: 5.563737920535508

Epoch: 5| Step: 4
Training loss: 5.387848854064941
Validation loss: 5.5493461034631215

Epoch: 5| Step: 5
Training loss: 5.521425724029541
Validation loss: 5.536765877918531

Epoch: 5| Step: 6
Training loss: 6.411004543304443
Validation loss: 5.52547073876986

Epoch: 5| Step: 7
Training loss: 4.15976095199585
Validation loss: 5.513186946991952

Epoch: 5| Step: 8
Training loss: 5.222677707672119
Validation loss: 5.494090290479763

Epoch: 5| Step: 9
Training loss: 5.942313194274902
Validation loss: 5.483083155847365

Epoch: 5| Step: 10
Training loss: 4.881927967071533
Validation loss: 5.465668903884067

Epoch: 12| Step: 0
Training loss: 6.292559623718262
Validation loss: 5.461198883671915

Epoch: 5| Step: 1
Training loss: 5.069261074066162
Validation loss: 5.440603322880243

Epoch: 5| Step: 2
Training loss: 5.691165924072266
Validation loss: 5.427164698159823

Epoch: 5| Step: 3
Training loss: 3.807508945465088
Validation loss: 5.413289505948303

Epoch: 5| Step: 4
Training loss: 5.525485992431641
Validation loss: 5.399096201824886

Epoch: 5| Step: 5
Training loss: 4.067257881164551
Validation loss: 5.387103301222607

Epoch: 5| Step: 6
Training loss: 5.797595977783203
Validation loss: 5.371491262989659

Epoch: 5| Step: 7
Training loss: 4.875906467437744
Validation loss: 5.358674126286661

Epoch: 5| Step: 8
Training loss: 5.389662742614746
Validation loss: 5.339436459284957

Epoch: 5| Step: 9
Training loss: 5.951976776123047
Validation loss: 5.324708354088568

Epoch: 5| Step: 10
Training loss: 3.9647293090820312
Validation loss: 5.309309969666184

Epoch: 13| Step: 0
Training loss: 4.482382297515869
Validation loss: 5.289150981492893

Epoch: 5| Step: 1
Training loss: 4.857417583465576
Validation loss: 5.268145212563136

Epoch: 5| Step: 2
Training loss: 5.652529716491699
Validation loss: 5.267651870686521

Epoch: 5| Step: 3
Training loss: 4.033689022064209
Validation loss: 5.245515925909883

Epoch: 5| Step: 4
Training loss: 5.616879940032959
Validation loss: 5.231767485218663

Epoch: 5| Step: 5
Training loss: 5.6028900146484375
Validation loss: 5.2125089142912175

Epoch: 5| Step: 6
Training loss: 5.332723140716553
Validation loss: 5.193733810096659

Epoch: 5| Step: 7
Training loss: 5.809976100921631
Validation loss: 5.16841798187584

Epoch: 5| Step: 8
Training loss: 4.697863578796387
Validation loss: 5.1594844582260295

Epoch: 5| Step: 9
Training loss: 4.0345354080200195
Validation loss: 5.140925730428388

Epoch: 5| Step: 10
Training loss: 4.453908443450928
Validation loss: 5.1268231894380305

Epoch: 14| Step: 0
Training loss: 4.97083044052124
Validation loss: 5.099221434644473

Epoch: 5| Step: 1
Training loss: 4.324734210968018
Validation loss: 5.081366487728652

Epoch: 5| Step: 2
Training loss: 4.151418209075928
Validation loss: 5.0594642444323465

Epoch: 5| Step: 3
Training loss: 4.645042896270752
Validation loss: 5.037833603479529

Epoch: 5| Step: 4
Training loss: 4.732569694519043
Validation loss: 5.034155527750651

Epoch: 5| Step: 5
Training loss: 5.132184028625488
Validation loss: 5.008284835405247

Epoch: 5| Step: 6
Training loss: 5.043633460998535
Validation loss: 4.987417454360633

Epoch: 5| Step: 7
Training loss: 5.8748650550842285
Validation loss: 4.966296744602983

Epoch: 5| Step: 8
Training loss: 4.798399448394775
Validation loss: 4.934149752381027

Epoch: 5| Step: 9
Training loss: 5.255256652832031
Validation loss: 4.917877812539378

Epoch: 5| Step: 10
Training loss: 3.2315518856048584
Validation loss: 4.913426194139706

Epoch: 15| Step: 0
Training loss: 4.560312271118164
Validation loss: 4.881018577083465

Epoch: 5| Step: 1
Training loss: 4.463196754455566
Validation loss: 4.857338889952628

Epoch: 5| Step: 2
Training loss: 5.031111240386963
Validation loss: 4.84201370772495

Epoch: 5| Step: 3
Training loss: 4.4815192222595215
Validation loss: 4.806893220511816

Epoch: 5| Step: 4
Training loss: 3.9483635425567627
Validation loss: 4.798647552408198

Epoch: 5| Step: 5
Training loss: 4.024568557739258
Validation loss: 4.765131037722352

Epoch: 5| Step: 6
Training loss: 3.5077927112579346
Validation loss: 4.743365821018014

Epoch: 5| Step: 7
Training loss: 4.474636077880859
Validation loss: 4.711204828754548

Epoch: 5| Step: 8
Training loss: 4.817435264587402
Validation loss: 4.70319785353958

Epoch: 5| Step: 9
Training loss: 5.525111675262451
Validation loss: 4.682707571214245

Epoch: 5| Step: 10
Training loss: 5.16083288192749
Validation loss: 4.6512431380569295

Epoch: 16| Step: 0
Training loss: 3.690046787261963
Validation loss: 4.636566323618735

Epoch: 5| Step: 1
Training loss: 4.2736639976501465
Validation loss: 4.601887590141707

Epoch: 5| Step: 2
Training loss: 3.934535264968872
Validation loss: 4.5874872156368784

Epoch: 5| Step: 3
Training loss: 5.067203998565674
Validation loss: 4.546409601806312

Epoch: 5| Step: 4
Training loss: 4.425387382507324
Validation loss: 4.543410913918608

Epoch: 5| Step: 5
Training loss: 4.206725597381592
Validation loss: 4.523869352955972

Epoch: 5| Step: 6
Training loss: 5.536962032318115
Validation loss: 4.4914594209322365

Epoch: 5| Step: 7
Training loss: 4.828670024871826
Validation loss: 4.466610677780643

Epoch: 5| Step: 8
Training loss: 2.756190776824951
Validation loss: 4.44750286943169

Epoch: 5| Step: 9
Training loss: 3.918996810913086
Validation loss: 4.409541899158109

Epoch: 5| Step: 10
Training loss: 4.485291004180908
Validation loss: 4.399852050248013

Epoch: 17| Step: 0
Training loss: 4.0298285484313965
Validation loss: 4.368462285687847

Epoch: 5| Step: 1
Training loss: 3.7044951915740967
Validation loss: 4.352329818151331

Epoch: 5| Step: 2
Training loss: 5.1782684326171875
Validation loss: 4.321544995871923

Epoch: 5| Step: 3
Training loss: 4.905461311340332
Validation loss: 4.2944784933520905

Epoch: 5| Step: 4
Training loss: 3.116476535797119
Validation loss: 4.263777740540043

Epoch: 5| Step: 5
Training loss: 4.124627590179443
Validation loss: 4.245051507026918

Epoch: 5| Step: 6
Training loss: 3.423276901245117
Validation loss: 4.216941638659406

Epoch: 5| Step: 7
Training loss: 5.0375494956970215
Validation loss: 4.184713389283868

Epoch: 5| Step: 8
Training loss: 3.3045172691345215
Validation loss: 4.1660851816977225

Epoch: 5| Step: 9
Training loss: 3.2148234844207764
Validation loss: 4.1432969493250695

Epoch: 5| Step: 10
Training loss: 4.315606594085693
Validation loss: 4.110973040262858

Epoch: 18| Step: 0
Training loss: 3.258057117462158
Validation loss: 4.111872185942947

Epoch: 5| Step: 1
Training loss: 4.5394439697265625
Validation loss: 4.071157250353085

Epoch: 5| Step: 2
Training loss: 3.5247790813446045
Validation loss: 4.026664821050501

Epoch: 5| Step: 3
Training loss: 4.377425670623779
Validation loss: 4.023348762143042

Epoch: 5| Step: 4
Training loss: 4.134670734405518
Validation loss: 4.006309334949781

Epoch: 5| Step: 5
Training loss: 3.0300440788269043
Validation loss: 3.957680389445315

Epoch: 5| Step: 6
Training loss: 3.056941270828247
Validation loss: 3.9261659550410446

Epoch: 5| Step: 7
Training loss: 4.083081245422363
Validation loss: 3.9163191164693525

Epoch: 5| Step: 8
Training loss: 3.710906505584717
Validation loss: 3.877105943618282

Epoch: 5| Step: 9
Training loss: 4.274547576904297
Validation loss: 3.8802183033317648

Epoch: 5| Step: 10
Training loss: 3.85233211517334
Validation loss: 3.837914461730629

Epoch: 19| Step: 0
Training loss: 3.6432621479034424
Validation loss: 3.8121593947051675

Epoch: 5| Step: 1
Training loss: 4.616342067718506
Validation loss: 3.799436592286633

Epoch: 5| Step: 2
Training loss: 3.816417694091797
Validation loss: 3.773310645934074

Epoch: 5| Step: 3
Training loss: 5.138890743255615
Validation loss: 3.7587276838159047

Epoch: 5| Step: 4
Training loss: 3.4976539611816406
Validation loss: 3.723067945049655

Epoch: 5| Step: 5
Training loss: 2.901705503463745
Validation loss: 3.702321344806302

Epoch: 5| Step: 6
Training loss: 2.981977701187134
Validation loss: 3.6690810726534937

Epoch: 5| Step: 7
Training loss: 3.171046018600464
Validation loss: 3.663968188788301

Epoch: 5| Step: 8
Training loss: 2.4919118881225586
Validation loss: 3.6176325992871354

Epoch: 5| Step: 9
Training loss: 3.7886359691619873
Validation loss: 3.6143348114464873

Epoch: 5| Step: 10
Training loss: 3.3347315788269043
Validation loss: 3.5683155623815392

Epoch: 20| Step: 0
Training loss: 4.008805751800537
Validation loss: 3.55107795294895

Epoch: 5| Step: 1
Training loss: 3.544440507888794
Validation loss: 3.53669394985322

Epoch: 5| Step: 2
Training loss: 3.3061294555664062
Validation loss: 3.5172853931303947

Epoch: 5| Step: 3
Training loss: 3.667552947998047
Validation loss: 3.489933144661688

Epoch: 5| Step: 4
Training loss: 2.370098352432251
Validation loss: 3.4604824819872455

Epoch: 5| Step: 5
Training loss: 2.7929282188415527
Validation loss: 3.4158109388043805

Epoch: 5| Step: 6
Training loss: 2.695788860321045
Validation loss: 3.413678753760553

Epoch: 5| Step: 7
Training loss: 3.928166151046753
Validation loss: 3.385495526816255

Epoch: 5| Step: 8
Training loss: 3.2740612030029297
Validation loss: 3.380951322535033

Epoch: 5| Step: 9
Training loss: 3.625614881515503
Validation loss: 3.3451260187292613

Epoch: 5| Step: 10
Training loss: 3.8363728523254395
Validation loss: 3.306435597840176

Epoch: 21| Step: 0
Training loss: 2.9015865325927734
Validation loss: 3.303459326426188

Epoch: 5| Step: 1
Training loss: 3.2435379028320312
Validation loss: 3.290601671382945

Epoch: 5| Step: 2
Training loss: 3.3100457191467285
Validation loss: 3.2579005533649075

Epoch: 5| Step: 3
Training loss: 3.219015598297119
Validation loss: 3.236272327361568

Epoch: 5| Step: 4
Training loss: 2.9455058574676514
Validation loss: 3.2039958559056765

Epoch: 5| Step: 5
Training loss: 2.672740936279297
Validation loss: 3.2078216101533625

Epoch: 5| Step: 6
Training loss: 3.1581668853759766
Validation loss: 3.165618681138562

Epoch: 5| Step: 7
Training loss: 3.0177910327911377
Validation loss: 3.1416312033130276

Epoch: 5| Step: 8
Training loss: 3.756859302520752
Validation loss: 3.1132918762904342

Epoch: 5| Step: 9
Training loss: 3.040067672729492
Validation loss: 3.0776544796523226

Epoch: 5| Step: 10
Training loss: 3.816352367401123
Validation loss: 3.056005157450194

Epoch: 22| Step: 0
Training loss: 2.718275547027588
Validation loss: 3.0820362875538487

Epoch: 5| Step: 1
Training loss: 1.9780813455581665
Validation loss: 3.0500559268459195

Epoch: 5| Step: 2
Training loss: 3.632711887359619
Validation loss: 3.005789272246822

Epoch: 5| Step: 3
Training loss: 3.102959394454956
Validation loss: 2.9877230557062293

Epoch: 5| Step: 4
Training loss: 3.0555179119110107
Validation loss: 2.960761723979827

Epoch: 5| Step: 5
Training loss: 3.471850633621216
Validation loss: 2.9595461019905667

Epoch: 5| Step: 6
Training loss: 3.2001235485076904
Validation loss: 2.907495226911319

Epoch: 5| Step: 7
Training loss: 2.639850616455078
Validation loss: 2.935162167395315

Epoch: 5| Step: 8
Training loss: 2.925692081451416
Validation loss: 2.901900209406371

Epoch: 5| Step: 9
Training loss: 3.86370587348938
Validation loss: 2.8715693719925417

Epoch: 5| Step: 10
Training loss: 2.708738327026367
Validation loss: 2.86776323985028

Epoch: 23| Step: 0
Training loss: 2.562654972076416
Validation loss: 2.862920653435492

Epoch: 5| Step: 1
Training loss: 2.9519906044006348
Validation loss: 2.8217009164953746

Epoch: 5| Step: 2
Training loss: 4.111438274383545
Validation loss: 2.7987526334742063

Epoch: 5| Step: 3
Training loss: 2.3614847660064697
Validation loss: 2.792487411088841

Epoch: 5| Step: 4
Training loss: 3.0176615715026855
Validation loss: 2.791476108694589

Epoch: 5| Step: 5
Training loss: 2.8225550651550293
Validation loss: 2.743762541842717

Epoch: 5| Step: 6
Training loss: 2.3944077491760254
Validation loss: 2.72072890240659

Epoch: 5| Step: 7
Training loss: 3.093247652053833
Validation loss: 2.7211032759758735

Epoch: 5| Step: 8
Training loss: 2.832688093185425
Validation loss: 2.731686258828768

Epoch: 5| Step: 9
Training loss: 3.2056078910827637
Validation loss: 2.7198557161515757

Epoch: 5| Step: 10
Training loss: 2.3493258953094482
Validation loss: 2.7002876471447688

Epoch: 24| Step: 0
Training loss: 4.075219631195068
Validation loss: 2.6775908623972247

Epoch: 5| Step: 1
Training loss: 2.8758363723754883
Validation loss: 2.6649924350041214

Epoch: 5| Step: 2
Training loss: 3.234793186187744
Validation loss: 2.6440936826890513

Epoch: 5| Step: 3
Training loss: 3.128115177154541
Validation loss: 2.6334188830467964

Epoch: 5| Step: 4
Training loss: 2.7526183128356934
Validation loss: 2.5988884843805784

Epoch: 5| Step: 5
Training loss: 2.3918797969818115
Validation loss: 2.590232987557688

Epoch: 5| Step: 6
Training loss: 2.184670925140381
Validation loss: 2.5671044767543836

Epoch: 5| Step: 7
Training loss: 2.4191908836364746
Validation loss: 2.564543495896042

Epoch: 5| Step: 8
Training loss: 2.6495604515075684
Validation loss: 2.525031574310795

Epoch: 5| Step: 9
Training loss: 2.642756700515747
Validation loss: 2.5354789508286344

Epoch: 5| Step: 10
Training loss: 2.2109053134918213
Validation loss: 2.490127671149469

Epoch: 25| Step: 0
Training loss: 2.4214446544647217
Validation loss: 2.5120814897680797

Epoch: 5| Step: 1
Training loss: 3.54447603225708
Validation loss: 2.4789901625725532

Epoch: 5| Step: 2
Training loss: 2.672276020050049
Validation loss: 2.4636471527878956

Epoch: 5| Step: 3
Training loss: 3.0122928619384766
Validation loss: 2.467653242490625

Epoch: 5| Step: 4
Training loss: 2.847813129425049
Validation loss: 2.462187474773776

Epoch: 5| Step: 5
Training loss: 2.7800521850585938
Validation loss: 2.4639152954983454

Epoch: 5| Step: 6
Training loss: 2.3085999488830566
Validation loss: 2.4669276257996917

Epoch: 5| Step: 7
Training loss: 2.40461802482605
Validation loss: 2.4505247351943806

Epoch: 5| Step: 8
Training loss: 2.6376235485076904
Validation loss: 2.440769540366306

Epoch: 5| Step: 9
Training loss: 2.7305381298065186
Validation loss: 2.4103588673376266

Epoch: 5| Step: 10
Training loss: 1.5688263177871704
Validation loss: 2.410777558562576

Epoch: 26| Step: 0
Training loss: 2.8678951263427734
Validation loss: 2.4045417642080658

Epoch: 5| Step: 1
Training loss: 2.9832282066345215
Validation loss: 2.414719368821831

Epoch: 5| Step: 2
Training loss: 2.73848295211792
Validation loss: 2.3495305635595836

Epoch: 5| Step: 3
Training loss: 2.8429415225982666
Validation loss: 2.4253636790860083

Epoch: 5| Step: 4
Training loss: 2.2117691040039062
Validation loss: 2.3538600578103015

Epoch: 5| Step: 5
Training loss: 2.574615240097046
Validation loss: 2.3795745577863467

Epoch: 5| Step: 6
Training loss: 1.7514784336090088
Validation loss: 2.343016993614935

Epoch: 5| Step: 7
Training loss: 2.905327320098877
Validation loss: 2.3608020018505793

Epoch: 5| Step: 8
Training loss: 2.4984078407287598
Validation loss: 2.3475842552800334

Epoch: 5| Step: 9
Training loss: 2.659606456756592
Validation loss: 2.3304041021613666

Epoch: 5| Step: 10
Training loss: 2.400780200958252
Validation loss: 2.2960699322403118

Epoch: 27| Step: 0
Training loss: 3.12304949760437
Validation loss: 2.3215653114421393

Epoch: 5| Step: 1
Training loss: 2.5178802013397217
Validation loss: 2.297754964520854

Epoch: 5| Step: 2
Training loss: 2.866063117980957
Validation loss: 2.3380229447477605

Epoch: 5| Step: 3
Training loss: 2.3314852714538574
Validation loss: 2.3248811588492444

Epoch: 5| Step: 4
Training loss: 2.6534886360168457
Validation loss: 2.2801705150194067

Epoch: 5| Step: 5
Training loss: 2.3773653507232666
Validation loss: 2.3263799503285396

Epoch: 5| Step: 6
Training loss: 2.120835065841675
Validation loss: 2.344594483734459

Epoch: 5| Step: 7
Training loss: 2.771625280380249
Validation loss: 2.317205523931852

Epoch: 5| Step: 8
Training loss: 2.331092357635498
Validation loss: 2.3309298228192072

Epoch: 5| Step: 9
Training loss: 2.9871487617492676
Validation loss: 2.3030039302764402

Epoch: 5| Step: 10
Training loss: 2.1330626010894775
Validation loss: 2.294216558497439

Epoch: 28| Step: 0
Training loss: 3.1336984634399414
Validation loss: 2.3022126536215506

Epoch: 5| Step: 1
Training loss: 2.8540942668914795
Validation loss: 2.3138876217667774

Epoch: 5| Step: 2
Training loss: 2.647465467453003
Validation loss: 2.2773864166710966

Epoch: 5| Step: 3
Training loss: 2.5434117317199707
Validation loss: 2.2869130001273206

Epoch: 5| Step: 4
Training loss: 2.7921969890594482
Validation loss: 2.30975079536438

Epoch: 5| Step: 5
Training loss: 2.1605772972106934
Validation loss: 2.2574710153764292

Epoch: 5| Step: 6
Training loss: 2.281078815460205
Validation loss: 2.268703201765655

Epoch: 5| Step: 7
Training loss: 2.7050437927246094
Validation loss: 2.2601774738680933

Epoch: 5| Step: 8
Training loss: 1.9418176412582397
Validation loss: 2.306300699069936

Epoch: 5| Step: 9
Training loss: 2.5963566303253174
Validation loss: 2.285584795859552

Epoch: 5| Step: 10
Training loss: 2.377640962600708
Validation loss: 2.263374751613986

Epoch: 29| Step: 0
Training loss: 2.9604413509368896
Validation loss: 2.2850625156074442

Epoch: 5| Step: 1
Training loss: 2.2075488567352295
Validation loss: 2.238094852816674

Epoch: 5| Step: 2
Training loss: 2.3813416957855225
Validation loss: 2.279165408944571

Epoch: 5| Step: 3
Training loss: 2.7953169345855713
Validation loss: 2.2783830268408662

Epoch: 5| Step: 4
Training loss: 1.986457109451294
Validation loss: 2.2865949010336273

Epoch: 5| Step: 5
Training loss: 2.020751714706421
Validation loss: 2.2743281600295857

Epoch: 5| Step: 6
Training loss: 2.834232807159424
Validation loss: 2.264842479459701

Epoch: 5| Step: 7
Training loss: 2.3632843494415283
Validation loss: 2.308457692464193

Epoch: 5| Step: 8
Training loss: 2.8256924152374268
Validation loss: 2.260007207111646

Epoch: 5| Step: 9
Training loss: 2.741176128387451
Validation loss: 2.280171291802519

Epoch: 5| Step: 10
Training loss: 3.099315881729126
Validation loss: 2.2500314738160823

Epoch: 30| Step: 0
Training loss: 2.8071091175079346
Validation loss: 2.208389671899939

Epoch: 5| Step: 1
Training loss: 2.370939254760742
Validation loss: 2.2600193395409534

Epoch: 5| Step: 2
Training loss: 2.1674628257751465
Validation loss: 2.3052600583722516

Epoch: 5| Step: 3
Training loss: 2.472100257873535
Validation loss: 2.24181100373627

Epoch: 5| Step: 4
Training loss: 2.751744270324707
Validation loss: 2.2876395281924995

Epoch: 5| Step: 5
Training loss: 2.5053341388702393
Validation loss: 2.238552495997439

Epoch: 5| Step: 6
Training loss: 2.655547857284546
Validation loss: 2.2494837840398154

Epoch: 5| Step: 7
Training loss: 3.2876758575439453
Validation loss: 2.259332982442712

Epoch: 5| Step: 8
Training loss: 2.6949124336242676
Validation loss: 2.2503203294610463

Epoch: 5| Step: 9
Training loss: 2.5645365715026855
Validation loss: 2.275590535133116

Epoch: 5| Step: 10
Training loss: 1.7935068607330322
Validation loss: 2.2634408473968506

Epoch: 31| Step: 0
Training loss: 2.6985301971435547
Validation loss: 2.2769296887100383

Epoch: 5| Step: 1
Training loss: 2.13273024559021
Validation loss: 2.256061210427233

Epoch: 5| Step: 2
Training loss: 2.278179407119751
Validation loss: 2.2507399769239527

Epoch: 5| Step: 3
Training loss: 2.54341197013855
Validation loss: 2.2761092673065844

Epoch: 5| Step: 4
Training loss: 2.9302265644073486
Validation loss: 2.2632348460535847

Epoch: 5| Step: 5
Training loss: 2.568615436553955
Validation loss: 2.245201087767078

Epoch: 5| Step: 6
Training loss: 2.353304624557495
Validation loss: 2.2713049252827964

Epoch: 5| Step: 7
Training loss: 2.5612645149230957
Validation loss: 2.2724316325238956

Epoch: 5| Step: 8
Training loss: 2.767554759979248
Validation loss: 2.2469314631595405

Epoch: 5| Step: 9
Training loss: 2.281052350997925
Validation loss: 2.280168970425924

Epoch: 5| Step: 10
Training loss: 2.6625750064849854
Validation loss: 2.2468716777781004

Epoch: 32| Step: 0
Training loss: 2.5901753902435303
Validation loss: 2.25813199627784

Epoch: 5| Step: 1
Training loss: 1.8989204168319702
Validation loss: 2.2686836386239655

Epoch: 5| Step: 2
Training loss: 3.287271499633789
Validation loss: 2.274506151035268

Epoch: 5| Step: 3
Training loss: 1.9917072057724
Validation loss: 2.205812005586522

Epoch: 5| Step: 4
Training loss: 2.535429000854492
Validation loss: 2.2539340065371607

Epoch: 5| Step: 5
Training loss: 2.679046630859375
Validation loss: 2.267057357295867

Epoch: 5| Step: 6
Training loss: 2.0919787883758545
Validation loss: 2.2668319594475532

Epoch: 5| Step: 7
Training loss: 2.42156982421875
Validation loss: 2.2356290381441832

Epoch: 5| Step: 8
Training loss: 2.842217206954956
Validation loss: 2.2442027522671606

Epoch: 5| Step: 9
Training loss: 3.264118194580078
Validation loss: 2.2348648322525846

Epoch: 5| Step: 10
Training loss: 2.348357677459717
Validation loss: 2.2364171628029115

Epoch: 33| Step: 0
Training loss: 2.4241509437561035
Validation loss: 2.261964274990943

Epoch: 5| Step: 1
Training loss: 1.8023662567138672
Validation loss: 2.2554541403247463

Epoch: 5| Step: 2
Training loss: 2.141754150390625
Validation loss: 2.2199232527004775

Epoch: 5| Step: 3
Training loss: 2.7084107398986816
Validation loss: 2.243674583332513

Epoch: 5| Step: 4
Training loss: 2.975613832473755
Validation loss: 2.2460421644231325

Epoch: 5| Step: 5
Training loss: 2.8541018962860107
Validation loss: 2.2858526911786807

Epoch: 5| Step: 6
Training loss: 2.066924571990967
Validation loss: 2.244363595080632

Epoch: 5| Step: 7
Training loss: 2.12070894241333
Validation loss: 2.2496787463465044

Epoch: 5| Step: 8
Training loss: 2.8766286373138428
Validation loss: 2.279959556876972

Epoch: 5| Step: 9
Training loss: 3.1041367053985596
Validation loss: 2.2544074135441936

Epoch: 5| Step: 10
Training loss: 2.5349910259246826
Validation loss: 2.2445196900316464

Epoch: 34| Step: 0
Training loss: 2.5155673027038574
Validation loss: 2.259432920845606

Epoch: 5| Step: 1
Training loss: 3.130995035171509
Validation loss: 2.285878194275723

Epoch: 5| Step: 2
Training loss: 3.0385098457336426
Validation loss: 2.3076931917539207

Epoch: 5| Step: 3
Training loss: 3.058785915374756
Validation loss: 2.2702621811179706

Epoch: 5| Step: 4
Training loss: 2.2583227157592773
Validation loss: 2.2491937478383384

Epoch: 5| Step: 5
Training loss: 2.040907382965088
Validation loss: 2.2013106679403656

Epoch: 5| Step: 6
Training loss: 1.9164472818374634
Validation loss: 2.2452028797518824

Epoch: 5| Step: 7
Training loss: 2.2816624641418457
Validation loss: 2.2551584013046755

Epoch: 5| Step: 8
Training loss: 2.6028785705566406
Validation loss: 2.2509682383588565

Epoch: 5| Step: 9
Training loss: 2.7401623725891113
Validation loss: 2.270465868775563

Epoch: 5| Step: 10
Training loss: 2.3892738819122314
Validation loss: 2.242092242804907

Epoch: 35| Step: 0
Training loss: 3.0590267181396484
Validation loss: 2.22127245062141

Epoch: 5| Step: 1
Training loss: 2.9378395080566406
Validation loss: 2.2525752334184546

Epoch: 5| Step: 2
Training loss: 2.50228214263916
Validation loss: 2.205858644618783

Epoch: 5| Step: 3
Training loss: 2.0751781463623047
Validation loss: 2.234385915981826

Epoch: 5| Step: 4
Training loss: 2.583322048187256
Validation loss: 2.2385548981287147

Epoch: 5| Step: 5
Training loss: 2.4730374813079834
Validation loss: 2.2538318428941952

Epoch: 5| Step: 6
Training loss: 2.316591739654541
Validation loss: 2.217303534989716

Epoch: 5| Step: 7
Training loss: 3.1331417560577393
Validation loss: 2.2346211928193287

Epoch: 5| Step: 8
Training loss: 2.2077040672302246
Validation loss: 2.242523927842417

Epoch: 5| Step: 9
Training loss: 2.2654762268066406
Validation loss: 2.222536092163414

Epoch: 5| Step: 10
Training loss: 2.2751400470733643
Validation loss: 2.24805377375695

Epoch: 36| Step: 0
Training loss: 2.508294105529785
Validation loss: 2.2566867643787014

Epoch: 5| Step: 1
Training loss: 2.2510156631469727
Validation loss: 2.2380479215293803

Epoch: 5| Step: 2
Training loss: 2.8722662925720215
Validation loss: 2.286921901087607

Epoch: 5| Step: 3
Training loss: 2.5219600200653076
Validation loss: 2.232818312542413

Epoch: 5| Step: 4
Training loss: 2.397949695587158
Validation loss: 2.207367322778189

Epoch: 5| Step: 5
Training loss: 3.3314037322998047
Validation loss: 2.2237512667973838

Epoch: 5| Step: 6
Training loss: 2.3470826148986816
Validation loss: 2.2202195172668784

Epoch: 5| Step: 7
Training loss: 2.253371477127075
Validation loss: 2.257912133329658

Epoch: 5| Step: 8
Training loss: 2.7364420890808105
Validation loss: 2.2405624312739216

Epoch: 5| Step: 9
Training loss: 2.5019454956054688
Validation loss: 2.2186521689097085

Epoch: 5| Step: 10
Training loss: 1.9891263246536255
Validation loss: 2.284039807576005

Epoch: 37| Step: 0
Training loss: 2.9671454429626465
Validation loss: 2.2626498719697357

Epoch: 5| Step: 1
Training loss: 2.644538640975952
Validation loss: 2.2580321476023686

Epoch: 5| Step: 2
Training loss: 2.330197811126709
Validation loss: 2.252699044442946

Epoch: 5| Step: 3
Training loss: 2.4476330280303955
Validation loss: 2.240382750829061

Epoch: 5| Step: 4
Training loss: 2.5478742122650146
Validation loss: 2.243198463993688

Epoch: 5| Step: 5
Training loss: 1.9522119760513306
Validation loss: 2.216866377861269

Epoch: 5| Step: 6
Training loss: 3.025434970855713
Validation loss: 2.255175144441666

Epoch: 5| Step: 7
Training loss: 2.796699285507202
Validation loss: 2.2685314045157483

Epoch: 5| Step: 8
Training loss: 2.6286935806274414
Validation loss: 2.2311142721483783

Epoch: 5| Step: 9
Training loss: 2.464362859725952
Validation loss: 2.274452637600642

Epoch: 5| Step: 10
Training loss: 2.038400650024414
Validation loss: 2.2134361728545158

Epoch: 38| Step: 0
Training loss: 2.8160459995269775
Validation loss: 2.2374457954078593

Epoch: 5| Step: 1
Training loss: 2.162297487258911
Validation loss: 2.2669634511393886

Epoch: 5| Step: 2
Training loss: 2.6275272369384766
Validation loss: 2.216740151887299

Epoch: 5| Step: 3
Training loss: 1.7952913045883179
Validation loss: 2.235164614133937

Epoch: 5| Step: 4
Training loss: 2.8709254264831543
Validation loss: 2.2567512707043718

Epoch: 5| Step: 5
Training loss: 3.1012778282165527
Validation loss: 2.238661899361559

Epoch: 5| Step: 6
Training loss: 2.7971224784851074
Validation loss: 2.2214178962092244

Epoch: 5| Step: 7
Training loss: 2.715628147125244
Validation loss: 2.2061653419207503

Epoch: 5| Step: 8
Training loss: 2.2507243156433105
Validation loss: 2.2246591378283758

Epoch: 5| Step: 9
Training loss: 1.9193508625030518
Validation loss: 2.2540628217881724

Epoch: 5| Step: 10
Training loss: 2.6786932945251465
Validation loss: 2.2160559956745436

Epoch: 39| Step: 0
Training loss: 3.0805752277374268
Validation loss: 2.24085811902118

Epoch: 5| Step: 1
Training loss: 2.412904977798462
Validation loss: 2.2388081281415877

Epoch: 5| Step: 2
Training loss: 2.510049819946289
Validation loss: 2.2204598931856054

Epoch: 5| Step: 3
Training loss: 1.8697140216827393
Validation loss: 2.2556768873686432

Epoch: 5| Step: 4
Training loss: 2.4494926929473877
Validation loss: 2.261244294463947

Epoch: 5| Step: 5
Training loss: 2.2994704246520996
Validation loss: 2.232272063532183

Epoch: 5| Step: 6
Training loss: 3.0909500122070312
Validation loss: 2.2406593484263264

Epoch: 5| Step: 7
Training loss: 2.8320460319519043
Validation loss: 2.2672070636544177

Epoch: 5| Step: 8
Training loss: 2.2775206565856934
Validation loss: 2.224039703287104

Epoch: 5| Step: 9
Training loss: 2.447711229324341
Validation loss: 2.2421290605298934

Epoch: 5| Step: 10
Training loss: 2.3234736919403076
Validation loss: 2.228045686598747

Epoch: 40| Step: 0
Training loss: 2.8024368286132812
Validation loss: 2.2386759276031167

Epoch: 5| Step: 1
Training loss: 2.7002627849578857
Validation loss: 2.2743415499246247

Epoch: 5| Step: 2
Training loss: 2.9225635528564453
Validation loss: 2.2586655386032595

Epoch: 5| Step: 3
Training loss: 2.161595582962036
Validation loss: 2.223482411394837

Epoch: 5| Step: 4
Training loss: 2.0021350383758545
Validation loss: 2.260542602949245

Epoch: 5| Step: 5
Training loss: 2.044440269470215
Validation loss: 2.2225166930947253

Epoch: 5| Step: 6
Training loss: 3.329139232635498
Validation loss: 2.196425276417886

Epoch: 5| Step: 7
Training loss: 2.2775635719299316
Validation loss: 2.208312749862671

Epoch: 5| Step: 8
Training loss: 3.122910976409912
Validation loss: 2.2177759498678227

Epoch: 5| Step: 9
Training loss: 2.341512441635132
Validation loss: 2.2603286415018062

Epoch: 5| Step: 10
Training loss: 2.212498903274536
Validation loss: 2.1975563726117535

Epoch: 41| Step: 0
Training loss: 2.361217737197876
Validation loss: 2.2305324257061048

Epoch: 5| Step: 1
Training loss: 2.8792810440063477
Validation loss: 2.240843480633151

Epoch: 5| Step: 2
Training loss: 1.9763370752334595
Validation loss: 2.2428231393137286

Epoch: 5| Step: 3
Training loss: 3.175081968307495
Validation loss: 2.2607282669313493

Epoch: 5| Step: 4
Training loss: 2.7321362495422363
Validation loss: 2.253218038107759

Epoch: 5| Step: 5
Training loss: 2.3779711723327637
Validation loss: 2.2278098701148905

Epoch: 5| Step: 6
Training loss: 2.454371929168701
Validation loss: 2.2014970805055354

Epoch: 5| Step: 7
Training loss: 2.712467908859253
Validation loss: 2.2533709310716197

Epoch: 5| Step: 8
Training loss: 3.119658946990967
Validation loss: 2.207533459509573

Epoch: 5| Step: 9
Training loss: 2.1112117767333984
Validation loss: 2.2213516517352034

Epoch: 5| Step: 10
Training loss: 1.7234493494033813
Validation loss: 2.2091293514415784

Epoch: 42| Step: 0
Training loss: 2.978027105331421
Validation loss: 2.1853068951637513

Epoch: 5| Step: 1
Training loss: 2.3542346954345703
Validation loss: 2.192783978677565

Epoch: 5| Step: 2
Training loss: 2.6175835132598877
Validation loss: 2.1918143495436637

Epoch: 5| Step: 3
Training loss: 2.138901710510254
Validation loss: 2.1911260825331493

Epoch: 5| Step: 4
Training loss: 2.05039644241333
Validation loss: 2.2438753189579135

Epoch: 5| Step: 5
Training loss: 1.965928316116333
Validation loss: 2.2456442181782057

Epoch: 5| Step: 6
Training loss: 2.8685851097106934
Validation loss: 2.1946000053036596

Epoch: 5| Step: 7
Training loss: 2.3911490440368652
Validation loss: 2.2089655501868135

Epoch: 5| Step: 8
Training loss: 2.542499303817749
Validation loss: 2.238937247184015

Epoch: 5| Step: 9
Training loss: 2.844902515411377
Validation loss: 2.2449273024835894

Epoch: 5| Step: 10
Training loss: 2.7449021339416504
Validation loss: 2.233785439563054

Epoch: 43| Step: 0
Training loss: 3.0441250801086426
Validation loss: 2.2054311049881803

Epoch: 5| Step: 1
Training loss: 2.217346429824829
Validation loss: 2.227667681632503

Epoch: 5| Step: 2
Training loss: 2.7301695346832275
Validation loss: 2.1958597167845695

Epoch: 5| Step: 3
Training loss: 2.806509494781494
Validation loss: 2.2038084153206117

Epoch: 5| Step: 4
Training loss: 2.324612855911255
Validation loss: 2.198678613990866

Epoch: 5| Step: 5
Training loss: 1.8266521692276
Validation loss: 2.2053008669166156

Epoch: 5| Step: 6
Training loss: 2.1757164001464844
Validation loss: 2.222268630099553

Epoch: 5| Step: 7
Training loss: 2.936617374420166
Validation loss: 2.2454554291181665

Epoch: 5| Step: 8
Training loss: 2.889618396759033
Validation loss: 2.2390220959981284

Epoch: 5| Step: 9
Training loss: 2.8301730155944824
Validation loss: 2.200917959213257

Epoch: 5| Step: 10
Training loss: 1.5543286800384521
Validation loss: 2.2274228526699926

Epoch: 44| Step: 0
Training loss: 2.898841381072998
Validation loss: 2.2430332142819642

Epoch: 5| Step: 1
Training loss: 2.342008113861084
Validation loss: 2.216055072763915

Epoch: 5| Step: 2
Training loss: 2.3730504512786865
Validation loss: 2.2177113871420584

Epoch: 5| Step: 3
Training loss: 2.14121675491333
Validation loss: 2.246314110294465

Epoch: 5| Step: 4
Training loss: 2.746619701385498
Validation loss: 2.22346995722863

Epoch: 5| Step: 5
Training loss: 2.7155845165252686
Validation loss: 2.2867188197310253

Epoch: 5| Step: 6
Training loss: 2.2379038333892822
Validation loss: 2.229205874986546

Epoch: 5| Step: 7
Training loss: 2.9472267627716064
Validation loss: 2.1898081302642822

Epoch: 5| Step: 8
Training loss: 2.463921308517456
Validation loss: 2.23783790808852

Epoch: 5| Step: 9
Training loss: 1.8222516775131226
Validation loss: 2.254212987038397

Epoch: 5| Step: 10
Training loss: 2.442786931991577
Validation loss: 2.239418657877112

Epoch: 45| Step: 0
Training loss: 2.6547207832336426
Validation loss: 2.227063763526178

Epoch: 5| Step: 1
Training loss: 2.4927897453308105
Validation loss: 2.1914031377402683

Epoch: 5| Step: 2
Training loss: 3.083322525024414
Validation loss: 2.202485929253281

Epoch: 5| Step: 3
Training loss: 3.0268497467041016
Validation loss: 2.2178365069050945

Epoch: 5| Step: 4
Training loss: 2.5453624725341797
Validation loss: 2.2280823005143033

Epoch: 5| Step: 5
Training loss: 1.8331775665283203
Validation loss: 2.2354304944315264

Epoch: 5| Step: 6
Training loss: 1.9383246898651123
Validation loss: 2.2257094331966933

Epoch: 5| Step: 7
Training loss: 2.486172676086426
Validation loss: 2.2264279985940583

Epoch: 5| Step: 8
Training loss: 2.454017162322998
Validation loss: 2.2030928750191965

Epoch: 5| Step: 9
Training loss: 2.5182785987854004
Validation loss: 2.235205829784434

Epoch: 5| Step: 10
Training loss: 2.467869281768799
Validation loss: 2.218732431370725

Epoch: 46| Step: 0
Training loss: 2.6784889698028564
Validation loss: 2.214210516663008

Epoch: 5| Step: 1
Training loss: 2.6735575199127197
Validation loss: 2.2166313484150875

Epoch: 5| Step: 2
Training loss: 2.4197463989257812
Validation loss: 2.19912257886702

Epoch: 5| Step: 3
Training loss: 2.9523873329162598
Validation loss: 2.2740554219932965

Epoch: 5| Step: 4
Training loss: 2.683614730834961
Validation loss: 2.195062809093024

Epoch: 5| Step: 5
Training loss: 2.583930730819702
Validation loss: 2.1955286020873697

Epoch: 5| Step: 6
Training loss: 1.7262489795684814
Validation loss: 2.23406518531102

Epoch: 5| Step: 7
Training loss: 1.6066995859146118
Validation loss: 2.20834058202723

Epoch: 5| Step: 8
Training loss: 2.506992816925049
Validation loss: 2.249659720287528

Epoch: 5| Step: 9
Training loss: 3.1051254272460938
Validation loss: 2.228403914359308

Epoch: 5| Step: 10
Training loss: 2.2448344230651855
Validation loss: 2.18429151914453

Epoch: 47| Step: 0
Training loss: 2.3538899421691895
Validation loss: 2.228411287389776

Epoch: 5| Step: 1
Training loss: 2.308223009109497
Validation loss: 2.148195548724103

Epoch: 5| Step: 2
Training loss: 2.5161654949188232
Validation loss: 2.1843286457882134

Epoch: 5| Step: 3
Training loss: 2.8444721698760986
Validation loss: 2.138084650039673

Epoch: 5| Step: 4
Training loss: 2.8767504692077637
Validation loss: 2.1805207831885225

Epoch: 5| Step: 5
Training loss: 2.734673261642456
Validation loss: 2.210919128951206

Epoch: 5| Step: 6
Training loss: 2.1862454414367676
Validation loss: 2.266704151707311

Epoch: 5| Step: 7
Training loss: 2.2632336616516113
Validation loss: 2.2050448771445983

Epoch: 5| Step: 8
Training loss: 1.9524720907211304
Validation loss: 2.227548465933851

Epoch: 5| Step: 9
Training loss: 2.327371835708618
Validation loss: 2.220931932490359

Epoch: 5| Step: 10
Training loss: 2.8921494483947754
Validation loss: 2.226746952661904

Epoch: 48| Step: 0
Training loss: 2.8219354152679443
Validation loss: 2.211393451177946

Epoch: 5| Step: 1
Training loss: 2.8120815753936768
Validation loss: 2.2197324383643364

Epoch: 5| Step: 2
Training loss: 2.3960673809051514
Validation loss: 2.198330194719376

Epoch: 5| Step: 3
Training loss: 2.502019166946411
Validation loss: 2.1906185432146956

Epoch: 5| Step: 4
Training loss: 3.0713438987731934
Validation loss: 2.216478814360916

Epoch: 5| Step: 5
Training loss: 2.3968424797058105
Validation loss: 2.190575145906018

Epoch: 5| Step: 6
Training loss: 1.9634687900543213
Validation loss: 2.23267989261176

Epoch: 5| Step: 7
Training loss: 2.332594871520996
Validation loss: 2.226786408373105

Epoch: 5| Step: 8
Training loss: 2.1108031272888184
Validation loss: 2.2022241738534745

Epoch: 5| Step: 9
Training loss: 2.5563294887542725
Validation loss: 2.20729576131349

Epoch: 5| Step: 10
Training loss: 2.304778814315796
Validation loss: 2.2088769456391693

Epoch: 49| Step: 0
Training loss: 1.5111258029937744
Validation loss: 2.183430684510098

Epoch: 5| Step: 1
Training loss: 3.034353733062744
Validation loss: 2.1900265985919583

Epoch: 5| Step: 2
Training loss: 2.1144206523895264
Validation loss: 2.2021445048752653

Epoch: 5| Step: 3
Training loss: 1.735694169998169
Validation loss: 2.1970818811847317

Epoch: 5| Step: 4
Training loss: 3.169299602508545
Validation loss: 2.192258127274052

Epoch: 5| Step: 5
Training loss: 1.8860657215118408
Validation loss: 2.166852802358648

Epoch: 5| Step: 6
Training loss: 2.6034932136535645
Validation loss: 2.1800156229285785

Epoch: 5| Step: 7
Training loss: 2.8622334003448486
Validation loss: 2.214920659219065

Epoch: 5| Step: 8
Training loss: 2.3762922286987305
Validation loss: 2.2132581844124743

Epoch: 5| Step: 9
Training loss: 3.847865581512451
Validation loss: 2.1401091647404495

Epoch: 5| Step: 10
Training loss: 2.044323682785034
Validation loss: 2.2162899278825328

Epoch: 50| Step: 0
Training loss: 2.841357707977295
Validation loss: 2.1746360255825903

Epoch: 5| Step: 1
Training loss: 1.8948919773101807
Validation loss: 2.157255813639651

Epoch: 5| Step: 2
Training loss: 2.764725685119629
Validation loss: 2.191865505710725

Epoch: 5| Step: 3
Training loss: 2.1363139152526855
Validation loss: 2.2124499300474763

Epoch: 5| Step: 4
Training loss: 2.8245723247528076
Validation loss: 2.2242371869343582

Epoch: 5| Step: 5
Training loss: 1.7703651189804077
Validation loss: 2.169618288675944

Epoch: 5| Step: 6
Training loss: 1.903442144393921
Validation loss: 2.2295300934904363

Epoch: 5| Step: 7
Training loss: 2.8734850883483887
Validation loss: 2.187930573699295

Epoch: 5| Step: 8
Training loss: 2.202131986618042
Validation loss: 2.1948107698912263

Epoch: 5| Step: 9
Training loss: 3.0397422313690186
Validation loss: 2.2260729676933697

Epoch: 5| Step: 10
Training loss: 2.6944332122802734
Validation loss: 2.1584390017294113

Epoch: 51| Step: 0
Training loss: 2.4328012466430664
Validation loss: 2.212506619832849

Epoch: 5| Step: 1
Training loss: 2.481943368911743
Validation loss: 2.216706857886366

Epoch: 5| Step: 2
Training loss: 2.1057324409484863
Validation loss: 2.179264788986534

Epoch: 5| Step: 3
Training loss: 2.8165993690490723
Validation loss: 2.1778189533500263

Epoch: 5| Step: 4
Training loss: 2.314939260482788
Validation loss: 2.2235050444961875

Epoch: 5| Step: 5
Training loss: 2.069694995880127
Validation loss: 2.2195352508175756

Epoch: 5| Step: 6
Training loss: 1.9719358682632446
Validation loss: 2.162674621869159

Epoch: 5| Step: 7
Training loss: 2.505059242248535
Validation loss: 2.2454602846535305

Epoch: 5| Step: 8
Training loss: 2.771259069442749
Validation loss: 2.214560551028098

Epoch: 5| Step: 9
Training loss: 2.875633955001831
Validation loss: 2.1803534825642905

Epoch: 5| Step: 10
Training loss: 2.726473808288574
Validation loss: 2.225227758448611

Epoch: 52| Step: 0
Training loss: 1.7931686639785767
Validation loss: 2.184243607264693

Epoch: 5| Step: 1
Training loss: 2.545274257659912
Validation loss: 2.2456982981774116

Epoch: 5| Step: 2
Training loss: 2.6889405250549316
Validation loss: 2.1724549698573288

Epoch: 5| Step: 3
Training loss: 2.8616135120391846
Validation loss: 2.2373654791103896

Epoch: 5| Step: 4
Training loss: 2.748962163925171
Validation loss: 2.1554180524682485

Epoch: 5| Step: 5
Training loss: 2.2407286167144775
Validation loss: 2.187337895875336

Epoch: 5| Step: 6
Training loss: 3.176217555999756
Validation loss: 2.156176556823074

Epoch: 5| Step: 7
Training loss: 2.8701889514923096
Validation loss: 2.2268587453390962

Epoch: 5| Step: 8
Training loss: 2.143205165863037
Validation loss: 2.245898280092465

Epoch: 5| Step: 9
Training loss: 2.0987086296081543
Validation loss: 2.202996519304091

Epoch: 5| Step: 10
Training loss: 1.788439393043518
Validation loss: 2.1785642049645864

Epoch: 53| Step: 0
Training loss: 2.6104729175567627
Validation loss: 2.2087359710406234

Epoch: 5| Step: 1
Training loss: 2.254084348678589
Validation loss: 2.1351577774170907

Epoch: 5| Step: 2
Training loss: 1.8016583919525146
Validation loss: 2.1979740947805424

Epoch: 5| Step: 3
Training loss: 2.8749871253967285
Validation loss: 2.198245712505874

Epoch: 5| Step: 4
Training loss: 2.5835649967193604
Validation loss: 2.198545314932382

Epoch: 5| Step: 5
Training loss: 2.7747514247894287
Validation loss: 2.1835195941309773

Epoch: 5| Step: 6
Training loss: 2.409912109375
Validation loss: 2.151850531178136

Epoch: 5| Step: 7
Training loss: 2.3120713233947754
Validation loss: 2.2083988138424453

Epoch: 5| Step: 8
Training loss: 2.3913750648498535
Validation loss: 2.1802355320222917

Epoch: 5| Step: 9
Training loss: 2.2296676635742188
Validation loss: 2.180316496920842

Epoch: 5| Step: 10
Training loss: 2.5573887825012207
Validation loss: 2.1722063146611696

Epoch: 54| Step: 0
Training loss: 2.873002767562866
Validation loss: 2.169176673376432

Epoch: 5| Step: 1
Training loss: 3.145529270172119
Validation loss: 2.212646543338735

Epoch: 5| Step: 2
Training loss: 2.4190361499786377
Validation loss: 2.205714761569936

Epoch: 5| Step: 3
Training loss: 2.85404634475708
Validation loss: 2.187278180994013

Epoch: 5| Step: 4
Training loss: 2.211709499359131
Validation loss: 2.2113830543333486

Epoch: 5| Step: 5
Training loss: 2.790148973464966
Validation loss: 2.187895045485548

Epoch: 5| Step: 6
Training loss: 1.9634218215942383
Validation loss: 2.166604672708819

Epoch: 5| Step: 7
Training loss: 2.2730109691619873
Validation loss: 2.2377299877905075

Epoch: 5| Step: 8
Training loss: 2.0376577377319336
Validation loss: 2.201665255331224

Epoch: 5| Step: 9
Training loss: 1.7319347858428955
Validation loss: 2.2035265686691448

Epoch: 5| Step: 10
Training loss: 3.016287326812744
Validation loss: 2.166513499393258

Epoch: 55| Step: 0
Training loss: 1.9323358535766602
Validation loss: 2.2311676625282533

Epoch: 5| Step: 1
Training loss: 2.118743896484375
Validation loss: 2.1245374871838476

Epoch: 5| Step: 2
Training loss: 2.365427017211914
Validation loss: 2.2217678664832987

Epoch: 5| Step: 3
Training loss: 3.0541539192199707
Validation loss: 2.1807085519195883

Epoch: 5| Step: 4
Training loss: 3.171830892562866
Validation loss: 2.17812454828652

Epoch: 5| Step: 5
Training loss: 2.0005946159362793
Validation loss: 2.1490250607972503

Epoch: 5| Step: 6
Training loss: 2.603881359100342
Validation loss: 2.251990515698669

Epoch: 5| Step: 7
Training loss: 2.626967191696167
Validation loss: 2.202784502378074

Epoch: 5| Step: 8
Training loss: 2.7760050296783447
Validation loss: 2.172612596583623

Epoch: 5| Step: 9
Training loss: 2.043217897415161
Validation loss: 2.2057683198682723

Epoch: 5| Step: 10
Training loss: 2.129945755004883
Validation loss: 2.2108508938102314

Epoch: 56| Step: 0
Training loss: 2.684812545776367
Validation loss: 2.1784637743426907

Epoch: 5| Step: 1
Training loss: 2.4407684803009033
Validation loss: 2.2529689214562856

Epoch: 5| Step: 2
Training loss: 1.8850843906402588
Validation loss: 2.1839396889491747

Epoch: 5| Step: 3
Training loss: 2.698490619659424
Validation loss: 2.1470875842596895

Epoch: 5| Step: 4
Training loss: 3.026352643966675
Validation loss: 2.1861246324354604

Epoch: 5| Step: 5
Training loss: 2.5143561363220215
Validation loss: 2.1632054236627396

Epoch: 5| Step: 6
Training loss: 1.7426468133926392
Validation loss: 2.1824233775497763

Epoch: 5| Step: 7
Training loss: 2.077336311340332
Validation loss: 2.2088675960417716

Epoch: 5| Step: 8
Training loss: 3.035857677459717
Validation loss: 2.2051913302431823

Epoch: 5| Step: 9
Training loss: 3.0357024669647217
Validation loss: 2.1430377832023044

Epoch: 5| Step: 10
Training loss: 1.5186796188354492
Validation loss: 2.245237817046463

Epoch: 57| Step: 0
Training loss: 2.4651641845703125
Validation loss: 2.154922575078985

Epoch: 5| Step: 1
Training loss: 2.4215006828308105
Validation loss: 2.194787807362054

Epoch: 5| Step: 2
Training loss: 1.442638635635376
Validation loss: 2.1765414271303403

Epoch: 5| Step: 3
Training loss: 3.111975908279419
Validation loss: 2.2358827360214724

Epoch: 5| Step: 4
Training loss: 2.7267045974731445
Validation loss: 2.1922402817715883

Epoch: 5| Step: 5
Training loss: 2.444220781326294
Validation loss: 2.193576584580124

Epoch: 5| Step: 6
Training loss: 2.7096340656280518
Validation loss: 2.175456057312668

Epoch: 5| Step: 7
Training loss: 2.8511924743652344
Validation loss: 2.218382345732822

Epoch: 5| Step: 8
Training loss: 2.448714017868042
Validation loss: 2.174500257738175

Epoch: 5| Step: 9
Training loss: 2.1573643684387207
Validation loss: 2.1103720652159823

Epoch: 5| Step: 10
Training loss: 2.305889368057251
Validation loss: 2.2079098763004428

Epoch: 58| Step: 0
Training loss: 2.3657431602478027
Validation loss: 2.1979067940865793

Epoch: 5| Step: 1
Training loss: 2.3852899074554443
Validation loss: 2.191970025339434

Epoch: 5| Step: 2
Training loss: 2.637929677963257
Validation loss: 2.1835794718034807

Epoch: 5| Step: 3
Training loss: 1.6701042652130127
Validation loss: 2.1997841199239097

Epoch: 5| Step: 4
Training loss: 2.527954339981079
Validation loss: 2.143482344124907

Epoch: 5| Step: 5
Training loss: 2.5259785652160645
Validation loss: 2.1341042005887596

Epoch: 5| Step: 6
Training loss: 2.512979030609131
Validation loss: 2.181869932400283

Epoch: 5| Step: 7
Training loss: 2.6054625511169434
Validation loss: 2.16715121012862

Epoch: 5| Step: 8
Training loss: 2.7018909454345703
Validation loss: 2.169526723123366

Epoch: 5| Step: 9
Training loss: 2.742495536804199
Validation loss: 2.1919396333797003

Epoch: 5| Step: 10
Training loss: 2.2976531982421875
Validation loss: 2.1965263376953783

Epoch: 59| Step: 0
Training loss: 2.3898613452911377
Validation loss: 2.181779225667318

Epoch: 5| Step: 1
Training loss: 2.462146759033203
Validation loss: 2.2246017366327266

Epoch: 5| Step: 2
Training loss: 2.3710789680480957
Validation loss: 2.212539106286982

Epoch: 5| Step: 3
Training loss: 2.3425214290618896
Validation loss: 2.206718660170032

Epoch: 5| Step: 4
Training loss: 2.2309041023254395
Validation loss: 2.1707275939244095

Epoch: 5| Step: 5
Training loss: 2.4638097286224365
Validation loss: 2.215671957180064

Epoch: 5| Step: 6
Training loss: 2.6375718116760254
Validation loss: 2.154259543265066

Epoch: 5| Step: 7
Training loss: 1.5010993480682373
Validation loss: 2.216759616328824

Epoch: 5| Step: 8
Training loss: 3.3130600452423096
Validation loss: 2.171199455056139

Epoch: 5| Step: 9
Training loss: 2.5249433517456055
Validation loss: 2.2106219260923323

Epoch: 5| Step: 10
Training loss: 2.5263307094573975
Validation loss: 2.198640456763647

Epoch: 60| Step: 0
Training loss: 2.122101306915283
Validation loss: 2.1825981601592033

Epoch: 5| Step: 1
Training loss: 1.7940855026245117
Validation loss: 2.1663116408932592

Epoch: 5| Step: 2
Training loss: 2.5438811779022217
Validation loss: 2.161919750193114

Epoch: 5| Step: 3
Training loss: 2.281578302383423
Validation loss: 2.196676177363242

Epoch: 5| Step: 4
Training loss: 2.2287888526916504
Validation loss: 2.189940029574979

Epoch: 5| Step: 5
Training loss: 2.4270052909851074
Validation loss: 2.22010128472441

Epoch: 5| Step: 6
Training loss: 2.7204525470733643
Validation loss: 2.1793686471959597

Epoch: 5| Step: 7
Training loss: 2.115586042404175
Validation loss: 2.1698661747799126

Epoch: 5| Step: 8
Training loss: 2.7769200801849365
Validation loss: 2.1633419529084237

Epoch: 5| Step: 9
Training loss: 2.5588788986206055
Validation loss: 2.1605326488453853

Epoch: 5| Step: 10
Training loss: 3.0665853023529053
Validation loss: 2.1770463938354165

Epoch: 61| Step: 0
Training loss: 2.3398337364196777
Validation loss: 2.225523171886321

Epoch: 5| Step: 1
Training loss: 3.0877506732940674
Validation loss: 2.1890850849049066

Epoch: 5| Step: 2
Training loss: 3.2727856636047363
Validation loss: 2.1257513056519213

Epoch: 5| Step: 3
Training loss: 2.124018430709839
Validation loss: 2.2124326562368744

Epoch: 5| Step: 4
Training loss: 1.9601223468780518
Validation loss: 2.187066334550099

Epoch: 5| Step: 5
Training loss: 2.434893846511841
Validation loss: 2.244804446415235

Epoch: 5| Step: 6
Training loss: 2.662055253982544
Validation loss: 2.233119756944718

Epoch: 5| Step: 7
Training loss: 2.786184549331665
Validation loss: 2.2336701821255427

Epoch: 5| Step: 8
Training loss: 1.9553779363632202
Validation loss: 2.186187828740766

Epoch: 5| Step: 9
Training loss: 1.6453635692596436
Validation loss: 2.1481956333242436

Epoch: 5| Step: 10
Training loss: 2.442927122116089
Validation loss: 2.140879856642856

Epoch: 62| Step: 0
Training loss: 1.9598140716552734
Validation loss: 2.2150776693897862

Epoch: 5| Step: 1
Training loss: 2.767932415008545
Validation loss: 2.2323381823878132

Epoch: 5| Step: 2
Training loss: 2.5592925548553467
Validation loss: 2.202223518843292

Epoch: 5| Step: 3
Training loss: 2.7489609718322754
Validation loss: 2.239068644021147

Epoch: 5| Step: 4
Training loss: 2.5702788829803467
Validation loss: 2.2004899953001287

Epoch: 5| Step: 5
Training loss: 2.7446048259735107
Validation loss: 2.190676079001478

Epoch: 5| Step: 6
Training loss: 2.4167251586914062
Validation loss: 2.180395269906649

Epoch: 5| Step: 7
Training loss: 1.8189815282821655
Validation loss: 2.1894623515426472

Epoch: 5| Step: 8
Training loss: 2.429104804992676
Validation loss: 2.1682955065081195

Epoch: 5| Step: 9
Training loss: 2.405270576477051
Validation loss: 2.1635214231347524

Epoch: 5| Step: 10
Training loss: 2.1463229656219482
Validation loss: 2.1836574500606907

Epoch: 63| Step: 0
Training loss: 1.492534875869751
Validation loss: 2.1766554130020963

Epoch: 5| Step: 1
Training loss: 2.9416873455047607
Validation loss: 2.1477476448141117

Epoch: 5| Step: 2
Training loss: 2.5020062923431396
Validation loss: 2.1645726311591362

Epoch: 5| Step: 3
Training loss: 2.5843586921691895
Validation loss: 2.1740927696228027

Epoch: 5| Step: 4
Training loss: 2.148611068725586
Validation loss: 2.179095506668091

Epoch: 5| Step: 5
Training loss: 2.549156665802002
Validation loss: 2.221640791944278

Epoch: 5| Step: 6
Training loss: 2.001638412475586
Validation loss: 2.2031311706830095

Epoch: 5| Step: 7
Training loss: 3.226153612136841
Validation loss: 2.217536710923718

Epoch: 5| Step: 8
Training loss: 2.290978193283081
Validation loss: 2.1497305029182026

Epoch: 5| Step: 9
Training loss: 1.8372548818588257
Validation loss: 2.19697158311003

Epoch: 5| Step: 10
Training loss: 3.3134424686431885
Validation loss: 2.173634011258361

Epoch: 64| Step: 0
Training loss: 2.5319912433624268
Validation loss: 2.1241205148799445

Epoch: 5| Step: 1
Training loss: 3.0550472736358643
Validation loss: 2.1692665546171126

Epoch: 5| Step: 2
Training loss: 2.3410959243774414
Validation loss: 2.202222511332522

Epoch: 5| Step: 3
Training loss: 3.367513656616211
Validation loss: 2.1820847552309752

Epoch: 5| Step: 4
Training loss: 2.830659866333008
Validation loss: 2.1966292986305813

Epoch: 5| Step: 5
Training loss: 2.2261948585510254
Validation loss: 2.1980765840058685

Epoch: 5| Step: 6
Training loss: 1.9968674182891846
Validation loss: 2.21648907661438

Epoch: 5| Step: 7
Training loss: 1.9674259424209595
Validation loss: 2.146540185456635

Epoch: 5| Step: 8
Training loss: 2.1039462089538574
Validation loss: 2.161895618643812

Epoch: 5| Step: 9
Training loss: 2.281439781188965
Validation loss: 2.2029302581664054

Epoch: 5| Step: 10
Training loss: 1.774376630783081
Validation loss: 2.17336150651337

Epoch: 65| Step: 0
Training loss: 2.6968061923980713
Validation loss: 2.197981593429401

Epoch: 5| Step: 1
Training loss: 2.658663034439087
Validation loss: 2.2053873128788446

Epoch: 5| Step: 2
Training loss: 2.2940897941589355
Validation loss: 2.2148913260429137

Epoch: 5| Step: 3
Training loss: 2.467665910720825
Validation loss: 2.2093562438923824

Epoch: 5| Step: 4
Training loss: 2.292346477508545
Validation loss: 2.177366959151401

Epoch: 5| Step: 5
Training loss: 2.1404738426208496
Validation loss: 2.1739472804530973

Epoch: 5| Step: 6
Training loss: 2.2017359733581543
Validation loss: 2.158838987350464

Epoch: 5| Step: 7
Training loss: 2.1701836585998535
Validation loss: 2.1776024872256863

Epoch: 5| Step: 8
Training loss: 2.4906833171844482
Validation loss: 2.153540631776215

Epoch: 5| Step: 9
Training loss: 2.775181770324707
Validation loss: 2.167008423036145

Epoch: 5| Step: 10
Training loss: 2.3217568397521973
Validation loss: 2.2145580937785487

Epoch: 66| Step: 0
Training loss: 2.2391209602355957
Validation loss: 2.173737387503347

Epoch: 5| Step: 1
Training loss: 2.65545916557312
Validation loss: 2.227581711225612

Epoch: 5| Step: 2
Training loss: 2.32224702835083
Validation loss: 2.165676345107376

Epoch: 5| Step: 3
Training loss: 2.0261833667755127
Validation loss: 2.1616822404246174

Epoch: 5| Step: 4
Training loss: 2.087404251098633
Validation loss: 2.165941661404025

Epoch: 5| Step: 5
Training loss: 2.6466803550720215
Validation loss: 2.1723018897477018

Epoch: 5| Step: 6
Training loss: 1.8926973342895508
Validation loss: 2.1498198573307326

Epoch: 5| Step: 7
Training loss: 2.854318618774414
Validation loss: 2.126533709546571

Epoch: 5| Step: 8
Training loss: 3.1279101371765137
Validation loss: 2.194943968967725

Epoch: 5| Step: 9
Training loss: 2.4669861793518066
Validation loss: 2.1981086551502185

Epoch: 5| Step: 10
Training loss: 2.1845524311065674
Validation loss: 2.1773372414291545

Epoch: 67| Step: 0
Training loss: 2.6450695991516113
Validation loss: 2.2514954074736564

Epoch: 5| Step: 1
Training loss: 2.9027042388916016
Validation loss: 2.115750235895957

Epoch: 5| Step: 2
Training loss: 2.596688985824585
Validation loss: 2.196950397183818

Epoch: 5| Step: 3
Training loss: 2.1254494190216064
Validation loss: 2.221688014204784

Epoch: 5| Step: 4
Training loss: 1.9598267078399658
Validation loss: 2.1646427864669473

Epoch: 5| Step: 5
Training loss: 2.652484178543091
Validation loss: 2.203056691795267

Epoch: 5| Step: 6
Training loss: 2.026118040084839
Validation loss: 2.18683853713415

Epoch: 5| Step: 7
Training loss: 2.432203531265259
Validation loss: 2.18103971276232

Epoch: 5| Step: 8
Training loss: 2.4121627807617188
Validation loss: 2.1784204103613414

Epoch: 5| Step: 9
Training loss: 2.0608162879943848
Validation loss: 2.1463801245535574

Epoch: 5| Step: 10
Training loss: 2.685880422592163
Validation loss: 2.2158271317840903

Epoch: 68| Step: 0
Training loss: 3.021055221557617
Validation loss: 2.129732447285806

Epoch: 5| Step: 1
Training loss: 2.053377628326416
Validation loss: 2.1389674191833823

Epoch: 5| Step: 2
Training loss: 2.186103105545044
Validation loss: 2.221391443283327

Epoch: 5| Step: 3
Training loss: 2.3741888999938965
Validation loss: 2.1849108434492543

Epoch: 5| Step: 4
Training loss: 2.400538206100464
Validation loss: 2.229688782845774

Epoch: 5| Step: 5
Training loss: 2.671339511871338
Validation loss: 2.1889644976585143

Epoch: 5| Step: 6
Training loss: 2.5170469284057617
Validation loss: 2.1638976886708248

Epoch: 5| Step: 7
Training loss: 2.365602970123291
Validation loss: 2.1754485202091995

Epoch: 5| Step: 8
Training loss: 2.2096469402313232
Validation loss: 2.1931440843048917

Epoch: 5| Step: 9
Training loss: 2.7572503089904785
Validation loss: 2.154604805413113

Epoch: 5| Step: 10
Training loss: 1.9378769397735596
Validation loss: 2.172131871664396

Epoch: 69| Step: 0
Training loss: 1.9559400081634521
Validation loss: 2.160621669984633

Epoch: 5| Step: 1
Training loss: 2.5937907695770264
Validation loss: 2.1908627197306645

Epoch: 5| Step: 2
Training loss: 2.004598617553711
Validation loss: 2.1945579333971907

Epoch: 5| Step: 3
Training loss: 2.230333089828491
Validation loss: 2.1583044605870403

Epoch: 5| Step: 4
Training loss: 2.2074413299560547
Validation loss: 2.2022752505476757

Epoch: 5| Step: 5
Training loss: 2.3237318992614746
Validation loss: 2.2152513111791303

Epoch: 5| Step: 6
Training loss: 2.478586196899414
Validation loss: 2.166105326785836

Epoch: 5| Step: 7
Training loss: 2.6527886390686035
Validation loss: 2.1833963778711136

Epoch: 5| Step: 8
Training loss: 2.3823916912078857
Validation loss: 2.237744713342318

Epoch: 5| Step: 9
Training loss: 2.7862110137939453
Validation loss: 2.183934288640176

Epoch: 5| Step: 10
Training loss: 2.690157175064087
Validation loss: 2.2029569559199835

Epoch: 70| Step: 0
Training loss: 2.292782783508301
Validation loss: 2.154565163837966

Epoch: 5| Step: 1
Training loss: 2.019378900527954
Validation loss: 2.221718598437566

Epoch: 5| Step: 2
Training loss: 2.1460654735565186
Validation loss: 2.2088635852259975

Epoch: 5| Step: 3
Training loss: 2.7433605194091797
Validation loss: 2.142919655769102

Epoch: 5| Step: 4
Training loss: 1.953655481338501
Validation loss: 2.162196937427726

Epoch: 5| Step: 5
Training loss: 2.8050308227539062
Validation loss: 2.1992054421414613

Epoch: 5| Step: 6
Training loss: 2.649449586868286
Validation loss: 2.215658423721149

Epoch: 5| Step: 7
Training loss: 2.4371039867401123
Validation loss: 2.156210933962176

Epoch: 5| Step: 8
Training loss: 2.473344326019287
Validation loss: 2.1305641333262124

Epoch: 5| Step: 9
Training loss: 2.233503818511963
Validation loss: 2.0903912205849924

Epoch: 5| Step: 10
Training loss: 2.307426691055298
Validation loss: 2.1563022239233858

Epoch: 71| Step: 0
Training loss: 2.04524827003479
Validation loss: 2.1414297498682493

Epoch: 5| Step: 1
Training loss: 2.4083683490753174
Validation loss: 2.177258756852919

Epoch: 5| Step: 2
Training loss: 3.1420397758483887
Validation loss: 2.162534595817648

Epoch: 5| Step: 3
Training loss: 2.726555585861206
Validation loss: 2.196206783735624

Epoch: 5| Step: 4
Training loss: 3.0198159217834473
Validation loss: 2.196257245156073

Epoch: 5| Step: 5
Training loss: 2.226083993911743
Validation loss: 2.158103983889344

Epoch: 5| Step: 6
Training loss: 1.625982642173767
Validation loss: 2.172507632163263

Epoch: 5| Step: 7
Training loss: 1.8206754922866821
Validation loss: 2.216772097413258

Epoch: 5| Step: 8
Training loss: 1.985449194908142
Validation loss: 2.164485728868874

Epoch: 5| Step: 9
Training loss: 2.4615142345428467
Validation loss: 2.2238954805558726

Epoch: 5| Step: 10
Training loss: 2.809469223022461
Validation loss: 2.205923634190713

Epoch: 72| Step: 0
Training loss: 2.078030824661255
Validation loss: 2.2366713734083277

Epoch: 5| Step: 1
Training loss: 2.7572474479675293
Validation loss: 2.1468072860471663

Epoch: 5| Step: 2
Training loss: 2.2525794506073
Validation loss: 2.197260195209134

Epoch: 5| Step: 3
Training loss: 1.5491045713424683
Validation loss: 2.1518245781621625

Epoch: 5| Step: 4
Training loss: 2.49951171875
Validation loss: 2.1820124169831634

Epoch: 5| Step: 5
Training loss: 3.169445037841797
Validation loss: 2.1511650393086095

Epoch: 5| Step: 6
Training loss: 2.8471970558166504
Validation loss: 2.1587920855450373

Epoch: 5| Step: 7
Training loss: 2.364762783050537
Validation loss: 2.1914022404660463

Epoch: 5| Step: 8
Training loss: 2.2931103706359863
Validation loss: 2.163705356659428

Epoch: 5| Step: 9
Training loss: 2.0525944232940674
Validation loss: 2.1657701307727444

Epoch: 5| Step: 10
Training loss: 2.5335533618927
Validation loss: 2.1975074006665136

Epoch: 73| Step: 0
Training loss: 1.9527063369750977
Validation loss: 2.143905435839007

Epoch: 5| Step: 1
Training loss: 2.067317485809326
Validation loss: 2.169499530587145

Epoch: 5| Step: 2
Training loss: 2.3806204795837402
Validation loss: 2.2110487056034867

Epoch: 5| Step: 3
Training loss: 2.6761536598205566
Validation loss: 2.1206376475672566

Epoch: 5| Step: 4
Training loss: 2.532644271850586
Validation loss: 2.145725634790236

Epoch: 5| Step: 5
Training loss: 2.1818854808807373
Validation loss: 2.168409016824538

Epoch: 5| Step: 6
Training loss: 2.496397018432617
Validation loss: 2.19312576324709

Epoch: 5| Step: 7
Training loss: 2.9323487281799316
Validation loss: 2.191184430994013

Epoch: 5| Step: 8
Training loss: 1.9738651514053345
Validation loss: 2.145570585804601

Epoch: 5| Step: 9
Training loss: 3.1390058994293213
Validation loss: 2.1622867943138204

Epoch: 5| Step: 10
Training loss: 2.2235562801361084
Validation loss: 2.158490493733396

Epoch: 74| Step: 0
Training loss: 2.5781314373016357
Validation loss: 2.2042896850134737

Epoch: 5| Step: 1
Training loss: 3.0232129096984863
Validation loss: 2.195278318979407

Epoch: 5| Step: 2
Training loss: 2.773606061935425
Validation loss: 2.141440781213904

Epoch: 5| Step: 3
Training loss: 2.729201078414917
Validation loss: 2.1669243817688315

Epoch: 5| Step: 4
Training loss: 2.2813007831573486
Validation loss: 2.1856408426838536

Epoch: 5| Step: 5
Training loss: 1.7272298336029053
Validation loss: 2.1925302423456663

Epoch: 5| Step: 6
Training loss: 1.9024436473846436
Validation loss: 2.1346004688611595

Epoch: 5| Step: 7
Training loss: 2.5998027324676514
Validation loss: 2.1193451740408458

Epoch: 5| Step: 8
Training loss: 2.2454140186309814
Validation loss: 2.153358285145093

Epoch: 5| Step: 9
Training loss: 2.0496747493743896
Validation loss: 2.129224031202255

Epoch: 5| Step: 10
Training loss: 2.1208715438842773
Validation loss: 2.170750969199724

Epoch: 75| Step: 0
Training loss: 2.5778260231018066
Validation loss: 2.1189742780500844

Epoch: 5| Step: 1
Training loss: 2.153024673461914
Validation loss: 2.1622903244469756

Epoch: 5| Step: 2
Training loss: 2.2393438816070557
Validation loss: 2.192913032347156

Epoch: 5| Step: 3
Training loss: 1.726287841796875
Validation loss: 2.097441186187088

Epoch: 5| Step: 4
Training loss: 1.6491000652313232
Validation loss: 2.2012787019052813

Epoch: 5| Step: 5
Training loss: 2.543552875518799
Validation loss: 2.1211578935705204

Epoch: 5| Step: 6
Training loss: 2.9019343852996826
Validation loss: 2.1497598348125333

Epoch: 5| Step: 7
Training loss: 2.046767473220825
Validation loss: 2.205594712688077

Epoch: 5| Step: 8
Training loss: 3.077277421951294
Validation loss: 2.159431116555327

Epoch: 5| Step: 9
Training loss: 2.252931833267212
Validation loss: 2.1880536387043614

Epoch: 5| Step: 10
Training loss: 2.9496805667877197
Validation loss: 2.172861627353135

Epoch: 76| Step: 0
Training loss: 2.6796042919158936
Validation loss: 2.1429799654150523

Epoch: 5| Step: 1
Training loss: 2.5805070400238037
Validation loss: 2.193130698255313

Epoch: 5| Step: 2
Training loss: 2.1286613941192627
Validation loss: 2.1607234836906515

Epoch: 5| Step: 3
Training loss: 2.239795207977295
Validation loss: 2.120422601699829

Epoch: 5| Step: 4
Training loss: 1.8723434209823608
Validation loss: 2.112568691212644

Epoch: 5| Step: 5
Training loss: 2.39719557762146
Validation loss: 2.2106083041878155

Epoch: 5| Step: 6
Training loss: 2.543088436126709
Validation loss: 2.160272502130078

Epoch: 5| Step: 7
Training loss: 1.6756912469863892
Validation loss: 2.0953773644662674

Epoch: 5| Step: 8
Training loss: 2.4044241905212402
Validation loss: 2.1777199622123473

Epoch: 5| Step: 9
Training loss: 2.6548352241516113
Validation loss: 2.16854444883203

Epoch: 5| Step: 10
Training loss: 2.9059596061706543
Validation loss: 2.1132789042688187

Epoch: 77| Step: 0
Training loss: 2.6319656372070312
Validation loss: 2.1475981076558432

Epoch: 5| Step: 1
Training loss: 2.015270471572876
Validation loss: 2.198982331060594

Epoch: 5| Step: 2
Training loss: 2.099855899810791
Validation loss: 2.164648732831401

Epoch: 5| Step: 3
Training loss: 2.421985149383545
Validation loss: 2.1604428073411346

Epoch: 5| Step: 4
Training loss: 2.6171445846557617
Validation loss: 2.1602734263225267

Epoch: 5| Step: 5
Training loss: 2.418456554412842
Validation loss: 2.1554725195771907

Epoch: 5| Step: 6
Training loss: 2.7907662391662598
Validation loss: 2.145938854063711

Epoch: 5| Step: 7
Training loss: 2.668613910675049
Validation loss: 2.1881333487008208

Epoch: 5| Step: 8
Training loss: 1.7858238220214844
Validation loss: 2.1842817670555523

Epoch: 5| Step: 9
Training loss: 2.4574077129364014
Validation loss: 2.1752955785361667

Epoch: 5| Step: 10
Training loss: 2.522988796234131
Validation loss: 2.1794523577536307

Epoch: 78| Step: 0
Training loss: 2.1379237174987793
Validation loss: 2.1260484187833724

Epoch: 5| Step: 1
Training loss: 1.681117057800293
Validation loss: 2.142961581548055

Epoch: 5| Step: 2
Training loss: 2.1525676250457764
Validation loss: 2.12101855585652

Epoch: 5| Step: 3
Training loss: 2.214470386505127
Validation loss: 2.1872349862129457

Epoch: 5| Step: 4
Training loss: 2.3133699893951416
Validation loss: 2.213196510909706

Epoch: 5| Step: 5
Training loss: 2.6748876571655273
Validation loss: 2.123349860150327

Epoch: 5| Step: 6
Training loss: 2.6924915313720703
Validation loss: 2.1479052753858667

Epoch: 5| Step: 7
Training loss: 2.785919427871704
Validation loss: 2.178663753694104

Epoch: 5| Step: 8
Training loss: 3.2060039043426514
Validation loss: 2.175634730246759

Epoch: 5| Step: 9
Training loss: 1.7949104309082031
Validation loss: 2.1276698445761077

Epoch: 5| Step: 10
Training loss: 2.1085500717163086
Validation loss: 2.174388507361053

Epoch: 79| Step: 0
Training loss: 2.169354200363159
Validation loss: 2.134988756589992

Epoch: 5| Step: 1
Training loss: 2.7097043991088867
Validation loss: 2.197639675550563

Epoch: 5| Step: 2
Training loss: 2.7329866886138916
Validation loss: 2.091551612782222

Epoch: 5| Step: 3
Training loss: 2.1177029609680176
Validation loss: 2.1489542761156635

Epoch: 5| Step: 4
Training loss: 1.9288654327392578
Validation loss: 2.1682350609892156

Epoch: 5| Step: 5
Training loss: 2.3433990478515625
Validation loss: 2.1719247705192974

Epoch: 5| Step: 6
Training loss: 2.4791054725646973
Validation loss: 2.1597130708797003

Epoch: 5| Step: 7
Training loss: 2.7947964668273926
Validation loss: 2.138512547298144

Epoch: 5| Step: 8
Training loss: 2.582237720489502
Validation loss: 2.0817605231397893

Epoch: 5| Step: 9
Training loss: 2.117793321609497
Validation loss: 2.161913856383293

Epoch: 5| Step: 10
Training loss: 2.38993239402771
Validation loss: 2.2025153252386276

Epoch: 80| Step: 0
Training loss: 2.755297899246216
Validation loss: 2.2205026072840535

Epoch: 5| Step: 1
Training loss: 2.410691738128662
Validation loss: 2.136865328716975

Epoch: 5| Step: 2
Training loss: 2.0734920501708984
Validation loss: 2.1812594526557514

Epoch: 5| Step: 3
Training loss: 2.3283944129943848
Validation loss: 2.1453341322560466

Epoch: 5| Step: 4
Training loss: 2.173288345336914
Validation loss: 2.2184832211463683

Epoch: 5| Step: 5
Training loss: 2.3004539012908936
Validation loss: 2.131738278173631

Epoch: 5| Step: 6
Training loss: 1.6559956073760986
Validation loss: 2.1119687377765612

Epoch: 5| Step: 7
Training loss: 2.287416934967041
Validation loss: 2.1426510426305954

Epoch: 5| Step: 8
Training loss: 2.2597978115081787
Validation loss: 2.13731820865344

Epoch: 5| Step: 9
Training loss: 2.568211078643799
Validation loss: 2.162538379751226

Epoch: 5| Step: 10
Training loss: 3.2656943798065186
Validation loss: 2.112247311940757

Epoch: 81| Step: 0
Training loss: 2.6953182220458984
Validation loss: 2.1661808106207077

Epoch: 5| Step: 1
Training loss: 2.3492588996887207
Validation loss: 2.1726142539772937

Epoch: 5| Step: 2
Training loss: 2.887813091278076
Validation loss: 2.099911892285911

Epoch: 5| Step: 3
Training loss: 2.5655486583709717
Validation loss: 2.1297854287649995

Epoch: 5| Step: 4
Training loss: 2.561304807662964
Validation loss: 2.1071520723322386

Epoch: 5| Step: 5
Training loss: 1.8406873941421509
Validation loss: 2.157430580867234

Epoch: 5| Step: 6
Training loss: 2.0045323371887207
Validation loss: 2.1487286103669034

Epoch: 5| Step: 7
Training loss: 2.3535780906677246
Validation loss: 2.161691677185797

Epoch: 5| Step: 8
Training loss: 1.900148630142212
Validation loss: 2.2059071961269585

Epoch: 5| Step: 9
Training loss: 2.7755203247070312
Validation loss: 2.159783272333043

Epoch: 5| Step: 10
Training loss: 2.146024465560913
Validation loss: 2.173472219897855

Epoch: 82| Step: 0
Training loss: 1.9723138809204102
Validation loss: 2.11670652128035

Epoch: 5| Step: 1
Training loss: 2.2238011360168457
Validation loss: 2.143658061181345

Epoch: 5| Step: 2
Training loss: 2.7799673080444336
Validation loss: 2.142557482565603

Epoch: 5| Step: 3
Training loss: 2.386629104614258
Validation loss: 2.054187831058297

Epoch: 5| Step: 4
Training loss: 2.3909432888031006
Validation loss: 2.151155707656696

Epoch: 5| Step: 5
Training loss: 2.1473546028137207
Validation loss: 2.150382185495028

Epoch: 5| Step: 6
Training loss: 2.197798728942871
Validation loss: 2.1685264136201594

Epoch: 5| Step: 7
Training loss: 2.4991822242736816
Validation loss: 2.165959042887534

Epoch: 5| Step: 8
Training loss: 3.0169930458068848
Validation loss: 2.143982130994079

Epoch: 5| Step: 9
Training loss: 1.9134624004364014
Validation loss: 2.1550718097276587

Epoch: 5| Step: 10
Training loss: 2.119568347930908
Validation loss: 2.1432857756973593

Epoch: 83| Step: 0
Training loss: 2.5443291664123535
Validation loss: 2.176969587161977

Epoch: 5| Step: 1
Training loss: 2.215024471282959
Validation loss: 2.1679660927864814

Epoch: 5| Step: 2
Training loss: 1.9185196161270142
Validation loss: 2.139906983221731

Epoch: 5| Step: 3
Training loss: 2.13997220993042
Validation loss: 2.1573183075074227

Epoch: 5| Step: 4
Training loss: 2.0322659015655518
Validation loss: 2.1386022298566756

Epoch: 5| Step: 5
Training loss: 2.5013461112976074
Validation loss: 2.13989931537259

Epoch: 5| Step: 6
Training loss: 3.2589454650878906
Validation loss: 2.221396341118761

Epoch: 5| Step: 7
Training loss: 2.7276930809020996
Validation loss: 2.1224890370522775

Epoch: 5| Step: 8
Training loss: 2.0337753295898438
Validation loss: 2.178342821777508

Epoch: 5| Step: 9
Training loss: 2.742769241333008
Validation loss: 2.129074965753863

Epoch: 5| Step: 10
Training loss: 1.960418701171875
Validation loss: 2.13860765323844

Epoch: 84| Step: 0
Training loss: 1.864569067955017
Validation loss: 2.1167778609901347

Epoch: 5| Step: 1
Training loss: 1.8523365259170532
Validation loss: 2.1319892893555346

Epoch: 5| Step: 2
Training loss: 2.3642475605010986
Validation loss: 2.122040605032316

Epoch: 5| Step: 3
Training loss: 2.309037446975708
Validation loss: 2.0922546053445465

Epoch: 5| Step: 4
Training loss: 2.5182127952575684
Validation loss: 2.148333277753604

Epoch: 5| Step: 5
Training loss: 2.2224173545837402
Validation loss: 2.1716970679580525

Epoch: 5| Step: 6
Training loss: 2.774723529815674
Validation loss: 2.2236473534696843

Epoch: 5| Step: 7
Training loss: 2.2528157234191895
Validation loss: 2.190708206545922

Epoch: 5| Step: 8
Training loss: 2.091674327850342
Validation loss: 2.1466865834369453

Epoch: 5| Step: 9
Training loss: 2.8412444591522217
Validation loss: 2.150819102923075

Epoch: 5| Step: 10
Training loss: 2.3150508403778076
Validation loss: 2.1483400457648822

Epoch: 85| Step: 0
Training loss: 2.485438823699951
Validation loss: 2.1898054179324897

Epoch: 5| Step: 1
Training loss: 2.168560028076172
Validation loss: 2.170027045793431

Epoch: 5| Step: 2
Training loss: 2.5172410011291504
Validation loss: 2.174337743431009

Epoch: 5| Step: 3
Training loss: 2.400299072265625
Validation loss: 2.160021000010993

Epoch: 5| Step: 4
Training loss: 2.5257160663604736
Validation loss: 2.2042047874901884

Epoch: 5| Step: 5
Training loss: 2.819216251373291
Validation loss: 2.1719092348570466

Epoch: 5| Step: 6
Training loss: 2.057689905166626
Validation loss: 2.129705423949867

Epoch: 5| Step: 7
Training loss: 2.092233180999756
Validation loss: 2.156072634522633

Epoch: 5| Step: 8
Training loss: 2.2936301231384277
Validation loss: 2.1260660797037105

Epoch: 5| Step: 9
Training loss: 2.6324121952056885
Validation loss: 2.1937650967669744

Epoch: 5| Step: 10
Training loss: 1.702539324760437
Validation loss: 2.1619312494031844

Epoch: 86| Step: 0
Training loss: 2.4594902992248535
Validation loss: 2.120762214865736

Epoch: 5| Step: 1
Training loss: 2.0110883712768555
Validation loss: 2.129206813791747

Epoch: 5| Step: 2
Training loss: 2.9550251960754395
Validation loss: 2.161018075481538

Epoch: 5| Step: 3
Training loss: 2.2908549308776855
Validation loss: 2.1424542614208755

Epoch: 5| Step: 4
Training loss: 1.9296939373016357
Validation loss: 2.140056954917087

Epoch: 5| Step: 5
Training loss: 1.9976539611816406
Validation loss: 2.1249089651210333

Epoch: 5| Step: 6
Training loss: 1.98148512840271
Validation loss: 2.2005984731899795

Epoch: 5| Step: 7
Training loss: 2.5569844245910645
Validation loss: 2.1824767025568153

Epoch: 5| Step: 8
Training loss: 2.54358172416687
Validation loss: 2.1520002965004212

Epoch: 5| Step: 9
Training loss: 2.6536402702331543
Validation loss: 2.1526259863248436

Epoch: 5| Step: 10
Training loss: 2.4672763347625732
Validation loss: 2.1711976528167725

Epoch: 87| Step: 0
Training loss: 2.3857016563415527
Validation loss: 2.173861884301709

Epoch: 5| Step: 1
Training loss: 2.5802388191223145
Validation loss: 2.255029386089694

Epoch: 5| Step: 2
Training loss: 2.846315383911133
Validation loss: 2.134529664952268

Epoch: 5| Step: 3
Training loss: 2.7838501930236816
Validation loss: 2.190611832885332

Epoch: 5| Step: 4
Training loss: 2.425589084625244
Validation loss: 2.192700478338426

Epoch: 5| Step: 5
Training loss: 1.6425457000732422
Validation loss: 2.1270265989406134

Epoch: 5| Step: 6
Training loss: 2.515349864959717
Validation loss: 2.2018575091515817

Epoch: 5| Step: 7
Training loss: 2.321824550628662
Validation loss: 2.194654710831181

Epoch: 5| Step: 8
Training loss: 2.446805238723755
Validation loss: 2.133788933036148

Epoch: 5| Step: 9
Training loss: 1.9793583154678345
Validation loss: 2.1181982973570466

Epoch: 5| Step: 10
Training loss: 1.8220818042755127
Validation loss: 2.150155972408992

Epoch: 88| Step: 0
Training loss: 2.4813449382781982
Validation loss: 2.1832641222143687

Epoch: 5| Step: 1
Training loss: 2.2313380241394043
Validation loss: 2.083075951504451

Epoch: 5| Step: 2
Training loss: 2.306265115737915
Validation loss: 2.18157087602923

Epoch: 5| Step: 3
Training loss: 2.1944432258605957
Validation loss: 2.1556448577552714

Epoch: 5| Step: 4
Training loss: 2.5701377391815186
Validation loss: 2.1575178202762397

Epoch: 5| Step: 5
Training loss: 2.691077470779419
Validation loss: 2.1938351444018784

Epoch: 5| Step: 6
Training loss: 2.6502902507781982
Validation loss: 2.1481520539970806

Epoch: 5| Step: 7
Training loss: 2.264244318008423
Validation loss: 2.1425982200971214

Epoch: 5| Step: 8
Training loss: 2.117084503173828
Validation loss: 2.2431548180118686

Epoch: 5| Step: 9
Training loss: 2.2384891510009766
Validation loss: 2.168199477657195

Epoch: 5| Step: 10
Training loss: 2.0752170085906982
Validation loss: 2.156814629031766

Epoch: 89| Step: 0
Training loss: 2.223970890045166
Validation loss: 2.12230896693404

Epoch: 5| Step: 1
Training loss: 2.3855643272399902
Validation loss: 2.1395812239698184

Epoch: 5| Step: 2
Training loss: 2.1145496368408203
Validation loss: 2.190772318070935

Epoch: 5| Step: 3
Training loss: 2.4578683376312256
Validation loss: 2.169403915764183

Epoch: 5| Step: 4
Training loss: 2.9660630226135254
Validation loss: 2.1791009954226914

Epoch: 5| Step: 5
Training loss: 1.5037950277328491
Validation loss: 2.1555147735021447

Epoch: 5| Step: 6
Training loss: 2.4399075508117676
Validation loss: 2.171383286035189

Epoch: 5| Step: 7
Training loss: 2.201028347015381
Validation loss: 2.138083155437182

Epoch: 5| Step: 8
Training loss: 2.707040786743164
Validation loss: 2.15310154679001

Epoch: 5| Step: 9
Training loss: 2.3024983406066895
Validation loss: 2.114275881039199

Epoch: 5| Step: 10
Training loss: 2.706674575805664
Validation loss: 2.159092508336549

Epoch: 90| Step: 0
Training loss: 2.1504311561584473
Validation loss: 2.1130495366229805

Epoch: 5| Step: 1
Training loss: 2.448883056640625
Validation loss: 2.1530065177589335

Epoch: 5| Step: 2
Training loss: 2.020481586456299
Validation loss: 2.1252251466115317

Epoch: 5| Step: 3
Training loss: 2.226252794265747
Validation loss: 2.1235669146301928

Epoch: 5| Step: 4
Training loss: 2.6388964653015137
Validation loss: 2.199983560910789

Epoch: 5| Step: 5
Training loss: 2.49448823928833
Validation loss: 2.1965000501243015

Epoch: 5| Step: 6
Training loss: 2.03647518157959
Validation loss: 2.082816252144434

Epoch: 5| Step: 7
Training loss: 2.3204445838928223
Validation loss: 2.158911043597806

Epoch: 5| Step: 8
Training loss: 2.587804079055786
Validation loss: 2.168165899092151

Epoch: 5| Step: 9
Training loss: 2.1675498485565186
Validation loss: 2.1914812377704087

Epoch: 5| Step: 10
Training loss: 2.4867725372314453
Validation loss: 2.1715871646840084

Epoch: 91| Step: 0
Training loss: 2.0912106037139893
Validation loss: 2.0763989097328595

Epoch: 5| Step: 1
Training loss: 2.3366012573242188
Validation loss: 2.1353334034642866

Epoch: 5| Step: 2
Training loss: 2.2502264976501465
Validation loss: 2.1518371387194564

Epoch: 5| Step: 3
Training loss: 2.5057952404022217
Validation loss: 2.137339904744138

Epoch: 5| Step: 4
Training loss: 2.3908004760742188
Validation loss: 2.0958572997841785

Epoch: 5| Step: 5
Training loss: 2.485133409500122
Validation loss: 2.0613928405187463

Epoch: 5| Step: 6
Training loss: 1.9706512689590454
Validation loss: 2.150693811396117

Epoch: 5| Step: 7
Training loss: 2.614955186843872
Validation loss: 2.138913764748522

Epoch: 5| Step: 8
Training loss: 2.6905159950256348
Validation loss: 2.146043954357024

Epoch: 5| Step: 9
Training loss: 1.9552562236785889
Validation loss: 2.173400148268669

Epoch: 5| Step: 10
Training loss: 2.1735000610351562
Validation loss: 2.1815553980488933

Epoch: 92| Step: 0
Training loss: 2.764982223510742
Validation loss: 2.121894972298735

Epoch: 5| Step: 1
Training loss: 1.9949404001235962
Validation loss: 2.1441322013896

Epoch: 5| Step: 2
Training loss: 2.7021536827087402
Validation loss: 2.122727765831896

Epoch: 5| Step: 3
Training loss: 2.0251176357269287
Validation loss: 2.1471510446199806

Epoch: 5| Step: 4
Training loss: 2.4889237880706787
Validation loss: 2.1646107127589564

Epoch: 5| Step: 5
Training loss: 2.507115125656128
Validation loss: 2.1854199850431053

Epoch: 5| Step: 6
Training loss: 1.7948687076568604
Validation loss: 2.140124318420246

Epoch: 5| Step: 7
Training loss: 2.243157386779785
Validation loss: 2.17238817163693

Epoch: 5| Step: 8
Training loss: 1.9418363571166992
Validation loss: 2.1674398465823104

Epoch: 5| Step: 9
Training loss: 2.3480582237243652
Validation loss: 2.1549563561716387

Epoch: 5| Step: 10
Training loss: 2.4331798553466797
Validation loss: 2.150297041862242

Epoch: 93| Step: 0
Training loss: 2.4346327781677246
Validation loss: 2.203012230575726

Epoch: 5| Step: 1
Training loss: 1.764902114868164
Validation loss: 2.139684243868756

Epoch: 5| Step: 2
Training loss: 2.202892541885376
Validation loss: 2.223977470910677

Epoch: 5| Step: 3
Training loss: 2.4197628498077393
Validation loss: 2.141615388213947

Epoch: 5| Step: 4
Training loss: 2.692086696624756
Validation loss: 2.126778979455271

Epoch: 5| Step: 5
Training loss: 2.1049911975860596
Validation loss: 2.0890801106729815

Epoch: 5| Step: 6
Training loss: 2.429792642593384
Validation loss: 2.2022067680153796

Epoch: 5| Step: 7
Training loss: 2.5008463859558105
Validation loss: 2.0795038002793507

Epoch: 5| Step: 8
Training loss: 2.08636474609375
Validation loss: 2.1255335423254196

Epoch: 5| Step: 9
Training loss: 2.94734263420105
Validation loss: 2.13678942572686

Epoch: 5| Step: 10
Training loss: 2.0712740421295166
Validation loss: 2.1133994107605307

Epoch: 94| Step: 0
Training loss: 2.749873638153076
Validation loss: 2.1601808430046163

Epoch: 5| Step: 1
Training loss: 1.9158766269683838
Validation loss: 2.1726297332394506

Epoch: 5| Step: 2
Training loss: 2.6678733825683594
Validation loss: 2.152239022716399

Epoch: 5| Step: 3
Training loss: 2.1939899921417236
Validation loss: 2.1411573758689304

Epoch: 5| Step: 4
Training loss: 2.5484540462493896
Validation loss: 2.103806730239622

Epoch: 5| Step: 5
Training loss: 1.9427080154418945
Validation loss: 2.189672049655709

Epoch: 5| Step: 6
Training loss: 2.0019001960754395
Validation loss: 2.1036982408133884

Epoch: 5| Step: 7
Training loss: 2.672693967819214
Validation loss: 2.1457192154340845

Epoch: 5| Step: 8
Training loss: 1.8351755142211914
Validation loss: 2.136861862674836

Epoch: 5| Step: 9
Training loss: 2.7798373699188232
Validation loss: 2.186227801025555

Epoch: 5| Step: 10
Training loss: 2.444671630859375
Validation loss: 2.16595378229695

Epoch: 95| Step: 0
Training loss: 2.9035091400146484
Validation loss: 2.155671345290317

Epoch: 5| Step: 1
Training loss: 2.43084716796875
Validation loss: 2.131608002929277

Epoch: 5| Step: 2
Training loss: 2.250210762023926
Validation loss: 2.2139045910168718

Epoch: 5| Step: 3
Training loss: 1.8017104864120483
Validation loss: 2.1155933641618296

Epoch: 5| Step: 4
Training loss: 2.7033352851867676
Validation loss: 2.1284961790166874

Epoch: 5| Step: 5
Training loss: 2.511601209640503
Validation loss: 2.1092219250176543

Epoch: 5| Step: 6
Training loss: 2.1051459312438965
Validation loss: 2.1217925702371905

Epoch: 5| Step: 7
Training loss: 2.09928035736084
Validation loss: 2.174019992992442

Epoch: 5| Step: 8
Training loss: 1.9889488220214844
Validation loss: 2.036338786925039

Epoch: 5| Step: 9
Training loss: 2.2573647499084473
Validation loss: 2.1481639454441686

Epoch: 5| Step: 10
Training loss: 2.602353096008301
Validation loss: 2.159746039298273

Epoch: 96| Step: 0
Training loss: 2.106560230255127
Validation loss: 2.197452110628928

Epoch: 5| Step: 1
Training loss: 2.5013375282287598
Validation loss: 2.177745408909295

Epoch: 5| Step: 2
Training loss: 2.1602253913879395
Validation loss: 2.1681335459473314

Epoch: 5| Step: 3
Training loss: 2.536491632461548
Validation loss: 2.2175736017124628

Epoch: 5| Step: 4
Training loss: 2.832334041595459
Validation loss: 2.159549334997772

Epoch: 5| Step: 5
Training loss: 2.1469740867614746
Validation loss: 2.203583061054189

Epoch: 5| Step: 6
Training loss: 2.2606005668640137
Validation loss: 2.16650289873923

Epoch: 5| Step: 7
Training loss: 1.9881597757339478
Validation loss: 2.1452641987031504

Epoch: 5| Step: 8
Training loss: 2.1178946495056152
Validation loss: 2.1587161325639292

Epoch: 5| Step: 9
Training loss: 2.6953835487365723
Validation loss: 2.2011918252514255

Epoch: 5| Step: 10
Training loss: 2.366783380508423
Validation loss: 2.173274117131387

Epoch: 97| Step: 0
Training loss: 2.568915367126465
Validation loss: 2.115349938792567

Epoch: 5| Step: 1
Training loss: 2.3817145824432373
Validation loss: 2.1406952104260846

Epoch: 5| Step: 2
Training loss: 2.135525941848755
Validation loss: 2.185532316084831

Epoch: 5| Step: 3
Training loss: 1.6102983951568604
Validation loss: 2.2038567168738252

Epoch: 5| Step: 4
Training loss: 2.5054805278778076
Validation loss: 2.1497043871110484

Epoch: 5| Step: 5
Training loss: 2.609116554260254
Validation loss: 2.1405627778781358

Epoch: 5| Step: 6
Training loss: 2.225196123123169
Validation loss: 2.1327582405459498

Epoch: 5| Step: 7
Training loss: 2.3550822734832764
Validation loss: 2.121036027067451

Epoch: 5| Step: 8
Training loss: 2.0377707481384277
Validation loss: 2.1558747983747915

Epoch: 5| Step: 9
Training loss: 2.6348214149475098
Validation loss: 2.218540064750179

Epoch: 5| Step: 10
Training loss: 2.133587598800659
Validation loss: 2.15086688533906

Epoch: 98| Step: 0
Training loss: 2.4742188453674316
Validation loss: 2.1255204857036634

Epoch: 5| Step: 1
Training loss: 1.9762948751449585
Validation loss: 2.073625280011085

Epoch: 5| Step: 2
Training loss: 2.29582142829895
Validation loss: 2.1211621043502644

Epoch: 5| Step: 3
Training loss: 2.1941797733306885
Validation loss: 2.170714009192682

Epoch: 5| Step: 4
Training loss: 2.173356771469116
Validation loss: 2.133424835820352

Epoch: 5| Step: 5
Training loss: 2.8371524810791016
Validation loss: 2.153635576207151

Epoch: 5| Step: 6
Training loss: 2.6112775802612305
Validation loss: 2.200310707092285

Epoch: 5| Step: 7
Training loss: 2.077420949935913
Validation loss: 2.16189222181997

Epoch: 5| Step: 8
Training loss: 2.3083062171936035
Validation loss: 2.1210076014200845

Epoch: 5| Step: 9
Training loss: 2.5474393367767334
Validation loss: 2.1617010575468822

Epoch: 5| Step: 10
Training loss: 2.1533710956573486
Validation loss: 2.1259497006734214

Epoch: 99| Step: 0
Training loss: 2.0380442142486572
Validation loss: 2.1576314267291816

Epoch: 5| Step: 1
Training loss: 2.2509307861328125
Validation loss: 2.1082960944021902

Epoch: 5| Step: 2
Training loss: 1.8087806701660156
Validation loss: 2.1157269875208535

Epoch: 5| Step: 3
Training loss: 2.1948325634002686
Validation loss: 2.1715764461025113

Epoch: 5| Step: 4
Training loss: 2.8302664756774902
Validation loss: 2.157197121650942

Epoch: 5| Step: 5
Training loss: 2.434762477874756
Validation loss: 2.082999247376637

Epoch: 5| Step: 6
Training loss: 2.9261116981506348
Validation loss: 2.136865008261896

Epoch: 5| Step: 7
Training loss: 2.5289840698242188
Validation loss: 2.1604706164329284

Epoch: 5| Step: 8
Training loss: 1.5248949527740479
Validation loss: 2.1568818399983067

Epoch: 5| Step: 9
Training loss: 1.924609899520874
Validation loss: 2.1415162471032914

Epoch: 5| Step: 10
Training loss: 3.191037654876709
Validation loss: 2.1900094068178566

Epoch: 100| Step: 0
Training loss: 1.7167199850082397
Validation loss: 2.1028011486094487

Epoch: 5| Step: 1
Training loss: 2.6193413734436035
Validation loss: 2.124269408564414

Epoch: 5| Step: 2
Training loss: 2.2179532051086426
Validation loss: 2.1294724505434752

Epoch: 5| Step: 3
Training loss: 2.4716601371765137
Validation loss: 2.145095153521466

Epoch: 5| Step: 4
Training loss: 2.652113676071167
Validation loss: 2.1706321085652998

Epoch: 5| Step: 5
Training loss: 1.6904456615447998
Validation loss: 2.1410229436812864

Epoch: 5| Step: 6
Training loss: 2.2114174365997314
Validation loss: 2.1525495565065773

Epoch: 5| Step: 7
Training loss: 2.2060089111328125
Validation loss: 2.166563210948821

Epoch: 5| Step: 8
Training loss: 3.020711660385132
Validation loss: 2.1619962210296304

Epoch: 5| Step: 9
Training loss: 2.5878634452819824
Validation loss: 2.1664253332281627

Epoch: 5| Step: 10
Training loss: 1.8103036880493164
Validation loss: 2.1243790657289567

Epoch: 101| Step: 0
Training loss: 2.5788369178771973
Validation loss: 2.1088227610434256

Epoch: 5| Step: 1
Training loss: 1.9100335836410522
Validation loss: 2.1319119340629986

Epoch: 5| Step: 2
Training loss: 2.4109292030334473
Validation loss: 2.15281480614857

Epoch: 5| Step: 3
Training loss: 2.023301362991333
Validation loss: 2.1232084817783807

Epoch: 5| Step: 4
Training loss: 1.5366020202636719
Validation loss: 2.141897650175197

Epoch: 5| Step: 5
Training loss: 2.5381810665130615
Validation loss: 2.096798445588799

Epoch: 5| Step: 6
Training loss: 2.1929211616516113
Validation loss: 2.121776242409983

Epoch: 5| Step: 7
Training loss: 2.475878953933716
Validation loss: 2.2376068433125815

Epoch: 5| Step: 8
Training loss: 2.492948532104492
Validation loss: 2.1696878376827446

Epoch: 5| Step: 9
Training loss: 1.9922901391983032
Validation loss: 2.161689685237023

Epoch: 5| Step: 10
Training loss: 3.394346237182617
Validation loss: 2.131553611447734

Epoch: 102| Step: 0
Training loss: 2.766099214553833
Validation loss: 2.16683292388916

Epoch: 5| Step: 1
Training loss: 2.2977097034454346
Validation loss: 2.1099690365534958

Epoch: 5| Step: 2
Training loss: 1.9597523212432861
Validation loss: 2.1724810087552635

Epoch: 5| Step: 3
Training loss: 2.1448702812194824
Validation loss: 2.1265382330904723

Epoch: 5| Step: 4
Training loss: 2.8106303215026855
Validation loss: 2.1180842845670638

Epoch: 5| Step: 5
Training loss: 2.7802605628967285
Validation loss: 2.18147454210507

Epoch: 5| Step: 6
Training loss: 2.0089900493621826
Validation loss: 2.0929194227341683

Epoch: 5| Step: 7
Training loss: 1.9090278148651123
Validation loss: 2.1440035425206667

Epoch: 5| Step: 8
Training loss: 1.9545360803604126
Validation loss: 2.058865995817287

Epoch: 5| Step: 9
Training loss: 2.087956428527832
Validation loss: 2.109719976302116

Epoch: 5| Step: 10
Training loss: 2.6334171295166016
Validation loss: 2.1858191541446153

Epoch: 103| Step: 0
Training loss: 2.426067352294922
Validation loss: 2.180721011213077

Epoch: 5| Step: 1
Training loss: 2.0521702766418457
Validation loss: 2.12465323427672

Epoch: 5| Step: 2
Training loss: 2.548567533493042
Validation loss: 2.110405232316704

Epoch: 5| Step: 3
Training loss: 2.222625494003296
Validation loss: 2.1230099329384426

Epoch: 5| Step: 4
Training loss: 1.8391109704971313
Validation loss: 2.12633042822602

Epoch: 5| Step: 5
Training loss: 2.728102207183838
Validation loss: 2.1358200952570927

Epoch: 5| Step: 6
Training loss: 2.544694185256958
Validation loss: 2.1412948382798063

Epoch: 5| Step: 7
Training loss: 2.057840347290039
Validation loss: 2.1680502929995136

Epoch: 5| Step: 8
Training loss: 2.306166172027588
Validation loss: 2.129277936873897

Epoch: 5| Step: 9
Training loss: 2.4351019859313965
Validation loss: 2.1288722202342045

Epoch: 5| Step: 10
Training loss: 2.158553123474121
Validation loss: 2.175465237709784

Epoch: 104| Step: 0
Training loss: 2.4241020679473877
Validation loss: 2.1324634885275238

Epoch: 5| Step: 1
Training loss: 2.5344083309173584
Validation loss: 2.1689053684152584

Epoch: 5| Step: 2
Training loss: 2.7567789554595947
Validation loss: 2.1375331340297574

Epoch: 5| Step: 3
Training loss: 3.0749197006225586
Validation loss: 2.1952407565168155

Epoch: 5| Step: 4
Training loss: 2.187548875808716
Validation loss: 2.172567070171397

Epoch: 5| Step: 5
Training loss: 2.1534624099731445
Validation loss: 2.1163273831849456

Epoch: 5| Step: 6
Training loss: 2.0926077365875244
Validation loss: 2.1761326225855018

Epoch: 5| Step: 7
Training loss: 2.0064122676849365
Validation loss: 2.1587284406026206

Epoch: 5| Step: 8
Training loss: 2.356950521469116
Validation loss: 2.1360494757211335

Epoch: 5| Step: 9
Training loss: 1.8266899585723877
Validation loss: 2.1897600466205227

Epoch: 5| Step: 10
Training loss: 2.03971004486084
Validation loss: 2.175027331998271

Epoch: 105| Step: 0
Training loss: 2.4814748764038086
Validation loss: 2.1794880949040896

Epoch: 5| Step: 1
Training loss: 2.8457159996032715
Validation loss: 2.19143646506853

Epoch: 5| Step: 2
Training loss: 2.763908863067627
Validation loss: 2.1363738839344313

Epoch: 5| Step: 3
Training loss: 2.698939800262451
Validation loss: 2.0764521014305855

Epoch: 5| Step: 4
Training loss: 1.5486847162246704
Validation loss: 2.121576251522187

Epoch: 5| Step: 5
Training loss: 1.8385404348373413
Validation loss: 2.129581812889345

Epoch: 5| Step: 6
Training loss: 2.797706127166748
Validation loss: 2.1356517499493015

Epoch: 5| Step: 7
Training loss: 1.4897706508636475
Validation loss: 2.136546129821449

Epoch: 5| Step: 8
Training loss: 1.6342378854751587
Validation loss: 2.1535441465275262

Epoch: 5| Step: 9
Training loss: 2.266972064971924
Validation loss: 2.136448206440095

Epoch: 5| Step: 10
Training loss: 2.8233652114868164
Validation loss: 2.152802557073614

Epoch: 106| Step: 0
Training loss: 2.5932841300964355
Validation loss: 2.1690599662001415

Epoch: 5| Step: 1
Training loss: 2.390390396118164
Validation loss: 2.171687130005129

Epoch: 5| Step: 2
Training loss: 1.9887949228286743
Validation loss: 2.2298609902781825

Epoch: 5| Step: 3
Training loss: 2.07519793510437
Validation loss: 2.123882509046985

Epoch: 5| Step: 4
Training loss: 2.2063958644866943
Validation loss: 2.1526067885019446

Epoch: 5| Step: 5
Training loss: 2.227262496948242
Validation loss: 2.094717220593524

Epoch: 5| Step: 6
Training loss: 2.296905279159546
Validation loss: 2.18794894859355

Epoch: 5| Step: 7
Training loss: 2.479386806488037
Validation loss: 2.130439789064469

Epoch: 5| Step: 8
Training loss: 2.2954654693603516
Validation loss: 2.123446049228791

Epoch: 5| Step: 9
Training loss: 1.8814098834991455
Validation loss: 2.156066390775865

Epoch: 5| Step: 10
Training loss: 2.890501022338867
Validation loss: 2.1470301074366414

Epoch: 107| Step: 0
Training loss: 2.450026512145996
Validation loss: 2.0767080014751804

Epoch: 5| Step: 1
Training loss: 2.032203435897827
Validation loss: 2.148264697802964

Epoch: 5| Step: 2
Training loss: 2.521531343460083
Validation loss: 2.158857399417508

Epoch: 5| Step: 3
Training loss: 1.4969537258148193
Validation loss: 2.103434362719136

Epoch: 5| Step: 4
Training loss: 2.761786937713623
Validation loss: 2.081234326926611

Epoch: 5| Step: 5
Training loss: 2.9660804271698
Validation loss: 2.1284164574838456

Epoch: 5| Step: 6
Training loss: 2.2081503868103027
Validation loss: 2.16128021670926

Epoch: 5| Step: 7
Training loss: 2.438800573348999
Validation loss: 2.1176011126528502

Epoch: 5| Step: 8
Training loss: 1.8067413568496704
Validation loss: 2.1318644400565856

Epoch: 5| Step: 9
Training loss: 2.258937358856201
Validation loss: 2.1044425387536325

Epoch: 5| Step: 10
Training loss: 2.5449275970458984
Validation loss: 2.1757788465869043

Epoch: 108| Step: 0
Training loss: 2.3088150024414062
Validation loss: 2.163251003911418

Epoch: 5| Step: 1
Training loss: 2.6121826171875
Validation loss: 2.1850106869974444

Epoch: 5| Step: 2
Training loss: 2.078939437866211
Validation loss: 2.1486492900438208

Epoch: 5| Step: 3
Training loss: 2.7130861282348633
Validation loss: 2.123611242540421

Epoch: 5| Step: 4
Training loss: 2.314420223236084
Validation loss: 2.166538364143782

Epoch: 5| Step: 5
Training loss: 1.8616740703582764
Validation loss: 2.079972154350691

Epoch: 5| Step: 6
Training loss: 2.5691399574279785
Validation loss: 2.1183074802480717

Epoch: 5| Step: 7
Training loss: 1.8816230297088623
Validation loss: 2.127952661565555

Epoch: 5| Step: 8
Training loss: 1.991478681564331
Validation loss: 2.1009639616935485

Epoch: 5| Step: 9
Training loss: 2.3182601928710938
Validation loss: 2.1942300386326288

Epoch: 5| Step: 10
Training loss: 2.731745958328247
Validation loss: 2.11390963421073

Epoch: 109| Step: 0
Training loss: 2.1265206336975098
Validation loss: 2.1125687296672533

Epoch: 5| Step: 1
Training loss: 2.937152862548828
Validation loss: 2.1397673032617055

Epoch: 5| Step: 2
Training loss: 2.789903163909912
Validation loss: 2.187468583865832

Epoch: 5| Step: 3
Training loss: 1.9516521692276
Validation loss: 2.1074811822624615

Epoch: 5| Step: 4
Training loss: 2.3165841102600098
Validation loss: 2.1491480232566915

Epoch: 5| Step: 5
Training loss: 2.4294307231903076
Validation loss: 2.1440816079416583

Epoch: 5| Step: 6
Training loss: 1.8682085275650024
Validation loss: 2.099796995039909

Epoch: 5| Step: 7
Training loss: 1.743544578552246
Validation loss: 2.024979317060081

Epoch: 5| Step: 8
Training loss: 2.036149263381958
Validation loss: 2.141157912951644

Epoch: 5| Step: 9
Training loss: 2.7633464336395264
Validation loss: 2.084546373736474

Epoch: 5| Step: 10
Training loss: 2.4954781532287598
Validation loss: 2.1745915079629548

Epoch: 110| Step: 0
Training loss: 2.3081798553466797
Validation loss: 2.0990525625085317

Epoch: 5| Step: 1
Training loss: 1.8992588520050049
Validation loss: 2.2044500573988883

Epoch: 5| Step: 2
Training loss: 2.6918721199035645
Validation loss: 2.1164177694628314

Epoch: 5| Step: 3
Training loss: 1.8427555561065674
Validation loss: 2.0792688528696694

Epoch: 5| Step: 4
Training loss: 1.6387052536010742
Validation loss: 2.1316064865358415

Epoch: 5| Step: 5
Training loss: 2.302050828933716
Validation loss: 2.134696501557545

Epoch: 5| Step: 6
Training loss: 2.5101571083068848
Validation loss: 2.125147263209025

Epoch: 5| Step: 7
Training loss: 2.2914552688598633
Validation loss: 2.1902023259029595

Epoch: 5| Step: 8
Training loss: 1.7451393604278564
Validation loss: 2.133542565889256

Epoch: 5| Step: 9
Training loss: 1.9711620807647705
Validation loss: 2.1381369534359185

Epoch: 5| Step: 10
Training loss: 3.924405336380005
Validation loss: 2.142374707806495

Epoch: 111| Step: 0
Training loss: 1.9708799123764038
Validation loss: 2.137066307888236

Epoch: 5| Step: 1
Training loss: 2.0714354515075684
Validation loss: 2.120567662741548

Epoch: 5| Step: 2
Training loss: 2.725874662399292
Validation loss: 2.150739990254884

Epoch: 5| Step: 3
Training loss: 2.0612902641296387
Validation loss: 2.128178652896676

Epoch: 5| Step: 4
Training loss: 2.656705141067505
Validation loss: 2.1134198904037476

Epoch: 5| Step: 5
Training loss: 2.5055108070373535
Validation loss: 2.138947138222315

Epoch: 5| Step: 6
Training loss: 2.453085422515869
Validation loss: 2.1487787269776866

Epoch: 5| Step: 7
Training loss: 2.1537675857543945
Validation loss: 2.1452838477268013

Epoch: 5| Step: 8
Training loss: 1.7211353778839111
Validation loss: 2.15287426722947

Epoch: 5| Step: 9
Training loss: 2.089508533477783
Validation loss: 2.1239873311852895

Epoch: 5| Step: 10
Training loss: 2.353315830230713
Validation loss: 2.106078693943639

Epoch: 112| Step: 0
Training loss: 2.301105499267578
Validation loss: 2.069927700104252

Epoch: 5| Step: 1
Training loss: 2.894530773162842
Validation loss: 2.092610095136909

Epoch: 5| Step: 2
Training loss: 2.1917200088500977
Validation loss: 2.1453204001149824

Epoch: 5| Step: 3
Training loss: 2.4517822265625
Validation loss: 2.10888256308853

Epoch: 5| Step: 4
Training loss: 2.1250383853912354
Validation loss: 2.1343650253870154

Epoch: 5| Step: 5
Training loss: 2.0007686614990234
Validation loss: 2.187726669414069

Epoch: 5| Step: 6
Training loss: 2.1689658164978027
Validation loss: 2.1263385229213263

Epoch: 5| Step: 7
Training loss: 2.4528515338897705
Validation loss: 2.089144898999122

Epoch: 5| Step: 8
Training loss: 2.5260491371154785
Validation loss: 2.1082565733181533

Epoch: 5| Step: 9
Training loss: 2.1480154991149902
Validation loss: 2.1080153590889386

Epoch: 5| Step: 10
Training loss: 1.996497631072998
Validation loss: 2.1389830227821105

Epoch: 113| Step: 0
Training loss: 2.7519657611846924
Validation loss: 2.10197760340988

Epoch: 5| Step: 1
Training loss: 2.1919736862182617
Validation loss: 2.1548677593149166

Epoch: 5| Step: 2
Training loss: 2.880645275115967
Validation loss: 2.126828880720241

Epoch: 5| Step: 3
Training loss: 2.553586483001709
Validation loss: 2.1208863565998692

Epoch: 5| Step: 4
Training loss: 1.9653135538101196
Validation loss: 2.151742604471022

Epoch: 5| Step: 5
Training loss: 2.2143728733062744
Validation loss: 2.1570045717300905

Epoch: 5| Step: 6
Training loss: 2.0605812072753906
Validation loss: 2.158803721909882

Epoch: 5| Step: 7
Training loss: 1.7457853555679321
Validation loss: 2.1450142655321347

Epoch: 5| Step: 8
Training loss: 2.2396240234375
Validation loss: 2.124234311042293

Epoch: 5| Step: 9
Training loss: 2.1217269897460938
Validation loss: 2.1398296817656486

Epoch: 5| Step: 10
Training loss: 1.8296297788619995
Validation loss: 2.077071997427171

Epoch: 114| Step: 0
Training loss: 2.7171149253845215
Validation loss: 2.196760041739351

Epoch: 5| Step: 1
Training loss: 2.1525189876556396
Validation loss: 2.162094141847344

Epoch: 5| Step: 2
Training loss: 2.435199499130249
Validation loss: 2.172230689756332

Epoch: 5| Step: 3
Training loss: 1.8773200511932373
Validation loss: 2.142432041065667

Epoch: 5| Step: 4
Training loss: 2.5437533855438232
Validation loss: 2.095280829296317

Epoch: 5| Step: 5
Training loss: 2.1585800647735596
Validation loss: 2.087369377895068

Epoch: 5| Step: 6
Training loss: 2.226865291595459
Validation loss: 2.0986902188229304

Epoch: 5| Step: 7
Training loss: 2.372119426727295
Validation loss: 2.1518404035158056

Epoch: 5| Step: 8
Training loss: 1.8952882289886475
Validation loss: 2.145246873619736

Epoch: 5| Step: 9
Training loss: 2.0836267471313477
Validation loss: 2.077503155636531

Epoch: 5| Step: 10
Training loss: 2.361297607421875
Validation loss: 2.2029098951688377

Epoch: 115| Step: 0
Training loss: 1.8948581218719482
Validation loss: 2.1123572805876374

Epoch: 5| Step: 1
Training loss: 2.6095099449157715
Validation loss: 2.204620199818765

Epoch: 5| Step: 2
Training loss: 1.589533805847168
Validation loss: 2.094242924003191

Epoch: 5| Step: 3
Training loss: 2.5590901374816895
Validation loss: 2.1127742362278763

Epoch: 5| Step: 4
Training loss: 2.1629042625427246
Validation loss: 2.098339783248081

Epoch: 5| Step: 5
Training loss: 2.749096632003784
Validation loss: 2.169503176084129

Epoch: 5| Step: 6
Training loss: 2.9039394855499268
Validation loss: 2.1234391402172785

Epoch: 5| Step: 7
Training loss: 2.4934191703796387
Validation loss: 2.0906499970343804

Epoch: 5| Step: 8
Training loss: 1.914101004600525
Validation loss: 2.1350306798053045

Epoch: 5| Step: 9
Training loss: 2.357950448989868
Validation loss: 2.202000320598643

Epoch: 5| Step: 10
Training loss: 2.08689546585083
Validation loss: 2.119811814318421

Epoch: 116| Step: 0
Training loss: 1.7179924249649048
Validation loss: 2.1180751426245576

Epoch: 5| Step: 1
Training loss: 1.9051640033721924
Validation loss: 2.1306196540914555

Epoch: 5| Step: 2
Training loss: 2.159557819366455
Validation loss: 2.1466404981510614

Epoch: 5| Step: 3
Training loss: 2.3225553035736084
Validation loss: 2.1533688242717455

Epoch: 5| Step: 4
Training loss: 2.0429022312164307
Validation loss: 2.140868394605575

Epoch: 5| Step: 5
Training loss: 2.2381136417388916
Validation loss: 2.1629711094722954

Epoch: 5| Step: 6
Training loss: 2.7044565677642822
Validation loss: 2.196785960146176

Epoch: 5| Step: 7
Training loss: 2.5968551635742188
Validation loss: 2.169023472775695

Epoch: 5| Step: 8
Training loss: 2.5478060245513916
Validation loss: 2.1468353886758127

Epoch: 5| Step: 9
Training loss: 2.5534157752990723
Validation loss: 2.19680884961159

Epoch: 5| Step: 10
Training loss: 1.9190819263458252
Validation loss: 2.1268886699471423

Epoch: 117| Step: 0
Training loss: 2.7535524368286133
Validation loss: 2.131599808251986

Epoch: 5| Step: 1
Training loss: 2.695300817489624
Validation loss: 2.137894440722722

Epoch: 5| Step: 2
Training loss: 2.371633768081665
Validation loss: 2.1112099206575783

Epoch: 5| Step: 3
Training loss: 1.7110092639923096
Validation loss: 2.139167465189452

Epoch: 5| Step: 4
Training loss: 2.2236900329589844
Validation loss: 2.0983976125717163

Epoch: 5| Step: 5
Training loss: 2.5735220909118652
Validation loss: 2.081926859835143

Epoch: 5| Step: 6
Training loss: 1.8248401880264282
Validation loss: 2.1294132304447952

Epoch: 5| Step: 7
Training loss: 2.8271799087524414
Validation loss: 2.180773860664778

Epoch: 5| Step: 8
Training loss: 2.0351996421813965
Validation loss: 2.08566802547824

Epoch: 5| Step: 9
Training loss: 1.4733893871307373
Validation loss: 2.126807156429496

Epoch: 5| Step: 10
Training loss: 2.342407464981079
Validation loss: 2.142090824342543

Epoch: 118| Step: 0
Training loss: 2.5171422958374023
Validation loss: 2.0658267364707044

Epoch: 5| Step: 1
Training loss: 2.3932607173919678
Validation loss: 2.1580925910703597

Epoch: 5| Step: 2
Training loss: 2.177957773208618
Validation loss: 2.1429596101084063

Epoch: 5| Step: 3
Training loss: 2.231612205505371
Validation loss: 2.102465573177543

Epoch: 5| Step: 4
Training loss: 1.7029619216918945
Validation loss: 2.143334586133239

Epoch: 5| Step: 5
Training loss: 2.2142117023468018
Validation loss: 2.1838150562778598

Epoch: 5| Step: 6
Training loss: 2.738098382949829
Validation loss: 2.088622618747014

Epoch: 5| Step: 7
Training loss: 1.904991865158081
Validation loss: 2.1351429006104827

Epoch: 5| Step: 8
Training loss: 2.4632928371429443
Validation loss: 2.1304282988271406

Epoch: 5| Step: 9
Training loss: 2.7276296615600586
Validation loss: 2.1468618069925616

Epoch: 5| Step: 10
Training loss: 1.4333887100219727
Validation loss: 2.12098095750296

Epoch: 119| Step: 0
Training loss: 2.213789701461792
Validation loss: 2.0802378551934355

Epoch: 5| Step: 1
Training loss: 2.702643632888794
Validation loss: 2.1059460870681272

Epoch: 5| Step: 2
Training loss: 1.6052303314208984
Validation loss: 2.1021269867497105

Epoch: 5| Step: 3
Training loss: 2.5455009937286377
Validation loss: 2.1576796398367932

Epoch: 5| Step: 4
Training loss: 1.8669955730438232
Validation loss: 2.128320599115023

Epoch: 5| Step: 5
Training loss: 1.8810641765594482
Validation loss: 2.132376073509134

Epoch: 5| Step: 6
Training loss: 2.1791396141052246
Validation loss: 2.1242940041326706

Epoch: 5| Step: 7
Training loss: 1.9504085779190063
Validation loss: 2.158820277901106

Epoch: 5| Step: 8
Training loss: 3.194427013397217
Validation loss: 2.126811545382264

Epoch: 5| Step: 9
Training loss: 2.2932746410369873
Validation loss: 2.1216063935269593

Epoch: 5| Step: 10
Training loss: 2.2455434799194336
Validation loss: 2.1434596584689234

Epoch: 120| Step: 0
Training loss: 2.255110263824463
Validation loss: 2.1248592420290877

Epoch: 5| Step: 1
Training loss: 1.9709784984588623
Validation loss: 2.1324387186317035

Epoch: 5| Step: 2
Training loss: 2.162055730819702
Validation loss: 2.19925082114435

Epoch: 5| Step: 3
Training loss: 1.3622331619262695
Validation loss: 2.0975281743593115

Epoch: 5| Step: 4
Training loss: 2.2123475074768066
Validation loss: 2.0249170257199194

Epoch: 5| Step: 5
Training loss: 1.4798083305358887
Validation loss: 2.1172839428788874

Epoch: 5| Step: 6
Training loss: 2.4179210662841797
Validation loss: 2.1540132594364945

Epoch: 5| Step: 7
Training loss: 2.1556620597839355
Validation loss: 2.101621953389978

Epoch: 5| Step: 8
Training loss: 2.8286147117614746
Validation loss: 2.1219069227095573

Epoch: 5| Step: 9
Training loss: 2.2646467685699463
Validation loss: 2.166434887916811

Epoch: 5| Step: 10
Training loss: 2.867161750793457
Validation loss: 2.133256732776601

Epoch: 121| Step: 0
Training loss: 2.5449483394622803
Validation loss: 2.119612090049251

Epoch: 5| Step: 1
Training loss: 2.188751697540283
Validation loss: 2.112136335783107

Epoch: 5| Step: 2
Training loss: 2.134263515472412
Validation loss: 2.1754990162387973

Epoch: 5| Step: 3
Training loss: 2.2423255443573
Validation loss: 2.07700196132865

Epoch: 5| Step: 4
Training loss: 2.167285442352295
Validation loss: 2.1818696401452504

Epoch: 5| Step: 5
Training loss: 2.614628314971924
Validation loss: 2.1541512640573646

Epoch: 5| Step: 6
Training loss: 3.052630662918091
Validation loss: 2.1175449355956046

Epoch: 5| Step: 7
Training loss: 2.108708620071411
Validation loss: 2.1797738075256348

Epoch: 5| Step: 8
Training loss: 1.7249656915664673
Validation loss: 2.190882703309418

Epoch: 5| Step: 9
Training loss: 2.0275206565856934
Validation loss: 2.181309030902001

Epoch: 5| Step: 10
Training loss: 2.1971795558929443
Validation loss: 2.112727298531481

Epoch: 122| Step: 0
Training loss: 2.4216713905334473
Validation loss: 2.162358499342395

Epoch: 5| Step: 1
Training loss: 2.215012311935425
Validation loss: 2.1449442243063324

Epoch: 5| Step: 2
Training loss: 2.267223834991455
Validation loss: 2.14127020553876

Epoch: 5| Step: 3
Training loss: 2.271977663040161
Validation loss: 2.1167320871865876

Epoch: 5| Step: 4
Training loss: 1.8449077606201172
Validation loss: 2.1059562237032

Epoch: 5| Step: 5
Training loss: 2.338718891143799
Validation loss: 2.1235266552176526

Epoch: 5| Step: 6
Training loss: 1.842795968055725
Validation loss: 2.093413758021529

Epoch: 5| Step: 7
Training loss: 2.1026692390441895
Validation loss: 2.1450828083099855

Epoch: 5| Step: 8
Training loss: 2.481733560562134
Validation loss: 2.120192809771466

Epoch: 5| Step: 9
Training loss: 2.0633132457733154
Validation loss: 2.1225514834926975

Epoch: 5| Step: 10
Training loss: 2.9089016914367676
Validation loss: 2.1559142604950936

Epoch: 123| Step: 0
Training loss: 2.527930736541748
Validation loss: 2.0944058215746315

Epoch: 5| Step: 1
Training loss: 1.7968437671661377
Validation loss: 2.1257164824393486

Epoch: 5| Step: 2
Training loss: 1.9249217510223389
Validation loss: 2.090508771199052

Epoch: 5| Step: 3
Training loss: 1.9905494451522827
Validation loss: 2.135032255162475

Epoch: 5| Step: 4
Training loss: 2.5028088092803955
Validation loss: 2.1588209982841247

Epoch: 5| Step: 5
Training loss: 2.034651279449463
Validation loss: 2.1759301616299536

Epoch: 5| Step: 6
Training loss: 2.0842299461364746
Validation loss: 2.140631825693192

Epoch: 5| Step: 7
Training loss: 2.4492807388305664
Validation loss: 2.119165469241399

Epoch: 5| Step: 8
Training loss: 2.6229350566864014
Validation loss: 2.1152998914000807

Epoch: 5| Step: 9
Training loss: 2.068753480911255
Validation loss: 2.147046184027067

Epoch: 5| Step: 10
Training loss: 2.4365460872650146
Validation loss: 2.215008892038817

Epoch: 124| Step: 0
Training loss: 1.9016056060791016
Validation loss: 2.200827202489299

Epoch: 5| Step: 1
Training loss: 2.2730536460876465
Validation loss: 2.088089317403814

Epoch: 5| Step: 2
Training loss: 2.525505542755127
Validation loss: 2.1672913092438892

Epoch: 5| Step: 3
Training loss: 2.3105568885803223
Validation loss: 2.154435649994881

Epoch: 5| Step: 4
Training loss: 1.9687774181365967
Validation loss: 2.1341229587472896

Epoch: 5| Step: 5
Training loss: 1.6213195323944092
Validation loss: 2.104226614839287

Epoch: 5| Step: 6
Training loss: 2.4971776008605957
Validation loss: 2.1981458202485116

Epoch: 5| Step: 7
Training loss: 2.9207446575164795
Validation loss: 2.133656399224394

Epoch: 5| Step: 8
Training loss: 2.367671489715576
Validation loss: 2.121605732107675

Epoch: 5| Step: 9
Training loss: 1.7642276287078857
Validation loss: 2.130453150759461

Epoch: 5| Step: 10
Training loss: 1.8339699506759644
Validation loss: 2.1552644314304477

Epoch: 125| Step: 0
Training loss: 2.6749520301818848
Validation loss: 2.244152025509906

Epoch: 5| Step: 1
Training loss: 2.2100038528442383
Validation loss: 2.1296092079531763

Epoch: 5| Step: 2
Training loss: 2.3170506954193115
Validation loss: 2.1367727812900337

Epoch: 5| Step: 3
Training loss: 2.060380220413208
Validation loss: 2.211936068791215

Epoch: 5| Step: 4
Training loss: 2.0256216526031494
Validation loss: 2.1273666299799436

Epoch: 5| Step: 5
Training loss: 2.7768394947052
Validation loss: 2.1544058938180246

Epoch: 5| Step: 6
Training loss: 1.5694122314453125
Validation loss: 2.1825945582441104

Epoch: 5| Step: 7
Training loss: 1.7485558986663818
Validation loss: 2.1268923410805325

Epoch: 5| Step: 8
Training loss: 1.9190778732299805
Validation loss: 2.126045048877757

Epoch: 5| Step: 9
Training loss: 2.743234157562256
Validation loss: 2.2605908327205206

Epoch: 5| Step: 10
Training loss: 2.550950288772583
Validation loss: 2.147880328598843

Epoch: 126| Step: 0
Training loss: 2.1619350910186768
Validation loss: 2.1277608538186676

Epoch: 5| Step: 1
Training loss: 2.5767648220062256
Validation loss: 2.171362658982636

Epoch: 5| Step: 2
Training loss: 2.3056578636169434
Validation loss: 2.164376175531777

Epoch: 5| Step: 3
Training loss: 1.8427040576934814
Validation loss: 2.1480340829459568

Epoch: 5| Step: 4
Training loss: 2.046318292617798
Validation loss: 2.1013365945508404

Epoch: 5| Step: 5
Training loss: 1.9190181493759155
Validation loss: 2.145189851842901

Epoch: 5| Step: 6
Training loss: 2.5638985633850098
Validation loss: 2.127895483406641

Epoch: 5| Step: 7
Training loss: 2.2445075511932373
Validation loss: 2.153811844446326

Epoch: 5| Step: 8
Training loss: 2.229417324066162
Validation loss: 2.1126453133039576

Epoch: 5| Step: 9
Training loss: 2.252575635910034
Validation loss: 2.057809582320593

Epoch: 5| Step: 10
Training loss: 2.5147531032562256
Validation loss: 2.1168985725730978

Epoch: 127| Step: 0
Training loss: 1.6784194707870483
Validation loss: 2.1611500119650238

Epoch: 5| Step: 1
Training loss: 1.7327678203582764
Validation loss: 2.0871558881575063

Epoch: 5| Step: 2
Training loss: 2.2082033157348633
Validation loss: 2.121421585800827

Epoch: 5| Step: 3
Training loss: 2.013946533203125
Validation loss: 2.1103961070378623

Epoch: 5| Step: 4
Training loss: 2.869176149368286
Validation loss: 2.1057644813291487

Epoch: 5| Step: 5
Training loss: 2.0455212593078613
Validation loss: 2.0766233039158646

Epoch: 5| Step: 6
Training loss: 2.3118462562561035
Validation loss: 2.1386820911079325

Epoch: 5| Step: 7
Training loss: 2.252291440963745
Validation loss: 2.1314617177491546

Epoch: 5| Step: 8
Training loss: 2.0533366203308105
Validation loss: 2.0673328202257872

Epoch: 5| Step: 9
Training loss: 2.311464309692383
Validation loss: 2.10937790460484

Epoch: 5| Step: 10
Training loss: 2.99379301071167
Validation loss: 2.1267360307837047

Epoch: 128| Step: 0
Training loss: 2.6477103233337402
Validation loss: 2.187350626914732

Epoch: 5| Step: 1
Training loss: 2.2857234477996826
Validation loss: 2.1534973780314126

Epoch: 5| Step: 2
Training loss: 2.078519582748413
Validation loss: 2.109384899498314

Epoch: 5| Step: 3
Training loss: 1.4751079082489014
Validation loss: 2.111886052675145

Epoch: 5| Step: 4
Training loss: 1.9112392663955688
Validation loss: 2.0657405827635076

Epoch: 5| Step: 5
Training loss: 2.167907238006592
Validation loss: 2.1492666634180213

Epoch: 5| Step: 6
Training loss: 2.8636443614959717
Validation loss: 2.0853306439615067

Epoch: 5| Step: 7
Training loss: 2.4907031059265137
Validation loss: 2.1982995617774224

Epoch: 5| Step: 8
Training loss: 2.188282012939453
Validation loss: 2.1403498829052015

Epoch: 5| Step: 9
Training loss: 2.379873752593994
Validation loss: 2.1658239569715274

Epoch: 5| Step: 10
Training loss: 2.040214776992798
Validation loss: 2.0964428993963424

Epoch: 129| Step: 0
Training loss: 2.5897269248962402
Validation loss: 2.1034837345923147

Epoch: 5| Step: 1
Training loss: 1.9151151180267334
Validation loss: 2.120113285638953

Epoch: 5| Step: 2
Training loss: 1.8348290920257568
Validation loss: 2.160958592609693

Epoch: 5| Step: 3
Training loss: 1.892128348350525
Validation loss: 2.0549244188493296

Epoch: 5| Step: 4
Training loss: 2.198481559753418
Validation loss: 2.042179480675728

Epoch: 5| Step: 5
Training loss: 2.501389265060425
Validation loss: 2.13984655052103

Epoch: 5| Step: 6
Training loss: 3.0942368507385254
Validation loss: 2.0615936325442408

Epoch: 5| Step: 7
Training loss: 2.334132671356201
Validation loss: 2.0845050850222187

Epoch: 5| Step: 8
Training loss: 1.7731876373291016
Validation loss: 2.1908537136611117

Epoch: 5| Step: 9
Training loss: 2.364553928375244
Validation loss: 2.122968658324211

Epoch: 5| Step: 10
Training loss: 2.0252273082733154
Validation loss: 2.0983898152587233

Epoch: 130| Step: 0
Training loss: 2.3083901405334473
Validation loss: 2.0703589070227837

Epoch: 5| Step: 1
Training loss: 2.599987030029297
Validation loss: 2.095803224912254

Epoch: 5| Step: 2
Training loss: 1.7615703344345093
Validation loss: 2.1225736218114055

Epoch: 5| Step: 3
Training loss: 2.5892815589904785
Validation loss: 2.0921994075980237

Epoch: 5| Step: 4
Training loss: 2.386143445968628
Validation loss: 2.1243462075469313

Epoch: 5| Step: 5
Training loss: 1.9378206729888916
Validation loss: 2.0651183218084355

Epoch: 5| Step: 6
Training loss: 2.148747444152832
Validation loss: 2.0550311611544703

Epoch: 5| Step: 7
Training loss: 2.471670627593994
Validation loss: 2.121452098251671

Epoch: 5| Step: 8
Training loss: 1.6134198904037476
Validation loss: 2.1969282242559616

Epoch: 5| Step: 9
Training loss: 2.8115944862365723
Validation loss: 2.150855513029201

Epoch: 5| Step: 10
Training loss: 1.9279462099075317
Validation loss: 2.1770198293911514

Epoch: 131| Step: 0
Training loss: 1.7348140478134155
Validation loss: 2.078617686866432

Epoch: 5| Step: 1
Training loss: 2.1085762977600098
Validation loss: 2.2417693676487094

Epoch: 5| Step: 2
Training loss: 2.3585638999938965
Validation loss: 2.083203051679878

Epoch: 5| Step: 3
Training loss: 2.401597738265991
Validation loss: 2.1405176808757167

Epoch: 5| Step: 4
Training loss: 2.248499870300293
Validation loss: 2.123871946847567

Epoch: 5| Step: 5
Training loss: 2.1550681591033936
Validation loss: 2.063122873665184

Epoch: 5| Step: 6
Training loss: 2.4059572219848633
Validation loss: 2.1237926636972735

Epoch: 5| Step: 7
Training loss: 1.4040623903274536
Validation loss: 2.160400222706538

Epoch: 5| Step: 8
Training loss: 2.4678943157196045
Validation loss: 2.1221313886745

Epoch: 5| Step: 9
Training loss: 2.870985984802246
Validation loss: 2.007974217014928

Epoch: 5| Step: 10
Training loss: 2.137723207473755
Validation loss: 2.147182874782111

Epoch: 132| Step: 0
Training loss: 2.6192193031311035
Validation loss: 2.0843512909386748

Epoch: 5| Step: 1
Training loss: 1.8605149984359741
Validation loss: 2.155397815089072

Epoch: 5| Step: 2
Training loss: 2.3468847274780273
Validation loss: 2.149351353286415

Epoch: 5| Step: 3
Training loss: 1.7988475561141968
Validation loss: 2.1048758722120717

Epoch: 5| Step: 4
Training loss: 2.528028964996338
Validation loss: 2.0926876042478826

Epoch: 5| Step: 5
Training loss: 2.2631356716156006
Validation loss: 2.1768533542592037

Epoch: 5| Step: 6
Training loss: 2.1139674186706543
Validation loss: 2.085997725045809

Epoch: 5| Step: 7
Training loss: 1.7993433475494385
Validation loss: 2.0834414676953386

Epoch: 5| Step: 8
Training loss: 2.3191616535186768
Validation loss: 2.114767377094556

Epoch: 5| Step: 9
Training loss: 2.101814031600952
Validation loss: 2.1019183051201606

Epoch: 5| Step: 10
Training loss: 2.811075448989868
Validation loss: 2.158309575050108

Epoch: 133| Step: 0
Training loss: 2.3662261962890625
Validation loss: 2.1298990429088636

Epoch: 5| Step: 1
Training loss: 2.538813591003418
Validation loss: 2.146797674958424

Epoch: 5| Step: 2
Training loss: 1.8994410037994385
Validation loss: 2.0896344697603615

Epoch: 5| Step: 3
Training loss: 2.9247748851776123
Validation loss: 2.0930599294682986

Epoch: 5| Step: 4
Training loss: 2.2109782695770264
Validation loss: 2.128394373001591

Epoch: 5| Step: 5
Training loss: 2.1752591133117676
Validation loss: 2.1656457788200787

Epoch: 5| Step: 6
Training loss: 2.2010040283203125
Validation loss: 2.1779913107554116

Epoch: 5| Step: 7
Training loss: 1.8972581624984741
Validation loss: 2.1518829522594327

Epoch: 5| Step: 8
Training loss: 2.3516159057617188
Validation loss: 2.147844153065835

Epoch: 5| Step: 9
Training loss: 1.8565702438354492
Validation loss: 2.1157201695185837

Epoch: 5| Step: 10
Training loss: 2.110652446746826
Validation loss: 2.1194000474868284

Epoch: 134| Step: 0
Training loss: 2.489252805709839
Validation loss: 2.1176692106390513

Epoch: 5| Step: 1
Training loss: 2.473536729812622
Validation loss: 2.093297653300788

Epoch: 5| Step: 2
Training loss: 2.0561790466308594
Validation loss: 2.137261103558284

Epoch: 5| Step: 3
Training loss: 2.220707416534424
Validation loss: 2.1183673002386607

Epoch: 5| Step: 4
Training loss: 2.136019706726074
Validation loss: 2.14667679930246

Epoch: 5| Step: 5
Training loss: 2.0636894702911377
Validation loss: 2.1122311520320114

Epoch: 5| Step: 6
Training loss: 2.9423742294311523
Validation loss: 2.1358443665248092

Epoch: 5| Step: 7
Training loss: 1.6644573211669922
Validation loss: 2.0495113454839236

Epoch: 5| Step: 8
Training loss: 2.090801239013672
Validation loss: 2.154149886100523

Epoch: 5| Step: 9
Training loss: 2.233450412750244
Validation loss: 2.100398955806609

Epoch: 5| Step: 10
Training loss: 1.9663482904434204
Validation loss: 2.1009566476268153

Epoch: 135| Step: 0
Training loss: 2.414755344390869
Validation loss: 2.1357337838859967

Epoch: 5| Step: 1
Training loss: 2.59185791015625
Validation loss: 2.1335997504572712

Epoch: 5| Step: 2
Training loss: 2.411515474319458
Validation loss: 2.137369922412339

Epoch: 5| Step: 3
Training loss: 2.164302110671997
Validation loss: 2.148680615168746

Epoch: 5| Step: 4
Training loss: 1.824013113975525
Validation loss: 2.1667239845439954

Epoch: 5| Step: 5
Training loss: 2.4047257900238037
Validation loss: 2.1480684959760277

Epoch: 5| Step: 6
Training loss: 2.6990630626678467
Validation loss: 2.094800095404348

Epoch: 5| Step: 7
Training loss: 2.0319011211395264
Validation loss: 2.120347543429303

Epoch: 5| Step: 8
Training loss: 2.140254020690918
Validation loss: 2.0832463156792427

Epoch: 5| Step: 9
Training loss: 2.196049928665161
Validation loss: 2.152924742749942

Epoch: 5| Step: 10
Training loss: 1.691041111946106
Validation loss: 2.1670278579958024

Epoch: 136| Step: 0
Training loss: 2.3132970333099365
Validation loss: 2.081544799189414

Epoch: 5| Step: 1
Training loss: 2.201707363128662
Validation loss: 2.139440826190415

Epoch: 5| Step: 2
Training loss: 1.9514837265014648
Validation loss: 2.1075614908690095

Epoch: 5| Step: 3
Training loss: 1.8799593448638916
Validation loss: 2.1609488456479964

Epoch: 5| Step: 4
Training loss: 2.103797435760498
Validation loss: 2.1309396502792195

Epoch: 5| Step: 5
Training loss: 2.2547659873962402
Validation loss: 2.1494210394479896

Epoch: 5| Step: 6
Training loss: 1.8944175243377686
Validation loss: 2.11237265986781

Epoch: 5| Step: 7
Training loss: 2.4836742877960205
Validation loss: 2.1253784997488863

Epoch: 5| Step: 8
Training loss: 1.9507620334625244
Validation loss: 2.1178529416361163

Epoch: 5| Step: 9
Training loss: 2.7145166397094727
Validation loss: 2.159970527054161

Epoch: 5| Step: 10
Training loss: 2.2549145221710205
Validation loss: 2.102724148381141

Epoch: 137| Step: 0
Training loss: 2.2910494804382324
Validation loss: 2.135720670864146

Epoch: 5| Step: 1
Training loss: 1.8040707111358643
Validation loss: 2.1464096756391626

Epoch: 5| Step: 2
Training loss: 1.7307281494140625
Validation loss: 2.1086760387625745

Epoch: 5| Step: 3
Training loss: 2.4952099323272705
Validation loss: 2.066789222019975

Epoch: 5| Step: 4
Training loss: 2.295727252960205
Validation loss: 2.1065763683729273

Epoch: 5| Step: 5
Training loss: 2.4374117851257324
Validation loss: 2.06618490270389

Epoch: 5| Step: 6
Training loss: 2.1669135093688965
Validation loss: 2.1289585739053707

Epoch: 5| Step: 7
Training loss: 2.0562024116516113
Validation loss: 2.09760223409181

Epoch: 5| Step: 8
Training loss: 2.384916305541992
Validation loss: 2.067526094375118

Epoch: 5| Step: 9
Training loss: 2.419487953186035
Validation loss: 2.134478742076505

Epoch: 5| Step: 10
Training loss: 2.1835477352142334
Validation loss: 2.191893505793746

Epoch: 138| Step: 0
Training loss: 2.2810111045837402
Validation loss: 2.053583239996305

Epoch: 5| Step: 1
Training loss: 2.1229872703552246
Validation loss: 2.1380234354285785

Epoch: 5| Step: 2
Training loss: 2.6083321571350098
Validation loss: 2.1094799631385395

Epoch: 5| Step: 3
Training loss: 2.1254000663757324
Validation loss: 2.106008775772587

Epoch: 5| Step: 4
Training loss: 2.796525001525879
Validation loss: 2.0739108118959653

Epoch: 5| Step: 5
Training loss: 2.389570951461792
Validation loss: 2.0727006991704306

Epoch: 5| Step: 6
Training loss: 2.2834067344665527
Validation loss: 2.108137164064633

Epoch: 5| Step: 7
Training loss: 1.8732722997665405
Validation loss: 2.050016405761883

Epoch: 5| Step: 8
Training loss: 2.195749521255493
Validation loss: 2.1034523197399673

Epoch: 5| Step: 9
Training loss: 1.5297293663024902
Validation loss: 2.1569494380745837

Epoch: 5| Step: 10
Training loss: 2.422394275665283
Validation loss: 2.1420257476068314

Epoch: 139| Step: 0
Training loss: 2.314378261566162
Validation loss: 2.0883043363530147

Epoch: 5| Step: 1
Training loss: 2.3715922832489014
Validation loss: 2.085157823818986

Epoch: 5| Step: 2
Training loss: 1.7232593297958374
Validation loss: 2.087380375913394

Epoch: 5| Step: 3
Training loss: 2.103074312210083
Validation loss: 2.0834533258150985

Epoch: 5| Step: 4
Training loss: 2.27156662940979
Validation loss: 2.1554307065984255

Epoch: 5| Step: 5
Training loss: 2.1269311904907227
Validation loss: 2.151595530971404

Epoch: 5| Step: 6
Training loss: 2.1879124641418457
Validation loss: 2.0974963377880793

Epoch: 5| Step: 7
Training loss: 2.184138298034668
Validation loss: 2.0415532524867723

Epoch: 5| Step: 8
Training loss: 2.3073983192443848
Validation loss: 2.091088177055441

Epoch: 5| Step: 9
Training loss: 2.3367226123809814
Validation loss: 2.0893329394760953

Epoch: 5| Step: 10
Training loss: 1.7940627336502075
Validation loss: 2.1181902667527557

Epoch: 140| Step: 0
Training loss: 2.4262797832489014
Validation loss: 2.136715578776534

Epoch: 5| Step: 1
Training loss: 2.7299141883850098
Validation loss: 2.0534471414422475

Epoch: 5| Step: 2
Training loss: 1.5691837072372437
Validation loss: 2.12742026775114

Epoch: 5| Step: 3
Training loss: 2.262206554412842
Validation loss: 2.147349651141833

Epoch: 5| Step: 4
Training loss: 2.28267502784729
Validation loss: 2.1724515243243148

Epoch: 5| Step: 5
Training loss: 1.6916759014129639
Validation loss: 2.0907064304556897

Epoch: 5| Step: 6
Training loss: 2.785457134246826
Validation loss: 2.133679525826567

Epoch: 5| Step: 7
Training loss: 2.0071778297424316
Validation loss: 2.126798527215117

Epoch: 5| Step: 8
Training loss: 2.2009778022766113
Validation loss: 2.1285230421250865

Epoch: 5| Step: 9
Training loss: 2.658900022506714
Validation loss: 2.171962791873563

Epoch: 5| Step: 10
Training loss: 2.036342144012451
Validation loss: 2.1725817598322386

Epoch: 141| Step: 0
Training loss: 2.8363683223724365
Validation loss: 2.1608761356722925

Epoch: 5| Step: 1
Training loss: 1.6312954425811768
Validation loss: 2.1716752718853694

Epoch: 5| Step: 2
Training loss: 2.8505072593688965
Validation loss: 2.173586064769376

Epoch: 5| Step: 3
Training loss: 2.437650680541992
Validation loss: 2.1714618898207143

Epoch: 5| Step: 4
Training loss: 1.6618268489837646
Validation loss: 2.1376014704345376

Epoch: 5| Step: 5
Training loss: 2.400688648223877
Validation loss: 2.143168503238309

Epoch: 5| Step: 6
Training loss: 1.69550359249115
Validation loss: 2.1440622242548133

Epoch: 5| Step: 7
Training loss: 2.6363632678985596
Validation loss: 2.128744207402711

Epoch: 5| Step: 8
Training loss: 1.847731351852417
Validation loss: 2.104682894163234

Epoch: 5| Step: 9
Training loss: 2.2859959602355957
Validation loss: 2.1309170274324316

Epoch: 5| Step: 10
Training loss: 1.8073534965515137
Validation loss: 2.133064272583172

Epoch: 142| Step: 0
Training loss: 2.4197518825531006
Validation loss: 2.158798893292745

Epoch: 5| Step: 1
Training loss: 2.6765823364257812
Validation loss: 2.1312730286711004

Epoch: 5| Step: 2
Training loss: 1.9106762409210205
Validation loss: 2.129962562232889

Epoch: 5| Step: 3
Training loss: 2.086768627166748
Validation loss: 2.1766970670351418

Epoch: 5| Step: 4
Training loss: 2.2284722328186035
Validation loss: 2.162650756938483

Epoch: 5| Step: 5
Training loss: 2.1365580558776855
Validation loss: 2.128608480576546

Epoch: 5| Step: 6
Training loss: 1.5782015323638916
Validation loss: 2.1589013684180474

Epoch: 5| Step: 7
Training loss: 2.010540723800659
Validation loss: 2.141612122135778

Epoch: 5| Step: 8
Training loss: 2.531493663787842
Validation loss: 2.090224260924965

Epoch: 5| Step: 9
Training loss: 2.2217321395874023
Validation loss: 2.1820664252004316

Epoch: 5| Step: 10
Training loss: 2.2010374069213867
Validation loss: 2.098646144713125

Epoch: 143| Step: 0
Training loss: 2.4502196311950684
Validation loss: 2.1432233689933695

Epoch: 5| Step: 1
Training loss: 1.6786352396011353
Validation loss: 2.1152883524535806

Epoch: 5| Step: 2
Training loss: 2.0379440784454346
Validation loss: 2.121941885640544

Epoch: 5| Step: 3
Training loss: 2.5000782012939453
Validation loss: 2.226220384720833

Epoch: 5| Step: 4
Training loss: 3.164574146270752
Validation loss: 2.1487458854593258

Epoch: 5| Step: 5
Training loss: 2.3637897968292236
Validation loss: 2.176422252449938

Epoch: 5| Step: 6
Training loss: 1.6188805103302002
Validation loss: 2.106388497096236

Epoch: 5| Step: 7
Training loss: 2.2011373043060303
Validation loss: 2.1257552203311714

Epoch: 5| Step: 8
Training loss: 1.976198434829712
Validation loss: 2.0692847749238372

Epoch: 5| Step: 9
Training loss: 2.062117099761963
Validation loss: 2.1502819061279297

Epoch: 5| Step: 10
Training loss: 2.3424177169799805
Validation loss: 2.1762090139491583

Epoch: 144| Step: 0
Training loss: 2.1791205406188965
Validation loss: 2.182481647819601

Epoch: 5| Step: 1
Training loss: 1.8605678081512451
Validation loss: 2.159956908995105

Epoch: 5| Step: 2
Training loss: 1.5343244075775146
Validation loss: 2.113167724301738

Epoch: 5| Step: 3
Training loss: 2.269322633743286
Validation loss: 2.1426424134162163

Epoch: 5| Step: 4
Training loss: 2.2957844734191895
Validation loss: 2.1042403405712498

Epoch: 5| Step: 5
Training loss: 3.038571834564209
Validation loss: 2.0763823127233856

Epoch: 5| Step: 6
Training loss: 2.253386974334717
Validation loss: 2.076926205747871

Epoch: 5| Step: 7
Training loss: 1.8501098155975342
Validation loss: 2.1813408687550533

Epoch: 5| Step: 8
Training loss: 3.1236698627471924
Validation loss: 2.163945692841725

Epoch: 5| Step: 9
Training loss: 1.7747857570648193
Validation loss: 2.1630372001278784

Epoch: 5| Step: 10
Training loss: 1.888683557510376
Validation loss: 2.1140658855438232

Epoch: 145| Step: 0
Training loss: 2.7054715156555176
Validation loss: 2.0885593019505984

Epoch: 5| Step: 1
Training loss: 2.1045687198638916
Validation loss: 2.1335637748882337

Epoch: 5| Step: 2
Training loss: 1.9822559356689453
Validation loss: 2.0908883092223958

Epoch: 5| Step: 3
Training loss: 1.9956541061401367
Validation loss: 2.1104417616321194

Epoch: 5| Step: 4
Training loss: 2.2267978191375732
Validation loss: 2.125432270829396

Epoch: 5| Step: 5
Training loss: 2.305901050567627
Validation loss: 2.150206877339271

Epoch: 5| Step: 6
Training loss: 2.3021469116210938
Validation loss: 2.115139804860597

Epoch: 5| Step: 7
Training loss: 2.179216146469116
Validation loss: 2.0645035697567846

Epoch: 5| Step: 8
Training loss: 1.6035966873168945
Validation loss: 2.1102702617645264

Epoch: 5| Step: 9
Training loss: 2.0208580493927
Validation loss: 2.1785136422803326

Epoch: 5| Step: 10
Training loss: 2.792280673980713
Validation loss: 2.1409744396004626

Epoch: 146| Step: 0
Training loss: 2.441671848297119
Validation loss: 2.097410355844805

Epoch: 5| Step: 1
Training loss: 2.043715000152588
Validation loss: 2.125247968140469

Epoch: 5| Step: 2
Training loss: 1.7243858575820923
Validation loss: 2.163777892307569

Epoch: 5| Step: 3
Training loss: 1.9520633220672607
Validation loss: 2.1242214018298733

Epoch: 5| Step: 4
Training loss: 2.4877853393554688
Validation loss: 2.072562430494575

Epoch: 5| Step: 5
Training loss: 2.116773843765259
Validation loss: 2.080139131956203

Epoch: 5| Step: 6
Training loss: 2.0521316528320312
Validation loss: 2.1622061870431386

Epoch: 5| Step: 7
Training loss: 2.508845090866089
Validation loss: 2.130281679091915

Epoch: 5| Step: 8
Training loss: 1.9489303827285767
Validation loss: 2.1423929686187417

Epoch: 5| Step: 9
Training loss: 2.4287173748016357
Validation loss: 2.0540105065991803

Epoch: 5| Step: 10
Training loss: 2.3371846675872803
Validation loss: 2.17161230118044

Epoch: 147| Step: 0
Training loss: 1.9297138452529907
Validation loss: 2.0965401895584597

Epoch: 5| Step: 1
Training loss: 1.6206649541854858
Validation loss: 2.1680301517568608

Epoch: 5| Step: 2
Training loss: 2.4407858848571777
Validation loss: 2.099080544646068

Epoch: 5| Step: 3
Training loss: 1.6950839757919312
Validation loss: 2.1582281333143993

Epoch: 5| Step: 4
Training loss: 1.8559942245483398
Validation loss: 2.081751782407043

Epoch: 5| Step: 5
Training loss: 2.4287781715393066
Validation loss: 2.1079959177201792

Epoch: 5| Step: 6
Training loss: 2.451836109161377
Validation loss: 2.0946983137438373

Epoch: 5| Step: 7
Training loss: 2.5930492877960205
Validation loss: 2.149830428502893

Epoch: 5| Step: 8
Training loss: 2.3581159114837646
Validation loss: 2.090445755630411

Epoch: 5| Step: 9
Training loss: 2.5897810459136963
Validation loss: 2.0267053906635573

Epoch: 5| Step: 10
Training loss: 2.218867063522339
Validation loss: 2.1584895810773297

Epoch: 148| Step: 0
Training loss: 1.8671642541885376
Validation loss: 2.1089605874912714

Epoch: 5| Step: 1
Training loss: 1.928491234779358
Validation loss: 2.1230145231370003

Epoch: 5| Step: 2
Training loss: 1.946903944015503
Validation loss: 2.1049587790684035

Epoch: 5| Step: 3
Training loss: 2.2036354541778564
Validation loss: 2.0694527651674006

Epoch: 5| Step: 4
Training loss: 2.1611175537109375
Validation loss: 2.1207681112391974

Epoch: 5| Step: 5
Training loss: 2.1859469413757324
Validation loss: 2.106268685351136

Epoch: 5| Step: 6
Training loss: 2.431731700897217
Validation loss: 2.119505477207963

Epoch: 5| Step: 7
Training loss: 1.8838484287261963
Validation loss: 2.116609920737564

Epoch: 5| Step: 8
Training loss: 2.1713874340057373
Validation loss: 2.134551960934875

Epoch: 5| Step: 9
Training loss: 2.2289059162139893
Validation loss: 2.0854219467409196

Epoch: 5| Step: 10
Training loss: 2.8622138500213623
Validation loss: 2.1072983793033067

Epoch: 149| Step: 0
Training loss: 2.140738010406494
Validation loss: 2.120361387088735

Epoch: 5| Step: 1
Training loss: 2.652855634689331
Validation loss: 2.117159128189087

Epoch: 5| Step: 2
Training loss: 2.1286346912384033
Validation loss: 2.1308586917897707

Epoch: 5| Step: 3
Training loss: 2.1732897758483887
Validation loss: 2.1327954876807427

Epoch: 5| Step: 4
Training loss: 2.307650327682495
Validation loss: 2.1059771173743793

Epoch: 5| Step: 5
Training loss: 2.209345817565918
Validation loss: 2.1531360944112143

Epoch: 5| Step: 6
Training loss: 1.7986571788787842
Validation loss: 2.1555552764605452

Epoch: 5| Step: 7
Training loss: 2.192972183227539
Validation loss: 2.1472569255418676

Epoch: 5| Step: 8
Training loss: 2.8083300590515137
Validation loss: 2.091318130493164

Epoch: 5| Step: 9
Training loss: 1.6853336095809937
Validation loss: 2.153056111387027

Epoch: 5| Step: 10
Training loss: 2.0782361030578613
Validation loss: 2.1089908153780046

Epoch: 150| Step: 0
Training loss: 1.9839553833007812
Validation loss: 2.1220140072607223

Epoch: 5| Step: 1
Training loss: 1.7008775472640991
Validation loss: 2.0716185864581855

Epoch: 5| Step: 2
Training loss: 2.358142614364624
Validation loss: 2.101990174221736

Epoch: 5| Step: 3
Training loss: 2.2654006481170654
Validation loss: 2.145044062727241

Epoch: 5| Step: 4
Training loss: 2.834840774536133
Validation loss: 2.1613070580267135

Epoch: 5| Step: 5
Training loss: 2.486311435699463
Validation loss: 2.092940999615577

Epoch: 5| Step: 6
Training loss: 1.8218166828155518
Validation loss: 2.09837306058535

Epoch: 5| Step: 7
Training loss: 1.7377656698226929
Validation loss: 2.0849457786929224

Epoch: 5| Step: 8
Training loss: 2.324591875076294
Validation loss: 2.1256952824131137

Epoch: 5| Step: 9
Training loss: 2.2602498531341553
Validation loss: 2.131284018998505

Epoch: 5| Step: 10
Training loss: 1.8939015865325928
Validation loss: 2.1308892414134037

Epoch: 151| Step: 0
Training loss: 1.4327954053878784
Validation loss: 2.1209447140334756

Epoch: 5| Step: 1
Training loss: 2.002027988433838
Validation loss: 2.091107347960113

Epoch: 5| Step: 2
Training loss: 2.302694797515869
Validation loss: 2.2420987365066365

Epoch: 5| Step: 3
Training loss: 1.9045391082763672
Validation loss: 2.157898874693019

Epoch: 5| Step: 4
Training loss: 2.26275372505188
Validation loss: 2.162703776872286

Epoch: 5| Step: 5
Training loss: 2.7069544792175293
Validation loss: 2.12672734004195

Epoch: 5| Step: 6
Training loss: 2.317453622817993
Validation loss: 2.211416002242796

Epoch: 5| Step: 7
Training loss: 1.9176666736602783
Validation loss: 2.092985676180932

Epoch: 5| Step: 8
Training loss: 2.0551271438598633
Validation loss: 2.120775920088573

Epoch: 5| Step: 9
Training loss: 2.0238261222839355
Validation loss: 2.1723342903198732

Epoch: 5| Step: 10
Training loss: 2.808382749557495
Validation loss: 2.1289574433398504

Epoch: 152| Step: 0
Training loss: 2.0329947471618652
Validation loss: 2.099842122806016

Epoch: 5| Step: 1
Training loss: 2.063213586807251
Validation loss: 2.170784404200892

Epoch: 5| Step: 2
Training loss: 2.3073089122772217
Validation loss: 2.1630314319364485

Epoch: 5| Step: 3
Training loss: 2.088597059249878
Validation loss: 2.1601934586801836

Epoch: 5| Step: 4
Training loss: 1.546870470046997
Validation loss: 2.1215975028212353

Epoch: 5| Step: 5
Training loss: 2.810973644256592
Validation loss: 2.103040074789396

Epoch: 5| Step: 6
Training loss: 2.210630416870117
Validation loss: 2.14827988993737

Epoch: 5| Step: 7
Training loss: 2.591858386993408
Validation loss: 2.1934147163103987

Epoch: 5| Step: 8
Training loss: 1.8971284627914429
Validation loss: 2.17138671875

Epoch: 5| Step: 9
Training loss: 1.9728807210922241
Validation loss: 2.1088248914287937

Epoch: 5| Step: 10
Training loss: 2.029569625854492
Validation loss: 2.072798971206911

Epoch: 153| Step: 0
Training loss: 1.720243215560913
Validation loss: 2.1244131608675887

Epoch: 5| Step: 1
Training loss: 2.157966375350952
Validation loss: 2.1665181767555977

Epoch: 5| Step: 2
Training loss: 2.7443950176239014
Validation loss: 2.1951729482220066

Epoch: 5| Step: 3
Training loss: 1.939332365989685
Validation loss: 2.1645274828839045

Epoch: 5| Step: 4
Training loss: 2.273716688156128
Validation loss: 2.1462388077089862

Epoch: 5| Step: 5
Training loss: 2.1163649559020996
Validation loss: 2.1217344268675773

Epoch: 5| Step: 6
Training loss: 2.415964126586914
Validation loss: 2.1057366863373788

Epoch: 5| Step: 7
Training loss: 1.6302086114883423
Validation loss: 2.1202404499053955

Epoch: 5| Step: 8
Training loss: 2.367335557937622
Validation loss: 2.168583316187705

Epoch: 5| Step: 9
Training loss: 2.737705945968628
Validation loss: 2.1061464445565337

Epoch: 5| Step: 10
Training loss: 2.1009044647216797
Validation loss: 2.109949952812605

Epoch: 154| Step: 0
Training loss: 2.6112582683563232
Validation loss: 2.0758608643726637

Epoch: 5| Step: 1
Training loss: 2.0798516273498535
Validation loss: 2.1203540294401106

Epoch: 5| Step: 2
Training loss: 1.7700914144515991
Validation loss: 2.0775698590022262

Epoch: 5| Step: 3
Training loss: 1.8454113006591797
Validation loss: 2.1563331029748403

Epoch: 5| Step: 4
Training loss: 2.2819223403930664
Validation loss: 2.143794923700312

Epoch: 5| Step: 5
Training loss: 2.6956067085266113
Validation loss: 2.1127612231880106

Epoch: 5| Step: 6
Training loss: 2.0166335105895996
Validation loss: 2.0948981879859843

Epoch: 5| Step: 7
Training loss: 2.211914300918579
Validation loss: 2.210082197702059

Epoch: 5| Step: 8
Training loss: 2.476722240447998
Validation loss: 2.115427573521932

Epoch: 5| Step: 9
Training loss: 2.00504469871521
Validation loss: 2.1710451572172103

Epoch: 5| Step: 10
Training loss: 1.8653265237808228
Validation loss: 2.163484614382508

Epoch: 155| Step: 0
Training loss: 1.6243518590927124
Validation loss: 2.0896671741239485

Epoch: 5| Step: 1
Training loss: 3.353350877761841
Validation loss: 2.113337903894404

Epoch: 5| Step: 2
Training loss: 1.6823228597640991
Validation loss: 2.142186798075194

Epoch: 5| Step: 3
Training loss: 2.7593021392822266
Validation loss: 2.1106629371643066

Epoch: 5| Step: 4
Training loss: 2.526027202606201
Validation loss: 2.1773284917236655

Epoch: 5| Step: 5
Training loss: 1.2705179452896118
Validation loss: 2.1241991443018757

Epoch: 5| Step: 6
Training loss: 2.3560729026794434
Validation loss: 2.1978376539804603

Epoch: 5| Step: 7
Training loss: 2.369652509689331
Validation loss: 2.092579786495496

Epoch: 5| Step: 8
Training loss: 2.1324620246887207
Validation loss: 2.154349737269904

Epoch: 5| Step: 9
Training loss: 2.1561505794525146
Validation loss: 2.1941109652160318

Epoch: 5| Step: 10
Training loss: 1.5201879739761353
Validation loss: 2.1581777167576615

Epoch: 156| Step: 0
Training loss: 2.2148983478546143
Validation loss: 2.0847520956429104

Epoch: 5| Step: 1
Training loss: 2.3350329399108887
Validation loss: 2.1484525049886396

Epoch: 5| Step: 2
Training loss: 2.1196823120117188
Validation loss: 2.1166496199946248

Epoch: 5| Step: 3
Training loss: 2.1285548210144043
Validation loss: 2.05232923517945

Epoch: 5| Step: 4
Training loss: 1.6659977436065674
Validation loss: 2.0703881273987474

Epoch: 5| Step: 5
Training loss: 2.9912772178649902
Validation loss: 2.1883058547973633

Epoch: 5| Step: 6
Training loss: 1.6663204431533813
Validation loss: 2.1248696414373254

Epoch: 5| Step: 7
Training loss: 1.2192869186401367
Validation loss: 2.112849450880481

Epoch: 5| Step: 8
Training loss: 2.2955422401428223
Validation loss: 2.1186838790934575

Epoch: 5| Step: 9
Training loss: 2.621727228164673
Validation loss: 2.0727554213616157

Epoch: 5| Step: 10
Training loss: 2.5763766765594482
Validation loss: 2.086746420911563

Epoch: 157| Step: 0
Training loss: 2.0279974937438965
Validation loss: 2.0980200664971465

Epoch: 5| Step: 1
Training loss: 2.385222911834717
Validation loss: 2.1443645620858796

Epoch: 5| Step: 2
Training loss: 1.9667987823486328
Validation loss: 2.108735881825929

Epoch: 5| Step: 3
Training loss: 2.3893425464630127
Validation loss: 2.159141380299804

Epoch: 5| Step: 4
Training loss: 2.496375560760498
Validation loss: 2.1169749767549577

Epoch: 5| Step: 5
Training loss: 1.7257347106933594
Validation loss: 2.167420075785729

Epoch: 5| Step: 6
Training loss: 1.9110355377197266
Validation loss: 2.1828957578187347

Epoch: 5| Step: 7
Training loss: 2.371121644973755
Validation loss: 2.1087811775104974

Epoch: 5| Step: 8
Training loss: 2.2665600776672363
Validation loss: 2.134249294957807

Epoch: 5| Step: 9
Training loss: 2.2212586402893066
Validation loss: 2.0963113769408195

Epoch: 5| Step: 10
Training loss: 2.147645950317383
Validation loss: 2.1732146278504403

Epoch: 158| Step: 0
Training loss: 1.9954484701156616
Validation loss: 2.1097750458666074

Epoch: 5| Step: 1
Training loss: 2.6120026111602783
Validation loss: 2.1024044893121205

Epoch: 5| Step: 2
Training loss: 1.8968931436538696
Validation loss: 2.144845788196851

Epoch: 5| Step: 3
Training loss: 2.3614449501037598
Validation loss: 2.180014069362353

Epoch: 5| Step: 4
Training loss: 2.2734713554382324
Validation loss: 2.1413598368244786

Epoch: 5| Step: 5
Training loss: 2.2851099967956543
Validation loss: 2.1200124807255243

Epoch: 5| Step: 6
Training loss: 1.7752940654754639
Validation loss: 2.1258165785061416

Epoch: 5| Step: 7
Training loss: 2.23822283744812
Validation loss: 2.1835477993052494

Epoch: 5| Step: 8
Training loss: 2.7087912559509277
Validation loss: 2.1395805010231594

Epoch: 5| Step: 9
Training loss: 1.5435174703598022
Validation loss: 2.135387402708812

Epoch: 5| Step: 10
Training loss: 2.0430028438568115
Validation loss: 2.0695532496257494

Epoch: 159| Step: 0
Training loss: 2.2041938304901123
Validation loss: 2.1830513374779814

Epoch: 5| Step: 1
Training loss: 2.2533011436462402
Validation loss: 2.032283518903999

Epoch: 5| Step: 2
Training loss: 2.684418201446533
Validation loss: 2.1440425431856545

Epoch: 5| Step: 3
Training loss: 2.026259660720825
Validation loss: 2.156940601205313

Epoch: 5| Step: 4
Training loss: 1.6151692867279053
Validation loss: 2.1815439014024633

Epoch: 5| Step: 5
Training loss: 1.8639904260635376
Validation loss: 2.114529493034527

Epoch: 5| Step: 6
Training loss: 2.4499518871307373
Validation loss: 2.1795541573596258

Epoch: 5| Step: 7
Training loss: 2.2935702800750732
Validation loss: 2.130244593466482

Epoch: 5| Step: 8
Training loss: 2.885481357574463
Validation loss: 2.152677746229274

Epoch: 5| Step: 9
Training loss: 1.722899079322815
Validation loss: 2.074435717316084

Epoch: 5| Step: 10
Training loss: 1.5925114154815674
Validation loss: 2.0836968627027286

Epoch: 160| Step: 0
Training loss: 2.4619178771972656
Validation loss: 2.1212484708396335

Epoch: 5| Step: 1
Training loss: 2.2582130432128906
Validation loss: 2.1088594057226695

Epoch: 5| Step: 2
Training loss: 2.0267438888549805
Validation loss: 2.22097376854189

Epoch: 5| Step: 3
Training loss: 2.0800843238830566
Validation loss: 2.162059289152904

Epoch: 5| Step: 4
Training loss: 2.4742672443389893
Validation loss: 2.11276803862664

Epoch: 5| Step: 5
Training loss: 2.3923230171203613
Validation loss: 2.1507538851871284

Epoch: 5| Step: 6
Training loss: 1.8506847620010376
Validation loss: 2.1725274247507893

Epoch: 5| Step: 7
Training loss: 1.9562139511108398
Validation loss: 2.1504991951809136

Epoch: 5| Step: 8
Training loss: 1.608173131942749
Validation loss: 2.209392488643687

Epoch: 5| Step: 9
Training loss: 2.773258924484253
Validation loss: 2.1233458313890683

Epoch: 5| Step: 10
Training loss: 2.0349936485290527
Validation loss: 2.1485786168806014

Epoch: 161| Step: 0
Training loss: 2.076469898223877
Validation loss: 2.120891729990641

Epoch: 5| Step: 1
Training loss: 2.374718427658081
Validation loss: 2.0953005039563743

Epoch: 5| Step: 2
Training loss: 1.6658124923706055
Validation loss: 2.116706368743732

Epoch: 5| Step: 3
Training loss: 1.96832275390625
Validation loss: 2.1217867533365884

Epoch: 5| Step: 4
Training loss: 2.8024139404296875
Validation loss: 2.061057847033265

Epoch: 5| Step: 5
Training loss: 2.3112242221832275
Validation loss: 2.1694448712051555

Epoch: 5| Step: 6
Training loss: 2.44156813621521
Validation loss: 2.1372367720450125

Epoch: 5| Step: 7
Training loss: 2.284254550933838
Validation loss: 2.133536757961396

Epoch: 5| Step: 8
Training loss: 1.4597275257110596
Validation loss: 2.1681446567658456

Epoch: 5| Step: 9
Training loss: 2.2712836265563965
Validation loss: 2.141536831855774

Epoch: 5| Step: 10
Training loss: 2.134660243988037
Validation loss: 2.168145097712035

Epoch: 162| Step: 0
Training loss: 2.0008907318115234
Validation loss: 2.1463419557899557

Epoch: 5| Step: 1
Training loss: 2.2403178215026855
Validation loss: 2.0888087390571513

Epoch: 5| Step: 2
Training loss: 2.8013949394226074
Validation loss: 2.1486553069083922

Epoch: 5| Step: 3
Training loss: 2.2384278774261475
Validation loss: 2.193925662707257

Epoch: 5| Step: 4
Training loss: 1.5696866512298584
Validation loss: 2.153412667653894

Epoch: 5| Step: 5
Training loss: 2.1114089488983154
Validation loss: 2.120561288249108

Epoch: 5| Step: 6
Training loss: 2.146055221557617
Validation loss: 2.176409211210025

Epoch: 5| Step: 7
Training loss: 1.9370145797729492
Validation loss: 2.1087081893797843

Epoch: 5| Step: 8
Training loss: 1.819745421409607
Validation loss: 2.1587141918879684

Epoch: 5| Step: 9
Training loss: 2.169081926345825
Validation loss: 2.1848652542278333

Epoch: 5| Step: 10
Training loss: 2.441628932952881
Validation loss: 2.1325037633219073

Epoch: 163| Step: 0
Training loss: 2.1954078674316406
Validation loss: 2.106753497995356

Epoch: 5| Step: 1
Training loss: 2.355252742767334
Validation loss: 2.081735195652131

Epoch: 5| Step: 2
Training loss: 2.1320106983184814
Validation loss: 2.1206539087398077

Epoch: 5| Step: 3
Training loss: 1.453301191329956
Validation loss: 2.1782173828412126

Epoch: 5| Step: 4
Training loss: 1.3352735042572021
Validation loss: 2.1515946849699943

Epoch: 5| Step: 5
Training loss: 2.4668924808502197
Validation loss: 2.164084149945167

Epoch: 5| Step: 6
Training loss: 2.6697216033935547
Validation loss: 2.0609101377507693

Epoch: 5| Step: 7
Training loss: 2.5902655124664307
Validation loss: 2.1151290875609203

Epoch: 5| Step: 8
Training loss: 2.5710766315460205
Validation loss: 2.075203405913486

Epoch: 5| Step: 9
Training loss: 2.060163974761963
Validation loss: 2.096543042890487

Epoch: 5| Step: 10
Training loss: 2.5298233032226562
Validation loss: 2.105731310382966

Epoch: 164| Step: 0
Training loss: 2.8544087409973145
Validation loss: 2.0539736875923733

Epoch: 5| Step: 1
Training loss: 2.0347166061401367
Validation loss: 2.167431551923034

Epoch: 5| Step: 2
Training loss: 2.45652437210083
Validation loss: 2.1427231065688597

Epoch: 5| Step: 3
Training loss: 2.2331321239471436
Validation loss: 2.030848367239839

Epoch: 5| Step: 4
Training loss: 2.577784538269043
Validation loss: 2.0683052232188563

Epoch: 5| Step: 5
Training loss: 1.3640555143356323
Validation loss: 2.1533962680447485

Epoch: 5| Step: 6
Training loss: 2.1582329273223877
Validation loss: 2.1685958036812405

Epoch: 5| Step: 7
Training loss: 1.3216779232025146
Validation loss: 2.0811961338084233

Epoch: 5| Step: 8
Training loss: 2.474355459213257
Validation loss: 2.1181993535769883

Epoch: 5| Step: 9
Training loss: 2.2257766723632812
Validation loss: 2.1425453129635064

Epoch: 5| Step: 10
Training loss: 2.452669620513916
Validation loss: 2.1185906112834973

Epoch: 165| Step: 0
Training loss: 2.0200352668762207
Validation loss: 2.088595764611357

Epoch: 5| Step: 1
Training loss: 2.07848858833313
Validation loss: 2.103732024469683

Epoch: 5| Step: 2
Training loss: 2.027784824371338
Validation loss: 2.125791177954725

Epoch: 5| Step: 3
Training loss: 2.2244491577148438
Validation loss: 2.1099780759503766

Epoch: 5| Step: 4
Training loss: 2.5230414867401123
Validation loss: 2.074054851326891

Epoch: 5| Step: 5
Training loss: 2.1124777793884277
Validation loss: 2.128166417921743

Epoch: 5| Step: 6
Training loss: 2.754495620727539
Validation loss: 2.1668094383772982

Epoch: 5| Step: 7
Training loss: 1.2592638731002808
Validation loss: 2.1045669278790875

Epoch: 5| Step: 8
Training loss: 2.971799850463867
Validation loss: 2.158981684715517

Epoch: 5| Step: 9
Training loss: 1.9463955163955688
Validation loss: 2.1535162336082867

Epoch: 5| Step: 10
Training loss: 2.027634382247925
Validation loss: 2.1533594977471138

Epoch: 166| Step: 0
Training loss: 1.8175243139266968
Validation loss: 2.1882257307729414

Epoch: 5| Step: 1
Training loss: 2.377009868621826
Validation loss: 2.0634705123081

Epoch: 5| Step: 2
Training loss: 2.428142786026001
Validation loss: 2.2228450980237735

Epoch: 5| Step: 3
Training loss: 3.0134778022766113
Validation loss: 2.22948351470373

Epoch: 5| Step: 4
Training loss: 2.153731107711792
Validation loss: 2.2132753069682787

Epoch: 5| Step: 5
Training loss: 1.7767480611801147
Validation loss: 2.141648946269866

Epoch: 5| Step: 6
Training loss: 2.2704246044158936
Validation loss: 2.2352313662088044

Epoch: 5| Step: 7
Training loss: 1.8948863744735718
Validation loss: 2.1747094982413837

Epoch: 5| Step: 8
Training loss: 1.8239368200302124
Validation loss: 2.14339982053285

Epoch: 5| Step: 9
Training loss: 2.202414035797119
Validation loss: 2.2062666108531337

Epoch: 5| Step: 10
Training loss: 1.8408386707305908
Validation loss: 2.114110436490787

Epoch: 167| Step: 0
Training loss: 2.0963268280029297
Validation loss: 2.1264579783203783

Epoch: 5| Step: 1
Training loss: 1.692091703414917
Validation loss: 2.1512272716850362

Epoch: 5| Step: 2
Training loss: 1.9857794046401978
Validation loss: 2.1433485015746085

Epoch: 5| Step: 3
Training loss: 1.7313077449798584
Validation loss: 2.2069839380120717

Epoch: 5| Step: 4
Training loss: 1.6948821544647217
Validation loss: 2.1325149305405153

Epoch: 5| Step: 5
Training loss: 2.432180404663086
Validation loss: 2.1407485033876155

Epoch: 5| Step: 6
Training loss: 1.9507858753204346
Validation loss: 2.119227809290732

Epoch: 5| Step: 7
Training loss: 2.4757707118988037
Validation loss: 2.1397655753679174

Epoch: 5| Step: 8
Training loss: 2.462641477584839
Validation loss: 2.042846877087829

Epoch: 5| Step: 9
Training loss: 2.312028408050537
Validation loss: 2.096581733354958

Epoch: 5| Step: 10
Training loss: 2.8484528064727783
Validation loss: 2.1432980273359563

Epoch: 168| Step: 0
Training loss: 1.6149240732192993
Validation loss: 2.125627430536414

Epoch: 5| Step: 1
Training loss: 2.652834892272949
Validation loss: 2.1866392525293494

Epoch: 5| Step: 2
Training loss: 1.6319262981414795
Validation loss: 2.119502503384826

Epoch: 5| Step: 3
Training loss: 1.8551673889160156
Validation loss: 2.1489932075623543

Epoch: 5| Step: 4
Training loss: 1.9034793376922607
Validation loss: 2.159334573694455

Epoch: 5| Step: 5
Training loss: 2.4964816570281982
Validation loss: 2.154954946169289

Epoch: 5| Step: 6
Training loss: 3.0377840995788574
Validation loss: 2.0383275298662085

Epoch: 5| Step: 7
Training loss: 2.257073163986206
Validation loss: 2.0811111234849498

Epoch: 5| Step: 8
Training loss: 1.938066840171814
Validation loss: 2.1223603974106493

Epoch: 5| Step: 9
Training loss: 1.744579553604126
Validation loss: 2.1029880175026516

Epoch: 5| Step: 10
Training loss: 2.4152610301971436
Validation loss: 2.176116879268359

Epoch: 169| Step: 0
Training loss: 2.016960859298706
Validation loss: 2.1019959321586033

Epoch: 5| Step: 1
Training loss: 2.275590658187866
Validation loss: 2.161652003565142

Epoch: 5| Step: 2
Training loss: 2.044292688369751
Validation loss: 2.138103441525531

Epoch: 5| Step: 3
Training loss: 2.294027805328369
Validation loss: 2.1703205647007113

Epoch: 5| Step: 4
Training loss: 1.8330341577529907
Validation loss: 2.1446140145742767

Epoch: 5| Step: 5
Training loss: 2.21825909614563
Validation loss: 2.080397803296325

Epoch: 5| Step: 6
Training loss: 2.39286470413208
Validation loss: 2.112399637058217

Epoch: 5| Step: 7
Training loss: 2.2253355979919434
Validation loss: 2.141929223973264

Epoch: 5| Step: 8
Training loss: 2.1870617866516113
Validation loss: 2.0921566768359114

Epoch: 5| Step: 9
Training loss: 2.362757921218872
Validation loss: 2.071552058701874

Epoch: 5| Step: 10
Training loss: 2.3308873176574707
Validation loss: 2.138714941599036

Epoch: 170| Step: 0
Training loss: 1.8296467065811157
Validation loss: 2.129397822964576

Epoch: 5| Step: 1
Training loss: 1.9106452465057373
Validation loss: 2.1447235051021782

Epoch: 5| Step: 2
Training loss: 1.9915443658828735
Validation loss: 2.0987479097099713

Epoch: 5| Step: 3
Training loss: 2.068566083908081
Validation loss: 2.143400192260742

Epoch: 5| Step: 4
Training loss: 2.288978099822998
Validation loss: 2.1965305228387155

Epoch: 5| Step: 5
Training loss: 2.145733594894409
Validation loss: 2.1203657555323776

Epoch: 5| Step: 6
Training loss: 2.3114264011383057
Validation loss: 2.208708022230415

Epoch: 5| Step: 7
Training loss: 2.199188470840454
Validation loss: 2.2090259393056235

Epoch: 5| Step: 8
Training loss: 2.138280153274536
Validation loss: 2.152126173819265

Epoch: 5| Step: 9
Training loss: 2.4940667152404785
Validation loss: 2.1888415326354322

Epoch: 5| Step: 10
Training loss: 2.201906442642212
Validation loss: 2.129727425113801

Epoch: 171| Step: 0
Training loss: 1.7404191493988037
Validation loss: 2.2281401003560712

Epoch: 5| Step: 1
Training loss: 2.418807029724121
Validation loss: 2.1629087886502667

Epoch: 5| Step: 2
Training loss: 2.199950695037842
Validation loss: 2.0882936767352525

Epoch: 5| Step: 3
Training loss: 2.2093186378479004
Validation loss: 2.1527004113761325

Epoch: 5| Step: 4
Training loss: 2.18585467338562
Validation loss: 2.1620704473987704

Epoch: 5| Step: 5
Training loss: 2.249448299407959
Validation loss: 2.085193239232545

Epoch: 5| Step: 6
Training loss: 2.018852949142456
Validation loss: 2.221587780983217

Epoch: 5| Step: 7
Training loss: 2.229382276535034
Validation loss: 2.191386907331405

Epoch: 5| Step: 8
Training loss: 2.1437301635742188
Validation loss: 2.0894282646076654

Epoch: 5| Step: 9
Training loss: 2.2938003540039062
Validation loss: 2.1433339452230804

Epoch: 5| Step: 10
Training loss: 1.4699413776397705
Validation loss: 2.1385591619758197

Epoch: 172| Step: 0
Training loss: 1.9909045696258545
Validation loss: 2.1459334511910715

Epoch: 5| Step: 1
Training loss: 1.4906260967254639
Validation loss: 2.2053705389781664

Epoch: 5| Step: 2
Training loss: 2.8260436058044434
Validation loss: 2.1173212400046726

Epoch: 5| Step: 3
Training loss: 2.428576946258545
Validation loss: 2.1322151050772717

Epoch: 5| Step: 4
Training loss: 1.5106561183929443
Validation loss: 2.0931431388342254

Epoch: 5| Step: 5
Training loss: 2.1669325828552246
Validation loss: 2.133095828435754

Epoch: 5| Step: 6
Training loss: 2.005342483520508
Validation loss: 2.1819615517893145

Epoch: 5| Step: 7
Training loss: 1.5024057626724243
Validation loss: 2.136401887862913

Epoch: 5| Step: 8
Training loss: 2.924900770187378
Validation loss: 2.113278350522441

Epoch: 5| Step: 9
Training loss: 2.4725306034088135
Validation loss: 2.088596070966413

Epoch: 5| Step: 10
Training loss: 1.8705452680587769
Validation loss: 2.1111309707805677

Epoch: 173| Step: 0
Training loss: 2.8391273021698
Validation loss: 2.112252991686585

Epoch: 5| Step: 1
Training loss: 1.221043348312378
Validation loss: 2.114528491932859

Epoch: 5| Step: 2
Training loss: 2.456251382827759
Validation loss: 2.1516478420585714

Epoch: 5| Step: 3
Training loss: 1.9605381488800049
Validation loss: 2.1498105064515145

Epoch: 5| Step: 4
Training loss: 2.7003352642059326
Validation loss: 2.1614401084120556

Epoch: 5| Step: 5
Training loss: 1.485887885093689
Validation loss: 2.148733368483923

Epoch: 5| Step: 6
Training loss: 2.41818904876709
Validation loss: 2.1675224637472503

Epoch: 5| Step: 7
Training loss: 1.8080885410308838
Validation loss: 2.0942994112609536

Epoch: 5| Step: 8
Training loss: 2.514801025390625
Validation loss: 2.1629178318926083

Epoch: 5| Step: 9
Training loss: 2.4068140983581543
Validation loss: 2.1353531947699924

Epoch: 5| Step: 10
Training loss: 1.937205195426941
Validation loss: 2.2597096696976693

Epoch: 174| Step: 0
Training loss: 1.9137989282608032
Validation loss: 2.102357551615725

Epoch: 5| Step: 1
Training loss: 1.658116102218628
Validation loss: 2.17421454768027

Epoch: 5| Step: 2
Training loss: 2.6007258892059326
Validation loss: 2.113139843428007

Epoch: 5| Step: 3
Training loss: 1.304914116859436
Validation loss: 2.157791030022406

Epoch: 5| Step: 4
Training loss: 2.5083823204040527
Validation loss: 2.1856170982442875

Epoch: 5| Step: 5
Training loss: 1.4607925415039062
Validation loss: 2.1245729974521104

Epoch: 5| Step: 6
Training loss: 2.7333099842071533
Validation loss: 2.193048546391149

Epoch: 5| Step: 7
Training loss: 2.5925629138946533
Validation loss: 2.190866603646227

Epoch: 5| Step: 8
Training loss: 2.3527355194091797
Validation loss: 2.12372931357353

Epoch: 5| Step: 9
Training loss: 2.415673017501831
Validation loss: 2.179510226813696

Epoch: 5| Step: 10
Training loss: 2.0932679176330566
Validation loss: 2.060088662691014

Epoch: 175| Step: 0
Training loss: 2.647015333175659
Validation loss: 2.130285175897742

Epoch: 5| Step: 1
Training loss: 1.4652267694473267
Validation loss: 2.147113128374982

Epoch: 5| Step: 2
Training loss: 2.219210147857666
Validation loss: 2.133890087886523

Epoch: 5| Step: 3
Training loss: 2.3876824378967285
Validation loss: 2.111196862754001

Epoch: 5| Step: 4
Training loss: 1.736806869506836
Validation loss: 2.114027818044027

Epoch: 5| Step: 5
Training loss: 1.7354494333267212
Validation loss: 2.113296672862063

Epoch: 5| Step: 6
Training loss: 2.862725019454956
Validation loss: 2.135675771262056

Epoch: 5| Step: 7
Training loss: 1.760353446006775
Validation loss: 2.1871632888752925

Epoch: 5| Step: 8
Training loss: 2.350473403930664
Validation loss: 2.174524943033854

Epoch: 5| Step: 9
Training loss: 2.238110065460205
Validation loss: 2.115079374723537

Epoch: 5| Step: 10
Training loss: 2.051009178161621
Validation loss: 1.9978027805205314

Epoch: 176| Step: 0
Training loss: 2.2073190212249756
Validation loss: 2.1701915776857765

Epoch: 5| Step: 1
Training loss: 2.2551963329315186
Validation loss: 2.149053999172744

Epoch: 5| Step: 2
Training loss: 2.0622377395629883
Validation loss: 2.1451383149752052

Epoch: 5| Step: 3
Training loss: 1.9664815664291382
Validation loss: 2.1167947746092275

Epoch: 5| Step: 4
Training loss: 1.8549836874008179
Validation loss: 2.1528899541465183

Epoch: 5| Step: 5
Training loss: 2.6240029335021973
Validation loss: 2.1619165725605463

Epoch: 5| Step: 6
Training loss: 1.9150092601776123
Validation loss: 2.2325554688771567

Epoch: 5| Step: 7
Training loss: 2.6311378479003906
Validation loss: 2.179805158286966

Epoch: 5| Step: 8
Training loss: 1.7288068532943726
Validation loss: 2.1675963081339353

Epoch: 5| Step: 9
Training loss: 2.457691192626953
Validation loss: 2.2031197419730564

Epoch: 5| Step: 10
Training loss: 1.5761785507202148
Validation loss: 2.0913019052115818

Epoch: 177| Step: 0
Training loss: 1.461614966392517
Validation loss: 2.181148975126205

Epoch: 5| Step: 1
Training loss: 2.2004024982452393
Validation loss: 2.1585039579740135

Epoch: 5| Step: 2
Training loss: 1.969930648803711
Validation loss: 2.197177921572039

Epoch: 5| Step: 3
Training loss: 2.28554105758667
Validation loss: 2.2043200641550045

Epoch: 5| Step: 4
Training loss: 2.1792609691619873
Validation loss: 2.1701085721292803

Epoch: 5| Step: 5
Training loss: 2.607912540435791
Validation loss: 2.137399358134116

Epoch: 5| Step: 6
Training loss: 2.1083483695983887
Validation loss: 2.125055656638197

Epoch: 5| Step: 7
Training loss: 2.3691577911376953
Validation loss: 2.1162497074373308

Epoch: 5| Step: 8
Training loss: 2.7167446613311768
Validation loss: 2.178786587971513

Epoch: 5| Step: 9
Training loss: 2.24206280708313
Validation loss: 2.17072174626012

Epoch: 5| Step: 10
Training loss: 1.8710047006607056
Validation loss: 2.1427610228138585

Epoch: 178| Step: 0
Training loss: 2.7060739994049072
Validation loss: 2.1999548494174914

Epoch: 5| Step: 1
Training loss: 1.9066917896270752
Validation loss: 2.147650809698207

Epoch: 5| Step: 2
Training loss: 2.1734132766723633
Validation loss: 2.1182276818060104

Epoch: 5| Step: 3
Training loss: 2.021740436553955
Validation loss: 2.1517172346832933

Epoch: 5| Step: 4
Training loss: 1.5902576446533203
Validation loss: 2.1332907792060607

Epoch: 5| Step: 5
Training loss: 2.2090866565704346
Validation loss: 2.161996051829348

Epoch: 5| Step: 6
Training loss: 2.091278314590454
Validation loss: 2.1995310386021933

Epoch: 5| Step: 7
Training loss: 1.9321616888046265
Validation loss: 2.170499386325959

Epoch: 5| Step: 8
Training loss: 2.404946804046631
Validation loss: 2.143156715618667

Epoch: 5| Step: 9
Training loss: 2.049797534942627
Validation loss: 2.1872908607605965

Epoch: 5| Step: 10
Training loss: 1.9068071842193604
Validation loss: 2.1179911462209557

Epoch: 179| Step: 0
Training loss: 2.044658660888672
Validation loss: 2.086523312394337

Epoch: 5| Step: 1
Training loss: 2.161078691482544
Validation loss: 2.1680205560499624

Epoch: 5| Step: 2
Training loss: 1.698714256286621
Validation loss: 2.1030216499041487

Epoch: 5| Step: 3
Training loss: 2.6141505241394043
Validation loss: 2.1331242284467145

Epoch: 5| Step: 4
Training loss: 2.023139238357544
Validation loss: 2.1196713139933925

Epoch: 5| Step: 5
Training loss: 2.467238187789917
Validation loss: 2.107012878182114

Epoch: 5| Step: 6
Training loss: 2.425248622894287
Validation loss: 2.1423029233050603

Epoch: 5| Step: 7
Training loss: 1.6580263376235962
Validation loss: 2.1502641913711384

Epoch: 5| Step: 8
Training loss: 2.429831027984619
Validation loss: 2.1374285785100793

Epoch: 5| Step: 9
Training loss: 1.7350133657455444
Validation loss: 2.1291397028071906

Epoch: 5| Step: 10
Training loss: 2.169614315032959
Validation loss: 2.100837617792109

Epoch: 180| Step: 0
Training loss: 1.8387248516082764
Validation loss: 2.1544072371657177

Epoch: 5| Step: 1
Training loss: 2.694319248199463
Validation loss: 2.118562388163741

Epoch: 5| Step: 2
Training loss: 2.034125804901123
Validation loss: 2.116790453592936

Epoch: 5| Step: 3
Training loss: 2.5007145404815674
Validation loss: 2.141380871495893

Epoch: 5| Step: 4
Training loss: 1.7053918838500977
Validation loss: 2.091578701490997

Epoch: 5| Step: 5
Training loss: 1.5468127727508545
Validation loss: 2.111105940675223

Epoch: 5| Step: 6
Training loss: 1.9640045166015625
Validation loss: 2.1371584143689883

Epoch: 5| Step: 7
Training loss: 2.1416938304901123
Validation loss: 2.1332992148655716

Epoch: 5| Step: 8
Training loss: 1.9191192388534546
Validation loss: 2.1554952257422992

Epoch: 5| Step: 9
Training loss: 2.6375107765197754
Validation loss: 2.127560273293526

Epoch: 5| Step: 10
Training loss: 2.307107925415039
Validation loss: 2.1264489337962162

Epoch: 181| Step: 0
Training loss: 1.9792076349258423
Validation loss: 2.1286990206728698

Epoch: 5| Step: 1
Training loss: 1.7354300022125244
Validation loss: 2.118861230470801

Epoch: 5| Step: 2
Training loss: 2.128441095352173
Validation loss: 2.1476446787516275

Epoch: 5| Step: 3
Training loss: 1.5389646291732788
Validation loss: 2.1808189653581187

Epoch: 5| Step: 4
Training loss: 2.3744101524353027
Validation loss: 2.188076647379065

Epoch: 5| Step: 5
Training loss: 1.9965026378631592
Validation loss: 2.1203866594581195

Epoch: 5| Step: 6
Training loss: 2.124343156814575
Validation loss: 2.135974309777701

Epoch: 5| Step: 7
Training loss: 3.237687587738037
Validation loss: 2.120687287340882

Epoch: 5| Step: 8
Training loss: 2.047666072845459
Validation loss: 2.2088742538165023

Epoch: 5| Step: 9
Training loss: 2.5464415550231934
Validation loss: 2.2096335516181043

Epoch: 5| Step: 10
Training loss: 2.098203182220459
Validation loss: 2.1476399257618892

Epoch: 182| Step: 0
Training loss: 1.3103309869766235
Validation loss: 2.1393455561771186

Epoch: 5| Step: 1
Training loss: 1.8818645477294922
Validation loss: 2.120396069301072

Epoch: 5| Step: 2
Training loss: 2.8441290855407715
Validation loss: 2.047272874462989

Epoch: 5| Step: 3
Training loss: 2.3550524711608887
Validation loss: 2.1588167785316386

Epoch: 5| Step: 4
Training loss: 1.6422107219696045
Validation loss: 2.189843880232944

Epoch: 5| Step: 5
Training loss: 2.336815357208252
Validation loss: 2.167379676654775

Epoch: 5| Step: 6
Training loss: 1.8979761600494385
Validation loss: 2.169017186728857

Epoch: 5| Step: 7
Training loss: 2.4284205436706543
Validation loss: 2.1449558311893093

Epoch: 5| Step: 8
Training loss: 2.3583052158355713
Validation loss: 2.1533052229112193

Epoch: 5| Step: 9
Training loss: 2.279623508453369
Validation loss: 2.126188232052711

Epoch: 5| Step: 10
Training loss: 1.8096625804901123
Validation loss: 2.16835198351132

Epoch: 183| Step: 0
Training loss: 2.8287181854248047
Validation loss: 2.151070579405754

Epoch: 5| Step: 1
Training loss: 2.799976348876953
Validation loss: 2.1470207873211113

Epoch: 5| Step: 2
Training loss: 2.325866222381592
Validation loss: 2.172878352544641

Epoch: 5| Step: 3
Training loss: 1.3944106101989746
Validation loss: 2.1899139458133328

Epoch: 5| Step: 4
Training loss: 2.166339635848999
Validation loss: 2.174985272910005

Epoch: 5| Step: 5
Training loss: 1.9249343872070312
Validation loss: 2.107484495767983

Epoch: 5| Step: 6
Training loss: 1.6286704540252686
Validation loss: 2.104647572322558

Epoch: 5| Step: 7
Training loss: 2.5796751976013184
Validation loss: 2.1371793952039493

Epoch: 5| Step: 8
Training loss: 1.824753999710083
Validation loss: 2.199821141458327

Epoch: 5| Step: 9
Training loss: 1.9098832607269287
Validation loss: 2.1493486255727787

Epoch: 5| Step: 10
Training loss: 2.164372205734253
Validation loss: 2.1680348791101927

Epoch: 184| Step: 0
Training loss: 2.099869966506958
Validation loss: 2.139715809975901

Epoch: 5| Step: 1
Training loss: 2.2457141876220703
Validation loss: 2.1722146849478445

Epoch: 5| Step: 2
Training loss: 2.488354444503784
Validation loss: 2.0935815072828725

Epoch: 5| Step: 3
Training loss: 2.177136182785034
Validation loss: 2.237141478446222

Epoch: 5| Step: 4
Training loss: 2.047212600708008
Validation loss: 2.227815674197289

Epoch: 5| Step: 5
Training loss: 2.13574481010437
Validation loss: 2.114407188148909

Epoch: 5| Step: 6
Training loss: 2.40258526802063
Validation loss: 2.093407561702113

Epoch: 5| Step: 7
Training loss: 1.502976894378662
Validation loss: 2.1471432665342927

Epoch: 5| Step: 8
Training loss: 1.699170708656311
Validation loss: 2.1036038962743615

Epoch: 5| Step: 9
Training loss: 2.357245922088623
Validation loss: 2.1634364205022014

Epoch: 5| Step: 10
Training loss: 2.1146228313446045
Validation loss: 2.1411871474276305

Epoch: 185| Step: 0
Training loss: 2.921619415283203
Validation loss: 2.083552460516653

Epoch: 5| Step: 1
Training loss: 2.4832186698913574
Validation loss: 2.091206407034269

Epoch: 5| Step: 2
Training loss: 1.9676973819732666
Validation loss: 2.0926986150844122

Epoch: 5| Step: 3
Training loss: 1.694014310836792
Validation loss: 2.206600204590828

Epoch: 5| Step: 4
Training loss: 1.8056758642196655
Validation loss: 2.086650712515718

Epoch: 5| Step: 5
Training loss: 2.2605912685394287
Validation loss: 2.089347195881669

Epoch: 5| Step: 6
Training loss: 1.9977928400039673
Validation loss: 2.1110152736786874

Epoch: 5| Step: 7
Training loss: 2.071462869644165
Validation loss: 2.1363770731033815

Epoch: 5| Step: 8
Training loss: 2.6666107177734375
Validation loss: 2.1437529799758748

Epoch: 5| Step: 9
Training loss: 1.5618010759353638
Validation loss: 2.1776976200842086

Epoch: 5| Step: 10
Training loss: 2.1016685962677
Validation loss: 2.1302057363653697

Epoch: 186| Step: 0
Training loss: 2.1221752166748047
Validation loss: 2.1346214420051983

Epoch: 5| Step: 1
Training loss: 1.8346469402313232
Validation loss: 2.130179159102901

Epoch: 5| Step: 2
Training loss: 2.0986809730529785
Validation loss: 2.1332598014544417

Epoch: 5| Step: 3
Training loss: 2.167320489883423
Validation loss: 2.1445698122824393

Epoch: 5| Step: 4
Training loss: 1.6513607501983643
Validation loss: 2.1083544146630073

Epoch: 5| Step: 5
Training loss: 2.1609654426574707
Validation loss: 2.1017734312242076

Epoch: 5| Step: 6
Training loss: 2.4059085845947266
Validation loss: 2.1681348303312897

Epoch: 5| Step: 7
Training loss: 2.017691135406494
Validation loss: 2.0923586994089107

Epoch: 5| Step: 8
Training loss: 2.3854079246520996
Validation loss: 2.172884141245196

Epoch: 5| Step: 9
Training loss: 2.2570714950561523
Validation loss: 2.0722072342390656

Epoch: 5| Step: 10
Training loss: 2.4231338500976562
Validation loss: 2.1355300513646935

Epoch: 187| Step: 0
Training loss: 2.230360507965088
Validation loss: 2.1458310952750583

Epoch: 5| Step: 1
Training loss: 2.164926052093506
Validation loss: 2.1479859531566663

Epoch: 5| Step: 2
Training loss: 2.1630053520202637
Validation loss: 2.1988412616073445

Epoch: 5| Step: 3
Training loss: 2.297827959060669
Validation loss: 2.1729609915005264

Epoch: 5| Step: 4
Training loss: 2.016407012939453
Validation loss: 2.1523122864384807

Epoch: 5| Step: 5
Training loss: 2.1683058738708496
Validation loss: 2.146352632071382

Epoch: 5| Step: 6
Training loss: 1.2618591785430908
Validation loss: 2.2145462612951956

Epoch: 5| Step: 7
Training loss: 1.990795373916626
Validation loss: 2.2495652693574146

Epoch: 5| Step: 8
Training loss: 2.984678268432617
Validation loss: 2.1557203338992212

Epoch: 5| Step: 9
Training loss: 2.313451051712036
Validation loss: 2.16721373732372

Epoch: 5| Step: 10
Training loss: 1.865141749382019
Validation loss: 2.141684591129262

Epoch: 188| Step: 0
Training loss: 2.5922763347625732
Validation loss: 2.200340809360627

Epoch: 5| Step: 1
Training loss: 2.2024340629577637
Validation loss: 2.1604530965128252

Epoch: 5| Step: 2
Training loss: 2.056673049926758
Validation loss: 2.1534933556792555

Epoch: 5| Step: 3
Training loss: 1.8588701486587524
Validation loss: 2.174597804264356

Epoch: 5| Step: 4
Training loss: 1.9422909021377563
Validation loss: 2.201619989128523

Epoch: 5| Step: 5
Training loss: 1.552016258239746
Validation loss: 2.0967920941691243

Epoch: 5| Step: 6
Training loss: 2.139474391937256
Validation loss: 2.1028199580407914

Epoch: 5| Step: 7
Training loss: 2.6907529830932617
Validation loss: 2.1790437159999723

Epoch: 5| Step: 8
Training loss: 2.2133710384368896
Validation loss: 2.1767623552712063

Epoch: 5| Step: 9
Training loss: 1.969175100326538
Validation loss: 2.142577532799013

Epoch: 5| Step: 10
Training loss: 2.2039272785186768
Validation loss: 2.132503345448484

Epoch: 189| Step: 0
Training loss: 2.310025453567505
Validation loss: 2.104037668115349

Epoch: 5| Step: 1
Training loss: 1.795802354812622
Validation loss: 2.080667664927821

Epoch: 5| Step: 2
Training loss: 1.7916412353515625
Validation loss: 2.1068761784543275

Epoch: 5| Step: 3
Training loss: 3.0152335166931152
Validation loss: 2.1633147398630777

Epoch: 5| Step: 4
Training loss: 2.59836483001709
Validation loss: 2.160862843195597

Epoch: 5| Step: 5
Training loss: 2.0403828620910645
Validation loss: 2.1760561773853917

Epoch: 5| Step: 6
Training loss: 2.6603505611419678
Validation loss: 2.118377721437844

Epoch: 5| Step: 7
Training loss: 1.8090178966522217
Validation loss: 2.120634827562558

Epoch: 5| Step: 8
Training loss: 1.6633800268173218
Validation loss: 2.0949364195587816

Epoch: 5| Step: 9
Training loss: 1.9846935272216797
Validation loss: 2.1264882305616974

Epoch: 5| Step: 10
Training loss: 1.8732123374938965
Validation loss: 2.1236754335382932

Epoch: 190| Step: 0
Training loss: 1.833261489868164
Validation loss: 2.2224647755263955

Epoch: 5| Step: 1
Training loss: 1.855806589126587
Validation loss: 2.0784688226638304

Epoch: 5| Step: 2
Training loss: 2.3213162422180176
Validation loss: 2.118382297536378

Epoch: 5| Step: 3
Training loss: 1.8964141607284546
Validation loss: 2.173016991666568

Epoch: 5| Step: 4
Training loss: 2.1106715202331543
Validation loss: 2.1089943608930035

Epoch: 5| Step: 5
Training loss: 2.570681571960449
Validation loss: 2.0927962641562186

Epoch: 5| Step: 6
Training loss: 1.4838374853134155
Validation loss: 2.122165923477501

Epoch: 5| Step: 7
Training loss: 2.1414217948913574
Validation loss: 2.1357611507497807

Epoch: 5| Step: 8
Training loss: 1.824711561203003
Validation loss: 2.119453858303767

Epoch: 5| Step: 9
Training loss: 2.5366604328155518
Validation loss: 2.1236035926367647

Epoch: 5| Step: 10
Training loss: 2.5287258625030518
Validation loss: 2.140413163810648

Epoch: 191| Step: 0
Training loss: 1.9581992626190186
Validation loss: 2.1682111268402426

Epoch: 5| Step: 1
Training loss: 2.5938644409179688
Validation loss: 2.1424200919366654

Epoch: 5| Step: 2
Training loss: 2.322835922241211
Validation loss: 2.1823262450515584

Epoch: 5| Step: 3
Training loss: 2.210406541824341
Validation loss: 2.1350655991544008

Epoch: 5| Step: 4
Training loss: 2.0065817832946777
Validation loss: 2.1031468094036145

Epoch: 5| Step: 5
Training loss: 1.78128981590271
Validation loss: 2.163103490747431

Epoch: 5| Step: 6
Training loss: 1.6688133478164673
Validation loss: 2.208358833866735

Epoch: 5| Step: 7
Training loss: 2.1823248863220215
Validation loss: 2.159997796499601

Epoch: 5| Step: 8
Training loss: 2.165306329727173
Validation loss: 2.160124353183213

Epoch: 5| Step: 9
Training loss: 2.0627126693725586
Validation loss: 2.16893534762885

Epoch: 5| Step: 10
Training loss: 1.6628963947296143
Validation loss: 2.1300139529730684

Epoch: 192| Step: 0
Training loss: 2.345900535583496
Validation loss: 2.203888729054441

Epoch: 5| Step: 1
Training loss: 2.124164581298828
Validation loss: 2.131117414402705

Epoch: 5| Step: 2
Training loss: 2.165066957473755
Validation loss: 2.117285733581871

Epoch: 5| Step: 3
Training loss: 1.8504931926727295
Validation loss: 2.175853171656209

Epoch: 5| Step: 4
Training loss: 1.624525785446167
Validation loss: 2.1510641472313994

Epoch: 5| Step: 5
Training loss: 2.09987211227417
Validation loss: 2.166070189527286

Epoch: 5| Step: 6
Training loss: 2.151705503463745
Validation loss: 2.148671570644584

Epoch: 5| Step: 7
Training loss: 2.125296115875244
Validation loss: 2.140022058640757

Epoch: 5| Step: 8
Training loss: 2.17814564704895
Validation loss: 2.1401010277450725

Epoch: 5| Step: 9
Training loss: 2.032541513442993
Validation loss: 2.1407871707793205

Epoch: 5| Step: 10
Training loss: 2.775357484817505
Validation loss: 2.1209432335310083

Epoch: 193| Step: 0
Training loss: 1.9649184942245483
Validation loss: 2.1323311841616066

Epoch: 5| Step: 1
Training loss: 2.1006932258605957
Validation loss: 2.1331723761814896

Epoch: 5| Step: 2
Training loss: 1.9700552225112915
Validation loss: 2.133473324519332

Epoch: 5| Step: 3
Training loss: 1.9433772563934326
Validation loss: 2.1383574137123684

Epoch: 5| Step: 4
Training loss: 1.8901817798614502
Validation loss: 2.149001113830074

Epoch: 5| Step: 5
Training loss: 2.3348641395568848
Validation loss: 2.198236068089803

Epoch: 5| Step: 6
Training loss: 1.949573278427124
Validation loss: 2.1098317305246987

Epoch: 5| Step: 7
Training loss: 2.3818070888519287
Validation loss: 2.2023163046888126

Epoch: 5| Step: 8
Training loss: 2.205029010772705
Validation loss: 2.2187363563045377

Epoch: 5| Step: 9
Training loss: 1.9421546459197998
Validation loss: 2.1157686710357666

Epoch: 5| Step: 10
Training loss: 2.7296597957611084
Validation loss: 2.1354263918374174

Epoch: 194| Step: 0
Training loss: 2.015768051147461
Validation loss: 2.1478539282275784

Epoch: 5| Step: 1
Training loss: 2.1282284259796143
Validation loss: 2.1402801672617593

Epoch: 5| Step: 2
Training loss: 1.849551796913147
Validation loss: 2.0958974040964597

Epoch: 5| Step: 3
Training loss: 1.848292589187622
Validation loss: 2.1856212487784763

Epoch: 5| Step: 4
Training loss: 2.0953547954559326
Validation loss: 2.1273674195812595

Epoch: 5| Step: 5
Training loss: 2.496464967727661
Validation loss: 2.174352438219132

Epoch: 5| Step: 6
Training loss: 2.5567100048065186
Validation loss: 2.088650406047862

Epoch: 5| Step: 7
Training loss: 2.0684008598327637
Validation loss: 2.106877188528738

Epoch: 5| Step: 8
Training loss: 2.4096083641052246
Validation loss: 2.136915294072961

Epoch: 5| Step: 9
Training loss: 1.5528972148895264
Validation loss: 2.206316363426947

Epoch: 5| Step: 10
Training loss: 2.3194329738616943
Validation loss: 2.098278263563751

Epoch: 195| Step: 0
Training loss: 1.8437293767929077
Validation loss: 2.122108356927031

Epoch: 5| Step: 1
Training loss: 1.9681274890899658
Validation loss: 2.122396446043445

Epoch: 5| Step: 2
Training loss: 1.7105178833007812
Validation loss: 2.182251609781737

Epoch: 5| Step: 3
Training loss: 2.786682605743408
Validation loss: 2.1924232308582594

Epoch: 5| Step: 4
Training loss: 1.994104027748108
Validation loss: 2.153101134043868

Epoch: 5| Step: 5
Training loss: 1.8803476095199585
Validation loss: 2.1423475127066336

Epoch: 5| Step: 6
Training loss: 2.219508647918701
Validation loss: 2.0680985912199943

Epoch: 5| Step: 7
Training loss: 2.2200663089752197
Validation loss: 2.160115985460179

Epoch: 5| Step: 8
Training loss: 2.2404375076293945
Validation loss: 2.1680062714443413

Epoch: 5| Step: 9
Training loss: 2.2269649505615234
Validation loss: 2.1682250961180656

Epoch: 5| Step: 10
Training loss: 1.9567415714263916
Validation loss: 2.1420268858632734

Epoch: 196| Step: 0
Training loss: 1.8721237182617188
Validation loss: 2.2115309187161025

Epoch: 5| Step: 1
Training loss: 1.726854681968689
Validation loss: 2.1023126981591664

Epoch: 5| Step: 2
Training loss: 1.934691071510315
Validation loss: 2.147957868473504

Epoch: 5| Step: 3
Training loss: 2.2702300548553467
Validation loss: 2.1906958280071134

Epoch: 5| Step: 4
Training loss: 2.2974774837493896
Validation loss: 2.1275174553676317

Epoch: 5| Step: 5
Training loss: 2.5386180877685547
Validation loss: 2.1459637713688675

Epoch: 5| Step: 6
Training loss: 2.3937525749206543
Validation loss: 2.153121180431817

Epoch: 5| Step: 7
Training loss: 2.3981072902679443
Validation loss: 2.141375587832543

Epoch: 5| Step: 8
Training loss: 1.8248627185821533
Validation loss: 2.1304054234617498

Epoch: 5| Step: 9
Training loss: 1.7379810810089111
Validation loss: 2.124866602241352

Epoch: 5| Step: 10
Training loss: 2.1941065788269043
Validation loss: 2.086263270788295

Epoch: 197| Step: 0
Training loss: 2.1142101287841797
Validation loss: 2.186501467099754

Epoch: 5| Step: 1
Training loss: 2.347504138946533
Validation loss: 2.124572274505451

Epoch: 5| Step: 2
Training loss: 1.8483152389526367
Validation loss: 2.115316649918915

Epoch: 5| Step: 3
Training loss: 1.7138128280639648
Validation loss: 2.1794783966515654

Epoch: 5| Step: 4
Training loss: 1.855398178100586
Validation loss: 2.118845044925649

Epoch: 5| Step: 5
Training loss: 2.4418044090270996
Validation loss: 2.1442484932561077

Epoch: 5| Step: 6
Training loss: 1.9852235317230225
Validation loss: 2.13865339884194

Epoch: 5| Step: 7
Training loss: 1.637030839920044
Validation loss: 2.130486111487112

Epoch: 5| Step: 8
Training loss: 2.361525058746338
Validation loss: 2.133103096356956

Epoch: 5| Step: 9
Training loss: 1.7784175872802734
Validation loss: 2.1267353847462642

Epoch: 5| Step: 10
Training loss: 2.9231836795806885
Validation loss: 2.084149906712194

Epoch: 198| Step: 0
Training loss: 2.3192009925842285
Validation loss: 2.122708953836913

Epoch: 5| Step: 1
Training loss: 2.0271615982055664
Validation loss: 2.1559290129651307

Epoch: 5| Step: 2
Training loss: 1.7463109493255615
Validation loss: 2.1204055637441654

Epoch: 5| Step: 3
Training loss: 1.7587153911590576
Validation loss: 2.137859877719674

Epoch: 5| Step: 4
Training loss: 2.1056926250457764
Validation loss: 2.143413541137531

Epoch: 5| Step: 5
Training loss: 2.652176856994629
Validation loss: 2.1135572541144585

Epoch: 5| Step: 6
Training loss: 2.5112452507019043
Validation loss: 2.1518321088565293

Epoch: 5| Step: 7
Training loss: 2.31207275390625
Validation loss: 2.144215435110113

Epoch: 5| Step: 8
Training loss: 2.243820905685425
Validation loss: 2.109646230615595

Epoch: 5| Step: 9
Training loss: 1.628904938697815
Validation loss: 2.1255599439785047

Epoch: 5| Step: 10
Training loss: 1.367363691329956
Validation loss: 2.1739738654064875

Epoch: 199| Step: 0
Training loss: 2.6959710121154785
Validation loss: 2.0774547566649733

Epoch: 5| Step: 1
Training loss: 2.017162322998047
Validation loss: 2.097793591919766

Epoch: 5| Step: 2
Training loss: 1.2589077949523926
Validation loss: 2.1589354033111245

Epoch: 5| Step: 3
Training loss: 1.8701289892196655
Validation loss: 2.1636076678511915

Epoch: 5| Step: 4
Training loss: 1.6257941722869873
Validation loss: 2.149004626017745

Epoch: 5| Step: 5
Training loss: 2.360373020172119
Validation loss: 2.1351735502161007

Epoch: 5| Step: 6
Training loss: 1.989518404006958
Validation loss: 2.098687852582624

Epoch: 5| Step: 7
Training loss: 2.1099133491516113
Validation loss: 2.164524814134003

Epoch: 5| Step: 8
Training loss: 1.9019187688827515
Validation loss: 2.110585710053803

Epoch: 5| Step: 9
Training loss: 1.7708723545074463
Validation loss: 2.08533150406294

Epoch: 5| Step: 10
Training loss: 3.2642080783843994
Validation loss: 2.1848218979374057

Epoch: 200| Step: 0
Training loss: 2.0797858238220215
Validation loss: 2.0592325272098666

Epoch: 5| Step: 1
Training loss: 2.378063201904297
Validation loss: 2.099842212533438

Epoch: 5| Step: 2
Training loss: 2.239170789718628
Validation loss: 2.114781851409584

Epoch: 5| Step: 3
Training loss: 1.5918954610824585
Validation loss: 2.135101238886515

Epoch: 5| Step: 4
Training loss: 1.9035507440567017
Validation loss: 2.1810717300702165

Epoch: 5| Step: 5
Training loss: 2.488704204559326
Validation loss: 2.176203586721933

Epoch: 5| Step: 6
Training loss: 2.3224663734436035
Validation loss: 2.184163314039989

Epoch: 5| Step: 7
Training loss: 1.5686867237091064
Validation loss: 2.127223724959999

Epoch: 5| Step: 8
Training loss: 1.7185710668563843
Validation loss: 2.21256354290952

Epoch: 5| Step: 9
Training loss: 1.9739700555801392
Validation loss: 2.1054551370682253

Epoch: 5| Step: 10
Training loss: 2.684319257736206
Validation loss: 2.2296449394636255

Epoch: 201| Step: 0
Training loss: 2.5310070514678955
Validation loss: 2.076039698816115

Epoch: 5| Step: 1
Training loss: 1.410128116607666
Validation loss: 2.1281300975430395

Epoch: 5| Step: 2
Training loss: 1.7015933990478516
Validation loss: 2.1583353114384476

Epoch: 5| Step: 3
Training loss: 1.9908215999603271
Validation loss: 2.1811682126855336

Epoch: 5| Step: 4
Training loss: 2.387458562850952
Validation loss: 2.161559115173996

Epoch: 5| Step: 5
Training loss: 1.9143836498260498
Validation loss: 2.1147345573671403

Epoch: 5| Step: 6
Training loss: 1.7300453186035156
Validation loss: 2.159088473166189

Epoch: 5| Step: 7
Training loss: 2.6437013149261475
Validation loss: 2.1932423217322237

Epoch: 5| Step: 8
Training loss: 2.5700693130493164
Validation loss: 2.2217556712447957

Epoch: 5| Step: 9
Training loss: 2.0380961894989014
Validation loss: 2.151105316736365

Epoch: 5| Step: 10
Training loss: 2.0166707038879395
Validation loss: 2.0604801024160078

Epoch: 202| Step: 0
Training loss: 2.259115219116211
Validation loss: 2.169955622765326

Epoch: 5| Step: 1
Training loss: 1.790226936340332
Validation loss: 2.219895229544691

Epoch: 5| Step: 2
Training loss: 2.0012168884277344
Validation loss: 2.1148436095124934

Epoch: 5| Step: 3
Training loss: 2.5742366313934326
Validation loss: 2.0911564262964393

Epoch: 5| Step: 4
Training loss: 1.9403215646743774
Validation loss: 2.132245163763723

Epoch: 5| Step: 5
Training loss: 2.4111850261688232
Validation loss: 2.1226368642622426

Epoch: 5| Step: 6
Training loss: 2.094257354736328
Validation loss: 2.1370616151440527

Epoch: 5| Step: 7
Training loss: 1.8085880279541016
Validation loss: 2.1288083061095207

Epoch: 5| Step: 8
Training loss: 1.9347957372665405
Validation loss: 2.114318657946843

Epoch: 5| Step: 9
Training loss: 1.56857430934906
Validation loss: 2.1657757451457362

Epoch: 5| Step: 10
Training loss: 2.2686307430267334
Validation loss: 2.1296390820575017

Epoch: 203| Step: 0
Training loss: 2.4027276039123535
Validation loss: 2.208305617814423

Epoch: 5| Step: 1
Training loss: 1.8135038614273071
Validation loss: 2.1204323819888535

Epoch: 5| Step: 2
Training loss: 2.1795451641082764
Validation loss: 2.1616543390417613

Epoch: 5| Step: 3
Training loss: 1.9583461284637451
Validation loss: 2.240760221276232

Epoch: 5| Step: 4
Training loss: 1.6809546947479248
Validation loss: 2.120422750390986

Epoch: 5| Step: 5
Training loss: 1.4879953861236572
Validation loss: 2.141521138529624

Epoch: 5| Step: 6
Training loss: 1.887030839920044
Validation loss: 2.185868622154318

Epoch: 5| Step: 7
Training loss: 2.5235631465911865
Validation loss: 2.215380061057306

Epoch: 5| Step: 8
Training loss: 2.611088514328003
Validation loss: 2.119135287500197

Epoch: 5| Step: 9
Training loss: 2.1999266147613525
Validation loss: 2.119288213791386

Epoch: 5| Step: 10
Training loss: 2.155792236328125
Validation loss: 2.10756939970037

Epoch: 204| Step: 0
Training loss: 2.023740530014038
Validation loss: 2.0936284526701896

Epoch: 5| Step: 1
Training loss: 2.1455607414245605
Validation loss: 2.139434811889484

Epoch: 5| Step: 2
Training loss: 2.1642956733703613
Validation loss: 2.153668260061613

Epoch: 5| Step: 3
Training loss: 2.3499960899353027
Validation loss: 2.1755223504958616

Epoch: 5| Step: 4
Training loss: 1.9980825185775757
Validation loss: 2.135812167198427

Epoch: 5| Step: 5
Training loss: 1.6258033514022827
Validation loss: 2.182041060539984

Epoch: 5| Step: 6
Training loss: 2.246662139892578
Validation loss: 2.083596514117333

Epoch: 5| Step: 7
Training loss: 2.370539426803589
Validation loss: 2.1729703718616116

Epoch: 5| Step: 8
Training loss: 2.2782375812530518
Validation loss: 2.101930909259345

Epoch: 5| Step: 9
Training loss: 1.6846271753311157
Validation loss: 2.1062191660686205

Epoch: 5| Step: 10
Training loss: 1.943424940109253
Validation loss: 2.1154957073991016

Epoch: 205| Step: 0
Training loss: 1.7091920375823975
Validation loss: 2.0924719789976716

Epoch: 5| Step: 1
Training loss: 2.3285439014434814
Validation loss: 2.1484075771865023

Epoch: 5| Step: 2
Training loss: 3.012193202972412
Validation loss: 2.0770844515933784

Epoch: 5| Step: 3
Training loss: 1.8642292022705078
Validation loss: 2.090555510213298

Epoch: 5| Step: 4
Training loss: 1.829064130783081
Validation loss: 2.1822796483193674

Epoch: 5| Step: 5
Training loss: 2.1484904289245605
Validation loss: 2.1953870352878364

Epoch: 5| Step: 6
Training loss: 2.0787904262542725
Validation loss: 2.080170791636231

Epoch: 5| Step: 7
Training loss: 1.4423339366912842
Validation loss: 2.193486841776038

Epoch: 5| Step: 8
Training loss: 2.2779452800750732
Validation loss: 2.1387307336253505

Epoch: 5| Step: 9
Training loss: 1.959062933921814
Validation loss: 2.1321495784226285

Epoch: 5| Step: 10
Training loss: 2.0954980850219727
Validation loss: 2.1262973329072357

Epoch: 206| Step: 0
Training loss: 2.0663745403289795
Validation loss: 2.1734059279964817

Epoch: 5| Step: 1
Training loss: 1.8923553228378296
Validation loss: 2.1031248338760866

Epoch: 5| Step: 2
Training loss: 1.7906427383422852
Validation loss: 2.11292705997344

Epoch: 5| Step: 3
Training loss: 1.9155353307724
Validation loss: 2.1004556609738256

Epoch: 5| Step: 4
Training loss: 1.8359960317611694
Validation loss: 2.1173446691164406

Epoch: 5| Step: 5
Training loss: 2.136418581008911
Validation loss: 2.1576975878848823

Epoch: 5| Step: 6
Training loss: 2.4860119819641113
Validation loss: 2.0768312126077633

Epoch: 5| Step: 7
Training loss: 2.004465103149414
Validation loss: 2.1340403454278105

Epoch: 5| Step: 8
Training loss: 1.566081166267395
Validation loss: 2.15763872156861

Epoch: 5| Step: 9
Training loss: 2.3338844776153564
Validation loss: 2.153770444213703

Epoch: 5| Step: 10
Training loss: 2.117955207824707
Validation loss: 2.180920362472534

Epoch: 207| Step: 0
Training loss: 1.9877303838729858
Validation loss: 2.106201215456891

Epoch: 5| Step: 1
Training loss: 2.013227701187134
Validation loss: 2.1349258833034064

Epoch: 5| Step: 2
Training loss: 1.9745651483535767
Validation loss: 2.1450251122956634

Epoch: 5| Step: 3
Training loss: 1.8711544275283813
Validation loss: 2.1293928392471804

Epoch: 5| Step: 4
Training loss: 1.94906747341156
Validation loss: 2.1567748746564313

Epoch: 5| Step: 5
Training loss: 1.9522249698638916
Validation loss: 2.173106739597936

Epoch: 5| Step: 6
Training loss: 2.2709052562713623
Validation loss: 2.0815506186536563

Epoch: 5| Step: 7
Training loss: 2.1515250205993652
Validation loss: 2.12383799142735

Epoch: 5| Step: 8
Training loss: 2.10953950881958
Validation loss: 2.1226365643162883

Epoch: 5| Step: 9
Training loss: 2.1501059532165527
Validation loss: 2.1184907215897755

Epoch: 5| Step: 10
Training loss: 2.396070957183838
Validation loss: 2.1353582002783336

Epoch: 208| Step: 0
Training loss: 2.2019543647766113
Validation loss: 2.1381406079056444

Epoch: 5| Step: 1
Training loss: 1.542195200920105
Validation loss: 2.1326082291141635

Epoch: 5| Step: 2
Training loss: 1.227244257926941
Validation loss: 2.155577850598161

Epoch: 5| Step: 3
Training loss: 1.636564016342163
Validation loss: 2.153711953470784

Epoch: 5| Step: 4
Training loss: 2.276448965072632
Validation loss: 2.167099580969862

Epoch: 5| Step: 5
Training loss: 2.6924538612365723
Validation loss: 2.1176373984224055

Epoch: 5| Step: 6
Training loss: 2.6036524772644043
Validation loss: 2.1071806159070743

Epoch: 5| Step: 7
Training loss: 2.1741528511047363
Validation loss: 2.1854465623055734

Epoch: 5| Step: 8
Training loss: 1.8946959972381592
Validation loss: 2.1675428703267086

Epoch: 5| Step: 9
Training loss: 2.6484291553497314
Validation loss: 2.168317517926616

Epoch: 5| Step: 10
Training loss: 1.5871379375457764
Validation loss: 2.1903959499892367

Epoch: 209| Step: 0
Training loss: 2.437222480773926
Validation loss: 2.121241925865091

Epoch: 5| Step: 1
Training loss: 1.6340086460113525
Validation loss: 2.089056476469963

Epoch: 5| Step: 2
Training loss: 2.6093456745147705
Validation loss: 2.1307914795414096

Epoch: 5| Step: 3
Training loss: 1.8005740642547607
Validation loss: 2.115073388622653

Epoch: 5| Step: 4
Training loss: 2.299454927444458
Validation loss: 2.164792917108023

Epoch: 5| Step: 5
Training loss: 2.03235125541687
Validation loss: 2.1966068795932236

Epoch: 5| Step: 6
Training loss: 2.0677056312561035
Validation loss: 2.139387058955367

Epoch: 5| Step: 7
Training loss: 1.7860009670257568
Validation loss: 2.2153489640963975

Epoch: 5| Step: 8
Training loss: 2.164541721343994
Validation loss: 2.2088725925773702

Epoch: 5| Step: 9
Training loss: 2.1470389366149902
Validation loss: 2.23713904939672

Epoch: 5| Step: 10
Training loss: 2.147505044937134
Validation loss: 2.1687856874158307

Epoch: 210| Step: 0
Training loss: 1.507322072982788
Validation loss: 2.212565263112386

Epoch: 5| Step: 1
Training loss: 2.091216802597046
Validation loss: 2.1666666128302134

Epoch: 5| Step: 2
Training loss: 2.6726088523864746
Validation loss: 2.087406139219961

Epoch: 5| Step: 3
Training loss: 2.5923964977264404
Validation loss: 2.1277428903887348

Epoch: 5| Step: 4
Training loss: 2.340104579925537
Validation loss: 2.1938332075713785

Epoch: 5| Step: 5
Training loss: 2.3197734355926514
Validation loss: 2.14151591895729

Epoch: 5| Step: 6
Training loss: 2.5439748764038086
Validation loss: 2.188330296547182

Epoch: 5| Step: 7
Training loss: 1.4666869640350342
Validation loss: 2.118123622350795

Epoch: 5| Step: 8
Training loss: 1.6072276830673218
Validation loss: 2.1659239902291247

Epoch: 5| Step: 9
Training loss: 2.3396334648132324
Validation loss: 2.2082745798172487

Epoch: 5| Step: 10
Training loss: 1.7374531030654907
Validation loss: 2.076201312003597

Epoch: 211| Step: 0
Training loss: 2.570211172103882
Validation loss: 2.0862117736570296

Epoch: 5| Step: 1
Training loss: 2.458449602127075
Validation loss: 2.144315109458021

Epoch: 5| Step: 2
Training loss: 2.271338939666748
Validation loss: 2.0797322975691928

Epoch: 5| Step: 3
Training loss: 2.100579023361206
Validation loss: 2.1008214719833864

Epoch: 5| Step: 4
Training loss: 2.469472646713257
Validation loss: 2.1840013355337162

Epoch: 5| Step: 5
Training loss: 1.531258225440979
Validation loss: 2.1633577705711446

Epoch: 5| Step: 6
Training loss: 2.5181381702423096
Validation loss: 2.1007211003252255

Epoch: 5| Step: 7
Training loss: 2.0257408618927
Validation loss: 2.1304827300451135

Epoch: 5| Step: 8
Training loss: 1.7307984828948975
Validation loss: 2.1424117062681463

Epoch: 5| Step: 9
Training loss: 1.771567940711975
Validation loss: 2.104791950154048

Epoch: 5| Step: 10
Training loss: 1.7368000745773315
Validation loss: 2.1085133155186973

Epoch: 212| Step: 0
Training loss: 1.3611176013946533
Validation loss: 2.066810172091248

Epoch: 5| Step: 1
Training loss: 1.995720624923706
Validation loss: 2.142332523099838

Epoch: 5| Step: 2
Training loss: 2.749851703643799
Validation loss: 2.1877420140850927

Epoch: 5| Step: 3
Training loss: 2.1898467540740967
Validation loss: 2.1889858912396174

Epoch: 5| Step: 4
Training loss: 2.1312308311462402
Validation loss: 2.1794138236712386

Epoch: 5| Step: 5
Training loss: 2.6165988445281982
Validation loss: 2.1016899898488033

Epoch: 5| Step: 6
Training loss: 1.892270803451538
Validation loss: 2.135101722132775

Epoch: 5| Step: 7
Training loss: 1.8142540454864502
Validation loss: 2.184341364009406

Epoch: 5| Step: 8
Training loss: 1.7617614269256592
Validation loss: 2.163848143751903

Epoch: 5| Step: 9
Training loss: 1.9688920974731445
Validation loss: 2.114770689318257

Epoch: 5| Step: 10
Training loss: 1.7327584028244019
Validation loss: 2.1162903257595596

Epoch: 213| Step: 0
Training loss: 2.3886592388153076
Validation loss: 2.0953461047141784

Epoch: 5| Step: 1
Training loss: 1.9691587686538696
Validation loss: 2.1252896401189987

Epoch: 5| Step: 2
Training loss: 1.9587624073028564
Validation loss: 2.1464160001406105

Epoch: 5| Step: 3
Training loss: 2.0690512657165527
Validation loss: 2.0694818958159416

Epoch: 5| Step: 4
Training loss: 1.6916319131851196
Validation loss: 2.1783362460392777

Epoch: 5| Step: 5
Training loss: 2.052156925201416
Validation loss: 2.113528308048043

Epoch: 5| Step: 6
Training loss: 1.9622589349746704
Validation loss: 2.129111025923042

Epoch: 5| Step: 7
Training loss: 1.9639495611190796
Validation loss: 2.08540423967505

Epoch: 5| Step: 8
Training loss: 2.4435458183288574
Validation loss: 2.1704791976559545

Epoch: 5| Step: 9
Training loss: 2.0701966285705566
Validation loss: 2.147787271007415

Epoch: 5| Step: 10
Training loss: 1.9889353513717651
Validation loss: 2.1170968291580037

Epoch: 214| Step: 0
Training loss: 2.5948920249938965
Validation loss: 2.131433194683444

Epoch: 5| Step: 1
Training loss: 1.9362232685089111
Validation loss: 2.1358249597651984

Epoch: 5| Step: 2
Training loss: 2.7122836112976074
Validation loss: 2.200903337488892

Epoch: 5| Step: 3
Training loss: 2.151663303375244
Validation loss: 2.139076255982922

Epoch: 5| Step: 4
Training loss: 1.7901254892349243
Validation loss: 2.186212526854648

Epoch: 5| Step: 5
Training loss: 2.5389046669006348
Validation loss: 2.1708886815655615

Epoch: 5| Step: 6
Training loss: 1.8256120681762695
Validation loss: 2.1286222191267115

Epoch: 5| Step: 7
Training loss: 1.3953486680984497
Validation loss: 2.1762493066890265

Epoch: 5| Step: 8
Training loss: 2.19594144821167
Validation loss: 2.1533085838440926

Epoch: 5| Step: 9
Training loss: 2.040769100189209
Validation loss: 2.1449522702924666

Epoch: 5| Step: 10
Training loss: 1.5781033039093018
Validation loss: 2.219692268679219

Epoch: 215| Step: 0
Training loss: 1.7906439304351807
Validation loss: 2.1481482239179712

Epoch: 5| Step: 1
Training loss: 2.2054436206817627
Validation loss: 2.099789386154503

Epoch: 5| Step: 2
Training loss: 2.1154580116271973
Validation loss: 2.14010646266322

Epoch: 5| Step: 3
Training loss: 1.7195028066635132
Validation loss: 2.1299579733161518

Epoch: 5| Step: 4
Training loss: 2.3405613899230957
Validation loss: 2.177585618470305

Epoch: 5| Step: 5
Training loss: 2.0840506553649902
Validation loss: 2.1878148227609615

Epoch: 5| Step: 6
Training loss: 1.6911602020263672
Validation loss: 2.1761664946873984

Epoch: 5| Step: 7
Training loss: 1.9944854974746704
Validation loss: 2.1050025493867937

Epoch: 5| Step: 8
Training loss: 1.8023582696914673
Validation loss: 2.1752755616300847

Epoch: 5| Step: 9
Training loss: 2.2853691577911377
Validation loss: 2.1166698650647233

Epoch: 5| Step: 10
Training loss: 2.1815342903137207
Validation loss: 2.1382303955734416

Epoch: 216| Step: 0
Training loss: 2.5546488761901855
Validation loss: 2.204905302293839

Epoch: 5| Step: 1
Training loss: 2.273956060409546
Validation loss: 2.1536909469994168

Epoch: 5| Step: 2
Training loss: 1.6909825801849365
Validation loss: 2.124936507594201

Epoch: 5| Step: 3
Training loss: 1.7635148763656616
Validation loss: 2.1561850296553744

Epoch: 5| Step: 4
Training loss: 1.6423530578613281
Validation loss: 2.0750681802790654

Epoch: 5| Step: 5
Training loss: 2.244971752166748
Validation loss: 2.1039435658403622

Epoch: 5| Step: 6
Training loss: 2.16212797164917
Validation loss: 2.148675282796224

Epoch: 5| Step: 7
Training loss: 1.8512859344482422
Validation loss: 2.0646035004687566

Epoch: 5| Step: 8
Training loss: 2.124408721923828
Validation loss: 2.0844646512821154

Epoch: 5| Step: 9
Training loss: 2.472151279449463
Validation loss: 2.0699497269045923

Epoch: 5| Step: 10
Training loss: 1.8015632629394531
Validation loss: 2.0371998766417145

Epoch: 217| Step: 0
Training loss: 1.616281509399414
Validation loss: 2.150902335361768

Epoch: 5| Step: 1
Training loss: 1.4276975393295288
Validation loss: 2.144460265354444

Epoch: 5| Step: 2
Training loss: 2.5436770915985107
Validation loss: 2.128535242490871

Epoch: 5| Step: 3
Training loss: 2.1497178077697754
Validation loss: 2.181354540650563

Epoch: 5| Step: 4
Training loss: 2.257995367050171
Validation loss: 2.131406802003102

Epoch: 5| Step: 5
Training loss: 1.9483859539031982
Validation loss: 2.1623003175181728

Epoch: 5| Step: 6
Training loss: 1.9991670846939087
Validation loss: 2.1808433968533754

Epoch: 5| Step: 7
Training loss: 2.4426465034484863
Validation loss: 2.167756780501335

Epoch: 5| Step: 8
Training loss: 1.595225214958191
Validation loss: 2.1438386619731946

Epoch: 5| Step: 9
Training loss: 2.41070294380188
Validation loss: 2.0813324618083175

Epoch: 5| Step: 10
Training loss: 2.3337645530700684
Validation loss: 2.1763177687121975

Epoch: 218| Step: 0
Training loss: 1.869698166847229
Validation loss: 2.1196050387556835

Epoch: 5| Step: 1
Training loss: 1.823836088180542
Validation loss: 2.141004894369392

Epoch: 5| Step: 2
Training loss: 1.8284612894058228
Validation loss: 2.135510649732364

Epoch: 5| Step: 3
Training loss: 1.739068627357483
Validation loss: 2.1483498273357267

Epoch: 5| Step: 4
Training loss: 2.346083879470825
Validation loss: 2.1856734496290966

Epoch: 5| Step: 5
Training loss: 1.9005241394042969
Validation loss: 2.1942199276339625

Epoch: 5| Step: 6
Training loss: 2.341970920562744
Validation loss: 2.207825458177956

Epoch: 5| Step: 7
Training loss: 2.417497396469116
Validation loss: 2.0950801936529015

Epoch: 5| Step: 8
Training loss: 2.289332866668701
Validation loss: 2.1858973349294355

Epoch: 5| Step: 9
Training loss: 2.5573601722717285
Validation loss: 2.1846727145615445

Epoch: 5| Step: 10
Training loss: 1.6738508939743042
Validation loss: 2.1600294651523715

Epoch: 219| Step: 0
Training loss: 1.8036823272705078
Validation loss: 2.177141102411414

Epoch: 5| Step: 1
Training loss: 2.5476908683776855
Validation loss: 2.174287388401647

Epoch: 5| Step: 2
Training loss: 2.070641279220581
Validation loss: 2.1432978696720575

Epoch: 5| Step: 3
Training loss: 1.648662805557251
Validation loss: 2.129365708238335

Epoch: 5| Step: 4
Training loss: 1.878464698791504
Validation loss: 2.1950382519793767

Epoch: 5| Step: 5
Training loss: 1.9558372497558594
Validation loss: 2.2137095518009637

Epoch: 5| Step: 6
Training loss: 1.9031429290771484
Validation loss: 2.1482204775656424

Epoch: 5| Step: 7
Training loss: 2.1458301544189453
Validation loss: 2.1359108378810268

Epoch: 5| Step: 8
Training loss: 2.1623713970184326
Validation loss: 2.0483510007140455

Epoch: 5| Step: 9
Training loss: 2.0872089862823486
Validation loss: 2.096230594060754

Epoch: 5| Step: 10
Training loss: 2.510580539703369
Validation loss: 2.0653762073927027

Epoch: 220| Step: 0
Training loss: 2.0010263919830322
Validation loss: 2.1868176434629705

Epoch: 5| Step: 1
Training loss: 2.0915989875793457
Validation loss: 2.1184937556584678

Epoch: 5| Step: 2
Training loss: 2.633375644683838
Validation loss: 2.1194898620728524

Epoch: 5| Step: 3
Training loss: 1.7460607290267944
Validation loss: 2.1157193619717836

Epoch: 5| Step: 4
Training loss: 2.3876900672912598
Validation loss: 2.1125489357979066

Epoch: 5| Step: 5
Training loss: 2.009901523590088
Validation loss: 2.1331825640893753

Epoch: 5| Step: 6
Training loss: 1.6572145223617554
Validation loss: 2.1050591417538222

Epoch: 5| Step: 7
Training loss: 2.8001251220703125
Validation loss: 2.110723426265101

Epoch: 5| Step: 8
Training loss: 1.9145281314849854
Validation loss: 2.126714119347193

Epoch: 5| Step: 9
Training loss: 1.2855485677719116
Validation loss: 2.1269095149091495

Epoch: 5| Step: 10
Training loss: 2.407731533050537
Validation loss: 2.1868189381014917

Epoch: 221| Step: 0
Training loss: 2.0921597480773926
Validation loss: 2.167821277854263

Epoch: 5| Step: 1
Training loss: 2.4397459030151367
Validation loss: 2.0538266679292083

Epoch: 5| Step: 2
Training loss: 2.102201223373413
Validation loss: 2.1590120625752274

Epoch: 5| Step: 3
Training loss: 2.1799960136413574
Validation loss: 2.0763899741634244

Epoch: 5| Step: 4
Training loss: 2.1218101978302
Validation loss: 2.216224995992517

Epoch: 5| Step: 5
Training loss: 1.9480552673339844
Validation loss: 2.126586485934514

Epoch: 5| Step: 6
Training loss: 1.8113090991973877
Validation loss: 2.1287548862477785

Epoch: 5| Step: 7
Training loss: 1.9930356740951538
Validation loss: 2.144583740542012

Epoch: 5| Step: 8
Training loss: 2.008730411529541
Validation loss: 2.069399987497637

Epoch: 5| Step: 9
Training loss: 2.4955527782440186
Validation loss: 2.122633885311824

Epoch: 5| Step: 10
Training loss: 1.7160413265228271
Validation loss: 2.078767994398712

Epoch: 222| Step: 0
Training loss: 1.9896295070648193
Validation loss: 2.071877758990052

Epoch: 5| Step: 1
Training loss: 2.3652002811431885
Validation loss: 2.0838479303544566

Epoch: 5| Step: 2
Training loss: 2.5323898792266846
Validation loss: 2.080009736040587

Epoch: 5| Step: 3
Training loss: 2.0787193775177
Validation loss: 2.173664063535711

Epoch: 5| Step: 4
Training loss: 1.7150671482086182
Validation loss: 2.132101830615792

Epoch: 5| Step: 5
Training loss: 1.4367529153823853
Validation loss: 2.139464256584003

Epoch: 5| Step: 6
Training loss: 1.893304467201233
Validation loss: 2.1188790234186317

Epoch: 5| Step: 7
Training loss: 2.154879570007324
Validation loss: 2.112995829633487

Epoch: 5| Step: 8
Training loss: 2.8215525150299072
Validation loss: 2.149531384950043

Epoch: 5| Step: 9
Training loss: 1.394362211227417
Validation loss: 2.1700921148382206

Epoch: 5| Step: 10
Training loss: 1.8290585279464722
Validation loss: 2.100122445373125

Epoch: 223| Step: 0
Training loss: 2.074622392654419
Validation loss: 2.155973146038671

Epoch: 5| Step: 1
Training loss: 1.5471258163452148
Validation loss: 2.0953625197051675

Epoch: 5| Step: 2
Training loss: 1.8233661651611328
Validation loss: 2.125020683452647

Epoch: 5| Step: 3
Training loss: 1.874947190284729
Validation loss: 2.095481197039286

Epoch: 5| Step: 4
Training loss: 2.087425947189331
Validation loss: 2.1528641408489597

Epoch: 5| Step: 5
Training loss: 2.0684025287628174
Validation loss: 2.1324568999710904

Epoch: 5| Step: 6
Training loss: 2.1199281215667725
Validation loss: 2.1131369913777998

Epoch: 5| Step: 7
Training loss: 2.095526933670044
Validation loss: 2.177404329340945

Epoch: 5| Step: 8
Training loss: 2.211813449859619
Validation loss: 2.1841230392456055

Epoch: 5| Step: 9
Training loss: 2.313485860824585
Validation loss: 2.08123081473894

Epoch: 5| Step: 10
Training loss: 2.350327730178833
Validation loss: 2.1316530076406335

Epoch: 224| Step: 0
Training loss: 2.4231672286987305
Validation loss: 2.1462894793479674

Epoch: 5| Step: 1
Training loss: 2.217081069946289
Validation loss: 2.2164572541431715

Epoch: 5| Step: 2
Training loss: 2.086465835571289
Validation loss: 2.199897578967515

Epoch: 5| Step: 3
Training loss: 2.1198315620422363
Validation loss: 2.190595019248224

Epoch: 5| Step: 4
Training loss: 1.7431004047393799
Validation loss: 2.1473112529323948

Epoch: 5| Step: 5
Training loss: 2.034363269805908
Validation loss: 2.1320511961496003

Epoch: 5| Step: 6
Training loss: 1.8509156703948975
Validation loss: 2.141301675509381

Epoch: 5| Step: 7
Training loss: 2.5312445163726807
Validation loss: 2.1894844719158706

Epoch: 5| Step: 8
Training loss: 1.887014389038086
Validation loss: 2.233922691755397

Epoch: 5| Step: 9
Training loss: 1.654148817062378
Validation loss: 2.171063930757584

Epoch: 5| Step: 10
Training loss: 1.654270052909851
Validation loss: 2.0668434648103613

Epoch: 225| Step: 0
Training loss: 1.8362751007080078
Validation loss: 2.145016977863927

Epoch: 5| Step: 1
Training loss: 2.4338159561157227
Validation loss: 2.183546373921056

Epoch: 5| Step: 2
Training loss: 2.142726421356201
Validation loss: 2.1620690489328034

Epoch: 5| Step: 3
Training loss: 1.5027849674224854
Validation loss: 2.1498024463653564

Epoch: 5| Step: 4
Training loss: 2.0606722831726074
Validation loss: 2.1388567057988976

Epoch: 5| Step: 5
Training loss: 2.1143951416015625
Validation loss: 2.1468079308027863

Epoch: 5| Step: 6
Training loss: 2.119901418685913
Validation loss: 2.1283511064385854

Epoch: 5| Step: 7
Training loss: 1.7547622919082642
Validation loss: 2.138713316891783

Epoch: 5| Step: 8
Training loss: 1.5929858684539795
Validation loss: 2.123882915384026

Epoch: 5| Step: 9
Training loss: 2.4743926525115967
Validation loss: 2.1753685551304973

Epoch: 5| Step: 10
Training loss: 2.296372652053833
Validation loss: 2.1272274550571235

Epoch: 226| Step: 0
Training loss: 1.7387161254882812
Validation loss: 2.1351928928846955

Epoch: 5| Step: 1
Training loss: 2.033313035964966
Validation loss: 2.1164134215283137

Epoch: 5| Step: 2
Training loss: 2.221867561340332
Validation loss: 2.078816535652325

Epoch: 5| Step: 3
Training loss: 1.869791030883789
Validation loss: 2.159492467039375

Epoch: 5| Step: 4
Training loss: 2.272914409637451
Validation loss: 2.0756457159596104

Epoch: 5| Step: 5
Training loss: 2.19584321975708
Validation loss: 2.162831683312693

Epoch: 5| Step: 6
Training loss: 2.1875240802764893
Validation loss: 2.1862841113921134

Epoch: 5| Step: 7
Training loss: 1.6987091302871704
Validation loss: 2.189421510183683

Epoch: 5| Step: 8
Training loss: 1.7777150869369507
Validation loss: 2.150756856446625

Epoch: 5| Step: 9
Training loss: 2.6886096000671387
Validation loss: 2.156815844197427

Epoch: 5| Step: 10
Training loss: 1.7512425184249878
Validation loss: 2.1135796962245816

Epoch: 227| Step: 0
Training loss: 2.0922439098358154
Validation loss: 2.192344475817937

Epoch: 5| Step: 1
Training loss: 2.4792580604553223
Validation loss: 2.1490783486315

Epoch: 5| Step: 2
Training loss: 2.0058555603027344
Validation loss: 2.115177672396424

Epoch: 5| Step: 3
Training loss: 1.541693925857544
Validation loss: 2.1038785954957366

Epoch: 5| Step: 4
Training loss: 2.5954036712646484
Validation loss: 2.1443129252361994

Epoch: 5| Step: 5
Training loss: 1.6447954177856445
Validation loss: 2.10387667276526

Epoch: 5| Step: 6
Training loss: 2.210099458694458
Validation loss: 2.157567104985637

Epoch: 5| Step: 7
Training loss: 2.2180683612823486
Validation loss: 2.0696749251375914

Epoch: 5| Step: 8
Training loss: 1.924682855606079
Validation loss: 2.1310476692773963

Epoch: 5| Step: 9
Training loss: 2.0975701808929443
Validation loss: 2.0922196808681695

Epoch: 5| Step: 10
Training loss: 1.7692850828170776
Validation loss: 2.1326263514898156

Epoch: 228| Step: 0
Training loss: 1.7996654510498047
Validation loss: 2.18859766375634

Epoch: 5| Step: 1
Training loss: 1.6595439910888672
Validation loss: 2.1140849551846905

Epoch: 5| Step: 2
Training loss: 1.3974665403366089
Validation loss: 2.1139318840478056

Epoch: 5| Step: 3
Training loss: 1.5573655366897583
Validation loss: 2.1896592468343754

Epoch: 5| Step: 4
Training loss: 2.3722739219665527
Validation loss: 2.1253706344994168

Epoch: 5| Step: 5
Training loss: 2.13401460647583
Validation loss: 2.1163056999124508

Epoch: 5| Step: 6
Training loss: 2.2110588550567627
Validation loss: 2.0222321761551725

Epoch: 5| Step: 7
Training loss: 2.347221851348877
Validation loss: 2.0741356008796283

Epoch: 5| Step: 8
Training loss: 1.920721411705017
Validation loss: 2.1451731933060514

Epoch: 5| Step: 9
Training loss: 2.4274356365203857
Validation loss: 2.1074359070870186

Epoch: 5| Step: 10
Training loss: 2.7855417728424072
Validation loss: 2.123966468277798

Epoch: 229| Step: 0
Training loss: 1.706346869468689
Validation loss: 2.1300787195082633

Epoch: 5| Step: 1
Training loss: 1.9065005779266357
Validation loss: 2.1893439703090216

Epoch: 5| Step: 2
Training loss: 1.787908911705017
Validation loss: 2.1760296924139864

Epoch: 5| Step: 3
Training loss: 1.8777964115142822
Validation loss: 2.1268263683524182

Epoch: 5| Step: 4
Training loss: 2.0523340702056885
Validation loss: 2.1269743186171337

Epoch: 5| Step: 5
Training loss: 2.0006637573242188
Validation loss: 2.134292697393766

Epoch: 5| Step: 6
Training loss: 2.5306713581085205
Validation loss: 2.200053604700232

Epoch: 5| Step: 7
Training loss: 2.2550864219665527
Validation loss: 2.1150074453764063

Epoch: 5| Step: 8
Training loss: 1.5688180923461914
Validation loss: 2.1201437903988745

Epoch: 5| Step: 9
Training loss: 2.002668857574463
Validation loss: 2.1861333539409022

Epoch: 5| Step: 10
Training loss: 2.8047780990600586
Validation loss: 2.120648245657644

Epoch: 230| Step: 0
Training loss: 2.075838088989258
Validation loss: 2.14573678406336

Epoch: 5| Step: 1
Training loss: 2.4011387825012207
Validation loss: 2.105911288210141

Epoch: 5| Step: 2
Training loss: 1.311921238899231
Validation loss: 2.1202008198666316

Epoch: 5| Step: 3
Training loss: 1.9667192697525024
Validation loss: 2.147962365099179

Epoch: 5| Step: 4
Training loss: 1.5660737752914429
Validation loss: 2.177153533504855

Epoch: 5| Step: 5
Training loss: 1.996976613998413
Validation loss: 2.1446283145617415

Epoch: 5| Step: 6
Training loss: 2.2065348625183105
Validation loss: 2.125548506295809

Epoch: 5| Step: 7
Training loss: 2.281646251678467
Validation loss: 2.1684399010032736

Epoch: 5| Step: 8
Training loss: 2.4809019565582275
Validation loss: 2.2107670281523015

Epoch: 5| Step: 9
Training loss: 2.2200446128845215
Validation loss: 2.2364569581964964

Epoch: 5| Step: 10
Training loss: 2.2247791290283203
Validation loss: 2.1961594499567503

Epoch: 231| Step: 0
Training loss: 2.5513339042663574
Validation loss: 2.1373180740623066

Epoch: 5| Step: 1
Training loss: 1.870833158493042
Validation loss: 2.1344172159830728

Epoch: 5| Step: 2
Training loss: 2.3691112995147705
Validation loss: 2.110583092576714

Epoch: 5| Step: 3
Training loss: 2.032132625579834
Validation loss: 2.2025444007688955

Epoch: 5| Step: 4
Training loss: 2.368649959564209
Validation loss: 2.139914292161183

Epoch: 5| Step: 5
Training loss: 1.692082166671753
Validation loss: 2.144019998529906

Epoch: 5| Step: 6
Training loss: 2.1545448303222656
Validation loss: 2.184412443509666

Epoch: 5| Step: 7
Training loss: 1.5289831161499023
Validation loss: 2.2192426855846117

Epoch: 5| Step: 8
Training loss: 1.4926671981811523
Validation loss: 2.191166962346723

Epoch: 5| Step: 9
Training loss: 2.2777657508850098
Validation loss: 2.1467616929802844

Epoch: 5| Step: 10
Training loss: 1.837396502494812
Validation loss: 2.1442205854641494

Epoch: 232| Step: 0
Training loss: 1.6320804357528687
Validation loss: 2.159742439946821

Epoch: 5| Step: 1
Training loss: 1.5077563524246216
Validation loss: 2.18323637336813

Epoch: 5| Step: 2
Training loss: 2.16805362701416
Validation loss: 2.1025222475810716

Epoch: 5| Step: 3
Training loss: 2.1340532302856445
Validation loss: 2.1482368310292563

Epoch: 5| Step: 4
Training loss: 2.0837037563323975
Validation loss: 2.141590363235884

Epoch: 5| Step: 5
Training loss: 1.982251763343811
Validation loss: 2.120728959319412

Epoch: 5| Step: 6
Training loss: 2.5416066646575928
Validation loss: 2.119194702435565

Epoch: 5| Step: 7
Training loss: 1.8503535985946655
Validation loss: 2.0791174057991273

Epoch: 5| Step: 8
Training loss: 2.362471342086792
Validation loss: 2.1449718654796643

Epoch: 5| Step: 9
Training loss: 2.08931565284729
Validation loss: 2.061444305604504

Epoch: 5| Step: 10
Training loss: 2.216153860092163
Validation loss: 2.1836332044293805

Epoch: 233| Step: 0
Training loss: 2.433037281036377
Validation loss: 2.1148595220299176

Epoch: 5| Step: 1
Training loss: 1.562166452407837
Validation loss: 2.208139996374807

Epoch: 5| Step: 2
Training loss: 1.3874249458312988
Validation loss: 2.146619100724497

Epoch: 5| Step: 3
Training loss: 2.531830310821533
Validation loss: 2.153913010833084

Epoch: 5| Step: 4
Training loss: 1.801282525062561
Validation loss: 2.0644436600387737

Epoch: 5| Step: 5
Training loss: 2.2131361961364746
Validation loss: 2.1554485008280766

Epoch: 5| Step: 6
Training loss: 2.303323268890381
Validation loss: 2.1646562289166194

Epoch: 5| Step: 7
Training loss: 2.0336129665374756
Validation loss: 2.0893439323671403

Epoch: 5| Step: 8
Training loss: 1.8006680011749268
Validation loss: 2.188107262375534

Epoch: 5| Step: 9
Training loss: 2.2288646697998047
Validation loss: 2.2047770330982823

Epoch: 5| Step: 10
Training loss: 2.0610570907592773
Validation loss: 2.1665645965965847

Epoch: 234| Step: 0
Training loss: 1.2829755544662476
Validation loss: 2.138174524871252

Epoch: 5| Step: 1
Training loss: 2.01495099067688
Validation loss: 2.129486673621721

Epoch: 5| Step: 2
Training loss: 2.3929736614227295
Validation loss: 2.1357781566599363

Epoch: 5| Step: 3
Training loss: 1.9030042886734009
Validation loss: 2.134551999389484

Epoch: 5| Step: 4
Training loss: 2.082477569580078
Validation loss: 2.1315798656914824

Epoch: 5| Step: 5
Training loss: 2.149775981903076
Validation loss: 2.112931687344787

Epoch: 5| Step: 6
Training loss: 2.3997106552124023
Validation loss: 2.122558081021873

Epoch: 5| Step: 7
Training loss: 1.867126226425171
Validation loss: 2.135950070555492

Epoch: 5| Step: 8
Training loss: 2.4678452014923096
Validation loss: 2.1338453549210743

Epoch: 5| Step: 9
Training loss: 1.8811918497085571
Validation loss: 2.136274673605478

Epoch: 5| Step: 10
Training loss: 2.0998384952545166
Validation loss: 2.1433803701913483

Epoch: 235| Step: 0
Training loss: 2.1132590770721436
Validation loss: 2.13556529373251

Epoch: 5| Step: 1
Training loss: 2.3606116771698
Validation loss: 2.253520557957311

Epoch: 5| Step: 2
Training loss: 2.0304698944091797
Validation loss: 2.110295162406019

Epoch: 5| Step: 3
Training loss: 1.6872749328613281
Validation loss: 2.149854806161696

Epoch: 5| Step: 4
Training loss: 2.5183444023132324
Validation loss: 2.129863821050172

Epoch: 5| Step: 5
Training loss: 1.7754476070404053
Validation loss: 2.2077122042256017

Epoch: 5| Step: 6
Training loss: 1.9017804861068726
Validation loss: 2.2114284499999015

Epoch: 5| Step: 7
Training loss: 2.2000985145568848
Validation loss: 2.153197084703753

Epoch: 5| Step: 8
Training loss: 2.2858078479766846
Validation loss: 2.195527563812912

Epoch: 5| Step: 9
Training loss: 1.8116886615753174
Validation loss: 2.1740013860887095

Epoch: 5| Step: 10
Training loss: 2.2670669555664062
Validation loss: 2.1782281603864444

Epoch: 236| Step: 0
Training loss: 2.0483362674713135
Validation loss: 2.168406794148107

Epoch: 5| Step: 1
Training loss: 1.8230632543563843
Validation loss: 2.1616817558965375

Epoch: 5| Step: 2
Training loss: 1.9385074377059937
Validation loss: 2.180343110074279

Epoch: 5| Step: 3
Training loss: 2.154980182647705
Validation loss: 2.2188885904127553

Epoch: 5| Step: 4
Training loss: 2.232198715209961
Validation loss: 2.2000717886032595

Epoch: 5| Step: 5
Training loss: 1.2309850454330444
Validation loss: 2.1720901125220844

Epoch: 5| Step: 6
Training loss: 2.4151344299316406
Validation loss: 2.2835060281138264

Epoch: 5| Step: 7
Training loss: 1.8439109325408936
Validation loss: 2.1402710458283782

Epoch: 5| Step: 8
Training loss: 2.2151432037353516
Validation loss: 2.210964914291136

Epoch: 5| Step: 9
Training loss: 2.257734775543213
Validation loss: 2.2008472822045766

Epoch: 5| Step: 10
Training loss: 2.2507100105285645
Validation loss: 2.167192068151248

Epoch: 237| Step: 0
Training loss: 2.2547695636749268
Validation loss: 2.1406615703336653

Epoch: 5| Step: 1
Training loss: 1.65595281124115
Validation loss: 2.220834160363802

Epoch: 5| Step: 2
Training loss: 1.7348260879516602
Validation loss: 2.1626984329633814

Epoch: 5| Step: 3
Training loss: 2.447964906692505
Validation loss: 2.225478595302951

Epoch: 5| Step: 4
Training loss: 2.1784520149230957
Validation loss: 2.1106838744173766

Epoch: 5| Step: 5
Training loss: 2.0907604694366455
Validation loss: 2.2101639124654953

Epoch: 5| Step: 6
Training loss: 2.075629472732544
Validation loss: 2.1338004322462183

Epoch: 5| Step: 7
Training loss: 1.9583717584609985
Validation loss: 2.177717033252921

Epoch: 5| Step: 8
Training loss: 1.972577691078186
Validation loss: 2.0762752973905174

Epoch: 5| Step: 9
Training loss: 2.05315899848938
Validation loss: 2.1516821730521416

Epoch: 5| Step: 10
Training loss: 1.4562956094741821
Validation loss: 2.1278620073872228

Epoch: 238| Step: 0
Training loss: 1.9815189838409424
Validation loss: 2.171088121270621

Epoch: 5| Step: 1
Training loss: 2.0496811866760254
Validation loss: 2.1003828330706527

Epoch: 5| Step: 2
Training loss: 2.1825966835021973
Validation loss: 2.112036015397759

Epoch: 5| Step: 3
Training loss: 1.8290821313858032
Validation loss: 2.1147052036818637

Epoch: 5| Step: 4
Training loss: 2.740140199661255
Validation loss: 2.157970472048688

Epoch: 5| Step: 5
Training loss: 1.4323770999908447
Validation loss: 2.1350652107628445

Epoch: 5| Step: 6
Training loss: 2.2783656120300293
Validation loss: 2.153915168136679

Epoch: 5| Step: 7
Training loss: 1.9281628131866455
Validation loss: 2.188191834316459

Epoch: 5| Step: 8
Training loss: 1.9428478479385376
Validation loss: 2.1455410065189486

Epoch: 5| Step: 9
Training loss: 2.073638439178467
Validation loss: 2.110696341401787

Epoch: 5| Step: 10
Training loss: 2.311779499053955
Validation loss: 2.1566448109124297

Epoch: 239| Step: 0
Training loss: 2.009040355682373
Validation loss: 2.1569525605888775

Epoch: 5| Step: 1
Training loss: 1.9132763147354126
Validation loss: 2.1224667538878736

Epoch: 5| Step: 2
Training loss: 2.2622878551483154
Validation loss: 2.1125417294040805

Epoch: 5| Step: 3
Training loss: 1.7218738794326782
Validation loss: 2.0814908627540833

Epoch: 5| Step: 4
Training loss: 1.7177215814590454
Validation loss: 2.1463874591294156

Epoch: 5| Step: 5
Training loss: 1.9815309047698975
Validation loss: 2.1704104279959076

Epoch: 5| Step: 6
Training loss: 2.264630079269409
Validation loss: 2.1090529708452124

Epoch: 5| Step: 7
Training loss: 1.9529441595077515
Validation loss: 2.1068535517620783

Epoch: 5| Step: 8
Training loss: 2.3170950412750244
Validation loss: 2.1276902127009567

Epoch: 5| Step: 9
Training loss: 2.630833148956299
Validation loss: 2.156008433270198

Epoch: 5| Step: 10
Training loss: 1.9356775283813477
Validation loss: 2.1626889962022022

Epoch: 240| Step: 0
Training loss: 2.4918460845947266
Validation loss: 2.234827260817251

Epoch: 5| Step: 1
Training loss: 2.5475947856903076
Validation loss: 2.2082046642098376

Epoch: 5| Step: 2
Training loss: 1.6137784719467163
Validation loss: 2.095108375754408

Epoch: 5| Step: 3
Training loss: 1.2231959104537964
Validation loss: 2.1796453178569837

Epoch: 5| Step: 4
Training loss: 1.6853160858154297
Validation loss: 2.2083443441698627

Epoch: 5| Step: 5
Training loss: 1.9437828063964844
Validation loss: 2.111206070069344

Epoch: 5| Step: 6
Training loss: 2.284822463989258
Validation loss: 2.120032610431794

Epoch: 5| Step: 7
Training loss: 2.6722145080566406
Validation loss: 2.169492603630148

Epoch: 5| Step: 8
Training loss: 2.162400245666504
Validation loss: 2.135344636055731

Epoch: 5| Step: 9
Training loss: 1.8023426532745361
Validation loss: 2.076704604651338

Epoch: 5| Step: 10
Training loss: 1.9331748485565186
Validation loss: 2.1700152709919918

Epoch: 241| Step: 0
Training loss: 1.830844521522522
Validation loss: 2.1599610479929114

Epoch: 5| Step: 1
Training loss: 2.067558526992798
Validation loss: 2.1569575814790625

Epoch: 5| Step: 2
Training loss: 1.9732894897460938
Validation loss: 2.20550214347019

Epoch: 5| Step: 3
Training loss: 1.8335742950439453
Validation loss: 2.1498611537359094

Epoch: 5| Step: 4
Training loss: 2.341766119003296
Validation loss: 2.193009481635145

Epoch: 5| Step: 5
Training loss: 1.8152902126312256
Validation loss: 2.1574652669250325

Epoch: 5| Step: 6
Training loss: 1.7484846115112305
Validation loss: 2.201031618220832

Epoch: 5| Step: 7
Training loss: 2.079826831817627
Validation loss: 2.2008228584002425

Epoch: 5| Step: 8
Training loss: 2.179908037185669
Validation loss: 2.16624286354229

Epoch: 5| Step: 9
Training loss: 2.2224066257476807
Validation loss: 2.151161468157204

Epoch: 5| Step: 10
Training loss: 1.766341209411621
Validation loss: 2.185570106711439

Epoch: 242| Step: 0
Training loss: 1.888635277748108
Validation loss: 2.2081076073390182

Epoch: 5| Step: 1
Training loss: 1.8895585536956787
Validation loss: 2.2014913020595426

Epoch: 5| Step: 2
Training loss: 2.440521240234375
Validation loss: 2.175683048463637

Epoch: 5| Step: 3
Training loss: 1.9087499380111694
Validation loss: 2.176107164352171

Epoch: 5| Step: 4
Training loss: 1.8220497369766235
Validation loss: 2.251883734938919

Epoch: 5| Step: 5
Training loss: 2.5807292461395264
Validation loss: 2.162519347283148

Epoch: 5| Step: 6
Training loss: 1.8849786520004272
Validation loss: 2.1426257907703357

Epoch: 5| Step: 7
Training loss: 1.4253476858139038
Validation loss: 2.165987842826433

Epoch: 5| Step: 8
Training loss: 2.3990111351013184
Validation loss: 2.1634400839446695

Epoch: 5| Step: 9
Training loss: 2.5709617137908936
Validation loss: 2.1134818600070093

Epoch: 5| Step: 10
Training loss: 1.6367968320846558
Validation loss: 2.1955573994626283

Epoch: 243| Step: 0
Training loss: 2.44208025932312
Validation loss: 2.1631477853303314

Epoch: 5| Step: 1
Training loss: 2.2516720294952393
Validation loss: 2.2023910143042125

Epoch: 5| Step: 2
Training loss: 1.7642656564712524
Validation loss: 2.1859305750939155

Epoch: 5| Step: 3
Training loss: 2.514589309692383
Validation loss: 2.2210799673552155

Epoch: 5| Step: 4
Training loss: 1.6187925338745117
Validation loss: 2.158094923983338

Epoch: 5| Step: 5
Training loss: 1.593778371810913
Validation loss: 2.120115375006071

Epoch: 5| Step: 6
Training loss: 2.1879372596740723
Validation loss: 2.145186771628677

Epoch: 5| Step: 7
Training loss: 1.5550305843353271
Validation loss: 2.1635070898199595

Epoch: 5| Step: 8
Training loss: 2.293943405151367
Validation loss: 2.1395583178407405

Epoch: 5| Step: 9
Training loss: 1.2173901796340942
Validation loss: 2.1236549936315066

Epoch: 5| Step: 10
Training loss: 2.3324105739593506
Validation loss: 2.169699489429433

Epoch: 244| Step: 0
Training loss: 2.0690252780914307
Validation loss: 2.0613032412785355

Epoch: 5| Step: 1
Training loss: 2.193634510040283
Validation loss: 2.1598526406031784

Epoch: 5| Step: 2
Training loss: 2.05271577835083
Validation loss: 2.1077921185442197

Epoch: 5| Step: 3
Training loss: 1.9928489923477173
Validation loss: 2.0976215959877096

Epoch: 5| Step: 4
Training loss: 2.5973289012908936
Validation loss: 2.1747158752974642

Epoch: 5| Step: 5
Training loss: 2.2551767826080322
Validation loss: 2.1423909946154525

Epoch: 5| Step: 6
Training loss: 1.4912205934524536
Validation loss: 2.118042933043613

Epoch: 5| Step: 7
Training loss: 1.588140845298767
Validation loss: 2.13393719221956

Epoch: 5| Step: 8
Training loss: 2.1404972076416016
Validation loss: 2.0544418083724154

Epoch: 5| Step: 9
Training loss: 2.310664653778076
Validation loss: 2.1741573451667704

Epoch: 5| Step: 10
Training loss: 1.684895396232605
Validation loss: 2.1247863666985625

Epoch: 245| Step: 0
Training loss: 2.1505863666534424
Validation loss: 2.1625358289287937

Epoch: 5| Step: 1
Training loss: 1.480560302734375
Validation loss: 2.1223820140284877

Epoch: 5| Step: 2
Training loss: 2.2903661727905273
Validation loss: 2.153107189363049

Epoch: 5| Step: 3
Training loss: 1.471977949142456
Validation loss: 2.098982339264244

Epoch: 5| Step: 4
Training loss: 1.6729227304458618
Validation loss: 2.2275559979100383

Epoch: 5| Step: 5
Training loss: 1.5915378332138062
Validation loss: 2.1347651020173104

Epoch: 5| Step: 6
Training loss: 2.533730983734131
Validation loss: 2.0913986929001345

Epoch: 5| Step: 7
Training loss: 1.123622179031372
Validation loss: 2.199984609439809

Epoch: 5| Step: 8
Training loss: 2.73744535446167
Validation loss: 2.143090855690741

Epoch: 5| Step: 9
Training loss: 2.4001660346984863
Validation loss: 2.179387402790849

Epoch: 5| Step: 10
Training loss: 2.2470741271972656
Validation loss: 2.1672184467315674

Epoch: 246| Step: 0
Training loss: 2.092926263809204
Validation loss: 2.1707064861892373

Epoch: 5| Step: 1
Training loss: 1.7595341205596924
Validation loss: 2.1822446648792555

Epoch: 5| Step: 2
Training loss: 2.3246383666992188
Validation loss: 2.206963873678638

Epoch: 5| Step: 3
Training loss: 2.6467466354370117
Validation loss: 2.1644950169388966

Epoch: 5| Step: 4
Training loss: 2.066636323928833
Validation loss: 2.173518112910691

Epoch: 5| Step: 5
Training loss: 1.4149539470672607
Validation loss: 2.1146106361061014

Epoch: 5| Step: 6
Training loss: 1.6681573390960693
Validation loss: 2.2358996919406358

Epoch: 5| Step: 7
Training loss: 2.2606208324432373
Validation loss: 2.1496298902778217

Epoch: 5| Step: 8
Training loss: 1.675910234451294
Validation loss: 2.1666756214634066

Epoch: 5| Step: 9
Training loss: 2.130521059036255
Validation loss: 2.1349351175369753

Epoch: 5| Step: 10
Training loss: 1.8302534818649292
Validation loss: 2.143729122736121

Epoch: 247| Step: 0
Training loss: 1.9444698095321655
Validation loss: 2.0892948001943608

Epoch: 5| Step: 1
Training loss: 2.1501762866973877
Validation loss: 2.1953351561741163

Epoch: 5| Step: 2
Training loss: 1.8150196075439453
Validation loss: 2.169819962593817

Epoch: 5| Step: 3
Training loss: 1.9380147457122803
Validation loss: 2.183060698611762

Epoch: 5| Step: 4
Training loss: 2.222883701324463
Validation loss: 2.1621078163064937

Epoch: 5| Step: 5
Training loss: 2.620638847351074
Validation loss: 2.103698133140482

Epoch: 5| Step: 6
Training loss: 2.0715160369873047
Validation loss: 2.1192997783742924

Epoch: 5| Step: 7
Training loss: 1.9281848669052124
Validation loss: 2.1464081784730316

Epoch: 5| Step: 8
Training loss: 2.1140475273132324
Validation loss: 2.1746240328716975

Epoch: 5| Step: 9
Training loss: 1.8164339065551758
Validation loss: 2.1299676228595037

Epoch: 5| Step: 10
Training loss: 1.7586160898208618
Validation loss: 2.145908860750096

Epoch: 248| Step: 0
Training loss: 1.2865393161773682
Validation loss: 2.127364932849843

Epoch: 5| Step: 1
Training loss: 1.7866744995117188
Validation loss: 2.131302741266066

Epoch: 5| Step: 2
Training loss: 2.1783156394958496
Validation loss: 2.2001044237485496

Epoch: 5| Step: 3
Training loss: 1.9451615810394287
Validation loss: 2.1721650221014537

Epoch: 5| Step: 4
Training loss: 1.9106239080429077
Validation loss: 2.1127964476103425

Epoch: 5| Step: 5
Training loss: 2.096331834793091
Validation loss: 2.212657226029263

Epoch: 5| Step: 6
Training loss: 2.1079444885253906
Validation loss: 2.1005262713278494

Epoch: 5| Step: 7
Training loss: 2.30010986328125
Validation loss: 2.1683074428189184

Epoch: 5| Step: 8
Training loss: 1.6991970539093018
Validation loss: 2.1496546883736887

Epoch: 5| Step: 9
Training loss: 1.8678433895111084
Validation loss: 2.179778129823746

Epoch: 5| Step: 10
Training loss: 2.5876357555389404
Validation loss: 2.174345039552258

Epoch: 249| Step: 0
Training loss: 2.196138381958008
Validation loss: 2.1593810332718717

Epoch: 5| Step: 1
Training loss: 2.0680713653564453
Validation loss: 2.1869928734276884

Epoch: 5| Step: 2
Training loss: 1.8709758520126343
Validation loss: 2.119076059710595

Epoch: 5| Step: 3
Training loss: 1.6434799432754517
Validation loss: 2.1250354166953795

Epoch: 5| Step: 4
Training loss: 2.107130527496338
Validation loss: 2.1314610435116674

Epoch: 5| Step: 5
Training loss: 2.323493480682373
Validation loss: 2.193247284940494

Epoch: 5| Step: 6
Training loss: 1.8170726299285889
Validation loss: 2.128407282214011

Epoch: 5| Step: 7
Training loss: 1.6846745014190674
Validation loss: 2.1873707373936973

Epoch: 5| Step: 8
Training loss: 2.3342208862304688
Validation loss: 2.1873009897047475

Epoch: 5| Step: 9
Training loss: 2.179182529449463
Validation loss: 2.1229133682866252

Epoch: 5| Step: 10
Training loss: 1.8379727602005005
Validation loss: 2.117703027622674

Epoch: 250| Step: 0
Training loss: 2.5940022468566895
Validation loss: 2.159293633635326

Epoch: 5| Step: 1
Training loss: 1.8159974813461304
Validation loss: 2.1236555140505553

Epoch: 5| Step: 2
Training loss: 2.515852689743042
Validation loss: 2.107272571133029

Epoch: 5| Step: 3
Training loss: 1.7689130306243896
Validation loss: 2.1584975693815496

Epoch: 5| Step: 4
Training loss: 2.2640764713287354
Validation loss: 2.1504179726364794

Epoch: 5| Step: 5
Training loss: 1.5031322240829468
Validation loss: 2.150269800616849

Epoch: 5| Step: 6
Training loss: 1.4471877813339233
Validation loss: 2.173082502939368

Epoch: 5| Step: 7
Training loss: 1.7915416955947876
Validation loss: 2.2056919964410926

Epoch: 5| Step: 8
Training loss: 2.758345127105713
Validation loss: 2.1370460730727

Epoch: 5| Step: 9
Training loss: 1.4868924617767334
Validation loss: 2.1565695501142934

Epoch: 5| Step: 10
Training loss: 2.5448365211486816
Validation loss: 2.1713540361773584

Epoch: 251| Step: 0
Training loss: 1.834205985069275
Validation loss: 2.155513701900359

Epoch: 5| Step: 1
Training loss: 2.1551146507263184
Validation loss: 2.1574525884402695

Epoch: 5| Step: 2
Training loss: 2.1488442420959473
Validation loss: 2.118923075737492

Epoch: 5| Step: 3
Training loss: 2.3306820392608643
Validation loss: 2.1332430326810448

Epoch: 5| Step: 4
Training loss: 1.8601291179656982
Validation loss: 2.062756433281847

Epoch: 5| Step: 5
Training loss: 1.6639297008514404
Validation loss: 2.120763671013617

Epoch: 5| Step: 6
Training loss: 2.216019868850708
Validation loss: 2.16394998950343

Epoch: 5| Step: 7
Training loss: 2.0624656677246094
Validation loss: 2.1920312668687556

Epoch: 5| Step: 8
Training loss: 1.9943039417266846
Validation loss: 2.141705231000018

Epoch: 5| Step: 9
Training loss: 2.4341747760772705
Validation loss: 2.1682746089914793

Epoch: 5| Step: 10
Training loss: 1.8636757135391235
Validation loss: 2.1581145742888093

Epoch: 252| Step: 0
Training loss: 2.4809539318084717
Validation loss: 2.1364963464839484

Epoch: 5| Step: 1
Training loss: 1.669498085975647
Validation loss: 2.13016221087466

Epoch: 5| Step: 2
Training loss: 1.7320823669433594
Validation loss: 2.1191343338258806

Epoch: 5| Step: 3
Training loss: 1.9724632501602173
Validation loss: 2.1409006144410823

Epoch: 5| Step: 4
Training loss: 1.6536359786987305
Validation loss: 2.158969279258482

Epoch: 5| Step: 5
Training loss: 2.555093765258789
Validation loss: 2.1132313025894987

Epoch: 5| Step: 6
Training loss: 1.7438701391220093
Validation loss: 2.130865079100414

Epoch: 5| Step: 7
Training loss: 2.3524043560028076
Validation loss: 2.128781990338397

Epoch: 5| Step: 8
Training loss: 2.0849573612213135
Validation loss: 2.121656381955711

Epoch: 5| Step: 9
Training loss: 1.732595443725586
Validation loss: 2.171523053158996

Epoch: 5| Step: 10
Training loss: 2.2198374271392822
Validation loss: 2.108241686256983

Epoch: 253| Step: 0
Training loss: 1.538867712020874
Validation loss: 2.172282474015349

Epoch: 5| Step: 1
Training loss: 1.7783466577529907
Validation loss: 2.2014915840600127

Epoch: 5| Step: 2
Training loss: 2.167905807495117
Validation loss: 2.179832440550609

Epoch: 5| Step: 3
Training loss: 2.6927924156188965
Validation loss: 2.1507244686926565

Epoch: 5| Step: 4
Training loss: 2.7831764221191406
Validation loss: 2.1578578051700386

Epoch: 5| Step: 5
Training loss: 1.83514404296875
Validation loss: 2.1609396678145214

Epoch: 5| Step: 6
Training loss: 1.6785223484039307
Validation loss: 2.1416108915882726

Epoch: 5| Step: 7
Training loss: 1.7609097957611084
Validation loss: 2.1790798607692925

Epoch: 5| Step: 8
Training loss: 2.2533938884735107
Validation loss: 2.141855901287448

Epoch: 5| Step: 9
Training loss: 2.2193188667297363
Validation loss: 2.0999357110710553

Epoch: 5| Step: 10
Training loss: 1.845354676246643
Validation loss: 2.2230054229818363

Epoch: 254| Step: 0
Training loss: 1.8337109088897705
Validation loss: 2.1940055713858655

Epoch: 5| Step: 1
Training loss: 1.5003173351287842
Validation loss: 2.1438615206749208

Epoch: 5| Step: 2
Training loss: 2.0377039909362793
Validation loss: 2.1542539429920975

Epoch: 5| Step: 3
Training loss: 2.134826898574829
Validation loss: 2.1281993773675736

Epoch: 5| Step: 4
Training loss: 2.098411798477173
Validation loss: 2.1503868154300156

Epoch: 5| Step: 5
Training loss: 1.952571153640747
Validation loss: 2.1645934876575263

Epoch: 5| Step: 6
Training loss: 2.1901895999908447
Validation loss: 2.1801862998675277

Epoch: 5| Step: 7
Training loss: 1.8538364171981812
Validation loss: 2.210823421837181

Epoch: 5| Step: 8
Training loss: 2.517082929611206
Validation loss: 2.08904234440096

Epoch: 5| Step: 9
Training loss: 1.97771418094635
Validation loss: 2.126556065774733

Epoch: 5| Step: 10
Training loss: 1.9494097232818604
Validation loss: 2.111404565072829

Epoch: 255| Step: 0
Training loss: 1.9480434656143188
Validation loss: 2.107284874044439

Epoch: 5| Step: 1
Training loss: 2.4777209758758545
Validation loss: 2.1464180933531893

Epoch: 5| Step: 2
Training loss: 2.0943121910095215
Validation loss: 2.1782259107917867

Epoch: 5| Step: 3
Training loss: 2.164757013320923
Validation loss: 2.0908659504305933

Epoch: 5| Step: 4
Training loss: 1.4556999206542969
Validation loss: 2.1761601945405364

Epoch: 5| Step: 5
Training loss: 1.9445991516113281
Validation loss: 2.122668012495964

Epoch: 5| Step: 6
Training loss: 2.377279281616211
Validation loss: 2.2040647691295994

Epoch: 5| Step: 7
Training loss: 2.2552378177642822
Validation loss: 2.115737509983842

Epoch: 5| Step: 8
Training loss: 1.6838710308074951
Validation loss: 2.199558460584251

Epoch: 5| Step: 9
Training loss: 1.6381022930145264
Validation loss: 2.161113098103513

Epoch: 5| Step: 10
Training loss: 2.084246873855591
Validation loss: 2.2087810116429485

Epoch: 256| Step: 0
Training loss: 2.0381972789764404
Validation loss: 2.151728577511285

Epoch: 5| Step: 1
Training loss: 2.807567596435547
Validation loss: 2.2005767219810077

Epoch: 5| Step: 2
Training loss: 1.7173064947128296
Validation loss: 2.146769982512279

Epoch: 5| Step: 3
Training loss: 2.4505648612976074
Validation loss: 2.112913864915089

Epoch: 5| Step: 4
Training loss: 1.6922569274902344
Validation loss: 2.1462982828899095

Epoch: 5| Step: 5
Training loss: 1.7622699737548828
Validation loss: 2.1311251040427917

Epoch: 5| Step: 6
Training loss: 1.663673758506775
Validation loss: 2.1296759484916605

Epoch: 5| Step: 7
Training loss: 2.1092758178710938
Validation loss: 2.1355849581380046

Epoch: 5| Step: 8
Training loss: 1.8695074319839478
Validation loss: 2.1422844945743518

Epoch: 5| Step: 9
Training loss: 2.049652576446533
Validation loss: 2.108479840781099

Epoch: 5| Step: 10
Training loss: 2.0049586296081543
Validation loss: 2.1335757060717513

Epoch: 257| Step: 0
Training loss: 2.184915781021118
Validation loss: 2.1989883351069626

Epoch: 5| Step: 1
Training loss: 2.0274176597595215
Validation loss: 2.090834245886854

Epoch: 5| Step: 2
Training loss: 2.367354393005371
Validation loss: 2.144595169251965

Epoch: 5| Step: 3
Training loss: 1.3490781784057617
Validation loss: 2.186899059562273

Epoch: 5| Step: 4
Training loss: 2.686830997467041
Validation loss: 2.146343837502182

Epoch: 5| Step: 5
Training loss: 1.409468412399292
Validation loss: 2.152940998795212

Epoch: 5| Step: 6
Training loss: 2.632622480392456
Validation loss: 2.1200902987551946

Epoch: 5| Step: 7
Training loss: 1.64761483669281
Validation loss: 2.107716288617862

Epoch: 5| Step: 8
Training loss: 2.217031955718994
Validation loss: 2.1589787096105595

Epoch: 5| Step: 9
Training loss: 1.983237862586975
Validation loss: 2.1056771457836194

Epoch: 5| Step: 10
Training loss: 1.9072535037994385
Validation loss: 2.0950380550917758

Epoch: 258| Step: 0
Training loss: 2.5968775749206543
Validation loss: 2.11988857740997

Epoch: 5| Step: 1
Training loss: 1.3509713411331177
Validation loss: 2.1489166867348457

Epoch: 5| Step: 2
Training loss: 1.5224249362945557
Validation loss: 2.155546631864322

Epoch: 5| Step: 3
Training loss: 2.1711530685424805
Validation loss: 2.2534684775978007

Epoch: 5| Step: 4
Training loss: 2.3239264488220215
Validation loss: 2.1652619325986473

Epoch: 5| Step: 5
Training loss: 1.4685862064361572
Validation loss: 2.171459356943766

Epoch: 5| Step: 6
Training loss: 2.7483386993408203
Validation loss: 2.1468960290314048

Epoch: 5| Step: 7
Training loss: 2.1087229251861572
Validation loss: 2.149896547358523

Epoch: 5| Step: 8
Training loss: 1.676189661026001
Validation loss: 2.2014834586010186

Epoch: 5| Step: 9
Training loss: 1.9534854888916016
Validation loss: 2.1626054881721415

Epoch: 5| Step: 10
Training loss: 2.2568416595458984
Validation loss: 2.1718279033578853

Epoch: 259| Step: 0
Training loss: 2.282649517059326
Validation loss: 2.200546735076494

Epoch: 5| Step: 1
Training loss: 1.355028748512268
Validation loss: 2.164350671152915

Epoch: 5| Step: 2
Training loss: 1.8973939418792725
Validation loss: 2.1171177164200814

Epoch: 5| Step: 3
Training loss: 1.7320514917373657
Validation loss: 2.1659435149162047

Epoch: 5| Step: 4
Training loss: 2.4251458644866943
Validation loss: 2.1823280267818

Epoch: 5| Step: 5
Training loss: 1.2899259328842163
Validation loss: 2.229947918204851

Epoch: 5| Step: 6
Training loss: 1.7716814279556274
Validation loss: 2.146853082923479

Epoch: 5| Step: 7
Training loss: 1.917395830154419
Validation loss: 2.120964252820579

Epoch: 5| Step: 8
Training loss: 2.2667922973632812
Validation loss: 2.1102804471087713

Epoch: 5| Step: 9
Training loss: 2.570117473602295
Validation loss: 2.215634528026786

Epoch: 5| Step: 10
Training loss: 2.3873395919799805
Validation loss: 2.136932921665971

Epoch: 260| Step: 0
Training loss: 1.9972196817398071
Validation loss: 2.1360249160438456

Epoch: 5| Step: 1
Training loss: 2.230663776397705
Validation loss: 2.1456859291240735

Epoch: 5| Step: 2
Training loss: 1.8275171518325806
Validation loss: 2.157403317830896

Epoch: 5| Step: 3
Training loss: 2.016249895095825
Validation loss: 2.1127308094373314

Epoch: 5| Step: 4
Training loss: 2.1242012977600098
Validation loss: 2.188018270718154

Epoch: 5| Step: 5
Training loss: 2.027428150177002
Validation loss: 2.119803076149315

Epoch: 5| Step: 6
Training loss: 2.9320015907287598
Validation loss: 2.1136274901769494

Epoch: 5| Step: 7
Training loss: 2.454179286956787
Validation loss: 2.1608426058164207

Epoch: 5| Step: 8
Training loss: 1.2877699136734009
Validation loss: 2.122617067829255

Epoch: 5| Step: 9
Training loss: 1.4501956701278687
Validation loss: 2.1113245487213135

Epoch: 5| Step: 10
Training loss: 1.987280011177063
Validation loss: 2.1937871556128226

Epoch: 261| Step: 0
Training loss: 1.843872308731079
Validation loss: 2.194590336533003

Epoch: 5| Step: 1
Training loss: 2.44608998298645
Validation loss: 2.1451221589119203

Epoch: 5| Step: 2
Training loss: 1.938661813735962
Validation loss: 2.211596388970652

Epoch: 5| Step: 3
Training loss: 2.030864715576172
Validation loss: 2.1969738647501957

Epoch: 5| Step: 4
Training loss: 1.9921646118164062
Validation loss: 2.1863086223602295

Epoch: 5| Step: 5
Training loss: 1.5449836254119873
Validation loss: 2.0794579162392566

Epoch: 5| Step: 6
Training loss: 1.1940569877624512
Validation loss: 2.113704236604834

Epoch: 5| Step: 7
Training loss: 2.2558693885803223
Validation loss: 2.112744341614426

Epoch: 5| Step: 8
Training loss: 2.4100115299224854
Validation loss: 2.166186927467264

Epoch: 5| Step: 9
Training loss: 2.242819309234619
Validation loss: 2.1910435512501705

Epoch: 5| Step: 10
Training loss: 1.7491998672485352
Validation loss: 2.1438972770526843

Epoch: 262| Step: 0
Training loss: 1.7454726696014404
Validation loss: 2.176822781562805

Epoch: 5| Step: 1
Training loss: 2.244723081588745
Validation loss: 2.1349694062304754

Epoch: 5| Step: 2
Training loss: 2.2792980670928955
Validation loss: 2.150899846066711

Epoch: 5| Step: 3
Training loss: 2.0404486656188965
Validation loss: 2.1343679633191837

Epoch: 5| Step: 4
Training loss: 1.9146091938018799
Validation loss: 2.139642443708194

Epoch: 5| Step: 5
Training loss: 2.061685562133789
Validation loss: 2.182680215886844

Epoch: 5| Step: 6
Training loss: 1.1842085123062134
Validation loss: 2.1631193135374334

Epoch: 5| Step: 7
Training loss: 1.7222750186920166
Validation loss: 2.1587943902579685

Epoch: 5| Step: 8
Training loss: 2.1090872287750244
Validation loss: 2.121240015952818

Epoch: 5| Step: 9
Training loss: 2.520246744155884
Validation loss: 2.1422793519112373

Epoch: 5| Step: 10
Training loss: 1.677504539489746
Validation loss: 2.107913492828287

Epoch: 263| Step: 0
Training loss: 2.0180163383483887
Validation loss: 2.1737604897509337

Epoch: 5| Step: 1
Training loss: 2.2221500873565674
Validation loss: 2.095968133659773

Epoch: 5| Step: 2
Training loss: 1.6264604330062866
Validation loss: 2.215011296733733

Epoch: 5| Step: 3
Training loss: 2.1232731342315674
Validation loss: 2.182133218293549

Epoch: 5| Step: 4
Training loss: 1.8382259607315063
Validation loss: 2.1357052582566456

Epoch: 5| Step: 5
Training loss: 1.733696699142456
Validation loss: 2.192961385173182

Epoch: 5| Step: 6
Training loss: 1.9921785593032837
Validation loss: 2.211730775012765

Epoch: 5| Step: 7
Training loss: 1.9773982763290405
Validation loss: 2.1182318451584026

Epoch: 5| Step: 8
Training loss: 2.0310018062591553
Validation loss: 2.177350337787341

Epoch: 5| Step: 9
Training loss: 2.0255661010742188
Validation loss: 2.1158068282629854

Epoch: 5| Step: 10
Training loss: 2.3769397735595703
Validation loss: 2.233342488606771

Epoch: 264| Step: 0
Training loss: 2.3180665969848633
Validation loss: 2.130371009149859

Epoch: 5| Step: 1
Training loss: 1.7348148822784424
Validation loss: 2.1209534880935506

Epoch: 5| Step: 2
Training loss: 2.1866295337677
Validation loss: 2.1425282339895926

Epoch: 5| Step: 3
Training loss: 2.551619529724121
Validation loss: 2.1625572289189985

Epoch: 5| Step: 4
Training loss: 1.958839774131775
Validation loss: 2.2475655181433565

Epoch: 5| Step: 5
Training loss: 1.852189064025879
Validation loss: 2.186599008498653

Epoch: 5| Step: 6
Training loss: 1.263867974281311
Validation loss: 2.1737549484417005

Epoch: 5| Step: 7
Training loss: 2.026017904281616
Validation loss: 2.2268629497097385

Epoch: 5| Step: 8
Training loss: 1.8456112146377563
Validation loss: 2.1367766857147217

Epoch: 5| Step: 9
Training loss: 2.307192802429199
Validation loss: 2.157562176386515

Epoch: 5| Step: 10
Training loss: 1.5382568836212158
Validation loss: 2.1072492804578555

Epoch: 265| Step: 0
Training loss: 2.243440628051758
Validation loss: 2.1578624376686673

Epoch: 5| Step: 1
Training loss: 2.044153928756714
Validation loss: 2.231344520404775

Epoch: 5| Step: 2
Training loss: 2.187129020690918
Validation loss: 2.145094903566504

Epoch: 5| Step: 3
Training loss: 1.8242082595825195
Validation loss: 2.148230706491778

Epoch: 5| Step: 4
Training loss: 2.5610008239746094
Validation loss: 2.1517586810614473

Epoch: 5| Step: 5
Training loss: 1.7401126623153687
Validation loss: 2.147654714122895

Epoch: 5| Step: 6
Training loss: 1.862017273902893
Validation loss: 2.1834725090252456

Epoch: 5| Step: 7
Training loss: 2.0658748149871826
Validation loss: 2.153699787714148

Epoch: 5| Step: 8
Training loss: 1.9481074810028076
Validation loss: 2.14919771686677

Epoch: 5| Step: 9
Training loss: 2.0146689414978027
Validation loss: 2.222189841731902

Epoch: 5| Step: 10
Training loss: 1.6548832654953003
Validation loss: 2.1138374459358955

Epoch: 266| Step: 0
Training loss: 1.8680843114852905
Validation loss: 2.1339029829989196

Epoch: 5| Step: 1
Training loss: 2.213172435760498
Validation loss: 2.1867845186623196

Epoch: 5| Step: 2
Training loss: 2.0737013816833496
Validation loss: 2.167352077781513

Epoch: 5| Step: 3
Training loss: 1.8329722881317139
Validation loss: 2.1543753800853604

Epoch: 5| Step: 4
Training loss: 1.5658025741577148
Validation loss: 2.1152437117791947

Epoch: 5| Step: 5
Training loss: 1.5020496845245361
Validation loss: 2.1082546300785516

Epoch: 5| Step: 6
Training loss: 2.2598860263824463
Validation loss: 2.112968267933015

Epoch: 5| Step: 7
Training loss: 1.822750449180603
Validation loss: 2.128058829615193

Epoch: 5| Step: 8
Training loss: 1.9673343896865845
Validation loss: 2.154037461485914

Epoch: 5| Step: 9
Training loss: 2.433560609817505
Validation loss: 2.146986590918674

Epoch: 5| Step: 10
Training loss: 1.9915361404418945
Validation loss: 2.141021179896529

Epoch: 267| Step: 0
Training loss: 1.5341522693634033
Validation loss: 2.1492340795455442

Epoch: 5| Step: 1
Training loss: 1.8777412176132202
Validation loss: 2.1460690600897676

Epoch: 5| Step: 2
Training loss: 2.6368985176086426
Validation loss: 2.079477443489977

Epoch: 5| Step: 3
Training loss: 1.1208702325820923
Validation loss: 2.144688331952659

Epoch: 5| Step: 4
Training loss: 1.8732913732528687
Validation loss: 2.1446853491567794

Epoch: 5| Step: 5
Training loss: 2.2439732551574707
Validation loss: 2.2012350866871495

Epoch: 5| Step: 6
Training loss: 1.9871364831924438
Validation loss: 2.219341580585767

Epoch: 5| Step: 7
Training loss: 2.286674976348877
Validation loss: 2.15253645630293

Epoch: 5| Step: 8
Training loss: 2.1289196014404297
Validation loss: 2.1120156934184413

Epoch: 5| Step: 9
Training loss: 1.7429479360580444
Validation loss: 2.143230502323438

Epoch: 5| Step: 10
Training loss: 2.1590161323547363
Validation loss: 2.1013592878977456

Epoch: 268| Step: 0
Training loss: 1.8347305059432983
Validation loss: 2.106262259585883

Epoch: 5| Step: 1
Training loss: 1.8663288354873657
Validation loss: 2.1144604888013614

Epoch: 5| Step: 2
Training loss: 2.5880203247070312
Validation loss: 2.125188392977561

Epoch: 5| Step: 3
Training loss: 1.9003902673721313
Validation loss: 2.1609674064061974

Epoch: 5| Step: 4
Training loss: 1.6731866598129272
Validation loss: 2.1253623577856247

Epoch: 5| Step: 5
Training loss: 1.8686141967773438
Validation loss: 2.1713531581304406

Epoch: 5| Step: 6
Training loss: 2.168318271636963
Validation loss: 2.1128397859552854

Epoch: 5| Step: 7
Training loss: 1.7978365421295166
Validation loss: 2.149244011089366

Epoch: 5| Step: 8
Training loss: 2.008317470550537
Validation loss: 2.1843110784407584

Epoch: 5| Step: 9
Training loss: 1.6906810998916626
Validation loss: 2.1836557478033085

Epoch: 5| Step: 10
Training loss: 1.881872534751892
Validation loss: 2.193752278563797

Epoch: 269| Step: 0
Training loss: 2.0434670448303223
Validation loss: 2.1084100251556723

Epoch: 5| Step: 1
Training loss: 2.5484440326690674
Validation loss: 2.178675461840886

Epoch: 5| Step: 2
Training loss: 1.669887900352478
Validation loss: 2.1378122709130727

Epoch: 5| Step: 3
Training loss: 2.0551302433013916
Validation loss: 2.128519727337745

Epoch: 5| Step: 4
Training loss: 1.2500691413879395
Validation loss: 2.1649180484074417

Epoch: 5| Step: 5
Training loss: 1.7755377292633057
Validation loss: 2.131122657047805

Epoch: 5| Step: 6
Training loss: 1.7883358001708984
Validation loss: 2.157277871203679

Epoch: 5| Step: 7
Training loss: 2.220550537109375
Validation loss: 2.1291483397124917

Epoch: 5| Step: 8
Training loss: 1.408646821975708
Validation loss: 2.1103969556029125

Epoch: 5| Step: 9
Training loss: 2.6898627281188965
Validation loss: 2.1236210587204143

Epoch: 5| Step: 10
Training loss: 2.329542398452759
Validation loss: 2.1417456288491525

Epoch: 270| Step: 0
Training loss: 1.9952319860458374
Validation loss: 2.0766559672612015

Epoch: 5| Step: 1
Training loss: 1.7371034622192383
Validation loss: 2.154754501517101

Epoch: 5| Step: 2
Training loss: 1.3995193243026733
Validation loss: 2.1290971386817192

Epoch: 5| Step: 3
Training loss: 2.2389495372772217
Validation loss: 2.20759174131578

Epoch: 5| Step: 4
Training loss: 1.9950510263442993
Validation loss: 2.1379985245325233

Epoch: 5| Step: 5
Training loss: 2.207608222961426
Validation loss: 2.2142406407222954

Epoch: 5| Step: 6
Training loss: 1.5462373495101929
Validation loss: 2.1302477634081276

Epoch: 5| Step: 7
Training loss: 2.166111469268799
Validation loss: 2.149029679195855

Epoch: 5| Step: 8
Training loss: 1.9273723363876343
Validation loss: 2.1524507153418755

Epoch: 5| Step: 9
Training loss: 2.364301919937134
Validation loss: 2.1900378760471138

Epoch: 5| Step: 10
Training loss: 2.7001447677612305
Validation loss: 2.1523451779478338

Epoch: 271| Step: 0
Training loss: 1.4481327533721924
Validation loss: 2.175530666946083

Epoch: 5| Step: 1
Training loss: 2.0283164978027344
Validation loss: 2.2261050260195168

Epoch: 5| Step: 2
Training loss: 1.5847344398498535
Validation loss: 2.1812689073624147

Epoch: 5| Step: 3
Training loss: 1.859534502029419
Validation loss: 2.1776955691717004

Epoch: 5| Step: 4
Training loss: 1.9462887048721313
Validation loss: 2.1929172649178454

Epoch: 5| Step: 5
Training loss: 2.4667727947235107
Validation loss: 2.1595922593147523

Epoch: 5| Step: 6
Training loss: 2.146592140197754
Validation loss: 2.1092779508201023

Epoch: 5| Step: 7
Training loss: 1.94033682346344
Validation loss: 2.1660150994536695

Epoch: 5| Step: 8
Training loss: 1.6067898273468018
Validation loss: 2.1212425308842815

Epoch: 5| Step: 9
Training loss: 2.1142842769622803
Validation loss: 2.1728209782672185

Epoch: 5| Step: 10
Training loss: 2.4276974201202393
Validation loss: 2.137886619055143

Epoch: 272| Step: 0
Training loss: 1.9549589157104492
Validation loss: 2.1463376834828365

Epoch: 5| Step: 1
Training loss: 1.9619333744049072
Validation loss: 2.1728296395271056

Epoch: 5| Step: 2
Training loss: 1.8217756748199463
Validation loss: 2.190385687735773

Epoch: 5| Step: 3
Training loss: 2.1968636512756348
Validation loss: 2.0919357781769126

Epoch: 5| Step: 4
Training loss: 1.2260818481445312
Validation loss: 2.197656572505992

Epoch: 5| Step: 5
Training loss: 1.5853254795074463
Validation loss: 2.132836041911956

Epoch: 5| Step: 6
Training loss: 2.0493884086608887
Validation loss: 2.1837958699913433

Epoch: 5| Step: 7
Training loss: 2.037325859069824
Validation loss: 2.148290252172819

Epoch: 5| Step: 8
Training loss: 2.2425742149353027
Validation loss: 2.1597532867103495

Epoch: 5| Step: 9
Training loss: 1.7509788274765015
Validation loss: 2.2102518671302387

Epoch: 5| Step: 10
Training loss: 2.5088462829589844
Validation loss: 2.0873019259463073

Epoch: 273| Step: 0
Training loss: 2.3557753562927246
Validation loss: 2.239648006295645

Epoch: 5| Step: 1
Training loss: 1.982858657836914
Validation loss: 2.153560402572796

Epoch: 5| Step: 2
Training loss: 2.3232672214508057
Validation loss: 2.1497845277991345

Epoch: 5| Step: 3
Training loss: 1.980663537979126
Validation loss: 2.1515217955394457

Epoch: 5| Step: 4
Training loss: 1.3740648031234741
Validation loss: 2.185568207053728

Epoch: 5| Step: 5
Training loss: 2.235032081604004
Validation loss: 2.1369284224766556

Epoch: 5| Step: 6
Training loss: 1.7723522186279297
Validation loss: 2.1125753477055538

Epoch: 5| Step: 7
Training loss: 1.7796423435211182
Validation loss: 2.150195360183716

Epoch: 5| Step: 8
Training loss: 1.875634789466858
Validation loss: 2.1340991579076296

Epoch: 5| Step: 9
Training loss: 1.5356301069259644
Validation loss: 2.1614522536595664

Epoch: 5| Step: 10
Training loss: 2.409933090209961
Validation loss: 2.125006063010103

Epoch: 274| Step: 0
Training loss: 2.1108603477478027
Validation loss: 2.1580503781636557

Epoch: 5| Step: 1
Training loss: 1.9296321868896484
Validation loss: 2.1728962749563236

Epoch: 5| Step: 2
Training loss: 1.9968254566192627
Validation loss: 2.178939416844358

Epoch: 5| Step: 3
Training loss: 1.9314062595367432
Validation loss: 2.1819907619107153

Epoch: 5| Step: 4
Training loss: 1.563307523727417
Validation loss: 2.1663305297974618

Epoch: 5| Step: 5
Training loss: 2.1030259132385254
Validation loss: 2.141899544705627

Epoch: 5| Step: 6
Training loss: 2.3349111080169678
Validation loss: 2.152701349668605

Epoch: 5| Step: 7
Training loss: 1.776673674583435
Validation loss: 2.224749157505651

Epoch: 5| Step: 8
Training loss: 2.063448905944824
Validation loss: 2.161648319613549

Epoch: 5| Step: 9
Training loss: 2.0067927837371826
Validation loss: 2.1045424322928152

Epoch: 5| Step: 10
Training loss: 2.158986806869507
Validation loss: 2.2171008433065107

Epoch: 275| Step: 0
Training loss: 2.19920015335083
Validation loss: 2.223124670725997

Epoch: 5| Step: 1
Training loss: 1.555764079093933
Validation loss: 2.1602246735685613

Epoch: 5| Step: 2
Training loss: 2.413022994995117
Validation loss: 2.207669029953659

Epoch: 5| Step: 3
Training loss: 1.6133339405059814
Validation loss: 2.1062396469936577

Epoch: 5| Step: 4
Training loss: 1.640906572341919
Validation loss: 2.1715753539916007

Epoch: 5| Step: 5
Training loss: 2.0432472229003906
Validation loss: 2.207505351753645

Epoch: 5| Step: 6
Training loss: 1.8187614679336548
Validation loss: 2.149172898261778

Epoch: 5| Step: 7
Training loss: 2.55446195602417
Validation loss: 2.1791131983521166

Epoch: 5| Step: 8
Training loss: 1.9172710180282593
Validation loss: 2.140828610748373

Epoch: 5| Step: 9
Training loss: 1.993908166885376
Validation loss: 2.197261974375735

Epoch: 5| Step: 10
Training loss: 1.872328758239746
Validation loss: 2.0971188711863693

Epoch: 276| Step: 0
Training loss: 2.7800464630126953
Validation loss: 2.1322398031911542

Epoch: 5| Step: 1
Training loss: 2.06636381149292
Validation loss: 2.11706809074648

Epoch: 5| Step: 2
Training loss: 2.0222606658935547
Validation loss: 2.1286270605620516

Epoch: 5| Step: 3
Training loss: 1.8741111755371094
Validation loss: 2.1946507756428053

Epoch: 5| Step: 4
Training loss: 1.7278363704681396
Validation loss: 2.180609054462884

Epoch: 5| Step: 5
Training loss: 1.625920057296753
Validation loss: 2.144638402487642

Epoch: 5| Step: 6
Training loss: 2.3464550971984863
Validation loss: 2.1434167815792944

Epoch: 5| Step: 7
Training loss: 2.2296650409698486
Validation loss: 2.190666442276329

Epoch: 5| Step: 8
Training loss: 1.695399522781372
Validation loss: 2.1525918822134695

Epoch: 5| Step: 9
Training loss: 1.7434818744659424
Validation loss: 2.187407875573763

Epoch: 5| Step: 10
Training loss: 1.2579898834228516
Validation loss: 2.1344396055385633

Epoch: 277| Step: 0
Training loss: 2.0425562858581543
Validation loss: 2.0997836679540653

Epoch: 5| Step: 1
Training loss: 2.094717025756836
Validation loss: 2.1257821154850784

Epoch: 5| Step: 2
Training loss: 2.667717933654785
Validation loss: 2.1225453038369455

Epoch: 5| Step: 3
Training loss: 1.8783409595489502
Validation loss: 2.1763062541202833

Epoch: 5| Step: 4
Training loss: 2.080334186553955
Validation loss: 2.1353160770990516

Epoch: 5| Step: 5
Training loss: 1.8513110876083374
Validation loss: 2.203579366848033

Epoch: 5| Step: 6
Training loss: 1.9834983348846436
Validation loss: 2.141235398989852

Epoch: 5| Step: 7
Training loss: 1.4568917751312256
Validation loss: 2.1800616479689077

Epoch: 5| Step: 8
Training loss: 1.5987207889556885
Validation loss: 2.1246887304449595

Epoch: 5| Step: 9
Training loss: 2.398073434829712
Validation loss: 2.1914867278068297

Epoch: 5| Step: 10
Training loss: 1.4263296127319336
Validation loss: 2.1932583547407583

Epoch: 278| Step: 0
Training loss: 2.0579028129577637
Validation loss: 2.200440281180925

Epoch: 5| Step: 1
Training loss: 1.809816598892212
Validation loss: 2.188560701185657

Epoch: 5| Step: 2
Training loss: 1.9205782413482666
Validation loss: 2.15416964151526

Epoch: 5| Step: 3
Training loss: 1.856217622756958
Validation loss: 2.209087267998726

Epoch: 5| Step: 4
Training loss: 1.7003042697906494
Validation loss: 2.1685157847660843

Epoch: 5| Step: 5
Training loss: 2.000502347946167
Validation loss: 2.144019156373957

Epoch: 5| Step: 6
Training loss: 1.1932376623153687
Validation loss: 2.1597102021658294

Epoch: 5| Step: 7
Training loss: 1.9006363153457642
Validation loss: 2.200751732754451

Epoch: 5| Step: 8
Training loss: 3.153482437133789
Validation loss: 2.145484288533529

Epoch: 5| Step: 9
Training loss: 1.9698944091796875
Validation loss: 2.1606205099372455

Epoch: 5| Step: 10
Training loss: 1.6368217468261719
Validation loss: 2.215518124641911

Epoch: 279| Step: 0
Training loss: 2.065155506134033
Validation loss: 2.1327242005255913

Epoch: 5| Step: 1
Training loss: 1.7988582849502563
Validation loss: 2.1333599641758907

Epoch: 5| Step: 2
Training loss: 2.003239154815674
Validation loss: 2.1226294579044467

Epoch: 5| Step: 3
Training loss: 1.5861728191375732
Validation loss: 2.163571775600474

Epoch: 5| Step: 4
Training loss: 1.9864425659179688
Validation loss: 2.134103851933633

Epoch: 5| Step: 5
Training loss: 2.72479510307312
Validation loss: 2.211636645819551

Epoch: 5| Step: 6
Training loss: 1.8207292556762695
Validation loss: 2.1737891986805904

Epoch: 5| Step: 7
Training loss: 1.4479552507400513
Validation loss: 2.165853954130603

Epoch: 5| Step: 8
Training loss: 2.3378872871398926
Validation loss: 2.206333662873955

Epoch: 5| Step: 9
Training loss: 1.814528465270996
Validation loss: 2.1042673600617277

Epoch: 5| Step: 10
Training loss: 2.0689098834991455
Validation loss: 2.128496818645026

Epoch: 280| Step: 0
Training loss: 1.9656116962432861
Validation loss: 2.147346709364204

Epoch: 5| Step: 1
Training loss: 1.6669584512710571
Validation loss: 2.1734802902385755

Epoch: 5| Step: 2
Training loss: 1.68832528591156
Validation loss: 2.133773483255858

Epoch: 5| Step: 3
Training loss: 2.4855716228485107
Validation loss: 2.171593709658551

Epoch: 5| Step: 4
Training loss: 2.313605546951294
Validation loss: 2.1527180287145797

Epoch: 5| Step: 5
Training loss: 1.8532264232635498
Validation loss: 2.1686029716204573

Epoch: 5| Step: 6
Training loss: 2.5299906730651855
Validation loss: 2.2083646738401024

Epoch: 5| Step: 7
Training loss: 1.3316482305526733
Validation loss: 2.161425672551637

Epoch: 5| Step: 8
Training loss: 2.0260162353515625
Validation loss: 2.1459909959505965

Epoch: 5| Step: 9
Training loss: 2.1167140007019043
Validation loss: 2.1086274513634304

Epoch: 5| Step: 10
Training loss: 2.382092237472534
Validation loss: 2.1421382619488623

Epoch: 281| Step: 0
Training loss: 2.066885471343994
Validation loss: 2.1597085075993694

Epoch: 5| Step: 1
Training loss: 2.2340760231018066
Validation loss: 2.1509017072698122

Epoch: 5| Step: 2
Training loss: 1.7693557739257812
Validation loss: 2.0893685176808345

Epoch: 5| Step: 3
Training loss: 1.771641492843628
Validation loss: 2.1735005224904707

Epoch: 5| Step: 4
Training loss: 1.9537996053695679
Validation loss: 2.1364420972844607

Epoch: 5| Step: 5
Training loss: 1.7950681447982788
Validation loss: 2.147344184178178

Epoch: 5| Step: 6
Training loss: 1.9690520763397217
Validation loss: 2.160741877812211

Epoch: 5| Step: 7
Training loss: 1.7711206674575806
Validation loss: 2.179048494626117

Epoch: 5| Step: 8
Training loss: 1.9874120950698853
Validation loss: 2.176064060580346

Epoch: 5| Step: 9
Training loss: 1.5341336727142334
Validation loss: 2.2110237383073374

Epoch: 5| Step: 10
Training loss: 2.506953477859497
Validation loss: 2.138205974332748

Epoch: 282| Step: 0
Training loss: 1.4974859952926636
Validation loss: 2.1716503122801423

Epoch: 5| Step: 1
Training loss: 1.8991315364837646
Validation loss: 2.1269592239010717

Epoch: 5| Step: 2
Training loss: 1.7429676055908203
Validation loss: 2.2156111527514715

Epoch: 5| Step: 3
Training loss: 1.3546712398529053
Validation loss: 2.1029508024133663

Epoch: 5| Step: 4
Training loss: 2.047826051712036
Validation loss: 2.223044628738075

Epoch: 5| Step: 5
Training loss: 2.267909288406372
Validation loss: 2.151398056296892

Epoch: 5| Step: 6
Training loss: 2.422201156616211
Validation loss: 2.197473479855445

Epoch: 5| Step: 7
Training loss: 1.9912726879119873
Validation loss: 2.1838557438183854

Epoch: 5| Step: 8
Training loss: 1.351694107055664
Validation loss: 2.171082427424769

Epoch: 5| Step: 9
Training loss: 2.580475091934204
Validation loss: 2.1746881059421006

Epoch: 5| Step: 10
Training loss: 1.7904268503189087
Validation loss: 2.190790501973962

Epoch: 283| Step: 0
Training loss: 2.019965648651123
Validation loss: 2.1905155463885237

Epoch: 5| Step: 1
Training loss: 1.2108234167099
Validation loss: 2.1612847940896147

Epoch: 5| Step: 2
Training loss: 1.8061845302581787
Validation loss: 2.1728405798635175

Epoch: 5| Step: 3
Training loss: 2.5554490089416504
Validation loss: 2.2185488926467074

Epoch: 5| Step: 4
Training loss: 2.0382778644561768
Validation loss: 2.1722792912555

Epoch: 5| Step: 5
Training loss: 1.5786930322647095
Validation loss: 2.1725633349469913

Epoch: 5| Step: 6
Training loss: 1.6498966217041016
Validation loss: 2.1801466800833262

Epoch: 5| Step: 7
Training loss: 2.1189091205596924
Validation loss: 2.1327762578123357

Epoch: 5| Step: 8
Training loss: 2.9479267597198486
Validation loss: 2.169695064585696

Epoch: 5| Step: 9
Training loss: 2.018477201461792
Validation loss: 2.1954579737878617

Epoch: 5| Step: 10
Training loss: 1.5274821519851685
Validation loss: 2.1579282206873738

Epoch: 284| Step: 0
Training loss: 2.032392978668213
Validation loss: 2.263921248015537

Epoch: 5| Step: 1
Training loss: 2.076648473739624
Validation loss: 2.1541407928671887

Epoch: 5| Step: 2
Training loss: 1.8423722982406616
Validation loss: 2.0828988782821165

Epoch: 5| Step: 3
Training loss: 2.1271705627441406
Validation loss: 2.169533403970862

Epoch: 5| Step: 4
Training loss: 1.5061999559402466
Validation loss: 2.1409917339201896

Epoch: 5| Step: 5
Training loss: 1.837175965309143
Validation loss: 2.1076071980178996

Epoch: 5| Step: 6
Training loss: 1.5302644968032837
Validation loss: 2.1603267141567764

Epoch: 5| Step: 7
Training loss: 1.6200764179229736
Validation loss: 2.1754877746746106

Epoch: 5| Step: 8
Training loss: 1.9400033950805664
Validation loss: 2.1123106197644304

Epoch: 5| Step: 9
Training loss: 2.4140539169311523
Validation loss: 2.0917692158811834

Epoch: 5| Step: 10
Training loss: 2.144165277481079
Validation loss: 2.0831058589361047

Epoch: 285| Step: 0
Training loss: 1.6667659282684326
Validation loss: 2.1423916585983767

Epoch: 5| Step: 1
Training loss: 2.3090217113494873
Validation loss: 2.0987115726676038

Epoch: 5| Step: 2
Training loss: 2.1070539951324463
Validation loss: 2.0831211587434173

Epoch: 5| Step: 3
Training loss: 1.7685960531234741
Validation loss: 2.1187085438800115

Epoch: 5| Step: 4
Training loss: 2.1009838581085205
Validation loss: 2.1705608303828905

Epoch: 5| Step: 5
Training loss: 1.6807228326797485
Validation loss: 2.2000647616642777

Epoch: 5| Step: 6
Training loss: 2.412161350250244
Validation loss: 2.136492326695432

Epoch: 5| Step: 7
Training loss: 1.3785603046417236
Validation loss: 2.1438720969743628

Epoch: 5| Step: 8
Training loss: 1.935831069946289
Validation loss: 2.155060314363049

Epoch: 5| Step: 9
Training loss: 1.682342767715454
Validation loss: 2.125819811256983

Epoch: 5| Step: 10
Training loss: 1.903850793838501
Validation loss: 2.0685414421942925

Epoch: 286| Step: 0
Training loss: 2.1094002723693848
Validation loss: 2.209294457589426

Epoch: 5| Step: 1
Training loss: 1.787372350692749
Validation loss: 2.149753966639119

Epoch: 5| Step: 2
Training loss: 1.7407045364379883
Validation loss: 2.1579162792492936

Epoch: 5| Step: 3
Training loss: 1.6519625186920166
Validation loss: 2.2185019728957966

Epoch: 5| Step: 4
Training loss: 2.029547691345215
Validation loss: 2.1774417943851923

Epoch: 5| Step: 5
Training loss: 1.3181960582733154
Validation loss: 2.1991366468450075

Epoch: 5| Step: 6
Training loss: 1.6090047359466553
Validation loss: 2.148897845257995

Epoch: 5| Step: 7
Training loss: 2.376988172531128
Validation loss: 2.1723028126583306

Epoch: 5| Step: 8
Training loss: 2.4788737297058105
Validation loss: 2.1738882577547463

Epoch: 5| Step: 9
Training loss: 1.6322017908096313
Validation loss: 2.167732479751751

Epoch: 5| Step: 10
Training loss: 2.311851978302002
Validation loss: 2.17768451475328

Epoch: 287| Step: 0
Training loss: 2.1711153984069824
Validation loss: 2.1676052872852614

Epoch: 5| Step: 1
Training loss: 2.181597948074341
Validation loss: 2.1768687232848136

Epoch: 5| Step: 2
Training loss: 2.2409820556640625
Validation loss: 2.191785627795804

Epoch: 5| Step: 3
Training loss: 1.500227928161621
Validation loss: 2.2195332165687316

Epoch: 5| Step: 4
Training loss: 2.0150790214538574
Validation loss: 2.1625671040627266

Epoch: 5| Step: 5
Training loss: 1.992409348487854
Validation loss: 2.1572942631219023

Epoch: 5| Step: 6
Training loss: 1.9913570880889893
Validation loss: 2.2002971377424014

Epoch: 5| Step: 7
Training loss: 1.6278305053710938
Validation loss: 2.144948423549693

Epoch: 5| Step: 8
Training loss: 1.678285002708435
Validation loss: 2.10706191678201

Epoch: 5| Step: 9
Training loss: 1.880231499671936
Validation loss: 2.1725008564610637

Epoch: 5| Step: 10
Training loss: 1.9700061082839966
Validation loss: 2.1866426185895036

Epoch: 288| Step: 0
Training loss: 1.8432466983795166
Validation loss: 2.1246625928468603

Epoch: 5| Step: 1
Training loss: 1.6206166744232178
Validation loss: 2.114867118097121

Epoch: 5| Step: 2
Training loss: 2.5375514030456543
Validation loss: 2.2138617641182354

Epoch: 5| Step: 3
Training loss: 1.9493684768676758
Validation loss: 2.1542652589018627

Epoch: 5| Step: 4
Training loss: 2.1827855110168457
Validation loss: 2.1629783389388875

Epoch: 5| Step: 5
Training loss: 1.3709778785705566
Validation loss: 2.146672205258441

Epoch: 5| Step: 6
Training loss: 2.244513988494873
Validation loss: 2.204401860954941

Epoch: 5| Step: 7
Training loss: 1.5622100830078125
Validation loss: 2.135647581469628

Epoch: 5| Step: 8
Training loss: 1.5784571170806885
Validation loss: 2.155438810266474

Epoch: 5| Step: 9
Training loss: 2.2582356929779053
Validation loss: 2.0464092749421314

Epoch: 5| Step: 10
Training loss: 1.9310026168823242
Validation loss: 2.1676016417882775

Epoch: 289| Step: 0
Training loss: 2.4718422889709473
Validation loss: 2.149273016119516

Epoch: 5| Step: 1
Training loss: 1.869929313659668
Validation loss: 2.191471025507937

Epoch: 5| Step: 2
Training loss: 2.1174676418304443
Validation loss: 2.1767985461860575

Epoch: 5| Step: 3
Training loss: 1.9553009271621704
Validation loss: 2.1456033158045944

Epoch: 5| Step: 4
Training loss: 1.7993097305297852
Validation loss: 2.1066894672250234

Epoch: 5| Step: 5
Training loss: 2.269132137298584
Validation loss: 2.0811761169023413

Epoch: 5| Step: 6
Training loss: 2.0441741943359375
Validation loss: 2.1281275890206777

Epoch: 5| Step: 7
Training loss: 1.686357855796814
Validation loss: 2.1721042535638295

Epoch: 5| Step: 8
Training loss: 1.8273168802261353
Validation loss: 2.086856065257903

Epoch: 5| Step: 9
Training loss: 1.3155779838562012
Validation loss: 2.1363149919817523

Epoch: 5| Step: 10
Training loss: 1.6414148807525635
Validation loss: 2.0938232432129564

Epoch: 290| Step: 0
Training loss: 1.8444268703460693
Validation loss: 2.14481843415127

Epoch: 5| Step: 1
Training loss: 2.510063648223877
Validation loss: 2.193225667040835

Epoch: 5| Step: 2
Training loss: 1.503598928451538
Validation loss: 2.170399317177393

Epoch: 5| Step: 3
Training loss: 1.7853673696517944
Validation loss: 2.1777639389038086

Epoch: 5| Step: 4
Training loss: 2.0994791984558105
Validation loss: 2.1907811087946736

Epoch: 5| Step: 5
Training loss: 1.6784946918487549
Validation loss: 2.124667147154449

Epoch: 5| Step: 6
Training loss: 2.5606632232666016
Validation loss: 2.1090720174133137

Epoch: 5| Step: 7
Training loss: 2.0520427227020264
Validation loss: 2.1430487043114117

Epoch: 5| Step: 8
Training loss: 1.830133080482483
Validation loss: 2.109364976165115

Epoch: 5| Step: 9
Training loss: 1.736750602722168
Validation loss: 2.1519703813778457

Epoch: 5| Step: 10
Training loss: 1.559693455696106
Validation loss: 2.1495584518678728

Epoch: 291| Step: 0
Training loss: 2.290452480316162
Validation loss: 2.216720950218939

Epoch: 5| Step: 1
Training loss: 2.295839786529541
Validation loss: 2.1277115652638097

Epoch: 5| Step: 2
Training loss: 2.6398355960845947
Validation loss: 2.2220045392231276

Epoch: 5| Step: 3
Training loss: 1.8930248022079468
Validation loss: 2.1103665033976235

Epoch: 5| Step: 4
Training loss: 1.6596416234970093
Validation loss: 2.202195869979038

Epoch: 5| Step: 5
Training loss: 2.247140645980835
Validation loss: 2.232130136541141

Epoch: 5| Step: 6
Training loss: 1.7144159078598022
Validation loss: 2.189979117403748

Epoch: 5| Step: 7
Training loss: 1.2415167093276978
Validation loss: 2.1972301519045265

Epoch: 5| Step: 8
Training loss: 1.4967650175094604
Validation loss: 2.2095776578431487

Epoch: 5| Step: 9
Training loss: 1.568131446838379
Validation loss: 2.228322316241521

Epoch: 5| Step: 10
Training loss: 2.060075044631958
Validation loss: 2.1471095610690374

Epoch: 292| Step: 0
Training loss: 2.1216089725494385
Validation loss: 2.169518745073708

Epoch: 5| Step: 1
Training loss: 2.301208019256592
Validation loss: 2.1324919064839682

Epoch: 5| Step: 2
Training loss: 2.0103061199188232
Validation loss: 2.2027599452644266

Epoch: 5| Step: 3
Training loss: 1.8909130096435547
Validation loss: 2.1094872989962177

Epoch: 5| Step: 4
Training loss: 2.2519640922546387
Validation loss: 2.159209964095905

Epoch: 5| Step: 5
Training loss: 2.2363247871398926
Validation loss: 2.1258550151701896

Epoch: 5| Step: 6
Training loss: 1.3709596395492554
Validation loss: 2.034177525069124

Epoch: 5| Step: 7
Training loss: 2.064279317855835
Validation loss: 2.1595284285083896

Epoch: 5| Step: 8
Training loss: 1.314292073249817
Validation loss: 2.157006743133709

Epoch: 5| Step: 9
Training loss: 1.5442583560943604
Validation loss: 2.082444647307037

Epoch: 5| Step: 10
Training loss: 1.9012784957885742
Validation loss: 2.1620197167960544

Epoch: 293| Step: 0
Training loss: 1.749652624130249
Validation loss: 2.1151624494983303

Epoch: 5| Step: 1
Training loss: 2.0810189247131348
Validation loss: 2.1088242146276657

Epoch: 5| Step: 2
Training loss: 1.7488462924957275
Validation loss: 2.206294254590106

Epoch: 5| Step: 3
Training loss: 2.171339988708496
Validation loss: 2.2328039702548774

Epoch: 5| Step: 4
Training loss: 2.401991367340088
Validation loss: 2.171162554012832

Epoch: 5| Step: 5
Training loss: 1.5855975151062012
Validation loss: 2.189357619131765

Epoch: 5| Step: 6
Training loss: 1.9297643899917603
Validation loss: 2.1138714269925187

Epoch: 5| Step: 7
Training loss: 1.6991360187530518
Validation loss: 2.1850683355844147

Epoch: 5| Step: 8
Training loss: 1.8847068548202515
Validation loss: 2.159869437576622

Epoch: 5| Step: 9
Training loss: 2.064014196395874
Validation loss: 2.227156857008575

Epoch: 5| Step: 10
Training loss: 1.5312532186508179
Validation loss: 2.157392477476469

Epoch: 294| Step: 0
Training loss: 2.0780880451202393
Validation loss: 2.2070446052858905

Epoch: 5| Step: 1
Training loss: 2.054527521133423
Validation loss: 2.269147301232943

Epoch: 5| Step: 2
Training loss: 1.684849500656128
Validation loss: 2.195895364207606

Epoch: 5| Step: 3
Training loss: 1.8635365962982178
Validation loss: 2.2852185208310365

Epoch: 5| Step: 4
Training loss: 2.217176914215088
Validation loss: 2.161877771859528

Epoch: 5| Step: 5
Training loss: 1.665615439414978
Validation loss: 2.1647528089502805

Epoch: 5| Step: 6
Training loss: 2.4585189819335938
Validation loss: 2.1661893577985865

Epoch: 5| Step: 7
Training loss: 2.073093891143799
Validation loss: 2.2255916954368673

Epoch: 5| Step: 8
Training loss: 1.8948924541473389
Validation loss: 2.1761641553653184

Epoch: 5| Step: 9
Training loss: 1.267661213874817
Validation loss: 2.0728129866302654

Epoch: 5| Step: 10
Training loss: 2.0403707027435303
Validation loss: 2.230012165602817

Epoch: 295| Step: 0
Training loss: 1.9943439960479736
Validation loss: 2.1323037429522445

Epoch: 5| Step: 1
Training loss: 2.0190701484680176
Validation loss: 2.1524759569475727

Epoch: 5| Step: 2
Training loss: 2.098590135574341
Validation loss: 2.1082081538374706

Epoch: 5| Step: 3
Training loss: 2.194125175476074
Validation loss: 2.1703962331177085

Epoch: 5| Step: 4
Training loss: 1.3041468858718872
Validation loss: 2.1234520955752303

Epoch: 5| Step: 5
Training loss: 2.1608617305755615
Validation loss: 2.144889341887607

Epoch: 5| Step: 6
Training loss: 2.0849525928497314
Validation loss: 2.139955289902226

Epoch: 5| Step: 7
Training loss: 1.7795130014419556
Validation loss: 2.2119849625454155

Epoch: 5| Step: 8
Training loss: 1.2471730709075928
Validation loss: 2.1134435707522976

Epoch: 5| Step: 9
Training loss: 1.8836711645126343
Validation loss: 2.177732836815619

Epoch: 5| Step: 10
Training loss: 1.927266240119934
Validation loss: 2.2144932849432832

Epoch: 296| Step: 0
Training loss: 1.5916366577148438
Validation loss: 2.1421711188490673

Epoch: 5| Step: 1
Training loss: 1.8614555597305298
Validation loss: 2.171795621995003

Epoch: 5| Step: 2
Training loss: 2.0487875938415527
Validation loss: 2.115235854220647

Epoch: 5| Step: 3
Training loss: 2.6586172580718994
Validation loss: 2.121253284074927

Epoch: 5| Step: 4
Training loss: 1.6310962438583374
Validation loss: 2.0895865322441183

Epoch: 5| Step: 5
Training loss: 2.3945131301879883
Validation loss: 2.2442785116934005

Epoch: 5| Step: 6
Training loss: 1.583852767944336
Validation loss: 2.179788153658631

Epoch: 5| Step: 7
Training loss: 2.1969285011291504
Validation loss: 2.0852303248579784

Epoch: 5| Step: 8
Training loss: 1.855980634689331
Validation loss: 2.1285024073816117

Epoch: 5| Step: 9
Training loss: 1.5268430709838867
Validation loss: 2.172336070768295

Epoch: 5| Step: 10
Training loss: 1.4916528463363647
Validation loss: 2.061850102998877

Epoch: 297| Step: 0
Training loss: 1.7624390125274658
Validation loss: 2.1717989188368603

Epoch: 5| Step: 1
Training loss: 1.572156548500061
Validation loss: 2.1120080050601753

Epoch: 5| Step: 2
Training loss: 1.743151068687439
Validation loss: 2.096926917311966

Epoch: 5| Step: 3
Training loss: 1.8836921453475952
Validation loss: 2.1647458204659085

Epoch: 5| Step: 4
Training loss: 1.5009241104125977
Validation loss: 2.1833947935412006

Epoch: 5| Step: 5
Training loss: 2.0309953689575195
Validation loss: 2.1654012408307803

Epoch: 5| Step: 6
Training loss: 1.8289053440093994
Validation loss: 2.1740496607236963

Epoch: 5| Step: 7
Training loss: 2.0117995738983154
Validation loss: 2.1415829325235016

Epoch: 5| Step: 8
Training loss: 2.553013563156128
Validation loss: 2.1754747077982914

Epoch: 5| Step: 9
Training loss: 2.0284810066223145
Validation loss: 2.1195725035923783

Epoch: 5| Step: 10
Training loss: 1.5989720821380615
Validation loss: 2.1138245174961705

Epoch: 298| Step: 0
Training loss: 1.590175986289978
Validation loss: 2.1161433701874106

Epoch: 5| Step: 1
Training loss: 1.6926038265228271
Validation loss: 2.112789992363222

Epoch: 5| Step: 2
Training loss: 2.070359468460083
Validation loss: 2.103407359892322

Epoch: 5| Step: 3
Training loss: 1.9226347208023071
Validation loss: 2.1359905914593766

Epoch: 5| Step: 4
Training loss: 1.6267017126083374
Validation loss: 2.179119053707328

Epoch: 5| Step: 5
Training loss: 1.8754409551620483
Validation loss: 2.207590749186854

Epoch: 5| Step: 6
Training loss: 2.304147720336914
Validation loss: 2.173397070618086

Epoch: 5| Step: 7
Training loss: 1.8125455379486084
Validation loss: 2.0952755866512174

Epoch: 5| Step: 8
Training loss: 1.9044907093048096
Validation loss: 2.2392042529198433

Epoch: 5| Step: 9
Training loss: 2.3827712535858154
Validation loss: 2.1150900830504713

Epoch: 5| Step: 10
Training loss: 1.750576376914978
Validation loss: 2.1945824315471034

Epoch: 299| Step: 0
Training loss: 2.0020720958709717
Validation loss: 2.2932609742687595

Epoch: 5| Step: 1
Training loss: 1.5548862218856812
Validation loss: 2.23797881731423

Epoch: 5| Step: 2
Training loss: 1.7536849975585938
Validation loss: 2.1638607876275175

Epoch: 5| Step: 3
Training loss: 1.8708568811416626
Validation loss: 2.197777041824915

Epoch: 5| Step: 4
Training loss: 1.8991897106170654
Validation loss: 2.2871985820031937

Epoch: 5| Step: 5
Training loss: 1.5544646978378296
Validation loss: 2.1704135582011235

Epoch: 5| Step: 6
Training loss: 1.8156818151474
Validation loss: 2.14721522279965

Epoch: 5| Step: 7
Training loss: 1.7656694650650024
Validation loss: 2.1332809130350747

Epoch: 5| Step: 8
Training loss: 2.233402967453003
Validation loss: 2.148656665637929

Epoch: 5| Step: 9
Training loss: 2.1413609981536865
Validation loss: 2.1575982134829284

Epoch: 5| Step: 10
Training loss: 2.362638235092163
Validation loss: 2.178641435920551

Epoch: 300| Step: 0
Training loss: 1.9470462799072266
Validation loss: 2.2091049302008843

Epoch: 5| Step: 1
Training loss: 1.481041669845581
Validation loss: 2.1785339052959154

Epoch: 5| Step: 2
Training loss: 1.8217580318450928
Validation loss: 2.1980589359037337

Epoch: 5| Step: 3
Training loss: 1.9122480154037476
Validation loss: 2.1244231449660433

Epoch: 5| Step: 4
Training loss: 2.1403822898864746
Validation loss: 2.1363075253784016

Epoch: 5| Step: 5
Training loss: 1.9763580560684204
Validation loss: 2.1461950271360335

Epoch: 5| Step: 6
Training loss: 1.7986819744110107
Validation loss: 2.1400857945924163

Epoch: 5| Step: 7
Training loss: 1.995453119277954
Validation loss: 2.1916725225346063

Epoch: 5| Step: 8
Training loss: 2.2007944583892822
Validation loss: 2.1402250874427056

Epoch: 5| Step: 9
Training loss: 1.5642802715301514
Validation loss: 2.1245930630673646

Epoch: 5| Step: 10
Training loss: 2.3845677375793457
Validation loss: 2.130208758897679

Epoch: 301| Step: 0
Training loss: 2.380744695663452
Validation loss: 2.062162691547025

Epoch: 5| Step: 1
Training loss: 1.926903486251831
Validation loss: 2.2066669694838987

Epoch: 5| Step: 2
Training loss: 1.5322686433792114
Validation loss: 2.130116972872006

Epoch: 5| Step: 3
Training loss: 1.6122395992279053
Validation loss: 2.194657507763114

Epoch: 5| Step: 4
Training loss: 1.9419605731964111
Validation loss: 2.18745223681132

Epoch: 5| Step: 5
Training loss: 1.844482183456421
Validation loss: 2.167827393418999

Epoch: 5| Step: 6
Training loss: 1.9290313720703125
Validation loss: 2.207257563068021

Epoch: 5| Step: 7
Training loss: 2.2144217491149902
Validation loss: 2.123205490009759

Epoch: 5| Step: 8
Training loss: 1.7052886486053467
Validation loss: 2.174179296339712

Epoch: 5| Step: 9
Training loss: 2.2640469074249268
Validation loss: 2.1404892847102177

Epoch: 5| Step: 10
Training loss: 1.0606999397277832
Validation loss: 2.212538480758667

Epoch: 302| Step: 0
Training loss: 2.066260814666748
Validation loss: 2.1291187014631046

Epoch: 5| Step: 1
Training loss: 2.0604801177978516
Validation loss: 2.23381539826752

Epoch: 5| Step: 2
Training loss: 1.6493088006973267
Validation loss: 2.1792075403275026

Epoch: 5| Step: 3
Training loss: 1.6819746494293213
Validation loss: 2.2365129429806947

Epoch: 5| Step: 4
Training loss: 2.0269908905029297
Validation loss: 2.2000357002340336

Epoch: 5| Step: 5
Training loss: 1.8753881454467773
Validation loss: 2.1063834800515124

Epoch: 5| Step: 6
Training loss: 1.622953176498413
Validation loss: 2.195251662244079

Epoch: 5| Step: 7
Training loss: 2.2779622077941895
Validation loss: 2.1149805309951946

Epoch: 5| Step: 8
Training loss: 1.407372236251831
Validation loss: 2.21412734318805

Epoch: 5| Step: 9
Training loss: 2.0977089405059814
Validation loss: 2.1852211888118456

Epoch: 5| Step: 10
Training loss: 2.2778749465942383
Validation loss: 2.148796930108019

Epoch: 303| Step: 0
Training loss: 1.4386472702026367
Validation loss: 2.2323519094015962

Epoch: 5| Step: 1
Training loss: 1.8730440139770508
Validation loss: 2.162730147761683

Epoch: 5| Step: 2
Training loss: 2.0074267387390137
Validation loss: 2.1269929152663036

Epoch: 5| Step: 3
Training loss: 2.0512807369232178
Validation loss: 2.100240433087913

Epoch: 5| Step: 4
Training loss: 1.290930151939392
Validation loss: 2.156562569320843

Epoch: 5| Step: 5
Training loss: 2.200488805770874
Validation loss: 2.1746426769482192

Epoch: 5| Step: 6
Training loss: 1.9587615728378296
Validation loss: 2.144540189414896

Epoch: 5| Step: 7
Training loss: 2.6615500450134277
Validation loss: 2.1086427832162506

Epoch: 5| Step: 8
Training loss: 1.948082685470581
Validation loss: 2.17193708368527

Epoch: 5| Step: 9
Training loss: 1.7797988653182983
Validation loss: 2.1316793605845463

Epoch: 5| Step: 10
Training loss: 2.025256872177124
Validation loss: 2.1522576655111005

Epoch: 304| Step: 0
Training loss: 2.0016231536865234
Validation loss: 2.1384560805495068

Epoch: 5| Step: 1
Training loss: 1.6771856546401978
Validation loss: 2.2163471380869546

Epoch: 5| Step: 2
Training loss: 1.3249894380569458
Validation loss: 2.0901251351961525

Epoch: 5| Step: 3
Training loss: 2.65045428276062
Validation loss: 2.1352444207796486

Epoch: 5| Step: 4
Training loss: 1.720342993736267
Validation loss: 2.161859068819272

Epoch: 5| Step: 5
Training loss: 1.8595545291900635
Validation loss: 2.209120794009137

Epoch: 5| Step: 6
Training loss: 2.4438693523406982
Validation loss: 2.16508214704452

Epoch: 5| Step: 7
Training loss: 1.633795976638794
Validation loss: 2.1640070510166947

Epoch: 5| Step: 8
Training loss: 1.1347140073776245
Validation loss: 2.101382370918028

Epoch: 5| Step: 9
Training loss: 1.5753560066223145
Validation loss: 2.0831413935589533

Epoch: 5| Step: 10
Training loss: 2.6363699436187744
Validation loss: 2.1633073488871255

Epoch: 305| Step: 0
Training loss: 2.1281394958496094
Validation loss: 2.1567406590266893

Epoch: 5| Step: 1
Training loss: 1.5671676397323608
Validation loss: 2.2245649829987557

Epoch: 5| Step: 2
Training loss: 1.383663535118103
Validation loss: 2.197499728971912

Epoch: 5| Step: 3
Training loss: 1.6529512405395508
Validation loss: 2.180329745815646

Epoch: 5| Step: 4
Training loss: 1.9956496953964233
Validation loss: 2.193015657445436

Epoch: 5| Step: 5
Training loss: 2.0670337677001953
Validation loss: 2.1644807169514317

Epoch: 5| Step: 6
Training loss: 2.1356494426727295
Validation loss: 2.1800621914607223

Epoch: 5| Step: 7
Training loss: 2.115281581878662
Validation loss: 2.1916305583010436

Epoch: 5| Step: 8
Training loss: 1.7386009693145752
Validation loss: 2.1610249934657926

Epoch: 5| Step: 9
Training loss: 2.1911697387695312
Validation loss: 2.1492607029535438

Epoch: 5| Step: 10
Training loss: 1.965705156326294
Validation loss: 2.1760855669616372

Epoch: 306| Step: 0
Training loss: 1.2933378219604492
Validation loss: 2.1762171868355042

Epoch: 5| Step: 1
Training loss: 1.7086591720581055
Validation loss: 2.182558064819664

Epoch: 5| Step: 2
Training loss: 2.3712806701660156
Validation loss: 2.2421498426827053

Epoch: 5| Step: 3
Training loss: 2.283565044403076
Validation loss: 2.169167805743474

Epoch: 5| Step: 4
Training loss: 1.8673782348632812
Validation loss: 2.1597888828605734

Epoch: 5| Step: 5
Training loss: 1.942432165145874
Validation loss: 2.1327950185345066

Epoch: 5| Step: 6
Training loss: 2.236358165740967
Validation loss: 2.1805899194491807

Epoch: 5| Step: 7
Training loss: 1.222368597984314
Validation loss: 2.1835086409763624

Epoch: 5| Step: 8
Training loss: 2.0926859378814697
Validation loss: 2.1635402248751734

Epoch: 5| Step: 9
Training loss: 2.2077910900115967
Validation loss: 2.144541609671808

Epoch: 5| Step: 10
Training loss: 1.7320297956466675
Validation loss: 2.168802212643367

Epoch: 307| Step: 0
Training loss: 2.1757142543792725
Validation loss: 2.105473220989268

Epoch: 5| Step: 1
Training loss: 2.0917410850524902
Validation loss: 2.1108674541596444

Epoch: 5| Step: 2
Training loss: 1.8574062585830688
Validation loss: 2.1294870850860432

Epoch: 5| Step: 3
Training loss: 1.6601991653442383
Validation loss: 2.1433481708649667

Epoch: 5| Step: 4
Training loss: 2.1326489448547363
Validation loss: 2.1240187280921528

Epoch: 5| Step: 5
Training loss: 1.5139107704162598
Validation loss: 2.1162984012275614

Epoch: 5| Step: 6
Training loss: 2.508761167526245
Validation loss: 2.0604181046126993

Epoch: 5| Step: 7
Training loss: 1.7381575107574463
Validation loss: 2.156514375440536

Epoch: 5| Step: 8
Training loss: 1.9329334497451782
Validation loss: 2.114040249137468

Epoch: 5| Step: 9
Training loss: 1.9119949340820312
Validation loss: 2.058348754400848

Epoch: 5| Step: 10
Training loss: 1.5528110265731812
Validation loss: 2.1434491936878493

Epoch: 308| Step: 0
Training loss: 2.271005630493164
Validation loss: 2.1392940116185013

Epoch: 5| Step: 1
Training loss: 1.95365309715271
Validation loss: 2.150958562410006

Epoch: 5| Step: 2
Training loss: 1.7463510036468506
Validation loss: 2.1429246958865913

Epoch: 5| Step: 3
Training loss: 2.0240349769592285
Validation loss: 2.1146059882256294

Epoch: 5| Step: 4
Training loss: 1.7895406484603882
Validation loss: 2.180584489658315

Epoch: 5| Step: 5
Training loss: 1.7687479257583618
Validation loss: 2.101642600951656

Epoch: 5| Step: 6
Training loss: 1.9855436086654663
Validation loss: 2.1535351801944036

Epoch: 5| Step: 7
Training loss: 1.7715132236480713
Validation loss: 2.1269158778652066

Epoch: 5| Step: 8
Training loss: 1.9293384552001953
Validation loss: 2.137806092539141

Epoch: 5| Step: 9
Training loss: 2.2732720375061035
Validation loss: 2.087636947631836

Epoch: 5| Step: 10
Training loss: 1.480474829673767
Validation loss: 2.167478689583399

Epoch: 309| Step: 0
Training loss: 2.423171281814575
Validation loss: 2.1527260272733626

Epoch: 5| Step: 1
Training loss: 1.8324315547943115
Validation loss: 2.1694206781284784

Epoch: 5| Step: 2
Training loss: 1.622410774230957
Validation loss: 2.1702297631130425

Epoch: 5| Step: 3
Training loss: 2.536473035812378
Validation loss: 2.1716381272962018

Epoch: 5| Step: 4
Training loss: 1.7067817449569702
Validation loss: 2.182612811365435

Epoch: 5| Step: 5
Training loss: 1.4517102241516113
Validation loss: 2.155150741659185

Epoch: 5| Step: 6
Training loss: 1.952691674232483
Validation loss: 2.184915881003103

Epoch: 5| Step: 7
Training loss: 1.8572088479995728
Validation loss: 2.164095893982918

Epoch: 5| Step: 8
Training loss: 1.498253345489502
Validation loss: 2.183492896377399

Epoch: 5| Step: 9
Training loss: 1.9180028438568115
Validation loss: 2.1785717446316957

Epoch: 5| Step: 10
Training loss: 2.098802089691162
Validation loss: 2.1919623421084498

Epoch: 310| Step: 0
Training loss: 1.9996944665908813
Validation loss: 2.1902216621624526

Epoch: 5| Step: 1
Training loss: 2.1947522163391113
Validation loss: 2.2083666683525167

Epoch: 5| Step: 2
Training loss: 2.262152910232544
Validation loss: 2.1645791017881004

Epoch: 5| Step: 3
Training loss: 1.7866098880767822
Validation loss: 2.125796712854857

Epoch: 5| Step: 4
Training loss: 1.5826425552368164
Validation loss: 2.1584582969706547

Epoch: 5| Step: 5
Training loss: 1.7356908321380615
Validation loss: 2.133342500655882

Epoch: 5| Step: 6
Training loss: 2.2918801307678223
Validation loss: 2.2058956264167704

Epoch: 5| Step: 7
Training loss: 1.7360990047454834
Validation loss: 2.1347264935893397

Epoch: 5| Step: 8
Training loss: 1.653412103652954
Validation loss: 2.1614944011934343

Epoch: 5| Step: 9
Training loss: 1.7775192260742188
Validation loss: 2.1934071279341176

Epoch: 5| Step: 10
Training loss: 1.7798247337341309
Validation loss: 2.115324486968338

Epoch: 311| Step: 0
Training loss: 1.8805757761001587
Validation loss: 2.1474059986811813

Epoch: 5| Step: 1
Training loss: 1.5008141994476318
Validation loss: 2.1386524759313112

Epoch: 5| Step: 2
Training loss: 1.4918142557144165
Validation loss: 2.0688866594786286

Epoch: 5| Step: 3
Training loss: 1.8889442682266235
Validation loss: 2.173057940698439

Epoch: 5| Step: 4
Training loss: 2.381666660308838
Validation loss: 2.150699620605797

Epoch: 5| Step: 5
Training loss: 1.615172028541565
Validation loss: 2.126755245270268

Epoch: 5| Step: 6
Training loss: 2.2764363288879395
Validation loss: 2.103857130132696

Epoch: 5| Step: 7
Training loss: 2.511035203933716
Validation loss: 2.125697599944248

Epoch: 5| Step: 8
Training loss: 1.938819169998169
Validation loss: 2.1716420804300616

Epoch: 5| Step: 9
Training loss: 1.5158922672271729
Validation loss: 2.135649627254855

Epoch: 5| Step: 10
Training loss: 1.9981880187988281
Validation loss: 2.196656088675222

Epoch: 312| Step: 0
Training loss: 1.9904552698135376
Validation loss: 2.21095335355369

Epoch: 5| Step: 1
Training loss: 2.1877944469451904
Validation loss: 2.053224563598633

Epoch: 5| Step: 2
Training loss: 2.305234432220459
Validation loss: 2.1281450153678976

Epoch: 5| Step: 3
Training loss: 1.4201905727386475
Validation loss: 2.0878545340671333

Epoch: 5| Step: 4
Training loss: 2.3900578022003174
Validation loss: 2.2423689416659776

Epoch: 5| Step: 5
Training loss: 2.158186435699463
Validation loss: 2.093794593247034

Epoch: 5| Step: 6
Training loss: 1.9139217138290405
Validation loss: 2.1490426063537598

Epoch: 5| Step: 7
Training loss: 1.6737216711044312
Validation loss: 2.179522088778916

Epoch: 5| Step: 8
Training loss: 1.2970428466796875
Validation loss: 2.1796474674696564

Epoch: 5| Step: 9
Training loss: 1.365984559059143
Validation loss: 2.19824892474759

Epoch: 5| Step: 10
Training loss: 1.7825331687927246
Validation loss: 2.1697901166895384

Epoch: 313| Step: 0
Training loss: 1.4545862674713135
Validation loss: 2.1415961429636967

Epoch: 5| Step: 1
Training loss: 1.251643180847168
Validation loss: 2.2334520239983835

Epoch: 5| Step: 2
Training loss: 2.162637233734131
Validation loss: 2.0873356788389144

Epoch: 5| Step: 3
Training loss: 1.980834722518921
Validation loss: 2.1453605364727717

Epoch: 5| Step: 4
Training loss: 1.760718584060669
Validation loss: 2.1892632771563787

Epoch: 5| Step: 5
Training loss: 1.7292594909667969
Validation loss: 2.1836551786750875

Epoch: 5| Step: 6
Training loss: 2.3801608085632324
Validation loss: 2.1376801601020237

Epoch: 5| Step: 7
Training loss: 1.6511589288711548
Validation loss: 2.1307055232345418

Epoch: 5| Step: 8
Training loss: 1.761609673500061
Validation loss: 2.1183579737140286

Epoch: 5| Step: 9
Training loss: 2.021463394165039
Validation loss: 2.1369143147622385

Epoch: 5| Step: 10
Training loss: 1.9819533824920654
Validation loss: 2.1051416576549573

Epoch: 314| Step: 0
Training loss: 1.7582807540893555
Validation loss: 2.1355121827894643

Epoch: 5| Step: 1
Training loss: 1.2336995601654053
Validation loss: 2.1344914167158064

Epoch: 5| Step: 2
Training loss: 2.489227771759033
Validation loss: 2.1033468823279104

Epoch: 5| Step: 3
Training loss: 1.882066011428833
Validation loss: 2.278389876888644

Epoch: 5| Step: 4
Training loss: 2.248542070388794
Validation loss: 2.1801686709926975

Epoch: 5| Step: 5
Training loss: 1.854548692703247
Validation loss: 2.2291798489068144

Epoch: 5| Step: 6
Training loss: 1.9858465194702148
Validation loss: 2.1777020936371176

Epoch: 5| Step: 7
Training loss: 2.1098694801330566
Validation loss: 2.1666400330041045

Epoch: 5| Step: 8
Training loss: 2.059602737426758
Validation loss: 2.206616714436521

Epoch: 5| Step: 9
Training loss: 1.403196930885315
Validation loss: 2.2158983163936163

Epoch: 5| Step: 10
Training loss: 1.6065871715545654
Validation loss: 2.169568464320193

Epoch: 315| Step: 0
Training loss: 1.3113102912902832
Validation loss: 2.096959117920168

Epoch: 5| Step: 1
Training loss: 1.8225924968719482
Validation loss: 2.19157362240617

Epoch: 5| Step: 2
Training loss: 2.2180721759796143
Validation loss: 2.2010740221187635

Epoch: 5| Step: 3
Training loss: 1.3589228391647339
Validation loss: 2.1303815841674805

Epoch: 5| Step: 4
Training loss: 2.1880412101745605
Validation loss: 2.1304144090221775

Epoch: 5| Step: 5
Training loss: 1.7681766748428345
Validation loss: 2.150519004432104

Epoch: 5| Step: 6
Training loss: 1.8916137218475342
Validation loss: 2.1305735213782198

Epoch: 5| Step: 7
Training loss: 1.969517469406128
Validation loss: 2.155599586425289

Epoch: 5| Step: 8
Training loss: 1.883486032485962
Validation loss: 2.189244024215206

Epoch: 5| Step: 9
Training loss: 1.4785070419311523
Validation loss: 2.1580288512732393

Epoch: 5| Step: 10
Training loss: 2.4488022327423096
Validation loss: 2.1675891696765857

Epoch: 316| Step: 0
Training loss: 1.657111406326294
Validation loss: 2.167881686200378

Epoch: 5| Step: 1
Training loss: 1.9942998886108398
Validation loss: 2.1817470237772953

Epoch: 5| Step: 2
Training loss: 2.113105297088623
Validation loss: 2.0981844420074136

Epoch: 5| Step: 3
Training loss: 1.2802844047546387
Validation loss: 2.1166072994150142

Epoch: 5| Step: 4
Training loss: 1.7406504154205322
Validation loss: 2.099950046949489

Epoch: 5| Step: 5
Training loss: 1.871610403060913
Validation loss: 2.1121788024902344

Epoch: 5| Step: 6
Training loss: 1.3687756061553955
Validation loss: 2.1151371527743597

Epoch: 5| Step: 7
Training loss: 1.5981587171554565
Validation loss: 2.1380886057371735

Epoch: 5| Step: 8
Training loss: 1.8495285511016846
Validation loss: 2.133015489065519

Epoch: 5| Step: 9
Training loss: 2.5100836753845215
Validation loss: 2.1401980743613294

Epoch: 5| Step: 10
Training loss: 2.1494200229644775
Validation loss: 2.164870890237952

Epoch: 317| Step: 0
Training loss: 2.0712361335754395
Validation loss: 2.1319199890218754

Epoch: 5| Step: 1
Training loss: 1.1747392416000366
Validation loss: 2.1469609634850615

Epoch: 5| Step: 2
Training loss: 1.6829032897949219
Validation loss: 2.170335805544289

Epoch: 5| Step: 3
Training loss: 2.055391550064087
Validation loss: 2.1800437870846

Epoch: 5| Step: 4
Training loss: 2.0529541969299316
Validation loss: 2.1777655514337684

Epoch: 5| Step: 5
Training loss: 1.5903428792953491
Validation loss: 2.0903639742123183

Epoch: 5| Step: 6
Training loss: 2.445143222808838
Validation loss: 2.1758542753035024

Epoch: 5| Step: 7
Training loss: 1.6547701358795166
Validation loss: 2.1171722335200154

Epoch: 5| Step: 8
Training loss: 1.8051402568817139
Validation loss: 2.2268637252110306

Epoch: 5| Step: 9
Training loss: 2.1459462642669678
Validation loss: 2.1748789279691634

Epoch: 5| Step: 10
Training loss: 1.723863959312439
Validation loss: 2.138401086612414

Epoch: 318| Step: 0
Training loss: 1.857080101966858
Validation loss: 2.239236298427787

Epoch: 5| Step: 1
Training loss: 1.2873512506484985
Validation loss: 2.1355673420813774

Epoch: 5| Step: 2
Training loss: 1.4004604816436768
Validation loss: 2.221231847681025

Epoch: 5| Step: 3
Training loss: 2.4545464515686035
Validation loss: 2.163431603421447

Epoch: 5| Step: 4
Training loss: 1.4548251628875732
Validation loss: 2.236550061933456

Epoch: 5| Step: 5
Training loss: 2.2828402519226074
Validation loss: 2.182515111020816

Epoch: 5| Step: 6
Training loss: 1.5220966339111328
Validation loss: 2.12797394106465

Epoch: 5| Step: 7
Training loss: 1.9030895233154297
Validation loss: 2.2099603376080914

Epoch: 5| Step: 8
Training loss: 2.7007086277008057
Validation loss: 2.1378340772403184

Epoch: 5| Step: 9
Training loss: 1.663835883140564
Validation loss: 2.1864282290140786

Epoch: 5| Step: 10
Training loss: 1.7987717390060425
Validation loss: 2.1385660632964103

Epoch: 319| Step: 0
Training loss: 2.1929385662078857
Validation loss: 2.07633779638557

Epoch: 5| Step: 1
Training loss: 1.8412342071533203
Validation loss: 2.1362258875241844

Epoch: 5| Step: 2
Training loss: 2.195554733276367
Validation loss: 2.1803673800601753

Epoch: 5| Step: 3
Training loss: 1.6655299663543701
Validation loss: 2.133416132260394

Epoch: 5| Step: 4
Training loss: 1.792104721069336
Validation loss: 2.18058334114731

Epoch: 5| Step: 5
Training loss: 2.593717575073242
Validation loss: 2.1854380023094917

Epoch: 5| Step: 6
Training loss: 1.8272240161895752
Validation loss: 2.1628661796610844

Epoch: 5| Step: 7
Training loss: 1.8378655910491943
Validation loss: 2.1406439811952653

Epoch: 5| Step: 8
Training loss: 1.8477033376693726
Validation loss: 2.171917860225965

Epoch: 5| Step: 9
Training loss: 1.195684790611267
Validation loss: 2.1593534690077587

Epoch: 5| Step: 10
Training loss: 1.4114675521850586
Validation loss: 2.0589053336010186

Epoch: 320| Step: 0
Training loss: 1.3881423473358154
Validation loss: 2.1813446885796

Epoch: 5| Step: 1
Training loss: 2.186296224594116
Validation loss: 2.1310452427915347

Epoch: 5| Step: 2
Training loss: 2.028561592102051
Validation loss: 2.141068914885162

Epoch: 5| Step: 3
Training loss: 2.8814585208892822
Validation loss: 2.0772413643457557

Epoch: 5| Step: 4
Training loss: 1.91599440574646
Validation loss: 2.1504881612716185

Epoch: 5| Step: 5
Training loss: 1.6417720317840576
Validation loss: 2.1689596586329962

Epoch: 5| Step: 6
Training loss: 1.462700605392456
Validation loss: 2.0874246910054195

Epoch: 5| Step: 7
Training loss: 1.8618671894073486
Validation loss: 2.215148300252935

Epoch: 5| Step: 8
Training loss: 1.2735041379928589
Validation loss: 2.0748952575909194

Epoch: 5| Step: 9
Training loss: 1.9312950372695923
Validation loss: 2.1227018961342434

Epoch: 5| Step: 10
Training loss: 1.6132049560546875
Validation loss: 2.245652155209613

Epoch: 321| Step: 0
Training loss: 1.7742122411727905
Validation loss: 2.188377090679702

Epoch: 5| Step: 1
Training loss: 2.0421242713928223
Validation loss: 2.111465269519437

Epoch: 5| Step: 2
Training loss: 1.7318662405014038
Validation loss: 2.189249628333635

Epoch: 5| Step: 3
Training loss: 1.1085965633392334
Validation loss: 2.1645954398698706

Epoch: 5| Step: 4
Training loss: 1.806038498878479
Validation loss: 2.1535425775794574

Epoch: 5| Step: 5
Training loss: 1.9252361059188843
Validation loss: 2.1717653735991447

Epoch: 5| Step: 6
Training loss: 2.189865827560425
Validation loss: 2.1870530266915598

Epoch: 5| Step: 7
Training loss: 2.0566000938415527
Validation loss: 2.1234667224268757

Epoch: 5| Step: 8
Training loss: 1.7088968753814697
Validation loss: 2.117846578680059

Epoch: 5| Step: 9
Training loss: 1.5616929531097412
Validation loss: 2.2556275449773318

Epoch: 5| Step: 10
Training loss: 2.587991952896118
Validation loss: 2.2110910210558163

Epoch: 322| Step: 0
Training loss: 1.7103288173675537
Validation loss: 2.0950231834124495

Epoch: 5| Step: 1
Training loss: 2.0672855377197266
Validation loss: 2.116299734320692

Epoch: 5| Step: 2
Training loss: 1.8318827152252197
Validation loss: 2.1744724178826935

Epoch: 5| Step: 3
Training loss: 1.7044795751571655
Validation loss: 2.1709681403252388

Epoch: 5| Step: 4
Training loss: 2.0701022148132324
Validation loss: 2.207815703525338

Epoch: 5| Step: 5
Training loss: 1.4570274353027344
Validation loss: 2.1378096765087498

Epoch: 5| Step: 6
Training loss: 2.146371603012085
Validation loss: 2.2070944052870556

Epoch: 5| Step: 7
Training loss: 2.2420337200164795
Validation loss: 2.1548700999188166

Epoch: 5| Step: 8
Training loss: 1.7868757247924805
Validation loss: 2.1568662197359147

Epoch: 5| Step: 9
Training loss: 1.2218698263168335
Validation loss: 2.2290750780413227

Epoch: 5| Step: 10
Training loss: 1.865918755531311
Validation loss: 2.1737311283747354

Epoch: 323| Step: 0
Training loss: 1.491686463356018
Validation loss: 2.1324129694251606

Epoch: 5| Step: 1
Training loss: 1.43621027469635
Validation loss: 2.235152106131277

Epoch: 5| Step: 2
Training loss: 2.7248640060424805
Validation loss: 2.1482287940158638

Epoch: 5| Step: 3
Training loss: 1.8541618585586548
Validation loss: 2.114403150414908

Epoch: 5| Step: 4
Training loss: 1.6351852416992188
Validation loss: 2.164712457246678

Epoch: 5| Step: 5
Training loss: 1.7709611654281616
Validation loss: 2.1808732299394507

Epoch: 5| Step: 6
Training loss: 1.9483776092529297
Validation loss: 2.1048697643382575

Epoch: 5| Step: 7
Training loss: 1.7617393732070923
Validation loss: 2.1061941436541978

Epoch: 5| Step: 8
Training loss: 2.1727817058563232
Validation loss: 2.1557329341929448

Epoch: 5| Step: 9
Training loss: 2.0147171020507812
Validation loss: 2.0918783680085213

Epoch: 5| Step: 10
Training loss: 1.411133050918579
Validation loss: 2.1600978835936515

Epoch: 324| Step: 0
Training loss: 1.4222347736358643
Validation loss: 2.081439297686341

Epoch: 5| Step: 1
Training loss: 1.6357402801513672
Validation loss: 2.2274347171988538

Epoch: 5| Step: 2
Training loss: 1.6460011005401611
Validation loss: 2.1977815730597383

Epoch: 5| Step: 3
Training loss: 2.5255069732666016
Validation loss: 2.169911564037364

Epoch: 5| Step: 4
Training loss: 1.5046281814575195
Validation loss: 2.1276522195467384

Epoch: 5| Step: 5
Training loss: 1.6828889846801758
Validation loss: 2.098973584431474

Epoch: 5| Step: 6
Training loss: 1.5842945575714111
Validation loss: 2.131144533875168

Epoch: 5| Step: 7
Training loss: 1.6018857955932617
Validation loss: 2.0491745766773017

Epoch: 5| Step: 8
Training loss: 2.407127618789673
Validation loss: 2.2104414842462026

Epoch: 5| Step: 9
Training loss: 2.4225165843963623
Validation loss: 2.1617807393432944

Epoch: 5| Step: 10
Training loss: 2.566338300704956
Validation loss: 2.1101586357239754

Epoch: 325| Step: 0
Training loss: 1.610395073890686
Validation loss: 2.1570760306491645

Epoch: 5| Step: 1
Training loss: 1.5584696531295776
Validation loss: 2.185234929925652

Epoch: 5| Step: 2
Training loss: 1.3841397762298584
Validation loss: 2.118462244669596

Epoch: 5| Step: 3
Training loss: 1.731549620628357
Validation loss: 2.165705421919464

Epoch: 5| Step: 4
Training loss: 2.232326030731201
Validation loss: 2.166728949034086

Epoch: 5| Step: 5
Training loss: 2.241765260696411
Validation loss: 2.1557062402848275

Epoch: 5| Step: 6
Training loss: 2.0090105533599854
Validation loss: 2.138772899104703

Epoch: 5| Step: 7
Training loss: 1.9231183528900146
Validation loss: 2.2117554859448503

Epoch: 5| Step: 8
Training loss: 1.9225994348526
Validation loss: 2.156129547344741

Epoch: 5| Step: 9
Training loss: 1.7962512969970703
Validation loss: 2.1077370861525178

Epoch: 5| Step: 10
Training loss: 1.9623634815216064
Validation loss: 2.1301694941777054

Epoch: 326| Step: 0
Training loss: 1.7936599254608154
Validation loss: 2.1645062238939348

Epoch: 5| Step: 1
Training loss: 1.9575074911117554
Validation loss: 2.1353003068636824

Epoch: 5| Step: 2
Training loss: 1.6868053674697876
Validation loss: 2.159449795240997

Epoch: 5| Step: 3
Training loss: 2.052647113800049
Validation loss: 2.190849606708814

Epoch: 5| Step: 4
Training loss: 1.1044150590896606
Validation loss: 2.150284139058923

Epoch: 5| Step: 5
Training loss: 1.9773610830307007
Validation loss: 2.1326663801746983

Epoch: 5| Step: 6
Training loss: 2.2385988235473633
Validation loss: 2.178414672933599

Epoch: 5| Step: 7
Training loss: 1.8909419775009155
Validation loss: 2.1419714881527807

Epoch: 5| Step: 8
Training loss: 1.548137903213501
Validation loss: 2.124479070786507

Epoch: 5| Step: 9
Training loss: 2.1412434577941895
Validation loss: 2.0307300731699955

Epoch: 5| Step: 10
Training loss: 2.5041558742523193
Validation loss: 2.0578348303353913

Epoch: 327| Step: 0
Training loss: 1.695385217666626
Validation loss: 2.161673080536627

Epoch: 5| Step: 1
Training loss: 1.3519890308380127
Validation loss: 2.1313691805767756

Epoch: 5| Step: 2
Training loss: 1.8817598819732666
Validation loss: 2.1076702405047674

Epoch: 5| Step: 3
Training loss: 2.1787612438201904
Validation loss: 2.2061832463869484

Epoch: 5| Step: 4
Training loss: 1.8794949054718018
Validation loss: 2.1168177948203137

Epoch: 5| Step: 5
Training loss: 2.398298740386963
Validation loss: 2.126051854061824

Epoch: 5| Step: 6
Training loss: 2.116755247116089
Validation loss: 2.0911334586399857

Epoch: 5| Step: 7
Training loss: 1.6714614629745483
Validation loss: 2.1429330302822973

Epoch: 5| Step: 8
Training loss: 2.5039780139923096
Validation loss: 2.184220507580747

Epoch: 5| Step: 9
Training loss: 1.1895759105682373
Validation loss: 2.176663411560879

Epoch: 5| Step: 10
Training loss: 1.4728639125823975
Validation loss: 2.1318710555312452

Epoch: 328| Step: 0
Training loss: 2.0607028007507324
Validation loss: 2.197297501307662

Epoch: 5| Step: 1
Training loss: 1.6755754947662354
Validation loss: 2.0760243631178334

Epoch: 5| Step: 2
Training loss: 1.787467360496521
Validation loss: 2.2322507391693773

Epoch: 5| Step: 3
Training loss: 1.7415215969085693
Validation loss: 2.1370712839147097

Epoch: 5| Step: 4
Training loss: 2.1757845878601074
Validation loss: 2.153590174131496

Epoch: 5| Step: 5
Training loss: 2.2056102752685547
Validation loss: 2.0625950700493267

Epoch: 5| Step: 6
Training loss: 1.6684907674789429
Validation loss: 2.1182380491687405

Epoch: 5| Step: 7
Training loss: 1.9081077575683594
Validation loss: 2.17208908706583

Epoch: 5| Step: 8
Training loss: 1.5295383930206299
Validation loss: 2.159804133958714

Epoch: 5| Step: 9
Training loss: 1.759722113609314
Validation loss: 2.2300481924446682

Epoch: 5| Step: 10
Training loss: 1.9666600227355957
Validation loss: 2.2147818790969027

Epoch: 329| Step: 0
Training loss: 2.0003128051757812
Validation loss: 2.1855533866472143

Epoch: 5| Step: 1
Training loss: 1.7536957263946533
Validation loss: 2.1719756280222247

Epoch: 5| Step: 2
Training loss: 2.1910479068756104
Validation loss: 2.136118491490682

Epoch: 5| Step: 3
Training loss: 1.8013718128204346
Validation loss: 2.1434028789561284

Epoch: 5| Step: 4
Training loss: 2.15740966796875
Validation loss: 2.167495180201787

Epoch: 5| Step: 5
Training loss: 0.9604434967041016
Validation loss: 2.17654267690515

Epoch: 5| Step: 6
Training loss: 1.087355613708496
Validation loss: 2.101615600688483

Epoch: 5| Step: 7
Training loss: 2.4631948471069336
Validation loss: 2.2320273435243996

Epoch: 5| Step: 8
Training loss: 2.074378490447998
Validation loss: 2.1105402925963044

Epoch: 5| Step: 9
Training loss: 1.9753634929656982
Validation loss: 2.20969057595858

Epoch: 5| Step: 10
Training loss: 1.3368440866470337
Validation loss: 2.1416726958367134

Epoch: 330| Step: 0
Training loss: 1.8277969360351562
Validation loss: 2.1168452411569576

Epoch: 5| Step: 1
Training loss: 1.9669685363769531
Validation loss: 2.2141956231927358

Epoch: 5| Step: 2
Training loss: 1.4925545454025269
Validation loss: 2.1498162977157103

Epoch: 5| Step: 3
Training loss: 1.7991358041763306
Validation loss: 2.130180352477617

Epoch: 5| Step: 4
Training loss: 2.482598066329956
Validation loss: 2.176741107817619

Epoch: 5| Step: 5
Training loss: 1.172782301902771
Validation loss: 2.1588802594010548

Epoch: 5| Step: 6
Training loss: 2.3587512969970703
Validation loss: 2.124241934027723

Epoch: 5| Step: 7
Training loss: 2.1022677421569824
Validation loss: 2.1500211402934086

Epoch: 5| Step: 8
Training loss: 1.980513334274292
Validation loss: 2.1268160061169694

Epoch: 5| Step: 9
Training loss: 1.6022555828094482
Validation loss: 2.102467611271848

Epoch: 5| Step: 10
Training loss: 1.5827794075012207
Validation loss: 2.125383687275712

Epoch: 331| Step: 0
Training loss: 1.2366069555282593
Validation loss: 2.118585555784164

Epoch: 5| Step: 1
Training loss: 2.2669835090637207
Validation loss: 2.174072168206656

Epoch: 5| Step: 2
Training loss: 1.0854127407073975
Validation loss: 2.1174655986088577

Epoch: 5| Step: 3
Training loss: 1.406105399131775
Validation loss: 2.1204657785354124

Epoch: 5| Step: 4
Training loss: 2.6097443103790283
Validation loss: 2.1218381235676427

Epoch: 5| Step: 5
Training loss: 2.3078765869140625
Validation loss: 2.0991594727321337

Epoch: 5| Step: 6
Training loss: 2.675783157348633
Validation loss: 2.09731976960295

Epoch: 5| Step: 7
Training loss: 1.5574995279312134
Validation loss: 2.1524726037056214

Epoch: 5| Step: 8
Training loss: 1.9247089624404907
Validation loss: 2.1194690068562827

Epoch: 5| Step: 9
Training loss: 1.5800745487213135
Validation loss: 2.171002936619584

Epoch: 5| Step: 10
Training loss: 1.7009974718093872
Validation loss: 2.1447398675385343

Epoch: 332| Step: 0
Training loss: 1.539926290512085
Validation loss: 2.1762679443564465

Epoch: 5| Step: 1
Training loss: 1.8329150676727295
Validation loss: 2.159954301772579

Epoch: 5| Step: 2
Training loss: 1.3098742961883545
Validation loss: 2.187289155939574

Epoch: 5| Step: 3
Training loss: 2.0373899936676025
Validation loss: 2.185561990225187

Epoch: 5| Step: 4
Training loss: 2.2621312141418457
Validation loss: 2.2032429992511706

Epoch: 5| Step: 5
Training loss: 1.4639933109283447
Validation loss: 2.200184304227111

Epoch: 5| Step: 6
Training loss: 2.0615787506103516
Validation loss: 2.165490406815724

Epoch: 5| Step: 7
Training loss: 2.2027173042297363
Validation loss: 2.1798395777261383

Epoch: 5| Step: 8
Training loss: 1.8719947338104248
Validation loss: 2.1362136845947592

Epoch: 5| Step: 9
Training loss: 1.7538414001464844
Validation loss: 2.2429699385037987

Epoch: 5| Step: 10
Training loss: 2.192140579223633
Validation loss: 2.2149542634205153

Epoch: 333| Step: 0
Training loss: 1.8306457996368408
Validation loss: 2.1476165325410905

Epoch: 5| Step: 1
Training loss: 2.045403003692627
Validation loss: 2.144219629226192

Epoch: 5| Step: 2
Training loss: 2.174731731414795
Validation loss: 2.119078366987167

Epoch: 5| Step: 3
Training loss: 1.866991400718689
Validation loss: 2.165570823095178

Epoch: 5| Step: 4
Training loss: 1.8015419244766235
Validation loss: 2.1370688215378792

Epoch: 5| Step: 5
Training loss: 1.1014091968536377
Validation loss: 2.1399410206784486

Epoch: 5| Step: 6
Training loss: 2.0408995151519775
Validation loss: 2.0808465326986005

Epoch: 5| Step: 7
Training loss: 2.0505383014678955
Validation loss: 2.1013327106352775

Epoch: 5| Step: 8
Training loss: 1.364652395248413
Validation loss: 2.1639809454641035

Epoch: 5| Step: 9
Training loss: 1.6727508306503296
Validation loss: 2.0909461603369763

Epoch: 5| Step: 10
Training loss: 1.9077563285827637
Validation loss: 2.103208371388015

Epoch: 334| Step: 0
Training loss: 1.384779930114746
Validation loss: 2.1561335927696637

Epoch: 5| Step: 1
Training loss: 2.3664040565490723
Validation loss: 2.1680483689872165

Epoch: 5| Step: 2
Training loss: 2.06634259223938
Validation loss: 2.159944434319773

Epoch: 5| Step: 3
Training loss: 1.8463865518569946
Validation loss: 2.111736712917205

Epoch: 5| Step: 4
Training loss: 2.1147046089172363
Validation loss: 2.1244557211475987

Epoch: 5| Step: 5
Training loss: 1.9477043151855469
Validation loss: 2.1245029946809173

Epoch: 5| Step: 6
Training loss: 1.7596635818481445
Validation loss: 2.1540050711683048

Epoch: 5| Step: 7
Training loss: 1.1315126419067383
Validation loss: 2.148050738919166

Epoch: 5| Step: 8
Training loss: 1.6977198123931885
Validation loss: 2.1846555497056697

Epoch: 5| Step: 9
Training loss: 2.1475911140441895
Validation loss: 2.118681166761665

Epoch: 5| Step: 10
Training loss: 1.649195909500122
Validation loss: 2.1183288584473314

Epoch: 335| Step: 0
Training loss: 1.552651047706604
Validation loss: 2.164369499811562

Epoch: 5| Step: 1
Training loss: 1.8576713800430298
Validation loss: 2.120622347759944

Epoch: 5| Step: 2
Training loss: 2.114281177520752
Validation loss: 2.190380198981172

Epoch: 5| Step: 3
Training loss: 1.5662652254104614
Validation loss: 2.216684877231557

Epoch: 5| Step: 4
Training loss: 1.8019216060638428
Validation loss: 2.1524853398722987

Epoch: 5| Step: 5
Training loss: 1.964328408241272
Validation loss: 2.261524123530234

Epoch: 5| Step: 6
Training loss: 2.351858615875244
Validation loss: 2.1370622432360085

Epoch: 5| Step: 7
Training loss: 2.198373317718506
Validation loss: 2.141134053148249

Epoch: 5| Step: 8
Training loss: 1.5399210453033447
Validation loss: 2.1250465749412455

Epoch: 5| Step: 9
Training loss: 1.549404263496399
Validation loss: 2.177413393092412

Epoch: 5| Step: 10
Training loss: 1.5463014841079712
Validation loss: 2.1319195993484987

Epoch: 336| Step: 0
Training loss: 2.2838099002838135
Validation loss: 2.1190602766570223

Epoch: 5| Step: 1
Training loss: 1.2042341232299805
Validation loss: 2.1561790461181314

Epoch: 5| Step: 2
Training loss: 1.5188267230987549
Validation loss: 2.199180501763539

Epoch: 5| Step: 3
Training loss: 1.9149805307388306
Validation loss: 2.1052425292230423

Epoch: 5| Step: 4
Training loss: 2.0773873329162598
Validation loss: 2.138123522522629

Epoch: 5| Step: 5
Training loss: 1.7368513345718384
Validation loss: 2.16044904083334

Epoch: 5| Step: 6
Training loss: 2.5422203540802
Validation loss: 2.2020344657282673

Epoch: 5| Step: 7
Training loss: 1.5051941871643066
Validation loss: 2.156510091597034

Epoch: 5| Step: 8
Training loss: 0.9400219917297363
Validation loss: 2.1662657760804698

Epoch: 5| Step: 9
Training loss: 2.1149497032165527
Validation loss: 2.161431356142926

Epoch: 5| Step: 10
Training loss: 2.303145170211792
Validation loss: 2.155263828974898

Epoch: 337| Step: 0
Training loss: 2.3662514686584473
Validation loss: 2.1582322530849005

Epoch: 5| Step: 1
Training loss: 1.2188299894332886
Validation loss: 2.195571618695413

Epoch: 5| Step: 2
Training loss: 1.6736609935760498
Validation loss: 2.214007398133637

Epoch: 5| Step: 3
Training loss: 1.7903152704238892
Validation loss: 2.1313696471593713

Epoch: 5| Step: 4
Training loss: 1.1671693325042725
Validation loss: 2.10019318134554

Epoch: 5| Step: 5
Training loss: 1.3024680614471436
Validation loss: 2.1427684342989357

Epoch: 5| Step: 6
Training loss: 2.3304173946380615
Validation loss: 2.090639696326307

Epoch: 5| Step: 7
Training loss: 2.4935860633850098
Validation loss: 2.145732779656687

Epoch: 5| Step: 8
Training loss: 1.553047776222229
Validation loss: 2.1777620674461446

Epoch: 5| Step: 9
Training loss: 1.7790158987045288
Validation loss: 2.1428507489542805

Epoch: 5| Step: 10
Training loss: 2.271965742111206
Validation loss: 2.1866327895913074

Epoch: 338| Step: 0
Training loss: 2.231316089630127
Validation loss: 2.129335649551884

Epoch: 5| Step: 1
Training loss: 2.2389891147613525
Validation loss: 2.1201100413517286

Epoch: 5| Step: 2
Training loss: 1.890088438987732
Validation loss: 2.157290333060808

Epoch: 5| Step: 3
Training loss: 1.7714658975601196
Validation loss: 2.0665032914889756

Epoch: 5| Step: 4
Training loss: 1.7686264514923096
Validation loss: 2.0935257942445817

Epoch: 5| Step: 5
Training loss: 1.742040991783142
Validation loss: 2.140448602296973

Epoch: 5| Step: 6
Training loss: 2.298017978668213
Validation loss: 2.1380790818122124

Epoch: 5| Step: 7
Training loss: 1.4993627071380615
Validation loss: 2.1676727443613033

Epoch: 5| Step: 8
Training loss: 1.3680393695831299
Validation loss: 2.1679301825902795

Epoch: 5| Step: 9
Training loss: 1.9423593282699585
Validation loss: 2.1114549649659025

Epoch: 5| Step: 10
Training loss: 1.1776968240737915
Validation loss: 2.161691822031493

Epoch: 339| Step: 0
Training loss: 1.2018089294433594
Validation loss: 2.135895006118282

Epoch: 5| Step: 1
Training loss: 1.7705259323120117
Validation loss: 2.1091134317459597

Epoch: 5| Step: 2
Training loss: 1.5456899404525757
Validation loss: 2.1521929720396638

Epoch: 5| Step: 3
Training loss: 1.844808578491211
Validation loss: 2.1967089637633292

Epoch: 5| Step: 4
Training loss: 2.034945249557495
Validation loss: 2.128006722337456

Epoch: 5| Step: 5
Training loss: 1.751133680343628
Validation loss: 2.171318274672313

Epoch: 5| Step: 6
Training loss: 1.931888222694397
Validation loss: 2.15185986539369

Epoch: 5| Step: 7
Training loss: 1.9526550769805908
Validation loss: 2.1597704323389197

Epoch: 5| Step: 8
Training loss: 1.7942577600479126
Validation loss: 2.1580107468430714

Epoch: 5| Step: 9
Training loss: 2.2227015495300293
Validation loss: 2.1629868822713054

Epoch: 5| Step: 10
Training loss: 1.739382028579712
Validation loss: 2.1975298081674883

Epoch: 340| Step: 0
Training loss: 1.9179710149765015
Validation loss: 2.1487523765974146

Epoch: 5| Step: 1
Training loss: 1.7242441177368164
Validation loss: 2.1720737744403142

Epoch: 5| Step: 2
Training loss: 2.2028579711914062
Validation loss: 2.1887089065326157

Epoch: 5| Step: 3
Training loss: 1.6023889780044556
Validation loss: 2.1228385753529047

Epoch: 5| Step: 4
Training loss: 2.4606709480285645
Validation loss: 2.231158415476481

Epoch: 5| Step: 5
Training loss: 2.0305635929107666
Validation loss: 2.1471744250225764

Epoch: 5| Step: 6
Training loss: 1.4831678867340088
Validation loss: 2.1487941895761797

Epoch: 5| Step: 7
Training loss: 1.6639430522918701
Validation loss: 2.146603233070784

Epoch: 5| Step: 8
Training loss: 1.5638145208358765
Validation loss: 2.1529275601910007

Epoch: 5| Step: 9
Training loss: 1.6465383768081665
Validation loss: 2.1380624617299726

Epoch: 5| Step: 10
Training loss: 1.5421768426895142
Validation loss: 2.083642316120927

Epoch: 341| Step: 0
Training loss: 2.0645036697387695
Validation loss: 2.0948655413043116

Epoch: 5| Step: 1
Training loss: 1.4008616209030151
Validation loss: 2.0887729429429576

Epoch: 5| Step: 2
Training loss: 1.9686342477798462
Validation loss: 2.1289291484381563

Epoch: 5| Step: 3
Training loss: 2.1598522663116455
Validation loss: 2.173206647237142

Epoch: 5| Step: 4
Training loss: 2.0994839668273926
Validation loss: 2.208936381083663

Epoch: 5| Step: 5
Training loss: 1.255612850189209
Validation loss: 2.172859085503445

Epoch: 5| Step: 6
Training loss: 0.821036696434021
Validation loss: 2.167078866753527

Epoch: 5| Step: 7
Training loss: 2.176980972290039
Validation loss: 2.185522856250886

Epoch: 5| Step: 8
Training loss: 2.0922932624816895
Validation loss: 2.18422967644148

Epoch: 5| Step: 9
Training loss: 1.4463894367218018
Validation loss: 2.1760536265629593

Epoch: 5| Step: 10
Training loss: 1.964581847190857
Validation loss: 2.195934716091361

Epoch: 342| Step: 0
Training loss: 2.3421790599823
Validation loss: 2.169263526957522

Epoch: 5| Step: 1
Training loss: 1.819955825805664
Validation loss: 2.1303197619735554

Epoch: 5| Step: 2
Training loss: 1.742116928100586
Validation loss: 2.2024321068999586

Epoch: 5| Step: 3
Training loss: 1.6603933572769165
Validation loss: 2.210135200972198

Epoch: 5| Step: 4
Training loss: 1.7404758930206299
Validation loss: 2.133496489576114

Epoch: 5| Step: 5
Training loss: 1.4512425661087036
Validation loss: 2.189066062691391

Epoch: 5| Step: 6
Training loss: 1.433883786201477
Validation loss: 2.237464834285039

Epoch: 5| Step: 7
Training loss: 2.278353214263916
Validation loss: 2.1168572659133584

Epoch: 5| Step: 8
Training loss: 2.185883045196533
Validation loss: 2.038496022583336

Epoch: 5| Step: 9
Training loss: 1.689073920249939
Validation loss: 2.1621373622648177

Epoch: 5| Step: 10
Training loss: 1.6791913509368896
Validation loss: 2.142837703868907

Epoch: 343| Step: 0
Training loss: 1.8228397369384766
Validation loss: 2.1476047654305734

Epoch: 5| Step: 1
Training loss: 1.9994230270385742
Validation loss: 2.179180597746244

Epoch: 5| Step: 2
Training loss: 1.6925420761108398
Validation loss: 2.156731446584066

Epoch: 5| Step: 3
Training loss: 1.7121994495391846
Validation loss: 2.150944253449799

Epoch: 5| Step: 4
Training loss: 1.5232056379318237
Validation loss: 2.134545587724255

Epoch: 5| Step: 5
Training loss: 1.732137680053711
Validation loss: 2.1376356642733336

Epoch: 5| Step: 6
Training loss: 2.331456422805786
Validation loss: 2.142960358691472

Epoch: 5| Step: 7
Training loss: 1.5701583623886108
Validation loss: 2.1223275584559285

Epoch: 5| Step: 8
Training loss: 1.4467827081680298
Validation loss: 2.1125325079887145

Epoch: 5| Step: 9
Training loss: 2.3318352699279785
Validation loss: 2.0720961657903527

Epoch: 5| Step: 10
Training loss: 1.560354471206665
Validation loss: 2.0898330711549327

Epoch: 344| Step: 0
Training loss: 2.0232646465301514
Validation loss: 2.1547174530644573

Epoch: 5| Step: 1
Training loss: 2.321763515472412
Validation loss: 2.1256691102058656

Epoch: 5| Step: 2
Training loss: 2.1092875003814697
Validation loss: 2.1427956870807114

Epoch: 5| Step: 3
Training loss: 1.5622845888137817
Validation loss: 2.161203320308398

Epoch: 5| Step: 4
Training loss: 1.4742923974990845
Validation loss: 2.1570989149872974

Epoch: 5| Step: 5
Training loss: 1.9230540990829468
Validation loss: 2.1900051422016595

Epoch: 5| Step: 6
Training loss: 1.4426366090774536
Validation loss: 2.1347394463836507

Epoch: 5| Step: 7
Training loss: 1.709539771080017
Validation loss: 2.151886506747174

Epoch: 5| Step: 8
Training loss: 1.849761962890625
Validation loss: 2.221512281766502

Epoch: 5| Step: 9
Training loss: 1.4177106618881226
Validation loss: 2.180147437639134

Epoch: 5| Step: 10
Training loss: 2.1974172592163086
Validation loss: 2.108540642646051

Epoch: 345| Step: 0
Training loss: 1.7523934841156006
Validation loss: 2.201401102927423

Epoch: 5| Step: 1
Training loss: 1.737012267112732
Validation loss: 2.1623298929583643

Epoch: 5| Step: 2
Training loss: 1.6974151134490967
Validation loss: 2.212413348177428

Epoch: 5| Step: 3
Training loss: 2.1264421939849854
Validation loss: 2.12734321625002

Epoch: 5| Step: 4
Training loss: 1.7036603689193726
Validation loss: 2.2063548077819166

Epoch: 5| Step: 5
Training loss: 1.8777501583099365
Validation loss: 2.1647163885895924

Epoch: 5| Step: 6
Training loss: 1.5969841480255127
Validation loss: 2.1171202428879274

Epoch: 5| Step: 7
Training loss: 1.5152112245559692
Validation loss: 2.151562298497846

Epoch: 5| Step: 8
Training loss: 1.5751153230667114
Validation loss: 2.0791954891656035

Epoch: 5| Step: 9
Training loss: 2.2741706371307373
Validation loss: 2.1662898743024437

Epoch: 5| Step: 10
Training loss: 1.6448324918746948
Validation loss: 2.1581411066875664

Epoch: 346| Step: 0
Training loss: 1.5461785793304443
Validation loss: 2.130567237895022

Epoch: 5| Step: 1
Training loss: 2.295180320739746
Validation loss: 2.1751839268592095

Epoch: 5| Step: 2
Training loss: 1.7925631999969482
Validation loss: 2.1238325718910462

Epoch: 5| Step: 3
Training loss: 1.7618367671966553
Validation loss: 2.1962340467719623

Epoch: 5| Step: 4
Training loss: 1.9817142486572266
Validation loss: 2.1629773673190864

Epoch: 5| Step: 5
Training loss: 2.1383018493652344
Validation loss: 2.153156162590109

Epoch: 5| Step: 6
Training loss: 1.4600231647491455
Validation loss: 2.1452281167430263

Epoch: 5| Step: 7
Training loss: 1.3372691869735718
Validation loss: 2.0878874922311432

Epoch: 5| Step: 8
Training loss: 1.5909103155136108
Validation loss: 2.111987078061668

Epoch: 5| Step: 9
Training loss: 2.599335193634033
Validation loss: 2.1539037586540304

Epoch: 5| Step: 10
Training loss: 1.470410704612732
Validation loss: 2.0639543597416212

Epoch: 347| Step: 0
Training loss: 1.4486972093582153
Validation loss: 2.087347306231017

Epoch: 5| Step: 1
Training loss: 2.6427130699157715
Validation loss: 2.1198238301020798

Epoch: 5| Step: 2
Training loss: 1.7329343557357788
Validation loss: 2.1162020288487917

Epoch: 5| Step: 3
Training loss: 1.8179889917373657
Validation loss: 2.111355286772533

Epoch: 5| Step: 4
Training loss: 1.3391878604888916
Validation loss: 2.2202653243977535

Epoch: 5| Step: 5
Training loss: 1.837063193321228
Validation loss: 2.2054625864951842

Epoch: 5| Step: 6
Training loss: 1.6950562000274658
Validation loss: 2.119776902660247

Epoch: 5| Step: 7
Training loss: 2.1463325023651123
Validation loss: 2.071428968060401

Epoch: 5| Step: 8
Training loss: 1.6944109201431274
Validation loss: 2.103866213111467

Epoch: 5| Step: 9
Training loss: 1.5878092050552368
Validation loss: 2.160502564522528

Epoch: 5| Step: 10
Training loss: 2.1322999000549316
Validation loss: 2.1284423156451155

Epoch: 348| Step: 0
Training loss: 2.2563109397888184
Validation loss: 2.1267075128452753

Epoch: 5| Step: 1
Training loss: 2.1678409576416016
Validation loss: 2.024952247578611

Epoch: 5| Step: 2
Training loss: 1.6512119770050049
Validation loss: 2.1833854823984127

Epoch: 5| Step: 3
Training loss: 1.6080900430679321
Validation loss: 2.187679203607703

Epoch: 5| Step: 4
Training loss: 1.9980525970458984
Validation loss: 2.139045905041438

Epoch: 5| Step: 5
Training loss: 2.1008403301239014
Validation loss: 2.160322199585617

Epoch: 5| Step: 6
Training loss: 1.6734294891357422
Validation loss: 2.1327360330089444

Epoch: 5| Step: 7
Training loss: 1.465407133102417
Validation loss: 2.0687204202016196

Epoch: 5| Step: 8
Training loss: 1.8446975946426392
Validation loss: 2.125057407604751

Epoch: 5| Step: 9
Training loss: 1.516556978225708
Validation loss: 2.1305982374375865

Epoch: 5| Step: 10
Training loss: 2.1725831031799316
Validation loss: 2.1052016814549765

Epoch: 349| Step: 0
Training loss: 2.0938563346862793
Validation loss: 2.1606205304463706

Epoch: 5| Step: 1
Training loss: 1.515141248703003
Validation loss: 2.110108487067684

Epoch: 5| Step: 2
Training loss: 1.5223296880722046
Validation loss: 2.119231488115044

Epoch: 5| Step: 3
Training loss: 1.9498745203018188
Validation loss: 2.1215399542162494

Epoch: 5| Step: 4
Training loss: 1.8442165851593018
Validation loss: 2.121508090726791

Epoch: 5| Step: 5
Training loss: 1.4825966358184814
Validation loss: 2.1917405923207602

Epoch: 5| Step: 6
Training loss: 1.7527635097503662
Validation loss: 2.1352544292326896

Epoch: 5| Step: 7
Training loss: 2.5750503540039062
Validation loss: 2.195555128077025

Epoch: 5| Step: 8
Training loss: 1.5777628421783447
Validation loss: 2.165093380917785

Epoch: 5| Step: 9
Training loss: 1.9248886108398438
Validation loss: 2.179311498518913

Epoch: 5| Step: 10
Training loss: 1.9289522171020508
Validation loss: 2.134865536484667

Epoch: 350| Step: 0
Training loss: 1.8058497905731201
Validation loss: 2.157130597740091

Epoch: 5| Step: 1
Training loss: 1.910294771194458
Validation loss: 2.204195266128868

Epoch: 5| Step: 2
Training loss: 1.686873197555542
Validation loss: 2.2125456999706965

Epoch: 5| Step: 3
Training loss: 2.2811007499694824
Validation loss: 2.2421557621289323

Epoch: 5| Step: 4
Training loss: 1.329571008682251
Validation loss: 2.2143437811123428

Epoch: 5| Step: 5
Training loss: 2.2216601371765137
Validation loss: 2.1977921019318285

Epoch: 5| Step: 6
Training loss: 1.4017932415008545
Validation loss: 2.22899628198275

Epoch: 5| Step: 7
Training loss: 1.812558889389038
Validation loss: 2.1022341071918444

Epoch: 5| Step: 8
Training loss: 1.6570932865142822
Validation loss: 2.1205581952166814

Epoch: 5| Step: 9
Training loss: 1.6845118999481201
Validation loss: 2.130351997190906

Epoch: 5| Step: 10
Training loss: 1.6596460342407227
Validation loss: 2.1781639206794

Epoch: 351| Step: 0
Training loss: 1.0305110216140747
Validation loss: 2.1553417636502172

Epoch: 5| Step: 1
Training loss: 1.956783652305603
Validation loss: 2.1794281275041643

Epoch: 5| Step: 2
Training loss: 1.8495712280273438
Validation loss: 2.133994763897311

Epoch: 5| Step: 3
Training loss: 1.4301526546478271
Validation loss: 2.0694764467977707

Epoch: 5| Step: 4
Training loss: 2.4044601917266846
Validation loss: 2.1528752978130052

Epoch: 5| Step: 5
Training loss: 1.7898132801055908
Validation loss: 2.1136863193204327

Epoch: 5| Step: 6
Training loss: 1.7377792596817017
Validation loss: 2.1633095869454007

Epoch: 5| Step: 7
Training loss: 1.7642042636871338
Validation loss: 2.164112651219932

Epoch: 5| Step: 8
Training loss: 1.7730684280395508
Validation loss: 2.1730456275324666

Epoch: 5| Step: 9
Training loss: 1.740167260169983
Validation loss: 2.1550433122983543

Epoch: 5| Step: 10
Training loss: 2.3054261207580566
Validation loss: 2.12781096530217

Epoch: 352| Step: 0
Training loss: 2.0238516330718994
Validation loss: 2.1590915867077407

Epoch: 5| Step: 1
Training loss: 1.6915359497070312
Validation loss: 2.174746628730528

Epoch: 5| Step: 2
Training loss: 1.6098756790161133
Validation loss: 2.171716185026271

Epoch: 5| Step: 3
Training loss: 1.5973317623138428
Validation loss: 2.0771061887023268

Epoch: 5| Step: 4
Training loss: 1.4569509029388428
Validation loss: 2.134613007627508

Epoch: 5| Step: 5
Training loss: 2.5210318565368652
Validation loss: 2.1320175714390253

Epoch: 5| Step: 6
Training loss: 1.844707727432251
Validation loss: 2.0949862157144854

Epoch: 5| Step: 7
Training loss: 1.9993444681167603
Validation loss: 2.151680588722229

Epoch: 5| Step: 8
Training loss: 1.8207927942276
Validation loss: 2.148518617435168

Epoch: 5| Step: 9
Training loss: 1.6068027019500732
Validation loss: 2.1522118737620692

Epoch: 5| Step: 10
Training loss: 1.6220016479492188
Validation loss: 2.082507174502137

Epoch: 353| Step: 0
Training loss: 1.5446394681930542
Validation loss: 2.156653037635229

Epoch: 5| Step: 1
Training loss: 1.4318231344223022
Validation loss: 2.099118686491443

Epoch: 5| Step: 2
Training loss: 2.088414192199707
Validation loss: 2.1672147038162395

Epoch: 5| Step: 3
Training loss: 1.466626763343811
Validation loss: 2.138079453540105

Epoch: 5| Step: 4
Training loss: 2.163100004196167
Validation loss: 2.1815274761569117

Epoch: 5| Step: 5
Training loss: 1.4307849407196045
Validation loss: 2.1002365901906

Epoch: 5| Step: 6
Training loss: 2.16621994972229
Validation loss: 2.1436889376691592

Epoch: 5| Step: 7
Training loss: 1.777263879776001
Validation loss: 2.1239419329550957

Epoch: 5| Step: 8
Training loss: 1.7418453693389893
Validation loss: 2.1195408375032487

Epoch: 5| Step: 9
Training loss: 1.8676725625991821
Validation loss: 2.185104518808344

Epoch: 5| Step: 10
Training loss: 1.6532474756240845
Validation loss: 2.137263241634574

Epoch: 354| Step: 0
Training loss: 1.342056155204773
Validation loss: 2.146810357288648

Epoch: 5| Step: 1
Training loss: 1.3865387439727783
Validation loss: 2.1256097439796693

Epoch: 5| Step: 2
Training loss: 1.7357887029647827
Validation loss: 2.175370047169347

Epoch: 5| Step: 3
Training loss: 1.910832405090332
Validation loss: 2.174873016213858

Epoch: 5| Step: 4
Training loss: 1.9227596521377563
Validation loss: 2.168110780818488

Epoch: 5| Step: 5
Training loss: 1.7774146795272827
Validation loss: 2.195319003956292

Epoch: 5| Step: 6
Training loss: 2.009575366973877
Validation loss: 2.14049010122976

Epoch: 5| Step: 7
Training loss: 2.2209858894348145
Validation loss: 2.1878361304601035

Epoch: 5| Step: 8
Training loss: 2.1174521446228027
Validation loss: 2.299534697686472

Epoch: 5| Step: 9
Training loss: 1.1786730289459229
Validation loss: 2.1879455299787622

Epoch: 5| Step: 10
Training loss: 2.1261022090911865
Validation loss: 2.1474650380431966

Epoch: 355| Step: 0
Training loss: 2.1511917114257812
Validation loss: 2.233305092780821

Epoch: 5| Step: 1
Training loss: 2.2701003551483154
Validation loss: 2.1446101537314792

Epoch: 5| Step: 2
Training loss: 1.2214131355285645
Validation loss: 2.1341332620190037

Epoch: 5| Step: 3
Training loss: 1.8978204727172852
Validation loss: 2.102390754607416

Epoch: 5| Step: 4
Training loss: 1.8543163537979126
Validation loss: 2.134325212047946

Epoch: 5| Step: 5
Training loss: 1.7013047933578491
Validation loss: 2.1729133180392686

Epoch: 5| Step: 6
Training loss: 1.2700027227401733
Validation loss: 2.122488913997527

Epoch: 5| Step: 7
Training loss: 2.1763129234313965
Validation loss: 2.1796558557018155

Epoch: 5| Step: 8
Training loss: 1.236142873764038
Validation loss: 2.1092309515963317

Epoch: 5| Step: 9
Training loss: 1.6422412395477295
Validation loss: 2.1261655489603677

Epoch: 5| Step: 10
Training loss: 2.355236291885376
Validation loss: 2.1118071950891966

Epoch: 356| Step: 0
Training loss: 1.4917603731155396
Validation loss: 2.150280405116338

Epoch: 5| Step: 1
Training loss: 1.5005905628204346
Validation loss: 2.133207021221038

Epoch: 5| Step: 2
Training loss: 1.3656352758407593
Validation loss: 2.122374698679934

Epoch: 5| Step: 3
Training loss: 2.0304388999938965
Validation loss: 2.1687591473261514

Epoch: 5| Step: 4
Training loss: 1.689483880996704
Validation loss: 2.164788907574069

Epoch: 5| Step: 5
Training loss: 1.8536250591278076
Validation loss: 2.091296224183934

Epoch: 5| Step: 6
Training loss: 2.369347095489502
Validation loss: 2.172638826472785

Epoch: 5| Step: 7
Training loss: 2.4505486488342285
Validation loss: 2.1394318624209334

Epoch: 5| Step: 8
Training loss: 2.113358974456787
Validation loss: 2.226212401543894

Epoch: 5| Step: 9
Training loss: 1.4767255783081055
Validation loss: 2.1332603064916467

Epoch: 5| Step: 10
Training loss: 1.7176960706710815
Validation loss: 2.155311676763719

Epoch: 357| Step: 0
Training loss: 1.619805932044983
Validation loss: 2.141709389225129

Epoch: 5| Step: 1
Training loss: 1.6802623271942139
Validation loss: 2.2095562181165143

Epoch: 5| Step: 2
Training loss: 1.9480043649673462
Validation loss: 2.1510669262178483

Epoch: 5| Step: 3
Training loss: 1.32486093044281
Validation loss: 2.1783583600033998

Epoch: 5| Step: 4
Training loss: 1.7553869485855103
Validation loss: 2.167890987088603

Epoch: 5| Step: 5
Training loss: 1.3361799716949463
Validation loss: 2.137471902754999

Epoch: 5| Step: 6
Training loss: 2.3191640377044678
Validation loss: 2.118797923928948

Epoch: 5| Step: 7
Training loss: 2.3504772186279297
Validation loss: 2.157975189147457

Epoch: 5| Step: 8
Training loss: 1.7119948863983154
Validation loss: 2.129904700863746

Epoch: 5| Step: 9
Training loss: 1.7060620784759521
Validation loss: 2.1864252077635897

Epoch: 5| Step: 10
Training loss: 1.73775053024292
Validation loss: 2.194569318525253

Epoch: 358| Step: 0
Training loss: 1.765655755996704
Validation loss: 2.1387898165692567

Epoch: 5| Step: 1
Training loss: 1.6759235858917236
Validation loss: 2.156069294098885

Epoch: 5| Step: 2
Training loss: 1.4208651781082153
Validation loss: 2.1717966961604294

Epoch: 5| Step: 3
Training loss: 2.3346805572509766
Validation loss: 2.196379510305261

Epoch: 5| Step: 4
Training loss: 1.98356032371521
Validation loss: 2.216308016930857

Epoch: 5| Step: 5
Training loss: 1.6822052001953125
Validation loss: 2.1661093452925324

Epoch: 5| Step: 6
Training loss: 1.786277174949646
Validation loss: 2.1401438046527166

Epoch: 5| Step: 7
Training loss: 2.0723652839660645
Validation loss: 2.134469352742677

Epoch: 5| Step: 8
Training loss: 1.351926565170288
Validation loss: 2.145876690905581

Epoch: 5| Step: 9
Training loss: 2.1419341564178467
Validation loss: 2.097896827164517

Epoch: 5| Step: 10
Training loss: 1.41267728805542
Validation loss: 2.151741197032313

Epoch: 359| Step: 0
Training loss: 1.7791351079940796
Validation loss: 2.1553330908539476

Epoch: 5| Step: 1
Training loss: 1.2892590761184692
Validation loss: 2.1613401533454977

Epoch: 5| Step: 2
Training loss: 1.795985460281372
Validation loss: 2.1261820382969354

Epoch: 5| Step: 3
Training loss: 1.9876171350479126
Validation loss: 2.1091038001480924

Epoch: 5| Step: 4
Training loss: 1.9567047357559204
Validation loss: 2.158792495727539

Epoch: 5| Step: 5
Training loss: 1.8535610437393188
Validation loss: 2.062098700513122

Epoch: 5| Step: 6
Training loss: 1.6419626474380493
Validation loss: 2.118344760710193

Epoch: 5| Step: 7
Training loss: 1.8465973138809204
Validation loss: 2.1648434567195114

Epoch: 5| Step: 8
Training loss: 2.101458787918091
Validation loss: 2.1504771888896985

Epoch: 5| Step: 9
Training loss: 1.7992750406265259
Validation loss: 2.194317404941846

Epoch: 5| Step: 10
Training loss: 1.4272253513336182
Validation loss: 2.227488645943262

Epoch: 360| Step: 0
Training loss: 1.1573413610458374
Validation loss: 2.1696288636935654

Epoch: 5| Step: 1
Training loss: 1.7882068157196045
Validation loss: 2.1863871492365354

Epoch: 5| Step: 2
Training loss: 1.5838004350662231
Validation loss: 2.1508441048283733

Epoch: 5| Step: 3
Training loss: 2.059675455093384
Validation loss: 2.148909943078154

Epoch: 5| Step: 4
Training loss: 1.7639907598495483
Validation loss: 2.1220132535503757

Epoch: 5| Step: 5
Training loss: 1.7316100597381592
Validation loss: 2.1108868224646455

Epoch: 5| Step: 6
Training loss: 2.3142292499542236
Validation loss: 2.157030192754602

Epoch: 5| Step: 7
Training loss: 2.010162353515625
Validation loss: 2.2153116297978226

Epoch: 5| Step: 8
Training loss: 2.025099515914917
Validation loss: 2.1608747538699897

Epoch: 5| Step: 9
Training loss: 1.8335672616958618
Validation loss: 2.206662683076756

Epoch: 5| Step: 10
Training loss: 1.7110592126846313
Validation loss: 2.199034417829206

Epoch: 361| Step: 0
Training loss: 1.7427854537963867
Validation loss: 2.125157751062865

Epoch: 5| Step: 1
Training loss: 1.7255239486694336
Validation loss: 2.115357017004362

Epoch: 5| Step: 2
Training loss: 1.5028516054153442
Validation loss: 2.1521608162951726

Epoch: 5| Step: 3
Training loss: 2.364213705062866
Validation loss: 2.182425259262003

Epoch: 5| Step: 4
Training loss: 1.6002094745635986
Validation loss: 2.219729523504934

Epoch: 5| Step: 5
Training loss: 1.6419203281402588
Validation loss: 2.187304150673651

Epoch: 5| Step: 6
Training loss: 2.0743861198425293
Validation loss: 2.1725492374871367

Epoch: 5| Step: 7
Training loss: 1.329679250717163
Validation loss: 2.110935236818047

Epoch: 5| Step: 8
Training loss: 1.3528101444244385
Validation loss: 2.120725836805118

Epoch: 5| Step: 9
Training loss: 2.0644383430480957
Validation loss: 2.109827131353399

Epoch: 5| Step: 10
Training loss: 2.6238596439361572
Validation loss: 2.110766663346239

Epoch: 362| Step: 0
Training loss: 1.7910230159759521
Validation loss: 2.1451826659581994

Epoch: 5| Step: 1
Training loss: 1.5824122428894043
Validation loss: 2.13756481037345

Epoch: 5| Step: 2
Training loss: 2.2253165245056152
Validation loss: 2.0687503378878356

Epoch: 5| Step: 3
Training loss: 1.7822396755218506
Validation loss: 2.1921963486620175

Epoch: 5| Step: 4
Training loss: 1.6466878652572632
Validation loss: 2.1450843759762344

Epoch: 5| Step: 5
Training loss: 1.057691216468811
Validation loss: 2.1942317049990416

Epoch: 5| Step: 6
Training loss: 1.7706743478775024
Validation loss: 2.222838763267763

Epoch: 5| Step: 7
Training loss: 2.1782777309417725
Validation loss: 2.2392483347205707

Epoch: 5| Step: 8
Training loss: 2.128490924835205
Validation loss: 2.1445138223709597

Epoch: 5| Step: 9
Training loss: 2.234445810317993
Validation loss: 2.164138283780826

Epoch: 5| Step: 10
Training loss: 1.2966679334640503
Validation loss: 2.1942808397354616

Epoch: 363| Step: 0
Training loss: 1.941769003868103
Validation loss: 2.255530385560887

Epoch: 5| Step: 1
Training loss: 2.1020309925079346
Validation loss: 2.1267576217651367

Epoch: 5| Step: 2
Training loss: 1.6101758480072021
Validation loss: 2.1210280746541996

Epoch: 5| Step: 3
Training loss: 1.2537500858306885
Validation loss: 2.1213943214826685

Epoch: 5| Step: 4
Training loss: 2.6196722984313965
Validation loss: 2.156306448803153

Epoch: 5| Step: 5
Training loss: 1.7485198974609375
Validation loss: 2.114946119246944

Epoch: 5| Step: 6
Training loss: 1.4889787435531616
Validation loss: 2.1561305625464326

Epoch: 5| Step: 7
Training loss: 1.6215451955795288
Validation loss: 2.1448890368143716

Epoch: 5| Step: 8
Training loss: 1.64906907081604
Validation loss: 2.083049479351249

Epoch: 5| Step: 9
Training loss: 1.446671724319458
Validation loss: 2.1499687856243503

Epoch: 5| Step: 10
Training loss: 1.6735550165176392
Validation loss: 2.1769124205394457

Epoch: 364| Step: 0
Training loss: 1.9904295206069946
Validation loss: 2.1360215038381596

Epoch: 5| Step: 1
Training loss: 2.489351987838745
Validation loss: 2.157282652393464

Epoch: 5| Step: 2
Training loss: 1.5056817531585693
Validation loss: 2.068063028397099

Epoch: 5| Step: 3
Training loss: 2.0145130157470703
Validation loss: 2.104764025698426

Epoch: 5| Step: 4
Training loss: 1.4230420589447021
Validation loss: 2.197364089309528

Epoch: 5| Step: 5
Training loss: 1.4596010446548462
Validation loss: 2.1546452686350834

Epoch: 5| Step: 6
Training loss: 1.4757678508758545
Validation loss: 2.1780349285371843

Epoch: 5| Step: 7
Training loss: 2.0561442375183105
Validation loss: 2.0929323396375104

Epoch: 5| Step: 8
Training loss: 1.2748782634735107
Validation loss: 2.1434700027588875

Epoch: 5| Step: 9
Training loss: 1.7521568536758423
Validation loss: 2.163830062394501

Epoch: 5| Step: 10
Training loss: 2.040419101715088
Validation loss: 2.1792471049934306

Epoch: 365| Step: 0
Training loss: 1.9293642044067383
Validation loss: 2.1687330135735134

Epoch: 5| Step: 1
Training loss: 2.0537588596343994
Validation loss: 2.1241568442313903

Epoch: 5| Step: 2
Training loss: 2.172358274459839
Validation loss: 2.1388648786852436

Epoch: 5| Step: 3
Training loss: 1.5788408517837524
Validation loss: 2.144739394546837

Epoch: 5| Step: 4
Training loss: 1.7701900005340576
Validation loss: 2.151059795451421

Epoch: 5| Step: 5
Training loss: 1.7542734146118164
Validation loss: 2.212672689909576

Epoch: 5| Step: 6
Training loss: 1.5042132139205933
Validation loss: 2.117480108814855

Epoch: 5| Step: 7
Training loss: 1.4080125093460083
Validation loss: 2.1309784202165503

Epoch: 5| Step: 8
Training loss: 1.9427484273910522
Validation loss: 2.08632295362411

Epoch: 5| Step: 9
Training loss: 1.9271936416625977
Validation loss: 2.176802982566177

Epoch: 5| Step: 10
Training loss: 1.74627685546875
Validation loss: 2.194278868295813

Epoch: 366| Step: 0
Training loss: 1.2870835065841675
Validation loss: 2.1184393846860496

Epoch: 5| Step: 1
Training loss: 1.7039310932159424
Validation loss: 2.1989285715164675

Epoch: 5| Step: 2
Training loss: 1.4362850189208984
Validation loss: 2.0891410740472938

Epoch: 5| Step: 3
Training loss: 1.6564222574234009
Validation loss: 2.093146885595014

Epoch: 5| Step: 4
Training loss: 1.5328432321548462
Validation loss: 2.1009595535134755

Epoch: 5| Step: 5
Training loss: 1.3763039112091064
Validation loss: 2.185532799331091

Epoch: 5| Step: 6
Training loss: 1.630016565322876
Validation loss: 2.1673313802288425

Epoch: 5| Step: 7
Training loss: 1.8133151531219482
Validation loss: 2.094314690559141

Epoch: 5| Step: 8
Training loss: 2.233487367630005
Validation loss: 2.175076843589865

Epoch: 5| Step: 9
Training loss: 2.355170726776123
Validation loss: 2.2186105251312256

Epoch: 5| Step: 10
Training loss: 2.7325313091278076
Validation loss: 2.134728063819229

Epoch: 367| Step: 0
Training loss: 1.7785428762435913
Validation loss: 2.1537041177031813

Epoch: 5| Step: 1
Training loss: 1.5479192733764648
Validation loss: 2.1147404486133206

Epoch: 5| Step: 2
Training loss: 1.4239736795425415
Validation loss: 2.145617397882605

Epoch: 5| Step: 3
Training loss: 1.66031813621521
Validation loss: 2.070466605565881

Epoch: 5| Step: 4
Training loss: 2.1953012943267822
Validation loss: 2.160031498119395

Epoch: 5| Step: 5
Training loss: 1.9356266260147095
Validation loss: 2.1226790002597276

Epoch: 5| Step: 6
Training loss: 1.8168914318084717
Validation loss: 2.1479626701724146

Epoch: 5| Step: 7
Training loss: 2.0597405433654785
Validation loss: 2.193536643059023

Epoch: 5| Step: 8
Training loss: 1.6617587804794312
Validation loss: 2.1186295247847036

Epoch: 5| Step: 9
Training loss: 1.323707938194275
Validation loss: 2.180788287552454

Epoch: 5| Step: 10
Training loss: 2.1017696857452393
Validation loss: 2.0843187019389164

Epoch: 368| Step: 0
Training loss: 1.4365098476409912
Validation loss: 2.1880975974503385

Epoch: 5| Step: 1
Training loss: 2.731377124786377
Validation loss: 2.1654774860669206

Epoch: 5| Step: 2
Training loss: 2.0555167198181152
Validation loss: 2.167820729235167

Epoch: 5| Step: 3
Training loss: 1.414635419845581
Validation loss: 2.2101629677639214

Epoch: 5| Step: 4
Training loss: 1.6536391973495483
Validation loss: 2.164945020470568

Epoch: 5| Step: 5
Training loss: 0.9920753240585327
Validation loss: 2.182487528811219

Epoch: 5| Step: 6
Training loss: 1.9107825756072998
Validation loss: 2.165091235150573

Epoch: 5| Step: 7
Training loss: 1.7331749200820923
Validation loss: 2.1443860351398425

Epoch: 5| Step: 8
Training loss: 1.640774130821228
Validation loss: 2.165759758282733

Epoch: 5| Step: 9
Training loss: 2.0037903785705566
Validation loss: 2.16972949171579

Epoch: 5| Step: 10
Training loss: 1.8495054244995117
Validation loss: 2.1595503258448776

Epoch: 369| Step: 0
Training loss: 2.234099864959717
Validation loss: 2.185256153024653

Epoch: 5| Step: 1
Training loss: 1.7441980838775635
Validation loss: 2.1813094128844557

Epoch: 5| Step: 2
Training loss: 1.7214863300323486
Validation loss: 2.0965477804983816

Epoch: 5| Step: 3
Training loss: 0.9248552322387695
Validation loss: 2.160409854304406

Epoch: 5| Step: 4
Training loss: 2.3702166080474854
Validation loss: 2.2055818778212353

Epoch: 5| Step: 5
Training loss: 2.033250570297241
Validation loss: 2.2411721201353174

Epoch: 5| Step: 6
Training loss: 1.8082523345947266
Validation loss: 2.208962327690535

Epoch: 5| Step: 7
Training loss: 1.129471778869629
Validation loss: 2.1445390332129692

Epoch: 5| Step: 8
Training loss: 1.8676588535308838
Validation loss: 2.189980988861412

Epoch: 5| Step: 9
Training loss: 1.4751724004745483
Validation loss: 2.1258725145811677

Epoch: 5| Step: 10
Training loss: 1.706952452659607
Validation loss: 2.2388951252865534

Epoch: 370| Step: 0
Training loss: 1.4419896602630615
Validation loss: 2.181822448648432

Epoch: 5| Step: 1
Training loss: 1.5896825790405273
Validation loss: 2.1734682488185104

Epoch: 5| Step: 2
Training loss: 1.286184310913086
Validation loss: 2.1490291805677515

Epoch: 5| Step: 3
Training loss: 1.3904718160629272
Validation loss: 2.1422716955984793

Epoch: 5| Step: 4
Training loss: 1.5516716241836548
Validation loss: 2.132835416383641

Epoch: 5| Step: 5
Training loss: 2.232151508331299
Validation loss: 2.1500635531640824

Epoch: 5| Step: 6
Training loss: 1.5740389823913574
Validation loss: 2.211183842792306

Epoch: 5| Step: 7
Training loss: 2.127284526824951
Validation loss: 2.150867942840822

Epoch: 5| Step: 8
Training loss: 1.7965713739395142
Validation loss: 2.15655118291096

Epoch: 5| Step: 9
Training loss: 1.7648887634277344
Validation loss: 2.0984306232903593

Epoch: 5| Step: 10
Training loss: 2.40266489982605
Validation loss: 2.2130694376525057

Epoch: 371| Step: 0
Training loss: 1.513019323348999
Validation loss: 2.07911289763707

Epoch: 5| Step: 1
Training loss: 1.9846309423446655
Validation loss: 2.142528795426892

Epoch: 5| Step: 2
Training loss: 1.5076627731323242
Validation loss: 2.1591268611210648

Epoch: 5| Step: 3
Training loss: 1.2379438877105713
Validation loss: 2.2015452256766697

Epoch: 5| Step: 4
Training loss: 2.336498737335205
Validation loss: 2.143169338985156

Epoch: 5| Step: 5
Training loss: 1.7064087390899658
Validation loss: 2.088824563128974

Epoch: 5| Step: 6
Training loss: 2.031018018722534
Validation loss: 2.157818052076524

Epoch: 5| Step: 7
Training loss: 1.5441601276397705
Validation loss: 2.121064006641347

Epoch: 5| Step: 8
Training loss: 1.7776988744735718
Validation loss: 2.197585690406061

Epoch: 5| Step: 9
Training loss: 1.2305749654769897
Validation loss: 2.0966221811950847

Epoch: 5| Step: 10
Training loss: 2.457458257675171
Validation loss: 2.1762743483307543

Epoch: 372| Step: 0
Training loss: 2.1319077014923096
Validation loss: 2.1343327722241803

Epoch: 5| Step: 1
Training loss: 1.5975602865219116
Validation loss: 2.130866119938512

Epoch: 5| Step: 2
Training loss: 2.0335443019866943
Validation loss: 2.0694788181653587

Epoch: 5| Step: 3
Training loss: 1.522637128829956
Validation loss: 2.186245911864824

Epoch: 5| Step: 4
Training loss: 1.568296194076538
Validation loss: 2.10853644340269

Epoch: 5| Step: 5
Training loss: 1.8590097427368164
Validation loss: 2.167047180155272

Epoch: 5| Step: 6
Training loss: 1.8926479816436768
Validation loss: 2.127624765519173

Epoch: 5| Step: 7
Training loss: 1.175078272819519
Validation loss: 2.1686242472740913

Epoch: 5| Step: 8
Training loss: 1.9906032085418701
Validation loss: 2.1853067105816257

Epoch: 5| Step: 9
Training loss: 1.225185751914978
Validation loss: 2.1667577066729145

Epoch: 5| Step: 10
Training loss: 2.1736032962799072
Validation loss: 2.1583794996302617

Epoch: 373| Step: 0
Training loss: 1.5915932655334473
Validation loss: 2.102334822377851

Epoch: 5| Step: 1
Training loss: 1.7870616912841797
Validation loss: 2.1550756859522995

Epoch: 5| Step: 2
Training loss: 1.5467416048049927
Validation loss: 2.1006657205602175

Epoch: 5| Step: 3
Training loss: 1.83608078956604
Validation loss: 2.166236241658529

Epoch: 5| Step: 4
Training loss: 1.711014747619629
Validation loss: 2.1654993180305726

Epoch: 5| Step: 5
Training loss: 2.245497941970825
Validation loss: 2.156038281738117

Epoch: 5| Step: 6
Training loss: 1.1904160976409912
Validation loss: 2.180813567612761

Epoch: 5| Step: 7
Training loss: 1.7440322637557983
Validation loss: 2.1977971574311614

Epoch: 5| Step: 8
Training loss: 1.88037109375
Validation loss: 2.1231514433378815

Epoch: 5| Step: 9
Training loss: 2.2216687202453613
Validation loss: 2.254552169512677

Epoch: 5| Step: 10
Training loss: 1.4125527143478394
Validation loss: 2.205490260995844

Epoch: 374| Step: 0
Training loss: 2.029475688934326
Validation loss: 2.1481661360750914

Epoch: 5| Step: 1
Training loss: 1.5691794157028198
Validation loss: 2.09387146657513

Epoch: 5| Step: 2
Training loss: 1.418046236038208
Validation loss: 2.1764984489769064

Epoch: 5| Step: 3
Training loss: 1.3959897756576538
Validation loss: 2.166762177662183

Epoch: 5| Step: 4
Training loss: 2.4997148513793945
Validation loss: 2.1987534364064536

Epoch: 5| Step: 5
Training loss: 1.5502312183380127
Validation loss: 2.1848799874705653

Epoch: 5| Step: 6
Training loss: 1.3408640623092651
Validation loss: 2.143788053143409

Epoch: 5| Step: 7
Training loss: 1.5886318683624268
Validation loss: 2.1000747321754374

Epoch: 5| Step: 8
Training loss: 1.7665141820907593
Validation loss: 2.100117661619699

Epoch: 5| Step: 9
Training loss: 2.0825228691101074
Validation loss: 2.146733299378426

Epoch: 5| Step: 10
Training loss: 2.102717399597168
Validation loss: 2.1207956306395994

Epoch: 375| Step: 0
Training loss: 2.291029214859009
Validation loss: 2.1078043342918478

Epoch: 5| Step: 1
Training loss: 1.3919137716293335
Validation loss: 2.152007561857982

Epoch: 5| Step: 2
Training loss: 1.851258635520935
Validation loss: 2.0933089512650684

Epoch: 5| Step: 3
Training loss: 1.152747392654419
Validation loss: 2.195103314615065

Epoch: 5| Step: 4
Training loss: 1.3267498016357422
Validation loss: 2.118822156742055

Epoch: 5| Step: 5
Training loss: 1.7855842113494873
Validation loss: 2.086565425319056

Epoch: 5| Step: 6
Training loss: 1.7569046020507812
Validation loss: 2.1719005569334953

Epoch: 5| Step: 7
Training loss: 2.005894422531128
Validation loss: 2.164995165281398

Epoch: 5| Step: 8
Training loss: 2.4508419036865234
Validation loss: 2.0823002835755706

Epoch: 5| Step: 9
Training loss: 1.2788405418395996
Validation loss: 2.1792652747964345

Epoch: 5| Step: 10
Training loss: 1.8037158250808716
Validation loss: 2.202387514934745

Epoch: 376| Step: 0
Training loss: 1.4253926277160645
Validation loss: 2.1190478353090185

Epoch: 5| Step: 1
Training loss: 2.0421550273895264
Validation loss: 2.159442381192279

Epoch: 5| Step: 2
Training loss: 1.702164888381958
Validation loss: 2.2013627354816725

Epoch: 5| Step: 3
Training loss: 1.7062854766845703
Validation loss: 2.129227720281129

Epoch: 5| Step: 4
Training loss: 1.4959380626678467
Validation loss: 2.211244708748274

Epoch: 5| Step: 5
Training loss: 2.2342638969421387
Validation loss: 2.135015931180728

Epoch: 5| Step: 6
Training loss: 2.175502300262451
Validation loss: 2.165070423515894

Epoch: 5| Step: 7
Training loss: 1.7407963275909424
Validation loss: 2.2062629807379937

Epoch: 5| Step: 8
Training loss: 1.659044623374939
Validation loss: 2.132706429368706

Epoch: 5| Step: 9
Training loss: 1.6204893589019775
Validation loss: 2.099966804186503

Epoch: 5| Step: 10
Training loss: 1.6999579668045044
Validation loss: 2.1623198729689403

Epoch: 377| Step: 0
Training loss: 1.5277501344680786
Validation loss: 2.146173927091783

Epoch: 5| Step: 1
Training loss: 1.6064565181732178
Validation loss: 2.131432961392146

Epoch: 5| Step: 2
Training loss: 1.7302138805389404
Validation loss: 2.224972979996794

Epoch: 5| Step: 3
Training loss: 2.0600972175598145
Validation loss: 2.192339248554681

Epoch: 5| Step: 4
Training loss: 2.021214485168457
Validation loss: 2.160376887167654

Epoch: 5| Step: 5
Training loss: 2.0277769565582275
Validation loss: 2.1399225688749746

Epoch: 5| Step: 6
Training loss: 0.9957975149154663
Validation loss: 2.192504298302435

Epoch: 5| Step: 7
Training loss: 1.6809933185577393
Validation loss: 2.1714346819026495

Epoch: 5| Step: 8
Training loss: 1.6828606128692627
Validation loss: 2.1733594786736274

Epoch: 5| Step: 9
Training loss: 2.3804962635040283
Validation loss: 2.1318027075900825

Epoch: 5| Step: 10
Training loss: 1.965001106262207
Validation loss: 2.2307024091802616

Epoch: 378| Step: 0
Training loss: 1.8994646072387695
Validation loss: 2.1539410006615425

Epoch: 5| Step: 1
Training loss: 1.5526363849639893
Validation loss: 2.1882589119736866

Epoch: 5| Step: 2
Training loss: 1.637670874595642
Validation loss: 2.1340390264347033

Epoch: 5| Step: 3
Training loss: 1.844294786453247
Validation loss: 2.1842438097923034

Epoch: 5| Step: 4
Training loss: 1.1877162456512451
Validation loss: 2.17362896344995

Epoch: 5| Step: 5
Training loss: 1.9706761837005615
Validation loss: 2.1255083468652542

Epoch: 5| Step: 6
Training loss: 2.1986591815948486
Validation loss: 2.1505147654523133

Epoch: 5| Step: 7
Training loss: 1.1723637580871582
Validation loss: 2.1044224205837456

Epoch: 5| Step: 8
Training loss: 1.483712911605835
Validation loss: 2.0959782087674705

Epoch: 5| Step: 9
Training loss: 2.399880886077881
Validation loss: 2.1577561901461695

Epoch: 5| Step: 10
Training loss: 1.907842755317688
Validation loss: 2.1120150012354695

Epoch: 379| Step: 0
Training loss: 2.1766064167022705
Validation loss: 2.1829847789579824

Epoch: 5| Step: 1
Training loss: 1.6575167179107666
Validation loss: 2.1810698611761934

Epoch: 5| Step: 2
Training loss: 1.1825988292694092
Validation loss: 2.201787361534693

Epoch: 5| Step: 3
Training loss: 1.709511160850525
Validation loss: 2.1397560040156045

Epoch: 5| Step: 4
Training loss: 1.6312553882598877
Validation loss: 2.0934566015838296

Epoch: 5| Step: 5
Training loss: 1.94357168674469
Validation loss: 2.1195789152576077

Epoch: 5| Step: 6
Training loss: 1.3236926794052124
Validation loss: 2.207050592668595

Epoch: 5| Step: 7
Training loss: 2.235461473464966
Validation loss: 2.1239657478947795

Epoch: 5| Step: 8
Training loss: 2.045112371444702
Validation loss: 2.157937393393568

Epoch: 5| Step: 9
Training loss: 1.4449902772903442
Validation loss: 2.140648190693189

Epoch: 5| Step: 10
Training loss: 1.4012824296951294
Validation loss: 2.156478565226319

Epoch: 380| Step: 0
Training loss: 1.053180456161499
Validation loss: 2.1552733426452964

Epoch: 5| Step: 1
Training loss: 1.717905044555664
Validation loss: 2.089954874848807

Epoch: 5| Step: 2
Training loss: 2.203500270843506
Validation loss: 2.121102299741519

Epoch: 5| Step: 3
Training loss: 1.2331945896148682
Validation loss: 2.127290843635477

Epoch: 5| Step: 4
Training loss: 2.3846824169158936
Validation loss: 2.152758190708776

Epoch: 5| Step: 5
Training loss: 1.8551175594329834
Validation loss: 2.17984869915952

Epoch: 5| Step: 6
Training loss: 1.5909340381622314
Validation loss: 2.18313584532789

Epoch: 5| Step: 7
Training loss: 1.5979567766189575
Validation loss: 2.0825091344054028

Epoch: 5| Step: 8
Training loss: 2.3476109504699707
Validation loss: 2.178981791260422

Epoch: 5| Step: 9
Training loss: 1.489018440246582
Validation loss: 2.172054362553422

Epoch: 5| Step: 10
Training loss: 2.04132080078125
Validation loss: 2.1899928380084295

Epoch: 381| Step: 0
Training loss: 1.4134948253631592
Validation loss: 2.18333496585969

Epoch: 5| Step: 1
Training loss: 1.8287489414215088
Validation loss: 2.1853776439543693

Epoch: 5| Step: 2
Training loss: 1.7111823558807373
Validation loss: 2.1035654160284225

Epoch: 5| Step: 3
Training loss: 1.81204092502594
Validation loss: 2.1482046893847886

Epoch: 5| Step: 4
Training loss: 1.8749030828475952
Validation loss: 2.1244069171208206

Epoch: 5| Step: 5
Training loss: 2.2137956619262695
Validation loss: 2.167611104185863

Epoch: 5| Step: 6
Training loss: 1.3839752674102783
Validation loss: 2.182646418130526

Epoch: 5| Step: 7
Training loss: 1.3985202312469482
Validation loss: 2.1679427341748307

Epoch: 5| Step: 8
Training loss: 1.8934147357940674
Validation loss: 2.1157112249764065

Epoch: 5| Step: 9
Training loss: 1.9603761434555054
Validation loss: 2.205458851270778

Epoch: 5| Step: 10
Training loss: 1.498275637626648
Validation loss: 2.113055831642561

Epoch: 382| Step: 0
Training loss: 1.7940003871917725
Validation loss: 2.1182232364531486

Epoch: 5| Step: 1
Training loss: 1.6789319515228271
Validation loss: 2.143336455027262

Epoch: 5| Step: 2
Training loss: 1.518215298652649
Validation loss: 2.165186551309401

Epoch: 5| Step: 3
Training loss: 1.4166314601898193
Validation loss: 2.1365659621454056

Epoch: 5| Step: 4
Training loss: 1.8701515197753906
Validation loss: 2.1466919645186393

Epoch: 5| Step: 5
Training loss: 1.418798565864563
Validation loss: 2.102655481266719

Epoch: 5| Step: 6
Training loss: 1.4998716115951538
Validation loss: 2.157924618772281

Epoch: 5| Step: 7
Training loss: 1.9394171237945557
Validation loss: 2.1622035964842765

Epoch: 5| Step: 8
Training loss: 2.0471408367156982
Validation loss: 2.1690596354904996

Epoch: 5| Step: 9
Training loss: 1.6451717615127563
Validation loss: 2.134725198950819

Epoch: 5| Step: 10
Training loss: 1.76962411403656
Validation loss: 2.171752352868357

Epoch: 383| Step: 0
Training loss: 1.2782626152038574
Validation loss: 2.114818730661946

Epoch: 5| Step: 1
Training loss: 1.7008161544799805
Validation loss: 2.1396437409103557

Epoch: 5| Step: 2
Training loss: 2.3848278522491455
Validation loss: 2.143692062747094

Epoch: 5| Step: 3
Training loss: 1.427006483078003
Validation loss: 2.1325988666985625

Epoch: 5| Step: 4
Training loss: 1.7801491022109985
Validation loss: 2.1243120803627917

Epoch: 5| Step: 5
Training loss: 1.6759440898895264
Validation loss: 2.095943227890999

Epoch: 5| Step: 6
Training loss: 2.525885820388794
Validation loss: 2.130684200153556

Epoch: 5| Step: 7
Training loss: 1.564758062362671
Validation loss: 2.1416391608535603

Epoch: 5| Step: 8
Training loss: 1.9389070272445679
Validation loss: 2.165138788120721

Epoch: 5| Step: 9
Training loss: 1.32416570186615
Validation loss: 2.130272916568223

Epoch: 5| Step: 10
Training loss: 1.7424306869506836
Validation loss: 2.1344983654637493

Epoch: 384| Step: 0
Training loss: 2.055244207382202
Validation loss: 2.228049606405279

Epoch: 5| Step: 1
Training loss: 1.6172726154327393
Validation loss: 2.127672705599057

Epoch: 5| Step: 2
Training loss: 1.9112608432769775
Validation loss: 2.094677303427009

Epoch: 5| Step: 3
Training loss: 1.4149352312088013
Validation loss: 2.1335057417551675

Epoch: 5| Step: 4
Training loss: 1.8480325937271118
Validation loss: 2.1878926920634445

Epoch: 5| Step: 5
Training loss: 1.286383867263794
Validation loss: 2.217842641697135

Epoch: 5| Step: 6
Training loss: 2.3589234352111816
Validation loss: 2.150332878994685

Epoch: 5| Step: 7
Training loss: 1.4504120349884033
Validation loss: 2.152332813509049

Epoch: 5| Step: 8
Training loss: 1.769526481628418
Validation loss: 2.099017758523264

Epoch: 5| Step: 9
Training loss: 1.8384517431259155
Validation loss: 2.0915655525781776

Epoch: 5| Step: 10
Training loss: 1.5069233179092407
Validation loss: 2.0947038653076335

Epoch: 385| Step: 0
Training loss: 1.3843618631362915
Validation loss: 2.1394127030526437

Epoch: 5| Step: 1
Training loss: 2.0134048461914062
Validation loss: 2.16615919656651

Epoch: 5| Step: 2
Training loss: 2.0889129638671875
Validation loss: 2.1598936357805805

Epoch: 5| Step: 3
Training loss: 1.6243226528167725
Validation loss: 2.1734372646577897

Epoch: 5| Step: 4
Training loss: 1.7970774173736572
Validation loss: 2.0910181678751463

Epoch: 5| Step: 5
Training loss: 1.407631516456604
Validation loss: 2.1088400169085433

Epoch: 5| Step: 6
Training loss: 1.2524187564849854
Validation loss: 2.131026444896575

Epoch: 5| Step: 7
Training loss: 1.2963411808013916
Validation loss: 2.1282443487516014

Epoch: 5| Step: 8
Training loss: 1.452202558517456
Validation loss: 2.1543544338595484

Epoch: 5| Step: 9
Training loss: 2.1587274074554443
Validation loss: 2.1271909308689896

Epoch: 5| Step: 10
Training loss: 2.252825975418091
Validation loss: 2.1418743595000236

Epoch: 386| Step: 0
Training loss: 1.7605926990509033
Validation loss: 2.149898262434108

Epoch: 5| Step: 1
Training loss: 2.0737504959106445
Validation loss: 2.059949697986726

Epoch: 5| Step: 2
Training loss: 1.6241995096206665
Validation loss: 2.1227055647039927

Epoch: 5| Step: 3
Training loss: 1.6561914682388306
Validation loss: 2.1575005528747395

Epoch: 5| Step: 4
Training loss: 2.0174481868743896
Validation loss: 2.150110290896508

Epoch: 5| Step: 5
Training loss: 1.706352949142456
Validation loss: 2.183692391200732

Epoch: 5| Step: 6
Training loss: 1.8831764459609985
Validation loss: 2.131126880645752

Epoch: 5| Step: 7
Training loss: 1.5937167406082153
Validation loss: 2.172465790984451

Epoch: 5| Step: 8
Training loss: 1.4312427043914795
Validation loss: 2.1119816277616765

Epoch: 5| Step: 9
Training loss: 1.2940508127212524
Validation loss: 2.1250888993663173

Epoch: 5| Step: 10
Training loss: 1.455145001411438
Validation loss: 2.133652223053799

Epoch: 387| Step: 0
Training loss: 1.5834591388702393
Validation loss: 2.192079661994852

Epoch: 5| Step: 1
Training loss: 1.7645152807235718
Validation loss: 2.188406839165636

Epoch: 5| Step: 2
Training loss: 2.0772597789764404
Validation loss: 2.2362944643984557

Epoch: 5| Step: 3
Training loss: 1.3639885187149048
Validation loss: 2.1205303412611767

Epoch: 5| Step: 4
Training loss: 1.5864347219467163
Validation loss: 2.149830510539393

Epoch: 5| Step: 5
Training loss: 1.6189483404159546
Validation loss: 2.211803518315797

Epoch: 5| Step: 6
Training loss: 1.5624698400497437
Validation loss: 2.068505025679065

Epoch: 5| Step: 7
Training loss: 1.926628828048706
Validation loss: 2.18835703275537

Epoch: 5| Step: 8
Training loss: 1.744696855545044
Validation loss: 2.141806480705097

Epoch: 5| Step: 9
Training loss: 1.5019196271896362
Validation loss: 2.149957219759623

Epoch: 5| Step: 10
Training loss: 2.0051846504211426
Validation loss: 2.188022582761703

Epoch: 388| Step: 0
Training loss: 1.2247953414916992
Validation loss: 2.1498223248348443

Epoch: 5| Step: 1
Training loss: 1.9197666645050049
Validation loss: 2.1967119222046225

Epoch: 5| Step: 2
Training loss: 1.5000324249267578
Validation loss: 2.1935154545691704

Epoch: 5| Step: 3
Training loss: 2.2898097038269043
Validation loss: 2.205041031683645

Epoch: 5| Step: 4
Training loss: 1.7963025569915771
Validation loss: 2.1429376422718005

Epoch: 5| Step: 5
Training loss: 1.9551661014556885
Validation loss: 2.2009906832889845

Epoch: 5| Step: 6
Training loss: 1.2541254758834839
Validation loss: 2.18247317242366

Epoch: 5| Step: 7
Training loss: 2.1958725452423096
Validation loss: 2.137884973197855

Epoch: 5| Step: 8
Training loss: 1.5635334253311157
Validation loss: 2.1232438677100727

Epoch: 5| Step: 9
Training loss: 1.3465540409088135
Validation loss: 2.1544463019217215

Epoch: 5| Step: 10
Training loss: 1.675404667854309
Validation loss: 2.1180549667727564

Epoch: 389| Step: 0
Training loss: 1.079956293106079
Validation loss: 2.1040492967892717

Epoch: 5| Step: 1
Training loss: 1.9655025005340576
Validation loss: 2.132892608642578

Epoch: 5| Step: 2
Training loss: 1.9688446521759033
Validation loss: 2.133474108993366

Epoch: 5| Step: 3
Training loss: 1.437160849571228
Validation loss: 2.1415434422031527

Epoch: 5| Step: 4
Training loss: 1.7763149738311768
Validation loss: 2.1114115266389746

Epoch: 5| Step: 5
Training loss: 1.389321208000183
Validation loss: 2.149678995532374

Epoch: 5| Step: 6
Training loss: 1.6525160074234009
Validation loss: 2.15713168216008

Epoch: 5| Step: 7
Training loss: 2.1731204986572266
Validation loss: 2.1486482286965973

Epoch: 5| Step: 8
Training loss: 1.4617334604263306
Validation loss: 2.194600371904271

Epoch: 5| Step: 9
Training loss: 2.01662015914917
Validation loss: 2.101955715046134

Epoch: 5| Step: 10
Training loss: 1.6902856826782227
Validation loss: 2.157936098755047

Epoch: 390| Step: 0
Training loss: 1.7069705724716187
Validation loss: 2.133224456541

Epoch: 5| Step: 1
Training loss: 1.9412246942520142
Validation loss: 2.200278118092527

Epoch: 5| Step: 2
Training loss: 1.4435250759124756
Validation loss: 2.1707040879034225

Epoch: 5| Step: 3
Training loss: 2.017260789871216
Validation loss: 2.1403601502859466

Epoch: 5| Step: 4
Training loss: 1.9595577716827393
Validation loss: 2.2005546272441907

Epoch: 5| Step: 5
Training loss: 2.0428998470306396
Validation loss: 2.135179099216256

Epoch: 5| Step: 6
Training loss: 1.2674998044967651
Validation loss: 2.2143801386638353

Epoch: 5| Step: 7
Training loss: 1.838867425918579
Validation loss: 2.152766507158997

Epoch: 5| Step: 8
Training loss: 1.547523021697998
Validation loss: 2.219785906935251

Epoch: 5| Step: 9
Training loss: 1.4775450229644775
Validation loss: 2.203277180271764

Epoch: 5| Step: 10
Training loss: 1.5956757068634033
Validation loss: 2.1680619665371474

Epoch: 391| Step: 0
Training loss: 0.9286998510360718
Validation loss: 2.22803101488339

Epoch: 5| Step: 1
Training loss: 1.7795078754425049
Validation loss: 2.157087759305072

Epoch: 5| Step: 2
Training loss: 1.509084939956665
Validation loss: 2.1763834068852086

Epoch: 5| Step: 3
Training loss: 1.8997552394866943
Validation loss: 2.2274672062166276

Epoch: 5| Step: 4
Training loss: 2.290942430496216
Validation loss: 2.1424477138826923

Epoch: 5| Step: 5
Training loss: 2.110381841659546
Validation loss: 2.185216267903646

Epoch: 5| Step: 6
Training loss: 1.949976921081543
Validation loss: 2.1729128335111882

Epoch: 5| Step: 7
Training loss: 1.3200831413269043
Validation loss: 2.143695144243138

Epoch: 5| Step: 8
Training loss: 1.3654539585113525
Validation loss: 2.1583728354464293

Epoch: 5| Step: 9
Training loss: 1.6936410665512085
Validation loss: 2.222342893641482

Epoch: 5| Step: 10
Training loss: 1.6143884658813477
Validation loss: 2.098824683056083

Epoch: 392| Step: 0
Training loss: 1.8558088541030884
Validation loss: 2.1495213508605957

Epoch: 5| Step: 1
Training loss: 1.7268478870391846
Validation loss: 2.0967307013850056

Epoch: 5| Step: 2
Training loss: 1.056437611579895
Validation loss: 2.0768360181521346

Epoch: 5| Step: 3
Training loss: 1.6658920049667358
Validation loss: 2.105833917535761

Epoch: 5| Step: 4
Training loss: 1.437150239944458
Validation loss: 2.1594208209745345

Epoch: 5| Step: 5
Training loss: 2.04463529586792
Validation loss: 2.176994546767204

Epoch: 5| Step: 6
Training loss: 2.1889119148254395
Validation loss: 2.1161194744930474

Epoch: 5| Step: 7
Training loss: 2.513566493988037
Validation loss: 2.1402484114452074

Epoch: 5| Step: 8
Training loss: 1.772977590560913
Validation loss: 2.1671423399320213

Epoch: 5| Step: 9
Training loss: 1.6769529581069946
Validation loss: 2.1701119048621065

Epoch: 5| Step: 10
Training loss: 0.9792316555976868
Validation loss: 2.1523877190005396

Epoch: 393| Step: 0
Training loss: 1.8152443170547485
Validation loss: 2.1115141453281527

Epoch: 5| Step: 1
Training loss: 1.2742418050765991
Validation loss: 2.1419618693731164

Epoch: 5| Step: 2
Training loss: 2.1703414916992188
Validation loss: 2.1412593010933167

Epoch: 5| Step: 3
Training loss: 1.2380554676055908
Validation loss: 2.145967157938147

Epoch: 5| Step: 4
Training loss: 1.880735993385315
Validation loss: 2.1093445516401723

Epoch: 5| Step: 5
Training loss: 1.829779028892517
Validation loss: 2.169895077264437

Epoch: 5| Step: 6
Training loss: 1.508404016494751
Validation loss: 2.0946226876269103

Epoch: 5| Step: 7
Training loss: 1.9030895233154297
Validation loss: 2.143383328632642

Epoch: 5| Step: 8
Training loss: 1.5052907466888428
Validation loss: 2.0765191073058755

Epoch: 5| Step: 9
Training loss: 1.792730689048767
Validation loss: 2.11675605722653

Epoch: 5| Step: 10
Training loss: 1.6318477392196655
Validation loss: 2.1436079291887182

Epoch: 394| Step: 0
Training loss: 1.8160336017608643
Validation loss: 2.1535148518059843

Epoch: 5| Step: 1
Training loss: 2.07313871383667
Validation loss: 2.09025465801198

Epoch: 5| Step: 2
Training loss: 1.6058523654937744
Validation loss: 2.0633374234681487

Epoch: 5| Step: 3
Training loss: 2.138982057571411
Validation loss: 2.0842667997524305

Epoch: 5| Step: 4
Training loss: 1.7172095775604248
Validation loss: 2.1653410529577606

Epoch: 5| Step: 5
Training loss: 1.6083873510360718
Validation loss: 2.1507456917916574

Epoch: 5| Step: 6
Training loss: 1.589885950088501
Validation loss: 2.1676444725323747

Epoch: 5| Step: 7
Training loss: 1.3011356592178345
Validation loss: 2.123277162992826

Epoch: 5| Step: 8
Training loss: 1.7989839315414429
Validation loss: 2.130330193427301

Epoch: 5| Step: 9
Training loss: 0.9863832592964172
Validation loss: 2.1465374782521236

Epoch: 5| Step: 10
Training loss: 2.095477342605591
Validation loss: 2.208522729976203

Epoch: 395| Step: 0
Training loss: 1.4590198993682861
Validation loss: 2.1185054215051795

Epoch: 5| Step: 1
Training loss: 1.7787805795669556
Validation loss: 2.201820958045221

Epoch: 5| Step: 2
Training loss: 1.4081201553344727
Validation loss: 2.212331277067943

Epoch: 5| Step: 3
Training loss: 1.466837763786316
Validation loss: 2.1705057133910475

Epoch: 5| Step: 4
Training loss: 1.3657283782958984
Validation loss: 2.172065870736235

Epoch: 5| Step: 5
Training loss: 1.9316354990005493
Validation loss: 2.2133498832743657

Epoch: 5| Step: 6
Training loss: 1.846013069152832
Validation loss: 2.161214769527476

Epoch: 5| Step: 7
Training loss: 1.7454197406768799
Validation loss: 2.2164671703051497

Epoch: 5| Step: 8
Training loss: 2.249821186065674
Validation loss: 2.1480211032334195

Epoch: 5| Step: 9
Training loss: 1.81363046169281
Validation loss: 2.178214757673202

Epoch: 5| Step: 10
Training loss: 1.6909350156784058
Validation loss: 2.218170979971527

Epoch: 396| Step: 0
Training loss: 1.5622446537017822
Validation loss: 2.164465732471917

Epoch: 5| Step: 1
Training loss: 1.5406850576400757
Validation loss: 2.219744989948888

Epoch: 5| Step: 2
Training loss: 1.4825077056884766
Validation loss: 2.105728328868907

Epoch: 5| Step: 3
Training loss: 1.7937122583389282
Validation loss: 2.127963980038961

Epoch: 5| Step: 4
Training loss: 1.587873101234436
Validation loss: 2.189054827536306

Epoch: 5| Step: 5
Training loss: 1.6341898441314697
Validation loss: 2.1516020195458525

Epoch: 5| Step: 6
Training loss: 1.9602282047271729
Validation loss: 2.0738731148422405

Epoch: 5| Step: 7
Training loss: 1.891862154006958
Validation loss: 2.2119898603808497

Epoch: 5| Step: 8
Training loss: 1.8546737432479858
Validation loss: 2.1193997783045613

Epoch: 5| Step: 9
Training loss: 1.799058198928833
Validation loss: 2.1616730228547127

Epoch: 5| Step: 10
Training loss: 1.4392011165618896
Validation loss: 2.1787620667488343

Epoch: 397| Step: 0
Training loss: 1.414827823638916
Validation loss: 2.2140385143218504

Epoch: 5| Step: 1
Training loss: 1.3231277465820312
Validation loss: 2.1059803655070644

Epoch: 5| Step: 2
Training loss: 1.2176201343536377
Validation loss: 1.9922979711204447

Epoch: 5| Step: 3
Training loss: 1.6527338027954102
Validation loss: 2.1685468022541334

Epoch: 5| Step: 4
Training loss: 1.597254991531372
Validation loss: 2.1301796961856145

Epoch: 5| Step: 5
Training loss: 2.2867488861083984
Validation loss: 2.0973421694130026

Epoch: 5| Step: 6
Training loss: 2.107003927230835
Validation loss: 2.1169694700548725

Epoch: 5| Step: 7
Training loss: 1.849901795387268
Validation loss: 2.107686609350225

Epoch: 5| Step: 8
Training loss: 2.1268510818481445
Validation loss: 2.2311845133381505

Epoch: 5| Step: 9
Training loss: 1.3666329383850098
Validation loss: 2.10071853796641

Epoch: 5| Step: 10
Training loss: 1.6609153747558594
Validation loss: 2.164442800706433

Epoch: 398| Step: 0
Training loss: 1.5142649412155151
Validation loss: 2.1262500645011984

Epoch: 5| Step: 1
Training loss: 1.9748302698135376
Validation loss: 2.162988849865493

Epoch: 5| Step: 2
Training loss: 1.8209388256072998
Validation loss: 2.129082067038423

Epoch: 5| Step: 3
Training loss: 1.852425217628479
Validation loss: 2.143149729697935

Epoch: 5| Step: 4
Training loss: 1.734057068824768
Validation loss: 2.151350934018371

Epoch: 5| Step: 5
Training loss: 1.664229154586792
Validation loss: 2.178220530991913

Epoch: 5| Step: 6
Training loss: 1.9484611749649048
Validation loss: 2.147974498810307

Epoch: 5| Step: 7
Training loss: 1.5305320024490356
Validation loss: 2.1624958694622083

Epoch: 5| Step: 8
Training loss: 1.4253044128417969
Validation loss: 2.168245438606508

Epoch: 5| Step: 9
Training loss: 1.5252749919891357
Validation loss: 2.161285674700173

Epoch: 5| Step: 10
Training loss: 1.877898097038269
Validation loss: 2.235695074963313

Epoch: 399| Step: 0
Training loss: 1.7711461782455444
Validation loss: 2.143502866068194

Epoch: 5| Step: 1
Training loss: 1.6729176044464111
Validation loss: 2.1398593841060514

Epoch: 5| Step: 2
Training loss: 1.6527643203735352
Validation loss: 2.1944572156475437

Epoch: 5| Step: 3
Training loss: 2.0023462772369385
Validation loss: 2.1289150253418954

Epoch: 5| Step: 4
Training loss: 1.4549744129180908
Validation loss: 2.115763178435705

Epoch: 5| Step: 5
Training loss: 1.4011075496673584
Validation loss: 2.2069724272656184

Epoch: 5| Step: 6
Training loss: 1.9382171630859375
Validation loss: 2.1366168837393484

Epoch: 5| Step: 7
Training loss: 1.6050771474838257
Validation loss: 2.09880034513371

Epoch: 5| Step: 8
Training loss: 1.2898099422454834
Validation loss: 2.110624067244991

Epoch: 5| Step: 9
Training loss: 1.7963975667953491
Validation loss: 2.1856726420822965

Epoch: 5| Step: 10
Training loss: 2.214399814605713
Validation loss: 2.077076668380409

Epoch: 400| Step: 0
Training loss: 1.4743578433990479
Validation loss: 2.1175019228330223

Epoch: 5| Step: 1
Training loss: 1.3465988636016846
Validation loss: 2.045849638600503

Epoch: 5| Step: 2
Training loss: 1.5773327350616455
Validation loss: 2.094169723090305

Epoch: 5| Step: 3
Training loss: 0.9936882257461548
Validation loss: 2.093410950835033

Epoch: 5| Step: 4
Training loss: 2.175098419189453
Validation loss: 2.1900346817508822

Epoch: 5| Step: 5
Training loss: 1.6652485132217407
Validation loss: 2.1338607944468015

Epoch: 5| Step: 6
Training loss: 2.1197845935821533
Validation loss: 2.1250782589758597

Epoch: 5| Step: 7
Training loss: 2.090609073638916
Validation loss: 2.1171635684146675

Epoch: 5| Step: 8
Training loss: 1.6548808813095093
Validation loss: 2.137381371631417

Epoch: 5| Step: 9
Training loss: 1.2811594009399414
Validation loss: 2.1187026705793155

Epoch: 5| Step: 10
Training loss: 2.156778573989868
Validation loss: 2.1419380364879483

Epoch: 401| Step: 0
Training loss: 1.416078805923462
Validation loss: 2.2642508142737934

Epoch: 5| Step: 1
Training loss: 1.1354162693023682
Validation loss: 2.2230254680879655

Epoch: 5| Step: 2
Training loss: 1.3964070081710815
Validation loss: 2.1853245945386988

Epoch: 5| Step: 3
Training loss: 1.7887461185455322
Validation loss: 2.1343946072363083

Epoch: 5| Step: 4
Training loss: 1.8685775995254517
Validation loss: 2.233834017989456

Epoch: 5| Step: 5
Training loss: 2.079648733139038
Validation loss: 2.20110833773049

Epoch: 5| Step: 6
Training loss: 1.5549472570419312
Validation loss: 2.156980618353813

Epoch: 5| Step: 7
Training loss: 2.144166946411133
Validation loss: 2.223156670088409

Epoch: 5| Step: 8
Training loss: 1.658029556274414
Validation loss: 2.153023096822923

Epoch: 5| Step: 9
Training loss: 1.693373441696167
Validation loss: 2.1914025814302507

Epoch: 5| Step: 10
Training loss: 1.72109854221344
Validation loss: 2.2193868134611394

Epoch: 402| Step: 0
Training loss: 2.096439838409424
Validation loss: 2.1814311422327513

Epoch: 5| Step: 1
Training loss: 2.008458137512207
Validation loss: 2.1008641104544363

Epoch: 5| Step: 2
Training loss: 1.8373963832855225
Validation loss: 2.202414225506526

Epoch: 5| Step: 3
Training loss: 1.573970079421997
Validation loss: 2.2136121373022757

Epoch: 5| Step: 4
Training loss: 1.6455955505371094
Validation loss: 2.1451511665057112

Epoch: 5| Step: 5
Training loss: 1.7216002941131592
Validation loss: 2.2088183228687575

Epoch: 5| Step: 6
Training loss: 1.9812424182891846
Validation loss: 2.2466387710263653

Epoch: 5| Step: 7
Training loss: 1.7067315578460693
Validation loss: 2.1212018971802085

Epoch: 5| Step: 8
Training loss: 1.1206552982330322
Validation loss: 2.1011989078214093

Epoch: 5| Step: 9
Training loss: 1.3097110986709595
Validation loss: 2.1609497941950315

Epoch: 5| Step: 10
Training loss: 1.6871927976608276
Validation loss: 2.153593358173165

Epoch: 403| Step: 0
Training loss: 1.5040446519851685
Validation loss: 2.1213084831032702

Epoch: 5| Step: 1
Training loss: 2.2100958824157715
Validation loss: 2.166579184993621

Epoch: 5| Step: 2
Training loss: 2.017357349395752
Validation loss: 2.204740126927694

Epoch: 5| Step: 3
Training loss: 1.2990524768829346
Validation loss: 2.158435695914812

Epoch: 5| Step: 4
Training loss: 1.3767502307891846
Validation loss: 2.1700360210992957

Epoch: 5| Step: 5
Training loss: 2.100381851196289
Validation loss: 2.147162684830286

Epoch: 5| Step: 6
Training loss: 1.7610843181610107
Validation loss: 2.160556242030154

Epoch: 5| Step: 7
Training loss: 1.6972709894180298
Validation loss: 2.1367175130433935

Epoch: 5| Step: 8
Training loss: 1.8665988445281982
Validation loss: 2.162043930381857

Epoch: 5| Step: 9
Training loss: 1.3773655891418457
Validation loss: 2.1611319357349026

Epoch: 5| Step: 10
Training loss: 1.2182272672653198
Validation loss: 2.1079837122271137

Epoch: 404| Step: 0
Training loss: 1.3000367879867554
Validation loss: 2.100092782769152

Epoch: 5| Step: 1
Training loss: 1.9133975505828857
Validation loss: 2.1723476353512017

Epoch: 5| Step: 2
Training loss: 1.5923502445220947
Validation loss: 2.2178921225250408

Epoch: 5| Step: 3
Training loss: 1.7587871551513672
Validation loss: 2.1303043980752268

Epoch: 5| Step: 4
Training loss: 1.6109602451324463
Validation loss: 2.180776221777803

Epoch: 5| Step: 5
Training loss: 2.0081753730773926
Validation loss: 2.1383026210210656

Epoch: 5| Step: 6
Training loss: 2.3381752967834473
Validation loss: 2.1706795436079784

Epoch: 5| Step: 7
Training loss: 1.6159145832061768
Validation loss: 2.147386864949298

Epoch: 5| Step: 8
Training loss: 1.499727725982666
Validation loss: 2.117094350117509

Epoch: 5| Step: 9
Training loss: 2.1146717071533203
Validation loss: 2.2155240530608804

Epoch: 5| Step: 10
Training loss: 1.302782654762268
Validation loss: 2.1763057093466482

Epoch: 405| Step: 0
Training loss: 1.2755613327026367
Validation loss: 2.1940941272243375

Epoch: 5| Step: 1
Training loss: 1.2148785591125488
Validation loss: 2.1406554637416715

Epoch: 5| Step: 2
Training loss: 2.493666172027588
Validation loss: 2.172769561890633

Epoch: 5| Step: 3
Training loss: 1.81704580783844
Validation loss: 2.145313967940628

Epoch: 5| Step: 4
Training loss: 2.1043574810028076
Validation loss: 2.1987658008452384

Epoch: 5| Step: 5
Training loss: 1.5361546277999878
Validation loss: 2.181405310989708

Epoch: 5| Step: 6
Training loss: 1.8738136291503906
Validation loss: 2.124113041867492

Epoch: 5| Step: 7
Training loss: 1.2581506967544556
Validation loss: 2.1792112012063303

Epoch: 5| Step: 8
Training loss: 1.6802833080291748
Validation loss: 2.19098001141702

Epoch: 5| Step: 9
Training loss: 1.7020981311798096
Validation loss: 2.0638338442771667

Epoch: 5| Step: 10
Training loss: 1.4409509897232056
Validation loss: 2.181626401921754

Epoch: 406| Step: 0
Training loss: 1.7317081689834595
Validation loss: 2.1970977706293904

Epoch: 5| Step: 1
Training loss: 1.6437374353408813
Validation loss: 2.23437524226404

Epoch: 5| Step: 2
Training loss: 1.7508394718170166
Validation loss: 2.2389066988422024

Epoch: 5| Step: 3
Training loss: 1.310469150543213
Validation loss: 2.1113275225444506

Epoch: 5| Step: 4
Training loss: 2.214712619781494
Validation loss: 2.17823016002614

Epoch: 5| Step: 5
Training loss: 1.3768318891525269
Validation loss: 2.1545969593909478

Epoch: 5| Step: 6
Training loss: 1.7379558086395264
Validation loss: 2.1204466665944746

Epoch: 5| Step: 7
Training loss: 1.4645510911941528
Validation loss: 2.1064471096120854

Epoch: 5| Step: 8
Training loss: 1.3713891506195068
Validation loss: 2.1640339577069847

Epoch: 5| Step: 9
Training loss: 1.6478468179702759
Validation loss: 2.129867631901977

Epoch: 5| Step: 10
Training loss: 1.952043890953064
Validation loss: 2.1279184510630946

Epoch: 407| Step: 0
Training loss: 1.1195555925369263
Validation loss: 2.1473654777772966

Epoch: 5| Step: 1
Training loss: 1.7319492101669312
Validation loss: 2.059181979907456

Epoch: 5| Step: 2
Training loss: 1.611589789390564
Validation loss: 2.127344528834025

Epoch: 5| Step: 3
Training loss: 2.3230223655700684
Validation loss: 2.0914561658777218

Epoch: 5| Step: 4
Training loss: 1.4920326471328735
Validation loss: 2.0415174473998365

Epoch: 5| Step: 5
Training loss: 1.4407141208648682
Validation loss: 2.1425288031178136

Epoch: 5| Step: 6
Training loss: 1.9181556701660156
Validation loss: 2.1540762750051354

Epoch: 5| Step: 7
Training loss: 1.1628025770187378
Validation loss: 2.152569901558661

Epoch: 5| Step: 8
Training loss: 1.735290288925171
Validation loss: 2.1259581030056043

Epoch: 5| Step: 9
Training loss: 1.7952899932861328
Validation loss: 2.1727380701290664

Epoch: 5| Step: 10
Training loss: 1.9131734371185303
Validation loss: 2.2000504386040474

Epoch: 408| Step: 0
Training loss: 1.5807069540023804
Validation loss: 2.1328853817396265

Epoch: 5| Step: 1
Training loss: 2.027829170227051
Validation loss: 2.190586356706517

Epoch: 5| Step: 2
Training loss: 2.0189473628997803
Validation loss: 2.13768111377634

Epoch: 5| Step: 3
Training loss: 1.3053560256958008
Validation loss: 2.163978853533345

Epoch: 5| Step: 4
Training loss: 1.151720643043518
Validation loss: 2.120073292845039

Epoch: 5| Step: 5
Training loss: 1.9768489599227905
Validation loss: 2.111945302255692

Epoch: 5| Step: 6
Training loss: 2.030982255935669
Validation loss: 2.1605388041465514

Epoch: 5| Step: 7
Training loss: 1.7110744714736938
Validation loss: 2.1104653932714976

Epoch: 5| Step: 8
Training loss: 1.2998334169387817
Validation loss: 2.1431782681454896

Epoch: 5| Step: 9
Training loss: 1.805489182472229
Validation loss: 2.1935698293870494

Epoch: 5| Step: 10
Training loss: 1.576075553894043
Validation loss: 2.1335898958226687

Epoch: 409| Step: 0
Training loss: 1.8135530948638916
Validation loss: 2.1366041885909213

Epoch: 5| Step: 1
Training loss: 1.5505009889602661
Validation loss: 2.151196937407217

Epoch: 5| Step: 2
Training loss: 1.5317744016647339
Validation loss: 2.1288197784013647

Epoch: 5| Step: 3
Training loss: 1.5840235948562622
Validation loss: 2.149327829319944

Epoch: 5| Step: 4
Training loss: 1.8080670833587646
Validation loss: 2.1531753822039534

Epoch: 5| Step: 5
Training loss: 1.7794334888458252
Validation loss: 2.1864070533424296

Epoch: 5| Step: 6
Training loss: 1.682385802268982
Validation loss: 2.117616679078789

Epoch: 5| Step: 7
Training loss: 1.7327349185943604
Validation loss: 2.2010283803427093

Epoch: 5| Step: 8
Training loss: 1.2474693059921265
Validation loss: 2.1615378933568157

Epoch: 5| Step: 9
Training loss: 1.9263393878936768
Validation loss: 2.159089275585708

Epoch: 5| Step: 10
Training loss: 1.774338722229004
Validation loss: 2.1794892331605316

Epoch: 410| Step: 0
Training loss: 1.7889467477798462
Validation loss: 2.1734962873561408

Epoch: 5| Step: 1
Training loss: 1.854975938796997
Validation loss: 2.130899706194478

Epoch: 5| Step: 2
Training loss: 2.0079665184020996
Validation loss: 2.202823591488664

Epoch: 5| Step: 3
Training loss: 1.3104956150054932
Validation loss: 2.1339070040692567

Epoch: 5| Step: 4
Training loss: 1.528334140777588
Validation loss: 2.1393851490430933

Epoch: 5| Step: 5
Training loss: 1.9865672588348389
Validation loss: 2.1640825553606917

Epoch: 5| Step: 6
Training loss: 1.5222899913787842
Validation loss: 2.1418707575849307

Epoch: 5| Step: 7
Training loss: 1.7151384353637695
Validation loss: 2.1948601045916156

Epoch: 5| Step: 8
Training loss: 1.4644525051116943
Validation loss: 2.1397554310419227

Epoch: 5| Step: 9
Training loss: 1.5138561725616455
Validation loss: 2.1788761692662395

Epoch: 5| Step: 10
Training loss: 1.394435167312622
Validation loss: 2.1204731233658327

Epoch: 411| Step: 0
Training loss: 1.387470006942749
Validation loss: 2.1643837933899253

Epoch: 5| Step: 1
Training loss: 1.582074522972107
Validation loss: 2.1594870193030244

Epoch: 5| Step: 2
Training loss: 1.8462069034576416
Validation loss: 2.1891715270216747

Epoch: 5| Step: 3
Training loss: 1.5930454730987549
Validation loss: 2.187975516883276

Epoch: 5| Step: 4
Training loss: 1.6085342168807983
Validation loss: 2.093946482545586

Epoch: 5| Step: 5
Training loss: 1.7083120346069336
Validation loss: 2.148135777442686

Epoch: 5| Step: 6
Training loss: 1.2246358394622803
Validation loss: 2.1447403277120283

Epoch: 5| Step: 7
Training loss: 2.477375030517578
Validation loss: 2.1309339948879775

Epoch: 5| Step: 8
Training loss: 1.609609842300415
Validation loss: 2.1534165105512066

Epoch: 5| Step: 9
Training loss: 1.6679022312164307
Validation loss: 2.2637557009214997

Epoch: 5| Step: 10
Training loss: 1.509464979171753
Validation loss: 2.1170906174567437

Epoch: 412| Step: 0
Training loss: 1.8246862888336182
Validation loss: 2.1734827282608196

Epoch: 5| Step: 1
Training loss: 1.1411038637161255
Validation loss: 2.163787411105248

Epoch: 5| Step: 2
Training loss: 1.8402512073516846
Validation loss: 2.1712865393648864

Epoch: 5| Step: 3
Training loss: 1.6998640298843384
Validation loss: 2.1252950570916616

Epoch: 5| Step: 4
Training loss: 2.226670265197754
Validation loss: 2.159987474000582

Epoch: 5| Step: 5
Training loss: 1.7475872039794922
Validation loss: 2.1125912153592674

Epoch: 5| Step: 6
Training loss: 1.8590621948242188
Validation loss: 2.049768849085736

Epoch: 5| Step: 7
Training loss: 1.3417291641235352
Validation loss: 2.1723774645918157

Epoch: 5| Step: 8
Training loss: 1.8193159103393555
Validation loss: 2.1970964426635415

Epoch: 5| Step: 9
Training loss: 1.594935655593872
Validation loss: 2.21088739620742

Epoch: 5| Step: 10
Training loss: 1.413576364517212
Validation loss: 2.133159969442634

Epoch: 413| Step: 0
Training loss: 1.205029010772705
Validation loss: 2.140732370397096

Epoch: 5| Step: 1
Training loss: 1.722712755203247
Validation loss: 2.1501046483234694

Epoch: 5| Step: 2
Training loss: 1.7053978443145752
Validation loss: 2.2329473034028084

Epoch: 5| Step: 3
Training loss: 1.464608073234558
Validation loss: 2.182461779604676

Epoch: 5| Step: 4
Training loss: 2.3062357902526855
Validation loss: 2.1413778361453804

Epoch: 5| Step: 5
Training loss: 1.8433301448822021
Validation loss: 2.1281436925293296

Epoch: 5| Step: 6
Training loss: 1.5326340198516846
Validation loss: 2.0863854539009834

Epoch: 5| Step: 7
Training loss: 1.3915836811065674
Validation loss: 2.1930483848817888

Epoch: 5| Step: 8
Training loss: 2.0345067977905273
Validation loss: 2.1554676871145926

Epoch: 5| Step: 9
Training loss: 1.8425929546356201
Validation loss: 2.0635448412228654

Epoch: 5| Step: 10
Training loss: 1.4961905479431152
Validation loss: 2.1614324764538835

Epoch: 414| Step: 0
Training loss: 1.953601598739624
Validation loss: 2.12283754861483

Epoch: 5| Step: 1
Training loss: 1.6465072631835938
Validation loss: 2.16097278236061

Epoch: 5| Step: 2
Training loss: 1.5377017259597778
Validation loss: 2.1264162589144964

Epoch: 5| Step: 3
Training loss: 1.4724277257919312
Validation loss: 2.113210011554021

Epoch: 5| Step: 4
Training loss: 1.9243863821029663
Validation loss: 2.1380966696687924

Epoch: 5| Step: 5
Training loss: 1.414211630821228
Validation loss: 2.1980524845020746

Epoch: 5| Step: 6
Training loss: 1.135432243347168
Validation loss: 2.098865924342986

Epoch: 5| Step: 7
Training loss: 1.6089808940887451
Validation loss: 2.2485873109550885

Epoch: 5| Step: 8
Training loss: 1.5164202451705933
Validation loss: 2.085933034138013

Epoch: 5| Step: 9
Training loss: 2.116483211517334
Validation loss: 2.1265570348308933

Epoch: 5| Step: 10
Training loss: 1.462938904762268
Validation loss: 2.131639575445524

Epoch: 415| Step: 0
Training loss: 1.9805257320404053
Validation loss: 2.1905329214629305

Epoch: 5| Step: 1
Training loss: 1.8679234981536865
Validation loss: 2.1683786274284444

Epoch: 5| Step: 2
Training loss: 1.4440289735794067
Validation loss: 2.132164288592595

Epoch: 5| Step: 3
Training loss: 1.6079870462417603
Validation loss: 2.2074154218037925

Epoch: 5| Step: 4
Training loss: 2.137956380844116
Validation loss: 2.180881223370952

Epoch: 5| Step: 5
Training loss: 1.7827990055084229
Validation loss: 2.148928496145433

Epoch: 5| Step: 6
Training loss: 1.3347089290618896
Validation loss: 2.165824080026278

Epoch: 5| Step: 7
Training loss: 1.5613348484039307
Validation loss: 2.1759107933249524

Epoch: 5| Step: 8
Training loss: 1.445157766342163
Validation loss: 2.1325071011820147

Epoch: 5| Step: 9
Training loss: 1.895368218421936
Validation loss: 2.167675197765391

Epoch: 5| Step: 10
Training loss: 1.2951457500457764
Validation loss: 2.176469090164349

Epoch: 416| Step: 0
Training loss: 1.4837563037872314
Validation loss: 2.1595845632655646

Epoch: 5| Step: 1
Training loss: 2.010380983352661
Validation loss: 2.0710486468448432

Epoch: 5| Step: 2
Training loss: 1.513362169265747
Validation loss: 2.1596078629134805

Epoch: 5| Step: 3
Training loss: 2.2987639904022217
Validation loss: 2.131849927286948

Epoch: 5| Step: 4
Training loss: 1.7963759899139404
Validation loss: 2.082812209283152

Epoch: 5| Step: 5
Training loss: 1.5546878576278687
Validation loss: 2.156485849811185

Epoch: 5| Step: 6
Training loss: 1.546008586883545
Validation loss: 2.164507850523918

Epoch: 5| Step: 7
Training loss: 1.501560926437378
Validation loss: 2.173088437767439

Epoch: 5| Step: 8
Training loss: 1.8228256702423096
Validation loss: 2.154428643565024

Epoch: 5| Step: 9
Training loss: 1.4850915670394897
Validation loss: 2.131415041544104

Epoch: 5| Step: 10
Training loss: 1.436254858970642
Validation loss: 2.1834424106023644

Epoch: 417| Step: 0
Training loss: 1.2792035341262817
Validation loss: 2.071032724072856

Epoch: 5| Step: 1
Training loss: 2.1556143760681152
Validation loss: 2.102144266969414

Epoch: 5| Step: 2
Training loss: 1.163253664970398
Validation loss: 2.1395469070762716

Epoch: 5| Step: 3
Training loss: 1.9006664752960205
Validation loss: 2.1882345894331574

Epoch: 5| Step: 4
Training loss: 2.277311086654663
Validation loss: 2.167815021289292

Epoch: 5| Step: 5
Training loss: 1.8079144954681396
Validation loss: 2.161223126995948

Epoch: 5| Step: 6
Training loss: 1.6799390316009521
Validation loss: 2.204050143559774

Epoch: 5| Step: 7
Training loss: 1.470850944519043
Validation loss: 2.1641009417913293

Epoch: 5| Step: 8
Training loss: 1.2943930625915527
Validation loss: 2.155876394241087

Epoch: 5| Step: 9
Training loss: 1.7081031799316406
Validation loss: 2.135130864317699

Epoch: 5| Step: 10
Training loss: 1.7706655263900757
Validation loss: 2.199270094594648

Epoch: 418| Step: 0
Training loss: 1.3721212148666382
Validation loss: 2.1538778492199477

Epoch: 5| Step: 1
Training loss: 1.9870131015777588
Validation loss: 2.1434019509182183

Epoch: 5| Step: 2
Training loss: 1.3642939329147339
Validation loss: 2.170716085741597

Epoch: 5| Step: 3
Training loss: 1.5554929971694946
Validation loss: 2.099667041532455

Epoch: 5| Step: 4
Training loss: 0.9757516980171204
Validation loss: 2.104362767229798

Epoch: 5| Step: 5
Training loss: 2.303773880004883
Validation loss: 2.120069844748384

Epoch: 5| Step: 6
Training loss: 1.6600992679595947
Validation loss: 2.10558662363278

Epoch: 5| Step: 7
Training loss: 2.657951831817627
Validation loss: 2.149599531645416

Epoch: 5| Step: 8
Training loss: 0.9741804003715515
Validation loss: 2.1677734877473567

Epoch: 5| Step: 9
Training loss: 2.0541574954986572
Validation loss: 2.1725611686706543

Epoch: 5| Step: 10
Training loss: 1.5516700744628906
Validation loss: 2.150460845680647

Epoch: 419| Step: 0
Training loss: 1.716723084449768
Validation loss: 2.1281259239360852

Epoch: 5| Step: 1
Training loss: 1.1912542581558228
Validation loss: 2.1703593295107604

Epoch: 5| Step: 2
Training loss: 1.9484485387802124
Validation loss: 2.111134194558667

Epoch: 5| Step: 3
Training loss: 1.8234971761703491
Validation loss: 2.1407946130280853

Epoch: 5| Step: 4
Training loss: 1.7712719440460205
Validation loss: 2.1639732007057435

Epoch: 5| Step: 5
Training loss: 1.2451660633087158
Validation loss: 2.134151194685249

Epoch: 5| Step: 6
Training loss: 1.8364765644073486
Validation loss: 2.124720311933948

Epoch: 5| Step: 7
Training loss: 1.7352073192596436
Validation loss: 2.132831278667655

Epoch: 5| Step: 8
Training loss: 2.042320728302002
Validation loss: 2.1626155453343547

Epoch: 5| Step: 9
Training loss: 1.1849644184112549
Validation loss: 2.1118749495475524

Epoch: 5| Step: 10
Training loss: 1.984606146812439
Validation loss: 2.150327010821271

Epoch: 420| Step: 0
Training loss: 1.5457956790924072
Validation loss: 2.144078149590441

Epoch: 5| Step: 1
Training loss: 1.8143799304962158
Validation loss: 2.1282148591933714

Epoch: 5| Step: 2
Training loss: 1.716468095779419
Validation loss: 2.125012472111692

Epoch: 5| Step: 3
Training loss: 1.832457184791565
Validation loss: 2.129279334058044

Epoch: 5| Step: 4
Training loss: 1.4594894647598267
Validation loss: 2.1199379274922032

Epoch: 5| Step: 5
Training loss: 1.7567743062973022
Validation loss: 2.151747844552481

Epoch: 5| Step: 6
Training loss: 1.6054245233535767
Validation loss: 2.0950055481285177

Epoch: 5| Step: 7
Training loss: 1.3884823322296143
Validation loss: 2.1080175856108307

Epoch: 5| Step: 8
Training loss: 1.9272658824920654
Validation loss: 2.165470287364016

Epoch: 5| Step: 9
Training loss: 1.5778383016586304
Validation loss: 2.1294512799991074

Epoch: 5| Step: 10
Training loss: 2.2309935092926025
Validation loss: 2.13237734763853

Epoch: 421| Step: 0
Training loss: 1.237125277519226
Validation loss: 2.1291862354483655

Epoch: 5| Step: 1
Training loss: 2.1936631202697754
Validation loss: 2.114732324436147

Epoch: 5| Step: 2
Training loss: 1.8891541957855225
Validation loss: 2.101696962951332

Epoch: 5| Step: 3
Training loss: 1.2086137533187866
Validation loss: 2.1422492073428248

Epoch: 5| Step: 4
Training loss: 1.276013731956482
Validation loss: 2.2271797375012468

Epoch: 5| Step: 5
Training loss: 1.1220372915267944
Validation loss: 2.191049806533321

Epoch: 5| Step: 6
Training loss: 1.964281678199768
Validation loss: 2.141550494778541

Epoch: 5| Step: 7
Training loss: 1.8911774158477783
Validation loss: 2.190052673380862

Epoch: 5| Step: 8
Training loss: 1.856562852859497
Validation loss: 2.173156797244985

Epoch: 5| Step: 9
Training loss: 1.5629205703735352
Validation loss: 2.155810938086561

Epoch: 5| Step: 10
Training loss: 1.974713683128357
Validation loss: 2.1515174091503186

Epoch: 422| Step: 0
Training loss: 1.7341463565826416
Validation loss: 2.1651874562745452

Epoch: 5| Step: 1
Training loss: 1.6158809661865234
Validation loss: 2.195970335314351

Epoch: 5| Step: 2
Training loss: 2.230438232421875
Validation loss: 2.0934297833391415

Epoch: 5| Step: 3
Training loss: 1.5269451141357422
Validation loss: 2.184060187749965

Epoch: 5| Step: 4
Training loss: 1.9565210342407227
Validation loss: 2.1435199527330298

Epoch: 5| Step: 5
Training loss: 1.9714183807373047
Validation loss: 2.1654551516297045

Epoch: 5| Step: 6
Training loss: 1.8101532459259033
Validation loss: 2.1473424678207724

Epoch: 5| Step: 7
Training loss: 1.1155340671539307
Validation loss: 2.154797251506518

Epoch: 5| Step: 8
Training loss: 1.0042117834091187
Validation loss: 2.1933069177853164

Epoch: 5| Step: 9
Training loss: 1.6453710794448853
Validation loss: 2.07965834166414

Epoch: 5| Step: 10
Training loss: 1.3922346830368042
Validation loss: 2.0851873428590837

Epoch: 423| Step: 0
Training loss: 1.749850869178772
Validation loss: 2.19438087812034

Epoch: 5| Step: 1
Training loss: 1.7126251459121704
Validation loss: 2.101412627004808

Epoch: 5| Step: 2
Training loss: 2.246644973754883
Validation loss: 2.069982656868555

Epoch: 5| Step: 3
Training loss: 1.5906871557235718
Validation loss: 2.1283182687656854

Epoch: 5| Step: 4
Training loss: 1.4075453281402588
Validation loss: 2.158760283582954

Epoch: 5| Step: 5
Training loss: 1.6553268432617188
Validation loss: 2.1709963865177606

Epoch: 5| Step: 6
Training loss: 1.3017594814300537
Validation loss: 2.1869619225942962

Epoch: 5| Step: 7
Training loss: 1.5917832851409912
Validation loss: 2.1438487678445797

Epoch: 5| Step: 8
Training loss: 2.003983974456787
Validation loss: 2.081906498119395

Epoch: 5| Step: 9
Training loss: 2.1144134998321533
Validation loss: 2.1384697870541642

Epoch: 5| Step: 10
Training loss: 1.0927907228469849
Validation loss: 2.104374042121313

Epoch: 424| Step: 0
Training loss: 1.6426022052764893
Validation loss: 2.105067414622153

Epoch: 5| Step: 1
Training loss: 1.4226160049438477
Validation loss: 2.1063205901012627

Epoch: 5| Step: 2
Training loss: 1.2220615148544312
Validation loss: 2.131690109929731

Epoch: 5| Step: 3
Training loss: 1.8142337799072266
Validation loss: 2.107494654194001

Epoch: 5| Step: 4
Training loss: 1.6869518756866455
Validation loss: 2.1552153095122306

Epoch: 5| Step: 5
Training loss: 1.8789952993392944
Validation loss: 2.1578520280058666

Epoch: 5| Step: 6
Training loss: 2.320610523223877
Validation loss: 2.1748774641303608

Epoch: 5| Step: 7
Training loss: 1.3821132183074951
Validation loss: 2.1740668127613683

Epoch: 5| Step: 8
Training loss: 1.6048349142074585
Validation loss: 2.1853772773537585

Epoch: 5| Step: 9
Training loss: 1.4532123804092407
Validation loss: 2.159898619497976

Epoch: 5| Step: 10
Training loss: 1.7402280569076538
Validation loss: 2.188869498109305

Epoch: 425| Step: 0
Training loss: 1.67738938331604
Validation loss: 2.1713344640629266

Epoch: 5| Step: 1
Training loss: 1.575975775718689
Validation loss: 2.167064784675516

Epoch: 5| Step: 2
Training loss: 1.4191714525222778
Validation loss: 2.2452822821114653

Epoch: 5| Step: 3
Training loss: 1.4999282360076904
Validation loss: 2.216092432698896

Epoch: 5| Step: 4
Training loss: 1.747910737991333
Validation loss: 2.1427628865806003

Epoch: 5| Step: 5
Training loss: 2.0786070823669434
Validation loss: 2.112906494448262

Epoch: 5| Step: 6
Training loss: 1.624140977859497
Validation loss: 2.1195129168930875

Epoch: 5| Step: 7
Training loss: 2.1640546321868896
Validation loss: 2.105109827492827

Epoch: 5| Step: 8
Training loss: 1.1713736057281494
Validation loss: 2.186407446861267

Epoch: 5| Step: 9
Training loss: 1.3586328029632568
Validation loss: 2.0997921600136706

Epoch: 5| Step: 10
Training loss: 1.556452989578247
Validation loss: 2.1503965688008133

Epoch: 426| Step: 0
Training loss: 1.3225383758544922
Validation loss: 2.1198050232343775

Epoch: 5| Step: 1
Training loss: 1.9773247241973877
Validation loss: 2.1391851209825083

Epoch: 5| Step: 2
Training loss: 1.5531562566757202
Validation loss: 2.163012371268324

Epoch: 5| Step: 3
Training loss: 1.8523948192596436
Validation loss: 2.167132705770513

Epoch: 5| Step: 4
Training loss: 1.617612600326538
Validation loss: 2.1467450152161303

Epoch: 5| Step: 5
Training loss: 1.8052284717559814
Validation loss: 2.1143178862910115

Epoch: 5| Step: 6
Training loss: 1.571394681930542
Validation loss: 2.134694842882054

Epoch: 5| Step: 7
Training loss: 1.6900485754013062
Validation loss: 2.1699256986700077

Epoch: 5| Step: 8
Training loss: 1.8948882818222046
Validation loss: 2.192832634013186

Epoch: 5| Step: 9
Training loss: 1.1830365657806396
Validation loss: 2.206170053892238

Epoch: 5| Step: 10
Training loss: 1.8940640687942505
Validation loss: 2.1314047997997654

Epoch: 427| Step: 0
Training loss: 2.311258316040039
Validation loss: 2.140554015354444

Epoch: 5| Step: 1
Training loss: 1.605279564857483
Validation loss: 2.1791166849033807

Epoch: 5| Step: 2
Training loss: 1.5840047597885132
Validation loss: 2.1286484067158034

Epoch: 5| Step: 3
Training loss: 1.2099946737289429
Validation loss: 2.235632768241308

Epoch: 5| Step: 4
Training loss: 1.1519787311553955
Validation loss: 2.1861745106276644

Epoch: 5| Step: 5
Training loss: 1.7199795246124268
Validation loss: 2.15367631758413

Epoch: 5| Step: 6
Training loss: 1.3761367797851562
Validation loss: 2.1121187440810667

Epoch: 5| Step: 7
Training loss: 1.8003437519073486
Validation loss: 2.1784752030526437

Epoch: 5| Step: 8
Training loss: 2.0127034187316895
Validation loss: 2.099369882255472

Epoch: 5| Step: 9
Training loss: 2.0281572341918945
Validation loss: 2.0681050131397862

Epoch: 5| Step: 10
Training loss: 1.2330001592636108
Validation loss: 2.108816958242847

Epoch: 428| Step: 0
Training loss: 2.082435131072998
Validation loss: 2.178624500510513

Epoch: 5| Step: 1
Training loss: 2.2029755115509033
Validation loss: 2.209500507641864

Epoch: 5| Step: 2
Training loss: 1.5912219285964966
Validation loss: 2.048523485019643

Epoch: 5| Step: 3
Training loss: 2.0529026985168457
Validation loss: 2.1404979613519486

Epoch: 5| Step: 4
Training loss: 1.4016135931015015
Validation loss: 2.1761938141238306

Epoch: 5| Step: 5
Training loss: 1.6980845928192139
Validation loss: 2.1045294192529496

Epoch: 5| Step: 6
Training loss: 1.7983438968658447
Validation loss: 2.1521320881382113

Epoch: 5| Step: 7
Training loss: 1.2774438858032227
Validation loss: 2.1302776413579143

Epoch: 5| Step: 8
Training loss: 1.3677279949188232
Validation loss: 2.1995050650770946

Epoch: 5| Step: 9
Training loss: 0.933594822883606
Validation loss: 2.11437734224463

Epoch: 5| Step: 10
Training loss: 1.3916760683059692
Validation loss: 2.101733091056988

Epoch: 429| Step: 0
Training loss: 2.213505744934082
Validation loss: 2.09526349395834

Epoch: 5| Step: 1
Training loss: 1.8700335025787354
Validation loss: 2.1317404905954995

Epoch: 5| Step: 2
Training loss: 1.6190617084503174
Validation loss: 2.1265551121004167

Epoch: 5| Step: 3
Training loss: 1.3902238607406616
Validation loss: 2.1063151064739434

Epoch: 5| Step: 4
Training loss: 1.3952128887176514
Validation loss: 2.0996217625115507

Epoch: 5| Step: 5
Training loss: 1.495345115661621
Validation loss: 2.2088290388866136

Epoch: 5| Step: 6
Training loss: 1.3754825592041016
Validation loss: 2.1687423900891374

Epoch: 5| Step: 7
Training loss: 2.087657928466797
Validation loss: 2.130548962982752

Epoch: 5| Step: 8
Training loss: 1.6321613788604736
Validation loss: 2.0927309233655214

Epoch: 5| Step: 9
Training loss: 1.4579989910125732
Validation loss: 2.118741559725936

Epoch: 5| Step: 10
Training loss: 1.5931177139282227
Validation loss: 2.105621636554759

Epoch: 430| Step: 0
Training loss: 1.2161062955856323
Validation loss: 2.179421147992534

Epoch: 5| Step: 1
Training loss: 1.9673030376434326
Validation loss: 2.1208918812454387

Epoch: 5| Step: 2
Training loss: 1.4694896936416626
Validation loss: 2.0646527274962394

Epoch: 5| Step: 3
Training loss: 1.215355396270752
Validation loss: 2.180778311144921

Epoch: 5| Step: 4
Training loss: 1.851824402809143
Validation loss: 2.123618430988763

Epoch: 5| Step: 5
Training loss: 1.641789436340332
Validation loss: 2.126315857774468

Epoch: 5| Step: 6
Training loss: 2.615983724594116
Validation loss: 2.1740891625804286

Epoch: 5| Step: 7
Training loss: 2.1227447986602783
Validation loss: 2.1151607100681593

Epoch: 5| Step: 8
Training loss: 1.1838514804840088
Validation loss: 2.0862685685516684

Epoch: 5| Step: 9
Training loss: 1.5627353191375732
Validation loss: 2.1684038395522744

Epoch: 5| Step: 10
Training loss: 1.311627984046936
Validation loss: 2.1340355539834626

Epoch: 431| Step: 0
Training loss: 1.388073205947876
Validation loss: 2.1195042082058486

Epoch: 5| Step: 1
Training loss: 1.6566779613494873
Validation loss: 2.1715472513629543

Epoch: 5| Step: 2
Training loss: 1.5612618923187256
Validation loss: 2.0948560058429675

Epoch: 5| Step: 3
Training loss: 1.4748508930206299
Validation loss: 2.123467468446301

Epoch: 5| Step: 4
Training loss: 1.985438346862793
Validation loss: 2.1142451993880735

Epoch: 5| Step: 5
Training loss: 1.6130834817886353
Validation loss: 2.250123637978749

Epoch: 5| Step: 6
Training loss: 1.8027299642562866
Validation loss: 2.161857698553352

Epoch: 5| Step: 7
Training loss: 1.5756021738052368
Validation loss: 2.1685113394132225

Epoch: 5| Step: 8
Training loss: 2.011052370071411
Validation loss: 2.209467931460309

Epoch: 5| Step: 9
Training loss: 1.5762571096420288
Validation loss: 2.208154583490023

Epoch: 5| Step: 10
Training loss: 1.5594851970672607
Validation loss: 2.145856201007802

Epoch: 432| Step: 0
Training loss: 1.682415246963501
Validation loss: 2.0878127697975404

Epoch: 5| Step: 1
Training loss: 1.3381779193878174
Validation loss: 2.1536516989431074

Epoch: 5| Step: 2
Training loss: 1.6765377521514893
Validation loss: 2.2175616154106716

Epoch: 5| Step: 3
Training loss: 1.9725803136825562
Validation loss: 2.1461673654535764

Epoch: 5| Step: 4
Training loss: 1.3373931646347046
Validation loss: 2.146929564014558

Epoch: 5| Step: 5
Training loss: 1.7961009740829468
Validation loss: 2.1707600765330817

Epoch: 5| Step: 6
Training loss: 1.7236820459365845
Validation loss: 2.1203912663203415

Epoch: 5| Step: 7
Training loss: 1.5981435775756836
Validation loss: 2.077572782834371

Epoch: 5| Step: 8
Training loss: 1.4524487257003784
Validation loss: 2.087900161743164

Epoch: 5| Step: 9
Training loss: 1.634289026260376
Validation loss: 2.1189213363073205

Epoch: 5| Step: 10
Training loss: 1.5148371458053589
Validation loss: 2.151161350229735

Epoch: 433| Step: 0
Training loss: 1.5327856540679932
Validation loss: 2.0906340665714715

Epoch: 5| Step: 1
Training loss: 1.80548095703125
Validation loss: 2.1272275140208583

Epoch: 5| Step: 2
Training loss: 0.8772276043891907
Validation loss: 2.1757399266765964

Epoch: 5| Step: 3
Training loss: 1.3909581899642944
Validation loss: 2.099701096934657

Epoch: 5| Step: 4
Training loss: 2.0068440437316895
Validation loss: 2.1107257437962357

Epoch: 5| Step: 5
Training loss: 1.6726243495941162
Validation loss: 2.051316497146442

Epoch: 5| Step: 6
Training loss: 1.5668144226074219
Validation loss: 2.1418830886963875

Epoch: 5| Step: 7
Training loss: 1.7888290882110596
Validation loss: 2.1387860646811863

Epoch: 5| Step: 8
Training loss: 2.1821582317352295
Validation loss: 2.1415111454584266

Epoch: 5| Step: 9
Training loss: 1.3075917959213257
Validation loss: 2.1554238642415693

Epoch: 5| Step: 10
Training loss: 2.1726319789886475
Validation loss: 2.090416492954377

Epoch: 434| Step: 0
Training loss: 2.481111764907837
Validation loss: 2.230078289585729

Epoch: 5| Step: 1
Training loss: 1.5280420780181885
Validation loss: 2.1592108203518774

Epoch: 5| Step: 2
Training loss: 1.788722276687622
Validation loss: 2.1184148890997774

Epoch: 5| Step: 3
Training loss: 1.207163691520691
Validation loss: 2.1295654440438874

Epoch: 5| Step: 4
Training loss: 0.977713942527771
Validation loss: 2.1167791351195304

Epoch: 5| Step: 5
Training loss: 1.7903026342391968
Validation loss: 2.230471513604605

Epoch: 5| Step: 6
Training loss: 1.8274199962615967
Validation loss: 2.178149418164325

Epoch: 5| Step: 7
Training loss: 1.518024206161499
Validation loss: 2.1074884437745616

Epoch: 5| Step: 8
Training loss: 1.4506317377090454
Validation loss: 2.1574585540320284

Epoch: 5| Step: 9
Training loss: 2.068286895751953
Validation loss: 2.1673727138068086

Epoch: 5| Step: 10
Training loss: 1.309338927268982
Validation loss: 2.19836103018894

Epoch: 435| Step: 0
Training loss: 1.6411666870117188
Validation loss: 2.185724941633081

Epoch: 5| Step: 1
Training loss: 2.387396812438965
Validation loss: 2.1795901995833202

Epoch: 5| Step: 2
Training loss: 1.187808871269226
Validation loss: 2.185588791806211

Epoch: 5| Step: 3
Training loss: 1.5579187870025635
Validation loss: 2.1533337229041645

Epoch: 5| Step: 4
Training loss: 1.6158077716827393
Validation loss: 2.148903436558221

Epoch: 5| Step: 5
Training loss: 1.640825867652893
Validation loss: 2.104093569581227

Epoch: 5| Step: 6
Training loss: 1.6472867727279663
Validation loss: 2.128897210603119

Epoch: 5| Step: 7
Training loss: 1.8412595987319946
Validation loss: 2.1161055205970682

Epoch: 5| Step: 8
Training loss: 1.568040132522583
Validation loss: 2.151845916624992

Epoch: 5| Step: 9
Training loss: 1.6960569620132446
Validation loss: 2.1308774537937616

Epoch: 5| Step: 10
Training loss: 1.1822898387908936
Validation loss: 2.1853605495986117

Epoch: 436| Step: 0
Training loss: 1.6277707815170288
Validation loss: 2.0778933007230043

Epoch: 5| Step: 1
Training loss: 1.9783071279525757
Validation loss: 2.146688707413212

Epoch: 5| Step: 2
Training loss: 2.059192180633545
Validation loss: 2.1366418433445755

Epoch: 5| Step: 3
Training loss: 1.5604791641235352
Validation loss: 2.172994239355928

Epoch: 5| Step: 4
Training loss: 1.2559841871261597
Validation loss: 2.1688762326394357

Epoch: 5| Step: 5
Training loss: 1.922218680381775
Validation loss: 2.0844415772345757

Epoch: 5| Step: 6
Training loss: 1.745669960975647
Validation loss: 2.1522128953728625

Epoch: 5| Step: 7
Training loss: 1.1702383756637573
Validation loss: 2.242124693368071

Epoch: 5| Step: 8
Training loss: 2.164724826812744
Validation loss: 2.168550706678821

Epoch: 5| Step: 9
Training loss: 0.9905563592910767
Validation loss: 2.14816225728681

Epoch: 5| Step: 10
Training loss: 1.359800100326538
Validation loss: 2.153980549945626

Epoch: 437| Step: 0
Training loss: 1.372649908065796
Validation loss: 2.117358620448779

Epoch: 5| Step: 1
Training loss: 1.676727533340454
Validation loss: 2.060867530043407

Epoch: 5| Step: 2
Training loss: 1.2577108144760132
Validation loss: 2.155056820120863

Epoch: 5| Step: 3
Training loss: 1.4026813507080078
Validation loss: 2.0659023420785063

Epoch: 5| Step: 4
Training loss: 2.7410664558410645
Validation loss: 2.1775490904367096

Epoch: 5| Step: 5
Training loss: 1.9752118587493896
Validation loss: 2.1167165515243367

Epoch: 5| Step: 6
Training loss: 1.4052366018295288
Validation loss: 2.09361328617219

Epoch: 5| Step: 7
Training loss: 1.528751015663147
Validation loss: 2.163392215646723

Epoch: 5| Step: 8
Training loss: 1.798413872718811
Validation loss: 2.1543717204883532

Epoch: 5| Step: 9
Training loss: 1.2356226444244385
Validation loss: 2.141895758208408

Epoch: 5| Step: 10
Training loss: 1.2486646175384521
Validation loss: 2.156725720692706

Epoch: 438| Step: 0
Training loss: 1.6669600009918213
Validation loss: 2.178659890287666

Epoch: 5| Step: 1
Training loss: 1.991912841796875
Validation loss: 2.100807523214689

Epoch: 5| Step: 2
Training loss: 1.1208713054656982
Validation loss: 2.138127011637534

Epoch: 5| Step: 3
Training loss: 1.9008855819702148
Validation loss: 2.1036341985066733

Epoch: 5| Step: 4
Training loss: 1.4963091611862183
Validation loss: 2.1189179548653225

Epoch: 5| Step: 5
Training loss: 1.9327919483184814
Validation loss: 2.074809217965731

Epoch: 5| Step: 6
Training loss: 1.5853867530822754
Validation loss: 2.0791089906487414

Epoch: 5| Step: 7
Training loss: 1.8887430429458618
Validation loss: 2.079510437544956

Epoch: 5| Step: 8
Training loss: 1.470836877822876
Validation loss: 2.1605387836374264

Epoch: 5| Step: 9
Training loss: 1.392759919166565
Validation loss: 2.1197598365045365

Epoch: 5| Step: 10
Training loss: 1.4152650833129883
Validation loss: 2.010582621379565

Epoch: 439| Step: 0
Training loss: 1.5781283378601074
Validation loss: 2.08498453709387

Epoch: 5| Step: 1
Training loss: 1.5285093784332275
Validation loss: 2.21016965886598

Epoch: 5| Step: 2
Training loss: 1.8583885431289673
Validation loss: 2.1669833224306823

Epoch: 5| Step: 3
Training loss: 1.8760324716567993
Validation loss: 2.0830106940320743

Epoch: 5| Step: 4
Training loss: 2.421891212463379
Validation loss: 2.138623296573598

Epoch: 5| Step: 5
Training loss: 1.0174800157546997
Validation loss: 2.1738095744963615

Epoch: 5| Step: 6
Training loss: 1.6997854709625244
Validation loss: 2.1818335722851496

Epoch: 5| Step: 7
Training loss: 1.8053276538848877
Validation loss: 2.167660423504409

Epoch: 5| Step: 8
Training loss: 1.5561355352401733
Validation loss: 2.199887814060334

Epoch: 5| Step: 9
Training loss: 1.00597083568573
Validation loss: 2.1914913423599733

Epoch: 5| Step: 10
Training loss: 1.334345817565918
Validation loss: 2.125478850897922

Epoch: 440| Step: 0
Training loss: 1.4622446298599243
Validation loss: 2.190591537824241

Epoch: 5| Step: 1
Training loss: 1.5351307392120361
Validation loss: 2.1657478296628563

Epoch: 5| Step: 2
Training loss: 1.884310007095337
Validation loss: 2.1536396985412924

Epoch: 5| Step: 3
Training loss: 1.7641594409942627
Validation loss: 2.104750512748636

Epoch: 5| Step: 4
Training loss: 1.8358738422393799
Validation loss: 2.1103453225986932

Epoch: 5| Step: 5
Training loss: 1.4112131595611572
Validation loss: 2.209784168069081

Epoch: 5| Step: 6
Training loss: 1.7224104404449463
Validation loss: 2.0905147470453733

Epoch: 5| Step: 7
Training loss: 1.56307053565979
Validation loss: 2.18954409322431

Epoch: 5| Step: 8
Training loss: 1.6580028533935547
Validation loss: 2.1513247361747165

Epoch: 5| Step: 9
Training loss: 1.7373714447021484
Validation loss: 2.1860398015668316

Epoch: 5| Step: 10
Training loss: 1.2766506671905518
Validation loss: 2.119499603907267

Epoch: 441| Step: 0
Training loss: 1.9257047176361084
Validation loss: 2.1567408500179166

Epoch: 5| Step: 1
Training loss: 1.598935842514038
Validation loss: 2.1425744128483597

Epoch: 5| Step: 2
Training loss: 1.6387672424316406
Validation loss: 2.172823349634806

Epoch: 5| Step: 3
Training loss: 1.4563696384429932
Validation loss: 2.097548246383667

Epoch: 5| Step: 4
Training loss: 1.317262887954712
Validation loss: 2.136400966234105

Epoch: 5| Step: 5
Training loss: 1.4111990928649902
Validation loss: 2.143351726634528

Epoch: 5| Step: 6
Training loss: 1.6276254653930664
Validation loss: 2.1816198582290323

Epoch: 5| Step: 7
Training loss: 1.4358559846878052
Validation loss: 2.131701777058263

Epoch: 5| Step: 8
Training loss: 1.5673463344573975
Validation loss: 2.1559164703533216

Epoch: 5| Step: 9
Training loss: 1.5883989334106445
Validation loss: 2.1725676572451027

Epoch: 5| Step: 10
Training loss: 2.131143569946289
Validation loss: 2.1516074006275465

Epoch: 442| Step: 0
Training loss: 1.6298935413360596
Validation loss: 2.1431438025607856

Epoch: 5| Step: 1
Training loss: 1.8236652612686157
Validation loss: 2.1357077052516322

Epoch: 5| Step: 2
Training loss: 1.7984145879745483
Validation loss: 2.1728875713963665

Epoch: 5| Step: 3
Training loss: 1.2486613988876343
Validation loss: 2.1505226730018534

Epoch: 5| Step: 4
Training loss: 1.3246452808380127
Validation loss: 2.136672217358825

Epoch: 5| Step: 5
Training loss: 1.232591986656189
Validation loss: 2.1018161055862263

Epoch: 5| Step: 6
Training loss: 1.991529107093811
Validation loss: 2.139467500871228

Epoch: 5| Step: 7
Training loss: 1.5025269985198975
Validation loss: 2.205841533599361

Epoch: 5| Step: 8
Training loss: 1.3494104146957397
Validation loss: 2.2002266017339562

Epoch: 5| Step: 9
Training loss: 2.094839572906494
Validation loss: 2.117758421487706

Epoch: 5| Step: 10
Training loss: 1.3461389541625977
Validation loss: 2.1039026937177105

Epoch: 443| Step: 0
Training loss: 1.58797025680542
Validation loss: 2.099589496530512

Epoch: 5| Step: 1
Training loss: 1.32273268699646
Validation loss: 2.087171775038524

Epoch: 5| Step: 2
Training loss: 1.1972562074661255
Validation loss: 2.1034330655169744

Epoch: 5| Step: 3
Training loss: 2.165803909301758
Validation loss: 2.130043693768081

Epoch: 5| Step: 4
Training loss: 2.027833938598633
Validation loss: 2.125898507333571

Epoch: 5| Step: 5
Training loss: 1.6906509399414062
Validation loss: 2.0543931709822787

Epoch: 5| Step: 6
Training loss: 2.0348222255706787
Validation loss: 2.129401781225717

Epoch: 5| Step: 7
Training loss: 0.961765468120575
Validation loss: 2.1864435134395475

Epoch: 5| Step: 8
Training loss: 1.321439504623413
Validation loss: 2.149494173706219

Epoch: 5| Step: 9
Training loss: 1.463215947151184
Validation loss: 2.1183607296277116

Epoch: 5| Step: 10
Training loss: 1.7331405878067017
Validation loss: 2.1720715133092736

Epoch: 444| Step: 0
Training loss: 1.4435625076293945
Validation loss: 2.1341762440178984

Epoch: 5| Step: 1
Training loss: 2.3138318061828613
Validation loss: 2.1935143137490876

Epoch: 5| Step: 2
Training loss: 1.3720076084136963
Validation loss: 2.1104361267500025

Epoch: 5| Step: 3
Training loss: 1.5896066427230835
Validation loss: 2.0977857856340307

Epoch: 5| Step: 4
Training loss: 1.8334242105484009
Validation loss: 2.128589907000142

Epoch: 5| Step: 5
Training loss: 1.1798489093780518
Validation loss: 2.1640940507253013

Epoch: 5| Step: 6
Training loss: 1.6677078008651733
Validation loss: 2.1210783732834684

Epoch: 5| Step: 7
Training loss: 1.7771122455596924
Validation loss: 2.1135378294093634

Epoch: 5| Step: 8
Training loss: 1.7836906909942627
Validation loss: 2.135430371889504

Epoch: 5| Step: 9
Training loss: 1.4687466621398926
Validation loss: 2.1537856748027187

Epoch: 5| Step: 10
Training loss: 1.3134127855300903
Validation loss: 2.131195973324519

Epoch: 445| Step: 0
Training loss: 1.7285957336425781
Validation loss: 2.1686273749156664

Epoch: 5| Step: 1
Training loss: 1.8232533931732178
Validation loss: 2.1361056258601527

Epoch: 5| Step: 2
Training loss: 1.14811110496521
Validation loss: 2.1043580244946223

Epoch: 5| Step: 3
Training loss: 1.349853754043579
Validation loss: 2.1856064065810172

Epoch: 5| Step: 4
Training loss: 2.1694185733795166
Validation loss: 2.1485856399741223

Epoch: 5| Step: 5
Training loss: 1.9747593402862549
Validation loss: 2.1800578294261808

Epoch: 5| Step: 6
Training loss: 1.4999366998672485
Validation loss: 2.171182042808943

Epoch: 5| Step: 7
Training loss: 1.8504610061645508
Validation loss: 2.1948292537402083

Epoch: 5| Step: 8
Training loss: 1.488123893737793
Validation loss: 2.1302246047604467

Epoch: 5| Step: 9
Training loss: 1.3143646717071533
Validation loss: 2.19507925228406

Epoch: 5| Step: 10
Training loss: 1.1410984992980957
Validation loss: 2.1222085645121913

Epoch: 446| Step: 0
Training loss: 1.6207748651504517
Validation loss: 2.167354473503687

Epoch: 5| Step: 1
Training loss: 1.6733611822128296
Validation loss: 2.118769509817964

Epoch: 5| Step: 2
Training loss: 1.7631438970565796
Validation loss: 2.1474332373629332

Epoch: 5| Step: 3
Training loss: 1.9269959926605225
Validation loss: 2.1598035033031175

Epoch: 5| Step: 4
Training loss: 1.5200624465942383
Validation loss: 2.131341290730302

Epoch: 5| Step: 5
Training loss: 1.7481653690338135
Validation loss: 2.0349556348657094

Epoch: 5| Step: 6
Training loss: 1.229978322982788
Validation loss: 2.141593192213325

Epoch: 5| Step: 7
Training loss: 2.074265241622925
Validation loss: 2.065028470049622

Epoch: 5| Step: 8
Training loss: 1.385350227355957
Validation loss: 2.1157755890200214

Epoch: 5| Step: 9
Training loss: 1.3535938262939453
Validation loss: 2.109567843457704

Epoch: 5| Step: 10
Training loss: 0.9543472528457642
Validation loss: 2.14557844849043

Epoch: 447| Step: 0
Training loss: 1.6322314739227295
Validation loss: 2.1396954239055677

Epoch: 5| Step: 1
Training loss: 1.726387619972229
Validation loss: 2.1857218947461856

Epoch: 5| Step: 2
Training loss: 1.1578502655029297
Validation loss: 2.09890398158822

Epoch: 5| Step: 3
Training loss: 2.098832368850708
Validation loss: 2.0327654948798557

Epoch: 5| Step: 4
Training loss: 1.8406264781951904
Validation loss: 2.145447643854285

Epoch: 5| Step: 5
Training loss: 1.340453863143921
Validation loss: 2.105995906296597

Epoch: 5| Step: 6
Training loss: 1.7617099285125732
Validation loss: 2.167354263285155

Epoch: 5| Step: 7
Training loss: 1.6238048076629639
Validation loss: 2.0924957875282533

Epoch: 5| Step: 8
Training loss: 1.6499607563018799
Validation loss: 2.140672800361469

Epoch: 5| Step: 9
Training loss: 1.3079208135604858
Validation loss: 2.131662325192523

Epoch: 5| Step: 10
Training loss: 1.4181746244430542
Validation loss: 2.1725417324291763

Epoch: 448| Step: 0
Training loss: 1.8628342151641846
Validation loss: 2.0835458476056337

Epoch: 5| Step: 1
Training loss: 1.4288564920425415
Validation loss: 2.180492208849999

Epoch: 5| Step: 2
Training loss: 1.4254615306854248
Validation loss: 2.1277183858297204

Epoch: 5| Step: 3
Training loss: 0.9482135772705078
Validation loss: 2.164567547459756

Epoch: 5| Step: 4
Training loss: 2.214273452758789
Validation loss: 2.115857160219582

Epoch: 5| Step: 5
Training loss: 1.2189397811889648
Validation loss: 2.20584632760735

Epoch: 5| Step: 6
Training loss: 1.9690723419189453
Validation loss: 2.1229923925092145

Epoch: 5| Step: 7
Training loss: 1.6658293008804321
Validation loss: 2.113845148394185

Epoch: 5| Step: 8
Training loss: 1.681318998336792
Validation loss: 2.191313964064403

Epoch: 5| Step: 9
Training loss: 1.7352640628814697
Validation loss: 2.17593022828461

Epoch: 5| Step: 10
Training loss: 1.8745536804199219
Validation loss: 2.219196855380971

Epoch: 449| Step: 0
Training loss: 1.8138033151626587
Validation loss: 2.1494514839623564

Epoch: 5| Step: 1
Training loss: 1.0866045951843262
Validation loss: 2.1933626333872476

Epoch: 5| Step: 2
Training loss: 1.728713035583496
Validation loss: 2.21430710054213

Epoch: 5| Step: 3
Training loss: 1.247866153717041
Validation loss: 2.1379773898791243

Epoch: 5| Step: 4
Training loss: 1.5968927145004272
Validation loss: 2.1526721946654783

Epoch: 5| Step: 5
Training loss: 1.5192151069641113
Validation loss: 2.1687953882319952

Epoch: 5| Step: 6
Training loss: 1.4976272583007812
Validation loss: 2.1097675882359987

Epoch: 5| Step: 7
Training loss: 2.370330572128296
Validation loss: 2.124108570878224

Epoch: 5| Step: 8
Training loss: 1.2905170917510986
Validation loss: 2.0896894495974303

Epoch: 5| Step: 9
Training loss: 1.6066595315933228
Validation loss: 2.1099250726802374

Epoch: 5| Step: 10
Training loss: 1.643153429031372
Validation loss: 2.181495253757764

Epoch: 450| Step: 0
Training loss: 1.6056636571884155
Validation loss: 2.166999782285383

Epoch: 5| Step: 1
Training loss: 1.8175084590911865
Validation loss: 2.1593675485221286

Epoch: 5| Step: 2
Training loss: 1.4291024208068848
Validation loss: 2.1281215157560123

Epoch: 5| Step: 3
Training loss: 1.3979136943817139
Validation loss: 2.1684754484443256

Epoch: 5| Step: 4
Training loss: 2.379636287689209
Validation loss: 2.1754287007034465

Epoch: 5| Step: 5
Training loss: 1.472671389579773
Validation loss: 2.089142891668504

Epoch: 5| Step: 6
Training loss: 1.6760156154632568
Validation loss: 2.1361356396828928

Epoch: 5| Step: 7
Training loss: 1.4146074056625366
Validation loss: 2.144056515027118

Epoch: 5| Step: 8
Training loss: 1.1462863683700562
Validation loss: 2.154863465216852

Epoch: 5| Step: 9
Training loss: 1.7392886877059937
Validation loss: 2.1517201469790552

Epoch: 5| Step: 10
Training loss: 1.6912516355514526
Validation loss: 2.116335925235543

Testing loss: 2.2941965659459433
