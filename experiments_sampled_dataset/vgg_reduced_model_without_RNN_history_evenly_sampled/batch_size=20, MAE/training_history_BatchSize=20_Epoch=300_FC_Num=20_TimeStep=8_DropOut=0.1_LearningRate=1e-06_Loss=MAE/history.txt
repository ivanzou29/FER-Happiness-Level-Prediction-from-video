Epoch: 1| Step: 0
Training loss: 5.230545997619629
Validation loss: 5.588558909713581

Epoch: 5| Step: 1
Training loss: 5.712575435638428
Validation loss: 5.583029695736465

Epoch: 5| Step: 2
Training loss: 5.1601243019104
Validation loss: 5.576662807054417

Epoch: 5| Step: 3
Training loss: 5.302685260772705
Validation loss: 5.57462263620028

Epoch: 5| Step: 4
Training loss: 5.6665730476379395
Validation loss: 5.569302461480581

Epoch: 5| Step: 5
Training loss: 6.011852741241455
Validation loss: 5.562043389966411

Epoch: 5| Step: 6
Training loss: 4.724469184875488
Validation loss: 5.559639479524346

Epoch: 5| Step: 7
Training loss: 5.4105963706970215
Validation loss: 5.55351581368395

Epoch: 5| Step: 8
Training loss: 5.5239996910095215
Validation loss: 5.551782525995726

Epoch: 5| Step: 9
Training loss: 5.363810062408447
Validation loss: 5.545434782581944

Epoch: 5| Step: 10
Training loss: 4.757322311401367
Validation loss: 5.542422017743511

Epoch: 2| Step: 0
Training loss: 6.520047187805176
Validation loss: 5.536089774101011

Epoch: 5| Step: 1
Training loss: 6.29159688949585
Validation loss: 5.531835356066304

Epoch: 5| Step: 2
Training loss: 4.564037322998047
Validation loss: 5.530251559390817

Epoch: 5| Step: 3
Training loss: 4.669567108154297
Validation loss: 5.521754228940574

Epoch: 5| Step: 4
Training loss: 4.453916549682617
Validation loss: 5.518868395077285

Epoch: 5| Step: 5
Training loss: 5.5367112159729
Validation loss: 5.510634094156245

Epoch: 5| Step: 6
Training loss: 3.7436280250549316
Validation loss: 5.50608326286398

Epoch: 5| Step: 7
Training loss: 5.450345516204834
Validation loss: 5.50281137035739

Epoch: 5| Step: 8
Training loss: 6.647080898284912
Validation loss: 5.500546363092238

Epoch: 5| Step: 9
Training loss: 5.532410144805908
Validation loss: 5.491000375440044

Epoch: 5| Step: 10
Training loss: 4.857870578765869
Validation loss: 5.484287144035421

Epoch: 3| Step: 0
Training loss: 4.4137163162231445
Validation loss: 5.480415939002909

Epoch: 5| Step: 1
Training loss: 5.328644752502441
Validation loss: 5.476588926007671

Epoch: 5| Step: 2
Training loss: 5.068781852722168
Validation loss: 5.468384901682536

Epoch: 5| Step: 3
Training loss: 4.892989635467529
Validation loss: 5.463966267083281

Epoch: 5| Step: 4
Training loss: 5.150143146514893
Validation loss: 5.456369138533069

Epoch: 5| Step: 5
Training loss: 5.741837501525879
Validation loss: 5.4538447882539485

Epoch: 5| Step: 6
Training loss: 5.063940525054932
Validation loss: 5.447017321022608

Epoch: 5| Step: 7
Training loss: 5.387538433074951
Validation loss: 5.438975872532014

Epoch: 5| Step: 8
Training loss: 6.1622209548950195
Validation loss: 5.433563406749438

Epoch: 5| Step: 9
Training loss: 6.005197525024414
Validation loss: 5.428902815747005

Epoch: 5| Step: 10
Training loss: 4.315624237060547
Validation loss: 5.421455624283001

Epoch: 4| Step: 0
Training loss: 5.243322849273682
Validation loss: 5.416798740304927

Epoch: 5| Step: 1
Training loss: 4.574962139129639
Validation loss: 5.410503305414672

Epoch: 5| Step: 2
Training loss: 5.3679304122924805
Validation loss: 5.40415483392695

Epoch: 5| Step: 3
Training loss: 4.363387107849121
Validation loss: 5.397127735999323

Epoch: 5| Step: 4
Training loss: 5.942447662353516
Validation loss: 5.388441588288995

Epoch: 5| Step: 5
Training loss: 6.355530738830566
Validation loss: 5.38474553631198

Epoch: 5| Step: 6
Training loss: 5.102638244628906
Validation loss: 5.376673962480279

Epoch: 5| Step: 7
Training loss: 4.828814506530762
Validation loss: 5.373576584682669

Epoch: 5| Step: 8
Training loss: 5.339420795440674
Validation loss: 5.3682956387919765

Epoch: 5| Step: 9
Training loss: 4.5722808837890625
Validation loss: 5.3573878452342045

Epoch: 5| Step: 10
Training loss: 5.212841033935547
Validation loss: 5.354379433457569

Epoch: 5| Step: 0
Training loss: 5.808049201965332
Validation loss: 5.344016393025716

Epoch: 5| Step: 1
Training loss: 4.692648887634277
Validation loss: 5.337856610616048

Epoch: 5| Step: 2
Training loss: 4.7178497314453125
Validation loss: 5.330943148623231

Epoch: 5| Step: 3
Training loss: 5.2820611000061035
Validation loss: 5.330265937312957

Epoch: 5| Step: 4
Training loss: 4.553404808044434
Validation loss: 5.321646280186151

Epoch: 5| Step: 5
Training loss: 4.033387660980225
Validation loss: 5.313707443975633

Epoch: 5| Step: 6
Training loss: 5.6879377365112305
Validation loss: 5.309392939331711

Epoch: 5| Step: 7
Training loss: 5.547787666320801
Validation loss: 5.301243700006957

Epoch: 5| Step: 8
Training loss: 5.262389183044434
Validation loss: 5.291679771997595

Epoch: 5| Step: 9
Training loss: 5.318292140960693
Validation loss: 5.284965792009907

Epoch: 5| Step: 10
Training loss: 5.189723968505859
Validation loss: 5.276585845537083

Epoch: 6| Step: 0
Training loss: 4.880524635314941
Validation loss: 5.269119929241878

Epoch: 5| Step: 1
Training loss: 6.28750467300415
Validation loss: 5.262941750147009

Epoch: 5| Step: 2
Training loss: 5.410037994384766
Validation loss: 5.253706957704278

Epoch: 5| Step: 3
Training loss: 5.663018703460693
Validation loss: 5.251230701323478

Epoch: 5| Step: 4
Training loss: 4.4365692138671875
Validation loss: 5.244298458099365

Epoch: 5| Step: 5
Training loss: 4.829162120819092
Validation loss: 5.236399424973355

Epoch: 5| Step: 6
Training loss: 3.6636962890625
Validation loss: 5.227294501437936

Epoch: 5| Step: 7
Training loss: 4.67102575302124
Validation loss: 5.220924582532657

Epoch: 5| Step: 8
Training loss: 4.862497806549072
Validation loss: 5.210499476361019

Epoch: 5| Step: 9
Training loss: 5.359204292297363
Validation loss: 5.207128863180837

Epoch: 5| Step: 10
Training loss: 5.173702239990234
Validation loss: 5.195692949397589

Epoch: 7| Step: 0
Training loss: 4.512775421142578
Validation loss: 5.192274426901212

Epoch: 5| Step: 1
Training loss: 5.360620021820068
Validation loss: 5.181912550362208

Epoch: 5| Step: 2
Training loss: 5.2848029136657715
Validation loss: 5.17701736060522

Epoch: 5| Step: 3
Training loss: 5.275030612945557
Validation loss: 5.163485296310917

Epoch: 5| Step: 4
Training loss: 5.533207416534424
Validation loss: 5.156997665282218

Epoch: 5| Step: 5
Training loss: 4.879937648773193
Validation loss: 5.156247656832459

Epoch: 5| Step: 6
Training loss: 5.065340518951416
Validation loss: 5.14162653235979

Epoch: 5| Step: 7
Training loss: 4.775899410247803
Validation loss: 5.131919645494031

Epoch: 5| Step: 8
Training loss: 3.4936001300811768
Validation loss: 5.127440606394122

Epoch: 5| Step: 9
Training loss: 4.917015552520752
Validation loss: 5.115753860883816

Epoch: 5| Step: 10
Training loss: 5.203092575073242
Validation loss: 5.1080331135821595

Epoch: 8| Step: 0
Training loss: 4.245282173156738
Validation loss: 5.1016101990976646

Epoch: 5| Step: 1
Training loss: 5.016938209533691
Validation loss: 5.090495232612856

Epoch: 5| Step: 2
Training loss: 5.484616756439209
Validation loss: 5.085291985542543

Epoch: 5| Step: 3
Training loss: 4.845710754394531
Validation loss: 5.07786496480306

Epoch: 5| Step: 4
Training loss: 4.045605659484863
Validation loss: 5.06550605322725

Epoch: 5| Step: 5
Training loss: 4.709563255310059
Validation loss: 5.054948770871726

Epoch: 5| Step: 6
Training loss: 6.105038166046143
Validation loss: 5.048561752483409

Epoch: 5| Step: 7
Training loss: 5.455528736114502
Validation loss: 5.038587436881117

Epoch: 5| Step: 8
Training loss: 4.791184425354004
Validation loss: 5.030311656254594

Epoch: 5| Step: 9
Training loss: 4.024448394775391
Validation loss: 5.018544976429273

Epoch: 5| Step: 10
Training loss: 4.45087194442749
Validation loss: 5.012646587946081

Epoch: 9| Step: 0
Training loss: 4.27374267578125
Validation loss: 5.005242839936288

Epoch: 5| Step: 1
Training loss: 5.237513065338135
Validation loss: 4.995165942817606

Epoch: 5| Step: 2
Training loss: 5.563023090362549
Validation loss: 4.983152210071522

Epoch: 5| Step: 3
Training loss: 4.967623710632324
Validation loss: 4.9772571081756265

Epoch: 5| Step: 4
Training loss: 4.660317897796631
Validation loss: 4.966053772998112

Epoch: 5| Step: 5
Training loss: 5.229503631591797
Validation loss: 4.954589556622249

Epoch: 5| Step: 6
Training loss: 4.809592247009277
Validation loss: 4.949923546083512

Epoch: 5| Step: 7
Training loss: 4.215904712677002
Validation loss: 4.934110180024178

Epoch: 5| Step: 8
Training loss: 3.9519851207733154
Validation loss: 4.923854679189702

Epoch: 5| Step: 9
Training loss: 4.014822959899902
Validation loss: 4.913732687632243

Epoch: 5| Step: 10
Training loss: 5.2161149978637695
Validation loss: 4.903449801988499

Epoch: 10| Step: 0
Training loss: 5.340951442718506
Validation loss: 4.892672661812075

Epoch: 5| Step: 1
Training loss: 5.116159915924072
Validation loss: 4.884039560953776

Epoch: 5| Step: 2
Training loss: 4.495922088623047
Validation loss: 4.869068545679892

Epoch: 5| Step: 3
Training loss: 3.587207078933716
Validation loss: 4.856242313179918

Epoch: 5| Step: 4
Training loss: 4.148497581481934
Validation loss: 4.850604195748606

Epoch: 5| Step: 5
Training loss: 3.825268507003784
Validation loss: 4.841330594913934

Epoch: 5| Step: 6
Training loss: 4.332371234893799
Validation loss: 4.829927147075694

Epoch: 5| Step: 7
Training loss: 4.974399566650391
Validation loss: 4.814710240210256

Epoch: 5| Step: 8
Training loss: 5.020057201385498
Validation loss: 4.805781590041294

Epoch: 5| Step: 9
Training loss: 4.779225826263428
Validation loss: 4.791854694325437

Epoch: 5| Step: 10
Training loss: 5.293354034423828
Validation loss: 4.782688597197174

Epoch: 11| Step: 0
Training loss: 4.939724922180176
Validation loss: 4.77006031364523

Epoch: 5| Step: 1
Training loss: 4.7548933029174805
Validation loss: 4.753295708728093

Epoch: 5| Step: 2
Training loss: 3.334416151046753
Validation loss: 4.745384667509345

Epoch: 5| Step: 3
Training loss: 5.429526329040527
Validation loss: 4.737937101753809

Epoch: 5| Step: 4
Training loss: 4.224175453186035
Validation loss: 4.717916570683961

Epoch: 5| Step: 5
Training loss: 4.563904762268066
Validation loss: 4.705850206395631

Epoch: 5| Step: 6
Training loss: 3.4997527599334717
Validation loss: 4.693077528348533

Epoch: 5| Step: 7
Training loss: 4.35756778717041
Validation loss: 4.683958858572026

Epoch: 5| Step: 8
Training loss: 4.363196849822998
Validation loss: 4.667943159739177

Epoch: 5| Step: 9
Training loss: 5.032004356384277
Validation loss: 4.652354573690763

Epoch: 5| Step: 10
Training loss: 4.843600749969482
Validation loss: 4.642203146411527

Epoch: 12| Step: 0
Training loss: 5.047897815704346
Validation loss: 4.627730979714342

Epoch: 5| Step: 1
Training loss: 3.640995740890503
Validation loss: 4.6185038576843915

Epoch: 5| Step: 2
Training loss: 4.754260063171387
Validation loss: 4.601035656467561

Epoch: 5| Step: 3
Training loss: 3.656637191772461
Validation loss: 4.591438657494002

Epoch: 5| Step: 4
Training loss: 4.257837772369385
Validation loss: 4.5703171478804725

Epoch: 5| Step: 5
Training loss: 3.603619337081909
Validation loss: 4.5546126058024745

Epoch: 5| Step: 6
Training loss: 4.664621829986572
Validation loss: 4.5380705710380305

Epoch: 5| Step: 7
Training loss: 3.531790256500244
Validation loss: 4.5246093914073

Epoch: 5| Step: 8
Training loss: 6.1641340255737305
Validation loss: 4.512491846597323

Epoch: 5| Step: 9
Training loss: 3.8242290019989014
Validation loss: 4.495824060132427

Epoch: 5| Step: 10
Training loss: 4.407290458679199
Validation loss: 4.478636341710245

Epoch: 13| Step: 0
Training loss: 4.472878456115723
Validation loss: 4.467865708053753

Epoch: 5| Step: 1
Training loss: 4.281776428222656
Validation loss: 4.445643527533418

Epoch: 5| Step: 2
Training loss: 3.599611759185791
Validation loss: 4.436340885777628

Epoch: 5| Step: 3
Training loss: 4.227075576782227
Validation loss: 4.40950729000953

Epoch: 5| Step: 4
Training loss: 4.413791656494141
Validation loss: 4.405635751703734

Epoch: 5| Step: 5
Training loss: 4.770504951477051
Validation loss: 4.384656683091195

Epoch: 5| Step: 6
Training loss: 3.6585211753845215
Validation loss: 4.3650958204782135

Epoch: 5| Step: 7
Training loss: 3.617288112640381
Validation loss: 4.356365003893452

Epoch: 5| Step: 8
Training loss: 4.0562543869018555
Validation loss: 4.3326897621154785

Epoch: 5| Step: 9
Training loss: 4.42842960357666
Validation loss: 4.320043425406179

Epoch: 5| Step: 10
Training loss: 4.193667888641357
Validation loss: 4.296452147986299

Epoch: 14| Step: 0
Training loss: 4.471848487854004
Validation loss: 4.278980588400236

Epoch: 5| Step: 1
Training loss: 4.630821228027344
Validation loss: 4.268644553358837

Epoch: 5| Step: 2
Training loss: 4.640829563140869
Validation loss: 4.251404326449158

Epoch: 5| Step: 3
Training loss: 4.602430820465088
Validation loss: 4.2253669692624

Epoch: 5| Step: 4
Training loss: 3.3737683296203613
Validation loss: 4.209711808030323

Epoch: 5| Step: 5
Training loss: 3.8684310913085938
Validation loss: 4.190279565831666

Epoch: 5| Step: 6
Training loss: 3.8254482746124268
Validation loss: 4.169709769628382

Epoch: 5| Step: 7
Training loss: 3.8124377727508545
Validation loss: 4.156507922757056

Epoch: 5| Step: 8
Training loss: 2.3667500019073486
Validation loss: 4.140703019275461

Epoch: 5| Step: 9
Training loss: 4.049962043762207
Validation loss: 4.114684468956404

Epoch: 5| Step: 10
Training loss: 4.290144443511963
Validation loss: 4.095676022191202

Epoch: 15| Step: 0
Training loss: 3.881488084793091
Validation loss: 4.074210853986843

Epoch: 5| Step: 1
Training loss: 3.595489025115967
Validation loss: 4.059919244499617

Epoch: 5| Step: 2
Training loss: 4.584623336791992
Validation loss: 4.045515691080401

Epoch: 5| Step: 3
Training loss: 4.061888694763184
Validation loss: 4.029979290500764

Epoch: 5| Step: 4
Training loss: 3.729989528656006
Validation loss: 4.001900493457753

Epoch: 5| Step: 5
Training loss: 3.787972927093506
Validation loss: 3.9960036918681157

Epoch: 5| Step: 6
Training loss: 4.7924017906188965
Validation loss: 3.9755743652261715

Epoch: 5| Step: 7
Training loss: 3.4348998069763184
Validation loss: 3.947385957164149

Epoch: 5| Step: 8
Training loss: 3.3994979858398438
Validation loss: 3.93921563958609

Epoch: 5| Step: 9
Training loss: 3.6925454139709473
Validation loss: 3.9201424865312475

Epoch: 5| Step: 10
Training loss: 2.861929416656494
Validation loss: 3.8953888647017942

Epoch: 16| Step: 0
Training loss: 3.700794219970703
Validation loss: 3.8753165327092653

Epoch: 5| Step: 1
Training loss: 4.191149711608887
Validation loss: 3.8655155858685895

Epoch: 5| Step: 2
Training loss: 2.5613460540771484
Validation loss: 3.8399110250575568

Epoch: 5| Step: 3
Training loss: 4.101228713989258
Validation loss: 3.8173361080949024

Epoch: 5| Step: 4
Training loss: 4.7315673828125
Validation loss: 3.8170088286040933

Epoch: 5| Step: 5
Training loss: 3.5743446350097656
Validation loss: 3.7908016738071235

Epoch: 5| Step: 6
Training loss: 3.7544219493865967
Validation loss: 3.762624817509805

Epoch: 5| Step: 7
Training loss: 3.4476654529571533
Validation loss: 3.747577844127532

Epoch: 5| Step: 8
Training loss: 2.4954264163970947
Validation loss: 3.7320857714581233

Epoch: 5| Step: 9
Training loss: 4.1765336990356445
Validation loss: 3.7046126498970935

Epoch: 5| Step: 10
Training loss: 3.367858409881592
Validation loss: 3.680823859348092

Epoch: 17| Step: 0
Training loss: 3.564962863922119
Validation loss: 3.6803764861117125

Epoch: 5| Step: 1
Training loss: 2.9090137481689453
Validation loss: 3.6543531084573395

Epoch: 5| Step: 2
Training loss: 2.917910099029541
Validation loss: 3.640354064203078

Epoch: 5| Step: 3
Training loss: 3.0220046043395996
Validation loss: 3.610861934641356

Epoch: 5| Step: 4
Training loss: 4.854502201080322
Validation loss: 3.598754305993357

Epoch: 5| Step: 5
Training loss: 4.672191143035889
Validation loss: 3.577421106317992

Epoch: 5| Step: 6
Training loss: 3.1057190895080566
Validation loss: 3.5550131105607554

Epoch: 5| Step: 7
Training loss: 3.7952332496643066
Validation loss: 3.536048012395059

Epoch: 5| Step: 8
Training loss: 2.8303470611572266
Validation loss: 3.52531478481908

Epoch: 5| Step: 9
Training loss: 3.151059627532959
Validation loss: 3.4960046891243226

Epoch: 5| Step: 10
Training loss: 3.2126805782318115
Validation loss: 3.474167231590517

Epoch: 18| Step: 0
Training loss: 3.899282932281494
Validation loss: 3.4459461704377206

Epoch: 5| Step: 1
Training loss: 2.6405856609344482
Validation loss: 3.428901077598654

Epoch: 5| Step: 2
Training loss: 3.8968727588653564
Validation loss: 3.4092301322567846

Epoch: 5| Step: 3
Training loss: 4.069462776184082
Validation loss: 3.3767178802080053

Epoch: 5| Step: 4
Training loss: 3.742955446243286
Validation loss: 3.3691634926744687

Epoch: 5| Step: 5
Training loss: 2.582083225250244
Validation loss: 3.347722663674303

Epoch: 5| Step: 6
Training loss: 2.5704097747802734
Validation loss: 3.316149286044541

Epoch: 5| Step: 7
Training loss: 3.9285683631896973
Validation loss: 3.3003651967612644

Epoch: 5| Step: 8
Training loss: 2.9139761924743652
Validation loss: 3.271692701565322

Epoch: 5| Step: 9
Training loss: 2.958266496658325
Validation loss: 3.2515012448833835

Epoch: 5| Step: 10
Training loss: 2.864990472793579
Validation loss: 3.2327128943576606

Epoch: 19| Step: 0
Training loss: 3.2940564155578613
Validation loss: 3.210947190561602

Epoch: 5| Step: 1
Training loss: 2.7853195667266846
Validation loss: 3.1969357382866646

Epoch: 5| Step: 2
Training loss: 3.464275360107422
Validation loss: 3.178934592072682

Epoch: 5| Step: 3
Training loss: 3.231921672821045
Validation loss: 3.141549656468053

Epoch: 5| Step: 4
Training loss: 2.6005024909973145
Validation loss: 3.1423070789665304

Epoch: 5| Step: 5
Training loss: 3.4043326377868652
Validation loss: 3.137782194281137

Epoch: 5| Step: 6
Training loss: 2.9106884002685547
Validation loss: 3.1023957062793035

Epoch: 5| Step: 7
Training loss: 3.0769007205963135
Validation loss: 3.0849871173981698

Epoch: 5| Step: 8
Training loss: 3.5315799713134766
Validation loss: 3.0705711303218717

Epoch: 5| Step: 9
Training loss: 2.925499677658081
Validation loss: 3.059123128973028

Epoch: 5| Step: 10
Training loss: 2.9032764434814453
Validation loss: 3.018959068482922

Epoch: 20| Step: 0
Training loss: 3.6166725158691406
Validation loss: 3.0112602915815128

Epoch: 5| Step: 1
Training loss: 2.7924957275390625
Validation loss: 2.985986066120927

Epoch: 5| Step: 2
Training loss: 3.582904815673828
Validation loss: 2.9620668426636727

Epoch: 5| Step: 3
Training loss: 2.4551174640655518
Validation loss: 2.9465651589055217

Epoch: 5| Step: 4
Training loss: 2.964794397354126
Validation loss: 2.9321907592076126

Epoch: 5| Step: 5
Training loss: 2.934046506881714
Validation loss: 2.9139590724822013

Epoch: 5| Step: 6
Training loss: 3.2061238288879395
Validation loss: 2.894946849474343

Epoch: 5| Step: 7
Training loss: 3.179373264312744
Validation loss: 2.864593182840655

Epoch: 5| Step: 8
Training loss: 2.2249488830566406
Validation loss: 2.8346661752270115

Epoch: 5| Step: 9
Training loss: 2.4718246459960938
Validation loss: 2.835613730133221

Epoch: 5| Step: 10
Training loss: 3.245393753051758
Validation loss: 2.809193226598924

Epoch: 21| Step: 0
Training loss: 3.199371814727783
Validation loss: 2.7935230783236924

Epoch: 5| Step: 1
Training loss: 2.4878883361816406
Validation loss: 2.7916110484830794

Epoch: 5| Step: 2
Training loss: 3.361193895339966
Validation loss: 2.757944145510274

Epoch: 5| Step: 3
Training loss: 2.6222832202911377
Validation loss: 2.736692351679648

Epoch: 5| Step: 4
Training loss: 2.110034227371216
Validation loss: 2.7192250067187893

Epoch: 5| Step: 5
Training loss: 2.837939500808716
Validation loss: 2.7096387237630863

Epoch: 5| Step: 6
Training loss: 3.37229585647583
Validation loss: 2.692513447935863

Epoch: 5| Step: 7
Training loss: 3.1667728424072266
Validation loss: 2.6916462785454205

Epoch: 5| Step: 8
Training loss: 2.6399741172790527
Validation loss: 2.6537675780634724

Epoch: 5| Step: 9
Training loss: 2.95483136177063
Validation loss: 2.640265252000542

Epoch: 5| Step: 10
Training loss: 2.2703609466552734
Validation loss: 2.624706076037499

Epoch: 22| Step: 0
Training loss: 2.9584808349609375
Validation loss: 2.6151593064749115

Epoch: 5| Step: 1
Training loss: 2.81929612159729
Validation loss: 2.6009389508155083

Epoch: 5| Step: 2
Training loss: 2.5399577617645264
Validation loss: 2.5854792543636855

Epoch: 5| Step: 3
Training loss: 2.808556079864502
Validation loss: 2.545540095657431

Epoch: 5| Step: 4
Training loss: 2.183882474899292
Validation loss: 2.54580020904541

Epoch: 5| Step: 5
Training loss: 3.303499698638916
Validation loss: 2.5268161553208546

Epoch: 5| Step: 6
Training loss: 2.7222042083740234
Validation loss: 2.5297315607788744

Epoch: 5| Step: 7
Training loss: 2.6792397499084473
Validation loss: 2.508258088942497

Epoch: 5| Step: 8
Training loss: 2.9111320972442627
Validation loss: 2.4986408295169955

Epoch: 5| Step: 9
Training loss: 2.408435821533203
Validation loss: 2.46967908131179

Epoch: 5| Step: 10
Training loss: 2.2568116188049316
Validation loss: 2.445733142155473

Epoch: 23| Step: 0
Training loss: 2.503260374069214
Validation loss: 2.4289121781626055

Epoch: 5| Step: 1
Training loss: 2.7437846660614014
Validation loss: 2.4318364230535363

Epoch: 5| Step: 2
Training loss: 2.7203595638275146
Validation loss: 2.3855449640622703

Epoch: 5| Step: 3
Training loss: 2.6703567504882812
Validation loss: 2.4040863283218874

Epoch: 5| Step: 4
Training loss: 2.6280860900878906
Validation loss: 2.386078057750579

Epoch: 5| Step: 5
Training loss: 1.95488703250885
Validation loss: 2.345998138509771

Epoch: 5| Step: 6
Training loss: 3.075582981109619
Validation loss: 2.3568374649170907

Epoch: 5| Step: 7
Training loss: 2.419797658920288
Validation loss: 2.336907561107348

Epoch: 5| Step: 8
Training loss: 2.630796194076538
Validation loss: 2.328974093160322

Epoch: 5| Step: 9
Training loss: 2.7603471279144287
Validation loss: 2.3259962015254523

Epoch: 5| Step: 10
Training loss: 2.255358934402466
Validation loss: 2.314572872654084

Epoch: 24| Step: 0
Training loss: 1.7380542755126953
Validation loss: 2.2932269970575967

Epoch: 5| Step: 1
Training loss: 2.519625663757324
Validation loss: 2.2843592820628995

Epoch: 5| Step: 2
Training loss: 2.3919625282287598
Validation loss: 2.283402471132176

Epoch: 5| Step: 3
Training loss: 2.520050525665283
Validation loss: 2.2802619216262654

Epoch: 5| Step: 4
Training loss: 2.151895046234131
Validation loss: 2.259217467359317

Epoch: 5| Step: 5
Training loss: 3.0269248485565186
Validation loss: 2.2702951162092146

Epoch: 5| Step: 6
Training loss: 2.7994585037231445
Validation loss: 2.2506089902693227

Epoch: 5| Step: 7
Training loss: 2.36836314201355
Validation loss: 2.233579389510616

Epoch: 5| Step: 8
Training loss: 2.156698226928711
Validation loss: 2.2414400551908757

Epoch: 5| Step: 9
Training loss: 2.8816800117492676
Validation loss: 2.240956119311753

Epoch: 5| Step: 10
Training loss: 2.9704341888427734
Validation loss: 2.235502358405821

Epoch: 25| Step: 0
Training loss: 2.8557372093200684
Validation loss: 2.233371696164531

Epoch: 5| Step: 1
Training loss: 1.863623857498169
Validation loss: 2.2108050648884108

Epoch: 5| Step: 2
Training loss: 1.9279375076293945
Validation loss: 2.2247071471265567

Epoch: 5| Step: 3
Training loss: 2.52239727973938
Validation loss: 2.1936912305893435

Epoch: 5| Step: 4
Training loss: 2.171623706817627
Validation loss: 2.1930951072323706

Epoch: 5| Step: 5
Training loss: 2.5326666831970215
Validation loss: 2.19841101092677

Epoch: 5| Step: 6
Training loss: 2.7631969451904297
Validation loss: 2.196271816889445

Epoch: 5| Step: 7
Training loss: 2.289067268371582
Validation loss: 2.199257278955111

Epoch: 5| Step: 8
Training loss: 2.5774221420288086
Validation loss: 2.1953183835552585

Epoch: 5| Step: 9
Training loss: 3.407578229904175
Validation loss: 2.177094631297614

Epoch: 5| Step: 10
Training loss: 2.372023582458496
Validation loss: 2.1701190420376357

Epoch: 26| Step: 0
Training loss: 2.274970054626465
Validation loss: 2.1670589882840394

Epoch: 5| Step: 1
Training loss: 2.26344633102417
Validation loss: 2.1563895876689623

Epoch: 5| Step: 2
Training loss: 3.5943267345428467
Validation loss: 2.1869225835287445

Epoch: 5| Step: 3
Training loss: 2.2573161125183105
Validation loss: 2.168930471584361

Epoch: 5| Step: 4
Training loss: 2.2402491569519043
Validation loss: 2.160480877404572

Epoch: 5| Step: 5
Training loss: 2.3624472618103027
Validation loss: 2.1551471666623185

Epoch: 5| Step: 6
Training loss: 2.5816502571105957
Validation loss: 2.141274162518081

Epoch: 5| Step: 7
Training loss: 2.3707401752471924
Validation loss: 2.1585097287290838

Epoch: 5| Step: 8
Training loss: 2.7579803466796875
Validation loss: 2.166746252326555

Epoch: 5| Step: 9
Training loss: 1.9369627237319946
Validation loss: 2.174442319459813

Epoch: 5| Step: 10
Training loss: 2.650169849395752
Validation loss: 2.139226895506664

Epoch: 27| Step: 0
Training loss: 2.9247775077819824
Validation loss: 2.1529234673387263

Epoch: 5| Step: 1
Training loss: 2.460202932357788
Validation loss: 2.1442763241388465

Epoch: 5| Step: 2
Training loss: 2.3502962589263916
Validation loss: 2.1265157473984586

Epoch: 5| Step: 3
Training loss: 3.0999553203582764
Validation loss: 2.1731035555562666

Epoch: 5| Step: 4
Training loss: 2.2470927238464355
Validation loss: 2.1367587658666793

Epoch: 5| Step: 5
Training loss: 2.516551971435547
Validation loss: 2.140564781363292

Epoch: 5| Step: 6
Training loss: 2.5324158668518066
Validation loss: 2.1348695601186445

Epoch: 5| Step: 7
Training loss: 2.1650307178497314
Validation loss: 2.1394650436216787

Epoch: 5| Step: 8
Training loss: 2.083430290222168
Validation loss: 2.153642964619462

Epoch: 5| Step: 9
Training loss: 2.359841823577881
Validation loss: 2.130829288113502

Epoch: 5| Step: 10
Training loss: 2.596034288406372
Validation loss: 2.1520168499280046

Epoch: 28| Step: 0
Training loss: 2.7059569358825684
Validation loss: 2.1215142332097536

Epoch: 5| Step: 1
Training loss: 2.222782611846924
Validation loss: 2.146668188033565

Epoch: 5| Step: 2
Training loss: 2.3391265869140625
Validation loss: 2.1364894374724357

Epoch: 5| Step: 3
Training loss: 2.5182816982269287
Validation loss: 2.1278861261183217

Epoch: 5| Step: 4
Training loss: 2.5457777976989746
Validation loss: 2.1633318598552416

Epoch: 5| Step: 5
Training loss: 2.0238170623779297
Validation loss: 2.1413871344699653

Epoch: 5| Step: 6
Training loss: 3.335017681121826
Validation loss: 2.1180091493873188

Epoch: 5| Step: 7
Training loss: 2.238264560699463
Validation loss: 2.151007716373731

Epoch: 5| Step: 8
Training loss: 2.0117721557617188
Validation loss: 2.1401706357156076

Epoch: 5| Step: 9
Training loss: 3.5242342948913574
Validation loss: 2.1460458796511412

Epoch: 5| Step: 10
Training loss: 1.813459873199463
Validation loss: 2.1340522663567656

Epoch: 29| Step: 0
Training loss: 2.4239237308502197
Validation loss: 2.137961005651823

Epoch: 5| Step: 1
Training loss: 2.1979622840881348
Validation loss: 2.1301255456862913

Epoch: 5| Step: 2
Training loss: 2.203763484954834
Validation loss: 2.155376890654205

Epoch: 5| Step: 3
Training loss: 2.8645617961883545
Validation loss: 2.1328224302620016

Epoch: 5| Step: 4
Training loss: 2.559453248977661
Validation loss: 2.139188535751835

Epoch: 5| Step: 5
Training loss: 2.68639874458313
Validation loss: 2.1158491257698304

Epoch: 5| Step: 6
Training loss: 2.687309741973877
Validation loss: 2.1429160025811966

Epoch: 5| Step: 7
Training loss: 2.1995863914489746
Validation loss: 2.143266298437631

Epoch: 5| Step: 8
Training loss: 2.951587677001953
Validation loss: 2.1254090673180035

Epoch: 5| Step: 9
Training loss: 2.3387856483459473
Validation loss: 2.140466328590147

Epoch: 5| Step: 10
Training loss: 2.05110239982605
Validation loss: 2.1272431240286878

Epoch: 30| Step: 0
Training loss: 2.180908441543579
Validation loss: 2.128144576985349

Epoch: 5| Step: 1
Training loss: 1.908227562904358
Validation loss: 2.13412986006788

Epoch: 5| Step: 2
Training loss: 3.120914936065674
Validation loss: 2.1568115936812533

Epoch: 5| Step: 3
Training loss: 3.029244899749756
Validation loss: 2.132088884230583

Epoch: 5| Step: 4
Training loss: 2.708296298980713
Validation loss: 2.098945148529545

Epoch: 5| Step: 5
Training loss: 2.014542579650879
Validation loss: 2.1165032156052126

Epoch: 5| Step: 6
Training loss: 2.2294201850891113
Validation loss: 2.1340085409020864

Epoch: 5| Step: 7
Training loss: 2.6426479816436768
Validation loss: 2.1367394103798816

Epoch: 5| Step: 8
Training loss: 2.554091215133667
Validation loss: 2.1057019361885647

Epoch: 5| Step: 9
Training loss: 2.197448492050171
Validation loss: 2.132706331950362

Epoch: 5| Step: 10
Training loss: 2.763514518737793
Validation loss: 2.1177091572874334

Epoch: 31| Step: 0
Training loss: 2.9713504314422607
Validation loss: 2.1353478367610643

Epoch: 5| Step: 1
Training loss: 1.853040099143982
Validation loss: 2.1075870042206137

Epoch: 5| Step: 2
Training loss: 2.459559440612793
Validation loss: 2.1311410909057944

Epoch: 5| Step: 3
Training loss: 2.272106647491455
Validation loss: 2.1491508996614845

Epoch: 5| Step: 4
Training loss: 2.1453404426574707
Validation loss: 2.1196849897343624

Epoch: 5| Step: 5
Training loss: 2.0375969409942627
Validation loss: 2.150825395379015

Epoch: 5| Step: 6
Training loss: 2.5811808109283447
Validation loss: 2.127795406567153

Epoch: 5| Step: 7
Training loss: 2.342419385910034
Validation loss: 2.1345624205886677

Epoch: 5| Step: 8
Training loss: 2.8720927238464355
Validation loss: 2.1207757290973457

Epoch: 5| Step: 9
Training loss: 2.7859280109405518
Validation loss: 2.1364588096577632

Epoch: 5| Step: 10
Training loss: 2.840083599090576
Validation loss: 2.1485452190522225

Epoch: 32| Step: 0
Training loss: 2.4720561504364014
Validation loss: 2.157853285471598

Epoch: 5| Step: 1
Training loss: 1.971503496170044
Validation loss: 2.1216266975607923

Epoch: 5| Step: 2
Training loss: 2.487536907196045
Validation loss: 2.137148077769946

Epoch: 5| Step: 3
Training loss: 3.1206157207489014
Validation loss: 2.128082372808969

Epoch: 5| Step: 4
Training loss: 2.789095401763916
Validation loss: 2.13949256045844

Epoch: 5| Step: 5
Training loss: 2.3473992347717285
Validation loss: 2.13097390051811

Epoch: 5| Step: 6
Training loss: 2.7379379272460938
Validation loss: 2.1269299599432174

Epoch: 5| Step: 7
Training loss: 2.2391793727874756
Validation loss: 2.130443514034312

Epoch: 5| Step: 8
Training loss: 1.8222839832305908
Validation loss: 2.1259963832875735

Epoch: 5| Step: 9
Training loss: 2.484283924102783
Validation loss: 2.1273236659265335

Epoch: 5| Step: 10
Training loss: 2.7053213119506836
Validation loss: 2.1270956018919587

Epoch: 33| Step: 0
Training loss: 3.4175662994384766
Validation loss: 2.1285947509991225

Epoch: 5| Step: 1
Training loss: 3.1074070930480957
Validation loss: 2.1304904594216296

Epoch: 5| Step: 2
Training loss: 2.2141315937042236
Validation loss: 2.1340220025790635

Epoch: 5| Step: 3
Training loss: 2.0556321144104004
Validation loss: 2.1239073045792116

Epoch: 5| Step: 4
Training loss: 2.2463531494140625
Validation loss: 2.144227612403131

Epoch: 5| Step: 5
Training loss: 2.3915963172912598
Validation loss: 2.1232489232094056

Epoch: 5| Step: 6
Training loss: 2.087315082550049
Validation loss: 2.123747928168184

Epoch: 5| Step: 7
Training loss: 2.0058019161224365
Validation loss: 2.144935190036733

Epoch: 5| Step: 8
Training loss: 2.8097147941589355
Validation loss: 2.119385944899692

Epoch: 5| Step: 9
Training loss: 2.347058057785034
Validation loss: 2.111000286635532

Epoch: 5| Step: 10
Training loss: 2.298948049545288
Validation loss: 2.114106191101895

Epoch: 34| Step: 0
Training loss: 2.3363277912139893
Validation loss: 2.130608322799847

Epoch: 5| Step: 1
Training loss: 2.940095901489258
Validation loss: 2.1347867981080086

Epoch: 5| Step: 2
Training loss: 2.2095096111297607
Validation loss: 2.1280642222332697

Epoch: 5| Step: 3
Training loss: 2.7000482082366943
Validation loss: 2.125365072681058

Epoch: 5| Step: 4
Training loss: 2.702528476715088
Validation loss: 2.1429837314031457

Epoch: 5| Step: 5
Training loss: 2.592996120452881
Validation loss: 2.1436964875908306

Epoch: 5| Step: 6
Training loss: 2.3022475242614746
Validation loss: 2.1293022812053723

Epoch: 5| Step: 7
Training loss: 2.54734468460083
Validation loss: 2.1227951767624065

Epoch: 5| Step: 8
Training loss: 1.921076774597168
Validation loss: 2.1219186372654413

Epoch: 5| Step: 9
Training loss: 2.3871002197265625
Validation loss: 2.108322533228064

Epoch: 5| Step: 10
Training loss: 2.361299753189087
Validation loss: 2.1448237255055416

Epoch: 35| Step: 0
Training loss: 2.1377835273742676
Validation loss: 2.150085349236765

Epoch: 5| Step: 1
Training loss: 2.0714001655578613
Validation loss: 2.1422396295814106

Epoch: 5| Step: 2
Training loss: 2.5913589000701904
Validation loss: 2.1144439405010593

Epoch: 5| Step: 3
Training loss: 2.581977605819702
Validation loss: 2.1276344778717204

Epoch: 5| Step: 4
Training loss: 2.29083514213562
Validation loss: 2.1171129595848823

Epoch: 5| Step: 5
Training loss: 2.420334577560425
Validation loss: 2.1411776773391233

Epoch: 5| Step: 6
Training loss: 2.089242696762085
Validation loss: 2.111439783086059

Epoch: 5| Step: 7
Training loss: 2.6013622283935547
Validation loss: 2.1248983234487553

Epoch: 5| Step: 8
Training loss: 2.158125400543213
Validation loss: 2.1027544672771166

Epoch: 5| Step: 9
Training loss: 3.244279146194458
Validation loss: 2.125994356729651

Epoch: 5| Step: 10
Training loss: 2.873809337615967
Validation loss: 2.1355347658998225

Epoch: 36| Step: 0
Training loss: 2.226473569869995
Validation loss: 2.1179234212444675

Epoch: 5| Step: 1
Training loss: 2.4583284854888916
Validation loss: 2.1005203916180517

Epoch: 5| Step: 2
Training loss: 2.584524393081665
Validation loss: 2.094539891007126

Epoch: 5| Step: 3
Training loss: 2.1416876316070557
Validation loss: 2.1087666544862973

Epoch: 5| Step: 4
Training loss: 2.9318642616271973
Validation loss: 2.0736649049225675

Epoch: 5| Step: 5
Training loss: 2.3077244758605957
Validation loss: 2.1009767619512414

Epoch: 5| Step: 6
Training loss: 2.501438856124878
Validation loss: 2.11237427496141

Epoch: 5| Step: 7
Training loss: 2.391667604446411
Validation loss: 2.0993842130066245

Epoch: 5| Step: 8
Training loss: 3.2074532508850098
Validation loss: 2.104255049459396

Epoch: 5| Step: 9
Training loss: 1.6987533569335938
Validation loss: 2.109156606017902

Epoch: 5| Step: 10
Training loss: 2.4512710571289062
Validation loss: 2.129300532802459

Epoch: 37| Step: 0
Training loss: 2.8102262020111084
Validation loss: 2.0999778342503372

Epoch: 5| Step: 1
Training loss: 3.7890381813049316
Validation loss: 2.1145371852382535

Epoch: 5| Step: 2
Training loss: 2.2399466037750244
Validation loss: 2.079479581566267

Epoch: 5| Step: 3
Training loss: 2.1651504039764404
Validation loss: 2.1277412227405015

Epoch: 5| Step: 4
Training loss: 2.756175994873047
Validation loss: 2.1238511249583256

Epoch: 5| Step: 5
Training loss: 2.717742919921875
Validation loss: 2.0719619515121623

Epoch: 5| Step: 6
Training loss: 2.329265832901001
Validation loss: 2.0977881800743843

Epoch: 5| Step: 7
Training loss: 2.155306100845337
Validation loss: 2.1157076768977667

Epoch: 5| Step: 8
Training loss: 1.6871168613433838
Validation loss: 2.087984564483807

Epoch: 5| Step: 9
Training loss: 1.982600212097168
Validation loss: 2.115188762705813

Epoch: 5| Step: 10
Training loss: 2.123086929321289
Validation loss: 2.1072314670009

Epoch: 38| Step: 0
Training loss: 1.9871362447738647
Validation loss: 2.0898747110879548

Epoch: 5| Step: 1
Training loss: 2.097766160964966
Validation loss: 2.1216903912123812

Epoch: 5| Step: 2
Training loss: 2.653730630874634
Validation loss: 2.1138851334971767

Epoch: 5| Step: 3
Training loss: 2.37631893157959
Validation loss: 2.1003728733267835

Epoch: 5| Step: 4
Training loss: 2.382936477661133
Validation loss: 2.1266371768007994

Epoch: 5| Step: 5
Training loss: 2.9034583568573
Validation loss: 2.0960927753038305

Epoch: 5| Step: 6
Training loss: 2.7538349628448486
Validation loss: 2.0975415168269986

Epoch: 5| Step: 7
Training loss: 2.175645351409912
Validation loss: 2.115496922564763

Epoch: 5| Step: 8
Training loss: 1.8828849792480469
Validation loss: 2.1108658249660204

Epoch: 5| Step: 9
Training loss: 2.5551540851593018
Validation loss: 2.0937134091572096

Epoch: 5| Step: 10
Training loss: 2.9963479042053223
Validation loss: 2.1245248394627727

Epoch: 39| Step: 0
Training loss: 2.37296724319458
Validation loss: 2.1047893493406233

Epoch: 5| Step: 1
Training loss: 2.3821487426757812
Validation loss: 2.098801479544691

Epoch: 5| Step: 2
Training loss: 2.135148048400879
Validation loss: 2.106685116726865

Epoch: 5| Step: 3
Training loss: 2.406283140182495
Validation loss: 2.1032703858549877

Epoch: 5| Step: 4
Training loss: 2.7091686725616455
Validation loss: 2.0916878177273657

Epoch: 5| Step: 5
Training loss: 2.3900387287139893
Validation loss: 2.121569918047997

Epoch: 5| Step: 6
Training loss: 3.0576119422912598
Validation loss: 2.1050956428691907

Epoch: 5| Step: 7
Training loss: 2.1739935874938965
Validation loss: 2.1325376956693587

Epoch: 5| Step: 8
Training loss: 2.87977933883667
Validation loss: 2.126120005884478

Epoch: 5| Step: 9
Training loss: 1.7845706939697266
Validation loss: 2.0880937345566286

Epoch: 5| Step: 10
Training loss: 2.4838123321533203
Validation loss: 2.110568695170905

Epoch: 40| Step: 0
Training loss: 2.380552291870117
Validation loss: 2.1092707880081667

Epoch: 5| Step: 1
Training loss: 2.1174914836883545
Validation loss: 2.1010601187265046

Epoch: 5| Step: 2
Training loss: 2.275665760040283
Validation loss: 2.1051378468031525

Epoch: 5| Step: 3
Training loss: 2.525841236114502
Validation loss: 2.106171533625613

Epoch: 5| Step: 4
Training loss: 2.7587528228759766
Validation loss: 2.1221958539819203

Epoch: 5| Step: 5
Training loss: 1.75601065158844
Validation loss: 2.1137987208622757

Epoch: 5| Step: 6
Training loss: 2.533839702606201
Validation loss: 2.108245967536844

Epoch: 5| Step: 7
Training loss: 2.8906257152557373
Validation loss: 2.1192076847117436

Epoch: 5| Step: 8
Training loss: 2.4451065063476562
Validation loss: 2.112286763806497

Epoch: 5| Step: 9
Training loss: 2.708590507507324
Validation loss: 2.114538997732183

Epoch: 5| Step: 10
Training loss: 2.3619701862335205
Validation loss: 2.1455282703522713

Epoch: 41| Step: 0
Training loss: 2.4670143127441406
Validation loss: 2.1149556085627568

Epoch: 5| Step: 1
Training loss: 2.5362887382507324
Validation loss: 2.1044808369810863

Epoch: 5| Step: 2
Training loss: 2.1813454627990723
Validation loss: 2.1228424400411625

Epoch: 5| Step: 3
Training loss: 2.3447296619415283
Validation loss: 2.086949327940582

Epoch: 5| Step: 4
Training loss: 2.9670825004577637
Validation loss: 2.10396792170822

Epoch: 5| Step: 5
Training loss: 2.579796314239502
Validation loss: 2.1010571859216176

Epoch: 5| Step: 6
Training loss: 2.608860969543457
Validation loss: 2.1046830479816725

Epoch: 5| Step: 7
Training loss: 2.086533308029175
Validation loss: 2.0855667924368255

Epoch: 5| Step: 8
Training loss: 2.3144099712371826
Validation loss: 2.0841847799157582

Epoch: 5| Step: 9
Training loss: 1.6721382141113281
Validation loss: 2.102910828846757

Epoch: 5| Step: 10
Training loss: 2.889099359512329
Validation loss: 2.1210905326310026

Epoch: 42| Step: 0
Training loss: 2.4016952514648438
Validation loss: 2.112926444699687

Epoch: 5| Step: 1
Training loss: 2.6825437545776367
Validation loss: 2.1117992670305314

Epoch: 5| Step: 2
Training loss: 2.2989501953125
Validation loss: 2.098408918226919

Epoch: 5| Step: 3
Training loss: 2.720543622970581
Validation loss: 2.115303712506448

Epoch: 5| Step: 4
Training loss: 2.291764259338379
Validation loss: 2.1013229649554015

Epoch: 5| Step: 5
Training loss: 1.687325119972229
Validation loss: 2.1103677236905662

Epoch: 5| Step: 6
Training loss: 2.1421406269073486
Validation loss: 2.105125137554702

Epoch: 5| Step: 7
Training loss: 2.7945141792297363
Validation loss: 2.1140143717488935

Epoch: 5| Step: 8
Training loss: 2.7746458053588867
Validation loss: 2.120777949210136

Epoch: 5| Step: 9
Training loss: 2.6055617332458496
Validation loss: 2.0988417261390278

Epoch: 5| Step: 10
Training loss: 2.101118564605713
Validation loss: 2.118890908456618

Epoch: 43| Step: 0
Training loss: 2.625380277633667
Validation loss: 2.1061051378967943

Epoch: 5| Step: 1
Training loss: 2.7388908863067627
Validation loss: 2.1021429005489556

Epoch: 5| Step: 2
Training loss: 3.2011947631835938
Validation loss: 2.1104240878935783

Epoch: 5| Step: 3
Training loss: 1.8415930271148682
Validation loss: 2.1034053064161733

Epoch: 5| Step: 4
Training loss: 2.352231502532959
Validation loss: 2.077859688830632

Epoch: 5| Step: 5
Training loss: 2.1877269744873047
Validation loss: 2.0902668788868892

Epoch: 5| Step: 6
Training loss: 2.5049057006835938
Validation loss: 2.089748672259751

Epoch: 5| Step: 7
Training loss: 2.1336863040924072
Validation loss: 2.110636229156166

Epoch: 5| Step: 8
Training loss: 2.385948419570923
Validation loss: 2.0816078750036096

Epoch: 5| Step: 9
Training loss: 2.3091578483581543
Validation loss: 2.0737957492951424

Epoch: 5| Step: 10
Training loss: 2.3167598247528076
Validation loss: 2.0856256254257692

Epoch: 44| Step: 0
Training loss: 2.2575020790100098
Validation loss: 2.092149879342766

Epoch: 5| Step: 1
Training loss: 2.4318606853485107
Validation loss: 2.0879102599236274

Epoch: 5| Step: 2
Training loss: 2.433893918991089
Validation loss: 2.095250727027975

Epoch: 5| Step: 3
Training loss: 2.9001364707946777
Validation loss: 2.0855437709439184

Epoch: 5| Step: 4
Training loss: 2.597381114959717
Validation loss: 2.0948976957669823

Epoch: 5| Step: 5
Training loss: 2.09507417678833
Validation loss: 2.07791325353807

Epoch: 5| Step: 6
Training loss: 2.6244518756866455
Validation loss: 2.098904455861738

Epoch: 5| Step: 7
Training loss: 2.233945846557617
Validation loss: 2.083019497574017

Epoch: 5| Step: 8
Training loss: 2.373706102371216
Validation loss: 2.0801648709081833

Epoch: 5| Step: 9
Training loss: 2.7245960235595703
Validation loss: 2.0780333754836873

Epoch: 5| Step: 10
Training loss: 1.8775229454040527
Validation loss: 2.086316042048957

Epoch: 45| Step: 0
Training loss: 2.6821303367614746
Validation loss: 2.091993870273713

Epoch: 5| Step: 1
Training loss: 2.2730777263641357
Validation loss: 2.0563306347016366

Epoch: 5| Step: 2
Training loss: 2.324381113052368
Validation loss: 2.0758724289555706

Epoch: 5| Step: 3
Training loss: 2.8094935417175293
Validation loss: 2.1004077926758797

Epoch: 5| Step: 4
Training loss: 2.1433467864990234
Validation loss: 2.0810097058614097

Epoch: 5| Step: 5
Training loss: 2.1849801540374756
Validation loss: 2.095115279638639

Epoch: 5| Step: 6
Training loss: 1.9049596786499023
Validation loss: 2.101679531476831

Epoch: 5| Step: 7
Training loss: 2.523432493209839
Validation loss: 2.096763681339961

Epoch: 5| Step: 8
Training loss: 2.393643856048584
Validation loss: 2.0989779233932495

Epoch: 5| Step: 9
Training loss: 2.515927791595459
Validation loss: 2.0875415596910702

Epoch: 5| Step: 10
Training loss: 2.9088497161865234
Validation loss: 2.098915179570516

Epoch: 46| Step: 0
Training loss: 2.16806697845459
Validation loss: 2.080839685214463

Epoch: 5| Step: 1
Training loss: 2.1013407707214355
Validation loss: 2.0760538962579544

Epoch: 5| Step: 2
Training loss: 2.5690090656280518
Validation loss: 2.0857505080520466

Epoch: 5| Step: 3
Training loss: 1.741721749305725
Validation loss: 2.08190317051385

Epoch: 5| Step: 4
Training loss: 2.9186763763427734
Validation loss: 2.090997580559023

Epoch: 5| Step: 5
Training loss: 2.868431329727173
Validation loss: 2.079628062504594

Epoch: 5| Step: 6
Training loss: 1.8909902572631836
Validation loss: 2.0877673331127373

Epoch: 5| Step: 7
Training loss: 3.2773728370666504
Validation loss: 2.089610707375311

Epoch: 5| Step: 8
Training loss: 2.57439923286438
Validation loss: 2.071932036389587

Epoch: 5| Step: 9
Training loss: 1.9846813678741455
Validation loss: 2.0717811020471717

Epoch: 5| Step: 10
Training loss: 2.2912673950195312
Validation loss: 2.111520556993382

Epoch: 47| Step: 0
Training loss: 1.9341800212860107
Validation loss: 2.081120780719224

Epoch: 5| Step: 1
Training loss: 2.0496788024902344
Validation loss: 2.071765057502254

Epoch: 5| Step: 2
Training loss: 2.69435453414917
Validation loss: 2.095877242344682

Epoch: 5| Step: 3
Training loss: 1.8469409942626953
Validation loss: 2.0598362953432146

Epoch: 5| Step: 4
Training loss: 2.705887794494629
Validation loss: 2.084599942289373

Epoch: 5| Step: 5
Training loss: 2.581941843032837
Validation loss: 2.089879787096413

Epoch: 5| Step: 6
Training loss: 2.1656951904296875
Validation loss: 2.0799965384185954

Epoch: 5| Step: 7
Training loss: 2.6181132793426514
Validation loss: 2.0887716431771555

Epoch: 5| Step: 8
Training loss: 2.0538392066955566
Validation loss: 2.0809075447820846

Epoch: 5| Step: 9
Training loss: 3.4404845237731934
Validation loss: 2.116075772111134

Epoch: 5| Step: 10
Training loss: 2.3526976108551025
Validation loss: 2.089078821161742

Epoch: 48| Step: 0
Training loss: 2.2291600704193115
Validation loss: 2.081021349917176

Epoch: 5| Step: 1
Training loss: 2.7364585399627686
Validation loss: 2.081217599171464

Epoch: 5| Step: 2
Training loss: 2.4064204692840576
Validation loss: 2.074753210108767

Epoch: 5| Step: 3
Training loss: 2.3774399757385254
Validation loss: 2.065197390894736

Epoch: 5| Step: 4
Training loss: 1.7868788242340088
Validation loss: 2.097184496541177

Epoch: 5| Step: 5
Training loss: 1.9138429164886475
Validation loss: 2.1066450175418647

Epoch: 5| Step: 6
Training loss: 2.0098109245300293
Validation loss: 2.081118849016005

Epoch: 5| Step: 7
Training loss: 2.795321226119995
Validation loss: 2.07639935452451

Epoch: 5| Step: 8
Training loss: 2.4587197303771973
Validation loss: 2.092885617286928

Epoch: 5| Step: 9
Training loss: 2.9136664867401123
Validation loss: 2.054063726496953

Epoch: 5| Step: 10
Training loss: 2.8927793502807617
Validation loss: 2.083021484395509

Epoch: 49| Step: 0
Training loss: 2.760085105895996
Validation loss: 2.0866228508692917

Epoch: 5| Step: 1
Training loss: 2.1193690299987793
Validation loss: 2.0860535201206

Epoch: 5| Step: 2
Training loss: 1.7513248920440674
Validation loss: 2.0872724645881244

Epoch: 5| Step: 3
Training loss: 2.464996814727783
Validation loss: 2.0768536547178864

Epoch: 5| Step: 4
Training loss: 1.9460245370864868
Validation loss: 2.083789228111185

Epoch: 5| Step: 5
Training loss: 2.795464277267456
Validation loss: 2.081708268452716

Epoch: 5| Step: 6
Training loss: 2.8051838874816895
Validation loss: 2.0905614668323147

Epoch: 5| Step: 7
Training loss: 2.633131504058838
Validation loss: 2.0898633849236274

Epoch: 5| Step: 8
Training loss: 2.1795713901519775
Validation loss: 2.0930812538311048

Epoch: 5| Step: 9
Training loss: 2.334198236465454
Validation loss: 2.103069546402142

Epoch: 5| Step: 10
Training loss: 2.571664810180664
Validation loss: 2.0732129004693802

Epoch: 50| Step: 0
Training loss: 2.7347235679626465
Validation loss: 2.0861908671676472

Epoch: 5| Step: 1
Training loss: 2.4801130294799805
Validation loss: 2.0887605579950477

Epoch: 5| Step: 2
Training loss: 2.4631333351135254
Validation loss: 2.110626143793906

Epoch: 5| Step: 3
Training loss: 2.8187623023986816
Validation loss: 2.085451408099103

Epoch: 5| Step: 4
Training loss: 2.032811403274536
Validation loss: 2.0733660215972574

Epoch: 5| Step: 5
Training loss: 1.686375379562378
Validation loss: 2.101931805251747

Epoch: 5| Step: 6
Training loss: 2.9097046852111816
Validation loss: 2.0974106147725093

Epoch: 5| Step: 7
Training loss: 2.5450592041015625
Validation loss: 2.0949517655116257

Epoch: 5| Step: 8
Training loss: 2.432687759399414
Validation loss: 2.0772070692431543

Epoch: 5| Step: 9
Training loss: 1.817461609840393
Validation loss: 2.106780216258059

Epoch: 5| Step: 10
Training loss: 2.594477891921997
Validation loss: 2.0907037386330227

Epoch: 51| Step: 0
Training loss: 2.238433837890625
Validation loss: 2.099653656764697

Epoch: 5| Step: 1
Training loss: 2.01568865776062
Validation loss: 2.0944490355830037

Epoch: 5| Step: 2
Training loss: 2.7184290885925293
Validation loss: 2.07848681429381

Epoch: 5| Step: 3
Training loss: 2.6612019538879395
Validation loss: 2.065538598645118

Epoch: 5| Step: 4
Training loss: 2.096463680267334
Validation loss: 2.065723592235196

Epoch: 5| Step: 5
Training loss: 2.566965103149414
Validation loss: 2.0975376790569675

Epoch: 5| Step: 6
Training loss: 2.0575432777404785
Validation loss: 2.083904443248626

Epoch: 5| Step: 7
Training loss: 1.9829336404800415
Validation loss: 2.071311709701374

Epoch: 5| Step: 8
Training loss: 3.4019718170166016
Validation loss: 2.1010206642971245

Epoch: 5| Step: 9
Training loss: 2.2811636924743652
Validation loss: 2.0631697844433528

Epoch: 5| Step: 10
Training loss: 2.4249656200408936
Validation loss: 2.0874198123972905

Epoch: 52| Step: 0
Training loss: 1.862276315689087
Validation loss: 2.0806266684685983

Epoch: 5| Step: 1
Training loss: 1.990582823753357
Validation loss: 2.0919395698014127

Epoch: 5| Step: 2
Training loss: 2.596306324005127
Validation loss: 2.064523612299273

Epoch: 5| Step: 3
Training loss: 2.8202366828918457
Validation loss: 2.0833179284167547

Epoch: 5| Step: 4
Training loss: 3.173375129699707
Validation loss: 2.0728773788739274

Epoch: 5| Step: 5
Training loss: 1.5643959045410156
Validation loss: 2.0876867937785324

Epoch: 5| Step: 6
Training loss: 2.1445202827453613
Validation loss: 2.0807941177839875

Epoch: 5| Step: 7
Training loss: 3.118772029876709
Validation loss: 2.072119323156213

Epoch: 5| Step: 8
Training loss: 2.0346310138702393
Validation loss: 2.0706579467301727

Epoch: 5| Step: 9
Training loss: 2.387965202331543
Validation loss: 2.078783151923969

Epoch: 5| Step: 10
Training loss: 2.779989242553711
Validation loss: 2.0566620160174627

Epoch: 53| Step: 0
Training loss: 2.5220983028411865
Validation loss: 2.079732337305623

Epoch: 5| Step: 1
Training loss: 2.5499672889709473
Validation loss: 2.0633220800789456

Epoch: 5| Step: 2
Training loss: 1.9890152215957642
Validation loss: 2.061046947715103

Epoch: 5| Step: 3
Training loss: 2.0865120887756348
Validation loss: 2.062044600004791

Epoch: 5| Step: 4
Training loss: 1.9804683923721313
Validation loss: 2.0545394087350495

Epoch: 5| Step: 5
Training loss: 2.9677982330322266
Validation loss: 2.0713364488335064

Epoch: 5| Step: 6
Training loss: 2.394585609436035
Validation loss: 2.09730266499263

Epoch: 5| Step: 7
Training loss: 2.808533191680908
Validation loss: 2.0590182670982937

Epoch: 5| Step: 8
Training loss: 2.9374001026153564
Validation loss: 2.0771287051580285

Epoch: 5| Step: 9
Training loss: 1.827754259109497
Validation loss: 2.0797282957261607

Epoch: 5| Step: 10
Training loss: 2.192178964614868
Validation loss: 2.082775637667666

Epoch: 54| Step: 0
Training loss: 1.8880923986434937
Validation loss: 2.0522875144917476

Epoch: 5| Step: 1
Training loss: 2.7343051433563232
Validation loss: 2.088596449103407

Epoch: 5| Step: 2
Training loss: 2.27308988571167
Validation loss: 2.0539798095662105

Epoch: 5| Step: 3
Training loss: 2.148120403289795
Validation loss: 2.0860158192214144

Epoch: 5| Step: 4
Training loss: 2.2484841346740723
Validation loss: 2.0923897015151156

Epoch: 5| Step: 5
Training loss: 2.345940351486206
Validation loss: 2.085752799946775

Epoch: 5| Step: 6
Training loss: 2.7790422439575195
Validation loss: 2.0640381766903784

Epoch: 5| Step: 7
Training loss: 2.3333468437194824
Validation loss: 2.0889465065412622

Epoch: 5| Step: 8
Training loss: 2.552849292755127
Validation loss: 2.0570452418378604

Epoch: 5| Step: 9
Training loss: 2.452657699584961
Validation loss: 2.0504923341094807

Epoch: 5| Step: 10
Training loss: 2.598362445831299
Validation loss: 2.087876089157597

Epoch: 55| Step: 0
Training loss: 2.1689271926879883
Validation loss: 2.0872625176624586

Epoch: 5| Step: 1
Training loss: 2.830164670944214
Validation loss: 2.0860637311012513

Epoch: 5| Step: 2
Training loss: 2.72891902923584
Validation loss: 2.075888746528215

Epoch: 5| Step: 3
Training loss: 2.458199977874756
Validation loss: 2.0482513468752623

Epoch: 5| Step: 4
Training loss: 2.3188209533691406
Validation loss: 2.081897786868516

Epoch: 5| Step: 5
Training loss: 2.2196121215820312
Validation loss: 2.062550744702739

Epoch: 5| Step: 6
Training loss: 2.1641316413879395
Validation loss: 2.078483845597954

Epoch: 5| Step: 7
Training loss: 2.480834722518921
Validation loss: 2.1072649289202947

Epoch: 5| Step: 8
Training loss: 2.1108462810516357
Validation loss: 2.060308271838773

Epoch: 5| Step: 9
Training loss: 1.809191107749939
Validation loss: 2.0842832442252868

Epoch: 5| Step: 10
Training loss: 2.812278985977173
Validation loss: 2.075199565579814

Epoch: 56| Step: 0
Training loss: 2.5277886390686035
Validation loss: 2.091013487949166

Epoch: 5| Step: 1
Training loss: 1.356658697128296
Validation loss: 2.0983006723465456

Epoch: 5| Step: 2
Training loss: 3.4402847290039062
Validation loss: 2.0798282854018675

Epoch: 5| Step: 3
Training loss: 2.996041774749756
Validation loss: 2.077202909736223

Epoch: 5| Step: 4
Training loss: 1.7608747482299805
Validation loss: 2.069235191550306

Epoch: 5| Step: 5
Training loss: 2.363274097442627
Validation loss: 2.103110251888152

Epoch: 5| Step: 6
Training loss: 2.284780979156494
Validation loss: 2.110877695903983

Epoch: 5| Step: 7
Training loss: 2.7323203086853027
Validation loss: 2.080690017310522

Epoch: 5| Step: 8
Training loss: 2.5705575942993164
Validation loss: 2.0775016969250095

Epoch: 5| Step: 9
Training loss: 2.2648301124572754
Validation loss: 2.080154152326686

Epoch: 5| Step: 10
Training loss: 1.779236078262329
Validation loss: 2.0843286232281755

Epoch: 57| Step: 0
Training loss: 2.595546007156372
Validation loss: 2.0849157533337994

Epoch: 5| Step: 1
Training loss: 2.5388083457946777
Validation loss: 2.072487149187314

Epoch: 5| Step: 2
Training loss: 1.923182725906372
Validation loss: 2.081323533929804

Epoch: 5| Step: 3
Training loss: 2.2628469467163086
Validation loss: 2.0923183425780265

Epoch: 5| Step: 4
Training loss: 2.4863340854644775
Validation loss: 2.0721839294638684

Epoch: 5| Step: 5
Training loss: 2.235930919647217
Validation loss: 2.067723501113153

Epoch: 5| Step: 6
Training loss: 2.4202358722686768
Validation loss: 2.0829622053330943

Epoch: 5| Step: 7
Training loss: 2.1894443035125732
Validation loss: 2.057876460013851

Epoch: 5| Step: 8
Training loss: 2.3308990001678467
Validation loss: 2.0700551630348287

Epoch: 5| Step: 9
Training loss: 2.5852227210998535
Validation loss: 2.0568006346302647

Epoch: 5| Step: 10
Training loss: 2.4597480297088623
Validation loss: 2.0505677987170476

Epoch: 58| Step: 0
Training loss: 2.0655906200408936
Validation loss: 2.088238121360861

Epoch: 5| Step: 1
Training loss: 2.878652811050415
Validation loss: 2.0460915411672285

Epoch: 5| Step: 2
Training loss: 2.220914840698242
Validation loss: 2.051286816596985

Epoch: 5| Step: 3
Training loss: 2.2788710594177246
Validation loss: 2.0657365860477572

Epoch: 5| Step: 4
Training loss: 2.1335902214050293
Validation loss: 2.081420244709138

Epoch: 5| Step: 5
Training loss: 2.700901746749878
Validation loss: 2.0519053269458074

Epoch: 5| Step: 6
Training loss: 2.698716402053833
Validation loss: 2.08305924682207

Epoch: 5| Step: 7
Training loss: 1.9475162029266357
Validation loss: 2.0729382249616806

Epoch: 5| Step: 8
Training loss: 2.1886026859283447
Validation loss: 2.0361670627388904

Epoch: 5| Step: 9
Training loss: 2.6756629943847656
Validation loss: 2.064501670099074

Epoch: 5| Step: 10
Training loss: 2.3445842266082764
Validation loss: 2.0616376117993425

Epoch: 59| Step: 0
Training loss: 2.2938055992126465
Validation loss: 2.0650417343262704

Epoch: 5| Step: 1
Training loss: 1.837179183959961
Validation loss: 2.08480244041771

Epoch: 5| Step: 2
Training loss: 2.2362325191497803
Validation loss: 2.081764982592675

Epoch: 5| Step: 3
Training loss: 2.397446393966675
Validation loss: 2.0670482522697857

Epoch: 5| Step: 4
Training loss: 2.704068422317505
Validation loss: 2.0668141675251785

Epoch: 5| Step: 5
Training loss: 2.3900485038757324
Validation loss: 2.070789106430546

Epoch: 5| Step: 6
Training loss: 2.676245927810669
Validation loss: 2.080264388874013

Epoch: 5| Step: 7
Training loss: 2.054562568664551
Validation loss: 2.0812014841264292

Epoch: 5| Step: 8
Training loss: 2.5641064643859863
Validation loss: 2.072835623577077

Epoch: 5| Step: 9
Training loss: 2.6072773933410645
Validation loss: 2.059139795200799

Epoch: 5| Step: 10
Training loss: 2.1924309730529785
Validation loss: 2.076428301872746

Epoch: 60| Step: 0
Training loss: 2.092531442642212
Validation loss: 2.0741879209395377

Epoch: 5| Step: 1
Training loss: 2.2748560905456543
Validation loss: 2.0658193711311585

Epoch: 5| Step: 2
Training loss: 2.447535276412964
Validation loss: 2.0596309220919045

Epoch: 5| Step: 3
Training loss: 2.463778018951416
Validation loss: 2.0609476156132196

Epoch: 5| Step: 4
Training loss: 2.82397723197937
Validation loss: 2.095685794789304

Epoch: 5| Step: 5
Training loss: 2.6162896156311035
Validation loss: 2.0517020840798654

Epoch: 5| Step: 6
Training loss: 2.9087510108947754
Validation loss: 2.062399746269308

Epoch: 5| Step: 7
Training loss: 2.4223945140838623
Validation loss: 2.0915138772738877

Epoch: 5| Step: 8
Training loss: 2.089080333709717
Validation loss: 2.074952492149927

Epoch: 5| Step: 9
Training loss: 1.7737871408462524
Validation loss: 2.0494012268640662

Epoch: 5| Step: 10
Training loss: 2.0726566314697266
Validation loss: 2.041057030359904

Epoch: 61| Step: 0
Training loss: 2.1964075565338135
Validation loss: 2.049045783217235

Epoch: 5| Step: 1
Training loss: 2.089339017868042
Validation loss: 2.0749623839573195

Epoch: 5| Step: 2
Training loss: 1.6274654865264893
Validation loss: 2.0858811255424254

Epoch: 5| Step: 3
Training loss: 3.397799015045166
Validation loss: 2.0674229219395626

Epoch: 5| Step: 4
Training loss: 2.382441759109497
Validation loss: 2.065290697159306

Epoch: 5| Step: 5
Training loss: 2.2954819202423096
Validation loss: 2.068544292962679

Epoch: 5| Step: 6
Training loss: 2.008504629135132
Validation loss: 2.100939654534863

Epoch: 5| Step: 7
Training loss: 2.0102250576019287
Validation loss: 2.08404904027139

Epoch: 5| Step: 8
Training loss: 3.1613287925720215
Validation loss: 2.0508138620725243

Epoch: 5| Step: 9
Training loss: 2.378833293914795
Validation loss: 2.0380177446590957

Epoch: 5| Step: 10
Training loss: 2.2817742824554443
Validation loss: 2.0681760182944675

Epoch: 62| Step: 0
Training loss: 2.588991403579712
Validation loss: 2.0567592036339546

Epoch: 5| Step: 1
Training loss: 2.5166430473327637
Validation loss: 2.078331078252485

Epoch: 5| Step: 2
Training loss: 2.501783847808838
Validation loss: 2.0649420779238463

Epoch: 5| Step: 3
Training loss: 1.3131892681121826
Validation loss: 2.0734792268404396

Epoch: 5| Step: 4
Training loss: 2.552102565765381
Validation loss: 2.0750381997836533

Epoch: 5| Step: 5
Training loss: 2.066312313079834
Validation loss: 2.0790670738425305

Epoch: 5| Step: 6
Training loss: 3.2726054191589355
Validation loss: 2.0881865844931653

Epoch: 5| Step: 7
Training loss: 3.0585265159606934
Validation loss: 2.051537803424302

Epoch: 5| Step: 8
Training loss: 1.9443581104278564
Validation loss: 2.078171855659895

Epoch: 5| Step: 9
Training loss: 1.5796763896942139
Validation loss: 2.063899620886772

Epoch: 5| Step: 10
Training loss: 2.7242472171783447
Validation loss: 2.0630766448154243

Epoch: 63| Step: 0
Training loss: 2.001735210418701
Validation loss: 2.0573323298526067

Epoch: 5| Step: 1
Training loss: 2.476496696472168
Validation loss: 2.0606439344344603

Epoch: 5| Step: 2
Training loss: 2.0132789611816406
Validation loss: 2.0641507999871367

Epoch: 5| Step: 3
Training loss: 2.3760132789611816
Validation loss: 2.0717868869022658

Epoch: 5| Step: 4
Training loss: 2.3651795387268066
Validation loss: 2.0688700060690604

Epoch: 5| Step: 5
Training loss: 2.495915174484253
Validation loss: 2.0631775202289706

Epoch: 5| Step: 6
Training loss: 2.433757781982422
Validation loss: 2.0555260155790593

Epoch: 5| Step: 7
Training loss: 2.609663248062134
Validation loss: 2.073447201841621

Epoch: 5| Step: 8
Training loss: 2.026609420776367
Validation loss: 2.056242045535836

Epoch: 5| Step: 9
Training loss: 2.9375619888305664
Validation loss: 2.066386907331405

Epoch: 5| Step: 10
Training loss: 2.169959783554077
Validation loss: 2.083423165864842

Epoch: 64| Step: 0
Training loss: 2.3217759132385254
Validation loss: 2.0591373520512737

Epoch: 5| Step: 1
Training loss: 2.0078189373016357
Validation loss: 2.071349879746796

Epoch: 5| Step: 2
Training loss: 2.345960855484009
Validation loss: 2.056595469033846

Epoch: 5| Step: 3
Training loss: 2.726771593093872
Validation loss: 2.0750607213666363

Epoch: 5| Step: 4
Training loss: 2.0252161026000977
Validation loss: 2.068517013262677

Epoch: 5| Step: 5
Training loss: 2.5001962184906006
Validation loss: 2.0704038860977336

Epoch: 5| Step: 6
Training loss: 2.2727255821228027
Validation loss: 2.0677226128116732

Epoch: 5| Step: 7
Training loss: 1.9272476434707642
Validation loss: 2.06478395769673

Epoch: 5| Step: 8
Training loss: 2.269690752029419
Validation loss: 2.0973777463359218

Epoch: 5| Step: 9
Training loss: 2.737393379211426
Validation loss: 2.0979277600524244

Epoch: 5| Step: 10
Training loss: 2.8853342533111572
Validation loss: 2.0884718638594433

Epoch: 65| Step: 0
Training loss: 1.5306522846221924
Validation loss: 2.0842534842029696

Epoch: 5| Step: 1
Training loss: 2.6312673091888428
Validation loss: 2.1001029476042716

Epoch: 5| Step: 2
Training loss: 2.255241870880127
Validation loss: 2.072060626040223

Epoch: 5| Step: 3
Training loss: 2.713238000869751
Validation loss: 2.0713468367053616

Epoch: 5| Step: 4
Training loss: 2.8232295513153076
Validation loss: 2.076580568026471

Epoch: 5| Step: 5
Training loss: 1.6925112009048462
Validation loss: 2.058582282835437

Epoch: 5| Step: 6
Training loss: 2.447946071624756
Validation loss: 2.089391134118521

Epoch: 5| Step: 7
Training loss: 2.1438496112823486
Validation loss: 2.0666033721739248

Epoch: 5| Step: 8
Training loss: 2.5060033798217773
Validation loss: 2.075257614094724

Epoch: 5| Step: 9
Training loss: 2.4823648929595947
Validation loss: 2.07432448223073

Epoch: 5| Step: 10
Training loss: 2.8746721744537354
Validation loss: 2.0656579040711924

Epoch: 66| Step: 0
Training loss: 2.9177932739257812
Validation loss: 2.0782851455032185

Epoch: 5| Step: 1
Training loss: 2.427762269973755
Validation loss: 2.065159046521751

Epoch: 5| Step: 2
Training loss: 1.4701519012451172
Validation loss: 2.061760017948766

Epoch: 5| Step: 3
Training loss: 2.336771249771118
Validation loss: 2.070240748825894

Epoch: 5| Step: 4
Training loss: 1.7210239171981812
Validation loss: 2.0664285921281382

Epoch: 5| Step: 5
Training loss: 2.555840015411377
Validation loss: 2.069130124584321

Epoch: 5| Step: 6
Training loss: 2.696115493774414
Validation loss: 2.0773755363238755

Epoch: 5| Step: 7
Training loss: 2.36037540435791
Validation loss: 2.063828901578021

Epoch: 5| Step: 8
Training loss: 2.1785643100738525
Validation loss: 2.0540181167664064

Epoch: 5| Step: 9
Training loss: 2.1914894580841064
Validation loss: 2.073615707376952

Epoch: 5| Step: 10
Training loss: 3.1262214183807373
Validation loss: 2.0815625600917365

Epoch: 67| Step: 0
Training loss: 1.8566081523895264
Validation loss: 2.0704061241560083

Epoch: 5| Step: 1
Training loss: 2.4505345821380615
Validation loss: 2.0854425558479885

Epoch: 5| Step: 2
Training loss: 1.755348563194275
Validation loss: 2.079997867666265

Epoch: 5| Step: 3
Training loss: 2.0082361698150635
Validation loss: 2.083693673533778

Epoch: 5| Step: 4
Training loss: 2.485666275024414
Validation loss: 2.0579127393743044

Epoch: 5| Step: 5
Training loss: 2.9300692081451416
Validation loss: 2.0962246964054723

Epoch: 5| Step: 6
Training loss: 2.1936657428741455
Validation loss: 2.107419985596852

Epoch: 5| Step: 7
Training loss: 2.1273748874664307
Validation loss: 2.0795900103866414

Epoch: 5| Step: 8
Training loss: 3.155562162399292
Validation loss: 2.065161687071605

Epoch: 5| Step: 9
Training loss: 2.4105701446533203
Validation loss: 2.0736251390108498

Epoch: 5| Step: 10
Training loss: 2.3725414276123047
Validation loss: 2.094437086454002

Epoch: 68| Step: 0
Training loss: 2.202138662338257
Validation loss: 2.0996865687831754

Epoch: 5| Step: 1
Training loss: 3.155627489089966
Validation loss: 2.0773399478645733

Epoch: 5| Step: 2
Training loss: 2.0833945274353027
Validation loss: 2.0840063184820194

Epoch: 5| Step: 3
Training loss: 2.617946147918701
Validation loss: 2.067343182461236

Epoch: 5| Step: 4
Training loss: 2.0971322059631348
Validation loss: 2.0502032092822495

Epoch: 5| Step: 5
Training loss: 1.9726251363754272
Validation loss: 2.0972386278131956

Epoch: 5| Step: 6
Training loss: 2.3161540031433105
Validation loss: 2.073605771987669

Epoch: 5| Step: 7
Training loss: 2.694685935974121
Validation loss: 2.0790209565111386

Epoch: 5| Step: 8
Training loss: 2.9477648735046387
Validation loss: 2.0402567386627197

Epoch: 5| Step: 9
Training loss: 1.7832714319229126
Validation loss: 2.0951095857927875

Epoch: 5| Step: 10
Training loss: 1.992964744567871
Validation loss: 2.073790555359215

Epoch: 69| Step: 0
Training loss: 2.916346788406372
Validation loss: 2.0958192194661787

Epoch: 5| Step: 1
Training loss: 2.5134663581848145
Validation loss: 2.074895671618882

Epoch: 5| Step: 2
Training loss: 1.8222687244415283
Validation loss: 2.0739899207186956

Epoch: 5| Step: 3
Training loss: 2.8699302673339844
Validation loss: 2.069184316101895

Epoch: 5| Step: 4
Training loss: 2.406226634979248
Validation loss: 2.086285594970949

Epoch: 5| Step: 5
Training loss: 1.9183189868927002
Validation loss: 2.0818844277371644

Epoch: 5| Step: 6
Training loss: 2.3302090167999268
Validation loss: 2.0712868244417253

Epoch: 5| Step: 7
Training loss: 2.5229084491729736
Validation loss: 2.0667319733609437

Epoch: 5| Step: 8
Training loss: 2.3004186153411865
Validation loss: 2.056425779096542

Epoch: 5| Step: 9
Training loss: 1.9719339609146118
Validation loss: 2.09251178849128

Epoch: 5| Step: 10
Training loss: 2.1983895301818848
Validation loss: 2.064422092130107

Epoch: 70| Step: 0
Training loss: 2.2695775032043457
Validation loss: 2.0636439374698106

Epoch: 5| Step: 1
Training loss: 2.117488145828247
Validation loss: 2.0713200543516423

Epoch: 5| Step: 2
Training loss: 2.275195598602295
Validation loss: 2.0735611813042754

Epoch: 5| Step: 3
Training loss: 2.543170928955078
Validation loss: 2.0601884472754692

Epoch: 5| Step: 4
Training loss: 2.087200164794922
Validation loss: 2.0878905506544214

Epoch: 5| Step: 5
Training loss: 2.656095027923584
Validation loss: 2.0596085081818285

Epoch: 5| Step: 6
Training loss: 2.7399086952209473
Validation loss: 2.068091200244042

Epoch: 5| Step: 7
Training loss: 1.6865346431732178
Validation loss: 2.0532789384165118

Epoch: 5| Step: 8
Training loss: 3.1115734577178955
Validation loss: 2.058722067904729

Epoch: 5| Step: 9
Training loss: 2.041510820388794
Validation loss: 2.0416028038147958

Epoch: 5| Step: 10
Training loss: 1.961321234703064
Validation loss: 2.0655339623010285

Epoch: 71| Step: 0
Training loss: 2.0991806983947754
Validation loss: 2.084460735321045

Epoch: 5| Step: 1
Training loss: 2.7375216484069824
Validation loss: 2.053684660183486

Epoch: 5| Step: 2
Training loss: 2.3212263584136963
Validation loss: 2.075013090205449

Epoch: 5| Step: 3
Training loss: 1.4649708271026611
Validation loss: 2.064032276471456

Epoch: 5| Step: 4
Training loss: 2.370999813079834
Validation loss: 2.087057703284807

Epoch: 5| Step: 5
Training loss: 2.691495180130005
Validation loss: 2.0616983047095676

Epoch: 5| Step: 6
Training loss: 2.2788383960723877
Validation loss: 2.06950556847357

Epoch: 5| Step: 7
Training loss: 2.554152488708496
Validation loss: 2.0757801866018646

Epoch: 5| Step: 8
Training loss: 2.214113712310791
Validation loss: 2.042725670722223

Epoch: 5| Step: 9
Training loss: 2.543992757797241
Validation loss: 2.06654772450847

Epoch: 5| Step: 10
Training loss: 2.442580223083496
Validation loss: 2.065199400788994

Epoch: 72| Step: 0
Training loss: 1.846575140953064
Validation loss: 2.0649617692475677

Epoch: 5| Step: 1
Training loss: 2.4807307720184326
Validation loss: 2.0600756624693513

Epoch: 5| Step: 2
Training loss: 2.701146364212036
Validation loss: 2.0725219018997683

Epoch: 5| Step: 3
Training loss: 2.827165126800537
Validation loss: 2.0739315325214016

Epoch: 5| Step: 4
Training loss: 2.5397515296936035
Validation loss: 2.0754390557607016

Epoch: 5| Step: 5
Training loss: 2.6099560260772705
Validation loss: 2.0722486831808604

Epoch: 5| Step: 6
Training loss: 2.5693631172180176
Validation loss: 2.05723209791286

Epoch: 5| Step: 7
Training loss: 1.8190486431121826
Validation loss: 2.050549073885846

Epoch: 5| Step: 8
Training loss: 2.3321404457092285
Validation loss: 2.0442702744596746

Epoch: 5| Step: 9
Training loss: 2.086527109146118
Validation loss: 2.0475495643513177

Epoch: 5| Step: 10
Training loss: 1.6553974151611328
Validation loss: 2.057604984570575

Epoch: 73| Step: 0
Training loss: 2.1485707759857178
Validation loss: 2.094131121071436

Epoch: 5| Step: 1
Training loss: 2.2364261150360107
Validation loss: 2.063276139638757

Epoch: 5| Step: 2
Training loss: 2.3262972831726074
Validation loss: 2.045907799915601

Epoch: 5| Step: 3
Training loss: 2.315594434738159
Validation loss: 2.089452887094149

Epoch: 5| Step: 4
Training loss: 2.548292636871338
Validation loss: 2.0459706001384284

Epoch: 5| Step: 5
Training loss: 2.383399248123169
Validation loss: 2.045793911462189

Epoch: 5| Step: 6
Training loss: 2.0362677574157715
Validation loss: 2.066981336121918

Epoch: 5| Step: 7
Training loss: 2.8127474784851074
Validation loss: 2.0706943850363455

Epoch: 5| Step: 8
Training loss: 1.7377557754516602
Validation loss: 2.0599498633415467

Epoch: 5| Step: 9
Training loss: 2.2201690673828125
Validation loss: 2.0793876019857263

Epoch: 5| Step: 10
Training loss: 2.839911460876465
Validation loss: 2.065780052574732

Epoch: 74| Step: 0
Training loss: 2.453968048095703
Validation loss: 2.0638784567515054

Epoch: 5| Step: 1
Training loss: 2.107966661453247
Validation loss: 2.0834268472527944

Epoch: 5| Step: 2
Training loss: 2.4952712059020996
Validation loss: 2.1008490234292965

Epoch: 5| Step: 3
Training loss: 2.5385706424713135
Validation loss: 2.0643329287088044

Epoch: 5| Step: 4
Training loss: 1.4212713241577148
Validation loss: 2.0577183308139926

Epoch: 5| Step: 5
Training loss: 2.6559994220733643
Validation loss: 2.0934856219958236

Epoch: 5| Step: 6
Training loss: 1.4678876399993896
Validation loss: 2.0825276310725878

Epoch: 5| Step: 7
Training loss: 2.305568218231201
Validation loss: 2.0705004930496216

Epoch: 5| Step: 8
Training loss: 3.1247472763061523
Validation loss: 2.061678624922229

Epoch: 5| Step: 9
Training loss: 2.199927568435669
Validation loss: 2.0763279032963577

Epoch: 5| Step: 10
Training loss: 2.7364423274993896
Validation loss: 2.0490910750563427

Epoch: 75| Step: 0
Training loss: 2.4268507957458496
Validation loss: 2.0895915672343266

Epoch: 5| Step: 1
Training loss: 2.356926679611206
Validation loss: 2.0785450396999234

Epoch: 5| Step: 2
Training loss: 2.239070177078247
Validation loss: 2.0837914648876397

Epoch: 5| Step: 3
Training loss: 2.202942132949829
Validation loss: 2.0729056353210122

Epoch: 5| Step: 4
Training loss: 2.7571699619293213
Validation loss: 2.0748563786988616

Epoch: 5| Step: 5
Training loss: 2.5262057781219482
Validation loss: 2.077845214515604

Epoch: 5| Step: 6
Training loss: 2.1681432723999023
Validation loss: 2.0870158428786905

Epoch: 5| Step: 7
Training loss: 2.6062111854553223
Validation loss: 2.0740808568974978

Epoch: 5| Step: 8
Training loss: 1.8597062826156616
Validation loss: 2.0771919988816783

Epoch: 5| Step: 9
Training loss: 2.1064579486846924
Validation loss: 2.0427988524078042

Epoch: 5| Step: 10
Training loss: 2.267676830291748
Validation loss: 2.0774436996829126

Epoch: 76| Step: 0
Training loss: 2.373690128326416
Validation loss: 2.065338418047915

Epoch: 5| Step: 1
Training loss: 3.080767869949341
Validation loss: 2.0801259112614456

Epoch: 5| Step: 2
Training loss: 2.2940125465393066
Validation loss: 2.086223186985139

Epoch: 5| Step: 3
Training loss: 2.1874961853027344
Validation loss: 2.07113855244011

Epoch: 5| Step: 4
Training loss: 2.032247304916382
Validation loss: 2.0767068760369414

Epoch: 5| Step: 5
Training loss: 2.1824536323547363
Validation loss: 2.0832050359377297

Epoch: 5| Step: 6
Training loss: 2.7737619876861572
Validation loss: 2.0672149017292965

Epoch: 5| Step: 7
Training loss: 1.7784833908081055
Validation loss: 2.08174906751161

Epoch: 5| Step: 8
Training loss: 2.4554405212402344
Validation loss: 2.0527865168868855

Epoch: 5| Step: 9
Training loss: 1.9285633563995361
Validation loss: 2.0654806449849117

Epoch: 5| Step: 10
Training loss: 2.5071284770965576
Validation loss: 2.050299418869839

Epoch: 77| Step: 0
Training loss: 2.310987949371338
Validation loss: 2.0584288412524807

Epoch: 5| Step: 1
Training loss: 2.8169105052948
Validation loss: 2.059532193727391

Epoch: 5| Step: 2
Training loss: 2.04628849029541
Validation loss: 2.055715517331195

Epoch: 5| Step: 3
Training loss: 2.1071228981018066
Validation loss: 2.0503801748316777

Epoch: 5| Step: 4
Training loss: 2.392094373703003
Validation loss: 2.0581573760637673

Epoch: 5| Step: 5
Training loss: 2.241337299346924
Validation loss: 2.0371400476783834

Epoch: 5| Step: 6
Training loss: 2.0082805156707764
Validation loss: 2.070442594507689

Epoch: 5| Step: 7
Training loss: 2.4511725902557373
Validation loss: 2.0638764609572706

Epoch: 5| Step: 8
Training loss: 2.7891688346862793
Validation loss: 2.0578144417014173

Epoch: 5| Step: 9
Training loss: 2.186999797821045
Validation loss: 2.0325879332839802

Epoch: 5| Step: 10
Training loss: 2.067831039428711
Validation loss: 2.068092570509962

Epoch: 78| Step: 0
Training loss: 2.237283229827881
Validation loss: 2.066027823314872

Epoch: 5| Step: 1
Training loss: 2.6157631874084473
Validation loss: 2.0684957991364183

Epoch: 5| Step: 2
Training loss: 2.955907106399536
Validation loss: 2.064735322870234

Epoch: 5| Step: 3
Training loss: 1.7728631496429443
Validation loss: 2.0615405087829917

Epoch: 5| Step: 4
Training loss: 2.3821825981140137
Validation loss: 2.062751946910735

Epoch: 5| Step: 5
Training loss: 1.784743309020996
Validation loss: 2.060976207897227

Epoch: 5| Step: 6
Training loss: 2.194222927093506
Validation loss: 2.096185630367648

Epoch: 5| Step: 7
Training loss: 1.9148280620574951
Validation loss: 2.0749913928329304

Epoch: 5| Step: 8
Training loss: 3.0071988105773926
Validation loss: 2.06922802617473

Epoch: 5| Step: 9
Training loss: 2.0482494831085205
Validation loss: 2.0721187027551795

Epoch: 5| Step: 10
Training loss: 2.615313768386841
Validation loss: 2.092885266068161

Epoch: 79| Step: 0
Training loss: 2.546832323074341
Validation loss: 2.044037857363301

Epoch: 5| Step: 1
Training loss: 1.973466157913208
Validation loss: 2.0885492934975574

Epoch: 5| Step: 2
Training loss: 2.274850368499756
Validation loss: 2.053571690795242

Epoch: 5| Step: 3
Training loss: 3.006394147872925
Validation loss: 2.048584884212863

Epoch: 5| Step: 4
Training loss: 2.3070011138916016
Validation loss: 2.0886543771272064

Epoch: 5| Step: 5
Training loss: 1.7845118045806885
Validation loss: 2.063779671986898

Epoch: 5| Step: 6
Training loss: 2.3139119148254395
Validation loss: 2.0551046145859586

Epoch: 5| Step: 7
Training loss: 2.18940806388855
Validation loss: 2.0904082200860463

Epoch: 5| Step: 8
Training loss: 1.849565863609314
Validation loss: 2.049464382151122

Epoch: 5| Step: 9
Training loss: 2.566389799118042
Validation loss: 2.0729999132053827

Epoch: 5| Step: 10
Training loss: 2.6016767024993896
Validation loss: 2.0555578726594166

Epoch: 80| Step: 0
Training loss: 2.1241748332977295
Validation loss: 2.0598301913148616

Epoch: 5| Step: 1
Training loss: 1.9763730764389038
Validation loss: 2.0721584814851

Epoch: 5| Step: 2
Training loss: 2.2092385292053223
Validation loss: 2.0628616989299817

Epoch: 5| Step: 3
Training loss: 2.4846878051757812
Validation loss: 2.0405649267217165

Epoch: 5| Step: 4
Training loss: 2.5791375637054443
Validation loss: 2.072731271866829

Epoch: 5| Step: 5
Training loss: 2.1323506832122803
Validation loss: 2.040734601277177

Epoch: 5| Step: 6
Training loss: 2.0959339141845703
Validation loss: 2.036355346761724

Epoch: 5| Step: 7
Training loss: 2.450490713119507
Validation loss: 2.0661608134546587

Epoch: 5| Step: 8
Training loss: 2.569206476211548
Validation loss: 2.0624734893921883

Epoch: 5| Step: 9
Training loss: 2.843181848526001
Validation loss: 2.0539758269504835

Epoch: 5| Step: 10
Training loss: 1.9088523387908936
Validation loss: 2.068027509156094

Epoch: 81| Step: 0
Training loss: 1.944247841835022
Validation loss: 2.0574271089287213

Epoch: 5| Step: 1
Training loss: 2.4340434074401855
Validation loss: 2.0717570397161666

Epoch: 5| Step: 2
Training loss: 2.16404128074646
Validation loss: 2.0679789102205666

Epoch: 5| Step: 3
Training loss: 1.9555604457855225
Validation loss: 2.059194859638009

Epoch: 5| Step: 4
Training loss: 2.9113399982452393
Validation loss: 2.0498766783745057

Epoch: 5| Step: 5
Training loss: 2.294097423553467
Validation loss: 2.0663541350313412

Epoch: 5| Step: 6
Training loss: 2.005284547805786
Validation loss: 2.0809573114559217

Epoch: 5| Step: 7
Training loss: 2.1978869438171387
Validation loss: 2.0652534705336376

Epoch: 5| Step: 8
Training loss: 2.3452484607696533
Validation loss: 2.0696417208640807

Epoch: 5| Step: 9
Training loss: 3.0288028717041016
Validation loss: 2.0535596827025056

Epoch: 5| Step: 10
Training loss: 2.0656545162200928
Validation loss: 2.0731729281845914

Epoch: 82| Step: 0
Training loss: 2.502131938934326
Validation loss: 2.050473552878185

Epoch: 5| Step: 1
Training loss: 1.7590839862823486
Validation loss: 2.0677617826769428

Epoch: 5| Step: 2
Training loss: 2.2070095539093018
Validation loss: 2.0622803690612956

Epoch: 5| Step: 3
Training loss: 1.7312628030776978
Validation loss: 2.0673734603389615

Epoch: 5| Step: 4
Training loss: 2.6798558235168457
Validation loss: 2.040614584440826

Epoch: 5| Step: 5
Training loss: 1.384745478630066
Validation loss: 2.046783924102783

Epoch: 5| Step: 6
Training loss: 2.9369893074035645
Validation loss: 2.0775228226056663

Epoch: 5| Step: 7
Training loss: 2.3451156616210938
Validation loss: 2.0747312371448805

Epoch: 5| Step: 8
Training loss: 2.930474281311035
Validation loss: 2.065447258692916

Epoch: 5| Step: 9
Training loss: 2.3430862426757812
Validation loss: 2.0525028987597396

Epoch: 5| Step: 10
Training loss: 2.615471124649048
Validation loss: 2.058834563019455

Epoch: 83| Step: 0
Training loss: 2.4181811809539795
Validation loss: 2.0591933893901047

Epoch: 5| Step: 1
Training loss: 2.764387845993042
Validation loss: 2.0557311170844623

Epoch: 5| Step: 2
Training loss: 2.0021581649780273
Validation loss: 2.070633283225439

Epoch: 5| Step: 3
Training loss: 2.228078603744507
Validation loss: 2.049307487344229

Epoch: 5| Step: 4
Training loss: 2.008331298828125
Validation loss: 2.0647125526141097

Epoch: 5| Step: 5
Training loss: 2.9327290058135986
Validation loss: 2.0406111824897026

Epoch: 5| Step: 6
Training loss: 1.8886550664901733
Validation loss: 2.0625100469076507

Epoch: 5| Step: 7
Training loss: 1.4780523777008057
Validation loss: 2.0800479829952283

Epoch: 5| Step: 8
Training loss: 2.1548848152160645
Validation loss: 2.0662822364478983

Epoch: 5| Step: 9
Training loss: 2.7643964290618896
Validation loss: 2.056351013081048

Epoch: 5| Step: 10
Training loss: 2.8123414516448975
Validation loss: 2.026331942568543

Epoch: 84| Step: 0
Training loss: 2.487917423248291
Validation loss: 2.074470116246131

Epoch: 5| Step: 1
Training loss: 1.868304967880249
Validation loss: 2.0740844383034656

Epoch: 5| Step: 2
Training loss: 2.1762216091156006
Validation loss: 2.0814095389458442

Epoch: 5| Step: 3
Training loss: 2.5492806434631348
Validation loss: 2.05270524947874

Epoch: 5| Step: 4
Training loss: 2.433110237121582
Validation loss: 2.0629988537039807

Epoch: 5| Step: 5
Training loss: 2.54717755317688
Validation loss: 2.082711681242912

Epoch: 5| Step: 6
Training loss: 2.567253828048706
Validation loss: 2.080062840574531

Epoch: 5| Step: 7
Training loss: 2.583487033843994
Validation loss: 2.087540118925033

Epoch: 5| Step: 8
Training loss: 1.872155785560608
Validation loss: 2.0839555827520226

Epoch: 5| Step: 9
Training loss: 2.39188814163208
Validation loss: 2.080419724987399

Epoch: 5| Step: 10
Training loss: 1.7980543375015259
Validation loss: 2.101395273721346

Epoch: 85| Step: 0
Training loss: 1.6685619354248047
Validation loss: 2.0695922707998626

Epoch: 5| Step: 1
Training loss: 2.0264368057250977
Validation loss: 2.0756909385804208

Epoch: 5| Step: 2
Training loss: 2.313514471054077
Validation loss: 2.0930979021133913

Epoch: 5| Step: 3
Training loss: 2.476365089416504
Validation loss: 2.100218108905259

Epoch: 5| Step: 4
Training loss: 2.6527976989746094
Validation loss: 2.0862170009202856

Epoch: 5| Step: 5
Training loss: 3.5265045166015625
Validation loss: 2.0800500813350884

Epoch: 5| Step: 6
Training loss: 3.332751512527466
Validation loss: 2.090652158183436

Epoch: 5| Step: 7
Training loss: 1.9139152765274048
Validation loss: 2.106687681649321

Epoch: 5| Step: 8
Training loss: 1.8426471948623657
Validation loss: 2.078828991100352

Epoch: 5| Step: 9
Training loss: 1.6742023229599
Validation loss: 2.090217850541556

Epoch: 5| Step: 10
Training loss: 1.7983899116516113
Validation loss: 2.058096383207588

Epoch: 86| Step: 0
Training loss: 2.3302369117736816
Validation loss: 2.0610509687854397

Epoch: 5| Step: 1
Training loss: 2.828325033187866
Validation loss: 2.0765911686804985

Epoch: 5| Step: 2
Training loss: 2.3442025184631348
Validation loss: 2.0650119025220155

Epoch: 5| Step: 3
Training loss: 2.1073689460754395
Validation loss: 2.0644135129067207

Epoch: 5| Step: 4
Training loss: 2.769076108932495
Validation loss: 2.0493213886855752

Epoch: 5| Step: 5
Training loss: 1.729888916015625
Validation loss: 2.0739012302890902

Epoch: 5| Step: 6
Training loss: 2.7264907360076904
Validation loss: 2.0740622615301483

Epoch: 5| Step: 7
Training loss: 1.6849056482315063
Validation loss: 2.0842958265735256

Epoch: 5| Step: 8
Training loss: 2.00830340385437
Validation loss: 2.0561876912270822

Epoch: 5| Step: 9
Training loss: 2.095231294631958
Validation loss: 2.0703298750744072

Epoch: 5| Step: 10
Training loss: 2.8503854274749756
Validation loss: 2.0604790923415974

Epoch: 87| Step: 0
Training loss: 3.063504457473755
Validation loss: 2.0389690411988126

Epoch: 5| Step: 1
Training loss: 2.465848445892334
Validation loss: 2.059431004267867

Epoch: 5| Step: 2
Training loss: 2.0935699939727783
Validation loss: 2.069916502121956

Epoch: 5| Step: 3
Training loss: 2.7940611839294434
Validation loss: 2.068642945699794

Epoch: 5| Step: 4
Training loss: 2.297668933868408
Validation loss: 2.0560910240296395

Epoch: 5| Step: 5
Training loss: 1.6140823364257812
Validation loss: 2.060870806376139

Epoch: 5| Step: 6
Training loss: 2.342280149459839
Validation loss: 2.0500758130063295

Epoch: 5| Step: 7
Training loss: 1.81294846534729
Validation loss: 2.0680080921419206

Epoch: 5| Step: 8
Training loss: 2.139496326446533
Validation loss: 2.051495013698455

Epoch: 5| Step: 9
Training loss: 2.46565580368042
Validation loss: 2.053507771543277

Epoch: 5| Step: 10
Training loss: 2.26060152053833
Validation loss: 2.0476360256953905

Epoch: 88| Step: 0
Training loss: 2.2251152992248535
Validation loss: 2.05879194249389

Epoch: 5| Step: 1
Training loss: 2.1402664184570312
Validation loss: 2.078901324220883

Epoch: 5| Step: 2
Training loss: 2.9354069232940674
Validation loss: 2.0510727282493346

Epoch: 5| Step: 3
Training loss: 1.7685394287109375
Validation loss: 2.0391335372001893

Epoch: 5| Step: 4
Training loss: 2.292240619659424
Validation loss: 2.0512565925557125

Epoch: 5| Step: 5
Training loss: 1.7139228582382202
Validation loss: 2.0641252366445397

Epoch: 5| Step: 6
Training loss: 2.5154151916503906
Validation loss: 2.0674830893034577

Epoch: 5| Step: 7
Training loss: 2.1386547088623047
Validation loss: 2.053806722805064

Epoch: 5| Step: 8
Training loss: 2.8529553413391113
Validation loss: 2.0520036964006323

Epoch: 5| Step: 9
Training loss: 1.8661730289459229
Validation loss: 2.0617243718075495

Epoch: 5| Step: 10
Training loss: 2.8681704998016357
Validation loss: 2.0619469534966255

Epoch: 89| Step: 0
Training loss: 2.027686357498169
Validation loss: 2.0241011393967496

Epoch: 5| Step: 1
Training loss: 2.209862470626831
Validation loss: 2.0291709258992183

Epoch: 5| Step: 2
Training loss: 2.7788174152374268
Validation loss: 2.038825270950153

Epoch: 5| Step: 3
Training loss: 2.377894163131714
Validation loss: 2.0314516764815136

Epoch: 5| Step: 4
Training loss: 2.110391616821289
Validation loss: 2.0591249427487774

Epoch: 5| Step: 5
Training loss: 2.0107150077819824
Validation loss: 2.071908539341342

Epoch: 5| Step: 6
Training loss: 2.5052716732025146
Validation loss: 2.0790950893073954

Epoch: 5| Step: 7
Training loss: 1.9659643173217773
Validation loss: 2.039227995821225

Epoch: 5| Step: 8
Training loss: 1.9346542358398438
Validation loss: 2.046765345399098

Epoch: 5| Step: 9
Training loss: 2.760481595993042
Validation loss: 2.077889161725198

Epoch: 5| Step: 10
Training loss: 2.543458938598633
Validation loss: 2.034860703252977

Epoch: 90| Step: 0
Training loss: 2.003981113433838
Validation loss: 2.067587785823371

Epoch: 5| Step: 1
Training loss: 1.8701213598251343
Validation loss: 2.0616182998944352

Epoch: 5| Step: 2
Training loss: 1.9918617010116577
Validation loss: 2.0325185278410554

Epoch: 5| Step: 3
Training loss: 1.8248443603515625
Validation loss: 2.0833399564989152

Epoch: 5| Step: 4
Training loss: 2.6522603034973145
Validation loss: 2.0593012225243355

Epoch: 5| Step: 5
Training loss: 2.7466869354248047
Validation loss: 2.042825578361429

Epoch: 5| Step: 6
Training loss: 3.0841164588928223
Validation loss: 2.027693974074497

Epoch: 5| Step: 7
Training loss: 2.5975661277770996
Validation loss: 2.075170939968478

Epoch: 5| Step: 8
Training loss: 2.330592393875122
Validation loss: 2.042062791444922

Epoch: 5| Step: 9
Training loss: 2.4384872913360596
Validation loss: 2.0325761918098695

Epoch: 5| Step: 10
Training loss: 1.58071768283844
Validation loss: 2.0551150357851418

Epoch: 91| Step: 0
Training loss: 2.896287679672241
Validation loss: 2.0417966714469333

Epoch: 5| Step: 1
Training loss: 1.3537662029266357
Validation loss: 2.036123591084634

Epoch: 5| Step: 2
Training loss: 2.3510756492614746
Validation loss: 2.0640668433199645

Epoch: 5| Step: 3
Training loss: 1.6645863056182861
Validation loss: 2.0530099304773475

Epoch: 5| Step: 4
Training loss: 2.4999518394470215
Validation loss: 2.0808769861857095

Epoch: 5| Step: 5
Training loss: 2.556809186935425
Validation loss: 2.055109699567159

Epoch: 5| Step: 6
Training loss: 2.674893617630005
Validation loss: 2.065461663789647

Epoch: 5| Step: 7
Training loss: 2.6732280254364014
Validation loss: 2.0611758565389984

Epoch: 5| Step: 8
Training loss: 1.9446752071380615
Validation loss: 2.0254820110977336

Epoch: 5| Step: 9
Training loss: 1.7056124210357666
Validation loss: 2.066842120180848

Epoch: 5| Step: 10
Training loss: 2.6984479427337646
Validation loss: 2.0621353721105926

Epoch: 92| Step: 0
Training loss: 1.9465278387069702
Validation loss: 2.0805928168758268

Epoch: 5| Step: 1
Training loss: 1.6173534393310547
Validation loss: 2.02671060510861

Epoch: 5| Step: 2
Training loss: 2.5990865230560303
Validation loss: 2.077001097381756

Epoch: 5| Step: 3
Training loss: 2.6556308269500732
Validation loss: 2.0768582256891395

Epoch: 5| Step: 4
Training loss: 2.4429521560668945
Validation loss: 2.0640330981182795

Epoch: 5| Step: 5
Training loss: 2.3760836124420166
Validation loss: 2.052820148006562

Epoch: 5| Step: 6
Training loss: 2.6670069694519043
Validation loss: 2.0977219586731284

Epoch: 5| Step: 7
Training loss: 2.2186264991760254
Validation loss: 2.0753951816148657

Epoch: 5| Step: 8
Training loss: 2.507056474685669
Validation loss: 2.086030173045333

Epoch: 5| Step: 9
Training loss: 2.243378162384033
Validation loss: 2.1023230168127243

Epoch: 5| Step: 10
Training loss: 1.7458404302597046
Validation loss: 2.056037187576294

Epoch: 93| Step: 0
Training loss: 1.9125699996948242
Validation loss: 2.0773274155073267

Epoch: 5| Step: 1
Training loss: 2.4086403846740723
Validation loss: 2.060338612525694

Epoch: 5| Step: 2
Training loss: 1.6248916387557983
Validation loss: 2.0628874968456965

Epoch: 5| Step: 3
Training loss: 3.1872787475585938
Validation loss: 2.065277657201213

Epoch: 5| Step: 4
Training loss: 2.5934202671051025
Validation loss: 2.0750397046407065

Epoch: 5| Step: 5
Training loss: 3.0148251056671143
Validation loss: 2.077111398020098

Epoch: 5| Step: 6
Training loss: 1.5296156406402588
Validation loss: 2.070265917367833

Epoch: 5| Step: 7
Training loss: 2.2533836364746094
Validation loss: 2.080904229994743

Epoch: 5| Step: 8
Training loss: 1.8626034259796143
Validation loss: 2.0522839689767487

Epoch: 5| Step: 9
Training loss: 2.4336047172546387
Validation loss: 2.0764133827660674

Epoch: 5| Step: 10
Training loss: 2.090339183807373
Validation loss: 2.052183046135851

Epoch: 94| Step: 0
Training loss: 1.8945318460464478
Validation loss: 2.060892853685605

Epoch: 5| Step: 1
Training loss: 2.018740177154541
Validation loss: 2.051343946046727

Epoch: 5| Step: 2
Training loss: 1.8259111642837524
Validation loss: 2.05072674956373

Epoch: 5| Step: 3
Training loss: 2.0340163707733154
Validation loss: 2.061539460253972

Epoch: 5| Step: 4
Training loss: 2.297863721847534
Validation loss: 2.057959715525309

Epoch: 5| Step: 5
Training loss: 2.236746311187744
Validation loss: 2.048102496772684

Epoch: 5| Step: 6
Training loss: 2.6705310344696045
Validation loss: 2.0477259210360947

Epoch: 5| Step: 7
Training loss: 2.4641945362091064
Validation loss: 2.05422301958966

Epoch: 5| Step: 8
Training loss: 2.1441400051116943
Validation loss: 2.061842049321821

Epoch: 5| Step: 9
Training loss: 2.9883952140808105
Validation loss: 2.0427566459102016

Epoch: 5| Step: 10
Training loss: 2.426504135131836
Validation loss: 2.0453691123634257

Epoch: 95| Step: 0
Training loss: 1.771338701248169
Validation loss: 2.0658877203541417

Epoch: 5| Step: 1
Training loss: 2.083033323287964
Validation loss: 2.0492530381807716

Epoch: 5| Step: 2
Training loss: 2.1996212005615234
Validation loss: 2.03823907016426

Epoch: 5| Step: 3
Training loss: 1.9640750885009766
Validation loss: 2.0563132173271588

Epoch: 5| Step: 4
Training loss: 3.211973190307617
Validation loss: 2.0590995768065095

Epoch: 5| Step: 5
Training loss: 1.9742610454559326
Validation loss: 2.0613150852982716

Epoch: 5| Step: 6
Training loss: 2.1203155517578125
Validation loss: 2.0484321566038233

Epoch: 5| Step: 7
Training loss: 2.1888623237609863
Validation loss: 2.0391056588900986

Epoch: 5| Step: 8
Training loss: 2.7782180309295654
Validation loss: 2.057529386653695

Epoch: 5| Step: 9
Training loss: 2.255577564239502
Validation loss: 2.0544825753858014

Epoch: 5| Step: 10
Training loss: 2.4367313385009766
Validation loss: 2.0439136874291206

Epoch: 96| Step: 0
Training loss: 1.967170000076294
Validation loss: 2.060962733402047

Epoch: 5| Step: 1
Training loss: 2.357952117919922
Validation loss: 2.068378963778096

Epoch: 5| Step: 2
Training loss: 2.4718685150146484
Validation loss: 2.0343550815377185

Epoch: 5| Step: 3
Training loss: 2.7071990966796875
Validation loss: 2.0569083357370026

Epoch: 5| Step: 4
Training loss: 2.1594722270965576
Validation loss: 2.0473223911818637

Epoch: 5| Step: 5
Training loss: 1.8166602849960327
Validation loss: 2.0295037633629254

Epoch: 5| Step: 6
Training loss: 2.3767571449279785
Validation loss: 2.0329554926964546

Epoch: 5| Step: 7
Training loss: 1.7423975467681885
Validation loss: 2.053742609998231

Epoch: 5| Step: 8
Training loss: 2.8072402477264404
Validation loss: 2.059238444092453

Epoch: 5| Step: 9
Training loss: 2.0848793983459473
Validation loss: 2.0431039564071165

Epoch: 5| Step: 10
Training loss: 2.5924220085144043
Validation loss: 2.0473414313408638

Epoch: 97| Step: 0
Training loss: 2.325136423110962
Validation loss: 2.0603662408808225

Epoch: 5| Step: 1
Training loss: 1.7942345142364502
Validation loss: 2.0775298021172963

Epoch: 5| Step: 2
Training loss: 2.059213638305664
Validation loss: 2.065243605644472

Epoch: 5| Step: 3
Training loss: 2.797290086746216
Validation loss: 2.052213330422678

Epoch: 5| Step: 4
Training loss: 2.227930784225464
Validation loss: 2.054125729427543

Epoch: 5| Step: 5
Training loss: 2.2702629566192627
Validation loss: 2.06823218125169

Epoch: 5| Step: 6
Training loss: 2.3709311485290527
Validation loss: 2.0702070600243023

Epoch: 5| Step: 7
Training loss: 2.7427494525909424
Validation loss: 2.0660585126569195

Epoch: 5| Step: 8
Training loss: 1.969447135925293
Validation loss: 2.0627014611357

Epoch: 5| Step: 9
Training loss: 1.9243252277374268
Validation loss: 2.064167994324879

Epoch: 5| Step: 10
Training loss: 2.4787158966064453
Validation loss: 2.078776764613326

Epoch: 98| Step: 0
Training loss: 2.471985340118408
Validation loss: 2.061004595089984

Epoch: 5| Step: 1
Training loss: 2.4702627658843994
Validation loss: 2.0971172855746363

Epoch: 5| Step: 2
Training loss: 1.787590742111206
Validation loss: 2.084434627204813

Epoch: 5| Step: 3
Training loss: 1.7900972366333008
Validation loss: 2.07534457278508

Epoch: 5| Step: 4
Training loss: 2.3688621520996094
Validation loss: 2.0766578387188654

Epoch: 5| Step: 5
Training loss: 2.2361762523651123
Validation loss: 2.05793676581434

Epoch: 5| Step: 6
Training loss: 2.0404772758483887
Validation loss: 2.0747985378388436

Epoch: 5| Step: 7
Training loss: 1.6879959106445312
Validation loss: 2.0982306029206965

Epoch: 5| Step: 8
Training loss: 2.815004587173462
Validation loss: 2.058628911613136

Epoch: 5| Step: 9
Training loss: 3.1529953479766846
Validation loss: 2.0753734034876667

Epoch: 5| Step: 10
Training loss: 1.9908747673034668
Validation loss: 2.076698613423173

Epoch: 99| Step: 0
Training loss: 2.5683608055114746
Validation loss: 2.0582414416856665

Epoch: 5| Step: 1
Training loss: 1.9136186838150024
Validation loss: 2.060560077749273

Epoch: 5| Step: 2
Training loss: 2.233078956604004
Validation loss: 2.0777005200744956

Epoch: 5| Step: 3
Training loss: 2.117656707763672
Validation loss: 2.069610554684875

Epoch: 5| Step: 4
Training loss: 2.4486334323883057
Validation loss: 2.0808620632335706

Epoch: 5| Step: 5
Training loss: 2.5558645725250244
Validation loss: 2.071294783264078

Epoch: 5| Step: 6
Training loss: 2.442664861679077
Validation loss: 2.0726826344766924

Epoch: 5| Step: 7
Training loss: 1.829707384109497
Validation loss: 2.065053173290786

Epoch: 5| Step: 8
Training loss: 2.248347759246826
Validation loss: 2.0760199382740963

Epoch: 5| Step: 9
Training loss: 2.5666494369506836
Validation loss: 2.093970151357753

Epoch: 5| Step: 10
Training loss: 1.9692084789276123
Validation loss: 2.060373636984056

Epoch: 100| Step: 0
Training loss: 1.9352779388427734
Validation loss: 2.0449584504609466

Epoch: 5| Step: 1
Training loss: 1.9794445037841797
Validation loss: 2.050368127002511

Epoch: 5| Step: 2
Training loss: 3.0179057121276855
Validation loss: 2.0460548605970157

Epoch: 5| Step: 3
Training loss: 2.1356422901153564
Validation loss: 2.0986754022618777

Epoch: 5| Step: 4
Training loss: 2.2171785831451416
Validation loss: 2.055340750243074

Epoch: 5| Step: 5
Training loss: 1.809343934059143
Validation loss: 2.0722690807875765

Epoch: 5| Step: 6
Training loss: 2.397157669067383
Validation loss: 2.0602812959301855

Epoch: 5| Step: 7
Training loss: 2.480273723602295
Validation loss: 2.0702951544074604

Epoch: 5| Step: 8
Training loss: 1.702254056930542
Validation loss: 2.032054987005008

Epoch: 5| Step: 9
Training loss: 2.378810167312622
Validation loss: 2.063366428498299

Epoch: 5| Step: 10
Training loss: 3.06770658493042
Validation loss: 2.033881354075606

Epoch: 101| Step: 0
Training loss: 2.4880878925323486
Validation loss: 2.0485493418990925

Epoch: 5| Step: 1
Training loss: 2.4433939456939697
Validation loss: 2.0621315279314594

Epoch: 5| Step: 2
Training loss: 2.0021417140960693
Validation loss: 2.0265968435554096

Epoch: 5| Step: 3
Training loss: 2.437094211578369
Validation loss: 2.056973441954582

Epoch: 5| Step: 4
Training loss: 2.198173999786377
Validation loss: 2.073707808730423

Epoch: 5| Step: 5
Training loss: 2.496887445449829
Validation loss: 2.1006904853287565

Epoch: 5| Step: 6
Training loss: 2.282871723175049
Validation loss: 2.055555260309609

Epoch: 5| Step: 7
Training loss: 1.9896074533462524
Validation loss: 2.0688394679818103

Epoch: 5| Step: 8
Training loss: 2.0563313961029053
Validation loss: 2.0543082170588995

Epoch: 5| Step: 9
Training loss: 2.6000401973724365
Validation loss: 2.110670417867681

Epoch: 5| Step: 10
Training loss: 2.0145270824432373
Validation loss: 2.06647119855368

Epoch: 102| Step: 0
Training loss: 1.9734424352645874
Validation loss: 2.0879092088309665

Epoch: 5| Step: 1
Training loss: 1.9367191791534424
Validation loss: 2.0759510250501734

Epoch: 5| Step: 2
Training loss: 2.744631290435791
Validation loss: 2.0854926750224125

Epoch: 5| Step: 3
Training loss: 2.4060237407684326
Validation loss: 2.0575344947076615

Epoch: 5| Step: 4
Training loss: 2.8655858039855957
Validation loss: 2.0714991208045714

Epoch: 5| Step: 5
Training loss: 1.9678783416748047
Validation loss: 2.078568479066254

Epoch: 5| Step: 6
Training loss: 2.0246994495391846
Validation loss: 2.0739482577129076

Epoch: 5| Step: 7
Training loss: 2.748046875
Validation loss: 2.071900116500034

Epoch: 5| Step: 8
Training loss: 2.047762393951416
Validation loss: 2.059708538875785

Epoch: 5| Step: 9
Training loss: 2.479342222213745
Validation loss: 2.0643018176478725

Epoch: 5| Step: 10
Training loss: 1.711519718170166
Validation loss: 2.060604133913594

Epoch: 103| Step: 0
Training loss: 2.530639171600342
Validation loss: 2.0659359629436205

Epoch: 5| Step: 1
Training loss: 2.1872000694274902
Validation loss: 2.0468407702702347

Epoch: 5| Step: 2
Training loss: 2.633089780807495
Validation loss: 2.0883058630010134

Epoch: 5| Step: 3
Training loss: 2.180924654006958
Validation loss: 2.0824290706265356

Epoch: 5| Step: 4
Training loss: 1.9814484119415283
Validation loss: 2.065641087870444

Epoch: 5| Step: 5
Training loss: 2.483665704727173
Validation loss: 2.0846259286326747

Epoch: 5| Step: 6
Training loss: 1.7058565616607666
Validation loss: 2.0746233399196337

Epoch: 5| Step: 7
Training loss: 2.0148417949676514
Validation loss: 2.0940003984717914

Epoch: 5| Step: 8
Training loss: 2.341487407684326
Validation loss: 2.0729914826731526

Epoch: 5| Step: 9
Training loss: 2.4139647483825684
Validation loss: 2.0762620907957836

Epoch: 5| Step: 10
Training loss: 2.562039852142334
Validation loss: 2.08203887426725

Epoch: 104| Step: 0
Training loss: 2.2533791065216064
Validation loss: 2.070980098939711

Epoch: 5| Step: 1
Training loss: 2.7804007530212402
Validation loss: 2.078534351882114

Epoch: 5| Step: 2
Training loss: 1.5983303785324097
Validation loss: 2.1023707876923265

Epoch: 5| Step: 3
Training loss: 2.082887649536133
Validation loss: 2.0913320946437057

Epoch: 5| Step: 4
Training loss: 2.2543444633483887
Validation loss: 2.0837164437899025

Epoch: 5| Step: 5
Training loss: 3.2256386280059814
Validation loss: 2.0859891009587113

Epoch: 5| Step: 6
Training loss: 2.2831008434295654
Validation loss: 2.0584229115516908

Epoch: 5| Step: 7
Training loss: 1.7796781063079834
Validation loss: 2.0691056354071504

Epoch: 5| Step: 8
Training loss: 3.311154842376709
Validation loss: 2.083373773482538

Epoch: 5| Step: 9
Training loss: 1.8495429754257202
Validation loss: 2.0716586048885057

Epoch: 5| Step: 10
Training loss: 1.4057916402816772
Validation loss: 2.094290469282417

Epoch: 105| Step: 0
Training loss: 1.9414653778076172
Validation loss: 2.076195319493612

Epoch: 5| Step: 1
Training loss: 2.1461267471313477
Validation loss: 2.084517248215214

Epoch: 5| Step: 2
Training loss: 2.016839027404785
Validation loss: 2.0562690022171184

Epoch: 5| Step: 3
Training loss: 1.8101555109024048
Validation loss: 2.0597852955582323

Epoch: 5| Step: 4
Training loss: 3.0864059925079346
Validation loss: 2.040317295699991

Epoch: 5| Step: 5
Training loss: 2.840322971343994
Validation loss: 2.059364370120469

Epoch: 5| Step: 6
Training loss: 2.260720729827881
Validation loss: 2.0648601337145736

Epoch: 5| Step: 7
Training loss: 2.5496902465820312
Validation loss: 2.066724520857616

Epoch: 5| Step: 8
Training loss: 2.0400798320770264
Validation loss: 2.075676260455962

Epoch: 5| Step: 9
Training loss: 2.2297520637512207
Validation loss: 2.0533283346442768

Epoch: 5| Step: 10
Training loss: 1.8016599416732788
Validation loss: 2.058559630506782

Epoch: 106| Step: 0
Training loss: 1.7728904485702515
Validation loss: 2.069220112216088

Epoch: 5| Step: 1
Training loss: 2.126525402069092
Validation loss: 2.049944923770043

Epoch: 5| Step: 2
Training loss: 2.016247510910034
Validation loss: 2.0626129552882206

Epoch: 5| Step: 3
Training loss: 2.235255002975464
Validation loss: 2.060584413108005

Epoch: 5| Step: 4
Training loss: 2.307587146759033
Validation loss: 2.0711179112875335

Epoch: 5| Step: 5
Training loss: 1.7976438999176025
Validation loss: 2.0461379328081684

Epoch: 5| Step: 6
Training loss: 2.398707866668701
Validation loss: 2.0424930126436296

Epoch: 5| Step: 7
Training loss: 2.509852647781372
Validation loss: 2.059680454192623

Epoch: 5| Step: 8
Training loss: 2.4122719764709473
Validation loss: 2.0712633645662697

Epoch: 5| Step: 9
Training loss: 2.7053582668304443
Validation loss: 2.0524290184820853

Epoch: 5| Step: 10
Training loss: 2.7510173320770264
Validation loss: 2.0380831200589418

Epoch: 107| Step: 0
Training loss: 2.0573604106903076
Validation loss: 2.062535785859631

Epoch: 5| Step: 1
Training loss: 2.7659268379211426
Validation loss: 2.069980534174109

Epoch: 5| Step: 2
Training loss: 2.4443681240081787
Validation loss: 2.0715604033521426

Epoch: 5| Step: 3
Training loss: 1.7619082927703857
Validation loss: 2.0596123421063988

Epoch: 5| Step: 4
Training loss: 1.9706312417984009
Validation loss: 2.060619402957219

Epoch: 5| Step: 5
Training loss: 2.9302608966827393
Validation loss: 2.0776980410340014

Epoch: 5| Step: 6
Training loss: 2.1671011447906494
Validation loss: 2.0681874059861705

Epoch: 5| Step: 7
Training loss: 2.0182271003723145
Validation loss: 2.0738701166645175

Epoch: 5| Step: 8
Training loss: 2.4211575984954834
Validation loss: 2.056873216423937

Epoch: 5| Step: 9
Training loss: 1.689213752746582
Validation loss: 2.0869508507431194

Epoch: 5| Step: 10
Training loss: 2.6658098697662354
Validation loss: 2.075142575848487

Epoch: 108| Step: 0
Training loss: 2.6030125617980957
Validation loss: 2.0802339174414195

Epoch: 5| Step: 1
Training loss: 1.915492296218872
Validation loss: 2.056314524783883

Epoch: 5| Step: 2
Training loss: 2.408782482147217
Validation loss: 2.085496110300864

Epoch: 5| Step: 3
Training loss: 2.2209954261779785
Validation loss: 2.0604602752193326

Epoch: 5| Step: 4
Training loss: 1.5469157695770264
Validation loss: 2.0758223713085218

Epoch: 5| Step: 5
Training loss: 1.7997182607650757
Validation loss: 2.0688354879297237

Epoch: 5| Step: 6
Training loss: 2.6599555015563965
Validation loss: 2.0905717521585445

Epoch: 5| Step: 7
Training loss: 2.901982545852661
Validation loss: 2.09672014944015

Epoch: 5| Step: 8
Training loss: 1.781943917274475
Validation loss: 2.063190742205548

Epoch: 5| Step: 9
Training loss: 2.5974478721618652
Validation loss: 2.081720600845993

Epoch: 5| Step: 10
Training loss: 2.6183037757873535
Validation loss: 2.093151843676003

Epoch: 109| Step: 0
Training loss: 1.9413236379623413
Validation loss: 2.0468801888086463

Epoch: 5| Step: 1
Training loss: 3.262977123260498
Validation loss: 2.067456428722669

Epoch: 5| Step: 2
Training loss: 1.8286529779434204
Validation loss: 2.08960461103788

Epoch: 5| Step: 3
Training loss: 2.553894519805908
Validation loss: 2.05608094123102

Epoch: 5| Step: 4
Training loss: 1.9000108242034912
Validation loss: 2.071747386327354

Epoch: 5| Step: 5
Training loss: 2.1692380905151367
Validation loss: 2.077321962643695

Epoch: 5| Step: 6
Training loss: 1.9506633281707764
Validation loss: 2.0731355349222818

Epoch: 5| Step: 7
Training loss: 2.8746025562286377
Validation loss: 2.0745327421413955

Epoch: 5| Step: 8
Training loss: 2.0948336124420166
Validation loss: 2.0729679830612673

Epoch: 5| Step: 9
Training loss: 1.8562424182891846
Validation loss: 2.085071122774514

Epoch: 5| Step: 10
Training loss: 2.3582208156585693
Validation loss: 2.079612224332748

Epoch: 110| Step: 0
Training loss: 2.4035792350769043
Validation loss: 2.051587807234897

Epoch: 5| Step: 1
Training loss: 1.926659345626831
Validation loss: 2.066379480464484

Epoch: 5| Step: 2
Training loss: 2.7148776054382324
Validation loss: 2.0380451269047235

Epoch: 5| Step: 3
Training loss: 2.792031764984131
Validation loss: 2.089486059322152

Epoch: 5| Step: 4
Training loss: 2.2092411518096924
Validation loss: 2.0611028530264415

Epoch: 5| Step: 5
Training loss: 2.652616024017334
Validation loss: 2.0758003868082517

Epoch: 5| Step: 6
Training loss: 2.237222194671631
Validation loss: 2.0732491734207317

Epoch: 5| Step: 7
Training loss: 2.230576992034912
Validation loss: 2.078254971452939

Epoch: 5| Step: 8
Training loss: 2.054208755493164
Validation loss: 2.0587275989593996

Epoch: 5| Step: 9
Training loss: 1.9327430725097656
Validation loss: 2.0784816754761564

Epoch: 5| Step: 10
Training loss: 1.5960023403167725
Validation loss: 2.064834410144437

Epoch: 111| Step: 0
Training loss: 1.870612382888794
Validation loss: 2.0604119582842757

Epoch: 5| Step: 1
Training loss: 3.1070404052734375
Validation loss: 2.0756938662580264

Epoch: 5| Step: 2
Training loss: 1.6483253240585327
Validation loss: 2.075347928590672

Epoch: 5| Step: 3
Training loss: 1.7368472814559937
Validation loss: 2.064131618827902

Epoch: 5| Step: 4
Training loss: 2.3253231048583984
Validation loss: 2.0595693857439104

Epoch: 5| Step: 5
Training loss: 3.0493130683898926
Validation loss: 2.0655064941734396

Epoch: 5| Step: 6
Training loss: 2.1144959926605225
Validation loss: 2.048047491299209

Epoch: 5| Step: 7
Training loss: 2.1167588233947754
Validation loss: 2.0751364333655244

Epoch: 5| Step: 8
Training loss: 2.6156153678894043
Validation loss: 2.097666025161743

Epoch: 5| Step: 9
Training loss: 1.7802200317382812
Validation loss: 2.0881744918002876

Epoch: 5| Step: 10
Training loss: 2.559112310409546
Validation loss: 2.0577101861276934

Epoch: 112| Step: 0
Training loss: 2.8391077518463135
Validation loss: 2.06169403752973

Epoch: 5| Step: 1
Training loss: 2.2982187271118164
Validation loss: 2.0768141054338023

Epoch: 5| Step: 2
Training loss: 2.331080198287964
Validation loss: 2.0513074295495146

Epoch: 5| Step: 3
Training loss: 2.1430776119232178
Validation loss: 2.0583988697298112

Epoch: 5| Step: 4
Training loss: 2.8289499282836914
Validation loss: 2.0657281157790974

Epoch: 5| Step: 5
Training loss: 1.837048888206482
Validation loss: 2.0480478758453042

Epoch: 5| Step: 6
Training loss: 1.8450877666473389
Validation loss: 2.0441785230431506

Epoch: 5| Step: 7
Training loss: 2.627721071243286
Validation loss: 2.05022834449686

Epoch: 5| Step: 8
Training loss: 1.7951366901397705
Validation loss: 2.0713438346821773

Epoch: 5| Step: 9
Training loss: 2.251594066619873
Validation loss: 2.058203761295606

Epoch: 5| Step: 10
Training loss: 1.84243643283844
Validation loss: 2.0405676710990166

Epoch: 113| Step: 0
Training loss: 2.809044122695923
Validation loss: 2.0657126416442213

Epoch: 5| Step: 1
Training loss: 2.4056169986724854
Validation loss: 2.0396082683276107

Epoch: 5| Step: 2
Training loss: 2.052703380584717
Validation loss: 2.042003700810094

Epoch: 5| Step: 3
Training loss: 2.042919635772705
Validation loss: 2.0548173586527505

Epoch: 5| Step: 4
Training loss: 1.1579148769378662
Validation loss: 2.053298548985553

Epoch: 5| Step: 5
Training loss: 2.44079852104187
Validation loss: 2.07094745994896

Epoch: 5| Step: 6
Training loss: 2.340710163116455
Validation loss: 2.05626610273956

Epoch: 5| Step: 7
Training loss: 2.868466854095459
Validation loss: 2.082092305665375

Epoch: 5| Step: 8
Training loss: 2.5882785320281982
Validation loss: 2.051472069114767

Epoch: 5| Step: 9
Training loss: 1.8391239643096924
Validation loss: 2.0782578965669036

Epoch: 5| Step: 10
Training loss: 2.421020984649658
Validation loss: 2.065622370730164

Epoch: 114| Step: 0
Training loss: 1.3544118404388428
Validation loss: 2.059326378248071

Epoch: 5| Step: 1
Training loss: 3.524803876876831
Validation loss: 2.0492156808094313

Epoch: 5| Step: 2
Training loss: 1.9410778284072876
Validation loss: 2.0544498120584795

Epoch: 5| Step: 3
Training loss: 2.0245137214660645
Validation loss: 2.0343878858832904

Epoch: 5| Step: 4
Training loss: 2.1411783695220947
Validation loss: 2.060068504784697

Epoch: 5| Step: 5
Training loss: 2.1652607917785645
Validation loss: 2.062469240157835

Epoch: 5| Step: 6
Training loss: 2.931567907333374
Validation loss: 2.0566763775323027

Epoch: 5| Step: 7
Training loss: 1.8274520635604858
Validation loss: 2.069963429563789

Epoch: 5| Step: 8
Training loss: 1.7747375965118408
Validation loss: 2.051570644942663

Epoch: 5| Step: 9
Training loss: 2.8779187202453613
Validation loss: 2.060682676171744

Epoch: 5| Step: 10
Training loss: 2.049241304397583
Validation loss: 2.049549379656392

Epoch: 115| Step: 0
Training loss: 2.514395236968994
Validation loss: 2.063298886822116

Epoch: 5| Step: 1
Training loss: 2.480403423309326
Validation loss: 2.036378026008606

Epoch: 5| Step: 2
Training loss: 2.863124132156372
Validation loss: 2.030437707901001

Epoch: 5| Step: 3
Training loss: 1.9545902013778687
Validation loss: 2.0461127514480264

Epoch: 5| Step: 4
Training loss: 1.9755792617797852
Validation loss: 2.0343467189419653

Epoch: 5| Step: 5
Training loss: 2.4492056369781494
Validation loss: 2.0466856430935603

Epoch: 5| Step: 6
Training loss: 1.717101812362671
Validation loss: 2.0576797480224283

Epoch: 5| Step: 7
Training loss: 2.609780788421631
Validation loss: 2.043633499453145

Epoch: 5| Step: 8
Training loss: 1.9092738628387451
Validation loss: 2.0559105616743847

Epoch: 5| Step: 9
Training loss: 2.0643181800842285
Validation loss: 2.046830359325614

Epoch: 5| Step: 10
Training loss: 2.1002378463745117
Validation loss: 2.056017916689637

Epoch: 116| Step: 0
Training loss: 2.263577938079834
Validation loss: 2.0724608090616043

Epoch: 5| Step: 1
Training loss: 2.2599215507507324
Validation loss: 2.0579087426585536

Epoch: 5| Step: 2
Training loss: 2.503507137298584
Validation loss: 2.0563191085733394

Epoch: 5| Step: 3
Training loss: 2.198735237121582
Validation loss: 2.075566332827332

Epoch: 5| Step: 4
Training loss: 2.0787930488586426
Validation loss: 2.0541628663257887

Epoch: 5| Step: 5
Training loss: 2.0388102531433105
Validation loss: 2.0633671898995676

Epoch: 5| Step: 6
Training loss: 2.442736864089966
Validation loss: 2.055815044269767

Epoch: 5| Step: 7
Training loss: 2.6729602813720703
Validation loss: 2.0840298091211626

Epoch: 5| Step: 8
Training loss: 2.2060904502868652
Validation loss: 2.048675412772804

Epoch: 5| Step: 9
Training loss: 2.1434614658355713
Validation loss: 2.0757343922891924

Epoch: 5| Step: 10
Training loss: 1.7334263324737549
Validation loss: 2.0472534933397846

Epoch: 117| Step: 0
Training loss: 2.1112825870513916
Validation loss: 2.0604661510836695

Epoch: 5| Step: 1
Training loss: 2.2664685249328613
Validation loss: 2.070183487348659

Epoch: 5| Step: 2
Training loss: 2.8031163215637207
Validation loss: 2.0418305243215253

Epoch: 5| Step: 3
Training loss: 2.1503167152404785
Validation loss: 2.0443657546915035

Epoch: 5| Step: 4
Training loss: 1.6703517436981201
Validation loss: 2.066879657007033

Epoch: 5| Step: 5
Training loss: 2.3269381523132324
Validation loss: 2.046660820643107

Epoch: 5| Step: 6
Training loss: 2.0774667263031006
Validation loss: 2.047526623613091

Epoch: 5| Step: 7
Training loss: 2.236787796020508
Validation loss: 2.0625043838254866

Epoch: 5| Step: 8
Training loss: 2.1095244884490967
Validation loss: 2.0581820459776026

Epoch: 5| Step: 9
Training loss: 2.2107386589050293
Validation loss: 2.069244820584533

Epoch: 5| Step: 10
Training loss: 2.8702316284179688
Validation loss: 2.0654173128066526

Epoch: 118| Step: 0
Training loss: 2.786989688873291
Validation loss: 2.0637162834085445

Epoch: 5| Step: 1
Training loss: 1.9871718883514404
Validation loss: 2.036383354535667

Epoch: 5| Step: 2
Training loss: 2.226494312286377
Validation loss: 2.06283095318784

Epoch: 5| Step: 3
Training loss: 2.4854588508605957
Validation loss: 2.0777546487828737

Epoch: 5| Step: 4
Training loss: 2.197727680206299
Validation loss: 2.025550873048844

Epoch: 5| Step: 5
Training loss: 1.7840321063995361
Validation loss: 2.0545133083097395

Epoch: 5| Step: 6
Training loss: 1.9227869510650635
Validation loss: 2.043203220572523

Epoch: 5| Step: 7
Training loss: 2.1426780223846436
Validation loss: 2.0835838164052656

Epoch: 5| Step: 8
Training loss: 1.9129974842071533
Validation loss: 2.049790915622506

Epoch: 5| Step: 9
Training loss: 2.8314127922058105
Validation loss: 2.0574993548854703

Epoch: 5| Step: 10
Training loss: 2.2743823528289795
Validation loss: 2.0718858908581477

Epoch: 119| Step: 0
Training loss: 2.045926570892334
Validation loss: 2.051817940127465

Epoch: 5| Step: 1
Training loss: 2.15122652053833
Validation loss: 2.077854721776901

Epoch: 5| Step: 2
Training loss: 2.3444714546203613
Validation loss: 2.065930084515643

Epoch: 5| Step: 3
Training loss: 2.6487576961517334
Validation loss: 2.0593220559499597

Epoch: 5| Step: 4
Training loss: 1.966233491897583
Validation loss: 2.054135248225222

Epoch: 5| Step: 5
Training loss: 2.1998677253723145
Validation loss: 2.0937932793812086

Epoch: 5| Step: 6
Training loss: 2.46527099609375
Validation loss: 2.0358932915554253

Epoch: 5| Step: 7
Training loss: 2.983917474746704
Validation loss: 2.0378543971687235

Epoch: 5| Step: 8
Training loss: 2.416536808013916
Validation loss: 2.0716515074494066

Epoch: 5| Step: 9
Training loss: 1.4173269271850586
Validation loss: 2.0756985256748814

Epoch: 5| Step: 10
Training loss: 2.0715465545654297
Validation loss: 2.0447352983618297

Epoch: 120| Step: 0
Training loss: 1.9945472478866577
Validation loss: 2.0559979792564147

Epoch: 5| Step: 1
Training loss: 1.9387365579605103
Validation loss: 2.056380036056683

Epoch: 5| Step: 2
Training loss: 2.5594584941864014
Validation loss: 2.078445617870618

Epoch: 5| Step: 3
Training loss: 2.2752010822296143
Validation loss: 2.087119781842796

Epoch: 5| Step: 4
Training loss: 1.7063121795654297
Validation loss: 2.0773235341554046

Epoch: 5| Step: 5
Training loss: 2.287428855895996
Validation loss: 2.0720566805972847

Epoch: 5| Step: 6
Training loss: 1.9250385761260986
Validation loss: 2.0597767573530956

Epoch: 5| Step: 7
Training loss: 2.0187277793884277
Validation loss: 2.052612514906032

Epoch: 5| Step: 8
Training loss: 2.4925739765167236
Validation loss: 2.062122421879922

Epoch: 5| Step: 9
Training loss: 3.3214519023895264
Validation loss: 2.0708536255744194

Epoch: 5| Step: 10
Training loss: 2.1576805114746094
Validation loss: 2.0618147542399745

Epoch: 121| Step: 0
Training loss: 1.9769983291625977
Validation loss: 2.0625121670384563

Epoch: 5| Step: 1
Training loss: 3.0224783420562744
Validation loss: 2.087301831091604

Epoch: 5| Step: 2
Training loss: 1.8450558185577393
Validation loss: 2.0708824075678343

Epoch: 5| Step: 3
Training loss: 2.5009305477142334
Validation loss: 2.079919615099507

Epoch: 5| Step: 4
Training loss: 2.354647397994995
Validation loss: 2.056130366940652

Epoch: 5| Step: 5
Training loss: 2.2047762870788574
Validation loss: 2.0635549304305867

Epoch: 5| Step: 6
Training loss: 2.0553345680236816
Validation loss: 2.064345436711465

Epoch: 5| Step: 7
Training loss: 2.2098960876464844
Validation loss: 2.076502647451175

Epoch: 5| Step: 8
Training loss: 1.8496696949005127
Validation loss: 2.1055350970196467

Epoch: 5| Step: 9
Training loss: 2.4689948558807373
Validation loss: 2.0627661481980355

Epoch: 5| Step: 10
Training loss: 2.1934139728546143
Validation loss: 2.0880809458353187

Epoch: 122| Step: 0
Training loss: 2.221062183380127
Validation loss: 2.095473048507526

Epoch: 5| Step: 1
Training loss: 2.1286115646362305
Validation loss: 2.079918114087915

Epoch: 5| Step: 2
Training loss: 2.687314987182617
Validation loss: 2.062328423223188

Epoch: 5| Step: 3
Training loss: 2.284379482269287
Validation loss: 2.0722128140029086

Epoch: 5| Step: 4
Training loss: 2.7774932384490967
Validation loss: 2.071504815932243

Epoch: 5| Step: 5
Training loss: 2.031919002532959
Validation loss: 2.0472001670509257

Epoch: 5| Step: 6
Training loss: 2.399364471435547
Validation loss: 2.0568307368986067

Epoch: 5| Step: 7
Training loss: 1.2571220397949219
Validation loss: 2.0583475123169603

Epoch: 5| Step: 8
Training loss: 2.2942070960998535
Validation loss: 2.0517789599716023

Epoch: 5| Step: 9
Training loss: 2.2219505310058594
Validation loss: 2.0839500452882502

Epoch: 5| Step: 10
Training loss: 2.292558431625366
Validation loss: 2.0500373045603433

Epoch: 123| Step: 0
Training loss: 1.968923568725586
Validation loss: 2.0577060432844263

Epoch: 5| Step: 1
Training loss: 1.994826078414917
Validation loss: 2.0533157458869358

Epoch: 5| Step: 2
Training loss: 1.92470383644104
Validation loss: 2.053966006925029

Epoch: 5| Step: 3
Training loss: 2.3435921669006348
Validation loss: 2.0764026872573362

Epoch: 5| Step: 4
Training loss: 1.911465048789978
Validation loss: 2.068644577457059

Epoch: 5| Step: 5
Training loss: 2.22206711769104
Validation loss: 2.070847676646325

Epoch: 5| Step: 6
Training loss: 2.849696636199951
Validation loss: 2.1032434612192135

Epoch: 5| Step: 7
Training loss: 1.996691107749939
Validation loss: 2.039253229736

Epoch: 5| Step: 8
Training loss: 2.5428271293640137
Validation loss: 2.0583307435435634

Epoch: 5| Step: 9
Training loss: 2.467909097671509
Validation loss: 2.078211522871448

Epoch: 5| Step: 10
Training loss: 2.3870949745178223
Validation loss: 2.075855785800565

Epoch: 124| Step: 0
Training loss: 2.7821271419525146
Validation loss: 2.0628363650332213

Epoch: 5| Step: 1
Training loss: 2.5676941871643066
Validation loss: 2.077859027411348

Epoch: 5| Step: 2
Training loss: 1.6908693313598633
Validation loss: 2.0878213477391068

Epoch: 5| Step: 3
Training loss: 2.703509569168091
Validation loss: 2.0780642660715247

Epoch: 5| Step: 4
Training loss: 1.7857952117919922
Validation loss: 2.0651544294049664

Epoch: 5| Step: 5
Training loss: 2.572420835494995
Validation loss: 2.0688985752803024

Epoch: 5| Step: 6
Training loss: 1.840644121170044
Validation loss: 2.0740683476130166

Epoch: 5| Step: 7
Training loss: 1.7780141830444336
Validation loss: 2.036194961558106

Epoch: 5| Step: 8
Training loss: 2.243812084197998
Validation loss: 2.0815862071129585

Epoch: 5| Step: 9
Training loss: 1.8969885110855103
Validation loss: 2.063198768964378

Epoch: 5| Step: 10
Training loss: 2.7677173614501953
Validation loss: 2.063986470622401

Epoch: 125| Step: 0
Training loss: 2.038581371307373
Validation loss: 2.065305330420053

Epoch: 5| Step: 1
Training loss: 1.9411594867706299
Validation loss: 2.0644465800254577

Epoch: 5| Step: 2
Training loss: 1.6874358654022217
Validation loss: 2.080988940372262

Epoch: 5| Step: 3
Training loss: 2.0198750495910645
Validation loss: 2.0774183862952778

Epoch: 5| Step: 4
Training loss: 2.449887275695801
Validation loss: 2.089302791062222

Epoch: 5| Step: 5
Training loss: 1.8424450159072876
Validation loss: 2.104085563331522

Epoch: 5| Step: 6
Training loss: 3.153233051300049
Validation loss: 2.0573182311109317

Epoch: 5| Step: 7
Training loss: 2.6801977157592773
Validation loss: 2.0628666083017984

Epoch: 5| Step: 8
Training loss: 2.310821533203125
Validation loss: 2.083825816390335

Epoch: 5| Step: 9
Training loss: 2.4967379570007324
Validation loss: 2.076730648676554

Epoch: 5| Step: 10
Training loss: 2.007815361022949
Validation loss: 2.0517569434258247

Epoch: 126| Step: 0
Training loss: 2.56880784034729
Validation loss: 2.078961403139176

Epoch: 5| Step: 1
Training loss: 2.158362627029419
Validation loss: 2.0724422213851765

Epoch: 5| Step: 2
Training loss: 2.6235806941986084
Validation loss: 2.097767419712518

Epoch: 5| Step: 3
Training loss: 2.0827739238739014
Validation loss: 2.078435509435592

Epoch: 5| Step: 4
Training loss: 2.4698264598846436
Validation loss: 2.0753654305652907

Epoch: 5| Step: 5
Training loss: 2.37839937210083
Validation loss: 2.0731262712068457

Epoch: 5| Step: 6
Training loss: 2.3684372901916504
Validation loss: 2.0945410472090527

Epoch: 5| Step: 7
Training loss: 2.0198779106140137
Validation loss: 2.061787856522427

Epoch: 5| Step: 8
Training loss: 1.5290632247924805
Validation loss: 2.0506738667847006

Epoch: 5| Step: 9
Training loss: 2.2732138633728027
Validation loss: 2.0599747114284064

Epoch: 5| Step: 10
Training loss: 2.0687551498413086
Validation loss: 2.059504779436255

Epoch: 127| Step: 0
Training loss: 1.967503547668457
Validation loss: 2.073580236845119

Epoch: 5| Step: 1
Training loss: 1.9914891719818115
Validation loss: 2.0881933909590527

Epoch: 5| Step: 2
Training loss: 2.244011878967285
Validation loss: 2.055801901766049

Epoch: 5| Step: 3
Training loss: 2.7011685371398926
Validation loss: 2.0802316588740193

Epoch: 5| Step: 4
Training loss: 2.5916004180908203
Validation loss: 2.0704940313934

Epoch: 5| Step: 5
Training loss: 2.310659408569336
Validation loss: 2.047400971894623

Epoch: 5| Step: 6
Training loss: 1.9024617671966553
Validation loss: 2.061944928220523

Epoch: 5| Step: 7
Training loss: 2.5331385135650635
Validation loss: 2.0744912585904522

Epoch: 5| Step: 8
Training loss: 2.3862369060516357
Validation loss: 2.0587390699694232

Epoch: 5| Step: 9
Training loss: 2.122046947479248
Validation loss: 2.064963492014075

Epoch: 5| Step: 10
Training loss: 1.7423434257507324
Validation loss: 2.047946576149233

Epoch: 128| Step: 0
Training loss: 2.3588852882385254
Validation loss: 2.0687417496917067

Epoch: 5| Step: 1
Training loss: 2.6327121257781982
Validation loss: 2.071004585553241

Epoch: 5| Step: 2
Training loss: 1.8640180826187134
Validation loss: 2.0567120121371363

Epoch: 5| Step: 3
Training loss: 2.3933682441711426
Validation loss: 2.061438261821706

Epoch: 5| Step: 4
Training loss: 2.1190567016601562
Validation loss: 2.065419086845972

Epoch: 5| Step: 5
Training loss: 2.1036415100097656
Validation loss: 2.060063741540396

Epoch: 5| Step: 6
Training loss: 2.5418522357940674
Validation loss: 2.084482266056922

Epoch: 5| Step: 7
Training loss: 2.2998509407043457
Validation loss: 2.064591387266754

Epoch: 5| Step: 8
Training loss: 2.5267064571380615
Validation loss: 2.068576580734663

Epoch: 5| Step: 9
Training loss: 2.144826650619507
Validation loss: 2.0853910548712618

Epoch: 5| Step: 10
Training loss: 1.4264261722564697
Validation loss: 2.0727986545972925

Epoch: 129| Step: 0
Training loss: 2.236590623855591
Validation loss: 2.0491452268374863

Epoch: 5| Step: 1
Training loss: 3.3065991401672363
Validation loss: 2.088286675432677

Epoch: 5| Step: 2
Training loss: 2.0647006034851074
Validation loss: 2.0428220174645864

Epoch: 5| Step: 3
Training loss: 2.229937791824341
Validation loss: 2.0480525852531515

Epoch: 5| Step: 4
Training loss: 1.8723485469818115
Validation loss: 2.0855298696025724

Epoch: 5| Step: 5
Training loss: 2.0979182720184326
Validation loss: 2.064089307221033

Epoch: 5| Step: 6
Training loss: 2.010239601135254
Validation loss: 2.045727078632642

Epoch: 5| Step: 7
Training loss: 2.269893169403076
Validation loss: 2.05445465477564

Epoch: 5| Step: 8
Training loss: 2.6657321453094482
Validation loss: 2.040947639813987

Epoch: 5| Step: 9
Training loss: 1.840344786643982
Validation loss: 2.049318164907476

Epoch: 5| Step: 10
Training loss: 1.8985916376113892
Validation loss: 2.0667325668437506

Epoch: 130| Step: 0
Training loss: 3.1236255168914795
Validation loss: 2.0637608471737114

Epoch: 5| Step: 1
Training loss: 2.3078408241271973
Validation loss: 2.0660653498864945

Epoch: 5| Step: 2
Training loss: 2.0730371475219727
Validation loss: 2.0632658696943715

Epoch: 5| Step: 3
Training loss: 2.2511134147644043
Validation loss: 2.0666738838277836

Epoch: 5| Step: 4
Training loss: 2.024017810821533
Validation loss: 2.0611140920269873

Epoch: 5| Step: 5
Training loss: 2.4200010299682617
Validation loss: 2.0589914680809103

Epoch: 5| Step: 6
Training loss: 2.657510995864868
Validation loss: 2.0789783770038235

Epoch: 5| Step: 7
Training loss: 1.8082119226455688
Validation loss: 2.069629428207233

Epoch: 5| Step: 8
Training loss: 1.6065908670425415
Validation loss: 2.0924406256726993

Epoch: 5| Step: 9
Training loss: 2.3145511150360107
Validation loss: 2.0835538500098774

Epoch: 5| Step: 10
Training loss: 1.8439544439315796
Validation loss: 2.04284728470669

Epoch: 131| Step: 0
Training loss: 1.975206971168518
Validation loss: 2.079658546755391

Epoch: 5| Step: 1
Training loss: 2.938775062561035
Validation loss: 2.0830219958418157

Epoch: 5| Step: 2
Training loss: 2.4308905601501465
Validation loss: 2.067012074173138

Epoch: 5| Step: 3
Training loss: 2.4721591472625732
Validation loss: 2.0870318746054046

Epoch: 5| Step: 4
Training loss: 2.296302318572998
Validation loss: 2.097145313857704

Epoch: 5| Step: 5
Training loss: 2.0775389671325684
Validation loss: 2.0618883704626434

Epoch: 5| Step: 6
Training loss: 2.362292766571045
Validation loss: 2.0864498935719973

Epoch: 5| Step: 7
Training loss: 2.0358080863952637
Validation loss: 2.105172957143476

Epoch: 5| Step: 8
Training loss: 2.196270227432251
Validation loss: 2.0448886937992548

Epoch: 5| Step: 9
Training loss: 1.8163633346557617
Validation loss: 2.0561722914377847

Epoch: 5| Step: 10
Training loss: 1.9157633781433105
Validation loss: 2.0749854605684996

Epoch: 132| Step: 0
Training loss: 1.7636268138885498
Validation loss: 2.0859440501018236

Epoch: 5| Step: 1
Training loss: 2.843301296234131
Validation loss: 2.06800014357413

Epoch: 5| Step: 2
Training loss: 2.2539727687835693
Validation loss: 2.065878645066292

Epoch: 5| Step: 3
Training loss: 2.4094443321228027
Validation loss: 2.070588101622879

Epoch: 5| Step: 4
Training loss: 1.7536513805389404
Validation loss: 2.0742890962990383

Epoch: 5| Step: 5
Training loss: 2.314523220062256
Validation loss: 2.0552787114215154

Epoch: 5| Step: 6
Training loss: 1.718549132347107
Validation loss: 2.0418841095380884

Epoch: 5| Step: 7
Training loss: 2.149505376815796
Validation loss: 2.049672617707201

Epoch: 5| Step: 8
Training loss: 2.721342086791992
Validation loss: 2.07327930132548

Epoch: 5| Step: 9
Training loss: 2.2485809326171875
Validation loss: 2.076715887233775

Epoch: 5| Step: 10
Training loss: 2.244842529296875
Validation loss: 2.0517935688777635

Epoch: 133| Step: 0
Training loss: 2.2645602226257324
Validation loss: 2.0600514078652985

Epoch: 5| Step: 1
Training loss: 2.660611629486084
Validation loss: 2.082215662925474

Epoch: 5| Step: 2
Training loss: 2.3529276847839355
Validation loss: 2.0660190069547264

Epoch: 5| Step: 3
Training loss: 1.6372203826904297
Validation loss: 2.0578108269681215

Epoch: 5| Step: 4
Training loss: 1.8034098148345947
Validation loss: 2.0572002292961202

Epoch: 5| Step: 5
Training loss: 1.843727707862854
Validation loss: 2.0623918502561507

Epoch: 5| Step: 6
Training loss: 2.707768678665161
Validation loss: 2.070429491740401

Epoch: 5| Step: 7
Training loss: 2.3266348838806152
Validation loss: 2.0393480357303413

Epoch: 5| Step: 8
Training loss: 2.5198652744293213
Validation loss: 2.0629699691649406

Epoch: 5| Step: 9
Training loss: 1.8602546453475952
Validation loss: 2.084142800300352

Epoch: 5| Step: 10
Training loss: 2.4171371459960938
Validation loss: 2.0621502501990205

Epoch: 134| Step: 0
Training loss: 1.3728694915771484
Validation loss: 2.0428240427406887

Epoch: 5| Step: 1
Training loss: 1.4976167678833008
Validation loss: 2.0823516435520624

Epoch: 5| Step: 2
Training loss: 2.5421254634857178
Validation loss: 2.0656585539540937

Epoch: 5| Step: 3
Training loss: 2.406851291656494
Validation loss: 2.0738466426890385

Epoch: 5| Step: 4
Training loss: 1.7901909351348877
Validation loss: 2.072157972602434

Epoch: 5| Step: 5
Training loss: 2.141950845718384
Validation loss: 2.056635764337355

Epoch: 5| Step: 6
Training loss: 2.9284119606018066
Validation loss: 2.080713096485343

Epoch: 5| Step: 7
Training loss: 2.0980398654937744
Validation loss: 2.106399078522959

Epoch: 5| Step: 8
Training loss: 2.4816031455993652
Validation loss: 2.093918122271056

Epoch: 5| Step: 9
Training loss: 3.0537967681884766
Validation loss: 2.08284592628479

Epoch: 5| Step: 10
Training loss: 2.1476287841796875
Validation loss: 2.0848709280772875

Epoch: 135| Step: 0
Training loss: 2.0123696327209473
Validation loss: 2.097742017879281

Epoch: 5| Step: 1
Training loss: 2.5364296436309814
Validation loss: 2.0805825238586753

Epoch: 5| Step: 2
Training loss: 2.313112735748291
Validation loss: 2.1035942416037283

Epoch: 5| Step: 3
Training loss: 2.3417651653289795
Validation loss: 2.1039708942495365

Epoch: 5| Step: 4
Training loss: 2.0884037017822266
Validation loss: 2.1047961737519953

Epoch: 5| Step: 5
Training loss: 1.8706481456756592
Validation loss: 2.113124901248563

Epoch: 5| Step: 6
Training loss: 1.9892746210098267
Validation loss: 2.1030896837993334

Epoch: 5| Step: 7
Training loss: 2.4139418601989746
Validation loss: 2.1067784934915523

Epoch: 5| Step: 8
Training loss: 2.3357346057891846
Validation loss: 2.063533539413124

Epoch: 5| Step: 9
Training loss: 2.2849373817443848
Validation loss: 2.1055461847653953

Epoch: 5| Step: 10
Training loss: 2.4554407596588135
Validation loss: 2.0728211043983378

Epoch: 136| Step: 0
Training loss: 2.5396106243133545
Validation loss: 2.092951492596698

Epoch: 5| Step: 1
Training loss: 1.8293476104736328
Validation loss: 2.0793142767362696

Epoch: 5| Step: 2
Training loss: 2.2935335636138916
Validation loss: 2.093540412123485

Epoch: 5| Step: 3
Training loss: 3.209702968597412
Validation loss: 2.0942058537596013

Epoch: 5| Step: 4
Training loss: 1.8994801044464111
Validation loss: 2.1117159781917447

Epoch: 5| Step: 5
Training loss: 2.3174874782562256
Validation loss: 2.091784915616435

Epoch: 5| Step: 6
Training loss: 2.1593644618988037
Validation loss: 2.1052810556145123

Epoch: 5| Step: 7
Training loss: 2.416283369064331
Validation loss: 2.1092947195934992

Epoch: 5| Step: 8
Training loss: 2.310065269470215
Validation loss: 2.099195364982851

Epoch: 5| Step: 9
Training loss: 1.9763545989990234
Validation loss: 2.066710772052888

Epoch: 5| Step: 10
Training loss: 1.484919548034668
Validation loss: 2.087044915845317

Epoch: 137| Step: 0
Training loss: 1.7708085775375366
Validation loss: 2.065721514404461

Epoch: 5| Step: 1
Training loss: 2.548147678375244
Validation loss: 2.0576022260932514

Epoch: 5| Step: 2
Training loss: 2.3760979175567627
Validation loss: 2.08893810677272

Epoch: 5| Step: 3
Training loss: 2.385672092437744
Validation loss: 2.0750375922008226

Epoch: 5| Step: 4
Training loss: 2.0312061309814453
Validation loss: 2.0691018719826975

Epoch: 5| Step: 5
Training loss: 2.174466609954834
Validation loss: 2.078026789490895

Epoch: 5| Step: 6
Training loss: 2.193620204925537
Validation loss: 2.0451683254652124

Epoch: 5| Step: 7
Training loss: 2.541811466217041
Validation loss: 2.0482442507179837

Epoch: 5| Step: 8
Training loss: 2.742501735687256
Validation loss: 2.0757072151348157

Epoch: 5| Step: 9
Training loss: 1.4337866306304932
Validation loss: 2.0680908259525093

Epoch: 5| Step: 10
Training loss: 2.2365944385528564
Validation loss: 2.0696547954313216

Epoch: 138| Step: 0
Training loss: 2.33919095993042
Validation loss: 2.064653990089252

Epoch: 5| Step: 1
Training loss: 2.3828792572021484
Validation loss: 2.0653348148510022

Epoch: 5| Step: 2
Training loss: 1.900409460067749
Validation loss: 2.0669612243611324

Epoch: 5| Step: 3
Training loss: 2.5983376502990723
Validation loss: 2.0559848213708527

Epoch: 5| Step: 4
Training loss: 2.042436122894287
Validation loss: 2.0703699229865946

Epoch: 5| Step: 5
Training loss: 1.3956118822097778
Validation loss: 2.0567034059955227

Epoch: 5| Step: 6
Training loss: 2.593846082687378
Validation loss: 2.06869307128332

Epoch: 5| Step: 7
Training loss: 2.5097804069519043
Validation loss: 2.057685275231638

Epoch: 5| Step: 8
Training loss: 2.5353927612304688
Validation loss: 2.058692774465007

Epoch: 5| Step: 9
Training loss: 2.501096487045288
Validation loss: 2.0588655805075042

Epoch: 5| Step: 10
Training loss: 1.4547995328903198
Validation loss: 2.0674750945901357

Epoch: 139| Step: 0
Training loss: 2.5409579277038574
Validation loss: 2.069636316709621

Epoch: 5| Step: 1
Training loss: 2.3229382038116455
Validation loss: 2.0764723400915823

Epoch: 5| Step: 2
Training loss: 2.556098461151123
Validation loss: 2.0906474026300574

Epoch: 5| Step: 3
Training loss: 1.770643949508667
Validation loss: 2.0530179136542865

Epoch: 5| Step: 4
Training loss: 2.029381275177002
Validation loss: 2.068256652483376

Epoch: 5| Step: 5
Training loss: 2.1058316230773926
Validation loss: 2.09259823829897

Epoch: 5| Step: 6
Training loss: 2.051481008529663
Validation loss: 2.0702763449761177

Epoch: 5| Step: 7
Training loss: 2.086244821548462
Validation loss: 2.1077068108384327

Epoch: 5| Step: 8
Training loss: 2.526334047317505
Validation loss: 2.066985071346324

Epoch: 5| Step: 9
Training loss: 2.574246644973755
Validation loss: 2.082192846523818

Epoch: 5| Step: 10
Training loss: 1.7974052429199219
Validation loss: 2.0876016360457226

Epoch: 140| Step: 0
Training loss: 2.5931410789489746
Validation loss: 2.0770976543426514

Epoch: 5| Step: 1
Training loss: 2.3611888885498047
Validation loss: 2.0858353722480034

Epoch: 5| Step: 2
Training loss: 2.334826946258545
Validation loss: 2.0647601581388906

Epoch: 5| Step: 3
Training loss: 2.353476047515869
Validation loss: 2.0995162353720715

Epoch: 5| Step: 4
Training loss: 2.1208064556121826
Validation loss: 2.081629841558395

Epoch: 5| Step: 5
Training loss: 2.346071720123291
Validation loss: 2.068586867342713

Epoch: 5| Step: 6
Training loss: 2.0717761516571045
Validation loss: 2.0925841613482405

Epoch: 5| Step: 7
Training loss: 1.630811333656311
Validation loss: 2.1114098743725846

Epoch: 5| Step: 8
Training loss: 1.8247730731964111
Validation loss: 2.117664865268174

Epoch: 5| Step: 9
Training loss: 2.545797824859619
Validation loss: 2.1076186459551574

Epoch: 5| Step: 10
Training loss: 2.129974365234375
Validation loss: 2.098001023774506

Epoch: 141| Step: 0
Training loss: 2.3616461753845215
Validation loss: 2.0733562233627483

Epoch: 5| Step: 1
Training loss: 2.343470811843872
Validation loss: 2.1022460435026433

Epoch: 5| Step: 2
Training loss: 2.2887206077575684
Validation loss: 2.0992803406971756

Epoch: 5| Step: 3
Training loss: 2.381819486618042
Validation loss: 2.0999787417791222

Epoch: 5| Step: 4
Training loss: 1.460510015487671
Validation loss: 2.0805817009300314

Epoch: 5| Step: 5
Training loss: 2.8153810501098633
Validation loss: 2.080878148796738

Epoch: 5| Step: 6
Training loss: 2.0193841457366943
Validation loss: 2.0935536456364456

Epoch: 5| Step: 7
Training loss: 1.802302598953247
Validation loss: 2.069686761466406

Epoch: 5| Step: 8
Training loss: 2.301945924758911
Validation loss: 2.05130398273468

Epoch: 5| Step: 9
Training loss: 2.488356113433838
Validation loss: 2.0890201317366732

Epoch: 5| Step: 10
Training loss: 2.2033979892730713
Validation loss: 2.1152788157104165

Epoch: 142| Step: 0
Training loss: 1.8345718383789062
Validation loss: 2.090268963126726

Epoch: 5| Step: 1
Training loss: 1.8685600757598877
Validation loss: 2.1101668163012435

Epoch: 5| Step: 2
Training loss: 1.811611533164978
Validation loss: 2.076010855295325

Epoch: 5| Step: 3
Training loss: 2.5041415691375732
Validation loss: 2.0733182225176083

Epoch: 5| Step: 4
Training loss: 2.24497652053833
Validation loss: 2.089846246985979

Epoch: 5| Step: 5
Training loss: 2.0080485343933105
Validation loss: 2.0739725174442416

Epoch: 5| Step: 6
Training loss: 2.2694098949432373
Validation loss: 2.065187003022881

Epoch: 5| Step: 7
Training loss: 1.7987697124481201
Validation loss: 2.0797640200584167

Epoch: 5| Step: 8
Training loss: 2.969048023223877
Validation loss: 2.07143715248313

Epoch: 5| Step: 9
Training loss: 2.223815441131592
Validation loss: 2.0723907152811685

Epoch: 5| Step: 10
Training loss: 2.8145668506622314
Validation loss: 2.072174299147821

Epoch: 143| Step: 0
Training loss: 2.4720945358276367
Validation loss: 2.085699253184821

Epoch: 5| Step: 1
Training loss: 2.6009254455566406
Validation loss: 2.0745245461822837

Epoch: 5| Step: 2
Training loss: 1.7563083171844482
Validation loss: 2.0582867283974924

Epoch: 5| Step: 3
Training loss: 2.330986738204956
Validation loss: 2.0691555494903238

Epoch: 5| Step: 4
Training loss: 2.182356595993042
Validation loss: 2.0619067145932104

Epoch: 5| Step: 5
Training loss: 2.2831130027770996
Validation loss: 2.0580125624133694

Epoch: 5| Step: 6
Training loss: 1.7221488952636719
Validation loss: 2.0740914652424474

Epoch: 5| Step: 7
Training loss: 2.211184024810791
Validation loss: 2.0851054268498577

Epoch: 5| Step: 8
Training loss: 2.260124921798706
Validation loss: 2.0646485974711757

Epoch: 5| Step: 9
Training loss: 2.079237461090088
Validation loss: 2.078559849851875

Epoch: 5| Step: 10
Training loss: 2.519040584564209
Validation loss: 2.069716904752998

Epoch: 144| Step: 0
Training loss: 2.362916946411133
Validation loss: 2.0675264712302917

Epoch: 5| Step: 1
Training loss: 2.3168814182281494
Validation loss: 2.075277392582227

Epoch: 5| Step: 2
Training loss: 2.4446520805358887
Validation loss: 2.1019237823383783

Epoch: 5| Step: 3
Training loss: 2.22967529296875
Validation loss: 2.0482873916625977

Epoch: 5| Step: 4
Training loss: 2.001338005065918
Validation loss: 2.0830709959871028

Epoch: 5| Step: 5
Training loss: 2.4163222312927246
Validation loss: 2.0954116262415403

Epoch: 5| Step: 6
Training loss: 2.672046422958374
Validation loss: 2.0733903069649973

Epoch: 5| Step: 7
Training loss: 1.9967817068099976
Validation loss: 2.0748053135410434

Epoch: 5| Step: 8
Training loss: 1.9245656728744507
Validation loss: 2.0973283565172585

Epoch: 5| Step: 9
Training loss: 1.9247303009033203
Validation loss: 2.077858668501659

Epoch: 5| Step: 10
Training loss: 2.042829990386963
Validation loss: 2.0856802014894384

Epoch: 145| Step: 0
Training loss: 2.3159403800964355
Validation loss: 2.072000922695283

Epoch: 5| Step: 1
Training loss: 2.4401543140411377
Validation loss: 2.1015596107770036

Epoch: 5| Step: 2
Training loss: 2.552371025085449
Validation loss: 2.0995892119664017

Epoch: 5| Step: 3
Training loss: 2.849860429763794
Validation loss: 2.067753948191161

Epoch: 5| Step: 4
Training loss: 1.7966248989105225
Validation loss: 2.0842119211791665

Epoch: 5| Step: 5
Training loss: 2.1885650157928467
Validation loss: 2.0811074420969975

Epoch: 5| Step: 6
Training loss: 1.9069616794586182
Validation loss: 2.1029041992720736

Epoch: 5| Step: 7
Training loss: 2.1355183124542236
Validation loss: 2.062386546083676

Epoch: 5| Step: 8
Training loss: 2.8112339973449707
Validation loss: 2.08252538147793

Epoch: 5| Step: 9
Training loss: 1.3005942106246948
Validation loss: 2.1096265187827488

Epoch: 5| Step: 10
Training loss: 1.973163366317749
Validation loss: 2.065759474231351

Epoch: 146| Step: 0
Training loss: 1.570273756980896
Validation loss: 2.084875686194307

Epoch: 5| Step: 1
Training loss: 2.250868320465088
Validation loss: 2.091998969354937

Epoch: 5| Step: 2
Training loss: 2.9694066047668457
Validation loss: 2.066676534632201

Epoch: 5| Step: 3
Training loss: 2.3388466835021973
Validation loss: 2.064074859824232

Epoch: 5| Step: 4
Training loss: 1.9432792663574219
Validation loss: 2.057621035524594

Epoch: 5| Step: 5
Training loss: 2.187605619430542
Validation loss: 2.081413058824437

Epoch: 5| Step: 6
Training loss: 1.8702834844589233
Validation loss: 2.089103978167298

Epoch: 5| Step: 7
Training loss: 1.9227983951568604
Validation loss: 2.0741477371543966

Epoch: 5| Step: 8
Training loss: 2.63439679145813
Validation loss: 2.0823627889797254

Epoch: 5| Step: 9
Training loss: 1.9849603176116943
Validation loss: 2.082681930193337

Epoch: 5| Step: 10
Training loss: 2.7670905590057373
Validation loss: 2.0527789131287606

Epoch: 147| Step: 0
Training loss: 2.489772319793701
Validation loss: 2.0593103760032245

Epoch: 5| Step: 1
Training loss: 2.3490612506866455
Validation loss: 2.0672586143657727

Epoch: 5| Step: 2
Training loss: 2.2825686931610107
Validation loss: 2.0787147783464

Epoch: 5| Step: 3
Training loss: 2.6584296226501465
Validation loss: 2.061307055975801

Epoch: 5| Step: 4
Training loss: 2.039072036743164
Validation loss: 2.0588164239801388

Epoch: 5| Step: 5
Training loss: 1.9455267190933228
Validation loss: 2.0619790195136942

Epoch: 5| Step: 6
Training loss: 2.367490291595459
Validation loss: 2.0678220666864866

Epoch: 5| Step: 7
Training loss: 1.861785650253296
Validation loss: 2.08320947359967

Epoch: 5| Step: 8
Training loss: 2.482003688812256
Validation loss: 2.0792262400350263

Epoch: 5| Step: 9
Training loss: 1.9835891723632812
Validation loss: 2.0544845775891374

Epoch: 5| Step: 10
Training loss: 1.8581866025924683
Validation loss: 2.0865285140211864

Epoch: 148| Step: 0
Training loss: 2.348039150238037
Validation loss: 2.063757142712993

Epoch: 5| Step: 1
Training loss: 2.337111234664917
Validation loss: 2.0857514348081363

Epoch: 5| Step: 2
Training loss: 3.1505255699157715
Validation loss: 2.0940027672757386

Epoch: 5| Step: 3
Training loss: 1.3304035663604736
Validation loss: 2.070382966790148

Epoch: 5| Step: 4
Training loss: 2.798370122909546
Validation loss: 2.08041444260587

Epoch: 5| Step: 5
Training loss: 2.332303285598755
Validation loss: 2.0622425938165314

Epoch: 5| Step: 6
Training loss: 1.9270051717758179
Validation loss: 2.0748615059801327

Epoch: 5| Step: 7
Training loss: 1.9859737157821655
Validation loss: 2.0643607467733402

Epoch: 5| Step: 8
Training loss: 1.8175424337387085
Validation loss: 2.080239183159285

Epoch: 5| Step: 9
Training loss: 2.188580274581909
Validation loss: 2.077760427228866

Epoch: 5| Step: 10
Training loss: 2.018819808959961
Validation loss: 2.0488793516671784

Epoch: 149| Step: 0
Training loss: 2.653439521789551
Validation loss: 2.0517469798364947

Epoch: 5| Step: 1
Training loss: 2.740879535675049
Validation loss: 2.072900886176735

Epoch: 5| Step: 2
Training loss: 2.6140506267547607
Validation loss: 2.081636054541475

Epoch: 5| Step: 3
Training loss: 2.292562961578369
Validation loss: 2.10875783171705

Epoch: 5| Step: 4
Training loss: 1.9539527893066406
Validation loss: 2.079349804950017

Epoch: 5| Step: 5
Training loss: 2.6757099628448486
Validation loss: 2.050389917947913

Epoch: 5| Step: 6
Training loss: 1.7599550485610962
Validation loss: 2.1080922824080273

Epoch: 5| Step: 7
Training loss: 2.084400177001953
Validation loss: 2.0786559991939093

Epoch: 5| Step: 8
Training loss: 1.9605178833007812
Validation loss: 2.0987936860771588

Epoch: 5| Step: 9
Training loss: 1.9097360372543335
Validation loss: 2.09676420047719

Epoch: 5| Step: 10
Training loss: 1.5218820571899414
Validation loss: 2.1039240347441805

Epoch: 150| Step: 0
Training loss: 1.933707594871521
Validation loss: 2.0838353403152956

Epoch: 5| Step: 1
Training loss: 2.073802947998047
Validation loss: 2.1061948653190368

Epoch: 5| Step: 2
Training loss: 1.5598375797271729
Validation loss: 2.0851038809745543

Epoch: 5| Step: 3
Training loss: 2.5373737812042236
Validation loss: 2.102379973216723

Epoch: 5| Step: 4
Training loss: 1.936725378036499
Validation loss: 2.082326533973858

Epoch: 5| Step: 5
Training loss: 2.06744122505188
Validation loss: 2.092046909434821

Epoch: 5| Step: 6
Training loss: 2.5748274326324463
Validation loss: 2.0805005514493553

Epoch: 5| Step: 7
Training loss: 2.2650439739227295
Validation loss: 2.085487525950196

Epoch: 5| Step: 8
Training loss: 2.5155868530273438
Validation loss: 2.085268218030212

Epoch: 5| Step: 9
Training loss: 2.6219568252563477
Validation loss: 2.071978263957526

Epoch: 5| Step: 10
Training loss: 2.368441104888916
Validation loss: 2.07594084611503

Epoch: 151| Step: 0
Training loss: 2.65319561958313
Validation loss: 2.0763416726102113

Epoch: 5| Step: 1
Training loss: 2.177173137664795
Validation loss: 2.0565613508224487

Epoch: 5| Step: 2
Training loss: 2.4497036933898926
Validation loss: 2.074810025512531

Epoch: 5| Step: 3
Training loss: 1.7403450012207031
Validation loss: 2.0663041914663007

Epoch: 5| Step: 4
Training loss: 2.1018340587615967
Validation loss: 2.0600360657579158

Epoch: 5| Step: 5
Training loss: 2.4254684448242188
Validation loss: 2.0888397180905907

Epoch: 5| Step: 6
Training loss: 2.4111742973327637
Validation loss: 2.062877414047077

Epoch: 5| Step: 7
Training loss: 1.6064414978027344
Validation loss: 2.0772270669219313

Epoch: 5| Step: 8
Training loss: 1.872995376586914
Validation loss: 2.0718669737538984

Epoch: 5| Step: 9
Training loss: 2.4446730613708496
Validation loss: 2.090936455675351

Epoch: 5| Step: 10
Training loss: 2.404905319213867
Validation loss: 2.0686619820133334

Epoch: 152| Step: 0
Training loss: 2.1360132694244385
Validation loss: 2.065258217114274

Epoch: 5| Step: 1
Training loss: 2.80340313911438
Validation loss: 2.082356991306428

Epoch: 5| Step: 2
Training loss: 1.781802773475647
Validation loss: 2.0667660851632395

Epoch: 5| Step: 3
Training loss: 1.9032840728759766
Validation loss: 2.0719583021697177

Epoch: 5| Step: 4
Training loss: 2.709853172302246
Validation loss: 2.0551410016193183

Epoch: 5| Step: 5
Training loss: 2.231826066970825
Validation loss: 2.0836159080587406

Epoch: 5| Step: 6
Training loss: 2.192121744155884
Validation loss: 2.076098381832082

Epoch: 5| Step: 7
Training loss: 1.8633317947387695
Validation loss: 2.0854110551136795

Epoch: 5| Step: 8
Training loss: 2.503955841064453
Validation loss: 2.073118366220946

Epoch: 5| Step: 9
Training loss: 2.2498390674591064
Validation loss: 2.0558514069485407

Epoch: 5| Step: 10
Training loss: 1.7801460027694702
Validation loss: 2.051217690590889

Epoch: 153| Step: 0
Training loss: 2.073080539703369
Validation loss: 2.0810900683044107

Epoch: 5| Step: 1
Training loss: 2.433506488800049
Validation loss: 2.076503183252068

Epoch: 5| Step: 2
Training loss: 1.890373945236206
Validation loss: 2.078061734476397

Epoch: 5| Step: 3
Training loss: 1.7761539220809937
Validation loss: 2.1018455630989483

Epoch: 5| Step: 4
Training loss: 2.5683982372283936
Validation loss: 2.101086534479613

Epoch: 5| Step: 5
Training loss: 1.6309945583343506
Validation loss: 2.105882047325052

Epoch: 5| Step: 6
Training loss: 2.8414955139160156
Validation loss: 2.106369523591893

Epoch: 5| Step: 7
Training loss: 2.0679469108581543
Validation loss: 2.118800808024663

Epoch: 5| Step: 8
Training loss: 2.675797462463379
Validation loss: 2.0733751148305912

Epoch: 5| Step: 9
Training loss: 2.3162906169891357
Validation loss: 2.1196163059562765

Epoch: 5| Step: 10
Training loss: 2.1970303058624268
Validation loss: 2.088164673056654

Epoch: 154| Step: 0
Training loss: 2.420602321624756
Validation loss: 2.0840636773775985

Epoch: 5| Step: 1
Training loss: 1.8741319179534912
Validation loss: 2.0891364620577906

Epoch: 5| Step: 2
Training loss: 1.9194285869598389
Validation loss: 2.078846917357496

Epoch: 5| Step: 3
Training loss: 2.5235848426818848
Validation loss: 2.108874064619823

Epoch: 5| Step: 4
Training loss: 2.153080701828003
Validation loss: 2.100548936474708

Epoch: 5| Step: 5
Training loss: 2.237663745880127
Validation loss: 2.1129516170870875

Epoch: 5| Step: 6
Training loss: 2.4421489238739014
Validation loss: 2.096382664095971

Epoch: 5| Step: 7
Training loss: 2.6893954277038574
Validation loss: 2.09918947117303

Epoch: 5| Step: 8
Training loss: 2.311809539794922
Validation loss: 2.09904650462571

Epoch: 5| Step: 9
Training loss: 1.9002113342285156
Validation loss: 2.1185498288882676

Epoch: 5| Step: 10
Training loss: 1.5944772958755493
Validation loss: 2.114956622482628

Epoch: 155| Step: 0
Training loss: 2.904209613800049
Validation loss: 2.1267224434883363

Epoch: 5| Step: 1
Training loss: 1.9581553936004639
Validation loss: 2.0934348106384277

Epoch: 5| Step: 2
Training loss: 2.0957398414611816
Validation loss: 2.0566450677892214

Epoch: 5| Step: 3
Training loss: 2.2278733253479004
Validation loss: 2.1019161273074407

Epoch: 5| Step: 4
Training loss: 1.810525894165039
Validation loss: 2.0902127629967144

Epoch: 5| Step: 5
Training loss: 2.237375259399414
Validation loss: 2.094436299416327

Epoch: 5| Step: 6
Training loss: 2.401944637298584
Validation loss: 2.0893918404015164

Epoch: 5| Step: 7
Training loss: 2.123344898223877
Validation loss: 2.1088101094768894

Epoch: 5| Step: 8
Training loss: 2.2272095680236816
Validation loss: 2.095207534810548

Epoch: 5| Step: 9
Training loss: 2.522956609725952
Validation loss: 2.079546441314041

Epoch: 5| Step: 10
Training loss: 1.6861664056777954
Validation loss: 2.0990268773930048

Epoch: 156| Step: 0
Training loss: 1.86094069480896
Validation loss: 2.06376717680244

Epoch: 5| Step: 1
Training loss: 2.4066364765167236
Validation loss: 2.0876786132012644

Epoch: 5| Step: 2
Training loss: 2.047192096710205
Validation loss: 2.0680112941290743

Epoch: 5| Step: 3
Training loss: 1.8122707605361938
Validation loss: 2.094367378501482

Epoch: 5| Step: 4
Training loss: 1.8670530319213867
Validation loss: 2.0897198582208283

Epoch: 5| Step: 5
Training loss: 2.3055813312530518
Validation loss: 2.0757509444349553

Epoch: 5| Step: 6
Training loss: 2.5315494537353516
Validation loss: 2.069412990282941

Epoch: 5| Step: 7
Training loss: 2.708564043045044
Validation loss: 2.074425874217864

Epoch: 5| Step: 8
Training loss: 1.6191291809082031
Validation loss: 2.0990650269293014

Epoch: 5| Step: 9
Training loss: 2.968635082244873
Validation loss: 2.094590538291521

Epoch: 5| Step: 10
Training loss: 1.9327441453933716
Validation loss: 2.0768466021424983

Epoch: 157| Step: 0
Training loss: 2.412673234939575
Validation loss: 2.07076689504808

Epoch: 5| Step: 1
Training loss: 3.127531051635742
Validation loss: 2.098225957603865

Epoch: 5| Step: 2
Training loss: 1.4826823472976685
Validation loss: 2.093991377020395

Epoch: 5| Step: 3
Training loss: 2.1775918006896973
Validation loss: 2.061358044224401

Epoch: 5| Step: 4
Training loss: 2.7952189445495605
Validation loss: 2.0700439406979467

Epoch: 5| Step: 5
Training loss: 2.0370688438415527
Validation loss: 2.0450986610945834

Epoch: 5| Step: 6
Training loss: 2.2068324089050293
Validation loss: 2.0585970878601074

Epoch: 5| Step: 7
Training loss: 1.8961255550384521
Validation loss: 2.076085147037301

Epoch: 5| Step: 8
Training loss: 1.9933216571807861
Validation loss: 2.0698092919524

Epoch: 5| Step: 9
Training loss: 2.5092554092407227
Validation loss: 2.0771938831575456

Epoch: 5| Step: 10
Training loss: 1.4767937660217285
Validation loss: 2.0499728892439153

Epoch: 158| Step: 0
Training loss: 2.6259753704071045
Validation loss: 2.054970113180017

Epoch: 5| Step: 1
Training loss: 1.7116073369979858
Validation loss: 2.084223790835309

Epoch: 5| Step: 2
Training loss: 2.087859630584717
Validation loss: 2.0827904157741095

Epoch: 5| Step: 3
Training loss: 2.3286476135253906
Validation loss: 2.0617029423354776

Epoch: 5| Step: 4
Training loss: 1.8211034536361694
Validation loss: 2.0707911547794136

Epoch: 5| Step: 5
Training loss: 1.6747608184814453
Validation loss: 2.065634568532308

Epoch: 5| Step: 6
Training loss: 2.7678418159484863
Validation loss: 2.0795392374838553

Epoch: 5| Step: 7
Training loss: 2.2779603004455566
Validation loss: 2.0647753387369137

Epoch: 5| Step: 8
Training loss: 1.9231793880462646
Validation loss: 2.0498627924150035

Epoch: 5| Step: 9
Training loss: 2.5640337467193604
Validation loss: 2.0618559468177056

Epoch: 5| Step: 10
Training loss: 2.295260190963745
Validation loss: 2.068128042323615

Epoch: 159| Step: 0
Training loss: 2.0904297828674316
Validation loss: 2.076711690554055

Epoch: 5| Step: 1
Training loss: 2.351274013519287
Validation loss: 2.0602584782467095

Epoch: 5| Step: 2
Training loss: 2.176175594329834
Validation loss: 2.071410873884796

Epoch: 5| Step: 3
Training loss: 2.031379461288452
Validation loss: 2.0858768968171972

Epoch: 5| Step: 4
Training loss: 1.945432424545288
Validation loss: 2.099204312088669

Epoch: 5| Step: 5
Training loss: 1.9104076623916626
Validation loss: 2.101052197076941

Epoch: 5| Step: 6
Training loss: 1.9455054998397827
Validation loss: 2.111091131805092

Epoch: 5| Step: 7
Training loss: 2.3731625080108643
Validation loss: 2.0995201115967124

Epoch: 5| Step: 8
Training loss: 2.437649965286255
Validation loss: 2.077495754406016

Epoch: 5| Step: 9
Training loss: 2.568225383758545
Validation loss: 2.080052926976194

Epoch: 5| Step: 10
Training loss: 2.2819080352783203
Validation loss: 2.0945937684787217

Epoch: 160| Step: 0
Training loss: 1.907552719116211
Validation loss: 2.0978823643858715

Epoch: 5| Step: 1
Training loss: 2.6707558631896973
Validation loss: 2.113886264062697

Epoch: 5| Step: 2
Training loss: 2.0849084854125977
Validation loss: 2.114468423269128

Epoch: 5| Step: 3
Training loss: 1.871208906173706
Validation loss: 2.0651537769584247

Epoch: 5| Step: 4
Training loss: 2.786860227584839
Validation loss: 2.0853978485189457

Epoch: 5| Step: 5
Training loss: 1.7607234716415405
Validation loss: 2.0730772992616058

Epoch: 5| Step: 6
Training loss: 2.621727466583252
Validation loss: 2.080483651930286

Epoch: 5| Step: 7
Training loss: 2.175896167755127
Validation loss: 2.087215663284384

Epoch: 5| Step: 8
Training loss: 1.9406688213348389
Validation loss: 2.0982908279665056

Epoch: 5| Step: 9
Training loss: 2.1077449321746826
Validation loss: 2.07138055627064

Epoch: 5| Step: 10
Training loss: 2.0288116931915283
Validation loss: 2.08630379169218

Epoch: 161| Step: 0
Training loss: 1.464922308921814
Validation loss: 2.0966938080326205

Epoch: 5| Step: 1
Training loss: 1.5496056079864502
Validation loss: 2.081304278424991

Epoch: 5| Step: 2
Training loss: 2.69773530960083
Validation loss: 2.0912423928578696

Epoch: 5| Step: 3
Training loss: 2.048726797103882
Validation loss: 2.069307606707337

Epoch: 5| Step: 4
Training loss: 1.8080966472625732
Validation loss: 2.0589261644630024

Epoch: 5| Step: 5
Training loss: 2.7255172729492188
Validation loss: 2.0726733797339985

Epoch: 5| Step: 6
Training loss: 2.4019761085510254
Validation loss: 2.040323212582578

Epoch: 5| Step: 7
Training loss: 2.2749767303466797
Validation loss: 2.0556418895721436

Epoch: 5| Step: 8
Training loss: 2.297861337661743
Validation loss: 2.054369298360681

Epoch: 5| Step: 9
Training loss: 2.432460308074951
Validation loss: 2.074059993990006

Epoch: 5| Step: 10
Training loss: 2.537083387374878
Validation loss: 2.0470663680825183

Epoch: 162| Step: 0
Training loss: 2.3420958518981934
Validation loss: 2.0807225729829524

Epoch: 5| Step: 1
Training loss: 2.28593373298645
Validation loss: 2.05515048837149

Epoch: 5| Step: 2
Training loss: 2.445033550262451
Validation loss: 2.057785221325454

Epoch: 5| Step: 3
Training loss: 1.9717448949813843
Validation loss: 2.0718565435819727

Epoch: 5| Step: 4
Training loss: 2.3261938095092773
Validation loss: 2.084854628450127

Epoch: 5| Step: 5
Training loss: 2.626133441925049
Validation loss: 2.064909327414728

Epoch: 5| Step: 6
Training loss: 1.3345377445220947
Validation loss: 2.085192517567706

Epoch: 5| Step: 7
Training loss: 1.646864652633667
Validation loss: 2.0684498125506985

Epoch: 5| Step: 8
Training loss: 2.7169530391693115
Validation loss: 2.068445651761947

Epoch: 5| Step: 9
Training loss: 2.531737804412842
Validation loss: 2.08661622898553

Epoch: 5| Step: 10
Training loss: 1.8944181203842163
Validation loss: 2.073917717062017

Epoch: 163| Step: 0
Training loss: 2.0002784729003906
Validation loss: 2.0892435145634476

Epoch: 5| Step: 1
Training loss: 2.0568926334381104
Validation loss: 2.081353182433754

Epoch: 5| Step: 2
Training loss: 2.5500741004943848
Validation loss: 2.1077257971609793

Epoch: 5| Step: 3
Training loss: 2.1368064880371094
Validation loss: 2.089120213703443

Epoch: 5| Step: 4
Training loss: 2.281531810760498
Validation loss: 2.098679316941128

Epoch: 5| Step: 5
Training loss: 2.3980841636657715
Validation loss: 2.1066999486697617

Epoch: 5| Step: 6
Training loss: 2.2032523155212402
Validation loss: 2.0917231780226513

Epoch: 5| Step: 7
Training loss: 2.5152716636657715
Validation loss: 2.0894790259740685

Epoch: 5| Step: 8
Training loss: 2.057202100753784
Validation loss: 2.114729148085399

Epoch: 5| Step: 9
Training loss: 2.1234445571899414
Validation loss: 2.1037135585661857

Epoch: 5| Step: 10
Training loss: 1.7884806394577026
Validation loss: 2.095186254029633

Epoch: 164| Step: 0
Training loss: 2.0540308952331543
Validation loss: 2.091847235156644

Epoch: 5| Step: 1
Training loss: 1.7265303134918213
Validation loss: 2.097676323306176

Epoch: 5| Step: 2
Training loss: 2.122807502746582
Validation loss: 2.100411574045817

Epoch: 5| Step: 3
Training loss: 2.8093912601470947
Validation loss: 2.097575517110927

Epoch: 5| Step: 4
Training loss: 1.9027659893035889
Validation loss: 2.110677142297068

Epoch: 5| Step: 5
Training loss: 1.920462965965271
Validation loss: 2.080778078366351

Epoch: 5| Step: 6
Training loss: 2.6884942054748535
Validation loss: 2.095581926325316

Epoch: 5| Step: 7
Training loss: 2.082334518432617
Validation loss: 2.067626599342592

Epoch: 5| Step: 8
Training loss: 2.6979963779449463
Validation loss: 2.0800127752365603

Epoch: 5| Step: 9
Training loss: 2.039519786834717
Validation loss: 2.0836390577336794

Epoch: 5| Step: 10
Training loss: 2.2345573902130127
Validation loss: 2.087819258371989

Epoch: 165| Step: 0
Training loss: 2.466660976409912
Validation loss: 2.0892024796496154

Epoch: 5| Step: 1
Training loss: 1.772558569908142
Validation loss: 2.0867722893273957

Epoch: 5| Step: 2
Training loss: 1.7811992168426514
Validation loss: 2.052626215001588

Epoch: 5| Step: 3
Training loss: 2.236095905303955
Validation loss: 2.074812566080401

Epoch: 5| Step: 4
Training loss: 2.28027606010437
Validation loss: 2.0900483592864005

Epoch: 5| Step: 5
Training loss: 2.2412636280059814
Validation loss: 2.077879680100308

Epoch: 5| Step: 6
Training loss: 1.985287070274353
Validation loss: 2.0765718901029198

Epoch: 5| Step: 7
Training loss: 2.8122994899749756
Validation loss: 2.0766583104287424

Epoch: 5| Step: 8
Training loss: 2.0541110038757324
Validation loss: 2.077309082913142

Epoch: 5| Step: 9
Training loss: 2.5089364051818848
Validation loss: 2.101383391247001

Epoch: 5| Step: 10
Training loss: 1.943491816520691
Validation loss: 2.089201363184119

Epoch: 166| Step: 0
Training loss: 2.644460678100586
Validation loss: 2.066762544775522

Epoch: 5| Step: 1
Training loss: 2.513108730316162
Validation loss: 2.0691083579935055

Epoch: 5| Step: 2
Training loss: 2.332319736480713
Validation loss: 2.0674955255241803

Epoch: 5| Step: 3
Training loss: 1.5958818197250366
Validation loss: 2.0767700005603094

Epoch: 5| Step: 4
Training loss: 1.8392078876495361
Validation loss: 2.08075035772016

Epoch: 5| Step: 5
Training loss: 2.3703339099884033
Validation loss: 2.0834836549656366

Epoch: 5| Step: 6
Training loss: 2.1231331825256348
Validation loss: 2.0775968772108837

Epoch: 5| Step: 7
Training loss: 1.775730848312378
Validation loss: 2.0872944836975424

Epoch: 5| Step: 8
Training loss: 1.7969958782196045
Validation loss: 2.0735484989740516

Epoch: 5| Step: 9
Training loss: 2.5550568103790283
Validation loss: 2.0876598422245314

Epoch: 5| Step: 10
Training loss: 2.518536329269409
Validation loss: 2.0720827310316023

Epoch: 167| Step: 0
Training loss: 1.6820532083511353
Validation loss: 2.0878882715778966

Epoch: 5| Step: 1
Training loss: 1.6966392993927002
Validation loss: 2.07141270688785

Epoch: 5| Step: 2
Training loss: 2.289696216583252
Validation loss: 2.073918156726386

Epoch: 5| Step: 3
Training loss: 2.374906063079834
Validation loss: 2.0676502309819704

Epoch: 5| Step: 4
Training loss: 2.703929901123047
Validation loss: 2.0682754362783125

Epoch: 5| Step: 5
Training loss: 2.506218433380127
Validation loss: 2.0988975853048344

Epoch: 5| Step: 6
Training loss: 2.2848362922668457
Validation loss: 2.0551323762504

Epoch: 5| Step: 7
Training loss: 3.3635382652282715
Validation loss: 2.0706215622604534

Epoch: 5| Step: 8
Training loss: 1.4781744480133057
Validation loss: 2.066269318262736

Epoch: 5| Step: 9
Training loss: 1.5802806615829468
Validation loss: 2.070557217444143

Epoch: 5| Step: 10
Training loss: 2.0345635414123535
Validation loss: 2.0831821169904483

Epoch: 168| Step: 0
Training loss: 2.2426910400390625
Validation loss: 2.0968847197871052

Epoch: 5| Step: 1
Training loss: 3.163036823272705
Validation loss: 2.0988917760951544

Epoch: 5| Step: 2
Training loss: 1.9696983098983765
Validation loss: 2.089169518921965

Epoch: 5| Step: 3
Training loss: 2.392427444458008
Validation loss: 2.10453878166855

Epoch: 5| Step: 4
Training loss: 2.571469306945801
Validation loss: 2.114313030755648

Epoch: 5| Step: 5
Training loss: 2.033588409423828
Validation loss: 2.116406354852902

Epoch: 5| Step: 6
Training loss: 2.1546459197998047
Validation loss: 2.1001444042369886

Epoch: 5| Step: 7
Training loss: 2.211813449859619
Validation loss: 2.114272181705762

Epoch: 5| Step: 8
Training loss: 1.5395828485488892
Validation loss: 2.099791275557651

Epoch: 5| Step: 9
Training loss: 1.6551166772842407
Validation loss: 2.112201549673593

Epoch: 5| Step: 10
Training loss: 2.0996696949005127
Validation loss: 2.1191282656884964

Epoch: 169| Step: 0
Training loss: 1.876050353050232
Validation loss: 2.114132462009307

Epoch: 5| Step: 1
Training loss: 2.2553517818450928
Validation loss: 2.0926949977874756

Epoch: 5| Step: 2
Training loss: 2.220106601715088
Validation loss: 2.088180168982475

Epoch: 5| Step: 3
Training loss: 1.8322280645370483
Validation loss: 2.100981345740698

Epoch: 5| Step: 4
Training loss: 2.5403544902801514
Validation loss: 2.110297636319232

Epoch: 5| Step: 5
Training loss: 2.292572259902954
Validation loss: 2.068804755005785

Epoch: 5| Step: 6
Training loss: 1.9940868616104126
Validation loss: 2.1071189552225094

Epoch: 5| Step: 7
Training loss: 2.51865816116333
Validation loss: 2.0500715342901086

Epoch: 5| Step: 8
Training loss: 2.4904110431671143
Validation loss: 2.0856022027231034

Epoch: 5| Step: 9
Training loss: 1.8226566314697266
Validation loss: 2.063949264505858

Epoch: 5| Step: 10
Training loss: 2.3089001178741455
Validation loss: 2.065857448885518

Epoch: 170| Step: 0
Training loss: 2.1713333129882812
Validation loss: 2.087016433797857

Epoch: 5| Step: 1
Training loss: 2.2362260818481445
Validation loss: 2.0756962978711693

Epoch: 5| Step: 2
Training loss: 1.5623177289962769
Validation loss: 2.0754785896629415

Epoch: 5| Step: 3
Training loss: 3.004500389099121
Validation loss: 2.0817453938145793

Epoch: 5| Step: 4
Training loss: 2.701115846633911
Validation loss: 2.0732537956647974

Epoch: 5| Step: 5
Training loss: 2.0665788650512695
Validation loss: 2.073116957500417

Epoch: 5| Step: 6
Training loss: 1.8305752277374268
Validation loss: 2.104952343048588

Epoch: 5| Step: 7
Training loss: 2.3036508560180664
Validation loss: 2.105701026096139

Epoch: 5| Step: 8
Training loss: 2.253070116043091
Validation loss: 2.0974209052260204

Epoch: 5| Step: 9
Training loss: 2.325458288192749
Validation loss: 2.082646326352191

Epoch: 5| Step: 10
Training loss: 1.490706443786621
Validation loss: 2.10151276024439

Epoch: 171| Step: 0
Training loss: 2.3042054176330566
Validation loss: 2.081791639328003

Epoch: 5| Step: 1
Training loss: 1.2719703912734985
Validation loss: 2.0685572598570134

Epoch: 5| Step: 2
Training loss: 2.2229881286621094
Validation loss: 2.0658856617507113

Epoch: 5| Step: 3
Training loss: 2.024810552597046
Validation loss: 2.061118548916232

Epoch: 5| Step: 4
Training loss: 2.2270023822784424
Validation loss: 2.0801845263409358

Epoch: 5| Step: 5
Training loss: 2.1387698650360107
Validation loss: 2.0806948856640886

Epoch: 5| Step: 6
Training loss: 2.5677566528320312
Validation loss: 2.1015072368806407

Epoch: 5| Step: 7
Training loss: 2.5251104831695557
Validation loss: 2.087429415795111

Epoch: 5| Step: 8
Training loss: 2.7043700218200684
Validation loss: 2.118786693901144

Epoch: 5| Step: 9
Training loss: 1.8931801319122314
Validation loss: 2.099411156869704

Epoch: 5| Step: 10
Training loss: 2.158855676651001
Validation loss: 2.0940723034643356

Epoch: 172| Step: 0
Training loss: 1.2383908033370972
Validation loss: 2.09606590834997

Epoch: 5| Step: 1
Training loss: 2.147481918334961
Validation loss: 2.078414172254583

Epoch: 5| Step: 2
Training loss: 2.239441394805908
Validation loss: 2.0961204767227173

Epoch: 5| Step: 3
Training loss: 2.6264166831970215
Validation loss: 2.070074978695121

Epoch: 5| Step: 4
Training loss: 2.5105581283569336
Validation loss: 2.1075715121402534

Epoch: 5| Step: 5
Training loss: 2.0510337352752686
Validation loss: 2.086485796077277

Epoch: 5| Step: 6
Training loss: 2.227994680404663
Validation loss: 2.0858864399694625

Epoch: 5| Step: 7
Training loss: 2.5597264766693115
Validation loss: 2.0829726175595353

Epoch: 5| Step: 8
Training loss: 2.0164380073547363
Validation loss: 2.118529860691358

Epoch: 5| Step: 9
Training loss: 2.105022668838501
Validation loss: 2.0963452246881302

Epoch: 5| Step: 10
Training loss: 2.209038019180298
Validation loss: 2.075764040793142

Epoch: 173| Step: 0
Training loss: 2.6055495738983154
Validation loss: 2.0778548435498307

Epoch: 5| Step: 1
Training loss: 1.908515214920044
Validation loss: 2.0746563737110426

Epoch: 5| Step: 2
Training loss: 2.4788055419921875
Validation loss: 2.0784270199396278

Epoch: 5| Step: 3
Training loss: 1.3852636814117432
Validation loss: 2.117513996298595

Epoch: 5| Step: 4
Training loss: 1.9850009679794312
Validation loss: 2.0964093772313928

Epoch: 5| Step: 5
Training loss: 1.5408636331558228
Validation loss: 2.1181636459083966

Epoch: 5| Step: 6
Training loss: 2.4330391883850098
Validation loss: 2.06417275756918

Epoch: 5| Step: 7
Training loss: 2.680773973464966
Validation loss: 2.101977498300614

Epoch: 5| Step: 8
Training loss: 2.3216564655303955
Validation loss: 2.1065576204689602

Epoch: 5| Step: 9
Training loss: 2.18365740776062
Validation loss: 2.0783340443847

Epoch: 5| Step: 10
Training loss: 2.502218246459961
Validation loss: 2.089843516708702

Epoch: 174| Step: 0
Training loss: 2.0366299152374268
Validation loss: 2.0894852453662502

Epoch: 5| Step: 1
Training loss: 2.2365357875823975
Validation loss: 2.098517071816229

Epoch: 5| Step: 2
Training loss: 2.6271185874938965
Validation loss: 2.0786482672537527

Epoch: 5| Step: 3
Training loss: 2.9877383708953857
Validation loss: 2.098989817403978

Epoch: 5| Step: 4
Training loss: 1.3590741157531738
Validation loss: 2.069567299658252

Epoch: 5| Step: 5
Training loss: 2.2206897735595703
Validation loss: 2.1017048282008015

Epoch: 5| Step: 6
Training loss: 2.0970571041107178
Validation loss: 2.1016585121872606

Epoch: 5| Step: 7
Training loss: 2.2234785556793213
Validation loss: 2.0804751880707277

Epoch: 5| Step: 8
Training loss: 2.6255478858947754
Validation loss: 2.0971672483669814

Epoch: 5| Step: 9
Training loss: 1.5750043392181396
Validation loss: 2.0935300652698805

Epoch: 5| Step: 10
Training loss: 2.0614686012268066
Validation loss: 2.0937536044787337

Epoch: 175| Step: 0
Training loss: 2.3997642993927
Validation loss: 2.0870002597890873

Epoch: 5| Step: 1
Training loss: 2.492992877960205
Validation loss: 2.102018156359273

Epoch: 5| Step: 2
Training loss: 1.8440914154052734
Validation loss: 2.082558173005299

Epoch: 5| Step: 3
Training loss: 2.1824140548706055
Validation loss: 2.08900115823233

Epoch: 5| Step: 4
Training loss: 2.569197654724121
Validation loss: 2.078441401963593

Epoch: 5| Step: 5
Training loss: 2.4953415393829346
Validation loss: 2.081931857652562

Epoch: 5| Step: 6
Training loss: 2.3038835525512695
Validation loss: 2.0872102963027133

Epoch: 5| Step: 7
Training loss: 1.3871805667877197
Validation loss: 2.1252117054436797

Epoch: 5| Step: 8
Training loss: 2.0660085678100586
Validation loss: 2.0912352121004494

Epoch: 5| Step: 9
Training loss: 2.150911331176758
Validation loss: 2.084921222861095

Epoch: 5| Step: 10
Training loss: 2.041520357131958
Validation loss: 2.091918040347356

Epoch: 176| Step: 0
Training loss: 1.8539960384368896
Validation loss: 2.0954041199017595

Epoch: 5| Step: 1
Training loss: 1.7600911855697632
Validation loss: 2.0959179196306454

Epoch: 5| Step: 2
Training loss: 2.116323471069336
Validation loss: 2.0767686854126635

Epoch: 5| Step: 3
Training loss: 2.1956989765167236
Validation loss: 2.0643272002538047

Epoch: 5| Step: 4
Training loss: 2.520474910736084
Validation loss: 2.0674609163756013

Epoch: 5| Step: 5
Training loss: 1.5846580266952515
Validation loss: 2.059377852306571

Epoch: 5| Step: 6
Training loss: 1.9464843273162842
Validation loss: 2.0456818919028006

Epoch: 5| Step: 7
Training loss: 3.1515190601348877
Validation loss: 2.0665214600101596

Epoch: 5| Step: 8
Training loss: 1.966520071029663
Validation loss: 2.063307516036495

Epoch: 5| Step: 9
Training loss: 2.3577704429626465
Validation loss: 2.0422360999609834

Epoch: 5| Step: 10
Training loss: 2.4445674419403076
Validation loss: 2.071845431481638

Epoch: 177| Step: 0
Training loss: 1.275320053100586
Validation loss: 2.0706791313745643

Epoch: 5| Step: 1
Training loss: 2.4528167247772217
Validation loss: 2.079473223737491

Epoch: 5| Step: 2
Training loss: 2.018432140350342
Validation loss: 2.0604902057237524

Epoch: 5| Step: 3
Training loss: 2.1424918174743652
Validation loss: 2.0829246685069096

Epoch: 5| Step: 4
Training loss: 2.343759536743164
Validation loss: 2.0787097984744656

Epoch: 5| Step: 5
Training loss: 1.9677330255508423
Validation loss: 2.050056824120142

Epoch: 5| Step: 6
Training loss: 2.0465221405029297
Validation loss: 2.040424446905813

Epoch: 5| Step: 7
Training loss: 3.0516037940979004
Validation loss: 2.1057254460550126

Epoch: 5| Step: 8
Training loss: 2.540160894393921
Validation loss: 2.098773892207812

Epoch: 5| Step: 9
Training loss: 2.000293731689453
Validation loss: 2.073838560811935

Epoch: 5| Step: 10
Training loss: 2.4421346187591553
Validation loss: 2.0950065710211314

Epoch: 178| Step: 0
Training loss: 2.616433620452881
Validation loss: 2.0986522269505326

Epoch: 5| Step: 1
Training loss: 2.1450185775756836
Validation loss: 2.0522649390723116

Epoch: 5| Step: 2
Training loss: 2.5358693599700928
Validation loss: 2.090025048102102

Epoch: 5| Step: 3
Training loss: 2.787545680999756
Validation loss: 2.102100744042345

Epoch: 5| Step: 4
Training loss: 2.174419403076172
Validation loss: 2.1114435324104885

Epoch: 5| Step: 5
Training loss: 1.8883222341537476
Validation loss: 2.0988392201803063

Epoch: 5| Step: 6
Training loss: 1.7531770467758179
Validation loss: 2.082878415302564

Epoch: 5| Step: 7
Training loss: 1.9186499118804932
Validation loss: 2.0951947486528786

Epoch: 5| Step: 8
Training loss: 2.159562826156616
Validation loss: 2.1104144345047655

Epoch: 5| Step: 9
Training loss: 2.1930594444274902
Validation loss: 2.1066944932424896

Epoch: 5| Step: 10
Training loss: 1.7325156927108765
Validation loss: 2.1083884239196777

Epoch: 179| Step: 0
Training loss: 1.8803060054779053
Validation loss: 2.107559968066472

Epoch: 5| Step: 1
Training loss: 2.181126117706299
Validation loss: 2.0914337968313568

Epoch: 5| Step: 2
Training loss: 1.8645387887954712
Validation loss: 2.083625287138006

Epoch: 5| Step: 3
Training loss: 1.9404773712158203
Validation loss: 2.099783617963073

Epoch: 5| Step: 4
Training loss: 2.342982292175293
Validation loss: 2.0855005825719526

Epoch: 5| Step: 5
Training loss: 2.3424735069274902
Validation loss: 2.0879280746624036

Epoch: 5| Step: 6
Training loss: 2.3147940635681152
Validation loss: 2.084126434018535

Epoch: 5| Step: 7
Training loss: 2.0267815589904785
Validation loss: 2.0887156865930043

Epoch: 5| Step: 8
Training loss: 2.560029983520508
Validation loss: 2.07639774071273

Epoch: 5| Step: 9
Training loss: 1.8873474597930908
Validation loss: 2.0803560236448884

Epoch: 5| Step: 10
Training loss: 2.598623037338257
Validation loss: 2.0933595011311192

Epoch: 180| Step: 0
Training loss: 2.3335392475128174
Validation loss: 2.0951898354356007

Epoch: 5| Step: 1
Training loss: 2.0075087547302246
Validation loss: 2.0855440285898026

Epoch: 5| Step: 2
Training loss: 2.005924701690674
Validation loss: 2.0830320389040056

Epoch: 5| Step: 3
Training loss: 2.5224921703338623
Validation loss: 2.0937446573729157

Epoch: 5| Step: 4
Training loss: 2.2719039916992188
Validation loss: 2.067275006283996

Epoch: 5| Step: 5
Training loss: 1.9765846729278564
Validation loss: 2.0723128011149745

Epoch: 5| Step: 6
Training loss: 2.180574893951416
Validation loss: 2.050691996851275

Epoch: 5| Step: 7
Training loss: 2.3262414932250977
Validation loss: 2.0847365138351277

Epoch: 5| Step: 8
Training loss: 1.9627773761749268
Validation loss: 2.0845058220689014

Epoch: 5| Step: 9
Training loss: 2.3955650329589844
Validation loss: 2.055859404225503

Epoch: 5| Step: 10
Training loss: 1.9434549808502197
Validation loss: 2.0835069071862007

Epoch: 181| Step: 0
Training loss: 1.5240323543548584
Validation loss: 2.0833563086807088

Epoch: 5| Step: 1
Training loss: 2.247037649154663
Validation loss: 2.068836191649078

Epoch: 5| Step: 2
Training loss: 2.2169618606567383
Validation loss: 2.081741771390361

Epoch: 5| Step: 3
Training loss: 2.3931148052215576
Validation loss: 2.0775725636430966

Epoch: 5| Step: 4
Training loss: 2.2779812812805176
Validation loss: 2.074912199410059

Epoch: 5| Step: 5
Training loss: 2.3586387634277344
Validation loss: 2.0821529152572795

Epoch: 5| Step: 6
Training loss: 2.3515172004699707
Validation loss: 2.0950636786799275

Epoch: 5| Step: 7
Training loss: 1.9531428813934326
Validation loss: 2.1018522349737023

Epoch: 5| Step: 8
Training loss: 1.7446577548980713
Validation loss: 2.0778592376298803

Epoch: 5| Step: 9
Training loss: 2.600961923599243
Validation loss: 2.1225995786728395

Epoch: 5| Step: 10
Training loss: 1.9522234201431274
Validation loss: 2.105917963930356

Epoch: 182| Step: 0
Training loss: 2.4519271850585938
Validation loss: 2.0926957720069477

Epoch: 5| Step: 1
Training loss: 2.3810060024261475
Validation loss: 2.099257094885713

Epoch: 5| Step: 2
Training loss: 1.7931140661239624
Validation loss: 2.0984281596317085

Epoch: 5| Step: 3
Training loss: 3.004124879837036
Validation loss: 2.1028445946272982

Epoch: 5| Step: 4
Training loss: 2.2804312705993652
Validation loss: 2.1075087862630046

Epoch: 5| Step: 5
Training loss: 1.761035680770874
Validation loss: 2.102505532644128

Epoch: 5| Step: 6
Training loss: 1.4721373319625854
Validation loss: 2.096337446602442

Epoch: 5| Step: 7
Training loss: 1.8696428537368774
Validation loss: 2.095414976919851

Epoch: 5| Step: 8
Training loss: 2.43855357170105
Validation loss: 2.1407038165676977

Epoch: 5| Step: 9
Training loss: 2.2285966873168945
Validation loss: 2.103740653684062

Epoch: 5| Step: 10
Training loss: 2.4264907836914062
Validation loss: 2.106607849879931

Epoch: 183| Step: 0
Training loss: 2.3786215782165527
Validation loss: 2.1004825471549906

Epoch: 5| Step: 1
Training loss: 2.301295042037964
Validation loss: 2.117960686324745

Epoch: 5| Step: 2
Training loss: 2.4495131969451904
Validation loss: 2.1172974442922943

Epoch: 5| Step: 3
Training loss: 1.816300630569458
Validation loss: 2.085788414042483

Epoch: 5| Step: 4
Training loss: 2.0249273777008057
Validation loss: 2.0950097806992067

Epoch: 5| Step: 5
Training loss: 2.1913042068481445
Validation loss: 2.0913425581429594

Epoch: 5| Step: 6
Training loss: 3.0395445823669434
Validation loss: 2.0866627359902985

Epoch: 5| Step: 7
Training loss: 1.6445327997207642
Validation loss: 2.09043183377994

Epoch: 5| Step: 8
Training loss: 1.9775241613388062
Validation loss: 2.07692470858174

Epoch: 5| Step: 9
Training loss: 1.9084227085113525
Validation loss: 2.097084145392141

Epoch: 5| Step: 10
Training loss: 2.2396697998046875
Validation loss: 2.0667279715179117

Epoch: 184| Step: 0
Training loss: 1.9234302043914795
Validation loss: 2.110213409187973

Epoch: 5| Step: 1
Training loss: 2.2394137382507324
Validation loss: 2.085183466634443

Epoch: 5| Step: 2
Training loss: 1.9394581317901611
Validation loss: 2.0639839300545315

Epoch: 5| Step: 3
Training loss: 2.2934741973876953
Validation loss: 2.0606168521347867

Epoch: 5| Step: 4
Training loss: 2.783066987991333
Validation loss: 2.0503169541717856

Epoch: 5| Step: 5
Training loss: 2.183682680130005
Validation loss: 2.0649570521487983

Epoch: 5| Step: 6
Training loss: 2.190298557281494
Validation loss: 2.0488988225178053

Epoch: 5| Step: 7
Training loss: 2.3466572761535645
Validation loss: 2.072276956291609

Epoch: 5| Step: 8
Training loss: 2.2326412200927734
Validation loss: 2.05266720761535

Epoch: 5| Step: 9
Training loss: 2.139070987701416
Validation loss: 2.0682939355091383

Epoch: 5| Step: 10
Training loss: 1.710679531097412
Validation loss: 2.0474637862174743

Epoch: 185| Step: 0
Training loss: 2.0538878440856934
Validation loss: 2.0785276095072427

Epoch: 5| Step: 1
Training loss: 2.6561410427093506
Validation loss: 2.062409472721879

Epoch: 5| Step: 2
Training loss: 2.4225363731384277
Validation loss: 2.057808636337198

Epoch: 5| Step: 3
Training loss: 2.3236794471740723
Validation loss: 2.0511583512829197

Epoch: 5| Step: 4
Training loss: 1.9123684167861938
Validation loss: 2.0649133061849945

Epoch: 5| Step: 5
Training loss: 1.9245967864990234
Validation loss: 2.0501181053858932

Epoch: 5| Step: 6
Training loss: 2.1023597717285156
Validation loss: 2.0776171838083575

Epoch: 5| Step: 7
Training loss: 2.37919282913208
Validation loss: 2.0597916290324223

Epoch: 5| Step: 8
Training loss: 2.141918659210205
Validation loss: 2.099082895504531

Epoch: 5| Step: 9
Training loss: 1.8120473623275757
Validation loss: 2.100073002999829

Epoch: 5| Step: 10
Training loss: 2.1933255195617676
Validation loss: 2.0965664309840046

Epoch: 186| Step: 0
Training loss: 2.5959715843200684
Validation loss: 2.0993169379490677

Epoch: 5| Step: 1
Training loss: 2.5788025856018066
Validation loss: 2.1171364668876893

Epoch: 5| Step: 2
Training loss: 2.182279109954834
Validation loss: 2.110701951929318

Epoch: 5| Step: 3
Training loss: 2.0960443019866943
Validation loss: 2.0920187452787995

Epoch: 5| Step: 4
Training loss: 2.182511329650879
Validation loss: 2.1099236934415755

Epoch: 5| Step: 5
Training loss: 2.088681936264038
Validation loss: 2.1014114400391937

Epoch: 5| Step: 6
Training loss: 2.449207305908203
Validation loss: 2.1036790211995444

Epoch: 5| Step: 7
Training loss: 1.5826259851455688
Validation loss: 2.0912939079346193

Epoch: 5| Step: 8
Training loss: 2.0994625091552734
Validation loss: 2.0719334630556006

Epoch: 5| Step: 9
Training loss: 2.063173770904541
Validation loss: 2.095706784597007

Epoch: 5| Step: 10
Training loss: 1.9394762516021729
Validation loss: 2.0885804263494347

Epoch: 187| Step: 0
Training loss: 2.126469373703003
Validation loss: 2.078282076825378

Epoch: 5| Step: 1
Training loss: 1.7936084270477295
Validation loss: 2.074865916723846

Epoch: 5| Step: 2
Training loss: 2.639406442642212
Validation loss: 2.0873864030325286

Epoch: 5| Step: 3
Training loss: 1.9599330425262451
Validation loss: 2.0899291525604906

Epoch: 5| Step: 4
Training loss: 2.487107753753662
Validation loss: 2.1030373355393768

Epoch: 5| Step: 5
Training loss: 1.8296066522598267
Validation loss: 2.0932378948375745

Epoch: 5| Step: 6
Training loss: 2.384554386138916
Validation loss: 2.0714006103495115

Epoch: 5| Step: 7
Training loss: 2.314664363861084
Validation loss: 2.1184180628868843

Epoch: 5| Step: 8
Training loss: 1.766850471496582
Validation loss: 2.101531405602732

Epoch: 5| Step: 9
Training loss: 2.064777135848999
Validation loss: 2.073068536737914

Epoch: 5| Step: 10
Training loss: 2.3303377628326416
Validation loss: 2.1035778804491927

Epoch: 188| Step: 0
Training loss: 1.9860341548919678
Validation loss: 2.1028462340754848

Epoch: 5| Step: 1
Training loss: 2.0322070121765137
Validation loss: 2.09233586506177

Epoch: 5| Step: 2
Training loss: 2.3929054737091064
Validation loss: 2.093753069959661

Epoch: 5| Step: 3
Training loss: 1.6978709697723389
Validation loss: 2.1185027809553247

Epoch: 5| Step: 4
Training loss: 2.4590256214141846
Validation loss: 2.1055202381585234

Epoch: 5| Step: 5
Training loss: 2.899138927459717
Validation loss: 2.079260600510464

Epoch: 5| Step: 6
Training loss: 2.2994332313537598
Validation loss: 2.1013961799683107

Epoch: 5| Step: 7
Training loss: 2.396498203277588
Validation loss: 2.088397038880215

Epoch: 5| Step: 8
Training loss: 2.167090654373169
Validation loss: 2.0800640890675206

Epoch: 5| Step: 9
Training loss: 1.797202467918396
Validation loss: 2.0892194599233647

Epoch: 5| Step: 10
Training loss: 1.6762614250183105
Validation loss: 2.0786021896587905

Epoch: 189| Step: 0
Training loss: 2.5890133380889893
Validation loss: 2.0948143684735863

Epoch: 5| Step: 1
Training loss: 2.1882691383361816
Validation loss: 2.102545271637619

Epoch: 5| Step: 2
Training loss: 1.5134400129318237
Validation loss: 2.1139148435285016

Epoch: 5| Step: 3
Training loss: 2.179784059524536
Validation loss: 2.0752870780165478

Epoch: 5| Step: 4
Training loss: 1.59092378616333
Validation loss: 2.0917073603599303

Epoch: 5| Step: 5
Training loss: 2.4457075595855713
Validation loss: 2.124423788439843

Epoch: 5| Step: 6
Training loss: 2.144253730773926
Validation loss: 2.100647895566879

Epoch: 5| Step: 7
Training loss: 2.5180087089538574
Validation loss: 2.0759701254547283

Epoch: 5| Step: 8
Training loss: 2.1464710235595703
Validation loss: 2.1184370287003054

Epoch: 5| Step: 9
Training loss: 2.3698570728302
Validation loss: 2.1011962582988124

Epoch: 5| Step: 10
Training loss: 2.0548126697540283
Validation loss: 2.1274797890775945

Epoch: 190| Step: 0
Training loss: 2.3513741493225098
Validation loss: 2.09782059731022

Epoch: 5| Step: 1
Training loss: 2.177621603012085
Validation loss: 2.0861061978083786

Epoch: 5| Step: 2
Training loss: 2.308013439178467
Validation loss: 2.0831514148301977

Epoch: 5| Step: 3
Training loss: 1.8820078372955322
Validation loss: 2.0874159900091027

Epoch: 5| Step: 4
Training loss: 2.0172128677368164
Validation loss: 2.077143415327995

Epoch: 5| Step: 5
Training loss: 2.4896864891052246
Validation loss: 2.083998005877259

Epoch: 5| Step: 6
Training loss: 2.0776913166046143
Validation loss: 2.0867015469458794

Epoch: 5| Step: 7
Training loss: 1.9668232202529907
Validation loss: 2.0847479861269713

Epoch: 5| Step: 8
Training loss: 2.3675122261047363
Validation loss: 2.1041199955888974

Epoch: 5| Step: 9
Training loss: 1.763593077659607
Validation loss: 2.088200528134582

Epoch: 5| Step: 10
Training loss: 2.4479587078094482
Validation loss: 2.092706871289079

Epoch: 191| Step: 0
Training loss: 1.3542840480804443
Validation loss: 2.089982376303724

Epoch: 5| Step: 1
Training loss: 2.374495267868042
Validation loss: 2.1029163201649985

Epoch: 5| Step: 2
Training loss: 2.4494423866271973
Validation loss: 2.088188971242597

Epoch: 5| Step: 3
Training loss: 1.6860930919647217
Validation loss: 2.079524158149637

Epoch: 5| Step: 4
Training loss: 2.5628132820129395
Validation loss: 2.1108215752468316

Epoch: 5| Step: 5
Training loss: 2.727376937866211
Validation loss: 2.0946783340105446

Epoch: 5| Step: 6
Training loss: 2.303048610687256
Validation loss: 2.093535279714933

Epoch: 5| Step: 7
Training loss: 2.3327529430389404
Validation loss: 2.116257688050629

Epoch: 5| Step: 8
Training loss: 1.7511146068572998
Validation loss: 2.0702208075472104

Epoch: 5| Step: 9
Training loss: 1.7107360363006592
Validation loss: 2.1067863331046155

Epoch: 5| Step: 10
Training loss: 2.2700977325439453
Validation loss: 2.0885246492201284

Epoch: 192| Step: 0
Training loss: 2.039494037628174
Validation loss: 2.09113867949414

Epoch: 5| Step: 1
Training loss: 2.024801254272461
Validation loss: 2.106237757590509

Epoch: 5| Step: 2
Training loss: 2.4845919609069824
Validation loss: 2.097063959285777

Epoch: 5| Step: 3
Training loss: 2.369025468826294
Validation loss: 2.1128885041001024

Epoch: 5| Step: 4
Training loss: 2.6429247856140137
Validation loss: 2.109185390574958

Epoch: 5| Step: 5
Training loss: 2.2933502197265625
Validation loss: 2.0842999373712847

Epoch: 5| Step: 6
Training loss: 1.9474595785140991
Validation loss: 2.0956888301398164

Epoch: 5| Step: 7
Training loss: 2.0911202430725098
Validation loss: 2.0883448123931885

Epoch: 5| Step: 8
Training loss: 1.7113621234893799
Validation loss: 2.0870648417421567

Epoch: 5| Step: 9
Training loss: 2.046555280685425
Validation loss: 2.0858620212924097

Epoch: 5| Step: 10
Training loss: 1.9558433294296265
Validation loss: 2.0872367248740247

Epoch: 193| Step: 0
Training loss: 2.0988214015960693
Validation loss: 2.090359575004988

Epoch: 5| Step: 1
Training loss: 2.4344475269317627
Validation loss: 2.0756261502542803

Epoch: 5| Step: 2
Training loss: 2.5014498233795166
Validation loss: 2.0802515655435543

Epoch: 5| Step: 3
Training loss: 2.006218433380127
Validation loss: 2.0696404210982786

Epoch: 5| Step: 4
Training loss: 2.194704055786133
Validation loss: 2.0778568034530966

Epoch: 5| Step: 5
Training loss: 2.675999879837036
Validation loss: 2.042379950964323

Epoch: 5| Step: 6
Training loss: 1.792262315750122
Validation loss: 2.082872845793283

Epoch: 5| Step: 7
Training loss: 1.9890186786651611
Validation loss: 2.052494861746347

Epoch: 5| Step: 8
Training loss: 2.3306784629821777
Validation loss: 2.058789860817694

Epoch: 5| Step: 9
Training loss: 1.9795360565185547
Validation loss: 2.054066211946549

Epoch: 5| Step: 10
Training loss: 1.8359426259994507
Validation loss: 2.049986979012848

Epoch: 194| Step: 0
Training loss: 2.2191309928894043
Validation loss: 2.075833010417159

Epoch: 5| Step: 1
Training loss: 2.061112880706787
Validation loss: 2.080164555580385

Epoch: 5| Step: 2
Training loss: 2.258401870727539
Validation loss: 2.072052296771798

Epoch: 5| Step: 3
Training loss: 2.341015577316284
Validation loss: 2.0781721466331073

Epoch: 5| Step: 4
Training loss: 2.802255868911743
Validation loss: 2.0915742612654165

Epoch: 5| Step: 5
Training loss: 1.778354287147522
Validation loss: 2.0767143234129875

Epoch: 5| Step: 6
Training loss: 2.0462756156921387
Validation loss: 2.0726538563287384

Epoch: 5| Step: 7
Training loss: 1.9980895519256592
Validation loss: 2.0765820498107583

Epoch: 5| Step: 8
Training loss: 2.3267626762390137
Validation loss: 2.0796771741682485

Epoch: 5| Step: 9
Training loss: 1.7245620489120483
Validation loss: 2.076580762863159

Epoch: 5| Step: 10
Training loss: 2.2506656646728516
Validation loss: 2.0945398845980243

Epoch: 195| Step: 0
Training loss: 2.5448403358459473
Validation loss: 2.1054466565450034

Epoch: 5| Step: 1
Training loss: 2.138836145401001
Validation loss: 2.087959166496031

Epoch: 5| Step: 2
Training loss: 1.8132861852645874
Validation loss: 2.124540675070978

Epoch: 5| Step: 3
Training loss: 2.6956329345703125
Validation loss: 2.1215257016561364

Epoch: 5| Step: 4
Training loss: 2.182901620864868
Validation loss: 2.1009997513986405

Epoch: 5| Step: 5
Training loss: 1.834280252456665
Validation loss: 2.110689669527033

Epoch: 5| Step: 6
Training loss: 1.6426165103912354
Validation loss: 2.082797227367278

Epoch: 5| Step: 7
Training loss: 2.5635297298431396
Validation loss: 2.067682902018229

Epoch: 5| Step: 8
Training loss: 2.06907057762146
Validation loss: 2.089462623801283

Epoch: 5| Step: 9
Training loss: 2.1352009773254395
Validation loss: 2.1094354557734665

Epoch: 5| Step: 10
Training loss: 2.0124902725219727
Validation loss: 2.0892396357751664

Epoch: 196| Step: 0
Training loss: 2.5581068992614746
Validation loss: 2.1086057732182164

Epoch: 5| Step: 1
Training loss: 1.8932669162750244
Validation loss: 2.0934537815791305

Epoch: 5| Step: 2
Training loss: 2.1251730918884277
Validation loss: 2.109450432562059

Epoch: 5| Step: 3
Training loss: 2.433380603790283
Validation loss: 2.11926539738973

Epoch: 5| Step: 4
Training loss: 1.6918309926986694
Validation loss: 2.0981197716087423

Epoch: 5| Step: 5
Training loss: 2.018188238143921
Validation loss: 2.1168896562309674

Epoch: 5| Step: 6
Training loss: 2.127584457397461
Validation loss: 2.1082821328152894

Epoch: 5| Step: 7
Training loss: 2.5875306129455566
Validation loss: 2.1143351383106683

Epoch: 5| Step: 8
Training loss: 2.2891459465026855
Validation loss: 2.0858559326459

Epoch: 5| Step: 9
Training loss: 2.193927049636841
Validation loss: 2.1287335426576677

Epoch: 5| Step: 10
Training loss: 1.873617172241211
Validation loss: 2.1109886246342815

Epoch: 197| Step: 0
Training loss: 2.8045403957366943
Validation loss: 2.1096203173360517

Epoch: 5| Step: 1
Training loss: 2.176084041595459
Validation loss: 2.084554933732556

Epoch: 5| Step: 2
Training loss: 2.08662748336792
Validation loss: 2.09122545232055

Epoch: 5| Step: 3
Training loss: 1.8266332149505615
Validation loss: 2.083554531938286

Epoch: 5| Step: 4
Training loss: 1.8794019222259521
Validation loss: 2.116399963696798

Epoch: 5| Step: 5
Training loss: 1.988227128982544
Validation loss: 2.0792330465009137

Epoch: 5| Step: 6
Training loss: 1.6760728359222412
Validation loss: 2.071280961395592

Epoch: 5| Step: 7
Training loss: 1.9779847860336304
Validation loss: 2.09770941862496

Epoch: 5| Step: 8
Training loss: 2.2686948776245117
Validation loss: 2.0849418947773595

Epoch: 5| Step: 9
Training loss: 2.484590768814087
Validation loss: 2.0883698130166657

Epoch: 5| Step: 10
Training loss: 2.692789316177368
Validation loss: 2.0915922657135995

Epoch: 198| Step: 0
Training loss: 2.0314409732818604
Validation loss: 2.072690274125786

Epoch: 5| Step: 1
Training loss: 2.182452440261841
Validation loss: 2.0858464228209628

Epoch: 5| Step: 2
Training loss: 2.062779188156128
Validation loss: 2.0627899939014065

Epoch: 5| Step: 3
Training loss: 2.37892484664917
Validation loss: 2.073338052277924

Epoch: 5| Step: 4
Training loss: 2.446465253829956
Validation loss: 2.0639620955272386

Epoch: 5| Step: 5
Training loss: 1.6022422313690186
Validation loss: 2.079561274538758

Epoch: 5| Step: 6
Training loss: 1.7375915050506592
Validation loss: 2.048115973831505

Epoch: 5| Step: 7
Training loss: 2.3601818084716797
Validation loss: 2.0719753542254047

Epoch: 5| Step: 8
Training loss: 2.0818850994110107
Validation loss: 2.078460988178048

Epoch: 5| Step: 9
Training loss: 2.3103089332580566
Validation loss: 2.090467163311538

Epoch: 5| Step: 10
Training loss: 2.572970151901245
Validation loss: 2.0597531898047334

Epoch: 199| Step: 0
Training loss: 2.510180950164795
Validation loss: 2.0946144826950563

Epoch: 5| Step: 1
Training loss: 1.7155473232269287
Validation loss: 2.0693231244241037

Epoch: 5| Step: 2
Training loss: 1.9853061437606812
Validation loss: 2.1084274117664625

Epoch: 5| Step: 3
Training loss: 2.447441339492798
Validation loss: 2.061226938360481

Epoch: 5| Step: 4
Training loss: 2.887685775756836
Validation loss: 2.0951814228488552

Epoch: 5| Step: 5
Training loss: 2.086580514907837
Validation loss: 2.084989317001835

Epoch: 5| Step: 6
Training loss: 1.9100902080535889
Validation loss: 2.1085208692858295

Epoch: 5| Step: 7
Training loss: 2.1463704109191895
Validation loss: 2.0994829567529822

Epoch: 5| Step: 8
Training loss: 2.094040870666504
Validation loss: 2.1067443124709593

Epoch: 5| Step: 9
Training loss: 1.6453704833984375
Validation loss: 2.1105708563199608

Epoch: 5| Step: 10
Training loss: 2.3516287803649902
Validation loss: 2.0821218131690897

Epoch: 200| Step: 0
Training loss: 2.242427349090576
Validation loss: 2.121895244044642

Epoch: 5| Step: 1
Training loss: 1.974032998085022
Validation loss: 2.081927296935871

Epoch: 5| Step: 2
Training loss: 1.7563974857330322
Validation loss: 2.102461714898386

Epoch: 5| Step: 3
Training loss: 2.4874911308288574
Validation loss: 2.097097658341931

Epoch: 5| Step: 4
Training loss: 1.9216951131820679
Validation loss: 2.113466326908399

Epoch: 5| Step: 5
Training loss: 2.176168918609619
Validation loss: 2.1151248819084576

Epoch: 5| Step: 6
Training loss: 2.265360116958618
Validation loss: 2.084177553012807

Epoch: 5| Step: 7
Training loss: 2.5051541328430176
Validation loss: 2.091908444640457

Epoch: 5| Step: 8
Training loss: 1.8839681148529053
Validation loss: 2.0673162808982273

Epoch: 5| Step: 9
Training loss: 2.1717042922973633
Validation loss: 2.067844029395811

Epoch: 5| Step: 10
Training loss: 2.2574117183685303
Validation loss: 2.1003459038272982

Epoch: 201| Step: 0
Training loss: 2.3581128120422363
Validation loss: 2.0620704953388502

Epoch: 5| Step: 1
Training loss: 1.9741122722625732
Validation loss: 2.0725716211462535

Epoch: 5| Step: 2
Training loss: 1.81691575050354
Validation loss: 2.1034880543267853

Epoch: 5| Step: 3
Training loss: 1.6075143814086914
Validation loss: 2.092268386194783

Epoch: 5| Step: 4
Training loss: 2.1747446060180664
Validation loss: 2.0820901137526318

Epoch: 5| Step: 5
Training loss: 1.877462387084961
Validation loss: 2.0895730756944224

Epoch: 5| Step: 6
Training loss: 2.1684460639953613
Validation loss: 2.075247041640743

Epoch: 5| Step: 7
Training loss: 2.2525360584259033
Validation loss: 2.096451824711215

Epoch: 5| Step: 8
Training loss: 2.066436767578125
Validation loss: 2.0612686539209015

Epoch: 5| Step: 9
Training loss: 2.804394483566284
Validation loss: 2.0744903882344565

Epoch: 5| Step: 10
Training loss: 2.531622886657715
Validation loss: 2.074182577030633

Epoch: 202| Step: 0
Training loss: 2.4922618865966797
Validation loss: 2.0847342039949153

Epoch: 5| Step: 1
Training loss: 2.6947474479675293
Validation loss: 2.0868615245306366

Epoch: 5| Step: 2
Training loss: 1.841650366783142
Validation loss: 2.0957584611831175

Epoch: 5| Step: 3
Training loss: 1.70260488986969
Validation loss: 2.0948810564574374

Epoch: 5| Step: 4
Training loss: 2.29510760307312
Validation loss: 2.082206626092234

Epoch: 5| Step: 5
Training loss: 2.1965994834899902
Validation loss: 2.078367861368323

Epoch: 5| Step: 6
Training loss: 2.566596269607544
Validation loss: 2.05297157841344

Epoch: 5| Step: 7
Training loss: 2.157892942428589
Validation loss: 2.088480700728714

Epoch: 5| Step: 8
Training loss: 1.9040676355361938
Validation loss: 2.085722418241603

Epoch: 5| Step: 9
Training loss: 2.0664544105529785
Validation loss: 2.061066286538237

Epoch: 5| Step: 10
Training loss: 1.7944501638412476
Validation loss: 2.0791492923613517

Epoch: 203| Step: 0
Training loss: 2.005922317504883
Validation loss: 2.0548961470204015

Epoch: 5| Step: 1
Training loss: 2.4585671424865723
Validation loss: 2.0652042383788736

Epoch: 5| Step: 2
Training loss: 2.219362735748291
Validation loss: 2.0781247513268584

Epoch: 5| Step: 3
Training loss: 1.9025697708129883
Validation loss: 2.075569422014298

Epoch: 5| Step: 4
Training loss: 1.6417224407196045
Validation loss: 2.090515605864986

Epoch: 5| Step: 5
Training loss: 1.9317537546157837
Validation loss: 2.067911450580884

Epoch: 5| Step: 6
Training loss: 2.416074752807617
Validation loss: 2.1165900999499905

Epoch: 5| Step: 7
Training loss: 2.1025514602661133
Validation loss: 2.1052232609000257

Epoch: 5| Step: 8
Training loss: 2.429206609725952
Validation loss: 2.099398869340138

Epoch: 5| Step: 9
Training loss: 1.8694846630096436
Validation loss: 2.100971434706001

Epoch: 5| Step: 10
Training loss: 2.814093828201294
Validation loss: 2.117468616013886

Epoch: 204| Step: 0
Training loss: 2.0318689346313477
Validation loss: 2.1026378062463578

Epoch: 5| Step: 1
Training loss: 2.529737949371338
Validation loss: 2.08964370143029

Epoch: 5| Step: 2
Training loss: 2.3663041591644287
Validation loss: 2.087207617298249

Epoch: 5| Step: 3
Training loss: 1.8510684967041016
Validation loss: 2.108215117967257

Epoch: 5| Step: 4
Training loss: 2.4384751319885254
Validation loss: 2.1074703252443703

Epoch: 5| Step: 5
Training loss: 2.1847662925720215
Validation loss: 2.120185354704498

Epoch: 5| Step: 6
Training loss: 1.5167615413665771
Validation loss: 2.106121181159891

Epoch: 5| Step: 7
Training loss: 2.0586836338043213
Validation loss: 2.1136332276046916

Epoch: 5| Step: 8
Training loss: 2.399296998977661
Validation loss: 2.0857763521132933

Epoch: 5| Step: 9
Training loss: 2.150559186935425
Validation loss: 2.114209895492882

Epoch: 5| Step: 10
Training loss: 2.1329591274261475
Validation loss: 2.097254730040027

Epoch: 205| Step: 0
Training loss: 2.6639726161956787
Validation loss: 2.0944036950347242

Epoch: 5| Step: 1
Training loss: 2.664400815963745
Validation loss: 2.1248762684483684

Epoch: 5| Step: 2
Training loss: 1.9176619052886963
Validation loss: 2.1126018929225143

Epoch: 5| Step: 3
Training loss: 1.5713658332824707
Validation loss: 2.113324449908349

Epoch: 5| Step: 4
Training loss: 2.3533244132995605
Validation loss: 2.0890286686599895

Epoch: 5| Step: 5
Training loss: 2.4130845069885254
Validation loss: 2.0996193296165875

Epoch: 5| Step: 6
Training loss: 1.8831422328948975
Validation loss: 2.089627100575355

Epoch: 5| Step: 7
Training loss: 1.6440684795379639
Validation loss: 2.0782686305302445

Epoch: 5| Step: 8
Training loss: 2.2637996673583984
Validation loss: 2.076836516780238

Epoch: 5| Step: 9
Training loss: 1.8764235973358154
Validation loss: 2.066329730454312

Epoch: 5| Step: 10
Training loss: 2.4441981315612793
Validation loss: 2.0966167526860393

Epoch: 206| Step: 0
Training loss: 2.4770560264587402
Validation loss: 2.091390271340647

Epoch: 5| Step: 1
Training loss: 1.8087116479873657
Validation loss: 2.0880574154597458

Epoch: 5| Step: 2
Training loss: 2.0375723838806152
Validation loss: 2.062407765337216

Epoch: 5| Step: 3
Training loss: 2.262516498565674
Validation loss: 2.092394339141025

Epoch: 5| Step: 4
Training loss: 1.1381356716156006
Validation loss: 2.0826532353637037

Epoch: 5| Step: 5
Training loss: 2.543062925338745
Validation loss: 2.100649001777813

Epoch: 5| Step: 6
Training loss: 1.997905969619751
Validation loss: 2.0524543895516345

Epoch: 5| Step: 7
Training loss: 2.414942502975464
Validation loss: 2.095752718628094

Epoch: 5| Step: 8
Training loss: 2.1789047718048096
Validation loss: 2.075315385736445

Epoch: 5| Step: 9
Training loss: 2.730550527572632
Validation loss: 2.0908282033858763

Epoch: 5| Step: 10
Training loss: 2.101716995239258
Validation loss: 2.0913369617154522

Epoch: 207| Step: 0
Training loss: 2.2664575576782227
Validation loss: 2.062627246302943

Epoch: 5| Step: 1
Training loss: 1.9660640954971313
Validation loss: 2.0574596722920737

Epoch: 5| Step: 2
Training loss: 2.8223700523376465
Validation loss: 2.0869648687301146

Epoch: 5| Step: 3
Training loss: 2.34006404876709
Validation loss: 2.097228556550959

Epoch: 5| Step: 4
Training loss: 1.6806964874267578
Validation loss: 2.0769476403472242

Epoch: 5| Step: 5
Training loss: 2.3175559043884277
Validation loss: 2.0789918476535427

Epoch: 5| Step: 6
Training loss: 1.6768553256988525
Validation loss: 2.061981160153625

Epoch: 5| Step: 7
Training loss: 2.029217481613159
Validation loss: 2.077091381114016

Epoch: 5| Step: 8
Training loss: 1.5372860431671143
Validation loss: 2.0806768068703274

Epoch: 5| Step: 9
Training loss: 2.2731781005859375
Validation loss: 2.0784175575420423

Epoch: 5| Step: 10
Training loss: 2.5169155597686768
Validation loss: 2.074875457312471

Epoch: 208| Step: 0
Training loss: 2.058567523956299
Validation loss: 2.0813711843182965

Epoch: 5| Step: 1
Training loss: 1.5606648921966553
Validation loss: 2.076201344049105

Epoch: 5| Step: 2
Training loss: 2.083738088607788
Validation loss: 2.1104535902700117

Epoch: 5| Step: 3
Training loss: 2.025277853012085
Validation loss: 2.092576015380121

Epoch: 5| Step: 4
Training loss: 2.418973684310913
Validation loss: 2.066879416024813

Epoch: 5| Step: 5
Training loss: 1.9580119848251343
Validation loss: 2.0720077227520686

Epoch: 5| Step: 6
Training loss: 2.386960506439209
Validation loss: 2.0757479744572795

Epoch: 5| Step: 7
Training loss: 2.256345272064209
Validation loss: 2.079035461589854

Epoch: 5| Step: 8
Training loss: 2.5750598907470703
Validation loss: 2.075841840877328

Epoch: 5| Step: 9
Training loss: 2.0231387615203857
Validation loss: 2.0838626982063375

Epoch: 5| Step: 10
Training loss: 2.1541554927825928
Validation loss: 2.0951222527411675

Epoch: 209| Step: 0
Training loss: 2.5025198459625244
Validation loss: 2.08953591315977

Epoch: 5| Step: 1
Training loss: 1.9599571228027344
Validation loss: 2.081773237515521

Epoch: 5| Step: 2
Training loss: 2.0954489707946777
Validation loss: 2.096111023297874

Epoch: 5| Step: 3
Training loss: 2.006859540939331
Validation loss: 2.08264991288544

Epoch: 5| Step: 4
Training loss: 1.666151762008667
Validation loss: 2.0971620108491633

Epoch: 5| Step: 5
Training loss: 2.4080586433410645
Validation loss: 2.0792508971306587

Epoch: 5| Step: 6
Training loss: 1.9932918548583984
Validation loss: 2.069076274030952

Epoch: 5| Step: 7
Training loss: 2.142029285430908
Validation loss: 2.102219263712565

Epoch: 5| Step: 8
Training loss: 2.5087904930114746
Validation loss: 2.1184166605754564

Epoch: 5| Step: 9
Training loss: 2.2434728145599365
Validation loss: 2.1191256482114076

Epoch: 5| Step: 10
Training loss: 2.09037446975708
Validation loss: 2.082151456545758

Epoch: 210| Step: 0
Training loss: 2.225454568862915
Validation loss: 2.0936757390217116

Epoch: 5| Step: 1
Training loss: 2.327993869781494
Validation loss: 2.109663414698775

Epoch: 5| Step: 2
Training loss: 1.6696395874023438
Validation loss: 2.109904635337091

Epoch: 5| Step: 3
Training loss: 1.9693615436553955
Validation loss: 2.0920900349975913

Epoch: 5| Step: 4
Training loss: 2.421464443206787
Validation loss: 2.0785362976853565

Epoch: 5| Step: 5
Training loss: 2.1817307472229004
Validation loss: 2.1073865223956365

Epoch: 5| Step: 6
Training loss: 2.0110199451446533
Validation loss: 2.087662268710393

Epoch: 5| Step: 7
Training loss: 2.057433605194092
Validation loss: 2.091333422609555

Epoch: 5| Step: 8
Training loss: 2.454620599746704
Validation loss: 2.1062341890027447

Epoch: 5| Step: 9
Training loss: 1.9415948390960693
Validation loss: 2.08953752568973

Epoch: 5| Step: 10
Training loss: 2.4525272846221924
Validation loss: 2.1030323672038254

Epoch: 211| Step: 0
Training loss: 2.942474603652954
Validation loss: 2.1151315781377975

Epoch: 5| Step: 1
Training loss: 2.3182103633880615
Validation loss: 2.1044834967582458

Epoch: 5| Step: 2
Training loss: 2.0678257942199707
Validation loss: 2.1246025587922786

Epoch: 5| Step: 3
Training loss: 2.2416281700134277
Validation loss: 2.102092137900732

Epoch: 5| Step: 4
Training loss: 1.959107756614685
Validation loss: 2.0826054978114303

Epoch: 5| Step: 5
Training loss: 2.4209465980529785
Validation loss: 2.1062332122556624

Epoch: 5| Step: 6
Training loss: 1.8297908306121826
Validation loss: 2.0955998564279206

Epoch: 5| Step: 7
Training loss: 2.111496686935425
Validation loss: 2.094768048614584

Epoch: 5| Step: 8
Training loss: 1.7994123697280884
Validation loss: 2.0985762124420493

Epoch: 5| Step: 9
Training loss: 2.09307861328125
Validation loss: 2.1174187865308536

Epoch: 5| Step: 10
Training loss: 1.6423829793930054
Validation loss: 2.081620321478895

Epoch: 212| Step: 0
Training loss: 2.940932512283325
Validation loss: 2.086180986896638

Epoch: 5| Step: 1
Training loss: 1.9384320974349976
Validation loss: 2.1162903821596535

Epoch: 5| Step: 2
Training loss: 2.023919105529785
Validation loss: 2.0737386724000335

Epoch: 5| Step: 3
Training loss: 1.8840045928955078
Validation loss: 2.099205993836926

Epoch: 5| Step: 4
Training loss: 1.5673134326934814
Validation loss: 2.06628752780217

Epoch: 5| Step: 5
Training loss: 2.351168394088745
Validation loss: 2.0935493464111

Epoch: 5| Step: 6
Training loss: 1.6471859216690063
Validation loss: 2.0959317299627487

Epoch: 5| Step: 7
Training loss: 2.431124210357666
Validation loss: 2.100615309130761

Epoch: 5| Step: 8
Training loss: 2.108140230178833
Validation loss: 2.060025156185191

Epoch: 5| Step: 9
Training loss: 1.8736766576766968
Validation loss: 2.0718540478778142

Epoch: 5| Step: 10
Training loss: 2.823245048522949
Validation loss: 2.0768845055692937

Epoch: 213| Step: 0
Training loss: 1.9749336242675781
Validation loss: 2.1131557072362592

Epoch: 5| Step: 1
Training loss: 1.9569467306137085
Validation loss: 2.0808167226852907

Epoch: 5| Step: 2
Training loss: 2.0740981101989746
Validation loss: 2.092292695917109

Epoch: 5| Step: 3
Training loss: 2.3114631175994873
Validation loss: 2.078825919858871

Epoch: 5| Step: 4
Training loss: 2.520608901977539
Validation loss: 2.0990490528845016

Epoch: 5| Step: 5
Training loss: 2.4062914848327637
Validation loss: 2.1061070554999897

Epoch: 5| Step: 6
Training loss: 1.724156141281128
Validation loss: 2.0920968619726037

Epoch: 5| Step: 7
Training loss: 2.4078991413116455
Validation loss: 2.0993305842081704

Epoch: 5| Step: 8
Training loss: 2.238009452819824
Validation loss: 2.0899408350708666

Epoch: 5| Step: 9
Training loss: 1.9322702884674072
Validation loss: 2.102266014263194

Epoch: 5| Step: 10
Training loss: 1.9722126722335815
Validation loss: 2.0949532498595533

Epoch: 214| Step: 0
Training loss: 2.4039127826690674
Validation loss: 2.1066562949970202

Epoch: 5| Step: 1
Training loss: 2.173478603363037
Validation loss: 2.0870909742129746

Epoch: 5| Step: 2
Training loss: 1.5479936599731445
Validation loss: 2.090868970399262

Epoch: 5| Step: 3
Training loss: 2.218535900115967
Validation loss: 2.0770536084328928

Epoch: 5| Step: 4
Training loss: 2.2203495502471924
Validation loss: 2.0918681108823387

Epoch: 5| Step: 5
Training loss: 1.5357615947723389
Validation loss: 2.100987111368487

Epoch: 5| Step: 6
Training loss: 1.9049510955810547
Validation loss: 2.0792846128504765

Epoch: 5| Step: 7
Training loss: 3.010415554046631
Validation loss: 2.087926621078163

Epoch: 5| Step: 8
Training loss: 1.764798879623413
Validation loss: 2.0900082242104316

Epoch: 5| Step: 9
Training loss: 1.8826429843902588
Validation loss: 2.0763516810632523

Epoch: 5| Step: 10
Training loss: 2.9021060466766357
Validation loss: 2.0687094273105746

Epoch: 215| Step: 0
Training loss: 1.9056146144866943
Validation loss: 2.0798392270200994

Epoch: 5| Step: 1
Training loss: 3.046877384185791
Validation loss: 2.0718870265509493

Epoch: 5| Step: 2
Training loss: 2.100996732711792
Validation loss: 2.0900322955141784

Epoch: 5| Step: 3
Training loss: 3.0147032737731934
Validation loss: 2.0787580077366163

Epoch: 5| Step: 4
Training loss: 1.921278715133667
Validation loss: 2.1089712137817056

Epoch: 5| Step: 5
Training loss: 2.455213785171509
Validation loss: 2.0843935025635587

Epoch: 5| Step: 6
Training loss: 2.057774782180786
Validation loss: 2.078674885534471

Epoch: 5| Step: 7
Training loss: 1.3358592987060547
Validation loss: 2.085453417993361

Epoch: 5| Step: 8
Training loss: 2.040726900100708
Validation loss: 2.0688585773591073

Epoch: 5| Step: 9
Training loss: 1.3921544551849365
Validation loss: 2.1227841633622364

Epoch: 5| Step: 10
Training loss: 2.292865037918091
Validation loss: 2.0776982563798145

Epoch: 216| Step: 0
Training loss: 2.1837093830108643
Validation loss: 2.092155107887842

Epoch: 5| Step: 1
Training loss: 2.146021842956543
Validation loss: 2.0817523822989514

Epoch: 5| Step: 2
Training loss: 1.5167596340179443
Validation loss: 2.083596608972037

Epoch: 5| Step: 3
Training loss: 1.9039055109024048
Validation loss: 2.0992322096260647

Epoch: 5| Step: 4
Training loss: 2.4576313495635986
Validation loss: 2.0928688254407657

Epoch: 5| Step: 5
Training loss: 2.3454344272613525
Validation loss: 2.097425860743369

Epoch: 5| Step: 6
Training loss: 2.117466449737549
Validation loss: 2.0732512140786774

Epoch: 5| Step: 7
Training loss: 2.137662172317505
Validation loss: 2.122137050474844

Epoch: 5| Step: 8
Training loss: 2.0058181285858154
Validation loss: 2.066513479396861

Epoch: 5| Step: 9
Training loss: 2.206728458404541
Validation loss: 2.106393421849897

Epoch: 5| Step: 10
Training loss: 2.576550245285034
Validation loss: 2.0783037985524824

Epoch: 217| Step: 0
Training loss: 2.1408562660217285
Validation loss: 2.0862811252635014

Epoch: 5| Step: 1
Training loss: 2.123155117034912
Validation loss: 2.084412702950098

Epoch: 5| Step: 2
Training loss: 1.8951165676116943
Validation loss: 2.1052199281671995

Epoch: 5| Step: 3
Training loss: 2.585387706756592
Validation loss: 2.088004812117546

Epoch: 5| Step: 4
Training loss: 2.053537130355835
Validation loss: 2.0865915539444133

Epoch: 5| Step: 5
Training loss: 1.7920196056365967
Validation loss: 2.074639578019419

Epoch: 5| Step: 6
Training loss: 2.5561156272888184
Validation loss: 2.100848250491645

Epoch: 5| Step: 7
Training loss: 2.744199752807617
Validation loss: 2.1174696312155774

Epoch: 5| Step: 8
Training loss: 1.7558635473251343
Validation loss: 2.0769278413505963

Epoch: 5| Step: 9
Training loss: 1.8004627227783203
Validation loss: 2.093958382965416

Epoch: 5| Step: 10
Training loss: 1.9427083730697632
Validation loss: 2.109594216910742

Epoch: 218| Step: 0
Training loss: 2.0714175701141357
Validation loss: 2.0737022892121346

Epoch: 5| Step: 1
Training loss: 2.494633913040161
Validation loss: 2.0651377900954215

Epoch: 5| Step: 2
Training loss: 2.470097780227661
Validation loss: 2.0968142786333637

Epoch: 5| Step: 3
Training loss: 1.2465031147003174
Validation loss: 2.102971807602913

Epoch: 5| Step: 4
Training loss: 2.3337416648864746
Validation loss: 2.114330930094565

Epoch: 5| Step: 5
Training loss: 2.069969654083252
Validation loss: 2.089896268742059

Epoch: 5| Step: 6
Training loss: 2.153886079788208
Validation loss: 2.1045625273899367

Epoch: 5| Step: 7
Training loss: 1.8806679248809814
Validation loss: 2.098086846772061

Epoch: 5| Step: 8
Training loss: 2.320955753326416
Validation loss: 2.0934655204896004

Epoch: 5| Step: 9
Training loss: 2.0697662830352783
Validation loss: 2.0744043883456977

Epoch: 5| Step: 10
Training loss: 2.273195743560791
Validation loss: 2.0904274294453282

Epoch: 219| Step: 0
Training loss: 2.3133785724639893
Validation loss: 2.099064362946377

Epoch: 5| Step: 1
Training loss: 2.0569863319396973
Validation loss: 2.101918640957084

Epoch: 5| Step: 2
Training loss: 2.1196956634521484
Validation loss: 2.0964247795843307

Epoch: 5| Step: 3
Training loss: 1.9126665592193604
Validation loss: 2.085207526401807

Epoch: 5| Step: 4
Training loss: 2.429426670074463
Validation loss: 2.1158276616886096

Epoch: 5| Step: 5
Training loss: 2.388723134994507
Validation loss: 2.099026164700908

Epoch: 5| Step: 6
Training loss: 2.391442060470581
Validation loss: 2.098928648938415

Epoch: 5| Step: 7
Training loss: 2.0338664054870605
Validation loss: 2.1050225868020007

Epoch: 5| Step: 8
Training loss: 2.1906919479370117
Validation loss: 2.095802496838313

Epoch: 5| Step: 9
Training loss: 1.7674442529678345
Validation loss: 2.1128708649707097

Epoch: 5| Step: 10
Training loss: 1.7148034572601318
Validation loss: 2.06867919557838

Epoch: 220| Step: 0
Training loss: 2.308101177215576
Validation loss: 2.1108959515889487

Epoch: 5| Step: 1
Training loss: 2.2275187969207764
Validation loss: 2.083636471020278

Epoch: 5| Step: 2
Training loss: 1.4458874464035034
Validation loss: 2.097862951217159

Epoch: 5| Step: 3
Training loss: 2.091503620147705
Validation loss: 2.103601481324883

Epoch: 5| Step: 4
Training loss: 2.777721405029297
Validation loss: 2.07918845581752

Epoch: 5| Step: 5
Training loss: 2.0073351860046387
Validation loss: 2.0938322608188917

Epoch: 5| Step: 6
Training loss: 2.353996753692627
Validation loss: 2.0759731838780064

Epoch: 5| Step: 7
Training loss: 1.904248595237732
Validation loss: 2.094097911670644

Epoch: 5| Step: 8
Training loss: 1.7774956226348877
Validation loss: 2.0640359578594083

Epoch: 5| Step: 9
Training loss: 2.117309093475342
Validation loss: 2.0649878235273462

Epoch: 5| Step: 10
Training loss: 2.577071189880371
Validation loss: 2.0833006904971216

Epoch: 221| Step: 0
Training loss: 1.9986019134521484
Validation loss: 2.081082933692522

Epoch: 5| Step: 1
Training loss: 1.7615478038787842
Validation loss: 2.0664595211705854

Epoch: 5| Step: 2
Training loss: 1.9591782093048096
Validation loss: 2.08502035884447

Epoch: 5| Step: 3
Training loss: 1.8932745456695557
Validation loss: 2.070281852958023

Epoch: 5| Step: 4
Training loss: 2.2262816429138184
Validation loss: 2.0530221026430846

Epoch: 5| Step: 5
Training loss: 3.3306782245635986
Validation loss: 2.089497832841771

Epoch: 5| Step: 6
Training loss: 1.938301682472229
Validation loss: 2.076704950742824

Epoch: 5| Step: 7
Training loss: 2.5339627265930176
Validation loss: 2.099426820713987

Epoch: 5| Step: 8
Training loss: 1.9123964309692383
Validation loss: 2.090494901903214

Epoch: 5| Step: 9
Training loss: 1.5858787298202515
Validation loss: 2.0604467840604883

Epoch: 5| Step: 10
Training loss: 2.4466686248779297
Validation loss: 2.080343146477976

Epoch: 222| Step: 0
Training loss: 2.1803066730499268
Validation loss: 2.105906730057091

Epoch: 5| Step: 1
Training loss: 2.2531301975250244
Validation loss: 2.081263162756479

Epoch: 5| Step: 2
Training loss: 2.2781426906585693
Validation loss: 2.114564452120053

Epoch: 5| Step: 3
Training loss: 2.4011197090148926
Validation loss: 2.107559255374375

Epoch: 5| Step: 4
Training loss: 1.739479660987854
Validation loss: 2.097950255999001

Epoch: 5| Step: 5
Training loss: 2.002504348754883
Validation loss: 2.0838689393894647

Epoch: 5| Step: 6
Training loss: 2.004650354385376
Validation loss: 2.121168357069774

Epoch: 5| Step: 7
Training loss: 2.0161287784576416
Validation loss: 2.1156089549423545

Epoch: 5| Step: 8
Training loss: 1.7412744760513306
Validation loss: 2.107791651961624

Epoch: 5| Step: 9
Training loss: 2.898298740386963
Validation loss: 2.1357844029703448

Epoch: 5| Step: 10
Training loss: 2.021411418914795
Validation loss: 2.112373254632437

Epoch: 223| Step: 0
Training loss: 2.1322360038757324
Validation loss: 2.0833737388733895

Epoch: 5| Step: 1
Training loss: 2.8447399139404297
Validation loss: 2.071252425511678

Epoch: 5| Step: 2
Training loss: 2.107515811920166
Validation loss: 2.1222622984199115

Epoch: 5| Step: 3
Training loss: 2.273827314376831
Validation loss: 2.1029057143836893

Epoch: 5| Step: 4
Training loss: 1.7578561305999756
Validation loss: 2.099004068682271

Epoch: 5| Step: 5
Training loss: 2.7076525688171387
Validation loss: 2.0841863334819837

Epoch: 5| Step: 6
Training loss: 2.5035977363586426
Validation loss: 2.076540620096268

Epoch: 5| Step: 7
Training loss: 1.3787410259246826
Validation loss: 2.0834659196997203

Epoch: 5| Step: 8
Training loss: 1.945542335510254
Validation loss: 2.072607327533025

Epoch: 5| Step: 9
Training loss: 1.7973970174789429
Validation loss: 2.0903353460373415

Epoch: 5| Step: 10
Training loss: 2.060187578201294
Validation loss: 2.0798707162180254

Epoch: 224| Step: 0
Training loss: 2.1557414531707764
Validation loss: 2.1134300488297657

Epoch: 5| Step: 1
Training loss: 2.3774349689483643
Validation loss: 2.0958910090948946

Epoch: 5| Step: 2
Training loss: 2.002615451812744
Validation loss: 2.1030335733967442

Epoch: 5| Step: 3
Training loss: 1.7965370416641235
Validation loss: 2.0844383291018906

Epoch: 5| Step: 4
Training loss: 2.0835559368133545
Validation loss: 2.111478900396696

Epoch: 5| Step: 5
Training loss: 2.4846949577331543
Validation loss: 2.093609058728782

Epoch: 5| Step: 6
Training loss: 1.9354496002197266
Validation loss: 2.1401508521008235

Epoch: 5| Step: 7
Training loss: 1.9596980810165405
Validation loss: 2.107168406568548

Epoch: 5| Step: 8
Training loss: 1.9785617589950562
Validation loss: 2.10001568384068

Epoch: 5| Step: 9
Training loss: 2.7510228157043457
Validation loss: 2.1201033412769275

Epoch: 5| Step: 10
Training loss: 1.560966968536377
Validation loss: 2.1183551806275562

Epoch: 225| Step: 0
Training loss: 2.424342632293701
Validation loss: 2.107449846882974

Epoch: 5| Step: 1
Training loss: 2.574863910675049
Validation loss: 2.1005456998784053

Epoch: 5| Step: 2
Training loss: 2.2537331581115723
Validation loss: 2.0901358217321415

Epoch: 5| Step: 3
Training loss: 2.0490880012512207
Validation loss: 2.0975178595512145

Epoch: 5| Step: 4
Training loss: 2.282636880874634
Validation loss: 2.095336365443404

Epoch: 5| Step: 5
Training loss: 1.6170966625213623
Validation loss: 2.1124985448775755

Epoch: 5| Step: 6
Training loss: 2.001060962677002
Validation loss: 2.113831945644912

Epoch: 5| Step: 7
Training loss: 2.593348264694214
Validation loss: 2.0799109884487685

Epoch: 5| Step: 8
Training loss: 1.8173555135726929
Validation loss: 2.068323499412947

Epoch: 5| Step: 9
Training loss: 1.4727957248687744
Validation loss: 2.123324994117983

Epoch: 5| Step: 10
Training loss: 2.485006332397461
Validation loss: 2.0848284921338482

Epoch: 226| Step: 0
Training loss: 1.974738359451294
Validation loss: 2.111601045054774

Epoch: 5| Step: 1
Training loss: 2.0860536098480225
Validation loss: 2.0571546708383868

Epoch: 5| Step: 2
Training loss: 2.555467128753662
Validation loss: 2.1075363479634768

Epoch: 5| Step: 3
Training loss: 2.5347707271575928
Validation loss: 2.087742326080158

Epoch: 5| Step: 4
Training loss: 2.136049509048462
Validation loss: 2.0755118580274683

Epoch: 5| Step: 5
Training loss: 1.8998069763183594
Validation loss: 2.069617530351044

Epoch: 5| Step: 6
Training loss: 2.262072801589966
Validation loss: 2.0830390504611436

Epoch: 5| Step: 7
Training loss: 1.6428829431533813
Validation loss: 2.099995573361715

Epoch: 5| Step: 8
Training loss: 2.0430760383605957
Validation loss: 2.1056741847786853

Epoch: 5| Step: 9
Training loss: 2.1971423625946045
Validation loss: 2.109594779629861

Epoch: 5| Step: 10
Training loss: 2.051830530166626
Validation loss: 2.115779515235655

Epoch: 227| Step: 0
Training loss: 1.9792503118515015
Validation loss: 2.0710724348663003

Epoch: 5| Step: 1
Training loss: 1.759528398513794
Validation loss: 2.059411564180928

Epoch: 5| Step: 2
Training loss: 2.3104851245880127
Validation loss: 2.108438056002381

Epoch: 5| Step: 3
Training loss: 2.4032092094421387
Validation loss: 2.0931756778429915

Epoch: 5| Step: 4
Training loss: 1.8466449975967407
Validation loss: 2.100284566161453

Epoch: 5| Step: 5
Training loss: 3.108947277069092
Validation loss: 2.1229230485936648

Epoch: 5| Step: 6
Training loss: 2.6390953063964844
Validation loss: 2.095208047538675

Epoch: 5| Step: 7
Training loss: 1.608202576637268
Validation loss: 2.079941743163652

Epoch: 5| Step: 8
Training loss: 1.978224515914917
Validation loss: 2.1083419604968

Epoch: 5| Step: 9
Training loss: 1.5365742444992065
Validation loss: 2.078652472906215

Epoch: 5| Step: 10
Training loss: 2.1326332092285156
Validation loss: 2.0938709923016128

Epoch: 228| Step: 0
Training loss: 1.852099061012268
Validation loss: 2.0910327460176203

Epoch: 5| Step: 1
Training loss: 2.0666935443878174
Validation loss: 2.0897094472762077

Epoch: 5| Step: 2
Training loss: 2.2644619941711426
Validation loss: 2.0993757247924805

Epoch: 5| Step: 3
Training loss: 2.080422878265381
Validation loss: 2.1044868166728685

Epoch: 5| Step: 4
Training loss: 2.3384013175964355
Validation loss: 2.087893778277982

Epoch: 5| Step: 5
Training loss: 1.7802116870880127
Validation loss: 2.0873947207645704

Epoch: 5| Step: 6
Training loss: 1.9089313745498657
Validation loss: 2.112002126632198

Epoch: 5| Step: 7
Training loss: 2.491241931915283
Validation loss: 2.113656349079583

Epoch: 5| Step: 8
Training loss: 2.0044124126434326
Validation loss: 2.0801519334957166

Epoch: 5| Step: 9
Training loss: 2.7345807552337646
Validation loss: 2.0946460077839513

Epoch: 5| Step: 10
Training loss: 2.1360979080200195
Validation loss: 2.1045748444013697

Epoch: 229| Step: 0
Training loss: 1.9473367929458618
Validation loss: 2.0915982569417646

Epoch: 5| Step: 1
Training loss: 1.9153484106063843
Validation loss: 2.09407716156334

Epoch: 5| Step: 2
Training loss: 1.7763162851333618
Validation loss: 2.072510534717191

Epoch: 5| Step: 3
Training loss: 2.4785754680633545
Validation loss: 2.105998105900262

Epoch: 5| Step: 4
Training loss: 2.3480639457702637
Validation loss: 2.088463447427237

Epoch: 5| Step: 5
Training loss: 2.4276766777038574
Validation loss: 2.121449560247442

Epoch: 5| Step: 6
Training loss: 2.00968599319458
Validation loss: 2.1202035719348538

Epoch: 5| Step: 7
Training loss: 2.7592687606811523
Validation loss: 2.1099176214587305

Epoch: 5| Step: 8
Training loss: 2.072768449783325
Validation loss: 2.096357378908383

Epoch: 5| Step: 9
Training loss: 2.0276947021484375
Validation loss: 2.1130356993726505

Epoch: 5| Step: 10
Training loss: 1.5103124380111694
Validation loss: 2.1146330500161774

Epoch: 230| Step: 0
Training loss: 2.6226298809051514
Validation loss: 2.1134182996647333

Epoch: 5| Step: 1
Training loss: 2.129160165786743
Validation loss: 2.1023690649258193

Epoch: 5| Step: 2
Training loss: 1.965381383895874
Validation loss: 2.1416880751168854

Epoch: 5| Step: 3
Training loss: 2.2495689392089844
Validation loss: 2.0929810718823503

Epoch: 5| Step: 4
Training loss: 1.9402141571044922
Validation loss: 2.107456435439407

Epoch: 5| Step: 5
Training loss: 2.3664984703063965
Validation loss: 2.1025680136936966

Epoch: 5| Step: 6
Training loss: 1.7009847164154053
Validation loss: 2.089862523540374

Epoch: 5| Step: 7
Training loss: 1.8385517597198486
Validation loss: 2.069135276220178

Epoch: 5| Step: 8
Training loss: 2.406646251678467
Validation loss: 2.089905358129932

Epoch: 5| Step: 9
Training loss: 1.8168671131134033
Validation loss: 2.069954010748094

Epoch: 5| Step: 10
Training loss: 2.5284745693206787
Validation loss: 2.0541268061566096

Epoch: 231| Step: 0
Training loss: 1.4752576351165771
Validation loss: 2.1081289732328026

Epoch: 5| Step: 1
Training loss: 2.394623279571533
Validation loss: 2.096725171612155

Epoch: 5| Step: 2
Training loss: 1.8668428659439087
Validation loss: 2.0890314322645946

Epoch: 5| Step: 3
Training loss: 2.5767903327941895
Validation loss: 2.0738987512485956

Epoch: 5| Step: 4
Training loss: 2.3359882831573486
Validation loss: 2.0976125783817743

Epoch: 5| Step: 5
Training loss: 2.5852439403533936
Validation loss: 2.090630523620113

Epoch: 5| Step: 6
Training loss: 2.6706535816192627
Validation loss: 2.073040013672203

Epoch: 5| Step: 7
Training loss: 1.6774036884307861
Validation loss: 2.099507680503271

Epoch: 5| Step: 8
Training loss: 1.8475749492645264
Validation loss: 2.0702462914169475

Epoch: 5| Step: 9
Training loss: 1.7290401458740234
Validation loss: 2.089981239329102

Epoch: 5| Step: 10
Training loss: 2.0655014514923096
Validation loss: 2.0685286893639514

Epoch: 232| Step: 0
Training loss: 1.9897606372833252
Validation loss: 2.0876085348026727

Epoch: 5| Step: 1
Training loss: 2.8281736373901367
Validation loss: 2.0795370122437835

Epoch: 5| Step: 2
Training loss: 1.9656498432159424
Validation loss: 2.070464208561887

Epoch: 5| Step: 3
Training loss: 2.219691514968872
Validation loss: 2.1009205592575895

Epoch: 5| Step: 4
Training loss: 2.0957560539245605
Validation loss: 2.104557091189969

Epoch: 5| Step: 5
Training loss: 2.2322194576263428
Validation loss: 2.064998883073048

Epoch: 5| Step: 6
Training loss: 2.3120296001434326
Validation loss: 2.0959233622397146

Epoch: 5| Step: 7
Training loss: 1.9205207824707031
Validation loss: 2.0951665139967397

Epoch: 5| Step: 8
Training loss: 1.7994056940078735
Validation loss: 2.126427017232423

Epoch: 5| Step: 9
Training loss: 1.8728080987930298
Validation loss: 2.0773076921380977

Epoch: 5| Step: 10
Training loss: 2.207770586013794
Validation loss: 2.081271848370952

Epoch: 233| Step: 0
Training loss: 1.7248014211654663
Validation loss: 2.071626986226728

Epoch: 5| Step: 1
Training loss: 1.7082836627960205
Validation loss: 2.076951324298818

Epoch: 5| Step: 2
Training loss: 1.998500108718872
Validation loss: 2.097235461717011

Epoch: 5| Step: 3
Training loss: 1.99261474609375
Validation loss: 2.101242851185542

Epoch: 5| Step: 4
Training loss: 2.763164520263672
Validation loss: 2.0874425262533207

Epoch: 5| Step: 5
Training loss: 2.7406086921691895
Validation loss: 2.0993514394247406

Epoch: 5| Step: 6
Training loss: 1.766122817993164
Validation loss: 2.1172396008686354

Epoch: 5| Step: 7
Training loss: 2.5092406272888184
Validation loss: 2.107823847442545

Epoch: 5| Step: 8
Training loss: 1.7742599248886108
Validation loss: 2.0822487595260784

Epoch: 5| Step: 9
Training loss: 2.2806200981140137
Validation loss: 2.079648703657171

Epoch: 5| Step: 10
Training loss: 1.9087008237838745
Validation loss: 2.0843572514031523

Epoch: 234| Step: 0
Training loss: 1.6132278442382812
Validation loss: 2.1132930606924076

Epoch: 5| Step: 1
Training loss: 2.4979050159454346
Validation loss: 2.0939745492832635

Epoch: 5| Step: 2
Training loss: 2.4520697593688965
Validation loss: 2.0719443072554884

Epoch: 5| Step: 3
Training loss: 2.2891883850097656
Validation loss: 2.085177872770576

Epoch: 5| Step: 4
Training loss: 2.4297597408294678
Validation loss: 2.1001302298679145

Epoch: 5| Step: 5
Training loss: 1.8694345951080322
Validation loss: 2.0821333290428243

Epoch: 5| Step: 6
Training loss: 2.692098379135132
Validation loss: 2.0785241255196194

Epoch: 5| Step: 7
Training loss: 1.8535267114639282
Validation loss: 2.0872239733255036

Epoch: 5| Step: 8
Training loss: 1.8206523656845093
Validation loss: 2.079973328498102

Epoch: 5| Step: 9
Training loss: 1.947411298751831
Validation loss: 2.0822803230695826

Epoch: 5| Step: 10
Training loss: 1.9230979681015015
Validation loss: 2.0711197096814393

Epoch: 235| Step: 0
Training loss: 2.037487268447876
Validation loss: 2.086310653276341

Epoch: 5| Step: 1
Training loss: 2.1426024436950684
Validation loss: 2.1194255352020264

Epoch: 5| Step: 2
Training loss: 2.2833449840545654
Validation loss: 2.1026008821302846

Epoch: 5| Step: 3
Training loss: 1.46634042263031
Validation loss: 2.0918748660754134

Epoch: 5| Step: 4
Training loss: 2.333326816558838
Validation loss: 2.1071658237006075

Epoch: 5| Step: 5
Training loss: 2.2084875106811523
Validation loss: 2.115045375721429

Epoch: 5| Step: 6
Training loss: 2.4957098960876465
Validation loss: 2.1189614624105473

Epoch: 5| Step: 7
Training loss: 2.0960869789123535
Validation loss: 2.1229310035705566

Epoch: 5| Step: 8
Training loss: 2.5199778079986572
Validation loss: 2.134232762039349

Epoch: 5| Step: 9
Training loss: 2.6902568340301514
Validation loss: 2.132176242848878

Epoch: 5| Step: 10
Training loss: 1.204140067100525
Validation loss: 2.136023532959723

Epoch: 236| Step: 0
Training loss: 2.0508551597595215
Validation loss: 2.143215569116736

Epoch: 5| Step: 1
Training loss: 2.590449571609497
Validation loss: 2.108502318782191

Epoch: 5| Step: 2
Training loss: 1.9354021549224854
Validation loss: 2.120084528000124

Epoch: 5| Step: 3
Training loss: 2.0916497707366943
Validation loss: 2.114174755670691

Epoch: 5| Step: 4
Training loss: 2.411975383758545
Validation loss: 2.122076670328776

Epoch: 5| Step: 5
Training loss: 2.1738038063049316
Validation loss: 2.0899761953661518

Epoch: 5| Step: 6
Training loss: 1.7267059087753296
Validation loss: 2.1099634042350193

Epoch: 5| Step: 7
Training loss: 1.9959533214569092
Validation loss: 2.1038780353402577

Epoch: 5| Step: 8
Training loss: 1.8456175327301025
Validation loss: 2.1259314231975104

Epoch: 5| Step: 9
Training loss: 2.0797228813171387
Validation loss: 2.124894224187379

Epoch: 5| Step: 10
Training loss: 2.3912720680236816
Validation loss: 2.118489493605911

Epoch: 237| Step: 0
Training loss: 1.8249385356903076
Validation loss: 2.0999146405086724

Epoch: 5| Step: 1
Training loss: 1.7636827230453491
Validation loss: 2.1078611702047367

Epoch: 5| Step: 2
Training loss: 2.297142505645752
Validation loss: 2.093948027139069

Epoch: 5| Step: 3
Training loss: 1.5658882856369019
Validation loss: 2.0999489266385316

Epoch: 5| Step: 4
Training loss: 2.6390271186828613
Validation loss: 2.097044167980071

Epoch: 5| Step: 5
Training loss: 1.6285539865493774
Validation loss: 2.1083113070457213

Epoch: 5| Step: 6
Training loss: 1.9616925716400146
Validation loss: 2.1161951095827165

Epoch: 5| Step: 7
Training loss: 2.8532662391662598
Validation loss: 2.0703222597798994

Epoch: 5| Step: 8
Training loss: 2.3935837745666504
Validation loss: 2.081943929836314

Epoch: 5| Step: 9
Training loss: 2.2328288555145264
Validation loss: 2.0753129272050757

Epoch: 5| Step: 10
Training loss: 2.2700564861297607
Validation loss: 2.0793202654007943

Epoch: 238| Step: 0
Training loss: 2.0132501125335693
Validation loss: 2.059045180197685

Epoch: 5| Step: 1
Training loss: 1.9670956134796143
Validation loss: 2.090769516524448

Epoch: 5| Step: 2
Training loss: 2.3874313831329346
Validation loss: 2.0641203054817776

Epoch: 5| Step: 3
Training loss: 1.5211519002914429
Validation loss: 2.0519720303115023

Epoch: 5| Step: 4
Training loss: 2.1343657970428467
Validation loss: 2.087372270963525

Epoch: 5| Step: 5
Training loss: 2.183168888092041
Validation loss: 2.1067843514104045

Epoch: 5| Step: 6
Training loss: 2.2282443046569824
Validation loss: 2.0897985222519084

Epoch: 5| Step: 7
Training loss: 2.280061721801758
Validation loss: 2.109984972143686

Epoch: 5| Step: 8
Training loss: 2.52937912940979
Validation loss: 2.060839360760104

Epoch: 5| Step: 9
Training loss: 2.3194680213928223
Validation loss: 2.114493047037432

Epoch: 5| Step: 10
Training loss: 1.6070220470428467
Validation loss: 2.0731718476100633

Epoch: 239| Step: 0
Training loss: 2.3800148963928223
Validation loss: 2.0959187656320553

Epoch: 5| Step: 1
Training loss: 1.9252275228500366
Validation loss: 2.073033573806927

Epoch: 5| Step: 2
Training loss: 1.886547327041626
Validation loss: 2.0898456727304766

Epoch: 5| Step: 3
Training loss: 1.9887068271636963
Validation loss: 2.0985359530295096

Epoch: 5| Step: 4
Training loss: 2.0983450412750244
Validation loss: 2.087843736012777

Epoch: 5| Step: 5
Training loss: 2.8998169898986816
Validation loss: 2.079968706254036

Epoch: 5| Step: 6
Training loss: 1.997800588607788
Validation loss: 2.0917937345402215

Epoch: 5| Step: 7
Training loss: 2.1888253688812256
Validation loss: 2.0981090196999173

Epoch: 5| Step: 8
Training loss: 1.6829382181167603
Validation loss: 2.087429678568276

Epoch: 5| Step: 9
Training loss: 1.9416974782943726
Validation loss: 2.095222237289593

Epoch: 5| Step: 10
Training loss: 2.154047727584839
Validation loss: 2.0893251947177354

Epoch: 240| Step: 0
Training loss: 1.9720739126205444
Validation loss: 2.1069458171885502

Epoch: 5| Step: 1
Training loss: 2.362645387649536
Validation loss: 2.081329620012673

Epoch: 5| Step: 2
Training loss: 2.047107219696045
Validation loss: 2.113806636102738

Epoch: 5| Step: 3
Training loss: 2.2428462505340576
Validation loss: 2.102267911357264

Epoch: 5| Step: 4
Training loss: 1.5273888111114502
Validation loss: 2.1345653123753046

Epoch: 5| Step: 5
Training loss: 1.8762214183807373
Validation loss: 2.1078683650621803

Epoch: 5| Step: 6
Training loss: 2.458151340484619
Validation loss: 2.1186727810931463

Epoch: 5| Step: 7
Training loss: 1.9762895107269287
Validation loss: 2.0942756258031374

Epoch: 5| Step: 8
Training loss: 1.9949384927749634
Validation loss: 2.0868025966869888

Epoch: 5| Step: 9
Training loss: 1.9809526205062866
Validation loss: 2.1032322914369646

Epoch: 5| Step: 10
Training loss: 2.888375997543335
Validation loss: 2.116768019173735

Epoch: 241| Step: 0
Training loss: 2.258836269378662
Validation loss: 2.098676735355008

Epoch: 5| Step: 1
Training loss: 1.6999692916870117
Validation loss: 2.096602729571763

Epoch: 5| Step: 2
Training loss: 2.551909923553467
Validation loss: 2.0903543374871694

Epoch: 5| Step: 3
Training loss: 2.1591179370880127
Validation loss: 2.1126883081210557

Epoch: 5| Step: 4
Training loss: 2.1481270790100098
Validation loss: 2.0395370990999284

Epoch: 5| Step: 5
Training loss: 2.4045825004577637
Validation loss: 2.086195940612465

Epoch: 5| Step: 6
Training loss: 1.3341106176376343
Validation loss: 2.092265805890483

Epoch: 5| Step: 7
Training loss: 1.4796336889266968
Validation loss: 2.0815222929882746

Epoch: 5| Step: 8
Training loss: 2.4830825328826904
Validation loss: 2.0978852523270475

Epoch: 5| Step: 9
Training loss: 2.345987319946289
Validation loss: 2.0830843833185013

Epoch: 5| Step: 10
Training loss: 2.372119665145874
Validation loss: 2.0729701929194952

Epoch: 242| Step: 0
Training loss: 1.907958984375
Validation loss: 2.1179913141394175

Epoch: 5| Step: 1
Training loss: 2.110064744949341
Validation loss: 2.0826436076112973

Epoch: 5| Step: 2
Training loss: 2.1660590171813965
Validation loss: 2.0858158501245643

Epoch: 5| Step: 3
Training loss: 2.098132371902466
Validation loss: 2.0912956576193533

Epoch: 5| Step: 4
Training loss: 2.486701726913452
Validation loss: 2.0742346753356276

Epoch: 5| Step: 5
Training loss: 2.3237457275390625
Validation loss: 2.107816816658102

Epoch: 5| Step: 6
Training loss: 2.5260910987854004
Validation loss: 2.1061721283902406

Epoch: 5| Step: 7
Training loss: 1.8106138706207275
Validation loss: 2.117918558018182

Epoch: 5| Step: 8
Training loss: 1.6400007009506226
Validation loss: 2.10190305402202

Epoch: 5| Step: 9
Training loss: 1.6836456060409546
Validation loss: 2.128457251415458

Epoch: 5| Step: 10
Training loss: 2.320974826812744
Validation loss: 2.123114593567387

Epoch: 243| Step: 0
Training loss: 2.534487724304199
Validation loss: 2.0999823847124652

Epoch: 5| Step: 1
Training loss: 2.287985324859619
Validation loss: 2.1219583326770413

Epoch: 5| Step: 2
Training loss: 1.321164846420288
Validation loss: 2.0975369855921757

Epoch: 5| Step: 3
Training loss: 2.360867977142334
Validation loss: 2.1093514145061536

Epoch: 5| Step: 4
Training loss: 2.276590347290039
Validation loss: 2.12789580129808

Epoch: 5| Step: 5
Training loss: 2.2304863929748535
Validation loss: 2.0988958369019213

Epoch: 5| Step: 6
Training loss: 2.4304022789001465
Validation loss: 2.110757436803592

Epoch: 5| Step: 7
Training loss: 1.6309053897857666
Validation loss: 2.112854864007683

Epoch: 5| Step: 8
Training loss: 2.35386323928833
Validation loss: 2.1116055762895973

Epoch: 5| Step: 9
Training loss: 1.5455348491668701
Validation loss: 2.081406893268708

Epoch: 5| Step: 10
Training loss: 2.074220657348633
Validation loss: 2.0729695648275395

Epoch: 244| Step: 0
Training loss: 1.3788776397705078
Validation loss: 2.0978126833515782

Epoch: 5| Step: 1
Training loss: 2.398808240890503
Validation loss: 2.0894074542548067

Epoch: 5| Step: 2
Training loss: 1.70741868019104
Validation loss: 2.0883645460169804

Epoch: 5| Step: 3
Training loss: 1.8479591608047485
Validation loss: 2.0637195200048466

Epoch: 5| Step: 4
Training loss: 1.9543737173080444
Validation loss: 2.099090442862562

Epoch: 5| Step: 5
Training loss: 1.95876145362854
Validation loss: 2.075810409361316

Epoch: 5| Step: 6
Training loss: 2.375645875930786
Validation loss: 2.0697322276330765

Epoch: 5| Step: 7
Training loss: 2.2367587089538574
Validation loss: 2.086949876559678

Epoch: 5| Step: 8
Training loss: 2.242565870285034
Validation loss: 2.071511681361865

Epoch: 5| Step: 9
Training loss: 3.031604766845703
Validation loss: 2.0478916334849533

Epoch: 5| Step: 10
Training loss: 2.1262683868408203
Validation loss: 2.073584779616325

Epoch: 245| Step: 0
Training loss: 2.5397770404815674
Validation loss: 2.1376484030036518

Epoch: 5| Step: 1
Training loss: 2.1571688652038574
Validation loss: 2.0980708150453466

Epoch: 5| Step: 2
Training loss: 1.9962571859359741
Validation loss: 2.1084343617962253

Epoch: 5| Step: 3
Training loss: 2.106173515319824
Validation loss: 2.116985344117688

Epoch: 5| Step: 4
Training loss: 1.9297893047332764
Validation loss: 2.1046724652731292

Epoch: 5| Step: 5
Training loss: 2.289520740509033
Validation loss: 2.098796558636491

Epoch: 5| Step: 6
Training loss: 2.4966793060302734
Validation loss: 2.119279505104147

Epoch: 5| Step: 7
Training loss: 1.9157302379608154
Validation loss: 2.1255425612131753

Epoch: 5| Step: 8
Training loss: 2.2411205768585205
Validation loss: 2.119667692850995

Epoch: 5| Step: 9
Training loss: 1.611351728439331
Validation loss: 2.136337350773555

Epoch: 5| Step: 10
Training loss: 1.7793010473251343
Validation loss: 2.110348786077192

Epoch: 246| Step: 0
Training loss: 2.0435447692871094
Validation loss: 2.12230364225244

Epoch: 5| Step: 1
Training loss: 1.496131181716919
Validation loss: 2.129460616778302

Epoch: 5| Step: 2
Training loss: 2.4644112586975098
Validation loss: 2.1021443900241645

Epoch: 5| Step: 3
Training loss: 2.5073463916778564
Validation loss: 2.120029613535891

Epoch: 5| Step: 4
Training loss: 2.0324809551239014
Validation loss: 2.098381309099095

Epoch: 5| Step: 5
Training loss: 1.670998215675354
Validation loss: 2.11765496576986

Epoch: 5| Step: 6
Training loss: 2.1641898155212402
Validation loss: 2.1181870301564536

Epoch: 5| Step: 7
Training loss: 2.8633880615234375
Validation loss: 2.10337552203927

Epoch: 5| Step: 8
Training loss: 1.8050702810287476
Validation loss: 2.088621452290525

Epoch: 5| Step: 9
Training loss: 1.9920921325683594
Validation loss: 2.1046224409534084

Epoch: 5| Step: 10
Training loss: 2.2941513061523438
Validation loss: 2.110730137876285

Epoch: 247| Step: 0
Training loss: 1.7996799945831299
Validation loss: 2.089063339335944

Epoch: 5| Step: 1
Training loss: 2.2080371379852295
Validation loss: 2.0631381798815984

Epoch: 5| Step: 2
Training loss: 2.0767149925231934
Validation loss: 2.0837370016241588

Epoch: 5| Step: 3
Training loss: 2.0196919441223145
Validation loss: 2.102280024559267

Epoch: 5| Step: 4
Training loss: 2.414292812347412
Validation loss: 2.0915593434405584

Epoch: 5| Step: 5
Training loss: 2.012321949005127
Validation loss: 2.0938214255917456

Epoch: 5| Step: 6
Training loss: 2.5705714225769043
Validation loss: 2.0687388143231793

Epoch: 5| Step: 7
Training loss: 1.9190704822540283
Validation loss: 2.077177634803198

Epoch: 5| Step: 8
Training loss: 2.226130962371826
Validation loss: 2.1237258962405625

Epoch: 5| Step: 9
Training loss: 1.8602592945098877
Validation loss: 2.0949711235620643

Epoch: 5| Step: 10
Training loss: 1.949657678604126
Validation loss: 2.098079046895427

Epoch: 248| Step: 0
Training loss: 1.9055312871932983
Validation loss: 2.103844263220346

Epoch: 5| Step: 1
Training loss: 2.4954240322113037
Validation loss: 2.0920694181996007

Epoch: 5| Step: 2
Training loss: 2.2637124061584473
Validation loss: 2.100936246174638

Epoch: 5| Step: 3
Training loss: 2.3031787872314453
Validation loss: 2.0939038210017706

Epoch: 5| Step: 4
Training loss: 2.1547932624816895
Validation loss: 2.122696958562379

Epoch: 5| Step: 5
Training loss: 1.9935150146484375
Validation loss: 2.115508493556771

Epoch: 5| Step: 6
Training loss: 2.3171963691711426
Validation loss: 2.111831295874811

Epoch: 5| Step: 7
Training loss: 1.7364647388458252
Validation loss: 2.12875428763769

Epoch: 5| Step: 8
Training loss: 2.103127956390381
Validation loss: 2.1068106851270123

Epoch: 5| Step: 9
Training loss: 1.8948227167129517
Validation loss: 2.109144392833915

Epoch: 5| Step: 10
Training loss: 1.8155311346054077
Validation loss: 2.1112526475742297

Epoch: 249| Step: 0
Training loss: 2.0021729469299316
Validation loss: 2.122318667750205

Epoch: 5| Step: 1
Training loss: 2.5160045623779297
Validation loss: 2.0577096733995663

Epoch: 5| Step: 2
Training loss: 2.272681474685669
Validation loss: 2.101043201261951

Epoch: 5| Step: 3
Training loss: 2.3601112365722656
Validation loss: 2.1024149489659134

Epoch: 5| Step: 4
Training loss: 1.4564863443374634
Validation loss: 2.106569599079829

Epoch: 5| Step: 5
Training loss: 2.3386270999908447
Validation loss: 2.1137070502004316

Epoch: 5| Step: 6
Training loss: 1.981958031654358
Validation loss: 2.0889112846825713

Epoch: 5| Step: 7
Training loss: 2.0865931510925293
Validation loss: 2.1282451063074093

Epoch: 5| Step: 8
Training loss: 2.295886754989624
Validation loss: 2.0845576845189577

Epoch: 5| Step: 9
Training loss: 1.7250152826309204
Validation loss: 2.1088564062631256

Epoch: 5| Step: 10
Training loss: 1.9100427627563477
Validation loss: 2.0906102900863974

Epoch: 250| Step: 0
Training loss: 2.223038673400879
Validation loss: 2.081910735817366

Epoch: 5| Step: 1
Training loss: 1.7675426006317139
Validation loss: 2.086248661882134

Epoch: 5| Step: 2
Training loss: 1.9657102823257446
Validation loss: 2.1073448068352154

Epoch: 5| Step: 3
Training loss: 2.0375640392303467
Validation loss: 2.0879757955510128

Epoch: 5| Step: 4
Training loss: 2.0710349082946777
Validation loss: 2.089089306451941

Epoch: 5| Step: 5
Training loss: 2.4665660858154297
Validation loss: 2.0492905147614016

Epoch: 5| Step: 6
Training loss: 1.8173973560333252
Validation loss: 2.059603173245666

Epoch: 5| Step: 7
Training loss: 1.7239080667495728
Validation loss: 2.1015212382039716

Epoch: 5| Step: 8
Training loss: 2.4075474739074707
Validation loss: 2.098217605262674

Epoch: 5| Step: 9
Training loss: 2.8269362449645996
Validation loss: 2.0838491711565243

Epoch: 5| Step: 10
Training loss: 1.643409252166748
Validation loss: 2.0727680062734954

Epoch: 251| Step: 0
Training loss: 2.627655029296875
Validation loss: 2.0912771378794024

Epoch: 5| Step: 1
Training loss: 1.6726710796356201
Validation loss: 2.0905736005434425

Epoch: 5| Step: 2
Training loss: 1.9862957000732422
Validation loss: 2.0636942835264307

Epoch: 5| Step: 3
Training loss: 2.1450812816619873
Validation loss: 2.0804344505392094

Epoch: 5| Step: 4
Training loss: 1.8969309329986572
Validation loss: 2.098325921643165

Epoch: 5| Step: 5
Training loss: 2.0749707221984863
Validation loss: 2.100241567498894

Epoch: 5| Step: 6
Training loss: 1.8597224950790405
Validation loss: 2.100224141151674

Epoch: 5| Step: 7
Training loss: 1.7125880718231201
Validation loss: 2.1088305801473637

Epoch: 5| Step: 8
Training loss: 2.535156726837158
Validation loss: 2.0976667839993715

Epoch: 5| Step: 9
Training loss: 2.642970561981201
Validation loss: 2.136639980859654

Epoch: 5| Step: 10
Training loss: 1.8828915357589722
Validation loss: 2.11195207154879

Epoch: 252| Step: 0
Training loss: 2.7866692543029785
Validation loss: 2.1265464393041467

Epoch: 5| Step: 1
Training loss: 1.9214811325073242
Validation loss: 2.1064907171392955

Epoch: 5| Step: 2
Training loss: 1.623131513595581
Validation loss: 2.1271224329548497

Epoch: 5| Step: 3
Training loss: 2.4437060356140137
Validation loss: 2.111096546214114

Epoch: 5| Step: 4
Training loss: 1.7287410497665405
Validation loss: 2.0902238404879006

Epoch: 5| Step: 5
Training loss: 1.8485138416290283
Validation loss: 2.124502326852532

Epoch: 5| Step: 6
Training loss: 2.410306215286255
Validation loss: 2.0926637059898785

Epoch: 5| Step: 7
Training loss: 2.152296304702759
Validation loss: 2.0799095284554268

Epoch: 5| Step: 8
Training loss: 1.8073810338974
Validation loss: 2.107287024938932

Epoch: 5| Step: 9
Training loss: 2.2628560066223145
Validation loss: 2.1058469280119865

Epoch: 5| Step: 10
Training loss: 2.034574270248413
Validation loss: 2.099372274132185

Epoch: 253| Step: 0
Training loss: 1.6853212118148804
Validation loss: 2.10804303743506

Epoch: 5| Step: 1
Training loss: 1.8352819681167603
Validation loss: 2.106639478796272

Epoch: 5| Step: 2
Training loss: 2.0254225730895996
Validation loss: 2.10977590468622

Epoch: 5| Step: 3
Training loss: 2.503814697265625
Validation loss: 2.103283525795065

Epoch: 5| Step: 4
Training loss: 2.458996534347534
Validation loss: 2.0837946720020746

Epoch: 5| Step: 5
Training loss: 1.8825881481170654
Validation loss: 2.099189983901157

Epoch: 5| Step: 6
Training loss: 2.093026876449585
Validation loss: 2.066637715985698

Epoch: 5| Step: 7
Training loss: 2.0051064491271973
Validation loss: 2.0662832003767773

Epoch: 5| Step: 8
Training loss: 2.7109293937683105
Validation loss: 2.066454069588774

Epoch: 5| Step: 9
Training loss: 1.7852325439453125
Validation loss: 2.0585854873862317

Epoch: 5| Step: 10
Training loss: 2.0081212520599365
Validation loss: 2.058089622887232

Epoch: 254| Step: 0
Training loss: 1.7700239419937134
Validation loss: 2.077680867205384

Epoch: 5| Step: 1
Training loss: 1.9770644903182983
Validation loss: 2.0982326845968924

Epoch: 5| Step: 2
Training loss: 2.0613160133361816
Validation loss: 2.084311196880956

Epoch: 5| Step: 3
Training loss: 2.4270119667053223
Validation loss: 2.0805550993129773

Epoch: 5| Step: 4
Training loss: 1.8901023864746094
Validation loss: 2.095139531679051

Epoch: 5| Step: 5
Training loss: 1.8670984506607056
Validation loss: 2.081128235786192

Epoch: 5| Step: 6
Training loss: 2.0710737705230713
Validation loss: 2.0837789632940806

Epoch: 5| Step: 7
Training loss: 1.3568744659423828
Validation loss: 2.0923991933945687

Epoch: 5| Step: 8
Training loss: 2.996410846710205
Validation loss: 2.0860112738865677

Epoch: 5| Step: 9
Training loss: 1.928480863571167
Validation loss: 2.095102599872056

Epoch: 5| Step: 10
Training loss: 2.7148585319519043
Validation loss: 2.110700020226099

Epoch: 255| Step: 0
Training loss: 2.540436267852783
Validation loss: 2.1055544243063977

Epoch: 5| Step: 1
Training loss: 1.8677303791046143
Validation loss: 2.114810200147731

Epoch: 5| Step: 2
Training loss: 1.706949234008789
Validation loss: 2.1148988534045476

Epoch: 5| Step: 3
Training loss: 2.0122017860412598
Validation loss: 2.1018932173329015

Epoch: 5| Step: 4
Training loss: 2.2509095668792725
Validation loss: 2.1052055025613434

Epoch: 5| Step: 5
Training loss: 2.7602391242980957
Validation loss: 2.131251863254014

Epoch: 5| Step: 6
Training loss: 2.0308053493499756
Validation loss: 2.1095697008153445

Epoch: 5| Step: 7
Training loss: 2.2427382469177246
Validation loss: 2.082891756488431

Epoch: 5| Step: 8
Training loss: 1.9078705310821533
Validation loss: 2.085751546326504

Epoch: 5| Step: 9
Training loss: 1.4933712482452393
Validation loss: 2.1150477522162983

Epoch: 5| Step: 10
Training loss: 2.1124656200408936
Validation loss: 2.108027458190918

Epoch: 256| Step: 0
Training loss: 2.3736109733581543
Validation loss: 2.1171110535180695

Epoch: 5| Step: 1
Training loss: 1.7954822778701782
Validation loss: 2.0848254080741637

Epoch: 5| Step: 2
Training loss: 1.3977606296539307
Validation loss: 2.13730054004218

Epoch: 5| Step: 3
Training loss: 2.3555150032043457
Validation loss: 2.1068549130552556

Epoch: 5| Step: 4
Training loss: 2.3932578563690186
Validation loss: 2.136903391089491

Epoch: 5| Step: 5
Training loss: 2.7659835815429688
Validation loss: 2.0960122551969302

Epoch: 5| Step: 6
Training loss: 2.347566843032837
Validation loss: 2.1074876605823474

Epoch: 5| Step: 7
Training loss: 1.7487767934799194
Validation loss: 2.0852797364675872

Epoch: 5| Step: 8
Training loss: 1.692086935043335
Validation loss: 2.1112077620721634

Epoch: 5| Step: 9
Training loss: 1.7328274250030518
Validation loss: 2.125249219197099

Epoch: 5| Step: 10
Training loss: 2.364919424057007
Validation loss: 2.1072003931127568

Epoch: 257| Step: 0
Training loss: 2.3247263431549072
Validation loss: 2.1212977875945387

Epoch: 5| Step: 1
Training loss: 2.0846400260925293
Validation loss: 2.134597614247312

Epoch: 5| Step: 2
Training loss: 2.4763309955596924
Validation loss: 2.0738365727086223

Epoch: 5| Step: 3
Training loss: 2.144665241241455
Validation loss: 2.0768533573355725

Epoch: 5| Step: 4
Training loss: 1.7640011310577393
Validation loss: 2.0822110150450017

Epoch: 5| Step: 5
Training loss: 2.2448041439056396
Validation loss: 2.0778975666210218

Epoch: 5| Step: 6
Training loss: 2.4727280139923096
Validation loss: 2.0826653511293474

Epoch: 5| Step: 7
Training loss: 1.3800814151763916
Validation loss: 2.099579934150942

Epoch: 5| Step: 8
Training loss: 2.090898036956787
Validation loss: 2.0866790163901543

Epoch: 5| Step: 9
Training loss: 1.553943395614624
Validation loss: 2.0930774237519953

Epoch: 5| Step: 10
Training loss: 2.5235788822174072
Validation loss: 2.061367860404394

Epoch: 258| Step: 0
Training loss: 1.964219331741333
Validation loss: 2.0755221741173857

Epoch: 5| Step: 1
Training loss: 2.3904428482055664
Validation loss: 2.0831237070022093

Epoch: 5| Step: 2
Training loss: 2.4101994037628174
Validation loss: 2.073610185295023

Epoch: 5| Step: 3
Training loss: 2.058561086654663
Validation loss: 2.0827873458144484

Epoch: 5| Step: 4
Training loss: 1.9576114416122437
Validation loss: 2.072752842339136

Epoch: 5| Step: 5
Training loss: 2.1665287017822266
Validation loss: 2.065922523057589

Epoch: 5| Step: 6
Training loss: 2.1741485595703125
Validation loss: 2.086108539694099

Epoch: 5| Step: 7
Training loss: 2.2620129585266113
Validation loss: 2.0746169718362952

Epoch: 5| Step: 8
Training loss: 2.0193421840667725
Validation loss: 2.060291992720737

Epoch: 5| Step: 9
Training loss: 1.8102385997772217
Validation loss: 2.0950867206819597

Epoch: 5| Step: 10
Training loss: 1.7369931936264038
Validation loss: 2.1089350382486978

Epoch: 259| Step: 0
Training loss: 1.8868945837020874
Validation loss: 2.115009448861563

Epoch: 5| Step: 1
Training loss: 2.132439136505127
Validation loss: 2.0924750476755123

Epoch: 5| Step: 2
Training loss: 2.5989952087402344
Validation loss: 2.1196056719749206

Epoch: 5| Step: 3
Training loss: 1.7148139476776123
Validation loss: 2.074025865524046

Epoch: 5| Step: 4
Training loss: 1.8213104009628296
Validation loss: 2.095286826933584

Epoch: 5| Step: 5
Training loss: 2.406306505203247
Validation loss: 2.1066431230114353

Epoch: 5| Step: 6
Training loss: 2.0636966228485107
Validation loss: 2.0850240876597743

Epoch: 5| Step: 7
Training loss: 2.134239435195923
Validation loss: 2.075721195949021

Epoch: 5| Step: 8
Training loss: 2.1114578247070312
Validation loss: 2.091634294038178

Epoch: 5| Step: 9
Training loss: 2.083372116088867
Validation loss: 2.1001527386326946

Epoch: 5| Step: 10
Training loss: 2.0026681423187256
Validation loss: 2.124471254246209

Epoch: 260| Step: 0
Training loss: 2.2782797813415527
Validation loss: 2.1297219568683254

Epoch: 5| Step: 1
Training loss: 1.9417461156845093
Validation loss: 2.107929281009141

Epoch: 5| Step: 2
Training loss: 1.7967866659164429
Validation loss: 2.1366411383434007

Epoch: 5| Step: 3
Training loss: 2.068176746368408
Validation loss: 2.1082130939729753

Epoch: 5| Step: 4
Training loss: 2.163374900817871
Validation loss: 2.1190116302941435

Epoch: 5| Step: 5
Training loss: 1.4853919744491577
Validation loss: 2.093354061085691

Epoch: 5| Step: 6
Training loss: 1.9602830410003662
Validation loss: 2.0971322444177445

Epoch: 5| Step: 7
Training loss: 2.3395180702209473
Validation loss: 2.0955479888505835

Epoch: 5| Step: 8
Training loss: 2.0447957515716553
Validation loss: 2.115846663393

Epoch: 5| Step: 9
Training loss: 2.618070125579834
Validation loss: 2.1333518092350294

Epoch: 5| Step: 10
Training loss: 2.265828847885132
Validation loss: 2.123559569799772

Epoch: 261| Step: 0
Training loss: 1.9488906860351562
Validation loss: 2.090574064562398

Epoch: 5| Step: 1
Training loss: 2.412209987640381
Validation loss: 2.083220120399229

Epoch: 5| Step: 2
Training loss: 2.4975616931915283
Validation loss: 2.1283009872641614

Epoch: 5| Step: 3
Training loss: 2.2740044593811035
Validation loss: 2.1198771640818608

Epoch: 5| Step: 4
Training loss: 2.4744842052459717
Validation loss: 2.1000653864235006

Epoch: 5| Step: 5
Training loss: 2.0018210411071777
Validation loss: 2.099486440740606

Epoch: 5| Step: 6
Training loss: 1.8189477920532227
Validation loss: 2.101142344936248

Epoch: 5| Step: 7
Training loss: 2.1617040634155273
Validation loss: 2.1270269347775366

Epoch: 5| Step: 8
Training loss: 2.1758475303649902
Validation loss: 2.0953364884981545

Epoch: 5| Step: 9
Training loss: 1.5435988903045654
Validation loss: 2.093868288942563

Epoch: 5| Step: 10
Training loss: 1.6016168594360352
Validation loss: 2.0443181735213085

Epoch: 262| Step: 0
Training loss: 1.9437650442123413
Validation loss: 2.0640530176060174

Epoch: 5| Step: 1
Training loss: 1.5847272872924805
Validation loss: 2.0809348142275246

Epoch: 5| Step: 2
Training loss: 2.018711566925049
Validation loss: 2.066494967347832

Epoch: 5| Step: 3
Training loss: 2.301135778427124
Validation loss: 2.0975066807962235

Epoch: 5| Step: 4
Training loss: 2.3189544677734375
Validation loss: 2.108498413075683

Epoch: 5| Step: 5
Training loss: 2.5781664848327637
Validation loss: 2.0783573837690454

Epoch: 5| Step: 6
Training loss: 2.5464937686920166
Validation loss: 2.0901373663256244

Epoch: 5| Step: 7
Training loss: 2.2005505561828613
Validation loss: 2.106918483652094

Epoch: 5| Step: 8
Training loss: 1.768355369567871
Validation loss: 2.089280536097865

Epoch: 5| Step: 9
Training loss: 1.2688145637512207
Validation loss: 2.0843105187980075

Epoch: 5| Step: 10
Training loss: 2.040074586868286
Validation loss: 2.0990633246719197

Epoch: 263| Step: 0
Training loss: 2.5050737857818604
Validation loss: 2.122403638337248

Epoch: 5| Step: 1
Training loss: 2.0875630378723145
Validation loss: 2.0972151012830835

Epoch: 5| Step: 2
Training loss: 1.9604909420013428
Validation loss: 2.1085944470538887

Epoch: 5| Step: 3
Training loss: 2.522545337677002
Validation loss: 2.0828146088507866

Epoch: 5| Step: 4
Training loss: 2.5239689350128174
Validation loss: 2.085332424409928

Epoch: 5| Step: 5
Training loss: 2.1875128746032715
Validation loss: 2.0752806189239665

Epoch: 5| Step: 6
Training loss: 2.3398940563201904
Validation loss: 2.1023621328415407

Epoch: 5| Step: 7
Training loss: 2.106177806854248
Validation loss: 2.086095453590475

Epoch: 5| Step: 8
Training loss: 1.2667484283447266
Validation loss: 2.0712475866399784

Epoch: 5| Step: 9
Training loss: 1.373246192932129
Validation loss: 2.084610072515344

Epoch: 5| Step: 10
Training loss: 1.8603014945983887
Validation loss: 2.108888887589978

Epoch: 264| Step: 0
Training loss: 1.8683254718780518
Validation loss: 2.1072999508150163

Epoch: 5| Step: 1
Training loss: 2.4333291053771973
Validation loss: 2.0861751046231998

Epoch: 5| Step: 2
Training loss: 1.4293333292007446
Validation loss: 2.086514346061214

Epoch: 5| Step: 3
Training loss: 1.8612754344940186
Validation loss: 2.0960092390737226

Epoch: 5| Step: 4
Training loss: 1.7872997522354126
Validation loss: 2.079950476205477

Epoch: 5| Step: 5
Training loss: 2.0788025856018066
Validation loss: 2.0998162556720037

Epoch: 5| Step: 6
Training loss: 2.536428451538086
Validation loss: 2.0912723310532106

Epoch: 5| Step: 7
Training loss: 2.1802000999450684
Validation loss: 2.0775972027932443

Epoch: 5| Step: 8
Training loss: 2.461583375930786
Validation loss: 2.097494424030345

Epoch: 5| Step: 9
Training loss: 1.9682315587997437
Validation loss: 2.099343135792722

Epoch: 5| Step: 10
Training loss: 2.374319076538086
Validation loss: 2.0830185156996532

Epoch: 265| Step: 0
Training loss: 1.638021469116211
Validation loss: 2.0895831072202293

Epoch: 5| Step: 1
Training loss: 2.1922523975372314
Validation loss: 2.0974631335145686

Epoch: 5| Step: 2
Training loss: 2.438958168029785
Validation loss: 2.092674557880689

Epoch: 5| Step: 3
Training loss: 2.2209346294403076
Validation loss: 2.0906334487340783

Epoch: 5| Step: 4
Training loss: 1.909558892250061
Validation loss: 2.081770989202684

Epoch: 5| Step: 5
Training loss: 1.8859226703643799
Validation loss: 2.100786739780057

Epoch: 5| Step: 6
Training loss: 1.858109712600708
Validation loss: 2.078899411744969

Epoch: 5| Step: 7
Training loss: 2.4021313190460205
Validation loss: 2.0857239371986798

Epoch: 5| Step: 8
Training loss: 1.9645830392837524
Validation loss: 2.102005274065079

Epoch: 5| Step: 9
Training loss: 2.142805576324463
Validation loss: 2.0819122073470906

Epoch: 5| Step: 10
Training loss: 2.1961724758148193
Validation loss: 2.1220084390332623

Epoch: 266| Step: 0
Training loss: 1.9293159246444702
Validation loss: 2.1015923997407318

Epoch: 5| Step: 1
Training loss: 1.662405014038086
Validation loss: 2.1013510496385637

Epoch: 5| Step: 2
Training loss: 2.548668384552002
Validation loss: 2.102887595853498

Epoch: 5| Step: 3
Training loss: 2.2970783710479736
Validation loss: 2.1045715731959187

Epoch: 5| Step: 4
Training loss: 2.4131722450256348
Validation loss: 2.111375844606789

Epoch: 5| Step: 5
Training loss: 2.2118287086486816
Validation loss: 2.1121276578595563

Epoch: 5| Step: 6
Training loss: 1.9310020208358765
Validation loss: 2.0872298825171685

Epoch: 5| Step: 7
Training loss: 1.9989982843399048
Validation loss: 2.112387821238528

Epoch: 5| Step: 8
Training loss: 1.562225341796875
Validation loss: 2.0902411014802995

Epoch: 5| Step: 9
Training loss: 2.126967191696167
Validation loss: 2.092549418890348

Epoch: 5| Step: 10
Training loss: 2.04154372215271
Validation loss: 2.099386512592275

Epoch: 267| Step: 0
Training loss: 2.8184094429016113
Validation loss: 2.101770036964006

Epoch: 5| Step: 1
Training loss: 2.6404061317443848
Validation loss: 2.073608101055186

Epoch: 5| Step: 2
Training loss: 2.1241097450256348
Validation loss: 2.085662685414796

Epoch: 5| Step: 3
Training loss: 2.435539960861206
Validation loss: 2.111032585943899

Epoch: 5| Step: 4
Training loss: 2.409587860107422
Validation loss: 2.07402475162219

Epoch: 5| Step: 5
Training loss: 1.2705886363983154
Validation loss: 2.068921234018059

Epoch: 5| Step: 6
Training loss: 1.515285849571228
Validation loss: 2.0656336712580856

Epoch: 5| Step: 7
Training loss: 1.9509122371673584
Validation loss: 2.0612477076950895

Epoch: 5| Step: 8
Training loss: 2.184579372406006
Validation loss: 2.04982764233825

Epoch: 5| Step: 9
Training loss: 1.5010063648223877
Validation loss: 2.1057881027139644

Epoch: 5| Step: 10
Training loss: 1.9905644655227661
Validation loss: 2.1003421814210954

Epoch: 268| Step: 0
Training loss: 1.965248703956604
Validation loss: 2.096472931164567

Epoch: 5| Step: 1
Training loss: 1.5331343412399292
Validation loss: 2.082501326837847

Epoch: 5| Step: 2
Training loss: 2.097275972366333
Validation loss: 2.0584860104386524

Epoch: 5| Step: 3
Training loss: 2.3617231845855713
Validation loss: 2.0829870303471885

Epoch: 5| Step: 4
Training loss: 1.7103694677352905
Validation loss: 2.0619421851250435

Epoch: 5| Step: 5
Training loss: 2.6906580924987793
Validation loss: 2.0919887045378327

Epoch: 5| Step: 6
Training loss: 2.13438081741333
Validation loss: 2.069466660099645

Epoch: 5| Step: 7
Training loss: 1.980176329612732
Validation loss: 2.0500265218878306

Epoch: 5| Step: 8
Training loss: 2.145059585571289
Validation loss: 2.097509621292032

Epoch: 5| Step: 9
Training loss: 2.1992225646972656
Validation loss: 2.072551888804282

Epoch: 5| Step: 10
Training loss: 2.0919880867004395
Validation loss: 2.1111721300309703

Epoch: 269| Step: 0
Training loss: 1.6958630084991455
Validation loss: 2.0829604620574624

Epoch: 5| Step: 1
Training loss: 2.611102342605591
Validation loss: 2.088106862960323

Epoch: 5| Step: 2
Training loss: 1.7277923822402954
Validation loss: 2.0912227066614295

Epoch: 5| Step: 3
Training loss: 2.3899776935577393
Validation loss: 2.10372878402792

Epoch: 5| Step: 4
Training loss: 1.5106526613235474
Validation loss: 2.0823446525040494

Epoch: 5| Step: 5
Training loss: 2.0853679180145264
Validation loss: 2.133513799277685

Epoch: 5| Step: 6
Training loss: 2.532121181488037
Validation loss: 2.1105778537770754

Epoch: 5| Step: 7
Training loss: 2.070310592651367
Validation loss: 2.098559700032716

Epoch: 5| Step: 8
Training loss: 1.5417848825454712
Validation loss: 2.090730426132038

Epoch: 5| Step: 9
Training loss: 2.032827377319336
Validation loss: 2.1100739535465034

Epoch: 5| Step: 10
Training loss: 2.814922571182251
Validation loss: 2.095873627611386

Epoch: 270| Step: 0
Training loss: 1.5724581480026245
Validation loss: 2.1042765532770464

Epoch: 5| Step: 1
Training loss: 1.8207824230194092
Validation loss: 2.140851564304803

Epoch: 5| Step: 2
Training loss: 2.2692713737487793
Validation loss: 2.1241526411425684

Epoch: 5| Step: 3
Training loss: 2.5300278663635254
Validation loss: 2.124391551940672

Epoch: 5| Step: 4
Training loss: 1.8810908794403076
Validation loss: 2.1010783590296263

Epoch: 5| Step: 5
Training loss: 2.365377426147461
Validation loss: 2.1214689952070995

Epoch: 5| Step: 6
Training loss: 1.7036882638931274
Validation loss: 2.1248436743213284

Epoch: 5| Step: 7
Training loss: 2.351391553878784
Validation loss: 2.112424588972522

Epoch: 5| Step: 8
Training loss: 2.606165885925293
Validation loss: 2.11686344556911

Epoch: 5| Step: 9
Training loss: 1.7623851299285889
Validation loss: 2.1205338752397926

Epoch: 5| Step: 10
Training loss: 1.8714662790298462
Validation loss: 2.1184370722821964

Epoch: 271| Step: 0
Training loss: 1.698568344116211
Validation loss: 2.12365250690009

Epoch: 5| Step: 1
Training loss: 2.331751585006714
Validation loss: 2.125022654892296

Epoch: 5| Step: 2
Training loss: 1.5032427310943604
Validation loss: 2.096027126876257

Epoch: 5| Step: 3
Training loss: 1.9604030847549438
Validation loss: 2.0877088449334584

Epoch: 5| Step: 4
Training loss: 1.6924183368682861
Validation loss: 2.0886436713639127

Epoch: 5| Step: 5
Training loss: 2.1806063652038574
Validation loss: 2.101612179510055

Epoch: 5| Step: 6
Training loss: 2.269195079803467
Validation loss: 2.1024001183048373

Epoch: 5| Step: 7
Training loss: 2.1516799926757812
Validation loss: 2.0624920552776707

Epoch: 5| Step: 8
Training loss: 2.1583423614501953
Validation loss: 2.069029185079759

Epoch: 5| Step: 9
Training loss: 2.3861584663391113
Validation loss: 2.066476919317758

Epoch: 5| Step: 10
Training loss: 2.379544258117676
Validation loss: 2.0797432878965973

Epoch: 272| Step: 0
Training loss: 2.0821077823638916
Validation loss: 2.1036353931632092

Epoch: 5| Step: 1
Training loss: 1.819141149520874
Validation loss: 2.1186317948884863

Epoch: 5| Step: 2
Training loss: 2.1721606254577637
Validation loss: 2.062347727437173

Epoch: 5| Step: 3
Training loss: 1.9058902263641357
Validation loss: 2.0909162311143774

Epoch: 5| Step: 4
Training loss: 1.8198535442352295
Validation loss: 2.087641271211768

Epoch: 5| Step: 5
Training loss: 1.9421745538711548
Validation loss: 2.089751728119389

Epoch: 5| Step: 6
Training loss: 2.617551803588867
Validation loss: 2.0933962124650196

Epoch: 5| Step: 7
Training loss: 2.2083544731140137
Validation loss: 2.1025502950914445

Epoch: 5| Step: 8
Training loss: 2.286851406097412
Validation loss: 2.1002388743944067

Epoch: 5| Step: 9
Training loss: 1.627459168434143
Validation loss: 2.0830714112968853

Epoch: 5| Step: 10
Training loss: 2.2461888790130615
Validation loss: 2.0909421546484834

Epoch: 273| Step: 0
Training loss: 2.009425401687622
Validation loss: 2.0989826456193

Epoch: 5| Step: 1
Training loss: 1.9942560195922852
Validation loss: 2.099179288392426

Epoch: 5| Step: 2
Training loss: 2.1977627277374268
Validation loss: 2.0910774341193576

Epoch: 5| Step: 3
Training loss: 2.0366828441619873
Validation loss: 2.0999015018504155

Epoch: 5| Step: 4
Training loss: 2.204944133758545
Validation loss: 2.111270684067921

Epoch: 5| Step: 5
Training loss: 1.8673804998397827
Validation loss: 2.1095925902807586

Epoch: 5| Step: 6
Training loss: 1.8135602474212646
Validation loss: 2.1468533918421757

Epoch: 5| Step: 7
Training loss: 1.6087392568588257
Validation loss: 2.1312017774069183

Epoch: 5| Step: 8
Training loss: 2.552388906478882
Validation loss: 2.102597213560535

Epoch: 5| Step: 9
Training loss: 2.181448459625244
Validation loss: 2.1600416168089835

Epoch: 5| Step: 10
Training loss: 2.404980421066284
Validation loss: 2.1238302979418027

Epoch: 274| Step: 0
Training loss: 2.506950855255127
Validation loss: 2.1057018105701735

Epoch: 5| Step: 1
Training loss: 2.5121946334838867
Validation loss: 2.0718229022077335

Epoch: 5| Step: 2
Training loss: 1.6081796884536743
Validation loss: 2.1069397490511657

Epoch: 5| Step: 3
Training loss: 1.5181716680526733
Validation loss: 2.1208535522542973

Epoch: 5| Step: 4
Training loss: 1.7180324792861938
Validation loss: 2.1522223026521745

Epoch: 5| Step: 5
Training loss: 2.2752292156219482
Validation loss: 2.119309094644362

Epoch: 5| Step: 6
Training loss: 1.7470295429229736
Validation loss: 2.1190621211964595

Epoch: 5| Step: 7
Training loss: 2.6952812671661377
Validation loss: 2.1071022351582847

Epoch: 5| Step: 8
Training loss: 1.8095146417617798
Validation loss: 2.0894025307829662

Epoch: 5| Step: 9
Training loss: 1.7605769634246826
Validation loss: 2.092442153602518

Epoch: 5| Step: 10
Training loss: 2.626478433609009
Validation loss: 2.0852181911468506

Epoch: 275| Step: 0
Training loss: 1.9942405223846436
Validation loss: 2.0996504278593164

Epoch: 5| Step: 1
Training loss: 1.835923433303833
Validation loss: 2.0978479769922074

Epoch: 5| Step: 2
Training loss: 2.081690788269043
Validation loss: 2.0816116409917034

Epoch: 5| Step: 3
Training loss: 2.6731839179992676
Validation loss: 2.0735409580251223

Epoch: 5| Step: 4
Training loss: 1.3187445402145386
Validation loss: 2.0713632747691166

Epoch: 5| Step: 5
Training loss: 1.3535964488983154
Validation loss: 2.1051486897212204

Epoch: 5| Step: 6
Training loss: 1.7729222774505615
Validation loss: 2.090472600793326

Epoch: 5| Step: 7
Training loss: 2.334641695022583
Validation loss: 2.0991928141604186

Epoch: 5| Step: 8
Training loss: 2.2220299243927
Validation loss: 2.0745249614920667

Epoch: 5| Step: 9
Training loss: 2.790489673614502
Validation loss: 2.096449118788524

Epoch: 5| Step: 10
Training loss: 2.308952808380127
Validation loss: 2.0644466646255983

Epoch: 276| Step: 0
Training loss: 1.9456809759140015
Validation loss: 2.0912896164001955

Epoch: 5| Step: 1
Training loss: 1.8070018291473389
Validation loss: 2.0848059192780526

Epoch: 5| Step: 2
Training loss: 2.372708797454834
Validation loss: 2.0713574899140226

Epoch: 5| Step: 3
Training loss: 1.7491124868392944
Validation loss: 2.104468084150745

Epoch: 5| Step: 4
Training loss: 1.9407914876937866
Validation loss: 2.070214681727912

Epoch: 5| Step: 5
Training loss: 1.8055264949798584
Validation loss: 2.070347188621439

Epoch: 5| Step: 6
Training loss: 2.3414411544799805
Validation loss: 2.079768498738607

Epoch: 5| Step: 7
Training loss: 2.257005214691162
Validation loss: 2.0849824797722603

Epoch: 5| Step: 8
Training loss: 1.9971519708633423
Validation loss: 2.0960067907969155

Epoch: 5| Step: 9
Training loss: 2.0674195289611816
Validation loss: 2.089067388606328

Epoch: 5| Step: 10
Training loss: 2.0656490325927734
Validation loss: 2.0748311922114384

Epoch: 277| Step: 0
Training loss: 1.7038838863372803
Validation loss: 2.102134516162257

Epoch: 5| Step: 1
Training loss: 2.1808390617370605
Validation loss: 2.0827247455555904

Epoch: 5| Step: 2
Training loss: 2.2750320434570312
Validation loss: 2.0791582702308573

Epoch: 5| Step: 3
Training loss: 2.1763062477111816
Validation loss: 2.09553014591176

Epoch: 5| Step: 4
Training loss: 2.020615816116333
Validation loss: 2.111876733841435

Epoch: 5| Step: 5
Training loss: 2.147002935409546
Validation loss: 2.085235385484593

Epoch: 5| Step: 6
Training loss: 1.258135199546814
Validation loss: 2.09128693098663

Epoch: 5| Step: 7
Training loss: 1.949438452720642
Validation loss: 2.066527966530092

Epoch: 5| Step: 8
Training loss: 2.2911248207092285
Validation loss: 2.063855137876285

Epoch: 5| Step: 9
Training loss: 2.3439078330993652
Validation loss: 2.0979293918096893

Epoch: 5| Step: 10
Training loss: 2.365022659301758
Validation loss: 2.0964211225509644

Epoch: 278| Step: 0
Training loss: 2.3151333332061768
Validation loss: 2.091967095610916

Epoch: 5| Step: 1
Training loss: 2.454714775085449
Validation loss: 2.0821483353132844

Epoch: 5| Step: 2
Training loss: 1.716805100440979
Validation loss: 2.071160049848659

Epoch: 5| Step: 3
Training loss: 1.565891981124878
Validation loss: 2.095016121864319

Epoch: 5| Step: 4
Training loss: 1.6196460723876953
Validation loss: 2.079270839691162

Epoch: 5| Step: 5
Training loss: 2.402317523956299
Validation loss: 2.094700107010462

Epoch: 5| Step: 6
Training loss: 2.0804340839385986
Validation loss: 2.0837219133171985

Epoch: 5| Step: 7
Training loss: 2.5554428100585938
Validation loss: 2.119249577163368

Epoch: 5| Step: 8
Training loss: 2.5546371936798096
Validation loss: 2.093090318864392

Epoch: 5| Step: 9
Training loss: 1.4452049732208252
Validation loss: 2.1022326446348623

Epoch: 5| Step: 10
Training loss: 1.840027928352356
Validation loss: 2.106397280129053

Epoch: 279| Step: 0
Training loss: 2.2772507667541504
Validation loss: 2.0866398747249315

Epoch: 5| Step: 1
Training loss: 2.088412046432495
Validation loss: 2.078231844850766

Epoch: 5| Step: 2
Training loss: 2.028949499130249
Validation loss: 2.105069011770269

Epoch: 5| Step: 3
Training loss: 1.59097421169281
Validation loss: 2.0825744572506157

Epoch: 5| Step: 4
Training loss: 1.944976568222046
Validation loss: 2.0836477202753865

Epoch: 5| Step: 5
Training loss: 2.340299606323242
Validation loss: 2.0976414885572208

Epoch: 5| Step: 6
Training loss: 1.8336689472198486
Validation loss: 2.0985084861837406

Epoch: 5| Step: 7
Training loss: 2.128317356109619
Validation loss: 2.0991303613108974

Epoch: 5| Step: 8
Training loss: 1.5731552839279175
Validation loss: 2.096949420949464

Epoch: 5| Step: 9
Training loss: 2.361100196838379
Validation loss: 2.0750313625540784

Epoch: 5| Step: 10
Training loss: 2.61655330657959
Validation loss: 2.0782046856418734

Epoch: 280| Step: 0
Training loss: 2.6652092933654785
Validation loss: 2.08973168429508

Epoch: 5| Step: 1
Training loss: 2.3004417419433594
Validation loss: 2.0898786949855026

Epoch: 5| Step: 2
Training loss: 2.654244899749756
Validation loss: 2.119750525361748

Epoch: 5| Step: 3
Training loss: 1.8631643056869507
Validation loss: 2.097830225062627

Epoch: 5| Step: 4
Training loss: 2.332219123840332
Validation loss: 2.086672877752653

Epoch: 5| Step: 5
Training loss: 2.309370994567871
Validation loss: 2.0901784691759335

Epoch: 5| Step: 6
Training loss: 1.4232845306396484
Validation loss: 2.07776786563217

Epoch: 5| Step: 7
Training loss: 2.061927556991577
Validation loss: 2.095984284595777

Epoch: 5| Step: 8
Training loss: 1.685459852218628
Validation loss: 2.070809802701396

Epoch: 5| Step: 9
Training loss: 1.7588764429092407
Validation loss: 2.0969821458221762

Epoch: 5| Step: 10
Training loss: 1.7363314628601074
Validation loss: 2.07631794739795

Epoch: 281| Step: 0
Training loss: 1.7277618646621704
Validation loss: 2.088460277485591

Epoch: 5| Step: 1
Training loss: 1.878252625465393
Validation loss: 2.076369090746808

Epoch: 5| Step: 2
Training loss: 2.4126267433166504
Validation loss: 2.077181080336212

Epoch: 5| Step: 3
Training loss: 2.41245698928833
Validation loss: 2.0969158757117485

Epoch: 5| Step: 4
Training loss: 1.7692859172821045
Validation loss: 2.097526402883632

Epoch: 5| Step: 5
Training loss: 1.9828331470489502
Validation loss: 2.09034966140665

Epoch: 5| Step: 6
Training loss: 2.1770119667053223
Validation loss: 2.102602784351636

Epoch: 5| Step: 7
Training loss: 2.2684953212738037
Validation loss: 2.0831144061139835

Epoch: 5| Step: 8
Training loss: 1.988273024559021
Validation loss: 2.096624625626431

Epoch: 5| Step: 9
Training loss: 2.0158066749572754
Validation loss: 2.087407309521911

Epoch: 5| Step: 10
Training loss: 2.2964112758636475
Validation loss: 2.0918635963111796

Epoch: 282| Step: 0
Training loss: 2.2963805198669434
Validation loss: 2.10551187299913

Epoch: 5| Step: 1
Training loss: 1.9409027099609375
Validation loss: 2.1197032928466797

Epoch: 5| Step: 2
Training loss: 2.1695170402526855
Validation loss: 2.102239429309804

Epoch: 5| Step: 3
Training loss: 1.7314927577972412
Validation loss: 2.123325792692041

Epoch: 5| Step: 4
Training loss: 2.12221360206604
Validation loss: 2.1162537605531755

Epoch: 5| Step: 5
Training loss: 2.0488409996032715
Validation loss: 2.0952954907571115

Epoch: 5| Step: 6
Training loss: 2.320294141769409
Validation loss: 2.1180873532449045

Epoch: 5| Step: 7
Training loss: 2.0095624923706055
Validation loss: 2.0942954299270466

Epoch: 5| Step: 8
Training loss: 1.9745738506317139
Validation loss: 2.1142672390066166

Epoch: 5| Step: 9
Training loss: 2.3150181770324707
Validation loss: 2.0777257027164584

Epoch: 5| Step: 10
Training loss: 1.6630204916000366
Validation loss: 2.0938528788987028

Epoch: 283| Step: 0
Training loss: 1.5048997402191162
Validation loss: 2.0887725263513546

Epoch: 5| Step: 1
Training loss: 2.1691951751708984
Validation loss: 2.077776156445985

Epoch: 5| Step: 2
Training loss: 1.5815414190292358
Validation loss: 2.085552170712461

Epoch: 5| Step: 3
Training loss: 1.7554289102554321
Validation loss: 2.111780838299823

Epoch: 5| Step: 4
Training loss: 2.471158027648926
Validation loss: 2.085145542698522

Epoch: 5| Step: 5
Training loss: 2.4820785522460938
Validation loss: 2.09378360420145

Epoch: 5| Step: 6
Training loss: 2.3201098442077637
Validation loss: 2.0785944718186573

Epoch: 5| Step: 7
Training loss: 2.492539167404175
Validation loss: 2.069646895572703

Epoch: 5| Step: 8
Training loss: 1.715416669845581
Validation loss: 2.0786069349576066

Epoch: 5| Step: 9
Training loss: 2.1714231967926025
Validation loss: 2.099084013251848

Epoch: 5| Step: 10
Training loss: 2.1039552688598633
Validation loss: 2.063247074363052

Epoch: 284| Step: 0
Training loss: 2.356834650039673
Validation loss: 2.0715961046116327

Epoch: 5| Step: 1
Training loss: 1.9050893783569336
Validation loss: 2.0848337552880727

Epoch: 5| Step: 2
Training loss: 1.8720744848251343
Validation loss: 2.0724519029740365

Epoch: 5| Step: 3
Training loss: 1.9247993230819702
Validation loss: 2.1082990605344056

Epoch: 5| Step: 4
Training loss: 1.3499760627746582
Validation loss: 2.09561566639972

Epoch: 5| Step: 5
Training loss: 2.2772164344787598
Validation loss: 2.1222902344119166

Epoch: 5| Step: 6
Training loss: 2.2219080924987793
Validation loss: 2.09379550462128

Epoch: 5| Step: 7
Training loss: 2.5970547199249268
Validation loss: 2.129777435333498

Epoch: 5| Step: 8
Training loss: 2.095133066177368
Validation loss: 2.100688733080382

Epoch: 5| Step: 9
Training loss: 1.7280828952789307
Validation loss: 2.1020918661548245

Epoch: 5| Step: 10
Training loss: 2.485008955001831
Validation loss: 2.106520337443198

Epoch: 285| Step: 0
Training loss: 2.2127938270568848
Validation loss: 2.075576373325881

Epoch: 5| Step: 1
Training loss: 2.318596839904785
Validation loss: 2.1049713255256735

Epoch: 5| Step: 2
Training loss: 2.245239734649658
Validation loss: 2.10498950558324

Epoch: 5| Step: 3
Training loss: 2.1416404247283936
Validation loss: 2.0926324603378132

Epoch: 5| Step: 4
Training loss: 1.962215781211853
Validation loss: 2.0993529365908716

Epoch: 5| Step: 5
Training loss: 2.3667187690734863
Validation loss: 2.100598774930482

Epoch: 5| Step: 6
Training loss: 2.320281505584717
Validation loss: 2.099363209098898

Epoch: 5| Step: 7
Training loss: 1.648909568786621
Validation loss: 2.103811840857229

Epoch: 5| Step: 8
Training loss: 1.503189206123352
Validation loss: 2.0872550472136466

Epoch: 5| Step: 9
Training loss: 1.772015929222107
Validation loss: 2.1209342530978623

Epoch: 5| Step: 10
Training loss: 1.9200907945632935
Validation loss: 2.112394622577134

Epoch: 286| Step: 0
Training loss: 1.9457883834838867
Validation loss: 2.1000492829148487

Epoch: 5| Step: 1
Training loss: 2.2005722522735596
Validation loss: 2.0982990482802033

Epoch: 5| Step: 2
Training loss: 1.7490198612213135
Validation loss: 2.0923695666815645

Epoch: 5| Step: 3
Training loss: 1.9696693420410156
Validation loss: 2.0902890543783865

Epoch: 5| Step: 4
Training loss: 2.6584794521331787
Validation loss: 2.095505045306298

Epoch: 5| Step: 5
Training loss: 2.1308155059814453
Validation loss: 2.0954188685263357

Epoch: 5| Step: 6
Training loss: 2.594040870666504
Validation loss: 2.0919655407628706

Epoch: 5| Step: 7
Training loss: 1.3722784519195557
Validation loss: 2.043421606863699

Epoch: 5| Step: 8
Training loss: 2.388011932373047
Validation loss: 2.082987267483947

Epoch: 5| Step: 9
Training loss: 1.697083830833435
Validation loss: 2.0651352085093015

Epoch: 5| Step: 10
Training loss: 1.7140016555786133
Validation loss: 2.0719310173424343

Epoch: 287| Step: 0
Training loss: 1.750889539718628
Validation loss: 2.0871319155539236

Epoch: 5| Step: 1
Training loss: 2.5693106651306152
Validation loss: 2.112450030542189

Epoch: 5| Step: 2
Training loss: 1.9792473316192627
Validation loss: 2.0718468286657847

Epoch: 5| Step: 3
Training loss: 2.002967596054077
Validation loss: 2.108934828030166

Epoch: 5| Step: 4
Training loss: 1.8620021343231201
Validation loss: 2.1011830222222114

Epoch: 5| Step: 5
Training loss: 2.243370771408081
Validation loss: 2.0785355760205175

Epoch: 5| Step: 6
Training loss: 1.957362413406372
Validation loss: 2.0979395092174573

Epoch: 5| Step: 7
Training loss: 2.076524019241333
Validation loss: 2.0829117400671846

Epoch: 5| Step: 8
Training loss: 2.375375509262085
Validation loss: 2.0966958486905662

Epoch: 5| Step: 9
Training loss: 1.954411268234253
Validation loss: 2.073666185461065

Epoch: 5| Step: 10
Training loss: 1.6442209482192993
Validation loss: 2.114971442889142

Epoch: 288| Step: 0
Training loss: 2.5716381072998047
Validation loss: 2.1137172842538483

Epoch: 5| Step: 1
Training loss: 2.2908072471618652
Validation loss: 2.1158027187470467

Epoch: 5| Step: 2
Training loss: 2.255023956298828
Validation loss: 2.0929085362342095

Epoch: 5| Step: 3
Training loss: 1.8357197046279907
Validation loss: 2.0929897677513862

Epoch: 5| Step: 4
Training loss: 1.6105964183807373
Validation loss: 2.110991895839732

Epoch: 5| Step: 5
Training loss: 2.28056263923645
Validation loss: 2.1090590184734714

Epoch: 5| Step: 6
Training loss: 2.076456069946289
Validation loss: 2.092793676160997

Epoch: 5| Step: 7
Training loss: 2.1568336486816406
Validation loss: 2.1236487409119964

Epoch: 5| Step: 8
Training loss: 2.045236110687256
Validation loss: 2.079969944492463

Epoch: 5| Step: 9
Training loss: 1.4450021982192993
Validation loss: 2.119322746030746

Epoch: 5| Step: 10
Training loss: 1.912500262260437
Validation loss: 2.1088556346072944

Epoch: 289| Step: 0
Training loss: 1.5727179050445557
Validation loss: 2.0816838933575537

Epoch: 5| Step: 1
Training loss: 1.8951756954193115
Validation loss: 2.1017418753716255

Epoch: 5| Step: 2
Training loss: 2.5253233909606934
Validation loss: 2.0944022799050934

Epoch: 5| Step: 3
Training loss: 1.804319977760315
Validation loss: 2.109980765209403

Epoch: 5| Step: 4
Training loss: 2.4152259826660156
Validation loss: 2.0719540644717473

Epoch: 5| Step: 5
Training loss: 2.149796962738037
Validation loss: 2.1182612219164447

Epoch: 5| Step: 6
Training loss: 1.8002345561981201
Validation loss: 2.0674291451772056

Epoch: 5| Step: 7
Training loss: 2.678114414215088
Validation loss: 2.094758733626335

Epoch: 5| Step: 8
Training loss: 1.4957011938095093
Validation loss: 2.1165707444631927

Epoch: 5| Step: 9
Training loss: 2.0798592567443848
Validation loss: 2.110740336038733

Epoch: 5| Step: 10
Training loss: 2.2471659183502197
Validation loss: 2.1076682690651185

Epoch: 290| Step: 0
Training loss: 1.930902123451233
Validation loss: 2.11240828165444

Epoch: 5| Step: 1
Training loss: 1.5789940357208252
Validation loss: 2.0879447588356594

Epoch: 5| Step: 2
Training loss: 2.1405181884765625
Validation loss: 2.0979102529505247

Epoch: 5| Step: 3
Training loss: 1.5495028495788574
Validation loss: 2.112631546553745

Epoch: 5| Step: 4
Training loss: 1.5006625652313232
Validation loss: 2.098657968223736

Epoch: 5| Step: 5
Training loss: 2.189422845840454
Validation loss: 2.1036125280523814

Epoch: 5| Step: 6
Training loss: 2.782508134841919
Validation loss: 2.072778337745256

Epoch: 5| Step: 7
Training loss: 2.0731606483459473
Validation loss: 2.0686484613726215

Epoch: 5| Step: 8
Training loss: 2.593470811843872
Validation loss: 2.07342057330634

Epoch: 5| Step: 9
Training loss: 2.2905075550079346
Validation loss: 2.077092456561263

Epoch: 5| Step: 10
Training loss: 1.8950202465057373
Validation loss: 2.071820633385771

Epoch: 291| Step: 0
Training loss: 2.2993862628936768
Validation loss: 2.0778614051880373

Epoch: 5| Step: 1
Training loss: 2.329390048980713
Validation loss: 2.107892144110895

Epoch: 5| Step: 2
Training loss: 2.2629036903381348
Validation loss: 2.079615915975263

Epoch: 5| Step: 3
Training loss: 1.6927560567855835
Validation loss: 2.0919630476223525

Epoch: 5| Step: 4
Training loss: 2.2833306789398193
Validation loss: 2.0727717991798156

Epoch: 5| Step: 5
Training loss: 1.7701953649520874
Validation loss: 2.0768748124440513

Epoch: 5| Step: 6
Training loss: 1.8325926065444946
Validation loss: 2.063759493571456

Epoch: 5| Step: 7
Training loss: 2.22855281829834
Validation loss: 2.085967925287062

Epoch: 5| Step: 8
Training loss: 2.076683282852173
Validation loss: 2.058207073519307

Epoch: 5| Step: 9
Training loss: 2.3579211235046387
Validation loss: 2.0933344184711413

Epoch: 5| Step: 10
Training loss: 1.1434582471847534
Validation loss: 2.066758548059771

Epoch: 292| Step: 0
Training loss: 2.052006244659424
Validation loss: 2.0909551317973802

Epoch: 5| Step: 1
Training loss: 2.247209072113037
Validation loss: 2.0871778508668304

Epoch: 5| Step: 2
Training loss: 2.2793869972229004
Validation loss: 2.087628297908332

Epoch: 5| Step: 3
Training loss: 1.8607733249664307
Validation loss: 2.117692196240989

Epoch: 5| Step: 4
Training loss: 2.749203681945801
Validation loss: 2.069567549613214

Epoch: 5| Step: 5
Training loss: 1.5767390727996826
Validation loss: 2.0806371601678992

Epoch: 5| Step: 6
Training loss: 1.6186326742172241
Validation loss: 2.099436754821449

Epoch: 5| Step: 7
Training loss: 1.6954777240753174
Validation loss: 2.0974506152573453

Epoch: 5| Step: 8
Training loss: 1.8991320133209229
Validation loss: 2.082276672445318

Epoch: 5| Step: 9
Training loss: 1.6639400720596313
Validation loss: 2.098729734779686

Epoch: 5| Step: 10
Training loss: 3.0894129276275635
Validation loss: 2.081124372379754

Epoch: 293| Step: 0
Training loss: 2.3555009365081787
Validation loss: 2.0973392327626548

Epoch: 5| Step: 1
Training loss: 2.040797710418701
Validation loss: 2.094068584903594

Epoch: 5| Step: 2
Training loss: 2.0162715911865234
Validation loss: 2.1025125685558526

Epoch: 5| Step: 3
Training loss: 2.193378448486328
Validation loss: 2.1191744125017555

Epoch: 5| Step: 4
Training loss: 1.9851830005645752
Validation loss: 2.083624444982057

Epoch: 5| Step: 5
Training loss: 1.9019962549209595
Validation loss: 2.077996479567661

Epoch: 5| Step: 6
Training loss: 1.576106309890747
Validation loss: 2.085340872887642

Epoch: 5| Step: 7
Training loss: 2.1316099166870117
Validation loss: 2.0872914252742643

Epoch: 5| Step: 8
Training loss: 1.6344406604766846
Validation loss: 2.0865104736820346

Epoch: 5| Step: 9
Training loss: 2.3705406188964844
Validation loss: 2.0640379754445886

Epoch: 5| Step: 10
Training loss: 2.1538777351379395
Validation loss: 2.0875676908800678

Epoch: 294| Step: 0
Training loss: 1.6678491830825806
Validation loss: 2.0680136039692867

Epoch: 5| Step: 1
Training loss: 2.878101348876953
Validation loss: 2.112597260423886

Epoch: 5| Step: 2
Training loss: 1.805668592453003
Validation loss: 2.078284876320952

Epoch: 5| Step: 3
Training loss: 1.9142446517944336
Validation loss: 2.07440750316907

Epoch: 5| Step: 4
Training loss: 2.4956908226013184
Validation loss: 2.1068766117095947

Epoch: 5| Step: 5
Training loss: 1.741373062133789
Validation loss: 2.0947366991350727

Epoch: 5| Step: 6
Training loss: 2.001621961593628
Validation loss: 2.0580822626749673

Epoch: 5| Step: 7
Training loss: 1.9773457050323486
Validation loss: 2.0687776509151665

Epoch: 5| Step: 8
Training loss: 1.557422399520874
Validation loss: 2.0837743923228276

Epoch: 5| Step: 9
Training loss: 1.7265510559082031
Validation loss: 2.0868640151075137

Epoch: 5| Step: 10
Training loss: 2.741856336593628
Validation loss: 2.101899205997426

Epoch: 295| Step: 0
Training loss: 1.896209955215454
Validation loss: 2.1012578715560255

Epoch: 5| Step: 1
Training loss: 2.049609422683716
Validation loss: 2.0783247819510837

Epoch: 5| Step: 2
Training loss: 1.6356394290924072
Validation loss: 2.1287992731217416

Epoch: 5| Step: 3
Training loss: 2.2207329273223877
Validation loss: 2.117082953453064

Epoch: 5| Step: 4
Training loss: 2.0168185234069824
Validation loss: 2.1179287023441766

Epoch: 5| Step: 5
Training loss: 2.316650867462158
Validation loss: 2.122036580116518

Epoch: 5| Step: 6
Training loss: 2.4977688789367676
Validation loss: 2.135755549194992

Epoch: 5| Step: 7
Training loss: 2.0240519046783447
Validation loss: 2.1355088116020284

Epoch: 5| Step: 8
Training loss: 1.7274404764175415
Validation loss: 2.1245162230665966

Epoch: 5| Step: 9
Training loss: 2.2089180946350098
Validation loss: 2.109532638262677

Epoch: 5| Step: 10
Training loss: 1.8491733074188232
Validation loss: 2.1028185262474963

Epoch: 296| Step: 0
Training loss: 2.5779824256896973
Validation loss: 2.117339457235029

Epoch: 5| Step: 1
Training loss: 1.9995113611221313
Validation loss: 2.092233011799474

Epoch: 5| Step: 2
Training loss: 2.1931698322296143
Validation loss: 2.092173643009637

Epoch: 5| Step: 3
Training loss: 2.3273773193359375
Validation loss: 2.09740476710822

Epoch: 5| Step: 4
Training loss: 1.425694465637207
Validation loss: 2.073509757236768

Epoch: 5| Step: 5
Training loss: 2.0713441371917725
Validation loss: 2.093253361281528

Epoch: 5| Step: 6
Training loss: 2.3599157333374023
Validation loss: 2.0957738404632895

Epoch: 5| Step: 7
Training loss: 2.1261801719665527
Validation loss: 2.0695925861276607

Epoch: 5| Step: 8
Training loss: 1.7811044454574585
Validation loss: 2.077152416270266

Epoch: 5| Step: 9
Training loss: 1.6550829410552979
Validation loss: 2.096920297991845

Epoch: 5| Step: 10
Training loss: 1.8647551536560059
Validation loss: 2.08268399905133

Epoch: 297| Step: 0
Training loss: 2.0411794185638428
Validation loss: 2.0829351730244134

Epoch: 5| Step: 1
Training loss: 1.9091848134994507
Validation loss: 2.08052420872514

Epoch: 5| Step: 2
Training loss: 1.4381277561187744
Validation loss: 2.074227662496669

Epoch: 5| Step: 3
Training loss: 2.3886985778808594
Validation loss: 2.1034995561004965

Epoch: 5| Step: 4
Training loss: 1.872293472290039
Validation loss: 2.083037869904631

Epoch: 5| Step: 5
Training loss: 1.8535321950912476
Validation loss: 2.0840327085987216

Epoch: 5| Step: 6
Training loss: 2.393465518951416
Validation loss: 2.059122388080884

Epoch: 5| Step: 7
Training loss: 1.9241806268692017
Validation loss: 2.085435116162864

Epoch: 5| Step: 8
Training loss: 1.8296695947647095
Validation loss: 2.066267869805777

Epoch: 5| Step: 9
Training loss: 2.0910449028015137
Validation loss: 2.073311746761363

Epoch: 5| Step: 10
Training loss: 2.8808422088623047
Validation loss: 2.083103517050384

Epoch: 298| Step: 0
Training loss: 1.774924874305725
Validation loss: 2.088766421041181

Epoch: 5| Step: 1
Training loss: 1.6856696605682373
Validation loss: 2.076981662422098

Epoch: 5| Step: 2
Training loss: 1.6733801364898682
Validation loss: 2.0644884442770355

Epoch: 5| Step: 3
Training loss: 2.0077919960021973
Validation loss: 2.0914140465439006

Epoch: 5| Step: 4
Training loss: 1.925532579421997
Validation loss: 2.104701611303514

Epoch: 5| Step: 5
Training loss: 2.480841875076294
Validation loss: 2.103494623655914

Epoch: 5| Step: 6
Training loss: 1.4264576435089111
Validation loss: 2.091286087548861

Epoch: 5| Step: 7
Training loss: 2.013185739517212
Validation loss: 2.105020910181025

Epoch: 5| Step: 8
Training loss: 2.1469292640686035
Validation loss: 2.134605412842125

Epoch: 5| Step: 9
Training loss: 2.907958507537842
Validation loss: 2.1402883119480585

Epoch: 5| Step: 10
Training loss: 2.6007096767425537
Validation loss: 2.115636674306726

Epoch: 299| Step: 0
Training loss: 2.8179545402526855
Validation loss: 2.109460933234102

Epoch: 5| Step: 1
Training loss: 1.4450533390045166
Validation loss: 2.100431743488517

Epoch: 5| Step: 2
Training loss: 2.170999526977539
Validation loss: 2.118172889114708

Epoch: 5| Step: 3
Training loss: 1.717889428138733
Validation loss: 2.1229713296377533

Epoch: 5| Step: 4
Training loss: 2.1783485412597656
Validation loss: 2.11664520284181

Epoch: 5| Step: 5
Training loss: 2.289367198944092
Validation loss: 2.123408456002512

Epoch: 5| Step: 6
Training loss: 1.7685058116912842
Validation loss: 2.0998780112112723

Epoch: 5| Step: 7
Training loss: 1.5510555505752563
Validation loss: 2.117060897170856

Epoch: 5| Step: 8
Training loss: 1.8032928705215454
Validation loss: 2.134611693761682

Epoch: 5| Step: 9
Training loss: 2.6973578929901123
Validation loss: 2.1057108474034134

Epoch: 5| Step: 10
Training loss: 1.9419736862182617
Validation loss: 2.1155914798859627

Epoch: 300| Step: 0
Training loss: 1.7120224237442017
Validation loss: 2.1005044880733696

Epoch: 5| Step: 1
Training loss: 2.515974760055542
Validation loss: 2.1173211810409382

Epoch: 5| Step: 2
Training loss: 2.3890373706817627
Validation loss: 2.0729463202978975

Epoch: 5| Step: 3
Training loss: 1.303891658782959
Validation loss: 2.108893435488465

Epoch: 5| Step: 4
Training loss: 2.7008891105651855
Validation loss: 2.0697279027713242

Epoch: 5| Step: 5
Training loss: 1.6873095035552979
Validation loss: 2.065380338699587

Epoch: 5| Step: 6
Training loss: 1.9034302234649658
Validation loss: 2.0880359988058768

Epoch: 5| Step: 7
Training loss: 1.854400396347046
Validation loss: 2.0731871743356027

Epoch: 5| Step: 8
Training loss: 1.8824670314788818
Validation loss: 2.081952823105679

Epoch: 5| Step: 9
Training loss: 2.31461501121521
Validation loss: 2.0628037221970095

Epoch: 5| Step: 10
Training loss: 2.149052143096924
Validation loss: 2.0998058883092736

Testing loss: 2.014874259630839
