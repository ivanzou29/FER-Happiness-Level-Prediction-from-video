Epoch: 1| Step: 0
Training loss: 9.331979751586914
Validation loss: 8.597856911279822

Epoch: 5| Step: 1
Training loss: 8.232856750488281
Validation loss: 8.592285104977186

Epoch: 5| Step: 2
Training loss: 7.891971588134766
Validation loss: 8.592852674504762

Epoch: 5| Step: 3
Training loss: 8.189122200012207
Validation loss: 8.587314216039514

Epoch: 5| Step: 4
Training loss: 8.98710823059082
Validation loss: 8.58129757706837

Epoch: 5| Step: 5
Training loss: 9.05297565460205
Validation loss: 8.57741610209147

Epoch: 5| Step: 6
Training loss: 7.953057765960693
Validation loss: 8.576792424724948

Epoch: 5| Step: 7
Training loss: 8.196969985961914
Validation loss: 8.572716072041501

Epoch: 5| Step: 8
Training loss: 7.609238624572754
Validation loss: 8.567926499151415

Epoch: 5| Step: 9
Training loss: 8.093428611755371
Validation loss: 8.56562339618642

Epoch: 5| Step: 10
Training loss: 8.572389602661133
Validation loss: 8.562861134929042

Epoch: 2| Step: 0
Training loss: 8.570829391479492
Validation loss: 8.557022074217437

Epoch: 5| Step: 1
Training loss: 7.728553771972656
Validation loss: 8.554514023565478

Epoch: 5| Step: 2
Training loss: 7.130186557769775
Validation loss: 8.552078729034752

Epoch: 5| Step: 3
Training loss: 9.650007247924805
Validation loss: 8.546692796932753

Epoch: 5| Step: 4
Training loss: 7.946867942810059
Validation loss: 8.542761382236275

Epoch: 5| Step: 5
Training loss: 8.781694412231445
Validation loss: 8.540301702355826

Epoch: 5| Step: 6
Training loss: 8.173296928405762
Validation loss: 8.538684086133076

Epoch: 5| Step: 7
Training loss: 8.104333877563477
Validation loss: 8.532551314241143

Epoch: 5| Step: 8
Training loss: 9.163783073425293
Validation loss: 8.528304202582246

Epoch: 5| Step: 9
Training loss: 8.364351272583008
Validation loss: 8.528129198217904

Epoch: 5| Step: 10
Training loss: 7.994526386260986
Validation loss: 8.520973236330095

Epoch: 3| Step: 0
Training loss: 7.6227312088012695
Validation loss: 8.520240845218781

Epoch: 5| Step: 1
Training loss: 8.416582107543945
Validation loss: 8.515684312389743

Epoch: 5| Step: 2
Training loss: 8.108331680297852
Validation loss: 8.513621576370731

Epoch: 5| Step: 3
Training loss: 8.443816184997559
Validation loss: 8.509246108352498

Epoch: 5| Step: 4
Training loss: 8.87749195098877
Validation loss: 8.504504901106639

Epoch: 5| Step: 5
Training loss: 9.465383529663086
Validation loss: 8.502542977691979

Epoch: 5| Step: 6
Training loss: 8.220392227172852
Validation loss: 8.497875562278173

Epoch: 5| Step: 7
Training loss: 7.160749912261963
Validation loss: 8.493941481395435

Epoch: 5| Step: 8
Training loss: 8.131902694702148
Validation loss: 8.490725619818575

Epoch: 5| Step: 9
Training loss: 8.411388397216797
Validation loss: 8.485330279155445

Epoch: 5| Step: 10
Training loss: 8.373717308044434
Validation loss: 8.484474930711972

Epoch: 4| Step: 0
Training loss: 7.535701751708984
Validation loss: 8.479795753314932

Epoch: 5| Step: 1
Training loss: 8.947771072387695
Validation loss: 8.475857396279611

Epoch: 5| Step: 2
Training loss: 8.96886920928955
Validation loss: 8.472492176999328

Epoch: 5| Step: 3
Training loss: 7.815920352935791
Validation loss: 8.467941950726253

Epoch: 5| Step: 4
Training loss: 8.950029373168945
Validation loss: 8.463167067497007

Epoch: 5| Step: 5
Training loss: 9.198488235473633
Validation loss: 8.457928401167674

Epoch: 5| Step: 6
Training loss: 7.127296447753906
Validation loss: 8.452509736502043

Epoch: 5| Step: 7
Training loss: 8.309739112854004
Validation loss: 8.452429197167838

Epoch: 5| Step: 8
Training loss: 8.211507797241211
Validation loss: 8.448934042325584

Epoch: 5| Step: 9
Training loss: 8.112295150756836
Validation loss: 8.443053989000218

Epoch: 5| Step: 10
Training loss: 7.471167087554932
Validation loss: 8.437706793508221

Epoch: 5| Step: 0
Training loss: 8.599096298217773
Validation loss: 8.433691522126557

Epoch: 5| Step: 1
Training loss: 8.73773193359375
Validation loss: 8.42758168456375

Epoch: 5| Step: 2
Training loss: 8.614015579223633
Validation loss: 8.42505871352329

Epoch: 5| Step: 3
Training loss: 7.778801918029785
Validation loss: 8.42284059011808

Epoch: 5| Step: 4
Training loss: 8.630533218383789
Validation loss: 8.41582876636136

Epoch: 5| Step: 5
Training loss: 8.58397102355957
Validation loss: 8.412802419354838

Epoch: 5| Step: 6
Training loss: 7.627285003662109
Validation loss: 8.407544228338427

Epoch: 5| Step: 7
Training loss: 8.537687301635742
Validation loss: 8.406785934202132

Epoch: 5| Step: 8
Training loss: 8.110830307006836
Validation loss: 8.399625644888928

Epoch: 5| Step: 9
Training loss: 7.795129299163818
Validation loss: 8.397396538847236

Epoch: 5| Step: 10
Training loss: 7.020262241363525
Validation loss: 8.3919066152265

Epoch: 6| Step: 0
Training loss: 7.838352203369141
Validation loss: 8.386415194439632

Epoch: 5| Step: 1
Training loss: 8.502450942993164
Validation loss: 8.384060962225801

Epoch: 5| Step: 2
Training loss: 8.302377700805664
Validation loss: 8.37901415876163

Epoch: 5| Step: 3
Training loss: 8.919572830200195
Validation loss: 8.378322570554671

Epoch: 5| Step: 4
Training loss: 7.059536933898926
Validation loss: 8.370258679953954

Epoch: 5| Step: 5
Training loss: 8.215433120727539
Validation loss: 8.363628520760486

Epoch: 5| Step: 6
Training loss: 8.467272758483887
Validation loss: 8.360620970367103

Epoch: 5| Step: 7
Training loss: 8.37353801727295
Validation loss: 8.356540526113202

Epoch: 5| Step: 8
Training loss: 8.242892265319824
Validation loss: 8.35329181917252

Epoch: 5| Step: 9
Training loss: 7.1334662437438965
Validation loss: 8.345352265142626

Epoch: 5| Step: 10
Training loss: 8.683738708496094
Validation loss: 8.341930615004673

Epoch: 7| Step: 0
Training loss: 8.703360557556152
Validation loss: 8.336022766687536

Epoch: 5| Step: 1
Training loss: 7.738796234130859
Validation loss: 8.333074436392835

Epoch: 5| Step: 2
Training loss: 8.269842147827148
Validation loss: 8.329612854988344

Epoch: 5| Step: 3
Training loss: 8.716554641723633
Validation loss: 8.320111008100612

Epoch: 5| Step: 4
Training loss: 8.60590934753418
Validation loss: 8.31685108266851

Epoch: 5| Step: 5
Training loss: 8.270848274230957
Validation loss: 8.307571564951251

Epoch: 5| Step: 6
Training loss: 7.864805698394775
Validation loss: 8.308888066199518

Epoch: 5| Step: 7
Training loss: 7.378406524658203
Validation loss: 8.30124843761485

Epoch: 5| Step: 8
Training loss: 6.974461555480957
Validation loss: 8.295525376514721

Epoch: 5| Step: 9
Training loss: 7.7797722816467285
Validation loss: 8.289175946225402

Epoch: 5| Step: 10
Training loss: 8.865995407104492
Validation loss: 8.287877021297332

Epoch: 8| Step: 0
Training loss: 8.296079635620117
Validation loss: 8.279862362851379

Epoch: 5| Step: 1
Training loss: 8.784313201904297
Validation loss: 8.274554703825263

Epoch: 5| Step: 2
Training loss: 7.045910835266113
Validation loss: 8.267376397245673

Epoch: 5| Step: 3
Training loss: 8.426414489746094
Validation loss: 8.265479549284905

Epoch: 5| Step: 4
Training loss: 7.893023490905762
Validation loss: 8.253570484858686

Epoch: 5| Step: 5
Training loss: 7.185727119445801
Validation loss: 8.249554275184549

Epoch: 5| Step: 6
Training loss: 8.696589469909668
Validation loss: 8.244009171762775

Epoch: 5| Step: 7
Training loss: 8.321069717407227
Validation loss: 8.239191793626354

Epoch: 5| Step: 8
Training loss: 8.194640159606934
Validation loss: 8.23198006230016

Epoch: 5| Step: 9
Training loss: 8.226445198059082
Validation loss: 8.225396033256285

Epoch: 5| Step: 10
Training loss: 7.1936798095703125
Validation loss: 8.217429048271589

Epoch: 9| Step: 0
Training loss: 7.860579013824463
Validation loss: 8.214735523346931

Epoch: 5| Step: 1
Training loss: 7.95782470703125
Validation loss: 8.212199262393419

Epoch: 5| Step: 2
Training loss: 8.666985511779785
Validation loss: 8.203432206184633

Epoch: 5| Step: 3
Training loss: 7.9524335861206055
Validation loss: 8.194940669562227

Epoch: 5| Step: 4
Training loss: 7.778943061828613
Validation loss: 8.18925549907069

Epoch: 5| Step: 5
Training loss: 7.125436305999756
Validation loss: 8.18928418108212

Epoch: 5| Step: 6
Training loss: 8.356301307678223
Validation loss: 8.178036371866861

Epoch: 5| Step: 7
Training loss: 7.881119728088379
Validation loss: 8.165499435958042

Epoch: 5| Step: 8
Training loss: 8.561752319335938
Validation loss: 8.163430121637159

Epoch: 5| Step: 9
Training loss: 7.468727111816406
Validation loss: 8.155479185042843

Epoch: 5| Step: 10
Training loss: 7.954984664916992
Validation loss: 8.155049416326708

Epoch: 10| Step: 0
Training loss: 7.535593509674072
Validation loss: 8.139891598814277

Epoch: 5| Step: 1
Training loss: 8.536935806274414
Validation loss: 8.139005025227865

Epoch: 5| Step: 2
Training loss: 7.211642265319824
Validation loss: 8.126184350700788

Epoch: 5| Step: 3
Training loss: 7.5448102951049805
Validation loss: 8.11505256160613

Epoch: 5| Step: 4
Training loss: 8.491920471191406
Validation loss: 8.107610394877772

Epoch: 5| Step: 5
Training loss: 7.077967643737793
Validation loss: 8.102689179041052

Epoch: 5| Step: 6
Training loss: 6.990412712097168
Validation loss: 8.095023324412685

Epoch: 5| Step: 7
Training loss: 8.164888381958008
Validation loss: 8.085370458582396

Epoch: 5| Step: 8
Training loss: 8.735923767089844
Validation loss: 8.0750186263874

Epoch: 5| Step: 9
Training loss: 7.466504096984863
Validation loss: 8.062754502860448

Epoch: 5| Step: 10
Training loss: 9.105443000793457
Validation loss: 8.062476055596465

Epoch: 11| Step: 0
Training loss: 8.592680931091309
Validation loss: 8.04994148849159

Epoch: 5| Step: 1
Training loss: 6.817244529724121
Validation loss: 8.039413318839124

Epoch: 5| Step: 2
Training loss: 7.221163272857666
Validation loss: 8.033363665303876

Epoch: 5| Step: 3
Training loss: 8.199102401733398
Validation loss: 8.025059966630833

Epoch: 5| Step: 4
Training loss: 7.813549041748047
Validation loss: 8.019310735887096

Epoch: 5| Step: 5
Training loss: 8.059123992919922
Validation loss: 8.00867780049642

Epoch: 5| Step: 6
Training loss: 7.4414238929748535
Validation loss: 7.999779855051348

Epoch: 5| Step: 7
Training loss: 8.25288200378418
Validation loss: 7.997475952230474

Epoch: 5| Step: 8
Training loss: 8.465144157409668
Validation loss: 7.9844893793905936

Epoch: 5| Step: 9
Training loss: 6.8797287940979
Validation loss: 7.975726168642762

Epoch: 5| Step: 10
Training loss: 7.885730743408203
Validation loss: 7.969247551374538

Epoch: 12| Step: 0
Training loss: 7.511216640472412
Validation loss: 7.953604005998181

Epoch: 5| Step: 1
Training loss: 7.4657087326049805
Validation loss: 7.945471050918743

Epoch: 5| Step: 2
Training loss: 8.03198528289795
Validation loss: 7.944769264549337

Epoch: 5| Step: 3
Training loss: 7.559906959533691
Validation loss: 7.932959238688151

Epoch: 5| Step: 4
Training loss: 8.6155366897583
Validation loss: 7.919614335542084

Epoch: 5| Step: 5
Training loss: 5.9907426834106445
Validation loss: 7.9083001126525225

Epoch: 5| Step: 6
Training loss: 7.87717342376709
Validation loss: 7.901350693036151

Epoch: 5| Step: 7
Training loss: 8.641228675842285
Validation loss: 7.889926941164078

Epoch: 5| Step: 8
Training loss: 8.087909698486328
Validation loss: 7.881731622962541

Epoch: 5| Step: 9
Training loss: 7.113969326019287
Validation loss: 7.874465521945749

Epoch: 5| Step: 10
Training loss: 7.581140041351318
Validation loss: 7.8645520620448615

Epoch: 13| Step: 0
Training loss: 7.035953521728516
Validation loss: 7.855787123403242

Epoch: 5| Step: 1
Training loss: 7.6946845054626465
Validation loss: 7.843898096392231

Epoch: 5| Step: 2
Training loss: 7.445199489593506
Validation loss: 7.833614687765798

Epoch: 5| Step: 3
Training loss: 7.217033386230469
Validation loss: 7.8342581461834655

Epoch: 5| Step: 4
Training loss: 7.615954399108887
Validation loss: 7.819221137672343

Epoch: 5| Step: 5
Training loss: 6.824501037597656
Validation loss: 7.805257951059649

Epoch: 5| Step: 6
Training loss: 8.954262733459473
Validation loss: 7.802534867358464

Epoch: 5| Step: 7
Training loss: 8.156087875366211
Validation loss: 7.784242394149945

Epoch: 5| Step: 8
Training loss: 7.1042585372924805
Validation loss: 7.774961133157054

Epoch: 5| Step: 9
Training loss: 7.83361291885376
Validation loss: 7.764855010535127

Epoch: 5| Step: 10
Training loss: 7.3969502449035645
Validation loss: 7.760796854572911

Epoch: 14| Step: 0
Training loss: 8.143143653869629
Validation loss: 7.747201688828007

Epoch: 5| Step: 1
Training loss: 7.861371040344238
Validation loss: 7.731675588956443

Epoch: 5| Step: 2
Training loss: 7.862477779388428
Validation loss: 7.726349061535251

Epoch: 5| Step: 3
Training loss: 6.933183193206787
Validation loss: 7.714495017964353

Epoch: 5| Step: 4
Training loss: 6.928743839263916
Validation loss: 7.702086776815435

Epoch: 5| Step: 5
Training loss: 6.653721809387207
Validation loss: 7.695498825401388

Epoch: 5| Step: 6
Training loss: 7.104672431945801
Validation loss: 7.67829183865619

Epoch: 5| Step: 7
Training loss: 7.21536111831665
Validation loss: 7.676336852453089

Epoch: 5| Step: 8
Training loss: 7.867153167724609
Validation loss: 7.670178249318113

Epoch: 5| Step: 9
Training loss: 7.489415645599365
Validation loss: 7.657461822673839

Epoch: 5| Step: 10
Training loss: 8.115415573120117
Validation loss: 7.639612433730915

Epoch: 15| Step: 0
Training loss: 6.6958794593811035
Validation loss: 7.638602969466999

Epoch: 5| Step: 1
Training loss: 6.911044120788574
Validation loss: 7.613149227634553

Epoch: 5| Step: 2
Training loss: 6.981450080871582
Validation loss: 7.599226474761963

Epoch: 5| Step: 3
Training loss: 7.85604190826416
Validation loss: 7.60669256025745

Epoch: 5| Step: 4
Training loss: 6.899587154388428
Validation loss: 7.581860116733018

Epoch: 5| Step: 5
Training loss: 7.457498073577881
Validation loss: 7.571803544157294

Epoch: 5| Step: 6
Training loss: 7.186725616455078
Validation loss: 7.5625659676008326

Epoch: 5| Step: 7
Training loss: 6.928028106689453
Validation loss: 7.5533902414383425

Epoch: 5| Step: 8
Training loss: 8.642468452453613
Validation loss: 7.539573243869248

Epoch: 5| Step: 9
Training loss: 7.756335258483887
Validation loss: 7.529783105337492

Epoch: 5| Step: 10
Training loss: 7.321934700012207
Validation loss: 7.513621719934607

Epoch: 16| Step: 0
Training loss: 7.8523969650268555
Validation loss: 7.495379688919232

Epoch: 5| Step: 1
Training loss: 7.035195827484131
Validation loss: 7.488974366136777

Epoch: 5| Step: 2
Training loss: 7.316735744476318
Validation loss: 7.488880808635424

Epoch: 5| Step: 3
Training loss: 7.820641994476318
Validation loss: 7.468898742429672

Epoch: 5| Step: 4
Training loss: 7.639260292053223
Validation loss: 7.457620384872601

Epoch: 5| Step: 5
Training loss: 7.0022172927856445
Validation loss: 7.454736248139413

Epoch: 5| Step: 6
Training loss: 7.9401655197143555
Validation loss: 7.433623816377374

Epoch: 5| Step: 7
Training loss: 6.741976737976074
Validation loss: 7.429999633501935

Epoch: 5| Step: 8
Training loss: 7.153630256652832
Validation loss: 7.408018999202277

Epoch: 5| Step: 9
Training loss: 6.2755560874938965
Validation loss: 7.40264412664598

Epoch: 5| Step: 10
Training loss: 6.423084735870361
Validation loss: 7.384792635517735

Epoch: 17| Step: 0
Training loss: 7.084265232086182
Validation loss: 7.377432474526026

Epoch: 5| Step: 1
Training loss: 8.183978080749512
Validation loss: 7.358737196973575

Epoch: 5| Step: 2
Training loss: 6.666297912597656
Validation loss: 7.351181758347378

Epoch: 5| Step: 3
Training loss: 7.919116973876953
Validation loss: 7.3400334952979955

Epoch: 5| Step: 4
Training loss: 5.9666948318481445
Validation loss: 7.324027871572843

Epoch: 5| Step: 5
Training loss: 7.722563743591309
Validation loss: 7.317026656161072

Epoch: 5| Step: 6
Training loss: 6.413165092468262
Validation loss: 7.304015456989247

Epoch: 5| Step: 7
Training loss: 6.08223819732666
Validation loss: 7.30062686756093

Epoch: 5| Step: 8
Training loss: 7.634915828704834
Validation loss: 7.279156228547455

Epoch: 5| Step: 9
Training loss: 6.899822235107422
Validation loss: 7.260946509658649

Epoch: 5| Step: 10
Training loss: 7.100792407989502
Validation loss: 7.236728160612045

Epoch: 18| Step: 0
Training loss: 6.364297389984131
Validation loss: 7.2285786187776955

Epoch: 5| Step: 1
Training loss: 8.03959846496582
Validation loss: 7.219551435080907

Epoch: 5| Step: 2
Training loss: 7.085108757019043
Validation loss: 7.203733705705212

Epoch: 5| Step: 3
Training loss: 6.275057315826416
Validation loss: 7.200135102836034

Epoch: 5| Step: 4
Training loss: 6.8656768798828125
Validation loss: 7.191276606693063

Epoch: 5| Step: 5
Training loss: 6.897161960601807
Validation loss: 7.186536922249743

Epoch: 5| Step: 6
Training loss: 6.184842586517334
Validation loss: 7.153224555394983

Epoch: 5| Step: 7
Training loss: 7.4183149337768555
Validation loss: 7.1506519471445396

Epoch: 5| Step: 8
Training loss: 6.585061550140381
Validation loss: 7.126182427970312

Epoch: 5| Step: 9
Training loss: 7.1941680908203125
Validation loss: 7.114903470521332

Epoch: 5| Step: 10
Training loss: 7.33363151550293
Validation loss: 7.118664100605955

Epoch: 19| Step: 0
Training loss: 7.250022888183594
Validation loss: 7.085195254254085

Epoch: 5| Step: 1
Training loss: 6.4298553466796875
Validation loss: 7.079019551636071

Epoch: 5| Step: 2
Training loss: 5.920331001281738
Validation loss: 7.070056156445575

Epoch: 5| Step: 3
Training loss: 7.611750602722168
Validation loss: 7.053102780413884

Epoch: 5| Step: 4
Training loss: 6.326043605804443
Validation loss: 7.041011092483356

Epoch: 5| Step: 5
Training loss: 6.952699184417725
Validation loss: 7.0365888585326495

Epoch: 5| Step: 6
Training loss: 6.596624851226807
Validation loss: 7.0039305225495365

Epoch: 5| Step: 7
Training loss: 6.663949489593506
Validation loss: 6.987141855301395

Epoch: 5| Step: 8
Training loss: 6.1628594398498535
Validation loss: 6.972165056454238

Epoch: 5| Step: 9
Training loss: 8.128249168395996
Validation loss: 6.965786287861485

Epoch: 5| Step: 10
Training loss: 6.435153007507324
Validation loss: 6.957878240975001

Epoch: 20| Step: 0
Training loss: 6.463435173034668
Validation loss: 6.926350403857487

Epoch: 5| Step: 1
Training loss: 5.705302715301514
Validation loss: 6.926366616320866

Epoch: 5| Step: 2
Training loss: 6.876060485839844
Validation loss: 6.913143588650611

Epoch: 5| Step: 3
Training loss: 6.734260559082031
Validation loss: 6.89176800430462

Epoch: 5| Step: 4
Training loss: 6.568961143493652
Validation loss: 6.896861450646513

Epoch: 5| Step: 5
Training loss: 6.7104973793029785
Validation loss: 6.882239885227655

Epoch: 5| Step: 6
Training loss: 7.432618141174316
Validation loss: 6.836218428868119

Epoch: 5| Step: 7
Training loss: 6.8726487159729
Validation loss: 6.834861463116061

Epoch: 5| Step: 8
Training loss: 6.942249298095703
Validation loss: 6.81143138229206

Epoch: 5| Step: 9
Training loss: 7.032877445220947
Validation loss: 6.803714111287107

Epoch: 5| Step: 10
Training loss: 4.9450273513793945
Validation loss: 6.791561967583113

Epoch: 21| Step: 0
Training loss: 7.021018028259277
Validation loss: 6.765938199976439

Epoch: 5| Step: 1
Training loss: 6.27875280380249
Validation loss: 6.755300926905806

Epoch: 5| Step: 2
Training loss: 6.0854620933532715
Validation loss: 6.739794203030166

Epoch: 5| Step: 3
Training loss: 7.523409843444824
Validation loss: 6.7130145667701635

Epoch: 5| Step: 4
Training loss: 6.977159023284912
Validation loss: 6.710047260407479

Epoch: 5| Step: 5
Training loss: 5.231759071350098
Validation loss: 6.663058962873233

Epoch: 5| Step: 6
Training loss: 5.712873935699463
Validation loss: 6.664425296168173

Epoch: 5| Step: 7
Training loss: 7.228593349456787
Validation loss: 6.657071913442304

Epoch: 5| Step: 8
Training loss: 6.855922698974609
Validation loss: 6.626926734883298

Epoch: 5| Step: 9
Training loss: 5.3249006271362305
Validation loss: 6.612668129705614

Epoch: 5| Step: 10
Training loss: 6.405468463897705
Validation loss: 6.592841661104592

Epoch: 22| Step: 0
Training loss: 6.602019309997559
Validation loss: 6.577676629507414

Epoch: 5| Step: 1
Training loss: 6.388082504272461
Validation loss: 6.559261286130515

Epoch: 5| Step: 2
Training loss: 7.0606207847595215
Validation loss: 6.564849622787968

Epoch: 5| Step: 3
Training loss: 5.594027042388916
Validation loss: 6.531919315297117

Epoch: 5| Step: 4
Training loss: 5.635608196258545
Validation loss: 6.509657224019368

Epoch: 5| Step: 5
Training loss: 6.323544979095459
Validation loss: 6.498524737614457

Epoch: 5| Step: 6
Training loss: 5.798076629638672
Validation loss: 6.479314537458523

Epoch: 5| Step: 7
Training loss: 6.220864295959473
Validation loss: 6.468325261146791

Epoch: 5| Step: 8
Training loss: 6.5194411277771
Validation loss: 6.435641463084887

Epoch: 5| Step: 9
Training loss: 7.019278049468994
Validation loss: 6.415065683344359

Epoch: 5| Step: 10
Training loss: 5.115866184234619
Validation loss: 6.424123425637522

Epoch: 23| Step: 0
Training loss: 7.113503932952881
Validation loss: 6.385292417259627

Epoch: 5| Step: 1
Training loss: 5.002025127410889
Validation loss: 6.359383444632253

Epoch: 5| Step: 2
Training loss: 5.365450859069824
Validation loss: 6.360500715112173

Epoch: 5| Step: 3
Training loss: 5.526922225952148
Validation loss: 6.324546639637281

Epoch: 5| Step: 4
Training loss: 6.626319885253906
Validation loss: 6.313447295978505

Epoch: 5| Step: 5
Training loss: 6.215157985687256
Validation loss: 6.2681442076160065

Epoch: 5| Step: 6
Training loss: 5.967843055725098
Validation loss: 6.258478826092135

Epoch: 5| Step: 7
Training loss: 5.731967926025391
Validation loss: 6.271576717335691

Epoch: 5| Step: 8
Training loss: 6.521553039550781
Validation loss: 6.217868702386015

Epoch: 5| Step: 9
Training loss: 5.553031921386719
Validation loss: 6.1730152304454515

Epoch: 5| Step: 10
Training loss: 6.34221887588501
Validation loss: 6.181259401382938

Epoch: 24| Step: 0
Training loss: 5.79189395904541
Validation loss: 6.15591263001965

Epoch: 5| Step: 1
Training loss: 5.914139747619629
Validation loss: 6.120606150678409

Epoch: 5| Step: 2
Training loss: 4.3466362953186035
Validation loss: 6.080841695108721

Epoch: 5| Step: 3
Training loss: 5.0466156005859375
Validation loss: 6.10190805824854

Epoch: 5| Step: 4
Training loss: 6.039499282836914
Validation loss: 6.064178307851155

Epoch: 5| Step: 5
Training loss: 6.825935363769531
Validation loss: 6.019055351134269

Epoch: 5| Step: 6
Training loss: 5.451488971710205
Validation loss: 6.0262361803362445

Epoch: 5| Step: 7
Training loss: 5.693185806274414
Validation loss: 5.9830110816545385

Epoch: 5| Step: 8
Training loss: 6.027649879455566
Validation loss: 5.957063649290351

Epoch: 5| Step: 9
Training loss: 5.900699615478516
Validation loss: 5.953426960975893

Epoch: 5| Step: 10
Training loss: 6.308485507965088
Validation loss: 5.897880877217939

Epoch: 25| Step: 0
Training loss: 5.143282890319824
Validation loss: 5.890521659645983

Epoch: 5| Step: 1
Training loss: 5.382046699523926
Validation loss: 5.883184894438712

Epoch: 5| Step: 2
Training loss: 5.426817417144775
Validation loss: 5.8411747409451396

Epoch: 5| Step: 3
Training loss: 4.756938457489014
Validation loss: 5.820150139511273

Epoch: 5| Step: 4
Training loss: 5.20141077041626
Validation loss: 5.7985051524254585

Epoch: 5| Step: 5
Training loss: 6.947390556335449
Validation loss: 5.751631736755371

Epoch: 5| Step: 6
Training loss: 4.507762908935547
Validation loss: 5.749869479927965

Epoch: 5| Step: 7
Training loss: 4.729121208190918
Validation loss: 5.6931823197231495

Epoch: 5| Step: 8
Training loss: 5.927153587341309
Validation loss: 5.691131520014937

Epoch: 5| Step: 9
Training loss: 5.619973659515381
Validation loss: 5.632526510505266

Epoch: 5| Step: 10
Training loss: 6.645732402801514
Validation loss: 5.616788828244773

Epoch: 26| Step: 0
Training loss: 5.095187187194824
Validation loss: 5.603552879825715

Epoch: 5| Step: 1
Training loss: 4.487674236297607
Validation loss: 5.559649482850106

Epoch: 5| Step: 2
Training loss: 5.270529747009277
Validation loss: 5.501707635900026

Epoch: 5| Step: 3
Training loss: 4.864496231079102
Validation loss: 5.499254626612509

Epoch: 5| Step: 4
Training loss: 6.162255764007568
Validation loss: 5.420800855082851

Epoch: 5| Step: 5
Training loss: 5.099576473236084
Validation loss: 5.374218222915485

Epoch: 5| Step: 6
Training loss: 5.236910820007324
Validation loss: 5.373356937080302

Epoch: 5| Step: 7
Training loss: 6.207408905029297
Validation loss: 5.3492062271282235

Epoch: 5| Step: 8
Training loss: 4.559076309204102
Validation loss: 5.334085654186946

Epoch: 5| Step: 9
Training loss: 4.642851829528809
Validation loss: 5.230598977817002

Epoch: 5| Step: 10
Training loss: 4.733872413635254
Validation loss: 5.247970637454782

Epoch: 27| Step: 0
Training loss: 3.9744505882263184
Validation loss: 5.176216704871065

Epoch: 5| Step: 1
Training loss: 4.535025596618652
Validation loss: 5.180029248678556

Epoch: 5| Step: 2
Training loss: 5.29776668548584
Validation loss: 5.137216075774162

Epoch: 5| Step: 3
Training loss: 4.244652271270752
Validation loss: 5.0759574315881215

Epoch: 5| Step: 4
Training loss: 5.442958831787109
Validation loss: 5.05358354506954

Epoch: 5| Step: 5
Training loss: 4.876787185668945
Validation loss: 5.006429164640365

Epoch: 5| Step: 6
Training loss: 5.175574779510498
Validation loss: 4.980810175659836

Epoch: 5| Step: 7
Training loss: 3.315939426422119
Validation loss: 4.939055350518996

Epoch: 5| Step: 8
Training loss: 5.631680965423584
Validation loss: 4.907934460588681

Epoch: 5| Step: 9
Training loss: 4.461546897888184
Validation loss: 4.825022384684573

Epoch: 5| Step: 10
Training loss: 5.124640941619873
Validation loss: 4.840659777323405

Epoch: 28| Step: 0
Training loss: 2.606717824935913
Validation loss: 4.786750290983466

Epoch: 5| Step: 1
Training loss: 4.146206855773926
Validation loss: 4.7664835940125165

Epoch: 5| Step: 2
Training loss: 4.98602294921875
Validation loss: 4.6743803383201685

Epoch: 5| Step: 3
Training loss: 4.316035270690918
Validation loss: 4.692523135933825

Epoch: 5| Step: 4
Training loss: 5.5487799644470215
Validation loss: 4.606135983620921

Epoch: 5| Step: 5
Training loss: 4.564598083496094
Validation loss: 4.567493918121502

Epoch: 5| Step: 6
Training loss: 4.210844993591309
Validation loss: 4.531665555892452

Epoch: 5| Step: 7
Training loss: 4.37200927734375
Validation loss: 4.492759335425593

Epoch: 5| Step: 8
Training loss: 4.24163293838501
Validation loss: 4.451768577739757

Epoch: 5| Step: 9
Training loss: 4.381220817565918
Validation loss: 4.4050626036941365

Epoch: 5| Step: 10
Training loss: 3.9681997299194336
Validation loss: 4.362090997798468

Epoch: 29| Step: 0
Training loss: 4.45953893661499
Validation loss: 4.3158348503933155

Epoch: 5| Step: 1
Training loss: 3.6209819316864014
Validation loss: 4.276704239588912

Epoch: 5| Step: 2
Training loss: 3.578779935836792
Validation loss: 4.248926424211072

Epoch: 5| Step: 3
Training loss: 3.6604793071746826
Validation loss: 4.173020921727662

Epoch: 5| Step: 4
Training loss: 3.265826463699341
Validation loss: 4.136373125096803

Epoch: 5| Step: 5
Training loss: 4.230242729187012
Validation loss: 4.106415933178317

Epoch: 5| Step: 6
Training loss: 4.498783111572266
Validation loss: 4.085023454440537

Epoch: 5| Step: 7
Training loss: 3.4357235431671143
Validation loss: 4.005585378216159

Epoch: 5| Step: 8
Training loss: 3.794548749923706
Validation loss: 3.9938638697388353

Epoch: 5| Step: 9
Training loss: 4.455357551574707
Validation loss: 3.912375032260854

Epoch: 5| Step: 10
Training loss: 4.094197750091553
Validation loss: 3.894895210061022

Epoch: 30| Step: 0
Training loss: 3.7816195487976074
Validation loss: 3.860214602562689

Epoch: 5| Step: 1
Training loss: 4.106356143951416
Validation loss: 3.853114425495107

Epoch: 5| Step: 2
Training loss: 3.460064649581909
Validation loss: 3.7905341117612776

Epoch: 5| Step: 3
Training loss: 3.905702590942383
Validation loss: 3.7479493592375066

Epoch: 5| Step: 4
Training loss: 3.9834911823272705
Validation loss: 3.740602154885569

Epoch: 5| Step: 5
Training loss: 3.1149988174438477
Validation loss: 3.6421964732549523

Epoch: 5| Step: 6
Training loss: 2.801129102706909
Validation loss: 3.6744022113020702

Epoch: 5| Step: 7
Training loss: 3.5409762859344482
Validation loss: 3.6404763447341097

Epoch: 5| Step: 8
Training loss: 4.297508239746094
Validation loss: 3.5777481602084253

Epoch: 5| Step: 9
Training loss: 3.2200920581817627
Validation loss: 3.534785009199573

Epoch: 5| Step: 10
Training loss: 3.091811418533325
Validation loss: 3.5086887985147457

Epoch: 31| Step: 0
Training loss: 3.522296190261841
Validation loss: 3.426714879210277

Epoch: 5| Step: 1
Training loss: 2.8041512966156006
Validation loss: 3.455497762208344

Epoch: 5| Step: 2
Training loss: 3.3573410511016846
Validation loss: 3.354181748564525

Epoch: 5| Step: 3
Training loss: 3.4226322174072266
Validation loss: 3.4380197140478317

Epoch: 5| Step: 4
Training loss: 3.1131505966186523
Validation loss: 3.3183742210429203

Epoch: 5| Step: 5
Training loss: 3.0459399223327637
Validation loss: 3.28737372736777

Epoch: 5| Step: 6
Training loss: 3.120161294937134
Validation loss: 3.242066055215815

Epoch: 5| Step: 7
Training loss: 2.855084180831909
Validation loss: 3.1670629465451805

Epoch: 5| Step: 8
Training loss: 3.440148115158081
Validation loss: 3.0976894568371516

Epoch: 5| Step: 9
Training loss: 3.45147442817688
Validation loss: 3.185022638690087

Epoch: 5| Step: 10
Training loss: 3.3012211322784424
Validation loss: 3.157317446124169

Epoch: 32| Step: 0
Training loss: 3.9143028259277344
Validation loss: 3.0546528703422955

Epoch: 5| Step: 1
Training loss: 2.6327197551727295
Validation loss: 3.121639859291815

Epoch: 5| Step: 2
Training loss: 3.3792548179626465
Validation loss: 3.0004173119862876

Epoch: 5| Step: 3
Training loss: 3.1198232173919678
Validation loss: 3.055175837650094

Epoch: 5| Step: 4
Training loss: 3.098127841949463
Validation loss: 2.9767408499153714

Epoch: 5| Step: 5
Training loss: 3.0671334266662598
Validation loss: 2.9235884322915027

Epoch: 5| Step: 6
Training loss: 3.367000102996826
Validation loss: 2.989485889352778

Epoch: 5| Step: 7
Training loss: 2.771272659301758
Validation loss: 2.9196603221278035

Epoch: 5| Step: 8
Training loss: 2.5183558464050293
Validation loss: 2.9012129306793213

Epoch: 5| Step: 9
Training loss: 3.212397813796997
Validation loss: 2.9246396890250583

Epoch: 5| Step: 10
Training loss: 1.9814600944519043
Validation loss: 2.8193668601333455

Epoch: 33| Step: 0
Training loss: 3.4826316833496094
Validation loss: 2.795062857289468

Epoch: 5| Step: 1
Training loss: 2.8904261589050293
Validation loss: 2.8605359805527555

Epoch: 5| Step: 2
Training loss: 2.667314052581787
Validation loss: 2.8273341707004014

Epoch: 5| Step: 3
Training loss: 3.091132640838623
Validation loss: 2.74806982727461

Epoch: 5| Step: 4
Training loss: 3.461458683013916
Validation loss: 2.68107880315473

Epoch: 5| Step: 5
Training loss: 2.235957384109497
Validation loss: 2.7578004739617787

Epoch: 5| Step: 6
Training loss: 3.2304892539978027
Validation loss: 2.707759590559108

Epoch: 5| Step: 7
Training loss: 2.839797019958496
Validation loss: 2.6874056170063634

Epoch: 5| Step: 8
Training loss: 2.0969958305358887
Validation loss: 2.7009365789351927

Epoch: 5| Step: 9
Training loss: 2.715729236602783
Validation loss: 2.687458953549785

Epoch: 5| Step: 10
Training loss: 2.322335720062256
Validation loss: 2.6516428814139417

Epoch: 34| Step: 0
Training loss: 2.8510282039642334
Validation loss: 2.5682280191811184

Epoch: 5| Step: 1
Training loss: 2.3225982189178467
Validation loss: 2.6673483515298493

Epoch: 5| Step: 2
Training loss: 3.0133719444274902
Validation loss: 2.5330586228319394

Epoch: 5| Step: 3
Training loss: 3.4733920097351074
Validation loss: 2.615089621595157

Epoch: 5| Step: 4
Training loss: 2.87015962600708
Validation loss: 2.5056090560010684

Epoch: 5| Step: 5
Training loss: 2.40854811668396
Validation loss: 2.5284923712412515

Epoch: 5| Step: 6
Training loss: 2.706279754638672
Validation loss: 2.5298662826579106

Epoch: 5| Step: 7
Training loss: 2.305666446685791
Validation loss: 2.5246790814143356

Epoch: 5| Step: 8
Training loss: 2.6609394550323486
Validation loss: 2.514599379672799

Epoch: 5| Step: 9
Training loss: 2.3732352256774902
Validation loss: 2.539182655272945

Epoch: 5| Step: 10
Training loss: 2.9671521186828613
Validation loss: 2.461834092294016

Epoch: 35| Step: 0
Training loss: 2.1265976428985596
Validation loss: 2.4955503453490553

Epoch: 5| Step: 1
Training loss: 2.6394381523132324
Validation loss: 2.537170648574829

Epoch: 5| Step: 2
Training loss: 2.7389426231384277
Validation loss: 2.501711186542306

Epoch: 5| Step: 3
Training loss: 2.968230724334717
Validation loss: 2.5166583881583264

Epoch: 5| Step: 4
Training loss: 1.9069633483886719
Validation loss: 2.413339809704852

Epoch: 5| Step: 5
Training loss: 3.333519697189331
Validation loss: 2.4463279401102374

Epoch: 5| Step: 6
Training loss: 3.057474136352539
Validation loss: 2.495636160655688

Epoch: 5| Step: 7
Training loss: 2.0569052696228027
Validation loss: 2.5218044173332954

Epoch: 5| Step: 8
Training loss: 2.835575580596924
Validation loss: 2.4229880276546685

Epoch: 5| Step: 9
Training loss: 2.631037950515747
Validation loss: 2.424501129375991

Epoch: 5| Step: 10
Training loss: 2.557776927947998
Validation loss: 2.460173099271713

Epoch: 36| Step: 0
Training loss: 2.4678897857666016
Validation loss: 2.4504186363630396

Epoch: 5| Step: 1
Training loss: 2.9374849796295166
Validation loss: 2.441381864650275

Epoch: 5| Step: 2
Training loss: 2.6453440189361572
Validation loss: 2.3704743077678065

Epoch: 5| Step: 3
Training loss: 2.7421698570251465
Validation loss: 2.417826816599856

Epoch: 5| Step: 4
Training loss: 2.651902437210083
Validation loss: 2.429189761479696

Epoch: 5| Step: 5
Training loss: 2.0160136222839355
Validation loss: 2.3977857687140025

Epoch: 5| Step: 6
Training loss: 2.2514495849609375
Validation loss: 2.422972371501307

Epoch: 5| Step: 7
Training loss: 2.9896464347839355
Validation loss: 2.393120027357532

Epoch: 5| Step: 8
Training loss: 2.6154701709747314
Validation loss: 2.4251525248250654

Epoch: 5| Step: 9
Training loss: 2.813490390777588
Validation loss: 2.4380131126731954

Epoch: 5| Step: 10
Training loss: 2.606477737426758
Validation loss: 2.44819632140539

Epoch: 37| Step: 0
Training loss: 2.373105525970459
Validation loss: 2.347352627784975

Epoch: 5| Step: 1
Training loss: 2.5758464336395264
Validation loss: 2.4283894864461755

Epoch: 5| Step: 2
Training loss: 2.8807709217071533
Validation loss: 2.422115020854499

Epoch: 5| Step: 3
Training loss: 1.8952223062515259
Validation loss: 2.4404734898638982

Epoch: 5| Step: 4
Training loss: 2.413461208343506
Validation loss: 2.3878497205754763

Epoch: 5| Step: 5
Training loss: 3.028263807296753
Validation loss: 2.398042130213912

Epoch: 5| Step: 6
Training loss: 2.5153536796569824
Validation loss: 2.4641854532303347

Epoch: 5| Step: 7
Training loss: 2.4805314540863037
Validation loss: 2.365039292202201

Epoch: 5| Step: 8
Training loss: 2.774888515472412
Validation loss: 2.4118065167498846

Epoch: 5| Step: 9
Training loss: 2.8775734901428223
Validation loss: 2.3467943694001887

Epoch: 5| Step: 10
Training loss: 3.416213035583496
Validation loss: 2.4026720395652195

Epoch: 38| Step: 0
Training loss: 1.8560806512832642
Validation loss: 2.45215509271109

Epoch: 5| Step: 1
Training loss: 3.23460054397583
Validation loss: 2.3592871568536244

Epoch: 5| Step: 2
Training loss: 2.610478162765503
Validation loss: 2.380214624507453

Epoch: 5| Step: 3
Training loss: 2.7922043800354004
Validation loss: 2.4221838135873117

Epoch: 5| Step: 4
Training loss: 2.7400550842285156
Validation loss: 2.3906946746251916

Epoch: 5| Step: 5
Training loss: 2.005523204803467
Validation loss: 2.447427813724805

Epoch: 5| Step: 6
Training loss: 3.1306543350219727
Validation loss: 2.3324343491626043

Epoch: 5| Step: 7
Training loss: 2.8772025108337402
Validation loss: 2.4046912975208734

Epoch: 5| Step: 8
Training loss: 1.97927725315094
Validation loss: 2.4081622144227386

Epoch: 5| Step: 9
Training loss: 3.090864658355713
Validation loss: 2.3751396081780873

Epoch: 5| Step: 10
Training loss: 2.290912389755249
Validation loss: 2.446487395994125

Epoch: 39| Step: 0
Training loss: 2.453476667404175
Validation loss: 2.4519356181544643

Epoch: 5| Step: 1
Training loss: 2.8560080528259277
Validation loss: 2.384189539058234

Epoch: 5| Step: 2
Training loss: 2.9114372730255127
Validation loss: 2.374359558987361

Epoch: 5| Step: 3
Training loss: 3.4950637817382812
Validation loss: 2.4947250991739254

Epoch: 5| Step: 4
Training loss: 1.8049339056015015
Validation loss: 2.3652135454198366

Epoch: 5| Step: 5
Training loss: 3.0864505767822266
Validation loss: 2.3771875648088354

Epoch: 5| Step: 6
Training loss: 2.7271649837493896
Validation loss: 2.471238115782379

Epoch: 5| Step: 7
Training loss: 3.033834934234619
Validation loss: 2.4093235974670737

Epoch: 5| Step: 8
Training loss: 2.2298331260681152
Validation loss: 2.444351893599315

Epoch: 5| Step: 9
Training loss: 2.6628568172454834
Validation loss: 2.4520793614848966

Epoch: 5| Step: 10
Training loss: 1.9587328433990479
Validation loss: 2.422011620254927

Epoch: 40| Step: 0
Training loss: 2.2803187370300293
Validation loss: 2.377505429329411

Epoch: 5| Step: 1
Training loss: 2.9875619411468506
Validation loss: 2.347647049093759

Epoch: 5| Step: 2
Training loss: 2.5811333656311035
Validation loss: 2.341626626189037

Epoch: 5| Step: 3
Training loss: 2.1529908180236816
Validation loss: 2.4563956799045688

Epoch: 5| Step: 4
Training loss: 2.6537699699401855
Validation loss: 2.398853414802141

Epoch: 5| Step: 5
Training loss: 2.4608631134033203
Validation loss: 2.3649902087385937

Epoch: 5| Step: 6
Training loss: 2.7475600242614746
Validation loss: 2.3975538182002243

Epoch: 5| Step: 7
Training loss: 2.7058279514312744
Validation loss: 2.4071269958249983

Epoch: 5| Step: 8
Training loss: 2.5897154808044434
Validation loss: 2.4870809867817867

Epoch: 5| Step: 9
Training loss: 2.6795248985290527
Validation loss: 2.431412612238238

Epoch: 5| Step: 10
Training loss: 2.4899158477783203
Validation loss: 2.3473869600603656

Epoch: 41| Step: 0
Training loss: 2.6490161418914795
Validation loss: 2.343851989315402

Epoch: 5| Step: 1
Training loss: 3.0138967037200928
Validation loss: 2.314981973299416

Epoch: 5| Step: 2
Training loss: 2.775604486465454
Validation loss: 2.3905433685548845

Epoch: 5| Step: 3
Training loss: 2.7414193153381348
Validation loss: 2.3762616790750974

Epoch: 5| Step: 4
Training loss: 2.068701982498169
Validation loss: 2.456064478043587

Epoch: 5| Step: 5
Training loss: 2.133328676223755
Validation loss: 2.4269390080564763

Epoch: 5| Step: 6
Training loss: 2.290942430496216
Validation loss: 2.4303070268323346

Epoch: 5| Step: 7
Training loss: 2.9025487899780273
Validation loss: 2.3826915397438952

Epoch: 5| Step: 8
Training loss: 2.981881618499756
Validation loss: 2.338173172807181

Epoch: 5| Step: 9
Training loss: 2.574026107788086
Validation loss: 2.3666584530184345

Epoch: 5| Step: 10
Training loss: 2.66084361076355
Validation loss: 2.3261261473419848

Epoch: 42| Step: 0
Training loss: 2.8177242279052734
Validation loss: 2.35550521778804

Epoch: 5| Step: 1
Training loss: 2.6768574714660645
Validation loss: 2.37983630036795

Epoch: 5| Step: 2
Training loss: 2.650054454803467
Validation loss: 2.3687442451395015

Epoch: 5| Step: 3
Training loss: 2.820136547088623
Validation loss: 2.4217634239504413

Epoch: 5| Step: 4
Training loss: 2.8569722175598145
Validation loss: 2.4402636802324684

Epoch: 5| Step: 5
Training loss: 2.839806318283081
Validation loss: 2.3799705531007502

Epoch: 5| Step: 6
Training loss: 1.9697933197021484
Validation loss: 2.3795524553586076

Epoch: 5| Step: 7
Training loss: 2.533247470855713
Validation loss: 2.38700698268029

Epoch: 5| Step: 8
Training loss: 2.4926745891571045
Validation loss: 2.4207695197033625

Epoch: 5| Step: 9
Training loss: 2.3076138496398926
Validation loss: 2.3528445715545327

Epoch: 5| Step: 10
Training loss: 2.3942525386810303
Validation loss: 2.3359625788145166

Epoch: 43| Step: 0
Training loss: 2.8488106727600098
Validation loss: 2.527079648869012

Epoch: 5| Step: 1
Training loss: 2.023507833480835
Validation loss: 2.3766719910406295

Epoch: 5| Step: 2
Training loss: 2.842221736907959
Validation loss: 2.4200930467215915

Epoch: 5| Step: 3
Training loss: 2.4299674034118652
Validation loss: 2.4102009573290424

Epoch: 5| Step: 4
Training loss: 2.511697292327881
Validation loss: 2.3810294289742746

Epoch: 5| Step: 5
Training loss: 2.9571776390075684
Validation loss: 2.2945479141768588

Epoch: 5| Step: 6
Training loss: 2.073474168777466
Validation loss: 2.4439395525122203

Epoch: 5| Step: 7
Training loss: 2.9719161987304688
Validation loss: 2.3694588010029127

Epoch: 5| Step: 8
Training loss: 2.533095121383667
Validation loss: 2.4486856486207698

Epoch: 5| Step: 9
Training loss: 2.2837204933166504
Validation loss: 2.4605981944709696

Epoch: 5| Step: 10
Training loss: 2.6448378562927246
Validation loss: 2.404296221271638

Epoch: 44| Step: 0
Training loss: 3.062223196029663
Validation loss: 2.4615755824632544

Epoch: 5| Step: 1
Training loss: 2.3031041622161865
Validation loss: 2.3524129441989365

Epoch: 5| Step: 2
Training loss: 3.0820016860961914
Validation loss: 2.383113504737936

Epoch: 5| Step: 3
Training loss: 2.1500422954559326
Validation loss: 2.4395854165477138

Epoch: 5| Step: 4
Training loss: 2.192671298980713
Validation loss: 2.405714593907838

Epoch: 5| Step: 5
Training loss: 2.579011917114258
Validation loss: 2.427001853143015

Epoch: 5| Step: 6
Training loss: 2.559002637863159
Validation loss: 2.4148413673523934

Epoch: 5| Step: 7
Training loss: 2.923957347869873
Validation loss: 2.281356662832281

Epoch: 5| Step: 8
Training loss: 2.3205182552337646
Validation loss: 2.409408389881093

Epoch: 5| Step: 9
Training loss: 2.3401551246643066
Validation loss: 2.419091755344022

Epoch: 5| Step: 10
Training loss: 2.521545886993408
Validation loss: 2.484445657781375

Epoch: 45| Step: 0
Training loss: 2.0897128582000732
Validation loss: 2.492420493915517

Epoch: 5| Step: 1
Training loss: 2.9688215255737305
Validation loss: 2.434278634286696

Epoch: 5| Step: 2
Training loss: 2.2986414432525635
Validation loss: 2.3155963318322295

Epoch: 5| Step: 3
Training loss: 3.1320576667785645
Validation loss: 2.346843822028047

Epoch: 5| Step: 4
Training loss: 2.5577480792999268
Validation loss: 2.4426958791671263

Epoch: 5| Step: 5
Training loss: 1.8181720972061157
Validation loss: 2.4682672587774133

Epoch: 5| Step: 6
Training loss: 3.2125096321105957
Validation loss: 2.353976188167449

Epoch: 5| Step: 7
Training loss: 2.946540117263794
Validation loss: 2.4138862471426688

Epoch: 5| Step: 8
Training loss: 2.6381423473358154
Validation loss: 2.420333057321528

Epoch: 5| Step: 9
Training loss: 2.0785956382751465
Validation loss: 2.356090725109141

Epoch: 5| Step: 10
Training loss: 2.830717086791992
Validation loss: 2.3838679559769167

Epoch: 46| Step: 0
Training loss: 2.2302682399749756
Validation loss: 2.3984734448053504

Epoch: 5| Step: 1
Training loss: 2.3788974285125732
Validation loss: 2.4282874599579842

Epoch: 5| Step: 2
Training loss: 2.3518054485321045
Validation loss: 2.363387615449967

Epoch: 5| Step: 3
Training loss: 2.402345657348633
Validation loss: 2.3345885328067246

Epoch: 5| Step: 4
Training loss: 1.8288352489471436
Validation loss: 2.4198488573874197

Epoch: 5| Step: 5
Training loss: 3.1205575466156006
Validation loss: 2.4101812019143054

Epoch: 5| Step: 6
Training loss: 2.744581460952759
Validation loss: 2.3027022051554855

Epoch: 5| Step: 7
Training loss: 3.15455961227417
Validation loss: 2.432428447149133

Epoch: 5| Step: 8
Training loss: 2.9527206420898438
Validation loss: 2.3554023491439

Epoch: 5| Step: 9
Training loss: 2.625153064727783
Validation loss: 2.3492382444361204

Epoch: 5| Step: 10
Training loss: 2.8677401542663574
Validation loss: 2.4218515273063415

Epoch: 47| Step: 0
Training loss: 2.623444080352783
Validation loss: 2.320712835557999

Epoch: 5| Step: 1
Training loss: 2.8235268592834473
Validation loss: 2.33365156573634

Epoch: 5| Step: 2
Training loss: 2.5920639038085938
Validation loss: 2.3569815363935245

Epoch: 5| Step: 3
Training loss: 3.162907361984253
Validation loss: 2.433200354217201

Epoch: 5| Step: 4
Training loss: 2.33620548248291
Validation loss: 2.4048117822216404

Epoch: 5| Step: 5
Training loss: 2.7186951637268066
Validation loss: 2.386611964112969

Epoch: 5| Step: 6
Training loss: 2.3231539726257324
Validation loss: 2.3475274885854414

Epoch: 5| Step: 7
Training loss: 2.744328022003174
Validation loss: 2.406247433795724

Epoch: 5| Step: 8
Training loss: 2.4101688861846924
Validation loss: 2.453991477207471

Epoch: 5| Step: 9
Training loss: 2.1785407066345215
Validation loss: 2.293872674306234

Epoch: 5| Step: 10
Training loss: 1.9213144779205322
Validation loss: 2.414654685604957

Epoch: 48| Step: 0
Training loss: 2.2809202671051025
Validation loss: 2.3930080424072924

Epoch: 5| Step: 1
Training loss: 2.424004316329956
Validation loss: 2.4318718320579937

Epoch: 5| Step: 2
Training loss: 2.1654651165008545
Validation loss: 2.4395326875871226

Epoch: 5| Step: 3
Training loss: 3.0660126209259033
Validation loss: 2.3686321550799954

Epoch: 5| Step: 4
Training loss: 3.4096920490264893
Validation loss: 2.4555766428670576

Epoch: 5| Step: 5
Training loss: 2.0477919578552246
Validation loss: 2.4167021705258276

Epoch: 5| Step: 6
Training loss: 2.282439708709717
Validation loss: 2.336678317798081

Epoch: 5| Step: 7
Training loss: 3.53379487991333
Validation loss: 2.4504803637022614

Epoch: 5| Step: 8
Training loss: 2.860384702682495
Validation loss: 2.4143218378866873

Epoch: 5| Step: 9
Training loss: 2.4696364402770996
Validation loss: 2.418928233526086

Epoch: 5| Step: 10
Training loss: 2.1728012561798096
Validation loss: 2.39789314680202

Epoch: 49| Step: 0
Training loss: 1.9669681787490845
Validation loss: 2.4233676284872074

Epoch: 5| Step: 1
Training loss: 3.510267734527588
Validation loss: 2.3469294527525544

Epoch: 5| Step: 2
Training loss: 2.7082691192626953
Validation loss: 2.435385964250052

Epoch: 5| Step: 3
Training loss: 2.4385218620300293
Validation loss: 2.459266629270328

Epoch: 5| Step: 4
Training loss: 1.8471091985702515
Validation loss: 2.411076312424034

Epoch: 5| Step: 5
Training loss: 2.315896511077881
Validation loss: 2.3589470565959973

Epoch: 5| Step: 6
Training loss: 2.5557966232299805
Validation loss: 2.338282295452651

Epoch: 5| Step: 7
Training loss: 2.7850756645202637
Validation loss: 2.3833665578596053

Epoch: 5| Step: 8
Training loss: 2.2647080421447754
Validation loss: 2.4070244732723443

Epoch: 5| Step: 9
Training loss: 3.053373336791992
Validation loss: 2.4042667470952517

Epoch: 5| Step: 10
Training loss: 2.7352089881896973
Validation loss: 2.4210919616042927

Epoch: 50| Step: 0
Training loss: 2.5910463333129883
Validation loss: 2.4387584424787954

Epoch: 5| Step: 1
Training loss: 2.7498950958251953
Validation loss: 2.382552316111903

Epoch: 5| Step: 2
Training loss: 3.62298321723938
Validation loss: 2.393916747903311

Epoch: 5| Step: 3
Training loss: 2.8229777812957764
Validation loss: 2.3369851317456973

Epoch: 5| Step: 4
Training loss: 2.821614980697632
Validation loss: 2.463677793420771

Epoch: 5| Step: 5
Training loss: 2.088477611541748
Validation loss: 2.3744512065764396

Epoch: 5| Step: 6
Training loss: 1.9718589782714844
Validation loss: 2.361997007041849

Epoch: 5| Step: 7
Training loss: 1.744367241859436
Validation loss: 2.3659098532892044

Epoch: 5| Step: 8
Training loss: 1.8640304803848267
Validation loss: 2.310580252319254

Epoch: 5| Step: 9
Training loss: 2.578199625015259
Validation loss: 2.3571042886344333

Epoch: 5| Step: 10
Training loss: 3.6316168308258057
Validation loss: 2.3625069920734694

Epoch: 51| Step: 0
Training loss: 2.161616802215576
Validation loss: 2.4261261596474597

Epoch: 5| Step: 1
Training loss: 2.395143985748291
Validation loss: 2.3843706653964136

Epoch: 5| Step: 2
Training loss: 2.3712880611419678
Validation loss: 2.3552515993836107

Epoch: 5| Step: 3
Training loss: 2.2800815105438232
Validation loss: 2.434420072904197

Epoch: 5| Step: 4
Training loss: 2.2978320121765137
Validation loss: 2.360866633794641

Epoch: 5| Step: 5
Training loss: 2.738507032394409
Validation loss: 2.3829758731267785

Epoch: 5| Step: 6
Training loss: 2.9764411449432373
Validation loss: 2.4432854575495564

Epoch: 5| Step: 7
Training loss: 2.3016865253448486
Validation loss: 2.3884800941713396

Epoch: 5| Step: 8
Training loss: 2.727506160736084
Validation loss: 2.4268921523965816

Epoch: 5| Step: 9
Training loss: 2.2514538764953613
Validation loss: 2.3768253095688356

Epoch: 5| Step: 10
Training loss: 3.352400779724121
Validation loss: 2.404743266362016

Epoch: 52| Step: 0
Training loss: 2.5732719898223877
Validation loss: 2.3747323148994037

Epoch: 5| Step: 1
Training loss: 2.85229754447937
Validation loss: 2.415821700967768

Epoch: 5| Step: 2
Training loss: 1.9750373363494873
Validation loss: 2.3853777095835698

Epoch: 5| Step: 3
Training loss: 2.964287042617798
Validation loss: 2.3732313289437243

Epoch: 5| Step: 4
Training loss: 2.576000928878784
Validation loss: 2.3779068428982972

Epoch: 5| Step: 5
Training loss: 2.100027561187744
Validation loss: 2.4762395069163334

Epoch: 5| Step: 6
Training loss: 2.7346935272216797
Validation loss: 2.3589776485197005

Epoch: 5| Step: 7
Training loss: 2.7172353267669678
Validation loss: 2.3438592777457288

Epoch: 5| Step: 8
Training loss: 2.5244927406311035
Validation loss: 2.2571331083133654

Epoch: 5| Step: 9
Training loss: 2.337712049484253
Validation loss: 2.412372745493407

Epoch: 5| Step: 10
Training loss: 2.632896900177002
Validation loss: 2.467247860406035

Epoch: 53| Step: 0
Training loss: 2.613560914993286
Validation loss: 2.266010304932953

Epoch: 5| Step: 1
Training loss: 2.903285503387451
Validation loss: 2.3729297396957234

Epoch: 5| Step: 2
Training loss: 2.3490281105041504
Validation loss: 2.4014767946735507

Epoch: 5| Step: 3
Training loss: 1.5210258960723877
Validation loss: 2.3696763643654446

Epoch: 5| Step: 4
Training loss: 2.624220848083496
Validation loss: 2.3714564141406806

Epoch: 5| Step: 5
Training loss: 3.0016369819641113
Validation loss: 2.2836667696634927

Epoch: 5| Step: 6
Training loss: 2.3105204105377197
Validation loss: 2.4262819931071293

Epoch: 5| Step: 7
Training loss: 2.795121192932129
Validation loss: 2.3996115987018873

Epoch: 5| Step: 8
Training loss: 2.3889806270599365
Validation loss: 2.4034021028908352

Epoch: 5| Step: 9
Training loss: 3.2390170097351074
Validation loss: 2.4367123855057584

Epoch: 5| Step: 10
Training loss: 2.1470911502838135
Validation loss: 2.3647792185506513

Epoch: 54| Step: 0
Training loss: 2.4292004108428955
Validation loss: 2.396441387873824

Epoch: 5| Step: 1
Training loss: 2.5096588134765625
Validation loss: 2.4433581444524948

Epoch: 5| Step: 2
Training loss: 2.8586950302124023
Validation loss: 2.4450423499589324

Epoch: 5| Step: 3
Training loss: 2.1309523582458496
Validation loss: 2.371103730252994

Epoch: 5| Step: 4
Training loss: 2.4841806888580322
Validation loss: 2.353440059128628

Epoch: 5| Step: 5
Training loss: 1.7297340631484985
Validation loss: 2.475204672864688

Epoch: 5| Step: 6
Training loss: 2.29841947555542
Validation loss: 2.3967170202603905

Epoch: 5| Step: 7
Training loss: 2.205465316772461
Validation loss: 2.404643392050138

Epoch: 5| Step: 8
Training loss: 3.4597015380859375
Validation loss: 2.2583161400210474

Epoch: 5| Step: 9
Training loss: 2.5056936740875244
Validation loss: 2.3399794460624777

Epoch: 5| Step: 10
Training loss: 2.646871328353882
Validation loss: 2.459746232596777

Epoch: 55| Step: 0
Training loss: 2.1962695121765137
Validation loss: 2.4626947808009323

Epoch: 5| Step: 1
Training loss: 2.777229070663452
Validation loss: 2.2908986230050363

Epoch: 5| Step: 2
Training loss: 3.0943355560302734
Validation loss: 2.440103059173912

Epoch: 5| Step: 3
Training loss: 2.532742977142334
Validation loss: 2.478572371185467

Epoch: 5| Step: 4
Training loss: 2.2510294914245605
Validation loss: 2.4669983771539505

Epoch: 5| Step: 5
Training loss: 2.6770434379577637
Validation loss: 2.46397663188237

Epoch: 5| Step: 6
Training loss: 2.5731093883514404
Validation loss: 2.4953829524337605

Epoch: 5| Step: 7
Training loss: 2.2244813442230225
Validation loss: 2.328005588182839

Epoch: 5| Step: 8
Training loss: 1.9353549480438232
Validation loss: 2.325935750879267

Epoch: 5| Step: 9
Training loss: 2.532604455947876
Validation loss: 2.3492183916030394

Epoch: 5| Step: 10
Training loss: 2.779348134994507
Validation loss: 2.337648883942635

Epoch: 56| Step: 0
Training loss: 2.541945695877075
Validation loss: 2.2996125836526193

Epoch: 5| Step: 1
Training loss: 2.4353437423706055
Validation loss: 2.349724538864628

Epoch: 5| Step: 2
Training loss: 2.4413933753967285
Validation loss: 2.2759612990963842

Epoch: 5| Step: 3
Training loss: 2.1952147483825684
Validation loss: 2.3613061020451207

Epoch: 5| Step: 4
Training loss: 2.3532867431640625
Validation loss: 2.42953985480852

Epoch: 5| Step: 5
Training loss: 2.2305922508239746
Validation loss: 2.426905770455637

Epoch: 5| Step: 6
Training loss: 2.2647299766540527
Validation loss: 2.374741531187488

Epoch: 5| Step: 7
Training loss: 3.1075758934020996
Validation loss: 2.323283872296733

Epoch: 5| Step: 8
Training loss: 2.546487808227539
Validation loss: 2.522701258300453

Epoch: 5| Step: 9
Training loss: 2.6786677837371826
Validation loss: 2.403892563235375

Epoch: 5| Step: 10
Training loss: 2.2336671352386475
Validation loss: 2.4017338573291735

Epoch: 57| Step: 0
Training loss: 2.2575340270996094
Validation loss: 2.413150671989687

Epoch: 5| Step: 1
Training loss: 2.9290518760681152
Validation loss: 2.4277717580077467

Epoch: 5| Step: 2
Training loss: 2.8111164569854736
Validation loss: 2.3493388288764545

Epoch: 5| Step: 3
Training loss: 2.6380372047424316
Validation loss: 2.4104181310181976

Epoch: 5| Step: 4
Training loss: 2.9328978061676025
Validation loss: 2.4131682406189623

Epoch: 5| Step: 5
Training loss: 2.3712687492370605
Validation loss: 2.407123073454826

Epoch: 5| Step: 6
Training loss: 2.9194095134735107
Validation loss: 2.3808868290275655

Epoch: 5| Step: 7
Training loss: 2.204005241394043
Validation loss: 2.342619431916104

Epoch: 5| Step: 8
Training loss: 1.8281227350234985
Validation loss: 2.4297350145155385

Epoch: 5| Step: 9
Training loss: 2.232811450958252
Validation loss: 2.2905872086043

Epoch: 5| Step: 10
Training loss: 2.3986093997955322
Validation loss: 2.3255072024560746

Epoch: 58| Step: 0
Training loss: 2.302733898162842
Validation loss: 2.427409320749262

Epoch: 5| Step: 1
Training loss: 2.5466389656066895
Validation loss: 2.3621087792099162

Epoch: 5| Step: 2
Training loss: 2.62239146232605
Validation loss: 2.4354662433747323

Epoch: 5| Step: 3
Training loss: 2.167595386505127
Validation loss: 2.339635650316874

Epoch: 5| Step: 4
Training loss: 1.9835624694824219
Validation loss: 2.369417275151899

Epoch: 5| Step: 5
Training loss: 3.440009355545044
Validation loss: 2.3460438469404816

Epoch: 5| Step: 6
Training loss: 2.493661642074585
Validation loss: 2.403662432906448

Epoch: 5| Step: 7
Training loss: 2.6218769550323486
Validation loss: 2.340184079703464

Epoch: 5| Step: 8
Training loss: 2.6936259269714355
Validation loss: 2.3761638377302434

Epoch: 5| Step: 9
Training loss: 2.433029890060425
Validation loss: 2.3560410853355163

Epoch: 5| Step: 10
Training loss: 2.305682420730591
Validation loss: 2.3775260294637373

Epoch: 59| Step: 0
Training loss: 2.67760968208313
Validation loss: 2.362240437538393

Epoch: 5| Step: 1
Training loss: 2.846036911010742
Validation loss: 2.3672773966225247

Epoch: 5| Step: 2
Training loss: 2.4672858715057373
Validation loss: 2.337671072252335

Epoch: 5| Step: 3
Training loss: 2.522696018218994
Validation loss: 2.3447341354944373

Epoch: 5| Step: 4
Training loss: 2.3777451515197754
Validation loss: 2.318891086886006

Epoch: 5| Step: 5
Training loss: 2.3499703407287598
Validation loss: 2.399264822724045

Epoch: 5| Step: 6
Training loss: 1.9034827947616577
Validation loss: 2.377700453163475

Epoch: 5| Step: 7
Training loss: 1.6873966455459595
Validation loss: 2.4516717926148446

Epoch: 5| Step: 8
Training loss: 3.2570769786834717
Validation loss: 2.3444198062342982

Epoch: 5| Step: 9
Training loss: 2.464423656463623
Validation loss: 2.4321468722435737

Epoch: 5| Step: 10
Training loss: 1.801798701286316
Validation loss: 2.410276151472522

Epoch: 60| Step: 0
Training loss: 2.913935422897339
Validation loss: 2.4048998022592194

Epoch: 5| Step: 1
Training loss: 2.5308167934417725
Validation loss: 2.3895922399336293

Epoch: 5| Step: 2
Training loss: 2.4532883167266846
Validation loss: 2.451219686897852

Epoch: 5| Step: 3
Training loss: 1.862069845199585
Validation loss: 2.3381415746545278

Epoch: 5| Step: 4
Training loss: 2.214744806289673
Validation loss: 2.3804042646961827

Epoch: 5| Step: 5
Training loss: 2.599971294403076
Validation loss: 2.449098530636039

Epoch: 5| Step: 6
Training loss: 2.479976177215576
Validation loss: 2.4335795961400515

Epoch: 5| Step: 7
Training loss: 2.6563830375671387
Validation loss: 2.3168117128392702

Epoch: 5| Step: 8
Training loss: 2.3649559020996094
Validation loss: 2.4840490946205716

Epoch: 5| Step: 9
Training loss: 2.6987996101379395
Validation loss: 2.343453271414644

Epoch: 5| Step: 10
Training loss: 2.176156520843506
Validation loss: 2.415477414284983

Epoch: 61| Step: 0
Training loss: 2.6575942039489746
Validation loss: 2.3134220184818393

Epoch: 5| Step: 1
Training loss: 2.809603214263916
Validation loss: 2.4142934545393913

Epoch: 5| Step: 2
Training loss: 2.9652822017669678
Validation loss: 2.4020833866570586

Epoch: 5| Step: 3
Training loss: 2.767920970916748
Validation loss: 2.3723983559557187

Epoch: 5| Step: 4
Training loss: 2.707266330718994
Validation loss: 2.3612619010351037

Epoch: 5| Step: 5
Training loss: 2.172065258026123
Validation loss: 2.41258841688915

Epoch: 5| Step: 6
Training loss: 2.823753833770752
Validation loss: 2.363351737299273

Epoch: 5| Step: 7
Training loss: 1.6906602382659912
Validation loss: 2.405114914781304

Epoch: 5| Step: 8
Training loss: 1.9203288555145264
Validation loss: 2.295308474571474

Epoch: 5| Step: 9
Training loss: 2.3948612213134766
Validation loss: 2.366820735316123

Epoch: 5| Step: 10
Training loss: 2.362597942352295
Validation loss: 2.3804931307351715

Epoch: 62| Step: 0
Training loss: 2.5818119049072266
Validation loss: 2.426366344574959

Epoch: 5| Step: 1
Training loss: 3.3672776222229004
Validation loss: 2.4219945553810365

Epoch: 5| Step: 2
Training loss: 2.766768455505371
Validation loss: 2.3096815488671743

Epoch: 5| Step: 3
Training loss: 2.0221405029296875
Validation loss: 2.45013254175904

Epoch: 5| Step: 4
Training loss: 2.44520902633667
Validation loss: 2.485646777255561

Epoch: 5| Step: 5
Training loss: 3.014397382736206
Validation loss: 2.4111244934861378

Epoch: 5| Step: 6
Training loss: 2.3409221172332764
Validation loss: 2.424243151500661

Epoch: 5| Step: 7
Training loss: 1.925746202468872
Validation loss: 2.376987072729295

Epoch: 5| Step: 8
Training loss: 2.2874038219451904
Validation loss: 2.383579828405893

Epoch: 5| Step: 9
Training loss: 2.1558351516723633
Validation loss: 2.255780977587546

Epoch: 5| Step: 10
Training loss: 2.32582950592041
Validation loss: 2.4445762685550156

Epoch: 63| Step: 0
Training loss: 2.773277521133423
Validation loss: 2.366395950317383

Epoch: 5| Step: 1
Training loss: 2.466114044189453
Validation loss: 2.372028940467424

Epoch: 5| Step: 2
Training loss: 2.748246669769287
Validation loss: 2.3259585724082044

Epoch: 5| Step: 3
Training loss: 2.319542407989502
Validation loss: 2.375050239665534

Epoch: 5| Step: 4
Training loss: 2.2890985012054443
Validation loss: 2.402912337292907

Epoch: 5| Step: 5
Training loss: 2.3265528678894043
Validation loss: 2.3798548790716354

Epoch: 5| Step: 6
Training loss: 2.265738010406494
Validation loss: 2.4706612210119925

Epoch: 5| Step: 7
Training loss: 3.073943853378296
Validation loss: 2.381527095712641

Epoch: 5| Step: 8
Training loss: 2.3783538341522217
Validation loss: 2.468345131925357

Epoch: 5| Step: 9
Training loss: 2.5185816287994385
Validation loss: 2.357019974339393

Epoch: 5| Step: 10
Training loss: 2.089047908782959
Validation loss: 2.3462481703809512

Epoch: 64| Step: 0
Training loss: 2.584625244140625
Validation loss: 2.267719620017595

Epoch: 5| Step: 1
Training loss: 3.592374086380005
Validation loss: 2.4624034563700357

Epoch: 5| Step: 2
Training loss: 2.411512851715088
Validation loss: 2.3075065484610935

Epoch: 5| Step: 3
Training loss: 3.0086798667907715
Validation loss: 2.4254148903713433

Epoch: 5| Step: 4
Training loss: 1.9802509546279907
Validation loss: 2.3128970746071107

Epoch: 5| Step: 5
Training loss: 2.0953550338745117
Validation loss: 2.4580807993488927

Epoch: 5| Step: 6
Training loss: 2.32635498046875
Validation loss: 2.3824393415963776

Epoch: 5| Step: 7
Training loss: 2.225734233856201
Validation loss: 2.3696532454541934

Epoch: 5| Step: 8
Training loss: 2.8141374588012695
Validation loss: 2.389019675152276

Epoch: 5| Step: 9
Training loss: 1.9356234073638916
Validation loss: 2.427627358385312

Epoch: 5| Step: 10
Training loss: 2.7618417739868164
Validation loss: 2.408042869260234

Epoch: 65| Step: 0
Training loss: 1.3699926137924194
Validation loss: 2.4899020835917485

Epoch: 5| Step: 1
Training loss: 2.6118946075439453
Validation loss: 2.3474124298300794

Epoch: 5| Step: 2
Training loss: 1.985040307044983
Validation loss: 2.397463298613025

Epoch: 5| Step: 3
Training loss: 2.682945728302002
Validation loss: 2.4305472425235215

Epoch: 5| Step: 4
Training loss: 3.6738834381103516
Validation loss: 2.4136267157011133

Epoch: 5| Step: 5
Training loss: 2.641860246658325
Validation loss: 2.464356868497787

Epoch: 5| Step: 6
Training loss: 2.146915912628174
Validation loss: 2.459925026021978

Epoch: 5| Step: 7
Training loss: 2.8575127124786377
Validation loss: 2.3388742708390757

Epoch: 5| Step: 8
Training loss: 2.537339687347412
Validation loss: 2.3169188191813808

Epoch: 5| Step: 9
Training loss: 2.89475154876709
Validation loss: 2.352305425110684

Epoch: 5| Step: 10
Training loss: 1.9845296144485474
Validation loss: 2.317212804671257

Epoch: 66| Step: 0
Training loss: 2.3200466632843018
Validation loss: 2.4905477005948304

Epoch: 5| Step: 1
Training loss: 2.110462188720703
Validation loss: 2.4622032052727154

Epoch: 5| Step: 2
Training loss: 2.654149293899536
Validation loss: 2.3364741366396666

Epoch: 5| Step: 3
Training loss: 3.0645928382873535
Validation loss: 2.355569598495319

Epoch: 5| Step: 4
Training loss: 2.5345098972320557
Validation loss: 2.3388942941542594

Epoch: 5| Step: 5
Training loss: 2.6413304805755615
Validation loss: 2.3939022684610016

Epoch: 5| Step: 6
Training loss: 2.004385471343994
Validation loss: 2.3001168876565914

Epoch: 5| Step: 7
Training loss: 2.164003372192383
Validation loss: 2.4008879251377557

Epoch: 5| Step: 8
Training loss: 2.6863019466400146
Validation loss: 2.4036021565878265

Epoch: 5| Step: 9
Training loss: 2.1886274814605713
Validation loss: 2.389805019542735

Epoch: 5| Step: 10
Training loss: 2.850954055786133
Validation loss: 2.3587748440363074

Epoch: 67| Step: 0
Training loss: 2.3929100036621094
Validation loss: 2.368458996536911

Epoch: 5| Step: 1
Training loss: 2.5692877769470215
Validation loss: 2.347449838474233

Epoch: 5| Step: 2
Training loss: 1.7733091115951538
Validation loss: 2.36993315399334

Epoch: 5| Step: 3
Training loss: 1.7997522354125977
Validation loss: 2.4188176906237038

Epoch: 5| Step: 4
Training loss: 2.605772018432617
Validation loss: 2.399294117445587

Epoch: 5| Step: 5
Training loss: 2.4850127696990967
Validation loss: 2.419436695755169

Epoch: 5| Step: 6
Training loss: 2.3900535106658936
Validation loss: 2.3997974036842264

Epoch: 5| Step: 7
Training loss: 2.371887683868408
Validation loss: 2.431259737219862

Epoch: 5| Step: 8
Training loss: 3.0142433643341064
Validation loss: 2.468343916759696

Epoch: 5| Step: 9
Training loss: 2.5535387992858887
Validation loss: 2.463965262136152

Epoch: 5| Step: 10
Training loss: 2.781076669692993
Validation loss: 2.426943334200049

Epoch: 68| Step: 0
Training loss: 2.629343032836914
Validation loss: 2.353587294137606

Epoch: 5| Step: 1
Training loss: 2.7791619300842285
Validation loss: 2.369502441857451

Epoch: 5| Step: 2
Training loss: 3.6155753135681152
Validation loss: 2.3678566512241157

Epoch: 5| Step: 3
Training loss: 2.2860474586486816
Validation loss: 2.3683251488593315

Epoch: 5| Step: 4
Training loss: 2.269519090652466
Validation loss: 2.3495724816476145

Epoch: 5| Step: 5
Training loss: 2.80403208732605
Validation loss: 2.2728376439822617

Epoch: 5| Step: 6
Training loss: 1.7873796224594116
Validation loss: 2.4132163498991277

Epoch: 5| Step: 7
Training loss: 2.1175103187561035
Validation loss: 2.495191220314272

Epoch: 5| Step: 8
Training loss: 2.1760964393615723
Validation loss: 2.445828699296521

Epoch: 5| Step: 9
Training loss: 2.368081569671631
Validation loss: 2.4096872011820474

Epoch: 5| Step: 10
Training loss: 2.3522446155548096
Validation loss: 2.5091383482820246

Epoch: 69| Step: 0
Training loss: 2.3869876861572266
Validation loss: 2.4300684134165444

Epoch: 5| Step: 1
Training loss: 2.283468723297119
Validation loss: 2.3720374286815686

Epoch: 5| Step: 2
Training loss: 3.031934976577759
Validation loss: 2.333569857382005

Epoch: 5| Step: 3
Training loss: 2.292797327041626
Validation loss: 2.2717751559390815

Epoch: 5| Step: 4
Training loss: 2.1250858306884766
Validation loss: 2.3698323003707396

Epoch: 5| Step: 5
Training loss: 2.8950862884521484
Validation loss: 2.3332062972489225

Epoch: 5| Step: 6
Training loss: 2.0547585487365723
Validation loss: 2.3074084148612073

Epoch: 5| Step: 7
Training loss: 2.626709461212158
Validation loss: 2.3632479252353793

Epoch: 5| Step: 8
Training loss: 2.969142436981201
Validation loss: 2.3204952081044516

Epoch: 5| Step: 9
Training loss: 2.0338387489318848
Validation loss: 2.341914261541059

Epoch: 5| Step: 10
Training loss: 2.042980909347534
Validation loss: 2.403895620376833

Epoch: 70| Step: 0
Training loss: 2.5176777839660645
Validation loss: 2.4194384287762385

Epoch: 5| Step: 1
Training loss: 2.7316818237304688
Validation loss: 2.3319548201817337

Epoch: 5| Step: 2
Training loss: 2.6937317848205566
Validation loss: 2.369853324787591

Epoch: 5| Step: 3
Training loss: 2.268845319747925
Validation loss: 2.3229160129383044

Epoch: 5| Step: 4
Training loss: 2.177278995513916
Validation loss: 2.3920680810046453

Epoch: 5| Step: 5
Training loss: 1.9405052661895752
Validation loss: 2.3614851890071744

Epoch: 5| Step: 6
Training loss: 2.452220916748047
Validation loss: 2.3415446050705446

Epoch: 5| Step: 7
Training loss: 2.4850399494171143
Validation loss: 2.348345684748824

Epoch: 5| Step: 8
Training loss: 2.297558069229126
Validation loss: 2.3275581226553967

Epoch: 5| Step: 9
Training loss: 2.2746846675872803
Validation loss: 2.4854198322501233

Epoch: 5| Step: 10
Training loss: 3.1601755619049072
Validation loss: 2.4441720362632506

Epoch: 71| Step: 0
Training loss: 1.9767816066741943
Validation loss: 2.3863820593844176

Epoch: 5| Step: 1
Training loss: 3.1775341033935547
Validation loss: 2.384352017474431

Epoch: 5| Step: 2
Training loss: 1.6890161037445068
Validation loss: 2.3294579816120926

Epoch: 5| Step: 3
Training loss: 2.5456302165985107
Validation loss: 2.3791956593913417

Epoch: 5| Step: 4
Training loss: 2.3523240089416504
Validation loss: 2.3936221625215266

Epoch: 5| Step: 5
Training loss: 2.7800586223602295
Validation loss: 2.3877131913297918

Epoch: 5| Step: 6
Training loss: 1.9459257125854492
Validation loss: 2.4194777883509153

Epoch: 5| Step: 7
Training loss: 2.1235511302948
Validation loss: 2.3921857546734553

Epoch: 5| Step: 8
Training loss: 2.8642075061798096
Validation loss: 2.4448728420401133

Epoch: 5| Step: 9
Training loss: 2.909449577331543
Validation loss: 2.3309165431607153

Epoch: 5| Step: 10
Training loss: 2.4371042251586914
Validation loss: 2.413048839056364

Epoch: 72| Step: 0
Training loss: 2.005265712738037
Validation loss: 2.4113886689627044

Epoch: 5| Step: 1
Training loss: 2.416569232940674
Validation loss: 2.3654557569052583

Epoch: 5| Step: 2
Training loss: 2.106332302093506
Validation loss: 2.4164501672149985

Epoch: 5| Step: 3
Training loss: 3.0180041790008545
Validation loss: 2.406866027462867

Epoch: 5| Step: 4
Training loss: 2.4679765701293945
Validation loss: 2.350623417926091

Epoch: 5| Step: 5
Training loss: 1.8891754150390625
Validation loss: 2.457262351948728

Epoch: 5| Step: 6
Training loss: 2.651031970977783
Validation loss: 2.487043108991397

Epoch: 5| Step: 7
Training loss: 3.385453701019287
Validation loss: 2.4162626394661526

Epoch: 5| Step: 8
Training loss: 2.462883949279785
Validation loss: 2.415177083784534

Epoch: 5| Step: 9
Training loss: 2.232001543045044
Validation loss: 2.423410610486102

Epoch: 5| Step: 10
Training loss: 1.8300912380218506
Validation loss: 2.325009702354349

Epoch: 73| Step: 0
Training loss: 2.9097132682800293
Validation loss: 2.4252427598481536

Epoch: 5| Step: 1
Training loss: 2.602027416229248
Validation loss: 2.3284201570736465

Epoch: 5| Step: 2
Training loss: 2.35959792137146
Validation loss: 2.4743381674571703

Epoch: 5| Step: 3
Training loss: 2.855808973312378
Validation loss: 2.5220892301169773

Epoch: 5| Step: 4
Training loss: 1.8515586853027344
Validation loss: 2.3400682557013726

Epoch: 5| Step: 5
Training loss: 2.4399046897888184
Validation loss: 2.325503482613512

Epoch: 5| Step: 6
Training loss: 1.7087663412094116
Validation loss: 2.363055077932214

Epoch: 5| Step: 7
Training loss: 2.003754138946533
Validation loss: 2.2688731890852734

Epoch: 5| Step: 8
Training loss: 2.637288808822632
Validation loss: 2.3485932324522283

Epoch: 5| Step: 9
Training loss: 2.422797918319702
Validation loss: 2.3625933457446355

Epoch: 5| Step: 10
Training loss: 2.090310573577881
Validation loss: 2.401230417272096

Epoch: 74| Step: 0
Training loss: 2.138859272003174
Validation loss: 2.4461045239561345

Epoch: 5| Step: 1
Training loss: 2.372405529022217
Validation loss: 2.3999874873827864

Epoch: 5| Step: 2
Training loss: 2.9473788738250732
Validation loss: 2.43650326677548

Epoch: 5| Step: 3
Training loss: 2.4898488521575928
Validation loss: 2.37900895713478

Epoch: 5| Step: 4
Training loss: 2.02306866645813
Validation loss: 2.3683473320417505

Epoch: 5| Step: 5
Training loss: 2.5440146923065186
Validation loss: 2.4416833667344946

Epoch: 5| Step: 6
Training loss: 2.9129624366760254
Validation loss: 2.472975138695009

Epoch: 5| Step: 7
Training loss: 2.630882978439331
Validation loss: 2.479165377155427

Epoch: 5| Step: 8
Training loss: 2.402646064758301
Validation loss: 2.4096745060336207

Epoch: 5| Step: 9
Training loss: 2.1201493740081787
Validation loss: 2.491484357464698

Epoch: 5| Step: 10
Training loss: 2.1253116130828857
Validation loss: 2.3224148468304704

Epoch: 75| Step: 0
Training loss: 1.9096238613128662
Validation loss: 2.613222657993276

Epoch: 5| Step: 1
Training loss: 2.8937675952911377
Validation loss: 2.3716274897257485

Epoch: 5| Step: 2
Training loss: 2.906123399734497
Validation loss: 2.350570240328389

Epoch: 5| Step: 3
Training loss: 1.9255279302597046
Validation loss: 2.408309713486702

Epoch: 5| Step: 4
Training loss: 2.5401840209960938
Validation loss: 2.4082864587024977

Epoch: 5| Step: 5
Training loss: 2.0746521949768066
Validation loss: 2.4668899018277406

Epoch: 5| Step: 6
Training loss: 2.5137741565704346
Validation loss: 2.373447556649485

Epoch: 5| Step: 7
Training loss: 2.387849807739258
Validation loss: 2.3503312974847774

Epoch: 5| Step: 8
Training loss: 2.5631089210510254
Validation loss: 2.4250056948713077

Epoch: 5| Step: 9
Training loss: 2.474004030227661
Validation loss: 2.4833227921557683

Epoch: 5| Step: 10
Training loss: 2.5097415447235107
Validation loss: 2.4348481880721224

Epoch: 76| Step: 0
Training loss: 2.641465663909912
Validation loss: 2.475513155742358

Epoch: 5| Step: 1
Training loss: 2.5234732627868652
Validation loss: 2.465521222801619

Epoch: 5| Step: 2
Training loss: 3.2306296825408936
Validation loss: 2.3964021385356946

Epoch: 5| Step: 3
Training loss: 2.393540620803833
Validation loss: 2.4835291344632386

Epoch: 5| Step: 4
Training loss: 2.2968475818634033
Validation loss: 2.4082109748676257

Epoch: 5| Step: 5
Training loss: 2.5586745738983154
Validation loss: 2.558551408911264

Epoch: 5| Step: 6
Training loss: 1.6645481586456299
Validation loss: 2.3906725670701716

Epoch: 5| Step: 7
Training loss: 2.387272357940674
Validation loss: 2.4502965404141333

Epoch: 5| Step: 8
Training loss: 2.0784072875976562
Validation loss: 2.3295687706239763

Epoch: 5| Step: 9
Training loss: 2.5228800773620605
Validation loss: 2.432816836141771

Epoch: 5| Step: 10
Training loss: 2.289354085922241
Validation loss: 2.354714831998271

Epoch: 77| Step: 0
Training loss: 2.172346591949463
Validation loss: 2.4823209316499772

Epoch: 5| Step: 1
Training loss: 2.550447940826416
Validation loss: 2.3521343841347644

Epoch: 5| Step: 2
Training loss: 2.7293944358825684
Validation loss: 2.3776061201608307

Epoch: 5| Step: 3
Training loss: 2.2536532878875732
Validation loss: 2.290638654462753

Epoch: 5| Step: 4
Training loss: 2.9329190254211426
Validation loss: 2.39070523682461

Epoch: 5| Step: 5
Training loss: 2.5341029167175293
Validation loss: 2.3548456597071823

Epoch: 5| Step: 6
Training loss: 2.517857789993286
Validation loss: 2.44164946258709

Epoch: 5| Step: 7
Training loss: 2.260924816131592
Validation loss: 2.35223082188637

Epoch: 5| Step: 8
Training loss: 1.9529273509979248
Validation loss: 2.337005317852061

Epoch: 5| Step: 9
Training loss: 2.577585220336914
Validation loss: 2.2958566834849696

Epoch: 5| Step: 10
Training loss: 2.383073091506958
Validation loss: 2.521307247941212

Epoch: 78| Step: 0
Training loss: 2.2819161415100098
Validation loss: 2.4031147341574393

Epoch: 5| Step: 1
Training loss: 2.452547788619995
Validation loss: 2.371333702918022

Epoch: 5| Step: 2
Training loss: 3.0868637561798096
Validation loss: 2.4987839421918316

Epoch: 5| Step: 3
Training loss: 2.0895538330078125
Validation loss: 2.3027302424112954

Epoch: 5| Step: 4
Training loss: 2.210341453552246
Validation loss: 2.3374122060755247

Epoch: 5| Step: 5
Training loss: 2.285554885864258
Validation loss: 2.4163060777930805

Epoch: 5| Step: 6
Training loss: 2.136430025100708
Validation loss: 2.370210416855351

Epoch: 5| Step: 7
Training loss: 2.332432270050049
Validation loss: 2.3535673951589935

Epoch: 5| Step: 8
Training loss: 2.6604743003845215
Validation loss: 2.222124981623824

Epoch: 5| Step: 9
Training loss: 2.3407156467437744
Validation loss: 2.424933220750542

Epoch: 5| Step: 10
Training loss: 2.269519567489624
Validation loss: 2.3901011277270574

Epoch: 79| Step: 0
Training loss: 2.607950448989868
Validation loss: 2.498167945492652

Epoch: 5| Step: 1
Training loss: 2.1164047718048096
Validation loss: 2.360505452720068

Epoch: 5| Step: 2
Training loss: 1.9802627563476562
Validation loss: 2.3252442882907007

Epoch: 5| Step: 3
Training loss: 3.0536084175109863
Validation loss: 2.3389091824972503

Epoch: 5| Step: 4
Training loss: 1.7882955074310303
Validation loss: 2.405414755626391

Epoch: 5| Step: 5
Training loss: 2.0033745765686035
Validation loss: 2.426147048191358

Epoch: 5| Step: 6
Training loss: 2.192572593688965
Validation loss: 2.3233197991565993

Epoch: 5| Step: 7
Training loss: 2.4565060138702393
Validation loss: 2.3661181157635105

Epoch: 5| Step: 8
Training loss: 2.836416006088257
Validation loss: 2.37505599247512

Epoch: 5| Step: 9
Training loss: 3.6929543018341064
Validation loss: 2.32340100888283

Epoch: 5| Step: 10
Training loss: 2.240856170654297
Validation loss: 2.4803281727657525

Epoch: 80| Step: 0
Training loss: 2.1688051223754883
Validation loss: 2.499058485031128

Epoch: 5| Step: 1
Training loss: 1.7558081150054932
Validation loss: 2.3321286837259927

Epoch: 5| Step: 2
Training loss: 2.3432765007019043
Validation loss: 2.370350863343926

Epoch: 5| Step: 3
Training loss: 2.92460298538208
Validation loss: 2.4042915836457284

Epoch: 5| Step: 4
Training loss: 2.7419142723083496
Validation loss: 2.4482810574193157

Epoch: 5| Step: 5
Training loss: 2.4850668907165527
Validation loss: 2.3932882278196272

Epoch: 5| Step: 6
Training loss: 3.3574767112731934
Validation loss: 2.412805646978399

Epoch: 5| Step: 7
Training loss: 2.1752641201019287
Validation loss: 2.380585793525942

Epoch: 5| Step: 8
Training loss: 2.820260524749756
Validation loss: 2.3325351643305954

Epoch: 5| Step: 9
Training loss: 1.571853756904602
Validation loss: 2.313344624734694

Epoch: 5| Step: 10
Training loss: 1.6493438482284546
Validation loss: 2.4635806263134046

Epoch: 81| Step: 0
Training loss: 2.0087151527404785
Validation loss: 2.3992704499152397

Epoch: 5| Step: 1
Training loss: 2.7285447120666504
Validation loss: 2.444065888722738

Epoch: 5| Step: 2
Training loss: 2.1104581356048584
Validation loss: 2.408202350780528

Epoch: 5| Step: 3
Training loss: 2.0379374027252197
Validation loss: 2.3705839982596775

Epoch: 5| Step: 4
Training loss: 2.3651061058044434
Validation loss: 2.457382784094862

Epoch: 5| Step: 5
Training loss: 2.533299207687378
Validation loss: 2.281770065266599

Epoch: 5| Step: 6
Training loss: 2.7183830738067627
Validation loss: 2.3487836519877114

Epoch: 5| Step: 7
Training loss: 2.3293442726135254
Validation loss: 2.3749987668888544

Epoch: 5| Step: 8
Training loss: 2.746903896331787
Validation loss: 2.423511838400236

Epoch: 5| Step: 9
Training loss: 2.9949288368225098
Validation loss: 2.3537518132117485

Epoch: 5| Step: 10
Training loss: 2.2905447483062744
Validation loss: 2.3358442629537275

Epoch: 82| Step: 0
Training loss: 1.90765380859375
Validation loss: 2.3858461226186445

Epoch: 5| Step: 1
Training loss: 2.179323673248291
Validation loss: 2.3032138193807294

Epoch: 5| Step: 2
Training loss: 2.6770923137664795
Validation loss: 2.3833620420066257

Epoch: 5| Step: 3
Training loss: 2.1231188774108887
Validation loss: 2.426484606599295

Epoch: 5| Step: 4
Training loss: 2.341707944869995
Validation loss: 2.403027649848692

Epoch: 5| Step: 5
Training loss: 2.249448776245117
Validation loss: 2.536489289294007

Epoch: 5| Step: 6
Training loss: 3.204444169998169
Validation loss: 2.4823481267498386

Epoch: 5| Step: 7
Training loss: 2.6352994441986084
Validation loss: 2.411803845436342

Epoch: 5| Step: 8
Training loss: 2.5868916511535645
Validation loss: 2.426626797645323

Epoch: 5| Step: 9
Training loss: 2.4658451080322266
Validation loss: 2.4327360583889868

Epoch: 5| Step: 10
Training loss: 2.87248158454895
Validation loss: 2.5326271057128906

Epoch: 83| Step: 0
Training loss: 2.6352429389953613
Validation loss: 2.350127248353856

Epoch: 5| Step: 1
Training loss: 2.0637824535369873
Validation loss: 2.5019385148120183

Epoch: 5| Step: 2
Training loss: 1.8521778583526611
Validation loss: 2.5212082837217595

Epoch: 5| Step: 3
Training loss: 2.3036324977874756
Validation loss: 2.4740809702104136

Epoch: 5| Step: 4
Training loss: 2.6852402687072754
Validation loss: 2.536791252833541

Epoch: 5| Step: 5
Training loss: 2.539489984512329
Validation loss: 2.366709045184556

Epoch: 5| Step: 6
Training loss: 2.8017773628234863
Validation loss: 2.476385231940977

Epoch: 5| Step: 7
Training loss: 2.4739770889282227
Validation loss: 2.3961580696926323

Epoch: 5| Step: 8
Training loss: 2.304316997528076
Validation loss: 2.4362881491261144

Epoch: 5| Step: 9
Training loss: 2.9274983406066895
Validation loss: 2.3955049053315194

Epoch: 5| Step: 10
Training loss: 1.866368293762207
Validation loss: 2.324937753779914

Epoch: 84| Step: 0
Training loss: 2.2836740016937256
Validation loss: 2.343646187936106

Epoch: 5| Step: 1
Training loss: 1.8371732234954834
Validation loss: 2.439134459341726

Epoch: 5| Step: 2
Training loss: 2.3125882148742676
Validation loss: 2.4976251381699757

Epoch: 5| Step: 3
Training loss: 2.955620288848877
Validation loss: 2.3518081711184595

Epoch: 5| Step: 4
Training loss: 3.024339199066162
Validation loss: 2.290239687888853

Epoch: 5| Step: 5
Training loss: 2.417501449584961
Validation loss: 2.5414948796713226

Epoch: 5| Step: 6
Training loss: 2.4405112266540527
Validation loss: 2.367559286855882

Epoch: 5| Step: 7
Training loss: 2.428825855255127
Validation loss: 2.43626727596406

Epoch: 5| Step: 8
Training loss: 2.3087759017944336
Validation loss: 2.3588364970299507

Epoch: 5| Step: 9
Training loss: 2.2663025856018066
Validation loss: 2.29873832707764

Epoch: 5| Step: 10
Training loss: 1.9493751525878906
Validation loss: 2.398301693700975

Epoch: 85| Step: 0
Training loss: 2.284428119659424
Validation loss: 2.3565676827584543

Epoch: 5| Step: 1
Training loss: 1.9825836420059204
Validation loss: 2.367337803686819

Epoch: 5| Step: 2
Training loss: 2.7103817462921143
Validation loss: 2.4667539545284805

Epoch: 5| Step: 3
Training loss: 2.322089195251465
Validation loss: 2.3759049548897693

Epoch: 5| Step: 4
Training loss: 2.784811496734619
Validation loss: 2.394833049466533

Epoch: 5| Step: 5
Training loss: 2.888976573944092
Validation loss: 2.381797457254061

Epoch: 5| Step: 6
Training loss: 2.3903379440307617
Validation loss: 2.3618219539683354

Epoch: 5| Step: 7
Training loss: 1.405605673789978
Validation loss: 2.354927600070994

Epoch: 5| Step: 8
Training loss: 3.2372233867645264
Validation loss: 2.391583461915293

Epoch: 5| Step: 9
Training loss: 2.714709758758545
Validation loss: 2.4079312739833707

Epoch: 5| Step: 10
Training loss: 1.985369324684143
Validation loss: 2.2981587533027894

Epoch: 86| Step: 0
Training loss: 2.5348916053771973
Validation loss: 2.4439103987909134

Epoch: 5| Step: 1
Training loss: 2.85103178024292
Validation loss: 2.394014832794025

Epoch: 5| Step: 2
Training loss: 2.0789406299591064
Validation loss: 2.492155005854945

Epoch: 5| Step: 3
Training loss: 3.202052593231201
Validation loss: 2.516789706804419

Epoch: 5| Step: 4
Training loss: 1.5172367095947266
Validation loss: 2.4000371963747087

Epoch: 5| Step: 5
Training loss: 2.2382779121398926
Validation loss: 2.530852681847029

Epoch: 5| Step: 6
Training loss: 3.119520902633667
Validation loss: 2.5093996781174854

Epoch: 5| Step: 7
Training loss: 1.6817572116851807
Validation loss: 2.481189825201547

Epoch: 5| Step: 8
Training loss: 2.7009856700897217
Validation loss: 2.5134745682439497

Epoch: 5| Step: 9
Training loss: 2.7039566040039062
Validation loss: 2.3530530468110116

Epoch: 5| Step: 10
Training loss: 2.212193727493286
Validation loss: 2.3566831132417083

Epoch: 87| Step: 0
Training loss: 2.308579206466675
Validation loss: 2.4114468853960753

Epoch: 5| Step: 1
Training loss: 2.8608689308166504
Validation loss: 2.3732743724699943

Epoch: 5| Step: 2
Training loss: 2.0902740955352783
Validation loss: 2.3600296153817126

Epoch: 5| Step: 3
Training loss: 1.7053028345108032
Validation loss: 2.370853203599171

Epoch: 5| Step: 4
Training loss: 2.746243953704834
Validation loss: 2.4108768996372016

Epoch: 5| Step: 5
Training loss: 1.6814804077148438
Validation loss: 2.356441987458096

Epoch: 5| Step: 6
Training loss: 2.4528732299804688
Validation loss: 2.391437404899187

Epoch: 5| Step: 7
Training loss: 2.5532994270324707
Validation loss: 2.45484774087065

Epoch: 5| Step: 8
Training loss: 1.9712318181991577
Validation loss: 2.324738556338895

Epoch: 5| Step: 9
Training loss: 3.25140118598938
Validation loss: 2.4460189086134716

Epoch: 5| Step: 10
Training loss: 2.345587968826294
Validation loss: 2.3884184257958525

Epoch: 88| Step: 0
Training loss: 1.918927788734436
Validation loss: 2.346190673048778

Epoch: 5| Step: 1
Training loss: 2.5360472202301025
Validation loss: 2.3562308280698714

Epoch: 5| Step: 2
Training loss: 1.6014583110809326
Validation loss: 2.2843409020413636

Epoch: 5| Step: 3
Training loss: 2.599553346633911
Validation loss: 2.2687694052214264

Epoch: 5| Step: 4
Training loss: 2.829296827316284
Validation loss: 2.3583322776261197

Epoch: 5| Step: 5
Training loss: 2.0810012817382812
Validation loss: 2.361067907784575

Epoch: 5| Step: 6
Training loss: 2.0652222633361816
Validation loss: 2.38274488910552

Epoch: 5| Step: 7
Training loss: 2.6101021766662598
Validation loss: 2.4289828295348794

Epoch: 5| Step: 8
Training loss: 2.46600079536438
Validation loss: 2.3765806357065835

Epoch: 5| Step: 9
Training loss: 3.1553168296813965
Validation loss: 2.3699539912644254

Epoch: 5| Step: 10
Training loss: 2.4214322566986084
Validation loss: 2.378018884248631

Epoch: 89| Step: 0
Training loss: 3.346179246902466
Validation loss: 2.4058729628080964

Epoch: 5| Step: 1
Training loss: 2.3984251022338867
Validation loss: 2.434789531974382

Epoch: 5| Step: 2
Training loss: 2.3546745777130127
Validation loss: 2.401474742479222

Epoch: 5| Step: 3
Training loss: 2.3393516540527344
Validation loss: 2.444746337911134

Epoch: 5| Step: 4
Training loss: 2.386653184890747
Validation loss: 2.494564717815768

Epoch: 5| Step: 5
Training loss: 2.4240081310272217
Validation loss: 2.388795091259864

Epoch: 5| Step: 6
Training loss: 2.1412582397460938
Validation loss: 2.3801352977752686

Epoch: 5| Step: 7
Training loss: 3.0113275051116943
Validation loss: 2.299304316120763

Epoch: 5| Step: 8
Training loss: 2.523137331008911
Validation loss: 2.4570777980230187

Epoch: 5| Step: 9
Training loss: 2.3331515789031982
Validation loss: 2.375060325027794

Epoch: 5| Step: 10
Training loss: 1.8960142135620117
Validation loss: 2.4163781622404694

Epoch: 90| Step: 0
Training loss: 2.715872049331665
Validation loss: 2.3995569136834916

Epoch: 5| Step: 1
Training loss: 1.6224091053009033
Validation loss: 2.4647956894290064

Epoch: 5| Step: 2
Training loss: 2.1893882751464844
Validation loss: 2.4018537434198524

Epoch: 5| Step: 3
Training loss: 1.644134521484375
Validation loss: 2.508471753007622

Epoch: 5| Step: 4
Training loss: 2.0448405742645264
Validation loss: 2.426294836946713

Epoch: 5| Step: 5
Training loss: 2.7167155742645264
Validation loss: 2.2738070052157164

Epoch: 5| Step: 6
Training loss: 2.5664401054382324
Validation loss: 2.3488672317997104

Epoch: 5| Step: 7
Training loss: 3.0129096508026123
Validation loss: 2.313907914264228

Epoch: 5| Step: 8
Training loss: 2.324183464050293
Validation loss: 2.3122997514663206

Epoch: 5| Step: 9
Training loss: 2.7510712146759033
Validation loss: 2.3177710361378168

Epoch: 5| Step: 10
Training loss: 2.5546019077301025
Validation loss: 2.4678522694495415

Epoch: 91| Step: 0
Training loss: 2.075737476348877
Validation loss: 2.3491397929447952

Epoch: 5| Step: 1
Training loss: 2.008803606033325
Validation loss: 2.35874104756181

Epoch: 5| Step: 2
Training loss: 2.59548020362854
Validation loss: 2.426088122911351

Epoch: 5| Step: 3
Training loss: 2.6797995567321777
Validation loss: 2.3159643744909637

Epoch: 5| Step: 4
Training loss: 2.356980323791504
Validation loss: 2.423130302019017

Epoch: 5| Step: 5
Training loss: 2.1977896690368652
Validation loss: 2.378430912571569

Epoch: 5| Step: 6
Training loss: 1.8608777523040771
Validation loss: 2.3150867121194

Epoch: 5| Step: 7
Training loss: 3.091460943222046
Validation loss: 2.3209735578106296

Epoch: 5| Step: 8
Training loss: 2.0632927417755127
Validation loss: 2.461477930827807

Epoch: 5| Step: 9
Training loss: 2.292400360107422
Validation loss: 2.3946485006681053

Epoch: 5| Step: 10
Training loss: 2.4984347820281982
Validation loss: 2.4146086067281742

Epoch: 92| Step: 0
Training loss: 2.5342864990234375
Validation loss: 2.370387295240997

Epoch: 5| Step: 1
Training loss: 2.0030815601348877
Validation loss: 2.3724094821560766

Epoch: 5| Step: 2
Training loss: 2.1766247749328613
Validation loss: 2.3959966756964244

Epoch: 5| Step: 3
Training loss: 1.6480433940887451
Validation loss: 2.369176572368991

Epoch: 5| Step: 4
Training loss: 2.513507604598999
Validation loss: 2.3400268926415393

Epoch: 5| Step: 5
Training loss: 2.2149863243103027
Validation loss: 2.3707271160617953

Epoch: 5| Step: 6
Training loss: 2.782874584197998
Validation loss: 2.429949624564058

Epoch: 5| Step: 7
Training loss: 2.15151047706604
Validation loss: 2.287389519394085

Epoch: 5| Step: 8
Training loss: 2.870215892791748
Validation loss: 2.4338106186159196

Epoch: 5| Step: 9
Training loss: 2.485025405883789
Validation loss: 2.3948490030022076

Epoch: 5| Step: 10
Training loss: 2.7272446155548096
Validation loss: 2.3501386052818707

Epoch: 93| Step: 0
Training loss: 1.8321586847305298
Validation loss: 2.3702630253248316

Epoch: 5| Step: 1
Training loss: 1.896414041519165
Validation loss: 2.359736422056793

Epoch: 5| Step: 2
Training loss: 2.08367657661438
Validation loss: 2.3218399863089285

Epoch: 5| Step: 3
Training loss: 2.8920254707336426
Validation loss: 2.4127593501921623

Epoch: 5| Step: 4
Training loss: 2.195190906524658
Validation loss: 2.2662062593685683

Epoch: 5| Step: 5
Training loss: 3.1254563331604004
Validation loss: 2.572085001135385

Epoch: 5| Step: 6
Training loss: 2.1382694244384766
Validation loss: 2.37640982033104

Epoch: 5| Step: 7
Training loss: 2.21455979347229
Validation loss: 2.3285081360929754

Epoch: 5| Step: 8
Training loss: 3.407813549041748
Validation loss: 2.5170800608973347

Epoch: 5| Step: 9
Training loss: 1.6897764205932617
Validation loss: 2.3440513495476014

Epoch: 5| Step: 10
Training loss: 1.7499561309814453
Validation loss: 2.2590942164903045

Epoch: 94| Step: 0
Training loss: 1.6073074340820312
Validation loss: 2.436760994695848

Epoch: 5| Step: 1
Training loss: 2.2654519081115723
Validation loss: 2.348274694975986

Epoch: 5| Step: 2
Training loss: 2.3686814308166504
Validation loss: 2.4345166580651396

Epoch: 5| Step: 3
Training loss: 1.9485619068145752
Validation loss: 2.4227576435253186

Epoch: 5| Step: 4
Training loss: 1.5752277374267578
Validation loss: 2.4973697431625856

Epoch: 5| Step: 5
Training loss: 2.9445929527282715
Validation loss: 2.4462288477087535

Epoch: 5| Step: 6
Training loss: 2.0999560356140137
Validation loss: 2.4280067541266

Epoch: 5| Step: 7
Training loss: 2.8881430625915527
Validation loss: 2.415634819256362

Epoch: 5| Step: 8
Training loss: 2.682650566101074
Validation loss: 2.373974856509957

Epoch: 5| Step: 9
Training loss: 2.961212396621704
Validation loss: 2.3999980034366732

Epoch: 5| Step: 10
Training loss: 2.836111068725586
Validation loss: 2.4951579263133388

Epoch: 95| Step: 0
Training loss: 2.0368287563323975
Validation loss: 2.4859130638901905

Epoch: 5| Step: 1
Training loss: 1.746421456336975
Validation loss: 2.4957126109830794

Epoch: 5| Step: 2
Training loss: 2.6382713317871094
Validation loss: 2.467767802617883

Epoch: 5| Step: 3
Training loss: 2.507699489593506
Validation loss: 2.50269389665255

Epoch: 5| Step: 4
Training loss: 3.1999406814575195
Validation loss: 2.4239924082192044

Epoch: 5| Step: 5
Training loss: 2.9621176719665527
Validation loss: 2.3728481441415767

Epoch: 5| Step: 6
Training loss: 1.8523237705230713
Validation loss: 2.455487351263723

Epoch: 5| Step: 7
Training loss: 2.5576939582824707
Validation loss: 2.4097065643597673

Epoch: 5| Step: 8
Training loss: 2.4602437019348145
Validation loss: 2.437088135750063

Epoch: 5| Step: 9
Training loss: 1.8922882080078125
Validation loss: 2.401106096083118

Epoch: 5| Step: 10
Training loss: 1.912121295928955
Validation loss: 2.3042999954633814

Epoch: 96| Step: 0
Training loss: 2.0115694999694824
Validation loss: 2.3765214514988724

Epoch: 5| Step: 1
Training loss: 2.3653907775878906
Validation loss: 2.430067700724448

Epoch: 5| Step: 2
Training loss: 2.068586826324463
Validation loss: 2.4632623285375614

Epoch: 5| Step: 3
Training loss: 3.048646926879883
Validation loss: 2.3800462907360447

Epoch: 5| Step: 4
Training loss: 1.9488471746444702
Validation loss: 2.3625832116732033

Epoch: 5| Step: 5
Training loss: 2.7604801654815674
Validation loss: 2.451253537208803

Epoch: 5| Step: 6
Training loss: 2.242760181427002
Validation loss: 2.496633686045165

Epoch: 5| Step: 7
Training loss: 2.537104606628418
Validation loss: 2.47259610186341

Epoch: 5| Step: 8
Training loss: 2.6148533821105957
Validation loss: 2.4006887174421743

Epoch: 5| Step: 9
Training loss: 1.9884170293807983
Validation loss: 2.260110321865287

Epoch: 5| Step: 10
Training loss: 2.461341381072998
Validation loss: 2.4285440983310824

Epoch: 97| Step: 0
Training loss: 2.1539902687072754
Validation loss: 2.275599815512216

Epoch: 5| Step: 1
Training loss: 2.2384750843048096
Validation loss: 2.4581549757270404

Epoch: 5| Step: 2
Training loss: 2.145068645477295
Validation loss: 2.4019601114334597

Epoch: 5| Step: 3
Training loss: 2.4623332023620605
Validation loss: 2.401512228032594

Epoch: 5| Step: 4
Training loss: 2.593752145767212
Validation loss: 2.5087476981583463

Epoch: 5| Step: 5
Training loss: 2.485093593597412
Validation loss: 2.2841526462185766

Epoch: 5| Step: 6
Training loss: 1.787103295326233
Validation loss: 2.374967477654898

Epoch: 5| Step: 7
Training loss: 2.3788368701934814
Validation loss: 2.344690102402882

Epoch: 5| Step: 8
Training loss: 3.178600788116455
Validation loss: 2.4055322806040444

Epoch: 5| Step: 9
Training loss: 2.5291333198547363
Validation loss: 2.5405390518967823

Epoch: 5| Step: 10
Training loss: 2.365719795227051
Validation loss: 2.3939881529859317

Epoch: 98| Step: 0
Training loss: 2.024367570877075
Validation loss: 2.2412277985644597

Epoch: 5| Step: 1
Training loss: 2.424809694290161
Validation loss: 2.346880012942899

Epoch: 5| Step: 2
Training loss: 2.6541459560394287
Validation loss: 2.3641281691930627

Epoch: 5| Step: 3
Training loss: 2.5405259132385254
Validation loss: 2.3356568172413814

Epoch: 5| Step: 4
Training loss: 2.2984211444854736
Validation loss: 2.4442551700017785

Epoch: 5| Step: 5
Training loss: 1.9217199087142944
Validation loss: 2.3009824496443554

Epoch: 5| Step: 6
Training loss: 3.0377402305603027
Validation loss: 2.403234451047836

Epoch: 5| Step: 7
Training loss: 1.7544056177139282
Validation loss: 2.341017835883684

Epoch: 5| Step: 8
Training loss: 2.143131971359253
Validation loss: 2.3752289997634066

Epoch: 5| Step: 9
Training loss: 2.5893654823303223
Validation loss: 2.4304339988257295

Epoch: 5| Step: 10
Training loss: 2.9859116077423096
Validation loss: 2.4060077180144606

Epoch: 99| Step: 0
Training loss: 2.1279826164245605
Validation loss: 2.3458793676027687

Epoch: 5| Step: 1
Training loss: 2.7008509635925293
Validation loss: 2.3955921588405484

Epoch: 5| Step: 2
Training loss: 2.9076857566833496
Validation loss: 2.4037254446296283

Epoch: 5| Step: 3
Training loss: 2.5207126140594482
Validation loss: 2.299268223906076

Epoch: 5| Step: 4
Training loss: 2.4311702251434326
Validation loss: 2.345433512041646

Epoch: 5| Step: 5
Training loss: 2.32454776763916
Validation loss: 2.380976394940448

Epoch: 5| Step: 6
Training loss: 2.4100708961486816
Validation loss: 2.2978597507681897

Epoch: 5| Step: 7
Training loss: 1.899817705154419
Validation loss: 2.4759776976800736

Epoch: 5| Step: 8
Training loss: 2.0661110877990723
Validation loss: 2.449219040973212

Epoch: 5| Step: 9
Training loss: 2.5803685188293457
Validation loss: 2.4620693575951362

Epoch: 5| Step: 10
Training loss: 2.0440287590026855
Validation loss: 2.3077954989607616

Epoch: 100| Step: 0
Training loss: 2.067561388015747
Validation loss: 2.346010510639478

Epoch: 5| Step: 1
Training loss: 2.5757017135620117
Validation loss: 2.3764475519939134

Epoch: 5| Step: 2
Training loss: 2.5758137702941895
Validation loss: 2.508537241207656

Epoch: 5| Step: 3
Training loss: 2.4989027976989746
Validation loss: 2.3927976469839773

Epoch: 5| Step: 4
Training loss: 2.152264356613159
Validation loss: 2.421257927853574

Epoch: 5| Step: 5
Training loss: 2.2505152225494385
Validation loss: 2.5207232557317263

Epoch: 5| Step: 6
Training loss: 2.4128575325012207
Validation loss: 2.3573923880054104

Epoch: 5| Step: 7
Training loss: 2.332396984100342
Validation loss: 2.3511115633031374

Epoch: 5| Step: 8
Training loss: 2.5066046714782715
Validation loss: 2.3188549164802796

Epoch: 5| Step: 9
Training loss: 2.439932107925415
Validation loss: 2.4713276740043395

Epoch: 5| Step: 10
Training loss: 1.8168139457702637
Validation loss: 2.43162013125676

Epoch: 101| Step: 0
Training loss: 2.8379154205322266
Validation loss: 2.5042481627515567

Epoch: 5| Step: 1
Training loss: 2.2515158653259277
Validation loss: 2.4245832735492336

Epoch: 5| Step: 2
Training loss: 2.871269941329956
Validation loss: 2.430258233060119

Epoch: 5| Step: 3
Training loss: 2.2854247093200684
Validation loss: 2.366796544803086

Epoch: 5| Step: 4
Training loss: 2.076554775238037
Validation loss: 2.471695371853408

Epoch: 5| Step: 5
Training loss: 2.5759706497192383
Validation loss: 2.448505882293947

Epoch: 5| Step: 6
Training loss: 1.9948320388793945
Validation loss: 2.36343079228555

Epoch: 5| Step: 7
Training loss: 2.4910712242126465
Validation loss: 2.4707502857331307

Epoch: 5| Step: 8
Training loss: 2.3895983695983887
Validation loss: 2.363878739777432

Epoch: 5| Step: 9
Training loss: 1.961949110031128
Validation loss: 2.3600579589925785

Epoch: 5| Step: 10
Training loss: 2.3980178833007812
Validation loss: 2.4546390092501076

Epoch: 102| Step: 0
Training loss: 2.036040782928467
Validation loss: 2.3856295116486086

Epoch: 5| Step: 1
Training loss: 1.9046179056167603
Validation loss: 2.4311946720205326

Epoch: 5| Step: 2
Training loss: 1.8567936420440674
Validation loss: 2.4974792413814093

Epoch: 5| Step: 3
Training loss: 2.255037307739258
Validation loss: 2.492043351614347

Epoch: 5| Step: 4
Training loss: 2.49249529838562
Validation loss: 2.4238824716178318

Epoch: 5| Step: 5
Training loss: 3.312133312225342
Validation loss: 2.346657080035056

Epoch: 5| Step: 6
Training loss: 1.9573723077774048
Validation loss: 2.3469242383075017

Epoch: 5| Step: 7
Training loss: 2.8626792430877686
Validation loss: 2.4102736480774416

Epoch: 5| Step: 8
Training loss: 2.5232040882110596
Validation loss: 2.3509652165956396

Epoch: 5| Step: 9
Training loss: 2.721628427505493
Validation loss: 2.3067873575354136

Epoch: 5| Step: 10
Training loss: 2.1245789527893066
Validation loss: 2.3598223937455045

Epoch: 103| Step: 0
Training loss: 2.9046878814697266
Validation loss: 2.406564989397603

Epoch: 5| Step: 1
Training loss: 1.9113582372665405
Validation loss: 2.3581895443700973

Epoch: 5| Step: 2
Training loss: 1.8952077627182007
Validation loss: 2.36043518845753

Epoch: 5| Step: 3
Training loss: 2.6556060314178467
Validation loss: 2.4579896157787693

Epoch: 5| Step: 4
Training loss: 2.4942264556884766
Validation loss: 2.4390498322825276

Epoch: 5| Step: 5
Training loss: 2.401218891143799
Validation loss: 2.4404750126664356

Epoch: 5| Step: 6
Training loss: 2.0120723247528076
Validation loss: 2.3130109617787022

Epoch: 5| Step: 7
Training loss: 2.8148140907287598
Validation loss: 2.3648189344713764

Epoch: 5| Step: 8
Training loss: 2.532343626022339
Validation loss: 2.4656540142592562

Epoch: 5| Step: 9
Training loss: 2.301528215408325
Validation loss: 2.4894785932315293

Epoch: 5| Step: 10
Training loss: 2.405708074569702
Validation loss: 2.3332126422594954

Epoch: 104| Step: 0
Training loss: 2.8403468132019043
Validation loss: 2.4204993760713966

Epoch: 5| Step: 1
Training loss: 2.1913976669311523
Validation loss: 2.495510211554907

Epoch: 5| Step: 2
Training loss: 2.6474883556365967
Validation loss: 2.4473265140287337

Epoch: 5| Step: 3
Training loss: 2.9026198387145996
Validation loss: 2.3674960341504825

Epoch: 5| Step: 4
Training loss: 2.3288040161132812
Validation loss: 2.3981936285572667

Epoch: 5| Step: 5
Training loss: 1.8216886520385742
Validation loss: 2.528030051979967

Epoch: 5| Step: 6
Training loss: 1.6398473978042603
Validation loss: 2.4438921097786195

Epoch: 5| Step: 7
Training loss: 2.4363605976104736
Validation loss: 2.505457217975329

Epoch: 5| Step: 8
Training loss: 2.415428876876831
Validation loss: 2.3831768112797893

Epoch: 5| Step: 9
Training loss: 2.4469149112701416
Validation loss: 2.45327607534265

Epoch: 5| Step: 10
Training loss: 2.73124098777771
Validation loss: 2.5138167758141794

Epoch: 105| Step: 0
Training loss: 2.753674030303955
Validation loss: 2.4832872139510287

Epoch: 5| Step: 1
Training loss: 1.3866138458251953
Validation loss: 2.4650209001315537

Epoch: 5| Step: 2
Training loss: 1.5265129804611206
Validation loss: 2.440136947939473

Epoch: 5| Step: 3
Training loss: 3.255539655685425
Validation loss: 2.4848248112586235

Epoch: 5| Step: 4
Training loss: 2.389685869216919
Validation loss: 2.3593679064063617

Epoch: 5| Step: 5
Training loss: 1.950034737586975
Validation loss: 2.4124835152779855

Epoch: 5| Step: 6
Training loss: 2.4896531105041504
Validation loss: 2.377102956976942

Epoch: 5| Step: 7
Training loss: 2.842055082321167
Validation loss: 2.5672213967128465

Epoch: 5| Step: 8
Training loss: 2.4836959838867188
Validation loss: 2.442066897628128

Epoch: 5| Step: 9
Training loss: 2.2584829330444336
Validation loss: 2.364062868138795

Epoch: 5| Step: 10
Training loss: 2.1070005893707275
Validation loss: 2.4935045421764417

Epoch: 106| Step: 0
Training loss: 1.7257897853851318
Validation loss: 2.360244563830796

Epoch: 5| Step: 1
Training loss: 2.2871670722961426
Validation loss: 2.531200508917532

Epoch: 5| Step: 2
Training loss: 2.3078434467315674
Validation loss: 2.42977935524397

Epoch: 5| Step: 3
Training loss: 2.381293773651123
Validation loss: 2.293302047637201

Epoch: 5| Step: 4
Training loss: 2.2127490043640137
Validation loss: 2.3954360485076904

Epoch: 5| Step: 5
Training loss: 2.3472840785980225
Validation loss: 2.3433038086019535

Epoch: 5| Step: 6
Training loss: 1.919774055480957
Validation loss: 2.3839040904916744

Epoch: 5| Step: 7
Training loss: 3.4733970165252686
Validation loss: 2.334820898630286

Epoch: 5| Step: 8
Training loss: 2.312169075012207
Validation loss: 2.276715329898301

Epoch: 5| Step: 9
Training loss: 2.23138165473938
Validation loss: 2.3514148240448325

Epoch: 5| Step: 10
Training loss: 1.9023159742355347
Validation loss: 2.4392929000239216

Epoch: 107| Step: 0
Training loss: 1.9732046127319336
Validation loss: 2.3252269298799577

Epoch: 5| Step: 1
Training loss: 2.5484325885772705
Validation loss: 2.4524119361754386

Epoch: 5| Step: 2
Training loss: 1.833009123802185
Validation loss: 2.357952134583586

Epoch: 5| Step: 3
Training loss: 2.5465645790100098
Validation loss: 2.412623441347512

Epoch: 5| Step: 4
Training loss: 2.3016409873962402
Validation loss: 2.281478371671451

Epoch: 5| Step: 5
Training loss: 2.2877256870269775
Validation loss: 2.3571771678104194

Epoch: 5| Step: 6
Training loss: 2.341597318649292
Validation loss: 2.4266583073523735

Epoch: 5| Step: 7
Training loss: 2.401029586791992
Validation loss: 2.364110174999442

Epoch: 5| Step: 8
Training loss: 2.624387264251709
Validation loss: 2.357386883868966

Epoch: 5| Step: 9
Training loss: 2.6573891639709473
Validation loss: 2.3575014645053494

Epoch: 5| Step: 10
Training loss: 2.304893970489502
Validation loss: 2.3935477272156747

Epoch: 108| Step: 0
Training loss: 1.6191543340682983
Validation loss: 2.462809214027979

Epoch: 5| Step: 1
Training loss: 1.5804189443588257
Validation loss: 2.2740255171252834

Epoch: 5| Step: 2
Training loss: 2.088407516479492
Validation loss: 2.4506401246593845

Epoch: 5| Step: 3
Training loss: 2.5609254837036133
Validation loss: 2.3749342913268716

Epoch: 5| Step: 4
Training loss: 2.306421995162964
Validation loss: 2.3417965250630535

Epoch: 5| Step: 5
Training loss: 2.369306802749634
Validation loss: 2.432081148188601

Epoch: 5| Step: 6
Training loss: 2.751495599746704
Validation loss: 2.361005729244601

Epoch: 5| Step: 7
Training loss: 1.8017451763153076
Validation loss: 2.346594150348376

Epoch: 5| Step: 8
Training loss: 2.417738437652588
Validation loss: 2.2987872323682232

Epoch: 5| Step: 9
Training loss: 3.0953269004821777
Validation loss: 2.4841774830254177

Epoch: 5| Step: 10
Training loss: 2.560481309890747
Validation loss: 2.4277738448112243

Epoch: 109| Step: 0
Training loss: 2.0642776489257812
Validation loss: 2.4622664554144746

Epoch: 5| Step: 1
Training loss: 2.2040867805480957
Validation loss: 2.446566116425299

Epoch: 5| Step: 2
Training loss: 1.7571996450424194
Validation loss: 2.524850913273391

Epoch: 5| Step: 3
Training loss: 2.4968795776367188
Validation loss: 2.54886209067478

Epoch: 5| Step: 4
Training loss: 2.0775575637817383
Validation loss: 2.4957942962646484

Epoch: 5| Step: 5
Training loss: 2.4471049308776855
Validation loss: 2.3493079677704842

Epoch: 5| Step: 6
Training loss: 3.129671812057495
Validation loss: 2.470853808105633

Epoch: 5| Step: 7
Training loss: 2.201429843902588
Validation loss: 2.471816019345355

Epoch: 5| Step: 8
Training loss: 2.2358057498931885
Validation loss: 2.477947614526236

Epoch: 5| Step: 9
Training loss: 3.4840455055236816
Validation loss: 2.4511306516585813

Epoch: 5| Step: 10
Training loss: 2.4204564094543457
Validation loss: 2.4515962959617696

Epoch: 110| Step: 0
Training loss: 2.5077786445617676
Validation loss: 2.4254119575664563

Epoch: 5| Step: 1
Training loss: 1.8293848037719727
Validation loss: 2.5379922646348194

Epoch: 5| Step: 2
Training loss: 2.6690993309020996
Validation loss: 2.39202219183727

Epoch: 5| Step: 3
Training loss: 1.955681562423706
Validation loss: 2.4108584106609388

Epoch: 5| Step: 4
Training loss: 2.350048065185547
Validation loss: 2.3966300384972685

Epoch: 5| Step: 5
Training loss: 2.5859246253967285
Validation loss: 2.432560820733347

Epoch: 5| Step: 6
Training loss: 2.0729012489318848
Validation loss: 2.4464070566238894

Epoch: 5| Step: 7
Training loss: 2.718898057937622
Validation loss: 2.453082169255903

Epoch: 5| Step: 8
Training loss: 1.8939762115478516
Validation loss: 2.4491311811631724

Epoch: 5| Step: 9
Training loss: 2.090467929840088
Validation loss: 2.3897342246065856

Epoch: 5| Step: 10
Training loss: 2.741288661956787
Validation loss: 2.3359677894141084

Epoch: 111| Step: 0
Training loss: 1.5690844058990479
Validation loss: 2.50967502081266

Epoch: 5| Step: 1
Training loss: 2.428837537765503
Validation loss: 2.4186700031321537

Epoch: 5| Step: 2
Training loss: 2.8557538986206055
Validation loss: 2.3891368732657483

Epoch: 5| Step: 3
Training loss: 2.2808802127838135
Validation loss: 2.4502124760740545

Epoch: 5| Step: 4
Training loss: 2.642357110977173
Validation loss: 2.3028383267823087

Epoch: 5| Step: 5
Training loss: 2.076294422149658
Validation loss: 2.443403369636946

Epoch: 5| Step: 6
Training loss: 2.272954225540161
Validation loss: 2.371465593255976

Epoch: 5| Step: 7
Training loss: 1.9922672510147095
Validation loss: 2.3682466630012757

Epoch: 5| Step: 8
Training loss: 2.8105852603912354
Validation loss: 2.4232291508746404

Epoch: 5| Step: 9
Training loss: 2.133634090423584
Validation loss: 2.4519636887376026

Epoch: 5| Step: 10
Training loss: 2.937871217727661
Validation loss: 2.398195525651337

Epoch: 112| Step: 0
Training loss: 2.9825549125671387
Validation loss: 2.3546560349002963

Epoch: 5| Step: 1
Training loss: 1.65826416015625
Validation loss: 2.399870334133025

Epoch: 5| Step: 2
Training loss: 1.9269752502441406
Validation loss: 2.461617636424239

Epoch: 5| Step: 3
Training loss: 2.2636771202087402
Validation loss: 2.3345325082860966

Epoch: 5| Step: 4
Training loss: 2.744020462036133
Validation loss: 2.435424986705985

Epoch: 5| Step: 5
Training loss: 2.3228631019592285
Validation loss: 2.432487803120767

Epoch: 5| Step: 6
Training loss: 2.532611608505249
Validation loss: 2.2958944818024993

Epoch: 5| Step: 7
Training loss: 2.514241933822632
Validation loss: 2.332503813569264

Epoch: 5| Step: 8
Training loss: 2.5252645015716553
Validation loss: 2.3858904300197477

Epoch: 5| Step: 9
Training loss: 1.7814788818359375
Validation loss: 2.4453923753512803

Epoch: 5| Step: 10
Training loss: 2.3264923095703125
Validation loss: 2.3603701104399977

Epoch: 113| Step: 0
Training loss: 1.8739995956420898
Validation loss: 2.3958764742779475

Epoch: 5| Step: 1
Training loss: 2.86348295211792
Validation loss: 2.265088373614896

Epoch: 5| Step: 2
Training loss: 1.666316270828247
Validation loss: 2.277017508783648

Epoch: 5| Step: 3
Training loss: 1.8724136352539062
Validation loss: 2.316516714711343

Epoch: 5| Step: 4
Training loss: 2.499356746673584
Validation loss: 2.3567875969794487

Epoch: 5| Step: 5
Training loss: 2.637580633163452
Validation loss: 2.4275162155910204

Epoch: 5| Step: 6
Training loss: 2.658355712890625
Validation loss: 2.3325183160843386

Epoch: 5| Step: 7
Training loss: 2.637859344482422
Validation loss: 2.300780780853764

Epoch: 5| Step: 8
Training loss: 2.2001140117645264
Validation loss: 2.292446956839613

Epoch: 5| Step: 9
Training loss: 2.4224472045898438
Validation loss: 2.3185069689186673

Epoch: 5| Step: 10
Training loss: 2.600837230682373
Validation loss: 2.273763910416634

Epoch: 114| Step: 0
Training loss: 2.0357553958892822
Validation loss: 2.3958350278997935

Epoch: 5| Step: 1
Training loss: 1.982244849205017
Validation loss: 2.5145328813983547

Epoch: 5| Step: 2
Training loss: 2.254427433013916
Validation loss: 2.311618073012239

Epoch: 5| Step: 3
Training loss: 2.4427502155303955
Validation loss: 2.3882301853549097

Epoch: 5| Step: 4
Training loss: 2.8062384128570557
Validation loss: 2.494904964200912

Epoch: 5| Step: 5
Training loss: 2.578010082244873
Validation loss: 2.3527092164562595

Epoch: 5| Step: 6
Training loss: 2.0337703227996826
Validation loss: 2.422934111728463

Epoch: 5| Step: 7
Training loss: 2.7262675762176514
Validation loss: 2.397554935947541

Epoch: 5| Step: 8
Training loss: 2.5734870433807373
Validation loss: 2.536097154822401

Epoch: 5| Step: 9
Training loss: 2.119871139526367
Validation loss: 2.3942047319104596

Epoch: 5| Step: 10
Training loss: 1.9030044078826904
Validation loss: 2.3414864437554472

Epoch: 115| Step: 0
Training loss: 2.4136245250701904
Validation loss: 2.382578762628699

Epoch: 5| Step: 1
Training loss: 2.4355640411376953
Validation loss: 2.416509195040631

Epoch: 5| Step: 2
Training loss: 1.8033301830291748
Validation loss: 2.4358283896600046

Epoch: 5| Step: 3
Training loss: 2.5428173542022705
Validation loss: 2.440914994926863

Epoch: 5| Step: 4
Training loss: 2.8272972106933594
Validation loss: 2.3281482829842517

Epoch: 5| Step: 5
Training loss: 3.0058746337890625
Validation loss: 2.3056424099911927

Epoch: 5| Step: 6
Training loss: 2.6773650646209717
Validation loss: 2.3311790112526185

Epoch: 5| Step: 7
Training loss: 2.162365436553955
Validation loss: 2.4787739579395582

Epoch: 5| Step: 8
Training loss: 2.0842185020446777
Validation loss: 2.3091086546579995

Epoch: 5| Step: 9
Training loss: 2.083527088165283
Validation loss: 2.3106101277053996

Epoch: 5| Step: 10
Training loss: 2.1408426761627197
Validation loss: 2.2890992395339476

Epoch: 116| Step: 0
Training loss: 2.106781005859375
Validation loss: 2.4329549932992585

Epoch: 5| Step: 1
Training loss: 2.4659512042999268
Validation loss: 2.402723402105352

Epoch: 5| Step: 2
Training loss: 2.6575400829315186
Validation loss: 2.4775033432950258

Epoch: 5| Step: 3
Training loss: 2.0690829753875732
Validation loss: 2.2882306345047487

Epoch: 5| Step: 4
Training loss: 2.5844807624816895
Validation loss: 2.3903769113684215

Epoch: 5| Step: 5
Training loss: 2.260650157928467
Validation loss: 2.375538695243097

Epoch: 5| Step: 6
Training loss: 2.2731895446777344
Validation loss: 2.27891230839555

Epoch: 5| Step: 7
Training loss: 2.109304189682007
Validation loss: 2.3991192758724256

Epoch: 5| Step: 8
Training loss: 3.063307523727417
Validation loss: 2.4824819000818397

Epoch: 5| Step: 9
Training loss: 2.400665760040283
Validation loss: 2.4677886527071715

Epoch: 5| Step: 10
Training loss: 2.302884578704834
Validation loss: 2.4440133161442255

Epoch: 117| Step: 0
Training loss: 2.3360087871551514
Validation loss: 2.296778594293902

Epoch: 5| Step: 1
Training loss: 2.57747220993042
Validation loss: 2.374121058371759

Epoch: 5| Step: 2
Training loss: 2.2443368434906006
Validation loss: 2.4583626639458442

Epoch: 5| Step: 3
Training loss: 3.6160380840301514
Validation loss: 2.453624185695443

Epoch: 5| Step: 4
Training loss: 2.1019864082336426
Validation loss: 2.4340726047433834

Epoch: 5| Step: 5
Training loss: 2.5188395977020264
Validation loss: 2.546979667038046

Epoch: 5| Step: 6
Training loss: 1.742188811302185
Validation loss: 2.381080127531482

Epoch: 5| Step: 7
Training loss: 1.939051628112793
Validation loss: 2.3365361511066394

Epoch: 5| Step: 8
Training loss: 2.12422251701355
Validation loss: 2.4495532487028386

Epoch: 5| Step: 9
Training loss: 1.8919156789779663
Validation loss: 2.4827834329297467

Epoch: 5| Step: 10
Training loss: 2.81428861618042
Validation loss: 2.272143848480717

Epoch: 118| Step: 0
Training loss: 2.4351966381073
Validation loss: 2.402238392060803

Epoch: 5| Step: 1
Training loss: 2.8757736682891846
Validation loss: 2.4222305308106127

Epoch: 5| Step: 2
Training loss: 2.59201717376709
Validation loss: 2.471498904689666

Epoch: 5| Step: 3
Training loss: 1.9893054962158203
Validation loss: 2.3239270179502425

Epoch: 5| Step: 4
Training loss: 2.3091790676116943
Validation loss: 2.3230558236440024

Epoch: 5| Step: 5
Training loss: 2.785130023956299
Validation loss: 2.473410678166215

Epoch: 5| Step: 6
Training loss: 1.8273937702178955
Validation loss: 2.3529995333763862

Epoch: 5| Step: 7
Training loss: 2.2593655586242676
Validation loss: 2.2973707952807025

Epoch: 5| Step: 8
Training loss: 2.3239264488220215
Validation loss: 2.335855427608695

Epoch: 5| Step: 9
Training loss: 2.4103236198425293
Validation loss: 2.391085914386216

Epoch: 5| Step: 10
Training loss: 2.254251718521118
Validation loss: 2.4605337342908307

Epoch: 119| Step: 0
Training loss: 2.650358200073242
Validation loss: 2.3604299637579147

Epoch: 5| Step: 1
Training loss: 1.8627170324325562
Validation loss: 2.3637410081842893

Epoch: 5| Step: 2
Training loss: 1.5944870710372925
Validation loss: 2.436063861334196

Epoch: 5| Step: 3
Training loss: 2.9526209831237793
Validation loss: 2.459295557391259

Epoch: 5| Step: 4
Training loss: 1.9524848461151123
Validation loss: 2.52669027287473

Epoch: 5| Step: 5
Training loss: 2.06986141204834
Validation loss: 2.4176628307629655

Epoch: 5| Step: 6
Training loss: 3.2423787117004395
Validation loss: 2.4013469424299014

Epoch: 5| Step: 7
Training loss: 1.7532036304473877
Validation loss: 2.5092622259611725

Epoch: 5| Step: 8
Training loss: 3.109541654586792
Validation loss: 2.3640985386345976

Epoch: 5| Step: 9
Training loss: 2.027945041656494
Validation loss: 2.4294244499616724

Epoch: 5| Step: 10
Training loss: 2.6579513549804688
Validation loss: 2.4519542929946736

Epoch: 120| Step: 0
Training loss: 2.597287654876709
Validation loss: 2.3795337651365545

Epoch: 5| Step: 1
Training loss: 2.0999388694763184
Validation loss: 2.4787864915786253

Epoch: 5| Step: 2
Training loss: 2.0482540130615234
Validation loss: 2.3595142185047107

Epoch: 5| Step: 3
Training loss: 2.0306239128112793
Validation loss: 2.3272011356969036

Epoch: 5| Step: 4
Training loss: 1.7173521518707275
Validation loss: 2.4485563975508495

Epoch: 5| Step: 5
Training loss: 2.13057017326355
Validation loss: 2.3869873887749127

Epoch: 5| Step: 6
Training loss: 2.624891996383667
Validation loss: 2.4119121002894577

Epoch: 5| Step: 7
Training loss: 2.6672282218933105
Validation loss: 2.370438855181458

Epoch: 5| Step: 8
Training loss: 3.0802018642425537
Validation loss: 2.3340185175659838

Epoch: 5| Step: 9
Training loss: 2.3143367767333984
Validation loss: 2.397692918777466

Epoch: 5| Step: 10
Training loss: 2.2722294330596924
Validation loss: 2.417296753134779

Epoch: 121| Step: 0
Training loss: 1.9915368556976318
Validation loss: 2.3505675767057683

Epoch: 5| Step: 1
Training loss: 2.2117340564727783
Validation loss: 2.3365540658274004

Epoch: 5| Step: 2
Training loss: 2.452040433883667
Validation loss: 2.3372249218725387

Epoch: 5| Step: 3
Training loss: 2.4611363410949707
Validation loss: 2.3356615240855882

Epoch: 5| Step: 4
Training loss: 3.180345296859741
Validation loss: 2.3502117254400767

Epoch: 5| Step: 5
Training loss: 1.9342453479766846
Validation loss: 2.3414212965196177

Epoch: 5| Step: 6
Training loss: 3.083707809448242
Validation loss: 2.3636827597054104

Epoch: 5| Step: 7
Training loss: 1.8590259552001953
Validation loss: 2.44628075117706

Epoch: 5| Step: 8
Training loss: 2.3351094722747803
Validation loss: 2.489653218177057

Epoch: 5| Step: 9
Training loss: 2.3650007247924805
Validation loss: 2.3884508481589695

Epoch: 5| Step: 10
Training loss: 1.9947034120559692
Validation loss: 2.2867353039403118

Epoch: 122| Step: 0
Training loss: 1.7119802236557007
Validation loss: 2.426598997526271

Epoch: 5| Step: 1
Training loss: 2.0587897300720215
Validation loss: 2.388653362950971

Epoch: 5| Step: 2
Training loss: 1.7418289184570312
Validation loss: 2.381601607927712

Epoch: 5| Step: 3
Training loss: 1.7090171575546265
Validation loss: 2.327242543620448

Epoch: 5| Step: 4
Training loss: 2.008953094482422
Validation loss: 2.336078833508235

Epoch: 5| Step: 5
Training loss: 1.8883765935897827
Validation loss: 2.39800678530047

Epoch: 5| Step: 6
Training loss: 2.768242120742798
Validation loss: 2.306886952410462

Epoch: 5| Step: 7
Training loss: 2.7540271282196045
Validation loss: 2.3078085325097524

Epoch: 5| Step: 8
Training loss: 3.318930149078369
Validation loss: 2.2723505676433606

Epoch: 5| Step: 9
Training loss: 2.068657398223877
Validation loss: 2.3688161962775776

Epoch: 5| Step: 10
Training loss: 2.6308202743530273
Validation loss: 2.312474112356863

Epoch: 123| Step: 0
Training loss: 3.3216323852539062
Validation loss: 2.4318361923258793

Epoch: 5| Step: 1
Training loss: 2.310006618499756
Validation loss: 2.3279651082972044

Epoch: 5| Step: 2
Training loss: 2.2882533073425293
Validation loss: 2.426547458094935

Epoch: 5| Step: 3
Training loss: 2.4916021823883057
Validation loss: 2.532300759387273

Epoch: 5| Step: 4
Training loss: 2.1892476081848145
Validation loss: 2.5250316486563733

Epoch: 5| Step: 5
Training loss: 1.75911545753479
Validation loss: 2.380718033800843

Epoch: 5| Step: 6
Training loss: 2.2015395164489746
Validation loss: 2.469525779447248

Epoch: 5| Step: 7
Training loss: 1.7339017391204834
Validation loss: 2.4241330162171395

Epoch: 5| Step: 8
Training loss: 1.8655325174331665
Validation loss: 2.534698014618248

Epoch: 5| Step: 9
Training loss: 2.5265021324157715
Validation loss: 2.3662779536298526

Epoch: 5| Step: 10
Training loss: 2.394287347793579
Validation loss: 2.2983677925602084

Epoch: 124| Step: 0
Training loss: 2.0852203369140625
Validation loss: 2.3524242524177796

Epoch: 5| Step: 1
Training loss: 2.471459150314331
Validation loss: 2.4725525943181847

Epoch: 5| Step: 2
Training loss: 1.9909133911132812
Validation loss: 2.551744007295178

Epoch: 5| Step: 3
Training loss: 1.5583648681640625
Validation loss: 2.543196775579965

Epoch: 5| Step: 4
Training loss: 2.7937674522399902
Validation loss: 2.3421605376787085

Epoch: 5| Step: 5
Training loss: 1.883520483970642
Validation loss: 2.540990032175536

Epoch: 5| Step: 6
Training loss: 2.542863130569458
Validation loss: 2.285655943296289

Epoch: 5| Step: 7
Training loss: 3.073657274246216
Validation loss: 2.4817278308253132

Epoch: 5| Step: 8
Training loss: 3.160407304763794
Validation loss: 2.3445404550080657

Epoch: 5| Step: 9
Training loss: 1.8858600854873657
Validation loss: 2.4504069282162573

Epoch: 5| Step: 10
Training loss: 1.70675790309906
Validation loss: 2.3962607806728733

Epoch: 125| Step: 0
Training loss: 2.115875720977783
Validation loss: 2.4598375904944634

Epoch: 5| Step: 1
Training loss: 2.133781909942627
Validation loss: 2.390419029420422

Epoch: 5| Step: 2
Training loss: 2.0482563972473145
Validation loss: 2.3992719727177776

Epoch: 5| Step: 3
Training loss: 2.1775646209716797
Validation loss: 2.274080909708495

Epoch: 5| Step: 4
Training loss: 1.760000467300415
Validation loss: 2.3319407688674105

Epoch: 5| Step: 5
Training loss: 2.765700578689575
Validation loss: 2.4061711090867237

Epoch: 5| Step: 6
Training loss: 2.911318302154541
Validation loss: 2.4296549956003823

Epoch: 5| Step: 7
Training loss: 2.7974300384521484
Validation loss: 2.3514020391689834

Epoch: 5| Step: 8
Training loss: 2.227405309677124
Validation loss: 2.416622966848394

Epoch: 5| Step: 9
Training loss: 1.6338897943496704
Validation loss: 2.386859850216937

Epoch: 5| Step: 10
Training loss: 2.4729363918304443
Validation loss: 2.310658775350099

Testing loss: 2.405992772844103
