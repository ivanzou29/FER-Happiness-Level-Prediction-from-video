Epoch: 1| Step: 0
Training loss: 3.9997947216033936
Validation loss: 3.789194109619305

Epoch: 5| Step: 1
Training loss: 2.3690733909606934
Validation loss: 3.787700463366765

Epoch: 5| Step: 2
Training loss: 3.5457115173339844
Validation loss: 3.7847823481405936

Epoch: 5| Step: 3
Training loss: 3.5732223987579346
Validation loss: 3.7828114109654583

Epoch: 5| Step: 4
Training loss: 3.7813313007354736
Validation loss: 3.778608860508088

Epoch: 5| Step: 5
Training loss: 4.359623908996582
Validation loss: 3.77439300475582

Epoch: 5| Step: 6
Training loss: 3.9914886951446533
Validation loss: 3.7707493638479583

Epoch: 5| Step: 7
Training loss: 3.9847054481506348
Validation loss: 3.769967791854694

Epoch: 5| Step: 8
Training loss: 3.7409145832061768
Validation loss: 3.7632457005080355

Epoch: 5| Step: 9
Training loss: 3.9192123413085938
Validation loss: 3.7645271311524096

Epoch: 5| Step: 10
Training loss: 2.9422686100006104
Validation loss: 3.76058606947622

Epoch: 2| Step: 0
Training loss: 4.044843673706055
Validation loss: 3.7574352500259236

Epoch: 5| Step: 1
Training loss: 3.608678102493286
Validation loss: 3.7536113287812922

Epoch: 5| Step: 2
Training loss: 3.7114574909210205
Validation loss: 3.7499536339954664

Epoch: 5| Step: 3
Training loss: 3.223963499069214
Validation loss: 3.7477672023157917

Epoch: 5| Step: 4
Training loss: 3.7967045307159424
Validation loss: 3.7431786342333724

Epoch: 5| Step: 5
Training loss: 3.017246961593628
Validation loss: 3.7417798298661427

Epoch: 5| Step: 6
Training loss: 4.105277061462402
Validation loss: 3.7403226052561114

Epoch: 5| Step: 7
Training loss: 2.930588960647583
Validation loss: 3.735759186488326

Epoch: 5| Step: 8
Training loss: 3.905421018600464
Validation loss: 3.733930495477492

Epoch: 5| Step: 9
Training loss: 3.4686176776885986
Validation loss: 3.731741064338274

Epoch: 5| Step: 10
Training loss: 4.328324794769287
Validation loss: 3.7279088086979364

Epoch: 3| Step: 0
Training loss: 4.134295463562012
Validation loss: 3.7236118778105705

Epoch: 5| Step: 1
Training loss: 3.951986312866211
Validation loss: 3.722675056867702

Epoch: 5| Step: 2
Training loss: 2.8718326091766357
Validation loss: 3.7192386504142516

Epoch: 5| Step: 3
Training loss: 3.059882402420044
Validation loss: 3.7148236587483394

Epoch: 5| Step: 4
Training loss: 3.5525126457214355
Validation loss: 3.714920187509188

Epoch: 5| Step: 5
Training loss: 2.8073039054870605
Validation loss: 3.7123582773311163

Epoch: 5| Step: 6
Training loss: 3.593392848968506
Validation loss: 3.7075932282273487

Epoch: 5| Step: 7
Training loss: 4.327675819396973
Validation loss: 3.706513099772956

Epoch: 5| Step: 8
Training loss: 4.146147727966309
Validation loss: 3.704298327046056

Epoch: 5| Step: 9
Training loss: 3.60905385017395
Validation loss: 3.698817273621918

Epoch: 5| Step: 10
Training loss: 3.712604284286499
Validation loss: 3.696889702991773

Epoch: 4| Step: 0
Training loss: 3.2745521068573
Validation loss: 3.6937704547759025

Epoch: 5| Step: 1
Training loss: 4.036993980407715
Validation loss: 3.69278278914831

Epoch: 5| Step: 2
Training loss: 3.7157139778137207
Validation loss: 3.6875293280488703

Epoch: 5| Step: 3
Training loss: 3.589266300201416
Validation loss: 3.6884762343539985

Epoch: 5| Step: 4
Training loss: 3.4965012073516846
Validation loss: 3.681582509830434

Epoch: 5| Step: 5
Training loss: 3.2022883892059326
Validation loss: 3.6816669535893265

Epoch: 5| Step: 6
Training loss: 2.934067964553833
Validation loss: 3.6764110749767673

Epoch: 5| Step: 7
Training loss: 3.4276652336120605
Validation loss: 3.6751502611303843

Epoch: 5| Step: 8
Training loss: 3.395965576171875
Validation loss: 3.6726111545357654

Epoch: 5| Step: 9
Training loss: 3.9480812549591064
Validation loss: 3.6682405266710507

Epoch: 5| Step: 10
Training loss: 4.5806708335876465
Validation loss: 3.6663341522216797

Epoch: 5| Step: 0
Training loss: 3.5169315338134766
Validation loss: 3.6660086647156747

Epoch: 5| Step: 1
Training loss: 3.340684175491333
Validation loss: 3.6589048421511086

Epoch: 5| Step: 2
Training loss: 2.3901045322418213
Validation loss: 3.6580738354754705

Epoch: 5| Step: 3
Training loss: 4.568614959716797
Validation loss: 3.655972844810896

Epoch: 5| Step: 4
Training loss: 4.3551344871521
Validation loss: 3.6513290123272966

Epoch: 5| Step: 5
Training loss: 4.167752742767334
Validation loss: 3.6475756322183917

Epoch: 5| Step: 6
Training loss: 3.4275829792022705
Validation loss: 3.6478357879064416

Epoch: 5| Step: 7
Training loss: 3.1519651412963867
Validation loss: 3.6443806976400395

Epoch: 5| Step: 8
Training loss: 2.9800336360931396
Validation loss: 3.638055952646399

Epoch: 5| Step: 9
Training loss: 4.03792142868042
Validation loss: 3.6357724922959522

Epoch: 5| Step: 10
Training loss: 3.1532695293426514
Validation loss: 3.634474262114494

Epoch: 6| Step: 0
Training loss: 3.5480446815490723
Validation loss: 3.628384533748832

Epoch: 5| Step: 1
Training loss: 3.596322536468506
Validation loss: 3.626280492351901

Epoch: 5| Step: 2
Training loss: 3.267880916595459
Validation loss: 3.6226280607203

Epoch: 5| Step: 3
Training loss: 3.901987075805664
Validation loss: 3.6195441215269026

Epoch: 5| Step: 4
Training loss: 3.367586612701416
Validation loss: 3.615592489960373

Epoch: 5| Step: 5
Training loss: 3.7176411151885986
Validation loss: 3.6123889800040954

Epoch: 5| Step: 6
Training loss: 2.35010027885437
Validation loss: 3.6079799231662544

Epoch: 5| Step: 7
Training loss: 3.0147554874420166
Validation loss: 3.605296793804374

Epoch: 5| Step: 8
Training loss: 4.088980674743652
Validation loss: 3.601622986537154

Epoch: 5| Step: 9
Training loss: 4.013045310974121
Validation loss: 3.596935554217267

Epoch: 5| Step: 10
Training loss: 4.003421783447266
Validation loss: 3.5920403772784817

Epoch: 7| Step: 0
Training loss: 3.8655898571014404
Validation loss: 3.588582859244398

Epoch: 5| Step: 1
Training loss: 3.3107285499572754
Validation loss: 3.5861871011795534

Epoch: 5| Step: 2
Training loss: 3.679750442504883
Validation loss: 3.5809810238499797

Epoch: 5| Step: 3
Training loss: 2.897151231765747
Validation loss: 3.5753500923033683

Epoch: 5| Step: 4
Training loss: 3.623375654220581
Validation loss: 3.5715007602527575

Epoch: 5| Step: 5
Training loss: 2.9649062156677246
Validation loss: 3.5670735810392644

Epoch: 5| Step: 6
Training loss: 3.5988857746124268
Validation loss: 3.565307927388017

Epoch: 5| Step: 7
Training loss: 3.755878448486328
Validation loss: 3.560337902397238

Epoch: 5| Step: 8
Training loss: 3.338460922241211
Validation loss: 3.556402596094275

Epoch: 5| Step: 9
Training loss: 3.93892240524292
Validation loss: 3.5535792048259447

Epoch: 5| Step: 10
Training loss: 3.454440116882324
Validation loss: 3.5481414871831096

Epoch: 8| Step: 0
Training loss: 3.808941602706909
Validation loss: 3.5458700169799147

Epoch: 5| Step: 1
Training loss: 2.9511921405792236
Validation loss: 3.5393025875091553

Epoch: 5| Step: 2
Training loss: 3.5161967277526855
Validation loss: 3.5354332103524158

Epoch: 5| Step: 3
Training loss: 4.340871334075928
Validation loss: 3.5329955982905563

Epoch: 5| Step: 4
Training loss: 4.382211685180664
Validation loss: 3.5262139074264036

Epoch: 5| Step: 5
Training loss: 3.1601433753967285
Validation loss: 3.522536249570949

Epoch: 5| Step: 6
Training loss: 3.2669615745544434
Validation loss: 3.5156544639218237

Epoch: 5| Step: 7
Training loss: 2.4992005825042725
Validation loss: 3.5095135883618425

Epoch: 5| Step: 8
Training loss: 2.709890365600586
Validation loss: 3.5094711960002942

Epoch: 5| Step: 9
Training loss: 3.6647987365722656
Validation loss: 3.501661051986038

Epoch: 5| Step: 10
Training loss: 3.7124974727630615
Validation loss: 3.497220044494957

Epoch: 9| Step: 0
Training loss: 3.354412794113159
Validation loss: 3.494690315697783

Epoch: 5| Step: 1
Training loss: 2.840385913848877
Validation loss: 3.4915853110692834

Epoch: 5| Step: 2
Training loss: 2.998429775238037
Validation loss: 3.4830761699266333

Epoch: 5| Step: 3
Training loss: 3.460601806640625
Validation loss: 3.48026878090315

Epoch: 5| Step: 4
Training loss: 3.5621485710144043
Validation loss: 3.4762880981609388

Epoch: 5| Step: 5
Training loss: 3.310979127883911
Validation loss: 3.471090339845227

Epoch: 5| Step: 6
Training loss: 3.4209747314453125
Validation loss: 3.4641262151861705

Epoch: 5| Step: 7
Training loss: 2.8901000022888184
Validation loss: 3.457948366800944

Epoch: 5| Step: 8
Training loss: 4.066983222961426
Validation loss: 3.452262693835843

Epoch: 5| Step: 9
Training loss: 3.8828582763671875
Validation loss: 3.448395898265223

Epoch: 5| Step: 10
Training loss: 3.706070899963379
Validation loss: 3.441828963577106

Epoch: 10| Step: 0
Training loss: 3.4566218852996826
Validation loss: 3.4349868323213313

Epoch: 5| Step: 1
Training loss: 3.240382671356201
Validation loss: 3.4347117613720637

Epoch: 5| Step: 2
Training loss: 2.6489005088806152
Validation loss: 3.4264884456511466

Epoch: 5| Step: 3
Training loss: 3.5736279487609863
Validation loss: 3.421065302305324

Epoch: 5| Step: 4
Training loss: 4.022693634033203
Validation loss: 3.413876361744378

Epoch: 5| Step: 5
Training loss: 2.907762050628662
Validation loss: 3.4086055601796796

Epoch: 5| Step: 6
Training loss: 2.710278272628784
Validation loss: 3.4007435665335706

Epoch: 5| Step: 7
Training loss: 3.689210891723633
Validation loss: 3.395421387046896

Epoch: 5| Step: 8
Training loss: 3.594788074493408
Validation loss: 3.386268800304782

Epoch: 5| Step: 9
Training loss: 3.3299388885498047
Validation loss: 3.3829617449032363

Epoch: 5| Step: 10
Training loss: 3.781388759613037
Validation loss: 3.3732464210961455

Epoch: 11| Step: 0
Training loss: 4.137114524841309
Validation loss: 3.368857842619701

Epoch: 5| Step: 1
Training loss: 3.5974698066711426
Validation loss: 3.3660455801153697

Epoch: 5| Step: 2
Training loss: 2.519878387451172
Validation loss: 3.359137478695121

Epoch: 5| Step: 3
Training loss: 3.6264312267303467
Validation loss: 3.3514608567760837

Epoch: 5| Step: 4
Training loss: 2.3001697063446045
Validation loss: 3.3445827704603954

Epoch: 5| Step: 5
Training loss: 3.644252300262451
Validation loss: 3.3362590805176766

Epoch: 5| Step: 6
Training loss: 2.8242146968841553
Validation loss: 3.3306590536589264

Epoch: 5| Step: 7
Training loss: 3.769681215286255
Validation loss: 3.321493866623089

Epoch: 5| Step: 8
Training loss: 3.005955219268799
Validation loss: 3.31614883740743

Epoch: 5| Step: 9
Training loss: 3.17421293258667
Validation loss: 3.3061070801109396

Epoch: 5| Step: 10
Training loss: 3.6872425079345703
Validation loss: 3.2999102197667605

Epoch: 12| Step: 0
Training loss: 4.155214309692383
Validation loss: 3.298350359803887

Epoch: 5| Step: 1
Training loss: 2.592473030090332
Validation loss: 3.2846186494314544

Epoch: 5| Step: 2
Training loss: 3.7218213081359863
Validation loss: 3.2808558043613227

Epoch: 5| Step: 3
Training loss: 3.3062217235565186
Validation loss: 3.2729336061785297

Epoch: 5| Step: 4
Training loss: 2.8398938179016113
Validation loss: 3.2640722361944055

Epoch: 5| Step: 5
Training loss: 3.457610607147217
Validation loss: 3.2516890956509497

Epoch: 5| Step: 6
Training loss: 3.1808135509490967
Validation loss: 3.247330763006723

Epoch: 5| Step: 7
Training loss: 3.8026885986328125
Validation loss: 3.2360510492837555

Epoch: 5| Step: 8
Training loss: 2.8126380443573
Validation loss: 3.2317132924192693

Epoch: 5| Step: 9
Training loss: 2.5036354064941406
Validation loss: 3.2207965645738827

Epoch: 5| Step: 10
Training loss: 3.202428102493286
Validation loss: 3.2126062377806632

Epoch: 13| Step: 0
Training loss: 3.799325942993164
Validation loss: 3.2088412725797264

Epoch: 5| Step: 1
Training loss: 3.101254940032959
Validation loss: 3.19974821870045

Epoch: 5| Step: 2
Training loss: 3.228170871734619
Validation loss: 3.1900128933691208

Epoch: 5| Step: 3
Training loss: 2.862154722213745
Validation loss: 3.178468317113897

Epoch: 5| Step: 4
Training loss: 3.0511324405670166
Validation loss: 3.169432350384292

Epoch: 5| Step: 5
Training loss: 2.2052226066589355
Validation loss: 3.1671547120617283

Epoch: 5| Step: 6
Training loss: 3.5145773887634277
Validation loss: 3.159037718208887

Epoch: 5| Step: 7
Training loss: 3.2894606590270996
Validation loss: 3.145236502411545

Epoch: 5| Step: 8
Training loss: 3.2668139934539795
Validation loss: 3.132884276810513

Epoch: 5| Step: 9
Training loss: 2.6263267993927
Validation loss: 3.1266930154574815

Epoch: 5| Step: 10
Training loss: 3.945552110671997
Validation loss: 3.118574337292743

Epoch: 14| Step: 0
Training loss: 3.348562717437744
Validation loss: 3.108148943993353

Epoch: 5| Step: 1
Training loss: 2.93247127532959
Validation loss: 3.100217109085411

Epoch: 5| Step: 2
Training loss: 2.6862235069274902
Validation loss: 3.0902971426645913

Epoch: 5| Step: 3
Training loss: 2.374440908432007
Validation loss: 3.0775309685737855

Epoch: 5| Step: 4
Training loss: 2.8326241970062256
Validation loss: 3.0669361109374673

Epoch: 5| Step: 5
Training loss: 4.533699035644531
Validation loss: 3.0583418928166872

Epoch: 5| Step: 6
Training loss: 3.457714080810547
Validation loss: 3.047802917418941

Epoch: 5| Step: 7
Training loss: 2.9434916973114014
Validation loss: 3.0362327073210027

Epoch: 5| Step: 8
Training loss: 2.897141218185425
Validation loss: 3.0245511890739523

Epoch: 5| Step: 9
Training loss: 3.161273956298828
Validation loss: 3.019573829507315

Epoch: 5| Step: 10
Training loss: 2.733313798904419
Validation loss: 3.00878418132823

Epoch: 15| Step: 0
Training loss: 2.9152278900146484
Validation loss: 2.997688260129703

Epoch: 5| Step: 1
Training loss: 3.6588339805603027
Validation loss: 2.9905694684674664

Epoch: 5| Step: 2
Training loss: 3.567277431488037
Validation loss: 2.985314884493428

Epoch: 5| Step: 3
Training loss: 2.75612211227417
Validation loss: 2.969615638896983

Epoch: 5| Step: 4
Training loss: 2.2990710735321045
Validation loss: 2.9586812706403833

Epoch: 5| Step: 5
Training loss: 2.281130075454712
Validation loss: 2.945338503006966

Epoch: 5| Step: 6
Training loss: 3.3609936237335205
Validation loss: 2.946380405015843

Epoch: 5| Step: 7
Training loss: 2.857565402984619
Validation loss: 2.933225670168477

Epoch: 5| Step: 8
Training loss: 3.3794703483581543
Validation loss: 2.923165600786927

Epoch: 5| Step: 9
Training loss: 3.2415378093719482
Validation loss: 2.913681330219392

Epoch: 5| Step: 10
Training loss: 2.7660274505615234
Validation loss: 2.9056991172093216

Epoch: 16| Step: 0
Training loss: 3.6270720958709717
Validation loss: 2.8961921532948813

Epoch: 5| Step: 1
Training loss: 3.0265018939971924
Validation loss: 2.8761070184810187

Epoch: 5| Step: 2
Training loss: 4.127439498901367
Validation loss: 2.877640462690784

Epoch: 5| Step: 3
Training loss: 2.605135202407837
Validation loss: 2.863771782126478

Epoch: 5| Step: 4
Training loss: 2.3478803634643555
Validation loss: 2.849696292672106

Epoch: 5| Step: 5
Training loss: 2.235638380050659
Validation loss: 2.830758140933129

Epoch: 5| Step: 6
Training loss: 3.0784010887145996
Validation loss: 2.827198913020472

Epoch: 5| Step: 7
Training loss: 2.757718324661255
Validation loss: 2.8132183218515046

Epoch: 5| Step: 8
Training loss: 2.9177701473236084
Validation loss: 2.806602742082329

Epoch: 5| Step: 9
Training loss: 2.0972251892089844
Validation loss: 2.7976794806859826

Epoch: 5| Step: 10
Training loss: 3.471121311187744
Validation loss: 2.7851770667619604

Epoch: 17| Step: 0
Training loss: 2.490220546722412
Validation loss: 2.7722804674538235

Epoch: 5| Step: 1
Training loss: 3.137725353240967
Validation loss: 2.7544873760592554

Epoch: 5| Step: 2
Training loss: 3.077977180480957
Validation loss: 2.7493036203486945

Epoch: 5| Step: 3
Training loss: 2.1092369556427
Validation loss: 2.7374395606338338

Epoch: 5| Step: 4
Training loss: 2.9233510494232178
Validation loss: 2.7250332601608767

Epoch: 5| Step: 5
Training loss: 2.4248058795928955
Validation loss: 2.706467156769127

Epoch: 5| Step: 6
Training loss: 2.8205161094665527
Validation loss: 2.7011436467529624

Epoch: 5| Step: 7
Training loss: 2.959512233734131
Validation loss: 2.6840989230781473

Epoch: 5| Step: 8
Training loss: 3.899850845336914
Validation loss: 2.6785553706589567

Epoch: 5| Step: 9
Training loss: 2.852692127227783
Validation loss: 2.6662512594653713

Epoch: 5| Step: 10
Training loss: 2.655012369155884
Validation loss: 2.6535168578547816

Epoch: 18| Step: 0
Training loss: 3.250835418701172
Validation loss: 2.641574182818013

Epoch: 5| Step: 1
Training loss: 3.313973903656006
Validation loss: 2.628248865886401

Epoch: 5| Step: 2
Training loss: 3.3850395679473877
Validation loss: 2.6097292284811697

Epoch: 5| Step: 3
Training loss: 2.6905839443206787
Validation loss: 2.606678355124689

Epoch: 5| Step: 4
Training loss: 2.561028242111206
Validation loss: 2.580503217635616

Epoch: 5| Step: 5
Training loss: 1.8114436864852905
Validation loss: 2.5712096332221903

Epoch: 5| Step: 6
Training loss: 2.981985569000244
Validation loss: 2.5501956119332263

Epoch: 5| Step: 7
Training loss: 2.3892698287963867
Validation loss: 2.550348553606259

Epoch: 5| Step: 8
Training loss: 2.724061965942383
Validation loss: 2.523347426486272

Epoch: 5| Step: 9
Training loss: 2.6308956146240234
Validation loss: 2.517962988986764

Epoch: 5| Step: 10
Training loss: 2.93149733543396
Validation loss: 2.5111253030838503

Epoch: 19| Step: 0
Training loss: 2.926445722579956
Validation loss: 2.4974152990566787

Epoch: 5| Step: 1
Training loss: 3.339909791946411
Validation loss: 2.4775759481614634

Epoch: 5| Step: 2
Training loss: 2.530825138092041
Validation loss: 2.462179168578117

Epoch: 5| Step: 3
Training loss: 2.641995906829834
Validation loss: 2.4580598954231507

Epoch: 5| Step: 4
Training loss: 2.473179817199707
Validation loss: 2.4378686079414944

Epoch: 5| Step: 5
Training loss: 2.589998960494995
Validation loss: 2.430881997590424

Epoch: 5| Step: 6
Training loss: 2.3421595096588135
Validation loss: 2.414073169872325

Epoch: 5| Step: 7
Training loss: 2.6293118000030518
Validation loss: 2.419857443019908

Epoch: 5| Step: 8
Training loss: 2.2492892742156982
Validation loss: 2.3984854785344933

Epoch: 5| Step: 9
Training loss: 2.8294737339019775
Validation loss: 2.397233478484615

Epoch: 5| Step: 10
Training loss: 3.233281373977661
Validation loss: 2.398176852092948

Epoch: 20| Step: 0
Training loss: 2.542865753173828
Validation loss: 2.363320735193068

Epoch: 5| Step: 1
Training loss: 3.1100075244903564
Validation loss: 2.3580423298702446

Epoch: 5| Step: 2
Training loss: 2.352519989013672
Validation loss: 2.3561050507330124

Epoch: 5| Step: 3
Training loss: 1.9325577020645142
Validation loss: 2.3482703137141403

Epoch: 5| Step: 4
Training loss: 2.6068825721740723
Validation loss: 2.348848100631468

Epoch: 5| Step: 5
Training loss: 3.138030529022217
Validation loss: 2.3295115360649685

Epoch: 5| Step: 6
Training loss: 2.2088305950164795
Validation loss: 2.324430757953275

Epoch: 5| Step: 7
Training loss: 2.513280153274536
Validation loss: 2.3206347265551166

Epoch: 5| Step: 8
Training loss: 2.531233072280884
Validation loss: 2.3150036181173017

Epoch: 5| Step: 9
Training loss: 2.737586498260498
Validation loss: 2.309450431536603

Epoch: 5| Step: 10
Training loss: 3.258983612060547
Validation loss: 2.301149929723432

Epoch: 21| Step: 0
Training loss: 2.3788890838623047
Validation loss: 2.2906278371810913

Epoch: 5| Step: 1
Training loss: 2.5905327796936035
Validation loss: 2.2787079939278225

Epoch: 5| Step: 2
Training loss: 2.609123468399048
Validation loss: 2.2796740096102477

Epoch: 5| Step: 3
Training loss: 2.795529842376709
Validation loss: 2.2634073124136975

Epoch: 5| Step: 4
Training loss: 2.2853775024414062
Validation loss: 2.2547310859926286

Epoch: 5| Step: 5
Training loss: 2.29998517036438
Validation loss: 2.261147009429111

Epoch: 5| Step: 6
Training loss: 2.604719877243042
Validation loss: 2.2479787782956193

Epoch: 5| Step: 7
Training loss: 2.9720754623413086
Validation loss: 2.240042976153794

Epoch: 5| Step: 8
Training loss: 2.481966733932495
Validation loss: 2.236237943813365

Epoch: 5| Step: 9
Training loss: 2.289893865585327
Validation loss: 2.212321568560857

Epoch: 5| Step: 10
Training loss: 2.8810322284698486
Validation loss: 2.219768580570016

Epoch: 22| Step: 0
Training loss: 2.503793716430664
Validation loss: 2.202839748833769

Epoch: 5| Step: 1
Training loss: 3.0803401470184326
Validation loss: 2.1971868981597242

Epoch: 5| Step: 2
Training loss: 2.313591718673706
Validation loss: 2.188115187870559

Epoch: 5| Step: 3
Training loss: 2.5271048545837402
Validation loss: 2.1818978504468034

Epoch: 5| Step: 4
Training loss: 2.63134765625
Validation loss: 2.18989315853324

Epoch: 5| Step: 5
Training loss: 2.8042490482330322
Validation loss: 2.1687385279645204

Epoch: 5| Step: 6
Training loss: 1.6566970348358154
Validation loss: 2.1635266119433987

Epoch: 5| Step: 7
Training loss: 2.4191365242004395
Validation loss: 2.1448898546157347

Epoch: 5| Step: 8
Training loss: 2.6764097213745117
Validation loss: 2.1451677353151384

Epoch: 5| Step: 9
Training loss: 2.4956207275390625
Validation loss: 2.143626674529045

Epoch: 5| Step: 10
Training loss: 2.6449697017669678
Validation loss: 2.1494853304278467

Epoch: 23| Step: 0
Training loss: 3.0517373085021973
Validation loss: 2.1318925978035055

Epoch: 5| Step: 1
Training loss: 2.5501835346221924
Validation loss: 2.129021727910606

Epoch: 5| Step: 2
Training loss: 2.7240536212921143
Validation loss: 2.1146906601485385

Epoch: 5| Step: 3
Training loss: 2.2896759510040283
Validation loss: 2.114663600921631

Epoch: 5| Step: 4
Training loss: 1.864882469177246
Validation loss: 2.1174863410252396

Epoch: 5| Step: 5
Training loss: 2.354360580444336
Validation loss: 2.1104613158010666

Epoch: 5| Step: 6
Training loss: 2.2758736610412598
Validation loss: 2.106780534149498

Epoch: 5| Step: 7
Training loss: 3.1830945014953613
Validation loss: 2.0994601506058888

Epoch: 5| Step: 8
Training loss: 2.4817519187927246
Validation loss: 2.112332518382739

Epoch: 5| Step: 9
Training loss: 2.424431324005127
Validation loss: 2.098992968118319

Epoch: 5| Step: 10
Training loss: 2.159466505050659
Validation loss: 2.092445570935485

Epoch: 24| Step: 0
Training loss: 1.9820983409881592
Validation loss: 2.0886702178626932

Epoch: 5| Step: 1
Training loss: 2.5731489658355713
Validation loss: 2.0910052958355156

Epoch: 5| Step: 2
Training loss: 2.684929370880127
Validation loss: 2.0820019168238484

Epoch: 5| Step: 3
Training loss: 2.659832239151001
Validation loss: 2.094873579599524

Epoch: 5| Step: 4
Training loss: 2.922760009765625
Validation loss: 2.0976136397289973

Epoch: 5| Step: 5
Training loss: 2.713132381439209
Validation loss: 2.0824348311270438

Epoch: 5| Step: 6
Training loss: 1.9306501150131226
Validation loss: 2.069554026408862

Epoch: 5| Step: 7
Training loss: 2.514725923538208
Validation loss: 2.0797828551261657

Epoch: 5| Step: 8
Training loss: 2.4990241527557373
Validation loss: 2.0759834602314937

Epoch: 5| Step: 9
Training loss: 2.4013590812683105
Validation loss: 2.0906401821362075

Epoch: 5| Step: 10
Training loss: 2.3789031505584717
Validation loss: 2.077884130580451

Epoch: 25| Step: 0
Training loss: 2.629316806793213
Validation loss: 2.0773424666414977

Epoch: 5| Step: 1
Training loss: 2.1776504516601562
Validation loss: 2.091027849464006

Epoch: 5| Step: 2
Training loss: 2.522714614868164
Validation loss: 2.0646476489241405

Epoch: 5| Step: 3
Training loss: 2.469282627105713
Validation loss: 2.0639626620918192

Epoch: 5| Step: 4
Training loss: 2.390763998031616
Validation loss: 2.0576412447037233

Epoch: 5| Step: 5
Training loss: 1.8237006664276123
Validation loss: 2.072558437624285

Epoch: 5| Step: 6
Training loss: 2.7696239948272705
Validation loss: 2.0789611595933155

Epoch: 5| Step: 7
Training loss: 3.257672071456909
Validation loss: 2.0680388199385775

Epoch: 5| Step: 8
Training loss: 2.3472723960876465
Validation loss: 2.0766120315879903

Epoch: 5| Step: 9
Training loss: 2.0071330070495605
Validation loss: 2.088459127692766

Epoch: 5| Step: 10
Training loss: 3.022486448287964
Validation loss: 2.0788594650965866

Epoch: 26| Step: 0
Training loss: 2.5420749187469482
Validation loss: 2.0680005037656395

Epoch: 5| Step: 1
Training loss: 2.0432283878326416
Validation loss: 2.0739864226310485

Epoch: 5| Step: 2
Training loss: 2.428327798843384
Validation loss: 2.0702766526129937

Epoch: 5| Step: 3
Training loss: 2.8477237224578857
Validation loss: 2.0735491206569057

Epoch: 5| Step: 4
Training loss: 2.8904035091400146
Validation loss: 2.0749611675098376

Epoch: 5| Step: 5
Training loss: 2.278219699859619
Validation loss: 2.056544578203591

Epoch: 5| Step: 6
Training loss: 2.7377119064331055
Validation loss: 2.0623922630022933

Epoch: 5| Step: 7
Training loss: 2.2092597484588623
Validation loss: 2.07144005580615

Epoch: 5| Step: 8
Training loss: 2.2314138412475586
Validation loss: 2.066084784846152

Epoch: 5| Step: 9
Training loss: 2.637363910675049
Validation loss: 2.048590149930728

Epoch: 5| Step: 10
Training loss: 2.2972381114959717
Validation loss: 2.080815674156271

Epoch: 27| Step: 0
Training loss: 2.27586030960083
Validation loss: 2.076874657343793

Epoch: 5| Step: 1
Training loss: 2.5069668292999268
Validation loss: 2.078419780218473

Epoch: 5| Step: 2
Training loss: 2.2602696418762207
Validation loss: 2.064102554834017

Epoch: 5| Step: 3
Training loss: 2.4574012756347656
Validation loss: 2.0791838476734776

Epoch: 5| Step: 4
Training loss: 2.7521567344665527
Validation loss: 2.0621796782298754

Epoch: 5| Step: 5
Training loss: 2.380794048309326
Validation loss: 2.0662105109101985

Epoch: 5| Step: 6
Training loss: 2.9177653789520264
Validation loss: 2.0731009091100385

Epoch: 5| Step: 7
Training loss: 2.470689058303833
Validation loss: 2.0706402281279206

Epoch: 5| Step: 8
Training loss: 2.133849620819092
Validation loss: 2.083963624892696

Epoch: 5| Step: 9
Training loss: 2.167670726776123
Validation loss: 2.088230235602266

Epoch: 5| Step: 10
Training loss: 2.7022593021392822
Validation loss: 2.065340759933636

Epoch: 28| Step: 0
Training loss: 2.6492486000061035
Validation loss: 2.0601961356337353

Epoch: 5| Step: 1
Training loss: 2.458415985107422
Validation loss: 2.075328834595219

Epoch: 5| Step: 2
Training loss: 1.999315857887268
Validation loss: 2.093606097723848

Epoch: 5| Step: 3
Training loss: 1.7452690601348877
Validation loss: 2.0792337361202446

Epoch: 5| Step: 4
Training loss: 2.4276747703552246
Validation loss: 2.089069862519541

Epoch: 5| Step: 5
Training loss: 2.6386680603027344
Validation loss: 2.078876828634611

Epoch: 5| Step: 6
Training loss: 2.8885087966918945
Validation loss: 2.074942606751637

Epoch: 5| Step: 7
Training loss: 2.2739641666412354
Validation loss: 2.0853797338342153

Epoch: 5| Step: 8
Training loss: 2.779378652572632
Validation loss: 2.083253611800491

Epoch: 5| Step: 9
Training loss: 2.815884828567505
Validation loss: 2.067555535224176

Epoch: 5| Step: 10
Training loss: 2.5216732025146484
Validation loss: 2.0681283384241085

Epoch: 29| Step: 0
Training loss: 2.8987936973571777
Validation loss: 2.071417866214629

Epoch: 5| Step: 1
Training loss: 1.8911933898925781
Validation loss: 2.079393850859775

Epoch: 5| Step: 2
Training loss: 2.6616992950439453
Validation loss: 2.0720504996597127

Epoch: 5| Step: 3
Training loss: 2.1398417949676514
Validation loss: 2.055463344820084

Epoch: 5| Step: 4
Training loss: 2.580704927444458
Validation loss: 2.078879439702598

Epoch: 5| Step: 5
Training loss: 2.3203139305114746
Validation loss: 2.067356123719164

Epoch: 5| Step: 6
Training loss: 2.6590147018432617
Validation loss: 2.078010174535936

Epoch: 5| Step: 7
Training loss: 2.260467767715454
Validation loss: 2.0776704203697944

Epoch: 5| Step: 8
Training loss: 2.5790717601776123
Validation loss: 2.0735292409055974

Epoch: 5| Step: 9
Training loss: 2.4078965187072754
Validation loss: 2.069180942350818

Epoch: 5| Step: 10
Training loss: 2.6105659008026123
Validation loss: 2.0837809116609636

Epoch: 30| Step: 0
Training loss: 1.792863130569458
Validation loss: 2.0672467472732707

Epoch: 5| Step: 1
Training loss: 2.98714017868042
Validation loss: 2.067552972865361

Epoch: 5| Step: 2
Training loss: 2.544180393218994
Validation loss: 2.0732977826108216

Epoch: 5| Step: 3
Training loss: 2.3507626056671143
Validation loss: 2.059649964814545

Epoch: 5| Step: 4
Training loss: 2.1838784217834473
Validation loss: 2.0750159396920154

Epoch: 5| Step: 5
Training loss: 2.175518751144409
Validation loss: 2.066555300066548

Epoch: 5| Step: 6
Training loss: 2.646152973175049
Validation loss: 2.071306441419868

Epoch: 5| Step: 7
Training loss: 2.755922794342041
Validation loss: 2.071533223634125

Epoch: 5| Step: 8
Training loss: 2.5648245811462402
Validation loss: 2.0546273826270975

Epoch: 5| Step: 9
Training loss: 2.3176000118255615
Validation loss: 2.0603309010946624

Epoch: 5| Step: 10
Training loss: 2.7952382564544678
Validation loss: 2.0652693830510622

Epoch: 31| Step: 0
Training loss: 2.1697521209716797
Validation loss: 2.070148491090344

Epoch: 5| Step: 1
Training loss: 2.636941432952881
Validation loss: 2.0561691240597795

Epoch: 5| Step: 2
Training loss: 2.6021480560302734
Validation loss: 2.077552985119563

Epoch: 5| Step: 3
Training loss: 2.2634806632995605
Validation loss: 2.0626210038379957

Epoch: 5| Step: 4
Training loss: 2.0032410621643066
Validation loss: 2.073471273145368

Epoch: 5| Step: 5
Training loss: 2.478898525238037
Validation loss: 2.069727341334025

Epoch: 5| Step: 6
Training loss: 2.747344493865967
Validation loss: 2.0790944701881817

Epoch: 5| Step: 7
Training loss: 2.9477806091308594
Validation loss: 2.0547873358572684

Epoch: 5| Step: 8
Training loss: 2.4592432975769043
Validation loss: 2.074673020711509

Epoch: 5| Step: 9
Training loss: 2.317134141921997
Validation loss: 2.068166968643024

Epoch: 5| Step: 10
Training loss: 2.295130729675293
Validation loss: 2.0633226568980882

Epoch: 32| Step: 0
Training loss: 2.6157877445220947
Validation loss: 2.0758993318003993

Epoch: 5| Step: 1
Training loss: 3.0463647842407227
Validation loss: 2.0586675033774426

Epoch: 5| Step: 2
Training loss: 3.091346025466919
Validation loss: 2.0699631373087564

Epoch: 5| Step: 3
Training loss: 2.2497992515563965
Validation loss: 2.064485312789999

Epoch: 5| Step: 4
Training loss: 2.2679190635681152
Validation loss: 2.0618487199147544

Epoch: 5| Step: 5
Training loss: 1.776365041732788
Validation loss: 2.061845285918123

Epoch: 5| Step: 6
Training loss: 2.0986692905426025
Validation loss: 2.0649077764121433

Epoch: 5| Step: 7
Training loss: 1.886762261390686
Validation loss: 2.0612947146097818

Epoch: 5| Step: 8
Training loss: 2.8122427463531494
Validation loss: 2.06122870983616

Epoch: 5| Step: 9
Training loss: 2.686215877532959
Validation loss: 2.049081992077571

Epoch: 5| Step: 10
Training loss: 2.426816940307617
Validation loss: 2.053607251054497

Epoch: 33| Step: 0
Training loss: 2.3364779949188232
Validation loss: 2.0747390613761

Epoch: 5| Step: 1
Training loss: 2.495443820953369
Validation loss: 2.054188947523794

Epoch: 5| Step: 2
Training loss: 2.6763436794281006
Validation loss: 2.057577763834307

Epoch: 5| Step: 3
Training loss: 2.207282543182373
Validation loss: 2.0563551020878617

Epoch: 5| Step: 4
Training loss: 2.1647868156433105
Validation loss: 2.053873477443572

Epoch: 5| Step: 5
Training loss: 2.9447903633117676
Validation loss: 2.0570827171366703

Epoch: 5| Step: 6
Training loss: 2.4725232124328613
Validation loss: 2.055247376042028

Epoch: 5| Step: 7
Training loss: 1.6386315822601318
Validation loss: 2.065438852515272

Epoch: 5| Step: 8
Training loss: 2.3163890838623047
Validation loss: 2.043417017946961

Epoch: 5| Step: 9
Training loss: 3.1013426780700684
Validation loss: 2.045777085006878

Epoch: 5| Step: 10
Training loss: 2.5485544204711914
Validation loss: 2.0426764693311465

Epoch: 34| Step: 0
Training loss: 3.091312885284424
Validation loss: 2.0569705347861014

Epoch: 5| Step: 1
Training loss: 2.2615742683410645
Validation loss: 2.05519272435096

Epoch: 5| Step: 2
Training loss: 1.444409966468811
Validation loss: 2.057386267569757

Epoch: 5| Step: 3
Training loss: 2.7322890758514404
Validation loss: 2.0532103546204103

Epoch: 5| Step: 4
Training loss: 2.346217632293701
Validation loss: 2.069051731017328

Epoch: 5| Step: 5
Training loss: 2.347425937652588
Validation loss: 2.049281853501515

Epoch: 5| Step: 6
Training loss: 2.3588531017303467
Validation loss: 2.057964094223515

Epoch: 5| Step: 7
Training loss: 2.5005645751953125
Validation loss: 2.050817055086936

Epoch: 5| Step: 8
Training loss: 2.6121973991394043
Validation loss: 2.0665716304573962

Epoch: 5| Step: 9
Training loss: 2.8163886070251465
Validation loss: 2.0452434414176532

Epoch: 5| Step: 10
Training loss: 2.150785446166992
Validation loss: 2.085154797441216

Epoch: 35| Step: 0
Training loss: 2.8140158653259277
Validation loss: 2.0647775973043134

Epoch: 5| Step: 1
Training loss: 2.454045057296753
Validation loss: 2.055896407814436

Epoch: 5| Step: 2
Training loss: 2.0169284343719482
Validation loss: 2.0535424370919504

Epoch: 5| Step: 3
Training loss: 3.162691116333008
Validation loss: 2.0555789650127454

Epoch: 5| Step: 4
Training loss: 2.332237958908081
Validation loss: 2.0563825766245523

Epoch: 5| Step: 5
Training loss: 1.8722584247589111
Validation loss: 2.068503531076575

Epoch: 5| Step: 6
Training loss: 2.1034369468688965
Validation loss: 2.0609927331247637

Epoch: 5| Step: 7
Training loss: 3.134154796600342
Validation loss: 2.038256396529495

Epoch: 5| Step: 8
Training loss: 2.607215166091919
Validation loss: 2.0495533430448143

Epoch: 5| Step: 9
Training loss: 2.062617540359497
Validation loss: 2.0478568717997563

Epoch: 5| Step: 10
Training loss: 2.069606304168701
Validation loss: 2.0472306205380346

Epoch: 36| Step: 0
Training loss: 2.5730793476104736
Validation loss: 2.0368571307069514

Epoch: 5| Step: 1
Training loss: 2.6058144569396973
Validation loss: 2.047089660039512

Epoch: 5| Step: 2
Training loss: 2.5389370918273926
Validation loss: 2.051117786797144

Epoch: 5| Step: 3
Training loss: 2.1442668437957764
Validation loss: 2.0310919002820085

Epoch: 5| Step: 4
Training loss: 2.538980007171631
Validation loss: 2.0496979964676725

Epoch: 5| Step: 5
Training loss: 2.8609204292297363
Validation loss: 2.036563863036453

Epoch: 5| Step: 6
Training loss: 2.0995595455169678
Validation loss: 2.0406690284770024

Epoch: 5| Step: 7
Training loss: 1.907300353050232
Validation loss: 2.035995057834092

Epoch: 5| Step: 8
Training loss: 2.032339572906494
Validation loss: 2.04456078749831

Epoch: 5| Step: 9
Training loss: 2.888390064239502
Validation loss: 2.0374122383773967

Epoch: 5| Step: 10
Training loss: 2.5550715923309326
Validation loss: 2.0380196020167363

Epoch: 37| Step: 0
Training loss: 1.8641321659088135
Validation loss: 2.046434853666572

Epoch: 5| Step: 1
Training loss: 2.4179389476776123
Validation loss: 2.042845461958198

Epoch: 5| Step: 2
Training loss: 2.4404683113098145
Validation loss: 2.028164158585251

Epoch: 5| Step: 3
Training loss: 2.519935131072998
Validation loss: 2.0502908922010854

Epoch: 5| Step: 4
Training loss: 2.6713757514953613
Validation loss: 2.032973712490451

Epoch: 5| Step: 5
Training loss: 2.649336338043213
Validation loss: 2.0504944273220596

Epoch: 5| Step: 6
Training loss: 1.8797639608383179
Validation loss: 2.046769516442412

Epoch: 5| Step: 7
Training loss: 2.032531261444092
Validation loss: 2.052388842387866

Epoch: 5| Step: 8
Training loss: 2.651709794998169
Validation loss: 2.0527049905510357

Epoch: 5| Step: 9
Training loss: 3.0721065998077393
Validation loss: 2.0431209725718342

Epoch: 5| Step: 10
Training loss: 2.4740846157073975
Validation loss: 2.0370895747215516

Epoch: 38| Step: 0
Training loss: 2.9238438606262207
Validation loss: 2.0445725199996785

Epoch: 5| Step: 1
Training loss: 2.716472625732422
Validation loss: 2.034673701050461

Epoch: 5| Step: 2
Training loss: 2.7332539558410645
Validation loss: 2.0464684258225145

Epoch: 5| Step: 3
Training loss: 2.028308391571045
Validation loss: 2.046443247026013

Epoch: 5| Step: 4
Training loss: 2.245952606201172
Validation loss: 2.049909932639009

Epoch: 5| Step: 5
Training loss: 1.9604661464691162
Validation loss: 2.0419698325536584

Epoch: 5| Step: 6
Training loss: 2.2329132556915283
Validation loss: 2.0450520925624396

Epoch: 5| Step: 7
Training loss: 2.214987277984619
Validation loss: 2.0395121689765685

Epoch: 5| Step: 8
Training loss: 2.6637396812438965
Validation loss: 2.0324660308899416

Epoch: 5| Step: 9
Training loss: 2.5243172645568848
Validation loss: 2.0375569994731615

Epoch: 5| Step: 10
Training loss: 2.353212356567383
Validation loss: 2.028334891924294

Epoch: 39| Step: 0
Training loss: 2.227632999420166
Validation loss: 2.0254628401930614

Epoch: 5| Step: 1
Training loss: 2.837671995162964
Validation loss: 2.0347131080524896

Epoch: 5| Step: 2
Training loss: 2.822643756866455
Validation loss: 2.0266204418674594

Epoch: 5| Step: 3
Training loss: 1.965136170387268
Validation loss: 2.039193771218741

Epoch: 5| Step: 4
Training loss: 2.5875720977783203
Validation loss: 2.020473293078843

Epoch: 5| Step: 5
Training loss: 2.1830224990844727
Validation loss: 2.0290197621109667

Epoch: 5| Step: 6
Training loss: 2.6792845726013184
Validation loss: 2.0469419456297353

Epoch: 5| Step: 7
Training loss: 2.478482723236084
Validation loss: 2.0462635088992376

Epoch: 5| Step: 8
Training loss: 2.013759136199951
Validation loss: 2.041167652735146

Epoch: 5| Step: 9
Training loss: 2.5624663829803467
Validation loss: 2.0220703950492283

Epoch: 5| Step: 10
Training loss: 2.0963878631591797
Validation loss: 2.026967151190645

Epoch: 40| Step: 0
Training loss: 2.7202134132385254
Validation loss: 2.0313871342648744

Epoch: 5| Step: 1
Training loss: 2.298635482788086
Validation loss: 2.024855923909013

Epoch: 5| Step: 2
Training loss: 2.13299298286438
Validation loss: 2.046863255962249

Epoch: 5| Step: 3
Training loss: 2.3220887184143066
Validation loss: 2.028311011611774

Epoch: 5| Step: 4
Training loss: 2.105146646499634
Validation loss: 2.0360769302614274

Epoch: 5| Step: 5
Training loss: 2.9443399906158447
Validation loss: 2.043036930022701

Epoch: 5| Step: 6
Training loss: 2.3247220516204834
Validation loss: 2.034051437531748

Epoch: 5| Step: 7
Training loss: 2.45398211479187
Validation loss: 2.0375640905031593

Epoch: 5| Step: 8
Training loss: 1.7734947204589844
Validation loss: 2.0450110422667636

Epoch: 5| Step: 9
Training loss: 2.768315076828003
Validation loss: 2.0413694689350743

Epoch: 5| Step: 10
Training loss: 2.720212936401367
Validation loss: 2.0615153107591855

Epoch: 41| Step: 0
Training loss: 2.4546141624450684
Validation loss: 2.0405927370953303

Epoch: 5| Step: 1
Training loss: 2.236090660095215
Validation loss: 2.0331736380054104

Epoch: 5| Step: 2
Training loss: 2.939667224884033
Validation loss: 2.0498648100001837

Epoch: 5| Step: 3
Training loss: 2.2706828117370605
Validation loss: 2.030286249294076

Epoch: 5| Step: 4
Training loss: 2.2784693241119385
Validation loss: 2.0452349262852825

Epoch: 5| Step: 5
Training loss: 2.3130288124084473
Validation loss: 2.036765101135418

Epoch: 5| Step: 6
Training loss: 2.035405158996582
Validation loss: 2.0415089438038487

Epoch: 5| Step: 7
Training loss: 2.6773478984832764
Validation loss: 2.0458098573069416

Epoch: 5| Step: 8
Training loss: 2.1108274459838867
Validation loss: 2.043347615067677

Epoch: 5| Step: 9
Training loss: 2.8179538249969482
Validation loss: 2.0437851746877036

Epoch: 5| Step: 10
Training loss: 2.3202695846557617
Validation loss: 2.054436832345942

Epoch: 42| Step: 0
Training loss: 2.7051162719726562
Validation loss: 2.0375781712993497

Epoch: 5| Step: 1
Training loss: 2.390200138092041
Validation loss: 2.0489234642315934

Epoch: 5| Step: 2
Training loss: 2.4154510498046875
Validation loss: 2.041232289806489

Epoch: 5| Step: 3
Training loss: 2.899432420730591
Validation loss: 2.0318432930977113

Epoch: 5| Step: 4
Training loss: 1.8879520893096924
Validation loss: 2.045458862858434

Epoch: 5| Step: 5
Training loss: 2.9832959175109863
Validation loss: 2.041143718586173

Epoch: 5| Step: 6
Training loss: 2.084179162979126
Validation loss: 2.0491122866189606

Epoch: 5| Step: 7
Training loss: 1.627035140991211
Validation loss: 2.0421207899688394

Epoch: 5| Step: 8
Training loss: 2.6695995330810547
Validation loss: 2.0306470163406862

Epoch: 5| Step: 9
Training loss: 2.448322296142578
Validation loss: 2.042027496522473

Epoch: 5| Step: 10
Training loss: 2.255854845046997
Validation loss: 2.038745959599813

Epoch: 43| Step: 0
Training loss: 2.342437505722046
Validation loss: 2.03589097146065

Epoch: 5| Step: 1
Training loss: 2.266613245010376
Validation loss: 2.0349544940456266

Epoch: 5| Step: 2
Training loss: 2.5056042671203613
Validation loss: 2.0360882794985207

Epoch: 5| Step: 3
Training loss: 2.421335220336914
Validation loss: 2.0169730186462402

Epoch: 5| Step: 4
Training loss: 2.261551856994629
Validation loss: 2.03328844552399

Epoch: 5| Step: 5
Training loss: 2.3098654747009277
Validation loss: 2.0355406576587307

Epoch: 5| Step: 6
Training loss: 2.700429916381836
Validation loss: 2.0339845585566696

Epoch: 5| Step: 7
Training loss: 2.674997329711914
Validation loss: 2.039760080716943

Epoch: 5| Step: 8
Training loss: 2.6425576210021973
Validation loss: 2.0194957794681674

Epoch: 5| Step: 9
Training loss: 1.9748144149780273
Validation loss: 2.0096468848566853

Epoch: 5| Step: 10
Training loss: 2.1888551712036133
Validation loss: 2.03801336467907

Epoch: 44| Step: 0
Training loss: 1.9631401300430298
Validation loss: 2.0223811826398297

Epoch: 5| Step: 1
Training loss: 1.818777084350586
Validation loss: 2.0311287654343473

Epoch: 5| Step: 2
Training loss: 2.8203911781311035
Validation loss: 2.015288755457888

Epoch: 5| Step: 3
Training loss: 2.2490365505218506
Validation loss: 2.0234921260546614

Epoch: 5| Step: 4
Training loss: 2.635746479034424
Validation loss: 2.020562074517691

Epoch: 5| Step: 5
Training loss: 3.4122397899627686
Validation loss: 2.029187801063702

Epoch: 5| Step: 6
Training loss: 1.7351782321929932
Validation loss: 2.014427511922775

Epoch: 5| Step: 7
Training loss: 2.3345589637756348
Validation loss: 2.0043283188214867

Epoch: 5| Step: 8
Training loss: 2.943676233291626
Validation loss: 2.0193647594862085

Epoch: 5| Step: 9
Training loss: 2.182551383972168
Validation loss: 2.000444059730858

Epoch: 5| Step: 10
Training loss: 2.1862008571624756
Validation loss: 2.009927334324006

Epoch: 45| Step: 0
Training loss: 1.749508261680603
Validation loss: 2.0212021438024377

Epoch: 5| Step: 1
Training loss: 2.2820382118225098
Validation loss: 2.0117838485266573

Epoch: 5| Step: 2
Training loss: 2.7575557231903076
Validation loss: 1.990235577347458

Epoch: 5| Step: 3
Training loss: 2.5654220581054688
Validation loss: 2.022026482448783

Epoch: 5| Step: 4
Training loss: 2.2056326866149902
Validation loss: 2.011869110086913

Epoch: 5| Step: 5
Training loss: 2.375458002090454
Validation loss: 1.9950574572368334

Epoch: 5| Step: 6
Training loss: 2.5806117057800293
Validation loss: 2.0005112283973285

Epoch: 5| Step: 7
Training loss: 2.3666064739227295
Validation loss: 2.019067182335802

Epoch: 5| Step: 8
Training loss: 2.0808041095733643
Validation loss: 1.990447763473757

Epoch: 5| Step: 9
Training loss: 2.0738444328308105
Validation loss: 2.0124891470837336

Epoch: 5| Step: 10
Training loss: 3.398656129837036
Validation loss: 2.0026477383029078

Epoch: 46| Step: 0
Training loss: 2.7964820861816406
Validation loss: 2.012969357993013

Epoch: 5| Step: 1
Training loss: 2.4920356273651123
Validation loss: 2.0167949199676514

Epoch: 5| Step: 2
Training loss: 2.411792755126953
Validation loss: 1.9918075274395686

Epoch: 5| Step: 3
Training loss: 2.358154773712158
Validation loss: 1.9943824352756623

Epoch: 5| Step: 4
Training loss: 2.061918020248413
Validation loss: 2.0029549111602125

Epoch: 5| Step: 5
Training loss: 3.0900232791900635
Validation loss: 2.002928644098261

Epoch: 5| Step: 6
Training loss: 2.0782253742218018
Validation loss: 2.006864547729492

Epoch: 5| Step: 7
Training loss: 2.2939093112945557
Validation loss: 1.9978481185051702

Epoch: 5| Step: 8
Training loss: 2.5191450119018555
Validation loss: 2.0201340849681566

Epoch: 5| Step: 9
Training loss: 2.023606300354004
Validation loss: 2.0054198080493557

Epoch: 5| Step: 10
Training loss: 2.1423661708831787
Validation loss: 2.0203057758269773

Epoch: 47| Step: 0
Training loss: 2.3892576694488525
Validation loss: 2.0101749461184264

Epoch: 5| Step: 1
Training loss: 1.8386485576629639
Validation loss: 2.0119518080065326

Epoch: 5| Step: 2
Training loss: 2.111253023147583
Validation loss: 2.005020033928656

Epoch: 5| Step: 3
Training loss: 2.5986154079437256
Validation loss: 2.0141039638109106

Epoch: 5| Step: 4
Training loss: 1.9814647436141968
Validation loss: 2.0112883480646278

Epoch: 5| Step: 5
Training loss: 2.544827938079834
Validation loss: 2.030478295459542

Epoch: 5| Step: 6
Training loss: 2.4274537563323975
Validation loss: 2.0063878772079304

Epoch: 5| Step: 7
Training loss: 2.576590061187744
Validation loss: 2.0285549715001094

Epoch: 5| Step: 8
Training loss: 2.667971611022949
Validation loss: 2.005971299704685

Epoch: 5| Step: 9
Training loss: 2.7424991130828857
Validation loss: 2.0405519623910227

Epoch: 5| Step: 10
Training loss: 2.251300573348999
Validation loss: 2.0225720456851426

Epoch: 48| Step: 0
Training loss: 2.2062814235687256
Validation loss: 2.02448445750821

Epoch: 5| Step: 1
Training loss: 1.9626182317733765
Validation loss: 2.0183877406581754

Epoch: 5| Step: 2
Training loss: 1.959246277809143
Validation loss: 2.004896171631352

Epoch: 5| Step: 3
Training loss: 2.6954562664031982
Validation loss: 2.025599597602762

Epoch: 5| Step: 4
Training loss: 2.351039171218872
Validation loss: 2.0203046029613865

Epoch: 5| Step: 5
Training loss: 2.808253049850464
Validation loss: 2.0216801602353334

Epoch: 5| Step: 6
Training loss: 2.4296650886535645
Validation loss: 2.004186855849399

Epoch: 5| Step: 7
Training loss: 2.9319026470184326
Validation loss: 2.0151467759122133

Epoch: 5| Step: 8
Training loss: 1.9835809469223022
Validation loss: 2.028435658383113

Epoch: 5| Step: 9
Training loss: 2.6171181201934814
Validation loss: 2.042861073247848

Epoch: 5| Step: 10
Training loss: 2.177170753479004
Validation loss: 2.0203303778043358

Epoch: 49| Step: 0
Training loss: 2.111361026763916
Validation loss: 2.0268415058812788

Epoch: 5| Step: 1
Training loss: 2.0303244590759277
Validation loss: 1.99796853398764

Epoch: 5| Step: 2
Training loss: 1.8654731512069702
Validation loss: 2.0151082085024927

Epoch: 5| Step: 3
Training loss: 1.986943006515503
Validation loss: 2.013889366580594

Epoch: 5| Step: 4
Training loss: 2.3785860538482666
Validation loss: 1.9966578739945606

Epoch: 5| Step: 5
Training loss: 2.3662915229797363
Validation loss: 2.018128013098112

Epoch: 5| Step: 6
Training loss: 2.62235951423645
Validation loss: 2.03331264885523

Epoch: 5| Step: 7
Training loss: 2.591474771499634
Validation loss: 2.0151046501692904

Epoch: 5| Step: 8
Training loss: 2.6868538856506348
Validation loss: 2.0153773869237592

Epoch: 5| Step: 9
Training loss: 3.013575792312622
Validation loss: 2.003497854355843

Epoch: 5| Step: 10
Training loss: 2.4243338108062744
Validation loss: 2.009542675428493

Epoch: 50| Step: 0
Training loss: 2.4507479667663574
Validation loss: 2.0065455334160918

Epoch: 5| Step: 1
Training loss: 2.399463415145874
Validation loss: 2.004896471577306

Epoch: 5| Step: 2
Training loss: 2.0200228691101074
Validation loss: 2.0071724640425814

Epoch: 5| Step: 3
Training loss: 2.1628987789154053
Validation loss: 1.9995687956451087

Epoch: 5| Step: 4
Training loss: 2.633596897125244
Validation loss: 2.01466227346851

Epoch: 5| Step: 5
Training loss: 1.9695796966552734
Validation loss: 2.012268058715328

Epoch: 5| Step: 6
Training loss: 2.6589736938476562
Validation loss: 2.0123108535684566

Epoch: 5| Step: 7
Training loss: 2.5097434520721436
Validation loss: 2.0004309223544214

Epoch: 5| Step: 8
Training loss: 2.30464506149292
Validation loss: 1.9948630409855996

Epoch: 5| Step: 9
Training loss: 1.9917576313018799
Validation loss: 2.002775752416221

Epoch: 5| Step: 10
Training loss: 3.014723062515259
Validation loss: 1.9971310297648113

Epoch: 51| Step: 0
Training loss: 2.167327642440796
Validation loss: 2.0031432977286716

Epoch: 5| Step: 1
Training loss: 2.453916072845459
Validation loss: 2.0214679971818

Epoch: 5| Step: 2
Training loss: 2.416050434112549
Validation loss: 2.0143087166611866

Epoch: 5| Step: 3
Training loss: 2.751488208770752
Validation loss: 1.9949043168816516

Epoch: 5| Step: 4
Training loss: 2.0520436763763428
Validation loss: 2.0038102749855287

Epoch: 5| Step: 5
Training loss: 2.5142695903778076
Validation loss: 2.015227879247358

Epoch: 5| Step: 6
Training loss: 2.0888466835021973
Validation loss: 2.007302520095661

Epoch: 5| Step: 7
Training loss: 2.5472943782806396
Validation loss: 2.0032254495928363

Epoch: 5| Step: 8
Training loss: 2.2092325687408447
Validation loss: 2.0009594489169378

Epoch: 5| Step: 9
Training loss: 2.3354833126068115
Validation loss: 2.0215402521112913

Epoch: 5| Step: 10
Training loss: 2.364997148513794
Validation loss: 2.021871752636407

Epoch: 52| Step: 0
Training loss: 2.4337399005889893
Validation loss: 2.0047497480146346

Epoch: 5| Step: 1
Training loss: 2.2394680976867676
Validation loss: 2.0028807168365805

Epoch: 5| Step: 2
Training loss: 1.9933154582977295
Validation loss: 2.0062116474233647

Epoch: 5| Step: 3
Training loss: 2.4090800285339355
Validation loss: 2.0164603341010308

Epoch: 5| Step: 4
Training loss: 3.2375900745391846
Validation loss: 2.0144666574334584

Epoch: 5| Step: 5
Training loss: 2.7731471061706543
Validation loss: 2.0322573723331576

Epoch: 5| Step: 6
Training loss: 1.8300071954727173
Validation loss: 2.0127589189878075

Epoch: 5| Step: 7
Training loss: 1.963968276977539
Validation loss: 2.005320954066451

Epoch: 5| Step: 8
Training loss: 2.332007884979248
Validation loss: 1.9986536067019227

Epoch: 5| Step: 9
Training loss: 2.2630081176757812
Validation loss: 2.0144575283091557

Epoch: 5| Step: 10
Training loss: 2.442474126815796
Validation loss: 2.0119197342985418

Epoch: 53| Step: 0
Training loss: 1.8857616186141968
Validation loss: 2.0224490768165997

Epoch: 5| Step: 1
Training loss: 2.2245185375213623
Validation loss: 2.0125473263443157

Epoch: 5| Step: 2
Training loss: 2.127232313156128
Validation loss: 2.0127207002332135

Epoch: 5| Step: 3
Training loss: 3.0267484188079834
Validation loss: 2.0121110587991695

Epoch: 5| Step: 4
Training loss: 2.4489779472351074
Validation loss: 2.0193548663969962

Epoch: 5| Step: 5
Training loss: 2.614534854888916
Validation loss: 2.011526842271128

Epoch: 5| Step: 6
Training loss: 2.210862636566162
Validation loss: 2.016801908452024

Epoch: 5| Step: 7
Training loss: 2.608485460281372
Validation loss: 2.008751110364032

Epoch: 5| Step: 8
Training loss: 1.7357666492462158
Validation loss: 1.9983026481443835

Epoch: 5| Step: 9
Training loss: 2.081009864807129
Validation loss: 2.008270909709315

Epoch: 5| Step: 10
Training loss: 2.906911611557007
Validation loss: 2.0107377190743723

Epoch: 54| Step: 0
Training loss: 1.7439963817596436
Validation loss: 2.0258937138383106

Epoch: 5| Step: 1
Training loss: 2.4955105781555176
Validation loss: 2.0019391608494583

Epoch: 5| Step: 2
Training loss: 2.5394623279571533
Validation loss: 2.005647531119726

Epoch: 5| Step: 3
Training loss: 2.101003646850586
Validation loss: 2.001232304880696

Epoch: 5| Step: 4
Training loss: 2.418304920196533
Validation loss: 2.018765114968823

Epoch: 5| Step: 5
Training loss: 2.4801502227783203
Validation loss: 2.019758225769125

Epoch: 5| Step: 6
Training loss: 2.4781954288482666
Validation loss: 1.9982940868664814

Epoch: 5| Step: 7
Training loss: 2.2027955055236816
Validation loss: 2.005568955534248

Epoch: 5| Step: 8
Training loss: 2.2690086364746094
Validation loss: 2.002870948083939

Epoch: 5| Step: 9
Training loss: 2.5760786533355713
Validation loss: 2.0020437676419496

Epoch: 5| Step: 10
Training loss: 2.4361956119537354
Validation loss: 2.0117966974935224

Epoch: 55| Step: 0
Training loss: 2.627358913421631
Validation loss: 2.011331376209054

Epoch: 5| Step: 1
Training loss: 2.1906230449676514
Validation loss: 1.9940765250113703

Epoch: 5| Step: 2
Training loss: 2.5589842796325684
Validation loss: 2.0168868444299184

Epoch: 5| Step: 3
Training loss: 3.0100061893463135
Validation loss: 2.0086917056832263

Epoch: 5| Step: 4
Training loss: 1.9126694202423096
Validation loss: 2.0191315745794647

Epoch: 5| Step: 5
Training loss: 2.1744086742401123
Validation loss: 1.9998052274027178

Epoch: 5| Step: 6
Training loss: 2.4083456993103027
Validation loss: 2.0038031044826714

Epoch: 5| Step: 7
Training loss: 2.1769886016845703
Validation loss: 1.9975244076021257

Epoch: 5| Step: 8
Training loss: 1.9561961889266968
Validation loss: 1.9973007030384515

Epoch: 5| Step: 9
Training loss: 2.5743777751922607
Validation loss: 2.015424968093954

Epoch: 5| Step: 10
Training loss: 2.2943787574768066
Validation loss: 2.0082040281705957

Epoch: 56| Step: 0
Training loss: 2.7103323936462402
Validation loss: 2.006253734711678

Epoch: 5| Step: 1
Training loss: 2.4513821601867676
Validation loss: 2.007920193415816

Epoch: 5| Step: 2
Training loss: 1.9487009048461914
Validation loss: 2.011258481651224

Epoch: 5| Step: 3
Training loss: 2.6747705936431885
Validation loss: 2.004556331583249

Epoch: 5| Step: 4
Training loss: 2.2683494091033936
Validation loss: 2.005993316250463

Epoch: 5| Step: 5
Training loss: 1.4195752143859863
Validation loss: 1.9945075409386748

Epoch: 5| Step: 6
Training loss: 2.794020414352417
Validation loss: 2.003361014909642

Epoch: 5| Step: 7
Training loss: 2.49200177192688
Validation loss: 2.005031677984422

Epoch: 5| Step: 8
Training loss: 2.5629947185516357
Validation loss: 2.006671296652927

Epoch: 5| Step: 9
Training loss: 2.286207914352417
Validation loss: 1.990696858334285

Epoch: 5| Step: 10
Training loss: 2.0507185459136963
Validation loss: 2.0005734043736614

Epoch: 57| Step: 0
Training loss: 2.088937282562256
Validation loss: 1.9852909657262987

Epoch: 5| Step: 1
Training loss: 1.903045415878296
Validation loss: 2.011588533719381

Epoch: 5| Step: 2
Training loss: 2.3313145637512207
Validation loss: 2.0035223550693964

Epoch: 5| Step: 3
Training loss: 2.32637357711792
Validation loss: 1.9967253054341962

Epoch: 5| Step: 4
Training loss: 2.248823642730713
Validation loss: 1.9996572130469865

Epoch: 5| Step: 5
Training loss: 2.1747848987579346
Validation loss: 1.998680208318977

Epoch: 5| Step: 6
Training loss: 3.070307493209839
Validation loss: 1.9839947274936143

Epoch: 5| Step: 7
Training loss: 1.8229068517684937
Validation loss: 1.993532274359016

Epoch: 5| Step: 8
Training loss: 2.576267719268799
Validation loss: 1.9873061000659902

Epoch: 5| Step: 9
Training loss: 2.4077625274658203
Validation loss: 2.000441958827357

Epoch: 5| Step: 10
Training loss: 2.8959920406341553
Validation loss: 1.991341665226926

Epoch: 58| Step: 0
Training loss: 1.945966362953186
Validation loss: 1.9702666600545247

Epoch: 5| Step: 1
Training loss: 2.584587812423706
Validation loss: 1.9828386499035744

Epoch: 5| Step: 2
Training loss: 1.7866332530975342
Validation loss: 1.9788761908008206

Epoch: 5| Step: 3
Training loss: 3.0796749591827393
Validation loss: 1.9729950069099345

Epoch: 5| Step: 4
Training loss: 2.8421688079833984
Validation loss: 1.9977210503752514

Epoch: 5| Step: 5
Training loss: 2.068258285522461
Validation loss: 1.99955484303095

Epoch: 5| Step: 6
Training loss: 2.0932016372680664
Validation loss: 2.0044653723316808

Epoch: 5| Step: 7
Training loss: 1.9626579284667969
Validation loss: 2.0005517762194396

Epoch: 5| Step: 8
Training loss: 2.388885498046875
Validation loss: 2.007964095120789

Epoch: 5| Step: 9
Training loss: 2.5803215503692627
Validation loss: 2.0059943763158654

Epoch: 5| Step: 10
Training loss: 2.277428388595581
Validation loss: 2.009429277912263

Epoch: 59| Step: 0
Training loss: 2.2234573364257812
Validation loss: 2.0012240499578495

Epoch: 5| Step: 1
Training loss: 2.204860210418701
Validation loss: 1.9955983110653457

Epoch: 5| Step: 2
Training loss: 2.39042592048645
Validation loss: 1.9979494130739601

Epoch: 5| Step: 3
Training loss: 2.2334742546081543
Validation loss: 1.9931698614551174

Epoch: 5| Step: 4
Training loss: 2.216230630874634
Validation loss: 2.004053605500088

Epoch: 5| Step: 5
Training loss: 2.837894916534424
Validation loss: 2.0042034567043348

Epoch: 5| Step: 6
Training loss: 2.607795000076294
Validation loss: 2.0072757403055825

Epoch: 5| Step: 7
Training loss: 1.685715675354004
Validation loss: 1.9929685656742384

Epoch: 5| Step: 8
Training loss: 2.2382771968841553
Validation loss: 1.999780329324866

Epoch: 5| Step: 9
Training loss: 2.7338223457336426
Validation loss: 1.9891220087646155

Epoch: 5| Step: 10
Training loss: 2.058126211166382
Validation loss: 1.9644198571482012

Epoch: 60| Step: 0
Training loss: 1.6378482580184937
Validation loss: 2.0014745599480084

Epoch: 5| Step: 1
Training loss: 2.4616754055023193
Validation loss: 1.9786174476787608

Epoch: 5| Step: 2
Training loss: 2.428811550140381
Validation loss: 1.9755341058136315

Epoch: 5| Step: 3
Training loss: 2.323188543319702
Validation loss: 1.987947863917197

Epoch: 5| Step: 4
Training loss: 2.9729342460632324
Validation loss: 1.972281402157199

Epoch: 5| Step: 5
Training loss: 1.9276511669158936
Validation loss: 2.012082561369865

Epoch: 5| Step: 6
Training loss: 2.4843688011169434
Validation loss: 1.9807871234032415

Epoch: 5| Step: 7
Training loss: 2.2160158157348633
Validation loss: 1.995647204819546

Epoch: 5| Step: 8
Training loss: 2.2454285621643066
Validation loss: 2.001830752177905

Epoch: 5| Step: 9
Training loss: 2.6947779655456543
Validation loss: 1.9959101574395293

Epoch: 5| Step: 10
Training loss: 2.2745556831359863
Validation loss: 1.9823672515089794

Epoch: 61| Step: 0
Training loss: 2.595017910003662
Validation loss: 1.9886330763498943

Epoch: 5| Step: 1
Training loss: 1.4296607971191406
Validation loss: 1.9823474012395388

Epoch: 5| Step: 2
Training loss: 2.6658661365509033
Validation loss: 1.9800078381774247

Epoch: 5| Step: 3
Training loss: 2.5285661220550537
Validation loss: 1.969493869812258

Epoch: 5| Step: 4
Training loss: 1.7133127450942993
Validation loss: 1.9847024435638099

Epoch: 5| Step: 5
Training loss: 2.5611815452575684
Validation loss: 1.9855544515835342

Epoch: 5| Step: 6
Training loss: 2.5527567863464355
Validation loss: 1.9883631916456326

Epoch: 5| Step: 7
Training loss: 2.3272616863250732
Validation loss: 1.957789227526675

Epoch: 5| Step: 8
Training loss: 2.9098377227783203
Validation loss: 1.9839976231257122

Epoch: 5| Step: 9
Training loss: 1.9703195095062256
Validation loss: 1.9751900972858552

Epoch: 5| Step: 10
Training loss: 2.1614902019500732
Validation loss: 1.972064015685871

Epoch: 62| Step: 0
Training loss: 2.2646543979644775
Validation loss: 1.9673262052638556

Epoch: 5| Step: 1
Training loss: 2.322300672531128
Validation loss: 1.9690632307401268

Epoch: 5| Step: 2
Training loss: 1.952615737915039
Validation loss: 1.950048832483189

Epoch: 5| Step: 3
Training loss: 2.4540698528289795
Validation loss: 1.959442227117477

Epoch: 5| Step: 4
Training loss: 2.0007379055023193
Validation loss: 1.9857361034680439

Epoch: 5| Step: 5
Training loss: 2.5956037044525146
Validation loss: 1.9813677226343462

Epoch: 5| Step: 6
Training loss: 2.5439565181732178
Validation loss: 1.9727801763883202

Epoch: 5| Step: 7
Training loss: 2.332587242126465
Validation loss: 1.978604233393105

Epoch: 5| Step: 8
Training loss: 2.223522663116455
Validation loss: 1.9625464126627932

Epoch: 5| Step: 9
Training loss: 2.16534423828125
Validation loss: 1.979774300770093

Epoch: 5| Step: 10
Training loss: 2.5799286365509033
Validation loss: 1.9767770151938162

Epoch: 63| Step: 0
Training loss: 1.621683120727539
Validation loss: 1.9647700094407605

Epoch: 5| Step: 1
Training loss: 2.5406782627105713
Validation loss: 1.9673522915891422

Epoch: 5| Step: 2
Training loss: 2.3355679512023926
Validation loss: 1.9682630774795369

Epoch: 5| Step: 3
Training loss: 2.039721965789795
Validation loss: 1.980674224515115

Epoch: 5| Step: 4
Training loss: 2.4282257556915283
Validation loss: 1.9560610632742605

Epoch: 5| Step: 5
Training loss: 2.564598560333252
Validation loss: 1.981605165748186

Epoch: 5| Step: 6
Training loss: 2.3261423110961914
Validation loss: 1.9693942249462169

Epoch: 5| Step: 7
Training loss: 2.509190082550049
Validation loss: 1.9608731462109474

Epoch: 5| Step: 8
Training loss: 1.9469438791275024
Validation loss: 1.9614245981298468

Epoch: 5| Step: 9
Training loss: 2.8525447845458984
Validation loss: 1.9852119594491937

Epoch: 5| Step: 10
Training loss: 2.2772316932678223
Validation loss: 1.977599710546514

Epoch: 64| Step: 0
Training loss: 2.1441617012023926
Validation loss: 1.9764970246181692

Epoch: 5| Step: 1
Training loss: 1.858446478843689
Validation loss: 1.9803917177261845

Epoch: 5| Step: 2
Training loss: 1.9675010442733765
Validation loss: 1.9670828593674528

Epoch: 5| Step: 3
Training loss: 2.8938913345336914
Validation loss: 1.9842107513899445

Epoch: 5| Step: 4
Training loss: 2.15238618850708
Validation loss: 1.9877340101426648

Epoch: 5| Step: 5
Training loss: 2.2320079803466797
Validation loss: 1.9799167891984344

Epoch: 5| Step: 6
Training loss: 2.765559673309326
Validation loss: 1.981349898922828

Epoch: 5| Step: 7
Training loss: 2.391162157058716
Validation loss: 1.9887390880174534

Epoch: 5| Step: 8
Training loss: 2.5384631156921387
Validation loss: 2.000636472496935

Epoch: 5| Step: 9
Training loss: 2.0315306186676025
Validation loss: 1.9806698201805033

Epoch: 5| Step: 10
Training loss: 2.4925780296325684
Validation loss: 2.003650132045951

Epoch: 65| Step: 0
Training loss: 2.758986234664917
Validation loss: 1.9886739189906786

Epoch: 5| Step: 1
Training loss: 2.535545825958252
Validation loss: 1.9863517028029247

Epoch: 5| Step: 2
Training loss: 2.13075590133667
Validation loss: 1.9759218897870792

Epoch: 5| Step: 3
Training loss: 2.618683099746704
Validation loss: 1.965744549228299

Epoch: 5| Step: 4
Training loss: 1.971085548400879
Validation loss: 1.9931459734516759

Epoch: 5| Step: 5
Training loss: 2.2900803089141846
Validation loss: 1.9783103722397999

Epoch: 5| Step: 6
Training loss: 2.14107084274292
Validation loss: 1.976651245547879

Epoch: 5| Step: 7
Training loss: 2.939516544342041
Validation loss: 1.9733365222971926

Epoch: 5| Step: 8
Training loss: 2.1448521614074707
Validation loss: 1.9763407963578419

Epoch: 5| Step: 9
Training loss: 2.1132328510284424
Validation loss: 1.966861496689499

Epoch: 5| Step: 10
Training loss: 1.4646610021591187
Validation loss: 1.9792108176856913

Epoch: 66| Step: 0
Training loss: 1.973544716835022
Validation loss: 1.9817844898469987

Epoch: 5| Step: 1
Training loss: 2.8380255699157715
Validation loss: 1.970704851611968

Epoch: 5| Step: 2
Training loss: 2.129633665084839
Validation loss: 1.9688769309751448

Epoch: 5| Step: 3
Training loss: 2.567610025405884
Validation loss: 1.9686961033010995

Epoch: 5| Step: 4
Training loss: 1.7865664958953857
Validation loss: 1.9825978996933147

Epoch: 5| Step: 5
Training loss: 2.8115718364715576
Validation loss: 1.9707825491505284

Epoch: 5| Step: 6
Training loss: 1.9180113077163696
Validation loss: 1.9812151924256356

Epoch: 5| Step: 7
Training loss: 1.8758138418197632
Validation loss: 1.9887059298894738

Epoch: 5| Step: 8
Training loss: 2.4674277305603027
Validation loss: 1.9797076358590076

Epoch: 5| Step: 9
Training loss: 2.2439827919006348
Validation loss: 1.9716134186713927

Epoch: 5| Step: 10
Training loss: 2.569415330886841
Validation loss: 1.9685631926341722

Epoch: 67| Step: 0
Training loss: 2.089228391647339
Validation loss: 1.9712125069351607

Epoch: 5| Step: 1
Training loss: 1.9152015447616577
Validation loss: 1.9797108557916456

Epoch: 5| Step: 2
Training loss: 1.9531863927841187
Validation loss: 1.9845773404644382

Epoch: 5| Step: 3
Training loss: 2.2657344341278076
Validation loss: 1.972192184899443

Epoch: 5| Step: 4
Training loss: 2.7551705837249756
Validation loss: 1.9736365900244763

Epoch: 5| Step: 5
Training loss: 2.6522417068481445
Validation loss: 1.9775912069505261

Epoch: 5| Step: 6
Training loss: 2.0952441692352295
Validation loss: 1.9859550383783156

Epoch: 5| Step: 7
Training loss: 1.9093008041381836
Validation loss: 1.985069667139361

Epoch: 5| Step: 8
Training loss: 2.0283572673797607
Validation loss: 1.9749730838242399

Epoch: 5| Step: 9
Training loss: 2.5863537788391113
Validation loss: 1.9669067949377081

Epoch: 5| Step: 10
Training loss: 2.8733367919921875
Validation loss: 1.9721380895183933

Epoch: 68| Step: 0
Training loss: 1.982282042503357
Validation loss: 1.9748945492570118

Epoch: 5| Step: 1
Training loss: 1.6776161193847656
Validation loss: 1.9614646383511123

Epoch: 5| Step: 2
Training loss: 2.1554391384124756
Validation loss: 1.9725714960405905

Epoch: 5| Step: 3
Training loss: 3.145373821258545
Validation loss: 1.9696754806785173

Epoch: 5| Step: 4
Training loss: 2.0052990913391113
Validation loss: 1.9720911697674823

Epoch: 5| Step: 5
Training loss: 1.7835443019866943
Validation loss: 1.9715788377228605

Epoch: 5| Step: 6
Training loss: 2.2378151416778564
Validation loss: 1.9694342254310526

Epoch: 5| Step: 7
Training loss: 2.7314884662628174
Validation loss: 1.9717447360356648

Epoch: 5| Step: 8
Training loss: 2.285555601119995
Validation loss: 1.9862321038399973

Epoch: 5| Step: 9
Training loss: 2.2815897464752197
Validation loss: 1.9755331572665964

Epoch: 5| Step: 10
Training loss: 2.9918925762176514
Validation loss: 1.9786736567815144

Epoch: 69| Step: 0
Training loss: 2.7060534954071045
Validation loss: 1.9629545057973554

Epoch: 5| Step: 1
Training loss: 2.221653461456299
Validation loss: 1.9713018735249836

Epoch: 5| Step: 2
Training loss: 2.3826656341552734
Validation loss: 1.9682645310637772

Epoch: 5| Step: 3
Training loss: 2.098020076751709
Validation loss: 1.9935001583509548

Epoch: 5| Step: 4
Training loss: 2.056431531906128
Validation loss: 1.9975470573671403

Epoch: 5| Step: 5
Training loss: 1.9845151901245117
Validation loss: 2.006841557000273

Epoch: 5| Step: 6
Training loss: 2.52170991897583
Validation loss: 1.9940955549158075

Epoch: 5| Step: 7
Training loss: 2.322866439819336
Validation loss: 1.9851835696927962

Epoch: 5| Step: 8
Training loss: 2.060450792312622
Validation loss: 1.976570806195659

Epoch: 5| Step: 9
Training loss: 2.220726490020752
Validation loss: 1.9912875134457824

Epoch: 5| Step: 10
Training loss: 2.399770498275757
Validation loss: 1.9914232787265573

Epoch: 70| Step: 0
Training loss: 1.9143264293670654
Validation loss: 1.990558374312616

Epoch: 5| Step: 1
Training loss: 2.1353139877319336
Validation loss: 1.9675346882112565

Epoch: 5| Step: 2
Training loss: 2.0219249725341797
Validation loss: 1.9619939686149679

Epoch: 5| Step: 3
Training loss: 2.4480488300323486
Validation loss: 1.9784368417596305

Epoch: 5| Step: 4
Training loss: 1.9462509155273438
Validation loss: 1.981126126422677

Epoch: 5| Step: 5
Training loss: 2.309338331222534
Validation loss: 1.957662933616228

Epoch: 5| Step: 6
Training loss: 2.2570371627807617
Validation loss: 1.9595251621738556

Epoch: 5| Step: 7
Training loss: 2.9776885509490967
Validation loss: 1.9869694889232676

Epoch: 5| Step: 8
Training loss: 2.7958736419677734
Validation loss: 1.9683181778077157

Epoch: 5| Step: 9
Training loss: 1.9000036716461182
Validation loss: 1.9742233509658484

Epoch: 5| Step: 10
Training loss: 2.352846145629883
Validation loss: 1.9601969629205682

Epoch: 71| Step: 0
Training loss: 1.9679672718048096
Validation loss: 1.9577658509695401

Epoch: 5| Step: 1
Training loss: 2.2456562519073486
Validation loss: 1.9654348665668118

Epoch: 5| Step: 2
Training loss: 1.835458755493164
Validation loss: 1.9750363493478427

Epoch: 5| Step: 3
Training loss: 1.897439956665039
Validation loss: 1.9626727232369043

Epoch: 5| Step: 4
Training loss: 2.169132947921753
Validation loss: 1.9732075019549298

Epoch: 5| Step: 5
Training loss: 2.4756381511688232
Validation loss: 1.975334161071367

Epoch: 5| Step: 6
Training loss: 2.3274099826812744
Validation loss: 1.9572303692499797

Epoch: 5| Step: 7
Training loss: 2.1445865631103516
Validation loss: 1.9518960650249193

Epoch: 5| Step: 8
Training loss: 3.005408525466919
Validation loss: 1.9541843437379407

Epoch: 5| Step: 9
Training loss: 2.446859836578369
Validation loss: 1.937480802177101

Epoch: 5| Step: 10
Training loss: 2.4610767364501953
Validation loss: 1.9488674235600296

Epoch: 72| Step: 0
Training loss: 1.68645441532135
Validation loss: 1.9657822578184065

Epoch: 5| Step: 1
Training loss: 2.190924882888794
Validation loss: 1.9624978111636253

Epoch: 5| Step: 2
Training loss: 2.047226667404175
Validation loss: 1.9477250717019523

Epoch: 5| Step: 3
Training loss: 2.994600534439087
Validation loss: 1.957457116855088

Epoch: 5| Step: 4
Training loss: 2.2476601600646973
Validation loss: 1.9586794607100948

Epoch: 5| Step: 5
Training loss: 2.536583662033081
Validation loss: 1.9816935780227825

Epoch: 5| Step: 6
Training loss: 2.5496554374694824
Validation loss: 1.988347686747069

Epoch: 5| Step: 7
Training loss: 2.0678024291992188
Validation loss: 1.9776574283517816

Epoch: 5| Step: 8
Training loss: 2.1824100017547607
Validation loss: 1.9891882916932464

Epoch: 5| Step: 9
Training loss: 2.4137086868286133
Validation loss: 1.9746679311157556

Epoch: 5| Step: 10
Training loss: 1.990399956703186
Validation loss: 1.9569834842476794

Epoch: 73| Step: 0
Training loss: 2.470407485961914
Validation loss: 1.9704880996416974

Epoch: 5| Step: 1
Training loss: 2.3785340785980225
Validation loss: 1.9762896619817263

Epoch: 5| Step: 2
Training loss: 2.9744019508361816
Validation loss: 1.9702816445340392

Epoch: 5| Step: 3
Training loss: 1.442286729812622
Validation loss: 1.9779198823436615

Epoch: 5| Step: 4
Training loss: 2.6193318367004395
Validation loss: 1.9692049539217384

Epoch: 5| Step: 5
Training loss: 2.3151841163635254
Validation loss: 1.990756937252578

Epoch: 5| Step: 6
Training loss: 1.581639051437378
Validation loss: 1.9797065065753074

Epoch: 5| Step: 7
Training loss: 2.4698233604431152
Validation loss: 1.9691858009625507

Epoch: 5| Step: 8
Training loss: 2.031639575958252
Validation loss: 1.968358265456333

Epoch: 5| Step: 9
Training loss: 2.4339582920074463
Validation loss: 1.9522881379691504

Epoch: 5| Step: 10
Training loss: 2.2301981449127197
Validation loss: 1.9558060399947628

Epoch: 74| Step: 0
Training loss: 2.397832155227661
Validation loss: 1.9642758215627363

Epoch: 5| Step: 1
Training loss: 2.7119243144989014
Validation loss: 1.9509800095711984

Epoch: 5| Step: 2
Training loss: 2.334806442260742
Validation loss: 1.9906943587846653

Epoch: 5| Step: 3
Training loss: 2.1539437770843506
Validation loss: 1.972688913345337

Epoch: 5| Step: 4
Training loss: 2.3177719116210938
Validation loss: 1.9751957578043784

Epoch: 5| Step: 5
Training loss: 2.4566919803619385
Validation loss: 1.979022850272476

Epoch: 5| Step: 6
Training loss: 2.377169370651245
Validation loss: 1.9746245940526326

Epoch: 5| Step: 7
Training loss: 1.5999661684036255
Validation loss: 1.9785557305941017

Epoch: 5| Step: 8
Training loss: 1.941288709640503
Validation loss: 1.9738164153150333

Epoch: 5| Step: 9
Training loss: 2.5489368438720703
Validation loss: 1.9707147203465945

Epoch: 5| Step: 10
Training loss: 2.013420581817627
Validation loss: 1.975966639416192

Epoch: 75| Step: 0
Training loss: 2.046673059463501
Validation loss: 1.9733871413815407

Epoch: 5| Step: 1
Training loss: 2.7022287845611572
Validation loss: 1.9852109980839554

Epoch: 5| Step: 2
Training loss: 2.702723979949951
Validation loss: 1.9699124418279177

Epoch: 5| Step: 3
Training loss: 2.0451865196228027
Validation loss: 1.9822839767702165

Epoch: 5| Step: 4
Training loss: 1.5938646793365479
Validation loss: 1.9795119031783073

Epoch: 5| Step: 5
Training loss: 1.9380273818969727
Validation loss: 1.9770859749086442

Epoch: 5| Step: 6
Training loss: 2.8274149894714355
Validation loss: 1.9886296333805207

Epoch: 5| Step: 7
Training loss: 1.9228105545043945
Validation loss: 1.9769832241919734

Epoch: 5| Step: 8
Training loss: 2.339578151702881
Validation loss: 1.9855092161445207

Epoch: 5| Step: 9
Training loss: 2.1152591705322266
Validation loss: 1.9900070646757722

Epoch: 5| Step: 10
Training loss: 2.737346887588501
Validation loss: 1.9900322139904063

Epoch: 76| Step: 0
Training loss: 2.190722703933716
Validation loss: 1.9811384485613914

Epoch: 5| Step: 1
Training loss: 1.9652912616729736
Validation loss: 1.9762571498911867

Epoch: 5| Step: 2
Training loss: 2.631296157836914
Validation loss: 1.9757545955719487

Epoch: 5| Step: 3
Training loss: 2.2502334117889404
Validation loss: 1.9817149036674089

Epoch: 5| Step: 4
Training loss: 2.188678503036499
Validation loss: 1.9649073129059167

Epoch: 5| Step: 5
Training loss: 2.609593629837036
Validation loss: 1.9828461511160738

Epoch: 5| Step: 6
Training loss: 1.5052944421768188
Validation loss: 1.9422205955751481

Epoch: 5| Step: 7
Training loss: 2.376786231994629
Validation loss: 1.9699448231727845

Epoch: 5| Step: 8
Training loss: 2.827183485031128
Validation loss: 1.9811114444527576

Epoch: 5| Step: 9
Training loss: 2.5710902214050293
Validation loss: 1.9649558503140685

Epoch: 5| Step: 10
Training loss: 1.5666742324829102
Validation loss: 1.966815653667655

Epoch: 77| Step: 0
Training loss: 2.3493494987487793
Validation loss: 1.9610199902647285

Epoch: 5| Step: 1
Training loss: 2.653231620788574
Validation loss: 1.9594995770403134

Epoch: 5| Step: 2
Training loss: 2.150641441345215
Validation loss: 1.9553999875181465

Epoch: 5| Step: 3
Training loss: 2.9441170692443848
Validation loss: 1.971870522345266

Epoch: 5| Step: 4
Training loss: 1.69828200340271
Validation loss: 1.9833814238989225

Epoch: 5| Step: 5
Training loss: 2.2787890434265137
Validation loss: 1.9631759402572468

Epoch: 5| Step: 6
Training loss: 1.9319947957992554
Validation loss: 1.962099975155246

Epoch: 5| Step: 7
Training loss: 2.5164763927459717
Validation loss: 1.9601206112933416

Epoch: 5| Step: 8
Training loss: 2.091468334197998
Validation loss: 1.9812492350096345

Epoch: 5| Step: 9
Training loss: 2.2921338081359863
Validation loss: 1.98345531699478

Epoch: 5| Step: 10
Training loss: 1.598341941833496
Validation loss: 1.9675965924416818

Epoch: 78| Step: 0
Training loss: 2.024653434753418
Validation loss: 1.959234142816195

Epoch: 5| Step: 1
Training loss: 2.117515802383423
Validation loss: 1.9822416036359725

Epoch: 5| Step: 2
Training loss: 2.485304117202759
Validation loss: 1.9829095678944741

Epoch: 5| Step: 3
Training loss: 2.8870654106140137
Validation loss: 1.9677871850229078

Epoch: 5| Step: 4
Training loss: 2.3262057304382324
Validation loss: 1.9797118043386808

Epoch: 5| Step: 5
Training loss: 2.107149600982666
Validation loss: 1.9849929399387811

Epoch: 5| Step: 6
Training loss: 1.9501063823699951
Validation loss: 1.9827612702564528

Epoch: 5| Step: 7
Training loss: 2.185391426086426
Validation loss: 1.9706947495860438

Epoch: 5| Step: 8
Training loss: 1.8405811786651611
Validation loss: 1.9922046904922814

Epoch: 5| Step: 9
Training loss: 2.4978976249694824
Validation loss: 1.9861998737499278

Epoch: 5| Step: 10
Training loss: 2.4823856353759766
Validation loss: 1.9670683132704867

Epoch: 79| Step: 0
Training loss: 1.9532954692840576
Validation loss: 1.9806107654366443

Epoch: 5| Step: 1
Training loss: 2.591670274734497
Validation loss: 1.9867185341414584

Epoch: 5| Step: 2
Training loss: 2.414595127105713
Validation loss: 1.9801325746761855

Epoch: 5| Step: 3
Training loss: 2.7030367851257324
Validation loss: 1.9713526682187152

Epoch: 5| Step: 4
Training loss: 2.0342884063720703
Validation loss: 1.9689648843580676

Epoch: 5| Step: 5
Training loss: 2.2541937828063965
Validation loss: 1.9771731233084073

Epoch: 5| Step: 6
Training loss: 2.4046988487243652
Validation loss: 1.9689658559778684

Epoch: 5| Step: 7
Training loss: 2.4807217121124268
Validation loss: 1.9686212962673557

Epoch: 5| Step: 8
Training loss: 2.0703136920928955
Validation loss: 1.9888784411132976

Epoch: 5| Step: 9
Training loss: 1.8618965148925781
Validation loss: 1.9667491874387186

Epoch: 5| Step: 10
Training loss: 1.9608006477355957
Validation loss: 1.9702082705754105

Epoch: 80| Step: 0
Training loss: 1.9786689281463623
Validation loss: 1.9546470231907342

Epoch: 5| Step: 1
Training loss: 2.711869716644287
Validation loss: 1.9796319571874474

Epoch: 5| Step: 2
Training loss: 1.7209155559539795
Validation loss: 1.9472500662649832

Epoch: 5| Step: 3
Training loss: 2.434401750564575
Validation loss: 1.9671519059006886

Epoch: 5| Step: 4
Training loss: 2.679588556289673
Validation loss: 1.9523403260015673

Epoch: 5| Step: 5
Training loss: 1.8323827981948853
Validation loss: 1.9681200083865915

Epoch: 5| Step: 6
Training loss: 2.0864710807800293
Validation loss: 1.9688572486241658

Epoch: 5| Step: 7
Training loss: 2.1972670555114746
Validation loss: 1.9535398521730978

Epoch: 5| Step: 8
Training loss: 2.4449610710144043
Validation loss: 1.9709653841551913

Epoch: 5| Step: 9
Training loss: 2.3451313972473145
Validation loss: 1.9439814462456653

Epoch: 5| Step: 10
Training loss: 2.284837484359741
Validation loss: 1.968090481655572

Epoch: 81| Step: 0
Training loss: 1.8560386896133423
Validation loss: 1.9640458886341383

Epoch: 5| Step: 1
Training loss: 2.153323173522949
Validation loss: 1.9688487078553887

Epoch: 5| Step: 2
Training loss: 2.413376569747925
Validation loss: 1.9756558736165364

Epoch: 5| Step: 3
Training loss: 2.8946447372436523
Validation loss: 1.9832704528685539

Epoch: 5| Step: 4
Training loss: 2.224395275115967
Validation loss: 1.9818726162756644

Epoch: 5| Step: 5
Training loss: 2.253506898880005
Validation loss: 1.9530625266413535

Epoch: 5| Step: 6
Training loss: 2.5593838691711426
Validation loss: 1.9714828486083655

Epoch: 5| Step: 7
Training loss: 1.8340024948120117
Validation loss: 1.987664435499458

Epoch: 5| Step: 8
Training loss: 1.905998945236206
Validation loss: 1.9713027707992061

Epoch: 5| Step: 9
Training loss: 2.610092878341675
Validation loss: 1.9903977032630675

Epoch: 5| Step: 10
Training loss: 1.8749809265136719
Validation loss: 1.9739141259142148

Epoch: 82| Step: 0
Training loss: 1.939287781715393
Validation loss: 1.9818209178986088

Epoch: 5| Step: 1
Training loss: 1.5560083389282227
Validation loss: 1.9834930973668252

Epoch: 5| Step: 2
Training loss: 1.7348941564559937
Validation loss: 1.9833964455512263

Epoch: 5| Step: 3
Training loss: 2.080894947052002
Validation loss: 1.9726934702165666

Epoch: 5| Step: 4
Training loss: 1.974066972732544
Validation loss: 1.9821736299863426

Epoch: 5| Step: 5
Training loss: 3.0353829860687256
Validation loss: 1.991782429397747

Epoch: 5| Step: 6
Training loss: 2.40559458732605
Validation loss: 1.959528100106024

Epoch: 5| Step: 7
Training loss: 2.227050304412842
Validation loss: 1.9788244103872648

Epoch: 5| Step: 8
Training loss: 2.2331347465515137
Validation loss: 1.977304691909462

Epoch: 5| Step: 9
Training loss: 2.490483283996582
Validation loss: 1.9750543922506354

Epoch: 5| Step: 10
Training loss: 3.007988214492798
Validation loss: 1.9825040614733132

Epoch: 83| Step: 0
Training loss: 2.176865816116333
Validation loss: 1.9745426588161017

Epoch: 5| Step: 1
Training loss: 2.5505130290985107
Validation loss: 1.984900656566825

Epoch: 5| Step: 2
Training loss: 1.9218353033065796
Validation loss: 1.9845316897156418

Epoch: 5| Step: 3
Training loss: 2.2490057945251465
Validation loss: 1.9731431622659006

Epoch: 5| Step: 4
Training loss: 2.580589771270752
Validation loss: 1.9782397670130576

Epoch: 5| Step: 5
Training loss: 2.2867445945739746
Validation loss: 1.9743104083563692

Epoch: 5| Step: 6
Training loss: 1.8686012029647827
Validation loss: 1.9683908416378884

Epoch: 5| Step: 7
Training loss: 2.5530941486358643
Validation loss: 1.9806137777143908

Epoch: 5| Step: 8
Training loss: 2.5398030281066895
Validation loss: 1.9697365619802987

Epoch: 5| Step: 9
Training loss: 2.266022205352783
Validation loss: 1.9947186618722894

Epoch: 5| Step: 10
Training loss: 1.561976671218872
Validation loss: 1.9816870561210058

Epoch: 84| Step: 0
Training loss: 2.202702045440674
Validation loss: 1.9770697098906322

Epoch: 5| Step: 1
Training loss: 2.602414131164551
Validation loss: 1.979988367326798

Epoch: 5| Step: 2
Training loss: 2.526993989944458
Validation loss: 1.9618244888961955

Epoch: 5| Step: 3
Training loss: 2.1325197219848633
Validation loss: 1.9799444675445557

Epoch: 5| Step: 4
Training loss: 2.840998888015747
Validation loss: 1.970631637880879

Epoch: 5| Step: 5
Training loss: 2.431993007659912
Validation loss: 1.9758581128171695

Epoch: 5| Step: 6
Training loss: 1.872551679611206
Validation loss: 1.969178427932083

Epoch: 5| Step: 7
Training loss: 2.173501491546631
Validation loss: 1.9579324491562382

Epoch: 5| Step: 8
Training loss: 2.076066732406616
Validation loss: 1.9782058936293407

Epoch: 5| Step: 9
Training loss: 2.1430704593658447
Validation loss: 1.9655363623813917

Epoch: 5| Step: 10
Training loss: 1.558139443397522
Validation loss: 1.9589060839786325

Epoch: 85| Step: 0
Training loss: 2.6406445503234863
Validation loss: 1.9629951010468185

Epoch: 5| Step: 1
Training loss: 2.0089950561523438
Validation loss: 1.968598081219581

Epoch: 5| Step: 2
Training loss: 1.824011206626892
Validation loss: 1.9704762748492661

Epoch: 5| Step: 3
Training loss: 1.9755451679229736
Validation loss: 1.9495857787388626

Epoch: 5| Step: 4
Training loss: 2.6334354877471924
Validation loss: 1.9496105255619172

Epoch: 5| Step: 5
Training loss: 2.2513515949249268
Validation loss: 1.9556363372392551

Epoch: 5| Step: 6
Training loss: 2.282508373260498
Validation loss: 1.9582305057074434

Epoch: 5| Step: 7
Training loss: 1.8163974285125732
Validation loss: 1.9701839262439358

Epoch: 5| Step: 8
Training loss: 2.4507317543029785
Validation loss: 1.9552553533225931

Epoch: 5| Step: 9
Training loss: 2.1956124305725098
Validation loss: 1.9530839676498084

Epoch: 5| Step: 10
Training loss: 2.607919216156006
Validation loss: 1.9770581235167801

Epoch: 86| Step: 0
Training loss: 1.955806016921997
Validation loss: 1.9612360590247697

Epoch: 5| Step: 1
Training loss: 2.0788111686706543
Validation loss: 1.9598430779672438

Epoch: 5| Step: 2
Training loss: 2.291170597076416
Validation loss: 1.9722402839250461

Epoch: 5| Step: 3
Training loss: 2.0340981483459473
Validation loss: 1.9844390230794107

Epoch: 5| Step: 4
Training loss: 2.3733603954315186
Validation loss: 1.9649912490639636

Epoch: 5| Step: 5
Training loss: 2.490072727203369
Validation loss: 1.9579228021765267

Epoch: 5| Step: 6
Training loss: 2.0553462505340576
Validation loss: 1.9772612689643778

Epoch: 5| Step: 7
Training loss: 1.8935282230377197
Validation loss: 1.9822902525624921

Epoch: 5| Step: 8
Training loss: 2.7836692333221436
Validation loss: 1.976235161545456

Epoch: 5| Step: 9
Training loss: 1.8900811672210693
Validation loss: 1.9707491526039698

Epoch: 5| Step: 10
Training loss: 2.702596664428711
Validation loss: 1.9866085667763986

Epoch: 87| Step: 0
Training loss: 2.5462803840637207
Validation loss: 1.9908704706417617

Epoch: 5| Step: 1
Training loss: 1.366561770439148
Validation loss: 1.985391357893585

Epoch: 5| Step: 2
Training loss: 1.7786099910736084
Validation loss: 1.9959182508530156

Epoch: 5| Step: 3
Training loss: 2.3070199489593506
Validation loss: 1.9969986254169094

Epoch: 5| Step: 4
Training loss: 2.5927138328552246
Validation loss: 1.9993290414092362

Epoch: 5| Step: 5
Training loss: 2.9490323066711426
Validation loss: 1.9987032746755948

Epoch: 5| Step: 6
Training loss: 1.7685003280639648
Validation loss: 1.963052700924617

Epoch: 5| Step: 7
Training loss: 2.7363576889038086
Validation loss: 1.9886153821022279

Epoch: 5| Step: 8
Training loss: 1.8805532455444336
Validation loss: 1.9960505103552213

Epoch: 5| Step: 9
Training loss: 2.2234320640563965
Validation loss: 1.9749417740811583

Epoch: 5| Step: 10
Training loss: 2.6123805046081543
Validation loss: 1.9761172045943558

Epoch: 88| Step: 0
Training loss: 2.4281997680664062
Validation loss: 2.0051402353471324

Epoch: 5| Step: 1
Training loss: 1.8381173610687256
Validation loss: 1.9843518708341865

Epoch: 5| Step: 2
Training loss: 2.5913619995117188
Validation loss: 1.9997545980638074

Epoch: 5| Step: 3
Training loss: 2.1271090507507324
Validation loss: 1.9818134077133671

Epoch: 5| Step: 4
Training loss: 2.286742687225342
Validation loss: 1.9871145089467366

Epoch: 5| Step: 5
Training loss: 2.344695568084717
Validation loss: 1.9852428820825392

Epoch: 5| Step: 6
Training loss: 1.8272594213485718
Validation loss: 1.9807247410538376

Epoch: 5| Step: 7
Training loss: 2.4579341411590576
Validation loss: 1.983853995159108

Epoch: 5| Step: 8
Training loss: 2.4095911979675293
Validation loss: 1.9729187206555439

Epoch: 5| Step: 9
Training loss: 2.317094087600708
Validation loss: 1.9857441699633034

Epoch: 5| Step: 10
Training loss: 1.8236123323440552
Validation loss: 1.977010937147243

Epoch: 89| Step: 0
Training loss: 1.9319127798080444
Validation loss: 1.9740108879663611

Epoch: 5| Step: 1
Training loss: 2.174692153930664
Validation loss: 1.9813421439099055

Epoch: 5| Step: 2
Training loss: 2.1964800357818604
Validation loss: 1.9796750289137646

Epoch: 5| Step: 3
Training loss: 2.5769615173339844
Validation loss: 1.9885908224249398

Epoch: 5| Step: 4
Training loss: 2.649545192718506
Validation loss: 1.9799384506799842

Epoch: 5| Step: 5
Training loss: 2.1219491958618164
Validation loss: 1.9927482117888748

Epoch: 5| Step: 6
Training loss: 2.798603057861328
Validation loss: 1.9755932772031395

Epoch: 5| Step: 7
Training loss: 2.0886528491973877
Validation loss: 1.9711599375611992

Epoch: 5| Step: 8
Training loss: 1.6830604076385498
Validation loss: 1.979383719864712

Epoch: 5| Step: 9
Training loss: 2.3770270347595215
Validation loss: 1.9615507689855431

Epoch: 5| Step: 10
Training loss: 2.0675277709960938
Validation loss: 1.9691011546760477

Epoch: 90| Step: 0
Training loss: 2.091975212097168
Validation loss: 1.9696745270042009

Epoch: 5| Step: 1
Training loss: 2.5484039783477783
Validation loss: 1.9875567395200011

Epoch: 5| Step: 2
Training loss: 3.1101441383361816
Validation loss: 1.9651788088583177

Epoch: 5| Step: 3
Training loss: 1.7589073181152344
Validation loss: 1.962058618504514

Epoch: 5| Step: 4
Training loss: 1.4231703281402588
Validation loss: 1.9863985943537887

Epoch: 5| Step: 5
Training loss: 1.806998610496521
Validation loss: 1.9738873025422454

Epoch: 5| Step: 6
Training loss: 2.1687448024749756
Validation loss: 1.9795493515588904

Epoch: 5| Step: 7
Training loss: 2.7971062660217285
Validation loss: 1.98777993904647

Epoch: 5| Step: 8
Training loss: 2.1486096382141113
Validation loss: 1.995162256302372

Epoch: 5| Step: 9
Training loss: 2.6045889854431152
Validation loss: 1.9856203884206793

Epoch: 5| Step: 10
Training loss: 1.8149455785751343
Validation loss: 1.9730350945585517

Epoch: 91| Step: 0
Training loss: 2.751730442047119
Validation loss: 1.9892823926864132

Epoch: 5| Step: 1
Training loss: 2.3156492710113525
Validation loss: 2.0136243451026177

Epoch: 5| Step: 2
Training loss: 2.788412570953369
Validation loss: 1.9947190976911975

Epoch: 5| Step: 3
Training loss: 2.1101229190826416
Validation loss: 1.9929978334775535

Epoch: 5| Step: 4
Training loss: 1.7490928173065186
Validation loss: 1.984155083215365

Epoch: 5| Step: 5
Training loss: 2.363511562347412
Validation loss: 1.9781122694733322

Epoch: 5| Step: 6
Training loss: 1.9939788579940796
Validation loss: 1.998280438043738

Epoch: 5| Step: 7
Training loss: 1.6420114040374756
Validation loss: 1.993365433908278

Epoch: 5| Step: 8
Training loss: 2.3905341625213623
Validation loss: 2.0131209601638136

Epoch: 5| Step: 9
Training loss: 2.35992169380188
Validation loss: 2.0085427735441472

Epoch: 5| Step: 10
Training loss: 2.017781972885132
Validation loss: 2.005491356695852

Epoch: 92| Step: 0
Training loss: 2.7533621788024902
Validation loss: 1.9949755937822404

Epoch: 5| Step: 1
Training loss: 2.4362804889678955
Validation loss: 2.008831854789488

Epoch: 5| Step: 2
Training loss: 1.7164676189422607
Validation loss: 1.9991847020323559

Epoch: 5| Step: 3
Training loss: 2.479924440383911
Validation loss: 1.9933440287907918

Epoch: 5| Step: 4
Training loss: 2.4458813667297363
Validation loss: 1.979274053727427

Epoch: 5| Step: 5
Training loss: 2.330181837081909
Validation loss: 1.9778152101783342

Epoch: 5| Step: 6
Training loss: 2.1562752723693848
Validation loss: 1.9782609247392224

Epoch: 5| Step: 7
Training loss: 2.3818562030792236
Validation loss: 1.988329452853049

Epoch: 5| Step: 8
Training loss: 1.9524726867675781
Validation loss: 1.9805472563671809

Epoch: 5| Step: 9
Training loss: 2.173208475112915
Validation loss: 1.9879734951962706

Epoch: 5| Step: 10
Training loss: 1.5578137636184692
Validation loss: 1.9604082056271133

Epoch: 93| Step: 0
Training loss: 1.885167121887207
Validation loss: 1.9776222757113877

Epoch: 5| Step: 1
Training loss: 2.1752753257751465
Validation loss: 1.980522878708378

Epoch: 5| Step: 2
Training loss: 2.0476107597351074
Validation loss: 1.970945039103108

Epoch: 5| Step: 3
Training loss: 2.063159942626953
Validation loss: 1.9725831106144895

Epoch: 5| Step: 4
Training loss: 2.3965766429901123
Validation loss: 1.9584552626455984

Epoch: 5| Step: 5
Training loss: 2.2323591709136963
Validation loss: 1.9535531638770975

Epoch: 5| Step: 6
Training loss: 2.532468795776367
Validation loss: 1.966160612721597

Epoch: 5| Step: 7
Training loss: 1.8154023885726929
Validation loss: 1.9798509664432977

Epoch: 5| Step: 8
Training loss: 2.470520496368408
Validation loss: 1.9716109280945153

Epoch: 5| Step: 9
Training loss: 2.816596269607544
Validation loss: 1.9752808360643284

Epoch: 5| Step: 10
Training loss: 1.833069086074829
Validation loss: 1.9627755931628648

Epoch: 94| Step: 0
Training loss: 2.218780517578125
Validation loss: 1.9612369101534608

Epoch: 5| Step: 1
Training loss: 2.29129958152771
Validation loss: 1.9666086191772132

Epoch: 5| Step: 2
Training loss: 1.6025619506835938
Validation loss: 1.9729175183080858

Epoch: 5| Step: 3
Training loss: 1.9945249557495117
Validation loss: 1.9727268808631486

Epoch: 5| Step: 4
Training loss: 2.15928316116333
Validation loss: 1.9578455443023353

Epoch: 5| Step: 5
Training loss: 2.3443496227264404
Validation loss: 1.9760119786826513

Epoch: 5| Step: 6
Training loss: 2.280810594558716
Validation loss: 1.9828795912445232

Epoch: 5| Step: 7
Training loss: 2.5400211811065674
Validation loss: 1.9783136203724851

Epoch: 5| Step: 8
Training loss: 2.7400405406951904
Validation loss: 1.969643323652206

Epoch: 5| Step: 9
Training loss: 2.121093273162842
Validation loss: 1.9606474086802492

Epoch: 5| Step: 10
Training loss: 2.2130110263824463
Validation loss: 1.9687538275154688

Epoch: 95| Step: 0
Training loss: 2.319639205932617
Validation loss: 1.993317093900455

Epoch: 5| Step: 1
Training loss: 1.7758111953735352
Validation loss: 1.9732184576731857

Epoch: 5| Step: 2
Training loss: 2.3502655029296875
Validation loss: 1.9758978402742775

Epoch: 5| Step: 3
Training loss: 1.9721759557724
Validation loss: 1.9742573743225427

Epoch: 5| Step: 4
Training loss: 2.1599512100219727
Validation loss: 1.9899634135666715

Epoch: 5| Step: 5
Training loss: 2.4105372428894043
Validation loss: 1.980640338313195

Epoch: 5| Step: 6
Training loss: 2.234231948852539
Validation loss: 1.9900587374164211

Epoch: 5| Step: 7
Training loss: 1.977697730064392
Validation loss: 1.9986944198608398

Epoch: 5| Step: 8
Training loss: 1.8196437358856201
Validation loss: 1.9887471814309396

Epoch: 5| Step: 9
Training loss: 2.823118209838867
Validation loss: 1.9820054692606772

Epoch: 5| Step: 10
Training loss: 2.5898830890655518
Validation loss: 1.9794826174295077

Epoch: 96| Step: 0
Training loss: 1.9207532405853271
Validation loss: 2.0065113267590924

Epoch: 5| Step: 1
Training loss: 2.276534080505371
Validation loss: 1.9846657924754645

Epoch: 5| Step: 2
Training loss: 2.268636465072632
Validation loss: 1.9876189129326933

Epoch: 5| Step: 3
Training loss: 2.3461830615997314
Validation loss: 1.9868119455152942

Epoch: 5| Step: 4
Training loss: 2.511042833328247
Validation loss: 1.9890898889110935

Epoch: 5| Step: 5
Training loss: 1.7734655141830444
Validation loss: 1.9956385550960418

Epoch: 5| Step: 6
Training loss: 2.5293900966644287
Validation loss: 1.99672713587361

Epoch: 5| Step: 7
Training loss: 2.2475247383117676
Validation loss: 1.9687289191830544

Epoch: 5| Step: 8
Training loss: 2.558363914489746
Validation loss: 2.0084112767250306

Epoch: 5| Step: 9
Training loss: 2.068373203277588
Validation loss: 1.9855423460724533

Epoch: 5| Step: 10
Training loss: 1.971514105796814
Validation loss: 1.9834725395325692

Epoch: 97| Step: 0
Training loss: 2.348635196685791
Validation loss: 2.001548864508188

Epoch: 5| Step: 1
Training loss: 1.7968719005584717
Validation loss: 1.9877917484570575

Epoch: 5| Step: 2
Training loss: 2.000307559967041
Validation loss: 2.0012895214942192

Epoch: 5| Step: 3
Training loss: 2.689362049102783
Validation loss: 1.9895150789650538

Epoch: 5| Step: 4
Training loss: 2.0665271282196045
Validation loss: 1.9996658602068502

Epoch: 5| Step: 5
Training loss: 1.8050930500030518
Validation loss: 1.9986298930260442

Epoch: 5| Step: 6
Training loss: 1.7913954257965088
Validation loss: 1.9976277864107521

Epoch: 5| Step: 7
Training loss: 2.7048134803771973
Validation loss: 2.0024898693125737

Epoch: 5| Step: 8
Training loss: 2.2804105281829834
Validation loss: 2.0004947493153233

Epoch: 5| Step: 9
Training loss: 2.4133243560791016
Validation loss: 2.000845709154683

Epoch: 5| Step: 10
Training loss: 2.501051425933838
Validation loss: 2.0015826520099433

Epoch: 98| Step: 0
Training loss: 1.8078876733779907
Validation loss: 1.996270029775558

Epoch: 5| Step: 1
Training loss: 2.4001994132995605
Validation loss: 1.994046413770286

Epoch: 5| Step: 2
Training loss: 2.472151517868042
Validation loss: 1.9987376556601575

Epoch: 5| Step: 3
Training loss: 2.043131113052368
Validation loss: 1.9944164727323799

Epoch: 5| Step: 4
Training loss: 2.5657951831817627
Validation loss: 1.9809384294735488

Epoch: 5| Step: 5
Training loss: 2.1248621940612793
Validation loss: 1.9688672301589802

Epoch: 5| Step: 6
Training loss: 2.1282501220703125
Validation loss: 1.9875569292294082

Epoch: 5| Step: 7
Training loss: 2.4237074851989746
Validation loss: 1.9825673000786894

Epoch: 5| Step: 8
Training loss: 2.1491618156433105
Validation loss: 1.9818688566966722

Epoch: 5| Step: 9
Training loss: 2.0110116004943848
Validation loss: 1.9667950496878674

Epoch: 5| Step: 10
Training loss: 2.274709701538086
Validation loss: 1.9593443178361463

Epoch: 99| Step: 0
Training loss: 2.2620933055877686
Validation loss: 1.9634279128043883

Epoch: 5| Step: 1
Training loss: 1.9807989597320557
Validation loss: 1.9562865611045592

Epoch: 5| Step: 2
Training loss: 2.6652143001556396
Validation loss: 1.9566340164471698

Epoch: 5| Step: 3
Training loss: 2.098801374435425
Validation loss: 1.9415203871265534

Epoch: 5| Step: 4
Training loss: 2.0038115978240967
Validation loss: 1.9505156675974529

Epoch: 5| Step: 5
Training loss: 2.522622585296631
Validation loss: 1.9634070216968496

Epoch: 5| Step: 6
Training loss: 2.0695884227752686
Validation loss: 1.988310606248917

Epoch: 5| Step: 7
Training loss: 2.8752143383026123
Validation loss: 1.966076806027402

Epoch: 5| Step: 8
Training loss: 1.7508646249771118
Validation loss: 1.9727327541638446

Epoch: 5| Step: 9
Training loss: 1.9269144535064697
Validation loss: 1.9642941451841784

Epoch: 5| Step: 10
Training loss: 2.223663091659546
Validation loss: 1.9784660070173201

Epoch: 100| Step: 0
Training loss: 2.0874457359313965
Validation loss: 1.99606075081774

Epoch: 5| Step: 1
Training loss: 2.09354829788208
Validation loss: 1.9788149749079058

Epoch: 5| Step: 2
Training loss: 1.8536884784698486
Validation loss: 1.9726996344904746

Epoch: 5| Step: 3
Training loss: 2.9990057945251465
Validation loss: 1.998751950520341

Epoch: 5| Step: 4
Training loss: 1.7285449504852295
Validation loss: 1.9958422465990948

Epoch: 5| Step: 5
Training loss: 2.67646861076355
Validation loss: 1.996406175756967

Epoch: 5| Step: 6
Training loss: 1.9142109155654907
Validation loss: 1.9839871224536691

Epoch: 5| Step: 7
Training loss: 1.8723922967910767
Validation loss: 1.9766090493048392

Epoch: 5| Step: 8
Training loss: 2.2512991428375244
Validation loss: 1.9703059837382326

Epoch: 5| Step: 9
Training loss: 2.8740711212158203
Validation loss: 1.9844934607064852

Epoch: 5| Step: 10
Training loss: 1.9324663877487183
Validation loss: 1.9808271725972493

Epoch: 101| Step: 0
Training loss: 2.0464048385620117
Validation loss: 1.9801359279181368

Epoch: 5| Step: 1
Training loss: 1.8718526363372803
Validation loss: 1.9923690711298296

Epoch: 5| Step: 2
Training loss: 2.135627508163452
Validation loss: 1.9939659615998626

Epoch: 5| Step: 3
Training loss: 2.079160213470459
Validation loss: 1.9872863061966435

Epoch: 5| Step: 4
Training loss: 2.2311453819274902
Validation loss: 1.9888858231165076

Epoch: 5| Step: 5
Training loss: 2.692556858062744
Validation loss: 1.9820659288796045

Epoch: 5| Step: 6
Training loss: 2.203962802886963
Validation loss: 1.9936339137374715

Epoch: 5| Step: 7
Training loss: 2.2630927562713623
Validation loss: 1.9806610615022722

Epoch: 5| Step: 8
Training loss: 1.6699800491333008
Validation loss: 1.9932336525250507

Epoch: 5| Step: 9
Training loss: 2.5240206718444824
Validation loss: 1.999851139642859

Epoch: 5| Step: 10
Training loss: 2.6693527698516846
Validation loss: 1.981085624746097

Epoch: 102| Step: 0
Training loss: 2.465610980987549
Validation loss: 1.9824454566483856

Epoch: 5| Step: 1
Training loss: 3.356719970703125
Validation loss: 1.9930478283154067

Epoch: 5| Step: 2
Training loss: 1.817880630493164
Validation loss: 1.9965312096380419

Epoch: 5| Step: 3
Training loss: 2.1553966999053955
Validation loss: 1.984805928763523

Epoch: 5| Step: 4
Training loss: 1.9372503757476807
Validation loss: 1.9685550864024828

Epoch: 5| Step: 5
Training loss: 2.5455963611602783
Validation loss: 1.9577725420715988

Epoch: 5| Step: 6
Training loss: 2.3887100219726562
Validation loss: 1.9823375530140375

Epoch: 5| Step: 7
Training loss: 1.6209720373153687
Validation loss: 1.9877908755374212

Epoch: 5| Step: 8
Training loss: 2.078183174133301
Validation loss: 1.9818682029683103

Epoch: 5| Step: 9
Training loss: 1.6740858554840088
Validation loss: 1.9741424604128766

Epoch: 5| Step: 10
Training loss: 2.1267075538635254
Validation loss: 1.9681987736814766

Epoch: 103| Step: 0
Training loss: 1.9996745586395264
Validation loss: 1.999456137739202

Epoch: 5| Step: 1
Training loss: 2.165663480758667
Validation loss: 1.975315022212203

Epoch: 5| Step: 2
Training loss: 2.2753891944885254
Validation loss: 1.977028166094134

Epoch: 5| Step: 3
Training loss: 1.9063301086425781
Validation loss: 1.970711664486957

Epoch: 5| Step: 4
Training loss: 2.5808169841766357
Validation loss: 1.9732999032543552

Epoch: 5| Step: 5
Training loss: 2.2604594230651855
Validation loss: 1.954964514701597

Epoch: 5| Step: 6
Training loss: 2.421863317489624
Validation loss: 1.9629376242237706

Epoch: 5| Step: 7
Training loss: 2.0448760986328125
Validation loss: 1.94615049259637

Epoch: 5| Step: 8
Training loss: 2.8301854133605957
Validation loss: 1.9453986331980715

Epoch: 5| Step: 9
Training loss: 2.273987054824829
Validation loss: 1.958285375307965

Epoch: 5| Step: 10
Training loss: 1.4902156591415405
Validation loss: 1.9516544624041485

Epoch: 104| Step: 0
Training loss: 1.882401466369629
Validation loss: 1.970156822153317

Epoch: 5| Step: 1
Training loss: 2.3103721141815186
Validation loss: 1.9670558334678732

Epoch: 5| Step: 2
Training loss: 2.292771577835083
Validation loss: 1.9779842822782454

Epoch: 5| Step: 3
Training loss: 2.161271095275879
Validation loss: 1.9571802282846102

Epoch: 5| Step: 4
Training loss: 2.060328960418701
Validation loss: 1.9630907120243195

Epoch: 5| Step: 5
Training loss: 2.6723830699920654
Validation loss: 1.9731915509828957

Epoch: 5| Step: 6
Training loss: 2.2563259601593018
Validation loss: 1.9696368107231714

Epoch: 5| Step: 7
Training loss: 2.2510573863983154
Validation loss: 1.9813544955304874

Epoch: 5| Step: 8
Training loss: 2.035804510116577
Validation loss: 1.9685786129325948

Epoch: 5| Step: 9
Training loss: 1.9709926843643188
Validation loss: 1.9730889592119443

Epoch: 5| Step: 10
Training loss: 2.309422254562378
Validation loss: 1.9781683632122573

Epoch: 105| Step: 0
Training loss: 2.009674549102783
Validation loss: 1.9930738941315682

Epoch: 5| Step: 1
Training loss: 1.7633804082870483
Validation loss: 1.9963637346862464

Epoch: 5| Step: 2
Training loss: 2.0308871269226074
Validation loss: 2.0132626589908393

Epoch: 5| Step: 3
Training loss: 2.5719501972198486
Validation loss: 1.9847514219181512

Epoch: 5| Step: 4
Training loss: 2.515784502029419
Validation loss: 1.9899241591012606

Epoch: 5| Step: 5
Training loss: 2.225919723510742
Validation loss: 2.0047627828454457

Epoch: 5| Step: 6
Training loss: 1.8838016986846924
Validation loss: 1.9947744492561585

Epoch: 5| Step: 7
Training loss: 2.5255582332611084
Validation loss: 1.9999550670705817

Epoch: 5| Step: 8
Training loss: 1.8437988758087158
Validation loss: 1.9854603352085236

Epoch: 5| Step: 9
Training loss: 2.8763427734375
Validation loss: 1.985883383340733

Epoch: 5| Step: 10
Training loss: 1.9275294542312622
Validation loss: 2.0202635821475776

Epoch: 106| Step: 0
Training loss: 2.202991008758545
Validation loss: 2.001505054453368

Epoch: 5| Step: 1
Training loss: 2.0742292404174805
Validation loss: 2.007130406236136

Epoch: 5| Step: 2
Training loss: 2.660090923309326
Validation loss: 2.007807967483356

Epoch: 5| Step: 3
Training loss: 2.5759105682373047
Validation loss: 1.9883382628040929

Epoch: 5| Step: 4
Training loss: 2.315516948699951
Validation loss: 2.0093349385005173

Epoch: 5| Step: 5
Training loss: 2.154357671737671
Validation loss: 1.9959876960323704

Epoch: 5| Step: 6
Training loss: 2.367558002471924
Validation loss: 2.003473734342924

Epoch: 5| Step: 7
Training loss: 1.965705156326294
Validation loss: 2.011627666411861

Epoch: 5| Step: 8
Training loss: 1.835526466369629
Validation loss: 2.0060049679971512

Epoch: 5| Step: 9
Training loss: 1.9680016040802002
Validation loss: 2.0057394837820404

Epoch: 5| Step: 10
Training loss: 2.1449191570281982
Validation loss: 1.996588751833926

Epoch: 107| Step: 0
Training loss: 1.478341817855835
Validation loss: 1.9965814877581853

Epoch: 5| Step: 1
Training loss: 2.1631157398223877
Validation loss: 1.9974069390245663

Epoch: 5| Step: 2
Training loss: 2.2978062629699707
Validation loss: 1.9976322099726687

Epoch: 5| Step: 3
Training loss: 2.645963191986084
Validation loss: 1.9923997463718537

Epoch: 5| Step: 4
Training loss: 2.024570941925049
Validation loss: 1.9743186261064263

Epoch: 5| Step: 5
Training loss: 2.1405396461486816
Validation loss: 1.984421113485931

Epoch: 5| Step: 6
Training loss: 1.8069112300872803
Validation loss: 1.9811193673841414

Epoch: 5| Step: 7
Training loss: 2.5536816120147705
Validation loss: 1.9870764824651903

Epoch: 5| Step: 8
Training loss: 2.289583921432495
Validation loss: 1.9724914643072313

Epoch: 5| Step: 9
Training loss: 2.5814852714538574
Validation loss: 1.9985576701420609

Epoch: 5| Step: 10
Training loss: 2.2965195178985596
Validation loss: 1.9798242533078758

Epoch: 108| Step: 0
Training loss: 2.3920207023620605
Validation loss: 1.9691250631886144

Epoch: 5| Step: 1
Training loss: 1.6057888269424438
Validation loss: 1.9875905180490145

Epoch: 5| Step: 2
Training loss: 1.6736557483673096
Validation loss: 1.9786110283226095

Epoch: 5| Step: 3
Training loss: 2.7398061752319336
Validation loss: 1.9950318336486816

Epoch: 5| Step: 4
Training loss: 1.7482837438583374
Validation loss: 1.9653515905462287

Epoch: 5| Step: 5
Training loss: 2.4586522579193115
Validation loss: 1.9642864158076625

Epoch: 5| Step: 6
Training loss: 2.1391866207122803
Validation loss: 1.9700874141467515

Epoch: 5| Step: 7
Training loss: 2.4135398864746094
Validation loss: 1.9805048114509993

Epoch: 5| Step: 8
Training loss: 2.0580248832702637
Validation loss: 1.9678988046543573

Epoch: 5| Step: 9
Training loss: 1.894065499305725
Validation loss: 1.967087104756345

Epoch: 5| Step: 10
Training loss: 3.3767035007476807
Validation loss: 1.9665914043303458

Epoch: 109| Step: 0
Training loss: 1.688950538635254
Validation loss: 1.9732150031674294

Epoch: 5| Step: 1
Training loss: 1.9276292324066162
Validation loss: 1.979369459613677

Epoch: 5| Step: 2
Training loss: 2.0312438011169434
Validation loss: 1.9728524479814755

Epoch: 5| Step: 3
Training loss: 2.5330512523651123
Validation loss: 1.9876557075849144

Epoch: 5| Step: 4
Training loss: 2.1985459327697754
Validation loss: 1.973293089097546

Epoch: 5| Step: 5
Training loss: 2.3087875843048096
Validation loss: 1.9831752751463203

Epoch: 5| Step: 6
Training loss: 1.727307677268982
Validation loss: 1.9951735491393714

Epoch: 5| Step: 7
Training loss: 2.4368999004364014
Validation loss: 1.9692921510306738

Epoch: 5| Step: 8
Training loss: 1.9852145910263062
Validation loss: 1.9886079783080726

Epoch: 5| Step: 9
Training loss: 2.5593080520629883
Validation loss: 1.9967152200719362

Epoch: 5| Step: 10
Training loss: 2.830235481262207
Validation loss: 2.0077627089715775

Epoch: 110| Step: 0
Training loss: 1.9948886632919312
Validation loss: 1.9947822350327686

Epoch: 5| Step: 1
Training loss: 2.393138885498047
Validation loss: 1.9901028435717347

Epoch: 5| Step: 2
Training loss: 2.152141809463501
Validation loss: 1.9914378068780387

Epoch: 5| Step: 3
Training loss: 2.0405445098876953
Validation loss: 2.0253922298390377

Epoch: 5| Step: 4
Training loss: 2.337237596511841
Validation loss: 1.9997059875918972

Epoch: 5| Step: 5
Training loss: 2.5308187007904053
Validation loss: 2.0317890823528333

Epoch: 5| Step: 6
Training loss: 2.0397534370422363
Validation loss: 2.0156631636363205

Epoch: 5| Step: 7
Training loss: 1.6498692035675049
Validation loss: 2.015510691109524

Epoch: 5| Step: 8
Training loss: 2.4628429412841797
Validation loss: 2.0047184344260924

Epoch: 5| Step: 9
Training loss: 2.323090076446533
Validation loss: 2.0068918197385726

Epoch: 5| Step: 10
Training loss: 2.4887216091156006
Validation loss: 1.9974350583168767

Epoch: 111| Step: 0
Training loss: 2.2428336143493652
Validation loss: 1.987570922861817

Epoch: 5| Step: 1
Training loss: 2.540353775024414
Validation loss: 1.999140570240636

Epoch: 5| Step: 2
Training loss: 2.0575459003448486
Validation loss: 1.9905740676387664

Epoch: 5| Step: 3
Training loss: 2.42225980758667
Validation loss: 2.0224249837219075

Epoch: 5| Step: 4
Training loss: 2.0126030445098877
Validation loss: 2.010322973292361

Epoch: 5| Step: 5
Training loss: 1.8407342433929443
Validation loss: 1.993758750218217

Epoch: 5| Step: 6
Training loss: 2.105032205581665
Validation loss: 2.001119670047555

Epoch: 5| Step: 7
Training loss: 1.92031991481781
Validation loss: 2.0040484333551056

Epoch: 5| Step: 8
Training loss: 1.9437395334243774
Validation loss: 2.007717122313797

Epoch: 5| Step: 9
Training loss: 2.374861001968384
Validation loss: 1.974493472806869

Epoch: 5| Step: 10
Training loss: 2.7975542545318604
Validation loss: 1.9969449953366352

Epoch: 112| Step: 0
Training loss: 2.1195507049560547
Validation loss: 1.982190046259152

Epoch: 5| Step: 1
Training loss: 2.097862720489502
Validation loss: 1.987529077837544

Epoch: 5| Step: 2
Training loss: 1.9710934162139893
Validation loss: 2.0013751701642106

Epoch: 5| Step: 3
Training loss: 1.9042842388153076
Validation loss: 1.9899299144744873

Epoch: 5| Step: 4
Training loss: 2.509373188018799
Validation loss: 1.9961751122628488

Epoch: 5| Step: 5
Training loss: 2.289722204208374
Validation loss: 1.9888208655900852

Epoch: 5| Step: 6
Training loss: 2.1006593704223633
Validation loss: 1.988650478342528

Epoch: 5| Step: 7
Training loss: 2.5815184116363525
Validation loss: 1.9797541915729482

Epoch: 5| Step: 8
Training loss: 2.047606945037842
Validation loss: 1.967432451504533

Epoch: 5| Step: 9
Training loss: 2.315826177597046
Validation loss: 1.993051657112696

Epoch: 5| Step: 10
Training loss: 2.0766348838806152
Validation loss: 1.9736894420398179

Epoch: 113| Step: 0
Training loss: 1.9673579931259155
Validation loss: 1.9801454056975663

Epoch: 5| Step: 1
Training loss: 2.3439743518829346
Validation loss: 1.9664884433951428

Epoch: 5| Step: 2
Training loss: 1.896213173866272
Validation loss: 1.97082483255735

Epoch: 5| Step: 3
Training loss: 2.346818447113037
Validation loss: 1.9823567764733427

Epoch: 5| Step: 4
Training loss: 2.003288745880127
Validation loss: 1.9763183439931562

Epoch: 5| Step: 5
Training loss: 2.051793336868286
Validation loss: 1.968785588459302

Epoch: 5| Step: 6
Training loss: 2.795496940612793
Validation loss: 1.980768576745064

Epoch: 5| Step: 7
Training loss: 1.821096420288086
Validation loss: 1.9851049915436776

Epoch: 5| Step: 8
Training loss: 2.0834615230560303
Validation loss: 1.9706365959618681

Epoch: 5| Step: 9
Training loss: 2.9182162284851074
Validation loss: 1.9716493827040478

Epoch: 5| Step: 10
Training loss: 1.8823875188827515
Validation loss: 1.9701157026393439

Epoch: 114| Step: 0
Training loss: 1.8537838459014893
Validation loss: 1.9834039313818819

Epoch: 5| Step: 1
Training loss: 2.0165152549743652
Validation loss: 1.9714949002829931

Epoch: 5| Step: 2
Training loss: 1.8535972833633423
Validation loss: 1.9801548552769486

Epoch: 5| Step: 3
Training loss: 2.809354782104492
Validation loss: 1.960034615250044

Epoch: 5| Step: 4
Training loss: 1.6907150745391846
Validation loss: 1.9671333015605967

Epoch: 5| Step: 5
Training loss: 2.257432699203491
Validation loss: 1.9799020495466007

Epoch: 5| Step: 6
Training loss: 1.958709716796875
Validation loss: 1.98622945175376

Epoch: 5| Step: 7
Training loss: 1.9454619884490967
Validation loss: 1.949767715187483

Epoch: 5| Step: 8
Training loss: 2.4266417026519775
Validation loss: 1.9585312733086206

Epoch: 5| Step: 9
Training loss: 2.704446315765381
Validation loss: 1.948433212054673

Epoch: 5| Step: 10
Training loss: 2.665605306625366
Validation loss: 1.9712266088813863

Epoch: 115| Step: 0
Training loss: 2.5363357067108154
Validation loss: 1.9871800689287082

Epoch: 5| Step: 1
Training loss: 1.6502268314361572
Validation loss: 1.96843703844214

Epoch: 5| Step: 2
Training loss: 2.6905205249786377
Validation loss: 1.9761820634206135

Epoch: 5| Step: 3
Training loss: 1.7186113595962524
Validation loss: 1.986159191336683

Epoch: 5| Step: 4
Training loss: 2.562891960144043
Validation loss: 1.9945558091645599

Epoch: 5| Step: 5
Training loss: 2.1788711547851562
Validation loss: 1.9745909988239247

Epoch: 5| Step: 6
Training loss: 2.0167605876922607
Validation loss: 1.9717042612773117

Epoch: 5| Step: 7
Training loss: 2.0816495418548584
Validation loss: 1.992327993915927

Epoch: 5| Step: 8
Training loss: 1.6989109516143799
Validation loss: 1.981338353567226

Epoch: 5| Step: 9
Training loss: 2.4313442707061768
Validation loss: 1.9809526845973024

Epoch: 5| Step: 10
Training loss: 2.6858232021331787
Validation loss: 1.9880601616315945

Epoch: 116| Step: 0
Training loss: 2.189854621887207
Validation loss: 1.9987825898713962

Epoch: 5| Step: 1
Training loss: 2.83632230758667
Validation loss: 1.9976831995030886

Epoch: 5| Step: 2
Training loss: 1.7274341583251953
Validation loss: 1.9896283752174788

Epoch: 5| Step: 3
Training loss: 2.6837801933288574
Validation loss: 1.9904236255153533

Epoch: 5| Step: 4
Training loss: 2.2218518257141113
Validation loss: 1.983499309068085

Epoch: 5| Step: 5
Training loss: 1.8399204015731812
Validation loss: 1.9912397964026338

Epoch: 5| Step: 6
Training loss: 1.9220958948135376
Validation loss: 1.9840390297674364

Epoch: 5| Step: 7
Training loss: 3.0087287425994873
Validation loss: 1.9727099210985246

Epoch: 5| Step: 8
Training loss: 1.9238860607147217
Validation loss: 1.9719262956291117

Epoch: 5| Step: 9
Training loss: 1.7942339181900024
Validation loss: 1.98207389795652

Epoch: 5| Step: 10
Training loss: 2.029799699783325
Validation loss: 1.967976676520481

Epoch: 117| Step: 0
Training loss: 2.548966884613037
Validation loss: 1.982068725811538

Epoch: 5| Step: 1
Training loss: 2.3803248405456543
Validation loss: 1.9748635343326035

Epoch: 5| Step: 2
Training loss: 2.0314583778381348
Validation loss: 1.9854962928320772

Epoch: 5| Step: 3
Training loss: 1.6585344076156616
Validation loss: 1.9978535482960362

Epoch: 5| Step: 4
Training loss: 2.4991214275360107
Validation loss: 1.9770800554624168

Epoch: 5| Step: 5
Training loss: 1.9608590602874756
Validation loss: 1.985635821537305

Epoch: 5| Step: 6
Training loss: 2.423215866088867
Validation loss: 1.9966768398079822

Epoch: 5| Step: 7
Training loss: 1.9323362112045288
Validation loss: 1.980594999046736

Epoch: 5| Step: 8
Training loss: 2.0810670852661133
Validation loss: 1.9625092065462502

Epoch: 5| Step: 9
Training loss: 2.395752191543579
Validation loss: 1.9639543487179665

Epoch: 5| Step: 10
Training loss: 2.292097330093384
Validation loss: 1.9814452381544216

Epoch: 118| Step: 0
Training loss: 2.552093505859375
Validation loss: 1.9712109283734394

Epoch: 5| Step: 1
Training loss: 2.21468186378479
Validation loss: 1.9695801722106112

Epoch: 5| Step: 2
Training loss: 2.1765453815460205
Validation loss: 1.9769920456794001

Epoch: 5| Step: 3
Training loss: 2.1078362464904785
Validation loss: 1.9766093454053324

Epoch: 5| Step: 4
Training loss: 1.8566709756851196
Validation loss: 1.9791616906401932

Epoch: 5| Step: 5
Training loss: 1.6365207433700562
Validation loss: 1.9847480276579499

Epoch: 5| Step: 6
Training loss: 2.2222514152526855
Validation loss: 1.9806574493326166

Epoch: 5| Step: 7
Training loss: 3.0235416889190674
Validation loss: 1.9770223838026806

Epoch: 5| Step: 8
Training loss: 1.8669357299804688
Validation loss: 1.9630314150164205

Epoch: 5| Step: 9
Training loss: 1.8660539388656616
Validation loss: 1.9756165935147194

Epoch: 5| Step: 10
Training loss: 2.6693248748779297
Validation loss: 1.98804642820871

Epoch: 119| Step: 0
Training loss: 1.5914784669876099
Validation loss: 1.9796833940731582

Epoch: 5| Step: 1
Training loss: 2.1481659412384033
Validation loss: 1.98951970377276

Epoch: 5| Step: 2
Training loss: 1.9226030111312866
Validation loss: 1.9802919485235726

Epoch: 5| Step: 3
Training loss: 1.7014436721801758
Validation loss: 2.0006156070258028

Epoch: 5| Step: 4
Training loss: 2.5775609016418457
Validation loss: 2.0066304053029707

Epoch: 5| Step: 5
Training loss: 2.5875635147094727
Validation loss: 1.9993016283999208

Epoch: 5| Step: 6
Training loss: 2.178290843963623
Validation loss: 1.9879843637507448

Epoch: 5| Step: 7
Training loss: 2.269151210784912
Validation loss: 2.00339368466408

Epoch: 5| Step: 8
Training loss: 2.5047829151153564
Validation loss: 2.021599761901363

Epoch: 5| Step: 9
Training loss: 2.2112412452697754
Validation loss: 1.9917228632075812

Epoch: 5| Step: 10
Training loss: 2.390249729156494
Validation loss: 1.9857345486199984

Epoch: 120| Step: 0
Training loss: 2.6351075172424316
Validation loss: 2.0155194433786536

Epoch: 5| Step: 1
Training loss: 2.2396790981292725
Validation loss: 1.9854428255429832

Epoch: 5| Step: 2
Training loss: 2.3509955406188965
Validation loss: 2.0171928533943753

Epoch: 5| Step: 3
Training loss: 1.9471461772918701
Validation loss: 1.9794197338883595

Epoch: 5| Step: 4
Training loss: 1.8914234638214111
Validation loss: 1.984287069689843

Epoch: 5| Step: 5
Training loss: 2.216266393661499
Validation loss: 1.9927817429265668

Epoch: 5| Step: 6
Training loss: 2.1091513633728027
Validation loss: 1.979592764249412

Epoch: 5| Step: 7
Training loss: 1.8088477849960327
Validation loss: 2.0037627989246

Epoch: 5| Step: 8
Training loss: 2.0787386894226074
Validation loss: 1.9860263075879825

Epoch: 5| Step: 9
Training loss: 2.6156795024871826
Validation loss: 1.956267455572723

Epoch: 5| Step: 10
Training loss: 2.1121184825897217
Validation loss: 1.9824159260719054

Epoch: 121| Step: 0
Training loss: 2.029475688934326
Validation loss: 1.9911614502629926

Epoch: 5| Step: 1
Training loss: 2.791975498199463
Validation loss: 1.9646492273576799

Epoch: 5| Step: 2
Training loss: 1.8067805767059326
Validation loss: 1.9722164202761907

Epoch: 5| Step: 3
Training loss: 1.825226068496704
Validation loss: 1.9932364750933904

Epoch: 5| Step: 4
Training loss: 2.046222686767578
Validation loss: 1.9944507473258561

Epoch: 5| Step: 5
Training loss: 2.092297077178955
Validation loss: 1.996124436778407

Epoch: 5| Step: 6
Training loss: 1.9822485446929932
Validation loss: 1.9885474302435433

Epoch: 5| Step: 7
Training loss: 2.4996414184570312
Validation loss: 1.994128284915801

Epoch: 5| Step: 8
Training loss: 2.4772133827209473
Validation loss: 1.9934817526930122

Epoch: 5| Step: 9
Training loss: 2.3139071464538574
Validation loss: 1.990532475133096

Epoch: 5| Step: 10
Training loss: 2.292057752609253
Validation loss: 1.9879360827066566

Epoch: 122| Step: 0
Training loss: 1.7245639562606812
Validation loss: 1.9952225313391736

Epoch: 5| Step: 1
Training loss: 3.206523895263672
Validation loss: 2.001635556579918

Epoch: 5| Step: 2
Training loss: 2.1614251136779785
Validation loss: 1.993014371523293

Epoch: 5| Step: 3
Training loss: 2.166908025741577
Validation loss: 1.9983237610068372

Epoch: 5| Step: 4
Training loss: 1.772542953491211
Validation loss: 2.0069664293719875

Epoch: 5| Step: 5
Training loss: 2.198349714279175
Validation loss: 2.006294104360765

Epoch: 5| Step: 6
Training loss: 1.41796875
Validation loss: 2.0083411226990404

Epoch: 5| Step: 7
Training loss: 2.448273181915283
Validation loss: 2.0115649174618464

Epoch: 5| Step: 8
Training loss: 1.853723168373108
Validation loss: 1.9992528371913458

Epoch: 5| Step: 9
Training loss: 2.364292621612549
Validation loss: 1.994734965344911

Epoch: 5| Step: 10
Training loss: 2.8514842987060547
Validation loss: 1.9936142070319063

Epoch: 123| Step: 0
Training loss: 2.4957687854766846
Validation loss: 2.0154653146702755

Epoch: 5| Step: 1
Training loss: 2.2159812450408936
Validation loss: 1.985881620837796

Epoch: 5| Step: 2
Training loss: 2.34860897064209
Validation loss: 1.9789646171754407

Epoch: 5| Step: 3
Training loss: 2.268019437789917
Validation loss: 1.9883005926685948

Epoch: 5| Step: 4
Training loss: 1.9389301538467407
Validation loss: 1.9761631873346144

Epoch: 5| Step: 5
Training loss: 2.3918282985687256
Validation loss: 1.998182991499542

Epoch: 5| Step: 6
Training loss: 2.532923460006714
Validation loss: 1.9909703654627646

Epoch: 5| Step: 7
Training loss: 1.8619086742401123
Validation loss: 1.9925017792691466

Epoch: 5| Step: 8
Training loss: 2.0110554695129395
Validation loss: 1.9814367486584572

Epoch: 5| Step: 9
Training loss: 2.0242836475372314
Validation loss: 1.9867024601146739

Epoch: 5| Step: 10
Training loss: 1.8952113389968872
Validation loss: 1.9886760839851954

Epoch: 124| Step: 0
Training loss: 1.6298080682754517
Validation loss: 1.9847431054679296

Epoch: 5| Step: 1
Training loss: 1.7523895502090454
Validation loss: 1.9937467716073478

Epoch: 5| Step: 2
Training loss: 2.7085769176483154
Validation loss: 1.995435708312578

Epoch: 5| Step: 3
Training loss: 2.4565815925598145
Validation loss: 2.000328899711691

Epoch: 5| Step: 4
Training loss: 1.9338794946670532
Validation loss: 1.9787829999000794

Epoch: 5| Step: 5
Training loss: 1.7882181406021118
Validation loss: 2.00218593048793

Epoch: 5| Step: 6
Training loss: 2.1372790336608887
Validation loss: 2.00216483300732

Epoch: 5| Step: 7
Training loss: 2.16434907913208
Validation loss: 2.01895050848684

Epoch: 5| Step: 8
Training loss: 2.9145352840423584
Validation loss: 1.996098074861752

Epoch: 5| Step: 9
Training loss: 2.0357565879821777
Validation loss: 2.0037903490886895

Epoch: 5| Step: 10
Training loss: 2.5306625366210938
Validation loss: 2.0090783872912006

Epoch: 125| Step: 0
Training loss: 1.7956864833831787
Validation loss: 1.987088599512654

Epoch: 5| Step: 1
Training loss: 2.1676647663116455
Validation loss: 1.9880444900963896

Epoch: 5| Step: 2
Training loss: 2.505077362060547
Validation loss: 1.9846415109531854

Epoch: 5| Step: 3
Training loss: 2.0947394371032715
Validation loss: 1.9826754985317108

Epoch: 5| Step: 4
Training loss: 2.2878026962280273
Validation loss: 1.9884975328240344

Epoch: 5| Step: 5
Training loss: 1.8616501092910767
Validation loss: 1.9835790049645208

Epoch: 5| Step: 6
Training loss: 2.0035955905914307
Validation loss: 1.9785442480476954

Epoch: 5| Step: 7
Training loss: 2.4451701641082764
Validation loss: 1.9867151770540463

Epoch: 5| Step: 8
Training loss: 2.4074673652648926
Validation loss: 1.9995226129408805

Epoch: 5| Step: 9
Training loss: 2.093838930130005
Validation loss: 1.976643236734534

Epoch: 5| Step: 10
Training loss: 2.3922715187072754
Validation loss: 1.9853108006138955

Epoch: 126| Step: 0
Training loss: 2.5396218299865723
Validation loss: 1.9932144713658158

Epoch: 5| Step: 1
Training loss: 2.3952624797821045
Validation loss: 1.9969612193363968

Epoch: 5| Step: 2
Training loss: 1.6713111400604248
Validation loss: 1.99038666038103

Epoch: 5| Step: 3
Training loss: 2.547441005706787
Validation loss: 1.9854558283282864

Epoch: 5| Step: 4
Training loss: 1.6571757793426514
Validation loss: 1.9855974989552652

Epoch: 5| Step: 5
Training loss: 1.8670015335083008
Validation loss: 1.9839066946378319

Epoch: 5| Step: 6
Training loss: 2.3095898628234863
Validation loss: 1.9834906529354792

Epoch: 5| Step: 7
Training loss: 2.558098316192627
Validation loss: 1.995276561347387

Epoch: 5| Step: 8
Training loss: 2.189239263534546
Validation loss: 1.9949044694182694

Epoch: 5| Step: 9
Training loss: 2.008838415145874
Validation loss: 1.99486328453146

Epoch: 5| Step: 10
Training loss: 2.2158043384552
Validation loss: 1.9987241683467742

Epoch: 127| Step: 0
Training loss: 2.4828076362609863
Validation loss: 2.0005516672647126

Epoch: 5| Step: 1
Training loss: 2.542095899581909
Validation loss: 1.9865704762038363

Epoch: 5| Step: 2
Training loss: 2.1442744731903076
Validation loss: 1.9939994068555935

Epoch: 5| Step: 3
Training loss: 2.167278528213501
Validation loss: 2.0092262619285175

Epoch: 5| Step: 4
Training loss: 2.5193710327148438
Validation loss: 2.0023878235970773

Epoch: 5| Step: 5
Training loss: 1.9257023334503174
Validation loss: 1.9922407570705618

Epoch: 5| Step: 6
Training loss: 1.8535274267196655
Validation loss: 1.9904016679333103

Epoch: 5| Step: 7
Training loss: 2.7841930389404297
Validation loss: 2.029830760853265

Epoch: 5| Step: 8
Training loss: 1.8840726613998413
Validation loss: 2.005258398671304

Epoch: 5| Step: 9
Training loss: 1.7762435674667358
Validation loss: 2.0100425097250167

Epoch: 5| Step: 10
Training loss: 2.0448265075683594
Validation loss: 2.0037132347783735

Epoch: 128| Step: 0
Training loss: 2.030216693878174
Validation loss: 2.027904111851928

Epoch: 5| Step: 1
Training loss: 2.2308685779571533
Validation loss: 2.0105736896555912

Epoch: 5| Step: 2
Training loss: 1.9884405136108398
Validation loss: 1.9930277973093011

Epoch: 5| Step: 3
Training loss: 2.219536066055298
Validation loss: 1.9832435730964906

Epoch: 5| Step: 4
Training loss: 2.246041774749756
Validation loss: 2.0190630125743088

Epoch: 5| Step: 5
Training loss: 2.477806568145752
Validation loss: 2.0086556224412817

Epoch: 5| Step: 6
Training loss: 1.8146018981933594
Validation loss: 1.9948351485754854

Epoch: 5| Step: 7
Training loss: 2.4690794944763184
Validation loss: 1.990858539458244

Epoch: 5| Step: 8
Training loss: 1.601156234741211
Validation loss: 1.988716979180613

Epoch: 5| Step: 9
Training loss: 2.964200496673584
Validation loss: 1.988220892926698

Epoch: 5| Step: 10
Training loss: 1.9640393257141113
Validation loss: 2.0018946945026355

Epoch: 129| Step: 0
Training loss: 2.2874443531036377
Validation loss: 1.9936702969253703

Epoch: 5| Step: 1
Training loss: 1.780718207359314
Validation loss: 1.980086830354506

Epoch: 5| Step: 2
Training loss: 1.7492592334747314
Validation loss: 1.978766200362995

Epoch: 5| Step: 3
Training loss: 2.0235040187835693
Validation loss: 1.9911311339306574

Epoch: 5| Step: 4
Training loss: 1.931314468383789
Validation loss: 1.9864772622303297

Epoch: 5| Step: 5
Training loss: 2.4381182193756104
Validation loss: 1.9652947289969331

Epoch: 5| Step: 6
Training loss: 2.327500581741333
Validation loss: 1.9696910471044562

Epoch: 5| Step: 7
Training loss: 2.2817463874816895
Validation loss: 1.966118593369761

Epoch: 5| Step: 8
Training loss: 2.6281189918518066
Validation loss: 1.9623707699519333

Epoch: 5| Step: 9
Training loss: 2.3309409618377686
Validation loss: 1.9566856020240373

Epoch: 5| Step: 10
Training loss: 2.2877705097198486
Validation loss: 1.9543846884081442

Epoch: 130| Step: 0
Training loss: 2.4734344482421875
Validation loss: 1.9777920592215754

Epoch: 5| Step: 1
Training loss: 1.8107092380523682
Validation loss: 1.9713780623610302

Epoch: 5| Step: 2
Training loss: 2.711601734161377
Validation loss: 1.9509403744051534

Epoch: 5| Step: 3
Training loss: 2.689290761947632
Validation loss: 1.9788691561709169

Epoch: 5| Step: 4
Training loss: 1.7520954608917236
Validation loss: 1.9868434911133142

Epoch: 5| Step: 5
Training loss: 2.349483013153076
Validation loss: 1.9704609276146017

Epoch: 5| Step: 6
Training loss: 1.665283203125
Validation loss: 1.9705075551104803

Epoch: 5| Step: 7
Training loss: 1.7929214239120483
Validation loss: 1.9894690090610134

Epoch: 5| Step: 8
Training loss: 2.7261812686920166
Validation loss: 1.9856579739560363

Epoch: 5| Step: 9
Training loss: 1.9238048791885376
Validation loss: 1.9855623168330039

Epoch: 5| Step: 10
Training loss: 2.014744520187378
Validation loss: 1.9947670916075348

Epoch: 131| Step: 0
Training loss: 1.873579740524292
Validation loss: 2.0194664847466255

Epoch: 5| Step: 1
Training loss: 1.5025502443313599
Validation loss: 2.0004287688962874

Epoch: 5| Step: 2
Training loss: 2.6186625957489014
Validation loss: 2.004129434144625

Epoch: 5| Step: 3
Training loss: 1.8411262035369873
Validation loss: 1.9808448463357904

Epoch: 5| Step: 4
Training loss: 2.781230926513672
Validation loss: 2.0025226582763014

Epoch: 5| Step: 5
Training loss: 2.5216798782348633
Validation loss: 1.9906438601914274

Epoch: 5| Step: 6
Training loss: 2.578105926513672
Validation loss: 2.0094207025343374

Epoch: 5| Step: 7
Training loss: 1.5168668031692505
Validation loss: 1.9746700281737952

Epoch: 5| Step: 8
Training loss: 2.274366617202759
Validation loss: 2.0007459655884774

Epoch: 5| Step: 9
Training loss: 2.1971116065979004
Validation loss: 1.9900394024387482

Epoch: 5| Step: 10
Training loss: 2.2186152935028076
Validation loss: 2.0036093893871514

Epoch: 132| Step: 0
Training loss: 2.5605506896972656
Validation loss: 1.9950363148925125

Epoch: 5| Step: 1
Training loss: 2.6658687591552734
Validation loss: 1.9967536849360312

Epoch: 5| Step: 2
Training loss: 2.310359239578247
Validation loss: 1.9897976665086643

Epoch: 5| Step: 3
Training loss: 2.3904378414154053
Validation loss: 1.9912925971451627

Epoch: 5| Step: 4
Training loss: 2.1300301551818848
Validation loss: 1.9791440643290037

Epoch: 5| Step: 5
Training loss: 1.9146919250488281
Validation loss: 1.9823379644783594

Epoch: 5| Step: 6
Training loss: 2.0608162879943848
Validation loss: 1.9774704787038988

Epoch: 5| Step: 7
Training loss: 2.0320651531219482
Validation loss: 1.9712580147609915

Epoch: 5| Step: 8
Training loss: 2.062525749206543
Validation loss: 1.9860821872629144

Epoch: 5| Step: 9
Training loss: 1.9470081329345703
Validation loss: 1.9752176051498742

Epoch: 5| Step: 10
Training loss: 1.8651913404464722
Validation loss: 2.0056852448371147

Epoch: 133| Step: 0
Training loss: 1.950523018836975
Validation loss: 1.9852741354255266

Epoch: 5| Step: 1
Training loss: 2.0490946769714355
Validation loss: 1.9899452732455345

Epoch: 5| Step: 2
Training loss: 2.414783000946045
Validation loss: 1.9862354314455422

Epoch: 5| Step: 3
Training loss: 1.825295090675354
Validation loss: 1.9896195268118253

Epoch: 5| Step: 4
Training loss: 2.098456621170044
Validation loss: 1.9966178350551154

Epoch: 5| Step: 5
Training loss: 3.0208218097686768
Validation loss: 2.0108700413857736

Epoch: 5| Step: 6
Training loss: 1.9494531154632568
Validation loss: 1.9862336984244726

Epoch: 5| Step: 7
Training loss: 2.229015588760376
Validation loss: 2.0151855073949343

Epoch: 5| Step: 8
Training loss: 2.29348087310791
Validation loss: 2.0070786117225565

Epoch: 5| Step: 9
Training loss: 1.8219707012176514
Validation loss: 2.003892262776693

Epoch: 5| Step: 10
Training loss: 2.3060271739959717
Validation loss: 2.001237802608039

Epoch: 134| Step: 0
Training loss: 2.299943208694458
Validation loss: 2.010565821842481

Epoch: 5| Step: 1
Training loss: 2.2348711490631104
Validation loss: 2.0053721474063013

Epoch: 5| Step: 2
Training loss: 2.506636381149292
Validation loss: 2.0097768640005462

Epoch: 5| Step: 3
Training loss: 1.984008550643921
Validation loss: 1.9892099595838977

Epoch: 5| Step: 4
Training loss: 2.634258270263672
Validation loss: 2.010724997007719

Epoch: 5| Step: 5
Training loss: 2.3255391120910645
Validation loss: 2.0058488999643633

Epoch: 5| Step: 6
Training loss: 2.294121742248535
Validation loss: 2.0117241362089753

Epoch: 5| Step: 7
Training loss: 2.3059635162353516
Validation loss: 2.0120634250743414

Epoch: 5| Step: 8
Training loss: 1.619539499282837
Validation loss: 2.0112336784280758

Epoch: 5| Step: 9
Training loss: 2.120274066925049
Validation loss: 2.002899487813314

Epoch: 5| Step: 10
Training loss: 1.5419973134994507
Validation loss: 1.9866282798910653

Epoch: 135| Step: 0
Training loss: 2.1591639518737793
Validation loss: 2.003717545540102

Epoch: 5| Step: 1
Training loss: 2.6413192749023438
Validation loss: 1.9768814861133535

Epoch: 5| Step: 2
Training loss: 1.6681734323501587
Validation loss: 1.9944391263428556

Epoch: 5| Step: 3
Training loss: 3.186469316482544
Validation loss: 2.0065458551529916

Epoch: 5| Step: 4
Training loss: 1.7358633279800415
Validation loss: 1.9956509631167176

Epoch: 5| Step: 5
Training loss: 1.639080286026001
Validation loss: 1.9751540050711682

Epoch: 5| Step: 6
Training loss: 2.2318930625915527
Validation loss: 1.986151993915599

Epoch: 5| Step: 7
Training loss: 2.313525676727295
Validation loss: 1.9759813944498699

Epoch: 5| Step: 8
Training loss: 2.0293688774108887
Validation loss: 1.9804153493655625

Epoch: 5| Step: 9
Training loss: 2.1097378730773926
Validation loss: 1.9918444413010792

Epoch: 5| Step: 10
Training loss: 2.183030605316162
Validation loss: 1.9964692951530538

Epoch: 136| Step: 0
Training loss: 1.8624706268310547
Validation loss: 1.9927378880080355

Epoch: 5| Step: 1
Training loss: 2.3226306438446045
Validation loss: 1.9867649821824924

Epoch: 5| Step: 2
Training loss: 2.072444438934326
Validation loss: 1.9925049299834876

Epoch: 5| Step: 3
Training loss: 1.8442742824554443
Validation loss: 2.0052176329397384

Epoch: 5| Step: 4
Training loss: 2.2526049613952637
Validation loss: 1.9958901443789083

Epoch: 5| Step: 5
Training loss: 2.301072835922241
Validation loss: 2.0067862925990934

Epoch: 5| Step: 6
Training loss: 1.6161296367645264
Validation loss: 2.000522344343124

Epoch: 5| Step: 7
Training loss: 2.093466281890869
Validation loss: 1.9963013843823505

Epoch: 5| Step: 8
Training loss: 2.3548667430877686
Validation loss: 1.999443748945831

Epoch: 5| Step: 9
Training loss: 2.4612910747528076
Validation loss: 2.0064926006460704

Epoch: 5| Step: 10
Training loss: 2.718909502029419
Validation loss: 1.995263079161285

Epoch: 137| Step: 0
Training loss: 1.7452621459960938
Validation loss: 1.9885855900344027

Epoch: 5| Step: 1
Training loss: 2.3283543586730957
Validation loss: 1.9794541674275552

Epoch: 5| Step: 2
Training loss: 1.7167774438858032
Validation loss: 1.9943074052051832

Epoch: 5| Step: 3
Training loss: 1.9117310047149658
Validation loss: 2.003510541813348

Epoch: 5| Step: 4
Training loss: 2.476992130279541
Validation loss: 1.9658329281755673

Epoch: 5| Step: 5
Training loss: 2.773646593093872
Validation loss: 1.9991212737175725

Epoch: 5| Step: 6
Training loss: 2.0282349586486816
Validation loss: 1.969710555127872

Epoch: 5| Step: 7
Training loss: 2.237001419067383
Validation loss: 1.9734170898314445

Epoch: 5| Step: 8
Training loss: 2.037273406982422
Validation loss: 1.9657909383055985

Epoch: 5| Step: 9
Training loss: 1.7415316104888916
Validation loss: 1.9739627261315622

Epoch: 5| Step: 10
Training loss: 2.930807113647461
Validation loss: 1.980563525230654

Epoch: 138| Step: 0
Training loss: 1.980234146118164
Validation loss: 1.9778162381982292

Epoch: 5| Step: 1
Training loss: 2.1165518760681152
Validation loss: 1.9752444733855545

Epoch: 5| Step: 2
Training loss: 2.108604669570923
Validation loss: 1.9658060150761758

Epoch: 5| Step: 3
Training loss: 2.0833873748779297
Validation loss: 1.9643454244059901

Epoch: 5| Step: 4
Training loss: 3.3806393146514893
Validation loss: 1.9765484525311379

Epoch: 5| Step: 5
Training loss: 2.181506633758545
Validation loss: 1.9819798110633768

Epoch: 5| Step: 6
Training loss: 2.292248487472534
Validation loss: 1.9859360007829563

Epoch: 5| Step: 7
Training loss: 2.1594038009643555
Validation loss: 1.9781105249158797

Epoch: 5| Step: 8
Training loss: 1.8986890316009521
Validation loss: 1.9862877450963503

Epoch: 5| Step: 9
Training loss: 1.9304654598236084
Validation loss: 1.9640862813559912

Epoch: 5| Step: 10
Training loss: 1.6736356019973755
Validation loss: 1.9723462186833864

Epoch: 139| Step: 0
Training loss: 2.4351181983947754
Validation loss: 1.9963276129896923

Epoch: 5| Step: 1
Training loss: 1.9015592336654663
Validation loss: 1.9672833693924772

Epoch: 5| Step: 2
Training loss: 2.529245615005493
Validation loss: 1.9742091035330167

Epoch: 5| Step: 3
Training loss: 1.959882140159607
Validation loss: 1.9628536560202157

Epoch: 5| Step: 4
Training loss: 2.012479305267334
Validation loss: 1.9673898245698662

Epoch: 5| Step: 5
Training loss: 2.8949339389801025
Validation loss: 1.985400064017183

Epoch: 5| Step: 6
Training loss: 1.889853835105896
Validation loss: 1.9847155232583322

Epoch: 5| Step: 7
Training loss: 2.086256742477417
Validation loss: 1.9912728571122693

Epoch: 5| Step: 8
Training loss: 1.9364421367645264
Validation loss: 2.0123082078913206

Epoch: 5| Step: 9
Training loss: 1.83693528175354
Validation loss: 1.985528967713797

Epoch: 5| Step: 10
Training loss: 2.2898972034454346
Validation loss: 2.0027670885926936

Epoch: 140| Step: 0
Training loss: 2.2524638175964355
Validation loss: 2.002268337434338

Epoch: 5| Step: 1
Training loss: 1.7743446826934814
Validation loss: 1.9899589246319187

Epoch: 5| Step: 2
Training loss: 2.2638700008392334
Validation loss: 2.0101282968316028

Epoch: 5| Step: 3
Training loss: 2.3004775047302246
Validation loss: 1.9926674686452395

Epoch: 5| Step: 4
Training loss: 2.1685564517974854
Validation loss: 2.0082150825890164

Epoch: 5| Step: 5
Training loss: 1.8890771865844727
Validation loss: 2.022162668166622

Epoch: 5| Step: 6
Training loss: 2.5987586975097656
Validation loss: 2.0033095549511653

Epoch: 5| Step: 7
Training loss: 2.2056503295898438
Validation loss: 2.0005580763663016

Epoch: 5| Step: 8
Training loss: 2.265336513519287
Validation loss: 2.028739998417516

Epoch: 5| Step: 9
Training loss: 1.8164478540420532
Validation loss: 2.0132953505362234

Epoch: 5| Step: 10
Training loss: 2.2810676097869873
Validation loss: 2.0060400655192714

Epoch: 141| Step: 0
Training loss: 2.39516019821167
Validation loss: 1.9848798321139427

Epoch: 5| Step: 1
Training loss: 1.7609550952911377
Validation loss: 2.000898368896977

Epoch: 5| Step: 2
Training loss: 2.0976014137268066
Validation loss: 2.011676279447412

Epoch: 5| Step: 3
Training loss: 2.4153542518615723
Validation loss: 2.0254608174806

Epoch: 5| Step: 4
Training loss: 2.5646939277648926
Validation loss: 2.0031831661860147

Epoch: 5| Step: 5
Training loss: 1.897142767906189
Validation loss: 1.9984215408243158

Epoch: 5| Step: 6
Training loss: 2.1304712295532227
Validation loss: 1.9983011445691508

Epoch: 5| Step: 7
Training loss: 2.2270779609680176
Validation loss: 1.9983638858282438

Epoch: 5| Step: 8
Training loss: 1.6465027332305908
Validation loss: 2.0152342114397275

Epoch: 5| Step: 9
Training loss: 2.5869038105010986
Validation loss: 1.9990110115338398

Epoch: 5| Step: 10
Training loss: 1.8876793384552002
Validation loss: 1.9756523460470221

Epoch: 142| Step: 0
Training loss: 2.4569170475006104
Validation loss: 1.9888126773218955

Epoch: 5| Step: 1
Training loss: 2.269866466522217
Validation loss: 1.9917112755519089

Epoch: 5| Step: 2
Training loss: 1.7152385711669922
Validation loss: 1.9719001272673249

Epoch: 5| Step: 3
Training loss: 2.3269476890563965
Validation loss: 1.972682858026156

Epoch: 5| Step: 4
Training loss: 2.0458626747131348
Validation loss: 1.9775320047973304

Epoch: 5| Step: 5
Training loss: 2.401872158050537
Validation loss: 1.9590923837436143

Epoch: 5| Step: 6
Training loss: 2.0387885570526123
Validation loss: 1.9704573615904777

Epoch: 5| Step: 7
Training loss: 1.5630335807800293
Validation loss: 1.9838313646213983

Epoch: 5| Step: 8
Training loss: 2.3236942291259766
Validation loss: 1.9657035014962638

Epoch: 5| Step: 9
Training loss: 2.0924861431121826
Validation loss: 1.9656686180381364

Epoch: 5| Step: 10
Training loss: 2.693096399307251
Validation loss: 1.9737471790723904

Epoch: 143| Step: 0
Training loss: 2.558387517929077
Validation loss: 2.003699729519506

Epoch: 5| Step: 1
Training loss: 1.9090592861175537
Validation loss: 1.9756267429679952

Epoch: 5| Step: 2
Training loss: 2.466944456100464
Validation loss: 1.974155818262408

Epoch: 5| Step: 3
Training loss: 1.9919140338897705
Validation loss: 1.9813805985194382

Epoch: 5| Step: 4
Training loss: 1.7863069772720337
Validation loss: 1.998881447699762

Epoch: 5| Step: 5
Training loss: 1.8406976461410522
Validation loss: 1.984365620920735

Epoch: 5| Step: 6
Training loss: 2.1077234745025635
Validation loss: 1.9765106401135843

Epoch: 5| Step: 7
Training loss: 2.2341506481170654
Validation loss: 1.9914611283168997

Epoch: 5| Step: 8
Training loss: 2.4384257793426514
Validation loss: 1.979001925837609

Epoch: 5| Step: 9
Training loss: 2.0512938499450684
Validation loss: 1.9719222412314465

Epoch: 5| Step: 10
Training loss: 2.555495262145996
Validation loss: 1.990757115425602

Epoch: 144| Step: 0
Training loss: 2.2471415996551514
Validation loss: 2.003044879564675

Epoch: 5| Step: 1
Training loss: 2.2355475425720215
Validation loss: 1.9851404069572367

Epoch: 5| Step: 2
Training loss: 2.432396411895752
Validation loss: 1.9789857351651756

Epoch: 5| Step: 3
Training loss: 2.1961681842803955
Validation loss: 1.9982504998483965

Epoch: 5| Step: 4
Training loss: 1.5539579391479492
Validation loss: 1.978709779759889

Epoch: 5| Step: 5
Training loss: 2.4255032539367676
Validation loss: 1.9734346379515946

Epoch: 5| Step: 6
Training loss: 2.1880927085876465
Validation loss: 2.006341632976327

Epoch: 5| Step: 7
Training loss: 1.8427059650421143
Validation loss: 2.0075802085220174

Epoch: 5| Step: 8
Training loss: 1.9859650135040283
Validation loss: 1.990182553568194

Epoch: 5| Step: 9
Training loss: 2.1649606227874756
Validation loss: 1.990349736264957

Epoch: 5| Step: 10
Training loss: 2.3857953548431396
Validation loss: 2.0000438395366875

Epoch: 145| Step: 0
Training loss: 2.384019136428833
Validation loss: 1.986765476965135

Epoch: 5| Step: 1
Training loss: 2.225201368331909
Validation loss: 1.9933962232323104

Epoch: 5| Step: 2
Training loss: 1.9036662578582764
Validation loss: 1.976033080008722

Epoch: 5| Step: 3
Training loss: 2.2414517402648926
Validation loss: 2.0028274059295654

Epoch: 5| Step: 4
Training loss: 1.8757619857788086
Validation loss: 1.9963428435787078

Epoch: 5| Step: 5
Training loss: 2.4345009326934814
Validation loss: 2.0030571850397254

Epoch: 5| Step: 6
Training loss: 2.0858261585235596
Validation loss: 1.9995149771372478

Epoch: 5| Step: 7
Training loss: 2.0950677394866943
Validation loss: 1.979844448386982

Epoch: 5| Step: 8
Training loss: 2.915512800216675
Validation loss: 2.0018361845324115

Epoch: 5| Step: 9
Training loss: 1.8817729949951172
Validation loss: 1.985884980488849

Epoch: 5| Step: 10
Training loss: 1.534083366394043
Validation loss: 2.0185689054509646

Epoch: 146| Step: 0
Training loss: 2.2319583892822266
Validation loss: 1.9997111623005202

Epoch: 5| Step: 1
Training loss: 1.5259523391723633
Validation loss: 1.9971993264331613

Epoch: 5| Step: 2
Training loss: 2.018366575241089
Validation loss: 1.9925296832156438

Epoch: 5| Step: 3
Training loss: 2.220795154571533
Validation loss: 2.005987710850213

Epoch: 5| Step: 4
Training loss: 1.6420694589614868
Validation loss: 1.9811540367782756

Epoch: 5| Step: 5
Training loss: 2.843266725540161
Validation loss: 1.9941353554366736

Epoch: 5| Step: 6
Training loss: 1.8182216882705688
Validation loss: 1.9854552207454559

Epoch: 5| Step: 7
Training loss: 2.4308574199676514
Validation loss: 1.965259313583374

Epoch: 5| Step: 8
Training loss: 2.1010212898254395
Validation loss: 1.9735482200499503

Epoch: 5| Step: 9
Training loss: 2.565851926803589
Validation loss: 1.9750240131091046

Epoch: 5| Step: 10
Training loss: 2.143021821975708
Validation loss: 1.971459052895987

Epoch: 147| Step: 0
Training loss: 2.17427396774292
Validation loss: 1.9763296445210774

Epoch: 5| Step: 1
Training loss: 1.8995434045791626
Validation loss: 1.9788511901773431

Epoch: 5| Step: 2
Training loss: 2.114434003829956
Validation loss: 1.9832867089138235

Epoch: 5| Step: 3
Training loss: 2.2973105907440186
Validation loss: 1.9777955726910663

Epoch: 5| Step: 4
Training loss: 2.201810359954834
Validation loss: 1.9873050412824076

Epoch: 5| Step: 5
Training loss: 2.30423641204834
Validation loss: 2.0043742541343934

Epoch: 5| Step: 6
Training loss: 2.2622649669647217
Validation loss: 1.9898250487542921

Epoch: 5| Step: 7
Training loss: 2.080226182937622
Validation loss: 1.9780192811002013

Epoch: 5| Step: 8
Training loss: 2.0054707527160645
Validation loss: 2.0069011539541264

Epoch: 5| Step: 9
Training loss: 2.2182250022888184
Validation loss: 2.0025211136828185

Epoch: 5| Step: 10
Training loss: 2.1234824657440186
Validation loss: 1.989437695472471

Epoch: 148| Step: 0
Training loss: 2.1592631340026855
Validation loss: 1.991494345408614

Epoch: 5| Step: 1
Training loss: 1.6920557022094727
Validation loss: 1.9873693591804915

Epoch: 5| Step: 2
Training loss: 2.7607810497283936
Validation loss: 1.9935891935902257

Epoch: 5| Step: 3
Training loss: 2.244971513748169
Validation loss: 1.9962471223646594

Epoch: 5| Step: 4
Training loss: 1.8802601099014282
Validation loss: 2.0119743770168674

Epoch: 5| Step: 5
Training loss: 2.06870174407959
Validation loss: 1.9830494952458206

Epoch: 5| Step: 6
Training loss: 2.0769200325012207
Validation loss: 2.008751671801331

Epoch: 5| Step: 7
Training loss: 1.983449935913086
Validation loss: 1.9909568627675374

Epoch: 5| Step: 8
Training loss: 1.9862754344940186
Validation loss: 1.982142145915698

Epoch: 5| Step: 9
Training loss: 2.2506837844848633
Validation loss: 1.9844916789762435

Epoch: 5| Step: 10
Training loss: 2.6159961223602295
Validation loss: 1.9887135541567238

Epoch: 149| Step: 0
Training loss: 2.1693313121795654
Validation loss: 2.0051298218388713

Epoch: 5| Step: 1
Training loss: 2.459998369216919
Validation loss: 2.004671571075275

Epoch: 5| Step: 2
Training loss: 2.356147289276123
Validation loss: 2.001915107491196

Epoch: 5| Step: 3
Training loss: 1.8357919454574585
Validation loss: 1.9985235609034055

Epoch: 5| Step: 4
Training loss: 1.8531259298324585
Validation loss: 2.007295895648259

Epoch: 5| Step: 5
Training loss: 2.759575366973877
Validation loss: 1.977325875272033

Epoch: 5| Step: 6
Training loss: 1.3579972982406616
Validation loss: 1.996884963845694

Epoch: 5| Step: 7
Training loss: 1.7937504053115845
Validation loss: 2.0021240903485205

Epoch: 5| Step: 8
Training loss: 2.7101173400878906
Validation loss: 1.9955754190362909

Epoch: 5| Step: 9
Training loss: 1.9997743368148804
Validation loss: 2.0034458291146064

Epoch: 5| Step: 10
Training loss: 2.422067642211914
Validation loss: 1.9931554768675117

Epoch: 150| Step: 0
Training loss: 1.999098777770996
Validation loss: 1.9876065459302676

Epoch: 5| Step: 1
Training loss: 1.981670618057251
Validation loss: 1.9816487322571457

Epoch: 5| Step: 2
Training loss: 2.3476688861846924
Validation loss: 1.9963819929348525

Epoch: 5| Step: 3
Training loss: 1.9420573711395264
Validation loss: 2.001517759856357

Epoch: 5| Step: 4
Training loss: 2.440629243850708
Validation loss: 2.0080033899635397

Epoch: 5| Step: 5
Training loss: 2.268223285675049
Validation loss: 2.0018139244407736

Epoch: 5| Step: 6
Training loss: 2.086451768875122
Validation loss: 1.9760781411201722

Epoch: 5| Step: 7
Training loss: 2.335338830947876
Validation loss: 1.9824827589014524

Epoch: 5| Step: 8
Training loss: 2.0099143981933594
Validation loss: 1.99919593334198

Epoch: 5| Step: 9
Training loss: 1.746824860572815
Validation loss: 2.0021236788841987

Epoch: 5| Step: 10
Training loss: 2.6114892959594727
Validation loss: 1.99747759039684

Epoch: 151| Step: 0
Training loss: 1.8444139957427979
Validation loss: 1.9870069552493352

Epoch: 5| Step: 1
Training loss: 2.2721710205078125
Validation loss: 2.0091685018231793

Epoch: 5| Step: 2
Training loss: 2.1516287326812744
Validation loss: 1.992263114580544

Epoch: 5| Step: 3
Training loss: 1.3007094860076904
Validation loss: 1.9979078154410086

Epoch: 5| Step: 4
Training loss: 2.283069610595703
Validation loss: 2.0027700457521664

Epoch: 5| Step: 5
Training loss: 1.965336799621582
Validation loss: 1.9911594801051642

Epoch: 5| Step: 6
Training loss: 2.4576382637023926
Validation loss: 1.9873655483286867

Epoch: 5| Step: 7
Training loss: 2.4561171531677246
Validation loss: 1.9796117274991927

Epoch: 5| Step: 8
Training loss: 2.1713485717773438
Validation loss: 1.9900817614729687

Epoch: 5| Step: 9
Training loss: 1.9702796936035156
Validation loss: 1.9943523432618828

Epoch: 5| Step: 10
Training loss: 2.851646900177002
Validation loss: 1.9605734707206808

Epoch: 152| Step: 0
Training loss: 1.480810523033142
Validation loss: 1.9757310075144614

Epoch: 5| Step: 1
Training loss: 1.9198925495147705
Validation loss: 2.014841374530587

Epoch: 5| Step: 2
Training loss: 2.2859749794006348
Validation loss: 1.9976667229847243

Epoch: 5| Step: 3
Training loss: 2.0879738330841064
Validation loss: 2.001213950495566

Epoch: 5| Step: 4
Training loss: 2.1846840381622314
Validation loss: 1.9981810751781668

Epoch: 5| Step: 5
Training loss: 2.5157876014709473
Validation loss: 2.0028856864539524

Epoch: 5| Step: 6
Training loss: 2.0419015884399414
Validation loss: 2.004210933562248

Epoch: 5| Step: 7
Training loss: 1.896410346031189
Validation loss: 2.0088516127678657

Epoch: 5| Step: 8
Training loss: 2.6743476390838623
Validation loss: 2.016995737629552

Epoch: 5| Step: 9
Training loss: 2.212379217147827
Validation loss: 2.006721831137134

Epoch: 5| Step: 10
Training loss: 2.3251466751098633
Validation loss: 2.0206915370879637

Epoch: 153| Step: 0
Training loss: 1.922732949256897
Validation loss: 2.016649817907682

Epoch: 5| Step: 1
Training loss: 1.800296425819397
Validation loss: 2.027817846626364

Epoch: 5| Step: 2
Training loss: 2.6744706630706787
Validation loss: 2.0287620713633876

Epoch: 5| Step: 3
Training loss: 2.3735527992248535
Validation loss: 2.0340804617892028

Epoch: 5| Step: 4
Training loss: 1.8856210708618164
Validation loss: 2.022114235867736

Epoch: 5| Step: 5
Training loss: 2.281859874725342
Validation loss: 2.0210806169817523

Epoch: 5| Step: 6
Training loss: 2.4753754138946533
Validation loss: 2.0211017080532607

Epoch: 5| Step: 7
Training loss: 2.297475814819336
Validation loss: 2.0406923268430974

Epoch: 5| Step: 8
Training loss: 2.1276166439056396
Validation loss: 2.042999008650421

Epoch: 5| Step: 9
Training loss: 1.6666033267974854
Validation loss: 2.0255013947845786

Epoch: 5| Step: 10
Training loss: 2.1052966117858887
Validation loss: 2.0326826905691497

Epoch: 154| Step: 0
Training loss: 1.4060720205307007
Validation loss: 1.9973282326934159

Epoch: 5| Step: 1
Training loss: 2.1210150718688965
Validation loss: 2.0212170654727566

Epoch: 5| Step: 2
Training loss: 2.15514874458313
Validation loss: 2.004261535982932

Epoch: 5| Step: 3
Training loss: 1.6582603454589844
Validation loss: 2.0073443138471214

Epoch: 5| Step: 4
Training loss: 2.699322462081909
Validation loss: 2.008545519203268

Epoch: 5| Step: 5
Training loss: 1.8748579025268555
Validation loss: 1.9961935217662523

Epoch: 5| Step: 6
Training loss: 2.3284895420074463
Validation loss: 2.002582651312633

Epoch: 5| Step: 7
Training loss: 2.3452839851379395
Validation loss: 1.9857044117425078

Epoch: 5| Step: 8
Training loss: 2.667591094970703
Validation loss: 1.974461801590458

Epoch: 5| Step: 9
Training loss: 2.1784369945526123
Validation loss: 1.9681470650498585

Epoch: 5| Step: 10
Training loss: 2.1441009044647217
Validation loss: 1.959208091100057

Epoch: 155| Step: 0
Training loss: 2.6607108116149902
Validation loss: 1.9753171192702426

Epoch: 5| Step: 1
Training loss: 2.283346652984619
Validation loss: 1.9921888894932245

Epoch: 5| Step: 2
Training loss: 1.0335607528686523
Validation loss: 1.9839631652319303

Epoch: 5| Step: 3
Training loss: 2.1344473361968994
Validation loss: 1.983002644713207

Epoch: 5| Step: 4
Training loss: 2.1507482528686523
Validation loss: 1.9771047202489709

Epoch: 5| Step: 5
Training loss: 2.6808547973632812
Validation loss: 1.97579163377003

Epoch: 5| Step: 6
Training loss: 2.396920680999756
Validation loss: 1.9676927558837398

Epoch: 5| Step: 7
Training loss: 1.8435243368148804
Validation loss: 1.9828913916823685

Epoch: 5| Step: 8
Training loss: 2.144056797027588
Validation loss: 1.960656330149661

Epoch: 5| Step: 9
Training loss: 1.8575198650360107
Validation loss: 1.9745967900881203

Epoch: 5| Step: 10
Training loss: 2.455327033996582
Validation loss: 1.9615632359699537

Epoch: 156| Step: 0
Training loss: 1.998051404953003
Validation loss: 1.9689604108051588

Epoch: 5| Step: 1
Training loss: 2.1977200508117676
Validation loss: 1.9528677668622745

Epoch: 5| Step: 2
Training loss: 1.7380104064941406
Validation loss: 1.9971755960936188

Epoch: 5| Step: 3
Training loss: 2.373910427093506
Validation loss: 1.9705819596526444

Epoch: 5| Step: 4
Training loss: 2.2860474586486816
Validation loss: 1.959830887856022

Epoch: 5| Step: 5
Training loss: 1.2860950231552124
Validation loss: 1.9527323963821575

Epoch: 5| Step: 6
Training loss: 2.973876953125
Validation loss: 1.9599620808837235

Epoch: 5| Step: 7
Training loss: 2.367218494415283
Validation loss: 1.9847651130409651

Epoch: 5| Step: 8
Training loss: 2.287457227706909
Validation loss: 1.9890123195545648

Epoch: 5| Step: 9
Training loss: 2.401170253753662
Validation loss: 1.9979370422260736

Epoch: 5| Step: 10
Training loss: 1.7546833753585815
Validation loss: 1.9853243392000917

Epoch: 157| Step: 0
Training loss: 2.406406879425049
Validation loss: 1.9749987612488449

Epoch: 5| Step: 1
Training loss: 2.4917361736297607
Validation loss: 1.9888769144652991

Epoch: 5| Step: 2
Training loss: 1.7295945882797241
Validation loss: 1.9951333409996443

Epoch: 5| Step: 3
Training loss: 2.6069257259368896
Validation loss: 1.9966893503742833

Epoch: 5| Step: 4
Training loss: 1.9061416387557983
Validation loss: 2.0125180495682584

Epoch: 5| Step: 5
Training loss: 1.225134015083313
Validation loss: 2.0061776202212096

Epoch: 5| Step: 6
Training loss: 2.4617507457733154
Validation loss: 2.0157583759677027

Epoch: 5| Step: 7
Training loss: 3.052135467529297
Validation loss: 1.9904065773051272

Epoch: 5| Step: 8
Training loss: 1.8624675273895264
Validation loss: 2.015805431591567

Epoch: 5| Step: 9
Training loss: 2.075909376144409
Validation loss: 2.011699758550172

Epoch: 5| Step: 10
Training loss: 1.6569452285766602
Validation loss: 2.0154260871230916

Epoch: 158| Step: 0
Training loss: 2.1369833946228027
Validation loss: 2.0348845758745746

Epoch: 5| Step: 1
Training loss: 2.0136454105377197
Validation loss: 2.020867081098659

Epoch: 5| Step: 2
Training loss: 2.6670193672180176
Validation loss: 2.0222329811383317

Epoch: 5| Step: 3
Training loss: 2.136690139770508
Validation loss: 2.0163990015624673

Epoch: 5| Step: 4
Training loss: 2.2450637817382812
Validation loss: 2.0245340293453586

Epoch: 5| Step: 5
Training loss: 2.3599536418914795
Validation loss: 2.005296899426368

Epoch: 5| Step: 6
Training loss: 2.083057165145874
Validation loss: 2.0145035315585393

Epoch: 5| Step: 7
Training loss: 1.8320567607879639
Validation loss: 2.002852088661604

Epoch: 5| Step: 8
Training loss: 2.531301498413086
Validation loss: 2.0120994737071376

Epoch: 5| Step: 9
Training loss: 1.5906531810760498
Validation loss: 2.012734825893115

Epoch: 5| Step: 10
Training loss: 1.8307828903198242
Validation loss: 2.014210060078611

Epoch: 159| Step: 0
Training loss: 2.4788646697998047
Validation loss: 2.027867001871909

Epoch: 5| Step: 1
Training loss: 2.1874451637268066
Validation loss: 2.0030957152766566

Epoch: 5| Step: 2
Training loss: 2.5058348178863525
Validation loss: 1.9975885883454354

Epoch: 5| Step: 3
Training loss: 1.9240554571151733
Validation loss: 1.9835430011954358

Epoch: 5| Step: 4
Training loss: 1.7615890502929688
Validation loss: 1.990315652662708

Epoch: 5| Step: 5
Training loss: 2.418041229248047
Validation loss: 1.9711725891277354

Epoch: 5| Step: 6
Training loss: 2.6656365394592285
Validation loss: 2.0003150970705095

Epoch: 5| Step: 7
Training loss: 2.5591368675231934
Validation loss: 1.9787176962821715

Epoch: 5| Step: 8
Training loss: 1.974439024925232
Validation loss: 1.9633288229665449

Epoch: 5| Step: 9
Training loss: 1.6371463537216187
Validation loss: 1.9741492630333028

Epoch: 5| Step: 10
Training loss: 1.2893259525299072
Validation loss: 1.9990323794785367

Epoch: 160| Step: 0
Training loss: 2.9910385608673096
Validation loss: 1.9797202194890668

Epoch: 5| Step: 1
Training loss: 2.7236273288726807
Validation loss: 1.9828035549450946

Epoch: 5| Step: 2
Training loss: 1.6958459615707397
Validation loss: 1.9865730295899093

Epoch: 5| Step: 3
Training loss: 1.639880895614624
Validation loss: 1.986094141519198

Epoch: 5| Step: 4
Training loss: 2.5801918506622314
Validation loss: 1.977527133880123

Epoch: 5| Step: 5
Training loss: 2.5171782970428467
Validation loss: 2.0017534609763854

Epoch: 5| Step: 6
Training loss: 2.0271339416503906
Validation loss: 1.994274047113234

Epoch: 5| Step: 7
Training loss: 2.080941677093506
Validation loss: 1.980456780361873

Epoch: 5| Step: 8
Training loss: 1.288334608078003
Validation loss: 1.9805711802615915

Epoch: 5| Step: 9
Training loss: 1.7446823120117188
Validation loss: 1.965426379634488

Epoch: 5| Step: 10
Training loss: 2.1497609615325928
Validation loss: 2.0021590930159374

Epoch: 161| Step: 0
Training loss: 2.3144993782043457
Validation loss: 1.9897571379138577

Epoch: 5| Step: 1
Training loss: 1.9504883289337158
Validation loss: 1.979014091594245

Epoch: 5| Step: 2
Training loss: 2.1571788787841797
Validation loss: 1.9821230583293463

Epoch: 5| Step: 3
Training loss: 2.337493419647217
Validation loss: 2.0158209646901777

Epoch: 5| Step: 4
Training loss: 1.7130239009857178
Validation loss: 1.984448771322927

Epoch: 5| Step: 5
Training loss: 1.6313419342041016
Validation loss: 2.0251294374465942

Epoch: 5| Step: 6
Training loss: 2.462324857711792
Validation loss: 2.0095966823639406

Epoch: 5| Step: 7
Training loss: 2.3309006690979004
Validation loss: 2.004756026370551

Epoch: 5| Step: 8
Training loss: 2.020947217941284
Validation loss: 1.990617613638601

Epoch: 5| Step: 9
Training loss: 2.231092929840088
Validation loss: 1.9918011567925895

Epoch: 5| Step: 10
Training loss: 2.249943256378174
Validation loss: 2.0193025924826182

Epoch: 162| Step: 0
Training loss: 2.514953136444092
Validation loss: 1.9755263559279903

Epoch: 5| Step: 1
Training loss: 1.9695167541503906
Validation loss: 2.0189100811558385

Epoch: 5| Step: 2
Training loss: 1.8956215381622314
Validation loss: 1.998748610096593

Epoch: 5| Step: 3
Training loss: 2.5178306102752686
Validation loss: 2.0125357207431587

Epoch: 5| Step: 4
Training loss: 2.03955340385437
Validation loss: 1.9932216649414392

Epoch: 5| Step: 5
Training loss: 2.271315336227417
Validation loss: 1.9924429590984056

Epoch: 5| Step: 6
Training loss: 1.8978052139282227
Validation loss: 1.9908878649434736

Epoch: 5| Step: 7
Training loss: 2.2251267433166504
Validation loss: 2.000089886367962

Epoch: 5| Step: 8
Training loss: 1.6456756591796875
Validation loss: 1.9934144096989785

Epoch: 5| Step: 9
Training loss: 2.500303268432617
Validation loss: 1.9981995577453284

Epoch: 5| Step: 10
Training loss: 1.9439966678619385
Validation loss: 2.013213506308935

Epoch: 163| Step: 0
Training loss: 2.0368590354919434
Validation loss: 1.9914808862952775

Epoch: 5| Step: 1
Training loss: 1.6944715976715088
Validation loss: 1.9987655403793498

Epoch: 5| Step: 2
Training loss: 2.0105838775634766
Validation loss: 2.0141057865594023

Epoch: 5| Step: 3
Training loss: 2.619917154312134
Validation loss: 1.9859174092610676

Epoch: 5| Step: 4
Training loss: 2.420468807220459
Validation loss: 1.9977747830011512

Epoch: 5| Step: 5
Training loss: 1.7976592779159546
Validation loss: 1.9973932414926507

Epoch: 5| Step: 6
Training loss: 2.0536274909973145
Validation loss: 1.9849524433894823

Epoch: 5| Step: 7
Training loss: 1.9237396717071533
Validation loss: 1.9865180138618714

Epoch: 5| Step: 8
Training loss: 2.542463541030884
Validation loss: 2.007491462974138

Epoch: 5| Step: 9
Training loss: 2.095776319503784
Validation loss: 1.9843793992073304

Epoch: 5| Step: 10
Training loss: 2.108814239501953
Validation loss: 1.984817058809342

Epoch: 164| Step: 0
Training loss: 2.0789732933044434
Validation loss: 1.9786340395609539

Epoch: 5| Step: 1
Training loss: 2.1270384788513184
Validation loss: 2.002213598579489

Epoch: 5| Step: 2
Training loss: 2.370490074157715
Validation loss: 2.0003134947951122

Epoch: 5| Step: 3
Training loss: 2.730246067047119
Validation loss: 1.9962020458713654

Epoch: 5| Step: 4
Training loss: 2.1746013164520264
Validation loss: 1.9959900327908096

Epoch: 5| Step: 5
Training loss: 2.2450108528137207
Validation loss: 2.000488782441744

Epoch: 5| Step: 6
Training loss: 2.0179190635681152
Validation loss: 2.0172678962830575

Epoch: 5| Step: 7
Training loss: 1.9076688289642334
Validation loss: 2.0035145616018646

Epoch: 5| Step: 8
Training loss: 1.5495678186416626
Validation loss: 2.0182465327683317

Epoch: 5| Step: 9
Training loss: 1.870862364768982
Validation loss: 2.0360623482734925

Epoch: 5| Step: 10
Training loss: 2.4357049465179443
Validation loss: 2.0099485587048274

Epoch: 165| Step: 0
Training loss: 2.056974411010742
Validation loss: 2.0138941939159105

Epoch: 5| Step: 1
Training loss: 2.1982836723327637
Validation loss: 1.9978080564929592

Epoch: 5| Step: 2
Training loss: 2.36738920211792
Validation loss: 2.0124753662334975

Epoch: 5| Step: 3
Training loss: 2.1635794639587402
Validation loss: 1.990150938751877

Epoch: 5| Step: 4
Training loss: 2.701044797897339
Validation loss: 2.001551148711994

Epoch: 5| Step: 5
Training loss: 2.1813900470733643
Validation loss: 2.003294434598697

Epoch: 5| Step: 6
Training loss: 1.4810457229614258
Validation loss: 1.995268367951916

Epoch: 5| Step: 7
Training loss: 2.246018171310425
Validation loss: 2.006238801504976

Epoch: 5| Step: 8
Training loss: 2.532166004180908
Validation loss: 2.004355994603967

Epoch: 5| Step: 9
Training loss: 1.895037293434143
Validation loss: 1.988766780463598

Epoch: 5| Step: 10
Training loss: 1.5785191059112549
Validation loss: 2.0095603696761595

Epoch: 166| Step: 0
Training loss: 2.6453540325164795
Validation loss: 2.008804000833983

Epoch: 5| Step: 1
Training loss: 2.185041666030884
Validation loss: 2.001645435569107

Epoch: 5| Step: 2
Training loss: 2.5940651893615723
Validation loss: 1.9934437018568798

Epoch: 5| Step: 3
Training loss: 1.9534965753555298
Validation loss: 2.0030072491656066

Epoch: 5| Step: 4
Training loss: 2.3211779594421387
Validation loss: 2.027459516320177

Epoch: 5| Step: 5
Training loss: 1.781374216079712
Validation loss: 2.0210575903615644

Epoch: 5| Step: 6
Training loss: 1.7130733728408813
Validation loss: 2.0273405121218775

Epoch: 5| Step: 7
Training loss: 1.8916645050048828
Validation loss: 2.011608151979344

Epoch: 5| Step: 8
Training loss: 1.8678830862045288
Validation loss: 2.026532793557772

Epoch: 5| Step: 9
Training loss: 2.6653730869293213
Validation loss: 2.0256742892726773

Epoch: 5| Step: 10
Training loss: 1.7479580640792847
Validation loss: 2.0050746907470045

Epoch: 167| Step: 0
Training loss: 2.1115291118621826
Validation loss: 2.0015069182201097

Epoch: 5| Step: 1
Training loss: 1.6282424926757812
Validation loss: 2.0187660007066626

Epoch: 5| Step: 2
Training loss: 2.4371211528778076
Validation loss: 2.0038904272099978

Epoch: 5| Step: 3
Training loss: 2.710948944091797
Validation loss: 2.005620247574263

Epoch: 5| Step: 4
Training loss: 1.9020490646362305
Validation loss: 1.9983513662892003

Epoch: 5| Step: 5
Training loss: 2.0920777320861816
Validation loss: 1.9942240599663026

Epoch: 5| Step: 6
Training loss: 2.027937650680542
Validation loss: 1.9846613227680165

Epoch: 5| Step: 7
Training loss: 2.326463460922241
Validation loss: 1.9780118657696633

Epoch: 5| Step: 8
Training loss: 2.1153292655944824
Validation loss: 1.9641470422026932

Epoch: 5| Step: 9
Training loss: 2.086026668548584
Validation loss: 1.9851963571322861

Epoch: 5| Step: 10
Training loss: 1.8601940870285034
Validation loss: 1.9672463004307081

Epoch: 168| Step: 0
Training loss: 1.6445773839950562
Validation loss: 1.985928294479206

Epoch: 5| Step: 1
Training loss: 2.7528252601623535
Validation loss: 1.9925637860451975

Epoch: 5| Step: 2
Training loss: 2.260326862335205
Validation loss: 1.9934191601250761

Epoch: 5| Step: 3
Training loss: 2.2886340618133545
Validation loss: 1.9917468947748984

Epoch: 5| Step: 4
Training loss: 2.004425048828125
Validation loss: 1.9795698350475681

Epoch: 5| Step: 5
Training loss: 2.086210012435913
Validation loss: 1.9942434321167648

Epoch: 5| Step: 6
Training loss: 1.6789630651474
Validation loss: 1.9920138569288357

Epoch: 5| Step: 7
Training loss: 1.84088933467865
Validation loss: 1.9955578901434456

Epoch: 5| Step: 8
Training loss: 2.4326553344726562
Validation loss: 1.9895027504172376

Epoch: 5| Step: 9
Training loss: 1.8955154418945312
Validation loss: 1.993795253897226

Epoch: 5| Step: 10
Training loss: 2.6181271076202393
Validation loss: 1.9929934406793246

Epoch: 169| Step: 0
Training loss: 2.253464698791504
Validation loss: 1.9731927648667367

Epoch: 5| Step: 1
Training loss: 2.4070591926574707
Validation loss: 1.9653164904604676

Epoch: 5| Step: 2
Training loss: 1.892887830734253
Validation loss: 1.99288769050311

Epoch: 5| Step: 3
Training loss: 2.752309560775757
Validation loss: 2.0052442704477618

Epoch: 5| Step: 4
Training loss: 1.2759778499603271
Validation loss: 2.003872302270705

Epoch: 5| Step: 5
Training loss: 2.2611401081085205
Validation loss: 1.9940044149275749

Epoch: 5| Step: 6
Training loss: 2.431786060333252
Validation loss: 2.012766709891699

Epoch: 5| Step: 7
Training loss: 2.4891197681427
Validation loss: 1.9914817579330937

Epoch: 5| Step: 8
Training loss: 1.651468276977539
Validation loss: 1.993795274406351

Epoch: 5| Step: 9
Training loss: 2.0571224689483643
Validation loss: 2.006840826362692

Epoch: 5| Step: 10
Training loss: 1.8963849544525146
Validation loss: 2.0047452808708273

Epoch: 170| Step: 0
Training loss: 2.2923998832702637
Validation loss: 2.0110150139818908

Epoch: 5| Step: 1
Training loss: 1.8966808319091797
Validation loss: 1.997039605212468

Epoch: 5| Step: 2
Training loss: 2.03015398979187
Validation loss: 2.0082287314117595

Epoch: 5| Step: 3
Training loss: 1.7409814596176147
Validation loss: 1.9758764108022053

Epoch: 5| Step: 4
Training loss: 2.23716139793396
Validation loss: 1.9923477224124375

Epoch: 5| Step: 5
Training loss: 1.972241997718811
Validation loss: 2.000015950972034

Epoch: 5| Step: 6
Training loss: 2.1931471824645996
Validation loss: 1.9938545150141562

Epoch: 5| Step: 7
Training loss: 2.798398017883301
Validation loss: 1.9830918517164005

Epoch: 5| Step: 8
Training loss: 1.8134006261825562
Validation loss: 2.0168767757313226

Epoch: 5| Step: 9
Training loss: 1.8951953649520874
Validation loss: 2.002179056085566

Epoch: 5| Step: 10
Training loss: 2.448683977127075
Validation loss: 2.0045937261273785

Epoch: 171| Step: 0
Training loss: 2.413670301437378
Validation loss: 2.0092937356682232

Epoch: 5| Step: 1
Training loss: 1.8047459125518799
Validation loss: 2.0005221930883264

Epoch: 5| Step: 2
Training loss: 2.0196220874786377
Validation loss: 2.004068932225627

Epoch: 5| Step: 3
Training loss: 1.5724445581436157
Validation loss: 1.9986302621902958

Epoch: 5| Step: 4
Training loss: 2.2370502948760986
Validation loss: 1.9972686639396093

Epoch: 5| Step: 5
Training loss: 2.0164897441864014
Validation loss: 2.016952250593452

Epoch: 5| Step: 6
Training loss: 2.270423173904419
Validation loss: 1.9877018185072048

Epoch: 5| Step: 7
Training loss: 2.4316484928131104
Validation loss: 2.0044805157569145

Epoch: 5| Step: 8
Training loss: 1.9611432552337646
Validation loss: 1.9848176176830004

Epoch: 5| Step: 9
Training loss: 2.1256823539733887
Validation loss: 2.0074713550588137

Epoch: 5| Step: 10
Training loss: 2.596344232559204
Validation loss: 2.0096422805581042

Epoch: 172| Step: 0
Training loss: 1.5724048614501953
Validation loss: 1.9811531446313346

Epoch: 5| Step: 1
Training loss: 2.5195631980895996
Validation loss: 2.024477917660949

Epoch: 5| Step: 2
Training loss: 1.8345203399658203
Validation loss: 2.0039084265308995

Epoch: 5| Step: 3
Training loss: 2.8006691932678223
Validation loss: 2.0240342873398975

Epoch: 5| Step: 4
Training loss: 2.2622299194335938
Validation loss: 2.033020559177604

Epoch: 5| Step: 5
Training loss: 1.878519058227539
Validation loss: 2.029054234104772

Epoch: 5| Step: 6
Training loss: 1.8366953134536743
Validation loss: 2.02175437378627

Epoch: 5| Step: 7
Training loss: 2.555842876434326
Validation loss: 2.0308510475261237

Epoch: 5| Step: 8
Training loss: 2.132615327835083
Validation loss: 2.034756706606957

Epoch: 5| Step: 9
Training loss: 2.236464262008667
Validation loss: 2.034489039451845

Epoch: 5| Step: 10
Training loss: 1.5652787685394287
Validation loss: 2.050506196996217

Epoch: 173| Step: 0
Training loss: 1.8693641424179077
Validation loss: 2.0295168981757215

Epoch: 5| Step: 1
Training loss: 1.456671953201294
Validation loss: 2.0222406938511837

Epoch: 5| Step: 2
Training loss: 1.547885775566101
Validation loss: 2.00564327034899

Epoch: 5| Step: 3
Training loss: 2.321301221847534
Validation loss: 2.005370068293746

Epoch: 5| Step: 4
Training loss: 2.420748472213745
Validation loss: 1.9958633145978373

Epoch: 5| Step: 5
Training loss: 1.732944130897522
Validation loss: 1.9936982662447038

Epoch: 5| Step: 6
Training loss: 3.0125250816345215
Validation loss: 1.9975404277924569

Epoch: 5| Step: 7
Training loss: 2.219294786453247
Validation loss: 1.960584125211162

Epoch: 5| Step: 8
Training loss: 1.895642876625061
Validation loss: 1.966051540067119

Epoch: 5| Step: 9
Training loss: 2.1013574600219727
Validation loss: 1.9985065485841484

Epoch: 5| Step: 10
Training loss: 2.953408718109131
Validation loss: 1.975611791815809

Epoch: 174| Step: 0
Training loss: 2.23291015625
Validation loss: 1.9926704052955873

Epoch: 5| Step: 1
Training loss: 2.2341108322143555
Validation loss: 1.970985948398549

Epoch: 5| Step: 2
Training loss: 2.6099295616149902
Validation loss: 1.9990014658179334

Epoch: 5| Step: 3
Training loss: 2.2697670459747314
Validation loss: 2.0035924603862147

Epoch: 5| Step: 4
Training loss: 2.282212734222412
Validation loss: 1.9829608932618172

Epoch: 5| Step: 5
Training loss: 2.125983238220215
Validation loss: 1.978842608390316

Epoch: 5| Step: 6
Training loss: 2.3828213214874268
Validation loss: 1.987848574115384

Epoch: 5| Step: 7
Training loss: 2.149893045425415
Validation loss: 1.9779522444612236

Epoch: 5| Step: 8
Training loss: 1.6437467336654663
Validation loss: 1.9914063048619095

Epoch: 5| Step: 9
Training loss: 1.4964336156845093
Validation loss: 1.969166648003363

Epoch: 5| Step: 10
Training loss: 1.750866174697876
Validation loss: 1.9917598488510295

Epoch: 175| Step: 0
Training loss: 1.4217506647109985
Validation loss: 1.9988588979167323

Epoch: 5| Step: 1
Training loss: 2.244001626968384
Validation loss: 2.000107575488347

Epoch: 5| Step: 2
Training loss: 2.2029948234558105
Validation loss: 2.015300966078235

Epoch: 5| Step: 3
Training loss: 2.2248682975769043
Validation loss: 2.0116733210061186

Epoch: 5| Step: 4
Training loss: 1.5743070840835571
Validation loss: 2.0251119482901787

Epoch: 5| Step: 5
Training loss: 1.7688041925430298
Validation loss: 2.003228413161411

Epoch: 5| Step: 6
Training loss: 2.150421619415283
Validation loss: 2.025242865726512

Epoch: 5| Step: 7
Training loss: 2.2203714847564697
Validation loss: 2.042443957380069

Epoch: 5| Step: 8
Training loss: 2.172823429107666
Validation loss: 2.030403075679656

Epoch: 5| Step: 9
Training loss: 2.6400105953216553
Validation loss: 2.0056111812591553

Epoch: 5| Step: 10
Training loss: 2.7535622119903564
Validation loss: 2.007204069886156

Epoch: 176| Step: 0
Training loss: 2.3712687492370605
Validation loss: 2.0264344087211033

Epoch: 5| Step: 1
Training loss: 1.6249706745147705
Validation loss: 2.0122836405231106

Epoch: 5| Step: 2
Training loss: 1.9788284301757812
Validation loss: 2.0258731636949765

Epoch: 5| Step: 3
Training loss: 2.6789588928222656
Validation loss: 2.0227787699750674

Epoch: 5| Step: 4
Training loss: 1.3700264692306519
Validation loss: 2.011262575785319

Epoch: 5| Step: 5
Training loss: 2.6685383319854736
Validation loss: 1.9870507409495692

Epoch: 5| Step: 6
Training loss: 2.289259433746338
Validation loss: 1.9900941528299803

Epoch: 5| Step: 7
Training loss: 2.171154499053955
Validation loss: 1.9729255399396342

Epoch: 5| Step: 8
Training loss: 1.8245189189910889
Validation loss: 2.011449726678992

Epoch: 5| Step: 9
Training loss: 2.003408908843994
Validation loss: 1.994183813371966

Epoch: 5| Step: 10
Training loss: 2.353316307067871
Validation loss: 2.0111196066743586

Epoch: 177| Step: 0
Training loss: 2.3162481784820557
Validation loss: 2.000865367151076

Epoch: 5| Step: 1
Training loss: 1.5123357772827148
Validation loss: 1.9740071694056194

Epoch: 5| Step: 2
Training loss: 2.4979186058044434
Validation loss: 1.9798402606800038

Epoch: 5| Step: 3
Training loss: 2.202427387237549
Validation loss: 1.9742149486336658

Epoch: 5| Step: 4
Training loss: 2.155593156814575
Validation loss: 1.972191793944246

Epoch: 5| Step: 5
Training loss: 2.30962872505188
Validation loss: 1.977335440215244

Epoch: 5| Step: 6
Training loss: 2.6384873390197754
Validation loss: 1.9552777838963333

Epoch: 5| Step: 7
Training loss: 2.3385050296783447
Validation loss: 1.9814209271502752

Epoch: 5| Step: 8
Training loss: 1.5958651304244995
Validation loss: 1.9874150419747958

Epoch: 5| Step: 9
Training loss: 1.811540961265564
Validation loss: 1.9956747190926665

Epoch: 5| Step: 10
Training loss: 1.933387279510498
Validation loss: 1.9932579148200251

Epoch: 178| Step: 0
Training loss: 2.51275897026062
Validation loss: 2.001609279263404

Epoch: 5| Step: 1
Training loss: 2.429131031036377
Validation loss: 1.9722634477000083

Epoch: 5| Step: 2
Training loss: 2.031508445739746
Validation loss: 1.9851200016595985

Epoch: 5| Step: 3
Training loss: 2.11620831489563
Validation loss: 2.0030247665220693

Epoch: 5| Step: 4
Training loss: 2.2505197525024414
Validation loss: 1.9854958903404973

Epoch: 5| Step: 5
Training loss: 2.2157654762268066
Validation loss: 1.9937728720326577

Epoch: 5| Step: 6
Training loss: 1.7141163349151611
Validation loss: 2.0084919314230643

Epoch: 5| Step: 7
Training loss: 1.7734769582748413
Validation loss: 2.0215177100191832

Epoch: 5| Step: 8
Training loss: 2.271010160446167
Validation loss: 1.9925150332912323

Epoch: 5| Step: 9
Training loss: 1.963108777999878
Validation loss: 2.009830900417861

Epoch: 5| Step: 10
Training loss: 1.979443073272705
Validation loss: 2.0115301916676183

Epoch: 179| Step: 0
Training loss: 1.9593158960342407
Validation loss: 2.0161931130193893

Epoch: 5| Step: 1
Training loss: 2.2395987510681152
Validation loss: 1.9940725911048152

Epoch: 5| Step: 2
Training loss: 1.8528432846069336
Validation loss: 1.998026217183759

Epoch: 5| Step: 3
Training loss: 2.2356486320495605
Validation loss: 2.0367423385702152

Epoch: 5| Step: 4
Training loss: 1.9586690664291382
Validation loss: 2.0194593732075026

Epoch: 5| Step: 5
Training loss: 2.3964672088623047
Validation loss: 2.0117973871128534

Epoch: 5| Step: 6
Training loss: 1.9968631267547607
Validation loss: 1.998371180667672

Epoch: 5| Step: 7
Training loss: 1.7318280935287476
Validation loss: 2.0132166429232528

Epoch: 5| Step: 8
Training loss: 2.356339693069458
Validation loss: 2.0163194312844226

Epoch: 5| Step: 9
Training loss: 2.4378955364227295
Validation loss: 2.0352060397466025

Epoch: 5| Step: 10
Training loss: 1.9876691102981567
Validation loss: 2.021109555357246

Epoch: 180| Step: 0
Training loss: 2.520533323287964
Validation loss: 1.9950838306898713

Epoch: 5| Step: 1
Training loss: 2.00648832321167
Validation loss: 2.018685216544777

Epoch: 5| Step: 2
Training loss: 2.383972406387329
Validation loss: 1.9968716995690459

Epoch: 5| Step: 3
Training loss: 2.028642416000366
Validation loss: 2.0180157640928864

Epoch: 5| Step: 4
Training loss: 2.6834988594055176
Validation loss: 1.9836309879056868

Epoch: 5| Step: 5
Training loss: 1.696772575378418
Validation loss: 1.9846339071950605

Epoch: 5| Step: 6
Training loss: 2.190366744995117
Validation loss: 2.0066765495525893

Epoch: 5| Step: 7
Training loss: 1.6398799419403076
Validation loss: 2.0087215708148096

Epoch: 5| Step: 8
Training loss: 1.7109206914901733
Validation loss: 1.9890871124882852

Epoch: 5| Step: 9
Training loss: 1.75180983543396
Validation loss: 2.0082184319855063

Epoch: 5| Step: 10
Training loss: 2.668909788131714
Validation loss: 1.9930565382844658

Epoch: 181| Step: 0
Training loss: 1.7193782329559326
Validation loss: 1.9975400201735958

Epoch: 5| Step: 1
Training loss: 2.3313944339752197
Validation loss: 1.9969272459706953

Epoch: 5| Step: 2
Training loss: 2.269035816192627
Validation loss: 2.006075059213946

Epoch: 5| Step: 3
Training loss: 2.615408420562744
Validation loss: 2.001315088682277

Epoch: 5| Step: 4
Training loss: 1.9450969696044922
Validation loss: 2.0008861172583794

Epoch: 5| Step: 5
Training loss: 2.0849945545196533
Validation loss: 2.005869802608285

Epoch: 5| Step: 6
Training loss: 2.3613600730895996
Validation loss: 2.01017891335231

Epoch: 5| Step: 7
Training loss: 2.055124044418335
Validation loss: 1.995682349769018

Epoch: 5| Step: 8
Training loss: 1.25032639503479
Validation loss: 1.9662888191079582

Epoch: 5| Step: 9
Training loss: 2.204926013946533
Validation loss: 2.007971312410088

Epoch: 5| Step: 10
Training loss: 2.234405517578125
Validation loss: 2.01099762352564

Epoch: 182| Step: 0
Training loss: 1.8982120752334595
Validation loss: 1.9916214840386504

Epoch: 5| Step: 1
Training loss: 2.814321279525757
Validation loss: 1.9873474515894407

Epoch: 5| Step: 2
Training loss: 2.0389435291290283
Validation loss: 2.010228454425771

Epoch: 5| Step: 3
Training loss: 1.9699747562408447
Validation loss: 2.0011341879444737

Epoch: 5| Step: 4
Training loss: 2.3807613849639893
Validation loss: 1.993308921014109

Epoch: 5| Step: 5
Training loss: 2.0448641777038574
Validation loss: 1.9905946600821711

Epoch: 5| Step: 6
Training loss: 1.9762548208236694
Validation loss: 1.991651964443986

Epoch: 5| Step: 7
Training loss: 2.2734360694885254
Validation loss: 1.996863744592154

Epoch: 5| Step: 8
Training loss: 1.7834689617156982
Validation loss: 1.986937125523885

Epoch: 5| Step: 9
Training loss: 2.154597043991089
Validation loss: 1.99409354758519

Epoch: 5| Step: 10
Training loss: 1.8466087579727173
Validation loss: 1.9923186891822404

Epoch: 183| Step: 0
Training loss: 2.5712473392486572
Validation loss: 2.0112542862533243

Epoch: 5| Step: 1
Training loss: 1.9896571636199951
Validation loss: 1.9856064088882939

Epoch: 5| Step: 2
Training loss: 2.040989637374878
Validation loss: 1.9972821986803444

Epoch: 5| Step: 3
Training loss: 2.0664398670196533
Validation loss: 2.009297396547051

Epoch: 5| Step: 4
Training loss: 1.9149945974349976
Validation loss: 2.005552912271151

Epoch: 5| Step: 5
Training loss: 2.433823823928833
Validation loss: 2.0147272168949084

Epoch: 5| Step: 6
Training loss: 2.2902445793151855
Validation loss: 2.0196315626944266

Epoch: 5| Step: 7
Training loss: 2.0703041553497314
Validation loss: 1.9810078836256457

Epoch: 5| Step: 8
Training loss: 2.336275339126587
Validation loss: 2.0013597293566634

Epoch: 5| Step: 9
Training loss: 1.521911382675171
Validation loss: 2.005174216403756

Epoch: 5| Step: 10
Training loss: 1.9725561141967773
Validation loss: 2.0016193415528987

Epoch: 184| Step: 0
Training loss: 2.729226589202881
Validation loss: 1.9892530877103087

Epoch: 5| Step: 1
Training loss: 2.0602684020996094
Validation loss: 2.023298704495994

Epoch: 5| Step: 2
Training loss: 2.6507270336151123
Validation loss: 2.0161499566929315

Epoch: 5| Step: 3
Training loss: 2.2948203086853027
Validation loss: 2.014512187691145

Epoch: 5| Step: 4
Training loss: 2.0003299713134766
Validation loss: 2.0231336906392086

Epoch: 5| Step: 5
Training loss: 1.86049485206604
Validation loss: 1.9955036845258487

Epoch: 5| Step: 6
Training loss: 1.7220239639282227
Validation loss: 1.9874411142000588

Epoch: 5| Step: 7
Training loss: 1.6907199621200562
Validation loss: 2.020184754043497

Epoch: 5| Step: 8
Training loss: 1.9278653860092163
Validation loss: 2.024881464178844

Epoch: 5| Step: 9
Training loss: 2.2825684547424316
Validation loss: 1.9938223900333527

Epoch: 5| Step: 10
Training loss: 1.7329248189926147
Validation loss: 1.9924820879454255

Epoch: 185| Step: 0
Training loss: 1.677239179611206
Validation loss: 1.9815359154055197

Epoch: 5| Step: 1
Training loss: 1.8257014751434326
Validation loss: 1.9888914861986715

Epoch: 5| Step: 2
Training loss: 2.0819251537323
Validation loss: 1.9980418579552763

Epoch: 5| Step: 3
Training loss: 1.9976015090942383
Validation loss: 2.0096939084350423

Epoch: 5| Step: 4
Training loss: 2.141958713531494
Validation loss: 1.9914981870241062

Epoch: 5| Step: 5
Training loss: 2.126319169998169
Validation loss: 1.974251115193931

Epoch: 5| Step: 6
Training loss: 2.5224480628967285
Validation loss: 1.9914668119081886

Epoch: 5| Step: 7
Training loss: 2.0704917907714844
Validation loss: 2.0084939861810334

Epoch: 5| Step: 8
Training loss: 2.553837299346924
Validation loss: 1.9966987948263846

Epoch: 5| Step: 9
Training loss: 2.39817476272583
Validation loss: 2.000056702603576

Epoch: 5| Step: 10
Training loss: 1.8281583786010742
Validation loss: 1.9930359958320536

Epoch: 186| Step: 0
Training loss: 2.1482245922088623
Validation loss: 1.9840870467565392

Epoch: 5| Step: 1
Training loss: 2.215728282928467
Validation loss: 1.9969606732809415

Epoch: 5| Step: 2
Training loss: 1.2847715616226196
Validation loss: 1.9980666970693937

Epoch: 5| Step: 3
Training loss: 2.497689962387085
Validation loss: 2.0115533349334553

Epoch: 5| Step: 4
Training loss: 2.051037549972534
Validation loss: 1.9895083083901355

Epoch: 5| Step: 5
Training loss: 2.393718719482422
Validation loss: 2.0004059896674207

Epoch: 5| Step: 6
Training loss: 2.376451015472412
Validation loss: 2.024542489359456

Epoch: 5| Step: 7
Training loss: 2.0705881118774414
Validation loss: 2.0021546553539973

Epoch: 5| Step: 8
Training loss: 2.1156792640686035
Validation loss: 1.9998568296432495

Epoch: 5| Step: 9
Training loss: 1.6660664081573486
Validation loss: 2.00712905135206

Epoch: 5| Step: 10
Training loss: 2.285141944885254
Validation loss: 2.011554016861864

Epoch: 187| Step: 0
Training loss: 2.006765127182007
Validation loss: 2.0050474264288463

Epoch: 5| Step: 1
Training loss: 2.222079038619995
Validation loss: 2.0349178955119145

Epoch: 5| Step: 2
Training loss: 2.250913143157959
Validation loss: 2.0174590797834497

Epoch: 5| Step: 3
Training loss: 2.189528226852417
Validation loss: 1.9999463096741708

Epoch: 5| Step: 4
Training loss: 2.3149924278259277
Validation loss: 2.011127857751744

Epoch: 5| Step: 5
Training loss: 2.603726863861084
Validation loss: 2.006725747098205

Epoch: 5| Step: 6
Training loss: 1.7595669031143188
Validation loss: 2.022248045090706

Epoch: 5| Step: 7
Training loss: 1.8952887058258057
Validation loss: 2.0080206830014466

Epoch: 5| Step: 8
Training loss: 1.9336944818496704
Validation loss: 2.0098878106763287

Epoch: 5| Step: 9
Training loss: 1.812429666519165
Validation loss: 2.000152036707888

Epoch: 5| Step: 10
Training loss: 2.1083552837371826
Validation loss: 1.9917400985635736

Epoch: 188| Step: 0
Training loss: 1.5964453220367432
Validation loss: 2.012714342404437

Epoch: 5| Step: 1
Training loss: 2.190187931060791
Validation loss: 2.0139812961701424

Epoch: 5| Step: 2
Training loss: 1.3685872554779053
Validation loss: 2.0124547917355775

Epoch: 5| Step: 3
Training loss: 2.1273562908172607
Validation loss: 2.0135811067396596

Epoch: 5| Step: 4
Training loss: 2.0200459957122803
Validation loss: 1.9857487204254314

Epoch: 5| Step: 5
Training loss: 1.9626411199569702
Validation loss: 1.9922080603978967

Epoch: 5| Step: 6
Training loss: 1.7450402975082397
Validation loss: 1.9962118415422336

Epoch: 5| Step: 7
Training loss: 2.64904522895813
Validation loss: 1.9810251881999354

Epoch: 5| Step: 8
Training loss: 2.8971829414367676
Validation loss: 1.980081291608913

Epoch: 5| Step: 9
Training loss: 2.3404839038848877
Validation loss: 1.9806166938556138

Epoch: 5| Step: 10
Training loss: 2.285820722579956
Validation loss: 2.001659039528139

Epoch: 189| Step: 0
Training loss: 2.5706329345703125
Validation loss: 1.9944061976607128

Epoch: 5| Step: 1
Training loss: 2.356698513031006
Validation loss: 1.9985794790329472

Epoch: 5| Step: 2
Training loss: 1.1703789234161377
Validation loss: 1.9934503660407117

Epoch: 5| Step: 3
Training loss: 2.443098783493042
Validation loss: 1.972932110550583

Epoch: 5| Step: 4
Training loss: 1.909559965133667
Validation loss: 1.9942025548668318

Epoch: 5| Step: 5
Training loss: 1.6370933055877686
Validation loss: 1.974806244655322

Epoch: 5| Step: 6
Training loss: 3.0063815116882324
Validation loss: 1.9923538379771735

Epoch: 5| Step: 7
Training loss: 1.8133671283721924
Validation loss: 1.9945734726485385

Epoch: 5| Step: 8
Training loss: 1.8813955783843994
Validation loss: 1.9933337011644918

Epoch: 5| Step: 9
Training loss: 2.26245379447937
Validation loss: 2.0116538001644995

Epoch: 5| Step: 10
Training loss: 1.8789193630218506
Validation loss: 2.0012711991545973

Epoch: 190| Step: 0
Training loss: 1.5227186679840088
Validation loss: 1.9780940701884608

Epoch: 5| Step: 1
Training loss: 2.8360724449157715
Validation loss: 2.0049104267551052

Epoch: 5| Step: 2
Training loss: 2.051609516143799
Validation loss: 1.9965195130276423

Epoch: 5| Step: 3
Training loss: 2.511881113052368
Validation loss: 2.009235830717189

Epoch: 5| Step: 4
Training loss: 1.7359120845794678
Validation loss: 2.018641887172576

Epoch: 5| Step: 5
Training loss: 1.7085294723510742
Validation loss: 2.0247381041126866

Epoch: 5| Step: 6
Training loss: 1.8156276941299438
Validation loss: 2.0073706937092606

Epoch: 5| Step: 7
Training loss: 2.0346083641052246
Validation loss: 2.025619255599155

Epoch: 5| Step: 8
Training loss: 2.166386842727661
Validation loss: 2.0203967453331075

Epoch: 5| Step: 9
Training loss: 2.2270302772521973
Validation loss: 2.012763761704968

Epoch: 5| Step: 10
Training loss: 2.374143600463867
Validation loss: 2.0105902712832213

Epoch: 191| Step: 0
Training loss: 1.7701886892318726
Validation loss: 2.006810575403193

Epoch: 5| Step: 1
Training loss: 2.26271390914917
Validation loss: 1.9993724566633984

Epoch: 5| Step: 2
Training loss: 1.9211959838867188
Validation loss: 1.9893784907556349

Epoch: 5| Step: 3
Training loss: 2.0068063735961914
Validation loss: 2.0221927396712767

Epoch: 5| Step: 4
Training loss: 2.178433895111084
Validation loss: 2.0033252508409563

Epoch: 5| Step: 5
Training loss: 2.045480966567993
Validation loss: 1.9870108084012104

Epoch: 5| Step: 6
Training loss: 2.4720406532287598
Validation loss: 1.9951158108249787

Epoch: 5| Step: 7
Training loss: 2.25052547454834
Validation loss: 2.0002699975044496

Epoch: 5| Step: 8
Training loss: 2.2762341499328613
Validation loss: 2.016512178605603

Epoch: 5| Step: 9
Training loss: 2.358142375946045
Validation loss: 1.9693946556378437

Epoch: 5| Step: 10
Training loss: 1.6581729650497437
Validation loss: 1.9811318728231615

Epoch: 192| Step: 0
Training loss: 2.238187789916992
Validation loss: 2.0039212908796085

Epoch: 5| Step: 1
Training loss: 2.427534341812134
Validation loss: 1.9798911181829308

Epoch: 5| Step: 2
Training loss: 2.1664299964904785
Validation loss: 2.002767062956287

Epoch: 5| Step: 3
Training loss: 1.6171000003814697
Validation loss: 2.0021462850673224

Epoch: 5| Step: 4
Training loss: 2.6156413555145264
Validation loss: 2.011202698112816

Epoch: 5| Step: 5
Training loss: 1.5769892930984497
Validation loss: 1.9956642479024909

Epoch: 5| Step: 6
Training loss: 1.5712206363677979
Validation loss: 1.999027911052909

Epoch: 5| Step: 7
Training loss: 2.5398831367492676
Validation loss: 2.0059195128820275

Epoch: 5| Step: 8
Training loss: 2.3045411109924316
Validation loss: 1.997688190911406

Epoch: 5| Step: 9
Training loss: 2.5195887088775635
Validation loss: 1.986856695144407

Epoch: 5| Step: 10
Training loss: 1.3665375709533691
Validation loss: 2.014813207810925

Epoch: 193| Step: 0
Training loss: 2.39656662940979
Validation loss: 1.9921785913487917

Epoch: 5| Step: 1
Training loss: 2.667741060256958
Validation loss: 1.9913747990003197

Epoch: 5| Step: 2
Training loss: 2.344208240509033
Validation loss: 1.9761155382279427

Epoch: 5| Step: 3
Training loss: 2.2194080352783203
Validation loss: 1.9731334486315328

Epoch: 5| Step: 4
Training loss: 1.6665821075439453
Validation loss: 1.957774386611036

Epoch: 5| Step: 5
Training loss: 2.168759822845459
Validation loss: 1.9750959104107273

Epoch: 5| Step: 6
Training loss: 1.9832690954208374
Validation loss: 1.9810587667649793

Epoch: 5| Step: 7
Training loss: 2.5399937629699707
Validation loss: 1.9701867975214475

Epoch: 5| Step: 8
Training loss: 1.679796576499939
Validation loss: 1.9698027000632337

Epoch: 5| Step: 9
Training loss: 1.6194807291030884
Validation loss: 1.969393963454872

Epoch: 5| Step: 10
Training loss: 1.7505816221237183
Validation loss: 1.9856188117816884

Epoch: 194| Step: 0
Training loss: 1.948058843612671
Validation loss: 1.9753674999360116

Epoch: 5| Step: 1
Training loss: 1.86386239528656
Validation loss: 1.9769772868002615

Epoch: 5| Step: 2
Training loss: 2.0633649826049805
Validation loss: 1.9992748639916862

Epoch: 5| Step: 3
Training loss: 1.985306739807129
Validation loss: 2.001860011008478

Epoch: 5| Step: 4
Training loss: 2.177928924560547
Validation loss: 1.9975205467593284

Epoch: 5| Step: 5
Training loss: 1.6256307363510132
Validation loss: 1.9963671507373932

Epoch: 5| Step: 6
Training loss: 2.3363306522369385
Validation loss: 2.0006051166083223

Epoch: 5| Step: 7
Training loss: 2.633195161819458
Validation loss: 2.0168026134531987

Epoch: 5| Step: 8
Training loss: 1.9792001247406006
Validation loss: 2.0056339386970765

Epoch: 5| Step: 9
Training loss: 2.0665526390075684
Validation loss: 2.013168029887702

Epoch: 5| Step: 10
Training loss: 2.1881182193756104
Validation loss: 2.0199191672827608

Epoch: 195| Step: 0
Training loss: 2.588361978530884
Validation loss: 2.013827678977802

Epoch: 5| Step: 1
Training loss: 2.188208818435669
Validation loss: 2.0199615506715674

Epoch: 5| Step: 2
Training loss: 2.153468608856201
Validation loss: 2.0132027044091174

Epoch: 5| Step: 3
Training loss: 2.0952322483062744
Validation loss: 2.0070965341342393

Epoch: 5| Step: 4
Training loss: 1.8254988193511963
Validation loss: 2.016720708980355

Epoch: 5| Step: 5
Training loss: 1.8945777416229248
Validation loss: 1.991155844862743

Epoch: 5| Step: 6
Training loss: 1.614315390586853
Validation loss: 1.9989415676363054

Epoch: 5| Step: 7
Training loss: 2.051607608795166
Validation loss: 1.9887828621813046

Epoch: 5| Step: 8
Training loss: 2.110712766647339
Validation loss: 2.0023652507412817

Epoch: 5| Step: 9
Training loss: 2.282691240310669
Validation loss: 1.9979613968121108

Epoch: 5| Step: 10
Training loss: 2.349552869796753
Validation loss: 1.9758086345529045

Epoch: 196| Step: 0
Training loss: 1.7223386764526367
Validation loss: 1.995395774482399

Epoch: 5| Step: 1
Training loss: 2.3512260913848877
Validation loss: 2.0111058976060603

Epoch: 5| Step: 2
Training loss: 2.0911898612976074
Validation loss: 2.0034125363954933

Epoch: 5| Step: 3
Training loss: 1.8384040594100952
Validation loss: 1.963653233743483

Epoch: 5| Step: 4
Training loss: 2.046508312225342
Validation loss: 1.9808444182078044

Epoch: 5| Step: 5
Training loss: 2.3086159229278564
Validation loss: 1.9654036311693088

Epoch: 5| Step: 6
Training loss: 1.8986679315567017
Validation loss: 1.9928618938692155

Epoch: 5| Step: 7
Training loss: 2.2422537803649902
Validation loss: 2.0114455133356075

Epoch: 5| Step: 8
Training loss: 2.1498496532440186
Validation loss: 1.9827392357651905

Epoch: 5| Step: 9
Training loss: 2.381530284881592
Validation loss: 1.9904109918943016

Epoch: 5| Step: 10
Training loss: 1.8166154623031616
Validation loss: 1.9846622379877235

Epoch: 197| Step: 0
Training loss: 1.4631893634796143
Validation loss: 2.002793288999988

Epoch: 5| Step: 1
Training loss: 2.315906047821045
Validation loss: 1.9914900026013773

Epoch: 5| Step: 2
Training loss: 2.2544047832489014
Validation loss: 2.0137312617353214

Epoch: 5| Step: 3
Training loss: 2.166069984436035
Validation loss: 2.004094695532194

Epoch: 5| Step: 4
Training loss: 2.0526809692382812
Validation loss: 2.000769599791496

Epoch: 5| Step: 5
Training loss: 1.851766586303711
Validation loss: 2.010262773882958

Epoch: 5| Step: 6
Training loss: 2.454303026199341
Validation loss: 2.015734621273574

Epoch: 5| Step: 7
Training loss: 1.5393354892730713
Validation loss: 2.016927444806663

Epoch: 5| Step: 8
Training loss: 2.2285704612731934
Validation loss: 2.0183340041868147

Epoch: 5| Step: 9
Training loss: 2.4966633319854736
Validation loss: 2.013241667901316

Epoch: 5| Step: 10
Training loss: 2.25256609916687
Validation loss: 2.0373239401848084

Epoch: 198| Step: 0
Training loss: 1.9360721111297607
Validation loss: 2.0244486280666885

Epoch: 5| Step: 1
Training loss: 1.5026904344558716
Validation loss: 2.0201320904557423

Epoch: 5| Step: 2
Training loss: 2.3037848472595215
Validation loss: 2.016166075583427

Epoch: 5| Step: 3
Training loss: 1.7191646099090576
Validation loss: 2.0218260249783917

Epoch: 5| Step: 4
Training loss: 1.9793081283569336
Validation loss: 2.01968095251309

Epoch: 5| Step: 5
Training loss: 2.0970845222473145
Validation loss: 2.00571548169659

Epoch: 5| Step: 6
Training loss: 2.023339033126831
Validation loss: 2.004002321150995

Epoch: 5| Step: 7
Training loss: 1.741459608078003
Validation loss: 2.007433719532464

Epoch: 5| Step: 8
Training loss: 2.7315971851348877
Validation loss: 1.9854152702516126

Epoch: 5| Step: 9
Training loss: 2.456540584564209
Validation loss: 2.0112640703878095

Epoch: 5| Step: 10
Training loss: 2.4590110778808594
Validation loss: 1.9876934225841234

Epoch: 199| Step: 0
Training loss: 1.9497677087783813
Validation loss: 2.0155118139841224

Epoch: 5| Step: 1
Training loss: 2.7534241676330566
Validation loss: 2.0055168700474564

Epoch: 5| Step: 2
Training loss: 1.9986698627471924
Validation loss: 2.0003763629544165

Epoch: 5| Step: 3
Training loss: 2.037731647491455
Validation loss: 1.9975115253079323

Epoch: 5| Step: 4
Training loss: 2.2394051551818848
Validation loss: 2.0011628109921693

Epoch: 5| Step: 5
Training loss: 1.7484254837036133
Validation loss: 1.9811516115742345

Epoch: 5| Step: 6
Training loss: 1.9912277460098267
Validation loss: 1.992181226771365

Epoch: 5| Step: 7
Training loss: 2.0930867195129395
Validation loss: 2.0074495679588726

Epoch: 5| Step: 8
Training loss: 2.1232635974884033
Validation loss: 1.995681160239763

Epoch: 5| Step: 9
Training loss: 2.2463951110839844
Validation loss: 1.9998420464095248

Epoch: 5| Step: 10
Training loss: 1.8126524686813354
Validation loss: 1.9833031559503207

Epoch: 200| Step: 0
Training loss: 1.9278943538665771
Validation loss: 2.010395085939797

Epoch: 5| Step: 1
Training loss: 2.636625051498413
Validation loss: 1.9916909715180755

Epoch: 5| Step: 2
Training loss: 2.2096526622772217
Validation loss: 2.0118735733852593

Epoch: 5| Step: 3
Training loss: 1.8626708984375
Validation loss: 2.005913467817409

Epoch: 5| Step: 4
Training loss: 2.0807807445526123
Validation loss: 1.9931804800546298

Epoch: 5| Step: 5
Training loss: 1.9659923315048218
Validation loss: 1.9974865605754237

Epoch: 5| Step: 6
Training loss: 2.2670302391052246
Validation loss: 2.002951204135854

Epoch: 5| Step: 7
Training loss: 1.8680455684661865
Validation loss: 1.966032592199182

Epoch: 5| Step: 8
Training loss: 2.675450325012207
Validation loss: 1.9940233743318947

Epoch: 5| Step: 9
Training loss: 1.2628474235534668
Validation loss: 2.0027261639154084

Epoch: 5| Step: 10
Training loss: 2.169658899307251
Validation loss: 1.9899992430081932

Testing loss: 2.0680176284578113
