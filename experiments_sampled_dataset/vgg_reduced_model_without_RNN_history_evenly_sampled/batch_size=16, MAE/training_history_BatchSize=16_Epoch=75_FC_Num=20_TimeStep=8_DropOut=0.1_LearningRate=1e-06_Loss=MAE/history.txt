Epoch: 1| Step: 0
Training loss: 4.3134307861328125
Validation loss: 4.50552854230327

Epoch: 6| Step: 1
Training loss: 4.020622253417969
Validation loss: 4.501388744641376

Epoch: 6| Step: 2
Training loss: 3.943930149078369
Validation loss: 4.4969800620950675

Epoch: 6| Step: 3
Training loss: 5.079080104827881
Validation loss: 4.491675720419935

Epoch: 6| Step: 4
Training loss: 4.375851154327393
Validation loss: 4.4890718101173315

Epoch: 6| Step: 5
Training loss: 5.578901290893555
Validation loss: 4.486424512760614

Epoch: 6| Step: 6
Training loss: 4.768587112426758
Validation loss: 4.482577887914514

Epoch: 6| Step: 7
Training loss: 4.756529808044434
Validation loss: 4.479144706520983

Epoch: 6| Step: 8
Training loss: 3.609679698944092
Validation loss: 4.473705094347718

Epoch: 6| Step: 9
Training loss: 4.198009967803955
Validation loss: 4.473983190392935

Epoch: 6| Step: 10
Training loss: 3.5828540325164795
Validation loss: 4.468228514476489

Epoch: 6| Step: 11
Training loss: 3.5683956146240234
Validation loss: 4.465087844479468

Epoch: 6| Step: 12
Training loss: 4.305670261383057
Validation loss: 4.459171787385018

Epoch: 6| Step: 13
Training loss: 3.783963203430176
Validation loss: 4.456688860411285

Epoch: 2| Step: 0
Training loss: 4.967496871948242
Validation loss: 4.452543750885995

Epoch: 6| Step: 1
Training loss: 5.012136459350586
Validation loss: 4.452160973702708

Epoch: 6| Step: 2
Training loss: 4.138134479522705
Validation loss: 4.448423908602807

Epoch: 6| Step: 3
Training loss: 4.684925079345703
Validation loss: 4.44506125809044

Epoch: 6| Step: 4
Training loss: 4.145836353302002
Validation loss: 4.44295092551939

Epoch: 6| Step: 5
Training loss: 4.478877067565918
Validation loss: 4.440979188488376

Epoch: 6| Step: 6
Training loss: 5.26043701171875
Validation loss: 4.435138546010499

Epoch: 6| Step: 7
Training loss: 3.489710807800293
Validation loss: 4.431010164240355

Epoch: 6| Step: 8
Training loss: 4.461485385894775
Validation loss: 4.430385745981688

Epoch: 6| Step: 9
Training loss: 3.146834135055542
Validation loss: 4.42768620931974

Epoch: 6| Step: 10
Training loss: 4.531594276428223
Validation loss: 4.42310929554765

Epoch: 6| Step: 11
Training loss: 4.533961772918701
Validation loss: 4.420310538302186

Epoch: 6| Step: 12
Training loss: 2.7319538593292236
Validation loss: 4.4174803251861245

Epoch: 6| Step: 13
Training loss: 3.6038427352905273
Validation loss: 4.415010534307008

Epoch: 3| Step: 0
Training loss: 4.096279144287109
Validation loss: 4.410846520495671

Epoch: 6| Step: 1
Training loss: 3.6625540256500244
Validation loss: 4.407793403953634

Epoch: 6| Step: 2
Training loss: 3.723422050476074
Validation loss: 4.406183299197946

Epoch: 6| Step: 3
Training loss: 5.285702705383301
Validation loss: 4.405818636699389

Epoch: 6| Step: 4
Training loss: 4.119800567626953
Validation loss: 4.401305816506826

Epoch: 6| Step: 5
Training loss: 4.104142189025879
Validation loss: 4.399369547444005

Epoch: 6| Step: 6
Training loss: 3.665398597717285
Validation loss: 4.396554362389349

Epoch: 6| Step: 7
Training loss: 3.4626238346099854
Validation loss: 4.392948904345112

Epoch: 6| Step: 8
Training loss: 4.375583648681641
Validation loss: 4.390119275739116

Epoch: 6| Step: 9
Training loss: 5.500072002410889
Validation loss: 4.388107520277782

Epoch: 6| Step: 10
Training loss: 3.4690756797790527
Validation loss: 4.38617984197473

Epoch: 6| Step: 11
Training loss: 5.721636772155762
Validation loss: 4.385122040266632

Epoch: 6| Step: 12
Training loss: 3.6999716758728027
Validation loss: 4.380991997257356

Epoch: 6| Step: 13
Training loss: 3.8754148483276367
Validation loss: 4.378547586420531

Epoch: 4| Step: 0
Training loss: 3.2659997940063477
Validation loss: 4.3757235721875265

Epoch: 6| Step: 1
Training loss: 3.758127212524414
Validation loss: 4.371812866580102

Epoch: 6| Step: 2
Training loss: 3.929677963256836
Validation loss: 4.368842860703827

Epoch: 6| Step: 3
Training loss: 3.4278810024261475
Validation loss: 4.368670166179698

Epoch: 6| Step: 4
Training loss: 5.494272708892822
Validation loss: 4.3637166023254395

Epoch: 6| Step: 5
Training loss: 3.6256396770477295
Validation loss: 4.361107375032159

Epoch: 6| Step: 6
Training loss: 5.227329254150391
Validation loss: 4.3591859109940065

Epoch: 6| Step: 7
Training loss: 3.729055881500244
Validation loss: 4.355343859682801

Epoch: 6| Step: 8
Training loss: 2.820866584777832
Validation loss: 4.351034046501241

Epoch: 6| Step: 9
Training loss: 4.496702194213867
Validation loss: 4.349061519868912

Epoch: 6| Step: 10
Training loss: 3.660137176513672
Validation loss: 4.344046956749373

Epoch: 6| Step: 11
Training loss: 5.547353744506836
Validation loss: 4.3444629638425765

Epoch: 6| Step: 12
Training loss: 4.339785575866699
Validation loss: 4.33956406706123

Epoch: 6| Step: 13
Training loss: 5.72028923034668
Validation loss: 4.336163556703958

Epoch: 5| Step: 0
Training loss: 4.56889533996582
Validation loss: 4.333481498943862

Epoch: 6| Step: 1
Training loss: 4.257421493530273
Validation loss: 4.33059004814394

Epoch: 6| Step: 2
Training loss: 4.447585105895996
Validation loss: 4.325740357880951

Epoch: 6| Step: 3
Training loss: 3.6106815338134766
Validation loss: 4.323540320960424

Epoch: 6| Step: 4
Training loss: 5.289935111999512
Validation loss: 4.321176195657381

Epoch: 6| Step: 5
Training loss: 4.109265327453613
Validation loss: 4.319217712648453

Epoch: 6| Step: 6
Training loss: 2.6732969284057617
Validation loss: 4.31264191545466

Epoch: 6| Step: 7
Training loss: 2.615436553955078
Validation loss: 4.311439401359968

Epoch: 6| Step: 8
Training loss: 4.994617462158203
Validation loss: 4.307665542889667

Epoch: 6| Step: 9
Training loss: 3.732447862625122
Validation loss: 4.303672498272311

Epoch: 6| Step: 10
Training loss: 4.118722438812256
Validation loss: 4.300683652201006

Epoch: 6| Step: 11
Training loss: 5.588198661804199
Validation loss: 4.294938097717941

Epoch: 6| Step: 12
Training loss: 3.3532464504241943
Validation loss: 4.292453914560298

Epoch: 6| Step: 13
Training loss: 4.624166011810303
Validation loss: 4.2887276475147535

Epoch: 6| Step: 0
Training loss: 4.286126613616943
Validation loss: 4.286553341855285

Epoch: 6| Step: 1
Training loss: 4.555202484130859
Validation loss: 4.282078748108239

Epoch: 6| Step: 2
Training loss: 4.144722938537598
Validation loss: 4.279042536212552

Epoch: 6| Step: 3
Training loss: 3.6205735206604004
Validation loss: 4.274381452991117

Epoch: 6| Step: 4
Training loss: 3.9812867641448975
Validation loss: 4.2710286571133524

Epoch: 6| Step: 5
Training loss: 3.735248565673828
Validation loss: 4.264715615139212

Epoch: 6| Step: 6
Training loss: 4.513814449310303
Validation loss: 4.261357312561364

Epoch: 6| Step: 7
Training loss: 3.8568599224090576
Validation loss: 4.2589056517488215

Epoch: 6| Step: 8
Training loss: 4.210531711578369
Validation loss: 4.253565357577417

Epoch: 6| Step: 9
Training loss: 3.389284133911133
Validation loss: 4.248272008793329

Epoch: 6| Step: 10
Training loss: 4.091569900512695
Validation loss: 4.24582750566544

Epoch: 6| Step: 11
Training loss: 4.149254322052002
Validation loss: 4.243990611004573

Epoch: 6| Step: 12
Training loss: 4.309835910797119
Validation loss: 4.236268927974086

Epoch: 6| Step: 13
Training loss: 4.377854347229004
Validation loss: 4.233444557395033

Epoch: 7| Step: 0
Training loss: 4.867392539978027
Validation loss: 4.231652787936631

Epoch: 6| Step: 1
Training loss: 4.37708044052124
Validation loss: 4.2242558412654425

Epoch: 6| Step: 2
Training loss: 3.3060526847839355
Validation loss: 4.221752138548

Epoch: 6| Step: 3
Training loss: 3.496735095977783
Validation loss: 4.216029823467296

Epoch: 6| Step: 4
Training loss: 2.0606987476348877
Validation loss: 4.211847956462573

Epoch: 6| Step: 5
Training loss: 4.091009140014648
Validation loss: 4.206319626941476

Epoch: 6| Step: 6
Training loss: 4.111286640167236
Validation loss: 4.203637402544739

Epoch: 6| Step: 7
Training loss: 4.9583024978637695
Validation loss: 4.197353050272952

Epoch: 6| Step: 8
Training loss: 4.211280822753906
Validation loss: 4.194386218183784

Epoch: 6| Step: 9
Training loss: 3.831508159637451
Validation loss: 4.188324454010174

Epoch: 6| Step: 10
Training loss: 4.437483310699463
Validation loss: 4.184580536298855

Epoch: 6| Step: 11
Training loss: 4.464425086975098
Validation loss: 4.18270742765037

Epoch: 6| Step: 12
Training loss: 3.756704330444336
Validation loss: 4.176124995754611

Epoch: 6| Step: 13
Training loss: 4.597357749938965
Validation loss: 4.1711995781108895

Epoch: 8| Step: 0
Training loss: 3.4966328144073486
Validation loss: 4.164444631145846

Epoch: 6| Step: 1
Training loss: 3.8299341201782227
Validation loss: 4.159985765334098

Epoch: 6| Step: 2
Training loss: 3.9712207317352295
Validation loss: 4.156658790444815

Epoch: 6| Step: 3
Training loss: 3.7915639877319336
Validation loss: 4.148100955511934

Epoch: 6| Step: 4
Training loss: 2.9344701766967773
Validation loss: 4.145966399100519

Epoch: 6| Step: 5
Training loss: 4.836523056030273
Validation loss: 4.141300180906891

Epoch: 6| Step: 6
Training loss: 4.640537261962891
Validation loss: 4.13428419892506

Epoch: 6| Step: 7
Training loss: 3.219325065612793
Validation loss: 4.124380432149415

Epoch: 6| Step: 8
Training loss: 5.2642621994018555
Validation loss: 4.122099015020555

Epoch: 6| Step: 9
Training loss: 4.496528625488281
Validation loss: 4.113180745032526

Epoch: 6| Step: 10
Training loss: 3.701352119445801
Validation loss: 4.108681673644691

Epoch: 6| Step: 11
Training loss: 3.577592611312866
Validation loss: 4.1006745933204565

Epoch: 6| Step: 12
Training loss: 3.3063454627990723
Validation loss: 4.096641307236046

Epoch: 6| Step: 13
Training loss: 4.6006011962890625
Validation loss: 4.08863825439125

Epoch: 9| Step: 0
Training loss: 3.4957776069641113
Validation loss: 4.082920520536361

Epoch: 6| Step: 1
Training loss: 3.401803493499756
Validation loss: 4.074667135874431

Epoch: 6| Step: 2
Training loss: 4.701220512390137
Validation loss: 4.069794357463878

Epoch: 6| Step: 3
Training loss: 3.697518825531006
Validation loss: 4.063903618884343

Epoch: 6| Step: 4
Training loss: 4.448580265045166
Validation loss: 4.054169511282316

Epoch: 6| Step: 5
Training loss: 4.25449800491333
Validation loss: 4.0476704156526955

Epoch: 6| Step: 6
Training loss: 3.753530263900757
Validation loss: 4.042863125442176

Epoch: 6| Step: 7
Training loss: 4.659422874450684
Validation loss: 4.033531178710281

Epoch: 6| Step: 8
Training loss: 4.2648162841796875
Validation loss: 4.024600946775046

Epoch: 6| Step: 9
Training loss: 2.7242462635040283
Validation loss: 4.023083112573111

Epoch: 6| Step: 10
Training loss: 3.906501293182373
Validation loss: 4.008747290539485

Epoch: 6| Step: 11
Training loss: 2.503551959991455
Validation loss: 4.004763285319011

Epoch: 6| Step: 12
Training loss: 4.89134407043457
Validation loss: 3.993508113327847

Epoch: 6| Step: 13
Training loss: 3.3794443607330322
Validation loss: 3.985759581288984

Epoch: 10| Step: 0
Training loss: 3.565577268600464
Validation loss: 3.9838814120138846

Epoch: 6| Step: 1
Training loss: 4.317244529724121
Validation loss: 3.97272148183597

Epoch: 6| Step: 2
Training loss: 4.015756607055664
Validation loss: 3.9648237843667307

Epoch: 6| Step: 3
Training loss: 4.187610626220703
Validation loss: 3.9589915788301857

Epoch: 6| Step: 4
Training loss: 4.027624130249023
Validation loss: 3.947238399136451

Epoch: 6| Step: 5
Training loss: 3.444873332977295
Validation loss: 3.9418276817567888

Epoch: 6| Step: 6
Training loss: 4.065090179443359
Validation loss: 3.9299812573258595

Epoch: 6| Step: 7
Training loss: 3.699721097946167
Validation loss: 3.926799440896639

Epoch: 6| Step: 8
Training loss: 3.4677815437316895
Validation loss: 3.911715930508029

Epoch: 6| Step: 9
Training loss: 4.362355709075928
Validation loss: 3.9048393259766283

Epoch: 6| Step: 10
Training loss: 3.6991078853607178
Validation loss: 3.8993929381011636

Epoch: 6| Step: 11
Training loss: 3.8901431560516357
Validation loss: 3.889423426761422

Epoch: 6| Step: 12
Training loss: 2.4745564460754395
Validation loss: 3.8809436726313766

Epoch: 6| Step: 13
Training loss: 3.749830961227417
Validation loss: 3.869254619844498

Epoch: 11| Step: 0
Training loss: 3.231818675994873
Validation loss: 3.863195675675587

Epoch: 6| Step: 1
Training loss: 3.6199522018432617
Validation loss: 3.8537391539542907

Epoch: 6| Step: 2
Training loss: 3.4275238513946533
Validation loss: 3.842969545754053

Epoch: 6| Step: 3
Training loss: 2.972179889678955
Validation loss: 3.833593947913057

Epoch: 6| Step: 4
Training loss: 3.916342258453369
Validation loss: 3.824072607101933

Epoch: 6| Step: 5
Training loss: 3.8000547885894775
Validation loss: 3.817469850663216

Epoch: 6| Step: 6
Training loss: 3.313123941421509
Validation loss: 3.8122016435028403

Epoch: 6| Step: 7
Training loss: 3.9594521522521973
Validation loss: 3.800646751157699

Epoch: 6| Step: 8
Training loss: 4.032341957092285
Validation loss: 3.7938249854631323

Epoch: 6| Step: 9
Training loss: 4.966092109680176
Validation loss: 3.7779842371581704

Epoch: 6| Step: 10
Training loss: 4.008720397949219
Validation loss: 3.7750958781088553

Epoch: 6| Step: 11
Training loss: 2.6560347080230713
Validation loss: 3.7613176376588884

Epoch: 6| Step: 12
Training loss: 3.545154094696045
Validation loss: 3.7496990490985174

Epoch: 6| Step: 13
Training loss: 4.320265769958496
Validation loss: 3.738786159023162

Epoch: 12| Step: 0
Training loss: 3.140150547027588
Validation loss: 3.730251750638408

Epoch: 6| Step: 1
Training loss: 3.551741123199463
Validation loss: 3.7223414323663198

Epoch: 6| Step: 2
Training loss: 3.446791410446167
Validation loss: 3.7129173483899844

Epoch: 6| Step: 3
Training loss: 3.019517183303833
Validation loss: 3.6995588015484553

Epoch: 6| Step: 4
Training loss: 3.219050884246826
Validation loss: 3.6885673871604343

Epoch: 6| Step: 5
Training loss: 4.453746795654297
Validation loss: 3.678407851085868

Epoch: 6| Step: 6
Training loss: 3.3140501976013184
Validation loss: 3.6675138934966056

Epoch: 6| Step: 7
Training loss: 4.557886123657227
Validation loss: 3.659771873104957

Epoch: 6| Step: 8
Training loss: 3.664998769760132
Validation loss: 3.648182451084096

Epoch: 6| Step: 9
Training loss: 3.2516555786132812
Validation loss: 3.6350425802251345

Epoch: 6| Step: 10
Training loss: 3.224841833114624
Validation loss: 3.622222449189873

Epoch: 6| Step: 11
Training loss: 3.5070302486419678
Validation loss: 3.612281019969653

Epoch: 6| Step: 12
Training loss: 3.962412118911743
Validation loss: 3.6017560189770115

Epoch: 6| Step: 13
Training loss: 3.5253090858459473
Validation loss: 3.5931377051978983

Epoch: 13| Step: 0
Training loss: 3.2043447494506836
Validation loss: 3.5745892217082362

Epoch: 6| Step: 1
Training loss: 4.085747718811035
Validation loss: 3.5692475047162784

Epoch: 6| Step: 2
Training loss: 3.698521137237549
Validation loss: 3.556056030334965

Epoch: 6| Step: 3
Training loss: 3.0532991886138916
Validation loss: 3.5350945944427163

Epoch: 6| Step: 4
Training loss: 4.900224685668945
Validation loss: 3.5248226529808453

Epoch: 6| Step: 5
Training loss: 3.1765642166137695
Validation loss: 3.5094614721113637

Epoch: 6| Step: 6
Training loss: 2.1294095516204834
Validation loss: 3.5038455788807203

Epoch: 6| Step: 7
Training loss: 3.8742947578430176
Validation loss: 3.4909595417720016

Epoch: 6| Step: 8
Training loss: 4.6845622062683105
Validation loss: 3.4714818974976898

Epoch: 6| Step: 9
Training loss: 3.095377206802368
Validation loss: 3.4629522831209245

Epoch: 6| Step: 10
Training loss: 2.5446043014526367
Validation loss: 3.4476791453617874

Epoch: 6| Step: 11
Training loss: 2.0258030891418457
Validation loss: 3.4304617758720153

Epoch: 6| Step: 12
Training loss: 3.478964328765869
Validation loss: 3.4172104302273003

Epoch: 6| Step: 13
Training loss: 4.307596206665039
Validation loss: 3.4062191901668424

Epoch: 14| Step: 0
Training loss: 2.8383164405822754
Validation loss: 3.3962613946648053

Epoch: 6| Step: 1
Training loss: 3.535796642303467
Validation loss: 3.383060855250205

Epoch: 6| Step: 2
Training loss: 3.081101417541504
Validation loss: 3.3639768272317867

Epoch: 6| Step: 3
Training loss: 3.024841785430908
Validation loss: 3.348678212012014

Epoch: 6| Step: 4
Training loss: 3.1545333862304688
Validation loss: 3.3380049454268588

Epoch: 6| Step: 5
Training loss: 2.7927894592285156
Validation loss: 3.322689046141922

Epoch: 6| Step: 6
Training loss: 3.1337709426879883
Validation loss: 3.30070230525027

Epoch: 6| Step: 7
Training loss: 3.37668514251709
Validation loss: 3.28188394987455

Epoch: 6| Step: 8
Training loss: 4.164609909057617
Validation loss: 3.2812156933610157

Epoch: 6| Step: 9
Training loss: 3.772916793823242
Validation loss: 3.25908600899481

Epoch: 6| Step: 10
Training loss: 3.016251802444458
Validation loss: 3.243547513920774

Epoch: 6| Step: 11
Training loss: 3.636535406112671
Validation loss: 3.2364683151245117

Epoch: 6| Step: 12
Training loss: 2.58941650390625
Validation loss: 3.2094763914744058

Epoch: 6| Step: 13
Training loss: 3.4500863552093506
Validation loss: 3.1992481036852767

Epoch: 15| Step: 0
Training loss: 3.139680862426758
Validation loss: 3.1810962794929423

Epoch: 6| Step: 1
Training loss: 2.9447708129882812
Validation loss: 3.162024756913544

Epoch: 6| Step: 2
Training loss: 2.1921496391296387
Validation loss: 3.143403317338677

Epoch: 6| Step: 3
Training loss: 3.3081161975860596
Validation loss: 3.1355744766932663

Epoch: 6| Step: 4
Training loss: 3.0238919258117676
Validation loss: 3.114585327845748

Epoch: 6| Step: 5
Training loss: 3.380812644958496
Validation loss: 3.091541623556486

Epoch: 6| Step: 6
Training loss: 3.312859296798706
Validation loss: 3.078255266271612

Epoch: 6| Step: 7
Training loss: 3.422093152999878
Validation loss: 3.059905236767184

Epoch: 6| Step: 8
Training loss: 2.720179796218872
Validation loss: 3.0291971673247633

Epoch: 6| Step: 9
Training loss: 3.032961845397949
Validation loss: 3.0247848213359876

Epoch: 6| Step: 10
Training loss: 3.937373161315918
Validation loss: 3.0151420511225218

Epoch: 6| Step: 11
Training loss: 2.5849406719207764
Validation loss: 2.9785496906567643

Epoch: 6| Step: 12
Training loss: 3.177466869354248
Validation loss: 2.977680908736362

Epoch: 6| Step: 13
Training loss: 2.808149814605713
Validation loss: 2.9690082970485894

Epoch: 16| Step: 0
Training loss: 3.3736627101898193
Validation loss: 2.944449552925684

Epoch: 6| Step: 1
Training loss: 2.6032066345214844
Validation loss: 2.9244326135163665

Epoch: 6| Step: 2
Training loss: 2.93436336517334
Validation loss: 2.912722877276841

Epoch: 6| Step: 3
Training loss: 3.094974994659424
Validation loss: 2.89552277903403

Epoch: 6| Step: 4
Training loss: 3.7293543815612793
Validation loss: 2.8755376287685928

Epoch: 6| Step: 5
Training loss: 2.185208797454834
Validation loss: 2.8614339649036364

Epoch: 6| Step: 6
Training loss: 3.1099977493286133
Validation loss: 2.8574618370302263

Epoch: 6| Step: 7
Training loss: 2.7417383193969727
Validation loss: 2.81829591976699

Epoch: 6| Step: 8
Training loss: 3.308655023574829
Validation loss: 2.8085818880347797

Epoch: 6| Step: 9
Training loss: 2.4152612686157227
Validation loss: 2.7865025074251237

Epoch: 6| Step: 10
Training loss: 3.0749428272247314
Validation loss: 2.7726522620006273

Epoch: 6| Step: 11
Training loss: 2.8212687969207764
Validation loss: 2.7441113712967082

Epoch: 6| Step: 12
Training loss: 2.9494285583496094
Validation loss: 2.7411599492514007

Epoch: 6| Step: 13
Training loss: 2.249138355255127
Validation loss: 2.7312187379406345

Epoch: 17| Step: 0
Training loss: 2.635288715362549
Validation loss: 2.6944916043230283

Epoch: 6| Step: 1
Training loss: 2.544160842895508
Validation loss: 2.6914816389801683

Epoch: 6| Step: 2
Training loss: 3.577444314956665
Validation loss: 2.662913668540216

Epoch: 6| Step: 3
Training loss: 2.7672204971313477
Validation loss: 2.6505957213781213

Epoch: 6| Step: 4
Training loss: 3.6648058891296387
Validation loss: 2.620965175731208

Epoch: 6| Step: 5
Training loss: 2.7465147972106934
Validation loss: 2.614562298661919

Epoch: 6| Step: 6
Training loss: 2.7813079357147217
Validation loss: 2.590007520491077

Epoch: 6| Step: 7
Training loss: 2.6374833583831787
Validation loss: 2.5848059320962555

Epoch: 6| Step: 8
Training loss: 2.3654651641845703
Validation loss: 2.562930037898402

Epoch: 6| Step: 9
Training loss: 3.206301689147949
Validation loss: 2.542494773864746

Epoch: 6| Step: 10
Training loss: 2.6174702644348145
Validation loss: 2.5549950471488376

Epoch: 6| Step: 11
Training loss: 2.0403289794921875
Validation loss: 2.538107056771555

Epoch: 6| Step: 12
Training loss: 2.675583839416504
Validation loss: 2.5166093098220004

Epoch: 6| Step: 13
Training loss: 2.3165385723114014
Validation loss: 2.5013864271102415

Epoch: 18| Step: 0
Training loss: 3.7431931495666504
Validation loss: 2.4762739981374433

Epoch: 6| Step: 1
Training loss: 2.7006053924560547
Validation loss: 2.485479465094946

Epoch: 6| Step: 2
Training loss: 2.6011781692504883
Validation loss: 2.4654525056962044

Epoch: 6| Step: 3
Training loss: 2.5918850898742676
Validation loss: 2.4376374906109226

Epoch: 6| Step: 4
Training loss: 2.7383182048797607
Validation loss: 2.4329290287469023

Epoch: 6| Step: 5
Training loss: 2.7170770168304443
Validation loss: 2.4211005087821715

Epoch: 6| Step: 6
Training loss: 2.289486885070801
Validation loss: 2.422683790165891

Epoch: 6| Step: 7
Training loss: 2.5090627670288086
Validation loss: 2.370938008831393

Epoch: 6| Step: 8
Training loss: 2.4897565841674805
Validation loss: 2.3732983937827488

Epoch: 6| Step: 9
Training loss: 3.415738821029663
Validation loss: 2.3684728555781867

Epoch: 6| Step: 10
Training loss: 2.4906091690063477
Validation loss: 2.3424062087971675

Epoch: 6| Step: 11
Training loss: 2.994020700454712
Validation loss: 2.3471612391933316

Epoch: 6| Step: 12
Training loss: 1.25166916847229
Validation loss: 2.347581501929991

Epoch: 6| Step: 13
Training loss: 2.068284749984741
Validation loss: 2.3133095413125973

Epoch: 19| Step: 0
Training loss: 3.2087554931640625
Validation loss: 2.3251072796442176

Epoch: 6| Step: 1
Training loss: 2.618281126022339
Validation loss: 2.2993169933237056

Epoch: 6| Step: 2
Training loss: 2.6576719284057617
Validation loss: 2.287021521599062

Epoch: 6| Step: 3
Training loss: 2.452690601348877
Validation loss: 2.2783908382538827

Epoch: 6| Step: 4
Training loss: 2.9037017822265625
Validation loss: 2.267544513107628

Epoch: 6| Step: 5
Training loss: 2.1261205673217773
Validation loss: 2.2683903991535144

Epoch: 6| Step: 6
Training loss: 1.864828109741211
Validation loss: 2.2613547873753372

Epoch: 6| Step: 7
Training loss: 2.461550235748291
Validation loss: 2.2401774109050794

Epoch: 6| Step: 8
Training loss: 2.6074676513671875
Validation loss: 2.2231865826473443

Epoch: 6| Step: 9
Training loss: 2.874263286590576
Validation loss: 2.2063668081837315

Epoch: 6| Step: 10
Training loss: 2.562804698944092
Validation loss: 2.2026207575234036

Epoch: 6| Step: 11
Training loss: 2.2802252769470215
Validation loss: 2.191101187018938

Epoch: 6| Step: 12
Training loss: 2.3515138626098633
Validation loss: 2.21530931995761

Epoch: 6| Step: 13
Training loss: 2.494799852371216
Validation loss: 2.2088244063879854

Epoch: 20| Step: 0
Training loss: 2.5678534507751465
Validation loss: 2.1740362567286335

Epoch: 6| Step: 1
Training loss: 2.484402656555176
Validation loss: 2.18002289084978

Epoch: 6| Step: 2
Training loss: 2.8067400455474854
Validation loss: 2.1934588519475793

Epoch: 6| Step: 3
Training loss: 2.0278213024139404
Validation loss: 2.1651944960317304

Epoch: 6| Step: 4
Training loss: 2.540196418762207
Validation loss: 2.1815977814376994

Epoch: 6| Step: 5
Training loss: 2.2491812705993652
Validation loss: 2.183215856552124

Epoch: 6| Step: 6
Training loss: 2.8239173889160156
Validation loss: 2.1609064891774166

Epoch: 6| Step: 7
Training loss: 2.5174429416656494
Validation loss: 2.151946488247123

Epoch: 6| Step: 8
Training loss: 1.9790067672729492
Validation loss: 2.1609442592948995

Epoch: 6| Step: 9
Training loss: 2.8300013542175293
Validation loss: 2.1350482535618607

Epoch: 6| Step: 10
Training loss: 2.060319185256958
Validation loss: 2.1657414923432055

Epoch: 6| Step: 11
Training loss: 1.8897833824157715
Validation loss: 2.134435353740569

Epoch: 6| Step: 12
Training loss: 2.8114264011383057
Validation loss: 2.127983654699018

Epoch: 6| Step: 13
Training loss: 3.5807533264160156
Validation loss: 2.15023148188027

Epoch: 21| Step: 0
Training loss: 2.2139580249786377
Validation loss: 2.1341843963951193

Epoch: 6| Step: 1
Training loss: 2.952528953552246
Validation loss: 2.144246114197598

Epoch: 6| Step: 2
Training loss: 3.0377249717712402
Validation loss: 2.129524976976456

Epoch: 6| Step: 3
Training loss: 1.9339581727981567
Validation loss: 2.140145291564285

Epoch: 6| Step: 4
Training loss: 2.520966053009033
Validation loss: 2.112426932140063

Epoch: 6| Step: 5
Training loss: 2.445098400115967
Validation loss: 2.1191342722985054

Epoch: 6| Step: 6
Training loss: 2.6635868549346924
Validation loss: 2.1251178685054986

Epoch: 6| Step: 7
Training loss: 3.0263867378234863
Validation loss: 2.123251352258908

Epoch: 6| Step: 8
Training loss: 2.572470188140869
Validation loss: 2.114253600438436

Epoch: 6| Step: 9
Training loss: 2.532400131225586
Validation loss: 2.107624405173845

Epoch: 6| Step: 10
Training loss: 2.1323819160461426
Validation loss: 2.114040684956376

Epoch: 6| Step: 11
Training loss: 2.043224334716797
Validation loss: 2.0948930889047603

Epoch: 6| Step: 12
Training loss: 1.8187618255615234
Validation loss: 2.119315557582404

Epoch: 6| Step: 13
Training loss: 2.6661570072174072
Validation loss: 2.1049938227540705

Epoch: 22| Step: 0
Training loss: 2.7591114044189453
Validation loss: 2.089009705410209

Epoch: 6| Step: 1
Training loss: 2.113316535949707
Validation loss: 2.120854475164926

Epoch: 6| Step: 2
Training loss: 2.7536234855651855
Validation loss: 2.096190174420675

Epoch: 6| Step: 3
Training loss: 2.723750114440918
Validation loss: 2.1009446497886413

Epoch: 6| Step: 4
Training loss: 3.021879196166992
Validation loss: 2.099647985991611

Epoch: 6| Step: 5
Training loss: 2.14249849319458
Validation loss: 2.105745441170149

Epoch: 6| Step: 6
Training loss: 1.5228043794631958
Validation loss: 2.087999971964026

Epoch: 6| Step: 7
Training loss: 1.8613977432250977
Validation loss: 2.098488062940618

Epoch: 6| Step: 8
Training loss: 2.8615036010742188
Validation loss: 2.117821717774996

Epoch: 6| Step: 9
Training loss: 2.760828733444214
Validation loss: 2.0990729831880137

Epoch: 6| Step: 10
Training loss: 2.6374244689941406
Validation loss: 2.100612025107107

Epoch: 6| Step: 11
Training loss: 2.1812071800231934
Validation loss: 2.100049275223927

Epoch: 6| Step: 12
Training loss: 2.586085796356201
Validation loss: 2.1084500435859925

Epoch: 6| Step: 13
Training loss: 2.5178112983703613
Validation loss: 2.1033836308346

Epoch: 23| Step: 0
Training loss: 2.316969871520996
Validation loss: 2.1101150487058904

Epoch: 6| Step: 1
Training loss: 1.661484718322754
Validation loss: 2.1019345150198987

Epoch: 6| Step: 2
Training loss: 2.1788415908813477
Validation loss: 2.0822516205490276

Epoch: 6| Step: 3
Training loss: 1.903159260749817
Validation loss: 2.0899452804237284

Epoch: 6| Step: 4
Training loss: 2.3325438499450684
Validation loss: 2.0942855932379283

Epoch: 6| Step: 5
Training loss: 2.9580750465393066
Validation loss: 2.093330225636882

Epoch: 6| Step: 6
Training loss: 2.5549890995025635
Validation loss: 2.1118303255368303

Epoch: 6| Step: 7
Training loss: 2.743471622467041
Validation loss: 2.0966581426640993

Epoch: 6| Step: 8
Training loss: 2.5227713584899902
Validation loss: 2.098250340389949

Epoch: 6| Step: 9
Training loss: 2.530535936355591
Validation loss: 2.1033401950713126

Epoch: 6| Step: 10
Training loss: 3.004225254058838
Validation loss: 2.0896436757938837

Epoch: 6| Step: 11
Training loss: 3.0208892822265625
Validation loss: 2.107103083723335

Epoch: 6| Step: 12
Training loss: 2.2214250564575195
Validation loss: 2.105857801693742

Epoch: 6| Step: 13
Training loss: 2.477001905441284
Validation loss: 2.0938007395754576

Epoch: 24| Step: 0
Training loss: 2.863008975982666
Validation loss: 2.0898686057777813

Epoch: 6| Step: 1
Training loss: 1.8250579833984375
Validation loss: 2.078636747534557

Epoch: 6| Step: 2
Training loss: 2.238490581512451
Validation loss: 2.0743032399044243

Epoch: 6| Step: 3
Training loss: 2.9996414184570312
Validation loss: 2.078595825420913

Epoch: 6| Step: 4
Training loss: 2.9339165687561035
Validation loss: 2.0770481504419798

Epoch: 6| Step: 5
Training loss: 2.4173245429992676
Validation loss: 2.079472505918113

Epoch: 6| Step: 6
Training loss: 2.468459129333496
Validation loss: 2.0804864642440632

Epoch: 6| Step: 7
Training loss: 1.6318615674972534
Validation loss: 2.0836471742199314

Epoch: 6| Step: 8
Training loss: 2.411747455596924
Validation loss: 2.077700217564901

Epoch: 6| Step: 9
Training loss: 3.1685714721679688
Validation loss: 2.078201643882259

Epoch: 6| Step: 10
Training loss: 2.2887871265411377
Validation loss: 2.0695003348012126

Epoch: 6| Step: 11
Training loss: 2.797278642654419
Validation loss: 2.0796110527489775

Epoch: 6| Step: 12
Training loss: 2.055105209350586
Validation loss: 2.0750893879962224

Epoch: 6| Step: 13
Training loss: 1.6464320421218872
Validation loss: 2.0994814288231636

Epoch: 25| Step: 0
Training loss: 2.1920628547668457
Validation loss: 2.0891769624525502

Epoch: 6| Step: 1
Training loss: 2.001833915710449
Validation loss: 2.072921138937755

Epoch: 6| Step: 2
Training loss: 2.888902187347412
Validation loss: 2.079606527923256

Epoch: 6| Step: 3
Training loss: 2.4128754138946533
Validation loss: 2.095026359763197

Epoch: 6| Step: 4
Training loss: 2.4792754650115967
Validation loss: 2.088104381356188

Epoch: 6| Step: 5
Training loss: 2.2477359771728516
Validation loss: 2.0764688189311693

Epoch: 6| Step: 6
Training loss: 2.5931396484375
Validation loss: 2.0986191636772564

Epoch: 6| Step: 7
Training loss: 3.0772221088409424
Validation loss: 2.076387072122225

Epoch: 6| Step: 8
Training loss: 2.18475604057312
Validation loss: 2.082896024950089

Epoch: 6| Step: 9
Training loss: 2.9299049377441406
Validation loss: 2.064132841684485

Epoch: 6| Step: 10
Training loss: 2.562718391418457
Validation loss: 2.065356271241301

Epoch: 6| Step: 11
Training loss: 2.666201591491699
Validation loss: 2.0767544930981052

Epoch: 6| Step: 12
Training loss: 1.6212036609649658
Validation loss: 2.058267375474335

Epoch: 6| Step: 13
Training loss: 2.4018845558166504
Validation loss: 2.0816601437907063

Epoch: 26| Step: 0
Training loss: 3.29238224029541
Validation loss: 2.0659251430983185

Epoch: 6| Step: 1
Training loss: 2.4241209030151367
Validation loss: 2.0926211905735794

Epoch: 6| Step: 2
Training loss: 2.402395486831665
Validation loss: 2.0628640984976165

Epoch: 6| Step: 3
Training loss: 2.564824104309082
Validation loss: 2.0849619527016916

Epoch: 6| Step: 4
Training loss: 2.1342315673828125
Validation loss: 2.0957467299635693

Epoch: 6| Step: 5
Training loss: 1.8844298124313354
Validation loss: 2.070275607929435

Epoch: 6| Step: 6
Training loss: 1.851492166519165
Validation loss: 2.0984546010212233

Epoch: 6| Step: 7
Training loss: 2.071171760559082
Validation loss: 2.0708991455775436

Epoch: 6| Step: 8
Training loss: 3.0478577613830566
Validation loss: 2.0954261415748188

Epoch: 6| Step: 9
Training loss: 2.4874184131622314
Validation loss: 2.08671425619433

Epoch: 6| Step: 10
Training loss: 2.964351177215576
Validation loss: 2.0758542168524956

Epoch: 6| Step: 11
Training loss: 1.8929576873779297
Validation loss: 2.0783735244504866

Epoch: 6| Step: 12
Training loss: 2.6947929859161377
Validation loss: 2.1056522246330016

Epoch: 6| Step: 13
Training loss: 2.3316214084625244
Validation loss: 2.092968012696953

Epoch: 27| Step: 0
Training loss: 2.2211313247680664
Validation loss: 2.079358426473474

Epoch: 6| Step: 1
Training loss: 1.4470891952514648
Validation loss: 2.0842291565351587

Epoch: 6| Step: 2
Training loss: 2.4502763748168945
Validation loss: 2.095778162761401

Epoch: 6| Step: 3
Training loss: 2.6697750091552734
Validation loss: 2.0854346649621123

Epoch: 6| Step: 4
Training loss: 2.542078971862793
Validation loss: 2.085158371156262

Epoch: 6| Step: 5
Training loss: 3.086092948913574
Validation loss: 2.080193749038122

Epoch: 6| Step: 6
Training loss: 3.0638904571533203
Validation loss: 2.088807422627685

Epoch: 6| Step: 7
Training loss: 2.1911215782165527
Validation loss: 2.084144615357922

Epoch: 6| Step: 8
Training loss: 2.305850028991699
Validation loss: 2.0907681219039427

Epoch: 6| Step: 9
Training loss: 2.654576301574707
Validation loss: 2.107011023388114

Epoch: 6| Step: 10
Training loss: 2.461371421813965
Validation loss: 2.1065755095533145

Epoch: 6| Step: 11
Training loss: 2.5822384357452393
Validation loss: 2.092362961461467

Epoch: 6| Step: 12
Training loss: 2.0521862506866455
Validation loss: 2.0965690356428905

Epoch: 6| Step: 13
Training loss: 2.2331888675689697
Validation loss: 2.0976686439206524

Epoch: 28| Step: 0
Training loss: 2.9324207305908203
Validation loss: 2.0858792489574802

Epoch: 6| Step: 1
Training loss: 2.5693535804748535
Validation loss: 2.0957486385940225

Epoch: 6| Step: 2
Training loss: 2.11045503616333
Validation loss: 2.083279553280082

Epoch: 6| Step: 3
Training loss: 1.7356908321380615
Validation loss: 2.1020387372662945

Epoch: 6| Step: 4
Training loss: 2.1842498779296875
Validation loss: 2.0954388367232455

Epoch: 6| Step: 5
Training loss: 2.6589479446411133
Validation loss: 2.1000049062954482

Epoch: 6| Step: 6
Training loss: 2.373579502105713
Validation loss: 2.090774029813787

Epoch: 6| Step: 7
Training loss: 2.0325822830200195
Validation loss: 2.0901258837792183

Epoch: 6| Step: 8
Training loss: 2.3489603996276855
Validation loss: 2.0818213044956164

Epoch: 6| Step: 9
Training loss: 2.490053653717041
Validation loss: 2.083390949874796

Epoch: 6| Step: 10
Training loss: 3.115386962890625
Validation loss: 2.08816368861865

Epoch: 6| Step: 11
Training loss: 2.901200532913208
Validation loss: 2.0684035619099936

Epoch: 6| Step: 12
Training loss: 2.136164665222168
Validation loss: 2.0913509040750484

Epoch: 6| Step: 13
Training loss: 2.3355913162231445
Validation loss: 2.0832598504199775

Epoch: 29| Step: 0
Training loss: 2.3884201049804688
Validation loss: 2.1016387888180312

Epoch: 6| Step: 1
Training loss: 2.6889829635620117
Validation loss: 2.090392384477841

Epoch: 6| Step: 2
Training loss: 2.157301902770996
Validation loss: 2.0986537535985312

Epoch: 6| Step: 3
Training loss: 2.23958158493042
Validation loss: 2.0928033962044665

Epoch: 6| Step: 4
Training loss: 2.3410558700561523
Validation loss: 2.104598056885504

Epoch: 6| Step: 5
Training loss: 2.290933609008789
Validation loss: 2.084381336806923

Epoch: 6| Step: 6
Training loss: 1.849708080291748
Validation loss: 2.094827659668461

Epoch: 6| Step: 7
Training loss: 2.634416103363037
Validation loss: 2.0829493422662058

Epoch: 6| Step: 8
Training loss: 2.093949556350708
Validation loss: 2.0829575215616534

Epoch: 6| Step: 9
Training loss: 2.3243448734283447
Validation loss: 2.0920954442793325

Epoch: 6| Step: 10
Training loss: 2.8040199279785156
Validation loss: 2.090681022213351

Epoch: 6| Step: 11
Training loss: 3.063643217086792
Validation loss: 2.0819787094669957

Epoch: 6| Step: 12
Training loss: 2.7889962196350098
Validation loss: 2.0974762721728255

Epoch: 6| Step: 13
Training loss: 2.468925952911377
Validation loss: 2.0863413118547007

Epoch: 30| Step: 0
Training loss: 2.030029296875
Validation loss: 2.1017863712003155

Epoch: 6| Step: 1
Training loss: 2.513601541519165
Validation loss: 2.0933135965819

Epoch: 6| Step: 2
Training loss: 2.144761085510254
Validation loss: 2.111320790424142

Epoch: 6| Step: 3
Training loss: 2.246680498123169
Validation loss: 2.0735479580458773

Epoch: 6| Step: 4
Training loss: 2.8612451553344727
Validation loss: 2.0681415578370452

Epoch: 6| Step: 5
Training loss: 2.887984037399292
Validation loss: 2.095397847954945

Epoch: 6| Step: 6
Training loss: 1.652536392211914
Validation loss: 2.0919197220956125

Epoch: 6| Step: 7
Training loss: 2.150566577911377
Validation loss: 2.09061998192982

Epoch: 6| Step: 8
Training loss: 2.666810989379883
Validation loss: 2.080471623328424

Epoch: 6| Step: 9
Training loss: 3.564592123031616
Validation loss: 2.066837667137064

Epoch: 6| Step: 10
Training loss: 2.5569539070129395
Validation loss: 2.073449642427506

Epoch: 6| Step: 11
Training loss: 2.5018527507781982
Validation loss: 2.0759140086430374

Epoch: 6| Step: 12
Training loss: 1.9055615663528442
Validation loss: 2.0918292589085077

Epoch: 6| Step: 13
Training loss: 1.7153704166412354
Validation loss: 2.07028389746143

Epoch: 31| Step: 0
Training loss: 2.4548401832580566
Validation loss: 2.056352130828365

Epoch: 6| Step: 1
Training loss: 1.803994059562683
Validation loss: 2.0800108589151853

Epoch: 6| Step: 2
Training loss: 2.653352737426758
Validation loss: 2.0719525365419287

Epoch: 6| Step: 3
Training loss: 3.2314205169677734
Validation loss: 2.0700645087867655

Epoch: 6| Step: 4
Training loss: 3.393193244934082
Validation loss: 2.076997278839029

Epoch: 6| Step: 5
Training loss: 2.6517763137817383
Validation loss: 2.0735620939603416

Epoch: 6| Step: 6
Training loss: 2.239356756210327
Validation loss: 2.0916978082349225

Epoch: 6| Step: 7
Training loss: 2.6098854541778564
Validation loss: 2.0694483069963354

Epoch: 6| Step: 8
Training loss: 1.9949294328689575
Validation loss: 2.0511754507659585

Epoch: 6| Step: 9
Training loss: 2.0336430072784424
Validation loss: 2.061415862011653

Epoch: 6| Step: 10
Training loss: 1.855055809020996
Validation loss: 2.072423150462489

Epoch: 6| Step: 11
Training loss: 2.3541972637176514
Validation loss: 2.057051638121246

Epoch: 6| Step: 12
Training loss: 1.899718999862671
Validation loss: 2.0717438600396596

Epoch: 6| Step: 13
Training loss: 2.87939453125
Validation loss: 2.0616905766148723

Epoch: 32| Step: 0
Training loss: 2.3060402870178223
Validation loss: 2.078882122552523

Epoch: 6| Step: 1
Training loss: 2.7929439544677734
Validation loss: 2.0540555266923803

Epoch: 6| Step: 2
Training loss: 2.3856358528137207
Validation loss: 2.0754006472967004

Epoch: 6| Step: 3
Training loss: 2.5140624046325684
Validation loss: 2.0673700199332288

Epoch: 6| Step: 4
Training loss: 2.2303481101989746
Validation loss: 2.071812455372144

Epoch: 6| Step: 5
Training loss: 2.309445381164551
Validation loss: 2.049773427747911

Epoch: 6| Step: 6
Training loss: 2.3655359745025635
Validation loss: 2.0667734428118636

Epoch: 6| Step: 7
Training loss: 1.7946035861968994
Validation loss: 2.087784682550738

Epoch: 6| Step: 8
Training loss: 2.7958836555480957
Validation loss: 2.093237348782119

Epoch: 6| Step: 9
Training loss: 2.1829586029052734
Validation loss: 2.0709471497484433

Epoch: 6| Step: 10
Training loss: 2.0106844902038574
Validation loss: 2.0570209692883235

Epoch: 6| Step: 11
Training loss: 2.8014626502990723
Validation loss: 2.0746417263502717

Epoch: 6| Step: 12
Training loss: 2.7742671966552734
Validation loss: 2.076744579499768

Epoch: 6| Step: 13
Training loss: 2.575352191925049
Validation loss: 2.0526061186226467

Epoch: 33| Step: 0
Training loss: 2.482089042663574
Validation loss: 2.082052077016523

Epoch: 6| Step: 1
Training loss: 2.517629623413086
Validation loss: 2.0729632787807013

Epoch: 6| Step: 2
Training loss: 2.516382932662964
Validation loss: 2.0876929003705262

Epoch: 6| Step: 3
Training loss: 2.2445144653320312
Validation loss: 2.0871181026581795

Epoch: 6| Step: 4
Training loss: 2.119006872177124
Validation loss: 2.072177869017406

Epoch: 6| Step: 5
Training loss: 2.891968250274658
Validation loss: 2.0810304123868226

Epoch: 6| Step: 6
Training loss: 2.3115174770355225
Validation loss: 2.0821132403548046

Epoch: 6| Step: 7
Training loss: 2.6370112895965576
Validation loss: 2.074255730516167

Epoch: 6| Step: 8
Training loss: 2.6013917922973633
Validation loss: 2.0916237087659937

Epoch: 6| Step: 9
Training loss: 2.0647544860839844
Validation loss: 2.092201999438706

Epoch: 6| Step: 10
Training loss: 2.5377378463745117
Validation loss: 2.1036152224386893

Epoch: 6| Step: 11
Training loss: 2.490812063217163
Validation loss: 2.0888111693884737

Epoch: 6| Step: 12
Training loss: 2.32545804977417
Validation loss: 2.0909956475739837

Epoch: 6| Step: 13
Training loss: 1.766302466392517
Validation loss: 2.085923042348636

Epoch: 34| Step: 0
Training loss: 2.474823236465454
Validation loss: 2.104568571172735

Epoch: 6| Step: 1
Training loss: 2.9659602642059326
Validation loss: 2.083716102825698

Epoch: 6| Step: 2
Training loss: 2.331120014190674
Validation loss: 2.0803537368774414

Epoch: 6| Step: 3
Training loss: 2.951286792755127
Validation loss: 2.0947944297585437

Epoch: 6| Step: 4
Training loss: 2.9610090255737305
Validation loss: 2.073718196602278

Epoch: 6| Step: 5
Training loss: 2.0611519813537598
Validation loss: 2.0850342307039487

Epoch: 6| Step: 6
Training loss: 1.6672592163085938
Validation loss: 2.084894322579907

Epoch: 6| Step: 7
Training loss: 2.7683544158935547
Validation loss: 2.079944561886531

Epoch: 6| Step: 8
Training loss: 1.8898344039916992
Validation loss: 2.09171494489075

Epoch: 6| Step: 9
Training loss: 1.8637890815734863
Validation loss: 2.0559503698861725

Epoch: 6| Step: 10
Training loss: 2.4213500022888184
Validation loss: 2.070538333667222

Epoch: 6| Step: 11
Training loss: 2.198026657104492
Validation loss: 2.0728177960200975

Epoch: 6| Step: 12
Training loss: 2.685760021209717
Validation loss: 2.0750137144519436

Epoch: 6| Step: 13
Training loss: 2.1767094135284424
Validation loss: 2.046473417230832

Epoch: 35| Step: 0
Training loss: 2.1061978340148926
Validation loss: 2.069545784304219

Epoch: 6| Step: 1
Training loss: 2.4838056564331055
Validation loss: 2.0795577418419624

Epoch: 6| Step: 2
Training loss: 2.00986385345459
Validation loss: 2.0679795947126163

Epoch: 6| Step: 3
Training loss: 2.791696071624756
Validation loss: 2.075200976863984

Epoch: 6| Step: 4
Training loss: 2.1789584159851074
Validation loss: 2.0719090123330393

Epoch: 6| Step: 5
Training loss: 2.5645570755004883
Validation loss: 2.0709187151283346

Epoch: 6| Step: 6
Training loss: 2.3352279663085938
Validation loss: 2.0608542324394308

Epoch: 6| Step: 7
Training loss: 2.297778367996216
Validation loss: 2.081781892366307

Epoch: 6| Step: 8
Training loss: 2.3743395805358887
Validation loss: 2.0543655092998216

Epoch: 6| Step: 9
Training loss: 2.4511947631835938
Validation loss: 2.0803436899697907

Epoch: 6| Step: 10
Training loss: 2.5325896739959717
Validation loss: 2.058618490413953

Epoch: 6| Step: 11
Training loss: 2.636892080307007
Validation loss: 2.055795092736521

Epoch: 6| Step: 12
Training loss: 2.4509060382843018
Validation loss: 2.037767865324533

Epoch: 6| Step: 13
Training loss: 2.443455457687378
Validation loss: 2.0696025368987874

Epoch: 36| Step: 0
Training loss: 2.1586990356445312
Validation loss: 2.060635769239036

Epoch: 6| Step: 1
Training loss: 2.2013602256774902
Validation loss: 2.05826231228408

Epoch: 6| Step: 2
Training loss: 2.622375011444092
Validation loss: 2.040493243484087

Epoch: 6| Step: 3
Training loss: 1.8968207836151123
Validation loss: 2.0615135367198656

Epoch: 6| Step: 4
Training loss: 3.122300624847412
Validation loss: 2.0599700250933246

Epoch: 6| Step: 5
Training loss: 1.6158626079559326
Validation loss: 2.0608440932407173

Epoch: 6| Step: 6
Training loss: 2.332402229309082
Validation loss: 2.0585657999079716

Epoch: 6| Step: 7
Training loss: 2.257826328277588
Validation loss: 2.0607206488168366

Epoch: 6| Step: 8
Training loss: 2.847275733947754
Validation loss: 2.060012650746171

Epoch: 6| Step: 9
Training loss: 2.8781471252441406
Validation loss: 2.0443095443069295

Epoch: 6| Step: 10
Training loss: 2.6114606857299805
Validation loss: 2.0582047893155004

Epoch: 6| Step: 11
Training loss: 1.776824712753296
Validation loss: 2.050146605378838

Epoch: 6| Step: 12
Training loss: 2.3370361328125
Validation loss: 2.040654795144194

Epoch: 6| Step: 13
Training loss: 3.3424339294433594
Validation loss: 2.0387540632678616

Epoch: 37| Step: 0
Training loss: 2.021045684814453
Validation loss: 2.077703809225431

Epoch: 6| Step: 1
Training loss: 1.9832379817962646
Validation loss: 2.052786047740649

Epoch: 6| Step: 2
Training loss: 2.63261079788208
Validation loss: 2.0506482944693616

Epoch: 6| Step: 3
Training loss: 2.680047035217285
Validation loss: 2.0554672030992407

Epoch: 6| Step: 4
Training loss: 2.5302181243896484
Validation loss: 2.061350485329987

Epoch: 6| Step: 5
Training loss: 2.460726022720337
Validation loss: 2.033019983640281

Epoch: 6| Step: 6
Training loss: 2.6571128368377686
Validation loss: 2.075598345007948

Epoch: 6| Step: 7
Training loss: 2.8511962890625
Validation loss: 2.0601465266237975

Epoch: 6| Step: 8
Training loss: 2.448293685913086
Validation loss: 2.051961468112084

Epoch: 6| Step: 9
Training loss: 2.0705697536468506
Validation loss: 2.0539357764746553

Epoch: 6| Step: 10
Training loss: 2.6121206283569336
Validation loss: 2.051095311359693

Epoch: 6| Step: 11
Training loss: 2.036412000656128
Validation loss: 2.0343423940802134

Epoch: 6| Step: 12
Training loss: 1.8729848861694336
Validation loss: 2.069111975290442

Epoch: 6| Step: 13
Training loss: 2.8821775913238525
Validation loss: 2.0574380120923443

Epoch: 38| Step: 0
Training loss: 2.563509941101074
Validation loss: 2.0748608086698797

Epoch: 6| Step: 1
Training loss: 2.936190605163574
Validation loss: 2.072561381965555

Epoch: 6| Step: 2
Training loss: 2.4770283699035645
Validation loss: 2.0728484904894264

Epoch: 6| Step: 3
Training loss: 2.501981496810913
Validation loss: 2.089647154654226

Epoch: 6| Step: 4
Training loss: 2.1588940620422363
Validation loss: 2.069403971395185

Epoch: 6| Step: 5
Training loss: 2.206803560256958
Validation loss: 2.0781974510479997

Epoch: 6| Step: 6
Training loss: 2.1814773082733154
Validation loss: 2.073098918443085

Epoch: 6| Step: 7
Training loss: 2.0365710258483887
Validation loss: 2.065330315661687

Epoch: 6| Step: 8
Training loss: 2.5625715255737305
Validation loss: 2.0692673267856723

Epoch: 6| Step: 9
Training loss: 2.856869697570801
Validation loss: 2.0784056096948604

Epoch: 6| Step: 10
Training loss: 2.247309923171997
Validation loss: 2.078306190429195

Epoch: 6| Step: 11
Training loss: 2.1888363361358643
Validation loss: 2.075348907901395

Epoch: 6| Step: 12
Training loss: 1.5906774997711182
Validation loss: 2.0732651231109456

Epoch: 6| Step: 13
Training loss: 3.1310510635375977
Validation loss: 2.064862107717863

Epoch: 39| Step: 0
Training loss: 2.089296579360962
Validation loss: 2.071725888918805

Epoch: 6| Step: 1
Training loss: 2.650196075439453
Validation loss: 2.0677378818552983

Epoch: 6| Step: 2
Training loss: 2.071514129638672
Validation loss: 2.0722123858749226

Epoch: 6| Step: 3
Training loss: 3.1013131141662598
Validation loss: 2.0798339946295625

Epoch: 6| Step: 4
Training loss: 2.226576805114746
Validation loss: 2.074243107149678

Epoch: 6| Step: 5
Training loss: 2.277508497238159
Validation loss: 2.079596993743732

Epoch: 6| Step: 6
Training loss: 2.7195286750793457
Validation loss: 2.075209656069356

Epoch: 6| Step: 7
Training loss: 1.9112989902496338
Validation loss: 2.0563973329400502

Epoch: 6| Step: 8
Training loss: 2.7610831260681152
Validation loss: 2.0673693046774915

Epoch: 6| Step: 9
Training loss: 2.768846035003662
Validation loss: 2.060729544649842

Epoch: 6| Step: 10
Training loss: 2.2381036281585693
Validation loss: 2.0978186258705716

Epoch: 6| Step: 11
Training loss: 2.11179256439209
Validation loss: 2.0465177233501146

Epoch: 6| Step: 12
Training loss: 2.3516392707824707
Validation loss: 2.062059005101522

Epoch: 6| Step: 13
Training loss: 1.7994965314865112
Validation loss: 2.061125247709213

Epoch: 40| Step: 0
Training loss: 2.6650390625
Validation loss: 2.057539793752855

Epoch: 6| Step: 1
Training loss: 2.8603734970092773
Validation loss: 2.0647700653281262

Epoch: 6| Step: 2
Training loss: 2.2570648193359375
Validation loss: 2.076631117892522

Epoch: 6| Step: 3
Training loss: 2.034607172012329
Validation loss: 2.0675952921631517

Epoch: 6| Step: 4
Training loss: 2.036334753036499
Validation loss: 2.0741610757766233

Epoch: 6| Step: 5
Training loss: 3.019011974334717
Validation loss: 2.0671336548302763

Epoch: 6| Step: 6
Training loss: 2.5302999019622803
Validation loss: 2.0471812025193246

Epoch: 6| Step: 7
Training loss: 1.6101150512695312
Validation loss: 2.0639814779322636

Epoch: 6| Step: 8
Training loss: 2.403970718383789
Validation loss: 2.070891454655637

Epoch: 6| Step: 9
Training loss: 2.2371907234191895
Validation loss: 2.060831312210329

Epoch: 6| Step: 10
Training loss: 1.9213387966156006
Validation loss: 2.0517692899191253

Epoch: 6| Step: 11
Training loss: 2.5060675144195557
Validation loss: 2.026080490440451

Epoch: 6| Step: 12
Training loss: 2.6495466232299805
Validation loss: 2.0510875050739577

Epoch: 6| Step: 13
Training loss: 2.3124747276306152
Validation loss: 2.048370485664696

Epoch: 41| Step: 0
Training loss: 3.342435359954834
Validation loss: 2.0465297416974138

Epoch: 6| Step: 1
Training loss: 2.0673036575317383
Validation loss: 2.058857460175791

Epoch: 6| Step: 2
Training loss: 3.3351504802703857
Validation loss: 2.0505365569104432

Epoch: 6| Step: 3
Training loss: 1.5386598110198975
Validation loss: 2.048253672097319

Epoch: 6| Step: 4
Training loss: 2.0357179641723633
Validation loss: 2.0509872974887973

Epoch: 6| Step: 5
Training loss: 1.7901010513305664
Validation loss: 2.051751693089803

Epoch: 6| Step: 6
Training loss: 2.022817373275757
Validation loss: 2.0423941586607244

Epoch: 6| Step: 7
Training loss: 1.8372998237609863
Validation loss: 2.070203960582774

Epoch: 6| Step: 8
Training loss: 2.5437889099121094
Validation loss: 2.0470167231816117

Epoch: 6| Step: 9
Training loss: 1.954872727394104
Validation loss: 2.052648182838194

Epoch: 6| Step: 10
Training loss: 2.8785300254821777
Validation loss: 2.06551855866627

Epoch: 6| Step: 11
Training loss: 2.149013042449951
Validation loss: 2.0497745467770483

Epoch: 6| Step: 12
Training loss: 2.6710100173950195
Validation loss: 2.0535319646199546

Epoch: 6| Step: 13
Training loss: 3.438506603240967
Validation loss: 2.0530154807593233

Epoch: 42| Step: 0
Training loss: 3.00512957572937
Validation loss: 2.0405341912341375

Epoch: 6| Step: 1
Training loss: 1.9509066343307495
Validation loss: 2.043785261851485

Epoch: 6| Step: 2
Training loss: 2.7339394092559814
Validation loss: 2.039875030517578

Epoch: 6| Step: 3
Training loss: 1.9276814460754395
Validation loss: 2.0696551287046043

Epoch: 6| Step: 4
Training loss: 2.641890287399292
Validation loss: 2.0752597496073735

Epoch: 6| Step: 5
Training loss: 2.312455177307129
Validation loss: 2.033459186553955

Epoch: 6| Step: 6
Training loss: 2.231541633605957
Validation loss: 2.041409377128847

Epoch: 6| Step: 7
Training loss: 2.3852057456970215
Validation loss: 2.0440196426965858

Epoch: 6| Step: 8
Training loss: 2.604578733444214
Validation loss: 2.068730092817737

Epoch: 6| Step: 9
Training loss: 1.7699140310287476
Validation loss: 2.0441197579906834

Epoch: 6| Step: 10
Training loss: 3.071475028991699
Validation loss: 2.0618871693970053

Epoch: 6| Step: 11
Training loss: 2.4674839973449707
Validation loss: 2.0606598751519316

Epoch: 6| Step: 12
Training loss: 1.6572935581207275
Validation loss: 2.0647119117039505

Epoch: 6| Step: 13
Training loss: 2.4211740493774414
Validation loss: 2.0375791672737367

Epoch: 43| Step: 0
Training loss: 2.6647214889526367
Validation loss: 2.056680593439328

Epoch: 6| Step: 1
Training loss: 2.717966079711914
Validation loss: 2.0400833570829002

Epoch: 6| Step: 2
Training loss: 1.8212261199951172
Validation loss: 2.064058801179291

Epoch: 6| Step: 3
Training loss: 2.6282777786254883
Validation loss: 2.057526188512002

Epoch: 6| Step: 4
Training loss: 2.262150764465332
Validation loss: 2.046585177862516

Epoch: 6| Step: 5
Training loss: 2.174084424972534
Validation loss: 2.038886261242692

Epoch: 6| Step: 6
Training loss: 2.6203036308288574
Validation loss: 2.059546652660575

Epoch: 6| Step: 7
Training loss: 2.293283462524414
Validation loss: 2.0602154654841267

Epoch: 6| Step: 8
Training loss: 1.4520103931427002
Validation loss: 2.063114963552003

Epoch: 6| Step: 9
Training loss: 3.0754799842834473
Validation loss: 2.0637519731316516

Epoch: 6| Step: 10
Training loss: 2.453673839569092
Validation loss: 2.068152194382042

Epoch: 6| Step: 11
Training loss: 2.867272138595581
Validation loss: 2.067643509116224

Epoch: 6| Step: 12
Training loss: 1.958400845527649
Validation loss: 2.060775133871263

Epoch: 6| Step: 13
Training loss: 1.7394627332687378
Validation loss: 2.0680119452937955

Epoch: 44| Step: 0
Training loss: 1.6933379173278809
Validation loss: 2.046526009036649

Epoch: 6| Step: 1
Training loss: 2.6024396419525146
Validation loss: 2.064136661509032

Epoch: 6| Step: 2
Training loss: 2.2359790802001953
Validation loss: 2.070952110393073

Epoch: 6| Step: 3
Training loss: 2.788210868835449
Validation loss: 2.061870600587578

Epoch: 6| Step: 4
Training loss: 2.259754180908203
Validation loss: 2.0547469610809

Epoch: 6| Step: 5
Training loss: 2.6026206016540527
Validation loss: 2.05780561765035

Epoch: 6| Step: 6
Training loss: 3.2410812377929688
Validation loss: 2.055958581227128

Epoch: 6| Step: 7
Training loss: 2.1194794178009033
Validation loss: 2.0539561010176137

Epoch: 6| Step: 8
Training loss: 3.2894704341888428
Validation loss: 2.0703631934299263

Epoch: 6| Step: 9
Training loss: 2.032033920288086
Validation loss: 2.0419957432695615

Epoch: 6| Step: 10
Training loss: 2.4319653511047363
Validation loss: 2.052511925338417

Epoch: 6| Step: 11
Training loss: 1.65871262550354
Validation loss: 2.0570852961591495

Epoch: 6| Step: 12
Training loss: 1.8931598663330078
Validation loss: 2.047688458555488

Epoch: 6| Step: 13
Training loss: 1.7867769002914429
Validation loss: 2.0528201198065155

Epoch: 45| Step: 0
Training loss: 2.615354537963867
Validation loss: 2.0558452208836875

Epoch: 6| Step: 1
Training loss: 1.449191689491272
Validation loss: 2.039159542770796

Epoch: 6| Step: 2
Training loss: 2.8505747318267822
Validation loss: 2.060970421760313

Epoch: 6| Step: 3
Training loss: 2.593052387237549
Validation loss: 2.038572931802401

Epoch: 6| Step: 4
Training loss: 2.0979456901550293
Validation loss: 2.03292013624663

Epoch: 6| Step: 5
Training loss: 2.158543586730957
Validation loss: 2.0435569670892533

Epoch: 6| Step: 6
Training loss: 2.4441604614257812
Validation loss: 2.0576615795012443

Epoch: 6| Step: 7
Training loss: 2.4817135334014893
Validation loss: 2.044494337933038

Epoch: 6| Step: 8
Training loss: 2.483201742172241
Validation loss: 2.0544294644427556

Epoch: 6| Step: 9
Training loss: 2.637356758117676
Validation loss: 2.047345094783332

Epoch: 6| Step: 10
Training loss: 2.089406967163086
Validation loss: 2.0491259572326497

Epoch: 6| Step: 11
Training loss: 1.688846230506897
Validation loss: 2.015843145308956

Epoch: 6| Step: 12
Training loss: 2.286454916000366
Validation loss: 2.016820475619326

Epoch: 6| Step: 13
Training loss: 3.3307058811187744
Validation loss: 2.0397387576359574

Epoch: 46| Step: 0
Training loss: 2.7309484481811523
Validation loss: 2.0492122327127764

Epoch: 6| Step: 1
Training loss: 2.5455822944641113
Validation loss: 2.0486241002236643

Epoch: 6| Step: 2
Training loss: 1.8955239057540894
Validation loss: 2.0279016417841755

Epoch: 6| Step: 3
Training loss: 2.2466604709625244
Validation loss: 2.0364640810156382

Epoch: 6| Step: 4
Training loss: 2.6260292530059814
Validation loss: 2.0532800946184384

Epoch: 6| Step: 5
Training loss: 2.8937954902648926
Validation loss: 2.056450588728792

Epoch: 6| Step: 6
Training loss: 2.2684988975524902
Validation loss: 2.051103804701118

Epoch: 6| Step: 7
Training loss: 1.6342532634735107
Validation loss: 2.034915485689717

Epoch: 6| Step: 8
Training loss: 2.3250977993011475
Validation loss: 2.06799155153254

Epoch: 6| Step: 9
Training loss: 1.8962717056274414
Validation loss: 2.0527848748750586

Epoch: 6| Step: 10
Training loss: 2.491720199584961
Validation loss: 2.038343680802212

Epoch: 6| Step: 11
Training loss: 2.3645033836364746
Validation loss: 2.052856876004127

Epoch: 6| Step: 12
Training loss: 3.0802319049835205
Validation loss: 2.030459855192451

Epoch: 6| Step: 13
Training loss: 1.8559279441833496
Validation loss: 2.0405446098696802

Epoch: 47| Step: 0
Training loss: 1.9727617502212524
Validation loss: 2.0608921192025624

Epoch: 6| Step: 1
Training loss: 2.086397171020508
Validation loss: 2.0502025081265356

Epoch: 6| Step: 2
Training loss: 1.9040606021881104
Validation loss: 2.06005447910678

Epoch: 6| Step: 3
Training loss: 2.3675856590270996
Validation loss: 2.056573362760646

Epoch: 6| Step: 4
Training loss: 2.009709358215332
Validation loss: 2.0526395023510022

Epoch: 6| Step: 5
Training loss: 2.3003780841827393
Validation loss: 2.0363284977533485

Epoch: 6| Step: 6
Training loss: 2.7224512100219727
Validation loss: 2.0682510381103842

Epoch: 6| Step: 7
Training loss: 3.069467306137085
Validation loss: 2.047724077778478

Epoch: 6| Step: 8
Training loss: 3.026088237762451
Validation loss: 2.063661990627166

Epoch: 6| Step: 9
Training loss: 1.6606422662734985
Validation loss: 2.0578307413285777

Epoch: 6| Step: 10
Training loss: 3.023374080657959
Validation loss: 2.0292643718822028

Epoch: 6| Step: 11
Training loss: 2.1089844703674316
Validation loss: 2.066294235567893

Epoch: 6| Step: 12
Training loss: 1.9997501373291016
Validation loss: 2.0512718846721034

Epoch: 6| Step: 13
Training loss: 2.861956834793091
Validation loss: 2.0463898181915283

Epoch: 48| Step: 0
Training loss: 2.5908610820770264
Validation loss: 2.0400932578630346

Epoch: 6| Step: 1
Training loss: 2.22465181350708
Validation loss: 2.0457213206957747

Epoch: 6| Step: 2
Training loss: 1.658193588256836
Validation loss: 2.0463123552260862

Epoch: 6| Step: 3
Training loss: 2.2356295585632324
Validation loss: 2.029092529768585

Epoch: 6| Step: 4
Training loss: 3.0466809272766113
Validation loss: 2.0533591572956373

Epoch: 6| Step: 5
Training loss: 2.3786168098449707
Validation loss: 2.0532766413945023

Epoch: 6| Step: 6
Training loss: 2.822361707687378
Validation loss: 2.0399871180134435

Epoch: 6| Step: 7
Training loss: 2.299191951751709
Validation loss: 2.0571803738993983

Epoch: 6| Step: 8
Training loss: 2.1240761280059814
Validation loss: 2.0406876046170472

Epoch: 6| Step: 9
Training loss: 1.7669271230697632
Validation loss: 2.0399788720633394

Epoch: 6| Step: 10
Training loss: 2.6543545722961426
Validation loss: 2.0482028940672516

Epoch: 6| Step: 11
Training loss: 1.397321343421936
Validation loss: 2.060069650732061

Epoch: 6| Step: 12
Training loss: 2.5709033012390137
Validation loss: 2.069592514345723

Epoch: 6| Step: 13
Training loss: 3.3709027767181396
Validation loss: 2.0239922436334754

Epoch: 49| Step: 0
Training loss: 2.3991923332214355
Validation loss: 2.054367488430392

Epoch: 6| Step: 1
Training loss: 2.272351026535034
Validation loss: 2.0441058733130015

Epoch: 6| Step: 2
Training loss: 2.2005205154418945
Validation loss: 2.0682950430018927

Epoch: 6| Step: 3
Training loss: 2.1225786209106445
Validation loss: 2.0353719316503054

Epoch: 6| Step: 4
Training loss: 2.8275985717773438
Validation loss: 2.0361083553683375

Epoch: 6| Step: 5
Training loss: 2.548274517059326
Validation loss: 2.063930498656406

Epoch: 6| Step: 6
Training loss: 2.305572509765625
Validation loss: 2.0543040460155857

Epoch: 6| Step: 7
Training loss: 2.40818190574646
Validation loss: 2.056899928277539

Epoch: 6| Step: 8
Training loss: 1.8368260860443115
Validation loss: 2.0609348281737296

Epoch: 6| Step: 9
Training loss: 2.1802992820739746
Validation loss: 2.0588406388477614

Epoch: 6| Step: 10
Training loss: 2.3215675354003906
Validation loss: 2.0629928291484876

Epoch: 6| Step: 11
Training loss: 2.4008450508117676
Validation loss: 2.0514418232825493

Epoch: 6| Step: 12
Training loss: 2.1338624954223633
Validation loss: 2.0435225681592057

Epoch: 6| Step: 13
Training loss: 2.918870687484741
Validation loss: 2.0470593411435365

Epoch: 50| Step: 0
Training loss: 2.0506348609924316
Validation loss: 2.034861365954081

Epoch: 6| Step: 1
Training loss: 2.2482686042785645
Validation loss: 2.049637448403143

Epoch: 6| Step: 2
Training loss: 1.9938898086547852
Validation loss: 2.0480351858241583

Epoch: 6| Step: 3
Training loss: 2.852537155151367
Validation loss: 2.06391421697473

Epoch: 6| Step: 4
Training loss: 2.9692542552948
Validation loss: 2.056236159416937

Epoch: 6| Step: 5
Training loss: 2.8322291374206543
Validation loss: 2.058829797211514

Epoch: 6| Step: 6
Training loss: 1.7495746612548828
Validation loss: 2.0506686292668825

Epoch: 6| Step: 7
Training loss: 2.3611063957214355
Validation loss: 2.025755984808809

Epoch: 6| Step: 8
Training loss: 2.3357043266296387
Validation loss: 2.030636529768667

Epoch: 6| Step: 9
Training loss: 2.2262392044067383
Validation loss: 2.0541814604113178

Epoch: 6| Step: 10
Training loss: 1.7234759330749512
Validation loss: 2.035514106032669

Epoch: 6| Step: 11
Training loss: 1.8806257247924805
Validation loss: 2.049168663640176

Epoch: 6| Step: 12
Training loss: 3.2530643939971924
Validation loss: 2.0404054810923915

Epoch: 6| Step: 13
Training loss: 2.4594671726226807
Validation loss: 2.0459788063521027

Epoch: 51| Step: 0
Training loss: 1.8285558223724365
Validation loss: 2.0586525676071004

Epoch: 6| Step: 1
Training loss: 3.210174798965454
Validation loss: 2.02628497410846

Epoch: 6| Step: 2
Training loss: 2.466834545135498
Validation loss: 2.0399291848623626

Epoch: 6| Step: 3
Training loss: 1.6658190488815308
Validation loss: 2.04906617441485

Epoch: 6| Step: 4
Training loss: 2.2713255882263184
Validation loss: 2.0438640399645736

Epoch: 6| Step: 5
Training loss: 2.364877700805664
Validation loss: 2.031722519987373

Epoch: 6| Step: 6
Training loss: 2.475020170211792
Validation loss: 2.034180405319378

Epoch: 6| Step: 7
Training loss: 2.3317596912384033
Validation loss: 2.0447135612528813

Epoch: 6| Step: 8
Training loss: 2.7210888862609863
Validation loss: 2.0379362362687305

Epoch: 6| Step: 9
Training loss: 2.036618947982788
Validation loss: 2.0170425420166342

Epoch: 6| Step: 10
Training loss: 2.4770190715789795
Validation loss: 2.036498959346484

Epoch: 6| Step: 11
Training loss: 2.4253945350646973
Validation loss: 2.029145868875647

Epoch: 6| Step: 12
Training loss: 2.0219240188598633
Validation loss: 2.0439615403452227

Epoch: 6| Step: 13
Training loss: 2.3983287811279297
Validation loss: 2.0357923328235583

Epoch: 52| Step: 0
Training loss: 1.9471454620361328
Validation loss: 2.026795518013739

Epoch: 6| Step: 1
Training loss: 2.346996784210205
Validation loss: 2.0269005285796298

Epoch: 6| Step: 2
Training loss: 2.4035191535949707
Validation loss: 2.020608345667521

Epoch: 6| Step: 3
Training loss: 1.8056039810180664
Validation loss: 2.034537881933233

Epoch: 6| Step: 4
Training loss: 2.1598973274230957
Validation loss: 2.0274906312265704

Epoch: 6| Step: 5
Training loss: 2.2704615592956543
Validation loss: 2.0211344931715276

Epoch: 6| Step: 6
Training loss: 1.9214887619018555
Validation loss: 2.015130409630396

Epoch: 6| Step: 7
Training loss: 2.7171568870544434
Validation loss: 2.01098386702999

Epoch: 6| Step: 8
Training loss: 1.8292372226715088
Validation loss: 2.0176531191795104

Epoch: 6| Step: 9
Training loss: 2.674799919128418
Validation loss: 2.0241641754745157

Epoch: 6| Step: 10
Training loss: 2.7257018089294434
Validation loss: 2.0312459084295456

Epoch: 6| Step: 11
Training loss: 2.510714530944824
Validation loss: 2.030664690079228

Epoch: 6| Step: 12
Training loss: 2.261871814727783
Validation loss: 2.0175643428679435

Epoch: 6| Step: 13
Training loss: 3.1876208782196045
Validation loss: 2.02395498752594

Epoch: 53| Step: 0
Training loss: 1.9169405698776245
Validation loss: 2.026578341760943

Epoch: 6| Step: 1
Training loss: 1.9845720529556274
Validation loss: 2.0142267365609445

Epoch: 6| Step: 2
Training loss: 3.3436388969421387
Validation loss: 2.0389583495355423

Epoch: 6| Step: 3
Training loss: 2.190063714981079
Validation loss: 2.035058579137248

Epoch: 6| Step: 4
Training loss: 2.2373931407928467
Validation loss: 2.0332020649345974

Epoch: 6| Step: 5
Training loss: 2.9224390983581543
Validation loss: 2.033773826014611

Epoch: 6| Step: 6
Training loss: 3.0035643577575684
Validation loss: 2.0485289981288295

Epoch: 6| Step: 7
Training loss: 2.0751168727874756
Validation loss: 2.0274947330515873

Epoch: 6| Step: 8
Training loss: 2.498189926147461
Validation loss: 2.046742404660871

Epoch: 6| Step: 9
Training loss: 1.8885985612869263
Validation loss: 2.0308369359662457

Epoch: 6| Step: 10
Training loss: 2.5628108978271484
Validation loss: 2.024839739645681

Epoch: 6| Step: 11
Training loss: 1.9075803756713867
Validation loss: 2.021122021059836

Epoch: 6| Step: 12
Training loss: 1.9131348133087158
Validation loss: 2.03732943278487

Epoch: 6| Step: 13
Training loss: 1.831103801727295
Validation loss: 2.063133598655783

Epoch: 54| Step: 0
Training loss: 1.7961543798446655
Validation loss: 2.0425750004347933

Epoch: 6| Step: 1
Training loss: 2.184633493423462
Validation loss: 2.0484587095117055

Epoch: 6| Step: 2
Training loss: 3.130087375640869
Validation loss: 2.0273167151276783

Epoch: 6| Step: 3
Training loss: 2.5260825157165527
Validation loss: 2.024799539196876

Epoch: 6| Step: 4
Training loss: 1.4730679988861084
Validation loss: 2.0043045731001

Epoch: 6| Step: 5
Training loss: 1.9257006645202637
Validation loss: 2.0157245436022357

Epoch: 6| Step: 6
Training loss: 2.5584006309509277
Validation loss: 2.022117219945436

Epoch: 6| Step: 7
Training loss: 1.6747641563415527
Validation loss: 2.0137212097003894

Epoch: 6| Step: 8
Training loss: 2.011357069015503
Validation loss: 2.0402135413180114

Epoch: 6| Step: 9
Training loss: 2.4686591625213623
Validation loss: 2.0405084599730787

Epoch: 6| Step: 10
Training loss: 3.0620627403259277
Validation loss: 2.0232880961510444

Epoch: 6| Step: 11
Training loss: 3.2236990928649902
Validation loss: 2.0421887520820863

Epoch: 6| Step: 12
Training loss: 2.0852041244506836
Validation loss: 2.0243775460027877

Epoch: 6| Step: 13
Training loss: 2.1397411823272705
Validation loss: 2.0463099454038884

Epoch: 55| Step: 0
Training loss: 2.627310037612915
Validation loss: 2.0257847027112077

Epoch: 6| Step: 1
Training loss: 2.6578760147094727
Validation loss: 2.0401582948623167

Epoch: 6| Step: 2
Training loss: 2.831932783126831
Validation loss: 2.0221328991715626

Epoch: 6| Step: 3
Training loss: 1.7087373733520508
Validation loss: 2.0227613551642305

Epoch: 6| Step: 4
Training loss: 2.1014328002929688
Validation loss: 2.009538117275443

Epoch: 6| Step: 5
Training loss: 1.622896432876587
Validation loss: 2.02863331507611

Epoch: 6| Step: 6
Training loss: 2.8300962448120117
Validation loss: 2.0160031933938303

Epoch: 6| Step: 7
Training loss: 2.5966899394989014
Validation loss: 2.0133988152268114

Epoch: 6| Step: 8
Training loss: 2.9440529346466064
Validation loss: 2.029630161100818

Epoch: 6| Step: 9
Training loss: 2.098936080932617
Validation loss: 2.0053261108295892

Epoch: 6| Step: 10
Training loss: 1.516923189163208
Validation loss: 2.0123892073990195

Epoch: 6| Step: 11
Training loss: 1.966936469078064
Validation loss: 2.0077605644861856

Epoch: 6| Step: 12
Training loss: 2.9026002883911133
Validation loss: 2.0123021448812177

Epoch: 6| Step: 13
Training loss: 1.5657217502593994
Validation loss: 2.0260525467575237

Epoch: 56| Step: 0
Training loss: 2.6666717529296875
Validation loss: 2.003757833152689

Epoch: 6| Step: 1
Training loss: 2.760098695755005
Validation loss: 2.0003044041254188

Epoch: 6| Step: 2
Training loss: 2.1159069538116455
Validation loss: 2.0194837880390946

Epoch: 6| Step: 3
Training loss: 1.9484772682189941
Validation loss: 2.00252011001751

Epoch: 6| Step: 4
Training loss: 2.3608407974243164
Validation loss: 1.9955851800980107

Epoch: 6| Step: 5
Training loss: 2.314582347869873
Validation loss: 2.029862612806341

Epoch: 6| Step: 6
Training loss: 2.7584948539733887
Validation loss: 2.0259992896869616

Epoch: 6| Step: 7
Training loss: 2.534421920776367
Validation loss: 2.022987929723596

Epoch: 6| Step: 8
Training loss: 1.7781522274017334
Validation loss: 2.0080272356669107

Epoch: 6| Step: 9
Training loss: 2.0623698234558105
Validation loss: 2.000954867691122

Epoch: 6| Step: 10
Training loss: 2.408151149749756
Validation loss: 2.0312451701010428

Epoch: 6| Step: 11
Training loss: 2.5802626609802246
Validation loss: 2.0299349061904417

Epoch: 6| Step: 12
Training loss: 2.260927438735962
Validation loss: 2.0062766510953187

Epoch: 6| Step: 13
Training loss: 1.001267433166504
Validation loss: 2.0191921187985327

Epoch: 57| Step: 0
Training loss: 2.9599223136901855
Validation loss: 2.0217956202004546

Epoch: 6| Step: 1
Training loss: 2.6366019248962402
Validation loss: 2.0310553107210385

Epoch: 6| Step: 2
Training loss: 2.0369882583618164
Validation loss: 2.0181376626414638

Epoch: 6| Step: 3
Training loss: 2.0084662437438965
Validation loss: 2.00097071355389

Epoch: 6| Step: 4
Training loss: 1.96287202835083
Validation loss: 2.014498277377057

Epoch: 6| Step: 5
Training loss: 2.379063129425049
Validation loss: 2.0182829031380276

Epoch: 6| Step: 6
Training loss: 2.4378132820129395
Validation loss: 2.0295693617995068

Epoch: 6| Step: 7
Training loss: 2.3571901321411133
Validation loss: 2.0231119509666198

Epoch: 6| Step: 8
Training loss: 2.4535555839538574
Validation loss: 2.01157352488528

Epoch: 6| Step: 9
Training loss: 1.9394335746765137
Validation loss: 1.9950862071847404

Epoch: 6| Step: 10
Training loss: 2.0956506729125977
Validation loss: 2.0243757719634683

Epoch: 6| Step: 11
Training loss: 2.199523448944092
Validation loss: 2.0160560672001173

Epoch: 6| Step: 12
Training loss: 2.3193955421447754
Validation loss: 1.999108604205552

Epoch: 6| Step: 13
Training loss: 2.569153308868408
Validation loss: 1.9690173441363918

Epoch: 58| Step: 0
Training loss: 2.681124687194824
Validation loss: 2.0016651153564453

Epoch: 6| Step: 1
Training loss: 2.2309374809265137
Validation loss: 2.027259039622481

Epoch: 6| Step: 2
Training loss: 2.301300287246704
Validation loss: 2.0067867437998452

Epoch: 6| Step: 3
Training loss: 2.737664222717285
Validation loss: 2.0089353745983494

Epoch: 6| Step: 4
Training loss: 2.068162441253662
Validation loss: 2.0142750124777518

Epoch: 6| Step: 5
Training loss: 2.4364044666290283
Validation loss: 2.0195974265375445

Epoch: 6| Step: 6
Training loss: 1.6232832670211792
Validation loss: 2.030847849384431

Epoch: 6| Step: 7
Training loss: 1.9106019735336304
Validation loss: 2.0228569533235286

Epoch: 6| Step: 8
Training loss: 2.1450071334838867
Validation loss: 2.004409586229632

Epoch: 6| Step: 9
Training loss: 2.7566380500793457
Validation loss: 2.028701110552716

Epoch: 6| Step: 10
Training loss: 2.304656982421875
Validation loss: 2.032924013753091

Epoch: 6| Step: 11
Training loss: 2.3729894161224365
Validation loss: 2.0136391091090378

Epoch: 6| Step: 12
Training loss: 2.1966605186462402
Validation loss: 2.0385096432060323

Epoch: 6| Step: 13
Training loss: 2.21529483795166
Validation loss: 2.0173518080865183

Epoch: 59| Step: 0
Training loss: 2.040424346923828
Validation loss: 2.0366742790386243

Epoch: 6| Step: 1
Training loss: 2.0702052116394043
Validation loss: 2.01655674493441

Epoch: 6| Step: 2
Training loss: 2.2500500679016113
Validation loss: 2.018819579514124

Epoch: 6| Step: 3
Training loss: 2.2122349739074707
Validation loss: 2.0038308815289567

Epoch: 6| Step: 4
Training loss: 1.895838975906372
Validation loss: 2.0170380351363972

Epoch: 6| Step: 5
Training loss: 1.6652841567993164
Validation loss: 2.035711614034509

Epoch: 6| Step: 6
Training loss: 2.6131110191345215
Validation loss: 2.0127855359867053

Epoch: 6| Step: 7
Training loss: 2.4418740272521973
Validation loss: 2.00915793449648

Epoch: 6| Step: 8
Training loss: 2.84517240524292
Validation loss: 2.007619683460523

Epoch: 6| Step: 9
Training loss: 2.4027862548828125
Validation loss: 2.0123328701142342

Epoch: 6| Step: 10
Training loss: 2.1647887229919434
Validation loss: 2.0145921527698474

Epoch: 6| Step: 11
Training loss: 2.358886241912842
Validation loss: 1.9875636459678732

Epoch: 6| Step: 12
Training loss: 2.5286076068878174
Validation loss: 2.0046766342655307

Epoch: 6| Step: 13
Training loss: 3.03657603263855
Validation loss: 1.9893472784308976

Epoch: 60| Step: 0
Training loss: 3.0543642044067383
Validation loss: 2.023022970845622

Epoch: 6| Step: 1
Training loss: 2.8724095821380615
Validation loss: 2.0386013689861504

Epoch: 6| Step: 2
Training loss: 2.082202672958374
Validation loss: 2.014670269463652

Epoch: 6| Step: 3
Training loss: 1.8867483139038086
Validation loss: 2.0112914526334373

Epoch: 6| Step: 4
Training loss: 2.2058019638061523
Validation loss: 2.0123834251075663

Epoch: 6| Step: 5
Training loss: 2.772822618484497
Validation loss: 2.033648552433137

Epoch: 6| Step: 6
Training loss: 2.4778780937194824
Validation loss: 2.0160796360302995

Epoch: 6| Step: 7
Training loss: 1.677119255065918
Validation loss: 2.014349599038401

Epoch: 6| Step: 8
Training loss: 1.648641586303711
Validation loss: 2.011269630924348

Epoch: 6| Step: 9
Training loss: 1.7741878032684326
Validation loss: 2.003336610332612

Epoch: 6| Step: 10
Training loss: 2.180248498916626
Validation loss: 2.016949289588518

Epoch: 6| Step: 11
Training loss: 2.1202220916748047
Validation loss: 2.0224879018722044

Epoch: 6| Step: 12
Training loss: 2.9940433502197266
Validation loss: 2.0248992391811904

Epoch: 6| Step: 13
Training loss: 2.7349510192871094
Validation loss: 2.034079167150682

Epoch: 61| Step: 0
Training loss: 2.761234998703003
Validation loss: 1.9975636518129738

Epoch: 6| Step: 1
Training loss: 2.902810573577881
Validation loss: 2.0073981259458806

Epoch: 6| Step: 2
Training loss: 1.6661620140075684
Validation loss: 1.9888424334987518

Epoch: 6| Step: 3
Training loss: 2.4786601066589355
Validation loss: 1.9962479119659753

Epoch: 6| Step: 4
Training loss: 1.977116346359253
Validation loss: 2.0009667796473347

Epoch: 6| Step: 5
Training loss: 2.444223642349243
Validation loss: 2.010882373779051

Epoch: 6| Step: 6
Training loss: 2.550220012664795
Validation loss: 2.0078718059806415

Epoch: 6| Step: 7
Training loss: 2.0870630741119385
Validation loss: 2.0029281775156655

Epoch: 6| Step: 8
Training loss: 2.208808422088623
Validation loss: 1.988956392452281

Epoch: 6| Step: 9
Training loss: 1.946129322052002
Validation loss: 2.010164365973524

Epoch: 6| Step: 10
Training loss: 2.2773988246917725
Validation loss: 2.01913869765497

Epoch: 6| Step: 11
Training loss: 2.1318535804748535
Validation loss: 2.000081866018234

Epoch: 6| Step: 12
Training loss: 2.3114023208618164
Validation loss: 2.0106568259577595

Epoch: 6| Step: 13
Training loss: 2.444260597229004
Validation loss: 1.9968787406080513

Epoch: 62| Step: 0
Training loss: 2.344050407409668
Validation loss: 2.0053150525657077

Epoch: 6| Step: 1
Training loss: 2.5956411361694336
Validation loss: 2.0122354722792104

Epoch: 6| Step: 2
Training loss: 2.23679780960083
Validation loss: 1.9959242728448683

Epoch: 6| Step: 3
Training loss: 1.9462368488311768
Validation loss: 2.0080035989002516

Epoch: 6| Step: 4
Training loss: 2.03599214553833
Validation loss: 1.9981582344219249

Epoch: 6| Step: 5
Training loss: 2.283752918243408
Validation loss: 2.0107667856318976

Epoch: 6| Step: 6
Training loss: 2.1877565383911133
Validation loss: 2.0261815760725286

Epoch: 6| Step: 7
Training loss: 2.5559403896331787
Validation loss: 2.012890205588392

Epoch: 6| Step: 8
Training loss: 1.9669665098190308
Validation loss: 2.016608576620779

Epoch: 6| Step: 9
Training loss: 2.007767677307129
Validation loss: 2.023609584377658

Epoch: 6| Step: 10
Training loss: 2.972269058227539
Validation loss: 2.0127930384810253

Epoch: 6| Step: 11
Training loss: 1.6438482999801636
Validation loss: 2.013103618416735

Epoch: 6| Step: 12
Training loss: 2.6067001819610596
Validation loss: 2.0165527200186126

Epoch: 6| Step: 13
Training loss: 2.5777015686035156
Validation loss: 2.0214027281730407

Epoch: 63| Step: 0
Training loss: 2.2058804035186768
Validation loss: 2.0285691061327533

Epoch: 6| Step: 1
Training loss: 1.5129485130310059
Validation loss: 2.0173067815842165

Epoch: 6| Step: 2
Training loss: 2.8738882541656494
Validation loss: 2.032490640558222

Epoch: 6| Step: 3
Training loss: 1.8717204332351685
Validation loss: 2.0261096685163436

Epoch: 6| Step: 4
Training loss: 2.6112711429595947
Validation loss: 2.012317471606757

Epoch: 6| Step: 5
Training loss: 2.021111488342285
Validation loss: 2.002626235767077

Epoch: 6| Step: 6
Training loss: 2.487947463989258
Validation loss: 2.036328278562074

Epoch: 6| Step: 7
Training loss: 2.1969058513641357
Validation loss: 1.9986081110533847

Epoch: 6| Step: 8
Training loss: 2.187343120574951
Validation loss: 2.0240569704322406

Epoch: 6| Step: 9
Training loss: 2.172226905822754
Validation loss: 1.9976244588052072

Epoch: 6| Step: 10
Training loss: 2.2273082733154297
Validation loss: 2.008285081514748

Epoch: 6| Step: 11
Training loss: 2.317902088165283
Validation loss: 2.004163980484009

Epoch: 6| Step: 12
Training loss: 3.095555305480957
Validation loss: 2.0339545408884683

Epoch: 6| Step: 13
Training loss: 2.039712905883789
Validation loss: 2.028646969026135

Epoch: 64| Step: 0
Training loss: 2.4427690505981445
Validation loss: 2.0002940995718843

Epoch: 6| Step: 1
Training loss: 2.0378105640411377
Validation loss: 2.004402688754502

Epoch: 6| Step: 2
Training loss: 2.019044876098633
Validation loss: 2.0163006577440488

Epoch: 6| Step: 3
Training loss: 2.1943295001983643
Validation loss: 2.005264371953985

Epoch: 6| Step: 4
Training loss: 1.9474856853485107
Validation loss: 2.009372821418188

Epoch: 6| Step: 5
Training loss: 3.4322471618652344
Validation loss: 2.013462540923908

Epoch: 6| Step: 6
Training loss: 2.3797054290771484
Validation loss: 2.01412401148068

Epoch: 6| Step: 7
Training loss: 2.471430540084839
Validation loss: 2.012372782153468

Epoch: 6| Step: 8
Training loss: 1.947969675064087
Validation loss: 2.003195280669838

Epoch: 6| Step: 9
Training loss: 2.3277840614318848
Validation loss: 2.0301223749755533

Epoch: 6| Step: 10
Training loss: 2.2253007888793945
Validation loss: 2.0321205610870035

Epoch: 6| Step: 11
Training loss: 2.0899767875671387
Validation loss: 2.0304806770816928

Epoch: 6| Step: 12
Training loss: 2.10092830657959
Validation loss: 2.028608863071729

Epoch: 6| Step: 13
Training loss: 2.264439582824707
Validation loss: 2.0224597812980734

Epoch: 65| Step: 0
Training loss: 2.3358540534973145
Validation loss: 2.0229962692465833

Epoch: 6| Step: 1
Training loss: 2.3136632442474365
Validation loss: 1.9967890170312697

Epoch: 6| Step: 2
Training loss: 3.0384135246276855
Validation loss: 1.9807926019032795

Epoch: 6| Step: 3
Training loss: 1.9577021598815918
Validation loss: 1.9934626176793089

Epoch: 6| Step: 4
Training loss: 1.1534498929977417
Validation loss: 1.996346794148927

Epoch: 6| Step: 5
Training loss: 1.6985734701156616
Validation loss: 2.014804510660069

Epoch: 6| Step: 6
Training loss: 2.0898075103759766
Validation loss: 2.014618912050801

Epoch: 6| Step: 7
Training loss: 2.3510799407958984
Validation loss: 2.009901499235502

Epoch: 6| Step: 8
Training loss: 2.3871283531188965
Validation loss: 1.9958629146698983

Epoch: 6| Step: 9
Training loss: 2.5121707916259766
Validation loss: 1.9924065656559442

Epoch: 6| Step: 10
Training loss: 1.7995084524154663
Validation loss: 1.989421829100578

Epoch: 6| Step: 11
Training loss: 2.9831480979919434
Validation loss: 1.993701042667512

Epoch: 6| Step: 12
Training loss: 2.851346969604492
Validation loss: 1.9906325468453028

Epoch: 6| Step: 13
Training loss: 2.7105307579040527
Validation loss: 2.000330203322954

Epoch: 66| Step: 0
Training loss: 2.2430641651153564
Validation loss: 1.9873704602641444

Epoch: 6| Step: 1
Training loss: 2.162869453430176
Validation loss: 1.9856594198493547

Epoch: 6| Step: 2
Training loss: 2.5407538414001465
Validation loss: 1.9968387875505673

Epoch: 6| Step: 3
Training loss: 2.6012473106384277
Validation loss: 1.9863795452220465

Epoch: 6| Step: 4
Training loss: 2.6779823303222656
Validation loss: 2.003508661382942

Epoch: 6| Step: 5
Training loss: 2.4839038848876953
Validation loss: 2.0098559805141982

Epoch: 6| Step: 6
Training loss: 2.0267887115478516
Validation loss: 1.9895900154626498

Epoch: 6| Step: 7
Training loss: 1.9537285566329956
Validation loss: 1.9958852439798334

Epoch: 6| Step: 8
Training loss: 2.4914908409118652
Validation loss: 2.0009044113979546

Epoch: 6| Step: 9
Training loss: 2.427985668182373
Validation loss: 2.007696751625307

Epoch: 6| Step: 10
Training loss: 2.753139019012451
Validation loss: 2.0078400719550347

Epoch: 6| Step: 11
Training loss: 2.225139856338501
Validation loss: 1.9977194263089089

Epoch: 6| Step: 12
Training loss: 1.6437962055206299
Validation loss: 2.0239898735477078

Epoch: 6| Step: 13
Training loss: 1.2079614400863647
Validation loss: 1.9972894063559912

Epoch: 67| Step: 0
Training loss: 1.6187264919281006
Validation loss: 2.012328367079458

Epoch: 6| Step: 1
Training loss: 2.5739073753356934
Validation loss: 2.0339930262616885

Epoch: 6| Step: 2
Training loss: 2.964712619781494
Validation loss: 2.02378281470268

Epoch: 6| Step: 3
Training loss: 2.448061466217041
Validation loss: 2.00702686976361

Epoch: 6| Step: 4
Training loss: 2.0855116844177246
Validation loss: 2.0220306637466594

Epoch: 6| Step: 5
Training loss: 2.8605003356933594
Validation loss: 2.0131095583720873

Epoch: 6| Step: 6
Training loss: 1.4817702770233154
Validation loss: 2.0175028718927854

Epoch: 6| Step: 7
Training loss: 2.247403860092163
Validation loss: 2.025939605569327

Epoch: 6| Step: 8
Training loss: 1.5943522453308105
Validation loss: 1.9838003471333494

Epoch: 6| Step: 9
Training loss: 2.3923628330230713
Validation loss: 1.9840352612157022

Epoch: 6| Step: 10
Training loss: 2.1616568565368652
Validation loss: 2.0041405244540145

Epoch: 6| Step: 11
Training loss: 3.2658820152282715
Validation loss: 1.9980885738967566

Epoch: 6| Step: 12
Training loss: 1.4631907939910889
Validation loss: 1.9659377951775827

Epoch: 6| Step: 13
Training loss: 3.203747272491455
Validation loss: 2.007477965406192

Epoch: 68| Step: 0
Training loss: 1.715423345565796
Validation loss: 1.98284395792151

Epoch: 6| Step: 1
Training loss: 2.277528762817383
Validation loss: 1.9927593379892328

Epoch: 6| Step: 2
Training loss: 1.9158015251159668
Validation loss: 1.9902108997427008

Epoch: 6| Step: 3
Training loss: 1.9272311925888062
Validation loss: 1.9841233094533284

Epoch: 6| Step: 4
Training loss: 1.838240385055542
Validation loss: 1.985007425790192

Epoch: 6| Step: 5
Training loss: 2.4591727256774902
Validation loss: 2.0006199946967502

Epoch: 6| Step: 6
Training loss: 3.1033289432525635
Validation loss: 2.005151851202852

Epoch: 6| Step: 7
Training loss: 2.2278904914855957
Validation loss: 2.0044405550085087

Epoch: 6| Step: 8
Training loss: 1.8118014335632324
Validation loss: 2.0268317140558714

Epoch: 6| Step: 9
Training loss: 2.796154022216797
Validation loss: 1.9948706408982635

Epoch: 6| Step: 10
Training loss: 2.3667569160461426
Validation loss: 2.0130030570491666

Epoch: 6| Step: 11
Training loss: 2.1829395294189453
Validation loss: 2.0166718203534364

Epoch: 6| Step: 12
Training loss: 2.62802791595459
Validation loss: 2.007470137329512

Epoch: 6| Step: 13
Training loss: 2.763416051864624
Validation loss: 2.016583868252334

Epoch: 69| Step: 0
Training loss: 1.9833192825317383
Validation loss: 2.022933275468888

Epoch: 6| Step: 1
Training loss: 2.535600185394287
Validation loss: 2.0024795903954455

Epoch: 6| Step: 2
Training loss: 1.9398703575134277
Validation loss: 2.013736560780515

Epoch: 6| Step: 3
Training loss: 1.907448410987854
Validation loss: 2.0203885673194804

Epoch: 6| Step: 4
Training loss: 2.6523685455322266
Validation loss: 2.0167794137872677

Epoch: 6| Step: 5
Training loss: 1.7874709367752075
Validation loss: 2.022365258586022

Epoch: 6| Step: 6
Training loss: 2.325087070465088
Validation loss: 2.0239626822933072

Epoch: 6| Step: 7
Training loss: 2.827415943145752
Validation loss: 2.0149872764464347

Epoch: 6| Step: 8
Training loss: 2.382707357406616
Validation loss: 2.030426626564354

Epoch: 6| Step: 9
Training loss: 1.8335970640182495
Validation loss: 2.027540078727148

Epoch: 6| Step: 10
Training loss: 2.4918971061706543
Validation loss: 2.024651368459066

Epoch: 6| Step: 11
Training loss: 2.610567092895508
Validation loss: 2.0274009550771406

Epoch: 6| Step: 12
Training loss: 2.254473924636841
Validation loss: 2.033217986424764

Epoch: 6| Step: 13
Training loss: 2.3337886333465576
Validation loss: 2.0172600899973223

Epoch: 70| Step: 0
Training loss: 1.665867805480957
Validation loss: 2.0212057546902726

Epoch: 6| Step: 1
Training loss: 2.476073980331421
Validation loss: 2.007260955790038

Epoch: 6| Step: 2
Training loss: 2.486973762512207
Validation loss: 2.0241534581748386

Epoch: 6| Step: 3
Training loss: 2.6024444103240967
Validation loss: 2.0452161937631588

Epoch: 6| Step: 4
Training loss: 2.7313461303710938
Validation loss: 2.025690863209386

Epoch: 6| Step: 5
Training loss: 2.1687841415405273
Validation loss: 2.0119392564219813

Epoch: 6| Step: 6
Training loss: 2.148632526397705
Validation loss: 2.0174903792719685

Epoch: 6| Step: 7
Training loss: 2.0147793292999268
Validation loss: 2.006145054294217

Epoch: 6| Step: 8
Training loss: 2.35196852684021
Validation loss: 1.9881278801989812

Epoch: 6| Step: 9
Training loss: 2.281513214111328
Validation loss: 2.0133428906881683

Epoch: 6| Step: 10
Training loss: 1.9445338249206543
Validation loss: 1.9950799762561757

Epoch: 6| Step: 11
Training loss: 2.1694278717041016
Validation loss: 2.0198136632160475

Epoch: 6| Step: 12
Training loss: 2.2609219551086426
Validation loss: 2.013293486769481

Epoch: 6| Step: 13
Training loss: 2.319916248321533
Validation loss: 2.011019152979697

Epoch: 71| Step: 0
Training loss: 2.480001449584961
Validation loss: 1.9940861681456208

Epoch: 6| Step: 1
Training loss: 2.1848466396331787
Validation loss: 2.001348385246851

Epoch: 6| Step: 2
Training loss: 2.3058362007141113
Validation loss: 1.974778699618514

Epoch: 6| Step: 3
Training loss: 2.763265609741211
Validation loss: 1.9963137334392917

Epoch: 6| Step: 4
Training loss: 1.6163884401321411
Validation loss: 1.987915679972659

Epoch: 6| Step: 5
Training loss: 2.245521068572998
Validation loss: 1.9913350715432117

Epoch: 6| Step: 6
Training loss: 1.7098503112792969
Validation loss: 2.0018474837785125

Epoch: 6| Step: 7
Training loss: 1.6640419960021973
Validation loss: 2.0034388944666874

Epoch: 6| Step: 8
Training loss: 2.4856057167053223
Validation loss: 2.0394562213651595

Epoch: 6| Step: 9
Training loss: 2.384711742401123
Validation loss: 2.006260336086314

Epoch: 6| Step: 10
Training loss: 2.0455076694488525
Validation loss: 1.9866720373912523

Epoch: 6| Step: 11
Training loss: 3.2827274799346924
Validation loss: 2.0045954976030576

Epoch: 6| Step: 12
Training loss: 2.188870906829834
Validation loss: 2.0111825440519597

Epoch: 6| Step: 13
Training loss: 2.472001314163208
Validation loss: 2.001371637467415

Epoch: 72| Step: 0
Training loss: 2.4507594108581543
Validation loss: 2.0155344701582387

Epoch: 6| Step: 1
Training loss: 1.6933119297027588
Validation loss: 2.011967119350228

Epoch: 6| Step: 2
Training loss: 2.789086103439331
Validation loss: 2.0093283537895448

Epoch: 6| Step: 3
Training loss: 2.481250286102295
Validation loss: 2.0051119160908524

Epoch: 6| Step: 4
Training loss: 2.1800436973571777
Validation loss: 2.002911993252334

Epoch: 6| Step: 5
Training loss: 2.304800271987915
Validation loss: 2.0143031202336794

Epoch: 6| Step: 6
Training loss: 2.4724724292755127
Validation loss: 2.0195133609156453

Epoch: 6| Step: 7
Training loss: 1.7839199304580688
Validation loss: 2.0255452471394695

Epoch: 6| Step: 8
Training loss: 2.637636184692383
Validation loss: 2.0171266230203773

Epoch: 6| Step: 9
Training loss: 1.8775267601013184
Validation loss: 2.024307458631454

Epoch: 6| Step: 10
Training loss: 2.9816489219665527
Validation loss: 2.019033319206648

Epoch: 6| Step: 11
Training loss: 1.3554351329803467
Validation loss: 2.0167474387794413

Epoch: 6| Step: 12
Training loss: 2.325193405151367
Validation loss: 2.011902624560941

Epoch: 6| Step: 13
Training loss: 2.566239356994629
Validation loss: 2.0230273162164996

Epoch: 73| Step: 0
Training loss: 1.9914195537567139
Validation loss: 2.0068949525074293

Epoch: 6| Step: 1
Training loss: 3.0328335762023926
Validation loss: 2.0139398510738085

Epoch: 6| Step: 2
Training loss: 2.256129741668701
Validation loss: 2.0066549906166653

Epoch: 6| Step: 3
Training loss: 1.9379398822784424
Validation loss: 2.0063103706605974

Epoch: 6| Step: 4
Training loss: 2.498068332672119
Validation loss: 2.0067123918123144

Epoch: 6| Step: 5
Training loss: 1.5364716053009033
Validation loss: 1.9873405848779986

Epoch: 6| Step: 6
Training loss: 3.238435745239258
Validation loss: 2.000710787311677

Epoch: 6| Step: 7
Training loss: 1.863508701324463
Validation loss: 1.995531528226791

Epoch: 6| Step: 8
Training loss: 2.3928003311157227
Validation loss: 2.004294071146237

Epoch: 6| Step: 9
Training loss: 1.8219298124313354
Validation loss: 1.9890644896414973

Epoch: 6| Step: 10
Training loss: 1.8425694704055786
Validation loss: 2.016063286412147

Epoch: 6| Step: 11
Training loss: 2.470123767852783
Validation loss: 1.9974756407481369

Epoch: 6| Step: 12
Training loss: 2.695415735244751
Validation loss: 2.030690590540568

Epoch: 6| Step: 13
Training loss: 1.5632566213607788
Validation loss: 2.0102975432590773

Epoch: 74| Step: 0
Training loss: 2.1197948455810547
Validation loss: 2.0054488053885837

Epoch: 6| Step: 1
Training loss: 2.315225124359131
Validation loss: 2.012722797291253

Epoch: 6| Step: 2
Training loss: 2.0963759422302246
Validation loss: 2.0018966890150502

Epoch: 6| Step: 3
Training loss: 1.9334028959274292
Validation loss: 1.9778944792286042

Epoch: 6| Step: 4
Training loss: 2.7554354667663574
Validation loss: 1.990125129299779

Epoch: 6| Step: 5
Training loss: 2.7777223587036133
Validation loss: 1.9967761680644045

Epoch: 6| Step: 6
Training loss: 2.173250675201416
Validation loss: 2.0110731253059964

Epoch: 6| Step: 7
Training loss: 2.0550758838653564
Validation loss: 1.9819758489567747

Epoch: 6| Step: 8
Training loss: 2.2684273719787598
Validation loss: 2.005379981892083

Epoch: 6| Step: 9
Training loss: 2.994370937347412
Validation loss: 2.008362118915845

Epoch: 6| Step: 10
Training loss: 2.0460357666015625
Validation loss: 2.008439092225926

Epoch: 6| Step: 11
Training loss: 1.9088749885559082
Validation loss: 2.02087063430458

Epoch: 6| Step: 12
Training loss: 2.1767783164978027
Validation loss: 2.0161452921487952

Epoch: 6| Step: 13
Training loss: 1.9517385959625244
Validation loss: 2.009485920270284

Epoch: 75| Step: 0
Training loss: 3.0647032260894775
Validation loss: 2.0117377722135155

Epoch: 6| Step: 1
Training loss: 2.8272337913513184
Validation loss: 2.016435323222991

Epoch: 6| Step: 2
Training loss: 1.8547377586364746
Validation loss: 2.0166212666419243

Epoch: 6| Step: 3
Training loss: 2.661454439163208
Validation loss: 2.0262614321965042

Epoch: 6| Step: 4
Training loss: 2.358694076538086
Validation loss: 1.995455616263933

Epoch: 6| Step: 5
Training loss: 1.9998712539672852
Validation loss: 2.024742966057152

Epoch: 6| Step: 6
Training loss: 2.1912851333618164
Validation loss: 2.0305050188495266

Epoch: 6| Step: 7
Training loss: 2.434685230255127
Validation loss: 2.0422908747068016

Epoch: 6| Step: 8
Training loss: 1.9320701360702515
Validation loss: 2.025736447303526

Epoch: 6| Step: 9
Training loss: 2.5968823432922363
Validation loss: 2.054662791631555

Epoch: 6| Step: 10
Training loss: 2.26094126701355
Validation loss: 2.0700381109791417

Epoch: 6| Step: 11
Training loss: 1.492502212524414
Validation loss: 2.0368907669539094

Epoch: 6| Step: 12
Training loss: 2.1194727420806885
Validation loss: 2.028530433613767

Epoch: 6| Step: 13
Training loss: 1.7168025970458984
Validation loss: 2.0188457863305205

Testing loss: 2.1084364944034153
