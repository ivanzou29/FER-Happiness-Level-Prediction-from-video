Epoch: 1| Step: 0
Training loss: 3.6546502113342285
Validation loss: 3.6894567448605775

Epoch: 6| Step: 1
Training loss: 3.7143115997314453
Validation loss: 3.6863959425239154

Epoch: 6| Step: 2
Training loss: 2.4407572746276855
Validation loss: 3.6848275840923352

Epoch: 6| Step: 3
Training loss: 3.6653497219085693
Validation loss: 3.683060861402942

Epoch: 6| Step: 4
Training loss: 3.838160991668701
Validation loss: 3.679511885489187

Epoch: 6| Step: 5
Training loss: 3.3506147861480713
Validation loss: 3.681561859705115

Epoch: 6| Step: 6
Training loss: 4.305195331573486
Validation loss: 3.678478758822205

Epoch: 6| Step: 7
Training loss: 3.180753707885742
Validation loss: 3.6778714221010924

Epoch: 6| Step: 8
Training loss: 4.013216495513916
Validation loss: 3.674610258430563

Epoch: 6| Step: 9
Training loss: 3.50431489944458
Validation loss: 3.6736383720110823

Epoch: 6| Step: 10
Training loss: 3.2114949226379395
Validation loss: 3.6721162129473943

Epoch: 6| Step: 11
Training loss: 3.3890838623046875
Validation loss: 3.671059541804816

Epoch: 6| Step: 12
Training loss: 4.069313049316406
Validation loss: 3.6684196302967687

Epoch: 6| Step: 13
Training loss: 4.042147636413574
Validation loss: 3.666647498325635

Epoch: 2| Step: 0
Training loss: 3.2091429233551025
Validation loss: 3.6652720102699856

Epoch: 6| Step: 1
Training loss: 3.1562771797180176
Validation loss: 3.66149079415106

Epoch: 6| Step: 2
Training loss: 2.780529499053955
Validation loss: 3.66118630286186

Epoch: 6| Step: 3
Training loss: 4.366765975952148
Validation loss: 3.6592969714954333

Epoch: 6| Step: 4
Training loss: 3.042804718017578
Validation loss: 3.6565401579744075

Epoch: 6| Step: 5
Training loss: 3.6771163940429688
Validation loss: 3.65811998357055

Epoch: 6| Step: 6
Training loss: 4.502863883972168
Validation loss: 3.6542621402330298

Epoch: 6| Step: 7
Training loss: 3.05458927154541
Validation loss: 3.6528703320410942

Epoch: 6| Step: 8
Training loss: 4.358974456787109
Validation loss: 3.6526525815327964

Epoch: 6| Step: 9
Training loss: 3.598439931869507
Validation loss: 3.649688764285016

Epoch: 6| Step: 10
Training loss: 4.052296161651611
Validation loss: 3.650212187920847

Epoch: 6| Step: 11
Training loss: 1.938504695892334
Validation loss: 3.6488022035168064

Epoch: 6| Step: 12
Training loss: 4.266906261444092
Validation loss: 3.6451703143376175

Epoch: 6| Step: 13
Training loss: 4.1030473709106445
Validation loss: 3.6430585692005772

Epoch: 3| Step: 0
Training loss: 4.070180892944336
Validation loss: 3.6425618099909958

Epoch: 6| Step: 1
Training loss: 2.4826278686523438
Validation loss: 3.640077772960868

Epoch: 6| Step: 2
Training loss: 3.556171417236328
Validation loss: 3.636665277583625

Epoch: 6| Step: 3
Training loss: 2.910475730895996
Validation loss: 3.6367508160170687

Epoch: 6| Step: 4
Training loss: 3.4059879779815674
Validation loss: 3.634281232792844

Epoch: 6| Step: 5
Training loss: 2.590664863586426
Validation loss: 3.632147373691682

Epoch: 6| Step: 6
Training loss: 3.319317102432251
Validation loss: 3.633832626445319

Epoch: 6| Step: 7
Training loss: 4.471743583679199
Validation loss: 3.629798730214437

Epoch: 6| Step: 8
Training loss: 3.983834981918335
Validation loss: 3.6290555513033302

Epoch: 6| Step: 9
Training loss: 4.048790454864502
Validation loss: 3.6256186116126274

Epoch: 6| Step: 10
Training loss: 3.3000741004943848
Validation loss: 3.62456968779205

Epoch: 6| Step: 11
Training loss: 4.323142051696777
Validation loss: 3.622962567114061

Epoch: 6| Step: 12
Training loss: 3.6542530059814453
Validation loss: 3.6214196399975846

Epoch: 6| Step: 13
Training loss: 3.487704038619995
Validation loss: 3.61996635313957

Epoch: 4| Step: 0
Training loss: 4.5283203125
Validation loss: 3.6155296141101467

Epoch: 6| Step: 1
Training loss: 3.7353811264038086
Validation loss: 3.6169980392661145

Epoch: 6| Step: 2
Training loss: 2.9313981533050537
Validation loss: 3.6143261027592484

Epoch: 6| Step: 3
Training loss: 4.615781307220459
Validation loss: 3.6102808444730696

Epoch: 6| Step: 4
Training loss: 2.958815574645996
Validation loss: 3.6110322988161476

Epoch: 6| Step: 5
Training loss: 3.8825125694274902
Validation loss: 3.6054372813111994

Epoch: 6| Step: 6
Training loss: 3.5166914463043213
Validation loss: 3.6059546932097404

Epoch: 6| Step: 7
Training loss: 3.265496253967285
Validation loss: 3.6026834416133102

Epoch: 6| Step: 8
Training loss: 2.972299098968506
Validation loss: 3.59936773648826

Epoch: 6| Step: 9
Training loss: 2.623615264892578
Validation loss: 3.596866556393203

Epoch: 6| Step: 10
Training loss: 4.389414310455322
Validation loss: 3.5972329672946723

Epoch: 6| Step: 11
Training loss: 3.1428439617156982
Validation loss: 3.5943178438371226

Epoch: 6| Step: 12
Training loss: 3.633528709411621
Validation loss: 3.591477750450052

Epoch: 6| Step: 13
Training loss: 2.791327476501465
Validation loss: 3.5901968709884153

Epoch: 5| Step: 0
Training loss: 3.7818381786346436
Validation loss: 3.5882820211431032

Epoch: 6| Step: 1
Training loss: 4.601208686828613
Validation loss: 3.587411626692741

Epoch: 6| Step: 2
Training loss: 3.426363468170166
Validation loss: 3.5823127274872153

Epoch: 6| Step: 3
Training loss: 3.394272565841675
Validation loss: 3.5811964055543304

Epoch: 6| Step: 4
Training loss: 2.618715763092041
Validation loss: 3.578702506198678

Epoch: 6| Step: 5
Training loss: 2.8516411781311035
Validation loss: 3.5757689604195217

Epoch: 6| Step: 6
Training loss: 4.661332607269287
Validation loss: 3.5741893655510357

Epoch: 6| Step: 7
Training loss: 2.5674679279327393
Validation loss: 3.570482820592901

Epoch: 6| Step: 8
Training loss: 3.8841664791107178
Validation loss: 3.5741515774880686

Epoch: 6| Step: 9
Training loss: 4.128051280975342
Validation loss: 3.563982925107402

Epoch: 6| Step: 10
Training loss: 2.1093239784240723
Validation loss: 3.5673970458328084

Epoch: 6| Step: 11
Training loss: 4.555312156677246
Validation loss: 3.5630926111693024

Epoch: 6| Step: 12
Training loss: 3.381835460662842
Validation loss: 3.5575845421001477

Epoch: 6| Step: 13
Training loss: 2.539672613143921
Validation loss: 3.5584392188697733

Epoch: 6| Step: 0
Training loss: 2.287076473236084
Validation loss: 3.5550497629309215

Epoch: 6| Step: 1
Training loss: 3.0992815494537354
Validation loss: 3.552083497406334

Epoch: 6| Step: 2
Training loss: 3.334867477416992
Validation loss: 3.5516516059957524

Epoch: 6| Step: 3
Training loss: 3.5801522731781006
Validation loss: 3.5481904245192006

Epoch: 6| Step: 4
Training loss: 3.0888001918792725
Validation loss: 3.5454030908564085

Epoch: 6| Step: 5
Training loss: 3.1540541648864746
Validation loss: 3.542349946114325

Epoch: 6| Step: 6
Training loss: 3.266317129135132
Validation loss: 3.537729496596962

Epoch: 6| Step: 7
Training loss: 4.0890960693359375
Validation loss: 3.536601253735122

Epoch: 6| Step: 8
Training loss: 4.453492641448975
Validation loss: 3.533876636976837

Epoch: 6| Step: 9
Training loss: 4.326850891113281
Validation loss: 3.530146321942729

Epoch: 6| Step: 10
Training loss: 3.4030113220214844
Validation loss: 3.5300989304819415

Epoch: 6| Step: 11
Training loss: 3.5829553604125977
Validation loss: 3.5220449842432493

Epoch: 6| Step: 12
Training loss: 2.668071985244751
Validation loss: 3.5213990211486816

Epoch: 6| Step: 13
Training loss: 4.690001010894775
Validation loss: 3.515796992086595

Epoch: 7| Step: 0
Training loss: 2.7825469970703125
Validation loss: 3.51259845559315

Epoch: 6| Step: 1
Training loss: 3.376561164855957
Validation loss: 3.5099250962657313

Epoch: 6| Step: 2
Training loss: 4.576141357421875
Validation loss: 3.5084083439201437

Epoch: 6| Step: 3
Training loss: 3.625812292098999
Validation loss: 3.502519123015865

Epoch: 6| Step: 4
Training loss: 3.42317533493042
Validation loss: 3.5016433449201685

Epoch: 6| Step: 5
Training loss: 3.5565319061279297
Validation loss: 3.4954849238036783

Epoch: 6| Step: 6
Training loss: 3.096348285675049
Validation loss: 3.4884264571692354

Epoch: 6| Step: 7
Training loss: 4.023280143737793
Validation loss: 3.4874234481524398

Epoch: 6| Step: 8
Training loss: 2.9867947101593018
Validation loss: 3.4801608695778796

Epoch: 6| Step: 9
Training loss: 3.6458282470703125
Validation loss: 3.47279445586666

Epoch: 6| Step: 10
Training loss: 3.0345730781555176
Validation loss: 3.47075588985156

Epoch: 6| Step: 11
Training loss: 2.704638957977295
Validation loss: 3.4672748273418796

Epoch: 6| Step: 12
Training loss: 3.1352667808532715
Validation loss: 3.465599670205065

Epoch: 6| Step: 13
Training loss: 4.290678977966309
Validation loss: 3.459145927941927

Epoch: 8| Step: 0
Training loss: 3.138918399810791
Validation loss: 3.454119884839622

Epoch: 6| Step: 1
Training loss: 3.385817050933838
Validation loss: 3.4519810010028142

Epoch: 6| Step: 2
Training loss: 4.9046525955200195
Validation loss: 3.443796888474495

Epoch: 6| Step: 3
Training loss: 4.276756763458252
Validation loss: 3.43890558263307

Epoch: 6| Step: 4
Training loss: 3.390613555908203
Validation loss: 3.4292855262756348

Epoch: 6| Step: 5
Training loss: 3.3999969959259033
Validation loss: 3.425054545043617

Epoch: 6| Step: 6
Training loss: 2.751486301422119
Validation loss: 3.4239619290956886

Epoch: 6| Step: 7
Training loss: 3.6756763458251953
Validation loss: 3.4174120938906105

Epoch: 6| Step: 8
Training loss: 2.800302028656006
Validation loss: 3.4140644432396017

Epoch: 6| Step: 9
Training loss: 2.931828498840332
Validation loss: 3.4081262593628256

Epoch: 6| Step: 10
Training loss: 2.742647171020508
Validation loss: 3.400936452291345

Epoch: 6| Step: 11
Training loss: 2.802846908569336
Validation loss: 3.397101835537982

Epoch: 6| Step: 12
Training loss: 3.373141288757324
Validation loss: 3.3917136141048965

Epoch: 6| Step: 13
Training loss: 3.6397197246551514
Validation loss: 3.3773182694629957

Epoch: 9| Step: 0
Training loss: 3.664793014526367
Validation loss: 3.374043546697145

Epoch: 6| Step: 1
Training loss: 2.1576507091522217
Validation loss: 3.3713229497273765

Epoch: 6| Step: 2
Training loss: 3.547830820083618
Validation loss: 3.3655309036213863

Epoch: 6| Step: 3
Training loss: 2.2886786460876465
Validation loss: 3.359358013317149

Epoch: 6| Step: 4
Training loss: 2.974842071533203
Validation loss: 3.354506436214652

Epoch: 6| Step: 5
Training loss: 3.970496416091919
Validation loss: 3.3472695632647445

Epoch: 6| Step: 6
Training loss: 2.447147846221924
Validation loss: 3.345749324367892

Epoch: 6| Step: 7
Training loss: 3.093078374862671
Validation loss: 3.3354381771497827

Epoch: 6| Step: 8
Training loss: 3.314213275909424
Validation loss: 3.3238317299914617

Epoch: 6| Step: 9
Training loss: 3.5645294189453125
Validation loss: 3.323362842682869

Epoch: 6| Step: 10
Training loss: 3.3673207759857178
Validation loss: 3.312641438617501

Epoch: 6| Step: 11
Training loss: 3.941004753112793
Validation loss: 3.3113235965851815

Epoch: 6| Step: 12
Training loss: 4.729800701141357
Validation loss: 3.3037324413176505

Epoch: 6| Step: 13
Training loss: 2.8092024326324463
Validation loss: 3.2910841408596245

Epoch: 10| Step: 0
Training loss: 2.876333475112915
Validation loss: 3.287566546470888

Epoch: 6| Step: 1
Training loss: 3.7567601203918457
Validation loss: 3.281880312068488

Epoch: 6| Step: 2
Training loss: 3.6647603511810303
Validation loss: 3.2727927187437653

Epoch: 6| Step: 3
Training loss: 3.3815436363220215
Validation loss: 3.2601758049380396

Epoch: 6| Step: 4
Training loss: 3.630409002304077
Validation loss: 3.2557172852177776

Epoch: 6| Step: 5
Training loss: 3.5145416259765625
Validation loss: 3.247664846399779

Epoch: 6| Step: 6
Training loss: 4.786478519439697
Validation loss: 3.242253957256194

Epoch: 6| Step: 7
Training loss: 2.6333134174346924
Validation loss: 3.228304324611541

Epoch: 6| Step: 8
Training loss: 3.0942862033843994
Validation loss: 3.221268218050721

Epoch: 6| Step: 9
Training loss: 2.5403010845184326
Validation loss: 3.211439140381352

Epoch: 6| Step: 10
Training loss: 2.9543771743774414
Validation loss: 3.2062644522677184

Epoch: 6| Step: 11
Training loss: 3.076296806335449
Validation loss: 3.2002148243688766

Epoch: 6| Step: 12
Training loss: 2.1398444175720215
Validation loss: 3.1857205898531022

Epoch: 6| Step: 13
Training loss: 2.9541215896606445
Validation loss: 3.18517311926811

Epoch: 11| Step: 0
Training loss: 3.077817916870117
Validation loss: 3.180782474497313

Epoch: 6| Step: 1
Training loss: 2.719268798828125
Validation loss: 3.1643631304464033

Epoch: 6| Step: 2
Training loss: 3.4005184173583984
Validation loss: 3.1581936472205707

Epoch: 6| Step: 3
Training loss: 3.412313461303711
Validation loss: 3.1497105706122612

Epoch: 6| Step: 4
Training loss: 2.977264642715454
Validation loss: 3.1396415797613

Epoch: 6| Step: 5
Training loss: 2.7530648708343506
Validation loss: 3.1347598978268203

Epoch: 6| Step: 6
Training loss: 2.537369728088379
Validation loss: 3.1257296377612698

Epoch: 6| Step: 7
Training loss: 3.494082450866699
Validation loss: 3.1193871805744786

Epoch: 6| Step: 8
Training loss: 4.192715644836426
Validation loss: 3.107067431173017

Epoch: 6| Step: 9
Training loss: 3.3466339111328125
Validation loss: 3.101560297832694

Epoch: 6| Step: 10
Training loss: 3.280022144317627
Validation loss: 3.0932472854532223

Epoch: 6| Step: 11
Training loss: 2.9092578887939453
Validation loss: 3.082669996446179

Epoch: 6| Step: 12
Training loss: 3.2004661560058594
Validation loss: 3.0712252099026918

Epoch: 6| Step: 13
Training loss: 1.9156382083892822
Validation loss: 3.0583032587523102

Epoch: 12| Step: 0
Training loss: 3.2021610736846924
Validation loss: 3.05356437929215

Epoch: 6| Step: 1
Training loss: 2.2633414268493652
Validation loss: 3.0428266166358866

Epoch: 6| Step: 2
Training loss: 2.2255055904388428
Validation loss: 3.0338907395639727

Epoch: 6| Step: 3
Training loss: 2.5825812816619873
Validation loss: 3.0273567425307406

Epoch: 6| Step: 4
Training loss: 2.6805472373962402
Validation loss: 3.0172270036512807

Epoch: 6| Step: 5
Training loss: 2.5140228271484375
Validation loss: 3.005467948093209

Epoch: 6| Step: 6
Training loss: 2.5549919605255127
Validation loss: 3.0070292718948854

Epoch: 6| Step: 7
Training loss: 4.349953651428223
Validation loss: 2.9933226698188373

Epoch: 6| Step: 8
Training loss: 3.956179618835449
Validation loss: 2.978033291396274

Epoch: 6| Step: 9
Training loss: 2.929719924926758
Validation loss: 2.9696636840861332

Epoch: 6| Step: 10
Training loss: 3.50905442237854
Validation loss: 2.9613046902482227

Epoch: 6| Step: 11
Training loss: 3.7978055477142334
Validation loss: 2.948996769484653

Epoch: 6| Step: 12
Training loss: 2.9703757762908936
Validation loss: 2.9328056317503735

Epoch: 6| Step: 13
Training loss: 2.6889500617980957
Validation loss: 2.9265166636436217

Epoch: 13| Step: 0
Training loss: 2.5146846771240234
Validation loss: 2.9190455226488012

Epoch: 6| Step: 1
Training loss: 3.6931872367858887
Validation loss: 2.8995453080823346

Epoch: 6| Step: 2
Training loss: 3.566537857055664
Validation loss: 2.8891174126696844

Epoch: 6| Step: 3
Training loss: 2.2863736152648926
Validation loss: 2.8818532369470082

Epoch: 6| Step: 4
Training loss: 2.662405014038086
Validation loss: 2.8665078737402476

Epoch: 6| Step: 5
Training loss: 2.7040910720825195
Validation loss: 2.8527529316563762

Epoch: 6| Step: 6
Training loss: 2.01515793800354
Validation loss: 2.8478587083919074

Epoch: 6| Step: 7
Training loss: 4.044835567474365
Validation loss: 2.842662818970219

Epoch: 6| Step: 8
Training loss: 2.819209575653076
Validation loss: 2.8254912027748684

Epoch: 6| Step: 9
Training loss: 2.4097652435302734
Validation loss: 2.8179727574830413

Epoch: 6| Step: 10
Training loss: 3.175316333770752
Validation loss: 2.809204404072095

Epoch: 6| Step: 11
Training loss: 3.3695476055145264
Validation loss: 2.795963771881596

Epoch: 6| Step: 12
Training loss: 2.6627769470214844
Validation loss: 2.784775544238347

Epoch: 6| Step: 13
Training loss: 3.397028923034668
Validation loss: 2.76888431015835

Epoch: 14| Step: 0
Training loss: 2.8722124099731445
Validation loss: 2.7534010717945714

Epoch: 6| Step: 1
Training loss: 2.931225299835205
Validation loss: 2.7447404630722536

Epoch: 6| Step: 2
Training loss: 2.0614585876464844
Validation loss: 2.7307698290835143

Epoch: 6| Step: 3
Training loss: 2.2079968452453613
Validation loss: 2.723907562994188

Epoch: 6| Step: 4
Training loss: 3.1139211654663086
Validation loss: 2.7087939580281577

Epoch: 6| Step: 5
Training loss: 2.3316783905029297
Validation loss: 2.7015970663357805

Epoch: 6| Step: 6
Training loss: 3.388505697250366
Validation loss: 2.688713119876

Epoch: 6| Step: 7
Training loss: 2.419795513153076
Validation loss: 2.672444705040224

Epoch: 6| Step: 8
Training loss: 3.3164305686950684
Validation loss: 2.6617373010163665

Epoch: 6| Step: 9
Training loss: 3.516240358352661
Validation loss: 2.655483873941565

Epoch: 6| Step: 10
Training loss: 3.089747905731201
Validation loss: 2.641018457310174

Epoch: 6| Step: 11
Training loss: 2.946847438812256
Validation loss: 2.628126108518211

Epoch: 6| Step: 12
Training loss: 2.526036262512207
Validation loss: 2.599597728380593

Epoch: 6| Step: 13
Training loss: 2.9126029014587402
Validation loss: 2.594476276828397

Epoch: 15| Step: 0
Training loss: 3.6291513442993164
Validation loss: 2.5868946275403424

Epoch: 6| Step: 1
Training loss: 3.053731918334961
Validation loss: 2.5694920401419363

Epoch: 6| Step: 2
Training loss: 2.8604888916015625
Validation loss: 2.5505026078993276

Epoch: 6| Step: 3
Training loss: 2.142197847366333
Validation loss: 2.5476452073743268

Epoch: 6| Step: 4
Training loss: 2.143545389175415
Validation loss: 2.522250542076685

Epoch: 6| Step: 5
Training loss: 2.57440185546875
Validation loss: 2.507250291044994

Epoch: 6| Step: 6
Training loss: 2.4747965335845947
Validation loss: 2.495322778660764

Epoch: 6| Step: 7
Training loss: 2.7634663581848145
Validation loss: 2.4787814591520574

Epoch: 6| Step: 8
Training loss: 2.392869472503662
Validation loss: 2.4862711942324074

Epoch: 6| Step: 9
Training loss: 2.5008656978607178
Validation loss: 2.459338770117811

Epoch: 6| Step: 10
Training loss: 2.587388515472412
Validation loss: 2.456577193352484

Epoch: 6| Step: 11
Training loss: 3.1854419708251953
Validation loss: 2.451618730380971

Epoch: 6| Step: 12
Training loss: 2.687842845916748
Validation loss: 2.4402637763689925

Epoch: 6| Step: 13
Training loss: 3.728563070297241
Validation loss: 2.4260486095182356

Epoch: 16| Step: 0
Training loss: 2.770704746246338
Validation loss: 2.4097689159454836

Epoch: 6| Step: 1
Training loss: 2.899981737136841
Validation loss: 2.404943850732619

Epoch: 6| Step: 2
Training loss: 2.566311836242676
Validation loss: 2.3878394352492465

Epoch: 6| Step: 3
Training loss: 3.434633255004883
Validation loss: 2.3872206877636653

Epoch: 6| Step: 4
Training loss: 2.3973686695098877
Validation loss: 2.3554157492935017

Epoch: 6| Step: 5
Training loss: 2.6215953826904297
Validation loss: 2.3690372308095298

Epoch: 6| Step: 6
Training loss: 2.384265899658203
Validation loss: 2.355645674531178

Epoch: 6| Step: 7
Training loss: 3.0397305488586426
Validation loss: 2.34116841003459

Epoch: 6| Step: 8
Training loss: 2.374782085418701
Validation loss: 2.3417501090675272

Epoch: 6| Step: 9
Training loss: 1.991847038269043
Validation loss: 2.3295200742701048

Epoch: 6| Step: 10
Training loss: 2.796684503555298
Validation loss: 2.316917755270517

Epoch: 6| Step: 11
Training loss: 2.5724592208862305
Validation loss: 2.3134495366004204

Epoch: 6| Step: 12
Training loss: 2.5382513999938965
Validation loss: 2.308749919296593

Epoch: 6| Step: 13
Training loss: 2.644669532775879
Validation loss: 2.282653531720561

Epoch: 17| Step: 0
Training loss: 2.484564781188965
Validation loss: 2.285738170787852

Epoch: 6| Step: 1
Training loss: 2.8561267852783203
Validation loss: 2.275227669746645

Epoch: 6| Step: 2
Training loss: 2.268184185028076
Validation loss: 2.2664193786600584

Epoch: 6| Step: 3
Training loss: 3.14615797996521
Validation loss: 2.265032765685871

Epoch: 6| Step: 4
Training loss: 1.8507535457611084
Validation loss: 2.250123962279289

Epoch: 6| Step: 5
Training loss: 2.355516195297241
Validation loss: 2.241025686264038

Epoch: 6| Step: 6
Training loss: 2.9647090435028076
Validation loss: 2.2368420477836364

Epoch: 6| Step: 7
Training loss: 2.277446746826172
Validation loss: 2.242155446801134

Epoch: 6| Step: 8
Training loss: 2.7416458129882812
Validation loss: 2.2394421895345054

Epoch: 6| Step: 9
Training loss: 2.7812182903289795
Validation loss: 2.2252215441837104

Epoch: 6| Step: 10
Training loss: 1.9594533443450928
Validation loss: 2.2196301747393865

Epoch: 6| Step: 11
Training loss: 2.6980507373809814
Validation loss: 2.2097135743787213

Epoch: 6| Step: 12
Training loss: 2.9973559379577637
Validation loss: 2.200077203012282

Epoch: 6| Step: 13
Training loss: 2.3035669326782227
Validation loss: 2.2033888652760494

Epoch: 18| Step: 0
Training loss: 3.453911304473877
Validation loss: 2.1841223855172434

Epoch: 6| Step: 1
Training loss: 2.057549476623535
Validation loss: 2.1727607506577686

Epoch: 6| Step: 2
Training loss: 2.659868001937866
Validation loss: 2.1690511959855274

Epoch: 6| Step: 3
Training loss: 2.261338949203491
Validation loss: 2.1607969204584756

Epoch: 6| Step: 4
Training loss: 1.8379377126693726
Validation loss: 2.148855293950727

Epoch: 6| Step: 5
Training loss: 2.755622148513794
Validation loss: 2.146745462571421

Epoch: 6| Step: 6
Training loss: 2.8720645904541016
Validation loss: 2.144522205475838

Epoch: 6| Step: 7
Training loss: 2.8909943103790283
Validation loss: 2.153840962276664

Epoch: 6| Step: 8
Training loss: 2.498671770095825
Validation loss: 2.135499018494801

Epoch: 6| Step: 9
Training loss: 1.9863855838775635
Validation loss: 2.134089208418323

Epoch: 6| Step: 10
Training loss: 2.882004976272583
Validation loss: 2.135807446254197

Epoch: 6| Step: 11
Training loss: 2.388843059539795
Validation loss: 2.1291646162668862

Epoch: 6| Step: 12
Training loss: 2.576240062713623
Validation loss: 2.133900139921455

Epoch: 6| Step: 13
Training loss: 1.5277639627456665
Validation loss: 2.1128231299820768

Epoch: 19| Step: 0
Training loss: 2.588608741760254
Validation loss: 2.1211502270032

Epoch: 6| Step: 1
Training loss: 2.5156593322753906
Validation loss: 2.09526535003416

Epoch: 6| Step: 2
Training loss: 2.769092321395874
Validation loss: 2.10997684027559

Epoch: 6| Step: 3
Training loss: 3.1059651374816895
Validation loss: 2.0968320497902493

Epoch: 6| Step: 4
Training loss: 2.7409653663635254
Validation loss: 2.0829800072536675

Epoch: 6| Step: 5
Training loss: 2.0267863273620605
Validation loss: 2.0954893660801712

Epoch: 6| Step: 6
Training loss: 1.767784833908081
Validation loss: 2.081469069245041

Epoch: 6| Step: 7
Training loss: 2.9209227561950684
Validation loss: 2.073889729797199

Epoch: 6| Step: 8
Training loss: 2.178356885910034
Validation loss: 2.0741411383434007

Epoch: 6| Step: 9
Training loss: 1.7889211177825928
Validation loss: 2.065880178123392

Epoch: 6| Step: 10
Training loss: 2.945141553878784
Validation loss: 2.0814723455777733

Epoch: 6| Step: 11
Training loss: 2.1656494140625
Validation loss: 2.094887956496208

Epoch: 6| Step: 12
Training loss: 2.633676528930664
Validation loss: 2.0864519970391386

Epoch: 6| Step: 13
Training loss: 2.603743314743042
Validation loss: 2.080209817937625

Epoch: 20| Step: 0
Training loss: 2.058262348175049
Validation loss: 2.0730220502422703

Epoch: 6| Step: 1
Training loss: 2.475996494293213
Validation loss: 2.069222729693177

Epoch: 6| Step: 2
Training loss: 2.360100269317627
Validation loss: 2.072041093662221

Epoch: 6| Step: 3
Training loss: 1.873875617980957
Validation loss: 2.058138096204368

Epoch: 6| Step: 4
Training loss: 2.389946460723877
Validation loss: 2.0412507749372915

Epoch: 6| Step: 5
Training loss: 2.046935796737671
Validation loss: 2.0702430317478795

Epoch: 6| Step: 6
Training loss: 2.4667911529541016
Validation loss: 2.0445093544580604

Epoch: 6| Step: 7
Training loss: 2.8576431274414062
Validation loss: 2.0448568187734133

Epoch: 6| Step: 8
Training loss: 2.5727601051330566
Validation loss: 2.042074731601182

Epoch: 6| Step: 9
Training loss: 2.4382572174072266
Validation loss: 2.056476769908782

Epoch: 6| Step: 10
Training loss: 3.0108931064605713
Validation loss: 2.0406647497607815

Epoch: 6| Step: 11
Training loss: 2.7964799404144287
Validation loss: 2.0492839428686325

Epoch: 6| Step: 12
Training loss: 2.8358945846557617
Validation loss: 2.054398093172299

Epoch: 6| Step: 13
Training loss: 2.4404306411743164
Validation loss: 2.04465163394969

Epoch: 21| Step: 0
Training loss: 2.3244853019714355
Validation loss: 2.0436956600476335

Epoch: 6| Step: 1
Training loss: 2.353804111480713
Validation loss: 2.047412772332468

Epoch: 6| Step: 2
Training loss: 2.5043606758117676
Validation loss: 2.0585245765665525

Epoch: 6| Step: 3
Training loss: 2.693166971206665
Validation loss: 2.0496393454972135

Epoch: 6| Step: 4
Training loss: 3.0500645637512207
Validation loss: 2.0498201001075005

Epoch: 6| Step: 5
Training loss: 1.9509742259979248
Validation loss: 2.0533020009276686

Epoch: 6| Step: 6
Training loss: 2.63421630859375
Validation loss: 2.053971621298021

Epoch: 6| Step: 7
Training loss: 2.3269166946411133
Validation loss: 2.0564949973937003

Epoch: 6| Step: 8
Training loss: 2.0097131729125977
Validation loss: 2.0478047196583082

Epoch: 6| Step: 9
Training loss: 2.170544385910034
Validation loss: 2.067818255834682

Epoch: 6| Step: 10
Training loss: 2.9389731884002686
Validation loss: 2.0694596485425065

Epoch: 6| Step: 11
Training loss: 2.810868263244629
Validation loss: 2.048749568641827

Epoch: 6| Step: 12
Training loss: 2.675649642944336
Validation loss: 2.0621606508890786

Epoch: 6| Step: 13
Training loss: 1.8057588338851929
Validation loss: 2.0589950828142065

Epoch: 22| Step: 0
Training loss: 2.853200912475586
Validation loss: 2.0582583283865326

Epoch: 6| Step: 1
Training loss: 2.3900701999664307
Validation loss: 2.0371791649890203

Epoch: 6| Step: 2
Training loss: 2.556246519088745
Validation loss: 2.0474434744927192

Epoch: 6| Step: 3
Training loss: 1.9897840023040771
Validation loss: 2.0564595191709456

Epoch: 6| Step: 4
Training loss: 2.8714182376861572
Validation loss: 2.0686576622788624

Epoch: 6| Step: 5
Training loss: 2.774765729904175
Validation loss: 2.0522338651841685

Epoch: 6| Step: 6
Training loss: 2.09952974319458
Validation loss: 2.0433761842789187

Epoch: 6| Step: 7
Training loss: 2.5018808841705322
Validation loss: 2.0538450569234867

Epoch: 6| Step: 8
Training loss: 2.7534523010253906
Validation loss: 2.052219006323045

Epoch: 6| Step: 9
Training loss: 2.6851377487182617
Validation loss: 2.0493122198248424

Epoch: 6| Step: 10
Training loss: 1.9221385717391968
Validation loss: 2.0500312056592715

Epoch: 6| Step: 11
Training loss: 1.9040628671646118
Validation loss: 2.0415086489851757

Epoch: 6| Step: 12
Training loss: 2.6028506755828857
Validation loss: 2.036633781207505

Epoch: 6| Step: 13
Training loss: 2.702946662902832
Validation loss: 2.0372296071821645

Epoch: 23| Step: 0
Training loss: 1.9540455341339111
Validation loss: 2.045330096316594

Epoch: 6| Step: 1
Training loss: 2.538620948791504
Validation loss: 2.053159744508805

Epoch: 6| Step: 2
Training loss: 2.5739729404449463
Validation loss: 2.0425817248641804

Epoch: 6| Step: 3
Training loss: 1.7816680669784546
Validation loss: 2.048323533868277

Epoch: 6| Step: 4
Training loss: 2.750938892364502
Validation loss: 2.0324848480122064

Epoch: 6| Step: 5
Training loss: 2.852969169616699
Validation loss: 2.0268348698974936

Epoch: 6| Step: 6
Training loss: 2.628087282180786
Validation loss: 2.052669890465275

Epoch: 6| Step: 7
Training loss: 2.492356300354004
Validation loss: 2.0390584930296867

Epoch: 6| Step: 8
Training loss: 2.295863151550293
Validation loss: 2.0299228186248452

Epoch: 6| Step: 9
Training loss: 2.17913556098938
Validation loss: 2.046268895108213

Epoch: 6| Step: 10
Training loss: 2.620215892791748
Validation loss: 2.060980942941481

Epoch: 6| Step: 11
Training loss: 2.6975514888763428
Validation loss: 2.03707032562584

Epoch: 6| Step: 12
Training loss: 2.512644052505493
Validation loss: 2.0492048673732306

Epoch: 6| Step: 13
Training loss: 2.577927350997925
Validation loss: 2.02418573569226

Epoch: 24| Step: 0
Training loss: 2.4713902473449707
Validation loss: 2.044853566795267

Epoch: 6| Step: 1
Training loss: 2.5689806938171387
Validation loss: 2.058252539685977

Epoch: 6| Step: 2
Training loss: 1.976199746131897
Validation loss: 2.0522618729581117

Epoch: 6| Step: 3
Training loss: 3.2096266746520996
Validation loss: 2.033058883041464

Epoch: 6| Step: 4
Training loss: 2.8098833560943604
Validation loss: 2.0357467923113095

Epoch: 6| Step: 5
Training loss: 2.42388653755188
Validation loss: 2.058731670020729

Epoch: 6| Step: 6
Training loss: 3.09987211227417
Validation loss: 2.053239619860085

Epoch: 6| Step: 7
Training loss: 2.2329607009887695
Validation loss: 2.0727160489687355

Epoch: 6| Step: 8
Training loss: 2.6378252506256104
Validation loss: 2.041997763418382

Epoch: 6| Step: 9
Training loss: 2.2333269119262695
Validation loss: 2.0629279690404094

Epoch: 6| Step: 10
Training loss: 2.3265273571014404
Validation loss: 2.0481938264703237

Epoch: 6| Step: 11
Training loss: 2.2500903606414795
Validation loss: 2.045040935598394

Epoch: 6| Step: 12
Training loss: 2.2209010124206543
Validation loss: 2.027081548526723

Epoch: 6| Step: 13
Training loss: 1.5932106971740723
Validation loss: 2.036186978381167

Epoch: 25| Step: 0
Training loss: 2.258136749267578
Validation loss: 2.0488020950748074

Epoch: 6| Step: 1
Training loss: 2.188450336456299
Validation loss: 2.0497508331011702

Epoch: 6| Step: 2
Training loss: 2.129091262817383
Validation loss: 2.048887255371258

Epoch: 6| Step: 3
Training loss: 2.9407310485839844
Validation loss: 2.039874530607654

Epoch: 6| Step: 4
Training loss: 2.202223777770996
Validation loss: 2.0436369001224475

Epoch: 6| Step: 5
Training loss: 3.0188686847686768
Validation loss: 2.060581173948062

Epoch: 6| Step: 6
Training loss: 2.4132370948791504
Validation loss: 2.0481907642015846

Epoch: 6| Step: 7
Training loss: 2.3356611728668213
Validation loss: 2.0262157481203795

Epoch: 6| Step: 8
Training loss: 2.2390191555023193
Validation loss: 2.0403980490981892

Epoch: 6| Step: 9
Training loss: 2.206265926361084
Validation loss: 2.0383872511566326

Epoch: 6| Step: 10
Training loss: 1.9586336612701416
Validation loss: 2.0371044399917766

Epoch: 6| Step: 11
Training loss: 2.872440814971924
Validation loss: 2.0543977893808836

Epoch: 6| Step: 12
Training loss: 2.9232325553894043
Validation loss: 2.0379040728333178

Epoch: 6| Step: 13
Training loss: 2.6810593605041504
Validation loss: 2.0431629957691317

Epoch: 26| Step: 0
Training loss: 1.923777461051941
Validation loss: 2.0501590287813576

Epoch: 6| Step: 1
Training loss: 1.8417844772338867
Validation loss: 2.049993881615259

Epoch: 6| Step: 2
Training loss: 2.5526185035705566
Validation loss: 2.0476685826496412

Epoch: 6| Step: 3
Training loss: 2.4148755073547363
Validation loss: 2.048200604736164

Epoch: 6| Step: 4
Training loss: 2.675441265106201
Validation loss: 2.047153126808905

Epoch: 6| Step: 5
Training loss: 2.4516217708587646
Validation loss: 2.035155047652542

Epoch: 6| Step: 6
Training loss: 2.734692335128784
Validation loss: 2.0386287986591296

Epoch: 6| Step: 7
Training loss: 2.6008830070495605
Validation loss: 2.0428299647505566

Epoch: 6| Step: 8
Training loss: 2.62949275970459
Validation loss: 2.0332210986844954

Epoch: 6| Step: 9
Training loss: 2.730952262878418
Validation loss: 2.0447308401907645

Epoch: 6| Step: 10
Training loss: 2.3646926879882812
Validation loss: 2.046726139642859

Epoch: 6| Step: 11
Training loss: 2.3295016288757324
Validation loss: 2.043537562893283

Epoch: 6| Step: 12
Training loss: 2.5114493370056152
Validation loss: 2.048572254437272

Epoch: 6| Step: 13
Training loss: 2.539799690246582
Validation loss: 2.0382122262831657

Epoch: 27| Step: 0
Training loss: 2.962240695953369
Validation loss: 2.039948590340153

Epoch: 6| Step: 1
Training loss: 3.002342700958252
Validation loss: 2.0471777403226463

Epoch: 6| Step: 2
Training loss: 2.049767255783081
Validation loss: 2.0375333960338304

Epoch: 6| Step: 3
Training loss: 2.127741813659668
Validation loss: 2.0458567424487044

Epoch: 6| Step: 4
Training loss: 2.254262924194336
Validation loss: 2.049292734874192

Epoch: 6| Step: 5
Training loss: 2.0886170864105225
Validation loss: 2.03062351288334

Epoch: 6| Step: 6
Training loss: 1.9531971216201782
Validation loss: 2.0287442591882523

Epoch: 6| Step: 7
Training loss: 2.743941307067871
Validation loss: 2.044110434029692

Epoch: 6| Step: 8
Training loss: 2.4624218940734863
Validation loss: 2.0488690894137145

Epoch: 6| Step: 9
Training loss: 2.4111289978027344
Validation loss: 2.0541579197811823

Epoch: 6| Step: 10
Training loss: 3.1915342807769775
Validation loss: 2.051175655857209

Epoch: 6| Step: 11
Training loss: 2.3432395458221436
Validation loss: 2.0350907335999193

Epoch: 6| Step: 12
Training loss: 2.5102596282958984
Validation loss: 2.041563674967776

Epoch: 6| Step: 13
Training loss: 1.8718727827072144
Validation loss: 2.0456236767512497

Epoch: 28| Step: 0
Training loss: 2.5061209201812744
Validation loss: 2.051842507495675

Epoch: 6| Step: 1
Training loss: 2.0860230922698975
Validation loss: 2.035345187751196

Epoch: 6| Step: 2
Training loss: 2.6685400009155273
Validation loss: 2.0311545325863745

Epoch: 6| Step: 3
Training loss: 2.512439250946045
Validation loss: 2.044979090331703

Epoch: 6| Step: 4
Training loss: 2.345609188079834
Validation loss: 2.0435464253989597

Epoch: 6| Step: 5
Training loss: 2.3115034103393555
Validation loss: 2.04685212719825

Epoch: 6| Step: 6
Training loss: 1.8781259059906006
Validation loss: 2.0497219947076615

Epoch: 6| Step: 7
Training loss: 3.1657252311706543
Validation loss: 2.0566921246949064

Epoch: 6| Step: 8
Training loss: 2.392111301422119
Validation loss: 2.049583637586204

Epoch: 6| Step: 9
Training loss: 2.2788989543914795
Validation loss: 2.0513362294884137

Epoch: 6| Step: 10
Training loss: 2.7780423164367676
Validation loss: 2.049539404530679

Epoch: 6| Step: 11
Training loss: 2.485424518585205
Validation loss: 2.043530218062862

Epoch: 6| Step: 12
Training loss: 2.4538490772247314
Validation loss: 2.041857356666237

Epoch: 6| Step: 13
Training loss: 2.418626070022583
Validation loss: 2.040052262685632

Epoch: 29| Step: 0
Training loss: 2.127903938293457
Validation loss: 2.0392502097673315

Epoch: 6| Step: 1
Training loss: 2.2450480461120605
Validation loss: 2.0399511578262493

Epoch: 6| Step: 2
Training loss: 2.474396228790283
Validation loss: 2.042855331974645

Epoch: 6| Step: 3
Training loss: 2.519676923751831
Validation loss: 2.0516591994993147

Epoch: 6| Step: 4
Training loss: 1.9763691425323486
Validation loss: 2.03834714171707

Epoch: 6| Step: 5
Training loss: 1.8122739791870117
Validation loss: 2.0470061404730684

Epoch: 6| Step: 6
Training loss: 3.0346384048461914
Validation loss: 2.0728948859758276

Epoch: 6| Step: 7
Training loss: 2.895210027694702
Validation loss: 2.0563162372958277

Epoch: 6| Step: 8
Training loss: 1.9824038743972778
Validation loss: 2.0565501810402

Epoch: 6| Step: 9
Training loss: 2.201164960861206
Validation loss: 2.0383097151274323

Epoch: 6| Step: 10
Training loss: 2.930267333984375
Validation loss: 2.050041698640393

Epoch: 6| Step: 11
Training loss: 2.879533052444458
Validation loss: 2.050447094825006

Epoch: 6| Step: 12
Training loss: 2.8972442150115967
Validation loss: 2.037639884538548

Epoch: 6| Step: 13
Training loss: 2.100445032119751
Validation loss: 2.054739664959651

Epoch: 30| Step: 0
Training loss: 2.794600009918213
Validation loss: 2.045651435852051

Epoch: 6| Step: 1
Training loss: 2.034574508666992
Validation loss: 2.0462580573174263

Epoch: 6| Step: 2
Training loss: 2.204732894897461
Validation loss: 2.066438087853052

Epoch: 6| Step: 3
Training loss: 2.398768424987793
Validation loss: 2.038410832805018

Epoch: 6| Step: 4
Training loss: 2.07570219039917
Validation loss: 2.0547662627312446

Epoch: 6| Step: 5
Training loss: 2.345172166824341
Validation loss: 2.0402159062764977

Epoch: 6| Step: 6
Training loss: 2.952474594116211
Validation loss: 2.0661796318587435

Epoch: 6| Step: 7
Training loss: 2.7374863624572754
Validation loss: 2.041987806238154

Epoch: 6| Step: 8
Training loss: 1.7740634679794312
Validation loss: 2.0435809512292185

Epoch: 6| Step: 9
Training loss: 2.9881253242492676
Validation loss: 2.02802953925184

Epoch: 6| Step: 10
Training loss: 2.3394222259521484
Validation loss: 2.0436445564352055

Epoch: 6| Step: 11
Training loss: 2.110055923461914
Validation loss: 2.0464977782259703

Epoch: 6| Step: 12
Training loss: 2.375916004180908
Validation loss: 2.038865775190374

Epoch: 6| Step: 13
Training loss: 3.3721275329589844
Validation loss: 2.0218026843122257

Epoch: 31| Step: 0
Training loss: 2.4041800498962402
Validation loss: 2.045823891957601

Epoch: 6| Step: 1
Training loss: 2.28725528717041
Validation loss: 2.036452556169161

Epoch: 6| Step: 2
Training loss: 2.6917850971221924
Validation loss: 2.0368300381527153

Epoch: 6| Step: 3
Training loss: 2.5069386959075928
Validation loss: 2.040866631333546

Epoch: 6| Step: 4
Training loss: 2.317056179046631
Validation loss: 2.045176799579333

Epoch: 6| Step: 5
Training loss: 2.206028938293457
Validation loss: 2.0526144863456808

Epoch: 6| Step: 6
Training loss: 1.8922452926635742
Validation loss: 2.0425547374192106

Epoch: 6| Step: 7
Training loss: 1.878039002418518
Validation loss: 2.0423233047608407

Epoch: 6| Step: 8
Training loss: 2.4371180534362793
Validation loss: 2.044681949000205

Epoch: 6| Step: 9
Training loss: 2.4426259994506836
Validation loss: 2.0566254508110786

Epoch: 6| Step: 10
Training loss: 2.9313712120056152
Validation loss: 2.063677872380903

Epoch: 6| Step: 11
Training loss: 2.973038673400879
Validation loss: 2.051151996017784

Epoch: 6| Step: 12
Training loss: 2.3409910202026367
Validation loss: 2.032945289406725

Epoch: 6| Step: 13
Training loss: 3.0837130546569824
Validation loss: 2.0482167941267773

Epoch: 32| Step: 0
Training loss: 3.005587577819824
Validation loss: 2.045485838767021

Epoch: 6| Step: 1
Training loss: 2.1921112537384033
Validation loss: 2.0473709234627346

Epoch: 6| Step: 2
Training loss: 3.0065159797668457
Validation loss: 2.0625916398981565

Epoch: 6| Step: 3
Training loss: 2.8961803913116455
Validation loss: 2.0524351032831336

Epoch: 6| Step: 4
Training loss: 1.7788183689117432
Validation loss: 2.0390693244113716

Epoch: 6| Step: 5
Training loss: 1.9611116647720337
Validation loss: 2.058678916705552

Epoch: 6| Step: 6
Training loss: 2.459899425506592
Validation loss: 2.055147417130009

Epoch: 6| Step: 7
Training loss: 1.8392362594604492
Validation loss: 2.0363786092368503

Epoch: 6| Step: 8
Training loss: 2.616230010986328
Validation loss: 2.045256999231154

Epoch: 6| Step: 9
Training loss: 2.4679198265075684
Validation loss: 2.0524028629385014

Epoch: 6| Step: 10
Training loss: 2.547009229660034
Validation loss: 2.0445645278499973

Epoch: 6| Step: 11
Training loss: 2.763009548187256
Validation loss: 2.0598351647776942

Epoch: 6| Step: 12
Training loss: 1.8254806995391846
Validation loss: 2.0625543812269806

Epoch: 6| Step: 13
Training loss: 3.05796480178833
Validation loss: 2.028348743274648

Epoch: 33| Step: 0
Training loss: 2.462425470352173
Validation loss: 2.05582457716747

Epoch: 6| Step: 1
Training loss: 1.9188203811645508
Validation loss: 2.0422225101019746

Epoch: 6| Step: 2
Training loss: 1.7802338600158691
Validation loss: 2.0412785340380926

Epoch: 6| Step: 3
Training loss: 2.5427489280700684
Validation loss: 2.0415279647355438

Epoch: 6| Step: 4
Training loss: 2.9689278602600098
Validation loss: 2.0339246642205024

Epoch: 6| Step: 5
Training loss: 2.9588494300842285
Validation loss: 2.043277527696343

Epoch: 6| Step: 6
Training loss: 2.4060513973236084
Validation loss: 2.045557424586306

Epoch: 6| Step: 7
Training loss: 3.0192432403564453
Validation loss: 2.0431735605321903

Epoch: 6| Step: 8
Training loss: 2.262521266937256
Validation loss: 2.043589976526076

Epoch: 6| Step: 9
Training loss: 2.805068254470825
Validation loss: 2.0573025903394146

Epoch: 6| Step: 10
Training loss: 2.3938865661621094
Validation loss: 2.0388814351891957

Epoch: 6| Step: 11
Training loss: 1.7327606678009033
Validation loss: 2.0599836675069665

Epoch: 6| Step: 12
Training loss: 2.013145923614502
Validation loss: 2.0384795255558465

Epoch: 6| Step: 13
Training loss: 2.8247900009155273
Validation loss: 2.0571659688026673

Epoch: 34| Step: 0
Training loss: 2.3344783782958984
Validation loss: 2.036512836333244

Epoch: 6| Step: 1
Training loss: 2.341890811920166
Validation loss: 2.038735488409637

Epoch: 6| Step: 2
Training loss: 2.428152084350586
Validation loss: 2.035094735442951

Epoch: 6| Step: 3
Training loss: 2.6869759559631348
Validation loss: 2.0381528126296176

Epoch: 6| Step: 4
Training loss: 2.707857847213745
Validation loss: 2.047952030294685

Epoch: 6| Step: 5
Training loss: 2.5142569541931152
Validation loss: 2.038971185684204

Epoch: 6| Step: 6
Training loss: 2.0286061763763428
Validation loss: 2.0563514950454875

Epoch: 6| Step: 7
Training loss: 2.421226978302002
Validation loss: 2.039788148736441

Epoch: 6| Step: 8
Training loss: 2.0479304790496826
Validation loss: 2.03377345813218

Epoch: 6| Step: 9
Training loss: 2.6388351917266846
Validation loss: 2.0325705236004246

Epoch: 6| Step: 10
Training loss: 2.5742440223693848
Validation loss: 2.036287269284648

Epoch: 6| Step: 11
Training loss: 2.659390449523926
Validation loss: 2.02615277741545

Epoch: 6| Step: 12
Training loss: 2.494961977005005
Validation loss: 2.029345034271158

Epoch: 6| Step: 13
Training loss: 1.8075536489486694
Validation loss: 2.047271849006735

Epoch: 35| Step: 0
Training loss: 2.666350841522217
Validation loss: 2.0267837483395814

Epoch: 6| Step: 1
Training loss: 2.323240280151367
Validation loss: 2.0196775390255834

Epoch: 6| Step: 2
Training loss: 2.1104609966278076
Validation loss: 2.033183974604453

Epoch: 6| Step: 3
Training loss: 2.473952293395996
Validation loss: 2.027160520194679

Epoch: 6| Step: 4
Training loss: 1.861101746559143
Validation loss: 2.0361439566458426

Epoch: 6| Step: 5
Training loss: 3.2429404258728027
Validation loss: 2.035661760196891

Epoch: 6| Step: 6
Training loss: 2.274550437927246
Validation loss: 2.029880190408358

Epoch: 6| Step: 7
Training loss: 1.7578909397125244
Validation loss: 2.0260776422357045

Epoch: 6| Step: 8
Training loss: 2.6311421394348145
Validation loss: 2.0519640753346104

Epoch: 6| Step: 9
Training loss: 2.0708937644958496
Validation loss: 2.041068482142623

Epoch: 6| Step: 10
Training loss: 2.3905701637268066
Validation loss: 2.0361473534696843

Epoch: 6| Step: 11
Training loss: 3.1895194053649902
Validation loss: 2.0217890072894353

Epoch: 6| Step: 12
Training loss: 2.5469255447387695
Validation loss: 2.0317322643854285

Epoch: 6| Step: 13
Training loss: 2.155196189880371
Validation loss: 2.0470221837361655

Epoch: 36| Step: 0
Training loss: 2.0880799293518066
Validation loss: 2.0321208533420356

Epoch: 6| Step: 1
Training loss: 2.057084560394287
Validation loss: 2.0344166691585253

Epoch: 6| Step: 2
Training loss: 2.3228158950805664
Validation loss: 2.0225648931277695

Epoch: 6| Step: 3
Training loss: 2.7573533058166504
Validation loss: 2.0384513870362313

Epoch: 6| Step: 4
Training loss: 2.636864185333252
Validation loss: 2.050763490379498

Epoch: 6| Step: 5
Training loss: 2.9847307205200195
Validation loss: 2.0291759531985045

Epoch: 6| Step: 6
Training loss: 1.97743558883667
Validation loss: 2.049541046542506

Epoch: 6| Step: 7
Training loss: 2.1275134086608887
Validation loss: 2.038679245979555

Epoch: 6| Step: 8
Training loss: 2.5341856479644775
Validation loss: 2.031414403710314

Epoch: 6| Step: 9
Training loss: 2.7828831672668457
Validation loss: 2.0530333365163496

Epoch: 6| Step: 10
Training loss: 2.423672914505005
Validation loss: 2.0466238426905807

Epoch: 6| Step: 11
Training loss: 2.003730535507202
Validation loss: 2.0417594922486173

Epoch: 6| Step: 12
Training loss: 2.808067798614502
Validation loss: 2.0329352732627624

Epoch: 6| Step: 13
Training loss: 2.0715103149414062
Validation loss: 2.0479437343535887

Epoch: 37| Step: 0
Training loss: 2.173455238342285
Validation loss: 2.0445228776624127

Epoch: 6| Step: 1
Training loss: 2.4955251216888428
Validation loss: 2.038824401875978

Epoch: 6| Step: 2
Training loss: 2.9630556106567383
Validation loss: 2.0273860654523297

Epoch: 6| Step: 3
Training loss: 2.6470813751220703
Validation loss: 2.0193551278883413

Epoch: 6| Step: 4
Training loss: 2.5486979484558105
Validation loss: 2.040637344442388

Epoch: 6| Step: 5
Training loss: 2.158639907836914
Validation loss: 2.0104929554846978

Epoch: 6| Step: 6
Training loss: 2.8688199520111084
Validation loss: 2.036533107039749

Epoch: 6| Step: 7
Training loss: 2.0617027282714844
Validation loss: 2.02815277858447

Epoch: 6| Step: 8
Training loss: 2.553095579147339
Validation loss: 2.044303692797179

Epoch: 6| Step: 9
Training loss: 2.8791768550872803
Validation loss: 2.011475573303879

Epoch: 6| Step: 10
Training loss: 1.9706488847732544
Validation loss: 2.0358308822877946

Epoch: 6| Step: 11
Training loss: 2.0775980949401855
Validation loss: 2.038729467699605

Epoch: 6| Step: 12
Training loss: 2.2366771697998047
Validation loss: 2.0130325363528345

Epoch: 6| Step: 13
Training loss: 1.89117431640625
Validation loss: 2.026795635941208

Epoch: 38| Step: 0
Training loss: 1.656984567642212
Validation loss: 2.030337146533433

Epoch: 6| Step: 1
Training loss: 2.6867785453796387
Validation loss: 2.030624715230798

Epoch: 6| Step: 2
Training loss: 1.7076878547668457
Validation loss: 2.023009500195903

Epoch: 6| Step: 3
Training loss: 2.608818531036377
Validation loss: 2.0259107697394585

Epoch: 6| Step: 4
Training loss: 2.686567783355713
Validation loss: 2.027394030683784

Epoch: 6| Step: 5
Training loss: 2.628087043762207
Validation loss: 2.038539230182607

Epoch: 6| Step: 6
Training loss: 2.413851737976074
Validation loss: 2.01383702985702

Epoch: 6| Step: 7
Training loss: 1.5235910415649414
Validation loss: 2.016625278739519

Epoch: 6| Step: 8
Training loss: 1.9744181632995605
Validation loss: 2.025043401666867

Epoch: 6| Step: 9
Training loss: 2.915839433670044
Validation loss: 2.02738719601785

Epoch: 6| Step: 10
Training loss: 2.674252510070801
Validation loss: 2.0255371165531937

Epoch: 6| Step: 11
Training loss: 3.1693010330200195
Validation loss: 2.000880073475581

Epoch: 6| Step: 12
Training loss: 2.6513712406158447
Validation loss: 2.0426026646808912

Epoch: 6| Step: 13
Training loss: 2.2162132263183594
Validation loss: 2.011728044479124

Epoch: 39| Step: 0
Training loss: 2.974834442138672
Validation loss: 2.0056627617087415

Epoch: 6| Step: 1
Training loss: 2.0300962924957275
Validation loss: 2.0058775255756993

Epoch: 6| Step: 2
Training loss: 2.7650861740112305
Validation loss: 2.004488786061605

Epoch: 6| Step: 3
Training loss: 2.781567335128784
Validation loss: 2.023220762129753

Epoch: 6| Step: 4
Training loss: 2.072305679321289
Validation loss: 2.015204459108332

Epoch: 6| Step: 5
Training loss: 2.1066677570343018
Validation loss: 2.0195744524719896

Epoch: 6| Step: 6
Training loss: 2.6467223167419434
Validation loss: 1.9975708633340814

Epoch: 6| Step: 7
Training loss: 2.2162187099456787
Validation loss: 2.016581377675456

Epoch: 6| Step: 8
Training loss: 2.271263837814331
Validation loss: 2.008707202890868

Epoch: 6| Step: 9
Training loss: 2.6879723072052
Validation loss: 2.0051186648748254

Epoch: 6| Step: 10
Training loss: 2.99870228767395
Validation loss: 2.0051690429769535

Epoch: 6| Step: 11
Training loss: 1.843158483505249
Validation loss: 2.0195752754006335

Epoch: 6| Step: 12
Training loss: 2.0609347820281982
Validation loss: 1.9999958827931394

Epoch: 6| Step: 13
Training loss: 2.198838233947754
Validation loss: 2.00175702956415

Epoch: 40| Step: 0
Training loss: 3.401099920272827
Validation loss: 2.0247480561656337

Epoch: 6| Step: 1
Training loss: 2.690279960632324
Validation loss: 2.0010814615475234

Epoch: 6| Step: 2
Training loss: 2.338629722595215
Validation loss: 2.0048887678371963

Epoch: 6| Step: 3
Training loss: 2.6106925010681152
Validation loss: 2.0336376287603892

Epoch: 6| Step: 4
Training loss: 2.1209421157836914
Validation loss: 2.0212422083782893

Epoch: 6| Step: 5
Training loss: 2.1473748683929443
Validation loss: 2.016758075324438

Epoch: 6| Step: 6
Training loss: 2.3471195697784424
Validation loss: 2.016806967796818

Epoch: 6| Step: 7
Training loss: 2.193195343017578
Validation loss: 2.020875738513085

Epoch: 6| Step: 8
Training loss: 1.9516711235046387
Validation loss: 2.010017369383125

Epoch: 6| Step: 9
Training loss: 1.628052830696106
Validation loss: 2.0201283347222114

Epoch: 6| Step: 10
Training loss: 2.8862061500549316
Validation loss: 2.0343655065823625

Epoch: 6| Step: 11
Training loss: 2.6732611656188965
Validation loss: 2.0404302099699616

Epoch: 6| Step: 12
Training loss: 2.080209970474243
Validation loss: 2.0319139829245945

Epoch: 6| Step: 13
Training loss: 2.3642704486846924
Validation loss: 2.0243404270500265

Epoch: 41| Step: 0
Training loss: 2.4744577407836914
Validation loss: 2.049431641896566

Epoch: 6| Step: 1
Training loss: 1.5201709270477295
Validation loss: 2.02110565862348

Epoch: 6| Step: 2
Training loss: 1.9800822734832764
Validation loss: 2.0192098784190353

Epoch: 6| Step: 3
Training loss: 2.526787757873535
Validation loss: 2.0173301696777344

Epoch: 6| Step: 4
Training loss: 3.431971549987793
Validation loss: 2.0261008047288462

Epoch: 6| Step: 5
Training loss: 2.0036978721618652
Validation loss: 2.0351447661717734

Epoch: 6| Step: 6
Training loss: 2.4374938011169434
Validation loss: 2.0330662163355018

Epoch: 6| Step: 7
Training loss: 2.751120090484619
Validation loss: 2.0449234413844284

Epoch: 6| Step: 8
Training loss: 2.5495002269744873
Validation loss: 2.0204844077428183

Epoch: 6| Step: 9
Training loss: 1.7693612575531006
Validation loss: 2.0447729838791715

Epoch: 6| Step: 10
Training loss: 2.4745607376098633
Validation loss: 2.012269784045476

Epoch: 6| Step: 11
Training loss: 2.1151180267333984
Validation loss: 2.0321119498181086

Epoch: 6| Step: 12
Training loss: 2.9160046577453613
Validation loss: 2.0401332250205417

Epoch: 6| Step: 13
Training loss: 3.1056292057037354
Validation loss: 2.0265233426965694

Epoch: 42| Step: 0
Training loss: 3.2443997859954834
Validation loss: 2.020737407028034

Epoch: 6| Step: 1
Training loss: 2.3936262130737305
Validation loss: 2.0185299970770396

Epoch: 6| Step: 2
Training loss: 2.0362441539764404
Validation loss: 2.004778274925806

Epoch: 6| Step: 3
Training loss: 2.2961411476135254
Validation loss: 2.0115680489488827

Epoch: 6| Step: 4
Training loss: 2.3025124073028564
Validation loss: 2.0402440960689256

Epoch: 6| Step: 5
Training loss: 2.2001006603240967
Validation loss: 2.048962909688232

Epoch: 6| Step: 6
Training loss: 2.1612343788146973
Validation loss: 2.0389387069209928

Epoch: 6| Step: 7
Training loss: 2.7850501537323
Validation loss: 2.02931732772499

Epoch: 6| Step: 8
Training loss: 1.9960144758224487
Validation loss: 2.039782540772551

Epoch: 6| Step: 9
Training loss: 2.564642906188965
Validation loss: 2.034576987707487

Epoch: 6| Step: 10
Training loss: 2.0689005851745605
Validation loss: 2.0062102797210857

Epoch: 6| Step: 11
Training loss: 2.5702202320098877
Validation loss: 2.0271143682541384

Epoch: 6| Step: 12
Training loss: 2.592536211013794
Validation loss: 2.030637450115655

Epoch: 6| Step: 13
Training loss: 2.319474458694458
Validation loss: 2.0454624135007142

Epoch: 43| Step: 0
Training loss: 2.4962575435638428
Validation loss: 2.03115798324667

Epoch: 6| Step: 1
Training loss: 2.166337728500366
Validation loss: 2.0240106839005665

Epoch: 6| Step: 2
Training loss: 2.493015766143799
Validation loss: 2.0259197642726283

Epoch: 6| Step: 3
Training loss: 2.3559622764587402
Validation loss: 2.022053098165861

Epoch: 6| Step: 4
Training loss: 2.770146131515503
Validation loss: 2.0261562767849175

Epoch: 6| Step: 5
Training loss: 2.430403709411621
Validation loss: 2.0192050754383044

Epoch: 6| Step: 6
Training loss: 2.3150973320007324
Validation loss: 2.038374199662157

Epoch: 6| Step: 7
Training loss: 2.0944466590881348
Validation loss: 2.0318533143689557

Epoch: 6| Step: 8
Training loss: 2.3670191764831543
Validation loss: 2.031854596189273

Epoch: 6| Step: 9
Training loss: 1.702408790588379
Validation loss: 2.0352209870533278

Epoch: 6| Step: 10
Training loss: 2.3409945964813232
Validation loss: 2.0031287977772374

Epoch: 6| Step: 11
Training loss: 2.3820409774780273
Validation loss: 2.017561371608447

Epoch: 6| Step: 12
Training loss: 3.175978660583496
Validation loss: 2.0256288128514446

Epoch: 6| Step: 13
Training loss: 2.28147029876709
Validation loss: 2.0287088758202008

Epoch: 44| Step: 0
Training loss: 2.6217360496520996
Validation loss: 2.0098719853226856

Epoch: 6| Step: 1
Training loss: 2.052872657775879
Validation loss: 2.009394566218058

Epoch: 6| Step: 2
Training loss: 2.644583225250244
Validation loss: 2.0236218744708645

Epoch: 6| Step: 3
Training loss: 2.76304030418396
Validation loss: 2.0130653560802503

Epoch: 6| Step: 4
Training loss: 2.388803005218506
Validation loss: 2.02333737445134

Epoch: 6| Step: 5
Training loss: 2.1916861534118652
Validation loss: 2.0270434451359574

Epoch: 6| Step: 6
Training loss: 2.015132427215576
Validation loss: 2.022866261902676

Epoch: 6| Step: 7
Training loss: 2.1693058013916016
Validation loss: 2.0249886307665097

Epoch: 6| Step: 8
Training loss: 2.3116307258605957
Validation loss: 2.009652251838356

Epoch: 6| Step: 9
Training loss: 2.828383207321167
Validation loss: 2.0166872368063977

Epoch: 6| Step: 10
Training loss: 2.2276692390441895
Validation loss: 2.023388913882676

Epoch: 6| Step: 11
Training loss: 2.033872604370117
Validation loss: 2.0266798721846713

Epoch: 6| Step: 12
Training loss: 2.0690970420837402
Validation loss: 2.010019379277383

Epoch: 6| Step: 13
Training loss: 3.6902830600738525
Validation loss: 2.008271163509738

Epoch: 45| Step: 0
Training loss: 2.4401769638061523
Validation loss: 2.005678915208386

Epoch: 6| Step: 1
Training loss: 1.742148518562317
Validation loss: 1.9997219988094863

Epoch: 6| Step: 2
Training loss: 2.4708621501922607
Validation loss: 1.9957025589481476

Epoch: 6| Step: 3
Training loss: 3.454698085784912
Validation loss: 2.0039619092018373

Epoch: 6| Step: 4
Training loss: 2.610513687133789
Validation loss: 2.01069502933051

Epoch: 6| Step: 5
Training loss: 2.6584858894348145
Validation loss: 2.0127955764852543

Epoch: 6| Step: 6
Training loss: 2.589843511581421
Validation loss: 2.0031082245611374

Epoch: 6| Step: 7
Training loss: 2.9597537517547607
Validation loss: 1.9993454666547879

Epoch: 6| Step: 8
Training loss: 1.5988138914108276
Validation loss: 2.010323304002003

Epoch: 6| Step: 9
Training loss: 2.1469147205352783
Validation loss: 2.010828969299152

Epoch: 6| Step: 10
Training loss: 1.9400237798690796
Validation loss: 1.9965772705693399

Epoch: 6| Step: 11
Training loss: 2.115694522857666
Validation loss: 2.006967641974008

Epoch: 6| Step: 12
Training loss: 2.424147129058838
Validation loss: 2.0128366562627975

Epoch: 6| Step: 13
Training loss: 1.953474521636963
Validation loss: 1.9960512127927554

Epoch: 46| Step: 0
Training loss: 2.6386122703552246
Validation loss: 2.0059541707397788

Epoch: 6| Step: 1
Training loss: 3.0214295387268066
Validation loss: 2.0226384811503912

Epoch: 6| Step: 2
Training loss: 1.8861076831817627
Validation loss: 2.004862258511205

Epoch: 6| Step: 3
Training loss: 2.2910940647125244
Validation loss: 2.017193312286049

Epoch: 6| Step: 4
Training loss: 2.9705989360809326
Validation loss: 2.0077979282666276

Epoch: 6| Step: 5
Training loss: 2.2061514854431152
Validation loss: 2.0148427230055614

Epoch: 6| Step: 6
Training loss: 2.018350124359131
Validation loss: 1.989796725652551

Epoch: 6| Step: 7
Training loss: 2.715210437774658
Validation loss: 2.0060790713115404

Epoch: 6| Step: 8
Training loss: 2.2799999713897705
Validation loss: 2.0084952051921556

Epoch: 6| Step: 9
Training loss: 2.296936273574829
Validation loss: 2.0042228570548435

Epoch: 6| Step: 10
Training loss: 2.2940216064453125
Validation loss: 2.000879333865258

Epoch: 6| Step: 11
Training loss: 1.9045841693878174
Validation loss: 2.0091272066998225

Epoch: 6| Step: 12
Training loss: 2.4432554244995117
Validation loss: 2.0212451463104575

Epoch: 6| Step: 13
Training loss: 2.3594369888305664
Validation loss: 2.0013782939603253

Epoch: 47| Step: 0
Training loss: 2.6677842140197754
Validation loss: 2.0037707769742577

Epoch: 6| Step: 1
Training loss: 1.7428816556930542
Validation loss: 1.9999542185055312

Epoch: 6| Step: 2
Training loss: 2.6137592792510986
Validation loss: 2.0017523650200135

Epoch: 6| Step: 3
Training loss: 1.924155831336975
Validation loss: 2.0062786968805457

Epoch: 6| Step: 4
Training loss: 2.650729179382324
Validation loss: 1.9988779521757556

Epoch: 6| Step: 5
Training loss: 2.6792895793914795
Validation loss: 1.9987737491566648

Epoch: 6| Step: 6
Training loss: 2.237947940826416
Validation loss: 2.009189232703178

Epoch: 6| Step: 7
Training loss: 2.294806957244873
Validation loss: 2.0027051664167836

Epoch: 6| Step: 8
Training loss: 2.2944836616516113
Validation loss: 1.9936611049918718

Epoch: 6| Step: 9
Training loss: 2.74249005317688
Validation loss: 1.9987308594488329

Epoch: 6| Step: 10
Training loss: 2.502513885498047
Validation loss: 2.02543039988446

Epoch: 6| Step: 11
Training loss: 2.1846656799316406
Validation loss: 1.9950986728873303

Epoch: 6| Step: 12
Training loss: 2.387047052383423
Validation loss: 2.0027109704991823

Epoch: 6| Step: 13
Training loss: 2.3162477016448975
Validation loss: 2.003596144337808

Epoch: 48| Step: 0
Training loss: 3.150528907775879
Validation loss: 2.007227543861635

Epoch: 6| Step: 1
Training loss: 1.6893935203552246
Validation loss: 2.004014843253679

Epoch: 6| Step: 2
Training loss: 2.922551155090332
Validation loss: 1.998668348917397

Epoch: 6| Step: 3
Training loss: 2.6513514518737793
Validation loss: 1.9982926102094754

Epoch: 6| Step: 4
Training loss: 1.8466168642044067
Validation loss: 1.9990349251736876

Epoch: 6| Step: 5
Training loss: 2.3558807373046875
Validation loss: 2.0109570103306926

Epoch: 6| Step: 6
Training loss: 2.7450966835021973
Validation loss: 2.008178234100342

Epoch: 6| Step: 7
Training loss: 2.252467393875122
Validation loss: 1.994115242394068

Epoch: 6| Step: 8
Training loss: 1.9292973279953003
Validation loss: 1.9958239063139884

Epoch: 6| Step: 9
Training loss: 2.0497632026672363
Validation loss: 2.0021788330488306

Epoch: 6| Step: 10
Training loss: 2.191932201385498
Validation loss: 2.0123087565104165

Epoch: 6| Step: 11
Training loss: 2.2371182441711426
Validation loss: 1.9960300409665672

Epoch: 6| Step: 12
Training loss: 1.9560080766677856
Validation loss: 2.0232790336813977

Epoch: 6| Step: 13
Training loss: 3.6985158920288086
Validation loss: 2.005678574244181

Epoch: 49| Step: 0
Training loss: 2.366041660308838
Validation loss: 2.0034415414256435

Epoch: 6| Step: 1
Training loss: 1.8977108001708984
Validation loss: 2.014448742712698

Epoch: 6| Step: 2
Training loss: 2.456784248352051
Validation loss: 2.0163112173798265

Epoch: 6| Step: 3
Training loss: 1.823838710784912
Validation loss: 1.976162149060157

Epoch: 6| Step: 4
Training loss: 2.2276721000671387
Validation loss: 1.9992192163262317

Epoch: 6| Step: 5
Training loss: 2.8961987495422363
Validation loss: 2.006899074841571

Epoch: 6| Step: 6
Training loss: 2.4240121841430664
Validation loss: 2.0031667678586897

Epoch: 6| Step: 7
Training loss: 2.3777718544006348
Validation loss: 2.004291880515314

Epoch: 6| Step: 8
Training loss: 1.8601940870285034
Validation loss: 2.017327864964803

Epoch: 6| Step: 9
Training loss: 2.485764265060425
Validation loss: 2.0175803784401185

Epoch: 6| Step: 10
Training loss: 3.1245484352111816
Validation loss: 1.9925880432128906

Epoch: 6| Step: 11
Training loss: 2.656892776489258
Validation loss: 2.009868359053007

Epoch: 6| Step: 12
Training loss: 2.4444828033447266
Validation loss: 2.0208492484143985

Epoch: 6| Step: 13
Training loss: 1.7769455909729004
Validation loss: 2.0091407042677685

Epoch: 50| Step: 0
Training loss: 2.2816877365112305
Validation loss: 1.9978790565203595

Epoch: 6| Step: 1
Training loss: 1.469012975692749
Validation loss: 2.00417136889632

Epoch: 6| Step: 2
Training loss: 2.715212345123291
Validation loss: 2.0103848493227394

Epoch: 6| Step: 3
Training loss: 2.1731820106506348
Validation loss: 1.984885787451139

Epoch: 6| Step: 4
Training loss: 2.3746912479400635
Validation loss: 1.988578692559273

Epoch: 6| Step: 5
Training loss: 2.429297924041748
Validation loss: 2.0000190927136328

Epoch: 6| Step: 6
Training loss: 2.622978925704956
Validation loss: 2.0150123796155377

Epoch: 6| Step: 7
Training loss: 2.3231468200683594
Validation loss: 2.000801811936081

Epoch: 6| Step: 8
Training loss: 2.000575542449951
Validation loss: 2.0019555348221973

Epoch: 6| Step: 9
Training loss: 2.8693456649780273
Validation loss: 1.9913192410622873

Epoch: 6| Step: 10
Training loss: 2.359013795852661
Validation loss: 1.9998904530720045

Epoch: 6| Step: 11
Training loss: 2.677945852279663
Validation loss: 1.9842031873682493

Epoch: 6| Step: 12
Training loss: 2.1179680824279785
Validation loss: 1.9857523672042354

Epoch: 6| Step: 13
Training loss: 2.974719762802124
Validation loss: 1.9826510926728607

Epoch: 51| Step: 0
Training loss: 1.8244212865829468
Validation loss: 1.983319435068356

Epoch: 6| Step: 1
Training loss: 2.4685192108154297
Validation loss: 1.9816829209686608

Epoch: 6| Step: 2
Training loss: 3.044231414794922
Validation loss: 1.984645511514397

Epoch: 6| Step: 3
Training loss: 2.0334200859069824
Validation loss: 1.9804984651586062

Epoch: 6| Step: 4
Training loss: 2.4970703125
Validation loss: 1.9911169057251306

Epoch: 6| Step: 5
Training loss: 2.375061273574829
Validation loss: 1.976907423747483

Epoch: 6| Step: 6
Training loss: 2.542222499847412
Validation loss: 1.9964787037141862

Epoch: 6| Step: 7
Training loss: 1.7464547157287598
Validation loss: 1.9825181499604256

Epoch: 6| Step: 8
Training loss: 1.825728178024292
Validation loss: 1.9933150968243998

Epoch: 6| Step: 9
Training loss: 2.340473175048828
Validation loss: 1.9707884403967089

Epoch: 6| Step: 10
Training loss: 2.5429797172546387
Validation loss: 1.9740072014511272

Epoch: 6| Step: 11
Training loss: 3.0436251163482666
Validation loss: 1.988195303947695

Epoch: 6| Step: 12
Training loss: 2.5099875926971436
Validation loss: 1.9811078066466956

Epoch: 6| Step: 13
Training loss: 2.0595333576202393
Validation loss: 1.9846705980198358

Epoch: 52| Step: 0
Training loss: 1.8531627655029297
Validation loss: 1.9915717378739388

Epoch: 6| Step: 1
Training loss: 2.4383018016815186
Validation loss: 1.9887851207487044

Epoch: 6| Step: 2
Training loss: 2.003880262374878
Validation loss: 1.9953387757783294

Epoch: 6| Step: 3
Training loss: 2.242225170135498
Validation loss: 1.9752920161011398

Epoch: 6| Step: 4
Training loss: 2.002925395965576
Validation loss: 2.001707979427871

Epoch: 6| Step: 5
Training loss: 2.44685959815979
Validation loss: 1.995854990456694

Epoch: 6| Step: 6
Training loss: 2.402141571044922
Validation loss: 1.9974796259275047

Epoch: 6| Step: 7
Training loss: 3.2531723976135254
Validation loss: 2.0095092353000434

Epoch: 6| Step: 8
Training loss: 2.696570873260498
Validation loss: 1.9937355928523566

Epoch: 6| Step: 9
Training loss: 2.3259048461914062
Validation loss: 2.005669768138598

Epoch: 6| Step: 10
Training loss: 2.1419565677642822
Validation loss: 2.005521538437054

Epoch: 6| Step: 11
Training loss: 2.3039283752441406
Validation loss: 2.009039217425931

Epoch: 6| Step: 12
Training loss: 2.404766082763672
Validation loss: 2.0256166714493946

Epoch: 6| Step: 13
Training loss: 2.4400246143341064
Validation loss: 1.9950736658547514

Epoch: 53| Step: 0
Training loss: 2.478024959564209
Validation loss: 1.995505686729185

Epoch: 6| Step: 1
Training loss: 2.488234043121338
Validation loss: 2.022491714005829

Epoch: 6| Step: 2
Training loss: 1.814074993133545
Validation loss: 2.0179540303445633

Epoch: 6| Step: 3
Training loss: 2.6659140586853027
Validation loss: 2.0027907202320714

Epoch: 6| Step: 4
Training loss: 1.646278977394104
Validation loss: 2.0262948133612193

Epoch: 6| Step: 5
Training loss: 2.8995330333709717
Validation loss: 2.017113095970564

Epoch: 6| Step: 6
Training loss: 2.2950830459594727
Validation loss: 2.0064582235069683

Epoch: 6| Step: 7
Training loss: 2.2349767684936523
Validation loss: 2.0052446960121073

Epoch: 6| Step: 8
Training loss: 2.7636656761169434
Validation loss: 2.037030320013723

Epoch: 6| Step: 9
Training loss: 1.2563029527664185
Validation loss: 2.00771080037599

Epoch: 6| Step: 10
Training loss: 3.1926941871643066
Validation loss: 2.0202250749834123

Epoch: 6| Step: 11
Training loss: 2.563817024230957
Validation loss: 2.010406671031829

Epoch: 6| Step: 12
Training loss: 2.829413414001465
Validation loss: 2.007382035255432

Epoch: 6| Step: 13
Training loss: 1.2499849796295166
Validation loss: 2.025496412349004

Epoch: 54| Step: 0
Training loss: 2.165661334991455
Validation loss: 2.006604741978389

Epoch: 6| Step: 1
Training loss: 2.666388988494873
Validation loss: 1.9972222902441537

Epoch: 6| Step: 2
Training loss: 2.3730435371398926
Validation loss: 2.013027891036003

Epoch: 6| Step: 3
Training loss: 2.1278762817382812
Validation loss: 1.995237837555588

Epoch: 6| Step: 4
Training loss: 2.399517297744751
Validation loss: 1.9995330623401109

Epoch: 6| Step: 5
Training loss: 2.4930500984191895
Validation loss: 2.016703405687886

Epoch: 6| Step: 6
Training loss: 1.576238751411438
Validation loss: 1.9909344950029928

Epoch: 6| Step: 7
Training loss: 2.419463872909546
Validation loss: 2.0064203995530323

Epoch: 6| Step: 8
Training loss: 2.901170253753662
Validation loss: 1.990523160144847

Epoch: 6| Step: 9
Training loss: 2.355567455291748
Validation loss: 2.0116264115097704

Epoch: 6| Step: 10
Training loss: 1.8315913677215576
Validation loss: 2.013602420847903

Epoch: 6| Step: 11
Training loss: 2.0362865924835205
Validation loss: 1.982727768600628

Epoch: 6| Step: 12
Training loss: 2.581160545349121
Validation loss: 2.0071175816238567

Epoch: 6| Step: 13
Training loss: 3.3932254314422607
Validation loss: 1.9981106737608552

Epoch: 55| Step: 0
Training loss: 2.406782388687134
Validation loss: 1.9888902402693225

Epoch: 6| Step: 1
Training loss: 2.74257755279541
Validation loss: 2.0058932740201234

Epoch: 6| Step: 2
Training loss: 2.3852550983428955
Validation loss: 2.001206659501599

Epoch: 6| Step: 3
Training loss: 2.2107176780700684
Validation loss: 1.9849630965981433

Epoch: 6| Step: 4
Training loss: 2.811005115509033
Validation loss: 1.997863987440704

Epoch: 6| Step: 5
Training loss: 1.981223225593567
Validation loss: 1.9825543818935272

Epoch: 6| Step: 6
Training loss: 2.4308412075042725
Validation loss: 1.9948691142502653

Epoch: 6| Step: 7
Training loss: 2.822650909423828
Validation loss: 1.9940378153195946

Epoch: 6| Step: 8
Training loss: 2.350351095199585
Validation loss: 1.9901843352984356

Epoch: 6| Step: 9
Training loss: 1.4209868907928467
Validation loss: 1.993991800533828

Epoch: 6| Step: 10
Training loss: 1.7303688526153564
Validation loss: 1.9799801893131708

Epoch: 6| Step: 11
Training loss: 2.4115562438964844
Validation loss: 1.9902575554386261

Epoch: 6| Step: 12
Training loss: 2.237574338912964
Validation loss: 1.9939611188827022

Epoch: 6| Step: 13
Training loss: 2.8552358150482178
Validation loss: 1.9907264376199374

Epoch: 56| Step: 0
Training loss: 1.9660816192626953
Validation loss: 1.9777583999018515

Epoch: 6| Step: 1
Training loss: 2.254146099090576
Validation loss: 1.9894789059956868

Epoch: 6| Step: 2
Training loss: 2.057705879211426
Validation loss: 1.9957816382890106

Epoch: 6| Step: 3
Training loss: 2.9873695373535156
Validation loss: 2.0001852691814466

Epoch: 6| Step: 4
Training loss: 2.509503126144409
Validation loss: 1.9757116392094602

Epoch: 6| Step: 5
Training loss: 2.1904444694519043
Validation loss: 1.9759847451281805

Epoch: 6| Step: 6
Training loss: 2.2588295936584473
Validation loss: 1.9758476749543221

Epoch: 6| Step: 7
Training loss: 2.532966375350952
Validation loss: 1.9832520715651973

Epoch: 6| Step: 8
Training loss: 1.7009012699127197
Validation loss: 1.9743316686281593

Epoch: 6| Step: 9
Training loss: 1.9177470207214355
Validation loss: 1.9809314486800984

Epoch: 6| Step: 10
Training loss: 2.059375286102295
Validation loss: 1.986791108244209

Epoch: 6| Step: 11
Training loss: 2.934718608856201
Validation loss: 1.969558943984329

Epoch: 6| Step: 12
Training loss: 2.708775520324707
Validation loss: 1.9710808518112346

Epoch: 6| Step: 13
Training loss: 2.7861196994781494
Validation loss: 1.9801621770346036

Epoch: 57| Step: 0
Training loss: 2.10477352142334
Validation loss: 1.9612955854785057

Epoch: 6| Step: 1
Training loss: 2.210512161254883
Validation loss: 1.9661099013461862

Epoch: 6| Step: 2
Training loss: 2.0839786529541016
Validation loss: 1.9618073509585472

Epoch: 6| Step: 3
Training loss: 3.067229986190796
Validation loss: 1.9767278061118176

Epoch: 6| Step: 4
Training loss: 2.457932472229004
Validation loss: 1.9809539882085656

Epoch: 6| Step: 5
Training loss: 2.100754737854004
Validation loss: 1.9587750409239082

Epoch: 6| Step: 6
Training loss: 3.102184534072876
Validation loss: 1.9651631873141053

Epoch: 6| Step: 7
Training loss: 2.066859245300293
Validation loss: 1.973417366704633

Epoch: 6| Step: 8
Training loss: 1.9794450998306274
Validation loss: 1.9728751233828965

Epoch: 6| Step: 9
Training loss: 2.0011515617370605
Validation loss: 1.980170694730615

Epoch: 6| Step: 10
Training loss: 1.6365721225738525
Validation loss: 1.9627300321414907

Epoch: 6| Step: 11
Training loss: 2.7971744537353516
Validation loss: 1.9634584124370287

Epoch: 6| Step: 12
Training loss: 2.7559194564819336
Validation loss: 1.9484100777615783

Epoch: 6| Step: 13
Training loss: 2.1432559490203857
Validation loss: 1.9697975445819158

Epoch: 58| Step: 0
Training loss: 2.729970932006836
Validation loss: 1.959024478030461

Epoch: 6| Step: 1
Training loss: 3.203413486480713
Validation loss: 1.948363124683339

Epoch: 6| Step: 2
Training loss: 2.5034661293029785
Validation loss: 1.9826554329164567

Epoch: 6| Step: 3
Training loss: 1.6416351795196533
Validation loss: 1.9836618208116101

Epoch: 6| Step: 4
Training loss: 2.802110433578491
Validation loss: 1.9682806563633743

Epoch: 6| Step: 5
Training loss: 3.037992000579834
Validation loss: 1.972721294690204

Epoch: 6| Step: 6
Training loss: 2.6627798080444336
Validation loss: 1.9750059368789836

Epoch: 6| Step: 7
Training loss: 1.7474157810211182
Validation loss: 1.9710412038269864

Epoch: 6| Step: 8
Training loss: 1.8647395372390747
Validation loss: 1.9765183079627253

Epoch: 6| Step: 9
Training loss: 2.169459581375122
Validation loss: 1.9623831959180935

Epoch: 6| Step: 10
Training loss: 2.043508768081665
Validation loss: 1.9834506909052532

Epoch: 6| Step: 11
Training loss: 2.3794708251953125
Validation loss: 1.9864102153367893

Epoch: 6| Step: 12
Training loss: 1.7716630697250366
Validation loss: 1.9831309651815763

Epoch: 6| Step: 13
Training loss: 1.587525725364685
Validation loss: 1.9928655521844023

Epoch: 59| Step: 0
Training loss: 2.767930507659912
Validation loss: 1.9784568394384077

Epoch: 6| Step: 1
Training loss: 2.59934663772583
Validation loss: 1.9854236520746702

Epoch: 6| Step: 2
Training loss: 2.1652793884277344
Validation loss: 1.960957400260433

Epoch: 6| Step: 3
Training loss: 2.1268367767333984
Validation loss: 1.9824725479208014

Epoch: 6| Step: 4
Training loss: 3.6435441970825195
Validation loss: 1.9761674096507411

Epoch: 6| Step: 5
Training loss: 2.9228615760803223
Validation loss: 1.9835261939674296

Epoch: 6| Step: 6
Training loss: 2.275298595428467
Validation loss: 1.9745009509466027

Epoch: 6| Step: 7
Training loss: 2.1609246730804443
Validation loss: 1.9719460548893097

Epoch: 6| Step: 8
Training loss: 1.7109782695770264
Validation loss: 1.984792294040803

Epoch: 6| Step: 9
Training loss: 1.8344037532806396
Validation loss: 1.9792859374835927

Epoch: 6| Step: 10
Training loss: 1.8604567050933838
Validation loss: 1.9844116190428376

Epoch: 6| Step: 11
Training loss: 2.398736000061035
Validation loss: 1.9883026922902753

Epoch: 6| Step: 12
Training loss: 1.7348672151565552
Validation loss: 1.9917377823142595

Epoch: 6| Step: 13
Training loss: 2.3840482234954834
Validation loss: 1.9928611965589627

Epoch: 60| Step: 0
Training loss: 1.9655520915985107
Validation loss: 1.9958905443068473

Epoch: 6| Step: 1
Training loss: 2.650820016860962
Validation loss: 1.9924701106163762

Epoch: 6| Step: 2
Training loss: 2.4486148357391357
Validation loss: 1.9965586572565057

Epoch: 6| Step: 3
Training loss: 2.150851011276245
Validation loss: 1.9986959336906351

Epoch: 6| Step: 4
Training loss: 2.1223678588867188
Validation loss: 1.9876349331230245

Epoch: 6| Step: 5
Training loss: 2.3834545612335205
Validation loss: 1.9824653210178498

Epoch: 6| Step: 6
Training loss: 2.500393867492676
Validation loss: 1.997885629694949

Epoch: 6| Step: 7
Training loss: 2.076241970062256
Validation loss: 1.974452475065826

Epoch: 6| Step: 8
Training loss: 2.752187728881836
Validation loss: 1.9658511146422355

Epoch: 6| Step: 9
Training loss: 2.134862184524536
Validation loss: 1.9664269903654694

Epoch: 6| Step: 10
Training loss: 2.774268388748169
Validation loss: 1.9847980519776702

Epoch: 6| Step: 11
Training loss: 2.12691593170166
Validation loss: 1.9756475058935021

Epoch: 6| Step: 12
Training loss: 2.006171226501465
Validation loss: 1.9739218014542774

Epoch: 6| Step: 13
Training loss: 2.2642180919647217
Validation loss: 1.9721556825022544

Epoch: 61| Step: 0
Training loss: 2.6219029426574707
Validation loss: 1.971015981448594

Epoch: 6| Step: 1
Training loss: 2.2689356803894043
Validation loss: 1.9961720384577268

Epoch: 6| Step: 2
Training loss: 2.4553802013397217
Validation loss: 2.007164251419806

Epoch: 6| Step: 3
Training loss: 1.838104248046875
Validation loss: 2.006881256257334

Epoch: 6| Step: 4
Training loss: 2.6332831382751465
Validation loss: 1.9978114456258795

Epoch: 6| Step: 5
Training loss: 2.4039199352264404
Validation loss: 2.013793806875906

Epoch: 6| Step: 6
Training loss: 2.174531936645508
Validation loss: 1.9835145063297723

Epoch: 6| Step: 7
Training loss: 3.2553048133850098
Validation loss: 1.9784712124896306

Epoch: 6| Step: 8
Training loss: 2.3075735569000244
Validation loss: 2.0100567469032864

Epoch: 6| Step: 9
Training loss: 1.9363467693328857
Validation loss: 2.0093007395344396

Epoch: 6| Step: 10
Training loss: 2.1999495029449463
Validation loss: 1.9877494817139

Epoch: 6| Step: 11
Training loss: 2.358372449874878
Validation loss: 2.0178971034224316

Epoch: 6| Step: 12
Training loss: 2.3151118755340576
Validation loss: 2.002749862209443

Epoch: 6| Step: 13
Training loss: 1.0778024196624756
Validation loss: 1.9901652143847557

Epoch: 62| Step: 0
Training loss: 2.293564796447754
Validation loss: 2.0204906296986405

Epoch: 6| Step: 1
Training loss: 2.6139273643493652
Validation loss: 1.9948363765593498

Epoch: 6| Step: 2
Training loss: 2.0124378204345703
Validation loss: 2.0070285130572576

Epoch: 6| Step: 3
Training loss: 2.622999429702759
Validation loss: 1.9856760040406258

Epoch: 6| Step: 4
Training loss: 1.8353874683380127
Validation loss: 1.9908914181493944

Epoch: 6| Step: 5
Training loss: 2.55694580078125
Validation loss: 2.0024281842734224

Epoch: 6| Step: 6
Training loss: 2.5661699771881104
Validation loss: 1.987216168834317

Epoch: 6| Step: 7
Training loss: 2.4591400623321533
Validation loss: 2.000190919445407

Epoch: 6| Step: 8
Training loss: 2.240936279296875
Validation loss: 2.003224410036559

Epoch: 6| Step: 9
Training loss: 2.122528076171875
Validation loss: 1.9782997638948503

Epoch: 6| Step: 10
Training loss: 2.584075689315796
Validation loss: 1.9705401787193872

Epoch: 6| Step: 11
Training loss: 1.9366194009780884
Validation loss: 1.9906055299184655

Epoch: 6| Step: 12
Training loss: 2.3420846462249756
Validation loss: 1.987342305080865

Epoch: 6| Step: 13
Training loss: 1.8591257333755493
Validation loss: 1.9875708382616761

Epoch: 63| Step: 0
Training loss: 2.2138147354125977
Validation loss: 1.9791764931012226

Epoch: 6| Step: 1
Training loss: 2.2827579975128174
Validation loss: 1.9955715158934235

Epoch: 6| Step: 2
Training loss: 1.8055219650268555
Validation loss: 1.988424406256727

Epoch: 6| Step: 3
Training loss: 2.6541528701782227
Validation loss: 1.969533146068614

Epoch: 6| Step: 4
Training loss: 1.93031907081604
Validation loss: 1.9844887487349971

Epoch: 6| Step: 5
Training loss: 2.4871294498443604
Validation loss: 1.9737245164891726

Epoch: 6| Step: 6
Training loss: 2.311112880706787
Validation loss: 1.9885998848945863

Epoch: 6| Step: 7
Training loss: 2.4616894721984863
Validation loss: 1.9913888285236974

Epoch: 6| Step: 8
Training loss: 3.0081136226654053
Validation loss: 1.9977377794122184

Epoch: 6| Step: 9
Training loss: 2.7534899711608887
Validation loss: 1.9936272956991707

Epoch: 6| Step: 10
Training loss: 1.7609457969665527
Validation loss: 2.011390716798844

Epoch: 6| Step: 11
Training loss: 2.119701862335205
Validation loss: 1.9786357418183358

Epoch: 6| Step: 12
Training loss: 2.3310813903808594
Validation loss: 1.9760732984030118

Epoch: 6| Step: 13
Training loss: 1.8296599388122559
Validation loss: 1.984853954725368

Epoch: 64| Step: 0
Training loss: 2.930908679962158
Validation loss: 1.9826920135046846

Epoch: 6| Step: 1
Training loss: 2.2403244972229004
Validation loss: 1.9811081732473066

Epoch: 6| Step: 2
Training loss: 1.9252078533172607
Validation loss: 1.971487993835121

Epoch: 6| Step: 3
Training loss: 2.0510597229003906
Validation loss: 1.9792174857149842

Epoch: 6| Step: 4
Training loss: 2.594799757003784
Validation loss: 1.9765339282251173

Epoch: 6| Step: 5
Training loss: 2.343441963195801
Validation loss: 1.9734536268377816

Epoch: 6| Step: 6
Training loss: 2.4891152381896973
Validation loss: 1.9759231587891937

Epoch: 6| Step: 7
Training loss: 2.1224241256713867
Validation loss: 1.9690626077754523

Epoch: 6| Step: 8
Training loss: 1.9920144081115723
Validation loss: 1.9716932042952506

Epoch: 6| Step: 9
Training loss: 2.373522996902466
Validation loss: 1.984044082703129

Epoch: 6| Step: 10
Training loss: 2.1710658073425293
Validation loss: 1.974591378242739

Epoch: 6| Step: 11
Training loss: 2.4056363105773926
Validation loss: 1.9881088349127

Epoch: 6| Step: 12
Training loss: 1.9180214405059814
Validation loss: 1.948865444429459

Epoch: 6| Step: 13
Training loss: 2.750178337097168
Validation loss: 1.9690106081706222

Epoch: 65| Step: 0
Training loss: 2.277695655822754
Validation loss: 1.9586334305424844

Epoch: 6| Step: 1
Training loss: 2.6099720001220703
Validation loss: 1.9634243531893658

Epoch: 6| Step: 2
Training loss: 2.3504598140716553
Validation loss: 1.9480268468138993

Epoch: 6| Step: 3
Training loss: 1.857029914855957
Validation loss: 1.9780279590237526

Epoch: 6| Step: 4
Training loss: 1.5216584205627441
Validation loss: 1.9811535855775237

Epoch: 6| Step: 5
Training loss: 1.6591328382492065
Validation loss: 1.95946700854968

Epoch: 6| Step: 6
Training loss: 2.6983139514923096
Validation loss: 1.9669228766554145

Epoch: 6| Step: 7
Training loss: 1.8468890190124512
Validation loss: 1.9696899844754128

Epoch: 6| Step: 8
Training loss: 2.9462335109710693
Validation loss: 1.9634567127432874

Epoch: 6| Step: 9
Training loss: 2.376197338104248
Validation loss: 1.972663342311818

Epoch: 6| Step: 10
Training loss: 2.7622671127319336
Validation loss: 1.9625933875319779

Epoch: 6| Step: 11
Training loss: 2.337982654571533
Validation loss: 1.9726334310347033

Epoch: 6| Step: 12
Training loss: 2.7306556701660156
Validation loss: 1.9535706684153566

Epoch: 6| Step: 13
Training loss: 1.8320952653884888
Validation loss: 1.9555402289154709

Epoch: 66| Step: 0
Training loss: 2.0005993843078613
Validation loss: 1.9678992007368354

Epoch: 6| Step: 1
Training loss: 2.7017621994018555
Validation loss: 1.9745810954801497

Epoch: 6| Step: 2
Training loss: 2.601484775543213
Validation loss: 1.9660936068463069

Epoch: 6| Step: 3
Training loss: 2.1401121616363525
Validation loss: 1.9784970232235488

Epoch: 6| Step: 4
Training loss: 2.5123796463012695
Validation loss: 1.954088487932759

Epoch: 6| Step: 5
Training loss: 2.4417810440063477
Validation loss: 1.9595788012268722

Epoch: 6| Step: 6
Training loss: 2.078918933868408
Validation loss: 1.9611984516984673

Epoch: 6| Step: 7
Training loss: 2.4025156497955322
Validation loss: 1.9643305078629525

Epoch: 6| Step: 8
Training loss: 1.8651554584503174
Validation loss: 1.9705857115407144

Epoch: 6| Step: 9
Training loss: 2.7949161529541016
Validation loss: 1.9649483209015222

Epoch: 6| Step: 10
Training loss: 1.7334418296813965
Validation loss: 1.9625990416413994

Epoch: 6| Step: 11
Training loss: 1.990149974822998
Validation loss: 1.9495534922486992

Epoch: 6| Step: 12
Training loss: 2.48355770111084
Validation loss: 1.959369646605625

Epoch: 6| Step: 13
Training loss: 2.497756004333496
Validation loss: 1.9709651662457375

Epoch: 67| Step: 0
Training loss: 2.3590855598449707
Validation loss: 1.954222627865371

Epoch: 6| Step: 1
Training loss: 1.6322790384292603
Validation loss: 1.9595473081834855

Epoch: 6| Step: 2
Training loss: 1.9256486892700195
Validation loss: 1.9760898684942594

Epoch: 6| Step: 3
Training loss: 1.9800502061843872
Validation loss: 1.9716225439502346

Epoch: 6| Step: 4
Training loss: 2.146188497543335
Validation loss: 1.9645622148308703

Epoch: 6| Step: 5
Training loss: 2.984388828277588
Validation loss: 1.9728939533233643

Epoch: 6| Step: 6
Training loss: 1.7842189073562622
Validation loss: 1.9666579077320714

Epoch: 6| Step: 7
Training loss: 2.8687195777893066
Validation loss: 1.9412358268614738

Epoch: 6| Step: 8
Training loss: 2.023226737976074
Validation loss: 1.960850813055551

Epoch: 6| Step: 9
Training loss: 2.988494396209717
Validation loss: 1.9795759800941712

Epoch: 6| Step: 10
Training loss: 2.3365273475646973
Validation loss: 1.9738831366262128

Epoch: 6| Step: 11
Training loss: 1.9309546947479248
Validation loss: 1.9831899648071618

Epoch: 6| Step: 12
Training loss: 2.738696575164795
Validation loss: 1.9765107221500848

Epoch: 6| Step: 13
Training loss: 2.503565788269043
Validation loss: 1.9727788458588302

Epoch: 68| Step: 0
Training loss: 2.6366920471191406
Validation loss: 1.9477938823802496

Epoch: 6| Step: 1
Training loss: 3.135619640350342
Validation loss: 1.9329238258382326

Epoch: 6| Step: 2
Training loss: 2.3518500328063965
Validation loss: 1.9581298417942499

Epoch: 6| Step: 3
Training loss: 2.2462713718414307
Validation loss: 1.9317189672941804

Epoch: 6| Step: 4
Training loss: 1.5012139081954956
Validation loss: 1.953262508556407

Epoch: 6| Step: 5
Training loss: 2.508425712585449
Validation loss: 1.9616605158775084

Epoch: 6| Step: 6
Training loss: 2.192970037460327
Validation loss: 1.9611059850262058

Epoch: 6| Step: 7
Training loss: 2.0850448608398438
Validation loss: 1.963291819377612

Epoch: 6| Step: 8
Training loss: 2.0692124366760254
Validation loss: 1.9616982219039754

Epoch: 6| Step: 9
Training loss: 2.2489376068115234
Validation loss: 1.9439322294727448

Epoch: 6| Step: 10
Training loss: 2.1723556518554688
Validation loss: 1.9652997280961724

Epoch: 6| Step: 11
Training loss: 1.7904716730117798
Validation loss: 1.9551996159297165

Epoch: 6| Step: 12
Training loss: 2.864041328430176
Validation loss: 1.9440547266314108

Epoch: 6| Step: 13
Training loss: 2.1766085624694824
Validation loss: 1.9491501418493127

Epoch: 69| Step: 0
Training loss: 1.8810293674468994
Validation loss: 1.9474655864059285

Epoch: 6| Step: 1
Training loss: 2.7385826110839844
Validation loss: 1.9452803698919152

Epoch: 6| Step: 2
Training loss: 2.2083370685577393
Validation loss: 1.9529428135964177

Epoch: 6| Step: 3
Training loss: 3.2081897258758545
Validation loss: 1.958371816142913

Epoch: 6| Step: 4
Training loss: 2.3755509853363037
Validation loss: 1.97880764930479

Epoch: 6| Step: 5
Training loss: 2.211432456970215
Validation loss: 1.9605010696636733

Epoch: 6| Step: 6
Training loss: 2.3411216735839844
Validation loss: 1.9587230887464298

Epoch: 6| Step: 7
Training loss: 2.347452163696289
Validation loss: 1.9429970210598362

Epoch: 6| Step: 8
Training loss: 2.7237439155578613
Validation loss: 1.9493112922996603

Epoch: 6| Step: 9
Training loss: 1.6920607089996338
Validation loss: 1.9535911993313861

Epoch: 6| Step: 10
Training loss: 2.1279006004333496
Validation loss: 1.9503209796003116

Epoch: 6| Step: 11
Training loss: 2.4193954467773438
Validation loss: 1.959325849369008

Epoch: 6| Step: 12
Training loss: 1.8334532976150513
Validation loss: 1.9603674924501808

Epoch: 6| Step: 13
Training loss: 1.827575922012329
Validation loss: 1.9506833502041396

Epoch: 70| Step: 0
Training loss: 2.6734118461608887
Validation loss: 1.9367619611883675

Epoch: 6| Step: 1
Training loss: 1.9514312744140625
Validation loss: 1.9569132199851416

Epoch: 6| Step: 2
Training loss: 2.745789051055908
Validation loss: 1.9560775910654375

Epoch: 6| Step: 3
Training loss: 2.7870335578918457
Validation loss: 1.9583850150467248

Epoch: 6| Step: 4
Training loss: 2.378570079803467
Validation loss: 1.9527081674145115

Epoch: 6| Step: 5
Training loss: 1.9909031391143799
Validation loss: 1.9258258406833937

Epoch: 6| Step: 6
Training loss: 2.5380468368530273
Validation loss: 1.947604815165202

Epoch: 6| Step: 7
Training loss: 2.5155091285705566
Validation loss: 1.9720426246684084

Epoch: 6| Step: 8
Training loss: 1.4765589237213135
Validation loss: 1.954048123410953

Epoch: 6| Step: 9
Training loss: 2.656189441680908
Validation loss: 1.9474972178859096

Epoch: 6| Step: 10
Training loss: 1.9286830425262451
Validation loss: 1.9207160370324248

Epoch: 6| Step: 11
Training loss: 2.323958396911621
Validation loss: 1.938466659156225

Epoch: 6| Step: 12
Training loss: 2.1849546432495117
Validation loss: 1.94954082914578

Epoch: 6| Step: 13
Training loss: 1.473339557647705
Validation loss: 1.9527716329020839

Epoch: 71| Step: 0
Training loss: 2.52199125289917
Validation loss: 1.948324353464188

Epoch: 6| Step: 1
Training loss: 2.6538729667663574
Validation loss: 1.9511295236567014

Epoch: 6| Step: 2
Training loss: 2.276583433151245
Validation loss: 1.9562529594667497

Epoch: 6| Step: 3
Training loss: 2.101961374282837
Validation loss: 1.944774422594296

Epoch: 6| Step: 4
Training loss: 1.8195576667785645
Validation loss: 1.9471598927692702

Epoch: 6| Step: 5
Training loss: 2.0558159351348877
Validation loss: 1.9612964404526578

Epoch: 6| Step: 6
Training loss: 2.028317451477051
Validation loss: 1.9370188213163806

Epoch: 6| Step: 7
Training loss: 1.9004765748977661
Validation loss: 1.9437494457408946

Epoch: 6| Step: 8
Training loss: 2.7578725814819336
Validation loss: 1.9487213691075642

Epoch: 6| Step: 9
Training loss: 2.2404332160949707
Validation loss: 1.960600983711981

Epoch: 6| Step: 10
Training loss: 2.3232192993164062
Validation loss: 1.960404957494428

Epoch: 6| Step: 11
Training loss: 1.942081093788147
Validation loss: 1.9757391188734321

Epoch: 6| Step: 12
Training loss: 2.3463425636291504
Validation loss: 1.9826381385967295

Epoch: 6| Step: 13
Training loss: 3.037867546081543
Validation loss: 1.9541880533259401

Epoch: 72| Step: 0
Training loss: 1.8143525123596191
Validation loss: 1.9536833417031072

Epoch: 6| Step: 1
Training loss: 3.11624813079834
Validation loss: 1.9593361552043627

Epoch: 6| Step: 2
Training loss: 2.306469202041626
Validation loss: 1.9499502887008011

Epoch: 6| Step: 3
Training loss: 2.1253297328948975
Validation loss: 1.9502573192760508

Epoch: 6| Step: 4
Training loss: 2.756418228149414
Validation loss: 1.948042279930525

Epoch: 6| Step: 5
Training loss: 2.0415380001068115
Validation loss: 1.9659961308202436

Epoch: 6| Step: 6
Training loss: 2.6917028427124023
Validation loss: 1.9610036688466226

Epoch: 6| Step: 7
Training loss: 2.1001458168029785
Validation loss: 1.932021492271013

Epoch: 6| Step: 8
Training loss: 1.755875825881958
Validation loss: 1.9447673238733763

Epoch: 6| Step: 9
Training loss: 1.6489629745483398
Validation loss: 1.9455749732191845

Epoch: 6| Step: 10
Training loss: 2.527597665786743
Validation loss: 1.9550131995190856

Epoch: 6| Step: 11
Training loss: 2.9088668823242188
Validation loss: 1.953308472069361

Epoch: 6| Step: 12
Training loss: 1.8456251621246338
Validation loss: 1.9575932769365207

Epoch: 6| Step: 13
Training loss: 2.1069560050964355
Validation loss: 1.9523699488691104

Epoch: 73| Step: 0
Training loss: 1.6726491451263428
Validation loss: 1.9559099264042352

Epoch: 6| Step: 1
Training loss: 2.7295138835906982
Validation loss: 1.9519668868792954

Epoch: 6| Step: 2
Training loss: 2.845839500427246
Validation loss: 1.9403239847511373

Epoch: 6| Step: 3
Training loss: 1.6212022304534912
Validation loss: 1.969891486629363

Epoch: 6| Step: 4
Training loss: 1.6453238725662231
Validation loss: 1.9676730889146046

Epoch: 6| Step: 5
Training loss: 2.153369188308716
Validation loss: 1.9464799204180319

Epoch: 6| Step: 6
Training loss: 2.229620933532715
Validation loss: 1.9422274866411764

Epoch: 6| Step: 7
Training loss: 2.7719621658325195
Validation loss: 1.9470250375809208

Epoch: 6| Step: 8
Training loss: 2.3855795860290527
Validation loss: 1.9512548203109412

Epoch: 6| Step: 9
Training loss: 1.7860138416290283
Validation loss: 1.9421028347425564

Epoch: 6| Step: 10
Training loss: 2.231877565383911
Validation loss: 1.9494064213127218

Epoch: 6| Step: 11
Training loss: 2.413546085357666
Validation loss: 1.9228196426104474

Epoch: 6| Step: 12
Training loss: 2.5492894649505615
Validation loss: 1.9394328683935187

Epoch: 6| Step: 13
Training loss: 3.206873655319214
Validation loss: 1.9485521380619337

Epoch: 74| Step: 0
Training loss: 2.6058263778686523
Validation loss: 1.9754351133941321

Epoch: 6| Step: 1
Training loss: 1.8374806642532349
Validation loss: 1.9497278851847495

Epoch: 6| Step: 2
Training loss: 1.9168578386306763
Validation loss: 1.9517284465092484

Epoch: 6| Step: 3
Training loss: 2.1613245010375977
Validation loss: 1.952164473072175

Epoch: 6| Step: 4
Training loss: 2.2863998413085938
Validation loss: 1.9688045478636218

Epoch: 6| Step: 5
Training loss: 2.0747880935668945
Validation loss: 1.9715150197347004

Epoch: 6| Step: 6
Training loss: 2.7474067211151123
Validation loss: 1.9503460520057267

Epoch: 6| Step: 7
Training loss: 2.612403154373169
Validation loss: 1.9692063549513459

Epoch: 6| Step: 8
Training loss: 2.1118109226226807
Validation loss: 1.9549801541912941

Epoch: 6| Step: 9
Training loss: 2.5703177452087402
Validation loss: 1.9785337268665273

Epoch: 6| Step: 10
Training loss: 2.6908740997314453
Validation loss: 1.9521772092388523

Epoch: 6| Step: 11
Training loss: 2.0312485694885254
Validation loss: 1.9687571230755057

Epoch: 6| Step: 12
Training loss: 2.094784736633301
Validation loss: 1.9802838756192116

Epoch: 6| Step: 13
Training loss: 1.6797648668289185
Validation loss: 1.9706057502377419

Epoch: 75| Step: 0
Training loss: 1.706526756286621
Validation loss: 1.962318317864531

Epoch: 6| Step: 1
Training loss: 2.303955316543579
Validation loss: 1.9705010934542584

Epoch: 6| Step: 2
Training loss: 2.4673519134521484
Validation loss: 1.9546994547690115

Epoch: 6| Step: 3
Training loss: 2.1588616371154785
Validation loss: 1.9665911889845324

Epoch: 6| Step: 4
Training loss: 1.706899881362915
Validation loss: 1.9644833367357972

Epoch: 6| Step: 5
Training loss: 2.4090166091918945
Validation loss: 1.9754492044448853

Epoch: 6| Step: 6
Training loss: 2.0466232299804688
Validation loss: 1.9636879326194845

Epoch: 6| Step: 7
Training loss: 2.529099464416504
Validation loss: 1.9535971585140433

Epoch: 6| Step: 8
Training loss: 1.918571949005127
Validation loss: 1.9635274910157727

Epoch: 6| Step: 9
Training loss: 2.858644723892212
Validation loss: 1.958023178961969

Epoch: 6| Step: 10
Training loss: 2.7337875366210938
Validation loss: 1.931059423313346

Epoch: 6| Step: 11
Training loss: 1.373337745666504
Validation loss: 1.9578229047918831

Epoch: 6| Step: 12
Training loss: 3.1433563232421875
Validation loss: 1.9604954232451737

Epoch: 6| Step: 13
Training loss: 2.3140993118286133
Validation loss: 1.9676278880847398

Epoch: 76| Step: 0
Training loss: 2.438563346862793
Validation loss: 1.969518671753586

Epoch: 6| Step: 1
Training loss: 2.7297823429107666
Validation loss: 1.9564073188330537

Epoch: 6| Step: 2
Training loss: 1.9139260053634644
Validation loss: 1.9563142522688834

Epoch: 6| Step: 3
Training loss: 1.8802012205123901
Validation loss: 1.962402351440922

Epoch: 6| Step: 4
Training loss: 1.8431763648986816
Validation loss: 1.9791058519835114

Epoch: 6| Step: 5
Training loss: 2.6247127056121826
Validation loss: 1.9460928132457118

Epoch: 6| Step: 6
Training loss: 2.674083948135376
Validation loss: 1.9454797865242086

Epoch: 6| Step: 7
Training loss: 2.452369213104248
Validation loss: 1.9615933382382957

Epoch: 6| Step: 8
Training loss: 2.4416627883911133
Validation loss: 1.959769110525808

Epoch: 6| Step: 9
Training loss: 1.6210649013519287
Validation loss: 1.956502777273937

Epoch: 6| Step: 10
Training loss: 2.7049224376678467
Validation loss: 1.9627127980673185

Epoch: 6| Step: 11
Training loss: 1.8923230171203613
Validation loss: 1.9595750019114504

Epoch: 6| Step: 12
Training loss: 2.1370253562927246
Validation loss: 1.9698472715193225

Epoch: 6| Step: 13
Training loss: 2.148730516433716
Validation loss: 1.9681071978743359

Epoch: 77| Step: 0
Training loss: 2.1058216094970703
Validation loss: 1.9650751698401667

Epoch: 6| Step: 1
Training loss: 2.02047061920166
Validation loss: 1.96219398513917

Epoch: 6| Step: 2
Training loss: 2.315784215927124
Validation loss: 1.9658489765659455

Epoch: 6| Step: 3
Training loss: 2.5977325439453125
Validation loss: 1.991197939841978

Epoch: 6| Step: 4
Training loss: 2.325591564178467
Validation loss: 1.95899139424806

Epoch: 6| Step: 5
Training loss: 2.848284959793091
Validation loss: 1.9667506987048733

Epoch: 6| Step: 6
Training loss: 1.9141572713851929
Validation loss: 1.9593173137275122

Epoch: 6| Step: 7
Training loss: 2.9501609802246094
Validation loss: 1.9656399834540583

Epoch: 6| Step: 8
Training loss: 1.7353177070617676
Validation loss: 1.9948116630636237

Epoch: 6| Step: 9
Training loss: 1.6535699367523193
Validation loss: 1.962109145297799

Epoch: 6| Step: 10
Training loss: 2.174834728240967
Validation loss: 1.9686089202921877

Epoch: 6| Step: 11
Training loss: 1.5995712280273438
Validation loss: 1.9649336927680559

Epoch: 6| Step: 12
Training loss: 2.6707935333251953
Validation loss: 1.970922472656414

Epoch: 6| Step: 13
Training loss: 2.9348220825195312
Validation loss: 1.9524325683552732

Epoch: 78| Step: 0
Training loss: 1.5437872409820557
Validation loss: 1.9409610033035278

Epoch: 6| Step: 1
Training loss: 2.444305896759033
Validation loss: 1.9772113189902356

Epoch: 6| Step: 2
Training loss: 2.419713020324707
Validation loss: 1.9289763640331965

Epoch: 6| Step: 3
Training loss: 2.3879716396331787
Validation loss: 1.9820066933990808

Epoch: 6| Step: 4
Training loss: 1.8793981075286865
Validation loss: 1.9732599104604414

Epoch: 6| Step: 5
Training loss: 2.0751404762268066
Validation loss: 1.9539796485695788

Epoch: 6| Step: 6
Training loss: 2.2727718353271484
Validation loss: 1.9436140291152462

Epoch: 6| Step: 7
Training loss: 2.5400214195251465
Validation loss: 1.9611272837526055

Epoch: 6| Step: 8
Training loss: 2.659381866455078
Validation loss: 1.9655855291633195

Epoch: 6| Step: 9
Training loss: 2.333015203475952
Validation loss: 1.9793099434145036

Epoch: 6| Step: 10
Training loss: 2.271979331970215
Validation loss: 1.9550276622977307

Epoch: 6| Step: 11
Training loss: 2.3342504501342773
Validation loss: 1.9669762144806564

Epoch: 6| Step: 12
Training loss: 1.890274167060852
Validation loss: 1.9693579904494747

Epoch: 6| Step: 13
Training loss: 2.4979095458984375
Validation loss: 1.9696085312033211

Epoch: 79| Step: 0
Training loss: 2.03232741355896
Validation loss: 1.9915166080638926

Epoch: 6| Step: 1
Training loss: 1.9369001388549805
Validation loss: 1.9800946353584208

Epoch: 6| Step: 2
Training loss: 1.7386186122894287
Validation loss: 2.003975442660752

Epoch: 6| Step: 3
Training loss: 2.690260648727417
Validation loss: 1.9627919209900724

Epoch: 6| Step: 4
Training loss: 2.482138156890869
Validation loss: 1.9847501606069586

Epoch: 6| Step: 5
Training loss: 2.2767624855041504
Validation loss: 1.987545536410424

Epoch: 6| Step: 6
Training loss: 2.082798480987549
Validation loss: 1.9651902491046536

Epoch: 6| Step: 7
Training loss: 1.938452124595642
Validation loss: 1.9967345653041717

Epoch: 6| Step: 8
Training loss: 2.311779022216797
Validation loss: 1.970509736768661

Epoch: 6| Step: 9
Training loss: 2.186300277709961
Validation loss: 1.974222170409336

Epoch: 6| Step: 10
Training loss: 2.9384217262268066
Validation loss: 1.982439676920573

Epoch: 6| Step: 11
Training loss: 2.2273082733154297
Validation loss: 1.9760878586000012

Epoch: 6| Step: 12
Training loss: 2.4234628677368164
Validation loss: 1.9585394038948962

Epoch: 6| Step: 13
Training loss: 2.206564426422119
Validation loss: 1.960160651514607

Epoch: 80| Step: 0
Training loss: 1.983805775642395
Validation loss: 1.9618896668957126

Epoch: 6| Step: 1
Training loss: 1.98740816116333
Validation loss: 1.9577829196888914

Epoch: 6| Step: 2
Training loss: 2.925231456756592
Validation loss: 1.9491999623596028

Epoch: 6| Step: 3
Training loss: 2.008331060409546
Validation loss: 1.96148834946335

Epoch: 6| Step: 4
Training loss: 2.415158271789551
Validation loss: 1.9547349881100398

Epoch: 6| Step: 5
Training loss: 2.511929512023926
Validation loss: 1.9578156573798067

Epoch: 6| Step: 6
Training loss: 2.290928363800049
Validation loss: 1.9606717581390052

Epoch: 6| Step: 7
Training loss: 1.2983012199401855
Validation loss: 1.9609616828221146

Epoch: 6| Step: 8
Training loss: 2.205019474029541
Validation loss: 1.965235569143808

Epoch: 6| Step: 9
Training loss: 2.70888090133667
Validation loss: 1.9582631485436552

Epoch: 6| Step: 10
Training loss: 2.4045064449310303
Validation loss: 1.9528788366625387

Epoch: 6| Step: 11
Training loss: 2.4979779720306396
Validation loss: 1.957217647183326

Epoch: 6| Step: 12
Training loss: 1.7495696544647217
Validation loss: 1.969145349276963

Epoch: 6| Step: 13
Training loss: 2.2899322509765625
Validation loss: 1.9451247248598325

Epoch: 81| Step: 0
Training loss: 2.524937152862549
Validation loss: 1.953886253859407

Epoch: 6| Step: 1
Training loss: 2.014970302581787
Validation loss: 1.9479144952630485

Epoch: 6| Step: 2
Training loss: 2.4064393043518066
Validation loss: 1.9509020390049103

Epoch: 6| Step: 3
Training loss: 2.306806802749634
Validation loss: 1.9462213285507695

Epoch: 6| Step: 4
Training loss: 2.71010160446167
Validation loss: 1.936905546854901

Epoch: 6| Step: 5
Training loss: 2.4515390396118164
Validation loss: 1.9469690169057539

Epoch: 6| Step: 6
Training loss: 1.9367386102676392
Validation loss: 1.9569049189167638

Epoch: 6| Step: 7
Training loss: 2.769918441772461
Validation loss: 1.961163258039823

Epoch: 6| Step: 8
Training loss: 1.893630027770996
Validation loss: 1.9480647451134139

Epoch: 6| Step: 9
Training loss: 2.8552792072296143
Validation loss: 1.9322716933424755

Epoch: 6| Step: 10
Training loss: 1.6335585117340088
Validation loss: 1.9542284306659494

Epoch: 6| Step: 11
Training loss: 1.9036906957626343
Validation loss: 1.9519660511324484

Epoch: 6| Step: 12
Training loss: 1.9383395910263062
Validation loss: 1.930187475296759

Epoch: 6| Step: 13
Training loss: 1.781088948249817
Validation loss: 1.9419363326923822

Epoch: 82| Step: 0
Training loss: 2.4175782203674316
Validation loss: 1.9492909985203897

Epoch: 6| Step: 1
Training loss: 2.0855846405029297
Validation loss: 1.9533279775291361

Epoch: 6| Step: 2
Training loss: 2.354001045227051
Validation loss: 1.955912483635769

Epoch: 6| Step: 3
Training loss: 2.186870574951172
Validation loss: 1.9435411448119788

Epoch: 6| Step: 4
Training loss: 2.210095167160034
Validation loss: 1.9341189810024795

Epoch: 6| Step: 5
Training loss: 3.0116794109344482
Validation loss: 1.9491037091901224

Epoch: 6| Step: 6
Training loss: 2.037623882293701
Validation loss: 1.9513228054969542

Epoch: 6| Step: 7
Training loss: 2.1588926315307617
Validation loss: 1.9373818405212895

Epoch: 6| Step: 8
Training loss: 2.6546058654785156
Validation loss: 1.9351854067976757

Epoch: 6| Step: 9
Training loss: 1.674958348274231
Validation loss: 1.9520442678082375

Epoch: 6| Step: 10
Training loss: 2.031172513961792
Validation loss: 1.938275578201458

Epoch: 6| Step: 11
Training loss: 2.1077170372009277
Validation loss: 1.9519844055175781

Epoch: 6| Step: 12
Training loss: 1.8478493690490723
Validation loss: 1.9467716499041485

Epoch: 6| Step: 13
Training loss: 2.6369104385375977
Validation loss: 1.9326715853906447

Epoch: 83| Step: 0
Training loss: 2.224567174911499
Validation loss: 1.9530496135834725

Epoch: 6| Step: 1
Training loss: 2.1472222805023193
Validation loss: 1.9525144984645229

Epoch: 6| Step: 2
Training loss: 1.530167818069458
Validation loss: 1.9557591522893598

Epoch: 6| Step: 3
Training loss: 2.0941548347473145
Validation loss: 1.9337399877527708

Epoch: 6| Step: 4
Training loss: 2.643794536590576
Validation loss: 1.951192412325131

Epoch: 6| Step: 5
Training loss: 1.9279613494873047
Validation loss: 1.947423860590945

Epoch: 6| Step: 6
Training loss: 2.4680542945861816
Validation loss: 1.943537740297215

Epoch: 6| Step: 7
Training loss: 2.112119436264038
Validation loss: 1.9362384708978797

Epoch: 6| Step: 8
Training loss: 2.2832374572753906
Validation loss: 1.9455068290874522

Epoch: 6| Step: 9
Training loss: 2.0173680782318115
Validation loss: 1.9263507038034418

Epoch: 6| Step: 10
Training loss: 2.7359166145324707
Validation loss: 1.93271932935202

Epoch: 6| Step: 11
Training loss: 2.455199718475342
Validation loss: 1.9526822208076395

Epoch: 6| Step: 12
Training loss: 2.2484049797058105
Validation loss: 1.9269040938346618

Epoch: 6| Step: 13
Training loss: 2.227349281311035
Validation loss: 1.9246128477076048

Epoch: 84| Step: 0
Training loss: 2.4798383712768555
Validation loss: 1.92302825373988

Epoch: 6| Step: 1
Training loss: 2.0083189010620117
Validation loss: 1.9587388359090334

Epoch: 6| Step: 2
Training loss: 1.3679267168045044
Validation loss: 1.9505042978512344

Epoch: 6| Step: 3
Training loss: 2.1578707695007324
Validation loss: 1.9457473536973358

Epoch: 6| Step: 4
Training loss: 1.8210382461547852
Validation loss: 1.93887661862117

Epoch: 6| Step: 5
Training loss: 2.568821430206299
Validation loss: 1.9437614076880998

Epoch: 6| Step: 6
Training loss: 2.028900146484375
Validation loss: 1.948650872835549

Epoch: 6| Step: 7
Training loss: 2.7419753074645996
Validation loss: 1.9345738528877177

Epoch: 6| Step: 8
Training loss: 2.2048768997192383
Validation loss: 1.9518834198674848

Epoch: 6| Step: 9
Training loss: 2.761359691619873
Validation loss: 1.9448642987076954

Epoch: 6| Step: 10
Training loss: 2.353440999984741
Validation loss: 1.9488404591878254

Epoch: 6| Step: 11
Training loss: 1.9119223356246948
Validation loss: 1.9413717075060772

Epoch: 6| Step: 12
Training loss: 2.0790300369262695
Validation loss: 1.926075707199753

Epoch: 6| Step: 13
Training loss: 3.168301582336426
Validation loss: 1.9310182820084274

Epoch: 85| Step: 0
Training loss: 2.334360361099243
Validation loss: 1.9392223640154767

Epoch: 6| Step: 1
Training loss: 2.343510627746582
Validation loss: 1.9577130168996832

Epoch: 6| Step: 2
Training loss: 2.0378270149230957
Validation loss: 1.9509767460566696

Epoch: 6| Step: 3
Training loss: 2.2545838356018066
Validation loss: 1.9589460998453119

Epoch: 6| Step: 4
Training loss: 1.721264123916626
Validation loss: 1.9442268340818343

Epoch: 6| Step: 5
Training loss: 1.2990058660507202
Validation loss: 1.9809639889706847

Epoch: 6| Step: 6
Training loss: 2.1132168769836426
Validation loss: 1.9443103062209262

Epoch: 6| Step: 7
Training loss: 2.4566431045532227
Validation loss: 1.9428171368055447

Epoch: 6| Step: 8
Training loss: 2.0769591331481934
Validation loss: 1.9500821354568645

Epoch: 6| Step: 9
Training loss: 1.8079330921173096
Validation loss: 1.9537573065809024

Epoch: 6| Step: 10
Training loss: 3.3309342861175537
Validation loss: 1.946045111584407

Epoch: 6| Step: 11
Training loss: 2.219386100769043
Validation loss: 1.9307463643371419

Epoch: 6| Step: 12
Training loss: 2.879204511642456
Validation loss: 1.9368231193993681

Epoch: 6| Step: 13
Training loss: 2.299032211303711
Validation loss: 1.947576384390554

Epoch: 86| Step: 0
Training loss: 2.171699047088623
Validation loss: 1.9717755625324864

Epoch: 6| Step: 1
Training loss: 2.7805657386779785
Validation loss: 1.9462426118953253

Epoch: 6| Step: 2
Training loss: 2.1475954055786133
Validation loss: 1.9672693296145367

Epoch: 6| Step: 3
Training loss: 1.9510579109191895
Validation loss: 1.9595527956562657

Epoch: 6| Step: 4
Training loss: 1.695756196975708
Validation loss: 1.961760510680496

Epoch: 6| Step: 5
Training loss: 1.5505139827728271
Validation loss: 1.9714828242537796

Epoch: 6| Step: 6
Training loss: 2.4245529174804688
Validation loss: 1.9523658701168594

Epoch: 6| Step: 7
Training loss: 2.3392727375030518
Validation loss: 1.9670858831815823

Epoch: 6| Step: 8
Training loss: 3.0785675048828125
Validation loss: 1.9473107207205989

Epoch: 6| Step: 9
Training loss: 2.17541766166687
Validation loss: 1.9599250285856185

Epoch: 6| Step: 10
Training loss: 1.9718787670135498
Validation loss: 1.9447396839818647

Epoch: 6| Step: 11
Training loss: 1.5596224069595337
Validation loss: 1.966779924208118

Epoch: 6| Step: 12
Training loss: 2.797522783279419
Validation loss: 1.9604525437919043

Epoch: 6| Step: 13
Training loss: 2.161323308944702
Validation loss: 1.9384916290160148

Epoch: 87| Step: 0
Training loss: 1.9978787899017334
Validation loss: 1.9587012324281918

Epoch: 6| Step: 1
Training loss: 2.2160959243774414
Validation loss: 1.9446543224396244

Epoch: 6| Step: 2
Training loss: 2.2537882328033447
Validation loss: 1.9481997438656387

Epoch: 6| Step: 3
Training loss: 2.4492835998535156
Validation loss: 1.9679523411617483

Epoch: 6| Step: 4
Training loss: 1.6348592042922974
Validation loss: 1.9585289301410798

Epoch: 6| Step: 5
Training loss: 2.0383729934692383
Validation loss: 1.961844733966294

Epoch: 6| Step: 6
Training loss: 2.184177875518799
Validation loss: 1.970262610784141

Epoch: 6| Step: 7
Training loss: 2.1407628059387207
Validation loss: 1.9533364349795925

Epoch: 6| Step: 8
Training loss: 2.2416138648986816
Validation loss: 1.9704342337064846

Epoch: 6| Step: 9
Training loss: 2.74784779548645
Validation loss: 1.9601840985718595

Epoch: 6| Step: 10
Training loss: 2.337571144104004
Validation loss: 1.9562084033925047

Epoch: 6| Step: 11
Training loss: 2.298125743865967
Validation loss: 1.9381295865581882

Epoch: 6| Step: 12
Training loss: 2.2471911907196045
Validation loss: 1.9712048012723205

Epoch: 6| Step: 13
Training loss: 2.310594081878662
Validation loss: 1.96759674626012

Epoch: 88| Step: 0
Training loss: 1.5850565433502197
Validation loss: 1.9281105482450096

Epoch: 6| Step: 1
Training loss: 1.7430381774902344
Validation loss: 1.9693978217340284

Epoch: 6| Step: 2
Training loss: 1.6736233234405518
Validation loss: 1.9658412882076797

Epoch: 6| Step: 3
Training loss: 1.8870288133621216
Validation loss: 1.9538000270884524

Epoch: 6| Step: 4
Training loss: 1.9230139255523682
Validation loss: 1.9784887157460695

Epoch: 6| Step: 5
Training loss: 3.0906004905700684
Validation loss: 1.978779419775932

Epoch: 6| Step: 6
Training loss: 1.714991569519043
Validation loss: 1.972626805305481

Epoch: 6| Step: 7
Training loss: 1.8887252807617188
Validation loss: 1.9691887619674846

Epoch: 6| Step: 8
Training loss: 2.8080129623413086
Validation loss: 1.9856524800741544

Epoch: 6| Step: 9
Training loss: 2.6416337490081787
Validation loss: 1.9755166384481615

Epoch: 6| Step: 10
Training loss: 2.5133707523345947
Validation loss: 1.9599774229911067

Epoch: 6| Step: 11
Training loss: 2.4630370140075684
Validation loss: 1.9673471091895975

Epoch: 6| Step: 12
Training loss: 2.401909828186035
Validation loss: 1.998009084373392

Epoch: 6| Step: 13
Training loss: 2.9430601596832275
Validation loss: 1.9893544232973488

Epoch: 89| Step: 0
Training loss: 1.4740517139434814
Validation loss: 1.9935790800279187

Epoch: 6| Step: 1
Training loss: 2.3565096855163574
Validation loss: 1.9732708136240642

Epoch: 6| Step: 2
Training loss: 2.167443037033081
Validation loss: 1.9810646785202848

Epoch: 6| Step: 3
Training loss: 2.5213565826416016
Validation loss: 1.977477591524842

Epoch: 6| Step: 4
Training loss: 2.671046733856201
Validation loss: 1.9787261088689168

Epoch: 6| Step: 5
Training loss: 2.6388065814971924
Validation loss: 1.9825620369244648

Epoch: 6| Step: 6
Training loss: 2.0961575508117676
Validation loss: 1.9777054799500333

Epoch: 6| Step: 7
Training loss: 1.8513610363006592
Validation loss: 1.9546647789657756

Epoch: 6| Step: 8
Training loss: 2.6531124114990234
Validation loss: 1.962682754762711

Epoch: 6| Step: 9
Training loss: 2.468515396118164
Validation loss: 1.9390515409490114

Epoch: 6| Step: 10
Training loss: 1.3395100831985474
Validation loss: 1.9616733033169982

Epoch: 6| Step: 11
Training loss: 2.2145602703094482
Validation loss: 1.9346450644154702

Epoch: 6| Step: 12
Training loss: 1.6508883237838745
Validation loss: 1.9702683084754533

Epoch: 6| Step: 13
Training loss: 3.2539045810699463
Validation loss: 1.935442566871643

Epoch: 90| Step: 0
Training loss: 2.8945727348327637
Validation loss: 1.9666854848143875

Epoch: 6| Step: 1
Training loss: 2.0120606422424316
Validation loss: 1.9786920009120819

Epoch: 6| Step: 2
Training loss: 2.802417755126953
Validation loss: 1.9642658720734298

Epoch: 6| Step: 3
Training loss: 1.899980902671814
Validation loss: 1.9583881170518938

Epoch: 6| Step: 4
Training loss: 1.6512706279754639
Validation loss: 1.9775690570954354

Epoch: 6| Step: 5
Training loss: 2.1896843910217285
Validation loss: 1.9732402319549232

Epoch: 6| Step: 6
Training loss: 2.879322052001953
Validation loss: 1.9888623119682394

Epoch: 6| Step: 7
Training loss: 2.660696029663086
Validation loss: 1.963570838333458

Epoch: 6| Step: 8
Training loss: 1.4628734588623047
Validation loss: 1.9509171824301443

Epoch: 6| Step: 9
Training loss: 2.3079347610473633
Validation loss: 1.9793874704709618

Epoch: 6| Step: 10
Training loss: 1.7481043338775635
Validation loss: 1.9731469385085567

Epoch: 6| Step: 11
Training loss: 2.1468050479888916
Validation loss: 1.973320407252158

Epoch: 6| Step: 12
Training loss: 2.1754255294799805
Validation loss: 1.9639754961895686

Epoch: 6| Step: 13
Training loss: 1.6607091426849365
Validation loss: 1.9741496616794216

Epoch: 91| Step: 0
Training loss: 1.585789442062378
Validation loss: 1.976902913021785

Epoch: 6| Step: 1
Training loss: 1.6685171127319336
Validation loss: 1.9904733575800413

Epoch: 6| Step: 2
Training loss: 2.6326241493225098
Validation loss: 1.9559439741155153

Epoch: 6| Step: 3
Training loss: 2.1961729526519775
Validation loss: 1.9668466455192977

Epoch: 6| Step: 4
Training loss: 2.5893638134002686
Validation loss: 1.9883351300352363

Epoch: 6| Step: 5
Training loss: 1.8859930038452148
Validation loss: 1.9431833028793335

Epoch: 6| Step: 6
Training loss: 2.0828797817230225
Validation loss: 1.9495883808341077

Epoch: 6| Step: 7
Training loss: 2.8482298851013184
Validation loss: 1.9493497584455757

Epoch: 6| Step: 8
Training loss: 2.6337199211120605
Validation loss: 1.9279762262939124

Epoch: 6| Step: 9
Training loss: 1.5889699459075928
Validation loss: 1.9385995736686132

Epoch: 6| Step: 10
Training loss: 2.409364938735962
Validation loss: 1.950975828273322

Epoch: 6| Step: 11
Training loss: 2.271250009536743
Validation loss: 1.960313803406172

Epoch: 6| Step: 12
Training loss: 2.6311533451080322
Validation loss: 1.9501795589282949

Epoch: 6| Step: 13
Training loss: 1.4869627952575684
Validation loss: 1.9606691944983698

Epoch: 92| Step: 0
Training loss: 2.3746705055236816
Validation loss: 1.968233959649199

Epoch: 6| Step: 1
Training loss: 1.7870962619781494
Validation loss: 1.9863802873960106

Epoch: 6| Step: 2
Training loss: 1.974228858947754
Validation loss: 1.959639823564919

Epoch: 6| Step: 3
Training loss: 2.3174960613250732
Validation loss: 1.9656816810689948

Epoch: 6| Step: 4
Training loss: 2.13927960395813
Validation loss: 1.9402594720163653

Epoch: 6| Step: 5
Training loss: 1.8108388185501099
Validation loss: 1.9696622048654864

Epoch: 6| Step: 6
Training loss: 2.081963539123535
Validation loss: 1.9436637663072156

Epoch: 6| Step: 7
Training loss: 2.334719181060791
Validation loss: 1.9527985408741941

Epoch: 6| Step: 8
Training loss: 2.214336395263672
Validation loss: 1.978772206973004

Epoch: 6| Step: 9
Training loss: 2.201967716217041
Validation loss: 1.9650897159371326

Epoch: 6| Step: 10
Training loss: 1.7297539710998535
Validation loss: 1.9812348145310597

Epoch: 6| Step: 11
Training loss: 3.5623064041137695
Validation loss: 1.9579360177440028

Epoch: 6| Step: 12
Training loss: 1.9987856149673462
Validation loss: 2.0026971422215945

Epoch: 6| Step: 13
Training loss: 2.144688129425049
Validation loss: 1.9554284003473097

Epoch: 93| Step: 0
Training loss: 1.2793861627578735
Validation loss: 1.9693376325791883

Epoch: 6| Step: 1
Training loss: 2.2005200386047363
Validation loss: 1.974929831361258

Epoch: 6| Step: 2
Training loss: 2.7470736503601074
Validation loss: 1.981195616465743

Epoch: 6| Step: 3
Training loss: 1.7577595710754395
Validation loss: 2.0011567044001755

Epoch: 6| Step: 4
Training loss: 2.217630386352539
Validation loss: 1.9787597322976718

Epoch: 6| Step: 5
Training loss: 2.688091278076172
Validation loss: 1.9973669975034651

Epoch: 6| Step: 6
Training loss: 2.4068286418914795
Validation loss: 2.0025991957674742

Epoch: 6| Step: 7
Training loss: 2.0486888885498047
Validation loss: 1.9930857278967415

Epoch: 6| Step: 8
Training loss: 2.4664857387542725
Validation loss: 2.0049355235151065

Epoch: 6| Step: 9
Training loss: 1.9839876890182495
Validation loss: 2.0172663350259104

Epoch: 6| Step: 10
Training loss: 2.814786911010742
Validation loss: 1.9688899260695263

Epoch: 6| Step: 11
Training loss: 1.6010760068893433
Validation loss: 1.979150600330804

Epoch: 6| Step: 12
Training loss: 2.132662773132324
Validation loss: 1.9882539856818415

Epoch: 6| Step: 13
Training loss: 2.430973768234253
Validation loss: 1.9654043694978118

Epoch: 94| Step: 0
Training loss: 1.9021821022033691
Validation loss: 1.958429285275039

Epoch: 6| Step: 1
Training loss: 2.635355234146118
Validation loss: 1.937120932404713

Epoch: 6| Step: 2
Training loss: 1.9968574047088623
Validation loss: 1.9414802071868733

Epoch: 6| Step: 3
Training loss: 2.35322904586792
Validation loss: 1.9439326306825042

Epoch: 6| Step: 4
Training loss: 2.562276601791382
Validation loss: 1.9465528559941117

Epoch: 6| Step: 5
Training loss: 2.0532612800598145
Validation loss: 1.9302386237728981

Epoch: 6| Step: 6
Training loss: 1.95845627784729
Validation loss: 1.9552437618214598

Epoch: 6| Step: 7
Training loss: 1.8825055360794067
Validation loss: 1.9395545913327126

Epoch: 6| Step: 8
Training loss: 2.03902530670166
Validation loss: 1.9589034126650902

Epoch: 6| Step: 9
Training loss: 2.1987156867980957
Validation loss: 1.9713419278462727

Epoch: 6| Step: 10
Training loss: 2.5172195434570312
Validation loss: 1.970144715360416

Epoch: 6| Step: 11
Training loss: 2.2712159156799316
Validation loss: 1.9632797241210938

Epoch: 6| Step: 12
Training loss: 2.4208526611328125
Validation loss: 1.9773487019282516

Epoch: 6| Step: 13
Training loss: 1.7040979862213135
Validation loss: 1.9401320616404216

Epoch: 95| Step: 0
Training loss: 2.388345718383789
Validation loss: 1.9179096375742266

Epoch: 6| Step: 1
Training loss: 1.6618847846984863
Validation loss: 1.9361546949673725

Epoch: 6| Step: 2
Training loss: 2.3154611587524414
Validation loss: 1.9514207045237224

Epoch: 6| Step: 3
Training loss: 2.040083408355713
Validation loss: 1.9548041064252135

Epoch: 6| Step: 4
Training loss: 2.2887754440307617
Validation loss: 1.952254984968452

Epoch: 6| Step: 5
Training loss: 1.820730447769165
Validation loss: 1.954823632394114

Epoch: 6| Step: 6
Training loss: 2.281479835510254
Validation loss: 1.9600594761551067

Epoch: 6| Step: 7
Training loss: 2.000438928604126
Validation loss: 1.9564193858895251

Epoch: 6| Step: 8
Training loss: 2.575474977493286
Validation loss: 1.9683870218133415

Epoch: 6| Step: 9
Training loss: 3.1956539154052734
Validation loss: 1.9840050564017346

Epoch: 6| Step: 10
Training loss: 2.192253351211548
Validation loss: 1.9637444621773177

Epoch: 6| Step: 11
Training loss: 2.24497127532959
Validation loss: 1.9714453451095089

Epoch: 6| Step: 12
Training loss: 1.5985158681869507
Validation loss: 1.9705913143773233

Epoch: 6| Step: 13
Training loss: 1.741391897201538
Validation loss: 1.9574953356096823

Epoch: 96| Step: 0
Training loss: 2.330498218536377
Validation loss: 1.9729591056864748

Epoch: 6| Step: 1
Training loss: 2.7250924110412598
Validation loss: 1.9780641294294787

Epoch: 6| Step: 2
Training loss: 2.704768180847168
Validation loss: 1.9621436467734716

Epoch: 6| Step: 3
Training loss: 1.7671515941619873
Validation loss: 1.9659082620374617

Epoch: 6| Step: 4
Training loss: 2.1718921661376953
Validation loss: 1.9526222867350425

Epoch: 6| Step: 5
Training loss: 2.044619560241699
Validation loss: 1.9531118280144149

Epoch: 6| Step: 6
Training loss: 2.5992488861083984
Validation loss: 1.9512515580782326

Epoch: 6| Step: 7
Training loss: 1.8265947103500366
Validation loss: 1.9599962260133477

Epoch: 6| Step: 8
Training loss: 1.8094573020935059
Validation loss: 1.961619802700576

Epoch: 6| Step: 9
Training loss: 2.533439874649048
Validation loss: 1.9739719437014671

Epoch: 6| Step: 10
Training loss: 1.818389654159546
Validation loss: 1.9411752941787883

Epoch: 6| Step: 11
Training loss: 1.693177580833435
Validation loss: 1.9628596190483338

Epoch: 6| Step: 12
Training loss: 2.5310463905334473
Validation loss: 1.9548077814040645

Epoch: 6| Step: 13
Training loss: 1.8503015041351318
Validation loss: 1.9607358004457207

Epoch: 97| Step: 0
Training loss: 2.196810722351074
Validation loss: 1.968426933852575

Epoch: 6| Step: 1
Training loss: 2.1236162185668945
Validation loss: 1.9605790210026566

Epoch: 6| Step: 2
Training loss: 2.0279669761657715
Validation loss: 1.961497422187559

Epoch: 6| Step: 3
Training loss: 2.16509747505188
Validation loss: 1.9572321599529636

Epoch: 6| Step: 4
Training loss: 2.6060330867767334
Validation loss: 1.9595281231787898

Epoch: 6| Step: 5
Training loss: 1.9533274173736572
Validation loss: 1.9654173466467089

Epoch: 6| Step: 6
Training loss: 2.824586868286133
Validation loss: 1.9647586294399795

Epoch: 6| Step: 7
Training loss: 3.2130870819091797
Validation loss: 1.942789666114315

Epoch: 6| Step: 8
Training loss: 1.4974250793457031
Validation loss: 1.9819495895857453

Epoch: 6| Step: 9
Training loss: 1.8197697401046753
Validation loss: 1.9644735359376477

Epoch: 6| Step: 10
Training loss: 2.5875515937805176
Validation loss: 1.967106080824329

Epoch: 6| Step: 11
Training loss: 2.0438129901885986
Validation loss: 1.968722092208042

Epoch: 6| Step: 12
Training loss: 1.503929853439331
Validation loss: 1.9616361715460335

Epoch: 6| Step: 13
Training loss: 1.7181059122085571
Validation loss: 1.9682855452260664

Epoch: 98| Step: 0
Training loss: 2.1919381618499756
Validation loss: 1.9483454073629072

Epoch: 6| Step: 1
Training loss: 1.8422154188156128
Validation loss: 1.9535326034792009

Epoch: 6| Step: 2
Training loss: 2.603281021118164
Validation loss: 1.9594093920082174

Epoch: 6| Step: 3
Training loss: 2.3296303749084473
Validation loss: 1.9307049730772614

Epoch: 6| Step: 4
Training loss: 2.37093448638916
Validation loss: 1.9285176210505988

Epoch: 6| Step: 5
Training loss: 2.2039999961853027
Validation loss: 1.9305432560623332

Epoch: 6| Step: 6
Training loss: 2.8897716999053955
Validation loss: 1.9410857346750074

Epoch: 6| Step: 7
Training loss: 2.2544000148773193
Validation loss: 1.9151948703232633

Epoch: 6| Step: 8
Training loss: 2.1167211532592773
Validation loss: 1.9366197752696213

Epoch: 6| Step: 9
Training loss: 2.0283572673797607
Validation loss: 1.9330005017659997

Epoch: 6| Step: 10
Training loss: 1.4666311740875244
Validation loss: 1.9211290779934134

Epoch: 6| Step: 11
Training loss: 1.9887239933013916
Validation loss: 1.9631618389519312

Epoch: 6| Step: 12
Training loss: 2.276247978210449
Validation loss: 1.944076527831375

Epoch: 6| Step: 13
Training loss: 2.0244481563568115
Validation loss: 1.9358474298190045

Epoch: 99| Step: 0
Training loss: 2.262287139892578
Validation loss: 1.9483459482910812

Epoch: 6| Step: 1
Training loss: 2.2769625186920166
Validation loss: 1.933146676709575

Epoch: 6| Step: 2
Training loss: 2.313464403152466
Validation loss: 1.9435541757973291

Epoch: 6| Step: 3
Training loss: 2.4730587005615234
Validation loss: 1.9559721280169744

Epoch: 6| Step: 4
Training loss: 2.002563953399658
Validation loss: 1.9737958818353631

Epoch: 6| Step: 5
Training loss: 2.605374574661255
Validation loss: 1.9635723918996832

Epoch: 6| Step: 6
Training loss: 3.060746669769287
Validation loss: 1.9499491363443353

Epoch: 6| Step: 7
Training loss: 1.8710495233535767
Validation loss: 1.9755280966399817

Epoch: 6| Step: 8
Training loss: 2.064182758331299
Validation loss: 1.9678313732147217

Epoch: 6| Step: 9
Training loss: 1.5299712419509888
Validation loss: 1.947401903008902

Epoch: 6| Step: 10
Training loss: 1.5221093893051147
Validation loss: 1.9689451879070652

Epoch: 6| Step: 11
Training loss: 2.5554935932159424
Validation loss: 1.952892755949369

Epoch: 6| Step: 12
Training loss: 1.613057017326355
Validation loss: 1.9639692511609805

Epoch: 6| Step: 13
Training loss: 2.6988284587860107
Validation loss: 1.972192149008474

Epoch: 100| Step: 0
Training loss: 1.8662867546081543
Validation loss: 1.9606641313081146

Epoch: 6| Step: 1
Training loss: 1.9160919189453125
Validation loss: 1.9491237542962516

Epoch: 6| Step: 2
Training loss: 2.354015827178955
Validation loss: 1.9497195802709109

Epoch: 6| Step: 3
Training loss: 2.315690040588379
Validation loss: 1.9615521302787207

Epoch: 6| Step: 4
Training loss: 2.3080673217773438
Validation loss: 1.953662823605281

Epoch: 6| Step: 5
Training loss: 2.090639591217041
Validation loss: 1.9615932126199045

Epoch: 6| Step: 6
Training loss: 1.7165166139602661
Validation loss: 1.9570055456571682

Epoch: 6| Step: 7
Training loss: 1.8501200675964355
Validation loss: 1.927899472175106

Epoch: 6| Step: 8
Training loss: 2.488900899887085
Validation loss: 1.9626091295673

Epoch: 6| Step: 9
Training loss: 1.9705618619918823
Validation loss: 1.9534361875185402

Epoch: 6| Step: 10
Training loss: 2.3944287300109863
Validation loss: 1.9463225705649263

Epoch: 6| Step: 11
Training loss: 2.429062604904175
Validation loss: 1.9212874084390619

Epoch: 6| Step: 12
Training loss: 2.438070774078369
Validation loss: 1.9673824592303204

Epoch: 6| Step: 13
Training loss: 2.3325228691101074
Validation loss: 1.948794029092276

Epoch: 101| Step: 0
Training loss: 2.1148338317871094
Validation loss: 1.9606201110347625

Epoch: 6| Step: 1
Training loss: 2.284390926361084
Validation loss: 1.9586307669198642

Epoch: 6| Step: 2
Training loss: 2.1896939277648926
Validation loss: 1.9894219098552581

Epoch: 6| Step: 3
Training loss: 2.566833734512329
Validation loss: 1.9702706849703224

Epoch: 6| Step: 4
Training loss: 2.2610349655151367
Validation loss: 1.9306653058657082

Epoch: 6| Step: 5
Training loss: 1.808518648147583
Validation loss: 1.969092075542737

Epoch: 6| Step: 6
Training loss: 2.4112210273742676
Validation loss: 1.957397844201775

Epoch: 6| Step: 7
Training loss: 1.8609814643859863
Validation loss: 1.9481330558817873

Epoch: 6| Step: 8
Training loss: 2.086057186126709
Validation loss: 1.9544538067233177

Epoch: 6| Step: 9
Training loss: 2.2096731662750244
Validation loss: 1.9619151430745279

Epoch: 6| Step: 10
Training loss: 2.490452289581299
Validation loss: 1.9435384260710848

Epoch: 6| Step: 11
Training loss: 2.317006826400757
Validation loss: 1.9500985171205254

Epoch: 6| Step: 12
Training loss: 1.9240570068359375
Validation loss: 1.982944788471345

Epoch: 6| Step: 13
Training loss: 1.301323652267456
Validation loss: 1.9693923637431154

Epoch: 102| Step: 0
Training loss: 2.723358392715454
Validation loss: 1.96540617686446

Epoch: 6| Step: 1
Training loss: 2.2804973125457764
Validation loss: 1.9635632448298956

Epoch: 6| Step: 2
Training loss: 1.8402831554412842
Validation loss: 1.9719328162490681

Epoch: 6| Step: 3
Training loss: 1.6492098569869995
Validation loss: 1.982619511183872

Epoch: 6| Step: 4
Training loss: 1.405582308769226
Validation loss: 1.9289433135781238

Epoch: 6| Step: 5
Training loss: 2.371910810470581
Validation loss: 1.9651581805239442

Epoch: 6| Step: 6
Training loss: 2.9502973556518555
Validation loss: 1.9691263270634476

Epoch: 6| Step: 7
Training loss: 1.9026391506195068
Validation loss: 1.9761140513163742

Epoch: 6| Step: 8
Training loss: 1.6854214668273926
Validation loss: 1.9442590449445991

Epoch: 6| Step: 9
Training loss: 2.182389736175537
Validation loss: 1.9893104748059345

Epoch: 6| Step: 10
Training loss: 2.7242608070373535
Validation loss: 1.9664717887037544

Epoch: 6| Step: 11
Training loss: 2.4195783138275146
Validation loss: 1.9624143967064478

Epoch: 6| Step: 12
Training loss: 2.520670175552368
Validation loss: 1.9697034499978507

Epoch: 6| Step: 13
Training loss: 1.414680004119873
Validation loss: 1.9694221583745812

Epoch: 103| Step: 0
Training loss: 1.8663859367370605
Validation loss: 1.967660875730617

Epoch: 6| Step: 1
Training loss: 1.7205396890640259
Validation loss: 1.9668526828929942

Epoch: 6| Step: 2
Training loss: 2.310809850692749
Validation loss: 1.9850598958230787

Epoch: 6| Step: 3
Training loss: 2.2676758766174316
Validation loss: 1.9722384868129608

Epoch: 6| Step: 4
Training loss: 1.8780606985092163
Validation loss: 1.9768355764368528

Epoch: 6| Step: 5
Training loss: 2.1880109310150146
Validation loss: 1.9866225078541746

Epoch: 6| Step: 6
Training loss: 2.310734748840332
Validation loss: 1.9950023312722482

Epoch: 6| Step: 7
Training loss: 2.0931897163391113
Validation loss: 2.0147970491839993

Epoch: 6| Step: 8
Training loss: 2.521742820739746
Validation loss: 1.9840021543605353

Epoch: 6| Step: 9
Training loss: 2.3104655742645264
Validation loss: 1.9690148766322801

Epoch: 6| Step: 10
Training loss: 2.6496756076812744
Validation loss: 1.9875409795391945

Epoch: 6| Step: 11
Training loss: 2.248227119445801
Validation loss: 2.0151751272140013

Epoch: 6| Step: 12
Training loss: 1.7005383968353271
Validation loss: 2.002169414233136

Epoch: 6| Step: 13
Training loss: 2.189643383026123
Validation loss: 1.9752002377663889

Epoch: 104| Step: 0
Training loss: 1.6190074682235718
Validation loss: 1.9732950323371476

Epoch: 6| Step: 1
Training loss: 1.6727468967437744
Validation loss: 1.994998025637801

Epoch: 6| Step: 2
Training loss: 2.269892454147339
Validation loss: 1.9638499239439606

Epoch: 6| Step: 3
Training loss: 3.030177116394043
Validation loss: 1.9986691936369865

Epoch: 6| Step: 4
Training loss: 1.7329297065734863
Validation loss: 1.9780415027372298

Epoch: 6| Step: 5
Training loss: 1.9623441696166992
Validation loss: 1.9700016385765486

Epoch: 6| Step: 6
Training loss: 3.469095468521118
Validation loss: 1.9841943863899476

Epoch: 6| Step: 7
Training loss: 1.332916259765625
Validation loss: 1.9421058547112249

Epoch: 6| Step: 8
Training loss: 1.4286061525344849
Validation loss: 1.9878411831394318

Epoch: 6| Step: 9
Training loss: 2.240123748779297
Validation loss: 1.958220845909529

Epoch: 6| Step: 10
Training loss: 2.0425314903259277
Validation loss: 1.9739917914072673

Epoch: 6| Step: 11
Training loss: 2.0813965797424316
Validation loss: 1.9671999639080417

Epoch: 6| Step: 12
Training loss: 3.0012733936309814
Validation loss: 1.9670261388183923

Epoch: 6| Step: 13
Training loss: 2.4288294315338135
Validation loss: 1.9389662255523026

Epoch: 105| Step: 0
Training loss: 2.603731393814087
Validation loss: 1.962303553858111

Epoch: 6| Step: 1
Training loss: 2.2227160930633545
Validation loss: 1.961436253721996

Epoch: 6| Step: 2
Training loss: 2.37548565864563
Validation loss: 1.974600520185245

Epoch: 6| Step: 3
Training loss: 1.8031147718429565
Validation loss: 1.9932573636372883

Epoch: 6| Step: 4
Training loss: 2.7905774116516113
Validation loss: 1.9465943241632113

Epoch: 6| Step: 5
Training loss: 2.4089481830596924
Validation loss: 1.9829247010651456

Epoch: 6| Step: 6
Training loss: 2.256359100341797
Validation loss: 1.9488143792716406

Epoch: 6| Step: 7
Training loss: 2.599453926086426
Validation loss: 1.9416966540839082

Epoch: 6| Step: 8
Training loss: 1.9059028625488281
Validation loss: 1.9404396177620016

Epoch: 6| Step: 9
Training loss: 2.015127182006836
Validation loss: 1.972438871219594

Epoch: 6| Step: 10
Training loss: 1.6834986209869385
Validation loss: 1.9447946586916525

Epoch: 6| Step: 11
Training loss: 1.8289151191711426
Validation loss: 1.9355221051041798

Epoch: 6| Step: 12
Training loss: 2.138460397720337
Validation loss: 1.9523814519246419

Epoch: 6| Step: 13
Training loss: 1.5718655586242676
Validation loss: 1.9698201943469305

Epoch: 106| Step: 0
Training loss: 1.6482577323913574
Validation loss: 1.9638633766481954

Epoch: 6| Step: 1
Training loss: 1.6021966934204102
Validation loss: 1.9692477359566638

Epoch: 6| Step: 2
Training loss: 2.378153085708618
Validation loss: 1.966670387534685

Epoch: 6| Step: 3
Training loss: 1.9179000854492188
Validation loss: 1.9676152083181566

Epoch: 6| Step: 4
Training loss: 2.9887630939483643
Validation loss: 1.983743457384007

Epoch: 6| Step: 5
Training loss: 2.096554756164551
Validation loss: 1.951809907472262

Epoch: 6| Step: 6
Training loss: 2.2872977256774902
Validation loss: 1.9694313285171345

Epoch: 6| Step: 7
Training loss: 1.844490647315979
Validation loss: 1.9710881530597646

Epoch: 6| Step: 8
Training loss: 2.504883050918579
Validation loss: 1.9605392050999466

Epoch: 6| Step: 9
Training loss: 2.1780877113342285
Validation loss: 1.9675331282359299

Epoch: 6| Step: 10
Training loss: 2.2051117420196533
Validation loss: 1.9622841035166094

Epoch: 6| Step: 11
Training loss: 1.727755069732666
Validation loss: 1.98117313590101

Epoch: 6| Step: 12
Training loss: 2.494428873062134
Validation loss: 1.9645989889739661

Epoch: 6| Step: 13
Training loss: 2.365838050842285
Validation loss: 1.9556987259977607

Epoch: 107| Step: 0
Training loss: 2.2806382179260254
Validation loss: 1.9705429666785783

Epoch: 6| Step: 1
Training loss: 1.602679967880249
Validation loss: 1.9523103108970068

Epoch: 6| Step: 2
Training loss: 2.6896536350250244
Validation loss: 1.9730458695401427

Epoch: 6| Step: 3
Training loss: 1.8250445127487183
Validation loss: 2.002150607365434

Epoch: 6| Step: 4
Training loss: 1.4101083278656006
Validation loss: 1.9965374905575988

Epoch: 6| Step: 5
Training loss: 1.6302990913391113
Validation loss: 1.980565640234178

Epoch: 6| Step: 6
Training loss: 2.249882936477661
Validation loss: 1.9877423599202146

Epoch: 6| Step: 7
Training loss: 2.5624401569366455
Validation loss: 1.9861158504280993

Epoch: 6| Step: 8
Training loss: 2.2112386226654053
Validation loss: 2.0419381203189975

Epoch: 6| Step: 9
Training loss: 2.2784576416015625
Validation loss: 1.9906664202290196

Epoch: 6| Step: 10
Training loss: 2.204051971435547
Validation loss: 1.9992331612494685

Epoch: 6| Step: 11
Training loss: 2.8890326023101807
Validation loss: 1.981017643405545

Epoch: 6| Step: 12
Training loss: 2.6909475326538086
Validation loss: 1.977555956891788

Epoch: 6| Step: 13
Training loss: 1.3337682485580444
Validation loss: 1.9865979238223004

Epoch: 108| Step: 0
Training loss: 1.8907415866851807
Validation loss: 1.9654807621432888

Epoch: 6| Step: 1
Training loss: 2.2131943702697754
Validation loss: 1.9630617275032947

Epoch: 6| Step: 2
Training loss: 2.5161283016204834
Validation loss: 1.9571081566554245

Epoch: 6| Step: 3
Training loss: 2.725008487701416
Validation loss: 1.9653577984020274

Epoch: 6| Step: 4
Training loss: 1.5564826726913452
Validation loss: 1.959205376204624

Epoch: 6| Step: 5
Training loss: 2.27811598777771
Validation loss: 1.9435905666761502

Epoch: 6| Step: 6
Training loss: 2.013692855834961
Validation loss: 1.9541367843586912

Epoch: 6| Step: 7
Training loss: 2.550880193710327
Validation loss: 1.935879485581511

Epoch: 6| Step: 8
Training loss: 1.7834111452102661
Validation loss: 1.933763450191867

Epoch: 6| Step: 9
Training loss: 2.5030062198638916
Validation loss: 1.9474848252470776

Epoch: 6| Step: 10
Training loss: 2.1036791801452637
Validation loss: 1.934786763242496

Epoch: 6| Step: 11
Training loss: 2.0960426330566406
Validation loss: 1.9488163327658048

Epoch: 6| Step: 12
Training loss: 1.438622236251831
Validation loss: 1.9227494847389959

Epoch: 6| Step: 13
Training loss: 3.18645977973938
Validation loss: 1.9312452654684744

Epoch: 109| Step: 0
Training loss: 2.3734889030456543
Validation loss: 1.9451710306188112

Epoch: 6| Step: 1
Training loss: 2.3841447830200195
Validation loss: 1.9290871709905646

Epoch: 6| Step: 2
Training loss: 2.092888116836548
Validation loss: 1.932855970116072

Epoch: 6| Step: 3
Training loss: 2.132028818130493
Validation loss: 1.9531143070549093

Epoch: 6| Step: 4
Training loss: 1.8521842956542969
Validation loss: 1.9311278122727589

Epoch: 6| Step: 5
Training loss: 1.872800588607788
Validation loss: 1.9533205762986214

Epoch: 6| Step: 6
Training loss: 2.69145131111145
Validation loss: 1.9555903211716683

Epoch: 6| Step: 7
Training loss: 1.9173014163970947
Validation loss: 1.957875585043302

Epoch: 6| Step: 8
Training loss: 1.9528183937072754
Validation loss: 1.9372215668360393

Epoch: 6| Step: 9
Training loss: 1.8061110973358154
Validation loss: 1.9617227905540056

Epoch: 6| Step: 10
Training loss: 1.6972503662109375
Validation loss: 1.958924303772629

Epoch: 6| Step: 11
Training loss: 3.309631824493408
Validation loss: 1.9710975564936155

Epoch: 6| Step: 12
Training loss: 2.359452247619629
Validation loss: 1.9505938381277106

Epoch: 6| Step: 13
Training loss: 1.4413655996322632
Validation loss: 1.9907160920481528

Epoch: 110| Step: 0
Training loss: 2.6109135150909424
Validation loss: 1.9841642546397384

Epoch: 6| Step: 1
Training loss: 2.057525634765625
Validation loss: 1.9813155115291636

Epoch: 6| Step: 2
Training loss: 1.8463915586471558
Validation loss: 1.9685160011373541

Epoch: 6| Step: 3
Training loss: 2.2888402938842773
Validation loss: 1.964786083467545

Epoch: 6| Step: 4
Training loss: 2.062798261642456
Validation loss: 1.9741606366249822

Epoch: 6| Step: 5
Training loss: 2.857365131378174
Validation loss: 1.9840126178597892

Epoch: 6| Step: 6
Training loss: 2.3083908557891846
Validation loss: 1.9776392021486837

Epoch: 6| Step: 7
Training loss: 2.3196096420288086
Validation loss: 1.9728336000955233

Epoch: 6| Step: 8
Training loss: 1.6881859302520752
Validation loss: 1.967739628207299

Epoch: 6| Step: 9
Training loss: 1.7554099559783936
Validation loss: 1.9850615327076246

Epoch: 6| Step: 10
Training loss: 1.7137703895568848
Validation loss: 1.9655136536526423

Epoch: 6| Step: 11
Training loss: 2.203056812286377
Validation loss: 1.9519649846579439

Epoch: 6| Step: 12
Training loss: 2.766847610473633
Validation loss: 1.9685720807762557

Epoch: 6| Step: 13
Training loss: 1.4807705879211426
Validation loss: 1.9764292009415165

Epoch: 111| Step: 0
Training loss: 2.4478659629821777
Validation loss: 1.9752983611117128

Epoch: 6| Step: 1
Training loss: 2.106221914291382
Validation loss: 1.9756323624682683

Epoch: 6| Step: 2
Training loss: 1.8785810470581055
Validation loss: 1.9482726025324997

Epoch: 6| Step: 3
Training loss: 2.291022777557373
Validation loss: 1.934470522788263

Epoch: 6| Step: 4
Training loss: 1.796849250793457
Validation loss: 1.9813918862291562

Epoch: 6| Step: 5
Training loss: 1.7600914239883423
Validation loss: 1.9672513854119085

Epoch: 6| Step: 6
Training loss: 2.534628391265869
Validation loss: 2.0044995148976645

Epoch: 6| Step: 7
Training loss: 2.703965187072754
Validation loss: 1.9496009734369093

Epoch: 6| Step: 8
Training loss: 1.9036829471588135
Validation loss: 1.961260449501776

Epoch: 6| Step: 9
Training loss: 2.5709280967712402
Validation loss: 1.9846458409422187

Epoch: 6| Step: 10
Training loss: 1.7282166481018066
Validation loss: 1.9647077847552556

Epoch: 6| Step: 11
Training loss: 2.1761481761932373
Validation loss: 1.9683657769233949

Epoch: 6| Step: 12
Training loss: 2.1356706619262695
Validation loss: 1.9779053452194377

Epoch: 6| Step: 13
Training loss: 1.9133764505386353
Validation loss: 1.9678484355249712

Epoch: 112| Step: 0
Training loss: 1.8258247375488281
Validation loss: 1.943006484739242

Epoch: 6| Step: 1
Training loss: 2.2148942947387695
Validation loss: 1.9787455105012464

Epoch: 6| Step: 2
Training loss: 2.476412296295166
Validation loss: 1.954066413705067

Epoch: 6| Step: 3
Training loss: 1.9348069429397583
Validation loss: 1.9560964581786946

Epoch: 6| Step: 4
Training loss: 2.0247325897216797
Validation loss: 1.9794336916297994

Epoch: 6| Step: 5
Training loss: 2.2875518798828125
Validation loss: 1.9408195428950812

Epoch: 6| Step: 6
Training loss: 2.4123942852020264
Validation loss: 1.9761114299938243

Epoch: 6| Step: 7
Training loss: 1.889050841331482
Validation loss: 1.9746755118011146

Epoch: 6| Step: 8
Training loss: 2.1241581439971924
Validation loss: 1.9659129970817155

Epoch: 6| Step: 9
Training loss: 2.8421483039855957
Validation loss: 1.9992788017437022

Epoch: 6| Step: 10
Training loss: 1.7873060703277588
Validation loss: 1.9825720851139357

Epoch: 6| Step: 11
Training loss: 1.6058212518692017
Validation loss: 1.9848911749419345

Epoch: 6| Step: 12
Training loss: 2.6165246963500977
Validation loss: 1.9717751420954222

Epoch: 6| Step: 13
Training loss: 1.8186155557632446
Validation loss: 2.004527912344984

Epoch: 113| Step: 0
Training loss: 2.1476497650146484
Validation loss: 1.9696338971455891

Epoch: 6| Step: 1
Training loss: 1.8077595233917236
Validation loss: 1.9496977995800715

Epoch: 6| Step: 2
Training loss: 2.5448920726776123
Validation loss: 1.976857490437005

Epoch: 6| Step: 3
Training loss: 1.7507376670837402
Validation loss: 1.9673947147143784

Epoch: 6| Step: 4
Training loss: 2.1751999855041504
Validation loss: 1.937826169434414

Epoch: 6| Step: 5
Training loss: 1.483973503112793
Validation loss: 1.9406259649543351

Epoch: 6| Step: 6
Training loss: 2.3176348209381104
Validation loss: 1.9377287459629837

Epoch: 6| Step: 7
Training loss: 2.0672550201416016
Validation loss: 1.9294704891020251

Epoch: 6| Step: 8
Training loss: 1.6618893146514893
Validation loss: 1.9351449397302443

Epoch: 6| Step: 9
Training loss: 1.9802014827728271
Validation loss: 1.9281973736260527

Epoch: 6| Step: 10
Training loss: 2.6434881687164307
Validation loss: 1.9531336279325588

Epoch: 6| Step: 11
Training loss: 2.419227123260498
Validation loss: 1.9324818836745394

Epoch: 6| Step: 12
Training loss: 2.523207426071167
Validation loss: 1.9562140421200824

Epoch: 6| Step: 13
Training loss: 2.4445676803588867
Validation loss: 1.9599284074639762

Epoch: 114| Step: 0
Training loss: 2.1135916709899902
Validation loss: 1.9513274418410433

Epoch: 6| Step: 1
Training loss: 2.3082313537597656
Validation loss: 1.9487300226765294

Epoch: 6| Step: 2
Training loss: 1.9511849880218506
Validation loss: 1.9637811594111945

Epoch: 6| Step: 3
Training loss: 1.7916278839111328
Validation loss: 1.9727881185470089

Epoch: 6| Step: 4
Training loss: 2.7276923656463623
Validation loss: 1.9645119508107503

Epoch: 6| Step: 5
Training loss: 2.161947727203369
Validation loss: 1.9923238779908867

Epoch: 6| Step: 6
Training loss: 2.1753592491149902
Validation loss: 1.9772845724577546

Epoch: 6| Step: 7
Training loss: 1.9982733726501465
Validation loss: 2.0002426896044003

Epoch: 6| Step: 8
Training loss: 2.340322732925415
Validation loss: 1.9865645798303748

Epoch: 6| Step: 9
Training loss: 2.107313632965088
Validation loss: 1.950062172387236

Epoch: 6| Step: 10
Training loss: 2.063809394836426
Validation loss: 2.000200991989464

Epoch: 6| Step: 11
Training loss: 2.428946018218994
Validation loss: 1.9965508471253097

Epoch: 6| Step: 12
Training loss: 1.3828771114349365
Validation loss: 1.9741933409885695

Epoch: 6| Step: 13
Training loss: 2.58996844291687
Validation loss: 1.9814734753742014

Epoch: 115| Step: 0
Training loss: 1.7798045873641968
Validation loss: 2.011292811362974

Epoch: 6| Step: 1
Training loss: 2.577993154525757
Validation loss: 1.953489593280259

Epoch: 6| Step: 2
Training loss: 1.7277294397354126
Validation loss: 1.963455221986258

Epoch: 6| Step: 3
Training loss: 2.1314148902893066
Validation loss: 1.9950658775145007

Epoch: 6| Step: 4
Training loss: 2.6627774238586426
Validation loss: 1.9627328483007287

Epoch: 6| Step: 5
Training loss: 2.196568489074707
Validation loss: 1.9908903080929992

Epoch: 6| Step: 6
Training loss: 2.51285457611084
Validation loss: 1.9952315822724374

Epoch: 6| Step: 7
Training loss: 1.7899785041809082
Validation loss: 1.9726396440177836

Epoch: 6| Step: 8
Training loss: 2.1982033252716064
Validation loss: 1.9576625926520235

Epoch: 6| Step: 9
Training loss: 1.9810693264007568
Validation loss: 1.9699495210442493

Epoch: 6| Step: 10
Training loss: 2.8178553581237793
Validation loss: 1.9372813675993232

Epoch: 6| Step: 11
Training loss: 1.6171212196350098
Validation loss: 1.9707839553074171

Epoch: 6| Step: 12
Training loss: 1.7923929691314697
Validation loss: 1.9636015584391933

Epoch: 6| Step: 13
Training loss: 2.3572638034820557
Validation loss: 1.9599903604035736

Epoch: 116| Step: 0
Training loss: 1.7960643768310547
Validation loss: 1.9633830311477825

Epoch: 6| Step: 1
Training loss: 2.0763893127441406
Validation loss: 1.9800895913954704

Epoch: 6| Step: 2
Training loss: 2.6411356925964355
Validation loss: 1.98065048392101

Epoch: 6| Step: 3
Training loss: 2.5129592418670654
Validation loss: 1.9566499417827976

Epoch: 6| Step: 4
Training loss: 1.9418001174926758
Validation loss: 1.9686513562356271

Epoch: 6| Step: 5
Training loss: 1.8784420490264893
Validation loss: 1.9633978002814836

Epoch: 6| Step: 6
Training loss: 2.2365927696228027
Validation loss: 1.9750385425424064

Epoch: 6| Step: 7
Training loss: 2.0394725799560547
Validation loss: 1.9798379957035024

Epoch: 6| Step: 8
Training loss: 2.625683307647705
Validation loss: 1.9828620892699047

Epoch: 6| Step: 9
Training loss: 2.26983380317688
Validation loss: 1.9624920839904456

Epoch: 6| Step: 10
Training loss: 2.1552846431732178
Validation loss: 1.9780057450776458

Epoch: 6| Step: 11
Training loss: 1.4734058380126953
Validation loss: 1.978882489665862

Epoch: 6| Step: 12
Training loss: 2.3633060455322266
Validation loss: 1.9795551735867736

Epoch: 6| Step: 13
Training loss: 1.8426121473312378
Validation loss: 1.963930001822851

Epoch: 117| Step: 0
Training loss: 2.463796377182007
Validation loss: 1.9572661717732747

Epoch: 6| Step: 1
Training loss: 1.8381190299987793
Validation loss: 1.990246844548051

Epoch: 6| Step: 2
Training loss: 2.2531182765960693
Validation loss: 1.9833058990458006

Epoch: 6| Step: 3
Training loss: 2.1580324172973633
Validation loss: 1.9715089644155195

Epoch: 6| Step: 4
Training loss: 1.6697735786437988
Validation loss: 1.9802357701845066

Epoch: 6| Step: 5
Training loss: 2.741105079650879
Validation loss: 1.9806540576360558

Epoch: 6| Step: 6
Training loss: 2.3052003383636475
Validation loss: 1.9940686392527756

Epoch: 6| Step: 7
Training loss: 1.6534937620162964
Validation loss: 1.998340024743029

Epoch: 6| Step: 8
Training loss: 2.729637622833252
Validation loss: 1.9751368184243479

Epoch: 6| Step: 9
Training loss: 2.166064500808716
Validation loss: 2.004516905353915

Epoch: 6| Step: 10
Training loss: 1.9957152605056763
Validation loss: 1.9957708197255288

Epoch: 6| Step: 11
Training loss: 1.7859536409378052
Validation loss: 2.0115012481648433

Epoch: 6| Step: 12
Training loss: 2.0105841159820557
Validation loss: 2.002496809087774

Epoch: 6| Step: 13
Training loss: 2.3992233276367188
Validation loss: 1.985503488971341

Epoch: 118| Step: 0
Training loss: 1.808924913406372
Validation loss: 1.9815185813493625

Epoch: 6| Step: 1
Training loss: 2.0670251846313477
Validation loss: 1.9809584643251152

Epoch: 6| Step: 2
Training loss: 2.022894859313965
Validation loss: 1.9592781502713439

Epoch: 6| Step: 3
Training loss: 2.114739418029785
Validation loss: 1.9345742579429381

Epoch: 6| Step: 4
Training loss: 2.234541654586792
Validation loss: 1.942319768731312

Epoch: 6| Step: 5
Training loss: 1.8440618515014648
Validation loss: 1.948116111499007

Epoch: 6| Step: 6
Training loss: 1.2635650634765625
Validation loss: 1.9377828567258772

Epoch: 6| Step: 7
Training loss: 2.293030023574829
Validation loss: 1.9598338347609325

Epoch: 6| Step: 8
Training loss: 1.7568559646606445
Validation loss: 1.9338772578905987

Epoch: 6| Step: 9
Training loss: 2.7478995323181152
Validation loss: 1.9453500598989508

Epoch: 6| Step: 10
Training loss: 2.438380002975464
Validation loss: 1.925488765521716

Epoch: 6| Step: 11
Training loss: 2.537290334701538
Validation loss: 1.9207960867112683

Epoch: 6| Step: 12
Training loss: 2.472230911254883
Validation loss: 1.936409536228385

Epoch: 6| Step: 13
Training loss: 2.1591882705688477
Validation loss: 1.9461057852673274

Epoch: 119| Step: 0
Training loss: 2.440967082977295
Validation loss: 1.9205006271280267

Epoch: 6| Step: 1
Training loss: 2.161501407623291
Validation loss: 1.9427140374337473

Epoch: 6| Step: 2
Training loss: 1.7481096982955933
Validation loss: 1.9835006934340282

Epoch: 6| Step: 3
Training loss: 2.228029251098633
Validation loss: 1.9555354797711937

Epoch: 6| Step: 4
Training loss: 2.2131011486053467
Validation loss: 1.9602797031402588

Epoch: 6| Step: 5
Training loss: 2.698273181915283
Validation loss: 1.9491763294384044

Epoch: 6| Step: 6
Training loss: 1.8963521718978882
Validation loss: 1.9720905955119798

Epoch: 6| Step: 7
Training loss: 2.5216479301452637
Validation loss: 1.9701866001211188

Epoch: 6| Step: 8
Training loss: 1.5342953205108643
Validation loss: 1.9467702450290802

Epoch: 6| Step: 9
Training loss: 2.043567657470703
Validation loss: 1.957667209768808

Epoch: 6| Step: 10
Training loss: 2.07240891456604
Validation loss: 1.9740323994749336

Epoch: 6| Step: 11
Training loss: 2.206605911254883
Validation loss: 2.0018698118066274

Epoch: 6| Step: 12
Training loss: 2.1526670455932617
Validation loss: 1.9826103359140375

Epoch: 6| Step: 13
Training loss: 2.0101442337036133
Validation loss: 2.0008309272027787

Epoch: 120| Step: 0
Training loss: 2.450181484222412
Validation loss: 1.9763079099757697

Epoch: 6| Step: 1
Training loss: 1.8329036235809326
Validation loss: 1.9899325806607482

Epoch: 6| Step: 2
Training loss: 2.136927604675293
Validation loss: 1.9780024379812262

Epoch: 6| Step: 3
Training loss: 2.5368595123291016
Validation loss: 2.0046367491445234

Epoch: 6| Step: 4
Training loss: 2.4640915393829346
Validation loss: 1.996461922122586

Epoch: 6| Step: 5
Training loss: 1.7319254875183105
Validation loss: 2.0015335941827423

Epoch: 6| Step: 6
Training loss: 2.457981586456299
Validation loss: 1.9656230377894577

Epoch: 6| Step: 7
Training loss: 2.176605224609375
Validation loss: 2.012208254106583

Epoch: 6| Step: 8
Training loss: 2.1322133541107178
Validation loss: 2.008118421800675

Epoch: 6| Step: 9
Training loss: 2.3915319442749023
Validation loss: 1.979809034255243

Epoch: 6| Step: 10
Training loss: 2.2842354774475098
Validation loss: 1.986227027831539

Epoch: 6| Step: 11
Training loss: 1.7280155420303345
Validation loss: 1.9850503244707662

Epoch: 6| Step: 12
Training loss: 1.2561695575714111
Validation loss: 1.9745101556983045

Epoch: 6| Step: 13
Training loss: 2.0763967037200928
Validation loss: 1.9885423849987727

Epoch: 121| Step: 0
Training loss: 1.294783592224121
Validation loss: 1.9777987926237044

Epoch: 6| Step: 1
Training loss: 2.5498318672180176
Validation loss: 1.968608151199997

Epoch: 6| Step: 2
Training loss: 2.2041594982147217
Validation loss: 1.9824830037291332

Epoch: 6| Step: 3
Training loss: 2.5681684017181396
Validation loss: 1.9802039695042435

Epoch: 6| Step: 4
Training loss: 1.9283941984176636
Validation loss: 1.9815927038910568

Epoch: 6| Step: 5
Training loss: 1.8334639072418213
Validation loss: 1.967672981241698

Epoch: 6| Step: 6
Training loss: 2.0021424293518066
Validation loss: 1.9914116115980252

Epoch: 6| Step: 7
Training loss: 1.6871099472045898
Validation loss: 1.9461790105347991

Epoch: 6| Step: 8
Training loss: 1.9249205589294434
Validation loss: 1.963431522410403

Epoch: 6| Step: 9
Training loss: 2.3875627517700195
Validation loss: 1.9509149136081818

Epoch: 6| Step: 10
Training loss: 2.501694679260254
Validation loss: 1.983303593051049

Epoch: 6| Step: 11
Training loss: 1.7710424661636353
Validation loss: 1.9623800349491898

Epoch: 6| Step: 12
Training loss: 1.7937915325164795
Validation loss: 1.9667394468861241

Epoch: 6| Step: 13
Training loss: 3.9693307876586914
Validation loss: 1.9659611819892802

Epoch: 122| Step: 0
Training loss: 2.7015275955200195
Validation loss: 1.9449299907171598

Epoch: 6| Step: 1
Training loss: 2.6085944175720215
Validation loss: 1.9751823525274954

Epoch: 6| Step: 2
Training loss: 1.8770077228546143
Validation loss: 1.9703085153333602

Epoch: 6| Step: 3
Training loss: 1.4609256982803345
Validation loss: 1.9557326891088997

Epoch: 6| Step: 4
Training loss: 1.8205010890960693
Validation loss: 1.9493541614983672

Epoch: 6| Step: 5
Training loss: 2.2112884521484375
Validation loss: 1.966322031072391

Epoch: 6| Step: 6
Training loss: 1.560262680053711
Validation loss: 1.9368583169034732

Epoch: 6| Step: 7
Training loss: 2.5224509239196777
Validation loss: 1.9438285161090154

Epoch: 6| Step: 8
Training loss: 2.526975631713867
Validation loss: 1.950881564488975

Epoch: 6| Step: 9
Training loss: 1.676863670349121
Validation loss: 1.9463250367872176

Epoch: 6| Step: 10
Training loss: 1.6697098016738892
Validation loss: 1.9463136478136944

Epoch: 6| Step: 11
Training loss: 2.1512110233306885
Validation loss: 1.959965055988681

Epoch: 6| Step: 12
Training loss: 2.676386594772339
Validation loss: 1.9664857720816007

Epoch: 6| Step: 13
Training loss: 1.9950599670410156
Validation loss: 1.9897489163183397

Epoch: 123| Step: 0
Training loss: 2.3447346687316895
Validation loss: 1.957828842183595

Epoch: 6| Step: 1
Training loss: 1.8677088022232056
Validation loss: 1.9730472705697502

Epoch: 6| Step: 2
Training loss: 1.9912259578704834
Validation loss: 1.9772421275415728

Epoch: 6| Step: 3
Training loss: 2.4461348056793213
Validation loss: 1.9724852320968465

Epoch: 6| Step: 4
Training loss: 2.333651065826416
Validation loss: 1.9298023459731892

Epoch: 6| Step: 5
Training loss: 1.7127331495285034
Validation loss: 1.943620665099031

Epoch: 6| Step: 6
Training loss: 2.627713203430176
Validation loss: 1.9569398805659304

Epoch: 6| Step: 7
Training loss: 2.401538372039795
Validation loss: 1.9478949821123512

Epoch: 6| Step: 8
Training loss: 1.9575674533843994
Validation loss: 1.9498360387740596

Epoch: 6| Step: 9
Training loss: 2.3866190910339355
Validation loss: 1.955106339147014

Epoch: 6| Step: 10
Training loss: 1.6264837980270386
Validation loss: 1.969950770819059

Epoch: 6| Step: 11
Training loss: 1.9854071140289307
Validation loss: 1.9548583299882951

Epoch: 6| Step: 12
Training loss: 2.7093234062194824
Validation loss: 1.9479504028956096

Epoch: 6| Step: 13
Training loss: 0.9758405685424805
Validation loss: 1.9421307502254364

Epoch: 124| Step: 0
Training loss: 2.689849853515625
Validation loss: 1.9600665812851281

Epoch: 6| Step: 1
Training loss: 2.6951332092285156
Validation loss: 1.955489973868093

Epoch: 6| Step: 2
Training loss: 1.7386926412582397
Validation loss: 1.9680399766532324

Epoch: 6| Step: 3
Training loss: 2.0664892196655273
Validation loss: 1.9717351287923834

Epoch: 6| Step: 4
Training loss: 1.1339236497879028
Validation loss: 1.9635446276716007

Epoch: 6| Step: 5
Training loss: 2.0997474193573
Validation loss: 1.9775415902496667

Epoch: 6| Step: 6
Training loss: 1.5505897998809814
Validation loss: 1.9728747439640824

Epoch: 6| Step: 7
Training loss: 2.851750612258911
Validation loss: 1.9795797883823354

Epoch: 6| Step: 8
Training loss: 1.7471070289611816
Validation loss: 1.9885126595856042

Epoch: 6| Step: 9
Training loss: 1.8548026084899902
Validation loss: 1.9682905673980713

Epoch: 6| Step: 10
Training loss: 2.195142984390259
Validation loss: 1.9835131219638291

Epoch: 6| Step: 11
Training loss: 2.5809006690979004
Validation loss: 1.9829828405892977

Epoch: 6| Step: 12
Training loss: 2.183014154434204
Validation loss: 1.9715673615855556

Epoch: 6| Step: 13
Training loss: 2.1177895069122314
Validation loss: 1.9911220945337766

Epoch: 125| Step: 0
Training loss: 1.940239429473877
Validation loss: 1.9693765755622619

Epoch: 6| Step: 1
Training loss: 2.4920005798339844
Validation loss: 1.9892706512123026

Epoch: 6| Step: 2
Training loss: 2.644491672515869
Validation loss: 1.9909105736722228

Epoch: 6| Step: 3
Training loss: 2.6415889263153076
Validation loss: 1.9841563855448077

Epoch: 6| Step: 4
Training loss: 2.2617154121398926
Validation loss: 1.979361980192123

Epoch: 6| Step: 5
Training loss: 2.5507142543792725
Validation loss: 1.9916173335044616

Epoch: 6| Step: 6
Training loss: 1.7797397375106812
Validation loss: 1.99268477706499

Epoch: 6| Step: 7
Training loss: 1.7256582975387573
Validation loss: 1.996584669236214

Epoch: 6| Step: 8
Training loss: 1.9443213939666748
Validation loss: 1.9915496790280907

Epoch: 6| Step: 9
Training loss: 1.6108198165893555
Validation loss: 2.005824932488062

Epoch: 6| Step: 10
Training loss: 2.454193353652954
Validation loss: 2.007198305540187

Epoch: 6| Step: 11
Training loss: 1.8869818449020386
Validation loss: 2.0014847940014255

Epoch: 6| Step: 12
Training loss: 1.8887845277786255
Validation loss: 1.9908725138633483

Epoch: 6| Step: 13
Training loss: 1.5949345827102661
Validation loss: 1.989644968381492

Epoch: 126| Step: 0
Training loss: 2.0921707153320312
Validation loss: 1.9806636969248455

Epoch: 6| Step: 1
Training loss: 1.9419068098068237
Validation loss: 2.0017764952874955

Epoch: 6| Step: 2
Training loss: 1.9633491039276123
Validation loss: 1.9717773263172438

Epoch: 6| Step: 3
Training loss: 2.2427988052368164
Validation loss: 1.9709017635673605

Epoch: 6| Step: 4
Training loss: 1.9074057340621948
Validation loss: 1.9962090523012224

Epoch: 6| Step: 5
Training loss: 2.662569284439087
Validation loss: 1.9720355208202074

Epoch: 6| Step: 6
Training loss: 2.2268683910369873
Validation loss: 1.972721997127738

Epoch: 6| Step: 7
Training loss: 2.5011849403381348
Validation loss: 1.9679280404121644

Epoch: 6| Step: 8
Training loss: 1.6010477542877197
Validation loss: 1.9528578955640075

Epoch: 6| Step: 9
Training loss: 2.4033775329589844
Validation loss: 1.9604452348524524

Epoch: 6| Step: 10
Training loss: 2.2178380489349365
Validation loss: 1.9709613964121828

Epoch: 6| Step: 11
Training loss: 1.9809515476226807
Validation loss: 1.9534485135027158

Epoch: 6| Step: 12
Training loss: 1.9262306690216064
Validation loss: 1.9655586993822487

Epoch: 6| Step: 13
Training loss: 1.9350123405456543
Validation loss: 1.9669036583233905

Epoch: 127| Step: 0
Training loss: 1.9757509231567383
Validation loss: 1.978937913012761

Epoch: 6| Step: 1
Training loss: 2.7134766578674316
Validation loss: 1.9396387184819868

Epoch: 6| Step: 2
Training loss: 2.010359048843384
Validation loss: 1.954045718716037

Epoch: 6| Step: 3
Training loss: 1.9250383377075195
Validation loss: 1.9614144525220316

Epoch: 6| Step: 4
Training loss: 2.6121110916137695
Validation loss: 1.9473855418543662

Epoch: 6| Step: 5
Training loss: 1.8734092712402344
Validation loss: 1.9667064310401998

Epoch: 6| Step: 6
Training loss: 1.988663673400879
Validation loss: 1.9484640616242603

Epoch: 6| Step: 7
Training loss: 1.7564752101898193
Validation loss: 1.9344394617183234

Epoch: 6| Step: 8
Training loss: 2.5179924964904785
Validation loss: 1.9628611174962853

Epoch: 6| Step: 9
Training loss: 2.483229160308838
Validation loss: 1.9479201673179545

Epoch: 6| Step: 10
Training loss: 1.5219266414642334
Validation loss: 1.9377250671386719

Epoch: 6| Step: 11
Training loss: 1.4492841958999634
Validation loss: 1.9385468729080693

Epoch: 6| Step: 12
Training loss: 2.306386709213257
Validation loss: 1.9471892426090855

Epoch: 6| Step: 13
Training loss: 2.561551570892334
Validation loss: 1.9668611659798572

Epoch: 128| Step: 0
Training loss: 1.8600654602050781
Validation loss: 1.9674329206507692

Epoch: 6| Step: 1
Training loss: 1.6825001239776611
Validation loss: 1.956843432559762

Epoch: 6| Step: 2
Training loss: 2.2107255458831787
Validation loss: 1.932950754319468

Epoch: 6| Step: 3
Training loss: 2.391436815261841
Validation loss: 1.9757876844816311

Epoch: 6| Step: 4
Training loss: 1.9168305397033691
Validation loss: 1.9664808063096897

Epoch: 6| Step: 5
Training loss: 1.5534327030181885
Validation loss: 1.960141779274069

Epoch: 6| Step: 6
Training loss: 2.1628684997558594
Validation loss: 1.9819413320992583

Epoch: 6| Step: 7
Training loss: 2.721330404281616
Validation loss: 1.9811535932684456

Epoch: 6| Step: 8
Training loss: 2.1336212158203125
Validation loss: 1.9751911394057735

Epoch: 6| Step: 9
Training loss: 2.3665618896484375
Validation loss: 1.984750122152349

Epoch: 6| Step: 10
Training loss: 2.2802979946136475
Validation loss: 1.97790031151105

Epoch: 6| Step: 11
Training loss: 2.2264184951782227
Validation loss: 1.9660131469849618

Epoch: 6| Step: 12
Training loss: 2.1579480171203613
Validation loss: 2.0005377646415465

Epoch: 6| Step: 13
Training loss: 1.8670005798339844
Validation loss: 1.9609925875099756

Epoch: 129| Step: 0
Training loss: 1.5178649425506592
Validation loss: 1.9782092801986202

Epoch: 6| Step: 1
Training loss: 2.7891697883605957
Validation loss: 1.9918739103501844

Epoch: 6| Step: 2
Training loss: 1.8802566528320312
Validation loss: 1.9766242542574484

Epoch: 6| Step: 3
Training loss: 2.492405891418457
Validation loss: 1.9928754042553645

Epoch: 6| Step: 4
Training loss: 1.740664005279541
Validation loss: 1.9933255116144817

Epoch: 6| Step: 5
Training loss: 2.2128448486328125
Validation loss: 1.9607485904488513

Epoch: 6| Step: 6
Training loss: 2.3991668224334717
Validation loss: 1.9742093137515488

Epoch: 6| Step: 7
Training loss: 2.1385436058044434
Validation loss: 1.9832420477303125

Epoch: 6| Step: 8
Training loss: 2.2639517784118652
Validation loss: 1.9595405670904344

Epoch: 6| Step: 9
Training loss: 2.0355138778686523
Validation loss: 1.9475952399674283

Epoch: 6| Step: 10
Training loss: 1.812584400177002
Validation loss: 1.9630930346827353

Epoch: 6| Step: 11
Training loss: 1.8418042659759521
Validation loss: 1.9705897018473635

Epoch: 6| Step: 12
Training loss: 2.3624086380004883
Validation loss: 1.9685591164455618

Epoch: 6| Step: 13
Training loss: 2.36529803276062
Validation loss: 1.9681619495473883

Epoch: 130| Step: 0
Training loss: 2.148411750793457
Validation loss: 1.9405970342697636

Epoch: 6| Step: 1
Training loss: 2.06272029876709
Validation loss: 1.9553601434153896

Epoch: 6| Step: 2
Training loss: 2.268768548965454
Validation loss: 1.9642746217789189

Epoch: 6| Step: 3
Training loss: 1.591357707977295
Validation loss: 1.9918936529467184

Epoch: 6| Step: 4
Training loss: 2.2615694999694824
Validation loss: 1.9978953535838793

Epoch: 6| Step: 5
Training loss: 2.3518645763397217
Validation loss: 1.9832193569470478

Epoch: 6| Step: 6
Training loss: 2.2144322395324707
Validation loss: 1.9882287197215582

Epoch: 6| Step: 7
Training loss: 1.4678595066070557
Validation loss: 1.9692209882120932

Epoch: 6| Step: 8
Training loss: 2.8888394832611084
Validation loss: 2.0036063091729277

Epoch: 6| Step: 9
Training loss: 2.062912940979004
Validation loss: 1.9720738677568332

Epoch: 6| Step: 10
Training loss: 2.630897045135498
Validation loss: 1.9850358873285272

Epoch: 6| Step: 11
Training loss: 1.7044028043746948
Validation loss: 1.9860133406936482

Epoch: 6| Step: 12
Training loss: 1.7613641023635864
Validation loss: 1.9732809092408867

Epoch: 6| Step: 13
Training loss: 2.053412914276123
Validation loss: 1.9796649730333717

Epoch: 131| Step: 0
Training loss: 1.7411460876464844
Validation loss: 1.9776373089000743

Epoch: 6| Step: 1
Training loss: 2.4886956214904785
Validation loss: 1.9653798021296018

Epoch: 6| Step: 2
Training loss: 2.2032628059387207
Validation loss: 1.9513038871108845

Epoch: 6| Step: 3
Training loss: 2.609602451324463
Validation loss: 1.9493301837675032

Epoch: 6| Step: 4
Training loss: 1.9791269302368164
Validation loss: 1.961300419222924

Epoch: 6| Step: 5
Training loss: 1.9647389650344849
Validation loss: 1.981810974818404

Epoch: 6| Step: 6
Training loss: 1.637331485748291
Validation loss: 1.948338606024301

Epoch: 6| Step: 7
Training loss: 1.9785699844360352
Validation loss: 1.9855293637962752

Epoch: 6| Step: 8
Training loss: 2.785717487335205
Validation loss: 1.9787902934576875

Epoch: 6| Step: 9
Training loss: 2.416928291320801
Validation loss: 1.9878035283857776

Epoch: 6| Step: 10
Training loss: 1.6600940227508545
Validation loss: 1.9770057457749561

Epoch: 6| Step: 11
Training loss: 1.6959127187728882
Validation loss: 1.9594599803288777

Epoch: 6| Step: 12
Training loss: 1.5736011266708374
Validation loss: 1.967280109723409

Epoch: 6| Step: 13
Training loss: 3.0781891345977783
Validation loss: 1.9729037348942091

Epoch: 132| Step: 0
Training loss: 2.4452781677246094
Validation loss: 1.9808661809531591

Epoch: 6| Step: 1
Training loss: 2.7576301097869873
Validation loss: 1.9559262926860521

Epoch: 6| Step: 2
Training loss: 1.4189050197601318
Validation loss: 1.970396412316189

Epoch: 6| Step: 3
Training loss: 2.080838441848755
Validation loss: 1.960006421612155

Epoch: 6| Step: 4
Training loss: 1.7087949514389038
Validation loss: 1.9771352211634319

Epoch: 6| Step: 5
Training loss: 1.9511404037475586
Validation loss: 1.9710688283366542

Epoch: 6| Step: 6
Training loss: 1.5519742965698242
Validation loss: 1.9417402334110712

Epoch: 6| Step: 7
Training loss: 2.0375633239746094
Validation loss: 1.9758344093958538

Epoch: 6| Step: 8
Training loss: 2.4369897842407227
Validation loss: 1.9640700227470809

Epoch: 6| Step: 9
Training loss: 2.2776873111724854
Validation loss: 1.9577546350417598

Epoch: 6| Step: 10
Training loss: 1.7558667659759521
Validation loss: 1.9655842909248926

Epoch: 6| Step: 11
Training loss: 2.933567523956299
Validation loss: 1.9540578767817507

Epoch: 6| Step: 12
Training loss: 1.7445331811904907
Validation loss: 1.981602999471849

Epoch: 6| Step: 13
Training loss: 2.615767240524292
Validation loss: 1.944303850973806

Epoch: 133| Step: 0
Training loss: 1.7771377563476562
Validation loss: 1.9675505135648994

Epoch: 6| Step: 1
Training loss: 1.591843605041504
Validation loss: 1.9417669491101337

Epoch: 6| Step: 2
Training loss: 2.460993766784668
Validation loss: 1.9446310407371932

Epoch: 6| Step: 3
Training loss: 1.8026182651519775
Validation loss: 1.9429886879459504

Epoch: 6| Step: 4
Training loss: 1.4574310779571533
Validation loss: 1.9697006133294874

Epoch: 6| Step: 5
Training loss: 2.643200159072876
Validation loss: 1.9465024458464755

Epoch: 6| Step: 6
Training loss: 2.025012969970703
Validation loss: 1.95462812659561

Epoch: 6| Step: 7
Training loss: 2.2515270709991455
Validation loss: 1.9601966232381842

Epoch: 6| Step: 8
Training loss: 2.270876407623291
Validation loss: 1.9690922947340115

Epoch: 6| Step: 9
Training loss: 1.923363447189331
Validation loss: 1.9699022282836258

Epoch: 6| Step: 10
Training loss: 2.7058591842651367
Validation loss: 1.9804147879282634

Epoch: 6| Step: 11
Training loss: 1.9533804655075073
Validation loss: 1.9570305860170754

Epoch: 6| Step: 12
Training loss: 2.2238612174987793
Validation loss: 1.9657212790622507

Epoch: 6| Step: 13
Training loss: 2.755603790283203
Validation loss: 1.9636488832453245

Epoch: 134| Step: 0
Training loss: 2.2336103916168213
Validation loss: 1.952203712155742

Epoch: 6| Step: 1
Training loss: 3.0737767219543457
Validation loss: 1.9884168024986022

Epoch: 6| Step: 2
Training loss: 1.8990613222122192
Validation loss: 1.9923084179560344

Epoch: 6| Step: 3
Training loss: 2.3042752742767334
Validation loss: 1.9887482581600067

Epoch: 6| Step: 4
Training loss: 2.073367118835449
Validation loss: 2.0120870554318993

Epoch: 6| Step: 5
Training loss: 2.3306055068969727
Validation loss: 2.0102167026970976

Epoch: 6| Step: 6
Training loss: 2.2221925258636475
Validation loss: 2.0511106598761772

Epoch: 6| Step: 7
Training loss: 2.0616965293884277
Validation loss: 2.0413465128150037

Epoch: 6| Step: 8
Training loss: 2.1331069469451904
Validation loss: 2.0138212903853385

Epoch: 6| Step: 9
Training loss: 1.4191999435424805
Validation loss: 2.020811182196422

Epoch: 6| Step: 10
Training loss: 2.1467838287353516
Validation loss: 2.0136783225561983

Epoch: 6| Step: 11
Training loss: 2.320204019546509
Validation loss: 1.986784419705791

Epoch: 6| Step: 12
Training loss: 1.9432315826416016
Validation loss: 2.0306955152942288

Epoch: 6| Step: 13
Training loss: 1.1890323162078857
Validation loss: 2.036581729048042

Epoch: 135| Step: 0
Training loss: 1.5450788736343384
Validation loss: 2.022553566963442

Epoch: 6| Step: 1
Training loss: 2.186075210571289
Validation loss: 1.9841748578574068

Epoch: 6| Step: 2
Training loss: 1.9958782196044922
Validation loss: 1.9606655336195422

Epoch: 6| Step: 3
Training loss: 2.3087897300720215
Validation loss: 1.9502756108519852

Epoch: 6| Step: 4
Training loss: 1.695054531097412
Validation loss: 1.974579272731658

Epoch: 6| Step: 5
Training loss: 1.9847426414489746
Validation loss: 1.946294678154812

Epoch: 6| Step: 6
Training loss: 2.601083278656006
Validation loss: 1.9557445767105266

Epoch: 6| Step: 7
Training loss: 1.82956862449646
Validation loss: 1.96304839657199

Epoch: 6| Step: 8
Training loss: 2.1103224754333496
Validation loss: 1.9358879584138111

Epoch: 6| Step: 9
Training loss: 2.6813371181488037
Validation loss: 1.948838186520402

Epoch: 6| Step: 10
Training loss: 2.0245437622070312
Validation loss: 1.9542684375598867

Epoch: 6| Step: 11
Training loss: 2.007180690765381
Validation loss: 1.9441838277283536

Epoch: 6| Step: 12
Training loss: 2.310734748840332
Validation loss: 1.9314690764232347

Epoch: 6| Step: 13
Training loss: 2.5264456272125244
Validation loss: 1.9462216682331537

Epoch: 136| Step: 0
Training loss: 1.646661639213562
Validation loss: 1.9756074361903693

Epoch: 6| Step: 1
Training loss: 1.8412448167800903
Validation loss: 1.9341748363228255

Epoch: 6| Step: 2
Training loss: 2.1125545501708984
Validation loss: 1.952656833074426

Epoch: 6| Step: 3
Training loss: 1.954774260520935
Validation loss: 1.9239135724242016

Epoch: 6| Step: 4
Training loss: 2.299248218536377
Validation loss: 1.9439087657518284

Epoch: 6| Step: 5
Training loss: 2.5806233882904053
Validation loss: 1.9453076521555583

Epoch: 6| Step: 6
Training loss: 2.1237194538116455
Validation loss: 1.9219405215273622

Epoch: 6| Step: 7
Training loss: 1.9361088275909424
Validation loss: 1.944604940311883

Epoch: 6| Step: 8
Training loss: 2.316568613052368
Validation loss: 1.924222223220333

Epoch: 6| Step: 9
Training loss: 1.6382707357406616
Validation loss: 1.9784121167275213

Epoch: 6| Step: 10
Training loss: 2.235928773880005
Validation loss: 1.9622304413908271

Epoch: 6| Step: 11
Training loss: 2.308058738708496
Validation loss: 1.9881073967103036

Epoch: 6| Step: 12
Training loss: 2.5473475456237793
Validation loss: 1.9502698759878836

Epoch: 6| Step: 13
Training loss: 1.3862829208374023
Validation loss: 1.9583828910704582

Epoch: 137| Step: 0
Training loss: 2.8380126953125
Validation loss: 1.9954450925191243

Epoch: 6| Step: 1
Training loss: 2.117020845413208
Validation loss: 1.979559749685308

Epoch: 6| Step: 2
Training loss: 1.988553524017334
Validation loss: 2.0042841088387275

Epoch: 6| Step: 3
Training loss: 2.016022205352783
Validation loss: 1.9896161517789286

Epoch: 6| Step: 4
Training loss: 2.5262887477874756
Validation loss: 1.9995388087405954

Epoch: 6| Step: 5
Training loss: 2.016984462738037
Validation loss: 1.9797637949707687

Epoch: 6| Step: 6
Training loss: 1.698647141456604
Validation loss: 1.9599281011089202

Epoch: 6| Step: 7
Training loss: 1.9857449531555176
Validation loss: 1.9750883502344931

Epoch: 6| Step: 8
Training loss: 2.309417247772217
Validation loss: 1.9936811718889462

Epoch: 6| Step: 9
Training loss: 2.125391960144043
Validation loss: 1.9926593060134559

Epoch: 6| Step: 10
Training loss: 1.5356171131134033
Validation loss: 1.951491859651381

Epoch: 6| Step: 11
Training loss: 2.4213132858276367
Validation loss: 1.9782206563539402

Epoch: 6| Step: 12
Training loss: 1.610476016998291
Validation loss: 1.989141523197133

Epoch: 6| Step: 13
Training loss: 1.8781365156173706
Validation loss: 1.9848071900747155

Epoch: 138| Step: 0
Training loss: 2.429110527038574
Validation loss: 1.971672922052363

Epoch: 6| Step: 1
Training loss: 1.461073398590088
Validation loss: 1.9707099007021995

Epoch: 6| Step: 2
Training loss: 1.7757560014724731
Validation loss: 1.9692577431278844

Epoch: 6| Step: 3
Training loss: 2.106560468673706
Validation loss: 1.9825959205627441

Epoch: 6| Step: 4
Training loss: 2.314427614212036
Validation loss: 1.9732124190176688

Epoch: 6| Step: 5
Training loss: 2.3663666248321533
Validation loss: 1.9626620815646263

Epoch: 6| Step: 6
Training loss: 1.9784228801727295
Validation loss: 1.9787713020078597

Epoch: 6| Step: 7
Training loss: 1.8771343231201172
Validation loss: 1.9828003657761442

Epoch: 6| Step: 8
Training loss: 2.159940481185913
Validation loss: 1.9746324503293602

Epoch: 6| Step: 9
Training loss: 2.224593162536621
Validation loss: 1.9845543279442737

Epoch: 6| Step: 10
Training loss: 2.0912556648254395
Validation loss: 1.971100289334533

Epoch: 6| Step: 11
Training loss: 2.3675360679626465
Validation loss: 1.9575983631995417

Epoch: 6| Step: 12
Training loss: 1.9300673007965088
Validation loss: 1.946964971480831

Epoch: 6| Step: 13
Training loss: 1.8992146253585815
Validation loss: 1.9552933695495769

Epoch: 139| Step: 0
Training loss: 1.4132771492004395
Validation loss: 1.9533575273329211

Epoch: 6| Step: 1
Training loss: 2.5514018535614014
Validation loss: 1.9622421046738983

Epoch: 6| Step: 2
Training loss: 1.4507875442504883
Validation loss: 1.9690502561548704

Epoch: 6| Step: 3
Training loss: 2.372882604598999
Validation loss: 1.9696542268158288

Epoch: 6| Step: 4
Training loss: 1.7626357078552246
Validation loss: 1.9490115283637919

Epoch: 6| Step: 5
Training loss: 1.8233036994934082
Validation loss: 1.9618603183377175

Epoch: 6| Step: 6
Training loss: 1.8655471801757812
Validation loss: 1.9657564035025976

Epoch: 6| Step: 7
Training loss: 2.458103656768799
Validation loss: 1.98047605124853

Epoch: 6| Step: 8
Training loss: 2.3007712364196777
Validation loss: 1.9950554755426222

Epoch: 6| Step: 9
Training loss: 1.840916633605957
Validation loss: 1.965612780663275

Epoch: 6| Step: 10
Training loss: 1.6856911182403564
Validation loss: 1.963991177979336

Epoch: 6| Step: 11
Training loss: 3.076967239379883
Validation loss: 1.9639721019293672

Epoch: 6| Step: 12
Training loss: 2.1315205097198486
Validation loss: 1.9912720098290393

Epoch: 6| Step: 13
Training loss: 2.8603498935699463
Validation loss: 1.9732665772079139

Epoch: 140| Step: 0
Training loss: 1.833635687828064
Validation loss: 1.9886938192511117

Epoch: 6| Step: 1
Training loss: 2.292419672012329
Validation loss: 1.9828999362966067

Epoch: 6| Step: 2
Training loss: 1.8362596035003662
Validation loss: 1.9864277147477674

Epoch: 6| Step: 3
Training loss: 1.9898245334625244
Validation loss: 1.9931735941158828

Epoch: 6| Step: 4
Training loss: 2.2851362228393555
Validation loss: 2.0116419689629668

Epoch: 6| Step: 5
Training loss: 2.223236560821533
Validation loss: 2.018723121253393

Epoch: 6| Step: 6
Training loss: 2.166670799255371
Validation loss: 2.0238060079595095

Epoch: 6| Step: 7
Training loss: 2.546088695526123
Validation loss: 2.0251132262650358

Epoch: 6| Step: 8
Training loss: 1.8469406366348267
Validation loss: 2.0235214784581173

Epoch: 6| Step: 9
Training loss: 1.8907806873321533
Validation loss: 2.045494028317031

Epoch: 6| Step: 10
Training loss: 1.769468069076538
Validation loss: 1.9819843871619112

Epoch: 6| Step: 11
Training loss: 1.674350619316101
Validation loss: 2.023465202700707

Epoch: 6| Step: 12
Training loss: 2.427708625793457
Validation loss: 2.028282234745641

Epoch: 6| Step: 13
Training loss: 2.460648536682129
Validation loss: 2.0436792373657227

Epoch: 141| Step: 0
Training loss: 1.9655308723449707
Validation loss: 2.0051792001211517

Epoch: 6| Step: 1
Training loss: 2.013631820678711
Validation loss: 1.9991203802888111

Epoch: 6| Step: 2
Training loss: 2.328068733215332
Validation loss: 1.991688028458626

Epoch: 6| Step: 3
Training loss: 1.7144376039505005
Validation loss: 1.9672883890008415

Epoch: 6| Step: 4
Training loss: 2.1886863708496094
Validation loss: 1.963855463971374

Epoch: 6| Step: 5
Training loss: 2.4599785804748535
Validation loss: 1.9724630809599353

Epoch: 6| Step: 6
Training loss: 1.8089931011199951
Validation loss: 1.9671964927386212

Epoch: 6| Step: 7
Training loss: 2.0847890377044678
Validation loss: 1.9358761772032707

Epoch: 6| Step: 8
Training loss: 2.17049503326416
Validation loss: 1.970555361881051

Epoch: 6| Step: 9
Training loss: 1.7117445468902588
Validation loss: 1.9400158825741018

Epoch: 6| Step: 10
Training loss: 1.8070075511932373
Validation loss: 1.9613593342483684

Epoch: 6| Step: 11
Training loss: 1.7916698455810547
Validation loss: 1.9835210166951662

Epoch: 6| Step: 12
Training loss: 2.6471805572509766
Validation loss: 1.9524223907019502

Epoch: 6| Step: 13
Training loss: 2.9249162673950195
Validation loss: 1.9545019390762493

Epoch: 142| Step: 0
Training loss: 2.289008140563965
Validation loss: 1.9691399989589569

Epoch: 6| Step: 1
Training loss: 2.117946147918701
Validation loss: 1.9426834416645828

Epoch: 6| Step: 2
Training loss: 2.040767192840576
Validation loss: 1.9561395388777538

Epoch: 6| Step: 3
Training loss: 1.8816938400268555
Validation loss: 1.9697035166525072

Epoch: 6| Step: 4
Training loss: 2.901029586791992
Validation loss: 1.987193110168621

Epoch: 6| Step: 5
Training loss: 1.3137438297271729
Validation loss: 1.9830524254870672

Epoch: 6| Step: 6
Training loss: 2.1703755855560303
Validation loss: 1.960966440939134

Epoch: 6| Step: 7
Training loss: 1.5363256931304932
Validation loss: 1.9439244629234396

Epoch: 6| Step: 8
Training loss: 2.019791841506958
Validation loss: 1.988889810859516

Epoch: 6| Step: 9
Training loss: 2.460495948791504
Validation loss: 1.9563418895967546

Epoch: 6| Step: 10
Training loss: 2.343735694885254
Validation loss: 1.9626442078621156

Epoch: 6| Step: 11
Training loss: 2.5424728393554688
Validation loss: 1.9730046244077786

Epoch: 6| Step: 12
Training loss: 1.6857495307922363
Validation loss: 1.9673208882731776

Epoch: 6| Step: 13
Training loss: 1.7778269052505493
Validation loss: 1.9631064091959307

Epoch: 143| Step: 0
Training loss: 1.7524504661560059
Validation loss: 1.9491512339602235

Epoch: 6| Step: 1
Training loss: 2.0477635860443115
Validation loss: 1.964906269504178

Epoch: 6| Step: 2
Training loss: 1.970739483833313
Validation loss: 1.9551630430324103

Epoch: 6| Step: 3
Training loss: 1.9731193780899048
Validation loss: 1.9835431524502334

Epoch: 6| Step: 4
Training loss: 1.758745789527893
Validation loss: 1.9584102643433439

Epoch: 6| Step: 5
Training loss: 2.3317813873291016
Validation loss: 1.9682503002946095

Epoch: 6| Step: 6
Training loss: 2.4401445388793945
Validation loss: 1.9473591312285392

Epoch: 6| Step: 7
Training loss: 3.216610908508301
Validation loss: 1.9705488117792274

Epoch: 6| Step: 8
Training loss: 1.711570143699646
Validation loss: 1.9553103395687637

Epoch: 6| Step: 9
Training loss: 2.243628740310669
Validation loss: 1.9926590688766972

Epoch: 6| Step: 10
Training loss: 2.3581414222717285
Validation loss: 1.9737035843633837

Epoch: 6| Step: 11
Training loss: 1.5116522312164307
Validation loss: 1.9859471282651346

Epoch: 6| Step: 12
Training loss: 1.6652334928512573
Validation loss: 1.9892772910415486

Epoch: 6| Step: 13
Training loss: 2.2515463829040527
Validation loss: 1.9701880203780306

Epoch: 144| Step: 0
Training loss: 1.9987369775772095
Validation loss: 1.9743129104696295

Epoch: 6| Step: 1
Training loss: 1.7352559566497803
Validation loss: 2.0184952802555536

Epoch: 6| Step: 2
Training loss: 1.7863962650299072
Validation loss: 1.9648654268633934

Epoch: 6| Step: 3
Training loss: 2.487518548965454
Validation loss: 1.9654501176649524

Epoch: 6| Step: 4
Training loss: 2.233537197113037
Validation loss: 2.028010452947309

Epoch: 6| Step: 5
Training loss: 1.306880235671997
Validation loss: 1.9965431651761454

Epoch: 6| Step: 6
Training loss: 1.9000446796417236
Validation loss: 2.01657433407281

Epoch: 6| Step: 7
Training loss: 2.045961618423462
Validation loss: 1.9767012493584746

Epoch: 6| Step: 8
Training loss: 2.705940008163452
Validation loss: 1.9975498927536832

Epoch: 6| Step: 9
Training loss: 1.7019538879394531
Validation loss: 2.005270383691275

Epoch: 6| Step: 10
Training loss: 2.5319061279296875
Validation loss: 1.974151196018342

Epoch: 6| Step: 11
Training loss: 1.8300412893295288
Validation loss: 2.0016905517988306

Epoch: 6| Step: 12
Training loss: 2.509718656539917
Validation loss: 2.004968712406774

Epoch: 6| Step: 13
Training loss: 2.174055814743042
Validation loss: 2.0009676487215105

Epoch: 145| Step: 0
Training loss: 1.5231521129608154
Validation loss: 1.975177131673341

Epoch: 6| Step: 1
Training loss: 1.728513479232788
Validation loss: 1.961833123237856

Epoch: 6| Step: 2
Training loss: 1.6760625839233398
Validation loss: 1.9799305533850065

Epoch: 6| Step: 3
Training loss: 1.748754858970642
Validation loss: 1.962334276527487

Epoch: 6| Step: 4
Training loss: 2.1219711303710938
Validation loss: 1.9659758460137151

Epoch: 6| Step: 5
Training loss: 2.5716075897216797
Validation loss: 1.9603763165012482

Epoch: 6| Step: 6
Training loss: 1.929551362991333
Validation loss: 1.9547804914494997

Epoch: 6| Step: 7
Training loss: 2.332759380340576
Validation loss: 1.9991081683866438

Epoch: 6| Step: 8
Training loss: 2.269929885864258
Validation loss: 1.9565199818662418

Epoch: 6| Step: 9
Training loss: 2.448122024536133
Validation loss: 1.975737884480466

Epoch: 6| Step: 10
Training loss: 2.5415971279144287
Validation loss: 1.9638478909769366

Epoch: 6| Step: 11
Training loss: 2.275148868560791
Validation loss: 1.9694700599998556

Epoch: 6| Step: 12
Training loss: 1.5452089309692383
Validation loss: 1.964454448351296

Epoch: 6| Step: 13
Training loss: 2.2752108573913574
Validation loss: 1.9478504696199972

Epoch: 146| Step: 0
Training loss: 1.4554345607757568
Validation loss: 1.9647344978906776

Epoch: 6| Step: 1
Training loss: 2.5496983528137207
Validation loss: 1.9690029595487861

Epoch: 6| Step: 2
Training loss: 2.336974620819092
Validation loss: 1.9571726258083055

Epoch: 6| Step: 3
Training loss: 2.1129190921783447
Validation loss: 1.9698034935100104

Epoch: 6| Step: 4
Training loss: 1.7024662494659424
Validation loss: 1.9719557146872244

Epoch: 6| Step: 5
Training loss: 1.5762104988098145
Validation loss: 1.9625785043162685

Epoch: 6| Step: 6
Training loss: 2.0309700965881348
Validation loss: 1.934260663165841

Epoch: 6| Step: 7
Training loss: 2.150515079498291
Validation loss: 1.947292891881799

Epoch: 6| Step: 8
Training loss: 2.1328513622283936
Validation loss: 1.9578998986110892

Epoch: 6| Step: 9
Training loss: 2.0161168575286865
Validation loss: 1.9720322162874284

Epoch: 6| Step: 10
Training loss: 1.736433982849121
Validation loss: 1.9646947640244679

Epoch: 6| Step: 11
Training loss: 2.211719512939453
Validation loss: 2.000895852683693

Epoch: 6| Step: 12
Training loss: 2.9822287559509277
Validation loss: 1.9736622982127692

Epoch: 6| Step: 13
Training loss: 1.9044126272201538
Validation loss: 1.9750036052478257

Epoch: 147| Step: 0
Training loss: 2.33743953704834
Validation loss: 1.9910685080353931

Epoch: 6| Step: 1
Training loss: 2.737269639968872
Validation loss: 1.9949611694582048

Epoch: 6| Step: 2
Training loss: 2.7603139877319336
Validation loss: 2.0206271858625513

Epoch: 6| Step: 3
Training loss: 2.031869411468506
Validation loss: 1.9712433866275254

Epoch: 6| Step: 4
Training loss: 1.7526345252990723
Validation loss: 1.959981192824661

Epoch: 6| Step: 5
Training loss: 1.448254108428955
Validation loss: 1.9824098156344505

Epoch: 6| Step: 6
Training loss: 1.9392666816711426
Validation loss: 1.9696871183251823

Epoch: 6| Step: 7
Training loss: 1.3484858274459839
Validation loss: 1.9691886645491405

Epoch: 6| Step: 8
Training loss: 2.7877349853515625
Validation loss: 1.9669374663342711

Epoch: 6| Step: 9
Training loss: 1.6570736169815063
Validation loss: 1.982175765498992

Epoch: 6| Step: 10
Training loss: 2.034259557723999
Validation loss: 1.9610458830351472

Epoch: 6| Step: 11
Training loss: 2.4098472595214844
Validation loss: 1.9418737696063133

Epoch: 6| Step: 12
Training loss: 2.1700756549835205
Validation loss: 1.987966223429608

Epoch: 6| Step: 13
Training loss: 1.036546230316162
Validation loss: 1.9556958931748585

Epoch: 148| Step: 0
Training loss: 2.0442490577697754
Validation loss: 2.0017067078621156

Epoch: 6| Step: 1
Training loss: 1.9729046821594238
Validation loss: 1.966051427266931

Epoch: 6| Step: 2
Training loss: 1.8729052543640137
Validation loss: 1.9694269652007728

Epoch: 6| Step: 3
Training loss: 1.668595790863037
Validation loss: 1.9902594935509466

Epoch: 6| Step: 4
Training loss: 1.5417673587799072
Validation loss: 1.976653334914997

Epoch: 6| Step: 5
Training loss: 2.6383016109466553
Validation loss: 1.9777018985440653

Epoch: 6| Step: 6
Training loss: 2.1464080810546875
Validation loss: 1.9644767417702624

Epoch: 6| Step: 7
Training loss: 1.5592374801635742
Validation loss: 1.9744972093130952

Epoch: 6| Step: 8
Training loss: 2.013833999633789
Validation loss: 1.973870651696318

Epoch: 6| Step: 9
Training loss: 2.7686877250671387
Validation loss: 1.969789005094959

Epoch: 6| Step: 10
Training loss: 1.7798733711242676
Validation loss: 1.954329372734152

Epoch: 6| Step: 11
Training loss: 2.811358690261841
Validation loss: 1.9675783675204042

Epoch: 6| Step: 12
Training loss: 1.8252737522125244
Validation loss: 1.96543502038525

Epoch: 6| Step: 13
Training loss: 2.290250301361084
Validation loss: 1.9759321674223869

Epoch: 149| Step: 0
Training loss: 2.4659790992736816
Validation loss: 1.9455154865018782

Epoch: 6| Step: 1
Training loss: 2.0169079303741455
Validation loss: 1.9714209507870417

Epoch: 6| Step: 2
Training loss: 2.463512897491455
Validation loss: 1.9657076635668356

Epoch: 6| Step: 3
Training loss: 2.915358781814575
Validation loss: 1.9502945830745082

Epoch: 6| Step: 4
Training loss: 2.3643178939819336
Validation loss: 1.9651079024038007

Epoch: 6| Step: 5
Training loss: 1.846581220626831
Validation loss: 1.946935103785607

Epoch: 6| Step: 6
Training loss: 1.710194706916809
Validation loss: 1.9926843950825353

Epoch: 6| Step: 7
Training loss: 1.6540696620941162
Validation loss: 1.9689540350308983

Epoch: 6| Step: 8
Training loss: 2.7053003311157227
Validation loss: 1.932131395545057

Epoch: 6| Step: 9
Training loss: 1.9141448736190796
Validation loss: 1.9683354836638256

Epoch: 6| Step: 10
Training loss: 2.1841495037078857
Validation loss: 1.9494476395268594

Epoch: 6| Step: 11
Training loss: 0.8041679263114929
Validation loss: 1.9797258095074726

Epoch: 6| Step: 12
Training loss: 2.2319858074188232
Validation loss: 1.9583853957473591

Epoch: 6| Step: 13
Training loss: 1.0465435981750488
Validation loss: 1.959697638788531

Epoch: 150| Step: 0
Training loss: 1.2793188095092773
Validation loss: 1.9713637918554328

Epoch: 6| Step: 1
Training loss: 1.3120723962783813
Validation loss: 1.9447180827458699

Epoch: 6| Step: 2
Training loss: 1.9925060272216797
Validation loss: 1.9802611284358527

Epoch: 6| Step: 3
Training loss: 1.7048606872558594
Validation loss: 1.9595193555278163

Epoch: 6| Step: 4
Training loss: 2.542257785797119
Validation loss: 1.9326540270159323

Epoch: 6| Step: 5
Training loss: 2.1364083290100098
Validation loss: 1.944667407261428

Epoch: 6| Step: 6
Training loss: 2.5196473598480225
Validation loss: 1.9730010596654748

Epoch: 6| Step: 7
Training loss: 2.6511270999908447
Validation loss: 1.9831107303660402

Epoch: 6| Step: 8
Training loss: 2.486767530441284
Validation loss: 1.9723034699757893

Epoch: 6| Step: 9
Training loss: 1.3443149328231812
Validation loss: 1.9562278434794436

Epoch: 6| Step: 10
Training loss: 1.9777193069458008
Validation loss: 1.9485224113669446

Epoch: 6| Step: 11
Training loss: 2.4247007369995117
Validation loss: 1.9708780024641304

Epoch: 6| Step: 12
Training loss: 2.2214815616607666
Validation loss: 1.9829442988159836

Epoch: 6| Step: 13
Training loss: 2.319941520690918
Validation loss: 1.9860723480101554

Epoch: 151| Step: 0
Training loss: 1.7803118228912354
Validation loss: 1.9631477222647717

Epoch: 6| Step: 1
Training loss: 2.8857614994049072
Validation loss: 1.9838417153204642

Epoch: 6| Step: 2
Training loss: 2.1092722415924072
Validation loss: 2.0021334463550198

Epoch: 6| Step: 3
Training loss: 2.8545632362365723
Validation loss: 1.9776362372982887

Epoch: 6| Step: 4
Training loss: 2.1596527099609375
Validation loss: 1.9612930949016283

Epoch: 6| Step: 5
Training loss: 1.744201898574829
Validation loss: 1.9699807474690099

Epoch: 6| Step: 6
Training loss: 1.8526896238327026
Validation loss: 1.981963780618483

Epoch: 6| Step: 7
Training loss: 2.426726818084717
Validation loss: 1.9564490997663109

Epoch: 6| Step: 8
Training loss: 2.4256277084350586
Validation loss: 1.9875263347420642

Epoch: 6| Step: 9
Training loss: 1.843719482421875
Validation loss: 1.9762738763645131

Epoch: 6| Step: 10
Training loss: 1.4309258460998535
Validation loss: 1.9677438735961914

Epoch: 6| Step: 11
Training loss: 1.4830310344696045
Validation loss: 1.9799796612032

Epoch: 6| Step: 12
Training loss: 1.979680061340332
Validation loss: 1.9578609235825077

Epoch: 6| Step: 13
Training loss: 1.7869848012924194
Validation loss: 1.9725391710958173

Epoch: 152| Step: 0
Training loss: 2.2446632385253906
Validation loss: 1.9866636196772258

Epoch: 6| Step: 1
Training loss: 2.114215135574341
Validation loss: 1.9930244927765222

Epoch: 6| Step: 2
Training loss: 2.0067148208618164
Validation loss: 1.9693111527350642

Epoch: 6| Step: 3
Training loss: 1.8267385959625244
Validation loss: 2.003329587239091

Epoch: 6| Step: 4
Training loss: 1.649898886680603
Validation loss: 1.9773810063638995

Epoch: 6| Step: 5
Training loss: 2.048663854598999
Validation loss: 1.9513353532360447

Epoch: 6| Step: 6
Training loss: 2.799908399581909
Validation loss: 1.9627283465477727

Epoch: 6| Step: 7
Training loss: 2.447563409805298
Validation loss: 1.9898407177258564

Epoch: 6| Step: 8
Training loss: 1.452873706817627
Validation loss: 1.959905409043835

Epoch: 6| Step: 9
Training loss: 1.6124951839447021
Validation loss: 1.989402671014109

Epoch: 6| Step: 10
Training loss: 2.0171399116516113
Validation loss: 1.9596706308344358

Epoch: 6| Step: 11
Training loss: 2.0380189418792725
Validation loss: 1.9679862042909027

Epoch: 6| Step: 12
Training loss: 2.5634686946868896
Validation loss: 1.998962135725124

Epoch: 6| Step: 13
Training loss: 1.8889105319976807
Validation loss: 1.984413327709321

Epoch: 153| Step: 0
Training loss: 1.8328051567077637
Validation loss: 1.966022934964908

Epoch: 6| Step: 1
Training loss: 2.6587939262390137
Validation loss: 2.007401394587691

Epoch: 6| Step: 2
Training loss: 2.053727865219116
Validation loss: 2.009017244462044

Epoch: 6| Step: 3
Training loss: 1.8546044826507568
Validation loss: 2.00172713751434

Epoch: 6| Step: 4
Training loss: 1.7840487957000732
Validation loss: 2.007296186621471

Epoch: 6| Step: 5
Training loss: 2.4440767765045166
Validation loss: 2.0052683686697357

Epoch: 6| Step: 6
Training loss: 2.095207452774048
Validation loss: 2.007280827850424

Epoch: 6| Step: 7
Training loss: 1.6002614498138428
Validation loss: 1.9964696848264305

Epoch: 6| Step: 8
Training loss: 2.056408405303955
Validation loss: 2.012335278654611

Epoch: 6| Step: 9
Training loss: 2.6549761295318604
Validation loss: 1.9989745616912842

Epoch: 6| Step: 10
Training loss: 2.14117431640625
Validation loss: 1.9932861712671095

Epoch: 6| Step: 11
Training loss: 2.009852409362793
Validation loss: 1.9935940388710267

Epoch: 6| Step: 12
Training loss: 2.112773895263672
Validation loss: 1.9868599317407096

Epoch: 6| Step: 13
Training loss: 1.3054389953613281
Validation loss: 1.999054496006299

Epoch: 154| Step: 0
Training loss: 1.3624951839447021
Validation loss: 1.9705849668031097

Epoch: 6| Step: 1
Training loss: 1.979583978652954
Validation loss: 1.9861135303333242

Epoch: 6| Step: 2
Training loss: 2.099785566329956
Validation loss: 1.9741377189595213

Epoch: 6| Step: 3
Training loss: 2.47326922416687
Validation loss: 1.9752484342103362

Epoch: 6| Step: 4
Training loss: 1.9906723499298096
Validation loss: 1.9823171220799929

Epoch: 6| Step: 5
Training loss: 2.192065715789795
Validation loss: 1.9791485160909674

Epoch: 6| Step: 6
Training loss: 1.4172276258468628
Validation loss: 1.939539319725447

Epoch: 6| Step: 7
Training loss: 2.465348482131958
Validation loss: 1.9664628300615536

Epoch: 6| Step: 8
Training loss: 1.3928980827331543
Validation loss: 1.9406950448148994

Epoch: 6| Step: 9
Training loss: 2.7946324348449707
Validation loss: 1.9370207684014433

Epoch: 6| Step: 10
Training loss: 3.064188003540039
Validation loss: 1.962336540222168

Epoch: 6| Step: 11
Training loss: 1.8168326616287231
Validation loss: 1.9809945975580523

Epoch: 6| Step: 12
Training loss: 2.162132740020752
Validation loss: 1.9468320723502868

Epoch: 6| Step: 13
Training loss: 1.4329122304916382
Validation loss: 1.9654755310345722

Epoch: 155| Step: 0
Training loss: 1.845542550086975
Validation loss: 1.9531314680653233

Epoch: 6| Step: 1
Training loss: 2.319382667541504
Validation loss: 1.964748331936457

Epoch: 6| Step: 2
Training loss: 2.6056220531463623
Validation loss: 1.9576630412891347

Epoch: 6| Step: 3
Training loss: 2.4860317707061768
Validation loss: 1.9694673348498601

Epoch: 6| Step: 4
Training loss: 1.511763572692871
Validation loss: 1.975542482509408

Epoch: 6| Step: 5
Training loss: 2.509812355041504
Validation loss: 1.9657509378207627

Epoch: 6| Step: 6
Training loss: 1.4570564031600952
Validation loss: 1.9659470717112224

Epoch: 6| Step: 7
Training loss: 2.3098325729370117
Validation loss: 1.984191963749547

Epoch: 6| Step: 8
Training loss: 2.0838570594787598
Validation loss: 2.0037907169711207

Epoch: 6| Step: 9
Training loss: 2.2895445823669434
Validation loss: 1.9597168020022813

Epoch: 6| Step: 10
Training loss: 2.264352798461914
Validation loss: 1.9740120544228503

Epoch: 6| Step: 11
Training loss: 1.9409914016723633
Validation loss: 2.011047410708602

Epoch: 6| Step: 12
Training loss: 1.4166972637176514
Validation loss: 1.9956700571121708

Epoch: 6| Step: 13
Training loss: 1.670305848121643
Validation loss: 1.966115600319319

Epoch: 156| Step: 0
Training loss: 2.778409957885742
Validation loss: 1.9835233406354023

Epoch: 6| Step: 1
Training loss: 2.0465309619903564
Validation loss: 1.9532846020114036

Epoch: 6| Step: 2
Training loss: 2.5344796180725098
Validation loss: 1.968193910455191

Epoch: 6| Step: 3
Training loss: 1.80985689163208
Validation loss: 1.9682868603737123

Epoch: 6| Step: 4
Training loss: 2.1793465614318848
Validation loss: 1.9838103350772653

Epoch: 6| Step: 5
Training loss: 1.7702665328979492
Validation loss: 1.965775166788409

Epoch: 6| Step: 6
Training loss: 1.8814724683761597
Validation loss: 1.9758151423546575

Epoch: 6| Step: 7
Training loss: 1.7763326168060303
Validation loss: 1.9687450726826985

Epoch: 6| Step: 8
Training loss: 2.211184501647949
Validation loss: 1.9384868632080734

Epoch: 6| Step: 9
Training loss: 1.4679275751113892
Validation loss: 1.9660481278614332

Epoch: 6| Step: 10
Training loss: 2.299434185028076
Validation loss: 1.9772571632939

Epoch: 6| Step: 11
Training loss: 1.980637550354004
Validation loss: 1.9550399498272968

Epoch: 6| Step: 12
Training loss: 1.8875281810760498
Validation loss: 1.9511410933668896

Epoch: 6| Step: 13
Training loss: 2.390674114227295
Validation loss: 1.958323565862512

Epoch: 157| Step: 0
Training loss: 2.502005100250244
Validation loss: 1.9489128307629657

Epoch: 6| Step: 1
Training loss: 2.129671335220337
Validation loss: 2.007633411756126

Epoch: 6| Step: 2
Training loss: 1.3920148611068726
Validation loss: 1.9526561780642437

Epoch: 6| Step: 3
Training loss: 1.9804545640945435
Validation loss: 1.965268288889239

Epoch: 6| Step: 4
Training loss: 1.5277847051620483
Validation loss: 1.9569174320467058

Epoch: 6| Step: 5
Training loss: 2.07950496673584
Validation loss: 1.9632236649913173

Epoch: 6| Step: 6
Training loss: 1.9883149862289429
Validation loss: 1.9959638990381712

Epoch: 6| Step: 7
Training loss: 1.9652063846588135
Validation loss: 1.9554676778854863

Epoch: 6| Step: 8
Training loss: 2.398195743560791
Validation loss: 1.9886878690411967

Epoch: 6| Step: 9
Training loss: 1.6714147329330444
Validation loss: 1.978143185697576

Epoch: 6| Step: 10
Training loss: 2.0375566482543945
Validation loss: 1.9835312879213722

Epoch: 6| Step: 11
Training loss: 2.504075765609741
Validation loss: 1.9785363763891242

Epoch: 6| Step: 12
Training loss: 2.3316843509674072
Validation loss: 1.9757196992956183

Epoch: 6| Step: 13
Training loss: 2.432461738586426
Validation loss: 1.9690682349666473

Epoch: 158| Step: 0
Training loss: 2.2378671169281006
Validation loss: 1.9784975385153165

Epoch: 6| Step: 1
Training loss: 2.5219664573669434
Validation loss: 1.9791321703182754

Epoch: 6| Step: 2
Training loss: 2.088864326477051
Validation loss: 1.9715596681000085

Epoch: 6| Step: 3
Training loss: 2.113710880279541
Validation loss: 1.986217297533507

Epoch: 6| Step: 4
Training loss: 2.40915846824646
Validation loss: 1.9651385327821136

Epoch: 6| Step: 5
Training loss: 2.0871243476867676
Validation loss: 1.9886417952916955

Epoch: 6| Step: 6
Training loss: 2.7510480880737305
Validation loss: 1.9738147720213859

Epoch: 6| Step: 7
Training loss: 1.8875267505645752
Validation loss: 1.9815066565749466

Epoch: 6| Step: 8
Training loss: 1.7125270366668701
Validation loss: 1.971094754434401

Epoch: 6| Step: 9
Training loss: 1.5473458766937256
Validation loss: 1.9965305943642893

Epoch: 6| Step: 10
Training loss: 1.7074902057647705
Validation loss: 2.014862629675096

Epoch: 6| Step: 11
Training loss: 1.8406567573547363
Validation loss: 1.9835578100655669

Epoch: 6| Step: 12
Training loss: 2.3907346725463867
Validation loss: 1.9816793664809196

Epoch: 6| Step: 13
Training loss: 0.913975179195404
Validation loss: 1.9872634500585578

Epoch: 159| Step: 0
Training loss: 1.0298992395401
Validation loss: 1.9673221713753157

Epoch: 6| Step: 1
Training loss: 2.112424373626709
Validation loss: 1.9797015984853108

Epoch: 6| Step: 2
Training loss: 2.3471639156341553
Validation loss: 1.9566806183066419

Epoch: 6| Step: 3
Training loss: 2.9082674980163574
Validation loss: 1.9842560752745597

Epoch: 6| Step: 4
Training loss: 2.1509008407592773
Validation loss: 1.9857747888052335

Epoch: 6| Step: 5
Training loss: 1.445011854171753
Validation loss: 1.9533523474970171

Epoch: 6| Step: 6
Training loss: 2.481666088104248
Validation loss: 1.9312148299268497

Epoch: 6| Step: 7
Training loss: 1.522907018661499
Validation loss: 1.9719694596464916

Epoch: 6| Step: 8
Training loss: 2.0861239433288574
Validation loss: 1.9731944120058449

Epoch: 6| Step: 9
Training loss: 2.5564756393432617
Validation loss: 1.932506456170031

Epoch: 6| Step: 10
Training loss: 2.3834831714630127
Validation loss: 1.9567608858949395

Epoch: 6| Step: 11
Training loss: 1.8245232105255127
Validation loss: 1.9387984865455217

Epoch: 6| Step: 12
Training loss: 1.9007036685943604
Validation loss: 1.9550903945840814

Epoch: 6| Step: 13
Training loss: 2.254516124725342
Validation loss: 1.9667130503603207

Epoch: 160| Step: 0
Training loss: 1.5895051956176758
Validation loss: 1.9738768172520462

Epoch: 6| Step: 1
Training loss: 2.0835399627685547
Validation loss: 1.9793208119689778

Epoch: 6| Step: 2
Training loss: 2.06758713722229
Validation loss: 1.961904369374757

Epoch: 6| Step: 3
Training loss: 2.257847785949707
Validation loss: 1.960740408589763

Epoch: 6| Step: 4
Training loss: 2.8957676887512207
Validation loss: 1.9489690975476337

Epoch: 6| Step: 5
Training loss: 1.5700626373291016
Validation loss: 1.9816527494820215

Epoch: 6| Step: 6
Training loss: 2.4301257133483887
Validation loss: 1.9348143339157104

Epoch: 6| Step: 7
Training loss: 1.389817476272583
Validation loss: 1.9889543133397256

Epoch: 6| Step: 8
Training loss: 1.6776199340820312
Validation loss: 1.9645529408608713

Epoch: 6| Step: 9
Training loss: 2.520017623901367
Validation loss: 1.9578105095894105

Epoch: 6| Step: 10
Training loss: 1.4437217712402344
Validation loss: 1.9812164460459063

Epoch: 6| Step: 11
Training loss: 2.408135414123535
Validation loss: 1.9852917168730049

Epoch: 6| Step: 12
Training loss: 2.2659366130828857
Validation loss: 1.9789729323438419

Epoch: 6| Step: 13
Training loss: 1.6938459873199463
Validation loss: 1.9836167532910582

Epoch: 161| Step: 0
Training loss: 1.7596596479415894
Validation loss: 2.00620795578085

Epoch: 6| Step: 1
Training loss: 2.61346173286438
Validation loss: 2.0028192855978526

Epoch: 6| Step: 2
Training loss: 1.717814326286316
Validation loss: 1.9780895351081766

Epoch: 6| Step: 3
Training loss: 1.7045131921768188
Validation loss: 1.9873827888119606

Epoch: 6| Step: 4
Training loss: 1.8452341556549072
Validation loss: 2.0187511674819456

Epoch: 6| Step: 5
Training loss: 1.9622812271118164
Validation loss: 1.993728715886352

Epoch: 6| Step: 6
Training loss: 2.0845470428466797
Validation loss: 2.015335811081753

Epoch: 6| Step: 7
Training loss: 2.538400173187256
Validation loss: 2.008863156841647

Epoch: 6| Step: 8
Training loss: 2.2270169258117676
Validation loss: 2.011860578290878

Epoch: 6| Step: 9
Training loss: 1.9467726945877075
Validation loss: 1.9756016961989864

Epoch: 6| Step: 10
Training loss: 2.2941999435424805
Validation loss: 1.9913088608813543

Epoch: 6| Step: 11
Training loss: 1.717390775680542
Validation loss: 1.9797465185965262

Epoch: 6| Step: 12
Training loss: 2.2769827842712402
Validation loss: 2.00076279845289

Epoch: 6| Step: 13
Training loss: 1.9587661027908325
Validation loss: 2.0041298558635097

Epoch: 162| Step: 0
Training loss: 2.1603500843048096
Validation loss: 1.9738906275841497

Epoch: 6| Step: 1
Training loss: 2.0170626640319824
Validation loss: 1.9792542265307518

Epoch: 6| Step: 2
Training loss: 2.1932950019836426
Validation loss: 1.98881531787175

Epoch: 6| Step: 3
Training loss: 1.910168170928955
Validation loss: 1.9643824254312823

Epoch: 6| Step: 4
Training loss: 1.4986011981964111
Validation loss: 1.9790079388567197

Epoch: 6| Step: 5
Training loss: 1.3892863988876343
Validation loss: 1.9588115112755888

Epoch: 6| Step: 6
Training loss: 2.055731773376465
Validation loss: 1.9689768475870932

Epoch: 6| Step: 7
Training loss: 2.2647523880004883
Validation loss: 1.9577429679132277

Epoch: 6| Step: 8
Training loss: 2.0015709400177
Validation loss: 1.9493601296537666

Epoch: 6| Step: 9
Training loss: 2.2206430435180664
Validation loss: 1.952407108840122

Epoch: 6| Step: 10
Training loss: 2.680119514465332
Validation loss: 1.9573084039072837

Epoch: 6| Step: 11
Training loss: 2.2517013549804688
Validation loss: 1.9554348735399143

Epoch: 6| Step: 12
Training loss: 2.1226134300231934
Validation loss: 1.9972897293747112

Epoch: 6| Step: 13
Training loss: 1.6999812126159668
Validation loss: 1.9628471648821266

Epoch: 163| Step: 0
Training loss: 1.8234295845031738
Validation loss: 1.9566430930168397

Epoch: 6| Step: 1
Training loss: 2.1434578895568848
Validation loss: 1.953598891535113

Epoch: 6| Step: 2
Training loss: 2.266940116882324
Validation loss: 1.967195414727734

Epoch: 6| Step: 3
Training loss: 1.9563055038452148
Validation loss: 1.9387264713164298

Epoch: 6| Step: 4
Training loss: 2.174351215362549
Validation loss: 1.9659839907000143

Epoch: 6| Step: 5
Training loss: 1.4957804679870605
Validation loss: 1.9542090956882765

Epoch: 6| Step: 6
Training loss: 1.4554755687713623
Validation loss: 1.957240649448928

Epoch: 6| Step: 7
Training loss: 2.4605236053466797
Validation loss: 1.9503932101752168

Epoch: 6| Step: 8
Training loss: 2.321887493133545
Validation loss: 1.9508451800192557

Epoch: 6| Step: 9
Training loss: 1.8617167472839355
Validation loss: 1.9674727160443541

Epoch: 6| Step: 10
Training loss: 2.273890495300293
Validation loss: 1.9916052023569744

Epoch: 6| Step: 11
Training loss: 1.963509202003479
Validation loss: 1.95038769578421

Epoch: 6| Step: 12
Training loss: 2.066133975982666
Validation loss: 1.9954141442493727

Epoch: 6| Step: 13
Training loss: 2.1848366260528564
Validation loss: 1.9650064335074475

Epoch: 164| Step: 0
Training loss: 1.9274444580078125
Validation loss: 1.9583622563269831

Epoch: 6| Step: 1
Training loss: 1.612675428390503
Validation loss: 1.9543929817855998

Epoch: 6| Step: 2
Training loss: 1.9845091104507446
Validation loss: 1.9448297113500617

Epoch: 6| Step: 3
Training loss: 2.8861849308013916
Validation loss: 1.9873072178133073

Epoch: 6| Step: 4
Training loss: 2.332409620285034
Validation loss: 1.957623016449713

Epoch: 6| Step: 5
Training loss: 2.588346242904663
Validation loss: 1.9728102222565682

Epoch: 6| Step: 6
Training loss: 2.1259303092956543
Validation loss: 1.9822578481448594

Epoch: 6| Step: 7
Training loss: 1.6587004661560059
Validation loss: 1.9455106745484054

Epoch: 6| Step: 8
Training loss: 2.0637764930725098
Validation loss: 1.9862847764004943

Epoch: 6| Step: 9
Training loss: 1.7268226146697998
Validation loss: 1.969298324277324

Epoch: 6| Step: 10
Training loss: 2.6970579624176025
Validation loss: 1.968859826364825

Epoch: 6| Step: 11
Training loss: 1.3572487831115723
Validation loss: 1.960389910205718

Epoch: 6| Step: 12
Training loss: 1.6711452007293701
Validation loss: 1.99652390069859

Epoch: 6| Step: 13
Training loss: 1.5836224555969238
Validation loss: 2.000281059613792

Epoch: 165| Step: 0
Training loss: 1.3210389614105225
Validation loss: 1.9714625035562823

Epoch: 6| Step: 1
Training loss: 1.4961469173431396
Validation loss: 1.9834788922340638

Epoch: 6| Step: 2
Training loss: 1.1552482843399048
Validation loss: 2.009089405818652

Epoch: 6| Step: 3
Training loss: 2.4176313877105713
Validation loss: 1.9900506875848258

Epoch: 6| Step: 4
Training loss: 2.7926855087280273
Validation loss: 1.9586971729032454

Epoch: 6| Step: 5
Training loss: 1.9258397817611694
Validation loss: 1.952287103540154

Epoch: 6| Step: 6
Training loss: 2.057435989379883
Validation loss: 1.966503571438533

Epoch: 6| Step: 7
Training loss: 2.7396841049194336
Validation loss: 1.980404717947847

Epoch: 6| Step: 8
Training loss: 2.2575502395629883
Validation loss: 1.9760276271450905

Epoch: 6| Step: 9
Training loss: 1.8326302766799927
Validation loss: 1.98112835679003

Epoch: 6| Step: 10
Training loss: 2.7590742111206055
Validation loss: 1.955155836638584

Epoch: 6| Step: 11
Training loss: 2.1480560302734375
Validation loss: 1.9632099777139642

Epoch: 6| Step: 12
Training loss: 1.9566726684570312
Validation loss: 1.9852812905465402

Epoch: 6| Step: 13
Training loss: 1.3335318565368652
Validation loss: 1.9723359205389535

Epoch: 166| Step: 0
Training loss: 1.8067296743392944
Validation loss: 1.9749120281588646

Epoch: 6| Step: 1
Training loss: 1.9444546699523926
Validation loss: 2.003521196303829

Epoch: 6| Step: 2
Training loss: 1.4905993938446045
Validation loss: 1.9653934791523924

Epoch: 6| Step: 3
Training loss: 2.084482431411743
Validation loss: 1.9602809157422794

Epoch: 6| Step: 4
Training loss: 2.923818588256836
Validation loss: 1.9570578734079997

Epoch: 6| Step: 5
Training loss: 2.4362287521362305
Validation loss: 1.9706315750716834

Epoch: 6| Step: 6
Training loss: 2.1739869117736816
Validation loss: 1.9720487158785585

Epoch: 6| Step: 7
Training loss: 2.1946258544921875
Validation loss: 1.9618243658414452

Epoch: 6| Step: 8
Training loss: 1.7046409845352173
Validation loss: 1.9635703871327062

Epoch: 6| Step: 9
Training loss: 2.231934070587158
Validation loss: 1.9595599943591702

Epoch: 6| Step: 10
Training loss: 1.5696823596954346
Validation loss: 1.9762939945344002

Epoch: 6| Step: 11
Training loss: 1.7209298610687256
Validation loss: 1.99999390878985

Epoch: 6| Step: 12
Training loss: 1.8877203464508057
Validation loss: 1.9621565470131495

Epoch: 6| Step: 13
Training loss: 2.4458987712860107
Validation loss: 1.9711895014650078

Epoch: 167| Step: 0
Training loss: 2.4023876190185547
Validation loss: 1.97506377004808

Epoch: 6| Step: 1
Training loss: 1.008193850517273
Validation loss: 1.9814628721565328

Epoch: 6| Step: 2
Training loss: 1.7112090587615967
Validation loss: 2.0025185474785427

Epoch: 6| Step: 3
Training loss: 2.468559741973877
Validation loss: 1.972614178093531

Epoch: 6| Step: 4
Training loss: 2.6690049171447754
Validation loss: 1.9695883694515433

Epoch: 6| Step: 5
Training loss: 2.331578254699707
Validation loss: 1.994682893958143

Epoch: 6| Step: 6
Training loss: 1.7551703453063965
Validation loss: 1.9547699830865348

Epoch: 6| Step: 7
Training loss: 2.4951019287109375
Validation loss: 1.9728363649819487

Epoch: 6| Step: 8
Training loss: 2.182633399963379
Validation loss: 1.9861642634996803

Epoch: 6| Step: 9
Training loss: 1.8176994323730469
Validation loss: 1.988571156737625

Epoch: 6| Step: 10
Training loss: 1.971449613571167
Validation loss: 1.9915784097486926

Epoch: 6| Step: 11
Training loss: 1.829609990119934
Validation loss: 1.9638980460423294

Epoch: 6| Step: 12
Training loss: 1.775461196899414
Validation loss: 1.962988374053791

Epoch: 6| Step: 13
Training loss: 2.107668161392212
Validation loss: 1.9897159325179232

Epoch: 168| Step: 0
Training loss: 2.5181119441986084
Validation loss: 1.972673875029369

Epoch: 6| Step: 1
Training loss: 1.7106609344482422
Validation loss: 1.9817676595462266

Epoch: 6| Step: 2
Training loss: 1.964362382888794
Validation loss: 1.9743044914737824

Epoch: 6| Step: 3
Training loss: 2.209352970123291
Validation loss: 1.9972409791843866

Epoch: 6| Step: 4
Training loss: 1.9643514156341553
Validation loss: 1.9616464286722162

Epoch: 6| Step: 5
Training loss: 2.1561012268066406
Validation loss: 1.9200869350023166

Epoch: 6| Step: 6
Training loss: 2.1594951152801514
Validation loss: 1.9618532606350478

Epoch: 6| Step: 7
Training loss: 2.1288223266601562
Validation loss: 1.967377862622661

Epoch: 6| Step: 8
Training loss: 2.2575368881225586
Validation loss: 1.9693887438825382

Epoch: 6| Step: 9
Training loss: 1.7911570072174072
Validation loss: 1.9655987242216706

Epoch: 6| Step: 10
Training loss: 2.0152926445007324
Validation loss: 1.981800192145891

Epoch: 6| Step: 11
Training loss: 2.0940301418304443
Validation loss: 1.9654086751322593

Epoch: 6| Step: 12
Training loss: 2.192638397216797
Validation loss: 1.9715948822677776

Epoch: 6| Step: 13
Training loss: 1.168302297592163
Validation loss: 1.9910922896477483

Epoch: 169| Step: 0
Training loss: 2.230159282684326
Validation loss: 1.9975614829729962

Epoch: 6| Step: 1
Training loss: 1.6554630994796753
Validation loss: 1.9737305794992754

Epoch: 6| Step: 2
Training loss: 2.182534694671631
Validation loss: 1.9504622336356872

Epoch: 6| Step: 3
Training loss: 1.4986298084259033
Validation loss: 1.9764307416895384

Epoch: 6| Step: 4
Training loss: 2.8666749000549316
Validation loss: 1.9842572212219238

Epoch: 6| Step: 5
Training loss: 1.951881766319275
Validation loss: 2.0399057916415635

Epoch: 6| Step: 6
Training loss: 2.0946593284606934
Validation loss: 1.9838948198544082

Epoch: 6| Step: 7
Training loss: 1.8674585819244385
Validation loss: 2.0122930567751647

Epoch: 6| Step: 8
Training loss: 1.7627291679382324
Validation loss: 2.025172051563058

Epoch: 6| Step: 9
Training loss: 1.8150737285614014
Validation loss: 2.0062070059519943

Epoch: 6| Step: 10
Training loss: 2.6268324851989746
Validation loss: 1.9883091193373486

Epoch: 6| Step: 11
Training loss: 1.9842723608016968
Validation loss: 2.003166014148343

Epoch: 6| Step: 12
Training loss: 1.8032113313674927
Validation loss: 2.001898316926854

Epoch: 6| Step: 13
Training loss: 1.5451488494873047
Validation loss: 1.997744478205199

Epoch: 170| Step: 0
Training loss: 2.5390963554382324
Validation loss: 1.9897598887002597

Epoch: 6| Step: 1
Training loss: 2.2172815799713135
Validation loss: 1.9910148651369157

Epoch: 6| Step: 2
Training loss: 2.028981924057007
Validation loss: 1.9731094298824188

Epoch: 6| Step: 3
Training loss: 2.268376588821411
Validation loss: 1.9851956931493615

Epoch: 6| Step: 4
Training loss: 2.2079076766967773
Validation loss: 1.9631920604295627

Epoch: 6| Step: 5
Training loss: 1.8634274005889893
Validation loss: 1.9779701156000937

Epoch: 6| Step: 6
Training loss: 2.4268407821655273
Validation loss: 2.0050313806021087

Epoch: 6| Step: 7
Training loss: 2.064054489135742
Validation loss: 2.011663882963119

Epoch: 6| Step: 8
Training loss: 2.066330909729004
Validation loss: 1.9900703430175781

Epoch: 6| Step: 9
Training loss: 1.9629392623901367
Validation loss: 1.9708596198789534

Epoch: 6| Step: 10
Training loss: 1.3308839797973633
Validation loss: 1.9809641171527166

Epoch: 6| Step: 11
Training loss: 2.5053820610046387
Validation loss: 1.9892488320668538

Epoch: 6| Step: 12
Training loss: 1.3611118793487549
Validation loss: 1.9863228669730566

Epoch: 6| Step: 13
Training loss: 1.0450451374053955
Validation loss: 1.9834384097847888

Epoch: 171| Step: 0
Training loss: 2.3922059535980225
Validation loss: 1.9720062901896815

Epoch: 6| Step: 1
Training loss: 2.370818614959717
Validation loss: 1.9861452489770868

Epoch: 6| Step: 2
Training loss: 1.4726026058197021
Validation loss: 2.000898563733665

Epoch: 6| Step: 3
Training loss: 1.829293966293335
Validation loss: 1.9831583243544384

Epoch: 6| Step: 4
Training loss: 1.8675808906555176
Validation loss: 1.9696853737677298

Epoch: 6| Step: 5
Training loss: 2.3760619163513184
Validation loss: 1.9822840382975917

Epoch: 6| Step: 6
Training loss: 2.0718703269958496
Validation loss: 1.9689131423991213

Epoch: 6| Step: 7
Training loss: 2.284519672393799
Validation loss: 1.990275126631542

Epoch: 6| Step: 8
Training loss: 1.8590093851089478
Validation loss: 1.9760259659059587

Epoch: 6| Step: 9
Training loss: 2.297630548477173
Validation loss: 1.9557867973081526

Epoch: 6| Step: 10
Training loss: 1.2237420082092285
Validation loss: 1.9805145802036408

Epoch: 6| Step: 11
Training loss: 2.301060438156128
Validation loss: 1.9962796857280116

Epoch: 6| Step: 12
Training loss: 1.9423785209655762
Validation loss: 1.987026160763156

Epoch: 6| Step: 13
Training loss: 2.146422863006592
Validation loss: 1.95441726715334

Epoch: 172| Step: 0
Training loss: 2.1721959114074707
Validation loss: 1.9612561028490785

Epoch: 6| Step: 1
Training loss: 1.8177690505981445
Validation loss: 1.982562800889374

Epoch: 6| Step: 2
Training loss: 1.981630802154541
Validation loss: 1.964160010378848

Epoch: 6| Step: 3
Training loss: 2.159878730773926
Validation loss: 1.9668488810139317

Epoch: 6| Step: 4
Training loss: 1.779914140701294
Validation loss: 1.9619689321005216

Epoch: 6| Step: 5
Training loss: 2.667942523956299
Validation loss: 1.970383580012988

Epoch: 6| Step: 6
Training loss: 2.053050994873047
Validation loss: 1.9510276984143

Epoch: 6| Step: 7
Training loss: 1.7221922874450684
Validation loss: 1.9603998802041496

Epoch: 6| Step: 8
Training loss: 1.7545291185379028
Validation loss: 1.9677745552473171

Epoch: 6| Step: 9
Training loss: 2.0511224269866943
Validation loss: 1.9525573766359718

Epoch: 6| Step: 10
Training loss: 1.7823021411895752
Validation loss: 1.9569591245343607

Epoch: 6| Step: 11
Training loss: 2.255451202392578
Validation loss: 1.9513882296059721

Epoch: 6| Step: 12
Training loss: 1.9345176219940186
Validation loss: 1.9425904135550223

Epoch: 6| Step: 13
Training loss: 2.1132023334503174
Validation loss: 1.9625566069797804

Epoch: 173| Step: 0
Training loss: 2.3576467037200928
Validation loss: 1.9281522868781962

Epoch: 6| Step: 1
Training loss: 1.6194936037063599
Validation loss: 1.9624111960011144

Epoch: 6| Step: 2
Training loss: 1.497424602508545
Validation loss: 1.9527391208115445

Epoch: 6| Step: 3
Training loss: 2.4581711292266846
Validation loss: 2.01091754821039

Epoch: 6| Step: 4
Training loss: 2.7096548080444336
Validation loss: 1.9344494547895206

Epoch: 6| Step: 5
Training loss: 1.9388046264648438
Validation loss: 1.9262016114368234

Epoch: 6| Step: 6
Training loss: 2.031261682510376
Validation loss: 1.98673620916182

Epoch: 6| Step: 7
Training loss: 1.9401202201843262
Validation loss: 1.9702936987723074

Epoch: 6| Step: 8
Training loss: 1.9341663122177124
Validation loss: 1.9836816428810038

Epoch: 6| Step: 9
Training loss: 1.699049949645996
Validation loss: 1.9843290467416086

Epoch: 6| Step: 10
Training loss: 2.0103368759155273
Validation loss: 1.9936576492042952

Epoch: 6| Step: 11
Training loss: 2.555492401123047
Validation loss: 1.997140202471005

Epoch: 6| Step: 12
Training loss: 1.9317386150360107
Validation loss: 1.9645596114538049

Epoch: 6| Step: 13
Training loss: 1.4519201517105103
Validation loss: 1.9719497683227702

Epoch: 174| Step: 0
Training loss: 2.2382633686065674
Validation loss: 1.9989752256742088

Epoch: 6| Step: 1
Training loss: 2.3701443672180176
Validation loss: 1.968423496010483

Epoch: 6| Step: 2
Training loss: 2.2583045959472656
Validation loss: 1.9795850861457087

Epoch: 6| Step: 3
Training loss: 2.186173915863037
Validation loss: 1.971571663374542

Epoch: 6| Step: 4
Training loss: 2.008812189102173
Validation loss: 1.9871078063082952

Epoch: 6| Step: 5
Training loss: 2.1231236457824707
Validation loss: 1.9886916119565246

Epoch: 6| Step: 6
Training loss: 2.221607208251953
Validation loss: 1.985966169705955

Epoch: 6| Step: 7
Training loss: 1.6606180667877197
Validation loss: 1.9478401612210017

Epoch: 6| Step: 8
Training loss: 1.4841508865356445
Validation loss: 1.9959659166233514

Epoch: 6| Step: 9
Training loss: 2.24885892868042
Validation loss: 1.9776038482624998

Epoch: 6| Step: 10
Training loss: 1.8150310516357422
Validation loss: 1.9615322582183345

Epoch: 6| Step: 11
Training loss: 1.9652740955352783
Validation loss: 1.9884261405596169

Epoch: 6| Step: 12
Training loss: 1.8048055171966553
Validation loss: 1.9974485546030023

Epoch: 6| Step: 13
Training loss: 1.7895891666412354
Validation loss: 2.000004227443408

Epoch: 175| Step: 0
Training loss: 1.855067491531372
Validation loss: 1.9889565693434847

Epoch: 6| Step: 1
Training loss: 2.817286491394043
Validation loss: 2.002908400309983

Epoch: 6| Step: 2
Training loss: 2.4899086952209473
Validation loss: 1.9933840126119635

Epoch: 6| Step: 3
Training loss: 1.3144488334655762
Validation loss: 1.984174959121212

Epoch: 6| Step: 4
Training loss: 1.8872532844543457
Validation loss: 2.0089163664848573

Epoch: 6| Step: 5
Training loss: 1.2959725856781006
Validation loss: 2.0185620759123113

Epoch: 6| Step: 6
Training loss: 1.8632419109344482
Validation loss: 2.0170963579608547

Epoch: 6| Step: 7
Training loss: 2.017491579055786
Validation loss: 2.0074661252319173

Epoch: 6| Step: 8
Training loss: 2.3191425800323486
Validation loss: 1.9916603283215595

Epoch: 6| Step: 9
Training loss: 2.168097734451294
Validation loss: 2.0062347688982562

Epoch: 6| Step: 10
Training loss: 2.0962157249450684
Validation loss: 1.9921214093444168

Epoch: 6| Step: 11
Training loss: 2.234457492828369
Validation loss: 1.9888160728639173

Epoch: 6| Step: 12
Training loss: 1.5244762897491455
Validation loss: 1.9865490723681707

Epoch: 6| Step: 13
Training loss: 2.9523820877075195
Validation loss: 1.9976259457167758

Epoch: 176| Step: 0
Training loss: 2.0898666381835938
Validation loss: 2.0043328244199037

Epoch: 6| Step: 1
Training loss: 2.2537755966186523
Validation loss: 1.9758042635456208

Epoch: 6| Step: 2
Training loss: 2.394406318664551
Validation loss: 1.9769538987067439

Epoch: 6| Step: 3
Training loss: 2.337024450302124
Validation loss: 1.96972200434695

Epoch: 6| Step: 4
Training loss: 1.928572177886963
Validation loss: 1.9402832497832596

Epoch: 6| Step: 5
Training loss: 1.774097204208374
Validation loss: 1.9635646804686515

Epoch: 6| Step: 6
Training loss: 1.5759031772613525
Validation loss: 1.957309058917466

Epoch: 6| Step: 7
Training loss: 2.140028476715088
Validation loss: 1.9813063734321184

Epoch: 6| Step: 8
Training loss: 1.3038060665130615
Validation loss: 1.9806537653810234

Epoch: 6| Step: 9
Training loss: 2.0404720306396484
Validation loss: 1.9833831940927813

Epoch: 6| Step: 10
Training loss: 1.9253947734832764
Validation loss: 1.9777989669512677

Epoch: 6| Step: 11
Training loss: 1.7832967042922974
Validation loss: 2.0044611397609917

Epoch: 6| Step: 12
Training loss: 2.2478103637695312
Validation loss: 1.9819881518681843

Epoch: 6| Step: 13
Training loss: 2.484005928039551
Validation loss: 1.9879343317401024

Epoch: 177| Step: 0
Training loss: 1.7797577381134033
Validation loss: 1.9737652245388235

Epoch: 6| Step: 1
Training loss: 1.6115524768829346
Validation loss: 2.007689123512596

Epoch: 6| Step: 2
Training loss: 2.4095253944396973
Validation loss: 1.978039990189255

Epoch: 6| Step: 3
Training loss: 2.1808700561523438
Validation loss: 1.9914455952182892

Epoch: 6| Step: 4
Training loss: 1.5720648765563965
Validation loss: 1.9926880354522376

Epoch: 6| Step: 5
Training loss: 2.218872547149658
Validation loss: 1.9778686261946155

Epoch: 6| Step: 6
Training loss: 1.5631003379821777
Validation loss: 1.9694585569443241

Epoch: 6| Step: 7
Training loss: 2.1942081451416016
Validation loss: 1.974470656405213

Epoch: 6| Step: 8
Training loss: 2.065549850463867
Validation loss: 1.9733231682931223

Epoch: 6| Step: 9
Training loss: 1.9016526937484741
Validation loss: 1.9684942345465384

Epoch: 6| Step: 10
Training loss: 2.820848226547241
Validation loss: 1.9773583719807286

Epoch: 6| Step: 11
Training loss: 1.8113970756530762
Validation loss: 1.9947991127608924

Epoch: 6| Step: 12
Training loss: 2.1062610149383545
Validation loss: 1.9917482304316696

Epoch: 6| Step: 13
Training loss: 2.1674697399139404
Validation loss: 1.9733104551992109

Epoch: 178| Step: 0
Training loss: 2.3461525440216064
Validation loss: 1.981064522138206

Epoch: 6| Step: 1
Training loss: 1.533139944076538
Validation loss: 1.9838505765443206

Epoch: 6| Step: 2
Training loss: 1.7888617515563965
Validation loss: 1.9898241796801168

Epoch: 6| Step: 3
Training loss: 1.661697506904602
Validation loss: 1.987643159845824

Epoch: 6| Step: 4
Training loss: 2.1052775382995605
Validation loss: 1.9652014701597151

Epoch: 6| Step: 5
Training loss: 2.3732218742370605
Validation loss: 1.9663286491106915

Epoch: 6| Step: 6
Training loss: 2.864645481109619
Validation loss: 1.9604098854526397

Epoch: 6| Step: 7
Training loss: 2.236785411834717
Validation loss: 1.9796670906005367

Epoch: 6| Step: 8
Training loss: 1.6654629707336426
Validation loss: 1.9760370844153947

Epoch: 6| Step: 9
Training loss: 1.5285372734069824
Validation loss: 1.9299527637420162

Epoch: 6| Step: 10
Training loss: 1.8295702934265137
Validation loss: 1.9717409918385167

Epoch: 6| Step: 11
Training loss: 2.310530185699463
Validation loss: 1.982359560587073

Epoch: 6| Step: 12
Training loss: 1.8156177997589111
Validation loss: 1.9347051010336926

Epoch: 6| Step: 13
Training loss: 2.233567237854004
Validation loss: 1.961178861638551

Epoch: 179| Step: 0
Training loss: 1.6741331815719604
Validation loss: 1.957874805696549

Epoch: 6| Step: 1
Training loss: 2.714810371398926
Validation loss: 1.9779454226134925

Epoch: 6| Step: 2
Training loss: 2.2565724849700928
Validation loss: 1.9484779757838095

Epoch: 6| Step: 3
Training loss: 2.0510082244873047
Validation loss: 1.9762599801504483

Epoch: 6| Step: 4
Training loss: 1.8585865497589111
Validation loss: 1.9658795915624148

Epoch: 6| Step: 5
Training loss: 1.720959186553955
Validation loss: 1.9604663618149296

Epoch: 6| Step: 6
Training loss: 1.5758178234100342
Validation loss: 1.978311155432014

Epoch: 6| Step: 7
Training loss: 1.2779767513275146
Validation loss: 2.0118551100454023

Epoch: 6| Step: 8
Training loss: 2.11881422996521
Validation loss: 1.9985412295146654

Epoch: 6| Step: 9
Training loss: 2.3461482524871826
Validation loss: 1.9752883039494997

Epoch: 6| Step: 10
Training loss: 2.0038483142852783
Validation loss: 1.9763672992747316

Epoch: 6| Step: 11
Training loss: 2.13336181640625
Validation loss: 1.9765122628981067

Epoch: 6| Step: 12
Training loss: 2.142393112182617
Validation loss: 2.0052938627940353

Epoch: 6| Step: 13
Training loss: 2.1842470169067383
Validation loss: 2.0002658572248233

Epoch: 180| Step: 0
Training loss: 1.1628501415252686
Validation loss: 1.9968852689189296

Epoch: 6| Step: 1
Training loss: 2.52398681640625
Validation loss: 1.9987828167535926

Epoch: 6| Step: 2
Training loss: 2.463121175765991
Validation loss: 1.969307808465855

Epoch: 6| Step: 3
Training loss: 2.106278657913208
Validation loss: 1.9740019165059572

Epoch: 6| Step: 4
Training loss: 1.7017571926116943
Validation loss: 1.981220559407306

Epoch: 6| Step: 5
Training loss: 2.7724175453186035
Validation loss: 1.9710578405728905

Epoch: 6| Step: 6
Training loss: 1.6150085926055908
Validation loss: 1.97686392389318

Epoch: 6| Step: 7
Training loss: 2.2806015014648438
Validation loss: 1.9452804211647279

Epoch: 6| Step: 8
Training loss: 1.4100415706634521
Validation loss: 1.9788024745961672

Epoch: 6| Step: 9
Training loss: 2.169987201690674
Validation loss: 1.9728203281279533

Epoch: 6| Step: 10
Training loss: 1.6781319379806519
Validation loss: 1.9682353619606263

Epoch: 6| Step: 11
Training loss: 1.914083480834961
Validation loss: 1.953425140791042

Epoch: 6| Step: 12
Training loss: 1.6961060762405396
Validation loss: 1.990220287794708

Epoch: 6| Step: 13
Training loss: 2.9525511264801025
Validation loss: 1.9747637625663512

Epoch: 181| Step: 0
Training loss: 1.812922477722168
Validation loss: 1.9628550314134168

Epoch: 6| Step: 1
Training loss: 1.9395601749420166
Validation loss: 1.957186637386199

Epoch: 6| Step: 2
Training loss: 1.9748377799987793
Validation loss: 1.9660876092090402

Epoch: 6| Step: 3
Training loss: 2.4264259338378906
Validation loss: 1.95541182128332

Epoch: 6| Step: 4
Training loss: 2.7437503337860107
Validation loss: 1.976521611213684

Epoch: 6| Step: 5
Training loss: 1.9429994821548462
Validation loss: 1.9638093184399348

Epoch: 6| Step: 6
Training loss: 1.6343461275100708
Validation loss: 1.9623365068948397

Epoch: 6| Step: 7
Training loss: 2.121397018432617
Validation loss: 1.9570122521410707

Epoch: 6| Step: 8
Training loss: 1.6821037530899048
Validation loss: 1.9801747004191081

Epoch: 6| Step: 9
Training loss: 1.5826013088226318
Validation loss: 1.9586452553349156

Epoch: 6| Step: 10
Training loss: 1.9882097244262695
Validation loss: 1.9783816875949982

Epoch: 6| Step: 11
Training loss: 2.4539403915405273
Validation loss: 1.9779212628641436

Epoch: 6| Step: 12
Training loss: 1.8375473022460938
Validation loss: 2.0027059406362553

Epoch: 6| Step: 13
Training loss: 2.052908182144165
Validation loss: 1.985172346074094

Epoch: 182| Step: 0
Training loss: 1.5027259588241577
Validation loss: 1.9540467749359787

Epoch: 6| Step: 1
Training loss: 1.8613507747650146
Validation loss: 1.9897634162697742

Epoch: 6| Step: 2
Training loss: 2.59915828704834
Validation loss: 1.9824095643976682

Epoch: 6| Step: 3
Training loss: 1.9661648273468018
Validation loss: 1.968467031755755

Epoch: 6| Step: 4
Training loss: 1.8014063835144043
Validation loss: 1.9756445948795607

Epoch: 6| Step: 5
Training loss: 1.287759780883789
Validation loss: 1.9669284269373903

Epoch: 6| Step: 6
Training loss: 2.2830824851989746
Validation loss: 2.0169717060622347

Epoch: 6| Step: 7
Training loss: 1.6930873394012451
Validation loss: 1.9780371086571806

Epoch: 6| Step: 8
Training loss: 2.5419082641601562
Validation loss: 1.979153638244957

Epoch: 6| Step: 9
Training loss: 2.045746088027954
Validation loss: 2.0072296793742845

Epoch: 6| Step: 10
Training loss: 2.7835500240325928
Validation loss: 1.9847546867145005

Epoch: 6| Step: 11
Training loss: 1.9061144590377808
Validation loss: 2.018343840875933

Epoch: 6| Step: 12
Training loss: 1.7163231372833252
Validation loss: 1.9757659922363937

Epoch: 6| Step: 13
Training loss: 2.5256543159484863
Validation loss: 1.9994916146801365

Epoch: 183| Step: 0
Training loss: 1.7869912385940552
Validation loss: 1.9696906087219075

Epoch: 6| Step: 1
Training loss: 2.3385589122772217
Validation loss: 1.9939783183477258

Epoch: 6| Step: 2
Training loss: 1.647645115852356
Validation loss: 1.98044236757422

Epoch: 6| Step: 3
Training loss: 1.6538639068603516
Validation loss: 1.976251381699757

Epoch: 6| Step: 4
Training loss: 2.0940780639648438
Validation loss: 1.9630349810405443

Epoch: 6| Step: 5
Training loss: 2.4659485816955566
Validation loss: 1.9344730300288047

Epoch: 6| Step: 6
Training loss: 1.3579245805740356
Validation loss: 1.9650408888375888

Epoch: 6| Step: 7
Training loss: 2.8654608726501465
Validation loss: 1.9389643246127712

Epoch: 6| Step: 8
Training loss: 1.3969783782958984
Validation loss: 1.9589763213229436

Epoch: 6| Step: 9
Training loss: 2.3199939727783203
Validation loss: 1.9421043319086875

Epoch: 6| Step: 10
Training loss: 2.0948240756988525
Validation loss: 1.953485813192142

Epoch: 6| Step: 11
Training loss: 2.0979039669036865
Validation loss: 1.952654391206721

Epoch: 6| Step: 12
Training loss: 2.2483553886413574
Validation loss: 1.9598958492279053

Epoch: 6| Step: 13
Training loss: 2.1710827350616455
Validation loss: 1.9601199062921668

Epoch: 184| Step: 0
Training loss: 2.152766227722168
Validation loss: 1.9724751646800707

Epoch: 6| Step: 1
Training loss: 1.9137582778930664
Validation loss: 1.9858927162744666

Epoch: 6| Step: 2
Training loss: 2.0029613971710205
Validation loss: 1.9472207587252381

Epoch: 6| Step: 3
Training loss: 1.8461047410964966
Validation loss: 1.9671525480926677

Epoch: 6| Step: 4
Training loss: 1.4292124509811401
Validation loss: 1.9649540275655768

Epoch: 6| Step: 5
Training loss: 2.800818920135498
Validation loss: 1.982980223112209

Epoch: 6| Step: 6
Training loss: 2.113241672515869
Validation loss: 1.9866952383390037

Epoch: 6| Step: 7
Training loss: 1.9828729629516602
Validation loss: 1.9812784989674885

Epoch: 6| Step: 8
Training loss: 1.6119060516357422
Validation loss: 1.9828112420215402

Epoch: 6| Step: 9
Training loss: 2.0615782737731934
Validation loss: 1.960698458456224

Epoch: 6| Step: 10
Training loss: 1.7617824077606201
Validation loss: 1.99895994124874

Epoch: 6| Step: 11
Training loss: 1.6065306663513184
Validation loss: 1.9917197048023183

Epoch: 6| Step: 12
Training loss: 2.2053093910217285
Validation loss: 1.9776937179667975

Epoch: 6| Step: 13
Training loss: 2.4419925212860107
Validation loss: 1.9849455766780402

Epoch: 185| Step: 0
Training loss: 1.8445483446121216
Validation loss: 1.9435786303653513

Epoch: 6| Step: 1
Training loss: 2.5881199836730957
Validation loss: 1.9775326495529504

Epoch: 6| Step: 2
Training loss: 1.979793667793274
Validation loss: 1.9707733892625379

Epoch: 6| Step: 3
Training loss: 1.8682191371917725
Validation loss: 1.976851394099574

Epoch: 6| Step: 4
Training loss: 1.9753358364105225
Validation loss: 1.9995023870980868

Epoch: 6| Step: 5
Training loss: 1.7800955772399902
Validation loss: 1.9857649585252166

Epoch: 6| Step: 6
Training loss: 1.2152498960494995
Validation loss: 1.9861351815603112

Epoch: 6| Step: 7
Training loss: 2.5399765968322754
Validation loss: 1.9405362042047645

Epoch: 6| Step: 8
Training loss: 2.2811789512634277
Validation loss: 1.9941474442840905

Epoch: 6| Step: 9
Training loss: 1.7848384380340576
Validation loss: 1.9839553551007343

Epoch: 6| Step: 10
Training loss: 2.065519332885742
Validation loss: 2.0019911360997025

Epoch: 6| Step: 11
Training loss: 2.153505802154541
Validation loss: 1.9712076571679884

Epoch: 6| Step: 12
Training loss: 2.20516300201416
Validation loss: 1.9591697941544235

Epoch: 6| Step: 13
Training loss: 1.3043664693832397
Validation loss: 1.9947957851553475

Epoch: 186| Step: 0
Training loss: 2.4717960357666016
Validation loss: 1.9744985462516866

Epoch: 6| Step: 1
Training loss: 1.8233249187469482
Validation loss: 1.9730662325377106

Epoch: 6| Step: 2
Training loss: 1.7009285688400269
Validation loss: 1.9690129628745459

Epoch: 6| Step: 3
Training loss: 2.353524684906006
Validation loss: 1.959127668411501

Epoch: 6| Step: 4
Training loss: 1.8922460079193115
Validation loss: 1.9670865535736084

Epoch: 6| Step: 5
Training loss: 2.2655115127563477
Validation loss: 2.009812085859237

Epoch: 6| Step: 6
Training loss: 2.6670093536376953
Validation loss: 1.9763214395892235

Epoch: 6| Step: 7
Training loss: 1.754544734954834
Validation loss: 1.9871428807576497

Epoch: 6| Step: 8
Training loss: 2.4089934825897217
Validation loss: 1.9740033649629163

Epoch: 6| Step: 9
Training loss: 1.0699598789215088
Validation loss: 1.9754615778564124

Epoch: 6| Step: 10
Training loss: 2.2900891304016113
Validation loss: 1.9596849936310963

Epoch: 6| Step: 11
Training loss: 1.3786276578903198
Validation loss: 1.9940773620400378

Epoch: 6| Step: 12
Training loss: 1.7821921110153198
Validation loss: 1.9868273042863416

Epoch: 6| Step: 13
Training loss: 2.0766849517822266
Validation loss: 1.9811169588437645

Epoch: 187| Step: 0
Training loss: 1.4042236804962158
Validation loss: 2.0131702910187426

Epoch: 6| Step: 1
Training loss: 1.6811280250549316
Validation loss: 1.97826212580486

Epoch: 6| Step: 2
Training loss: 2.2266182899475098
Validation loss: 2.003011311254194

Epoch: 6| Step: 3
Training loss: 1.648414134979248
Validation loss: 1.9796841580380675

Epoch: 6| Step: 4
Training loss: 1.5779438018798828
Validation loss: 1.98394363926303

Epoch: 6| Step: 5
Training loss: 2.458566665649414
Validation loss: 1.9655008469858477

Epoch: 6| Step: 6
Training loss: 2.166436195373535
Validation loss: 1.9827131225216774

Epoch: 6| Step: 7
Training loss: 2.4004368782043457
Validation loss: 1.972476590064264

Epoch: 6| Step: 8
Training loss: 1.7188879251480103
Validation loss: 1.9866328098440682

Epoch: 6| Step: 9
Training loss: 2.0060861110687256
Validation loss: 1.9777782501712922

Epoch: 6| Step: 10
Training loss: 2.2947516441345215
Validation loss: 1.9663171383642382

Epoch: 6| Step: 11
Training loss: 1.9120128154754639
Validation loss: 1.9877318887300388

Epoch: 6| Step: 12
Training loss: 2.5136687755584717
Validation loss: 1.9669571871398597

Epoch: 6| Step: 13
Training loss: 1.8256765604019165
Validation loss: 1.9903534022710656

Epoch: 188| Step: 0
Training loss: 2.1499581336975098
Validation loss: 1.9651092483151344

Epoch: 6| Step: 1
Training loss: 1.7767478227615356
Validation loss: 1.9772803437325261

Epoch: 6| Step: 2
Training loss: 2.174548625946045
Validation loss: 2.0057417064584713

Epoch: 6| Step: 3
Training loss: 2.417170763015747
Validation loss: 1.9544017584093156

Epoch: 6| Step: 4
Training loss: 1.4907667636871338
Validation loss: 1.9806003903829923

Epoch: 6| Step: 5
Training loss: 1.4888956546783447
Validation loss: 1.9918538088439612

Epoch: 6| Step: 6
Training loss: 2.242448568344116
Validation loss: 1.9798691093280751

Epoch: 6| Step: 7
Training loss: 2.622300624847412
Validation loss: 1.9693105515613352

Epoch: 6| Step: 8
Training loss: 1.7012184858322144
Validation loss: 1.962424152640886

Epoch: 6| Step: 9
Training loss: 1.7510756254196167
Validation loss: 1.9596298304937219

Epoch: 6| Step: 10
Training loss: 2.0634963512420654
Validation loss: 1.9617828258904078

Epoch: 6| Step: 11
Training loss: 2.63739013671875
Validation loss: 1.9703666881848407

Epoch: 6| Step: 12
Training loss: 1.677546739578247
Validation loss: 1.9787109141708703

Epoch: 6| Step: 13
Training loss: 1.594664216041565
Validation loss: 1.9763955582854569

Epoch: 189| Step: 0
Training loss: 1.9869731664657593
Validation loss: 1.9909603288096767

Epoch: 6| Step: 1
Training loss: 1.7906379699707031
Validation loss: 1.9767655275201286

Epoch: 6| Step: 2
Training loss: 0.922950029373169
Validation loss: 1.9626363964490994

Epoch: 6| Step: 3
Training loss: 2.364487648010254
Validation loss: 1.9938819498144171

Epoch: 6| Step: 4
Training loss: 2.4960105419158936
Validation loss: 2.0000528853426696

Epoch: 6| Step: 5
Training loss: 2.0750131607055664
Validation loss: 1.9858866301915978

Epoch: 6| Step: 6
Training loss: 2.447535514831543
Validation loss: 1.985151485730243

Epoch: 6| Step: 7
Training loss: 1.822384238243103
Validation loss: 1.9971701252845027

Epoch: 6| Step: 8
Training loss: 1.7608160972595215
Validation loss: 1.968158761660258

Epoch: 6| Step: 9
Training loss: 2.115273952484131
Validation loss: 1.9892325119305683

Epoch: 6| Step: 10
Training loss: 2.0710413455963135
Validation loss: 1.996452768643697

Epoch: 6| Step: 11
Training loss: 1.629902720451355
Validation loss: 1.9868144130194059

Epoch: 6| Step: 12
Training loss: 2.2178149223327637
Validation loss: 1.9487286306196643

Epoch: 6| Step: 13
Training loss: 2.331425905227661
Validation loss: 1.9602333960994598

Epoch: 190| Step: 0
Training loss: 2.3668699264526367
Validation loss: 1.9967889298674881

Epoch: 6| Step: 1
Training loss: 1.9302150011062622
Validation loss: 1.9821750720342

Epoch: 6| Step: 2
Training loss: 1.6311211585998535
Validation loss: 1.971982127876692

Epoch: 6| Step: 3
Training loss: 1.939526915550232
Validation loss: 1.9876093300439979

Epoch: 6| Step: 4
Training loss: 1.6889572143554688
Validation loss: 1.9895500803506503

Epoch: 6| Step: 5
Training loss: 1.8259931802749634
Validation loss: 1.954478943219749

Epoch: 6| Step: 6
Training loss: 2.163431167602539
Validation loss: 1.9995634991635558

Epoch: 6| Step: 7
Training loss: 1.7236826419830322
Validation loss: 1.9700457947228545

Epoch: 6| Step: 8
Training loss: 2.373525619506836
Validation loss: 1.9981836144642164

Epoch: 6| Step: 9
Training loss: 1.4855003356933594
Validation loss: 2.009881529756772

Epoch: 6| Step: 10
Training loss: 2.4109861850738525
Validation loss: 1.9768643750939319

Epoch: 6| Step: 11
Training loss: 1.7446820735931396
Validation loss: 1.9592849926282

Epoch: 6| Step: 12
Training loss: 2.3855748176574707
Validation loss: 1.987591681941863

Epoch: 6| Step: 13
Training loss: 2.4659886360168457
Validation loss: 1.9804168311498498

Epoch: 191| Step: 0
Training loss: 1.748748779296875
Validation loss: 2.001110217904532

Epoch: 6| Step: 1
Training loss: 1.4140379428863525
Validation loss: 1.9887218321523359

Epoch: 6| Step: 2
Training loss: 2.1167917251586914
Validation loss: 2.0058067844760035

Epoch: 6| Step: 3
Training loss: 2.083340644836426
Validation loss: 2.00110286794683

Epoch: 6| Step: 4
Training loss: 1.6635864973068237
Validation loss: 1.9800386569833244

Epoch: 6| Step: 5
Training loss: 2.228245735168457
Validation loss: 1.9831461009158884

Epoch: 6| Step: 6
Training loss: 1.530644416809082
Validation loss: 1.9897118947839225

Epoch: 6| Step: 7
Training loss: 2.0022811889648438
Validation loss: 2.0198694582908385

Epoch: 6| Step: 8
Training loss: 2.8003766536712646
Validation loss: 1.9932834640625985

Epoch: 6| Step: 9
Training loss: 1.638829231262207
Validation loss: 1.9920119675256873

Epoch: 6| Step: 10
Training loss: 1.7302930355072021
Validation loss: 2.0070298358958256

Epoch: 6| Step: 11
Training loss: 2.6853110790252686
Validation loss: 2.0059340743608374

Epoch: 6| Step: 12
Training loss: 2.1672940254211426
Validation loss: 1.9720912518039826

Epoch: 6| Step: 13
Training loss: 1.8593711853027344
Validation loss: 1.9996527856396091

Epoch: 192| Step: 0
Training loss: 2.4617419242858887
Validation loss: 2.0058828425663773

Epoch: 6| Step: 1
Training loss: 2.6172401905059814
Validation loss: 1.9660409048039427

Epoch: 6| Step: 2
Training loss: 2.374987840652466
Validation loss: 2.001805515699489

Epoch: 6| Step: 3
Training loss: 1.9494307041168213
Validation loss: 1.9697821935017903

Epoch: 6| Step: 4
Training loss: 1.8979145288467407
Validation loss: 1.961620944802479

Epoch: 6| Step: 5
Training loss: 1.7890042066574097
Validation loss: 1.9842988239821566

Epoch: 6| Step: 6
Training loss: 2.3249707221984863
Validation loss: 1.951782311162641

Epoch: 6| Step: 7
Training loss: 1.8181887865066528
Validation loss: 1.9892498767504128

Epoch: 6| Step: 8
Training loss: 1.8040485382080078
Validation loss: 1.956104609274095

Epoch: 6| Step: 9
Training loss: 1.5868630409240723
Validation loss: 1.9793641797957882

Epoch: 6| Step: 10
Training loss: 1.685805082321167
Validation loss: 1.9970361712158367

Epoch: 6| Step: 11
Training loss: 1.4400184154510498
Validation loss: 1.9674198435198875

Epoch: 6| Step: 12
Training loss: 2.091233253479004
Validation loss: 1.979887003539711

Epoch: 6| Step: 13
Training loss: 1.9567233324050903
Validation loss: 2.008958396091256

Epoch: 193| Step: 0
Training loss: 1.4461829662322998
Validation loss: 1.972926555141326

Epoch: 6| Step: 1
Training loss: 2.126533031463623
Validation loss: 1.9763984718630392

Epoch: 6| Step: 2
Training loss: 2.6307625770568848
Validation loss: 2.000087491927608

Epoch: 6| Step: 3
Training loss: 2.061006546020508
Validation loss: 1.9988839344311786

Epoch: 6| Step: 4
Training loss: 1.4865342378616333
Validation loss: 2.0092871522390716

Epoch: 6| Step: 5
Training loss: 1.7508116960525513
Validation loss: 2.017060827183467

Epoch: 6| Step: 6
Training loss: 2.080308198928833
Validation loss: 1.987099015584556

Epoch: 6| Step: 7
Training loss: 1.9044406414031982
Validation loss: 2.000724861698766

Epoch: 6| Step: 8
Training loss: 1.9895343780517578
Validation loss: 1.9806899537322342

Epoch: 6| Step: 9
Training loss: 1.9458831548690796
Validation loss: 1.9951378747981081

Epoch: 6| Step: 10
Training loss: 2.136838436126709
Validation loss: 2.009396453057566

Epoch: 6| Step: 11
Training loss: 1.9961460828781128
Validation loss: 1.9501403031810638

Epoch: 6| Step: 12
Training loss: 2.096012592315674
Validation loss: 2.0179758840991604

Epoch: 6| Step: 13
Training loss: 2.4092562198638916
Validation loss: 1.9503409836881904

Epoch: 194| Step: 0
Training loss: 2.0590178966522217
Validation loss: 2.0004259809370963

Epoch: 6| Step: 1
Training loss: 2.692026138305664
Validation loss: 1.980284297338096

Epoch: 6| Step: 2
Training loss: 1.0637354850769043
Validation loss: 1.9719553750048402

Epoch: 6| Step: 3
Training loss: 2.63979434967041
Validation loss: 1.9832671803812827

Epoch: 6| Step: 4
Training loss: 1.7002063989639282
Validation loss: 1.9705439024074103

Epoch: 6| Step: 5
Training loss: 1.5309834480285645
Validation loss: 1.9634410335171608

Epoch: 6| Step: 6
Training loss: 1.9675092697143555
Validation loss: 1.9800679401684833

Epoch: 6| Step: 7
Training loss: 2.622419595718384
Validation loss: 1.9745396414110739

Epoch: 6| Step: 8
Training loss: 1.468719720840454
Validation loss: 2.0004158507111254

Epoch: 6| Step: 9
Training loss: 1.6848665475845337
Validation loss: 1.9594000385653587

Epoch: 6| Step: 10
Training loss: 1.9475338459014893
Validation loss: 1.9769979138528146

Epoch: 6| Step: 11
Training loss: 2.447584629058838
Validation loss: 1.952394990510838

Epoch: 6| Step: 12
Training loss: 2.23073673248291
Validation loss: 1.9728397259148218

Epoch: 6| Step: 13
Training loss: 1.6872469186782837
Validation loss: 2.0094562807390766

Epoch: 195| Step: 0
Training loss: 1.2367663383483887
Validation loss: 1.988265980956375

Epoch: 6| Step: 1
Training loss: 2.3715291023254395
Validation loss: 1.9791984737560313

Epoch: 6| Step: 2
Training loss: 2.315166711807251
Validation loss: 2.0056891556709044

Epoch: 6| Step: 3
Training loss: 1.8148852586746216
Validation loss: 1.9842872414537656

Epoch: 6| Step: 4
Training loss: 1.7860164642333984
Validation loss: 1.9911249555567259

Epoch: 6| Step: 5
Training loss: 1.9242817163467407
Validation loss: 1.9880861889931463

Epoch: 6| Step: 6
Training loss: 1.0906977653503418
Validation loss: 1.9829078951189596

Epoch: 6| Step: 7
Training loss: 2.566652297973633
Validation loss: 1.988520073634322

Epoch: 6| Step: 8
Training loss: 2.2946016788482666
Validation loss: 1.9947903079371299

Epoch: 6| Step: 9
Training loss: 1.5264207124710083
Validation loss: 1.9897593503357263

Epoch: 6| Step: 10
Training loss: 1.632805585861206
Validation loss: 1.9969537053056943

Epoch: 6| Step: 11
Training loss: 2.5819883346557617
Validation loss: 1.9996746624669721

Epoch: 6| Step: 12
Training loss: 2.3218612670898438
Validation loss: 1.9934098400095457

Epoch: 6| Step: 13
Training loss: 2.3602938652038574
Validation loss: 2.034771596231768

Epoch: 196| Step: 0
Training loss: 2.3778934478759766
Validation loss: 2.016022002825173

Epoch: 6| Step: 1
Training loss: 3.0539636611938477
Validation loss: 2.0195185279333465

Epoch: 6| Step: 2
Training loss: 1.4131823778152466
Validation loss: 2.050358454386393

Epoch: 6| Step: 3
Training loss: 1.4418926239013672
Validation loss: 2.011992503237981

Epoch: 6| Step: 4
Training loss: 2.21484375
Validation loss: 1.9943656203567341

Epoch: 6| Step: 5
Training loss: 2.1256461143493652
Validation loss: 2.0039739672855665

Epoch: 6| Step: 6
Training loss: 1.9214692115783691
Validation loss: 2.0270263841075282

Epoch: 6| Step: 7
Training loss: 1.909053087234497
Validation loss: 2.0212779762924358

Epoch: 6| Step: 8
Training loss: 2.1371822357177734
Validation loss: 2.022887170955699

Epoch: 6| Step: 9
Training loss: 2.288747787475586
Validation loss: 1.9843738207253077

Epoch: 6| Step: 10
Training loss: 2.11635684967041
Validation loss: 1.9717311795039842

Epoch: 6| Step: 11
Training loss: 1.9993150234222412
Validation loss: 1.9924692364149197

Epoch: 6| Step: 12
Training loss: 1.3333103656768799
Validation loss: 2.013723006812475

Epoch: 6| Step: 13
Training loss: 1.1774516105651855
Validation loss: 2.0203535377338366

Epoch: 197| Step: 0
Training loss: 2.153818130493164
Validation loss: 1.9718042176256898

Epoch: 6| Step: 1
Training loss: 1.394148588180542
Validation loss: 1.972643631760792

Epoch: 6| Step: 2
Training loss: 1.9796360731124878
Validation loss: 1.9729642957769415

Epoch: 6| Step: 3
Training loss: 2.07010555267334
Validation loss: 1.984083567896197

Epoch: 6| Step: 4
Training loss: 1.8273272514343262
Validation loss: 1.960979284778718

Epoch: 6| Step: 5
Training loss: 2.499218463897705
Validation loss: 1.9720631389207737

Epoch: 6| Step: 6
Training loss: 1.0666463375091553
Validation loss: 1.9634956570081814

Epoch: 6| Step: 7
Training loss: 1.9612445831298828
Validation loss: 1.9844140237377537

Epoch: 6| Step: 8
Training loss: 2.238044261932373
Validation loss: 1.9827872681361374

Epoch: 6| Step: 9
Training loss: 2.141627311706543
Validation loss: 1.9558143461904218

Epoch: 6| Step: 10
Training loss: 1.4538931846618652
Validation loss: 1.9535005874531244

Epoch: 6| Step: 11
Training loss: 2.345569610595703
Validation loss: 1.9379653366663123

Epoch: 6| Step: 12
Training loss: 2.2848403453826904
Validation loss: 1.984279248022264

Epoch: 6| Step: 13
Training loss: 2.1362626552581787
Validation loss: 1.9689909001832366

Epoch: 198| Step: 0
Training loss: 2.070725917816162
Validation loss: 1.956101740560224

Epoch: 6| Step: 1
Training loss: 2.4620823860168457
Validation loss: 1.9689799521559028

Epoch: 6| Step: 2
Training loss: 1.9150255918502808
Validation loss: 1.965297709229172

Epoch: 6| Step: 3
Training loss: 2.2877728939056396
Validation loss: 1.974221839699694

Epoch: 6| Step: 4
Training loss: 2.4877028465270996
Validation loss: 1.9541253120668474

Epoch: 6| Step: 5
Training loss: 1.3772069215774536
Validation loss: 1.958598470175138

Epoch: 6| Step: 6
Training loss: 1.613483190536499
Validation loss: 1.963769999883508

Epoch: 6| Step: 7
Training loss: 1.2456996440887451
Validation loss: 1.9652037389816777

Epoch: 6| Step: 8
Training loss: 1.9539625644683838
Validation loss: 1.9995375871658325

Epoch: 6| Step: 9
Training loss: 1.749983787536621
Validation loss: 1.9773201891171035

Epoch: 6| Step: 10
Training loss: 2.108535051345825
Validation loss: 1.9496082029035013

Epoch: 6| Step: 11
Training loss: 2.7141668796539307
Validation loss: 1.9732197574389878

Epoch: 6| Step: 12
Training loss: 1.7577399015426636
Validation loss: 1.9931475488088464

Epoch: 6| Step: 13
Training loss: 1.9155954122543335
Validation loss: 1.9779934203752907

Epoch: 199| Step: 0
Training loss: 1.824605941772461
Validation loss: 2.0019841732517367

Epoch: 6| Step: 1
Training loss: 1.5661922693252563
Validation loss: 2.003776470820109

Epoch: 6| Step: 2
Training loss: 2.48525333404541
Validation loss: 2.0258460634498188

Epoch: 6| Step: 3
Training loss: 1.8414645195007324
Validation loss: 2.0162787591257403

Epoch: 6| Step: 4
Training loss: 2.1055402755737305
Validation loss: 2.0293027508643364

Epoch: 6| Step: 5
Training loss: 2.014899492263794
Validation loss: 2.009237684229369

Epoch: 6| Step: 6
Training loss: 2.0843307971954346
Validation loss: 2.016044665408391

Epoch: 6| Step: 7
Training loss: 1.8262805938720703
Validation loss: 2.031254591480378

Epoch: 6| Step: 8
Training loss: 2.043518543243408
Validation loss: 2.038098935158022

Epoch: 6| Step: 9
Training loss: 1.6011736392974854
Validation loss: 2.0159647939025716

Epoch: 6| Step: 10
Training loss: 1.5728071928024292
Validation loss: 2.02554032751309

Epoch: 6| Step: 11
Training loss: 2.623722553253174
Validation loss: 2.0308914312752346

Epoch: 6| Step: 12
Training loss: 1.9550650119781494
Validation loss: 2.0302256127839446

Epoch: 6| Step: 13
Training loss: 2.58583664894104
Validation loss: 2.0196124943353797

Epoch: 200| Step: 0
Training loss: 2.3654873371124268
Validation loss: 2.011384208997091

Epoch: 6| Step: 1
Training loss: 1.691225528717041
Validation loss: 2.0074350167346258

Epoch: 6| Step: 2
Training loss: 1.9888319969177246
Validation loss: 2.002399038243037

Epoch: 6| Step: 3
Training loss: 1.6580531597137451
Validation loss: 1.9814181558547481

Epoch: 6| Step: 4
Training loss: 2.130274772644043
Validation loss: 2.00992944804571

Epoch: 6| Step: 5
Training loss: 1.9999768733978271
Validation loss: 1.9584032130497757

Epoch: 6| Step: 6
Training loss: 1.9760230779647827
Validation loss: 1.9780753838118685

Epoch: 6| Step: 7
Training loss: 2.2408509254455566
Validation loss: 1.9801005599319295

Epoch: 6| Step: 8
Training loss: 2.1848464012145996
Validation loss: 1.979284946636487

Epoch: 6| Step: 9
Training loss: 1.8555995225906372
Validation loss: 1.9607668666429416

Epoch: 6| Step: 10
Training loss: 2.4618918895721436
Validation loss: 1.9886628812359226

Epoch: 6| Step: 11
Training loss: 1.9857041835784912
Validation loss: 1.9842717903916554

Epoch: 6| Step: 12
Training loss: 1.4649170637130737
Validation loss: 1.9734592617198985

Epoch: 6| Step: 13
Training loss: 1.669070839881897
Validation loss: 1.9609171011114632

Epoch: 201| Step: 0
Training loss: 2.0770626068115234
Validation loss: 1.9965376764215448

Epoch: 6| Step: 1
Training loss: 1.3108316659927368
Validation loss: 1.9926517727554485

Epoch: 6| Step: 2
Training loss: 2.6000797748565674
Validation loss: 1.9940895931695097

Epoch: 6| Step: 3
Training loss: 1.4701728820800781
Validation loss: 2.0042848843400196

Epoch: 6| Step: 4
Training loss: 1.3278347253799438
Validation loss: 1.948219774871744

Epoch: 6| Step: 5
Training loss: 2.1402392387390137
Validation loss: 1.971288655393867

Epoch: 6| Step: 6
Training loss: 1.7877660989761353
Validation loss: 2.0057565012285785

Epoch: 6| Step: 7
Training loss: 1.5613529682159424
Validation loss: 1.9595216076861146

Epoch: 6| Step: 8
Training loss: 3.136329174041748
Validation loss: 1.9874737736999348

Epoch: 6| Step: 9
Training loss: 1.9036489725112915
Validation loss: 1.9511527681863436

Epoch: 6| Step: 10
Training loss: 1.8736274242401123
Validation loss: 1.9766624563483781

Epoch: 6| Step: 11
Training loss: 2.120657444000244
Validation loss: 1.9649358808353383

Epoch: 6| Step: 12
Training loss: 2.496033191680908
Validation loss: 1.987093888303285

Epoch: 6| Step: 13
Training loss: 1.3767662048339844
Validation loss: 1.9780822864142797

Epoch: 202| Step: 0
Training loss: 1.6815927028656006
Validation loss: 1.9800165340464602

Epoch: 6| Step: 1
Training loss: 1.8684160709381104
Validation loss: 1.9966245799936273

Epoch: 6| Step: 2
Training loss: 2.2962870597839355
Validation loss: 1.9665711772057317

Epoch: 6| Step: 3
Training loss: 2.4752233028411865
Validation loss: 2.0079576469236806

Epoch: 6| Step: 4
Training loss: 2.0330049991607666
Validation loss: 1.9760595983074558

Epoch: 6| Step: 5
Training loss: 2.0317177772521973
Validation loss: 1.9706243750869588

Epoch: 6| Step: 6
Training loss: 1.9578628540039062
Validation loss: 1.9889198272458968

Epoch: 6| Step: 7
Training loss: 1.5307669639587402
Validation loss: 2.0147175224878455

Epoch: 6| Step: 8
Training loss: 1.8276584148406982
Validation loss: 2.01818682301429

Epoch: 6| Step: 9
Training loss: 1.7194278240203857
Validation loss: 1.9566931134910994

Epoch: 6| Step: 10
Training loss: 2.489346504211426
Validation loss: 2.005143516807146

Epoch: 6| Step: 11
Training loss: 1.793184757232666
Validation loss: 1.9980941023877872

Epoch: 6| Step: 12
Training loss: 1.6228671073913574
Validation loss: 1.9714770022258963

Epoch: 6| Step: 13
Training loss: 2.303030252456665
Validation loss: 2.0060232403457805

Epoch: 203| Step: 0
Training loss: 1.9316675662994385
Validation loss: 1.9758461316426594

Epoch: 6| Step: 1
Training loss: 1.927358627319336
Validation loss: 1.9975993325633388

Epoch: 6| Step: 2
Training loss: 1.5490764379501343
Validation loss: 2.002271521476007

Epoch: 6| Step: 3
Training loss: 2.0158145427703857
Validation loss: 1.9895143560183945

Epoch: 6| Step: 4
Training loss: 1.6360591650009155
Validation loss: 2.0028567647421234

Epoch: 6| Step: 5
Training loss: 1.5661166906356812
Validation loss: 1.9824093105972453

Epoch: 6| Step: 6
Training loss: 1.835084319114685
Validation loss: 1.9858379133286015

Epoch: 6| Step: 7
Training loss: 2.2125630378723145
Validation loss: 1.9816879662134315

Epoch: 6| Step: 8
Training loss: 2.2114357948303223
Validation loss: 1.9858303377705235

Epoch: 6| Step: 9
Training loss: 1.5074095726013184
Validation loss: 1.9883798014733098

Epoch: 6| Step: 10
Training loss: 2.6179442405700684
Validation loss: 1.9712598528913272

Epoch: 6| Step: 11
Training loss: 1.8534690141677856
Validation loss: 1.9729572931925456

Epoch: 6| Step: 12
Training loss: 2.3929784297943115
Validation loss: 2.0023524133107995

Epoch: 6| Step: 13
Training loss: 2.4125266075134277
Validation loss: 1.9966050578701882

Epoch: 204| Step: 0
Training loss: 1.7328801155090332
Validation loss: 2.0236821520713066

Epoch: 6| Step: 1
Training loss: 1.6526951789855957
Validation loss: 1.9873711562925769

Epoch: 6| Step: 2
Training loss: 2.0010931491851807
Validation loss: 1.9977720655420774

Epoch: 6| Step: 3
Training loss: 2.3715591430664062
Validation loss: 1.9919382385028306

Epoch: 6| Step: 4
Training loss: 1.9884378910064697
Validation loss: 1.9839718546918643

Epoch: 6| Step: 5
Training loss: 1.8659873008728027
Validation loss: 2.0050628492909093

Epoch: 6| Step: 6
Training loss: 2.2584643363952637
Validation loss: 1.9356309060127503

Epoch: 6| Step: 7
Training loss: 1.8287523984909058
Validation loss: 1.9864557776399838

Epoch: 6| Step: 8
Training loss: 1.3758211135864258
Validation loss: 1.9706599020188855

Epoch: 6| Step: 9
Training loss: 2.814694881439209
Validation loss: 2.005308048699492

Epoch: 6| Step: 10
Training loss: 1.8240370750427246
Validation loss: 1.9774875948506017

Epoch: 6| Step: 11
Training loss: 1.3713963031768799
Validation loss: 2.0082590015985633

Epoch: 6| Step: 12
Training loss: 2.4248414039611816
Validation loss: 2.0006193576320523

Epoch: 6| Step: 13
Training loss: 1.7947934865951538
Validation loss: 1.9895356970448648

Epoch: 205| Step: 0
Training loss: 1.9431016445159912
Validation loss: 1.9614950867109402

Epoch: 6| Step: 1
Training loss: 1.6535168886184692
Validation loss: 2.012826786246351

Epoch: 6| Step: 2
Training loss: 2.4357705116271973
Validation loss: 1.9920649913049513

Epoch: 6| Step: 3
Training loss: 1.8419530391693115
Validation loss: 1.983952627387098

Epoch: 6| Step: 4
Training loss: 2.1852197647094727
Validation loss: 2.0000416360875612

Epoch: 6| Step: 5
Training loss: 1.922316551208496
Validation loss: 1.9986013084329584

Epoch: 6| Step: 6
Training loss: 1.3466768264770508
Validation loss: 2.0307075515870125

Epoch: 6| Step: 7
Training loss: 2.032097816467285
Validation loss: 1.9845547983723302

Epoch: 6| Step: 8
Training loss: 2.714707612991333
Validation loss: 1.996719757715861

Epoch: 6| Step: 9
Training loss: 2.0736770629882812
Validation loss: 1.9915207291162142

Epoch: 6| Step: 10
Training loss: 1.4032310247421265
Validation loss: 1.9844323665865007

Epoch: 6| Step: 11
Training loss: 2.033323049545288
Validation loss: 1.9737574695259013

Epoch: 6| Step: 12
Training loss: 1.9086461067199707
Validation loss: 1.996305077306686

Epoch: 6| Step: 13
Training loss: 1.9569032192230225
Validation loss: 2.012587490902152

Epoch: 206| Step: 0
Training loss: 2.075901746749878
Validation loss: 1.9895253130184707

Epoch: 6| Step: 1
Training loss: 1.6279963254928589
Validation loss: 1.9943834094591038

Epoch: 6| Step: 2
Training loss: 1.787229299545288
Validation loss: 1.9791110702740249

Epoch: 6| Step: 3
Training loss: 2.5264952182769775
Validation loss: 2.0036378342618226

Epoch: 6| Step: 4
Training loss: 1.881280541419983
Validation loss: 1.989196628652593

Epoch: 6| Step: 5
Training loss: 1.0622400045394897
Validation loss: 1.9650750890854867

Epoch: 6| Step: 6
Training loss: 2.323943614959717
Validation loss: 1.9333638555260115

Epoch: 6| Step: 7
Training loss: 2.3932132720947266
Validation loss: 1.969077681982389

Epoch: 6| Step: 8
Training loss: 1.7699260711669922
Validation loss: 1.986706482466831

Epoch: 6| Step: 9
Training loss: 2.0581953525543213
Validation loss: 1.9675849355677122

Epoch: 6| Step: 10
Training loss: 1.902113914489746
Validation loss: 1.993298536987715

Epoch: 6| Step: 11
Training loss: 2.2223703861236572
Validation loss: 1.977586671870242

Epoch: 6| Step: 12
Training loss: 2.0999679565429688
Validation loss: 1.9887142219851095

Epoch: 6| Step: 13
Training loss: 1.5740195512771606
Validation loss: 1.9766187514028242

Epoch: 207| Step: 0
Training loss: 1.9923124313354492
Validation loss: 2.0070582205249416

Epoch: 6| Step: 1
Training loss: 2.8218462467193604
Validation loss: 1.9676255333808161

Epoch: 6| Step: 2
Training loss: 1.751405954360962
Validation loss: 1.9470040029095066

Epoch: 6| Step: 3
Training loss: 1.698564052581787
Validation loss: 1.9713581390278314

Epoch: 6| Step: 4
Training loss: 2.816000461578369
Validation loss: 1.9815766375551942

Epoch: 6| Step: 5
Training loss: 1.744640588760376
Validation loss: 2.009990748538766

Epoch: 6| Step: 6
Training loss: 1.7463533878326416
Validation loss: 1.9852115313212078

Epoch: 6| Step: 7
Training loss: 2.1087281703948975
Validation loss: 2.0081375965508084

Epoch: 6| Step: 8
Training loss: 1.5010887384414673
Validation loss: 1.993018275947981

Epoch: 6| Step: 9
Training loss: 1.8597321510314941
Validation loss: 1.9701756341483003

Epoch: 6| Step: 10
Training loss: 2.125783920288086
Validation loss: 2.010786839710769

Epoch: 6| Step: 11
Training loss: 1.792344093322754
Validation loss: 2.020483950132965

Epoch: 6| Step: 12
Training loss: 1.3282034397125244
Validation loss: 2.0205968503029115

Epoch: 6| Step: 13
Training loss: 2.049516201019287
Validation loss: 1.996416066282539

Epoch: 208| Step: 0
Training loss: 1.4094057083129883
Validation loss: 1.9400139931709535

Epoch: 6| Step: 1
Training loss: 1.5339503288269043
Validation loss: 1.9945254300230293

Epoch: 6| Step: 2
Training loss: 2.011526107788086
Validation loss: 2.000084279685892

Epoch: 6| Step: 3
Training loss: 1.7369258403778076
Validation loss: 1.984737967932096

Epoch: 6| Step: 4
Training loss: 1.7632999420166016
Validation loss: 2.0190979460234284

Epoch: 6| Step: 5
Training loss: 2.6418824195861816
Validation loss: 1.9829914877491612

Epoch: 6| Step: 6
Training loss: 1.4693320989608765
Validation loss: 1.9975325599793465

Epoch: 6| Step: 7
Training loss: 1.9982178211212158
Validation loss: 1.9738298898102136

Epoch: 6| Step: 8
Training loss: 1.9200471639633179
Validation loss: 1.9845848160405313

Epoch: 6| Step: 9
Training loss: 1.681854009628296
Validation loss: 2.0115201204053816

Epoch: 6| Step: 10
Training loss: 1.7809934616088867
Validation loss: 1.9859279099331106

Epoch: 6| Step: 11
Training loss: 1.485001564025879
Validation loss: 1.9934026502793836

Epoch: 6| Step: 12
Training loss: 3.388723373413086
Validation loss: 1.9684111328535183

Epoch: 6| Step: 13
Training loss: 2.7665834426879883
Validation loss: 2.003883404116477

Epoch: 209| Step: 0
Training loss: 1.9363276958465576
Validation loss: 1.9780339194882302

Epoch: 6| Step: 1
Training loss: 2.4064345359802246
Validation loss: 1.991114693303262

Epoch: 6| Step: 2
Training loss: 2.477804660797119
Validation loss: 1.985539077430643

Epoch: 6| Step: 3
Training loss: 2.666106700897217
Validation loss: 2.0287216286505423

Epoch: 6| Step: 4
Training loss: 1.787957787513733
Validation loss: 2.009041961803231

Epoch: 6| Step: 5
Training loss: 1.5480304956436157
Validation loss: 1.991771977434876

Epoch: 6| Step: 6
Training loss: 2.2059147357940674
Validation loss: 1.988145257837029

Epoch: 6| Step: 7
Training loss: 1.5398507118225098
Validation loss: 1.9877813798125072

Epoch: 6| Step: 8
Training loss: 2.04026460647583
Validation loss: 1.992674836548426

Epoch: 6| Step: 9
Training loss: 1.62271249294281
Validation loss: 1.942625012449039

Epoch: 6| Step: 10
Training loss: 1.2633633613586426
Validation loss: 1.9894551654015817

Epoch: 6| Step: 11
Training loss: 2.2227487564086914
Validation loss: 1.9834526700358237

Epoch: 6| Step: 12
Training loss: 1.11309814453125
Validation loss: 1.9798317019657423

Epoch: 6| Step: 13
Training loss: 2.6202993392944336
Validation loss: 1.957831613479122

Epoch: 210| Step: 0
Training loss: 2.431819438934326
Validation loss: 2.011477308888589

Epoch: 6| Step: 1
Training loss: 2.0060043334960938
Validation loss: 1.9496632673407113

Epoch: 6| Step: 2
Training loss: 1.6301705837249756
Validation loss: 1.9719183252703758

Epoch: 6| Step: 3
Training loss: 1.8797601461410522
Validation loss: 1.9751041409789876

Epoch: 6| Step: 4
Training loss: 2.4821577072143555
Validation loss: 1.9939063287550403

Epoch: 6| Step: 5
Training loss: 1.5816898345947266
Validation loss: 1.9905864833503641

Epoch: 6| Step: 6
Training loss: 2.359886646270752
Validation loss: 2.010807004026187

Epoch: 6| Step: 7
Training loss: 1.85493803024292
Validation loss: 1.9903226103833926

Epoch: 6| Step: 8
Training loss: 1.4644043445587158
Validation loss: 1.97936963265942

Epoch: 6| Step: 9
Training loss: 2.392486095428467
Validation loss: 1.9892659238589707

Epoch: 6| Step: 10
Training loss: 1.6779965162277222
Validation loss: 2.0029635070472636

Epoch: 6| Step: 11
Training loss: 1.8823987245559692
Validation loss: 1.9603953887057561

Epoch: 6| Step: 12
Training loss: 1.8089162111282349
Validation loss: 2.0008884886259675

Epoch: 6| Step: 13
Training loss: 2.0753183364868164
Validation loss: 2.0090407517648514

Epoch: 211| Step: 0
Training loss: 1.6592473983764648
Validation loss: 2.0321364787317093

Epoch: 6| Step: 1
Training loss: 1.6375972032546997
Validation loss: 2.034204531741399

Epoch: 6| Step: 2
Training loss: 1.5816110372543335
Validation loss: 1.9512066136124313

Epoch: 6| Step: 3
Training loss: 2.0602540969848633
Validation loss: 2.00535761925482

Epoch: 6| Step: 4
Training loss: 1.6340677738189697
Validation loss: 1.9841879721610778

Epoch: 6| Step: 5
Training loss: 2.353788375854492
Validation loss: 1.9853785089267197

Epoch: 6| Step: 6
Training loss: 1.8683722019195557
Validation loss: 1.9834128143966838

Epoch: 6| Step: 7
Training loss: 2.6372475624084473
Validation loss: 1.9727123783480736

Epoch: 6| Step: 8
Training loss: 2.3158302307128906
Validation loss: 1.9902565402369345

Epoch: 6| Step: 9
Training loss: 2.33823823928833
Validation loss: 1.9691437700743317

Epoch: 6| Step: 10
Training loss: 1.9010672569274902
Validation loss: 1.9710526902188537

Epoch: 6| Step: 11
Training loss: 1.567406177520752
Validation loss: 1.9622563444158083

Epoch: 6| Step: 12
Training loss: 1.9052397012710571
Validation loss: 1.9842634047231367

Epoch: 6| Step: 13
Training loss: 2.1645448207855225
Validation loss: 1.9757004476362658

Epoch: 212| Step: 0
Training loss: 2.3814280033111572
Validation loss: 1.9748391515465193

Epoch: 6| Step: 1
Training loss: 1.5927270650863647
Validation loss: 1.9734865029652913

Epoch: 6| Step: 2
Training loss: 1.542157769203186
Validation loss: 1.9824548203458068

Epoch: 6| Step: 3
Training loss: 1.8196924924850464
Validation loss: 1.9816192914080877

Epoch: 6| Step: 4
Training loss: 1.3470669984817505
Validation loss: 2.036776868245935

Epoch: 6| Step: 5
Training loss: 2.342215061187744
Validation loss: 1.9888549876469437

Epoch: 6| Step: 6
Training loss: 2.1686477661132812
Validation loss: 2.0171287828876125

Epoch: 6| Step: 7
Training loss: 1.7002394199371338
Validation loss: 1.99853943240258

Epoch: 6| Step: 8
Training loss: 1.9477788209915161
Validation loss: 2.0171484934386386

Epoch: 6| Step: 9
Training loss: 2.059206485748291
Validation loss: 2.0173413010053736

Epoch: 6| Step: 10
Training loss: 2.08505916595459
Validation loss: 2.0239344412280666

Epoch: 6| Step: 11
Training loss: 1.9938188791275024
Validation loss: 2.029616073895526

Epoch: 6| Step: 12
Training loss: 1.8755422830581665
Validation loss: 2.037281500395908

Epoch: 6| Step: 13
Training loss: 2.9602601528167725
Validation loss: 2.0166818557247037

Epoch: 213| Step: 0
Training loss: 1.981823205947876
Validation loss: 2.0058935688387964

Epoch: 6| Step: 1
Training loss: 2.2621328830718994
Validation loss: 2.0667341075917727

Epoch: 6| Step: 2
Training loss: 1.6197222471237183
Validation loss: 2.0383555555856354

Epoch: 6| Step: 3
Training loss: 2.3536622524261475
Validation loss: 2.028053558000954

Epoch: 6| Step: 4
Training loss: 1.8258557319641113
Validation loss: 2.0608207077108402

Epoch: 6| Step: 5
Training loss: 1.8589074611663818
Validation loss: 1.9773582271350327

Epoch: 6| Step: 6
Training loss: 1.8800134658813477
Validation loss: 1.977759838104248

Epoch: 6| Step: 7
Training loss: 2.257580280303955
Validation loss: 1.9843479907640846

Epoch: 6| Step: 8
Training loss: 2.120486259460449
Validation loss: 1.9730904653508177

Epoch: 6| Step: 9
Training loss: 2.2835700511932373
Validation loss: 1.9766224045907297

Epoch: 6| Step: 10
Training loss: 1.6581794023513794
Validation loss: 1.9730472436515234

Epoch: 6| Step: 11
Training loss: 1.4601500034332275
Validation loss: 2.001401270589521

Epoch: 6| Step: 12
Training loss: 1.8602606058120728
Validation loss: 1.9799502831633373

Epoch: 6| Step: 13
Training loss: 1.3661143779754639
Validation loss: 1.9809325997547438

Epoch: 214| Step: 0
Training loss: 2.2733864784240723
Validation loss: 1.987980596480831

Epoch: 6| Step: 1
Training loss: 1.1512621641159058
Validation loss: 1.9685386329568841

Epoch: 6| Step: 2
Training loss: 2.316312789916992
Validation loss: 2.006989130409815

Epoch: 6| Step: 3
Training loss: 1.7889996767044067
Validation loss: 1.9950063138879754

Epoch: 6| Step: 4
Training loss: 1.932278037071228
Validation loss: 1.9861561841862176

Epoch: 6| Step: 5
Training loss: 2.321239471435547
Validation loss: 1.986192895520118

Epoch: 6| Step: 6
Training loss: 1.719255805015564
Validation loss: 1.9965754350026448

Epoch: 6| Step: 7
Training loss: 2.135338306427002
Validation loss: 1.96544889737201

Epoch: 6| Step: 8
Training loss: 1.7625961303710938
Validation loss: 1.989377006407707

Epoch: 6| Step: 9
Training loss: 2.899405002593994
Validation loss: 2.0148540876244985

Epoch: 6| Step: 10
Training loss: 1.3837783336639404
Validation loss: 1.9968885913971932

Epoch: 6| Step: 11
Training loss: 2.223858594894409
Validation loss: 1.9734614997781732

Epoch: 6| Step: 12
Training loss: 1.863304853439331
Validation loss: 1.9553614739448792

Epoch: 6| Step: 13
Training loss: 1.341840386390686
Validation loss: 2.014518745483891

Epoch: 215| Step: 0
Training loss: 1.8021914958953857
Validation loss: 1.9829661628251434

Epoch: 6| Step: 1
Training loss: 2.083498954772949
Validation loss: 1.998000834577827

Epoch: 6| Step: 2
Training loss: 1.8969697952270508
Validation loss: 2.014877962809737

Epoch: 6| Step: 3
Training loss: 2.377100706100464
Validation loss: 1.9908073538093156

Epoch: 6| Step: 4
Training loss: 2.314352512359619
Validation loss: 2.0036733906756163

Epoch: 6| Step: 5
Training loss: 1.8992046117782593
Validation loss: 2.0338769061591035

Epoch: 6| Step: 6
Training loss: 1.4098246097564697
Validation loss: 2.0247890218611686

Epoch: 6| Step: 7
Training loss: 2.0805366039276123
Validation loss: 1.9992532473738476

Epoch: 6| Step: 8
Training loss: 1.9368445873260498
Validation loss: 2.0129199463834047

Epoch: 6| Step: 9
Training loss: 2.065744400024414
Validation loss: 2.007392930728133

Epoch: 6| Step: 10
Training loss: 1.5383248329162598
Validation loss: 2.035787114533045

Epoch: 6| Step: 11
Training loss: 1.3122682571411133
Validation loss: 1.9975076055014005

Epoch: 6| Step: 12
Training loss: 1.8788363933563232
Validation loss: 1.9986314337740663

Epoch: 6| Step: 13
Training loss: 2.522207021713257
Validation loss: 2.0198459907244612

Epoch: 216| Step: 0
Training loss: 2.8502955436706543
Validation loss: 1.9970755500178183

Epoch: 6| Step: 1
Training loss: 1.4401264190673828
Validation loss: 2.03082489198254

Epoch: 6| Step: 2
Training loss: 2.280277967453003
Validation loss: 1.9636756861081688

Epoch: 6| Step: 3
Training loss: 2.6322147846221924
Validation loss: 1.9965633833280174

Epoch: 6| Step: 4
Training loss: 2.4900527000427246
Validation loss: 1.9388861989462247

Epoch: 6| Step: 5
Training loss: 1.2822980880737305
Validation loss: 1.9893190604384228

Epoch: 6| Step: 6
Training loss: 2.1965878009796143
Validation loss: 1.9892981847127278

Epoch: 6| Step: 7
Training loss: 1.384964942932129
Validation loss: 1.9737257547275995

Epoch: 6| Step: 8
Training loss: 1.7045140266418457
Validation loss: 1.9733722799567766

Epoch: 6| Step: 9
Training loss: 1.428795337677002
Validation loss: 1.9952832242493987

Epoch: 6| Step: 10
Training loss: 1.466987133026123
Validation loss: 2.0020621963726577

Epoch: 6| Step: 11
Training loss: 1.6357253789901733
Validation loss: 2.0309334134542816

Epoch: 6| Step: 12
Training loss: 1.8705480098724365
Validation loss: 1.99956218401591

Epoch: 6| Step: 13
Training loss: 2.276038408279419
Validation loss: 1.9944781564897107

Epoch: 217| Step: 0
Training loss: 2.096982479095459
Validation loss: 2.0155380028550343

Epoch: 6| Step: 1
Training loss: 1.3947265148162842
Validation loss: 1.9812090525063135

Epoch: 6| Step: 2
Training loss: 2.390110492706299
Validation loss: 1.9908709833698888

Epoch: 6| Step: 3
Training loss: 1.9514328241348267
Validation loss: 2.014347089234219

Epoch: 6| Step: 4
Training loss: 1.7124602794647217
Validation loss: 2.019408208067699

Epoch: 6| Step: 5
Training loss: 1.9426777362823486
Validation loss: 2.000579400729108

Epoch: 6| Step: 6
Training loss: 1.8415870666503906
Validation loss: 1.9496748011599305

Epoch: 6| Step: 7
Training loss: 1.747052788734436
Validation loss: 1.9883921261756652

Epoch: 6| Step: 8
Training loss: 1.981685996055603
Validation loss: 2.0162663216231973

Epoch: 6| Step: 9
Training loss: 2.4697928428649902
Validation loss: 1.9861683973702051

Epoch: 6| Step: 10
Training loss: 2.6029109954833984
Validation loss: 2.0040125539225917

Epoch: 6| Step: 11
Training loss: 2.5619101524353027
Validation loss: 1.9706712922742289

Epoch: 6| Step: 12
Training loss: 1.2634477615356445
Validation loss: 1.9951435750530613

Epoch: 6| Step: 13
Training loss: 1.446511149406433
Validation loss: 1.9880445811056322

Epoch: 218| Step: 0
Training loss: 1.8324967622756958
Validation loss: 2.023045280928253

Epoch: 6| Step: 1
Training loss: 2.006571054458618
Validation loss: 2.0209176950557257

Epoch: 6| Step: 2
Training loss: 1.7587931156158447
Validation loss: 1.9888794627240909

Epoch: 6| Step: 3
Training loss: 1.870542049407959
Validation loss: 2.004129513617485

Epoch: 6| Step: 4
Training loss: 1.757367491722107
Validation loss: 1.998080838111139

Epoch: 6| Step: 5
Training loss: 2.2042009830474854
Validation loss: 1.9950273959867415

Epoch: 6| Step: 6
Training loss: 1.8972396850585938
Validation loss: 1.9904291924609934

Epoch: 6| Step: 7
Training loss: 1.8270800113677979
Validation loss: 1.985644466133528

Epoch: 6| Step: 8
Training loss: 2.0437018871307373
Validation loss: 1.9946681966063797

Epoch: 6| Step: 9
Training loss: 1.9442288875579834
Validation loss: 1.9986587391104749

Epoch: 6| Step: 10
Training loss: 1.3553342819213867
Validation loss: 1.9780318070483465

Epoch: 6| Step: 11
Training loss: 1.5156443119049072
Validation loss: 1.996344530454246

Epoch: 6| Step: 12
Training loss: 2.1061182022094727
Validation loss: 1.9815968185342767

Epoch: 6| Step: 13
Training loss: 3.2554211616516113
Validation loss: 2.0115430290981005

Epoch: 219| Step: 0
Training loss: 1.601827621459961
Validation loss: 2.0058579880704164

Epoch: 6| Step: 1
Training loss: 2.134305000305176
Validation loss: 2.0226213214217976

Epoch: 6| Step: 2
Training loss: 2.3115766048431396
Validation loss: 1.9795884265694568

Epoch: 6| Step: 3
Training loss: 2.0202627182006836
Validation loss: 2.0304834573499617

Epoch: 6| Step: 4
Training loss: 0.9759578108787537
Validation loss: 1.9984700782324678

Epoch: 6| Step: 5
Training loss: 1.7476885318756104
Validation loss: 1.9910192451169413

Epoch: 6| Step: 6
Training loss: 1.933966875076294
Validation loss: 1.9867157333640642

Epoch: 6| Step: 7
Training loss: 2.505972385406494
Validation loss: 1.9911046822865803

Epoch: 6| Step: 8
Training loss: 1.9423404932022095
Validation loss: 2.0369877584518923

Epoch: 6| Step: 9
Training loss: 1.9998483657836914
Validation loss: 1.9662751446488083

Epoch: 6| Step: 10
Training loss: 1.4892916679382324
Validation loss: 2.0129314302116312

Epoch: 6| Step: 11
Training loss: 2.031970977783203
Validation loss: 1.955901357435411

Epoch: 6| Step: 12
Training loss: 2.163769483566284
Validation loss: 2.018280666361573

Epoch: 6| Step: 13
Training loss: 1.8789498805999756
Validation loss: 1.9955883987488285

Epoch: 220| Step: 0
Training loss: 1.7674827575683594
Validation loss: 1.988269280361873

Epoch: 6| Step: 1
Training loss: 2.087104082107544
Validation loss: 2.010003901297046

Epoch: 6| Step: 2
Training loss: 1.3070812225341797
Validation loss: 1.991216339090819

Epoch: 6| Step: 3
Training loss: 3.093384265899658
Validation loss: 2.020667051756254

Epoch: 6| Step: 4
Training loss: 2.49569034576416
Validation loss: 1.9949405911148235

Epoch: 6| Step: 5
Training loss: 2.1490187644958496
Validation loss: 2.01862237786734

Epoch: 6| Step: 6
Training loss: 1.8388628959655762
Validation loss: 2.002710037333991

Epoch: 6| Step: 7
Training loss: 1.559034824371338
Validation loss: 1.9846818267658193

Epoch: 6| Step: 8
Training loss: 1.4889912605285645
Validation loss: 1.9714759498514154

Epoch: 6| Step: 9
Training loss: 1.6901932954788208
Validation loss: 1.9990696804497832

Epoch: 6| Step: 10
Training loss: 2.4711837768554688
Validation loss: 2.0052863295360277

Epoch: 6| Step: 11
Training loss: 1.5615211725234985
Validation loss: 1.9928705743564072

Epoch: 6| Step: 12
Training loss: 1.798778772354126
Validation loss: 2.020007587248279

Epoch: 6| Step: 13
Training loss: 1.4440972805023193
Validation loss: 1.978458655777798

Epoch: 221| Step: 0
Training loss: 2.660137176513672
Validation loss: 1.965304292658324

Epoch: 6| Step: 1
Training loss: 2.288055658340454
Validation loss: 2.0202212641316075

Epoch: 6| Step: 2
Training loss: 1.5788397789001465
Validation loss: 1.9968159224397393

Epoch: 6| Step: 3
Training loss: 2.385852813720703
Validation loss: 1.9804791993992303

Epoch: 6| Step: 4
Training loss: 1.49802827835083
Validation loss: 2.0147914271200857

Epoch: 6| Step: 5
Training loss: 1.9496307373046875
Validation loss: 2.007921608545447

Epoch: 6| Step: 6
Training loss: 2.2561023235321045
Validation loss: 1.9689579932920394

Epoch: 6| Step: 7
Training loss: 1.963490605354309
Validation loss: 2.007299764181978

Epoch: 6| Step: 8
Training loss: 1.3911253213882446
Validation loss: 2.0093925537601596

Epoch: 6| Step: 9
Training loss: 1.7982826232910156
Validation loss: 2.0268841533250708

Epoch: 6| Step: 10
Training loss: 1.971938133239746
Validation loss: 2.001877720637988

Epoch: 6| Step: 11
Training loss: 1.2413898706436157
Validation loss: 2.0095881851770545

Epoch: 6| Step: 12
Training loss: 1.9384734630584717
Validation loss: 2.0293693286116405

Epoch: 6| Step: 13
Training loss: 2.5631892681121826
Validation loss: 1.9979211643177976

Epoch: 222| Step: 0
Training loss: 2.6908397674560547
Validation loss: 1.979381348497124

Epoch: 6| Step: 1
Training loss: 1.6564668416976929
Validation loss: 2.007289050727762

Epoch: 6| Step: 2
Training loss: 1.6573591232299805
Validation loss: 2.0454240268276584

Epoch: 6| Step: 3
Training loss: 1.4218437671661377
Validation loss: 1.9825135354072816

Epoch: 6| Step: 4
Training loss: 2.0808169841766357
Validation loss: 2.0153042757382957

Epoch: 6| Step: 5
Training loss: 1.334298849105835
Validation loss: 1.9782600505377657

Epoch: 6| Step: 6
Training loss: 1.7737886905670166
Validation loss: 1.9782931215019637

Epoch: 6| Step: 7
Training loss: 1.840295433998108
Validation loss: 1.9668744328201457

Epoch: 6| Step: 8
Training loss: 2.602670192718506
Validation loss: 1.9796413375485329

Epoch: 6| Step: 9
Training loss: 2.3786964416503906
Validation loss: 2.0102671115629134

Epoch: 6| Step: 10
Training loss: 1.6324403285980225
Validation loss: 1.9771907406468545

Epoch: 6| Step: 11
Training loss: 1.9245563745498657
Validation loss: 1.9810040817465833

Epoch: 6| Step: 12
Training loss: 2.2054238319396973
Validation loss: 2.0207768345391877

Epoch: 6| Step: 13
Training loss: 1.553114414215088
Validation loss: 1.967736864602694

Epoch: 223| Step: 0
Training loss: 1.528268814086914
Validation loss: 1.9714654094429427

Epoch: 6| Step: 1
Training loss: 2.4668426513671875
Validation loss: 1.9862067507159324

Epoch: 6| Step: 2
Training loss: 1.8820862770080566
Validation loss: 1.9907123657964891

Epoch: 6| Step: 3
Training loss: 1.6229082345962524
Validation loss: 1.9982035724065637

Epoch: 6| Step: 4
Training loss: 2.7824482917785645
Validation loss: 1.9855865970734627

Epoch: 6| Step: 5
Training loss: 2.123561382293701
Validation loss: 2.0102624188187304

Epoch: 6| Step: 6
Training loss: 2.25481915473938
Validation loss: 2.0081699919956986

Epoch: 6| Step: 7
Training loss: 1.550600528717041
Validation loss: 2.016911369498058

Epoch: 6| Step: 8
Training loss: 1.750679612159729
Validation loss: 2.026550918497065

Epoch: 6| Step: 9
Training loss: 1.6822748184204102
Validation loss: 1.9913349664339455

Epoch: 6| Step: 10
Training loss: 1.3567396402359009
Validation loss: 2.0554147317845333

Epoch: 6| Step: 11
Training loss: 2.0324935913085938
Validation loss: 1.9827703109351538

Epoch: 6| Step: 12
Training loss: 1.9816741943359375
Validation loss: 1.9912931021823679

Epoch: 6| Step: 13
Training loss: 1.8046144247055054
Validation loss: 2.010582529088502

Epoch: 224| Step: 0
Training loss: 1.938714861869812
Validation loss: 2.0036852077771257

Epoch: 6| Step: 1
Training loss: 1.7366399765014648
Validation loss: 1.9748550704730454

Epoch: 6| Step: 2
Training loss: 2.030202627182007
Validation loss: 1.9853005819423224

Epoch: 6| Step: 3
Training loss: 1.326625108718872
Validation loss: 2.0028301810705536

Epoch: 6| Step: 4
Training loss: 2.350666046142578
Validation loss: 2.0095155598014913

Epoch: 6| Step: 5
Training loss: 2.3943941593170166
Validation loss: 2.0343549315647413

Epoch: 6| Step: 6
Training loss: 1.6251256465911865
Validation loss: 2.013351536566211

Epoch: 6| Step: 7
Training loss: 2.8015289306640625
Validation loss: 1.9964059193929036

Epoch: 6| Step: 8
Training loss: 0.9853813648223877
Validation loss: 1.9893260309773106

Epoch: 6| Step: 9
Training loss: 2.4301223754882812
Validation loss: 2.023772188412246

Epoch: 6| Step: 10
Training loss: 1.841064214706421
Validation loss: 1.9618977577455583

Epoch: 6| Step: 11
Training loss: 2.3954946994781494
Validation loss: 2.022852013188024

Epoch: 6| Step: 12
Training loss: 1.4683938026428223
Validation loss: 1.9954702238882742

Epoch: 6| Step: 13
Training loss: 1.402056097984314
Validation loss: 1.9895968039830525

Epoch: 225| Step: 0
Training loss: 2.0098955631256104
Validation loss: 2.0049886344581522

Epoch: 6| Step: 1
Training loss: 2.2825212478637695
Validation loss: 1.9804728261886104

Epoch: 6| Step: 2
Training loss: 1.56904935836792
Validation loss: 1.9754572786310667

Epoch: 6| Step: 3
Training loss: 2.4064009189605713
Validation loss: 1.9944725472440001

Epoch: 6| Step: 4
Training loss: 2.1239571571350098
Validation loss: 1.9864189035149031

Epoch: 6| Step: 5
Training loss: 2.3254470825195312
Validation loss: 2.0076959043420772

Epoch: 6| Step: 6
Training loss: 1.598273754119873
Validation loss: 1.979390992913195

Epoch: 6| Step: 7
Training loss: 1.0639474391937256
Validation loss: 1.9985527530793221

Epoch: 6| Step: 8
Training loss: 2.1229605674743652
Validation loss: 1.997970837418751

Epoch: 6| Step: 9
Training loss: 1.7125695943832397
Validation loss: 2.0102324024323495

Epoch: 6| Step: 10
Training loss: 2.8270139694213867
Validation loss: 2.009873869598553

Epoch: 6| Step: 11
Training loss: 1.529853343963623
Validation loss: 2.0207590313367945

Epoch: 6| Step: 12
Training loss: 1.711273431777954
Validation loss: 1.9968231493426907

Epoch: 6| Step: 13
Training loss: 1.2724535465240479
Validation loss: 1.9667916118457753

Epoch: 226| Step: 0
Training loss: 2.2846767902374268
Validation loss: 1.9699396958915136

Epoch: 6| Step: 1
Training loss: 1.3990366458892822
Validation loss: 2.001112458526447

Epoch: 6| Step: 2
Training loss: 1.5201306343078613
Validation loss: 1.9987707881517307

Epoch: 6| Step: 3
Training loss: 1.7149492502212524
Validation loss: 2.0125778798134095

Epoch: 6| Step: 4
Training loss: 2.7113096714019775
Validation loss: 2.001273816631686

Epoch: 6| Step: 5
Training loss: 1.6318254470825195
Validation loss: 1.9934952310336533

Epoch: 6| Step: 6
Training loss: 1.9115514755249023
Validation loss: 2.012233349584764

Epoch: 6| Step: 7
Training loss: 1.9513838291168213
Validation loss: 1.9919010362317484

Epoch: 6| Step: 8
Training loss: 1.8517132997512817
Validation loss: 1.9973305989337224

Epoch: 6| Step: 9
Training loss: 1.679325819015503
Validation loss: 1.9861005429298646

Epoch: 6| Step: 10
Training loss: 2.252478837966919
Validation loss: 2.0347868345117055

Epoch: 6| Step: 11
Training loss: 1.4460948705673218
Validation loss: 2.0525674768673476

Epoch: 6| Step: 12
Training loss: 2.7451119422912598
Validation loss: 2.0434329099552606

Epoch: 6| Step: 13
Training loss: 1.7683064937591553
Validation loss: 1.9695131701807822

Epoch: 227| Step: 0
Training loss: 2.2681007385253906
Validation loss: 1.998088716178812

Epoch: 6| Step: 1
Training loss: 1.9529646635055542
Validation loss: 2.0049214452825566

Epoch: 6| Step: 2
Training loss: 2.168243646621704
Validation loss: 1.9914502097714333

Epoch: 6| Step: 3
Training loss: 2.2802529335021973
Validation loss: 2.0060049744062525

Epoch: 6| Step: 4
Training loss: 1.5554986000061035
Validation loss: 1.966596390611382

Epoch: 6| Step: 5
Training loss: 2.1150026321411133
Validation loss: 2.002276958957795

Epoch: 6| Step: 6
Training loss: 1.849593162536621
Validation loss: 2.0039144818500807

Epoch: 6| Step: 7
Training loss: 1.3041490316390991
Validation loss: 1.976190714425938

Epoch: 6| Step: 8
Training loss: 1.8239030838012695
Validation loss: 2.0016002244846796

Epoch: 6| Step: 9
Training loss: 1.7932765483856201
Validation loss: 1.9883795553638088

Epoch: 6| Step: 10
Training loss: 2.4368019104003906
Validation loss: 2.021206284082064

Epoch: 6| Step: 11
Training loss: 2.1509740352630615
Validation loss: 2.010327946755194

Epoch: 6| Step: 12
Training loss: 1.0110090970993042
Validation loss: 1.9918327280270156

Epoch: 6| Step: 13
Training loss: 1.8295953273773193
Validation loss: 2.001928056440046

Epoch: 228| Step: 0
Training loss: 1.505563497543335
Validation loss: 1.9834695766049046

Epoch: 6| Step: 1
Training loss: 2.1172327995300293
Validation loss: 2.0026912086753437

Epoch: 6| Step: 2
Training loss: 1.7679047584533691
Validation loss: 1.9876807992176344

Epoch: 6| Step: 3
Training loss: 2.2442944049835205
Validation loss: 2.0130153727787796

Epoch: 6| Step: 4
Training loss: 1.4382939338684082
Validation loss: 1.9847810601675382

Epoch: 6| Step: 5
Training loss: 1.8607548475265503
Validation loss: 1.978564271362879

Epoch: 6| Step: 6
Training loss: 1.305490255355835
Validation loss: 2.0130902631308443

Epoch: 6| Step: 7
Training loss: 1.818156361579895
Validation loss: 1.9899556611173896

Epoch: 6| Step: 8
Training loss: 1.7219058275222778
Validation loss: 1.9929875148239957

Epoch: 6| Step: 9
Training loss: 2.3219776153564453
Validation loss: 1.995729463074797

Epoch: 6| Step: 10
Training loss: 1.9162545204162598
Validation loss: 2.0162813163572744

Epoch: 6| Step: 11
Training loss: 2.8259003162384033
Validation loss: 2.018902770934566

Epoch: 6| Step: 12
Training loss: 1.596407413482666
Validation loss: 2.0031620379417174

Epoch: 6| Step: 13
Training loss: 2.503077745437622
Validation loss: 1.9762724266257337

Epoch: 229| Step: 0
Training loss: 2.4226021766662598
Validation loss: 2.026601417090303

Epoch: 6| Step: 1
Training loss: 2.1897268295288086
Validation loss: 2.012682407133041

Epoch: 6| Step: 2
Training loss: 1.8007664680480957
Validation loss: 2.0086345608516405

Epoch: 6| Step: 3
Training loss: 1.6064088344573975
Validation loss: 1.9926197785203175

Epoch: 6| Step: 4
Training loss: 1.6089340448379517
Validation loss: 1.999825555791137

Epoch: 6| Step: 5
Training loss: 2.1238503456115723
Validation loss: 1.9886802986104002

Epoch: 6| Step: 6
Training loss: 1.3863837718963623
Validation loss: 2.0488369913511377

Epoch: 6| Step: 7
Training loss: 1.6755492687225342
Validation loss: 1.9574501232434345

Epoch: 6| Step: 8
Training loss: 2.3446364402770996
Validation loss: 2.054915589670981

Epoch: 6| Step: 9
Training loss: 2.251171588897705
Validation loss: 1.9923595548957906

Epoch: 6| Step: 10
Training loss: 1.583309292793274
Validation loss: 2.010434527550974

Epoch: 6| Step: 11
Training loss: 1.3930824995040894
Validation loss: 1.9651658047911942

Epoch: 6| Step: 12
Training loss: 1.7533454895019531
Validation loss: 1.993249467624131

Epoch: 6| Step: 13
Training loss: 2.2414474487304688
Validation loss: 2.0275660714795514

Epoch: 230| Step: 0
Training loss: 2.152078151702881
Validation loss: 1.984094233923061

Epoch: 6| Step: 1
Training loss: 1.8221834897994995
Validation loss: 1.9796067091726488

Epoch: 6| Step: 2
Training loss: 1.6554982662200928
Validation loss: 1.9852677852876726

Epoch: 6| Step: 3
Training loss: 2.855093002319336
Validation loss: 1.9786194639821206

Epoch: 6| Step: 4
Training loss: 1.5599833726882935
Validation loss: 1.977931627663233

Epoch: 6| Step: 5
Training loss: 1.7942173480987549
Validation loss: 1.9814217039333877

Epoch: 6| Step: 6
Training loss: 2.123227119445801
Validation loss: 2.016271222022272

Epoch: 6| Step: 7
Training loss: 1.0394091606140137
Validation loss: 2.0258558168206164

Epoch: 6| Step: 8
Training loss: 2.2058265209198
Validation loss: 1.990715624183737

Epoch: 6| Step: 9
Training loss: 1.8506875038146973
Validation loss: 2.045107688955081

Epoch: 6| Step: 10
Training loss: 1.955833911895752
Validation loss: 1.9906675559218212

Epoch: 6| Step: 11
Training loss: 1.8720049858093262
Validation loss: 2.016015948787812

Epoch: 6| Step: 12
Training loss: 1.7317811250686646
Validation loss: 1.9816467967084659

Epoch: 6| Step: 13
Training loss: 1.8258039951324463
Validation loss: 2.017501800291

Epoch: 231| Step: 0
Training loss: 1.4529623985290527
Validation loss: 2.0051839351654053

Epoch: 6| Step: 1
Training loss: 1.8638906478881836
Validation loss: 1.9910609491409794

Epoch: 6| Step: 2
Training loss: 2.0403099060058594
Validation loss: 1.9863905983586465

Epoch: 6| Step: 3
Training loss: 2.439638614654541
Validation loss: 1.9776615865768925

Epoch: 6| Step: 4
Training loss: 1.5226125717163086
Validation loss: 1.9757203927604101

Epoch: 6| Step: 5
Training loss: 2.918264389038086
Validation loss: 1.9712359751424482

Epoch: 6| Step: 6
Training loss: 1.6162707805633545
Validation loss: 2.0131308545348463

Epoch: 6| Step: 7
Training loss: 1.2504401206970215
Validation loss: 1.974232167325994

Epoch: 6| Step: 8
Training loss: 2.1626994609832764
Validation loss: 2.013375933452319

Epoch: 6| Step: 9
Training loss: 2.032731533050537
Validation loss: 1.9940166896389377

Epoch: 6| Step: 10
Training loss: 1.4460252523422241
Validation loss: 2.0110437639297976

Epoch: 6| Step: 11
Training loss: 2.1761960983276367
Validation loss: 1.9727651483269149

Epoch: 6| Step: 12
Training loss: 1.6659910678863525
Validation loss: 2.015625815237722

Epoch: 6| Step: 13
Training loss: 2.339700937271118
Validation loss: 1.9933491611993441

Epoch: 232| Step: 0
Training loss: 1.7867445945739746
Validation loss: 2.008387383594308

Epoch: 6| Step: 1
Training loss: 1.9991272687911987
Validation loss: 2.010739985332694

Epoch: 6| Step: 2
Training loss: 1.2259271144866943
Validation loss: 2.0220370702846076

Epoch: 6| Step: 3
Training loss: 2.272589683532715
Validation loss: 1.9991034999970467

Epoch: 6| Step: 4
Training loss: 1.6042572259902954
Validation loss: 2.0132162929863058

Epoch: 6| Step: 5
Training loss: 1.6386886835098267
Validation loss: 2.0181896917281614

Epoch: 6| Step: 6
Training loss: 2.306959390640259
Validation loss: 2.0168354690715833

Epoch: 6| Step: 7
Training loss: 1.8988394737243652
Validation loss: 2.0053387585506646

Epoch: 6| Step: 8
Training loss: 1.8928459882736206
Validation loss: 2.0115332629091

Epoch: 6| Step: 9
Training loss: 2.082437038421631
Validation loss: 2.0122887216588503

Epoch: 6| Step: 10
Training loss: 1.7701071500778198
Validation loss: 2.0094573651590655

Epoch: 6| Step: 11
Training loss: 2.0908191204071045
Validation loss: 2.006798158409775

Epoch: 6| Step: 12
Training loss: 2.4791266918182373
Validation loss: 2.032882462265671

Epoch: 6| Step: 13
Training loss: 1.759786605834961
Validation loss: 2.0198638387905654

Epoch: 233| Step: 0
Training loss: 1.6952160596847534
Validation loss: 2.034398800583296

Epoch: 6| Step: 1
Training loss: 1.54827082157135
Validation loss: 2.0163821481889292

Epoch: 6| Step: 2
Training loss: 2.049654960632324
Validation loss: 2.0529163293941046

Epoch: 6| Step: 3
Training loss: 2.3818278312683105
Validation loss: 2.003017574228266

Epoch: 6| Step: 4
Training loss: 2.388526439666748
Validation loss: 1.9755281440673336

Epoch: 6| Step: 5
Training loss: 1.6361361742019653
Validation loss: 2.003774924944806

Epoch: 6| Step: 6
Training loss: 2.1902151107788086
Validation loss: 2.0006995072928806

Epoch: 6| Step: 7
Training loss: 1.855453372001648
Validation loss: 1.9865447885246688

Epoch: 6| Step: 8
Training loss: 2.262615203857422
Validation loss: 2.0373128460299585

Epoch: 6| Step: 9
Training loss: 1.7405831813812256
Validation loss: 2.0203665494918823

Epoch: 6| Step: 10
Training loss: 2.3990564346313477
Validation loss: 1.9989842432801441

Epoch: 6| Step: 11
Training loss: 1.3551956415176392
Validation loss: 1.974419520747277

Epoch: 6| Step: 12
Training loss: 1.1141283512115479
Validation loss: 2.029225395571801

Epoch: 6| Step: 13
Training loss: 1.6306499242782593
Validation loss: 1.9935630880376345

Epoch: 234| Step: 0
Training loss: 2.091620922088623
Validation loss: 1.9929311557482647

Epoch: 6| Step: 1
Training loss: 1.7878732681274414
Validation loss: 1.9653940854534027

Epoch: 6| Step: 2
Training loss: 2.056417465209961
Validation loss: 1.9986985332222396

Epoch: 6| Step: 3
Training loss: 1.8477542400360107
Validation loss: 2.0177208351832565

Epoch: 6| Step: 4
Training loss: 2.629045009613037
Validation loss: 1.9909454545667093

Epoch: 6| Step: 5
Training loss: 2.479940414428711
Validation loss: 2.027030728196585

Epoch: 6| Step: 6
Training loss: 1.6616084575653076
Validation loss: 1.9961437948288456

Epoch: 6| Step: 7
Training loss: 0.9376376271247864
Validation loss: 2.0108988874702045

Epoch: 6| Step: 8
Training loss: 1.9784032106399536
Validation loss: 2.0421248866665747

Epoch: 6| Step: 9
Training loss: 1.9240269660949707
Validation loss: 1.9905149936676025

Epoch: 6| Step: 10
Training loss: 1.5895106792449951
Validation loss: 2.003905354007598

Epoch: 6| Step: 11
Training loss: 1.6387839317321777
Validation loss: 1.9971536026206067

Epoch: 6| Step: 12
Training loss: 2.007530689239502
Validation loss: 1.9943548479387838

Epoch: 6| Step: 13
Training loss: 2.0798072814941406
Validation loss: 1.9812066401204755

Epoch: 235| Step: 0
Training loss: 1.7782580852508545
Validation loss: 1.9886715591594737

Epoch: 6| Step: 1
Training loss: 2.48622465133667
Validation loss: 1.9865965676564041

Epoch: 6| Step: 2
Training loss: 1.4079515933990479
Validation loss: 2.008903572636266

Epoch: 6| Step: 3
Training loss: 2.4319095611572266
Validation loss: 1.9792295899442447

Epoch: 6| Step: 4
Training loss: 2.1733806133270264
Validation loss: 2.0172892334640666

Epoch: 6| Step: 5
Training loss: 2.4267578125
Validation loss: 2.012017338506637

Epoch: 6| Step: 6
Training loss: 1.648360013961792
Validation loss: 2.0124777709284136

Epoch: 6| Step: 7
Training loss: 1.7012486457824707
Validation loss: 1.9940218643475605

Epoch: 6| Step: 8
Training loss: 1.972198247909546
Validation loss: 2.0298619270324707

Epoch: 6| Step: 9
Training loss: 1.2918304204940796
Validation loss: 2.0263299378015662

Epoch: 6| Step: 10
Training loss: 2.269893169403076
Validation loss: 2.0030773147459953

Epoch: 6| Step: 11
Training loss: 2.1795005798339844
Validation loss: 2.003812527143827

Epoch: 6| Step: 12
Training loss: 1.1779136657714844
Validation loss: 1.993014790678537

Epoch: 6| Step: 13
Training loss: 1.254367470741272
Validation loss: 2.00622284284202

Epoch: 236| Step: 0
Training loss: 1.8021584749221802
Validation loss: 1.9992452001058927

Epoch: 6| Step: 1
Training loss: 1.1052775382995605
Validation loss: 2.0199054107871106

Epoch: 6| Step: 2
Training loss: 1.764801263809204
Validation loss: 2.010906566855728

Epoch: 6| Step: 3
Training loss: 2.0564496517181396
Validation loss: 1.9973752293535458

Epoch: 6| Step: 4
Training loss: 2.396782875061035
Validation loss: 1.9754419826692151

Epoch: 6| Step: 5
Training loss: 2.4124245643615723
Validation loss: 2.0024146174871795

Epoch: 6| Step: 6
Training loss: 2.0574443340301514
Validation loss: 2.018518296621179

Epoch: 6| Step: 7
Training loss: 1.6240912675857544
Validation loss: 2.007380098424932

Epoch: 6| Step: 8
Training loss: 1.7004390954971313
Validation loss: 1.9886503386241134

Epoch: 6| Step: 9
Training loss: 2.281052589416504
Validation loss: 2.002359292840445

Epoch: 6| Step: 10
Training loss: 1.36305570602417
Validation loss: 1.9905432206328197

Epoch: 6| Step: 11
Training loss: 1.8528516292572021
Validation loss: 2.0098448107319493

Epoch: 6| Step: 12
Training loss: 1.9024310111999512
Validation loss: 1.9994972610986361

Epoch: 6| Step: 13
Training loss: 2.326411724090576
Validation loss: 1.9868885317156393

Epoch: 237| Step: 0
Training loss: 1.4430317878723145
Validation loss: 2.0088544071361585

Epoch: 6| Step: 1
Training loss: 1.4264870882034302
Validation loss: 2.0126513434994604

Epoch: 6| Step: 2
Training loss: 1.8078901767730713
Validation loss: 1.9889574640540666

Epoch: 6| Step: 3
Training loss: 1.382596731185913
Validation loss: 2.0602880806051274

Epoch: 6| Step: 4
Training loss: 2.6249756813049316
Validation loss: 2.0069473148674093

Epoch: 6| Step: 5
Training loss: 1.5855374336242676
Validation loss: 1.9831973493740123

Epoch: 6| Step: 6
Training loss: 2.7943036556243896
Validation loss: 2.0092339387504

Epoch: 6| Step: 7
Training loss: 2.173928737640381
Validation loss: 2.001740191572456

Epoch: 6| Step: 8
Training loss: 1.8154796361923218
Validation loss: 1.9884251112579017

Epoch: 6| Step: 9
Training loss: 1.672834038734436
Validation loss: 2.0168677965799966

Epoch: 6| Step: 10
Training loss: 2.140350818634033
Validation loss: 2.0029800707294094

Epoch: 6| Step: 11
Training loss: 2.1209492683410645
Validation loss: 1.9574709233417307

Epoch: 6| Step: 12
Training loss: 1.6755335330963135
Validation loss: 2.016056840137769

Epoch: 6| Step: 13
Training loss: 2.0678486824035645
Validation loss: 1.9908185979371429

Epoch: 238| Step: 0
Training loss: 1.647814393043518
Validation loss: 1.9534412122541858

Epoch: 6| Step: 1
Training loss: 2.0564823150634766
Validation loss: 1.9775485530976327

Epoch: 6| Step: 2
Training loss: 2.5966904163360596
Validation loss: 1.996573373835574

Epoch: 6| Step: 3
Training loss: 2.2154266834259033
Validation loss: 1.9867022575870636

Epoch: 6| Step: 4
Training loss: 1.9287947416305542
Validation loss: 2.012472216800977

Epoch: 6| Step: 5
Training loss: 1.4531843662261963
Validation loss: 1.9921335533101072

Epoch: 6| Step: 6
Training loss: 1.003374457359314
Validation loss: 2.0210518785702285

Epoch: 6| Step: 7
Training loss: 2.7098162174224854
Validation loss: 1.9999462071285452

Epoch: 6| Step: 8
Training loss: 1.8043761253356934
Validation loss: 2.0151761321611303

Epoch: 6| Step: 9
Training loss: 1.5334763526916504
Validation loss: 2.0143751290536698

Epoch: 6| Step: 10
Training loss: 2.007702350616455
Validation loss: 2.0023612835073985

Epoch: 6| Step: 11
Training loss: 1.507919192314148
Validation loss: 2.0002358280202395

Epoch: 6| Step: 12
Training loss: 2.356792449951172
Validation loss: 1.9904439218582646

Epoch: 6| Step: 13
Training loss: 1.3307509422302246
Validation loss: 1.999441836469917

Epoch: 239| Step: 0
Training loss: 2.0508859157562256
Validation loss: 1.9948024031936482

Epoch: 6| Step: 1
Training loss: 1.8727293014526367
Validation loss: 2.055393447158157

Epoch: 6| Step: 2
Training loss: 1.9317328929901123
Validation loss: 2.0090925821693997

Epoch: 6| Step: 3
Training loss: 1.8554357290267944
Validation loss: 2.008682935468612

Epoch: 6| Step: 4
Training loss: 2.409156322479248
Validation loss: 1.9861831511220625

Epoch: 6| Step: 5
Training loss: 2.14119291305542
Validation loss: 2.0078680053833993

Epoch: 6| Step: 6
Training loss: 1.6832754611968994
Validation loss: 2.0193257331848145

Epoch: 6| Step: 7
Training loss: 1.918565273284912
Validation loss: 1.9970384169650335

Epoch: 6| Step: 8
Training loss: 2.1326777935028076
Validation loss: 2.0421536532781457

Epoch: 6| Step: 9
Training loss: 1.6038784980773926
Validation loss: 2.004902805051496

Epoch: 6| Step: 10
Training loss: 1.6229921579360962
Validation loss: 2.026124039003926

Epoch: 6| Step: 11
Training loss: 2.0412421226501465
Validation loss: 1.9969005687262422

Epoch: 6| Step: 12
Training loss: 1.4322501420974731
Validation loss: 2.00968417813701

Epoch: 6| Step: 13
Training loss: 1.0318970680236816
Validation loss: 2.008720936313752

Epoch: 240| Step: 0
Training loss: 1.9304710626602173
Validation loss: 2.002683870254024

Epoch: 6| Step: 1
Training loss: 1.8848354816436768
Validation loss: 2.008557419623098

Epoch: 6| Step: 2
Training loss: 1.7746062278747559
Validation loss: 1.9975799155491654

Epoch: 6| Step: 3
Training loss: 1.638397216796875
Validation loss: 2.0180295372522004

Epoch: 6| Step: 4
Training loss: 1.7895275354385376
Validation loss: 1.991696952491678

Epoch: 6| Step: 5
Training loss: 1.6331477165222168
Validation loss: 2.0168331989678006

Epoch: 6| Step: 6
Training loss: 1.5795142650604248
Validation loss: 2.0510136337690454

Epoch: 6| Step: 7
Training loss: 1.2547314167022705
Validation loss: 2.001333259767102

Epoch: 6| Step: 8
Training loss: 2.9459588527679443
Validation loss: 1.9885774171480568

Epoch: 6| Step: 9
Training loss: 1.9420980215072632
Validation loss: 1.9925595688563522

Epoch: 6| Step: 10
Training loss: 2.576690912246704
Validation loss: 2.026703453833057

Epoch: 6| Step: 11
Training loss: 1.778517484664917
Validation loss: 1.9983105710757676

Epoch: 6| Step: 12
Training loss: 2.0581929683685303
Validation loss: 1.9852938011128416

Epoch: 6| Step: 13
Training loss: 1.8065869808197021
Validation loss: 1.9723903466296453

Epoch: 241| Step: 0
Training loss: 1.6963386535644531
Validation loss: 1.9992526410728373

Epoch: 6| Step: 1
Training loss: 1.7291345596313477
Validation loss: 2.0160498478079356

Epoch: 6| Step: 2
Training loss: 1.8564679622650146
Validation loss: 2.0357334152344735

Epoch: 6| Step: 3
Training loss: 1.7523000240325928
Validation loss: 2.01051006906776

Epoch: 6| Step: 4
Training loss: 2.4271140098571777
Validation loss: 1.9990515760196153

Epoch: 6| Step: 5
Training loss: 1.8909305334091187
Validation loss: 2.000099410292923

Epoch: 6| Step: 6
Training loss: 2.0430777072906494
Validation loss: 1.9918255921333068

Epoch: 6| Step: 7
Training loss: 2.071166753768921
Validation loss: 2.0206846242309897

Epoch: 6| Step: 8
Training loss: 1.7425874471664429
Validation loss: 1.9868814483765633

Epoch: 6| Step: 9
Training loss: 1.5594794750213623
Validation loss: 1.9868226474331272

Epoch: 6| Step: 10
Training loss: 1.7151261568069458
Validation loss: 2.0235249560366393

Epoch: 6| Step: 11
Training loss: 1.9032979011535645
Validation loss: 1.9757287451016006

Epoch: 6| Step: 12
Training loss: 1.7819223403930664
Validation loss: 2.005942666402427

Epoch: 6| Step: 13
Training loss: 2.4055027961730957
Validation loss: 1.9831494092941284

Epoch: 242| Step: 0
Training loss: 2.2179081439971924
Validation loss: 2.0063094554408902

Epoch: 6| Step: 1
Training loss: 1.995295763015747
Validation loss: 1.9884512552651026

Epoch: 6| Step: 2
Training loss: 2.3912713527679443
Validation loss: 1.9865163244226927

Epoch: 6| Step: 3
Training loss: 1.733067274093628
Validation loss: 2.0297747017234884

Epoch: 6| Step: 4
Training loss: 1.7781119346618652
Validation loss: 2.0038834489801878

Epoch: 6| Step: 5
Training loss: 2.2393524646759033
Validation loss: 2.0491472598045104

Epoch: 6| Step: 6
Training loss: 2.060894727706909
Validation loss: 1.9895519082264235

Epoch: 6| Step: 7
Training loss: 1.487684726715088
Validation loss: 2.00140723874492

Epoch: 6| Step: 8
Training loss: 1.2436246871948242
Validation loss: 2.019802836961644

Epoch: 6| Step: 9
Training loss: 1.7923181056976318
Validation loss: 1.9847063018429665

Epoch: 6| Step: 10
Training loss: 1.559648871421814
Validation loss: 2.0404036775712044

Epoch: 6| Step: 11
Training loss: 2.692267894744873
Validation loss: 2.0245855034038587

Epoch: 6| Step: 12
Training loss: 1.6573994159698486
Validation loss: 2.0170551987104517

Epoch: 6| Step: 13
Training loss: 0.8560140132904053
Validation loss: 2.013942233977779

Epoch: 243| Step: 0
Training loss: 1.642028570175171
Validation loss: 2.0308131633266324

Epoch: 6| Step: 1
Training loss: 1.323425054550171
Validation loss: 2.014469841475128

Epoch: 6| Step: 2
Training loss: 2.205462694168091
Validation loss: 2.020244957298361

Epoch: 6| Step: 3
Training loss: 2.5133326053619385
Validation loss: 2.0636451423809095

Epoch: 6| Step: 4
Training loss: 1.4677129983901978
Validation loss: 2.0199938281889884

Epoch: 6| Step: 5
Training loss: 1.7655162811279297
Validation loss: 2.0357354661469818

Epoch: 6| Step: 6
Training loss: 1.6788039207458496
Validation loss: 2.031565873853622

Epoch: 6| Step: 7
Training loss: 1.844225525856018
Validation loss: 2.0011017123858132

Epoch: 6| Step: 8
Training loss: 1.6121653318405151
Validation loss: 2.0624927320787982

Epoch: 6| Step: 9
Training loss: 3.167562484741211
Validation loss: 2.0412254307859685

Epoch: 6| Step: 10
Training loss: 0.9333253502845764
Validation loss: 2.0451033884479153

Epoch: 6| Step: 11
Training loss: 1.8488290309906006
Validation loss: 2.0273097381796887

Epoch: 6| Step: 12
Training loss: 2.227724075317383
Validation loss: 1.9988550140011696

Epoch: 6| Step: 13
Training loss: 1.8762692213058472
Validation loss: 2.020698102571631

Epoch: 244| Step: 0
Training loss: 1.8969264030456543
Validation loss: 2.029898033347181

Epoch: 6| Step: 1
Training loss: 2.0946693420410156
Validation loss: 2.0102256446756344

Epoch: 6| Step: 2
Training loss: 2.3820414543151855
Validation loss: 2.0041676823810866

Epoch: 6| Step: 3
Training loss: 1.5963702201843262
Validation loss: 1.9805961065394904

Epoch: 6| Step: 4
Training loss: 2.05332612991333
Validation loss: 2.002466606837447

Epoch: 6| Step: 5
Training loss: 2.0139412879943848
Validation loss: 2.041935328514345

Epoch: 6| Step: 6
Training loss: 1.143808126449585
Validation loss: 2.016520787310857

Epoch: 6| Step: 7
Training loss: 1.534391164779663
Validation loss: 1.9745040529517717

Epoch: 6| Step: 8
Training loss: 2.2856011390686035
Validation loss: 2.006025432258524

Epoch: 6| Step: 9
Training loss: 1.9694831371307373
Validation loss: 2.0213072684503373

Epoch: 6| Step: 10
Training loss: 2.1594324111938477
Validation loss: 1.9946202744719803

Epoch: 6| Step: 11
Training loss: 1.5490858554840088
Validation loss: 1.9787595092609365

Epoch: 6| Step: 12
Training loss: 1.3810532093048096
Validation loss: 1.9743510048876527

Epoch: 6| Step: 13
Training loss: 2.8385097980499268
Validation loss: 1.9773205787904802

Epoch: 245| Step: 0
Training loss: 2.0628838539123535
Validation loss: 1.991331664464807

Epoch: 6| Step: 1
Training loss: 1.8919683694839478
Validation loss: 2.017703956173312

Epoch: 6| Step: 2
Training loss: 2.00825834274292
Validation loss: 1.9799106377427296

Epoch: 6| Step: 3
Training loss: 1.548846960067749
Validation loss: 2.014913130831975

Epoch: 6| Step: 4
Training loss: 1.64335036277771
Validation loss: 1.9727436188728578

Epoch: 6| Step: 5
Training loss: 1.5307188034057617
Validation loss: 1.9925090138630202

Epoch: 6| Step: 6
Training loss: 2.0285558700561523
Validation loss: 1.9876381530556628

Epoch: 6| Step: 7
Training loss: 1.7357683181762695
Validation loss: 2.0362772659588884

Epoch: 6| Step: 8
Training loss: 1.1958307027816772
Validation loss: 1.9972113178622337

Epoch: 6| Step: 9
Training loss: 1.8940998315811157
Validation loss: 1.982738761491673

Epoch: 6| Step: 10
Training loss: 1.8514435291290283
Validation loss: 1.9995532753647014

Epoch: 6| Step: 11
Training loss: 2.1437578201293945
Validation loss: 2.024370780555151

Epoch: 6| Step: 12
Training loss: 2.4883742332458496
Validation loss: 2.0312409375303533

Epoch: 6| Step: 13
Training loss: 2.150312662124634
Validation loss: 2.020248838650283

Epoch: 246| Step: 0
Training loss: 1.7802598476409912
Validation loss: 1.977944585584825

Epoch: 6| Step: 1
Training loss: 2.173417568206787
Validation loss: 2.0143009513937016

Epoch: 6| Step: 2
Training loss: 2.019477128982544
Validation loss: 1.9726572395652853

Epoch: 6| Step: 3
Training loss: 1.529745101928711
Validation loss: 1.977994522740764

Epoch: 6| Step: 4
Training loss: 1.3711594343185425
Validation loss: 2.0113620809329453

Epoch: 6| Step: 5
Training loss: 1.6225357055664062
Validation loss: 1.951126084532789

Epoch: 6| Step: 6
Training loss: 2.040618419647217
Validation loss: 2.051727617940595

Epoch: 6| Step: 7
Training loss: 2.2387332916259766
Validation loss: 2.0122945718867804

Epoch: 6| Step: 8
Training loss: 2.850397825241089
Validation loss: 1.9863824767451133

Epoch: 6| Step: 9
Training loss: 2.18896222114563
Validation loss: 2.0090063976985153

Epoch: 6| Step: 10
Training loss: 1.2025331258773804
Validation loss: 1.9891037325705252

Epoch: 6| Step: 11
Training loss: 1.5710515975952148
Validation loss: 2.0263622319826515

Epoch: 6| Step: 12
Training loss: 1.6431889533996582
Validation loss: 2.0063636969494563

Epoch: 6| Step: 13
Training loss: 1.8463959693908691
Validation loss: 2.0341840661982054

Epoch: 247| Step: 0
Training loss: 2.6523799896240234
Validation loss: 2.019553219118426

Epoch: 6| Step: 1
Training loss: 2.453157901763916
Validation loss: 2.0137221582474245

Epoch: 6| Step: 2
Training loss: 1.7260191440582275
Validation loss: 2.016263679791522

Epoch: 6| Step: 3
Training loss: 1.1407392024993896
Validation loss: 2.016397919706119

Epoch: 6| Step: 4
Training loss: 2.0166900157928467
Validation loss: 1.9715274251917356

Epoch: 6| Step: 5
Training loss: 1.376718521118164
Validation loss: 2.0175270803513063

Epoch: 6| Step: 6
Training loss: 2.207554817199707
Validation loss: 2.0059362790917836

Epoch: 6| Step: 7
Training loss: 2.3713650703430176
Validation loss: 2.0211946272080943

Epoch: 6| Step: 8
Training loss: 1.2722969055175781
Validation loss: 2.0151618680646344

Epoch: 6| Step: 9
Training loss: 1.5813413858413696
Validation loss: 2.0362422030459166

Epoch: 6| Step: 10
Training loss: 1.8090122938156128
Validation loss: 1.9874341026429208

Epoch: 6| Step: 11
Training loss: 1.5373919010162354
Validation loss: 2.0427500150536977

Epoch: 6| Step: 12
Training loss: 2.1714563369750977
Validation loss: 1.9810669986150597

Epoch: 6| Step: 13
Training loss: 1.7392864227294922
Validation loss: 2.0140540702368623

Epoch: 248| Step: 0
Training loss: 1.6488075256347656
Validation loss: 2.039180317232686

Epoch: 6| Step: 1
Training loss: 1.8485074043273926
Validation loss: 1.9977953177626415

Epoch: 6| Step: 2
Training loss: 2.1312198638916016
Validation loss: 2.001154048468477

Epoch: 6| Step: 3
Training loss: 1.6350929737091064
Validation loss: 2.0075697078499743

Epoch: 6| Step: 4
Training loss: 1.7494410276412964
Validation loss: 2.0364809613074026

Epoch: 6| Step: 5
Training loss: 2.07716703414917
Validation loss: 2.014375461045132

Epoch: 6| Step: 6
Training loss: 1.874710202217102
Validation loss: 2.015483863892094

Epoch: 6| Step: 7
Training loss: 1.7494306564331055
Validation loss: 1.985800725157543

Epoch: 6| Step: 8
Training loss: 1.435708999633789
Validation loss: 2.0047732053264493

Epoch: 6| Step: 9
Training loss: 1.5825684070587158
Validation loss: 1.9947624847453127

Epoch: 6| Step: 10
Training loss: 1.546149492263794
Validation loss: 2.0175925172785276

Epoch: 6| Step: 11
Training loss: 2.366952419281006
Validation loss: 2.0372637805118354

Epoch: 6| Step: 12
Training loss: 2.1522326469421387
Validation loss: 2.002376180823131

Epoch: 6| Step: 13
Training loss: 2.4569010734558105
Validation loss: 2.0066839251466977

Epoch: 249| Step: 0
Training loss: 1.6301872730255127
Validation loss: 2.0162869422666487

Epoch: 6| Step: 1
Training loss: 1.841753602027893
Validation loss: 2.0087465099109116

Epoch: 6| Step: 2
Training loss: 2.2708044052124023
Validation loss: 2.0260421255583405

Epoch: 6| Step: 3
Training loss: 1.9740314483642578
Validation loss: 2.0099267792958084

Epoch: 6| Step: 4
Training loss: 2.1754820346832275
Validation loss: 2.014271402871737

Epoch: 6| Step: 5
Training loss: 1.375737190246582
Validation loss: 1.9931509546054307

Epoch: 6| Step: 6
Training loss: 1.3505266904830933
Validation loss: 2.019439197355701

Epoch: 6| Step: 7
Training loss: 1.87943434715271
Validation loss: 2.0156437402130454

Epoch: 6| Step: 8
Training loss: 1.7042213678359985
Validation loss: 1.9897423175073439

Epoch: 6| Step: 9
Training loss: 1.8660037517547607
Validation loss: 2.01184537846555

Epoch: 6| Step: 10
Training loss: 1.8314182758331299
Validation loss: 1.9980694311921314

Epoch: 6| Step: 11
Training loss: 1.6432197093963623
Validation loss: 1.9978533842230355

Epoch: 6| Step: 12
Training loss: 2.489051580429077
Validation loss: 1.994322261502666

Epoch: 6| Step: 13
Training loss: 1.8896650075912476
Validation loss: 2.0240734533597062

Epoch: 250| Step: 0
Training loss: 1.6856458187103271
Validation loss: 2.027229356509383

Epoch: 6| Step: 1
Training loss: 2.2073488235473633
Validation loss: 2.007863995849445

Epoch: 6| Step: 2
Training loss: 2.178637981414795
Validation loss: 2.0054017190010316

Epoch: 6| Step: 3
Training loss: 1.990934133529663
Validation loss: 2.006560266658824

Epoch: 6| Step: 4
Training loss: 1.6239054203033447
Validation loss: 2.008434964764503

Epoch: 6| Step: 5
Training loss: 1.6486821174621582
Validation loss: 2.01608774738927

Epoch: 6| Step: 6
Training loss: 1.3010811805725098
Validation loss: 2.030566410351825

Epoch: 6| Step: 7
Training loss: 2.2976460456848145
Validation loss: 2.0235746278557727

Epoch: 6| Step: 8
Training loss: 1.8803324699401855
Validation loss: 2.021935175823909

Epoch: 6| Step: 9
Training loss: 2.03397798538208
Validation loss: 2.040432330100767

Epoch: 6| Step: 10
Training loss: 1.440795660018921
Validation loss: 2.0224249875673683

Epoch: 6| Step: 11
Training loss: 1.2333362102508545
Validation loss: 2.0436619738096833

Epoch: 6| Step: 12
Training loss: 2.1037368774414062
Validation loss: 2.0495398121495403

Epoch: 6| Step: 13
Training loss: 2.525074005126953
Validation loss: 2.0092447303956553

Epoch: 251| Step: 0
Training loss: 1.485198974609375
Validation loss: 2.018903870736399

Epoch: 6| Step: 1
Training loss: 1.9176496267318726
Validation loss: 2.0266550740888043

Epoch: 6| Step: 2
Training loss: 1.8537485599517822
Validation loss: 2.0316058140929028

Epoch: 6| Step: 3
Training loss: 2.0282135009765625
Validation loss: 2.021455011060161

Epoch: 6| Step: 4
Training loss: 2.0223193168640137
Validation loss: 1.9899483739688832

Epoch: 6| Step: 5
Training loss: 1.7936100959777832
Validation loss: 2.000727354839284

Epoch: 6| Step: 6
Training loss: 1.3921526670455933
Validation loss: 1.995689897127049

Epoch: 6| Step: 7
Training loss: 1.2980296611785889
Validation loss: 2.012529642351212

Epoch: 6| Step: 8
Training loss: 1.897160530090332
Validation loss: 2.019678674718385

Epoch: 6| Step: 9
Training loss: 2.058091163635254
Validation loss: 2.0429079609532512

Epoch: 6| Step: 10
Training loss: 1.9475853443145752
Validation loss: 2.057911756218121

Epoch: 6| Step: 11
Training loss: 1.9545320272445679
Validation loss: 2.0177857183641

Epoch: 6| Step: 12
Training loss: 2.121455669403076
Validation loss: 1.960957633551731

Epoch: 6| Step: 13
Training loss: 1.983467698097229
Validation loss: 2.035250179229244

Epoch: 252| Step: 0
Training loss: 1.5072095394134521
Validation loss: 2.005188872737269

Epoch: 6| Step: 1
Training loss: 2.440260887145996
Validation loss: 2.014238324216617

Epoch: 6| Step: 2
Training loss: 1.6203281879425049
Validation loss: 2.021282221681328

Epoch: 6| Step: 3
Training loss: 1.6789554357528687
Validation loss: 1.9868853348557667

Epoch: 6| Step: 4
Training loss: 1.5295486450195312
Validation loss: 2.018562747586158

Epoch: 6| Step: 5
Training loss: 1.6221987009048462
Validation loss: 1.9848023358211722

Epoch: 6| Step: 6
Training loss: 1.9422094821929932
Validation loss: 1.9901410238717192

Epoch: 6| Step: 7
Training loss: 2.2145261764526367
Validation loss: 2.0061477679078297

Epoch: 6| Step: 8
Training loss: 1.4530665874481201
Validation loss: 2.009825268099385

Epoch: 6| Step: 9
Training loss: 1.734912395477295
Validation loss: 2.013809783484346

Epoch: 6| Step: 10
Training loss: 1.5905580520629883
Validation loss: 2.029866405712661

Epoch: 6| Step: 11
Training loss: 2.4813084602355957
Validation loss: 2.005334395234303

Epoch: 6| Step: 12
Training loss: 1.972301959991455
Validation loss: 2.0248813026694843

Epoch: 6| Step: 13
Training loss: 2.263606548309326
Validation loss: 2.0114311172116186

Epoch: 253| Step: 0
Training loss: 1.9130799770355225
Validation loss: 1.9732287199266496

Epoch: 6| Step: 1
Training loss: 1.33723783493042
Validation loss: 2.004481456613028

Epoch: 6| Step: 2
Training loss: 1.7810742855072021
Validation loss: 2.0599114869230535

Epoch: 6| Step: 3
Training loss: 2.500964879989624
Validation loss: 2.0024084327041463

Epoch: 6| Step: 4
Training loss: 1.6966118812561035
Validation loss: 1.9942367717783938

Epoch: 6| Step: 5
Training loss: 1.7091375589370728
Validation loss: 1.9876409115329865

Epoch: 6| Step: 6
Training loss: 1.6997828483581543
Validation loss: 2.033526820521201

Epoch: 6| Step: 7
Training loss: 1.850956678390503
Validation loss: 2.0096891157088743

Epoch: 6| Step: 8
Training loss: 1.7434784173965454
Validation loss: 2.017889925228652

Epoch: 6| Step: 9
Training loss: 1.7131071090698242
Validation loss: 2.02910194858428

Epoch: 6| Step: 10
Training loss: 1.7594399452209473
Validation loss: 2.0586949612504695

Epoch: 6| Step: 11
Training loss: 2.146831512451172
Validation loss: 1.9927332939640168

Epoch: 6| Step: 12
Training loss: 2.1484036445617676
Validation loss: 1.9980196901547012

Epoch: 6| Step: 13
Training loss: 1.7708474397659302
Validation loss: 2.021640703242312

Epoch: 254| Step: 0
Training loss: 1.2086045742034912
Validation loss: 2.025969191264081

Epoch: 6| Step: 1
Training loss: 1.7484114170074463
Validation loss: 2.010807277053915

Epoch: 6| Step: 2
Training loss: 1.8050938844680786
Validation loss: 1.9989523272360525

Epoch: 6| Step: 3
Training loss: 2.139893054962158
Validation loss: 2.00649118679826

Epoch: 6| Step: 4
Training loss: 1.643463134765625
Validation loss: 2.0404780744224467

Epoch: 6| Step: 5
Training loss: 2.186793565750122
Validation loss: 1.989400581646991

Epoch: 6| Step: 6
Training loss: 1.932895541191101
Validation loss: 2.0342029807388142

Epoch: 6| Step: 7
Training loss: 2.164153814315796
Validation loss: 2.0053687493006387

Epoch: 6| Step: 8
Training loss: 2.2694926261901855
Validation loss: 2.0110070628504597

Epoch: 6| Step: 9
Training loss: 1.7136728763580322
Validation loss: 2.042277584793747

Epoch: 6| Step: 10
Training loss: 1.7483669519424438
Validation loss: 1.9794639618166032

Epoch: 6| Step: 11
Training loss: 2.171992540359497
Validation loss: 2.0049632287794545

Epoch: 6| Step: 12
Training loss: 1.8643970489501953
Validation loss: 1.9901808923290623

Epoch: 6| Step: 13
Training loss: 1.6052532196044922
Validation loss: 2.023084860976024

Epoch: 255| Step: 0
Training loss: 1.025846242904663
Validation loss: 2.008637196274214

Epoch: 6| Step: 1
Training loss: 1.938680648803711
Validation loss: 1.9759337235522527

Epoch: 6| Step: 2
Training loss: 1.0963108539581299
Validation loss: 2.022372176570277

Epoch: 6| Step: 3
Training loss: 2.1728546619415283
Validation loss: 1.9994024410042712

Epoch: 6| Step: 4
Training loss: 2.0902678966522217
Validation loss: 2.0082564892307406

Epoch: 6| Step: 5
Training loss: 1.7663805484771729
Validation loss: 2.024047105543075

Epoch: 6| Step: 6
Training loss: 2.1444125175476074
Validation loss: 2.011332710584005

Epoch: 6| Step: 7
Training loss: 2.1628618240356445
Validation loss: 2.0678380330403647

Epoch: 6| Step: 8
Training loss: 2.5220818519592285
Validation loss: 2.0227995175187305

Epoch: 6| Step: 9
Training loss: 1.668473482131958
Validation loss: 2.030892527231606

Epoch: 6| Step: 10
Training loss: 2.201066255569458
Validation loss: 2.0148127745556574

Epoch: 6| Step: 11
Training loss: 1.4584991931915283
Validation loss: 2.038599924374652

Epoch: 6| Step: 12
Training loss: 1.5410317182540894
Validation loss: 2.025921462684549

Epoch: 6| Step: 13
Training loss: 1.813018798828125
Validation loss: 2.005323909944104

Epoch: 256| Step: 0
Training loss: 1.7708386182785034
Validation loss: 2.014251724366219

Epoch: 6| Step: 1
Training loss: 2.5450456142425537
Validation loss: 2.0282039232151483

Epoch: 6| Step: 2
Training loss: 1.9822373390197754
Validation loss: 1.9894737607689315

Epoch: 6| Step: 3
Training loss: 2.045423984527588
Validation loss: 2.026178821440666

Epoch: 6| Step: 4
Training loss: 2.214186429977417
Validation loss: 2.0438127427972774

Epoch: 6| Step: 5
Training loss: 1.5803260803222656
Validation loss: 2.001857142294607

Epoch: 6| Step: 6
Training loss: 1.6500444412231445
Validation loss: 1.9937519347795876

Epoch: 6| Step: 7
Training loss: 1.706391453742981
Validation loss: 2.0331606557292323

Epoch: 6| Step: 8
Training loss: 1.8158940076828003
Validation loss: 2.0096667351261264

Epoch: 6| Step: 9
Training loss: 1.226633071899414
Validation loss: 2.0046035756347

Epoch: 6| Step: 10
Training loss: 1.555286169052124
Validation loss: 2.0204663558672835

Epoch: 6| Step: 11
Training loss: 2.2579171657562256
Validation loss: 1.9987988677076114

Epoch: 6| Step: 12
Training loss: 1.7803577184677124
Validation loss: 1.9990815424150037

Epoch: 6| Step: 13
Training loss: 1.2554850578308105
Validation loss: 1.9864878808298418

Epoch: 257| Step: 0
Training loss: 1.7649376392364502
Validation loss: 1.9969922880972586

Epoch: 6| Step: 1
Training loss: 1.3729387521743774
Validation loss: 2.0037275309203775

Epoch: 6| Step: 2
Training loss: 2.067967414855957
Validation loss: 2.0233963035768077

Epoch: 6| Step: 3
Training loss: 1.427556037902832
Validation loss: 2.000871519888601

Epoch: 6| Step: 4
Training loss: 1.311261773109436
Validation loss: 2.0147698848478255

Epoch: 6| Step: 5
Training loss: 2.0764904022216797
Validation loss: 2.0343410430415982

Epoch: 6| Step: 6
Training loss: 1.680788516998291
Validation loss: 1.9857203114417292

Epoch: 6| Step: 7
Training loss: 1.525850534439087
Validation loss: 2.0221763131439046

Epoch: 6| Step: 8
Training loss: 1.9060935974121094
Validation loss: 2.0301418817171486

Epoch: 6| Step: 9
Training loss: 2.966099262237549
Validation loss: 2.008651976944298

Epoch: 6| Step: 10
Training loss: 1.680701494216919
Validation loss: 1.9939058903724916

Epoch: 6| Step: 11
Training loss: 1.8816856145858765
Validation loss: 2.023337571851669

Epoch: 6| Step: 12
Training loss: 2.0546092987060547
Validation loss: 2.034901101102111

Epoch: 6| Step: 13
Training loss: 2.3643617630004883
Validation loss: 1.9848821265723116

Epoch: 258| Step: 0
Training loss: 2.0774097442626953
Validation loss: 2.0236817675252117

Epoch: 6| Step: 1
Training loss: 1.558713674545288
Validation loss: 1.9787910266589093

Epoch: 6| Step: 2
Training loss: 1.5835726261138916
Validation loss: 2.0497771219540666

Epoch: 6| Step: 3
Training loss: 2.1164021492004395
Validation loss: 2.0206971476154942

Epoch: 6| Step: 4
Training loss: 2.6278204917907715
Validation loss: 2.0431732618680565

Epoch: 6| Step: 5
Training loss: 1.6726455688476562
Validation loss: 2.0623066822687783

Epoch: 6| Step: 6
Training loss: 1.3908687829971313
Validation loss: 2.000647444878855

Epoch: 6| Step: 7
Training loss: 1.4867048263549805
Validation loss: 2.0460914405443336

Epoch: 6| Step: 8
Training loss: 2.440849781036377
Validation loss: 2.03791566048899

Epoch: 6| Step: 9
Training loss: 1.6413705348968506
Validation loss: 2.048943614446989

Epoch: 6| Step: 10
Training loss: 1.7707598209381104
Validation loss: 2.0371635216538624

Epoch: 6| Step: 11
Training loss: 1.8491759300231934
Validation loss: 2.043780626789216

Epoch: 6| Step: 12
Training loss: 1.6183247566223145
Validation loss: 2.0421426667962024

Epoch: 6| Step: 13
Training loss: 1.77987802028656
Validation loss: 2.0585708182345153

Epoch: 259| Step: 0
Training loss: 1.550088882446289
Validation loss: 2.05248853980854

Epoch: 6| Step: 1
Training loss: 2.500119686126709
Validation loss: 2.047714005234421

Epoch: 6| Step: 2
Training loss: 2.2864608764648438
Validation loss: 2.0522780341486775

Epoch: 6| Step: 3
Training loss: 1.7399111986160278
Validation loss: 2.0401296820691837

Epoch: 6| Step: 4
Training loss: 1.9193780422210693
Validation loss: 1.9929535440219346

Epoch: 6| Step: 5
Training loss: 1.0712286233901978
Validation loss: 2.0482846921490085

Epoch: 6| Step: 6
Training loss: 1.5075167417526245
Validation loss: 2.0412230286546933

Epoch: 6| Step: 7
Training loss: 2.114193916320801
Validation loss: 2.076246071887273

Epoch: 6| Step: 8
Training loss: 1.410175085067749
Validation loss: 1.9935407702640822

Epoch: 6| Step: 9
Training loss: 1.7589744329452515
Validation loss: 2.0196491723419516

Epoch: 6| Step: 10
Training loss: 2.0105295181274414
Validation loss: 2.0119775533676147

Epoch: 6| Step: 11
Training loss: 2.026057243347168
Validation loss: 2.0101307797175583

Epoch: 6| Step: 12
Training loss: 1.9635921716690063
Validation loss: 2.029677524361559

Epoch: 6| Step: 13
Training loss: 1.7161803245544434
Validation loss: 2.0153472846554172

Epoch: 260| Step: 0
Training loss: 2.184237241744995
Validation loss: 1.9882515066413469

Epoch: 6| Step: 1
Training loss: 1.4065427780151367
Validation loss: 1.9912404962765273

Epoch: 6| Step: 2
Training loss: 1.7338385581970215
Validation loss: 2.0149448289666125

Epoch: 6| Step: 3
Training loss: 1.4629738330841064
Validation loss: 2.045875676216618

Epoch: 6| Step: 4
Training loss: 1.6959519386291504
Validation loss: 2.0385974171341106

Epoch: 6| Step: 5
Training loss: 2.211360454559326
Validation loss: 1.9920669012172247

Epoch: 6| Step: 6
Training loss: 2.104922294616699
Validation loss: 2.000534842091222

Epoch: 6| Step: 7
Training loss: 2.006493091583252
Validation loss: 2.0087767518976682

Epoch: 6| Step: 8
Training loss: 1.5940744876861572
Validation loss: 2.021355544367144

Epoch: 6| Step: 9
Training loss: 2.1385550498962402
Validation loss: 2.0280201511998333

Epoch: 6| Step: 10
Training loss: 2.221167802810669
Validation loss: 1.9739643040523733

Epoch: 6| Step: 11
Training loss: 1.8861162662506104
Validation loss: 2.009327701343003

Epoch: 6| Step: 12
Training loss: 1.7713439464569092
Validation loss: 1.9950403013537008

Epoch: 6| Step: 13
Training loss: 0.6314467787742615
Validation loss: 1.9889818865765807

Epoch: 261| Step: 0
Training loss: 1.8047242164611816
Validation loss: 2.01193541865195

Epoch: 6| Step: 1
Training loss: 1.7518656253814697
Validation loss: 1.9960852733222387

Epoch: 6| Step: 2
Training loss: 2.5816164016723633
Validation loss: 1.9958263302362094

Epoch: 6| Step: 3
Training loss: 1.7047960758209229
Validation loss: 2.0248039255860033

Epoch: 6| Step: 4
Training loss: 1.8034446239471436
Validation loss: 2.028351345369893

Epoch: 6| Step: 5
Training loss: 1.601280927658081
Validation loss: 2.059175278550835

Epoch: 6| Step: 6
Training loss: 1.7559783458709717
Validation loss: 2.006857490026823

Epoch: 6| Step: 7
Training loss: 1.8032567501068115
Validation loss: 2.025907011442287

Epoch: 6| Step: 8
Training loss: 1.7045221328735352
Validation loss: 2.0578793582095893

Epoch: 6| Step: 9
Training loss: 2.0358657836914062
Validation loss: 2.0362398650056575

Epoch: 6| Step: 10
Training loss: 1.719286322593689
Validation loss: 2.0319802068894908

Epoch: 6| Step: 11
Training loss: 1.2610548734664917
Validation loss: 2.0397111779900006

Epoch: 6| Step: 12
Training loss: 2.1179518699645996
Validation loss: 2.011682584721555

Epoch: 6| Step: 13
Training loss: 2.2203354835510254
Validation loss: 2.017336869752535

Epoch: 262| Step: 0
Training loss: 1.3435567617416382
Validation loss: 2.0382600445901193

Epoch: 6| Step: 1
Training loss: 1.966722011566162
Validation loss: 2.0530188058012273

Epoch: 6| Step: 2
Training loss: 1.9399101734161377
Validation loss: 1.9802057281617196

Epoch: 6| Step: 3
Training loss: 1.3217673301696777
Validation loss: 2.0400299513211815

Epoch: 6| Step: 4
Training loss: 1.2323384284973145
Validation loss: 2.0122467856253348

Epoch: 6| Step: 5
Training loss: 2.3223347663879395
Validation loss: 2.008532998382404

Epoch: 6| Step: 6
Training loss: 2.084182024002075
Validation loss: 2.0086731090340564

Epoch: 6| Step: 7
Training loss: 1.558241605758667
Validation loss: 2.03200787626287

Epoch: 6| Step: 8
Training loss: 2.208319664001465
Validation loss: 2.0154604809258574

Epoch: 6| Step: 9
Training loss: 2.2277145385742188
Validation loss: 2.0096410282196535

Epoch: 6| Step: 10
Training loss: 2.4822163581848145
Validation loss: 2.022596022134186

Epoch: 6| Step: 11
Training loss: 1.855189561843872
Validation loss: 2.0006890066208376

Epoch: 6| Step: 12
Training loss: 1.1917755603790283
Validation loss: 2.00331602814377

Epoch: 6| Step: 13
Training loss: 1.8180689811706543
Validation loss: 2.0199879664246754

Epoch: 263| Step: 0
Training loss: 1.9571619033813477
Validation loss: 2.0100366146333757

Epoch: 6| Step: 1
Training loss: 1.5962274074554443
Validation loss: 1.9987674592643656

Epoch: 6| Step: 2
Training loss: 1.5351557731628418
Validation loss: 2.000836344175441

Epoch: 6| Step: 3
Training loss: 1.8865244388580322
Validation loss: 2.0633134790646133

Epoch: 6| Step: 4
Training loss: 2.0987324714660645
Validation loss: 2.0539147776942097

Epoch: 6| Step: 5
Training loss: 1.7778873443603516
Validation loss: 2.0086194366537113

Epoch: 6| Step: 6
Training loss: 1.7444312572479248
Validation loss: 2.0460294574819584

Epoch: 6| Step: 7
Training loss: 1.3818074464797974
Validation loss: 2.0377676717696653

Epoch: 6| Step: 8
Training loss: 1.2462985515594482
Validation loss: 2.039787705226611

Epoch: 6| Step: 9
Training loss: 1.818303108215332
Validation loss: 2.0877810408992152

Epoch: 6| Step: 10
Training loss: 1.8124656677246094
Validation loss: 2.047226257221673

Epoch: 6| Step: 11
Training loss: 2.4980406761169434
Validation loss: 2.0310110815109743

Epoch: 6| Step: 12
Training loss: 1.892208218574524
Validation loss: 2.0150961824642715

Epoch: 6| Step: 13
Training loss: 2.361937999725342
Validation loss: 2.02736565502741

Epoch: 264| Step: 0
Training loss: 2.4586691856384277
Validation loss: 2.039737647579562

Epoch: 6| Step: 1
Training loss: 1.8537617921829224
Validation loss: 2.074281878368829

Epoch: 6| Step: 2
Training loss: 2.1314826011657715
Validation loss: 2.027122820577314

Epoch: 6| Step: 3
Training loss: 1.2994016408920288
Validation loss: 2.0329660625867945

Epoch: 6| Step: 4
Training loss: 2.090488910675049
Validation loss: 1.9831655525392102

Epoch: 6| Step: 5
Training loss: 1.6310288906097412
Validation loss: 2.0186867637019

Epoch: 6| Step: 6
Training loss: 1.408084511756897
Validation loss: 2.0202494769968014

Epoch: 6| Step: 7
Training loss: 2.107815742492676
Validation loss: 1.9970295634320987

Epoch: 6| Step: 8
Training loss: 2.3300719261169434
Validation loss: 1.9989437262217205

Epoch: 6| Step: 9
Training loss: 2.0101685523986816
Validation loss: 2.004007242059195

Epoch: 6| Step: 10
Training loss: 1.4875962734222412
Validation loss: 2.0074824645955074

Epoch: 6| Step: 11
Training loss: 1.299387812614441
Validation loss: 1.9967589634720997

Epoch: 6| Step: 12
Training loss: 2.089954376220703
Validation loss: 2.025256561976607

Epoch: 6| Step: 13
Training loss: 1.170795202255249
Validation loss: 1.9632066988175916

Epoch: 265| Step: 0
Training loss: 1.9546922445297241
Validation loss: 2.0028785377420406

Epoch: 6| Step: 1
Training loss: 2.0431575775146484
Validation loss: 2.03120078579072

Epoch: 6| Step: 2
Training loss: 1.8414725065231323
Validation loss: 2.0220831876159995

Epoch: 6| Step: 3
Training loss: 2.085653305053711
Validation loss: 2.0353275140126548

Epoch: 6| Step: 4
Training loss: 2.04013991355896
Validation loss: 2.0884824132406585

Epoch: 6| Step: 5
Training loss: 1.4026371240615845
Validation loss: 2.002527675321025

Epoch: 6| Step: 6
Training loss: 1.6588618755340576
Validation loss: 2.018328674377934

Epoch: 6| Step: 7
Training loss: 1.6099584102630615
Validation loss: 2.0396445592244468

Epoch: 6| Step: 8
Training loss: 1.6950438022613525
Validation loss: 2.012465227034784

Epoch: 6| Step: 9
Training loss: 1.6083474159240723
Validation loss: 2.00800024437648

Epoch: 6| Step: 10
Training loss: 1.5566997528076172
Validation loss: 2.051207588564965

Epoch: 6| Step: 11
Training loss: 1.9640297889709473
Validation loss: 2.028508488849927

Epoch: 6| Step: 12
Training loss: 2.152495861053467
Validation loss: 2.030812882607983

Epoch: 6| Step: 13
Training loss: 2.18233585357666
Validation loss: 2.0323320563121507

Epoch: 266| Step: 0
Training loss: 1.845088243484497
Validation loss: 2.0436716310439573

Epoch: 6| Step: 1
Training loss: 1.1411914825439453
Validation loss: 2.0002556154804845

Epoch: 6| Step: 2
Training loss: 2.2274701595306396
Validation loss: 2.0184934331524755

Epoch: 6| Step: 3
Training loss: 2.139235496520996
Validation loss: 2.005190118666618

Epoch: 6| Step: 4
Training loss: 2.226814031600952
Validation loss: 2.0385223229726157

Epoch: 6| Step: 5
Training loss: 2.2415809631347656
Validation loss: 2.043660822735038

Epoch: 6| Step: 6
Training loss: 1.151475429534912
Validation loss: 2.026812216287018

Epoch: 6| Step: 7
Training loss: 1.243083119392395
Validation loss: 2.04951560753648

Epoch: 6| Step: 8
Training loss: 1.9315766096115112
Validation loss: 2.0052482107634186

Epoch: 6| Step: 9
Training loss: 2.0033302307128906
Validation loss: 2.0194507363022014

Epoch: 6| Step: 10
Training loss: 1.7306098937988281
Validation loss: 2.02640672140224

Epoch: 6| Step: 11
Training loss: 2.2015552520751953
Validation loss: 2.041538328252813

Epoch: 6| Step: 12
Training loss: 1.481040358543396
Validation loss: 2.0257078268194713

Epoch: 6| Step: 13
Training loss: 1.6767126321792603
Validation loss: 2.0646776037831462

Epoch: 267| Step: 0
Training loss: 1.308915615081787
Validation loss: 2.0375843125004924

Epoch: 6| Step: 1
Training loss: 1.5270875692367554
Validation loss: 2.0182513139581166

Epoch: 6| Step: 2
Training loss: 1.716733694076538
Validation loss: 1.997052982289304

Epoch: 6| Step: 3
Training loss: 2.4811220169067383
Validation loss: 2.0316967784717517

Epoch: 6| Step: 4
Training loss: 1.476778268814087
Validation loss: 2.030592417204252

Epoch: 6| Step: 5
Training loss: 1.420189380645752
Validation loss: 2.047006590392

Epoch: 6| Step: 6
Training loss: 1.7825146913528442
Validation loss: 1.9921047149165985

Epoch: 6| Step: 7
Training loss: 2.4548187255859375
Validation loss: 1.997816192206516

Epoch: 6| Step: 8
Training loss: 2.2009363174438477
Validation loss: 2.016191351798273

Epoch: 6| Step: 9
Training loss: 1.1557406187057495
Validation loss: 2.051182769959973

Epoch: 6| Step: 10
Training loss: 1.9325639009475708
Validation loss: 2.062712087426134

Epoch: 6| Step: 11
Training loss: 1.898061752319336
Validation loss: 2.029929273871965

Epoch: 6| Step: 12
Training loss: 2.3977599143981934
Validation loss: 2.0606570628381546

Epoch: 6| Step: 13
Training loss: 1.9663842916488647
Validation loss: 2.0351081778926234

Epoch: 268| Step: 0
Training loss: 1.8780319690704346
Validation loss: 2.0441089445544827

Epoch: 6| Step: 1
Training loss: 2.3544394969940186
Validation loss: 2.019974918775661

Epoch: 6| Step: 2
Training loss: 1.6881341934204102
Validation loss: 2.0225461708602084

Epoch: 6| Step: 3
Training loss: 1.4198307991027832
Validation loss: 2.0113558999953733

Epoch: 6| Step: 4
Training loss: 2.0809497833251953
Validation loss: 2.055504498943206

Epoch: 6| Step: 5
Training loss: 2.200881004333496
Validation loss: 2.01478075468412

Epoch: 6| Step: 6
Training loss: 1.5824100971221924
Validation loss: 2.0248797965306107

Epoch: 6| Step: 7
Training loss: 1.9470045566558838
Validation loss: 2.062517096919398

Epoch: 6| Step: 8
Training loss: 1.7565737962722778
Validation loss: 2.0678804382201164

Epoch: 6| Step: 9
Training loss: 1.733447790145874
Validation loss: 1.9996988568254697

Epoch: 6| Step: 10
Training loss: 1.5615761280059814
Validation loss: 2.0231716145751295

Epoch: 6| Step: 11
Training loss: 1.5629154443740845
Validation loss: 2.037139513159311

Epoch: 6| Step: 12
Training loss: 2.0054304599761963
Validation loss: 2.0216869628557594

Epoch: 6| Step: 13
Training loss: 1.6254620552062988
Validation loss: 2.0279917204251854

Epoch: 269| Step: 0
Training loss: 2.204207420349121
Validation loss: 2.0419717681023384

Epoch: 6| Step: 1
Training loss: 2.4079790115356445
Validation loss: 2.058094337422361

Epoch: 6| Step: 2
Training loss: 1.9470398426055908
Validation loss: 2.0073322531997517

Epoch: 6| Step: 3
Training loss: 1.8172844648361206
Validation loss: 1.9871009549786967

Epoch: 6| Step: 4
Training loss: 1.6915843486785889
Validation loss: 1.998216462391679

Epoch: 6| Step: 5
Training loss: 1.6333868503570557
Validation loss: 2.0132883646154918

Epoch: 6| Step: 6
Training loss: 2.072632074356079
Validation loss: 1.9900070492939284

Epoch: 6| Step: 7
Training loss: 1.3127284049987793
Validation loss: 2.033923124754301

Epoch: 6| Step: 8
Training loss: 1.827888011932373
Validation loss: 1.984215219815572

Epoch: 6| Step: 9
Training loss: 2.2019028663635254
Validation loss: 2.010772946060345

Epoch: 6| Step: 10
Training loss: 1.1118223667144775
Validation loss: 2.0292965865904287

Epoch: 6| Step: 11
Training loss: 2.3270514011383057
Validation loss: 2.0102320358317387

Epoch: 6| Step: 12
Training loss: 1.2911765575408936
Validation loss: 2.014189653499152

Epoch: 6| Step: 13
Training loss: 0.9256571531295776
Validation loss: 2.019585765818114

Epoch: 270| Step: 0
Training loss: 1.788649082183838
Validation loss: 1.9880824729960451

Epoch: 6| Step: 1
Training loss: 1.6851484775543213
Validation loss: 2.057985228876914

Epoch: 6| Step: 2
Training loss: 2.427363872528076
Validation loss: 2.07255159911289

Epoch: 6| Step: 3
Training loss: 1.6098759174346924
Validation loss: 2.035342211364418

Epoch: 6| Step: 4
Training loss: 2.171778440475464
Validation loss: 2.045976438829976

Epoch: 6| Step: 5
Training loss: 1.8942316770553589
Validation loss: 2.0128467288068546

Epoch: 6| Step: 6
Training loss: 1.8869993686676025
Validation loss: 2.0402511422352125

Epoch: 6| Step: 7
Training loss: 2.2098023891448975
Validation loss: 2.034094907904184

Epoch: 6| Step: 8
Training loss: 1.1152033805847168
Validation loss: 2.028926323818904

Epoch: 6| Step: 9
Training loss: 2.2322628498077393
Validation loss: 2.0243353023323962

Epoch: 6| Step: 10
Training loss: 1.2612581253051758
Validation loss: 2.0643657561271422

Epoch: 6| Step: 11
Training loss: 1.799040675163269
Validation loss: 2.025084666026536

Epoch: 6| Step: 12
Training loss: 0.9969950914382935
Validation loss: 2.04908755517775

Epoch: 6| Step: 13
Training loss: 1.633556604385376
Validation loss: 2.0268954153983825

Epoch: 271| Step: 0
Training loss: 2.0784902572631836
Validation loss: 1.9991205507709133

Epoch: 6| Step: 1
Training loss: 1.9658243656158447
Validation loss: 2.0104027999344694

Epoch: 6| Step: 2
Training loss: 1.7438898086547852
Validation loss: 2.058276153379871

Epoch: 6| Step: 3
Training loss: 2.0670950412750244
Validation loss: 2.0069264788781442

Epoch: 6| Step: 4
Training loss: 1.7229375839233398
Validation loss: 2.0549498373462307

Epoch: 6| Step: 5
Training loss: 1.5394115447998047
Validation loss: 2.0442971721772225

Epoch: 6| Step: 6
Training loss: 2.4498205184936523
Validation loss: 1.9982219767826859

Epoch: 6| Step: 7
Training loss: 1.8839921951293945
Validation loss: 2.0343077951861965

Epoch: 6| Step: 8
Training loss: 1.9176678657531738
Validation loss: 2.0603382600251066

Epoch: 6| Step: 9
Training loss: 1.5678868293762207
Validation loss: 2.049875522172579

Epoch: 6| Step: 10
Training loss: 1.2208187580108643
Validation loss: 2.050198619083692

Epoch: 6| Step: 11
Training loss: 1.6185030937194824
Validation loss: 2.0206451659561484

Epoch: 6| Step: 12
Training loss: 1.0858720541000366
Validation loss: 2.026514748091339

Epoch: 6| Step: 13
Training loss: 1.9657026529312134
Validation loss: 1.9985630486601142

Epoch: 272| Step: 0
Training loss: 1.438407301902771
Validation loss: 2.0241182516979914

Epoch: 6| Step: 1
Training loss: 3.0213212966918945
Validation loss: 2.0370406437945623

Epoch: 6| Step: 2
Training loss: 1.0920355319976807
Validation loss: 2.0387460390726724

Epoch: 6| Step: 3
Training loss: 1.7498019933700562
Validation loss: 2.028646147379311

Epoch: 6| Step: 4
Training loss: 2.239281415939331
Validation loss: 2.018037880620649

Epoch: 6| Step: 5
Training loss: 1.1015372276306152
Validation loss: 2.0161542738637617

Epoch: 6| Step: 6
Training loss: 1.4851758480072021
Validation loss: 2.026972614308839

Epoch: 6| Step: 7
Training loss: 2.002765655517578
Validation loss: 2.0076870431182203

Epoch: 6| Step: 8
Training loss: 2.028308629989624
Validation loss: 2.030842634939378

Epoch: 6| Step: 9
Training loss: 1.876421570777893
Validation loss: 2.044059012525825

Epoch: 6| Step: 10
Training loss: 1.8636900186538696
Validation loss: 2.029055744089106

Epoch: 6| Step: 11
Training loss: 1.6928679943084717
Validation loss: 1.9792102690665954

Epoch: 6| Step: 12
Training loss: 1.4052928686141968
Validation loss: 1.977135694155129

Epoch: 6| Step: 13
Training loss: 2.500087261199951
Validation loss: 2.013191625636111

Epoch: 273| Step: 0
Training loss: 1.7691714763641357
Validation loss: 1.9922772146040393

Epoch: 6| Step: 1
Training loss: 0.9995790719985962
Validation loss: 2.0224732481023318

Epoch: 6| Step: 2
Training loss: 1.992900013923645
Validation loss: 2.046221817693403

Epoch: 6| Step: 3
Training loss: 1.744830846786499
Validation loss: 2.0235717373509563

Epoch: 6| Step: 4
Training loss: 1.518399715423584
Validation loss: 2.053975938468851

Epoch: 6| Step: 5
Training loss: 1.6647675037384033
Validation loss: 2.01792771585526

Epoch: 6| Step: 6
Training loss: 2.496108055114746
Validation loss: 2.045530414068571

Epoch: 6| Step: 7
Training loss: 1.168863296508789
Validation loss: 2.0498705089733167

Epoch: 6| Step: 8
Training loss: 1.294983983039856
Validation loss: 2.0067315101623535

Epoch: 6| Step: 9
Training loss: 2.5582003593444824
Validation loss: 2.033795156786519

Epoch: 6| Step: 10
Training loss: 1.98995041847229
Validation loss: 2.0398887280494935

Epoch: 6| Step: 11
Training loss: 1.9291690587997437
Validation loss: 2.070030730257752

Epoch: 6| Step: 12
Training loss: 2.0722568035125732
Validation loss: 2.08242803747936

Epoch: 6| Step: 13
Training loss: 1.7484164237976074
Validation loss: 2.0571329773113294

Epoch: 274| Step: 0
Training loss: 1.0317655801773071
Validation loss: 2.0641985990667857

Epoch: 6| Step: 1
Training loss: 1.6721701622009277
Validation loss: 2.0935427373455417

Epoch: 6| Step: 2
Training loss: 1.7509357929229736
Validation loss: 2.062781928687967

Epoch: 6| Step: 3
Training loss: 1.4860447645187378
Validation loss: 2.0836013081253215

Epoch: 6| Step: 4
Training loss: 2.097507953643799
Validation loss: 2.0651160491410123

Epoch: 6| Step: 5
Training loss: 2.169261932373047
Validation loss: 2.0409361572675806

Epoch: 6| Step: 6
Training loss: 2.1250410079956055
Validation loss: 2.0540173258832706

Epoch: 6| Step: 7
Training loss: 1.91902494430542
Validation loss: 1.9835768463791057

Epoch: 6| Step: 8
Training loss: 2.219634532928467
Validation loss: 2.0249789350776264

Epoch: 6| Step: 9
Training loss: 1.9107215404510498
Validation loss: 2.0482241415208384

Epoch: 6| Step: 10
Training loss: 1.836082100868225
Validation loss: 2.049577743776383

Epoch: 6| Step: 11
Training loss: 1.9867258071899414
Validation loss: 2.0399581360560592

Epoch: 6| Step: 12
Training loss: 1.3927428722381592
Validation loss: 2.03340761123165

Epoch: 6| Step: 13
Training loss: 1.2650575637817383
Validation loss: 2.0592706024005847

Epoch: 275| Step: 0
Training loss: 1.605992317199707
Validation loss: 2.0057012547728834

Epoch: 6| Step: 1
Training loss: 1.7208795547485352
Validation loss: 2.0171578891815676

Epoch: 6| Step: 2
Training loss: 1.8080220222473145
Validation loss: 2.0439418733760877

Epoch: 6| Step: 3
Training loss: 2.6213538646698
Validation loss: 2.01096849800438

Epoch: 6| Step: 4
Training loss: 1.7519731521606445
Validation loss: 2.0354529542307698

Epoch: 6| Step: 5
Training loss: 1.5191491842269897
Validation loss: 2.0018689401688112

Epoch: 6| Step: 6
Training loss: 1.439231276512146
Validation loss: 2.0276289140024493

Epoch: 6| Step: 7
Training loss: 3.099623203277588
Validation loss: 2.0426869982032367

Epoch: 6| Step: 8
Training loss: 0.7409151196479797
Validation loss: 2.0623377318023355

Epoch: 6| Step: 9
Training loss: 1.7315375804901123
Validation loss: 2.043705468536705

Epoch: 6| Step: 10
Training loss: 1.7861824035644531
Validation loss: 2.031160044413741

Epoch: 6| Step: 11
Training loss: 1.7188901901245117
Validation loss: 1.9978845388658586

Epoch: 6| Step: 12
Training loss: 1.6316624879837036
Validation loss: 2.0645622617454937

Epoch: 6| Step: 13
Training loss: 2.0327939987182617
Validation loss: 2.0189260475097166

Epoch: 276| Step: 0
Training loss: 1.5329716205596924
Validation loss: 2.0476204144057406

Epoch: 6| Step: 1
Training loss: 2.4186906814575195
Validation loss: 2.0364204593884048

Epoch: 6| Step: 2
Training loss: 1.5502420663833618
Validation loss: 2.0233420851410076

Epoch: 6| Step: 3
Training loss: 2.4165992736816406
Validation loss: 2.0502209945391585

Epoch: 6| Step: 4
Training loss: 1.0796236991882324
Validation loss: 2.0534300932320217

Epoch: 6| Step: 5
Training loss: 2.220187187194824
Validation loss: 2.045552399850661

Epoch: 6| Step: 6
Training loss: 1.3201267719268799
Validation loss: 2.085003310634244

Epoch: 6| Step: 7
Training loss: 1.7321438789367676
Validation loss: 2.0560466051101685

Epoch: 6| Step: 8
Training loss: 1.540801763534546
Validation loss: 2.0838155592641523

Epoch: 6| Step: 9
Training loss: 2.060821533203125
Validation loss: 2.043216815558813

Epoch: 6| Step: 10
Training loss: 2.167133331298828
Validation loss: 2.0423880007959183

Epoch: 6| Step: 11
Training loss: 1.7086671590805054
Validation loss: 2.0479593546159807

Epoch: 6| Step: 12
Training loss: 1.272791862487793
Validation loss: 1.97836087852396

Epoch: 6| Step: 13
Training loss: 1.715412974357605
Validation loss: 2.017273824702027

Epoch: 277| Step: 0
Training loss: 2.0944392681121826
Validation loss: 2.0341196419090353

Epoch: 6| Step: 1
Training loss: 2.1085758209228516
Validation loss: 2.0178700672682894

Epoch: 6| Step: 2
Training loss: 1.4808847904205322
Validation loss: 2.022958473492694

Epoch: 6| Step: 3
Training loss: 1.77169668674469
Validation loss: 2.0625387699373308

Epoch: 6| Step: 4
Training loss: 1.4618628025054932
Validation loss: 2.0648301288645756

Epoch: 6| Step: 5
Training loss: 1.2614496946334839
Validation loss: 2.041673106531943

Epoch: 6| Step: 6
Training loss: 2.1625304222106934
Validation loss: 2.0141745395557855

Epoch: 6| Step: 7
Training loss: 2.0853307247161865
Validation loss: 2.031879054602756

Epoch: 6| Step: 8
Training loss: 1.3671417236328125
Validation loss: 2.087069096103791

Epoch: 6| Step: 9
Training loss: 2.475285530090332
Validation loss: 2.0532491258395615

Epoch: 6| Step: 10
Training loss: 1.588806390762329
Validation loss: 2.0532064399411603

Epoch: 6| Step: 11
Training loss: 1.484872817993164
Validation loss: 2.038469442757227

Epoch: 6| Step: 12
Training loss: 1.3279950618743896
Validation loss: 2.040406286075551

Epoch: 6| Step: 13
Training loss: 2.2781448364257812
Validation loss: 2.0236700529693277

Epoch: 278| Step: 0
Training loss: 1.5664024353027344
Validation loss: 2.0727110652513403

Epoch: 6| Step: 1
Training loss: 1.4628803730010986
Validation loss: 1.9984857049039615

Epoch: 6| Step: 2
Training loss: 1.9205455780029297
Validation loss: 2.0199456368723223

Epoch: 6| Step: 3
Training loss: 1.408214807510376
Validation loss: 1.9915683372046358

Epoch: 6| Step: 4
Training loss: 1.8847548961639404
Validation loss: 2.042806230565553

Epoch: 6| Step: 5
Training loss: 1.7318681478500366
Validation loss: 2.0249400856674358

Epoch: 6| Step: 6
Training loss: 2.300873279571533
Validation loss: 2.02051124265117

Epoch: 6| Step: 7
Training loss: 1.5773398876190186
Validation loss: 2.0235334237416587

Epoch: 6| Step: 8
Training loss: 1.5126081705093384
Validation loss: 2.032218087104059

Epoch: 6| Step: 9
Training loss: 1.6225388050079346
Validation loss: 2.0333429228874946

Epoch: 6| Step: 10
Training loss: 2.0095300674438477
Validation loss: 2.037233850007416

Epoch: 6| Step: 11
Training loss: 1.5478289127349854
Validation loss: 2.0336527337310133

Epoch: 6| Step: 12
Training loss: 2.4327504634857178
Validation loss: 2.017224513074403

Epoch: 6| Step: 13
Training loss: 2.104677438735962
Validation loss: 2.023767340567804

Epoch: 279| Step: 0
Training loss: 1.8596827983856201
Validation loss: 2.054100118657594

Epoch: 6| Step: 1
Training loss: 2.115232229232788
Validation loss: 2.0429852547184115

Epoch: 6| Step: 2
Training loss: 2.642767906188965
Validation loss: 2.0064698226990236

Epoch: 6| Step: 3
Training loss: 1.7451074123382568
Validation loss: 2.0373146854421145

Epoch: 6| Step: 4
Training loss: 1.4054038524627686
Validation loss: 2.043746053531606

Epoch: 6| Step: 5
Training loss: 1.8522804975509644
Validation loss: 2.0338919201204853

Epoch: 6| Step: 6
Training loss: 1.8598518371582031
Validation loss: 2.0316636613620225

Epoch: 6| Step: 7
Training loss: 1.6659979820251465
Validation loss: 2.039092263867778

Epoch: 6| Step: 8
Training loss: 1.3390145301818848
Validation loss: 2.0813525953600482

Epoch: 6| Step: 9
Training loss: 1.5586369037628174
Validation loss: 2.0009746397695234

Epoch: 6| Step: 10
Training loss: 1.2581713199615479
Validation loss: 2.039269006380471

Epoch: 6| Step: 11
Training loss: 2.293107509613037
Validation loss: 2.0450562020783782

Epoch: 6| Step: 12
Training loss: 1.390730857849121
Validation loss: 2.035736365984845

Epoch: 6| Step: 13
Training loss: 2.0128698348999023
Validation loss: 2.055263908960486

Epoch: 280| Step: 0
Training loss: 2.00252366065979
Validation loss: 2.0620337583685435

Epoch: 6| Step: 1
Training loss: 1.3702205419540405
Validation loss: 2.0418479852778937

Epoch: 6| Step: 2
Training loss: 1.0170438289642334
Validation loss: 2.0751106034043016

Epoch: 6| Step: 3
Training loss: 1.5458935499191284
Validation loss: 2.0327719834543045

Epoch: 6| Step: 4
Training loss: 1.5414307117462158
Validation loss: 2.0701589943260275

Epoch: 6| Step: 5
Training loss: 2.073793888092041
Validation loss: 2.0193320987045125

Epoch: 6| Step: 6
Training loss: 2.5973057746887207
Validation loss: 2.0815122435169835

Epoch: 6| Step: 7
Training loss: 1.5841360092163086
Validation loss: 2.0319703907094975

Epoch: 6| Step: 8
Training loss: 1.4733169078826904
Validation loss: 2.0367721562744467

Epoch: 6| Step: 9
Training loss: 2.4651284217834473
Validation loss: 2.0218870229618524

Epoch: 6| Step: 10
Training loss: 2.4365785121917725
Validation loss: 2.066395616018644

Epoch: 6| Step: 11
Training loss: 1.0769696235656738
Validation loss: 2.0722167184275966

Epoch: 6| Step: 12
Training loss: 1.5268937349319458
Validation loss: 2.037792008410218

Epoch: 6| Step: 13
Training loss: 2.2689590454101562
Validation loss: 2.017641891715347

Epoch: 281| Step: 0
Training loss: 2.057948112487793
Validation loss: 2.0209549537269016

Epoch: 6| Step: 1
Training loss: 1.975006341934204
Validation loss: 2.0020335592249388

Epoch: 6| Step: 2
Training loss: 1.5987138748168945
Validation loss: 2.019686498949605

Epoch: 6| Step: 3
Training loss: 1.4758052825927734
Validation loss: 1.9912761731814312

Epoch: 6| Step: 4
Training loss: 2.0770792961120605
Validation loss: 1.9848665780918573

Epoch: 6| Step: 5
Training loss: 2.3509209156036377
Validation loss: 1.9989780354243454

Epoch: 6| Step: 6
Training loss: 1.4930393695831299
Validation loss: 2.0536219855790496

Epoch: 6| Step: 7
Training loss: 1.3112677335739136
Validation loss: 2.019523996178822

Epoch: 6| Step: 8
Training loss: 1.8768882751464844
Validation loss: 2.0624491655698387

Epoch: 6| Step: 9
Training loss: 1.1514694690704346
Validation loss: 2.0291952420306463

Epoch: 6| Step: 10
Training loss: 1.1037566661834717
Validation loss: 2.0558471141322965

Epoch: 6| Step: 11
Training loss: 1.7486640214920044
Validation loss: 2.037092093498476

Epoch: 6| Step: 12
Training loss: 2.624023914337158
Validation loss: 2.0582279236085954

Epoch: 6| Step: 13
Training loss: 2.620940685272217
Validation loss: 2.026972357944776

Epoch: 282| Step: 0
Training loss: 2.290092945098877
Validation loss: 2.0330213654425835

Epoch: 6| Step: 1
Training loss: 1.845221996307373
Validation loss: 2.015866202692832

Epoch: 6| Step: 2
Training loss: 1.6933307647705078
Validation loss: 2.072199172871087

Epoch: 6| Step: 3
Training loss: 2.2530031204223633
Validation loss: 2.0968608228109216

Epoch: 6| Step: 4
Training loss: 2.13084077835083
Validation loss: 2.072831512779318

Epoch: 6| Step: 5
Training loss: 1.929131269454956
Validation loss: 2.1071400257848922

Epoch: 6| Step: 6
Training loss: 1.9361518621444702
Validation loss: 2.065512252110307

Epoch: 6| Step: 7
Training loss: 1.466921329498291
Validation loss: 2.1259753422070573

Epoch: 6| Step: 8
Training loss: 1.6760478019714355
Validation loss: 2.1033949826353338

Epoch: 6| Step: 9
Training loss: 0.9086517691612244
Validation loss: 2.089263471223975

Epoch: 6| Step: 10
Training loss: 1.643578052520752
Validation loss: 2.092063009098012

Epoch: 6| Step: 11
Training loss: 0.8513372540473938
Validation loss: 2.089891331170195

Epoch: 6| Step: 12
Training loss: 2.646477222442627
Validation loss: 2.035624175943354

Epoch: 6| Step: 13
Training loss: 1.8506253957748413
Validation loss: 2.0923277331936743

Epoch: 283| Step: 0
Training loss: 1.4341444969177246
Validation loss: 2.06207283337911

Epoch: 6| Step: 1
Training loss: 1.7745399475097656
Validation loss: 2.046116413608674

Epoch: 6| Step: 2
Training loss: 2.381129741668701
Validation loss: 2.048346366933597

Epoch: 6| Step: 3
Training loss: 2.0463685989379883
Validation loss: 2.0246252834155993

Epoch: 6| Step: 4
Training loss: 1.8499641418457031
Validation loss: 1.9982930703829693

Epoch: 6| Step: 5
Training loss: 1.6602200269699097
Validation loss: 2.0259728572701894

Epoch: 6| Step: 6
Training loss: 1.7785279750823975
Validation loss: 2.0630281868801323

Epoch: 6| Step: 7
Training loss: 1.4953954219818115
Validation loss: 2.0057015162642284

Epoch: 6| Step: 8
Training loss: 1.6988816261291504
Validation loss: 2.0145239342925367

Epoch: 6| Step: 9
Training loss: 1.6913237571716309
Validation loss: 2.0072094035404984

Epoch: 6| Step: 10
Training loss: 1.2668427228927612
Validation loss: 1.9947231931071128

Epoch: 6| Step: 11
Training loss: 1.7013835906982422
Validation loss: 2.059443087988002

Epoch: 6| Step: 12
Training loss: 2.2526140213012695
Validation loss: 2.0507366170165358

Epoch: 6| Step: 13
Training loss: 1.8794869184494019
Validation loss: 2.054296028229498

Epoch: 284| Step: 0
Training loss: 1.4080651998519897
Validation loss: 2.0714141848266765

Epoch: 6| Step: 1
Training loss: 2.04866886138916
Validation loss: 2.055520954952445

Epoch: 6| Step: 2
Training loss: 1.649709939956665
Validation loss: 2.062556714139959

Epoch: 6| Step: 3
Training loss: 1.891966462135315
Validation loss: 2.072341460053639

Epoch: 6| Step: 4
Training loss: 1.6642472743988037
Validation loss: 2.071141163508097

Epoch: 6| Step: 5
Training loss: 1.7366526126861572
Validation loss: 2.08085649500611

Epoch: 6| Step: 6
Training loss: 2.015169858932495
Validation loss: 2.0602438629314466

Epoch: 6| Step: 7
Training loss: 1.5197606086730957
Validation loss: 2.0318198511677403

Epoch: 6| Step: 8
Training loss: 2.2513647079467773
Validation loss: 2.050749131428298

Epoch: 6| Step: 9
Training loss: 1.2099943161010742
Validation loss: 2.047685202731881

Epoch: 6| Step: 10
Training loss: 1.8550710678100586
Validation loss: 2.093199324864213

Epoch: 6| Step: 11
Training loss: 1.90232253074646
Validation loss: 2.062633878441267

Epoch: 6| Step: 12
Training loss: 2.0978946685791016
Validation loss: 2.0394103373250654

Epoch: 6| Step: 13
Training loss: 1.65341317653656
Validation loss: 2.030239353897751

Epoch: 285| Step: 0
Training loss: 1.1101627349853516
Validation loss: 2.035986582438151

Epoch: 6| Step: 1
Training loss: 2.0761630535125732
Validation loss: 2.062976316739154

Epoch: 6| Step: 2
Training loss: 1.487802505493164
Validation loss: 2.096079966073395

Epoch: 6| Step: 3
Training loss: 1.3861351013183594
Validation loss: 2.0527722502267487

Epoch: 6| Step: 4
Training loss: 1.395635962486267
Validation loss: 2.014423434452344

Epoch: 6| Step: 5
Training loss: 2.049567222595215
Validation loss: 2.0384968839665896

Epoch: 6| Step: 6
Training loss: 1.5180994272232056
Validation loss: 2.0593288226794173

Epoch: 6| Step: 7
Training loss: 2.0805954933166504
Validation loss: 2.0160278812531502

Epoch: 6| Step: 8
Training loss: 2.413384199142456
Validation loss: 2.063760220363576

Epoch: 6| Step: 9
Training loss: 2.0696206092834473
Validation loss: 2.030458511844758

Epoch: 6| Step: 10
Training loss: 1.5009045600891113
Validation loss: 2.001690472325971

Epoch: 6| Step: 11
Training loss: 1.7747083902359009
Validation loss: 2.006883663515891

Epoch: 6| Step: 12
Training loss: 2.09722900390625
Validation loss: 2.043493224728492

Epoch: 6| Step: 13
Training loss: 1.81746506690979
Validation loss: 2.058086763146103

Epoch: 286| Step: 0
Training loss: 1.9855018854141235
Validation loss: 2.071862074636644

Epoch: 6| Step: 1
Training loss: 1.5846319198608398
Validation loss: 2.014253854751587

Epoch: 6| Step: 2
Training loss: 2.0237784385681152
Validation loss: 2.003568628782867

Epoch: 6| Step: 3
Training loss: 1.7134063243865967
Validation loss: 2.0428314183347966

Epoch: 6| Step: 4
Training loss: 1.0588843822479248
Validation loss: 2.037940440639373

Epoch: 6| Step: 5
Training loss: 1.8984191417694092
Validation loss: 2.0517078650894987

Epoch: 6| Step: 6
Training loss: 2.0350606441497803
Validation loss: 2.0515972593779206

Epoch: 6| Step: 7
Training loss: 1.9366945028305054
Validation loss: 2.0446479320526123

Epoch: 6| Step: 8
Training loss: 1.689312219619751
Validation loss: 2.0508918300751717

Epoch: 6| Step: 9
Training loss: 1.323063850402832
Validation loss: 2.0436051840423257

Epoch: 6| Step: 10
Training loss: 1.8937407732009888
Validation loss: 2.04231442687332

Epoch: 6| Step: 11
Training loss: 2.2018165588378906
Validation loss: 2.0493750674750215

Epoch: 6| Step: 12
Training loss: 1.4848216772079468
Validation loss: 2.0678214065490232

Epoch: 6| Step: 13
Training loss: 2.369704008102417
Validation loss: 2.076967357307352

Epoch: 287| Step: 0
Training loss: 1.5911508798599243
Validation loss: 2.09799301239752

Epoch: 6| Step: 1
Training loss: 2.160585880279541
Validation loss: 2.07155680143705

Epoch: 6| Step: 2
Training loss: 2.098404884338379
Validation loss: 2.0952910043859996

Epoch: 6| Step: 3
Training loss: 2.103288173675537
Validation loss: 2.057166758403983

Epoch: 6| Step: 4
Training loss: 1.4189987182617188
Validation loss: 2.0288532498062297

Epoch: 6| Step: 5
Training loss: 1.100480556488037
Validation loss: 2.046606634252815

Epoch: 6| Step: 6
Training loss: 0.9850648641586304
Validation loss: 2.0183492065757833

Epoch: 6| Step: 7
Training loss: 2.3030216693878174
Validation loss: 2.0145934268992436

Epoch: 6| Step: 8
Training loss: 1.5844533443450928
Validation loss: 2.019244413222036

Epoch: 6| Step: 9
Training loss: 1.9739947319030762
Validation loss: 2.0399814459585373

Epoch: 6| Step: 10
Training loss: 2.223038673400879
Validation loss: 2.0442921653870614

Epoch: 6| Step: 11
Training loss: 1.4120112657546997
Validation loss: 2.0227952234206663

Epoch: 6| Step: 12
Training loss: 2.0909337997436523
Validation loss: 2.0470028846494612

Epoch: 6| Step: 13
Training loss: 1.7810224294662476
Validation loss: 2.021496688165972

Epoch: 288| Step: 0
Training loss: 1.4369113445281982
Validation loss: 2.0302823128238803

Epoch: 6| Step: 1
Training loss: 1.7167139053344727
Validation loss: 2.057881865450131

Epoch: 6| Step: 2
Training loss: 0.9738519191741943
Validation loss: 2.0390755335489907

Epoch: 6| Step: 3
Training loss: 1.2940547466278076
Validation loss: 2.059778926193073

Epoch: 6| Step: 4
Training loss: 1.4794508218765259
Validation loss: 2.0827324569866223

Epoch: 6| Step: 5
Training loss: 2.4393715858459473
Validation loss: 2.0697694978406354

Epoch: 6| Step: 6
Training loss: 1.7859532833099365
Validation loss: 2.054897581377337

Epoch: 6| Step: 7
Training loss: 1.5682615041732788
Validation loss: 2.058771102659164

Epoch: 6| Step: 8
Training loss: 1.4199527502059937
Validation loss: 2.087962294137606

Epoch: 6| Step: 9
Training loss: 2.6409060955047607
Validation loss: 2.04047449814376

Epoch: 6| Step: 10
Training loss: 2.608154773712158
Validation loss: 2.0706351162284933

Epoch: 6| Step: 11
Training loss: 1.283538579940796
Validation loss: 2.0290811164404756

Epoch: 6| Step: 12
Training loss: 2.009334087371826
Validation loss: 2.0497818044436875

Epoch: 6| Step: 13
Training loss: 2.5895509719848633
Validation loss: 2.03159575821251

Epoch: 289| Step: 0
Training loss: 1.2435297966003418
Validation loss: 2.0727545702329246

Epoch: 6| Step: 1
Training loss: 2.1490652561187744
Validation loss: 2.0518451198454826

Epoch: 6| Step: 2
Training loss: 1.4945218563079834
Validation loss: 2.0217175496521818

Epoch: 6| Step: 3
Training loss: 0.8757648468017578
Validation loss: 2.0659122390131794

Epoch: 6| Step: 4
Training loss: 1.717376708984375
Validation loss: 2.0935702580277638

Epoch: 6| Step: 5
Training loss: 1.44105863571167
Validation loss: 2.0598261420444777

Epoch: 6| Step: 6
Training loss: 1.8615843057632446
Validation loss: 2.047994828993274

Epoch: 6| Step: 7
Training loss: 1.6627051830291748
Validation loss: 2.055976231892904

Epoch: 6| Step: 8
Training loss: 1.1245861053466797
Validation loss: 2.0723264473740772

Epoch: 6| Step: 9
Training loss: 2.7099058628082275
Validation loss: 2.0470692085963424

Epoch: 6| Step: 10
Training loss: 2.3801932334899902
Validation loss: 2.033769654971297

Epoch: 6| Step: 11
Training loss: 2.2514145374298096
Validation loss: 2.0178081848288096

Epoch: 6| Step: 12
Training loss: 1.5933715105056763
Validation loss: 2.0336225776262182

Epoch: 6| Step: 13
Training loss: 2.0824060440063477
Validation loss: 2.0497481156420965

Epoch: 290| Step: 0
Training loss: 1.5956332683563232
Validation loss: 1.9872735392662786

Epoch: 6| Step: 1
Training loss: 1.6430325508117676
Validation loss: 2.0328345555131153

Epoch: 6| Step: 2
Training loss: 1.6676826477050781
Validation loss: 2.0618921441416584

Epoch: 6| Step: 3
Training loss: 2.185102939605713
Validation loss: 2.0263532553949664

Epoch: 6| Step: 4
Training loss: 1.321364164352417
Validation loss: 2.019304924113776

Epoch: 6| Step: 5
Training loss: 2.2820119857788086
Validation loss: 2.052757604147798

Epoch: 6| Step: 6
Training loss: 1.8323525190353394
Validation loss: 2.037449682912519

Epoch: 6| Step: 7
Training loss: 1.5221129655838013
Validation loss: 2.019903661102377

Epoch: 6| Step: 8
Training loss: 1.8360867500305176
Validation loss: 2.086929213616156

Epoch: 6| Step: 9
Training loss: 1.7127172946929932
Validation loss: 2.051770432021028

Epoch: 6| Step: 10
Training loss: 2.151827335357666
Validation loss: 2.072195827320058

Epoch: 6| Step: 11
Training loss: 1.7342901229858398
Validation loss: 2.0515808648960565

Epoch: 6| Step: 12
Training loss: 1.606644868850708
Validation loss: 2.045042699383151

Epoch: 6| Step: 13
Training loss: 1.0027016401290894
Validation loss: 2.092269028386762

Epoch: 291| Step: 0
Training loss: 2.204787254333496
Validation loss: 2.0455451857659126

Epoch: 6| Step: 1
Training loss: 1.8900632858276367
Validation loss: 2.042333209386436

Epoch: 6| Step: 2
Training loss: 2.607973098754883
Validation loss: 2.0376267074256815

Epoch: 6| Step: 3
Training loss: 2.165980100631714
Validation loss: 2.0393319129943848

Epoch: 6| Step: 4
Training loss: 2.154407024383545
Validation loss: 2.087843983404098

Epoch: 6| Step: 5
Training loss: 1.6481925249099731
Validation loss: 2.051184482471917

Epoch: 6| Step: 6
Training loss: 1.4619100093841553
Validation loss: 2.0795702036990913

Epoch: 6| Step: 7
Training loss: 1.273247480392456
Validation loss: 2.005992474094514

Epoch: 6| Step: 8
Training loss: 1.5346934795379639
Validation loss: 2.0705976601569884

Epoch: 6| Step: 9
Training loss: 1.7305293083190918
Validation loss: 2.0343160321635585

Epoch: 6| Step: 10
Training loss: 1.5284044742584229
Validation loss: 2.0310584088807464

Epoch: 6| Step: 11
Training loss: 1.305320382118225
Validation loss: 2.0304143813348587

Epoch: 6| Step: 12
Training loss: 1.514087438583374
Validation loss: 2.041890278939278

Epoch: 6| Step: 13
Training loss: 1.3420995473861694
Validation loss: 2.0358401370304886

Epoch: 292| Step: 0
Training loss: 1.8473238945007324
Validation loss: 2.0343975713176112

Epoch: 6| Step: 1
Training loss: 2.1413979530334473
Validation loss: 2.0810346808484805

Epoch: 6| Step: 2
Training loss: 2.536853075027466
Validation loss: 2.0899779258235807

Epoch: 6| Step: 3
Training loss: 1.5116796493530273
Validation loss: 2.0692315742533696

Epoch: 6| Step: 4
Training loss: 1.2360401153564453
Validation loss: 2.0674828431939565

Epoch: 6| Step: 5
Training loss: 1.3908095359802246
Validation loss: 2.0675870615948915

Epoch: 6| Step: 6
Training loss: 1.8837863206863403
Validation loss: 2.1179361087019726

Epoch: 6| Step: 7
Training loss: 1.6434638500213623
Validation loss: 2.0624886956266177

Epoch: 6| Step: 8
Training loss: 1.6688134670257568
Validation loss: 2.0650360430440595

Epoch: 6| Step: 9
Training loss: 1.7903738021850586
Validation loss: 2.062040517407079

Epoch: 6| Step: 10
Training loss: 1.3131455183029175
Validation loss: 2.0628384749094644

Epoch: 6| Step: 11
Training loss: 1.871253490447998
Validation loss: 2.0740911063327583

Epoch: 6| Step: 12
Training loss: 1.5493475198745728
Validation loss: 2.0213109011291177

Epoch: 6| Step: 13
Training loss: 1.934389591217041
Validation loss: 2.091770884811237

Epoch: 293| Step: 0
Training loss: 1.8765997886657715
Validation loss: 2.037807451781406

Epoch: 6| Step: 1
Training loss: 1.7504255771636963
Validation loss: 2.050713392996019

Epoch: 6| Step: 2
Training loss: 1.4362636804580688
Validation loss: 2.0401450344311294

Epoch: 6| Step: 3
Training loss: 2.233471393585205
Validation loss: 2.016932534915145

Epoch: 6| Step: 4
Training loss: 1.4610092639923096
Validation loss: 2.030106166357635

Epoch: 6| Step: 5
Training loss: 1.4350497722625732
Validation loss: 2.050554636986025

Epoch: 6| Step: 6
Training loss: 1.9447722434997559
Validation loss: 2.0347637514914236

Epoch: 6| Step: 7
Training loss: 1.9075472354888916
Validation loss: 2.0244061972505305

Epoch: 6| Step: 8
Training loss: 1.5203275680541992
Validation loss: 2.0602262814839682

Epoch: 6| Step: 9
Training loss: 1.5472792387008667
Validation loss: 2.0382766979996876

Epoch: 6| Step: 10
Training loss: 1.1968224048614502
Validation loss: 2.05727215479779

Epoch: 6| Step: 11
Training loss: 1.9030182361602783
Validation loss: 2.0745577735285603

Epoch: 6| Step: 12
Training loss: 2.0229904651641846
Validation loss: 2.0584262148026498

Epoch: 6| Step: 13
Training loss: 2.5666401386260986
Validation loss: 2.0428025607139833

Epoch: 294| Step: 0
Training loss: 2.582550048828125
Validation loss: 2.081315748153194

Epoch: 6| Step: 1
Training loss: 1.5954222679138184
Validation loss: 2.0310136272061254

Epoch: 6| Step: 2
Training loss: 1.6989383697509766
Validation loss: 2.0226780932436705

Epoch: 6| Step: 3
Training loss: 1.6521100997924805
Validation loss: 2.0599391537327922

Epoch: 6| Step: 4
Training loss: 2.0583128929138184
Validation loss: 2.068540128328467

Epoch: 6| Step: 5
Training loss: 1.777036428451538
Validation loss: 2.071950904784664

Epoch: 6| Step: 6
Training loss: 1.3707079887390137
Validation loss: 2.054221098141004

Epoch: 6| Step: 7
Training loss: 1.1931711435317993
Validation loss: 2.036613472046391

Epoch: 6| Step: 8
Training loss: 1.9719635248184204
Validation loss: 2.048203496522801

Epoch: 6| Step: 9
Training loss: 1.5542291402816772
Validation loss: 2.0817184166241716

Epoch: 6| Step: 10
Training loss: 2.0234384536743164
Validation loss: 2.0264878708829164

Epoch: 6| Step: 11
Training loss: 1.4764338731765747
Validation loss: 2.0615069648270965

Epoch: 6| Step: 12
Training loss: 1.7181532382965088
Validation loss: 2.094918081837316

Epoch: 6| Step: 13
Training loss: 1.5350263118743896
Validation loss: 2.035828841629849

Epoch: 295| Step: 0
Training loss: 1.6152255535125732
Validation loss: 2.0686192666330645

Epoch: 6| Step: 1
Training loss: 2.3052220344543457
Validation loss: 2.05644573960253

Epoch: 6| Step: 2
Training loss: 1.241092324256897
Validation loss: 2.0550670495597263

Epoch: 6| Step: 3
Training loss: 1.518900990486145
Validation loss: 2.0547114931127077

Epoch: 6| Step: 4
Training loss: 1.7509791851043701
Validation loss: 2.0322503492396367

Epoch: 6| Step: 5
Training loss: 1.8300178050994873
Validation loss: 2.0290583974571637

Epoch: 6| Step: 6
Training loss: 1.5363149642944336
Validation loss: 2.0859831404942337

Epoch: 6| Step: 7
Training loss: 1.8202728033065796
Validation loss: 2.0251242755561747

Epoch: 6| Step: 8
Training loss: 2.2074291706085205
Validation loss: 2.0125944217046103

Epoch: 6| Step: 9
Training loss: 1.834649920463562
Validation loss: 2.0859050199549687

Epoch: 6| Step: 10
Training loss: 1.1284582614898682
Validation loss: 1.9952765267382386

Epoch: 6| Step: 11
Training loss: 2.429352283477783
Validation loss: 2.060952815958249

Epoch: 6| Step: 12
Training loss: 1.633647084236145
Validation loss: 2.060010879270492

Epoch: 6| Step: 13
Training loss: 1.2912671566009521
Validation loss: 2.0724581800481325

Epoch: 296| Step: 0
Training loss: 1.2379965782165527
Validation loss: 2.049464225769043

Epoch: 6| Step: 1
Training loss: 1.785210371017456
Validation loss: 2.0623548607672415

Epoch: 6| Step: 2
Training loss: 2.5478110313415527
Validation loss: 2.045575411089005

Epoch: 6| Step: 3
Training loss: 1.4645861387252808
Validation loss: 2.0148067525638047

Epoch: 6| Step: 4
Training loss: 1.4262973070144653
Validation loss: 2.0180333814313336

Epoch: 6| Step: 5
Training loss: 2.0696206092834473
Validation loss: 2.0295518277793803

Epoch: 6| Step: 6
Training loss: 1.747791051864624
Validation loss: 2.0392210432278213

Epoch: 6| Step: 7
Training loss: 1.3115347623825073
Validation loss: 2.0786190596959924

Epoch: 6| Step: 8
Training loss: 1.3686846494674683
Validation loss: 2.070339023426015

Epoch: 6| Step: 9
Training loss: 1.2181988954544067
Validation loss: 2.016698927007696

Epoch: 6| Step: 10
Training loss: 2.7191967964172363
Validation loss: 2.074888247315602

Epoch: 6| Step: 11
Training loss: 1.659570336341858
Validation loss: 2.0656562453957013

Epoch: 6| Step: 12
Training loss: 1.7229580879211426
Validation loss: 2.068349681874757

Epoch: 6| Step: 13
Training loss: 1.9614925384521484
Validation loss: 2.0551614504988476

Epoch: 297| Step: 0
Training loss: 1.263115644454956
Validation loss: 2.0750072720230266

Epoch: 6| Step: 1
Training loss: 1.7021559476852417
Validation loss: 2.0734507550475416

Epoch: 6| Step: 2
Training loss: 1.9608014822006226
Validation loss: 2.0356113218492076

Epoch: 6| Step: 3
Training loss: 1.9508072137832642
Validation loss: 2.061618597276749

Epoch: 6| Step: 4
Training loss: 1.8550899028778076
Validation loss: 2.054778971979695

Epoch: 6| Step: 5
Training loss: 1.399977684020996
Validation loss: 2.046719338304253

Epoch: 6| Step: 6
Training loss: 1.954771637916565
Validation loss: 2.0801962844787107

Epoch: 6| Step: 7
Training loss: 1.986222505569458
Validation loss: 2.037865864333286

Epoch: 6| Step: 8
Training loss: 1.942245602607727
Validation loss: 2.0594587915687153

Epoch: 6| Step: 9
Training loss: 1.7751256227493286
Validation loss: 2.047096949751659

Epoch: 6| Step: 10
Training loss: 1.7991344928741455
Validation loss: 2.0253479826834893

Epoch: 6| Step: 11
Training loss: 2.1885933876037598
Validation loss: 2.0657259853937293

Epoch: 6| Step: 12
Training loss: 1.1124119758605957
Validation loss: 2.057375113169352

Epoch: 6| Step: 13
Training loss: 1.0251469612121582
Validation loss: 1.9916553138404764

Epoch: 298| Step: 0
Training loss: 1.250638484954834
Validation loss: 2.041903099706096

Epoch: 6| Step: 1
Training loss: 1.9705568552017212
Validation loss: 2.0512650269334034

Epoch: 6| Step: 2
Training loss: 2.675595998764038
Validation loss: 2.040137267881824

Epoch: 6| Step: 3
Training loss: 1.6457096338272095
Validation loss: 2.0551793549650457

Epoch: 6| Step: 4
Training loss: 2.002525806427002
Validation loss: 2.0675254021921465

Epoch: 6| Step: 5
Training loss: 1.646877646446228
Validation loss: 2.05112523417319

Epoch: 6| Step: 6
Training loss: 1.3718295097351074
Validation loss: 2.0487854583289034

Epoch: 6| Step: 7
Training loss: 1.7210428714752197
Validation loss: 2.05402377856675

Epoch: 6| Step: 8
Training loss: 1.6315875053405762
Validation loss: 2.0626917641649962

Epoch: 6| Step: 9
Training loss: 1.117751955986023
Validation loss: 2.0763988930691957

Epoch: 6| Step: 10
Training loss: 1.917146921157837
Validation loss: 2.0396614036252423

Epoch: 6| Step: 11
Training loss: 1.8581676483154297
Validation loss: 2.0428913677892377

Epoch: 6| Step: 12
Training loss: 1.8846697807312012
Validation loss: 2.046861853650821

Epoch: 6| Step: 13
Training loss: 1.4279614686965942
Validation loss: 2.0911554444220757

Epoch: 299| Step: 0
Training loss: 2.1537094116210938
Validation loss: 2.049844798221383

Epoch: 6| Step: 1
Training loss: 2.2262957096099854
Validation loss: 2.02775873291877

Epoch: 6| Step: 2
Training loss: 1.8427793979644775
Validation loss: 2.061626736835767

Epoch: 6| Step: 3
Training loss: 1.6329556703567505
Validation loss: 2.0517195283725695

Epoch: 6| Step: 4
Training loss: 1.771059274673462
Validation loss: 2.017284316401328

Epoch: 6| Step: 5
Training loss: 1.5454628467559814
Validation loss: 2.0548193557288057

Epoch: 6| Step: 6
Training loss: 1.6876044273376465
Validation loss: 2.0658058466449862

Epoch: 6| Step: 7
Training loss: 1.7903826236724854
Validation loss: 2.065461484334802

Epoch: 6| Step: 8
Training loss: 1.447544813156128
Validation loss: 2.017770451884116

Epoch: 6| Step: 9
Training loss: 2.2830889225006104
Validation loss: 2.036854654230097

Epoch: 6| Step: 10
Training loss: 1.5292973518371582
Validation loss: 2.043502924262836

Epoch: 6| Step: 11
Training loss: 1.450182557106018
Validation loss: 2.0367631553321757

Epoch: 6| Step: 12
Training loss: 1.423250675201416
Validation loss: 2.0663044375758015

Epoch: 6| Step: 13
Training loss: 1.3169951438903809
Validation loss: 2.0564969778060913

Epoch: 300| Step: 0
Training loss: 2.2986836433410645
Validation loss: 2.0590795214458177

Epoch: 6| Step: 1
Training loss: 1.6966187953948975
Validation loss: 2.047872466425742

Epoch: 6| Step: 2
Training loss: 1.9296677112579346
Validation loss: 2.1027885175520376

Epoch: 6| Step: 3
Training loss: 1.5224554538726807
Validation loss: 2.0760060253963677

Epoch: 6| Step: 4
Training loss: 1.08260178565979
Validation loss: 2.0996714458670667

Epoch: 6| Step: 5
Training loss: 1.0984811782836914
Validation loss: 2.1133598358400407

Epoch: 6| Step: 6
Training loss: 1.2631076574325562
Validation loss: 2.0869484101572344

Epoch: 6| Step: 7
Training loss: 2.0366036891937256
Validation loss: 2.0460072794268207

Epoch: 6| Step: 8
Training loss: 1.3789026737213135
Validation loss: 2.064293796016324

Epoch: 6| Step: 9
Training loss: 2.130718231201172
Validation loss: 2.054449689003729

Epoch: 6| Step: 10
Training loss: 1.5376251935958862
Validation loss: 2.0984762612209527

Epoch: 6| Step: 11
Training loss: 1.926170825958252
Validation loss: 2.082042331336647

Epoch: 6| Step: 12
Training loss: 2.3572278022766113
Validation loss: 2.0831034414229856

Epoch: 6| Step: 13
Training loss: 2.0398828983306885
Validation loss: 2.091138650012273

Epoch: 301| Step: 0
Training loss: 1.3793706893920898
Validation loss: 2.096052856855495

Epoch: 6| Step: 1
Training loss: 1.9147204160690308
Validation loss: 2.0619580412423737

Epoch: 6| Step: 2
Training loss: 1.9592607021331787
Validation loss: 2.0906481460858415

Epoch: 6| Step: 3
Training loss: 1.3863283395767212
Validation loss: 2.053719053986252

Epoch: 6| Step: 4
Training loss: 1.588173270225525
Validation loss: 2.065740910909509

Epoch: 6| Step: 5
Training loss: 1.4372553825378418
Validation loss: 2.041320505962577

Epoch: 6| Step: 6
Training loss: 1.0170750617980957
Validation loss: 2.05605649435392

Epoch: 6| Step: 7
Training loss: 1.7965754270553589
Validation loss: 2.0979920869232505

Epoch: 6| Step: 8
Training loss: 1.6902868747711182
Validation loss: 2.0523904702996694

Epoch: 6| Step: 9
Training loss: 1.8188692331314087
Validation loss: 2.029209857345909

Epoch: 6| Step: 10
Training loss: 2.1863160133361816
Validation loss: 2.0437053326637513

Epoch: 6| Step: 11
Training loss: 2.212982177734375
Validation loss: 2.025944653377738

Epoch: 6| Step: 12
Training loss: 1.8547924757003784
Validation loss: 2.0804149181612077

Epoch: 6| Step: 13
Training loss: 1.99736487865448
Validation loss: 2.0628533773524786

Epoch: 302| Step: 0
Training loss: 1.9840385913848877
Validation loss: 2.0158615945487894

Epoch: 6| Step: 1
Training loss: 1.110243558883667
Validation loss: 2.0771463404419603

Epoch: 6| Step: 2
Training loss: 1.713040828704834
Validation loss: 2.0976071485909085

Epoch: 6| Step: 3
Training loss: 2.2115325927734375
Validation loss: 2.0156590656567643

Epoch: 6| Step: 4
Training loss: 1.7833083868026733
Validation loss: 2.0433530910040743

Epoch: 6| Step: 5
Training loss: 1.881351113319397
Validation loss: 2.0446552179192983

Epoch: 6| Step: 6
Training loss: 1.7058417797088623
Validation loss: 2.046187448245223

Epoch: 6| Step: 7
Training loss: 1.4312087297439575
Validation loss: 2.049405982417445

Epoch: 6| Step: 8
Training loss: 2.3308939933776855
Validation loss: 1.997808152629483

Epoch: 6| Step: 9
Training loss: 2.2984256744384766
Validation loss: 2.054166796386883

Epoch: 6| Step: 10
Training loss: 1.160203456878662
Validation loss: 2.045370163456086

Epoch: 6| Step: 11
Training loss: 1.23124361038208
Validation loss: 2.046329464963687

Epoch: 6| Step: 12
Training loss: 1.5366802215576172
Validation loss: 2.063459814235728

Epoch: 6| Step: 13
Training loss: 1.6167405843734741
Validation loss: 2.072099739505399

Epoch: 303| Step: 0
Training loss: 1.5411031246185303
Validation loss: 2.0875811679388887

Epoch: 6| Step: 1
Training loss: 1.0327808856964111
Validation loss: 2.0663068371434368

Epoch: 6| Step: 2
Training loss: 1.8697469234466553
Validation loss: 2.0445032273569415

Epoch: 6| Step: 3
Training loss: 2.0832693576812744
Validation loss: 2.0458495463094404

Epoch: 6| Step: 4
Training loss: 1.6430184841156006
Validation loss: 2.0586932141293763

Epoch: 6| Step: 5
Training loss: 1.560670256614685
Validation loss: 2.0154067752181843

Epoch: 6| Step: 6
Training loss: 1.4514747858047485
Validation loss: 2.0403676571384555

Epoch: 6| Step: 7
Training loss: 1.6914963722229004
Validation loss: 2.0694137311750844

Epoch: 6| Step: 8
Training loss: 2.165437698364258
Validation loss: 2.01362278128183

Epoch: 6| Step: 9
Training loss: 1.9401087760925293
Validation loss: 2.0348667239630096

Epoch: 6| Step: 10
Training loss: 1.648647427558899
Validation loss: 2.0596826102143977

Epoch: 6| Step: 11
Training loss: 1.3064186573028564
Validation loss: 2.0487724939982095

Epoch: 6| Step: 12
Training loss: 1.8918203115463257
Validation loss: 2.061468057734992

Epoch: 6| Step: 13
Training loss: 2.3676059246063232
Validation loss: 2.0093038748669367

Epoch: 304| Step: 0
Training loss: 2.408792495727539
Validation loss: 2.0485223339449976

Epoch: 6| Step: 1
Training loss: 1.5919034481048584
Validation loss: 2.053498944928569

Epoch: 6| Step: 2
Training loss: 1.362866759300232
Validation loss: 2.0539668272900324

Epoch: 6| Step: 3
Training loss: 1.692154884338379
Validation loss: 2.0534783242851176

Epoch: 6| Step: 4
Training loss: 1.8402175903320312
Validation loss: 2.0876109497521513

Epoch: 6| Step: 5
Training loss: 1.9413831233978271
Validation loss: 2.0747437387384395

Epoch: 6| Step: 6
Training loss: 1.8405346870422363
Validation loss: 2.090928998044742

Epoch: 6| Step: 7
Training loss: 1.7843713760375977
Validation loss: 2.078695927896807

Epoch: 6| Step: 8
Training loss: 1.2897915840148926
Validation loss: 2.0551782884905414

Epoch: 6| Step: 9
Training loss: 1.7878013849258423
Validation loss: 2.0626261336829073

Epoch: 6| Step: 10
Training loss: 1.386598825454712
Validation loss: 2.0475830506252986

Epoch: 6| Step: 11
Training loss: 1.7017076015472412
Validation loss: 2.112356521750009

Epoch: 6| Step: 12
Training loss: 1.0483732223510742
Validation loss: 2.0515117465808825

Epoch: 6| Step: 13
Training loss: 2.7807977199554443
Validation loss: 2.0455372436072237

Epoch: 305| Step: 0
Training loss: 1.5495004653930664
Validation loss: 2.06553251512589

Epoch: 6| Step: 1
Training loss: 2.1111340522766113
Validation loss: 2.0560972216308757

Epoch: 6| Step: 2
Training loss: 2.5058183670043945
Validation loss: 2.0556180887324835

Epoch: 6| Step: 3
Training loss: 0.9495737552642822
Validation loss: 2.043404758617442

Epoch: 6| Step: 4
Training loss: 2.2588753700256348
Validation loss: 2.0707417098424767

Epoch: 6| Step: 5
Training loss: 1.6993608474731445
Validation loss: 2.042080702320222

Epoch: 6| Step: 6
Training loss: 1.8945189714431763
Validation loss: 2.045207982422203

Epoch: 6| Step: 7
Training loss: 1.5343742370605469
Validation loss: 2.0473415197864657

Epoch: 6| Step: 8
Training loss: 2.026298999786377
Validation loss: 2.0120501415703886

Epoch: 6| Step: 9
Training loss: 0.8810470700263977
Validation loss: 2.0094729559395903

Epoch: 6| Step: 10
Training loss: 1.361619234085083
Validation loss: 2.060382548198905

Epoch: 6| Step: 11
Training loss: 1.2921415567398071
Validation loss: 2.0401856873625066

Epoch: 6| Step: 12
Training loss: 1.7142983675003052
Validation loss: 2.0521670003091135

Epoch: 6| Step: 13
Training loss: 2.0006980895996094
Validation loss: 2.0942314209476596

Epoch: 306| Step: 0
Training loss: 1.4089124202728271
Validation loss: 2.040502622563352

Epoch: 6| Step: 1
Training loss: 1.2782264947891235
Validation loss: 2.04176333642775

Epoch: 6| Step: 2
Training loss: 1.4672859907150269
Validation loss: 2.0406135051481185

Epoch: 6| Step: 3
Training loss: 1.653597354888916
Validation loss: 2.0374549819577124

Epoch: 6| Step: 4
Training loss: 1.6911592483520508
Validation loss: 2.057699188109367

Epoch: 6| Step: 5
Training loss: 1.535543441772461
Validation loss: 2.047994823865993

Epoch: 6| Step: 6
Training loss: 1.9377632141113281
Validation loss: 2.08804367690958

Epoch: 6| Step: 7
Training loss: 2.066004514694214
Validation loss: 2.03129332552674

Epoch: 6| Step: 8
Training loss: 1.9512684345245361
Validation loss: 2.0572343987803303

Epoch: 6| Step: 9
Training loss: 1.3475421667099
Validation loss: 2.0579600821259203

Epoch: 6| Step: 10
Training loss: 2.208146095275879
Validation loss: 2.0902945098056587

Epoch: 6| Step: 11
Training loss: 1.6729161739349365
Validation loss: 2.0666913601659958

Epoch: 6| Step: 12
Training loss: 1.6320176124572754
Validation loss: 2.0355018774668374

Epoch: 6| Step: 13
Training loss: 1.95889151096344
Validation loss: 2.0542960859114126

Epoch: 307| Step: 0
Training loss: 1.4386942386627197
Validation loss: 2.072780204075639

Epoch: 6| Step: 1
Training loss: 2.3649237155914307
Validation loss: 2.0400113290356052

Epoch: 6| Step: 2
Training loss: 2.0981922149658203
Validation loss: 2.0859273454194427

Epoch: 6| Step: 3
Training loss: 2.1759912967681885
Validation loss: 2.0518257925587315

Epoch: 6| Step: 4
Training loss: 1.0922608375549316
Validation loss: 2.051547542695076

Epoch: 6| Step: 5
Training loss: 1.4859448671340942
Validation loss: 2.0740708433171755

Epoch: 6| Step: 6
Training loss: 1.6341755390167236
Validation loss: 2.0157141018939275

Epoch: 6| Step: 7
Training loss: 1.690171241760254
Validation loss: 2.055436036920035

Epoch: 6| Step: 8
Training loss: 1.1475834846496582
Validation loss: 2.076435245493407

Epoch: 6| Step: 9
Training loss: 2.29898738861084
Validation loss: 2.028153702776919

Epoch: 6| Step: 10
Training loss: 1.161771297454834
Validation loss: 2.0727704840321697

Epoch: 6| Step: 11
Training loss: 1.2932474613189697
Validation loss: 2.066772125100577

Epoch: 6| Step: 12
Training loss: 1.9191157817840576
Validation loss: 2.0585815419432936

Epoch: 6| Step: 13
Training loss: 1.7394328117370605
Validation loss: 2.0743638982055006

Epoch: 308| Step: 0
Training loss: 1.6464132070541382
Validation loss: 2.015151318683419

Epoch: 6| Step: 1
Training loss: 1.3272438049316406
Validation loss: 2.031374792898855

Epoch: 6| Step: 2
Training loss: 2.163646936416626
Validation loss: 2.041191698402487

Epoch: 6| Step: 3
Training loss: 1.2875678539276123
Validation loss: 2.0521747707038798

Epoch: 6| Step: 4
Training loss: 1.653934359550476
Validation loss: 2.060445426612772

Epoch: 6| Step: 5
Training loss: 1.8369495868682861
Validation loss: 2.065018243687127

Epoch: 6| Step: 6
Training loss: 1.2792706489562988
Validation loss: 2.0664852908862534

Epoch: 6| Step: 7
Training loss: 1.7088955640792847
Validation loss: 2.0377923545017036

Epoch: 6| Step: 8
Training loss: 1.868639349937439
Validation loss: 2.017269072994109

Epoch: 6| Step: 9
Training loss: 2.1277542114257812
Validation loss: 2.0473522422134236

Epoch: 6| Step: 10
Training loss: 1.7962889671325684
Validation loss: 2.095047958435551

Epoch: 6| Step: 11
Training loss: 1.936987042427063
Validation loss: 2.0394600975898003

Epoch: 6| Step: 12
Training loss: 1.4999749660491943
Validation loss: 2.030982689190936

Epoch: 6| Step: 13
Training loss: 2.039001703262329
Validation loss: 2.036578280951387

Epoch: 309| Step: 0
Training loss: 1.1738189458847046
Validation loss: 2.0631014095839633

Epoch: 6| Step: 1
Training loss: 1.7931042909622192
Validation loss: 2.0567557427190963

Epoch: 6| Step: 2
Training loss: 1.9972190856933594
Validation loss: 2.0536764078242804

Epoch: 6| Step: 3
Training loss: 1.419562816619873
Validation loss: 2.070816465603408

Epoch: 6| Step: 4
Training loss: 1.5501748323440552
Validation loss: 2.06770908704368

Epoch: 6| Step: 5
Training loss: 1.2135131359100342
Validation loss: 2.0511917119385092

Epoch: 6| Step: 6
Training loss: 1.4553190469741821
Validation loss: 2.0195587117184877

Epoch: 6| Step: 7
Training loss: 1.8080978393554688
Validation loss: 2.037814382583864

Epoch: 6| Step: 8
Training loss: 2.122645378112793
Validation loss: 2.048326834555595

Epoch: 6| Step: 9
Training loss: 1.5879186391830444
Validation loss: 2.029772348301385

Epoch: 6| Step: 10
Training loss: 2.1493120193481445
Validation loss: 2.0659883278672413

Epoch: 6| Step: 11
Training loss: 1.8803644180297852
Validation loss: 2.0388469388408046

Epoch: 6| Step: 12
Training loss: 2.3445541858673096
Validation loss: 2.032499744046119

Epoch: 6| Step: 13
Training loss: 1.4333387613296509
Validation loss: 2.038028863168532

Epoch: 310| Step: 0
Training loss: 1.2591116428375244
Validation loss: 2.0606652203426568

Epoch: 6| Step: 1
Training loss: 1.876114845275879
Validation loss: 2.0360651682781916

Epoch: 6| Step: 2
Training loss: 1.719860553741455
Validation loss: 2.0557441198697655

Epoch: 6| Step: 3
Training loss: 1.6929247379302979
Validation loss: 2.0271797936449767

Epoch: 6| Step: 4
Training loss: 1.5194965600967407
Validation loss: 2.060381704761136

Epoch: 6| Step: 5
Training loss: 2.1828513145446777
Validation loss: 2.017993357873732

Epoch: 6| Step: 6
Training loss: 2.1963951587677
Validation loss: 2.0672113715961413

Epoch: 6| Step: 7
Training loss: 1.573988914489746
Validation loss: 2.039822243875073

Epoch: 6| Step: 8
Training loss: 1.462349772453308
Validation loss: 2.0304838841961277

Epoch: 6| Step: 9
Training loss: 1.696648359298706
Validation loss: 2.0632339844139675

Epoch: 6| Step: 10
Training loss: 1.674032211303711
Validation loss: 2.0525668026298605

Epoch: 6| Step: 11
Training loss: 1.5977493524551392
Validation loss: 2.030824876600696

Epoch: 6| Step: 12
Training loss: 1.4767673015594482
Validation loss: 2.0580151055448797

Epoch: 6| Step: 13
Training loss: 1.772472858428955
Validation loss: 2.0787476339647846

Epoch: 311| Step: 0
Training loss: 1.6908646821975708
Validation loss: 2.07686048682018

Epoch: 6| Step: 1
Training loss: 1.9133590459823608
Validation loss: 2.071763066835301

Epoch: 6| Step: 2
Training loss: 1.4181863069534302
Validation loss: 2.058381768964952

Epoch: 6| Step: 3
Training loss: 1.6707391738891602
Validation loss: 2.0881271990396644

Epoch: 6| Step: 4
Training loss: 1.7190625667572021
Validation loss: 2.0613369967347834

Epoch: 6| Step: 5
Training loss: 2.369051218032837
Validation loss: 2.0644610569041264

Epoch: 6| Step: 6
Training loss: 1.5289888381958008
Validation loss: 2.0598974996997463

Epoch: 6| Step: 7
Training loss: 1.5261512994766235
Validation loss: 2.034296263930618

Epoch: 6| Step: 8
Training loss: 1.2452547550201416
Validation loss: 2.029235980843985

Epoch: 6| Step: 9
Training loss: 1.3359928131103516
Validation loss: 2.025689765971194

Epoch: 6| Step: 10
Training loss: 1.735081434249878
Validation loss: 2.0605105379576325

Epoch: 6| Step: 11
Training loss: 1.669081211090088
Validation loss: 2.0585893623290525

Epoch: 6| Step: 12
Training loss: 1.8916587829589844
Validation loss: 2.0610032004694783

Epoch: 6| Step: 13
Training loss: 2.044966697692871
Validation loss: 2.0581658963234193

Epoch: 312| Step: 0
Training loss: 1.2883647680282593
Validation loss: 2.023748641373009

Epoch: 6| Step: 1
Training loss: 1.769270896911621
Validation loss: 2.0138459256900254

Epoch: 6| Step: 2
Training loss: 1.6132535934448242
Validation loss: 2.077970876488634

Epoch: 6| Step: 3
Training loss: 2.484963893890381
Validation loss: 2.041261480700585

Epoch: 6| Step: 4
Training loss: 2.2111830711364746
Validation loss: 2.064668127285537

Epoch: 6| Step: 5
Training loss: 1.6486108303070068
Validation loss: 2.0278046361861692

Epoch: 6| Step: 6
Training loss: 1.6118602752685547
Validation loss: 2.082479597419821

Epoch: 6| Step: 7
Training loss: 1.4657416343688965
Validation loss: 2.0210604577936153

Epoch: 6| Step: 8
Training loss: 1.718165636062622
Validation loss: 2.0756760207555627

Epoch: 6| Step: 9
Training loss: 1.5891594886779785
Validation loss: 2.030944816527828

Epoch: 6| Step: 10
Training loss: 1.769605278968811
Validation loss: 2.0793716651137157

Epoch: 6| Step: 11
Training loss: 1.0966144800186157
Validation loss: 2.0987602587669127

Epoch: 6| Step: 12
Training loss: 1.2814148664474487
Validation loss: 2.0648039476845854

Epoch: 6| Step: 13
Training loss: 1.7721424102783203
Validation loss: 2.0195935618492866

Epoch: 313| Step: 0
Training loss: 1.0453178882598877
Validation loss: 2.0423286537970267

Epoch: 6| Step: 1
Training loss: 1.5086686611175537
Validation loss: 2.05767055737075

Epoch: 6| Step: 2
Training loss: 2.0664496421813965
Validation loss: 2.0724808477586314

Epoch: 6| Step: 3
Training loss: 1.548602819442749
Validation loss: 2.0427585942770845

Epoch: 6| Step: 4
Training loss: 1.4273375272750854
Validation loss: 2.045459524277718

Epoch: 6| Step: 5
Training loss: 2.2410311698913574
Validation loss: 2.0783698353716122

Epoch: 6| Step: 6
Training loss: 1.5804059505462646
Validation loss: 2.067572537288871

Epoch: 6| Step: 7
Training loss: 1.7277488708496094
Validation loss: 2.060626499114498

Epoch: 6| Step: 8
Training loss: 1.7116539478302002
Validation loss: 2.0896515371978923

Epoch: 6| Step: 9
Training loss: 2.0987329483032227
Validation loss: 2.083544554248933

Epoch: 6| Step: 10
Training loss: 2.0593814849853516
Validation loss: 2.123274746761527

Epoch: 6| Step: 11
Training loss: 1.2669466733932495
Validation loss: 2.095179941064568

Epoch: 6| Step: 12
Training loss: 1.669207215309143
Validation loss: 2.047591658048732

Epoch: 6| Step: 13
Training loss: 1.4021360874176025
Validation loss: 2.0421367819591234

Epoch: 314| Step: 0
Training loss: 1.5146551132202148
Validation loss: 2.0519583263704853

Epoch: 6| Step: 1
Training loss: 1.55082106590271
Validation loss: 2.0307647976824033

Epoch: 6| Step: 2
Training loss: 1.7963666915893555
Validation loss: 2.079509460797874

Epoch: 6| Step: 3
Training loss: 1.6891834735870361
Validation loss: 2.070668767857295

Epoch: 6| Step: 4
Training loss: 2.0597336292266846
Validation loss: 2.027122205303561

Epoch: 6| Step: 5
Training loss: 1.6919646263122559
Validation loss: 2.0361401240030923

Epoch: 6| Step: 6
Training loss: 1.4274197816848755
Validation loss: 2.072375379582887

Epoch: 6| Step: 7
Training loss: 1.2846996784210205
Validation loss: 2.05699558027329

Epoch: 6| Step: 8
Training loss: 1.278073787689209
Validation loss: 2.0579839368020334

Epoch: 6| Step: 9
Training loss: 1.7941269874572754
Validation loss: 2.067704995473226

Epoch: 6| Step: 10
Training loss: 1.5259202718734741
Validation loss: 2.065045343932285

Epoch: 6| Step: 11
Training loss: 2.021083354949951
Validation loss: 2.0911775455679944

Epoch: 6| Step: 12
Training loss: 1.7719911336898804
Validation loss: 2.069657858981881

Epoch: 6| Step: 13
Training loss: 2.3536462783813477
Validation loss: 2.0427567753740536

Epoch: 315| Step: 0
Training loss: 1.3818585872650146
Validation loss: 2.0532340336871404

Epoch: 6| Step: 1
Training loss: 1.8338592052459717
Validation loss: 2.080214564518262

Epoch: 6| Step: 2
Training loss: 0.9847031831741333
Validation loss: 2.08585649536502

Epoch: 6| Step: 3
Training loss: 1.3449451923370361
Validation loss: 2.043346979284799

Epoch: 6| Step: 4
Training loss: 1.9560372829437256
Validation loss: 2.041397656163862

Epoch: 6| Step: 5
Training loss: 2.377518653869629
Validation loss: 2.056265643847886

Epoch: 6| Step: 6
Training loss: 1.8624523878097534
Validation loss: 2.0837707455440233

Epoch: 6| Step: 7
Training loss: 1.4167927503585815
Validation loss: 2.064805030822754

Epoch: 6| Step: 8
Training loss: 1.9442040920257568
Validation loss: 2.0148906720581876

Epoch: 6| Step: 9
Training loss: 1.6516517400741577
Validation loss: 2.0511228884420087

Epoch: 6| Step: 10
Training loss: 1.664759874343872
Validation loss: 2.027511432606687

Epoch: 6| Step: 11
Training loss: 1.777523398399353
Validation loss: 2.073071120887674

Epoch: 6| Step: 12
Training loss: 1.7927954196929932
Validation loss: 2.0622520574959378

Epoch: 6| Step: 13
Training loss: 1.4415901899337769
Validation loss: 2.0869507866521038

Epoch: 316| Step: 0
Training loss: 1.6122205257415771
Validation loss: 2.044330084195701

Epoch: 6| Step: 1
Training loss: 1.412354826927185
Validation loss: 2.042991974020517

Epoch: 6| Step: 2
Training loss: 1.6425044536590576
Validation loss: 2.070752825788272

Epoch: 6| Step: 3
Training loss: 1.6950984001159668
Validation loss: 2.051958848071355

Epoch: 6| Step: 4
Training loss: 1.5505290031433105
Validation loss: 2.0487385603689376

Epoch: 6| Step: 5
Training loss: 1.4597482681274414
Validation loss: 2.0291212592073666

Epoch: 6| Step: 6
Training loss: 1.8580000400543213
Validation loss: 2.0159767238042687

Epoch: 6| Step: 7
Training loss: 2.1877565383911133
Validation loss: 2.0484510685807917

Epoch: 6| Step: 8
Training loss: 1.7758342027664185
Validation loss: 2.068919486896966

Epoch: 6| Step: 9
Training loss: 1.3390560150146484
Validation loss: 2.039342869994461

Epoch: 6| Step: 10
Training loss: 2.057888984680176
Validation loss: 2.063341135619789

Epoch: 6| Step: 11
Training loss: 1.4182300567626953
Validation loss: 2.0639329648786977

Epoch: 6| Step: 12
Training loss: 2.4220426082611084
Validation loss: 2.068855380499235

Epoch: 6| Step: 13
Training loss: 0.9856851100921631
Validation loss: 2.0800554111439693

Epoch: 317| Step: 0
Training loss: 1.2996406555175781
Validation loss: 2.059937966767178

Epoch: 6| Step: 1
Training loss: 2.0654194355010986
Validation loss: 2.017423363142116

Epoch: 6| Step: 2
Training loss: 2.080918073654175
Validation loss: 2.0650532758364113

Epoch: 6| Step: 3
Training loss: 1.487688660621643
Validation loss: 2.059607998017342

Epoch: 6| Step: 4
Training loss: 2.3533921241760254
Validation loss: 2.059292839419457

Epoch: 6| Step: 5
Training loss: 1.2416949272155762
Validation loss: 2.071779433117118

Epoch: 6| Step: 6
Training loss: 1.832817554473877
Validation loss: 2.05612874543795

Epoch: 6| Step: 7
Training loss: 1.1784387826919556
Validation loss: 2.0919880982368224

Epoch: 6| Step: 8
Training loss: 2.184169292449951
Validation loss: 2.0556858995909333

Epoch: 6| Step: 9
Training loss: 1.3128314018249512
Validation loss: 2.1070638266942834

Epoch: 6| Step: 10
Training loss: 1.628665566444397
Validation loss: 2.0518214600060576

Epoch: 6| Step: 11
Training loss: 1.6680793762207031
Validation loss: 2.052292053417493

Epoch: 6| Step: 12
Training loss: 1.3898518085479736
Validation loss: 2.0400714258993826

Epoch: 6| Step: 13
Training loss: 1.0037376880645752
Validation loss: 2.029507408859909

Epoch: 318| Step: 0
Training loss: 1.542121171951294
Validation loss: 2.095129087407102

Epoch: 6| Step: 1
Training loss: 2.2503113746643066
Validation loss: 2.042260618620021

Epoch: 6| Step: 2
Training loss: 1.6593997478485107
Validation loss: 2.0397071146195933

Epoch: 6| Step: 3
Training loss: 1.1653677225112915
Validation loss: 2.061851132300592

Epoch: 6| Step: 4
Training loss: 1.2466033697128296
Validation loss: 2.0458290294934343

Epoch: 6| Step: 5
Training loss: 2.0250797271728516
Validation loss: 2.0715309855758504

Epoch: 6| Step: 6
Training loss: 2.399791717529297
Validation loss: 2.058414343864687

Epoch: 6| Step: 7
Training loss: 2.1224186420440674
Validation loss: 2.0378981226234028

Epoch: 6| Step: 8
Training loss: 1.4657936096191406
Validation loss: 2.0518974052962435

Epoch: 6| Step: 9
Training loss: 1.0648353099822998
Validation loss: 2.0489896061599895

Epoch: 6| Step: 10
Training loss: 1.8067926168441772
Validation loss: 2.0332917269840034

Epoch: 6| Step: 11
Training loss: 1.3180325031280518
Validation loss: 2.0427652507699947

Epoch: 6| Step: 12
Training loss: 1.5070855617523193
Validation loss: 2.0352706691270233

Epoch: 6| Step: 13
Training loss: 2.2730023860931396
Validation loss: 2.0249194675876248

Epoch: 319| Step: 0
Training loss: 1.8572747707366943
Validation loss: 2.0316740979430494

Epoch: 6| Step: 1
Training loss: 2.395901918411255
Validation loss: 2.043412662321521

Epoch: 6| Step: 2
Training loss: 1.7746119499206543
Validation loss: 2.060079559203117

Epoch: 6| Step: 3
Training loss: 0.8640739917755127
Validation loss: 2.0557937968161797

Epoch: 6| Step: 4
Training loss: 2.114006519317627
Validation loss: 2.0522756204810193

Epoch: 6| Step: 5
Training loss: 1.7571730613708496
Validation loss: 2.040330086984942

Epoch: 6| Step: 6
Training loss: 1.7288140058517456
Validation loss: 2.0890560303964922

Epoch: 6| Step: 7
Training loss: 2.4167661666870117
Validation loss: 2.067445816532258

Epoch: 6| Step: 8
Training loss: 1.4128440618515015
Validation loss: 2.0492754367090042

Epoch: 6| Step: 9
Training loss: 1.4740517139434814
Validation loss: 2.0213602640295543

Epoch: 6| Step: 10
Training loss: 1.476337194442749
Validation loss: 2.062897741153676

Epoch: 6| Step: 11
Training loss: 1.5438342094421387
Validation loss: 2.0694893508829098

Epoch: 6| Step: 12
Training loss: 1.1676920652389526
Validation loss: 2.0636981020691576

Epoch: 6| Step: 13
Training loss: 1.2693895101547241
Validation loss: 2.0303360364770375

Epoch: 320| Step: 0
Training loss: 1.7264411449432373
Validation loss: 2.0484918727669665

Epoch: 6| Step: 1
Training loss: 1.9092094898223877
Validation loss: 2.002009859649084

Epoch: 6| Step: 2
Training loss: 1.425243854522705
Validation loss: 2.082888336591823

Epoch: 6| Step: 3
Training loss: 1.381329894065857
Validation loss: 2.0449743117055585

Epoch: 6| Step: 4
Training loss: 1.4286060333251953
Validation loss: 2.0743075775843796

Epoch: 6| Step: 5
Training loss: 1.466361403465271
Validation loss: 2.090452186522945

Epoch: 6| Step: 6
Training loss: 2.2552366256713867
Validation loss: 2.084303161149384

Epoch: 6| Step: 7
Training loss: 2.19527006149292
Validation loss: 2.0448703304413827

Epoch: 6| Step: 8
Training loss: 1.6785900592803955
Validation loss: 2.0571991576943347

Epoch: 6| Step: 9
Training loss: 1.5671336650848389
Validation loss: 2.0372989485340733

Epoch: 6| Step: 10
Training loss: 1.6198089122772217
Validation loss: 2.057260351796304

Epoch: 6| Step: 11
Training loss: 1.2830029726028442
Validation loss: 2.081489973170783

Epoch: 6| Step: 12
Training loss: 1.6126887798309326
Validation loss: 2.052197531987262

Epoch: 6| Step: 13
Training loss: 1.5340991020202637
Validation loss: 2.107767438375822

Epoch: 321| Step: 0
Training loss: 1.952521800994873
Validation loss: 2.0812430920139438

Epoch: 6| Step: 1
Training loss: 1.9541569948196411
Validation loss: 2.035061344023674

Epoch: 6| Step: 2
Training loss: 1.9051239490509033
Validation loss: 2.072620130354358

Epoch: 6| Step: 3
Training loss: 1.4135346412658691
Validation loss: 2.0973555618716824

Epoch: 6| Step: 4
Training loss: 2.7813751697540283
Validation loss: 2.07318514649586

Epoch: 6| Step: 5
Training loss: 1.1396379470825195
Validation loss: 2.073393685843355

Epoch: 6| Step: 6
Training loss: 1.967910647392273
Validation loss: 2.0807997577933857

Epoch: 6| Step: 7
Training loss: 1.635898232460022
Validation loss: 2.0809699784043016

Epoch: 6| Step: 8
Training loss: 1.287753701210022
Validation loss: 2.085727542959234

Epoch: 6| Step: 9
Training loss: 1.7600336074829102
Validation loss: 2.1180883646011353

Epoch: 6| Step: 10
Training loss: 1.498006820678711
Validation loss: 2.0602649488756732

Epoch: 6| Step: 11
Training loss: 1.5039806365966797
Validation loss: 2.0477592278552312

Epoch: 6| Step: 12
Training loss: 1.2669458389282227
Validation loss: 2.043330587366576

Epoch: 6| Step: 13
Training loss: 1.4130414724349976
Validation loss: 2.03133116486252

Epoch: 322| Step: 0
Training loss: 1.4296760559082031
Validation loss: 2.03766034495446

Epoch: 6| Step: 1
Training loss: 2.2973599433898926
Validation loss: 2.0521824821349113

Epoch: 6| Step: 2
Training loss: 1.1819392442703247
Validation loss: 2.0506005235897597

Epoch: 6| Step: 3
Training loss: 1.4394787549972534
Validation loss: 2.0730843210733063

Epoch: 6| Step: 4
Training loss: 1.188251256942749
Validation loss: 2.0663677620631393

Epoch: 6| Step: 5
Training loss: 1.7367801666259766
Validation loss: 2.107026602632256

Epoch: 6| Step: 6
Training loss: 2.589034080505371
Validation loss: 2.0251027948112896

Epoch: 6| Step: 7
Training loss: 1.304807186126709
Validation loss: 2.0709191906836724

Epoch: 6| Step: 8
Training loss: 1.1423559188842773
Validation loss: 2.0693988697503203

Epoch: 6| Step: 9
Training loss: 1.7225383520126343
Validation loss: 2.093731636642128

Epoch: 6| Step: 10
Training loss: 1.837149739265442
Validation loss: 2.0783480841626405

Epoch: 6| Step: 11
Training loss: 1.5747673511505127
Validation loss: 2.065294711820541

Epoch: 6| Step: 12
Training loss: 2.065291166305542
Validation loss: 2.0883157355811006

Epoch: 6| Step: 13
Training loss: 1.8095468282699585
Validation loss: 2.043113407268319

Epoch: 323| Step: 0
Training loss: 1.6742535829544067
Validation loss: 2.049999798497846

Epoch: 6| Step: 1
Training loss: 2.0453896522521973
Validation loss: 2.041079544251965

Epoch: 6| Step: 2
Training loss: 1.182042121887207
Validation loss: 2.0655814575892624

Epoch: 6| Step: 3
Training loss: 1.397054672241211
Validation loss: 2.063090096237839

Epoch: 6| Step: 4
Training loss: 1.7024924755096436
Validation loss: 2.0973079614741827

Epoch: 6| Step: 5
Training loss: 1.939925193786621
Validation loss: 2.054248486795733

Epoch: 6| Step: 6
Training loss: 2.128443717956543
Validation loss: 2.0181419234122

Epoch: 6| Step: 7
Training loss: 1.3697402477264404
Validation loss: 2.035223232802524

Epoch: 6| Step: 8
Training loss: 1.6788830757141113
Validation loss: 2.0470104050892655

Epoch: 6| Step: 9
Training loss: 1.5985257625579834
Validation loss: 2.0681580010280816

Epoch: 6| Step: 10
Training loss: 1.7217915058135986
Validation loss: 2.091210813932521

Epoch: 6| Step: 11
Training loss: 1.5958876609802246
Validation loss: 2.0309191134668167

Epoch: 6| Step: 12
Training loss: 1.5601742267608643
Validation loss: 2.069337534648116

Epoch: 6| Step: 13
Training loss: 1.4885039329528809
Validation loss: 2.090840990825366

Epoch: 324| Step: 0
Training loss: 1.3002362251281738
Validation loss: 2.0702928881491385

Epoch: 6| Step: 1
Training loss: 1.2339940071105957
Validation loss: 2.0382900225218905

Epoch: 6| Step: 2
Training loss: 2.09190034866333
Validation loss: 2.069446567566164

Epoch: 6| Step: 3
Training loss: 1.3598835468292236
Validation loss: 2.0563183997267034

Epoch: 6| Step: 4
Training loss: 1.3329432010650635
Validation loss: 2.0655249575132966

Epoch: 6| Step: 5
Training loss: 1.0598995685577393
Validation loss: 2.0313845783151607

Epoch: 6| Step: 6
Training loss: 1.581908941268921
Validation loss: 2.0824781515265025

Epoch: 6| Step: 7
Training loss: 1.6699961423873901
Validation loss: 2.084353636669856

Epoch: 6| Step: 8
Training loss: 2.4467248916625977
Validation loss: 2.095919211705526

Epoch: 6| Step: 9
Training loss: 2.203655242919922
Validation loss: 2.08459888222397

Epoch: 6| Step: 10
Training loss: 1.8050140142440796
Validation loss: 2.062084590235064

Epoch: 6| Step: 11
Training loss: 1.771754503250122
Validation loss: 2.0952754533419045

Epoch: 6| Step: 12
Training loss: 1.4356359243392944
Validation loss: 2.0581398728073284

Epoch: 6| Step: 13
Training loss: 1.9405542612075806
Validation loss: 2.0506757472151067

Epoch: 325| Step: 0
Training loss: 1.4196135997772217
Validation loss: 2.0793664634868665

Epoch: 6| Step: 1
Training loss: 1.8230640888214111
Validation loss: 2.042704692450903

Epoch: 6| Step: 2
Training loss: 1.7575767040252686
Validation loss: 2.03368684809695

Epoch: 6| Step: 3
Training loss: 1.6917476654052734
Validation loss: 2.0989071912662958

Epoch: 6| Step: 4
Training loss: 2.2752747535705566
Validation loss: 2.057271303669099

Epoch: 6| Step: 5
Training loss: 1.409232497215271
Validation loss: 2.0714810009925597

Epoch: 6| Step: 6
Training loss: 0.9928120374679565
Validation loss: 2.000090981042513

Epoch: 6| Step: 7
Training loss: 1.4559478759765625
Validation loss: 2.052512748267061

Epoch: 6| Step: 8
Training loss: 1.4011551141738892
Validation loss: 2.0370584200787287

Epoch: 6| Step: 9
Training loss: 1.4831041097640991
Validation loss: 2.019766681937761

Epoch: 6| Step: 10
Training loss: 1.866683006286621
Validation loss: 2.0466281701159734

Epoch: 6| Step: 11
Training loss: 1.6423407793045044
Validation loss: 2.038866078981789

Epoch: 6| Step: 12
Training loss: 1.720840573310852
Validation loss: 2.074562899528011

Epoch: 6| Step: 13
Training loss: 2.507874011993408
Validation loss: 2.068119410545595

Epoch: 326| Step: 0
Training loss: 1.7249886989593506
Validation loss: 2.0525351083406838

Epoch: 6| Step: 1
Training loss: 2.293610095977783
Validation loss: 2.093583345413208

Epoch: 6| Step: 2
Training loss: 1.3508436679840088
Validation loss: 2.0704160787725963

Epoch: 6| Step: 3
Training loss: 1.0666191577911377
Validation loss: 2.0805285976779078

Epoch: 6| Step: 4
Training loss: 1.8791935443878174
Validation loss: 2.089778938601094

Epoch: 6| Step: 5
Training loss: 1.613771677017212
Validation loss: 2.077579294481585

Epoch: 6| Step: 6
Training loss: 1.6249788999557495
Validation loss: 2.133031081127864

Epoch: 6| Step: 7
Training loss: 1.5064153671264648
Validation loss: 2.0600650900153705

Epoch: 6| Step: 8
Training loss: 1.63379967212677
Validation loss: 2.1275716840579944

Epoch: 6| Step: 9
Training loss: 1.6877039670944214
Validation loss: 2.088185207818144

Epoch: 6| Step: 10
Training loss: 2.1442294120788574
Validation loss: 2.051324708487398

Epoch: 6| Step: 11
Training loss: 1.6926504373550415
Validation loss: 2.075118713481452

Epoch: 6| Step: 12
Training loss: 1.484421968460083
Validation loss: 2.082311652039969

Epoch: 6| Step: 13
Training loss: 1.5414185523986816
Validation loss: 2.055034088832076

Epoch: 327| Step: 0
Training loss: 1.1831860542297363
Validation loss: 2.0770797562855545

Epoch: 6| Step: 1
Training loss: 1.6270290613174438
Validation loss: 2.0926537847006195

Epoch: 6| Step: 2
Training loss: 1.5778467655181885
Validation loss: 2.0688046306692143

Epoch: 6| Step: 3
Training loss: 1.4317600727081299
Validation loss: 2.032909749656595

Epoch: 6| Step: 4
Training loss: 1.217999815940857
Validation loss: 2.051927028163787

Epoch: 6| Step: 5
Training loss: 2.123859405517578
Validation loss: 2.0748753214395173

Epoch: 6| Step: 6
Training loss: 1.9533743858337402
Validation loss: 2.048960970294091

Epoch: 6| Step: 7
Training loss: 1.7961065769195557
Validation loss: 2.111378788948059

Epoch: 6| Step: 8
Training loss: 2.2118771076202393
Validation loss: 2.0314157739762337

Epoch: 6| Step: 9
Training loss: 1.5127718448638916
Validation loss: 2.067620644005396

Epoch: 6| Step: 10
Training loss: 1.826171636581421
Validation loss: 2.0527550123071157

Epoch: 6| Step: 11
Training loss: 1.6517670154571533
Validation loss: 2.0668916740725116

Epoch: 6| Step: 12
Training loss: 1.444495439529419
Validation loss: 2.1011459058330906

Epoch: 6| Step: 13
Training loss: 0.8261743187904358
Validation loss: 2.083991663430327

Epoch: 328| Step: 0
Training loss: 1.589794397354126
Validation loss: 2.067519304572895

Epoch: 6| Step: 1
Training loss: 1.431997537612915
Validation loss: 2.0638305717898953

Epoch: 6| Step: 2
Training loss: 1.2006103992462158
Validation loss: 2.0599869092305503

Epoch: 6| Step: 3
Training loss: 2.349688768386841
Validation loss: 2.057518183544118

Epoch: 6| Step: 4
Training loss: 0.9355708360671997
Validation loss: 2.035346972045078

Epoch: 6| Step: 5
Training loss: 1.741220235824585
Validation loss: 2.0537493792913293

Epoch: 6| Step: 6
Training loss: 1.831611156463623
Validation loss: 2.0314184209351898

Epoch: 6| Step: 7
Training loss: 1.7050409317016602
Validation loss: 2.0999368647093415

Epoch: 6| Step: 8
Training loss: 1.2704904079437256
Validation loss: 2.080517643241472

Epoch: 6| Step: 9
Training loss: 1.7110729217529297
Validation loss: 2.0705201266914286

Epoch: 6| Step: 10
Training loss: 1.54433012008667
Validation loss: 2.0896307832451275

Epoch: 6| Step: 11
Training loss: 2.25211501121521
Validation loss: 2.0310823340569772

Epoch: 6| Step: 12
Training loss: 1.5895941257476807
Validation loss: 2.056852025370444

Epoch: 6| Step: 13
Training loss: 1.7562007904052734
Validation loss: 2.0679812149334977

Epoch: 329| Step: 0
Training loss: 1.65212082862854
Validation loss: 2.047067742193899

Epoch: 6| Step: 1
Training loss: 1.479365348815918
Validation loss: 2.0656306512894167

Epoch: 6| Step: 2
Training loss: 1.4293073415756226
Validation loss: 2.045433844289472

Epoch: 6| Step: 3
Training loss: 1.5160750150680542
Validation loss: 2.0880581896792174

Epoch: 6| Step: 4
Training loss: 1.8382022380828857
Validation loss: 1.9909866804717689

Epoch: 6| Step: 5
Training loss: 2.1107611656188965
Validation loss: 2.034293108088996

Epoch: 6| Step: 6
Training loss: 1.3606245517730713
Validation loss: 2.0627533851131314

Epoch: 6| Step: 7
Training loss: 1.9434497356414795
Validation loss: 2.0936475492292836

Epoch: 6| Step: 8
Training loss: 2.0313124656677246
Validation loss: 2.0245809516599103

Epoch: 6| Step: 9
Training loss: 1.6568464040756226
Validation loss: 2.0457882752982517

Epoch: 6| Step: 10
Training loss: 1.7800202369689941
Validation loss: 2.036680377939696

Epoch: 6| Step: 11
Training loss: 1.5565584897994995
Validation loss: 2.037011315745692

Epoch: 6| Step: 12
Training loss: 1.356978416442871
Validation loss: 2.039954500813638

Epoch: 6| Step: 13
Training loss: 1.9709506034851074
Validation loss: 2.0809255428211664

Epoch: 330| Step: 0
Training loss: 2.0989506244659424
Validation loss: 2.0534551207737257

Epoch: 6| Step: 1
Training loss: 1.8601973056793213
Validation loss: 2.084829525281024

Epoch: 6| Step: 2
Training loss: 1.3440184593200684
Validation loss: 2.086727926808019

Epoch: 6| Step: 3
Training loss: 1.7753088474273682
Validation loss: 2.0568708501836306

Epoch: 6| Step: 4
Training loss: 1.4517996311187744
Validation loss: 2.061217256771621

Epoch: 6| Step: 5
Training loss: 1.8336265087127686
Validation loss: 2.052871360573717

Epoch: 6| Step: 6
Training loss: 2.777726650238037
Validation loss: 2.0884766578674316

Epoch: 6| Step: 7
Training loss: 1.2867227792739868
Validation loss: 2.0598398331672914

Epoch: 6| Step: 8
Training loss: 1.1748450994491577
Validation loss: 2.0988570515827467

Epoch: 6| Step: 9
Training loss: 1.4215633869171143
Validation loss: 2.07694657387272

Epoch: 6| Step: 10
Training loss: 1.3009178638458252
Validation loss: 2.083805658484018

Epoch: 6| Step: 11
Training loss: 1.5695630311965942
Validation loss: 2.048121290822183

Epoch: 6| Step: 12
Training loss: 1.7396705150604248
Validation loss: 2.071222830844182

Epoch: 6| Step: 13
Training loss: 1.072218656539917
Validation loss: 2.063238779703776

Epoch: 331| Step: 0
Training loss: 2.289295196533203
Validation loss: 2.0864515355838242

Epoch: 6| Step: 1
Training loss: 1.7339415550231934
Validation loss: 2.034520656831803

Epoch: 6| Step: 2
Training loss: 1.476975440979004
Validation loss: 2.08817901918965

Epoch: 6| Step: 3
Training loss: 1.8404569625854492
Validation loss: 2.05941911666624

Epoch: 6| Step: 4
Training loss: 1.3845093250274658
Validation loss: 2.123389054370183

Epoch: 6| Step: 5
Training loss: 1.251954436302185
Validation loss: 2.093239084366829

Epoch: 6| Step: 6
Training loss: 1.9016166925430298
Validation loss: 2.1125174337817776

Epoch: 6| Step: 7
Training loss: 1.2708035707473755
Validation loss: 2.0789533263893536

Epoch: 6| Step: 8
Training loss: 1.2699365615844727
Validation loss: 2.08770090277477

Epoch: 6| Step: 9
Training loss: 1.8669618368148804
Validation loss: 2.0518111080251713

Epoch: 6| Step: 10
Training loss: 1.2885205745697021
Validation loss: 2.0567320508341633

Epoch: 6| Step: 11
Training loss: 1.5854637622833252
Validation loss: 2.0814649238381335

Epoch: 6| Step: 12
Training loss: 1.800421953201294
Validation loss: 2.0150689335279566

Epoch: 6| Step: 13
Training loss: 2.420572280883789
Validation loss: 2.0446688898148073

Epoch: 332| Step: 0
Training loss: 1.0522446632385254
Validation loss: 2.0533183659276655

Epoch: 6| Step: 1
Training loss: 1.4722211360931396
Validation loss: 2.0684439546318463

Epoch: 6| Step: 2
Training loss: 1.7684636116027832
Validation loss: 2.0578291031622116

Epoch: 6| Step: 3
Training loss: 2.1451311111450195
Validation loss: 2.031437163711876

Epoch: 6| Step: 4
Training loss: 1.523186445236206
Validation loss: 2.0872600052946355

Epoch: 6| Step: 5
Training loss: 2.1500320434570312
Validation loss: 2.048895101393423

Epoch: 6| Step: 6
Training loss: 1.1983227729797363
Validation loss: 2.0290665344525407

Epoch: 6| Step: 7
Training loss: 1.3842847347259521
Validation loss: 2.052758370676348

Epoch: 6| Step: 8
Training loss: 1.7723642587661743
Validation loss: 2.0513938370571343

Epoch: 6| Step: 9
Training loss: 1.7963037490844727
Validation loss: 2.028851568057973

Epoch: 6| Step: 10
Training loss: 1.6704323291778564
Validation loss: 2.052063650982354

Epoch: 6| Step: 11
Training loss: 1.6520708799362183
Validation loss: 2.050297978103802

Epoch: 6| Step: 12
Training loss: 1.3019845485687256
Validation loss: 2.027196652145796

Epoch: 6| Step: 13
Training loss: 1.7152595520019531
Validation loss: 2.0966185421072026

Epoch: 333| Step: 0
Training loss: 1.3656716346740723
Validation loss: 2.076164266114594

Epoch: 6| Step: 1
Training loss: 1.5058021545410156
Validation loss: 2.0640731280849827

Epoch: 6| Step: 2
Training loss: 1.0695116519927979
Validation loss: 2.105688488611611

Epoch: 6| Step: 3
Training loss: 1.9166676998138428
Validation loss: 2.0491971610694804

Epoch: 6| Step: 4
Training loss: 1.7225148677825928
Validation loss: 2.064541397556182

Epoch: 6| Step: 5
Training loss: 0.753915011882782
Validation loss: 2.0678331364867506

Epoch: 6| Step: 6
Training loss: 1.4721598625183105
Validation loss: 2.0803719797442035

Epoch: 6| Step: 7
Training loss: 1.7694203853607178
Validation loss: 2.0345783131096953

Epoch: 6| Step: 8
Training loss: 1.5037329196929932
Validation loss: 2.035328627914511

Epoch: 6| Step: 9
Training loss: 2.3298656940460205
Validation loss: 2.02143294067793

Epoch: 6| Step: 10
Training loss: 2.1199817657470703
Validation loss: 2.0770535827964864

Epoch: 6| Step: 11
Training loss: 1.5636523962020874
Validation loss: 2.076116185034475

Epoch: 6| Step: 12
Training loss: 1.719621181488037
Validation loss: 2.0417310909558366

Epoch: 6| Step: 13
Training loss: 2.30303955078125
Validation loss: 2.0219760466647405

Epoch: 334| Step: 0
Training loss: 1.3745088577270508
Validation loss: 2.0620581462819088

Epoch: 6| Step: 1
Training loss: 1.4849085807800293
Validation loss: 2.0595926418099353

Epoch: 6| Step: 2
Training loss: 1.845280408859253
Validation loss: 2.0615700419231127

Epoch: 6| Step: 3
Training loss: 1.8826303482055664
Validation loss: 2.0494809048150175

Epoch: 6| Step: 4
Training loss: 2.4968581199645996
Validation loss: 2.042417897973009

Epoch: 6| Step: 5
Training loss: 1.4458339214324951
Validation loss: 2.0512636682038665

Epoch: 6| Step: 6
Training loss: 1.541964054107666
Validation loss: 2.07171408976278

Epoch: 6| Step: 7
Training loss: 2.457462787628174
Validation loss: 2.0714685916900635

Epoch: 6| Step: 8
Training loss: 2.025581121444702
Validation loss: 2.039754726553476

Epoch: 6| Step: 9
Training loss: 1.0750007629394531
Validation loss: 2.067250854225569

Epoch: 6| Step: 10
Training loss: 1.1883511543273926
Validation loss: 2.081455361458563

Epoch: 6| Step: 11
Training loss: 1.4746084213256836
Validation loss: 2.1185690536293933

Epoch: 6| Step: 12
Training loss: 0.9756373167037964
Validation loss: 2.084977287118153

Epoch: 6| Step: 13
Training loss: 1.4236019849777222
Validation loss: 2.0521340921360958

Epoch: 335| Step: 0
Training loss: 1.768604040145874
Validation loss: 2.0451034166479625

Epoch: 6| Step: 1
Training loss: 1.4955973625183105
Validation loss: 2.0624949598825104

Epoch: 6| Step: 2
Training loss: 2.6431117057800293
Validation loss: 2.0867851857216126

Epoch: 6| Step: 3
Training loss: 1.1897032260894775
Validation loss: 2.037772194031746

Epoch: 6| Step: 4
Training loss: 1.6091442108154297
Validation loss: 2.0757150675660823

Epoch: 6| Step: 5
Training loss: 1.4887325763702393
Validation loss: 2.0464807492430492

Epoch: 6| Step: 6
Training loss: 1.1976587772369385
Validation loss: 2.0462328451935963

Epoch: 6| Step: 7
Training loss: 1.1843844652175903
Validation loss: 2.0661619042837494

Epoch: 6| Step: 8
Training loss: 1.342670202255249
Validation loss: 2.099658904537078

Epoch: 6| Step: 9
Training loss: 1.7903013229370117
Validation loss: 2.0679244341388827

Epoch: 6| Step: 10
Training loss: 1.6500468254089355
Validation loss: 2.041553548587266

Epoch: 6| Step: 11
Training loss: 1.685915470123291
Validation loss: 2.0478079344636653

Epoch: 6| Step: 12
Training loss: 1.530731201171875
Validation loss: 2.0729997017050303

Epoch: 6| Step: 13
Training loss: 2.202700614929199
Validation loss: 2.0596830306514615

Epoch: 336| Step: 0
Training loss: 1.6032097339630127
Validation loss: 2.0730141516654723

Epoch: 6| Step: 1
Training loss: 1.5605491399765015
Validation loss: 2.0111125848626576

Epoch: 6| Step: 2
Training loss: 1.4543190002441406
Validation loss: 2.069065022212203

Epoch: 6| Step: 3
Training loss: 1.4950785636901855
Validation loss: 2.0742073315446095

Epoch: 6| Step: 4
Training loss: 1.8048865795135498
Validation loss: 2.0457077180185625

Epoch: 6| Step: 5
Training loss: 1.9264278411865234
Validation loss: 2.0732036482903267

Epoch: 6| Step: 6
Training loss: 1.245182991027832
Validation loss: 2.0969055314217844

Epoch: 6| Step: 7
Training loss: 1.889488935470581
Validation loss: 2.04967753348812

Epoch: 6| Step: 8
Training loss: 1.8023550510406494
Validation loss: 2.019310043704125

Epoch: 6| Step: 9
Training loss: 1.3869541883468628
Validation loss: 2.026961306089996

Epoch: 6| Step: 10
Training loss: 1.6687588691711426
Validation loss: 2.0617638249551096

Epoch: 6| Step: 11
Training loss: 1.446528434753418
Validation loss: 2.059907131297614

Epoch: 6| Step: 12
Training loss: 1.8287572860717773
Validation loss: 2.0133832449554117

Epoch: 6| Step: 13
Training loss: 1.4039983749389648
Validation loss: 2.0978717701409453

Epoch: 337| Step: 0
Training loss: 1.2338659763336182
Validation loss: 2.072390289716823

Epoch: 6| Step: 1
Training loss: 1.95524263381958
Validation loss: 2.06241133136134

Epoch: 6| Step: 2
Training loss: 1.4027471542358398
Validation loss: 2.0951683726362003

Epoch: 6| Step: 3
Training loss: 1.9603103399276733
Validation loss: 2.03006378681429

Epoch: 6| Step: 4
Training loss: 2.2121353149414062
Validation loss: 2.0694961676033596

Epoch: 6| Step: 5
Training loss: 1.954695224761963
Validation loss: 2.0467788134851763

Epoch: 6| Step: 6
Training loss: 1.7809102535247803
Validation loss: 2.0980077302584084

Epoch: 6| Step: 7
Training loss: 1.6275529861450195
Validation loss: 2.04053996968013

Epoch: 6| Step: 8
Training loss: 1.1232975721359253
Validation loss: 2.0181437897425827

Epoch: 6| Step: 9
Training loss: 1.430300235748291
Validation loss: 2.018747845003682

Epoch: 6| Step: 10
Training loss: 1.4723737239837646
Validation loss: 2.0489511374504334

Epoch: 6| Step: 11
Training loss: 1.205737590789795
Validation loss: 2.0668319732912126

Epoch: 6| Step: 12
Training loss: 1.4557514190673828
Validation loss: 2.035172813682146

Epoch: 6| Step: 13
Training loss: 1.9234262704849243
Validation loss: 2.021480450066187

Epoch: 338| Step: 0
Training loss: 1.5776021480560303
Validation loss: 2.0586040019989014

Epoch: 6| Step: 1
Training loss: 1.6474690437316895
Validation loss: 2.070388506817561

Epoch: 6| Step: 2
Training loss: 2.1463286876678467
Validation loss: 2.0718561423722135

Epoch: 6| Step: 3
Training loss: 1.6155489683151245
Validation loss: 2.0097758372624717

Epoch: 6| Step: 4
Training loss: 1.2077715396881104
Validation loss: 2.083534573995939

Epoch: 6| Step: 5
Training loss: 1.2059123516082764
Validation loss: 2.090897795974567

Epoch: 6| Step: 6
Training loss: 1.4508341550827026
Validation loss: 2.063062616573867

Epoch: 6| Step: 7
Training loss: 1.575732707977295
Validation loss: 2.0806793500018377

Epoch: 6| Step: 8
Training loss: 1.6861363649368286
Validation loss: 1.9966966388046101

Epoch: 6| Step: 9
Training loss: 1.6666970252990723
Validation loss: 2.067535738791189

Epoch: 6| Step: 10
Training loss: 1.935331106185913
Validation loss: 2.038308357679716

Epoch: 6| Step: 11
Training loss: 1.359496831893921
Validation loss: 2.092223910875218

Epoch: 6| Step: 12
Training loss: 1.8342819213867188
Validation loss: 2.0714468597083964

Epoch: 6| Step: 13
Training loss: 1.6189073324203491
Validation loss: 2.0388957095402542

Epoch: 339| Step: 0
Training loss: 1.5456187725067139
Validation loss: 2.0697216961973455

Epoch: 6| Step: 1
Training loss: 1.7272142171859741
Validation loss: 2.0428562587307346

Epoch: 6| Step: 2
Training loss: 1.9184155464172363
Validation loss: 2.0450340240232405

Epoch: 6| Step: 3
Training loss: 2.0832061767578125
Validation loss: 2.0562531332815848

Epoch: 6| Step: 4
Training loss: 1.4818711280822754
Validation loss: 2.0748275441508137

Epoch: 6| Step: 5
Training loss: 2.0080220699310303
Validation loss: 2.012585204134705

Epoch: 6| Step: 6
Training loss: 1.6472492218017578
Validation loss: 2.0293506550532516

Epoch: 6| Step: 7
Training loss: 1.449512004852295
Validation loss: 2.0396024629633915

Epoch: 6| Step: 8
Training loss: 1.0519458055496216
Validation loss: 2.0473760738167712

Epoch: 6| Step: 9
Training loss: 1.2085421085357666
Validation loss: 2.066177322018531

Epoch: 6| Step: 10
Training loss: 1.3996860980987549
Validation loss: 2.094691284241215

Epoch: 6| Step: 11
Training loss: 1.3970000743865967
Validation loss: 2.0618846339564167

Epoch: 6| Step: 12
Training loss: 1.8043385744094849
Validation loss: 2.0668569892965336

Epoch: 6| Step: 13
Training loss: 1.6309188604354858
Validation loss: 2.067896814756496

Epoch: 340| Step: 0
Training loss: 1.5418974161148071
Validation loss: 2.071204577722857

Epoch: 6| Step: 1
Training loss: 1.650707721710205
Validation loss: 2.0963411446540587

Epoch: 6| Step: 2
Training loss: 1.4163191318511963
Validation loss: 2.1016264602702153

Epoch: 6| Step: 3
Training loss: 1.520672082901001
Validation loss: 2.053053440586213

Epoch: 6| Step: 4
Training loss: 2.0493226051330566
Validation loss: 2.083073518609488

Epoch: 6| Step: 5
Training loss: 0.9085605144500732
Validation loss: 2.084438112474257

Epoch: 6| Step: 6
Training loss: 1.1669305562973022
Validation loss: 2.0296411552736835

Epoch: 6| Step: 7
Training loss: 2.103332996368408
Validation loss: 2.023835269353723

Epoch: 6| Step: 8
Training loss: 1.3152024745941162
Validation loss: 2.071829136981759

Epoch: 6| Step: 9
Training loss: 1.756709098815918
Validation loss: 2.0659332224117812

Epoch: 6| Step: 10
Training loss: 1.2332521677017212
Validation loss: 2.021756324716794

Epoch: 6| Step: 11
Training loss: 1.7538477182388306
Validation loss: 2.0592796943520986

Epoch: 6| Step: 12
Training loss: 2.091921806335449
Validation loss: 2.028211860246556

Epoch: 6| Step: 13
Training loss: 2.0156660079956055
Validation loss: 2.060194023193852

Epoch: 341| Step: 0
Training loss: 1.482944130897522
Validation loss: 2.071091441697972

Epoch: 6| Step: 1
Training loss: 1.7209547758102417
Validation loss: 2.050493517229634

Epoch: 6| Step: 2
Training loss: 1.898016095161438
Validation loss: 2.0716347309850875

Epoch: 6| Step: 3
Training loss: 0.9898585081100464
Validation loss: 2.078486304129324

Epoch: 6| Step: 4
Training loss: 1.5921990871429443
Validation loss: 2.049639568533949

Epoch: 6| Step: 5
Training loss: 1.2605094909667969
Validation loss: 2.009766932456724

Epoch: 6| Step: 6
Training loss: 1.3302409648895264
Validation loss: 2.045904872237995

Epoch: 6| Step: 7
Training loss: 1.1279863119125366
Validation loss: 2.0626081907620994

Epoch: 6| Step: 8
Training loss: 1.8921175003051758
Validation loss: 2.055302186678815

Epoch: 6| Step: 9
Training loss: 2.0677566528320312
Validation loss: 2.0691465408571306

Epoch: 6| Step: 10
Training loss: 2.0792996883392334
Validation loss: 2.0821542150230816

Epoch: 6| Step: 11
Training loss: 1.9327064752578735
Validation loss: 2.0669081877636653

Epoch: 6| Step: 12
Training loss: 1.3822758197784424
Validation loss: 2.0700027635020595

Epoch: 6| Step: 13
Training loss: 1.9468086957931519
Validation loss: 2.0619781786395657

Epoch: 342| Step: 0
Training loss: 1.3156472444534302
Validation loss: 2.125637456934939

Epoch: 6| Step: 1
Training loss: 1.7907918691635132
Validation loss: 2.0568615839045536

Epoch: 6| Step: 2
Training loss: 1.637160062789917
Validation loss: 2.0787192980448403

Epoch: 6| Step: 3
Training loss: 1.5430270433425903
Validation loss: 2.1138395237666305

Epoch: 6| Step: 4
Training loss: 2.125666618347168
Validation loss: 2.118913442857804

Epoch: 6| Step: 5
Training loss: 1.6488275527954102
Validation loss: 2.10877126519398

Epoch: 6| Step: 6
Training loss: 1.1743768453598022
Validation loss: 2.119135400300385

Epoch: 6| Step: 7
Training loss: 1.7427630424499512
Validation loss: 2.1290582379987164

Epoch: 6| Step: 8
Training loss: 1.8929082155227661
Validation loss: 2.103216504537931

Epoch: 6| Step: 9
Training loss: 1.2825056314468384
Validation loss: 2.1065927295274633

Epoch: 6| Step: 10
Training loss: 2.038370132446289
Validation loss: 2.0620294027431036

Epoch: 6| Step: 11
Training loss: 1.7667903900146484
Validation loss: 2.0990796614718694

Epoch: 6| Step: 12
Training loss: 1.6410243511199951
Validation loss: 2.0611289419153684

Epoch: 6| Step: 13
Training loss: 0.9788706302642822
Validation loss: 2.04437667323697

Epoch: 343| Step: 0
Training loss: 1.9029269218444824
Validation loss: 2.086094472997932

Epoch: 6| Step: 1
Training loss: 1.453493595123291
Validation loss: 2.0432917994837605

Epoch: 6| Step: 2
Training loss: 1.045416235923767
Validation loss: 2.0957343475792998

Epoch: 6| Step: 3
Training loss: 1.6981334686279297
Validation loss: 2.0147616555613856

Epoch: 6| Step: 4
Training loss: 1.7418190240859985
Validation loss: 2.0027781327565513

Epoch: 6| Step: 5
Training loss: 1.5317448377609253
Validation loss: 2.0449702508987917

Epoch: 6| Step: 6
Training loss: 1.515838623046875
Validation loss: 2.0908974293739564

Epoch: 6| Step: 7
Training loss: 1.5783522129058838
Validation loss: 2.0696669445242932

Epoch: 6| Step: 8
Training loss: 1.9491360187530518
Validation loss: 2.0224417255770777

Epoch: 6| Step: 9
Training loss: 1.5594115257263184
Validation loss: 2.0401668574220393

Epoch: 6| Step: 10
Training loss: 1.3304619789123535
Validation loss: 2.0236940383911133

Epoch: 6| Step: 11
Training loss: 1.8501331806182861
Validation loss: 2.0732916542278823

Epoch: 6| Step: 12
Training loss: 1.3268492221832275
Validation loss: 2.038833748909735

Epoch: 6| Step: 13
Training loss: 1.4855761528015137
Validation loss: 2.022008406218662

Epoch: 344| Step: 0
Training loss: 1.5364761352539062
Validation loss: 2.0507347481225127

Epoch: 6| Step: 1
Training loss: 1.488828182220459
Validation loss: 2.06733182168776

Epoch: 6| Step: 2
Training loss: 1.667480230331421
Validation loss: 2.053487826419133

Epoch: 6| Step: 3
Training loss: 2.5851070880889893
Validation loss: 2.038052720408286

Epoch: 6| Step: 4
Training loss: 1.6263377666473389
Validation loss: 2.049479571721887

Epoch: 6| Step: 5
Training loss: 1.1751022338867188
Validation loss: 2.0513212296270553

Epoch: 6| Step: 6
Training loss: 1.6259372234344482
Validation loss: 2.0728821498091503

Epoch: 6| Step: 7
Training loss: 1.5634748935699463
Validation loss: 2.05735763683114

Epoch: 6| Step: 8
Training loss: 1.4359169006347656
Validation loss: 2.0412967858775968

Epoch: 6| Step: 9
Training loss: 1.4168342351913452
Validation loss: 2.0989009898195983

Epoch: 6| Step: 10
Training loss: 1.7626768350601196
Validation loss: 2.0378612395255797

Epoch: 6| Step: 11
Training loss: 1.2516915798187256
Validation loss: 2.0760186718356226

Epoch: 6| Step: 12
Training loss: 1.811816930770874
Validation loss: 2.059673155507734

Epoch: 6| Step: 13
Training loss: 1.1434754133224487
Validation loss: 2.010307103075007

Epoch: 345| Step: 0
Training loss: 1.3301446437835693
Validation loss: 2.0701616348758822

Epoch: 6| Step: 1
Training loss: 1.4024780988693237
Validation loss: 2.0727254242025395

Epoch: 6| Step: 2
Training loss: 1.5700562000274658
Validation loss: 2.083151421239299

Epoch: 6| Step: 3
Training loss: 2.339430332183838
Validation loss: 2.0860698992206204

Epoch: 6| Step: 4
Training loss: 1.0418621301651
Validation loss: 2.0515466223480883

Epoch: 6| Step: 5
Training loss: 1.373591423034668
Validation loss: 2.071848289940947

Epoch: 6| Step: 6
Training loss: 1.89398193359375
Validation loss: 2.072075866883801

Epoch: 6| Step: 7
Training loss: 1.4349210262298584
Validation loss: 2.0746293055113925

Epoch: 6| Step: 8
Training loss: 1.3444581031799316
Validation loss: 2.1270165263965564

Epoch: 6| Step: 9
Training loss: 1.2038817405700684
Validation loss: 2.0679397788099063

Epoch: 6| Step: 10
Training loss: 1.775773286819458
Validation loss: 2.0770723460822977

Epoch: 6| Step: 11
Training loss: 1.831586480140686
Validation loss: 2.1040122227002214

Epoch: 6| Step: 12
Training loss: 2.300746440887451
Validation loss: 2.075632269664477

Epoch: 6| Step: 13
Training loss: 1.485400915145874
Validation loss: 2.07140019888519

Epoch: 346| Step: 0
Training loss: 0.8316075801849365
Validation loss: 2.0408670197251024

Epoch: 6| Step: 1
Training loss: 2.058865785598755
Validation loss: 2.0864677006198513

Epoch: 6| Step: 2
Training loss: 1.6907954216003418
Validation loss: 2.0553769603852303

Epoch: 6| Step: 3
Training loss: 2.516024351119995
Validation loss: 2.0691575619482223

Epoch: 6| Step: 4
Training loss: 2.0043835639953613
Validation loss: 2.0395297286331013

Epoch: 6| Step: 5
Training loss: 1.6616125106811523
Validation loss: 2.0792406899954683

Epoch: 6| Step: 6
Training loss: 1.4050157070159912
Validation loss: 2.0731516448400353

Epoch: 6| Step: 7
Training loss: 0.9063698053359985
Validation loss: 2.0472943141896236

Epoch: 6| Step: 8
Training loss: 1.5692775249481201
Validation loss: 2.0587297716448383

Epoch: 6| Step: 9
Training loss: 1.4378687143325806
Validation loss: 2.0972843939258206

Epoch: 6| Step: 10
Training loss: 2.219486713409424
Validation loss: 2.0291069041016283

Epoch: 6| Step: 11
Training loss: 1.492989420890808
Validation loss: 2.08882486948403

Epoch: 6| Step: 12
Training loss: 1.4292736053466797
Validation loss: 2.064589176126706

Epoch: 6| Step: 13
Training loss: 0.9126644134521484
Validation loss: 2.063097737168753

Epoch: 347| Step: 0
Training loss: 1.2338035106658936
Validation loss: 2.054616250017638

Epoch: 6| Step: 1
Training loss: 1.769802212715149
Validation loss: 2.0771589984175978

Epoch: 6| Step: 2
Training loss: 1.3648430109024048
Validation loss: 2.0519247542145433

Epoch: 6| Step: 3
Training loss: 1.606416940689087
Validation loss: 2.0562697328546995

Epoch: 6| Step: 4
Training loss: 1.345173954963684
Validation loss: 2.0579904407583256

Epoch: 6| Step: 5
Training loss: 1.4798760414123535
Validation loss: 2.064158711382138

Epoch: 6| Step: 6
Training loss: 1.5960813760757446
Validation loss: 2.058162473863171

Epoch: 6| Step: 7
Training loss: 2.045651435852051
Validation loss: 2.046661094952655

Epoch: 6| Step: 8
Training loss: 1.584578037261963
Validation loss: 2.0538673041969218

Epoch: 6| Step: 9
Training loss: 1.0470564365386963
Validation loss: 2.0577379811194634

Epoch: 6| Step: 10
Training loss: 1.9124836921691895
Validation loss: 2.066916105567768

Epoch: 6| Step: 11
Training loss: 1.7984769344329834
Validation loss: 2.053913372819142

Epoch: 6| Step: 12
Training loss: 1.801283359527588
Validation loss: 2.082707933200303

Epoch: 6| Step: 13
Training loss: 2.170346260070801
Validation loss: 2.0485841125570317

Epoch: 348| Step: 0
Training loss: 1.7875388860702515
Validation loss: 2.023729255122523

Epoch: 6| Step: 1
Training loss: 1.361131191253662
Validation loss: 2.105403031072309

Epoch: 6| Step: 2
Training loss: 1.5070085525512695
Validation loss: 2.043912882445961

Epoch: 6| Step: 3
Training loss: 1.5413057804107666
Validation loss: 2.053293207640289

Epoch: 6| Step: 4
Training loss: 2.0506691932678223
Validation loss: 2.0742096439484627

Epoch: 6| Step: 5
Training loss: 1.6257808208465576
Validation loss: 2.0725297427946523

Epoch: 6| Step: 6
Training loss: 1.5101165771484375
Validation loss: 2.0605801254190426

Epoch: 6| Step: 7
Training loss: 1.1008998155593872
Validation loss: 2.083449617508919

Epoch: 6| Step: 8
Training loss: 1.7693558931350708
Validation loss: 2.0840580694137083

Epoch: 6| Step: 9
Training loss: 1.6290404796600342
Validation loss: 2.019902693328037

Epoch: 6| Step: 10
Training loss: 2.2317094802856445
Validation loss: 2.064827803642519

Epoch: 6| Step: 11
Training loss: 1.2560453414916992
Validation loss: 2.0396440977691324

Epoch: 6| Step: 12
Training loss: 1.2955801486968994
Validation loss: 2.0585439679443196

Epoch: 6| Step: 13
Training loss: 1.53677499294281
Validation loss: 2.04938107152139

Epoch: 349| Step: 0
Training loss: 2.1846821308135986
Validation loss: 2.0510434489096365

Epoch: 6| Step: 1
Training loss: 1.1625936031341553
Validation loss: 2.0422136142689693

Epoch: 6| Step: 2
Training loss: 1.8407479524612427
Validation loss: 2.0526822561858804

Epoch: 6| Step: 3
Training loss: 1.4209359884262085
Validation loss: 2.0255971852169243

Epoch: 6| Step: 4
Training loss: 1.2264292240142822
Validation loss: 2.0271647399471653

Epoch: 6| Step: 5
Training loss: 1.9912300109863281
Validation loss: 2.015712299654561

Epoch: 6| Step: 6
Training loss: 1.4905076026916504
Validation loss: 2.0529859155736943

Epoch: 6| Step: 7
Training loss: 1.6425716876983643
Validation loss: 2.076652241009538

Epoch: 6| Step: 8
Training loss: 1.6566336154937744
Validation loss: 2.067473570505778

Epoch: 6| Step: 9
Training loss: 1.158028483390808
Validation loss: 2.054875671222646

Epoch: 6| Step: 10
Training loss: 0.996566653251648
Validation loss: 2.063010927169554

Epoch: 6| Step: 11
Training loss: 1.7811118364334106
Validation loss: 2.0534926601635513

Epoch: 6| Step: 12
Training loss: 2.071084976196289
Validation loss: 2.073917741416603

Epoch: 6| Step: 13
Training loss: 1.4333866834640503
Validation loss: 2.043506596678047

Epoch: 350| Step: 0
Training loss: 1.6060763597488403
Validation loss: 2.086910864358307

Epoch: 6| Step: 1
Training loss: 1.6164902448654175
Validation loss: 2.0547081398707565

Epoch: 6| Step: 2
Training loss: 1.5056695938110352
Validation loss: 2.046984230318377

Epoch: 6| Step: 3
Training loss: 1.4156508445739746
Validation loss: 2.0571192823430544

Epoch: 6| Step: 4
Training loss: 1.256610631942749
Validation loss: 2.0397198892408803

Epoch: 6| Step: 5
Training loss: 1.4586379528045654
Validation loss: 2.0437912428250877

Epoch: 6| Step: 6
Training loss: 1.558147668838501
Validation loss: 2.0513897275411956

Epoch: 6| Step: 7
Training loss: 1.6227734088897705
Validation loss: 2.053790456505232

Epoch: 6| Step: 8
Training loss: 1.1050373315811157
Validation loss: 2.044756725270261

Epoch: 6| Step: 9
Training loss: 1.5376169681549072
Validation loss: 2.0174166438400105

Epoch: 6| Step: 10
Training loss: 1.9479620456695557
Validation loss: 2.0017318520494687

Epoch: 6| Step: 11
Training loss: 2.058373212814331
Validation loss: 2.046788056691488

Epoch: 6| Step: 12
Training loss: 1.737584114074707
Validation loss: 2.05842988721786

Epoch: 6| Step: 13
Training loss: 1.8854700326919556
Validation loss: 2.056662667182184

Epoch: 351| Step: 0
Training loss: 1.4716049432754517
Validation loss: 2.042445485309888

Epoch: 6| Step: 1
Training loss: 1.6608375310897827
Validation loss: 2.057045296956134

Epoch: 6| Step: 2
Training loss: 1.763791799545288
Validation loss: 2.0649902333495436

Epoch: 6| Step: 3
Training loss: 1.4172096252441406
Validation loss: 2.0869599516673754

Epoch: 6| Step: 4
Training loss: 1.7445549964904785
Validation loss: 2.043621752851753

Epoch: 6| Step: 5
Training loss: 1.4764795303344727
Validation loss: 2.057792621274148

Epoch: 6| Step: 6
Training loss: 1.7560735940933228
Validation loss: 2.0453130058062974

Epoch: 6| Step: 7
Training loss: 1.4083714485168457
Validation loss: 2.069771598744136

Epoch: 6| Step: 8
Training loss: 1.3781490325927734
Validation loss: 2.083448968907838

Epoch: 6| Step: 9
Training loss: 1.663098692893982
Validation loss: 2.078112999598185

Epoch: 6| Step: 10
Training loss: 1.116868019104004
Validation loss: 2.058856600074358

Epoch: 6| Step: 11
Training loss: 2.529585838317871
Validation loss: 2.0697972159231863

Epoch: 6| Step: 12
Training loss: 0.9434510469436646
Validation loss: 2.040903816940964

Epoch: 6| Step: 13
Training loss: 1.2961856126785278
Validation loss: 2.0665158853735974

Epoch: 352| Step: 0
Training loss: 1.0762369632720947
Validation loss: 2.0157421429951987

Epoch: 6| Step: 1
Training loss: 0.9290922284126282
Validation loss: 2.0674566658594276

Epoch: 6| Step: 2
Training loss: 1.410056710243225
Validation loss: 2.0506675038286435

Epoch: 6| Step: 3
Training loss: 1.6403990983963013
Validation loss: 2.0627980821876117

Epoch: 6| Step: 4
Training loss: 1.5731350183486938
Validation loss: 2.054422527231196

Epoch: 6| Step: 5
Training loss: 1.5869040489196777
Validation loss: 2.043591514710457

Epoch: 6| Step: 6
Training loss: 1.4431284666061401
Validation loss: 2.0482683207399104

Epoch: 6| Step: 7
Training loss: 1.611979365348816
Validation loss: 2.020286848468165

Epoch: 6| Step: 8
Training loss: 2.129730463027954
Validation loss: 2.04365373170504

Epoch: 6| Step: 9
Training loss: 1.4736751317977905
Validation loss: 2.0172561368634625

Epoch: 6| Step: 10
Training loss: 1.2570600509643555
Validation loss: 2.032295289859977

Epoch: 6| Step: 11
Training loss: 1.810290813446045
Validation loss: 2.0530884445354505

Epoch: 6| Step: 12
Training loss: 2.254034996032715
Validation loss: 2.061313752205141

Epoch: 6| Step: 13
Training loss: 1.9899334907531738
Validation loss: 2.0548227717799525

Epoch: 353| Step: 0
Training loss: 2.2239270210266113
Validation loss: 2.043104894699589

Epoch: 6| Step: 1
Training loss: 1.2917248010635376
Validation loss: 2.044054287736134

Epoch: 6| Step: 2
Training loss: 1.554564356803894
Validation loss: 2.0461339155832925

Epoch: 6| Step: 3
Training loss: 1.31925368309021
Validation loss: 2.0638704966473322

Epoch: 6| Step: 4
Training loss: 1.8082988262176514
Validation loss: 2.055474558184224

Epoch: 6| Step: 5
Training loss: 1.6754302978515625
Validation loss: 2.071611809474166

Epoch: 6| Step: 6
Training loss: 2.00091290473938
Validation loss: 2.044017058546825

Epoch: 6| Step: 7
Training loss: 1.248819351196289
Validation loss: 2.06913935881789

Epoch: 6| Step: 8
Training loss: 1.809577465057373
Validation loss: 1.9986529863008888

Epoch: 6| Step: 9
Training loss: 1.5166785717010498
Validation loss: 2.0609888799728884

Epoch: 6| Step: 10
Training loss: 1.3168540000915527
Validation loss: 2.0416111971742366

Epoch: 6| Step: 11
Training loss: 1.309844732284546
Validation loss: 2.0344570144530265

Epoch: 6| Step: 12
Training loss: 1.2703275680541992
Validation loss: 2.0603614699456

Epoch: 6| Step: 13
Training loss: 1.6323113441467285
Validation loss: 2.0961298276019353

Epoch: 354| Step: 0
Training loss: 1.711609125137329
Validation loss: 2.047201874435589

Epoch: 6| Step: 1
Training loss: 1.7687042951583862
Validation loss: 2.0545095192488803

Epoch: 6| Step: 2
Training loss: 0.7904626131057739
Validation loss: 2.0193547510331675

Epoch: 6| Step: 3
Training loss: 1.8964426517486572
Validation loss: 2.047374709959953

Epoch: 6| Step: 4
Training loss: 1.8393163681030273
Validation loss: 2.0562060956032044

Epoch: 6| Step: 5
Training loss: 1.2487714290618896
Validation loss: 2.0469934965974543

Epoch: 6| Step: 6
Training loss: 1.966697096824646
Validation loss: 2.025058073382224

Epoch: 6| Step: 7
Training loss: 1.1255805492401123
Validation loss: 2.061587593888724

Epoch: 6| Step: 8
Training loss: 1.7964580059051514
Validation loss: 2.0553306994899625

Epoch: 6| Step: 9
Training loss: 1.0093767642974854
Validation loss: 2.0292399314142044

Epoch: 6| Step: 10
Training loss: 2.0763769149780273
Validation loss: 2.074649591599741

Epoch: 6| Step: 11
Training loss: 1.0816394090652466
Validation loss: 2.0433629071840675

Epoch: 6| Step: 12
Training loss: 2.022066116333008
Validation loss: 2.043755381338058

Epoch: 6| Step: 13
Training loss: 2.8193743228912354
Validation loss: 2.0158675152768373

Epoch: 355| Step: 0
Training loss: 1.1389423608779907
Validation loss: 2.079652417090631

Epoch: 6| Step: 1
Training loss: 1.2532050609588623
Validation loss: 2.0447608655498875

Epoch: 6| Step: 2
Training loss: 2.143367290496826
Validation loss: 2.034272583582068

Epoch: 6| Step: 3
Training loss: 1.5015873908996582
Validation loss: 2.072340960143715

Epoch: 6| Step: 4
Training loss: 1.7332698106765747
Validation loss: 2.052275816599528

Epoch: 6| Step: 5
Training loss: 1.9347047805786133
Validation loss: 2.1257509928877636

Epoch: 6| Step: 6
Training loss: 1.3061586618423462
Validation loss: 2.1024741677827734

Epoch: 6| Step: 7
Training loss: 1.541135311126709
Validation loss: 2.0820653912841633

Epoch: 6| Step: 8
Training loss: 1.6524630784988403
Validation loss: 2.0590609478694137

Epoch: 6| Step: 9
Training loss: 1.9178415536880493
Validation loss: 2.0654913738209713

Epoch: 6| Step: 10
Training loss: 1.383012056350708
Validation loss: 2.040061358482607

Epoch: 6| Step: 11
Training loss: 1.4270880222320557
Validation loss: 2.070523060778136

Epoch: 6| Step: 12
Training loss: 1.6596894264221191
Validation loss: 2.058317447221407

Epoch: 6| Step: 13
Training loss: 1.346284031867981
Validation loss: 2.04845784043753

Epoch: 356| Step: 0
Training loss: 1.7013862133026123
Validation loss: 2.058463256846192

Epoch: 6| Step: 1
Training loss: 1.25589919090271
Validation loss: 2.0512159178333897

Epoch: 6| Step: 2
Training loss: 1.0020067691802979
Validation loss: 2.046408886550575

Epoch: 6| Step: 3
Training loss: 1.532038688659668
Validation loss: 2.0526266597932383

Epoch: 6| Step: 4
Training loss: 1.8750433921813965
Validation loss: 2.0587670597978818

Epoch: 6| Step: 5
Training loss: 1.3013273477554321
Validation loss: 2.0179155847077728

Epoch: 6| Step: 6
Training loss: 1.608412504196167
Validation loss: 2.070083051599482

Epoch: 6| Step: 7
Training loss: 1.5309908390045166
Validation loss: 2.1110467680038942

Epoch: 6| Step: 8
Training loss: 1.869625210762024
Validation loss: 2.0382788591487433

Epoch: 6| Step: 9
Training loss: 2.260371208190918
Validation loss: 2.0809826645799863

Epoch: 6| Step: 10
Training loss: 1.7512905597686768
Validation loss: 2.0388875058902207

Epoch: 6| Step: 11
Training loss: 1.0370651483535767
Validation loss: 2.018451095909201

Epoch: 6| Step: 12
Training loss: 1.1666591167449951
Validation loss: 2.077787204455304

Epoch: 6| Step: 13
Training loss: 2.3515501022338867
Validation loss: 2.0446184835126324

Epoch: 357| Step: 0
Training loss: 1.2857754230499268
Validation loss: 2.037296527175493

Epoch: 6| Step: 1
Training loss: 1.1677134037017822
Validation loss: 2.097817349177535

Epoch: 6| Step: 2
Training loss: 1.8389918804168701
Validation loss: 2.0666605785328853

Epoch: 6| Step: 3
Training loss: 2.27846097946167
Validation loss: 2.061195650408345

Epoch: 6| Step: 4
Training loss: 2.2210144996643066
Validation loss: 2.0520275446676437

Epoch: 6| Step: 5
Training loss: 1.6077172756195068
Validation loss: 2.0172017902456303

Epoch: 6| Step: 6
Training loss: 1.7866876125335693
Validation loss: 2.071303798306373

Epoch: 6| Step: 7
Training loss: 1.3759639263153076
Validation loss: 2.029413004075327

Epoch: 6| Step: 8
Training loss: 1.1482579708099365
Validation loss: 2.0220497987603627

Epoch: 6| Step: 9
Training loss: 1.2577017545700073
Validation loss: 2.0385894608753983

Epoch: 6| Step: 10
Training loss: 1.922253131866455
Validation loss: 2.086471778090282

Epoch: 6| Step: 11
Training loss: 1.13637375831604
Validation loss: 2.0198128402874036

Epoch: 6| Step: 12
Training loss: 1.304740071296692
Validation loss: 2.0422799702613585

Epoch: 6| Step: 13
Training loss: 1.6419132947921753
Validation loss: 2.040525536383352

Epoch: 358| Step: 0
Training loss: 1.527482509613037
Validation loss: 2.0441584484551543

Epoch: 6| Step: 1
Training loss: 1.7537662982940674
Validation loss: 2.0482481884699997

Epoch: 6| Step: 2
Training loss: 1.7156531810760498
Validation loss: 2.0691958524847545

Epoch: 6| Step: 3
Training loss: 1.1282190084457397
Validation loss: 2.0652383963267007

Epoch: 6| Step: 4
Training loss: 1.3944146633148193
Validation loss: 2.0892406996860298

Epoch: 6| Step: 5
Training loss: 2.218081474304199
Validation loss: 2.0760803325201875

Epoch: 6| Step: 6
Training loss: 1.1595102548599243
Validation loss: 2.0556035182809316

Epoch: 6| Step: 7
Training loss: 1.2053769826889038
Validation loss: 2.0493597189585366

Epoch: 6| Step: 8
Training loss: 1.5870156288146973
Validation loss: 2.091282149796845

Epoch: 6| Step: 9
Training loss: 1.9164941310882568
Validation loss: 2.0574612335492204

Epoch: 6| Step: 10
Training loss: 1.5246877670288086
Validation loss: 2.0627843667102117

Epoch: 6| Step: 11
Training loss: 1.852728009223938
Validation loss: 2.0521553998352378

Epoch: 6| Step: 12
Training loss: 1.6972969770431519
Validation loss: 2.0539604668976157

Epoch: 6| Step: 13
Training loss: 1.857862949371338
Validation loss: 2.0422230228301017

Epoch: 359| Step: 0
Training loss: 1.4390918016433716
Validation loss: 2.045484309555382

Epoch: 6| Step: 1
Training loss: 1.4020107984542847
Validation loss: 1.9810677843709146

Epoch: 6| Step: 2
Training loss: 1.8922245502471924
Validation loss: 2.034762195361558

Epoch: 6| Step: 3
Training loss: 1.8106756210327148
Validation loss: 2.0786256636342695

Epoch: 6| Step: 4
Training loss: 1.3564412593841553
Validation loss: 2.0445561485905803

Epoch: 6| Step: 5
Training loss: 1.3383108377456665
Validation loss: 2.064550433107602

Epoch: 6| Step: 6
Training loss: 1.6349204778671265
Validation loss: 2.021311133138595

Epoch: 6| Step: 7
Training loss: 1.7379814386367798
Validation loss: 2.043212197160208

Epoch: 6| Step: 8
Training loss: 1.2208991050720215
Validation loss: 2.078712660779235

Epoch: 6| Step: 9
Training loss: 1.3803904056549072
Validation loss: 2.0579037127956266

Epoch: 6| Step: 10
Training loss: 1.982858419418335
Validation loss: 2.013652173421716

Epoch: 6| Step: 11
Training loss: 1.3944125175476074
Validation loss: 2.049130952486428

Epoch: 6| Step: 12
Training loss: 1.7525050640106201
Validation loss: 2.0251793681934314

Epoch: 6| Step: 13
Training loss: 1.9274622201919556
Validation loss: 2.0591058859261135

Epoch: 360| Step: 0
Training loss: 1.7331595420837402
Validation loss: 2.044887335069718

Epoch: 6| Step: 1
Training loss: 2.055208683013916
Validation loss: 2.0349289486485143

Epoch: 6| Step: 2
Training loss: 1.7306969165802002
Validation loss: 2.023124235932545

Epoch: 6| Step: 3
Training loss: 1.55001962184906
Validation loss: 2.030763646607758

Epoch: 6| Step: 4
Training loss: 1.4483641386032104
Validation loss: 2.0135536232302265

Epoch: 6| Step: 5
Training loss: 1.678470492362976
Validation loss: 2.030743911702146

Epoch: 6| Step: 6
Training loss: 1.5741876363754272
Validation loss: 2.064058308960289

Epoch: 6| Step: 7
Training loss: 1.6113901138305664
Validation loss: 2.0345231281813754

Epoch: 6| Step: 8
Training loss: 0.9951419234275818
Validation loss: 2.059501753058485

Epoch: 6| Step: 9
Training loss: 1.392416000366211
Validation loss: 2.0469937478342364

Epoch: 6| Step: 10
Training loss: 1.4530789852142334
Validation loss: 2.0024517018307924

Epoch: 6| Step: 11
Training loss: 1.6488850116729736
Validation loss: 2.063269998437615

Epoch: 6| Step: 12
Training loss: 1.4454920291900635
Validation loss: 2.031044452421127

Epoch: 6| Step: 13
Training loss: 1.513610601425171
Validation loss: 2.101127398911343

Epoch: 361| Step: 0
Training loss: 1.5566048622131348
Validation loss: 2.0750523600527035

Epoch: 6| Step: 1
Training loss: 2.011760950088501
Validation loss: 2.0533608492984565

Epoch: 6| Step: 2
Training loss: 1.908605933189392
Validation loss: 2.0528039804068943

Epoch: 6| Step: 3
Training loss: 1.3045477867126465
Validation loss: 2.075024502251738

Epoch: 6| Step: 4
Training loss: 1.63299560546875
Validation loss: 2.026596492336642

Epoch: 6| Step: 5
Training loss: 1.3903217315673828
Validation loss: 2.0546615790295344

Epoch: 6| Step: 6
Training loss: 1.2080857753753662
Validation loss: 2.021948081190868

Epoch: 6| Step: 7
Training loss: 1.8519024848937988
Validation loss: 2.0598194291514735

Epoch: 6| Step: 8
Training loss: 1.6281006336212158
Validation loss: 2.05840737588944

Epoch: 6| Step: 9
Training loss: 1.389678955078125
Validation loss: 2.0339427455779044

Epoch: 6| Step: 10
Training loss: 2.0664191246032715
Validation loss: 2.0368970773553334

Epoch: 6| Step: 11
Training loss: 1.4694937467575073
Validation loss: 2.0521019658734723

Epoch: 6| Step: 12
Training loss: 1.2691962718963623
Validation loss: 2.05023515993549

Epoch: 6| Step: 13
Training loss: 0.7699061632156372
Validation loss: 2.043835013143478

Epoch: 362| Step: 0
Training loss: 1.6232092380523682
Validation loss: 2.046090196537715

Epoch: 6| Step: 1
Training loss: 1.4489060640335083
Validation loss: 2.07778335643071

Epoch: 6| Step: 2
Training loss: 1.776054859161377
Validation loss: 2.073191422288136

Epoch: 6| Step: 3
Training loss: 1.3475041389465332
Validation loss: 2.0811325709025064

Epoch: 6| Step: 4
Training loss: 1.5496103763580322
Validation loss: 2.0326908583282144

Epoch: 6| Step: 5
Training loss: 1.46071195602417
Validation loss: 2.0105788182186823

Epoch: 6| Step: 6
Training loss: 1.7201286554336548
Validation loss: 2.0732579949081584

Epoch: 6| Step: 7
Training loss: 1.1992011070251465
Validation loss: 2.0354329642429145

Epoch: 6| Step: 8
Training loss: 2.118185520172119
Validation loss: 2.082922427884994

Epoch: 6| Step: 9
Training loss: 1.3152129650115967
Validation loss: 2.060616518861504

Epoch: 6| Step: 10
Training loss: 1.6580849885940552
Validation loss: 2.0809845129648843

Epoch: 6| Step: 11
Training loss: 1.458261251449585
Validation loss: 2.0390532068026963

Epoch: 6| Step: 12
Training loss: 1.5840357542037964
Validation loss: 2.0615928967793784

Epoch: 6| Step: 13
Training loss: 1.3404513597488403
Validation loss: 2.0520945569520355

Epoch: 363| Step: 0
Training loss: 1.1145802736282349
Validation loss: 2.03474098379894

Epoch: 6| Step: 1
Training loss: 1.4326399564743042
Validation loss: 2.0844934858301634

Epoch: 6| Step: 2
Training loss: 1.2930691242218018
Validation loss: 2.0164571244229554

Epoch: 6| Step: 3
Training loss: 1.0867919921875
Validation loss: 2.077264001292567

Epoch: 6| Step: 4
Training loss: 1.6068087816238403
Validation loss: 2.06252545438787

Epoch: 6| Step: 5
Training loss: 1.4339091777801514
Validation loss: 2.0557508289173083

Epoch: 6| Step: 6
Training loss: 1.6426736116409302
Validation loss: 2.1157428013381137

Epoch: 6| Step: 7
Training loss: 1.602557897567749
Validation loss: 2.055634429377894

Epoch: 6| Step: 8
Training loss: 1.7694718837738037
Validation loss: 2.0453371655556465

Epoch: 6| Step: 9
Training loss: 1.6697593927383423
Validation loss: 2.0684795110456404

Epoch: 6| Step: 10
Training loss: 1.375629186630249
Validation loss: 2.0989102868623633

Epoch: 6| Step: 11
Training loss: 1.8981857299804688
Validation loss: 2.0596255256283666

Epoch: 6| Step: 12
Training loss: 2.0623466968536377
Validation loss: 2.0728653656539096

Epoch: 6| Step: 13
Training loss: 2.288195848464966
Validation loss: 2.0557608501885527

Epoch: 364| Step: 0
Training loss: 1.1663525104522705
Validation loss: 2.0233456357832877

Epoch: 6| Step: 1
Training loss: 1.3902854919433594
Validation loss: 2.054802078072743

Epoch: 6| Step: 2
Training loss: 1.2089295387268066
Validation loss: 2.044472422651065

Epoch: 6| Step: 3
Training loss: 2.209582805633545
Validation loss: 2.0754771617151078

Epoch: 6| Step: 4
Training loss: 1.5026739835739136
Validation loss: 2.04188814983573

Epoch: 6| Step: 5
Training loss: 1.6000831127166748
Validation loss: 2.0387261298394974

Epoch: 6| Step: 6
Training loss: 2.1754589080810547
Validation loss: 2.0418296655019126

Epoch: 6| Step: 7
Training loss: 1.3995566368103027
Validation loss: 2.055282062099826

Epoch: 6| Step: 8
Training loss: 1.751300573348999
Validation loss: 2.072802169348604

Epoch: 6| Step: 9
Training loss: 1.4027926921844482
Validation loss: 2.0376407292581376

Epoch: 6| Step: 10
Training loss: 2.0511343479156494
Validation loss: 2.0103084938500517

Epoch: 6| Step: 11
Training loss: 1.9799151420593262
Validation loss: 2.0429318156293643

Epoch: 6| Step: 12
Training loss: 0.886028528213501
Validation loss: 2.0301713892208633

Epoch: 6| Step: 13
Training loss: 0.46614325046539307
Validation loss: 2.050999487600019

Epoch: 365| Step: 0
Training loss: 2.2327208518981934
Validation loss: 2.0337608655293784

Epoch: 6| Step: 1
Training loss: 1.5316450595855713
Validation loss: 2.05363937347166

Epoch: 6| Step: 2
Training loss: 0.7786699533462524
Validation loss: 2.0454788156735

Epoch: 6| Step: 3
Training loss: 1.833014726638794
Validation loss: 2.0415197175036193

Epoch: 6| Step: 4
Training loss: 1.125022530555725
Validation loss: 2.0232153195206837

Epoch: 6| Step: 5
Training loss: 1.3190648555755615
Validation loss: 2.024204597678236

Epoch: 6| Step: 6
Training loss: 1.8123629093170166
Validation loss: 2.065908544807024

Epoch: 6| Step: 7
Training loss: 1.369720697402954
Validation loss: 2.089862641467843

Epoch: 6| Step: 8
Training loss: 1.6543773412704468
Validation loss: 2.0741687410621235

Epoch: 6| Step: 9
Training loss: 1.5758596658706665
Validation loss: 2.0518170825896727

Epoch: 6| Step: 10
Training loss: 1.721734881401062
Validation loss: 2.084761268349104

Epoch: 6| Step: 11
Training loss: 1.8926753997802734
Validation loss: 2.02011187102205

Epoch: 6| Step: 12
Training loss: 1.1842553615570068
Validation loss: 2.027309884307205

Epoch: 6| Step: 13
Training loss: 2.0448899269104004
Validation loss: 2.0578343893892024

Epoch: 366| Step: 0
Training loss: 1.6015855073928833
Validation loss: 2.1018280829152753

Epoch: 6| Step: 1
Training loss: 1.8451036214828491
Validation loss: 2.063128479065434

Epoch: 6| Step: 2
Training loss: 1.415649175643921
Validation loss: 2.0396718568699335

Epoch: 6| Step: 3
Training loss: 2.2034435272216797
Validation loss: 2.0725361980417722

Epoch: 6| Step: 4
Training loss: 0.9413789510726929
Validation loss: 2.09631246905173

Epoch: 6| Step: 5
Training loss: 2.0330755710601807
Validation loss: 2.0409099337875203

Epoch: 6| Step: 6
Training loss: 1.1098051071166992
Validation loss: 2.0763946117893344

Epoch: 6| Step: 7
Training loss: 1.8786425590515137
Validation loss: 2.045163490438974

Epoch: 6| Step: 8
Training loss: 1.0216948986053467
Validation loss: 2.061039806694113

Epoch: 6| Step: 9
Training loss: 1.6004095077514648
Validation loss: 2.071614078296128

Epoch: 6| Step: 10
Training loss: 1.243805170059204
Validation loss: 2.0767302538758967

Epoch: 6| Step: 11
Training loss: 1.6092272996902466
Validation loss: 2.0487653004225863

Epoch: 6| Step: 12
Training loss: 1.5773673057556152
Validation loss: 2.0566270761592413

Epoch: 6| Step: 13
Training loss: 1.7328195571899414
Validation loss: 2.037318937240108

Epoch: 367| Step: 0
Training loss: 2.317477226257324
Validation loss: 2.0452036729422947

Epoch: 6| Step: 1
Training loss: 1.1557297706604004
Validation loss: 2.033023411227811

Epoch: 6| Step: 2
Training loss: 1.5345350503921509
Validation loss: 2.0590303123638196

Epoch: 6| Step: 3
Training loss: 2.143343925476074
Validation loss: 2.0489041010538735

Epoch: 6| Step: 4
Training loss: 1.548133134841919
Validation loss: 2.060855571941663

Epoch: 6| Step: 5
Training loss: 1.5742988586425781
Validation loss: 2.06692777141448

Epoch: 6| Step: 6
Training loss: 1.0550050735473633
Validation loss: 2.0650482741735314

Epoch: 6| Step: 7
Training loss: 1.150098204612732
Validation loss: 2.0694307358034196

Epoch: 6| Step: 8
Training loss: 1.3671965599060059
Validation loss: 2.07556297573992

Epoch: 6| Step: 9
Training loss: 1.7182257175445557
Validation loss: 2.0462979834566832

Epoch: 6| Step: 10
Training loss: 1.725243091583252
Validation loss: 2.0731980467355378

Epoch: 6| Step: 11
Training loss: 1.3545804023742676
Validation loss: 2.0279466823865007

Epoch: 6| Step: 12
Training loss: 1.917487382888794
Validation loss: 2.0602707862854004

Epoch: 6| Step: 13
Training loss: 1.9306589365005493
Validation loss: 2.056263772390222

Epoch: 368| Step: 0
Training loss: 1.003304123878479
Validation loss: 2.052005854986047

Epoch: 6| Step: 1
Training loss: 1.5374292135238647
Validation loss: 2.048530142794373

Epoch: 6| Step: 2
Training loss: 1.8210375308990479
Validation loss: 2.0499723957430933

Epoch: 6| Step: 3
Training loss: 1.935105562210083
Validation loss: 2.0460604019062494

Epoch: 6| Step: 4
Training loss: 0.7048993110656738
Validation loss: 2.054864768059023

Epoch: 6| Step: 5
Training loss: 1.5887988805770874
Validation loss: 2.081519760111327

Epoch: 6| Step: 6
Training loss: 1.393301010131836
Validation loss: 2.0787181802975234

Epoch: 6| Step: 7
Training loss: 2.15425443649292
Validation loss: 2.110161622365316

Epoch: 6| Step: 8
Training loss: 0.8718327283859253
Validation loss: 2.048089176095942

Epoch: 6| Step: 9
Training loss: 1.832364559173584
Validation loss: 2.0380925593837613

Epoch: 6| Step: 10
Training loss: 1.164459466934204
Validation loss: 2.029948106376074

Epoch: 6| Step: 11
Training loss: 1.6508865356445312
Validation loss: 2.068668032205233

Epoch: 6| Step: 12
Training loss: 1.5902236700057983
Validation loss: 2.022255011784133

Epoch: 6| Step: 13
Training loss: 2.8197555541992188
Validation loss: 2.0375674232359855

Epoch: 369| Step: 0
Training loss: 1.838836431503296
Validation loss: 2.0799211020110757

Epoch: 6| Step: 1
Training loss: 1.0989303588867188
Validation loss: 2.0274762581753474

Epoch: 6| Step: 2
Training loss: 1.661476731300354
Validation loss: 2.02531224296939

Epoch: 6| Step: 3
Training loss: 1.4612829685211182
Validation loss: 2.028788771680606

Epoch: 6| Step: 4
Training loss: 1.1068997383117676
Validation loss: 2.103999512169951

Epoch: 6| Step: 5
Training loss: 1.5559717416763306
Validation loss: 2.0396006312421573

Epoch: 6| Step: 6
Training loss: 1.6698307991027832
Validation loss: 2.054795862526022

Epoch: 6| Step: 7
Training loss: 1.7307534217834473
Validation loss: 2.0210895333238827

Epoch: 6| Step: 8
Training loss: 1.3336485624313354
Validation loss: 2.0227038450138544

Epoch: 6| Step: 9
Training loss: 1.60762619972229
Validation loss: 2.0240051464367936

Epoch: 6| Step: 10
Training loss: 1.8220653533935547
Validation loss: 2.058109885902815

Epoch: 6| Step: 11
Training loss: 1.593335509300232
Validation loss: 2.004700811960364

Epoch: 6| Step: 12
Training loss: 1.33918297290802
Validation loss: 2.0337633586698964

Epoch: 6| Step: 13
Training loss: 1.5312978029251099
Validation loss: 2.06475596145917

Epoch: 370| Step: 0
Training loss: 1.3080317974090576
Validation loss: 2.009069122293944

Epoch: 6| Step: 1
Training loss: 1.7356175184249878
Validation loss: 2.0017160613049745

Epoch: 6| Step: 2
Training loss: 1.0623509883880615
Validation loss: 2.0199002706876366

Epoch: 6| Step: 3
Training loss: 1.2153418064117432
Validation loss: 2.015769959777914

Epoch: 6| Step: 4
Training loss: 1.8626832962036133
Validation loss: 2.0322690625344553

Epoch: 6| Step: 5
Training loss: 1.3506476879119873
Validation loss: 2.0466979677959154

Epoch: 6| Step: 6
Training loss: 1.6277987957000732
Validation loss: 2.0794951685013308

Epoch: 6| Step: 7
Training loss: 2.2076334953308105
Validation loss: 2.031898516480641

Epoch: 6| Step: 8
Training loss: 1.6249420642852783
Validation loss: 2.0548668471715783

Epoch: 6| Step: 9
Training loss: 1.7802327871322632
Validation loss: 2.0775447250694357

Epoch: 6| Step: 10
Training loss: 1.3616485595703125
Validation loss: 2.0294227113005934

Epoch: 6| Step: 11
Training loss: 1.11344313621521
Validation loss: 2.088581277478126

Epoch: 6| Step: 12
Training loss: 1.3786513805389404
Validation loss: 2.085342896881924

Epoch: 6| Step: 13
Training loss: 1.540550708770752
Validation loss: 2.0560588157305153

Epoch: 371| Step: 0
Training loss: 1.758457064628601
Validation loss: 2.0149671980129775

Epoch: 6| Step: 1
Training loss: 1.6007976531982422
Validation loss: 2.0058913256532405

Epoch: 6| Step: 2
Training loss: 1.4709502458572388
Validation loss: 2.046232449111118

Epoch: 6| Step: 3
Training loss: 1.542008876800537
Validation loss: 2.0351965094125397

Epoch: 6| Step: 4
Training loss: 1.5550955533981323
Validation loss: 2.030378915930307

Epoch: 6| Step: 5
Training loss: 1.2004445791244507
Validation loss: 2.0472559211074666

Epoch: 6| Step: 6
Training loss: 1.779739499092102
Validation loss: 1.9897177296300088

Epoch: 6| Step: 7
Training loss: 1.704849362373352
Validation loss: 2.017737643693083

Epoch: 6| Step: 8
Training loss: 1.1659040451049805
Validation loss: 2.0207855521991687

Epoch: 6| Step: 9
Training loss: 1.514699101448059
Validation loss: 2.0350158188932683

Epoch: 6| Step: 10
Training loss: 1.360074520111084
Validation loss: 2.0677893866774855

Epoch: 6| Step: 11
Training loss: 1.2411189079284668
Validation loss: 2.0722024415128972

Epoch: 6| Step: 12
Training loss: 1.9948043823242188
Validation loss: 2.061945028202508

Epoch: 6| Step: 13
Training loss: 1.479729175567627
Validation loss: 2.0717253556815525

Epoch: 372| Step: 0
Training loss: 1.9185336828231812
Validation loss: 2.0519485473632812

Epoch: 6| Step: 1
Training loss: 1.174731969833374
Validation loss: 2.056277267394527

Epoch: 6| Step: 2
Training loss: 1.181036114692688
Validation loss: 2.0723434545660533

Epoch: 6| Step: 3
Training loss: 1.4077129364013672
Validation loss: 2.0362414019082182

Epoch: 6| Step: 4
Training loss: 1.235880732536316
Validation loss: 2.069369544265091

Epoch: 6| Step: 5
Training loss: 2.104736804962158
Validation loss: 2.043036363458121

Epoch: 6| Step: 6
Training loss: 1.5069055557250977
Validation loss: 2.0523414880998674

Epoch: 6| Step: 7
Training loss: 0.9729714393615723
Validation loss: 2.1023720618217223

Epoch: 6| Step: 8
Training loss: 1.556326150894165
Validation loss: 2.0790743186909664

Epoch: 6| Step: 9
Training loss: 1.6759567260742188
Validation loss: 2.088231041867246

Epoch: 6| Step: 10
Training loss: 1.9682910442352295
Validation loss: 2.0650828346129386

Epoch: 6| Step: 11
Training loss: 1.4918193817138672
Validation loss: 2.0422468185424805

Epoch: 6| Step: 12
Training loss: 1.758779764175415
Validation loss: 2.0175260472041305

Epoch: 6| Step: 13
Training loss: 1.5460405349731445
Validation loss: 2.019625292029432

Epoch: 373| Step: 0
Training loss: 1.4887235164642334
Validation loss: 2.0239894261924167

Epoch: 6| Step: 1
Training loss: 1.6543066501617432
Validation loss: 2.021439849689443

Epoch: 6| Step: 2
Training loss: 0.8400766849517822
Validation loss: 2.05068084116905

Epoch: 6| Step: 3
Training loss: 1.6079158782958984
Validation loss: 2.064673412230707

Epoch: 6| Step: 4
Training loss: 1.3422372341156006
Validation loss: 2.0274595291383806

Epoch: 6| Step: 5
Training loss: 1.5983760356903076
Validation loss: 1.9939610394098426

Epoch: 6| Step: 6
Training loss: 2.3374693393707275
Validation loss: 2.050661030636039

Epoch: 6| Step: 7
Training loss: 1.7866336107254028
Validation loss: 2.0504627663602113

Epoch: 6| Step: 8
Training loss: 1.4603368043899536
Validation loss: 2.0103274942726217

Epoch: 6| Step: 9
Training loss: 1.4141440391540527
Validation loss: 2.012922895851956

Epoch: 6| Step: 10
Training loss: 1.8348438739776611
Validation loss: 2.0565001169840493

Epoch: 6| Step: 11
Training loss: 1.1763920783996582
Validation loss: 2.0473298975216445

Epoch: 6| Step: 12
Training loss: 1.4983758926391602
Validation loss: 2.0150986025410313

Epoch: 6| Step: 13
Training loss: 1.0921754837036133
Validation loss: 2.042418124855206

Epoch: 374| Step: 0
Training loss: 1.818157434463501
Validation loss: 2.021608398806664

Epoch: 6| Step: 1
Training loss: 1.0849342346191406
Validation loss: 2.0535670326602076

Epoch: 6| Step: 2
Training loss: 1.2970114946365356
Validation loss: 2.053091482449603

Epoch: 6| Step: 3
Training loss: 1.7124580144882202
Validation loss: 2.005331413720244

Epoch: 6| Step: 4
Training loss: 1.884947657585144
Validation loss: 2.0348315623498734

Epoch: 6| Step: 5
Training loss: 1.5073350667953491
Validation loss: 2.029592271774046

Epoch: 6| Step: 6
Training loss: 1.198861002922058
Validation loss: 2.0521519286658174

Epoch: 6| Step: 7
Training loss: 1.4041149616241455
Validation loss: 2.097097353268695

Epoch: 6| Step: 8
Training loss: 1.3592777252197266
Validation loss: 2.032338535913857

Epoch: 6| Step: 9
Training loss: 1.4632701873779297
Validation loss: 2.065560843354912

Epoch: 6| Step: 10
Training loss: 1.5005416870117188
Validation loss: 2.0980382196364866

Epoch: 6| Step: 11
Training loss: 2.240910053253174
Validation loss: 2.0153522645273516

Epoch: 6| Step: 12
Training loss: 1.3348840475082397
Validation loss: 2.0496040210928967

Epoch: 6| Step: 13
Training loss: 1.5468666553497314
Validation loss: 1.9838004240425684

Epoch: 375| Step: 0
Training loss: 1.5104308128356934
Validation loss: 2.0504620857136224

Epoch: 6| Step: 1
Training loss: 1.1417431831359863
Validation loss: 2.0045253692134732

Epoch: 6| Step: 2
Training loss: 1.664093255996704
Validation loss: 2.033247399073775

Epoch: 6| Step: 3
Training loss: 1.1913976669311523
Validation loss: 2.0544953884616977

Epoch: 6| Step: 4
Training loss: 1.4798632860183716
Validation loss: 1.9833448189561085

Epoch: 6| Step: 5
Training loss: 1.3344547748565674
Validation loss: 2.0180271774209957

Epoch: 6| Step: 6
Training loss: 1.3902873992919922
Validation loss: 2.0167607389470583

Epoch: 6| Step: 7
Training loss: 1.393111228942871
Validation loss: 2.014448727330854

Epoch: 6| Step: 8
Training loss: 1.4781616926193237
Validation loss: 2.0342535857231385

Epoch: 6| Step: 9
Training loss: 2.5843169689178467
Validation loss: 1.9977249227544314

Epoch: 6| Step: 10
Training loss: 1.5424617528915405
Validation loss: 2.0968616239486204

Epoch: 6| Step: 11
Training loss: 1.60926353931427
Validation loss: 2.0385409721764187

Epoch: 6| Step: 12
Training loss: 1.4833581447601318
Validation loss: 2.010662042966453

Epoch: 6| Step: 13
Training loss: 1.7053481340408325
Validation loss: 2.0260429843779533

Epoch: 376| Step: 0
Training loss: 1.7209491729736328
Validation loss: 2.0224548937172018

Epoch: 6| Step: 1
Training loss: 1.7654922008514404
Validation loss: 2.0721259437581545

Epoch: 6| Step: 2
Training loss: 1.1900006532669067
Validation loss: 2.05331862613719

Epoch: 6| Step: 3
Training loss: 1.8598730564117432
Validation loss: 2.065047399972075

Epoch: 6| Step: 4
Training loss: 1.2594349384307861
Validation loss: 2.0625153638983287

Epoch: 6| Step: 5
Training loss: 1.554871916770935
Validation loss: 2.100247501045145

Epoch: 6| Step: 6
Training loss: 1.2333428859710693
Validation loss: 2.092110187776627

Epoch: 6| Step: 7
Training loss: 1.7978324890136719
Validation loss: 2.0773997204278105

Epoch: 6| Step: 8
Training loss: 1.7552238702774048
Validation loss: 2.0708569993254957

Epoch: 6| Step: 9
Training loss: 1.3149394989013672
Validation loss: 2.0594566099105345

Epoch: 6| Step: 10
Training loss: 1.1679432392120361
Validation loss: 2.0708535371288175

Epoch: 6| Step: 11
Training loss: 1.4947280883789062
Validation loss: 2.083155847364856

Epoch: 6| Step: 12
Training loss: 1.712193250656128
Validation loss: 2.0374761525020806

Epoch: 6| Step: 13
Training loss: 2.526911497116089
Validation loss: 2.0513165304737706

Epoch: 377| Step: 0
Training loss: 1.6404917240142822
Validation loss: 2.019253376991518

Epoch: 6| Step: 1
Training loss: 1.69883394241333
Validation loss: 2.095103565082755

Epoch: 6| Step: 2
Training loss: 1.3439022302627563
Validation loss: 2.030729504041774

Epoch: 6| Step: 3
Training loss: 1.2146410942077637
Validation loss: 2.044119438817424

Epoch: 6| Step: 4
Training loss: 1.6784254312515259
Validation loss: 2.050573854036229

Epoch: 6| Step: 5
Training loss: 2.1625173091888428
Validation loss: 2.01535209532707

Epoch: 6| Step: 6
Training loss: 0.9049148559570312
Validation loss: 2.0276425987161617

Epoch: 6| Step: 7
Training loss: 1.290745496749878
Validation loss: 2.0413756857636156

Epoch: 6| Step: 8
Training loss: 1.241398572921753
Validation loss: 2.0459991373041624

Epoch: 6| Step: 9
Training loss: 1.98402738571167
Validation loss: 2.031477297506025

Epoch: 6| Step: 10
Training loss: 1.8195843696594238
Validation loss: 2.0148030519485474

Epoch: 6| Step: 11
Training loss: 1.0784268379211426
Validation loss: 2.019317860244423

Epoch: 6| Step: 12
Training loss: 1.6117686033248901
Validation loss: 2.0908224275035243

Epoch: 6| Step: 13
Training loss: 1.5212105512619019
Validation loss: 2.0197603933272825

Epoch: 378| Step: 0
Training loss: 1.3294340372085571
Validation loss: 2.0247959270272204

Epoch: 6| Step: 1
Training loss: 1.8916759490966797
Validation loss: 2.060242819529708

Epoch: 6| Step: 2
Training loss: 1.1067924499511719
Validation loss: 2.073076540423978

Epoch: 6| Step: 3
Training loss: 1.4022870063781738
Validation loss: 2.0532941177327144

Epoch: 6| Step: 4
Training loss: 1.6882100105285645
Validation loss: 2.0223386800417336

Epoch: 6| Step: 5
Training loss: 1.4744391441345215
Validation loss: 2.0045838099654003

Epoch: 6| Step: 6
Training loss: 1.908416748046875
Validation loss: 2.0345588704591155

Epoch: 6| Step: 7
Training loss: 1.139571189880371
Validation loss: 2.0736075780724965

Epoch: 6| Step: 8
Training loss: 1.9070188999176025
Validation loss: 2.0737412770589194

Epoch: 6| Step: 9
Training loss: 1.5976808071136475
Validation loss: 2.0528294476129676

Epoch: 6| Step: 10
Training loss: 1.6871315240859985
Validation loss: 2.0615875156976844

Epoch: 6| Step: 11
Training loss: 1.536938190460205
Validation loss: 1.993449608484904

Epoch: 6| Step: 12
Training loss: 1.158851146697998
Validation loss: 2.066542422899636

Epoch: 6| Step: 13
Training loss: 1.067479133605957
Validation loss: 2.0053785577897103

Epoch: 379| Step: 0
Training loss: 1.3437442779541016
Validation loss: 2.0642821481150966

Epoch: 6| Step: 1
Training loss: 1.7072371244430542
Validation loss: 2.017463618709195

Epoch: 6| Step: 2
Training loss: 1.461432933807373
Validation loss: 2.0324853568948726

Epoch: 6| Step: 3
Training loss: 1.548309564590454
Validation loss: 2.022508482779226

Epoch: 6| Step: 4
Training loss: 1.4549660682678223
Validation loss: 2.015485066239552

Epoch: 6| Step: 5
Training loss: 1.4450562000274658
Validation loss: 2.058417325378746

Epoch: 6| Step: 6
Training loss: 1.6538584232330322
Validation loss: 2.0010491660846177

Epoch: 6| Step: 7
Training loss: 1.170363187789917
Validation loss: 2.0286504017409457

Epoch: 6| Step: 8
Training loss: 1.5054984092712402
Validation loss: 2.0084231207447667

Epoch: 6| Step: 9
Training loss: 1.6757848262786865
Validation loss: 2.063633736743722

Epoch: 6| Step: 10
Training loss: 1.4322636127471924
Validation loss: 2.0430651531424573

Epoch: 6| Step: 11
Training loss: 1.3706960678100586
Validation loss: 1.9992783377247472

Epoch: 6| Step: 12
Training loss: 1.5333912372589111
Validation loss: 2.0673429619881416

Epoch: 6| Step: 13
Training loss: 1.8347506523132324
Validation loss: 2.038022405357771

Epoch: 380| Step: 0
Training loss: 1.4989721775054932
Validation loss: 2.0509351543200913

Epoch: 6| Step: 1
Training loss: 1.5128592252731323
Validation loss: 2.0441861357740176

Epoch: 6| Step: 2
Training loss: 1.4276854991912842
Validation loss: 2.0008491534058765

Epoch: 6| Step: 3
Training loss: 1.574917197227478
Validation loss: 2.0670447734094437

Epoch: 6| Step: 4
Training loss: 1.5127562284469604
Validation loss: 2.0892977919629825

Epoch: 6| Step: 5
Training loss: 2.5864334106445312
Validation loss: 2.052378405806839

Epoch: 6| Step: 6
Training loss: 1.461836576461792
Validation loss: 2.0292155306826354

Epoch: 6| Step: 7
Training loss: 1.2421066761016846
Validation loss: 2.042208110132525

Epoch: 6| Step: 8
Training loss: 1.1273276805877686
Validation loss: 2.046029575409428

Epoch: 6| Step: 9
Training loss: 1.3525794744491577
Validation loss: 2.066575991210117

Epoch: 6| Step: 10
Training loss: 2.1354944705963135
Validation loss: 2.03449014822642

Epoch: 6| Step: 11
Training loss: 1.0026586055755615
Validation loss: 2.027609407260854

Epoch: 6| Step: 12
Training loss: 1.2098026275634766
Validation loss: 2.04595321993674

Epoch: 6| Step: 13
Training loss: 1.3959077596664429
Validation loss: 2.0429345830794303

Epoch: 381| Step: 0
Training loss: 1.6827055215835571
Validation loss: 1.9954039025050339

Epoch: 6| Step: 1
Training loss: 1.2526915073394775
Validation loss: 2.0339400255551903

Epoch: 6| Step: 2
Training loss: 1.4640874862670898
Validation loss: 2.03428376618252

Epoch: 6| Step: 3
Training loss: 1.3343784809112549
Validation loss: 2.0540687179052703

Epoch: 6| Step: 4
Training loss: 1.7767066955566406
Validation loss: 2.0321840945110528

Epoch: 6| Step: 5
Training loss: 0.9399380087852478
Validation loss: 2.0525107973365375

Epoch: 6| Step: 6
Training loss: 0.8461265563964844
Validation loss: 2.038994548141315

Epoch: 6| Step: 7
Training loss: 2.2515969276428223
Validation loss: 2.0458065925105924

Epoch: 6| Step: 8
Training loss: 1.3513014316558838
Validation loss: 2.050217564387988

Epoch: 6| Step: 9
Training loss: 1.5608465671539307
Validation loss: 1.9690019674198602

Epoch: 6| Step: 10
Training loss: 1.3295832872390747
Validation loss: 2.0406193464033064

Epoch: 6| Step: 11
Training loss: 1.8622428178787231
Validation loss: 2.0124313677510908

Epoch: 6| Step: 12
Training loss: 1.5196961164474487
Validation loss: 2.048863016149049

Epoch: 6| Step: 13
Training loss: 1.579284906387329
Validation loss: 2.0435567927616898

Epoch: 382| Step: 0
Training loss: 1.046689510345459
Validation loss: 2.0272006091251167

Epoch: 6| Step: 1
Training loss: 1.5057852268218994
Validation loss: 2.052401896445982

Epoch: 6| Step: 2
Training loss: 2.5926501750946045
Validation loss: 2.0298438610569125

Epoch: 6| Step: 3
Training loss: 1.187842607498169
Validation loss: 2.048620946945683

Epoch: 6| Step: 4
Training loss: 1.6989796161651611
Validation loss: 1.9895762192305697

Epoch: 6| Step: 5
Training loss: 1.4418586492538452
Validation loss: 2.0327745329949165

Epoch: 6| Step: 6
Training loss: 1.0691988468170166
Validation loss: 2.0052589831813687

Epoch: 6| Step: 7
Training loss: 1.9777792692184448
Validation loss: 2.048769534275096

Epoch: 6| Step: 8
Training loss: 1.7157762050628662
Validation loss: 2.044534639645648

Epoch: 6| Step: 9
Training loss: 1.5332001447677612
Validation loss: 2.037541671465802

Epoch: 6| Step: 10
Training loss: 1.5271341800689697
Validation loss: 2.0315428972244263

Epoch: 6| Step: 11
Training loss: 1.4687252044677734
Validation loss: 2.0064007377111786

Epoch: 6| Step: 12
Training loss: 1.206946849822998
Validation loss: 2.0473667806194675

Epoch: 6| Step: 13
Training loss: 1.1790618896484375
Validation loss: 2.055530386586343

Epoch: 383| Step: 0
Training loss: 1.8704009056091309
Validation loss: 2.0371545771116852

Epoch: 6| Step: 1
Training loss: 2.0807266235351562
Validation loss: 2.0748632159284366

Epoch: 6| Step: 2
Training loss: 1.0868903398513794
Validation loss: 2.0531601316185406

Epoch: 6| Step: 3
Training loss: 1.8060463666915894
Validation loss: 2.0631827821013746

Epoch: 6| Step: 4
Training loss: 1.5386016368865967
Validation loss: 2.0538941532052974

Epoch: 6| Step: 5
Training loss: 1.6956212520599365
Validation loss: 2.025965048420814

Epoch: 6| Step: 6
Training loss: 1.1090072393417358
Validation loss: 2.0579012465733353

Epoch: 6| Step: 7
Training loss: 1.5967047214508057
Validation loss: 2.030860757315031

Epoch: 6| Step: 8
Training loss: 1.5686415433883667
Validation loss: 2.0599692290829075

Epoch: 6| Step: 9
Training loss: 1.1251169443130493
Validation loss: 2.028023037859189

Epoch: 6| Step: 10
Training loss: 1.6687588691711426
Validation loss: 2.069964308892527

Epoch: 6| Step: 11
Training loss: 1.1837701797485352
Validation loss: 2.0588419181044384

Epoch: 6| Step: 12
Training loss: 1.2805522680282593
Validation loss: 2.036554826203213

Epoch: 6| Step: 13
Training loss: 1.45386803150177
Validation loss: 2.0671937952759447

Epoch: 384| Step: 0
Training loss: 2.091036796569824
Validation loss: 1.999022864526318

Epoch: 6| Step: 1
Training loss: 1.7246851921081543
Validation loss: 2.0704973102897726

Epoch: 6| Step: 2
Training loss: 1.395064353942871
Validation loss: 2.041627276328302

Epoch: 6| Step: 3
Training loss: 1.3831371068954468
Validation loss: 2.033872514642695

Epoch: 6| Step: 4
Training loss: 1.7386071681976318
Validation loss: 2.0379496774365826

Epoch: 6| Step: 5
Training loss: 1.333127498626709
Validation loss: 2.0394874695808656

Epoch: 6| Step: 6
Training loss: 1.578573226928711
Validation loss: 2.076092186794486

Epoch: 6| Step: 7
Training loss: 1.4961304664611816
Validation loss: 2.0199418465296426

Epoch: 6| Step: 8
Training loss: 1.2145556211471558
Validation loss: 2.0393610077519573

Epoch: 6| Step: 9
Training loss: 2.0097575187683105
Validation loss: 2.0075979950607463

Epoch: 6| Step: 10
Training loss: 1.1153534650802612
Validation loss: 2.0347182750701904

Epoch: 6| Step: 11
Training loss: 1.4678702354431152
Validation loss: 2.031949855948007

Epoch: 6| Step: 12
Training loss: 1.1205493211746216
Validation loss: 2.024527911216982

Epoch: 6| Step: 13
Training loss: 1.3513760566711426
Validation loss: 2.06535356531861

Epoch: 385| Step: 0
Training loss: 1.2410638332366943
Validation loss: 2.0444049860841487

Epoch: 6| Step: 1
Training loss: 1.1801272630691528
Validation loss: 2.0176829189382572

Epoch: 6| Step: 2
Training loss: 1.8289421796798706
Validation loss: 2.0913073785843386

Epoch: 6| Step: 3
Training loss: 1.2920308113098145
Validation loss: 2.016524489207934

Epoch: 6| Step: 4
Training loss: 0.9366754293441772
Validation loss: 2.039308677437485

Epoch: 6| Step: 5
Training loss: 1.472579002380371
Validation loss: 2.0194940003015662

Epoch: 6| Step: 6
Training loss: 1.3872992992401123
Validation loss: 2.0838805039723716

Epoch: 6| Step: 7
Training loss: 1.8827342987060547
Validation loss: 2.031428075605823

Epoch: 6| Step: 8
Training loss: 2.003537178039551
Validation loss: 2.078252915413149

Epoch: 6| Step: 9
Training loss: 1.0637016296386719
Validation loss: 2.024372982722457

Epoch: 6| Step: 10
Training loss: 1.675199031829834
Validation loss: 2.0784218900947162

Epoch: 6| Step: 11
Training loss: 1.855481743812561
Validation loss: 2.075286470433717

Epoch: 6| Step: 12
Training loss: 1.7036104202270508
Validation loss: 2.0506705622519217

Epoch: 6| Step: 13
Training loss: 1.692421793937683
Validation loss: 2.029655635997813

Epoch: 386| Step: 0
Training loss: 1.8025988340377808
Validation loss: 2.050016171188765

Epoch: 6| Step: 1
Training loss: 1.744031548500061
Validation loss: 2.0032724590711695

Epoch: 6| Step: 2
Training loss: 1.3109568357467651
Validation loss: 2.04986786073254

Epoch: 6| Step: 3
Training loss: 1.6565382480621338
Validation loss: 1.9954976753521991

Epoch: 6| Step: 4
Training loss: 0.76421719789505
Validation loss: 2.025895277659098

Epoch: 6| Step: 5
Training loss: 1.6409369707107544
Validation loss: 2.0647668607773317

Epoch: 6| Step: 6
Training loss: 1.7903387546539307
Validation loss: 2.0446620115669827

Epoch: 6| Step: 7
Training loss: 1.1430929899215698
Validation loss: 2.052057884072745

Epoch: 6| Step: 8
Training loss: 2.481743335723877
Validation loss: 2.002680213220658

Epoch: 6| Step: 9
Training loss: 1.6876901388168335
Validation loss: 2.031770690794914

Epoch: 6| Step: 10
Training loss: 1.4172782897949219
Validation loss: 2.0156765855768675

Epoch: 6| Step: 11
Training loss: 1.2002062797546387
Validation loss: 2.045617672704881

Epoch: 6| Step: 12
Training loss: 1.3551894426345825
Validation loss: 2.0420206285292104

Epoch: 6| Step: 13
Training loss: 1.1350953578948975
Validation loss: 2.0503278855354554

Epoch: 387| Step: 0
Training loss: 1.3206450939178467
Validation loss: 2.07677298720165

Epoch: 6| Step: 1
Training loss: 2.481520175933838
Validation loss: 2.022693710942422

Epoch: 6| Step: 2
Training loss: 2.3836348056793213
Validation loss: 2.0497233483099166

Epoch: 6| Step: 3
Training loss: 2.0676164627075195
Validation loss: 2.037984850586102

Epoch: 6| Step: 4
Training loss: 1.2166122198104858
Validation loss: 2.072898877564297

Epoch: 6| Step: 5
Training loss: 1.111379623413086
Validation loss: 2.0734033892231603

Epoch: 6| Step: 6
Training loss: 1.028092384338379
Validation loss: 2.059432996216641

Epoch: 6| Step: 7
Training loss: 1.0633177757263184
Validation loss: 2.042194648455548

Epoch: 6| Step: 8
Training loss: 2.3572864532470703
Validation loss: 1.9705610223995742

Epoch: 6| Step: 9
Training loss: 1.522314429283142
Validation loss: 2.0275728651272353

Epoch: 6| Step: 10
Training loss: 1.606513261795044
Validation loss: 2.00612372736777

Epoch: 6| Step: 11
Training loss: 1.2069183588027954
Validation loss: 2.0698433460727816

Epoch: 6| Step: 12
Training loss: 0.740689754486084
Validation loss: 2.023394589783043

Epoch: 6| Step: 13
Training loss: 0.605118989944458
Validation loss: 2.02934524320787

Epoch: 388| Step: 0
Training loss: 1.2227377891540527
Validation loss: 2.0205197641926427

Epoch: 6| Step: 1
Training loss: 1.3655210733413696
Validation loss: 2.015444791445168

Epoch: 6| Step: 2
Training loss: 1.5962913036346436
Validation loss: 2.0578640968568864

Epoch: 6| Step: 3
Training loss: 0.9041649103164673
Validation loss: 2.0230092566500426

Epoch: 6| Step: 4
Training loss: 1.735123872756958
Validation loss: 2.0241642767383206

Epoch: 6| Step: 5
Training loss: 1.382629156112671
Validation loss: 2.0406562987194268

Epoch: 6| Step: 6
Training loss: 1.4351110458374023
Validation loss: 2.0393934993333716

Epoch: 6| Step: 7
Training loss: 1.5960246324539185
Validation loss: 2.063504575401224

Epoch: 6| Step: 8
Training loss: 1.536696434020996
Validation loss: 2.0302394615706576

Epoch: 6| Step: 9
Training loss: 2.017970323562622
Validation loss: 2.039003631120087

Epoch: 6| Step: 10
Training loss: 1.1618406772613525
Validation loss: 2.0330951841928626

Epoch: 6| Step: 11
Training loss: 1.8612946271896362
Validation loss: 2.0815612193076842

Epoch: 6| Step: 12
Training loss: 1.8637083768844604
Validation loss: 1.990868442802019

Epoch: 6| Step: 13
Training loss: 0.9489907026290894
Validation loss: 2.04539482824264

Epoch: 389| Step: 0
Training loss: 1.0843126773834229
Validation loss: 2.0362043303828083

Epoch: 6| Step: 1
Training loss: 1.032933235168457
Validation loss: 2.026976095732822

Epoch: 6| Step: 2
Training loss: 1.1469213962554932
Validation loss: 2.023491628708378

Epoch: 6| Step: 3
Training loss: 1.544191837310791
Validation loss: 2.024821194269324

Epoch: 6| Step: 4
Training loss: 2.0391652584075928
Validation loss: 2.0813103516896567

Epoch: 6| Step: 5
Training loss: 2.0871095657348633
Validation loss: 2.062450465335641

Epoch: 6| Step: 6
Training loss: 0.9878997802734375
Validation loss: 2.087747884053056

Epoch: 6| Step: 7
Training loss: 1.9391950368881226
Validation loss: 2.062668959299723

Epoch: 6| Step: 8
Training loss: 1.7034685611724854
Validation loss: 2.0893673384061424

Epoch: 6| Step: 9
Training loss: 1.1370904445648193
Validation loss: 2.059802216868247

Epoch: 6| Step: 10
Training loss: 1.2464053630828857
Validation loss: 2.0061257244438253

Epoch: 6| Step: 11
Training loss: 1.7517871856689453
Validation loss: 2.0294445753097534

Epoch: 6| Step: 12
Training loss: 1.8522348403930664
Validation loss: 2.0610612835935367

Epoch: 6| Step: 13
Training loss: 2.1369597911834717
Validation loss: 2.0894268533234954

Epoch: 390| Step: 0
Training loss: 1.3758342266082764
Validation loss: 2.023766594548379

Epoch: 6| Step: 1
Training loss: 1.6165945529937744
Validation loss: 2.107979307892502

Epoch: 6| Step: 2
Training loss: 1.6845612525939941
Validation loss: 2.0609972656414075

Epoch: 6| Step: 3
Training loss: 1.7264623641967773
Validation loss: 2.0207388606122745

Epoch: 6| Step: 4
Training loss: 2.40616774559021
Validation loss: 2.010220794267552

Epoch: 6| Step: 5
Training loss: 1.5103046894073486
Validation loss: 2.0379938874193417

Epoch: 6| Step: 6
Training loss: 1.3063323497772217
Validation loss: 2.014954028591033

Epoch: 6| Step: 7
Training loss: 0.684766411781311
Validation loss: 2.0218045352607645

Epoch: 6| Step: 8
Training loss: 1.7854013442993164
Validation loss: 1.9654992600922943

Epoch: 6| Step: 9
Training loss: 1.3977305889129639
Validation loss: 2.0321567135472454

Epoch: 6| Step: 10
Training loss: 1.4303181171417236
Validation loss: 2.0036535724516837

Epoch: 6| Step: 11
Training loss: 1.144310474395752
Validation loss: 2.079622645531931

Epoch: 6| Step: 12
Training loss: 1.363471269607544
Validation loss: 2.0458159023715603

Epoch: 6| Step: 13
Training loss: 1.1849493980407715
Validation loss: 2.0181559157627884

Epoch: 391| Step: 0
Training loss: 1.7095955610275269
Validation loss: 2.030039609119456

Epoch: 6| Step: 1
Training loss: 2.3941397666931152
Validation loss: 2.072584864913776

Epoch: 6| Step: 2
Training loss: 2.07454252243042
Validation loss: 2.076657731045959

Epoch: 6| Step: 3
Training loss: 1.6950585842132568
Validation loss: 2.022190425985603

Epoch: 6| Step: 4
Training loss: 1.4550011157989502
Validation loss: 2.0561540152436946

Epoch: 6| Step: 5
Training loss: 1.2873250246047974
Validation loss: 2.049572111457907

Epoch: 6| Step: 6
Training loss: 1.0669543743133545
Validation loss: 2.0258741430056992

Epoch: 6| Step: 7
Training loss: 1.427657127380371
Validation loss: 2.0360632058112853

Epoch: 6| Step: 8
Training loss: 1.0915765762329102
Validation loss: 2.022934067633844

Epoch: 6| Step: 9
Training loss: 1.2535934448242188
Validation loss: 2.0667584839687554

Epoch: 6| Step: 10
Training loss: 1.2737064361572266
Validation loss: 2.0391493099991993

Epoch: 6| Step: 11
Training loss: 1.1755914688110352
Validation loss: 2.0429907332184496

Epoch: 6| Step: 12
Training loss: 1.5344438552856445
Validation loss: 2.0528979493725683

Epoch: 6| Step: 13
Training loss: 1.3979517221450806
Validation loss: 2.0238516330718994

Epoch: 392| Step: 0
Training loss: 1.631967544555664
Validation loss: 2.033031528995883

Epoch: 6| Step: 1
Training loss: 1.088412880897522
Validation loss: 2.0641257121998775

Epoch: 6| Step: 2
Training loss: 1.7548596858978271
Validation loss: 2.043529510498047

Epoch: 6| Step: 3
Training loss: 1.332744836807251
Validation loss: 2.0392059126207904

Epoch: 6| Step: 4
Training loss: 1.053690791130066
Validation loss: 2.0559605962486676

Epoch: 6| Step: 5
Training loss: 1.4545117616653442
Validation loss: 2.0522309554520475

Epoch: 6| Step: 6
Training loss: 1.4959710836410522
Validation loss: 2.0005411819745134

Epoch: 6| Step: 7
Training loss: 1.814687728881836
Validation loss: 2.047471712994319

Epoch: 6| Step: 8
Training loss: 1.1966485977172852
Validation loss: 2.0215288118649553

Epoch: 6| Step: 9
Training loss: 1.638749361038208
Validation loss: 2.0139719593909478

Epoch: 6| Step: 10
Training loss: 1.573105812072754
Validation loss: 2.0344047687386952

Epoch: 6| Step: 11
Training loss: 1.5978825092315674
Validation loss: 2.041815447550948

Epoch: 6| Step: 12
Training loss: 2.1221389770507812
Validation loss: 2.057399421609858

Epoch: 6| Step: 13
Training loss: 0.9056580066680908
Validation loss: 2.0649246990039782

Epoch: 393| Step: 0
Training loss: 2.1842422485351562
Validation loss: 2.0358618459393902

Epoch: 6| Step: 1
Training loss: 0.9674222469329834
Validation loss: 2.0535235392150057

Epoch: 6| Step: 2
Training loss: 1.935199499130249
Validation loss: 2.0506509324555755

Epoch: 6| Step: 3
Training loss: 1.2021499872207642
Validation loss: 2.0493689929285357

Epoch: 6| Step: 4
Training loss: 1.3886306285858154
Validation loss: 2.039238663129909

Epoch: 6| Step: 5
Training loss: 1.2328277826309204
Validation loss: 2.0942337794970443

Epoch: 6| Step: 6
Training loss: 1.5223716497421265
Validation loss: 2.024302004486002

Epoch: 6| Step: 7
Training loss: 1.8681058883666992
Validation loss: 2.0551909144206713

Epoch: 6| Step: 8
Training loss: 0.7865943908691406
Validation loss: 2.033602750429543

Epoch: 6| Step: 9
Training loss: 1.3481849431991577
Validation loss: 2.0657692583658362

Epoch: 6| Step: 10
Training loss: 1.4352803230285645
Validation loss: 2.0367710282725673

Epoch: 6| Step: 11
Training loss: 2.27396559715271
Validation loss: 2.0047619291531142

Epoch: 6| Step: 12
Training loss: 1.259042739868164
Validation loss: 2.051885803540548

Epoch: 6| Step: 13
Training loss: 1.2610483169555664
Validation loss: 2.055840492248535

Epoch: 394| Step: 0
Training loss: 1.3683453798294067
Validation loss: 2.050663907040832

Epoch: 6| Step: 1
Training loss: 1.5549492835998535
Validation loss: 2.044653320825228

Epoch: 6| Step: 2
Training loss: 1.8747382164001465
Validation loss: 2.034259852542672

Epoch: 6| Step: 3
Training loss: 1.7995073795318604
Validation loss: 2.051643757409947

Epoch: 6| Step: 4
Training loss: 1.2245069742202759
Validation loss: 2.073321262995402

Epoch: 6| Step: 5
Training loss: 1.2256022691726685
Validation loss: 2.0418597639247937

Epoch: 6| Step: 6
Training loss: 1.2353780269622803
Validation loss: 2.095664767808812

Epoch: 6| Step: 7
Training loss: 1.7025142908096313
Validation loss: 2.062193621871292

Epoch: 6| Step: 8
Training loss: 1.5436766147613525
Validation loss: 2.0706933416346067

Epoch: 6| Step: 9
Training loss: 0.8089139461517334
Validation loss: 2.0638756649468535

Epoch: 6| Step: 10
Training loss: 0.9842535257339478
Validation loss: 2.0545897842735372

Epoch: 6| Step: 11
Training loss: 1.810661792755127
Validation loss: 2.061636519688432

Epoch: 6| Step: 12
Training loss: 1.5107805728912354
Validation loss: 2.0369300278284217

Epoch: 6| Step: 13
Training loss: 2.181262731552124
Validation loss: 2.041580843669112

Epoch: 395| Step: 0
Training loss: 1.0330052375793457
Validation loss: 2.007321282099652

Epoch: 6| Step: 1
Training loss: 1.8922979831695557
Validation loss: 2.074167010604694

Epoch: 6| Step: 2
Training loss: 1.661100149154663
Validation loss: 2.0473840781437453

Epoch: 6| Step: 3
Training loss: 1.1396620273590088
Validation loss: 1.9952910689897434

Epoch: 6| Step: 4
Training loss: 1.374896764755249
Validation loss: 2.028917245967414

Epoch: 6| Step: 5
Training loss: 1.048198938369751
Validation loss: 2.06479226773785

Epoch: 6| Step: 6
Training loss: 1.912769079208374
Validation loss: 2.0112986615909043

Epoch: 6| Step: 7
Training loss: 1.291565179824829
Validation loss: 1.992141762087422

Epoch: 6| Step: 8
Training loss: 1.676067590713501
Validation loss: 2.0010777788777507

Epoch: 6| Step: 9
Training loss: 1.2952344417572021
Validation loss: 2.0657322099131923

Epoch: 6| Step: 10
Training loss: 1.4758670330047607
Validation loss: 2.0678487952037523

Epoch: 6| Step: 11
Training loss: 1.4911562204360962
Validation loss: 2.0636626879374185

Epoch: 6| Step: 12
Training loss: 1.8722078800201416
Validation loss: 2.032386661857687

Epoch: 6| Step: 13
Training loss: 1.6398334503173828
Validation loss: 2.106307909052859

Epoch: 396| Step: 0
Training loss: 1.5648930072784424
Validation loss: 2.0430886617270847

Epoch: 6| Step: 1
Training loss: 1.715218424797058
Validation loss: 2.0356929481670423

Epoch: 6| Step: 2
Training loss: 1.4571876525878906
Validation loss: 2.0160765212069274

Epoch: 6| Step: 3
Training loss: 1.0818681716918945
Validation loss: 2.000072435666156

Epoch: 6| Step: 4
Training loss: 0.8257964849472046
Validation loss: 2.046844087621217

Epoch: 6| Step: 5
Training loss: 1.4617927074432373
Validation loss: 2.05544271520389

Epoch: 6| Step: 6
Training loss: 1.32224702835083
Validation loss: 2.0042735440756685

Epoch: 6| Step: 7
Training loss: 1.4639145135879517
Validation loss: 2.0489684125428558

Epoch: 6| Step: 8
Training loss: 1.4066954851150513
Validation loss: 2.0508725745703584

Epoch: 6| Step: 9
Training loss: 1.151239275932312
Validation loss: 2.10699821800314

Epoch: 6| Step: 10
Training loss: 1.7257717847824097
Validation loss: 2.0694613777181154

Epoch: 6| Step: 11
Training loss: 1.4010326862335205
Validation loss: 2.060710049444629

Epoch: 6| Step: 12
Training loss: 1.9976134300231934
Validation loss: 2.0206317619610856

Epoch: 6| Step: 13
Training loss: 2.478175163269043
Validation loss: 2.05201296652517

Epoch: 397| Step: 0
Training loss: 1.6933047771453857
Validation loss: 2.051537823933427

Epoch: 6| Step: 1
Training loss: 1.3614739179611206
Validation loss: 2.0452897407675303

Epoch: 6| Step: 2
Training loss: 1.292938232421875
Validation loss: 2.04740539673836

Epoch: 6| Step: 3
Training loss: 1.9611176252365112
Validation loss: 2.091197850883648

Epoch: 6| Step: 4
Training loss: 2.0850348472595215
Validation loss: 2.112664116326199

Epoch: 6| Step: 5
Training loss: 1.2460787296295166
Validation loss: 2.096777564735823

Epoch: 6| Step: 6
Training loss: 1.9233415126800537
Validation loss: 2.1370155760037

Epoch: 6| Step: 7
Training loss: 1.495514154434204
Validation loss: 2.042214749961771

Epoch: 6| Step: 8
Training loss: 1.2732734680175781
Validation loss: 2.091000521054832

Epoch: 6| Step: 9
Training loss: 1.3644671440124512
Validation loss: 2.070851197806738

Epoch: 6| Step: 10
Training loss: 1.4091238975524902
Validation loss: 2.0422196977881977

Epoch: 6| Step: 11
Training loss: 1.8451873064041138
Validation loss: 2.0655705005891862

Epoch: 6| Step: 12
Training loss: 0.8366116285324097
Validation loss: 2.0687324180397937

Epoch: 6| Step: 13
Training loss: 1.2850093841552734
Validation loss: 2.0673011528548373

Epoch: 398| Step: 0
Training loss: 1.5067740678787231
Validation loss: 2.002314245829018

Epoch: 6| Step: 1
Training loss: 2.267981767654419
Validation loss: 2.037949864582349

Epoch: 6| Step: 2
Training loss: 1.8624104261398315
Validation loss: 2.0348400146730485

Epoch: 6| Step: 3
Training loss: 1.6051180362701416
Validation loss: 1.9898856634734778

Epoch: 6| Step: 4
Training loss: 1.6850342750549316
Validation loss: 2.042063054218087

Epoch: 6| Step: 5
Training loss: 0.9341467618942261
Validation loss: 2.0165093714191067

Epoch: 6| Step: 6
Training loss: 1.5929185152053833
Validation loss: 2.050394199227774

Epoch: 6| Step: 7
Training loss: 1.0525535345077515
Validation loss: 2.0489926953469553

Epoch: 6| Step: 8
Training loss: 1.033591628074646
Validation loss: 2.0600247998391428

Epoch: 6| Step: 9
Training loss: 2.4207754135131836
Validation loss: 2.0574474078352734

Epoch: 6| Step: 10
Training loss: 0.983286440372467
Validation loss: 1.9954628880305956

Epoch: 6| Step: 11
Training loss: 1.4267995357513428
Validation loss: 2.055204254324718

Epoch: 6| Step: 12
Training loss: 1.0639898777008057
Validation loss: 2.0283603488758044

Epoch: 6| Step: 13
Training loss: 1.3392506837844849
Validation loss: 2.0515775577996367

Epoch: 399| Step: 0
Training loss: 1.6506832838058472
Validation loss: 2.0458072411116732

Epoch: 6| Step: 1
Training loss: 2.024338483810425
Validation loss: 2.0456020498788483

Epoch: 6| Step: 2
Training loss: 1.7791680097579956
Validation loss: 2.0418075630741734

Epoch: 6| Step: 3
Training loss: 1.4036844968795776
Validation loss: 2.0644910796996085

Epoch: 6| Step: 4
Training loss: 1.5405452251434326
Validation loss: 2.0796926534304054

Epoch: 6| Step: 5
Training loss: 1.085379958152771
Validation loss: 2.112220343723092

Epoch: 6| Step: 6
Training loss: 1.3665056228637695
Validation loss: 2.0919075678753596

Epoch: 6| Step: 7
Training loss: 2.039388418197632
Validation loss: 2.083586105736353

Epoch: 6| Step: 8
Training loss: 1.8699443340301514
Validation loss: 2.0389602338114092

Epoch: 6| Step: 9
Training loss: 0.912029504776001
Validation loss: 2.0379896471577306

Epoch: 6| Step: 10
Training loss: 1.349158525466919
Validation loss: 2.083836201698549

Epoch: 6| Step: 11
Training loss: 1.0061259269714355
Validation loss: 2.0393578801103818

Epoch: 6| Step: 12
Training loss: 1.4727015495300293
Validation loss: 2.0891052612694363

Epoch: 6| Step: 13
Training loss: 1.1849522590637207
Validation loss: 2.036830949526961

Epoch: 400| Step: 0
Training loss: 0.91267991065979
Validation loss: 2.0685269678792646

Epoch: 6| Step: 1
Training loss: 1.2663183212280273
Validation loss: 2.0209948657661356

Epoch: 6| Step: 2
Training loss: 1.8927432298660278
Validation loss: 2.0616190612957044

Epoch: 6| Step: 3
Training loss: 2.0455751419067383
Validation loss: 2.0056726163433445

Epoch: 6| Step: 4
Training loss: 1.4576634168624878
Validation loss: 2.03597133005819

Epoch: 6| Step: 5
Training loss: 1.7274467945098877
Validation loss: 1.9986712906950264

Epoch: 6| Step: 6
Training loss: 2.0698492527008057
Validation loss: 2.049819141305903

Epoch: 6| Step: 7
Training loss: 1.8290905952453613
Validation loss: 2.092377680604176

Epoch: 6| Step: 8
Training loss: 1.0305886268615723
Validation loss: 2.0311742905647523

Epoch: 6| Step: 9
Training loss: 1.7776931524276733
Validation loss: 2.0681212871305403

Epoch: 6| Step: 10
Training loss: 1.1841704845428467
Validation loss: 2.0213008593487483

Epoch: 6| Step: 11
Training loss: 1.3408856391906738
Validation loss: 2.0510418543251614

Epoch: 6| Step: 12
Training loss: 1.1293631792068481
Validation loss: 2.031452243046094

Epoch: 6| Step: 13
Training loss: 0.9335620403289795
Validation loss: 2.049468107120965

Epoch: 401| Step: 0
Training loss: 1.741011142730713
Validation loss: 2.013700774920884

Epoch: 6| Step: 1
Training loss: 1.8248692750930786
Validation loss: 2.027967499148461

Epoch: 6| Step: 2
Training loss: 0.9930668473243713
Validation loss: 2.0304228618580806

Epoch: 6| Step: 3
Training loss: 1.7869880199432373
Validation loss: 2.0076255490702968

Epoch: 6| Step: 4
Training loss: 1.6936510801315308
Validation loss: 2.045411907216554

Epoch: 6| Step: 5
Training loss: 1.8246614933013916
Validation loss: 2.04292336715165

Epoch: 6| Step: 6
Training loss: 1.3787877559661865
Validation loss: 2.0372847972377652

Epoch: 6| Step: 7
Training loss: 1.210951805114746
Validation loss: 2.019298194557108

Epoch: 6| Step: 8
Training loss: 1.4088090658187866
Validation loss: 2.0614029258810063

Epoch: 6| Step: 9
Training loss: 1.2697265148162842
Validation loss: 2.0206043797154583

Epoch: 6| Step: 10
Training loss: 1.7456170320510864
Validation loss: 2.031297488879132

Epoch: 6| Step: 11
Training loss: 1.2232820987701416
Validation loss: 2.0790649690935687

Epoch: 6| Step: 12
Training loss: 1.0402404069900513
Validation loss: 2.0206463324126376

Epoch: 6| Step: 13
Training loss: 1.4321801662445068
Validation loss: 1.9966527005677581

Epoch: 402| Step: 0
Training loss: 1.8546150922775269
Validation loss: 2.035204138807071

Epoch: 6| Step: 1
Training loss: 1.1593753099441528
Validation loss: 2.0374258487455306

Epoch: 6| Step: 2
Training loss: 1.0561342239379883
Validation loss: 2.0524926723972445

Epoch: 6| Step: 3
Training loss: 0.8612074851989746
Validation loss: 2.0757708446953886

Epoch: 6| Step: 4
Training loss: 1.3745745420455933
Validation loss: 1.9793423080957064

Epoch: 6| Step: 5
Training loss: 2.1366891860961914
Validation loss: 2.076660804851081

Epoch: 6| Step: 6
Training loss: 1.3993232250213623
Validation loss: 2.0149593378907893

Epoch: 6| Step: 7
Training loss: 1.889941930770874
Validation loss: 2.041471128822655

Epoch: 6| Step: 8
Training loss: 1.910765290260315
Validation loss: 2.012000459496693

Epoch: 6| Step: 9
Training loss: 1.2432968616485596
Validation loss: 2.06167802246668

Epoch: 6| Step: 10
Training loss: 0.9371543526649475
Validation loss: 2.022205173328359

Epoch: 6| Step: 11
Training loss: 1.7567665576934814
Validation loss: 2.014523208782237

Epoch: 6| Step: 12
Training loss: 1.1405762434005737
Validation loss: 2.042349023203696

Epoch: 6| Step: 13
Training loss: 1.6457704305648804
Validation loss: 2.0462122937684417

Epoch: 403| Step: 0
Training loss: 1.2142925262451172
Validation loss: 1.9838788099186395

Epoch: 6| Step: 1
Training loss: 1.029849886894226
Validation loss: 2.0030586616967314

Epoch: 6| Step: 2
Training loss: 1.977756381034851
Validation loss: 2.009266020149313

Epoch: 6| Step: 3
Training loss: 1.8195667266845703
Validation loss: 2.019623742308668

Epoch: 6| Step: 4
Training loss: 1.3445754051208496
Validation loss: 2.005414319294755

Epoch: 6| Step: 5
Training loss: 0.839120626449585
Validation loss: 2.024409722256404

Epoch: 6| Step: 6
Training loss: 1.8008713722229004
Validation loss: 2.0442278026252665

Epoch: 6| Step: 7
Training loss: 1.6791822910308838
Validation loss: 2.0665690270803307

Epoch: 6| Step: 8
Training loss: 1.2190392017364502
Validation loss: 2.0150892683254775

Epoch: 6| Step: 9
Training loss: 1.3235334157943726
Validation loss: 2.042971349531604

Epoch: 6| Step: 10
Training loss: 1.098073124885559
Validation loss: 2.0383726114867837

Epoch: 6| Step: 11
Training loss: 1.7604068517684937
Validation loss: 2.02547392793881

Epoch: 6| Step: 12
Training loss: 1.9693055152893066
Validation loss: 2.055744650543377

Epoch: 6| Step: 13
Training loss: 1.3291492462158203
Validation loss: 2.0322953859965005

Epoch: 404| Step: 0
Training loss: 2.2338719367980957
Validation loss: 2.0608318710839875

Epoch: 6| Step: 1
Training loss: 1.290926218032837
Validation loss: 2.0569519868461033

Epoch: 6| Step: 2
Training loss: 0.8839802145957947
Validation loss: 2.0451155759954966

Epoch: 6| Step: 3
Training loss: 1.4453840255737305
Validation loss: 2.0347137399899062

Epoch: 6| Step: 4
Training loss: 1.1083600521087646
Validation loss: 2.0346464008413334

Epoch: 6| Step: 5
Training loss: 2.128859281539917
Validation loss: 2.04906758569902

Epoch: 6| Step: 6
Training loss: 1.4448121786117554
Validation loss: 2.0460789306189424

Epoch: 6| Step: 7
Training loss: 1.935204267501831
Validation loss: 1.9956027128363167

Epoch: 6| Step: 8
Training loss: 0.924260139465332
Validation loss: 2.005797875824795

Epoch: 6| Step: 9
Training loss: 1.6409640312194824
Validation loss: 2.02978431024859

Epoch: 6| Step: 10
Training loss: 1.072760820388794
Validation loss: 2.0556619449328353

Epoch: 6| Step: 11
Training loss: 1.6311088800430298
Validation loss: 2.006385557113155

Epoch: 6| Step: 12
Training loss: 1.4146658182144165
Validation loss: 2.026674373175508

Epoch: 6| Step: 13
Training loss: 0.8056840896606445
Validation loss: 2.01636476414178

Epoch: 405| Step: 0
Training loss: 1.335392951965332
Validation loss: 2.0522370799895255

Epoch: 6| Step: 1
Training loss: 1.766697883605957
Validation loss: 2.047051796349146

Epoch: 6| Step: 2
Training loss: 1.5587952136993408
Validation loss: 2.0692868937728224

Epoch: 6| Step: 3
Training loss: 1.552760124206543
Validation loss: 2.0627376084686606

Epoch: 6| Step: 4
Training loss: 1.5536009073257446
Validation loss: 2.034961341529764

Epoch: 6| Step: 5
Training loss: 1.7636758089065552
Validation loss: 2.023425207343153

Epoch: 6| Step: 6
Training loss: 1.8244030475616455
Validation loss: 1.9912971642709547

Epoch: 6| Step: 7
Training loss: 1.1847648620605469
Validation loss: 1.9888096227440784

Epoch: 6| Step: 8
Training loss: 1.490248441696167
Validation loss: 2.0395810475913425

Epoch: 6| Step: 9
Training loss: 0.8895143270492554
Validation loss: 2.045233218900619

Epoch: 6| Step: 10
Training loss: 0.8798531293869019
Validation loss: 2.0009946412937616

Epoch: 6| Step: 11
Training loss: 1.020068645477295
Validation loss: 2.0652445593187885

Epoch: 6| Step: 12
Training loss: 1.8696798086166382
Validation loss: 2.0301786622693463

Epoch: 6| Step: 13
Training loss: 1.79381263256073
Validation loss: 2.0289794911620436

Epoch: 406| Step: 0
Training loss: 2.052823066711426
Validation loss: 2.0282815297444663

Epoch: 6| Step: 1
Training loss: 1.7050461769104004
Validation loss: 2.064503081383244

Epoch: 6| Step: 2
Training loss: 0.9747295379638672
Validation loss: 2.0657398457168252

Epoch: 6| Step: 3
Training loss: 1.2366079092025757
Validation loss: 2.069937893139419

Epoch: 6| Step: 4
Training loss: 1.3656975030899048
Validation loss: 2.071054115090319

Epoch: 6| Step: 5
Training loss: 1.3055083751678467
Validation loss: 2.032990768391599

Epoch: 6| Step: 6
Training loss: 0.8677589297294617
Validation loss: 2.0314465517638833

Epoch: 6| Step: 7
Training loss: 1.588301181793213
Validation loss: 2.027155554422768

Epoch: 6| Step: 8
Training loss: 1.2137444019317627
Validation loss: 2.0201158177468086

Epoch: 6| Step: 9
Training loss: 1.5986744165420532
Validation loss: 2.0357361583299536

Epoch: 6| Step: 10
Training loss: 1.072527289390564
Validation loss: 2.028792332577449

Epoch: 6| Step: 11
Training loss: 2.3405749797821045
Validation loss: 2.024039763276295

Epoch: 6| Step: 12
Training loss: 1.6614779233932495
Validation loss: 2.044867912928263

Epoch: 6| Step: 13
Training loss: 1.216590404510498
Validation loss: 2.0008813950323288

Epoch: 407| Step: 0
Training loss: 1.3590326309204102
Validation loss: 1.9996022716645272

Epoch: 6| Step: 1
Training loss: 1.1327831745147705
Validation loss: 2.019574926745507

Epoch: 6| Step: 2
Training loss: 1.2631717920303345
Validation loss: 2.0381823124424105

Epoch: 6| Step: 3
Training loss: 1.046186923980713
Validation loss: 2.060523945798156

Epoch: 6| Step: 4
Training loss: 1.6149585247039795
Validation loss: 2.0399172049696728

Epoch: 6| Step: 5
Training loss: 1.7644379138946533
Validation loss: 2.056993889552291

Epoch: 6| Step: 6
Training loss: 1.3927252292633057
Validation loss: 2.0888322296962945

Epoch: 6| Step: 7
Training loss: 2.3438191413879395
Validation loss: 2.005167661174651

Epoch: 6| Step: 8
Training loss: 0.6366764903068542
Validation loss: 2.0089524407540598

Epoch: 6| Step: 9
Training loss: 1.563124656677246
Validation loss: 2.056264390227615

Epoch: 6| Step: 10
Training loss: 0.8742435574531555
Validation loss: 2.030117678385909

Epoch: 6| Step: 11
Training loss: 2.273494005203247
Validation loss: 2.050825201055055

Epoch: 6| Step: 12
Training loss: 1.7203469276428223
Validation loss: 2.044601494266141

Epoch: 6| Step: 13
Training loss: 0.763644814491272
Validation loss: 2.062793283052342

Epoch: 408| Step: 0
Training loss: 1.7984999418258667
Validation loss: 2.0138240386081

Epoch: 6| Step: 1
Training loss: 1.720806360244751
Validation loss: 2.0165569000346686

Epoch: 6| Step: 2
Training loss: 1.2311214208602905
Validation loss: 2.0526164911126576

Epoch: 6| Step: 3
Training loss: 1.3155388832092285
Validation loss: 1.9958720489214825

Epoch: 6| Step: 4
Training loss: 1.4085533618927002
Validation loss: 2.037724753861786

Epoch: 6| Step: 5
Training loss: 1.595475673675537
Validation loss: 1.9764101146369852

Epoch: 6| Step: 6
Training loss: 1.0850365161895752
Validation loss: 2.0238610813694615

Epoch: 6| Step: 7
Training loss: 1.798443078994751
Validation loss: 2.053272537005845

Epoch: 6| Step: 8
Training loss: 1.5162267684936523
Validation loss: 2.043583611006378

Epoch: 6| Step: 9
Training loss: 1.2869646549224854
Validation loss: 2.016259749730428

Epoch: 6| Step: 10
Training loss: 1.528106927871704
Validation loss: 2.038242914343393

Epoch: 6| Step: 11
Training loss: 1.4677003622055054
Validation loss: 1.9944573320368284

Epoch: 6| Step: 12
Training loss: 1.5093027353286743
Validation loss: 2.0022601094297183

Epoch: 6| Step: 13
Training loss: 0.37195461988449097
Validation loss: 2.023482022746917

Epoch: 409| Step: 0
Training loss: 1.5213792324066162
Validation loss: 2.032825472534344

Epoch: 6| Step: 1
Training loss: 1.305957317352295
Validation loss: 2.0490064800426526

Epoch: 6| Step: 2
Training loss: 1.3764071464538574
Validation loss: 2.0641645346918414

Epoch: 6| Step: 3
Training loss: 1.3506962060928345
Validation loss: 1.974486868868592

Epoch: 6| Step: 4
Training loss: 1.3236043453216553
Validation loss: 2.031534255191844

Epoch: 6| Step: 5
Training loss: 1.6401580572128296
Validation loss: 2.01388212942308

Epoch: 6| Step: 6
Training loss: 1.0776185989379883
Validation loss: 2.045222325991559

Epoch: 6| Step: 7
Training loss: 1.3509266376495361
Validation loss: 2.0384533405303955

Epoch: 6| Step: 8
Training loss: 1.3383262157440186
Validation loss: 2.051200471898561

Epoch: 6| Step: 9
Training loss: 1.6747952699661255
Validation loss: 2.031108942083133

Epoch: 6| Step: 10
Training loss: 0.8125729560852051
Validation loss: 2.027500525597603

Epoch: 6| Step: 11
Training loss: 2.242394208908081
Validation loss: 2.037020412824487

Epoch: 6| Step: 12
Training loss: 1.6918518543243408
Validation loss: 2.023264461948026

Epoch: 6| Step: 13
Training loss: 1.5015422105789185
Validation loss: 2.018681667184317

Epoch: 410| Step: 0
Training loss: 2.142167568206787
Validation loss: 2.030541104655112

Epoch: 6| Step: 1
Training loss: 1.2842607498168945
Validation loss: 2.0030643786153486

Epoch: 6| Step: 2
Training loss: 2.0407676696777344
Validation loss: 2.0605486208392727

Epoch: 6| Step: 3
Training loss: 1.2185263633728027
Validation loss: 2.0291995361287105

Epoch: 6| Step: 4
Training loss: 1.6344115734100342
Validation loss: 2.035231415943433

Epoch: 6| Step: 5
Training loss: 1.213546633720398
Validation loss: 2.0830162494413313

Epoch: 6| Step: 6
Training loss: 0.7707850933074951
Validation loss: 2.0158209505901543

Epoch: 6| Step: 7
Training loss: 1.655576229095459
Validation loss: 2.017667665276476

Epoch: 6| Step: 8
Training loss: 1.7291913032531738
Validation loss: 2.034685291269774

Epoch: 6| Step: 9
Training loss: 1.6187031269073486
Validation loss: 2.018313897553311

Epoch: 6| Step: 10
Training loss: 0.8815352916717529
Validation loss: 2.061193561041227

Epoch: 6| Step: 11
Training loss: 1.2638309001922607
Validation loss: 2.054903030395508

Epoch: 6| Step: 12
Training loss: 1.7802693843841553
Validation loss: 2.044426623211112

Epoch: 6| Step: 13
Training loss: 0.8764393329620361
Validation loss: 2.0273860731432514

Epoch: 411| Step: 0
Training loss: 1.3942546844482422
Validation loss: 2.048681902629073

Epoch: 6| Step: 1
Training loss: 1.413499116897583
Validation loss: 2.0323597333764516

Epoch: 6| Step: 2
Training loss: 1.671130657196045
Validation loss: 2.0518877916438605

Epoch: 6| Step: 3
Training loss: 1.0084147453308105
Validation loss: 2.009582147803358

Epoch: 6| Step: 4
Training loss: 1.4706172943115234
Validation loss: 2.039070229376516

Epoch: 6| Step: 5
Training loss: 1.3240020275115967
Validation loss: 2.01684675165402

Epoch: 6| Step: 6
Training loss: 1.4780277013778687
Validation loss: 2.0442442509435836

Epoch: 6| Step: 7
Training loss: 1.194779634475708
Validation loss: 2.040485878144541

Epoch: 6| Step: 8
Training loss: 1.7683773040771484
Validation loss: 2.0315448878913798

Epoch: 6| Step: 9
Training loss: 1.7142976522445679
Validation loss: 2.0633845342102872

Epoch: 6| Step: 10
Training loss: 1.1928400993347168
Validation loss: 2.0280751746187926

Epoch: 6| Step: 11
Training loss: 1.3010538816452026
Validation loss: 2.030475539545859

Epoch: 6| Step: 12
Training loss: 1.5461759567260742
Validation loss: 2.0550589843462874

Epoch: 6| Step: 13
Training loss: 1.9909591674804688
Validation loss: 2.0272581205573132

Epoch: 412| Step: 0
Training loss: 1.4902257919311523
Validation loss: 2.042301609951963

Epoch: 6| Step: 1
Training loss: 1.303727388381958
Validation loss: 2.0329331210864487

Epoch: 6| Step: 2
Training loss: 1.906450867652893
Validation loss: 2.040879790500928

Epoch: 6| Step: 3
Training loss: 1.3453205823898315
Validation loss: 2.0438300409624652

Epoch: 6| Step: 4
Training loss: 1.6694450378417969
Validation loss: 2.078276541925246

Epoch: 6| Step: 5
Training loss: 1.6173715591430664
Validation loss: 2.009782765501289

Epoch: 6| Step: 6
Training loss: 1.231216549873352
Validation loss: 2.022164590897099

Epoch: 6| Step: 7
Training loss: 1.5330040454864502
Validation loss: 2.027878035781204

Epoch: 6| Step: 8
Training loss: 1.5318936109542847
Validation loss: 2.0427422805499007

Epoch: 6| Step: 9
Training loss: 1.4342577457427979
Validation loss: 1.9858601247110674

Epoch: 6| Step: 10
Training loss: 1.267936110496521
Validation loss: 2.011954912575342

Epoch: 6| Step: 11
Training loss: 1.5188610553741455
Validation loss: 2.0298513238148024

Epoch: 6| Step: 12
Training loss: 1.1763848066329956
Validation loss: 2.043059056805026

Epoch: 6| Step: 13
Training loss: 1.1968495845794678
Validation loss: 2.021210934526177

Epoch: 413| Step: 0
Training loss: 1.0287742614746094
Validation loss: 2.0154180706188245

Epoch: 6| Step: 1
Training loss: 1.6856584548950195
Validation loss: 2.0223465452912035

Epoch: 6| Step: 2
Training loss: 0.8710082173347473
Validation loss: 1.9789375438485095

Epoch: 6| Step: 3
Training loss: 1.5955058336257935
Validation loss: 2.0674208825634373

Epoch: 6| Step: 4
Training loss: 1.584964394569397
Validation loss: 2.0645531992758475

Epoch: 6| Step: 5
Training loss: 1.1342270374298096
Validation loss: 2.067550530997656

Epoch: 6| Step: 6
Training loss: 1.622753620147705
Validation loss: 2.055267298093406

Epoch: 6| Step: 7
Training loss: 0.9902815222740173
Validation loss: 2.0523389923957085

Epoch: 6| Step: 8
Training loss: 1.0437631607055664
Validation loss: 2.0427627127657653

Epoch: 6| Step: 9
Training loss: 1.586892008781433
Validation loss: 1.9961339671124694

Epoch: 6| Step: 10
Training loss: 2.2399020195007324
Validation loss: 2.026743999091528

Epoch: 6| Step: 11
Training loss: 1.5630491971969604
Validation loss: 2.05730269288504

Epoch: 6| Step: 12
Training loss: 1.5388556718826294
Validation loss: 1.996627164143388

Epoch: 6| Step: 13
Training loss: 2.016036033630371
Validation loss: 1.9963579024038007

Epoch: 414| Step: 0
Training loss: 1.8044846057891846
Validation loss: 2.0515998153276342

Epoch: 6| Step: 1
Training loss: 2.078355073928833
Validation loss: 2.0474113777119625

Epoch: 6| Step: 2
Training loss: 1.3060109615325928
Validation loss: 2.086016854932231

Epoch: 6| Step: 3
Training loss: 1.684598445892334
Validation loss: 2.050846661290815

Epoch: 6| Step: 4
Training loss: 1.8428075313568115
Validation loss: 2.028515966989661

Epoch: 6| Step: 5
Training loss: 1.1124157905578613
Validation loss: 2.0405636090104298

Epoch: 6| Step: 6
Training loss: 1.2118563652038574
Validation loss: 2.0390488383590535

Epoch: 6| Step: 7
Training loss: 1.4900398254394531
Validation loss: 2.066575656655014

Epoch: 6| Step: 8
Training loss: 0.893183708190918
Validation loss: 1.998869421661541

Epoch: 6| Step: 9
Training loss: 0.9258077144622803
Validation loss: 1.996468154332971

Epoch: 6| Step: 10
Training loss: 1.7092528343200684
Validation loss: 2.018388735350742

Epoch: 6| Step: 11
Training loss: 1.3584253787994385
Validation loss: 1.9887785680832402

Epoch: 6| Step: 12
Training loss: 1.628842830657959
Validation loss: 2.032180254177381

Epoch: 6| Step: 13
Training loss: 0.8788426518440247
Validation loss: 1.979717739166752

Epoch: 415| Step: 0
Training loss: 1.4411232471466064
Validation loss: 1.9879908177160448

Epoch: 6| Step: 1
Training loss: 1.0165115594863892
Validation loss: 2.031924868142733

Epoch: 6| Step: 2
Training loss: 1.6376007795333862
Validation loss: 2.0554799982296523

Epoch: 6| Step: 3
Training loss: 2.074575424194336
Validation loss: 2.0667706920254614

Epoch: 6| Step: 4
Training loss: 1.2489731311798096
Validation loss: 2.0750731755328435

Epoch: 6| Step: 5
Training loss: 0.9229456782341003
Validation loss: 2.087056995719992

Epoch: 6| Step: 6
Training loss: 1.9226741790771484
Validation loss: 2.0820888178322905

Epoch: 6| Step: 7
Training loss: 1.242704153060913
Validation loss: 2.0666709946047876

Epoch: 6| Step: 8
Training loss: 1.856248140335083
Validation loss: 2.020282554370101

Epoch: 6| Step: 9
Training loss: 1.1257836818695068
Validation loss: 2.084607057673957

Epoch: 6| Step: 10
Training loss: 1.6454861164093018
Validation loss: 2.03697883441884

Epoch: 6| Step: 11
Training loss: 1.3392378091812134
Validation loss: 2.058489857181426

Epoch: 6| Step: 12
Training loss: 1.1007107496261597
Validation loss: 2.0671942503221574

Epoch: 6| Step: 13
Training loss: 2.401681900024414
Validation loss: 2.0096649585231656

Epoch: 416| Step: 0
Training loss: 1.2931997776031494
Validation loss: 2.009029067972655

Epoch: 6| Step: 1
Training loss: 1.4529873132705688
Validation loss: 2.0159727309339788

Epoch: 6| Step: 2
Training loss: 1.5610820055007935
Validation loss: 2.009294012541412

Epoch: 6| Step: 3
Training loss: 1.5196621417999268
Validation loss: 2.039541636743853

Epoch: 6| Step: 4
Training loss: 1.0357277393341064
Validation loss: 2.0396816922772314

Epoch: 6| Step: 5
Training loss: 1.866234540939331
Validation loss: 2.037859324486025

Epoch: 6| Step: 6
Training loss: 1.1802575588226318
Validation loss: 2.0035894737448743

Epoch: 6| Step: 7
Training loss: 1.333984613418579
Validation loss: 2.046516935030619

Epoch: 6| Step: 8
Training loss: 1.516535997390747
Validation loss: 2.0499393581062235

Epoch: 6| Step: 9
Training loss: 1.7603838443756104
Validation loss: 2.0375047294042443

Epoch: 6| Step: 10
Training loss: 1.6936503648757935
Validation loss: 2.024263407594414

Epoch: 6| Step: 11
Training loss: 1.5485374927520752
Validation loss: 2.0253702620024323

Epoch: 6| Step: 12
Training loss: 1.3682411909103394
Validation loss: 2.034840249246167

Epoch: 6| Step: 13
Training loss: 1.4656856060028076
Validation loss: 2.092474422147197

Epoch: 417| Step: 0
Training loss: 1.458277940750122
Validation loss: 2.0489193213883268

Epoch: 6| Step: 1
Training loss: 1.1721724271774292
Validation loss: 2.0494033021311604

Epoch: 6| Step: 2
Training loss: 1.4604154825210571
Validation loss: 2.050292925168109

Epoch: 6| Step: 3
Training loss: 1.215688705444336
Validation loss: 2.02290609318723

Epoch: 6| Step: 4
Training loss: 1.2537816762924194
Validation loss: 2.0017413516198435

Epoch: 6| Step: 5
Training loss: 1.953817367553711
Validation loss: 2.017524219328357

Epoch: 6| Step: 6
Training loss: 1.5521721839904785
Validation loss: 2.0421741624032297

Epoch: 6| Step: 7
Training loss: 1.2131872177124023
Validation loss: 2.0075080010198776

Epoch: 6| Step: 8
Training loss: 1.633852243423462
Validation loss: 2.0531012217203775

Epoch: 6| Step: 9
Training loss: 1.379459023475647
Validation loss: 2.016962323137509

Epoch: 6| Step: 10
Training loss: 0.9094281792640686
Validation loss: 1.9848501349008212

Epoch: 6| Step: 11
Training loss: 1.62990140914917
Validation loss: 2.073871192111764

Epoch: 6| Step: 12
Training loss: 1.8021365404129028
Validation loss: 1.9972209904783516

Epoch: 6| Step: 13
Training loss: 1.2028672695159912
Validation loss: 2.0152943390671925

Epoch: 418| Step: 0
Training loss: 2.310760974884033
Validation loss: 2.0346476621525262

Epoch: 6| Step: 1
Training loss: 1.750733494758606
Validation loss: 2.0331483528178227

Epoch: 6| Step: 2
Training loss: 1.0623221397399902
Validation loss: 2.073545689223915

Epoch: 6| Step: 3
Training loss: 1.4176864624023438
Validation loss: 2.0421528047130955

Epoch: 6| Step: 4
Training loss: 1.2413662672042847
Validation loss: 2.0856529820349907

Epoch: 6| Step: 5
Training loss: 1.523216724395752
Validation loss: 2.017672014492814

Epoch: 6| Step: 6
Training loss: 1.2870863676071167
Validation loss: 2.016322676853467

Epoch: 6| Step: 7
Training loss: 1.2585340738296509
Validation loss: 2.065068088552003

Epoch: 6| Step: 8
Training loss: 1.836451768875122
Validation loss: 2.0343357337418424

Epoch: 6| Step: 9
Training loss: 1.3225281238555908
Validation loss: 2.0181142694206646

Epoch: 6| Step: 10
Training loss: 1.1473298072814941
Validation loss: 2.0377904907349618

Epoch: 6| Step: 11
Training loss: 0.8763836026191711
Validation loss: 2.014123473116147

Epoch: 6| Step: 12
Training loss: 1.5887863636016846
Validation loss: 2.020688541473881

Epoch: 6| Step: 13
Training loss: 0.8989397883415222
Validation loss: 2.0716478132432505

Epoch: 419| Step: 0
Training loss: 1.3079981803894043
Validation loss: 2.0085230142839494

Epoch: 6| Step: 1
Training loss: 1.4213902950286865
Validation loss: 2.0483001419292983

Epoch: 6| Step: 2
Training loss: 1.605819821357727
Validation loss: 2.0095074574152627

Epoch: 6| Step: 3
Training loss: 1.200568675994873
Validation loss: 2.042049002903764

Epoch: 6| Step: 4
Training loss: 1.607630729675293
Validation loss: 2.050219161536104

Epoch: 6| Step: 5
Training loss: 2.0137453079223633
Validation loss: 2.04625702417025

Epoch: 6| Step: 6
Training loss: 1.658263921737671
Validation loss: 2.0130698424513622

Epoch: 6| Step: 7
Training loss: 1.3900127410888672
Validation loss: 1.9765252195378786

Epoch: 6| Step: 8
Training loss: 1.6772675514221191
Validation loss: 2.048324023523638

Epoch: 6| Step: 9
Training loss: 0.7892516851425171
Validation loss: 2.0627273282697125

Epoch: 6| Step: 10
Training loss: 1.1576042175292969
Validation loss: 2.040227456759381

Epoch: 6| Step: 11
Training loss: 1.2939682006835938
Validation loss: 2.0137890782407535

Epoch: 6| Step: 12
Training loss: 1.3183362483978271
Validation loss: 2.0670352161571546

Epoch: 6| Step: 13
Training loss: 1.971587896347046
Validation loss: 2.0677216104281846

Epoch: 420| Step: 0
Training loss: 1.0581477880477905
Validation loss: 2.0388260733696724

Epoch: 6| Step: 1
Training loss: 1.8103973865509033
Validation loss: 2.044901937566778

Epoch: 6| Step: 2
Training loss: 1.3122371435165405
Validation loss: 2.0612101529234197

Epoch: 6| Step: 3
Training loss: 1.506361484527588
Validation loss: 2.033863695718909

Epoch: 6| Step: 4
Training loss: 1.838943600654602
Validation loss: 2.073216107583815

Epoch: 6| Step: 5
Training loss: 1.3260116577148438
Validation loss: 2.050322332689839

Epoch: 6| Step: 6
Training loss: 1.1895477771759033
Validation loss: 2.0458600636451476

Epoch: 6| Step: 7
Training loss: 1.5693037509918213
Validation loss: 2.086687244394774

Epoch: 6| Step: 8
Training loss: 1.652667760848999
Validation loss: 2.0446542796268257

Epoch: 6| Step: 9
Training loss: 1.219590187072754
Validation loss: 2.0344477776558167

Epoch: 6| Step: 10
Training loss: 1.6896772384643555
Validation loss: 2.0535053360846733

Epoch: 6| Step: 11
Training loss: 1.288231372833252
Validation loss: 2.037727012429186

Epoch: 6| Step: 12
Training loss: 1.2272274494171143
Validation loss: 2.050037878815846

Epoch: 6| Step: 13
Training loss: 1.6107743978500366
Validation loss: 2.046269657791302

Epoch: 421| Step: 0
Training loss: 1.266890525817871
Validation loss: 2.0174944887879076

Epoch: 6| Step: 1
Training loss: 1.4571588039398193
Validation loss: 2.0141335392511017

Epoch: 6| Step: 2
Training loss: 1.4635732173919678
Validation loss: 2.040906902282469

Epoch: 6| Step: 3
Training loss: 1.8598759174346924
Validation loss: 2.0141813011579615

Epoch: 6| Step: 4
Training loss: 1.611804485321045
Validation loss: 2.0128125003589097

Epoch: 6| Step: 5
Training loss: 1.5684161186218262
Validation loss: 2.018466621316889

Epoch: 6| Step: 6
Training loss: 1.0835449695587158
Validation loss: 2.028443605669083

Epoch: 6| Step: 7
Training loss: 1.3017531633377075
Validation loss: 2.0231205058354202

Epoch: 6| Step: 8
Training loss: 1.133552074432373
Validation loss: 2.0211119574885212

Epoch: 6| Step: 9
Training loss: 1.2641352415084839
Validation loss: 2.0493061260510514

Epoch: 6| Step: 10
Training loss: 1.387803554534912
Validation loss: 2.0405696310022825

Epoch: 6| Step: 11
Training loss: 1.4314050674438477
Validation loss: 2.0402803100565428

Epoch: 6| Step: 12
Training loss: 1.5657007694244385
Validation loss: 2.0513333915382304

Epoch: 6| Step: 13
Training loss: 0.8907083868980408
Validation loss: 2.0539881875438075

Epoch: 422| Step: 0
Training loss: 1.2464460134506226
Validation loss: 2.0884423973739787

Epoch: 6| Step: 1
Training loss: 1.4355374574661255
Validation loss: 2.0280844601251746

Epoch: 6| Step: 2
Training loss: 0.9170941114425659
Validation loss: 2.0212501761733845

Epoch: 6| Step: 3
Training loss: 1.4312405586242676
Validation loss: 2.0366769195884786

Epoch: 6| Step: 4
Training loss: 1.71860671043396
Validation loss: 2.0360444053526847

Epoch: 6| Step: 5
Training loss: 1.3156602382659912
Validation loss: 2.026304065540273

Epoch: 6| Step: 6
Training loss: 1.5138458013534546
Validation loss: 2.061543813315771

Epoch: 6| Step: 7
Training loss: 2.047430992126465
Validation loss: 2.0350075075703282

Epoch: 6| Step: 8
Training loss: 2.2697789669036865
Validation loss: 2.000258707231091

Epoch: 6| Step: 9
Training loss: 1.4317375421524048
Validation loss: 2.0100710686816963

Epoch: 6| Step: 10
Training loss: 0.6628915071487427
Validation loss: 2.044892203423285

Epoch: 6| Step: 11
Training loss: 1.8627214431762695
Validation loss: 2.046355519243466

Epoch: 6| Step: 12
Training loss: 0.8026653528213501
Validation loss: 2.012219226488503

Epoch: 6| Step: 13
Training loss: 1.4508473873138428
Validation loss: 2.0240977682093138

Epoch: 423| Step: 0
Training loss: 0.984265923500061
Validation loss: 2.063772806557276

Epoch: 6| Step: 1
Training loss: 1.9155335426330566
Validation loss: 2.0187928586877804

Epoch: 6| Step: 2
Training loss: 1.3640488386154175
Validation loss: 2.031238837908673

Epoch: 6| Step: 3
Training loss: 1.6604036092758179
Validation loss: 2.0358562136209137

Epoch: 6| Step: 4
Training loss: 1.177870512008667
Validation loss: 2.055046481470908

Epoch: 6| Step: 5
Training loss: 1.5182983875274658
Validation loss: 2.0547945089237665

Epoch: 6| Step: 6
Training loss: 1.0101120471954346
Validation loss: 2.027052502478323

Epoch: 6| Step: 7
Training loss: 1.20864999294281
Validation loss: 2.064775215682163

Epoch: 6| Step: 8
Training loss: 2.571928024291992
Validation loss: 2.04694216738465

Epoch: 6| Step: 9
Training loss: 1.9247655868530273
Validation loss: 2.051887826253009

Epoch: 6| Step: 10
Training loss: 1.0431684255599976
Validation loss: 2.041169656220303

Epoch: 6| Step: 11
Training loss: 0.9372156858444214
Validation loss: 2.0009778366293958

Epoch: 6| Step: 12
Training loss: 1.3529186248779297
Validation loss: 2.034419023862449

Epoch: 6| Step: 13
Training loss: 1.1694331169128418
Validation loss: 2.047462845361361

Epoch: 424| Step: 0
Training loss: 0.9993435144424438
Validation loss: 1.9747470655748922

Epoch: 6| Step: 1
Training loss: 1.485005259513855
Validation loss: 2.0187372340950915

Epoch: 6| Step: 2
Training loss: 1.674782633781433
Validation loss: 2.0098887066687308

Epoch: 6| Step: 3
Training loss: 1.511784315109253
Validation loss: 2.0058440239198747

Epoch: 6| Step: 4
Training loss: 1.2591050863265991
Validation loss: 2.022156492356331

Epoch: 6| Step: 5
Training loss: 1.5608824491500854
Validation loss: 2.031343303700929

Epoch: 6| Step: 6
Training loss: 1.3083950281143188
Validation loss: 2.0292399878142984

Epoch: 6| Step: 7
Training loss: 1.2697991132736206
Validation loss: 2.0817213161017305

Epoch: 6| Step: 8
Training loss: 1.080680012702942
Validation loss: 2.0515450264817927

Epoch: 6| Step: 9
Training loss: 1.2953956127166748
Validation loss: 2.0288937630191928

Epoch: 6| Step: 10
Training loss: 0.8121145367622375
Validation loss: 2.050398229270853

Epoch: 6| Step: 11
Training loss: 2.259700298309326
Validation loss: 2.0722610283923406

Epoch: 6| Step: 12
Training loss: 1.7435916662216187
Validation loss: 2.0918130772088164

Epoch: 6| Step: 13
Training loss: 1.8846937417984009
Validation loss: 2.062585688406421

Epoch: 425| Step: 0
Training loss: 1.4430441856384277
Validation loss: 2.0677390124208186

Epoch: 6| Step: 1
Training loss: 1.3027446269989014
Validation loss: 2.017899105625768

Epoch: 6| Step: 2
Training loss: 1.6677300930023193
Validation loss: 2.036460348354873

Epoch: 6| Step: 3
Training loss: 1.183079481124878
Validation loss: 2.0617752088013517

Epoch: 6| Step: 4
Training loss: 1.9341943264007568
Validation loss: 2.016792047408319

Epoch: 6| Step: 5
Training loss: 1.9961695671081543
Validation loss: 2.0378922211226596

Epoch: 6| Step: 6
Training loss: 0.9589260816574097
Validation loss: 2.001402779292035

Epoch: 6| Step: 7
Training loss: 0.9986622333526611
Validation loss: 2.0193817025871685

Epoch: 6| Step: 8
Training loss: 2.091085910797119
Validation loss: 2.007952654233543

Epoch: 6| Step: 9
Training loss: 1.164527416229248
Validation loss: 2.012295796025184

Epoch: 6| Step: 10
Training loss: 1.460843563079834
Validation loss: 2.017062202576668

Epoch: 6| Step: 11
Training loss: 1.4190270900726318
Validation loss: 2.006549027658278

Epoch: 6| Step: 12
Training loss: 0.9325441122055054
Validation loss: 1.9758392008402015

Epoch: 6| Step: 13
Training loss: 1.385308027267456
Validation loss: 2.047602302284651

Epoch: 426| Step: 0
Training loss: 1.1385780572891235
Validation loss: 2.057524715700457

Epoch: 6| Step: 1
Training loss: 1.621802806854248
Validation loss: 2.015990626427435

Epoch: 6| Step: 2
Training loss: 1.5323551893234253
Validation loss: 2.013187377683578

Epoch: 6| Step: 3
Training loss: 1.2494667768478394
Validation loss: 2.033934485527777

Epoch: 6| Step: 4
Training loss: 1.4660886526107788
Validation loss: 2.090007548691124

Epoch: 6| Step: 5
Training loss: 1.022707223892212
Validation loss: 2.0284157799136255

Epoch: 6| Step: 6
Training loss: 1.4506537914276123
Validation loss: 2.0087945666364444

Epoch: 6| Step: 7
Training loss: 1.7615827322006226
Validation loss: 2.0623487400752243

Epoch: 6| Step: 8
Training loss: 1.1564176082611084
Validation loss: 2.0493028856092885

Epoch: 6| Step: 9
Training loss: 1.683301568031311
Validation loss: 2.052381906458127

Epoch: 6| Step: 10
Training loss: 1.235698938369751
Validation loss: 2.0720815658569336

Epoch: 6| Step: 11
Training loss: 1.597804069519043
Validation loss: 2.017631633307344

Epoch: 6| Step: 12
Training loss: 1.9050878286361694
Validation loss: 2.0531481004530385

Epoch: 6| Step: 13
Training loss: 1.0945326089859009
Validation loss: 2.044609013424125

Epoch: 427| Step: 0
Training loss: 1.0104665756225586
Validation loss: 2.023339348454629

Epoch: 6| Step: 1
Training loss: 1.5547902584075928
Validation loss: 2.0550103918198617

Epoch: 6| Step: 2
Training loss: 1.3755680322647095
Validation loss: 2.0103668333381735

Epoch: 6| Step: 3
Training loss: 0.9108672142028809
Validation loss: 2.009057573092881

Epoch: 6| Step: 4
Training loss: 1.6613811254501343
Validation loss: 2.0532357769627727

Epoch: 6| Step: 5
Training loss: 1.4886128902435303
Validation loss: 2.012542078571935

Epoch: 6| Step: 6
Training loss: 1.9400851726531982
Validation loss: 2.0368274155483452

Epoch: 6| Step: 7
Training loss: 1.374124526977539
Validation loss: 2.058447548138198

Epoch: 6| Step: 8
Training loss: 1.1549153327941895
Validation loss: 2.0211215788318264

Epoch: 6| Step: 9
Training loss: 1.7553930282592773
Validation loss: 2.0508129032709266

Epoch: 6| Step: 10
Training loss: 1.2158174514770508
Validation loss: 1.9969771869720951

Epoch: 6| Step: 11
Training loss: 0.7588835954666138
Validation loss: 2.054596375393611

Epoch: 6| Step: 12
Training loss: 2.089888572692871
Validation loss: 2.007557906130309

Epoch: 6| Step: 13
Training loss: 1.4573734998703003
Validation loss: 2.0256217987306657

Epoch: 428| Step: 0
Training loss: 1.5475027561187744
Validation loss: 2.064229175608645

Epoch: 6| Step: 1
Training loss: 0.8399171233177185
Validation loss: 2.0710412045960784

Epoch: 6| Step: 2
Training loss: 1.4123387336730957
Validation loss: 2.053753601607456

Epoch: 6| Step: 3
Training loss: 2.2077128887176514
Validation loss: 2.0256239573160806

Epoch: 6| Step: 4
Training loss: 1.3938512802124023
Validation loss: 2.0414479958113803

Epoch: 6| Step: 5
Training loss: 1.6222318410873413
Validation loss: 2.0532376561113583

Epoch: 6| Step: 6
Training loss: 1.4923303127288818
Validation loss: 2.0693712413951917

Epoch: 6| Step: 7
Training loss: 1.3113898038864136
Validation loss: 2.0201921745013167

Epoch: 6| Step: 8
Training loss: 1.7257345914840698
Validation loss: 2.059836754234888

Epoch: 6| Step: 9
Training loss: 1.182663917541504
Validation loss: 2.0532040288371425

Epoch: 6| Step: 10
Training loss: 1.9513359069824219
Validation loss: 2.0874401728312173

Epoch: 6| Step: 11
Training loss: 1.1443235874176025
Validation loss: 2.0285490135992728

Epoch: 6| Step: 12
Training loss: 1.1665631532669067
Validation loss: 2.060350928255307

Epoch: 6| Step: 13
Training loss: 0.7717292308807373
Validation loss: 2.027596022493096

Epoch: 429| Step: 0
Training loss: 2.317749261856079
Validation loss: 2.024742626374768

Epoch: 6| Step: 1
Training loss: 1.1904761791229248
Validation loss: 2.045500627128027

Epoch: 6| Step: 2
Training loss: 2.2141621112823486
Validation loss: 1.999057464702155

Epoch: 6| Step: 3
Training loss: 1.0934407711029053
Validation loss: 1.9967343973857101

Epoch: 6| Step: 4
Training loss: 1.5054292678833008
Validation loss: 2.0440058823554748

Epoch: 6| Step: 5
Training loss: 1.1362736225128174
Validation loss: 2.0565823355028705

Epoch: 6| Step: 6
Training loss: 1.4190919399261475
Validation loss: 2.0488137711760817

Epoch: 6| Step: 7
Training loss: 0.9688180685043335
Validation loss: 2.0121349570571736

Epoch: 6| Step: 8
Training loss: 1.1952505111694336
Validation loss: 1.9972044421780495

Epoch: 6| Step: 9
Training loss: 1.1776400804519653
Validation loss: 2.0316132524962067

Epoch: 6| Step: 10
Training loss: 1.3534584045410156
Validation loss: 1.998910250202302

Epoch: 6| Step: 11
Training loss: 1.397327184677124
Validation loss: 2.031910611737159

Epoch: 6| Step: 12
Training loss: 1.6569550037384033
Validation loss: 2.0589504139397734

Epoch: 6| Step: 13
Training loss: 1.0373376607894897
Validation loss: 2.00271785900157

Epoch: 430| Step: 0
Training loss: 1.0042188167572021
Validation loss: 2.0505550766503937

Epoch: 6| Step: 1
Training loss: 1.8182796239852905
Validation loss: 2.0246137213963333

Epoch: 6| Step: 2
Training loss: 1.3766672611236572
Validation loss: 2.039738219271424

Epoch: 6| Step: 3
Training loss: 1.4082655906677246
Validation loss: 2.0197886010651946

Epoch: 6| Step: 4
Training loss: 1.1334608793258667
Validation loss: 2.08326768490576

Epoch: 6| Step: 5
Training loss: 1.2425925731658936
Validation loss: 2.01898023902729

Epoch: 6| Step: 6
Training loss: 1.5778683423995972
Validation loss: 2.0418638952316774

Epoch: 6| Step: 7
Training loss: 1.6646714210510254
Validation loss: 2.03844779281206

Epoch: 6| Step: 8
Training loss: 1.477024793624878
Validation loss: 2.045140658655474

Epoch: 6| Step: 9
Training loss: 1.1007781028747559
Validation loss: 2.018413551392094

Epoch: 6| Step: 10
Training loss: 1.7640700340270996
Validation loss: 2.0190286174897225

Epoch: 6| Step: 11
Training loss: 1.3896121978759766
Validation loss: 2.0098777701777797

Epoch: 6| Step: 12
Training loss: 1.2861536741256714
Validation loss: 2.063470144425669

Epoch: 6| Step: 13
Training loss: 2.0748348236083984
Validation loss: 2.0265402665702243

Epoch: 431| Step: 0
Training loss: 1.422286868095398
Validation loss: 2.0104766366302327

Epoch: 6| Step: 1
Training loss: 1.6921223402023315
Validation loss: 2.03223245118254

Epoch: 6| Step: 2
Training loss: 1.2538456916809082
Validation loss: 1.9942791615763018

Epoch: 6| Step: 3
Training loss: 1.617516040802002
Validation loss: 2.036882513312883

Epoch: 6| Step: 4
Training loss: 1.1611825227737427
Validation loss: 2.028220735570436

Epoch: 6| Step: 5
Training loss: 1.6483557224273682
Validation loss: 1.9717877731528333

Epoch: 6| Step: 6
Training loss: 1.785125494003296
Validation loss: 2.0224128615471626

Epoch: 6| Step: 7
Training loss: 0.9865648746490479
Validation loss: 2.0248753101594987

Epoch: 6| Step: 8
Training loss: 1.9391454458236694
Validation loss: 2.0370278640459945

Epoch: 6| Step: 9
Training loss: 1.4020142555236816
Validation loss: 2.080138989674148

Epoch: 6| Step: 10
Training loss: 0.6815240979194641
Validation loss: 2.036479027040543

Epoch: 6| Step: 11
Training loss: 1.3301076889038086
Validation loss: 2.0083523693905083

Epoch: 6| Step: 12
Training loss: 0.8028867244720459
Validation loss: 2.0382964175234557

Epoch: 6| Step: 13
Training loss: 2.3240644931793213
Validation loss: 2.0756144549257014

Epoch: 432| Step: 0
Training loss: 1.2839488983154297
Validation loss: 2.0921749043208298

Epoch: 6| Step: 1
Training loss: 1.2642736434936523
Validation loss: 2.0309871678711264

Epoch: 6| Step: 2
Training loss: 1.7964788675308228
Validation loss: 2.0874972369081233

Epoch: 6| Step: 3
Training loss: 1.5352863073349
Validation loss: 2.065084788107103

Epoch: 6| Step: 4
Training loss: 1.4873517751693726
Validation loss: 2.015405342143069

Epoch: 6| Step: 5
Training loss: 1.3674598932266235
Validation loss: 2.085343409610051

Epoch: 6| Step: 6
Training loss: 1.11329984664917
Validation loss: 2.036980140593744

Epoch: 6| Step: 7
Training loss: 1.352189302444458
Validation loss: 2.0437273953550603

Epoch: 6| Step: 8
Training loss: 1.02436363697052
Validation loss: 2.042445335336911

Epoch: 6| Step: 9
Training loss: 1.635010838508606
Validation loss: 2.0646322273438975

Epoch: 6| Step: 10
Training loss: 0.9825992584228516
Validation loss: 2.028703015337708

Epoch: 6| Step: 11
Training loss: 2.380034923553467
Validation loss: 1.9960176739641415

Epoch: 6| Step: 12
Training loss: 1.4359225034713745
Validation loss: 2.059538872011246

Epoch: 6| Step: 13
Training loss: 0.9121574759483337
Validation loss: 2.028026170628045

Epoch: 433| Step: 0
Training loss: 1.3361294269561768
Validation loss: 2.0351161623513825

Epoch: 6| Step: 1
Training loss: 1.919691562652588
Validation loss: 2.0391017519017702

Epoch: 6| Step: 2
Training loss: 1.7793128490447998
Validation loss: 2.0158259862212726

Epoch: 6| Step: 3
Training loss: 1.4230639934539795
Validation loss: 2.073805983348559

Epoch: 6| Step: 4
Training loss: 2.0067741870880127
Validation loss: 2.036773371440108

Epoch: 6| Step: 5
Training loss: 1.332280158996582
Validation loss: 2.0244848369270243

Epoch: 6| Step: 6
Training loss: 1.175370693206787
Validation loss: 2.057507679026614

Epoch: 6| Step: 7
Training loss: 1.8594176769256592
Validation loss: 1.9886328686950028

Epoch: 6| Step: 8
Training loss: 0.8025252819061279
Validation loss: 2.0642074384996967

Epoch: 6| Step: 9
Training loss: 1.6516010761260986
Validation loss: 2.0604108482278805

Epoch: 6| Step: 10
Training loss: 1.1885607242584229
Validation loss: 2.061506530290009

Epoch: 6| Step: 11
Training loss: 0.9892714619636536
Validation loss: 2.0380318318643877

Epoch: 6| Step: 12
Training loss: 0.8455467224121094
Validation loss: 2.042252640570364

Epoch: 6| Step: 13
Training loss: 1.5222989320755005
Validation loss: 2.0369900324011363

Epoch: 434| Step: 0
Training loss: 1.3582127094268799
Validation loss: 2.0197012309105165

Epoch: 6| Step: 1
Training loss: 1.6458593606948853
Validation loss: 2.026773513004344

Epoch: 6| Step: 2
Training loss: 1.8068044185638428
Validation loss: 2.0287262880673973

Epoch: 6| Step: 3
Training loss: 1.2496192455291748
Validation loss: 2.061400890350342

Epoch: 6| Step: 4
Training loss: 1.9933934211730957
Validation loss: 2.0650511172509964

Epoch: 6| Step: 5
Training loss: 1.6920206546783447
Validation loss: 2.0246360968518

Epoch: 6| Step: 6
Training loss: 1.2529840469360352
Validation loss: 2.0453969547825475

Epoch: 6| Step: 7
Training loss: 0.777686595916748
Validation loss: 2.0372579943749214

Epoch: 6| Step: 8
Training loss: 1.078250527381897
Validation loss: 2.006797029126075

Epoch: 6| Step: 9
Training loss: 1.1579546928405762
Validation loss: 1.9983675902889622

Epoch: 6| Step: 10
Training loss: 1.0791733264923096
Validation loss: 2.0031484609009116

Epoch: 6| Step: 11
Training loss: 1.6355233192443848
Validation loss: 2.0201573474432832

Epoch: 6| Step: 12
Training loss: 1.2529411315917969
Validation loss: 1.9936807181245537

Epoch: 6| Step: 13
Training loss: 1.896228551864624
Validation loss: 2.03135787158884

Epoch: 435| Step: 0
Training loss: 0.7290365695953369
Validation loss: 2.03191513399924

Epoch: 6| Step: 1
Training loss: 1.3584308624267578
Validation loss: 2.052824571568479

Epoch: 6| Step: 2
Training loss: 1.4987528324127197
Validation loss: 2.0435714055133123

Epoch: 6| Step: 3
Training loss: 1.0661027431488037
Validation loss: 2.085050917440845

Epoch: 6| Step: 4
Training loss: 1.5816287994384766
Validation loss: 2.0458213770261375

Epoch: 6| Step: 5
Training loss: 1.0035080909729004
Validation loss: 2.055350031903995

Epoch: 6| Step: 6
Training loss: 2.145827293395996
Validation loss: 2.064297465867894

Epoch: 6| Step: 7
Training loss: 1.909109354019165
Validation loss: 2.035254269517878

Epoch: 6| Step: 8
Training loss: 1.298545002937317
Validation loss: 2.0602631415090253

Epoch: 6| Step: 9
Training loss: 1.4329341650009155
Validation loss: 2.0034487324376262

Epoch: 6| Step: 10
Training loss: 0.9304320216178894
Validation loss: 2.068525650167978

Epoch: 6| Step: 11
Training loss: 1.417476773262024
Validation loss: 2.045823471520537

Epoch: 6| Step: 12
Training loss: 2.3737220764160156
Validation loss: 2.0118576647132955

Epoch: 6| Step: 13
Training loss: 0.6353160738945007
Validation loss: 2.0280614206867833

Epoch: 436| Step: 0
Training loss: 1.3037394285202026
Validation loss: 2.00923397720501

Epoch: 6| Step: 1
Training loss: 1.3772640228271484
Validation loss: 2.029343948569349

Epoch: 6| Step: 2
Training loss: 0.8582278490066528
Validation loss: 2.0160417877217776

Epoch: 6| Step: 3
Training loss: 1.5253608226776123
Validation loss: 2.036564919256395

Epoch: 6| Step: 4
Training loss: 1.4569860696792603
Validation loss: 2.0190290815086773

Epoch: 6| Step: 5
Training loss: 1.244154691696167
Validation loss: 2.018183753054629

Epoch: 6| Step: 6
Training loss: 1.466496467590332
Validation loss: 2.0297248696768158

Epoch: 6| Step: 7
Training loss: 1.5276398658752441
Validation loss: 2.0227062253541845

Epoch: 6| Step: 8
Training loss: 1.3084802627563477
Validation loss: 2.0014133325187107

Epoch: 6| Step: 9
Training loss: 1.4418679475784302
Validation loss: 1.9981791409113074

Epoch: 6| Step: 10
Training loss: 1.621969223022461
Validation loss: 2.06321354322536

Epoch: 6| Step: 11
Training loss: 1.7852795124053955
Validation loss: 2.015751459265268

Epoch: 6| Step: 12
Training loss: 0.8938578367233276
Validation loss: 1.9848365822146017

Epoch: 6| Step: 13
Training loss: 1.483545184135437
Validation loss: 2.002207984206497

Epoch: 437| Step: 0
Training loss: 0.8598402738571167
Validation loss: 2.0400658115263908

Epoch: 6| Step: 1
Training loss: 1.8428653478622437
Validation loss: 2.025642380919508

Epoch: 6| Step: 2
Training loss: 1.5766878128051758
Validation loss: 2.040095160084386

Epoch: 6| Step: 3
Training loss: 1.9222891330718994
Validation loss: 2.0037201309716828

Epoch: 6| Step: 4
Training loss: 1.1880288124084473
Validation loss: 2.088861834618353

Epoch: 6| Step: 5
Training loss: 1.589318871498108
Validation loss: 2.033481728646063

Epoch: 6| Step: 6
Training loss: 2.1075830459594727
Validation loss: 2.043819821009072

Epoch: 6| Step: 7
Training loss: 1.0373895168304443
Validation loss: 1.9956809602757937

Epoch: 6| Step: 8
Training loss: 0.955980122089386
Validation loss: 2.010667888067102

Epoch: 6| Step: 9
Training loss: 1.0903491973876953
Validation loss: 2.002272775096278

Epoch: 6| Step: 10
Training loss: 1.6609654426574707
Validation loss: 2.0353351510981077

Epoch: 6| Step: 11
Training loss: 1.3863683938980103
Validation loss: 2.0531740509053713

Epoch: 6| Step: 12
Training loss: 0.9688147306442261
Validation loss: 2.026295195343674

Epoch: 6| Step: 13
Training loss: 1.070207118988037
Validation loss: 2.0064040332712154

Epoch: 438| Step: 0
Training loss: 1.4788711071014404
Validation loss: 2.0342640492223922

Epoch: 6| Step: 1
Training loss: 1.4231057167053223
Validation loss: 2.0267897921223796

Epoch: 6| Step: 2
Training loss: 1.802653193473816
Validation loss: 2.0120887269255934

Epoch: 6| Step: 3
Training loss: 1.18804931640625
Validation loss: 2.075350023085071

Epoch: 6| Step: 4
Training loss: 1.1728620529174805
Validation loss: 2.0275577229838215

Epoch: 6| Step: 5
Training loss: 1.0484066009521484
Validation loss: 2.0256160818120486

Epoch: 6| Step: 6
Training loss: 1.4391937255859375
Validation loss: 2.021699572122225

Epoch: 6| Step: 7
Training loss: 1.536870002746582
Validation loss: 1.9975964664131083

Epoch: 6| Step: 8
Training loss: 1.1143962144851685
Validation loss: 2.0298730532328286

Epoch: 6| Step: 9
Training loss: 1.2642385959625244
Validation loss: 2.035449078006129

Epoch: 6| Step: 10
Training loss: 1.2104203701019287
Validation loss: 2.007626098971213

Epoch: 6| Step: 11
Training loss: 1.5757744312286377
Validation loss: 2.027175969974969

Epoch: 6| Step: 12
Training loss: 1.5775036811828613
Validation loss: 2.041579632348912

Epoch: 6| Step: 13
Training loss: 1.4920326471328735
Validation loss: 2.0222302252246487

Epoch: 439| Step: 0
Training loss: 1.189581036567688
Validation loss: 2.077381177615094

Epoch: 6| Step: 1
Training loss: 1.2425909042358398
Validation loss: 2.0650191999250844

Epoch: 6| Step: 2
Training loss: 0.956836462020874
Validation loss: 2.036588071494974

Epoch: 6| Step: 3
Training loss: 2.253575325012207
Validation loss: 1.9838332745336718

Epoch: 6| Step: 4
Training loss: 1.0993967056274414
Validation loss: 2.0688420957134617

Epoch: 6| Step: 5
Training loss: 0.9788841605186462
Validation loss: 2.0028291120324084

Epoch: 6| Step: 6
Training loss: 1.9682598114013672
Validation loss: 2.016242919429656

Epoch: 6| Step: 7
Training loss: 1.4500880241394043
Validation loss: 2.014377628603289

Epoch: 6| Step: 8
Training loss: 2.049386978149414
Validation loss: 2.039525757553757

Epoch: 6| Step: 9
Training loss: 0.7923668026924133
Validation loss: 1.9782204615172518

Epoch: 6| Step: 10
Training loss: 1.363157033920288
Validation loss: 1.9898956796174407

Epoch: 6| Step: 11
Training loss: 0.9572134017944336
Validation loss: 2.0556141355986237

Epoch: 6| Step: 12
Training loss: 1.9037818908691406
Validation loss: 1.99962027483089

Epoch: 6| Step: 13
Training loss: 1.2686872482299805
Validation loss: 2.0297715125545377

Epoch: 440| Step: 0
Training loss: 1.4940212965011597
Validation loss: 2.0465127755236883

Epoch: 6| Step: 1
Training loss: 1.757409691810608
Validation loss: 2.0208949260814215

Epoch: 6| Step: 2
Training loss: 0.8861671090126038
Validation loss: 2.029241813126431

Epoch: 6| Step: 3
Training loss: 1.3355400562286377
Validation loss: 2.007376265782182

Epoch: 6| Step: 4
Training loss: 1.025465965270996
Validation loss: 2.016905011669282

Epoch: 6| Step: 5
Training loss: 1.3270270824432373
Validation loss: 2.002457530267777

Epoch: 6| Step: 6
Training loss: 1.36666738986969
Validation loss: 2.044299976800078

Epoch: 6| Step: 7
Training loss: 1.260480523109436
Validation loss: 2.0555687322411487

Epoch: 6| Step: 8
Training loss: 1.2064393758773804
Validation loss: 1.988218492077243

Epoch: 6| Step: 9
Training loss: 1.8753561973571777
Validation loss: 2.041814399021928

Epoch: 6| Step: 10
Training loss: 1.4620652198791504
Validation loss: 2.0081174629990772

Epoch: 6| Step: 11
Training loss: 1.041398525238037
Validation loss: 2.0793793816720285

Epoch: 6| Step: 12
Training loss: 1.5660903453826904
Validation loss: 2.039729354202106

Epoch: 6| Step: 13
Training loss: 1.3735122680664062
Validation loss: 2.007387976492605

Epoch: 441| Step: 0
Training loss: 1.1137440204620361
Validation loss: 2.0526050265117357

Epoch: 6| Step: 1
Training loss: 1.3221871852874756
Validation loss: 2.005341513182527

Epoch: 6| Step: 2
Training loss: 1.406710147857666
Validation loss: 2.0418539098514024

Epoch: 6| Step: 3
Training loss: 1.5493842363357544
Validation loss: 2.0609917166412517

Epoch: 6| Step: 4
Training loss: 0.7847099304199219
Validation loss: 2.055242489742976

Epoch: 6| Step: 5
Training loss: 1.1043782234191895
Validation loss: 2.0341575735358783

Epoch: 6| Step: 6
Training loss: 1.1065363883972168
Validation loss: 2.0353932970313617

Epoch: 6| Step: 7
Training loss: 1.3383160829544067
Validation loss: 2.0040643445907103

Epoch: 6| Step: 8
Training loss: 1.8332546949386597
Validation loss: 2.0382480749519925

Epoch: 6| Step: 9
Training loss: 1.942584753036499
Validation loss: 2.0441933831860943

Epoch: 6| Step: 10
Training loss: 1.1201353073120117
Validation loss: 2.029391798921811

Epoch: 6| Step: 11
Training loss: 1.4939777851104736
Validation loss: 2.036918665773125

Epoch: 6| Step: 12
Training loss: 1.722402572631836
Validation loss: 2.0382161371169554

Epoch: 6| Step: 13
Training loss: 1.644152283668518
Validation loss: 2.0472989159245647

Epoch: 442| Step: 0
Training loss: 1.3529026508331299
Validation loss: 2.0492384779837822

Epoch: 6| Step: 1
Training loss: 1.6508674621582031
Validation loss: 2.0549060349823325

Epoch: 6| Step: 2
Training loss: 1.0902377367019653
Validation loss: 2.0292293589602233

Epoch: 6| Step: 3
Training loss: 1.1776057481765747
Validation loss: 2.008567969004313

Epoch: 6| Step: 4
Training loss: 1.0584057569503784
Validation loss: 2.02213333242683

Epoch: 6| Step: 5
Training loss: 1.5396008491516113
Validation loss: 2.0280546270390993

Epoch: 6| Step: 6
Training loss: 0.7922191619873047
Validation loss: 1.974941720244705

Epoch: 6| Step: 7
Training loss: 0.9011364579200745
Validation loss: 1.997692624727885

Epoch: 6| Step: 8
Training loss: 2.343881607055664
Validation loss: 2.0453796322627733

Epoch: 6| Step: 9
Training loss: 1.6259013414382935
Validation loss: 2.0301779931591404

Epoch: 6| Step: 10
Training loss: 0.8616493940353394
Validation loss: 2.0464793789771294

Epoch: 6| Step: 11
Training loss: 2.090362071990967
Validation loss: 2.0554829233436176

Epoch: 6| Step: 12
Training loss: 1.2442706823349
Validation loss: 2.0336171042534614

Epoch: 6| Step: 13
Training loss: 1.4053856134414673
Validation loss: 2.0317606438872633

Epoch: 443| Step: 0
Training loss: 1.5026195049285889
Validation loss: 2.0129403388628395

Epoch: 6| Step: 1
Training loss: 1.426592469215393
Validation loss: 2.0254600253156436

Epoch: 6| Step: 2
Training loss: 1.6312978267669678
Validation loss: 2.024720007373441

Epoch: 6| Step: 3
Training loss: 0.9756121039390564
Validation loss: 2.0521279663167973

Epoch: 6| Step: 4
Training loss: 1.5670913457870483
Validation loss: 1.9931308761719735

Epoch: 6| Step: 5
Training loss: 1.0519665479660034
Validation loss: 2.037703983245357

Epoch: 6| Step: 6
Training loss: 1.241805076599121
Validation loss: 2.067183335622152

Epoch: 6| Step: 7
Training loss: 1.2002907991409302
Validation loss: 2.073076794224401

Epoch: 6| Step: 8
Training loss: 1.0705937147140503
Validation loss: 2.0194479175793227

Epoch: 6| Step: 9
Training loss: 2.170595645904541
Validation loss: 2.0406940444823234

Epoch: 6| Step: 10
Training loss: 1.7777364253997803
Validation loss: 2.062151778128839

Epoch: 6| Step: 11
Training loss: 0.9665354490280151
Validation loss: 2.0373400360025387

Epoch: 6| Step: 12
Training loss: 1.775820016860962
Validation loss: 2.043682329116329

Epoch: 6| Step: 13
Training loss: 1.1626428365707397
Validation loss: 2.009883020513801

Epoch: 444| Step: 0
Training loss: 1.529122233390808
Validation loss: 2.0308399020984607

Epoch: 6| Step: 1
Training loss: 1.9508283138275146
Validation loss: 2.029811554057624

Epoch: 6| Step: 2
Training loss: 1.099207878112793
Validation loss: 2.02784025925462

Epoch: 6| Step: 3
Training loss: 1.6313893795013428
Validation loss: 2.0796210535110964

Epoch: 6| Step: 4
Training loss: 1.5647053718566895
Validation loss: 2.0079731351585797

Epoch: 6| Step: 5
Training loss: 1.0027551651000977
Validation loss: 2.0438030124992452

Epoch: 6| Step: 6
Training loss: 1.2552566528320312
Validation loss: 2.02368119583335

Epoch: 6| Step: 7
Training loss: 1.1492345333099365
Validation loss: 2.054419767472052

Epoch: 6| Step: 8
Training loss: 1.1756073236465454
Validation loss: 2.0355790853500366

Epoch: 6| Step: 9
Training loss: 0.7689476013183594
Validation loss: 2.0449748321246077

Epoch: 6| Step: 10
Training loss: 1.0041780471801758
Validation loss: 2.046933932970929

Epoch: 6| Step: 11
Training loss: 2.143385171890259
Validation loss: 2.054282498616044

Epoch: 6| Step: 12
Training loss: 1.3335351943969727
Validation loss: 2.0615631508570846

Epoch: 6| Step: 13
Training loss: 1.9556431770324707
Validation loss: 2.0349682825867847

Epoch: 445| Step: 0
Training loss: 1.0675830841064453
Validation loss: 2.052106738090515

Epoch: 6| Step: 1
Training loss: 1.9196032285690308
Validation loss: 2.077540010534307

Epoch: 6| Step: 2
Training loss: 1.2438563108444214
Validation loss: 2.0623758185294365

Epoch: 6| Step: 3
Training loss: 1.2796030044555664
Validation loss: 2.067790357015466

Epoch: 6| Step: 4
Training loss: 1.2212603092193604
Validation loss: 2.033032815943482

Epoch: 6| Step: 5
Training loss: 1.0704469680786133
Validation loss: 2.01368510723114

Epoch: 6| Step: 6
Training loss: 1.1356885433197021
Validation loss: 2.045888049628145

Epoch: 6| Step: 7
Training loss: 1.3940963745117188
Validation loss: 2.1083567988487983

Epoch: 6| Step: 8
Training loss: 1.2963145971298218
Validation loss: 2.022081948095752

Epoch: 6| Step: 9
Training loss: 1.2071995735168457
Validation loss: 2.035234062902389

Epoch: 6| Step: 10
Training loss: 1.5093828439712524
Validation loss: 2.043565057939099

Epoch: 6| Step: 11
Training loss: 1.4121534824371338
Validation loss: 2.0402562772074053

Epoch: 6| Step: 12
Training loss: 2.003894805908203
Validation loss: 2.0071364410461916

Epoch: 6| Step: 13
Training loss: 0.9483602046966553
Validation loss: 2.029717431273512

Epoch: 446| Step: 0
Training loss: 1.7612345218658447
Validation loss: 1.9821145073060067

Epoch: 6| Step: 1
Training loss: 0.6299092769622803
Validation loss: 2.026266041622367

Epoch: 6| Step: 2
Training loss: 2.1114888191223145
Validation loss: 2.0479089726683912

Epoch: 6| Step: 3
Training loss: 1.492924690246582
Validation loss: 2.0203501152735885

Epoch: 6| Step: 4
Training loss: 1.2400909662246704
Validation loss: 2.0751957226825017

Epoch: 6| Step: 5
Training loss: 1.1726171970367432
Validation loss: 2.0085270020269577

Epoch: 6| Step: 6
Training loss: 1.069084644317627
Validation loss: 1.9884188662293136

Epoch: 6| Step: 7
Training loss: 1.7050886154174805
Validation loss: 2.00164520612327

Epoch: 6| Step: 8
Training loss: 1.1371792554855347
Validation loss: 2.0022000881933395

Epoch: 6| Step: 9
Training loss: 1.536820411682129
Validation loss: 1.9693396860553372

Epoch: 6| Step: 10
Training loss: 1.904850721359253
Validation loss: 2.014332348300565

Epoch: 6| Step: 11
Training loss: 1.1919384002685547
Validation loss: 2.011642015108498

Epoch: 6| Step: 12
Training loss: 1.1296566724777222
Validation loss: 1.991894006729126

Epoch: 6| Step: 13
Training loss: 1.0015019178390503
Validation loss: 2.0592416255704817

Epoch: 447| Step: 0
Training loss: 1.465773582458496
Validation loss: 2.068975708817923

Epoch: 6| Step: 1
Training loss: 1.7360644340515137
Validation loss: 2.0324306000945387

Epoch: 6| Step: 2
Training loss: 1.5245640277862549
Validation loss: 2.0119157939828853

Epoch: 6| Step: 3
Training loss: 0.9649693965911865
Validation loss: 2.0353529350731963

Epoch: 6| Step: 4
Training loss: 1.015110731124878
Validation loss: 2.013337750588694

Epoch: 6| Step: 5
Training loss: 1.4673118591308594
Validation loss: 2.0360190227467525

Epoch: 6| Step: 6
Training loss: 1.616140604019165
Validation loss: 2.0511220552588023

Epoch: 6| Step: 7
Training loss: 1.0338910818099976
Validation loss: 2.019865637184471

Epoch: 6| Step: 8
Training loss: 1.5111827850341797
Validation loss: 2.0229833895160305

Epoch: 6| Step: 9
Training loss: 1.047210931777954
Validation loss: 2.041862445492898

Epoch: 6| Step: 10
Training loss: 1.207319736480713
Validation loss: 2.064036915379186

Epoch: 6| Step: 11
Training loss: 1.492706537246704
Validation loss: 2.015943555421727

Epoch: 6| Step: 12
Training loss: 1.9066805839538574
Validation loss: 2.028273928549982

Epoch: 6| Step: 13
Training loss: 1.1320909261703491
Validation loss: 2.032775196977841

Epoch: 448| Step: 0
Training loss: 1.4068852663040161
Validation loss: 2.0587946189347135

Epoch: 6| Step: 1
Training loss: 1.5645220279693604
Validation loss: 2.028324359206743

Epoch: 6| Step: 2
Training loss: 1.4811887741088867
Validation loss: 2.063638230805756

Epoch: 6| Step: 3
Training loss: 1.4315918684005737
Validation loss: 2.0130291856745237

Epoch: 6| Step: 4
Training loss: 0.8781312704086304
Validation loss: 2.015482702562886

Epoch: 6| Step: 5
Training loss: 0.9881111979484558
Validation loss: 2.0436465804294874

Epoch: 6| Step: 6
Training loss: 1.7822742462158203
Validation loss: 2.043560888177605

Epoch: 6| Step: 7
Training loss: 2.359457492828369
Validation loss: 2.0394770663271666

Epoch: 6| Step: 8
Training loss: 1.2314951419830322
Validation loss: 2.008390444581227

Epoch: 6| Step: 9
Training loss: 1.1494414806365967
Validation loss: 2.044665205863214

Epoch: 6| Step: 10
Training loss: 1.038834810256958
Validation loss: 1.984117474607242

Epoch: 6| Step: 11
Training loss: 1.4615607261657715
Validation loss: 2.0460875444514777

Epoch: 6| Step: 12
Training loss: 1.0471770763397217
Validation loss: 2.0523776828601794

Epoch: 6| Step: 13
Training loss: 1.4036858081817627
Validation loss: 2.0604511217404435

Epoch: 449| Step: 0
Training loss: 1.6678581237792969
Validation loss: 1.9976449935666976

Epoch: 6| Step: 1
Training loss: 1.4830492734909058
Validation loss: 2.046940049817485

Epoch: 6| Step: 2
Training loss: 1.4042508602142334
Validation loss: 2.04051802491629

Epoch: 6| Step: 3
Training loss: 1.4380548000335693
Validation loss: 2.011776584450917

Epoch: 6| Step: 4
Training loss: 1.2535091638565063
Validation loss: 2.035749581552321

Epoch: 6| Step: 5
Training loss: 1.2841750383377075
Validation loss: 2.011881325834541

Epoch: 6| Step: 6
Training loss: 1.6274186372756958
Validation loss: 2.0126349887540265

Epoch: 6| Step: 7
Training loss: 1.5189732313156128
Validation loss: 2.032747846777721

Epoch: 6| Step: 8
Training loss: 2.0178794860839844
Validation loss: 2.050249126649672

Epoch: 6| Step: 9
Training loss: 1.2733855247497559
Validation loss: 2.0369227573435795

Epoch: 6| Step: 10
Training loss: 1.5729808807373047
Validation loss: 2.058734678453015

Epoch: 6| Step: 11
Training loss: 0.6238124966621399
Validation loss: 2.055851382593955

Epoch: 6| Step: 12
Training loss: 0.74705570936203
Validation loss: 2.0257673109731367

Epoch: 6| Step: 13
Training loss: 0.8086021542549133
Validation loss: 2.0460224689975863

Epoch: 450| Step: 0
Training loss: 0.9229251146316528
Validation loss: 2.046707619902908

Epoch: 6| Step: 1
Training loss: 1.1232465505599976
Validation loss: 2.0924691436111287

Epoch: 6| Step: 2
Training loss: 1.661410927772522
Validation loss: 2.0899021958792083

Epoch: 6| Step: 3
Training loss: 1.6458529233932495
Validation loss: 2.048717739761517

Epoch: 6| Step: 4
Training loss: 2.116457939147949
Validation loss: 2.0461087316595097

Epoch: 6| Step: 5
Training loss: 0.7285288572311401
Validation loss: 2.0233813229427544

Epoch: 6| Step: 6
Training loss: 1.61653470993042
Validation loss: 2.016930475029894

Epoch: 6| Step: 7
Training loss: 1.3687539100646973
Validation loss: 2.0576979344890964

Epoch: 6| Step: 8
Training loss: 1.2952520847320557
Validation loss: 2.0506136391752507

Epoch: 6| Step: 9
Training loss: 0.9915635585784912
Validation loss: 2.0086552020042174

Epoch: 6| Step: 10
Training loss: 1.4314374923706055
Validation loss: 2.048009059762442

Epoch: 6| Step: 11
Training loss: 1.6236419677734375
Validation loss: 2.0473151040333573

Epoch: 6| Step: 12
Training loss: 0.9116261005401611
Validation loss: 2.070797645917503

Epoch: 6| Step: 13
Training loss: 1.3557798862457275
Validation loss: 2.0297184554479455

Epoch: 451| Step: 0
Training loss: 1.0352457761764526
Validation loss: 2.0534381610091015

Epoch: 6| Step: 1
Training loss: 1.5331228971481323
Validation loss: 2.0140952474327496

Epoch: 6| Step: 2
Training loss: 0.7199058532714844
Validation loss: 2.0632201522909184

Epoch: 6| Step: 3
Training loss: 1.342513084411621
Validation loss: 2.0264041987798547

Epoch: 6| Step: 4
Training loss: 1.2688374519348145
Validation loss: 2.068152822473998

Epoch: 6| Step: 5
Training loss: 1.4658093452453613
Validation loss: 2.024587744025774

Epoch: 6| Step: 6
Training loss: 1.1793639659881592
Validation loss: 2.0388656739265687

Epoch: 6| Step: 7
Training loss: 0.6875873804092407
Validation loss: 2.055304078645604

Epoch: 6| Step: 8
Training loss: 1.0779616832733154
Validation loss: 2.046468714232086

Epoch: 6| Step: 9
Training loss: 1.832054615020752
Validation loss: 2.0403590099785918

Epoch: 6| Step: 10
Training loss: 1.849561333656311
Validation loss: 2.0533985155884937

Epoch: 6| Step: 11
Training loss: 2.305191993713379
Validation loss: 1.9809669128028295

Epoch: 6| Step: 12
Training loss: 1.2218568325042725
Validation loss: 2.059417534899968

Epoch: 6| Step: 13
Training loss: 1.571075677871704
Validation loss: 2.0589132642233245

Epoch: 452| Step: 0
Training loss: 1.3721320629119873
Validation loss: 2.047254336777554

Epoch: 6| Step: 1
Training loss: 1.2855963706970215
Validation loss: 2.0404771822755055

Epoch: 6| Step: 2
Training loss: 1.7694061994552612
Validation loss: 2.0221203206687846

Epoch: 6| Step: 3
Training loss: 1.5312999486923218
Validation loss: 2.040468080069429

Epoch: 6| Step: 4
Training loss: 1.1087610721588135
Validation loss: 2.0189848202531055

Epoch: 6| Step: 5
Training loss: 1.2362569570541382
Validation loss: 2.0306205775148127

Epoch: 6| Step: 6
Training loss: 0.7390598058700562
Validation loss: 2.0400455767108547

Epoch: 6| Step: 7
Training loss: 1.6438069343566895
Validation loss: 2.039805095682862

Epoch: 6| Step: 8
Training loss: 1.3904294967651367
Validation loss: 2.056088625743825

Epoch: 6| Step: 9
Training loss: 0.7739650011062622
Validation loss: 2.045550013101229

Epoch: 6| Step: 10
Training loss: 1.1386895179748535
Validation loss: 2.072520372688129

Epoch: 6| Step: 11
Training loss: 1.667108416557312
Validation loss: 2.0316054372377295

Epoch: 6| Step: 12
Training loss: 1.6118850708007812
Validation loss: 2.0647864162280993

Epoch: 6| Step: 13
Training loss: 1.8801229000091553
Validation loss: 2.065228719865122

Epoch: 453| Step: 0
Training loss: 1.3288869857788086
Validation loss: 2.081902434748988

Epoch: 6| Step: 1
Training loss: 1.5443661212921143
Validation loss: 2.071916168735873

Epoch: 6| Step: 2
Training loss: 1.2688138484954834
Validation loss: 2.063943488623506

Epoch: 6| Step: 3
Training loss: 1.1506688594818115
Validation loss: 2.0886008483107372

Epoch: 6| Step: 4
Training loss: 1.5294444561004639
Validation loss: 2.0812827028254026

Epoch: 6| Step: 5
Training loss: 1.501765251159668
Validation loss: 2.1224950757077945

Epoch: 6| Step: 6
Training loss: 1.6960636377334595
Validation loss: 2.0513145205795125

Epoch: 6| Step: 7
Training loss: 1.5409917831420898
Validation loss: 2.0623298101527716

Epoch: 6| Step: 8
Training loss: 1.154628038406372
Validation loss: 2.0468618869781494

Epoch: 6| Step: 9
Training loss: 1.3093535900115967
Validation loss: 1.997378449286184

Epoch: 6| Step: 10
Training loss: 0.8514696955680847
Validation loss: 2.0404476696445095

Epoch: 6| Step: 11
Training loss: 1.5347731113433838
Validation loss: 2.044838261860673

Epoch: 6| Step: 12
Training loss: 1.4664344787597656
Validation loss: 1.977308278442711

Epoch: 6| Step: 13
Training loss: 1.0777943134307861
Validation loss: 2.0492837172682568

Epoch: 454| Step: 0
Training loss: 1.7673768997192383
Validation loss: 1.9888077576955159

Epoch: 6| Step: 1
Training loss: 2.217620849609375
Validation loss: 2.0059617616797007

Epoch: 6| Step: 2
Training loss: 0.9838510751724243
Validation loss: 2.0147965300467705

Epoch: 6| Step: 3
Training loss: 1.2151508331298828
Validation loss: 1.999853503319525

Epoch: 6| Step: 4
Training loss: 1.2854487895965576
Validation loss: 2.0468076300877396

Epoch: 6| Step: 5
Training loss: 1.640674114227295
Validation loss: 1.9978116827626382

Epoch: 6| Step: 6
Training loss: 1.4786627292633057
Validation loss: 2.0146318712542133

Epoch: 6| Step: 7
Training loss: 1.3326493501663208
Validation loss: 2.0367066296198035

Epoch: 6| Step: 8
Training loss: 1.169663667678833
Validation loss: 2.044619487177941

Epoch: 6| Step: 9
Training loss: 1.1565067768096924
Validation loss: 2.0215944141469975

Epoch: 6| Step: 10
Training loss: 1.5331826210021973
Validation loss: 2.0469642082850137

Epoch: 6| Step: 11
Training loss: 0.7606598138809204
Validation loss: 2.0430632099028556

Epoch: 6| Step: 12
Training loss: 1.512704849243164
Validation loss: 2.0381809819129204

Epoch: 6| Step: 13
Training loss: 1.2524501085281372
Validation loss: 2.017986418098532

Epoch: 455| Step: 0
Training loss: 1.6703296899795532
Validation loss: 2.023243309349142

Epoch: 6| Step: 1
Training loss: 1.3460623025894165
Validation loss: 1.986402052705006

Epoch: 6| Step: 2
Training loss: 1.4127641916275024
Validation loss: 2.055719147446335

Epoch: 6| Step: 3
Training loss: 2.1192502975463867
Validation loss: 1.9994292489943966

Epoch: 6| Step: 4
Training loss: 1.2559871673583984
Validation loss: 2.048336452053439

Epoch: 6| Step: 5
Training loss: 1.0797897577285767
Validation loss: 2.0002880455345236

Epoch: 6| Step: 6
Training loss: 1.14579439163208
Validation loss: 2.0242242274745816

Epoch: 6| Step: 7
Training loss: 1.087756872177124
Validation loss: 2.0277760157021145

Epoch: 6| Step: 8
Training loss: 1.140249490737915
Validation loss: 2.0216836672957226

Epoch: 6| Step: 9
Training loss: 0.9777095913887024
Validation loss: 2.016626311886695

Epoch: 6| Step: 10
Training loss: 1.795107364654541
Validation loss: 2.0722082596953197

Epoch: 6| Step: 11
Training loss: 0.9266043305397034
Validation loss: 2.033287145758188

Epoch: 6| Step: 12
Training loss: 1.8321430683135986
Validation loss: 2.0519862815897953

Epoch: 6| Step: 13
Training loss: 0.9623035788536072
Validation loss: 2.010239431934972

Epoch: 456| Step: 0
Training loss: 1.610257863998413
Validation loss: 2.0216087833527596

Epoch: 6| Step: 1
Training loss: 1.0716862678527832
Validation loss: 2.002004877213509

Epoch: 6| Step: 2
Training loss: 1.4280028343200684
Validation loss: 2.040405168328234

Epoch: 6| Step: 3
Training loss: 1.4265751838684082
Validation loss: 2.0256764042762017

Epoch: 6| Step: 4
Training loss: 1.4946972131729126
Validation loss: 2.056704346851636

Epoch: 6| Step: 5
Training loss: 2.0447897911071777
Validation loss: 2.056167951194189

Epoch: 6| Step: 6
Training loss: 0.612342357635498
Validation loss: 2.059291366607912

Epoch: 6| Step: 7
Training loss: 0.8700321912765503
Validation loss: 2.0399153437665714

Epoch: 6| Step: 8
Training loss: 1.260793924331665
Validation loss: 2.041792079966555

Epoch: 6| Step: 9
Training loss: 1.2505130767822266
Validation loss: 2.021555801873566

Epoch: 6| Step: 10
Training loss: 1.7494962215423584
Validation loss: 2.072920947946528

Epoch: 6| Step: 11
Training loss: 1.600307822227478
Validation loss: 2.0324507887645433

Epoch: 6| Step: 12
Training loss: 1.2769272327423096
Validation loss: 2.059328930352324

Epoch: 6| Step: 13
Training loss: 1.4465969800949097
Validation loss: 2.067064073777968

Epoch: 457| Step: 0
Training loss: 0.6650461554527283
Validation loss: 2.0744331254754016

Epoch: 6| Step: 1
Training loss: 2.1414809226989746
Validation loss: 2.071124276807231

Epoch: 6| Step: 2
Training loss: 1.3503190279006958
Validation loss: 2.0156148441376223

Epoch: 6| Step: 3
Training loss: 1.5009660720825195
Validation loss: 2.0672924877494894

Epoch: 6| Step: 4
Training loss: 1.4223203659057617
Validation loss: 2.03203720302992

Epoch: 6| Step: 5
Training loss: 1.3704625368118286
Validation loss: 2.064657950914034

Epoch: 6| Step: 6
Training loss: 1.5059418678283691
Validation loss: 2.061231625977383

Epoch: 6| Step: 7
Training loss: 1.7781351804733276
Validation loss: 2.0406580560950824

Epoch: 6| Step: 8
Training loss: 1.748616337776184
Validation loss: 1.989244104713522

Epoch: 6| Step: 9
Training loss: 1.1232930421829224
Validation loss: 2.036095243628307

Epoch: 6| Step: 10
Training loss: 1.344774603843689
Validation loss: 2.0152028632420365

Epoch: 6| Step: 11
Training loss: 0.9832544326782227
Validation loss: 2.0366394019895986

Epoch: 6| Step: 12
Training loss: 1.042503833770752
Validation loss: 2.0081530642765824

Epoch: 6| Step: 13
Training loss: 0.9180302023887634
Validation loss: 2.044094011347781

Epoch: 458| Step: 0
Training loss: 1.3730031251907349
Validation loss: 2.030024825885732

Epoch: 6| Step: 1
Training loss: 1.381866693496704
Validation loss: 2.0434659475921304

Epoch: 6| Step: 2
Training loss: 1.3861048221588135
Validation loss: 2.0300950055481284

Epoch: 6| Step: 3
Training loss: 1.6036874055862427
Validation loss: 2.075405741250643

Epoch: 6| Step: 4
Training loss: 1.4156031608581543
Validation loss: 2.045198384151664

Epoch: 6| Step: 5
Training loss: 1.0778000354766846
Validation loss: 2.0178576092566214

Epoch: 6| Step: 6
Training loss: 0.9907291531562805
Validation loss: 2.0566020396447953

Epoch: 6| Step: 7
Training loss: 1.3016796112060547
Validation loss: 2.0456705811203166

Epoch: 6| Step: 8
Training loss: 1.7117009162902832
Validation loss: 2.096657387671932

Epoch: 6| Step: 9
Training loss: 1.4484505653381348
Validation loss: 2.0383221282753894

Epoch: 6| Step: 10
Training loss: 1.413901686668396
Validation loss: 2.0865657303922918

Epoch: 6| Step: 11
Training loss: 0.9232326745986938
Validation loss: 2.079340930907957

Epoch: 6| Step: 12
Training loss: 2.174617290496826
Validation loss: 2.051036557843608

Epoch: 6| Step: 13
Training loss: 1.2695554494857788
Validation loss: 2.0741394104496127

Epoch: 459| Step: 0
Training loss: 1.1134828329086304
Validation loss: 2.027344867747317

Epoch: 6| Step: 1
Training loss: 1.313541293144226
Validation loss: 2.032825472534344

Epoch: 6| Step: 2
Training loss: 1.3882591724395752
Validation loss: 1.9838603875970329

Epoch: 6| Step: 3
Training loss: 1.3749850988388062
Validation loss: 2.0335021377891622

Epoch: 6| Step: 4
Training loss: 1.0411574840545654
Validation loss: 2.025732627478979

Epoch: 6| Step: 5
Training loss: 1.583893895149231
Validation loss: 2.0400678803843837

Epoch: 6| Step: 6
Training loss: 0.8759205341339111
Validation loss: 2.0256689851002028

Epoch: 6| Step: 7
Training loss: 1.7447893619537354
Validation loss: 2.0175794145112396

Epoch: 6| Step: 8
Training loss: 1.209110140800476
Validation loss: 2.0253648168297222

Epoch: 6| Step: 9
Training loss: 1.207198143005371
Validation loss: 1.9567262126553444

Epoch: 6| Step: 10
Training loss: 1.8067846298217773
Validation loss: 2.02354710460991

Epoch: 6| Step: 11
Training loss: 1.4310222864151
Validation loss: 2.0198611008223666

Epoch: 6| Step: 12
Training loss: 1.1934823989868164
Validation loss: 2.00585538084789

Epoch: 6| Step: 13
Training loss: 1.6072853803634644
Validation loss: 2.0226212009306876

Epoch: 460| Step: 0
Training loss: 1.6973605155944824
Validation loss: 2.056307537581331

Epoch: 6| Step: 1
Training loss: 1.0562572479248047
Validation loss: 1.9999744187119186

Epoch: 6| Step: 2
Training loss: 1.4068796634674072
Validation loss: 2.0104381063933014

Epoch: 6| Step: 3
Training loss: 1.2209177017211914
Validation loss: 2.0590927152223486

Epoch: 6| Step: 4
Training loss: 0.9766340255737305
Validation loss: 2.0624254390757573

Epoch: 6| Step: 5
Training loss: 1.022167682647705
Validation loss: 2.055550641911004

Epoch: 6| Step: 6
Training loss: 1.130850076675415
Validation loss: 2.0679610211362123

Epoch: 6| Step: 7
Training loss: 1.5805919170379639
Validation loss: 2.0701875366190428

Epoch: 6| Step: 8
Training loss: 1.5530474185943604
Validation loss: 2.0399404520629556

Epoch: 6| Step: 9
Training loss: 1.080435037612915
Validation loss: 2.0431676295495804

Epoch: 6| Step: 10
Training loss: 1.7023191452026367
Validation loss: 2.0058584136347615

Epoch: 6| Step: 11
Training loss: 1.7319896221160889
Validation loss: 2.0234554172844015

Epoch: 6| Step: 12
Training loss: 1.315867304801941
Validation loss: 2.04955808577999

Epoch: 6| Step: 13
Training loss: 1.1923391819000244
Validation loss: 2.0356331281764533

Epoch: 461| Step: 0
Training loss: 1.7647968530654907
Validation loss: 2.015686135138235

Epoch: 6| Step: 1
Training loss: 1.4016902446746826
Validation loss: 2.0514371395111084

Epoch: 6| Step: 2
Training loss: 0.8909726142883301
Validation loss: 2.059101040645312

Epoch: 6| Step: 3
Training loss: 1.068006992340088
Validation loss: 2.010984088784905

Epoch: 6| Step: 4
Training loss: 1.280714750289917
Validation loss: 2.0566634465289373

Epoch: 6| Step: 5
Training loss: 1.5091005563735962
Validation loss: 1.9979004219014158

Epoch: 6| Step: 6
Training loss: 1.256357192993164
Validation loss: 1.9979993066480082

Epoch: 6| Step: 7
Training loss: 1.6509307622909546
Validation loss: 2.017989673922139

Epoch: 6| Step: 8
Training loss: 1.4740188121795654
Validation loss: 1.998021629548842

Epoch: 6| Step: 9
Training loss: 1.6762938499450684
Validation loss: 2.0335577482818277

Epoch: 6| Step: 10
Training loss: 1.3641929626464844
Validation loss: 2.03109771461897

Epoch: 6| Step: 11
Training loss: 1.5119428634643555
Validation loss: 1.9782313557081326

Epoch: 6| Step: 12
Training loss: 1.2296206951141357
Validation loss: 1.9867210516365625

Epoch: 6| Step: 13
Training loss: 1.1098016500473022
Validation loss: 2.023180115607477

Epoch: 462| Step: 0
Training loss: 1.154004693031311
Validation loss: 2.0107847490618305

Epoch: 6| Step: 1
Training loss: 1.5793068408966064
Validation loss: 2.0354672503727738

Epoch: 6| Step: 2
Training loss: 1.637403964996338
Validation loss: 2.0320549959777505

Epoch: 6| Step: 3
Training loss: 1.2283236980438232
Validation loss: 2.0809472478846067

Epoch: 6| Step: 4
Training loss: 1.3630932569503784
Validation loss: 2.035701900400141

Epoch: 6| Step: 5
Training loss: 1.7071990966796875
Validation loss: 2.0440147128156436

Epoch: 6| Step: 6
Training loss: 1.7545759677886963
Validation loss: 2.0768963085707797

Epoch: 6| Step: 7
Training loss: 1.0181560516357422
Validation loss: 2.0978148009187434

Epoch: 6| Step: 8
Training loss: 1.0988836288452148
Validation loss: 2.053462618140764

Epoch: 6| Step: 9
Training loss: 2.0431203842163086
Validation loss: 2.011653942446555

Epoch: 6| Step: 10
Training loss: 0.9922612905502319
Validation loss: 2.0691032871123283

Epoch: 6| Step: 11
Training loss: 1.284874439239502
Validation loss: 2.0410671810950003

Epoch: 6| Step: 12
Training loss: 1.2467100620269775
Validation loss: 2.0279335873101347

Epoch: 6| Step: 13
Training loss: 0.8390723466873169
Validation loss: 2.018620216718284

Epoch: 463| Step: 0
Training loss: 1.220812439918518
Validation loss: 2.080179766942096

Epoch: 6| Step: 1
Training loss: 1.17549729347229
Validation loss: 2.0140060583750405

Epoch: 6| Step: 2
Training loss: 1.9460246562957764
Validation loss: 1.9956020411624704

Epoch: 6| Step: 3
Training loss: 1.463631510734558
Validation loss: 2.0025440005845923

Epoch: 6| Step: 4
Training loss: 1.6464309692382812
Validation loss: 2.064295579028386

Epoch: 6| Step: 5
Training loss: 1.339644193649292
Validation loss: 1.9993224913074124

Epoch: 6| Step: 6
Training loss: 1.3765947818756104
Validation loss: 2.021563535095543

Epoch: 6| Step: 7
Training loss: 1.0505483150482178
Validation loss: 2.025721101350682

Epoch: 6| Step: 8
Training loss: 0.9728879928588867
Validation loss: 2.0902837168785835

Epoch: 6| Step: 9
Training loss: 1.8092411756515503
Validation loss: 2.0040782036319857

Epoch: 6| Step: 10
Training loss: 1.3853027820587158
Validation loss: 2.000262633446724

Epoch: 6| Step: 11
Training loss: 0.9395217895507812
Validation loss: 2.0602133902170325

Epoch: 6| Step: 12
Training loss: 0.9753556251525879
Validation loss: 2.0214331560237433

Epoch: 6| Step: 13
Training loss: 1.48491632938385
Validation loss: 2.042319743863998

Epoch: 464| Step: 0
Training loss: 1.240480899810791
Validation loss: 2.030464700473252

Epoch: 6| Step: 1
Training loss: 1.0645759105682373
Validation loss: 2.061973606386492

Epoch: 6| Step: 2
Training loss: 1.9121384620666504
Validation loss: 2.015170101196535

Epoch: 6| Step: 3
Training loss: 1.3921246528625488
Validation loss: 2.04892328862221

Epoch: 6| Step: 4
Training loss: 1.334180235862732
Validation loss: 2.0426787740440777

Epoch: 6| Step: 5
Training loss: 0.9614689946174622
Validation loss: 2.0310251200070946

Epoch: 6| Step: 6
Training loss: 1.5808578729629517
Validation loss: 2.056899514249576

Epoch: 6| Step: 7
Training loss: 1.0799169540405273
Validation loss: 2.0612041463134108

Epoch: 6| Step: 8
Training loss: 1.378175973892212
Validation loss: 2.02685333195553

Epoch: 6| Step: 9
Training loss: 1.1115121841430664
Validation loss: 2.0293661958427838

Epoch: 6| Step: 10
Training loss: 1.9022431373596191
Validation loss: 2.088468305526241

Epoch: 6| Step: 11
Training loss: 1.1066935062408447
Validation loss: 2.031245880229499

Epoch: 6| Step: 12
Training loss: 1.3082127571105957
Validation loss: 2.051361222420969

Epoch: 6| Step: 13
Training loss: 1.2542505264282227
Validation loss: 2.0109749801697268

Epoch: 465| Step: 0
Training loss: 1.243549108505249
Validation loss: 2.0274179379145303

Epoch: 6| Step: 1
Training loss: 1.5146076679229736
Validation loss: 2.018113351637317

Epoch: 6| Step: 2
Training loss: 1.6781145334243774
Validation loss: 2.0369198168477705

Epoch: 6| Step: 3
Training loss: 1.9279195070266724
Validation loss: 2.0196535664220012

Epoch: 6| Step: 4
Training loss: 1.2135568857192993
Validation loss: 2.0066925979429677

Epoch: 6| Step: 5
Training loss: 1.6739171743392944
Validation loss: 2.0469464845554803

Epoch: 6| Step: 6
Training loss: 1.1164675951004028
Validation loss: 2.0465122474137174

Epoch: 6| Step: 7
Training loss: 1.0648292303085327
Validation loss: 2.055464954786403

Epoch: 6| Step: 8
Training loss: 1.5239068269729614
Validation loss: 2.082938660857498

Epoch: 6| Step: 9
Training loss: 1.5891016721725464
Validation loss: 2.063172358338551

Epoch: 6| Step: 10
Training loss: 0.7105344533920288
Validation loss: 2.017769649464597

Epoch: 6| Step: 11
Training loss: 0.9868850708007812
Validation loss: 2.0294135693580873

Epoch: 6| Step: 12
Training loss: 1.5109269618988037
Validation loss: 2.0903214587960193

Epoch: 6| Step: 13
Training loss: 0.5142910480499268
Validation loss: 2.007199557878638

Epoch: 466| Step: 0
Training loss: 1.4262893199920654
Validation loss: 2.0086314062918387

Epoch: 6| Step: 1
Training loss: 1.1650067567825317
Validation loss: 2.0297604286542503

Epoch: 6| Step: 2
Training loss: 1.1493130922317505
Validation loss: 2.033422177837741

Epoch: 6| Step: 3
Training loss: 1.707177996635437
Validation loss: 2.0275741033656622

Epoch: 6| Step: 4
Training loss: 1.0116535425186157
Validation loss: 2.085169405065557

Epoch: 6| Step: 5
Training loss: 1.3485805988311768
Validation loss: 2.052991856810867

Epoch: 6| Step: 6
Training loss: 1.4430365562438965
Validation loss: 1.982961881545282

Epoch: 6| Step: 7
Training loss: 1.4016762971878052
Validation loss: 2.0242749029590237

Epoch: 6| Step: 8
Training loss: 1.684801459312439
Validation loss: 1.993838894751764

Epoch: 6| Step: 9
Training loss: 1.259469747543335
Validation loss: 2.0304891447867117

Epoch: 6| Step: 10
Training loss: 1.5306997299194336
Validation loss: 2.008538456373317

Epoch: 6| Step: 11
Training loss: 1.4823582172393799
Validation loss: 2.0316846011787333

Epoch: 6| Step: 12
Training loss: 1.1634663343429565
Validation loss: 2.0139115036174817

Epoch: 6| Step: 13
Training loss: 0.9682610630989075
Validation loss: 2.0066698238413823

Epoch: 467| Step: 0
Training loss: 1.1484957933425903
Validation loss: 2.0525416174242572

Epoch: 6| Step: 1
Training loss: 1.506838083267212
Validation loss: 2.0222784473050024

Epoch: 6| Step: 2
Training loss: 1.4912047386169434
Validation loss: 2.0437919247534966

Epoch: 6| Step: 3
Training loss: 0.9877066612243652
Validation loss: 2.047984230902887

Epoch: 6| Step: 4
Training loss: 1.0561835765838623
Validation loss: 2.041195002935266

Epoch: 6| Step: 5
Training loss: 1.5036158561706543
Validation loss: 2.0502855931558917

Epoch: 6| Step: 6
Training loss: 1.5137813091278076
Validation loss: 2.028159649141373

Epoch: 6| Step: 7
Training loss: 2.3049426078796387
Validation loss: 2.014419376209218

Epoch: 6| Step: 8
Training loss: 0.9934025406837463
Validation loss: 2.011108772729033

Epoch: 6| Step: 9
Training loss: 1.309117317199707
Validation loss: 2.0667881888727986

Epoch: 6| Step: 10
Training loss: 1.020036220550537
Validation loss: 2.0173033591239684

Epoch: 6| Step: 11
Training loss: 1.087709665298462
Validation loss: 2.0394068623101838

Epoch: 6| Step: 12
Training loss: 1.4261531829833984
Validation loss: 1.9891097763533234

Epoch: 6| Step: 13
Training loss: 0.9011555910110474
Validation loss: 2.0349034583696755

Epoch: 468| Step: 0
Training loss: 1.4425990581512451
Validation loss: 1.9956705595857354

Epoch: 6| Step: 1
Training loss: 1.4234373569488525
Validation loss: 2.0238539108666043

Epoch: 6| Step: 2
Training loss: 1.1192189455032349
Validation loss: 2.0311650614584646

Epoch: 6| Step: 3
Training loss: 1.1016145944595337
Validation loss: 2.0298762347108577

Epoch: 6| Step: 4
Training loss: 1.471832036972046
Validation loss: 2.018451867565032

Epoch: 6| Step: 5
Training loss: 1.1391050815582275
Validation loss: 2.025579594796704

Epoch: 6| Step: 6
Training loss: 1.2288144826889038
Validation loss: 2.0528831687024844

Epoch: 6| Step: 7
Training loss: 2.18190860748291
Validation loss: 2.0642295281092324

Epoch: 6| Step: 8
Training loss: 1.0764625072479248
Validation loss: 2.0623984208670993

Epoch: 6| Step: 9
Training loss: 1.7812910079956055
Validation loss: 2.0470805757789203

Epoch: 6| Step: 10
Training loss: 1.1152307987213135
Validation loss: 2.0559412356345885

Epoch: 6| Step: 11
Training loss: 1.3578884601593018
Validation loss: 2.0294421847148607

Epoch: 6| Step: 12
Training loss: 1.2049305438995361
Validation loss: 2.077408705988238

Epoch: 6| Step: 13
Training loss: 0.3816465139389038
Validation loss: 2.027927467899938

Epoch: 469| Step: 0
Training loss: 1.3238108158111572
Validation loss: 2.0588859717051187

Epoch: 6| Step: 1
Training loss: 1.3132405281066895
Validation loss: 2.0430047332599597

Epoch: 6| Step: 2
Training loss: 0.9088312387466431
Validation loss: 2.031844182681012

Epoch: 6| Step: 3
Training loss: 1.1018176078796387
Validation loss: 2.056038820615379

Epoch: 6| Step: 4
Training loss: 1.199145793914795
Validation loss: 2.035987202839185

Epoch: 6| Step: 5
Training loss: 1.4751460552215576
Validation loss: 1.994756353798733

Epoch: 6| Step: 6
Training loss: 1.6133803129196167
Validation loss: 2.046348552550039

Epoch: 6| Step: 7
Training loss: 1.6940802335739136
Validation loss: 2.014004877818528

Epoch: 6| Step: 8
Training loss: 1.3431298732757568
Validation loss: 2.0212327972535165

Epoch: 6| Step: 9
Training loss: 0.9147584438323975
Validation loss: 2.034464592574745

Epoch: 6| Step: 10
Training loss: 1.8082468509674072
Validation loss: 2.047523667735438

Epoch: 6| Step: 11
Training loss: 1.4392626285552979
Validation loss: 1.987995127195953

Epoch: 6| Step: 12
Training loss: 1.2193974256515503
Validation loss: 2.0473482442158524

Epoch: 6| Step: 13
Training loss: 1.5369908809661865
Validation loss: 2.0645109261235883

Epoch: 470| Step: 0
Training loss: 1.4760181903839111
Validation loss: 2.0706725607636156

Epoch: 6| Step: 1
Training loss: 1.6088449954986572
Validation loss: 2.0081298428197063

Epoch: 6| Step: 2
Training loss: 1.3955974578857422
Validation loss: 2.021246414030752

Epoch: 6| Step: 3
Training loss: 1.0319082736968994
Validation loss: 2.0305676921721427

Epoch: 6| Step: 4
Training loss: 1.4461925029754639
Validation loss: 2.0328312202166487

Epoch: 6| Step: 5
Training loss: 1.8930511474609375
Validation loss: 2.10440327787912

Epoch: 6| Step: 6
Training loss: 1.066375970840454
Validation loss: 2.0397987083722184

Epoch: 6| Step: 7
Training loss: 1.0912342071533203
Validation loss: 2.0289066632588706

Epoch: 6| Step: 8
Training loss: 1.0749155282974243
Validation loss: 2.0559200317628923

Epoch: 6| Step: 9
Training loss: 1.9398787021636963
Validation loss: 2.0404476401626424

Epoch: 6| Step: 10
Training loss: 0.8077137470245361
Validation loss: 2.0129314109843266

Epoch: 6| Step: 11
Training loss: 1.8571465015411377
Validation loss: 2.0473380140078965

Epoch: 6| Step: 12
Training loss: 1.0216618776321411
Validation loss: 2.0396033589557936

Epoch: 6| Step: 13
Training loss: 0.9194169640541077
Validation loss: 2.0791124656636226

Epoch: 471| Step: 0
Training loss: 1.0807651281356812
Validation loss: 2.072379614717217

Epoch: 6| Step: 1
Training loss: 1.1756675243377686
Validation loss: 2.034118101161013

Epoch: 6| Step: 2
Training loss: 1.7094722986221313
Validation loss: 2.038874828687278

Epoch: 6| Step: 3
Training loss: 1.78956937789917
Validation loss: 2.031126094120805

Epoch: 6| Step: 4
Training loss: 1.3835726976394653
Validation loss: 2.0172730722735004

Epoch: 6| Step: 5
Training loss: 1.0632774829864502
Validation loss: 2.0905229968409382

Epoch: 6| Step: 6
Training loss: 0.8634120225906372
Validation loss: 2.0674987287931543

Epoch: 6| Step: 7
Training loss: 1.1121901273727417
Validation loss: 2.0294536646976264

Epoch: 6| Step: 8
Training loss: 1.0739437341690063
Validation loss: 2.0902631282806396

Epoch: 6| Step: 9
Training loss: 1.4294019937515259
Validation loss: 2.0079017992942565

Epoch: 6| Step: 10
Training loss: 1.6227638721466064
Validation loss: 2.022226177236085

Epoch: 6| Step: 11
Training loss: 1.666507363319397
Validation loss: 2.093510509819113

Epoch: 6| Step: 12
Training loss: 1.4973905086517334
Validation loss: 2.012474067749516

Epoch: 6| Step: 13
Training loss: 1.6524872779846191
Validation loss: 2.0557759372136926

Epoch: 472| Step: 0
Training loss: 1.9395698308944702
Validation loss: 2.028606532722391

Epoch: 6| Step: 1
Training loss: 1.0515146255493164
Validation loss: 2.0701675184311403

Epoch: 6| Step: 2
Training loss: 1.1875182390213013
Validation loss: 2.0540254500604447

Epoch: 6| Step: 3
Training loss: 1.2762196063995361
Validation loss: 2.0360833855085474

Epoch: 6| Step: 4
Training loss: 1.0142500400543213
Validation loss: 2.0475912273571057

Epoch: 6| Step: 5
Training loss: 0.8012242913246155
Validation loss: 2.063304373013076

Epoch: 6| Step: 6
Training loss: 1.105806589126587
Validation loss: 2.022572571231473

Epoch: 6| Step: 7
Training loss: 1.495819091796875
Validation loss: 2.019145886103312

Epoch: 6| Step: 8
Training loss: 1.9415847063064575
Validation loss: 2.0730120789620186

Epoch: 6| Step: 9
Training loss: 1.0474103689193726
Validation loss: 2.0071218962310464

Epoch: 6| Step: 10
Training loss: 1.5389683246612549
Validation loss: 2.0541560034598074

Epoch: 6| Step: 11
Training loss: 1.3590675592422485
Validation loss: 2.0019508689962406

Epoch: 6| Step: 12
Training loss: 1.4765361547470093
Validation loss: 2.0178230500990346

Epoch: 6| Step: 13
Training loss: 1.1450973749160767
Validation loss: 2.056133113881593

Epoch: 473| Step: 0
Training loss: 1.317522644996643
Validation loss: 2.0686689025612286

Epoch: 6| Step: 1
Training loss: 1.114811658859253
Validation loss: 2.0326495068047636

Epoch: 6| Step: 2
Training loss: 1.834080457687378
Validation loss: 2.0723008801860194

Epoch: 6| Step: 3
Training loss: 1.5467338562011719
Validation loss: 2.0434848147053875

Epoch: 6| Step: 4
Training loss: 1.0998022556304932
Validation loss: 2.0551715102247012

Epoch: 6| Step: 5
Training loss: 1.216284155845642
Validation loss: 2.0324637992407686

Epoch: 6| Step: 6
Training loss: 1.6443663835525513
Validation loss: 2.072633156212427

Epoch: 6| Step: 7
Training loss: 0.7129849195480347
Validation loss: 2.019304951032003

Epoch: 6| Step: 8
Training loss: 1.885838508605957
Validation loss: 2.051086319390164

Epoch: 6| Step: 9
Training loss: 0.9958750009536743
Validation loss: 2.027928965066069

Epoch: 6| Step: 10
Training loss: 1.2482671737670898
Validation loss: 2.0483221597568964

Epoch: 6| Step: 11
Training loss: 1.3655006885528564
Validation loss: 2.0602731935439573

Epoch: 6| Step: 12
Training loss: 1.5028505325317383
Validation loss: 2.033908713248468

Epoch: 6| Step: 13
Training loss: 1.0615465641021729
Validation loss: 2.01943205248925

Epoch: 474| Step: 0
Training loss: 1.3763279914855957
Validation loss: 2.025506002928621

Epoch: 6| Step: 1
Training loss: 1.4277514219284058
Validation loss: 2.0123305551467405

Epoch: 6| Step: 2
Training loss: 1.4087817668914795
Validation loss: 2.052719061092664

Epoch: 6| Step: 3
Training loss: 1.4360723495483398
Validation loss: 2.033165047245641

Epoch: 6| Step: 4
Training loss: 1.1658798456192017
Validation loss: 2.0233547995167394

Epoch: 6| Step: 5
Training loss: 1.1951597929000854
Validation loss: 2.0388173621187926

Epoch: 6| Step: 6
Training loss: 0.9149258732795715
Validation loss: 2.063059219750025

Epoch: 6| Step: 7
Training loss: 1.6315746307373047
Validation loss: 2.001224261458202

Epoch: 6| Step: 8
Training loss: 0.8726152777671814
Validation loss: 2.051393557620305

Epoch: 6| Step: 9
Training loss: 1.598963737487793
Validation loss: 2.0911372861554547

Epoch: 6| Step: 10
Training loss: 1.7361418008804321
Validation loss: 2.030014381613783

Epoch: 6| Step: 11
Training loss: 1.4755797386169434
Validation loss: 2.045311220230595

Epoch: 6| Step: 12
Training loss: 1.1513843536376953
Validation loss: 2.062648037428497

Epoch: 6| Step: 13
Training loss: 1.0261293649673462
Validation loss: 2.0027592502614504

Epoch: 475| Step: 0
Training loss: 1.8423054218292236
Validation loss: 2.0259620374248875

Epoch: 6| Step: 1
Training loss: 1.6012988090515137
Validation loss: 1.9962697670023928

Epoch: 6| Step: 2
Training loss: 1.1307193040847778
Validation loss: 2.035815786289912

Epoch: 6| Step: 3
Training loss: 1.7721112966537476
Validation loss: 2.037307862312563

Epoch: 6| Step: 4
Training loss: 1.5880498886108398
Validation loss: 2.055371651085474

Epoch: 6| Step: 5
Training loss: 0.636572539806366
Validation loss: 2.0492235896407918

Epoch: 6| Step: 6
Training loss: 1.1789681911468506
Validation loss: 2.018285478315046

Epoch: 6| Step: 7
Training loss: 0.9357105493545532
Validation loss: 2.065831415114864

Epoch: 6| Step: 8
Training loss: 1.1634330749511719
Validation loss: 2.0063645608963503

Epoch: 6| Step: 9
Training loss: 1.3456966876983643
Validation loss: 2.040924741375831

Epoch: 6| Step: 10
Training loss: 0.9895062446594238
Validation loss: 2.0251168256164878

Epoch: 6| Step: 11
Training loss: 1.6201815605163574
Validation loss: 2.053011707080308

Epoch: 6| Step: 12
Training loss: 1.5492420196533203
Validation loss: 2.0192892371967273

Epoch: 6| Step: 13
Training loss: 1.0025691986083984
Validation loss: 2.0432245026352587

Epoch: 476| Step: 0
Training loss: 0.921135425567627
Validation loss: 2.0675676048442884

Epoch: 6| Step: 1
Training loss: 1.7803045511245728
Validation loss: 2.0683543694916593

Epoch: 6| Step: 2
Training loss: 1.1585440635681152
Validation loss: 2.094019279685072

Epoch: 6| Step: 3
Training loss: 1.3977501392364502
Validation loss: 2.093125776578021

Epoch: 6| Step: 4
Training loss: 1.1388537883758545
Validation loss: 2.0258267682085753

Epoch: 6| Step: 5
Training loss: 1.940805196762085
Validation loss: 2.0594876850804975

Epoch: 6| Step: 6
Training loss: 0.823877215385437
Validation loss: 2.0675631671823482

Epoch: 6| Step: 7
Training loss: 1.7048722505569458
Validation loss: 2.091444650003987

Epoch: 6| Step: 8
Training loss: 1.0038158893585205
Validation loss: 2.070164957354146

Epoch: 6| Step: 9
Training loss: 1.317331314086914
Validation loss: 2.0575211099399033

Epoch: 6| Step: 10
Training loss: 0.8699294924736023
Validation loss: 2.04377003382611

Epoch: 6| Step: 11
Training loss: 1.6523642539978027
Validation loss: 2.044864176422037

Epoch: 6| Step: 12
Training loss: 1.1641656160354614
Validation loss: 2.054907875676309

Epoch: 6| Step: 13
Training loss: 1.4473599195480347
Validation loss: 2.0837595590981106

Epoch: 477| Step: 0
Training loss: 1.1379754543304443
Validation loss: 2.0271702979200628

Epoch: 6| Step: 1
Training loss: 1.1209434270858765
Validation loss: 2.010474899763702

Epoch: 6| Step: 2
Training loss: 0.7766721844673157
Validation loss: 2.045279939969381

Epoch: 6| Step: 3
Training loss: 1.39662504196167
Validation loss: 2.0026418932022585

Epoch: 6| Step: 4
Training loss: 1.7569427490234375
Validation loss: 2.0936908055377264

Epoch: 6| Step: 5
Training loss: 1.1419240236282349
Validation loss: 2.0452508464936288

Epoch: 6| Step: 6
Training loss: 0.7230741381645203
Validation loss: 2.028502136148432

Epoch: 6| Step: 7
Training loss: 0.9602959156036377
Validation loss: 2.0167445803201325

Epoch: 6| Step: 8
Training loss: 1.8181772232055664
Validation loss: 2.0334270461913078

Epoch: 6| Step: 9
Training loss: 1.3247487545013428
Validation loss: 2.0145266466243292

Epoch: 6| Step: 10
Training loss: 1.8985588550567627
Validation loss: 2.040113688797079

Epoch: 6| Step: 11
Training loss: 1.6278798580169678
Validation loss: 2.0121391332277687

Epoch: 6| Step: 12
Training loss: 1.9771620035171509
Validation loss: 2.0620497170314995

Epoch: 6| Step: 13
Training loss: 0.5408185124397278
Validation loss: 2.0458778001928843

Epoch: 478| Step: 0
Training loss: 1.7482951879501343
Validation loss: 2.0604721051390453

Epoch: 6| Step: 1
Training loss: 1.6945557594299316
Validation loss: 2.022640819190651

Epoch: 6| Step: 2
Training loss: 1.252892255783081
Validation loss: 2.069551311513429

Epoch: 6| Step: 3
Training loss: 1.5614118576049805
Validation loss: 2.0408169043961393

Epoch: 6| Step: 4
Training loss: 1.650113582611084
Validation loss: 2.047297389276566

Epoch: 6| Step: 5
Training loss: 0.7289363145828247
Validation loss: 2.0127863153334586

Epoch: 6| Step: 6
Training loss: 1.2283334732055664
Validation loss: 1.9980478850744103

Epoch: 6| Step: 7
Training loss: 1.1323153972625732
Validation loss: 2.08783951241483

Epoch: 6| Step: 8
Training loss: 0.9335824251174927
Validation loss: 2.00172689396848

Epoch: 6| Step: 9
Training loss: 1.509016990661621
Validation loss: 2.049849017973869

Epoch: 6| Step: 10
Training loss: 1.4065117835998535
Validation loss: 2.0142551801537953

Epoch: 6| Step: 11
Training loss: 1.6530184745788574
Validation loss: 2.0365612788866927

Epoch: 6| Step: 12
Training loss: 1.262511968612671
Validation loss: 2.029869197517313

Epoch: 6| Step: 13
Training loss: 0.6141846776008606
Validation loss: 2.031962799769576

Epoch: 479| Step: 0
Training loss: 1.0187337398529053
Validation loss: 2.0158529025252148

Epoch: 6| Step: 1
Training loss: 1.2688345909118652
Validation loss: 2.045891546433972

Epoch: 6| Step: 2
Training loss: 1.3058497905731201
Validation loss: 2.02952754241164

Epoch: 6| Step: 3
Training loss: 0.7634265422821045
Validation loss: 2.023882758232855

Epoch: 6| Step: 4
Training loss: 0.8411282300949097
Validation loss: 2.0707963974245134

Epoch: 6| Step: 5
Training loss: 1.8562312126159668
Validation loss: 2.1037986432352374

Epoch: 6| Step: 6
Training loss: 1.553563117980957
Validation loss: 2.084041367294968

Epoch: 6| Step: 7
Training loss: 1.8668626546859741
Validation loss: 2.074289714136431

Epoch: 6| Step: 8
Training loss: 1.473236083984375
Validation loss: 2.0721948095547256

Epoch: 6| Step: 9
Training loss: 1.2816990613937378
Validation loss: 2.0655613253193517

Epoch: 6| Step: 10
Training loss: 2.040252685546875
Validation loss: 2.050806374960048

Epoch: 6| Step: 11
Training loss: 0.9438209533691406
Validation loss: 2.0276358576231104

Epoch: 6| Step: 12
Training loss: 1.2785265445709229
Validation loss: 1.995947091810165

Epoch: 6| Step: 13
Training loss: 0.6301271915435791
Validation loss: 2.04281009140835

Epoch: 480| Step: 0
Training loss: 0.5500984787940979
Validation loss: 2.012915354903026

Epoch: 6| Step: 1
Training loss: 1.674800157546997
Validation loss: 1.9852459020512079

Epoch: 6| Step: 2
Training loss: 1.811950922012329
Validation loss: 2.073370260577048

Epoch: 6| Step: 3
Training loss: 1.3052151203155518
Validation loss: 2.009129916467974

Epoch: 6| Step: 4
Training loss: 1.3661595582962036
Validation loss: 2.0332318993024927

Epoch: 6| Step: 5
Training loss: 1.0880519151687622
Validation loss: 2.0532367178188857

Epoch: 6| Step: 6
Training loss: 1.511792778968811
Validation loss: 2.0319426482723606

Epoch: 6| Step: 7
Training loss: 1.5648881196975708
Validation loss: 2.001836610096757

Epoch: 6| Step: 8
Training loss: 1.0022192001342773
Validation loss: 2.0361165077455583

Epoch: 6| Step: 9
Training loss: 1.1767692565917969
Validation loss: 2.042665717422321

Epoch: 6| Step: 10
Training loss: 1.4666242599487305
Validation loss: 2.054032446235739

Epoch: 6| Step: 11
Training loss: 1.6467232704162598
Validation loss: 2.0790146345733316

Epoch: 6| Step: 12
Training loss: 0.8830766677856445
Validation loss: 2.0178449538446244

Epoch: 6| Step: 13
Training loss: 1.2475075721740723
Validation loss: 2.053980396639916

Epoch: 481| Step: 0
Training loss: 0.8639824986457825
Validation loss: 2.0615793197385726

Epoch: 6| Step: 1
Training loss: 1.1684761047363281
Validation loss: 2.0583045187816826

Epoch: 6| Step: 2
Training loss: 1.6271040439605713
Validation loss: 2.0288473585600495

Epoch: 6| Step: 3
Training loss: 0.9315589666366577
Validation loss: 2.0303239386568785

Epoch: 6| Step: 4
Training loss: 1.8547115325927734
Validation loss: 2.0047658874142553

Epoch: 6| Step: 5
Training loss: 1.342940330505371
Validation loss: 2.027478947434374

Epoch: 6| Step: 6
Training loss: 1.4501233100891113
Validation loss: 1.998129375519291

Epoch: 6| Step: 7
Training loss: 1.3069801330566406
Validation loss: 2.014071677320747

Epoch: 6| Step: 8
Training loss: 1.443820595741272
Validation loss: 2.0465031669985865

Epoch: 6| Step: 9
Training loss: 0.8364143967628479
Validation loss: 2.026245347915157

Epoch: 6| Step: 10
Training loss: 1.3369559049606323
Validation loss: 2.0679097970326743

Epoch: 6| Step: 11
Training loss: 1.3971508741378784
Validation loss: 2.00464044591432

Epoch: 6| Step: 12
Training loss: 1.3608518838882446
Validation loss: 2.051795031434746

Epoch: 6| Step: 13
Training loss: 1.12214994430542
Validation loss: 2.0508869322397376

Epoch: 482| Step: 0
Training loss: 1.4679341316223145
Validation loss: 2.0302644647577757

Epoch: 6| Step: 1
Training loss: 1.2874640226364136
Validation loss: 2.0430899717474498

Epoch: 6| Step: 2
Training loss: 0.9424691200256348
Validation loss: 2.0187458786913144

Epoch: 6| Step: 3
Training loss: 1.2328951358795166
Validation loss: 2.0831443186729186

Epoch: 6| Step: 4
Training loss: 1.1309125423431396
Validation loss: 2.048438028622699

Epoch: 6| Step: 5
Training loss: 1.3587260246276855
Validation loss: 2.027831631322061

Epoch: 6| Step: 6
Training loss: 0.9615000486373901
Validation loss: 2.0206057179358696

Epoch: 6| Step: 7
Training loss: 1.8929766416549683
Validation loss: 2.0492415735798497

Epoch: 6| Step: 8
Training loss: 1.2052146196365356
Validation loss: 2.0114564100901284

Epoch: 6| Step: 9
Training loss: 0.8000988960266113
Validation loss: 2.0431020734130696

Epoch: 6| Step: 10
Training loss: 1.282346248626709
Validation loss: 2.0413989508023827

Epoch: 6| Step: 11
Training loss: 1.6474218368530273
Validation loss: 2.053406129601181

Epoch: 6| Step: 12
Training loss: 1.5565714836120605
Validation loss: 1.9727489435544578

Epoch: 6| Step: 13
Training loss: 1.1045540571212769
Validation loss: 2.0034807369273198

Epoch: 483| Step: 0
Training loss: 1.585558295249939
Validation loss: 2.0143200889710458

Epoch: 6| Step: 1
Training loss: 1.5820517539978027
Validation loss: 2.0027785942118657

Epoch: 6| Step: 2
Training loss: 0.8314169645309448
Validation loss: 1.9955730861233127

Epoch: 6| Step: 3
Training loss: 0.9351711869239807
Validation loss: 2.060573467644312

Epoch: 6| Step: 4
Training loss: 1.3251148462295532
Validation loss: 2.042961894824941

Epoch: 6| Step: 5
Training loss: 1.0579851865768433
Validation loss: 2.058201528364612

Epoch: 6| Step: 6
Training loss: 1.498242735862732
Validation loss: 2.0306007221180904

Epoch: 6| Step: 7
Training loss: 1.2924330234527588
Validation loss: 2.0805049250202794

Epoch: 6| Step: 8
Training loss: 1.536954402923584
Validation loss: 2.0450070519601145

Epoch: 6| Step: 9
Training loss: 1.6661980152130127
Validation loss: 2.049121828489406

Epoch: 6| Step: 10
Training loss: 1.5738286972045898
Validation loss: 2.031382874775958

Epoch: 6| Step: 11
Training loss: 1.3128117322921753
Validation loss: 2.0502698177932412

Epoch: 6| Step: 12
Training loss: 1.1478049755096436
Validation loss: 2.052688488396265

Epoch: 6| Step: 13
Training loss: 1.0389031171798706
Validation loss: 2.004626863746233

Epoch: 484| Step: 0
Training loss: 1.2822186946868896
Validation loss: 2.0039670390467488

Epoch: 6| Step: 1
Training loss: 1.0504323244094849
Validation loss: 1.978933988078948

Epoch: 6| Step: 2
Training loss: 1.5203163623809814
Validation loss: 2.042213419432281

Epoch: 6| Step: 3
Training loss: 1.3568131923675537
Validation loss: 2.0530740163659535

Epoch: 6| Step: 4
Training loss: 0.7868271470069885
Validation loss: 1.9801614489606632

Epoch: 6| Step: 5
Training loss: 1.098158597946167
Validation loss: 2.0560136674552836

Epoch: 6| Step: 6
Training loss: 1.1911888122558594
Validation loss: 2.0181162459875948

Epoch: 6| Step: 7
Training loss: 1.4724977016448975
Validation loss: 2.0246899768870366

Epoch: 6| Step: 8
Training loss: 1.4020345211029053
Validation loss: 2.0580455128864577

Epoch: 6| Step: 9
Training loss: 1.061598539352417
Validation loss: 2.016599852551696

Epoch: 6| Step: 10
Training loss: 1.0565202236175537
Validation loss: 2.0229523643370597

Epoch: 6| Step: 11
Training loss: 2.4790892601013184
Validation loss: 2.0538601311304236

Epoch: 6| Step: 12
Training loss: 1.233933687210083
Validation loss: 2.05538502816231

Epoch: 6| Step: 13
Training loss: 1.0794594287872314
Validation loss: 2.0931387947451685

Epoch: 485| Step: 0
Training loss: 0.8415811657905579
Validation loss: 1.9994700980442826

Epoch: 6| Step: 1
Training loss: 1.1888200044631958
Validation loss: 2.0647930688755487

Epoch: 6| Step: 2
Training loss: 1.284939169883728
Validation loss: 2.0680662073114866

Epoch: 6| Step: 3
Training loss: 1.3385064601898193
Validation loss: 2.061322545492521

Epoch: 6| Step: 4
Training loss: 0.8919919729232788
Validation loss: 1.9927081779767108

Epoch: 6| Step: 5
Training loss: 1.4238661527633667
Validation loss: 2.058144712960848

Epoch: 6| Step: 6
Training loss: 1.5650124549865723
Validation loss: 2.0625291665395102

Epoch: 6| Step: 7
Training loss: 1.550060510635376
Validation loss: 2.0835167246480144

Epoch: 6| Step: 8
Training loss: 1.3400650024414062
Validation loss: 2.0512278695260324

Epoch: 6| Step: 9
Training loss: 1.7238624095916748
Validation loss: 2.036879062652588

Epoch: 6| Step: 10
Training loss: 1.765868067741394
Validation loss: 2.082077387840517

Epoch: 6| Step: 11
Training loss: 1.664786696434021
Validation loss: 2.0581256164017545

Epoch: 6| Step: 12
Training loss: 0.7825484275817871
Validation loss: 2.068672210939469

Epoch: 6| Step: 13
Training loss: 0.5772157907485962
Validation loss: 2.0945975190849713

Epoch: 486| Step: 0
Training loss: 1.2864148616790771
Validation loss: 2.110124962304228

Epoch: 6| Step: 1
Training loss: 1.3579649925231934
Validation loss: 2.058799397560858

Epoch: 6| Step: 2
Training loss: 1.1526622772216797
Validation loss: 2.0463845037644908

Epoch: 6| Step: 3
Training loss: 1.248384952545166
Validation loss: 2.042804584708265

Epoch: 6| Step: 4
Training loss: 0.8367831707000732
Validation loss: 2.0384083819645706

Epoch: 6| Step: 5
Training loss: 1.8440659046173096
Validation loss: 2.0448323244689615

Epoch: 6| Step: 6
Training loss: 1.2278015613555908
Validation loss: 2.044562908910936

Epoch: 6| Step: 7
Training loss: 1.5365469455718994
Validation loss: 2.0751466315279723

Epoch: 6| Step: 8
Training loss: 0.877463698387146
Validation loss: 2.040724838933637

Epoch: 6| Step: 9
Training loss: 1.5486847162246704
Validation loss: 2.0253665818963

Epoch: 6| Step: 10
Training loss: 1.6146459579467773
Validation loss: 2.0442385776068575

Epoch: 6| Step: 11
Training loss: 1.366603970527649
Validation loss: 2.0401725435769684

Epoch: 6| Step: 12
Training loss: 1.022306203842163
Validation loss: 2.039073949219078

Epoch: 6| Step: 13
Training loss: 1.3184442520141602
Validation loss: 2.0200124184290567

Epoch: 487| Step: 0
Training loss: 1.0107653141021729
Validation loss: 2.0782780865187287

Epoch: 6| Step: 1
Training loss: 1.527287483215332
Validation loss: 1.9975772134719356

Epoch: 6| Step: 2
Training loss: 1.1044137477874756
Validation loss: 2.020695150539439

Epoch: 6| Step: 3
Training loss: 1.5606056451797485
Validation loss: 1.9959271005404893

Epoch: 6| Step: 4
Training loss: 1.5314288139343262
Validation loss: 2.0403412157489407

Epoch: 6| Step: 5
Training loss: 1.070369005203247
Validation loss: 2.044843203277998

Epoch: 6| Step: 6
Training loss: 1.5679666996002197
Validation loss: 2.046210012128276

Epoch: 6| Step: 7
Training loss: 1.4911068677902222
Validation loss: 2.059758537559099

Epoch: 6| Step: 8
Training loss: 0.9137563109397888
Validation loss: 2.030406786549476

Epoch: 6| Step: 9
Training loss: 1.2741007804870605
Validation loss: 2.0770908017312326

Epoch: 6| Step: 10
Training loss: 1.0516753196716309
Validation loss: 2.039430408067601

Epoch: 6| Step: 11
Training loss: 1.4711743593215942
Validation loss: 2.079307900962009

Epoch: 6| Step: 12
Training loss: 1.5683882236480713
Validation loss: 2.094752441170395

Epoch: 6| Step: 13
Training loss: 1.5090700387954712
Validation loss: 2.011222962410219

Epoch: 488| Step: 0
Training loss: 0.9611168503761292
Validation loss: 2.1062170408105336

Epoch: 6| Step: 1
Training loss: 1.3121943473815918
Validation loss: 2.108623570011508

Epoch: 6| Step: 2
Training loss: 1.3708522319793701
Validation loss: 2.0089297474071546

Epoch: 6| Step: 3
Training loss: 1.1169980764389038
Validation loss: 2.0632260281552552

Epoch: 6| Step: 4
Training loss: 1.4220898151397705
Validation loss: 1.9945720126551967

Epoch: 6| Step: 5
Training loss: 0.965848445892334
Validation loss: 2.0297684246493923

Epoch: 6| Step: 6
Training loss: 1.1236337423324585
Validation loss: 2.036659040758687

Epoch: 6| Step: 7
Training loss: 1.576648473739624
Validation loss: 2.0316712010291313

Epoch: 6| Step: 8
Training loss: 1.0995274782180786
Validation loss: 2.043334035463231

Epoch: 6| Step: 9
Training loss: 1.1715214252471924
Validation loss: 2.0271874268849692

Epoch: 6| Step: 10
Training loss: 1.6262344121932983
Validation loss: 2.0575346036623885

Epoch: 6| Step: 11
Training loss: 1.698035478591919
Validation loss: 2.045554822491061

Epoch: 6| Step: 12
Training loss: 1.3828098773956299
Validation loss: 2.075804461715042

Epoch: 6| Step: 13
Training loss: 1.0881065130233765
Validation loss: 2.023378595229118

Epoch: 489| Step: 0
Training loss: 1.168302297592163
Validation loss: 2.0530944075635684

Epoch: 6| Step: 1
Training loss: 1.044415831565857
Validation loss: 2.038532180170859

Epoch: 6| Step: 2
Training loss: 1.4394912719726562
Validation loss: 2.04608049315791

Epoch: 6| Step: 3
Training loss: 1.3410460948944092
Validation loss: 2.0458102021166074

Epoch: 6| Step: 4
Training loss: 1.1983206272125244
Validation loss: 2.052991920901883

Epoch: 6| Step: 5
Training loss: 1.2502117156982422
Validation loss: 2.0309257430414998

Epoch: 6| Step: 6
Training loss: 1.1846014261245728
Validation loss: 2.010480958928344

Epoch: 6| Step: 7
Training loss: 0.8902791738510132
Validation loss: 2.074421844174785

Epoch: 6| Step: 8
Training loss: 0.8032864928245544
Validation loss: 2.05436546059065

Epoch: 6| Step: 9
Training loss: 1.6894094944000244
Validation loss: 2.017844841044436

Epoch: 6| Step: 10
Training loss: 1.798459529876709
Validation loss: 2.051431381574241

Epoch: 6| Step: 11
Training loss: 1.3233013153076172
Validation loss: 2.04816960775724

Epoch: 6| Step: 12
Training loss: 1.6959307193756104
Validation loss: 1.9995835788788334

Epoch: 6| Step: 13
Training loss: 0.6380921006202698
Validation loss: 2.071880932777159

Epoch: 490| Step: 0
Training loss: 1.3005374670028687
Validation loss: 2.047055930219671

Epoch: 6| Step: 1
Training loss: 1.3549363613128662
Validation loss: 1.9788219185285671

Epoch: 6| Step: 2
Training loss: 1.1450297832489014
Validation loss: 2.021097138363828

Epoch: 6| Step: 3
Training loss: 1.0550110340118408
Validation loss: 2.0443460210677116

Epoch: 6| Step: 4
Training loss: 1.2919713258743286
Validation loss: 2.0402513050263926

Epoch: 6| Step: 5
Training loss: 0.8249555230140686
Validation loss: 2.043925267393871

Epoch: 6| Step: 6
Training loss: 1.6983122825622559
Validation loss: 2.0207627229793097

Epoch: 6| Step: 7
Training loss: 1.174882411956787
Validation loss: 2.0313947944230932

Epoch: 6| Step: 8
Training loss: 1.6900866031646729
Validation loss: 2.0049123853765507

Epoch: 6| Step: 9
Training loss: 1.5289192199707031
Validation loss: 2.0582509143378145

Epoch: 6| Step: 10
Training loss: 1.6835336685180664
Validation loss: 2.06536607075763

Epoch: 6| Step: 11
Training loss: 0.9862722158432007
Validation loss: 2.0276042133249264

Epoch: 6| Step: 12
Training loss: 1.2627321481704712
Validation loss: 2.0442779423088155

Epoch: 6| Step: 13
Training loss: 1.6310006380081177
Validation loss: 2.0561852711503223

Epoch: 491| Step: 0
Training loss: 0.8887408375740051
Validation loss: 2.0868368764077463

Epoch: 6| Step: 1
Training loss: 0.8688456416130066
Validation loss: 2.0286683164617068

Epoch: 6| Step: 2
Training loss: 1.1134865283966064
Validation loss: 2.0834287417832242

Epoch: 6| Step: 3
Training loss: 2.195861577987671
Validation loss: 2.032330661691645

Epoch: 6| Step: 4
Training loss: 1.161367416381836
Validation loss: 2.0319433007189023

Epoch: 6| Step: 5
Training loss: 1.3433783054351807
Validation loss: 2.070724102758592

Epoch: 6| Step: 6
Training loss: 1.3271658420562744
Validation loss: 2.0852615025735672

Epoch: 6| Step: 7
Training loss: 1.5004594326019287
Validation loss: 2.0325377961640716

Epoch: 6| Step: 8
Training loss: 1.2710015773773193
Validation loss: 2.098254487078677

Epoch: 6| Step: 9
Training loss: 1.7066001892089844
Validation loss: 2.021061561440909

Epoch: 6| Step: 10
Training loss: 1.009450912475586
Validation loss: 2.046297025936906

Epoch: 6| Step: 11
Training loss: 1.4805750846862793
Validation loss: 2.0594529951772382

Epoch: 6| Step: 12
Training loss: 1.0922977924346924
Validation loss: 2.011965613211355

Epoch: 6| Step: 13
Training loss: 1.1670122146606445
Validation loss: 2.010999510365148

Epoch: 492| Step: 0
Training loss: 1.6500258445739746
Validation loss: 2.0216734563150713

Epoch: 6| Step: 1
Training loss: 1.283400058746338
Validation loss: 1.9883234577794229

Epoch: 6| Step: 2
Training loss: 1.2591357231140137
Validation loss: 2.0415905739671443

Epoch: 6| Step: 3
Training loss: 1.2144873142242432
Validation loss: 2.0428697652714227

Epoch: 6| Step: 4
Training loss: 1.068328619003296
Validation loss: 2.0473054993537163

Epoch: 6| Step: 5
Training loss: 0.9205664396286011
Validation loss: 2.027086191279914

Epoch: 6| Step: 6
Training loss: 1.257054328918457
Validation loss: 2.0240119670027044

Epoch: 6| Step: 7
Training loss: 1.0791689157485962
Validation loss: 2.0707500429563623

Epoch: 6| Step: 8
Training loss: 1.721016526222229
Validation loss: 2.0642580883477324

Epoch: 6| Step: 9
Training loss: 1.3285099267959595
Validation loss: 2.0388277858816166

Epoch: 6| Step: 10
Training loss: 1.3100017309188843
Validation loss: 2.0754286191796743

Epoch: 6| Step: 11
Training loss: 1.443572759628296
Validation loss: 2.0676487261249172

Epoch: 6| Step: 12
Training loss: 1.1318840980529785
Validation loss: 2.0519587352711666

Epoch: 6| Step: 13
Training loss: 1.2656697034835815
Validation loss: 2.0500084046394593

Epoch: 493| Step: 0
Training loss: 1.4051705598831177
Validation loss: 2.056222246539208

Epoch: 6| Step: 1
Training loss: 1.212646245956421
Validation loss: 2.042979286563012

Epoch: 6| Step: 2
Training loss: 1.1098883152008057
Validation loss: 2.064877170388417

Epoch: 6| Step: 3
Training loss: 0.4942783713340759
Validation loss: 2.0580190304786927

Epoch: 6| Step: 4
Training loss: 1.2461588382720947
Validation loss: 2.0627331823431034

Epoch: 6| Step: 5
Training loss: 1.520206332206726
Validation loss: 2.037344821037785

Epoch: 6| Step: 6
Training loss: 1.4116227626800537
Validation loss: 2.086286906273134

Epoch: 6| Step: 7
Training loss: 1.401590347290039
Validation loss: 2.056442565815423

Epoch: 6| Step: 8
Training loss: 1.1466835737228394
Validation loss: 2.0583390189755346

Epoch: 6| Step: 9
Training loss: 0.799833357334137
Validation loss: 2.058468558455026

Epoch: 6| Step: 10
Training loss: 1.701197624206543
Validation loss: 2.0468795120075183

Epoch: 6| Step: 11
Training loss: 1.9967408180236816
Validation loss: 2.037241283283439

Epoch: 6| Step: 12
Training loss: 1.493268609046936
Validation loss: 2.0724277368155857

Epoch: 6| Step: 13
Training loss: 1.1099952459335327
Validation loss: 2.027842685740481

Epoch: 494| Step: 0
Training loss: 1.3300285339355469
Validation loss: 2.05495975863549

Epoch: 6| Step: 1
Training loss: 1.5841248035430908
Validation loss: 2.0762320205729496

Epoch: 6| Step: 2
Training loss: 1.3676539659500122
Validation loss: 2.104201155324136

Epoch: 6| Step: 3
Training loss: 1.3218026161193848
Validation loss: 2.024211146498239

Epoch: 6| Step: 4
Training loss: 1.4494224786758423
Validation loss: 2.0653156465099705

Epoch: 6| Step: 5
Training loss: 1.2716574668884277
Validation loss: 2.0716054618999524

Epoch: 6| Step: 6
Training loss: 1.62308931350708
Validation loss: 2.027747061944777

Epoch: 6| Step: 7
Training loss: 0.923887312412262
Validation loss: 2.0296316095577773

Epoch: 6| Step: 8
Training loss: 1.192325234413147
Validation loss: 2.026936697703536

Epoch: 6| Step: 9
Training loss: 0.8334304094314575
Validation loss: 2.0239249339667698

Epoch: 6| Step: 10
Training loss: 0.9372016787528992
Validation loss: 1.9924811778529998

Epoch: 6| Step: 11
Training loss: 0.9934036731719971
Validation loss: 2.043610977870162

Epoch: 6| Step: 12
Training loss: 1.7729008197784424
Validation loss: 2.070610868033542

Epoch: 6| Step: 13
Training loss: 1.3829195499420166
Validation loss: 2.0768861232265348

Epoch: 495| Step: 0
Training loss: 1.4940738677978516
Validation loss: 2.047903251904313

Epoch: 6| Step: 1
Training loss: 1.52097749710083
Validation loss: 2.079848840672483

Epoch: 6| Step: 2
Training loss: 1.497046947479248
Validation loss: 2.0756703628006803

Epoch: 6| Step: 3
Training loss: 1.1723406314849854
Validation loss: 2.0319042949266333

Epoch: 6| Step: 4
Training loss: 1.5746757984161377
Validation loss: 2.04139530915086

Epoch: 6| Step: 5
Training loss: 1.5497252941131592
Validation loss: 2.0327279952264603

Epoch: 6| Step: 6
Training loss: 1.2632237672805786
Validation loss: 2.057826671549069

Epoch: 6| Step: 7
Training loss: 1.358964204788208
Validation loss: 2.015025282418856

Epoch: 6| Step: 8
Training loss: 0.9977666735649109
Validation loss: 2.058882046771306

Epoch: 6| Step: 9
Training loss: 1.0225366353988647
Validation loss: 2.026295917008513

Epoch: 6| Step: 10
Training loss: 1.3282363414764404
Validation loss: 2.0569403171539307

Epoch: 6| Step: 11
Training loss: 1.3800725936889648
Validation loss: 2.038922522657661

Epoch: 6| Step: 12
Training loss: 1.2253774404525757
Validation loss: 2.0501472373162546

Epoch: 6| Step: 13
Training loss: 1.2941454648971558
Validation loss: 2.026158792998201

Epoch: 496| Step: 0
Training loss: 1.868003487586975
Validation loss: 1.9997330686097503

Epoch: 6| Step: 1
Training loss: 1.2197442054748535
Validation loss: 2.0788272298792356

Epoch: 6| Step: 2
Training loss: 1.5506765842437744
Validation loss: 2.053493353628343

Epoch: 6| Step: 3
Training loss: 1.1406724452972412
Validation loss: 2.0121709185261882

Epoch: 6| Step: 4
Training loss: 0.8553096055984497
Validation loss: 2.033852195227018

Epoch: 6| Step: 5
Training loss: 1.0685462951660156
Validation loss: 2.0159838866162043

Epoch: 6| Step: 6
Training loss: 1.3992339372634888
Validation loss: 2.056278195432437

Epoch: 6| Step: 7
Training loss: 1.0254888534545898
Validation loss: 2.025109242367488

Epoch: 6| Step: 8
Training loss: 0.7630921006202698
Validation loss: 2.053101847248693

Epoch: 6| Step: 9
Training loss: 1.1895582675933838
Validation loss: 2.0192428711921937

Epoch: 6| Step: 10
Training loss: 1.391116976737976
Validation loss: 2.018469807922199

Epoch: 6| Step: 11
Training loss: 0.8537517786026001
Validation loss: 2.013110340282481

Epoch: 6| Step: 12
Training loss: 1.3308311700820923
Validation loss: 2.017463635372859

Epoch: 6| Step: 13
Training loss: 2.297544479370117
Validation loss: 2.0621280259983514

Epoch: 497| Step: 0
Training loss: 1.4856092929840088
Validation loss: 2.0385226895732265

Epoch: 6| Step: 1
Training loss: 0.8536661267280579
Validation loss: 2.0460422538941905

Epoch: 6| Step: 2
Training loss: 0.8803232908248901
Validation loss: 2.0032250983740694

Epoch: 6| Step: 3
Training loss: 0.8758335709571838
Validation loss: 2.091740172396424

Epoch: 6| Step: 4
Training loss: 0.9579473733901978
Validation loss: 2.034283140654205

Epoch: 6| Step: 5
Training loss: 1.8171736001968384
Validation loss: 2.0652051202712522

Epoch: 6| Step: 6
Training loss: 1.1418004035949707
Validation loss: 2.0590421243380477

Epoch: 6| Step: 7
Training loss: 1.3562664985656738
Validation loss: 2.097202234370734

Epoch: 6| Step: 8
Training loss: 1.8991656303405762
Validation loss: 2.0967739935844176

Epoch: 6| Step: 9
Training loss: 1.6783807277679443
Validation loss: 2.1157931973857265

Epoch: 6| Step: 10
Training loss: 1.3086820840835571
Validation loss: 2.0531604930918705

Epoch: 6| Step: 11
Training loss: 1.1557660102844238
Validation loss: 2.0725000648088354

Epoch: 6| Step: 12
Training loss: 1.2572109699249268
Validation loss: 2.0230019015650593

Epoch: 6| Step: 13
Training loss: 1.6891984939575195
Validation loss: 2.0931416301317114

Epoch: 498| Step: 0
Training loss: 1.1233813762664795
Validation loss: 2.0395091874625093

Epoch: 6| Step: 1
Training loss: 1.6386573314666748
Validation loss: 2.036433499346497

Epoch: 6| Step: 2
Training loss: 1.4643276929855347
Validation loss: 1.9964426691814134

Epoch: 6| Step: 3
Training loss: 2.170597553253174
Validation loss: 2.014469583829244

Epoch: 6| Step: 4
Training loss: 0.8763211965560913
Validation loss: 2.0314192900093655

Epoch: 6| Step: 5
Training loss: 0.9788272976875305
Validation loss: 2.058866326526929

Epoch: 6| Step: 6
Training loss: 1.927628755569458
Validation loss: 2.020105549084243

Epoch: 6| Step: 7
Training loss: 1.1319615840911865
Validation loss: 2.022542327962896

Epoch: 6| Step: 8
Training loss: 1.1910442113876343
Validation loss: 2.035034897506878

Epoch: 6| Step: 9
Training loss: 0.8397083282470703
Validation loss: 2.007996727061528

Epoch: 6| Step: 10
Training loss: 0.8337666988372803
Validation loss: 2.034572151399428

Epoch: 6| Step: 11
Training loss: 1.3897950649261475
Validation loss: 2.0521973589415192

Epoch: 6| Step: 12
Training loss: 1.1961770057678223
Validation loss: 2.0417924670762915

Epoch: 6| Step: 13
Training loss: 1.3839497566223145
Validation loss: 2.0560914803576726

Epoch: 499| Step: 0
Training loss: 0.7756097316741943
Validation loss: 2.0690972715295772

Epoch: 6| Step: 1
Training loss: 2.3568763732910156
Validation loss: 1.9870150166173135

Epoch: 6| Step: 2
Training loss: 1.6044269800186157
Validation loss: 2.0747352671879593

Epoch: 6| Step: 3
Training loss: 1.160469651222229
Validation loss: 2.0634024143218994

Epoch: 6| Step: 4
Training loss: 1.6455821990966797
Validation loss: 2.0113859381726993

Epoch: 6| Step: 5
Training loss: 1.1804641485214233
Validation loss: 2.0496319750303864

Epoch: 6| Step: 6
Training loss: 1.1042709350585938
Validation loss: 2.0701127975217757

Epoch: 6| Step: 7
Training loss: 1.233870267868042
Validation loss: 2.0451855736394084

Epoch: 6| Step: 8
Training loss: 1.548689603805542
Validation loss: 2.062367184187776

Epoch: 6| Step: 9
Training loss: 1.013312816619873
Validation loss: 2.0401597510101976

Epoch: 6| Step: 10
Training loss: 0.947829008102417
Validation loss: 2.0816999481570337

Epoch: 6| Step: 11
Training loss: 0.9193302392959595
Validation loss: 2.069916848213442

Epoch: 6| Step: 12
Training loss: 1.4979000091552734
Validation loss: 2.0519222341557986

Epoch: 6| Step: 13
Training loss: 0.8485259413719177
Validation loss: 2.055558737888131

Epoch: 500| Step: 0
Training loss: 1.0168774127960205
Validation loss: 2.080316332078749

Epoch: 6| Step: 1
Training loss: 1.5406618118286133
Validation loss: 2.066778249638055

Epoch: 6| Step: 2
Training loss: 1.0854356288909912
Validation loss: 2.007726070701435

Epoch: 6| Step: 3
Training loss: 1.3001073598861694
Validation loss: 2.0431468512422297

Epoch: 6| Step: 4
Training loss: 1.4027979373931885
Validation loss: 2.037790035688749

Epoch: 6| Step: 5
Training loss: 1.5570098161697388
Validation loss: 2.0232201878742506

Epoch: 6| Step: 6
Training loss: 1.578192949295044
Validation loss: 2.0256621222342215

Epoch: 6| Step: 7
Training loss: 1.165440559387207
Validation loss: 2.02540151790906

Epoch: 6| Step: 8
Training loss: 0.8042294979095459
Validation loss: 2.0664450276282524

Epoch: 6| Step: 9
Training loss: 1.2246928215026855
Validation loss: 2.0816546819543325

Epoch: 6| Step: 10
Training loss: 1.4239299297332764
Validation loss: 2.0841887343314385

Epoch: 6| Step: 11
Training loss: 1.1791316270828247
Validation loss: 2.075969047443841

Epoch: 6| Step: 12
Training loss: 1.3604199886322021
Validation loss: 2.0634561572023618

Epoch: 6| Step: 13
Training loss: 1.4831881523132324
Validation loss: 2.101644810809884

Epoch: 501| Step: 0
Training loss: 1.243356704711914
Validation loss: 2.07567964061614

Epoch: 6| Step: 1
Training loss: 0.8629591464996338
Validation loss: 2.099511356763942

Epoch: 6| Step: 2
Training loss: 1.2721513509750366
Validation loss: 2.058405150649368

Epoch: 6| Step: 3
Training loss: 1.4999804496765137
Validation loss: 2.068604278308089

Epoch: 6| Step: 4
Training loss: 1.1980626583099365
Validation loss: 2.062778301136468

Epoch: 6| Step: 5
Training loss: 1.2519848346710205
Validation loss: 2.1012799329655145

Epoch: 6| Step: 6
Training loss: 2.049125909805298
Validation loss: 2.0403288102919057

Epoch: 6| Step: 7
Training loss: 0.7221896052360535
Validation loss: 2.0857858068199566

Epoch: 6| Step: 8
Training loss: 1.179832935333252
Validation loss: 2.0054673225648942

Epoch: 6| Step: 9
Training loss: 1.8621963262557983
Validation loss: 2.0737655701175814

Epoch: 6| Step: 10
Training loss: 1.3160340785980225
Validation loss: 2.0668160992283977

Epoch: 6| Step: 11
Training loss: 1.1587761640548706
Validation loss: 2.0339812668420936

Epoch: 6| Step: 12
Training loss: 0.8817890286445618
Validation loss: 2.0468985931847685

Epoch: 6| Step: 13
Training loss: 1.5604311227798462
Validation loss: 2.036701153683406

Epoch: 502| Step: 0
Training loss: 1.1608246564865112
Validation loss: 2.0113707793656217

Epoch: 6| Step: 1
Training loss: 0.8981066346168518
Validation loss: 2.0287076401454147

Epoch: 6| Step: 2
Training loss: 1.2991491556167603
Validation loss: 2.0225715124478905

Epoch: 6| Step: 3
Training loss: 0.8788987398147583
Validation loss: 2.0737842295759465

Epoch: 6| Step: 4
Training loss: 1.3731906414031982
Validation loss: 2.0459931896578882

Epoch: 6| Step: 5
Training loss: 1.6928932666778564
Validation loss: 2.069992091066094

Epoch: 6| Step: 6
Training loss: 1.2602133750915527
Validation loss: 2.0967365541765766

Epoch: 6| Step: 7
Training loss: 1.4570866823196411
Validation loss: 2.096450244226763

Epoch: 6| Step: 8
Training loss: 1.3115878105163574
Validation loss: 2.0937224075358403

Epoch: 6| Step: 9
Training loss: 1.4372200965881348
Validation loss: 2.068245719837886

Epoch: 6| Step: 10
Training loss: 1.5665093660354614
Validation loss: 2.0568722063495266

Epoch: 6| Step: 11
Training loss: 1.0603137016296387
Validation loss: 2.0191148801516463

Epoch: 6| Step: 12
Training loss: 1.4065418243408203
Validation loss: 2.115771693568076

Epoch: 6| Step: 13
Training loss: 0.7881755828857422
Validation loss: 2.0617752331559376

Epoch: 503| Step: 0
Training loss: 1.4501495361328125
Validation loss: 2.012045280907744

Epoch: 6| Step: 1
Training loss: 1.2445640563964844
Validation loss: 2.066838405465567

Epoch: 6| Step: 2
Training loss: 1.4322627782821655
Validation loss: 2.0826028316251692

Epoch: 6| Step: 3
Training loss: 1.6965363025665283
Validation loss: 2.04002179766214

Epoch: 6| Step: 4
Training loss: 1.3973171710968018
Validation loss: 2.046917810234972

Epoch: 6| Step: 5
Training loss: 1.3918826580047607
Validation loss: 2.0258296971680014

Epoch: 6| Step: 6
Training loss: 1.8798822164535522
Validation loss: 2.0555798776688112

Epoch: 6| Step: 7
Training loss: 0.723022997379303
Validation loss: 2.025597542844793

Epoch: 6| Step: 8
Training loss: 0.8249573707580566
Validation loss: 2.0305357774098716

Epoch: 6| Step: 9
Training loss: 1.4179399013519287
Validation loss: 2.0604936897113757

Epoch: 6| Step: 10
Training loss: 0.8289531469345093
Validation loss: 2.035688816860158

Epoch: 6| Step: 11
Training loss: 1.3768690824508667
Validation loss: 2.0253382587945588

Epoch: 6| Step: 12
Training loss: 1.1850292682647705
Validation loss: 2.0166936792353147

Epoch: 6| Step: 13
Training loss: 0.591313898563385
Validation loss: 2.078664010570895

Epoch: 504| Step: 0
Training loss: 1.25151789188385
Validation loss: 2.037145430041898

Epoch: 6| Step: 1
Training loss: 1.3301492929458618
Validation loss: 2.0384407581821566

Epoch: 6| Step: 2
Training loss: 0.8096253871917725
Validation loss: 2.044487464812494

Epoch: 6| Step: 3
Training loss: 1.3815224170684814
Validation loss: 2.025449151633888

Epoch: 6| Step: 4
Training loss: 1.5028953552246094
Validation loss: 2.0210366889994633

Epoch: 6| Step: 5
Training loss: 0.8544542193412781
Validation loss: 2.03709255239015

Epoch: 6| Step: 6
Training loss: 1.606157660484314
Validation loss: 2.036884935953284

Epoch: 6| Step: 7
Training loss: 2.049215316772461
Validation loss: 2.035437668523481

Epoch: 6| Step: 8
Training loss: 0.8311562538146973
Validation loss: 2.078747469891784

Epoch: 6| Step: 9
Training loss: 0.8967281579971313
Validation loss: 2.0290816266049623

Epoch: 6| Step: 10
Training loss: 1.19985032081604
Validation loss: 2.085097551345825

Epoch: 6| Step: 11
Training loss: 1.4310106039047241
Validation loss: 2.049085755502024

Epoch: 6| Step: 12
Training loss: 1.4162812232971191
Validation loss: 2.039960753533148

Epoch: 6| Step: 13
Training loss: 1.497904658317566
Validation loss: 2.0682462902479273

Epoch: 505| Step: 0
Training loss: 1.2036676406860352
Validation loss: 2.0742048666041386

Epoch: 6| Step: 1
Training loss: 1.8553667068481445
Validation loss: 2.05531257583249

Epoch: 6| Step: 2
Training loss: 1.3526301383972168
Validation loss: 2.0529226897865214

Epoch: 6| Step: 3
Training loss: 0.9849119186401367
Validation loss: 2.0516582009612874

Epoch: 6| Step: 4
Training loss: 1.5548800230026245
Validation loss: 2.0855976894337642

Epoch: 6| Step: 5
Training loss: 1.164911150932312
Validation loss: 2.04749660594489

Epoch: 6| Step: 6
Training loss: 1.7143657207489014
Validation loss: 2.064453754373776

Epoch: 6| Step: 7
Training loss: 0.9306288957595825
Validation loss: 2.074049790700277

Epoch: 6| Step: 8
Training loss: 0.7061102390289307
Validation loss: 2.088460547949678

Epoch: 6| Step: 9
Training loss: 0.7626523375511169
Validation loss: 2.084808372682141

Epoch: 6| Step: 10
Training loss: 1.2253103256225586
Validation loss: 2.0724955399831138

Epoch: 6| Step: 11
Training loss: 1.8409676551818848
Validation loss: 2.0534772667833554

Epoch: 6| Step: 12
Training loss: 1.0771037340164185
Validation loss: 2.057474410662087

Epoch: 6| Step: 13
Training loss: 1.8347865343093872
Validation loss: 2.0287932016516246

Epoch: 506| Step: 0
Training loss: 1.4551981687545776
Validation loss: 1.9966749811685214

Epoch: 6| Step: 1
Training loss: 1.6078903675079346
Validation loss: 2.048101022679319

Epoch: 6| Step: 2
Training loss: 1.6078652143478394
Validation loss: 2.10129540581857

Epoch: 6| Step: 3
Training loss: 1.414687991142273
Validation loss: 2.0077062217138146

Epoch: 6| Step: 4
Training loss: 0.9119691848754883
Validation loss: 2.0408814376400364

Epoch: 6| Step: 5
Training loss: 1.2605866193771362
Validation loss: 2.0146700054086666

Epoch: 6| Step: 6
Training loss: 1.280738115310669
Validation loss: 2.0595448324757237

Epoch: 6| Step: 7
Training loss: 1.158510446548462
Validation loss: 2.0296862163851337

Epoch: 6| Step: 8
Training loss: 1.3540886640548706
Validation loss: 2.054844697316488

Epoch: 6| Step: 9
Training loss: 1.1658289432525635
Validation loss: 2.012101547692412

Epoch: 6| Step: 10
Training loss: 1.5087817907333374
Validation loss: 2.055966117048776

Epoch: 6| Step: 11
Training loss: 1.0642856359481812
Validation loss: 2.1188191829189176

Epoch: 6| Step: 12
Training loss: 0.8419225215911865
Validation loss: 2.043365195233335

Epoch: 6| Step: 13
Training loss: 1.3108779191970825
Validation loss: 2.0408161942676832

Epoch: 507| Step: 0
Training loss: 1.0799882411956787
Validation loss: 2.040900038134667

Epoch: 6| Step: 1
Training loss: 1.6385904550552368
Validation loss: 2.045502278112596

Epoch: 6| Step: 2
Training loss: 1.2220056056976318
Validation loss: 1.9878158543699531

Epoch: 6| Step: 3
Training loss: 0.8152914047241211
Validation loss: 2.0404962852437007

Epoch: 6| Step: 4
Training loss: 1.5645922422409058
Validation loss: 2.071043801564042

Epoch: 6| Step: 5
Training loss: 1.2691854238510132
Validation loss: 2.0179168742190123

Epoch: 6| Step: 6
Training loss: 1.231353521347046
Validation loss: 2.0482542745528685

Epoch: 6| Step: 7
Training loss: 1.3662627935409546
Validation loss: 2.072065399539086

Epoch: 6| Step: 8
Training loss: 0.7863262891769409
Validation loss: 2.0248162425974363

Epoch: 6| Step: 9
Training loss: 0.6078945398330688
Validation loss: 2.0348264940323366

Epoch: 6| Step: 10
Training loss: 0.812743604183197
Validation loss: 2.036502351043045

Epoch: 6| Step: 11
Training loss: 2.366511344909668
Validation loss: 2.0289334686853553

Epoch: 6| Step: 12
Training loss: 1.7022345066070557
Validation loss: 2.0546497683371268

Epoch: 6| Step: 13
Training loss: 1.4447184801101685
Validation loss: 2.036076209878409

Epoch: 508| Step: 0
Training loss: 0.9314207434654236
Validation loss: 2.0179424337161485

Epoch: 6| Step: 1
Training loss: 1.1615012884140015
Validation loss: 2.028836663051318

Epoch: 6| Step: 2
Training loss: 1.6545332670211792
Validation loss: 2.0568897416514735

Epoch: 6| Step: 3
Training loss: 1.4984745979309082
Validation loss: 2.070504387219747

Epoch: 6| Step: 4
Training loss: 1.7492393255233765
Validation loss: 2.041590829049387

Epoch: 6| Step: 5
Training loss: 0.7402046918869019
Validation loss: 2.067543201549079

Epoch: 6| Step: 6
Training loss: 1.7642455101013184
Validation loss: 2.0508750946291032

Epoch: 6| Step: 7
Training loss: 0.9575194120407104
Validation loss: 2.0238644333295923

Epoch: 6| Step: 8
Training loss: 0.92200767993927
Validation loss: 2.0386543004743514

Epoch: 6| Step: 9
Training loss: 1.6608383655548096
Validation loss: 2.0475933679970364

Epoch: 6| Step: 10
Training loss: 0.8229546546936035
Validation loss: 2.0334618745311612

Epoch: 6| Step: 11
Training loss: 1.2611334323883057
Validation loss: 2.0290116610065585

Epoch: 6| Step: 12
Training loss: 1.3160332441329956
Validation loss: 2.016969878186462

Epoch: 6| Step: 13
Training loss: 1.1241612434387207
Validation loss: 2.0440573794867403

Epoch: 509| Step: 0
Training loss: 1.6172720193862915
Validation loss: 2.0992765631726993

Epoch: 6| Step: 1
Training loss: 1.499446153640747
Validation loss: 2.062758655958278

Epoch: 6| Step: 2
Training loss: 1.1716132164001465
Validation loss: 2.0531652473634288

Epoch: 6| Step: 3
Training loss: 0.9307116270065308
Validation loss: 2.014843289570142

Epoch: 6| Step: 4
Training loss: 1.734838843345642
Validation loss: 2.0370814261897916

Epoch: 6| Step: 5
Training loss: 1.6882452964782715
Validation loss: 2.0504159978640977

Epoch: 6| Step: 6
Training loss: 0.6907959580421448
Validation loss: 2.100626294330884

Epoch: 6| Step: 7
Training loss: 1.6725412607192993
Validation loss: 2.034248355896242

Epoch: 6| Step: 8
Training loss: 1.0274831056594849
Validation loss: 2.0346041648618636

Epoch: 6| Step: 9
Training loss: 0.7668164372444153
Validation loss: 2.0202938331070768

Epoch: 6| Step: 10
Training loss: 1.1487833261489868
Validation loss: 2.0364030074047785

Epoch: 6| Step: 11
Training loss: 0.9236528277397156
Validation loss: 2.008341718745488

Epoch: 6| Step: 12
Training loss: 0.9331928491592407
Validation loss: 2.0249721093844344

Epoch: 6| Step: 13
Training loss: 1.7897758483886719
Validation loss: 2.041028468839584

Epoch: 510| Step: 0
Training loss: 0.7303382158279419
Validation loss: 2.0313370214995516

Epoch: 6| Step: 1
Training loss: 1.3933546543121338
Validation loss: 2.0634777315201296

Epoch: 6| Step: 2
Training loss: 1.8282222747802734
Validation loss: 2.048973116823422

Epoch: 6| Step: 3
Training loss: 1.2837861776351929
Validation loss: 2.099961235959043

Epoch: 6| Step: 4
Training loss: 0.8443447351455688
Validation loss: 2.0504047434817076

Epoch: 6| Step: 5
Training loss: 1.0679267644882202
Validation loss: 1.9727011278111448

Epoch: 6| Step: 6
Training loss: 1.2687519788742065
Validation loss: 2.0715836632636284

Epoch: 6| Step: 7
Training loss: 0.4839142858982086
Validation loss: 2.0891914034402497

Epoch: 6| Step: 8
Training loss: 1.3945536613464355
Validation loss: 2.075637673818937

Epoch: 6| Step: 9
Training loss: 1.1404895782470703
Validation loss: 2.023264482457151

Epoch: 6| Step: 10
Training loss: 1.664258599281311
Validation loss: 2.0567619839022235

Epoch: 6| Step: 11
Training loss: 1.3695707321166992
Validation loss: 2.0313962685164584

Epoch: 6| Step: 12
Training loss: 1.2552852630615234
Validation loss: 2.020434343686668

Epoch: 6| Step: 13
Training loss: 2.51558518409729
Validation loss: 2.0288369399245068

Epoch: 511| Step: 0
Training loss: 1.2495365142822266
Validation loss: 2.011058831727633

Epoch: 6| Step: 1
Training loss: 1.6558902263641357
Validation loss: 2.02359389874243

Epoch: 6| Step: 2
Training loss: 0.7373802065849304
Validation loss: 2.035904492101362

Epoch: 6| Step: 3
Training loss: 1.1738224029541016
Validation loss: 2.031463510246687

Epoch: 6| Step: 4
Training loss: 1.0342521667480469
Validation loss: 2.017616346318235

Epoch: 6| Step: 5
Training loss: 1.2233226299285889
Validation loss: 2.0126859039388676

Epoch: 6| Step: 6
Training loss: 1.8362197875976562
Validation loss: 2.015441980413211

Epoch: 6| Step: 7
Training loss: 0.7120082974433899
Validation loss: 2.053564565156096

Epoch: 6| Step: 8
Training loss: 0.6968854665756226
Validation loss: 2.068160903069281

Epoch: 6| Step: 9
Training loss: 1.6547266244888306
Validation loss: 2.040216540777555

Epoch: 6| Step: 10
Training loss: 1.330777645111084
Validation loss: 2.0305507465075423

Epoch: 6| Step: 11
Training loss: 1.6632707118988037
Validation loss: 2.022477570400443

Epoch: 6| Step: 12
Training loss: 1.5024956464767456
Validation loss: 2.0628555103014876

Epoch: 6| Step: 13
Training loss: 1.3091374635696411
Validation loss: 2.0335155994661394

Epoch: 512| Step: 0
Training loss: 1.3923442363739014
Validation loss: 2.0188203883427445

Epoch: 6| Step: 1
Training loss: 1.4112367630004883
Validation loss: 2.045311063848516

Epoch: 6| Step: 2
Training loss: 1.1495394706726074
Validation loss: 2.0467208367522045

Epoch: 6| Step: 3
Training loss: 1.16385817527771
Validation loss: 2.047574127874067

Epoch: 6| Step: 4
Training loss: 0.9384085536003113
Validation loss: 2.0191982843542613

Epoch: 6| Step: 5
Training loss: 1.353572130203247
Validation loss: 2.0586197914615756

Epoch: 6| Step: 6
Training loss: 1.1416255235671997
Validation loss: 2.0739522787832443

Epoch: 6| Step: 7
Training loss: 1.988065481185913
Validation loss: 2.0509402469922136

Epoch: 6| Step: 8
Training loss: 1.4776742458343506
Validation loss: 2.0738162827748123

Epoch: 6| Step: 9
Training loss: 1.2139430046081543
Validation loss: 2.081398517854752

Epoch: 6| Step: 10
Training loss: 1.0004442930221558
Validation loss: 2.037495420825097

Epoch: 6| Step: 11
Training loss: 1.0232027769088745
Validation loss: 2.034932232672168

Epoch: 6| Step: 12
Training loss: 1.3864009380340576
Validation loss: 2.035531267043083

Epoch: 6| Step: 13
Training loss: 0.6369812488555908
Validation loss: 2.042439176190284

Epoch: 513| Step: 0
Training loss: 1.0862314701080322
Validation loss: 2.04123782086116

Epoch: 6| Step: 1
Training loss: 1.3779504299163818
Validation loss: 2.0549436525631974

Epoch: 6| Step: 2
Training loss: 1.3988747596740723
Validation loss: 2.046390282210483

Epoch: 6| Step: 3
Training loss: 0.8162425756454468
Validation loss: 2.0494055414712555

Epoch: 6| Step: 4
Training loss: 1.6194872856140137
Validation loss: 2.017800372133973

Epoch: 6| Step: 5
Training loss: 1.1683094501495361
Validation loss: 2.0493503616702173

Epoch: 6| Step: 6
Training loss: 1.2737621068954468
Validation loss: 2.0575145470198763

Epoch: 6| Step: 7
Training loss: 1.4902414083480835
Validation loss: 2.045774520084422

Epoch: 6| Step: 8
Training loss: 1.3916306495666504
Validation loss: 2.0697497167894916

Epoch: 6| Step: 9
Training loss: 1.1182562112808228
Validation loss: 2.0476166381630847

Epoch: 6| Step: 10
Training loss: 0.7863935232162476
Validation loss: 2.0253758379208144

Epoch: 6| Step: 11
Training loss: 1.026076316833496
Validation loss: 2.0161047545812463

Epoch: 6| Step: 12
Training loss: 1.597076654434204
Validation loss: 2.105746510208294

Epoch: 6| Step: 13
Training loss: 1.3161184787750244
Validation loss: 2.0937236560288297

Epoch: 514| Step: 0
Training loss: 1.219727635383606
Validation loss: 2.096503255187824

Epoch: 6| Step: 1
Training loss: 1.6781799793243408
Validation loss: 2.1171991889194777

Epoch: 6| Step: 2
Training loss: 1.3301838636398315
Validation loss: 2.1610412174655544

Epoch: 6| Step: 3
Training loss: 1.3072509765625
Validation loss: 2.1118528484016337

Epoch: 6| Step: 4
Training loss: 1.2217134237289429
Validation loss: 2.1430688442722445

Epoch: 6| Step: 5
Training loss: 1.1883119344711304
Validation loss: 2.0909137149010935

Epoch: 6| Step: 6
Training loss: 0.6367323398590088
Validation loss: 2.1005913467817408

Epoch: 6| Step: 7
Training loss: 1.3306798934936523
Validation loss: 2.0233054032889743

Epoch: 6| Step: 8
Training loss: 1.34236741065979
Validation loss: 2.0554426677765383

Epoch: 6| Step: 9
Training loss: 1.549110770225525
Validation loss: 2.051890719321466

Epoch: 6| Step: 10
Training loss: 1.3165149688720703
Validation loss: 2.047302343512094

Epoch: 6| Step: 11
Training loss: 1.6505928039550781
Validation loss: 2.071893999653478

Epoch: 6| Step: 12
Training loss: 1.0831677913665771
Validation loss: 2.0451443413252473

Epoch: 6| Step: 13
Training loss: 1.6141451597213745
Validation loss: 2.0211591989763322

Epoch: 515| Step: 0
Training loss: 1.3793799877166748
Validation loss: 2.087920804177561

Epoch: 6| Step: 1
Training loss: 0.9359995126724243
Validation loss: 2.028803515177901

Epoch: 6| Step: 2
Training loss: 0.9803094863891602
Validation loss: 2.0439471442212342

Epoch: 6| Step: 3
Training loss: 1.3140379190444946
Validation loss: 2.036974560829901

Epoch: 6| Step: 4
Training loss: 0.9846807718276978
Validation loss: 2.0366551427431006

Epoch: 6| Step: 5
Training loss: 1.403557300567627
Validation loss: 2.104269527619885

Epoch: 6| Step: 6
Training loss: 1.8196017742156982
Validation loss: 2.0477080127244354

Epoch: 6| Step: 7
Training loss: 1.656816005706787
Validation loss: 2.0814193640985796

Epoch: 6| Step: 8
Training loss: 1.0671217441558838
Validation loss: 2.071443675666727

Epoch: 6| Step: 9
Training loss: 1.4568054676055908
Validation loss: 2.079420958795855

Epoch: 6| Step: 10
Training loss: 1.322075605392456
Validation loss: 2.0850712996657177

Epoch: 6| Step: 11
Training loss: 0.6933324933052063
Validation loss: 2.0901207795707126

Epoch: 6| Step: 12
Training loss: 1.4553502798080444
Validation loss: 2.0869493971588793

Epoch: 6| Step: 13
Training loss: 1.1099439859390259
Validation loss: 2.048089358114427

Epoch: 516| Step: 0
Training loss: 0.9421247839927673
Validation loss: 2.0543591912074755

Epoch: 6| Step: 1
Training loss: 1.6467260122299194
Validation loss: 2.0318543590525144

Epoch: 6| Step: 2
Training loss: 0.9937143325805664
Validation loss: 2.020487694330113

Epoch: 6| Step: 3
Training loss: 1.579089879989624
Validation loss: 2.036867577542541

Epoch: 6| Step: 4
Training loss: 1.00553560256958
Validation loss: 2.0855513183019494

Epoch: 6| Step: 5
Training loss: 1.658179759979248
Validation loss: 2.049874226252238

Epoch: 6| Step: 6
Training loss: 0.7902179956436157
Validation loss: 2.054195192552382

Epoch: 6| Step: 7
Training loss: 1.7257908582687378
Validation loss: 2.0867523044668217

Epoch: 6| Step: 8
Training loss: 0.796933114528656
Validation loss: 2.055774119592482

Epoch: 6| Step: 9
Training loss: 1.6820509433746338
Validation loss: 2.0815016056901667

Epoch: 6| Step: 10
Training loss: 1.199561595916748
Validation loss: 1.9916831524141374

Epoch: 6| Step: 11
Training loss: 0.8643860816955566
Validation loss: 2.1238067944844565

Epoch: 6| Step: 12
Training loss: 1.0043500661849976
Validation loss: 2.0607301676145164

Epoch: 6| Step: 13
Training loss: 1.7067934274673462
Validation loss: 2.0342828060991023

Epoch: 517| Step: 0
Training loss: 1.2432610988616943
Validation loss: 2.028810290880101

Epoch: 6| Step: 1
Training loss: 0.9580466747283936
Validation loss: 2.0383178521228094

Epoch: 6| Step: 2
Training loss: 1.3858981132507324
Validation loss: 2.081239113243677

Epoch: 6| Step: 3
Training loss: 1.7786834239959717
Validation loss: 1.994120931112638

Epoch: 6| Step: 4
Training loss: 1.4428656101226807
Validation loss: 2.0143656371742167

Epoch: 6| Step: 5
Training loss: 1.5349926948547363
Validation loss: 2.0548924399960424

Epoch: 6| Step: 6
Training loss: 1.6379040479660034
Validation loss: 2.057652067112666

Epoch: 6| Step: 7
Training loss: 0.8086827397346497
Validation loss: 1.9946389326485254

Epoch: 6| Step: 8
Training loss: 1.3076965808868408
Validation loss: 2.0710478367344027

Epoch: 6| Step: 9
Training loss: 1.3526294231414795
Validation loss: 2.0628960004416843

Epoch: 6| Step: 10
Training loss: 0.7024837732315063
Validation loss: 2.0428326258095364

Epoch: 6| Step: 11
Training loss: 1.3223528861999512
Validation loss: 2.0062673976344447

Epoch: 6| Step: 12
Training loss: 0.8798762559890747
Validation loss: 2.067001724755892

Epoch: 6| Step: 13
Training loss: 1.3275994062423706
Validation loss: 2.054854246877855

Epoch: 518| Step: 0
Training loss: 1.179831862449646
Validation loss: 2.0429316182290354

Epoch: 6| Step: 1
Training loss: 1.5129320621490479
Validation loss: 2.0853664900666926

Epoch: 6| Step: 2
Training loss: 1.1328486204147339
Validation loss: 2.068964736436003

Epoch: 6| Step: 3
Training loss: 1.3787975311279297
Validation loss: 2.0883169328012774

Epoch: 6| Step: 4
Training loss: 1.0953501462936401
Validation loss: 2.0364823879734164

Epoch: 6| Step: 5
Training loss: 1.0237380266189575
Validation loss: 2.105296988641062

Epoch: 6| Step: 6
Training loss: 1.1214171648025513
Validation loss: 2.075101967780821

Epoch: 6| Step: 7
Training loss: 1.269681453704834
Validation loss: 2.05984228913502

Epoch: 6| Step: 8
Training loss: 1.1681663990020752
Validation loss: 2.0777578071881364

Epoch: 6| Step: 9
Training loss: 1.7601063251495361
Validation loss: 2.079898677846437

Epoch: 6| Step: 10
Training loss: 1.6528615951538086
Validation loss: 2.066961711452853

Epoch: 6| Step: 11
Training loss: 0.5787980556488037
Validation loss: 2.0745885807980775

Epoch: 6| Step: 12
Training loss: 1.4782086610794067
Validation loss: 2.0345703491600613

Epoch: 6| Step: 13
Training loss: 1.2928433418273926
Validation loss: 2.0669265562488186

Epoch: 519| Step: 0
Training loss: 1.05828058719635
Validation loss: 2.056065697823801

Epoch: 6| Step: 1
Training loss: 1.135366678237915
Validation loss: 2.0450379489570536

Epoch: 6| Step: 2
Training loss: 1.575617790222168
Validation loss: 2.0274042442280757

Epoch: 6| Step: 3
Training loss: 0.9793408513069153
Validation loss: 2.0576868134160198

Epoch: 6| Step: 4
Training loss: 1.4731321334838867
Validation loss: 2.0747865194915445

Epoch: 6| Step: 5
Training loss: 1.0053213834762573
Validation loss: 2.023280123228668

Epoch: 6| Step: 6
Training loss: 1.4737552404403687
Validation loss: 2.009133279964488

Epoch: 6| Step: 7
Training loss: 1.2950119972229004
Validation loss: 2.027617799338474

Epoch: 6| Step: 8
Training loss: 0.8734136819839478
Validation loss: 2.075169209511049

Epoch: 6| Step: 9
Training loss: 1.2569444179534912
Validation loss: 1.9811273428701586

Epoch: 6| Step: 10
Training loss: 1.3114655017852783
Validation loss: 2.0469074146721953

Epoch: 6| Step: 11
Training loss: 1.624530553817749
Validation loss: 2.074759667919528

Epoch: 6| Step: 12
Training loss: 1.49198317527771
Validation loss: 2.0656336507489605

Epoch: 6| Step: 13
Training loss: 0.8302402496337891
Validation loss: 2.0420642142654746

Epoch: 520| Step: 0
Training loss: 1.7517199516296387
Validation loss: 2.013616620853383

Epoch: 6| Step: 1
Training loss: 1.149587631225586
Validation loss: 2.0504195151790494

Epoch: 6| Step: 2
Training loss: 1.2090611457824707
Validation loss: 2.049305000612813

Epoch: 6| Step: 3
Training loss: 1.298808217048645
Validation loss: 2.044052263741852

Epoch: 6| Step: 4
Training loss: 1.7366355657577515
Validation loss: 2.0436423299133137

Epoch: 6| Step: 5
Training loss: 1.1728124618530273
Validation loss: 2.0423249531817693

Epoch: 6| Step: 6
Training loss: 1.2413465976715088
Validation loss: 2.06440891117178

Epoch: 6| Step: 7
Training loss: 0.9011216759681702
Validation loss: 2.0610463298777097

Epoch: 6| Step: 8
Training loss: 0.6317983865737915
Validation loss: 2.054139127013504

Epoch: 6| Step: 9
Training loss: 1.5953747034072876
Validation loss: 2.0433037306672786

Epoch: 6| Step: 10
Training loss: 1.3772518634796143
Validation loss: 2.037836910575949

Epoch: 6| Step: 11
Training loss: 1.1011288166046143
Validation loss: 2.0450489649208645

Epoch: 6| Step: 12
Training loss: 0.9908839464187622
Validation loss: 2.0431227607111775

Epoch: 6| Step: 13
Training loss: 1.1231218576431274
Validation loss: 2.058564457842099

Epoch: 521| Step: 0
Training loss: 0.8744947910308838
Validation loss: 2.0174963282000635

Epoch: 6| Step: 1
Training loss: 1.3434481620788574
Validation loss: 2.0237418015797934

Epoch: 6| Step: 2
Training loss: 0.7967556715011597
Validation loss: 2.0256159049208446

Epoch: 6| Step: 3
Training loss: 1.9074164628982544
Validation loss: 2.06468100957973

Epoch: 6| Step: 4
Training loss: 1.7744786739349365
Validation loss: 2.0610647919357463

Epoch: 6| Step: 5
Training loss: 1.3704140186309814
Validation loss: 2.0601446859298216

Epoch: 6| Step: 6
Training loss: 1.6971137523651123
Validation loss: 2.0477693952539915

Epoch: 6| Step: 7
Training loss: 1.4288959503173828
Validation loss: 2.0031834699774302

Epoch: 6| Step: 8
Training loss: 0.858709990978241
Validation loss: 2.0243999650401454

Epoch: 6| Step: 9
Training loss: 1.0467946529388428
Validation loss: 2.036804414564563

Epoch: 6| Step: 10
Training loss: 1.3052703142166138
Validation loss: 2.0671455193591375

Epoch: 6| Step: 11
Training loss: 1.197137475013733
Validation loss: 1.9992986212494552

Epoch: 6| Step: 12
Training loss: 0.9838951826095581
Validation loss: 2.0550427411192205

Epoch: 6| Step: 13
Training loss: 0.5867294073104858
Validation loss: 2.085700591405233

Epoch: 522| Step: 0
Training loss: 0.6856090426445007
Validation loss: 2.0913300821858067

Epoch: 6| Step: 1
Training loss: 1.1511552333831787
Validation loss: 2.064786687974007

Epoch: 6| Step: 2
Training loss: 1.4411325454711914
Validation loss: 2.07499752377951

Epoch: 6| Step: 3
Training loss: 0.9814600944519043
Validation loss: 2.0777777792305074

Epoch: 6| Step: 4
Training loss: 1.8989229202270508
Validation loss: 2.0701802776705835

Epoch: 6| Step: 5
Training loss: 1.3005671501159668
Validation loss: 2.0680676147501957

Epoch: 6| Step: 6
Training loss: 0.7288451790809631
Validation loss: 2.025864452444097

Epoch: 6| Step: 7
Training loss: 0.6882697343826294
Validation loss: 2.051493046104267

Epoch: 6| Step: 8
Training loss: 1.3753186464309692
Validation loss: 2.015126097586847

Epoch: 6| Step: 9
Training loss: 1.5319042205810547
Validation loss: 2.051657603633019

Epoch: 6| Step: 10
Training loss: 1.4016238451004028
Validation loss: 2.0510701466632146

Epoch: 6| Step: 11
Training loss: 1.6729408502578735
Validation loss: 2.1149494365979264

Epoch: 6| Step: 12
Training loss: 1.1375097036361694
Validation loss: 2.0623433666844524

Epoch: 6| Step: 13
Training loss: 1.109371542930603
Validation loss: 2.001936025516961

Epoch: 523| Step: 0
Training loss: 0.873100757598877
Validation loss: 2.001322606558441

Epoch: 6| Step: 1
Training loss: 1.319057822227478
Validation loss: 2.057798372801914

Epoch: 6| Step: 2
Training loss: 1.1674151420593262
Validation loss: 2.0173153364530174

Epoch: 6| Step: 3
Training loss: 1.5484133958816528
Validation loss: 2.031206721900612

Epoch: 6| Step: 4
Training loss: 1.3104170560836792
Validation loss: 2.014024526842179

Epoch: 6| Step: 5
Training loss: 0.9727802872657776
Validation loss: 2.0583265443002023

Epoch: 6| Step: 6
Training loss: 1.8027691841125488
Validation loss: 2.0201358384983514

Epoch: 6| Step: 7
Training loss: 0.7667543888092041
Validation loss: 2.075651184205086

Epoch: 6| Step: 8
Training loss: 0.9184502363204956
Validation loss: 2.0230417661769415

Epoch: 6| Step: 9
Training loss: 1.6421988010406494
Validation loss: 2.0600903880211616

Epoch: 6| Step: 10
Training loss: 1.3553096055984497
Validation loss: 2.035738698897823

Epoch: 6| Step: 11
Training loss: 1.0517566204071045
Validation loss: 2.0486592708095426

Epoch: 6| Step: 12
Training loss: 1.7358078956604004
Validation loss: 2.0646950839668192

Epoch: 6| Step: 13
Training loss: 0.8507740497589111
Validation loss: 2.04153545312984

Epoch: 524| Step: 0
Training loss: 1.6151022911071777
Validation loss: 2.102864980697632

Epoch: 6| Step: 1
Training loss: 0.8770168423652649
Validation loss: 2.0300327436898344

Epoch: 6| Step: 2
Training loss: 1.6963279247283936
Validation loss: 2.0487397063163018

Epoch: 6| Step: 3
Training loss: 1.2635951042175293
Validation loss: 2.0506942990005657

Epoch: 6| Step: 4
Training loss: 1.1961795091629028
Validation loss: 2.0870469411214194

Epoch: 6| Step: 5
Training loss: 1.195432186126709
Validation loss: 2.0542231336716683

Epoch: 6| Step: 6
Training loss: 0.8318334817886353
Validation loss: 2.08725135044385

Epoch: 6| Step: 7
Training loss: 0.8859990239143372
Validation loss: 2.023096376849759

Epoch: 6| Step: 8
Training loss: 1.2781904935836792
Validation loss: 2.019948301776763

Epoch: 6| Step: 9
Training loss: 1.5282182693481445
Validation loss: 2.0631904089322655

Epoch: 6| Step: 10
Training loss: 1.6016507148742676
Validation loss: 2.1027766709686606

Epoch: 6| Step: 11
Training loss: 1.1573903560638428
Validation loss: 2.0574190334607194

Epoch: 6| Step: 12
Training loss: 0.8433578014373779
Validation loss: 2.0338446670962917

Epoch: 6| Step: 13
Training loss: 1.5862535238265991
Validation loss: 2.005242263117144

Epoch: 525| Step: 0
Training loss: 1.0938549041748047
Validation loss: 2.0752572577486754

Epoch: 6| Step: 1
Training loss: 1.3035945892333984
Validation loss: 2.001571132290748

Epoch: 6| Step: 2
Training loss: 1.6152507066726685
Validation loss: 2.0168370636560584

Epoch: 6| Step: 3
Training loss: 1.3272982835769653
Validation loss: 2.0505930518591278

Epoch: 6| Step: 4
Training loss: 1.3012115955352783
Validation loss: 2.009946648792554

Epoch: 6| Step: 5
Training loss: 0.9507028460502625
Validation loss: 2.0805855540819067

Epoch: 6| Step: 6
Training loss: 0.8728437423706055
Validation loss: 2.032919363308978

Epoch: 6| Step: 7
Training loss: 0.9836190938949585
Validation loss: 2.0550870869749334

Epoch: 6| Step: 8
Training loss: 1.461495280265808
Validation loss: 2.033589745080599

Epoch: 6| Step: 9
Training loss: 1.4848768711090088
Validation loss: 2.101372835456684

Epoch: 6| Step: 10
Training loss: 1.0664503574371338
Validation loss: 2.0903063358799105

Epoch: 6| Step: 11
Training loss: 1.2327181100845337
Validation loss: 2.075386449854861

Epoch: 6| Step: 12
Training loss: 1.3540503978729248
Validation loss: 2.108942722761503

Epoch: 6| Step: 13
Training loss: 1.2586171627044678
Validation loss: 2.082655314476259

Epoch: 526| Step: 0
Training loss: 1.1773509979248047
Validation loss: 1.9999315123404227

Epoch: 6| Step: 1
Training loss: 0.8809201717376709
Validation loss: 2.0099651980143722

Epoch: 6| Step: 2
Training loss: 1.1807036399841309
Validation loss: 2.063022054651732

Epoch: 6| Step: 3
Training loss: 1.5391281843185425
Validation loss: 2.0365173201407156

Epoch: 6| Step: 4
Training loss: 1.1322534084320068
Validation loss: 2.0358397447934715

Epoch: 6| Step: 5
Training loss: 1.5259370803833008
Validation loss: 2.0586827314028175

Epoch: 6| Step: 6
Training loss: 1.3070114850997925
Validation loss: 2.0178964291849444

Epoch: 6| Step: 7
Training loss: 1.3133140802383423
Validation loss: 1.9896409793566632

Epoch: 6| Step: 8
Training loss: 1.241195559501648
Validation loss: 2.0566712784510788

Epoch: 6| Step: 9
Training loss: 0.9786476492881775
Validation loss: 2.019654122732019

Epoch: 6| Step: 10
Training loss: 1.3714358806610107
Validation loss: 2.0238239970258487

Epoch: 6| Step: 11
Training loss: 1.5998165607452393
Validation loss: 2.0372354317736883

Epoch: 6| Step: 12
Training loss: 0.6747667789459229
Validation loss: 2.043204270383363

Epoch: 6| Step: 13
Training loss: 1.6424283981323242
Validation loss: 2.039914549037974

Epoch: 527| Step: 0
Training loss: 1.3387759923934937
Validation loss: 2.0366191479467575

Epoch: 6| Step: 1
Training loss: 1.109762191772461
Validation loss: 2.037472294222924

Epoch: 6| Step: 2
Training loss: 1.4826290607452393
Validation loss: 2.092293411172846

Epoch: 6| Step: 3
Training loss: 0.7916588187217712
Validation loss: 2.0341888473879908

Epoch: 6| Step: 4
Training loss: 1.47641921043396
Validation loss: 2.0847366086898313

Epoch: 6| Step: 5
Training loss: 1.5516753196716309
Validation loss: 2.1212074833531536

Epoch: 6| Step: 6
Training loss: 0.9854274392127991
Validation loss: 2.0585887829462686

Epoch: 6| Step: 7
Training loss: 1.3969385623931885
Validation loss: 2.1196882622216338

Epoch: 6| Step: 8
Training loss: 1.3692320585250854
Validation loss: 2.1331474447763092

Epoch: 6| Step: 9
Training loss: 1.4560799598693848
Validation loss: 2.070241358972365

Epoch: 6| Step: 10
Training loss: 1.4666565656661987
Validation loss: 2.0656439822207213

Epoch: 6| Step: 11
Training loss: 1.4764463901519775
Validation loss: 2.057254050367622

Epoch: 6| Step: 12
Training loss: 0.9205883145332336
Validation loss: 2.0203245429582495

Epoch: 6| Step: 13
Training loss: 1.2330307960510254
Validation loss: 2.0142966047410042

Epoch: 528| Step: 0
Training loss: 1.2840754985809326
Validation loss: 2.0535668429508003

Epoch: 6| Step: 1
Training loss: 1.0941855907440186
Validation loss: 2.038168857174535

Epoch: 6| Step: 2
Training loss: 1.0675010681152344
Validation loss: 2.036539359759259

Epoch: 6| Step: 3
Training loss: 1.1368602514266968
Validation loss: 2.0454104356868292

Epoch: 6| Step: 4
Training loss: 1.3568516969680786
Validation loss: 2.049820828181441

Epoch: 6| Step: 5
Training loss: 1.3846468925476074
Validation loss: 2.030129160932315

Epoch: 6| Step: 6
Training loss: 0.8752543926239014
Validation loss: 2.0173013787115774

Epoch: 6| Step: 7
Training loss: 0.7767577767372131
Validation loss: 2.0581373847940916

Epoch: 6| Step: 8
Training loss: 1.837822437286377
Validation loss: 2.0062586017834243

Epoch: 6| Step: 9
Training loss: 1.086937665939331
Validation loss: 2.0499884287516275

Epoch: 6| Step: 10
Training loss: 1.5839800834655762
Validation loss: 2.0655644068153958

Epoch: 6| Step: 11
Training loss: 1.548635721206665
Validation loss: 2.054637009097684

Epoch: 6| Step: 12
Training loss: 1.2300491333007812
Validation loss: 2.0862496232473724

Epoch: 6| Step: 13
Training loss: 1.062349557876587
Validation loss: 2.1250699720075055

Epoch: 529| Step: 0
Training loss: 1.2195048332214355
Validation loss: 2.112658045625174

Epoch: 6| Step: 1
Training loss: 1.1371867656707764
Validation loss: 2.054247401093924

Epoch: 6| Step: 2
Training loss: 0.694132387638092
Validation loss: 2.072101544308406

Epoch: 6| Step: 3
Training loss: 1.3044906854629517
Validation loss: 2.0735665393132034

Epoch: 6| Step: 4
Training loss: 1.1869348287582397
Validation loss: 2.0390038272385955

Epoch: 6| Step: 5
Training loss: 1.4256342649459839
Validation loss: 2.0907132215397333

Epoch: 6| Step: 6
Training loss: 1.362412929534912
Validation loss: 2.022777798355267

Epoch: 6| Step: 7
Training loss: 0.8140330910682678
Validation loss: 2.0637681945677726

Epoch: 6| Step: 8
Training loss: 1.842185139656067
Validation loss: 2.0475083704917663

Epoch: 6| Step: 9
Training loss: 0.6573530435562134
Validation loss: 2.087123078684653

Epoch: 6| Step: 10
Training loss: 1.343451738357544
Validation loss: 2.011850715965353

Epoch: 6| Step: 11
Training loss: 0.592315137386322
Validation loss: 2.068845102863927

Epoch: 6| Step: 12
Training loss: 1.7157680988311768
Validation loss: 2.0573469541406118

Epoch: 6| Step: 13
Training loss: 1.820014476776123
Validation loss: 2.0521813643875944

Epoch: 530| Step: 0
Training loss: 1.384169101715088
Validation loss: 2.022020762966525

Epoch: 6| Step: 1
Training loss: 1.6822216510772705
Validation loss: 2.0096456248273133

Epoch: 6| Step: 2
Training loss: 1.3842813968658447
Validation loss: 2.066421049897389

Epoch: 6| Step: 3
Training loss: 0.9777578115463257
Validation loss: 2.08726760648912

Epoch: 6| Step: 4
Training loss: 1.0724842548370361
Validation loss: 2.016858358536997

Epoch: 6| Step: 5
Training loss: 0.9925782680511475
Validation loss: 2.0303729067566576

Epoch: 6| Step: 6
Training loss: 1.1548875570297241
Validation loss: 2.1115614598797214

Epoch: 6| Step: 7
Training loss: 0.9638221859931946
Validation loss: 2.0250786658256286

Epoch: 6| Step: 8
Training loss: 1.450636863708496
Validation loss: 2.0917180430504585

Epoch: 6| Step: 9
Training loss: 1.2746607065200806
Validation loss: 2.025447501931139

Epoch: 6| Step: 10
Training loss: 1.1853089332580566
Validation loss: 2.0672023488629248

Epoch: 6| Step: 11
Training loss: 1.1090949773788452
Validation loss: 2.0825477594970376

Epoch: 6| Step: 12
Training loss: 1.8147714138031006
Validation loss: 2.077246496754308

Epoch: 6| Step: 13
Training loss: 1.1566381454467773
Validation loss: 2.0066369118229037

Epoch: 531| Step: 0
Training loss: 1.357532262802124
Validation loss: 2.093715501087968

Epoch: 6| Step: 1
Training loss: 1.2333966493606567
Validation loss: 2.0524990597078876

Epoch: 6| Step: 2
Training loss: 1.2624971866607666
Validation loss: 2.0615781763548493

Epoch: 6| Step: 3
Training loss: 1.0886204242706299
Validation loss: 2.0477739341797365

Epoch: 6| Step: 4
Training loss: 1.8644630908966064
Validation loss: 2.045241512278075

Epoch: 6| Step: 5
Training loss: 1.2733771800994873
Validation loss: 2.0339483599508963

Epoch: 6| Step: 6
Training loss: 0.49855881929397583
Validation loss: 2.0302988611241823

Epoch: 6| Step: 7
Training loss: 1.499758005142212
Validation loss: 2.0573416550954184

Epoch: 6| Step: 8
Training loss: 1.414750099182129
Validation loss: 2.0451671487541607

Epoch: 6| Step: 9
Training loss: 1.3121713399887085
Validation loss: 2.050396485995221

Epoch: 6| Step: 10
Training loss: 0.7843242287635803
Validation loss: 2.076592952974381

Epoch: 6| Step: 11
Training loss: 1.4964724779129028
Validation loss: 2.063426495880209

Epoch: 6| Step: 12
Training loss: 0.49351930618286133
Validation loss: 2.067445332004178

Epoch: 6| Step: 13
Training loss: 1.5396088361740112
Validation loss: 2.0651970294214066

Epoch: 532| Step: 0
Training loss: 0.8229951858520508
Validation loss: 2.0888078315283662

Epoch: 6| Step: 1
Training loss: 1.3943023681640625
Validation loss: 2.066423298210226

Epoch: 6| Step: 2
Training loss: 1.3777294158935547
Validation loss: 2.0174494892038326

Epoch: 6| Step: 3
Training loss: 1.583998203277588
Validation loss: 2.071465857567326

Epoch: 6| Step: 4
Training loss: 1.407291293144226
Validation loss: 2.1047659433016213

Epoch: 6| Step: 5
Training loss: 1.5035486221313477
Validation loss: 2.1129140597517773

Epoch: 6| Step: 6
Training loss: 1.1220382452011108
Validation loss: 2.057154575983683

Epoch: 6| Step: 7
Training loss: 0.8826755285263062
Validation loss: 2.114295797963296

Epoch: 6| Step: 8
Training loss: 1.253929615020752
Validation loss: 2.059012466861356

Epoch: 6| Step: 9
Training loss: 0.8096300363540649
Validation loss: 2.046752652814311

Epoch: 6| Step: 10
Training loss: 0.9327488541603088
Validation loss: 2.029075954550056

Epoch: 6| Step: 11
Training loss: 1.3131957054138184
Validation loss: 2.070652131111391

Epoch: 6| Step: 12
Training loss: 1.5266746282577515
Validation loss: 2.1085508126084522

Epoch: 6| Step: 13
Training loss: 0.7694576978683472
Validation loss: 2.082903790217574

Epoch: 533| Step: 0
Training loss: 0.9020341634750366
Validation loss: 2.04224556748585

Epoch: 6| Step: 1
Training loss: 0.9800793528556824
Validation loss: 2.0717417822089246

Epoch: 6| Step: 2
Training loss: 0.9106489419937134
Validation loss: 2.0206260963152816

Epoch: 6| Step: 3
Training loss: 1.0160245895385742
Validation loss: 2.079397410474798

Epoch: 6| Step: 4
Training loss: 1.6357522010803223
Validation loss: 2.04234589299848

Epoch: 6| Step: 5
Training loss: 1.1979622840881348
Validation loss: 2.0557498111519763

Epoch: 6| Step: 6
Training loss: 0.9693702459335327
Validation loss: 2.047016018180437

Epoch: 6| Step: 7
Training loss: 1.0590879917144775
Validation loss: 2.0813687642415366

Epoch: 6| Step: 8
Training loss: 1.3599638938903809
Validation loss: 2.0502274318407943

Epoch: 6| Step: 9
Training loss: 1.5641422271728516
Validation loss: 2.054216536142493

Epoch: 6| Step: 10
Training loss: 1.3966172933578491
Validation loss: 2.0663578330829577

Epoch: 6| Step: 11
Training loss: 1.7449102401733398
Validation loss: 2.061422058331069

Epoch: 6| Step: 12
Training loss: 1.2505375146865845
Validation loss: 2.0859345569405505

Epoch: 6| Step: 13
Training loss: 0.9071068167686462
Validation loss: 2.003981274943198

Epoch: 534| Step: 0
Training loss: 1.15394127368927
Validation loss: 2.09757738472313

Epoch: 6| Step: 1
Training loss: 1.1218377351760864
Validation loss: 2.0837242372574343

Epoch: 6| Step: 2
Training loss: 1.072683334350586
Validation loss: 2.0273568155944988

Epoch: 6| Step: 3
Training loss: 1.4488961696624756
Validation loss: 2.0546240293851463

Epoch: 6| Step: 4
Training loss: 0.9296048879623413
Validation loss: 2.027582247411051

Epoch: 6| Step: 5
Training loss: 1.0259898900985718
Validation loss: 2.0318477333232923

Epoch: 6| Step: 6
Training loss: 1.487236499786377
Validation loss: 2.0486618793138893

Epoch: 6| Step: 7
Training loss: 1.6302618980407715
Validation loss: 2.0593065574604976

Epoch: 6| Step: 8
Training loss: 1.1233341693878174
Validation loss: 2.0385873497173352

Epoch: 6| Step: 9
Training loss: 1.357669711112976
Validation loss: 2.0466131318000054

Epoch: 6| Step: 10
Training loss: 0.8907774686813354
Validation loss: 2.03800912954474

Epoch: 6| Step: 11
Training loss: 1.1186202764511108
Validation loss: 2.0563749972210137

Epoch: 6| Step: 12
Training loss: 1.383495569229126
Validation loss: 2.0563454448535876

Epoch: 6| Step: 13
Training loss: 1.5992897748947144
Validation loss: 2.0713035047695203

Epoch: 535| Step: 0
Training loss: 1.448540210723877
Validation loss: 2.0628230135927916

Epoch: 6| Step: 1
Training loss: 1.3550124168395996
Validation loss: 2.0399335981697164

Epoch: 6| Step: 2
Training loss: 0.8613461852073669
Validation loss: 2.073403463568739

Epoch: 6| Step: 3
Training loss: 1.2846516370773315
Validation loss: 2.036231017881824

Epoch: 6| Step: 4
Training loss: 0.9867422580718994
Validation loss: 2.064814357347386

Epoch: 6| Step: 5
Training loss: 1.1455535888671875
Validation loss: 2.051034822258898

Epoch: 6| Step: 6
Training loss: 1.9522768259048462
Validation loss: 2.08387819797762

Epoch: 6| Step: 7
Training loss: 0.9216321706771851
Validation loss: 2.0493084205094205

Epoch: 6| Step: 8
Training loss: 1.1307570934295654
Validation loss: 2.0553691079539638

Epoch: 6| Step: 9
Training loss: 1.2401994466781616
Validation loss: 2.071266815226565

Epoch: 6| Step: 10
Training loss: 1.5306388139724731
Validation loss: 2.059584202304963

Epoch: 6| Step: 11
Training loss: 1.247909665107727
Validation loss: 2.078212438091155

Epoch: 6| Step: 12
Training loss: 0.6281235814094543
Validation loss: 2.0041100632759834

Epoch: 6| Step: 13
Training loss: 1.7145448923110962
Validation loss: 2.0676465675395024

Epoch: 536| Step: 0
Training loss: 1.3021429777145386
Validation loss: 2.0568518459155993

Epoch: 6| Step: 1
Training loss: 1.7182058095932007
Validation loss: 2.0347359782905987

Epoch: 6| Step: 2
Training loss: 1.7227144241333008
Validation loss: 2.0937148242868404

Epoch: 6| Step: 3
Training loss: 1.0490572452545166
Validation loss: 2.0455501002650105

Epoch: 6| Step: 4
Training loss: 1.0907647609710693
Validation loss: 2.0176439387823946

Epoch: 6| Step: 5
Training loss: 1.0583595037460327
Validation loss: 2.0828658124451995

Epoch: 6| Step: 6
Training loss: 0.7774169445037842
Validation loss: 2.065557236312538

Epoch: 6| Step: 7
Training loss: 1.0405138731002808
Validation loss: 2.026338913107431

Epoch: 6| Step: 8
Training loss: 0.7965293526649475
Validation loss: 2.043009740050121

Epoch: 6| Step: 9
Training loss: 0.9276625514030457
Validation loss: 2.0975884083778626

Epoch: 6| Step: 10
Training loss: 1.0182369947433472
Validation loss: 2.054394955276161

Epoch: 6| Step: 11
Training loss: 1.893758773803711
Validation loss: 2.0661004717632006

Epoch: 6| Step: 12
Training loss: 0.9231961965560913
Validation loss: 1.9957840211929814

Epoch: 6| Step: 13
Training loss: 1.7212729454040527
Validation loss: 2.030156648287209

Epoch: 537| Step: 0
Training loss: 1.4829325675964355
Validation loss: 2.004737354093982

Epoch: 6| Step: 1
Training loss: 1.3057516813278198
Validation loss: 2.0987055352939072

Epoch: 6| Step: 2
Training loss: 0.6562681198120117
Validation loss: 2.0381128429084696

Epoch: 6| Step: 3
Training loss: 1.2188889980316162
Validation loss: 2.0825357385860976

Epoch: 6| Step: 4
Training loss: 1.3467562198638916
Validation loss: 2.0839948538810975

Epoch: 6| Step: 5
Training loss: 0.9038025140762329
Validation loss: 2.0781982585948002

Epoch: 6| Step: 6
Training loss: 1.2593729496002197
Validation loss: 2.0769266595122633

Epoch: 6| Step: 7
Training loss: 0.8481864929199219
Validation loss: 2.067522774460495

Epoch: 6| Step: 8
Training loss: 1.3399226665496826
Validation loss: 2.055777624089231

Epoch: 6| Step: 9
Training loss: 1.7194218635559082
Validation loss: 2.0681470504371067

Epoch: 6| Step: 10
Training loss: 1.0056560039520264
Validation loss: 2.0806074962821057

Epoch: 6| Step: 11
Training loss: 1.2433651685714722
Validation loss: 2.0703826104440997

Epoch: 6| Step: 12
Training loss: 1.3294509649276733
Validation loss: 2.0558856853874783

Epoch: 6| Step: 13
Training loss: 1.8015692234039307
Validation loss: 2.021662369851143

Epoch: 538| Step: 0
Training loss: 1.2726466655731201
Validation loss: 2.018345115005329

Epoch: 6| Step: 1
Training loss: 0.8879684209823608
Validation loss: 2.0552420744331936

Epoch: 6| Step: 2
Training loss: 1.3013995885849
Validation loss: 2.0353998355968024

Epoch: 6| Step: 3
Training loss: 1.1448450088500977
Validation loss: 2.0515313097225722

Epoch: 6| Step: 4
Training loss: 0.8936748504638672
Validation loss: 2.0600932849350797

Epoch: 6| Step: 5
Training loss: 1.5081768035888672
Validation loss: 2.0633223902794624

Epoch: 6| Step: 6
Training loss: 1.395790934562683
Validation loss: 2.0245675079284178

Epoch: 6| Step: 7
Training loss: 1.527199387550354
Validation loss: 2.018372155004932

Epoch: 6| Step: 8
Training loss: 0.8941928148269653
Validation loss: 2.0468402126783967

Epoch: 6| Step: 9
Training loss: 1.1086375713348389
Validation loss: 2.07221209361989

Epoch: 6| Step: 10
Training loss: 1.145268440246582
Validation loss: 2.0464951645943428

Epoch: 6| Step: 11
Training loss: 1.6231213808059692
Validation loss: 2.0729038740998957

Epoch: 6| Step: 12
Training loss: 1.0993047952651978
Validation loss: 2.086331759729693

Epoch: 6| Step: 13
Training loss: 0.6126859188079834
Validation loss: 2.0164028944507724

Epoch: 539| Step: 0
Training loss: 1.7910866737365723
Validation loss: 2.0644017842508133

Epoch: 6| Step: 1
Training loss: 1.4823861122131348
Validation loss: 2.0329754173114734

Epoch: 6| Step: 2
Training loss: 0.8307981491088867
Validation loss: 2.0519115924835205

Epoch: 6| Step: 3
Training loss: 1.325580358505249
Validation loss: 2.0729416775447067

Epoch: 6| Step: 4
Training loss: 1.7834426164627075
Validation loss: 2.082166871716899

Epoch: 6| Step: 5
Training loss: 0.8115547895431519
Validation loss: 2.06640467592465

Epoch: 6| Step: 6
Training loss: 0.6735321283340454
Validation loss: 2.0423285217695337

Epoch: 6| Step: 7
Training loss: 1.1128926277160645
Validation loss: 2.0722509712301274

Epoch: 6| Step: 8
Training loss: 0.7388680577278137
Validation loss: 2.0373325565809846

Epoch: 6| Step: 9
Training loss: 1.2629802227020264
Validation loss: 2.041020635635622

Epoch: 6| Step: 10
Training loss: 1.729506015777588
Validation loss: 2.0667113565629527

Epoch: 6| Step: 11
Training loss: 0.9007934331893921
Validation loss: 2.0971895904951197

Epoch: 6| Step: 12
Training loss: 1.2009663581848145
Validation loss: 2.070673200391954

Epoch: 6| Step: 13
Training loss: 1.3889098167419434
Validation loss: 2.094871394095882

Epoch: 540| Step: 0
Training loss: 1.169403076171875
Validation loss: 2.0973861038043933

Epoch: 6| Step: 1
Training loss: 1.4155912399291992
Validation loss: 2.0636564223997054

Epoch: 6| Step: 2
Training loss: 1.2465977668762207
Validation loss: 2.0722270601539203

Epoch: 6| Step: 3
Training loss: 0.9346736669540405
Validation loss: 2.1013607760911346

Epoch: 6| Step: 4
Training loss: 1.325514793395996
Validation loss: 2.0767765609166955

Epoch: 6| Step: 5
Training loss: 1.3592064380645752
Validation loss: 2.0524000147337556

Epoch: 6| Step: 6
Training loss: 0.8270145654678345
Validation loss: 2.0775984897408435

Epoch: 6| Step: 7
Training loss: 1.5248897075653076
Validation loss: 2.0631761166357223

Epoch: 6| Step: 8
Training loss: 1.348304271697998
Validation loss: 2.0558686230772283

Epoch: 6| Step: 9
Training loss: 1.2343535423278809
Validation loss: 2.0613071636487077

Epoch: 6| Step: 10
Training loss: 0.9733675718307495
Validation loss: 2.033183810531452

Epoch: 6| Step: 11
Training loss: 1.0304679870605469
Validation loss: 2.0056127809709117

Epoch: 6| Step: 12
Training loss: 1.309349536895752
Validation loss: 2.026497551189956

Epoch: 6| Step: 13
Training loss: 1.3679155111312866
Validation loss: 2.0539032874568814

Epoch: 541| Step: 0
Training loss: 1.60366690158844
Validation loss: 2.0459820224392797

Epoch: 6| Step: 1
Training loss: 1.550830602645874
Validation loss: 1.9926798702568136

Epoch: 6| Step: 2
Training loss: 1.1844342947006226
Validation loss: 2.0231376809458577

Epoch: 6| Step: 3
Training loss: 1.6071062088012695
Validation loss: 2.018642787010439

Epoch: 6| Step: 4
Training loss: 1.3690463304519653
Validation loss: 2.0347156601567424

Epoch: 6| Step: 5
Training loss: 1.175339698791504
Validation loss: 1.9975157014785274

Epoch: 6| Step: 6
Training loss: 1.52286958694458
Validation loss: 2.0710345378486057

Epoch: 6| Step: 7
Training loss: 0.4893503785133362
Validation loss: 2.0600860708503315

Epoch: 6| Step: 8
Training loss: 1.239452600479126
Validation loss: 2.0137704175005675

Epoch: 6| Step: 9
Training loss: 1.3676114082336426
Validation loss: 2.0246181885401406

Epoch: 6| Step: 10
Training loss: 0.9317740797996521
Validation loss: 2.0517647804752475

Epoch: 6| Step: 11
Training loss: 1.338075876235962
Validation loss: 2.054473659043671

Epoch: 6| Step: 12
Training loss: 0.9635948538780212
Validation loss: 2.030568645846459

Epoch: 6| Step: 13
Training loss: 0.6586029529571533
Validation loss: 2.0621547878429456

Epoch: 542| Step: 0
Training loss: 0.9317833185195923
Validation loss: 2.0599812743484334

Epoch: 6| Step: 1
Training loss: 0.7971776127815247
Validation loss: 2.072545495084537

Epoch: 6| Step: 2
Training loss: 1.3334741592407227
Validation loss: 2.015970492875704

Epoch: 6| Step: 3
Training loss: 1.6699496507644653
Validation loss: 2.0518989383533435

Epoch: 6| Step: 4
Training loss: 1.404785394668579
Validation loss: 2.0224014097644436

Epoch: 6| Step: 5
Training loss: 1.5359801054000854
Validation loss: 2.0744092925902335

Epoch: 6| Step: 6
Training loss: 0.8743939399719238
Validation loss: 2.0045776431278517

Epoch: 6| Step: 7
Training loss: 1.393099069595337
Validation loss: 2.011175642731369

Epoch: 6| Step: 8
Training loss: 1.1430699825286865
Validation loss: 2.033672708337025

Epoch: 6| Step: 9
Training loss: 1.442412257194519
Validation loss: 2.0858727911467194

Epoch: 6| Step: 10
Training loss: 1.2134400606155396
Validation loss: 2.003339139364099

Epoch: 6| Step: 11
Training loss: 0.8061219453811646
Validation loss: 2.0424416629217004

Epoch: 6| Step: 12
Training loss: 1.123145580291748
Validation loss: 2.071423481869441

Epoch: 6| Step: 13
Training loss: 1.3396985530853271
Validation loss: 2.0267840354673323

Epoch: 543| Step: 0
Training loss: 1.357980728149414
Validation loss: 2.0768786784141295

Epoch: 6| Step: 1
Training loss: 1.596019983291626
Validation loss: 2.0935675123686432

Epoch: 6| Step: 2
Training loss: 1.8155397176742554
Validation loss: 2.095385438652449

Epoch: 6| Step: 3
Training loss: 0.9203718900680542
Validation loss: 2.046162493767277

Epoch: 6| Step: 4
Training loss: 0.7476191520690918
Validation loss: 2.073414297514064

Epoch: 6| Step: 5
Training loss: 1.4430204629898071
Validation loss: 2.0734279258276826

Epoch: 6| Step: 6
Training loss: 1.2872066497802734
Validation loss: 2.054533455961494

Epoch: 6| Step: 7
Training loss: 0.7855497002601624
Validation loss: 2.0712938052351757

Epoch: 6| Step: 8
Training loss: 1.0994828939437866
Validation loss: 2.0747552687121975

Epoch: 6| Step: 9
Training loss: 0.8554970026016235
Validation loss: 2.0528705837906047

Epoch: 6| Step: 10
Training loss: 0.8497015833854675
Validation loss: 2.0713167229006366

Epoch: 6| Step: 11
Training loss: 1.7441258430480957
Validation loss: 2.03551063999053

Epoch: 6| Step: 12
Training loss: 1.13435959815979
Validation loss: 2.0925765909174436

Epoch: 6| Step: 13
Training loss: 2.084444761276245
Validation loss: 2.0728571235492663

Epoch: 544| Step: 0
Training loss: 0.8949369192123413
Validation loss: 2.0291162370353617

Epoch: 6| Step: 1
Training loss: 1.0209017992019653
Validation loss: 2.0473443308184223

Epoch: 6| Step: 2
Training loss: 1.3235785961151123
Validation loss: 2.046001571480946

Epoch: 6| Step: 3
Training loss: 1.4343090057373047
Validation loss: 2.0382310472508913

Epoch: 6| Step: 4
Training loss: 1.7581264972686768
Validation loss: 2.0639320124862013

Epoch: 6| Step: 5
Training loss: 0.8701679706573486
Validation loss: 2.0362289849148003

Epoch: 6| Step: 6
Training loss: 1.650589942932129
Validation loss: 2.030894261534496

Epoch: 6| Step: 7
Training loss: 1.1140822172164917
Validation loss: 2.05423609031144

Epoch: 6| Step: 8
Training loss: 0.8747492432594299
Validation loss: 2.041522010680168

Epoch: 6| Step: 9
Training loss: 0.5665664672851562
Validation loss: 2.039391057465666

Epoch: 6| Step: 10
Training loss: 1.351000428199768
Validation loss: 2.0420364513192126

Epoch: 6| Step: 11
Training loss: 1.5829566717147827
Validation loss: 2.025827266836679

Epoch: 6| Step: 12
Training loss: 1.261451244354248
Validation loss: 2.068693754493549

Epoch: 6| Step: 13
Training loss: 0.46373674273490906
Validation loss: 2.0112700321341075

Epoch: 545| Step: 0
Training loss: 1.6249655485153198
Validation loss: 2.0841743792257

Epoch: 6| Step: 1
Training loss: 1.5426249504089355
Validation loss: 2.0247095759196947

Epoch: 6| Step: 2
Training loss: 1.093186855316162
Validation loss: 2.080878424388106

Epoch: 6| Step: 3
Training loss: 0.7569056749343872
Validation loss: 2.1170277928793304

Epoch: 6| Step: 4
Training loss: 1.5005316734313965
Validation loss: 2.057530786401482

Epoch: 6| Step: 5
Training loss: 1.0978310108184814
Validation loss: 2.0993943714326426

Epoch: 6| Step: 6
Training loss: 1.4226174354553223
Validation loss: 2.0497672429648777

Epoch: 6| Step: 7
Training loss: 0.6311204433441162
Validation loss: 2.113680552410823

Epoch: 6| Step: 8
Training loss: 1.1605701446533203
Validation loss: 2.083973656418503

Epoch: 6| Step: 9
Training loss: 1.7666337490081787
Validation loss: 2.083983623853294

Epoch: 6| Step: 10
Training loss: 0.49993252754211426
Validation loss: 2.0626595917568413

Epoch: 6| Step: 11
Training loss: 0.834924042224884
Validation loss: 2.063253556528399

Epoch: 6| Step: 12
Training loss: 1.3313928842544556
Validation loss: 2.0747719644218363

Epoch: 6| Step: 13
Training loss: 1.5025408267974854
Validation loss: 2.0916479249154367

Epoch: 546| Step: 0
Training loss: 1.4512929916381836
Validation loss: 2.044504398940712

Epoch: 6| Step: 1
Training loss: 0.7233359813690186
Validation loss: 2.0363885817989225

Epoch: 6| Step: 2
Training loss: 1.3090856075286865
Validation loss: 2.0190905114655853

Epoch: 6| Step: 3
Training loss: 0.8849655389785767
Validation loss: 2.043417153819915

Epoch: 6| Step: 4
Training loss: 0.8016261458396912
Validation loss: 2.0283239810697493

Epoch: 6| Step: 5
Training loss: 1.1672087907791138
Validation loss: 2.0417304513274983

Epoch: 6| Step: 6
Training loss: 1.0703179836273193
Validation loss: 2.048735935200927

Epoch: 6| Step: 7
Training loss: 1.5882869958877563
Validation loss: 2.03291057514888

Epoch: 6| Step: 8
Training loss: 1.0503346920013428
Validation loss: 2.0094386710915515

Epoch: 6| Step: 9
Training loss: 1.2147042751312256
Validation loss: 2.046998716169788

Epoch: 6| Step: 10
Training loss: 1.573988914489746
Validation loss: 2.0575442057783886

Epoch: 6| Step: 11
Training loss: 1.6532304286956787
Validation loss: 2.060625422385431

Epoch: 6| Step: 12
Training loss: 0.800505518913269
Validation loss: 2.0759332526114678

Epoch: 6| Step: 13
Training loss: 1.639059066772461
Validation loss: 2.0914017218415455

Epoch: 547| Step: 0
Training loss: 0.9703800678253174
Validation loss: 2.0854990687421573

Epoch: 6| Step: 1
Training loss: 0.7147114276885986
Validation loss: 2.1431645680499334

Epoch: 6| Step: 2
Training loss: 0.8314439058303833
Validation loss: 2.0845642294935

Epoch: 6| Step: 3
Training loss: 1.1142401695251465
Validation loss: 2.0974573730140604

Epoch: 6| Step: 4
Training loss: 1.1898294687271118
Validation loss: 2.0833273241596837

Epoch: 6| Step: 5
Training loss: 0.7668667435646057
Validation loss: 2.1166121626412995

Epoch: 6| Step: 6
Training loss: 1.4849779605865479
Validation loss: 2.081410592602145

Epoch: 6| Step: 7
Training loss: 0.8603769540786743
Validation loss: 2.1090822681303947

Epoch: 6| Step: 8
Training loss: 1.7747124433517456
Validation loss: 2.0517835758065663

Epoch: 6| Step: 9
Training loss: 2.0333824157714844
Validation loss: 2.041088468285017

Epoch: 6| Step: 10
Training loss: 0.8831163048744202
Validation loss: 2.067908913858475

Epoch: 6| Step: 11
Training loss: 1.5150890350341797
Validation loss: 2.0602522332181215

Epoch: 6| Step: 12
Training loss: 1.5446555614471436
Validation loss: 2.034178795353059

Epoch: 6| Step: 13
Training loss: 1.1090174913406372
Validation loss: 2.072228415037996

Epoch: 548| Step: 0
Training loss: 0.9217844009399414
Validation loss: 2.0990421297729656

Epoch: 6| Step: 1
Training loss: 0.8629217743873596
Validation loss: 2.0077284048962336

Epoch: 6| Step: 2
Training loss: 0.724057674407959
Validation loss: 2.0743384617631153

Epoch: 6| Step: 3
Training loss: 1.1480555534362793
Validation loss: 2.076769203268072

Epoch: 6| Step: 4
Training loss: 0.9801995754241943
Validation loss: 2.108616575118034

Epoch: 6| Step: 5
Training loss: 1.64113450050354
Validation loss: 2.0614084864175446

Epoch: 6| Step: 6
Training loss: 0.7019617557525635
Validation loss: 2.053639027380174

Epoch: 6| Step: 7
Training loss: 0.979917049407959
Validation loss: 2.0672516258814

Epoch: 6| Step: 8
Training loss: 1.5285530090332031
Validation loss: 2.038455596534155

Epoch: 6| Step: 9
Training loss: 1.1181341409683228
Validation loss: 2.0585990772452405

Epoch: 6| Step: 10
Training loss: 1.3482730388641357
Validation loss: 2.094483175585347

Epoch: 6| Step: 11
Training loss: 1.7642998695373535
Validation loss: 2.066537859619305

Epoch: 6| Step: 12
Training loss: 1.4635902643203735
Validation loss: 2.0553998421597224

Epoch: 6| Step: 13
Training loss: 1.3481956720352173
Validation loss: 2.116285748379205

Epoch: 549| Step: 0
Training loss: 0.9136788845062256
Validation loss: 2.072134917782199

Epoch: 6| Step: 1
Training loss: 0.8494528532028198
Validation loss: 2.0908133470883934

Epoch: 6| Step: 2
Training loss: 1.1769633293151855
Validation loss: 2.0747365336264334

Epoch: 6| Step: 3
Training loss: 1.1352438926696777
Validation loss: 2.0759980832376788

Epoch: 6| Step: 4
Training loss: 1.2344508171081543
Validation loss: 2.071610653272239

Epoch: 6| Step: 5
Training loss: 1.0783805847167969
Validation loss: 2.0703662236531577

Epoch: 6| Step: 6
Training loss: 1.1274791955947876
Validation loss: 2.0501035464707242

Epoch: 6| Step: 7
Training loss: 2.0772433280944824
Validation loss: 2.0425739442148516

Epoch: 6| Step: 8
Training loss: 1.0309206247329712
Validation loss: 2.0740858739422214

Epoch: 6| Step: 9
Training loss: 2.0055384635925293
Validation loss: 2.0662552284938034

Epoch: 6| Step: 10
Training loss: 1.1288058757781982
Validation loss: 2.077368149193384

Epoch: 6| Step: 11
Training loss: 0.9041409492492676
Validation loss: 2.087848855603126

Epoch: 6| Step: 12
Training loss: 0.6401858329772949
Validation loss: 2.081225302911574

Epoch: 6| Step: 13
Training loss: 1.198063611984253
Validation loss: 2.01120263273998

Epoch: 550| Step: 0
Training loss: 1.3088672161102295
Validation loss: 2.0241501920966694

Epoch: 6| Step: 1
Training loss: 1.401541829109192
Validation loss: 2.0340357826602076

Epoch: 6| Step: 2
Training loss: 0.5961376428604126
Validation loss: 2.0293949009269796

Epoch: 6| Step: 3
Training loss: 0.6832486391067505
Validation loss: 2.071585582148644

Epoch: 6| Step: 4
Training loss: 0.9460436105728149
Validation loss: 2.044694403166412

Epoch: 6| Step: 5
Training loss: 1.2322659492492676
Validation loss: 2.048215468724569

Epoch: 6| Step: 6
Training loss: 1.058826208114624
Validation loss: 2.015521264845325

Epoch: 6| Step: 7
Training loss: 1.3724074363708496
Validation loss: 2.022495126211515

Epoch: 6| Step: 8
Training loss: 1.5521553754806519
Validation loss: 1.9951776343007241

Epoch: 6| Step: 9
Training loss: 1.4718151092529297
Validation loss: 2.075976897311467

Epoch: 6| Step: 10
Training loss: 1.626534342765808
Validation loss: 2.0541288186145086

Epoch: 6| Step: 11
Training loss: 1.2985854148864746
Validation loss: 2.044710595120666

Epoch: 6| Step: 12
Training loss: 0.8826936483383179
Validation loss: 2.071180538464618

Epoch: 6| Step: 13
Training loss: 1.6163442134857178
Validation loss: 2.0478112415600846

Epoch: 551| Step: 0
Training loss: 1.0624107122421265
Validation loss: 2.0764623970113774

Epoch: 6| Step: 1
Training loss: 1.1484863758087158
Validation loss: 2.065580476996719

Epoch: 6| Step: 2
Training loss: 0.9632778167724609
Validation loss: 2.0540108590997677

Epoch: 6| Step: 3
Training loss: 1.2236745357513428
Validation loss: 2.0368048580743934

Epoch: 6| Step: 4
Training loss: 1.328071117401123
Validation loss: 2.1215144049736763

Epoch: 6| Step: 5
Training loss: 1.395185947418213
Validation loss: 2.0785234000093196

Epoch: 6| Step: 6
Training loss: 1.5283429622650146
Validation loss: 2.073509736727643

Epoch: 6| Step: 7
Training loss: 1.027368187904358
Validation loss: 2.0726419546270884

Epoch: 6| Step: 8
Training loss: 1.091623306274414
Validation loss: 2.092144919979957

Epoch: 6| Step: 9
Training loss: 2.1658482551574707
Validation loss: 2.058782195532194

Epoch: 6| Step: 10
Training loss: 0.7353178262710571
Validation loss: 2.091122500358089

Epoch: 6| Step: 11
Training loss: 1.3013224601745605
Validation loss: 2.0520842408621185

Epoch: 6| Step: 12
Training loss: 1.0175607204437256
Validation loss: 2.039733475254428

Epoch: 6| Step: 13
Training loss: 1.1116000413894653
Validation loss: 2.0461999870115712

Epoch: 552| Step: 0
Training loss: 1.3114557266235352
Validation loss: 2.018790187374238

Epoch: 6| Step: 1
Training loss: 0.982099711894989
Validation loss: 2.0788476646587415

Epoch: 6| Step: 2
Training loss: 0.9954556226730347
Validation loss: 2.019629029817479

Epoch: 6| Step: 3
Training loss: 1.2823349237442017
Validation loss: 1.972122484637845

Epoch: 6| Step: 4
Training loss: 1.437741994857788
Validation loss: 2.0092674634789907

Epoch: 6| Step: 5
Training loss: 1.331459641456604
Validation loss: 2.071833327252378

Epoch: 6| Step: 6
Training loss: 1.9200663566589355
Validation loss: 2.034030404142154

Epoch: 6| Step: 7
Training loss: 1.0486377477645874
Validation loss: 2.0147424256929787

Epoch: 6| Step: 8
Training loss: 1.6394556760787964
Validation loss: 2.060439734048741

Epoch: 6| Step: 9
Training loss: 1.0993075370788574
Validation loss: 2.0430229966358473

Epoch: 6| Step: 10
Training loss: 0.7475219964981079
Validation loss: 2.0285833228018975

Epoch: 6| Step: 11
Training loss: 1.1376025676727295
Validation loss: 2.067206491706192

Epoch: 6| Step: 12
Training loss: 0.72551029920578
Validation loss: 2.0599525333732687

Epoch: 6| Step: 13
Training loss: 1.1836084127426147
Validation loss: 2.0546605343459756

Epoch: 553| Step: 0
Training loss: 1.0574363470077515
Validation loss: 2.053900352088354

Epoch: 6| Step: 1
Training loss: 1.1851046085357666
Validation loss: 2.0988056659698486

Epoch: 6| Step: 2
Training loss: 1.0804216861724854
Validation loss: 2.1184873965478714

Epoch: 6| Step: 3
Training loss: 1.0046868324279785
Validation loss: 2.087853508610879

Epoch: 6| Step: 4
Training loss: 1.2694849967956543
Validation loss: 2.1278616023320023

Epoch: 6| Step: 5
Training loss: 1.4662014245986938
Validation loss: 2.0979706087420062

Epoch: 6| Step: 6
Training loss: 0.9974361062049866
Validation loss: 2.0909621971909718

Epoch: 6| Step: 7
Training loss: 1.3731038570404053
Validation loss: 2.107083587236302

Epoch: 6| Step: 8
Training loss: 1.2004213333129883
Validation loss: 2.0840775838462253

Epoch: 6| Step: 9
Training loss: 1.2756742238998413
Validation loss: 2.0918392391615015

Epoch: 6| Step: 10
Training loss: 1.2083264589309692
Validation loss: 2.073423211292554

Epoch: 6| Step: 11
Training loss: 1.511743187904358
Validation loss: 2.052356889170985

Epoch: 6| Step: 12
Training loss: 1.2133562564849854
Validation loss: 2.0521791417111634

Epoch: 6| Step: 13
Training loss: 1.0924122333526611
Validation loss: 2.062833465555663

Epoch: 554| Step: 0
Training loss: 1.723556399345398
Validation loss: 2.0534432485539424

Epoch: 6| Step: 1
Training loss: 1.1357700824737549
Validation loss: 2.0879418298762333

Epoch: 6| Step: 2
Training loss: 1.5026613473892212
Validation loss: 2.056985612838499

Epoch: 6| Step: 3
Training loss: 1.1598975658416748
Validation loss: 2.088203468630391

Epoch: 6| Step: 4
Training loss: 1.304088830947876
Validation loss: 1.9785099567905549

Epoch: 6| Step: 5
Training loss: 0.6741936206817627
Validation loss: 2.0716798074783815

Epoch: 6| Step: 6
Training loss: 1.4149420261383057
Validation loss: 2.0546250907323693

Epoch: 6| Step: 7
Training loss: 1.0137765407562256
Validation loss: 1.9963811430879819

Epoch: 6| Step: 8
Training loss: 0.9063202142715454
Validation loss: 2.0463671248446227

Epoch: 6| Step: 9
Training loss: 1.0567830801010132
Validation loss: 2.00987611791139

Epoch: 6| Step: 10
Training loss: 1.4425448179244995
Validation loss: 2.0432741129270164

Epoch: 6| Step: 11
Training loss: 1.5955853462219238
Validation loss: 2.0685260718868625

Epoch: 6| Step: 12
Training loss: 0.824531078338623
Validation loss: 2.048488650270688

Epoch: 6| Step: 13
Training loss: 0.4779309034347534
Validation loss: 2.0740938289191133

Epoch: 555| Step: 0
Training loss: 0.9487090706825256
Validation loss: 2.0825520356496177

Epoch: 6| Step: 1
Training loss: 1.4585108757019043
Validation loss: 2.1066070269512873

Epoch: 6| Step: 2
Training loss: 1.2970175743103027
Validation loss: 2.0744511747872956

Epoch: 6| Step: 3
Training loss: 0.9627050161361694
Validation loss: 2.100973882982808

Epoch: 6| Step: 4
Training loss: 1.2256007194519043
Validation loss: 2.0843861564513175

Epoch: 6| Step: 5
Training loss: 1.5921692848205566
Validation loss: 2.0790423039467103

Epoch: 6| Step: 6
Training loss: 1.0053600072860718
Validation loss: 2.0615997109361874

Epoch: 6| Step: 7
Training loss: 1.288879632949829
Validation loss: 2.045401155307729

Epoch: 6| Step: 8
Training loss: 0.5751502513885498
Validation loss: 2.026957796465966

Epoch: 6| Step: 9
Training loss: 1.5083112716674805
Validation loss: 2.05169786689102

Epoch: 6| Step: 10
Training loss: 1.711395502090454
Validation loss: 2.088587007214946

Epoch: 6| Step: 11
Training loss: 0.9161192178726196
Validation loss: 2.0414964819467194

Epoch: 6| Step: 12
Training loss: 0.9498067498207092
Validation loss: 2.0496136167997956

Epoch: 6| Step: 13
Training loss: 1.5350931882858276
Validation loss: 2.0703009687444216

Epoch: 556| Step: 0
Training loss: 1.9871888160705566
Validation loss: 2.0329459508260093

Epoch: 6| Step: 1
Training loss: 1.1699401140213013
Validation loss: 2.0429184667525755

Epoch: 6| Step: 2
Training loss: 1.6782920360565186
Validation loss: 1.9991478535436815

Epoch: 6| Step: 3
Training loss: 0.690187931060791
Validation loss: 2.0063181718190513

Epoch: 6| Step: 4
Training loss: 1.1815311908721924
Validation loss: 2.0457134054553126

Epoch: 6| Step: 5
Training loss: 0.8424603343009949
Validation loss: 2.0575903256734214

Epoch: 6| Step: 6
Training loss: 0.8544883728027344
Validation loss: 2.0474828212491927

Epoch: 6| Step: 7
Training loss: 1.3065565824508667
Validation loss: 2.014625821062314

Epoch: 6| Step: 8
Training loss: 1.0251377820968628
Validation loss: 2.059381572149133

Epoch: 6| Step: 9
Training loss: 1.0909804105758667
Validation loss: 2.0356888694147908

Epoch: 6| Step: 10
Training loss: 1.0293246507644653
Validation loss: 2.0506951860202256

Epoch: 6| Step: 11
Training loss: 1.1094876527786255
Validation loss: 2.057257745855598

Epoch: 6| Step: 12
Training loss: 1.239868402481079
Validation loss: 2.0677255558711227

Epoch: 6| Step: 13
Training loss: 1.958748459815979
Validation loss: 2.078793374441003

Epoch: 557| Step: 0
Training loss: 1.4947142601013184
Validation loss: 2.077129340940906

Epoch: 6| Step: 1
Training loss: 1.2936360836029053
Validation loss: 2.001490876238833

Epoch: 6| Step: 2
Training loss: 1.1078044176101685
Validation loss: 2.033347483604185

Epoch: 6| Step: 3
Training loss: 1.1813231706619263
Validation loss: 2.068349995920735

Epoch: 6| Step: 4
Training loss: 1.3806593418121338
Validation loss: 2.0323955743543562

Epoch: 6| Step: 5
Training loss: 1.4083808660507202
Validation loss: 2.0506558802820023

Epoch: 6| Step: 6
Training loss: 1.04511559009552
Validation loss: 1.9776251418616182

Epoch: 6| Step: 7
Training loss: 1.634458303451538
Validation loss: 2.069031274446877

Epoch: 6| Step: 8
Training loss: 1.1474664211273193
Validation loss: 2.0282508198932936

Epoch: 6| Step: 9
Training loss: 1.1384556293487549
Validation loss: 2.0273419528879146

Epoch: 6| Step: 10
Training loss: 0.7038059830665588
Validation loss: 2.0576984792627315

Epoch: 6| Step: 11
Training loss: 1.0714099407196045
Validation loss: 2.088305986055764

Epoch: 6| Step: 12
Training loss: 0.7552552819252014
Validation loss: 2.042155493972122

Epoch: 6| Step: 13
Training loss: 1.3402714729309082
Validation loss: 1.9957930657171434

Epoch: 558| Step: 0
Training loss: 0.962744414806366
Validation loss: 2.0950691187253563

Epoch: 6| Step: 1
Training loss: 0.9852886199951172
Validation loss: 2.0631539795988347

Epoch: 6| Step: 2
Training loss: 1.0205363035202026
Validation loss: 2.087573109134551

Epoch: 6| Step: 3
Training loss: 1.5492445230484009
Validation loss: 2.035968606190015

Epoch: 6| Step: 4
Training loss: 1.176302433013916
Validation loss: 2.0756730392415035

Epoch: 6| Step: 5
Training loss: 1.0662531852722168
Validation loss: 2.069440352019443

Epoch: 6| Step: 6
Training loss: 0.8785415887832642
Validation loss: 2.084559763631513

Epoch: 6| Step: 7
Training loss: 1.8538918495178223
Validation loss: 2.043611693125899

Epoch: 6| Step: 8
Training loss: 0.9202332496643066
Validation loss: 2.0376587657518286

Epoch: 6| Step: 9
Training loss: 1.121880054473877
Validation loss: 2.0336820707526257

Epoch: 6| Step: 10
Training loss: 1.4462556838989258
Validation loss: 2.0215873666988906

Epoch: 6| Step: 11
Training loss: 0.7503572106361389
Validation loss: 2.040303587913513

Epoch: 6| Step: 12
Training loss: 1.123250961303711
Validation loss: 2.003409852263748

Epoch: 6| Step: 13
Training loss: 1.9930294752120972
Validation loss: 2.015836497788788

Epoch: 559| Step: 0
Training loss: 0.8641668558120728
Validation loss: 2.038744141978602

Epoch: 6| Step: 1
Training loss: 0.8618937730789185
Validation loss: 2.0170317747259654

Epoch: 6| Step: 2
Training loss: 1.0563668012619019
Validation loss: 1.9758532277999385

Epoch: 6| Step: 3
Training loss: 0.8950387835502625
Validation loss: 2.038736075483343

Epoch: 6| Step: 4
Training loss: 1.4296886920928955
Validation loss: 2.019741565950455

Epoch: 6| Step: 5
Training loss: 1.0716660022735596
Validation loss: 2.051840812929215

Epoch: 6| Step: 6
Training loss: 1.1040091514587402
Validation loss: 2.0440751557709067

Epoch: 6| Step: 7
Training loss: 1.0496855974197388
Validation loss: 2.0048773160544773

Epoch: 6| Step: 8
Training loss: 1.2172679901123047
Validation loss: 2.0613782072579987

Epoch: 6| Step: 9
Training loss: 1.4808013439178467
Validation loss: 2.0597713147440264

Epoch: 6| Step: 10
Training loss: 1.0359256267547607
Validation loss: 2.04913269576206

Epoch: 6| Step: 11
Training loss: 1.4291744232177734
Validation loss: 2.0792168609557615

Epoch: 6| Step: 12
Training loss: 1.3702595233917236
Validation loss: 2.0464812196711057

Epoch: 6| Step: 13
Training loss: 1.611819863319397
Validation loss: 2.069176362406823

Epoch: 560| Step: 0
Training loss: 1.701470136642456
Validation loss: 2.0907516864038285

Epoch: 6| Step: 1
Training loss: 0.7278350591659546
Validation loss: 2.0760701471759426

Epoch: 6| Step: 2
Training loss: 1.070533275604248
Validation loss: 2.044775673138198

Epoch: 6| Step: 3
Training loss: 1.5302197933197021
Validation loss: 2.0652569570849018

Epoch: 6| Step: 4
Training loss: 0.7562386989593506
Validation loss: 2.1042522153546734

Epoch: 6| Step: 5
Training loss: 1.2060359716415405
Validation loss: 2.072870598044447

Epoch: 6| Step: 6
Training loss: 1.737372875213623
Validation loss: 2.0364311254152687

Epoch: 6| Step: 7
Training loss: 0.8861104249954224
Validation loss: 2.0739152136669365

Epoch: 6| Step: 8
Training loss: 0.9507274627685547
Validation loss: 2.0545122866989463

Epoch: 6| Step: 9
Training loss: 1.2435334920883179
Validation loss: 2.0066656579253492

Epoch: 6| Step: 10
Training loss: 1.3265347480773926
Validation loss: 2.0138806309751285

Epoch: 6| Step: 11
Training loss: 0.6169115304946899
Validation loss: 2.0286989660673242

Epoch: 6| Step: 12
Training loss: 1.581428050994873
Validation loss: 2.0308805563116588

Epoch: 6| Step: 13
Training loss: 1.2028460502624512
Validation loss: 1.9840045359826857

Epoch: 561| Step: 0
Training loss: 1.3113183975219727
Validation loss: 2.0310119057214386

Epoch: 6| Step: 1
Training loss: 0.8008803129196167
Validation loss: 2.1188147926843293

Epoch: 6| Step: 2
Training loss: 0.8613379597663879
Validation loss: 2.077048122241933

Epoch: 6| Step: 3
Training loss: 1.0654780864715576
Validation loss: 2.0646260348699426

Epoch: 6| Step: 4
Training loss: 1.227219820022583
Validation loss: 2.006388492481683

Epoch: 6| Step: 5
Training loss: 0.9329470992088318
Validation loss: 2.065073477324619

Epoch: 6| Step: 6
Training loss: 0.8775159120559692
Validation loss: 2.053424019967356

Epoch: 6| Step: 7
Training loss: 1.3601386547088623
Validation loss: 2.049537202363373

Epoch: 6| Step: 8
Training loss: 0.8807209730148315
Validation loss: 2.018121042559224

Epoch: 6| Step: 9
Training loss: 1.5818747282028198
Validation loss: 2.1015492152142268

Epoch: 6| Step: 10
Training loss: 1.5314208269119263
Validation loss: 2.031105564486596

Epoch: 6| Step: 11
Training loss: 1.9567097425460815
Validation loss: 2.1435309238331293

Epoch: 6| Step: 12
Training loss: 0.8054949641227722
Validation loss: 2.0570106865257345

Epoch: 6| Step: 13
Training loss: 1.4918090105056763
Validation loss: 2.089952181744319

Epoch: 562| Step: 0
Training loss: 1.0696547031402588
Validation loss: 2.0869612950150684

Epoch: 6| Step: 1
Training loss: 0.5017862319946289
Validation loss: 2.054968317349752

Epoch: 6| Step: 2
Training loss: 1.5748100280761719
Validation loss: 2.1066026021075506

Epoch: 6| Step: 3
Training loss: 1.2189607620239258
Validation loss: 2.028551155521024

Epoch: 6| Step: 4
Training loss: 1.4232406616210938
Validation loss: 2.0518881749081355

Epoch: 6| Step: 5
Training loss: 0.7663633823394775
Validation loss: 2.088750334196193

Epoch: 6| Step: 6
Training loss: 1.0945268869400024
Validation loss: 2.0392975063734156

Epoch: 6| Step: 7
Training loss: 1.6656877994537354
Validation loss: 2.0869215675579604

Epoch: 6| Step: 8
Training loss: 1.0200660228729248
Validation loss: 2.057283996253885

Epoch: 6| Step: 9
Training loss: 1.198011040687561
Validation loss: 2.021409237256614

Epoch: 6| Step: 10
Training loss: 1.116672158241272
Validation loss: 2.0690308488825315

Epoch: 6| Step: 11
Training loss: 1.2683796882629395
Validation loss: 2.041641286624375

Epoch: 6| Step: 12
Training loss: 1.1156926155090332
Validation loss: 2.0158835482853714

Epoch: 6| Step: 13
Training loss: 1.5465065240859985
Validation loss: 2.0851693461018224

Epoch: 563| Step: 0
Training loss: 1.6088933944702148
Validation loss: 2.043284308525824

Epoch: 6| Step: 1
Training loss: 1.1974114179611206
Validation loss: 2.0767835365828646

Epoch: 6| Step: 2
Training loss: 1.9363987445831299
Validation loss: 2.0568680468425957

Epoch: 6| Step: 3
Training loss: 0.6233954429626465
Validation loss: 2.0515865125963764

Epoch: 6| Step: 4
Training loss: 0.6673687100410461
Validation loss: 2.0946137405210927

Epoch: 6| Step: 5
Training loss: 1.0963428020477295
Validation loss: 2.1181496702214724

Epoch: 6| Step: 6
Training loss: 1.3102738857269287
Validation loss: 2.066385481947212

Epoch: 6| Step: 7
Training loss: 1.0783039331436157
Validation loss: 2.0735173956040414

Epoch: 6| Step: 8
Training loss: 1.6001733541488647
Validation loss: 2.0773004998442945

Epoch: 6| Step: 9
Training loss: 0.756999135017395
Validation loss: 2.0705958412539576

Epoch: 6| Step: 10
Training loss: 1.19173264503479
Validation loss: 2.008447777840399

Epoch: 6| Step: 11
Training loss: 1.4034743309020996
Validation loss: 2.023183448340303

Epoch: 6| Step: 12
Training loss: 0.6938113570213318
Validation loss: 2.052148190877771

Epoch: 6| Step: 13
Training loss: 1.5829098224639893
Validation loss: 2.0622613391568585

Epoch: 564| Step: 0
Training loss: 2.233090877532959
Validation loss: 2.03579617059359

Epoch: 6| Step: 1
Training loss: 1.197710394859314
Validation loss: 2.1089399988933275

Epoch: 6| Step: 2
Training loss: 0.7655602097511292
Validation loss: 2.053310601942001

Epoch: 6| Step: 3
Training loss: 0.9555563926696777
Validation loss: 2.06671295883835

Epoch: 6| Step: 4
Training loss: 1.0186827182769775
Validation loss: 2.0438137644080707

Epoch: 6| Step: 5
Training loss: 1.621843695640564
Validation loss: 2.05523851097271

Epoch: 6| Step: 6
Training loss: 0.9377233982086182
Validation loss: 2.055840280748183

Epoch: 6| Step: 7
Training loss: 1.024712324142456
Validation loss: 2.057676830599385

Epoch: 6| Step: 8
Training loss: 1.0764799118041992
Validation loss: 2.0478560386165494

Epoch: 6| Step: 9
Training loss: 0.980085551738739
Validation loss: 2.0613836857580368

Epoch: 6| Step: 10
Training loss: 1.2995119094848633
Validation loss: 2.0622564003031743

Epoch: 6| Step: 11
Training loss: 0.7909348011016846
Validation loss: 2.0335441891865065

Epoch: 6| Step: 12
Training loss: 1.0412375926971436
Validation loss: 2.059463631722235

Epoch: 6| Step: 13
Training loss: 0.9417687654495239
Validation loss: 2.071152102562689

Epoch: 565| Step: 0
Training loss: 1.4684727191925049
Validation loss: 2.040315302469397

Epoch: 6| Step: 1
Training loss: 0.7704156041145325
Validation loss: 2.068299202508824

Epoch: 6| Step: 2
Training loss: 0.9047604203224182
Validation loss: 2.0047422621839788

Epoch: 6| Step: 3
Training loss: 1.6016122102737427
Validation loss: 2.086023853671166

Epoch: 6| Step: 4
Training loss: 1.060962438583374
Validation loss: 2.0569679493545205

Epoch: 6| Step: 5
Training loss: 1.0564061403274536
Validation loss: 2.0531427757714384

Epoch: 6| Step: 6
Training loss: 1.0295398235321045
Validation loss: 2.03040038898427

Epoch: 6| Step: 7
Training loss: 1.1912851333618164
Validation loss: 2.057903251340312

Epoch: 6| Step: 8
Training loss: 1.3190208673477173
Validation loss: 2.0519916959988174

Epoch: 6| Step: 9
Training loss: 0.994994044303894
Validation loss: 2.06687165844825

Epoch: 6| Step: 10
Training loss: 1.2740248441696167
Validation loss: 2.016391875923321

Epoch: 6| Step: 11
Training loss: 1.0696296691894531
Validation loss: 2.071420672119305

Epoch: 6| Step: 12
Training loss: 1.340020775794983
Validation loss: 2.025875445335142

Epoch: 6| Step: 13
Training loss: 1.6932547092437744
Validation loss: 2.1040913340865925

Epoch: 566| Step: 0
Training loss: 0.5550031661987305
Validation loss: 2.063402045157648

Epoch: 6| Step: 1
Training loss: 0.9771550297737122
Validation loss: 2.050430028669296

Epoch: 6| Step: 2
Training loss: 1.155703067779541
Validation loss: 2.1019657170900734

Epoch: 6| Step: 3
Training loss: 1.4192800521850586
Validation loss: 2.067312268800633

Epoch: 6| Step: 4
Training loss: 1.139265775680542
Validation loss: 2.015527391946444

Epoch: 6| Step: 5
Training loss: 1.1287423372268677
Validation loss: 2.0670492751623994

Epoch: 6| Step: 6
Training loss: 0.9060012698173523
Validation loss: 2.0866307289369646

Epoch: 6| Step: 7
Training loss: 1.5984673500061035
Validation loss: 2.050097337333105

Epoch: 6| Step: 8
Training loss: 1.4433070421218872
Validation loss: 2.0763866862943097

Epoch: 6| Step: 9
Training loss: 1.6251239776611328
Validation loss: 2.073774576187134

Epoch: 6| Step: 10
Training loss: 0.7074333429336548
Validation loss: 2.1206456691988054

Epoch: 6| Step: 11
Training loss: 1.20733642578125
Validation loss: 2.0797268908510924

Epoch: 6| Step: 12
Training loss: 1.1905579566955566
Validation loss: 2.0746880039092033

Epoch: 6| Step: 13
Training loss: 0.8483204245567322
Validation loss: 2.044077223347079

Epoch: 567| Step: 0
Training loss: 1.0366212129592896
Validation loss: 2.013018105619697

Epoch: 6| Step: 1
Training loss: 1.4486627578735352
Validation loss: 2.0514291409523255

Epoch: 6| Step: 2
Training loss: 0.6151890158653259
Validation loss: 2.09599405975752

Epoch: 6| Step: 3
Training loss: 1.0664982795715332
Validation loss: 2.030825468801683

Epoch: 6| Step: 4
Training loss: 1.4105298519134521
Validation loss: 2.037785001980361

Epoch: 6| Step: 5
Training loss: 1.0390955209732056
Validation loss: 2.0796766870765278

Epoch: 6| Step: 6
Training loss: 1.3525700569152832
Validation loss: 2.0665909551805064

Epoch: 6| Step: 7
Training loss: 0.9530054330825806
Validation loss: 2.067716852311165

Epoch: 6| Step: 8
Training loss: 1.155670166015625
Validation loss: 2.051251465274442

Epoch: 6| Step: 9
Training loss: 0.652883768081665
Validation loss: 2.079867743676709

Epoch: 6| Step: 10
Training loss: 1.7675464153289795
Validation loss: 2.0839456576173023

Epoch: 6| Step: 11
Training loss: 1.21867036819458
Validation loss: 2.078304567644673

Epoch: 6| Step: 12
Training loss: 1.125896692276001
Validation loss: 2.052178171373183

Epoch: 6| Step: 13
Training loss: 1.359021782875061
Validation loss: 2.0800470985392088

Epoch: 568| Step: 0
Training loss: 1.6148192882537842
Validation loss: 2.040694964829312

Epoch: 6| Step: 1
Training loss: 1.4941554069519043
Validation loss: 2.0380559172681583

Epoch: 6| Step: 2
Training loss: 1.0267971754074097
Validation loss: 2.0532964852548417

Epoch: 6| Step: 3
Training loss: 1.4583226442337036
Validation loss: 2.061821227432579

Epoch: 6| Step: 4
Training loss: 1.464357614517212
Validation loss: 2.0950214298822547

Epoch: 6| Step: 5
Training loss: 1.2313555479049683
Validation loss: 2.0847212371005805

Epoch: 6| Step: 6
Training loss: 1.0544309616088867
Validation loss: 2.0342144427760953

Epoch: 6| Step: 7
Training loss: 1.025068759918213
Validation loss: 2.04462033061571

Epoch: 6| Step: 8
Training loss: 0.5546589493751526
Validation loss: 2.0371309018904165

Epoch: 6| Step: 9
Training loss: 1.1370066404342651
Validation loss: 2.071645546984929

Epoch: 6| Step: 10
Training loss: 1.075533151626587
Validation loss: 2.0547384113393803

Epoch: 6| Step: 11
Training loss: 0.7392687201499939
Validation loss: 2.0167406451317573

Epoch: 6| Step: 12
Training loss: 1.065793752670288
Validation loss: 2.1044519460329445

Epoch: 6| Step: 13
Training loss: 1.323875904083252
Validation loss: 2.0720713779490483

Epoch: 569| Step: 0
Training loss: 1.0604723691940308
Validation loss: 2.0277479681917416

Epoch: 6| Step: 1
Training loss: 0.7412517070770264
Validation loss: 2.056939523707154

Epoch: 6| Step: 2
Training loss: 1.329429268836975
Validation loss: 2.0810090675148913

Epoch: 6| Step: 3
Training loss: 0.6889867186546326
Validation loss: 2.106892357590378

Epoch: 6| Step: 4
Training loss: 1.1946442127227783
Validation loss: 2.0491627326575657

Epoch: 6| Step: 5
Training loss: 1.0896062850952148
Validation loss: 2.065639002348787

Epoch: 6| Step: 6
Training loss: 1.2027506828308105
Validation loss: 2.0758117962909

Epoch: 6| Step: 7
Training loss: 1.1462156772613525
Validation loss: 2.0478421283024613

Epoch: 6| Step: 8
Training loss: 2.0470211505889893
Validation loss: 2.06722867104315

Epoch: 6| Step: 9
Training loss: 0.8282216787338257
Validation loss: 2.067164718463857

Epoch: 6| Step: 10
Training loss: 0.6088993549346924
Validation loss: 2.0692858260164977

Epoch: 6| Step: 11
Training loss: 1.3845372200012207
Validation loss: 2.0057352704386555

Epoch: 6| Step: 12
Training loss: 1.8402462005615234
Validation loss: 2.046567581033194

Epoch: 6| Step: 13
Training loss: 1.1224424839019775
Validation loss: 2.0110650139470256

Epoch: 570| Step: 0
Training loss: 0.8487703800201416
Validation loss: 2.050379717221824

Epoch: 6| Step: 1
Training loss: 1.0266509056091309
Validation loss: 2.0654074914993776

Epoch: 6| Step: 2
Training loss: 1.2069079875946045
Validation loss: 2.0811801751454673

Epoch: 6| Step: 3
Training loss: 1.3208799362182617
Validation loss: 2.06760077066319

Epoch: 6| Step: 4
Training loss: 1.4183671474456787
Validation loss: 2.0854286916794313

Epoch: 6| Step: 5
Training loss: 1.7673985958099365
Validation loss: 2.0809883866258847

Epoch: 6| Step: 6
Training loss: 1.0227594375610352
Validation loss: 2.074066836346862

Epoch: 6| Step: 7
Training loss: 0.7004479765892029
Validation loss: 2.0816313041153776

Epoch: 6| Step: 8
Training loss: 1.3150784969329834
Validation loss: 2.060557755090857

Epoch: 6| Step: 9
Training loss: 1.1318460702896118
Validation loss: 2.0645210127676688

Epoch: 6| Step: 10
Training loss: 0.8612533807754517
Validation loss: 2.090002058654703

Epoch: 6| Step: 11
Training loss: 1.3000596761703491
Validation loss: 2.088346505677828

Epoch: 6| Step: 12
Training loss: 1.2780128717422485
Validation loss: 2.0756593955460416

Epoch: 6| Step: 13
Training loss: 1.0231454372406006
Validation loss: 2.061070139690112

Epoch: 571| Step: 0
Training loss: 1.2892271280288696
Validation loss: 2.0991633963841263

Epoch: 6| Step: 1
Training loss: 1.7792195081710815
Validation loss: 2.0716566231942948

Epoch: 6| Step: 2
Training loss: 1.300400733947754
Validation loss: 2.035904271628267

Epoch: 6| Step: 3
Training loss: 0.9561302661895752
Validation loss: 2.0683994716213596

Epoch: 6| Step: 4
Training loss: 1.337906837463379
Validation loss: 2.035885350678557

Epoch: 6| Step: 5
Training loss: 1.1193355321884155
Validation loss: 2.0845371702665925

Epoch: 6| Step: 6
Training loss: 1.1064260005950928
Validation loss: 2.032553893263622

Epoch: 6| Step: 7
Training loss: 0.7974838018417358
Validation loss: 2.0213963927761203

Epoch: 6| Step: 8
Training loss: 0.6693180203437805
Validation loss: 2.056598483875234

Epoch: 6| Step: 9
Training loss: 1.7750022411346436
Validation loss: 2.0992897505401285

Epoch: 6| Step: 10
Training loss: 0.7790868282318115
Validation loss: 2.058869182422597

Epoch: 6| Step: 11
Training loss: 1.2164738178253174
Validation loss: 2.0330747353133334

Epoch: 6| Step: 12
Training loss: 1.0552427768707275
Validation loss: 2.0527020923552977

Epoch: 6| Step: 13
Training loss: 0.8333790302276611
Validation loss: 2.1138212937180714

Epoch: 572| Step: 0
Training loss: 1.2403639554977417
Validation loss: 2.114176374609752

Epoch: 6| Step: 1
Training loss: 1.4746757745742798
Validation loss: 2.0761574647759877

Epoch: 6| Step: 2
Training loss: 0.7569679021835327
Validation loss: 2.076203123215706

Epoch: 6| Step: 3
Training loss: 1.3781261444091797
Validation loss: 2.0687169054503083

Epoch: 6| Step: 4
Training loss: 0.8714532256126404
Validation loss: 2.051180406283307

Epoch: 6| Step: 5
Training loss: 1.862726092338562
Validation loss: 2.024930992434102

Epoch: 6| Step: 6
Training loss: 1.683572769165039
Validation loss: 2.0508928324586604

Epoch: 6| Step: 7
Training loss: 0.8011682033538818
Validation loss: 2.0557206907579975

Epoch: 6| Step: 8
Training loss: 1.2316023111343384
Validation loss: 2.074527281586842

Epoch: 6| Step: 9
Training loss: 1.305701494216919
Validation loss: 2.069923987952612

Epoch: 6| Step: 10
Training loss: 1.1656749248504639
Validation loss: 2.093479407730923

Epoch: 6| Step: 11
Training loss: 1.0428909063339233
Validation loss: 2.0989249803686656

Epoch: 6| Step: 12
Training loss: 0.6987518072128296
Validation loss: 2.0523073775793916

Epoch: 6| Step: 13
Training loss: 0.704909086227417
Validation loss: 2.082731910931167

Epoch: 573| Step: 0
Training loss: 1.3296194076538086
Validation loss: 2.041158635129211

Epoch: 6| Step: 1
Training loss: 0.7232359647750854
Validation loss: 2.0571305341618036

Epoch: 6| Step: 2
Training loss: 1.636977195739746
Validation loss: 2.041168120599562

Epoch: 6| Step: 3
Training loss: 1.4552994966506958
Validation loss: 2.044444014949183

Epoch: 6| Step: 4
Training loss: 1.0004935264587402
Validation loss: 2.0754576703553558

Epoch: 6| Step: 5
Training loss: 0.856593132019043
Validation loss: 2.067757355269565

Epoch: 6| Step: 6
Training loss: 1.09839928150177
Validation loss: 2.0382291552841023

Epoch: 6| Step: 7
Training loss: 1.294559359550476
Validation loss: 2.0168994908691733

Epoch: 6| Step: 8
Training loss: 0.9285029172897339
Validation loss: 2.0732914324729674

Epoch: 6| Step: 9
Training loss: 1.2502762079238892
Validation loss: 2.0834788507030857

Epoch: 6| Step: 10
Training loss: 0.8127040863037109
Validation loss: 2.081392736845119

Epoch: 6| Step: 11
Training loss: 1.3374440670013428
Validation loss: 2.0815202036211566

Epoch: 6| Step: 12
Training loss: 1.1020612716674805
Validation loss: 2.0596107987947363

Epoch: 6| Step: 13
Training loss: 0.9657478332519531
Validation loss: 1.9942119377915577

Epoch: 574| Step: 0
Training loss: 1.0240721702575684
Validation loss: 2.0558668400651667

Epoch: 6| Step: 1
Training loss: 0.8147845268249512
Validation loss: 2.052623269378498

Epoch: 6| Step: 2
Training loss: 0.9800430536270142
Validation loss: 2.043165365854899

Epoch: 6| Step: 3
Training loss: 1.4183224439620972
Validation loss: 2.105029272776778

Epoch: 6| Step: 4
Training loss: 0.9965345859527588
Validation loss: 2.0338827589506745

Epoch: 6| Step: 5
Training loss: 1.0673190355300903
Validation loss: 2.0374655313389276

Epoch: 6| Step: 6
Training loss: 0.9172258377075195
Validation loss: 2.0343002862827753

Epoch: 6| Step: 7
Training loss: 1.254765510559082
Validation loss: 2.024710270666307

Epoch: 6| Step: 8
Training loss: 2.0220751762390137
Validation loss: 2.033232520985347

Epoch: 6| Step: 9
Training loss: 0.8722889423370361
Validation loss: 2.0177228373865925

Epoch: 6| Step: 10
Training loss: 0.9014900922775269
Validation loss: 2.0527392920627388

Epoch: 6| Step: 11
Training loss: 1.2842622995376587
Validation loss: 2.041787464131591

Epoch: 6| Step: 12
Training loss: 1.2764010429382324
Validation loss: 2.045659042173816

Epoch: 6| Step: 13
Training loss: 1.045886516571045
Validation loss: 2.0085775724021335

Epoch: 575| Step: 0
Training loss: 1.4060883522033691
Validation loss: 2.0422052632095995

Epoch: 6| Step: 1
Training loss: 1.0799169540405273
Validation loss: 2.0212243141666537

Epoch: 6| Step: 2
Training loss: 0.6351165175437927
Validation loss: 2.0481258797389206

Epoch: 6| Step: 3
Training loss: 0.9859737753868103
Validation loss: 2.0380111650754045

Epoch: 6| Step: 4
Training loss: 1.0837740898132324
Validation loss: 2.06103878636514

Epoch: 6| Step: 5
Training loss: 1.0377763509750366
Validation loss: 2.0633844829374746

Epoch: 6| Step: 6
Training loss: 1.1586370468139648
Validation loss: 2.058245902420372

Epoch: 6| Step: 7
Training loss: 1.327818751335144
Validation loss: 2.0257295921284664

Epoch: 6| Step: 8
Training loss: 1.1588890552520752
Validation loss: 2.016966527508151

Epoch: 6| Step: 9
Training loss: 1.011169672012329
Validation loss: 2.042824219631892

Epoch: 6| Step: 10
Training loss: 1.3665522336959839
Validation loss: 2.107690524029475

Epoch: 6| Step: 11
Training loss: 1.2021958827972412
Validation loss: 2.05905431701291

Epoch: 6| Step: 12
Training loss: 1.8391144275665283
Validation loss: 2.1178089726355767

Epoch: 6| Step: 13
Training loss: 0.8249485492706299
Validation loss: 2.0752786820934666

Epoch: 576| Step: 0
Training loss: 1.0223039388656616
Validation loss: 2.0498111350561983

Epoch: 6| Step: 1
Training loss: 0.844646692276001
Validation loss: 2.112401282915505

Epoch: 6| Step: 2
Training loss: 0.8403457999229431
Validation loss: 2.0628672222937308

Epoch: 6| Step: 3
Training loss: 0.8473317623138428
Validation loss: 2.0736286076166297

Epoch: 6| Step: 4
Training loss: 1.0498030185699463
Validation loss: 2.0643689799052414

Epoch: 6| Step: 5
Training loss: 1.4867496490478516
Validation loss: 2.0394322308160926

Epoch: 6| Step: 6
Training loss: 0.9204625487327576
Validation loss: 2.0605764619765745

Epoch: 6| Step: 7
Training loss: 1.1404911279678345
Validation loss: 2.01862492099885

Epoch: 6| Step: 8
Training loss: 2.054886817932129
Validation loss: 2.0719955146953626

Epoch: 6| Step: 9
Training loss: 1.0028917789459229
Validation loss: 1.9972764932981102

Epoch: 6| Step: 10
Training loss: 1.047973871231079
Validation loss: 2.0241723368244786

Epoch: 6| Step: 11
Training loss: 1.3971432447433472
Validation loss: 2.088628674066195

Epoch: 6| Step: 12
Training loss: 1.5421347618103027
Validation loss: 2.056695217727333

Epoch: 6| Step: 13
Training loss: 0.8356912136077881
Validation loss: 2.0674718785029587

Epoch: 577| Step: 0
Training loss: 0.9239709377288818
Validation loss: 2.0409423612779185

Epoch: 6| Step: 1
Training loss: 1.5997555255889893
Validation loss: 2.0592023313686414

Epoch: 6| Step: 2
Training loss: 0.8838037252426147
Validation loss: 2.102263927459717

Epoch: 6| Step: 3
Training loss: 1.0143722295761108
Validation loss: 2.0455174881924867

Epoch: 6| Step: 4
Training loss: 0.9525163173675537
Validation loss: 2.0487334600058933

Epoch: 6| Step: 5
Training loss: 0.7128769755363464
Validation loss: 2.0037079536786644

Epoch: 6| Step: 6
Training loss: 1.6681047677993774
Validation loss: 2.0288853517142673

Epoch: 6| Step: 7
Training loss: 1.5248286724090576
Validation loss: 2.0179541008446806

Epoch: 6| Step: 8
Training loss: 1.097706913948059
Validation loss: 2.029181723953575

Epoch: 6| Step: 9
Training loss: 0.9450169205665588
Validation loss: 2.088869035884898

Epoch: 6| Step: 10
Training loss: 1.2037674188613892
Validation loss: 2.070656416236713

Epoch: 6| Step: 11
Training loss: 1.148707628250122
Validation loss: 2.0514756171934065

Epoch: 6| Step: 12
Training loss: 1.5715477466583252
Validation loss: 2.07231221916855

Epoch: 6| Step: 13
Training loss: 0.7376647591590881
Validation loss: 2.1189536971430623

Epoch: 578| Step: 0
Training loss: 1.1171103715896606
Validation loss: 2.0504281700298352

Epoch: 6| Step: 1
Training loss: 0.9545646905899048
Validation loss: 2.0724982625694683

Epoch: 6| Step: 2
Training loss: 1.1224086284637451
Validation loss: 2.073331297084849

Epoch: 6| Step: 3
Training loss: 1.2853686809539795
Validation loss: 2.0635419814817366

Epoch: 6| Step: 4
Training loss: 1.3766238689422607
Validation loss: 2.0968732987680743

Epoch: 6| Step: 5
Training loss: 1.2844481468200684
Validation loss: 2.027855835935121

Epoch: 6| Step: 6
Training loss: 1.284314751625061
Validation loss: 2.0783998568852744

Epoch: 6| Step: 7
Training loss: 0.9783733487129211
Validation loss: 2.0773646934058076

Epoch: 6| Step: 8
Training loss: 1.08998441696167
Validation loss: 2.030005834435904

Epoch: 6| Step: 9
Training loss: 0.5973830223083496
Validation loss: 2.0117245489551174

Epoch: 6| Step: 10
Training loss: 1.0160818099975586
Validation loss: 2.0251837289461525

Epoch: 6| Step: 11
Training loss: 1.0358245372772217
Validation loss: 2.0928972844154603

Epoch: 6| Step: 12
Training loss: 1.6313005685806274
Validation loss: 2.0571821543478195

Epoch: 6| Step: 13
Training loss: 1.4575918912887573
Validation loss: 2.0355450543024207

Epoch: 579| Step: 0
Training loss: 0.8849173784255981
Validation loss: 2.0644694566726685

Epoch: 6| Step: 1
Training loss: 1.6980799436569214
Validation loss: 2.0493691608469975

Epoch: 6| Step: 2
Training loss: 0.7635700702667236
Validation loss: 2.0788721615268337

Epoch: 6| Step: 3
Training loss: 0.9080125689506531
Validation loss: 2.071926188725297

Epoch: 6| Step: 4
Training loss: 0.9921154975891113
Validation loss: 2.0073085267056703

Epoch: 6| Step: 5
Training loss: 1.13914155960083
Validation loss: 2.0411911164560625

Epoch: 6| Step: 6
Training loss: 1.1324673891067505
Validation loss: 2.0696091472461657

Epoch: 6| Step: 7
Training loss: 1.4227546453475952
Validation loss: 2.1136362757734073

Epoch: 6| Step: 8
Training loss: 1.0667128562927246
Validation loss: 2.0744767906845256

Epoch: 6| Step: 9
Training loss: 1.4536025524139404
Validation loss: 2.0743857135054884

Epoch: 6| Step: 10
Training loss: 1.1282689571380615
Validation loss: 2.0408215817584785

Epoch: 6| Step: 11
Training loss: 1.071483850479126
Validation loss: 2.0595131279319845

Epoch: 6| Step: 12
Training loss: 1.059584140777588
Validation loss: 2.0753652100921958

Epoch: 6| Step: 13
Training loss: 1.0703544616699219
Validation loss: 2.054332399881014

Epoch: 580| Step: 0
Training loss: 1.3247687816619873
Validation loss: 2.0687923046850387

Epoch: 6| Step: 1
Training loss: 0.6511522531509399
Validation loss: 2.070494705630887

Epoch: 6| Step: 2
Training loss: 1.2322434186935425
Validation loss: 2.107922687325426

Epoch: 6| Step: 3
Training loss: 1.1078349351882935
Validation loss: 2.0824817867689234

Epoch: 6| Step: 4
Training loss: 1.4485723972320557
Validation loss: 2.054977035009733

Epoch: 6| Step: 5
Training loss: 1.963139533996582
Validation loss: 2.067346993313041

Epoch: 6| Step: 6
Training loss: 0.819374144077301
Validation loss: 2.0554911167390886

Epoch: 6| Step: 7
Training loss: 0.6969653964042664
Validation loss: 2.0767209683695147

Epoch: 6| Step: 8
Training loss: 1.4586378335952759
Validation loss: 2.0450334997587305

Epoch: 6| Step: 9
Training loss: 1.1762484312057495
Validation loss: 2.026201375069157

Epoch: 6| Step: 10
Training loss: 1.007176399230957
Validation loss: 2.029726416833939

Epoch: 6| Step: 11
Training loss: 0.9088598489761353
Validation loss: 2.0409468399581088

Epoch: 6| Step: 12
Training loss: 0.8746117353439331
Validation loss: 2.0368584253454722

Epoch: 6| Step: 13
Training loss: 0.8768211603164673
Validation loss: 2.0441706308754544

Epoch: 581| Step: 0
Training loss: 0.8500398397445679
Validation loss: 2.0639054441964753

Epoch: 6| Step: 1
Training loss: 1.4610707759857178
Validation loss: 2.0808970735919092

Epoch: 6| Step: 2
Training loss: 1.1315388679504395
Validation loss: 2.091954800390428

Epoch: 6| Step: 3
Training loss: 1.4829360246658325
Validation loss: 2.072903187044205

Epoch: 6| Step: 4
Training loss: 1.4763625860214233
Validation loss: 2.0514926641218123

Epoch: 6| Step: 5
Training loss: 1.3521397113800049
Validation loss: 2.092768165373033

Epoch: 6| Step: 6
Training loss: 1.3380966186523438
Validation loss: 2.0826157369921283

Epoch: 6| Step: 7
Training loss: 1.3874125480651855
Validation loss: 2.0351907950575634

Epoch: 6| Step: 8
Training loss: 1.1790729761123657
Validation loss: 2.08694528764294

Epoch: 6| Step: 9
Training loss: 1.044593095779419
Validation loss: 2.0589425589448664

Epoch: 6| Step: 10
Training loss: 1.0695475339889526
Validation loss: 2.0695521805876043

Epoch: 6| Step: 11
Training loss: 0.8135099411010742
Validation loss: 2.0648955324644684

Epoch: 6| Step: 12
Training loss: 0.7272129058837891
Validation loss: 2.025459438241938

Epoch: 6| Step: 13
Training loss: 0.7909271717071533
Validation loss: 2.008139593626863

Epoch: 582| Step: 0
Training loss: 1.5880100727081299
Validation loss: 2.0515768784348682

Epoch: 6| Step: 1
Training loss: 1.8796604871749878
Validation loss: 2.0264433724905855

Epoch: 6| Step: 2
Training loss: 1.1870613098144531
Validation loss: 2.055456180726328

Epoch: 6| Step: 3
Training loss: 1.2084145545959473
Validation loss: 2.0827676634634695

Epoch: 6| Step: 4
Training loss: 0.6577310562133789
Validation loss: 2.0696694158738658

Epoch: 6| Step: 5
Training loss: 1.051756739616394
Validation loss: 2.0632009454952773

Epoch: 6| Step: 6
Training loss: 0.9930545091629028
Validation loss: 2.008242558407527

Epoch: 6| Step: 7
Training loss: 1.514676570892334
Validation loss: 2.0486589388180803

Epoch: 6| Step: 8
Training loss: 1.1023640632629395
Validation loss: 2.081861508789883

Epoch: 6| Step: 9
Training loss: 1.0662076473236084
Validation loss: 2.0468792607707362

Epoch: 6| Step: 10
Training loss: 0.8769258856773376
Validation loss: 2.038413063172371

Epoch: 6| Step: 11
Training loss: 0.7566678524017334
Validation loss: 2.034352074387253

Epoch: 6| Step: 12
Training loss: 0.9107840657234192
Validation loss: 2.0574918523911507

Epoch: 6| Step: 13
Training loss: 1.215543270111084
Validation loss: 2.0467780072201966

Epoch: 583| Step: 0
Training loss: 0.7198500633239746
Validation loss: 2.0697738150114655

Epoch: 6| Step: 1
Training loss: 0.7601699829101562
Validation loss: 2.0685049026243147

Epoch: 6| Step: 2
Training loss: 1.3384801149368286
Validation loss: 2.0942407679814163

Epoch: 6| Step: 3
Training loss: 1.0907928943634033
Validation loss: 2.0807609019740934

Epoch: 6| Step: 4
Training loss: 1.9016709327697754
Validation loss: 2.0473334135547763

Epoch: 6| Step: 5
Training loss: 0.9336041212081909
Validation loss: 2.0659939089129047

Epoch: 6| Step: 6
Training loss: 0.5869755744934082
Validation loss: 2.055930737526186

Epoch: 6| Step: 7
Training loss: 0.8848663568496704
Validation loss: 2.0271009911773024

Epoch: 6| Step: 8
Training loss: 1.226901888847351
Validation loss: 2.0215467150493334

Epoch: 6| Step: 9
Training loss: 1.3460900783538818
Validation loss: 2.0140045073724564

Epoch: 6| Step: 10
Training loss: 1.2729172706604004
Validation loss: 2.0368191349890923

Epoch: 6| Step: 11
Training loss: 1.599899172782898
Validation loss: 2.064960070835647

Epoch: 6| Step: 12
Training loss: 1.2992273569107056
Validation loss: 2.0228987534840903

Epoch: 6| Step: 13
Training loss: 1.416666030883789
Validation loss: 2.051251819056849

Epoch: 584| Step: 0
Training loss: 1.178074836730957
Validation loss: 2.0653020771600867

Epoch: 6| Step: 1
Training loss: 1.4994450807571411
Validation loss: 2.0777157839908393

Epoch: 6| Step: 2
Training loss: 1.4373611211776733
Validation loss: 2.084275254639246

Epoch: 6| Step: 3
Training loss: 0.6532241106033325
Validation loss: 2.1307200744587886

Epoch: 6| Step: 4
Training loss: 1.0410981178283691
Validation loss: 2.049169676278227

Epoch: 6| Step: 5
Training loss: 0.8802475929260254
Validation loss: 2.091023152874362

Epoch: 6| Step: 6
Training loss: 0.7851145267486572
Validation loss: 2.044061804330477

Epoch: 6| Step: 7
Training loss: 0.9249441623687744
Validation loss: 2.07608397288989

Epoch: 6| Step: 8
Training loss: 1.4041965007781982
Validation loss: 2.051024580514559

Epoch: 6| Step: 9
Training loss: 1.0027151107788086
Validation loss: 2.0861493182438675

Epoch: 6| Step: 10
Training loss: 1.23898446559906
Validation loss: 2.0527806666589554

Epoch: 6| Step: 11
Training loss: 1.174990177154541
Validation loss: 2.047841795029179

Epoch: 6| Step: 12
Training loss: 1.3256261348724365
Validation loss: 2.0654498005426056

Epoch: 6| Step: 13
Training loss: 1.0200045108795166
Validation loss: 2.1053408602232575

Epoch: 585| Step: 0
Training loss: 1.6342878341674805
Validation loss: 2.0333570408564743

Epoch: 6| Step: 1
Training loss: 0.3563995659351349
Validation loss: 2.0585884278820408

Epoch: 6| Step: 2
Training loss: 1.0174365043640137
Validation loss: 2.076712175082135

Epoch: 6| Step: 3
Training loss: 1.0750483274459839
Validation loss: 2.0773806905233734

Epoch: 6| Step: 4
Training loss: 0.9785027503967285
Validation loss: 2.0636007939615557

Epoch: 6| Step: 5
Training loss: 0.8285506367683411
Validation loss: 2.0817861198097147

Epoch: 6| Step: 6
Training loss: 1.4038941860198975
Validation loss: 2.0391496535270446

Epoch: 6| Step: 7
Training loss: 1.2793564796447754
Validation loss: 2.0559578685350317

Epoch: 6| Step: 8
Training loss: 1.2811355590820312
Validation loss: 2.0624132335826917

Epoch: 6| Step: 9
Training loss: 1.0358400344848633
Validation loss: 2.043295362944244

Epoch: 6| Step: 10
Training loss: 1.5908302068710327
Validation loss: 2.0329449894607707

Epoch: 6| Step: 11
Training loss: 1.247786045074463
Validation loss: 2.080938744288619

Epoch: 6| Step: 12
Training loss: 1.219817042350769
Validation loss: 2.0786004784286662

Epoch: 6| Step: 13
Training loss: 0.844989538192749
Validation loss: 2.1006949716998684

Epoch: 586| Step: 0
Training loss: 1.32938814163208
Validation loss: 2.0514166393587665

Epoch: 6| Step: 1
Training loss: 0.8975686430931091
Validation loss: 2.138465699329171

Epoch: 6| Step: 2
Training loss: 1.0675139427185059
Validation loss: 2.0852689473859725

Epoch: 6| Step: 3
Training loss: 1.1042776107788086
Validation loss: 2.1016537925248504

Epoch: 6| Step: 4
Training loss: 1.13971745967865
Validation loss: 2.104025243431009

Epoch: 6| Step: 5
Training loss: 1.5838310718536377
Validation loss: 2.080699764272218

Epoch: 6| Step: 6
Training loss: 1.2410707473754883
Validation loss: 2.085642377535502

Epoch: 6| Step: 7
Training loss: 1.2950661182403564
Validation loss: 2.0426839397799585

Epoch: 6| Step: 8
Training loss: 1.0615686178207397
Validation loss: 2.0620028780352686

Epoch: 6| Step: 9
Training loss: 0.8546591997146606
Validation loss: 2.0714024138706986

Epoch: 6| Step: 10
Training loss: 0.6277495622634888
Validation loss: 2.0721837884636334

Epoch: 6| Step: 11
Training loss: 2.0285775661468506
Validation loss: 2.0732033483443724

Epoch: 6| Step: 12
Training loss: 0.47649967670440674
Validation loss: 2.0618584604673487

Epoch: 6| Step: 13
Training loss: 0.9554831385612488
Validation loss: 2.061536988904399

Epoch: 587| Step: 0
Training loss: 0.8317475914955139
Validation loss: 2.0560277815788024

Epoch: 6| Step: 1
Training loss: 1.6179280281066895
Validation loss: 2.067331894751518

Epoch: 6| Step: 2
Training loss: 1.4551026821136475
Validation loss: 2.071683934939805

Epoch: 6| Step: 3
Training loss: 1.2830638885498047
Validation loss: 2.016333573607988

Epoch: 6| Step: 4
Training loss: 0.9118261933326721
Validation loss: 2.0453661103402414

Epoch: 6| Step: 5
Training loss: 1.3531800508499146
Validation loss: 2.0223477514841224

Epoch: 6| Step: 6
Training loss: 1.3145426511764526
Validation loss: 2.049071514478294

Epoch: 6| Step: 7
Training loss: 0.9104261994361877
Validation loss: 2.0826878496395644

Epoch: 6| Step: 8
Training loss: 0.7939529418945312
Validation loss: 2.0747625250970163

Epoch: 6| Step: 9
Training loss: 1.1506106853485107
Validation loss: 2.0557527926660355

Epoch: 6| Step: 10
Training loss: 0.7919742465019226
Validation loss: 2.0762629175698883

Epoch: 6| Step: 11
Training loss: 1.5162783861160278
Validation loss: 2.0863007268598004

Epoch: 6| Step: 12
Training loss: 0.8821966052055359
Validation loss: 2.110582717003361

Epoch: 6| Step: 13
Training loss: 0.5690432190895081
Validation loss: 2.1127519376816286

Epoch: 588| Step: 0
Training loss: 0.878717303276062
Validation loss: 2.103615504439159

Epoch: 6| Step: 1
Training loss: 1.2267277240753174
Validation loss: 2.0824441858517226

Epoch: 6| Step: 2
Training loss: 1.5779565572738647
Validation loss: 2.0534306956875708

Epoch: 6| Step: 3
Training loss: 1.2345490455627441
Validation loss: 2.0955909400857906

Epoch: 6| Step: 4
Training loss: 0.7836997509002686
Validation loss: 2.022149616672147

Epoch: 6| Step: 5
Training loss: 0.7256583571434021
Validation loss: 2.0845967056930705

Epoch: 6| Step: 6
Training loss: 0.8823881149291992
Validation loss: 2.056710216306871

Epoch: 6| Step: 7
Training loss: 0.737399697303772
Validation loss: 2.0371122655048164

Epoch: 6| Step: 8
Training loss: 1.9921929836273193
Validation loss: 2.0636434529417302

Epoch: 6| Step: 9
Training loss: 1.1652718782424927
Validation loss: 2.0693876679225633

Epoch: 6| Step: 10
Training loss: 1.1061465740203857
Validation loss: 2.072512008810556

Epoch: 6| Step: 11
Training loss: 1.3997101783752441
Validation loss: 2.0520356162901847

Epoch: 6| Step: 12
Training loss: 0.7756242752075195
Validation loss: 2.0637920928257767

Epoch: 6| Step: 13
Training loss: 1.7729532718658447
Validation loss: 2.0431966422706522

Epoch: 589| Step: 0
Training loss: 1.3853135108947754
Validation loss: 2.0453612009684243

Epoch: 6| Step: 1
Training loss: 1.1615934371948242
Validation loss: 2.05501123269399

Epoch: 6| Step: 2
Training loss: 0.9575471878051758
Validation loss: 2.0491392445820633

Epoch: 6| Step: 3
Training loss: 1.5295255184173584
Validation loss: 2.052491359813239

Epoch: 6| Step: 4
Training loss: 1.2581684589385986
Validation loss: 2.0490962382285827

Epoch: 6| Step: 5
Training loss: 1.1987766027450562
Validation loss: 2.069830689378964

Epoch: 6| Step: 6
Training loss: 1.0763287544250488
Validation loss: 2.0586134977238153

Epoch: 6| Step: 7
Training loss: 0.892917275428772
Validation loss: 2.0511443281686432

Epoch: 6| Step: 8
Training loss: 1.1339517831802368
Validation loss: 2.088438457058322

Epoch: 6| Step: 9
Training loss: 1.0728442668914795
Validation loss: 2.1249082985744683

Epoch: 6| Step: 10
Training loss: 0.7412497401237488
Validation loss: 2.082326930056336

Epoch: 6| Step: 11
Training loss: 1.1148078441619873
Validation loss: 2.0761087812403196

Epoch: 6| Step: 12
Training loss: 1.3238952159881592
Validation loss: 2.043333133061727

Epoch: 6| Step: 13
Training loss: 0.8229348063468933
Validation loss: 2.07710507095501

Epoch: 590| Step: 0
Training loss: 0.8910579681396484
Validation loss: 2.0557307581747732

Epoch: 6| Step: 1
Training loss: 0.8065178394317627
Validation loss: 2.0420598317218084

Epoch: 6| Step: 2
Training loss: 1.174386739730835
Validation loss: 2.0660266671129452

Epoch: 6| Step: 3
Training loss: 1.3968359231948853
Validation loss: 2.099260876255651

Epoch: 6| Step: 4
Training loss: 1.420310616493225
Validation loss: 2.0136297236206713

Epoch: 6| Step: 5
Training loss: 0.803654670715332
Validation loss: 2.051965639155398

Epoch: 6| Step: 6
Training loss: 0.9893176555633545
Validation loss: 2.085957481015113

Epoch: 6| Step: 7
Training loss: 1.2716697454452515
Validation loss: 2.0543279481190506

Epoch: 6| Step: 8
Training loss: 1.1206843852996826
Validation loss: 2.088221361560206

Epoch: 6| Step: 9
Training loss: 1.1219210624694824
Validation loss: 2.0555971963431245

Epoch: 6| Step: 10
Training loss: 1.0543086528778076
Validation loss: 2.0967521052206717

Epoch: 6| Step: 11
Training loss: 1.34601628780365
Validation loss: 2.095496335337239

Epoch: 6| Step: 12
Training loss: 0.8161472678184509
Validation loss: 2.1274672426203245

Epoch: 6| Step: 13
Training loss: 1.2558492422103882
Validation loss: 2.0533618247637184

Epoch: 591| Step: 0
Training loss: 0.7830928564071655
Validation loss: 2.162818149853778

Epoch: 6| Step: 1
Training loss: 1.1385101079940796
Validation loss: 2.0880893725220875

Epoch: 6| Step: 2
Training loss: 1.0990126132965088
Validation loss: 2.089684755571427

Epoch: 6| Step: 3
Training loss: 0.9675328135490417
Validation loss: 2.0728148747515935

Epoch: 6| Step: 4
Training loss: 1.1311664581298828
Validation loss: 2.0892877014734412

Epoch: 6| Step: 5
Training loss: 0.9085276126861572
Validation loss: 2.0689163541281097

Epoch: 6| Step: 6
Training loss: 0.8567993640899658
Validation loss: 2.0782134840565343

Epoch: 6| Step: 7
Training loss: 1.303730845451355
Validation loss: 2.061450896724578

Epoch: 6| Step: 8
Training loss: 1.4017285108566284
Validation loss: 2.057425340016683

Epoch: 6| Step: 9
Training loss: 1.4195427894592285
Validation loss: 2.046529418678694

Epoch: 6| Step: 10
Training loss: 1.1934617757797241
Validation loss: 2.1084225523856377

Epoch: 6| Step: 11
Training loss: 0.9206700325012207
Validation loss: 2.0580847365881807

Epoch: 6| Step: 12
Training loss: 1.4333934783935547
Validation loss: 2.0519219072916175

Epoch: 6| Step: 13
Training loss: 1.2796003818511963
Validation loss: 2.0657074246355283

Epoch: 592| Step: 0
Training loss: 0.7265672087669373
Validation loss: 2.0378662014520295

Epoch: 6| Step: 1
Training loss: 0.7468521595001221
Validation loss: 2.048255632000585

Epoch: 6| Step: 2
Training loss: 1.3467211723327637
Validation loss: 2.071015065716159

Epoch: 6| Step: 3
Training loss: 1.1221834421157837
Validation loss: 2.025493678226266

Epoch: 6| Step: 4
Training loss: 0.8147158622741699
Validation loss: 2.041107266179977

Epoch: 6| Step: 5
Training loss: 1.635429859161377
Validation loss: 2.0763208661028134

Epoch: 6| Step: 6
Training loss: 1.5000338554382324
Validation loss: 2.126013058488087

Epoch: 6| Step: 7
Training loss: 1.022298812866211
Validation loss: 2.0438434026574575

Epoch: 6| Step: 8
Training loss: 0.9938912391662598
Validation loss: 2.113428274790446

Epoch: 6| Step: 9
Training loss: 1.4540345668792725
Validation loss: 2.094561443533949

Epoch: 6| Step: 10
Training loss: 1.1112661361694336
Validation loss: 2.091329059293193

Epoch: 6| Step: 11
Training loss: 0.9332446455955505
Validation loss: 2.089400901589342

Epoch: 6| Step: 12
Training loss: 1.0333958864212036
Validation loss: 2.0793097262741416

Epoch: 6| Step: 13
Training loss: 0.9307039976119995
Validation loss: 2.0642287961898313

Epoch: 593| Step: 0
Training loss: 1.2094528675079346
Validation loss: 2.0704747630703833

Epoch: 6| Step: 1
Training loss: 0.5717062950134277
Validation loss: 2.0558360917593843

Epoch: 6| Step: 2
Training loss: 1.0818557739257812
Validation loss: 2.057993414581463

Epoch: 6| Step: 3
Training loss: 1.1420981884002686
Validation loss: 2.072255116637035

Epoch: 6| Step: 4
Training loss: 1.3500875234603882
Validation loss: 2.044757584089874

Epoch: 6| Step: 5
Training loss: 0.8612898588180542
Validation loss: 2.080122570837698

Epoch: 6| Step: 6
Training loss: 0.47512567043304443
Validation loss: 2.0303274713536745

Epoch: 6| Step: 7
Training loss: 1.185899019241333
Validation loss: 2.080410977845551

Epoch: 6| Step: 8
Training loss: 1.288703441619873
Validation loss: 2.0244111643042615

Epoch: 6| Step: 9
Training loss: 1.407394528388977
Validation loss: 2.0938101789002777

Epoch: 6| Step: 10
Training loss: 1.315505027770996
Validation loss: 2.081225102947604

Epoch: 6| Step: 11
Training loss: 1.3574602603912354
Validation loss: 2.0341387974318637

Epoch: 6| Step: 12
Training loss: 1.1604212522506714
Validation loss: 2.0652100680976786

Epoch: 6| Step: 13
Training loss: 1.3768558502197266
Validation loss: 2.081575437258649

Epoch: 594| Step: 0
Training loss: 0.9349155426025391
Validation loss: 2.074394695220455

Epoch: 6| Step: 1
Training loss: 0.6431466341018677
Validation loss: 2.0945155197574246

Epoch: 6| Step: 2
Training loss: 1.028881311416626
Validation loss: 2.0530394020900933

Epoch: 6| Step: 3
Training loss: 1.0103501081466675
Validation loss: 2.1081534790736374

Epoch: 6| Step: 4
Training loss: 1.059266448020935
Validation loss: 2.0982653043603383

Epoch: 6| Step: 5
Training loss: 0.5381783246994019
Validation loss: 2.1222099168326265

Epoch: 6| Step: 6
Training loss: 1.371958613395691
Validation loss: 2.122953135480163

Epoch: 6| Step: 7
Training loss: 1.1240439414978027
Validation loss: 2.0622165690186205

Epoch: 6| Step: 8
Training loss: 1.0428638458251953
Validation loss: 2.130918547671328

Epoch: 6| Step: 9
Training loss: 1.024601697921753
Validation loss: 2.0737495076271797

Epoch: 6| Step: 10
Training loss: 1.1907209157943726
Validation loss: 2.098583899518495

Epoch: 6| Step: 11
Training loss: 0.957853376865387
Validation loss: 2.0196473367752565

Epoch: 6| Step: 12
Training loss: 1.975895881652832
Validation loss: 2.062943455993488

Epoch: 6| Step: 13
Training loss: 1.9669750928878784
Validation loss: 2.102380229580787

Epoch: 595| Step: 0
Training loss: 0.9102891683578491
Validation loss: 2.0721290214087373

Epoch: 6| Step: 1
Training loss: 1.1559395790100098
Validation loss: 2.0403079730208202

Epoch: 6| Step: 2
Training loss: 1.060090184211731
Validation loss: 2.056351289954237

Epoch: 6| Step: 3
Training loss: 1.4306581020355225
Validation loss: 2.1178854562902965

Epoch: 6| Step: 4
Training loss: 1.1408215761184692
Validation loss: 2.1023787157509917

Epoch: 6| Step: 5
Training loss: 1.3953399658203125
Validation loss: 2.0440034533059723

Epoch: 6| Step: 6
Training loss: 1.1027815341949463
Validation loss: 2.046104105569983

Epoch: 6| Step: 7
Training loss: 1.0357489585876465
Validation loss: 2.0354133626466155

Epoch: 6| Step: 8
Training loss: 0.581852912902832
Validation loss: 2.065453588321645

Epoch: 6| Step: 9
Training loss: 1.6701329946517944
Validation loss: 2.051909726153138

Epoch: 6| Step: 10
Training loss: 1.3922510147094727
Validation loss: 2.0896699172194286

Epoch: 6| Step: 11
Training loss: 0.7952741384506226
Validation loss: 2.0404597174736763

Epoch: 6| Step: 12
Training loss: 1.0492758750915527
Validation loss: 2.0947261394992953

Epoch: 6| Step: 13
Training loss: 0.9247832894325256
Validation loss: 2.0745426865034204

Epoch: 596| Step: 0
Training loss: 1.2311711311340332
Validation loss: 2.046535908534963

Epoch: 6| Step: 1
Training loss: 1.2841521501541138
Validation loss: 2.0852479985965195

Epoch: 6| Step: 2
Training loss: 1.4593604803085327
Validation loss: 2.072892327462473

Epoch: 6| Step: 3
Training loss: 1.5279715061187744
Validation loss: 2.0511978646760345

Epoch: 6| Step: 4
Training loss: 0.8112614154815674
Validation loss: 2.068090513188352

Epoch: 6| Step: 5
Training loss: 1.2114734649658203
Validation loss: 2.0712951960102206

Epoch: 6| Step: 6
Training loss: 1.1377627849578857
Validation loss: 2.09347136943571

Epoch: 6| Step: 7
Training loss: 1.3040120601654053
Validation loss: 2.078690872397474

Epoch: 6| Step: 8
Training loss: 1.144018292427063
Validation loss: 2.0871855751160653

Epoch: 6| Step: 9
Training loss: 0.8992425203323364
Validation loss: 2.0710091975427445

Epoch: 6| Step: 10
Training loss: 1.0773687362670898
Validation loss: 2.044267515982351

Epoch: 6| Step: 11
Training loss: 1.0052127838134766
Validation loss: 2.0529501579141103

Epoch: 6| Step: 12
Training loss: 1.0076751708984375
Validation loss: 2.09506622950236

Epoch: 6| Step: 13
Training loss: 0.5723013877868652
Validation loss: 2.1146844471654584

Epoch: 597| Step: 0
Training loss: 1.0547945499420166
Validation loss: 2.0906926367872503

Epoch: 6| Step: 1
Training loss: 1.2975878715515137
Validation loss: 2.1177077293395996

Epoch: 6| Step: 2
Training loss: 1.2003966569900513
Validation loss: 2.0659583589082122

Epoch: 6| Step: 3
Training loss: 1.5063817501068115
Validation loss: 2.0433100731142106

Epoch: 6| Step: 4
Training loss: 1.110959529876709
Validation loss: 2.0423240020710933

Epoch: 6| Step: 5
Training loss: 1.1521093845367432
Validation loss: 2.04480484736863

Epoch: 6| Step: 6
Training loss: 1.0165005922317505
Validation loss: 2.045954790166629

Epoch: 6| Step: 7
Training loss: 0.9964255094528198
Validation loss: 2.0647200986903202

Epoch: 6| Step: 8
Training loss: 0.7619344592094421
Validation loss: 2.083665819578273

Epoch: 6| Step: 9
Training loss: 1.1394619941711426
Validation loss: 2.0496435216678086

Epoch: 6| Step: 10
Training loss: 2.088379383087158
Validation loss: 2.1081089409448768

Epoch: 6| Step: 11
Training loss: 0.7685815095901489
Validation loss: 2.102792734740883

Epoch: 6| Step: 12
Training loss: 0.7459197640419006
Validation loss: 2.102035149451225

Epoch: 6| Step: 13
Training loss: 0.7322547435760498
Validation loss: 2.1240063790352113

Epoch: 598| Step: 0
Training loss: 0.851131021976471
Validation loss: 2.1225869194153817

Epoch: 6| Step: 1
Training loss: 1.3453158140182495
Validation loss: 2.1036196280551214

Epoch: 6| Step: 2
Training loss: 1.238283395767212
Validation loss: 2.0859107279008433

Epoch: 6| Step: 3
Training loss: 1.2455248832702637
Validation loss: 2.1266518920980473

Epoch: 6| Step: 4
Training loss: 1.0436012744903564
Validation loss: 2.105461541042533

Epoch: 6| Step: 5
Training loss: 1.2862646579742432
Validation loss: 2.1174916451977146

Epoch: 6| Step: 6
Training loss: 0.6493057608604431
Validation loss: 2.121886871194327

Epoch: 6| Step: 7
Training loss: 1.0286788940429688
Validation loss: 2.119710080085262

Epoch: 6| Step: 8
Training loss: 1.1268545389175415
Validation loss: 2.0865754235175347

Epoch: 6| Step: 9
Training loss: 1.4325542449951172
Validation loss: 2.074521176276668

Epoch: 6| Step: 10
Training loss: 1.2366853952407837
Validation loss: 2.0873067789180304

Epoch: 6| Step: 11
Training loss: 1.2421820163726807
Validation loss: 2.0718513893824753

Epoch: 6| Step: 12
Training loss: 1.570168375968933
Validation loss: 2.0489888268132366

Epoch: 6| Step: 13
Training loss: 0.21084019541740417
Validation loss: 2.0443532364342802

Epoch: 599| Step: 0
Training loss: 1.1463813781738281
Validation loss: 2.058259364097349

Epoch: 6| Step: 1
Training loss: 0.6594127416610718
Validation loss: 2.0577102771369358

Epoch: 6| Step: 2
Training loss: 1.1149526834487915
Validation loss: 2.0352171954288276

Epoch: 6| Step: 3
Training loss: 1.1737217903137207
Validation loss: 2.0667909345319195

Epoch: 6| Step: 4
Training loss: 0.8638687133789062
Validation loss: 2.0590022712625484

Epoch: 6| Step: 5
Training loss: 1.272479772567749
Validation loss: 2.034645826585831

Epoch: 6| Step: 6
Training loss: 0.6138901114463806
Validation loss: 2.0297982872173352

Epoch: 6| Step: 7
Training loss: 1.3663651943206787
Validation loss: 2.05923492293204

Epoch: 6| Step: 8
Training loss: 1.307542324066162
Validation loss: 2.075525591450353

Epoch: 6| Step: 9
Training loss: 1.246262550354004
Validation loss: 2.0569398454440537

Epoch: 6| Step: 10
Training loss: 1.3381997346878052
Validation loss: 2.091983800293297

Epoch: 6| Step: 11
Training loss: 1.2777163982391357
Validation loss: 2.038927798630089

Epoch: 6| Step: 12
Training loss: 1.1198899745941162
Validation loss: 2.068125855538153

Epoch: 6| Step: 13
Training loss: 1.7140740156173706
Validation loss: 2.128549893697103

Epoch: 600| Step: 0
Training loss: 1.3498598337173462
Validation loss: 2.1133709030766643

Epoch: 6| Step: 1
Training loss: 1.192802906036377
Validation loss: 2.0549843554855673

Epoch: 6| Step: 2
Training loss: 1.4193462133407593
Validation loss: 2.076227831584151

Epoch: 6| Step: 3
Training loss: 1.4952324628829956
Validation loss: 2.070083418200093

Epoch: 6| Step: 4
Training loss: 1.46310555934906
Validation loss: 2.0878496464862617

Epoch: 6| Step: 5
Training loss: 0.6550434827804565
Validation loss: 2.0758958349945726

Epoch: 6| Step: 6
Training loss: 0.808452308177948
Validation loss: 2.0826316828368814

Epoch: 6| Step: 7
Training loss: 1.243856430053711
Validation loss: 2.048347742326798

Epoch: 6| Step: 8
Training loss: 0.8166085481643677
Validation loss: 2.077831863075174

Epoch: 6| Step: 9
Training loss: 1.0033156871795654
Validation loss: 2.0759115321661836

Epoch: 6| Step: 10
Training loss: 0.9101423025131226
Validation loss: 2.053008640966108

Epoch: 6| Step: 11
Training loss: 0.9641501307487488
Validation loss: 2.042330434245448

Epoch: 6| Step: 12
Training loss: 1.1436582803726196
Validation loss: 2.0645490205416115

Epoch: 6| Step: 13
Training loss: 1.1082572937011719
Validation loss: 2.0686281291387414

Epoch: 601| Step: 0
Training loss: 1.780153751373291
Validation loss: 2.052260104046073

Epoch: 6| Step: 1
Training loss: 0.9531466960906982
Validation loss: 1.998075730057173

Epoch: 6| Step: 2
Training loss: 0.9665166139602661
Validation loss: 2.0443670608664073

Epoch: 6| Step: 3
Training loss: 0.8584529161453247
Validation loss: 2.071586985741892

Epoch: 6| Step: 4
Training loss: 1.5764719247817993
Validation loss: 2.0502790097267396

Epoch: 6| Step: 5
Training loss: 1.2371268272399902
Validation loss: 2.0603499591991468

Epoch: 6| Step: 6
Training loss: 0.9369499683380127
Validation loss: 2.058189735617689

Epoch: 6| Step: 7
Training loss: 1.6215689182281494
Validation loss: 2.0562835047321935

Epoch: 6| Step: 8
Training loss: 0.9248002767562866
Validation loss: 2.0697194581390708

Epoch: 6| Step: 9
Training loss: 0.9825567603111267
Validation loss: 2.029317222615724

Epoch: 6| Step: 10
Training loss: 0.6912609338760376
Validation loss: 2.03867753090397

Epoch: 6| Step: 11
Training loss: 1.429255485534668
Validation loss: 2.0344868988119145

Epoch: 6| Step: 12
Training loss: 0.8684679269790649
Validation loss: 2.0368176275683987

Epoch: 6| Step: 13
Training loss: 1.274613857269287
Validation loss: 2.0625183159305203

Epoch: 602| Step: 0
Training loss: 1.1714255809783936
Validation loss: 2.029238598321074

Epoch: 6| Step: 1
Training loss: 1.2718143463134766
Validation loss: 2.0730280978705293

Epoch: 6| Step: 2
Training loss: 0.7312037944793701
Validation loss: 2.0210822756572435

Epoch: 6| Step: 3
Training loss: 1.15681791305542
Validation loss: 2.0973503615266536

Epoch: 6| Step: 4
Training loss: 1.2215890884399414
Validation loss: 2.0483351702331216

Epoch: 6| Step: 5
Training loss: 1.0480787754058838
Validation loss: 2.025841433514831

Epoch: 6| Step: 6
Training loss: 1.1473605632781982
Validation loss: 2.0304745076805033

Epoch: 6| Step: 7
Training loss: 1.0819380283355713
Validation loss: 2.0598975535362

Epoch: 6| Step: 8
Training loss: 1.2017637491226196
Validation loss: 2.0490385383687992

Epoch: 6| Step: 9
Training loss: 1.174599051475525
Validation loss: 2.0433174769083657

Epoch: 6| Step: 10
Training loss: 1.0539932250976562
Validation loss: 2.0613973781626713

Epoch: 6| Step: 11
Training loss: 0.9237722754478455
Validation loss: 2.0496682390089958

Epoch: 6| Step: 12
Training loss: 1.0127835273742676
Validation loss: 2.09822912498187

Epoch: 6| Step: 13
Training loss: 1.4785165786743164
Validation loss: 2.0628577278506373

Epoch: 603| Step: 0
Training loss: 0.42527490854263306
Validation loss: 2.0895692635607976

Epoch: 6| Step: 1
Training loss: 1.0633559226989746
Validation loss: 2.0684433701217815

Epoch: 6| Step: 2
Training loss: 1.084768533706665
Validation loss: 2.0667346792836345

Epoch: 6| Step: 3
Training loss: 0.7579076290130615
Validation loss: 2.132431907038535

Epoch: 6| Step: 4
Training loss: 1.6928701400756836
Validation loss: 2.04133500078673

Epoch: 6| Step: 5
Training loss: 1.6724302768707275
Validation loss: 2.055414294683805

Epoch: 6| Step: 6
Training loss: 1.2235617637634277
Validation loss: 2.096989695743848

Epoch: 6| Step: 7
Training loss: 0.5208472013473511
Validation loss: 2.0999820540028233

Epoch: 6| Step: 8
Training loss: 1.393052101135254
Validation loss: 2.0226283739971858

Epoch: 6| Step: 9
Training loss: 1.0356513261795044
Validation loss: 2.0748277402693227

Epoch: 6| Step: 10
Training loss: 1.3608726263046265
Validation loss: 2.0185083535409745

Epoch: 6| Step: 11
Training loss: 1.1500990390777588
Validation loss: 2.064775102881975

Epoch: 6| Step: 12
Training loss: 1.0537915229797363
Validation loss: 2.10253184200615

Epoch: 6| Step: 13
Training loss: 0.9707561135292053
Validation loss: 2.024127583349905

Epoch: 604| Step: 0
Training loss: 1.5826992988586426
Validation loss: 2.0743162273078837

Epoch: 6| Step: 1
Training loss: 0.9194498062133789
Validation loss: 2.094250427779331

Epoch: 6| Step: 2
Training loss: 1.2045856714248657
Validation loss: 1.9982871701640468

Epoch: 6| Step: 3
Training loss: 0.7583295106887817
Validation loss: 2.078009772044356

Epoch: 6| Step: 4
Training loss: 1.0194411277770996
Validation loss: 2.0478439190054454

Epoch: 6| Step: 5
Training loss: 2.132331132888794
Validation loss: 2.0574545860290527

Epoch: 6| Step: 6
Training loss: 1.0813467502593994
Validation loss: 2.0976474541489796

Epoch: 6| Step: 7
Training loss: 0.9996910095214844
Validation loss: 2.0929376745736725

Epoch: 6| Step: 8
Training loss: 1.1959609985351562
Validation loss: 2.066272783023055

Epoch: 6| Step: 9
Training loss: 0.4461319148540497
Validation loss: 2.0890183359064083

Epoch: 6| Step: 10
Training loss: 1.0670945644378662
Validation loss: 2.11672882879934

Epoch: 6| Step: 11
Training loss: 1.3795084953308105
Validation loss: 2.0885383698248092

Epoch: 6| Step: 12
Training loss: 0.9444025754928589
Validation loss: 2.079986926048033

Epoch: 6| Step: 13
Training loss: 0.7456200122833252
Validation loss: 2.111703521461897

Epoch: 605| Step: 0
Training loss: 1.121117115020752
Validation loss: 2.1204302362216416

Epoch: 6| Step: 1
Training loss: 1.113688349723816
Validation loss: 2.0908639610454602

Epoch: 6| Step: 2
Training loss: 0.7921696901321411
Validation loss: 2.0434835777487805

Epoch: 6| Step: 3
Training loss: 1.1261968612670898
Validation loss: 2.0692054943371843

Epoch: 6| Step: 4
Training loss: 1.2229535579681396
Validation loss: 2.0658665805734615

Epoch: 6| Step: 5
Training loss: 1.23215651512146
Validation loss: 2.0563359593832367

Epoch: 6| Step: 6
Training loss: 1.338445782661438
Validation loss: 2.030701953877685

Epoch: 6| Step: 7
Training loss: 0.9500269889831543
Validation loss: 2.037978579921107

Epoch: 6| Step: 8
Training loss: 1.1735352277755737
Validation loss: 2.053610950387934

Epoch: 6| Step: 9
Training loss: 1.2475955486297607
Validation loss: 2.009121894836426

Epoch: 6| Step: 10
Training loss: 1.144317388534546
Validation loss: 2.013079156157791

Epoch: 6| Step: 11
Training loss: 0.6691950559616089
Validation loss: 2.041890578885232

Epoch: 6| Step: 12
Training loss: 1.8471088409423828
Validation loss: 2.0225788418964674

Epoch: 6| Step: 13
Training loss: 1.3441135883331299
Validation loss: 2.0516150010529386

Epoch: 606| Step: 0
Training loss: 1.603187084197998
Validation loss: 2.0659897609423568

Epoch: 6| Step: 1
Training loss: 0.799464762210846
Validation loss: 2.1093193741254908

Epoch: 6| Step: 2
Training loss: 0.7476779222488403
Validation loss: 2.1060381345851447

Epoch: 6| Step: 3
Training loss: 0.8345330357551575
Validation loss: 2.092154707959903

Epoch: 6| Step: 4
Training loss: 1.1192526817321777
Validation loss: 2.114027028442711

Epoch: 6| Step: 5
Training loss: 0.5558426976203918
Validation loss: 2.125831514276484

Epoch: 6| Step: 6
Training loss: 0.908936083316803
Validation loss: 2.0680987450384323

Epoch: 6| Step: 7
Training loss: 1.2377920150756836
Validation loss: 2.036259892166302

Epoch: 6| Step: 8
Training loss: 1.4198079109191895
Validation loss: 2.052449080251878

Epoch: 6| Step: 9
Training loss: 1.536351203918457
Validation loss: 2.077416266164472

Epoch: 6| Step: 10
Training loss: 1.2309914827346802
Validation loss: 2.060278537452862

Epoch: 6| Step: 11
Training loss: 1.2083587646484375
Validation loss: 2.031113545099894

Epoch: 6| Step: 12
Training loss: 1.2232394218444824
Validation loss: 2.04307218264508

Epoch: 6| Step: 13
Training loss: 0.837809145450592
Validation loss: 2.028034676787674

Epoch: 607| Step: 0
Training loss: 1.4184627532958984
Validation loss: 2.0471577323893064

Epoch: 6| Step: 1
Training loss: 1.0837219953536987
Validation loss: 2.031516323807419

Epoch: 6| Step: 2
Training loss: 1.1500940322875977
Validation loss: 2.039774607586604

Epoch: 6| Step: 3
Training loss: 0.907157838344574
Validation loss: 2.1121835785527385

Epoch: 6| Step: 4
Training loss: 1.1960303783416748
Validation loss: 2.006455341974894

Epoch: 6| Step: 5
Training loss: 1.8848793506622314
Validation loss: 2.079626014155726

Epoch: 6| Step: 6
Training loss: 0.7975881099700928
Validation loss: 2.0103721977562032

Epoch: 6| Step: 7
Training loss: 0.9341126084327698
Validation loss: 2.0058150393988496

Epoch: 6| Step: 8
Training loss: 1.281959056854248
Validation loss: 2.070894633570025

Epoch: 6| Step: 9
Training loss: 0.5505853891372681
Validation loss: 2.0500737890120475

Epoch: 6| Step: 10
Training loss: 0.8964263796806335
Validation loss: 2.0084543202513006

Epoch: 6| Step: 11
Training loss: 1.2828800678253174
Validation loss: 2.0706515517286075

Epoch: 6| Step: 12
Training loss: 1.135825276374817
Validation loss: 2.05334440354378

Epoch: 6| Step: 13
Training loss: 1.0275148153305054
Validation loss: 2.08610559791647

Epoch: 608| Step: 0
Training loss: 1.2934048175811768
Validation loss: 2.0711749856190016

Epoch: 6| Step: 1
Training loss: 0.9362775087356567
Validation loss: 2.0776559998912196

Epoch: 6| Step: 2
Training loss: 1.0984387397766113
Validation loss: 2.0987443988041212

Epoch: 6| Step: 3
Training loss: 1.2095191478729248
Validation loss: 2.070619385729554

Epoch: 6| Step: 4
Training loss: 0.6807397603988647
Validation loss: 2.0737401490570395

Epoch: 6| Step: 5
Training loss: 1.124675989151001
Validation loss: 2.075225705741554

Epoch: 6| Step: 6
Training loss: 1.18088698387146
Validation loss: 2.0625509600485525

Epoch: 6| Step: 7
Training loss: 1.1844606399536133
Validation loss: 2.038166630652643

Epoch: 6| Step: 8
Training loss: 0.9942421913146973
Validation loss: 2.0794712676796863

Epoch: 6| Step: 9
Training loss: 1.5763870477676392
Validation loss: 2.092425278438035

Epoch: 6| Step: 10
Training loss: 1.0495264530181885
Validation loss: 2.05985878744433

Epoch: 6| Step: 11
Training loss: 1.0262551307678223
Validation loss: 2.050461479412612

Epoch: 6| Step: 12
Training loss: 1.1611957550048828
Validation loss: 2.06800014229231

Epoch: 6| Step: 13
Training loss: 0.9910044074058533
Validation loss: 2.0617975496476695

Epoch: 609| Step: 0
Training loss: 0.9037256240844727
Validation loss: 2.041684414750786

Epoch: 6| Step: 1
Training loss: 1.184973120689392
Validation loss: 2.034102970553983

Epoch: 6| Step: 2
Training loss: 1.3031437397003174
Validation loss: 2.057812508716378

Epoch: 6| Step: 3
Training loss: 1.0939600467681885
Validation loss: 2.0471626250974593

Epoch: 6| Step: 4
Training loss: 1.0199086666107178
Validation loss: 2.0188269922810216

Epoch: 6| Step: 5
Training loss: 2.0817058086395264
Validation loss: 2.0121641018057383

Epoch: 6| Step: 6
Training loss: 0.7187278270721436
Validation loss: 2.103147529786633

Epoch: 6| Step: 7
Training loss: 0.5910360813140869
Validation loss: 2.0319101220817974

Epoch: 6| Step: 8
Training loss: 1.1951487064361572
Validation loss: 2.066576660320323

Epoch: 6| Step: 9
Training loss: 1.1728692054748535
Validation loss: 2.056165596490265

Epoch: 6| Step: 10
Training loss: 0.7131181955337524
Validation loss: 2.0143394918851953

Epoch: 6| Step: 11
Training loss: 1.3268539905548096
Validation loss: 2.0775347601982856

Epoch: 6| Step: 12
Training loss: 1.423032283782959
Validation loss: 2.095728323023806

Epoch: 6| Step: 13
Training loss: 0.8235291242599487
Validation loss: 2.047121699138354

Epoch: 610| Step: 0
Training loss: 1.3293554782867432
Validation loss: 2.0761153569785495

Epoch: 6| Step: 1
Training loss: 0.7280814051628113
Validation loss: 2.0728303950320006

Epoch: 6| Step: 2
Training loss: 1.1056057214736938
Validation loss: 2.0600038779679166

Epoch: 6| Step: 3
Training loss: 0.9924862384796143
Validation loss: 2.055994418359572

Epoch: 6| Step: 4
Training loss: 1.2666525840759277
Validation loss: 2.0872605128954818

Epoch: 6| Step: 5
Training loss: 0.7689861059188843
Validation loss: 2.056906218169838

Epoch: 6| Step: 6
Training loss: 0.9281586408615112
Validation loss: 2.0760747771109305

Epoch: 6| Step: 7
Training loss: 1.3115981817245483
Validation loss: 2.0648954965734996

Epoch: 6| Step: 8
Training loss: 1.4255380630493164
Validation loss: 2.057550375179578

Epoch: 6| Step: 9
Training loss: 1.2689114809036255
Validation loss: 2.0650034924989105

Epoch: 6| Step: 10
Training loss: 0.9256734848022461
Validation loss: 2.0389184105780815

Epoch: 6| Step: 11
Training loss: 1.3258633613586426
Validation loss: 2.08605267155555

Epoch: 6| Step: 12
Training loss: 0.7566020488739014
Validation loss: 2.103009113701441

Epoch: 6| Step: 13
Training loss: 1.3721675872802734
Validation loss: 2.0816715558369956

Epoch: 611| Step: 0
Training loss: 1.1521780490875244
Validation loss: 2.090788487465151

Epoch: 6| Step: 1
Training loss: 1.2146580219268799
Validation loss: 2.0418305884125414

Epoch: 6| Step: 2
Training loss: 0.8064727783203125
Validation loss: 2.044502747956143

Epoch: 6| Step: 3
Training loss: 1.156903862953186
Validation loss: 2.0792525455515873

Epoch: 6| Step: 4
Training loss: 1.1646902561187744
Validation loss: 2.0381190648642917

Epoch: 6| Step: 5
Training loss: 1.1241776943206787
Validation loss: 2.044411959186677

Epoch: 6| Step: 6
Training loss: 1.6583775281906128
Validation loss: 2.077014897459297

Epoch: 6| Step: 7
Training loss: 1.429384708404541
Validation loss: 2.0960772011869695

Epoch: 6| Step: 8
Training loss: 0.8408825397491455
Validation loss: 2.0522565457128708

Epoch: 6| Step: 9
Training loss: 0.6413365602493286
Validation loss: 2.0274699323920795

Epoch: 6| Step: 10
Training loss: 1.1926186084747314
Validation loss: 2.0192367030728247

Epoch: 6| Step: 11
Training loss: 1.043642520904541
Validation loss: 2.050653954987885

Epoch: 6| Step: 12
Training loss: 0.8543736934661865
Validation loss: 2.0702969181922173

Epoch: 6| Step: 13
Training loss: 1.5989339351654053
Validation loss: 1.9980489797489618

Epoch: 612| Step: 0
Training loss: 0.9764416217803955
Validation loss: 2.0413174065210486

Epoch: 6| Step: 1
Training loss: 1.3561898469924927
Validation loss: 2.0035785295630015

Epoch: 6| Step: 2
Training loss: 0.7203752994537354
Validation loss: 2.055246586440712

Epoch: 6| Step: 3
Training loss: 1.3142966032028198
Validation loss: 2.0356019645608883

Epoch: 6| Step: 4
Training loss: 0.8237566947937012
Validation loss: 2.0410613603489374

Epoch: 6| Step: 5
Training loss: 1.2447452545166016
Validation loss: 2.1082037520664993

Epoch: 6| Step: 6
Training loss: 1.1596254110336304
Validation loss: 2.080118718967643

Epoch: 6| Step: 7
Training loss: 1.7285025119781494
Validation loss: 2.0601407609960085

Epoch: 6| Step: 8
Training loss: 1.2367056608200073
Validation loss: 2.0735173802221976

Epoch: 6| Step: 9
Training loss: 1.0247764587402344
Validation loss: 2.0871551421380814

Epoch: 6| Step: 10
Training loss: 0.8112735152244568
Validation loss: 2.098631551188807

Epoch: 6| Step: 11
Training loss: 1.105472207069397
Validation loss: 2.0872165656858876

Epoch: 6| Step: 12
Training loss: 1.2387974262237549
Validation loss: 2.1050460620593

Epoch: 6| Step: 13
Training loss: 0.3780815899372101
Validation loss: 2.031220525823614

Epoch: 613| Step: 0
Training loss: 1.7656863927841187
Validation loss: 2.043410699854615

Epoch: 6| Step: 1
Training loss: 1.2360018491744995
Validation loss: 2.0922857176872993

Epoch: 6| Step: 2
Training loss: 1.2009092569351196
Validation loss: 2.078600242573728

Epoch: 6| Step: 3
Training loss: 0.715279221534729
Validation loss: 2.04981723267545

Epoch: 6| Step: 4
Training loss: 0.8394413590431213
Validation loss: 2.0604868755545667

Epoch: 6| Step: 5
Training loss: 1.3456922769546509
Validation loss: 2.0396949039992465

Epoch: 6| Step: 6
Training loss: 0.8369581699371338
Validation loss: 2.044305342499928

Epoch: 6| Step: 7
Training loss: 1.1999236345291138
Validation loss: 2.078567240827827

Epoch: 6| Step: 8
Training loss: 1.2049460411071777
Validation loss: 2.0430927699612034

Epoch: 6| Step: 9
Training loss: 0.8214245438575745
Validation loss: 2.025402097291844

Epoch: 6| Step: 10
Training loss: 1.195831537246704
Validation loss: 2.0861416119401173

Epoch: 6| Step: 11
Training loss: 1.0911753177642822
Validation loss: 2.023389870120633

Epoch: 6| Step: 12
Training loss: 1.0033010244369507
Validation loss: 2.0552284640650593

Epoch: 6| Step: 13
Training loss: 0.8451971411705017
Validation loss: 2.071415660201862

Epoch: 614| Step: 0
Training loss: 0.8410958051681519
Validation loss: 2.054877576007638

Epoch: 6| Step: 1
Training loss: 1.343735694885254
Validation loss: 2.032833827439175

Epoch: 6| Step: 2
Training loss: 0.735812783241272
Validation loss: 2.064938881063974

Epoch: 6| Step: 3
Training loss: 1.1639796495437622
Validation loss: 2.0778674771708827

Epoch: 6| Step: 4
Training loss: 1.1040875911712646
Validation loss: 2.046480396742462

Epoch: 6| Step: 5
Training loss: 1.1181082725524902
Validation loss: 2.0598869362185077

Epoch: 6| Step: 6
Training loss: 1.0817787647247314
Validation loss: 2.0788501744629233

Epoch: 6| Step: 7
Training loss: 0.8814070820808411
Validation loss: 2.059634162533668

Epoch: 6| Step: 8
Training loss: 1.021155595779419
Validation loss: 2.070545640043033

Epoch: 6| Step: 9
Training loss: 1.2245268821716309
Validation loss: 2.0544672140511135

Epoch: 6| Step: 10
Training loss: 1.0371613502502441
Validation loss: 2.0529125480241674

Epoch: 6| Step: 11
Training loss: 1.160784125328064
Validation loss: 2.0687657158861876

Epoch: 6| Step: 12
Training loss: 1.4903621673583984
Validation loss: 2.110104209633284

Epoch: 6| Step: 13
Training loss: 1.0834795236587524
Validation loss: 2.080515702565511

Epoch: 615| Step: 0
Training loss: 0.831477165222168
Validation loss: 2.1225623648653746

Epoch: 6| Step: 1
Training loss: 1.221736192703247
Validation loss: 2.036536357736075

Epoch: 6| Step: 2
Training loss: 1.1399974822998047
Validation loss: 2.090735850795623

Epoch: 6| Step: 3
Training loss: 0.7566536068916321
Validation loss: 2.0756807711816605

Epoch: 6| Step: 4
Training loss: 1.4087531566619873
Validation loss: 2.100030024846395

Epoch: 6| Step: 5
Training loss: 0.6336317658424377
Validation loss: 2.062594644484981

Epoch: 6| Step: 6
Training loss: 1.4298921823501587
Validation loss: 2.014964783063499

Epoch: 6| Step: 7
Training loss: 0.8015480637550354
Validation loss: 2.0698224344561176

Epoch: 6| Step: 8
Training loss: 1.5505331754684448
Validation loss: 2.0681257683743715

Epoch: 6| Step: 9
Training loss: 1.1914606094360352
Validation loss: 2.0882561591363724

Epoch: 6| Step: 10
Training loss: 1.0845410823822021
Validation loss: 2.067066639982244

Epoch: 6| Step: 11
Training loss: 0.9697867631912231
Validation loss: 2.036586125691732

Epoch: 6| Step: 12
Training loss: 1.1791216135025024
Validation loss: 2.0655285158464984

Epoch: 6| Step: 13
Training loss: 1.3182568550109863
Validation loss: 2.0457543326962377

Epoch: 616| Step: 0
Training loss: 1.3384482860565186
Validation loss: 2.020569360384377

Epoch: 6| Step: 1
Training loss: 1.0149016380310059
Validation loss: 2.0432380809578845

Epoch: 6| Step: 2
Training loss: 1.9078857898712158
Validation loss: 2.0277087534627607

Epoch: 6| Step: 3
Training loss: 1.291729211807251
Validation loss: 2.082035828662175

Epoch: 6| Step: 4
Training loss: 0.4592829942703247
Validation loss: 2.060481987973695

Epoch: 6| Step: 5
Training loss: 1.014204740524292
Validation loss: 2.0564342262924358

Epoch: 6| Step: 6
Training loss: 1.0399844646453857
Validation loss: 2.0792159047178043

Epoch: 6| Step: 7
Training loss: 0.853168249130249
Validation loss: 2.079098547658613

Epoch: 6| Step: 8
Training loss: 1.1971549987792969
Validation loss: 2.066188462318913

Epoch: 6| Step: 9
Training loss: 1.3271234035491943
Validation loss: 2.0820286658502396

Epoch: 6| Step: 10
Training loss: 0.7996371388435364
Validation loss: 2.0441132078888598

Epoch: 6| Step: 11
Training loss: 1.0012760162353516
Validation loss: 2.087125419288553

Epoch: 6| Step: 12
Training loss: 1.1565190553665161
Validation loss: 2.084461255740094

Epoch: 6| Step: 13
Training loss: 1.080169677734375
Validation loss: 2.1078574631803777

Epoch: 617| Step: 0
Training loss: 1.740389347076416
Validation loss: 2.0379473086326354

Epoch: 6| Step: 1
Training loss: 1.305847406387329
Validation loss: 2.0607126169307257

Epoch: 6| Step: 2
Training loss: 0.8419907093048096
Validation loss: 2.0718554450619604

Epoch: 6| Step: 3
Training loss: 1.2792332172393799
Validation loss: 2.0689491994919313

Epoch: 6| Step: 4
Training loss: 0.8685370087623596
Validation loss: 2.04549337715231

Epoch: 6| Step: 5
Training loss: 1.6994731426239014
Validation loss: 2.104566231850655

Epoch: 6| Step: 6
Training loss: 0.8448348045349121
Validation loss: 2.0531214360267884

Epoch: 6| Step: 7
Training loss: 1.841230034828186
Validation loss: 2.1164569162553355

Epoch: 6| Step: 8
Training loss: 0.7136638164520264
Validation loss: 2.0372413845472437

Epoch: 6| Step: 9
Training loss: 0.8548717498779297
Validation loss: 2.031730305763983

Epoch: 6| Step: 10
Training loss: 0.990105152130127
Validation loss: 2.045668410998519

Epoch: 6| Step: 11
Training loss: 0.6173685789108276
Validation loss: 2.0455461266220256

Epoch: 6| Step: 12
Training loss: 0.768860399723053
Validation loss: 2.0562862311640093

Epoch: 6| Step: 13
Training loss: 0.9418475031852722
Validation loss: 2.0105107522779897

Epoch: 618| Step: 0
Training loss: 0.6536445021629333
Validation loss: 2.0440316354074786

Epoch: 6| Step: 1
Training loss: 0.7724246382713318
Validation loss: 2.0662082805428454

Epoch: 6| Step: 2
Training loss: 1.182306170463562
Validation loss: 2.043443101708607

Epoch: 6| Step: 3
Training loss: 0.6014323830604553
Validation loss: 2.119597265797277

Epoch: 6| Step: 4
Training loss: 0.7845016717910767
Validation loss: 2.0828643973155687

Epoch: 6| Step: 5
Training loss: 1.1595228910446167
Validation loss: 2.0578375606126684

Epoch: 6| Step: 6
Training loss: 1.4873852729797363
Validation loss: 2.0520001765220397

Epoch: 6| Step: 7
Training loss: 1.2077975273132324
Validation loss: 2.0603330237891084

Epoch: 6| Step: 8
Training loss: 0.39999547600746155
Validation loss: 2.0727841956641084

Epoch: 6| Step: 9
Training loss: 0.9854280948638916
Validation loss: 2.0375648031952562

Epoch: 6| Step: 10
Training loss: 0.9986623525619507
Validation loss: 2.0151775113997923

Epoch: 6| Step: 11
Training loss: 1.4656996726989746
Validation loss: 2.041067769450526

Epoch: 6| Step: 12
Training loss: 1.9526535272598267
Validation loss: 2.0729495915033485

Epoch: 6| Step: 13
Training loss: 1.3413528203964233
Validation loss: 2.0499172877239924

Epoch: 619| Step: 0
Training loss: 1.2424554824829102
Validation loss: 2.0533598084603586

Epoch: 6| Step: 1
Training loss: 1.1098061800003052
Validation loss: 2.0398224041026127

Epoch: 6| Step: 2
Training loss: 1.384852647781372
Validation loss: 2.078497535438948

Epoch: 6| Step: 3
Training loss: 1.1561602354049683
Validation loss: 2.0510088653974634

Epoch: 6| Step: 4
Training loss: 1.1683249473571777
Validation loss: 2.0227357469579226

Epoch: 6| Step: 5
Training loss: 1.0695908069610596
Validation loss: 2.0915009719069286

Epoch: 6| Step: 6
Training loss: 0.9948874115943909
Validation loss: 2.044671994383617

Epoch: 6| Step: 7
Training loss: 0.8538062572479248
Validation loss: 2.029641761574694

Epoch: 6| Step: 8
Training loss: 1.2537511587142944
Validation loss: 2.0706156761415544

Epoch: 6| Step: 9
Training loss: 0.7375965118408203
Validation loss: 2.038811050435548

Epoch: 6| Step: 10
Training loss: 1.2149475812911987
Validation loss: 2.044172369023805

Epoch: 6| Step: 11
Training loss: 0.6965864300727844
Validation loss: 2.0786959560968543

Epoch: 6| Step: 12
Training loss: 1.3971883058547974
Validation loss: 2.0321784429652716

Epoch: 6| Step: 13
Training loss: 0.7626278400421143
Validation loss: 2.0775069011154996

Epoch: 620| Step: 0
Training loss: 1.1179594993591309
Validation loss: 2.096783330363612

Epoch: 6| Step: 1
Training loss: 1.194580078125
Validation loss: 2.0945567443806636

Epoch: 6| Step: 2
Training loss: 1.0332967042922974
Validation loss: 2.084612656665105

Epoch: 6| Step: 3
Training loss: 1.0345032215118408
Validation loss: 2.066756095937503

Epoch: 6| Step: 4
Training loss: 1.0286362171173096
Validation loss: 2.11116180112285

Epoch: 6| Step: 5
Training loss: 0.790166974067688
Validation loss: 2.12316216704666

Epoch: 6| Step: 6
Training loss: 0.9849053621292114
Validation loss: 2.0638930028484714

Epoch: 6| Step: 7
Training loss: 1.1222286224365234
Validation loss: 2.0685414857761835

Epoch: 6| Step: 8
Training loss: 1.2229293584823608
Validation loss: 2.033607065036733

Epoch: 6| Step: 9
Training loss: 0.7433416843414307
Validation loss: 2.0582859977599113

Epoch: 6| Step: 10
Training loss: 1.2375054359436035
Validation loss: 2.1035425893722044

Epoch: 6| Step: 11
Training loss: 1.5971527099609375
Validation loss: 2.062669623282648

Epoch: 6| Step: 12
Training loss: 1.4285812377929688
Validation loss: 2.0992423513884186

Epoch: 6| Step: 13
Training loss: 0.8030287027359009
Validation loss: 2.0818423865943827

Epoch: 621| Step: 0
Training loss: 1.1220784187316895
Validation loss: 2.0595619934861378

Epoch: 6| Step: 1
Training loss: 0.765705943107605
Validation loss: 2.0354205177676294

Epoch: 6| Step: 2
Training loss: 1.381526231765747
Validation loss: 2.066252782780637

Epoch: 6| Step: 3
Training loss: 0.9822508692741394
Validation loss: 2.052482416552882

Epoch: 6| Step: 4
Training loss: 1.170539379119873
Validation loss: 2.0552836733479656

Epoch: 6| Step: 5
Training loss: 1.3733749389648438
Validation loss: 2.086036633419734

Epoch: 6| Step: 6
Training loss: 0.819006621837616
Validation loss: 2.0572197668014036

Epoch: 6| Step: 7
Training loss: 0.8935803771018982
Validation loss: 2.0635826228767313

Epoch: 6| Step: 8
Training loss: 1.1395621299743652
Validation loss: 2.0670664131000476

Epoch: 6| Step: 9
Training loss: 1.6513350009918213
Validation loss: 2.003826064448203

Epoch: 6| Step: 10
Training loss: 1.2548730373382568
Validation loss: 2.101152993017627

Epoch: 6| Step: 11
Training loss: 1.0129618644714355
Validation loss: 2.0620125724423315

Epoch: 6| Step: 12
Training loss: 0.832169771194458
Validation loss: 1.9969947645741124

Epoch: 6| Step: 13
Training loss: 0.9302165508270264
Validation loss: 2.0772239597894813

Epoch: 622| Step: 0
Training loss: 0.7151671648025513
Validation loss: 2.040402521369278

Epoch: 6| Step: 1
Training loss: 1.1566599607467651
Validation loss: 2.061399095801897

Epoch: 6| Step: 2
Training loss: 1.112401008605957
Validation loss: 2.0958247287299043

Epoch: 6| Step: 3
Training loss: 0.7440283894538879
Validation loss: 2.0029412623374694

Epoch: 6| Step: 4
Training loss: 1.3284862041473389
Validation loss: 2.025783209390538

Epoch: 6| Step: 5
Training loss: 0.7454015016555786
Validation loss: 2.018990367971441

Epoch: 6| Step: 6
Training loss: 0.7855216860771179
Validation loss: 2.032055227987228

Epoch: 6| Step: 7
Training loss: 1.5222628116607666
Validation loss: 2.0461606082095893

Epoch: 6| Step: 8
Training loss: 1.0369318723678589
Validation loss: 2.0876437707613875

Epoch: 6| Step: 9
Training loss: 1.8996104001998901
Validation loss: 2.1009076385087866

Epoch: 6| Step: 10
Training loss: 0.802147626876831
Validation loss: 2.101268446573647

Epoch: 6| Step: 11
Training loss: 1.084099292755127
Validation loss: 2.025641128581057

Epoch: 6| Step: 12
Training loss: 0.9474693536758423
Validation loss: 2.0701387390013664

Epoch: 6| Step: 13
Training loss: 1.3925966024398804
Validation loss: 2.0638882754951395

Epoch: 623| Step: 0
Training loss: 0.9094457626342773
Validation loss: 2.0471282684674827

Epoch: 6| Step: 1
Training loss: 1.176906704902649
Validation loss: 2.047054494580915

Epoch: 6| Step: 2
Training loss: 0.9248509407043457
Validation loss: 2.0277784896153275

Epoch: 6| Step: 3
Training loss: 1.085302710533142
Validation loss: 2.091278221017571

Epoch: 6| Step: 4
Training loss: 1.6975529193878174
Validation loss: 2.0969211004113637

Epoch: 6| Step: 5
Training loss: 0.9955219030380249
Validation loss: 2.058802984094107

Epoch: 6| Step: 6
Training loss: 1.4222314357757568
Validation loss: 2.040741560279682

Epoch: 6| Step: 7
Training loss: 0.680993914604187
Validation loss: 2.0544094962458455

Epoch: 6| Step: 8
Training loss: 0.884436309337616
Validation loss: 2.0642703810045795

Epoch: 6| Step: 9
Training loss: 1.1010150909423828
Validation loss: 2.0516838386494625

Epoch: 6| Step: 10
Training loss: 1.0237932205200195
Validation loss: 2.0766659603323987

Epoch: 6| Step: 11
Training loss: 1.3311834335327148
Validation loss: 2.005927029476371

Epoch: 6| Step: 12
Training loss: 1.0894248485565186
Validation loss: 2.0575924740042737

Epoch: 6| Step: 13
Training loss: 0.6020819544792175
Validation loss: 2.081352100577406

Epoch: 624| Step: 0
Training loss: 1.0594902038574219
Validation loss: 2.0877197429698002

Epoch: 6| Step: 1
Training loss: 0.8256500363349915
Validation loss: 2.075873456975465

Epoch: 6| Step: 2
Training loss: 1.5350699424743652
Validation loss: 2.041048857473558

Epoch: 6| Step: 3
Training loss: 0.9386849403381348
Validation loss: 2.027250878272518

Epoch: 6| Step: 4
Training loss: 0.9291516542434692
Validation loss: 2.0723346125695015

Epoch: 6| Step: 5
Training loss: 1.5397388935089111
Validation loss: 2.007382881256842

Epoch: 6| Step: 6
Training loss: 0.8026769161224365
Validation loss: 2.022728850764613

Epoch: 6| Step: 7
Training loss: 1.1360059976577759
Validation loss: 2.0430506275546167

Epoch: 6| Step: 8
Training loss: 0.6985838413238525
Validation loss: 2.0464795353592082

Epoch: 6| Step: 9
Training loss: 0.8704881072044373
Validation loss: 2.07122068507697

Epoch: 6| Step: 10
Training loss: 0.8502673506736755
Validation loss: 2.0260115438891995

Epoch: 6| Step: 11
Training loss: 1.5665833950042725
Validation loss: 2.0873524937578427

Epoch: 6| Step: 12
Training loss: 0.9172481298446655
Validation loss: 2.051009073052355

Epoch: 6| Step: 13
Training loss: 1.491066575050354
Validation loss: 2.0425202513253815

Epoch: 625| Step: 0
Training loss: 1.0893651247024536
Validation loss: 2.000243451005669

Epoch: 6| Step: 1
Training loss: 1.0980995893478394
Validation loss: 2.057482942458122

Epoch: 6| Step: 2
Training loss: 0.8694313764572144
Validation loss: 2.078766511332604

Epoch: 6| Step: 3
Training loss: 1.2988290786743164
Validation loss: 2.09757040649332

Epoch: 6| Step: 4
Training loss: 1.3325319290161133
Validation loss: 2.0673177203824444

Epoch: 6| Step: 5
Training loss: 1.0017904043197632
Validation loss: 2.115784829662692

Epoch: 6| Step: 6
Training loss: 0.8094415664672852
Validation loss: 2.1240774431536273

Epoch: 6| Step: 7
Training loss: 0.8408471345901489
Validation loss: 2.072907732379052

Epoch: 6| Step: 8
Training loss: 1.0156004428863525
Validation loss: 2.089938163757324

Epoch: 6| Step: 9
Training loss: 1.3836047649383545
Validation loss: 2.1009520330736713

Epoch: 6| Step: 10
Training loss: 0.7757857441902161
Validation loss: 2.061334470266937

Epoch: 6| Step: 11
Training loss: 0.5545800924301147
Validation loss: 2.0307022884327877

Epoch: 6| Step: 12
Training loss: 1.5557280778884888
Validation loss: 2.0768751405900523

Epoch: 6| Step: 13
Training loss: 1.6889325380325317
Validation loss: 2.0445029658655964

Epoch: 626| Step: 0
Training loss: 0.7261503338813782
Validation loss: 2.036227448012239

Epoch: 6| Step: 1
Training loss: 1.364256501197815
Validation loss: 2.0676940141185636

Epoch: 6| Step: 2
Training loss: 0.9624016880989075
Validation loss: 1.993601022228118

Epoch: 6| Step: 3
Training loss: 1.5929899215698242
Validation loss: 2.0913935963825514

Epoch: 6| Step: 4
Training loss: 1.0105037689208984
Validation loss: 2.045418308627221

Epoch: 6| Step: 5
Training loss: 0.7126764059066772
Validation loss: 2.051632992682918

Epoch: 6| Step: 6
Training loss: 1.421304702758789
Validation loss: 2.062849816455636

Epoch: 6| Step: 7
Training loss: 0.9833448529243469
Validation loss: 2.079822746656274

Epoch: 6| Step: 8
Training loss: 0.9808640480041504
Validation loss: 2.0628303186867827

Epoch: 6| Step: 9
Training loss: 1.4142420291900635
Validation loss: 2.064110776429535

Epoch: 6| Step: 10
Training loss: 1.126402735710144
Validation loss: 2.0620315920922065

Epoch: 6| Step: 11
Training loss: 1.321390151977539
Validation loss: 2.0353974424382693

Epoch: 6| Step: 12
Training loss: 0.9859756231307983
Validation loss: 2.0136223352083595

Epoch: 6| Step: 13
Training loss: 0.9613282084465027
Validation loss: 2.047222464315353

Epoch: 627| Step: 0
Training loss: 0.7591708898544312
Validation loss: 2.1006385228967153

Epoch: 6| Step: 1
Training loss: 1.1745092868804932
Validation loss: 2.0615972985503492

Epoch: 6| Step: 2
Training loss: 1.268243670463562
Validation loss: 2.0524314808589157

Epoch: 6| Step: 3
Training loss: 1.7078733444213867
Validation loss: 2.0682075523561045

Epoch: 6| Step: 4
Training loss: 1.1420825719833374
Validation loss: 1.9911870571874803

Epoch: 6| Step: 5
Training loss: 1.2490103244781494
Validation loss: 2.0659112981570664

Epoch: 6| Step: 6
Training loss: 1.0482401847839355
Validation loss: 2.087062819029695

Epoch: 6| Step: 7
Training loss: 1.0127159357070923
Validation loss: 2.0386340131041822

Epoch: 6| Step: 8
Training loss: 1.2013061046600342
Validation loss: 2.0831651149257535

Epoch: 6| Step: 9
Training loss: 0.8354306221008301
Validation loss: 2.0285327114084715

Epoch: 6| Step: 10
Training loss: 1.1232614517211914
Validation loss: 2.0579706212525726

Epoch: 6| Step: 11
Training loss: 0.5643718242645264
Validation loss: 2.0384778591894333

Epoch: 6| Step: 12
Training loss: 1.2210320234298706
Validation loss: 2.0570473568413847

Epoch: 6| Step: 13
Training loss: 1.1083959341049194
Validation loss: 2.051113161989438

Epoch: 628| Step: 0
Training loss: 1.1127724647521973
Validation loss: 2.050015930206545

Epoch: 6| Step: 1
Training loss: 0.8139952421188354
Validation loss: 2.0374627677343224

Epoch: 6| Step: 2
Training loss: 0.8853283524513245
Validation loss: 2.106263199160176

Epoch: 6| Step: 3
Training loss: 1.5791250467300415
Validation loss: 2.0823443461489934

Epoch: 6| Step: 4
Training loss: 1.3884259462356567
Validation loss: 2.140777508417765

Epoch: 6| Step: 5
Training loss: 1.291534185409546
Validation loss: 2.0685154981510614

Epoch: 6| Step: 6
Training loss: 0.32745957374572754
Validation loss: 2.0659256955628753

Epoch: 6| Step: 7
Training loss: 0.7556033134460449
Validation loss: 2.07044235608911

Epoch: 6| Step: 8
Training loss: 0.7061249017715454
Validation loss: 2.0924264461763444

Epoch: 6| Step: 9
Training loss: 1.647182822227478
Validation loss: 2.052546557559762

Epoch: 6| Step: 10
Training loss: 1.2024496793746948
Validation loss: 2.107753534470835

Epoch: 6| Step: 11
Training loss: 1.0965375900268555
Validation loss: 2.056027335505332

Epoch: 6| Step: 12
Training loss: 1.0221035480499268
Validation loss: 2.0827333017062117

Epoch: 6| Step: 13
Training loss: 1.4759488105773926
Validation loss: 2.0786831891664894

Epoch: 629| Step: 0
Training loss: 0.9484960436820984
Validation loss: 1.9866482314243112

Epoch: 6| Step: 1
Training loss: 1.402951717376709
Validation loss: 1.9877783277983307

Epoch: 6| Step: 2
Training loss: 1.2651698589324951
Validation loss: 2.0993717434585735

Epoch: 6| Step: 3
Training loss: 0.8233298063278198
Validation loss: 2.0502013416700464

Epoch: 6| Step: 4
Training loss: 0.9827014207839966
Validation loss: 2.047766072775728

Epoch: 6| Step: 5
Training loss: 0.848576545715332
Validation loss: 2.0489214415191324

Epoch: 6| Step: 6
Training loss: 1.16996169090271
Validation loss: 2.0558265306616343

Epoch: 6| Step: 7
Training loss: 0.8704518675804138
Validation loss: 2.0720681798073555

Epoch: 6| Step: 8
Training loss: 0.8411804437637329
Validation loss: 2.0406464556212067

Epoch: 6| Step: 9
Training loss: 1.3410392999649048
Validation loss: 2.0745864888673187

Epoch: 6| Step: 10
Training loss: 0.4137100279331207
Validation loss: 2.0626338399866575

Epoch: 6| Step: 11
Training loss: 1.736306071281433
Validation loss: 2.024764745466171

Epoch: 6| Step: 12
Training loss: 1.024753451347351
Validation loss: 2.0553393927953576

Epoch: 6| Step: 13
Training loss: 1.1575275659561157
Validation loss: 2.0132537247032247

Epoch: 630| Step: 0
Training loss: 0.9173032641410828
Validation loss: 2.034275849660238

Epoch: 6| Step: 1
Training loss: 1.4691613912582397
Validation loss: 2.0674969509083736

Epoch: 6| Step: 2
Training loss: 0.6284180879592896
Validation loss: 2.0576465719489643

Epoch: 6| Step: 3
Training loss: 1.0109965801239014
Validation loss: 2.068184562908706

Epoch: 6| Step: 4
Training loss: 1.007968783378601
Validation loss: 2.0762581184346187

Epoch: 6| Step: 5
Training loss: 1.6801148653030396
Validation loss: 2.0755778487010668

Epoch: 6| Step: 6
Training loss: 1.3480746746063232
Validation loss: 2.0463582956662743

Epoch: 6| Step: 7
Training loss: 1.0119385719299316
Validation loss: 2.054242044366816

Epoch: 6| Step: 8
Training loss: 0.9778225421905518
Validation loss: 2.0863535737478607

Epoch: 6| Step: 9
Training loss: 1.0931378602981567
Validation loss: 2.078178472416375

Epoch: 6| Step: 10
Training loss: 1.2652219533920288
Validation loss: 2.0416382333283782

Epoch: 6| Step: 11
Training loss: 1.01511812210083
Validation loss: 2.0694919606690765

Epoch: 6| Step: 12
Training loss: 0.4578871726989746
Validation loss: 1.9957861874693184

Epoch: 6| Step: 13
Training loss: 0.729478657245636
Validation loss: 2.0508703493302867

Epoch: 631| Step: 0
Training loss: 1.2953611612319946
Validation loss: 2.0365277515944613

Epoch: 6| Step: 1
Training loss: 0.5582091808319092
Validation loss: 2.076084827864042

Epoch: 6| Step: 2
Training loss: 0.927376389503479
Validation loss: 2.05840402777477

Epoch: 6| Step: 3
Training loss: 1.0293159484863281
Validation loss: 2.04661282672677

Epoch: 6| Step: 4
Training loss: 1.1325011253356934
Validation loss: 2.042548123226371

Epoch: 6| Step: 5
Training loss: 1.333270788192749
Validation loss: 2.0843639040506012

Epoch: 6| Step: 6
Training loss: 1.7096714973449707
Validation loss: 2.0360710133788404

Epoch: 6| Step: 7
Training loss: 0.808654248714447
Validation loss: 2.0203637051325973

Epoch: 6| Step: 8
Training loss: 0.6492394804954529
Validation loss: 2.0181412722474787

Epoch: 6| Step: 9
Training loss: 1.532227873802185
Validation loss: 2.0576868441797074

Epoch: 6| Step: 10
Training loss: 1.0303044319152832
Validation loss: 2.0321199522223523

Epoch: 6| Step: 11
Training loss: 0.6218904852867126
Validation loss: 2.0195546047661894

Epoch: 6| Step: 12
Training loss: 0.9319573640823364
Validation loss: 2.030428132703227

Epoch: 6| Step: 13
Training loss: 1.2879078388214111
Validation loss: 2.045205480308943

Epoch: 632| Step: 0
Training loss: 0.8507794141769409
Validation loss: 2.0610647432265745

Epoch: 6| Step: 1
Training loss: 0.5572044253349304
Validation loss: 2.030475857437298

Epoch: 6| Step: 2
Training loss: 0.8837025165557861
Validation loss: 2.0447576392081475

Epoch: 6| Step: 3
Training loss: 1.2875970602035522
Validation loss: 2.0401836569591234

Epoch: 6| Step: 4
Training loss: 1.3752131462097168
Validation loss: 1.987564807297081

Epoch: 6| Step: 5
Training loss: 1.5978323221206665
Validation loss: 2.040395047075005

Epoch: 6| Step: 6
Training loss: 1.02632737159729
Validation loss: 2.051801759709594

Epoch: 6| Step: 7
Training loss: 1.3983268737792969
Validation loss: 2.014107850290114

Epoch: 6| Step: 8
Training loss: 1.0079573392868042
Validation loss: 2.0798712674007622

Epoch: 6| Step: 9
Training loss: 0.9242580533027649
Validation loss: 2.0359721581141152

Epoch: 6| Step: 10
Training loss: 1.452085018157959
Validation loss: 2.079077443768901

Epoch: 6| Step: 11
Training loss: 1.137533187866211
Validation loss: 2.0503446132906022

Epoch: 6| Step: 12
Training loss: 0.8855754733085632
Validation loss: 2.058680920190709

Epoch: 6| Step: 13
Training loss: 0.33797091245651245
Validation loss: 2.081942104524182

Epoch: 633| Step: 0
Training loss: 1.4026753902435303
Validation loss: 2.0769739868820354

Epoch: 6| Step: 1
Training loss: 1.4930431842803955
Validation loss: 2.041831539523217

Epoch: 6| Step: 2
Training loss: 0.9882506132125854
Validation loss: 2.0172912100309968

Epoch: 6| Step: 3
Training loss: 1.2383464574813843
Validation loss: 2.0582156976064048

Epoch: 6| Step: 4
Training loss: 0.822462260723114
Validation loss: 2.0759399603771906

Epoch: 6| Step: 5
Training loss: 1.1097925901412964
Validation loss: 2.0993976105925856

Epoch: 6| Step: 6
Training loss: 0.5248380899429321
Validation loss: 2.0198738241708405

Epoch: 6| Step: 7
Training loss: 1.3688580989837646
Validation loss: 2.0585147052682857

Epoch: 6| Step: 8
Training loss: 0.7253010272979736
Validation loss: 2.053490497732675

Epoch: 6| Step: 9
Training loss: 0.6820575594902039
Validation loss: 2.090660184942266

Epoch: 6| Step: 10
Training loss: 1.3643476963043213
Validation loss: 2.011844301736483

Epoch: 6| Step: 11
Training loss: 1.078676462173462
Validation loss: 2.059852255287991

Epoch: 6| Step: 12
Training loss: 1.2407889366149902
Validation loss: 2.073427813027495

Epoch: 6| Step: 13
Training loss: 0.5465245842933655
Validation loss: 2.083819527779856

Epoch: 634| Step: 0
Training loss: 1.025534987449646
Validation loss: 2.106873007230861

Epoch: 6| Step: 1
Training loss: 0.9565401673316956
Validation loss: 2.0953955701602403

Epoch: 6| Step: 2
Training loss: 0.5904800891876221
Validation loss: 2.0689123163941088

Epoch: 6| Step: 3
Training loss: 0.9625623822212219
Validation loss: 2.1063869255845264

Epoch: 6| Step: 4
Training loss: 1.1686666011810303
Validation loss: 2.0397404201569094

Epoch: 6| Step: 5
Training loss: 1.1143074035644531
Validation loss: 2.0833040386117916

Epoch: 6| Step: 6
Training loss: 1.5256330966949463
Validation loss: 2.0883653920183898

Epoch: 6| Step: 7
Training loss: 1.5094631910324097
Validation loss: 2.0656209607278146

Epoch: 6| Step: 8
Training loss: 1.0582717657089233
Validation loss: 2.091036637624105

Epoch: 6| Step: 9
Training loss: 0.6778008937835693
Validation loss: 2.0674777325763496

Epoch: 6| Step: 10
Training loss: 0.9858301877975464
Validation loss: 2.0764255574954453

Epoch: 6| Step: 11
Training loss: 1.4049055576324463
Validation loss: 2.069623020387465

Epoch: 6| Step: 12
Training loss: 0.5607755184173584
Validation loss: 2.046962235563545

Epoch: 6| Step: 13
Training loss: 1.114391803741455
Validation loss: 2.0420038520648913

Epoch: 635| Step: 0
Training loss: 0.670513391494751
Validation loss: 2.0104683881164878

Epoch: 6| Step: 1
Training loss: 0.7170993685722351
Validation loss: 2.063158622352026

Epoch: 6| Step: 2
Training loss: 0.5001733303070068
Validation loss: 2.044274796721756

Epoch: 6| Step: 3
Training loss: 1.4765735864639282
Validation loss: 2.0397441617904173

Epoch: 6| Step: 4
Training loss: 1.3214631080627441
Validation loss: 2.040603745368219

Epoch: 6| Step: 5
Training loss: 1.2210874557495117
Validation loss: 2.0078365354127783

Epoch: 6| Step: 6
Training loss: 1.160706639289856
Validation loss: 2.0315832912280993

Epoch: 6| Step: 7
Training loss: 0.8609721660614014
Validation loss: 2.0824992413161905

Epoch: 6| Step: 8
Training loss: 1.3144605159759521
Validation loss: 2.0767535060964604

Epoch: 6| Step: 9
Training loss: 1.0565807819366455
Validation loss: 2.0566822995421705

Epoch: 6| Step: 10
Training loss: 0.9928321838378906
Validation loss: 2.043182098737327

Epoch: 6| Step: 11
Training loss: 1.455965280532837
Validation loss: 2.08772301032979

Epoch: 6| Step: 12
Training loss: 1.2091805934906006
Validation loss: 2.072223283911264

Epoch: 6| Step: 13
Training loss: 0.7614974975585938
Validation loss: 2.045406424871055

Epoch: 636| Step: 0
Training loss: 0.9307307004928589
Validation loss: 2.0582582822410007

Epoch: 6| Step: 1
Training loss: 1.3798539638519287
Validation loss: 2.0512812265785794

Epoch: 6| Step: 2
Training loss: 0.8238492012023926
Validation loss: 2.0348510434550624

Epoch: 6| Step: 3
Training loss: 1.5480248928070068
Validation loss: 2.0224752080055977

Epoch: 6| Step: 4
Training loss: 0.8765779733657837
Validation loss: 2.072584403458462

Epoch: 6| Step: 5
Training loss: 0.8787254691123962
Validation loss: 2.0294531314603743

Epoch: 6| Step: 6
Training loss: 1.1445801258087158
Validation loss: 2.0429388682047525

Epoch: 6| Step: 7
Training loss: 1.0032662153244019
Validation loss: 2.027506738580683

Epoch: 6| Step: 8
Training loss: 1.2832975387573242
Validation loss: 2.009712710175463

Epoch: 6| Step: 9
Training loss: 0.9008281826972961
Validation loss: 2.0271874038122033

Epoch: 6| Step: 10
Training loss: 0.7527703046798706
Validation loss: 2.042885632925136

Epoch: 6| Step: 11
Training loss: 1.1467161178588867
Validation loss: 2.0367133181582213

Epoch: 6| Step: 12
Training loss: 1.207788348197937
Validation loss: 2.0420292961981987

Epoch: 6| Step: 13
Training loss: 1.0621371269226074
Validation loss: 2.0675042265204975

Epoch: 637| Step: 0
Training loss: 1.1018275022506714
Validation loss: 2.030672828356425

Epoch: 6| Step: 1
Training loss: 1.0282751321792603
Validation loss: 2.0478448624251993

Epoch: 6| Step: 2
Training loss: 1.0607924461364746
Validation loss: 2.081786233891723

Epoch: 6| Step: 3
Training loss: 1.6356583833694458
Validation loss: 2.058822831799907

Epoch: 6| Step: 4
Training loss: 1.5954396724700928
Validation loss: 2.078302547495852

Epoch: 6| Step: 5
Training loss: 0.6824955940246582
Validation loss: 2.084121742556172

Epoch: 6| Step: 6
Training loss: 0.9909912347793579
Validation loss: 2.0778373146569855

Epoch: 6| Step: 7
Training loss: 1.043601632118225
Validation loss: 2.048864799161111

Epoch: 6| Step: 8
Training loss: 1.0182135105133057
Validation loss: 2.0422154139446955

Epoch: 6| Step: 9
Training loss: 1.038791298866272
Validation loss: 2.024652883570681

Epoch: 6| Step: 10
Training loss: 0.7720369696617126
Validation loss: 2.0159462010988625

Epoch: 6| Step: 11
Training loss: 1.111482858657837
Validation loss: 2.0546649886715795

Epoch: 6| Step: 12
Training loss: 0.8371909856796265
Validation loss: 1.9659940888804774

Epoch: 6| Step: 13
Training loss: 1.0491068363189697
Validation loss: 2.0307031908342914

Epoch: 638| Step: 0
Training loss: 1.1095120906829834
Validation loss: 2.020559313476727

Epoch: 6| Step: 1
Training loss: 1.1708619594573975
Validation loss: 2.0056377136579124

Epoch: 6| Step: 2
Training loss: 1.0217217206954956
Validation loss: 2.0407313403262886

Epoch: 6| Step: 3
Training loss: 0.9523986577987671
Validation loss: 2.0383205580455

Epoch: 6| Step: 4
Training loss: 0.6946772336959839
Validation loss: 1.9591857540992

Epoch: 6| Step: 5
Training loss: 1.371206521987915
Validation loss: 2.0069725269912393

Epoch: 6| Step: 6
Training loss: 0.8526685833930969
Validation loss: 2.0630294264003797

Epoch: 6| Step: 7
Training loss: 1.051069736480713
Validation loss: 2.0365088447447746

Epoch: 6| Step: 8
Training loss: 1.4927928447723389
Validation loss: 2.0483982691200833

Epoch: 6| Step: 9
Training loss: 1.2522976398468018
Validation loss: 2.093265264264999

Epoch: 6| Step: 10
Training loss: 0.7978286743164062
Validation loss: 2.0355824398738083

Epoch: 6| Step: 11
Training loss: 1.0945566892623901
Validation loss: 2.051675937509024

Epoch: 6| Step: 12
Training loss: 1.3511685132980347
Validation loss: 2.0666256309837423

Epoch: 6| Step: 13
Training loss: 0.5519824624061584
Validation loss: 2.0558717097005537

Epoch: 639| Step: 0
Training loss: 1.6152970790863037
Validation loss: 2.0823831686409573

Epoch: 6| Step: 1
Training loss: 0.6979754567146301
Validation loss: 2.069582716111214

Epoch: 6| Step: 2
Training loss: 0.9186732172966003
Validation loss: 2.04419768241144

Epoch: 6| Step: 3
Training loss: 1.3220863342285156
Validation loss: 2.036066448816689

Epoch: 6| Step: 4
Training loss: 1.22344172000885
Validation loss: 2.0191704662897254

Epoch: 6| Step: 5
Training loss: 0.8566367626190186
Validation loss: 2.0127275092627412

Epoch: 6| Step: 6
Training loss: 1.2230205535888672
Validation loss: 2.035628684105412

Epoch: 6| Step: 7
Training loss: 1.0314390659332275
Validation loss: 2.0629532708916614

Epoch: 6| Step: 8
Training loss: 0.77459716796875
Validation loss: 2.0754597161405828

Epoch: 6| Step: 9
Training loss: 0.9940922856330872
Validation loss: 2.054234786700177

Epoch: 6| Step: 10
Training loss: 1.3897883892059326
Validation loss: 2.045919692644509

Epoch: 6| Step: 11
Training loss: 0.7098357677459717
Validation loss: 2.0264234888938164

Epoch: 6| Step: 12
Training loss: 0.8660131692886353
Validation loss: 2.062348746484326

Epoch: 6| Step: 13
Training loss: 0.9152295589447021
Validation loss: 2.037902970467844

Epoch: 640| Step: 0
Training loss: 1.7349283695220947
Validation loss: 2.0779050947517477

Epoch: 6| Step: 1
Training loss: 1.125091314315796
Validation loss: 2.0548376101319508

Epoch: 6| Step: 2
Training loss: 0.7918504476547241
Validation loss: 2.0820638082360707

Epoch: 6| Step: 3
Training loss: 0.9383901357650757
Validation loss: 2.0472636863749516

Epoch: 6| Step: 4
Training loss: 1.4684851169586182
Validation loss: 2.0592540720457673

Epoch: 6| Step: 5
Training loss: 0.8235581517219543
Validation loss: 2.0798605385647027

Epoch: 6| Step: 6
Training loss: 0.7942161560058594
Validation loss: 2.093879324133678

Epoch: 6| Step: 7
Training loss: 0.5463560223579407
Validation loss: 2.0708757574840257

Epoch: 6| Step: 8
Training loss: 1.4222567081451416
Validation loss: 2.0504873362920617

Epoch: 6| Step: 9
Training loss: 0.7766897678375244
Validation loss: 2.0435732051890385

Epoch: 6| Step: 10
Training loss: 0.8287338018417358
Validation loss: 2.04543375456205

Epoch: 6| Step: 11
Training loss: 1.0517032146453857
Validation loss: 2.090219392571398

Epoch: 6| Step: 12
Training loss: 1.398186206817627
Validation loss: 1.991339183622791

Epoch: 6| Step: 13
Training loss: 0.9559614658355713
Validation loss: 2.0038291690170125

Epoch: 641| Step: 0
Training loss: 0.6807988882064819
Validation loss: 2.0616383450005644

Epoch: 6| Step: 1
Training loss: 0.8308359980583191
Validation loss: 2.036730489423198

Epoch: 6| Step: 2
Training loss: 1.3389261960983276
Validation loss: 2.0807416464692805

Epoch: 6| Step: 3
Training loss: 0.8005497455596924
Validation loss: 2.0501414934794107

Epoch: 6| Step: 4
Training loss: 0.954890787601471
Validation loss: 2.0097300224406744

Epoch: 6| Step: 5
Training loss: 1.1565474271774292
Validation loss: 2.0349485758812196

Epoch: 6| Step: 6
Training loss: 0.993162989616394
Validation loss: 2.034566884399742

Epoch: 6| Step: 7
Training loss: 0.7182525396347046
Validation loss: 2.0621293975460913

Epoch: 6| Step: 8
Training loss: 0.507902979850769
Validation loss: 2.0162440320496917

Epoch: 6| Step: 9
Training loss: 1.2406095266342163
Validation loss: 2.0656455793688373

Epoch: 6| Step: 10
Training loss: 1.2614375352859497
Validation loss: 2.0424842757563435

Epoch: 6| Step: 11
Training loss: 1.3548142910003662
Validation loss: 2.0886093467794438

Epoch: 6| Step: 12
Training loss: 1.7723506689071655
Validation loss: 2.011358981491417

Epoch: 6| Step: 13
Training loss: 1.479804277420044
Validation loss: 2.04350616598642

Epoch: 642| Step: 0
Training loss: 1.3393559455871582
Validation loss: 2.0501439135561705

Epoch: 6| Step: 1
Training loss: 0.4154748320579529
Validation loss: 2.0191007673099475

Epoch: 6| Step: 2
Training loss: 0.8124794960021973
Validation loss: 2.0529933309042327

Epoch: 6| Step: 3
Training loss: 1.2719736099243164
Validation loss: 2.058135376181654

Epoch: 6| Step: 4
Training loss: 0.7106826305389404
Validation loss: 2.1019825422635643

Epoch: 6| Step: 5
Training loss: 0.8073391914367676
Validation loss: 2.0498851601795485

Epoch: 6| Step: 6
Training loss: 0.7971264123916626
Validation loss: 2.0480486244283695

Epoch: 6| Step: 7
Training loss: 0.9002623558044434
Validation loss: 2.0729128378693775

Epoch: 6| Step: 8
Training loss: 1.8252558708190918
Validation loss: 2.052591554580196

Epoch: 6| Step: 9
Training loss: 0.8036836385726929
Validation loss: 2.0873565648191716

Epoch: 6| Step: 10
Training loss: 1.0532336235046387
Validation loss: 2.0060645918692313

Epoch: 6| Step: 11
Training loss: 1.2370752096176147
Validation loss: 2.022898312537901

Epoch: 6| Step: 12
Training loss: 1.6674704551696777
Validation loss: 2.0272455920455275

Epoch: 6| Step: 13
Training loss: 1.339417576789856
Validation loss: 2.0613947042854885

Epoch: 643| Step: 0
Training loss: 1.0206849575042725
Validation loss: 2.0693642298380532

Epoch: 6| Step: 1
Training loss: 1.345160722732544
Validation loss: 2.0634244975223335

Epoch: 6| Step: 2
Training loss: 1.511608362197876
Validation loss: 2.052899140183644

Epoch: 6| Step: 3
Training loss: 0.6747679710388184
Validation loss: 2.0320128240892963

Epoch: 6| Step: 4
Training loss: 1.1175673007965088
Validation loss: 2.057435676615725

Epoch: 6| Step: 5
Training loss: 1.4547977447509766
Validation loss: 2.0043461963694584

Epoch: 6| Step: 6
Training loss: 0.8429216146469116
Validation loss: 2.046977763534874

Epoch: 6| Step: 7
Training loss: 1.2622880935668945
Validation loss: 2.0189038450999925

Epoch: 6| Step: 8
Training loss: 1.0514044761657715
Validation loss: 2.0443855895791003

Epoch: 6| Step: 9
Training loss: 1.0566304922103882
Validation loss: 2.0726887461959675

Epoch: 6| Step: 10
Training loss: 1.0546109676361084
Validation loss: 2.0380802769814768

Epoch: 6| Step: 11
Training loss: 0.7990562915802002
Validation loss: 2.049070990213784

Epoch: 6| Step: 12
Training loss: 0.9151047468185425
Validation loss: 2.0868917037081975

Epoch: 6| Step: 13
Training loss: 0.6553799510002136
Validation loss: 2.0901395044019146

Epoch: 644| Step: 0
Training loss: 0.541678249835968
Validation loss: 2.0164723114300798

Epoch: 6| Step: 1
Training loss: 0.5560590028762817
Validation loss: 1.987188208487726

Epoch: 6| Step: 2
Training loss: 0.991959810256958
Validation loss: 2.0639794001015286

Epoch: 6| Step: 3
Training loss: 1.0707794427871704
Validation loss: 2.093437611415822

Epoch: 6| Step: 4
Training loss: 0.8418371677398682
Validation loss: 2.083985191519542

Epoch: 6| Step: 5
Training loss: 1.36238431930542
Validation loss: 2.096707095382034

Epoch: 6| Step: 6
Training loss: 1.085961103439331
Validation loss: 2.0785799052125666

Epoch: 6| Step: 7
Training loss: 1.5021398067474365
Validation loss: 2.056011603724572

Epoch: 6| Step: 8
Training loss: 1.9661730527877808
Validation loss: 2.065385849245133

Epoch: 6| Step: 9
Training loss: 0.9963481426239014
Validation loss: 2.0646977091348298

Epoch: 6| Step: 10
Training loss: 0.9864155650138855
Validation loss: 2.062981797802833

Epoch: 6| Step: 11
Training loss: 0.705634593963623
Validation loss: 2.070676757443336

Epoch: 6| Step: 12
Training loss: 0.645238995552063
Validation loss: 2.041092852110504

Epoch: 6| Step: 13
Training loss: 1.0529348850250244
Validation loss: 2.0395973318366596

Epoch: 645| Step: 0
Training loss: 0.9481832981109619
Validation loss: 2.0656003106024956

Epoch: 6| Step: 1
Training loss: 0.7864317297935486
Validation loss: 2.0954301459814912

Epoch: 6| Step: 2
Training loss: 0.972468376159668
Validation loss: 2.0221095405599123

Epoch: 6| Step: 3
Training loss: 1.4929699897766113
Validation loss: 2.0844773131032146

Epoch: 6| Step: 4
Training loss: 1.2485992908477783
Validation loss: 2.0259274257126676

Epoch: 6| Step: 5
Training loss: 0.6280317306518555
Validation loss: 2.0698277591377177

Epoch: 6| Step: 6
Training loss: 1.290833592414856
Validation loss: 2.0827062399156633

Epoch: 6| Step: 7
Training loss: 1.2493722438812256
Validation loss: 2.019111235936483

Epoch: 6| Step: 8
Training loss: 1.1560206413269043
Validation loss: 2.0942999188617994

Epoch: 6| Step: 9
Training loss: 1.0342113971710205
Validation loss: 2.072702366818664

Epoch: 6| Step: 10
Training loss: 0.6953701972961426
Validation loss: 2.0736783550631617

Epoch: 6| Step: 11
Training loss: 0.8552356958389282
Validation loss: 2.0846970440239034

Epoch: 6| Step: 12
Training loss: 0.8539214134216309
Validation loss: 2.0685844895660237

Epoch: 6| Step: 13
Training loss: 1.3020949363708496
Validation loss: 2.0511036175553516

Epoch: 646| Step: 0
Training loss: 0.8529785871505737
Validation loss: 2.0576733350753784

Epoch: 6| Step: 1
Training loss: 1.1126692295074463
Validation loss: 2.1030571845269974

Epoch: 6| Step: 2
Training loss: 1.3252373933792114
Validation loss: 2.0683166493651686

Epoch: 6| Step: 3
Training loss: 1.1343755722045898
Validation loss: 2.0432859197739632

Epoch: 6| Step: 4
Training loss: 1.2212626934051514
Validation loss: 2.0679356282757175

Epoch: 6| Step: 5
Training loss: 0.7937573194503784
Validation loss: 2.080743012889739

Epoch: 6| Step: 6
Training loss: 1.2616925239562988
Validation loss: 2.0503791865482124

Epoch: 6| Step: 7
Training loss: 1.6176470518112183
Validation loss: 1.990908638123543

Epoch: 6| Step: 8
Training loss: 1.253159999847412
Validation loss: 2.0351520110202093

Epoch: 6| Step: 9
Training loss: 0.9948606491088867
Validation loss: 2.0732018691237255

Epoch: 6| Step: 10
Training loss: 0.8406482934951782
Validation loss: 2.04686802048837

Epoch: 6| Step: 11
Training loss: 0.3657833933830261
Validation loss: 2.03504414327683

Epoch: 6| Step: 12
Training loss: 1.240299940109253
Validation loss: 2.065596809951208

Epoch: 6| Step: 13
Training loss: 0.6734123826026917
Validation loss: 2.0435314768104145

Epoch: 647| Step: 0
Training loss: 1.0474553108215332
Validation loss: 2.072297312880075

Epoch: 6| Step: 1
Training loss: 0.8359247446060181
Validation loss: 2.0508281928236767

Epoch: 6| Step: 2
Training loss: 1.4614346027374268
Validation loss: 2.1069157251747708

Epoch: 6| Step: 3
Training loss: 0.8116488456726074
Validation loss: 2.09607470163735

Epoch: 6| Step: 4
Training loss: 1.2832610607147217
Validation loss: 2.1094725055079304

Epoch: 6| Step: 5
Training loss: 1.4823131561279297
Validation loss: 2.1192875715994064

Epoch: 6| Step: 6
Training loss: 0.9867414236068726
Validation loss: 2.1050280845293434

Epoch: 6| Step: 7
Training loss: 0.9311133027076721
Validation loss: 2.049624120035479

Epoch: 6| Step: 8
Training loss: 1.0156188011169434
Validation loss: 2.091849675742529

Epoch: 6| Step: 9
Training loss: 0.9638135433197021
Validation loss: 2.0362969188280005

Epoch: 6| Step: 10
Training loss: 0.998243510723114
Validation loss: 2.0540571533223635

Epoch: 6| Step: 11
Training loss: 1.1870883703231812
Validation loss: 2.088138000939482

Epoch: 6| Step: 12
Training loss: 1.3244181871414185
Validation loss: 2.0393352931545627

Epoch: 6| Step: 13
Training loss: 1.114951252937317
Validation loss: 2.0130419436321465

Epoch: 648| Step: 0
Training loss: 0.695469856262207
Validation loss: 2.0526007170318277

Epoch: 6| Step: 1
Training loss: 1.2195234298706055
Validation loss: 2.0078366289856615

Epoch: 6| Step: 2
Training loss: 1.146040439605713
Validation loss: 2.007449398758591

Epoch: 6| Step: 3
Training loss: 1.3452599048614502
Validation loss: 2.018487717515679

Epoch: 6| Step: 4
Training loss: 1.3288605213165283
Validation loss: 2.0549152205067296

Epoch: 6| Step: 5
Training loss: 1.2623170614242554
Validation loss: 2.064222535779399

Epoch: 6| Step: 6
Training loss: 0.8732318878173828
Validation loss: 2.1078567145973124

Epoch: 6| Step: 7
Training loss: 1.4783353805541992
Validation loss: 2.049864048598915

Epoch: 6| Step: 8
Training loss: 0.841397762298584
Validation loss: 2.0399757021216938

Epoch: 6| Step: 9
Training loss: 0.6910269856452942
Validation loss: 2.07420487301324

Epoch: 6| Step: 10
Training loss: 0.5203121900558472
Validation loss: 2.024938242409819

Epoch: 6| Step: 11
Training loss: 1.0192075967788696
Validation loss: 2.061243749433948

Epoch: 6| Step: 12
Training loss: 1.3949556350708008
Validation loss: 2.035103985058364

Epoch: 6| Step: 13
Training loss: 0.48395097255706787
Validation loss: 1.985070038867253

Epoch: 649| Step: 0
Training loss: 1.029651403427124
Validation loss: 2.029621353713415

Epoch: 6| Step: 1
Training loss: 1.0747349262237549
Validation loss: 2.008196997386153

Epoch: 6| Step: 2
Training loss: 0.9327682256698608
Validation loss: 2.017423765633696

Epoch: 6| Step: 3
Training loss: 0.7951733469963074
Validation loss: 2.0272482825863745

Epoch: 6| Step: 4
Training loss: 1.620964765548706
Validation loss: 2.035874991006749

Epoch: 6| Step: 5
Training loss: 0.6409897804260254
Validation loss: 2.0650199587627123

Epoch: 6| Step: 6
Training loss: 1.1665819883346558
Validation loss: 2.0399402943990563

Epoch: 6| Step: 7
Training loss: 1.6473239660263062
Validation loss: 2.0982987547433503

Epoch: 6| Step: 8
Training loss: 1.2664852142333984
Validation loss: 2.0043950362872054

Epoch: 6| Step: 9
Training loss: 0.9142494797706604
Validation loss: 2.1003073235993743

Epoch: 6| Step: 10
Training loss: 0.8238354325294495
Validation loss: 2.036318855900918

Epoch: 6| Step: 11
Training loss: 1.315840244293213
Validation loss: 2.0445055525789977

Epoch: 6| Step: 12
Training loss: 0.771449089050293
Validation loss: 2.0799342406693326

Epoch: 6| Step: 13
Training loss: 0.666782021522522
Validation loss: 2.032947637701547

Epoch: 650| Step: 0
Training loss: 0.7044014930725098
Validation loss: 2.0850933482570033

Epoch: 6| Step: 1
Training loss: 1.477034330368042
Validation loss: 2.11640791995551

Epoch: 6| Step: 2
Training loss: 0.8799575567245483
Validation loss: 2.022937136311685

Epoch: 6| Step: 3
Training loss: 0.7573411464691162
Validation loss: 2.081611664064469

Epoch: 6| Step: 4
Training loss: 1.5961382389068604
Validation loss: 2.07866249545928

Epoch: 6| Step: 5
Training loss: 1.4388985633850098
Validation loss: 2.0529941858783847

Epoch: 6| Step: 6
Training loss: 1.6400383710861206
Validation loss: 2.066321096112651

Epoch: 6| Step: 7
Training loss: 0.9712134599685669
Validation loss: 2.056537382064327

Epoch: 6| Step: 8
Training loss: 0.8890648484230042
Validation loss: 2.0772572332812893

Epoch: 6| Step: 9
Training loss: 1.0919976234436035
Validation loss: 2.061809043730459

Epoch: 6| Step: 10
Training loss: 0.7604154348373413
Validation loss: 2.041878778447387

Epoch: 6| Step: 11
Training loss: 0.8279355764389038
Validation loss: 2.04089004506347

Epoch: 6| Step: 12
Training loss: 0.8005622625350952
Validation loss: 2.031469270747195

Epoch: 6| Step: 13
Training loss: 1.1201268434524536
Validation loss: 2.0261179324119323

Testing loss: 1.9163207822375827
