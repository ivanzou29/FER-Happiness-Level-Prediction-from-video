Epoch: 1| Step: 0
Training loss: 3.111525297164917
Validation loss: 3.495607145370976

Epoch: 6| Step: 1
Training loss: 3.346466064453125
Validation loss: 3.4942652589531353

Epoch: 6| Step: 2
Training loss: 3.2350711822509766
Validation loss: 3.4928735045976538

Epoch: 6| Step: 3
Training loss: 2.979844808578491
Validation loss: 3.48787046247913

Epoch: 6| Step: 4
Training loss: 3.8011293411254883
Validation loss: 3.487101444634058

Epoch: 6| Step: 5
Training loss: 3.8034348487854004
Validation loss: 3.4841064637707126

Epoch: 6| Step: 6
Training loss: 4.147948265075684
Validation loss: 3.482743593954271

Epoch: 6| Step: 7
Training loss: 3.3208165168762207
Validation loss: 3.479760598110896

Epoch: 6| Step: 8
Training loss: 3.643434762954712
Validation loss: 3.476039030218637

Epoch: 6| Step: 9
Training loss: 3.3494443893432617
Validation loss: 3.474921605920279

Epoch: 6| Step: 10
Training loss: 2.9755725860595703
Validation loss: 3.474344274049164

Epoch: 6| Step: 11
Training loss: 3.3642122745513916
Validation loss: 3.469624629584692

Epoch: 6| Step: 12
Training loss: 3.2301785945892334
Validation loss: 3.468488283054803

Epoch: 6| Step: 13
Training loss: 3.701575756072998
Validation loss: 3.465386454777051

Epoch: 2| Step: 0
Training loss: 3.47031307220459
Validation loss: 3.464478192790862

Epoch: 6| Step: 1
Training loss: 3.331130027770996
Validation loss: 3.4638395924721994

Epoch: 6| Step: 2
Training loss: 2.3097782135009766
Validation loss: 3.462025098903205

Epoch: 6| Step: 3
Training loss: 4.527457237243652
Validation loss: 3.4557203118519118

Epoch: 6| Step: 4
Training loss: 4.3479790687561035
Validation loss: 3.4545433008542625

Epoch: 6| Step: 5
Training loss: 2.434863567352295
Validation loss: 3.4539885879844747

Epoch: 6| Step: 6
Training loss: 3.811695098876953
Validation loss: 3.451324127053702

Epoch: 6| Step: 7
Training loss: 3.201672077178955
Validation loss: 3.448692080795124

Epoch: 6| Step: 8
Training loss: 3.609605550765991
Validation loss: 3.4458674769247732

Epoch: 6| Step: 9
Training loss: 4.011919021606445
Validation loss: 3.444384051907447

Epoch: 6| Step: 10
Training loss: 4.113579750061035
Validation loss: 3.4418025811513266

Epoch: 6| Step: 11
Training loss: 2.982149600982666
Validation loss: 3.439590423337875

Epoch: 6| Step: 12
Training loss: 2.8318209648132324
Validation loss: 3.4362225993987052

Epoch: 6| Step: 13
Training loss: 1.857546329498291
Validation loss: 3.4324730929508003

Epoch: 3| Step: 0
Training loss: 3.3410420417785645
Validation loss: 3.429075687162338

Epoch: 6| Step: 1
Training loss: 3.6197028160095215
Validation loss: 3.430849762373073

Epoch: 6| Step: 2
Training loss: 3.124647617340088
Validation loss: 3.428402828913863

Epoch: 6| Step: 3
Training loss: 2.3596646785736084
Validation loss: 3.4243426425482637

Epoch: 6| Step: 4
Training loss: 4.893037796020508
Validation loss: 3.42422834263053

Epoch: 6| Step: 5
Training loss: 3.4367504119873047
Validation loss: 3.420238712782501

Epoch: 6| Step: 6
Training loss: 3.6766469478607178
Validation loss: 3.4183943963819936

Epoch: 6| Step: 7
Training loss: 2.6138696670532227
Validation loss: 3.418283821434103

Epoch: 6| Step: 8
Training loss: 3.843308210372925
Validation loss: 3.4156996819280807

Epoch: 6| Step: 9
Training loss: 3.3283729553222656
Validation loss: 3.4121425254370576

Epoch: 6| Step: 10
Training loss: 2.6738271713256836
Validation loss: 3.4111359247597317

Epoch: 6| Step: 11
Training loss: 3.588024616241455
Validation loss: 3.4100429140111452

Epoch: 6| Step: 12
Training loss: 3.305184841156006
Validation loss: 3.4072819397013676

Epoch: 6| Step: 13
Training loss: 3.3036305904388428
Validation loss: 3.4041017819476385

Epoch: 4| Step: 0
Training loss: 3.6836671829223633
Validation loss: 3.4029086584685952

Epoch: 6| Step: 1
Training loss: 3.792670249938965
Validation loss: 3.398446170232629

Epoch: 6| Step: 2
Training loss: 2.6094038486480713
Validation loss: 3.396568716213267

Epoch: 6| Step: 3
Training loss: 2.7502427101135254
Validation loss: 3.3956897284394953

Epoch: 6| Step: 4
Training loss: 4.086850166320801
Validation loss: 3.394282102584839

Epoch: 6| Step: 5
Training loss: 3.676945209503174
Validation loss: 3.3890152233903126

Epoch: 6| Step: 6
Training loss: 2.5995452404022217
Validation loss: 3.388455844694568

Epoch: 6| Step: 7
Training loss: 2.3436176776885986
Validation loss: 3.3830597016119186

Epoch: 6| Step: 8
Training loss: 3.367720365524292
Validation loss: 3.3841738162502164

Epoch: 6| Step: 9
Training loss: 4.526504993438721
Validation loss: 3.3814220941194923

Epoch: 6| Step: 10
Training loss: 2.598630905151367
Validation loss: 3.3784640783904702

Epoch: 6| Step: 11
Training loss: 3.7259128093719482
Validation loss: 3.3763432989838305

Epoch: 6| Step: 12
Training loss: 3.296903610229492
Validation loss: 3.3720777906397337

Epoch: 6| Step: 13
Training loss: 3.928436279296875
Validation loss: 3.3738714366830806

Epoch: 5| Step: 0
Training loss: 2.8678011894226074
Validation loss: 3.3673835415993967

Epoch: 6| Step: 1
Training loss: 2.9032931327819824
Validation loss: 3.3622262708602415

Epoch: 6| Step: 2
Training loss: 2.514906883239746
Validation loss: 3.3623188490508706

Epoch: 6| Step: 3
Training loss: 2.222202777862549
Validation loss: 3.358939027273527

Epoch: 6| Step: 4
Training loss: 4.015692710876465
Validation loss: 3.3589376967440367

Epoch: 6| Step: 5
Training loss: 3.4883835315704346
Validation loss: 3.3536814592217885

Epoch: 6| Step: 6
Training loss: 3.7940986156463623
Validation loss: 3.353031640411705

Epoch: 6| Step: 7
Training loss: 2.923895835876465
Validation loss: 3.3471349029130835

Epoch: 6| Step: 8
Training loss: 4.412134647369385
Validation loss: 3.3471339543660483

Epoch: 6| Step: 9
Training loss: 3.2216973304748535
Validation loss: 3.3400431140776603

Epoch: 6| Step: 10
Training loss: 3.470308780670166
Validation loss: 3.3383612350750993

Epoch: 6| Step: 11
Training loss: 4.1686482429504395
Validation loss: 3.3402973682649675

Epoch: 6| Step: 12
Training loss: 2.740344524383545
Validation loss: 3.3351810516849643

Epoch: 6| Step: 13
Training loss: 3.695488452911377
Validation loss: 3.3303843390557075

Epoch: 6| Step: 0
Training loss: 2.989819049835205
Validation loss: 3.3293002036310013

Epoch: 6| Step: 1
Training loss: 2.2576076984405518
Validation loss: 3.3218700603772233

Epoch: 6| Step: 2
Training loss: 4.437134265899658
Validation loss: 3.3243518029489825

Epoch: 6| Step: 3
Training loss: 4.204921722412109
Validation loss: 3.3138933463763167

Epoch: 6| Step: 4
Training loss: 2.7317070960998535
Validation loss: 3.318115352302469

Epoch: 6| Step: 5
Training loss: 3.1152143478393555
Validation loss: 3.3093283484058995

Epoch: 6| Step: 6
Training loss: 4.254137992858887
Validation loss: 3.30842282695155

Epoch: 6| Step: 7
Training loss: 2.800954818725586
Validation loss: 3.3053999382962465

Epoch: 6| Step: 8
Training loss: 2.4788174629211426
Validation loss: 3.2995139552700903

Epoch: 6| Step: 9
Training loss: 3.5652904510498047
Validation loss: 3.29801949890711

Epoch: 6| Step: 10
Training loss: 2.9426045417785645
Validation loss: 3.296610709159605

Epoch: 6| Step: 11
Training loss: 2.9270615577697754
Validation loss: 3.2903317738604803

Epoch: 6| Step: 12
Training loss: 3.890761137008667
Validation loss: 3.2859424519282516

Epoch: 6| Step: 13
Training loss: 3.1715469360351562
Validation loss: 3.2853893310792985

Epoch: 7| Step: 0
Training loss: 2.8466811180114746
Validation loss: 3.280717055002848

Epoch: 6| Step: 1
Training loss: 2.921055555343628
Validation loss: 3.27680108880484

Epoch: 6| Step: 2
Training loss: 3.1870837211608887
Validation loss: 3.2739576524303806

Epoch: 6| Step: 3
Training loss: 4.178049087524414
Validation loss: 3.2694316192339827

Epoch: 6| Step: 4
Training loss: 2.9989380836486816
Validation loss: 3.266235961708971

Epoch: 6| Step: 5
Training loss: 3.5273284912109375
Validation loss: 3.26271657277179

Epoch: 6| Step: 6
Training loss: 2.881397247314453
Validation loss: 3.2595591827105452

Epoch: 6| Step: 7
Training loss: 3.1562790870666504
Validation loss: 3.261095154669977

Epoch: 6| Step: 8
Training loss: 2.5741171836853027
Validation loss: 3.253804358102942

Epoch: 6| Step: 9
Training loss: 4.129879951477051
Validation loss: 3.2491733899680515

Epoch: 6| Step: 10
Training loss: 3.2047948837280273
Validation loss: 3.2480233048879974

Epoch: 6| Step: 11
Training loss: 2.8517560958862305
Validation loss: 3.24537754571566

Epoch: 6| Step: 12
Training loss: 3.301027297973633
Validation loss: 3.2400489596910376

Epoch: 6| Step: 13
Training loss: 3.7297520637512207
Validation loss: 3.235367677545035

Epoch: 8| Step: 0
Training loss: 4.355837821960449
Validation loss: 3.2257263814249346

Epoch: 6| Step: 1
Training loss: 3.1077158451080322
Validation loss: 3.2229221354248705

Epoch: 6| Step: 2
Training loss: 2.7826690673828125
Validation loss: 3.218654563350062

Epoch: 6| Step: 3
Training loss: 2.4170823097229004
Validation loss: 3.2143201930548555

Epoch: 6| Step: 4
Training loss: 3.1686275005340576
Validation loss: 3.2124564827129407

Epoch: 6| Step: 5
Training loss: 3.5735816955566406
Validation loss: 3.2027320374724684

Epoch: 6| Step: 6
Training loss: 2.672822952270508
Validation loss: 3.2005866548066497

Epoch: 6| Step: 7
Training loss: 2.9289073944091797
Validation loss: 3.196003234514626

Epoch: 6| Step: 8
Training loss: 2.4222381114959717
Validation loss: 3.190771825851933

Epoch: 6| Step: 9
Training loss: 3.130631923675537
Validation loss: 3.1900068636863463

Epoch: 6| Step: 10
Training loss: 3.58199405670166
Validation loss: 3.182177197548651

Epoch: 6| Step: 11
Training loss: 3.1279349327087402
Validation loss: 3.174257437388102

Epoch: 6| Step: 12
Training loss: 4.278058052062988
Validation loss: 3.170652861236244

Epoch: 6| Step: 13
Training loss: 2.9931721687316895
Validation loss: 3.166006757367042

Epoch: 9| Step: 0
Training loss: 2.6349666118621826
Validation loss: 3.155954614762337

Epoch: 6| Step: 1
Training loss: 3.845860481262207
Validation loss: 3.149705620222194

Epoch: 6| Step: 2
Training loss: 2.316077470779419
Validation loss: 3.141407128303282

Epoch: 6| Step: 3
Training loss: 2.2836718559265137
Validation loss: 3.1374434450621247

Epoch: 6| Step: 4
Training loss: 3.6442792415618896
Validation loss: 3.1283550313723985

Epoch: 6| Step: 5
Training loss: 3.7156014442443848
Validation loss: 3.1259520053863525

Epoch: 6| Step: 6
Training loss: 3.415984630584717
Validation loss: 3.117958514921127

Epoch: 6| Step: 7
Training loss: 3.400486946105957
Validation loss: 3.1029007614299817

Epoch: 6| Step: 8
Training loss: 3.133098840713501
Validation loss: 3.0997963515661096

Epoch: 6| Step: 9
Training loss: 2.730161190032959
Validation loss: 3.0911944963598765

Epoch: 6| Step: 10
Training loss: 2.807027578353882
Validation loss: 3.0791708833427838

Epoch: 6| Step: 11
Training loss: 4.639490127563477
Validation loss: 3.078943775546166

Epoch: 6| Step: 12
Training loss: 2.180589199066162
Validation loss: 3.0688673398827993

Epoch: 6| Step: 13
Training loss: 2.9607741832733154
Validation loss: 3.0634498186008905

Epoch: 10| Step: 0
Training loss: 3.520089626312256
Validation loss: 3.0554646702222925

Epoch: 6| Step: 1
Training loss: 4.0570969581604
Validation loss: 3.052666328286612

Epoch: 6| Step: 2
Training loss: 3.7649178504943848
Validation loss: 3.0378938823617916

Epoch: 6| Step: 3
Training loss: 2.5526609420776367
Validation loss: 3.0316281626301427

Epoch: 6| Step: 4
Training loss: 2.774033784866333
Validation loss: 3.0234493824743454

Epoch: 6| Step: 5
Training loss: 3.1547930240631104
Validation loss: 3.0119711378569245

Epoch: 6| Step: 6
Training loss: 3.125861644744873
Validation loss: 3.00775541797761

Epoch: 6| Step: 7
Training loss: 2.3990511894226074
Validation loss: 3.0022165416389384

Epoch: 6| Step: 8
Training loss: 2.9982848167419434
Validation loss: 2.9965431613306843

Epoch: 6| Step: 9
Training loss: 2.6517677307128906
Validation loss: 2.985442320505778

Epoch: 6| Step: 10
Training loss: 2.8018813133239746
Validation loss: 2.9759351668819303

Epoch: 6| Step: 11
Training loss: 2.1064274311065674
Validation loss: 2.9712987587016118

Epoch: 6| Step: 12
Training loss: 3.6630263328552246
Validation loss: 2.9603900704332577

Epoch: 6| Step: 13
Training loss: 3.2350778579711914
Validation loss: 2.954218182512509

Epoch: 11| Step: 0
Training loss: 2.4683501720428467
Validation loss: 2.947884275067237

Epoch: 6| Step: 1
Training loss: 3.4250690937042236
Validation loss: 2.9426718629816526

Epoch: 6| Step: 2
Training loss: 3.394463539123535
Validation loss: 2.9337696490749234

Epoch: 6| Step: 3
Training loss: 2.996058940887451
Validation loss: 2.9287595082354803

Epoch: 6| Step: 4
Training loss: 3.2304985523223877
Validation loss: 2.920120039293843

Epoch: 6| Step: 5
Training loss: 2.5502822399139404
Validation loss: 2.905853174066031

Epoch: 6| Step: 6
Training loss: 3.6585288047790527
Validation loss: 2.897556176749609

Epoch: 6| Step: 7
Training loss: 2.997157335281372
Validation loss: 2.887811237765897

Epoch: 6| Step: 8
Training loss: 2.585049629211426
Validation loss: 2.8839490875121085

Epoch: 6| Step: 9
Training loss: 2.698225498199463
Validation loss: 2.875038436664048

Epoch: 6| Step: 10
Training loss: 2.894969940185547
Validation loss: 2.8717241851232385

Epoch: 6| Step: 11
Training loss: 3.3905386924743652
Validation loss: 2.8592764049447994

Epoch: 6| Step: 12
Training loss: 2.136794090270996
Validation loss: 2.8468865553538003

Epoch: 6| Step: 13
Training loss: 3.3310623168945312
Validation loss: 2.842230094376431

Epoch: 12| Step: 0
Training loss: 2.300704002380371
Validation loss: 2.8330554193066013

Epoch: 6| Step: 1
Training loss: 2.3830127716064453
Validation loss: 2.8238445046127483

Epoch: 6| Step: 2
Training loss: 2.3761978149414062
Validation loss: 2.8185638663589314

Epoch: 6| Step: 3
Training loss: 3.8489978313446045
Validation loss: 2.801762762890067

Epoch: 6| Step: 4
Training loss: 2.848954677581787
Validation loss: 2.7920701785754134

Epoch: 6| Step: 5
Training loss: 2.560093641281128
Validation loss: 2.7898451359041276

Epoch: 6| Step: 6
Training loss: 3.0313496589660645
Validation loss: 2.7762672542243876

Epoch: 6| Step: 7
Training loss: 3.0474023818969727
Validation loss: 2.778020948492071

Epoch: 6| Step: 8
Training loss: 2.7343544960021973
Validation loss: 2.761924061723935

Epoch: 6| Step: 9
Training loss: 2.4998459815979004
Validation loss: 2.754868922695037

Epoch: 6| Step: 10
Training loss: 3.828584909439087
Validation loss: 2.7462966006289244

Epoch: 6| Step: 11
Training loss: 3.297234058380127
Validation loss: 2.7315924347087903

Epoch: 6| Step: 12
Training loss: 2.5353879928588867
Validation loss: 2.726394271337858

Epoch: 6| Step: 13
Training loss: 3.4938879013061523
Validation loss: 2.7046910229549614

Epoch: 13| Step: 0
Training loss: 3.1490163803100586
Validation loss: 2.6999158807980117

Epoch: 6| Step: 1
Training loss: 2.0255134105682373
Validation loss: 2.6921333651388846

Epoch: 6| Step: 2
Training loss: 2.7268142700195312
Validation loss: 2.680674483699183

Epoch: 6| Step: 3
Training loss: 2.8679330348968506
Validation loss: 2.6662753833237516

Epoch: 6| Step: 4
Training loss: 2.9887497425079346
Validation loss: 2.6586176118543072

Epoch: 6| Step: 5
Training loss: 3.10965895652771
Validation loss: 2.6544999435383785

Epoch: 6| Step: 6
Training loss: 2.7219619750976562
Validation loss: 2.6349971807131203

Epoch: 6| Step: 7
Training loss: 2.8778998851776123
Validation loss: 2.622147221719065

Epoch: 6| Step: 8
Training loss: 3.984292984008789
Validation loss: 2.6188675870177565

Epoch: 6| Step: 9
Training loss: 2.2392468452453613
Validation loss: 2.595572917692123

Epoch: 6| Step: 10
Training loss: 2.697813034057617
Validation loss: 2.588869787031604

Epoch: 6| Step: 11
Training loss: 2.457973003387451
Validation loss: 2.5779662952628186

Epoch: 6| Step: 12
Training loss: 2.5604195594787598
Validation loss: 2.5602186572167183

Epoch: 6| Step: 13
Training loss: 3.1057913303375244
Validation loss: 2.568950540275984

Epoch: 14| Step: 0
Training loss: 3.061584711074829
Validation loss: 2.5520925906396683

Epoch: 6| Step: 1
Training loss: 3.1558544635772705
Validation loss: 2.5373860533519457

Epoch: 6| Step: 2
Training loss: 2.006089448928833
Validation loss: 2.530716639693065

Epoch: 6| Step: 3
Training loss: 2.9379308223724365
Validation loss: 2.52009061075026

Epoch: 6| Step: 4
Training loss: 3.040825843811035
Validation loss: 2.509231457146265

Epoch: 6| Step: 5
Training loss: 2.7915143966674805
Validation loss: 2.5028096604090866

Epoch: 6| Step: 6
Training loss: 2.574052333831787
Validation loss: 2.487515080359674

Epoch: 6| Step: 7
Training loss: 2.647895097732544
Validation loss: 2.4762952084182412

Epoch: 6| Step: 8
Training loss: 2.4779601097106934
Validation loss: 2.4720919901324856

Epoch: 6| Step: 9
Training loss: 3.296510696411133
Validation loss: 2.46415549965315

Epoch: 6| Step: 10
Training loss: 2.2388675212860107
Validation loss: 2.454490561639109

Epoch: 6| Step: 11
Training loss: 2.540815591812134
Validation loss: 2.4401060727334793

Epoch: 6| Step: 12
Training loss: 2.987764358520508
Validation loss: 2.4298714232701126

Epoch: 6| Step: 13
Training loss: 2.0250396728515625
Validation loss: 2.430862221666562

Epoch: 15| Step: 0
Training loss: 2.0219898223876953
Validation loss: 2.4172776796484507

Epoch: 6| Step: 1
Training loss: 2.6370556354522705
Validation loss: 2.4013666081172165

Epoch: 6| Step: 2
Training loss: 2.68511962890625
Validation loss: 2.393072589751213

Epoch: 6| Step: 3
Training loss: 2.4261221885681152
Validation loss: 2.3809071920251332

Epoch: 6| Step: 4
Training loss: 3.5133888721466064
Validation loss: 2.369454421022887

Epoch: 6| Step: 5
Training loss: 2.376955509185791
Validation loss: 2.369869580832861

Epoch: 6| Step: 6
Training loss: 2.891192674636841
Validation loss: 2.3594063353794876

Epoch: 6| Step: 7
Training loss: 2.9206995964050293
Validation loss: 2.352392306891821

Epoch: 6| Step: 8
Training loss: 3.0889830589294434
Validation loss: 2.3445341535793838

Epoch: 6| Step: 9
Training loss: 2.9497199058532715
Validation loss: 2.345221678415934

Epoch: 6| Step: 10
Training loss: 2.785485029220581
Validation loss: 2.3362956047058105

Epoch: 6| Step: 11
Training loss: 2.2135167121887207
Validation loss: 2.3145267604499735

Epoch: 6| Step: 12
Training loss: 2.1429715156555176
Validation loss: 2.3189398114399244

Epoch: 6| Step: 13
Training loss: 2.065314531326294
Validation loss: 2.3080246269062

Epoch: 16| Step: 0
Training loss: 2.9153659343719482
Validation loss: 2.2888227380732054

Epoch: 6| Step: 1
Training loss: 2.2920165061950684
Validation loss: 2.2924333900533695

Epoch: 6| Step: 2
Training loss: 2.5864737033843994
Validation loss: 2.26971221739246

Epoch: 6| Step: 3
Training loss: 2.4366135597229004
Validation loss: 2.265186753324283

Epoch: 6| Step: 4
Training loss: 3.377936363220215
Validation loss: 2.2479608879294446

Epoch: 6| Step: 5
Training loss: 2.989710807800293
Validation loss: 2.2605653116779942

Epoch: 6| Step: 6
Training loss: 2.3223958015441895
Validation loss: 2.2438906828562417

Epoch: 6| Step: 7
Training loss: 2.4928481578826904
Validation loss: 2.2399562815184235

Epoch: 6| Step: 8
Training loss: 2.2996973991394043
Validation loss: 2.2383079451899373

Epoch: 6| Step: 9
Training loss: 1.9436450004577637
Validation loss: 2.210729040125365

Epoch: 6| Step: 10
Training loss: 2.797361373901367
Validation loss: 2.205327133978567

Epoch: 6| Step: 11
Training loss: 2.0903444290161133
Validation loss: 2.209997178405844

Epoch: 6| Step: 12
Training loss: 2.830900192260742
Validation loss: 2.2028027862630863

Epoch: 6| Step: 13
Training loss: 2.4218435287475586
Validation loss: 2.2033780697853333

Epoch: 17| Step: 0
Training loss: 2.7100658416748047
Validation loss: 2.2041692272309334

Epoch: 6| Step: 1
Training loss: 3.306981086730957
Validation loss: 2.189955844674059

Epoch: 6| Step: 2
Training loss: 2.757736921310425
Validation loss: 2.175632510133969

Epoch: 6| Step: 3
Training loss: 2.1221883296966553
Validation loss: 2.171213142333492

Epoch: 6| Step: 4
Training loss: 2.4136886596679688
Validation loss: 2.161636080793155

Epoch: 6| Step: 5
Training loss: 1.7721492052078247
Validation loss: 2.164320816275894

Epoch: 6| Step: 6
Training loss: 3.108227014541626
Validation loss: 2.1391290567254506

Epoch: 6| Step: 7
Training loss: 2.4645588397979736
Validation loss: 2.1396973799633723

Epoch: 6| Step: 8
Training loss: 2.4967355728149414
Validation loss: 2.141668059492624

Epoch: 6| Step: 9
Training loss: 2.144956111907959
Validation loss: 2.1322046787508073

Epoch: 6| Step: 10
Training loss: 2.394611120223999
Validation loss: 2.119463461701588

Epoch: 6| Step: 11
Training loss: 2.6017026901245117
Validation loss: 2.1109173169700046

Epoch: 6| Step: 12
Training loss: 2.495975971221924
Validation loss: 2.1089610797102734

Epoch: 6| Step: 13
Training loss: 2.2108523845672607
Validation loss: 2.1303763005041305

Epoch: 18| Step: 0
Training loss: 2.692315101623535
Validation loss: 2.112919230614939

Epoch: 6| Step: 1
Training loss: 2.1326982975006104
Validation loss: 2.1130217031766008

Epoch: 6| Step: 2
Training loss: 2.417795181274414
Validation loss: 2.1067531519038702

Epoch: 6| Step: 3
Training loss: 2.0986979007720947
Validation loss: 2.109668247161373

Epoch: 6| Step: 4
Training loss: 2.3715498447418213
Validation loss: 2.099908615953179

Epoch: 6| Step: 5
Training loss: 1.7950639724731445
Validation loss: 2.09192237546367

Epoch: 6| Step: 6
Training loss: 2.5750937461853027
Validation loss: 2.1066692721459175

Epoch: 6| Step: 7
Training loss: 2.6524128913879395
Validation loss: 2.0978990370227444

Epoch: 6| Step: 8
Training loss: 2.478738307952881
Validation loss: 2.0968057340191257

Epoch: 6| Step: 9
Training loss: 3.106598377227783
Validation loss: 2.0827867292588755

Epoch: 6| Step: 10
Training loss: 2.6378369331359863
Validation loss: 2.105714556991413

Epoch: 6| Step: 11
Training loss: 2.2361083030700684
Validation loss: 2.0802656168578775

Epoch: 6| Step: 12
Training loss: 2.5153138637542725
Validation loss: 2.0772169328504995

Epoch: 6| Step: 13
Training loss: 3.1381618976593018
Validation loss: 2.074619398322157

Epoch: 19| Step: 0
Training loss: 2.2854528427124023
Validation loss: 2.0764357684760966

Epoch: 6| Step: 1
Training loss: 2.259535312652588
Validation loss: 2.0751445062698854

Epoch: 6| Step: 2
Training loss: 1.9932781457901
Validation loss: 2.0550549440486456

Epoch: 6| Step: 3
Training loss: 2.1084213256835938
Validation loss: 2.0640815586172123

Epoch: 6| Step: 4
Training loss: 2.8236608505249023
Validation loss: 2.061141506318123

Epoch: 6| Step: 5
Training loss: 2.540621042251587
Validation loss: 2.057214172937537

Epoch: 6| Step: 6
Training loss: 2.6512765884399414
Validation loss: 2.0529842581800235

Epoch: 6| Step: 7
Training loss: 3.26645827293396
Validation loss: 2.0599251972731722

Epoch: 6| Step: 8
Training loss: 2.467043876647949
Validation loss: 2.043336517067366

Epoch: 6| Step: 9
Training loss: 2.5903263092041016
Validation loss: 2.0540312592701246

Epoch: 6| Step: 10
Training loss: 1.707721471786499
Validation loss: 2.039948319876066

Epoch: 6| Step: 11
Training loss: 2.983964443206787
Validation loss: 2.0414425262840847

Epoch: 6| Step: 12
Training loss: 2.7952218055725098
Validation loss: 2.034084386723016

Epoch: 6| Step: 13
Training loss: 1.741675853729248
Validation loss: 2.041785709319576

Epoch: 20| Step: 0
Training loss: 1.867293357849121
Validation loss: 2.0384535943308184

Epoch: 6| Step: 1
Training loss: 2.9521124362945557
Validation loss: 2.032160116780189

Epoch: 6| Step: 2
Training loss: 2.531996726989746
Validation loss: 2.031379028033185

Epoch: 6| Step: 3
Training loss: 2.403885841369629
Validation loss: 2.036556436169532

Epoch: 6| Step: 4
Training loss: 2.8740181922912598
Validation loss: 2.049189018946822

Epoch: 6| Step: 5
Training loss: 2.562523365020752
Validation loss: 2.0304036140441895

Epoch: 6| Step: 6
Training loss: 2.31881046295166
Validation loss: 2.0330991219448786

Epoch: 6| Step: 7
Training loss: 2.39983868598938
Validation loss: 2.034764520583614

Epoch: 6| Step: 8
Training loss: 2.452382802963257
Validation loss: 2.0326210119391

Epoch: 6| Step: 9
Training loss: 2.4835245609283447
Validation loss: 2.049985579265061

Epoch: 6| Step: 10
Training loss: 2.167452812194824
Validation loss: 2.027725840127596

Epoch: 6| Step: 11
Training loss: 2.4928901195526123
Validation loss: 2.038496410974892

Epoch: 6| Step: 12
Training loss: 2.7232718467712402
Validation loss: 2.036624825128945

Epoch: 6| Step: 13
Training loss: 1.9366289377212524
Validation loss: 2.0441830004415205

Epoch: 21| Step: 0
Training loss: 2.6253724098205566
Validation loss: 2.029658231683957

Epoch: 6| Step: 1
Training loss: 2.499974250793457
Validation loss: 2.0566054877414497

Epoch: 6| Step: 2
Training loss: 2.971059799194336
Validation loss: 2.0324090321858725

Epoch: 6| Step: 3
Training loss: 2.243323802947998
Validation loss: 2.03121441923162

Epoch: 6| Step: 4
Training loss: 2.478928804397583
Validation loss: 2.019138482309157

Epoch: 6| Step: 5
Training loss: 2.628103256225586
Validation loss: 2.0321808271510626

Epoch: 6| Step: 6
Training loss: 1.6934089660644531
Validation loss: 2.0274715782493673

Epoch: 6| Step: 7
Training loss: 2.3040237426757812
Validation loss: 2.034028184029364

Epoch: 6| Step: 8
Training loss: 2.8118205070495605
Validation loss: 2.033813266343968

Epoch: 6| Step: 9
Training loss: 1.6348203420639038
Validation loss: 2.0291936269370456

Epoch: 6| Step: 10
Training loss: 2.7259268760681152
Validation loss: 2.02702679429003

Epoch: 6| Step: 11
Training loss: 3.213498115539551
Validation loss: 2.0091996346750567

Epoch: 6| Step: 12
Training loss: 2.0644583702087402
Validation loss: 2.0253512936253704

Epoch: 6| Step: 13
Training loss: 2.5133464336395264
Validation loss: 2.0391405244027414

Epoch: 22| Step: 0
Training loss: 2.650784969329834
Validation loss: 2.0301377593830066

Epoch: 6| Step: 1
Training loss: 2.396468162536621
Validation loss: 2.0323171372054727

Epoch: 6| Step: 2
Training loss: 2.1240034103393555
Validation loss: 2.025378099051855

Epoch: 6| Step: 3
Training loss: 2.245494842529297
Validation loss: 2.0222214050190424

Epoch: 6| Step: 4
Training loss: 2.8744900226593018
Validation loss: 2.0391504328737975

Epoch: 6| Step: 5
Training loss: 2.6735782623291016
Validation loss: 2.0306780543378604

Epoch: 6| Step: 6
Training loss: 2.21357798576355
Validation loss: 2.0291322085165207

Epoch: 6| Step: 7
Training loss: 2.3666982650756836
Validation loss: 2.016988169762396

Epoch: 6| Step: 8
Training loss: 2.2525596618652344
Validation loss: 2.0200773772372993

Epoch: 6| Step: 9
Training loss: 2.202204704284668
Validation loss: 2.014585589849821

Epoch: 6| Step: 10
Training loss: 2.700225830078125
Validation loss: 2.030678128683439

Epoch: 6| Step: 11
Training loss: 2.923727035522461
Validation loss: 2.028249495772905

Epoch: 6| Step: 12
Training loss: 2.4952690601348877
Validation loss: 2.045025166644845

Epoch: 6| Step: 13
Training loss: 1.9805703163146973
Validation loss: 2.033592600976267

Epoch: 23| Step: 0
Training loss: 2.6211628913879395
Validation loss: 2.0308355105820524

Epoch: 6| Step: 1
Training loss: 2.129002094268799
Validation loss: 2.0250224913320234

Epoch: 6| Step: 2
Training loss: 2.5927910804748535
Validation loss: 2.025393606514059

Epoch: 6| Step: 3
Training loss: 1.985515832901001
Validation loss: 2.0272347670729443

Epoch: 6| Step: 4
Training loss: 2.33225679397583
Validation loss: 2.0277691669361566

Epoch: 6| Step: 5
Training loss: 3.0565314292907715
Validation loss: 2.022433046371706

Epoch: 6| Step: 6
Training loss: 2.2765989303588867
Validation loss: 2.032469981460161

Epoch: 6| Step: 7
Training loss: 2.5259814262390137
Validation loss: 2.0287107677869898

Epoch: 6| Step: 8
Training loss: 2.6009068489074707
Validation loss: 2.0274611275683165

Epoch: 6| Step: 9
Training loss: 2.263845920562744
Validation loss: 2.0423346129796838

Epoch: 6| Step: 10
Training loss: 2.4907429218292236
Validation loss: 2.038911731012406

Epoch: 6| Step: 11
Training loss: 2.2772674560546875
Validation loss: 2.0393672707260295

Epoch: 6| Step: 12
Training loss: 2.2629733085632324
Validation loss: 2.032520014752624

Epoch: 6| Step: 13
Training loss: 3.1077167987823486
Validation loss: 2.0262691103002077

Epoch: 24| Step: 0
Training loss: 2.3920791149139404
Validation loss: 2.037121252347064

Epoch: 6| Step: 1
Training loss: 2.203616142272949
Validation loss: 2.046630705556562

Epoch: 6| Step: 2
Training loss: 2.6317553520202637
Validation loss: 2.0374500366949264

Epoch: 6| Step: 3
Training loss: 1.657124400138855
Validation loss: 2.022148971916527

Epoch: 6| Step: 4
Training loss: 1.405408263206482
Validation loss: 2.0168752106287147

Epoch: 6| Step: 5
Training loss: 2.719778537750244
Validation loss: 2.0154471679400374

Epoch: 6| Step: 6
Training loss: 2.3151021003723145
Validation loss: 2.0160167255709247

Epoch: 6| Step: 7
Training loss: 2.642530918121338
Validation loss: 2.023668384039274

Epoch: 6| Step: 8
Training loss: 2.7797179222106934
Validation loss: 2.022254728501843

Epoch: 6| Step: 9
Training loss: 3.058304786682129
Validation loss: 2.0234035650889077

Epoch: 6| Step: 10
Training loss: 2.4094700813293457
Validation loss: 2.0252273364733626

Epoch: 6| Step: 11
Training loss: 2.2175564765930176
Validation loss: 2.0230999774830316

Epoch: 6| Step: 12
Training loss: 3.214700937271118
Validation loss: 2.0298753925549087

Epoch: 6| Step: 13
Training loss: 2.635727882385254
Validation loss: 2.022255370693822

Epoch: 25| Step: 0
Training loss: 2.539072275161743
Validation loss: 2.0289897969973985

Epoch: 6| Step: 1
Training loss: 2.392113447189331
Validation loss: 2.025654016002532

Epoch: 6| Step: 2
Training loss: 1.8350403308868408
Validation loss: 2.015385625182941

Epoch: 6| Step: 3
Training loss: 2.533234119415283
Validation loss: 2.007225469876361

Epoch: 6| Step: 4
Training loss: 2.812466859817505
Validation loss: 2.0120643249122043

Epoch: 6| Step: 5
Training loss: 1.392103910446167
Validation loss: 2.02122276700953

Epoch: 6| Step: 6
Training loss: 2.778928279876709
Validation loss: 2.012152256504182

Epoch: 6| Step: 7
Training loss: 2.945174217224121
Validation loss: 2.0060515942112094

Epoch: 6| Step: 8
Training loss: 2.624858856201172
Validation loss: 2.0155160350184285

Epoch: 6| Step: 9
Training loss: 2.515533685684204
Validation loss: 2.0140253638708465

Epoch: 6| Step: 10
Training loss: 2.5444765090942383
Validation loss: 2.0040287304950017

Epoch: 6| Step: 11
Training loss: 2.319589138031006
Validation loss: 1.9988304568875221

Epoch: 6| Step: 12
Training loss: 2.4752440452575684
Validation loss: 2.012359913959298

Epoch: 6| Step: 13
Training loss: 2.5311732292175293
Validation loss: 2.022848485618509

Epoch: 26| Step: 0
Training loss: 2.302574634552002
Validation loss: 2.02009920407367

Epoch: 6| Step: 1
Training loss: 2.6724653244018555
Validation loss: 2.0081779290271062

Epoch: 6| Step: 2
Training loss: 2.591999053955078
Validation loss: 2.0124972379335793

Epoch: 6| Step: 3
Training loss: 2.7201201915740967
Validation loss: 2.012827209247056

Epoch: 6| Step: 4
Training loss: 2.3859782218933105
Validation loss: 2.0051210003514446

Epoch: 6| Step: 5
Training loss: 2.3116676807403564
Validation loss: 2.009535909980856

Epoch: 6| Step: 6
Training loss: 2.934720993041992
Validation loss: 2.013056389747127

Epoch: 6| Step: 7
Training loss: 2.4154109954833984
Validation loss: 2.0347790192532282

Epoch: 6| Step: 8
Training loss: 1.937709927558899
Validation loss: 2.0237664099662536

Epoch: 6| Step: 9
Training loss: 2.4854092597961426
Validation loss: 2.020431451900031

Epoch: 6| Step: 10
Training loss: 2.374180316925049
Validation loss: 2.0172903025022118

Epoch: 6| Step: 11
Training loss: 2.319793701171875
Validation loss: 2.0178903046474663

Epoch: 6| Step: 12
Training loss: 2.6910548210144043
Validation loss: 2.002798318862915

Epoch: 6| Step: 13
Training loss: 1.364926815032959
Validation loss: 2.0079194243236254

Epoch: 27| Step: 0
Training loss: 2.876284599304199
Validation loss: 2.018154177614438

Epoch: 6| Step: 1
Training loss: 1.918543815612793
Validation loss: 2.01391327252952

Epoch: 6| Step: 2
Training loss: 1.7359895706176758
Validation loss: 2.0108421976848314

Epoch: 6| Step: 3
Training loss: 2.618401050567627
Validation loss: 2.0193242565278084

Epoch: 6| Step: 4
Training loss: 2.3878774642944336
Validation loss: 2.0127130810932448

Epoch: 6| Step: 5
Training loss: 3.0085606575012207
Validation loss: 2.0162495977135113

Epoch: 6| Step: 6
Training loss: 2.566507339477539
Validation loss: 2.0197918953434115

Epoch: 6| Step: 7
Training loss: 2.53684663772583
Validation loss: 2.0128384854203913

Epoch: 6| Step: 8
Training loss: 1.8720018863677979
Validation loss: 2.0141420864289805

Epoch: 6| Step: 9
Training loss: 2.839733600616455
Validation loss: 2.0033853797502417

Epoch: 6| Step: 10
Training loss: 1.9357624053955078
Validation loss: 2.00936193876369

Epoch: 6| Step: 11
Training loss: 2.774350881576538
Validation loss: 2.00668332910025

Epoch: 6| Step: 12
Training loss: 2.3502302169799805
Validation loss: 2.010071644219019

Epoch: 6| Step: 13
Training loss: 2.6861379146575928
Validation loss: 2.022828660985475

Epoch: 28| Step: 0
Training loss: 3.100904941558838
Validation loss: 2.0191751462157055

Epoch: 6| Step: 1
Training loss: 2.330284357070923
Validation loss: 2.0252937937295563

Epoch: 6| Step: 2
Training loss: 2.0877199172973633
Validation loss: 2.020613754949262

Epoch: 6| Step: 3
Training loss: 2.1061081886291504
Validation loss: 2.0159050982485534

Epoch: 6| Step: 4
Training loss: 2.21420955657959
Validation loss: 2.0271155834198

Epoch: 6| Step: 5
Training loss: 3.5040788650512695
Validation loss: 2.0269594320686917

Epoch: 6| Step: 6
Training loss: 1.83843994140625
Validation loss: 2.0042494458536946

Epoch: 6| Step: 7
Training loss: 2.248260021209717
Validation loss: 2.02365570170905

Epoch: 6| Step: 8
Training loss: 2.186835765838623
Validation loss: 2.0330624324019237

Epoch: 6| Step: 9
Training loss: 2.3036842346191406
Validation loss: 2.030493272248135

Epoch: 6| Step: 10
Training loss: 2.863323211669922
Validation loss: 2.028450455716861

Epoch: 6| Step: 11
Training loss: 2.7107367515563965
Validation loss: 2.0297513815664474

Epoch: 6| Step: 12
Training loss: 2.1800689697265625
Validation loss: 2.0317173824515393

Epoch: 6| Step: 13
Training loss: 2.1697869300842285
Validation loss: 2.0314583111834783

Epoch: 29| Step: 0
Training loss: 2.883004665374756
Validation loss: 2.036595129197644

Epoch: 6| Step: 1
Training loss: 3.1668567657470703
Validation loss: 2.022307203662011

Epoch: 6| Step: 2
Training loss: 2.835186243057251
Validation loss: 2.02440970687456

Epoch: 6| Step: 3
Training loss: 2.108391284942627
Validation loss: 2.0484008276334373

Epoch: 6| Step: 4
Training loss: 2.129981517791748
Validation loss: 2.0285447079648256

Epoch: 6| Step: 5
Training loss: 2.045717716217041
Validation loss: 2.0392704817556564

Epoch: 6| Step: 6
Training loss: 3.156200885772705
Validation loss: 2.02945872019696

Epoch: 6| Step: 7
Training loss: 2.5488104820251465
Validation loss: 2.041636565680145

Epoch: 6| Step: 8
Training loss: 2.421231985092163
Validation loss: 2.0457775426167313

Epoch: 6| Step: 9
Training loss: 2.427164077758789
Validation loss: 2.0409566612653833

Epoch: 6| Step: 10
Training loss: 1.9244407415390015
Validation loss: 2.046532077174033

Epoch: 6| Step: 11
Training loss: 2.1595520973205566
Validation loss: 2.0349915335255284

Epoch: 6| Step: 12
Training loss: 1.8787730932235718
Validation loss: 2.056045465571906

Epoch: 6| Step: 13
Training loss: 1.970529556274414
Validation loss: 2.0414852826826033

Epoch: 30| Step: 0
Training loss: 2.0025739669799805
Validation loss: 2.0299006174969416

Epoch: 6| Step: 1
Training loss: 2.719059467315674
Validation loss: 2.0369999639449583

Epoch: 6| Step: 2
Training loss: 2.5870606899261475
Validation loss: 2.047836563920462

Epoch: 6| Step: 3
Training loss: 2.5770130157470703
Validation loss: 2.0532232561419086

Epoch: 6| Step: 4
Training loss: 1.7807984352111816
Validation loss: 2.0634900087951333

Epoch: 6| Step: 5
Training loss: 2.207716941833496
Validation loss: 2.0476215193348546

Epoch: 6| Step: 6
Training loss: 2.678406238555908
Validation loss: 2.029669192529494

Epoch: 6| Step: 7
Training loss: 2.3212764263153076
Validation loss: 2.0336250489757908

Epoch: 6| Step: 8
Training loss: 2.94374942779541
Validation loss: 2.0537344178845807

Epoch: 6| Step: 9
Training loss: 2.2312488555908203
Validation loss: 2.0289418440993114

Epoch: 6| Step: 10
Training loss: 2.3427772521972656
Validation loss: 2.0297521647586616

Epoch: 6| Step: 11
Training loss: 2.2749247550964355
Validation loss: 2.0321374900879396

Epoch: 6| Step: 12
Training loss: 2.472630739212036
Validation loss: 2.028516011853372

Epoch: 6| Step: 13
Training loss: 2.8395028114318848
Validation loss: 2.0285749922516527

Epoch: 31| Step: 0
Training loss: 2.936595916748047
Validation loss: 2.034924869896263

Epoch: 6| Step: 1
Training loss: 1.8117241859436035
Validation loss: 2.02135455992914

Epoch: 6| Step: 2
Training loss: 2.9935302734375
Validation loss: 2.034550670654543

Epoch: 6| Step: 3
Training loss: 2.4452991485595703
Validation loss: 2.0368983848120576

Epoch: 6| Step: 4
Training loss: 2.545663356781006
Validation loss: 2.022079501100766

Epoch: 6| Step: 5
Training loss: 1.9678173065185547
Validation loss: 2.0204152061093237

Epoch: 6| Step: 6
Training loss: 2.2651028633117676
Validation loss: 2.0161719270931777

Epoch: 6| Step: 7
Training loss: 1.6723988056182861
Validation loss: 2.0329898018990793

Epoch: 6| Step: 8
Training loss: 2.5824944972991943
Validation loss: 2.0222749017900035

Epoch: 6| Step: 9
Training loss: 2.6490602493286133
Validation loss: 2.0296497908971642

Epoch: 6| Step: 10
Training loss: 2.731368064880371
Validation loss: 2.0233111791713263

Epoch: 6| Step: 11
Training loss: 2.2923214435577393
Validation loss: 2.0340234746215162

Epoch: 6| Step: 12
Training loss: 2.6689324378967285
Validation loss: 2.036598055593429

Epoch: 6| Step: 13
Training loss: 1.9044407606124878
Validation loss: 2.0290798576929236

Epoch: 32| Step: 0
Training loss: 2.4980125427246094
Validation loss: 2.02551410787849

Epoch: 6| Step: 1
Training loss: 2.8393282890319824
Validation loss: 2.0379860375517156

Epoch: 6| Step: 2
Training loss: 2.141244888305664
Validation loss: 2.019409810343096

Epoch: 6| Step: 3
Training loss: 1.8502225875854492
Validation loss: 2.015364808420981

Epoch: 6| Step: 4
Training loss: 2.0204687118530273
Validation loss: 2.024256811347059

Epoch: 6| Step: 5
Training loss: 2.098936080932617
Validation loss: 2.0176966074974305

Epoch: 6| Step: 6
Training loss: 2.829421043395996
Validation loss: 2.0147004230048067

Epoch: 6| Step: 7
Training loss: 1.9077253341674805
Validation loss: 2.0139574889213807

Epoch: 6| Step: 8
Training loss: 2.561488628387451
Validation loss: 2.014158050219218

Epoch: 6| Step: 9
Training loss: 2.241586208343506
Validation loss: 2.0285897178034626

Epoch: 6| Step: 10
Training loss: 2.9941658973693848
Validation loss: 2.002933353506109

Epoch: 6| Step: 11
Training loss: 2.7119028568267822
Validation loss: 2.0058004753563994

Epoch: 6| Step: 12
Training loss: 2.695237159729004
Validation loss: 2.0175546817882086

Epoch: 6| Step: 13
Training loss: 2.1884307861328125
Validation loss: 2.0032025255182737

Epoch: 33| Step: 0
Training loss: 2.821216106414795
Validation loss: 2.012612563307567

Epoch: 6| Step: 1
Training loss: 3.1763765811920166
Validation loss: 2.018727123096425

Epoch: 6| Step: 2
Training loss: 2.1841089725494385
Validation loss: 2.00611005034498

Epoch: 6| Step: 3
Training loss: 2.204261302947998
Validation loss: 2.014994869949997

Epoch: 6| Step: 4
Training loss: 2.0393667221069336
Validation loss: 2.008347890710318

Epoch: 6| Step: 5
Training loss: 2.245176315307617
Validation loss: 2.021234671274821

Epoch: 6| Step: 6
Training loss: 1.9013704061508179
Validation loss: 2.022500967466703

Epoch: 6| Step: 7
Training loss: 2.2903482913970947
Validation loss: 2.0175665360625072

Epoch: 6| Step: 8
Training loss: 2.3205008506774902
Validation loss: 2.0139830958458687

Epoch: 6| Step: 9
Training loss: 2.3457345962524414
Validation loss: 1.9961331070110362

Epoch: 6| Step: 10
Training loss: 2.4075164794921875
Validation loss: 2.0153104310394614

Epoch: 6| Step: 11
Training loss: 1.9601070880889893
Validation loss: 2.01550393719827

Epoch: 6| Step: 12
Training loss: 2.9391884803771973
Validation loss: 2.006645538473642

Epoch: 6| Step: 13
Training loss: 3.141098737716675
Validation loss: 2.0103092270512737

Epoch: 34| Step: 0
Training loss: 2.811356544494629
Validation loss: 2.0013954844526065

Epoch: 6| Step: 1
Training loss: 2.935211181640625
Validation loss: 2.015386135347428

Epoch: 6| Step: 2
Training loss: 2.1784849166870117
Validation loss: 2.0133157186610724

Epoch: 6| Step: 3
Training loss: 2.119987964630127
Validation loss: 2.0176550765191354

Epoch: 6| Step: 4
Training loss: 2.5319111347198486
Validation loss: 2.029522680467175

Epoch: 6| Step: 5
Training loss: 2.001889705657959
Validation loss: 2.0256949752889652

Epoch: 6| Step: 6
Training loss: 2.5456972122192383
Validation loss: 2.011121560168523

Epoch: 6| Step: 7
Training loss: 2.4705848693847656
Validation loss: 2.022081046976069

Epoch: 6| Step: 8
Training loss: 2.8351898193359375
Validation loss: 2.0113476155906596

Epoch: 6| Step: 9
Training loss: 2.0795445442199707
Validation loss: 2.020312815584162

Epoch: 6| Step: 10
Training loss: 2.0630009174346924
Validation loss: 2.0019826658310427

Epoch: 6| Step: 11
Training loss: 1.5776638984680176
Validation loss: 2.027174098517305

Epoch: 6| Step: 12
Training loss: 2.8416409492492676
Validation loss: 2.0119120100493073

Epoch: 6| Step: 13
Training loss: 2.7168545722961426
Validation loss: 2.0184468671839726

Epoch: 35| Step: 0
Training loss: 2.7994627952575684
Validation loss: 2.0192601526937177

Epoch: 6| Step: 1
Training loss: 2.919656753540039
Validation loss: 2.0240165161830124

Epoch: 6| Step: 2
Training loss: 2.178302764892578
Validation loss: 2.0237795447790496

Epoch: 6| Step: 3
Training loss: 2.573176383972168
Validation loss: 2.01925987966599

Epoch: 6| Step: 4
Training loss: 2.7678017616271973
Validation loss: 2.0119390410761677

Epoch: 6| Step: 5
Training loss: 1.763554573059082
Validation loss: 2.030314532659387

Epoch: 6| Step: 6
Training loss: 1.7339403629302979
Validation loss: 2.009046294355905

Epoch: 6| Step: 7
Training loss: 1.9566011428833008
Validation loss: 2.024641427942502

Epoch: 6| Step: 8
Training loss: 2.217500686645508
Validation loss: 2.030236195492488

Epoch: 6| Step: 9
Training loss: 2.2058887481689453
Validation loss: 2.014737122802324

Epoch: 6| Step: 10
Training loss: 2.7957160472869873
Validation loss: 2.018896242623688

Epoch: 6| Step: 11
Training loss: 2.928912401199341
Validation loss: 2.0156459846804218

Epoch: 6| Step: 12
Training loss: 2.272988796234131
Validation loss: 2.0220401081987607

Epoch: 6| Step: 13
Training loss: 2.218050241470337
Validation loss: 2.009747120641893

Epoch: 36| Step: 0
Training loss: 2.1497018337249756
Validation loss: 2.029451713767103

Epoch: 6| Step: 1
Training loss: 2.7450990676879883
Validation loss: 2.029552771199134

Epoch: 6| Step: 2
Training loss: 2.6372554302215576
Validation loss: 2.018149680988763

Epoch: 6| Step: 3
Training loss: 2.6675806045532227
Validation loss: 2.026518039805915

Epoch: 6| Step: 4
Training loss: 2.7569522857666016
Validation loss: 2.0252819304825156

Epoch: 6| Step: 5
Training loss: 1.8954508304595947
Validation loss: 2.0204411911708053

Epoch: 6| Step: 6
Training loss: 2.731696128845215
Validation loss: 2.0285320012800154

Epoch: 6| Step: 7
Training loss: 2.4547910690307617
Validation loss: 2.0184665418440297

Epoch: 6| Step: 8
Training loss: 2.0575063228607178
Validation loss: 2.0417164166768393

Epoch: 6| Step: 9
Training loss: 1.6745634078979492
Validation loss: 2.026573900253542

Epoch: 6| Step: 10
Training loss: 2.0759029388427734
Validation loss: 2.0193115485611783

Epoch: 6| Step: 11
Training loss: 2.1641178131103516
Validation loss: 2.022913976382184

Epoch: 6| Step: 12
Training loss: 2.4092776775360107
Validation loss: 2.0260776858175955

Epoch: 6| Step: 13
Training loss: 3.310999631881714
Validation loss: 2.0226620640805972

Epoch: 37| Step: 0
Training loss: 1.5999603271484375
Validation loss: 2.017854485460507

Epoch: 6| Step: 1
Training loss: 2.5502800941467285
Validation loss: 2.0078574213930356

Epoch: 6| Step: 2
Training loss: 2.3554420471191406
Validation loss: 2.0273248777594617

Epoch: 6| Step: 3
Training loss: 2.0307273864746094
Validation loss: 2.034048634190713

Epoch: 6| Step: 4
Training loss: 2.1388893127441406
Validation loss: 2.0172268575237644

Epoch: 6| Step: 5
Training loss: 2.2346315383911133
Validation loss: 2.0184334208888393

Epoch: 6| Step: 6
Training loss: 3.3260855674743652
Validation loss: 2.023006900664299

Epoch: 6| Step: 7
Training loss: 2.0470621585845947
Validation loss: 2.03387043681196

Epoch: 6| Step: 8
Training loss: 2.0993688106536865
Validation loss: 2.0275415246204664

Epoch: 6| Step: 9
Training loss: 2.9772725105285645
Validation loss: 2.0174401870337864

Epoch: 6| Step: 10
Training loss: 2.689448118209839
Validation loss: 2.0262654750577864

Epoch: 6| Step: 11
Training loss: 2.352909564971924
Validation loss: 2.026408480059716

Epoch: 6| Step: 12
Training loss: 2.3184704780578613
Validation loss: 2.0101042844915904

Epoch: 6| Step: 13
Training loss: 2.8607676029205322
Validation loss: 2.02963876083333

Epoch: 38| Step: 0
Training loss: 1.9856348037719727
Validation loss: 2.0396874643141225

Epoch: 6| Step: 1
Training loss: 1.8252198696136475
Validation loss: 2.0232935156873477

Epoch: 6| Step: 2
Training loss: 2.4508683681488037
Validation loss: 2.027298870907035

Epoch: 6| Step: 3
Training loss: 2.2659616470336914
Validation loss: 2.016364569305092

Epoch: 6| Step: 4
Training loss: 2.533216953277588
Validation loss: 2.0282486779715425

Epoch: 6| Step: 5
Training loss: 2.408592700958252
Validation loss: 2.029906165215277

Epoch: 6| Step: 6
Training loss: 3.007807731628418
Validation loss: 2.003678483347739

Epoch: 6| Step: 7
Training loss: 2.603811264038086
Validation loss: 2.00961148354315

Epoch: 6| Step: 8
Training loss: 2.6331379413604736
Validation loss: 2.021916884247975

Epoch: 6| Step: 9
Training loss: 2.154848575592041
Validation loss: 2.0250988929502425

Epoch: 6| Step: 10
Training loss: 1.8756749629974365
Validation loss: 2.033907216082337

Epoch: 6| Step: 11
Training loss: 2.7257285118103027
Validation loss: 2.026993125997564

Epoch: 6| Step: 12
Training loss: 2.2849435806274414
Validation loss: 2.0231167180563814

Epoch: 6| Step: 13
Training loss: 2.4876604080200195
Validation loss: 2.0124843812757924

Epoch: 39| Step: 0
Training loss: 2.2055962085723877
Validation loss: 2.018151820346873

Epoch: 6| Step: 1
Training loss: 3.0702013969421387
Validation loss: 2.0227986330627115

Epoch: 6| Step: 2
Training loss: 2.488173007965088
Validation loss: 2.0243093903346727

Epoch: 6| Step: 3
Training loss: 2.4214372634887695
Validation loss: 2.009792529126649

Epoch: 6| Step: 4
Training loss: 2.614413261413574
Validation loss: 2.019765894900086

Epoch: 6| Step: 5
Training loss: 2.6676416397094727
Validation loss: 2.0320036078012116

Epoch: 6| Step: 6
Training loss: 1.7989678382873535
Validation loss: 2.0261692308610484

Epoch: 6| Step: 7
Training loss: 2.6310324668884277
Validation loss: 1.997589688147268

Epoch: 6| Step: 8
Training loss: 2.320767402648926
Validation loss: 2.0274040135004188

Epoch: 6| Step: 9
Training loss: 1.9153938293457031
Validation loss: 2.0147860165565246

Epoch: 6| Step: 10
Training loss: 2.2731773853302
Validation loss: 2.032332815149779

Epoch: 6| Step: 11
Training loss: 2.9389047622680664
Validation loss: 2.0212105345982376

Epoch: 6| Step: 12
Training loss: 1.9147753715515137
Validation loss: 1.9943736342973606

Epoch: 6| Step: 13
Training loss: 1.5404086112976074
Validation loss: 2.010636560378536

Epoch: 40| Step: 0
Training loss: 2.132538318634033
Validation loss: 2.0097577110413583

Epoch: 6| Step: 1
Training loss: 1.9212740659713745
Validation loss: 2.0061735581326228

Epoch: 6| Step: 2
Training loss: 2.554702043533325
Validation loss: 2.01181306633898

Epoch: 6| Step: 3
Training loss: 2.218695878982544
Validation loss: 2.0080935583319715

Epoch: 6| Step: 4
Training loss: 2.2163572311401367
Validation loss: 2.003146771461733

Epoch: 6| Step: 5
Training loss: 2.2567598819732666
Validation loss: 2.000972132528982

Epoch: 6| Step: 6
Training loss: 2.3987317085266113
Validation loss: 1.9979101662994714

Epoch: 6| Step: 7
Training loss: 2.2660486698150635
Validation loss: 1.9997849067052205

Epoch: 6| Step: 8
Training loss: 3.327432632446289
Validation loss: 1.9955733873510872

Epoch: 6| Step: 9
Training loss: 2.698391914367676
Validation loss: 1.984806619664674

Epoch: 6| Step: 10
Training loss: 2.2147841453552246
Validation loss: 1.9943583293627667

Epoch: 6| Step: 11
Training loss: 2.1373159885406494
Validation loss: 1.9942847990220594

Epoch: 6| Step: 12
Training loss: 1.6856958866119385
Validation loss: 1.981618704334382

Epoch: 6| Step: 13
Training loss: 3.7758631706237793
Validation loss: 1.9865612752975956

Epoch: 41| Step: 0
Training loss: 2.602407217025757
Validation loss: 1.9851653370805966

Epoch: 6| Step: 1
Training loss: 2.3325726985931396
Validation loss: 1.9953296799813547

Epoch: 6| Step: 2
Training loss: 2.1127753257751465
Validation loss: 2.0035018267170077

Epoch: 6| Step: 3
Training loss: 2.6145710945129395
Validation loss: 1.991956498033257

Epoch: 6| Step: 4
Training loss: 1.812747836112976
Validation loss: 1.9850596638136013

Epoch: 6| Step: 5
Training loss: 2.656127691268921
Validation loss: 2.006457057050479

Epoch: 6| Step: 6
Training loss: 2.0739564895629883
Validation loss: 1.9878140354669223

Epoch: 6| Step: 7
Training loss: 2.4795119762420654
Validation loss: 1.9997290154939056

Epoch: 6| Step: 8
Training loss: 2.4223592281341553
Validation loss: 1.990073129694949

Epoch: 6| Step: 9
Training loss: 1.713211178779602
Validation loss: 1.9965821312319847

Epoch: 6| Step: 10
Training loss: 2.7288804054260254
Validation loss: 1.9980063130778651

Epoch: 6| Step: 11
Training loss: 2.3260984420776367
Validation loss: 1.9930840205120783

Epoch: 6| Step: 12
Training loss: 2.485934257507324
Validation loss: 2.0055798497251285

Epoch: 6| Step: 13
Training loss: 2.8486623764038086
Validation loss: 1.9907380586029382

Epoch: 42| Step: 0
Training loss: 2.4360647201538086
Validation loss: 2.0000779564662645

Epoch: 6| Step: 1
Training loss: 2.2713537216186523
Validation loss: 1.9980350617439515

Epoch: 6| Step: 2
Training loss: 2.2956414222717285
Validation loss: 1.9913953914437243

Epoch: 6| Step: 3
Training loss: 3.0129311084747314
Validation loss: 1.9914159928598711

Epoch: 6| Step: 4
Training loss: 2.265993356704712
Validation loss: 1.989466518484136

Epoch: 6| Step: 5
Training loss: 2.3278584480285645
Validation loss: 1.986732973847338

Epoch: 6| Step: 6
Training loss: 2.1904683113098145
Validation loss: 2.007867192709318

Epoch: 6| Step: 7
Training loss: 2.1985526084899902
Validation loss: 1.9926879290611512

Epoch: 6| Step: 8
Training loss: 2.128352642059326
Validation loss: 2.0024026414399505

Epoch: 6| Step: 9
Training loss: 2.3882265090942383
Validation loss: 2.0010002325939875

Epoch: 6| Step: 10
Training loss: 2.191387176513672
Validation loss: 2.0003913410248293

Epoch: 6| Step: 11
Training loss: 2.3305788040161133
Validation loss: 1.995931794566493

Epoch: 6| Step: 12
Training loss: 2.34147310256958
Validation loss: 1.9740625184069398

Epoch: 6| Step: 13
Training loss: 2.911628246307373
Validation loss: 1.9973178307215373

Epoch: 43| Step: 0
Training loss: 1.6543405055999756
Validation loss: 1.999998793807081

Epoch: 6| Step: 1
Training loss: 2.212355852127075
Validation loss: 1.9885561414944228

Epoch: 6| Step: 2
Training loss: 2.7070553302764893
Validation loss: 1.9896645545959473

Epoch: 6| Step: 3
Training loss: 2.2788758277893066
Validation loss: 2.0005710496697375

Epoch: 6| Step: 4
Training loss: 2.260901927947998
Validation loss: 1.9860977588161346

Epoch: 6| Step: 5
Training loss: 2.4889936447143555
Validation loss: 1.977899529600656

Epoch: 6| Step: 6
Training loss: 2.0272600650787354
Validation loss: 1.974719883293234

Epoch: 6| Step: 7
Training loss: 2.178314447402954
Validation loss: 1.993003919560422

Epoch: 6| Step: 8
Training loss: 2.9922075271606445
Validation loss: 1.991769101030083

Epoch: 6| Step: 9
Training loss: 2.961148500442505
Validation loss: 1.9723752390953802

Epoch: 6| Step: 10
Training loss: 2.9400317668914795
Validation loss: 2.0168266604023595

Epoch: 6| Step: 11
Training loss: 2.0301997661590576
Validation loss: 1.974127040114454

Epoch: 6| Step: 12
Training loss: 2.3341946601867676
Validation loss: 1.979876789995419

Epoch: 6| Step: 13
Training loss: 1.718390941619873
Validation loss: 1.9692668684067265

Epoch: 44| Step: 0
Training loss: 2.474369525909424
Validation loss: 1.987878135455552

Epoch: 6| Step: 1
Training loss: 1.682395100593567
Validation loss: 1.9924657831909836

Epoch: 6| Step: 2
Training loss: 2.8385767936706543
Validation loss: 1.9899365555855535

Epoch: 6| Step: 3
Training loss: 1.286279559135437
Validation loss: 1.9831757109652284

Epoch: 6| Step: 4
Training loss: 2.117033004760742
Validation loss: 1.9999146692214473

Epoch: 6| Step: 5
Training loss: 2.419360876083374
Validation loss: 1.995478727484262

Epoch: 6| Step: 6
Training loss: 2.1911168098449707
Validation loss: 1.9883616508976105

Epoch: 6| Step: 7
Training loss: 2.654831886291504
Validation loss: 1.9849451985410465

Epoch: 6| Step: 8
Training loss: 2.1495330333709717
Validation loss: 1.9961322405005013

Epoch: 6| Step: 9
Training loss: 3.034531593322754
Validation loss: 1.9901472445457213

Epoch: 6| Step: 10
Training loss: 2.7797646522521973
Validation loss: 1.971434829055622

Epoch: 6| Step: 11
Training loss: 2.5626258850097656
Validation loss: 1.9986710804764942

Epoch: 6| Step: 12
Training loss: 2.5537853240966797
Validation loss: 1.9755006041578067

Epoch: 6| Step: 13
Training loss: 1.8731350898742676
Validation loss: 1.9876261680356917

Epoch: 45| Step: 0
Training loss: 2.049574375152588
Validation loss: 2.0105988671702724

Epoch: 6| Step: 1
Training loss: 2.7254738807678223
Validation loss: 1.9938244140276344

Epoch: 6| Step: 2
Training loss: 2.7748970985412598
Validation loss: 1.9955201302805254

Epoch: 6| Step: 3
Training loss: 2.6528658866882324
Validation loss: 1.9930406667852913

Epoch: 6| Step: 4
Training loss: 2.6045303344726562
Validation loss: 1.9932761910141155

Epoch: 6| Step: 5
Training loss: 2.6043548583984375
Validation loss: 1.9918953834041473

Epoch: 6| Step: 6
Training loss: 2.5787594318389893
Validation loss: 2.0109993962831396

Epoch: 6| Step: 7
Training loss: 1.8657023906707764
Validation loss: 2.0025474102266374

Epoch: 6| Step: 8
Training loss: 1.9085878133773804
Validation loss: 2.0149149458895446

Epoch: 6| Step: 9
Training loss: 2.634875774383545
Validation loss: 2.0241044516204507

Epoch: 6| Step: 10
Training loss: 2.1348419189453125
Validation loss: 2.0041476180476527

Epoch: 6| Step: 11
Training loss: 1.3478528261184692
Validation loss: 1.9943268786194503

Epoch: 6| Step: 12
Training loss: 2.2474923133850098
Validation loss: 2.0178716310890774

Epoch: 6| Step: 13
Training loss: 2.9046237468719482
Validation loss: 1.9970484446453791

Epoch: 46| Step: 0
Training loss: 1.5578635931015015
Validation loss: 2.0091239713853404

Epoch: 6| Step: 1
Training loss: 3.36698579788208
Validation loss: 2.003498979794082

Epoch: 6| Step: 2
Training loss: 2.6094167232513428
Validation loss: 2.0045091323955084

Epoch: 6| Step: 3
Training loss: 2.323099136352539
Validation loss: 1.9966509342193604

Epoch: 6| Step: 4
Training loss: 2.628612518310547
Validation loss: 2.0062755820571736

Epoch: 6| Step: 5
Training loss: 2.1941065788269043
Validation loss: 2.010017893647635

Epoch: 6| Step: 6
Training loss: 2.2930867671966553
Validation loss: 2.0024569598577355

Epoch: 6| Step: 7
Training loss: 2.683163642883301
Validation loss: 1.9914091005120227

Epoch: 6| Step: 8
Training loss: 1.8421454429626465
Validation loss: 1.9786747835015739

Epoch: 6| Step: 9
Training loss: 2.7013485431671143
Validation loss: 1.9706873111827399

Epoch: 6| Step: 10
Training loss: 1.4675683975219727
Validation loss: 1.9727148291885213

Epoch: 6| Step: 11
Training loss: 2.4242095947265625
Validation loss: 1.9783343525343045

Epoch: 6| Step: 12
Training loss: 2.4695968627929688
Validation loss: 1.9818131180219754

Epoch: 6| Step: 13
Training loss: 2.2355949878692627
Validation loss: 1.9792470316733084

Epoch: 47| Step: 0
Training loss: 2.530388355255127
Validation loss: 1.98306010230895

Epoch: 6| Step: 1
Training loss: 2.1812667846679688
Validation loss: 1.99619722366333

Epoch: 6| Step: 2
Training loss: 2.2314553260803223
Validation loss: 1.9920207454312233

Epoch: 6| Step: 3
Training loss: 2.242192506790161
Validation loss: 1.9891743531791113

Epoch: 6| Step: 4
Training loss: 2.448517322540283
Validation loss: 1.988880834271831

Epoch: 6| Step: 5
Training loss: 2.773041248321533
Validation loss: 1.9781194784307992

Epoch: 6| Step: 6
Training loss: 2.510159492492676
Validation loss: 1.9877919714937928

Epoch: 6| Step: 7
Training loss: 1.9435843229293823
Validation loss: 1.9861165285110474

Epoch: 6| Step: 8
Training loss: 2.3770694732666016
Validation loss: 1.9909789741680186

Epoch: 6| Step: 9
Training loss: 2.1257405281066895
Validation loss: 1.9720917581230082

Epoch: 6| Step: 10
Training loss: 2.4025559425354004
Validation loss: 1.9942118967733076

Epoch: 6| Step: 11
Training loss: 2.226656198501587
Validation loss: 1.9683833993891233

Epoch: 6| Step: 12
Training loss: 2.8608579635620117
Validation loss: 1.9777081384453723

Epoch: 6| Step: 13
Training loss: 1.5986254215240479
Validation loss: 1.9884710170889413

Epoch: 48| Step: 0
Training loss: 2.8946943283081055
Validation loss: 1.9797820737285

Epoch: 6| Step: 1
Training loss: 2.5163040161132812
Validation loss: 1.9879317104175527

Epoch: 6| Step: 2
Training loss: 1.8803844451904297
Validation loss: 1.9836098096703971

Epoch: 6| Step: 3
Training loss: 2.42096209526062
Validation loss: 1.9835676762365526

Epoch: 6| Step: 4
Training loss: 1.817582368850708
Validation loss: 1.9905246303927513

Epoch: 6| Step: 5
Training loss: 1.841469168663025
Validation loss: 1.9896234645638415

Epoch: 6| Step: 6
Training loss: 2.0509915351867676
Validation loss: 1.983997687216728

Epoch: 6| Step: 7
Training loss: 3.0369391441345215
Validation loss: 1.988194533573684

Epoch: 6| Step: 8
Training loss: 2.766525983810425
Validation loss: 1.9664140209074943

Epoch: 6| Step: 9
Training loss: 1.966687798500061
Validation loss: 1.981659496984174

Epoch: 6| Step: 10
Training loss: 2.0904829502105713
Validation loss: 1.9852788961061867

Epoch: 6| Step: 11
Training loss: 2.2154862880706787
Validation loss: 1.987639404112293

Epoch: 6| Step: 12
Training loss: 2.7156832218170166
Validation loss: 1.9897971230168496

Epoch: 6| Step: 13
Training loss: 2.6042776107788086
Validation loss: 1.9885214182638353

Epoch: 49| Step: 0
Training loss: 1.7783284187316895
Validation loss: 1.9754892241570257

Epoch: 6| Step: 1
Training loss: 1.7957420349121094
Validation loss: 1.9910296778525076

Epoch: 6| Step: 2
Training loss: 2.380268096923828
Validation loss: 1.983208425583378

Epoch: 6| Step: 3
Training loss: 2.8259408473968506
Validation loss: 1.9949257219991376

Epoch: 6| Step: 4
Training loss: 2.0968661308288574
Validation loss: 1.9716871092396397

Epoch: 6| Step: 5
Training loss: 2.981330156326294
Validation loss: 1.999942143758138

Epoch: 6| Step: 6
Training loss: 2.4011316299438477
Validation loss: 1.9888457636679373

Epoch: 6| Step: 7
Training loss: 2.6798462867736816
Validation loss: 1.9864123098311885

Epoch: 6| Step: 8
Training loss: 2.7665047645568848
Validation loss: 1.9910769283130605

Epoch: 6| Step: 9
Training loss: 2.4484496116638184
Validation loss: 1.9873452814676429

Epoch: 6| Step: 10
Training loss: 1.7160640954971313
Validation loss: 1.969273824845591

Epoch: 6| Step: 11
Training loss: 1.6760221719741821
Validation loss: 1.977758094828616

Epoch: 6| Step: 12
Training loss: 2.4553780555725098
Validation loss: 1.9684726333105436

Epoch: 6| Step: 13
Training loss: 2.9672627449035645
Validation loss: 1.9755438989208591

Epoch: 50| Step: 0
Training loss: 2.668300151824951
Validation loss: 1.992442641206967

Epoch: 6| Step: 1
Training loss: 2.501267433166504
Validation loss: 1.9608573452118905

Epoch: 6| Step: 2
Training loss: 2.60001277923584
Validation loss: 1.9670362036715272

Epoch: 6| Step: 3
Training loss: 2.201367139816284
Validation loss: 1.970747386255572

Epoch: 6| Step: 4
Training loss: 2.707735538482666
Validation loss: 1.9851516049395326

Epoch: 6| Step: 5
Training loss: 2.8428797721862793
Validation loss: 1.9808769456801876

Epoch: 6| Step: 6
Training loss: 1.9337544441223145
Validation loss: 1.9686347246170044

Epoch: 6| Step: 7
Training loss: 2.2199630737304688
Validation loss: 1.9716956717993623

Epoch: 6| Step: 8
Training loss: 1.5459083318710327
Validation loss: 1.9597417462256648

Epoch: 6| Step: 9
Training loss: 2.3978753089904785
Validation loss: 1.9572886202924995

Epoch: 6| Step: 10
Training loss: 1.8625264167785645
Validation loss: 1.97266649687162

Epoch: 6| Step: 11
Training loss: 2.200101852416992
Validation loss: 1.9761330658389675

Epoch: 6| Step: 12
Training loss: 2.511873245239258
Validation loss: 1.9713096823743594

Epoch: 6| Step: 13
Training loss: 2.263716697692871
Validation loss: 1.9754516283671062

Epoch: 51| Step: 0
Training loss: 1.9593843221664429
Validation loss: 1.9805184397646176

Epoch: 6| Step: 1
Training loss: 1.9102290868759155
Validation loss: 1.9673192642068351

Epoch: 6| Step: 2
Training loss: 2.505796432495117
Validation loss: 1.9700900918693953

Epoch: 6| Step: 3
Training loss: 2.851996421813965
Validation loss: 1.9713653364489157

Epoch: 6| Step: 4
Training loss: 2.795401096343994
Validation loss: 1.9565780957539876

Epoch: 6| Step: 5
Training loss: 2.460249900817871
Validation loss: 1.953406592851044

Epoch: 6| Step: 6
Training loss: 2.6036555767059326
Validation loss: 1.940336449171907

Epoch: 6| Step: 7
Training loss: 2.0310773849487305
Validation loss: 1.9733571724225116

Epoch: 6| Step: 8
Training loss: 2.6531596183776855
Validation loss: 1.956633024318244

Epoch: 6| Step: 9
Training loss: 2.2625443935394287
Validation loss: 1.961278857723359

Epoch: 6| Step: 10
Training loss: 1.6116684675216675
Validation loss: 1.9622291993069392

Epoch: 6| Step: 11
Training loss: 2.4732260704040527
Validation loss: 1.9703110930740193

Epoch: 6| Step: 12
Training loss: 1.589897871017456
Validation loss: 1.9630488939182733

Epoch: 6| Step: 13
Training loss: 3.1184167861938477
Validation loss: 1.96169828086771

Epoch: 52| Step: 0
Training loss: 2.834582567214966
Validation loss: 1.9682808499182425

Epoch: 6| Step: 1
Training loss: 1.978554368019104
Validation loss: 1.9570428530375164

Epoch: 6| Step: 2
Training loss: 1.9569169282913208
Validation loss: 1.9671203321026218

Epoch: 6| Step: 3
Training loss: 2.2439422607421875
Validation loss: 1.962454238245564

Epoch: 6| Step: 4
Training loss: 2.916083335876465
Validation loss: 1.945959242441321

Epoch: 6| Step: 5
Training loss: 1.8542084693908691
Validation loss: 1.9592931603872648

Epoch: 6| Step: 6
Training loss: 2.0849833488464355
Validation loss: 1.9590711529536913

Epoch: 6| Step: 7
Training loss: 2.9548869132995605
Validation loss: 1.96178267335379

Epoch: 6| Step: 8
Training loss: 2.7204952239990234
Validation loss: 1.970699587175923

Epoch: 6| Step: 9
Training loss: 2.1166164875030518
Validation loss: 1.9699742306945145

Epoch: 6| Step: 10
Training loss: 2.0712203979492188
Validation loss: 1.9724502332748906

Epoch: 6| Step: 11
Training loss: 2.419598340988159
Validation loss: 1.970857456166257

Epoch: 6| Step: 12
Training loss: 1.6705210208892822
Validation loss: 1.9584066778100946

Epoch: 6| Step: 13
Training loss: 2.837822437286377
Validation loss: 1.9766026850669616

Epoch: 53| Step: 0
Training loss: 1.9798170328140259
Validation loss: 1.9683392791337864

Epoch: 6| Step: 1
Training loss: 2.1248364448547363
Validation loss: 1.9658753397644206

Epoch: 6| Step: 2
Training loss: 2.9657435417175293
Validation loss: 1.957020305818127

Epoch: 6| Step: 3
Training loss: 2.2898457050323486
Validation loss: 1.964202380949451

Epoch: 6| Step: 4
Training loss: 2.276148796081543
Validation loss: 1.9612778822580974

Epoch: 6| Step: 5
Training loss: 2.3491344451904297
Validation loss: 1.944080655292798

Epoch: 6| Step: 6
Training loss: 2.461292266845703
Validation loss: 1.9788767701836043

Epoch: 6| Step: 7
Training loss: 2.3325023651123047
Validation loss: 1.9546199370455999

Epoch: 6| Step: 8
Training loss: 2.3389780521392822
Validation loss: 1.975124784695205

Epoch: 6| Step: 9
Training loss: 3.1260666847229004
Validation loss: 1.9691119309394591

Epoch: 6| Step: 10
Training loss: 1.9192373752593994
Validation loss: 1.9838403501818258

Epoch: 6| Step: 11
Training loss: 2.049149990081787
Validation loss: 1.9717173909628263

Epoch: 6| Step: 12
Training loss: 2.157864809036255
Validation loss: 1.9878834114279798

Epoch: 6| Step: 13
Training loss: 1.9050339460372925
Validation loss: 1.9833847707317722

Epoch: 54| Step: 0
Training loss: 2.812304973602295
Validation loss: 1.971542735253611

Epoch: 6| Step: 1
Training loss: 2.2786307334899902
Validation loss: 1.9688238072138962

Epoch: 6| Step: 2
Training loss: 2.3777151107788086
Validation loss: 1.9577460314637871

Epoch: 6| Step: 3
Training loss: 2.0774683952331543
Validation loss: 1.9652327337572653

Epoch: 6| Step: 4
Training loss: 2.251923084259033
Validation loss: 1.9595270285042383

Epoch: 6| Step: 5
Training loss: 2.2179136276245117
Validation loss: 1.9647527484483616

Epoch: 6| Step: 6
Training loss: 2.338714122772217
Validation loss: 1.9412824466664305

Epoch: 6| Step: 7
Training loss: 2.1329307556152344
Validation loss: 1.9702631376122917

Epoch: 6| Step: 8
Training loss: 2.072086811065674
Validation loss: 1.948036504048173

Epoch: 6| Step: 9
Training loss: 2.8933653831481934
Validation loss: 1.9358797150273477

Epoch: 6| Step: 10
Training loss: 2.8427672386169434
Validation loss: 1.94973712582742

Epoch: 6| Step: 11
Training loss: 1.8234689235687256
Validation loss: 1.9550104115598945

Epoch: 6| Step: 12
Training loss: 2.17692494392395
Validation loss: 1.9456650774966004

Epoch: 6| Step: 13
Training loss: 2.0226705074310303
Validation loss: 1.931264413300381

Epoch: 55| Step: 0
Training loss: 2.0125198364257812
Validation loss: 1.95504544883646

Epoch: 6| Step: 1
Training loss: 2.6981678009033203
Validation loss: 1.9584939120918192

Epoch: 6| Step: 2
Training loss: 2.638503074645996
Validation loss: 1.9531948540800361

Epoch: 6| Step: 3
Training loss: 2.231827974319458
Validation loss: 1.9449354640899166

Epoch: 6| Step: 4
Training loss: 2.1062324047088623
Validation loss: 1.9730711778004963

Epoch: 6| Step: 5
Training loss: 2.0898940563201904
Validation loss: 1.960510661525111

Epoch: 6| Step: 6
Training loss: 2.5674095153808594
Validation loss: 1.9667020433692521

Epoch: 6| Step: 7
Training loss: 2.085947275161743
Validation loss: 1.9692351946266748

Epoch: 6| Step: 8
Training loss: 2.2372584342956543
Validation loss: 1.9630494322828067

Epoch: 6| Step: 9
Training loss: 1.8177635669708252
Validation loss: 1.9667761248926963

Epoch: 6| Step: 10
Training loss: 2.7344822883605957
Validation loss: 1.967562621639621

Epoch: 6| Step: 11
Training loss: 2.4005908966064453
Validation loss: 1.9770794299341017

Epoch: 6| Step: 12
Training loss: 2.2037975788116455
Validation loss: 1.9699767251168527

Epoch: 6| Step: 13
Training loss: 2.7282168865203857
Validation loss: 1.9565178296899284

Epoch: 56| Step: 0
Training loss: 1.9887709617614746
Validation loss: 1.9796242034563454

Epoch: 6| Step: 1
Training loss: 2.1213738918304443
Validation loss: 1.9738267006412629

Epoch: 6| Step: 2
Training loss: 2.12031888961792
Validation loss: 1.9502107661257508

Epoch: 6| Step: 3
Training loss: 2.9063587188720703
Validation loss: 1.9728894310612832

Epoch: 6| Step: 4
Training loss: 2.60628080368042
Validation loss: 1.964774723975889

Epoch: 6| Step: 5
Training loss: 2.358145236968994
Validation loss: 1.976488080075992

Epoch: 6| Step: 6
Training loss: 1.9646477699279785
Validation loss: 1.9547253731758363

Epoch: 6| Step: 7
Training loss: 2.557109832763672
Validation loss: 1.9618802608982209

Epoch: 6| Step: 8
Training loss: 2.2068326473236084
Validation loss: 1.9721911389340636

Epoch: 6| Step: 9
Training loss: 2.475193500518799
Validation loss: 1.948519190152486

Epoch: 6| Step: 10
Training loss: 2.0619683265686035
Validation loss: 1.9524449533031834

Epoch: 6| Step: 11
Training loss: 2.6564273834228516
Validation loss: 1.9687946547744095

Epoch: 6| Step: 12
Training loss: 1.9432686567306519
Validation loss: 1.97470018171495

Epoch: 6| Step: 13
Training loss: 2.2814228534698486
Validation loss: 1.988299979958483

Epoch: 57| Step: 0
Training loss: 2.2839083671569824
Validation loss: 1.9605048010426183

Epoch: 6| Step: 1
Training loss: 2.633676767349243
Validation loss: 1.9723023137738627

Epoch: 6| Step: 2
Training loss: 2.4536943435668945
Validation loss: 1.9588353864608272

Epoch: 6| Step: 3
Training loss: 2.315319061279297
Validation loss: 1.9533621636770104

Epoch: 6| Step: 4
Training loss: 1.955726146697998
Validation loss: 1.958534291995469

Epoch: 6| Step: 5
Training loss: 2.2486886978149414
Validation loss: 1.9627341044846403

Epoch: 6| Step: 6
Training loss: 2.770935297012329
Validation loss: 1.9606636583164174

Epoch: 6| Step: 7
Training loss: 2.2541675567626953
Validation loss: 1.9601743734011086

Epoch: 6| Step: 8
Training loss: 2.630551338195801
Validation loss: 1.9505371598787205

Epoch: 6| Step: 9
Training loss: 2.254180431365967
Validation loss: 1.942321510725124

Epoch: 6| Step: 10
Training loss: 1.5324468612670898
Validation loss: 1.9371501502170358

Epoch: 6| Step: 11
Training loss: 2.067789316177368
Validation loss: 1.9440413777546217

Epoch: 6| Step: 12
Training loss: 2.431245803833008
Validation loss: 1.9313291452264274

Epoch: 6| Step: 13
Training loss: 2.18304443359375
Validation loss: 1.9400956015433035

Epoch: 58| Step: 0
Training loss: 2.6742849349975586
Validation loss: 1.9490807646064348

Epoch: 6| Step: 1
Training loss: 1.7343040704727173
Validation loss: 1.9451421255706458

Epoch: 6| Step: 2
Training loss: 2.2141127586364746
Validation loss: 1.942099908346771

Epoch: 6| Step: 3
Training loss: 2.665043830871582
Validation loss: 1.9407767249691872

Epoch: 6| Step: 4
Training loss: 1.8216618299484253
Validation loss: 1.943680852972051

Epoch: 6| Step: 5
Training loss: 2.306286573410034
Validation loss: 1.9543567575434202

Epoch: 6| Step: 6
Training loss: 2.562037467956543
Validation loss: 1.9423028422940163

Epoch: 6| Step: 7
Training loss: 2.097780704498291
Validation loss: 1.962723301303002

Epoch: 6| Step: 8
Training loss: 2.6018481254577637
Validation loss: 1.94006089497638

Epoch: 6| Step: 9
Training loss: 2.8155970573425293
Validation loss: 1.935480543362197

Epoch: 6| Step: 10
Training loss: 2.3383948802948
Validation loss: 1.939000766764405

Epoch: 6| Step: 11
Training loss: 2.2808711528778076
Validation loss: 1.9444802935405443

Epoch: 6| Step: 12
Training loss: 1.6874167919158936
Validation loss: 1.9568899805827806

Epoch: 6| Step: 13
Training loss: 2.3277416229248047
Validation loss: 1.9482950382335211

Epoch: 59| Step: 0
Training loss: 2.4120020866394043
Validation loss: 1.9556534597950597

Epoch: 6| Step: 1
Training loss: 2.323817729949951
Validation loss: 1.9685182340683476

Epoch: 6| Step: 2
Training loss: 2.02091646194458
Validation loss: 1.9551173589562858

Epoch: 6| Step: 3
Training loss: 1.789341688156128
Validation loss: 1.9329403779839958

Epoch: 6| Step: 4
Training loss: 1.7347285747528076
Validation loss: 1.9510486407946515

Epoch: 6| Step: 5
Training loss: 2.386500597000122
Validation loss: 1.9554996862206409

Epoch: 6| Step: 6
Training loss: 2.1669840812683105
Validation loss: 1.9652334387584398

Epoch: 6| Step: 7
Training loss: 1.9842109680175781
Validation loss: 1.9631288166969054

Epoch: 6| Step: 8
Training loss: 2.0153112411499023
Validation loss: 1.9722043980834305

Epoch: 6| Step: 9
Training loss: 2.8866217136383057
Validation loss: 1.9541614452997844

Epoch: 6| Step: 10
Training loss: 2.3557474613189697
Validation loss: 1.951288447585157

Epoch: 6| Step: 11
Training loss: 2.52241849899292
Validation loss: 1.971854507282216

Epoch: 6| Step: 12
Training loss: 2.95931339263916
Validation loss: 1.9466010498744186

Epoch: 6| Step: 13
Training loss: 2.5815820693969727
Validation loss: 1.9456226389895204

Epoch: 60| Step: 0
Training loss: 1.8130967617034912
Validation loss: 1.9605105371885403

Epoch: 6| Step: 1
Training loss: 2.4289350509643555
Validation loss: 1.938574537154167

Epoch: 6| Step: 2
Training loss: 2.3029093742370605
Validation loss: 1.961794178972962

Epoch: 6| Step: 3
Training loss: 1.9376282691955566
Validation loss: 1.9570774160405642

Epoch: 6| Step: 4
Training loss: 3.0132651329040527
Validation loss: 1.942025525595552

Epoch: 6| Step: 5
Training loss: 1.7039910554885864
Validation loss: 1.9561011534865185

Epoch: 6| Step: 6
Training loss: 2.1397359371185303
Validation loss: 1.9515593744093371

Epoch: 6| Step: 7
Training loss: 2.6656265258789062
Validation loss: 1.9471485922413487

Epoch: 6| Step: 8
Training loss: 2.0708425045013428
Validation loss: 1.9753789760733163

Epoch: 6| Step: 9
Training loss: 2.669896125793457
Validation loss: 1.9488169339395338

Epoch: 6| Step: 10
Training loss: 1.813669204711914
Validation loss: 1.9570788132247103

Epoch: 6| Step: 11
Training loss: 2.129937171936035
Validation loss: 1.9486779410351989

Epoch: 6| Step: 12
Training loss: 2.7013888359069824
Validation loss: 1.9594472121166926

Epoch: 6| Step: 13
Training loss: 2.9608395099639893
Validation loss: 1.9570335700947752

Epoch: 61| Step: 0
Training loss: 2.5773816108703613
Validation loss: 1.9677804618753412

Epoch: 6| Step: 1
Training loss: 2.363520860671997
Validation loss: 1.9561307891722648

Epoch: 6| Step: 2
Training loss: 2.6987955570220947
Validation loss: 1.9559907938844414

Epoch: 6| Step: 3
Training loss: 2.2569639682769775
Validation loss: 1.968767084101195

Epoch: 6| Step: 4
Training loss: 2.607649326324463
Validation loss: 1.968049491605451

Epoch: 6| Step: 5
Training loss: 2.570174217224121
Validation loss: 1.955512926142703

Epoch: 6| Step: 6
Training loss: 2.53963565826416
Validation loss: 1.9589878333512174

Epoch: 6| Step: 7
Training loss: 2.3581395149230957
Validation loss: 1.952765683973989

Epoch: 6| Step: 8
Training loss: 1.8598467111587524
Validation loss: 1.9630548800191572

Epoch: 6| Step: 9
Training loss: 1.9631061553955078
Validation loss: 1.9678406446210799

Epoch: 6| Step: 10
Training loss: 1.885321021080017
Validation loss: 1.9642326344725907

Epoch: 6| Step: 11
Training loss: 2.348681926727295
Validation loss: 1.9557523201870661

Epoch: 6| Step: 12
Training loss: 2.0725512504577637
Validation loss: 1.9504866369308964

Epoch: 6| Step: 13
Training loss: 1.6773008108139038
Validation loss: 1.978366518533358

Epoch: 62| Step: 0
Training loss: 1.667601466178894
Validation loss: 1.9633749223524524

Epoch: 6| Step: 1
Training loss: 2.4578115940093994
Validation loss: 1.9582905718075332

Epoch: 6| Step: 2
Training loss: 3.2586565017700195
Validation loss: 1.9612528406163698

Epoch: 6| Step: 3
Training loss: 2.1508660316467285
Validation loss: 1.9484122824925247

Epoch: 6| Step: 4
Training loss: 1.5296037197113037
Validation loss: 1.956681707853912

Epoch: 6| Step: 5
Training loss: 2.72102689743042
Validation loss: 1.9655912050636866

Epoch: 6| Step: 6
Training loss: 1.6724238395690918
Validation loss: 1.9460129045671033

Epoch: 6| Step: 7
Training loss: 2.076185941696167
Validation loss: 1.971884476241245

Epoch: 6| Step: 8
Training loss: 2.448333501815796
Validation loss: 1.961510992819263

Epoch: 6| Step: 9
Training loss: 2.03670072555542
Validation loss: 1.9553795963205316

Epoch: 6| Step: 10
Training loss: 2.720202922821045
Validation loss: 1.971119171829634

Epoch: 6| Step: 11
Training loss: 2.438328742980957
Validation loss: 1.956186822665635

Epoch: 6| Step: 12
Training loss: 2.3580448627471924
Validation loss: 1.949467388532495

Epoch: 6| Step: 13
Training loss: 2.6083033084869385
Validation loss: 1.9387378218353435

Epoch: 63| Step: 0
Training loss: 2.422527313232422
Validation loss: 1.955941156674457

Epoch: 6| Step: 1
Training loss: 1.835450291633606
Validation loss: 1.9527451838216474

Epoch: 6| Step: 2
Training loss: 2.37544846534729
Validation loss: 1.9720941769179476

Epoch: 6| Step: 3
Training loss: 1.8812614679336548
Validation loss: 1.9495634084106774

Epoch: 6| Step: 4
Training loss: 2.4402222633361816
Validation loss: 1.9464331057763868

Epoch: 6| Step: 5
Training loss: 2.507193088531494
Validation loss: 1.9501839132719143

Epoch: 6| Step: 6
Training loss: 2.474860668182373
Validation loss: 1.9547616307453444

Epoch: 6| Step: 7
Training loss: 2.5139362812042236
Validation loss: 1.9488105197106638

Epoch: 6| Step: 8
Training loss: 2.235083818435669
Validation loss: 1.9624845109960085

Epoch: 6| Step: 9
Training loss: 2.0808444023132324
Validation loss: 1.9474256371939054

Epoch: 6| Step: 10
Training loss: 1.8987576961517334
Validation loss: 1.9525100108115905

Epoch: 6| Step: 11
Training loss: 2.58548641204834
Validation loss: 1.9516427260573193

Epoch: 6| Step: 12
Training loss: 2.033262252807617
Validation loss: 1.959890636064673

Epoch: 6| Step: 13
Training loss: 2.6022162437438965
Validation loss: 1.953939824975947

Epoch: 64| Step: 0
Training loss: 1.693108081817627
Validation loss: 1.9604709391952844

Epoch: 6| Step: 1
Training loss: 2.917397975921631
Validation loss: 1.948755568073642

Epoch: 6| Step: 2
Training loss: 2.3344998359680176
Validation loss: 1.94959310946926

Epoch: 6| Step: 3
Training loss: 2.6053853034973145
Validation loss: 1.9676990867942892

Epoch: 6| Step: 4
Training loss: 1.537209391593933
Validation loss: 1.9515023205869941

Epoch: 6| Step: 5
Training loss: 2.5679306983947754
Validation loss: 1.9552281043862785

Epoch: 6| Step: 6
Training loss: 2.3014025688171387
Validation loss: 1.9436662927750619

Epoch: 6| Step: 7
Training loss: 2.3729231357574463
Validation loss: 1.960470002184632

Epoch: 6| Step: 8
Training loss: 2.0919034481048584
Validation loss: 1.946599429653537

Epoch: 6| Step: 9
Training loss: 2.292907476425171
Validation loss: 1.9438381451432423

Epoch: 6| Step: 10
Training loss: 2.0564446449279785
Validation loss: 1.9567131432153846

Epoch: 6| Step: 11
Training loss: 2.49344539642334
Validation loss: 1.9527570291232037

Epoch: 6| Step: 12
Training loss: 2.339752197265625
Validation loss: 1.951248748328096

Epoch: 6| Step: 13
Training loss: 2.2175936698913574
Validation loss: 1.9505728521654684

Epoch: 65| Step: 0
Training loss: 2.523721218109131
Validation loss: 1.9506272731288787

Epoch: 6| Step: 1
Training loss: 1.2347817420959473
Validation loss: 1.9583588261758127

Epoch: 6| Step: 2
Training loss: 2.3613438606262207
Validation loss: 1.940827056925784

Epoch: 6| Step: 3
Training loss: 2.2356491088867188
Validation loss: 1.9464768927584413

Epoch: 6| Step: 4
Training loss: 3.1410818099975586
Validation loss: 1.9541597058696132

Epoch: 6| Step: 5
Training loss: 1.823025107383728
Validation loss: 1.963724540125939

Epoch: 6| Step: 6
Training loss: 2.462925434112549
Validation loss: 1.9460802167974494

Epoch: 6| Step: 7
Training loss: 1.6376774311065674
Validation loss: 1.9674250297648932

Epoch: 6| Step: 8
Training loss: 2.2050509452819824
Validation loss: 1.9597124873950917

Epoch: 6| Step: 9
Training loss: 1.9612793922424316
Validation loss: 1.948122719282745

Epoch: 6| Step: 10
Training loss: 2.1513519287109375
Validation loss: 1.9646722078323364

Epoch: 6| Step: 11
Training loss: 3.105282783508301
Validation loss: 1.9716235886337936

Epoch: 6| Step: 12
Training loss: 2.1482746601104736
Validation loss: 1.9615300983510993

Epoch: 6| Step: 13
Training loss: 2.9631357192993164
Validation loss: 1.9625904893362394

Epoch: 66| Step: 0
Training loss: 1.6854881048202515
Validation loss: 1.946086932254094

Epoch: 6| Step: 1
Training loss: 2.5331106185913086
Validation loss: 1.9557013165566228

Epoch: 6| Step: 2
Training loss: 2.3248660564422607
Validation loss: 1.931116509181197

Epoch: 6| Step: 3
Training loss: 2.142066240310669
Validation loss: 1.954728013725691

Epoch: 6| Step: 4
Training loss: 2.2283968925476074
Validation loss: 1.9592840210083993

Epoch: 6| Step: 5
Training loss: 1.4722422361373901
Validation loss: 1.9452821323948521

Epoch: 6| Step: 6
Training loss: 2.587658405303955
Validation loss: 1.9494474139264835

Epoch: 6| Step: 7
Training loss: 2.669039249420166
Validation loss: 1.9567559278139504

Epoch: 6| Step: 8
Training loss: 2.249484062194824
Validation loss: 1.9474203355850712

Epoch: 6| Step: 9
Training loss: 1.8265084028244019
Validation loss: 1.9577805047394128

Epoch: 6| Step: 10
Training loss: 2.700166702270508
Validation loss: 1.9528308222370763

Epoch: 6| Step: 11
Training loss: 2.3673012256622314
Validation loss: 1.9608491313072942

Epoch: 6| Step: 12
Training loss: 2.4688944816589355
Validation loss: 1.9535842762198499

Epoch: 6| Step: 13
Training loss: 2.5364990234375
Validation loss: 1.9551238449670936

Epoch: 67| Step: 0
Training loss: 2.367269277572632
Validation loss: 1.944167124327793

Epoch: 6| Step: 1
Training loss: 2.162952423095703
Validation loss: 1.9364628612354238

Epoch: 6| Step: 2
Training loss: 2.378469467163086
Validation loss: 1.9453285035266672

Epoch: 6| Step: 3
Training loss: 2.685218334197998
Validation loss: 1.940356990342499

Epoch: 6| Step: 4
Training loss: 2.6269912719726562
Validation loss: 1.937544732965449

Epoch: 6| Step: 5
Training loss: 1.91497802734375
Validation loss: 1.9301149332395164

Epoch: 6| Step: 6
Training loss: 1.7257630825042725
Validation loss: 1.9380474052121561

Epoch: 6| Step: 7
Training loss: 1.9914491176605225
Validation loss: 1.9235910433594898

Epoch: 6| Step: 8
Training loss: 1.74777352809906
Validation loss: 1.938327294523998

Epoch: 6| Step: 9
Training loss: 2.995504140853882
Validation loss: 1.926534350200366

Epoch: 6| Step: 10
Training loss: 2.7368969917297363
Validation loss: 1.927906866996519

Epoch: 6| Step: 11
Training loss: 1.8293426036834717
Validation loss: 1.9495773725612189

Epoch: 6| Step: 12
Training loss: 2.279362440109253
Validation loss: 1.9446814521666496

Epoch: 6| Step: 13
Training loss: 2.0652968883514404
Validation loss: 1.9553023910009733

Epoch: 68| Step: 0
Training loss: 2.5167288780212402
Validation loss: 1.923912831532058

Epoch: 6| Step: 1
Training loss: 2.4003143310546875
Validation loss: 1.9341856074589554

Epoch: 6| Step: 2
Training loss: 2.286984443664551
Validation loss: 1.9303841257608065

Epoch: 6| Step: 3
Training loss: 2.6092276573181152
Validation loss: 1.941396201810529

Epoch: 6| Step: 4
Training loss: 1.9052413702011108
Validation loss: 1.9258838404891312

Epoch: 6| Step: 5
Training loss: 2.057866334915161
Validation loss: 1.9386097308128112

Epoch: 6| Step: 6
Training loss: 2.3248047828674316
Validation loss: 1.9363112808555685

Epoch: 6| Step: 7
Training loss: 2.3047752380371094
Validation loss: 1.9324702114187262

Epoch: 6| Step: 8
Training loss: 2.05509614944458
Validation loss: 1.933771938406011

Epoch: 6| Step: 9
Training loss: 2.2973928451538086
Validation loss: 1.9271460361378168

Epoch: 6| Step: 10
Training loss: 2.0989034175872803
Validation loss: 1.9252972974572131

Epoch: 6| Step: 11
Training loss: 2.4057915210723877
Validation loss: 1.9311947309842674

Epoch: 6| Step: 12
Training loss: 2.4256012439727783
Validation loss: 1.9289677540461223

Epoch: 6| Step: 13
Training loss: 1.7430201768875122
Validation loss: 1.9183909277762137

Epoch: 69| Step: 0
Training loss: 2.6365866661071777
Validation loss: 1.9519287052974905

Epoch: 6| Step: 1
Training loss: 2.306997776031494
Validation loss: 1.9392929230966875

Epoch: 6| Step: 2
Training loss: 2.558271646499634
Validation loss: 1.9392668880442137

Epoch: 6| Step: 3
Training loss: 2.078836441040039
Validation loss: 1.9592826468970186

Epoch: 6| Step: 4
Training loss: 2.783883571624756
Validation loss: 1.9676106501651067

Epoch: 6| Step: 5
Training loss: 2.177987813949585
Validation loss: 1.953712785115806

Epoch: 6| Step: 6
Training loss: 1.590680718421936
Validation loss: 1.9544457466371599

Epoch: 6| Step: 7
Training loss: 2.276083469390869
Validation loss: 1.959983915411016

Epoch: 6| Step: 8
Training loss: 1.7809233665466309
Validation loss: 1.9564411101802703

Epoch: 6| Step: 9
Training loss: 2.047694444656372
Validation loss: 1.9498057185962636

Epoch: 6| Step: 10
Training loss: 2.4805922508239746
Validation loss: 1.9507747747564828

Epoch: 6| Step: 11
Training loss: 2.334747314453125
Validation loss: 1.9655157725016277

Epoch: 6| Step: 12
Training loss: 2.0730748176574707
Validation loss: 1.9560900003679338

Epoch: 6| Step: 13
Training loss: 2.470771551132202
Validation loss: 1.947866327019148

Epoch: 70| Step: 0
Training loss: 2.299370288848877
Validation loss: 1.9619913370378557

Epoch: 6| Step: 1
Training loss: 2.066683053970337
Validation loss: 1.9558110134575957

Epoch: 6| Step: 2
Training loss: 2.468783140182495
Validation loss: 1.9753144659021848

Epoch: 6| Step: 3
Training loss: 2.2776436805725098
Validation loss: 1.9439509145675167

Epoch: 6| Step: 4
Training loss: 1.9037022590637207
Validation loss: 1.9408740317949684

Epoch: 6| Step: 5
Training loss: 2.395869255065918
Validation loss: 1.9515043150994085

Epoch: 6| Step: 6
Training loss: 2.1001954078674316
Validation loss: 1.9442603690649873

Epoch: 6| Step: 7
Training loss: 2.998981237411499
Validation loss: 1.9471002060879943

Epoch: 6| Step: 8
Training loss: 2.4453773498535156
Validation loss: 1.9559621490458006

Epoch: 6| Step: 9
Training loss: 2.196380615234375
Validation loss: 1.9474073225452053

Epoch: 6| Step: 10
Training loss: 1.7579412460327148
Validation loss: 1.943742472638366

Epoch: 6| Step: 11
Training loss: 1.9795970916748047
Validation loss: 1.9469369124340754

Epoch: 6| Step: 12
Training loss: 2.801797866821289
Validation loss: 1.9677367646207091

Epoch: 6| Step: 13
Training loss: 1.6883103847503662
Validation loss: 1.9603177398763678

Epoch: 71| Step: 0
Training loss: 2.258136510848999
Validation loss: 1.954796984631528

Epoch: 6| Step: 1
Training loss: 2.3995039463043213
Validation loss: 1.9675144405775173

Epoch: 6| Step: 2
Training loss: 1.972132921218872
Validation loss: 1.9664386139121106

Epoch: 6| Step: 3
Training loss: 2.7465949058532715
Validation loss: 1.9688378277645315

Epoch: 6| Step: 4
Training loss: 2.1226677894592285
Validation loss: 1.9684196928496003

Epoch: 6| Step: 5
Training loss: 2.1043243408203125
Validation loss: 1.9462446140986618

Epoch: 6| Step: 6
Training loss: 2.258634328842163
Validation loss: 1.955463558114985

Epoch: 6| Step: 7
Training loss: 2.1717259883880615
Validation loss: 1.9407656808053293

Epoch: 6| Step: 8
Training loss: 1.6018526554107666
Validation loss: 1.9391110084390129

Epoch: 6| Step: 9
Training loss: 2.083712100982666
Validation loss: 1.966258866812593

Epoch: 6| Step: 10
Training loss: 2.6849822998046875
Validation loss: 1.9533679972412765

Epoch: 6| Step: 11
Training loss: 2.9719815254211426
Validation loss: 1.948337556213461

Epoch: 6| Step: 12
Training loss: 1.5439270734786987
Validation loss: 1.9616003036499023

Epoch: 6| Step: 13
Training loss: 2.5112123489379883
Validation loss: 1.9476005313217

Epoch: 72| Step: 0
Training loss: 1.7302924394607544
Validation loss: 1.963800496952508

Epoch: 6| Step: 1
Training loss: 2.551097869873047
Validation loss: 1.9412504473040182

Epoch: 6| Step: 2
Training loss: 2.621652841567993
Validation loss: 1.944951234325286

Epoch: 6| Step: 3
Training loss: 2.7484302520751953
Validation loss: 1.9638866160505561

Epoch: 6| Step: 4
Training loss: 2.4412269592285156
Validation loss: 1.9390596215442946

Epoch: 6| Step: 5
Training loss: 1.964768409729004
Validation loss: 1.945441219114488

Epoch: 6| Step: 6
Training loss: 1.5738685131072998
Validation loss: 1.9424061070206344

Epoch: 6| Step: 7
Training loss: 2.7893247604370117
Validation loss: 1.9441628340751893

Epoch: 6| Step: 8
Training loss: 1.795470952987671
Validation loss: 1.9300832748413086

Epoch: 6| Step: 9
Training loss: 2.458514451980591
Validation loss: 1.9292629393198157

Epoch: 6| Step: 10
Training loss: 2.374450445175171
Validation loss: 1.9523147075406966

Epoch: 6| Step: 11
Training loss: 1.847791314125061
Validation loss: 1.9278699210895005

Epoch: 6| Step: 12
Training loss: 2.307889461517334
Validation loss: 1.9323993741825063

Epoch: 6| Step: 13
Training loss: 2.26041316986084
Validation loss: 1.9237781237530451

Epoch: 73| Step: 0
Training loss: 2.0059025287628174
Validation loss: 1.9481190071311048

Epoch: 6| Step: 1
Training loss: 1.959235429763794
Validation loss: 1.9343126230342413

Epoch: 6| Step: 2
Training loss: 1.9846621751785278
Validation loss: 1.9469202231335383

Epoch: 6| Step: 3
Training loss: 2.537928819656372
Validation loss: 1.946086017034387

Epoch: 6| Step: 4
Training loss: 2.5961921215057373
Validation loss: 1.9465504269446097

Epoch: 6| Step: 5
Training loss: 2.8843564987182617
Validation loss: 1.9435994945546633

Epoch: 6| Step: 6
Training loss: 2.0525946617126465
Validation loss: 1.9434493049498527

Epoch: 6| Step: 7
Training loss: 2.367403030395508
Validation loss: 1.9577553028701453

Epoch: 6| Step: 8
Training loss: 2.2367069721221924
Validation loss: 1.9661959063622259

Epoch: 6| Step: 9
Training loss: 2.1147007942199707
Validation loss: 1.953017702666662

Epoch: 6| Step: 10
Training loss: 1.8297832012176514
Validation loss: 1.9621178988487489

Epoch: 6| Step: 11
Training loss: 1.898633360862732
Validation loss: 1.9609596319096063

Epoch: 6| Step: 12
Training loss: 2.42629337310791
Validation loss: 1.9611454292010235

Epoch: 6| Step: 13
Training loss: 2.4168155193328857
Validation loss: 1.9663009028280936

Epoch: 74| Step: 0
Training loss: 2.297696590423584
Validation loss: 1.9481058633455666

Epoch: 6| Step: 1
Training loss: 1.5625982284545898
Validation loss: 1.945566008167882

Epoch: 6| Step: 2
Training loss: 2.296116828918457
Validation loss: 1.9576637796176377

Epoch: 6| Step: 3
Training loss: 1.9875205755233765
Validation loss: 1.9499927771988737

Epoch: 6| Step: 4
Training loss: 2.2525389194488525
Validation loss: 1.927849619619308

Epoch: 6| Step: 5
Training loss: 2.137002468109131
Validation loss: 1.9570827945586173

Epoch: 6| Step: 6
Training loss: 2.9454898834228516
Validation loss: 1.931318070298882

Epoch: 6| Step: 7
Training loss: 2.5285143852233887
Validation loss: 1.934934308451991

Epoch: 6| Step: 8
Training loss: 2.4078707695007324
Validation loss: 1.9386639351485877

Epoch: 6| Step: 9
Training loss: 2.1132168769836426
Validation loss: 1.9400964898447837

Epoch: 6| Step: 10
Training loss: 2.655428647994995
Validation loss: 1.9376946777425788

Epoch: 6| Step: 11
Training loss: 1.8621034622192383
Validation loss: 1.9238172859273932

Epoch: 6| Step: 12
Training loss: 1.989457368850708
Validation loss: 1.9445695364347069

Epoch: 6| Step: 13
Training loss: 2.100367546081543
Validation loss: 1.9239308141892957

Epoch: 75| Step: 0
Training loss: 2.0625741481781006
Validation loss: 1.9544918344866844

Epoch: 6| Step: 1
Training loss: 2.314840078353882
Validation loss: 1.9319325057409142

Epoch: 6| Step: 2
Training loss: 1.9420366287231445
Validation loss: 1.9409712565842496

Epoch: 6| Step: 3
Training loss: 1.8913803100585938
Validation loss: 1.9358596853030625

Epoch: 6| Step: 4
Training loss: 2.747499942779541
Validation loss: 1.9319838695628668

Epoch: 6| Step: 5
Training loss: 1.9256222248077393
Validation loss: 1.9310989226064375

Epoch: 6| Step: 6
Training loss: 1.8412225246429443
Validation loss: 1.9239408662242274

Epoch: 6| Step: 7
Training loss: 2.732795238494873
Validation loss: 1.9273234054606447

Epoch: 6| Step: 8
Training loss: 2.103391170501709
Validation loss: 1.9356247148206156

Epoch: 6| Step: 9
Training loss: 2.0933327674865723
Validation loss: 1.9414752401331419

Epoch: 6| Step: 10
Training loss: 2.1371102333068848
Validation loss: 1.9352331930591213

Epoch: 6| Step: 11
Training loss: 2.9868855476379395
Validation loss: 1.9194559704872869

Epoch: 6| Step: 12
Training loss: 2.3081932067871094
Validation loss: 1.9443724668154152

Epoch: 6| Step: 13
Training loss: 2.1715269088745117
Validation loss: 1.937731037857712

Epoch: 76| Step: 0
Training loss: 2.297675132751465
Validation loss: 1.9328500955335555

Epoch: 6| Step: 1
Training loss: 2.424654483795166
Validation loss: 1.9402578594864055

Epoch: 6| Step: 2
Training loss: 2.3600614070892334
Validation loss: 1.9346764087677002

Epoch: 6| Step: 3
Training loss: 2.7495951652526855
Validation loss: 1.9359710703613937

Epoch: 6| Step: 4
Training loss: 1.7551790475845337
Validation loss: 1.9320616132469588

Epoch: 6| Step: 5
Training loss: 1.7606667280197144
Validation loss: 1.9458924519118441

Epoch: 6| Step: 6
Training loss: 2.0241925716400146
Validation loss: 1.9481379908900107

Epoch: 6| Step: 7
Training loss: 2.293452262878418
Validation loss: 1.9353762172883557

Epoch: 6| Step: 8
Training loss: 2.3270909786224365
Validation loss: 1.9593320623520882

Epoch: 6| Step: 9
Training loss: 1.7332723140716553
Validation loss: 1.9422131276899768

Epoch: 6| Step: 10
Training loss: 2.3839755058288574
Validation loss: 1.9556220193063059

Epoch: 6| Step: 11
Training loss: 1.8204166889190674
Validation loss: 1.9442101140176096

Epoch: 6| Step: 12
Training loss: 2.7890377044677734
Validation loss: 1.9335579077402751

Epoch: 6| Step: 13
Training loss: 2.418243169784546
Validation loss: 1.9331721836520779

Epoch: 77| Step: 0
Training loss: 2.5224876403808594
Validation loss: 1.949199854686696

Epoch: 6| Step: 1
Training loss: 1.4338185787200928
Validation loss: 1.938252123453284

Epoch: 6| Step: 2
Training loss: 2.448551654815674
Validation loss: 1.9488966823906027

Epoch: 6| Step: 3
Training loss: 2.144216537475586
Validation loss: 1.9600296789600002

Epoch: 6| Step: 4
Training loss: 2.081040382385254
Validation loss: 1.9593145565320087

Epoch: 6| Step: 5
Training loss: 2.3819222450256348
Validation loss: 1.96509773372322

Epoch: 6| Step: 6
Training loss: 2.6888134479522705
Validation loss: 1.9383763946512693

Epoch: 6| Step: 7
Training loss: 2.228647232055664
Validation loss: 1.9471878172248922

Epoch: 6| Step: 8
Training loss: 2.48543643951416
Validation loss: 1.9627507630214895

Epoch: 6| Step: 9
Training loss: 2.2235636711120605
Validation loss: 1.9447034661487868

Epoch: 6| Step: 10
Training loss: 2.4793336391448975
Validation loss: 1.9510065022335257

Epoch: 6| Step: 11
Training loss: 1.6470887660980225
Validation loss: 1.9498463574276175

Epoch: 6| Step: 12
Training loss: 2.0737600326538086
Validation loss: 1.944792006605415

Epoch: 6| Step: 13
Training loss: 2.1458210945129395
Validation loss: 1.94490385055542

Epoch: 78| Step: 0
Training loss: 2.3030354976654053
Validation loss: 1.9364263139745241

Epoch: 6| Step: 1
Training loss: 2.4326601028442383
Validation loss: 1.9526642586595269

Epoch: 6| Step: 2
Training loss: 2.188929319381714
Validation loss: 1.9462463048196608

Epoch: 6| Step: 3
Training loss: 2.062279224395752
Validation loss: 1.9530584965982745

Epoch: 6| Step: 4
Training loss: 2.4788689613342285
Validation loss: 1.9475643224613641

Epoch: 6| Step: 5
Training loss: 1.7719650268554688
Validation loss: 1.9461829893050655

Epoch: 6| Step: 6
Training loss: 2.3072400093078613
Validation loss: 1.9429968018685617

Epoch: 6| Step: 7
Training loss: 2.5381064414978027
Validation loss: 1.9556013179081742

Epoch: 6| Step: 8
Training loss: 2.1720826625823975
Validation loss: 1.9306690116082468

Epoch: 6| Step: 9
Training loss: 1.5997551679611206
Validation loss: 1.939295240627822

Epoch: 6| Step: 10
Training loss: 1.936574935913086
Validation loss: 1.9282344310514388

Epoch: 6| Step: 11
Training loss: 1.942969560623169
Validation loss: 1.9467547465396184

Epoch: 6| Step: 12
Training loss: 2.809785842895508
Validation loss: 1.9407265647765128

Epoch: 6| Step: 13
Training loss: 2.6950912475585938
Validation loss: 1.9417386336993145

Epoch: 79| Step: 0
Training loss: 1.6704829931259155
Validation loss: 1.9269717201109855

Epoch: 6| Step: 1
Training loss: 2.184915542602539
Validation loss: 1.9588185612873366

Epoch: 6| Step: 2
Training loss: 2.8265936374664307
Validation loss: 1.9447978606788061

Epoch: 6| Step: 3
Training loss: 2.7300705909729004
Validation loss: 1.9526107823976906

Epoch: 6| Step: 4
Training loss: 2.1555535793304443
Validation loss: 1.9654825425917102

Epoch: 6| Step: 5
Training loss: 1.9357144832611084
Validation loss: 1.9758028548250917

Epoch: 6| Step: 6
Training loss: 2.6013827323913574
Validation loss: 1.980458080127675

Epoch: 6| Step: 7
Training loss: 2.1937363147735596
Validation loss: 1.9755158680741505

Epoch: 6| Step: 8
Training loss: 2.387859344482422
Validation loss: 1.9993643119770994

Epoch: 6| Step: 9
Training loss: 2.183015823364258
Validation loss: 1.9867440423657816

Epoch: 6| Step: 10
Training loss: 1.7270841598510742
Validation loss: 1.967250818847328

Epoch: 6| Step: 11
Training loss: 1.8977124691009521
Validation loss: 1.993176096229143

Epoch: 6| Step: 12
Training loss: 2.095430612564087
Validation loss: 1.9910431062021563

Epoch: 6| Step: 13
Training loss: 3.222012758255005
Validation loss: 2.007526397705078

Epoch: 80| Step: 0
Training loss: 1.9861148595809937
Validation loss: 1.987291250177609

Epoch: 6| Step: 1
Training loss: 3.1097288131713867
Validation loss: 1.981814084514495

Epoch: 6| Step: 2
Training loss: 2.274763345718384
Validation loss: 1.9681490928896013

Epoch: 6| Step: 3
Training loss: 2.4196057319641113
Validation loss: 1.9917439619700115

Epoch: 6| Step: 4
Training loss: 2.1819348335266113
Validation loss: 1.9778128195834417

Epoch: 6| Step: 5
Training loss: 1.896639347076416
Validation loss: 1.9771567724084342

Epoch: 6| Step: 6
Training loss: 2.5115082263946533
Validation loss: 1.9604495571505638

Epoch: 6| Step: 7
Training loss: 2.2420706748962402
Validation loss: 1.9597219472290368

Epoch: 6| Step: 8
Training loss: 2.04691743850708
Validation loss: 1.9607323062035344

Epoch: 6| Step: 9
Training loss: 1.8389077186584473
Validation loss: 1.9471720700622888

Epoch: 6| Step: 10
Training loss: 2.0213778018951416
Validation loss: 1.934722158216661

Epoch: 6| Step: 11
Training loss: 1.9564765691757202
Validation loss: 1.9703726742857246

Epoch: 6| Step: 12
Training loss: 2.3000030517578125
Validation loss: 1.9494993276493524

Epoch: 6| Step: 13
Training loss: 1.9899297952651978
Validation loss: 1.9667164048840922

Epoch: 81| Step: 0
Training loss: 2.2917492389678955
Validation loss: 1.9725490770032328

Epoch: 6| Step: 1
Training loss: 2.2782692909240723
Validation loss: 1.9726527762669388

Epoch: 6| Step: 2
Training loss: 2.78757381439209
Validation loss: 1.9676052908743582

Epoch: 6| Step: 3
Training loss: 2.538058042526245
Validation loss: 1.941735602194263

Epoch: 6| Step: 4
Training loss: 1.979396104812622
Validation loss: 1.9739158589352843

Epoch: 6| Step: 5
Training loss: 3.02370548248291
Validation loss: 1.985527782030003

Epoch: 6| Step: 6
Training loss: 1.937246561050415
Validation loss: 1.9704688454187045

Epoch: 6| Step: 7
Training loss: 1.8684971332550049
Validation loss: 1.9701038304195608

Epoch: 6| Step: 8
Training loss: 2.594975709915161
Validation loss: 1.9818127873123332

Epoch: 6| Step: 9
Training loss: 2.0743958950042725
Validation loss: 1.9850673214081795

Epoch: 6| Step: 10
Training loss: 1.9585487842559814
Validation loss: 1.9699165308347313

Epoch: 6| Step: 11
Training loss: 1.5026500225067139
Validation loss: 1.9753436247507732

Epoch: 6| Step: 12
Training loss: 1.88047194480896
Validation loss: 1.9729635984666887

Epoch: 6| Step: 13
Training loss: 2.3713977336883545
Validation loss: 1.9510831050975348

Epoch: 82| Step: 0
Training loss: 2.022592544555664
Validation loss: 1.972513710298846

Epoch: 6| Step: 1
Training loss: 2.2151334285736084
Validation loss: 1.968889545368892

Epoch: 6| Step: 2
Training loss: 1.487732172012329
Validation loss: 1.9506944482044508

Epoch: 6| Step: 3
Training loss: 2.3995752334594727
Validation loss: 1.9730145072424283

Epoch: 6| Step: 4
Training loss: 2.5541205406188965
Validation loss: 1.9696557906366163

Epoch: 6| Step: 5
Training loss: 2.1599924564361572
Validation loss: 1.9884112804166731

Epoch: 6| Step: 6
Training loss: 2.900618314743042
Validation loss: 1.9832510512362245

Epoch: 6| Step: 7
Training loss: 2.2757835388183594
Validation loss: 1.974347178654004

Epoch: 6| Step: 8
Training loss: 1.9839177131652832
Validation loss: 1.9636327169274772

Epoch: 6| Step: 9
Training loss: 1.557265043258667
Validation loss: 1.9821451607570852

Epoch: 6| Step: 10
Training loss: 2.6014504432678223
Validation loss: 1.9759152140668643

Epoch: 6| Step: 11
Training loss: 2.335829973220825
Validation loss: 1.9713890334611297

Epoch: 6| Step: 12
Training loss: 2.849799156188965
Validation loss: 1.9788763471828994

Epoch: 6| Step: 13
Training loss: 1.2929871082305908
Validation loss: 1.977152673147058

Epoch: 83| Step: 0
Training loss: 1.9823819398880005
Validation loss: 1.96531093248757

Epoch: 6| Step: 1
Training loss: 2.2946736812591553
Validation loss: 1.9901066364780549

Epoch: 6| Step: 2
Training loss: 2.1761951446533203
Validation loss: 1.9906644026438396

Epoch: 6| Step: 3
Training loss: 2.102163553237915
Validation loss: 1.9667883073129961

Epoch: 6| Step: 4
Training loss: 2.384859085083008
Validation loss: 1.9707847769542406

Epoch: 6| Step: 5
Training loss: 1.9524379968643188
Validation loss: 1.9759406184637418

Epoch: 6| Step: 6
Training loss: 2.5475401878356934
Validation loss: 1.965021805096698

Epoch: 6| Step: 7
Training loss: 2.3567187786102295
Validation loss: 1.9510280829603954

Epoch: 6| Step: 8
Training loss: 2.762281894683838
Validation loss: 1.9470631614808114

Epoch: 6| Step: 9
Training loss: 1.8607735633850098
Validation loss: 1.9449057476494902

Epoch: 6| Step: 10
Training loss: 2.4008944034576416
Validation loss: 1.9222449051436556

Epoch: 6| Step: 11
Training loss: 1.6284644603729248
Validation loss: 1.962809129427838

Epoch: 6| Step: 12
Training loss: 1.9997055530548096
Validation loss: 1.9452976513934392

Epoch: 6| Step: 13
Training loss: 2.640662670135498
Validation loss: 1.9368561621635192

Epoch: 84| Step: 0
Training loss: 2.2724432945251465
Validation loss: 1.9501062400879399

Epoch: 6| Step: 1
Training loss: 1.9551812410354614
Validation loss: 1.9422546855864986

Epoch: 6| Step: 2
Training loss: 2.6310324668884277
Validation loss: 1.9501239202355827

Epoch: 6| Step: 3
Training loss: 1.4738695621490479
Validation loss: 1.9456783904824206

Epoch: 6| Step: 4
Training loss: 1.5685389041900635
Validation loss: 1.9453198473940614

Epoch: 6| Step: 5
Training loss: 2.288893938064575
Validation loss: 1.9686371613574285

Epoch: 6| Step: 6
Training loss: 2.6417927742004395
Validation loss: 1.960157472600219

Epoch: 6| Step: 7
Training loss: 2.548557996749878
Validation loss: 1.936290971694454

Epoch: 6| Step: 8
Training loss: 2.73699688911438
Validation loss: 1.9352789296898791

Epoch: 6| Step: 9
Training loss: 2.316157341003418
Validation loss: 1.956766825850292

Epoch: 6| Step: 10
Training loss: 1.7461450099945068
Validation loss: 1.9542882378383348

Epoch: 6| Step: 11
Training loss: 1.9383299350738525
Validation loss: 1.9783187348355529

Epoch: 6| Step: 12
Training loss: 2.5959434509277344
Validation loss: 1.9418979332011232

Epoch: 6| Step: 13
Training loss: 1.934304118156433
Validation loss: 1.9467090060633998

Epoch: 85| Step: 0
Training loss: 1.5832568407058716
Validation loss: 1.9539129349493212

Epoch: 6| Step: 1
Training loss: 1.694347858428955
Validation loss: 1.9654550526731758

Epoch: 6| Step: 2
Training loss: 1.1922111511230469
Validation loss: 1.9561118233588435

Epoch: 6| Step: 3
Training loss: 2.3420093059539795
Validation loss: 1.9714421226132302

Epoch: 6| Step: 4
Training loss: 2.906184196472168
Validation loss: 1.9682567093961982

Epoch: 6| Step: 5
Training loss: 2.832473039627075
Validation loss: 1.9652745172541628

Epoch: 6| Step: 6
Training loss: 2.1257967948913574
Validation loss: 1.9675337512006041

Epoch: 6| Step: 7
Training loss: 2.6423017978668213
Validation loss: 1.9737859682370258

Epoch: 6| Step: 8
Training loss: 2.220707416534424
Validation loss: 1.988670866976502

Epoch: 6| Step: 9
Training loss: 1.731903076171875
Validation loss: 1.9728190898895264

Epoch: 6| Step: 10
Training loss: 2.700302839279175
Validation loss: 1.9628010680598598

Epoch: 6| Step: 11
Training loss: 2.575733184814453
Validation loss: 1.9946038005172566

Epoch: 6| Step: 12
Training loss: 2.4577479362487793
Validation loss: 1.9573212028831564

Epoch: 6| Step: 13
Training loss: 1.1092009544372559
Validation loss: 1.9704415041913268

Epoch: 86| Step: 0
Training loss: 2.8840579986572266
Validation loss: 1.967349511320873

Epoch: 6| Step: 1
Training loss: 2.062314987182617
Validation loss: 1.9788150069534138

Epoch: 6| Step: 2
Training loss: 2.03900146484375
Validation loss: 1.9712288392487394

Epoch: 6| Step: 3
Training loss: 2.6633410453796387
Validation loss: 1.9755791425704956

Epoch: 6| Step: 4
Training loss: 1.355531930923462
Validation loss: 1.9684206670330417

Epoch: 6| Step: 5
Training loss: 2.486830234527588
Validation loss: 1.9703682878965973

Epoch: 6| Step: 6
Training loss: 1.6438109874725342
Validation loss: 1.9718033844424832

Epoch: 6| Step: 7
Training loss: 1.7670197486877441
Validation loss: 1.9942614211831042

Epoch: 6| Step: 8
Training loss: 2.037400245666504
Validation loss: 1.9840874953936505

Epoch: 6| Step: 9
Training loss: 2.743722677230835
Validation loss: 1.9896204151133055

Epoch: 6| Step: 10
Training loss: 2.2935657501220703
Validation loss: 1.977199698007235

Epoch: 6| Step: 11
Training loss: 1.8926000595092773
Validation loss: 1.9682598985651487

Epoch: 6| Step: 12
Training loss: 2.1815757751464844
Validation loss: 1.9820475578308105

Epoch: 6| Step: 13
Training loss: 2.9617114067077637
Validation loss: 1.968993745824342

Epoch: 87| Step: 0
Training loss: 2.3182289600372314
Validation loss: 1.9604008595148723

Epoch: 6| Step: 1
Training loss: 2.463895797729492
Validation loss: 1.975199286655713

Epoch: 6| Step: 2
Training loss: 2.4539976119995117
Validation loss: 1.9746286792139853

Epoch: 6| Step: 3
Training loss: 2.2029709815979004
Validation loss: 1.9797106160912463

Epoch: 6| Step: 4
Training loss: 2.7093300819396973
Validation loss: 1.9695686832551034

Epoch: 6| Step: 5
Training loss: 1.3544518947601318
Validation loss: 1.9802969194227649

Epoch: 6| Step: 6
Training loss: 2.0470266342163086
Validation loss: 1.9492178014529649

Epoch: 6| Step: 7
Training loss: 1.5376324653625488
Validation loss: 1.9808096603680683

Epoch: 6| Step: 8
Training loss: 2.439401626586914
Validation loss: 1.9786088082098192

Epoch: 6| Step: 9
Training loss: 2.9157071113586426
Validation loss: 1.981443243642007

Epoch: 6| Step: 10
Training loss: 2.3640663623809814
Validation loss: 1.9917018310998076

Epoch: 6| Step: 11
Training loss: 2.069169521331787
Validation loss: 1.9788601398468018

Epoch: 6| Step: 12
Training loss: 1.8171608448028564
Validation loss: 1.9781183786289667

Epoch: 6| Step: 13
Training loss: 2.1594836711883545
Validation loss: 1.9851232100558538

Epoch: 88| Step: 0
Training loss: 2.564709186553955
Validation loss: 1.98049589895433

Epoch: 6| Step: 1
Training loss: 2.738957405090332
Validation loss: 1.9905851182117258

Epoch: 6| Step: 2
Training loss: 2.1642813682556152
Validation loss: 1.9714324217970653

Epoch: 6| Step: 3
Training loss: 2.5063862800598145
Validation loss: 1.9908440241249659

Epoch: 6| Step: 4
Training loss: 2.6403820514678955
Validation loss: 1.9925112173121462

Epoch: 6| Step: 5
Training loss: 2.3768038749694824
Validation loss: 1.9790425992781115

Epoch: 6| Step: 6
Training loss: 1.8739876747131348
Validation loss: 1.9768552241786834

Epoch: 6| Step: 7
Training loss: 1.8422647714614868
Validation loss: 1.9733789454224289

Epoch: 6| Step: 8
Training loss: 1.9359809160232544
Validation loss: 1.9651707897904098

Epoch: 6| Step: 9
Training loss: 1.9929442405700684
Validation loss: 1.9596364408411004

Epoch: 6| Step: 10
Training loss: 1.9428550004959106
Validation loss: 1.9692063485422442

Epoch: 6| Step: 11
Training loss: 1.7621660232543945
Validation loss: 1.9634434433393582

Epoch: 6| Step: 12
Training loss: 2.478019952774048
Validation loss: 1.9500893803053005

Epoch: 6| Step: 13
Training loss: 1.5204976797103882
Validation loss: 1.950375964564662

Epoch: 89| Step: 0
Training loss: 2.271674871444702
Validation loss: 1.9662576260105256

Epoch: 6| Step: 1
Training loss: 2.602208137512207
Validation loss: 1.972705307827201

Epoch: 6| Step: 2
Training loss: 2.5082898139953613
Validation loss: 1.968634392625542

Epoch: 6| Step: 3
Training loss: 2.5635292530059814
Validation loss: 1.9478997261293474

Epoch: 6| Step: 4
Training loss: 2.1867504119873047
Validation loss: 1.9591805114541003

Epoch: 6| Step: 5
Training loss: 1.8752691745758057
Validation loss: 1.994339450713127

Epoch: 6| Step: 6
Training loss: 2.0783891677856445
Validation loss: 1.9811064068989088

Epoch: 6| Step: 7
Training loss: 2.218297004699707
Validation loss: 1.9752622983788932

Epoch: 6| Step: 8
Training loss: 1.8159146308898926
Validation loss: 1.9742411772410076

Epoch: 6| Step: 9
Training loss: 2.273073673248291
Validation loss: 1.9842802055420414

Epoch: 6| Step: 10
Training loss: 1.598479151725769
Validation loss: 1.9716969497742192

Epoch: 6| Step: 11
Training loss: 2.330700397491455
Validation loss: 1.9677125702622116

Epoch: 6| Step: 12
Training loss: 2.0976245403289795
Validation loss: 1.964467587009553

Epoch: 6| Step: 13
Training loss: 2.08712100982666
Validation loss: 1.9936990609733007

Epoch: 90| Step: 0
Training loss: 1.5067219734191895
Validation loss: 1.9855216036560714

Epoch: 6| Step: 1
Training loss: 2.1006782054901123
Validation loss: 1.9883210684663506

Epoch: 6| Step: 2
Training loss: 2.515329360961914
Validation loss: 1.9893132627651255

Epoch: 6| Step: 3
Training loss: 2.9928131103515625
Validation loss: 1.979160988202659

Epoch: 6| Step: 4
Training loss: 2.8097269535064697
Validation loss: 1.999774891843078

Epoch: 6| Step: 5
Training loss: 2.538801908493042
Validation loss: 1.9969631753942019

Epoch: 6| Step: 6
Training loss: 2.019303798675537
Validation loss: 2.006465506810014

Epoch: 6| Step: 7
Training loss: 1.6732921600341797
Validation loss: 2.0020209153493247

Epoch: 6| Step: 8
Training loss: 1.892371654510498
Validation loss: 1.9872833990281629

Epoch: 6| Step: 9
Training loss: 2.1796746253967285
Validation loss: 1.9906372767622753

Epoch: 6| Step: 10
Training loss: 2.3925037384033203
Validation loss: 1.9979009577023086

Epoch: 6| Step: 11
Training loss: 2.031046152114868
Validation loss: 1.9946492448929818

Epoch: 6| Step: 12
Training loss: 1.9835264682769775
Validation loss: 2.0244560908245783

Epoch: 6| Step: 13
Training loss: 1.6947752237319946
Validation loss: 1.9876287355217883

Epoch: 91| Step: 0
Training loss: 2.3527655601501465
Validation loss: 1.9886454612978044

Epoch: 6| Step: 1
Training loss: 2.301441192626953
Validation loss: 1.981776524615544

Epoch: 6| Step: 2
Training loss: 1.9652972221374512
Validation loss: 1.976896350101758

Epoch: 6| Step: 3
Training loss: 2.264758586883545
Validation loss: 1.9728423459555513

Epoch: 6| Step: 4
Training loss: 2.0876107215881348
Validation loss: 1.957348076246118

Epoch: 6| Step: 5
Training loss: 2.460582971572876
Validation loss: 1.9641606576981083

Epoch: 6| Step: 6
Training loss: 2.2109262943267822
Validation loss: 1.9574235382900442

Epoch: 6| Step: 7
Training loss: 2.047302722930908
Validation loss: 1.9341100826058337

Epoch: 6| Step: 8
Training loss: 2.1522951126098633
Validation loss: 1.948436060259419

Epoch: 6| Step: 9
Training loss: 1.8004627227783203
Validation loss: 1.95204770693215

Epoch: 6| Step: 10
Training loss: 2.55442476272583
Validation loss: 1.9337820827320058

Epoch: 6| Step: 11
Training loss: 2.3776869773864746
Validation loss: 1.951626064956829

Epoch: 6| Step: 12
Training loss: 1.7391607761383057
Validation loss: 1.9428383957955144

Epoch: 6| Step: 13
Training loss: 2.5238730907440186
Validation loss: 1.9365620818189395

Epoch: 92| Step: 0
Training loss: 2.3161423206329346
Validation loss: 1.9557425642526278

Epoch: 6| Step: 1
Training loss: 1.6768898963928223
Validation loss: 1.968388754834411

Epoch: 6| Step: 2
Training loss: 2.6243836879730225
Validation loss: 1.9537720141872283

Epoch: 6| Step: 3
Training loss: 1.5773760080337524
Validation loss: 1.956964180033694

Epoch: 6| Step: 4
Training loss: 1.7760627269744873
Validation loss: 1.980709522001205

Epoch: 6| Step: 5
Training loss: 1.8180720806121826
Validation loss: 1.9675696870332122

Epoch: 6| Step: 6
Training loss: 1.597546100616455
Validation loss: 1.9559885301897604

Epoch: 6| Step: 7
Training loss: 2.57240629196167
Validation loss: 1.9712543436276015

Epoch: 6| Step: 8
Training loss: 3.4492716789245605
Validation loss: 1.9668330992421796

Epoch: 6| Step: 9
Training loss: 1.809524655342102
Validation loss: 1.9662462742097917

Epoch: 6| Step: 10
Training loss: 2.51395320892334
Validation loss: 1.985230307425222

Epoch: 6| Step: 11
Training loss: 2.857724189758301
Validation loss: 1.9896547691796416

Epoch: 6| Step: 12
Training loss: 1.8744665384292603
Validation loss: 1.97805582451564

Epoch: 6| Step: 13
Training loss: 1.5718351602554321
Validation loss: 1.9752926967477287

Epoch: 93| Step: 0
Training loss: 2.4301960468292236
Validation loss: 2.0024174785101287

Epoch: 6| Step: 1
Training loss: 2.155390977859497
Validation loss: 1.9921234833296908

Epoch: 6| Step: 2
Training loss: 2.290221691131592
Validation loss: 1.98119479866438

Epoch: 6| Step: 3
Training loss: 2.5362548828125
Validation loss: 1.993993474591163

Epoch: 6| Step: 4
Training loss: 1.2859522104263306
Validation loss: 2.017434313733091

Epoch: 6| Step: 5
Training loss: 1.9312595129013062
Validation loss: 2.0078002534886843

Epoch: 6| Step: 6
Training loss: 1.9249937534332275
Validation loss: 1.99423631288672

Epoch: 6| Step: 7
Training loss: 2.695621967315674
Validation loss: 2.0042942685465657

Epoch: 6| Step: 8
Training loss: 2.1980295181274414
Validation loss: 2.002037082948992

Epoch: 6| Step: 9
Training loss: 1.7600663900375366
Validation loss: 1.9943591663914342

Epoch: 6| Step: 10
Training loss: 2.5498952865600586
Validation loss: 1.9938324138682375

Epoch: 6| Step: 11
Training loss: 2.494877338409424
Validation loss: 1.9978024498108895

Epoch: 6| Step: 12
Training loss: 2.341515064239502
Validation loss: 2.0010657361758653

Epoch: 6| Step: 13
Training loss: 1.2564997673034668
Validation loss: 1.9931637651176863

Epoch: 94| Step: 0
Training loss: 2.1663241386413574
Validation loss: 1.9901282761686592

Epoch: 6| Step: 1
Training loss: 2.172196626663208
Validation loss: 1.9814133580012987

Epoch: 6| Step: 2
Training loss: 2.164564609527588
Validation loss: 1.9744813237138974

Epoch: 6| Step: 3
Training loss: 2.9363536834716797
Validation loss: 1.9809763764822355

Epoch: 6| Step: 4
Training loss: 2.0690970420837402
Validation loss: 1.9971296095078992

Epoch: 6| Step: 5
Training loss: 1.5731219053268433
Validation loss: 1.9912433931904454

Epoch: 6| Step: 6
Training loss: 2.500215530395508
Validation loss: 1.9928597750202302

Epoch: 6| Step: 7
Training loss: 2.190814733505249
Validation loss: 1.9868095074930499

Epoch: 6| Step: 8
Training loss: 2.2462425231933594
Validation loss: 2.009690002728534

Epoch: 6| Step: 9
Training loss: 1.9502308368682861
Validation loss: 1.9841131241090837

Epoch: 6| Step: 10
Training loss: 2.450439691543579
Validation loss: 1.9834242482339182

Epoch: 6| Step: 11
Training loss: 2.808636426925659
Validation loss: 1.9563643150432135

Epoch: 6| Step: 12
Training loss: 1.4477286338806152
Validation loss: 1.9516701903394473

Epoch: 6| Step: 13
Training loss: 1.46964430809021
Validation loss: 1.9574395994986258

Epoch: 95| Step: 0
Training loss: 2.2987043857574463
Validation loss: 1.967048833447118

Epoch: 6| Step: 1
Training loss: 2.3311548233032227
Validation loss: 1.9734672769423454

Epoch: 6| Step: 2
Training loss: 2.5724709033966064
Validation loss: 1.9531441709046722

Epoch: 6| Step: 3
Training loss: 1.750438928604126
Validation loss: 1.9558588099736038

Epoch: 6| Step: 4
Training loss: 2.0059592723846436
Validation loss: 1.9696972036874423

Epoch: 6| Step: 5
Training loss: 1.9716678857803345
Validation loss: 1.957952973663166

Epoch: 6| Step: 6
Training loss: 2.216759204864502
Validation loss: 1.9690747684048069

Epoch: 6| Step: 7
Training loss: 2.355097770690918
Validation loss: 1.9741310868211972

Epoch: 6| Step: 8
Training loss: 2.404496192932129
Validation loss: 1.9767488612923572

Epoch: 6| Step: 9
Training loss: 1.6164106130599976
Validation loss: 1.9666307254504132

Epoch: 6| Step: 10
Training loss: 2.080796241760254
Validation loss: 1.9755370437457997

Epoch: 6| Step: 11
Training loss: 2.112454891204834
Validation loss: 1.968516683065763

Epoch: 6| Step: 12
Training loss: 2.215156316757202
Validation loss: 1.9778687184856785

Epoch: 6| Step: 13
Training loss: 2.697754383087158
Validation loss: 1.9625028025719427

Epoch: 96| Step: 0
Training loss: 2.438784599304199
Validation loss: 1.9774337789063812

Epoch: 6| Step: 1
Training loss: 1.811378002166748
Validation loss: 1.9814745354396042

Epoch: 6| Step: 2
Training loss: 2.142350196838379
Validation loss: 1.972554773412725

Epoch: 6| Step: 3
Training loss: 3.0185790061950684
Validation loss: 1.9855051963560042

Epoch: 6| Step: 4
Training loss: 2.511916160583496
Validation loss: 1.9868244278815486

Epoch: 6| Step: 5
Training loss: 2.0774168968200684
Validation loss: 2.0022015148593533

Epoch: 6| Step: 6
Training loss: 2.337714672088623
Validation loss: 2.0048652823253343

Epoch: 6| Step: 7
Training loss: 2.536426067352295
Validation loss: 2.000556725327687

Epoch: 6| Step: 8
Training loss: 1.8997091054916382
Validation loss: 1.9758228307129235

Epoch: 6| Step: 9
Training loss: 2.3355259895324707
Validation loss: 1.9973331625743578

Epoch: 6| Step: 10
Training loss: 1.7137527465820312
Validation loss: 1.9889351142350065

Epoch: 6| Step: 11
Training loss: 1.6490578651428223
Validation loss: 1.9871939305336244

Epoch: 6| Step: 12
Training loss: 1.9418134689331055
Validation loss: 2.0060652302157496

Epoch: 6| Step: 13
Training loss: 1.8903961181640625
Validation loss: 1.9856840359267367

Epoch: 97| Step: 0
Training loss: 1.6829270124435425
Validation loss: 1.997140968999555

Epoch: 6| Step: 1
Training loss: 2.3789901733398438
Validation loss: 1.976122240866384

Epoch: 6| Step: 2
Training loss: 1.848649024963379
Validation loss: 1.9670701078189317

Epoch: 6| Step: 3
Training loss: 2.1880874633789062
Validation loss: 1.9655853343266312

Epoch: 6| Step: 4
Training loss: 2.235795736312866
Validation loss: 1.9659522759017123

Epoch: 6| Step: 5
Training loss: 2.2255396842956543
Validation loss: 1.944905447703536

Epoch: 6| Step: 6
Training loss: 2.252253293991089
Validation loss: 1.9490345934385895

Epoch: 6| Step: 7
Training loss: 1.7430431842803955
Validation loss: 1.9476585747093282

Epoch: 6| Step: 8
Training loss: 2.0738344192504883
Validation loss: 1.9613244200265536

Epoch: 6| Step: 9
Training loss: 2.590271472930908
Validation loss: 1.946628301374374

Epoch: 6| Step: 10
Training loss: 2.332242012023926
Validation loss: 1.9548944478393884

Epoch: 6| Step: 11
Training loss: 2.1158640384674072
Validation loss: 1.9381412947049705

Epoch: 6| Step: 12
Training loss: 2.457404613494873
Validation loss: 1.9543261194741854

Epoch: 6| Step: 13
Training loss: 2.171435832977295
Validation loss: 1.9416698614756267

Epoch: 98| Step: 0
Training loss: 2.538533926010132
Validation loss: 1.9491993611858738

Epoch: 6| Step: 1
Training loss: 2.2626447677612305
Validation loss: 1.9681819523534467

Epoch: 6| Step: 2
Training loss: 1.7587693929672241
Validation loss: 1.9660063866646058

Epoch: 6| Step: 3
Training loss: 2.2487144470214844
Validation loss: 1.952558563601586

Epoch: 6| Step: 4
Training loss: 1.8066350221633911
Validation loss: 1.937153047130954

Epoch: 6| Step: 5
Training loss: 2.0635194778442383
Validation loss: 1.9625131981347197

Epoch: 6| Step: 6
Training loss: 2.5301403999328613
Validation loss: 1.9453424202498568

Epoch: 6| Step: 7
Training loss: 2.45497465133667
Validation loss: 1.9508614770827755

Epoch: 6| Step: 8
Training loss: 1.7489991188049316
Validation loss: 1.9590591487064157

Epoch: 6| Step: 9
Training loss: 2.0802698135375977
Validation loss: 1.9373995386144167

Epoch: 6| Step: 10
Training loss: 2.190408706665039
Validation loss: 1.954618388606656

Epoch: 6| Step: 11
Training loss: 1.7000367641448975
Validation loss: 1.9551306757875668

Epoch: 6| Step: 12
Training loss: 2.343846321105957
Validation loss: 1.958552880953717

Epoch: 6| Step: 13
Training loss: 3.1048901081085205
Validation loss: 1.9575551043274582

Epoch: 99| Step: 0
Training loss: 2.7289271354675293
Validation loss: 1.9610427784663376

Epoch: 6| Step: 1
Training loss: 1.74288010597229
Validation loss: 1.98134191959135

Epoch: 6| Step: 2
Training loss: 1.444746971130371
Validation loss: 1.9869694876414474

Epoch: 6| Step: 3
Training loss: 2.9693925380706787
Validation loss: 1.9923562695903163

Epoch: 6| Step: 4
Training loss: 2.001833915710449
Validation loss: 1.9998067066233645

Epoch: 6| Step: 5
Training loss: 1.5567436218261719
Validation loss: 2.0003559499658565

Epoch: 6| Step: 6
Training loss: 1.5179827213287354
Validation loss: 2.0005798237298125

Epoch: 6| Step: 7
Training loss: 2.2469425201416016
Validation loss: 1.9896458374556674

Epoch: 6| Step: 8
Training loss: 2.786670684814453
Validation loss: 2.0050369026840373

Epoch: 6| Step: 9
Training loss: 2.9071788787841797
Validation loss: 1.9869309304862894

Epoch: 6| Step: 10
Training loss: 1.6146999597549438
Validation loss: 2.003113219814916

Epoch: 6| Step: 11
Training loss: 2.527200937271118
Validation loss: 1.9860104924889022

Epoch: 6| Step: 12
Training loss: 1.9055604934692383
Validation loss: 2.0029792426734843

Epoch: 6| Step: 13
Training loss: 2.403925657272339
Validation loss: 2.004351544123824

Epoch: 100| Step: 0
Training loss: 2.567261219024658
Validation loss: 1.9929492345420263

Epoch: 6| Step: 1
Training loss: 1.9009737968444824
Validation loss: 1.9879278495747557

Epoch: 6| Step: 2
Training loss: 2.210235834121704
Validation loss: 2.007218171191472

Epoch: 6| Step: 3
Training loss: 2.819042921066284
Validation loss: 2.0001770834768973

Epoch: 6| Step: 4
Training loss: 2.3915109634399414
Validation loss: 1.9974184779710666

Epoch: 6| Step: 5
Training loss: 2.223257303237915
Validation loss: 2.0170682232867003

Epoch: 6| Step: 6
Training loss: 2.278629779815674
Validation loss: 2.006551327243928

Epoch: 6| Step: 7
Training loss: 2.6125192642211914
Validation loss: 2.0121942502196117

Epoch: 6| Step: 8
Training loss: 2.0416743755340576
Validation loss: 2.0207152981911936

Epoch: 6| Step: 9
Training loss: 1.4935376644134521
Validation loss: 2.00589176916307

Epoch: 6| Step: 10
Training loss: 2.5258355140686035
Validation loss: 2.0122976546646445

Epoch: 6| Step: 11
Training loss: 1.7053031921386719
Validation loss: 2.017732251075006

Epoch: 6| Step: 12
Training loss: 1.5140033960342407
Validation loss: 1.9960776990459812

Epoch: 6| Step: 13
Training loss: 2.039074420928955
Validation loss: 1.993330006958336

Epoch: 101| Step: 0
Training loss: 1.9378230571746826
Validation loss: 1.9831830263137817

Epoch: 6| Step: 1
Training loss: 1.7628083229064941
Validation loss: 1.991269370561005

Epoch: 6| Step: 2
Training loss: 2.6909990310668945
Validation loss: 1.9846208582642257

Epoch: 6| Step: 3
Training loss: 2.3840279579162598
Validation loss: 1.9922064811952653

Epoch: 6| Step: 4
Training loss: 1.5354077816009521
Validation loss: 1.9834733522066506

Epoch: 6| Step: 5
Training loss: 2.1888585090637207
Validation loss: 1.968820079680412

Epoch: 6| Step: 6
Training loss: 2.6909689903259277
Validation loss: 1.9643738615897395

Epoch: 6| Step: 7
Training loss: 1.9275131225585938
Validation loss: 1.961474701922427

Epoch: 6| Step: 8
Training loss: 1.6106436252593994
Validation loss: 1.959173071768976

Epoch: 6| Step: 9
Training loss: 1.8227858543395996
Validation loss: 1.9689353358361028

Epoch: 6| Step: 10
Training loss: 2.75136137008667
Validation loss: 1.9495270034318328

Epoch: 6| Step: 11
Training loss: 2.9374523162841797
Validation loss: 1.9441935682809481

Epoch: 6| Step: 12
Training loss: 1.8896604776382446
Validation loss: 1.9544084354113507

Epoch: 6| Step: 13
Training loss: 2.128872871398926
Validation loss: 1.9622942324607604

Epoch: 102| Step: 0
Training loss: 2.207115650177002
Validation loss: 1.957150678480825

Epoch: 6| Step: 1
Training loss: 2.1694467067718506
Validation loss: 1.9757142054137362

Epoch: 6| Step: 2
Training loss: 1.9151500463485718
Validation loss: 1.9553487800782727

Epoch: 6| Step: 3
Training loss: 1.991258978843689
Validation loss: 1.9777704297855336

Epoch: 6| Step: 4
Training loss: 1.5564141273498535
Validation loss: 1.9695386745596444

Epoch: 6| Step: 5
Training loss: 2.2364096641540527
Validation loss: 1.9927080062127882

Epoch: 6| Step: 6
Training loss: 2.290015935897827
Validation loss: 1.983882555397608

Epoch: 6| Step: 7
Training loss: 2.104048252105713
Validation loss: 1.9674103042130828

Epoch: 6| Step: 8
Training loss: 2.6969900131225586
Validation loss: 1.9667385124391126

Epoch: 6| Step: 9
Training loss: 2.577033519744873
Validation loss: 2.015477947009507

Epoch: 6| Step: 10
Training loss: 1.962182641029358
Validation loss: 1.9935103436951995

Epoch: 6| Step: 11
Training loss: 2.428236961364746
Validation loss: 1.9854066743645618

Epoch: 6| Step: 12
Training loss: 1.8590970039367676
Validation loss: 1.991842113515382

Epoch: 6| Step: 13
Training loss: 2.2169840335845947
Validation loss: 1.998840226921984

Epoch: 103| Step: 0
Training loss: 2.2350375652313232
Validation loss: 1.9844859915394937

Epoch: 6| Step: 1
Training loss: 2.103571653366089
Validation loss: 1.9831698658645793

Epoch: 6| Step: 2
Training loss: 2.242673397064209
Validation loss: 1.9752749858363983

Epoch: 6| Step: 3
Training loss: 2.0378904342651367
Validation loss: 1.9704302510907572

Epoch: 6| Step: 4
Training loss: 1.7327017784118652
Validation loss: 1.967247555332799

Epoch: 6| Step: 5
Training loss: 2.7962021827697754
Validation loss: 1.9728789688438497

Epoch: 6| Step: 6
Training loss: 2.496311664581299
Validation loss: 1.9635381237153084

Epoch: 6| Step: 7
Training loss: 2.4883010387420654
Validation loss: 1.9784328732439267

Epoch: 6| Step: 8
Training loss: 1.4332901239395142
Validation loss: 1.9544994818267

Epoch: 6| Step: 9
Training loss: 2.7059755325317383
Validation loss: 1.9649011806775165

Epoch: 6| Step: 10
Training loss: 1.6857249736785889
Validation loss: 1.98290519432355

Epoch: 6| Step: 11
Training loss: 2.277531385421753
Validation loss: 1.9712351586229058

Epoch: 6| Step: 12
Training loss: 2.07157564163208
Validation loss: 1.998306341068719

Epoch: 6| Step: 13
Training loss: 1.5119808912277222
Validation loss: 1.983600761300774

Epoch: 104| Step: 0
Training loss: 1.7415146827697754
Validation loss: 1.9776484479186356

Epoch: 6| Step: 1
Training loss: 2.3084521293640137
Validation loss: 1.9748004226274387

Epoch: 6| Step: 2
Training loss: 1.7462985515594482
Validation loss: 1.9715063213020243

Epoch: 6| Step: 3
Training loss: 2.5667884349823
Validation loss: 1.9962834042887534

Epoch: 6| Step: 4
Training loss: 1.7967137098312378
Validation loss: 1.9710869186667985

Epoch: 6| Step: 5
Training loss: 1.9796533584594727
Validation loss: 1.9716643159107496

Epoch: 6| Step: 6
Training loss: 2.2715532779693604
Validation loss: 1.9822352086344073

Epoch: 6| Step: 7
Training loss: 2.2614097595214844
Validation loss: 1.9593440153265511

Epoch: 6| Step: 8
Training loss: 1.524003267288208
Validation loss: 1.9929439239604498

Epoch: 6| Step: 9
Training loss: 2.6198768615722656
Validation loss: 1.9735033781297746

Epoch: 6| Step: 10
Training loss: 1.4937807321548462
Validation loss: 1.9839567804849276

Epoch: 6| Step: 11
Training loss: 2.9020955562591553
Validation loss: 1.9612157716546008

Epoch: 6| Step: 12
Training loss: 2.5783770084381104
Validation loss: 1.9628384190220987

Epoch: 6| Step: 13
Training loss: 2.1607446670532227
Validation loss: 1.9871169392780592

Epoch: 105| Step: 0
Training loss: 1.3681797981262207
Validation loss: 1.9693117141723633

Epoch: 6| Step: 1
Training loss: 2.4399325847625732
Validation loss: 1.9606936593209543

Epoch: 6| Step: 2
Training loss: 2.809298276901245
Validation loss: 1.9594383021836639

Epoch: 6| Step: 3
Training loss: 1.9283782243728638
Validation loss: 1.9637243247801257

Epoch: 6| Step: 4
Training loss: 1.448134422302246
Validation loss: 1.9822064189500705

Epoch: 6| Step: 5
Training loss: 2.696329355239868
Validation loss: 1.9724316186802362

Epoch: 6| Step: 6
Training loss: 1.0687819719314575
Validation loss: 1.9938837546174244

Epoch: 6| Step: 7
Training loss: 2.486844539642334
Validation loss: 1.9834946714421755

Epoch: 6| Step: 8
Training loss: 2.4105565547943115
Validation loss: 1.976763895762864

Epoch: 6| Step: 9
Training loss: 2.625033378601074
Validation loss: 1.9856757194765153

Epoch: 6| Step: 10
Training loss: 1.6876780986785889
Validation loss: 1.9744240186547721

Epoch: 6| Step: 11
Training loss: 2.54561710357666
Validation loss: 1.9896293660645843

Epoch: 6| Step: 12
Training loss: 2.452699661254883
Validation loss: 1.9822450837781351

Epoch: 6| Step: 13
Training loss: 2.1360905170440674
Validation loss: 1.9962398082979265

Epoch: 106| Step: 0
Training loss: 1.7902894020080566
Validation loss: 1.9869182545651671

Epoch: 6| Step: 1
Training loss: 1.3174018859863281
Validation loss: 1.9686841375084334

Epoch: 6| Step: 2
Training loss: 1.446162223815918
Validation loss: 1.9809688701424548

Epoch: 6| Step: 3
Training loss: 2.326272487640381
Validation loss: 1.9722015908969346

Epoch: 6| Step: 4
Training loss: 2.3879008293151855
Validation loss: 1.9717289734912176

Epoch: 6| Step: 5
Training loss: 2.0011203289031982
Validation loss: 1.9699529460681382

Epoch: 6| Step: 6
Training loss: 1.4935636520385742
Validation loss: 1.970930576324463

Epoch: 6| Step: 7
Training loss: 2.9553024768829346
Validation loss: 1.9943247802795903

Epoch: 6| Step: 8
Training loss: 2.2397847175598145
Validation loss: 1.9780105954857283

Epoch: 6| Step: 9
Training loss: 2.7844738960266113
Validation loss: 1.9774289310619395

Epoch: 6| Step: 10
Training loss: 1.6858620643615723
Validation loss: 1.9572772364462576

Epoch: 6| Step: 11
Training loss: 2.3767895698547363
Validation loss: 1.9710837333433089

Epoch: 6| Step: 12
Training loss: 3.1871044635772705
Validation loss: 1.97943208038166

Epoch: 6| Step: 13
Training loss: 2.103189468383789
Validation loss: 1.9685671880681028

Epoch: 107| Step: 0
Training loss: 2.252943515777588
Validation loss: 1.978804447317636

Epoch: 6| Step: 1
Training loss: 2.1884498596191406
Validation loss: 1.9673506175318072

Epoch: 6| Step: 2
Training loss: 2.18558931350708
Validation loss: 1.973012383266162

Epoch: 6| Step: 3
Training loss: 1.9955005645751953
Validation loss: 1.9726884647082257

Epoch: 6| Step: 4
Training loss: 1.8036383390426636
Validation loss: 1.9591272159289288

Epoch: 6| Step: 5
Training loss: 1.9166909456253052
Validation loss: 1.9699370322688934

Epoch: 6| Step: 6
Training loss: 2.4532456398010254
Validation loss: 1.9654090071237216

Epoch: 6| Step: 7
Training loss: 2.014105796813965
Validation loss: 1.9861019529322141

Epoch: 6| Step: 8
Training loss: 1.8479039669036865
Validation loss: 1.94646962611906

Epoch: 6| Step: 9
Training loss: 2.1472716331481934
Validation loss: 1.9446734433533044

Epoch: 6| Step: 10
Training loss: 2.4923295974731445
Validation loss: 1.9608033254582395

Epoch: 6| Step: 11
Training loss: 1.9025702476501465
Validation loss: 1.962839166323344

Epoch: 6| Step: 12
Training loss: 2.3777899742126465
Validation loss: 1.9414674953747821

Epoch: 6| Step: 13
Training loss: 2.7130367755889893
Validation loss: 1.9503018445866083

Epoch: 108| Step: 0
Training loss: 1.9445091485977173
Validation loss: 1.9642812077717116

Epoch: 6| Step: 1
Training loss: 1.8010703325271606
Validation loss: 1.966211344606133

Epoch: 6| Step: 2
Training loss: 2.207651138305664
Validation loss: 1.9600998355496315

Epoch: 6| Step: 3
Training loss: 1.7662549018859863
Validation loss: 1.9762679492273638

Epoch: 6| Step: 4
Training loss: 2.4010305404663086
Validation loss: 1.981762739919847

Epoch: 6| Step: 5
Training loss: 1.6280560493469238
Validation loss: 1.9839573380767659

Epoch: 6| Step: 6
Training loss: 2.408740758895874
Validation loss: 1.9777801600835656

Epoch: 6| Step: 7
Training loss: 2.5874698162078857
Validation loss: 2.00304998377318

Epoch: 6| Step: 8
Training loss: 1.7796494960784912
Validation loss: 2.003315394924533

Epoch: 6| Step: 9
Training loss: 2.342724561691284
Validation loss: 2.0296097135031097

Epoch: 6| Step: 10
Training loss: 2.032628059387207
Validation loss: 2.018032581575455

Epoch: 6| Step: 11
Training loss: 2.8036537170410156
Validation loss: 2.023225131855216

Epoch: 6| Step: 12
Training loss: 2.4038867950439453
Validation loss: 2.0276053951632593

Epoch: 6| Step: 13
Training loss: 1.8969268798828125
Validation loss: 2.048320067826138

Epoch: 109| Step: 0
Training loss: 1.674612283706665
Validation loss: 2.02252471575173

Epoch: 6| Step: 1
Training loss: 3.012380599975586
Validation loss: 2.0250565672433503

Epoch: 6| Step: 2
Training loss: 1.825895071029663
Validation loss: 2.0151378467518795

Epoch: 6| Step: 3
Training loss: 2.1462512016296387
Validation loss: 2.0408079124266103

Epoch: 6| Step: 4
Training loss: 2.5947482585906982
Validation loss: 1.9992434247847526

Epoch: 6| Step: 5
Training loss: 2.6089887619018555
Validation loss: 1.9982533583077051

Epoch: 6| Step: 6
Training loss: 2.9179625511169434
Validation loss: 2.01050183978132

Epoch: 6| Step: 7
Training loss: 2.1870176792144775
Validation loss: 1.9880165746135097

Epoch: 6| Step: 8
Training loss: 2.054187774658203
Validation loss: 1.9975551712897517

Epoch: 6| Step: 9
Training loss: 1.7244302034378052
Validation loss: 1.9958533958722187

Epoch: 6| Step: 10
Training loss: 1.547292947769165
Validation loss: 1.9877806837840746

Epoch: 6| Step: 11
Training loss: 2.095551013946533
Validation loss: 1.975904498049008

Epoch: 6| Step: 12
Training loss: 1.5596613883972168
Validation loss: 2.004679027424064

Epoch: 6| Step: 13
Training loss: 1.692121982574463
Validation loss: 1.978566042838558

Epoch: 110| Step: 0
Training loss: 2.1279478073120117
Validation loss: 1.987887409425551

Epoch: 6| Step: 1
Training loss: 1.8478517532348633
Validation loss: 1.9794330673833047

Epoch: 6| Step: 2
Training loss: 2.5127532482147217
Validation loss: 1.9980667637240501

Epoch: 6| Step: 3
Training loss: 2.2360942363739014
Validation loss: 2.001066377086024

Epoch: 6| Step: 4
Training loss: 2.4456801414489746
Validation loss: 1.9763208473882368

Epoch: 6| Step: 5
Training loss: 2.366081714630127
Validation loss: 1.97672240964828

Epoch: 6| Step: 6
Training loss: 2.1842117309570312
Validation loss: 2.0017316110672487

Epoch: 6| Step: 7
Training loss: 1.9945282936096191
Validation loss: 1.9975141312486382

Epoch: 6| Step: 8
Training loss: 1.9331499338150024
Validation loss: 1.9851071526927333

Epoch: 6| Step: 9
Training loss: 1.824660062789917
Validation loss: 2.0030594128434376

Epoch: 6| Step: 10
Training loss: 2.2034475803375244
Validation loss: 2.0006189782132386

Epoch: 6| Step: 11
Training loss: 1.6649181842803955
Validation loss: 1.9632347142824562

Epoch: 6| Step: 12
Training loss: 1.7178516387939453
Validation loss: 1.9893364778129004

Epoch: 6| Step: 13
Training loss: 3.368680000305176
Validation loss: 1.9901843070983887

Epoch: 111| Step: 0
Training loss: 1.760025978088379
Validation loss: 2.000525225875198

Epoch: 6| Step: 1
Training loss: 2.4193058013916016
Validation loss: 1.9724527507699945

Epoch: 6| Step: 2
Training loss: 2.210256576538086
Validation loss: 1.9798638051556003

Epoch: 6| Step: 3
Training loss: 1.713254451751709
Validation loss: 1.9753946258175759

Epoch: 6| Step: 4
Training loss: 1.9740970134735107
Validation loss: 1.9976384742285616

Epoch: 6| Step: 5
Training loss: 2.1683642864227295
Validation loss: 1.9931417639537523

Epoch: 6| Step: 6
Training loss: 2.2547290325164795
Validation loss: 1.9869787500750633

Epoch: 6| Step: 7
Training loss: 2.069884777069092
Validation loss: 1.9670129078690723

Epoch: 6| Step: 8
Training loss: 1.9982876777648926
Validation loss: 1.9736997363387898

Epoch: 6| Step: 9
Training loss: 1.9244790077209473
Validation loss: 1.9743707641478507

Epoch: 6| Step: 10
Training loss: 2.2451741695404053
Validation loss: 1.9871168367324337

Epoch: 6| Step: 11
Training loss: 1.9249087572097778
Validation loss: 1.975659913914178

Epoch: 6| Step: 12
Training loss: 2.86653208732605
Validation loss: 1.9636483743626585

Epoch: 6| Step: 13
Training loss: 2.3599460124969482
Validation loss: 1.9749326385477537

Epoch: 112| Step: 0
Training loss: 2.255072593688965
Validation loss: 1.960565141452256

Epoch: 6| Step: 1
Training loss: 1.627496600151062
Validation loss: 1.9644356722472816

Epoch: 6| Step: 2
Training loss: 1.921756625175476
Validation loss: 1.9642041575524114

Epoch: 6| Step: 3
Training loss: 2.922013998031616
Validation loss: 1.9739832109020603

Epoch: 6| Step: 4
Training loss: 2.3663885593414307
Validation loss: 1.9837727751783145

Epoch: 6| Step: 5
Training loss: 2.241168260574341
Validation loss: 1.963117427723382

Epoch: 6| Step: 6
Training loss: 2.5016889572143555
Validation loss: 1.9524743057066394

Epoch: 6| Step: 7
Training loss: 2.2303056716918945
Validation loss: 1.9745945238297986

Epoch: 6| Step: 8
Training loss: 2.1679868698120117
Validation loss: 1.9670215319561701

Epoch: 6| Step: 9
Training loss: 2.328583240509033
Validation loss: 1.9569048702075917

Epoch: 6| Step: 10
Training loss: 1.3795526027679443
Validation loss: 1.9515688521887666

Epoch: 6| Step: 11
Training loss: 1.9804668426513672
Validation loss: 1.965395035282258

Epoch: 6| Step: 12
Training loss: 1.8727552890777588
Validation loss: 1.967416819705758

Epoch: 6| Step: 13
Training loss: 1.92069673538208
Validation loss: 1.9761354859157274

Epoch: 113| Step: 0
Training loss: 2.274837017059326
Validation loss: 1.9607710325589744

Epoch: 6| Step: 1
Training loss: 2.1770076751708984
Validation loss: 1.9604843534449095

Epoch: 6| Step: 2
Training loss: 1.6733856201171875
Validation loss: 1.9685191236516482

Epoch: 6| Step: 3
Training loss: 2.781381130218506
Validation loss: 2.002194760948099

Epoch: 6| Step: 4
Training loss: 1.6815299987792969
Validation loss: 1.9974531781288885

Epoch: 6| Step: 5
Training loss: 2.8186159133911133
Validation loss: 1.9910787715706775

Epoch: 6| Step: 6
Training loss: 1.8712592124938965
Validation loss: 2.0151804288228354

Epoch: 6| Step: 7
Training loss: 1.6339480876922607
Validation loss: 1.9777905223190144

Epoch: 6| Step: 8
Training loss: 1.7293803691864014
Validation loss: 1.9858139304704563

Epoch: 6| Step: 9
Training loss: 2.351935386657715
Validation loss: 1.999927290024296

Epoch: 6| Step: 10
Training loss: 2.197510242462158
Validation loss: 1.9829187777734572

Epoch: 6| Step: 11
Training loss: 2.1218461990356445
Validation loss: 2.0021467644681215

Epoch: 6| Step: 12
Training loss: 2.0107200145721436
Validation loss: 2.0103290773207143

Epoch: 6| Step: 13
Training loss: 2.8751094341278076
Validation loss: 2.009314129429479

Epoch: 114| Step: 0
Training loss: 2.0895204544067383
Validation loss: 1.989891416283064

Epoch: 6| Step: 1
Training loss: 1.5891300439834595
Validation loss: 2.0214934259332638

Epoch: 6| Step: 2
Training loss: 1.529183030128479
Validation loss: 2.0242298533839564

Epoch: 6| Step: 3
Training loss: 2.303713798522949
Validation loss: 2.0002938073168517

Epoch: 6| Step: 4
Training loss: 2.405519723892212
Validation loss: 2.0080041795648556

Epoch: 6| Step: 5
Training loss: 1.8748012781143188
Validation loss: 1.9943644680002683

Epoch: 6| Step: 6
Training loss: 2.172654151916504
Validation loss: 2.0081935018621464

Epoch: 6| Step: 7
Training loss: 2.028568744659424
Validation loss: 1.998095004789291

Epoch: 6| Step: 8
Training loss: 2.8650736808776855
Validation loss: 1.9893542848607546

Epoch: 6| Step: 9
Training loss: 2.3417391777038574
Validation loss: 2.0003585764156875

Epoch: 6| Step: 10
Training loss: 2.6397929191589355
Validation loss: 1.9931500214402393

Epoch: 6| Step: 11
Training loss: 1.565483808517456
Validation loss: 1.9995014898238643

Epoch: 6| Step: 12
Training loss: 2.0636613368988037
Validation loss: 2.0133611591913367

Epoch: 6| Step: 13
Training loss: 2.4276368618011475
Validation loss: 1.9798901106721611

Epoch: 115| Step: 0
Training loss: 2.3198938369750977
Validation loss: 1.994335937243636

Epoch: 6| Step: 1
Training loss: 2.947880506515503
Validation loss: 1.9832679251188874

Epoch: 6| Step: 2
Training loss: 1.8833295106887817
Validation loss: 1.9886428310025124

Epoch: 6| Step: 3
Training loss: 1.8471359014511108
Validation loss: 1.9994665166383148

Epoch: 6| Step: 4
Training loss: 2.6850080490112305
Validation loss: 2.005240773641935

Epoch: 6| Step: 5
Training loss: 2.214848518371582
Validation loss: 2.0023048590588313

Epoch: 6| Step: 6
Training loss: 1.9457417726516724
Validation loss: 2.0035815392771075

Epoch: 6| Step: 7
Training loss: 2.0509753227233887
Validation loss: 2.003382489245425

Epoch: 6| Step: 8
Training loss: 1.787731409072876
Validation loss: 1.9953005518964542

Epoch: 6| Step: 9
Training loss: 2.201815605163574
Validation loss: 1.9942010320642942

Epoch: 6| Step: 10
Training loss: 1.976576805114746
Validation loss: 2.0033259776330765

Epoch: 6| Step: 11
Training loss: 1.5857113599777222
Validation loss: 1.9958272800650647

Epoch: 6| Step: 12
Training loss: 1.9301931858062744
Validation loss: 1.9839703293256863

Epoch: 6| Step: 13
Training loss: 2.6736159324645996
Validation loss: 1.990302256358567

Epoch: 116| Step: 0
Training loss: 1.9601354598999023
Validation loss: 2.008890927478831

Epoch: 6| Step: 1
Training loss: 2.6087212562561035
Validation loss: 1.9966164519709926

Epoch: 6| Step: 2
Training loss: 1.9851112365722656
Validation loss: 1.9653738660197104

Epoch: 6| Step: 3
Training loss: 2.1447482109069824
Validation loss: 1.9879324000368837

Epoch: 6| Step: 4
Training loss: 1.9755717515945435
Validation loss: 1.989917939709079

Epoch: 6| Step: 5
Training loss: 1.9675524234771729
Validation loss: 1.9686345477258005

Epoch: 6| Step: 6
Training loss: 1.5442793369293213
Validation loss: 1.9798908002914921

Epoch: 6| Step: 7
Training loss: 2.176126718521118
Validation loss: 1.988987881650207

Epoch: 6| Step: 8
Training loss: 1.8558461666107178
Validation loss: 1.9468327940151255

Epoch: 6| Step: 9
Training loss: 2.2015721797943115
Validation loss: 1.9632260760953348

Epoch: 6| Step: 10
Training loss: 2.3743338584899902
Validation loss: 1.9620914818138204

Epoch: 6| Step: 11
Training loss: 2.0677855014801025
Validation loss: 1.9626860003317557

Epoch: 6| Step: 12
Training loss: 3.2881340980529785
Validation loss: 1.970109547338178

Epoch: 6| Step: 13
Training loss: 1.6582543849945068
Validation loss: 1.957620402818085

Epoch: 117| Step: 0
Training loss: 2.1521291732788086
Validation loss: 1.9547937172715382

Epoch: 6| Step: 1
Training loss: 1.3618494272232056
Validation loss: 1.9864379846921532

Epoch: 6| Step: 2
Training loss: 1.950164556503296
Validation loss: 1.9779924628555134

Epoch: 6| Step: 3
Training loss: 1.9892044067382812
Validation loss: 2.000106321868076

Epoch: 6| Step: 4
Training loss: 2.174851179122925
Validation loss: 1.9969765832347255

Epoch: 6| Step: 5
Training loss: 2.448033571243286
Validation loss: 2.003977708919074

Epoch: 6| Step: 6
Training loss: 2.132309913635254
Validation loss: 1.9702278849899129

Epoch: 6| Step: 7
Training loss: 1.9076709747314453
Validation loss: 2.0188532542156916

Epoch: 6| Step: 8
Training loss: 2.249415397644043
Validation loss: 1.9915881682467718

Epoch: 6| Step: 9
Training loss: 1.7290961742401123
Validation loss: 2.0003614528204805

Epoch: 6| Step: 10
Training loss: 2.381089687347412
Validation loss: 2.012046751155648

Epoch: 6| Step: 11
Training loss: 2.521653175354004
Validation loss: 1.9875890465192898

Epoch: 6| Step: 12
Training loss: 2.5772318840026855
Validation loss: 2.0132177286250617

Epoch: 6| Step: 13
Training loss: 1.7735371589660645
Validation loss: 1.9902834866636543

Epoch: 118| Step: 0
Training loss: 2.10263729095459
Validation loss: 1.983394875321337

Epoch: 6| Step: 1
Training loss: 2.456503391265869
Validation loss: 2.0024424163244103

Epoch: 6| Step: 2
Training loss: 1.8582556247711182
Validation loss: 1.9978561298821562

Epoch: 6| Step: 3
Training loss: 1.844709873199463
Validation loss: 1.9938182446264452

Epoch: 6| Step: 4
Training loss: 2.2417213916778564
Validation loss: 1.9977347414980653

Epoch: 6| Step: 5
Training loss: 1.9913504123687744
Validation loss: 1.9865774531518259

Epoch: 6| Step: 6
Training loss: 1.7632856369018555
Validation loss: 2.0245173567084858

Epoch: 6| Step: 7
Training loss: 2.245239019393921
Validation loss: 2.015387471004199

Epoch: 6| Step: 8
Training loss: 2.7191321849823
Validation loss: 2.014890605403531

Epoch: 6| Step: 9
Training loss: 2.1662979125976562
Validation loss: 2.0175275802612305

Epoch: 6| Step: 10
Training loss: 2.201784610748291
Validation loss: 2.025884336040866

Epoch: 6| Step: 11
Training loss: 2.3691978454589844
Validation loss: 2.0013779683779647

Epoch: 6| Step: 12
Training loss: 1.857245683670044
Validation loss: 2.009145772585305

Epoch: 6| Step: 13
Training loss: 1.8224817514419556
Validation loss: 1.9974103691757366

Epoch: 119| Step: 0
Training loss: 2.1202216148376465
Validation loss: 2.006687072015578

Epoch: 6| Step: 1
Training loss: 2.2313828468322754
Validation loss: 2.0104106792839627

Epoch: 6| Step: 2
Training loss: 1.7960994243621826
Validation loss: 1.9795591087751492

Epoch: 6| Step: 3
Training loss: 2.346254825592041
Validation loss: 1.985131489333286

Epoch: 6| Step: 4
Training loss: 2.154607057571411
Validation loss: 1.9987772664716166

Epoch: 6| Step: 5
Training loss: 1.9831631183624268
Validation loss: 1.9765916973031976

Epoch: 6| Step: 6
Training loss: 2.105259418487549
Validation loss: 1.9804839934072187

Epoch: 6| Step: 7
Training loss: 2.417318820953369
Validation loss: 1.971777198135212

Epoch: 6| Step: 8
Training loss: 2.0962345600128174
Validation loss: 1.9794146373707762

Epoch: 6| Step: 9
Training loss: 1.7199302911758423
Validation loss: 1.975293396621622

Epoch: 6| Step: 10
Training loss: 2.1406056880950928
Validation loss: 1.983394310038577

Epoch: 6| Step: 11
Training loss: 2.1773037910461426
Validation loss: 1.94557225319647

Epoch: 6| Step: 12
Training loss: 1.8578070402145386
Validation loss: 1.9775227449273551

Epoch: 6| Step: 13
Training loss: 2.451301097869873
Validation loss: 1.9960944088556434

Epoch: 120| Step: 0
Training loss: 2.195418357849121
Validation loss: 1.9878214405428978

Epoch: 6| Step: 1
Training loss: 1.3440918922424316
Validation loss: 1.9919001722848544

Epoch: 6| Step: 2
Training loss: 3.125396251678467
Validation loss: 1.9828737346074914

Epoch: 6| Step: 3
Training loss: 2.384854793548584
Validation loss: 1.9618746362706667

Epoch: 6| Step: 4
Training loss: 1.3906128406524658
Validation loss: 1.9667421643451979

Epoch: 6| Step: 5
Training loss: 2.2819273471832275
Validation loss: 1.9916070956055836

Epoch: 6| Step: 6
Training loss: 2.33453631401062
Validation loss: 1.9726357562567598

Epoch: 6| Step: 7
Training loss: 2.541602611541748
Validation loss: 1.9926332389154742

Epoch: 6| Step: 8
Training loss: 2.7663888931274414
Validation loss: 1.996259045857255

Epoch: 6| Step: 9
Training loss: 1.208688735961914
Validation loss: 1.9874022852989934

Epoch: 6| Step: 10
Training loss: 2.4489212036132812
Validation loss: 1.970737967439877

Epoch: 6| Step: 11
Training loss: 1.9789000749588013
Validation loss: 1.9920727886179441

Epoch: 6| Step: 12
Training loss: 1.7749900817871094
Validation loss: 1.979789767214047

Epoch: 6| Step: 13
Training loss: 1.271256446838379
Validation loss: 1.9935748871936594

Epoch: 121| Step: 0
Training loss: 2.1850709915161133
Validation loss: 1.991312183359618

Epoch: 6| Step: 1
Training loss: 1.8080943822860718
Validation loss: 2.010934437474897

Epoch: 6| Step: 2
Training loss: 2.550447940826416
Validation loss: 2.0184856076394357

Epoch: 6| Step: 3
Training loss: 2.7336666584014893
Validation loss: 2.011823400374382

Epoch: 6| Step: 4
Training loss: 2.368753433227539
Validation loss: 2.0045598617164035

Epoch: 6| Step: 5
Training loss: 2.325650691986084
Validation loss: 2.030562049599104

Epoch: 6| Step: 6
Training loss: 2.1051361560821533
Validation loss: 2.011125050565248

Epoch: 6| Step: 7
Training loss: 2.3737456798553467
Validation loss: 2.043003418112314

Epoch: 6| Step: 8
Training loss: 2.6311988830566406
Validation loss: 2.024154496449296

Epoch: 6| Step: 9
Training loss: 1.600111484527588
Validation loss: 2.0181306344206615

Epoch: 6| Step: 10
Training loss: 1.9512650966644287
Validation loss: 2.0249158784907353

Epoch: 6| Step: 11
Training loss: 1.766385555267334
Validation loss: 2.006704847017924

Epoch: 6| Step: 12
Training loss: 1.4093279838562012
Validation loss: 1.9972616293097054

Epoch: 6| Step: 13
Training loss: 1.7420356273651123
Validation loss: 2.0014542033595424

Epoch: 122| Step: 0
Training loss: 2.4182300567626953
Validation loss: 2.0008051087779384

Epoch: 6| Step: 1
Training loss: 2.153923988342285
Validation loss: 1.979648176059928

Epoch: 6| Step: 2
Training loss: 2.0883944034576416
Validation loss: 2.001738840533841

Epoch: 6| Step: 3
Training loss: 2.82041072845459
Validation loss: 1.9859022914722402

Epoch: 6| Step: 4
Training loss: 2.372318744659424
Validation loss: 1.9967115130475772

Epoch: 6| Step: 5
Training loss: 1.9988856315612793
Validation loss: 1.9722771106227752

Epoch: 6| Step: 6
Training loss: 1.5289320945739746
Validation loss: 2.000290231038165

Epoch: 6| Step: 7
Training loss: 1.9395562410354614
Validation loss: 2.0035439191326017

Epoch: 6| Step: 8
Training loss: 1.9914551973342896
Validation loss: 1.9944348386538926

Epoch: 6| Step: 9
Training loss: 2.468946695327759
Validation loss: 1.9778809931970411

Epoch: 6| Step: 10
Training loss: 2.102811813354492
Validation loss: 1.9770948194688367

Epoch: 6| Step: 11
Training loss: 1.6973718404769897
Validation loss: 1.9787876118895829

Epoch: 6| Step: 12
Training loss: 2.2773571014404297
Validation loss: 1.977038332211074

Epoch: 6| Step: 13
Training loss: 1.1344716548919678
Validation loss: 1.9818203154430594

Epoch: 123| Step: 0
Training loss: 1.7922537326812744
Validation loss: 1.997120762384066

Epoch: 6| Step: 1
Training loss: 1.5122884511947632
Validation loss: 1.9966023250292706

Epoch: 6| Step: 2
Training loss: 2.2085442543029785
Validation loss: 1.981534291339177

Epoch: 6| Step: 3
Training loss: 2.434285879135132
Validation loss: 1.9508234352193854

Epoch: 6| Step: 4
Training loss: 1.9814590215682983
Validation loss: 1.961930690273162

Epoch: 6| Step: 5
Training loss: 2.514810562133789
Validation loss: 1.9515325125827585

Epoch: 6| Step: 6
Training loss: 1.9459213018417358
Validation loss: 2.0046098591178976

Epoch: 6| Step: 7
Training loss: 3.1345653533935547
Validation loss: 1.9325349510356944

Epoch: 6| Step: 8
Training loss: 2.091858386993408
Validation loss: 1.9419317963302776

Epoch: 6| Step: 9
Training loss: 2.5437874794006348
Validation loss: 1.960370522673412

Epoch: 6| Step: 10
Training loss: 1.4712238311767578
Validation loss: 1.9679212236917147

Epoch: 6| Step: 11
Training loss: 2.3754167556762695
Validation loss: 1.9780492885138399

Epoch: 6| Step: 12
Training loss: 1.6653002500534058
Validation loss: 1.9747783727543329

Epoch: 6| Step: 13
Training loss: 1.7573598623275757
Validation loss: 1.9941361822107786

Epoch: 124| Step: 0
Training loss: 2.0696353912353516
Validation loss: 1.992730785441655

Epoch: 6| Step: 1
Training loss: 1.8217493295669556
Validation loss: 1.9890704821514826

Epoch: 6| Step: 2
Training loss: 1.626845359802246
Validation loss: 1.978728626364021

Epoch: 6| Step: 3
Training loss: 1.748254656791687
Validation loss: 1.9961120287577312

Epoch: 6| Step: 4
Training loss: 2.405026435852051
Validation loss: 1.9930092955148349

Epoch: 6| Step: 5
Training loss: 2.0396251678466797
Validation loss: 1.9699997132824314

Epoch: 6| Step: 6
Training loss: 2.0790131092071533
Validation loss: 1.9862833394799182

Epoch: 6| Step: 7
Training loss: 2.2990121841430664
Validation loss: 1.988617318932728

Epoch: 6| Step: 8
Training loss: 1.9186301231384277
Validation loss: 1.9850099048306864

Epoch: 6| Step: 9
Training loss: 2.9019174575805664
Validation loss: 1.9785849637882684

Epoch: 6| Step: 10
Training loss: 2.3388283252716064
Validation loss: 1.983177513204595

Epoch: 6| Step: 11
Training loss: 1.557320475578308
Validation loss: 1.9765840320176975

Epoch: 6| Step: 12
Training loss: 2.2621960639953613
Validation loss: 1.9774909339925295

Epoch: 6| Step: 13
Training loss: 2.5613977909088135
Validation loss: 1.9957748331049436

Epoch: 125| Step: 0
Training loss: 2.2945971488952637
Validation loss: 1.999190830415295

Epoch: 6| Step: 1
Training loss: 2.3143982887268066
Validation loss: 1.988403784331455

Epoch: 6| Step: 2
Training loss: 1.957354187965393
Validation loss: 1.9802672824551981

Epoch: 6| Step: 3
Training loss: 2.543370008468628
Validation loss: 1.993661360074115

Epoch: 6| Step: 4
Training loss: 2.5273842811584473
Validation loss: 2.031012346667628

Epoch: 6| Step: 5
Training loss: 1.5233614444732666
Validation loss: 1.9789590245933943

Epoch: 6| Step: 6
Training loss: 1.7609949111938477
Validation loss: 1.9909894376672723

Epoch: 6| Step: 7
Training loss: 2.4042811393737793
Validation loss: 1.9961968903900476

Epoch: 6| Step: 8
Training loss: 1.9140127897262573
Validation loss: 2.0024472821143364

Epoch: 6| Step: 9
Training loss: 1.4258029460906982
Validation loss: 2.0122398945593063

Epoch: 6| Step: 10
Training loss: 2.2641444206237793
Validation loss: 2.0117885989527546

Epoch: 6| Step: 11
Training loss: 2.4232687950134277
Validation loss: 1.9960231396459764

Epoch: 6| Step: 12
Training loss: 2.1553356647491455
Validation loss: 1.9628152706289803

Epoch: 6| Step: 13
Training loss: 1.800262451171875
Validation loss: 2.004087964693705

Epoch: 126| Step: 0
Training loss: 2.3563408851623535
Validation loss: 2.017206650908275

Epoch: 6| Step: 1
Training loss: 2.2693519592285156
Validation loss: 1.9876074252590057

Epoch: 6| Step: 2
Training loss: 2.2062172889709473
Validation loss: 2.0014331622790267

Epoch: 6| Step: 3
Training loss: 2.067373514175415
Validation loss: 2.0200914285516225

Epoch: 6| Step: 4
Training loss: 1.8480569124221802
Validation loss: 2.037401217286305

Epoch: 6| Step: 5
Training loss: 1.9579230546951294
Validation loss: 2.019695089709374

Epoch: 6| Step: 6
Training loss: 2.2400548458099365
Validation loss: 2.0354452620270433

Epoch: 6| Step: 7
Training loss: 1.9594180583953857
Validation loss: 1.976126504200761

Epoch: 6| Step: 8
Training loss: 1.3138294219970703
Validation loss: 1.9967766884834535

Epoch: 6| Step: 9
Training loss: 2.235347032546997
Validation loss: 2.013737129908736

Epoch: 6| Step: 10
Training loss: 1.9420440196990967
Validation loss: 2.0067993107662407

Epoch: 6| Step: 11
Training loss: 2.383575439453125
Validation loss: 1.979573308780629

Epoch: 6| Step: 12
Training loss: 2.3156285285949707
Validation loss: 1.9808377527421521

Epoch: 6| Step: 13
Training loss: 2.2217018604278564
Validation loss: 1.980282328462088

Epoch: 127| Step: 0
Training loss: 1.8563261032104492
Validation loss: 1.9831530842729794

Epoch: 6| Step: 1
Training loss: 2.067502021789551
Validation loss: 1.9726050387146652

Epoch: 6| Step: 2
Training loss: 2.138477325439453
Validation loss: 2.008200753119684

Epoch: 6| Step: 3
Training loss: 2.344078779220581
Validation loss: 1.9871086984552362

Epoch: 6| Step: 4
Training loss: 1.4615583419799805
Validation loss: 1.972611411925285

Epoch: 6| Step: 5
Training loss: 1.998354196548462
Validation loss: 1.9812578693512948

Epoch: 6| Step: 6
Training loss: 2.347799777984619
Validation loss: 1.9840035412901191

Epoch: 6| Step: 7
Training loss: 2.2479395866394043
Validation loss: 1.96932767539896

Epoch: 6| Step: 8
Training loss: 2.003479242324829
Validation loss: 1.9630743508697839

Epoch: 6| Step: 9
Training loss: 2.2084202766418457
Validation loss: 1.964909758619083

Epoch: 6| Step: 10
Training loss: 2.4547863006591797
Validation loss: 1.9794124518671343

Epoch: 6| Step: 11
Training loss: 2.251631498336792
Validation loss: 1.959096049749723

Epoch: 6| Step: 12
Training loss: 2.534250259399414
Validation loss: 1.9683227949245001

Epoch: 6| Step: 13
Training loss: 1.0797982215881348
Validation loss: 1.9679517592153242

Epoch: 128| Step: 0
Training loss: 1.11763596534729
Validation loss: 1.9599118053272206

Epoch: 6| Step: 1
Training loss: 2.9268863201141357
Validation loss: 1.9785177733308525

Epoch: 6| Step: 2
Training loss: 1.685259222984314
Validation loss: 1.9669221729360602

Epoch: 6| Step: 3
Training loss: 1.9127659797668457
Validation loss: 1.9834373445921047

Epoch: 6| Step: 4
Training loss: 2.2595272064208984
Validation loss: 1.9525193706635506

Epoch: 6| Step: 5
Training loss: 2.1250340938568115
Validation loss: 1.98052462198401

Epoch: 6| Step: 6
Training loss: 1.9450228214263916
Validation loss: 1.970930455833353

Epoch: 6| Step: 7
Training loss: 1.8559441566467285
Validation loss: 1.9887295487106487

Epoch: 6| Step: 8
Training loss: 2.631638765335083
Validation loss: 1.9997918977532336

Epoch: 6| Step: 9
Training loss: 2.506894588470459
Validation loss: 1.9976165179283387

Epoch: 6| Step: 10
Training loss: 1.8311786651611328
Validation loss: 1.9779678711327173

Epoch: 6| Step: 11
Training loss: 2.5041050910949707
Validation loss: 1.9730815733632734

Epoch: 6| Step: 12
Training loss: 2.072448253631592
Validation loss: 2.0098280906677246

Epoch: 6| Step: 13
Training loss: 1.501722812652588
Validation loss: 2.0194932068547895

Epoch: 129| Step: 0
Training loss: 2.8301968574523926
Validation loss: 2.001038700021723

Epoch: 6| Step: 1
Training loss: 1.8821420669555664
Validation loss: 1.9882565672679613

Epoch: 6| Step: 2
Training loss: 1.892423152923584
Validation loss: 2.0106430592075473

Epoch: 6| Step: 3
Training loss: 1.860007405281067
Validation loss: 2.0126502026793776

Epoch: 6| Step: 4
Training loss: 2.042573928833008
Validation loss: 2.0173747770247923

Epoch: 6| Step: 5
Training loss: 2.098574161529541
Validation loss: 2.01479943080615

Epoch: 6| Step: 6
Training loss: 1.5507755279541016
Validation loss: 2.029468576113383

Epoch: 6| Step: 7
Training loss: 2.157672882080078
Validation loss: 2.036549433585136

Epoch: 6| Step: 8
Training loss: 2.7940704822540283
Validation loss: 2.0368918808557654

Epoch: 6| Step: 9
Training loss: 1.8964236974716187
Validation loss: 2.055871617409491

Epoch: 6| Step: 10
Training loss: 2.4876041412353516
Validation loss: 2.0543109396452546

Epoch: 6| Step: 11
Training loss: 1.9811053276062012
Validation loss: 2.0461338540559173

Epoch: 6| Step: 12
Training loss: 2.002506732940674
Validation loss: 2.0463155085040676

Epoch: 6| Step: 13
Training loss: 1.958921194076538
Validation loss: 2.026572326178192

Epoch: 130| Step: 0
Training loss: 1.7550363540649414
Validation loss: 2.0294055502901793

Epoch: 6| Step: 1
Training loss: 2.4269118309020996
Validation loss: 2.0270620417851273

Epoch: 6| Step: 2
Training loss: 1.8842971324920654
Validation loss: 2.003749778193812

Epoch: 6| Step: 3
Training loss: 1.7274010181427002
Validation loss: 2.01263500285405

Epoch: 6| Step: 4
Training loss: 2.6026458740234375
Validation loss: 2.00147569564081

Epoch: 6| Step: 5
Training loss: 2.606940269470215
Validation loss: 2.0051039085593274

Epoch: 6| Step: 6
Training loss: 2.369248390197754
Validation loss: 2.021703758547383

Epoch: 6| Step: 7
Training loss: 2.057650089263916
Validation loss: 1.989929731174182

Epoch: 6| Step: 8
Training loss: 1.9787832498550415
Validation loss: 1.9762422577027352

Epoch: 6| Step: 9
Training loss: 1.5489468574523926
Validation loss: 1.9721099612533406

Epoch: 6| Step: 10
Training loss: 2.367788076400757
Validation loss: 1.9811196634846349

Epoch: 6| Step: 11
Training loss: 1.893698811531067
Validation loss: 1.9778099624059533

Epoch: 6| Step: 12
Training loss: 2.277817726135254
Validation loss: 1.9838765667330833

Epoch: 6| Step: 13
Training loss: 1.5227508544921875
Validation loss: 1.9829492671515352

Epoch: 131| Step: 0
Training loss: 2.0626657009124756
Validation loss: 1.9793409378297868

Epoch: 6| Step: 1
Training loss: 2.6706089973449707
Validation loss: 1.9651106403719993

Epoch: 6| Step: 2
Training loss: 2.1841700077056885
Validation loss: 1.972284896399385

Epoch: 6| Step: 3
Training loss: 1.7876662015914917
Validation loss: 1.9651804021609727

Epoch: 6| Step: 4
Training loss: 1.7555073499679565
Validation loss: 1.9649646897469797

Epoch: 6| Step: 5
Training loss: 1.9860121011734009
Validation loss: 1.9561134922888972

Epoch: 6| Step: 6
Training loss: 1.919026255607605
Validation loss: 1.9786841202807683

Epoch: 6| Step: 7
Training loss: 2.038787841796875
Validation loss: 1.9753974535131966

Epoch: 6| Step: 8
Training loss: 3.098289966583252
Validation loss: 1.9702376947608045

Epoch: 6| Step: 9
Training loss: 2.479412078857422
Validation loss: 1.9758727396688154

Epoch: 6| Step: 10
Training loss: 1.5211857557296753
Validation loss: 1.9753801130479383

Epoch: 6| Step: 11
Training loss: 1.9145609140396118
Validation loss: 1.9624037409341464

Epoch: 6| Step: 12
Training loss: 1.845202922821045
Validation loss: 1.9852349194147254

Epoch: 6| Step: 13
Training loss: 1.8781049251556396
Validation loss: 1.9807641608740694

Epoch: 132| Step: 0
Training loss: 1.8146926164627075
Validation loss: 1.9940004720482776

Epoch: 6| Step: 1
Training loss: 2.2678608894348145
Validation loss: 2.000687640200379

Epoch: 6| Step: 2
Training loss: 2.5406928062438965
Validation loss: 1.9835394326076712

Epoch: 6| Step: 3
Training loss: 1.8242051601409912
Validation loss: 1.9896344664276286

Epoch: 6| Step: 4
Training loss: 1.5265955924987793
Validation loss: 1.9896747360947311

Epoch: 6| Step: 5
Training loss: 1.7991065979003906
Validation loss: 1.9845563314294303

Epoch: 6| Step: 6
Training loss: 1.6355464458465576
Validation loss: 2.0174799708909887

Epoch: 6| Step: 7
Training loss: 2.1778483390808105
Validation loss: 1.991987205320789

Epoch: 6| Step: 8
Training loss: 2.377127170562744
Validation loss: 2.0089725371330016

Epoch: 6| Step: 9
Training loss: 2.384639263153076
Validation loss: 1.9998321892112814

Epoch: 6| Step: 10
Training loss: 1.8760144710540771
Validation loss: 2.0040691962806125

Epoch: 6| Step: 11
Training loss: 2.8513503074645996
Validation loss: 2.020697752634684

Epoch: 6| Step: 12
Training loss: 1.827803373336792
Validation loss: 2.0004250695628505

Epoch: 6| Step: 13
Training loss: 2.387629985809326
Validation loss: 1.9971896909898328

Epoch: 133| Step: 0
Training loss: 1.3737598657608032
Validation loss: 1.9894086442967898

Epoch: 6| Step: 1
Training loss: 1.68415105342865
Validation loss: 1.980711926696121

Epoch: 6| Step: 2
Training loss: 1.8527942895889282
Validation loss: 2.012034728962888

Epoch: 6| Step: 3
Training loss: 2.831089973449707
Validation loss: 2.0069694467770156

Epoch: 6| Step: 4
Training loss: 1.90476393699646
Validation loss: 1.9942617852200744

Epoch: 6| Step: 5
Training loss: 2.2874722480773926
Validation loss: 1.9842317719613352

Epoch: 6| Step: 6
Training loss: 2.3076119422912598
Validation loss: 2.0018863677978516

Epoch: 6| Step: 7
Training loss: 1.8986536264419556
Validation loss: 1.9745380878448486

Epoch: 6| Step: 8
Training loss: 2.279447078704834
Validation loss: 1.9613695926563715

Epoch: 6| Step: 9
Training loss: 2.6376476287841797
Validation loss: 1.9741405325551187

Epoch: 6| Step: 10
Training loss: 1.8497014045715332
Validation loss: 1.9857298199848463

Epoch: 6| Step: 11
Training loss: 1.996302604675293
Validation loss: 2.0074704026663177

Epoch: 6| Step: 12
Training loss: 1.9990911483764648
Validation loss: 1.9819751003737092

Epoch: 6| Step: 13
Training loss: 2.4016597270965576
Validation loss: 1.962208935009536

Epoch: 134| Step: 0
Training loss: 2.0946125984191895
Validation loss: 1.9839293982392998

Epoch: 6| Step: 1
Training loss: 2.5144729614257812
Validation loss: 1.9922634863084363

Epoch: 6| Step: 2
Training loss: 2.209885597229004
Validation loss: 1.9769823833178448

Epoch: 6| Step: 3
Training loss: 1.2849817276000977
Validation loss: 1.9978001656070832

Epoch: 6| Step: 4
Training loss: 1.685544729232788
Validation loss: 1.9973763855554725

Epoch: 6| Step: 5
Training loss: 2.051657199859619
Validation loss: 1.9863618804562477

Epoch: 6| Step: 6
Training loss: 2.374448776245117
Validation loss: 1.961908632709134

Epoch: 6| Step: 7
Training loss: 2.2706685066223145
Validation loss: 1.9792927785586285

Epoch: 6| Step: 8
Training loss: 2.419914960861206
Validation loss: 1.9696354917300645

Epoch: 6| Step: 9
Training loss: 2.538733959197998
Validation loss: 1.9749509942147039

Epoch: 6| Step: 10
Training loss: 1.7281270027160645
Validation loss: 2.000020983398602

Epoch: 6| Step: 11
Training loss: 2.0597333908081055
Validation loss: 2.0069734691291727

Epoch: 6| Step: 12
Training loss: 1.9252543449401855
Validation loss: 2.001334959460843

Epoch: 6| Step: 13
Training loss: 1.8962582349777222
Validation loss: 2.010757976962674

Epoch: 135| Step: 0
Training loss: 1.9197192192077637
Validation loss: 2.0204133615698865

Epoch: 6| Step: 1
Training loss: 2.387223243713379
Validation loss: 2.017922709065099

Epoch: 6| Step: 2
Training loss: 2.5251173973083496
Validation loss: 2.0002455634455525

Epoch: 6| Step: 3
Training loss: 2.040526866912842
Validation loss: 2.0007539077471663

Epoch: 6| Step: 4
Training loss: 2.534201145172119
Validation loss: 2.010123896342452

Epoch: 6| Step: 5
Training loss: 2.2107715606689453
Validation loss: 2.0100564982301448

Epoch: 6| Step: 6
Training loss: 1.9885220527648926
Validation loss: 2.0137199791528846

Epoch: 6| Step: 7
Training loss: 1.7921037673950195
Validation loss: 1.9997173714381393

Epoch: 6| Step: 8
Training loss: 1.463888168334961
Validation loss: 2.00002654393514

Epoch: 6| Step: 9
Training loss: 1.8774983882904053
Validation loss: 1.997290357466667

Epoch: 6| Step: 10
Training loss: 2.5455286502838135
Validation loss: 1.9931291290508804

Epoch: 6| Step: 11
Training loss: 1.525404453277588
Validation loss: 2.020017954611009

Epoch: 6| Step: 12
Training loss: 2.016164779663086
Validation loss: 1.9838206716763076

Epoch: 6| Step: 13
Training loss: 2.2189180850982666
Validation loss: 2.0183456251698155

Epoch: 136| Step: 0
Training loss: 1.7671654224395752
Validation loss: 1.9963069564552718

Epoch: 6| Step: 1
Training loss: 1.7464618682861328
Validation loss: 1.9938740102193688

Epoch: 6| Step: 2
Training loss: 2.5476386547088623
Validation loss: 1.9953637289744552

Epoch: 6| Step: 3
Training loss: 1.4985488653182983
Validation loss: 2.0187869700052405

Epoch: 6| Step: 4
Training loss: 2.4424631595611572
Validation loss: 1.9660904228046376

Epoch: 6| Step: 5
Training loss: 1.9207888841629028
Validation loss: 1.9920412763472526

Epoch: 6| Step: 6
Training loss: 2.382540702819824
Validation loss: 1.9808397882728166

Epoch: 6| Step: 7
Training loss: 2.250502824783325
Validation loss: 1.9977193211996427

Epoch: 6| Step: 8
Training loss: 2.291250705718994
Validation loss: 1.9827216030448995

Epoch: 6| Step: 9
Training loss: 1.816451072692871
Validation loss: 1.9544427574321788

Epoch: 6| Step: 10
Training loss: 2.175302505493164
Validation loss: 1.994817715819164

Epoch: 6| Step: 11
Training loss: 1.1264855861663818
Validation loss: 1.9671046631310576

Epoch: 6| Step: 12
Training loss: 2.7239370346069336
Validation loss: 1.9590164525534517

Epoch: 6| Step: 13
Training loss: 2.7527341842651367
Validation loss: 1.9705348117377168

Epoch: 137| Step: 0
Training loss: 1.8538025617599487
Validation loss: 1.9799801675222253

Epoch: 6| Step: 1
Training loss: 1.7434219121932983
Validation loss: 2.0009232746657504

Epoch: 6| Step: 2
Training loss: 1.7411057949066162
Validation loss: 1.9908103109687887

Epoch: 6| Step: 3
Training loss: 1.9948973655700684
Validation loss: 1.9879359455518826

Epoch: 6| Step: 4
Training loss: 2.078256607055664
Validation loss: 1.9992085541448286

Epoch: 6| Step: 5
Training loss: 2.47521710395813
Validation loss: 1.982811383021775

Epoch: 6| Step: 6
Training loss: 2.5501608848571777
Validation loss: 1.959258210274481

Epoch: 6| Step: 7
Training loss: 1.6635912656784058
Validation loss: 2.0101554701405187

Epoch: 6| Step: 8
Training loss: 1.6334426403045654
Validation loss: 1.9688695630719584

Epoch: 6| Step: 9
Training loss: 1.755460262298584
Validation loss: 1.970648536118128

Epoch: 6| Step: 10
Training loss: 1.703109860420227
Validation loss: 1.9710764013310915

Epoch: 6| Step: 11
Training loss: 2.644385814666748
Validation loss: 1.9951295980843164

Epoch: 6| Step: 12
Training loss: 2.974762439727783
Validation loss: 1.9891528698705858

Epoch: 6| Step: 13
Training loss: 2.447598457336426
Validation loss: 1.988390395718236

Epoch: 138| Step: 0
Training loss: 2.8306710720062256
Validation loss: 1.9867514128326087

Epoch: 6| Step: 1
Training loss: 2.4480745792388916
Validation loss: 2.0043679078420005

Epoch: 6| Step: 2
Training loss: 1.8731696605682373
Validation loss: 1.995338596323485

Epoch: 6| Step: 3
Training loss: 1.9852066040039062
Validation loss: 1.9780192375183105

Epoch: 6| Step: 4
Training loss: 2.296844959259033
Validation loss: 1.972693536871223

Epoch: 6| Step: 5
Training loss: 1.1921238899230957
Validation loss: 1.9742238829212804

Epoch: 6| Step: 6
Training loss: 2.0540642738342285
Validation loss: 1.9681147016504759

Epoch: 6| Step: 7
Training loss: 1.8123064041137695
Validation loss: 1.9981637872675413

Epoch: 6| Step: 8
Training loss: 1.6688216924667358
Validation loss: 1.9824014902114868

Epoch: 6| Step: 9
Training loss: 2.109707832336426
Validation loss: 1.9912942712024977

Epoch: 6| Step: 10
Training loss: 2.142932891845703
Validation loss: 1.9983697296470724

Epoch: 6| Step: 11
Training loss: 2.03920578956604
Validation loss: 1.9946840616964525

Epoch: 6| Step: 12
Training loss: 2.404918670654297
Validation loss: 2.0076519955870924

Epoch: 6| Step: 13
Training loss: 2.300992488861084
Validation loss: 1.9791525512613275

Epoch: 139| Step: 0
Training loss: 1.5362566709518433
Validation loss: 1.994558411259805

Epoch: 6| Step: 1
Training loss: 2.8865647315979004
Validation loss: 2.0015061901461695

Epoch: 6| Step: 2
Training loss: 1.6923096179962158
Validation loss: 2.0078891938732517

Epoch: 6| Step: 3
Training loss: 1.3603179454803467
Validation loss: 1.9884307487036592

Epoch: 6| Step: 4
Training loss: 1.9974119663238525
Validation loss: 2.0101545856844996

Epoch: 6| Step: 5
Training loss: 2.031803607940674
Validation loss: 2.032718214937436

Epoch: 6| Step: 6
Training loss: 1.6585147380828857
Validation loss: 2.0204725650049027

Epoch: 6| Step: 7
Training loss: 1.9993023872375488
Validation loss: 2.00229751166477

Epoch: 6| Step: 8
Training loss: 2.321413278579712
Validation loss: 2.001802449585289

Epoch: 6| Step: 9
Training loss: 2.5050768852233887
Validation loss: 1.9910726918969104

Epoch: 6| Step: 10
Training loss: 1.8634740114212036
Validation loss: 1.9794980108097036

Epoch: 6| Step: 11
Training loss: 2.6606264114379883
Validation loss: 1.9933732376303723

Epoch: 6| Step: 12
Training loss: 2.2782018184661865
Validation loss: 2.0231482777544247

Epoch: 6| Step: 13
Training loss: 2.2159945964813232
Validation loss: 2.0188344140206613

Epoch: 140| Step: 0
Training loss: 2.5217456817626953
Validation loss: 1.9986795251087477

Epoch: 6| Step: 1
Training loss: 2.2121143341064453
Validation loss: 1.9785333705204788

Epoch: 6| Step: 2
Training loss: 1.97071373462677
Validation loss: 2.0238061053778535

Epoch: 6| Step: 3
Training loss: 2.2869889736175537
Validation loss: 2.0075138768842145

Epoch: 6| Step: 4
Training loss: 2.103823661804199
Validation loss: 2.0021107940263647

Epoch: 6| Step: 5
Training loss: 1.7163902521133423
Validation loss: 2.0201065386495283

Epoch: 6| Step: 6
Training loss: 1.8877664804458618
Validation loss: 1.9945872342714699

Epoch: 6| Step: 7
Training loss: 1.9355518817901611
Validation loss: 2.0047571710360947

Epoch: 6| Step: 8
Training loss: 1.9941784143447876
Validation loss: 1.9926830889076315

Epoch: 6| Step: 9
Training loss: 1.8509777784347534
Validation loss: 2.014685200106713

Epoch: 6| Step: 10
Training loss: 2.0493838787078857
Validation loss: 1.9980075154253232

Epoch: 6| Step: 11
Training loss: 2.328969955444336
Validation loss: 1.9939128480931765

Epoch: 6| Step: 12
Training loss: 2.0629842281341553
Validation loss: 2.0080553126591507

Epoch: 6| Step: 13
Training loss: 2.0408923625946045
Validation loss: 1.994576036289174

Epoch: 141| Step: 0
Training loss: 2.2531135082244873
Validation loss: 1.9864097731087798

Epoch: 6| Step: 1
Training loss: 2.051609992980957
Validation loss: 1.9920029037742204

Epoch: 6| Step: 2
Training loss: 2.1351876258850098
Validation loss: 1.988528246520668

Epoch: 6| Step: 3
Training loss: 2.6292495727539062
Validation loss: 1.9882872719918527

Epoch: 6| Step: 4
Training loss: 1.9076420068740845
Validation loss: 2.001716535578492

Epoch: 6| Step: 5
Training loss: 1.8807471990585327
Validation loss: 2.0036735996123283

Epoch: 6| Step: 6
Training loss: 2.2697596549987793
Validation loss: 1.9962612467427407

Epoch: 6| Step: 7
Training loss: 1.9911516904830933
Validation loss: 1.964878382221345

Epoch: 6| Step: 8
Training loss: 1.9449353218078613
Validation loss: 2.006859771666988

Epoch: 6| Step: 9
Training loss: 2.1246204376220703
Validation loss: 1.973212570272466

Epoch: 6| Step: 10
Training loss: 1.9530715942382812
Validation loss: 1.990572166699235

Epoch: 6| Step: 11
Training loss: 1.3773859739303589
Validation loss: 2.003584905337262

Epoch: 6| Step: 12
Training loss: 2.105848550796509
Validation loss: 2.005786303550966

Epoch: 6| Step: 13
Training loss: 2.0589756965637207
Validation loss: 2.0050602728320706

Epoch: 142| Step: 0
Training loss: 1.7842620611190796
Validation loss: 1.9782670646585443

Epoch: 6| Step: 1
Training loss: 2.0293781757354736
Validation loss: 1.9932605630608016

Epoch: 6| Step: 2
Training loss: 1.6458947658538818
Validation loss: 1.9646248599534393

Epoch: 6| Step: 3
Training loss: 2.1061620712280273
Validation loss: 1.9836648112984114

Epoch: 6| Step: 4
Training loss: 1.6338821649551392
Validation loss: 1.9783734172903082

Epoch: 6| Step: 5
Training loss: 1.6988391876220703
Validation loss: 1.9873957518608338

Epoch: 6| Step: 6
Training loss: 2.0100884437561035
Validation loss: 1.9801517186626312

Epoch: 6| Step: 7
Training loss: 2.8208765983581543
Validation loss: 1.9870269247280654

Epoch: 6| Step: 8
Training loss: 2.508899688720703
Validation loss: 2.007873142919233

Epoch: 6| Step: 9
Training loss: 2.464430570602417
Validation loss: 1.9767475845993205

Epoch: 6| Step: 10
Training loss: 1.4990770816802979
Validation loss: 1.9734279032676452

Epoch: 6| Step: 11
Training loss: 1.974951148033142
Validation loss: 1.9722418618458573

Epoch: 6| Step: 12
Training loss: 2.3948707580566406
Validation loss: 1.9908616568452568

Epoch: 6| Step: 13
Training loss: 2.692657947540283
Validation loss: 1.9866172754636375

Epoch: 143| Step: 0
Training loss: 2.1396875381469727
Validation loss: 1.9781075421200003

Epoch: 6| Step: 1
Training loss: 1.8120591640472412
Validation loss: 2.007199336123723

Epoch: 6| Step: 2
Training loss: 1.572365641593933
Validation loss: 1.9733293043669833

Epoch: 6| Step: 3
Training loss: 1.8767478466033936
Validation loss: 1.9976642593260734

Epoch: 6| Step: 4
Training loss: 1.9641278982162476
Validation loss: 2.0108978145865986

Epoch: 6| Step: 5
Training loss: 2.3596444129943848
Validation loss: 1.9971765190042474

Epoch: 6| Step: 6
Training loss: 2.2425317764282227
Validation loss: 2.019561436868483

Epoch: 6| Step: 7
Training loss: 2.124584674835205
Validation loss: 2.0058092019891225

Epoch: 6| Step: 8
Training loss: 1.9346985816955566
Validation loss: 2.0190831281805552

Epoch: 6| Step: 9
Training loss: 2.445706367492676
Validation loss: 2.020159257355557

Epoch: 6| Step: 10
Training loss: 2.301079273223877
Validation loss: 1.996251630526717

Epoch: 6| Step: 11
Training loss: 1.9748793840408325
Validation loss: 2.007526771996611

Epoch: 6| Step: 12
Training loss: 1.7597922086715698
Validation loss: 2.018948240946698

Epoch: 6| Step: 13
Training loss: 2.492136240005493
Validation loss: 1.9973610485753706

Epoch: 144| Step: 0
Training loss: 2.1770505905151367
Validation loss: 1.974473230300411

Epoch: 6| Step: 1
Training loss: 1.976356029510498
Validation loss: 1.9903860040890273

Epoch: 6| Step: 2
Training loss: 1.3584907054901123
Validation loss: 2.010304715043755

Epoch: 6| Step: 3
Training loss: 2.0254623889923096
Validation loss: 2.005699537133658

Epoch: 6| Step: 4
Training loss: 1.0570417642593384
Validation loss: 2.0211789954093193

Epoch: 6| Step: 5
Training loss: 2.072948932647705
Validation loss: 1.9922557825683265

Epoch: 6| Step: 6
Training loss: 1.8868852853775024
Validation loss: 2.015255774221113

Epoch: 6| Step: 7
Training loss: 2.4184885025024414
Validation loss: 2.016480912444412

Epoch: 6| Step: 8
Training loss: 2.4199814796447754
Validation loss: 2.0326952088263726

Epoch: 6| Step: 9
Training loss: 2.6347787380218506
Validation loss: 1.996938193998029

Epoch: 6| Step: 10
Training loss: 1.5559496879577637
Validation loss: 1.993821115903957

Epoch: 6| Step: 11
Training loss: 2.1657845973968506
Validation loss: 2.008830275586856

Epoch: 6| Step: 12
Training loss: 2.534383535385132
Validation loss: 2.0056876674775155

Epoch: 6| Step: 13
Training loss: 2.946249008178711
Validation loss: 1.99818621143218

Epoch: 145| Step: 0
Training loss: 1.935220718383789
Validation loss: 2.0102516810099282

Epoch: 6| Step: 1
Training loss: 2.787069320678711
Validation loss: 2.0027066507647113

Epoch: 6| Step: 2
Training loss: 2.2283477783203125
Validation loss: 1.9686272913409817

Epoch: 6| Step: 3
Training loss: 1.840064525604248
Validation loss: 1.9838156366860995

Epoch: 6| Step: 4
Training loss: 2.028562545776367
Validation loss: 1.9944129041446153

Epoch: 6| Step: 5
Training loss: 2.012277603149414
Validation loss: 1.9840356073071879

Epoch: 6| Step: 6
Training loss: 1.6697826385498047
Validation loss: 1.9837079560884865

Epoch: 6| Step: 7
Training loss: 2.1729812622070312
Validation loss: 1.9828200263361777

Epoch: 6| Step: 8
Training loss: 1.6081645488739014
Validation loss: 2.003594817653779

Epoch: 6| Step: 9
Training loss: 2.3381245136260986
Validation loss: 2.0115693025691535

Epoch: 6| Step: 10
Training loss: 2.1081666946411133
Validation loss: 1.9853883866340882

Epoch: 6| Step: 11
Training loss: 1.6190876960754395
Validation loss: 2.0076886274481334

Epoch: 6| Step: 12
Training loss: 2.284670829772949
Validation loss: 2.0111061398701002

Epoch: 6| Step: 13
Training loss: 2.555593729019165
Validation loss: 2.0167439022371845

Epoch: 146| Step: 0
Training loss: 1.622619867324829
Validation loss: 2.0105447192345896

Epoch: 6| Step: 1
Training loss: 2.158165216445923
Validation loss: 2.0096526453571935

Epoch: 6| Step: 2
Training loss: 1.7072646617889404
Validation loss: 1.9846718875310754

Epoch: 6| Step: 3
Training loss: 2.627016544342041
Validation loss: 1.9710721277421521

Epoch: 6| Step: 4
Training loss: 2.9665846824645996
Validation loss: 1.95915896918184

Epoch: 6| Step: 5
Training loss: 1.9576210975646973
Validation loss: 1.9861890680046492

Epoch: 6| Step: 6
Training loss: 1.70417320728302
Validation loss: 1.9784937033089258

Epoch: 6| Step: 7
Training loss: 3.3526577949523926
Validation loss: 1.9932453965628019

Epoch: 6| Step: 8
Training loss: 1.9565460681915283
Validation loss: 1.9887059119439894

Epoch: 6| Step: 9
Training loss: 2.040375232696533
Validation loss: 1.9770898665151289

Epoch: 6| Step: 10
Training loss: 1.7864766120910645
Validation loss: 1.9726496947708951

Epoch: 6| Step: 11
Training loss: 1.9861987829208374
Validation loss: 2.000006548820003

Epoch: 6| Step: 12
Training loss: 1.3255949020385742
Validation loss: 1.992477814356486

Epoch: 6| Step: 13
Training loss: 1.5374265909194946
Validation loss: 1.9758519139341129

Epoch: 147| Step: 0
Training loss: 1.4458847045898438
Validation loss: 1.974160361033614

Epoch: 6| Step: 1
Training loss: 1.634994626045227
Validation loss: 2.00466695011303

Epoch: 6| Step: 2
Training loss: 2.4833903312683105
Validation loss: 2.008021439275434

Epoch: 6| Step: 3
Training loss: 2.0125231742858887
Validation loss: 2.0139936298452397

Epoch: 6| Step: 4
Training loss: 1.6066168546676636
Validation loss: 2.021565150189143

Epoch: 6| Step: 5
Training loss: 2.3138294219970703
Validation loss: 2.036740843967725

Epoch: 6| Step: 6
Training loss: 2.873368263244629
Validation loss: 2.0578952194542013

Epoch: 6| Step: 7
Training loss: 1.2201683521270752
Validation loss: 2.0474521703617548

Epoch: 6| Step: 8
Training loss: 1.9486676454544067
Validation loss: 2.04171129708649

Epoch: 6| Step: 9
Training loss: 2.7113242149353027
Validation loss: 2.0529898725530153

Epoch: 6| Step: 10
Training loss: 1.7740521430969238
Validation loss: 2.0387162726412535

Epoch: 6| Step: 11
Training loss: 2.1645827293395996
Validation loss: 2.054116533648583

Epoch: 6| Step: 12
Training loss: 2.928431510925293
Validation loss: 2.0384234920624764

Epoch: 6| Step: 13
Training loss: 2.0363664627075195
Validation loss: 2.0279852139052523

Epoch: 148| Step: 0
Training loss: 1.7307525873184204
Validation loss: 2.0526023308436074

Epoch: 6| Step: 1
Training loss: 2.131819486618042
Validation loss: 2.012798365726266

Epoch: 6| Step: 2
Training loss: 2.538752794265747
Validation loss: 2.0163921002418763

Epoch: 6| Step: 3
Training loss: 1.7862567901611328
Validation loss: 2.026198269218527

Epoch: 6| Step: 4
Training loss: 2.665109157562256
Validation loss: 2.028928397804178

Epoch: 6| Step: 5
Training loss: 2.066425323486328
Validation loss: 1.998370316720778

Epoch: 6| Step: 6
Training loss: 1.5328278541564941
Validation loss: 2.024916669373871

Epoch: 6| Step: 7
Training loss: 2.2277727127075195
Validation loss: 1.9967597940916657

Epoch: 6| Step: 8
Training loss: 2.42812442779541
Validation loss: 1.976843213522306

Epoch: 6| Step: 9
Training loss: 1.6449425220489502
Validation loss: 1.9861199240530691

Epoch: 6| Step: 10
Training loss: 1.4669018983840942
Validation loss: 1.9942226384275703

Epoch: 6| Step: 11
Training loss: 2.494874954223633
Validation loss: 1.9979515844775784

Epoch: 6| Step: 12
Training loss: 2.114983558654785
Validation loss: 1.9852483605825773

Epoch: 6| Step: 13
Training loss: 1.3326513767242432
Validation loss: 1.9696982957983529

Epoch: 149| Step: 0
Training loss: 1.6859674453735352
Validation loss: 1.9578052900170768

Epoch: 6| Step: 1
Training loss: 2.035682439804077
Validation loss: 1.9857975526522564

Epoch: 6| Step: 2
Training loss: 1.7192621231079102
Validation loss: 1.9732725210087274

Epoch: 6| Step: 3
Training loss: 2.701497793197632
Validation loss: 1.9901819344489806

Epoch: 6| Step: 4
Training loss: 1.6435401439666748
Validation loss: 1.9796070539823143

Epoch: 6| Step: 5
Training loss: 2.378044843673706
Validation loss: 1.9905752020497476

Epoch: 6| Step: 6
Training loss: 1.9761178493499756
Validation loss: 1.9839077713668987

Epoch: 6| Step: 7
Training loss: 1.5728737115859985
Validation loss: 1.9900477406799153

Epoch: 6| Step: 8
Training loss: 1.9277727603912354
Validation loss: 2.0196289003536267

Epoch: 6| Step: 9
Training loss: 2.7558493614196777
Validation loss: 1.9996574104473155

Epoch: 6| Step: 10
Training loss: 3.134158134460449
Validation loss: 1.990069591870872

Epoch: 6| Step: 11
Training loss: 1.746655821800232
Validation loss: 2.009357738238509

Epoch: 6| Step: 12
Training loss: 1.8826072216033936
Validation loss: 1.990683614566762

Epoch: 6| Step: 13
Training loss: 1.4739187955856323
Validation loss: 2.0083716043861966

Epoch: 150| Step: 0
Training loss: 2.382695436477661
Validation loss: 2.0107246624526156

Epoch: 6| Step: 1
Training loss: 1.5521771907806396
Validation loss: 1.9850424233303274

Epoch: 6| Step: 2
Training loss: 1.8751246929168701
Validation loss: 1.9923457612273514

Epoch: 6| Step: 3
Training loss: 1.3929599523544312
Validation loss: 1.9988388502469627

Epoch: 6| Step: 4
Training loss: 1.748514175415039
Validation loss: 1.9970682359510852

Epoch: 6| Step: 5
Training loss: 1.6801815032958984
Validation loss: 2.0039335425182054

Epoch: 6| Step: 6
Training loss: 2.0377302169799805
Validation loss: 2.000643584036058

Epoch: 6| Step: 7
Training loss: 2.778981924057007
Validation loss: 2.0060199678585096

Epoch: 6| Step: 8
Training loss: 2.1965060234069824
Validation loss: 2.0096821759336736

Epoch: 6| Step: 9
Training loss: 2.44984769821167
Validation loss: 2.005089929026942

Epoch: 6| Step: 10
Training loss: 2.2697105407714844
Validation loss: 1.9937587271454513

Epoch: 6| Step: 11
Training loss: 2.3895485401153564
Validation loss: 2.0050968649566814

Epoch: 6| Step: 12
Training loss: 1.897072434425354
Validation loss: 2.0074301586356214

Epoch: 6| Step: 13
Training loss: 1.8602886199951172
Validation loss: 1.9979643872989121

Epoch: 151| Step: 0
Training loss: 1.8714470863342285
Validation loss: 2.0035642218846146

Epoch: 6| Step: 1
Training loss: 1.892733097076416
Validation loss: 1.9961397929858136

Epoch: 6| Step: 2
Training loss: 2.2191500663757324
Validation loss: 1.999027890543784

Epoch: 6| Step: 3
Training loss: 1.7716684341430664
Validation loss: 1.9976981634734778

Epoch: 6| Step: 4
Training loss: 2.0087108612060547
Validation loss: 1.9845768867000457

Epoch: 6| Step: 5
Training loss: 2.0150787830352783
Validation loss: 1.9787348572925856

Epoch: 6| Step: 6
Training loss: 2.2075674533843994
Validation loss: 2.003533592788122

Epoch: 6| Step: 7
Training loss: 2.202180862426758
Validation loss: 1.9997570360860517

Epoch: 6| Step: 8
Training loss: 2.177356004714966
Validation loss: 1.968986290757374

Epoch: 6| Step: 9
Training loss: 2.293635129928589
Validation loss: 1.9781919756243307

Epoch: 6| Step: 10
Training loss: 2.1550424098968506
Validation loss: 1.9902945116002073

Epoch: 6| Step: 11
Training loss: 2.4612271785736084
Validation loss: 1.9871444881603282

Epoch: 6| Step: 12
Training loss: 1.248152494430542
Validation loss: 2.005847574562155

Epoch: 6| Step: 13
Training loss: 2.3770058155059814
Validation loss: 2.00164996552211

Epoch: 152| Step: 0
Training loss: 2.8383874893188477
Validation loss: 2.006801087369201

Epoch: 6| Step: 1
Training loss: 2.435634136199951
Validation loss: 1.9994177459388651

Epoch: 6| Step: 2
Training loss: 2.0474560260772705
Validation loss: 1.9833819148361043

Epoch: 6| Step: 3
Training loss: 2.3572938442230225
Validation loss: 1.9948324195800289

Epoch: 6| Step: 4
Training loss: 2.1153109073638916
Validation loss: 2.0005338166349675

Epoch: 6| Step: 5
Training loss: 2.611746311187744
Validation loss: 1.9831529509636663

Epoch: 6| Step: 6
Training loss: 1.4243847131729126
Validation loss: 2.0082327627366587

Epoch: 6| Step: 7
Training loss: 1.7708748579025269
Validation loss: 2.005925314400786

Epoch: 6| Step: 8
Training loss: 1.6372675895690918
Validation loss: 1.988404462414403

Epoch: 6| Step: 9
Training loss: 1.822579026222229
Validation loss: 2.021694565332064

Epoch: 6| Step: 10
Training loss: 1.8366304636001587
Validation loss: 1.976628964947116

Epoch: 6| Step: 11
Training loss: 2.0313940048217773
Validation loss: 2.00275916822495

Epoch: 6| Step: 12
Training loss: 1.5896127223968506
Validation loss: 1.9931423600002

Epoch: 6| Step: 13
Training loss: 2.0817558765411377
Validation loss: 2.0029283479977678

Epoch: 153| Step: 0
Training loss: 2.073568344116211
Validation loss: 1.988276353446386

Epoch: 6| Step: 1
Training loss: 2.160412311553955
Validation loss: 2.0023563305536904

Epoch: 6| Step: 2
Training loss: 1.6341192722320557
Validation loss: 2.000215845723306

Epoch: 6| Step: 3
Training loss: 1.2992315292358398
Validation loss: 2.0132180618983444

Epoch: 6| Step: 4
Training loss: 1.993410348892212
Validation loss: 2.011568206612782

Epoch: 6| Step: 5
Training loss: 2.0573832988739014
Validation loss: 2.0266938145442674

Epoch: 6| Step: 6
Training loss: 2.996702194213867
Validation loss: 2.0148407669477564

Epoch: 6| Step: 7
Training loss: 2.0298988819122314
Validation loss: 2.007826566696167

Epoch: 6| Step: 8
Training loss: 1.6027710437774658
Validation loss: 2.002356360035558

Epoch: 6| Step: 9
Training loss: 2.102811813354492
Validation loss: 2.0160802513040523

Epoch: 6| Step: 10
Training loss: 1.5141633749008179
Validation loss: 2.0295457250328472

Epoch: 6| Step: 11
Training loss: 1.8423845767974854
Validation loss: 2.037494064659201

Epoch: 6| Step: 12
Training loss: 2.5840229988098145
Validation loss: 2.039528000739313

Epoch: 6| Step: 13
Training loss: 2.757364511489868
Validation loss: 1.9924391059465305

Epoch: 154| Step: 0
Training loss: 2.128054618835449
Validation loss: 2.030268612728324

Epoch: 6| Step: 1
Training loss: 1.7929351329803467
Validation loss: 2.005526501645324

Epoch: 6| Step: 2
Training loss: 1.983964443206787
Validation loss: 2.0145888072188183

Epoch: 6| Step: 3
Training loss: 1.8266454935073853
Validation loss: 2.0164966339706094

Epoch: 6| Step: 4
Training loss: 2.17844557762146
Validation loss: 1.9990405562103435

Epoch: 6| Step: 5
Training loss: 1.986569881439209
Validation loss: 1.9969439147621073

Epoch: 6| Step: 6
Training loss: 1.8454464673995972
Validation loss: 1.9971429891483758

Epoch: 6| Step: 7
Training loss: 2.5116188526153564
Validation loss: 2.0089116199042207

Epoch: 6| Step: 8
Training loss: 2.528080940246582
Validation loss: 1.9987011622357111

Epoch: 6| Step: 9
Training loss: 1.6264619827270508
Validation loss: 1.9919530345547585

Epoch: 6| Step: 10
Training loss: 1.9461164474487305
Validation loss: 2.0006178617477417

Epoch: 6| Step: 11
Training loss: 1.6502370834350586
Validation loss: 1.9738430823049238

Epoch: 6| Step: 12
Training loss: 2.407306671142578
Validation loss: 1.995348003602797

Epoch: 6| Step: 13
Training loss: 2.1028099060058594
Validation loss: 2.026021768969874

Epoch: 155| Step: 0
Training loss: 1.680513620376587
Validation loss: 1.9846559583499868

Epoch: 6| Step: 1
Training loss: 1.6499894857406616
Validation loss: 1.9599390145271056

Epoch: 6| Step: 2
Training loss: 1.7541768550872803
Validation loss: 2.0079574610597346

Epoch: 6| Step: 3
Training loss: 2.634422779083252
Validation loss: 2.014419460809359

Epoch: 6| Step: 4
Training loss: 2.0150115489959717
Validation loss: 2.003919788586196

Epoch: 6| Step: 5
Training loss: 2.785771608352661
Validation loss: 1.9852683287794872

Epoch: 6| Step: 6
Training loss: 2.1436607837677
Validation loss: 2.001291908243651

Epoch: 6| Step: 7
Training loss: 2.4887306690216064
Validation loss: 1.9916233247326267

Epoch: 6| Step: 8
Training loss: 1.8323051929473877
Validation loss: 2.0276309726058797

Epoch: 6| Step: 9
Training loss: 1.364857792854309
Validation loss: 1.994151351272419

Epoch: 6| Step: 10
Training loss: 1.9540789127349854
Validation loss: 2.0162098305199736

Epoch: 6| Step: 11
Training loss: 1.8728901147842407
Validation loss: 2.005869814144668

Epoch: 6| Step: 12
Training loss: 2.2621448040008545
Validation loss: 2.0180810882199194

Epoch: 6| Step: 13
Training loss: 2.016846179962158
Validation loss: 2.0209404448027253

Epoch: 156| Step: 0
Training loss: 1.6805648803710938
Validation loss: 1.999420847944034

Epoch: 6| Step: 1
Training loss: 2.392634391784668
Validation loss: 2.0008432672869776

Epoch: 6| Step: 2
Training loss: 3.0416383743286133
Validation loss: 2.018420914167999

Epoch: 6| Step: 3
Training loss: 1.7811024188995361
Validation loss: 2.0202382021052863

Epoch: 6| Step: 4
Training loss: 1.6525328159332275
Validation loss: 2.031012015957986

Epoch: 6| Step: 5
Training loss: 2.101663589477539
Validation loss: 2.006954603297736

Epoch: 6| Step: 6
Training loss: 2.3216068744659424
Validation loss: 2.032714714286148

Epoch: 6| Step: 7
Training loss: 1.9424538612365723
Validation loss: 2.021058979854789

Epoch: 6| Step: 8
Training loss: 2.041464328765869
Validation loss: 1.9941543379137594

Epoch: 6| Step: 9
Training loss: 1.7053754329681396
Validation loss: 2.010560671488444

Epoch: 6| Step: 10
Training loss: 1.693426489830017
Validation loss: 2.030411661312144

Epoch: 6| Step: 11
Training loss: 2.335162878036499
Validation loss: 2.021261469010384

Epoch: 6| Step: 12
Training loss: 1.8912230730056763
Validation loss: 2.02239966136153

Epoch: 6| Step: 13
Training loss: 1.819968342781067
Validation loss: 2.018921526529456

Epoch: 157| Step: 0
Training loss: 1.9805653095245361
Validation loss: 1.9963720165273195

Epoch: 6| Step: 1
Training loss: 2.3608078956604004
Validation loss: 1.9768093324476672

Epoch: 6| Step: 2
Training loss: 1.6383675336837769
Validation loss: 2.014839421036423

Epoch: 6| Step: 3
Training loss: 1.734028697013855
Validation loss: 1.9747165479967672

Epoch: 6| Step: 4
Training loss: 2.6125893592834473
Validation loss: 1.9837453544780772

Epoch: 6| Step: 5
Training loss: 1.9140514135360718
Validation loss: 2.008703403575446

Epoch: 6| Step: 6
Training loss: 1.731235146522522
Validation loss: 2.0227025452480523

Epoch: 6| Step: 7
Training loss: 1.860213041305542
Validation loss: 1.9957241678750643

Epoch: 6| Step: 8
Training loss: 2.3679685592651367
Validation loss: 1.9935062649429485

Epoch: 6| Step: 9
Training loss: 2.142714500427246
Validation loss: 1.9834006986310404

Epoch: 6| Step: 10
Training loss: 1.9312447309494019
Validation loss: 2.0143932898839316

Epoch: 6| Step: 11
Training loss: 2.1812961101531982
Validation loss: 1.9763384890812699

Epoch: 6| Step: 12
Training loss: 1.8942593336105347
Validation loss: 1.9880989751508158

Epoch: 6| Step: 13
Training loss: 2.2042582035064697
Validation loss: 1.9975043509596138

Epoch: 158| Step: 0
Training loss: 2.248842716217041
Validation loss: 1.9805658401981476

Epoch: 6| Step: 1
Training loss: 1.8617708683013916
Validation loss: 2.0027647531160744

Epoch: 6| Step: 2
Training loss: 1.5023977756500244
Validation loss: 2.0047511516078824

Epoch: 6| Step: 3
Training loss: 1.5418967008590698
Validation loss: 2.003021212034328

Epoch: 6| Step: 4
Training loss: 2.3737926483154297
Validation loss: 2.0063154902509464

Epoch: 6| Step: 5
Training loss: 2.252427577972412
Validation loss: 1.9884110714799614

Epoch: 6| Step: 6
Training loss: 2.2278189659118652
Validation loss: 2.0083458551796536

Epoch: 6| Step: 7
Training loss: 1.5103272199630737
Validation loss: 2.003155764713082

Epoch: 6| Step: 8
Training loss: 2.145030975341797
Validation loss: 2.0164971966897287

Epoch: 6| Step: 9
Training loss: 2.1837449073791504
Validation loss: 1.9945009677640853

Epoch: 6| Step: 10
Training loss: 2.136686086654663
Validation loss: 2.016006790181642

Epoch: 6| Step: 11
Training loss: 2.0661964416503906
Validation loss: 1.9913314696281188

Epoch: 6| Step: 12
Training loss: 2.1688880920410156
Validation loss: 2.0078236556822255

Epoch: 6| Step: 13
Training loss: 2.143681287765503
Validation loss: 1.9977347696981123

Epoch: 159| Step: 0
Training loss: 2.8173599243164062
Validation loss: 1.9946031442252539

Epoch: 6| Step: 1
Training loss: 1.554816722869873
Validation loss: 2.017922370664535

Epoch: 6| Step: 2
Training loss: 2.350278854370117
Validation loss: 1.9948041669784053

Epoch: 6| Step: 3
Training loss: 1.8207136392593384
Validation loss: 1.9891909860795545

Epoch: 6| Step: 4
Training loss: 1.5908206701278687
Validation loss: 1.9993624405194355

Epoch: 6| Step: 5
Training loss: 2.126229763031006
Validation loss: 2.027026478962232

Epoch: 6| Step: 6
Training loss: 2.040266752243042
Validation loss: 2.0248361787488385

Epoch: 6| Step: 7
Training loss: 1.8257664442062378
Validation loss: 1.9868093293200257

Epoch: 6| Step: 8
Training loss: 2.2358288764953613
Validation loss: 2.0154751103411437

Epoch: 6| Step: 9
Training loss: 1.9327044486999512
Validation loss: 2.0022463131976385

Epoch: 6| Step: 10
Training loss: 2.16706919670105
Validation loss: 2.0032322073495514

Epoch: 6| Step: 11
Training loss: 1.9349210262298584
Validation loss: 1.9981630386844758

Epoch: 6| Step: 12
Training loss: 2.0798141956329346
Validation loss: 1.9915993213653564

Epoch: 6| Step: 13
Training loss: 1.708969235420227
Validation loss: 1.9907513818433207

Epoch: 160| Step: 0
Training loss: 1.9800326824188232
Validation loss: 2.012264710600658

Epoch: 6| Step: 1
Training loss: 2.5443975925445557
Validation loss: 2.0157417558854624

Epoch: 6| Step: 2
Training loss: 2.0466251373291016
Validation loss: 2.029773494248749

Epoch: 6| Step: 3
Training loss: 1.927258014678955
Validation loss: 2.0354551871617637

Epoch: 6| Step: 4
Training loss: 1.8431106805801392
Validation loss: 2.01102969466999

Epoch: 6| Step: 5
Training loss: 1.7014923095703125
Validation loss: 2.0312405183751094

Epoch: 6| Step: 6
Training loss: 2.380232334136963
Validation loss: 2.0246907523883286

Epoch: 6| Step: 7
Training loss: 1.795669436454773
Validation loss: 2.031646301669459

Epoch: 6| Step: 8
Training loss: 1.7994484901428223
Validation loss: 2.030629850202991

Epoch: 6| Step: 9
Training loss: 2.3187155723571777
Validation loss: 2.045820451551868

Epoch: 6| Step: 10
Training loss: 2.095343589782715
Validation loss: 2.030616024489044

Epoch: 6| Step: 11
Training loss: 2.4368643760681152
Validation loss: 2.0014664101344284

Epoch: 6| Step: 12
Training loss: 1.618290901184082
Validation loss: 2.010031215606197

Epoch: 6| Step: 13
Training loss: 1.2216315269470215
Validation loss: 2.0223681516544794

Epoch: 161| Step: 0
Training loss: 2.643017292022705
Validation loss: 2.039823919214228

Epoch: 6| Step: 1
Training loss: 2.472627639770508
Validation loss: 2.0106981697902886

Epoch: 6| Step: 2
Training loss: 1.940070629119873
Validation loss: 1.990540837728849

Epoch: 6| Step: 3
Training loss: 1.850715160369873
Validation loss: 2.0120357313463764

Epoch: 6| Step: 4
Training loss: 1.4813085794448853
Validation loss: 2.0203951315213273

Epoch: 6| Step: 5
Training loss: 2.452505111694336
Validation loss: 2.029140075047811

Epoch: 6| Step: 6
Training loss: 2.865295171737671
Validation loss: 2.008681087083714

Epoch: 6| Step: 7
Training loss: 1.923797607421875
Validation loss: 1.9945757004522509

Epoch: 6| Step: 8
Training loss: 1.3033673763275146
Validation loss: 2.0078223892437514

Epoch: 6| Step: 9
Training loss: 2.053694725036621
Validation loss: 2.0181558260353665

Epoch: 6| Step: 10
Training loss: 1.4010800123214722
Validation loss: 2.023110712728193

Epoch: 6| Step: 11
Training loss: 2.2894368171691895
Validation loss: 2.00499100582574

Epoch: 6| Step: 12
Training loss: 1.7907109260559082
Validation loss: 2.0051145579225276

Epoch: 6| Step: 13
Training loss: 1.8513096570968628
Validation loss: 2.024499304832951

Epoch: 162| Step: 0
Training loss: 2.7277283668518066
Validation loss: 1.979806071968489

Epoch: 6| Step: 1
Training loss: 2.146763801574707
Validation loss: 1.99357618055036

Epoch: 6| Step: 2
Training loss: 2.0034966468811035
Validation loss: 1.9863699149059992

Epoch: 6| Step: 3
Training loss: 1.585081934928894
Validation loss: 1.9929793829558997

Epoch: 6| Step: 4
Training loss: 2.16165828704834
Validation loss: 1.9950472590743855

Epoch: 6| Step: 5
Training loss: 2.2896366119384766
Validation loss: 1.9989939428144885

Epoch: 6| Step: 6
Training loss: 1.7458168268203735
Validation loss: 1.9968691410556916

Epoch: 6| Step: 7
Training loss: 1.0084025859832764
Validation loss: 1.9945173494277462

Epoch: 6| Step: 8
Training loss: 2.262852668762207
Validation loss: 1.9873861048811226

Epoch: 6| Step: 9
Training loss: 2.0379929542541504
Validation loss: 2.0257056733613372

Epoch: 6| Step: 10
Training loss: 1.791145920753479
Validation loss: 1.9837507381234118

Epoch: 6| Step: 11
Training loss: 1.9607970714569092
Validation loss: 1.984913500406409

Epoch: 6| Step: 12
Training loss: 2.363898277282715
Validation loss: 2.003853290311752

Epoch: 6| Step: 13
Training loss: 2.3183770179748535
Validation loss: 1.9991693060885194

Epoch: 163| Step: 0
Training loss: 2.2372851371765137
Validation loss: 1.9984409501475673

Epoch: 6| Step: 1
Training loss: 1.9137661457061768
Validation loss: 2.0160688764305523

Epoch: 6| Step: 2
Training loss: 1.5446058511734009
Validation loss: 1.999968449274699

Epoch: 6| Step: 3
Training loss: 1.7693321704864502
Validation loss: 1.9995030280082458

Epoch: 6| Step: 4
Training loss: 1.7855854034423828
Validation loss: 1.986650873255986

Epoch: 6| Step: 5
Training loss: 1.9034485816955566
Validation loss: 2.0028263061277327

Epoch: 6| Step: 6
Training loss: 2.247692823410034
Validation loss: 1.983213875883369

Epoch: 6| Step: 7
Training loss: 2.5625193119049072
Validation loss: 1.98777162900535

Epoch: 6| Step: 8
Training loss: 1.7777173519134521
Validation loss: 2.0132925305315243

Epoch: 6| Step: 9
Training loss: 1.55949068069458
Validation loss: 2.01224817896402

Epoch: 6| Step: 10
Training loss: 2.2422714233398438
Validation loss: 2.008423237390416

Epoch: 6| Step: 11
Training loss: 2.1278066635131836
Validation loss: 2.0136153121148386

Epoch: 6| Step: 12
Training loss: 2.1297824382781982
Validation loss: 1.9973406689141386

Epoch: 6| Step: 13
Training loss: 2.412890911102295
Validation loss: 1.9809673857945267

Epoch: 164| Step: 0
Training loss: 1.6774982213974
Validation loss: 2.0383989810943604

Epoch: 6| Step: 1
Training loss: 1.9710631370544434
Validation loss: 1.9895622602073095

Epoch: 6| Step: 2
Training loss: 1.5966718196868896
Validation loss: 2.017307109730218

Epoch: 6| Step: 3
Training loss: 2.0232715606689453
Validation loss: 2.0044121767884944

Epoch: 6| Step: 4
Training loss: 2.396265745162964
Validation loss: 2.0086166576672624

Epoch: 6| Step: 5
Training loss: 2.131565570831299
Validation loss: 2.003973430202853

Epoch: 6| Step: 6
Training loss: 1.9802782535552979
Validation loss: 1.9901641363738685

Epoch: 6| Step: 7
Training loss: 2.4321043491363525
Validation loss: 2.0090012396535566

Epoch: 6| Step: 8
Training loss: 2.3593273162841797
Validation loss: 2.003350046373183

Epoch: 6| Step: 9
Training loss: 1.18348228931427
Validation loss: 2.0129306483012375

Epoch: 6| Step: 10
Training loss: 2.2180228233337402
Validation loss: 1.9931072496598767

Epoch: 6| Step: 11
Training loss: 1.9251348972320557
Validation loss: 1.9887944242005706

Epoch: 6| Step: 12
Training loss: 2.3144021034240723
Validation loss: 2.0045767804627777

Epoch: 6| Step: 13
Training loss: 1.6306252479553223
Validation loss: 2.0019669866049163

Epoch: 165| Step: 0
Training loss: 2.3189754486083984
Validation loss: 2.0104692494997414

Epoch: 6| Step: 1
Training loss: 1.6677007675170898
Validation loss: 2.0298093095902474

Epoch: 6| Step: 2
Training loss: 2.1587069034576416
Validation loss: 2.003345230574249

Epoch: 6| Step: 3
Training loss: 1.9927196502685547
Validation loss: 2.043131246361681

Epoch: 6| Step: 4
Training loss: 1.9493837356567383
Validation loss: 1.9980381842582458

Epoch: 6| Step: 5
Training loss: 2.0857150554656982
Validation loss: 2.00425451032577

Epoch: 6| Step: 6
Training loss: 1.6254734992980957
Validation loss: 2.0142812113608084

Epoch: 6| Step: 7
Training loss: 2.254270076751709
Validation loss: 2.025601456242223

Epoch: 6| Step: 8
Training loss: 2.051164388656616
Validation loss: 2.0042861456512124

Epoch: 6| Step: 9
Training loss: 2.1728875637054443
Validation loss: 2.0409194795034264

Epoch: 6| Step: 10
Training loss: 2.099838972091675
Validation loss: 2.0341046458931378

Epoch: 6| Step: 11
Training loss: 1.8913393020629883
Validation loss: 2.032685551592099

Epoch: 6| Step: 12
Training loss: 1.7454638481140137
Validation loss: 2.020609910770129

Epoch: 6| Step: 13
Training loss: 3.02933931350708
Validation loss: 2.019212302341256

Epoch: 166| Step: 0
Training loss: 1.9980740547180176
Validation loss: 2.0256378881392942

Epoch: 6| Step: 1
Training loss: 1.8261923789978027
Validation loss: 2.0136367556869343

Epoch: 6| Step: 2
Training loss: 1.4663097858428955
Validation loss: 2.0059840461259246

Epoch: 6| Step: 3
Training loss: 1.7188538312911987
Validation loss: 2.034030028568801

Epoch: 6| Step: 4
Training loss: 2.041254758834839
Validation loss: 2.0180457048518683

Epoch: 6| Step: 5
Training loss: 2.3163416385650635
Validation loss: 2.009530773726843

Epoch: 6| Step: 6
Training loss: 1.9447591304779053
Validation loss: 2.0333672531189455

Epoch: 6| Step: 7
Training loss: 2.470745325088501
Validation loss: 2.0006211316713722

Epoch: 6| Step: 8
Training loss: 1.2547352313995361
Validation loss: 2.0095003522852415

Epoch: 6| Step: 9
Training loss: 2.6444525718688965
Validation loss: 2.002381145313222

Epoch: 6| Step: 10
Training loss: 2.362438917160034
Validation loss: 1.9895042950107205

Epoch: 6| Step: 11
Training loss: 2.1766538619995117
Validation loss: 2.004363613743936

Epoch: 6| Step: 12
Training loss: 1.8138470649719238
Validation loss: 2.0039597634346253

Epoch: 6| Step: 13
Training loss: 2.352771520614624
Validation loss: 2.0326444948873212

Epoch: 167| Step: 0
Training loss: 2.405956268310547
Validation loss: 2.0159507951428814

Epoch: 6| Step: 1
Training loss: 2.0468201637268066
Validation loss: 2.029435832013366

Epoch: 6| Step: 2
Training loss: 2.2827847003936768
Validation loss: 2.0169911564037366

Epoch: 6| Step: 3
Training loss: 2.0168092250823975
Validation loss: 2.013172403458626

Epoch: 6| Step: 4
Training loss: 1.6809898614883423
Validation loss: 2.002747990751779

Epoch: 6| Step: 5
Training loss: 2.4179532527923584
Validation loss: 2.0108428180858655

Epoch: 6| Step: 6
Training loss: 1.6498630046844482
Validation loss: 2.002988571761757

Epoch: 6| Step: 7
Training loss: 1.57628333568573
Validation loss: 1.9868766056594027

Epoch: 6| Step: 8
Training loss: 1.492094874382019
Validation loss: 2.0296971554397256

Epoch: 6| Step: 9
Training loss: 1.9596539735794067
Validation loss: 2.0220633963102936

Epoch: 6| Step: 10
Training loss: 2.656731128692627
Validation loss: 2.004844897536821

Epoch: 6| Step: 11
Training loss: 1.817131519317627
Validation loss: 2.0163110084431146

Epoch: 6| Step: 12
Training loss: 2.337212562561035
Validation loss: 2.0324344019736014

Epoch: 6| Step: 13
Training loss: 1.4551242589950562
Validation loss: 2.031210578897948

Epoch: 168| Step: 0
Training loss: 1.9658122062683105
Validation loss: 2.0221928883624334

Epoch: 6| Step: 1
Training loss: 1.988465666770935
Validation loss: 2.024159739094396

Epoch: 6| Step: 2
Training loss: 1.3333919048309326
Validation loss: 2.0074789267714306

Epoch: 6| Step: 3
Training loss: 1.3294239044189453
Validation loss: 2.0279373071526967

Epoch: 6| Step: 4
Training loss: 2.465909957885742
Validation loss: 2.0296768680695565

Epoch: 6| Step: 5
Training loss: 1.8992642164230347
Validation loss: 2.025271508001512

Epoch: 6| Step: 6
Training loss: 2.1885414123535156
Validation loss: 2.012638863696847

Epoch: 6| Step: 7
Training loss: 1.7807718515396118
Validation loss: 2.0048799668588946

Epoch: 6| Step: 8
Training loss: 2.613637685775757
Validation loss: 2.005888250566298

Epoch: 6| Step: 9
Training loss: 2.520552158355713
Validation loss: 1.9977148937922653

Epoch: 6| Step: 10
Training loss: 1.948594570159912
Validation loss: 2.0111839784088956

Epoch: 6| Step: 11
Training loss: 2.3681716918945312
Validation loss: 2.003415593536951

Epoch: 6| Step: 12
Training loss: 2.0010223388671875
Validation loss: 2.0083671462151313

Epoch: 6| Step: 13
Training loss: 1.561323642730713
Validation loss: 1.9991466640144266

Epoch: 169| Step: 0
Training loss: 2.0316638946533203
Validation loss: 1.974664867565196

Epoch: 6| Step: 1
Training loss: 1.8450038433074951
Validation loss: 1.9893298341381935

Epoch: 6| Step: 2
Training loss: 2.1636505126953125
Validation loss: 2.001514929597096

Epoch: 6| Step: 3
Training loss: 1.6810023784637451
Validation loss: 2.0239759388790337

Epoch: 6| Step: 4
Training loss: 2.101841449737549
Validation loss: 2.0092956045622468

Epoch: 6| Step: 5
Training loss: 1.6581737995147705
Validation loss: 1.9989608897957751

Epoch: 6| Step: 6
Training loss: 2.253228187561035
Validation loss: 2.0008686819384174

Epoch: 6| Step: 7
Training loss: 1.773032784461975
Validation loss: 2.013411823139396

Epoch: 6| Step: 8
Training loss: 2.1347546577453613
Validation loss: 2.0254040277132423

Epoch: 6| Step: 9
Training loss: 2.346998691558838
Validation loss: 1.9814566091824604

Epoch: 6| Step: 10
Training loss: 1.869828701019287
Validation loss: 2.013014552413776

Epoch: 6| Step: 11
Training loss: 2.261875629425049
Validation loss: 2.02498891276698

Epoch: 6| Step: 12
Training loss: 2.137718677520752
Validation loss: 2.028528718538182

Epoch: 6| Step: 13
Training loss: 1.3378223180770874
Validation loss: 2.010029444130518

Epoch: 170| Step: 0
Training loss: 1.5894176959991455
Validation loss: 2.028106040852044

Epoch: 6| Step: 1
Training loss: 2.1162209510803223
Validation loss: 2.005735014074592

Epoch: 6| Step: 2
Training loss: 2.409186363220215
Validation loss: 2.034124638444634

Epoch: 6| Step: 3
Training loss: 2.8856709003448486
Validation loss: 2.015314150882024

Epoch: 6| Step: 4
Training loss: 1.5684581995010376
Validation loss: 2.031815107150744

Epoch: 6| Step: 5
Training loss: 2.133129358291626
Validation loss: 2.0274513652247768

Epoch: 6| Step: 6
Training loss: 2.0825207233428955
Validation loss: 2.001016081020396

Epoch: 6| Step: 7
Training loss: 1.9225798845291138
Validation loss: 1.994662760406412

Epoch: 6| Step: 8
Training loss: 2.2693557739257812
Validation loss: 2.0083554239683252

Epoch: 6| Step: 9
Training loss: 1.2899142503738403
Validation loss: 2.0012582335420834

Epoch: 6| Step: 10
Training loss: 1.9986767768859863
Validation loss: 2.002746407703687

Epoch: 6| Step: 11
Training loss: 1.959587574005127
Validation loss: 1.999020234231026

Epoch: 6| Step: 12
Training loss: 2.098134994506836
Validation loss: 2.0072684416206936

Epoch: 6| Step: 13
Training loss: 1.2939807176589966
Validation loss: 1.9936992711918329

Epoch: 171| Step: 0
Training loss: 1.1968879699707031
Validation loss: 2.0037383879384687

Epoch: 6| Step: 1
Training loss: 2.5936365127563477
Validation loss: 2.0169629063657535

Epoch: 6| Step: 2
Training loss: 1.682863712310791
Validation loss: 2.0026808323398715

Epoch: 6| Step: 3
Training loss: 2.0408694744110107
Validation loss: 2.000992432717354

Epoch: 6| Step: 4
Training loss: 2.1394102573394775
Validation loss: 2.0047518412272134

Epoch: 6| Step: 5
Training loss: 1.6469873189926147
Validation loss: 2.0054386226079797

Epoch: 6| Step: 6
Training loss: 2.374176025390625
Validation loss: 2.0002346346455235

Epoch: 6| Step: 7
Training loss: 2.0564424991607666
Validation loss: 2.039308158300256

Epoch: 6| Step: 8
Training loss: 2.2250375747680664
Validation loss: 2.009260303230696

Epoch: 6| Step: 9
Training loss: 1.8135159015655518
Validation loss: 2.000590644856935

Epoch: 6| Step: 10
Training loss: 1.951149344444275
Validation loss: 2.002665450496058

Epoch: 6| Step: 11
Training loss: 2.1322550773620605
Validation loss: 2.0129795766645864

Epoch: 6| Step: 12
Training loss: 1.7845823764801025
Validation loss: 2.0208854342019684

Epoch: 6| Step: 13
Training loss: 2.4569103717803955
Validation loss: 2.0432441529407295

Epoch: 172| Step: 0
Training loss: 2.1404480934143066
Validation loss: 1.981505787500771

Epoch: 6| Step: 1
Training loss: 1.8476552963256836
Validation loss: 2.0116950722150904

Epoch: 6| Step: 2
Training loss: 1.5276942253112793
Validation loss: 2.0150510213708364

Epoch: 6| Step: 3
Training loss: 2.0291571617126465
Validation loss: 2.014536634568245

Epoch: 6| Step: 4
Training loss: 1.3099730014801025
Validation loss: 2.0532707886029313

Epoch: 6| Step: 5
Training loss: 1.1167914867401123
Validation loss: 2.003129541233022

Epoch: 6| Step: 6
Training loss: 2.3806071281433105
Validation loss: 2.0189232441686813

Epoch: 6| Step: 7
Training loss: 2.2518391609191895
Validation loss: 2.0314195489370697

Epoch: 6| Step: 8
Training loss: 2.6517348289489746
Validation loss: 2.013210869604541

Epoch: 6| Step: 9
Training loss: 2.0394763946533203
Validation loss: 1.9983291215794061

Epoch: 6| Step: 10
Training loss: 2.321974515914917
Validation loss: 2.0073355551688903

Epoch: 6| Step: 11
Training loss: 2.2362189292907715
Validation loss: 2.0195592257284347

Epoch: 6| Step: 12
Training loss: 2.282166004180908
Validation loss: 1.9955947963140344

Epoch: 6| Step: 13
Training loss: 2.003798007965088
Validation loss: 2.0084664180714595

Epoch: 173| Step: 0
Training loss: 2.820258378982544
Validation loss: 2.0319462873602427

Epoch: 6| Step: 1
Training loss: 2.316941499710083
Validation loss: 1.9953090478015203

Epoch: 6| Step: 2
Training loss: 1.716521978378296
Validation loss: 2.0006851073234313

Epoch: 6| Step: 3
Training loss: 1.958949089050293
Validation loss: 2.027546896729418

Epoch: 6| Step: 4
Training loss: 2.1274194717407227
Validation loss: 1.9974103935303227

Epoch: 6| Step: 5
Training loss: 2.1899423599243164
Validation loss: 2.012256796642016

Epoch: 6| Step: 6
Training loss: 1.7868572473526
Validation loss: 2.0409675208471154

Epoch: 6| Step: 7
Training loss: 1.8514800071716309
Validation loss: 2.0238479465566654

Epoch: 6| Step: 8
Training loss: 2.1685409545898438
Validation loss: 2.0384169176060665

Epoch: 6| Step: 9
Training loss: 1.4718785285949707
Validation loss: 2.009674611911979

Epoch: 6| Step: 10
Training loss: 2.3026111125946045
Validation loss: 2.0156806079290246

Epoch: 6| Step: 11
Training loss: 2.0314807891845703
Validation loss: 2.033038621307701

Epoch: 6| Step: 12
Training loss: 0.8424572348594666
Validation loss: 2.0129229971157607

Epoch: 6| Step: 13
Training loss: 2.6493687629699707
Validation loss: 2.013716540028972

Epoch: 174| Step: 0
Training loss: 1.2869364023208618
Validation loss: 2.039321373867732

Epoch: 6| Step: 1
Training loss: 1.1607372760772705
Validation loss: 2.0023273216780795

Epoch: 6| Step: 2
Training loss: 1.5473767518997192
Validation loss: 2.026442914880732

Epoch: 6| Step: 3
Training loss: 2.455613613128662
Validation loss: 2.01584150714259

Epoch: 6| Step: 4
Training loss: 1.9668570756912231
Validation loss: 2.0212267880798667

Epoch: 6| Step: 5
Training loss: 2.079893112182617
Validation loss: 2.024832220487697

Epoch: 6| Step: 6
Training loss: 2.606513023376465
Validation loss: 2.013282296478107

Epoch: 6| Step: 7
Training loss: 2.270432949066162
Validation loss: 2.005053248456729

Epoch: 6| Step: 8
Training loss: 1.9307198524475098
Validation loss: 2.014864654951198

Epoch: 6| Step: 9
Training loss: 1.4456666707992554
Validation loss: 2.0388628180309007

Epoch: 6| Step: 10
Training loss: 2.132383108139038
Validation loss: 2.0084602320066063

Epoch: 6| Step: 11
Training loss: 2.2322230339050293
Validation loss: 2.0036906529498357

Epoch: 6| Step: 12
Training loss: 2.7043027877807617
Validation loss: 2.0172700010320193

Epoch: 6| Step: 13
Training loss: 2.214808464050293
Validation loss: 2.0312611415822017

Epoch: 175| Step: 0
Training loss: 1.86114501953125
Validation loss: 2.0365380740934804

Epoch: 6| Step: 1
Training loss: 1.518003225326538
Validation loss: 2.03851624970795

Epoch: 6| Step: 2
Training loss: 1.973705768585205
Validation loss: 2.020637371206796

Epoch: 6| Step: 3
Training loss: 1.660634994506836
Validation loss: 2.027950518874712

Epoch: 6| Step: 4
Training loss: 2.2017030715942383
Validation loss: 1.9918113267549904

Epoch: 6| Step: 5
Training loss: 2.1872663497924805
Validation loss: 2.050373192756407

Epoch: 6| Step: 6
Training loss: 1.5426990985870361
Validation loss: 2.0296530800481

Epoch: 6| Step: 7
Training loss: 1.9766781330108643
Validation loss: 1.999735466895565

Epoch: 6| Step: 8
Training loss: 1.419447660446167
Validation loss: 2.0436451806817004

Epoch: 6| Step: 9
Training loss: 2.275618314743042
Validation loss: 2.004590436976443

Epoch: 6| Step: 10
Training loss: 2.4621591567993164
Validation loss: 2.0111867663680867

Epoch: 6| Step: 11
Training loss: 1.903637170791626
Validation loss: 2.005439817264516

Epoch: 6| Step: 12
Training loss: 2.3615939617156982
Validation loss: 2.015314536709939

Epoch: 6| Step: 13
Training loss: 2.841831922531128
Validation loss: 2.017785240245122

Epoch: 176| Step: 0
Training loss: 1.5475695133209229
Validation loss: 2.017452134880968

Epoch: 6| Step: 1
Training loss: 2.1020679473876953
Validation loss: 2.0019886160409577

Epoch: 6| Step: 2
Training loss: 1.3049249649047852
Validation loss: 2.02880113099211

Epoch: 6| Step: 3
Training loss: 2.2353477478027344
Validation loss: 1.984702819137163

Epoch: 6| Step: 4
Training loss: 2.268338203430176
Validation loss: 2.009236137072245

Epoch: 6| Step: 5
Training loss: 1.6434777975082397
Validation loss: 2.031498988469442

Epoch: 6| Step: 6
Training loss: 2.1551547050476074
Validation loss: 2.0453045970650128

Epoch: 6| Step: 7
Training loss: 1.5930858850479126
Validation loss: 2.0352686579509447

Epoch: 6| Step: 8
Training loss: 1.70458984375
Validation loss: 2.0323448322152577

Epoch: 6| Step: 9
Training loss: 2.364020347595215
Validation loss: 2.0255320405447357

Epoch: 6| Step: 10
Training loss: 2.499211549758911
Validation loss: 2.015518775550268

Epoch: 6| Step: 11
Training loss: 2.181330680847168
Validation loss: 1.9848944089745963

Epoch: 6| Step: 12
Training loss: 2.084904909133911
Validation loss: 2.0132024993178663

Epoch: 6| Step: 13
Training loss: 2.0145444869995117
Validation loss: 2.010240908591978

Epoch: 177| Step: 0
Training loss: 1.7985949516296387
Validation loss: 2.0223426818847656

Epoch: 6| Step: 1
Training loss: 1.3672771453857422
Validation loss: 1.9975867745696858

Epoch: 6| Step: 2
Training loss: 2.2529759407043457
Validation loss: 2.0304314321087253

Epoch: 6| Step: 3
Training loss: 2.308218240737915
Validation loss: 2.0304881270213793

Epoch: 6| Step: 4
Training loss: 1.6336407661437988
Validation loss: 2.017483724060879

Epoch: 6| Step: 5
Training loss: 1.4876563549041748
Validation loss: 2.0307126327227523

Epoch: 6| Step: 6
Training loss: 1.9330008029937744
Validation loss: 2.0155343714580742

Epoch: 6| Step: 7
Training loss: 2.657212734222412
Validation loss: 2.0057212921880905

Epoch: 6| Step: 8
Training loss: 2.086204767227173
Validation loss: 2.007924090149582

Epoch: 6| Step: 9
Training loss: 2.7757577896118164
Validation loss: 1.9872782384195635

Epoch: 6| Step: 10
Training loss: 2.1634507179260254
Validation loss: 2.0184986437520673

Epoch: 6| Step: 11
Training loss: 1.1907804012298584
Validation loss: 2.007766010940716

Epoch: 6| Step: 12
Training loss: 2.158902645111084
Validation loss: 2.0183317802285634

Epoch: 6| Step: 13
Training loss: 2.1838300228118896
Validation loss: 2.0100317847344185

Epoch: 178| Step: 0
Training loss: 2.3641815185546875
Validation loss: 2.0030636954051193

Epoch: 6| Step: 1
Training loss: 2.381697177886963
Validation loss: 2.0370920140256166

Epoch: 6| Step: 2
Training loss: 1.4095804691314697
Validation loss: 2.014061421476385

Epoch: 6| Step: 3
Training loss: 1.557046890258789
Validation loss: 2.0231305065975396

Epoch: 6| Step: 4
Training loss: 2.0625877380371094
Validation loss: 2.0284853827568794

Epoch: 6| Step: 5
Training loss: 2.8706464767456055
Validation loss: 2.028042265163955

Epoch: 6| Step: 6
Training loss: 1.417531967163086
Validation loss: 2.053699594672008

Epoch: 6| Step: 7
Training loss: 2.2651095390319824
Validation loss: 2.0347813073024956

Epoch: 6| Step: 8
Training loss: 2.039665460586548
Validation loss: 2.047974366013722

Epoch: 6| Step: 9
Training loss: 1.8135128021240234
Validation loss: 2.025339989251988

Epoch: 6| Step: 10
Training loss: 1.6362501382827759
Validation loss: 2.0200956444586478

Epoch: 6| Step: 11
Training loss: 2.3560984134674072
Validation loss: 2.038742394857509

Epoch: 6| Step: 12
Training loss: 2.000976800918579
Validation loss: 2.0310354501970354

Epoch: 6| Step: 13
Training loss: 1.3930364847183228
Validation loss: 2.0431001365825696

Epoch: 179| Step: 0
Training loss: 1.8614121675491333
Validation loss: 2.030942181105255

Epoch: 6| Step: 1
Training loss: 1.5636277198791504
Validation loss: 2.0248781981006747

Epoch: 6| Step: 2
Training loss: 1.6120790243148804
Validation loss: 2.0364697953706146

Epoch: 6| Step: 3
Training loss: 1.806731939315796
Validation loss: 2.0250265316296647

Epoch: 6| Step: 4
Training loss: 2.1552042961120605
Validation loss: 2.012882617212111

Epoch: 6| Step: 5
Training loss: 2.3062357902526855
Validation loss: 2.0280477834004227

Epoch: 6| Step: 6
Training loss: 2.348888397216797
Validation loss: 2.032579131023858

Epoch: 6| Step: 7
Training loss: 1.5447419881820679
Validation loss: 2.00593319759574

Epoch: 6| Step: 8
Training loss: 1.4631856679916382
Validation loss: 1.9888035738339989

Epoch: 6| Step: 9
Training loss: 1.4395925998687744
Validation loss: 2.005985052354874

Epoch: 6| Step: 10
Training loss: 2.2424871921539307
Validation loss: 1.9884031203485304

Epoch: 6| Step: 11
Training loss: 2.305870771408081
Validation loss: 1.9828243383797266

Epoch: 6| Step: 12
Training loss: 2.78145694732666
Validation loss: 1.9902871398515598

Epoch: 6| Step: 13
Training loss: 2.7964465618133545
Validation loss: 2.011959296400829

Epoch: 180| Step: 0
Training loss: 2.1489009857177734
Validation loss: 2.004546388503044

Epoch: 6| Step: 1
Training loss: 1.0455632209777832
Validation loss: 2.0348230164538146

Epoch: 6| Step: 2
Training loss: 2.4356303215026855
Validation loss: 2.0384107097502677

Epoch: 6| Step: 3
Training loss: 2.743657112121582
Validation loss: 2.0325934861295964

Epoch: 6| Step: 4
Training loss: 2.0826873779296875
Validation loss: 2.0358552599465973

Epoch: 6| Step: 5
Training loss: 1.7694365978240967
Validation loss: 2.0088121596203057

Epoch: 6| Step: 6
Training loss: 2.347315788269043
Validation loss: 2.030330986104986

Epoch: 6| Step: 7
Training loss: 1.5072600841522217
Validation loss: 2.0128813687191216

Epoch: 6| Step: 8
Training loss: 1.9165821075439453
Validation loss: 2.0333250312394995

Epoch: 6| Step: 9
Training loss: 1.5001327991485596
Validation loss: 2.019597425255724

Epoch: 6| Step: 10
Training loss: 2.142035484313965
Validation loss: 1.995093309751121

Epoch: 6| Step: 11
Training loss: 1.9735500812530518
Validation loss: 2.020144998386342

Epoch: 6| Step: 12
Training loss: 1.9004366397857666
Validation loss: 2.004459870758877

Epoch: 6| Step: 13
Training loss: 2.270732879638672
Validation loss: 2.019984581137216

Epoch: 181| Step: 0
Training loss: 2.6436281204223633
Validation loss: 2.0167911475704563

Epoch: 6| Step: 1
Training loss: 2.2850170135498047
Validation loss: 2.0212430595069804

Epoch: 6| Step: 2
Training loss: 2.594923496246338
Validation loss: 2.023821125748337

Epoch: 6| Step: 3
Training loss: 1.9693443775177002
Validation loss: 2.0027816167441745

Epoch: 6| Step: 4
Training loss: 2.702907085418701
Validation loss: 2.0193334253885413

Epoch: 6| Step: 5
Training loss: 1.748445987701416
Validation loss: 2.0242059230804443

Epoch: 6| Step: 6
Training loss: 1.3699713945388794
Validation loss: 1.9890280321080198

Epoch: 6| Step: 7
Training loss: 1.622270107269287
Validation loss: 2.005755627027122

Epoch: 6| Step: 8
Training loss: 1.6959350109100342
Validation loss: 2.01796535266343

Epoch: 6| Step: 9
Training loss: 1.5265679359436035
Validation loss: 2.005243896156229

Epoch: 6| Step: 10
Training loss: 1.0888314247131348
Validation loss: 2.0044608526332404

Epoch: 6| Step: 11
Training loss: 2.5879015922546387
Validation loss: 2.0116606425213557

Epoch: 6| Step: 12
Training loss: 2.024401903152466
Validation loss: 2.020500906052128

Epoch: 6| Step: 13
Training loss: 1.8964762687683105
Validation loss: 2.0136994379822926

Epoch: 182| Step: 0
Training loss: 2.4810829162597656
Validation loss: 2.010974416168787

Epoch: 6| Step: 1
Training loss: 1.5889581441879272
Validation loss: 2.0299175272705736

Epoch: 6| Step: 2
Training loss: 2.0635361671447754
Validation loss: 2.025700984462615

Epoch: 6| Step: 3
Training loss: 2.2374095916748047
Validation loss: 2.0071492220765803

Epoch: 6| Step: 4
Training loss: 2.1498947143554688
Validation loss: 2.0133100876244168

Epoch: 6| Step: 5
Training loss: 1.5246901512145996
Validation loss: 2.005285686062228

Epoch: 6| Step: 6
Training loss: 2.2270004749298096
Validation loss: 2.0452511156758955

Epoch: 6| Step: 7
Training loss: 1.3603240251541138
Validation loss: 2.0382500412643596

Epoch: 6| Step: 8
Training loss: 1.8437193632125854
Validation loss: 2.0180957201988465

Epoch: 6| Step: 9
Training loss: 2.1980972290039062
Validation loss: 2.027947013096143

Epoch: 6| Step: 10
Training loss: 2.1988065242767334
Validation loss: 2.013475856473369

Epoch: 6| Step: 11
Training loss: 1.4211724996566772
Validation loss: 2.0261614553390013

Epoch: 6| Step: 12
Training loss: 3.092818260192871
Validation loss: 2.023182745902769

Epoch: 6| Step: 13
Training loss: 1.0859476327896118
Validation loss: 2.010663975951492

Epoch: 183| Step: 0
Training loss: 2.3611698150634766
Validation loss: 2.043550214459819

Epoch: 6| Step: 1
Training loss: 2.6593844890594482
Validation loss: 2.021472236161591

Epoch: 6| Step: 2
Training loss: 1.4286901950836182
Validation loss: 2.0004441507401003

Epoch: 6| Step: 3
Training loss: 2.287264347076416
Validation loss: 2.0126623645905526

Epoch: 6| Step: 4
Training loss: 1.9040188789367676
Validation loss: 2.0201644205277964

Epoch: 6| Step: 5
Training loss: 1.883894920349121
Validation loss: 2.032305525195214

Epoch: 6| Step: 6
Training loss: 1.626051425933838
Validation loss: 2.0334370008078952

Epoch: 6| Step: 7
Training loss: 2.7109930515289307
Validation loss: 2.002272780223559

Epoch: 6| Step: 8
Training loss: 2.5701370239257812
Validation loss: 2.050952781913101

Epoch: 6| Step: 9
Training loss: 1.684943675994873
Validation loss: 2.0051575463305236

Epoch: 6| Step: 10
Training loss: 2.051858425140381
Validation loss: 2.013950845246674

Epoch: 6| Step: 11
Training loss: 1.7988947629928589
Validation loss: 2.0380269263380315

Epoch: 6| Step: 12
Training loss: 0.9326401948928833
Validation loss: 2.0362522755899737

Epoch: 6| Step: 13
Training loss: 1.7517904043197632
Validation loss: 2.016081065259954

Epoch: 184| Step: 0
Training loss: 2.16088604927063
Validation loss: 2.002313229345506

Epoch: 6| Step: 1
Training loss: 2.623295307159424
Validation loss: 2.033973293919717

Epoch: 6| Step: 2
Training loss: 2.0028128623962402
Validation loss: 1.9957424632964595

Epoch: 6| Step: 3
Training loss: 2.1294972896575928
Validation loss: 2.013601933756182

Epoch: 6| Step: 4
Training loss: 1.795360803604126
Validation loss: 2.01026217655469

Epoch: 6| Step: 5
Training loss: 1.6952872276306152
Validation loss: 2.0164218923097015

Epoch: 6| Step: 6
Training loss: 1.4452433586120605
Validation loss: 2.0242257220770723

Epoch: 6| Step: 7
Training loss: 2.5439963340759277
Validation loss: 2.0197506643110708

Epoch: 6| Step: 8
Training loss: 1.90421724319458
Validation loss: 2.019986597440576

Epoch: 6| Step: 9
Training loss: 1.4139189720153809
Validation loss: 2.019310338522798

Epoch: 6| Step: 10
Training loss: 1.6601908206939697
Validation loss: 2.0391534323333413

Epoch: 6| Step: 11
Training loss: 1.8344292640686035
Validation loss: 2.016814445936552

Epoch: 6| Step: 12
Training loss: 2.1833596229553223
Validation loss: 2.0403179455828924

Epoch: 6| Step: 13
Training loss: 2.497756242752075
Validation loss: 2.03967135952365

Epoch: 185| Step: 0
Training loss: 2.1216049194335938
Validation loss: 2.0066923761880524

Epoch: 6| Step: 1
Training loss: 1.356276035308838
Validation loss: 2.0492717322482856

Epoch: 6| Step: 2
Training loss: 1.768014669418335
Validation loss: 2.024946687042072

Epoch: 6| Step: 3
Training loss: 2.5418148040771484
Validation loss: 1.999702775350181

Epoch: 6| Step: 4
Training loss: 1.8632750511169434
Validation loss: 2.0106122045106787

Epoch: 6| Step: 5
Training loss: 2.2681736946105957
Validation loss: 2.010265745142455

Epoch: 6| Step: 6
Training loss: 2.0746493339538574
Validation loss: 2.0087473879578295

Epoch: 6| Step: 7
Training loss: 2.103562831878662
Validation loss: 2.014594142154981

Epoch: 6| Step: 8
Training loss: 1.2381733655929565
Validation loss: 2.020798680602863

Epoch: 6| Step: 9
Training loss: 2.424506425857544
Validation loss: 2.026255581968574

Epoch: 6| Step: 10
Training loss: 2.1741580963134766
Validation loss: 2.0092596366841304

Epoch: 6| Step: 11
Training loss: 1.7759363651275635
Validation loss: 2.001626512055756

Epoch: 6| Step: 12
Training loss: 1.7067385911941528
Validation loss: 2.0031863463822233

Epoch: 6| Step: 13
Training loss: 2.3805558681488037
Validation loss: 2.0319413779884257

Epoch: 186| Step: 0
Training loss: 1.0062793493270874
Validation loss: 2.0469398690808203

Epoch: 6| Step: 1
Training loss: 1.4738582372665405
Validation loss: 2.036087647561104

Epoch: 6| Step: 2
Training loss: 1.733393669128418
Validation loss: 2.0040837462230394

Epoch: 6| Step: 3
Training loss: 2.133462905883789
Validation loss: 2.0216701838278

Epoch: 6| Step: 4
Training loss: 2.562586545944214
Validation loss: 2.0148075344741985

Epoch: 6| Step: 5
Training loss: 2.476670980453491
Validation loss: 2.0197960356230378

Epoch: 6| Step: 6
Training loss: 2.0567328929901123
Validation loss: 2.0322801541256648

Epoch: 6| Step: 7
Training loss: 2.072298288345337
Validation loss: 2.0282002008089455

Epoch: 6| Step: 8
Training loss: 1.8015923500061035
Validation loss: 2.0401333993481052

Epoch: 6| Step: 9
Training loss: 1.6684391498565674
Validation loss: 2.031934786868352

Epoch: 6| Step: 10
Training loss: 2.3135054111480713
Validation loss: 2.0454911749850035

Epoch: 6| Step: 11
Training loss: 2.2013158798217773
Validation loss: 2.042147477467855

Epoch: 6| Step: 12
Training loss: 2.232626438140869
Validation loss: 2.044684315240511

Epoch: 6| Step: 13
Training loss: 1.7103126049041748
Validation loss: 2.0303794504493795

Epoch: 187| Step: 0
Training loss: 2.4433345794677734
Validation loss: 2.0315612541731967

Epoch: 6| Step: 1
Training loss: 1.5155065059661865
Validation loss: 2.0411269344309324

Epoch: 6| Step: 2
Training loss: 1.9448535442352295
Validation loss: 2.0099441107883247

Epoch: 6| Step: 3
Training loss: 1.7412505149841309
Validation loss: 2.024483537161222

Epoch: 6| Step: 4
Training loss: 2.09016752243042
Validation loss: 2.0255696145437097

Epoch: 6| Step: 5
Training loss: 2.59678053855896
Validation loss: 2.0286828907587195

Epoch: 6| Step: 6
Training loss: 1.6176384687423706
Validation loss: 2.0427922946150585

Epoch: 6| Step: 7
Training loss: 2.4249680042266846
Validation loss: 2.030873570390927

Epoch: 6| Step: 8
Training loss: 0.9311159253120422
Validation loss: 2.0288303949499644

Epoch: 6| Step: 9
Training loss: 1.4602913856506348
Validation loss: 2.020496319699031

Epoch: 6| Step: 10
Training loss: 2.816089630126953
Validation loss: 2.0343960023695424

Epoch: 6| Step: 11
Training loss: 2.2329916954040527
Validation loss: 2.0334905052697785

Epoch: 6| Step: 12
Training loss: 2.1875200271606445
Validation loss: 2.017579085083418

Epoch: 6| Step: 13
Training loss: 1.3654980659484863
Validation loss: 2.010123586141935

Epoch: 188| Step: 0
Training loss: 1.9036357402801514
Validation loss: 2.0218143911771875

Epoch: 6| Step: 1
Training loss: 2.2263853549957275
Validation loss: 2.033207008915563

Epoch: 6| Step: 2
Training loss: 1.5807162523269653
Validation loss: 2.0173497148739394

Epoch: 6| Step: 3
Training loss: 1.667127251625061
Validation loss: 2.014496954538489

Epoch: 6| Step: 4
Training loss: 1.2957878112792969
Validation loss: 2.0373170311732958

Epoch: 6| Step: 5
Training loss: 1.6713658571243286
Validation loss: 2.0423787716896302

Epoch: 6| Step: 6
Training loss: 1.7242951393127441
Validation loss: 2.029841289725355

Epoch: 6| Step: 7
Training loss: 2.348054885864258
Validation loss: 2.0229031475641395

Epoch: 6| Step: 8
Training loss: 2.115255832672119
Validation loss: 2.0335664108235347

Epoch: 6| Step: 9
Training loss: 1.7020968198776245
Validation loss: 2.041306121374971

Epoch: 6| Step: 10
Training loss: 2.51192045211792
Validation loss: 2.0132948224262526

Epoch: 6| Step: 11
Training loss: 2.7173898220062256
Validation loss: 2.0368441099761636

Epoch: 6| Step: 12
Training loss: 2.422273635864258
Validation loss: 2.066835626479118

Epoch: 6| Step: 13
Training loss: 1.6531230211257935
Validation loss: 2.0290839236269713

Epoch: 189| Step: 0
Training loss: 2.1079092025756836
Validation loss: 2.0601850568607287

Epoch: 6| Step: 1
Training loss: 1.6026873588562012
Validation loss: 2.0023025248640325

Epoch: 6| Step: 2
Training loss: 1.7129281759262085
Validation loss: 2.0120533717575895

Epoch: 6| Step: 3
Training loss: 2.2604751586914062
Validation loss: 2.0385492258174445

Epoch: 6| Step: 4
Training loss: 2.2320737838745117
Validation loss: 2.0280296648702314

Epoch: 6| Step: 5
Training loss: 2.4949893951416016
Validation loss: 2.0490535856575094

Epoch: 6| Step: 6
Training loss: 1.5645352602005005
Validation loss: 2.0289776696953723

Epoch: 6| Step: 7
Training loss: 2.070488691329956
Validation loss: 2.0384518202914985

Epoch: 6| Step: 8
Training loss: 1.4224693775177002
Validation loss: 2.0219872741289038

Epoch: 6| Step: 9
Training loss: 2.3181471824645996
Validation loss: 2.0350844270439556

Epoch: 6| Step: 10
Training loss: 2.9307713508605957
Validation loss: 2.0223014854615733

Epoch: 6| Step: 11
Training loss: 1.7258515357971191
Validation loss: 2.0453620597880375

Epoch: 6| Step: 12
Training loss: 1.5443165302276611
Validation loss: 2.026483561403008

Epoch: 6| Step: 13
Training loss: 1.5236204862594604
Validation loss: 2.0386888134864067

Epoch: 190| Step: 0
Training loss: 2.040823221206665
Validation loss: 2.0390733339453257

Epoch: 6| Step: 1
Training loss: 1.7649054527282715
Validation loss: 2.040742740836195

Epoch: 6| Step: 2
Training loss: 1.5886003971099854
Validation loss: 2.0136334896087646

Epoch: 6| Step: 3
Training loss: 1.860792636871338
Validation loss: 2.0039508881107455

Epoch: 6| Step: 4
Training loss: 1.749192476272583
Validation loss: 2.028614540253916

Epoch: 6| Step: 5
Training loss: 2.5698561668395996
Validation loss: 2.0342076158010833

Epoch: 6| Step: 6
Training loss: 1.6316030025482178
Validation loss: 1.9950413601372832

Epoch: 6| Step: 7
Training loss: 1.6423593759536743
Validation loss: 2.0216511526415424

Epoch: 6| Step: 8
Training loss: 1.8636584281921387
Validation loss: 1.996963103612264

Epoch: 6| Step: 9
Training loss: 2.195411205291748
Validation loss: 2.01239618691065

Epoch: 6| Step: 10
Training loss: 2.012268304824829
Validation loss: 2.0287778403169368

Epoch: 6| Step: 11
Training loss: 1.9034295082092285
Validation loss: 2.0041861226481776

Epoch: 6| Step: 12
Training loss: 2.3024988174438477
Validation loss: 2.0450271329572125

Epoch: 6| Step: 13
Training loss: 2.7825582027435303
Validation loss: 2.0222605607842885

Epoch: 191| Step: 0
Training loss: 1.862465739250183
Validation loss: 2.0339478574773318

Epoch: 6| Step: 1
Training loss: 1.2412941455841064
Validation loss: 2.031879873685939

Epoch: 6| Step: 2
Training loss: 1.978110909461975
Validation loss: 1.9887533162229805

Epoch: 6| Step: 3
Training loss: 2.1530065536499023
Validation loss: 2.0359349250793457

Epoch: 6| Step: 4
Training loss: 1.3922507762908936
Validation loss: 1.991917307658862

Epoch: 6| Step: 5
Training loss: 2.5186400413513184
Validation loss: 2.0166616529546757

Epoch: 6| Step: 6
Training loss: 1.288099765777588
Validation loss: 1.993905613499303

Epoch: 6| Step: 7
Training loss: 2.8919224739074707
Validation loss: 2.0100076890760854

Epoch: 6| Step: 8
Training loss: 2.525921106338501
Validation loss: 2.038962353942215

Epoch: 6| Step: 9
Training loss: 2.2126317024230957
Validation loss: 2.0260511559824788

Epoch: 6| Step: 10
Training loss: 1.5886547565460205
Validation loss: 1.9986943865335116

Epoch: 6| Step: 11
Training loss: 1.3126885890960693
Validation loss: 2.037524063100097

Epoch: 6| Step: 12
Training loss: 2.051008701324463
Validation loss: 2.0254525869123396

Epoch: 6| Step: 13
Training loss: 3.0923540592193604
Validation loss: 2.0267321012353383

Epoch: 192| Step: 0
Training loss: 1.7822641134262085
Validation loss: 2.0192895320154007

Epoch: 6| Step: 1
Training loss: 1.8494170904159546
Validation loss: 2.0263381414515997

Epoch: 6| Step: 2
Training loss: 2.166930675506592
Validation loss: 2.0190619025179135

Epoch: 6| Step: 3
Training loss: 2.2998223304748535
Validation loss: 2.042847825634864

Epoch: 6| Step: 4
Training loss: 1.427015781402588
Validation loss: 2.0505076954441686

Epoch: 6| Step: 5
Training loss: 2.700108766555786
Validation loss: 2.0187906629295758

Epoch: 6| Step: 6
Training loss: 1.6122689247131348
Validation loss: 2.007092429745582

Epoch: 6| Step: 7
Training loss: 2.0322787761688232
Validation loss: 2.032278838978019

Epoch: 6| Step: 8
Training loss: 1.960331678390503
Validation loss: 2.049804796454727

Epoch: 6| Step: 9
Training loss: 2.8395605087280273
Validation loss: 2.046828548113505

Epoch: 6| Step: 10
Training loss: 1.6216458082199097
Validation loss: 2.061479604372414

Epoch: 6| Step: 11
Training loss: 1.6166636943817139
Validation loss: 2.0316953287329724

Epoch: 6| Step: 12
Training loss: 2.017359495162964
Validation loss: 2.021580837106192

Epoch: 6| Step: 13
Training loss: 1.78267240524292
Validation loss: 2.0288355709404073

Epoch: 193| Step: 0
Training loss: 2.458178997039795
Validation loss: 2.021229379920549

Epoch: 6| Step: 1
Training loss: 1.629209280014038
Validation loss: 2.017424319380073

Epoch: 6| Step: 2
Training loss: 1.4793038368225098
Validation loss: 2.008755467271292

Epoch: 6| Step: 3
Training loss: 1.7279739379882812
Validation loss: 2.0133402373201106

Epoch: 6| Step: 4
Training loss: 2.6943817138671875
Validation loss: 2.017538311660931

Epoch: 6| Step: 5
Training loss: 1.8112516403198242
Validation loss: 2.023329705320379

Epoch: 6| Step: 6
Training loss: 2.1550183296203613
Validation loss: 2.040304083977976

Epoch: 6| Step: 7
Training loss: 2.225224018096924
Validation loss: 2.0333258721136276

Epoch: 6| Step: 8
Training loss: 2.3949227333068848
Validation loss: 2.0229277085232478

Epoch: 6| Step: 9
Training loss: 1.829311490058899
Validation loss: 2.0247395346241612

Epoch: 6| Step: 10
Training loss: 1.5789732933044434
Validation loss: 2.0076433420181274

Epoch: 6| Step: 11
Training loss: 1.6805956363677979
Validation loss: 2.0368852974266134

Epoch: 6| Step: 12
Training loss: 2.138009548187256
Validation loss: 2.0443605389646304

Epoch: 6| Step: 13
Training loss: 1.8487372398376465
Validation loss: 2.018984627980058

Epoch: 194| Step: 0
Training loss: 2.050476551055908
Validation loss: 2.037689926803753

Epoch: 6| Step: 1
Training loss: 2.182565450668335
Validation loss: 2.040913616457293

Epoch: 6| Step: 2
Training loss: 1.6946626901626587
Validation loss: 2.034878489791706

Epoch: 6| Step: 3
Training loss: 2.224520683288574
Validation loss: 2.0305896933360765

Epoch: 6| Step: 4
Training loss: 1.7175648212432861
Validation loss: 2.005127993963098

Epoch: 6| Step: 5
Training loss: 1.6295669078826904
Validation loss: 2.0037466454249557

Epoch: 6| Step: 6
Training loss: 2.4872961044311523
Validation loss: 2.0051188674024356

Epoch: 6| Step: 7
Training loss: 1.885565161705017
Validation loss: 2.009768510377535

Epoch: 6| Step: 8
Training loss: 1.7268038988113403
Validation loss: 2.0204281063490015

Epoch: 6| Step: 9
Training loss: 1.8440179824829102
Validation loss: 2.027570148949982

Epoch: 6| Step: 10
Training loss: 1.5068042278289795
Validation loss: 2.0212628200489986

Epoch: 6| Step: 11
Training loss: 2.7017455101013184
Validation loss: 2.02133862433895

Epoch: 6| Step: 12
Training loss: 2.0765280723571777
Validation loss: 2.0414984867136967

Epoch: 6| Step: 13
Training loss: 1.5790047645568848
Validation loss: 2.0319008673391035

Epoch: 195| Step: 0
Training loss: 2.269362449645996
Validation loss: 2.0475858539663334

Epoch: 6| Step: 1
Training loss: 1.9209171533584595
Validation loss: 2.0325086898701166

Epoch: 6| Step: 2
Training loss: 2.073551654815674
Validation loss: 2.0145929116074757

Epoch: 6| Step: 3
Training loss: 2.1527976989746094
Validation loss: 2.039742756915349

Epoch: 6| Step: 4
Training loss: 1.820979118347168
Validation loss: 2.0384990784429733

Epoch: 6| Step: 5
Training loss: 2.5343527793884277
Validation loss: 2.012101347728442

Epoch: 6| Step: 6
Training loss: 1.5139350891113281
Validation loss: 2.0612691576762865

Epoch: 6| Step: 7
Training loss: 1.5552783012390137
Validation loss: 2.072668258861829

Epoch: 6| Step: 8
Training loss: 2.2971177101135254
Validation loss: 2.069691127346408

Epoch: 6| Step: 9
Training loss: 2.778928756713867
Validation loss: 2.0540747975790374

Epoch: 6| Step: 10
Training loss: 1.72589111328125
Validation loss: 2.085941095505991

Epoch: 6| Step: 11
Training loss: 1.5907411575317383
Validation loss: 2.0824357386558288

Epoch: 6| Step: 12
Training loss: 1.7327481508255005
Validation loss: 2.0663943598347325

Epoch: 6| Step: 13
Training loss: 1.9560173749923706
Validation loss: 2.0518259284316853

Epoch: 196| Step: 0
Training loss: 2.4050049781799316
Validation loss: 2.03599218655658

Epoch: 6| Step: 1
Training loss: 2.0315561294555664
Validation loss: 2.0502070816614295

Epoch: 6| Step: 2
Training loss: 1.451584815979004
Validation loss: 2.036544986950454

Epoch: 6| Step: 3
Training loss: 1.3929884433746338
Validation loss: 2.034561005971765

Epoch: 6| Step: 4
Training loss: 1.2556138038635254
Validation loss: 2.034714674436918

Epoch: 6| Step: 5
Training loss: 1.9266724586486816
Validation loss: 2.0034683878703783

Epoch: 6| Step: 6
Training loss: 2.6531636714935303
Validation loss: 2.039426585679413

Epoch: 6| Step: 7
Training loss: 1.9571938514709473
Validation loss: 2.0286520142709055

Epoch: 6| Step: 8
Training loss: 1.554938554763794
Validation loss: 2.0085303245052213

Epoch: 6| Step: 9
Training loss: 2.3271424770355225
Validation loss: 2.015420979069125

Epoch: 6| Step: 10
Training loss: 1.783419132232666
Validation loss: 1.9961515831690964

Epoch: 6| Step: 11
Training loss: 2.3724730014801025
Validation loss: 2.0097474949334257

Epoch: 6| Step: 12
Training loss: 2.8836259841918945
Validation loss: 2.0083954795714347

Epoch: 6| Step: 13
Training loss: 0.9267838001251221
Validation loss: 1.996876831977598

Epoch: 197| Step: 0
Training loss: 0.7925683259963989
Validation loss: 2.0223739275368313

Epoch: 6| Step: 1
Training loss: 1.5095146894454956
Validation loss: 2.025049368540446

Epoch: 6| Step: 2
Training loss: 1.6370837688446045
Validation loss: 2.0086590192651235

Epoch: 6| Step: 3
Training loss: 2.1024863719940186
Validation loss: 1.9952249321886288

Epoch: 6| Step: 4
Training loss: 2.7253177165985107
Validation loss: 2.0069728154008106

Epoch: 6| Step: 5
Training loss: 1.7224609851837158
Validation loss: 2.038794420098746

Epoch: 6| Step: 6
Training loss: 2.176506996154785
Validation loss: 2.045918749224755

Epoch: 6| Step: 7
Training loss: 2.1551201343536377
Validation loss: 2.0662417309258574

Epoch: 6| Step: 8
Training loss: 1.5264697074890137
Validation loss: 2.0561594578527633

Epoch: 6| Step: 9
Training loss: 2.1157078742980957
Validation loss: 2.025907511352211

Epoch: 6| Step: 10
Training loss: 2.597961902618408
Validation loss: 2.0156057867952573

Epoch: 6| Step: 11
Training loss: 2.527585029602051
Validation loss: 2.0393682141457834

Epoch: 6| Step: 12
Training loss: 1.9248584508895874
Validation loss: 2.057022561309158

Epoch: 6| Step: 13
Training loss: 1.8076300621032715
Validation loss: 2.060545700852589

Epoch: 198| Step: 0
Training loss: 2.2967922687530518
Validation loss: 2.042878020194269

Epoch: 6| Step: 1
Training loss: 2.116091728210449
Validation loss: 2.0598943015580535

Epoch: 6| Step: 2
Training loss: 1.6571738719940186
Validation loss: 2.054560543388449

Epoch: 6| Step: 3
Training loss: 1.641486406326294
Validation loss: 2.040224838000472

Epoch: 6| Step: 4
Training loss: 2.3359193801879883
Validation loss: 2.037812985399718

Epoch: 6| Step: 5
Training loss: 2.1476330757141113
Validation loss: 2.0288558108832246

Epoch: 6| Step: 6
Training loss: 1.2241805791854858
Validation loss: 2.0646155636797667

Epoch: 6| Step: 7
Training loss: 2.0314338207244873
Validation loss: 2.027019864769392

Epoch: 6| Step: 8
Training loss: 2.054612159729004
Validation loss: 2.030025529605086

Epoch: 6| Step: 9
Training loss: 1.9463236331939697
Validation loss: 2.039586841419179

Epoch: 6| Step: 10
Training loss: 2.103236198425293
Validation loss: 2.0304409278336393

Epoch: 6| Step: 11
Training loss: 1.5348286628723145
Validation loss: 2.039802187232561

Epoch: 6| Step: 12
Training loss: 2.16017746925354
Validation loss: 2.0429821527132423

Epoch: 6| Step: 13
Training loss: 1.7548471689224243
Validation loss: 2.0306665974278606

Epoch: 199| Step: 0
Training loss: 2.0494632720947266
Validation loss: 2.036552862454486

Epoch: 6| Step: 1
Training loss: 1.885801076889038
Validation loss: 2.0377992199313257

Epoch: 6| Step: 2
Training loss: 1.928694248199463
Validation loss: 2.03619876856445

Epoch: 6| Step: 3
Training loss: 0.8060249090194702
Validation loss: 2.0255931115919545

Epoch: 6| Step: 4
Training loss: 1.624624252319336
Validation loss: 2.0467959334773402

Epoch: 6| Step: 5
Training loss: 1.372706413269043
Validation loss: 2.023358811614334

Epoch: 6| Step: 6
Training loss: 2.097811698913574
Validation loss: 2.0318971526238228

Epoch: 6| Step: 7
Training loss: 2.461444854736328
Validation loss: 2.052740881519933

Epoch: 6| Step: 8
Training loss: 1.9676352739334106
Validation loss: 2.0181316714132986

Epoch: 6| Step: 9
Training loss: 2.660327196121216
Validation loss: 2.0185042247977307

Epoch: 6| Step: 10
Training loss: 2.5286173820495605
Validation loss: 2.01751317644632

Epoch: 6| Step: 11
Training loss: 1.7672919034957886
Validation loss: 2.0032859976573656

Epoch: 6| Step: 12
Training loss: 2.185643434524536
Validation loss: 2.038194678163016

Epoch: 6| Step: 13
Training loss: 1.6434845924377441
Validation loss: 2.031299526973437

Epoch: 200| Step: 0
Training loss: 1.7863514423370361
Validation loss: 2.0130359549676218

Epoch: 6| Step: 1
Training loss: 2.3174235820770264
Validation loss: 2.028621795356915

Epoch: 6| Step: 2
Training loss: 1.4027717113494873
Validation loss: 2.023036934996164

Epoch: 6| Step: 3
Training loss: 1.6658140420913696
Validation loss: 2.036558751137026

Epoch: 6| Step: 4
Training loss: 2.553687572479248
Validation loss: 2.0169403758100284

Epoch: 6| Step: 5
Training loss: 2.10372257232666
Validation loss: 2.0479684106765257

Epoch: 6| Step: 6
Training loss: 2.1939849853515625
Validation loss: 2.0331901657965874

Epoch: 6| Step: 7
Training loss: 1.7306832075119019
Validation loss: 2.0122143914622646

Epoch: 6| Step: 8
Training loss: 2.177335739135742
Validation loss: 2.0319167132018716

Epoch: 6| Step: 9
Training loss: 1.5645264387130737
Validation loss: 2.0203699629793883

Epoch: 6| Step: 10
Training loss: 1.7930978536605835
Validation loss: 2.0013289438780917

Epoch: 6| Step: 11
Training loss: 2.0779707431793213
Validation loss: 2.034200414534538

Epoch: 6| Step: 12
Training loss: 2.048213243484497
Validation loss: 2.0491810280789613

Epoch: 6| Step: 13
Training loss: 1.8536516427993774
Validation loss: 2.0223524814010947

Epoch: 201| Step: 0
Training loss: 2.058684825897217
Validation loss: 2.022760457890008

Epoch: 6| Step: 1
Training loss: 2.0094528198242188
Validation loss: 2.0199696607487176

Epoch: 6| Step: 2
Training loss: 1.3657938241958618
Validation loss: 2.029933573097311

Epoch: 6| Step: 3
Training loss: 1.5353190898895264
Validation loss: 2.037860631942749

Epoch: 6| Step: 4
Training loss: 1.8485314846038818
Validation loss: 2.0342967664041827

Epoch: 6| Step: 5
Training loss: 2.1159000396728516
Validation loss: 2.023901921446605

Epoch: 6| Step: 6
Training loss: 1.972404956817627
Validation loss: 2.0112679812215988

Epoch: 6| Step: 7
Training loss: 2.0323996543884277
Validation loss: 2.051103030481646

Epoch: 6| Step: 8
Training loss: 1.8441168069839478
Validation loss: 2.053245921288767

Epoch: 6| Step: 9
Training loss: 1.8241066932678223
Validation loss: 2.0326498105961788

Epoch: 6| Step: 10
Training loss: 2.7143073081970215
Validation loss: 2.039106807401103

Epoch: 6| Step: 11
Training loss: 2.002264976501465
Validation loss: 2.043195374550358

Epoch: 6| Step: 12
Training loss: 1.9689977169036865
Validation loss: 1.9923054454147175

Epoch: 6| Step: 13
Training loss: 1.6958489418029785
Validation loss: 2.02166719846828

Epoch: 202| Step: 0
Training loss: 1.415635585784912
Validation loss: 2.052100027761152

Epoch: 6| Step: 1
Training loss: 2.323268413543701
Validation loss: 2.0573520122035855

Epoch: 6| Step: 2
Training loss: 2.358029365539551
Validation loss: 2.0327905070397163

Epoch: 6| Step: 3
Training loss: 2.0644993782043457
Validation loss: 2.03738373069353

Epoch: 6| Step: 4
Training loss: 2.389798641204834
Validation loss: 2.05001099007104

Epoch: 6| Step: 5
Training loss: 1.5572402477264404
Validation loss: 2.0108872011143673

Epoch: 6| Step: 6
Training loss: 1.6757795810699463
Validation loss: 2.015049840814324

Epoch: 6| Step: 7
Training loss: 1.5960092544555664
Validation loss: 2.0358501685562955

Epoch: 6| Step: 8
Training loss: 1.8379952907562256
Validation loss: 2.024414849537675

Epoch: 6| Step: 9
Training loss: 1.8563816547393799
Validation loss: 2.014203045957832

Epoch: 6| Step: 10
Training loss: 2.5856475830078125
Validation loss: 2.031068160969724

Epoch: 6| Step: 11
Training loss: 1.373205304145813
Validation loss: 2.012940242726316

Epoch: 6| Step: 12
Training loss: 2.310760736465454
Validation loss: 2.056249782603274

Epoch: 6| Step: 13
Training loss: 1.6727033853530884
Validation loss: 2.052664581165519

Epoch: 203| Step: 0
Training loss: 1.5073802471160889
Validation loss: 2.0330964839586647

Epoch: 6| Step: 1
Training loss: 1.775550365447998
Validation loss: 2.0292230370224162

Epoch: 6| Step: 2
Training loss: 1.9306092262268066
Validation loss: 2.0398340250856135

Epoch: 6| Step: 3
Training loss: 1.935927152633667
Validation loss: 2.027545611063639

Epoch: 6| Step: 4
Training loss: 1.6181989908218384
Validation loss: 2.0070064580568703

Epoch: 6| Step: 5
Training loss: 2.2951600551605225
Validation loss: 2.061601459339101

Epoch: 6| Step: 6
Training loss: 1.7563666105270386
Validation loss: 2.0300436276261524

Epoch: 6| Step: 7
Training loss: 1.695113182067871
Validation loss: 2.0343784260493454

Epoch: 6| Step: 8
Training loss: 2.451916217803955
Validation loss: 2.0341108229852494

Epoch: 6| Step: 9
Training loss: 2.405677556991577
Validation loss: 2.0304637442352953

Epoch: 6| Step: 10
Training loss: 1.6548101902008057
Validation loss: 2.046331044166319

Epoch: 6| Step: 11
Training loss: 1.8901443481445312
Validation loss: 2.018112687654393

Epoch: 6| Step: 12
Training loss: 2.214104175567627
Validation loss: 2.0454328213968584

Epoch: 6| Step: 13
Training loss: 2.3292665481567383
Validation loss: 2.0193589118219193

Epoch: 204| Step: 0
Training loss: 2.146745443344116
Validation loss: 2.0592488370915896

Epoch: 6| Step: 1
Training loss: 2.4067373275756836
Validation loss: 2.0573849780585176

Epoch: 6| Step: 2
Training loss: 1.6904144287109375
Validation loss: 2.0205360202379126

Epoch: 6| Step: 3
Training loss: 1.8563265800476074
Validation loss: 2.03157703979041

Epoch: 6| Step: 4
Training loss: 2.084855079650879
Validation loss: 1.9967683220422396

Epoch: 6| Step: 5
Training loss: 1.5984418392181396
Validation loss: 2.0163409043383855

Epoch: 6| Step: 6
Training loss: 2.172276735305786
Validation loss: 2.0226556716426725

Epoch: 6| Step: 7
Training loss: 1.644944429397583
Validation loss: 2.0156766676133677

Epoch: 6| Step: 8
Training loss: 2.1510019302368164
Validation loss: 2.059136954686975

Epoch: 6| Step: 9
Training loss: 1.7449183464050293
Validation loss: 2.0048333662812428

Epoch: 6| Step: 10
Training loss: 1.956486463546753
Validation loss: 2.0275260517674107

Epoch: 6| Step: 11
Training loss: 1.8613935708999634
Validation loss: 2.031482619623984

Epoch: 6| Step: 12
Training loss: 2.127154588699341
Validation loss: 2.0232914083747455

Epoch: 6| Step: 13
Training loss: 1.2608762979507446
Validation loss: 2.0485776291098645

Epoch: 205| Step: 0
Training loss: 1.8615527153015137
Validation loss: 2.0190951644733386

Epoch: 6| Step: 1
Training loss: 1.525444746017456
Validation loss: 2.036208955190515

Epoch: 6| Step: 2
Training loss: 2.3380517959594727
Validation loss: 2.0442868125054146

Epoch: 6| Step: 3
Training loss: 2.3435959815979004
Validation loss: 2.0238352949901293

Epoch: 6| Step: 4
Training loss: 2.060988187789917
Validation loss: 2.007147253200572

Epoch: 6| Step: 5
Training loss: 1.7707061767578125
Validation loss: 2.0230352391478834

Epoch: 6| Step: 6
Training loss: 1.9846450090408325
Validation loss: 2.0486911342990015

Epoch: 6| Step: 7
Training loss: 2.181105136871338
Validation loss: 2.0206983704720773

Epoch: 6| Step: 8
Training loss: 1.5627539157867432
Validation loss: 2.035490825612058

Epoch: 6| Step: 9
Training loss: 0.7527558207511902
Validation loss: 2.0193581401660876

Epoch: 6| Step: 10
Training loss: 1.944594383239746
Validation loss: 2.025350546324125

Epoch: 6| Step: 11
Training loss: 2.067216157913208
Validation loss: 2.0283442210125666

Epoch: 6| Step: 12
Training loss: 2.236492872238159
Validation loss: 2.0110181916144585

Epoch: 6| Step: 13
Training loss: 2.8120317459106445
Validation loss: 2.0231412995246147

Epoch: 206| Step: 0
Training loss: 1.8359043598175049
Validation loss: 2.040035815649135

Epoch: 6| Step: 1
Training loss: 2.1971402168273926
Validation loss: 2.064205728551393

Epoch: 6| Step: 2
Training loss: 2.5692062377929688
Validation loss: 2.0325631236517303

Epoch: 6| Step: 3
Training loss: 1.399571418762207
Validation loss: 2.0140820908290085

Epoch: 6| Step: 4
Training loss: 2.3713202476501465
Validation loss: 2.026688357835175

Epoch: 6| Step: 5
Training loss: 2.3936767578125
Validation loss: 2.0343959741694952

Epoch: 6| Step: 6
Training loss: 1.8917765617370605
Validation loss: 2.026852359053909

Epoch: 6| Step: 7
Training loss: 1.584450364112854
Validation loss: 2.020178259059947

Epoch: 6| Step: 8
Training loss: 1.7824110984802246
Validation loss: 2.0297725444198935

Epoch: 6| Step: 9
Training loss: 1.7687535285949707
Validation loss: 1.9905574962656984

Epoch: 6| Step: 10
Training loss: 1.9043115377426147
Validation loss: 2.0333728585191952

Epoch: 6| Step: 11
Training loss: 2.300260543823242
Validation loss: 2.044787750449232

Epoch: 6| Step: 12
Training loss: 1.4678876399993896
Validation loss: 2.029187176817207

Epoch: 6| Step: 13
Training loss: 1.485805630683899
Validation loss: 2.036099141643893

Epoch: 207| Step: 0
Training loss: 2.203677177429199
Validation loss: 2.043557079889441

Epoch: 6| Step: 1
Training loss: 1.1718034744262695
Validation loss: 2.011762776682454

Epoch: 6| Step: 2
Training loss: 2.0812065601348877
Validation loss: 2.020552562129113

Epoch: 6| Step: 3
Training loss: 2.1903398036956787
Validation loss: 2.027725524799798

Epoch: 6| Step: 4
Training loss: 1.4550687074661255
Validation loss: 2.0172987855890745

Epoch: 6| Step: 5
Training loss: 1.5205729007720947
Validation loss: 2.0571778410224506

Epoch: 6| Step: 6
Training loss: 1.4555935859680176
Validation loss: 2.042906056168259

Epoch: 6| Step: 7
Training loss: 2.3072710037231445
Validation loss: 2.018235300176887

Epoch: 6| Step: 8
Training loss: 2.285935401916504
Validation loss: 2.0229073826984694

Epoch: 6| Step: 9
Training loss: 1.8845876455307007
Validation loss: 2.0124232756194247

Epoch: 6| Step: 10
Training loss: 1.3585095405578613
Validation loss: 2.041928561784888

Epoch: 6| Step: 11
Training loss: 2.4209747314453125
Validation loss: 2.026472092956625

Epoch: 6| Step: 12
Training loss: 2.480820655822754
Validation loss: 2.031135510372859

Epoch: 6| Step: 13
Training loss: 2.3671038150787354
Validation loss: 2.027032959845758

Epoch: 208| Step: 0
Training loss: 2.583881378173828
Validation loss: 2.0294442176818848

Epoch: 6| Step: 1
Training loss: 1.148651361465454
Validation loss: 2.0487749627841416

Epoch: 6| Step: 2
Training loss: 1.2417961359024048
Validation loss: 2.0408773704241683

Epoch: 6| Step: 3
Training loss: 2.780284881591797
Validation loss: 1.9915579031872492

Epoch: 6| Step: 4
Training loss: 2.0684280395507812
Validation loss: 2.0349452687847998

Epoch: 6| Step: 5
Training loss: 2.168569564819336
Validation loss: 2.055947014080581

Epoch: 6| Step: 6
Training loss: 1.152759313583374
Validation loss: 2.0327901686391523

Epoch: 6| Step: 7
Training loss: 1.1803040504455566
Validation loss: 2.0446247221321188

Epoch: 6| Step: 8
Training loss: 2.249049186706543
Validation loss: 2.0391649084706462

Epoch: 6| Step: 9
Training loss: 2.492219924926758
Validation loss: 2.0293285769800984

Epoch: 6| Step: 10
Training loss: 2.0455799102783203
Validation loss: 2.025217863821214

Epoch: 6| Step: 11
Training loss: 2.0150346755981445
Validation loss: 2.0531354053046114

Epoch: 6| Step: 12
Training loss: 2.4702467918395996
Validation loss: 2.045236929770439

Epoch: 6| Step: 13
Training loss: 1.5090186595916748
Validation loss: 2.036283478941969

Epoch: 209| Step: 0
Training loss: 2.1795499324798584
Validation loss: 2.01299637363803

Epoch: 6| Step: 1
Training loss: 2.540780782699585
Validation loss: 2.0560447285252232

Epoch: 6| Step: 2
Training loss: 1.7998170852661133
Validation loss: 2.030947874951106

Epoch: 6| Step: 3
Training loss: 1.8063819408416748
Validation loss: 2.0372010674527896

Epoch: 6| Step: 4
Training loss: 2.1289830207824707
Validation loss: 2.0341142275000132

Epoch: 6| Step: 5
Training loss: 1.5863064527511597
Validation loss: 1.9991576363963466

Epoch: 6| Step: 6
Training loss: 1.8899867534637451
Validation loss: 2.0399640478113645

Epoch: 6| Step: 7
Training loss: 1.61387038230896
Validation loss: 2.0326841954262025

Epoch: 6| Step: 8
Training loss: 1.685689091682434
Validation loss: 2.002506794468049

Epoch: 6| Step: 9
Training loss: 2.3730900287628174
Validation loss: 2.0224568395204443

Epoch: 6| Step: 10
Training loss: 1.5047380924224854
Validation loss: 2.0405560962615477

Epoch: 6| Step: 11
Training loss: 1.8495923280715942
Validation loss: 2.038671374320984

Epoch: 6| Step: 12
Training loss: 2.140054225921631
Validation loss: 2.035160349261376

Epoch: 6| Step: 13
Training loss: 1.617289423942566
Validation loss: 2.0107501527314544

Epoch: 210| Step: 0
Training loss: 1.9445799589157104
Validation loss: 2.0494125581556752

Epoch: 6| Step: 1
Training loss: 1.9698865413665771
Validation loss: 2.0453029524895454

Epoch: 6| Step: 2
Training loss: 1.348885416984558
Validation loss: 2.025834616794381

Epoch: 6| Step: 3
Training loss: 2.0686256885528564
Validation loss: 2.014788609679027

Epoch: 6| Step: 4
Training loss: 1.9622923135757446
Validation loss: 2.0277961505356656

Epoch: 6| Step: 5
Training loss: 1.9741979837417603
Validation loss: 2.0178967496400237

Epoch: 6| Step: 6
Training loss: 1.8261821269989014
Validation loss: 2.0025564137325493

Epoch: 6| Step: 7
Training loss: 1.500568151473999
Validation loss: 2.033717759193913

Epoch: 6| Step: 8
Training loss: 1.9002383947372437
Validation loss: 2.015457396866173

Epoch: 6| Step: 9
Training loss: 2.126126766204834
Validation loss: 2.0392212893373225

Epoch: 6| Step: 10
Training loss: 1.880866289138794
Validation loss: 2.050024429957072

Epoch: 6| Step: 11
Training loss: 2.5411603450775146
Validation loss: 2.0231788337871595

Epoch: 6| Step: 12
Training loss: 1.987134575843811
Validation loss: 2.037270945887412

Epoch: 6| Step: 13
Training loss: 2.1044888496398926
Validation loss: 2.0458794793775006

Epoch: 211| Step: 0
Training loss: 1.9951751232147217
Validation loss: 2.0247042127834853

Epoch: 6| Step: 1
Training loss: 2.347954750061035
Validation loss: 2.0331920039269233

Epoch: 6| Step: 2
Training loss: 1.4134901762008667
Validation loss: 2.0340641467801985

Epoch: 6| Step: 3
Training loss: 1.9213018417358398
Validation loss: 2.0331090650250836

Epoch: 6| Step: 4
Training loss: 1.9502317905426025
Validation loss: 2.0497589136964534

Epoch: 6| Step: 5
Training loss: 1.9291776418685913
Validation loss: 2.026611989544284

Epoch: 6| Step: 6
Training loss: 1.943396806716919
Validation loss: 2.0290838428722915

Epoch: 6| Step: 7
Training loss: 1.6249823570251465
Validation loss: 2.0587156895668275

Epoch: 6| Step: 8
Training loss: 2.449739694595337
Validation loss: 2.024479862182371

Epoch: 6| Step: 9
Training loss: 1.4457435607910156
Validation loss: 1.9951153544969455

Epoch: 6| Step: 10
Training loss: 2.4533236026763916
Validation loss: 2.027052625533073

Epoch: 6| Step: 11
Training loss: 1.6856944561004639
Validation loss: 2.058214492695306

Epoch: 6| Step: 12
Training loss: 1.6061615943908691
Validation loss: 2.0479645511155486

Epoch: 6| Step: 13
Training loss: 2.0291061401367188
Validation loss: 2.054397985499392

Epoch: 212| Step: 0
Training loss: 2.575300455093384
Validation loss: 2.0736289562717563

Epoch: 6| Step: 1
Training loss: 2.1341583728790283
Validation loss: 2.01051026903173

Epoch: 6| Step: 2
Training loss: 2.2227723598480225
Validation loss: 2.047692487316747

Epoch: 6| Step: 3
Training loss: 1.5775984525680542
Validation loss: 2.056724102266373

Epoch: 6| Step: 4
Training loss: 1.4865729808807373
Validation loss: 2.0811110696484967

Epoch: 6| Step: 5
Training loss: 2.1261935234069824
Validation loss: 2.0392872671927176

Epoch: 6| Step: 6
Training loss: 2.1490345001220703
Validation loss: 2.063196607815322

Epoch: 6| Step: 7
Training loss: 2.1381030082702637
Validation loss: 2.078690395560316

Epoch: 6| Step: 8
Training loss: 1.9176225662231445
Validation loss: 2.0742053344685543

Epoch: 6| Step: 9
Training loss: 1.6564284563064575
Validation loss: 2.0714416811543126

Epoch: 6| Step: 10
Training loss: 1.7060623168945312
Validation loss: 2.0636265700863254

Epoch: 6| Step: 11
Training loss: 1.7227373123168945
Validation loss: 2.069846127622871

Epoch: 6| Step: 12
Training loss: 1.9332538843154907
Validation loss: 2.0727752075400403

Epoch: 6| Step: 13
Training loss: 2.3196449279785156
Validation loss: 2.0576763768349924

Epoch: 213| Step: 0
Training loss: 2.631373643875122
Validation loss: 2.0437903711872716

Epoch: 6| Step: 1
Training loss: 2.0403249263763428
Validation loss: 2.011186686895227

Epoch: 6| Step: 2
Training loss: 2.1246094703674316
Validation loss: 2.0219557669854935

Epoch: 6| Step: 3
Training loss: 1.942929744720459
Validation loss: 2.040577524451799

Epoch: 6| Step: 4
Training loss: 1.6716253757476807
Validation loss: 2.018458902194936

Epoch: 6| Step: 5
Training loss: 2.453508138656616
Validation loss: 2.0500896989658313

Epoch: 6| Step: 6
Training loss: 2.3891162872314453
Validation loss: 2.0259550092040852

Epoch: 6| Step: 7
Training loss: 1.635170340538025
Validation loss: 2.018784176918768

Epoch: 6| Step: 8
Training loss: 1.2977147102355957
Validation loss: 2.0169222303616103

Epoch: 6| Step: 9
Training loss: 1.8012349605560303
Validation loss: 2.0107728627420243

Epoch: 6| Step: 10
Training loss: 2.204254388809204
Validation loss: 2.018816976137059

Epoch: 6| Step: 11
Training loss: 1.6626179218292236
Validation loss: 2.0058897003050773

Epoch: 6| Step: 12
Training loss: 1.7688541412353516
Validation loss: 2.008325194799772

Epoch: 6| Step: 13
Training loss: 1.2820309400558472
Validation loss: 2.0209508749746505

Epoch: 214| Step: 0
Training loss: 1.9728310108184814
Validation loss: 2.0098502456500964

Epoch: 6| Step: 1
Training loss: 1.7763559818267822
Validation loss: 2.027665220281129

Epoch: 6| Step: 2
Training loss: 1.9974589347839355
Validation loss: 2.0274796408991658

Epoch: 6| Step: 3
Training loss: 2.538853645324707
Validation loss: 2.009696054202254

Epoch: 6| Step: 4
Training loss: 2.4107987880706787
Validation loss: 2.0586982183558966

Epoch: 6| Step: 5
Training loss: 1.927443504333496
Validation loss: 2.041387482356

Epoch: 6| Step: 6
Training loss: 1.5702265501022339
Validation loss: 2.0205842192455004

Epoch: 6| Step: 7
Training loss: 1.9133201837539673
Validation loss: 2.01440179476174

Epoch: 6| Step: 8
Training loss: 1.6872845888137817
Validation loss: 2.0470700110158613

Epoch: 6| Step: 9
Training loss: 1.4486865997314453
Validation loss: 2.0645697475761495

Epoch: 6| Step: 10
Training loss: 2.0785226821899414
Validation loss: 2.0358438966094807

Epoch: 6| Step: 11
Training loss: 2.369138717651367
Validation loss: 2.0457804446579306

Epoch: 6| Step: 12
Training loss: 1.268061876296997
Validation loss: 2.035129185645811

Epoch: 6| Step: 13
Training loss: 2.02278995513916
Validation loss: 2.0690895562530844

Epoch: 215| Step: 0
Training loss: 2.445889472961426
Validation loss: 2.0534557347656577

Epoch: 6| Step: 1
Training loss: 2.033621072769165
Validation loss: 2.0752431026069065

Epoch: 6| Step: 2
Training loss: 1.8768846988677979
Validation loss: 2.0509885972545994

Epoch: 6| Step: 3
Training loss: 2.2002596855163574
Validation loss: 2.0613530323069584

Epoch: 6| Step: 4
Training loss: 2.0119807720184326
Validation loss: 2.0407413487793296

Epoch: 6| Step: 5
Training loss: 1.970308780670166
Validation loss: 2.0327197826036842

Epoch: 6| Step: 6
Training loss: 1.9270775318145752
Validation loss: 2.03304470739057

Epoch: 6| Step: 7
Training loss: 1.2307629585266113
Validation loss: 2.056040071672009

Epoch: 6| Step: 8
Training loss: 2.0902843475341797
Validation loss: 2.0774792317421205

Epoch: 6| Step: 9
Training loss: 1.7461190223693848
Validation loss: 2.0398549469568397

Epoch: 6| Step: 10
Training loss: 1.3916385173797607
Validation loss: 2.0422218948282223

Epoch: 6| Step: 11
Training loss: 1.7570233345031738
Validation loss: 2.0690539242118917

Epoch: 6| Step: 12
Training loss: 2.284440755844116
Validation loss: 2.0568737714521346

Epoch: 6| Step: 13
Training loss: 2.17551589012146
Validation loss: 2.0183483221197642

Epoch: 216| Step: 0
Training loss: 1.6483173370361328
Validation loss: 2.0077086007723244

Epoch: 6| Step: 1
Training loss: 2.1125736236572266
Validation loss: 2.0011818639693724

Epoch: 6| Step: 2
Training loss: 1.8465944528579712
Validation loss: 2.03455566206286

Epoch: 6| Step: 3
Training loss: 2.072274923324585
Validation loss: 2.0141931451776975

Epoch: 6| Step: 4
Training loss: 1.9795994758605957
Validation loss: 1.9953654889137513

Epoch: 6| Step: 5
Training loss: 1.8595372438430786
Validation loss: 2.0380797668169905

Epoch: 6| Step: 6
Training loss: 1.2837234735488892
Validation loss: 2.039245237586319

Epoch: 6| Step: 7
Training loss: 1.722367286682129
Validation loss: 2.036555560686255

Epoch: 6| Step: 8
Training loss: 1.6454203128814697
Validation loss: 2.042616923650106

Epoch: 6| Step: 9
Training loss: 2.310652494430542
Validation loss: 1.9731719070865261

Epoch: 6| Step: 10
Training loss: 2.4885196685791016
Validation loss: 2.0130607825453564

Epoch: 6| Step: 11
Training loss: 1.50738525390625
Validation loss: 2.015953799729706

Epoch: 6| Step: 12
Training loss: 2.314913749694824
Validation loss: 2.027344890820083

Epoch: 6| Step: 13
Training loss: 2.271817445755005
Validation loss: 2.0509309602040116

Epoch: 217| Step: 0
Training loss: 1.5087023973464966
Validation loss: 2.021303394789337

Epoch: 6| Step: 1
Training loss: 1.3777034282684326
Validation loss: 2.0404545799378426

Epoch: 6| Step: 2
Training loss: 2.000352382659912
Validation loss: 2.0208265576311337

Epoch: 6| Step: 3
Training loss: 2.2132248878479004
Validation loss: 2.034679453860047

Epoch: 6| Step: 4
Training loss: 2.1298863887786865
Validation loss: 2.0474124698228735

Epoch: 6| Step: 5
Training loss: 1.6920846700668335
Validation loss: 2.0497441868628226

Epoch: 6| Step: 6
Training loss: 2.6115682125091553
Validation loss: 2.0334014251667965

Epoch: 6| Step: 7
Training loss: 2.245290994644165
Validation loss: 2.0517122809604933

Epoch: 6| Step: 8
Training loss: 2.00722599029541
Validation loss: 2.034844675371724

Epoch: 6| Step: 9
Training loss: 2.0614185333251953
Validation loss: 2.058995780124459

Epoch: 6| Step: 10
Training loss: 1.4699043035507202
Validation loss: 2.0607606377652896

Epoch: 6| Step: 11
Training loss: 2.233189582824707
Validation loss: 2.0403080550573205

Epoch: 6| Step: 12
Training loss: 1.2649753093719482
Validation loss: 2.0340936645384757

Epoch: 6| Step: 13
Training loss: 2.1234865188598633
Validation loss: 2.0371661916855843

Epoch: 218| Step: 0
Training loss: 2.007195234298706
Validation loss: 2.022545237695017

Epoch: 6| Step: 1
Training loss: 1.3420689105987549
Validation loss: 2.039466850219234

Epoch: 6| Step: 2
Training loss: 1.6572966575622559
Validation loss: 2.045234464829968

Epoch: 6| Step: 3
Training loss: 1.3109991550445557
Validation loss: 2.026455730520269

Epoch: 6| Step: 4
Training loss: 2.0628890991210938
Validation loss: 1.999247412527761

Epoch: 6| Step: 5
Training loss: 1.7064502239227295
Validation loss: 2.0355513916220715

Epoch: 6| Step: 6
Training loss: 2.001681327819824
Validation loss: 2.0524465448112896

Epoch: 6| Step: 7
Training loss: 2.2955129146575928
Validation loss: 2.0717240277157036

Epoch: 6| Step: 8
Training loss: 2.321354627609253
Validation loss: 2.0313628553062357

Epoch: 6| Step: 9
Training loss: 1.8260929584503174
Validation loss: 2.0461584060422835

Epoch: 6| Step: 10
Training loss: 1.9623346328735352
Validation loss: 2.041940612177695

Epoch: 6| Step: 11
Training loss: 1.494889497756958
Validation loss: 2.0259323837936565

Epoch: 6| Step: 12
Training loss: 2.93721604347229
Validation loss: 2.0517460069348736

Epoch: 6| Step: 13
Training loss: 2.034062385559082
Validation loss: 2.018522451000829

Epoch: 219| Step: 0
Training loss: 2.0769190788269043
Validation loss: 2.049876505328763

Epoch: 6| Step: 1
Training loss: 1.9741506576538086
Validation loss: 2.027665912464101

Epoch: 6| Step: 2
Training loss: 2.470026969909668
Validation loss: 2.027037492362402

Epoch: 6| Step: 3
Training loss: 1.1632142066955566
Validation loss: 2.039690932919902

Epoch: 6| Step: 4
Training loss: 1.894904613494873
Validation loss: 2.037396578378575

Epoch: 6| Step: 5
Training loss: 2.839298725128174
Validation loss: 2.0265472409545735

Epoch: 6| Step: 6
Training loss: 2.1018564701080322
Validation loss: 2.0655822369360153

Epoch: 6| Step: 7
Training loss: 2.1717097759246826
Validation loss: 2.031976745974633

Epoch: 6| Step: 8
Training loss: 2.4582085609436035
Validation loss: 2.0585660908811834

Epoch: 6| Step: 9
Training loss: 1.5952130556106567
Validation loss: 2.073906167860954

Epoch: 6| Step: 10
Training loss: 1.6256784200668335
Validation loss: 2.0558691076053086

Epoch: 6| Step: 11
Training loss: 1.3066935539245605
Validation loss: 2.0343720784751316

Epoch: 6| Step: 12
Training loss: 1.5222318172454834
Validation loss: 2.0224107849982476

Epoch: 6| Step: 13
Training loss: 1.022430658340454
Validation loss: 2.042885131733392

Epoch: 220| Step: 0
Training loss: 2.1044559478759766
Validation loss: 2.037650787702171

Epoch: 6| Step: 1
Training loss: 0.8516007661819458
Validation loss: 2.0176369964435534

Epoch: 6| Step: 2
Training loss: 1.5520787239074707
Validation loss: 2.048521272597774

Epoch: 6| Step: 3
Training loss: 2.1442642211914062
Validation loss: 2.0233447474818074

Epoch: 6| Step: 4
Training loss: 1.4940714836120605
Validation loss: 2.0152322425637195

Epoch: 6| Step: 5
Training loss: 2.0461134910583496
Validation loss: 2.0264587222888903

Epoch: 6| Step: 6
Training loss: 1.2262715101242065
Validation loss: 2.054767124114498

Epoch: 6| Step: 7
Training loss: 2.155102491378784
Validation loss: 2.0513285231846634

Epoch: 6| Step: 8
Training loss: 1.6526672840118408
Validation loss: 2.0479433946712042

Epoch: 6| Step: 9
Training loss: 1.9478018283843994
Validation loss: 2.050303882168185

Epoch: 6| Step: 10
Training loss: 1.9142773151397705
Validation loss: 2.0710747267610286

Epoch: 6| Step: 11
Training loss: 2.4212121963500977
Validation loss: 2.0681863766844555

Epoch: 6| Step: 12
Training loss: 2.7976784706115723
Validation loss: 2.0435352017802577

Epoch: 6| Step: 13
Training loss: 2.86904239654541
Validation loss: 2.0275778949901624

Epoch: 221| Step: 0
Training loss: 1.379459261894226
Validation loss: 2.0487962768923853

Epoch: 6| Step: 1
Training loss: 1.8952018022537231
Validation loss: 2.0530815150148127

Epoch: 6| Step: 2
Training loss: 2.3706419467926025
Validation loss: 2.0206476590966664

Epoch: 6| Step: 3
Training loss: 2.2263104915618896
Validation loss: 1.9960333660084715

Epoch: 6| Step: 4
Training loss: 1.4684875011444092
Validation loss: 2.0468105334107594

Epoch: 6| Step: 5
Training loss: 1.7940000295639038
Validation loss: 2.0690948963165283

Epoch: 6| Step: 6
Training loss: 2.1977086067199707
Validation loss: 2.0654998338350685

Epoch: 6| Step: 7
Training loss: 2.28253436088562
Validation loss: 2.048590565240511

Epoch: 6| Step: 8
Training loss: 1.9371482133865356
Validation loss: 2.0447139265716716

Epoch: 6| Step: 9
Training loss: 1.5424329042434692
Validation loss: 2.028155780607654

Epoch: 6| Step: 10
Training loss: 1.3536497354507446
Validation loss: 2.026850287632276

Epoch: 6| Step: 11
Training loss: 2.1087253093719482
Validation loss: 2.012062099672133

Epoch: 6| Step: 12
Training loss: 2.2724056243896484
Validation loss: 2.0410122781671505

Epoch: 6| Step: 13
Training loss: 2.0388615131378174
Validation loss: 2.0464791290221678

Epoch: 222| Step: 0
Training loss: 1.3258390426635742
Validation loss: 2.0628870212903587

Epoch: 6| Step: 1
Training loss: 1.6782374382019043
Validation loss: 2.0365578500173425

Epoch: 6| Step: 2
Training loss: 2.0169057846069336
Validation loss: 2.0228497071932723

Epoch: 6| Step: 3
Training loss: 1.5676803588867188
Validation loss: 2.0525693637068554

Epoch: 6| Step: 4
Training loss: 2.0322625637054443
Validation loss: 2.0371708126478296

Epoch: 6| Step: 5
Training loss: 2.0975828170776367
Validation loss: 2.0018882546373593

Epoch: 6| Step: 6
Training loss: 2.487640142440796
Validation loss: 2.029786143251645

Epoch: 6| Step: 7
Training loss: 2.3846569061279297
Validation loss: 2.0146271157008346

Epoch: 6| Step: 8
Training loss: 2.252629041671753
Validation loss: 2.0212771033727996

Epoch: 6| Step: 9
Training loss: 1.9062855243682861
Validation loss: 2.0423175801513014

Epoch: 6| Step: 10
Training loss: 1.9786922931671143
Validation loss: 2.0339884552904355

Epoch: 6| Step: 11
Training loss: 1.5781264305114746
Validation loss: 2.036488445856238

Epoch: 6| Step: 12
Training loss: 1.2031164169311523
Validation loss: 2.034273224492227

Epoch: 6| Step: 13
Training loss: 2.37565016746521
Validation loss: 2.043289348643313

Epoch: 223| Step: 0
Training loss: 2.573831796646118
Validation loss: 2.0774686656972414

Epoch: 6| Step: 1
Training loss: 1.528529167175293
Validation loss: 2.037315087933694

Epoch: 6| Step: 2
Training loss: 2.687086582183838
Validation loss: 2.0551699387129916

Epoch: 6| Step: 3
Training loss: 1.741635799407959
Validation loss: 2.0462645176918275

Epoch: 6| Step: 4
Training loss: 1.4711370468139648
Validation loss: 2.0244686501000517

Epoch: 6| Step: 5
Training loss: 2.2748770713806152
Validation loss: 2.0467426969159033

Epoch: 6| Step: 6
Training loss: 1.9561107158660889
Validation loss: 2.046666717016569

Epoch: 6| Step: 7
Training loss: 1.7150899171829224
Validation loss: 2.0752783052382933

Epoch: 6| Step: 8
Training loss: 1.3632943630218506
Validation loss: 2.052636161927254

Epoch: 6| Step: 9
Training loss: 2.010420322418213
Validation loss: 2.0301692562718547

Epoch: 6| Step: 10
Training loss: 1.8574912548065186
Validation loss: 2.053092192578059

Epoch: 6| Step: 11
Training loss: 2.371910572052002
Validation loss: 2.0412499930268977

Epoch: 6| Step: 12
Training loss: 1.457366943359375
Validation loss: 2.0218856642323155

Epoch: 6| Step: 13
Training loss: 1.5836542844772339
Validation loss: 2.010258205475346

Epoch: 224| Step: 0
Training loss: 2.2932674884796143
Validation loss: 2.0348962199303413

Epoch: 6| Step: 1
Training loss: 2.3947479724884033
Validation loss: 2.0749250124859553

Epoch: 6| Step: 2
Training loss: 2.0676651000976562
Validation loss: 2.0263240901372765

Epoch: 6| Step: 3
Training loss: 1.6600401401519775
Validation loss: 2.027764530592067

Epoch: 6| Step: 4
Training loss: 2.022960662841797
Validation loss: 2.0354820400156

Epoch: 6| Step: 5
Training loss: 1.594681739807129
Validation loss: 2.023836358900993

Epoch: 6| Step: 6
Training loss: 2.227543354034424
Validation loss: 2.0578074711625294

Epoch: 6| Step: 7
Training loss: 1.6526902914047241
Validation loss: 2.0182559849113546

Epoch: 6| Step: 8
Training loss: 2.1326096057891846
Validation loss: 2.0535984218761487

Epoch: 6| Step: 9
Training loss: 1.495367169380188
Validation loss: 2.021947594099147

Epoch: 6| Step: 10
Training loss: 1.593257188796997
Validation loss: 2.0412536731330295

Epoch: 6| Step: 11
Training loss: 1.5932583808898926
Validation loss: 2.029092486186694

Epoch: 6| Step: 12
Training loss: 1.9767780303955078
Validation loss: 2.011429875127731

Epoch: 6| Step: 13
Training loss: 1.9113107919692993
Validation loss: 2.0072477838044525

Epoch: 225| Step: 0
Training loss: 1.7590296268463135
Validation loss: 2.0350179313331522

Epoch: 6| Step: 1
Training loss: 1.9385616779327393
Validation loss: 2.028455072833646

Epoch: 6| Step: 2
Training loss: 2.3339967727661133
Validation loss: 2.0224608157270696

Epoch: 6| Step: 3
Training loss: 1.2541332244873047
Validation loss: 2.0380970726731005

Epoch: 6| Step: 4
Training loss: 1.662792444229126
Validation loss: 2.04495499467337

Epoch: 6| Step: 5
Training loss: 1.437022089958191
Validation loss: 2.0355971808074624

Epoch: 6| Step: 6
Training loss: 1.394620418548584
Validation loss: 2.0335553320505286

Epoch: 6| Step: 7
Training loss: 2.0938241481781006
Validation loss: 2.0572702141218286

Epoch: 6| Step: 8
Training loss: 2.3323941230773926
Validation loss: 2.014974363388554

Epoch: 6| Step: 9
Training loss: 2.42995548248291
Validation loss: 2.0403046684880413

Epoch: 6| Step: 10
Training loss: 2.3915159702301025
Validation loss: 2.021627433838383

Epoch: 6| Step: 11
Training loss: 1.5953588485717773
Validation loss: 2.041243624943559

Epoch: 6| Step: 12
Training loss: 2.0124106407165527
Validation loss: 2.0294774091371925

Epoch: 6| Step: 13
Training loss: 1.9261850118637085
Validation loss: 2.041632475391511

Epoch: 226| Step: 0
Training loss: 2.438321352005005
Validation loss: 2.0281741772928545

Epoch: 6| Step: 1
Training loss: 2.2070531845092773
Validation loss: 2.068301152157527

Epoch: 6| Step: 2
Training loss: 1.6229610443115234
Validation loss: 2.0364737805499824

Epoch: 6| Step: 3
Training loss: 2.1371359825134277
Validation loss: 2.018953723292197

Epoch: 6| Step: 4
Training loss: 1.9146802425384521
Validation loss: 2.0485293647294402

Epoch: 6| Step: 5
Training loss: 1.810073733329773
Validation loss: 2.080936224229874

Epoch: 6| Step: 6
Training loss: 1.8828160762786865
Validation loss: 2.063126056425033

Epoch: 6| Step: 7
Training loss: 1.7155025005340576
Validation loss: 2.042228332129858

Epoch: 6| Step: 8
Training loss: 1.9368795156478882
Validation loss: 2.024219923121955

Epoch: 6| Step: 9
Training loss: 1.2085400819778442
Validation loss: 2.040164742418515

Epoch: 6| Step: 10
Training loss: 2.0602502822875977
Validation loss: 2.0352550270736858

Epoch: 6| Step: 11
Training loss: 1.6293928623199463
Validation loss: 2.0387308110472975

Epoch: 6| Step: 12
Training loss: 1.7858004570007324
Validation loss: 2.0284427878677205

Epoch: 6| Step: 13
Training loss: 2.030918836593628
Validation loss: 2.037636935069997

Epoch: 227| Step: 0
Training loss: 1.4106513261795044
Validation loss: 2.0534768309644473

Epoch: 6| Step: 1
Training loss: 1.5017375946044922
Validation loss: 2.0124779644832818

Epoch: 6| Step: 2
Training loss: 2.6451261043548584
Validation loss: 2.0351289292817474

Epoch: 6| Step: 3
Training loss: 1.756748080253601
Validation loss: 2.0461551220186296

Epoch: 6| Step: 4
Training loss: 2.3330883979797363
Validation loss: 2.0402784398806992

Epoch: 6| Step: 5
Training loss: 2.0030691623687744
Validation loss: 2.027510742987356

Epoch: 6| Step: 6
Training loss: 1.6475783586502075
Validation loss: 2.0114437482690297

Epoch: 6| Step: 7
Training loss: 1.9054771661758423
Validation loss: 2.01738481367788

Epoch: 6| Step: 8
Training loss: 1.9889711141586304
Validation loss: 2.0628150688704623

Epoch: 6| Step: 9
Training loss: 1.4550949335098267
Validation loss: 2.022986368466449

Epoch: 6| Step: 10
Training loss: 1.5766980648040771
Validation loss: 2.039420186832387

Epoch: 6| Step: 11
Training loss: 2.063856601715088
Validation loss: 2.029129065493102

Epoch: 6| Step: 12
Training loss: 2.4064102172851562
Validation loss: 2.0573314133510796

Epoch: 6| Step: 13
Training loss: 2.0015339851379395
Validation loss: 2.0452780262116463

Epoch: 228| Step: 0
Training loss: 1.8103008270263672
Validation loss: 2.0394994020462036

Epoch: 6| Step: 1
Training loss: 1.6546885967254639
Validation loss: 2.02813793254155

Epoch: 6| Step: 2
Training loss: 1.9267921447753906
Validation loss: 2.0224597697616904

Epoch: 6| Step: 3
Training loss: 1.6383332014083862
Validation loss: 2.066411022217043

Epoch: 6| Step: 4
Training loss: 1.1903126239776611
Validation loss: 2.0351112068340345

Epoch: 6| Step: 5
Training loss: 2.5403151512145996
Validation loss: 2.0507740666789394

Epoch: 6| Step: 6
Training loss: 2.486721992492676
Validation loss: 2.04429272426072

Epoch: 6| Step: 7
Training loss: 1.7219698429107666
Validation loss: 2.0537247555230254

Epoch: 6| Step: 8
Training loss: 1.3205801248550415
Validation loss: 2.0553014765503588

Epoch: 6| Step: 9
Training loss: 2.0602617263793945
Validation loss: 2.0236168471715783

Epoch: 6| Step: 10
Training loss: 2.0242702960968018
Validation loss: 2.0185203359973047

Epoch: 6| Step: 11
Training loss: 2.0644009113311768
Validation loss: 2.0360089168753674

Epoch: 6| Step: 12
Training loss: 2.217782974243164
Validation loss: 2.039985672120125

Epoch: 6| Step: 13
Training loss: 2.1962668895721436
Validation loss: 2.095861524663946

Epoch: 229| Step: 0
Training loss: 2.298469066619873
Validation loss: 2.0396492019776375

Epoch: 6| Step: 1
Training loss: 2.0371906757354736
Validation loss: 2.028949042802216

Epoch: 6| Step: 2
Training loss: 0.7992649674415588
Validation loss: 2.0566720013977378

Epoch: 6| Step: 3
Training loss: 2.7218780517578125
Validation loss: 2.038426042884909

Epoch: 6| Step: 4
Training loss: 1.92923903465271
Validation loss: 2.0478480592850716

Epoch: 6| Step: 5
Training loss: 2.0197768211364746
Validation loss: 2.0323312436380694

Epoch: 6| Step: 6
Training loss: 1.930101990699768
Validation loss: 2.0367806470522316

Epoch: 6| Step: 7
Training loss: 2.5316991806030273
Validation loss: 2.0456609418315272

Epoch: 6| Step: 8
Training loss: 1.5843913555145264
Validation loss: 2.0512720256723385

Epoch: 6| Step: 9
Training loss: 1.2997019290924072
Validation loss: 2.0644052438838507

Epoch: 6| Step: 10
Training loss: 1.7719595432281494
Validation loss: 2.0746549329450055

Epoch: 6| Step: 11
Training loss: 1.6336514949798584
Validation loss: 2.0812041323672057

Epoch: 6| Step: 12
Training loss: 2.2482495307922363
Validation loss: 2.033308385520853

Epoch: 6| Step: 13
Training loss: 1.5870853662490845
Validation loss: 2.0479936240821757

Epoch: 230| Step: 0
Training loss: 2.169727325439453
Validation loss: 2.0430605103892665

Epoch: 6| Step: 1
Training loss: 2.173006296157837
Validation loss: 2.0459340682593723

Epoch: 6| Step: 2
Training loss: 2.174023151397705
Validation loss: 2.03406709753057

Epoch: 6| Step: 3
Training loss: 1.5781290531158447
Validation loss: 2.0341597052030664

Epoch: 6| Step: 4
Training loss: 1.2786017656326294
Validation loss: 2.023824614863242

Epoch: 6| Step: 5
Training loss: 1.5355987548828125
Validation loss: 2.021023319613549

Epoch: 6| Step: 6
Training loss: 2.170306921005249
Validation loss: 2.0222482732547227

Epoch: 6| Step: 7
Training loss: 1.9907444715499878
Validation loss: 2.030730019333542

Epoch: 6| Step: 8
Training loss: 2.332693099975586
Validation loss: 2.0296665981251705

Epoch: 6| Step: 9
Training loss: 2.252924919128418
Validation loss: 2.021095556597556

Epoch: 6| Step: 10
Training loss: 1.6922130584716797
Validation loss: 2.0609085816209034

Epoch: 6| Step: 11
Training loss: 1.4994378089904785
Validation loss: 2.037595755310469

Epoch: 6| Step: 12
Training loss: 1.9457974433898926
Validation loss: 2.044946587213906

Epoch: 6| Step: 13
Training loss: 1.4838021993637085
Validation loss: 1.9871292332167267

Epoch: 231| Step: 0
Training loss: 1.604725956916809
Validation loss: 2.067974199530899

Epoch: 6| Step: 1
Training loss: 2.335400342941284
Validation loss: 2.0368198451175483

Epoch: 6| Step: 2
Training loss: 2.0484676361083984
Validation loss: 2.0208024773546445

Epoch: 6| Step: 3
Training loss: 2.209827423095703
Validation loss: 2.0317778805250764

Epoch: 6| Step: 4
Training loss: 1.4808869361877441
Validation loss: 2.029107571930014

Epoch: 6| Step: 5
Training loss: 2.404792070388794
Validation loss: 2.0522367685071883

Epoch: 6| Step: 6
Training loss: 1.5303494930267334
Validation loss: 2.0545702941956057

Epoch: 6| Step: 7
Training loss: 2.060337543487549
Validation loss: 2.034164649184032

Epoch: 6| Step: 8
Training loss: 1.667038083076477
Validation loss: 2.0512647974875664

Epoch: 6| Step: 9
Training loss: 1.711167812347412
Validation loss: 2.0330849052757345

Epoch: 6| Step: 10
Training loss: 1.2246018648147583
Validation loss: 2.019073409418906

Epoch: 6| Step: 11
Training loss: 2.4504268169403076
Validation loss: 2.07109901981969

Epoch: 6| Step: 12
Training loss: 1.657515287399292
Validation loss: 2.0270016834300053

Epoch: 6| Step: 13
Training loss: 2.316868305206299
Validation loss: 2.0298739158979027

Epoch: 232| Step: 0
Training loss: 1.964926838874817
Validation loss: 2.0475878741151545

Epoch: 6| Step: 1
Training loss: 1.7156124114990234
Validation loss: 2.0524639468039236

Epoch: 6| Step: 2
Training loss: 2.2895450592041016
Validation loss: 2.035530169804891

Epoch: 6| Step: 3
Training loss: 1.9529592990875244
Validation loss: 2.0226354509271602

Epoch: 6| Step: 4
Training loss: 1.7464609146118164
Validation loss: 2.036107773421913

Epoch: 6| Step: 5
Training loss: 1.358279824256897
Validation loss: 2.086103964877385

Epoch: 6| Step: 6
Training loss: 2.0619616508483887
Validation loss: 2.0368350692974624

Epoch: 6| Step: 7
Training loss: 1.8590978384017944
Validation loss: 2.0069006104623117

Epoch: 6| Step: 8
Training loss: 1.6669381856918335
Validation loss: 2.0283777739412043

Epoch: 6| Step: 9
Training loss: 1.5029339790344238
Validation loss: 2.0190856149119716

Epoch: 6| Step: 10
Training loss: 1.8006253242492676
Validation loss: 2.0241853575552664

Epoch: 6| Step: 11
Training loss: 2.4286131858825684
Validation loss: 2.0569365332203526

Epoch: 6| Step: 12
Training loss: 2.174821376800537
Validation loss: 2.039930643573884

Epoch: 6| Step: 13
Training loss: 2.084824323654175
Validation loss: 2.0587950227081135

Epoch: 233| Step: 0
Training loss: 1.9867626428604126
Validation loss: 2.0250371553564586

Epoch: 6| Step: 1
Training loss: 2.1306090354919434
Validation loss: 2.0480072754685597

Epoch: 6| Step: 2
Training loss: 1.9517534971237183
Validation loss: 2.0455369616067536

Epoch: 6| Step: 3
Training loss: 1.931232213973999
Validation loss: 2.055575445134153

Epoch: 6| Step: 4
Training loss: 1.7395617961883545
Validation loss: 2.068041516888526

Epoch: 6| Step: 5
Training loss: 1.9270879030227661
Validation loss: 2.0755280192180345

Epoch: 6| Step: 6
Training loss: 2.3051187992095947
Validation loss: 2.048886001750987

Epoch: 6| Step: 7
Training loss: 1.8986709117889404
Validation loss: 2.058625510943833

Epoch: 6| Step: 8
Training loss: 1.8768389225006104
Validation loss: 2.0525038575613372

Epoch: 6| Step: 9
Training loss: 1.8278943300247192
Validation loss: 2.0485819770443823

Epoch: 6| Step: 10
Training loss: 1.7051749229431152
Validation loss: 2.048378265032204

Epoch: 6| Step: 11
Training loss: 1.8922443389892578
Validation loss: 2.048200379135788

Epoch: 6| Step: 12
Training loss: 1.9078956842422485
Validation loss: 2.058070748083053

Epoch: 6| Step: 13
Training loss: 1.0251013040542603
Validation loss: 2.05258112056281

Epoch: 234| Step: 0
Training loss: 1.3942042589187622
Validation loss: 2.0490066582156765

Epoch: 6| Step: 1
Training loss: 2.44480562210083
Validation loss: 2.0332044657840522

Epoch: 6| Step: 2
Training loss: 2.152315139770508
Validation loss: 2.0497967017594205

Epoch: 6| Step: 3
Training loss: 1.8463990688323975
Validation loss: 2.028162843437605

Epoch: 6| Step: 4
Training loss: 1.7386736869812012
Validation loss: 2.0246822603287233

Epoch: 6| Step: 5
Training loss: 2.305738925933838
Validation loss: 2.036182326655234

Epoch: 6| Step: 6
Training loss: 1.8788890838623047
Validation loss: 2.0699065244326027

Epoch: 6| Step: 7
Training loss: 2.1166651248931885
Validation loss: 2.0284692638663837

Epoch: 6| Step: 8
Training loss: 1.5966410636901855
Validation loss: 2.0251151131045435

Epoch: 6| Step: 9
Training loss: 1.6880309581756592
Validation loss: 2.0656981596382717

Epoch: 6| Step: 10
Training loss: 1.8280375003814697
Validation loss: 2.037478075232557

Epoch: 6| Step: 11
Training loss: 1.3978062868118286
Validation loss: 2.0267577376416934

Epoch: 6| Step: 12
Training loss: 2.085230827331543
Validation loss: 2.038345403568719

Epoch: 6| Step: 13
Training loss: 1.739398717880249
Validation loss: 2.0107781797327022

Epoch: 235| Step: 0
Training loss: 1.6156072616577148
Validation loss: 2.0334038131980487

Epoch: 6| Step: 1
Training loss: 2.143998861312866
Validation loss: 2.052554594573154

Epoch: 6| Step: 2
Training loss: 2.104300022125244
Validation loss: 2.0547776863139164

Epoch: 6| Step: 3
Training loss: 1.4585591554641724
Validation loss: 2.0246061099472867

Epoch: 6| Step: 4
Training loss: 2.2034878730773926
Validation loss: 2.0516427921992477

Epoch: 6| Step: 5
Training loss: 2.0153450965881348
Validation loss: 2.0505989443871284

Epoch: 6| Step: 6
Training loss: 1.5153930187225342
Validation loss: 2.018241584941905

Epoch: 6| Step: 7
Training loss: 1.8650182485580444
Validation loss: 2.0052991169755177

Epoch: 6| Step: 8
Training loss: 2.1232423782348633
Validation loss: 2.016854142629972

Epoch: 6| Step: 9
Training loss: 1.906869649887085
Validation loss: 2.062421193686865

Epoch: 6| Step: 10
Training loss: 2.327117443084717
Validation loss: 2.043260242349358

Epoch: 6| Step: 11
Training loss: 1.4285242557525635
Validation loss: 2.0689214339820285

Epoch: 6| Step: 12
Training loss: 1.4745985269546509
Validation loss: 2.04694866108638

Epoch: 6| Step: 13
Training loss: 2.867792844772339
Validation loss: 2.0571171083757953

Epoch: 236| Step: 0
Training loss: 2.828174591064453
Validation loss: 2.038336685908738

Epoch: 6| Step: 1
Training loss: 1.527350902557373
Validation loss: 2.0539302056835544

Epoch: 6| Step: 2
Training loss: 1.6373999118804932
Validation loss: 2.049360949506042

Epoch: 6| Step: 3
Training loss: 2.630493402481079
Validation loss: 2.0734303279589583

Epoch: 6| Step: 4
Training loss: 1.3817284107208252
Validation loss: 2.0435198430092103

Epoch: 6| Step: 5
Training loss: 1.7369178533554077
Validation loss: 2.041719813500681

Epoch: 6| Step: 6
Training loss: 1.6120729446411133
Validation loss: 2.0596415599187217

Epoch: 6| Step: 7
Training loss: 1.5234382152557373
Validation loss: 2.0676093716775217

Epoch: 6| Step: 8
Training loss: 1.9411354064941406
Validation loss: 2.0633801670484644

Epoch: 6| Step: 9
Training loss: 1.9297893047332764
Validation loss: 2.028224165721606

Epoch: 6| Step: 10
Training loss: 1.6704437732696533
Validation loss: 2.0315111260260306

Epoch: 6| Step: 11
Training loss: 2.553879976272583
Validation loss: 2.0577946798775786

Epoch: 6| Step: 12
Training loss: 2.2054662704467773
Validation loss: 2.0429566291070755

Epoch: 6| Step: 13
Training loss: 1.077181100845337
Validation loss: 2.0276668789566203

Epoch: 237| Step: 0
Training loss: 2.2589612007141113
Validation loss: 2.0322441490747596

Epoch: 6| Step: 1
Training loss: 2.098914861679077
Validation loss: 2.0440115544103805

Epoch: 6| Step: 2
Training loss: 1.4896892309188843
Validation loss: 2.0601368027348674

Epoch: 6| Step: 3
Training loss: 1.45401930809021
Validation loss: 2.031129190998693

Epoch: 6| Step: 4
Training loss: 2.174576759338379
Validation loss: 2.014434201743013

Epoch: 6| Step: 5
Training loss: 0.9158658981323242
Validation loss: 2.0306265059337822

Epoch: 6| Step: 6
Training loss: 1.631042718887329
Validation loss: 2.0577543986740934

Epoch: 6| Step: 7
Training loss: 2.147692918777466
Validation loss: 2.0413705789914696

Epoch: 6| Step: 8
Training loss: 1.690659523010254
Validation loss: 2.0414336419874624

Epoch: 6| Step: 9
Training loss: 1.360802173614502
Validation loss: 2.0519104016724454

Epoch: 6| Step: 10
Training loss: 2.9739909172058105
Validation loss: 2.048319790952949

Epoch: 6| Step: 11
Training loss: 2.3010103702545166
Validation loss: 2.050439016793364

Epoch: 6| Step: 12
Training loss: 1.4556376934051514
Validation loss: 2.0270000657727643

Epoch: 6| Step: 13
Training loss: 2.553276538848877
Validation loss: 2.0211915610938944

Epoch: 238| Step: 0
Training loss: 1.2947415113449097
Validation loss: 2.070367008127192

Epoch: 6| Step: 1
Training loss: 1.921332597732544
Validation loss: 2.040481129000264

Epoch: 6| Step: 2
Training loss: 1.9900267124176025
Validation loss: 2.02112054440283

Epoch: 6| Step: 3
Training loss: 2.12959885597229
Validation loss: 2.0829760977016982

Epoch: 6| Step: 4
Training loss: 2.3796310424804688
Validation loss: 2.0829954249884493

Epoch: 6| Step: 5
Training loss: 1.9287388324737549
Validation loss: 2.0514422437196136

Epoch: 6| Step: 6
Training loss: 2.158112049102783
Validation loss: 2.0491427657424763

Epoch: 6| Step: 7
Training loss: 1.575446367263794
Validation loss: 2.048609105489587

Epoch: 6| Step: 8
Training loss: 1.5900434255599976
Validation loss: 2.040916996617471

Epoch: 6| Step: 9
Training loss: 1.7701613903045654
Validation loss: 2.0386975849828413

Epoch: 6| Step: 10
Training loss: 1.8317484855651855
Validation loss: 2.0195851261897753

Epoch: 6| Step: 11
Training loss: 2.075599193572998
Validation loss: 2.04708699000779

Epoch: 6| Step: 12
Training loss: 1.8329840898513794
Validation loss: 2.0101278289671867

Epoch: 6| Step: 13
Training loss: 1.9647769927978516
Validation loss: 2.0386551246848157

Epoch: 239| Step: 0
Training loss: 2.1614036560058594
Validation loss: 2.034977411711088

Epoch: 6| Step: 1
Training loss: 2.0690999031066895
Validation loss: 2.0441872317303895

Epoch: 6| Step: 2
Training loss: 2.297417640686035
Validation loss: 2.032145748856247

Epoch: 6| Step: 3
Training loss: 1.9107351303100586
Validation loss: 2.0709453757091234

Epoch: 6| Step: 4
Training loss: 1.9297654628753662
Validation loss: 2.0318483973062165

Epoch: 6| Step: 5
Training loss: 2.090470314025879
Validation loss: 2.0469823806516585

Epoch: 6| Step: 6
Training loss: 1.655651330947876
Validation loss: 2.0734646307524813

Epoch: 6| Step: 7
Training loss: 1.520702838897705
Validation loss: 2.0471912673724595

Epoch: 6| Step: 8
Training loss: 1.814424991607666
Validation loss: 2.0534338015382008

Epoch: 6| Step: 9
Training loss: 1.9025126695632935
Validation loss: 2.0662796599890596

Epoch: 6| Step: 10
Training loss: 1.8685671091079712
Validation loss: 2.048696966581447

Epoch: 6| Step: 11
Training loss: 1.4680149555206299
Validation loss: 2.06612298052798

Epoch: 6| Step: 12
Training loss: 1.5253159999847412
Validation loss: 2.0833347535902456

Epoch: 6| Step: 13
Training loss: 1.9470738172531128
Validation loss: 2.027057073449576

Epoch: 240| Step: 0
Training loss: 2.123675584793091
Validation loss: 2.065670008300453

Epoch: 6| Step: 1
Training loss: 1.7880884408950806
Validation loss: 2.0564783696205384

Epoch: 6| Step: 2
Training loss: 1.6079318523406982
Validation loss: 2.0164594214449645

Epoch: 6| Step: 3
Training loss: 2.4324088096618652
Validation loss: 2.01932930689986

Epoch: 6| Step: 4
Training loss: 1.6229369640350342
Validation loss: 2.0469750537667224

Epoch: 6| Step: 5
Training loss: 1.8176610469818115
Validation loss: 2.0294828671281055

Epoch: 6| Step: 6
Training loss: 1.7319920063018799
Validation loss: 2.040876175767632

Epoch: 6| Step: 7
Training loss: 1.6155390739440918
Validation loss: 2.0336619128463087

Epoch: 6| Step: 8
Training loss: 2.072007179260254
Validation loss: 2.054854062295729

Epoch: 6| Step: 9
Training loss: 1.9796953201293945
Validation loss: 2.0516787190591135

Epoch: 6| Step: 10
Training loss: 1.7526336908340454
Validation loss: 2.0223052014586744

Epoch: 6| Step: 11
Training loss: 1.8878264427185059
Validation loss: 2.039174699014233

Epoch: 6| Step: 12
Training loss: 2.09599232673645
Validation loss: 2.059509454234954

Epoch: 6| Step: 13
Training loss: 1.684569001197815
Validation loss: 2.0394699611971454

Epoch: 241| Step: 0
Training loss: 2.4922361373901367
Validation loss: 2.037432082237736

Epoch: 6| Step: 1
Training loss: 1.80976140499115
Validation loss: 2.076905773532006

Epoch: 6| Step: 2
Training loss: 1.4849120378494263
Validation loss: 2.050248504966818

Epoch: 6| Step: 3
Training loss: 1.960762619972229
Validation loss: 2.0739873788690053

Epoch: 6| Step: 4
Training loss: 1.8862438201904297
Validation loss: 2.078828089980669

Epoch: 6| Step: 5
Training loss: 2.1469292640686035
Validation loss: 2.0507586207441104

Epoch: 6| Step: 6
Training loss: 1.563040018081665
Validation loss: 2.0672260356205765

Epoch: 6| Step: 7
Training loss: 1.6018327474594116
Validation loss: 2.0767545033526678

Epoch: 6| Step: 8
Training loss: 2.983708143234253
Validation loss: 2.070785827534173

Epoch: 6| Step: 9
Training loss: 1.5444308519363403
Validation loss: 2.050028124163228

Epoch: 6| Step: 10
Training loss: 1.5418994426727295
Validation loss: 2.0674233218675018

Epoch: 6| Step: 11
Training loss: 1.4966435432434082
Validation loss: 2.0471514245515228

Epoch: 6| Step: 12
Training loss: 1.8836559057235718
Validation loss: 2.062582846610777

Epoch: 6| Step: 13
Training loss: 1.693986415863037
Validation loss: 2.0270593717534053

Epoch: 242| Step: 0
Training loss: 2.3115267753601074
Validation loss: 2.0568451137952906

Epoch: 6| Step: 1
Training loss: 1.8396941423416138
Validation loss: 2.0607824620380195

Epoch: 6| Step: 2
Training loss: 1.6803202629089355
Validation loss: 1.9993989172802176

Epoch: 6| Step: 3
Training loss: 2.214067220687866
Validation loss: 2.0434198315425585

Epoch: 6| Step: 4
Training loss: 2.376760482788086
Validation loss: 2.0464242965944353

Epoch: 6| Step: 5
Training loss: 1.2787530422210693
Validation loss: 2.059853602481145

Epoch: 6| Step: 6
Training loss: 0.833213210105896
Validation loss: 2.0184645332315916

Epoch: 6| Step: 7
Training loss: 1.8963005542755127
Validation loss: 2.0110451021502094

Epoch: 6| Step: 8
Training loss: 1.659928798675537
Validation loss: 2.049892658828407

Epoch: 6| Step: 9
Training loss: 2.265699863433838
Validation loss: 2.062579785623858

Epoch: 6| Step: 10
Training loss: 2.1046276092529297
Validation loss: 2.0228484548548216

Epoch: 6| Step: 11
Training loss: 1.7290892601013184
Validation loss: 2.0394518708670013

Epoch: 6| Step: 12
Training loss: 1.4509408473968506
Validation loss: 2.057836878684259

Epoch: 6| Step: 13
Training loss: 2.998631000518799
Validation loss: 2.0566917670670377

Epoch: 243| Step: 0
Training loss: 1.3344439268112183
Validation loss: 2.0415622406108405

Epoch: 6| Step: 1
Training loss: 1.2196850776672363
Validation loss: 2.0557939775528444

Epoch: 6| Step: 2
Training loss: 1.8990452289581299
Validation loss: 2.0325150361625095

Epoch: 6| Step: 3
Training loss: 2.446683406829834
Validation loss: 2.052525967679998

Epoch: 6| Step: 4
Training loss: 1.9930623769760132
Validation loss: 2.029075348249046

Epoch: 6| Step: 5
Training loss: 2.088573455810547
Validation loss: 2.05409848818215

Epoch: 6| Step: 6
Training loss: 2.3759031295776367
Validation loss: 2.043135191804619

Epoch: 6| Step: 7
Training loss: 1.885158896446228
Validation loss: 2.07138378133056

Epoch: 6| Step: 8
Training loss: 2.448378086090088
Validation loss: 2.021209475814655

Epoch: 6| Step: 9
Training loss: 1.824615240097046
Validation loss: 2.0317624717630367

Epoch: 6| Step: 10
Training loss: 2.1253724098205566
Validation loss: 2.0427927009520994

Epoch: 6| Step: 11
Training loss: 1.687469482421875
Validation loss: 2.0575834602437992

Epoch: 6| Step: 12
Training loss: 1.4729413986206055
Validation loss: 2.0535616900331233

Epoch: 6| Step: 13
Training loss: 1.4605683088302612
Validation loss: 2.0839003837236794

Epoch: 244| Step: 0
Training loss: 2.0557749271392822
Validation loss: 2.046779086512904

Epoch: 6| Step: 1
Training loss: 2.1832339763641357
Validation loss: 2.068435130580779

Epoch: 6| Step: 2
Training loss: 1.3322110176086426
Validation loss: 2.0691154874781126

Epoch: 6| Step: 3
Training loss: 2.397782802581787
Validation loss: 2.045688662477719

Epoch: 6| Step: 4
Training loss: 2.0587573051452637
Validation loss: 2.058210383179367

Epoch: 6| Step: 5
Training loss: 2.2868309020996094
Validation loss: 2.048519124266922

Epoch: 6| Step: 6
Training loss: 1.932668924331665
Validation loss: 2.03681969001729

Epoch: 6| Step: 7
Training loss: 1.7681751251220703
Validation loss: 2.0780605385380406

Epoch: 6| Step: 8
Training loss: 1.143190622329712
Validation loss: 2.0740620090115454

Epoch: 6| Step: 9
Training loss: 1.8023927211761475
Validation loss: 2.04320312956328

Epoch: 6| Step: 10
Training loss: 1.9323813915252686
Validation loss: 2.069083764988889

Epoch: 6| Step: 11
Training loss: 2.311166286468506
Validation loss: 2.052820982471589

Epoch: 6| Step: 12
Training loss: 1.4328322410583496
Validation loss: 2.0315402553927515

Epoch: 6| Step: 13
Training loss: 1.1813730001449585
Validation loss: 2.0465918202554025

Epoch: 245| Step: 0
Training loss: 1.360954761505127
Validation loss: 2.0679220717440367

Epoch: 6| Step: 1
Training loss: 1.744660496711731
Validation loss: 2.035436725103727

Epoch: 6| Step: 2
Training loss: 2.1365671157836914
Validation loss: 2.0244593299845213

Epoch: 6| Step: 3
Training loss: 2.516526222229004
Validation loss: 2.0454568760369414

Epoch: 6| Step: 4
Training loss: 1.8303637504577637
Validation loss: 2.052438792362008

Epoch: 6| Step: 5
Training loss: 1.9047346115112305
Validation loss: 2.0293860486758653

Epoch: 6| Step: 6
Training loss: 1.9960787296295166
Validation loss: 2.058062529051176

Epoch: 6| Step: 7
Training loss: 1.5482749938964844
Validation loss: 2.0359476433005383

Epoch: 6| Step: 8
Training loss: 2.255911111831665
Validation loss: 2.022337693040089

Epoch: 6| Step: 9
Training loss: 2.1642887592315674
Validation loss: 2.0562244205064673

Epoch: 6| Step: 10
Training loss: 1.908250093460083
Validation loss: 2.0442026225469445

Epoch: 6| Step: 11
Training loss: 1.785585880279541
Validation loss: 2.062713840956329

Epoch: 6| Step: 12
Training loss: 1.0124938488006592
Validation loss: 2.0377422173817954

Epoch: 6| Step: 13
Training loss: 1.7289061546325684
Validation loss: 2.003897382367042

Epoch: 246| Step: 0
Training loss: 2.007479190826416
Validation loss: 1.9906577512782107

Epoch: 6| Step: 1
Training loss: 1.2786133289337158
Validation loss: 2.033601919809977

Epoch: 6| Step: 2
Training loss: 1.763634204864502
Validation loss: 2.046145236620339

Epoch: 6| Step: 3
Training loss: 1.715153694152832
Validation loss: 2.0388978155710364

Epoch: 6| Step: 4
Training loss: 1.8054401874542236
Validation loss: 2.053604716895729

Epoch: 6| Step: 5
Training loss: 1.587155818939209
Validation loss: 2.0643781667114585

Epoch: 6| Step: 6
Training loss: 1.6685774326324463
Validation loss: 2.059489628320099

Epoch: 6| Step: 7
Training loss: 1.8734321594238281
Validation loss: 2.057540241108146

Epoch: 6| Step: 8
Training loss: 1.8267782926559448
Validation loss: 2.0378629289647585

Epoch: 6| Step: 9
Training loss: 2.3786187171936035
Validation loss: 2.03331644176155

Epoch: 6| Step: 10
Training loss: 1.6536444425582886
Validation loss: 2.0390906346741544

Epoch: 6| Step: 11
Training loss: 2.4374923706054688
Validation loss: 2.049493699945429

Epoch: 6| Step: 12
Training loss: 2.341409206390381
Validation loss: 2.0468898024610294

Epoch: 6| Step: 13
Training loss: 1.6464753150939941
Validation loss: 2.037912025246569

Epoch: 247| Step: 0
Training loss: 1.868114709854126
Validation loss: 2.0839622584722375

Epoch: 6| Step: 1
Training loss: 1.8219467401504517
Validation loss: 2.0560904279831917

Epoch: 6| Step: 2
Training loss: 2.1770195960998535
Validation loss: 2.0421432718153922

Epoch: 6| Step: 3
Training loss: 1.3168251514434814
Validation loss: 2.051988617066414

Epoch: 6| Step: 4
Training loss: 1.9399880170822144
Validation loss: 2.058916236764641

Epoch: 6| Step: 5
Training loss: 1.905400276184082
Validation loss: 2.0682225022264706

Epoch: 6| Step: 6
Training loss: 1.8482823371887207
Validation loss: 2.058163240391721

Epoch: 6| Step: 7
Training loss: 1.7880818843841553
Validation loss: 2.03679443559339

Epoch: 6| Step: 8
Training loss: 1.3939571380615234
Validation loss: 2.0489547970474407

Epoch: 6| Step: 9
Training loss: 1.781935214996338
Validation loss: 2.068462961463518

Epoch: 6| Step: 10
Training loss: 1.9623799324035645
Validation loss: 2.0729349966972106

Epoch: 6| Step: 11
Training loss: 2.094743013381958
Validation loss: 2.039205579347508

Epoch: 6| Step: 12
Training loss: 2.530550241470337
Validation loss: 2.088531817159345

Epoch: 6| Step: 13
Training loss: 0.9254116415977478
Validation loss: 2.0662918731730473

Epoch: 248| Step: 0
Training loss: 2.406430244445801
Validation loss: 2.076807934750793

Epoch: 6| Step: 1
Training loss: 2.1226980686187744
Validation loss: 2.067397112487465

Epoch: 6| Step: 2
Training loss: 1.840857982635498
Validation loss: 2.06883974998228

Epoch: 6| Step: 3
Training loss: 1.4896823167800903
Validation loss: 2.044482067067136

Epoch: 6| Step: 4
Training loss: 1.2674963474273682
Validation loss: 2.0548797166475685

Epoch: 6| Step: 5
Training loss: 1.9819939136505127
Validation loss: 2.0409669927371445

Epoch: 6| Step: 6
Training loss: 1.7474479675292969
Validation loss: 2.0611605234043573

Epoch: 6| Step: 7
Training loss: 2.4175937175750732
Validation loss: 2.0645466081557737

Epoch: 6| Step: 8
Training loss: 1.4948930740356445
Validation loss: 2.0316992062394337

Epoch: 6| Step: 9
Training loss: 1.5850790739059448
Validation loss: 2.0204013868044783

Epoch: 6| Step: 10
Training loss: 2.0206384658813477
Validation loss: 2.0464378121078655

Epoch: 6| Step: 11
Training loss: 2.1930758953094482
Validation loss: 2.0496534455207085

Epoch: 6| Step: 12
Training loss: 1.9119582176208496
Validation loss: 2.049618390298659

Epoch: 6| Step: 13
Training loss: 1.244806170463562
Validation loss: 2.041362694514695

Epoch: 249| Step: 0
Training loss: 1.3868913650512695
Validation loss: 2.042223116402985

Epoch: 6| Step: 1
Training loss: 1.8470187187194824
Validation loss: 2.0484891911988616

Epoch: 6| Step: 2
Training loss: 1.9998815059661865
Validation loss: 2.039175006651109

Epoch: 6| Step: 3
Training loss: 1.9514057636260986
Validation loss: 2.0120113485602924

Epoch: 6| Step: 4
Training loss: 2.3050827980041504
Validation loss: 2.035552647805983

Epoch: 6| Step: 5
Training loss: 1.5949327945709229
Validation loss: 2.0443812929173952

Epoch: 6| Step: 6
Training loss: 1.6553354263305664
Validation loss: 2.0544861003916752

Epoch: 6| Step: 7
Training loss: 1.8485487699508667
Validation loss: 2.026208055916653

Epoch: 6| Step: 8
Training loss: 1.8931858539581299
Validation loss: 2.0649087275228193

Epoch: 6| Step: 9
Training loss: 1.346873164176941
Validation loss: 2.0354362649302327

Epoch: 6| Step: 10
Training loss: 2.4158875942230225
Validation loss: 2.054759015319168

Epoch: 6| Step: 11
Training loss: 2.082628011703491
Validation loss: 2.056807659005606

Epoch: 6| Step: 12
Training loss: 1.6047652959823608
Validation loss: 2.0300028875309932

Epoch: 6| Step: 13
Training loss: 2.2139439582824707
Validation loss: 2.0753117966395553

Epoch: 250| Step: 0
Training loss: 1.5276161432266235
Validation loss: 2.059539274502826

Epoch: 6| Step: 1
Training loss: 1.9989430904388428
Validation loss: 2.0437795474965084

Epoch: 6| Step: 2
Training loss: 2.037757396697998
Validation loss: 2.064026073742938

Epoch: 6| Step: 3
Training loss: 2.304518699645996
Validation loss: 2.0745496365331833

Epoch: 6| Step: 4
Training loss: 1.7859660387039185
Validation loss: 2.0823571784521944

Epoch: 6| Step: 5
Training loss: 1.6382862329483032
Validation loss: 2.067334254582723

Epoch: 6| Step: 6
Training loss: 2.0468666553497314
Validation loss: 2.0581134134723293

Epoch: 6| Step: 7
Training loss: 1.6296370029449463
Validation loss: 2.058889986366354

Epoch: 6| Step: 8
Training loss: 1.6200045347213745
Validation loss: 2.0379845365401237

Epoch: 6| Step: 9
Training loss: 2.068084478378296
Validation loss: 2.0521751373044905

Epoch: 6| Step: 10
Training loss: 1.816972017288208
Validation loss: 2.045404605968024

Epoch: 6| Step: 11
Training loss: 1.2510844469070435
Validation loss: 2.048559664398111

Epoch: 6| Step: 12
Training loss: 2.0122358798980713
Validation loss: 2.007562078455443

Epoch: 6| Step: 13
Training loss: 2.85544490814209
Validation loss: 2.025244669247699

Epoch: 251| Step: 0
Training loss: 2.463284492492676
Validation loss: 2.041869919787171

Epoch: 6| Step: 1
Training loss: 2.0240554809570312
Validation loss: 2.0203515996215162

Epoch: 6| Step: 2
Training loss: 2.489255905151367
Validation loss: 2.029023026907316

Epoch: 6| Step: 3
Training loss: 1.1033741235733032
Validation loss: 2.019497440707299

Epoch: 6| Step: 4
Training loss: 1.7114310264587402
Validation loss: 2.047421911711334

Epoch: 6| Step: 5
Training loss: 1.9905349016189575
Validation loss: 2.0368096072186708

Epoch: 6| Step: 6
Training loss: 1.9404772520065308
Validation loss: 2.0275657894790813

Epoch: 6| Step: 7
Training loss: 1.9695212841033936
Validation loss: 2.057282493960473

Epoch: 6| Step: 8
Training loss: 1.069917917251587
Validation loss: 2.064356356538752

Epoch: 6| Step: 9
Training loss: 1.8415275812149048
Validation loss: 2.069101564345821

Epoch: 6| Step: 10
Training loss: 1.4888362884521484
Validation loss: 2.0534746005970943

Epoch: 6| Step: 11
Training loss: 1.8906123638153076
Validation loss: 2.0543561699569866

Epoch: 6| Step: 12
Training loss: 2.0543198585510254
Validation loss: 2.0665641048903107

Epoch: 6| Step: 13
Training loss: 1.7659845352172852
Validation loss: 2.0819024296217066

Epoch: 252| Step: 0
Training loss: 1.6614106893539429
Validation loss: 2.053139361002112

Epoch: 6| Step: 1
Training loss: 1.6544787883758545
Validation loss: 2.0423973580842376

Epoch: 6| Step: 2
Training loss: 2.2490620613098145
Validation loss: 2.066958828638959

Epoch: 6| Step: 3
Training loss: 2.1996726989746094
Validation loss: 2.08207062239288

Epoch: 6| Step: 4
Training loss: 2.0590410232543945
Validation loss: 2.0656808858276694

Epoch: 6| Step: 5
Training loss: 2.1625614166259766
Validation loss: 2.055283377247472

Epoch: 6| Step: 6
Training loss: 1.3359873294830322
Validation loss: 2.0725918508345083

Epoch: 6| Step: 7
Training loss: 2.137661933898926
Validation loss: 2.047380562751524

Epoch: 6| Step: 8
Training loss: 1.4661837816238403
Validation loss: 2.072284520313304

Epoch: 6| Step: 9
Training loss: 1.547966480255127
Validation loss: 2.0442020739278486

Epoch: 6| Step: 10
Training loss: 2.032571792602539
Validation loss: 2.064709363445159

Epoch: 6| Step: 11
Training loss: 1.593480110168457
Validation loss: 2.0636408470010243

Epoch: 6| Step: 12
Training loss: 1.1636946201324463
Validation loss: 2.064473248297168

Epoch: 6| Step: 13
Training loss: 2.9489493370056152
Validation loss: 2.0334919575721986

Epoch: 253| Step: 0
Training loss: 2.161820411682129
Validation loss: 2.0315026326846053

Epoch: 6| Step: 1
Training loss: 1.8627560138702393
Validation loss: 2.0644036351993518

Epoch: 6| Step: 2
Training loss: 1.9322400093078613
Validation loss: 2.0439339017355316

Epoch: 6| Step: 3
Training loss: 2.0303146839141846
Validation loss: 2.0649345741477063

Epoch: 6| Step: 4
Training loss: 1.2046005725860596
Validation loss: 2.047840582427158

Epoch: 6| Step: 5
Training loss: 1.403381109237671
Validation loss: 2.063963658066206

Epoch: 6| Step: 6
Training loss: 1.423243522644043
Validation loss: 2.0492150296447096

Epoch: 6| Step: 7
Training loss: 1.8076379299163818
Validation loss: 2.0808451829418058

Epoch: 6| Step: 8
Training loss: 1.6957316398620605
Validation loss: 2.0178285157808693

Epoch: 6| Step: 9
Training loss: 2.1677169799804688
Validation loss: 2.0523127214882964

Epoch: 6| Step: 10
Training loss: 2.584946393966675
Validation loss: 2.0610414679332445

Epoch: 6| Step: 11
Training loss: 1.6419614553451538
Validation loss: 2.037624469367407

Epoch: 6| Step: 12
Training loss: 1.6623958349227905
Validation loss: 2.062310064992597

Epoch: 6| Step: 13
Training loss: 2.447317361831665
Validation loss: 2.087812800561228

Epoch: 254| Step: 0
Training loss: 1.3346987962722778
Validation loss: 2.056272873314478

Epoch: 6| Step: 1
Training loss: 1.7140679359436035
Validation loss: 2.082231334460679

Epoch: 6| Step: 2
Training loss: 1.6018457412719727
Validation loss: 2.053387262487924

Epoch: 6| Step: 3
Training loss: 1.8749514818191528
Validation loss: 2.0722665581651913

Epoch: 6| Step: 4
Training loss: 2.0914974212646484
Validation loss: 2.013351058447233

Epoch: 6| Step: 5
Training loss: 1.2490558624267578
Validation loss: 2.0565315446546

Epoch: 6| Step: 6
Training loss: 1.9470092058181763
Validation loss: 2.0612043052591305

Epoch: 6| Step: 7
Training loss: 2.360306739807129
Validation loss: 2.047062249593837

Epoch: 6| Step: 8
Training loss: 1.9790756702423096
Validation loss: 2.0404003973930114

Epoch: 6| Step: 9
Training loss: 2.324378490447998
Validation loss: 2.0407267373095275

Epoch: 6| Step: 10
Training loss: 1.812235951423645
Validation loss: 2.0414936170783093

Epoch: 6| Step: 11
Training loss: 1.3519854545593262
Validation loss: 2.0435832379966654

Epoch: 6| Step: 12
Training loss: 2.491297721862793
Validation loss: 2.0637716221553024

Epoch: 6| Step: 13
Training loss: 1.629927158355713
Validation loss: 2.0463080483098186

Epoch: 255| Step: 0
Training loss: 1.960360050201416
Validation loss: 2.0304834611954226

Epoch: 6| Step: 1
Training loss: 2.6575684547424316
Validation loss: 2.0328487119367047

Epoch: 6| Step: 2
Training loss: 2.2719106674194336
Validation loss: 2.0161441449196107

Epoch: 6| Step: 3
Training loss: 2.0388307571411133
Validation loss: 2.0243283881936023

Epoch: 6| Step: 4
Training loss: 1.5053200721740723
Validation loss: 2.037535305946104

Epoch: 6| Step: 5
Training loss: 1.2638936042785645
Validation loss: 2.0559816809110742

Epoch: 6| Step: 6
Training loss: 2.073725938796997
Validation loss: 2.044754538484799

Epoch: 6| Step: 7
Training loss: 1.9390614032745361
Validation loss: 2.0263523645298456

Epoch: 6| Step: 8
Training loss: 1.5527920722961426
Validation loss: 2.051356719386193

Epoch: 6| Step: 9
Training loss: 2.1608853340148926
Validation loss: 2.020399670447073

Epoch: 6| Step: 10
Training loss: 1.6738826036453247
Validation loss: 2.0492397764677643

Epoch: 6| Step: 11
Training loss: 1.3424556255340576
Validation loss: 2.04432180876373

Epoch: 6| Step: 12
Training loss: 1.0958576202392578
Validation loss: 2.0628699794892342

Epoch: 6| Step: 13
Training loss: 2.197406053543091
Validation loss: 2.0613880926562893

Epoch: 256| Step: 0
Training loss: 1.768554925918579
Validation loss: 2.056057349328072

Epoch: 6| Step: 1
Training loss: 1.8185664415359497
Validation loss: 2.090742326551868

Epoch: 6| Step: 2
Training loss: 1.8368949890136719
Validation loss: 2.1142984282585884

Epoch: 6| Step: 3
Training loss: 1.820848822593689
Validation loss: 2.118123341632146

Epoch: 6| Step: 4
Training loss: 2.7182583808898926
Validation loss: 2.134866299167756

Epoch: 6| Step: 5
Training loss: 1.7484276294708252
Validation loss: 2.097944818517213

Epoch: 6| Step: 6
Training loss: 1.7439743280410767
Validation loss: 2.1336971431650142

Epoch: 6| Step: 7
Training loss: 1.988420009613037
Validation loss: 2.103816665628905

Epoch: 6| Step: 8
Training loss: 1.8512005805969238
Validation loss: 2.113264694008776

Epoch: 6| Step: 9
Training loss: 2.0998406410217285
Validation loss: 2.092414317592498

Epoch: 6| Step: 10
Training loss: 1.5652825832366943
Validation loss: 2.096600273604034

Epoch: 6| Step: 11
Training loss: 1.6974239349365234
Validation loss: 2.075499673043528

Epoch: 6| Step: 12
Training loss: 1.699509620666504
Validation loss: 2.094734867413839

Epoch: 6| Step: 13
Training loss: 1.768407940864563
Validation loss: 2.075093141166113

Epoch: 257| Step: 0
Training loss: 1.2936936616897583
Validation loss: 2.0069947037645566

Epoch: 6| Step: 1
Training loss: 2.2578258514404297
Validation loss: 2.058925292825186

Epoch: 6| Step: 2
Training loss: 2.1702799797058105
Validation loss: 2.054671915628577

Epoch: 6| Step: 3
Training loss: 1.4642468690872192
Validation loss: 2.05582691777137

Epoch: 6| Step: 4
Training loss: 1.8448805809020996
Validation loss: 2.0314261323662213

Epoch: 6| Step: 5
Training loss: 1.797317624092102
Validation loss: 2.0249540216179303

Epoch: 6| Step: 6
Training loss: 2.254399538040161
Validation loss: 2.049865056109685

Epoch: 6| Step: 7
Training loss: 2.492004632949829
Validation loss: 2.041335690406061

Epoch: 6| Step: 8
Training loss: 1.9676227569580078
Validation loss: 2.0218567027840564

Epoch: 6| Step: 9
Training loss: 1.980118751525879
Validation loss: 2.042408010011078

Epoch: 6| Step: 10
Training loss: 1.3108649253845215
Validation loss: 2.0205196949743454

Epoch: 6| Step: 11
Training loss: 1.0753978490829468
Validation loss: 2.034151141361524

Epoch: 6| Step: 12
Training loss: 1.5370216369628906
Validation loss: 2.0450983662759104

Epoch: 6| Step: 13
Training loss: 2.76997709274292
Validation loss: 2.0768608957208614

Epoch: 258| Step: 0
Training loss: 2.1351795196533203
Validation loss: 2.026613043200585

Epoch: 6| Step: 1
Training loss: 2.754789352416992
Validation loss: 2.061843115796325

Epoch: 6| Step: 2
Training loss: 1.9352428913116455
Validation loss: 2.048481483613291

Epoch: 6| Step: 3
Training loss: 1.668915033340454
Validation loss: 2.059078571616962

Epoch: 6| Step: 4
Training loss: 2.9509711265563965
Validation loss: 2.031862517838837

Epoch: 6| Step: 5
Training loss: 1.6962931156158447
Validation loss: 2.079543664891233

Epoch: 6| Step: 6
Training loss: 1.6998229026794434
Validation loss: 2.051053165107645

Epoch: 6| Step: 7
Training loss: 1.3815791606903076
Validation loss: 2.027763221853523

Epoch: 6| Step: 8
Training loss: 2.128678321838379
Validation loss: 2.04366530910615

Epoch: 6| Step: 9
Training loss: 1.6969659328460693
Validation loss: 2.053788303047098

Epoch: 6| Step: 10
Training loss: 1.10132896900177
Validation loss: 2.0498668788581766

Epoch: 6| Step: 11
Training loss: 1.8705518245697021
Validation loss: 2.0739870276502383

Epoch: 6| Step: 12
Training loss: 1.2111884355545044
Validation loss: 2.0736876815877934

Epoch: 6| Step: 13
Training loss: 1.1996186971664429
Validation loss: 2.0712333392071467

Epoch: 259| Step: 0
Training loss: 1.8260154724121094
Validation loss: 2.045945172668785

Epoch: 6| Step: 1
Training loss: 2.0395359992980957
Validation loss: 2.073070946560111

Epoch: 6| Step: 2
Training loss: 1.2183599472045898
Validation loss: 2.064486495910152

Epoch: 6| Step: 3
Training loss: 1.6721522808074951
Validation loss: 2.056241532807709

Epoch: 6| Step: 4
Training loss: 2.226043224334717
Validation loss: 2.0546293143303163

Epoch: 6| Step: 5
Training loss: 1.874485969543457
Validation loss: 2.038311962158449

Epoch: 6| Step: 6
Training loss: 1.6613036394119263
Validation loss: 2.0473354708763862

Epoch: 6| Step: 7
Training loss: 2.1740121841430664
Validation loss: 2.024645233667025

Epoch: 6| Step: 8
Training loss: 1.6098322868347168
Validation loss: 2.050130101942247

Epoch: 6| Step: 9
Training loss: 1.7198221683502197
Validation loss: 2.060209410164946

Epoch: 6| Step: 10
Training loss: 1.6617457866668701
Validation loss: 2.0262530747280327

Epoch: 6| Step: 11
Training loss: 2.2753615379333496
Validation loss: 2.073904461758111

Epoch: 6| Step: 12
Training loss: 2.0027222633361816
Validation loss: 2.0514721844785955

Epoch: 6| Step: 13
Training loss: 1.7684299945831299
Validation loss: 2.038162657009658

Epoch: 260| Step: 0
Training loss: 2.94555926322937
Validation loss: 2.050192133072884

Epoch: 6| Step: 1
Training loss: 2.159294605255127
Validation loss: 2.0499503356154247

Epoch: 6| Step: 2
Training loss: 2.023275375366211
Validation loss: 2.0601392638298774

Epoch: 6| Step: 3
Training loss: 1.3759390115737915
Validation loss: 2.053753269615994

Epoch: 6| Step: 4
Training loss: 1.7209515571594238
Validation loss: 2.078483550779281

Epoch: 6| Step: 5
Training loss: 1.2914929389953613
Validation loss: 2.0479397568651425

Epoch: 6| Step: 6
Training loss: 1.795865774154663
Validation loss: 2.034245611518942

Epoch: 6| Step: 7
Training loss: 1.3283518552780151
Validation loss: 2.0604138605056272

Epoch: 6| Step: 8
Training loss: 1.7037214040756226
Validation loss: 2.045421779796641

Epoch: 6| Step: 9
Training loss: 2.3977606296539307
Validation loss: 2.086774459449194

Epoch: 6| Step: 10
Training loss: 1.4770119190216064
Validation loss: 2.084465552401799

Epoch: 6| Step: 11
Training loss: 1.7237659692764282
Validation loss: 2.049131247305101

Epoch: 6| Step: 12
Training loss: 1.8358027935028076
Validation loss: 2.0680428217816096

Epoch: 6| Step: 13
Training loss: 2.294074535369873
Validation loss: 2.03468027294323

Epoch: 261| Step: 0
Training loss: 1.8323196172714233
Validation loss: 2.0819095001425794

Epoch: 6| Step: 1
Training loss: 2.2342123985290527
Validation loss: 2.064061209719668

Epoch: 6| Step: 2
Training loss: 2.1811165809631348
Validation loss: 2.037830801420314

Epoch: 6| Step: 3
Training loss: 1.904591679573059
Validation loss: 2.0689572826508553

Epoch: 6| Step: 4
Training loss: 2.136732339859009
Validation loss: 2.038102429400208

Epoch: 6| Step: 5
Training loss: 2.282789945602417
Validation loss: 2.0384004269876788

Epoch: 6| Step: 6
Training loss: 1.3730050325393677
Validation loss: 2.0750883651036087

Epoch: 6| Step: 7
Training loss: 2.21992564201355
Validation loss: 2.0538382350757556

Epoch: 6| Step: 8
Training loss: 2.0421183109283447
Validation loss: 2.0400805242599978

Epoch: 6| Step: 9
Training loss: 1.3666296005249023
Validation loss: 2.078836738422353

Epoch: 6| Step: 10
Training loss: 1.2258380651474
Validation loss: 2.0735057579573763

Epoch: 6| Step: 11
Training loss: 1.3210294246673584
Validation loss: 2.0865536582085396

Epoch: 6| Step: 12
Training loss: 1.7732232809066772
Validation loss: 2.0459959891534623

Epoch: 6| Step: 13
Training loss: 1.8367271423339844
Validation loss: 2.044003890406701

Epoch: 262| Step: 0
Training loss: 2.0010294914245605
Validation loss: 2.036195619131929

Epoch: 6| Step: 1
Training loss: 2.064685344696045
Validation loss: 2.0674665486940773

Epoch: 6| Step: 2
Training loss: 1.8125085830688477
Validation loss: 2.075420520638907

Epoch: 6| Step: 3
Training loss: 1.4133960008621216
Validation loss: 2.06464986647329

Epoch: 6| Step: 4
Training loss: 1.780739188194275
Validation loss: 2.0812992049801733

Epoch: 6| Step: 5
Training loss: 1.8549672365188599
Validation loss: 2.0752978504344983

Epoch: 6| Step: 6
Training loss: 1.7052643299102783
Validation loss: 2.0725830857471754

Epoch: 6| Step: 7
Training loss: 2.558854341506958
Validation loss: 2.0701659879376813

Epoch: 6| Step: 8
Training loss: 2.7230310440063477
Validation loss: 2.071083668739565

Epoch: 6| Step: 9
Training loss: 1.9358540773391724
Validation loss: 2.0701837834491523

Epoch: 6| Step: 10
Training loss: 1.4526679515838623
Validation loss: 2.06397932575595

Epoch: 6| Step: 11
Training loss: 1.4736319780349731
Validation loss: 2.052474303912091

Epoch: 6| Step: 12
Training loss: 1.3181164264678955
Validation loss: 2.0800743385027816

Epoch: 6| Step: 13
Training loss: 1.2485469579696655
Validation loss: 2.0694506527275167

Epoch: 263| Step: 0
Training loss: 1.7079180479049683
Validation loss: 2.1056602244736045

Epoch: 6| Step: 1
Training loss: 2.1268067359924316
Validation loss: 2.0115860521152453

Epoch: 6| Step: 2
Training loss: 1.8509433269500732
Validation loss: 2.050357908330938

Epoch: 6| Step: 3
Training loss: 1.5517797470092773
Validation loss: 2.076195773258004

Epoch: 6| Step: 4
Training loss: 1.814266562461853
Validation loss: 2.0772292434528308

Epoch: 6| Step: 5
Training loss: 1.4931720495224
Validation loss: 2.028461092261858

Epoch: 6| Step: 6
Training loss: 1.287797451019287
Validation loss: 2.029513466742731

Epoch: 6| Step: 7
Training loss: 2.071676731109619
Validation loss: 2.052294877267653

Epoch: 6| Step: 8
Training loss: 1.5131115913391113
Validation loss: 2.059604493520593

Epoch: 6| Step: 9
Training loss: 2.422283172607422
Validation loss: 2.0560548920785227

Epoch: 6| Step: 10
Training loss: 1.8800933361053467
Validation loss: 2.065358045280621

Epoch: 6| Step: 11
Training loss: 2.245798110961914
Validation loss: 2.0679488028249433

Epoch: 6| Step: 12
Training loss: 2.116162061691284
Validation loss: 2.0573931150538947

Epoch: 6| Step: 13
Training loss: 1.2231669425964355
Validation loss: 2.0558773189462642

Epoch: 264| Step: 0
Training loss: 1.5251898765563965
Validation loss: 2.042963109990602

Epoch: 6| Step: 1
Training loss: 2.358388662338257
Validation loss: 2.0197739857499317

Epoch: 6| Step: 2
Training loss: 2.12576961517334
Validation loss: 2.049622901024357

Epoch: 6| Step: 3
Training loss: 1.349775791168213
Validation loss: 2.0416715670657415

Epoch: 6| Step: 4
Training loss: 1.9484649896621704
Validation loss: 2.07619281225307

Epoch: 6| Step: 5
Training loss: 2.7127797603607178
Validation loss: 2.073655378433966

Epoch: 6| Step: 6
Training loss: 2.0292890071868896
Validation loss: 2.0139869489977436

Epoch: 6| Step: 7
Training loss: 1.3241075277328491
Validation loss: 2.0566322534315047

Epoch: 6| Step: 8
Training loss: 2.053968667984009
Validation loss: 2.051920642134964

Epoch: 6| Step: 9
Training loss: 1.6332895755767822
Validation loss: 2.0658057428175405

Epoch: 6| Step: 10
Training loss: 2.1097865104675293
Validation loss: 2.0513042173077984

Epoch: 6| Step: 11
Training loss: 0.7538174390792847
Validation loss: 2.05682433548794

Epoch: 6| Step: 12
Training loss: 1.8339213132858276
Validation loss: 2.0408359958279516

Epoch: 6| Step: 13
Training loss: 1.9128273725509644
Validation loss: 2.0508399137886624

Epoch: 265| Step: 0
Training loss: 1.3919212818145752
Validation loss: 2.066647816729802

Epoch: 6| Step: 1
Training loss: 1.329624056816101
Validation loss: 2.034544380762244

Epoch: 6| Step: 2
Training loss: 2.410458564758301
Validation loss: 2.0325424427627237

Epoch: 6| Step: 3
Training loss: 1.598930835723877
Validation loss: 2.06783640000128

Epoch: 6| Step: 4
Training loss: 1.287614345550537
Validation loss: 2.0458025752857165

Epoch: 6| Step: 5
Training loss: 1.8491723537445068
Validation loss: 2.0056235738979873

Epoch: 6| Step: 6
Training loss: 2.297222137451172
Validation loss: 2.038985134452902

Epoch: 6| Step: 7
Training loss: 1.4114104509353638
Validation loss: 2.045224766577444

Epoch: 6| Step: 8
Training loss: 1.9396804571151733
Validation loss: 2.0802613176325315

Epoch: 6| Step: 9
Training loss: 1.9930955171585083
Validation loss: 2.0402372498666086

Epoch: 6| Step: 10
Training loss: 2.413567304611206
Validation loss: 2.062962894798607

Epoch: 6| Step: 11
Training loss: 2.143160343170166
Validation loss: 2.04511760639888

Epoch: 6| Step: 12
Training loss: 2.140880823135376
Validation loss: 2.055589516957601

Epoch: 6| Step: 13
Training loss: 0.7531247735023499
Validation loss: 2.0545021257092877

Epoch: 266| Step: 0
Training loss: 1.6656103134155273
Validation loss: 2.061096022205968

Epoch: 6| Step: 1
Training loss: 0.6707783341407776
Validation loss: 2.0552713101910007

Epoch: 6| Step: 2
Training loss: 1.931230068206787
Validation loss: 2.0630865135500507

Epoch: 6| Step: 3
Training loss: 2.295832872390747
Validation loss: 2.056153784516037

Epoch: 6| Step: 4
Training loss: 1.7922545671463013
Validation loss: 2.0617141133995465

Epoch: 6| Step: 5
Training loss: 1.9689247608184814
Validation loss: 2.0602073028523433

Epoch: 6| Step: 6
Training loss: 1.7074801921844482
Validation loss: 2.0491785798021542

Epoch: 6| Step: 7
Training loss: 2.365821361541748
Validation loss: 2.0303253819865565

Epoch: 6| Step: 8
Training loss: 2.383070707321167
Validation loss: 2.0805767402854016

Epoch: 6| Step: 9
Training loss: 1.246954321861267
Validation loss: 2.045987149720551

Epoch: 6| Step: 10
Training loss: 1.67442786693573
Validation loss: 2.0721491382968042

Epoch: 6| Step: 11
Training loss: 2.153238296508789
Validation loss: 2.035005073393545

Epoch: 6| Step: 12
Training loss: 2.29516863822937
Validation loss: 2.04686136399546

Epoch: 6| Step: 13
Training loss: 1.3443145751953125
Validation loss: 2.0456568118064635

Epoch: 267| Step: 0
Training loss: 1.5319833755493164
Validation loss: 2.0214574901006555

Epoch: 6| Step: 1
Training loss: 1.7060211896896362
Validation loss: 2.0570590265335573

Epoch: 6| Step: 2
Training loss: 1.9784140586853027
Validation loss: 2.0485422816327823

Epoch: 6| Step: 3
Training loss: 1.327133297920227
Validation loss: 2.036500398830701

Epoch: 6| Step: 4
Training loss: 2.0658798217773438
Validation loss: 2.0684314607292094

Epoch: 6| Step: 5
Training loss: 1.9272949695587158
Validation loss: 2.066093021823514

Epoch: 6| Step: 6
Training loss: 1.9618908166885376
Validation loss: 2.075452152118888

Epoch: 6| Step: 7
Training loss: 1.3123598098754883
Validation loss: 2.0686343459672827

Epoch: 6| Step: 8
Training loss: 1.9542796611785889
Validation loss: 2.0763093656109226

Epoch: 6| Step: 9
Training loss: 2.0332283973693848
Validation loss: 2.045899546274575

Epoch: 6| Step: 10
Training loss: 2.517963409423828
Validation loss: 2.0485594887887277

Epoch: 6| Step: 11
Training loss: 1.0848114490509033
Validation loss: 2.0619992389473865

Epoch: 6| Step: 12
Training loss: 2.1483004093170166
Validation loss: 2.0496158548580703

Epoch: 6| Step: 13
Training loss: 1.7414101362228394
Validation loss: 2.043818580207004

Epoch: 268| Step: 0
Training loss: 1.8807238340377808
Validation loss: 2.064694330256472

Epoch: 6| Step: 1
Training loss: 1.7712180614471436
Validation loss: 2.0641303703349125

Epoch: 6| Step: 2
Training loss: 2.340726137161255
Validation loss: 2.0681473311557563

Epoch: 6| Step: 3
Training loss: 1.8564364910125732
Validation loss: 2.053582194030926

Epoch: 6| Step: 4
Training loss: 2.1225879192352295
Validation loss: 2.0951803756016556

Epoch: 6| Step: 5
Training loss: 1.7677048444747925
Validation loss: 2.0832561908229703

Epoch: 6| Step: 6
Training loss: 2.0059635639190674
Validation loss: 2.0708953680530673

Epoch: 6| Step: 7
Training loss: 1.6714417934417725
Validation loss: 2.0589262823904715

Epoch: 6| Step: 8
Training loss: 1.4387609958648682
Validation loss: 2.0856874553106164

Epoch: 6| Step: 9
Training loss: 1.7360169887542725
Validation loss: 2.077338357125559

Epoch: 6| Step: 10
Training loss: 2.216714859008789
Validation loss: 2.0973552068074546

Epoch: 6| Step: 11
Training loss: 1.7440485954284668
Validation loss: 2.0679624593386086

Epoch: 6| Step: 12
Training loss: 1.4391562938690186
Validation loss: 2.0482485601978917

Epoch: 6| Step: 13
Training loss: 1.6508417129516602
Validation loss: 2.0256541313663607

Epoch: 269| Step: 0
Training loss: 2.1543455123901367
Validation loss: 2.06463219529839

Epoch: 6| Step: 1
Training loss: 2.570606231689453
Validation loss: 2.083772510610601

Epoch: 6| Step: 2
Training loss: 1.4637491703033447
Validation loss: 2.024496086182133

Epoch: 6| Step: 3
Training loss: 1.933889627456665
Validation loss: 2.061874217884515

Epoch: 6| Step: 4
Training loss: 1.5068726539611816
Validation loss: 2.030902129347606

Epoch: 6| Step: 5
Training loss: 2.487168788909912
Validation loss: 2.0662437562019593

Epoch: 6| Step: 6
Training loss: 2.196563720703125
Validation loss: 2.0611313337920816

Epoch: 6| Step: 7
Training loss: 2.0603740215301514
Validation loss: 2.05614213789663

Epoch: 6| Step: 8
Training loss: 0.9972561597824097
Validation loss: 2.010287023359729

Epoch: 6| Step: 9
Training loss: 1.6134425401687622
Validation loss: 2.0685788777566727

Epoch: 6| Step: 10
Training loss: 1.9479255676269531
Validation loss: 2.0692092654525593

Epoch: 6| Step: 11
Training loss: 1.6081643104553223
Validation loss: 2.071681313617255

Epoch: 6| Step: 12
Training loss: 1.0206074714660645
Validation loss: 2.0330992193632227

Epoch: 6| Step: 13
Training loss: 1.0067172050476074
Validation loss: 2.0640936205464024

Epoch: 270| Step: 0
Training loss: 2.4571878910064697
Validation loss: 2.030245897590473

Epoch: 6| Step: 1
Training loss: 1.832329511642456
Validation loss: 2.0604541468363937

Epoch: 6| Step: 2
Training loss: 1.5422178506851196
Validation loss: 2.0902844872525943

Epoch: 6| Step: 3
Training loss: 2.4343276023864746
Validation loss: 2.0472507656261487

Epoch: 6| Step: 4
Training loss: 1.8354146480560303
Validation loss: 2.04813737510353

Epoch: 6| Step: 5
Training loss: 1.732738733291626
Validation loss: 2.055499017879527

Epoch: 6| Step: 6
Training loss: 0.9613801836967468
Validation loss: 2.09747023992641

Epoch: 6| Step: 7
Training loss: 2.019880533218384
Validation loss: 2.045752786820935

Epoch: 6| Step: 8
Training loss: 1.495682716369629
Validation loss: 2.0742922675225044

Epoch: 6| Step: 9
Training loss: 1.4062623977661133
Validation loss: 2.041582440817228

Epoch: 6| Step: 10
Training loss: 1.8918251991271973
Validation loss: 2.080514174635692

Epoch: 6| Step: 11
Training loss: 2.072153091430664
Validation loss: 2.0463088609839

Epoch: 6| Step: 12
Training loss: 1.7487140893936157
Validation loss: 2.0677401429863385

Epoch: 6| Step: 13
Training loss: 1.763796091079712
Validation loss: 2.095951008540328

Epoch: 271| Step: 0
Training loss: 1.6961817741394043
Validation loss: 2.058365346283041

Epoch: 6| Step: 1
Training loss: 1.433053970336914
Validation loss: 2.070250670115153

Epoch: 6| Step: 2
Training loss: 1.6426737308502197
Validation loss: 2.0938916206359863

Epoch: 6| Step: 3
Training loss: 1.7155925035476685
Validation loss: 2.083917192233506

Epoch: 6| Step: 4
Training loss: 1.3022725582122803
Validation loss: 2.0512928860161894

Epoch: 6| Step: 5
Training loss: 2.182746648788452
Validation loss: 2.0667970462511946

Epoch: 6| Step: 6
Training loss: 2.208941698074341
Validation loss: 2.072254196290047

Epoch: 6| Step: 7
Training loss: 1.3120269775390625
Validation loss: 2.0676418555680143

Epoch: 6| Step: 8
Training loss: 2.234771966934204
Validation loss: 2.067084309875324

Epoch: 6| Step: 9
Training loss: 1.7976751327514648
Validation loss: 2.039204033472205

Epoch: 6| Step: 10
Training loss: 1.8581665754318237
Validation loss: 2.0840799718774776

Epoch: 6| Step: 11
Training loss: 2.3541464805603027
Validation loss: 2.0849675081109487

Epoch: 6| Step: 12
Training loss: 1.5832775831222534
Validation loss: 2.063920377403177

Epoch: 6| Step: 13
Training loss: 1.6847947835922241
Validation loss: 2.0459833811688166

Epoch: 272| Step: 0
Training loss: 1.4815865755081177
Validation loss: 2.0581486045673327

Epoch: 6| Step: 1
Training loss: 1.9812071323394775
Validation loss: 2.049694602207471

Epoch: 6| Step: 2
Training loss: 1.5849547386169434
Validation loss: 2.0802949654158724

Epoch: 6| Step: 3
Training loss: 1.629852533340454
Validation loss: 2.067306531372891

Epoch: 6| Step: 4
Training loss: 1.3358134031295776
Validation loss: 2.0260961350574287

Epoch: 6| Step: 5
Training loss: 1.4536148309707642
Validation loss: 2.093159282079307

Epoch: 6| Step: 6
Training loss: 1.1192212104797363
Validation loss: 2.031916082546275

Epoch: 6| Step: 7
Training loss: 2.63668155670166
Validation loss: 2.068840843375011

Epoch: 6| Step: 8
Training loss: 2.867283821105957
Validation loss: 2.033679203320575

Epoch: 6| Step: 9
Training loss: 1.904879093170166
Validation loss: 2.024324632460071

Epoch: 6| Step: 10
Training loss: 1.7688939571380615
Validation loss: 2.041834985056231

Epoch: 6| Step: 11
Training loss: 1.7811537981033325
Validation loss: 2.060904102940713

Epoch: 6| Step: 12
Training loss: 2.44417405128479
Validation loss: 2.0388510329748994

Epoch: 6| Step: 13
Training loss: 1.1529380083084106
Validation loss: 2.0706324705513577

Epoch: 273| Step: 0
Training loss: 1.728213906288147
Validation loss: 2.0760909383014967

Epoch: 6| Step: 1
Training loss: 1.4541137218475342
Validation loss: 2.0806458714187785

Epoch: 6| Step: 2
Training loss: 1.9960567951202393
Validation loss: 2.084953269650859

Epoch: 6| Step: 3
Training loss: 1.4932513236999512
Validation loss: 2.071138128157585

Epoch: 6| Step: 4
Training loss: 2.174729347229004
Validation loss: 2.1114111228655745

Epoch: 6| Step: 5
Training loss: 1.385324239730835
Validation loss: 2.1293505212312103

Epoch: 6| Step: 6
Training loss: 1.8821768760681152
Validation loss: 2.1058268252239434

Epoch: 6| Step: 7
Training loss: 1.7811167240142822
Validation loss: 2.0847896837419078

Epoch: 6| Step: 8
Training loss: 1.9221171140670776
Validation loss: 2.1174701285618607

Epoch: 6| Step: 9
Training loss: 1.4877240657806396
Validation loss: 2.091974498123251

Epoch: 6| Step: 10
Training loss: 2.0197157859802246
Validation loss: 2.1198561627377748

Epoch: 6| Step: 11
Training loss: 2.690800666809082
Validation loss: 2.082784955219556

Epoch: 6| Step: 12
Training loss: 1.8124703168869019
Validation loss: 2.0983552855830037

Epoch: 6| Step: 13
Training loss: 1.4586418867111206
Validation loss: 2.0467349201120357

Epoch: 274| Step: 0
Training loss: 1.9186067581176758
Validation loss: 2.0554247274193713

Epoch: 6| Step: 1
Training loss: 1.9103429317474365
Validation loss: 2.062668918281473

Epoch: 6| Step: 2
Training loss: 0.8444699048995972
Validation loss: 2.0477579921804447

Epoch: 6| Step: 3
Training loss: 1.637453556060791
Validation loss: 2.0673705031794887

Epoch: 6| Step: 4
Training loss: 2.2694194316864014
Validation loss: 2.0499737570362706

Epoch: 6| Step: 5
Training loss: 1.8504385948181152
Validation loss: 2.071682132700438

Epoch: 6| Step: 6
Training loss: 1.991927981376648
Validation loss: 2.0507497864384807

Epoch: 6| Step: 7
Training loss: 1.91016685962677
Validation loss: 2.042643389394206

Epoch: 6| Step: 8
Training loss: 2.147427558898926
Validation loss: 2.037460711694533

Epoch: 6| Step: 9
Training loss: 1.7914849519729614
Validation loss: 2.039236021298234

Epoch: 6| Step: 10
Training loss: 1.7092618942260742
Validation loss: 2.0432705674120175

Epoch: 6| Step: 11
Training loss: 2.0019240379333496
Validation loss: 2.0691321511422434

Epoch: 6| Step: 12
Training loss: 1.6215423345565796
Validation loss: 2.0234959843338176

Epoch: 6| Step: 13
Training loss: 1.556105613708496
Validation loss: 2.049970531976351

Epoch: 275| Step: 0
Training loss: 1.6434550285339355
Validation loss: 2.0479291831293414

Epoch: 6| Step: 1
Training loss: 1.9748516082763672
Validation loss: 2.0372923176775695

Epoch: 6| Step: 2
Training loss: 1.28616201877594
Validation loss: 2.0415983020618396

Epoch: 6| Step: 3
Training loss: 1.7422494888305664
Validation loss: 2.0505154350752473

Epoch: 6| Step: 4
Training loss: 1.33677077293396
Validation loss: 2.0326409621905257

Epoch: 6| Step: 5
Training loss: 2.67240309715271
Validation loss: 2.042418820883638

Epoch: 6| Step: 6
Training loss: 1.9670097827911377
Validation loss: 2.0546535791889315

Epoch: 6| Step: 7
Training loss: 1.8878867626190186
Validation loss: 2.069355721114784

Epoch: 6| Step: 8
Training loss: 1.8480089902877808
Validation loss: 2.0538448659322595

Epoch: 6| Step: 9
Training loss: 1.509640097618103
Validation loss: 2.084734529577276

Epoch: 6| Step: 10
Training loss: 1.7254600524902344
Validation loss: 2.044894292790403

Epoch: 6| Step: 11
Training loss: 2.3460745811462402
Validation loss: 2.063814560572306

Epoch: 6| Step: 12
Training loss: 2.1391682624816895
Validation loss: 2.084573689327445

Epoch: 6| Step: 13
Training loss: 1.0997371673583984
Validation loss: 2.0914546674297703

Epoch: 276| Step: 0
Training loss: 1.7215949296951294
Validation loss: 2.0827786512272333

Epoch: 6| Step: 1
Training loss: 1.3938474655151367
Validation loss: 2.0452715043098695

Epoch: 6| Step: 2
Training loss: 2.2434544563293457
Validation loss: 2.0628050181173507

Epoch: 6| Step: 3
Training loss: 1.821805477142334
Validation loss: 2.046453963043869

Epoch: 6| Step: 4
Training loss: 1.4338288307189941
Validation loss: 2.079037006183337

Epoch: 6| Step: 5
Training loss: 1.964219093322754
Validation loss: 2.04105318233531

Epoch: 6| Step: 6
Training loss: 1.2917684316635132
Validation loss: 2.0440940997933827

Epoch: 6| Step: 7
Training loss: 1.9537889957427979
Validation loss: 2.0962149135528074

Epoch: 6| Step: 8
Training loss: 1.7334665060043335
Validation loss: 2.050756626231696

Epoch: 6| Step: 9
Training loss: 1.6183422803878784
Validation loss: 2.0610400835673013

Epoch: 6| Step: 10
Training loss: 2.276059627532959
Validation loss: 2.0725776636472313

Epoch: 6| Step: 11
Training loss: 2.1444520950317383
Validation loss: 2.0312542658980175

Epoch: 6| Step: 12
Training loss: 1.776896357536316
Validation loss: 2.0594793993939637

Epoch: 6| Step: 13
Training loss: 2.325450897216797
Validation loss: 2.0117602579055296

Epoch: 277| Step: 0
Training loss: 1.6492877006530762
Validation loss: 2.042760977181055

Epoch: 6| Step: 1
Training loss: 2.2129766941070557
Validation loss: 2.04637288278149

Epoch: 6| Step: 2
Training loss: 2.050478935241699
Validation loss: 2.0694644310141124

Epoch: 6| Step: 3
Training loss: 1.9099998474121094
Validation loss: 2.089537347516706

Epoch: 6| Step: 4
Training loss: 1.6776093244552612
Validation loss: 2.0884094071644608

Epoch: 6| Step: 5
Training loss: 1.6209639310836792
Validation loss: 2.053937958132836

Epoch: 6| Step: 6
Training loss: 1.956263542175293
Validation loss: 2.0635117612859255

Epoch: 6| Step: 7
Training loss: 2.0875797271728516
Validation loss: 2.0372406616005847

Epoch: 6| Step: 8
Training loss: 1.422093152999878
Validation loss: 2.05594834332825

Epoch: 6| Step: 9
Training loss: 1.8759839534759521
Validation loss: 2.080732273799117

Epoch: 6| Step: 10
Training loss: 1.8668203353881836
Validation loss: 2.0595412408151934

Epoch: 6| Step: 11
Training loss: 1.670703649520874
Validation loss: 2.0500378890704085

Epoch: 6| Step: 12
Training loss: 1.3365025520324707
Validation loss: 2.0621087961299445

Epoch: 6| Step: 13
Training loss: 1.912731647491455
Validation loss: 2.0950102549727245

Epoch: 278| Step: 0
Training loss: 2.4300379753112793
Validation loss: 2.060863270554491

Epoch: 6| Step: 1
Training loss: 1.7876209020614624
Validation loss: 2.0572528172564764

Epoch: 6| Step: 2
Training loss: 2.278834104537964
Validation loss: 2.0548049121774654

Epoch: 6| Step: 3
Training loss: 2.135723829269409
Validation loss: 2.054104992138442

Epoch: 6| Step: 4
Training loss: 1.0915367603302002
Validation loss: 2.080518866098055

Epoch: 6| Step: 5
Training loss: 1.416257381439209
Validation loss: 2.087642215913342

Epoch: 6| Step: 6
Training loss: 2.711211681365967
Validation loss: 2.0762479869268273

Epoch: 6| Step: 7
Training loss: 1.3416595458984375
Validation loss: 2.0454447859077045

Epoch: 6| Step: 8
Training loss: 1.7294859886169434
Validation loss: 2.077319065729777

Epoch: 6| Step: 9
Training loss: 1.333591341972351
Validation loss: 2.0531317187893774

Epoch: 6| Step: 10
Training loss: 1.8867555856704712
Validation loss: 2.057567024743685

Epoch: 6| Step: 11
Training loss: 2.1987314224243164
Validation loss: 2.0678577999914847

Epoch: 6| Step: 12
Training loss: 1.3295944929122925
Validation loss: 2.0431897717137493

Epoch: 6| Step: 13
Training loss: 1.4934215545654297
Validation loss: 2.060105367373395

Epoch: 279| Step: 0
Training loss: 2.277985095977783
Validation loss: 2.0650299428611674

Epoch: 6| Step: 1
Training loss: 1.5161598920822144
Validation loss: 2.061334793285657

Epoch: 6| Step: 2
Training loss: 2.4708755016326904
Validation loss: 2.035246188922595

Epoch: 6| Step: 3
Training loss: 2.11883544921875
Validation loss: 2.083105989681777

Epoch: 6| Step: 4
Training loss: 1.561985969543457
Validation loss: 2.066509877481768

Epoch: 6| Step: 5
Training loss: 1.4348584413528442
Validation loss: 2.0340688972062964

Epoch: 6| Step: 6
Training loss: 2.160914659500122
Validation loss: 2.0734968621243715

Epoch: 6| Step: 7
Training loss: 1.647895336151123
Validation loss: 2.062785925403718

Epoch: 6| Step: 8
Training loss: 1.1536445617675781
Validation loss: 2.061100882868613

Epoch: 6| Step: 9
Training loss: 2.0633318424224854
Validation loss: 2.063873424324938

Epoch: 6| Step: 10
Training loss: 1.2611780166625977
Validation loss: 2.051916786419448

Epoch: 6| Step: 11
Training loss: 1.8298077583312988
Validation loss: 2.053727290963614

Epoch: 6| Step: 12
Training loss: 1.8502051830291748
Validation loss: 2.0459382713481946

Epoch: 6| Step: 13
Training loss: 1.7725157737731934
Validation loss: 2.043278019915345

Epoch: 280| Step: 0
Training loss: 2.1155033111572266
Validation loss: 2.055864372561055

Epoch: 6| Step: 1
Training loss: 1.9622681140899658
Validation loss: 2.057229390708349

Epoch: 6| Step: 2
Training loss: 1.2898187637329102
Validation loss: 2.036328669517271

Epoch: 6| Step: 3
Training loss: 1.6036372184753418
Validation loss: 2.079114447357834

Epoch: 6| Step: 4
Training loss: 2.142005443572998
Validation loss: 2.0681453263887795

Epoch: 6| Step: 5
Training loss: 2.2226181030273438
Validation loss: 2.0312502320094774

Epoch: 6| Step: 6
Training loss: 1.651965856552124
Validation loss: 2.0674479802449546

Epoch: 6| Step: 7
Training loss: 1.4988335371017456
Validation loss: 2.0446749297521447

Epoch: 6| Step: 8
Training loss: 1.7024612426757812
Validation loss: 2.0219602008019724

Epoch: 6| Step: 9
Training loss: 2.01889705657959
Validation loss: 2.0535544374937653

Epoch: 6| Step: 10
Training loss: 1.3969964981079102
Validation loss: 2.0339460654925277

Epoch: 6| Step: 11
Training loss: 1.963482141494751
Validation loss: 2.081763664881388

Epoch: 6| Step: 12
Training loss: 1.5775508880615234
Validation loss: 2.0843696119964763

Epoch: 6| Step: 13
Training loss: 1.4967271089553833
Validation loss: 2.097139755884806

Epoch: 281| Step: 0
Training loss: 1.657562255859375
Validation loss: 2.0573075843113724

Epoch: 6| Step: 1
Training loss: 1.7439581155776978
Validation loss: 2.0788654550429313

Epoch: 6| Step: 2
Training loss: 1.789480447769165
Validation loss: 2.0553697834732714

Epoch: 6| Step: 3
Training loss: 2.218073844909668
Validation loss: 2.095075079189834

Epoch: 6| Step: 4
Training loss: 2.556259870529175
Validation loss: 2.055355043821437

Epoch: 6| Step: 5
Training loss: 1.6569676399230957
Validation loss: 2.098281278405138

Epoch: 6| Step: 6
Training loss: 1.5794895887374878
Validation loss: 2.1034302865305254

Epoch: 6| Step: 7
Training loss: 1.8343985080718994
Validation loss: 2.1023427030091644

Epoch: 6| Step: 8
Training loss: 1.6739951372146606
Validation loss: 2.064362500303535

Epoch: 6| Step: 9
Training loss: 1.6991779804229736
Validation loss: 2.067674390731319

Epoch: 6| Step: 10
Training loss: 1.466444730758667
Validation loss: 2.0484372518395864

Epoch: 6| Step: 11
Training loss: 1.362804889678955
Validation loss: 2.0659527804261897

Epoch: 6| Step: 12
Training loss: 1.9995067119598389
Validation loss: 2.073406923201776

Epoch: 6| Step: 13
Training loss: 1.720676302909851
Validation loss: 2.072050227913805

Epoch: 282| Step: 0
Training loss: 2.12042236328125
Validation loss: 2.073947180983841

Epoch: 6| Step: 1
Training loss: 1.8205910921096802
Validation loss: 2.064383522156746

Epoch: 6| Step: 2
Training loss: 2.6098127365112305
Validation loss: 2.0516674685221847

Epoch: 6| Step: 3
Training loss: 1.8243476152420044
Validation loss: 2.066071620551489

Epoch: 6| Step: 4
Training loss: 1.6565507650375366
Validation loss: 2.0336395745636313

Epoch: 6| Step: 5
Training loss: 1.947615385055542
Validation loss: 2.026015712368873

Epoch: 6| Step: 6
Training loss: 1.151809811592102
Validation loss: 2.048468961510607

Epoch: 6| Step: 7
Training loss: 1.4937362670898438
Validation loss: 2.08829334474379

Epoch: 6| Step: 8
Training loss: 2.025083303451538
Validation loss: 2.037100358675885

Epoch: 6| Step: 9
Training loss: 1.6032440662384033
Validation loss: 2.057157644661524

Epoch: 6| Step: 10
Training loss: 1.3588600158691406
Validation loss: 2.062620042472757

Epoch: 6| Step: 11
Training loss: 2.1423749923706055
Validation loss: 2.057637014696675

Epoch: 6| Step: 12
Training loss: 1.8170174360275269
Validation loss: 2.0449016453117452

Epoch: 6| Step: 13
Training loss: 1.7078468799591064
Validation loss: 2.0514804445287234

Epoch: 283| Step: 0
Training loss: 2.060668468475342
Validation loss: 2.04824246129682

Epoch: 6| Step: 1
Training loss: 1.2988314628601074
Validation loss: 2.070502964399194

Epoch: 6| Step: 2
Training loss: 0.9353185892105103
Validation loss: 2.079475179795296

Epoch: 6| Step: 3
Training loss: 2.3277597427368164
Validation loss: 2.0681616003795336

Epoch: 6| Step: 4
Training loss: 2.358830451965332
Validation loss: 2.0799698701468845

Epoch: 6| Step: 5
Training loss: 1.1544301509857178
Validation loss: 2.0935154089363675

Epoch: 6| Step: 6
Training loss: 2.1295909881591797
Validation loss: 2.087091515141149

Epoch: 6| Step: 7
Training loss: 2.063450813293457
Validation loss: 2.09340182171073

Epoch: 6| Step: 8
Training loss: 1.7459852695465088
Validation loss: 2.083396323265568

Epoch: 6| Step: 9
Training loss: 1.8066511154174805
Validation loss: 2.081536614766685

Epoch: 6| Step: 10
Training loss: 1.4371933937072754
Validation loss: 2.111226048520816

Epoch: 6| Step: 11
Training loss: 2.3163089752197266
Validation loss: 2.0946365248772407

Epoch: 6| Step: 12
Training loss: 1.6758266687393188
Validation loss: 2.084406905276801

Epoch: 6| Step: 13
Training loss: 1.380306601524353
Validation loss: 2.0727176896987425

Epoch: 284| Step: 0
Training loss: 2.0549087524414062
Validation loss: 2.101017634073893

Epoch: 6| Step: 1
Training loss: 1.6676595211029053
Validation loss: 2.109365424802226

Epoch: 6| Step: 2
Training loss: 1.5100059509277344
Validation loss: 2.061500741589454

Epoch: 6| Step: 3
Training loss: 2.3129217624664307
Validation loss: 2.0951340160062237

Epoch: 6| Step: 4
Training loss: 2.0313358306884766
Validation loss: 2.0874614331030075

Epoch: 6| Step: 5
Training loss: 2.467885732650757
Validation loss: 2.0931365797596593

Epoch: 6| Step: 6
Training loss: 1.5919079780578613
Validation loss: 2.057236538138441

Epoch: 6| Step: 7
Training loss: 0.9791088104248047
Validation loss: 2.054597664904851

Epoch: 6| Step: 8
Training loss: 1.390640139579773
Validation loss: 2.0941431048095867

Epoch: 6| Step: 9
Training loss: 2.1404385566711426
Validation loss: 2.0339314488954443

Epoch: 6| Step: 10
Training loss: 1.8282203674316406
Validation loss: 2.084562627218103

Epoch: 6| Step: 11
Training loss: 1.6184492111206055
Validation loss: 2.043945509900329

Epoch: 6| Step: 12
Training loss: 1.8958098888397217
Validation loss: 2.07272695854146

Epoch: 6| Step: 13
Training loss: 1.3811707496643066
Validation loss: 2.08300615895179

Epoch: 285| Step: 0
Training loss: 1.937462329864502
Validation loss: 2.069223524421774

Epoch: 6| Step: 1
Training loss: 1.242008090019226
Validation loss: 2.0732195608077513

Epoch: 6| Step: 2
Training loss: 2.274183988571167
Validation loss: 2.0254838787099367

Epoch: 6| Step: 3
Training loss: 1.6563397645950317
Validation loss: 2.042309538010628

Epoch: 6| Step: 4
Training loss: 1.325667381286621
Validation loss: 2.089041035662415

Epoch: 6| Step: 5
Training loss: 1.8179868459701538
Validation loss: 2.07326877117157

Epoch: 6| Step: 6
Training loss: 1.6418108940124512
Validation loss: 2.037423436359693

Epoch: 6| Step: 7
Training loss: 1.216479778289795
Validation loss: 2.0379456679026284

Epoch: 6| Step: 8
Training loss: 2.3511316776275635
Validation loss: 2.0780861018806376

Epoch: 6| Step: 9
Training loss: 1.3264812231063843
Validation loss: 2.0880492900007512

Epoch: 6| Step: 10
Training loss: 1.5787547826766968
Validation loss: 2.073865814875531

Epoch: 6| Step: 11
Training loss: 1.985975980758667
Validation loss: 2.0491795462946736

Epoch: 6| Step: 12
Training loss: 2.2589709758758545
Validation loss: 2.090878539187934

Epoch: 6| Step: 13
Training loss: 2.817267417907715
Validation loss: 2.0834023209028345

Epoch: 286| Step: 0
Training loss: 1.765826940536499
Validation loss: 2.102285655595923

Epoch: 6| Step: 1
Training loss: 1.6616997718811035
Validation loss: 2.0667657518899567

Epoch: 6| Step: 2
Training loss: 1.5258697271347046
Validation loss: 2.0760970192570842

Epoch: 6| Step: 3
Training loss: 3.300067901611328
Validation loss: 2.0937374407245266

Epoch: 6| Step: 4
Training loss: 1.0042457580566406
Validation loss: 2.06506287154331

Epoch: 6| Step: 5
Training loss: 2.560607433319092
Validation loss: 2.061553926878078

Epoch: 6| Step: 6
Training loss: 1.1403812170028687
Validation loss: 2.0678232921067106

Epoch: 6| Step: 7
Training loss: 1.0046677589416504
Validation loss: 2.07098469426555

Epoch: 6| Step: 8
Training loss: 1.52213454246521
Validation loss: 2.0625858691430863

Epoch: 6| Step: 9
Training loss: 2.513805627822876
Validation loss: 2.052846085640692

Epoch: 6| Step: 10
Training loss: 1.5862548351287842
Validation loss: 2.0549051556535947

Epoch: 6| Step: 11
Training loss: 1.4713757038116455
Validation loss: 2.0666232544888734

Epoch: 6| Step: 12
Training loss: 2.20639967918396
Validation loss: 2.043759307553691

Epoch: 6| Step: 13
Training loss: 1.252424716949463
Validation loss: 2.059534308730915

Epoch: 287| Step: 0
Training loss: 1.1243796348571777
Validation loss: 2.055795728519399

Epoch: 6| Step: 1
Training loss: 1.408433198928833
Validation loss: 2.045134926355013

Epoch: 6| Step: 2
Training loss: 1.7959086894989014
Validation loss: 2.083727372589932

Epoch: 6| Step: 3
Training loss: 1.9260587692260742
Validation loss: 2.0552844962766095

Epoch: 6| Step: 4
Training loss: 2.4104115962982178
Validation loss: 2.0556943596050306

Epoch: 6| Step: 5
Training loss: 1.1127620935440063
Validation loss: 2.0531006436194144

Epoch: 6| Step: 6
Training loss: 1.7937653064727783
Validation loss: 2.0189913601003666

Epoch: 6| Step: 7
Training loss: 2.37812876701355
Validation loss: 2.051651621377596

Epoch: 6| Step: 8
Training loss: 1.4818594455718994
Validation loss: 2.0469955193099154

Epoch: 6| Step: 9
Training loss: 1.8115984201431274
Validation loss: 2.0442107979969313

Epoch: 6| Step: 10
Training loss: 2.0633480548858643
Validation loss: 2.034454914831346

Epoch: 6| Step: 11
Training loss: 2.611440658569336
Validation loss: 2.05489481008181

Epoch: 6| Step: 12
Training loss: 1.3935731649398804
Validation loss: 2.053639465762723

Epoch: 6| Step: 13
Training loss: 1.7873826026916504
Validation loss: 2.09895089621185

Epoch: 288| Step: 0
Training loss: 1.6613366603851318
Validation loss: 2.0380930182754353

Epoch: 6| Step: 1
Training loss: 1.3103411197662354
Validation loss: 2.0427575739481116

Epoch: 6| Step: 2
Training loss: 0.7935444116592407
Validation loss: 2.0781065610147293

Epoch: 6| Step: 3
Training loss: 1.6655054092407227
Validation loss: 2.0645199027112735

Epoch: 6| Step: 4
Training loss: 2.270310878753662
Validation loss: 2.0345637721400105

Epoch: 6| Step: 5
Training loss: 1.9557578563690186
Validation loss: 2.0459380662569435

Epoch: 6| Step: 6
Training loss: 2.1580100059509277
Validation loss: 2.057568689828278

Epoch: 6| Step: 7
Training loss: 1.939070463180542
Validation loss: 2.0627547720427155

Epoch: 6| Step: 8
Training loss: 1.6003150939941406
Validation loss: 2.055513212757726

Epoch: 6| Step: 9
Training loss: 2.095829963684082
Validation loss: 2.0644735392703804

Epoch: 6| Step: 10
Training loss: 1.3054325580596924
Validation loss: 2.0364084807775353

Epoch: 6| Step: 11
Training loss: 1.632826805114746
Validation loss: 2.0420535482386106

Epoch: 6| Step: 12
Training loss: 2.365941047668457
Validation loss: 2.0821827457797144

Epoch: 6| Step: 13
Training loss: 1.9083540439605713
Validation loss: 2.0791781589549077

Epoch: 289| Step: 0
Training loss: 1.5833861827850342
Validation loss: 2.0564774108189408

Epoch: 6| Step: 1
Training loss: 1.2188434600830078
Validation loss: 2.0889742348783757

Epoch: 6| Step: 2
Training loss: 1.9384727478027344
Validation loss: 2.086110061214816

Epoch: 6| Step: 3
Training loss: 1.4165250062942505
Validation loss: 2.074781393492094

Epoch: 6| Step: 4
Training loss: 1.764340877532959
Validation loss: 2.110078473244944

Epoch: 6| Step: 5
Training loss: 2.016057014465332
Validation loss: 2.1060769173406784

Epoch: 6| Step: 6
Training loss: 1.438462734222412
Validation loss: 2.084029132320035

Epoch: 6| Step: 7
Training loss: 2.5866498947143555
Validation loss: 2.102872371673584

Epoch: 6| Step: 8
Training loss: 1.8168116807937622
Validation loss: 2.077623772364791

Epoch: 6| Step: 9
Training loss: 1.7511796951293945
Validation loss: 2.0909145493661203

Epoch: 6| Step: 10
Training loss: 2.4160399436950684
Validation loss: 2.0706497892256706

Epoch: 6| Step: 11
Training loss: 1.918383240699768
Validation loss: 2.0870934173625004

Epoch: 6| Step: 12
Training loss: 1.5925707817077637
Validation loss: 2.066383764307986

Epoch: 6| Step: 13
Training loss: 1.1462939977645874
Validation loss: 2.0551678698549987

Epoch: 290| Step: 0
Training loss: 0.8391578197479248
Validation loss: 2.0573508534380185

Epoch: 6| Step: 1
Training loss: 1.8104114532470703
Validation loss: 2.0257467044297086

Epoch: 6| Step: 2
Training loss: 2.2018539905548096
Validation loss: 2.025552213832896

Epoch: 6| Step: 3
Training loss: 1.5834734439849854
Validation loss: 2.0567151090150237

Epoch: 6| Step: 4
Training loss: 1.7463645935058594
Validation loss: 2.0648940404256186

Epoch: 6| Step: 5
Training loss: 1.8003780841827393
Validation loss: 2.0669199753833074

Epoch: 6| Step: 6
Training loss: 1.8889305591583252
Validation loss: 2.058093182502254

Epoch: 6| Step: 7
Training loss: 1.5992867946624756
Validation loss: 2.023332949607603

Epoch: 6| Step: 8
Training loss: 0.9287703037261963
Validation loss: 2.030011030935472

Epoch: 6| Step: 9
Training loss: 2.8759195804595947
Validation loss: 2.060976425806681

Epoch: 6| Step: 10
Training loss: 1.9021804332733154
Validation loss: 2.03644210292447

Epoch: 6| Step: 11
Training loss: 1.7255382537841797
Validation loss: 2.078972001229563

Epoch: 6| Step: 12
Training loss: 1.1894264221191406
Validation loss: 2.043698674889021

Epoch: 6| Step: 13
Training loss: 3.116647243499756
Validation loss: 2.055831704088437

Epoch: 291| Step: 0
Training loss: 1.7288484573364258
Validation loss: 2.0687975768120057

Epoch: 6| Step: 1
Training loss: 1.231266736984253
Validation loss: 2.0422849539787538

Epoch: 6| Step: 2
Training loss: 1.5180821418762207
Validation loss: 2.0340792696963073

Epoch: 6| Step: 3
Training loss: 2.3923816680908203
Validation loss: 2.0732606405852945

Epoch: 6| Step: 4
Training loss: 1.5741093158721924
Validation loss: 2.091640290393624

Epoch: 6| Step: 5
Training loss: 1.0572956800460815
Validation loss: 2.1018539910675376

Epoch: 6| Step: 6
Training loss: 2.030449390411377
Validation loss: 2.106980223809519

Epoch: 6| Step: 7
Training loss: 1.7446939945220947
Validation loss: 2.1043322419607513

Epoch: 6| Step: 8
Training loss: 1.5953402519226074
Validation loss: 2.0713183264578543

Epoch: 6| Step: 9
Training loss: 1.4414234161376953
Validation loss: 2.106718396627775

Epoch: 6| Step: 10
Training loss: 2.129694938659668
Validation loss: 2.068430395536525

Epoch: 6| Step: 11
Training loss: 2.8072116374969482
Validation loss: 2.0593849651275145

Epoch: 6| Step: 12
Training loss: 1.4836773872375488
Validation loss: 2.072346615534957

Epoch: 6| Step: 13
Training loss: 2.040954351425171
Validation loss: 2.0958070216640348

Epoch: 292| Step: 0
Training loss: 2.022317409515381
Validation loss: 2.0675774287152033

Epoch: 6| Step: 1
Training loss: 1.3471671342849731
Validation loss: 2.0817672347509735

Epoch: 6| Step: 2
Training loss: 1.2861114740371704
Validation loss: 2.0645686247015513

Epoch: 6| Step: 3
Training loss: 1.6618777513504028
Validation loss: 2.0573325144347323

Epoch: 6| Step: 4
Training loss: 1.9918928146362305
Validation loss: 2.0827368792667182

Epoch: 6| Step: 5
Training loss: 2.2052931785583496
Validation loss: 2.051287011433673

Epoch: 6| Step: 6
Training loss: 1.90380859375
Validation loss: 2.0507451641944145

Epoch: 6| Step: 7
Training loss: 1.2428706884384155
Validation loss: 2.081590821666102

Epoch: 6| Step: 8
Training loss: 2.3102211952209473
Validation loss: 2.0355706932724162

Epoch: 6| Step: 9
Training loss: 1.406509280204773
Validation loss: 2.043107819813554

Epoch: 6| Step: 10
Training loss: 2.189277172088623
Validation loss: 2.0293217141141175

Epoch: 6| Step: 11
Training loss: 1.7925258874893188
Validation loss: 2.0231059353838683

Epoch: 6| Step: 12
Training loss: 1.3303749561309814
Validation loss: 2.052812114838631

Epoch: 6| Step: 13
Training loss: 2.2792506217956543
Validation loss: 2.0375120075800086

Epoch: 293| Step: 0
Training loss: 1.7159245014190674
Validation loss: 2.0749152860333844

Epoch: 6| Step: 1
Training loss: 1.2330421209335327
Validation loss: 2.0609654303519958

Epoch: 6| Step: 2
Training loss: 1.7642459869384766
Validation loss: 2.0404261876178045

Epoch: 6| Step: 3
Training loss: 1.4559218883514404
Validation loss: 2.0713530458429807

Epoch: 6| Step: 4
Training loss: 2.0034632682800293
Validation loss: 2.0329278310139975

Epoch: 6| Step: 5
Training loss: 2.214998722076416
Validation loss: 2.050157775161087

Epoch: 6| Step: 6
Training loss: 1.235196590423584
Validation loss: 2.0622801703791462

Epoch: 6| Step: 7
Training loss: 1.4955799579620361
Validation loss: 2.0859962612070064

Epoch: 6| Step: 8
Training loss: 2.2930002212524414
Validation loss: 2.043041839394518

Epoch: 6| Step: 9
Training loss: 2.2025275230407715
Validation loss: 2.0475789359820786

Epoch: 6| Step: 10
Training loss: 1.8442188501358032
Validation loss: 2.044603428533

Epoch: 6| Step: 11
Training loss: 1.8697497844696045
Validation loss: 2.07068298709008

Epoch: 6| Step: 12
Training loss: 1.729015827178955
Validation loss: 2.0886270564089537

Epoch: 6| Step: 13
Training loss: 1.1048543453216553
Validation loss: 2.086170786170549

Epoch: 294| Step: 0
Training loss: 1.2343523502349854
Validation loss: 2.0713693698247275

Epoch: 6| Step: 1
Training loss: 2.3298957347869873
Validation loss: 2.0827949021452214

Epoch: 6| Step: 2
Training loss: 1.9060776233673096
Validation loss: 2.0760871671861216

Epoch: 6| Step: 3
Training loss: 1.448599934577942
Validation loss: 2.064618933585382

Epoch: 6| Step: 4
Training loss: 1.8304712772369385
Validation loss: 2.084257497582384

Epoch: 6| Step: 5
Training loss: 1.95468008518219
Validation loss: 2.063778174820767

Epoch: 6| Step: 6
Training loss: 2.349858283996582
Validation loss: 2.046035461528327

Epoch: 6| Step: 7
Training loss: 1.58717679977417
Validation loss: 2.0475563285171345

Epoch: 6| Step: 8
Training loss: 2.2343521118164062
Validation loss: 2.078845461209615

Epoch: 6| Step: 9
Training loss: 1.3714640140533447
Validation loss: 2.0740211112524873

Epoch: 6| Step: 10
Training loss: 2.007110595703125
Validation loss: 2.0935356924610753

Epoch: 6| Step: 11
Training loss: 2.3523998260498047
Validation loss: 2.0381110457963842

Epoch: 6| Step: 12
Training loss: 1.2743433713912964
Validation loss: 2.0784079208168933

Epoch: 6| Step: 13
Training loss: 0.5576808452606201
Validation loss: 2.0422009114296205

Epoch: 295| Step: 0
Training loss: 2.051797866821289
Validation loss: 2.0743034578138784

Epoch: 6| Step: 1
Training loss: 2.2384209632873535
Validation loss: 2.047122683576358

Epoch: 6| Step: 2
Training loss: 1.6503474712371826
Validation loss: 2.075683616822766

Epoch: 6| Step: 3
Training loss: 1.6953352689743042
Validation loss: 2.09509414498524

Epoch: 6| Step: 4
Training loss: 1.5078136920928955
Validation loss: 2.044546923329753

Epoch: 6| Step: 5
Training loss: 1.662545919418335
Validation loss: 2.042296730062013

Epoch: 6| Step: 6
Training loss: 2.081780195236206
Validation loss: 2.066934583007648

Epoch: 6| Step: 7
Training loss: 1.8107078075408936
Validation loss: 2.0469048766679663

Epoch: 6| Step: 8
Training loss: 1.520531415939331
Validation loss: 2.055863521432364

Epoch: 6| Step: 9
Training loss: 1.9142093658447266
Validation loss: 2.0530249213659637

Epoch: 6| Step: 10
Training loss: 2.345273494720459
Validation loss: 2.0547208042554956

Epoch: 6| Step: 11
Training loss: 1.3612066507339478
Validation loss: 2.0365617544420305

Epoch: 6| Step: 12
Training loss: 1.2598692178726196
Validation loss: 2.0671634058798514

Epoch: 6| Step: 13
Training loss: 1.3917794227600098
Validation loss: 2.06358064118252

Epoch: 296| Step: 0
Training loss: 1.381347894668579
Validation loss: 2.0688470768672165

Epoch: 6| Step: 1
Training loss: 2.396778106689453
Validation loss: 2.060576423521965

Epoch: 6| Step: 2
Training loss: 2.0535521507263184
Validation loss: 2.0752101200883106

Epoch: 6| Step: 3
Training loss: 1.8895092010498047
Validation loss: 2.056317478097895

Epoch: 6| Step: 4
Training loss: 1.2547483444213867
Validation loss: 2.0305925697408695

Epoch: 6| Step: 5
Training loss: 1.918283462524414
Validation loss: 2.047409734418315

Epoch: 6| Step: 6
Training loss: 1.902085781097412
Validation loss: 2.035314998319072

Epoch: 6| Step: 7
Training loss: 2.174233913421631
Validation loss: 2.0830629641009915

Epoch: 6| Step: 8
Training loss: 1.5651934146881104
Validation loss: 2.0946840957928727

Epoch: 6| Step: 9
Training loss: 1.2653751373291016
Validation loss: 2.0834963052503523

Epoch: 6| Step: 10
Training loss: 1.225867509841919
Validation loss: 2.0723070406144664

Epoch: 6| Step: 11
Training loss: 1.1940014362335205
Validation loss: 2.048741276546191

Epoch: 6| Step: 12
Training loss: 1.872854471206665
Validation loss: 2.068581114533127

Epoch: 6| Step: 13
Training loss: 2.972011089324951
Validation loss: 2.0683241146866993

Epoch: 297| Step: 0
Training loss: 1.7321200370788574
Validation loss: 2.061589922956241

Epoch: 6| Step: 1
Training loss: 1.9221231937408447
Validation loss: 2.0542144288298902

Epoch: 6| Step: 2
Training loss: 1.7497361898422241
Validation loss: 2.073482036590576

Epoch: 6| Step: 3
Training loss: 2.054227590560913
Validation loss: 2.0730507373809814

Epoch: 6| Step: 4
Training loss: 1.6589267253875732
Validation loss: 2.060216596049647

Epoch: 6| Step: 5
Training loss: 1.7659473419189453
Validation loss: 2.0941148419534006

Epoch: 6| Step: 6
Training loss: 1.0802956819534302
Validation loss: 2.069090615036667

Epoch: 6| Step: 7
Training loss: 2.004807949066162
Validation loss: 2.0585240753748084

Epoch: 6| Step: 8
Training loss: 1.948874592781067
Validation loss: 2.0541015568599907

Epoch: 6| Step: 9
Training loss: 1.914249062538147
Validation loss: 2.036174294769123

Epoch: 6| Step: 10
Training loss: 2.0253217220306396
Validation loss: 2.069978852425852

Epoch: 6| Step: 11
Training loss: 1.459061861038208
Validation loss: 2.0715365409851074

Epoch: 6| Step: 12
Training loss: 1.7448668479919434
Validation loss: 2.038628952477568

Epoch: 6| Step: 13
Training loss: 1.2145241498947144
Validation loss: 2.058002000213951

Epoch: 298| Step: 0
Training loss: 1.462235450744629
Validation loss: 2.0610408026685

Epoch: 6| Step: 1
Training loss: 2.1384706497192383
Validation loss: 2.0560996506803777

Epoch: 6| Step: 2
Training loss: 2.6182656288146973
Validation loss: 2.0640398917659635

Epoch: 6| Step: 3
Training loss: 2.091778039932251
Validation loss: 2.0413628931968444

Epoch: 6| Step: 4
Training loss: 1.7390087842941284
Validation loss: 2.0627934676344677

Epoch: 6| Step: 5
Training loss: 1.536495327949524
Validation loss: 2.059994346352034

Epoch: 6| Step: 6
Training loss: 2.5526676177978516
Validation loss: 2.086626657875635

Epoch: 6| Step: 7
Training loss: 1.270721435546875
Validation loss: 2.0721668915082048

Epoch: 6| Step: 8
Training loss: 1.3788416385650635
Validation loss: 2.0942270576312976

Epoch: 6| Step: 9
Training loss: 1.1051647663116455
Validation loss: 2.087045472155335

Epoch: 6| Step: 10
Training loss: 1.9929430484771729
Validation loss: 2.0974250249965216

Epoch: 6| Step: 11
Training loss: 1.6754417419433594
Validation loss: 2.0850194718248103

Epoch: 6| Step: 12
Training loss: 1.5926446914672852
Validation loss: 2.0470354762128604

Epoch: 6| Step: 13
Training loss: 1.879945993423462
Validation loss: 2.0401481133635326

Epoch: 299| Step: 0
Training loss: 2.063601016998291
Validation loss: 2.0675621083987656

Epoch: 6| Step: 1
Training loss: 1.2807657718658447
Validation loss: 2.0389752977637836

Epoch: 6| Step: 2
Training loss: 2.218540668487549
Validation loss: 2.041680730799193

Epoch: 6| Step: 3
Training loss: 1.095827579498291
Validation loss: 2.0823497438943512

Epoch: 6| Step: 4
Training loss: 2.2165451049804688
Validation loss: 2.04858733248967

Epoch: 6| Step: 5
Training loss: 1.942608118057251
Validation loss: 2.0492638029078

Epoch: 6| Step: 6
Training loss: 2.0967183113098145
Validation loss: 2.0602898315716813

Epoch: 6| Step: 7
Training loss: 1.8420703411102295
Validation loss: 2.047481122837272

Epoch: 6| Step: 8
Training loss: 1.4480624198913574
Validation loss: 2.080623854873001

Epoch: 6| Step: 9
Training loss: 2.2754101753234863
Validation loss: 2.0387462236547984

Epoch: 6| Step: 10
Training loss: 1.6130931377410889
Validation loss: 2.055160863425142

Epoch: 6| Step: 11
Training loss: 1.3036844730377197
Validation loss: 2.045204847089706

Epoch: 6| Step: 12
Training loss: 2.123741626739502
Validation loss: 2.0387094251571165

Epoch: 6| Step: 13
Training loss: 0.9841406941413879
Validation loss: 2.0702525120909496

Epoch: 300| Step: 0
Training loss: 2.362070083618164
Validation loss: 2.014475385348002

Epoch: 6| Step: 1
Training loss: 1.4786878824234009
Validation loss: 2.0793378224936863

Epoch: 6| Step: 2
Training loss: 0.9901699423789978
Validation loss: 2.0674070991495603

Epoch: 6| Step: 3
Training loss: 1.6996432542800903
Validation loss: 2.082998434702555

Epoch: 6| Step: 4
Training loss: 1.802865982055664
Validation loss: 2.091050660738381

Epoch: 6| Step: 5
Training loss: 1.839076280593872
Validation loss: 2.090316313569264

Epoch: 6| Step: 6
Training loss: 1.9848054647445679
Validation loss: 2.061121174084243

Epoch: 6| Step: 7
Training loss: 1.4071714878082275
Validation loss: 2.074606495518838

Epoch: 6| Step: 8
Training loss: 1.7340474128723145
Validation loss: 2.1086845551767657

Epoch: 6| Step: 9
Training loss: 1.66260826587677
Validation loss: 2.068342057607507

Epoch: 6| Step: 10
Training loss: 1.9631271362304688
Validation loss: 2.066287830311765

Epoch: 6| Step: 11
Training loss: 1.4904659986495972
Validation loss: 2.061350796812324

Epoch: 6| Step: 12
Training loss: 1.9530649185180664
Validation loss: 2.0293715102698213

Epoch: 6| Step: 13
Training loss: 2.287381410598755
Validation loss: 2.0872243347988335

Epoch: 301| Step: 0
Training loss: 1.3559901714324951
Validation loss: 2.0576369813693467

Epoch: 6| Step: 1
Training loss: 1.522672414779663
Validation loss: 2.0736675544451644

Epoch: 6| Step: 2
Training loss: 1.6510334014892578
Validation loss: 2.0731885766470306

Epoch: 6| Step: 3
Training loss: 1.7420408725738525
Validation loss: 2.0637360593324066

Epoch: 6| Step: 4
Training loss: 1.1745612621307373
Validation loss: 2.0735682902797574

Epoch: 6| Step: 5
Training loss: 1.578973650932312
Validation loss: 2.0438606559589343

Epoch: 6| Step: 6
Training loss: 2.1755542755126953
Validation loss: 2.054586451540711

Epoch: 6| Step: 7
Training loss: 2.4704976081848145
Validation loss: 2.034902384204249

Epoch: 6| Step: 8
Training loss: 2.2214341163635254
Validation loss: 2.093557823088861

Epoch: 6| Step: 9
Training loss: 1.4247708320617676
Validation loss: 2.069999735842469

Epoch: 6| Step: 10
Training loss: 1.858097791671753
Validation loss: 2.0304264791550173

Epoch: 6| Step: 11
Training loss: 1.320166826248169
Validation loss: 2.03734931894528

Epoch: 6| Step: 12
Training loss: 1.6172614097595215
Validation loss: 2.08909329547677

Epoch: 6| Step: 13
Training loss: 2.8073720932006836
Validation loss: 2.058064797873138

Epoch: 302| Step: 0
Training loss: 1.6044001579284668
Validation loss: 2.0542474177575882

Epoch: 6| Step: 1
Training loss: 1.7718229293823242
Validation loss: 2.049337253775648

Epoch: 6| Step: 2
Training loss: 1.5046719312667847
Validation loss: 2.0412430750426425

Epoch: 6| Step: 3
Training loss: 1.4669749736785889
Validation loss: 2.0651541807318248

Epoch: 6| Step: 4
Training loss: 1.6098911762237549
Validation loss: 2.0248923250423965

Epoch: 6| Step: 5
Training loss: 2.128343343734741
Validation loss: 2.052130981158185

Epoch: 6| Step: 6
Training loss: 1.5084083080291748
Validation loss: 2.0729792823073683

Epoch: 6| Step: 7
Training loss: 2.3993802070617676
Validation loss: 2.0668038001624485

Epoch: 6| Step: 8
Training loss: 1.8703064918518066
Validation loss: 2.0745129187901816

Epoch: 6| Step: 9
Training loss: 1.6642762422561646
Validation loss: 2.0676078309294996

Epoch: 6| Step: 10
Training loss: 1.135488510131836
Validation loss: 2.086671235740826

Epoch: 6| Step: 11
Training loss: 2.057457447052002
Validation loss: 2.0610376391359555

Epoch: 6| Step: 12
Training loss: 1.6381425857543945
Validation loss: 2.1023255663533367

Epoch: 6| Step: 13
Training loss: 2.215118885040283
Validation loss: 2.063159506808045

Epoch: 303| Step: 0
Training loss: 1.7397352457046509
Validation loss: 2.068093725430068

Epoch: 6| Step: 1
Training loss: 2.262734889984131
Validation loss: 2.08534163044345

Epoch: 6| Step: 2
Training loss: 1.9520237445831299
Validation loss: 2.0801120099200996

Epoch: 6| Step: 3
Training loss: 1.606026291847229
Validation loss: 2.0754645383486183

Epoch: 6| Step: 4
Training loss: 2.2018704414367676
Validation loss: 2.077055904173082

Epoch: 6| Step: 5
Training loss: 1.792952060699463
Validation loss: 2.06167632790022

Epoch: 6| Step: 6
Training loss: 1.8311333656311035
Validation loss: 2.0815969615854244

Epoch: 6| Step: 7
Training loss: 1.2265026569366455
Validation loss: 2.072605638093846

Epoch: 6| Step: 8
Training loss: 1.1676058769226074
Validation loss: 2.0707176013659407

Epoch: 6| Step: 9
Training loss: 1.4644746780395508
Validation loss: 2.0780758524453766

Epoch: 6| Step: 10
Training loss: 1.5627518892288208
Validation loss: 2.0943485972701863

Epoch: 6| Step: 11
Training loss: 1.6264488697052002
Validation loss: 2.0949242448294036

Epoch: 6| Step: 12
Training loss: 2.1218459606170654
Validation loss: 2.0603092434585735

Epoch: 6| Step: 13
Training loss: 1.7532734870910645
Validation loss: 2.064179766562677

Epoch: 304| Step: 0
Training loss: 1.6385610103607178
Validation loss: 2.0752593137884654

Epoch: 6| Step: 1
Training loss: 1.3807487487792969
Validation loss: 2.0564778158741612

Epoch: 6| Step: 2
Training loss: 1.8902606964111328
Validation loss: 2.0477313790270077

Epoch: 6| Step: 3
Training loss: 1.489977478981018
Validation loss: 2.043027691943671

Epoch: 6| Step: 4
Training loss: 1.6982942819595337
Validation loss: 2.0764574158576226

Epoch: 6| Step: 5
Training loss: 2.0140974521636963
Validation loss: 2.0737297727215673

Epoch: 6| Step: 6
Training loss: 1.6125893592834473
Validation loss: 2.0587681519087924

Epoch: 6| Step: 7
Training loss: 1.5738685131072998
Validation loss: 2.0939273629137265

Epoch: 6| Step: 8
Training loss: 1.505842685699463
Validation loss: 2.0509433118245934

Epoch: 6| Step: 9
Training loss: 2.2221808433532715
Validation loss: 2.046245185277795

Epoch: 6| Step: 10
Training loss: 1.494929313659668
Validation loss: 2.038384001742127

Epoch: 6| Step: 11
Training loss: 1.6145223379135132
Validation loss: 2.0658819111444617

Epoch: 6| Step: 12
Training loss: 2.5062546730041504
Validation loss: 2.050824457599271

Epoch: 6| Step: 13
Training loss: 1.4250212907791138
Validation loss: 2.039431959070185

Epoch: 305| Step: 0
Training loss: 1.7837603092193604
Validation loss: 2.0459431050926127

Epoch: 6| Step: 1
Training loss: 1.3254677057266235
Validation loss: 2.093643009021718

Epoch: 6| Step: 2
Training loss: 1.7952784299850464
Validation loss: 2.0258103250175394

Epoch: 6| Step: 3
Training loss: 1.9720882177352905
Validation loss: 2.05200368870971

Epoch: 6| Step: 4
Training loss: 1.7097307443618774
Validation loss: 2.0545910558392926

Epoch: 6| Step: 5
Training loss: 1.9672772884368896
Validation loss: 2.0598846456056

Epoch: 6| Step: 6
Training loss: 2.235678195953369
Validation loss: 2.0664526390772995

Epoch: 6| Step: 7
Training loss: 1.4931470155715942
Validation loss: 2.100603280528899

Epoch: 6| Step: 8
Training loss: 1.8270070552825928
Validation loss: 2.084688271245649

Epoch: 6| Step: 9
Training loss: 1.8556208610534668
Validation loss: 2.0785351235379457

Epoch: 6| Step: 10
Training loss: 1.9405540227890015
Validation loss: 2.0918782885356615

Epoch: 6| Step: 11
Training loss: 1.5660473108291626
Validation loss: 2.0474012590223745

Epoch: 6| Step: 12
Training loss: 1.266433835029602
Validation loss: 2.10715659715796

Epoch: 6| Step: 13
Training loss: 1.785656213760376
Validation loss: 2.0822100844434512

Epoch: 306| Step: 0
Training loss: 1.5306727886199951
Validation loss: 2.0351172903532624

Epoch: 6| Step: 1
Training loss: 1.1623525619506836
Validation loss: 2.044737749202277

Epoch: 6| Step: 2
Training loss: 2.1561460494995117
Validation loss: 2.056104367779147

Epoch: 6| Step: 3
Training loss: 2.1230990886688232
Validation loss: 2.0401295910599413

Epoch: 6| Step: 4
Training loss: 2.144294261932373
Validation loss: 2.0348602981977564

Epoch: 6| Step: 5
Training loss: 2.137277603149414
Validation loss: 2.080324270391977

Epoch: 6| Step: 6
Training loss: 1.3901658058166504
Validation loss: 2.074316441371877

Epoch: 6| Step: 7
Training loss: 1.489112138748169
Validation loss: 2.0571109248745825

Epoch: 6| Step: 8
Training loss: 2.3385767936706543
Validation loss: 2.0673064583091327

Epoch: 6| Step: 9
Training loss: 1.206092357635498
Validation loss: 2.0458782847209642

Epoch: 6| Step: 10
Training loss: 1.490572452545166
Validation loss: 2.066684471663608

Epoch: 6| Step: 11
Training loss: 1.6951539516448975
Validation loss: 2.0337182873038837

Epoch: 6| Step: 12
Training loss: 1.9088960886001587
Validation loss: 2.020637127660936

Epoch: 6| Step: 13
Training loss: 1.5865319967269897
Validation loss: 2.0395961217982794

Epoch: 307| Step: 0
Training loss: 1.9111273288726807
Validation loss: 2.0608146729007846

Epoch: 6| Step: 1
Training loss: 1.6906893253326416
Validation loss: 2.0969502900236394

Epoch: 6| Step: 2
Training loss: 2.1149849891662598
Validation loss: 2.086207789759482

Epoch: 6| Step: 3
Training loss: 1.7616674900054932
Validation loss: 2.042348777094195

Epoch: 6| Step: 4
Training loss: 1.6761631965637207
Validation loss: 2.052815947481381

Epoch: 6| Step: 5
Training loss: 2.278702735900879
Validation loss: 2.051240410856021

Epoch: 6| Step: 6
Training loss: 1.438330888748169
Validation loss: 2.060782928620615

Epoch: 6| Step: 7
Training loss: 2.4184906482696533
Validation loss: 2.074541991756808

Epoch: 6| Step: 8
Training loss: 1.1008636951446533
Validation loss: 2.0733212578681206

Epoch: 6| Step: 9
Training loss: 1.0459272861480713
Validation loss: 2.0645006677155853

Epoch: 6| Step: 10
Training loss: 1.726406216621399
Validation loss: 2.068538315834538

Epoch: 6| Step: 11
Training loss: 1.7290081977844238
Validation loss: 2.0710748985249507

Epoch: 6| Step: 12
Training loss: 1.8973994255065918
Validation loss: 2.072189509227712

Epoch: 6| Step: 13
Training loss: 1.98488187789917
Validation loss: 2.1054862673564623

Epoch: 308| Step: 0
Training loss: 1.6145225763320923
Validation loss: 2.0716928653819586

Epoch: 6| Step: 1
Training loss: 1.9194109439849854
Validation loss: 2.0653976983921503

Epoch: 6| Step: 2
Training loss: 1.956148624420166
Validation loss: 2.0490282081788584

Epoch: 6| Step: 3
Training loss: 1.2890688180923462
Validation loss: 2.0513103687635033

Epoch: 6| Step: 4
Training loss: 1.709853172302246
Validation loss: 2.098199625169077

Epoch: 6| Step: 5
Training loss: 1.8555020093917847
Validation loss: 2.0551803419666905

Epoch: 6| Step: 6
Training loss: 1.888066053390503
Validation loss: 2.0878891021974626

Epoch: 6| Step: 7
Training loss: 2.6466479301452637
Validation loss: 2.079748248541227

Epoch: 6| Step: 8
Training loss: 1.2497270107269287
Validation loss: 2.065396052534862

Epoch: 6| Step: 9
Training loss: 1.5849570035934448
Validation loss: 2.0405922500036096

Epoch: 6| Step: 10
Training loss: 2.1066179275512695
Validation loss: 2.0768704491276897

Epoch: 6| Step: 11
Training loss: 1.3335026502609253
Validation loss: 2.077013609229877

Epoch: 6| Step: 12
Training loss: 1.8392224311828613
Validation loss: 2.055201256146995

Epoch: 6| Step: 13
Training loss: 0.9232984185218811
Validation loss: 2.076963852810603

Epoch: 309| Step: 0
Training loss: 1.5251060724258423
Validation loss: 2.0354117244802494

Epoch: 6| Step: 1
Training loss: 1.761963129043579
Validation loss: 2.0602137888631513

Epoch: 6| Step: 2
Training loss: 1.7326503992080688
Validation loss: 2.059497038523356

Epoch: 6| Step: 3
Training loss: 1.8952465057373047
Validation loss: 2.0472301308826735

Epoch: 6| Step: 4
Training loss: 1.5326662063598633
Validation loss: 2.0860616417341333

Epoch: 6| Step: 5
Training loss: 2.0333309173583984
Validation loss: 2.074449593021024

Epoch: 6| Step: 6
Training loss: 1.6576427221298218
Validation loss: 2.04096657101826

Epoch: 6| Step: 7
Training loss: 1.7991409301757812
Validation loss: 2.0663675826082946

Epoch: 6| Step: 8
Training loss: 1.0801537036895752
Validation loss: 2.0600397920095794

Epoch: 6| Step: 9
Training loss: 1.923222541809082
Validation loss: 2.046963717347832

Epoch: 6| Step: 10
Training loss: 1.6183035373687744
Validation loss: 2.058830955977081

Epoch: 6| Step: 11
Training loss: 1.9026250839233398
Validation loss: 2.074204594858231

Epoch: 6| Step: 12
Training loss: 1.872443437576294
Validation loss: 2.0336495753257506

Epoch: 6| Step: 13
Training loss: 2.1289031505584717
Validation loss: 2.0647525377171014

Epoch: 310| Step: 0
Training loss: 1.3930790424346924
Validation loss: 2.0621185302734375

Epoch: 6| Step: 1
Training loss: 2.163278579711914
Validation loss: 2.0754320749672512

Epoch: 6| Step: 2
Training loss: 2.213977336883545
Validation loss: 2.1016837230292698

Epoch: 6| Step: 3
Training loss: 1.4654982089996338
Validation loss: 2.1336843044527116

Epoch: 6| Step: 4
Training loss: 1.7273437976837158
Validation loss: 2.0643013908017065

Epoch: 6| Step: 5
Training loss: 2.306631565093994
Validation loss: 2.120528075002855

Epoch: 6| Step: 6
Training loss: 1.6559301614761353
Validation loss: 2.107923492308586

Epoch: 6| Step: 7
Training loss: 1.5239806175231934
Validation loss: 2.109824098566527

Epoch: 6| Step: 8
Training loss: 1.7498729228973389
Validation loss: 2.0916845939492665

Epoch: 6| Step: 9
Training loss: 1.6691370010375977
Validation loss: 2.0925734760940715

Epoch: 6| Step: 10
Training loss: 1.7146806716918945
Validation loss: 2.0456109841664634

Epoch: 6| Step: 11
Training loss: 1.368036150932312
Validation loss: 2.0741696293636034

Epoch: 6| Step: 12
Training loss: 1.8983001708984375
Validation loss: 2.0769263159844185

Epoch: 6| Step: 13
Training loss: 1.3290083408355713
Validation loss: 2.0680013830943773

Epoch: 311| Step: 0
Training loss: 1.5434266328811646
Validation loss: 2.060574239300143

Epoch: 6| Step: 1
Training loss: 2.3975305557250977
Validation loss: 2.0401905467433314

Epoch: 6| Step: 2
Training loss: 2.1086032390594482
Validation loss: 2.1133747254648516

Epoch: 6| Step: 3
Training loss: 1.6782960891723633
Validation loss: 2.1079400149724816

Epoch: 6| Step: 4
Training loss: 1.7001235485076904
Validation loss: 2.0595329833287064

Epoch: 6| Step: 5
Training loss: 1.3980103731155396
Validation loss: 2.0875527794643114

Epoch: 6| Step: 6
Training loss: 1.2248953580856323
Validation loss: 2.0684573214541198

Epoch: 6| Step: 7
Training loss: 2.2480456829071045
Validation loss: 2.0746931106813493

Epoch: 6| Step: 8
Training loss: 1.1496632099151611
Validation loss: 2.050092290806514

Epoch: 6| Step: 9
Training loss: 1.446270227432251
Validation loss: 2.0796781509153304

Epoch: 6| Step: 10
Training loss: 1.5646421909332275
Validation loss: 2.0652534064426216

Epoch: 6| Step: 11
Training loss: 1.9245494604110718
Validation loss: 2.0735946316872873

Epoch: 6| Step: 12
Training loss: 2.183162212371826
Validation loss: 2.036890570835401

Epoch: 6| Step: 13
Training loss: 1.124215006828308
Validation loss: 2.032765241079433

Epoch: 312| Step: 0
Training loss: 1.8790113925933838
Validation loss: 2.0755404644114996

Epoch: 6| Step: 1
Training loss: 2.1417269706726074
Validation loss: 2.011316425056868

Epoch: 6| Step: 2
Training loss: 2.0426876544952393
Validation loss: 2.0332798906551894

Epoch: 6| Step: 3
Training loss: 1.8135719299316406
Validation loss: 2.052197528141801

Epoch: 6| Step: 4
Training loss: 1.4331682920455933
Validation loss: 2.0138267983672438

Epoch: 6| Step: 5
Training loss: 1.4754717350006104
Validation loss: 2.050309096613238

Epoch: 6| Step: 6
Training loss: 1.9169318675994873
Validation loss: 2.0291013461287304

Epoch: 6| Step: 7
Training loss: 1.3814337253570557
Validation loss: 2.0586112545382593

Epoch: 6| Step: 8
Training loss: 1.588068962097168
Validation loss: 2.0711236846062446

Epoch: 6| Step: 9
Training loss: 1.7209744453430176
Validation loss: 2.056190090794717

Epoch: 6| Step: 10
Training loss: 1.3257923126220703
Validation loss: 2.046010809559976

Epoch: 6| Step: 11
Training loss: 1.8616310358047485
Validation loss: 2.0757893644353396

Epoch: 6| Step: 12
Training loss: 1.4606943130493164
Validation loss: 2.016851354670781

Epoch: 6| Step: 13
Training loss: 2.2876007556915283
Validation loss: 2.065075469273393

Epoch: 313| Step: 0
Training loss: 1.1539076566696167
Validation loss: 2.0369479938219954

Epoch: 6| Step: 1
Training loss: 1.4622845649719238
Validation loss: 2.103810002726893

Epoch: 6| Step: 2
Training loss: 1.7436370849609375
Validation loss: 2.073530909835651

Epoch: 6| Step: 3
Training loss: 1.3580873012542725
Validation loss: 2.086480671359647

Epoch: 6| Step: 4
Training loss: 1.7901620864868164
Validation loss: 2.0577699561272897

Epoch: 6| Step: 5
Training loss: 1.4592047929763794
Validation loss: 2.074715474600433

Epoch: 6| Step: 6
Training loss: 1.835009217262268
Validation loss: 2.0729242306883617

Epoch: 6| Step: 7
Training loss: 2.166982650756836
Validation loss: 2.065899136245892

Epoch: 6| Step: 8
Training loss: 2.643320322036743
Validation loss: 2.058281055060766

Epoch: 6| Step: 9
Training loss: 1.315375804901123
Validation loss: 2.057715351863574

Epoch: 6| Step: 10
Training loss: 2.4737677574157715
Validation loss: 2.0774104825911985

Epoch: 6| Step: 11
Training loss: 2.099167585372925
Validation loss: 2.079115234395509

Epoch: 6| Step: 12
Training loss: 1.302972674369812
Validation loss: 2.0536981013513382

Epoch: 6| Step: 13
Training loss: 1.1574652194976807
Validation loss: 2.0398973162456224

Epoch: 314| Step: 0
Training loss: 1.8216617107391357
Validation loss: 2.0602036060825473

Epoch: 6| Step: 1
Training loss: 2.084531307220459
Validation loss: 2.055732329686483

Epoch: 6| Step: 2
Training loss: 1.8596596717834473
Validation loss: 2.069790788876113

Epoch: 6| Step: 3
Training loss: 1.9936178922653198
Validation loss: 2.1057727695793234

Epoch: 6| Step: 4
Training loss: 1.1343766450881958
Validation loss: 2.029630584101523

Epoch: 6| Step: 5
Training loss: 1.355051875114441
Validation loss: 2.0555658673727386

Epoch: 6| Step: 6
Training loss: 1.5434579849243164
Validation loss: 2.083257366252202

Epoch: 6| Step: 7
Training loss: 1.5965235233306885
Validation loss: 2.054529595118697

Epoch: 6| Step: 8
Training loss: 1.6748709678649902
Validation loss: 2.028463831511877

Epoch: 6| Step: 9
Training loss: 2.1994211673736572
Validation loss: 2.040090782668001

Epoch: 6| Step: 10
Training loss: 1.2524183988571167
Validation loss: 2.0995402284847793

Epoch: 6| Step: 11
Training loss: 2.703205108642578
Validation loss: 2.075395116242029

Epoch: 6| Step: 12
Training loss: 1.7942379713058472
Validation loss: 2.042668018289792

Epoch: 6| Step: 13
Training loss: 0.6530001163482666
Validation loss: 2.0256189095076693

Epoch: 315| Step: 0
Training loss: 0.8332070112228394
Validation loss: 2.0489419685897006

Epoch: 6| Step: 1
Training loss: 1.3191988468170166
Validation loss: 2.094118946342058

Epoch: 6| Step: 2
Training loss: 1.4340741634368896
Validation loss: 2.0460365151846283

Epoch: 6| Step: 3
Training loss: 2.498354434967041
Validation loss: 2.0454031882747525

Epoch: 6| Step: 4
Training loss: 1.9310637712478638
Validation loss: 2.0680575934789514

Epoch: 6| Step: 5
Training loss: 2.0938029289245605
Validation loss: 2.052618219006446

Epoch: 6| Step: 6
Training loss: 2.153217315673828
Validation loss: 2.060442119516352

Epoch: 6| Step: 7
Training loss: 1.911722183227539
Validation loss: 2.054239280762211

Epoch: 6| Step: 8
Training loss: 2.2359914779663086
Validation loss: 2.0647749388089744

Epoch: 6| Step: 9
Training loss: 1.2751777172088623
Validation loss: 2.0381893727087204

Epoch: 6| Step: 10
Training loss: 1.79964017868042
Validation loss: 2.0826519099614953

Epoch: 6| Step: 11
Training loss: 1.9092646837234497
Validation loss: 2.067951153683406

Epoch: 6| Step: 12
Training loss: 1.1578538417816162
Validation loss: 2.106991344882596

Epoch: 6| Step: 13
Training loss: 1.1729254722595215
Validation loss: 2.071129666861667

Epoch: 316| Step: 0
Training loss: 1.4089417457580566
Validation loss: 2.071147129099856

Epoch: 6| Step: 1
Training loss: 1.9974911212921143
Validation loss: 2.0446893476670787

Epoch: 6| Step: 2
Training loss: 1.9883848428726196
Validation loss: 2.07824142261218

Epoch: 6| Step: 3
Training loss: 1.960747241973877
Validation loss: 2.055062327333676

Epoch: 6| Step: 4
Training loss: 1.9504590034484863
Validation loss: 2.0693959830909647

Epoch: 6| Step: 5
Training loss: 2.126660108566284
Validation loss: 2.048785300665004

Epoch: 6| Step: 6
Training loss: 1.3801933526992798
Validation loss: 2.0805808703104653

Epoch: 6| Step: 7
Training loss: 2.0084035396575928
Validation loss: 2.09730561061572

Epoch: 6| Step: 8
Training loss: 1.8301136493682861
Validation loss: 2.0712970559315016

Epoch: 6| Step: 9
Training loss: 1.1880630254745483
Validation loss: 2.0946936350996777

Epoch: 6| Step: 10
Training loss: 1.7012929916381836
Validation loss: 2.108914641923802

Epoch: 6| Step: 11
Training loss: 1.3152841329574585
Validation loss: 2.0378968741304133

Epoch: 6| Step: 12
Training loss: 2.002323627471924
Validation loss: 2.054370536599108

Epoch: 6| Step: 13
Training loss: 0.9929881691932678
Validation loss: 2.0486497827755508

Epoch: 317| Step: 0
Training loss: 1.6362488269805908
Validation loss: 2.0781619228342527

Epoch: 6| Step: 1
Training loss: 1.6990329027175903
Validation loss: 2.0941176414489746

Epoch: 6| Step: 2
Training loss: 1.0722746849060059
Validation loss: 2.0668130061959706

Epoch: 6| Step: 3
Training loss: 1.595805048942566
Validation loss: 2.0662169379572712

Epoch: 6| Step: 4
Training loss: 1.5092203617095947
Validation loss: 2.054837208922191

Epoch: 6| Step: 5
Training loss: 1.3955658674240112
Validation loss: 2.072751627173475

Epoch: 6| Step: 6
Training loss: 2.035921573638916
Validation loss: 2.0659896955695203

Epoch: 6| Step: 7
Training loss: 2.2475948333740234
Validation loss: 2.053235570589701

Epoch: 6| Step: 8
Training loss: 1.5431921482086182
Validation loss: 2.073017979180941

Epoch: 6| Step: 9
Training loss: 1.6618032455444336
Validation loss: 2.0860369436202513

Epoch: 6| Step: 10
Training loss: 1.550894021987915
Validation loss: 2.0839934220878025

Epoch: 6| Step: 11
Training loss: 1.831346869468689
Validation loss: 2.121615640578731

Epoch: 6| Step: 12
Training loss: 2.4248030185699463
Validation loss: 2.0648389772702287

Epoch: 6| Step: 13
Training loss: 1.5379196405410767
Validation loss: 2.092200102344636

Epoch: 318| Step: 0
Training loss: 1.8929495811462402
Validation loss: 2.075230224158174

Epoch: 6| Step: 1
Training loss: 1.870253086090088
Validation loss: 2.0716279552828882

Epoch: 6| Step: 2
Training loss: 1.9080555438995361
Validation loss: 2.063044830035138

Epoch: 6| Step: 3
Training loss: 1.7370452880859375
Validation loss: 2.053982966689653

Epoch: 6| Step: 4
Training loss: 1.804025650024414
Validation loss: 2.0695644950353973

Epoch: 6| Step: 5
Training loss: 1.5101462602615356
Validation loss: 2.07857415112116

Epoch: 6| Step: 6
Training loss: 1.6983668804168701
Validation loss: 2.0580327331378894

Epoch: 6| Step: 7
Training loss: 1.5566608905792236
Validation loss: 2.0639654641510337

Epoch: 6| Step: 8
Training loss: 1.6691492795944214
Validation loss: 2.0688449644273326

Epoch: 6| Step: 9
Training loss: 1.4632941484451294
Validation loss: 2.0536038362851707

Epoch: 6| Step: 10
Training loss: 1.3507261276245117
Validation loss: 2.0435441411951536

Epoch: 6| Step: 11
Training loss: 1.6243265867233276
Validation loss: 2.08385835283546

Epoch: 6| Step: 12
Training loss: 1.6116948127746582
Validation loss: 2.053185991061631

Epoch: 6| Step: 13
Training loss: 1.8172560930252075
Validation loss: 2.066994223543393

Epoch: 319| Step: 0
Training loss: 1.8974885940551758
Validation loss: 2.0691811077056395

Epoch: 6| Step: 1
Training loss: 1.5946475267410278
Validation loss: 2.0527081822836273

Epoch: 6| Step: 2
Training loss: 1.5226534605026245
Validation loss: 2.028859640962334

Epoch: 6| Step: 3
Training loss: 2.0049705505371094
Validation loss: 2.0363550980885825

Epoch: 6| Step: 4
Training loss: 0.996797502040863
Validation loss: 2.0632231748232277

Epoch: 6| Step: 5
Training loss: 1.8039700984954834
Validation loss: 2.059616050412578

Epoch: 6| Step: 6
Training loss: 2.2562787532806396
Validation loss: 2.061216354370117

Epoch: 6| Step: 7
Training loss: 1.3656947612762451
Validation loss: 2.0285921430075042

Epoch: 6| Step: 8
Training loss: 1.9835741519927979
Validation loss: 2.0528597395907164

Epoch: 6| Step: 9
Training loss: 1.53398597240448
Validation loss: 2.0718450443719023

Epoch: 6| Step: 10
Training loss: 2.148099660873413
Validation loss: 2.104471675811275

Epoch: 6| Step: 11
Training loss: 2.0376453399658203
Validation loss: 2.0762525014979865

Epoch: 6| Step: 12
Training loss: 1.270486831665039
Validation loss: 2.0771433679006432

Epoch: 6| Step: 13
Training loss: 1.2868423461914062
Validation loss: 2.120061565470952

Epoch: 320| Step: 0
Training loss: 1.9963808059692383
Validation loss: 2.066194233073983

Epoch: 6| Step: 1
Training loss: 1.8425158262252808
Validation loss: 2.0811276217942596

Epoch: 6| Step: 2
Training loss: 1.2032235860824585
Validation loss: 2.1070576790840394

Epoch: 6| Step: 3
Training loss: 1.6367377042770386
Validation loss: 2.0528081155592397

Epoch: 6| Step: 4
Training loss: 1.618429183959961
Validation loss: 2.0817847956893263

Epoch: 6| Step: 5
Training loss: 1.4672982692718506
Validation loss: 2.0633061752524426

Epoch: 6| Step: 6
Training loss: 1.9940619468688965
Validation loss: 2.06046958379848

Epoch: 6| Step: 7
Training loss: 1.9411523342132568
Validation loss: 2.113007796707974

Epoch: 6| Step: 8
Training loss: 2.2955286502838135
Validation loss: 2.0419489311915573

Epoch: 6| Step: 9
Training loss: 1.7399848699569702
Validation loss: 2.1015558217161443

Epoch: 6| Step: 10
Training loss: 1.9545022249221802
Validation loss: 2.099524300585511

Epoch: 6| Step: 11
Training loss: 1.8148701190948486
Validation loss: 2.040501058742564

Epoch: 6| Step: 12
Training loss: 1.1704084873199463
Validation loss: 2.0853896346143497

Epoch: 6| Step: 13
Training loss: 1.364768385887146
Validation loss: 2.04721333647287

Epoch: 321| Step: 0
Training loss: 1.902718186378479
Validation loss: 2.009657234273931

Epoch: 6| Step: 1
Training loss: 0.8885180354118347
Validation loss: 2.0825856065237396

Epoch: 6| Step: 2
Training loss: 1.435847520828247
Validation loss: 2.0798487919633106

Epoch: 6| Step: 3
Training loss: 1.6234742403030396
Validation loss: 2.067311312562676

Epoch: 6| Step: 4
Training loss: 2.355058193206787
Validation loss: 2.052010836139802

Epoch: 6| Step: 5
Training loss: 1.4774150848388672
Validation loss: 2.0794196769755375

Epoch: 6| Step: 6
Training loss: 2.4479546546936035
Validation loss: 2.102504114950857

Epoch: 6| Step: 7
Training loss: 1.2160143852233887
Validation loss: 2.0571560064951577

Epoch: 6| Step: 8
Training loss: 1.6912461519241333
Validation loss: 2.0930156759036485

Epoch: 6| Step: 9
Training loss: 2.0951414108276367
Validation loss: 2.058769864420737

Epoch: 6| Step: 10
Training loss: 1.6554205417633057
Validation loss: 2.048931711463518

Epoch: 6| Step: 11
Training loss: 2.0984408855438232
Validation loss: 2.08601217116079

Epoch: 6| Step: 12
Training loss: 1.5219906568527222
Validation loss: 2.0617375476385957

Epoch: 6| Step: 13
Training loss: 1.4765474796295166
Validation loss: 2.1059611407659387

Epoch: 322| Step: 0
Training loss: 1.8861947059631348
Validation loss: 2.0873684114025486

Epoch: 6| Step: 1
Training loss: 1.5829918384552002
Validation loss: 2.100868276370469

Epoch: 6| Step: 2
Training loss: 1.3747318983078003
Validation loss: 2.049029892490756

Epoch: 6| Step: 3
Training loss: 2.56923770904541
Validation loss: 2.0716998474572295

Epoch: 6| Step: 4
Training loss: 1.85027015209198
Validation loss: 2.070335042092108

Epoch: 6| Step: 5
Training loss: 2.3019673824310303
Validation loss: 2.0542700829044467

Epoch: 6| Step: 6
Training loss: 1.7245131731033325
Validation loss: 2.082963915281398

Epoch: 6| Step: 7
Training loss: 1.500105381011963
Validation loss: 2.0593845357177076

Epoch: 6| Step: 8
Training loss: 2.1144988536834717
Validation loss: 2.0752983554717033

Epoch: 6| Step: 9
Training loss: 1.6704578399658203
Validation loss: 2.077559681348903

Epoch: 6| Step: 10
Training loss: 1.2341285943984985
Validation loss: 2.0636930081152145

Epoch: 6| Step: 11
Training loss: 1.6513185501098633
Validation loss: 2.0786689507064

Epoch: 6| Step: 12
Training loss: 1.5911692380905151
Validation loss: 2.050356594465112

Epoch: 6| Step: 13
Training loss: 0.5541085600852966
Validation loss: 2.0538261244373937

Epoch: 323| Step: 0
Training loss: 1.0744988918304443
Validation loss: 2.06831443566148

Epoch: 6| Step: 1
Training loss: 1.5806450843811035
Validation loss: 2.057243444586313

Epoch: 6| Step: 2
Training loss: 2.090968132019043
Validation loss: 2.035231908162435

Epoch: 6| Step: 3
Training loss: 1.4398624897003174
Validation loss: 2.061947609788628

Epoch: 6| Step: 4
Training loss: 2.0443601608276367
Validation loss: 2.066544435357535

Epoch: 6| Step: 5
Training loss: 1.2935796976089478
Validation loss: 2.0526786465798654

Epoch: 6| Step: 6
Training loss: 2.1804161071777344
Validation loss: 2.066812753677368

Epoch: 6| Step: 7
Training loss: 2.143444538116455
Validation loss: 2.0680646921998713

Epoch: 6| Step: 8
Training loss: 1.7357630729675293
Validation loss: 2.039413962312924

Epoch: 6| Step: 9
Training loss: 1.8651912212371826
Validation loss: 2.0984842367069696

Epoch: 6| Step: 10
Training loss: 1.4220232963562012
Validation loss: 2.0690911739103255

Epoch: 6| Step: 11
Training loss: 2.059695243835449
Validation loss: 2.089295102703956

Epoch: 6| Step: 12
Training loss: 1.515958309173584
Validation loss: 2.073721981817676

Epoch: 6| Step: 13
Training loss: 1.4141062498092651
Validation loss: 2.0523183743158975

Epoch: 324| Step: 0
Training loss: 1.9720327854156494
Validation loss: 2.0656982121929044

Epoch: 6| Step: 1
Training loss: 1.4237637519836426
Validation loss: 2.0803821573975267

Epoch: 6| Step: 2
Training loss: 1.555628776550293
Validation loss: 2.067856316925377

Epoch: 6| Step: 3
Training loss: 1.1214804649353027
Validation loss: 2.082242186351489

Epoch: 6| Step: 4
Training loss: 2.1955647468566895
Validation loss: 2.0884729546885334

Epoch: 6| Step: 5
Training loss: 1.6482162475585938
Validation loss: 2.0682290459191925

Epoch: 6| Step: 6
Training loss: 1.4986908435821533
Validation loss: 2.0948876488593315

Epoch: 6| Step: 7
Training loss: 2.1469573974609375
Validation loss: 2.065686005418019

Epoch: 6| Step: 8
Training loss: 1.5295162200927734
Validation loss: 2.064746404206881

Epoch: 6| Step: 9
Training loss: 2.16359806060791
Validation loss: 2.0665292996232227

Epoch: 6| Step: 10
Training loss: 1.8711419105529785
Validation loss: 2.069010191066291

Epoch: 6| Step: 11
Training loss: 1.2160390615463257
Validation loss: 2.083895082114845

Epoch: 6| Step: 12
Training loss: 2.053691864013672
Validation loss: 2.0636985366062452

Epoch: 6| Step: 13
Training loss: 0.8890069127082825
Validation loss: 2.0408765218591176

Epoch: 325| Step: 0
Training loss: 1.6021963357925415
Validation loss: 2.0527159808784403

Epoch: 6| Step: 1
Training loss: 1.6606009006500244
Validation loss: 2.044526607759537

Epoch: 6| Step: 2
Training loss: 1.540277361869812
Validation loss: 2.0528990350743777

Epoch: 6| Step: 3
Training loss: 0.94461989402771
Validation loss: 2.0470717222459855

Epoch: 6| Step: 4
Training loss: 1.659989595413208
Validation loss: 2.033700289264802

Epoch: 6| Step: 5
Training loss: 2.783008098602295
Validation loss: 2.0749585602873113

Epoch: 6| Step: 6
Training loss: 1.4981863498687744
Validation loss: 2.0590233136248846

Epoch: 6| Step: 7
Training loss: 2.1657423973083496
Validation loss: 2.050669567559355

Epoch: 6| Step: 8
Training loss: 1.4031975269317627
Validation loss: 2.0597668822093675

Epoch: 6| Step: 9
Training loss: 1.8405158519744873
Validation loss: 2.033362942357217

Epoch: 6| Step: 10
Training loss: 1.5842106342315674
Validation loss: 2.103675055247481

Epoch: 6| Step: 11
Training loss: 1.6184437274932861
Validation loss: 2.066511259284071

Epoch: 6| Step: 12
Training loss: 2.1635546684265137
Validation loss: 2.1008180059412473

Epoch: 6| Step: 13
Training loss: 0.794781506061554
Validation loss: 2.0616094014977895

Epoch: 326| Step: 0
Training loss: 1.9278144836425781
Validation loss: 2.063756271075177

Epoch: 6| Step: 1
Training loss: 1.5473452806472778
Validation loss: 2.091879406282979

Epoch: 6| Step: 2
Training loss: 1.7228611707687378
Validation loss: 2.1001880335551437

Epoch: 6| Step: 3
Training loss: 1.2261860370635986
Validation loss: 2.0232040510382703

Epoch: 6| Step: 4
Training loss: 1.8500553369522095
Validation loss: 2.057062174684258

Epoch: 6| Step: 5
Training loss: 1.566309928894043
Validation loss: 2.0732146745086997

Epoch: 6| Step: 6
Training loss: 2.0642030239105225
Validation loss: 2.047600994827927

Epoch: 6| Step: 7
Training loss: 0.8818373680114746
Validation loss: 2.0658998386834257

Epoch: 6| Step: 8
Training loss: 2.4268529415130615
Validation loss: 2.0474428707553494

Epoch: 6| Step: 9
Training loss: 2.4196419715881348
Validation loss: 2.0729511271240892

Epoch: 6| Step: 10
Training loss: 1.5095757246017456
Validation loss: 2.0498566909502913

Epoch: 6| Step: 11
Training loss: 1.1503210067749023
Validation loss: 2.066860621975314

Epoch: 6| Step: 12
Training loss: 1.6202446222305298
Validation loss: 2.033884463771697

Epoch: 6| Step: 13
Training loss: 1.8820394277572632
Validation loss: 2.063036459748463

Epoch: 327| Step: 0
Training loss: 1.5233361721038818
Validation loss: 2.08801806101235

Epoch: 6| Step: 1
Training loss: 1.1564631462097168
Validation loss: 2.087029536565145

Epoch: 6| Step: 2
Training loss: 1.5868935585021973
Validation loss: 2.08543897187838

Epoch: 6| Step: 3
Training loss: 1.9706478118896484
Validation loss: 2.080530192262383

Epoch: 6| Step: 4
Training loss: 1.6403669118881226
Validation loss: 2.079383370696857

Epoch: 6| Step: 5
Training loss: 1.3788552284240723
Validation loss: 2.0894866886959282

Epoch: 6| Step: 6
Training loss: 1.9004979133605957
Validation loss: 2.085868832885578

Epoch: 6| Step: 7
Training loss: 2.194485664367676
Validation loss: 2.0870369583047848

Epoch: 6| Step: 8
Training loss: 1.813197135925293
Validation loss: 2.06414867472905

Epoch: 6| Step: 9
Training loss: 1.6052002906799316
Validation loss: 2.078663813170566

Epoch: 6| Step: 10
Training loss: 1.311987280845642
Validation loss: 2.055864344361008

Epoch: 6| Step: 11
Training loss: 2.1576311588287354
Validation loss: 2.1021505043070805

Epoch: 6| Step: 12
Training loss: 1.3198683261871338
Validation loss: 2.0874557008025465

Epoch: 6| Step: 13
Training loss: 2.8508496284484863
Validation loss: 2.063094728736467

Epoch: 328| Step: 0
Training loss: 1.423363447189331
Validation loss: 2.043680105158078

Epoch: 6| Step: 1
Training loss: 1.4729112386703491
Validation loss: 2.0313432729372414

Epoch: 6| Step: 2
Training loss: 2.050173044204712
Validation loss: 2.0704293251037598

Epoch: 6| Step: 3
Training loss: 1.6986075639724731
Validation loss: 2.051087728110693

Epoch: 6| Step: 4
Training loss: 2.028327465057373
Validation loss: 2.07819486946188

Epoch: 6| Step: 5
Training loss: 1.6986538171768188
Validation loss: 2.065644642358185

Epoch: 6| Step: 6
Training loss: 1.7345881462097168
Validation loss: 2.050548827776345

Epoch: 6| Step: 7
Training loss: 2.0673840045928955
Validation loss: 2.065235250739641

Epoch: 6| Step: 8
Training loss: 1.3075904846191406
Validation loss: 2.066673560809064

Epoch: 6| Step: 9
Training loss: 1.6756205558776855
Validation loss: 2.0427061908988544

Epoch: 6| Step: 10
Training loss: 1.9383457899093628
Validation loss: 2.067213528899736

Epoch: 6| Step: 11
Training loss: 1.615551471710205
Validation loss: 2.1013754503701323

Epoch: 6| Step: 12
Training loss: 1.2462137937545776
Validation loss: 2.071067287075904

Epoch: 6| Step: 13
Training loss: 1.7345693111419678
Validation loss: 2.0620942615693614

Epoch: 329| Step: 0
Training loss: 1.5963683128356934
Validation loss: 2.0733329352512153

Epoch: 6| Step: 1
Training loss: 1.7596700191497803
Validation loss: 2.050844192504883

Epoch: 6| Step: 2
Training loss: 1.9550647735595703
Validation loss: 2.051495223916987

Epoch: 6| Step: 3
Training loss: 1.6686291694641113
Validation loss: 2.0909286083713656

Epoch: 6| Step: 4
Training loss: 1.3035197257995605
Validation loss: 2.0592944391312136

Epoch: 6| Step: 5
Training loss: 1.382753849029541
Validation loss: 2.0600046201418807

Epoch: 6| Step: 6
Training loss: 1.8315832614898682
Validation loss: 2.0891860864495717

Epoch: 6| Step: 7
Training loss: 2.059018850326538
Validation loss: 2.0693156334661666

Epoch: 6| Step: 8
Training loss: 1.2042086124420166
Validation loss: 2.0799786788161083

Epoch: 6| Step: 9
Training loss: 1.4896883964538574
Validation loss: 2.0780378695457213

Epoch: 6| Step: 10
Training loss: 1.8470878601074219
Validation loss: 2.070504944811585

Epoch: 6| Step: 11
Training loss: 1.6010913848876953
Validation loss: 2.0774903041060253

Epoch: 6| Step: 12
Training loss: 2.1671667098999023
Validation loss: 2.0909722158985753

Epoch: 6| Step: 13
Training loss: 2.1522057056427
Validation loss: 2.0783441271833194

Epoch: 330| Step: 0
Training loss: 1.4505858421325684
Validation loss: 2.0709089925212245

Epoch: 6| Step: 1
Training loss: 1.5143194198608398
Validation loss: 2.1046567629742365

Epoch: 6| Step: 2
Training loss: 2.024312973022461
Validation loss: 2.0727433594324256

Epoch: 6| Step: 3
Training loss: 1.1756246089935303
Validation loss: 2.0508687188548427

Epoch: 6| Step: 4
Training loss: 1.7820765972137451
Validation loss: 2.061122220049622

Epoch: 6| Step: 5
Training loss: 1.7151167392730713
Validation loss: 2.0744796337619906

Epoch: 6| Step: 6
Training loss: 1.6817162036895752
Validation loss: 2.07138793699203

Epoch: 6| Step: 7
Training loss: 1.972637414932251
Validation loss: 2.0709916417316725

Epoch: 6| Step: 8
Training loss: 1.3309381008148193
Validation loss: 2.061112984534233

Epoch: 6| Step: 9
Training loss: 1.706966757774353
Validation loss: 2.091556055571443

Epoch: 6| Step: 10
Training loss: 2.3591725826263428
Validation loss: 2.03789153663061

Epoch: 6| Step: 11
Training loss: 1.7246536016464233
Validation loss: 2.0867570997566305

Epoch: 6| Step: 12
Training loss: 1.829729437828064
Validation loss: 2.0342010862083844

Epoch: 6| Step: 13
Training loss: 1.0868945121765137
Validation loss: 2.0760586210476455

Epoch: 331| Step: 0
Training loss: 1.9617455005645752
Validation loss: 2.0147787396625807

Epoch: 6| Step: 1
Training loss: 1.7011406421661377
Validation loss: 2.0547277055760866

Epoch: 6| Step: 2
Training loss: 1.4820280075073242
Validation loss: 2.0598954359690347

Epoch: 6| Step: 3
Training loss: 2.2012808322906494
Validation loss: 2.070597125637916

Epoch: 6| Step: 4
Training loss: 1.2632529735565186
Validation loss: 2.076037786340201

Epoch: 6| Step: 5
Training loss: 1.8763103485107422
Validation loss: 2.0781794850544264

Epoch: 6| Step: 6
Training loss: 1.4728455543518066
Validation loss: 2.1001464833495436

Epoch: 6| Step: 7
Training loss: 1.7090942859649658
Validation loss: 2.101263233410415

Epoch: 6| Step: 8
Training loss: 1.9804223775863647
Validation loss: 2.114014261512346

Epoch: 6| Step: 9
Training loss: 1.6635364294052124
Validation loss: 2.053195836723492

Epoch: 6| Step: 10
Training loss: 1.721815824508667
Validation loss: 2.0640850169684297

Epoch: 6| Step: 11
Training loss: 1.2827537059783936
Validation loss: 2.0631326013995754

Epoch: 6| Step: 12
Training loss: 1.4966586828231812
Validation loss: 2.064076941500428

Epoch: 6| Step: 13
Training loss: 1.529424786567688
Validation loss: 2.110145522702125

Epoch: 332| Step: 0
Training loss: 1.5713417530059814
Validation loss: 2.0770727947194088

Epoch: 6| Step: 1
Training loss: 2.236544132232666
Validation loss: 2.117786445925313

Epoch: 6| Step: 2
Training loss: 1.8289867639541626
Validation loss: 2.1017618435685352

Epoch: 6| Step: 3
Training loss: 1.732823133468628
Validation loss: 2.1005779466321393

Epoch: 6| Step: 4
Training loss: 1.5993942022323608
Validation loss: 2.097941219165761

Epoch: 6| Step: 5
Training loss: 1.4022883176803589
Validation loss: 2.0885471964395173

Epoch: 6| Step: 6
Training loss: 1.5101218223571777
Validation loss: 2.0654039126570507

Epoch: 6| Step: 7
Training loss: 0.8638126254081726
Validation loss: 2.075459767413396

Epoch: 6| Step: 8
Training loss: 1.328033447265625
Validation loss: 2.0870058946712042

Epoch: 6| Step: 9
Training loss: 1.9742114543914795
Validation loss: 2.056171240345124

Epoch: 6| Step: 10
Training loss: 1.4603948593139648
Validation loss: 2.0889959207145115

Epoch: 6| Step: 11
Training loss: 1.818105936050415
Validation loss: 2.0542469678386563

Epoch: 6| Step: 12
Training loss: 1.9315791130065918
Validation loss: 2.0737693694330033

Epoch: 6| Step: 13
Training loss: 2.467282295227051
Validation loss: 2.075912453794992

Epoch: 333| Step: 0
Training loss: 1.1811964511871338
Validation loss: 2.0106050288805397

Epoch: 6| Step: 1
Training loss: 1.5594877004623413
Validation loss: 2.0851395463430755

Epoch: 6| Step: 2
Training loss: 1.6785101890563965
Validation loss: 2.0761875670443297

Epoch: 6| Step: 3
Training loss: 1.9436696767807007
Validation loss: 2.0729859182911534

Epoch: 6| Step: 4
Training loss: 1.7412352561950684
Validation loss: 2.0750035355168004

Epoch: 6| Step: 5
Training loss: 1.9745301008224487
Validation loss: 2.105614664734051

Epoch: 6| Step: 6
Training loss: 1.7760746479034424
Validation loss: 2.049375808367165

Epoch: 6| Step: 7
Training loss: 1.174774408340454
Validation loss: 2.0724120665622014

Epoch: 6| Step: 8
Training loss: 1.9464362859725952
Validation loss: 2.11153289323212

Epoch: 6| Step: 9
Training loss: 1.6560662984848022
Validation loss: 2.0843885470462102

Epoch: 6| Step: 10
Training loss: 2.0144338607788086
Validation loss: 2.077664752160349

Epoch: 6| Step: 11
Training loss: 1.8306300640106201
Validation loss: 2.0564683765493412

Epoch: 6| Step: 12
Training loss: 0.9672833681106567
Validation loss: 2.0541927276119107

Epoch: 6| Step: 13
Training loss: 2.3886630535125732
Validation loss: 2.058571700126894

Epoch: 334| Step: 0
Training loss: 1.237652063369751
Validation loss: 2.041101017305928

Epoch: 6| Step: 1
Training loss: 1.2672415971755981
Validation loss: 2.045107961982809

Epoch: 6| Step: 2
Training loss: 1.7912477254867554
Validation loss: 2.0575455055441907

Epoch: 6| Step: 3
Training loss: 1.9232652187347412
Validation loss: 2.050548461175734

Epoch: 6| Step: 4
Training loss: 1.4998791217803955
Validation loss: 2.0906971295674643

Epoch: 6| Step: 5
Training loss: 1.6571260690689087
Validation loss: 2.076989876326694

Epoch: 6| Step: 6
Training loss: 1.782662272453308
Validation loss: 2.079175523532334

Epoch: 6| Step: 7
Training loss: 1.6390910148620605
Validation loss: 2.075669309144379

Epoch: 6| Step: 8
Training loss: 2.1011714935302734
Validation loss: 2.0829480873641146

Epoch: 6| Step: 9
Training loss: 1.8717999458312988
Validation loss: 2.115186123437779

Epoch: 6| Step: 10
Training loss: 1.7408146858215332
Validation loss: 2.102577458145798

Epoch: 6| Step: 11
Training loss: 2.2319374084472656
Validation loss: 2.089683360950921

Epoch: 6| Step: 12
Training loss: 1.1092596054077148
Validation loss: 2.077361963128531

Epoch: 6| Step: 13
Training loss: 1.428082823753357
Validation loss: 2.0829087611167663

Epoch: 335| Step: 0
Training loss: 1.764749526977539
Validation loss: 2.078352451324463

Epoch: 6| Step: 1
Training loss: 1.3299250602722168
Validation loss: 2.0798124920937324

Epoch: 6| Step: 2
Training loss: 1.5251283645629883
Validation loss: 2.0718455647909515

Epoch: 6| Step: 3
Training loss: 1.6623311042785645
Validation loss: 2.0956993474755237

Epoch: 6| Step: 4
Training loss: 1.3604013919830322
Validation loss: 2.072107793182455

Epoch: 6| Step: 5
Training loss: 1.499021291732788
Validation loss: 2.046685059865316

Epoch: 6| Step: 6
Training loss: 1.2761961221694946
Validation loss: 2.060346734139227

Epoch: 6| Step: 7
Training loss: 1.5768159627914429
Validation loss: 2.0896140426717777

Epoch: 6| Step: 8
Training loss: 2.1771295070648193
Validation loss: 2.033405004009124

Epoch: 6| Step: 9
Training loss: 1.5963071584701538
Validation loss: 2.089381925521358

Epoch: 6| Step: 10
Training loss: 2.014972448348999
Validation loss: 2.057434558868408

Epoch: 6| Step: 11
Training loss: 2.396998882293701
Validation loss: 2.0339454835461033

Epoch: 6| Step: 12
Training loss: 1.2669031620025635
Validation loss: 2.0928125766015824

Epoch: 6| Step: 13
Training loss: 2.2480974197387695
Validation loss: 2.0764056662077546

Epoch: 336| Step: 0
Training loss: 1.281842589378357
Validation loss: 2.0498017393132693

Epoch: 6| Step: 1
Training loss: 1.4553102254867554
Validation loss: 2.0648785816725863

Epoch: 6| Step: 2
Training loss: 1.8839898109436035
Validation loss: 2.1038407343690113

Epoch: 6| Step: 3
Training loss: 1.2564520835876465
Validation loss: 2.061121763721589

Epoch: 6| Step: 4
Training loss: 2.1204137802124023
Validation loss: 2.065172051870695

Epoch: 6| Step: 5
Training loss: 1.5516542196273804
Validation loss: 2.0748961651197044

Epoch: 6| Step: 6
Training loss: 1.6181020736694336
Validation loss: 2.0892085875234296

Epoch: 6| Step: 7
Training loss: 1.6643633842468262
Validation loss: 2.0595031553699124

Epoch: 6| Step: 8
Training loss: 1.851247787475586
Validation loss: 2.034449654240762

Epoch: 6| Step: 9
Training loss: 1.6722137928009033
Validation loss: 2.0251447616084928

Epoch: 6| Step: 10
Training loss: 1.2752188444137573
Validation loss: 2.0779257692316526

Epoch: 6| Step: 11
Training loss: 1.9713256359100342
Validation loss: 2.1162983986639206

Epoch: 6| Step: 12
Training loss: 2.29369854927063
Validation loss: 2.076971668069081

Epoch: 6| Step: 13
Training loss: 1.3077504634857178
Validation loss: 2.082683147922639

Epoch: 337| Step: 0
Training loss: 1.5378713607788086
Validation loss: 2.0679015216007026

Epoch: 6| Step: 1
Training loss: 1.4027328491210938
Validation loss: 2.069461145708638

Epoch: 6| Step: 2
Training loss: 2.022449254989624
Validation loss: 2.066350398525115

Epoch: 6| Step: 3
Training loss: 1.6835987567901611
Validation loss: 2.1007465188221266

Epoch: 6| Step: 4
Training loss: 1.2532678842544556
Validation loss: 2.04594781321864

Epoch: 6| Step: 5
Training loss: 2.0859971046447754
Validation loss: 2.054956672012165

Epoch: 6| Step: 6
Training loss: 1.1626356840133667
Validation loss: 2.047540383954202

Epoch: 6| Step: 7
Training loss: 1.957671046257019
Validation loss: 2.0588407362661054

Epoch: 6| Step: 8
Training loss: 1.7615559101104736
Validation loss: 2.075485614038283

Epoch: 6| Step: 9
Training loss: 1.5831427574157715
Validation loss: 2.084033789173249

Epoch: 6| Step: 10
Training loss: 1.6797560453414917
Validation loss: 2.054008101904264

Epoch: 6| Step: 11
Training loss: 1.649604320526123
Validation loss: 2.0905383376665014

Epoch: 6| Step: 12
Training loss: 2.2801246643066406
Validation loss: 2.0831757309616252

Epoch: 6| Step: 13
Training loss: 1.6759936809539795
Validation loss: 2.0488447245731147

Epoch: 338| Step: 0
Training loss: 1.2995150089263916
Validation loss: 2.0771196862702728

Epoch: 6| Step: 1
Training loss: 1.462256669998169
Validation loss: 2.072070775493499

Epoch: 6| Step: 2
Training loss: 2.224881649017334
Validation loss: 2.016479035859467

Epoch: 6| Step: 3
Training loss: 2.5187861919403076
Validation loss: 2.0471248780527422

Epoch: 6| Step: 4
Training loss: 2.335841655731201
Validation loss: 2.0919377996075537

Epoch: 6| Step: 5
Training loss: 1.7243478298187256
Validation loss: 2.0602483698116836

Epoch: 6| Step: 6
Training loss: 1.4182548522949219
Validation loss: 2.044353215925155

Epoch: 6| Step: 7
Training loss: 1.5224900245666504
Validation loss: 2.0857694059289913

Epoch: 6| Step: 8
Training loss: 1.2259665727615356
Validation loss: 2.048814373631631

Epoch: 6| Step: 9
Training loss: 1.6764447689056396
Validation loss: 2.0956584099800355

Epoch: 6| Step: 10
Training loss: 1.5096261501312256
Validation loss: 2.0316748747261624

Epoch: 6| Step: 11
Training loss: 1.5738407373428345
Validation loss: 2.064732177283174

Epoch: 6| Step: 12
Training loss: 1.3313498497009277
Validation loss: 2.0913383729996218

Epoch: 6| Step: 13
Training loss: 1.9035497903823853
Validation loss: 2.056281292310325

Epoch: 339| Step: 0
Training loss: 1.2709991931915283
Validation loss: 2.0655465792584162

Epoch: 6| Step: 1
Training loss: 2.1917123794555664
Validation loss: 2.1019203303962626

Epoch: 6| Step: 2
Training loss: 2.1819682121276855
Validation loss: 2.0778563266159384

Epoch: 6| Step: 3
Training loss: 1.110390305519104
Validation loss: 2.107184338313277

Epoch: 6| Step: 4
Training loss: 1.9026548862457275
Validation loss: 2.117471541127851

Epoch: 6| Step: 5
Training loss: 2.2896063327789307
Validation loss: 2.10620819112306

Epoch: 6| Step: 6
Training loss: 1.1202596426010132
Validation loss: 2.0830936585703204

Epoch: 6| Step: 7
Training loss: 1.42836332321167
Validation loss: 2.075945387604416

Epoch: 6| Step: 8
Training loss: 1.613994836807251
Validation loss: 2.0804037201789116

Epoch: 6| Step: 9
Training loss: 1.5142114162445068
Validation loss: 2.0893431684022308

Epoch: 6| Step: 10
Training loss: 1.1299381256103516
Validation loss: 2.077902050428493

Epoch: 6| Step: 11
Training loss: 1.8727335929870605
Validation loss: 2.079933638213783

Epoch: 6| Step: 12
Training loss: 1.8466649055480957
Validation loss: 2.112331090434905

Epoch: 6| Step: 13
Training loss: 1.79453444480896
Validation loss: 2.076590843098138

Epoch: 340| Step: 0
Training loss: 1.5008153915405273
Validation loss: 2.074998508217514

Epoch: 6| Step: 1
Training loss: 1.4110456705093384
Validation loss: 2.1011889519230014

Epoch: 6| Step: 2
Training loss: 1.5683541297912598
Validation loss: 2.087376052333463

Epoch: 6| Step: 3
Training loss: 2.0741868019104004
Validation loss: 2.0911000031296925

Epoch: 6| Step: 4
Training loss: 1.5624995231628418
Validation loss: 2.0600368771501767

Epoch: 6| Step: 5
Training loss: 1.476393222808838
Validation loss: 2.058110447340114

Epoch: 6| Step: 6
Training loss: 1.3431183099746704
Validation loss: 2.0579331241628176

Epoch: 6| Step: 7
Training loss: 1.7053710222244263
Validation loss: 2.0729571068158714

Epoch: 6| Step: 8
Training loss: 1.156672477722168
Validation loss: 2.0924413563102804

Epoch: 6| Step: 9
Training loss: 1.7558362483978271
Validation loss: 2.0363459894734044

Epoch: 6| Step: 10
Training loss: 1.7717691659927368
Validation loss: 2.0795981268728934

Epoch: 6| Step: 11
Training loss: 1.9352909326553345
Validation loss: 2.0800509427183416

Epoch: 6| Step: 12
Training loss: 2.377401828765869
Validation loss: 2.073299502813688

Epoch: 6| Step: 13
Training loss: 2.065591335296631
Validation loss: 2.0657332712604153

Epoch: 341| Step: 0
Training loss: 2.0370075702667236
Validation loss: 2.032114158394516

Epoch: 6| Step: 1
Training loss: 1.5251041650772095
Validation loss: 2.0489284710217546

Epoch: 6| Step: 2
Training loss: 2.05899715423584
Validation loss: 2.067090052430348

Epoch: 6| Step: 3
Training loss: 1.4129185676574707
Validation loss: 2.0905965976817633

Epoch: 6| Step: 4
Training loss: 1.495568871498108
Validation loss: 2.0937678839570735

Epoch: 6| Step: 5
Training loss: 1.4387072324752808
Validation loss: 2.122134513752435

Epoch: 6| Step: 6
Training loss: 1.4084391593933105
Validation loss: 2.1033927932862313

Epoch: 6| Step: 7
Training loss: 0.9466435313224792
Validation loss: 2.051419101735597

Epoch: 6| Step: 8
Training loss: 2.2637240886688232
Validation loss: 2.0768335532116633

Epoch: 6| Step: 9
Training loss: 1.354170799255371
Validation loss: 2.0947375900001934

Epoch: 6| Step: 10
Training loss: 1.5798765420913696
Validation loss: 2.0876446193264377

Epoch: 6| Step: 11
Training loss: 2.174128770828247
Validation loss: 2.0922106664667846

Epoch: 6| Step: 12
Training loss: 2.1626596450805664
Validation loss: 2.105027121882285

Epoch: 6| Step: 13
Training loss: 1.1106657981872559
Validation loss: 2.0796638419551234

Epoch: 342| Step: 0
Training loss: 1.8297442197799683
Validation loss: 2.0734376958621445

Epoch: 6| Step: 1
Training loss: 1.2351316213607788
Validation loss: 2.0911428851466023

Epoch: 6| Step: 2
Training loss: 1.9314086437225342
Validation loss: 2.071741191289758

Epoch: 6| Step: 3
Training loss: 1.0584022998809814
Validation loss: 2.034502375510431

Epoch: 6| Step: 4
Training loss: 1.962710976600647
Validation loss: 2.0744094079540623

Epoch: 6| Step: 5
Training loss: 1.3621454238891602
Validation loss: 2.0589359037337767

Epoch: 6| Step: 6
Training loss: 2.100100040435791
Validation loss: 2.0688293518558627

Epoch: 6| Step: 7
Training loss: 2.231351613998413
Validation loss: 2.0643475042876376

Epoch: 6| Step: 8
Training loss: 1.8610620498657227
Validation loss: 2.060009241104126

Epoch: 6| Step: 9
Training loss: 1.7076507806777954
Validation loss: 2.070671546843744

Epoch: 6| Step: 10
Training loss: 1.775172472000122
Validation loss: 2.0537590185801187

Epoch: 6| Step: 11
Training loss: 1.3485316038131714
Validation loss: 2.0817277457124446

Epoch: 6| Step: 12
Training loss: 1.3511769771575928
Validation loss: 2.0638143682992585

Epoch: 6| Step: 13
Training loss: 1.8408232927322388
Validation loss: 2.0773592238785117

Epoch: 343| Step: 0
Training loss: 1.5147475004196167
Validation loss: 2.1284525317530476

Epoch: 6| Step: 1
Training loss: 2.375357151031494
Validation loss: 2.1392430823336364

Epoch: 6| Step: 2
Training loss: 1.3700965642929077
Validation loss: 2.092707451953683

Epoch: 6| Step: 3
Training loss: 1.535223126411438
Validation loss: 2.0817420072452997

Epoch: 6| Step: 4
Training loss: 1.2102842330932617
Validation loss: 2.124519301999

Epoch: 6| Step: 5
Training loss: 1.8462311029434204
Validation loss: 2.089898350418255

Epoch: 6| Step: 6
Training loss: 2.02321457862854
Validation loss: 2.120910167694092

Epoch: 6| Step: 7
Training loss: 1.9534341096878052
Validation loss: 2.100257776116812

Epoch: 6| Step: 8
Training loss: 1.3222254514694214
Validation loss: 2.124350186317198

Epoch: 6| Step: 9
Training loss: 1.8540170192718506
Validation loss: 2.1046637822222967

Epoch: 6| Step: 10
Training loss: 1.7325178384780884
Validation loss: 2.1032297021599224

Epoch: 6| Step: 11
Training loss: 1.9714425802230835
Validation loss: 2.0834349304117183

Epoch: 6| Step: 12
Training loss: 1.2125232219696045
Validation loss: 2.1179740723743232

Epoch: 6| Step: 13
Training loss: 1.5923128128051758
Validation loss: 2.112561866801272

Epoch: 344| Step: 0
Training loss: 1.9354935884475708
Validation loss: 2.0971798742971113

Epoch: 6| Step: 1
Training loss: 1.5222448110580444
Validation loss: 2.089696572672936

Epoch: 6| Step: 2
Training loss: 1.4890286922454834
Validation loss: 2.0992340939019316

Epoch: 6| Step: 3
Training loss: 1.0706489086151123
Validation loss: 2.0947123560854184

Epoch: 6| Step: 4
Training loss: 1.64144766330719
Validation loss: 2.0729413455532444

Epoch: 6| Step: 5
Training loss: 1.8917735815048218
Validation loss: 2.096230355642175

Epoch: 6| Step: 6
Training loss: 2.3388452529907227
Validation loss: 2.0690982905767297

Epoch: 6| Step: 7
Training loss: 1.3861302137374878
Validation loss: 2.061891778822868

Epoch: 6| Step: 8
Training loss: 1.9905890226364136
Validation loss: 2.082871897246248

Epoch: 6| Step: 9
Training loss: 1.5868501663208008
Validation loss: 2.0863067219334264

Epoch: 6| Step: 10
Training loss: 1.513056993484497
Validation loss: 2.0355749412249495

Epoch: 6| Step: 11
Training loss: 1.6614503860473633
Validation loss: 2.072662853425549

Epoch: 6| Step: 12
Training loss: 1.5037034749984741
Validation loss: 2.0836550856149323

Epoch: 6| Step: 13
Training loss: 2.1674790382385254
Validation loss: 2.0906827244707333

Epoch: 345| Step: 0
Training loss: 1.707368016242981
Validation loss: 2.098762648079985

Epoch: 6| Step: 1
Training loss: 1.4657082557678223
Validation loss: 2.107646175610122

Epoch: 6| Step: 2
Training loss: 1.3759816884994507
Validation loss: 2.0774616195309545

Epoch: 6| Step: 3
Training loss: 1.6452758312225342
Validation loss: 2.0489484097367976

Epoch: 6| Step: 4
Training loss: 1.945732593536377
Validation loss: 2.104845667398104

Epoch: 6| Step: 5
Training loss: 1.4274533987045288
Validation loss: 2.1367205958212576

Epoch: 6| Step: 6
Training loss: 1.6354447603225708
Validation loss: 2.148227357095288

Epoch: 6| Step: 7
Training loss: 1.2458598613739014
Validation loss: 2.1552609192427767

Epoch: 6| Step: 8
Training loss: 1.439802885055542
Validation loss: 2.0948563878254225

Epoch: 6| Step: 9
Training loss: 2.1966712474823
Validation loss: 2.0870310068130493

Epoch: 6| Step: 10
Training loss: 2.0542683601379395
Validation loss: 2.0936116864604335

Epoch: 6| Step: 11
Training loss: 1.7974598407745361
Validation loss: 2.0523789287895284

Epoch: 6| Step: 12
Training loss: 1.7691715955734253
Validation loss: 2.079191497577134

Epoch: 6| Step: 13
Training loss: 1.5317950248718262
Validation loss: 2.0647244479066584

Epoch: 346| Step: 0
Training loss: 1.6386817693710327
Validation loss: 2.102463860665598

Epoch: 6| Step: 1
Training loss: 1.385271668434143
Validation loss: 2.0915273133144585

Epoch: 6| Step: 2
Training loss: 0.9529604911804199
Validation loss: 2.079313570453275

Epoch: 6| Step: 3
Training loss: 1.7786588668823242
Validation loss: 2.0672109114226473

Epoch: 6| Step: 4
Training loss: 1.5626511573791504
Validation loss: 2.043647976331813

Epoch: 6| Step: 5
Training loss: 1.5958603620529175
Validation loss: 2.0800490789515997

Epoch: 6| Step: 6
Training loss: 1.658064603805542
Validation loss: 2.0681554758420555

Epoch: 6| Step: 7
Training loss: 1.8823469877243042
Validation loss: 2.0918197426744687

Epoch: 6| Step: 8
Training loss: 2.0621657371520996
Validation loss: 2.0400943704830703

Epoch: 6| Step: 9
Training loss: 1.7420850992202759
Validation loss: 2.1002686536440285

Epoch: 6| Step: 10
Training loss: 1.5075418949127197
Validation loss: 2.0601057852468183

Epoch: 6| Step: 11
Training loss: 1.0570826530456543
Validation loss: 2.073115378297785

Epoch: 6| Step: 12
Training loss: 2.460444688796997
Validation loss: 2.0540509249574397

Epoch: 6| Step: 13
Training loss: 2.029491424560547
Validation loss: 2.081008748341632

Epoch: 347| Step: 0
Training loss: 1.8328211307525635
Validation loss: 2.0404774271031862

Epoch: 6| Step: 1
Training loss: 1.97062087059021
Validation loss: 2.0827539069678194

Epoch: 6| Step: 2
Training loss: 1.4865847826004028
Validation loss: 2.057709857981692

Epoch: 6| Step: 3
Training loss: 2.122398853302002
Validation loss: 2.0402095881841515

Epoch: 6| Step: 4
Training loss: 1.681745171546936
Validation loss: 2.0580834842497304

Epoch: 6| Step: 5
Training loss: 1.6312298774719238
Validation loss: 2.0493499104694655

Epoch: 6| Step: 6
Training loss: 2.1149635314941406
Validation loss: 2.1055538500508955

Epoch: 6| Step: 7
Training loss: 1.1173434257507324
Validation loss: 2.0698020547948857

Epoch: 6| Step: 8
Training loss: 1.196742296218872
Validation loss: 2.090993981207571

Epoch: 6| Step: 9
Training loss: 1.528085708618164
Validation loss: 2.0354163005787838

Epoch: 6| Step: 10
Training loss: 1.6602661609649658
Validation loss: 2.070053828659878

Epoch: 6| Step: 11
Training loss: 1.8686468601226807
Validation loss: 2.0518005919712845

Epoch: 6| Step: 12
Training loss: 1.067955493927002
Validation loss: 2.0377289556687876

Epoch: 6| Step: 13
Training loss: 1.6831263303756714
Validation loss: 2.0764037306590746

Epoch: 348| Step: 0
Training loss: 1.3797001838684082
Validation loss: 2.068076919483882

Epoch: 6| Step: 1
Training loss: 2.2101049423217773
Validation loss: 2.0668152070814565

Epoch: 6| Step: 2
Training loss: 2.014519214630127
Validation loss: 2.0726596437474734

Epoch: 6| Step: 3
Training loss: 1.9734437465667725
Validation loss: 2.073763724296324

Epoch: 6| Step: 4
Training loss: 1.521332859992981
Validation loss: 2.1053751412258355

Epoch: 6| Step: 5
Training loss: 1.274718999862671
Validation loss: 2.0356917894014748

Epoch: 6| Step: 6
Training loss: 0.9071327447891235
Validation loss: 2.0861956739938385

Epoch: 6| Step: 7
Training loss: 1.5684106349945068
Validation loss: 2.096724658884028

Epoch: 6| Step: 8
Training loss: 2.0510995388031006
Validation loss: 2.0858522179306194

Epoch: 6| Step: 9
Training loss: 1.7937097549438477
Validation loss: 2.0980454209030315

Epoch: 6| Step: 10
Training loss: 1.220186710357666
Validation loss: 2.09290627894863

Epoch: 6| Step: 11
Training loss: 2.1394946575164795
Validation loss: 2.0745715492515155

Epoch: 6| Step: 12
Training loss: 1.4167275428771973
Validation loss: 2.103967733280633

Epoch: 6| Step: 13
Training loss: 1.5357756614685059
Validation loss: 2.0424694502225487

Epoch: 349| Step: 0
Training loss: 1.4307827949523926
Validation loss: 2.0320125933616393

Epoch: 6| Step: 1
Training loss: 0.8347766399383545
Validation loss: 2.084359215151879

Epoch: 6| Step: 2
Training loss: 1.8464689254760742
Validation loss: 2.0671662233209096

Epoch: 6| Step: 3
Training loss: 0.9216077327728271
Validation loss: 2.0408571291995306

Epoch: 6| Step: 4
Training loss: 2.161367893218994
Validation loss: 2.077335816557689

Epoch: 6| Step: 5
Training loss: 1.6506078243255615
Validation loss: 2.098432364002351

Epoch: 6| Step: 6
Training loss: 2.234713554382324
Validation loss: 2.1011027007974605

Epoch: 6| Step: 7
Training loss: 1.9126614332199097
Validation loss: 2.053459129025859

Epoch: 6| Step: 8
Training loss: 1.822570562362671
Validation loss: 2.093251815406225

Epoch: 6| Step: 9
Training loss: 1.9514901638031006
Validation loss: 2.101279197200652

Epoch: 6| Step: 10
Training loss: 1.5381335020065308
Validation loss: 2.0814546923483572

Epoch: 6| Step: 11
Training loss: 0.9032558798789978
Validation loss: 2.0985115779343473

Epoch: 6| Step: 12
Training loss: 1.4564154148101807
Validation loss: 2.1172321304198234

Epoch: 6| Step: 13
Training loss: 2.4590578079223633
Validation loss: 2.0712896495737056

Epoch: 350| Step: 0
Training loss: 1.7035801410675049
Validation loss: 2.089042881483673

Epoch: 6| Step: 1
Training loss: 1.3944008350372314
Validation loss: 2.076819876188873

Epoch: 6| Step: 2
Training loss: 1.2004706859588623
Validation loss: 2.0664818491987003

Epoch: 6| Step: 3
Training loss: 1.6936229467391968
Validation loss: 2.1050248043511504

Epoch: 6| Step: 4
Training loss: 1.6990865468978882
Validation loss: 2.097964229122285

Epoch: 6| Step: 5
Training loss: 1.8818925619125366
Validation loss: 2.1511352600589877

Epoch: 6| Step: 6
Training loss: 1.4402605295181274
Validation loss: 2.13825568332467

Epoch: 6| Step: 7
Training loss: 1.3756425380706787
Validation loss: 2.0814499457677207

Epoch: 6| Step: 8
Training loss: 1.624740481376648
Validation loss: 2.0846547311352146

Epoch: 6| Step: 9
Training loss: 2.8751227855682373
Validation loss: 2.0520305441271876

Epoch: 6| Step: 10
Training loss: 1.7487425804138184
Validation loss: 2.07807481673456

Epoch: 6| Step: 11
Training loss: 1.415963888168335
Validation loss: 2.058824203347647

Epoch: 6| Step: 12
Training loss: 1.7626698017120361
Validation loss: 2.0660428616308395

Epoch: 6| Step: 13
Training loss: 1.0550551414489746
Validation loss: 2.1046981144976873

Epoch: 351| Step: 0
Training loss: 1.720536231994629
Validation loss: 2.0667550358721005

Epoch: 6| Step: 1
Training loss: 1.236154317855835
Validation loss: 2.1135884279845865

Epoch: 6| Step: 2
Training loss: 1.7689989805221558
Validation loss: 2.110024235581839

Epoch: 6| Step: 3
Training loss: 1.0814255475997925
Validation loss: 2.0432621073979202

Epoch: 6| Step: 4
Training loss: 1.82433021068573
Validation loss: 2.052010328538956

Epoch: 6| Step: 5
Training loss: 2.2183220386505127
Validation loss: 2.0800840649553525

Epoch: 6| Step: 6
Training loss: 1.2767328023910522
Validation loss: 2.0454198006660707

Epoch: 6| Step: 7
Training loss: 1.4671379327774048
Validation loss: 2.0701888107484385

Epoch: 6| Step: 8
Training loss: 2.0845794677734375
Validation loss: 2.0557172529159056

Epoch: 6| Step: 9
Training loss: 1.5444395542144775
Validation loss: 2.09010749478494

Epoch: 6| Step: 10
Training loss: 2.346611499786377
Validation loss: 2.065787906287819

Epoch: 6| Step: 11
Training loss: 1.5792675018310547
Validation loss: 2.0784051059394755

Epoch: 6| Step: 12
Training loss: 1.3178346157073975
Validation loss: 2.0242163468432683

Epoch: 6| Step: 13
Training loss: 1.3156026601791382
Validation loss: 2.072958700118526

Epoch: 352| Step: 0
Training loss: 1.8334861993789673
Validation loss: 2.075017963686297

Epoch: 6| Step: 1
Training loss: 2.3917689323425293
Validation loss: 2.090752314495784

Epoch: 6| Step: 2
Training loss: 1.5337083339691162
Validation loss: 2.0987009489408104

Epoch: 6| Step: 3
Training loss: 1.7839221954345703
Validation loss: 2.066435754940074

Epoch: 6| Step: 4
Training loss: 1.6819720268249512
Validation loss: 2.05330567718834

Epoch: 6| Step: 5
Training loss: 1.6246106624603271
Validation loss: 2.104178446595387

Epoch: 6| Step: 6
Training loss: 2.2188332080841064
Validation loss: 2.1076868580233667

Epoch: 6| Step: 7
Training loss: 1.9983235597610474
Validation loss: 2.0896809485650834

Epoch: 6| Step: 8
Training loss: 1.2988084554672241
Validation loss: 2.063299032949632

Epoch: 6| Step: 9
Training loss: 1.4352071285247803
Validation loss: 2.0721865046408867

Epoch: 6| Step: 10
Training loss: 1.262835144996643
Validation loss: 2.0791323466967513

Epoch: 6| Step: 11
Training loss: 0.9826356768608093
Validation loss: 2.0400005181630454

Epoch: 6| Step: 12
Training loss: 1.126299262046814
Validation loss: 2.056007940282104

Epoch: 6| Step: 13
Training loss: 1.867127776145935
Validation loss: 2.07038809663506

Epoch: 353| Step: 0
Training loss: 1.464597463607788
Validation loss: 2.0586841337142454

Epoch: 6| Step: 1
Training loss: 2.1933326721191406
Validation loss: 2.02768539356929

Epoch: 6| Step: 2
Training loss: 2.363166332244873
Validation loss: 2.0524161989970873

Epoch: 6| Step: 3
Training loss: 1.9058383703231812
Validation loss: 2.0901661380644767

Epoch: 6| Step: 4
Training loss: 1.4379839897155762
Validation loss: 2.049257052842007

Epoch: 6| Step: 5
Training loss: 1.3130229711532593
Validation loss: 2.0831885081465527

Epoch: 6| Step: 6
Training loss: 1.755078911781311
Validation loss: 2.0696851745728524

Epoch: 6| Step: 7
Training loss: 2.262694835662842
Validation loss: 2.0522502109568608

Epoch: 6| Step: 8
Training loss: 1.212493658065796
Validation loss: 2.0611417024366316

Epoch: 6| Step: 9
Training loss: 1.571456789970398
Validation loss: 2.062228513020341

Epoch: 6| Step: 10
Training loss: 1.1563401222229004
Validation loss: 2.0826661509852253

Epoch: 6| Step: 11
Training loss: 1.3413479328155518
Validation loss: 2.0791054771792505

Epoch: 6| Step: 12
Training loss: 1.1843212842941284
Validation loss: 2.0790337644597536

Epoch: 6| Step: 13
Training loss: 1.7844587564468384
Validation loss: 2.059257104832639

Epoch: 354| Step: 0
Training loss: 2.0032958984375
Validation loss: 2.049836386916458

Epoch: 6| Step: 1
Training loss: 1.4180138111114502
Validation loss: 2.10819116843644

Epoch: 6| Step: 2
Training loss: 0.9285796880722046
Validation loss: 2.0892816435906196

Epoch: 6| Step: 3
Training loss: 2.075134754180908
Validation loss: 2.1302233613947386

Epoch: 6| Step: 4
Training loss: 1.4508014917373657
Validation loss: 2.0786671330851894

Epoch: 6| Step: 5
Training loss: 1.7874876260757446
Validation loss: 2.0751296730451685

Epoch: 6| Step: 6
Training loss: 1.6034462451934814
Validation loss: 2.088483989879649

Epoch: 6| Step: 7
Training loss: 2.0552284717559814
Validation loss: 2.0997271742872012

Epoch: 6| Step: 8
Training loss: 1.4815486669540405
Validation loss: 2.1144563946672665

Epoch: 6| Step: 9
Training loss: 1.4744783639907837
Validation loss: 2.0678302190637075

Epoch: 6| Step: 10
Training loss: 1.5381675958633423
Validation loss: 2.0753295793328235

Epoch: 6| Step: 11
Training loss: 1.325864553451538
Validation loss: 2.0906667350440897

Epoch: 6| Step: 12
Training loss: 1.9261794090270996
Validation loss: 2.052980512701055

Epoch: 6| Step: 13
Training loss: 1.2388654947280884
Validation loss: 2.0852691678590674

Epoch: 355| Step: 0
Training loss: 1.2454595565795898
Validation loss: 2.0502224429961173

Epoch: 6| Step: 1
Training loss: 1.9820603132247925
Validation loss: 2.062480124094153

Epoch: 6| Step: 2
Training loss: 1.8000121116638184
Validation loss: 2.0786936180565947

Epoch: 6| Step: 3
Training loss: 1.3769562244415283
Validation loss: 2.082232566290004

Epoch: 6| Step: 4
Training loss: 1.088793158531189
Validation loss: 2.0590522904549875

Epoch: 6| Step: 5
Training loss: 1.6779361963272095
Validation loss: 2.0529658858494093

Epoch: 6| Step: 6
Training loss: 1.4870811700820923
Validation loss: 2.0843986977813063

Epoch: 6| Step: 7
Training loss: 1.7520558834075928
Validation loss: 2.0486747577626216

Epoch: 6| Step: 8
Training loss: 1.1659085750579834
Validation loss: 2.067380856442195

Epoch: 6| Step: 9
Training loss: 2.150437355041504
Validation loss: 2.072195581210557

Epoch: 6| Step: 10
Training loss: 2.135620594024658
Validation loss: 2.0702687078906643

Epoch: 6| Step: 11
Training loss: 1.5281777381896973
Validation loss: 2.0575356855187366

Epoch: 6| Step: 12
Training loss: 2.1343445777893066
Validation loss: 2.0610166544555337

Epoch: 6| Step: 13
Training loss: 1.1885255575180054
Validation loss: 2.063209855428306

Epoch: 356| Step: 0
Training loss: 1.2281763553619385
Validation loss: 2.0871333524745

Epoch: 6| Step: 1
Training loss: 1.8655517101287842
Validation loss: 2.1056168694649973

Epoch: 6| Step: 2
Training loss: 1.3644616603851318
Validation loss: 2.136702299118042

Epoch: 6| Step: 3
Training loss: 1.8316385746002197
Validation loss: 2.0938521764611684

Epoch: 6| Step: 4
Training loss: 1.2437018156051636
Validation loss: 2.1152007336257608

Epoch: 6| Step: 5
Training loss: 1.230285406112671
Validation loss: 2.1119618313286894

Epoch: 6| Step: 6
Training loss: 1.6976521015167236
Validation loss: 2.120896600907849

Epoch: 6| Step: 7
Training loss: 1.255137324333191
Validation loss: 2.1376603521326536

Epoch: 6| Step: 8
Training loss: 2.6720080375671387
Validation loss: 2.1340807304587415

Epoch: 6| Step: 9
Training loss: 2.0100183486938477
Validation loss: 2.0865346462495866

Epoch: 6| Step: 10
Training loss: 1.9088865518569946
Validation loss: 2.1051023262803272

Epoch: 6| Step: 11
Training loss: 1.5182551145553589
Validation loss: 2.1021453129347933

Epoch: 6| Step: 12
Training loss: 1.9546318054199219
Validation loss: 2.0573979218800864

Epoch: 6| Step: 13
Training loss: 1.3632683753967285
Validation loss: 2.0944265524546304

Epoch: 357| Step: 0
Training loss: 1.2953929901123047
Validation loss: 2.0927935800244732

Epoch: 6| Step: 1
Training loss: 2.3231048583984375
Validation loss: 2.029179452567972

Epoch: 6| Step: 2
Training loss: 1.6765477657318115
Validation loss: 2.012073770646126

Epoch: 6| Step: 3
Training loss: 1.7245678901672363
Validation loss: 2.0682931382169008

Epoch: 6| Step: 4
Training loss: 1.6798551082611084
Validation loss: 2.1091850496107534

Epoch: 6| Step: 5
Training loss: 1.875441551208496
Validation loss: 2.055406065397365

Epoch: 6| Step: 6
Training loss: 1.0396006107330322
Validation loss: 2.060913658911182

Epoch: 6| Step: 7
Training loss: 1.1846978664398193
Validation loss: 2.0917531469816804

Epoch: 6| Step: 8
Training loss: 1.7029764652252197
Validation loss: 2.0618495889889297

Epoch: 6| Step: 9
Training loss: 1.504787564277649
Validation loss: 2.056189671639473

Epoch: 6| Step: 10
Training loss: 0.8139153718948364
Validation loss: 2.050163015242546

Epoch: 6| Step: 11
Training loss: 1.8563733100891113
Validation loss: 2.030035585485479

Epoch: 6| Step: 12
Training loss: 2.3610169887542725
Validation loss: 2.0934086409948205

Epoch: 6| Step: 13
Training loss: 2.5700879096984863
Validation loss: 2.1096370861094487

Epoch: 358| Step: 0
Training loss: 2.2985587120056152
Validation loss: 2.08069275271508

Epoch: 6| Step: 1
Training loss: 1.0815818309783936
Validation loss: 2.0690014413608018

Epoch: 6| Step: 2
Training loss: 1.2075412273406982
Validation loss: 2.090035307791925

Epoch: 6| Step: 3
Training loss: 2.213178873062134
Validation loss: 2.0991755672680434

Epoch: 6| Step: 4
Training loss: 1.9864871501922607
Validation loss: 2.1387109295014413

Epoch: 6| Step: 5
Training loss: 1.7333693504333496
Validation loss: 2.1473306481556227

Epoch: 6| Step: 6
Training loss: 1.965047001838684
Validation loss: 2.159495089643745

Epoch: 6| Step: 7
Training loss: 1.8623650074005127
Validation loss: 2.1778402700219104

Epoch: 6| Step: 8
Training loss: 1.1864960193634033
Validation loss: 2.127621817332442

Epoch: 6| Step: 9
Training loss: 1.3984978199005127
Validation loss: 2.1538699339794856

Epoch: 6| Step: 10
Training loss: 1.799810767173767
Validation loss: 2.1352305630201935

Epoch: 6| Step: 11
Training loss: 1.8565311431884766
Validation loss: 2.110879998053274

Epoch: 6| Step: 12
Training loss: 1.5032811164855957
Validation loss: 2.098704461128481

Epoch: 6| Step: 13
Training loss: 1.274975299835205
Validation loss: 2.0493531611657914

Epoch: 359| Step: 0
Training loss: 1.2900569438934326
Validation loss: 2.069709483013358

Epoch: 6| Step: 1
Training loss: 1.1013164520263672
Validation loss: 2.091784634897786

Epoch: 6| Step: 2
Training loss: 2.472660541534424
Validation loss: 2.063970346604624

Epoch: 6| Step: 3
Training loss: 2.156217098236084
Validation loss: 2.094489830796437

Epoch: 6| Step: 4
Training loss: 1.2420120239257812
Validation loss: 2.083004078557414

Epoch: 6| Step: 5
Training loss: 1.491930603981018
Validation loss: 2.056522250175476

Epoch: 6| Step: 6
Training loss: 1.7546614408493042
Validation loss: 2.0676620788471674

Epoch: 6| Step: 7
Training loss: 1.2536327838897705
Validation loss: 2.072897193252399

Epoch: 6| Step: 8
Training loss: 2.108600378036499
Validation loss: 2.082020657036894

Epoch: 6| Step: 9
Training loss: 1.5468485355377197
Validation loss: 2.0609845679293395

Epoch: 6| Step: 10
Training loss: 2.204300880432129
Validation loss: 2.110908700573829

Epoch: 6| Step: 11
Training loss: 1.455010175704956
Validation loss: 2.1092441928002144

Epoch: 6| Step: 12
Training loss: 1.6758943796157837
Validation loss: 2.101774582298853

Epoch: 6| Step: 13
Training loss: 1.2776607275009155
Validation loss: 2.0970658486889255

Epoch: 360| Step: 0
Training loss: 0.9398318529129028
Validation loss: 2.0943164030710855

Epoch: 6| Step: 1
Training loss: 2.3166494369506836
Validation loss: 2.083935517136769

Epoch: 6| Step: 2
Training loss: 1.570275068283081
Validation loss: 2.071366484447192

Epoch: 6| Step: 3
Training loss: 1.9091978073120117
Validation loss: 2.1278673564234087

Epoch: 6| Step: 4
Training loss: 1.4243184328079224
Validation loss: 2.1278392781493483

Epoch: 6| Step: 5
Training loss: 1.7255535125732422
Validation loss: 2.1083363422783474

Epoch: 6| Step: 6
Training loss: 1.3975669145584106
Validation loss: 2.1114722669765515

Epoch: 6| Step: 7
Training loss: 1.5101840496063232
Validation loss: 2.0947411316697315

Epoch: 6| Step: 8
Training loss: 1.844709873199463
Validation loss: 2.0976663456168225

Epoch: 6| Step: 9
Training loss: 1.814098834991455
Validation loss: 2.083115639225129

Epoch: 6| Step: 10
Training loss: 2.012869358062744
Validation loss: 2.084051932058027

Epoch: 6| Step: 11
Training loss: 1.346606731414795
Validation loss: 2.11266827583313

Epoch: 6| Step: 12
Training loss: 1.5904937982559204
Validation loss: 2.0937214051523516

Epoch: 6| Step: 13
Training loss: 1.4922716617584229
Validation loss: 2.0704635099698137

Epoch: 361| Step: 0
Training loss: 1.9133143424987793
Validation loss: 2.092134262925835

Epoch: 6| Step: 1
Training loss: 2.898955821990967
Validation loss: 2.0849829925003873

Epoch: 6| Step: 2
Training loss: 1.3613864183425903
Validation loss: 2.0675304397459953

Epoch: 6| Step: 3
Training loss: 1.2489590644836426
Validation loss: 2.0916779477109193

Epoch: 6| Step: 4
Training loss: 1.5525187253952026
Validation loss: 2.038121686186842

Epoch: 6| Step: 5
Training loss: 1.3435074090957642
Validation loss: 2.0394736413032777

Epoch: 6| Step: 6
Training loss: 1.5341289043426514
Validation loss: 2.0417089923735587

Epoch: 6| Step: 7
Training loss: 1.121757984161377
Validation loss: 2.078600505346893

Epoch: 6| Step: 8
Training loss: 2.27355694770813
Validation loss: 2.0831144676413587

Epoch: 6| Step: 9
Training loss: 1.562252163887024
Validation loss: 2.0662561719135573

Epoch: 6| Step: 10
Training loss: 1.6224596500396729
Validation loss: 2.0827091342659405

Epoch: 6| Step: 11
Training loss: 1.4085665941238403
Validation loss: 2.03155291593203

Epoch: 6| Step: 12
Training loss: 1.14980149269104
Validation loss: 2.0634601423817296

Epoch: 6| Step: 13
Training loss: 1.6423168182373047
Validation loss: 2.0918587228303314

Epoch: 362| Step: 0
Training loss: 1.393090844154358
Validation loss: 2.0885874148338073

Epoch: 6| Step: 1
Training loss: 3.0160508155822754
Validation loss: 2.0585825648359073

Epoch: 6| Step: 2
Training loss: 1.7504849433898926
Validation loss: 2.0817173386132843

Epoch: 6| Step: 3
Training loss: 1.5860567092895508
Validation loss: 2.0695117596657044

Epoch: 6| Step: 4
Training loss: 1.1715812683105469
Validation loss: 2.1049392146448933

Epoch: 6| Step: 5
Training loss: 1.452019453048706
Validation loss: 2.0835942529862925

Epoch: 6| Step: 6
Training loss: 0.8134145140647888
Validation loss: 2.1156922847993913

Epoch: 6| Step: 7
Training loss: 1.504072904586792
Validation loss: 2.1248132464706257

Epoch: 6| Step: 8
Training loss: 2.1922545433044434
Validation loss: 2.123109198385669

Epoch: 6| Step: 9
Training loss: 1.4336597919464111
Validation loss: 2.0794551244346042

Epoch: 6| Step: 10
Training loss: 1.5262346267700195
Validation loss: 2.106433919681016

Epoch: 6| Step: 11
Training loss: 1.4132118225097656
Validation loss: 2.080344689789639

Epoch: 6| Step: 12
Training loss: 1.5545716285705566
Validation loss: 2.101428806140859

Epoch: 6| Step: 13
Training loss: 1.802856683731079
Validation loss: 2.0803569888555877

Epoch: 363| Step: 0
Training loss: 1.5293173789978027
Validation loss: 2.090042127076016

Epoch: 6| Step: 1
Training loss: 1.6894025802612305
Validation loss: 2.1191346055717877

Epoch: 6| Step: 2
Training loss: 1.4297631978988647
Validation loss: 2.0923980307835404

Epoch: 6| Step: 3
Training loss: 1.975914478302002
Validation loss: 2.088409923738049

Epoch: 6| Step: 4
Training loss: 1.8867756128311157
Validation loss: 2.099334680905906

Epoch: 6| Step: 5
Training loss: 2.0079336166381836
Validation loss: 2.04079633374368

Epoch: 6| Step: 6
Training loss: 1.5960943698883057
Validation loss: 2.072388102931361

Epoch: 6| Step: 7
Training loss: 1.7495813369750977
Validation loss: 2.0481767205781836

Epoch: 6| Step: 8
Training loss: 1.1659287214279175
Validation loss: 2.0719083368137317

Epoch: 6| Step: 9
Training loss: 1.9836119413375854
Validation loss: 2.086230886879788

Epoch: 6| Step: 10
Training loss: 1.707704782485962
Validation loss: 2.0749233986741755

Epoch: 6| Step: 11
Training loss: 1.0937620401382446
Validation loss: 2.081894995063864

Epoch: 6| Step: 12
Training loss: 1.0549390316009521
Validation loss: 2.0485807080422678

Epoch: 6| Step: 13
Training loss: 1.7300482988357544
Validation loss: 2.0626008972044914

Epoch: 364| Step: 0
Training loss: 0.9105823636054993
Validation loss: 2.0581074709533365

Epoch: 6| Step: 1
Training loss: 1.7643741369247437
Validation loss: 2.0949966958774033

Epoch: 6| Step: 2
Training loss: 2.325148105621338
Validation loss: 2.0939947020622993

Epoch: 6| Step: 3
Training loss: 1.4728800058364868
Validation loss: 2.1001305964685257

Epoch: 6| Step: 4
Training loss: 2.252092123031616
Validation loss: 2.089252838524439

Epoch: 6| Step: 5
Training loss: 1.4589924812316895
Validation loss: 2.0622945652213147

Epoch: 6| Step: 6
Training loss: 1.4189386367797852
Validation loss: 2.075843357270764

Epoch: 6| Step: 7
Training loss: 1.8457634449005127
Validation loss: 2.078103305191122

Epoch: 6| Step: 8
Training loss: 1.34981369972229
Validation loss: 2.0558626446672665

Epoch: 6| Step: 9
Training loss: 1.7104341983795166
Validation loss: 2.087824090834587

Epoch: 6| Step: 10
Training loss: 2.0924479961395264
Validation loss: 2.068517484972554

Epoch: 6| Step: 11
Training loss: 1.623653769493103
Validation loss: 2.0636497018157796

Epoch: 6| Step: 12
Training loss: 1.3368018865585327
Validation loss: 2.0799360031722696

Epoch: 6| Step: 13
Training loss: 1.116136074066162
Validation loss: 2.0760082608910015

Epoch: 365| Step: 0
Training loss: 1.7338032722473145
Validation loss: 2.076067001588883

Epoch: 6| Step: 1
Training loss: 2.0243301391601562
Validation loss: 2.0498104249277422

Epoch: 6| Step: 2
Training loss: 2.036958694458008
Validation loss: 2.0542198945117254

Epoch: 6| Step: 3
Training loss: 1.3897161483764648
Validation loss: 2.0792036505155664

Epoch: 6| Step: 4
Training loss: 1.761085033416748
Validation loss: 2.0715571949558873

Epoch: 6| Step: 5
Training loss: 1.651038408279419
Validation loss: 2.0600481417871292

Epoch: 6| Step: 6
Training loss: 0.8908874988555908
Validation loss: 2.0510532843169345

Epoch: 6| Step: 7
Training loss: 1.8093721866607666
Validation loss: 2.084455515748711

Epoch: 6| Step: 8
Training loss: 1.4887628555297852
Validation loss: 2.0791058489071426

Epoch: 6| Step: 9
Training loss: 1.5819658041000366
Validation loss: 2.077578524107574

Epoch: 6| Step: 10
Training loss: 1.4071193933486938
Validation loss: 2.118050927756935

Epoch: 6| Step: 11
Training loss: 1.5802505016326904
Validation loss: 2.106813915314213

Epoch: 6| Step: 12
Training loss: 1.7537686824798584
Validation loss: 2.094736760662448

Epoch: 6| Step: 13
Training loss: 1.761560320854187
Validation loss: 2.136719342200987

Epoch: 366| Step: 0
Training loss: 1.2412574291229248
Validation loss: 2.1224119022328365

Epoch: 6| Step: 1
Training loss: 1.3237497806549072
Validation loss: 2.1350727824754614

Epoch: 6| Step: 2
Training loss: 1.8097294569015503
Validation loss: 2.0518801622493292

Epoch: 6| Step: 3
Training loss: 1.5674997568130493
Validation loss: 2.075235051493491

Epoch: 6| Step: 4
Training loss: 1.581322193145752
Validation loss: 2.0663258901206394

Epoch: 6| Step: 5
Training loss: 1.2672278881072998
Validation loss: 2.079320089791411

Epoch: 6| Step: 6
Training loss: 1.6126593351364136
Validation loss: 2.08283749447074

Epoch: 6| Step: 7
Training loss: 2.1732540130615234
Validation loss: 2.032577706921485

Epoch: 6| Step: 8
Training loss: 1.4684312343597412
Validation loss: 2.099301633014474

Epoch: 6| Step: 9
Training loss: 1.7257976531982422
Validation loss: 2.0859463458420127

Epoch: 6| Step: 10
Training loss: 1.8108994960784912
Validation loss: 2.037338838782362

Epoch: 6| Step: 11
Training loss: 1.8445088863372803
Validation loss: 2.017760843359014

Epoch: 6| Step: 12
Training loss: 1.1269841194152832
Validation loss: 2.053137115252915

Epoch: 6| Step: 13
Training loss: 2.2454893589019775
Validation loss: 2.049659095784669

Epoch: 367| Step: 0
Training loss: 1.733567476272583
Validation loss: 2.07327841430582

Epoch: 6| Step: 1
Training loss: 1.1306400299072266
Validation loss: 2.058727743805096

Epoch: 6| Step: 2
Training loss: 1.4439191818237305
Validation loss: 2.0829939534587245

Epoch: 6| Step: 3
Training loss: 1.7618777751922607
Validation loss: 2.100902433036476

Epoch: 6| Step: 4
Training loss: 1.4631595611572266
Validation loss: 2.0966442374772924

Epoch: 6| Step: 5
Training loss: 1.7081329822540283
Validation loss: 2.0929037601717058

Epoch: 6| Step: 6
Training loss: 1.1578872203826904
Validation loss: 2.129128835534537

Epoch: 6| Step: 7
Training loss: 1.5522143840789795
Validation loss: 2.124224255161901

Epoch: 6| Step: 8
Training loss: 1.5891871452331543
Validation loss: 2.132547213185218

Epoch: 6| Step: 9
Training loss: 1.9324796199798584
Validation loss: 2.1113837842018373

Epoch: 6| Step: 10
Training loss: 1.670160174369812
Validation loss: 2.1037210777241695

Epoch: 6| Step: 11
Training loss: 1.553534984588623
Validation loss: 2.134055724707983

Epoch: 6| Step: 12
Training loss: 2.2406980991363525
Validation loss: 2.094838039849394

Epoch: 6| Step: 13
Training loss: 1.7248605489730835
Validation loss: 2.048192452358943

Epoch: 368| Step: 0
Training loss: 2.0158090591430664
Validation loss: 2.0784814537212415

Epoch: 6| Step: 1
Training loss: 1.683194637298584
Validation loss: 2.044799796996578

Epoch: 6| Step: 2
Training loss: 1.7389576435089111
Validation loss: 2.0619896432404876

Epoch: 6| Step: 3
Training loss: 1.6322414875030518
Validation loss: 2.030063070276732

Epoch: 6| Step: 4
Training loss: 1.8297028541564941
Validation loss: 2.0514690888825284

Epoch: 6| Step: 5
Training loss: 1.8608932495117188
Validation loss: 2.074755568658152

Epoch: 6| Step: 6
Training loss: 1.7831934690475464
Validation loss: 2.057855385606007

Epoch: 6| Step: 7
Training loss: 1.710869550704956
Validation loss: 2.0620564055699173

Epoch: 6| Step: 8
Training loss: 2.0397725105285645
Validation loss: 2.0425770949291926

Epoch: 6| Step: 9
Training loss: 0.8388801217079163
Validation loss: 2.086110407306302

Epoch: 6| Step: 10
Training loss: 1.666551113128662
Validation loss: 2.0509956793118547

Epoch: 6| Step: 11
Training loss: 1.2732861042022705
Validation loss: 2.0708564814700874

Epoch: 6| Step: 12
Training loss: 1.2020235061645508
Validation loss: 2.05889549563008

Epoch: 6| Step: 13
Training loss: 1.5934059619903564
Validation loss: 2.0636050765232374

Epoch: 369| Step: 0
Training loss: 0.9513609409332275
Validation loss: 2.0844663971213886

Epoch: 6| Step: 1
Training loss: 1.97344970703125
Validation loss: 2.111119649743521

Epoch: 6| Step: 2
Training loss: 1.2504481077194214
Validation loss: 2.05041628883731

Epoch: 6| Step: 3
Training loss: 1.8378369808197021
Validation loss: 2.117342495149182

Epoch: 6| Step: 4
Training loss: 1.5961143970489502
Validation loss: 2.1180067575106056

Epoch: 6| Step: 5
Training loss: 1.443802833557129
Validation loss: 2.169101212614326

Epoch: 6| Step: 6
Training loss: 1.851076364517212
Validation loss: 2.0781332626137683

Epoch: 6| Step: 7
Training loss: 1.5049248933792114
Validation loss: 2.0891978125418387

Epoch: 6| Step: 8
Training loss: 1.5397905111312866
Validation loss: 2.0858488569977465

Epoch: 6| Step: 9
Training loss: 1.4375731945037842
Validation loss: 2.094355760082122

Epoch: 6| Step: 10
Training loss: 1.867516040802002
Validation loss: 2.0408318363210207

Epoch: 6| Step: 11
Training loss: 1.9300992488861084
Validation loss: 2.04982590675354

Epoch: 6| Step: 12
Training loss: 1.7044659852981567
Validation loss: 2.108760356903076

Epoch: 6| Step: 13
Training loss: 1.3405898809432983
Validation loss: 2.0666523364282425

Epoch: 370| Step: 0
Training loss: 2.1378283500671387
Validation loss: 2.1142336886416198

Epoch: 6| Step: 1
Training loss: 1.736112356185913
Validation loss: 2.05422814174365

Epoch: 6| Step: 2
Training loss: 1.7088422775268555
Validation loss: 2.073754805390553

Epoch: 6| Step: 3
Training loss: 2.369971990585327
Validation loss: 2.052448594441978

Epoch: 6| Step: 4
Training loss: 1.4948947429656982
Validation loss: 2.052221062362835

Epoch: 6| Step: 5
Training loss: 1.8969876766204834
Validation loss: 2.0401588921905844

Epoch: 6| Step: 6
Training loss: 1.1998817920684814
Validation loss: 2.056294410459457

Epoch: 6| Step: 7
Training loss: 1.2977643013000488
Validation loss: 2.0790255044096257

Epoch: 6| Step: 8
Training loss: 1.2068204879760742
Validation loss: 2.051775940002934

Epoch: 6| Step: 9
Training loss: 1.769050121307373
Validation loss: 2.0721338128530853

Epoch: 6| Step: 10
Training loss: 1.4440984725952148
Validation loss: 2.0841163845472437

Epoch: 6| Step: 11
Training loss: 1.3074393272399902
Validation loss: 2.0445941750721266

Epoch: 6| Step: 12
Training loss: 1.397389531135559
Validation loss: 2.1063931731767553

Epoch: 6| Step: 13
Training loss: 1.131709098815918
Validation loss: 2.127634681681151

Epoch: 371| Step: 0
Training loss: 2.444892406463623
Validation loss: 2.1151812486751105

Epoch: 6| Step: 1
Training loss: 2.3336334228515625
Validation loss: 2.0874735796323387

Epoch: 6| Step: 2
Training loss: 1.6614398956298828
Validation loss: 2.074005365371704

Epoch: 6| Step: 3
Training loss: 1.3571442365646362
Validation loss: 2.087146287323326

Epoch: 6| Step: 4
Training loss: 1.6002492904663086
Validation loss: 2.068284780748429

Epoch: 6| Step: 5
Training loss: 1.476938009262085
Validation loss: 2.0680010562301963

Epoch: 6| Step: 6
Training loss: 1.6046547889709473
Validation loss: 2.051498241322015

Epoch: 6| Step: 7
Training loss: 1.4222774505615234
Validation loss: 2.0861891162010933

Epoch: 6| Step: 8
Training loss: 1.1518468856811523
Validation loss: 2.0821916531491023

Epoch: 6| Step: 9
Training loss: 1.771456241607666
Validation loss: 2.0580182793319866

Epoch: 6| Step: 10
Training loss: 1.5727450847625732
Validation loss: 2.073229947397786

Epoch: 6| Step: 11
Training loss: 1.6059060096740723
Validation loss: 2.03933383059758

Epoch: 6| Step: 12
Training loss: 1.2651159763336182
Validation loss: 2.081677331719347

Epoch: 6| Step: 13
Training loss: 1.4656728506088257
Validation loss: 2.114162532232141

Epoch: 372| Step: 0
Training loss: 1.4958927631378174
Validation loss: 2.0857295220898044

Epoch: 6| Step: 1
Training loss: 1.3580658435821533
Validation loss: 2.0853273317378056

Epoch: 6| Step: 2
Training loss: 1.948284387588501
Validation loss: 2.097286565329439

Epoch: 6| Step: 3
Training loss: 1.1344327926635742
Validation loss: 2.0976950391646354

Epoch: 6| Step: 4
Training loss: 1.9453327655792236
Validation loss: 2.1453482797068935

Epoch: 6| Step: 5
Training loss: 1.2479701042175293
Validation loss: 2.0911793426800798

Epoch: 6| Step: 6
Training loss: 2.1181626319885254
Validation loss: 2.1008034162623908

Epoch: 6| Step: 7
Training loss: 1.1527743339538574
Validation loss: 2.065754621259628

Epoch: 6| Step: 8
Training loss: 2.2377753257751465
Validation loss: 2.062232458463279

Epoch: 6| Step: 9
Training loss: 1.8174667358398438
Validation loss: 2.0550006281945015

Epoch: 6| Step: 10
Training loss: 1.554631233215332
Validation loss: 2.064099145191972

Epoch: 6| Step: 11
Training loss: 1.8999279737472534
Validation loss: 2.105681392454332

Epoch: 6| Step: 12
Training loss: 0.9053471684455872
Validation loss: 2.064286506304177

Epoch: 6| Step: 13
Training loss: 1.5605401992797852
Validation loss: 2.0557617730991815

Epoch: 373| Step: 0
Training loss: 1.7071014642715454
Validation loss: 2.057239897789494

Epoch: 6| Step: 1
Training loss: 1.6314812898635864
Validation loss: 2.0790162727396977

Epoch: 6| Step: 2
Training loss: 1.6221282482147217
Validation loss: 2.0412607564721057

Epoch: 6| Step: 3
Training loss: 1.1976755857467651
Validation loss: 2.0853201676440496

Epoch: 6| Step: 4
Training loss: 2.015029191970825
Validation loss: 2.0668339421672206

Epoch: 6| Step: 5
Training loss: 2.325674057006836
Validation loss: 2.0481203422751477

Epoch: 6| Step: 6
Training loss: 1.5361676216125488
Validation loss: 2.0598355416328675

Epoch: 6| Step: 7
Training loss: 1.5054473876953125
Validation loss: 2.097622826535215

Epoch: 6| Step: 8
Training loss: 0.8742794394493103
Validation loss: 2.0962227159930813

Epoch: 6| Step: 9
Training loss: 1.0748450756072998
Validation loss: 2.06333089259363

Epoch: 6| Step: 10
Training loss: 2.098296642303467
Validation loss: 2.0668010839851956

Epoch: 6| Step: 11
Training loss: 1.2791187763214111
Validation loss: 2.071030814160583

Epoch: 6| Step: 12
Training loss: 1.8421716690063477
Validation loss: 2.101099519319432

Epoch: 6| Step: 13
Training loss: 1.1833823919296265
Validation loss: 2.132314182096912

Epoch: 374| Step: 0
Training loss: 1.2140026092529297
Validation loss: 2.0992448201743503

Epoch: 6| Step: 1
Training loss: 1.4080700874328613
Validation loss: 2.149371800884124

Epoch: 6| Step: 2
Training loss: 1.6948010921478271
Validation loss: 2.1135324355094665

Epoch: 6| Step: 3
Training loss: 1.8752069473266602
Validation loss: 2.1006833378986647

Epoch: 6| Step: 4
Training loss: 1.2195894718170166
Validation loss: 2.0914520345708376

Epoch: 6| Step: 5
Training loss: 1.3480693101882935
Validation loss: 2.0510892278404644

Epoch: 6| Step: 6
Training loss: 1.954876184463501
Validation loss: 2.058163366010112

Epoch: 6| Step: 7
Training loss: 1.8143905401229858
Validation loss: 2.105651338895162

Epoch: 6| Step: 8
Training loss: 1.7976078987121582
Validation loss: 2.0496655548772504

Epoch: 6| Step: 9
Training loss: 1.7851078510284424
Validation loss: 2.0680316750721266

Epoch: 6| Step: 10
Training loss: 1.4606178998947144
Validation loss: 2.0699833887879566

Epoch: 6| Step: 11
Training loss: 1.4699809551239014
Validation loss: 2.052687100184861

Epoch: 6| Step: 12
Training loss: 2.0607028007507324
Validation loss: 2.047645027919482

Epoch: 6| Step: 13
Training loss: 1.2872098684310913
Validation loss: 2.0636817396328015

Epoch: 375| Step: 0
Training loss: 1.479190707206726
Validation loss: 2.078454412439818

Epoch: 6| Step: 1
Training loss: 1.6443045139312744
Validation loss: 2.102025076907168

Epoch: 6| Step: 2
Training loss: 1.4834518432617188
Validation loss: 2.0982237092910276

Epoch: 6| Step: 3
Training loss: 1.2275375127792358
Validation loss: 2.1281450179315384

Epoch: 6| Step: 4
Training loss: 1.108237624168396
Validation loss: 2.1183714982002013

Epoch: 6| Step: 5
Training loss: 1.3742058277130127
Validation loss: 2.0590557564971266

Epoch: 6| Step: 6
Training loss: 1.5715984106063843
Validation loss: 2.106290639087718

Epoch: 6| Step: 7
Training loss: 2.426511764526367
Validation loss: 2.051173097343855

Epoch: 6| Step: 8
Training loss: 1.4515806436538696
Validation loss: 2.0797644917682936

Epoch: 6| Step: 9
Training loss: 1.0117619037628174
Validation loss: 2.0659971160273396

Epoch: 6| Step: 10
Training loss: 1.9020050764083862
Validation loss: 2.0684707010945966

Epoch: 6| Step: 11
Training loss: 2.235316753387451
Validation loss: 2.058891555314423

Epoch: 6| Step: 12
Training loss: 1.5733160972595215
Validation loss: 2.0589346334498417

Epoch: 6| Step: 13
Training loss: 2.137483596801758
Validation loss: 2.060105190482191

Epoch: 376| Step: 0
Training loss: 1.9726054668426514
Validation loss: 2.02680020178518

Epoch: 6| Step: 1
Training loss: 1.8985487222671509
Validation loss: 2.047884679609729

Epoch: 6| Step: 2
Training loss: 2.4974467754364014
Validation loss: 2.04853529186659

Epoch: 6| Step: 3
Training loss: 1.049257755279541
Validation loss: 2.072705045823128

Epoch: 6| Step: 4
Training loss: 1.3408150672912598
Validation loss: 2.056788113809401

Epoch: 6| Step: 5
Training loss: 1.5149860382080078
Validation loss: 2.058371341356667

Epoch: 6| Step: 6
Training loss: 1.4893383979797363
Validation loss: 2.071818890110139

Epoch: 6| Step: 7
Training loss: 1.1808059215545654
Validation loss: 2.0679189748661493

Epoch: 6| Step: 8
Training loss: 1.0595372915267944
Validation loss: 2.1085537300314954

Epoch: 6| Step: 9
Training loss: 1.3292911052703857
Validation loss: 2.0726047767105924

Epoch: 6| Step: 10
Training loss: 1.72890305519104
Validation loss: 2.0918751865304928

Epoch: 6| Step: 11
Training loss: 1.8703497648239136
Validation loss: 2.074526595812972

Epoch: 6| Step: 12
Training loss: 1.870814561843872
Validation loss: 2.103110090378792

Epoch: 6| Step: 13
Training loss: 1.2356065511703491
Validation loss: 2.09805997725456

Epoch: 377| Step: 0
Training loss: 2.0024397373199463
Validation loss: 2.069196662595195

Epoch: 6| Step: 1
Training loss: 1.7245079278945923
Validation loss: 2.0991597995963147

Epoch: 6| Step: 2
Training loss: 1.723013162612915
Validation loss: 2.141053686859787

Epoch: 6| Step: 3
Training loss: 1.2691272497177124
Validation loss: 2.126121005704326

Epoch: 6| Step: 4
Training loss: 1.3030955791473389
Validation loss: 2.0949731065380957

Epoch: 6| Step: 5
Training loss: 1.3816063404083252
Validation loss: 2.1198379506347

Epoch: 6| Step: 6
Training loss: 1.0824838876724243
Validation loss: 2.0749350004298712

Epoch: 6| Step: 7
Training loss: 2.1885907649993896
Validation loss: 2.067830483118693

Epoch: 6| Step: 8
Training loss: 1.5364407300949097
Validation loss: 2.100022054487659

Epoch: 6| Step: 9
Training loss: 1.4107906818389893
Validation loss: 2.057663817559519

Epoch: 6| Step: 10
Training loss: 1.6305783987045288
Validation loss: 2.1053346715947634

Epoch: 6| Step: 11
Training loss: 2.552090644836426
Validation loss: 2.062439828790644

Epoch: 6| Step: 12
Training loss: 1.4842718839645386
Validation loss: 2.0548487350504887

Epoch: 6| Step: 13
Training loss: 1.2429815530776978
Validation loss: 2.085166338951357

Epoch: 378| Step: 0
Training loss: 0.7456578016281128
Validation loss: 2.0251897150470364

Epoch: 6| Step: 1
Training loss: 1.6849154233932495
Validation loss: 2.0378260689397014

Epoch: 6| Step: 2
Training loss: 0.9814467430114746
Validation loss: 2.0510280798840266

Epoch: 6| Step: 3
Training loss: 1.5765204429626465
Validation loss: 2.0770281899359917

Epoch: 6| Step: 4
Training loss: 1.9003138542175293
Validation loss: 2.0774761605006393

Epoch: 6| Step: 5
Training loss: 0.9907376766204834
Validation loss: 2.0677379677372594

Epoch: 6| Step: 6
Training loss: 1.1050190925598145
Validation loss: 2.039944887161255

Epoch: 6| Step: 7
Training loss: 2.6788434982299805
Validation loss: 2.081195651843984

Epoch: 6| Step: 8
Training loss: 1.7388269901275635
Validation loss: 2.04966039042319

Epoch: 6| Step: 9
Training loss: 1.968963861465454
Validation loss: 2.0770252955857145

Epoch: 6| Step: 10
Training loss: 1.8464381694793701
Validation loss: 2.050797270190331

Epoch: 6| Step: 11
Training loss: 1.5583744049072266
Validation loss: 2.0670108513165544

Epoch: 6| Step: 12
Training loss: 2.3010776042938232
Validation loss: 2.0987008374224425

Epoch: 6| Step: 13
Training loss: 1.1761959791183472
Validation loss: 2.084586799785655

Epoch: 379| Step: 0
Training loss: 1.4802696704864502
Validation loss: 2.159483232805806

Epoch: 6| Step: 1
Training loss: 1.6647791862487793
Validation loss: 2.09801051949942

Epoch: 6| Step: 2
Training loss: 1.1582978963851929
Validation loss: 2.1017503789676133

Epoch: 6| Step: 3
Training loss: 1.771056890487671
Validation loss: 2.0931816639438754

Epoch: 6| Step: 4
Training loss: 1.1017541885375977
Validation loss: 2.0867120117269535

Epoch: 6| Step: 5
Training loss: 2.088531017303467
Validation loss: 2.091485982300133

Epoch: 6| Step: 6
Training loss: 1.6672284603118896
Validation loss: 2.169560509343301

Epoch: 6| Step: 7
Training loss: 1.187950611114502
Validation loss: 2.128560471278365

Epoch: 6| Step: 8
Training loss: 1.982283592224121
Validation loss: 2.1247464174865396

Epoch: 6| Step: 9
Training loss: 1.6379196643829346
Validation loss: 2.140848926318589

Epoch: 6| Step: 10
Training loss: 1.755958080291748
Validation loss: 2.090967342417727

Epoch: 6| Step: 11
Training loss: 1.6060504913330078
Validation loss: 2.109722952688894

Epoch: 6| Step: 12
Training loss: 2.029271125793457
Validation loss: 2.0532272784940657

Epoch: 6| Step: 13
Training loss: 0.9466565251350403
Validation loss: 2.081030302150275

Epoch: 380| Step: 0
Training loss: 2.078108072280884
Validation loss: 2.0690303797362954

Epoch: 6| Step: 1
Training loss: 1.0322295427322388
Validation loss: 2.0457435474600842

Epoch: 6| Step: 2
Training loss: 1.4187588691711426
Validation loss: 2.0066248909119637

Epoch: 6| Step: 3
Training loss: 1.5998703241348267
Validation loss: 2.050838324331468

Epoch: 6| Step: 4
Training loss: 2.385733127593994
Validation loss: 2.0441487989118023

Epoch: 6| Step: 5
Training loss: 0.9580284357070923
Validation loss: 2.051914538106611

Epoch: 6| Step: 6
Training loss: 1.5588557720184326
Validation loss: 2.070806198222663

Epoch: 6| Step: 7
Training loss: 1.6654022932052612
Validation loss: 2.0446805800161054

Epoch: 6| Step: 8
Training loss: 1.3996682167053223
Validation loss: 2.0388838309113697

Epoch: 6| Step: 9
Training loss: 2.071110248565674
Validation loss: 2.08146692604147

Epoch: 6| Step: 10
Training loss: 1.9526787996292114
Validation loss: 2.1025371628422893

Epoch: 6| Step: 11
Training loss: 1.8166192770004272
Validation loss: 2.0868006880565355

Epoch: 6| Step: 12
Training loss: 1.4944870471954346
Validation loss: 2.101751055768741

Epoch: 6| Step: 13
Training loss: 1.0082719326019287
Validation loss: 2.10362853798815

Epoch: 381| Step: 0
Training loss: 1.8561233282089233
Validation loss: 2.0842543763499104

Epoch: 6| Step: 1
Training loss: 1.6384191513061523
Validation loss: 2.102139098669893

Epoch: 6| Step: 2
Training loss: 1.5786962509155273
Validation loss: 2.072987510311988

Epoch: 6| Step: 3
Training loss: 1.0084412097930908
Validation loss: 2.065001977387295

Epoch: 6| Step: 4
Training loss: 1.3680081367492676
Validation loss: 2.0977966093247935

Epoch: 6| Step: 5
Training loss: 1.4953187704086304
Validation loss: 2.0667739234944826

Epoch: 6| Step: 6
Training loss: 1.7501623630523682
Validation loss: 2.08781615636682

Epoch: 6| Step: 7
Training loss: 1.7857965230941772
Validation loss: 2.0192898934887302

Epoch: 6| Step: 8
Training loss: 1.065467357635498
Validation loss: 2.0803910891215005

Epoch: 6| Step: 9
Training loss: 1.3289250135421753
Validation loss: 2.0483080366606354

Epoch: 6| Step: 10
Training loss: 1.915858507156372
Validation loss: 2.0818798131840204

Epoch: 6| Step: 11
Training loss: 1.5266790390014648
Validation loss: 2.0597527129675752

Epoch: 6| Step: 12
Training loss: 2.024850845336914
Validation loss: 2.0839584950477845

Epoch: 6| Step: 13
Training loss: 1.7077174186706543
Validation loss: 2.083218446341894

Epoch: 382| Step: 0
Training loss: 1.4159188270568848
Validation loss: 2.078625702088879

Epoch: 6| Step: 1
Training loss: 1.3364880084991455
Validation loss: 2.092571432872485

Epoch: 6| Step: 2
Training loss: 1.7324612140655518
Validation loss: 2.0702250644724858

Epoch: 6| Step: 3
Training loss: 1.6599297523498535
Validation loss: 2.0651687627197592

Epoch: 6| Step: 4
Training loss: 0.8828659653663635
Validation loss: 2.1034815285795476

Epoch: 6| Step: 5
Training loss: 2.0606842041015625
Validation loss: 2.1215447918061288

Epoch: 6| Step: 6
Training loss: 2.063514471054077
Validation loss: 2.094295496581703

Epoch: 6| Step: 7
Training loss: 1.744640588760376
Validation loss: 2.101360769682033

Epoch: 6| Step: 8
Training loss: 1.4798974990844727
Validation loss: 2.0910807783885668

Epoch: 6| Step: 9
Training loss: 2.099169969558716
Validation loss: 2.0969941334057878

Epoch: 6| Step: 10
Training loss: 1.0893301963806152
Validation loss: 2.1138314559895504

Epoch: 6| Step: 11
Training loss: 0.9167670011520386
Validation loss: 2.109586158106404

Epoch: 6| Step: 12
Training loss: 1.8595967292785645
Validation loss: 2.1167196766022713

Epoch: 6| Step: 13
Training loss: 1.9479866027832031
Validation loss: 2.1055235350003807

Epoch: 383| Step: 0
Training loss: 1.8055901527404785
Validation loss: 2.073001302698607

Epoch: 6| Step: 1
Training loss: 1.2594449520111084
Validation loss: 2.0806101458047026

Epoch: 6| Step: 2
Training loss: 1.3606255054473877
Validation loss: 2.10382350285848

Epoch: 6| Step: 3
Training loss: 2.0474963188171387
Validation loss: 2.0429871800125285

Epoch: 6| Step: 4
Training loss: 1.5920467376708984
Validation loss: 2.1095271007989043

Epoch: 6| Step: 5
Training loss: 1.7347257137298584
Validation loss: 2.0751247265005626

Epoch: 6| Step: 6
Training loss: 2.058462381362915
Validation loss: 2.040454723501718

Epoch: 6| Step: 7
Training loss: 2.119680404663086
Validation loss: 2.0841382677837084

Epoch: 6| Step: 8
Training loss: 1.5501601696014404
Validation loss: 2.088712041096021

Epoch: 6| Step: 9
Training loss: 1.5982143878936768
Validation loss: 2.0694199556945474

Epoch: 6| Step: 10
Training loss: 0.941164493560791
Validation loss: 2.066599856140793

Epoch: 6| Step: 11
Training loss: 1.4587998390197754
Validation loss: 2.0611345767974854

Epoch: 6| Step: 12
Training loss: 1.4093186855316162
Validation loss: 2.0763492853410783

Epoch: 6| Step: 13
Training loss: 1.1917539834976196
Validation loss: 2.0569970402666318

Epoch: 384| Step: 0
Training loss: 1.8519551753997803
Validation loss: 2.0496214025764057

Epoch: 6| Step: 1
Training loss: 1.5195080041885376
Validation loss: 2.0874169539379817

Epoch: 6| Step: 2
Training loss: 1.992945909500122
Validation loss: 2.0992329479545675

Epoch: 6| Step: 3
Training loss: 1.015999436378479
Validation loss: 2.1218797788825086

Epoch: 6| Step: 4
Training loss: 1.8342928886413574
Validation loss: 2.0900114069702806

Epoch: 6| Step: 5
Training loss: 1.8917431831359863
Validation loss: 2.073610644186697

Epoch: 6| Step: 6
Training loss: 1.552504301071167
Validation loss: 2.091377116018726

Epoch: 6| Step: 7
Training loss: 1.480360507965088
Validation loss: 2.0559803144906157

Epoch: 6| Step: 8
Training loss: 1.2153793573379517
Validation loss: 2.079313019270538

Epoch: 6| Step: 9
Training loss: 1.4163581132888794
Validation loss: 2.1189415262591456

Epoch: 6| Step: 10
Training loss: 2.0996487140655518
Validation loss: 2.1252279832798946

Epoch: 6| Step: 11
Training loss: 1.2752814292907715
Validation loss: 2.0482363482957244

Epoch: 6| Step: 12
Training loss: 1.018977165222168
Validation loss: 2.0871754551446564

Epoch: 6| Step: 13
Training loss: 1.7754507064819336
Validation loss: 2.0445850959388157

Epoch: 385| Step: 0
Training loss: 1.6999764442443848
Validation loss: 2.0595257448893722

Epoch: 6| Step: 1
Training loss: 1.0816729068756104
Validation loss: 2.070952207811417

Epoch: 6| Step: 2
Training loss: 1.1413493156433105
Validation loss: 2.025391847856583

Epoch: 6| Step: 3
Training loss: 1.7884594202041626
Validation loss: 2.0477850462800715

Epoch: 6| Step: 4
Training loss: 1.4302303791046143
Validation loss: 2.0648787149818997

Epoch: 6| Step: 5
Training loss: 1.334259271621704
Validation loss: 2.083811221584197

Epoch: 6| Step: 6
Training loss: 1.2448956966400146
Validation loss: 2.08884455568047

Epoch: 6| Step: 7
Training loss: 2.065856695175171
Validation loss: 2.0700596147967922

Epoch: 6| Step: 8
Training loss: 1.8942646980285645
Validation loss: 2.069496011221281

Epoch: 6| Step: 9
Training loss: 1.4607911109924316
Validation loss: 2.073077896589874

Epoch: 6| Step: 10
Training loss: 1.5134849548339844
Validation loss: 2.0882718152897333

Epoch: 6| Step: 11
Training loss: 2.031729221343994
Validation loss: 2.070172366275582

Epoch: 6| Step: 12
Training loss: 2.1143031120300293
Validation loss: 2.075976837065912

Epoch: 6| Step: 13
Training loss: 1.8537733554840088
Validation loss: 2.1081814150656424

Epoch: 386| Step: 0
Training loss: 1.2224115133285522
Validation loss: 2.093158111777357

Epoch: 6| Step: 1
Training loss: 1.2808023691177368
Validation loss: 2.12106490647921

Epoch: 6| Step: 2
Training loss: 1.60874342918396
Validation loss: 2.1408398792307866

Epoch: 6| Step: 3
Training loss: 1.5204015970230103
Validation loss: 2.0827469274561894

Epoch: 6| Step: 4
Training loss: 1.9205071926116943
Validation loss: 2.141665989352811

Epoch: 6| Step: 5
Training loss: 1.3028719425201416
Validation loss: 2.0958158380241803

Epoch: 6| Step: 6
Training loss: 1.860994577407837
Validation loss: 2.0903195899019957

Epoch: 6| Step: 7
Training loss: 1.6270477771759033
Validation loss: 2.157169085676952

Epoch: 6| Step: 8
Training loss: 1.3938267230987549
Validation loss: 2.086043027139479

Epoch: 6| Step: 9
Training loss: 1.375566005706787
Validation loss: 2.074663669832291

Epoch: 6| Step: 10
Training loss: 2.082045555114746
Validation loss: 2.0485645609517253

Epoch: 6| Step: 11
Training loss: 1.857349157333374
Validation loss: 2.1294887322251514

Epoch: 6| Step: 12
Training loss: 1.625671148300171
Validation loss: 2.063431368079237

Epoch: 6| Step: 13
Training loss: 1.142724633216858
Validation loss: 2.101902861748972

Epoch: 387| Step: 0
Training loss: 1.2424712181091309
Validation loss: 2.039491666260586

Epoch: 6| Step: 1
Training loss: 1.6291399002075195
Validation loss: 2.05618602742431

Epoch: 6| Step: 2
Training loss: 1.0251312255859375
Validation loss: 2.0691334534716863

Epoch: 6| Step: 3
Training loss: 1.3781605958938599
Validation loss: 2.0521376568783998

Epoch: 6| Step: 4
Training loss: 1.034647822380066
Validation loss: 2.065337614346576

Epoch: 6| Step: 5
Training loss: 1.755289912223816
Validation loss: 2.0766119956970215

Epoch: 6| Step: 6
Training loss: 1.3838155269622803
Validation loss: 2.0885599236334524

Epoch: 6| Step: 7
Training loss: 2.1831226348876953
Validation loss: 2.0399690776742916

Epoch: 6| Step: 8
Training loss: 1.1577657461166382
Validation loss: 2.0760375915035123

Epoch: 6| Step: 9
Training loss: 2.1800320148468018
Validation loss: 2.0906941326715613

Epoch: 6| Step: 10
Training loss: 1.4395925998687744
Validation loss: 2.0689820474193943

Epoch: 6| Step: 11
Training loss: 1.753553867340088
Validation loss: 2.056392054403982

Epoch: 6| Step: 12
Training loss: 1.9969435930252075
Validation loss: 2.0924272485958633

Epoch: 6| Step: 13
Training loss: 2.057318687438965
Validation loss: 2.0975450328601304

Epoch: 388| Step: 0
Training loss: 1.515089750289917
Validation loss: 2.0318764589166127

Epoch: 6| Step: 1
Training loss: 1.5921393632888794
Validation loss: 2.104661556982225

Epoch: 6| Step: 2
Training loss: 1.3198394775390625
Validation loss: 2.075520674387614

Epoch: 6| Step: 3
Training loss: 1.8589057922363281
Validation loss: 2.0642314764761154

Epoch: 6| Step: 4
Training loss: 1.2041585445404053
Validation loss: 2.078619646769698

Epoch: 6| Step: 5
Training loss: 1.74272882938385
Validation loss: 2.0965458680224676

Epoch: 6| Step: 6
Training loss: 2.1609668731689453
Validation loss: 2.0571601621566282

Epoch: 6| Step: 7
Training loss: 1.3288631439208984
Validation loss: 2.0325415621521654

Epoch: 6| Step: 8
Training loss: 1.2075623273849487
Validation loss: 2.0835051716014905

Epoch: 6| Step: 9
Training loss: 1.9675376415252686
Validation loss: 2.0416508989949382

Epoch: 6| Step: 10
Training loss: 1.4872760772705078
Validation loss: 2.0904022903852564

Epoch: 6| Step: 11
Training loss: 1.6003044843673706
Validation loss: 2.048398725448116

Epoch: 6| Step: 12
Training loss: 1.6888909339904785
Validation loss: 2.0931225181907736

Epoch: 6| Step: 13
Training loss: 0.9846118092536926
Validation loss: 2.0508369220200406

Epoch: 389| Step: 0
Training loss: 1.5342421531677246
Validation loss: 2.0695169587289133

Epoch: 6| Step: 1
Training loss: 1.0451159477233887
Validation loss: 2.072421266186622

Epoch: 6| Step: 2
Training loss: 2.158402919769287
Validation loss: 2.0875415417455856

Epoch: 6| Step: 3
Training loss: 1.0045979022979736
Validation loss: 2.077695080029067

Epoch: 6| Step: 4
Training loss: 2.044677734375
Validation loss: 2.1281363835898777

Epoch: 6| Step: 5
Training loss: 0.9827083349227905
Validation loss: 2.113701699882425

Epoch: 6| Step: 6
Training loss: 1.6136391162872314
Validation loss: 2.1215938034877984

Epoch: 6| Step: 7
Training loss: 1.4982283115386963
Validation loss: 2.1754324359278523

Epoch: 6| Step: 8
Training loss: 2.1828861236572266
Validation loss: 2.176867510682793

Epoch: 6| Step: 9
Training loss: 2.7106571197509766
Validation loss: 2.1335516975771998

Epoch: 6| Step: 10
Training loss: 1.1838996410369873
Validation loss: 2.1667035023371377

Epoch: 6| Step: 11
Training loss: 1.5170114040374756
Validation loss: 2.1352027167556105

Epoch: 6| Step: 12
Training loss: 1.671538233757019
Validation loss: 2.095036260543331

Epoch: 6| Step: 13
Training loss: 1.742680311203003
Validation loss: 2.0940940764642533

Epoch: 390| Step: 0
Training loss: 1.0274460315704346
Validation loss: 2.1086943431567122

Epoch: 6| Step: 1
Training loss: 1.3975287675857544
Validation loss: 2.1187085720800583

Epoch: 6| Step: 2
Training loss: 1.1568673849105835
Validation loss: 2.0424659431621595

Epoch: 6| Step: 3
Training loss: 1.7049462795257568
Validation loss: 2.0672039780565488

Epoch: 6| Step: 4
Training loss: 1.656092882156372
Validation loss: 2.070337659569197

Epoch: 6| Step: 5
Training loss: 1.174933910369873
Validation loss: 2.0608663738414807

Epoch: 6| Step: 6
Training loss: 2.031177043914795
Validation loss: 2.0518963388217393

Epoch: 6| Step: 7
Training loss: 1.6866252422332764
Validation loss: 2.025272866731049

Epoch: 6| Step: 8
Training loss: 1.3836426734924316
Validation loss: 2.078539304835822

Epoch: 6| Step: 9
Training loss: 2.2365610599517822
Validation loss: 2.0947584464985836

Epoch: 6| Step: 10
Training loss: 1.2721699476242065
Validation loss: 2.09668610172887

Epoch: 6| Step: 11
Training loss: 1.461022973060608
Validation loss: 2.085145681135116

Epoch: 6| Step: 12
Training loss: 1.688123345375061
Validation loss: 2.0709512285006944

Epoch: 6| Step: 13
Training loss: 2.8273234367370605
Validation loss: 2.0720046604833295

Epoch: 391| Step: 0
Training loss: 1.8158936500549316
Validation loss: 2.0424708653521795

Epoch: 6| Step: 1
Training loss: 1.5189743041992188
Validation loss: 2.1150516874046734

Epoch: 6| Step: 2
Training loss: 1.7923760414123535
Validation loss: 2.0799482381472023

Epoch: 6| Step: 3
Training loss: 1.5905535221099854
Validation loss: 2.058808583085255

Epoch: 6| Step: 4
Training loss: 1.560813546180725
Validation loss: 2.11286913194964

Epoch: 6| Step: 5
Training loss: 1.425755262374878
Validation loss: 2.0847309225349018

Epoch: 6| Step: 6
Training loss: 1.5110228061676025
Validation loss: 2.054960168817992

Epoch: 6| Step: 7
Training loss: 2.2124404907226562
Validation loss: 2.087098729225897

Epoch: 6| Step: 8
Training loss: 1.5361278057098389
Validation loss: 2.0547323765293246

Epoch: 6| Step: 9
Training loss: 1.620621681213379
Validation loss: 2.079332938758276

Epoch: 6| Step: 10
Training loss: 1.134913444519043
Validation loss: 2.1007188430396457

Epoch: 6| Step: 11
Training loss: 1.2532941102981567
Validation loss: 2.1058599487427743

Epoch: 6| Step: 12
Training loss: 1.2519620656967163
Validation loss: 2.104846885127406

Epoch: 6| Step: 13
Training loss: 1.8049970865249634
Validation loss: 2.1056053535912627

Epoch: 392| Step: 0
Training loss: 1.7038569450378418
Validation loss: 2.074731337126865

Epoch: 6| Step: 1
Training loss: 1.7131394147872925
Validation loss: 2.1148978164119105

Epoch: 6| Step: 2
Training loss: 1.8433187007904053
Validation loss: 2.0490794579188027

Epoch: 6| Step: 3
Training loss: 1.0847196578979492
Validation loss: 2.0457887418808474

Epoch: 6| Step: 4
Training loss: 1.8453723192214966
Validation loss: 2.0892953718862226

Epoch: 6| Step: 5
Training loss: 1.1611032485961914
Validation loss: 2.0697201093037925

Epoch: 6| Step: 6
Training loss: 1.7805633544921875
Validation loss: 2.0590699026661534

Epoch: 6| Step: 7
Training loss: 1.2088783979415894
Validation loss: 2.0519265667084725

Epoch: 6| Step: 8
Training loss: 2.0286073684692383
Validation loss: 2.0599395985244424

Epoch: 6| Step: 9
Training loss: 1.6672941446304321
Validation loss: 2.083503891062993

Epoch: 6| Step: 10
Training loss: 1.4075967073440552
Validation loss: 2.048173342981646

Epoch: 6| Step: 11
Training loss: 1.7908165454864502
Validation loss: 2.040460858293759

Epoch: 6| Step: 12
Training loss: 1.865190029144287
Validation loss: 2.0796344767334642

Epoch: 6| Step: 13
Training loss: 1.0565696954727173
Validation loss: 2.097100814183553

Epoch: 393| Step: 0
Training loss: 1.5287556648254395
Validation loss: 2.0699830901238228

Epoch: 6| Step: 1
Training loss: 1.295893907546997
Validation loss: 2.070118373440158

Epoch: 6| Step: 2
Training loss: 1.7007999420166016
Validation loss: 2.053892940603277

Epoch: 6| Step: 3
Training loss: 1.42722749710083
Validation loss: 2.074539639616525

Epoch: 6| Step: 4
Training loss: 1.6060597896575928
Validation loss: 2.058204266332811

Epoch: 6| Step: 5
Training loss: 2.3314261436462402
Validation loss: 2.0520101772841586

Epoch: 6| Step: 6
Training loss: 1.4085068702697754
Validation loss: 2.117070064749769

Epoch: 6| Step: 7
Training loss: 1.6794724464416504
Validation loss: 2.0844009691669094

Epoch: 6| Step: 8
Training loss: 1.1758415699005127
Validation loss: 2.0295823953484975

Epoch: 6| Step: 9
Training loss: 1.7439823150634766
Validation loss: 2.0933410993186374

Epoch: 6| Step: 10
Training loss: 1.6360303163528442
Validation loss: 2.0591506688825545

Epoch: 6| Step: 11
Training loss: 1.2400429248809814
Validation loss: 2.0558629753769084

Epoch: 6| Step: 12
Training loss: 1.71244215965271
Validation loss: 2.075660636348109

Epoch: 6| Step: 13
Training loss: 1.3300813436508179
Validation loss: 2.0632512825791554

Epoch: 394| Step: 0
Training loss: 1.2228093147277832
Validation loss: 2.082457750074325

Epoch: 6| Step: 1
Training loss: 1.3488950729370117
Validation loss: 2.0867102043603056

Epoch: 6| Step: 2
Training loss: 1.937727689743042
Validation loss: 2.0671513772779897

Epoch: 6| Step: 3
Training loss: 0.8664244413375854
Validation loss: 2.0833745348838066

Epoch: 6| Step: 4
Training loss: 2.379672050476074
Validation loss: 2.040115774318736

Epoch: 6| Step: 5
Training loss: 1.4538480043411255
Validation loss: 2.0744769022028935

Epoch: 6| Step: 6
Training loss: 1.0115104913711548
Validation loss: 2.079453529850129

Epoch: 6| Step: 7
Training loss: 1.491529107093811
Validation loss: 2.075120246538552

Epoch: 6| Step: 8
Training loss: 1.615393877029419
Validation loss: 2.104585478382726

Epoch: 6| Step: 9
Training loss: 1.8775699138641357
Validation loss: 2.089602388361449

Epoch: 6| Step: 10
Training loss: 1.8014203310012817
Validation loss: 2.037883074052872

Epoch: 6| Step: 11
Training loss: 1.587193489074707
Validation loss: 2.0716365486062984

Epoch: 6| Step: 12
Training loss: 1.7630786895751953
Validation loss: 2.06127360815643

Epoch: 6| Step: 13
Training loss: 1.7295660972595215
Validation loss: 2.054084026685325

Epoch: 395| Step: 0
Training loss: 1.5660476684570312
Validation loss: 2.0803904635931856

Epoch: 6| Step: 1
Training loss: 1.3904434442520142
Validation loss: 2.0810240750671714

Epoch: 6| Step: 2
Training loss: 2.4871582984924316
Validation loss: 2.1030245775817544

Epoch: 6| Step: 3
Training loss: 1.0061850547790527
Validation loss: 2.1255991997257357

Epoch: 6| Step: 4
Training loss: 1.719120740890503
Validation loss: 2.1093577005529918

Epoch: 6| Step: 5
Training loss: 1.5121784210205078
Validation loss: 2.121534393679711

Epoch: 6| Step: 6
Training loss: 1.6067805290222168
Validation loss: 2.136855063899871

Epoch: 6| Step: 7
Training loss: 1.7780358791351318
Validation loss: 2.1348862878737913

Epoch: 6| Step: 8
Training loss: 1.433656930923462
Validation loss: 2.1619717664616083

Epoch: 6| Step: 9
Training loss: 1.640595555305481
Validation loss: 2.119453885221994

Epoch: 6| Step: 10
Training loss: 1.5397098064422607
Validation loss: 2.0664920601793515

Epoch: 6| Step: 11
Training loss: 2.044886827468872
Validation loss: 2.0941723187764487

Epoch: 6| Step: 12
Training loss: 1.3124412298202515
Validation loss: 2.0873603666982343

Epoch: 6| Step: 13
Training loss: 1.12441086769104
Validation loss: 2.0630127204361783

Epoch: 396| Step: 0
Training loss: 2.312394380569458
Validation loss: 2.069630781809489

Epoch: 6| Step: 1
Training loss: 1.7155051231384277
Validation loss: 2.0743685101950042

Epoch: 6| Step: 2
Training loss: 1.6891531944274902
Validation loss: 2.0695207926534835

Epoch: 6| Step: 3
Training loss: 2.287663698196411
Validation loss: 2.053464474216584

Epoch: 6| Step: 4
Training loss: 1.8391919136047363
Validation loss: 2.081352376168774

Epoch: 6| Step: 5
Training loss: 1.1167714595794678
Validation loss: 2.0692885870574624

Epoch: 6| Step: 6
Training loss: 1.2611010074615479
Validation loss: 2.030476636784051

Epoch: 6| Step: 7
Training loss: 0.8460797667503357
Validation loss: 2.073560501939507

Epoch: 6| Step: 8
Training loss: 1.234534740447998
Validation loss: 2.0469783518903997

Epoch: 6| Step: 9
Training loss: 1.5289849042892456
Validation loss: 2.0465692127904584

Epoch: 6| Step: 10
Training loss: 1.5149576663970947
Validation loss: 2.0544127905240623

Epoch: 6| Step: 11
Training loss: 0.9535512924194336
Validation loss: 2.0544557340683474

Epoch: 6| Step: 12
Training loss: 1.6625730991363525
Validation loss: 2.1086715165004937

Epoch: 6| Step: 13
Training loss: 1.2978768348693848
Validation loss: 2.0659671727047173

Epoch: 397| Step: 0
Training loss: 1.4997204542160034
Validation loss: 2.0746788376121112

Epoch: 6| Step: 1
Training loss: 2.223111867904663
Validation loss: 2.10253046917659

Epoch: 6| Step: 2
Training loss: 1.1732771396636963
Validation loss: 2.096918770062026

Epoch: 6| Step: 3
Training loss: 1.6205127239227295
Validation loss: 2.0973835170909925

Epoch: 6| Step: 4
Training loss: 1.1533501148223877
Validation loss: 2.087218012861026

Epoch: 6| Step: 5
Training loss: 1.9010932445526123
Validation loss: 2.0693256367919264

Epoch: 6| Step: 6
Training loss: 1.2906798124313354
Validation loss: 2.0886242312769734

Epoch: 6| Step: 7
Training loss: 1.5628846883773804
Validation loss: 2.095521142405848

Epoch: 6| Step: 8
Training loss: 1.3743451833724976
Validation loss: 2.0970519755476262

Epoch: 6| Step: 9
Training loss: 1.3709537982940674
Validation loss: 2.0979878312797955

Epoch: 6| Step: 10
Training loss: 1.1959168910980225
Validation loss: 2.101133664449056

Epoch: 6| Step: 11
Training loss: 1.5959203243255615
Validation loss: 2.0508658424500497

Epoch: 6| Step: 12
Training loss: 2.362769603729248
Validation loss: 2.105145920989334

Epoch: 6| Step: 13
Training loss: 1.163076639175415
Validation loss: 2.0876773147172827

Epoch: 398| Step: 0
Training loss: 2.005316734313965
Validation loss: 2.078900606401505

Epoch: 6| Step: 1
Training loss: 1.7289111614227295
Validation loss: 2.112337432881837

Epoch: 6| Step: 2
Training loss: 2.042790412902832
Validation loss: 2.104901598345849

Epoch: 6| Step: 3
Training loss: 1.7998356819152832
Validation loss: 2.0692689059883036

Epoch: 6| Step: 4
Training loss: 1.2311701774597168
Validation loss: 2.0925675297296173

Epoch: 6| Step: 5
Training loss: 1.832646369934082
Validation loss: 2.11725095523301

Epoch: 6| Step: 6
Training loss: 0.8980165719985962
Validation loss: 2.0687606052685807

Epoch: 6| Step: 7
Training loss: 2.1084110736846924
Validation loss: 2.0870432481970838

Epoch: 6| Step: 8
Training loss: 1.7077105045318604
Validation loss: 2.124828084822624

Epoch: 6| Step: 9
Training loss: 1.4281156063079834
Validation loss: 2.085971286219935

Epoch: 6| Step: 10
Training loss: 1.559058666229248
Validation loss: 2.099538160908607

Epoch: 6| Step: 11
Training loss: 1.2877590656280518
Validation loss: 2.082016706466675

Epoch: 6| Step: 12
Training loss: 1.2098803520202637
Validation loss: 2.0821123482078634

Epoch: 6| Step: 13
Training loss: 0.7600961327552795
Validation loss: 2.0671753562906736

Epoch: 399| Step: 0
Training loss: 1.2761280536651611
Validation loss: 2.062667001960098

Epoch: 6| Step: 1
Training loss: 1.5377109050750732
Validation loss: 2.0599088002276678

Epoch: 6| Step: 2
Training loss: 2.0203592777252197
Validation loss: 2.0537535990438154

Epoch: 6| Step: 3
Training loss: 1.3913421630859375
Validation loss: 2.10056040363927

Epoch: 6| Step: 4
Training loss: 1.7148795127868652
Validation loss: 2.0791464787657543

Epoch: 6| Step: 5
Training loss: 2.075335741043091
Validation loss: 2.08780066556828

Epoch: 6| Step: 6
Training loss: 1.8572825193405151
Validation loss: 2.0752776284371652

Epoch: 6| Step: 7
Training loss: 1.3676338195800781
Validation loss: 2.080091607186102

Epoch: 6| Step: 8
Training loss: 1.0775721073150635
Validation loss: 2.085954399519069

Epoch: 6| Step: 9
Training loss: 1.7879743576049805
Validation loss: 2.083653447448566

Epoch: 6| Step: 10
Training loss: 1.3235657215118408
Validation loss: 2.0472714567697174

Epoch: 6| Step: 11
Training loss: 0.8585430979728699
Validation loss: 2.0464015712020216

Epoch: 6| Step: 12
Training loss: 1.8423198461532593
Validation loss: 2.0834155146793654

Epoch: 6| Step: 13
Training loss: 1.7117578983306885
Validation loss: 2.0860937141603038

Epoch: 400| Step: 0
Training loss: 1.173440933227539
Validation loss: 2.0233631595488517

Epoch: 6| Step: 1
Training loss: 0.9105895757675171
Validation loss: 2.093746805703768

Epoch: 6| Step: 2
Training loss: 1.9561737775802612
Validation loss: 2.0734195234954997

Epoch: 6| Step: 3
Training loss: 1.3097050189971924
Validation loss: 2.0831030261132026

Epoch: 6| Step: 4
Training loss: 1.2565536499023438
Validation loss: 2.100398894279234

Epoch: 6| Step: 5
Training loss: 1.5804697275161743
Validation loss: 2.06914294791478

Epoch: 6| Step: 6
Training loss: 1.553274154663086
Validation loss: 2.0866387544139737

Epoch: 6| Step: 7
Training loss: 1.4416282176971436
Validation loss: 2.1145222507497317

Epoch: 6| Step: 8
Training loss: 1.7868212461471558
Validation loss: 2.1122149934050856

Epoch: 6| Step: 9
Training loss: 1.656661868095398
Validation loss: 2.0750909646352134

Epoch: 6| Step: 10
Training loss: 1.5632328987121582
Validation loss: 2.0838744871078

Epoch: 6| Step: 11
Training loss: 2.079552173614502
Validation loss: 2.0785456229281682

Epoch: 6| Step: 12
Training loss: 2.202338695526123
Validation loss: 2.054388120610227

Epoch: 6| Step: 13
Training loss: 1.111681580543518
Validation loss: 2.063123131311068

Epoch: 401| Step: 0
Training loss: 2.1084718704223633
Validation loss: 2.0822015526474162

Epoch: 6| Step: 1
Training loss: 1.5439107418060303
Validation loss: 2.0689761151549635

Epoch: 6| Step: 2
Training loss: 1.5847067832946777
Validation loss: 2.1040621073015275

Epoch: 6| Step: 3
Training loss: 1.257980465888977
Validation loss: 2.0867912807772235

Epoch: 6| Step: 4
Training loss: 1.6191344261169434
Validation loss: 2.0482192603490685

Epoch: 6| Step: 5
Training loss: 1.9223132133483887
Validation loss: 2.0212675704750964

Epoch: 6| Step: 6
Training loss: 1.0585181713104248
Validation loss: 2.0322481022086194

Epoch: 6| Step: 7
Training loss: 1.9246516227722168
Validation loss: 2.0416391408571632

Epoch: 6| Step: 8
Training loss: 1.943626046180725
Validation loss: 2.0632302735441472

Epoch: 6| Step: 9
Training loss: 2.026939868927002
Validation loss: 2.088531401849562

Epoch: 6| Step: 10
Training loss: 1.1271111965179443
Validation loss: 2.055627733148554

Epoch: 6| Step: 11
Training loss: 1.4770455360412598
Validation loss: 2.0803234102905437

Epoch: 6| Step: 12
Training loss: 0.7209236025810242
Validation loss: 2.083648289403608

Epoch: 6| Step: 13
Training loss: 1.721770167350769
Validation loss: 2.1013114580544094

Epoch: 402| Step: 0
Training loss: 1.9075566530227661
Validation loss: 2.074975347006193

Epoch: 6| Step: 1
Training loss: 1.7249813079833984
Validation loss: 2.090413205085262

Epoch: 6| Step: 2
Training loss: 1.229332685470581
Validation loss: 2.1205351403964463

Epoch: 6| Step: 3
Training loss: 1.7085739374160767
Validation loss: 2.1186120779283586

Epoch: 6| Step: 4
Training loss: 1.9742449522018433
Validation loss: 2.114976212542544

Epoch: 6| Step: 5
Training loss: 1.3047168254852295
Validation loss: 2.098951285885226

Epoch: 6| Step: 6
Training loss: 2.067824602127075
Validation loss: 2.081020095015085

Epoch: 6| Step: 7
Training loss: 1.524782419204712
Validation loss: 2.0609321671147502

Epoch: 6| Step: 8
Training loss: 1.3425796031951904
Validation loss: 2.107693736271192

Epoch: 6| Step: 9
Training loss: 1.3036531209945679
Validation loss: 2.072065914830854

Epoch: 6| Step: 10
Training loss: 1.1809546947479248
Validation loss: 2.098419270207805

Epoch: 6| Step: 11
Training loss: 1.7339606285095215
Validation loss: 2.069086382465978

Epoch: 6| Step: 12
Training loss: 1.7605605125427246
Validation loss: 2.076175738406438

Epoch: 6| Step: 13
Training loss: 0.6221995949745178
Validation loss: 2.0439522445842786

Epoch: 403| Step: 0
Training loss: 2.0710835456848145
Validation loss: 2.107169565334115

Epoch: 6| Step: 1
Training loss: 1.1966474056243896
Validation loss: 2.0832433662106915

Epoch: 6| Step: 2
Training loss: 2.0038537979125977
Validation loss: 2.1004960639502412

Epoch: 6| Step: 3
Training loss: 1.164812684059143
Validation loss: 2.0603944998915478

Epoch: 6| Step: 4
Training loss: 1.246813416481018
Validation loss: 2.0757082444365307

Epoch: 6| Step: 5
Training loss: 1.9543259143829346
Validation loss: 2.0857689457554973

Epoch: 6| Step: 6
Training loss: 1.5237059593200684
Validation loss: 2.106628571787188

Epoch: 6| Step: 7
Training loss: 1.18337082862854
Validation loss: 2.066451388020669

Epoch: 6| Step: 8
Training loss: 2.34808349609375
Validation loss: 2.081626763907812

Epoch: 6| Step: 9
Training loss: 1.357670783996582
Validation loss: 2.089274690997216

Epoch: 6| Step: 10
Training loss: 1.3590631484985352
Validation loss: 2.1012349051813923

Epoch: 6| Step: 11
Training loss: 1.3936527967453003
Validation loss: 2.037762067651236

Epoch: 6| Step: 12
Training loss: 1.429599642753601
Validation loss: 2.0582988339085735

Epoch: 6| Step: 13
Training loss: 1.2428491115570068
Validation loss: 2.09378291714576

Epoch: 404| Step: 0
Training loss: 2.5204672813415527
Validation loss: 2.0675267788671676

Epoch: 6| Step: 1
Training loss: 1.3471295833587646
Validation loss: 2.0448462758012997

Epoch: 6| Step: 2
Training loss: 1.5844252109527588
Validation loss: 2.078077580339165

Epoch: 6| Step: 3
Training loss: 1.2108484506607056
Validation loss: 2.0318704471793225

Epoch: 6| Step: 4
Training loss: 1.321803331375122
Validation loss: 2.029585564008323

Epoch: 6| Step: 5
Training loss: 1.9783775806427002
Validation loss: 2.078782029049371

Epoch: 6| Step: 6
Training loss: 1.394407033920288
Validation loss: 2.092947977845387

Epoch: 6| Step: 7
Training loss: 1.6288758516311646
Validation loss: 2.069328828524518

Epoch: 6| Step: 8
Training loss: 1.1976265907287598
Validation loss: 2.0661817366077053

Epoch: 6| Step: 9
Training loss: 1.9241466522216797
Validation loss: 2.0318978524977163

Epoch: 6| Step: 10
Training loss: 1.3225219249725342
Validation loss: 2.0627720714897237

Epoch: 6| Step: 11
Training loss: 1.420927882194519
Validation loss: 2.0502267652942288

Epoch: 6| Step: 12
Training loss: 1.1639320850372314
Validation loss: 2.0833573161914782

Epoch: 6| Step: 13
Training loss: 1.008775234222412
Validation loss: 2.034662631250197

Epoch: 405| Step: 0
Training loss: 1.048209309577942
Validation loss: 2.097037475596192

Epoch: 6| Step: 1
Training loss: 1.0500757694244385
Validation loss: 2.1224674063344158

Epoch: 6| Step: 2
Training loss: 1.757338285446167
Validation loss: 2.164332510322653

Epoch: 6| Step: 3
Training loss: 1.858581304550171
Validation loss: 2.1086234508022184

Epoch: 6| Step: 4
Training loss: 2.478062152862549
Validation loss: 2.1272228981858943

Epoch: 6| Step: 5
Training loss: 1.160879373550415
Validation loss: 2.120108873613419

Epoch: 6| Step: 6
Training loss: 1.1834192276000977
Validation loss: 2.1842766846379926

Epoch: 6| Step: 7
Training loss: 1.5876251459121704
Validation loss: 2.16077882628287

Epoch: 6| Step: 8
Training loss: 1.978583812713623
Validation loss: 2.14916798632632

Epoch: 6| Step: 9
Training loss: 1.364225149154663
Validation loss: 2.1386093657503844

Epoch: 6| Step: 10
Training loss: 1.225484013557434
Validation loss: 2.0950430208636868

Epoch: 6| Step: 11
Training loss: 2.2268476486206055
Validation loss: 2.131888222950761

Epoch: 6| Step: 12
Training loss: 1.2697560787200928
Validation loss: 2.085689094758803

Epoch: 6| Step: 13
Training loss: 2.1154298782348633
Validation loss: 2.036076994352443

Epoch: 406| Step: 0
Training loss: 1.6525657176971436
Validation loss: 2.0696578436000372

Epoch: 6| Step: 1
Training loss: 1.3251190185546875
Validation loss: 2.101717359276228

Epoch: 6| Step: 2
Training loss: 1.7842297554016113
Validation loss: 2.057314685595933

Epoch: 6| Step: 3
Training loss: 1.5250492095947266
Validation loss: 2.089872355102211

Epoch: 6| Step: 4
Training loss: 1.4231808185577393
Validation loss: 2.0245077058833134

Epoch: 6| Step: 5
Training loss: 1.6446915864944458
Validation loss: 2.0637259367973573

Epoch: 6| Step: 6
Training loss: 1.9009127616882324
Validation loss: 2.055869907461187

Epoch: 6| Step: 7
Training loss: 1.0989375114440918
Validation loss: 2.0249066224662204

Epoch: 6| Step: 8
Training loss: 1.5018751621246338
Validation loss: 2.088002217713223

Epoch: 6| Step: 9
Training loss: 1.7693132162094116
Validation loss: 2.0561951193758237

Epoch: 6| Step: 10
Training loss: 1.469288945198059
Validation loss: 2.075692927965554

Epoch: 6| Step: 11
Training loss: 1.5513521432876587
Validation loss: 2.059391329365392

Epoch: 6| Step: 12
Training loss: 1.5913569927215576
Validation loss: 2.097884187134363

Epoch: 6| Step: 13
Training loss: 1.3676929473876953
Validation loss: 2.0559983689297914

Epoch: 407| Step: 0
Training loss: 1.8644200563430786
Validation loss: 2.048207272765457

Epoch: 6| Step: 1
Training loss: 1.1937220096588135
Validation loss: 2.087188587393812

Epoch: 6| Step: 2
Training loss: 1.2165168523788452
Validation loss: 2.0551625400461178

Epoch: 6| Step: 3
Training loss: 1.8075551986694336
Validation loss: 2.074754857247876

Epoch: 6| Step: 4
Training loss: 1.8625900745391846
Validation loss: 2.081877157252322

Epoch: 6| Step: 5
Training loss: 1.858400821685791
Validation loss: 2.055820370233187

Epoch: 6| Step: 6
Training loss: 1.3488409519195557
Validation loss: 2.1141398260670323

Epoch: 6| Step: 7
Training loss: 1.4855660200119019
Validation loss: 2.070981799915273

Epoch: 6| Step: 8
Training loss: 1.278597116470337
Validation loss: 2.0858268122519217

Epoch: 6| Step: 9
Training loss: 1.46670663356781
Validation loss: 2.137155814837384

Epoch: 6| Step: 10
Training loss: 1.975238561630249
Validation loss: 2.140562501004947

Epoch: 6| Step: 11
Training loss: 1.426151990890503
Validation loss: 2.1001472139871247

Epoch: 6| Step: 12
Training loss: 1.555135726928711
Validation loss: 2.101762704951789

Epoch: 6| Step: 13
Training loss: 1.2119641304016113
Validation loss: 2.0917003257300264

Epoch: 408| Step: 0
Training loss: 1.555107831954956
Validation loss: 2.078319990506736

Epoch: 6| Step: 1
Training loss: 1.6164625883102417
Validation loss: 2.1126235479949624

Epoch: 6| Step: 2
Training loss: 2.1661570072174072
Validation loss: 2.094503838528869

Epoch: 6| Step: 3
Training loss: 1.2450069189071655
Validation loss: 2.085470102166617

Epoch: 6| Step: 4
Training loss: 1.5163675546646118
Validation loss: 2.0812199525935675

Epoch: 6| Step: 5
Training loss: 1.3349850177764893
Validation loss: 2.0814209856012815

Epoch: 6| Step: 6
Training loss: 1.3330926895141602
Validation loss: 2.060310356078609

Epoch: 6| Step: 7
Training loss: 1.5938485860824585
Validation loss: 2.102196349892565

Epoch: 6| Step: 8
Training loss: 1.6777225732803345
Validation loss: 2.0723798864631244

Epoch: 6| Step: 9
Training loss: 0.9048272967338562
Validation loss: 2.073388486780146

Epoch: 6| Step: 10
Training loss: 1.865642786026001
Validation loss: 2.0658827738095353

Epoch: 6| Step: 11
Training loss: 1.0321329832077026
Validation loss: 2.0726684549803376

Epoch: 6| Step: 12
Training loss: 1.8347461223602295
Validation loss: 2.0788361641668502

Epoch: 6| Step: 13
Training loss: 1.9398452043533325
Validation loss: 2.0570536134063557

Epoch: 409| Step: 0
Training loss: 1.5484057664871216
Validation loss: 2.075573241838845

Epoch: 6| Step: 1
Training loss: 1.2815942764282227
Validation loss: 2.083528450740281

Epoch: 6| Step: 2
Training loss: 1.3462598323822021
Validation loss: 2.0568171124304495

Epoch: 6| Step: 3
Training loss: 1.3173673152923584
Validation loss: 2.060286029692619

Epoch: 6| Step: 4
Training loss: 1.451314926147461
Validation loss: 2.0641869768019645

Epoch: 6| Step: 5
Training loss: 1.1809232234954834
Validation loss: 2.063757506749963

Epoch: 6| Step: 6
Training loss: 1.5159413814544678
Validation loss: 2.0865783819588284

Epoch: 6| Step: 7
Training loss: 1.5511717796325684
Validation loss: 2.096392208530057

Epoch: 6| Step: 8
Training loss: 1.8902734518051147
Validation loss: 2.0622573411592873

Epoch: 6| Step: 9
Training loss: 1.1514158248901367
Validation loss: 2.0732710681935793

Epoch: 6| Step: 10
Training loss: 1.412339448928833
Validation loss: 2.13952822326332

Epoch: 6| Step: 11
Training loss: 1.683645248413086
Validation loss: 2.061179949391273

Epoch: 6| Step: 12
Training loss: 2.842172145843506
Validation loss: 2.0746399561564126

Epoch: 6| Step: 13
Training loss: 0.9243218302726746
Validation loss: 2.103539038729924

Epoch: 410| Step: 0
Training loss: 0.8096107244491577
Validation loss: 2.0661267862525037

Epoch: 6| Step: 1
Training loss: 1.565626859664917
Validation loss: 2.0707013607025146

Epoch: 6| Step: 2
Training loss: 1.1673684120178223
Validation loss: 2.0875612587057133

Epoch: 6| Step: 3
Training loss: 1.4544332027435303
Validation loss: 2.0873940478089037

Epoch: 6| Step: 4
Training loss: 2.404179334640503
Validation loss: 2.0995005382004606

Epoch: 6| Step: 5
Training loss: 1.5225586891174316
Validation loss: 2.1105687618255615

Epoch: 6| Step: 6
Training loss: 1.825518250465393
Validation loss: 2.072312037150065

Epoch: 6| Step: 7
Training loss: 1.9736590385437012
Validation loss: 2.1268745071144513

Epoch: 6| Step: 8
Training loss: 1.3118609189987183
Validation loss: 2.0912255305115894

Epoch: 6| Step: 9
Training loss: 1.7313995361328125
Validation loss: 2.0428029888419696

Epoch: 6| Step: 10
Training loss: 1.3406327962875366
Validation loss: 2.0877592986629856

Epoch: 6| Step: 11
Training loss: 1.7128595113754272
Validation loss: 2.0815012711350636

Epoch: 6| Step: 12
Training loss: 1.6208983659744263
Validation loss: 2.072039673405309

Epoch: 6| Step: 13
Training loss: 0.983454704284668
Validation loss: 2.0755897081026466

Epoch: 411| Step: 0
Training loss: 0.5259072780609131
Validation loss: 2.0669902524640484

Epoch: 6| Step: 1
Training loss: 2.1945605278015137
Validation loss: 2.0475839286722164

Epoch: 6| Step: 2
Training loss: 0.9030036330223083
Validation loss: 2.0799814078115646

Epoch: 6| Step: 3
Training loss: 1.5759363174438477
Validation loss: 2.0600090155037503

Epoch: 6| Step: 4
Training loss: 1.3471333980560303
Validation loss: 2.1203308233650784

Epoch: 6| Step: 5
Training loss: 2.033353567123413
Validation loss: 2.090659390213669

Epoch: 6| Step: 6
Training loss: 1.9223893880844116
Validation loss: 2.1025080706483577

Epoch: 6| Step: 7
Training loss: 1.3806700706481934
Validation loss: 2.129728486461024

Epoch: 6| Step: 8
Training loss: 1.3664555549621582
Validation loss: 2.0996418153086016

Epoch: 6| Step: 9
Training loss: 1.8848817348480225
Validation loss: 2.1001790646583802

Epoch: 6| Step: 10
Training loss: 1.8723111152648926
Validation loss: 2.095565349824967

Epoch: 6| Step: 11
Training loss: 1.331586480140686
Validation loss: 2.1116320240882134

Epoch: 6| Step: 12
Training loss: 1.427450180053711
Validation loss: 2.103302217298938

Epoch: 6| Step: 13
Training loss: 1.9915242195129395
Validation loss: 2.0843502167732484

Epoch: 412| Step: 0
Training loss: 1.2057157754898071
Validation loss: 2.039600726096861

Epoch: 6| Step: 1
Training loss: 1.4881975650787354
Validation loss: 2.0407517597239506

Epoch: 6| Step: 2
Training loss: 1.3537774085998535
Validation loss: 2.0420641822199666

Epoch: 6| Step: 3
Training loss: 1.5333774089813232
Validation loss: 2.0906023517731698

Epoch: 6| Step: 4
Training loss: 2.1905179023742676
Validation loss: 2.0861850464215843

Epoch: 6| Step: 5
Training loss: 2.0873641967773438
Validation loss: 2.0448295429188716

Epoch: 6| Step: 6
Training loss: 1.201499581336975
Validation loss: 2.0717822197944886

Epoch: 6| Step: 7
Training loss: 1.1594315767288208
Validation loss: 2.0085524910239765

Epoch: 6| Step: 8
Training loss: 1.429269552230835
Validation loss: 2.0585042763781805

Epoch: 6| Step: 9
Training loss: 1.1842724084854126
Validation loss: 2.0757066588247977

Epoch: 6| Step: 10
Training loss: 1.9779744148254395
Validation loss: 2.0395195355979343

Epoch: 6| Step: 11
Training loss: 1.5747220516204834
Validation loss: 2.0321823422626784

Epoch: 6| Step: 12
Training loss: 1.1401660442352295
Validation loss: 2.0987053840391097

Epoch: 6| Step: 13
Training loss: 2.369529962539673
Validation loss: 2.059330363427439

Epoch: 413| Step: 0
Training loss: 1.9889113903045654
Validation loss: 2.0721985114518033

Epoch: 6| Step: 1
Training loss: 1.7565703392028809
Validation loss: 2.068276605298442

Epoch: 6| Step: 2
Training loss: 2.169445037841797
Validation loss: 2.0605217256853656

Epoch: 6| Step: 3
Training loss: 0.7583287954330444
Validation loss: 2.0472484327131704

Epoch: 6| Step: 4
Training loss: 2.0837345123291016
Validation loss: 2.049686598521407

Epoch: 6| Step: 5
Training loss: 1.092439889907837
Validation loss: 2.059116135361374

Epoch: 6| Step: 6
Training loss: 1.973902702331543
Validation loss: 2.0545586591125815

Epoch: 6| Step: 7
Training loss: 1.1316810846328735
Validation loss: 2.060661292845203

Epoch: 6| Step: 8
Training loss: 2.5234179496765137
Validation loss: 2.042611288767989

Epoch: 6| Step: 9
Training loss: 1.2385950088500977
Validation loss: 2.052901365423715

Epoch: 6| Step: 10
Training loss: 1.2028894424438477
Validation loss: 2.084690360612767

Epoch: 6| Step: 11
Training loss: 1.1614692211151123
Validation loss: 2.0496815314856907

Epoch: 6| Step: 12
Training loss: 1.0150972604751587
Validation loss: 2.065775073984618

Epoch: 6| Step: 13
Training loss: 1.015379548072815
Validation loss: 2.090101288210961

Epoch: 414| Step: 0
Training loss: 2.285975456237793
Validation loss: 2.0902205282641995

Epoch: 6| Step: 1
Training loss: 1.5137766599655151
Validation loss: 2.115218085627402

Epoch: 6| Step: 2
Training loss: 1.0033490657806396
Validation loss: 2.1031977515066824

Epoch: 6| Step: 3
Training loss: 1.3989853858947754
Validation loss: 2.0855687010672783

Epoch: 6| Step: 4
Training loss: 1.6583824157714844
Validation loss: 2.0705685077175016

Epoch: 6| Step: 5
Training loss: 1.403235912322998
Validation loss: 2.102292968380836

Epoch: 6| Step: 6
Training loss: 1.5416842699050903
Validation loss: 2.0443130398309357

Epoch: 6| Step: 7
Training loss: 1.7837622165679932
Validation loss: 2.069153461405026

Epoch: 6| Step: 8
Training loss: 1.1339716911315918
Validation loss: 2.06722322587044

Epoch: 6| Step: 9
Training loss: 1.5963490009307861
Validation loss: 2.0647372250915854

Epoch: 6| Step: 10
Training loss: 1.3166656494140625
Validation loss: 2.031030926653134

Epoch: 6| Step: 11
Training loss: 1.7761335372924805
Validation loss: 2.031039448194606

Epoch: 6| Step: 12
Training loss: 1.4841203689575195
Validation loss: 2.0811827016133133

Epoch: 6| Step: 13
Training loss: 1.7537003755569458
Validation loss: 2.0994204090487574

Epoch: 415| Step: 0
Training loss: 1.3821399211883545
Validation loss: 2.0628346140666673

Epoch: 6| Step: 1
Training loss: 1.8215088844299316
Validation loss: 2.0822485467439056

Epoch: 6| Step: 2
Training loss: 1.828479528427124
Validation loss: 2.0725891743936846

Epoch: 6| Step: 3
Training loss: 1.4925416707992554
Validation loss: 2.076397160048126

Epoch: 6| Step: 4
Training loss: 1.8720004558563232
Validation loss: 2.0755259618964246

Epoch: 6| Step: 5
Training loss: 1.8376638889312744
Validation loss: 2.070358628867775

Epoch: 6| Step: 6
Training loss: 1.01583993434906
Validation loss: 2.067457902816034

Epoch: 6| Step: 7
Training loss: 1.766474723815918
Validation loss: 2.064500895879602

Epoch: 6| Step: 8
Training loss: 1.4059739112854004
Validation loss: 2.107056176790627

Epoch: 6| Step: 9
Training loss: 1.2924251556396484
Validation loss: 2.1112280507241525

Epoch: 6| Step: 10
Training loss: 1.725495457649231
Validation loss: 2.1148300760535785

Epoch: 6| Step: 11
Training loss: 1.5466328859329224
Validation loss: 2.1327161737667617

Epoch: 6| Step: 12
Training loss: 1.3568545579910278
Validation loss: 2.1205329177200154

Epoch: 6| Step: 13
Training loss: 1.0900113582611084
Validation loss: 2.0606058874437885

Epoch: 416| Step: 0
Training loss: 1.7703068256378174
Validation loss: 2.0718046977955806

Epoch: 6| Step: 1
Training loss: 0.7041852474212646
Validation loss: 2.091770246464719

Epoch: 6| Step: 2
Training loss: 1.2443006038665771
Validation loss: 2.0647805506183254

Epoch: 6| Step: 3
Training loss: 1.5740406513214111
Validation loss: 2.048394392895442

Epoch: 6| Step: 4
Training loss: 1.6448540687561035
Validation loss: 2.0747986096207813

Epoch: 6| Step: 5
Training loss: 1.2347190380096436
Validation loss: 2.055351121451265

Epoch: 6| Step: 6
Training loss: 1.9041951894760132
Validation loss: 2.076916194731189

Epoch: 6| Step: 7
Training loss: 1.5972527265548706
Validation loss: 2.0445137639199533

Epoch: 6| Step: 8
Training loss: 1.5628784894943237
Validation loss: 2.0483607348575386

Epoch: 6| Step: 9
Training loss: 1.398235559463501
Validation loss: 2.092273450666858

Epoch: 6| Step: 10
Training loss: 1.931159257888794
Validation loss: 2.082928278112924

Epoch: 6| Step: 11
Training loss: 1.540654182434082
Validation loss: 2.02798367059359

Epoch: 6| Step: 12
Training loss: 1.7295174598693848
Validation loss: 2.0204770154850458

Epoch: 6| Step: 13
Training loss: 0.9990272521972656
Validation loss: 2.0864186825290805

Epoch: 417| Step: 0
Training loss: 2.1492156982421875
Validation loss: 2.0794803147674887

Epoch: 6| Step: 1
Training loss: 1.4361170530319214
Validation loss: 2.0758763026165705

Epoch: 6| Step: 2
Training loss: 0.9565541744232178
Validation loss: 2.1130755639845327

Epoch: 6| Step: 3
Training loss: 2.096950054168701
Validation loss: 2.0164989861108924

Epoch: 6| Step: 4
Training loss: 1.111657977104187
Validation loss: 2.0324901585937827

Epoch: 6| Step: 5
Training loss: 1.361158847808838
Validation loss: 2.040353564805882

Epoch: 6| Step: 6
Training loss: 1.5353200435638428
Validation loss: 2.0506671180007277

Epoch: 6| Step: 7
Training loss: 1.6795392036437988
Validation loss: 2.0447020530700684

Epoch: 6| Step: 8
Training loss: 1.8768301010131836
Validation loss: 2.0787040469467

Epoch: 6| Step: 9
Training loss: 1.4414324760437012
Validation loss: 2.0752071949743454

Epoch: 6| Step: 10
Training loss: 1.8247016668319702
Validation loss: 2.1015649534040883

Epoch: 6| Step: 11
Training loss: 1.4623847007751465
Validation loss: 2.085695589742353

Epoch: 6| Step: 12
Training loss: 1.433106780052185
Validation loss: 2.0257232496815343

Epoch: 6| Step: 13
Training loss: 0.7623958587646484
Validation loss: 2.084501479261665

Epoch: 418| Step: 0
Training loss: 1.1949877738952637
Validation loss: 2.0682049079607894

Epoch: 6| Step: 1
Training loss: 1.3904322385787964
Validation loss: 2.0927368415299283

Epoch: 6| Step: 2
Training loss: 1.4615726470947266
Validation loss: 2.0937420886049987

Epoch: 6| Step: 3
Training loss: 1.4392645359039307
Validation loss: 2.0569483246854556

Epoch: 6| Step: 4
Training loss: 1.456092357635498
Validation loss: 2.084982587445167

Epoch: 6| Step: 5
Training loss: 1.7065476179122925
Validation loss: 2.098413731462212

Epoch: 6| Step: 6
Training loss: 1.2954015731811523
Validation loss: 2.0696377510665567

Epoch: 6| Step: 7
Training loss: 1.7457969188690186
Validation loss: 2.0548641809853176

Epoch: 6| Step: 8
Training loss: 0.9364503622055054
Validation loss: 2.0687713699956096

Epoch: 6| Step: 9
Training loss: 1.718339204788208
Validation loss: 2.0302132509088002

Epoch: 6| Step: 10
Training loss: 1.6313704252243042
Validation loss: 2.0665922100825975

Epoch: 6| Step: 11
Training loss: 1.3293485641479492
Validation loss: 2.09090224260925

Epoch: 6| Step: 12
Training loss: 2.1310110092163086
Validation loss: 2.052559688527097

Epoch: 6| Step: 13
Training loss: 2.0526232719421387
Validation loss: 2.0483731121145268

Epoch: 419| Step: 0
Training loss: 1.627374529838562
Validation loss: 2.0886539079809703

Epoch: 6| Step: 1
Training loss: 1.717777132987976
Validation loss: 2.083708345249135

Epoch: 6| Step: 2
Training loss: 1.3169281482696533
Validation loss: 2.053357652438584

Epoch: 6| Step: 3
Training loss: 1.4492878913879395
Validation loss: 2.064311864555523

Epoch: 6| Step: 4
Training loss: 1.1457122564315796
Validation loss: 2.0644816339656873

Epoch: 6| Step: 5
Training loss: 0.9185913801193237
Validation loss: 2.0565451627136557

Epoch: 6| Step: 6
Training loss: 1.5988221168518066
Validation loss: 2.057751988851896

Epoch: 6| Step: 7
Training loss: 2.271695375442505
Validation loss: 2.077305655325613

Epoch: 6| Step: 8
Training loss: 1.3099051713943481
Validation loss: 2.0810904284959197

Epoch: 6| Step: 9
Training loss: 1.6792714595794678
Validation loss: 2.0848966926656742

Epoch: 6| Step: 10
Training loss: 2.133446216583252
Validation loss: 2.0437711708007322

Epoch: 6| Step: 11
Training loss: 1.5637433528900146
Validation loss: 2.0440626016227146

Epoch: 6| Step: 12
Training loss: 1.3236708641052246
Validation loss: 2.0951575771454842

Epoch: 6| Step: 13
Training loss: 1.3928866386413574
Validation loss: 2.059256056303619

Epoch: 420| Step: 0
Training loss: 1.1414604187011719
Validation loss: 2.0352720047837947

Epoch: 6| Step: 1
Training loss: 1.3602919578552246
Validation loss: 2.065489625418058

Epoch: 6| Step: 2
Training loss: 1.378828763961792
Validation loss: 2.0921162456594486

Epoch: 6| Step: 3
Training loss: 1.9501512050628662
Validation loss: 2.1026362219164447

Epoch: 6| Step: 4
Training loss: 1.2384288311004639
Validation loss: 2.083490352476797

Epoch: 6| Step: 5
Training loss: 1.6135480403900146
Validation loss: 2.055598262817629

Epoch: 6| Step: 6
Training loss: 2.1226539611816406
Validation loss: 2.0481499318153626

Epoch: 6| Step: 7
Training loss: 1.5032670497894287
Validation loss: 2.0791070743273665

Epoch: 6| Step: 8
Training loss: 2.7081191539764404
Validation loss: 2.0494905479492678

Epoch: 6| Step: 9
Training loss: 1.5707831382751465
Validation loss: 2.0715674713093746

Epoch: 6| Step: 10
Training loss: 0.713041365146637
Validation loss: 2.071666638056437

Epoch: 6| Step: 11
Training loss: 0.969106912612915
Validation loss: 2.0570973170700895

Epoch: 6| Step: 12
Training loss: 1.6196153163909912
Validation loss: 2.0681195054002988

Epoch: 6| Step: 13
Training loss: 1.397847056388855
Validation loss: 2.0850244196512366

Epoch: 421| Step: 0
Training loss: 1.0241676568984985
Validation loss: 2.071078541458294

Epoch: 6| Step: 1
Training loss: 1.7180330753326416
Validation loss: 2.088838734934407

Epoch: 6| Step: 2
Training loss: 1.4890066385269165
Validation loss: 2.133322021012665

Epoch: 6| Step: 3
Training loss: 1.8213109970092773
Validation loss: 2.0967137249567176

Epoch: 6| Step: 4
Training loss: 1.2452062368392944
Validation loss: 2.125430505762818

Epoch: 6| Step: 5
Training loss: 1.4570519924163818
Validation loss: 2.0937105891525105

Epoch: 6| Step: 6
Training loss: 1.4423418045043945
Validation loss: 2.1173786104366346

Epoch: 6| Step: 7
Training loss: 1.3970311880111694
Validation loss: 2.1199468643434587

Epoch: 6| Step: 8
Training loss: 1.8302435874938965
Validation loss: 2.0842653448863695

Epoch: 6| Step: 9
Training loss: 1.2891430854797363
Validation loss: 2.06224912212741

Epoch: 6| Step: 10
Training loss: 1.8886864185333252
Validation loss: 2.0859090820435555

Epoch: 6| Step: 11
Training loss: 1.9569556713104248
Validation loss: 2.0464049385439966

Epoch: 6| Step: 12
Training loss: 1.5625865459442139
Validation loss: 2.0692106946822135

Epoch: 6| Step: 13
Training loss: 1.0475343465805054
Validation loss: 2.067803623855755

Epoch: 422| Step: 0
Training loss: 1.0127007961273193
Validation loss: 2.0259544464849655

Epoch: 6| Step: 1
Training loss: 1.1366240978240967
Validation loss: 2.0554825003429125

Epoch: 6| Step: 2
Training loss: 1.1091835498809814
Validation loss: 2.085383476749543

Epoch: 6| Step: 3
Training loss: 1.049851417541504
Validation loss: 2.056999406506938

Epoch: 6| Step: 4
Training loss: 2.053823471069336
Validation loss: 2.02750119855327

Epoch: 6| Step: 5
Training loss: 1.9025604724884033
Validation loss: 2.0652930915996595

Epoch: 6| Step: 6
Training loss: 1.6318589448928833
Validation loss: 2.072816853882164

Epoch: 6| Step: 7
Training loss: 1.7198021411895752
Validation loss: 2.0856092258166243

Epoch: 6| Step: 8
Training loss: 1.4304029941558838
Validation loss: 2.077734298603509

Epoch: 6| Step: 9
Training loss: 1.6111977100372314
Validation loss: 2.1124116169509066

Epoch: 6| Step: 10
Training loss: 1.4096193313598633
Validation loss: 2.1124963645012147

Epoch: 6| Step: 11
Training loss: 1.6496330499649048
Validation loss: 2.0758018775652816

Epoch: 6| Step: 12
Training loss: 1.3415944576263428
Validation loss: 2.091879689565269

Epoch: 6| Step: 13
Training loss: 2.747943639755249
Validation loss: 2.07807897239603

Epoch: 423| Step: 0
Training loss: 1.073910117149353
Validation loss: 2.086874218397243

Epoch: 6| Step: 1
Training loss: 1.7048779726028442
Validation loss: 2.0532225729316793

Epoch: 6| Step: 2
Training loss: 1.2019749879837036
Validation loss: 2.044698529346015

Epoch: 6| Step: 3
Training loss: 1.0769933462142944
Validation loss: 2.059430947867773

Epoch: 6| Step: 4
Training loss: 2.0569007396698
Validation loss: 2.074507954300091

Epoch: 6| Step: 5
Training loss: 2.1463165283203125
Validation loss: 2.1221443837688816

Epoch: 6| Step: 6
Training loss: 1.3253107070922852
Validation loss: 2.04324536426093

Epoch: 6| Step: 7
Training loss: 1.8074800968170166
Validation loss: 2.0772153357023835

Epoch: 6| Step: 8
Training loss: 1.044295310974121
Validation loss: 2.038986526509767

Epoch: 6| Step: 9
Training loss: 2.081712484359741
Validation loss: 2.08004746642164

Epoch: 6| Step: 10
Training loss: 1.5615043640136719
Validation loss: 2.0778196409184444

Epoch: 6| Step: 11
Training loss: 1.7375125885009766
Validation loss: 2.0880337428021174

Epoch: 6| Step: 12
Training loss: 1.0636098384857178
Validation loss: 2.077972376218406

Epoch: 6| Step: 13
Training loss: 1.623168706893921
Validation loss: 2.038423522826164

Epoch: 424| Step: 0
Training loss: 1.6900906562805176
Validation loss: 2.0663315698664677

Epoch: 6| Step: 1
Training loss: 0.5564438104629517
Validation loss: 2.092383825650779

Epoch: 6| Step: 2
Training loss: 1.9862791299819946
Validation loss: 2.05015096997702

Epoch: 6| Step: 3
Training loss: 1.8090966939926147
Validation loss: 2.093990404118774

Epoch: 6| Step: 4
Training loss: 1.1629068851470947
Validation loss: 2.0782767072800667

Epoch: 6| Step: 5
Training loss: 1.857709527015686
Validation loss: 2.0846467159127675

Epoch: 6| Step: 6
Training loss: 1.4787921905517578
Validation loss: 2.077719831979403

Epoch: 6| Step: 7
Training loss: 1.838234305381775
Validation loss: 2.01602533940346

Epoch: 6| Step: 8
Training loss: 1.1270782947540283
Validation loss: 2.0759935071391444

Epoch: 6| Step: 9
Training loss: 1.4142253398895264
Validation loss: 2.0561425391063897

Epoch: 6| Step: 10
Training loss: 1.6601749658584595
Validation loss: 2.066149850045481

Epoch: 6| Step: 11
Training loss: 1.8429756164550781
Validation loss: 2.0482949697843162

Epoch: 6| Step: 12
Training loss: 1.374875545501709
Validation loss: 2.03377277364013

Epoch: 6| Step: 13
Training loss: 0.9588819146156311
Validation loss: 2.1000481228674612

Epoch: 425| Step: 0
Training loss: 1.343127965927124
Validation loss: 2.063150090555991

Epoch: 6| Step: 1
Training loss: 2.394632339477539
Validation loss: 2.043121817291424

Epoch: 6| Step: 2
Training loss: 1.7263516187667847
Validation loss: 2.096550133920485

Epoch: 6| Step: 3
Training loss: 1.9212841987609863
Validation loss: 2.070950769609021

Epoch: 6| Step: 4
Training loss: 1.6531953811645508
Validation loss: 2.0966226682868054

Epoch: 6| Step: 5
Training loss: 1.404707431793213
Validation loss: 2.0260627026199014

Epoch: 6| Step: 6
Training loss: 1.035231590270996
Validation loss: 2.0846408695302983

Epoch: 6| Step: 7
Training loss: 1.734420657157898
Validation loss: 2.0802422031279533

Epoch: 6| Step: 8
Training loss: 0.9769635200500488
Validation loss: 2.0976903002749205

Epoch: 6| Step: 9
Training loss: 1.7472810745239258
Validation loss: 2.0643318032705658

Epoch: 6| Step: 10
Training loss: 1.0878783464431763
Validation loss: 2.104261707234126

Epoch: 6| Step: 11
Training loss: 1.1733465194702148
Validation loss: 2.0579194484218473

Epoch: 6| Step: 12
Training loss: 1.698018193244934
Validation loss: 2.091203725466164

Epoch: 6| Step: 13
Training loss: 1.3552839756011963
Validation loss: 2.0542656631879908

Epoch: 426| Step: 0
Training loss: 1.506091833114624
Validation loss: 2.0405440458687405

Epoch: 6| Step: 1
Training loss: 1.0626590251922607
Validation loss: 2.05681973631664

Epoch: 6| Step: 2
Training loss: 1.047859787940979
Validation loss: 2.04679819204474

Epoch: 6| Step: 3
Training loss: 1.7346640825271606
Validation loss: 2.076691565975066

Epoch: 6| Step: 4
Training loss: 1.7850216627120972
Validation loss: 2.033604427050519

Epoch: 6| Step: 5
Training loss: 1.6243292093276978
Validation loss: 2.0607972862899944

Epoch: 6| Step: 6
Training loss: 1.238939642906189
Validation loss: 2.055171153878653

Epoch: 6| Step: 7
Training loss: 2.493730068206787
Validation loss: 2.021380069435284

Epoch: 6| Step: 8
Training loss: 1.3194917440414429
Validation loss: 2.0601517000506

Epoch: 6| Step: 9
Training loss: 2.0518763065338135
Validation loss: 2.049440186510804

Epoch: 6| Step: 10
Training loss: 0.9022929668426514
Validation loss: 2.055308820098959

Epoch: 6| Step: 11
Training loss: 1.6292202472686768
Validation loss: 2.0671575761610463

Epoch: 6| Step: 12
Training loss: 1.587181806564331
Validation loss: 2.052784337792345

Epoch: 6| Step: 13
Training loss: 1.3256309032440186
Validation loss: 2.0724717378616333

Epoch: 427| Step: 0
Training loss: 1.2224504947662354
Validation loss: 2.0877975468994467

Epoch: 6| Step: 1
Training loss: 1.2906501293182373
Validation loss: 2.0699919295567337

Epoch: 6| Step: 2
Training loss: 1.3496835231781006
Validation loss: 2.0732166497938094

Epoch: 6| Step: 3
Training loss: 1.157098650932312
Validation loss: 2.0892555559835126

Epoch: 6| Step: 4
Training loss: 1.4596445560455322
Validation loss: 2.1470652805861605

Epoch: 6| Step: 5
Training loss: 1.099543809890747
Validation loss: 2.1053456170584566

Epoch: 6| Step: 6
Training loss: 1.3408759832382202
Validation loss: 2.108157624480545

Epoch: 6| Step: 7
Training loss: 2.073880910873413
Validation loss: 2.059762849602648

Epoch: 6| Step: 8
Training loss: 1.8947906494140625
Validation loss: 2.112990854888834

Epoch: 6| Step: 9
Training loss: 2.4428911209106445
Validation loss: 2.0841323227010746

Epoch: 6| Step: 10
Training loss: 1.505615472793579
Validation loss: 2.124506159495282

Epoch: 6| Step: 11
Training loss: 1.4796836376190186
Validation loss: 2.0912047586133404

Epoch: 6| Step: 12
Training loss: 1.4751256704330444
Validation loss: 2.108393297400526

Epoch: 6| Step: 13
Training loss: 1.6398675441741943
Validation loss: 2.051591323268029

Epoch: 428| Step: 0
Training loss: 1.186628818511963
Validation loss: 2.0615647813325286

Epoch: 6| Step: 1
Training loss: 1.4738792181015015
Validation loss: 2.0659105957195325

Epoch: 6| Step: 2
Training loss: 2.016923666000366
Validation loss: 2.0296124078894175

Epoch: 6| Step: 3
Training loss: 1.9549590349197388
Validation loss: 2.080329224627505

Epoch: 6| Step: 4
Training loss: 1.3830485343933105
Validation loss: 2.0455101369529642

Epoch: 6| Step: 5
Training loss: 1.7611854076385498
Validation loss: 2.079046706999502

Epoch: 6| Step: 6
Training loss: 0.8998783826828003
Validation loss: 2.0410675874320408

Epoch: 6| Step: 7
Training loss: 1.0576026439666748
Validation loss: 2.014252888259067

Epoch: 6| Step: 8
Training loss: 1.4452236890792847
Validation loss: 2.0682584483136415

Epoch: 6| Step: 9
Training loss: 1.4968546628952026
Validation loss: 2.03300654631789

Epoch: 6| Step: 10
Training loss: 1.1718230247497559
Validation loss: 2.04890073755736

Epoch: 6| Step: 11
Training loss: 1.7121679782867432
Validation loss: 2.0776536131417878

Epoch: 6| Step: 12
Training loss: 1.497251033782959
Validation loss: 2.0612739465569936

Epoch: 6| Step: 13
Training loss: 2.676198720932007
Validation loss: 2.1017910306171705

Epoch: 429| Step: 0
Training loss: 1.686601161956787
Validation loss: 2.0192113730215255

Epoch: 6| Step: 1
Training loss: 1.2661492824554443
Validation loss: 2.1005232180318525

Epoch: 6| Step: 2
Training loss: 1.9586354494094849
Validation loss: 2.0854595476581204

Epoch: 6| Step: 3
Training loss: 1.6360678672790527
Validation loss: 2.0947688651341263

Epoch: 6| Step: 4
Training loss: 1.101428508758545
Validation loss: 2.109086731428741

Epoch: 6| Step: 5
Training loss: 2.3345282077789307
Validation loss: 2.075254868435603

Epoch: 6| Step: 6
Training loss: 1.5332279205322266
Validation loss: 2.0946296876476658

Epoch: 6| Step: 7
Training loss: 1.2363777160644531
Validation loss: 2.0751219744323404

Epoch: 6| Step: 8
Training loss: 1.4983646869659424
Validation loss: 2.1555303886372554

Epoch: 6| Step: 9
Training loss: 1.5057076215744019
Validation loss: 2.065520956952085

Epoch: 6| Step: 10
Training loss: 0.9968329071998596
Validation loss: 2.0803106010601087

Epoch: 6| Step: 11
Training loss: 0.8898274302482605
Validation loss: 2.0768346555771364

Epoch: 6| Step: 12
Training loss: 1.5344805717468262
Validation loss: 2.040147460916991

Epoch: 6| Step: 13
Training loss: 1.9198379516601562
Validation loss: 2.0543460602401407

Epoch: 430| Step: 0
Training loss: 1.663305640220642
Validation loss: 2.0586778822765557

Epoch: 6| Step: 1
Training loss: 1.8902393579483032
Validation loss: 2.029779482913274

Epoch: 6| Step: 2
Training loss: 1.2338557243347168
Validation loss: 2.0856834047584125

Epoch: 6| Step: 3
Training loss: 1.8850975036621094
Validation loss: 2.0808078422341296

Epoch: 6| Step: 4
Training loss: 1.2368260622024536
Validation loss: 2.0572181568350842

Epoch: 6| Step: 5
Training loss: 1.823371171951294
Validation loss: 2.0706007711348997

Epoch: 6| Step: 6
Training loss: 1.435581922531128
Validation loss: 2.0534384994096655

Epoch: 6| Step: 7
Training loss: 1.4497945308685303
Validation loss: 2.049424627775787

Epoch: 6| Step: 8
Training loss: 1.2716760635375977
Validation loss: 2.054477499377343

Epoch: 6| Step: 9
Training loss: 1.1574718952178955
Validation loss: 2.045623117877591

Epoch: 6| Step: 10
Training loss: 2.4436187744140625
Validation loss: 2.117027603169923

Epoch: 6| Step: 11
Training loss: 0.7570207715034485
Validation loss: 2.0696621633345083

Epoch: 6| Step: 12
Training loss: 1.4494476318359375
Validation loss: 2.0834125024016186

Epoch: 6| Step: 13
Training loss: 1.14516019821167
Validation loss: 2.12170639986633

Epoch: 431| Step: 0
Training loss: 1.6395525932312012
Validation loss: 2.088881072177682

Epoch: 6| Step: 1
Training loss: 2.0641870498657227
Validation loss: 2.1157728215699554

Epoch: 6| Step: 2
Training loss: 1.3899576663970947
Validation loss: 2.144405021462389

Epoch: 6| Step: 3
Training loss: 2.0981547832489014
Validation loss: 2.149087166273466

Epoch: 6| Step: 4
Training loss: 1.135539174079895
Validation loss: 2.149317140220314

Epoch: 6| Step: 5
Training loss: 1.5982609987258911
Validation loss: 2.155067243883687

Epoch: 6| Step: 6
Training loss: 1.7471212148666382
Validation loss: 2.150853576198701

Epoch: 6| Step: 7
Training loss: 1.89176607131958
Validation loss: 2.1465854542229765

Epoch: 6| Step: 8
Training loss: 1.1324788331985474
Validation loss: 2.1304674199832383

Epoch: 6| Step: 9
Training loss: 1.3135809898376465
Validation loss: 2.1196881776214926

Epoch: 6| Step: 10
Training loss: 1.6958328485488892
Validation loss: 2.0672822101141817

Epoch: 6| Step: 11
Training loss: 1.1257787942886353
Validation loss: 2.077134323376481

Epoch: 6| Step: 12
Training loss: 1.6254900693893433
Validation loss: 2.0301276945298716

Epoch: 6| Step: 13
Training loss: 1.0789542198181152
Validation loss: 2.0737783678116335

Epoch: 432| Step: 0
Training loss: 0.8850087523460388
Validation loss: 2.08012911581224

Epoch: 6| Step: 1
Training loss: 2.037675380706787
Validation loss: 2.0441981489940355

Epoch: 6| Step: 2
Training loss: 1.4766006469726562
Validation loss: 2.06410034753943

Epoch: 6| Step: 3
Training loss: 1.432072639465332
Validation loss: 2.020651489175776

Epoch: 6| Step: 4
Training loss: 1.5873193740844727
Validation loss: 2.0102782659633185

Epoch: 6| Step: 5
Training loss: 2.0840258598327637
Validation loss: 2.0554470246837986

Epoch: 6| Step: 6
Training loss: 0.9780845642089844
Validation loss: 2.0221254838410245

Epoch: 6| Step: 7
Training loss: 1.8666423559188843
Validation loss: 2.0272488876055648

Epoch: 6| Step: 8
Training loss: 2.0772387981414795
Validation loss: 2.0643432396714405

Epoch: 6| Step: 9
Training loss: 1.526118278503418
Validation loss: 2.058400538659865

Epoch: 6| Step: 10
Training loss: 0.8476341366767883
Validation loss: 2.080018474209693

Epoch: 6| Step: 11
Training loss: 1.6549873352050781
Validation loss: 2.0803942398358415

Epoch: 6| Step: 12
Training loss: 1.1594794988632202
Validation loss: 2.086241841316223

Epoch: 6| Step: 13
Training loss: 1.3481413125991821
Validation loss: 2.0445557948081725

Epoch: 433| Step: 0
Training loss: 1.265289306640625
Validation loss: 2.0439244213924614

Epoch: 6| Step: 1
Training loss: 1.1772527694702148
Validation loss: 2.073957766256025

Epoch: 6| Step: 2
Training loss: 2.1196582317352295
Validation loss: 2.0603880164443806

Epoch: 6| Step: 3
Training loss: 2.1584014892578125
Validation loss: 2.055385935691095

Epoch: 6| Step: 4
Training loss: 1.751042366027832
Validation loss: 2.1320654089732836

Epoch: 6| Step: 5
Training loss: 0.7782806158065796
Validation loss: 2.098835490083182

Epoch: 6| Step: 6
Training loss: 1.356162428855896
Validation loss: 2.1008421131359634

Epoch: 6| Step: 7
Training loss: 1.3707056045532227
Validation loss: 2.0773772719085857

Epoch: 6| Step: 8
Training loss: 1.507741928100586
Validation loss: 2.0793741710724367

Epoch: 6| Step: 9
Training loss: 1.1653110980987549
Validation loss: 2.101969520250956

Epoch: 6| Step: 10
Training loss: 1.6815500259399414
Validation loss: 2.084298764505694

Epoch: 6| Step: 11
Training loss: 1.7697813510894775
Validation loss: 2.0955160035881946

Epoch: 6| Step: 12
Training loss: 1.2453300952911377
Validation loss: 2.0610356228325957

Epoch: 6| Step: 13
Training loss: 2.114720582962036
Validation loss: 2.0647931278392835

Epoch: 434| Step: 0
Training loss: 2.080347776412964
Validation loss: 2.0160027793658677

Epoch: 6| Step: 1
Training loss: 1.7023181915283203
Validation loss: 2.0852250899038007

Epoch: 6| Step: 2
Training loss: 1.8481582403182983
Validation loss: 2.048817821728286

Epoch: 6| Step: 3
Training loss: 1.6873705387115479
Validation loss: 2.060901016317388

Epoch: 6| Step: 4
Training loss: 1.158247470855713
Validation loss: 2.0179403725490777

Epoch: 6| Step: 5
Training loss: 1.8995349407196045
Validation loss: 2.067347682932372

Epoch: 6| Step: 6
Training loss: 1.1431316137313843
Validation loss: 2.0381185521361647

Epoch: 6| Step: 7
Training loss: 1.1554371118545532
Validation loss: 2.0613250373512186

Epoch: 6| Step: 8
Training loss: 1.3442877531051636
Validation loss: 2.0249176076663438

Epoch: 6| Step: 9
Training loss: 1.4484103918075562
Validation loss: 2.053867613115618

Epoch: 6| Step: 10
Training loss: 1.6754080057144165
Validation loss: 2.0519450659392984

Epoch: 6| Step: 11
Training loss: 1.0928077697753906
Validation loss: 2.0851557318882277

Epoch: 6| Step: 12
Training loss: 1.4802827835083008
Validation loss: 2.103608218572473

Epoch: 6| Step: 13
Training loss: 1.0732083320617676
Validation loss: 2.0961782458007976

Epoch: 435| Step: 0
Training loss: 1.0898840427398682
Validation loss: 2.070899176341231

Epoch: 6| Step: 1
Training loss: 1.4977213144302368
Validation loss: 2.0610134191410516

Epoch: 6| Step: 2
Training loss: 1.1121615171432495
Validation loss: 2.0766787708446546

Epoch: 6| Step: 3
Training loss: 1.2181624174118042
Validation loss: 2.0760856443835842

Epoch: 6| Step: 4
Training loss: 2.02803897857666
Validation loss: 2.0820582771813996

Epoch: 6| Step: 5
Training loss: 2.661588191986084
Validation loss: 2.067037950279892

Epoch: 6| Step: 6
Training loss: 1.2781827449798584
Validation loss: 2.079214762615901

Epoch: 6| Step: 7
Training loss: 1.6675230264663696
Validation loss: 2.062870911372605

Epoch: 6| Step: 8
Training loss: 1.2167632579803467
Validation loss: 2.0774507240582536

Epoch: 6| Step: 9
Training loss: 1.3807129859924316
Validation loss: 2.04319840861905

Epoch: 6| Step: 10
Training loss: 1.5668714046478271
Validation loss: 2.0665883659034647

Epoch: 6| Step: 11
Training loss: 1.9041866064071655
Validation loss: 2.0511348901256437

Epoch: 6| Step: 12
Training loss: 0.9383002519607544
Validation loss: 2.037839512671194

Epoch: 6| Step: 13
Training loss: 1.7615383863449097
Validation loss: 2.079708489038611

Epoch: 436| Step: 0
Training loss: 1.1656410694122314
Validation loss: 2.0774452596582393

Epoch: 6| Step: 1
Training loss: 1.5502901077270508
Validation loss: 2.0525580849698795

Epoch: 6| Step: 2
Training loss: 1.5227653980255127
Validation loss: 2.0907383785452893

Epoch: 6| Step: 3
Training loss: 1.6159688234329224
Validation loss: 2.06066793651991

Epoch: 6| Step: 4
Training loss: 1.303685188293457
Validation loss: 2.011309166108408

Epoch: 6| Step: 5
Training loss: 1.8916683197021484
Validation loss: 2.033384123156148

Epoch: 6| Step: 6
Training loss: 1.4951624870300293
Validation loss: 2.060104191944163

Epoch: 6| Step: 7
Training loss: 2.04384708404541
Validation loss: 2.049455012044599

Epoch: 6| Step: 8
Training loss: 1.0399917364120483
Validation loss: 2.077414768998341

Epoch: 6| Step: 9
Training loss: 1.2061285972595215
Validation loss: 2.041668344569463

Epoch: 6| Step: 10
Training loss: 1.1015241146087646
Validation loss: 2.0746661591273483

Epoch: 6| Step: 11
Training loss: 1.4426606893539429
Validation loss: 2.0488292735110045

Epoch: 6| Step: 12
Training loss: 1.9143952131271362
Validation loss: 2.0715935153345906

Epoch: 6| Step: 13
Training loss: 1.4775736331939697
Validation loss: 2.0672921621671287

Epoch: 437| Step: 0
Training loss: 1.1709342002868652
Validation loss: 2.090167144293426

Epoch: 6| Step: 1
Training loss: 1.4094069004058838
Validation loss: 2.0923927009746595

Epoch: 6| Step: 2
Training loss: 1.856949806213379
Validation loss: 2.076199846882974

Epoch: 6| Step: 3
Training loss: 1.0354293584823608
Validation loss: 2.094962691748014

Epoch: 6| Step: 4
Training loss: 1.4773361682891846
Validation loss: 2.1069047809928976

Epoch: 6| Step: 5
Training loss: 1.1050801277160645
Validation loss: 2.077827017794373

Epoch: 6| Step: 6
Training loss: 1.6226425170898438
Validation loss: 2.100236015935098

Epoch: 6| Step: 7
Training loss: 1.3388062715530396
Validation loss: 2.075560862018216

Epoch: 6| Step: 8
Training loss: 1.5553078651428223
Validation loss: 2.077080270295502

Epoch: 6| Step: 9
Training loss: 1.466782569885254
Validation loss: 2.0923178913772746

Epoch: 6| Step: 10
Training loss: 1.6872308254241943
Validation loss: 2.0817585734910864

Epoch: 6| Step: 11
Training loss: 1.4090938568115234
Validation loss: 2.0690184921346684

Epoch: 6| Step: 12
Training loss: 1.4782159328460693
Validation loss: 2.041550628600582

Epoch: 6| Step: 13
Training loss: 1.8009978532791138
Validation loss: 2.0150867867213424

Epoch: 438| Step: 0
Training loss: 1.959822416305542
Validation loss: 2.041781597239997

Epoch: 6| Step: 1
Training loss: 0.7554954886436462
Validation loss: 2.0369937278891124

Epoch: 6| Step: 2
Training loss: 1.6402192115783691
Validation loss: 2.0682053796706663

Epoch: 6| Step: 3
Training loss: 2.1722240447998047
Validation loss: 2.0736323300228325

Epoch: 6| Step: 4
Training loss: 1.6713247299194336
Validation loss: 2.058534924701978

Epoch: 6| Step: 5
Training loss: 1.584019660949707
Validation loss: 2.074722582294095

Epoch: 6| Step: 6
Training loss: 1.1278061866760254
Validation loss: 2.0472990325702134

Epoch: 6| Step: 7
Training loss: 1.5284192562103271
Validation loss: 2.0503857135772705

Epoch: 6| Step: 8
Training loss: 1.078955888748169
Validation loss: 2.090147700361026

Epoch: 6| Step: 9
Training loss: 1.9706906080245972
Validation loss: 2.0777208933266262

Epoch: 6| Step: 10
Training loss: 1.5722875595092773
Validation loss: 2.0654201456295547

Epoch: 6| Step: 11
Training loss: 1.3964356184005737
Validation loss: 2.0539896052370787

Epoch: 6| Step: 12
Training loss: 1.2700515985488892
Validation loss: 2.0513710296282204

Epoch: 6| Step: 13
Training loss: 1.2019978761672974
Validation loss: 2.0603744291490123

Epoch: 439| Step: 0
Training loss: 1.624068021774292
Validation loss: 2.0742092594023673

Epoch: 6| Step: 1
Training loss: 1.701120138168335
Validation loss: 2.109026062873102

Epoch: 6| Step: 2
Training loss: 1.7565891742706299
Validation loss: 2.0815393335075787

Epoch: 6| Step: 3
Training loss: 1.208925485610962
Validation loss: 2.08820830622027

Epoch: 6| Step: 4
Training loss: 1.0495269298553467
Validation loss: 2.059078630580697

Epoch: 6| Step: 5
Training loss: 1.281665563583374
Validation loss: 2.0637876051728443

Epoch: 6| Step: 6
Training loss: 2.023547649383545
Validation loss: 2.074050239337388

Epoch: 6| Step: 7
Training loss: 1.2190314531326294
Validation loss: 2.1111911830081733

Epoch: 6| Step: 8
Training loss: 1.6882845163345337
Validation loss: 2.058822229344358

Epoch: 6| Step: 9
Training loss: 1.6033093929290771
Validation loss: 2.0819825562097694

Epoch: 6| Step: 10
Training loss: 0.8563644289970398
Validation loss: 2.1312194101272093

Epoch: 6| Step: 11
Training loss: 1.324774980545044
Validation loss: 2.0697838285917878

Epoch: 6| Step: 12
Training loss: 1.6802581548690796
Validation loss: 2.1005986582848335

Epoch: 6| Step: 13
Training loss: 2.0229310989379883
Validation loss: 2.0981674373790784

Epoch: 440| Step: 0
Training loss: 1.7456352710723877
Validation loss: 2.082208600095523

Epoch: 6| Step: 1
Training loss: 1.6999564170837402
Validation loss: 2.0688186102015997

Epoch: 6| Step: 2
Training loss: 1.024582862854004
Validation loss: 2.037623920748311

Epoch: 6| Step: 3
Training loss: 1.432761311531067
Validation loss: 2.099531260869836

Epoch: 6| Step: 4
Training loss: 1.4576094150543213
Validation loss: 2.0452859940067416

Epoch: 6| Step: 5
Training loss: 1.0539560317993164
Validation loss: 2.059147755304972

Epoch: 6| Step: 6
Training loss: 1.6825414896011353
Validation loss: 2.0791741519845943

Epoch: 6| Step: 7
Training loss: 2.0245697498321533
Validation loss: 2.0617775891416814

Epoch: 6| Step: 8
Training loss: 1.0728240013122559
Validation loss: 2.0520119218416113

Epoch: 6| Step: 9
Training loss: 0.834724485874176
Validation loss: 2.0598834381308606

Epoch: 6| Step: 10
Training loss: 1.7867844104766846
Validation loss: 2.076714143958143

Epoch: 6| Step: 11
Training loss: 1.732244849205017
Validation loss: 2.097920192185269

Epoch: 6| Step: 12
Training loss: 2.1093311309814453
Validation loss: 2.0868234557490193

Epoch: 6| Step: 13
Training loss: 1.1222079992294312
Validation loss: 2.089515309179983

Epoch: 441| Step: 0
Training loss: 2.1197681427001953
Validation loss: 2.041985382315933

Epoch: 6| Step: 1
Training loss: 1.236459732055664
Validation loss: 2.0625663290741625

Epoch: 6| Step: 2
Training loss: 1.861234188079834
Validation loss: 2.0649816861716648

Epoch: 6| Step: 3
Training loss: 1.58098304271698
Validation loss: 2.0825995860561246

Epoch: 6| Step: 4
Training loss: 0.9936724901199341
Validation loss: 2.09654406321946

Epoch: 6| Step: 5
Training loss: 1.004078984260559
Validation loss: 2.0871098067170832

Epoch: 6| Step: 6
Training loss: 1.412092924118042
Validation loss: 2.006113221568446

Epoch: 6| Step: 7
Training loss: 1.547224998474121
Validation loss: 2.0423024008350987

Epoch: 6| Step: 8
Training loss: 1.600407600402832
Validation loss: 2.012644560106339

Epoch: 6| Step: 9
Training loss: 1.6558144092559814
Validation loss: 2.0855132290112075

Epoch: 6| Step: 10
Training loss: 1.3406355381011963
Validation loss: 2.0265303862992154

Epoch: 6| Step: 11
Training loss: 1.2919151782989502
Validation loss: 2.0541144199268793

Epoch: 6| Step: 12
Training loss: 1.6038402318954468
Validation loss: 2.0910848033043647

Epoch: 6| Step: 13
Training loss: 1.8871086835861206
Validation loss: 2.0578163990410427

Epoch: 442| Step: 0
Training loss: 1.155759334564209
Validation loss: 2.0800722901539137

Epoch: 6| Step: 1
Training loss: 1.5156669616699219
Validation loss: 2.1030698155844085

Epoch: 6| Step: 2
Training loss: 1.218886375427246
Validation loss: 2.0502945530799126

Epoch: 6| Step: 3
Training loss: 1.224366545677185
Validation loss: 2.090204294009875

Epoch: 6| Step: 4
Training loss: 1.1669870615005493
Validation loss: 2.092061504240959

Epoch: 6| Step: 5
Training loss: 1.9862909317016602
Validation loss: 2.0728174409558697

Epoch: 6| Step: 6
Training loss: 2.140772819519043
Validation loss: 2.0464455978844756

Epoch: 6| Step: 7
Training loss: 1.5932435989379883
Validation loss: 2.096546342295985

Epoch: 6| Step: 8
Training loss: 1.6364080905914307
Validation loss: 2.053857200889177

Epoch: 6| Step: 9
Training loss: 1.6740148067474365
Validation loss: 2.0747696174088346

Epoch: 6| Step: 10
Training loss: 1.0190610885620117
Validation loss: 2.062216413918362

Epoch: 6| Step: 11
Training loss: 0.8064749240875244
Validation loss: 2.0308585295113186

Epoch: 6| Step: 12
Training loss: 1.6348907947540283
Validation loss: 2.0427060434895177

Epoch: 6| Step: 13
Training loss: 1.7203369140625
Validation loss: 2.0454067542988765

Epoch: 443| Step: 0
Training loss: 1.5353546142578125
Validation loss: 2.0416147196164696

Epoch: 6| Step: 1
Training loss: 1.7381037473678589
Validation loss: 2.0274008845770233

Epoch: 6| Step: 2
Training loss: 0.9512608051300049
Validation loss: 2.0514446919964207

Epoch: 6| Step: 3
Training loss: 1.1659727096557617
Validation loss: 2.0582605715720885

Epoch: 6| Step: 4
Training loss: 1.825181484222412
Validation loss: 2.041189883344917

Epoch: 6| Step: 5
Training loss: 1.8799551725387573
Validation loss: 2.074594828390306

Epoch: 6| Step: 6
Training loss: 1.6133809089660645
Validation loss: 2.0766746433832313

Epoch: 6| Step: 7
Training loss: 1.8053257465362549
Validation loss: 2.0847027673516223

Epoch: 6| Step: 8
Training loss: 1.2267119884490967
Validation loss: 2.063166892656716

Epoch: 6| Step: 9
Training loss: 1.2579002380371094
Validation loss: 2.066296787672145

Epoch: 6| Step: 10
Training loss: 1.2340033054351807
Validation loss: 2.0780869735184537

Epoch: 6| Step: 11
Training loss: 2.0116777420043945
Validation loss: 2.1206844980998705

Epoch: 6| Step: 12
Training loss: 1.4993007183074951
Validation loss: 2.1229539327724005

Epoch: 6| Step: 13
Training loss: 1.087647795677185
Validation loss: 2.118377771428836

Epoch: 444| Step: 0
Training loss: 1.0615522861480713
Validation loss: 2.1102603430389077

Epoch: 6| Step: 1
Training loss: 1.534590721130371
Validation loss: 2.0887017749970958

Epoch: 6| Step: 2
Training loss: 1.5618913173675537
Validation loss: 2.1048022265075357

Epoch: 6| Step: 3
Training loss: 1.1821346282958984
Validation loss: 2.053348884787611

Epoch: 6| Step: 4
Training loss: 1.694038987159729
Validation loss: 2.0523903087903093

Epoch: 6| Step: 5
Training loss: 1.8110997676849365
Validation loss: 2.053255732341479

Epoch: 6| Step: 6
Training loss: 1.4471673965454102
Validation loss: 2.078984961714796

Epoch: 6| Step: 7
Training loss: 1.7336552143096924
Validation loss: 2.062207030993636

Epoch: 6| Step: 8
Training loss: 1.989160180091858
Validation loss: 2.043993660198745

Epoch: 6| Step: 9
Training loss: 1.1337876319885254
Validation loss: 2.0511896879442277

Epoch: 6| Step: 10
Training loss: 1.3974530696868896
Validation loss: 2.0702132512164373

Epoch: 6| Step: 11
Training loss: 1.4535207748413086
Validation loss: 2.04511317001876

Epoch: 6| Step: 12
Training loss: 1.370255470275879
Validation loss: 2.0380307218079925

Epoch: 6| Step: 13
Training loss: 1.2763121128082275
Validation loss: 2.0093743878026165

Epoch: 445| Step: 0
Training loss: 1.6307003498077393
Validation loss: 2.0660378574043192

Epoch: 6| Step: 1
Training loss: 1.7517848014831543
Validation loss: 2.063312097262311

Epoch: 6| Step: 2
Training loss: 1.8230085372924805
Validation loss: 2.048138669742051

Epoch: 6| Step: 3
Training loss: 0.8335040807723999
Validation loss: 2.0583177869037916

Epoch: 6| Step: 4
Training loss: 0.9390256404876709
Validation loss: 2.0070666343935075

Epoch: 6| Step: 5
Training loss: 1.9641231298446655
Validation loss: 2.074967947057498

Epoch: 6| Step: 6
Training loss: 1.870380163192749
Validation loss: 2.0360088015115387

Epoch: 6| Step: 7
Training loss: 0.7880318760871887
Validation loss: 2.0938439676838536

Epoch: 6| Step: 8
Training loss: 1.8559553623199463
Validation loss: 2.0825967327240975

Epoch: 6| Step: 9
Training loss: 1.4020434617996216
Validation loss: 2.065250935093049

Epoch: 6| Step: 10
Training loss: 1.5559169054031372
Validation loss: 2.0619712747553343

Epoch: 6| Step: 11
Training loss: 1.2978650331497192
Validation loss: 2.0934545609258834

Epoch: 6| Step: 12
Training loss: 1.5700290203094482
Validation loss: 2.0537996561296525

Epoch: 6| Step: 13
Training loss: 1.34256911277771
Validation loss: 2.0660339581069125

Epoch: 446| Step: 0
Training loss: 1.185678243637085
Validation loss: 2.081706775132046

Epoch: 6| Step: 1
Training loss: 2.4240410327911377
Validation loss: 2.116909016845047

Epoch: 6| Step: 2
Training loss: 1.570678949356079
Validation loss: 2.0764189945754183

Epoch: 6| Step: 3
Training loss: 1.8143372535705566
Validation loss: 2.084644051008327

Epoch: 6| Step: 4
Training loss: 1.2168512344360352
Validation loss: 2.0599033653095202

Epoch: 6| Step: 5
Training loss: 1.6963748931884766
Validation loss: 2.0693088398184827

Epoch: 6| Step: 6
Training loss: 1.845057725906372
Validation loss: 2.095278929638606

Epoch: 6| Step: 7
Training loss: 1.0950394868850708
Validation loss: 2.0773157099241852

Epoch: 6| Step: 8
Training loss: 1.0744874477386475
Validation loss: 2.0631953900860203

Epoch: 6| Step: 9
Training loss: 0.8571503758430481
Validation loss: 2.0722732364490466

Epoch: 6| Step: 10
Training loss: 1.5444309711456299
Validation loss: 2.026392632915128

Epoch: 6| Step: 11
Training loss: 1.7312147617340088
Validation loss: 2.043386865687627

Epoch: 6| Step: 12
Training loss: 1.2988197803497314
Validation loss: 2.042015319229454

Epoch: 6| Step: 13
Training loss: 1.6490626335144043
Validation loss: 2.0296738391281455

Epoch: 447| Step: 0
Training loss: 1.812684416770935
Validation loss: 2.0577100938366306

Epoch: 6| Step: 1
Training loss: 1.0205597877502441
Validation loss: 2.0677739343335553

Epoch: 6| Step: 2
Training loss: 0.9441399574279785
Validation loss: 2.0735213474560807

Epoch: 6| Step: 3
Training loss: 1.452005386352539
Validation loss: 2.069276249536904

Epoch: 6| Step: 4
Training loss: 1.4126718044281006
Validation loss: 2.068223299518708

Epoch: 6| Step: 5
Training loss: 1.7118990421295166
Validation loss: 2.076895526660386

Epoch: 6| Step: 6
Training loss: 1.6645071506500244
Validation loss: 2.0537612258747058

Epoch: 6| Step: 7
Training loss: 0.8306396007537842
Validation loss: 2.0791539351145425

Epoch: 6| Step: 8
Training loss: 1.2635831832885742
Validation loss: 2.082474740602637

Epoch: 6| Step: 9
Training loss: 2.1370420455932617
Validation loss: 2.097061272590391

Epoch: 6| Step: 10
Training loss: 2.4470772743225098
Validation loss: 2.046284152615455

Epoch: 6| Step: 11
Training loss: 1.6093850135803223
Validation loss: 2.0644673583328084

Epoch: 6| Step: 12
Training loss: 0.8448998928070068
Validation loss: 2.0431350841317126

Epoch: 6| Step: 13
Training loss: 1.5120844841003418
Validation loss: 2.0618243294377483

Epoch: 448| Step: 0
Training loss: 1.8566186428070068
Validation loss: 2.059139085072343

Epoch: 6| Step: 1
Training loss: 1.1526421308517456
Validation loss: 2.021194383662234

Epoch: 6| Step: 2
Training loss: 1.524409294128418
Validation loss: 2.068362856423983

Epoch: 6| Step: 3
Training loss: 1.0887503623962402
Validation loss: 2.0368138615803053

Epoch: 6| Step: 4
Training loss: 1.3166611194610596
Validation loss: 2.035847290869682

Epoch: 6| Step: 5
Training loss: 1.9457206726074219
Validation loss: 2.051676529710011

Epoch: 6| Step: 6
Training loss: 1.1204166412353516
Validation loss: 2.0646230764286493

Epoch: 6| Step: 7
Training loss: 1.8845986127853394
Validation loss: 2.0660110519778345

Epoch: 6| Step: 8
Training loss: 1.6955013275146484
Validation loss: 2.0491512001201673

Epoch: 6| Step: 9
Training loss: 1.7199432849884033
Validation loss: 2.0427360047576246

Epoch: 6| Step: 10
Training loss: 1.5989830493927002
Validation loss: 2.067689959720899

Epoch: 6| Step: 11
Training loss: 1.039031744003296
Validation loss: 2.0591976540063017

Epoch: 6| Step: 12
Training loss: 1.3102401494979858
Validation loss: 2.096093031667894

Epoch: 6| Step: 13
Training loss: 1.4290788173675537
Validation loss: 2.0507963472797024

Epoch: 449| Step: 0
Training loss: 1.450576901435852
Validation loss: 2.060558094773241

Epoch: 6| Step: 1
Training loss: 1.2202799320220947
Validation loss: 2.038314670644781

Epoch: 6| Step: 2
Training loss: 1.9971108436584473
Validation loss: 2.0890243232891126

Epoch: 6| Step: 3
Training loss: 1.4827077388763428
Validation loss: 2.07763083006746

Epoch: 6| Step: 4
Training loss: 1.1456282138824463
Validation loss: 2.077787850492744

Epoch: 6| Step: 5
Training loss: 1.0173299312591553
Validation loss: 2.036601540862873

Epoch: 6| Step: 6
Training loss: 1.6278640031814575
Validation loss: 2.067578290098457

Epoch: 6| Step: 7
Training loss: 1.2966701984405518
Validation loss: 2.0654467177647415

Epoch: 6| Step: 8
Training loss: 1.4115138053894043
Validation loss: 2.0478950187724125

Epoch: 6| Step: 9
Training loss: 0.9398512840270996
Validation loss: 2.035873249012937

Epoch: 6| Step: 10
Training loss: 1.4451504945755005
Validation loss: 2.0582650669159426

Epoch: 6| Step: 11
Training loss: 2.044719934463501
Validation loss: 2.0912321293225853

Epoch: 6| Step: 12
Training loss: 1.7937893867492676
Validation loss: 2.080555477449971

Epoch: 6| Step: 13
Training loss: 2.10268497467041
Validation loss: 2.0606289781549925

Epoch: 450| Step: 0
Training loss: 1.8900887966156006
Validation loss: 2.096015179029075

Epoch: 6| Step: 1
Training loss: 0.8749829530715942
Validation loss: 2.0612628947022142

Epoch: 6| Step: 2
Training loss: 1.3414016962051392
Validation loss: 2.0528310601429274

Epoch: 6| Step: 3
Training loss: 1.8679083585739136
Validation loss: 2.04817053451333

Epoch: 6| Step: 4
Training loss: 1.6913561820983887
Validation loss: 2.095425728828676

Epoch: 6| Step: 5
Training loss: 1.3787996768951416
Validation loss: 2.092260019753569

Epoch: 6| Step: 6
Training loss: 1.1087723970413208
Validation loss: 2.027739704296153

Epoch: 6| Step: 7
Training loss: 1.1329357624053955
Validation loss: 2.111868714773527

Epoch: 6| Step: 8
Training loss: 0.713740348815918
Validation loss: 2.047317515137375

Epoch: 6| Step: 9
Training loss: 1.4410984516143799
Validation loss: 2.058956285958649

Epoch: 6| Step: 10
Training loss: 2.268913984298706
Validation loss: 2.058218417629119

Epoch: 6| Step: 11
Training loss: 1.503777027130127
Validation loss: 2.0207993266403035

Epoch: 6| Step: 12
Training loss: 2.0324907302856445
Validation loss: 2.0967943681183683

Epoch: 6| Step: 13
Training loss: 1.1432080268859863
Validation loss: 2.0851798185738186

Epoch: 451| Step: 0
Training loss: 1.319826364517212
Validation loss: 2.106999619032747

Epoch: 6| Step: 1
Training loss: 1.888389229774475
Validation loss: 2.114135819096719

Epoch: 6| Step: 2
Training loss: 0.8970271348953247
Validation loss: 2.0943592235606205

Epoch: 6| Step: 3
Training loss: 1.657817006111145
Validation loss: 2.096038600449921

Epoch: 6| Step: 4
Training loss: 1.4206211566925049
Validation loss: 2.074971709200131

Epoch: 6| Step: 5
Training loss: 1.6496195793151855
Validation loss: 2.1273329642511185

Epoch: 6| Step: 6
Training loss: 1.0435161590576172
Validation loss: 2.082093346503473

Epoch: 6| Step: 7
Training loss: 1.3036868572235107
Validation loss: 2.086835918887969

Epoch: 6| Step: 8
Training loss: 1.9323267936706543
Validation loss: 2.0884733456437305

Epoch: 6| Step: 9
Training loss: 1.3204069137573242
Validation loss: 2.068290302830358

Epoch: 6| Step: 10
Training loss: 1.7670069932937622
Validation loss: 2.0666297981815953

Epoch: 6| Step: 11
Training loss: 1.1464492082595825
Validation loss: 2.0492776824582006

Epoch: 6| Step: 12
Training loss: 1.8067803382873535
Validation loss: 2.0294828620008243

Epoch: 6| Step: 13
Training loss: 0.6653874516487122
Validation loss: 2.0679569167475544

Epoch: 452| Step: 0
Training loss: 2.300410270690918
Validation loss: 2.0756388043844574

Epoch: 6| Step: 1
Training loss: 1.4360268115997314
Validation loss: 2.0382758789165045

Epoch: 6| Step: 2
Training loss: 1.2144519090652466
Validation loss: 2.055849057371898

Epoch: 6| Step: 3
Training loss: 1.7610080242156982
Validation loss: 2.054935298940187

Epoch: 6| Step: 4
Training loss: 1.4124972820281982
Validation loss: 2.0779957104754705

Epoch: 6| Step: 5
Training loss: 1.2734458446502686
Validation loss: 2.039226539673344

Epoch: 6| Step: 6
Training loss: 1.1352808475494385
Validation loss: 2.0461591930799585

Epoch: 6| Step: 7
Training loss: 1.06719172000885
Validation loss: 2.021108733710422

Epoch: 6| Step: 8
Training loss: 1.0412484407424927
Validation loss: 2.056506062066683

Epoch: 6| Step: 9
Training loss: 1.146117925643921
Validation loss: 2.0731087397503596

Epoch: 6| Step: 10
Training loss: 1.0509542226791382
Validation loss: 2.0106024152489117

Epoch: 6| Step: 11
Training loss: 1.6741516590118408
Validation loss: 2.092277488400859

Epoch: 6| Step: 12
Training loss: 1.6110819578170776
Validation loss: 2.074451543951547

Epoch: 6| Step: 13
Training loss: 2.492973804473877
Validation loss: 2.0684849651910926

Epoch: 453| Step: 0
Training loss: 1.2649654150009155
Validation loss: 2.026305760106733

Epoch: 6| Step: 1
Training loss: 0.768290638923645
Validation loss: 2.0165245507353093

Epoch: 6| Step: 2
Training loss: 1.1401174068450928
Validation loss: 2.0310446036759244

Epoch: 6| Step: 3
Training loss: 0.9605323672294617
Validation loss: 2.058700138522733

Epoch: 6| Step: 4
Training loss: 1.7001545429229736
Validation loss: 2.0833796480650544

Epoch: 6| Step: 5
Training loss: 1.9424846172332764
Validation loss: 2.0506379091611473

Epoch: 6| Step: 6
Training loss: 1.2080609798431396
Validation loss: 2.121071607835831

Epoch: 6| Step: 7
Training loss: 1.8104240894317627
Validation loss: 2.0403000885440457

Epoch: 6| Step: 8
Training loss: 2.147038459777832
Validation loss: 2.074810956114082

Epoch: 6| Step: 9
Training loss: 1.0620535612106323
Validation loss: 2.0692250395333893

Epoch: 6| Step: 10
Training loss: 1.86141836643219
Validation loss: 2.0527748882129626

Epoch: 6| Step: 11
Training loss: 1.1793898344039917
Validation loss: 2.06818066617494

Epoch: 6| Step: 12
Training loss: 1.8419520854949951
Validation loss: 2.1020730605689426

Epoch: 6| Step: 13
Training loss: 1.1097350120544434
Validation loss: 2.1120622516960226

Epoch: 454| Step: 0
Training loss: 1.4587810039520264
Validation loss: 2.0466532271395446

Epoch: 6| Step: 1
Training loss: 1.0688894987106323
Validation loss: 2.03338728027959

Epoch: 6| Step: 2
Training loss: 1.692842960357666
Validation loss: 2.070125165806022

Epoch: 6| Step: 3
Training loss: 1.356134057044983
Validation loss: 2.0694920401419363

Epoch: 6| Step: 4
Training loss: 1.311950922012329
Validation loss: 2.0664117797728507

Epoch: 6| Step: 5
Training loss: 1.6185669898986816
Validation loss: 2.073028108125092

Epoch: 6| Step: 6
Training loss: 1.640934944152832
Validation loss: 2.0384834376714562

Epoch: 6| Step: 7
Training loss: 1.1862878799438477
Validation loss: 2.047721405183115

Epoch: 6| Step: 8
Training loss: 1.455622673034668
Validation loss: 2.0222194938249487

Epoch: 6| Step: 9
Training loss: 1.4878253936767578
Validation loss: 2.077499274284609

Epoch: 6| Step: 10
Training loss: 1.6528104543685913
Validation loss: 2.0264646032805085

Epoch: 6| Step: 11
Training loss: 1.730811595916748
Validation loss: 2.058312257130941

Epoch: 6| Step: 12
Training loss: 0.8938460350036621
Validation loss: 2.0211951655726277

Epoch: 6| Step: 13
Training loss: 1.8783323764801025
Validation loss: 2.046127989727964

Epoch: 455| Step: 0
Training loss: 1.0066360235214233
Validation loss: 2.0299509891899685

Epoch: 6| Step: 1
Training loss: 1.5995248556137085
Validation loss: 2.000568312983359

Epoch: 6| Step: 2
Training loss: 1.635780692100525
Validation loss: 2.0799946131244784

Epoch: 6| Step: 3
Training loss: 1.328956961631775
Validation loss: 2.0457306767022736

Epoch: 6| Step: 4
Training loss: 1.2239755392074585
Validation loss: 2.037640235757315

Epoch: 6| Step: 5
Training loss: 1.055915355682373
Validation loss: 2.089031625819463

Epoch: 6| Step: 6
Training loss: 1.579512357711792
Validation loss: 2.0356616666240077

Epoch: 6| Step: 7
Training loss: 2.5511302947998047
Validation loss: 2.032607832262593

Epoch: 6| Step: 8
Training loss: 1.3760640621185303
Validation loss: 2.0410290559132895

Epoch: 6| Step: 9
Training loss: 1.834038257598877
Validation loss: 2.0445366777399534

Epoch: 6| Step: 10
Training loss: 1.6475532054901123
Validation loss: 2.0293601353963218

Epoch: 6| Step: 11
Training loss: 0.8843425512313843
Validation loss: 2.0489274865837506

Epoch: 6| Step: 12
Training loss: 1.6302387714385986
Validation loss: 2.054745566460394

Epoch: 6| Step: 13
Training loss: 1.2265515327453613
Validation loss: 2.0703183348460863

Epoch: 456| Step: 0
Training loss: 0.7831348180770874
Validation loss: 2.0750299346062446

Epoch: 6| Step: 1
Training loss: 1.6015393733978271
Validation loss: 2.0762912047806608

Epoch: 6| Step: 2
Training loss: 2.0995168685913086
Validation loss: 2.1141833284849763

Epoch: 6| Step: 3
Training loss: 0.8110161423683167
Validation loss: 2.076027598432315

Epoch: 6| Step: 4
Training loss: 1.7721152305603027
Validation loss: 2.1039577966095298

Epoch: 6| Step: 5
Training loss: 1.4824192523956299
Validation loss: 2.0750473442898003

Epoch: 6| Step: 6
Training loss: 1.5841350555419922
Validation loss: 2.0631896193309496

Epoch: 6| Step: 7
Training loss: 1.0688234567642212
Validation loss: 2.0449507031389462

Epoch: 6| Step: 8
Training loss: 1.7703673839569092
Validation loss: 2.0840697724332093

Epoch: 6| Step: 9
Training loss: 1.1157166957855225
Validation loss: 2.041992541282408

Epoch: 6| Step: 10
Training loss: 1.761783480644226
Validation loss: 2.0653903920163392

Epoch: 6| Step: 11
Training loss: 1.8392934799194336
Validation loss: 2.0311068129795853

Epoch: 6| Step: 12
Training loss: 1.571845293045044
Validation loss: 2.0520948107524584

Epoch: 6| Step: 13
Training loss: 1.0338417291641235
Validation loss: 2.062842745934763

Epoch: 457| Step: 0
Training loss: 0.7599696516990662
Validation loss: 2.0313079805784326

Epoch: 6| Step: 1
Training loss: 1.6648114919662476
Validation loss: 2.077398646262384

Epoch: 6| Step: 2
Training loss: 1.5474056005477905
Validation loss: 2.0373641803700435

Epoch: 6| Step: 3
Training loss: 0.7861202359199524
Validation loss: 2.014173533326836

Epoch: 6| Step: 4
Training loss: 1.1000128984451294
Validation loss: 2.0301499007850565

Epoch: 6| Step: 5
Training loss: 1.7286179065704346
Validation loss: 2.043146769205729

Epoch: 6| Step: 6
Training loss: 2.241360664367676
Validation loss: 2.054410811393492

Epoch: 6| Step: 7
Training loss: 1.8676371574401855
Validation loss: 2.0542981496421238

Epoch: 6| Step: 8
Training loss: 1.3656233549118042
Validation loss: 2.07193325924617

Epoch: 6| Step: 9
Training loss: 1.7428321838378906
Validation loss: 2.0856320576001237

Epoch: 6| Step: 10
Training loss: 1.33543062210083
Validation loss: 2.057857805682767

Epoch: 6| Step: 11
Training loss: 1.7401514053344727
Validation loss: 2.064865796796737

Epoch: 6| Step: 12
Training loss: 1.1307134628295898
Validation loss: 2.048571918600349

Epoch: 6| Step: 13
Training loss: 1.4670149087905884
Validation loss: 2.078039694857854

Epoch: 458| Step: 0
Training loss: 0.8739990592002869
Validation loss: 2.064290297928677

Epoch: 6| Step: 1
Training loss: 1.6387829780578613
Validation loss: 2.050789738214144

Epoch: 6| Step: 2
Training loss: 1.677719235420227
Validation loss: 2.080430676860194

Epoch: 6| Step: 3
Training loss: 1.6110379695892334
Validation loss: 2.0291068246287685

Epoch: 6| Step: 4
Training loss: 1.1174442768096924
Validation loss: 2.037343011107496

Epoch: 6| Step: 5
Training loss: 1.6727299690246582
Validation loss: 2.036839326222738

Epoch: 6| Step: 6
Training loss: 1.8438228368759155
Validation loss: 2.0416139171969507

Epoch: 6| Step: 7
Training loss: 1.2359650135040283
Validation loss: 2.0708923532116796

Epoch: 6| Step: 8
Training loss: 1.53466796875
Validation loss: 2.0405499448058424

Epoch: 6| Step: 9
Training loss: 0.8252192139625549
Validation loss: 2.049388201005997

Epoch: 6| Step: 10
Training loss: 1.5852603912353516
Validation loss: 2.0568160869741954

Epoch: 6| Step: 11
Training loss: 2.076416492462158
Validation loss: 2.02109016910676

Epoch: 6| Step: 12
Training loss: 1.3565937280654907
Validation loss: 2.0831944532291864

Epoch: 6| Step: 13
Training loss: 0.9708434343338013
Validation loss: 2.0711607984317246

Epoch: 459| Step: 0
Training loss: 1.7859939336776733
Validation loss: 2.093682514723911

Epoch: 6| Step: 1
Training loss: 1.7260494232177734
Validation loss: 2.0397283146458287

Epoch: 6| Step: 2
Training loss: 1.0336878299713135
Validation loss: 2.070723557984957

Epoch: 6| Step: 3
Training loss: 1.1761541366577148
Validation loss: 2.092669798481849

Epoch: 6| Step: 4
Training loss: 1.140172004699707
Validation loss: 2.0472855157749628

Epoch: 6| Step: 5
Training loss: 1.4341046810150146
Validation loss: 2.0490417583014375

Epoch: 6| Step: 6
Training loss: 1.4315097332000732
Validation loss: 2.0519367341072328

Epoch: 6| Step: 7
Training loss: 1.8343218564987183
Validation loss: 2.0600556776087773

Epoch: 6| Step: 8
Training loss: 1.7784698009490967
Validation loss: 2.0999655646662556

Epoch: 6| Step: 9
Training loss: 1.4280548095703125
Validation loss: 2.0670495789538146

Epoch: 6| Step: 10
Training loss: 1.7612841129302979
Validation loss: 2.070756589212725

Epoch: 6| Step: 11
Training loss: 1.0901269912719727
Validation loss: 2.046965532405402

Epoch: 6| Step: 12
Training loss: 1.2763547897338867
Validation loss: 2.0583464484060965

Epoch: 6| Step: 13
Training loss: 1.5023776292800903
Validation loss: 2.0445671876271567

Epoch: 460| Step: 0
Training loss: 1.1831722259521484
Validation loss: 2.0651304132194928

Epoch: 6| Step: 1
Training loss: 1.5809977054595947
Validation loss: 2.0140628532696794

Epoch: 6| Step: 2
Training loss: 1.5706948041915894
Validation loss: 2.0849559819826515

Epoch: 6| Step: 3
Training loss: 1.072389841079712
Validation loss: 2.0415556943544777

Epoch: 6| Step: 4
Training loss: 1.21725332736969
Validation loss: 1.985141514449991

Epoch: 6| Step: 5
Training loss: 2.3060319423675537
Validation loss: 2.0201684018617034

Epoch: 6| Step: 6
Training loss: 1.496584415435791
Validation loss: 2.0499178055794007

Epoch: 6| Step: 7
Training loss: 1.2011122703552246
Validation loss: 2.076316870668883

Epoch: 6| Step: 8
Training loss: 2.0513720512390137
Validation loss: 2.0761753948785926

Epoch: 6| Step: 9
Training loss: 1.1780190467834473
Validation loss: 2.0347365025551087

Epoch: 6| Step: 10
Training loss: 1.156177043914795
Validation loss: 2.064742612582381

Epoch: 6| Step: 11
Training loss: 1.801379919052124
Validation loss: 2.043170359826857

Epoch: 6| Step: 12
Training loss: 1.2477102279663086
Validation loss: 2.0664384518900225

Epoch: 6| Step: 13
Training loss: 1.6359140872955322
Validation loss: 2.0691849365029285

Epoch: 461| Step: 0
Training loss: 1.2323191165924072
Validation loss: 2.049570140018258

Epoch: 6| Step: 1
Training loss: 1.5185550451278687
Validation loss: 2.052162798502112

Epoch: 6| Step: 2
Training loss: 1.2597181797027588
Validation loss: 2.0411963334647556

Epoch: 6| Step: 3
Training loss: 1.6483700275421143
Validation loss: 2.013513106171803

Epoch: 6| Step: 4
Training loss: 1.4288365840911865
Validation loss: 2.0554822670516146

Epoch: 6| Step: 5
Training loss: 2.2989230155944824
Validation loss: 2.0357709392424552

Epoch: 6| Step: 6
Training loss: 2.3522658348083496
Validation loss: 2.0905804429002988

Epoch: 6| Step: 7
Training loss: 1.1669481992721558
Validation loss: 2.0415686227942027

Epoch: 6| Step: 8
Training loss: 0.8971662521362305
Validation loss: 2.0475974890493576

Epoch: 6| Step: 9
Training loss: 1.3954403400421143
Validation loss: 2.0554528736299083

Epoch: 6| Step: 10
Training loss: 1.1599481105804443
Validation loss: 2.0588427551331057

Epoch: 6| Step: 11
Training loss: 1.7069882154464722
Validation loss: 2.0585559927007204

Epoch: 6| Step: 12
Training loss: 1.0705734491348267
Validation loss: 2.0672673320257537

Epoch: 6| Step: 13
Training loss: 1.5008140802383423
Validation loss: 2.0517901887175856

Epoch: 462| Step: 0
Training loss: 1.7800686359405518
Validation loss: 2.0551525392839984

Epoch: 6| Step: 1
Training loss: 2.080836057662964
Validation loss: 2.126693456403671

Epoch: 6| Step: 2
Training loss: 1.1451863050460815
Validation loss: 2.086864682935899

Epoch: 6| Step: 3
Training loss: 1.973862648010254
Validation loss: 2.0297882351824033

Epoch: 6| Step: 4
Training loss: 0.9416495561599731
Validation loss: 2.0212467024403233

Epoch: 6| Step: 5
Training loss: 1.1880570650100708
Validation loss: 2.0631458720853253

Epoch: 6| Step: 6
Training loss: 1.5011546611785889
Validation loss: 2.080206640305058

Epoch: 6| Step: 7
Training loss: 2.002224922180176
Validation loss: 2.049436278240655

Epoch: 6| Step: 8
Training loss: 0.8883742094039917
Validation loss: 2.1002709891206477

Epoch: 6| Step: 9
Training loss: 1.5767896175384521
Validation loss: 2.0726533474460727

Epoch: 6| Step: 10
Training loss: 1.210203766822815
Validation loss: 2.0395065943400064

Epoch: 6| Step: 11
Training loss: 1.2762658596038818
Validation loss: 2.098440986807628

Epoch: 6| Step: 12
Training loss: 1.25412917137146
Validation loss: 2.0418734832476546

Epoch: 6| Step: 13
Training loss: 1.8177157640457153
Validation loss: 2.034136350436877

Epoch: 463| Step: 0
Training loss: 1.6305556297302246
Validation loss: 2.002884370024486

Epoch: 6| Step: 1
Training loss: 0.8184124231338501
Validation loss: 2.0598470972430323

Epoch: 6| Step: 2
Training loss: 1.6978590488433838
Validation loss: 2.0106530881697133

Epoch: 6| Step: 3
Training loss: 1.9800221920013428
Validation loss: 2.0414303118182766

Epoch: 6| Step: 4
Training loss: 1.3119829893112183
Validation loss: 2.036539864796464

Epoch: 6| Step: 5
Training loss: 1.2690582275390625
Validation loss: 2.0742117281882995

Epoch: 6| Step: 6
Training loss: 1.6951937675476074
Validation loss: 2.033887509376772

Epoch: 6| Step: 7
Training loss: 1.5802011489868164
Validation loss: 2.0430935608443392

Epoch: 6| Step: 8
Training loss: 1.3215699195861816
Validation loss: 2.0491809165605934

Epoch: 6| Step: 9
Training loss: 1.3552898168563843
Validation loss: 2.058711765914835

Epoch: 6| Step: 10
Training loss: 1.0328457355499268
Validation loss: 2.091865820269431

Epoch: 6| Step: 11
Training loss: 1.7148455381393433
Validation loss: 2.0635144159358036

Epoch: 6| Step: 12
Training loss: 1.3953962326049805
Validation loss: 2.0917546236386864

Epoch: 6| Step: 13
Training loss: 1.381080150604248
Validation loss: 2.0888762807333343

Epoch: 464| Step: 0
Training loss: 1.542586326599121
Validation loss: 2.054403043562366

Epoch: 6| Step: 1
Training loss: 1.6100246906280518
Validation loss: 2.082071622212728

Epoch: 6| Step: 2
Training loss: 1.1347993612289429
Validation loss: 2.0892438004093785

Epoch: 6| Step: 3
Training loss: 1.3345918655395508
Validation loss: 2.0571526378713627

Epoch: 6| Step: 4
Training loss: 1.034510850906372
Validation loss: 2.0637968958065076

Epoch: 6| Step: 5
Training loss: 1.8043774366378784
Validation loss: 2.072518807585521

Epoch: 6| Step: 6
Training loss: 1.715259075164795
Validation loss: 2.04347990405175

Epoch: 6| Step: 7
Training loss: 1.7024962902069092
Validation loss: 2.084383446683166

Epoch: 6| Step: 8
Training loss: 1.6113684177398682
Validation loss: 2.0904431150805567

Epoch: 6| Step: 9
Training loss: 1.2247291803359985
Validation loss: 2.0816031912321686

Epoch: 6| Step: 10
Training loss: 1.3034549951553345
Validation loss: 2.0636643696856756

Epoch: 6| Step: 11
Training loss: 1.2019610404968262
Validation loss: 2.0321175231728503

Epoch: 6| Step: 12
Training loss: 0.9798775315284729
Validation loss: 2.084263095291712

Epoch: 6| Step: 13
Training loss: 2.1237924098968506
Validation loss: 2.0567819059536023

Epoch: 465| Step: 0
Training loss: 1.29327392578125
Validation loss: 2.0682424832415838

Epoch: 6| Step: 1
Training loss: 1.348867654800415
Validation loss: 1.9892878634955293

Epoch: 6| Step: 2
Training loss: 1.9209799766540527
Validation loss: 2.0506953475295857

Epoch: 6| Step: 3
Training loss: 1.8073776960372925
Validation loss: 2.039682562633227

Epoch: 6| Step: 4
Training loss: 2.5648932456970215
Validation loss: 2.0384865012220157

Epoch: 6| Step: 5
Training loss: 1.5747044086456299
Validation loss: 2.0725748923517044

Epoch: 6| Step: 6
Training loss: 0.9719766974449158
Validation loss: 2.0226929085229033

Epoch: 6| Step: 7
Training loss: 2.0724167823791504
Validation loss: 2.0551511754271803

Epoch: 6| Step: 8
Training loss: 1.2574489116668701
Validation loss: 2.015600953050839

Epoch: 6| Step: 9
Training loss: 0.7123428583145142
Validation loss: 2.058898530980592

Epoch: 6| Step: 10
Training loss: 0.7916371822357178
Validation loss: 2.0704615398119857

Epoch: 6| Step: 11
Training loss: 0.9803855419158936
Validation loss: 2.0718531608581543

Epoch: 6| Step: 12
Training loss: 1.325893759727478
Validation loss: 2.042837860763714

Epoch: 6| Step: 13
Training loss: 1.623895287513733
Validation loss: 2.059697174256848

Epoch: 466| Step: 0
Training loss: 1.4212658405303955
Validation loss: 2.0317699742573563

Epoch: 6| Step: 1
Training loss: 1.9133317470550537
Validation loss: 2.0295292638963267

Epoch: 6| Step: 2
Training loss: 1.717287540435791
Validation loss: 2.0872890308339107

Epoch: 6| Step: 3
Training loss: 1.5016350746154785
Validation loss: 2.1086679786764164

Epoch: 6| Step: 4
Training loss: 1.3890745639801025
Validation loss: 2.0769335992874636

Epoch: 6| Step: 5
Training loss: 1.8157658576965332
Validation loss: 2.0568762876654185

Epoch: 6| Step: 6
Training loss: 1.5728201866149902
Validation loss: 2.0158750844258133

Epoch: 6| Step: 7
Training loss: 1.619462490081787
Validation loss: 2.0516383263372604

Epoch: 6| Step: 8
Training loss: 1.54249906539917
Validation loss: 2.0808976311837473

Epoch: 6| Step: 9
Training loss: 1.270201563835144
Validation loss: 2.060169013597632

Epoch: 6| Step: 10
Training loss: 1.2046889066696167
Validation loss: 2.074280647821324

Epoch: 6| Step: 11
Training loss: 1.3073782920837402
Validation loss: 2.0702222649769118

Epoch: 6| Step: 12
Training loss: 1.0366133451461792
Validation loss: 2.139534206800563

Epoch: 6| Step: 13
Training loss: 0.4674399793148041
Validation loss: 2.0445359278750677

Epoch: 467| Step: 0
Training loss: 1.315227746963501
Validation loss: 2.0663279666695544

Epoch: 6| Step: 1
Training loss: 1.3515572547912598
Validation loss: 2.0486575698339813

Epoch: 6| Step: 2
Training loss: 1.7528831958770752
Validation loss: 2.0331381982372654

Epoch: 6| Step: 3
Training loss: 1.3628056049346924
Validation loss: 2.0389895541693575

Epoch: 6| Step: 4
Training loss: 1.8150732517242432
Validation loss: 2.0431130663041146

Epoch: 6| Step: 5
Training loss: 1.758171796798706
Validation loss: 2.0630254207118863

Epoch: 6| Step: 6
Training loss: 1.0043933391571045
Validation loss: 2.0550291256238054

Epoch: 6| Step: 7
Training loss: 1.403910517692566
Validation loss: 2.053304810677805

Epoch: 6| Step: 8
Training loss: 0.8577260971069336
Validation loss: 2.0960048091027046

Epoch: 6| Step: 9
Training loss: 1.9223320484161377
Validation loss: 2.021261820229151

Epoch: 6| Step: 10
Training loss: 1.0875248908996582
Validation loss: 2.0542094066578853

Epoch: 6| Step: 11
Training loss: 1.4198864698410034
Validation loss: 2.0681688849643995

Epoch: 6| Step: 12
Training loss: 1.9665087461471558
Validation loss: 2.053410096835065

Epoch: 6| Step: 13
Training loss: 1.4846409559249878
Validation loss: 2.058333771203154

Epoch: 468| Step: 0
Training loss: 1.297245740890503
Validation loss: 2.0582440527536536

Epoch: 6| Step: 1
Training loss: 1.7690002918243408
Validation loss: 2.029633024687408

Epoch: 6| Step: 2
Training loss: 1.3282639980316162
Validation loss: 2.0385893391024683

Epoch: 6| Step: 3
Training loss: 1.9471606016159058
Validation loss: 2.0229499545148624

Epoch: 6| Step: 4
Training loss: 1.4734108448028564
Validation loss: 2.022568371988112

Epoch: 6| Step: 5
Training loss: 1.2057074308395386
Validation loss: 2.0562490622202554

Epoch: 6| Step: 6
Training loss: 1.6382546424865723
Validation loss: 2.0561837996205976

Epoch: 6| Step: 7
Training loss: 1.2626925706863403
Validation loss: 1.9990373529413694

Epoch: 6| Step: 8
Training loss: 1.2017197608947754
Validation loss: 2.038141360846899

Epoch: 6| Step: 9
Training loss: 1.3674437999725342
Validation loss: 2.0413095233260945

Epoch: 6| Step: 10
Training loss: 1.3600834608078003
Validation loss: 2.12667788228681

Epoch: 6| Step: 11
Training loss: 1.2751790285110474
Validation loss: 2.0884978796846125

Epoch: 6| Step: 12
Training loss: 1.7528893947601318
Validation loss: 2.1114363362712245

Epoch: 6| Step: 13
Training loss: 1.308127522468567
Validation loss: 2.065281398834721

Epoch: 469| Step: 0
Training loss: 1.4536874294281006
Validation loss: 2.0543663258193643

Epoch: 6| Step: 1
Training loss: 1.9072552919387817
Validation loss: 2.068333004110603

Epoch: 6| Step: 2
Training loss: 1.8923760652542114
Validation loss: 2.096348424111643

Epoch: 6| Step: 3
Training loss: 1.4584741592407227
Validation loss: 2.0843499655364663

Epoch: 6| Step: 4
Training loss: 1.3816099166870117
Validation loss: 2.03348946314986

Epoch: 6| Step: 5
Training loss: 1.3247357606887817
Validation loss: 2.049652123963961

Epoch: 6| Step: 6
Training loss: 0.9356731176376343
Validation loss: 2.0749732845573017

Epoch: 6| Step: 7
Training loss: 1.2569894790649414
Validation loss: 2.006097173178068

Epoch: 6| Step: 8
Training loss: 1.9149413108825684
Validation loss: 2.0782397895730953

Epoch: 6| Step: 9
Training loss: 1.3129496574401855
Validation loss: 2.070060947889923

Epoch: 6| Step: 10
Training loss: 0.7384517788887024
Validation loss: 2.0201860909820883

Epoch: 6| Step: 11
Training loss: 1.4796960353851318
Validation loss: 2.0234594575820433

Epoch: 6| Step: 12
Training loss: 2.1032724380493164
Validation loss: 2.0519278305833057

Epoch: 6| Step: 13
Training loss: 0.9347696304321289
Validation loss: 2.0544372040738343

Epoch: 470| Step: 0
Training loss: 1.0243103504180908
Validation loss: 1.9961231600853704

Epoch: 6| Step: 1
Training loss: 1.3342788219451904
Validation loss: 2.056460113935573

Epoch: 6| Step: 2
Training loss: 1.1077053546905518
Validation loss: 2.0625037685517342

Epoch: 6| Step: 3
Training loss: 1.740003228187561
Validation loss: 2.084017030654415

Epoch: 6| Step: 4
Training loss: 1.490750789642334
Validation loss: 2.0703147201127905

Epoch: 6| Step: 5
Training loss: 1.633316993713379
Validation loss: 2.0191749757336033

Epoch: 6| Step: 6
Training loss: 1.0347261428833008
Validation loss: 2.0933469008373957

Epoch: 6| Step: 7
Training loss: 1.2160297632217407
Validation loss: 2.0301895808148127

Epoch: 6| Step: 8
Training loss: 1.3138519525527954
Validation loss: 2.018203386696436

Epoch: 6| Step: 9
Training loss: 2.2710351943969727
Validation loss: 2.0553995358046664

Epoch: 6| Step: 10
Training loss: 1.605316162109375
Validation loss: 2.0186325260387954

Epoch: 6| Step: 11
Training loss: 2.1411352157592773
Validation loss: 2.0590272949587916

Epoch: 6| Step: 12
Training loss: 1.3033554553985596
Validation loss: 2.0942533452023744

Epoch: 6| Step: 13
Training loss: 0.6540825963020325
Validation loss: 2.068214426758469

Epoch: 471| Step: 0
Training loss: 1.2926082611083984
Validation loss: 2.0450865478925806

Epoch: 6| Step: 1
Training loss: 1.7375723123550415
Validation loss: 2.0803395009809926

Epoch: 6| Step: 2
Training loss: 1.806440830230713
Validation loss: 2.058793934442664

Epoch: 6| Step: 3
Training loss: 1.0322664976119995
Validation loss: 2.0670098297057615

Epoch: 6| Step: 4
Training loss: 1.8764731884002686
Validation loss: 2.0767222450625513

Epoch: 6| Step: 5
Training loss: 1.3328899145126343
Validation loss: 2.0424484027329313

Epoch: 6| Step: 6
Training loss: 1.0465965270996094
Validation loss: 2.0736138256647254

Epoch: 6| Step: 7
Training loss: 0.990481972694397
Validation loss: 2.0389288381863664

Epoch: 6| Step: 8
Training loss: 1.1913821697235107
Validation loss: 2.0911750767820623

Epoch: 6| Step: 9
Training loss: 1.4770065546035767
Validation loss: 2.042755664035838

Epoch: 6| Step: 10
Training loss: 1.6556298732757568
Validation loss: 2.037577963644458

Epoch: 6| Step: 11
Training loss: 1.3901605606079102
Validation loss: 2.058879970222391

Epoch: 6| Step: 12
Training loss: 1.3933992385864258
Validation loss: 2.06796706363719

Epoch: 6| Step: 13
Training loss: 2.3215646743774414
Validation loss: 2.055595423585625

Epoch: 472| Step: 0
Training loss: 1.6065328121185303
Validation loss: 2.0482625897212694

Epoch: 6| Step: 1
Training loss: 1.5122987031936646
Validation loss: 2.007453289083255

Epoch: 6| Step: 2
Training loss: 1.6342567205429077
Validation loss: 2.033208618881882

Epoch: 6| Step: 3
Training loss: 1.7517529726028442
Validation loss: 2.0559229081676853

Epoch: 6| Step: 4
Training loss: 1.5544986724853516
Validation loss: 2.047261740571709

Epoch: 6| Step: 5
Training loss: 1.5342515707015991
Validation loss: 2.0739451428895355

Epoch: 6| Step: 6
Training loss: 1.7143115997314453
Validation loss: 2.0652985995815647

Epoch: 6| Step: 7
Training loss: 1.0517247915267944
Validation loss: 2.083916675659918

Epoch: 6| Step: 8
Training loss: 0.8258815407752991
Validation loss: 2.0716003153913762

Epoch: 6| Step: 9
Training loss: 0.9880388975143433
Validation loss: 2.0534587265342794

Epoch: 6| Step: 10
Training loss: 0.8471800088882446
Validation loss: 2.0691319024691017

Epoch: 6| Step: 11
Training loss: 1.7429336309432983
Validation loss: 2.0883569948134886

Epoch: 6| Step: 12
Training loss: 1.4937503337860107
Validation loss: 2.0461546451814714

Epoch: 6| Step: 13
Training loss: 2.328239917755127
Validation loss: 2.066984051017351

Epoch: 473| Step: 0
Training loss: 1.0884268283843994
Validation loss: 2.06078585245276

Epoch: 6| Step: 1
Training loss: 1.4411967992782593
Validation loss: 2.033381927397943

Epoch: 6| Step: 2
Training loss: 1.0822209119796753
Validation loss: 2.016021215787498

Epoch: 6| Step: 3
Training loss: 1.7048628330230713
Validation loss: 2.0396760330405286

Epoch: 6| Step: 4
Training loss: 1.5540498495101929
Validation loss: 2.010987881691225

Epoch: 6| Step: 5
Training loss: 1.2568947076797485
Validation loss: 2.0581866310488794

Epoch: 6| Step: 6
Training loss: 2.11600923538208
Validation loss: 2.052402368155859

Epoch: 6| Step: 7
Training loss: 1.4397029876708984
Validation loss: 2.023420592790009

Epoch: 6| Step: 8
Training loss: 1.0338225364685059
Validation loss: 2.050521230184904

Epoch: 6| Step: 9
Training loss: 1.54725980758667
Validation loss: 2.0278944533358336

Epoch: 6| Step: 10
Training loss: 1.7756292819976807
Validation loss: 2.068547607750021

Epoch: 6| Step: 11
Training loss: 1.3661823272705078
Validation loss: 2.0706066085446264

Epoch: 6| Step: 12
Training loss: 1.7311408519744873
Validation loss: 2.0459677198881745

Epoch: 6| Step: 13
Training loss: 0.9977807998657227
Validation loss: 2.0609555026536346

Epoch: 474| Step: 0
Training loss: 1.7866131067276
Validation loss: 2.030467123113653

Epoch: 6| Step: 1
Training loss: 0.5464292764663696
Validation loss: 2.0484696536935787

Epoch: 6| Step: 2
Training loss: 1.0498467683792114
Validation loss: 2.061170624148461

Epoch: 6| Step: 3
Training loss: 1.6433095932006836
Validation loss: 2.0236385842805267

Epoch: 6| Step: 4
Training loss: 1.1349915266036987
Validation loss: 2.069732094323763

Epoch: 6| Step: 5
Training loss: 1.4740608930587769
Validation loss: 2.0709663975623345

Epoch: 6| Step: 6
Training loss: 1.5148568153381348
Validation loss: 2.0394334613635974

Epoch: 6| Step: 7
Training loss: 1.9952290058135986
Validation loss: 2.0880601547097646

Epoch: 6| Step: 8
Training loss: 1.5400208234786987
Validation loss: 2.0362457485609156

Epoch: 6| Step: 9
Training loss: 1.4329274892807007
Validation loss: 2.034216874389238

Epoch: 6| Step: 10
Training loss: 1.0468754768371582
Validation loss: 2.053343980543075

Epoch: 6| Step: 11
Training loss: 1.4468188285827637
Validation loss: 2.0730183983361847

Epoch: 6| Step: 12
Training loss: 1.509985327720642
Validation loss: 2.044419386053598

Epoch: 6| Step: 13
Training loss: 1.9871147871017456
Validation loss: 2.0437100882171304

Epoch: 475| Step: 0
Training loss: 1.3896880149841309
Validation loss: 2.052848018625731

Epoch: 6| Step: 1
Training loss: 1.3797556161880493
Validation loss: 2.064132172574279

Epoch: 6| Step: 2
Training loss: 1.235323190689087
Validation loss: 2.042497888688118

Epoch: 6| Step: 3
Training loss: 1.846198558807373
Validation loss: 2.002791393187738

Epoch: 6| Step: 4
Training loss: 1.0266211032867432
Validation loss: 2.024034677013274

Epoch: 6| Step: 5
Training loss: 1.2781479358673096
Validation loss: 2.053035077228341

Epoch: 6| Step: 6
Training loss: 1.4424959421157837
Validation loss: 2.0560005685334564

Epoch: 6| Step: 7
Training loss: 1.258503794670105
Validation loss: 2.0794086687026487

Epoch: 6| Step: 8
Training loss: 1.7647781372070312
Validation loss: 2.03765965789877

Epoch: 6| Step: 9
Training loss: 1.5663340091705322
Validation loss: 2.068947220361361

Epoch: 6| Step: 10
Training loss: 1.240362286567688
Validation loss: 2.063480125960483

Epoch: 6| Step: 11
Training loss: 1.1964706182479858
Validation loss: 2.0383133401152906

Epoch: 6| Step: 12
Training loss: 1.2098582983016968
Validation loss: 2.051935654814525

Epoch: 6| Step: 13
Training loss: 2.0713844299316406
Validation loss: 2.045479343783471

Epoch: 476| Step: 0
Training loss: 0.9392061233520508
Validation loss: 2.0565236794051303

Epoch: 6| Step: 1
Training loss: 1.2686368227005005
Validation loss: 2.035905768794398

Epoch: 6| Step: 2
Training loss: 1.7309614419937134
Validation loss: 2.0361614714386644

Epoch: 6| Step: 3
Training loss: 1.5281568765640259
Validation loss: 2.057982817772896

Epoch: 6| Step: 4
Training loss: 1.368302583694458
Validation loss: 2.0446065946291854

Epoch: 6| Step: 5
Training loss: 1.0509313344955444
Validation loss: 2.0255403672495196

Epoch: 6| Step: 6
Training loss: 1.372178077697754
Validation loss: 2.000926561253045

Epoch: 6| Step: 7
Training loss: 1.8388848304748535
Validation loss: 2.032999061769055

Epoch: 6| Step: 8
Training loss: 1.3025578260421753
Validation loss: 2.0265098823014127

Epoch: 6| Step: 9
Training loss: 1.493105411529541
Validation loss: 2.100915216630505

Epoch: 6| Step: 10
Training loss: 1.2629773616790771
Validation loss: 2.0506769380261822

Epoch: 6| Step: 11
Training loss: 1.7655572891235352
Validation loss: 2.10381196647562

Epoch: 6| Step: 12
Training loss: 1.581915020942688
Validation loss: 2.094895693563646

Epoch: 6| Step: 13
Training loss: 1.7097148895263672
Validation loss: 2.0707501980566208

Epoch: 477| Step: 0
Training loss: 1.3287725448608398
Validation loss: 2.0811282383498324

Epoch: 6| Step: 1
Training loss: 0.8631445169448853
Validation loss: 2.08827910372006

Epoch: 6| Step: 2
Training loss: 0.8734410405158997
Validation loss: 2.04706129207406

Epoch: 6| Step: 3
Training loss: 1.6808357238769531
Validation loss: 2.0677175611578007

Epoch: 6| Step: 4
Training loss: 1.227632999420166
Validation loss: 2.0444823618858092

Epoch: 6| Step: 5
Training loss: 1.1988500356674194
Validation loss: 2.054531731913167

Epoch: 6| Step: 6
Training loss: 1.6475272178649902
Validation loss: 2.045923397105227

Epoch: 6| Step: 7
Training loss: 1.5956460237503052
Validation loss: 2.0777319849178357

Epoch: 6| Step: 8
Training loss: 1.8984493017196655
Validation loss: 2.0544689688631284

Epoch: 6| Step: 9
Training loss: 1.4059813022613525
Validation loss: 2.051652254596833

Epoch: 6| Step: 10
Training loss: 1.2338292598724365
Validation loss: 2.048054531056394

Epoch: 6| Step: 11
Training loss: 1.7891669273376465
Validation loss: 2.0096974834319083

Epoch: 6| Step: 12
Training loss: 1.6570918560028076
Validation loss: 2.046875943419754

Epoch: 6| Step: 13
Training loss: 1.204648494720459
Validation loss: 2.0753661842756372

Epoch: 478| Step: 0
Training loss: 2.558651924133301
Validation loss: 2.031131790530297

Epoch: 6| Step: 1
Training loss: 0.6145359873771667
Validation loss: 2.0696561413426555

Epoch: 6| Step: 2
Training loss: 1.1683993339538574
Validation loss: 2.0195742063624884

Epoch: 6| Step: 3
Training loss: 1.4414292573928833
Validation loss: 2.0951148745834187

Epoch: 6| Step: 4
Training loss: 1.790870189666748
Validation loss: 2.0353610515594482

Epoch: 6| Step: 5
Training loss: 1.3423490524291992
Validation loss: 2.0779443863899476

Epoch: 6| Step: 6
Training loss: 1.626354694366455
Validation loss: 2.0790036570641304

Epoch: 6| Step: 7
Training loss: 1.1581766605377197
Validation loss: 2.086748674351682

Epoch: 6| Step: 8
Training loss: 1.734748363494873
Validation loss: 2.0849711664261354

Epoch: 6| Step: 9
Training loss: 1.3375141620635986
Validation loss: 2.0846050990525113

Epoch: 6| Step: 10
Training loss: 1.1803346872329712
Validation loss: 2.0955558143636233

Epoch: 6| Step: 11
Training loss: 1.7846273183822632
Validation loss: 2.1072563535423687

Epoch: 6| Step: 12
Training loss: 1.3465418815612793
Validation loss: 2.0906697063035864

Epoch: 6| Step: 13
Training loss: 0.9965553283691406
Validation loss: 2.0670735272028113

Epoch: 479| Step: 0
Training loss: 1.8107560873031616
Validation loss: 2.0859344774676907

Epoch: 6| Step: 1
Training loss: 1.2024221420288086
Validation loss: 2.0691127648917575

Epoch: 6| Step: 2
Training loss: 2.0963809490203857
Validation loss: 2.095149124822309

Epoch: 6| Step: 3
Training loss: 1.1294962167739868
Validation loss: 2.0634518848952426

Epoch: 6| Step: 4
Training loss: 1.944258689880371
Validation loss: 2.070245122396818

Epoch: 6| Step: 5
Training loss: 1.0794662237167358
Validation loss: 2.031263583449907

Epoch: 6| Step: 6
Training loss: 1.2559537887573242
Validation loss: 2.034203924158568

Epoch: 6| Step: 7
Training loss: 0.8967758417129517
Validation loss: 2.0432622330163115

Epoch: 6| Step: 8
Training loss: 0.6345794200897217
Validation loss: 2.0617317281743532

Epoch: 6| Step: 9
Training loss: 1.5705196857452393
Validation loss: 2.040867123552548

Epoch: 6| Step: 10
Training loss: 0.8427456617355347
Validation loss: 2.0063375990877867

Epoch: 6| Step: 11
Training loss: 1.4875396490097046
Validation loss: 2.051658848280548

Epoch: 6| Step: 12
Training loss: 2.124688148498535
Validation loss: 2.0571203436902774

Epoch: 6| Step: 13
Training loss: 1.9488555192947388
Validation loss: 2.070545373424407

Epoch: 480| Step: 0
Training loss: 1.7199270725250244
Validation loss: 2.0230002941623813

Epoch: 6| Step: 1
Training loss: 2.1128268241882324
Validation loss: 2.0871269254274267

Epoch: 6| Step: 2
Training loss: 1.263211965560913
Validation loss: 2.0765857183805077

Epoch: 6| Step: 3
Training loss: 1.412174940109253
Validation loss: 2.1080530920336322

Epoch: 6| Step: 4
Training loss: 1.4218108654022217
Validation loss: 2.0559324064562396

Epoch: 6| Step: 5
Training loss: 1.494410753250122
Validation loss: 2.0363615584629837

Epoch: 6| Step: 6
Training loss: 1.8121507167816162
Validation loss: 2.034168012680546

Epoch: 6| Step: 7
Training loss: 1.2297722101211548
Validation loss: 2.049123269255443

Epoch: 6| Step: 8
Training loss: 0.8877289295196533
Validation loss: 2.0491525178314536

Epoch: 6| Step: 9
Training loss: 1.497912049293518
Validation loss: 2.0520033028817948

Epoch: 6| Step: 10
Training loss: 1.5296940803527832
Validation loss: 2.0577099925728253

Epoch: 6| Step: 11
Training loss: 1.3957645893096924
Validation loss: 2.0572675761356147

Epoch: 6| Step: 12
Training loss: 1.0591833591461182
Validation loss: 2.0126441870966265

Epoch: 6| Step: 13
Training loss: 1.0363316535949707
Validation loss: 2.0657067991072133

Epoch: 481| Step: 0
Training loss: 1.4346225261688232
Validation loss: 2.031795101781045

Epoch: 6| Step: 1
Training loss: 1.441072940826416
Validation loss: 2.054005701054809

Epoch: 6| Step: 2
Training loss: 2.094273328781128
Validation loss: 2.0611213253390406

Epoch: 6| Step: 3
Training loss: 1.330959439277649
Validation loss: 2.078109436137702

Epoch: 6| Step: 4
Training loss: 1.0120850801467896
Validation loss: 2.071011112582299

Epoch: 6| Step: 5
Training loss: 1.4366400241851807
Validation loss: 2.0878890919429

Epoch: 6| Step: 6
Training loss: 1.5312318801879883
Validation loss: 2.072872124692445

Epoch: 6| Step: 7
Training loss: 1.2691643238067627
Validation loss: 2.126947349117648

Epoch: 6| Step: 8
Training loss: 0.8541162610054016
Validation loss: 2.1097031383104223

Epoch: 6| Step: 9
Training loss: 1.627129077911377
Validation loss: 2.057147510590092

Epoch: 6| Step: 10
Training loss: 1.605426549911499
Validation loss: 2.059750308272659

Epoch: 6| Step: 11
Training loss: 1.4128186702728271
Validation loss: 2.0132104055855864

Epoch: 6| Step: 12
Training loss: 1.1709508895874023
Validation loss: 2.088132554484952

Epoch: 6| Step: 13
Training loss: 1.6316083669662476
Validation loss: 2.0006199511148597

Epoch: 482| Step: 0
Training loss: 1.1533466577529907
Validation loss: 2.0500629614758235

Epoch: 6| Step: 1
Training loss: 1.420186161994934
Validation loss: 2.011836897942328

Epoch: 6| Step: 2
Training loss: 1.2888422012329102
Validation loss: 2.0198450242319415

Epoch: 6| Step: 3
Training loss: 1.324300765991211
Validation loss: 2.042636174027638

Epoch: 6| Step: 4
Training loss: 1.589471459388733
Validation loss: 2.064352607214323

Epoch: 6| Step: 5
Training loss: 1.6450968980789185
Validation loss: 2.0800232682176816

Epoch: 6| Step: 6
Training loss: 1.112511396408081
Validation loss: 2.078463810746388

Epoch: 6| Step: 7
Training loss: 1.5803217887878418
Validation loss: 2.0827924641229774

Epoch: 6| Step: 8
Training loss: 0.9616848826408386
Validation loss: 2.049144617972835

Epoch: 6| Step: 9
Training loss: 2.1122584342956543
Validation loss: 2.072299967529953

Epoch: 6| Step: 10
Training loss: 1.612619400024414
Validation loss: 2.0567682353399133

Epoch: 6| Step: 11
Training loss: 1.4085643291473389
Validation loss: 2.088604316916517

Epoch: 6| Step: 12
Training loss: 1.3826572895050049
Validation loss: 2.0500288714644728

Epoch: 6| Step: 13
Training loss: 1.7335927486419678
Validation loss: 2.126580189633113

Epoch: 483| Step: 0
Training loss: 1.2863519191741943
Validation loss: 2.0596010287602744

Epoch: 6| Step: 1
Training loss: 1.3617486953735352
Validation loss: 2.048810948607742

Epoch: 6| Step: 2
Training loss: 1.4588899612426758
Validation loss: 2.0268215312752673

Epoch: 6| Step: 3
Training loss: 0.9447982907295227
Validation loss: 2.068083796449887

Epoch: 6| Step: 4
Training loss: 1.6745541095733643
Validation loss: 2.0574124295224427

Epoch: 6| Step: 5
Training loss: 1.0008498430252075
Validation loss: 2.030587330941231

Epoch: 6| Step: 6
Training loss: 1.320143461227417
Validation loss: 2.039895265333114

Epoch: 6| Step: 7
Training loss: 1.8514564037322998
Validation loss: 2.063971359242675

Epoch: 6| Step: 8
Training loss: 1.4677534103393555
Validation loss: 2.05371549693487

Epoch: 6| Step: 9
Training loss: 1.5185478925704956
Validation loss: 2.0802281043862783

Epoch: 6| Step: 10
Training loss: 1.5234766006469727
Validation loss: 2.0741696665363927

Epoch: 6| Step: 11
Training loss: 1.8050401210784912
Validation loss: 2.0549193966773247

Epoch: 6| Step: 12
Training loss: 1.4252629280090332
Validation loss: 2.002995248763792

Epoch: 6| Step: 13
Training loss: 1.1834394931793213
Validation loss: 2.0547144259175947

Epoch: 484| Step: 0
Training loss: 1.2395230531692505
Validation loss: 2.0615609525352396

Epoch: 6| Step: 1
Training loss: 1.3903355598449707
Validation loss: 2.0565349030238327

Epoch: 6| Step: 2
Training loss: 1.3592593669891357
Validation loss: 2.047445692041869

Epoch: 6| Step: 3
Training loss: 1.378239393234253
Validation loss: 2.0635061097401444

Epoch: 6| Step: 4
Training loss: 1.0279136896133423
Validation loss: 2.0459662445129885

Epoch: 6| Step: 5
Training loss: 1.3953497409820557
Validation loss: 2.0665416717529297

Epoch: 6| Step: 6
Training loss: 1.1395751237869263
Validation loss: 2.055680646691271

Epoch: 6| Step: 7
Training loss: 1.2650961875915527
Validation loss: 2.0555092121965144

Epoch: 6| Step: 8
Training loss: 1.8894973993301392
Validation loss: 2.0857982558588826

Epoch: 6| Step: 9
Training loss: 2.3132431507110596
Validation loss: 2.0642322148046186

Epoch: 6| Step: 10
Training loss: 1.179131269454956
Validation loss: 2.0875646721932197

Epoch: 6| Step: 11
Training loss: 1.0398802757263184
Validation loss: 2.050231631084155

Epoch: 6| Step: 12
Training loss: 1.7857661247253418
Validation loss: 2.027147077745007

Epoch: 6| Step: 13
Training loss: 1.2584184408187866
Validation loss: 2.0217921016036824

Epoch: 485| Step: 0
Training loss: 1.4645272493362427
Validation loss: 2.0376027809676303

Epoch: 6| Step: 1
Training loss: 0.7194013595581055
Validation loss: 2.1097365771570513

Epoch: 6| Step: 2
Training loss: 1.6536850929260254
Validation loss: 2.0443024571223924

Epoch: 6| Step: 3
Training loss: 1.4637901782989502
Validation loss: 2.0662904913707445

Epoch: 6| Step: 4
Training loss: 1.6834290027618408
Validation loss: 2.0649637676054433

Epoch: 6| Step: 5
Training loss: 1.9103819131851196
Validation loss: 2.08419390391278

Epoch: 6| Step: 6
Training loss: 1.5605053901672363
Validation loss: 2.053075716059695

Epoch: 6| Step: 7
Training loss: 1.4783064126968384
Validation loss: 2.06263510001603

Epoch: 6| Step: 8
Training loss: 1.412372350692749
Validation loss: 2.0326012180697535

Epoch: 6| Step: 9
Training loss: 1.0504807233810425
Validation loss: 2.0472821548420894

Epoch: 6| Step: 10
Training loss: 1.387514591217041
Validation loss: 2.038895191684846

Epoch: 6| Step: 11
Training loss: 1.626002311706543
Validation loss: 2.0930519027094685

Epoch: 6| Step: 12
Training loss: 1.2237944602966309
Validation loss: 2.049981819686069

Epoch: 6| Step: 13
Training loss: 1.1856310367584229
Validation loss: 2.046719443413519

Epoch: 486| Step: 0
Training loss: 1.4217060804367065
Validation loss: 2.0272838454092703

Epoch: 6| Step: 1
Training loss: 1.4022042751312256
Validation loss: 2.01228670407367

Epoch: 6| Step: 2
Training loss: 1.8017542362213135
Validation loss: 2.000397136134486

Epoch: 6| Step: 3
Training loss: 1.1684762239456177
Validation loss: 2.0703159993694675

Epoch: 6| Step: 4
Training loss: 1.2297590970993042
Validation loss: 2.0303239668569257

Epoch: 6| Step: 5
Training loss: 1.6386594772338867
Validation loss: 2.020905561344598

Epoch: 6| Step: 6
Training loss: 1.2810522317886353
Validation loss: 2.0542630969837146

Epoch: 6| Step: 7
Training loss: 0.9763058423995972
Validation loss: 2.069304625193278

Epoch: 6| Step: 8
Training loss: 1.0304322242736816
Validation loss: 2.0543616433297434

Epoch: 6| Step: 9
Training loss: 1.8699822425842285
Validation loss: 2.0462277986670054

Epoch: 6| Step: 10
Training loss: 1.7344248294830322
Validation loss: 2.063161103956161

Epoch: 6| Step: 11
Training loss: 1.9373821020126343
Validation loss: 2.083172680229269

Epoch: 6| Step: 12
Training loss: 1.63142728805542
Validation loss: 2.092506662491829

Epoch: 6| Step: 13
Training loss: 0.8846794366836548
Validation loss: 2.1014635588533137

Epoch: 487| Step: 0
Training loss: 1.2530877590179443
Validation loss: 2.1066231958327757

Epoch: 6| Step: 1
Training loss: 1.621086597442627
Validation loss: 2.0470310052235923

Epoch: 6| Step: 2
Training loss: 1.631714105606079
Validation loss: 2.086086006574733

Epoch: 6| Step: 3
Training loss: 1.5356261730194092
Validation loss: 2.051134870898339

Epoch: 6| Step: 4
Training loss: 2.0247962474823
Validation loss: 2.064975796207305

Epoch: 6| Step: 5
Training loss: 1.2293076515197754
Validation loss: 2.0709659540525047

Epoch: 6| Step: 6
Training loss: 1.5261657238006592
Validation loss: 2.0674926927012782

Epoch: 6| Step: 7
Training loss: 1.0920405387878418
Validation loss: 2.030698314789803

Epoch: 6| Step: 8
Training loss: 1.527388095855713
Validation loss: 2.0731279580823836

Epoch: 6| Step: 9
Training loss: 0.6162127256393433
Validation loss: 2.0205256323660574

Epoch: 6| Step: 10
Training loss: 1.8070844411849976
Validation loss: 2.0564673357112433

Epoch: 6| Step: 11
Training loss: 0.9928352236747742
Validation loss: 2.0511791706085205

Epoch: 6| Step: 12
Training loss: 1.4797749519348145
Validation loss: 2.0773256619771323

Epoch: 6| Step: 13
Training loss: 1.5264315605163574
Validation loss: 2.0322995801125803

Epoch: 488| Step: 0
Training loss: 1.546732783317566
Validation loss: 2.0761914227598455

Epoch: 6| Step: 1
Training loss: 1.5145390033721924
Validation loss: 2.0750181508320633

Epoch: 6| Step: 2
Training loss: 0.904080331325531
Validation loss: 2.055334719278479

Epoch: 6| Step: 3
Training loss: 1.39383864402771
Validation loss: 2.043712995385611

Epoch: 6| Step: 4
Training loss: 1.5681474208831787
Validation loss: 2.03413987159729

Epoch: 6| Step: 5
Training loss: 1.9480026960372925
Validation loss: 2.0342670333000923

Epoch: 6| Step: 6
Training loss: 2.0654547214508057
Validation loss: 2.0459648409197406

Epoch: 6| Step: 7
Training loss: 1.3573107719421387
Validation loss: 2.073867510723811

Epoch: 6| Step: 8
Training loss: 0.8871876001358032
Validation loss: 2.018640543824883

Epoch: 6| Step: 9
Training loss: 1.152456283569336
Validation loss: 2.0548872396510136

Epoch: 6| Step: 10
Training loss: 1.1613937616348267
Validation loss: 2.033953757696254

Epoch: 6| Step: 11
Training loss: 1.643293023109436
Validation loss: 2.046599124067573

Epoch: 6| Step: 12
Training loss: 1.3421331644058228
Validation loss: 2.038764497285248

Epoch: 6| Step: 13
Training loss: 0.9437696933746338
Validation loss: 2.0829422012452157

Epoch: 489| Step: 0
Training loss: 1.2572165727615356
Validation loss: 2.086870603663947

Epoch: 6| Step: 1
Training loss: 1.7371959686279297
Validation loss: 2.0529640028553624

Epoch: 6| Step: 2
Training loss: 1.1333348751068115
Validation loss: 2.065976776102538

Epoch: 6| Step: 3
Training loss: 1.2248046398162842
Validation loss: 2.1091271651688444

Epoch: 6| Step: 4
Training loss: 1.0394186973571777
Validation loss: 2.1284710335475143

Epoch: 6| Step: 5
Training loss: 1.6371362209320068
Validation loss: 2.1059352864501295

Epoch: 6| Step: 6
Training loss: 1.5107221603393555
Validation loss: 2.0758750156689714

Epoch: 6| Step: 7
Training loss: 1.2023415565490723
Validation loss: 2.1260689368811985

Epoch: 6| Step: 8
Training loss: 1.4158916473388672
Validation loss: 2.1104687375407063

Epoch: 6| Step: 9
Training loss: 0.8865426778793335
Validation loss: 2.092078217896082

Epoch: 6| Step: 10
Training loss: 1.6090114116668701
Validation loss: 2.0516573395780338

Epoch: 6| Step: 11
Training loss: 1.701117992401123
Validation loss: 2.022159989162158

Epoch: 6| Step: 12
Training loss: 2.1065192222595215
Validation loss: 2.047294898699689

Epoch: 6| Step: 13
Training loss: 1.0050245523452759
Validation loss: 2.0565407199244343

Epoch: 490| Step: 0
Training loss: 1.3315068483352661
Validation loss: 2.04346663208418

Epoch: 6| Step: 1
Training loss: 1.4190367460250854
Validation loss: 2.063521626175091

Epoch: 6| Step: 2
Training loss: 1.8699467182159424
Validation loss: 2.0291714745183147

Epoch: 6| Step: 3
Training loss: 1.4381599426269531
Validation loss: 2.0320207893207507

Epoch: 6| Step: 4
Training loss: 1.1409631967544556
Validation loss: 2.0613793673053866

Epoch: 6| Step: 5
Training loss: 1.4472613334655762
Validation loss: 2.013131885118382

Epoch: 6| Step: 6
Training loss: 0.9453716278076172
Validation loss: 2.011450747007965

Epoch: 6| Step: 7
Training loss: 1.3640615940093994
Validation loss: 2.0736296023091962

Epoch: 6| Step: 8
Training loss: 1.3876551389694214
Validation loss: 2.0527970137134677

Epoch: 6| Step: 9
Training loss: 1.5823743343353271
Validation loss: 2.0959956569056355

Epoch: 6| Step: 10
Training loss: 2.1941347122192383
Validation loss: 2.0471781351233043

Epoch: 6| Step: 11
Training loss: 1.0874525308609009
Validation loss: 2.0832744734261626

Epoch: 6| Step: 12
Training loss: 1.5272841453552246
Validation loss: 2.097159772790888

Epoch: 6| Step: 13
Training loss: 1.2957873344421387
Validation loss: 2.0455875025000623

Epoch: 491| Step: 0
Training loss: 1.2326998710632324
Validation loss: 2.086519507951634

Epoch: 6| Step: 1
Training loss: 1.4109861850738525
Validation loss: 2.09272139815874

Epoch: 6| Step: 2
Training loss: 1.3730875253677368
Validation loss: 2.0964534692866827

Epoch: 6| Step: 3
Training loss: 1.0128424167633057
Validation loss: 2.072876766163816

Epoch: 6| Step: 4
Training loss: 1.7821189165115356
Validation loss: 2.0710464036592873

Epoch: 6| Step: 5
Training loss: 0.7397733330726624
Validation loss: 2.080836824191514

Epoch: 6| Step: 6
Training loss: 1.2367572784423828
Validation loss: 2.039633330478463

Epoch: 6| Step: 7
Training loss: 1.6589906215667725
Validation loss: 2.0467367518332695

Epoch: 6| Step: 8
Training loss: 1.3527811765670776
Validation loss: 2.04095761622152

Epoch: 6| Step: 9
Training loss: 1.42459237575531
Validation loss: 2.0090153063497236

Epoch: 6| Step: 10
Training loss: 1.0395359992980957
Validation loss: 2.0361784196669057

Epoch: 6| Step: 11
Training loss: 1.7083473205566406
Validation loss: 1.991959169346799

Epoch: 6| Step: 12
Training loss: 1.6261448860168457
Validation loss: 2.040570742340498

Epoch: 6| Step: 13
Training loss: 2.4410505294799805
Validation loss: 2.0364042943523777

Epoch: 492| Step: 0
Training loss: 1.341967225074768
Validation loss: 1.999178841549863

Epoch: 6| Step: 1
Training loss: 1.7192308902740479
Validation loss: 2.054872085971217

Epoch: 6| Step: 2
Training loss: 1.4809825420379639
Validation loss: 2.0538998137238207

Epoch: 6| Step: 3
Training loss: 1.1696288585662842
Validation loss: 2.0705429559112876

Epoch: 6| Step: 4
Training loss: 0.9837681651115417
Validation loss: 2.064357339694936

Epoch: 6| Step: 5
Training loss: 1.2331607341766357
Validation loss: 2.046211370857813

Epoch: 6| Step: 6
Training loss: 1.729095458984375
Validation loss: 2.0123587372482463

Epoch: 6| Step: 7
Training loss: 1.277696132659912
Validation loss: 2.0201699605552097

Epoch: 6| Step: 8
Training loss: 1.138953685760498
Validation loss: 2.019281789820681

Epoch: 6| Step: 9
Training loss: 1.528921127319336
Validation loss: 2.077031425250474

Epoch: 6| Step: 10
Training loss: 1.3868095874786377
Validation loss: 2.0286382423934115

Epoch: 6| Step: 11
Training loss: 1.0051889419555664
Validation loss: 2.054223322099255

Epoch: 6| Step: 12
Training loss: 2.1052403450012207
Validation loss: 2.0788663561626146

Epoch: 6| Step: 13
Training loss: 2.2158665657043457
Validation loss: 2.093244186011694

Epoch: 493| Step: 0
Training loss: 1.5955991744995117
Validation loss: 2.094997843106588

Epoch: 6| Step: 1
Training loss: 1.512403964996338
Validation loss: 2.0296468145103863

Epoch: 6| Step: 2
Training loss: 2.1119158267974854
Validation loss: 2.082612309404599

Epoch: 6| Step: 3
Training loss: 1.2516776323318481
Validation loss: 2.0300014890650266

Epoch: 6| Step: 4
Training loss: 1.6144003868103027
Validation loss: 2.0332773577782417

Epoch: 6| Step: 5
Training loss: 1.2378255128860474
Validation loss: 2.036719060713245

Epoch: 6| Step: 6
Training loss: 2.0149688720703125
Validation loss: 2.0011445347980787

Epoch: 6| Step: 7
Training loss: 0.8851411938667297
Validation loss: 2.0375146545389646

Epoch: 6| Step: 8
Training loss: 1.72804594039917
Validation loss: 2.089182516579987

Epoch: 6| Step: 9
Training loss: 1.552422046661377
Validation loss: 2.0472323663773073

Epoch: 6| Step: 10
Training loss: 0.646994948387146
Validation loss: 2.0250705826667046

Epoch: 6| Step: 11
Training loss: 1.4376033544540405
Validation loss: 2.0480396850134737

Epoch: 6| Step: 12
Training loss: 1.0525484085083008
Validation loss: 2.0143560119854507

Epoch: 6| Step: 13
Training loss: 1.3552966117858887
Validation loss: 2.055100671706661

Epoch: 494| Step: 0
Training loss: 0.8744316697120667
Validation loss: 2.0696622569073915

Epoch: 6| Step: 1
Training loss: 1.3087689876556396
Validation loss: 2.058776086376559

Epoch: 6| Step: 2
Training loss: 1.5635218620300293
Validation loss: 2.031746784845988

Epoch: 6| Step: 3
Training loss: 1.1514360904693604
Validation loss: 2.0989018640210553

Epoch: 6| Step: 4
Training loss: 1.0875611305236816
Validation loss: 2.057602879821613

Epoch: 6| Step: 5
Training loss: 2.0551676750183105
Validation loss: 2.0634534025704987

Epoch: 6| Step: 6
Training loss: 1.3942298889160156
Validation loss: 2.0640843299127396

Epoch: 6| Step: 7
Training loss: 1.5434651374816895
Validation loss: 2.045546647041075

Epoch: 6| Step: 8
Training loss: 1.4818681478500366
Validation loss: 2.05440580203969

Epoch: 6| Step: 9
Training loss: 1.6095361709594727
Validation loss: 2.0187077663278066

Epoch: 6| Step: 10
Training loss: 1.9859203100204468
Validation loss: 2.0627001716244604

Epoch: 6| Step: 11
Training loss: 0.9233393669128418
Validation loss: 2.066550898295577

Epoch: 6| Step: 12
Training loss: 1.096980094909668
Validation loss: 2.0735519316888626

Epoch: 6| Step: 13
Training loss: 1.6261353492736816
Validation loss: 2.12455911790171

Epoch: 495| Step: 0
Training loss: 1.3741247653961182
Validation loss: 2.032786803860818

Epoch: 6| Step: 1
Training loss: 1.7403790950775146
Validation loss: 2.0647795456711964

Epoch: 6| Step: 2
Training loss: 1.2781058549880981
Validation loss: 2.0354049718508156

Epoch: 6| Step: 3
Training loss: 2.3984122276306152
Validation loss: 2.009698934452508

Epoch: 6| Step: 4
Training loss: 0.9908664226531982
Validation loss: 2.034704159664851

Epoch: 6| Step: 5
Training loss: 0.8727697134017944
Validation loss: 2.056553558636737

Epoch: 6| Step: 6
Training loss: 2.0618858337402344
Validation loss: 2.0666307941559823

Epoch: 6| Step: 7
Training loss: 1.4078166484832764
Validation loss: 2.0576429828520744

Epoch: 6| Step: 8
Training loss: 1.4057791233062744
Validation loss: 2.030445534695861

Epoch: 6| Step: 9
Training loss: 1.7076162099838257
Validation loss: 2.042833597429337

Epoch: 6| Step: 10
Training loss: 1.5547308921813965
Validation loss: 2.0110197041624334

Epoch: 6| Step: 11
Training loss: 0.6457013487815857
Validation loss: 2.100282642149156

Epoch: 6| Step: 12
Training loss: 1.1037812232971191
Validation loss: 2.0858346826286724

Epoch: 6| Step: 13
Training loss: 1.4417076110839844
Validation loss: 2.0501381633102254

Epoch: 496| Step: 0
Training loss: 1.3640568256378174
Validation loss: 2.088204627395958

Epoch: 6| Step: 1
Training loss: 1.3831902742385864
Validation loss: 2.0448908728937947

Epoch: 6| Step: 2
Training loss: 0.8161261081695557
Validation loss: 2.1286468454586562

Epoch: 6| Step: 3
Training loss: 1.4664698839187622
Validation loss: 2.03035762745847

Epoch: 6| Step: 4
Training loss: 1.5416669845581055
Validation loss: 2.0802071427786224

Epoch: 6| Step: 5
Training loss: 1.2611616849899292
Validation loss: 2.05466063304614

Epoch: 6| Step: 6
Training loss: 1.0433446168899536
Validation loss: 2.049252797198552

Epoch: 6| Step: 7
Training loss: 1.0122092962265015
Validation loss: 2.07462336427422

Epoch: 6| Step: 8
Training loss: 1.8386942148208618
Validation loss: 2.04396826733825

Epoch: 6| Step: 9
Training loss: 1.5301942825317383
Validation loss: 2.0152009507661224

Epoch: 6| Step: 10
Training loss: 1.4055923223495483
Validation loss: 2.040062145520282

Epoch: 6| Step: 11
Training loss: 1.6532227993011475
Validation loss: 2.0280088737446773

Epoch: 6| Step: 12
Training loss: 1.1662678718566895
Validation loss: 2.0117089453563897

Epoch: 6| Step: 13
Training loss: 1.9307717084884644
Validation loss: 2.05192764600118

Epoch: 497| Step: 0
Training loss: 1.6706700325012207
Validation loss: 2.027970888281381

Epoch: 6| Step: 1
Training loss: 1.518155813217163
Validation loss: 2.0449644596345964

Epoch: 6| Step: 2
Training loss: 1.0616393089294434
Validation loss: 2.0282017210478425

Epoch: 6| Step: 3
Training loss: 1.1609303951263428
Validation loss: 2.0372550154245026

Epoch: 6| Step: 4
Training loss: 1.9575879573822021
Validation loss: 2.0723558241321194

Epoch: 6| Step: 5
Training loss: 1.116481065750122
Validation loss: 2.070675774287152

Epoch: 6| Step: 6
Training loss: 1.437483310699463
Validation loss: 2.0688502250179166

Epoch: 6| Step: 7
Training loss: 1.3964850902557373
Validation loss: 2.1012491256959978

Epoch: 6| Step: 8
Training loss: 1.6181886196136475
Validation loss: 2.1189661205455823

Epoch: 6| Step: 9
Training loss: 0.8994922041893005
Validation loss: 2.1113386090083788

Epoch: 6| Step: 10
Training loss: 1.5185505151748657
Validation loss: 2.1235001753735285

Epoch: 6| Step: 11
Training loss: 1.0473308563232422
Validation loss: 2.090370180786297

Epoch: 6| Step: 12
Training loss: 1.4717981815338135
Validation loss: 2.0995715049005326

Epoch: 6| Step: 13
Training loss: 1.8858532905578613
Validation loss: 2.1045918195478377

Epoch: 498| Step: 0
Training loss: 1.8318336009979248
Validation loss: 2.0260912115855882

Epoch: 6| Step: 1
Training loss: 1.2365003824234009
Validation loss: 2.0556512917241743

Epoch: 6| Step: 2
Training loss: 1.069820761680603
Validation loss: 2.037936700287686

Epoch: 6| Step: 3
Training loss: 1.682059407234192
Validation loss: 2.013486095654067

Epoch: 6| Step: 4
Training loss: 1.2522766590118408
Validation loss: 2.0043542859374837

Epoch: 6| Step: 5
Training loss: 1.291738748550415
Validation loss: 2.053870657438873

Epoch: 6| Step: 6
Training loss: 1.516811728477478
Validation loss: 1.9981111916162635

Epoch: 6| Step: 7
Training loss: 1.2373156547546387
Validation loss: 2.0609162084517942

Epoch: 6| Step: 8
Training loss: 1.4691619873046875
Validation loss: 2.03738373069353

Epoch: 6| Step: 9
Training loss: 1.0257517099380493
Validation loss: 2.050904348332395

Epoch: 6| Step: 10
Training loss: 1.3113059997558594
Validation loss: 2.0072083780842442

Epoch: 6| Step: 11
Training loss: 1.909771203994751
Validation loss: 2.0482754066426265

Epoch: 6| Step: 12
Training loss: 1.911828637123108
Validation loss: 2.0706315553316506

Epoch: 6| Step: 13
Training loss: 1.029329538345337
Validation loss: 2.034859322732495

Epoch: 499| Step: 0
Training loss: 1.0500208139419556
Validation loss: 2.045079151789347

Epoch: 6| Step: 1
Training loss: 0.8798635005950928
Validation loss: 2.0612657044523504

Epoch: 6| Step: 2
Training loss: 1.6869661808013916
Validation loss: 2.0366228959893666

Epoch: 6| Step: 3
Training loss: 1.4520870447158813
Validation loss: 2.0498123527855

Epoch: 6| Step: 4
Training loss: 1.27189040184021
Validation loss: 2.0656201659992175

Epoch: 6| Step: 5
Training loss: 1.5430938005447388
Validation loss: 2.0311874138411654

Epoch: 6| Step: 6
Training loss: 1.6865098476409912
Validation loss: 2.0443173018834924

Epoch: 6| Step: 7
Training loss: 1.2466003894805908
Validation loss: 2.018947634645688

Epoch: 6| Step: 8
Training loss: 1.4263591766357422
Validation loss: 2.068185801147133

Epoch: 6| Step: 9
Training loss: 1.1195945739746094
Validation loss: 2.038801972584058

Epoch: 6| Step: 10
Training loss: 1.3695769309997559
Validation loss: 2.0435687316361295

Epoch: 6| Step: 11
Training loss: 1.4699831008911133
Validation loss: 2.0223669518706617

Epoch: 6| Step: 12
Training loss: 1.5397440195083618
Validation loss: 2.056672501307662

Epoch: 6| Step: 13
Training loss: 1.8273680210113525
Validation loss: 2.015794322054873

Epoch: 500| Step: 0
Training loss: 0.8659294247627258
Validation loss: 1.9967922241457048

Epoch: 6| Step: 1
Training loss: 1.0328962802886963
Validation loss: 2.043137650335989

Epoch: 6| Step: 2
Training loss: 2.1369643211364746
Validation loss: 2.0454690635845227

Epoch: 6| Step: 3
Training loss: 1.317546010017395
Validation loss: 2.0141824701780915

Epoch: 6| Step: 4
Training loss: 0.9013254642486572
Validation loss: 1.9864316448088615

Epoch: 6| Step: 5
Training loss: 1.673478364944458
Validation loss: 2.030533375278596

Epoch: 6| Step: 6
Training loss: 1.1520090103149414
Validation loss: 2.0062380336946055

Epoch: 6| Step: 7
Training loss: 1.6789820194244385
Validation loss: 2.011431601739699

Epoch: 6| Step: 8
Training loss: 2.0008599758148193
Validation loss: 2.056553756037066

Epoch: 6| Step: 9
Training loss: 1.1840894222259521
Validation loss: 2.0063764331161336

Epoch: 6| Step: 10
Training loss: 0.881240963935852
Validation loss: 2.038020363418005

Epoch: 6| Step: 11
Training loss: 1.6064203977584839
Validation loss: 2.0292172983128536

Epoch: 6| Step: 12
Training loss: 1.7621402740478516
Validation loss: 2.0260779075725104

Epoch: 6| Step: 13
Training loss: 1.5539580583572388
Validation loss: 2.069935048780134

Epoch: 501| Step: 0
Training loss: 1.5019060373306274
Validation loss: 2.0619439514734412

Epoch: 6| Step: 1
Training loss: 1.8149170875549316
Validation loss: 2.015800554265258

Epoch: 6| Step: 2
Training loss: 1.3718699216842651
Validation loss: 2.0595403909683228

Epoch: 6| Step: 3
Training loss: 0.6790801286697388
Validation loss: 2.045772067962154

Epoch: 6| Step: 4
Training loss: 1.1549946069717407
Validation loss: 2.032849680992865

Epoch: 6| Step: 5
Training loss: 1.845231294631958
Validation loss: 2.062840977022725

Epoch: 6| Step: 6
Training loss: 2.0159542560577393
Validation loss: 2.0755123297373452

Epoch: 6| Step: 7
Training loss: 1.09861159324646
Validation loss: 2.063124418258667

Epoch: 6| Step: 8
Training loss: 1.5382357835769653
Validation loss: 2.0661757556341027

Epoch: 6| Step: 9
Training loss: 1.4515597820281982
Validation loss: 2.0034559554951166

Epoch: 6| Step: 10
Training loss: 1.4384074211120605
Validation loss: 1.9843001211843183

Epoch: 6| Step: 11
Training loss: 1.0446758270263672
Validation loss: 2.0356936839319046

Epoch: 6| Step: 12
Training loss: 1.5100667476654053
Validation loss: 2.0635944028054514

Epoch: 6| Step: 13
Training loss: 0.9904933571815491
Validation loss: 2.0261889196211293

Epoch: 502| Step: 0
Training loss: 0.7646875381469727
Validation loss: 2.0303927621533795

Epoch: 6| Step: 1
Training loss: 1.5184175968170166
Validation loss: 2.0198686302349134

Epoch: 6| Step: 2
Training loss: 1.0739351511001587
Validation loss: 2.048908464370235

Epoch: 6| Step: 3
Training loss: 2.2284610271453857
Validation loss: 2.022096505729101

Epoch: 6| Step: 4
Training loss: 0.9720597267150879
Validation loss: 2.0351366766037478

Epoch: 6| Step: 5
Training loss: 1.3986899852752686
Validation loss: 2.0835006544666905

Epoch: 6| Step: 6
Training loss: 1.4705086946487427
Validation loss: 2.055044856122745

Epoch: 6| Step: 7
Training loss: 1.5452381372451782
Validation loss: 2.09639448119748

Epoch: 6| Step: 8
Training loss: 1.544790267944336
Validation loss: 2.0788439499434603

Epoch: 6| Step: 9
Training loss: 1.740325927734375
Validation loss: 2.0886135819137737

Epoch: 6| Step: 10
Training loss: 1.503614902496338
Validation loss: 2.045941637408349

Epoch: 6| Step: 11
Training loss: 0.6986774206161499
Validation loss: 2.0577516453240507

Epoch: 6| Step: 12
Training loss: 1.1966112852096558
Validation loss: 2.037184888316739

Epoch: 6| Step: 13
Training loss: 1.4073461294174194
Validation loss: 2.017793211885678

Epoch: 503| Step: 0
Training loss: 1.0580759048461914
Validation loss: 2.04705657241165

Epoch: 6| Step: 1
Training loss: 1.4209678173065186
Validation loss: 2.045082520413142

Epoch: 6| Step: 2
Training loss: 1.2004257440567017
Validation loss: 2.005844759684737

Epoch: 6| Step: 3
Training loss: 0.8757444620132446
Validation loss: 2.076186928697812

Epoch: 6| Step: 4
Training loss: 1.0067399740219116
Validation loss: 2.0329919322844474

Epoch: 6| Step: 5
Training loss: 0.7142007350921631
Validation loss: 2.0613021773676716

Epoch: 6| Step: 6
Training loss: 1.8121960163116455
Validation loss: 2.05031096037998

Epoch: 6| Step: 7
Training loss: 1.098045825958252
Validation loss: 2.0714772170589817

Epoch: 6| Step: 8
Training loss: 2.2154622077941895
Validation loss: 2.02032277148257

Epoch: 6| Step: 9
Training loss: 1.127120018005371
Validation loss: 2.0772375804121777

Epoch: 6| Step: 10
Training loss: 1.7363301515579224
Validation loss: 2.0550935447856946

Epoch: 6| Step: 11
Training loss: 1.8827921152114868
Validation loss: 2.0364099984527915

Epoch: 6| Step: 12
Training loss: 1.4735952615737915
Validation loss: 2.0610529120250414

Epoch: 6| Step: 13
Training loss: 1.6218065023422241
Validation loss: 2.0469965729662167

Epoch: 504| Step: 0
Training loss: 1.7000324726104736
Validation loss: 2.0309622339023057

Epoch: 6| Step: 1
Training loss: 1.9091743230819702
Validation loss: 2.054942436115716

Epoch: 6| Step: 2
Training loss: 1.9561337232589722
Validation loss: 2.0325064505300214

Epoch: 6| Step: 3
Training loss: 1.1613095998764038
Validation loss: 2.018739897717712

Epoch: 6| Step: 4
Training loss: 1.5592525005340576
Validation loss: 2.058780442001999

Epoch: 6| Step: 5
Training loss: 1.194673776626587
Validation loss: 2.019505598211801

Epoch: 6| Step: 6
Training loss: 0.8372849822044373
Validation loss: 2.0290371935854674

Epoch: 6| Step: 7
Training loss: 1.1271162033081055
Validation loss: 2.0617042485103814

Epoch: 6| Step: 8
Training loss: 1.7606314420700073
Validation loss: 2.039943282322217

Epoch: 6| Step: 9
Training loss: 1.0826830863952637
Validation loss: 2.0443652227360714

Epoch: 6| Step: 10
Training loss: 0.6074934601783752
Validation loss: 2.0588674288924023

Epoch: 6| Step: 11
Training loss: 1.42416512966156
Validation loss: 2.053290021034979

Epoch: 6| Step: 12
Training loss: 2.0250816345214844
Validation loss: 2.0306594666614326

Epoch: 6| Step: 13
Training loss: 1.02804696559906
Validation loss: 2.058310713819278

Epoch: 505| Step: 0
Training loss: 1.4260393381118774
Validation loss: 2.0768214015550512

Epoch: 6| Step: 1
Training loss: 1.2063543796539307
Validation loss: 2.0593725173704085

Epoch: 6| Step: 2
Training loss: 1.0436556339263916
Validation loss: 2.0978283856504705

Epoch: 6| Step: 3
Training loss: 1.4415531158447266
Validation loss: 2.034848124750199

Epoch: 6| Step: 4
Training loss: 1.2903220653533936
Validation loss: 2.065830235840172

Epoch: 6| Step: 5
Training loss: 1.5020267963409424
Validation loss: 2.060960069779427

Epoch: 6| Step: 6
Training loss: 1.664517879486084
Validation loss: 2.0644163008659118

Epoch: 6| Step: 7
Training loss: 1.466202735900879
Validation loss: 1.991305531993989

Epoch: 6| Step: 8
Training loss: 1.5166776180267334
Validation loss: 2.0285705058805403

Epoch: 6| Step: 9
Training loss: 1.5527000427246094
Validation loss: 2.0304680024423907

Epoch: 6| Step: 10
Training loss: 1.1782537698745728
Validation loss: 2.0277020290333736

Epoch: 6| Step: 11
Training loss: 1.3203067779541016
Validation loss: 2.027682747892154

Epoch: 6| Step: 12
Training loss: 2.0401508808135986
Validation loss: 2.018981981021102

Epoch: 6| Step: 13
Training loss: 1.428563117980957
Validation loss: 2.039065598159708

Epoch: 506| Step: 0
Training loss: 1.9354476928710938
Validation loss: 2.048581620698334

Epoch: 6| Step: 1
Training loss: 1.2729016542434692
Validation loss: 2.0340102077812277

Epoch: 6| Step: 2
Training loss: 0.8582645654678345
Validation loss: 2.0872078428986254

Epoch: 6| Step: 3
Training loss: 1.227830171585083
Validation loss: 2.091809641930365

Epoch: 6| Step: 4
Training loss: 1.776755452156067
Validation loss: 2.0645052117686116

Epoch: 6| Step: 5
Training loss: 1.2886130809783936
Validation loss: 2.078543398969917

Epoch: 6| Step: 6
Training loss: 1.805301547050476
Validation loss: 2.0952497861718618

Epoch: 6| Step: 7
Training loss: 1.3789985179901123
Validation loss: 2.081287504524313

Epoch: 6| Step: 8
Training loss: 1.5670967102050781
Validation loss: 2.1198794867402766

Epoch: 6| Step: 9
Training loss: 1.4937376976013184
Validation loss: 2.098954592981646

Epoch: 6| Step: 10
Training loss: 1.5369116067886353
Validation loss: 2.101328762628699

Epoch: 6| Step: 11
Training loss: 0.9680267572402954
Validation loss: 2.0474803601541827

Epoch: 6| Step: 12
Training loss: 1.4339711666107178
Validation loss: 2.0290621634452575

Epoch: 6| Step: 13
Training loss: 0.7807644009590149
Validation loss: 2.0650297057244087

Epoch: 507| Step: 0
Training loss: 1.1289892196655273
Validation loss: 2.07441641822938

Epoch: 6| Step: 1
Training loss: 1.3447920083999634
Validation loss: 2.058754764577394

Epoch: 6| Step: 2
Training loss: 1.2203360795974731
Validation loss: 2.014483964571389

Epoch: 6| Step: 3
Training loss: 1.6479159593582153
Validation loss: 2.0330135078840357

Epoch: 6| Step: 4
Training loss: 2.0285425186157227
Validation loss: 2.0481173069246355

Epoch: 6| Step: 5
Training loss: 1.238347053527832
Validation loss: 2.0753766952022428

Epoch: 6| Step: 6
Training loss: 1.4193542003631592
Validation loss: 2.037016725027433

Epoch: 6| Step: 7
Training loss: 0.9374555945396423
Validation loss: 2.0544235937057005

Epoch: 6| Step: 8
Training loss: 1.5445899963378906
Validation loss: 2.0564610304371005

Epoch: 6| Step: 9
Training loss: 1.0540716648101807
Validation loss: 2.050899674815516

Epoch: 6| Step: 10
Training loss: 0.9448766708374023
Validation loss: 2.0531589292710826

Epoch: 6| Step: 11
Training loss: 1.3209574222564697
Validation loss: 2.0501851317703084

Epoch: 6| Step: 12
Training loss: 1.5473483800888062
Validation loss: 2.0531333210647746

Epoch: 6| Step: 13
Training loss: 1.8664978742599487
Validation loss: 2.0548628171284995

Epoch: 508| Step: 0
Training loss: 1.6635407209396362
Validation loss: 2.074627589153987

Epoch: 6| Step: 1
Training loss: 1.051053762435913
Validation loss: 2.041226035805159

Epoch: 6| Step: 2
Training loss: 1.5920708179473877
Validation loss: 2.019380707894602

Epoch: 6| Step: 3
Training loss: 1.547836422920227
Validation loss: 2.012986589503545

Epoch: 6| Step: 4
Training loss: 1.7211791276931763
Validation loss: 2.013304284823838

Epoch: 6| Step: 5
Training loss: 1.140625
Validation loss: 2.0084871271605134

Epoch: 6| Step: 6
Training loss: 1.465372085571289
Validation loss: 2.0103464575224024

Epoch: 6| Step: 7
Training loss: 1.0831825733184814
Validation loss: 2.0022269256653322

Epoch: 6| Step: 8
Training loss: 1.2897207736968994
Validation loss: 2.0215992876278457

Epoch: 6| Step: 9
Training loss: 0.9347774386405945
Validation loss: 2.0005514493552585

Epoch: 6| Step: 10
Training loss: 1.409468173980713
Validation loss: 2.0272649308686614

Epoch: 6| Step: 11
Training loss: 1.3497085571289062
Validation loss: 2.057702390096521

Epoch: 6| Step: 12
Training loss: 1.6404659748077393
Validation loss: 2.0380505900229178

Epoch: 6| Step: 13
Training loss: 1.3177146911621094
Validation loss: 2.038775408139793

Epoch: 509| Step: 0
Training loss: 1.8534519672393799
Validation loss: 2.0479017649927447

Epoch: 6| Step: 1
Training loss: 0.7949796319007874
Validation loss: 2.05736860921306

Epoch: 6| Step: 2
Training loss: 1.4791619777679443
Validation loss: 1.9923264467588035

Epoch: 6| Step: 3
Training loss: 0.9041216373443604
Validation loss: 2.0382569374576693

Epoch: 6| Step: 4
Training loss: 1.5730005502700806
Validation loss: 2.0251287773091304

Epoch: 6| Step: 5
Training loss: 1.4918270111083984
Validation loss: 2.0486805900450675

Epoch: 6| Step: 6
Training loss: 1.500949501991272
Validation loss: 2.0687950106077295

Epoch: 6| Step: 7
Training loss: 0.8031567335128784
Validation loss: 2.0584719719425326

Epoch: 6| Step: 8
Training loss: 1.9337025880813599
Validation loss: 2.0211785762540755

Epoch: 6| Step: 9
Training loss: 1.5534733533859253
Validation loss: 2.048579731295186

Epoch: 6| Step: 10
Training loss: 1.2661998271942139
Validation loss: 2.0377800182629655

Epoch: 6| Step: 11
Training loss: 1.3158196210861206
Validation loss: 2.0608150010467856

Epoch: 6| Step: 12
Training loss: 1.848814845085144
Validation loss: 2.0098766332031577

Epoch: 6| Step: 13
Training loss: 0.9325678944587708
Validation loss: 1.9959867256943897

Epoch: 510| Step: 0
Training loss: 1.1912310123443604
Validation loss: 2.0682641254958285

Epoch: 6| Step: 1
Training loss: 1.3870819807052612
Validation loss: 2.0402931718416113

Epoch: 6| Step: 2
Training loss: 0.8682291507720947
Validation loss: 2.0660198709016204

Epoch: 6| Step: 3
Training loss: 1.192129373550415
Validation loss: 2.0580792209153533

Epoch: 6| Step: 4
Training loss: 1.9487333297729492
Validation loss: 2.0410241644869567

Epoch: 6| Step: 5
Training loss: 1.010084867477417
Validation loss: 2.0399897995815484

Epoch: 6| Step: 6
Training loss: 1.6851459741592407
Validation loss: 2.007963929125058

Epoch: 6| Step: 7
Training loss: 1.2999889850616455
Validation loss: 2.0591119489362164

Epoch: 6| Step: 8
Training loss: 1.8683454990386963
Validation loss: 2.051401530542681

Epoch: 6| Step: 9
Training loss: 1.1985015869140625
Validation loss: 2.0932937052942093

Epoch: 6| Step: 10
Training loss: 1.1898417472839355
Validation loss: 2.0575475487657773

Epoch: 6| Step: 11
Training loss: 1.611881136894226
Validation loss: 2.049140694320843

Epoch: 6| Step: 12
Training loss: 1.4184727668762207
Validation loss: 2.093450912865259

Epoch: 6| Step: 13
Training loss: 1.6138272285461426
Validation loss: 2.068021730710101

Epoch: 511| Step: 0
Training loss: 1.3960167169570923
Validation loss: 2.033283145196976

Epoch: 6| Step: 1
Training loss: 1.0977650880813599
Validation loss: 2.085905526273994

Epoch: 6| Step: 2
Training loss: 1.421443223953247
Validation loss: 2.091867257190007

Epoch: 6| Step: 3
Training loss: 1.3472392559051514
Validation loss: 2.0539799569755472

Epoch: 6| Step: 4
Training loss: 1.7456331253051758
Validation loss: 2.0691055841343378

Epoch: 6| Step: 5
Training loss: 1.181950330734253
Validation loss: 2.030048939489549

Epoch: 6| Step: 6
Training loss: 1.1433943510055542
Validation loss: 2.0369480194584018

Epoch: 6| Step: 7
Training loss: 1.1742234230041504
Validation loss: 2.041589529283585

Epoch: 6| Step: 8
Training loss: 1.8793470859527588
Validation loss: 2.035140588719358

Epoch: 6| Step: 9
Training loss: 1.776102900505066
Validation loss: 2.0451899484921525

Epoch: 6| Step: 10
Training loss: 1.2903354167938232
Validation loss: 2.0882972658321424

Epoch: 6| Step: 11
Training loss: 1.2709205150604248
Validation loss: 2.0164374202810307

Epoch: 6| Step: 12
Training loss: 1.3657770156860352
Validation loss: 2.0412015376552457

Epoch: 6| Step: 13
Training loss: 1.307761549949646
Validation loss: 2.01712861112369

Epoch: 512| Step: 0
Training loss: 1.4138712882995605
Validation loss: 2.0565398636684624

Epoch: 6| Step: 1
Training loss: 1.6325163841247559
Validation loss: 2.058396382998395

Epoch: 6| Step: 2
Training loss: 0.7618969678878784
Validation loss: 2.048683956105222

Epoch: 6| Step: 3
Training loss: 1.0413731336593628
Validation loss: 2.0536611080169678

Epoch: 6| Step: 4
Training loss: 1.2294962406158447
Validation loss: 2.084712461758685

Epoch: 6| Step: 5
Training loss: 1.907573938369751
Validation loss: 2.0361434439177155

Epoch: 6| Step: 6
Training loss: 1.9297679662704468
Validation loss: 2.0470465383222027

Epoch: 6| Step: 7
Training loss: 1.3477058410644531
Validation loss: 2.071807917728219

Epoch: 6| Step: 8
Training loss: 1.008488416671753
Validation loss: 2.0608753209472983

Epoch: 6| Step: 9
Training loss: 1.5863099098205566
Validation loss: 2.042383199097008

Epoch: 6| Step: 10
Training loss: 1.9104887247085571
Validation loss: 2.07868036659815

Epoch: 6| Step: 11
Training loss: 1.3590887784957886
Validation loss: 2.067169616299291

Epoch: 6| Step: 12
Training loss: 0.5280411839485168
Validation loss: 2.0809116940344534

Epoch: 6| Step: 13
Training loss: 1.635028600692749
Validation loss: 2.0777217098461684

Epoch: 513| Step: 0
Training loss: 1.2102583646774292
Validation loss: 2.0794272602245374

Epoch: 6| Step: 1
Training loss: 1.6798341274261475
Validation loss: 2.0601615008487495

Epoch: 6| Step: 2
Training loss: 0.7621941566467285
Validation loss: 2.0361054789635444

Epoch: 6| Step: 3
Training loss: 0.7576453685760498
Validation loss: 2.0437792936960855

Epoch: 6| Step: 4
Training loss: 1.4861023426055908
Validation loss: 1.9774350632903397

Epoch: 6| Step: 5
Training loss: 1.3302857875823975
Validation loss: 2.0350275014036443

Epoch: 6| Step: 6
Training loss: 1.6942541599273682
Validation loss: 1.9944002307871336

Epoch: 6| Step: 7
Training loss: 1.3583546876907349
Validation loss: 1.9909408271953624

Epoch: 6| Step: 8
Training loss: 1.0434534549713135
Validation loss: 2.0332073421888452

Epoch: 6| Step: 9
Training loss: 1.6810503005981445
Validation loss: 2.043671954062677

Epoch: 6| Step: 10
Training loss: 1.1517748832702637
Validation loss: 2.052755691671884

Epoch: 6| Step: 11
Training loss: 1.9828426837921143
Validation loss: 2.051712946225238

Epoch: 6| Step: 12
Training loss: 1.892746925354004
Validation loss: 2.0538289687966786

Epoch: 6| Step: 13
Training loss: 1.059169054031372
Validation loss: 2.0285136930404173

Epoch: 514| Step: 0
Training loss: 1.8802770376205444
Validation loss: 2.0387074306447017

Epoch: 6| Step: 1
Training loss: 1.0509612560272217
Validation loss: 2.0478118363247124

Epoch: 6| Step: 2
Training loss: 1.3780783414840698
Validation loss: 1.9965938855242986

Epoch: 6| Step: 3
Training loss: 0.7819592952728271
Validation loss: 2.0349876701190905

Epoch: 6| Step: 4
Training loss: 1.3790571689605713
Validation loss: 2.0258388506468905

Epoch: 6| Step: 5
Training loss: 1.4462230205535889
Validation loss: 2.0324026435934086

Epoch: 6| Step: 6
Training loss: 1.2963287830352783
Validation loss: 2.044755211440466

Epoch: 6| Step: 7
Training loss: 1.7781026363372803
Validation loss: 2.053238086802985

Epoch: 6| Step: 8
Training loss: 1.5507407188415527
Validation loss: 2.067304518914992

Epoch: 6| Step: 9
Training loss: 1.4691163301467896
Validation loss: 2.066788340127596

Epoch: 6| Step: 10
Training loss: 1.305662989616394
Validation loss: 2.0721737107922955

Epoch: 6| Step: 11
Training loss: 1.5129725933074951
Validation loss: 2.0185895427580802

Epoch: 6| Step: 12
Training loss: 1.0899677276611328
Validation loss: 2.05625940651022

Epoch: 6| Step: 13
Training loss: 1.3678157329559326
Validation loss: 2.0825321789710753

Epoch: 515| Step: 0
Training loss: 1.4291554689407349
Validation loss: 2.034919543932843

Epoch: 6| Step: 1
Training loss: 1.9055426120758057
Validation loss: 2.0833993675888225

Epoch: 6| Step: 2
Training loss: 1.2300300598144531
Validation loss: 2.065235371230751

Epoch: 6| Step: 3
Training loss: 1.0353891849517822
Validation loss: 2.0223795085824947

Epoch: 6| Step: 4
Training loss: 0.9265542030334473
Validation loss: 2.056142222496771

Epoch: 6| Step: 5
Training loss: 1.1008814573287964
Validation loss: 2.110785004913166

Epoch: 6| Step: 6
Training loss: 1.1191381216049194
Validation loss: 2.0628368059794107

Epoch: 6| Step: 7
Training loss: 1.442883014678955
Validation loss: 2.0398231142310688

Epoch: 6| Step: 8
Training loss: 1.4203490018844604
Validation loss: 2.0448901627653386

Epoch: 6| Step: 9
Training loss: 2.083043098449707
Validation loss: 2.03261492072895

Epoch: 6| Step: 10
Training loss: 1.1839408874511719
Validation loss: 2.043754718636954

Epoch: 6| Step: 11
Training loss: 1.162520170211792
Validation loss: 2.032119038284466

Epoch: 6| Step: 12
Training loss: 1.7426320314407349
Validation loss: 2.0652684575767926

Epoch: 6| Step: 13
Training loss: 1.07217538356781
Validation loss: 2.003887591823455

Epoch: 516| Step: 0
Training loss: 0.9751603007316589
Validation loss: 2.03468184573676

Epoch: 6| Step: 1
Training loss: 1.342621088027954
Validation loss: 2.063226984393212

Epoch: 6| Step: 2
Training loss: 1.169706106185913
Validation loss: 2.0786719655477874

Epoch: 6| Step: 3
Training loss: 1.800661325454712
Validation loss: 2.0718565499910744

Epoch: 6| Step: 4
Training loss: 1.3281548023223877
Validation loss: 2.0431635507973294

Epoch: 6| Step: 5
Training loss: 0.7486445903778076
Validation loss: 2.0931201929687173

Epoch: 6| Step: 6
Training loss: 1.8829798698425293
Validation loss: 2.0619881255652315

Epoch: 6| Step: 7
Training loss: 1.1098556518554688
Validation loss: 1.9830111790728826

Epoch: 6| Step: 8
Training loss: 1.5694469213485718
Validation loss: 2.029870911311078

Epoch: 6| Step: 9
Training loss: 1.7016921043395996
Validation loss: 2.0297058602815032

Epoch: 6| Step: 10
Training loss: 1.4507490396499634
Validation loss: 2.0529636721457205

Epoch: 6| Step: 11
Training loss: 1.2856873273849487
Validation loss: 2.0408224944145448

Epoch: 6| Step: 12
Training loss: 1.0123995542526245
Validation loss: 2.0163504538997525

Epoch: 6| Step: 13
Training loss: 1.983717441558838
Validation loss: 2.0524720825174803

Epoch: 517| Step: 0
Training loss: 1.8026983737945557
Validation loss: 2.047625434014105

Epoch: 6| Step: 1
Training loss: 0.40409204363822937
Validation loss: 2.0575080520363263

Epoch: 6| Step: 2
Training loss: 1.8144404888153076
Validation loss: 2.0266303682839997

Epoch: 6| Step: 3
Training loss: 1.440242052078247
Validation loss: 2.035399362605105

Epoch: 6| Step: 4
Training loss: 1.1863136291503906
Validation loss: 2.0084501081897366

Epoch: 6| Step: 5
Training loss: 1.0209026336669922
Validation loss: 2.048621495564779

Epoch: 6| Step: 6
Training loss: 1.0915093421936035
Validation loss: 2.077904610223668

Epoch: 6| Step: 7
Training loss: 1.3224507570266724
Validation loss: 2.049204821227699

Epoch: 6| Step: 8
Training loss: 1.560260534286499
Validation loss: 2.0466223865427

Epoch: 6| Step: 9
Training loss: 1.373236894607544
Validation loss: 2.0798444671015583

Epoch: 6| Step: 10
Training loss: 1.5568333864212036
Validation loss: 2.0424218664887133

Epoch: 6| Step: 11
Training loss: 1.705805778503418
Validation loss: 2.079997875357187

Epoch: 6| Step: 12
Training loss: 1.2864850759506226
Validation loss: 2.068122184404763

Epoch: 6| Step: 13
Training loss: 0.9524661302566528
Validation loss: 2.052800729710569

Epoch: 518| Step: 0
Training loss: 1.329959511756897
Validation loss: 2.0724511479818695

Epoch: 6| Step: 1
Training loss: 1.120766282081604
Validation loss: 2.027143238693155

Epoch: 6| Step: 2
Training loss: 0.90814208984375
Validation loss: 2.0644457263331257

Epoch: 6| Step: 3
Training loss: 0.8480178117752075
Validation loss: 2.035331904247243

Epoch: 6| Step: 4
Training loss: 1.5476130247116089
Validation loss: 1.9888088203245593

Epoch: 6| Step: 5
Training loss: 1.5113227367401123
Validation loss: 1.9989557125235116

Epoch: 6| Step: 6
Training loss: 2.0597405433654785
Validation loss: 2.061100903377738

Epoch: 6| Step: 7
Training loss: 1.6208196878433228
Validation loss: 2.0383544609110844

Epoch: 6| Step: 8
Training loss: 1.332123041152954
Validation loss: 2.0211452425167127

Epoch: 6| Step: 9
Training loss: 1.3699026107788086
Validation loss: 2.0754484079217397

Epoch: 6| Step: 10
Training loss: 1.3446611166000366
Validation loss: 2.031556071773652

Epoch: 6| Step: 11
Training loss: 1.468631625175476
Validation loss: 1.991474623321205

Epoch: 6| Step: 12
Training loss: 1.4446969032287598
Validation loss: 2.0317346818985476

Epoch: 6| Step: 13
Training loss: 1.1479911804199219
Validation loss: 2.0399158026582453

Epoch: 519| Step: 0
Training loss: 1.485601782798767
Validation loss: 2.036594636978642

Epoch: 6| Step: 1
Training loss: 1.4689679145812988
Validation loss: 2.036520652873542

Epoch: 6| Step: 2
Training loss: 1.6111760139465332
Validation loss: 2.0488967023869997

Epoch: 6| Step: 3
Training loss: 0.8587075471878052
Validation loss: 2.0428791264052033

Epoch: 6| Step: 4
Training loss: 0.9842421412467957
Validation loss: 2.037571373806205

Epoch: 6| Step: 5
Training loss: 1.1062111854553223
Validation loss: 2.0705309529458322

Epoch: 6| Step: 6
Training loss: 1.121652364730835
Validation loss: 2.0446000291455175

Epoch: 6| Step: 7
Training loss: 1.1336405277252197
Validation loss: 2.0544512553881575

Epoch: 6| Step: 8
Training loss: 1.0056241750717163
Validation loss: 2.036757555059207

Epoch: 6| Step: 9
Training loss: 2.047901153564453
Validation loss: 2.002535625170636

Epoch: 6| Step: 10
Training loss: 1.945756435394287
Validation loss: 2.036316511451557

Epoch: 6| Step: 11
Training loss: 1.6684516668319702
Validation loss: 2.0855510439924014

Epoch: 6| Step: 12
Training loss: 1.3496150970458984
Validation loss: 2.002962132935883

Epoch: 6| Step: 13
Training loss: 0.9467966556549072
Validation loss: 2.073017945853613

Epoch: 520| Step: 0
Training loss: 1.646129846572876
Validation loss: 2.0436274159339165

Epoch: 6| Step: 1
Training loss: 1.2268303632736206
Validation loss: 2.0434809923171997

Epoch: 6| Step: 2
Training loss: 1.8223650455474854
Validation loss: 2.0700276295344033

Epoch: 6| Step: 3
Training loss: 1.5271143913269043
Validation loss: 2.044738023511825

Epoch: 6| Step: 4
Training loss: 0.8372718095779419
Validation loss: 2.0636043266583513

Epoch: 6| Step: 5
Training loss: 1.8172311782836914
Validation loss: 2.0167261656894477

Epoch: 6| Step: 6
Training loss: 1.2413026094436646
Validation loss: 2.0834978793257024

Epoch: 6| Step: 7
Training loss: 0.8987681865692139
Validation loss: 2.0310276323749172

Epoch: 6| Step: 8
Training loss: 1.6766778230667114
Validation loss: 2.082396852072849

Epoch: 6| Step: 9
Training loss: 0.9419904947280884
Validation loss: 2.0700358075480305

Epoch: 6| Step: 10
Training loss: 1.121279239654541
Validation loss: 2.048140564272481

Epoch: 6| Step: 11
Training loss: 1.7826433181762695
Validation loss: 2.040810772167739

Epoch: 6| Step: 12
Training loss: 1.0951350927352905
Validation loss: 1.9794689698885846

Epoch: 6| Step: 13
Training loss: 2.004591941833496
Validation loss: 2.02455352070511

Epoch: 521| Step: 0
Training loss: 1.4019432067871094
Validation loss: 2.02630945944017

Epoch: 6| Step: 1
Training loss: 1.3672478199005127
Validation loss: 2.0466792762920423

Epoch: 6| Step: 2
Training loss: 1.35654616355896
Validation loss: 2.0314688528737714

Epoch: 6| Step: 3
Training loss: 1.5658292770385742
Validation loss: 2.073720177014669

Epoch: 6| Step: 4
Training loss: 2.0972113609313965
Validation loss: 2.0782435940157984

Epoch: 6| Step: 5
Training loss: 0.6540670990943909
Validation loss: 2.1221533603565668

Epoch: 6| Step: 6
Training loss: 1.1671645641326904
Validation loss: 2.067023079882386

Epoch: 6| Step: 7
Training loss: 1.40086829662323
Validation loss: 2.0729418826359574

Epoch: 6| Step: 8
Training loss: 1.7525302171707153
Validation loss: 2.0580914802448724

Epoch: 6| Step: 9
Training loss: 1.55086088180542
Validation loss: 2.0749998682288715

Epoch: 6| Step: 10
Training loss: 1.2069342136383057
Validation loss: 2.056460178026589

Epoch: 6| Step: 11
Training loss: 1.2774531841278076
Validation loss: 2.0541395500142086

Epoch: 6| Step: 12
Training loss: 1.2798384428024292
Validation loss: 2.0210701163097093

Epoch: 6| Step: 13
Training loss: 1.084069848060608
Validation loss: 2.0455726949117516

Epoch: 522| Step: 0
Training loss: 1.166443943977356
Validation loss: 2.0598357005785872

Epoch: 6| Step: 1
Training loss: 1.8856124877929688
Validation loss: 2.0041733595632736

Epoch: 6| Step: 2
Training loss: 1.652762532234192
Validation loss: 2.040776037400769

Epoch: 6| Step: 3
Training loss: 1.5027530193328857
Validation loss: 2.0679236804285357

Epoch: 6| Step: 4
Training loss: 1.31391179561615
Validation loss: 2.048250667510494

Epoch: 6| Step: 5
Training loss: 1.4675743579864502
Validation loss: 2.096339919233835

Epoch: 6| Step: 6
Training loss: 0.9270918369293213
Validation loss: 2.0574519262518933

Epoch: 6| Step: 7
Training loss: 1.9477906227111816
Validation loss: 2.0461513701305596

Epoch: 6| Step: 8
Training loss: 1.523625135421753
Validation loss: 2.0326200172465336

Epoch: 6| Step: 9
Training loss: 1.0767383575439453
Validation loss: 2.0709208083409134

Epoch: 6| Step: 10
Training loss: 1.3935596942901611
Validation loss: 2.0619495402100267

Epoch: 6| Step: 11
Training loss: 0.6787582635879517
Validation loss: 2.0473983800539406

Epoch: 6| Step: 12
Training loss: 1.1818718910217285
Validation loss: 2.029937988968306

Epoch: 6| Step: 13
Training loss: 1.8230531215667725
Validation loss: 2.0519515493864655

Epoch: 523| Step: 0
Training loss: 1.2507894039154053
Validation loss: 2.0284301247648013

Epoch: 6| Step: 1
Training loss: 1.2829577922821045
Validation loss: 2.0042415600951

Epoch: 6| Step: 2
Training loss: 1.3528337478637695
Validation loss: 2.081073289276451

Epoch: 6| Step: 3
Training loss: 1.7146693468093872
Validation loss: 2.0162922797664518

Epoch: 6| Step: 4
Training loss: 1.3222122192382812
Validation loss: 2.0355797993239535

Epoch: 6| Step: 5
Training loss: 1.6392977237701416
Validation loss: 2.040294801035235

Epoch: 6| Step: 6
Training loss: 1.2592015266418457
Validation loss: 2.078369963553644

Epoch: 6| Step: 7
Training loss: 1.59623384475708
Validation loss: 2.0417557044695784

Epoch: 6| Step: 8
Training loss: 1.1856695413589478
Validation loss: 2.0546635479055424

Epoch: 6| Step: 9
Training loss: 1.1721272468566895
Validation loss: 2.0346931924102125

Epoch: 6| Step: 10
Training loss: 1.4561794996261597
Validation loss: 2.0082881630107923

Epoch: 6| Step: 11
Training loss: 1.103529691696167
Validation loss: 2.0275871176873483

Epoch: 6| Step: 12
Training loss: 1.1843311786651611
Validation loss: 2.0802785555521646

Epoch: 6| Step: 13
Training loss: 1.667252779006958
Validation loss: 2.0551384751514723

Epoch: 524| Step: 0
Training loss: 1.7353193759918213
Validation loss: 2.035319969218264

Epoch: 6| Step: 1
Training loss: 1.5220670700073242
Validation loss: 2.0856759291823193

Epoch: 6| Step: 2
Training loss: 1.573190689086914
Validation loss: 2.0724099131040674

Epoch: 6| Step: 3
Training loss: 0.978718638420105
Validation loss: 2.0490904623462307

Epoch: 6| Step: 4
Training loss: 1.2253211736679077
Validation loss: 2.0777063164659726

Epoch: 6| Step: 5
Training loss: 1.3268756866455078
Validation loss: 2.0247063585506972

Epoch: 6| Step: 6
Training loss: 1.1901860237121582
Validation loss: 2.0517652316759993

Epoch: 6| Step: 7
Training loss: 1.2327841520309448
Validation loss: 2.0927422149207002

Epoch: 6| Step: 8
Training loss: 1.5216915607452393
Validation loss: 2.055680133963144

Epoch: 6| Step: 9
Training loss: 1.756048321723938
Validation loss: 2.0403404851113596

Epoch: 6| Step: 10
Training loss: 1.6235790252685547
Validation loss: 2.078529921911096

Epoch: 6| Step: 11
Training loss: 1.1936020851135254
Validation loss: 2.033487145618726

Epoch: 6| Step: 12
Training loss: 0.8065441250801086
Validation loss: 2.0479486244981007

Epoch: 6| Step: 13
Training loss: 1.104878306388855
Validation loss: 2.0598229362118627

Epoch: 525| Step: 0
Training loss: 1.9099583625793457
Validation loss: 2.03948220129936

Epoch: 6| Step: 1
Training loss: 1.1595027446746826
Validation loss: 2.0522235285851265

Epoch: 6| Step: 2
Training loss: 1.4418110847473145
Validation loss: 2.0478550714831196

Epoch: 6| Step: 3
Training loss: 0.8741892576217651
Validation loss: 2.1074222095551027

Epoch: 6| Step: 4
Training loss: 1.3609464168548584
Validation loss: 2.076547211216342

Epoch: 6| Step: 5
Training loss: 1.2210193872451782
Validation loss: 2.0290200966660694

Epoch: 6| Step: 6
Training loss: 1.6928168535232544
Validation loss: 2.057095032866283

Epoch: 6| Step: 7
Training loss: 1.6928421258926392
Validation loss: 2.0613298454592304

Epoch: 6| Step: 8
Training loss: 1.0875530242919922
Validation loss: 1.9985005778651084

Epoch: 6| Step: 9
Training loss: 1.154850959777832
Validation loss: 2.0060509789374565

Epoch: 6| Step: 10
Training loss: 1.3362962007522583
Validation loss: 2.055775797495278

Epoch: 6| Step: 11
Training loss: 1.4005115032196045
Validation loss: 2.0486580197529127

Epoch: 6| Step: 12
Training loss: 1.390758991241455
Validation loss: 2.063203029735114

Epoch: 6| Step: 13
Training loss: 1.0264227390289307
Validation loss: 2.04837784459514

Epoch: 526| Step: 0
Training loss: 1.0803852081298828
Validation loss: 2.0340136533142417

Epoch: 6| Step: 1
Training loss: 1.3230564594268799
Validation loss: 2.030449216083814

Epoch: 6| Step: 2
Training loss: 1.6707851886749268
Validation loss: 2.0889778034661406

Epoch: 6| Step: 3
Training loss: 1.7632622718811035
Validation loss: 2.043639229189965

Epoch: 6| Step: 4
Training loss: 1.0554063320159912
Validation loss: 2.062092370884393

Epoch: 6| Step: 5
Training loss: 1.1167669296264648
Validation loss: 2.0386316801912043

Epoch: 6| Step: 6
Training loss: 1.2111682891845703
Validation loss: 2.032945720098352

Epoch: 6| Step: 7
Training loss: 1.3606537580490112
Validation loss: 2.0254445793808147

Epoch: 6| Step: 8
Training loss: 1.3699002265930176
Validation loss: 2.0768397533765404

Epoch: 6| Step: 9
Training loss: 1.066076397895813
Validation loss: 2.0478526725563952

Epoch: 6| Step: 10
Training loss: 1.1844069957733154
Validation loss: 2.042660677304832

Epoch: 6| Step: 11
Training loss: 1.926609992980957
Validation loss: 2.075466325206141

Epoch: 6| Step: 12
Training loss: 1.2646493911743164
Validation loss: 2.060620948832522

Epoch: 6| Step: 13
Training loss: 1.452746033668518
Validation loss: 2.0620580437362834

Epoch: 527| Step: 0
Training loss: 0.9384490847587585
Validation loss: 2.056291054653865

Epoch: 6| Step: 1
Training loss: 1.472653865814209
Validation loss: 2.048922815630513

Epoch: 6| Step: 2
Training loss: 1.217577338218689
Validation loss: 2.0658088730227564

Epoch: 6| Step: 3
Training loss: 1.6353904008865356
Validation loss: 2.0469451745351157

Epoch: 6| Step: 4
Training loss: 1.374197006225586
Validation loss: 2.070924997329712

Epoch: 6| Step: 5
Training loss: 0.8387017250061035
Validation loss: 2.0512363936311457

Epoch: 6| Step: 6
Training loss: 1.77040696144104
Validation loss: 2.0487239386445735

Epoch: 6| Step: 7
Training loss: 1.4854791164398193
Validation loss: 2.0906751527581164

Epoch: 6| Step: 8
Training loss: 1.0710382461547852
Validation loss: 2.0950249638608707

Epoch: 6| Step: 9
Training loss: 1.9885971546173096
Validation loss: 2.055664711101081

Epoch: 6| Step: 10
Training loss: 1.3076508045196533
Validation loss: 2.0261169172102407

Epoch: 6| Step: 11
Training loss: 1.3848893642425537
Validation loss: 2.109321125092045

Epoch: 6| Step: 12
Training loss: 0.9529438614845276
Validation loss: 2.02828029406968

Epoch: 6| Step: 13
Training loss: 1.4623351097106934
Validation loss: 2.0666153046392624

Epoch: 528| Step: 0
Training loss: 2.1633472442626953
Validation loss: 2.0477099405821932

Epoch: 6| Step: 1
Training loss: 1.7121670246124268
Validation loss: 2.0254156820235716

Epoch: 6| Step: 2
Training loss: 1.5425841808319092
Validation loss: 2.029976664050933

Epoch: 6| Step: 3
Training loss: 0.7836688756942749
Validation loss: 2.013975756142729

Epoch: 6| Step: 4
Training loss: 1.386756181716919
Validation loss: 2.0478424718303065

Epoch: 6| Step: 5
Training loss: 1.4183452129364014
Validation loss: 2.055832180925595

Epoch: 6| Step: 6
Training loss: 1.0140841007232666
Validation loss: 2.054827651669902

Epoch: 6| Step: 7
Training loss: 1.7101505994796753
Validation loss: 2.0587828236241497

Epoch: 6| Step: 8
Training loss: 1.448395848274231
Validation loss: 2.095595273920285

Epoch: 6| Step: 9
Training loss: 1.0651612281799316
Validation loss: 2.064772959678404

Epoch: 6| Step: 10
Training loss: 1.4293880462646484
Validation loss: 2.0482459017025527

Epoch: 6| Step: 11
Training loss: 1.1779165267944336
Validation loss: 2.1048661739595476

Epoch: 6| Step: 12
Training loss: 1.0731035470962524
Validation loss: 2.111889082898376

Epoch: 6| Step: 13
Training loss: 1.0340601205825806
Validation loss: 2.054493091439688

Epoch: 529| Step: 0
Training loss: 0.9004230499267578
Validation loss: 2.0772152229021956

Epoch: 6| Step: 1
Training loss: 1.1300950050354004
Validation loss: 2.065845271592499

Epoch: 6| Step: 2
Training loss: 1.3985464572906494
Validation loss: 2.0260921793599285

Epoch: 6| Step: 3
Training loss: 1.8901879787445068
Validation loss: 2.020740100132522

Epoch: 6| Step: 4
Training loss: 1.6416587829589844
Validation loss: 2.0261497087376092

Epoch: 6| Step: 5
Training loss: 0.8104289770126343
Validation loss: 2.031765357140572

Epoch: 6| Step: 6
Training loss: 1.5983805656433105
Validation loss: 2.048042328126969

Epoch: 6| Step: 7
Training loss: 1.4075583219528198
Validation loss: 2.047509783057756

Epoch: 6| Step: 8
Training loss: 1.8594067096710205
Validation loss: 2.0337941108211393

Epoch: 6| Step: 9
Training loss: 1.3640767335891724
Validation loss: 2.0654066070433585

Epoch: 6| Step: 10
Training loss: 1.2353131771087646
Validation loss: 2.0320075199168217

Epoch: 6| Step: 11
Training loss: 1.34231436252594
Validation loss: 2.0564048943981046

Epoch: 6| Step: 12
Training loss: 1.1176947355270386
Validation loss: 2.0203473439780613

Epoch: 6| Step: 13
Training loss: 1.4745277166366577
Validation loss: 2.088689816895352

Epoch: 530| Step: 0
Training loss: 1.1557209491729736
Validation loss: 2.069365632149481

Epoch: 6| Step: 1
Training loss: 1.783732533454895
Validation loss: 2.0981865685473204

Epoch: 6| Step: 2
Training loss: 1.7153562307357788
Validation loss: 2.083784129029961

Epoch: 6| Step: 3
Training loss: 0.8916975259780884
Validation loss: 2.0325705441095496

Epoch: 6| Step: 4
Training loss: 1.052079439163208
Validation loss: 2.0644336874767015

Epoch: 6| Step: 5
Training loss: 0.9718810319900513
Validation loss: 2.0834814976620417

Epoch: 6| Step: 6
Training loss: 1.2937917709350586
Validation loss: 2.048787251595528

Epoch: 6| Step: 7
Training loss: 1.3990930318832397
Validation loss: 2.0591617732919674

Epoch: 6| Step: 8
Training loss: 1.456193447113037
Validation loss: 2.0196754291493404

Epoch: 6| Step: 9
Training loss: 1.2618310451507568
Validation loss: 2.0261128307670675

Epoch: 6| Step: 10
Training loss: 1.1264042854309082
Validation loss: 2.071487117839116

Epoch: 6| Step: 11
Training loss: 1.9044685363769531
Validation loss: 2.046785214895843

Epoch: 6| Step: 12
Training loss: 0.953935980796814
Validation loss: 2.074909817787909

Epoch: 6| Step: 13
Training loss: 2.3893144130706787
Validation loss: 2.0756355665063344

Epoch: 531| Step: 0
Training loss: 0.9089215397834778
Validation loss: 2.051994336548672

Epoch: 6| Step: 1
Training loss: 1.8641750812530518
Validation loss: 2.0357291108818463

Epoch: 6| Step: 2
Training loss: 1.2524662017822266
Validation loss: 2.0444472310363606

Epoch: 6| Step: 3
Training loss: 1.2182457447052002
Validation loss: 2.030694907711398

Epoch: 6| Step: 4
Training loss: 1.7866170406341553
Validation loss: 2.0491312485869213

Epoch: 6| Step: 5
Training loss: 1.535442590713501
Validation loss: 2.0232397087158693

Epoch: 6| Step: 6
Training loss: 1.0986846685409546
Validation loss: 2.0268178588600567

Epoch: 6| Step: 7
Training loss: 1.1156909465789795
Validation loss: 2.0573404860752884

Epoch: 6| Step: 8
Training loss: 1.6964471340179443
Validation loss: 2.015809666725897

Epoch: 6| Step: 9
Training loss: 1.3411552906036377
Validation loss: 2.037314502141809

Epoch: 6| Step: 10
Training loss: 1.180485486984253
Validation loss: 2.0257541851330827

Epoch: 6| Step: 11
Training loss: 1.0981781482696533
Validation loss: 2.0446864738259265

Epoch: 6| Step: 12
Training loss: 1.2868844270706177
Validation loss: 2.0593060972870036

Epoch: 6| Step: 13
Training loss: 1.2797449827194214
Validation loss: 2.016289339270643

Epoch: 532| Step: 0
Training loss: 1.7357131242752075
Validation loss: 2.0282633484050794

Epoch: 6| Step: 1
Training loss: 1.492221713066101
Validation loss: 2.114767528349353

Epoch: 6| Step: 2
Training loss: 1.1992781162261963
Validation loss: 2.0550279155854256

Epoch: 6| Step: 3
Training loss: 0.8386095762252808
Validation loss: 2.053702913304811

Epoch: 6| Step: 4
Training loss: 1.7768666744232178
Validation loss: 2.0591611605818554

Epoch: 6| Step: 5
Training loss: 1.4648970365524292
Validation loss: 2.0624847822291876

Epoch: 6| Step: 6
Training loss: 1.0301198959350586
Validation loss: 2.0684298033355386

Epoch: 6| Step: 7
Training loss: 1.0401582717895508
Validation loss: 2.0543216005448373

Epoch: 6| Step: 8
Training loss: 1.4429774284362793
Validation loss: 2.071496968628258

Epoch: 6| Step: 9
Training loss: 1.52964448928833
Validation loss: 2.063085671394102

Epoch: 6| Step: 10
Training loss: 1.3434638977050781
Validation loss: 2.0439578640845513

Epoch: 6| Step: 11
Training loss: 1.3365885019302368
Validation loss: 2.0958632294849684

Epoch: 6| Step: 12
Training loss: 1.4358264207839966
Validation loss: 2.0668667054945424

Epoch: 6| Step: 13
Training loss: 0.9665234088897705
Validation loss: 2.0465781278507684

Epoch: 533| Step: 0
Training loss: 0.9881001710891724
Validation loss: 2.0479061372818483

Epoch: 6| Step: 1
Training loss: 1.4325124025344849
Validation loss: 2.0816666785106865

Epoch: 6| Step: 2
Training loss: 1.1266355514526367
Validation loss: 2.0234138837424656

Epoch: 6| Step: 3
Training loss: 1.2321343421936035
Validation loss: 2.0542442208977154

Epoch: 6| Step: 4
Training loss: 0.9444758892059326
Validation loss: 2.0368390032040176

Epoch: 6| Step: 5
Training loss: 1.736842155456543
Validation loss: 2.0646986935728338

Epoch: 6| Step: 6
Training loss: 1.4296956062316895
Validation loss: 2.038483847853958

Epoch: 6| Step: 7
Training loss: 0.8734965324401855
Validation loss: 2.0605727908431843

Epoch: 6| Step: 8
Training loss: 1.3610838651657104
Validation loss: 2.057500969979071

Epoch: 6| Step: 9
Training loss: 1.7639981508255005
Validation loss: 2.022604291157056

Epoch: 6| Step: 10
Training loss: 1.1083086729049683
Validation loss: 2.0471373347825903

Epoch: 6| Step: 11
Training loss: 1.8326923847198486
Validation loss: 2.059248585854807

Epoch: 6| Step: 12
Training loss: 1.4136853218078613
Validation loss: 2.018792195986676

Epoch: 6| Step: 13
Training loss: 1.7998144626617432
Validation loss: 2.0010894895881735

Epoch: 534| Step: 0
Training loss: 1.125150442123413
Validation loss: 2.050880252674062

Epoch: 6| Step: 1
Training loss: 0.8199030160903931
Validation loss: 2.052281302790488

Epoch: 6| Step: 2
Training loss: 2.0832877159118652
Validation loss: 2.045467322872531

Epoch: 6| Step: 3
Training loss: 2.0416650772094727
Validation loss: 2.0416110151557514

Epoch: 6| Step: 4
Training loss: 1.4872138500213623
Validation loss: 2.071950286947271

Epoch: 6| Step: 5
Training loss: 1.9783227443695068
Validation loss: 2.0753654510744157

Epoch: 6| Step: 6
Training loss: 1.3771119117736816
Validation loss: 2.1196183158505346

Epoch: 6| Step: 7
Training loss: 1.266206979751587
Validation loss: 2.086935648354151

Epoch: 6| Step: 8
Training loss: 1.321866512298584
Validation loss: 2.0808355513439385

Epoch: 6| Step: 9
Training loss: 1.2175103425979614
Validation loss: 2.0430906895668275

Epoch: 6| Step: 10
Training loss: 1.105154275894165
Validation loss: 2.017460230217185

Epoch: 6| Step: 11
Training loss: 0.8836596012115479
Validation loss: 2.0398588116450975

Epoch: 6| Step: 12
Training loss: 1.0355262756347656
Validation loss: 2.042856793249807

Epoch: 6| Step: 13
Training loss: 1.044487476348877
Validation loss: 2.0793889748152865

Epoch: 535| Step: 0
Training loss: 2.0481314659118652
Validation loss: 2.02338905231927

Epoch: 6| Step: 1
Training loss: 1.5801557302474976
Validation loss: 2.015213544650744

Epoch: 6| Step: 2
Training loss: 0.792327344417572
Validation loss: 2.056267471723659

Epoch: 6| Step: 3
Training loss: 1.6833953857421875
Validation loss: 2.0676814497158094

Epoch: 6| Step: 4
Training loss: 0.8474472761154175
Validation loss: 2.020051961304039

Epoch: 6| Step: 5
Training loss: 1.1802430152893066
Validation loss: 2.0456657127667497

Epoch: 6| Step: 6
Training loss: 1.0296465158462524
Validation loss: 2.0362236704877628

Epoch: 6| Step: 7
Training loss: 1.9348760843276978
Validation loss: 2.053138473982452

Epoch: 6| Step: 8
Training loss: 1.4387714862823486
Validation loss: 2.0334228854025564

Epoch: 6| Step: 9
Training loss: 1.639836072921753
Validation loss: 2.079751431301076

Epoch: 6| Step: 10
Training loss: 1.5906344652175903
Validation loss: 2.06928357514002

Epoch: 6| Step: 11
Training loss: 1.1107203960418701
Validation loss: 2.05455728115574

Epoch: 6| Step: 12
Training loss: 0.802650511264801
Validation loss: 2.079088203368648

Epoch: 6| Step: 13
Training loss: 1.2448776960372925
Validation loss: 2.0443780922120616

Epoch: 536| Step: 0
Training loss: 1.2108410596847534
Validation loss: 2.054004176970451

Epoch: 6| Step: 1
Training loss: 2.160402774810791
Validation loss: 2.0292761736018683

Epoch: 6| Step: 2
Training loss: 1.2485086917877197
Validation loss: 2.050568308881534

Epoch: 6| Step: 3
Training loss: 0.8467464447021484
Validation loss: 2.1094805027848933

Epoch: 6| Step: 4
Training loss: 1.2062512636184692
Validation loss: 2.0738132820334485

Epoch: 6| Step: 5
Training loss: 1.5327610969543457
Validation loss: 2.067490102142416

Epoch: 6| Step: 6
Training loss: 1.179398775100708
Validation loss: 2.0745631584557156

Epoch: 6| Step: 7
Training loss: 1.0221092700958252
Validation loss: 2.054572961663687

Epoch: 6| Step: 8
Training loss: 1.4225471019744873
Validation loss: 2.0414430108121646

Epoch: 6| Step: 9
Training loss: 1.3521937131881714
Validation loss: 2.0514386482136224

Epoch: 6| Step: 10
Training loss: 1.6528899669647217
Validation loss: 2.0398478802814277

Epoch: 6| Step: 11
Training loss: 1.4019185304641724
Validation loss: 2.065656114650029

Epoch: 6| Step: 12
Training loss: 1.342229962348938
Validation loss: 2.072722145306167

Epoch: 6| Step: 13
Training loss: 1.2278094291687012
Validation loss: 2.0635853146993988

Epoch: 537| Step: 0
Training loss: 1.489135503768921
Validation loss: 2.0398330150112027

Epoch: 6| Step: 1
Training loss: 1.6265888214111328
Validation loss: 2.08054099031674

Epoch: 6| Step: 2
Training loss: 1.3433949947357178
Validation loss: 2.0483598145105506

Epoch: 6| Step: 3
Training loss: 1.119917631149292
Validation loss: 2.0603531060680265

Epoch: 6| Step: 4
Training loss: 1.830331802368164
Validation loss: 2.052732780415525

Epoch: 6| Step: 5
Training loss: 0.7188713550567627
Validation loss: 2.0522044166441886

Epoch: 6| Step: 6
Training loss: 1.4028615951538086
Validation loss: 2.0221998524922196

Epoch: 6| Step: 7
Training loss: 1.2363771200180054
Validation loss: 2.0531400813851306

Epoch: 6| Step: 8
Training loss: 1.4854354858398438
Validation loss: 2.0865359331971858

Epoch: 6| Step: 9
Training loss: 1.7755146026611328
Validation loss: 2.103098882141934

Epoch: 6| Step: 10
Training loss: 1.440431833267212
Validation loss: 2.0453467676716466

Epoch: 6| Step: 11
Training loss: 1.2429208755493164
Validation loss: 2.0214105575315413

Epoch: 6| Step: 12
Training loss: 0.8371570110321045
Validation loss: 2.056147618960309

Epoch: 6| Step: 13
Training loss: 1.2748141288757324
Validation loss: 2.04547631356024

Epoch: 538| Step: 0
Training loss: 1.043716311454773
Validation loss: 2.055073058733376

Epoch: 6| Step: 1
Training loss: 1.4198064804077148
Validation loss: 2.036277259549787

Epoch: 6| Step: 2
Training loss: 1.1010680198669434
Validation loss: 2.0906916690129105

Epoch: 6| Step: 3
Training loss: 1.3149055242538452
Validation loss: 2.040681473670467

Epoch: 6| Step: 4
Training loss: 1.0519589185714722
Validation loss: 2.0236135272569555

Epoch: 6| Step: 5
Training loss: 1.4728503227233887
Validation loss: 2.0652297132758686

Epoch: 6| Step: 6
Training loss: 1.4819186925888062
Validation loss: 2.0245744259126726

Epoch: 6| Step: 7
Training loss: 1.37888765335083
Validation loss: 2.0601138812239452

Epoch: 6| Step: 8
Training loss: 1.7819385528564453
Validation loss: 2.060350038672006

Epoch: 6| Step: 9
Training loss: 1.3530402183532715
Validation loss: 2.047022411900182

Epoch: 6| Step: 10
Training loss: 1.5730059146881104
Validation loss: 2.0321396614915583

Epoch: 6| Step: 11
Training loss: 1.4693872928619385
Validation loss: 2.037422328866938

Epoch: 6| Step: 12
Training loss: 1.061262607574463
Validation loss: 2.0868465515875045

Epoch: 6| Step: 13
Training loss: 1.548567295074463
Validation loss: 2.026250872560727

Epoch: 539| Step: 0
Training loss: 1.0807877779006958
Validation loss: 2.035854447272516

Epoch: 6| Step: 1
Training loss: 1.540524959564209
Validation loss: 2.030986608997468

Epoch: 6| Step: 2
Training loss: 1.320084810256958
Validation loss: 2.052985240054387

Epoch: 6| Step: 3
Training loss: 1.2084110975265503
Validation loss: 2.0649555447281047

Epoch: 6| Step: 4
Training loss: 1.2142691612243652
Validation loss: 2.0047014438977806

Epoch: 6| Step: 5
Training loss: 1.5308783054351807
Validation loss: 2.0819155118798696

Epoch: 6| Step: 6
Training loss: 1.9864835739135742
Validation loss: 2.077874304145895

Epoch: 6| Step: 7
Training loss: 0.8708622455596924
Validation loss: 2.0582196071583736

Epoch: 6| Step: 8
Training loss: 1.4757188558578491
Validation loss: 2.0708998428877963

Epoch: 6| Step: 9
Training loss: 1.2129769325256348
Validation loss: 2.055528845838321

Epoch: 6| Step: 10
Training loss: 1.205113410949707
Validation loss: 1.9968047744484358

Epoch: 6| Step: 11
Training loss: 1.4896212816238403
Validation loss: 2.0328850335972284

Epoch: 6| Step: 12
Training loss: 1.6063761711120605
Validation loss: 2.04499710887991

Epoch: 6| Step: 13
Training loss: 0.6963591575622559
Validation loss: 2.043401129784123

Epoch: 540| Step: 0
Training loss: 1.443194031715393
Validation loss: 2.0405312430474067

Epoch: 6| Step: 1
Training loss: 1.2520824670791626
Validation loss: 2.0593370186385287

Epoch: 6| Step: 2
Training loss: 1.012817621231079
Validation loss: 2.0528376640812045

Epoch: 6| Step: 3
Training loss: 2.0215373039245605
Validation loss: 2.041767244697899

Epoch: 6| Step: 4
Training loss: 1.3563232421875
Validation loss: 2.0295207782458236

Epoch: 6| Step: 5
Training loss: 0.8858170509338379
Validation loss: 2.061228544481339

Epoch: 6| Step: 6
Training loss: 1.8292794227600098
Validation loss: 2.059347176423637

Epoch: 6| Step: 7
Training loss: 1.253167748451233
Validation loss: 2.0653855492991786

Epoch: 6| Step: 8
Training loss: 1.3208681344985962
Validation loss: 2.055864498179446

Epoch: 6| Step: 9
Training loss: 1.0645557641983032
Validation loss: 2.069127162297567

Epoch: 6| Step: 10
Training loss: 1.399352788925171
Validation loss: 2.0573058897449124

Epoch: 6| Step: 11
Training loss: 1.4547240734100342
Validation loss: 2.072044572522563

Epoch: 6| Step: 12
Training loss: 0.8095127940177917
Validation loss: 2.037917037164011

Epoch: 6| Step: 13
Training loss: 1.3555811643600464
Validation loss: 2.0676203825140513

Epoch: 541| Step: 0
Training loss: 1.267676591873169
Validation loss: 2.007553321059032

Epoch: 6| Step: 1
Training loss: 1.5531518459320068
Validation loss: 2.019415613143675

Epoch: 6| Step: 2
Training loss: 1.2352882623672485
Validation loss: 2.015453642414462

Epoch: 6| Step: 3
Training loss: 1.6058179140090942
Validation loss: 2.036755620792348

Epoch: 6| Step: 4
Training loss: 1.6146459579467773
Validation loss: 2.047292701659664

Epoch: 6| Step: 5
Training loss: 0.9223494529724121
Validation loss: 2.0383830993406233

Epoch: 6| Step: 6
Training loss: 1.221582293510437
Validation loss: 2.0721950274641796

Epoch: 6| Step: 7
Training loss: 1.2667038440704346
Validation loss: 2.0746260189240977

Epoch: 6| Step: 8
Training loss: 1.350725769996643
Validation loss: 2.005711136325713

Epoch: 6| Step: 9
Training loss: 1.1379027366638184
Validation loss: 2.080997331168062

Epoch: 6| Step: 10
Training loss: 1.705308198928833
Validation loss: 2.0518214676969793

Epoch: 6| Step: 11
Training loss: 1.628067970275879
Validation loss: 2.055085712863553

Epoch: 6| Step: 12
Training loss: 1.2681729793548584
Validation loss: 2.0318272152254657

Epoch: 6| Step: 13
Training loss: 0.9659087657928467
Validation loss: 2.0406482027423

Epoch: 542| Step: 0
Training loss: 1.388502597808838
Validation loss: 2.07383543445218

Epoch: 6| Step: 1
Training loss: 1.032353162765503
Validation loss: 2.049971748423833

Epoch: 6| Step: 2
Training loss: 1.684285283088684
Validation loss: 2.064824950310492

Epoch: 6| Step: 3
Training loss: 1.3533966541290283
Validation loss: 2.066561757877309

Epoch: 6| Step: 4
Training loss: 1.2793011665344238
Validation loss: 2.081569931840384

Epoch: 6| Step: 5
Training loss: 1.6995875835418701
Validation loss: 2.072772163216786

Epoch: 6| Step: 6
Training loss: 1.1794939041137695
Validation loss: 2.063590180489325

Epoch: 6| Step: 7
Training loss: 1.6827027797698975
Validation loss: 2.043917066307478

Epoch: 6| Step: 8
Training loss: 0.9395694136619568
Validation loss: 2.0581940822703864

Epoch: 6| Step: 9
Training loss: 0.7953090667724609
Validation loss: 2.0636480021220382

Epoch: 6| Step: 10
Training loss: 1.519058346748352
Validation loss: 2.042860884820261

Epoch: 6| Step: 11
Training loss: 0.7247157096862793
Validation loss: 2.054693583519228

Epoch: 6| Step: 12
Training loss: 1.6979329586029053
Validation loss: 2.0245953388111566

Epoch: 6| Step: 13
Training loss: 1.322857141494751
Validation loss: 2.0585805767325946

Epoch: 543| Step: 0
Training loss: 1.1940343379974365
Validation loss: 2.0345687584210466

Epoch: 6| Step: 1
Training loss: 1.2790688276290894
Validation loss: 2.0436249907298754

Epoch: 6| Step: 2
Training loss: 1.2671465873718262
Validation loss: 2.0901885417199906

Epoch: 6| Step: 3
Training loss: 1.8701019287109375
Validation loss: 2.034915775381109

Epoch: 6| Step: 4
Training loss: 1.6704376935958862
Validation loss: 2.029614783102466

Epoch: 6| Step: 5
Training loss: 1.492032766342163
Validation loss: 2.0433913969224498

Epoch: 6| Step: 6
Training loss: 1.3601139783859253
Validation loss: 2.0462880442219396

Epoch: 6| Step: 7
Training loss: 0.8228029012680054
Validation loss: 2.0898158396444013

Epoch: 6| Step: 8
Training loss: 1.3205658197402954
Validation loss: 2.052728545281195

Epoch: 6| Step: 9
Training loss: 0.9453127980232239
Validation loss: 2.083459267052271

Epoch: 6| Step: 10
Training loss: 0.8741861581802368
Validation loss: 2.078926278698829

Epoch: 6| Step: 11
Training loss: 1.1015114784240723
Validation loss: 2.0902421910275697

Epoch: 6| Step: 12
Training loss: 1.5444672107696533
Validation loss: 2.0770560310732935

Epoch: 6| Step: 13
Training loss: 2.4076337814331055
Validation loss: 2.0391051743620183

Epoch: 544| Step: 0
Training loss: 1.6531505584716797
Validation loss: 2.0864540171879593

Epoch: 6| Step: 1
Training loss: 1.6813502311706543
Validation loss: 2.080506311308953

Epoch: 6| Step: 2
Training loss: 1.662784457206726
Validation loss: 2.0188502573197886

Epoch: 6| Step: 3
Training loss: 1.2116034030914307
Validation loss: 2.0623727511334162

Epoch: 6| Step: 4
Training loss: 1.3377318382263184
Validation loss: 2.0502918817663707

Epoch: 6| Step: 5
Training loss: 0.8939536809921265
Validation loss: 2.0590065640787922

Epoch: 6| Step: 6
Training loss: 0.9568544030189514
Validation loss: 2.0791853986760622

Epoch: 6| Step: 7
Training loss: 1.7037900686264038
Validation loss: 2.0129098046210503

Epoch: 6| Step: 8
Training loss: 1.7656314373016357
Validation loss: 2.0415034653038107

Epoch: 6| Step: 9
Training loss: 1.1539936065673828
Validation loss: 2.0280096274550243

Epoch: 6| Step: 10
Training loss: 1.2634685039520264
Validation loss: 2.014608839506744

Epoch: 6| Step: 11
Training loss: 1.158586025238037
Validation loss: 2.0488878885904946

Epoch: 6| Step: 12
Training loss: 0.920326292514801
Validation loss: 2.019955139006338

Epoch: 6| Step: 13
Training loss: 1.2529616355895996
Validation loss: 2.0338272510036344

Epoch: 545| Step: 0
Training loss: 0.9591866135597229
Validation loss: 2.0663458647266513

Epoch: 6| Step: 1
Training loss: 1.4818217754364014
Validation loss: 2.0895197250509776

Epoch: 6| Step: 2
Training loss: 1.3508566617965698
Validation loss: 2.047818690217951

Epoch: 6| Step: 3
Training loss: 1.3143917322158813
Validation loss: 2.103096792774816

Epoch: 6| Step: 4
Training loss: 1.8770732879638672
Validation loss: 2.064811054096427

Epoch: 6| Step: 5
Training loss: 0.9475698471069336
Validation loss: 2.046747140986945

Epoch: 6| Step: 6
Training loss: 0.7684345245361328
Validation loss: 2.0451931697066112

Epoch: 6| Step: 7
Training loss: 1.4298009872436523
Validation loss: 2.05744755524461

Epoch: 6| Step: 8
Training loss: 1.5650804042816162
Validation loss: 2.0587253224465156

Epoch: 6| Step: 9
Training loss: 1.3219726085662842
Validation loss: 2.0310748469445015

Epoch: 6| Step: 10
Training loss: 1.2572920322418213
Validation loss: 2.076895971452036

Epoch: 6| Step: 11
Training loss: 1.8239212036132812
Validation loss: 2.038224135675738

Epoch: 6| Step: 12
Training loss: 1.1796507835388184
Validation loss: 2.047475366182225

Epoch: 6| Step: 13
Training loss: 1.4506607055664062
Validation loss: 2.0719789625495992

Epoch: 546| Step: 0
Training loss: 0.9183894395828247
Validation loss: 2.0193209237949823

Epoch: 6| Step: 1
Training loss: 1.3716175556182861
Validation loss: 2.067441168651786

Epoch: 6| Step: 2
Training loss: 1.6316890716552734
Validation loss: 2.0315044567149174

Epoch: 6| Step: 3
Training loss: 2.067009687423706
Validation loss: 2.0081970839090246

Epoch: 6| Step: 4
Training loss: 1.4534040689468384
Validation loss: 2.0149965978437856

Epoch: 6| Step: 5
Training loss: 0.8745636940002441
Validation loss: 2.054235863429244

Epoch: 6| Step: 6
Training loss: 1.7173327207565308
Validation loss: 2.0270408840589624

Epoch: 6| Step: 7
Training loss: 0.9262664914131165
Validation loss: 2.007949447119108

Epoch: 6| Step: 8
Training loss: 1.266837239265442
Validation loss: 2.097465413872914

Epoch: 6| Step: 9
Training loss: 1.2220892906188965
Validation loss: 2.061386223762266

Epoch: 6| Step: 10
Training loss: 1.1277230978012085
Validation loss: 2.0717229086865663

Epoch: 6| Step: 11
Training loss: 1.373521327972412
Validation loss: 2.071978660040004

Epoch: 6| Step: 12
Training loss: 1.3658121824264526
Validation loss: 2.080618817319152

Epoch: 6| Step: 13
Training loss: 1.5485563278198242
Validation loss: 2.0344906532636253

Epoch: 547| Step: 0
Training loss: 1.8431062698364258
Validation loss: 2.023717312402623

Epoch: 6| Step: 1
Training loss: 1.2629024982452393
Validation loss: 2.04245993655215

Epoch: 6| Step: 2
Training loss: 0.8501548767089844
Validation loss: 2.056022844006938

Epoch: 6| Step: 3
Training loss: 1.4579191207885742
Validation loss: 2.010708966562825

Epoch: 6| Step: 4
Training loss: 1.5020475387573242
Validation loss: 2.056228255712858

Epoch: 6| Step: 5
Training loss: 1.069704532623291
Validation loss: 2.014219378912321

Epoch: 6| Step: 6
Training loss: 0.9444471001625061
Validation loss: 2.036407768085439

Epoch: 6| Step: 7
Training loss: 1.0444056987762451
Validation loss: 2.0571037364262406

Epoch: 6| Step: 8
Training loss: 1.8459596633911133
Validation loss: 2.0661769964361705

Epoch: 6| Step: 9
Training loss: 2.1278154850006104
Validation loss: 2.046548984384024

Epoch: 6| Step: 10
Training loss: 1.1880940198898315
Validation loss: 2.036915466349612

Epoch: 6| Step: 11
Training loss: 0.871003270149231
Validation loss: 2.0566872089139876

Epoch: 6| Step: 12
Training loss: 1.3330786228179932
Validation loss: 2.0655840007207726

Epoch: 6| Step: 13
Training loss: 1.2723342180252075
Validation loss: 2.0357815257964598

Epoch: 548| Step: 0
Training loss: 0.8101152777671814
Validation loss: 2.044544546834884

Epoch: 6| Step: 1
Training loss: 0.8917244672775269
Validation loss: 2.055378080696188

Epoch: 6| Step: 2
Training loss: 1.3646401166915894
Validation loss: 2.054261253726098

Epoch: 6| Step: 3
Training loss: 1.8558269739151
Validation loss: 2.0054138783485658

Epoch: 6| Step: 4
Training loss: 1.1593408584594727
Validation loss: 2.043669733949887

Epoch: 6| Step: 5
Training loss: 1.5829849243164062
Validation loss: 2.05734440588182

Epoch: 6| Step: 6
Training loss: 1.5552172660827637
Validation loss: 2.044893721098541

Epoch: 6| Step: 7
Training loss: 1.114069938659668
Validation loss: 2.0236545301252797

Epoch: 6| Step: 8
Training loss: 1.2671887874603271
Validation loss: 2.053398616852299

Epoch: 6| Step: 9
Training loss: 1.6691441535949707
Validation loss: 2.027339986575547

Epoch: 6| Step: 10
Training loss: 1.196547031402588
Validation loss: 2.093763598831751

Epoch: 6| Step: 11
Training loss: 1.1402406692504883
Validation loss: 2.0615725145545056

Epoch: 6| Step: 12
Training loss: 1.8430087566375732
Validation loss: 2.0784921620481756

Epoch: 6| Step: 13
Training loss: 1.2413229942321777
Validation loss: 2.0686494483742663

Epoch: 549| Step: 0
Training loss: 1.4439821243286133
Validation loss: 2.0494525291586436

Epoch: 6| Step: 1
Training loss: 1.3146575689315796
Validation loss: 2.0854884142516763

Epoch: 6| Step: 2
Training loss: 0.911024808883667
Validation loss: 2.0452527307694957

Epoch: 6| Step: 3
Training loss: 1.446171522140503
Validation loss: 2.0861396366550076

Epoch: 6| Step: 4
Training loss: 1.2663356065750122
Validation loss: 2.0335828386327273

Epoch: 6| Step: 5
Training loss: 0.9038981199264526
Validation loss: 2.0805883651138632

Epoch: 6| Step: 6
Training loss: 1.4894013404846191
Validation loss: 2.0814820925394693

Epoch: 6| Step: 7
Training loss: 1.2574455738067627
Validation loss: 2.0705207522197435

Epoch: 6| Step: 8
Training loss: 1.0534775257110596
Validation loss: 2.0390628896733767

Epoch: 6| Step: 9
Training loss: 1.392250418663025
Validation loss: 2.044331794144005

Epoch: 6| Step: 10
Training loss: 1.8998241424560547
Validation loss: 2.0617389191863356

Epoch: 6| Step: 11
Training loss: 1.2503315210342407
Validation loss: 2.053734888312637

Epoch: 6| Step: 12
Training loss: 0.9748436212539673
Validation loss: 2.0555677285758396

Epoch: 6| Step: 13
Training loss: 1.61759352684021
Validation loss: 2.0658083333764026

Epoch: 550| Step: 0
Training loss: 1.4857577085494995
Validation loss: 2.0600834303004767

Epoch: 6| Step: 1
Training loss: 1.0464953184127808
Validation loss: 2.097991725449921

Epoch: 6| Step: 2
Training loss: 1.1058173179626465
Validation loss: 2.0439129567915395

Epoch: 6| Step: 3
Training loss: 1.3528318405151367
Validation loss: 2.0724730619820217

Epoch: 6| Step: 4
Training loss: 1.1277134418487549
Validation loss: 2.036774907060849

Epoch: 6| Step: 5
Training loss: 1.3092635869979858
Validation loss: 2.0447244682619647

Epoch: 6| Step: 6
Training loss: 1.637495756149292
Validation loss: 2.0369885352350052

Epoch: 6| Step: 7
Training loss: 1.3547894954681396
Validation loss: 2.043614085002612

Epoch: 6| Step: 8
Training loss: 1.3859970569610596
Validation loss: 2.028588823092881

Epoch: 6| Step: 9
Training loss: 0.9677465558052063
Validation loss: 2.0262863405289187

Epoch: 6| Step: 10
Training loss: 1.279931664466858
Validation loss: 2.0943190000390493

Epoch: 6| Step: 11
Training loss: 1.7874183654785156
Validation loss: 2.0378580759930354

Epoch: 6| Step: 12
Training loss: 1.3618085384368896
Validation loss: 2.0242277601713776

Epoch: 6| Step: 13
Training loss: 1.7586939334869385
Validation loss: 2.110552990308372

Epoch: 551| Step: 0
Training loss: 1.634826421737671
Validation loss: 2.0259142460361605

Epoch: 6| Step: 1
Training loss: 1.383589506149292
Validation loss: 2.0267887717934063

Epoch: 6| Step: 2
Training loss: 1.246978759765625
Validation loss: 2.0560262408307803

Epoch: 6| Step: 3
Training loss: 1.0634093284606934
Validation loss: 2.0948767354411464

Epoch: 6| Step: 4
Training loss: 1.5580089092254639
Validation loss: 2.0601600241917435

Epoch: 6| Step: 5
Training loss: 1.0400207042694092
Validation loss: 2.045504194433971

Epoch: 6| Step: 6
Training loss: 1.3117434978485107
Validation loss: 2.0854122279792704

Epoch: 6| Step: 7
Training loss: 1.1010956764221191
Validation loss: 2.0745599795413274

Epoch: 6| Step: 8
Training loss: 1.4074733257293701
Validation loss: 2.0706374465778308

Epoch: 6| Step: 9
Training loss: 1.392427921295166
Validation loss: 2.1196905284799556

Epoch: 6| Step: 10
Training loss: 1.3662164211273193
Validation loss: 2.0959522185787076

Epoch: 6| Step: 11
Training loss: 1.3337507247924805
Validation loss: 2.098288820635888

Epoch: 6| Step: 12
Training loss: 1.6295135021209717
Validation loss: 2.0962976089087864

Epoch: 6| Step: 13
Training loss: 0.8025949001312256
Validation loss: 2.0833208766034854

Epoch: 552| Step: 0
Training loss: 1.4166008234024048
Validation loss: 2.082195415291735

Epoch: 6| Step: 1
Training loss: 1.1666860580444336
Validation loss: 2.0203897542850946

Epoch: 6| Step: 2
Training loss: 0.8326167464256287
Validation loss: 2.070884841744618

Epoch: 6| Step: 3
Training loss: 1.1629352569580078
Validation loss: 2.0576408011938936

Epoch: 6| Step: 4
Training loss: 1.3447984457015991
Validation loss: 2.109926954392464

Epoch: 6| Step: 5
Training loss: 1.2426880598068237
Validation loss: 1.976013538657978

Epoch: 6| Step: 6
Training loss: 1.840111255645752
Validation loss: 2.043434109739078

Epoch: 6| Step: 7
Training loss: 1.2529783248901367
Validation loss: 2.032894851059042

Epoch: 6| Step: 8
Training loss: 1.3080646991729736
Validation loss: 2.033987170906477

Epoch: 6| Step: 9
Training loss: 1.010617971420288
Validation loss: 2.0286831855773926

Epoch: 6| Step: 10
Training loss: 1.502468466758728
Validation loss: 2.032959254839087

Epoch: 6| Step: 11
Training loss: 1.4354026317596436
Validation loss: 2.046770671362518

Epoch: 6| Step: 12
Training loss: 1.0881662368774414
Validation loss: 2.0729026320160076

Epoch: 6| Step: 13
Training loss: 1.5575251579284668
Validation loss: 2.0710164795639696

Epoch: 553| Step: 0
Training loss: 0.9686706066131592
Validation loss: 2.0942151597751084

Epoch: 6| Step: 1
Training loss: 1.3566153049468994
Validation loss: 2.0441050785844044

Epoch: 6| Step: 2
Training loss: 1.5172088146209717
Validation loss: 2.055350083176808

Epoch: 6| Step: 3
Training loss: 1.118880033493042
Validation loss: 2.0482728455656316

Epoch: 6| Step: 4
Training loss: 0.8401593565940857
Validation loss: 2.055125077565511

Epoch: 6| Step: 5
Training loss: 1.074650526046753
Validation loss: 2.0682583432043753

Epoch: 6| Step: 6
Training loss: 1.6408950090408325
Validation loss: 2.0489713068931334

Epoch: 6| Step: 7
Training loss: 1.517042636871338
Validation loss: 1.9900538549628308

Epoch: 6| Step: 8
Training loss: 1.7589852809906006
Validation loss: 2.0636002197060535

Epoch: 6| Step: 9
Training loss: 1.3789901733398438
Validation loss: 2.034446090780279

Epoch: 6| Step: 10
Training loss: 1.1256710290908813
Validation loss: 2.0825297524852138

Epoch: 6| Step: 11
Training loss: 1.443359136581421
Validation loss: 2.0843132593298472

Epoch: 6| Step: 12
Training loss: 0.9047729969024658
Validation loss: 2.051106014559346

Epoch: 6| Step: 13
Training loss: 1.9063527584075928
Validation loss: 2.0641859475002495

Epoch: 554| Step: 0
Training loss: 1.4076120853424072
Validation loss: 2.0951436642677552

Epoch: 6| Step: 1
Training loss: 0.9533302783966064
Validation loss: 2.0594005533443984

Epoch: 6| Step: 2
Training loss: 0.918117344379425
Validation loss: 2.141024920248216

Epoch: 6| Step: 3
Training loss: 1.219484567642212
Validation loss: 2.1095800374143865

Epoch: 6| Step: 4
Training loss: 1.082702398300171
Validation loss: 2.080017420553392

Epoch: 6| Step: 5
Training loss: 1.036633014678955
Validation loss: 2.078278690256098

Epoch: 6| Step: 6
Training loss: 1.4774107933044434
Validation loss: 2.138535976409912

Epoch: 6| Step: 7
Training loss: 1.67997407913208
Validation loss: 2.108100906495125

Epoch: 6| Step: 8
Training loss: 1.6137125492095947
Validation loss: 2.0926500828035417

Epoch: 6| Step: 9
Training loss: 1.0372068881988525
Validation loss: 2.083437365870322

Epoch: 6| Step: 10
Training loss: 1.2658212184906006
Validation loss: 2.059741735458374

Epoch: 6| Step: 11
Training loss: 1.4614423513412476
Validation loss: 2.0403496219265844

Epoch: 6| Step: 12
Training loss: 1.544222354888916
Validation loss: 2.078901255002586

Epoch: 6| Step: 13
Training loss: 2.374682664871216
Validation loss: 2.0276254505239506

Epoch: 555| Step: 0
Training loss: 0.9740186333656311
Validation loss: 2.035313198643346

Epoch: 6| Step: 1
Training loss: 1.2847647666931152
Validation loss: 2.0927228632793633

Epoch: 6| Step: 2
Training loss: 1.530356764793396
Validation loss: 2.0677095331171507

Epoch: 6| Step: 3
Training loss: 1.3332390785217285
Validation loss: 2.0542811193773822

Epoch: 6| Step: 4
Training loss: 1.0607733726501465
Validation loss: 2.127890645816762

Epoch: 6| Step: 5
Training loss: 1.3245052099227905
Validation loss: 2.065991352963191

Epoch: 6| Step: 6
Training loss: 1.2153375148773193
Validation loss: 2.0629654507483206

Epoch: 6| Step: 7
Training loss: 1.5897669792175293
Validation loss: 2.0827519509100143

Epoch: 6| Step: 8
Training loss: 1.8798024654388428
Validation loss: 2.0885050847966182

Epoch: 6| Step: 9
Training loss: 1.9051097631454468
Validation loss: 2.0869878876593804

Epoch: 6| Step: 10
Training loss: 0.929557204246521
Validation loss: 2.0733803433756672

Epoch: 6| Step: 11
Training loss: 1.6471810340881348
Validation loss: 2.1032059525930755

Epoch: 6| Step: 12
Training loss: 1.4996850490570068
Validation loss: 2.082782647942984

Epoch: 6| Step: 13
Training loss: 0.8851816654205322
Validation loss: 2.1060326637760287

Epoch: 556| Step: 0
Training loss: 1.2569756507873535
Validation loss: 2.024874037311923

Epoch: 6| Step: 1
Training loss: 1.0167512893676758
Validation loss: 2.0530875229066416

Epoch: 6| Step: 2
Training loss: 0.8746017217636108
Validation loss: 2.027793756095312

Epoch: 6| Step: 3
Training loss: 0.9970758557319641
Validation loss: 2.0424128104281682

Epoch: 6| Step: 4
Training loss: 1.2890621423721313
Validation loss: 2.0268961870542137

Epoch: 6| Step: 5
Training loss: 1.849244236946106
Validation loss: 2.054416405257358

Epoch: 6| Step: 6
Training loss: 2.1354219913482666
Validation loss: 2.0161104791907856

Epoch: 6| Step: 7
Training loss: 1.3743820190429688
Validation loss: 2.020527187214103

Epoch: 6| Step: 8
Training loss: 1.3820796012878418
Validation loss: 2.0583910813895603

Epoch: 6| Step: 9
Training loss: 1.1332577466964722
Validation loss: 2.0882085741207166

Epoch: 6| Step: 10
Training loss: 1.169713020324707
Validation loss: 2.043067237382294

Epoch: 6| Step: 11
Training loss: 1.4065049886703491
Validation loss: 2.0613674861128612

Epoch: 6| Step: 12
Training loss: 1.1592228412628174
Validation loss: 2.0579803182232763

Epoch: 6| Step: 13
Training loss: 1.409690022468567
Validation loss: 2.0574905487798874

Epoch: 557| Step: 0
Training loss: 0.9443511366844177
Validation loss: 2.0592037759801394

Epoch: 6| Step: 1
Training loss: 1.159134864807129
Validation loss: 2.042248825873098

Epoch: 6| Step: 2
Training loss: 1.076969861984253
Validation loss: 2.076421373633928

Epoch: 6| Step: 3
Training loss: 1.8228480815887451
Validation loss: 2.0409067997368435

Epoch: 6| Step: 4
Training loss: 0.9996013045310974
Validation loss: 2.0183995154596146

Epoch: 6| Step: 5
Training loss: 1.4279344081878662
Validation loss: 2.1063062644773916

Epoch: 6| Step: 6
Training loss: 1.1464805603027344
Validation loss: 2.0764832368461033

Epoch: 6| Step: 7
Training loss: 1.431067705154419
Validation loss: 2.0859506771128666

Epoch: 6| Step: 8
Training loss: 1.543532133102417
Validation loss: 2.05240834272036

Epoch: 6| Step: 9
Training loss: 1.2853024005889893
Validation loss: 2.0422645435538342

Epoch: 6| Step: 10
Training loss: 1.3744590282440186
Validation loss: 2.0467524272139355

Epoch: 6| Step: 11
Training loss: 1.11635160446167
Validation loss: 2.032686694975822

Epoch: 6| Step: 12
Training loss: 1.9531867504119873
Validation loss: 2.0789834683941257

Epoch: 6| Step: 13
Training loss: 0.772991418838501
Validation loss: 2.062950370132282

Epoch: 558| Step: 0
Training loss: 1.2002146244049072
Validation loss: 2.0452940182019304

Epoch: 6| Step: 1
Training loss: 1.6043038368225098
Validation loss: 1.9975341802002282

Epoch: 6| Step: 2
Training loss: 0.6386606693267822
Validation loss: 2.014068172823998

Epoch: 6| Step: 3
Training loss: 1.6738686561584473
Validation loss: 2.040409957208941

Epoch: 6| Step: 4
Training loss: 0.9180769920349121
Validation loss: 2.026997866169099

Epoch: 6| Step: 5
Training loss: 1.2335896492004395
Validation loss: 2.009619817938856

Epoch: 6| Step: 6
Training loss: 1.307477355003357
Validation loss: 2.047945994202809

Epoch: 6| Step: 7
Training loss: 1.0636978149414062
Validation loss: 2.0500309518588486

Epoch: 6| Step: 8
Training loss: 1.9975535869598389
Validation loss: 2.080769192787909

Epoch: 6| Step: 9
Training loss: 1.3447827100753784
Validation loss: 2.030440498423833

Epoch: 6| Step: 10
Training loss: 1.4215089082717896
Validation loss: 2.0753850526707147

Epoch: 6| Step: 11
Training loss: 1.7030880451202393
Validation loss: 2.0893484084836897

Epoch: 6| Step: 12
Training loss: 0.8964443206787109
Validation loss: 2.058484060789949

Epoch: 6| Step: 13
Training loss: 1.0962036848068237
Validation loss: 2.0021413128863097

Epoch: 559| Step: 0
Training loss: 1.9002031087875366
Validation loss: 2.0713745035151

Epoch: 6| Step: 1
Training loss: 1.503699779510498
Validation loss: 2.0454613226716236

Epoch: 6| Step: 2
Training loss: 1.6302672624588013
Validation loss: 2.032289546023133

Epoch: 6| Step: 3
Training loss: 1.0849831104278564
Validation loss: 2.0563555238067464

Epoch: 6| Step: 4
Training loss: 1.4902514219284058
Validation loss: 2.0349862216621317

Epoch: 6| Step: 5
Training loss: 1.488670825958252
Validation loss: 2.0381180599171627

Epoch: 6| Step: 6
Training loss: 0.4635940492153168
Validation loss: 2.0907502661469164

Epoch: 6| Step: 7
Training loss: 0.9373469352722168
Validation loss: 2.0241311596285914

Epoch: 6| Step: 8
Training loss: 1.7434197664260864
Validation loss: 2.045156478881836

Epoch: 6| Step: 9
Training loss: 1.372477412223816
Validation loss: 2.0224700332969747

Epoch: 6| Step: 10
Training loss: 0.8611219525337219
Validation loss: 2.027223986964072

Epoch: 6| Step: 11
Training loss: 1.354778528213501
Validation loss: 2.0540143571874148

Epoch: 6| Step: 12
Training loss: 0.9080137610435486
Validation loss: 2.040954757762212

Epoch: 6| Step: 13
Training loss: 1.4791524410247803
Validation loss: 2.019094961945729

Epoch: 560| Step: 0
Training loss: 1.0975863933563232
Validation loss: 2.040321091169952

Epoch: 6| Step: 1
Training loss: 1.5528883934020996
Validation loss: 2.037908613040883

Epoch: 6| Step: 2
Training loss: 1.5165743827819824
Validation loss: 2.024514854595225

Epoch: 6| Step: 3
Training loss: 0.8780591487884521
Validation loss: 2.066419801404399

Epoch: 6| Step: 4
Training loss: 1.3824211359024048
Validation loss: 2.0204400657325663

Epoch: 6| Step: 5
Training loss: 1.6411781311035156
Validation loss: 2.030923867738375

Epoch: 6| Step: 6
Training loss: 1.3216040134429932
Validation loss: 2.0864546580981185

Epoch: 6| Step: 7
Training loss: 1.160187005996704
Validation loss: 2.035225404206143

Epoch: 6| Step: 8
Training loss: 1.4537897109985352
Validation loss: 2.0631934122372697

Epoch: 6| Step: 9
Training loss: 0.9433605670928955
Validation loss: 2.01168131571944

Epoch: 6| Step: 10
Training loss: 1.3043458461761475
Validation loss: 2.092706282933553

Epoch: 6| Step: 11
Training loss: 1.4228063821792603
Validation loss: 2.0376428788708103

Epoch: 6| Step: 12
Training loss: 1.0742013454437256
Validation loss: 2.0387263926126624

Epoch: 6| Step: 13
Training loss: 1.2974966764450073
Validation loss: 2.0425833553396244

Epoch: 561| Step: 0
Training loss: 1.0539631843566895
Validation loss: 2.0537233609025196

Epoch: 6| Step: 1
Training loss: 1.7612123489379883
Validation loss: 2.0923946288324173

Epoch: 6| Step: 2
Training loss: 2.2548015117645264
Validation loss: 2.125068720950875

Epoch: 6| Step: 3
Training loss: 0.8836753368377686
Validation loss: 2.152402985480524

Epoch: 6| Step: 4
Training loss: 1.3260406255722046
Validation loss: 2.106082267658685

Epoch: 6| Step: 5
Training loss: 1.1297729015350342
Validation loss: 2.073356355390241

Epoch: 6| Step: 6
Training loss: 1.2196146249771118
Validation loss: 2.0721640689398653

Epoch: 6| Step: 7
Training loss: 1.4303388595581055
Validation loss: 2.0268371592285814

Epoch: 6| Step: 8
Training loss: 1.2017451524734497
Validation loss: 2.075553849179258

Epoch: 6| Step: 9
Training loss: 1.2332011461257935
Validation loss: 2.011087650893837

Epoch: 6| Step: 10
Training loss: 1.5858923196792603
Validation loss: 2.0448617960817073

Epoch: 6| Step: 11
Training loss: 1.2640882730484009
Validation loss: 2.038667372477952

Epoch: 6| Step: 12
Training loss: 1.324537754058838
Validation loss: 2.038172293734807

Epoch: 6| Step: 13
Training loss: 0.786281943321228
Validation loss: 2.042404538841658

Epoch: 562| Step: 0
Training loss: 0.8025069236755371
Validation loss: 2.0118160504166798

Epoch: 6| Step: 1
Training loss: 1.1158925294876099
Validation loss: 2.0807015690752255

Epoch: 6| Step: 2
Training loss: 1.4131033420562744
Validation loss: 2.0313704065097276

Epoch: 6| Step: 3
Training loss: 1.4576550722122192
Validation loss: 2.054305843127671

Epoch: 6| Step: 4
Training loss: 1.209120512008667
Validation loss: 2.0466074046268257

Epoch: 6| Step: 5
Training loss: 0.8483970165252686
Validation loss: 2.0324072120010213

Epoch: 6| Step: 6
Training loss: 1.5405163764953613
Validation loss: 2.0475279720880653

Epoch: 6| Step: 7
Training loss: 1.1122380495071411
Validation loss: 2.0334178350305043

Epoch: 6| Step: 8
Training loss: 2.120774984359741
Validation loss: 2.047534724717499

Epoch: 6| Step: 9
Training loss: 1.4534692764282227
Validation loss: 2.0798150057433755

Epoch: 6| Step: 10
Training loss: 1.8788232803344727
Validation loss: 2.0980666760475404

Epoch: 6| Step: 11
Training loss: 0.8810194730758667
Validation loss: 2.095072179712275

Epoch: 6| Step: 12
Training loss: 1.0511155128479004
Validation loss: 2.0994841398731356

Epoch: 6| Step: 13
Training loss: 2.085726737976074
Validation loss: 2.107602442464521

Epoch: 563| Step: 0
Training loss: 1.2302985191345215
Validation loss: 2.051947006615259

Epoch: 6| Step: 1
Training loss: 1.4654353857040405
Validation loss: 2.0393068393071494

Epoch: 6| Step: 2
Training loss: 1.547013282775879
Validation loss: 2.0375481164583595

Epoch: 6| Step: 3
Training loss: 1.6651568412780762
Validation loss: 2.0605326775581605

Epoch: 6| Step: 4
Training loss: 1.3790600299835205
Validation loss: 2.0592909615526915

Epoch: 6| Step: 5
Training loss: 1.2946979999542236
Validation loss: 2.0338619729524017

Epoch: 6| Step: 6
Training loss: 0.8194605708122253
Validation loss: 2.0740050782439527

Epoch: 6| Step: 7
Training loss: 1.4916566610336304
Validation loss: 2.0399441513963925

Epoch: 6| Step: 8
Training loss: 0.9068853855133057
Validation loss: 2.040472892022902

Epoch: 6| Step: 9
Training loss: 1.2191574573516846
Validation loss: 2.0070409890144103

Epoch: 6| Step: 10
Training loss: 1.2426120042800903
Validation loss: 2.0712182432092647

Epoch: 6| Step: 11
Training loss: 1.4031509160995483
Validation loss: 2.123462192473873

Epoch: 6| Step: 12
Training loss: 0.9949096441268921
Validation loss: 2.0653496865303285

Epoch: 6| Step: 13
Training loss: 1.8027750253677368
Validation loss: 2.0989005629734327

Epoch: 564| Step: 0
Training loss: 1.324006199836731
Validation loss: 2.123593468819895

Epoch: 6| Step: 1
Training loss: 1.6778993606567383
Validation loss: 2.092175540103707

Epoch: 6| Step: 2
Training loss: 1.3902747631072998
Validation loss: 2.065465582314358

Epoch: 6| Step: 3
Training loss: 1.0730082988739014
Validation loss: 2.0593739735182894

Epoch: 6| Step: 4
Training loss: 1.069949746131897
Validation loss: 2.0568451484044394

Epoch: 6| Step: 5
Training loss: 2.3547253608703613
Validation loss: 2.108619632259492

Epoch: 6| Step: 6
Training loss: 1.68402099609375
Validation loss: 2.069946701808642

Epoch: 6| Step: 7
Training loss: 1.1684459447860718
Validation loss: 2.0923729224871566

Epoch: 6| Step: 8
Training loss: 1.1603118181228638
Validation loss: 2.029391563066872

Epoch: 6| Step: 9
Training loss: 1.0624973773956299
Validation loss: 2.0471085527891755

Epoch: 6| Step: 10
Training loss: 0.7501415610313416
Validation loss: 2.053112099247594

Epoch: 6| Step: 11
Training loss: 1.3713959455490112
Validation loss: 2.0305021719266008

Epoch: 6| Step: 12
Training loss: 1.4023631811141968
Validation loss: 2.0472181458627023

Epoch: 6| Step: 13
Training loss: 1.0873585939407349
Validation loss: 2.064740732151975

Epoch: 565| Step: 0
Training loss: 2.0690670013427734
Validation loss: 2.007886230304677

Epoch: 6| Step: 1
Training loss: 1.820057988166809
Validation loss: 2.0408887311976445

Epoch: 6| Step: 2
Training loss: 1.2873609066009521
Validation loss: 2.0640375152710946

Epoch: 6| Step: 3
Training loss: 1.454755425453186
Validation loss: 2.0719679068493586

Epoch: 6| Step: 4
Training loss: 1.2151520252227783
Validation loss: 2.0890142276722896

Epoch: 6| Step: 5
Training loss: 0.7823401689529419
Validation loss: 2.0962328705736386

Epoch: 6| Step: 6
Training loss: 1.2424219846725464
Validation loss: 2.1162699319983043

Epoch: 6| Step: 7
Training loss: 0.9057254791259766
Validation loss: 2.074463249534689

Epoch: 6| Step: 8
Training loss: 1.7367191314697266
Validation loss: 2.092578354702201

Epoch: 6| Step: 9
Training loss: 0.7792354822158813
Validation loss: 2.068503004248424

Epoch: 6| Step: 10
Training loss: 1.5016801357269287
Validation loss: 2.052837059062014

Epoch: 6| Step: 11
Training loss: 1.1916892528533936
Validation loss: 2.042412619436941

Epoch: 6| Step: 12
Training loss: 1.2971211671829224
Validation loss: 2.0063038769588677

Epoch: 6| Step: 13
Training loss: 1.1713976860046387
Validation loss: 2.025743717788368

Epoch: 566| Step: 0
Training loss: 1.266038179397583
Validation loss: 2.0530620480096466

Epoch: 6| Step: 1
Training loss: 1.564794659614563
Validation loss: 2.032686802648729

Epoch: 6| Step: 2
Training loss: 0.983487069606781
Validation loss: 2.0240648318362493

Epoch: 6| Step: 3
Training loss: 1.38034188747406
Validation loss: 2.074936225850095

Epoch: 6| Step: 4
Training loss: 1.368497371673584
Validation loss: 2.072171152278941

Epoch: 6| Step: 5
Training loss: 1.5630223751068115
Validation loss: 2.0477102200190225

Epoch: 6| Step: 6
Training loss: 0.7293411493301392
Validation loss: 2.048223659556399

Epoch: 6| Step: 7
Training loss: 1.548919439315796
Validation loss: 2.0632267754565

Epoch: 6| Step: 8
Training loss: 1.221074104309082
Validation loss: 2.0786331712558703

Epoch: 6| Step: 9
Training loss: 1.2368967533111572
Validation loss: 2.0970978865059475

Epoch: 6| Step: 10
Training loss: 1.206617832183838
Validation loss: 2.0955573692116687

Epoch: 6| Step: 11
Training loss: 1.2209622859954834
Validation loss: 2.0737294920029177

Epoch: 6| Step: 12
Training loss: 2.2568860054016113
Validation loss: 2.0821886613804805

Epoch: 6| Step: 13
Training loss: 1.0754752159118652
Validation loss: 2.0634946246300974

Epoch: 567| Step: 0
Training loss: 1.2252126932144165
Validation loss: 2.0195860939641155

Epoch: 6| Step: 1
Training loss: 0.9863142371177673
Validation loss: 2.0482047834704

Epoch: 6| Step: 2
Training loss: 1.5016319751739502
Validation loss: 2.0680596315732567

Epoch: 6| Step: 3
Training loss: 0.7964118123054504
Validation loss: 2.055373014942292

Epoch: 6| Step: 4
Training loss: 0.8241158127784729
Validation loss: 2.0144693518197663

Epoch: 6| Step: 5
Training loss: 1.7097212076187134
Validation loss: 2.04482469635625

Epoch: 6| Step: 6
Training loss: 1.558396816253662
Validation loss: 2.0753343592407885

Epoch: 6| Step: 7
Training loss: 1.6973761320114136
Validation loss: 2.032489977857118

Epoch: 6| Step: 8
Training loss: 1.6483361721038818
Validation loss: 2.039264411054632

Epoch: 6| Step: 9
Training loss: 1.288926601409912
Validation loss: 2.0326982467405257

Epoch: 6| Step: 10
Training loss: 1.1281498670578003
Validation loss: 2.078752194681475

Epoch: 6| Step: 11
Training loss: 1.3684488534927368
Validation loss: 2.053979586529475

Epoch: 6| Step: 12
Training loss: 1.072538137435913
Validation loss: 2.0533860447586223

Epoch: 6| Step: 13
Training loss: 1.8036348819732666
Validation loss: 2.0410592120180846

Epoch: 568| Step: 0
Training loss: 1.627244472503662
Validation loss: 2.021488542197853

Epoch: 6| Step: 1
Training loss: 0.7950074672698975
Validation loss: 2.0392595055282756

Epoch: 6| Step: 2
Training loss: 1.3438571691513062
Validation loss: 2.030921818107687

Epoch: 6| Step: 3
Training loss: 0.793311357498169
Validation loss: 2.0282911075058805

Epoch: 6| Step: 4
Training loss: 1.326997995376587
Validation loss: 2.062745160953973

Epoch: 6| Step: 5
Training loss: 2.309054374694824
Validation loss: 2.0272622044368456

Epoch: 6| Step: 6
Training loss: 1.3326398134231567
Validation loss: 2.0601897803686

Epoch: 6| Step: 7
Training loss: 1.806492805480957
Validation loss: 2.0758482897153465

Epoch: 6| Step: 8
Training loss: 1.3362106084823608
Validation loss: 2.068362920514999

Epoch: 6| Step: 9
Training loss: 1.0767186880111694
Validation loss: 2.068076140137129

Epoch: 6| Step: 10
Training loss: 1.1916944980621338
Validation loss: 2.0499219432953866

Epoch: 6| Step: 11
Training loss: 1.3024029731750488
Validation loss: 2.0610866802994923

Epoch: 6| Step: 12
Training loss: 0.820139467716217
Validation loss: 2.072251255794238

Epoch: 6| Step: 13
Training loss: 1.081567645072937
Validation loss: 2.038475610876596

Epoch: 569| Step: 0
Training loss: 1.299185037612915
Validation loss: 2.0754895030811267

Epoch: 6| Step: 1
Training loss: 1.1171326637268066
Validation loss: 2.0837522924587293

Epoch: 6| Step: 2
Training loss: 1.9027740955352783
Validation loss: 2.058445051152219

Epoch: 6| Step: 3
Training loss: 0.7583118081092834
Validation loss: 2.033316901935044

Epoch: 6| Step: 4
Training loss: 1.3715713024139404
Validation loss: 2.088412930888514

Epoch: 6| Step: 5
Training loss: 1.5886428356170654
Validation loss: 2.0932874295019333

Epoch: 6| Step: 6
Training loss: 1.455187201499939
Validation loss: 2.0581478470115253

Epoch: 6| Step: 7
Training loss: 1.4005231857299805
Validation loss: 2.068806755927301

Epoch: 6| Step: 8
Training loss: 1.2589799165725708
Validation loss: 2.0776642727595505

Epoch: 6| Step: 9
Training loss: 1.4880318641662598
Validation loss: 2.092662347260342

Epoch: 6| Step: 10
Training loss: 0.8473647236824036
Validation loss: 2.064430739289971

Epoch: 6| Step: 11
Training loss: 1.1034879684448242
Validation loss: 2.06858717754323

Epoch: 6| Step: 12
Training loss: 0.8843604326248169
Validation loss: 2.045713068336569

Epoch: 6| Step: 13
Training loss: 1.834218144416809
Validation loss: 2.0303575249128443

Epoch: 570| Step: 0
Training loss: 1.3080588579177856
Validation loss: 2.0664676786750875

Epoch: 6| Step: 1
Training loss: 1.2710936069488525
Validation loss: 2.0376221415817097

Epoch: 6| Step: 2
Training loss: 1.2641783952713013
Validation loss: 2.0540348176033265

Epoch: 6| Step: 3
Training loss: 1.2618670463562012
Validation loss: 2.0228474652895363

Epoch: 6| Step: 4
Training loss: 0.6770398020744324
Validation loss: 2.0767404674201884

Epoch: 6| Step: 5
Training loss: 2.218730926513672
Validation loss: 2.072645584742228

Epoch: 6| Step: 6
Training loss: 1.458399772644043
Validation loss: 2.044777882996426

Epoch: 6| Step: 7
Training loss: 1.8086638450622559
Validation loss: 2.0728973803981656

Epoch: 6| Step: 8
Training loss: 1.0104159116744995
Validation loss: 2.0716471466966855

Epoch: 6| Step: 9
Training loss: 0.9387783408164978
Validation loss: 2.0656210350733932

Epoch: 6| Step: 10
Training loss: 0.7898320555686951
Validation loss: 2.055847091059531

Epoch: 6| Step: 11
Training loss: 1.5448508262634277
Validation loss: 2.082651420306134

Epoch: 6| Step: 12
Training loss: 1.439526915550232
Validation loss: 2.0560653466050343

Epoch: 6| Step: 13
Training loss: 0.8936278820037842
Validation loss: 2.0319914510173183

Epoch: 571| Step: 0
Training loss: 0.9180034399032593
Validation loss: 2.027733854068223

Epoch: 6| Step: 1
Training loss: 0.9529077410697937
Validation loss: 2.0682011496636177

Epoch: 6| Step: 2
Training loss: 1.8138318061828613
Validation loss: 2.063675098521735

Epoch: 6| Step: 3
Training loss: 1.1928952932357788
Validation loss: 2.039452216958487

Epoch: 6| Step: 4
Training loss: 1.2837095260620117
Validation loss: 2.0511405596169094

Epoch: 6| Step: 5
Training loss: 1.7218586206436157
Validation loss: 2.0684138164725354

Epoch: 6| Step: 6
Training loss: 1.4553277492523193
Validation loss: 2.047237451358508

Epoch: 6| Step: 7
Training loss: 1.4070669412612915
Validation loss: 2.010166736059291

Epoch: 6| Step: 8
Training loss: 1.1533503532409668
Validation loss: 1.9885059518198813

Epoch: 6| Step: 9
Training loss: 0.9077702760696411
Validation loss: 1.9876167953655284

Epoch: 6| Step: 10
Training loss: 1.786352276802063
Validation loss: 2.0293870792594007

Epoch: 6| Step: 11
Training loss: 1.3555771112442017
Validation loss: 2.037763267435053

Epoch: 6| Step: 12
Training loss: 0.8568757772445679
Validation loss: 2.041475757475822

Epoch: 6| Step: 13
Training loss: 0.890687108039856
Validation loss: 2.031316339328725

Epoch: 572| Step: 0
Training loss: 1.0847729444503784
Validation loss: 2.050440401159307

Epoch: 6| Step: 1
Training loss: 1.1036440134048462
Validation loss: 2.041752238427439

Epoch: 6| Step: 2
Training loss: 1.1575467586517334
Validation loss: 2.0813664544013237

Epoch: 6| Step: 3
Training loss: 1.5754897594451904
Validation loss: 2.052821546472529

Epoch: 6| Step: 4
Training loss: 0.8734363913536072
Validation loss: 2.0900676019730104

Epoch: 6| Step: 5
Training loss: 1.2145086526870728
Validation loss: 2.0458192376680273

Epoch: 6| Step: 6
Training loss: 1.4292348623275757
Validation loss: 2.0769987401141914

Epoch: 6| Step: 7
Training loss: 1.4178247451782227
Validation loss: 2.074283653689969

Epoch: 6| Step: 8
Training loss: 1.3477427959442139
Validation loss: 2.0607220844555925

Epoch: 6| Step: 9
Training loss: 1.6263281106948853
Validation loss: 2.0541120690684163

Epoch: 6| Step: 10
Training loss: 0.7806413173675537
Validation loss: 2.0301192550249

Epoch: 6| Step: 11
Training loss: 1.1468740701675415
Validation loss: 2.089485045402281

Epoch: 6| Step: 12
Training loss: 1.8063905239105225
Validation loss: 2.0195834405960573

Epoch: 6| Step: 13
Training loss: 1.6163874864578247
Validation loss: 2.0585118032270864

Epoch: 573| Step: 0
Training loss: 1.153325080871582
Validation loss: 2.0281994419713176

Epoch: 6| Step: 1
Training loss: 1.135042428970337
Validation loss: 2.064346621113439

Epoch: 6| Step: 2
Training loss: 1.440138339996338
Validation loss: 2.0657572951368106

Epoch: 6| Step: 3
Training loss: 1.339821219444275
Validation loss: 2.041241225375924

Epoch: 6| Step: 4
Training loss: 0.8165570497512817
Validation loss: 2.0902492512938795

Epoch: 6| Step: 5
Training loss: 1.2913107872009277
Validation loss: 2.020426763001309

Epoch: 6| Step: 6
Training loss: 1.0914620161056519
Validation loss: 2.0603272325249127

Epoch: 6| Step: 7
Training loss: 1.4253751039505005
Validation loss: 2.0717895492430656

Epoch: 6| Step: 8
Training loss: 2.0294032096862793
Validation loss: 2.0550557131408365

Epoch: 6| Step: 9
Training loss: 1.0581914186477661
Validation loss: 2.0932469162889706

Epoch: 6| Step: 10
Training loss: 1.0582149028778076
Validation loss: 2.08192773531842

Epoch: 6| Step: 11
Training loss: 1.179173231124878
Validation loss: 2.053543507411916

Epoch: 6| Step: 12
Training loss: 1.5377740859985352
Validation loss: 2.1110363032228205

Epoch: 6| Step: 13
Training loss: 1.0647305250167847
Validation loss: 2.0743906985047045

Epoch: 574| Step: 0
Training loss: 1.4460651874542236
Validation loss: 2.1093731387968986

Epoch: 6| Step: 1
Training loss: 1.3407883644104004
Validation loss: 2.066430189276254

Epoch: 6| Step: 2
Training loss: 0.8400849103927612
Validation loss: 2.0826889468777563

Epoch: 6| Step: 3
Training loss: 1.68359375
Validation loss: 2.063260260448661

Epoch: 6| Step: 4
Training loss: 0.35935357213020325
Validation loss: 2.072493496761527

Epoch: 6| Step: 5
Training loss: 1.2235519886016846
Validation loss: 2.044932657672513

Epoch: 6| Step: 6
Training loss: 1.0643730163574219
Validation loss: 2.0598751755170923

Epoch: 6| Step: 7
Training loss: 2.035937547683716
Validation loss: 2.039134383201599

Epoch: 6| Step: 8
Training loss: 1.1523377895355225
Validation loss: 2.0235495798049437

Epoch: 6| Step: 9
Training loss: 0.9853825569152832
Validation loss: 2.0364070156569123

Epoch: 6| Step: 10
Training loss: 1.5858808755874634
Validation loss: 1.9951355277851064

Epoch: 6| Step: 11
Training loss: 1.8172820806503296
Validation loss: 2.0476442126817602

Epoch: 6| Step: 12
Training loss: 1.217245101928711
Validation loss: 2.0598067468212498

Epoch: 6| Step: 13
Training loss: 1.0888307094573975
Validation loss: 2.035794122244722

Epoch: 575| Step: 0
Training loss: 1.3530068397521973
Validation loss: 2.038666711058668

Epoch: 6| Step: 1
Training loss: 0.9361791014671326
Validation loss: 2.044434142369096

Epoch: 6| Step: 2
Training loss: 1.2837412357330322
Validation loss: 2.0372190193463395

Epoch: 6| Step: 3
Training loss: 1.7189269065856934
Validation loss: 2.0270621725308

Epoch: 6| Step: 4
Training loss: 0.9836112856864929
Validation loss: 2.043399880009313

Epoch: 6| Step: 5
Training loss: 1.0206501483917236
Validation loss: 2.0175107666241225

Epoch: 6| Step: 6
Training loss: 1.4134905338287354
Validation loss: 2.016504869666151

Epoch: 6| Step: 7
Training loss: 1.3736648559570312
Validation loss: 2.0182561374479726

Epoch: 6| Step: 8
Training loss: 1.4751365184783936
Validation loss: 2.099472963681785

Epoch: 6| Step: 9
Training loss: 1.513692855834961
Validation loss: 2.0218015255466586

Epoch: 6| Step: 10
Training loss: 1.0135769844055176
Validation loss: 2.091846799337736

Epoch: 6| Step: 11
Training loss: 0.9408437013626099
Validation loss: 2.0574428548095045

Epoch: 6| Step: 12
Training loss: 1.189650297164917
Validation loss: 2.0435814665209864

Epoch: 6| Step: 13
Training loss: 2.640625
Validation loss: 2.0443175121020247

Epoch: 576| Step: 0
Training loss: 1.9060559272766113
Validation loss: 2.025924519826007

Epoch: 6| Step: 1
Training loss: 1.2346209287643433
Validation loss: 2.060680627822876

Epoch: 6| Step: 2
Training loss: 1.5277199745178223
Validation loss: 2.0289029716163554

Epoch: 6| Step: 3
Training loss: 1.2107661962509155
Validation loss: 2.063826871174638

Epoch: 6| Step: 4
Training loss: 1.3332163095474243
Validation loss: 2.065324515424749

Epoch: 6| Step: 5
Training loss: 1.5330524444580078
Validation loss: 2.0635361479174708

Epoch: 6| Step: 6
Training loss: 1.465980052947998
Validation loss: 2.01460491072747

Epoch: 6| Step: 7
Training loss: 1.4553937911987305
Validation loss: 2.03034798560604

Epoch: 6| Step: 8
Training loss: 0.9712765216827393
Validation loss: 2.0666928265684392

Epoch: 6| Step: 9
Training loss: 1.2313402891159058
Validation loss: 2.0967790516473914

Epoch: 6| Step: 10
Training loss: 1.0654516220092773
Validation loss: 2.0727436568147395

Epoch: 6| Step: 11
Training loss: 1.3936402797698975
Validation loss: 2.073817747895436

Epoch: 6| Step: 12
Training loss: 0.5128951072692871
Validation loss: 2.114448365344796

Epoch: 6| Step: 13
Training loss: 1.3320316076278687
Validation loss: 2.095218707156438

Epoch: 577| Step: 0
Training loss: 1.075567364692688
Validation loss: 2.0529450960056757

Epoch: 6| Step: 1
Training loss: 1.7120240926742554
Validation loss: 2.0634151607431392

Epoch: 6| Step: 2
Training loss: 1.0418727397918701
Validation loss: 2.080773550976989

Epoch: 6| Step: 3
Training loss: 1.8229575157165527
Validation loss: 2.0767222501898326

Epoch: 6| Step: 4
Training loss: 1.6278469562530518
Validation loss: 2.0686845625600507

Epoch: 6| Step: 5
Training loss: 1.2151951789855957
Validation loss: 2.031665740474578

Epoch: 6| Step: 6
Training loss: 1.360116720199585
Validation loss: 2.0073566218858123

Epoch: 6| Step: 7
Training loss: 1.553026795387268
Validation loss: 2.008938253566783

Epoch: 6| Step: 8
Training loss: 0.938916027545929
Validation loss: 2.0710805205888647

Epoch: 6| Step: 9
Training loss: 1.6480211019515991
Validation loss: 2.041889044546312

Epoch: 6| Step: 10
Training loss: 1.5639617443084717
Validation loss: 2.0644681569068664

Epoch: 6| Step: 11
Training loss: 0.9913172721862793
Validation loss: 2.0584699517937115

Epoch: 6| Step: 12
Training loss: 0.8451175689697266
Validation loss: 2.059539552657835

Epoch: 6| Step: 13
Training loss: 1.206536889076233
Validation loss: 2.082657943489731

Epoch: 578| Step: 0
Training loss: 1.1181974411010742
Validation loss: 2.065329331223683

Epoch: 6| Step: 1
Training loss: 1.1724200248718262
Validation loss: 2.0315992281001103

Epoch: 6| Step: 2
Training loss: 1.4434658288955688
Validation loss: 2.074402678397394

Epoch: 6| Step: 3
Training loss: 0.7886859774589539
Validation loss: 2.0416387922020367

Epoch: 6| Step: 4
Training loss: 1.8525367975234985
Validation loss: 2.008475529250278

Epoch: 6| Step: 5
Training loss: 1.0798156261444092
Validation loss: 2.075352430343628

Epoch: 6| Step: 6
Training loss: 1.4970637559890747
Validation loss: 2.051546691566385

Epoch: 6| Step: 7
Training loss: 1.5958548784255981
Validation loss: 2.096654401030592

Epoch: 6| Step: 8
Training loss: 1.7847363948822021
Validation loss: 2.0778803927924043

Epoch: 6| Step: 9
Training loss: 1.638476848602295
Validation loss: 2.0597163836161294

Epoch: 6| Step: 10
Training loss: 0.8231120109558105
Validation loss: 2.0214362349561465

Epoch: 6| Step: 11
Training loss: 1.16130793094635
Validation loss: 2.025607707679913

Epoch: 6| Step: 12
Training loss: 0.8195176124572754
Validation loss: 2.050242203538136

Epoch: 6| Step: 13
Training loss: 0.9492401480674744
Validation loss: 2.033418837413993

Epoch: 579| Step: 0
Training loss: 0.9632923603057861
Validation loss: 2.062717996617799

Epoch: 6| Step: 1
Training loss: 0.8420114517211914
Validation loss: 2.045813665595106

Epoch: 6| Step: 2
Training loss: 1.6464719772338867
Validation loss: 2.0549837261117916

Epoch: 6| Step: 3
Training loss: 0.980861246585846
Validation loss: 2.055422789307051

Epoch: 6| Step: 4
Training loss: 1.1859052181243896
Validation loss: 2.0442431280689854

Epoch: 6| Step: 5
Training loss: 1.7153241634368896
Validation loss: 2.0480175325947423

Epoch: 6| Step: 6
Training loss: 1.683142900466919
Validation loss: 2.0079311760522986

Epoch: 6| Step: 7
Training loss: 1.7542390823364258
Validation loss: 2.05138462333269

Epoch: 6| Step: 8
Training loss: 0.9201810359954834
Validation loss: 2.0430986496710006

Epoch: 6| Step: 9
Training loss: 1.5924503803253174
Validation loss: 2.046911279360453

Epoch: 6| Step: 10
Training loss: 1.4508289098739624
Validation loss: 2.0098320117560764

Epoch: 6| Step: 11
Training loss: 0.9237813949584961
Validation loss: 2.0818775751257457

Epoch: 6| Step: 12
Training loss: 1.5436530113220215
Validation loss: 2.083063840866089

Epoch: 6| Step: 13
Training loss: 0.38485628366470337
Validation loss: 2.0589764297649427

Epoch: 580| Step: 0
Training loss: 1.340657114982605
Validation loss: 2.04829413660111

Epoch: 6| Step: 1
Training loss: 1.4856719970703125
Validation loss: 2.0418379152974775

Epoch: 6| Step: 2
Training loss: 1.0749846696853638
Validation loss: 2.0483417895532425

Epoch: 6| Step: 3
Training loss: 0.9655876159667969
Validation loss: 2.05459326569752

Epoch: 6| Step: 4
Training loss: 1.2321265935897827
Validation loss: 2.0085231591296453

Epoch: 6| Step: 5
Training loss: 1.8830828666687012
Validation loss: 2.054489204960485

Epoch: 6| Step: 6
Training loss: 0.8409529328346252
Validation loss: 2.0699367856466644

Epoch: 6| Step: 7
Training loss: 1.381717324256897
Validation loss: 2.083909688457366

Epoch: 6| Step: 8
Training loss: 1.7320916652679443
Validation loss: 2.0492847581063547

Epoch: 6| Step: 9
Training loss: 1.5279581546783447
Validation loss: 2.080447002123761

Epoch: 6| Step: 10
Training loss: 0.8363502025604248
Validation loss: 2.068043565237394

Epoch: 6| Step: 11
Training loss: 1.1314918994903564
Validation loss: 2.0625249339688208

Epoch: 6| Step: 12
Training loss: 1.0201265811920166
Validation loss: 2.080501469232703

Epoch: 6| Step: 13
Training loss: 1.3556069135665894
Validation loss: 2.0297869995076168

Epoch: 581| Step: 0
Training loss: 1.3558536767959595
Validation loss: 2.0762751563902824

Epoch: 6| Step: 1
Training loss: 1.120754361152649
Validation loss: 2.0742697869577715

Epoch: 6| Step: 2
Training loss: 1.5099823474884033
Validation loss: 2.0303765701991257

Epoch: 6| Step: 3
Training loss: 1.0865660905838013
Validation loss: 2.072838952464442

Epoch: 6| Step: 4
Training loss: 1.2232494354248047
Validation loss: 2.057466014739006

Epoch: 6| Step: 5
Training loss: 2.1244847774505615
Validation loss: 2.059583697267758

Epoch: 6| Step: 6
Training loss: 1.7271060943603516
Validation loss: 2.0882259568860455

Epoch: 6| Step: 7
Training loss: 0.9411513209342957
Validation loss: 2.073837108509515

Epoch: 6| Step: 8
Training loss: 1.1432080268859863
Validation loss: 2.0384414606196906

Epoch: 6| Step: 9
Training loss: 0.9665093421936035
Validation loss: 2.034227398134047

Epoch: 6| Step: 10
Training loss: 1.7680940628051758
Validation loss: 1.9977193660633539

Epoch: 6| Step: 11
Training loss: 1.431996464729309
Validation loss: 2.0664109106986754

Epoch: 6| Step: 12
Training loss: 0.6833508014678955
Validation loss: 2.0387496999515

Epoch: 6| Step: 13
Training loss: 0.7166821956634521
Validation loss: 2.0241579112186225

Epoch: 582| Step: 0
Training loss: 1.7155309915542603
Validation loss: 2.0537174876018236

Epoch: 6| Step: 1
Training loss: 1.7935819625854492
Validation loss: 2.0276315494250228

Epoch: 6| Step: 2
Training loss: 1.359917402267456
Validation loss: 2.0637497491734003

Epoch: 6| Step: 3
Training loss: 0.754732072353363
Validation loss: 2.072238095345036

Epoch: 6| Step: 4
Training loss: 1.7097309827804565
Validation loss: 2.042122802426738

Epoch: 6| Step: 5
Training loss: 1.0478496551513672
Validation loss: 2.0437526690062655

Epoch: 6| Step: 6
Training loss: 1.838958978652954
Validation loss: 2.0827080434368503

Epoch: 6| Step: 7
Training loss: 1.4771034717559814
Validation loss: 2.062001298832637

Epoch: 6| Step: 8
Training loss: 1.1171435117721558
Validation loss: 2.0441786396887993

Epoch: 6| Step: 9
Training loss: 0.6236890554428101
Validation loss: 2.0444766193307857

Epoch: 6| Step: 10
Training loss: 0.9714090824127197
Validation loss: 2.049413187529451

Epoch: 6| Step: 11
Training loss: 0.8947527408599854
Validation loss: 2.0252508630034742

Epoch: 6| Step: 12
Training loss: 1.5539448261260986
Validation loss: 2.0325449794851322

Epoch: 6| Step: 13
Training loss: 1.0228347778320312
Validation loss: 2.0622936371834046

Epoch: 583| Step: 0
Training loss: 1.39335036277771
Validation loss: 2.0708216339029293

Epoch: 6| Step: 1
Training loss: 1.0978474617004395
Validation loss: 2.0253367706011702

Epoch: 6| Step: 2
Training loss: 1.679192066192627
Validation loss: 2.057453005544601

Epoch: 6| Step: 3
Training loss: 1.2377712726593018
Validation loss: 2.031505525753062

Epoch: 6| Step: 4
Training loss: 1.6975016593933105
Validation loss: 2.0594040424593034

Epoch: 6| Step: 5
Training loss: 0.8921023011207581
Validation loss: 2.0315676722475278

Epoch: 6| Step: 6
Training loss: 1.1728153228759766
Validation loss: 2.0228785417413198

Epoch: 6| Step: 7
Training loss: 1.1460368633270264
Validation loss: 2.008742117112683

Epoch: 6| Step: 8
Training loss: 1.693963646888733
Validation loss: 2.0600220541800223

Epoch: 6| Step: 9
Training loss: 0.934007465839386
Validation loss: 2.0276506549568585

Epoch: 6| Step: 10
Training loss: 1.4977542161941528
Validation loss: 2.061306239456259

Epoch: 6| Step: 11
Training loss: 1.2063065767288208
Validation loss: 2.0438031227357927

Epoch: 6| Step: 12
Training loss: 1.124002456665039
Validation loss: 2.0528297347407185

Epoch: 6| Step: 13
Training loss: 0.642388105392456
Validation loss: 2.03445710930773

Epoch: 584| Step: 0
Training loss: 0.9889432191848755
Validation loss: 2.064667952957974

Epoch: 6| Step: 1
Training loss: 2.0578670501708984
Validation loss: 2.0390507021257953

Epoch: 6| Step: 2
Training loss: 0.7950106859207153
Validation loss: 2.0460617952449347

Epoch: 6| Step: 3
Training loss: 0.8093039989471436
Validation loss: 2.0532461289436585

Epoch: 6| Step: 4
Training loss: 1.1337740421295166
Validation loss: 2.0629430893928773

Epoch: 6| Step: 5
Training loss: 1.062107801437378
Validation loss: 2.0400264698971986

Epoch: 6| Step: 6
Training loss: 2.16733717918396
Validation loss: 2.0742645917400235

Epoch: 6| Step: 7
Training loss: 1.336366891860962
Validation loss: 2.0397492249806723

Epoch: 6| Step: 8
Training loss: 1.3378069400787354
Validation loss: 2.08117950090798

Epoch: 6| Step: 9
Training loss: 1.320279836654663
Validation loss: 2.0295691272263885

Epoch: 6| Step: 10
Training loss: 1.3905632495880127
Validation loss: 2.0326699390206286

Epoch: 6| Step: 11
Training loss: 1.0082268714904785
Validation loss: 2.040716184082852

Epoch: 6| Step: 12
Training loss: 1.0198910236358643
Validation loss: 2.0603103996605

Epoch: 6| Step: 13
Training loss: 1.3681279420852661
Validation loss: 2.085229960821008

Epoch: 585| Step: 0
Training loss: 1.1156349182128906
Validation loss: 2.0903943302810832

Epoch: 6| Step: 1
Training loss: 1.186793327331543
Validation loss: 2.0608182684067757

Epoch: 6| Step: 2
Training loss: 1.4001134634017944
Validation loss: 2.021545079446608

Epoch: 6| Step: 3
Training loss: 0.837042510509491
Validation loss: 2.059997171484014

Epoch: 6| Step: 4
Training loss: 0.9489393830299377
Validation loss: 2.064299967981154

Epoch: 6| Step: 5
Training loss: 1.5190069675445557
Validation loss: 2.0863306932551886

Epoch: 6| Step: 6
Training loss: 1.2524573802947998
Validation loss: 2.0800012209082164

Epoch: 6| Step: 7
Training loss: 1.3629025220870972
Validation loss: 2.0692391959569787

Epoch: 6| Step: 8
Training loss: 1.0574465990066528
Validation loss: 2.1304287115732827

Epoch: 6| Step: 9
Training loss: 1.2863332033157349
Validation loss: 2.0320531732292584

Epoch: 6| Step: 10
Training loss: 1.6667314767837524
Validation loss: 2.011132706878006

Epoch: 6| Step: 11
Training loss: 1.1374791860580444
Validation loss: 2.044660161900264

Epoch: 6| Step: 12
Training loss: 1.58724045753479
Validation loss: 2.0961615270183933

Epoch: 6| Step: 13
Training loss: 1.184030532836914
Validation loss: 2.062164111803937

Epoch: 586| Step: 0
Training loss: 1.0706535577774048
Validation loss: 2.0924181322897635

Epoch: 6| Step: 1
Training loss: 1.2149441242218018
Validation loss: 2.0144541930126887

Epoch: 6| Step: 2
Training loss: 1.3650238513946533
Validation loss: 2.060499216920586

Epoch: 6| Step: 3
Training loss: 1.4426405429840088
Validation loss: 2.043548498102414

Epoch: 6| Step: 4
Training loss: 0.9344818592071533
Validation loss: 2.0975582381730438

Epoch: 6| Step: 5
Training loss: 1.3842726945877075
Validation loss: 2.0360136852469495

Epoch: 6| Step: 6
Training loss: 1.8015450239181519
Validation loss: 2.0601094538165676

Epoch: 6| Step: 7
Training loss: 1.5841846466064453
Validation loss: 2.0311300780183528

Epoch: 6| Step: 8
Training loss: 1.5417046546936035
Validation loss: 2.0377117562037643

Epoch: 6| Step: 9
Training loss: 0.502601683139801
Validation loss: 2.053512368150937

Epoch: 6| Step: 10
Training loss: 1.6382371187210083
Validation loss: 2.059762485565678

Epoch: 6| Step: 11
Training loss: 0.5891886949539185
Validation loss: 2.0647984063753517

Epoch: 6| Step: 12
Training loss: 1.4218617677688599
Validation loss: 2.025079111899099

Epoch: 6| Step: 13
Training loss: 1.391074538230896
Validation loss: 2.0575491574502762

Epoch: 587| Step: 0
Training loss: 1.3079441785812378
Validation loss: 2.076196878187118

Epoch: 6| Step: 1
Training loss: 1.1194729804992676
Validation loss: 2.0803371039769982

Epoch: 6| Step: 2
Training loss: 1.032510757446289
Validation loss: 2.117782110808998

Epoch: 6| Step: 3
Training loss: 1.198371410369873
Validation loss: 2.1148388462681926

Epoch: 6| Step: 4
Training loss: 1.047273874282837
Validation loss: 2.1019784481294694

Epoch: 6| Step: 5
Training loss: 1.0624074935913086
Validation loss: 2.0868282805206957

Epoch: 6| Step: 6
Training loss: 1.7786550521850586
Validation loss: 2.0736159201591247

Epoch: 6| Step: 7
Training loss: 1.4492642879486084
Validation loss: 2.0796440032220658

Epoch: 6| Step: 8
Training loss: 1.9438129663467407
Validation loss: 2.067824991800452

Epoch: 6| Step: 9
Training loss: 0.9756723046302795
Validation loss: 2.044610220898864

Epoch: 6| Step: 10
Training loss: 0.7636435031890869
Validation loss: 2.0524661079529793

Epoch: 6| Step: 11
Training loss: 1.1822435855865479
Validation loss: 2.0774573023601244

Epoch: 6| Step: 12
Training loss: 1.312481164932251
Validation loss: 2.0385858269147974

Epoch: 6| Step: 13
Training loss: 2.0511534214019775
Validation loss: 2.041633645693461

Epoch: 588| Step: 0
Training loss: 0.8289578557014465
Validation loss: 2.04315589063911

Epoch: 6| Step: 1
Training loss: 1.972623348236084
Validation loss: 2.0530298474014446

Epoch: 6| Step: 2
Training loss: 1.382152795791626
Validation loss: 2.0260211190869732

Epoch: 6| Step: 3
Training loss: 1.2999026775360107
Validation loss: 2.066306257760653

Epoch: 6| Step: 4
Training loss: 1.7607529163360596
Validation loss: 2.0285655657450357

Epoch: 6| Step: 5
Training loss: 1.9364880323410034
Validation loss: 2.0853548075563166

Epoch: 6| Step: 6
Training loss: 1.0868990421295166
Validation loss: 2.0564841249937653

Epoch: 6| Step: 7
Training loss: 1.0093865394592285
Validation loss: 2.0302963000471874

Epoch: 6| Step: 8
Training loss: 1.088671326637268
Validation loss: 2.025787543225032

Epoch: 6| Step: 9
Training loss: 1.0475811958312988
Validation loss: 2.04969798621311

Epoch: 6| Step: 10
Training loss: 0.7176604270935059
Validation loss: 2.0577241002872424

Epoch: 6| Step: 11
Training loss: 1.2343719005584717
Validation loss: 2.072092738202823

Epoch: 6| Step: 12
Training loss: 1.549926519393921
Validation loss: 2.040114156661495

Epoch: 6| Step: 13
Training loss: 1.1242692470550537
Validation loss: 2.054028687938567

Epoch: 589| Step: 0
Training loss: 0.8661375641822815
Validation loss: 2.069858886862314

Epoch: 6| Step: 1
Training loss: 1.266209602355957
Validation loss: 2.0517859971651466

Epoch: 6| Step: 2
Training loss: 1.1061049699783325
Validation loss: 2.0404111403290943

Epoch: 6| Step: 3
Training loss: 1.1284239292144775
Validation loss: 2.0665920396004953

Epoch: 6| Step: 4
Training loss: 1.3222079277038574
Validation loss: 2.034536718040384

Epoch: 6| Step: 5
Training loss: 1.0603828430175781
Validation loss: 2.0427644509141163

Epoch: 6| Step: 6
Training loss: 1.2727327346801758
Validation loss: 2.0396681524092153

Epoch: 6| Step: 7
Training loss: 1.345879316329956
Validation loss: 2.032367439680202

Epoch: 6| Step: 8
Training loss: 0.897716224193573
Validation loss: 2.078861008408249

Epoch: 6| Step: 9
Training loss: 1.157737135887146
Validation loss: 2.0667131485477572

Epoch: 6| Step: 10
Training loss: 1.4906542301177979
Validation loss: 2.056152187367921

Epoch: 6| Step: 11
Training loss: 1.3915534019470215
Validation loss: 2.0097790520678283

Epoch: 6| Step: 12
Training loss: 1.4180834293365479
Validation loss: 2.040822902033406

Epoch: 6| Step: 13
Training loss: 2.174428701400757
Validation loss: 2.0541108474936536

Epoch: 590| Step: 0
Training loss: 0.7182329893112183
Validation loss: 2.072513452140234

Epoch: 6| Step: 1
Training loss: 1.5056301355361938
Validation loss: 2.0631891706938386

Epoch: 6| Step: 2
Training loss: 1.0817534923553467
Validation loss: 2.061224656720315

Epoch: 6| Step: 3
Training loss: 1.4659706354141235
Validation loss: 2.09288949863885

Epoch: 6| Step: 4
Training loss: 1.0383723974227905
Validation loss: 2.057049846136442

Epoch: 6| Step: 5
Training loss: 1.3108586072921753
Validation loss: 2.0857163475405787

Epoch: 6| Step: 6
Training loss: 1.499430775642395
Validation loss: 2.0954148743742254

Epoch: 6| Step: 7
Training loss: 1.0284384489059448
Validation loss: 2.0519961618608042

Epoch: 6| Step: 8
Training loss: 1.4638557434082031
Validation loss: 2.0259463774260653

Epoch: 6| Step: 9
Training loss: 1.6096508502960205
Validation loss: 2.0542938401622157

Epoch: 6| Step: 10
Training loss: 1.1612104177474976
Validation loss: 2.0517128231704875

Epoch: 6| Step: 11
Training loss: 0.8778265118598938
Validation loss: 2.075046682870516

Epoch: 6| Step: 12
Training loss: 1.2997279167175293
Validation loss: 2.060544962524086

Epoch: 6| Step: 13
Training loss: 1.512154459953308
Validation loss: 2.019789077902353

Epoch: 591| Step: 0
Training loss: 1.2300653457641602
Validation loss: 2.081452981118233

Epoch: 6| Step: 1
Training loss: 1.585078477859497
Validation loss: 2.0421148371952835

Epoch: 6| Step: 2
Training loss: 1.1214580535888672
Validation loss: 2.0860722116244736

Epoch: 6| Step: 3
Training loss: 1.4375371932983398
Validation loss: 2.0123902725917038

Epoch: 6| Step: 4
Training loss: 1.2821636199951172
Validation loss: 2.056276379093047

Epoch: 6| Step: 5
Training loss: 1.350728988647461
Validation loss: 2.0914559287409626

Epoch: 6| Step: 6
Training loss: 1.2664134502410889
Validation loss: 2.042252076569424

Epoch: 6| Step: 7
Training loss: 0.7729472517967224
Validation loss: 2.0765094295624764

Epoch: 6| Step: 8
Training loss: 1.2823617458343506
Validation loss: 2.071083052183992

Epoch: 6| Step: 9
Training loss: 0.8646715879440308
Validation loss: 2.06557257329264

Epoch: 6| Step: 10
Training loss: 1.6507625579833984
Validation loss: 2.0596065072603125

Epoch: 6| Step: 11
Training loss: 1.4197804927825928
Validation loss: 2.051350197484416

Epoch: 6| Step: 12
Training loss: 1.2986774444580078
Validation loss: 2.103247736089973

Epoch: 6| Step: 13
Training loss: 1.3327490091323853
Validation loss: 2.0714599214574343

Epoch: 592| Step: 0
Training loss: 1.5702205896377563
Validation loss: 2.06116013116734

Epoch: 6| Step: 1
Training loss: 1.0096564292907715
Validation loss: 2.053965622378934

Epoch: 6| Step: 2
Training loss: 1.2414631843566895
Validation loss: 2.113568894324764

Epoch: 6| Step: 3
Training loss: 0.6544150710105896
Validation loss: 2.0893184625974266

Epoch: 6| Step: 4
Training loss: 0.9793497920036316
Validation loss: 2.073586335746191

Epoch: 6| Step: 5
Training loss: 1.0393953323364258
Validation loss: 2.0449060188826693

Epoch: 6| Step: 6
Training loss: 1.2390644550323486
Validation loss: 2.0565359477073915

Epoch: 6| Step: 7
Training loss: 1.1427242755889893
Validation loss: 2.056069238211519

Epoch: 6| Step: 8
Training loss: 1.369661569595337
Validation loss: 2.0668218520379837

Epoch: 6| Step: 9
Training loss: 1.921822190284729
Validation loss: 2.0438675867613925

Epoch: 6| Step: 10
Training loss: 1.1598302125930786
Validation loss: 2.009670131949968

Epoch: 6| Step: 11
Training loss: 1.1739184856414795
Validation loss: 2.0161208568080777

Epoch: 6| Step: 12
Training loss: 1.5984864234924316
Validation loss: 2.064316559863347

Epoch: 6| Step: 13
Training loss: 2.545891284942627
Validation loss: 2.0774127437222387

Epoch: 593| Step: 0
Training loss: 1.2596880197525024
Validation loss: 2.0725871926994732

Epoch: 6| Step: 1
Training loss: 1.6198917627334595
Validation loss: 2.0483108361562095

Epoch: 6| Step: 2
Training loss: 1.2339906692504883
Validation loss: 2.050154170682353

Epoch: 6| Step: 3
Training loss: 1.3718247413635254
Validation loss: 2.0480555219034993

Epoch: 6| Step: 4
Training loss: 0.6801996231079102
Validation loss: 2.0800465973474647

Epoch: 6| Step: 5
Training loss: 1.2387804985046387
Validation loss: 2.0663413732282576

Epoch: 6| Step: 6
Training loss: 1.8611799478530884
Validation loss: 2.0852860763508785

Epoch: 6| Step: 7
Training loss: 1.188939094543457
Validation loss: 2.0707105205905054

Epoch: 6| Step: 8
Training loss: 0.9669530391693115
Validation loss: 2.0746930312084895

Epoch: 6| Step: 9
Training loss: 1.359835147857666
Validation loss: 2.0600426248324815

Epoch: 6| Step: 10
Training loss: 0.9618170261383057
Validation loss: 2.098551570728261

Epoch: 6| Step: 11
Training loss: 1.947216510772705
Validation loss: 2.094848696903516

Epoch: 6| Step: 12
Training loss: 1.0027010440826416
Validation loss: 2.0852164042893278

Epoch: 6| Step: 13
Training loss: 1.4446492195129395
Validation loss: 2.086126423651172

Epoch: 594| Step: 0
Training loss: 1.6362476348876953
Validation loss: 2.0551315571672175

Epoch: 6| Step: 1
Training loss: 1.4458975791931152
Validation loss: 2.0569760504589287

Epoch: 6| Step: 2
Training loss: 0.7901060581207275
Validation loss: 2.073236962800385

Epoch: 6| Step: 3
Training loss: 1.1075530052185059
Validation loss: 1.987493940578994

Epoch: 6| Step: 4
Training loss: 1.7786445617675781
Validation loss: 2.0559576134527884

Epoch: 6| Step: 5
Training loss: 1.1440396308898926
Validation loss: 2.087087062097365

Epoch: 6| Step: 6
Training loss: 1.3304286003112793
Validation loss: 2.061119762800073

Epoch: 6| Step: 7
Training loss: 1.2760977745056152
Validation loss: 2.066742193314337

Epoch: 6| Step: 8
Training loss: 0.7358663082122803
Validation loss: 2.0501987562384656

Epoch: 6| Step: 9
Training loss: 1.3327362537384033
Validation loss: 2.054739304768142

Epoch: 6| Step: 10
Training loss: 1.0388518571853638
Validation loss: 2.047960094226304

Epoch: 6| Step: 11
Training loss: 1.300784945487976
Validation loss: 2.0183372471922185

Epoch: 6| Step: 12
Training loss: 1.4422788619995117
Validation loss: 2.0299542091226064

Epoch: 6| Step: 13
Training loss: 2.0178613662719727
Validation loss: 2.0737830413285123

Epoch: 595| Step: 0
Training loss: 0.6765508055686951
Validation loss: 2.077090287721285

Epoch: 6| Step: 1
Training loss: 1.0343868732452393
Validation loss: 2.062933889768457

Epoch: 6| Step: 2
Training loss: 1.0813243389129639
Validation loss: 2.0355884836566065

Epoch: 6| Step: 3
Training loss: 0.6864379048347473
Validation loss: 2.058099792849633

Epoch: 6| Step: 4
Training loss: 1.3403576612472534
Validation loss: 2.1057084221993723

Epoch: 6| Step: 5
Training loss: 1.2721821069717407
Validation loss: 2.0529591345017955

Epoch: 6| Step: 6
Training loss: 1.8264693021774292
Validation loss: 2.0579858659416117

Epoch: 6| Step: 7
Training loss: 1.4474873542785645
Validation loss: 2.0742073687173987

Epoch: 6| Step: 8
Training loss: 1.4550124406814575
Validation loss: 2.0286186356698312

Epoch: 6| Step: 9
Training loss: 1.5976464748382568
Validation loss: 2.0302764766959736

Epoch: 6| Step: 10
Training loss: 1.6657108068466187
Validation loss: 2.030209097810971

Epoch: 6| Step: 11
Training loss: 1.0501103401184082
Validation loss: 2.0226158352308374

Epoch: 6| Step: 12
Training loss: 1.4697465896606445
Validation loss: 2.069946515944696

Epoch: 6| Step: 13
Training loss: 1.1642234325408936
Validation loss: 2.062262701731856

Epoch: 596| Step: 0
Training loss: 1.2172706127166748
Validation loss: 2.050683673991952

Epoch: 6| Step: 1
Training loss: 1.942962884902954
Validation loss: 2.04132979659624

Epoch: 6| Step: 2
Training loss: 1.2286951541900635
Validation loss: 2.0426121450239614

Epoch: 6| Step: 3
Training loss: 1.412712812423706
Validation loss: 2.0499949557806856

Epoch: 6| Step: 4
Training loss: 0.7221843004226685
Validation loss: 2.0568279168939076

Epoch: 6| Step: 5
Training loss: 1.1985712051391602
Validation loss: 2.092079331797938

Epoch: 6| Step: 6
Training loss: 1.4185148477554321
Validation loss: 2.0219608224848264

Epoch: 6| Step: 7
Training loss: 0.9843695163726807
Validation loss: 2.0347431936571674

Epoch: 6| Step: 8
Training loss: 1.012502908706665
Validation loss: 2.06809357161163

Epoch: 6| Step: 9
Training loss: 1.3239070177078247
Validation loss: 2.0425573523326586

Epoch: 6| Step: 10
Training loss: 1.2627921104431152
Validation loss: 2.0889256385064896

Epoch: 6| Step: 11
Training loss: 1.1374125480651855
Validation loss: 2.0544318691376717

Epoch: 6| Step: 12
Training loss: 1.4420632123947144
Validation loss: 2.0502835806979927

Epoch: 6| Step: 13
Training loss: 1.312223196029663
Validation loss: 2.063088801599318

Epoch: 597| Step: 0
Training loss: 1.392078161239624
Validation loss: 2.0635234489235827

Epoch: 6| Step: 1
Training loss: 1.1984174251556396
Validation loss: 2.0569488694590907

Epoch: 6| Step: 2
Training loss: 1.3411824703216553
Validation loss: 2.0937947304018083

Epoch: 6| Step: 3
Training loss: 1.5143299102783203
Validation loss: 2.067675454642183

Epoch: 6| Step: 4
Training loss: 0.7709592580795288
Validation loss: 2.059681666794644

Epoch: 6| Step: 5
Training loss: 1.3099009990692139
Validation loss: 2.0432986854225077

Epoch: 6| Step: 6
Training loss: 1.4605823755264282
Validation loss: 2.1141109107643046

Epoch: 6| Step: 7
Training loss: 1.7144325971603394
Validation loss: 2.0691449642181396

Epoch: 6| Step: 8
Training loss: 1.380394697189331
Validation loss: 2.0965404548952655

Epoch: 6| Step: 9
Training loss: 1.1960220336914062
Validation loss: 2.0892217031089206

Epoch: 6| Step: 10
Training loss: 0.9663593769073486
Validation loss: 2.0785642618774087

Epoch: 6| Step: 11
Training loss: 1.5963091850280762
Validation loss: 2.0906823424882788

Epoch: 6| Step: 12
Training loss: 0.6614159941673279
Validation loss: 2.0169478821498092

Epoch: 6| Step: 13
Training loss: 1.1272834539413452
Validation loss: 2.0415792106300272

Epoch: 598| Step: 0
Training loss: 1.4421159029006958
Validation loss: 2.042771239434519

Epoch: 6| Step: 1
Training loss: 1.4935095310211182
Validation loss: 2.0694238652465162

Epoch: 6| Step: 2
Training loss: 1.268462061882019
Validation loss: 2.068935622451126

Epoch: 6| Step: 3
Training loss: 1.095054030418396
Validation loss: 2.0879893995100454

Epoch: 6| Step: 4
Training loss: 0.9948999881744385
Validation loss: 2.056766022918045

Epoch: 6| Step: 5
Training loss: 1.2925750017166138
Validation loss: 2.044620583134313

Epoch: 6| Step: 6
Training loss: 0.898593008518219
Validation loss: 2.039152410722548

Epoch: 6| Step: 7
Training loss: 0.7679947018623352
Validation loss: 2.029593657421809

Epoch: 6| Step: 8
Training loss: 1.0422323942184448
Validation loss: 2.057968056330117

Epoch: 6| Step: 9
Training loss: 1.2268340587615967
Validation loss: 2.0803136466651835

Epoch: 6| Step: 10
Training loss: 1.4665378332138062
Validation loss: 2.0912573183736494

Epoch: 6| Step: 11
Training loss: 1.629628300666809
Validation loss: 2.106568900487756

Epoch: 6| Step: 12
Training loss: 1.726921558380127
Validation loss: 2.088872707018288

Epoch: 6| Step: 13
Training loss: 1.2288753986358643
Validation loss: 2.0507205968262046

Epoch: 599| Step: 0
Training loss: 1.3284056186676025
Validation loss: 2.0658331301904496

Epoch: 6| Step: 1
Training loss: 1.0583391189575195
Validation loss: 2.064673959567983

Epoch: 6| Step: 2
Training loss: 0.5672271847724915
Validation loss: 2.044322157418856

Epoch: 6| Step: 3
Training loss: 0.616879403591156
Validation loss: 2.0609250824938536

Epoch: 6| Step: 4
Training loss: 1.161665916442871
Validation loss: 2.0595862250174246

Epoch: 6| Step: 5
Training loss: 1.6187965869903564
Validation loss: 2.052798132742605

Epoch: 6| Step: 6
Training loss: 1.528569221496582
Validation loss: 2.0542559880082325

Epoch: 6| Step: 7
Training loss: 1.597835898399353
Validation loss: 2.0162106008939844

Epoch: 6| Step: 8
Training loss: 0.8522883653640747
Validation loss: 2.0732240817880117

Epoch: 6| Step: 9
Training loss: 1.4583739042282104
Validation loss: 2.04240910596745

Epoch: 6| Step: 10
Training loss: 1.4049928188323975
Validation loss: 2.062820508915891

Epoch: 6| Step: 11
Training loss: 1.0986323356628418
Validation loss: 2.0517925882852204

Epoch: 6| Step: 12
Training loss: 1.785304307937622
Validation loss: 2.0810428127165763

Epoch: 6| Step: 13
Training loss: 1.3509634733200073
Validation loss: 2.049900121586297

Epoch: 600| Step: 0
Training loss: 1.540568470954895
Validation loss: 2.0906591210314023

Epoch: 6| Step: 1
Training loss: 1.1288537979125977
Validation loss: 2.0629582379453923

Epoch: 6| Step: 2
Training loss: 1.570333480834961
Validation loss: 2.084275640467162

Epoch: 6| Step: 3
Training loss: 1.091654896736145
Validation loss: 2.11129952246143

Epoch: 6| Step: 4
Training loss: 1.1387240886688232
Validation loss: 2.090707045729442

Epoch: 6| Step: 5
Training loss: 1.8419724702835083
Validation loss: 2.0847994076308383

Epoch: 6| Step: 6
Training loss: 1.0806455612182617
Validation loss: 2.0920707897473405

Epoch: 6| Step: 7
Training loss: 1.356511116027832
Validation loss: 2.105368680851434

Epoch: 6| Step: 8
Training loss: 1.297730565071106
Validation loss: 2.112546024783965

Epoch: 6| Step: 9
Training loss: 1.0586562156677246
Validation loss: 2.0679545351254043

Epoch: 6| Step: 10
Training loss: 1.6630661487579346
Validation loss: 2.0483448607947237

Epoch: 6| Step: 11
Training loss: 0.9902365803718567
Validation loss: 2.042824467023214

Epoch: 6| Step: 12
Training loss: 0.7480425834655762
Validation loss: 2.0419678329139628

Epoch: 6| Step: 13
Training loss: 0.9907839894294739
Validation loss: 2.0481247953189317

Testing loss: 2.1412251128090753
