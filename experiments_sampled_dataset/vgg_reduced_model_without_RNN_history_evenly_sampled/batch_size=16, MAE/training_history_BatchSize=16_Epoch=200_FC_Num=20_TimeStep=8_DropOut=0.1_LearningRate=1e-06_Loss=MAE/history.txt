Epoch: 1| Step: 0
Training loss: 4.110125541687012
Validation loss: 4.132490409317837

Epoch: 6| Step: 1
Training loss: 4.342065811157227
Validation loss: 4.1311273497919885

Epoch: 6| Step: 2
Training loss: 3.638932228088379
Validation loss: 4.127315641731344

Epoch: 6| Step: 3
Training loss: 5.4672675132751465
Validation loss: 4.125633649928595

Epoch: 6| Step: 4
Training loss: 4.319515228271484
Validation loss: 4.123309012382261

Epoch: 6| Step: 5
Training loss: 2.882429361343384
Validation loss: 4.1226441424380065

Epoch: 6| Step: 6
Training loss: 5.0218048095703125
Validation loss: 4.1171844492676435

Epoch: 6| Step: 7
Training loss: 2.7686212062835693
Validation loss: 4.115873218864523

Epoch: 6| Step: 8
Training loss: 2.983945846557617
Validation loss: 4.113298211046445

Epoch: 6| Step: 9
Training loss: 4.002493381500244
Validation loss: 4.111586493830527

Epoch: 6| Step: 10
Training loss: 3.74196195602417
Validation loss: 4.107972780863444

Epoch: 6| Step: 11
Training loss: 4.0247907638549805
Validation loss: 4.10803416467482

Epoch: 6| Step: 12
Training loss: 4.287662506103516
Validation loss: 4.105179473917971

Epoch: 6| Step: 13
Training loss: 3.6819937229156494
Validation loss: 4.104417006174724

Epoch: 2| Step: 0
Training loss: 3.0561177730560303
Validation loss: 4.101103069961712

Epoch: 6| Step: 1
Training loss: 3.2696003913879395
Validation loss: 4.099267539157663

Epoch: 6| Step: 2
Training loss: 4.326796531677246
Validation loss: 4.09777174201063

Epoch: 6| Step: 3
Training loss: 4.124123573303223
Validation loss: 4.093284660770047

Epoch: 6| Step: 4
Training loss: 4.269479751586914
Validation loss: 4.091099416055987

Epoch: 6| Step: 5
Training loss: 4.9915385246276855
Validation loss: 4.08971627553304

Epoch: 6| Step: 6
Training loss: 3.4998292922973633
Validation loss: 4.086925521973641

Epoch: 6| Step: 7
Training loss: 4.576557159423828
Validation loss: 4.08503443707702

Epoch: 6| Step: 8
Training loss: 3.7970876693725586
Validation loss: 4.082802167502782

Epoch: 6| Step: 9
Training loss: 3.4420886039733887
Validation loss: 4.080652431775165

Epoch: 6| Step: 10
Training loss: 2.9149322509765625
Validation loss: 4.077220588602046

Epoch: 6| Step: 11
Training loss: 4.379039287567139
Validation loss: 4.075781560713245

Epoch: 6| Step: 12
Training loss: 4.084266662597656
Validation loss: 4.0727193535015145

Epoch: 6| Step: 13
Training loss: 4.496493816375732
Validation loss: 4.070966507798882

Epoch: 3| Step: 0
Training loss: 3.7377302646636963
Validation loss: 4.066680231401997

Epoch: 6| Step: 1
Training loss: 5.092649459838867
Validation loss: 4.066462455257293

Epoch: 6| Step: 2
Training loss: 4.584157943725586
Validation loss: 4.063840807125133

Epoch: 6| Step: 3
Training loss: 4.760544776916504
Validation loss: 4.059524833515126

Epoch: 6| Step: 4
Training loss: 3.6060774326324463
Validation loss: 4.059831626953617

Epoch: 6| Step: 5
Training loss: 3.9846694469451904
Validation loss: 4.057019349067442

Epoch: 6| Step: 6
Training loss: 2.9607958793640137
Validation loss: 4.054157000716015

Epoch: 6| Step: 7
Training loss: 4.021136283874512
Validation loss: 4.048612251076647

Epoch: 6| Step: 8
Training loss: 3.100356101989746
Validation loss: 4.047981723662345

Epoch: 6| Step: 9
Training loss: 3.451298952102661
Validation loss: 4.048386466118597

Epoch: 6| Step: 10
Training loss: 3.2207961082458496
Validation loss: 4.0427619616190595

Epoch: 6| Step: 11
Training loss: 4.9795002937316895
Validation loss: 4.041348431700019

Epoch: 6| Step: 12
Training loss: 3.899162769317627
Validation loss: 4.037717675649992

Epoch: 6| Step: 13
Training loss: 2.628357410430908
Validation loss: 4.038065459138604

Epoch: 4| Step: 0
Training loss: 5.3266096115112305
Validation loss: 4.032436437504266

Epoch: 6| Step: 1
Training loss: 4.16890811920166
Validation loss: 4.0301950670057725

Epoch: 6| Step: 2
Training loss: 4.303497314453125
Validation loss: 4.025659920066915

Epoch: 6| Step: 3
Training loss: 3.340728998184204
Validation loss: 4.021647514835481

Epoch: 6| Step: 4
Training loss: 4.610795021057129
Validation loss: 4.016853758083877

Epoch: 6| Step: 5
Training loss: 2.7349112033843994
Validation loss: 4.0166529378583355

Epoch: 6| Step: 6
Training loss: 3.989604949951172
Validation loss: 4.014325295725176

Epoch: 6| Step: 7
Training loss: 3.536329746246338
Validation loss: 4.011236634305728

Epoch: 6| Step: 8
Training loss: 3.763719081878662
Validation loss: 4.010346579295333

Epoch: 6| Step: 9
Training loss: 3.1598141193389893
Validation loss: 4.005213757996918

Epoch: 6| Step: 10
Training loss: 4.06748628616333
Validation loss: 4.003904888706822

Epoch: 6| Step: 11
Training loss: 4.072474479675293
Validation loss: 4.003162181505593

Epoch: 6| Step: 12
Training loss: 3.527599334716797
Validation loss: 3.9967925702371905

Epoch: 6| Step: 13
Training loss: 3.2181332111358643
Validation loss: 3.9937665385584675

Epoch: 5| Step: 0
Training loss: 3.1678271293640137
Validation loss: 3.991711134551674

Epoch: 6| Step: 1
Training loss: 3.5291099548339844
Validation loss: 3.987334633386263

Epoch: 6| Step: 2
Training loss: 4.074488162994385
Validation loss: 3.984811439309069

Epoch: 6| Step: 3
Training loss: 4.3304443359375
Validation loss: 3.979530167836015

Epoch: 6| Step: 4
Training loss: 4.96317195892334
Validation loss: 3.9779827261483796

Epoch: 6| Step: 5
Training loss: 4.670853614807129
Validation loss: 3.9751858070332515

Epoch: 6| Step: 6
Training loss: 3.5548582077026367
Validation loss: 3.970068859797652

Epoch: 6| Step: 7
Training loss: 3.9622435569763184
Validation loss: 3.969529777444819

Epoch: 6| Step: 8
Training loss: 3.976080894470215
Validation loss: 3.9619160570124143

Epoch: 6| Step: 9
Training loss: 3.8328006267547607
Validation loss: 3.9612686095699186

Epoch: 6| Step: 10
Training loss: 4.420921802520752
Validation loss: 3.9541506664727324

Epoch: 6| Step: 11
Training loss: 2.5229389667510986
Validation loss: 3.9512031155247844

Epoch: 6| Step: 12
Training loss: 3.3583617210388184
Validation loss: 3.9513253601648475

Epoch: 6| Step: 13
Training loss: 2.7235541343688965
Validation loss: 3.9465997629268195

Epoch: 6| Step: 0
Training loss: 4.063056468963623
Validation loss: 3.941244386857556

Epoch: 6| Step: 1
Training loss: 3.4858481884002686
Validation loss: 3.9393337875284176

Epoch: 6| Step: 2
Training loss: 5.177118301391602
Validation loss: 3.937312026177683

Epoch: 6| Step: 3
Training loss: 3.87536883354187
Validation loss: 3.9310157683587845

Epoch: 6| Step: 4
Training loss: 3.2514052391052246
Validation loss: 3.9268194270390335

Epoch: 6| Step: 5
Training loss: 4.832646369934082
Validation loss: 3.9258463536539385

Epoch: 6| Step: 6
Training loss: 2.274702548980713
Validation loss: 3.917285616679858

Epoch: 6| Step: 7
Training loss: 4.271145820617676
Validation loss: 3.9159022095382854

Epoch: 6| Step: 8
Training loss: 3.037492036819458
Validation loss: 3.909741552927161

Epoch: 6| Step: 9
Training loss: 3.6885530948638916
Validation loss: 3.9070183923167567

Epoch: 6| Step: 10
Training loss: 4.134987831115723
Validation loss: 3.903626931610928

Epoch: 6| Step: 11
Training loss: 3.3397209644317627
Validation loss: 3.901028187044205

Epoch: 6| Step: 12
Training loss: 4.306004524230957
Validation loss: 3.8956433701258835

Epoch: 6| Step: 13
Training loss: 2.7457313537597656
Validation loss: 3.8935870073174916

Epoch: 7| Step: 0
Training loss: 4.218698024749756
Validation loss: 3.888103603034891

Epoch: 6| Step: 1
Training loss: 3.995431423187256
Validation loss: 3.8823402876495035

Epoch: 6| Step: 2
Training loss: 4.113126754760742
Validation loss: 3.8780489147350354

Epoch: 6| Step: 3
Training loss: 3.595277786254883
Validation loss: 3.8753968592612975

Epoch: 6| Step: 4
Training loss: 3.977527618408203
Validation loss: 3.8702990624212448

Epoch: 6| Step: 5
Training loss: 4.110073566436768
Validation loss: 3.8669999312329035

Epoch: 6| Step: 6
Training loss: 3.126819610595703
Validation loss: 3.861034313837687

Epoch: 6| Step: 7
Training loss: 2.9411230087280273
Validation loss: 3.8592828730101227

Epoch: 6| Step: 8
Training loss: 4.607369422912598
Validation loss: 3.8491284821623113

Epoch: 6| Step: 9
Training loss: 4.503081798553467
Validation loss: 3.8467602370887675

Epoch: 6| Step: 10
Training loss: 3.845576524734497
Validation loss: 3.8455605763261036

Epoch: 6| Step: 11
Training loss: 3.257268190383911
Validation loss: 3.838189640352803

Epoch: 6| Step: 12
Training loss: 2.1297554969787598
Validation loss: 3.83308236316968

Epoch: 6| Step: 13
Training loss: 3.970881223678589
Validation loss: 3.8249688584317445

Epoch: 8| Step: 0
Training loss: 2.1337532997131348
Validation loss: 3.825368219806302

Epoch: 6| Step: 1
Training loss: 5.500524997711182
Validation loss: 3.818702772099485

Epoch: 6| Step: 2
Training loss: 2.556429147720337
Validation loss: 3.8141951253337245

Epoch: 6| Step: 3
Training loss: 3.8495283126831055
Validation loss: 3.8092570151052167

Epoch: 6| Step: 4
Training loss: 4.911923885345459
Validation loss: 3.805082239130492

Epoch: 6| Step: 5
Training loss: 3.640407085418701
Validation loss: 3.8001678553960656

Epoch: 6| Step: 6
Training loss: 3.6617281436920166
Validation loss: 3.7954553839980916

Epoch: 6| Step: 7
Training loss: 3.659384250640869
Validation loss: 3.794446083807176

Epoch: 6| Step: 8
Training loss: 3.6722326278686523
Validation loss: 3.785879801678401

Epoch: 6| Step: 9
Training loss: 3.5785255432128906
Validation loss: 3.7803348290022982

Epoch: 6| Step: 10
Training loss: 3.1625163555145264
Validation loss: 3.7792763556203535

Epoch: 6| Step: 11
Training loss: 4.196996212005615
Validation loss: 3.772751336456627

Epoch: 6| Step: 12
Training loss: 3.916412115097046
Validation loss: 3.764085264616115

Epoch: 6| Step: 13
Training loss: 2.544940710067749
Validation loss: 3.756096386140393

Epoch: 9| Step: 0
Training loss: 2.45658802986145
Validation loss: 3.75693452999156

Epoch: 6| Step: 1
Training loss: 3.4634618759155273
Validation loss: 3.747420152028402

Epoch: 6| Step: 2
Training loss: 3.5445351600646973
Validation loss: 3.7409262759711153

Epoch: 6| Step: 3
Training loss: 3.480532169342041
Validation loss: 3.7366305141038794

Epoch: 6| Step: 4
Training loss: 3.0390446186065674
Validation loss: 3.7308639480221655

Epoch: 6| Step: 5
Training loss: 3.6026813983917236
Validation loss: 3.7293530664136334

Epoch: 6| Step: 6
Training loss: 3.7623767852783203
Validation loss: 3.721214022687686

Epoch: 6| Step: 7
Training loss: 4.650887489318848
Validation loss: 3.717624669433922

Epoch: 6| Step: 8
Training loss: 4.2641682624816895
Validation loss: 3.7033561404033373

Epoch: 6| Step: 9
Training loss: 2.890197277069092
Validation loss: 3.702649665135209

Epoch: 6| Step: 10
Training loss: 2.9412107467651367
Validation loss: 3.701088474642846

Epoch: 6| Step: 11
Training loss: 4.428821563720703
Validation loss: 3.688473770695348

Epoch: 6| Step: 12
Training loss: 4.328168869018555
Validation loss: 3.6842621141864407

Epoch: 6| Step: 13
Training loss: 3.79091215133667
Validation loss: 3.6758070658611994

Epoch: 10| Step: 0
Training loss: 2.890655517578125
Validation loss: 3.674779527930803

Epoch: 6| Step: 1
Training loss: 5.3121161460876465
Validation loss: 3.668301351608769

Epoch: 6| Step: 2
Training loss: 3.4284000396728516
Validation loss: 3.6587442377562165

Epoch: 6| Step: 3
Training loss: 2.932948350906372
Validation loss: 3.6513403102915776

Epoch: 6| Step: 4
Training loss: 3.277608871459961
Validation loss: 3.6467714514783633

Epoch: 6| Step: 5
Training loss: 1.8555166721343994
Validation loss: 3.6397657778955277

Epoch: 6| Step: 6
Training loss: 2.1962804794311523
Validation loss: 3.6329608296835296

Epoch: 6| Step: 7
Training loss: 3.996277093887329
Validation loss: 3.6262118072919947

Epoch: 6| Step: 8
Training loss: 3.7985434532165527
Validation loss: 3.619130560146865

Epoch: 6| Step: 9
Training loss: 4.572216033935547
Validation loss: 3.6125939635820288

Epoch: 6| Step: 10
Training loss: 3.4254050254821777
Validation loss: 3.6052346203916814

Epoch: 6| Step: 11
Training loss: 2.8264341354370117
Validation loss: 3.602392127436976

Epoch: 6| Step: 12
Training loss: 4.475371360778809
Validation loss: 3.5929141839345298

Epoch: 6| Step: 13
Training loss: 5.094749927520752
Validation loss: 3.5832006008394304

Epoch: 11| Step: 0
Training loss: 2.661989450454712
Validation loss: 3.5664380519620833

Epoch: 6| Step: 1
Training loss: 2.788689613342285
Validation loss: 3.56254066446776

Epoch: 6| Step: 2
Training loss: 4.2420430183410645
Validation loss: 3.555375550382881

Epoch: 6| Step: 3
Training loss: 2.609191417694092
Validation loss: 3.548436128964988

Epoch: 6| Step: 4
Training loss: 4.281493663787842
Validation loss: 3.5404573999425417

Epoch: 6| Step: 5
Training loss: 3.073972463607788
Validation loss: 3.53350910832805

Epoch: 6| Step: 6
Training loss: 4.302424430847168
Validation loss: 3.518036534709315

Epoch: 6| Step: 7
Training loss: 3.564054012298584
Validation loss: 3.5179137696502027

Epoch: 6| Step: 8
Training loss: 3.9465324878692627
Validation loss: 3.506130054432859

Epoch: 6| Step: 9
Training loss: 3.226672649383545
Validation loss: 3.4969922829699773

Epoch: 6| Step: 10
Training loss: 3.41788911819458
Validation loss: 3.4818013227114113

Epoch: 6| Step: 11
Training loss: 3.07558012008667
Validation loss: 3.470083446912868

Epoch: 6| Step: 12
Training loss: 3.315950632095337
Validation loss: 3.467610087445987

Epoch: 6| Step: 13
Training loss: 3.64508318901062
Validation loss: 3.4505667173734276

Epoch: 12| Step: 0
Training loss: 3.655489206314087
Validation loss: 3.4395232123713337

Epoch: 6| Step: 1
Training loss: 3.885202169418335
Validation loss: 3.4254716724477787

Epoch: 6| Step: 2
Training loss: 4.3364362716674805
Validation loss: 3.4199127202392905

Epoch: 6| Step: 3
Training loss: 4.836472034454346
Validation loss: 3.403623604005383

Epoch: 6| Step: 4
Training loss: 2.931088447570801
Validation loss: 3.39527884093664

Epoch: 6| Step: 5
Training loss: 2.5434203147888184
Validation loss: 3.3818223296955066

Epoch: 6| Step: 6
Training loss: 3.2790842056274414
Validation loss: 3.361057286621422

Epoch: 6| Step: 7
Training loss: 2.926382064819336
Validation loss: 3.3518750308662333

Epoch: 6| Step: 8
Training loss: 2.893887519836426
Validation loss: 3.3431142068678334

Epoch: 6| Step: 9
Training loss: 3.3234164714813232
Validation loss: 3.336162151828889

Epoch: 6| Step: 10
Training loss: 2.7506046295166016
Validation loss: 3.3158129927932576

Epoch: 6| Step: 11
Training loss: 2.5233118534088135
Validation loss: 3.3057506110078547

Epoch: 6| Step: 12
Training loss: 3.461076259613037
Validation loss: 3.295804387779646

Epoch: 6| Step: 13
Training loss: 2.8062658309936523
Validation loss: 3.284767940480222

Epoch: 13| Step: 0
Training loss: 3.1501636505126953
Validation loss: 3.269166874629195

Epoch: 6| Step: 1
Training loss: 3.6182374954223633
Validation loss: 3.25900633617114

Epoch: 6| Step: 2
Training loss: 2.7149550914764404
Validation loss: 3.2406906363784627

Epoch: 6| Step: 3
Training loss: 2.8841538429260254
Validation loss: 3.2326933696705806

Epoch: 6| Step: 4
Training loss: 3.2491350173950195
Validation loss: 3.2123390961718816

Epoch: 6| Step: 5
Training loss: 2.8689842224121094
Validation loss: 3.199951797403315

Epoch: 6| Step: 6
Training loss: 2.615385055541992
Validation loss: 3.1960158091719433

Epoch: 6| Step: 7
Training loss: 2.6200857162475586
Validation loss: 3.172167621633058

Epoch: 6| Step: 8
Training loss: 3.3492870330810547
Validation loss: 3.17462743225918

Epoch: 6| Step: 9
Training loss: 3.951995849609375
Validation loss: 3.1486052620795464

Epoch: 6| Step: 10
Training loss: 4.845748424530029
Validation loss: 3.1370025629638345

Epoch: 6| Step: 11
Training loss: 2.7856264114379883
Validation loss: 3.1247993874293503

Epoch: 6| Step: 12
Training loss: 2.7027063369750977
Validation loss: 3.099246771104874

Epoch: 6| Step: 13
Training loss: 2.670755624771118
Validation loss: 3.1025886228007655

Epoch: 14| Step: 0
Training loss: 2.535219669342041
Validation loss: 3.0864781179735736

Epoch: 6| Step: 1
Training loss: 3.9443578720092773
Validation loss: 3.0703719713354625

Epoch: 6| Step: 2
Training loss: 3.4691269397735596
Validation loss: 3.059318652717016

Epoch: 6| Step: 3
Training loss: 2.9184775352478027
Validation loss: 3.035782601243706

Epoch: 6| Step: 4
Training loss: 3.3085663318634033
Validation loss: 3.0216894559962775

Epoch: 6| Step: 5
Training loss: 3.5692801475524902
Validation loss: 3.0076137204324045

Epoch: 6| Step: 6
Training loss: 2.751847505569458
Validation loss: 3.0088669869207565

Epoch: 6| Step: 7
Training loss: 1.9369878768920898
Validation loss: 2.9787017658192623

Epoch: 6| Step: 8
Training loss: 3.3756933212280273
Validation loss: 2.9584590517064577

Epoch: 6| Step: 9
Training loss: 2.8030128479003906
Validation loss: 2.950850304736886

Epoch: 6| Step: 10
Training loss: 2.2484428882598877
Validation loss: 2.937726797596101

Epoch: 6| Step: 11
Training loss: 3.458015203475952
Validation loss: 2.929348689253612

Epoch: 6| Step: 12
Training loss: 3.0043423175811768
Validation loss: 2.9113870436145413

Epoch: 6| Step: 13
Training loss: 3.0900392532348633
Validation loss: 2.904167654693768

Epoch: 15| Step: 0
Training loss: 1.9487377405166626
Validation loss: 2.889250527146042

Epoch: 6| Step: 1
Training loss: 2.9628381729125977
Validation loss: 2.8701290827925487

Epoch: 6| Step: 2
Training loss: 2.7201526165008545
Validation loss: 2.86509431305752

Epoch: 6| Step: 3
Training loss: 1.8798998594284058
Validation loss: 2.85820516719613

Epoch: 6| Step: 4
Training loss: 3.3576090335845947
Validation loss: 2.8472216488212667

Epoch: 6| Step: 5
Training loss: 2.252023935317993
Validation loss: 2.8383000948095836

Epoch: 6| Step: 6
Training loss: 3.7113864421844482
Validation loss: 2.8272588919567805

Epoch: 6| Step: 7
Training loss: 3.3470993041992188
Validation loss: 2.8203113130343858

Epoch: 6| Step: 8
Training loss: 2.8921566009521484
Validation loss: 2.7968175616315616

Epoch: 6| Step: 9
Training loss: 3.8057825565338135
Validation loss: 2.79275700353807

Epoch: 6| Step: 10
Training loss: 3.2247307300567627
Validation loss: 2.766438197064143

Epoch: 6| Step: 11
Training loss: 2.2036988735198975
Validation loss: 2.764759081666188

Epoch: 6| Step: 12
Training loss: 2.9584569931030273
Validation loss: 2.7316400312608287

Epoch: 6| Step: 13
Training loss: 3.115178108215332
Validation loss: 2.719240962818105

Epoch: 16| Step: 0
Training loss: 2.600085496902466
Validation loss: 2.688608902756886

Epoch: 6| Step: 1
Training loss: 3.3480417728424072
Validation loss: 2.676937592926846

Epoch: 6| Step: 2
Training loss: 3.1879379749298096
Validation loss: 2.659599606708814

Epoch: 6| Step: 3
Training loss: 2.941039562225342
Validation loss: 2.6326874097188315

Epoch: 6| Step: 4
Training loss: 2.3830959796905518
Validation loss: 2.617311539188508

Epoch: 6| Step: 5
Training loss: 2.944124698638916
Validation loss: 2.6239214353663947

Epoch: 6| Step: 6
Training loss: 2.3280067443847656
Validation loss: 2.588210198187059

Epoch: 6| Step: 7
Training loss: 2.3304316997528076
Validation loss: 2.5800258780038483

Epoch: 6| Step: 8
Training loss: 3.6534457206726074
Validation loss: 2.5642526739387104

Epoch: 6| Step: 9
Training loss: 1.7850817441940308
Validation loss: 2.5275254480300413

Epoch: 6| Step: 10
Training loss: 3.0621871948242188
Validation loss: 2.532305214994697

Epoch: 6| Step: 11
Training loss: 2.4305496215820312
Validation loss: 2.50613502020477

Epoch: 6| Step: 12
Training loss: 2.652395248413086
Validation loss: 2.474422782979986

Epoch: 6| Step: 13
Training loss: 2.4067366123199463
Validation loss: 2.4695113884505404

Epoch: 17| Step: 0
Training loss: 2.565392017364502
Validation loss: 2.4585623638604277

Epoch: 6| Step: 1
Training loss: 3.0787482261657715
Validation loss: 2.447792778732956

Epoch: 6| Step: 2
Training loss: 2.4786181449890137
Validation loss: 2.41377850245404

Epoch: 6| Step: 3
Training loss: 3.2155261039733887
Validation loss: 2.4286067037172216

Epoch: 6| Step: 4
Training loss: 2.8362362384796143
Validation loss: 2.4042665291857976

Epoch: 6| Step: 5
Training loss: 3.0205063819885254
Validation loss: 2.3785570206180697

Epoch: 6| Step: 6
Training loss: 2.477522373199463
Validation loss: 2.368051411003195

Epoch: 6| Step: 7
Training loss: 2.687638759613037
Validation loss: 2.3511092201355965

Epoch: 6| Step: 8
Training loss: 2.303597927093506
Validation loss: 2.334617281472811

Epoch: 6| Step: 9
Training loss: 2.8926010131835938
Validation loss: 2.319805522118845

Epoch: 6| Step: 10
Training loss: 2.10551118850708
Validation loss: 2.2907514533688946

Epoch: 6| Step: 11
Training loss: 2.1062166690826416
Validation loss: 2.3015143307306434

Epoch: 6| Step: 12
Training loss: 2.4344308376312256
Validation loss: 2.2884079051274124

Epoch: 6| Step: 13
Training loss: 1.7765055894851685
Validation loss: 2.275503226505813

Epoch: 18| Step: 0
Training loss: 2.566638469696045
Validation loss: 2.2630975656611945

Epoch: 6| Step: 1
Training loss: 2.3183705806732178
Validation loss: 2.2387786629379436

Epoch: 6| Step: 2
Training loss: 2.6818761825561523
Validation loss: 2.2190307314677904

Epoch: 6| Step: 3
Training loss: 2.602719306945801
Validation loss: 2.193783078142392

Epoch: 6| Step: 4
Training loss: 2.225876808166504
Validation loss: 2.2077036749932075

Epoch: 6| Step: 5
Training loss: 2.613323211669922
Validation loss: 2.207568500631599

Epoch: 6| Step: 6
Training loss: 2.218493938446045
Validation loss: 2.1879140446262975

Epoch: 6| Step: 7
Training loss: 2.4669506549835205
Validation loss: 2.1849461678535707

Epoch: 6| Step: 8
Training loss: 2.4576830863952637
Validation loss: 2.155985745050574

Epoch: 6| Step: 9
Training loss: 2.756335735321045
Validation loss: 2.1643330307417017

Epoch: 6| Step: 10
Training loss: 2.375840902328491
Validation loss: 2.1370760407499088

Epoch: 6| Step: 11
Training loss: 2.4452130794525146
Validation loss: 2.149286318850774

Epoch: 6| Step: 12
Training loss: 2.559225559234619
Validation loss: 2.1521939462231052

Epoch: 6| Step: 13
Training loss: 2.2688512802124023
Validation loss: 2.140163831813361

Epoch: 19| Step: 0
Training loss: 2.13120698928833
Validation loss: 2.136420924176452

Epoch: 6| Step: 1
Training loss: 2.5317277908325195
Validation loss: 2.1183384490269486

Epoch: 6| Step: 2
Training loss: 2.4584426879882812
Validation loss: 2.120075741121846

Epoch: 6| Step: 3
Training loss: 2.7490596771240234
Validation loss: 2.091146376825148

Epoch: 6| Step: 4
Training loss: 1.6819548606872559
Validation loss: 2.1000512069271458

Epoch: 6| Step: 5
Training loss: 1.8518474102020264
Validation loss: 2.0651094631482194

Epoch: 6| Step: 6
Training loss: 2.9461936950683594
Validation loss: 2.0824161242413264

Epoch: 6| Step: 7
Training loss: 2.428605079650879
Validation loss: 2.0917522394528953

Epoch: 6| Step: 8
Training loss: 2.478257656097412
Validation loss: 2.0512853232763146

Epoch: 6| Step: 9
Training loss: 2.0728156566619873
Validation loss: 2.0781456398707565

Epoch: 6| Step: 10
Training loss: 2.917130708694458
Validation loss: 2.077121159081818

Epoch: 6| Step: 11
Training loss: 3.159951686859131
Validation loss: 2.052401943873334

Epoch: 6| Step: 12
Training loss: 2.1435515880584717
Validation loss: 2.0632754038738947

Epoch: 6| Step: 13
Training loss: 2.1153154373168945
Validation loss: 2.0629519967622656

Epoch: 20| Step: 0
Training loss: 2.5244498252868652
Validation loss: 2.052159108141417

Epoch: 6| Step: 1
Training loss: 2.0551209449768066
Validation loss: 2.0679403812654558

Epoch: 6| Step: 2
Training loss: 2.6954715251922607
Validation loss: 2.056354494505031

Epoch: 6| Step: 3
Training loss: 2.417245864868164
Validation loss: 2.020839318152397

Epoch: 6| Step: 4
Training loss: 2.625713348388672
Validation loss: 2.05224359163674

Epoch: 6| Step: 5
Training loss: 2.3678040504455566
Validation loss: 2.0600534844142135

Epoch: 6| Step: 6
Training loss: 1.6379508972167969
Validation loss: 2.052789609919312

Epoch: 6| Step: 7
Training loss: 2.5854272842407227
Validation loss: 2.033886933839449

Epoch: 6| Step: 8
Training loss: 2.959777355194092
Validation loss: 2.033981957743245

Epoch: 6| Step: 9
Training loss: 2.2278873920440674
Validation loss: 2.0558643623064925

Epoch: 6| Step: 10
Training loss: 2.710378408432007
Validation loss: 2.0556409435887493

Epoch: 6| Step: 11
Training loss: 2.6211061477661133
Validation loss: 2.0369904477109193

Epoch: 6| Step: 12
Training loss: 2.0768909454345703
Validation loss: 2.038781701877553

Epoch: 6| Step: 13
Training loss: 2.003941774368286
Validation loss: 2.0229165015682096

Epoch: 21| Step: 0
Training loss: 1.8085269927978516
Validation loss: 2.0275206860675605

Epoch: 6| Step: 1
Training loss: 2.2811152935028076
Validation loss: 2.050053402941714

Epoch: 6| Step: 2
Training loss: 3.1998257637023926
Validation loss: 2.0248812321693666

Epoch: 6| Step: 3
Training loss: 2.238931179046631
Validation loss: 2.022714379013226

Epoch: 6| Step: 4
Training loss: 2.0660338401794434
Validation loss: 2.0214995902071715

Epoch: 6| Step: 5
Training loss: 2.4757587909698486
Validation loss: 2.0476324058348134

Epoch: 6| Step: 6
Training loss: 2.148499011993408
Validation loss: 2.0095692501273206

Epoch: 6| Step: 7
Training loss: 2.3492321968078613
Validation loss: 2.0345635055213847

Epoch: 6| Step: 8
Training loss: 2.61641001701355
Validation loss: 2.0384141706651255

Epoch: 6| Step: 9
Training loss: 3.111787796020508
Validation loss: 2.010063878951534

Epoch: 6| Step: 10
Training loss: 2.4481279850006104
Validation loss: 2.0288501670283656

Epoch: 6| Step: 11
Training loss: 2.436274528503418
Validation loss: 2.0033298794941237

Epoch: 6| Step: 12
Training loss: 2.646848201751709
Validation loss: 2.0033732947482856

Epoch: 6| Step: 13
Training loss: 1.3847556114196777
Validation loss: 2.021578524702339

Epoch: 22| Step: 0
Training loss: 2.20957088470459
Validation loss: 2.058779901073825

Epoch: 6| Step: 1
Training loss: 2.7515931129455566
Validation loss: 2.036799866666076

Epoch: 6| Step: 2
Training loss: 1.7578604221343994
Validation loss: 2.0009519361680552

Epoch: 6| Step: 3
Training loss: 3.010112762451172
Validation loss: 2.023441635152345

Epoch: 6| Step: 4
Training loss: 2.2894086837768555
Validation loss: 2.038978071622951

Epoch: 6| Step: 5
Training loss: 2.412642478942871
Validation loss: 2.0148435177341586

Epoch: 6| Step: 6
Training loss: 1.5219038724899292
Validation loss: 2.013006551291353

Epoch: 6| Step: 7
Training loss: 2.5521655082702637
Validation loss: 2.0129845667910833

Epoch: 6| Step: 8
Training loss: 2.4468822479248047
Validation loss: 2.0392189102788127

Epoch: 6| Step: 9
Training loss: 2.688744068145752
Validation loss: 2.0226760269493185

Epoch: 6| Step: 10
Training loss: 2.6431353092193604
Validation loss: 1.985334006688928

Epoch: 6| Step: 11
Training loss: 1.9717929363250732
Validation loss: 2.0063651659155406

Epoch: 6| Step: 12
Training loss: 2.756533622741699
Validation loss: 2.0044835972529587

Epoch: 6| Step: 13
Training loss: 2.3145642280578613
Validation loss: 2.025033184277114

Epoch: 23| Step: 0
Training loss: 1.9628410339355469
Validation loss: 2.0179878101553967

Epoch: 6| Step: 1
Training loss: 1.7674204111099243
Validation loss: 2.001584747786163

Epoch: 6| Step: 2
Training loss: 3.1265995502471924
Validation loss: 2.0096585301942724

Epoch: 6| Step: 3
Training loss: 2.3941328525543213
Validation loss: 2.0034961469711794

Epoch: 6| Step: 4
Training loss: 2.577302932739258
Validation loss: 2.026356235627205

Epoch: 6| Step: 5
Training loss: 3.09682035446167
Validation loss: 2.011856722575362

Epoch: 6| Step: 6
Training loss: 2.105112314224243
Validation loss: 2.0088301230502386

Epoch: 6| Step: 7
Training loss: 2.5070748329162598
Validation loss: 2.0045729875564575

Epoch: 6| Step: 8
Training loss: 1.8636442422866821
Validation loss: 1.985075419948947

Epoch: 6| Step: 9
Training loss: 2.8152456283569336
Validation loss: 1.9936993711738176

Epoch: 6| Step: 10
Training loss: 2.595906972885132
Validation loss: 2.0150047066391155

Epoch: 6| Step: 11
Training loss: 2.110825538635254
Validation loss: 2.0034359629436205

Epoch: 6| Step: 12
Training loss: 2.243525505065918
Validation loss: 2.01906225245486

Epoch: 6| Step: 13
Training loss: 2.0583086013793945
Validation loss: 2.0196191213464223

Epoch: 24| Step: 0
Training loss: 2.858218193054199
Validation loss: 2.037648916244507

Epoch: 6| Step: 1
Training loss: 3.0877366065979004
Validation loss: 2.0260321171052995

Epoch: 6| Step: 2
Training loss: 1.6968834400177002
Validation loss: 2.0157002172162457

Epoch: 6| Step: 3
Training loss: 2.2651724815368652
Validation loss: 2.0020430587953135

Epoch: 6| Step: 4
Training loss: 2.520550489425659
Validation loss: 2.020231487930462

Epoch: 6| Step: 5
Training loss: 2.3458034992218018
Validation loss: 2.0050583424106723

Epoch: 6| Step: 6
Training loss: 2.0560028553009033
Validation loss: 1.9975837456282748

Epoch: 6| Step: 7
Training loss: 2.5366177558898926
Validation loss: 1.9977946524978967

Epoch: 6| Step: 8
Training loss: 2.4065537452697754
Validation loss: 2.0245408345294256

Epoch: 6| Step: 9
Training loss: 2.3018546104431152
Validation loss: 1.9882053739281111

Epoch: 6| Step: 10
Training loss: 2.041841506958008
Validation loss: 2.0141078848992624

Epoch: 6| Step: 11
Training loss: 2.5937561988830566
Validation loss: 1.9988962655426354

Epoch: 6| Step: 12
Training loss: 2.238755226135254
Validation loss: 2.040143373191998

Epoch: 6| Step: 13
Training loss: 2.5117268562316895
Validation loss: 2.0065334894323863

Epoch: 25| Step: 0
Training loss: 2.149803876876831
Validation loss: 2.0165801919916624

Epoch: 6| Step: 1
Training loss: 2.5216875076293945
Validation loss: 2.0180970879011255

Epoch: 6| Step: 2
Training loss: 2.7118582725524902
Validation loss: 2.0089587165463354

Epoch: 6| Step: 3
Training loss: 2.619269847869873
Validation loss: 1.9993170089619134

Epoch: 6| Step: 4
Training loss: 2.3143060207366943
Validation loss: 2.0303268740254063

Epoch: 6| Step: 5
Training loss: 1.9628009796142578
Validation loss: 1.9822291135787964

Epoch: 6| Step: 6
Training loss: 2.5739123821258545
Validation loss: 2.0032093858206146

Epoch: 6| Step: 7
Training loss: 2.5973477363586426
Validation loss: 1.9867563222044258

Epoch: 6| Step: 8
Training loss: 3.040947437286377
Validation loss: 1.9880531834017845

Epoch: 6| Step: 9
Training loss: 1.871636152267456
Validation loss: 1.9673750759452902

Epoch: 6| Step: 10
Training loss: 2.564220905303955
Validation loss: 1.9729241863373788

Epoch: 6| Step: 11
Training loss: 2.348395586013794
Validation loss: 2.010691403060831

Epoch: 6| Step: 12
Training loss: 1.4609241485595703
Validation loss: 1.9997989362285984

Epoch: 6| Step: 13
Training loss: 2.7532262802124023
Validation loss: 1.984035389397734

Epoch: 26| Step: 0
Training loss: 2.7085769176483154
Validation loss: 2.028887694881808

Epoch: 6| Step: 1
Training loss: 1.9545942544937134
Validation loss: 2.004045396722773

Epoch: 6| Step: 2
Training loss: 2.0162100791931152
Validation loss: 2.010681289498524

Epoch: 6| Step: 3
Training loss: 2.746412754058838
Validation loss: 1.9997239317945255

Epoch: 6| Step: 4
Training loss: 1.8909051418304443
Validation loss: 1.9965123168883785

Epoch: 6| Step: 5
Training loss: 2.124563217163086
Validation loss: 2.006067998947636

Epoch: 6| Step: 6
Training loss: 2.301663875579834
Validation loss: 1.9882643286899855

Epoch: 6| Step: 7
Training loss: 2.0169625282287598
Validation loss: 2.004099072948579

Epoch: 6| Step: 8
Training loss: 3.2935426235198975
Validation loss: 2.046665217286797

Epoch: 6| Step: 9
Training loss: 2.52250599861145
Validation loss: 1.989087935416929

Epoch: 6| Step: 10
Training loss: 1.9975138902664185
Validation loss: 2.030613958194692

Epoch: 6| Step: 11
Training loss: 2.658817768096924
Validation loss: 2.0110303689074773

Epoch: 6| Step: 12
Training loss: 2.87361216545105
Validation loss: 2.0132217778954455

Epoch: 6| Step: 13
Training loss: 2.41514253616333
Validation loss: 2.0039657956810406

Epoch: 27| Step: 0
Training loss: 2.898454189300537
Validation loss: 2.0200200209053616

Epoch: 6| Step: 1
Training loss: 2.30656099319458
Validation loss: 2.015011556686894

Epoch: 6| Step: 2
Training loss: 2.5057826042175293
Validation loss: 2.025144282207694

Epoch: 6| Step: 3
Training loss: 2.7177681922912598
Validation loss: 2.0119996634862756

Epoch: 6| Step: 4
Training loss: 2.187467098236084
Validation loss: 2.016975674577939

Epoch: 6| Step: 5
Training loss: 2.875309705734253
Validation loss: 2.027241263338315

Epoch: 6| Step: 6
Training loss: 2.424539804458618
Validation loss: 2.0113239147329844

Epoch: 6| Step: 7
Training loss: 2.206702947616577
Validation loss: 2.0242513302833802

Epoch: 6| Step: 8
Training loss: 2.4780890941619873
Validation loss: 2.006449713501879

Epoch: 6| Step: 9
Training loss: 1.582517385482788
Validation loss: 2.02549042752994

Epoch: 6| Step: 10
Training loss: 2.0666418075561523
Validation loss: 2.0043154455000356

Epoch: 6| Step: 11
Training loss: 1.9935269355773926
Validation loss: 1.9836228662921536

Epoch: 6| Step: 12
Training loss: 2.673693895339966
Validation loss: 2.014909072588849

Epoch: 6| Step: 13
Training loss: 2.5658934116363525
Validation loss: 2.029168398149552

Epoch: 28| Step: 0
Training loss: 2.8628740310668945
Validation loss: 1.9981904260573848

Epoch: 6| Step: 1
Training loss: 2.010615110397339
Validation loss: 2.025605170957504

Epoch: 6| Step: 2
Training loss: 2.396660089492798
Validation loss: 1.9790982853981756

Epoch: 6| Step: 3
Training loss: 2.9132614135742188
Validation loss: 1.9952515120147376

Epoch: 6| Step: 4
Training loss: 2.8695085048675537
Validation loss: 2.0441043300013386

Epoch: 6| Step: 5
Training loss: 1.8034493923187256
Validation loss: 2.015415576196486

Epoch: 6| Step: 6
Training loss: 2.6661996841430664
Validation loss: 2.018376455512098

Epoch: 6| Step: 7
Training loss: 2.922806739807129
Validation loss: 2.0218331531811784

Epoch: 6| Step: 8
Training loss: 2.3216612339019775
Validation loss: 2.0021551757730465

Epoch: 6| Step: 9
Training loss: 1.9363925457000732
Validation loss: 2.03357030243002

Epoch: 6| Step: 10
Training loss: 2.3644700050354004
Validation loss: 2.0143319022270942

Epoch: 6| Step: 11
Training loss: 1.682584285736084
Validation loss: 2.017060043991253

Epoch: 6| Step: 12
Training loss: 2.039046287536621
Validation loss: 2.003376454435369

Epoch: 6| Step: 13
Training loss: 2.564882755279541
Validation loss: 1.987331808254283

Epoch: 29| Step: 0
Training loss: 1.6957945823669434
Validation loss: 2.019524597352551

Epoch: 6| Step: 1
Training loss: 1.8360838890075684
Validation loss: 2.0070493349464993

Epoch: 6| Step: 2
Training loss: 2.5158045291900635
Validation loss: 2.0453202750093196

Epoch: 6| Step: 3
Training loss: 2.776470184326172
Validation loss: 1.9934689793535458

Epoch: 6| Step: 4
Training loss: 3.141608238220215
Validation loss: 2.0048241781932052

Epoch: 6| Step: 5
Training loss: 2.764430046081543
Validation loss: 2.0070296718228247

Epoch: 6| Step: 6
Training loss: 2.3722798824310303
Validation loss: 2.0187247568561184

Epoch: 6| Step: 7
Training loss: 2.774010419845581
Validation loss: 2.010102318179223

Epoch: 6| Step: 8
Training loss: 2.1692652702331543
Validation loss: 2.0126862167030253

Epoch: 6| Step: 9
Training loss: 2.2031259536743164
Validation loss: 2.0253923413574055

Epoch: 6| Step: 10
Training loss: 1.695530652999878
Validation loss: 2.020370892299119

Epoch: 6| Step: 11
Training loss: 2.78035831451416
Validation loss: 1.9923505539535193

Epoch: 6| Step: 12
Training loss: 2.328707218170166
Validation loss: 2.0029648298858316

Epoch: 6| Step: 13
Training loss: 2.1715450286865234
Validation loss: 2.0060370711870092

Epoch: 30| Step: 0
Training loss: 3.094294309616089
Validation loss: 1.9927674493482035

Epoch: 6| Step: 1
Training loss: 2.5148043632507324
Validation loss: 2.0002646753864903

Epoch: 6| Step: 2
Training loss: 2.384185314178467
Validation loss: 1.9889060451138405

Epoch: 6| Step: 3
Training loss: 2.0930562019348145
Validation loss: 1.994697379809554

Epoch: 6| Step: 4
Training loss: 1.6090402603149414
Validation loss: 2.0235949844442387

Epoch: 6| Step: 5
Training loss: 2.076658010482788
Validation loss: 2.0366876253517727

Epoch: 6| Step: 6
Training loss: 2.6011905670166016
Validation loss: 2.012357122154646

Epoch: 6| Step: 7
Training loss: 1.8838205337524414
Validation loss: 2.014051492496203

Epoch: 6| Step: 8
Training loss: 2.3307371139526367
Validation loss: 2.030222861997543

Epoch: 6| Step: 9
Training loss: 2.1644201278686523
Validation loss: 1.9943606238211355

Epoch: 6| Step: 10
Training loss: 2.481290340423584
Validation loss: 1.9702531573592976

Epoch: 6| Step: 11
Training loss: 2.668168544769287
Validation loss: 2.029272731914315

Epoch: 6| Step: 12
Training loss: 2.7042453289031982
Validation loss: 2.025908890590873

Epoch: 6| Step: 13
Training loss: 2.5512750148773193
Validation loss: 2.0218487836981334

Epoch: 31| Step: 0
Training loss: 2.367018222808838
Validation loss: 2.0312255531229

Epoch: 6| Step: 1
Training loss: 2.7667055130004883
Validation loss: 2.007500917680802

Epoch: 6| Step: 2
Training loss: 2.180095672607422
Validation loss: 2.014050313221511

Epoch: 6| Step: 3
Training loss: 2.092334270477295
Validation loss: 2.0503362122402398

Epoch: 6| Step: 4
Training loss: 2.073828935623169
Validation loss: 2.004423605498447

Epoch: 6| Step: 5
Training loss: 1.9110325574874878
Validation loss: 2.009656495945428

Epoch: 6| Step: 6
Training loss: 2.0689151287078857
Validation loss: 2.011716123550169

Epoch: 6| Step: 7
Training loss: 2.6751201152801514
Validation loss: 2.0257432742785384

Epoch: 6| Step: 8
Training loss: 1.8376178741455078
Validation loss: 2.008104439704649

Epoch: 6| Step: 9
Training loss: 2.9060871601104736
Validation loss: 2.0301337601036153

Epoch: 6| Step: 10
Training loss: 2.5344223976135254
Validation loss: 2.0105065735437537

Epoch: 6| Step: 11
Training loss: 2.8983659744262695
Validation loss: 2.047070259689003

Epoch: 6| Step: 12
Training loss: 2.3761086463928223
Validation loss: 2.0267640672704226

Epoch: 6| Step: 13
Training loss: 2.130427122116089
Validation loss: 2.0303366248325636

Epoch: 32| Step: 0
Training loss: 1.9692015647888184
Validation loss: 2.033540086079669

Epoch: 6| Step: 1
Training loss: 2.330993890762329
Validation loss: 2.0413465871605823

Epoch: 6| Step: 2
Training loss: 2.4114890098571777
Validation loss: 1.9999871625695178

Epoch: 6| Step: 3
Training loss: 2.2673346996307373
Validation loss: 2.0124955561853226

Epoch: 6| Step: 4
Training loss: 2.2238101959228516
Validation loss: 2.0287170576792892

Epoch: 6| Step: 5
Training loss: 2.3919358253479004
Validation loss: 2.0081823282344367

Epoch: 6| Step: 6
Training loss: 2.9647574424743652
Validation loss: 2.031108599837108

Epoch: 6| Step: 7
Training loss: 2.680978298187256
Validation loss: 2.0005734607737553

Epoch: 6| Step: 8
Training loss: 2.288466215133667
Validation loss: 2.0240545606100433

Epoch: 6| Step: 9
Training loss: 2.9046642780303955
Validation loss: 2.012625318701549

Epoch: 6| Step: 10
Training loss: 1.9267723560333252
Validation loss: 2.005686062638478

Epoch: 6| Step: 11
Training loss: 1.6648503541946411
Validation loss: 2.0196134441642353

Epoch: 6| Step: 12
Training loss: 2.5687851905822754
Validation loss: 2.013584786845792

Epoch: 6| Step: 13
Training loss: 2.7398006916046143
Validation loss: 1.9872223433627878

Epoch: 33| Step: 0
Training loss: 1.7510120868682861
Validation loss: 2.003962129674932

Epoch: 6| Step: 1
Training loss: 2.537344455718994
Validation loss: 2.014810130160342

Epoch: 6| Step: 2
Training loss: 2.2419142723083496
Validation loss: 2.0203785563027985

Epoch: 6| Step: 3
Training loss: 2.399372100830078
Validation loss: 1.9819890273514615

Epoch: 6| Step: 4
Training loss: 2.5449299812316895
Validation loss: 2.0114960683289396

Epoch: 6| Step: 5
Training loss: 2.116151809692383
Validation loss: 2.032963416909659

Epoch: 6| Step: 6
Training loss: 2.6713356971740723
Validation loss: 2.0172288558816396

Epoch: 6| Step: 7
Training loss: 2.581416130065918
Validation loss: 1.9758843068153626

Epoch: 6| Step: 8
Training loss: 1.738158941268921
Validation loss: 2.003086506679494

Epoch: 6| Step: 9
Training loss: 2.970999002456665
Validation loss: 1.993556663554202

Epoch: 6| Step: 10
Training loss: 2.1660256385803223
Validation loss: 1.9561054296390985

Epoch: 6| Step: 11
Training loss: 2.5615923404693604
Validation loss: 1.9892628974812006

Epoch: 6| Step: 12
Training loss: 2.327742576599121
Validation loss: 2.0032414005648707

Epoch: 6| Step: 13
Training loss: 2.3409979343414307
Validation loss: 2.0161340903210383

Epoch: 34| Step: 0
Training loss: 2.214125633239746
Validation loss: 1.9819175812505907

Epoch: 6| Step: 1
Training loss: 2.068781852722168
Validation loss: 1.9987461336197392

Epoch: 6| Step: 2
Training loss: 2.0932445526123047
Validation loss: 1.9897834216394732

Epoch: 6| Step: 3
Training loss: 2.4357962608337402
Validation loss: 1.9613636514191986

Epoch: 6| Step: 4
Training loss: 2.994894504547119
Validation loss: 1.9919559237777547

Epoch: 6| Step: 5
Training loss: 2.5883073806762695
Validation loss: 1.9987234274546306

Epoch: 6| Step: 6
Training loss: 2.6683430671691895
Validation loss: 1.9825869760205668

Epoch: 6| Step: 7
Training loss: 1.5885035991668701
Validation loss: 2.0038354781366166

Epoch: 6| Step: 8
Training loss: 3.1959376335144043
Validation loss: 1.9864742396980204

Epoch: 6| Step: 9
Training loss: 2.2024986743927
Validation loss: 1.9924661408188522

Epoch: 6| Step: 10
Training loss: 1.9699745178222656
Validation loss: 2.0080650211662374

Epoch: 6| Step: 11
Training loss: 2.4424519538879395
Validation loss: 1.9763388556818808

Epoch: 6| Step: 12
Training loss: 1.8313915729522705
Validation loss: 2.012771285990233

Epoch: 6| Step: 13
Training loss: 2.7290866374969482
Validation loss: 2.006120894544868

Epoch: 35| Step: 0
Training loss: 3.2994320392608643
Validation loss: 2.0071078782440512

Epoch: 6| Step: 1
Training loss: 2.3260438442230225
Validation loss: 1.9841261550944338

Epoch: 6| Step: 2
Training loss: 2.598344326019287
Validation loss: 1.9741692299483924

Epoch: 6| Step: 3
Training loss: 1.6718146800994873
Validation loss: 1.9988032374330746

Epoch: 6| Step: 4
Training loss: 2.7804999351501465
Validation loss: 1.991476374287759

Epoch: 6| Step: 5
Training loss: 1.6794559955596924
Validation loss: 1.9997594471900695

Epoch: 6| Step: 6
Training loss: 2.1509017944335938
Validation loss: 1.9857860252421389

Epoch: 6| Step: 7
Training loss: 2.2334554195404053
Validation loss: 2.0007192934713056

Epoch: 6| Step: 8
Training loss: 2.2838516235351562
Validation loss: 2.0126230114249775

Epoch: 6| Step: 9
Training loss: 2.4275498390197754
Validation loss: 2.0040211575005644

Epoch: 6| Step: 10
Training loss: 2.136615037918091
Validation loss: 1.9930471322869743

Epoch: 6| Step: 11
Training loss: 2.3456625938415527
Validation loss: 1.9666884778648295

Epoch: 6| Step: 12
Training loss: 2.3556575775146484
Validation loss: 1.9886270748671664

Epoch: 6| Step: 13
Training loss: 2.396101951599121
Validation loss: 1.9531288070063437

Epoch: 36| Step: 0
Training loss: 2.2684378623962402
Validation loss: 1.967023955878391

Epoch: 6| Step: 1
Training loss: 1.8930003643035889
Validation loss: 1.9662910430662093

Epoch: 6| Step: 2
Training loss: 1.9022210836410522
Validation loss: 2.0095469131264636

Epoch: 6| Step: 3
Training loss: 3.192835807800293
Validation loss: 1.985570840938117

Epoch: 6| Step: 4
Training loss: 3.027094602584839
Validation loss: 1.9962491348225584

Epoch: 6| Step: 5
Training loss: 2.3028151988983154
Validation loss: 2.0066707813611595

Epoch: 6| Step: 6
Training loss: 2.000370502471924
Validation loss: 1.9604388398508872

Epoch: 6| Step: 7
Training loss: 1.9688445329666138
Validation loss: 1.9947265053308139

Epoch: 6| Step: 8
Training loss: 1.8837544918060303
Validation loss: 2.021674991935812

Epoch: 6| Step: 9
Training loss: 3.0487210750579834
Validation loss: 1.988454386752139

Epoch: 6| Step: 10
Training loss: 2.209446907043457
Validation loss: 2.000366303228563

Epoch: 6| Step: 11
Training loss: 2.6441612243652344
Validation loss: 1.9667727575507215

Epoch: 6| Step: 12
Training loss: 2.1124191284179688
Validation loss: 2.0213954910155265

Epoch: 6| Step: 13
Training loss: 2.398543119430542
Validation loss: 1.981081880548949

Epoch: 37| Step: 0
Training loss: 1.7353918552398682
Validation loss: 2.0025467206073064

Epoch: 6| Step: 1
Training loss: 2.056546688079834
Validation loss: 1.9989233504059494

Epoch: 6| Step: 2
Training loss: 2.474384307861328
Validation loss: 1.9946437010201075

Epoch: 6| Step: 3
Training loss: 2.3160042762756348
Validation loss: 2.003043049125261

Epoch: 6| Step: 4
Training loss: 2.17918062210083
Validation loss: 1.9802255950948244

Epoch: 6| Step: 5
Training loss: 2.2375874519348145
Validation loss: 1.9661053752386441

Epoch: 6| Step: 6
Training loss: 2.3827083110809326
Validation loss: 1.9763189900305964

Epoch: 6| Step: 7
Training loss: 2.89806866645813
Validation loss: 2.007406655178275

Epoch: 6| Step: 8
Training loss: 2.103839874267578
Validation loss: 1.9618945531947638

Epoch: 6| Step: 9
Training loss: 3.042187213897705
Validation loss: 1.9733143506511566

Epoch: 6| Step: 10
Training loss: 2.991787910461426
Validation loss: 1.992646926192827

Epoch: 6| Step: 11
Training loss: 1.7808459997177124
Validation loss: 1.9796689505218177

Epoch: 6| Step: 12
Training loss: 2.563616991043091
Validation loss: 2.007125868592211

Epoch: 6| Step: 13
Training loss: 1.8457118272781372
Validation loss: 1.9999237880911878

Epoch: 38| Step: 0
Training loss: 2.4268956184387207
Validation loss: 1.999281282066017

Epoch: 6| Step: 1
Training loss: 2.2552075386047363
Validation loss: 1.9814685429296186

Epoch: 6| Step: 2
Training loss: 1.7119836807250977
Validation loss: 2.0151941340456725

Epoch: 6| Step: 3
Training loss: 2.053471088409424
Validation loss: 2.006018189973729

Epoch: 6| Step: 4
Training loss: 2.8236451148986816
Validation loss: 2.010995336758193

Epoch: 6| Step: 5
Training loss: 2.014169931411743
Validation loss: 1.9784616603646228

Epoch: 6| Step: 6
Training loss: 2.0620903968811035
Validation loss: 2.026967206308919

Epoch: 6| Step: 7
Training loss: 2.606205940246582
Validation loss: 2.010330246340844

Epoch: 6| Step: 8
Training loss: 2.3111186027526855
Validation loss: 2.0156656849768853

Epoch: 6| Step: 9
Training loss: 2.3747525215148926
Validation loss: 2.019131601497691

Epoch: 6| Step: 10
Training loss: 2.1266350746154785
Validation loss: 1.9682218438835555

Epoch: 6| Step: 11
Training loss: 2.2855992317199707
Validation loss: 2.0237556631847093

Epoch: 6| Step: 12
Training loss: 3.1166491508483887
Validation loss: 2.0060433905611754

Epoch: 6| Step: 13
Training loss: 3.0887372493743896
Validation loss: 1.9751175295922063

Epoch: 39| Step: 0
Training loss: 2.474123477935791
Validation loss: 2.0192534462098153

Epoch: 6| Step: 1
Training loss: 2.9431285858154297
Validation loss: 2.0035228998430314

Epoch: 6| Step: 2
Training loss: 1.6493139266967773
Validation loss: 1.9932683206373645

Epoch: 6| Step: 3
Training loss: 2.678520917892456
Validation loss: 2.004775734357936

Epoch: 6| Step: 4
Training loss: 2.859934091567993
Validation loss: 2.01301614058915

Epoch: 6| Step: 5
Training loss: 2.3254852294921875
Validation loss: 2.010213005927301

Epoch: 6| Step: 6
Training loss: 2.027524471282959
Validation loss: 1.9875470438311178

Epoch: 6| Step: 7
Training loss: 2.6811656951904297
Validation loss: 1.9791061698749501

Epoch: 6| Step: 8
Training loss: 1.8477535247802734
Validation loss: 2.0016449087409565

Epoch: 6| Step: 9
Training loss: 2.89041805267334
Validation loss: 2.003778576850891

Epoch: 6| Step: 10
Training loss: 1.7813985347747803
Validation loss: 1.9887927039977042

Epoch: 6| Step: 11
Training loss: 1.9722930192947388
Validation loss: 1.9615932536381546

Epoch: 6| Step: 12
Training loss: 1.7830018997192383
Validation loss: 2.0050399969982844

Epoch: 6| Step: 13
Training loss: 3.314581871032715
Validation loss: 1.997373636050891

Epoch: 40| Step: 0
Training loss: 2.5475478172302246
Validation loss: 1.9939879743001794

Epoch: 6| Step: 1
Training loss: 1.3200607299804688
Validation loss: 2.008780846031763

Epoch: 6| Step: 2
Training loss: 1.6236295700073242
Validation loss: 1.986461297158272

Epoch: 6| Step: 3
Training loss: 2.8910973072052
Validation loss: 1.9934903139709144

Epoch: 6| Step: 4
Training loss: 2.770411252975464
Validation loss: 2.0080555818414174

Epoch: 6| Step: 5
Training loss: 2.3611373901367188
Validation loss: 2.009802177388181

Epoch: 6| Step: 6
Training loss: 2.9001574516296387
Validation loss: 2.018549350000197

Epoch: 6| Step: 7
Training loss: 2.508756399154663
Validation loss: 2.017734172523663

Epoch: 6| Step: 8
Training loss: 2.5041921138763428
Validation loss: 1.9985241120861423

Epoch: 6| Step: 9
Training loss: 2.102044105529785
Validation loss: 2.0258993782022947

Epoch: 6| Step: 10
Training loss: 2.2635161876678467
Validation loss: 1.9979345119127663

Epoch: 6| Step: 11
Training loss: 1.885026216506958
Validation loss: 2.013146733724943

Epoch: 6| Step: 12
Training loss: 2.8512489795684814
Validation loss: 1.9723794409023818

Epoch: 6| Step: 13
Training loss: 2.4993114471435547
Validation loss: 1.9899032705573625

Epoch: 41| Step: 0
Training loss: 2.335991621017456
Validation loss: 2.0008307708207

Epoch: 6| Step: 1
Training loss: 2.106618881225586
Validation loss: 1.9891101749994422

Epoch: 6| Step: 2
Training loss: 1.9019116163253784
Validation loss: 2.013526483248639

Epoch: 6| Step: 3
Training loss: 2.357600688934326
Validation loss: 2.0103335508736233

Epoch: 6| Step: 4
Training loss: 2.8546805381774902
Validation loss: 2.013876981632684

Epoch: 6| Step: 5
Training loss: 2.1070199012756348
Validation loss: 2.0115239133117018

Epoch: 6| Step: 6
Training loss: 2.0250251293182373
Validation loss: 2.0094700321074455

Epoch: 6| Step: 7
Training loss: 2.5442423820495605
Validation loss: 2.0351451135450795

Epoch: 6| Step: 8
Training loss: 2.1206929683685303
Validation loss: 1.9958496119386406

Epoch: 6| Step: 9
Training loss: 3.292750597000122
Validation loss: 2.0064096527714885

Epoch: 6| Step: 10
Training loss: 2.4817299842834473
Validation loss: 2.0102783582543813

Epoch: 6| Step: 11
Training loss: 2.4834399223327637
Validation loss: 2.0261671850758214

Epoch: 6| Step: 12
Training loss: 2.0727293491363525
Validation loss: 2.0211670629439817

Epoch: 6| Step: 13
Training loss: 2.0021169185638428
Validation loss: 2.0242845909569853

Epoch: 42| Step: 0
Training loss: 1.9153563976287842
Validation loss: 2.0418083206299813

Epoch: 6| Step: 1
Training loss: 1.5383944511413574
Validation loss: 1.9986199576367614

Epoch: 6| Step: 2
Training loss: 2.364366054534912
Validation loss: 2.0282050537806686

Epoch: 6| Step: 3
Training loss: 2.152277946472168
Validation loss: 2.014958966162897

Epoch: 6| Step: 4
Training loss: 2.2285776138305664
Validation loss: 2.046902548882269

Epoch: 6| Step: 5
Training loss: 2.762880802154541
Validation loss: 2.007271966626567

Epoch: 6| Step: 6
Training loss: 2.416577100753784
Validation loss: 2.0085078875223794

Epoch: 6| Step: 7
Training loss: 2.058499813079834
Validation loss: 2.0030084835585726

Epoch: 6| Step: 8
Training loss: 2.448202133178711
Validation loss: 2.0327636490585985

Epoch: 6| Step: 9
Training loss: 2.523702383041382
Validation loss: 2.0106625813309864

Epoch: 6| Step: 10
Training loss: 2.3172225952148438
Validation loss: 2.0357340202536633

Epoch: 6| Step: 11
Training loss: 2.8514997959136963
Validation loss: 2.0021152150246406

Epoch: 6| Step: 12
Training loss: 2.3649275302886963
Validation loss: 2.0118267074708016

Epoch: 6| Step: 13
Training loss: 2.7821097373962402
Validation loss: 2.029384392564015

Epoch: 43| Step: 0
Training loss: 2.6152453422546387
Validation loss: 2.0244263833568943

Epoch: 6| Step: 1
Training loss: 2.3215107917785645
Validation loss: 2.0063842752928376

Epoch: 6| Step: 2
Training loss: 2.0520401000976562
Validation loss: 2.0220355346638668

Epoch: 6| Step: 3
Training loss: 2.2503886222839355
Validation loss: 1.9949155584458382

Epoch: 6| Step: 4
Training loss: 1.9841424226760864
Validation loss: 2.0073907939336633

Epoch: 6| Step: 5
Training loss: 2.6651148796081543
Validation loss: 2.026526701065802

Epoch: 6| Step: 6
Training loss: 1.7143892049789429
Validation loss: 2.0065787453805246

Epoch: 6| Step: 7
Training loss: 2.7016243934631348
Validation loss: 2.0161483185265654

Epoch: 6| Step: 8
Training loss: 1.9690532684326172
Validation loss: 2.0026012569345455

Epoch: 6| Step: 9
Training loss: 2.4758455753326416
Validation loss: 2.0051309857317197

Epoch: 6| Step: 10
Training loss: 2.3973941802978516
Validation loss: 1.9819397887875956

Epoch: 6| Step: 11
Training loss: 2.845641613006592
Validation loss: 1.9730175592566048

Epoch: 6| Step: 12
Training loss: 2.075082778930664
Validation loss: 2.0100433441900436

Epoch: 6| Step: 13
Training loss: 2.8389053344726562
Validation loss: 2.000544899253435

Epoch: 44| Step: 0
Training loss: 2.3353729248046875
Validation loss: 1.9906444088105233

Epoch: 6| Step: 1
Training loss: 2.644674301147461
Validation loss: 2.001085042953491

Epoch: 6| Step: 2
Training loss: 2.69712495803833
Validation loss: 2.0025331256210164

Epoch: 6| Step: 3
Training loss: 1.7416367530822754
Validation loss: 1.9906565720035183

Epoch: 6| Step: 4
Training loss: 2.7549984455108643
Validation loss: 2.0139532627597934

Epoch: 6| Step: 5
Training loss: 1.9553554058074951
Validation loss: 1.9924770734643424

Epoch: 6| Step: 6
Training loss: 2.2598862648010254
Validation loss: 1.9961908760891165

Epoch: 6| Step: 7
Training loss: 1.8959293365478516
Validation loss: 1.9983016034608245

Epoch: 6| Step: 8
Training loss: 2.626893997192383
Validation loss: 2.017972505220803

Epoch: 6| Step: 9
Training loss: 2.9012272357940674
Validation loss: 1.98844357972504

Epoch: 6| Step: 10
Training loss: 1.7615301609039307
Validation loss: 1.9974377950032551

Epoch: 6| Step: 11
Training loss: 2.63653564453125
Validation loss: 1.995866451212155

Epoch: 6| Step: 12
Training loss: 1.7663843631744385
Validation loss: 1.9848574848585232

Epoch: 6| Step: 13
Training loss: 2.9083187580108643
Validation loss: 1.9839676490394018

Epoch: 45| Step: 0
Training loss: 1.933547019958496
Validation loss: 2.0208978294044413

Epoch: 6| Step: 1
Training loss: 2.1464924812316895
Validation loss: 1.9919525987358504

Epoch: 6| Step: 2
Training loss: 2.289797782897949
Validation loss: 2.0040590865637666

Epoch: 6| Step: 3
Training loss: 1.6794695854187012
Validation loss: 1.9991736591503184

Epoch: 6| Step: 4
Training loss: 2.62404465675354
Validation loss: 2.0087202338762182

Epoch: 6| Step: 5
Training loss: 2.427419900894165
Validation loss: 2.009753352852278

Epoch: 6| Step: 6
Training loss: 2.2708005905151367
Validation loss: 2.0182239432488718

Epoch: 6| Step: 7
Training loss: 2.428892135620117
Validation loss: 1.9900072723306634

Epoch: 6| Step: 8
Training loss: 2.6921277046203613
Validation loss: 2.0041933751875356

Epoch: 6| Step: 9
Training loss: 2.878115177154541
Validation loss: 1.9937418045536164

Epoch: 6| Step: 10
Training loss: 2.5539307594299316
Validation loss: 1.9986501278415802

Epoch: 6| Step: 11
Training loss: 2.0121042728424072
Validation loss: 1.982673934710923

Epoch: 6| Step: 12
Training loss: 2.3620729446411133
Validation loss: 1.9962766439683977

Epoch: 6| Step: 13
Training loss: 2.0838749408721924
Validation loss: 2.003691824533606

Epoch: 46| Step: 0
Training loss: 2.2783753871917725
Validation loss: 2.0076898861956853

Epoch: 6| Step: 1
Training loss: 2.35310697555542
Validation loss: 2.017873705074351

Epoch: 6| Step: 2
Training loss: 2.883575201034546
Validation loss: 2.003305532599008

Epoch: 6| Step: 3
Training loss: 2.445711135864258
Validation loss: 1.9992771071772422

Epoch: 6| Step: 4
Training loss: 2.667907476425171
Validation loss: 1.9916492380121702

Epoch: 6| Step: 5
Training loss: 1.4087598323822021
Validation loss: 1.9709400335947673

Epoch: 6| Step: 6
Training loss: 2.1576688289642334
Validation loss: 1.9709316312625844

Epoch: 6| Step: 7
Training loss: 2.4021542072296143
Validation loss: 1.9978596959062802

Epoch: 6| Step: 8
Training loss: 2.567628860473633
Validation loss: 2.0073402158675657

Epoch: 6| Step: 9
Training loss: 2.2004923820495605
Validation loss: 2.0022262732187905

Epoch: 6| Step: 10
Training loss: 2.23532772064209
Validation loss: 1.973342244343091

Epoch: 6| Step: 11
Training loss: 2.6227495670318604
Validation loss: 2.003815958576818

Epoch: 6| Step: 12
Training loss: 1.9402750730514526
Validation loss: 1.9975153553870417

Epoch: 6| Step: 13
Training loss: 2.15925931930542
Validation loss: 1.9902855170670377

Epoch: 47| Step: 0
Training loss: 2.5772671699523926
Validation loss: 1.9997540955902429

Epoch: 6| Step: 1
Training loss: 1.700219988822937
Validation loss: 1.9899668180814354

Epoch: 6| Step: 2
Training loss: 2.016894817352295
Validation loss: 1.9693885323821858

Epoch: 6| Step: 3
Training loss: 2.5549120903015137
Validation loss: 1.9794359027698476

Epoch: 6| Step: 4
Training loss: 2.5289013385772705
Validation loss: 1.9898377182663127

Epoch: 6| Step: 5
Training loss: 2.2492847442626953
Validation loss: 2.0063121062453075

Epoch: 6| Step: 6
Training loss: 3.0165960788726807
Validation loss: 2.0112310032690726

Epoch: 6| Step: 7
Training loss: 1.6579477787017822
Validation loss: 2.000680395351943

Epoch: 6| Step: 8
Training loss: 2.089794874191284
Validation loss: 1.9965014816612325

Epoch: 6| Step: 9
Training loss: 2.488222599029541
Validation loss: 1.9764253606078446

Epoch: 6| Step: 10
Training loss: 2.110201835632324
Validation loss: 1.9705655446616552

Epoch: 6| Step: 11
Training loss: 2.4292080402374268
Validation loss: 1.9818033197874665

Epoch: 6| Step: 12
Training loss: 2.107835292816162
Validation loss: 1.9979413619605444

Epoch: 6| Step: 13
Training loss: 3.41860294342041
Validation loss: 2.010375153633856

Epoch: 48| Step: 0
Training loss: 1.9895473718643188
Validation loss: 1.9836200757693219

Epoch: 6| Step: 1
Training loss: 2.0556230545043945
Validation loss: 2.0224394823915217

Epoch: 6| Step: 2
Training loss: 1.9497876167297363
Validation loss: 2.0132529620201356

Epoch: 6| Step: 3
Training loss: 2.931885242462158
Validation loss: 1.9933205484062113

Epoch: 6| Step: 4
Training loss: 2.494748830795288
Validation loss: 2.0110014510411087

Epoch: 6| Step: 5
Training loss: 2.1297638416290283
Validation loss: 2.0029780134077995

Epoch: 6| Step: 6
Training loss: 2.423861265182495
Validation loss: 2.010673761367798

Epoch: 6| Step: 7
Training loss: 2.5131475925445557
Validation loss: 2.0186213447201635

Epoch: 6| Step: 8
Training loss: 2.919646739959717
Validation loss: 1.9969313401047901

Epoch: 6| Step: 9
Training loss: 1.8038043975830078
Validation loss: 2.021570486407126

Epoch: 6| Step: 10
Training loss: 2.152153968811035
Validation loss: 1.9935463243915188

Epoch: 6| Step: 11
Training loss: 2.365128517150879
Validation loss: 1.9905551120799074

Epoch: 6| Step: 12
Training loss: 2.5247204303741455
Validation loss: 2.0104615008959206

Epoch: 6| Step: 13
Training loss: 1.99168062210083
Validation loss: 1.9672645240701654

Epoch: 49| Step: 0
Training loss: 2.3193249702453613
Validation loss: 1.9919288107143935

Epoch: 6| Step: 1
Training loss: 2.5936286449432373
Validation loss: 1.993836482365926

Epoch: 6| Step: 2
Training loss: 2.339653253555298
Validation loss: 1.9992357671901744

Epoch: 6| Step: 3
Training loss: 2.40767502784729
Validation loss: 1.974731171002952

Epoch: 6| Step: 4
Training loss: 1.883227825164795
Validation loss: 2.0015778272382674

Epoch: 6| Step: 5
Training loss: 2.6591906547546387
Validation loss: 1.9770914636632448

Epoch: 6| Step: 6
Training loss: 2.8301539421081543
Validation loss: 1.9974313589834398

Epoch: 6| Step: 7
Training loss: 2.0980827808380127
Validation loss: 1.9958068093945902

Epoch: 6| Step: 8
Training loss: 2.305610179901123
Validation loss: 2.010897341594901

Epoch: 6| Step: 9
Training loss: 1.3357601165771484
Validation loss: 1.996226103075089

Epoch: 6| Step: 10
Training loss: 2.026017189025879
Validation loss: 1.976843698050386

Epoch: 6| Step: 11
Training loss: 3.225024700164795
Validation loss: 1.9732120472897765

Epoch: 6| Step: 12
Training loss: 1.7904503345489502
Validation loss: 1.9742740136320873

Epoch: 6| Step: 13
Training loss: 3.0928640365600586
Validation loss: 1.9795251225912442

Epoch: 50| Step: 0
Training loss: 1.8986601829528809
Validation loss: 2.00683105632823

Epoch: 6| Step: 1
Training loss: 1.9897165298461914
Validation loss: 2.0100873465179117

Epoch: 6| Step: 2
Training loss: 2.0601112842559814
Validation loss: 2.0172726608091787

Epoch: 6| Step: 3
Training loss: 1.6765458583831787
Validation loss: 1.9781067409823019

Epoch: 6| Step: 4
Training loss: 2.7060601711273193
Validation loss: 2.003599261724821

Epoch: 6| Step: 5
Training loss: 2.316392421722412
Validation loss: 1.9899734540652203

Epoch: 6| Step: 6
Training loss: 2.7097296714782715
Validation loss: 2.0008027015193814

Epoch: 6| Step: 7
Training loss: 1.9806482791900635
Validation loss: 2.0072357270025436

Epoch: 6| Step: 8
Training loss: 2.3062214851379395
Validation loss: 2.004101776307629

Epoch: 6| Step: 9
Training loss: 2.8058712482452393
Validation loss: 1.9746398413053123

Epoch: 6| Step: 10
Training loss: 2.4041476249694824
Validation loss: 2.0228939094851093

Epoch: 6| Step: 11
Training loss: 2.471569538116455
Validation loss: 1.9897838856584282

Epoch: 6| Step: 12
Training loss: 2.5581183433532715
Validation loss: 1.9943332249118435

Epoch: 6| Step: 13
Training loss: 2.637643575668335
Validation loss: 2.0188739158773936

Epoch: 51| Step: 0
Training loss: 2.6745548248291016
Validation loss: 1.9924882996466853

Epoch: 6| Step: 1
Training loss: 2.4129738807678223
Validation loss: 2.0103206711430706

Epoch: 6| Step: 2
Training loss: 2.3679730892181396
Validation loss: 1.9924350387306624

Epoch: 6| Step: 3
Training loss: 2.031142234802246
Validation loss: 2.0009660067096835

Epoch: 6| Step: 4
Training loss: 1.9510576725006104
Validation loss: 2.004560362908148

Epoch: 6| Step: 5
Training loss: 2.89724063873291
Validation loss: 2.0007418509452575

Epoch: 6| Step: 6
Training loss: 1.7293139696121216
Validation loss: 2.0149766168286725

Epoch: 6| Step: 7
Training loss: 2.098316192626953
Validation loss: 1.9967833231854182

Epoch: 6| Step: 8
Training loss: 2.040647506713867
Validation loss: 1.986406321166664

Epoch: 6| Step: 9
Training loss: 2.6908860206604004
Validation loss: 1.97072462625401

Epoch: 6| Step: 10
Training loss: 2.2602899074554443
Validation loss: 1.9859974807308567

Epoch: 6| Step: 11
Training loss: 2.3039653301239014
Validation loss: 1.9933678975669287

Epoch: 6| Step: 12
Training loss: 2.729161262512207
Validation loss: 2.0177310205275014

Epoch: 6| Step: 13
Training loss: 1.7334463596343994
Validation loss: 1.9950585147385955

Epoch: 52| Step: 0
Training loss: 2.115988254547119
Validation loss: 1.994984096096408

Epoch: 6| Step: 1
Training loss: 2.6972179412841797
Validation loss: 1.9773986519023936

Epoch: 6| Step: 2
Training loss: 1.9582407474517822
Validation loss: 2.0031391625763266

Epoch: 6| Step: 3
Training loss: 2.6491215229034424
Validation loss: 2.0056561539250035

Epoch: 6| Step: 4
Training loss: 2.0811681747436523
Validation loss: 2.0128985092204106

Epoch: 6| Step: 5
Training loss: 2.5280535221099854
Validation loss: 1.9842554446189635

Epoch: 6| Step: 6
Training loss: 2.050917625427246
Validation loss: 1.9946909796807073

Epoch: 6| Step: 7
Training loss: 2.058305025100708
Validation loss: 1.9839808094886042

Epoch: 6| Step: 8
Training loss: 2.586002826690674
Validation loss: 1.9804644815383419

Epoch: 6| Step: 9
Training loss: 2.247765064239502
Validation loss: 1.9852482016368578

Epoch: 6| Step: 10
Training loss: 2.943720817565918
Validation loss: 1.9906863166439919

Epoch: 6| Step: 11
Training loss: 2.046116828918457
Validation loss: 1.9873352794237034

Epoch: 6| Step: 12
Training loss: 2.529956817626953
Validation loss: 2.000118322269891

Epoch: 6| Step: 13
Training loss: 1.4979887008666992
Validation loss: 1.9908954969016455

Epoch: 53| Step: 0
Training loss: 1.984595537185669
Validation loss: 2.0019397556140857

Epoch: 6| Step: 1
Training loss: 1.968505859375
Validation loss: 2.0196842839640956

Epoch: 6| Step: 2
Training loss: 2.9528472423553467
Validation loss: 1.9919157079471055

Epoch: 6| Step: 3
Training loss: 2.0141243934631348
Validation loss: 1.9991638006702546

Epoch: 6| Step: 4
Training loss: 2.400695562362671
Validation loss: 2.0011877321427867

Epoch: 6| Step: 5
Training loss: 1.8919272422790527
Validation loss: 2.0245668016454226

Epoch: 6| Step: 6
Training loss: 3.0575199127197266
Validation loss: 2.014450353960837

Epoch: 6| Step: 7
Training loss: 1.8150064945220947
Validation loss: 2.000755176749281

Epoch: 6| Step: 8
Training loss: 2.1177024841308594
Validation loss: 2.0145909017132175

Epoch: 6| Step: 9
Training loss: 2.595968246459961
Validation loss: 1.991016782740111

Epoch: 6| Step: 10
Training loss: 2.531919002532959
Validation loss: 2.013221504867718

Epoch: 6| Step: 11
Training loss: 2.6978540420532227
Validation loss: 2.016127263346026

Epoch: 6| Step: 12
Training loss: 2.1674141883850098
Validation loss: 2.020709708172788

Epoch: 6| Step: 13
Training loss: 1.7241077423095703
Validation loss: 2.0168938713689006

Epoch: 54| Step: 0
Training loss: 2.496485710144043
Validation loss: 2.011383407859392

Epoch: 6| Step: 1
Training loss: 1.6409133672714233
Validation loss: 2.008577483956532

Epoch: 6| Step: 2
Training loss: 2.418250560760498
Validation loss: 2.024521876406926

Epoch: 6| Step: 3
Training loss: 2.085719108581543
Validation loss: 2.004598891863259

Epoch: 6| Step: 4
Training loss: 2.3176350593566895
Validation loss: 2.026016918561792

Epoch: 6| Step: 5
Training loss: 2.6869025230407715
Validation loss: 2.0283418163176505

Epoch: 6| Step: 6
Training loss: 1.9656181335449219
Validation loss: 1.9861039141173005

Epoch: 6| Step: 7
Training loss: 2.0373480319976807
Validation loss: 2.0168586777102564

Epoch: 6| Step: 8
Training loss: 2.203810691833496
Validation loss: 2.0300509416928856

Epoch: 6| Step: 9
Training loss: 2.7175068855285645
Validation loss: 2.0392204151358655

Epoch: 6| Step: 10
Training loss: 1.8592957258224487
Validation loss: 2.0004264744379188

Epoch: 6| Step: 11
Training loss: 3.267805576324463
Validation loss: 2.0337224916745256

Epoch: 6| Step: 12
Training loss: 2.0190863609313965
Validation loss: 2.028365481284357

Epoch: 6| Step: 13
Training loss: 2.5962612628936768
Validation loss: 2.0020904617924846

Epoch: 55| Step: 0
Training loss: 2.0898537635803223
Validation loss: 2.016396394339941

Epoch: 6| Step: 1
Training loss: 2.007068634033203
Validation loss: 2.015652323281893

Epoch: 6| Step: 2
Training loss: 2.3592569828033447
Validation loss: 2.007859440260036

Epoch: 6| Step: 3
Training loss: 2.9705071449279785
Validation loss: 2.0143053198373444

Epoch: 6| Step: 4
Training loss: 1.8122329711914062
Validation loss: 1.9940317202639837

Epoch: 6| Step: 5
Training loss: 1.6872961521148682
Validation loss: 1.992061097134826

Epoch: 6| Step: 6
Training loss: 2.0318713188171387
Validation loss: 1.978316532668247

Epoch: 6| Step: 7
Training loss: 2.8140347003936768
Validation loss: 2.0071111622677056

Epoch: 6| Step: 8
Training loss: 2.3991122245788574
Validation loss: 2.0325840621866207

Epoch: 6| Step: 9
Training loss: 1.7131167650222778
Validation loss: 2.024257718875844

Epoch: 6| Step: 10
Training loss: 2.2872071266174316
Validation loss: 2.0281691474299275

Epoch: 6| Step: 11
Training loss: 2.945211887359619
Validation loss: 2.0084492121973345

Epoch: 6| Step: 12
Training loss: 2.8601784706115723
Validation loss: 1.9997739740597305

Epoch: 6| Step: 13
Training loss: 1.904213547706604
Validation loss: 2.0128995218584613

Epoch: 56| Step: 0
Training loss: 2.0457935333251953
Validation loss: 2.0208058869966896

Epoch: 6| Step: 1
Training loss: 2.389686107635498
Validation loss: 2.0347394379236365

Epoch: 6| Step: 2
Training loss: 2.229315757751465
Validation loss: 2.030248298439928

Epoch: 6| Step: 3
Training loss: 1.5693732500076294
Validation loss: 1.99772217453167

Epoch: 6| Step: 4
Training loss: 2.742020845413208
Validation loss: 1.9918314051884476

Epoch: 6| Step: 5
Training loss: 1.9065701961517334
Validation loss: 1.9683344441075479

Epoch: 6| Step: 6
Training loss: 2.5225234031677246
Validation loss: 1.994201590937953

Epoch: 6| Step: 7
Training loss: 1.9839329719543457
Validation loss: 1.959888219833374

Epoch: 6| Step: 8
Training loss: 2.350219249725342
Validation loss: 1.9739615571114324

Epoch: 6| Step: 9
Training loss: 2.739074230194092
Validation loss: 1.9687504024915798

Epoch: 6| Step: 10
Training loss: 1.7218730449676514
Validation loss: 1.963474524918423

Epoch: 6| Step: 11
Training loss: 2.6748995780944824
Validation loss: 1.9768035834835422

Epoch: 6| Step: 12
Training loss: 2.814565420150757
Validation loss: 1.989458550689041

Epoch: 6| Step: 13
Training loss: 2.954892635345459
Validation loss: 2.0155476741893317

Epoch: 57| Step: 0
Training loss: 1.8580787181854248
Validation loss: 1.9827034806692472

Epoch: 6| Step: 1
Training loss: 2.1086623668670654
Validation loss: 1.99975799745129

Epoch: 6| Step: 2
Training loss: 2.675342082977295
Validation loss: 1.9916862915920954

Epoch: 6| Step: 3
Training loss: 2.215714931488037
Validation loss: 2.006724957496889

Epoch: 6| Step: 4
Training loss: 2.250997543334961
Validation loss: 1.9981095175589285

Epoch: 6| Step: 5
Training loss: 2.2635340690612793
Validation loss: 1.9645172793378112

Epoch: 6| Step: 6
Training loss: 2.7531399726867676
Validation loss: 2.0039478181510844

Epoch: 6| Step: 7
Training loss: 3.1229140758514404
Validation loss: 2.019841068534441

Epoch: 6| Step: 8
Training loss: 2.454310417175293
Validation loss: 2.0034354168881654

Epoch: 6| Step: 9
Training loss: 2.0923378467559814
Validation loss: 2.000077086110269

Epoch: 6| Step: 10
Training loss: 2.20845627784729
Validation loss: 2.0127996347283803

Epoch: 6| Step: 11
Training loss: 1.9157295227050781
Validation loss: 2.0233088270310433

Epoch: 6| Step: 12
Training loss: 1.845257043838501
Validation loss: 1.9963433601522957

Epoch: 6| Step: 13
Training loss: 2.1661646366119385
Validation loss: 2.002957785001365

Epoch: 58| Step: 0
Training loss: 2.130033493041992
Validation loss: 1.9946103557463615

Epoch: 6| Step: 1
Training loss: 2.5033740997314453
Validation loss: 2.002717967956297

Epoch: 6| Step: 2
Training loss: 1.1660926342010498
Validation loss: 1.9879583171618882

Epoch: 6| Step: 3
Training loss: 2.373380184173584
Validation loss: 2.01179249312288

Epoch: 6| Step: 4
Training loss: 2.3174262046813965
Validation loss: 2.0245226044808664

Epoch: 6| Step: 5
Training loss: 2.5947389602661133
Validation loss: 2.0184659393884803

Epoch: 6| Step: 6
Training loss: 2.5488295555114746
Validation loss: 2.003792929392989

Epoch: 6| Step: 7
Training loss: 2.5001637935638428
Validation loss: 1.9885592755450998

Epoch: 6| Step: 8
Training loss: 2.4001595973968506
Validation loss: 1.988949857732301

Epoch: 6| Step: 9
Training loss: 2.395707607269287
Validation loss: 2.005890130996704

Epoch: 6| Step: 10
Training loss: 1.9740430116653442
Validation loss: 1.991588633547547

Epoch: 6| Step: 11
Training loss: 1.9583868980407715
Validation loss: 2.0072242213833715

Epoch: 6| Step: 12
Training loss: 2.6100170612335205
Validation loss: 2.00141159437036

Epoch: 6| Step: 13
Training loss: 3.0161163806915283
Validation loss: 2.0381825252245833

Epoch: 59| Step: 0
Training loss: 2.4888343811035156
Validation loss: 2.0056868445488716

Epoch: 6| Step: 1
Training loss: 3.0865650177001953
Validation loss: 1.990153807465748

Epoch: 6| Step: 2
Training loss: 1.876877784729004
Validation loss: 2.001851362566794

Epoch: 6| Step: 3
Training loss: 2.4931232929229736
Validation loss: 1.9942447857190204

Epoch: 6| Step: 4
Training loss: 2.2958996295928955
Validation loss: 2.0125425579727336

Epoch: 6| Step: 5
Training loss: 2.221902847290039
Validation loss: 2.006762742996216

Epoch: 6| Step: 6
Training loss: 2.3444032669067383
Validation loss: 1.990883537518081

Epoch: 6| Step: 7
Training loss: 1.9290282726287842
Validation loss: 1.9919888447689753

Epoch: 6| Step: 8
Training loss: 2.084686756134033
Validation loss: 2.0087772453984907

Epoch: 6| Step: 9
Training loss: 1.9306262731552124
Validation loss: 2.001467443281604

Epoch: 6| Step: 10
Training loss: 2.678273916244507
Validation loss: 2.0003794367595384

Epoch: 6| Step: 11
Training loss: 1.7643351554870605
Validation loss: 2.008836110432943

Epoch: 6| Step: 12
Training loss: 2.1214587688446045
Validation loss: 2.0121110421355053

Epoch: 6| Step: 13
Training loss: 3.3070859909057617
Validation loss: 1.9956342276706491

Epoch: 60| Step: 0
Training loss: 2.095588207244873
Validation loss: 2.022810423245994

Epoch: 6| Step: 1
Training loss: 1.681412696838379
Validation loss: 2.000799863569198

Epoch: 6| Step: 2
Training loss: 1.5247905254364014
Validation loss: 1.9987080199744112

Epoch: 6| Step: 3
Training loss: 1.9178900718688965
Validation loss: 2.003139406122187

Epoch: 6| Step: 4
Training loss: 2.7549099922180176
Validation loss: 2.0247410843449254

Epoch: 6| Step: 5
Training loss: 2.7662620544433594
Validation loss: 2.010235458291987

Epoch: 6| Step: 6
Training loss: 2.0554494857788086
Validation loss: 1.9972516157293831

Epoch: 6| Step: 7
Training loss: 1.9583333730697632
Validation loss: 2.020830974783949

Epoch: 6| Step: 8
Training loss: 2.186593532562256
Validation loss: 1.9974180498430807

Epoch: 6| Step: 9
Training loss: 2.7412900924682617
Validation loss: 1.983504799104506

Epoch: 6| Step: 10
Training loss: 2.7259371280670166
Validation loss: 2.0144702106393795

Epoch: 6| Step: 11
Training loss: 2.7279064655303955
Validation loss: 2.000248316795595

Epoch: 6| Step: 12
Training loss: 2.4962148666381836
Validation loss: 1.9937601679114885

Epoch: 6| Step: 13
Training loss: 2.405148506164551
Validation loss: 2.0287106652413645

Epoch: 61| Step: 0
Training loss: 2.39884352684021
Validation loss: 2.010423529532648

Epoch: 6| Step: 1
Training loss: 1.7170084714889526
Validation loss: 2.013506039496391

Epoch: 6| Step: 2
Training loss: 2.463554859161377
Validation loss: 2.016340580037845

Epoch: 6| Step: 3
Training loss: 2.069622278213501
Validation loss: 2.0319193640062885

Epoch: 6| Step: 4
Training loss: 2.1199235916137695
Validation loss: 2.0050448448427263

Epoch: 6| Step: 5
Training loss: 2.1585798263549805
Validation loss: 1.9921584552334202

Epoch: 6| Step: 6
Training loss: 2.687087059020996
Validation loss: 1.9941474083931214

Epoch: 6| Step: 7
Training loss: 2.5213942527770996
Validation loss: 2.015118897602122

Epoch: 6| Step: 8
Training loss: 1.947260856628418
Validation loss: 2.0063734631384573

Epoch: 6| Step: 9
Training loss: 1.6692675352096558
Validation loss: 2.029082098314839

Epoch: 6| Step: 10
Training loss: 2.232006549835205
Validation loss: 2.014991988417923

Epoch: 6| Step: 11
Training loss: 2.964944362640381
Validation loss: 2.041559218078531

Epoch: 6| Step: 12
Training loss: 3.16397762298584
Validation loss: 1.9654185079759168

Epoch: 6| Step: 13
Training loss: 1.677318811416626
Validation loss: 1.981134928682799

Epoch: 62| Step: 0
Training loss: 2.1175079345703125
Validation loss: 2.005385055336901

Epoch: 6| Step: 1
Training loss: 2.5086982250213623
Validation loss: 1.984000495685044

Epoch: 6| Step: 2
Training loss: 3.0572547912597656
Validation loss: 2.022005037594867

Epoch: 6| Step: 3
Training loss: 2.034071445465088
Validation loss: 2.013784644424274

Epoch: 6| Step: 4
Training loss: 1.6513206958770752
Validation loss: 2.0105177151259555

Epoch: 6| Step: 5
Training loss: 2.6139633655548096
Validation loss: 1.972270026001879

Epoch: 6| Step: 6
Training loss: 1.2186846733093262
Validation loss: 2.002807447987218

Epoch: 6| Step: 7
Training loss: 2.182074546813965
Validation loss: 1.9996688878664406

Epoch: 6| Step: 8
Training loss: 2.1274232864379883
Validation loss: 1.996824715727119

Epoch: 6| Step: 9
Training loss: 2.7825851440429688
Validation loss: 2.0169058320342854

Epoch: 6| Step: 10
Training loss: 2.6949496269226074
Validation loss: 2.003126211063836

Epoch: 6| Step: 11
Training loss: 2.0935864448547363
Validation loss: 2.0208819937962357

Epoch: 6| Step: 12
Training loss: 2.2108123302459717
Validation loss: 2.0096512904731174

Epoch: 6| Step: 13
Training loss: 2.9454400539398193
Validation loss: 2.0240180133491434

Epoch: 63| Step: 0
Training loss: 2.724493980407715
Validation loss: 2.0054405581566597

Epoch: 6| Step: 1
Training loss: 2.839824676513672
Validation loss: 2.001784614337388

Epoch: 6| Step: 2
Training loss: 1.693629503250122
Validation loss: 2.0012986429276003

Epoch: 6| Step: 3
Training loss: 2.0399348735809326
Validation loss: 1.9844610306524462

Epoch: 6| Step: 4
Training loss: 2.246385097503662
Validation loss: 1.9975012527999056

Epoch: 6| Step: 5
Training loss: 3.3843040466308594
Validation loss: 1.988095889809311

Epoch: 6| Step: 6
Training loss: 2.148017644882202
Validation loss: 1.995311325596225

Epoch: 6| Step: 7
Training loss: 2.1457512378692627
Validation loss: 2.014221679779791

Epoch: 6| Step: 8
Training loss: 2.6185014247894287
Validation loss: 2.010788445831627

Epoch: 6| Step: 9
Training loss: 1.6043541431427002
Validation loss: 1.9867695569992065

Epoch: 6| Step: 10
Training loss: 2.2141292095184326
Validation loss: 1.9861732849510767

Epoch: 6| Step: 11
Training loss: 2.200197219848633
Validation loss: 1.9920226502162155

Epoch: 6| Step: 12
Training loss: 1.7349815368652344
Validation loss: 1.9735501209894817

Epoch: 6| Step: 13
Training loss: 2.1493515968322754
Validation loss: 2.0071771221776165

Epoch: 64| Step: 0
Training loss: 1.2612839937210083
Validation loss: 1.9839260501246299

Epoch: 6| Step: 1
Training loss: 2.3111588954925537
Validation loss: 1.9979170573654996

Epoch: 6| Step: 2
Training loss: 2.805732488632202
Validation loss: 1.9848724616471158

Epoch: 6| Step: 3
Training loss: 3.4939374923706055
Validation loss: 1.990848418205015

Epoch: 6| Step: 4
Training loss: 2.728377342224121
Validation loss: 2.00815704689231

Epoch: 6| Step: 5
Training loss: 1.5440788269042969
Validation loss: 1.9927826440462502

Epoch: 6| Step: 6
Training loss: 1.9077417850494385
Validation loss: 2.002337150676276

Epoch: 6| Step: 7
Training loss: 2.2398362159729004
Validation loss: 1.9739635554693078

Epoch: 6| Step: 8
Training loss: 1.970394253730774
Validation loss: 1.9923775580621534

Epoch: 6| Step: 9
Training loss: 2.702582836151123
Validation loss: 2.0110887635138726

Epoch: 6| Step: 10
Training loss: 2.0035126209259033
Validation loss: 1.9707227112144552

Epoch: 6| Step: 11
Training loss: 2.3315157890319824
Validation loss: 1.975088604034916

Epoch: 6| Step: 12
Training loss: 2.4938323497772217
Validation loss: 2.015348511357461

Epoch: 6| Step: 13
Training loss: 2.0242021083831787
Validation loss: 1.9690455147015151

Epoch: 65| Step: 0
Training loss: 1.8685380220413208
Validation loss: 1.978913773772537

Epoch: 6| Step: 1
Training loss: 2.111874580383301
Validation loss: 2.0044263537212084

Epoch: 6| Step: 2
Training loss: 2.269975423812866
Validation loss: 2.0030578041589386

Epoch: 6| Step: 3
Training loss: 1.9974355697631836
Validation loss: 1.9821076803309943

Epoch: 6| Step: 4
Training loss: 2.4681997299194336
Validation loss: 2.0269681176831646

Epoch: 6| Step: 5
Training loss: 1.985412836074829
Validation loss: 1.9707449405424056

Epoch: 6| Step: 6
Training loss: 2.833702564239502
Validation loss: 1.9893344499731576

Epoch: 6| Step: 7
Training loss: 1.5972776412963867
Validation loss: 1.9961061195660663

Epoch: 6| Step: 8
Training loss: 2.7820849418640137
Validation loss: 2.00905942404142

Epoch: 6| Step: 9
Training loss: 2.3224730491638184
Validation loss: 1.9975217555158882

Epoch: 6| Step: 10
Training loss: 2.932011127471924
Validation loss: 2.0036732291662567

Epoch: 6| Step: 11
Training loss: 2.421613931655884
Validation loss: 1.9904009872867214

Epoch: 6| Step: 12
Training loss: 2.128917694091797
Validation loss: 1.9972685870303903

Epoch: 6| Step: 13
Training loss: 2.0518808364868164
Validation loss: 2.0078009072170464

Epoch: 66| Step: 0
Training loss: 1.892105221748352
Validation loss: 1.9826147697305168

Epoch: 6| Step: 1
Training loss: 2.500885009765625
Validation loss: 2.0081831447539793

Epoch: 6| Step: 2
Training loss: 2.3824148178100586
Validation loss: 2.0297808698428574

Epoch: 6| Step: 3
Training loss: 2.343425750732422
Validation loss: 1.9726623950466033

Epoch: 6| Step: 4
Training loss: 2.366260528564453
Validation loss: 2.007679549596643

Epoch: 6| Step: 5
Training loss: 2.0211944580078125
Validation loss: 1.99466876317096

Epoch: 6| Step: 6
Training loss: 2.43325138092041
Validation loss: 1.9850740253284413

Epoch: 6| Step: 7
Training loss: 3.2467708587646484
Validation loss: 2.0093169545614593

Epoch: 6| Step: 8
Training loss: 1.9398037195205688
Validation loss: 1.9761778641772527

Epoch: 6| Step: 9
Training loss: 1.5936336517333984
Validation loss: 2.0310386534660094

Epoch: 6| Step: 10
Training loss: 2.8481969833374023
Validation loss: 1.9922361732811056

Epoch: 6| Step: 11
Training loss: 2.153278350830078
Validation loss: 2.02883969583819

Epoch: 6| Step: 12
Training loss: 2.2058370113372803
Validation loss: 1.9995622750251525

Epoch: 6| Step: 13
Training loss: 1.5123205184936523
Validation loss: 2.00801041049342

Epoch: 67| Step: 0
Training loss: 1.729721188545227
Validation loss: 2.015117310708569

Epoch: 6| Step: 1
Training loss: 2.2221012115478516
Validation loss: 2.006233076895437

Epoch: 6| Step: 2
Training loss: 2.4809908866882324
Validation loss: 2.0339724889365574

Epoch: 6| Step: 3
Training loss: 2.240098237991333
Validation loss: 2.029415771525393

Epoch: 6| Step: 4
Training loss: 2.9827446937561035
Validation loss: 2.024406499760125

Epoch: 6| Step: 5
Training loss: 3.0346288681030273
Validation loss: 2.012279043915451

Epoch: 6| Step: 6
Training loss: 2.156437873840332
Validation loss: 2.008730797357457

Epoch: 6| Step: 7
Training loss: 2.5392532348632812
Validation loss: 2.0245213021514235

Epoch: 6| Step: 8
Training loss: 1.9753788709640503
Validation loss: 2.028535459631233

Epoch: 6| Step: 9
Training loss: 2.061544418334961
Validation loss: 2.0029992570159254

Epoch: 6| Step: 10
Training loss: 2.0242598056793213
Validation loss: 2.025473303692315

Epoch: 6| Step: 11
Training loss: 1.9475924968719482
Validation loss: 2.0064777917759393

Epoch: 6| Step: 12
Training loss: 1.9180232286453247
Validation loss: 2.0233472034495366

Epoch: 6| Step: 13
Training loss: 2.4934511184692383
Validation loss: 1.9931824489306378

Epoch: 68| Step: 0
Training loss: 3.268008232116699
Validation loss: 1.989173577677819

Epoch: 6| Step: 1
Training loss: 2.2887113094329834
Validation loss: 1.9972533820777811

Epoch: 6| Step: 2
Training loss: 1.7545278072357178
Validation loss: 1.9989431827299056

Epoch: 6| Step: 3
Training loss: 2.6168534755706787
Validation loss: 1.9952807554634668

Epoch: 6| Step: 4
Training loss: 2.5840249061584473
Validation loss: 2.0106143874506794

Epoch: 6| Step: 5
Training loss: 2.047316789627075
Validation loss: 2.0028142967531757

Epoch: 6| Step: 6
Training loss: 1.3743531703948975
Validation loss: 1.9925748917364305

Epoch: 6| Step: 7
Training loss: 2.432713508605957
Validation loss: 2.0017746097298077

Epoch: 6| Step: 8
Training loss: 2.2990055084228516
Validation loss: 2.0109105315259708

Epoch: 6| Step: 9
Training loss: 2.0181140899658203
Validation loss: 1.9944131361540927

Epoch: 6| Step: 10
Training loss: 2.1737003326416016
Validation loss: 2.022494831392842

Epoch: 6| Step: 11
Training loss: 2.350104570388794
Validation loss: 2.0133990959454606

Epoch: 6| Step: 12
Training loss: 2.552387237548828
Validation loss: 2.0032741356921453

Epoch: 6| Step: 13
Training loss: 1.761753797531128
Validation loss: 2.027882558043285

Epoch: 69| Step: 0
Training loss: 2.459588050842285
Validation loss: 2.0331062129748765

Epoch: 6| Step: 1
Training loss: 1.4870857000350952
Validation loss: 1.999554951985677

Epoch: 6| Step: 2
Training loss: 2.591726779937744
Validation loss: 1.9967522146881267

Epoch: 6| Step: 3
Training loss: 2.2296130657196045
Validation loss: 1.988227326382873

Epoch: 6| Step: 4
Training loss: 2.117788791656494
Validation loss: 1.9545036772246003

Epoch: 6| Step: 5
Training loss: 2.1888508796691895
Validation loss: 1.982363252229588

Epoch: 6| Step: 6
Training loss: 1.6834348440170288
Validation loss: 1.9891159034544421

Epoch: 6| Step: 7
Training loss: 3.074849843978882
Validation loss: 2.0131932971298054

Epoch: 6| Step: 8
Training loss: 2.766197919845581
Validation loss: 1.980792099429715

Epoch: 6| Step: 9
Training loss: 1.8805944919586182
Validation loss: 1.9686501872154973

Epoch: 6| Step: 10
Training loss: 1.6592097282409668
Validation loss: 1.9891537953448553

Epoch: 6| Step: 11
Training loss: 2.288518190383911
Validation loss: 1.97350739407283

Epoch: 6| Step: 12
Training loss: 2.773686647415161
Validation loss: 1.9914623921917332

Epoch: 6| Step: 13
Training loss: 2.44711971282959
Validation loss: 2.0001386468128493

Epoch: 70| Step: 0
Training loss: 2.137287139892578
Validation loss: 1.995609850011846

Epoch: 6| Step: 1
Training loss: 2.0948646068573
Validation loss: 1.98671854055056

Epoch: 6| Step: 2
Training loss: 1.7009341716766357
Validation loss: 2.0033539533615112

Epoch: 6| Step: 3
Training loss: 2.579888343811035
Validation loss: 2.0191672886571577

Epoch: 6| Step: 4
Training loss: 1.461547613143921
Validation loss: 1.9811071567637946

Epoch: 6| Step: 5
Training loss: 2.596984624862671
Validation loss: 1.977594643510798

Epoch: 6| Step: 6
Training loss: 2.426255464553833
Validation loss: 2.0066353787658033

Epoch: 6| Step: 7
Training loss: 2.5778980255126953
Validation loss: 2.0263441749798354

Epoch: 6| Step: 8
Training loss: 2.271047592163086
Validation loss: 1.9934662234398626

Epoch: 6| Step: 9
Training loss: 1.5651295185089111
Validation loss: 2.018475583804551

Epoch: 6| Step: 10
Training loss: 2.1588752269744873
Validation loss: 2.0140420570168445

Epoch: 6| Step: 11
Training loss: 3.218975067138672
Validation loss: 1.993807610645089

Epoch: 6| Step: 12
Training loss: 2.284332752227783
Validation loss: 1.9912413909871092

Epoch: 6| Step: 13
Training loss: 2.2899527549743652
Validation loss: 2.013041978241295

Epoch: 71| Step: 0
Training loss: 2.0557589530944824
Validation loss: 1.9884490197704685

Epoch: 6| Step: 1
Training loss: 1.9122086763381958
Validation loss: 1.9960476057503813

Epoch: 6| Step: 2
Training loss: 2.0244975090026855
Validation loss: 1.998464548459617

Epoch: 6| Step: 3
Training loss: 2.6467204093933105
Validation loss: 1.9881763919707267

Epoch: 6| Step: 4
Training loss: 2.739065170288086
Validation loss: 2.004566736118768

Epoch: 6| Step: 5
Training loss: 2.666372060775757
Validation loss: 1.9952384925657702

Epoch: 6| Step: 6
Training loss: 2.2138116359710693
Validation loss: 2.0222432075008268

Epoch: 6| Step: 7
Training loss: 2.8410091400146484
Validation loss: 2.001745859781901

Epoch: 6| Step: 8
Training loss: 2.286956548690796
Validation loss: 1.9825859454370314

Epoch: 6| Step: 9
Training loss: 2.1936874389648438
Validation loss: 2.0022835834051973

Epoch: 6| Step: 10
Training loss: 2.241934061050415
Validation loss: 1.99350102614331

Epoch: 6| Step: 11
Training loss: 2.0964457988739014
Validation loss: 2.024122615014353

Epoch: 6| Step: 12
Training loss: 1.6799315214157104
Validation loss: 2.0252564671219035

Epoch: 6| Step: 13
Training loss: 2.275413990020752
Validation loss: 2.0112635576596825

Epoch: 72| Step: 0
Training loss: 2.4547524452209473
Validation loss: 2.007865503270139

Epoch: 6| Step: 1
Training loss: 2.158595085144043
Validation loss: 2.0308081129545807

Epoch: 6| Step: 2
Training loss: 1.9602110385894775
Validation loss: 2.0060633228671167

Epoch: 6| Step: 3
Training loss: 2.1481635570526123
Validation loss: 2.0142509360467233

Epoch: 6| Step: 4
Training loss: 2.2097690105438232
Validation loss: 2.003287079513714

Epoch: 6| Step: 5
Training loss: 2.976071834564209
Validation loss: 2.036001282353555

Epoch: 6| Step: 6
Training loss: 2.0600383281707764
Validation loss: 2.003022870709819

Epoch: 6| Step: 7
Training loss: 1.9387297630310059
Validation loss: 2.017012475639261

Epoch: 6| Step: 8
Training loss: 2.1562986373901367
Validation loss: 2.026028751045145

Epoch: 6| Step: 9
Training loss: 2.512385368347168
Validation loss: 2.0273901954773934

Epoch: 6| Step: 10
Training loss: 1.8934571743011475
Validation loss: 2.01856404735196

Epoch: 6| Step: 11
Training loss: 2.0346457958221436
Validation loss: 2.025957624117533

Epoch: 6| Step: 12
Training loss: 2.5132815837860107
Validation loss: 2.0318707291797926

Epoch: 6| Step: 13
Training loss: 2.813528060913086
Validation loss: 1.9875364534316524

Epoch: 73| Step: 0
Training loss: 1.8676300048828125
Validation loss: 2.011803598814113

Epoch: 6| Step: 1
Training loss: 2.2794361114501953
Validation loss: 2.0414521886456396

Epoch: 6| Step: 2
Training loss: 2.710253953933716
Validation loss: 2.0614452387696955

Epoch: 6| Step: 3
Training loss: 2.1663990020751953
Validation loss: 2.026835281361816

Epoch: 6| Step: 4
Training loss: 2.5248560905456543
Validation loss: 2.049192782371275

Epoch: 6| Step: 5
Training loss: 2.723201274871826
Validation loss: 2.0398485378552507

Epoch: 6| Step: 6
Training loss: 2.296177864074707
Validation loss: 2.0674081515240412

Epoch: 6| Step: 7
Training loss: 2.21213698387146
Validation loss: 2.0404258979264127

Epoch: 6| Step: 8
Training loss: 2.431797742843628
Validation loss: 2.0120645953762915

Epoch: 6| Step: 9
Training loss: 1.9239202737808228
Validation loss: 2.0272237972546647

Epoch: 6| Step: 10
Training loss: 1.6742260456085205
Validation loss: 2.0095576393988823

Epoch: 6| Step: 11
Training loss: 1.7175025939941406
Validation loss: 2.017025996279973

Epoch: 6| Step: 12
Training loss: 2.815783977508545
Validation loss: 2.026967910028273

Epoch: 6| Step: 13
Training loss: 2.17934250831604
Validation loss: 2.003342092678111

Epoch: 74| Step: 0
Training loss: 2.132514238357544
Validation loss: 1.9877979729765205

Epoch: 6| Step: 1
Training loss: 1.8847877979278564
Validation loss: 2.037829073526526

Epoch: 6| Step: 2
Training loss: 2.0874218940734863
Validation loss: 1.992235537498228

Epoch: 6| Step: 3
Training loss: 2.1365551948547363
Validation loss: 2.0325134979781283

Epoch: 6| Step: 4
Training loss: 2.768948554992676
Validation loss: 2.0407250670976538

Epoch: 6| Step: 5
Training loss: 2.287914752960205
Validation loss: 2.024110068557083

Epoch: 6| Step: 6
Training loss: 2.5898141860961914
Validation loss: 2.0075631526208695

Epoch: 6| Step: 7
Training loss: 1.7763999700546265
Validation loss: 2.052156807273947

Epoch: 6| Step: 8
Training loss: 1.75844144821167
Validation loss: 2.0347660664589173

Epoch: 6| Step: 9
Training loss: 2.805583953857422
Validation loss: 2.0418321189060005

Epoch: 6| Step: 10
Training loss: 2.371771812438965
Validation loss: 2.027353773834885

Epoch: 6| Step: 11
Training loss: 2.236166000366211
Validation loss: 2.022467477347261

Epoch: 6| Step: 12
Training loss: 2.3474016189575195
Validation loss: 2.0078839332826677

Epoch: 6| Step: 13
Training loss: 2.393117666244507
Validation loss: 1.9836798175688712

Epoch: 75| Step: 0
Training loss: 2.3114094734191895
Validation loss: 2.0023868083953857

Epoch: 6| Step: 1
Training loss: 2.458359718322754
Validation loss: 1.9756098998490201

Epoch: 6| Step: 2
Training loss: 2.5978713035583496
Validation loss: 2.0302332447421167

Epoch: 6| Step: 3
Training loss: 2.9276633262634277
Validation loss: 2.009141381068896

Epoch: 6| Step: 4
Training loss: 2.748295307159424
Validation loss: 2.0385674763751287

Epoch: 6| Step: 5
Training loss: 1.6476017236709595
Validation loss: 2.0225331501294206

Epoch: 6| Step: 6
Training loss: 1.672175407409668
Validation loss: 2.048928222348613

Epoch: 6| Step: 7
Training loss: 2.649348258972168
Validation loss: 2.036594867706299

Epoch: 6| Step: 8
Training loss: 1.9566245079040527
Validation loss: 2.024337436563225

Epoch: 6| Step: 9
Training loss: 1.6170408725738525
Validation loss: 1.9906932538555515

Epoch: 6| Step: 10
Training loss: 2.0989274978637695
Validation loss: 2.013284270481397

Epoch: 6| Step: 11
Training loss: 2.3850061893463135
Validation loss: 2.0054241265020063

Epoch: 6| Step: 12
Training loss: 2.290987491607666
Validation loss: 2.001883009428619

Epoch: 6| Step: 13
Training loss: 2.2084290981292725
Validation loss: 2.0056839860895628

Epoch: 76| Step: 0
Training loss: 2.3896336555480957
Validation loss: 2.0107251187806487

Epoch: 6| Step: 1
Training loss: 2.2195773124694824
Validation loss: 2.02930026413292

Epoch: 6| Step: 2
Training loss: 1.528205156326294
Validation loss: 1.9886568618077103

Epoch: 6| Step: 3
Training loss: 2.0987730026245117
Validation loss: 2.008539302374727

Epoch: 6| Step: 4
Training loss: 2.473522901535034
Validation loss: 1.9956872258135068

Epoch: 6| Step: 5
Training loss: 1.5340602397918701
Validation loss: 2.010620996516238

Epoch: 6| Step: 6
Training loss: 2.4876487255096436
Validation loss: 2.004988416548698

Epoch: 6| Step: 7
Training loss: 2.4916651248931885
Validation loss: 1.9947525519196705

Epoch: 6| Step: 8
Training loss: 2.4636332988739014
Validation loss: 2.0285176564288396

Epoch: 6| Step: 9
Training loss: 2.299588918685913
Validation loss: 2.005334873353281

Epoch: 6| Step: 10
Training loss: 2.1923305988311768
Validation loss: 2.0125390278395785

Epoch: 6| Step: 11
Training loss: 2.3674473762512207
Validation loss: 1.9948769846270162

Epoch: 6| Step: 12
Training loss: 2.2328314781188965
Validation loss: 2.025832510763599

Epoch: 6| Step: 13
Training loss: 2.561739683151245
Validation loss: 2.0371526671994116

Epoch: 77| Step: 0
Training loss: 1.9733879566192627
Validation loss: 1.9885855079979025

Epoch: 6| Step: 1
Training loss: 2.6202552318573
Validation loss: 2.0006891835120415

Epoch: 6| Step: 2
Training loss: 1.6959904432296753
Validation loss: 1.9738198300843597

Epoch: 6| Step: 3
Training loss: 2.595036029815674
Validation loss: 2.0086207082194667

Epoch: 6| Step: 4
Training loss: 2.218914031982422
Validation loss: 2.0122195879618325

Epoch: 6| Step: 5
Training loss: 2.0019755363464355
Validation loss: 1.9970086184881066

Epoch: 6| Step: 6
Training loss: 2.5883102416992188
Validation loss: 2.0082441376101587

Epoch: 6| Step: 7
Training loss: 2.1717371940612793
Validation loss: 2.018515243325182

Epoch: 6| Step: 8
Training loss: 2.51975679397583
Validation loss: 1.9945733431846864

Epoch: 6| Step: 9
Training loss: 2.0963711738586426
Validation loss: 1.9973860991898404

Epoch: 6| Step: 10
Training loss: 2.1588973999023438
Validation loss: 1.9781896914205244

Epoch: 6| Step: 11
Training loss: 2.979386806488037
Validation loss: 1.989579318672098

Epoch: 6| Step: 12
Training loss: 1.6956677436828613
Validation loss: 2.0231112510927263

Epoch: 6| Step: 13
Training loss: 2.546250343322754
Validation loss: 1.9968220418499363

Epoch: 78| Step: 0
Training loss: 2.3916125297546387
Validation loss: 1.9961481504542853

Epoch: 6| Step: 1
Training loss: 2.166259765625
Validation loss: 2.029006104315481

Epoch: 6| Step: 2
Training loss: 2.364441394805908
Validation loss: 2.0024683526767197

Epoch: 6| Step: 3
Training loss: 2.674806594848633
Validation loss: 1.9992227041593162

Epoch: 6| Step: 4
Training loss: 2.972414016723633
Validation loss: 1.9928417385265391

Epoch: 6| Step: 5
Training loss: 1.3386775255203247
Validation loss: 2.0189017506055933

Epoch: 6| Step: 6
Training loss: 2.0674681663513184
Validation loss: 2.0363219720061108

Epoch: 6| Step: 7
Training loss: 1.5292448997497559
Validation loss: 2.001308412962062

Epoch: 6| Step: 8
Training loss: 2.250610113143921
Validation loss: 2.0062820808861845

Epoch: 6| Step: 9
Training loss: 2.2932348251342773
Validation loss: 1.9963418565770632

Epoch: 6| Step: 10
Training loss: 2.638509511947632
Validation loss: 2.0111776192982993

Epoch: 6| Step: 11
Training loss: 2.3125414848327637
Validation loss: 1.995458085049865

Epoch: 6| Step: 12
Training loss: 1.990048885345459
Validation loss: 1.9883822036045853

Epoch: 6| Step: 13
Training loss: 2.417495012283325
Validation loss: 2.0087081578470047

Epoch: 79| Step: 0
Training loss: 1.500606656074524
Validation loss: 2.0345449037449335

Epoch: 6| Step: 1
Training loss: 1.9937832355499268
Validation loss: 2.0145664843179847

Epoch: 6| Step: 2
Training loss: 3.0405020713806152
Validation loss: 2.0004486114748063

Epoch: 6| Step: 3
Training loss: 2.286080837249756
Validation loss: 2.027973444231095

Epoch: 6| Step: 4
Training loss: 2.2006208896636963
Validation loss: 2.046125900360846

Epoch: 6| Step: 5
Training loss: 2.8323166370391846
Validation loss: 1.989072177999763

Epoch: 6| Step: 6
Training loss: 2.131235122680664
Validation loss: 2.029638986433706

Epoch: 6| Step: 7
Training loss: 1.7361018657684326
Validation loss: 2.0132519955276162

Epoch: 6| Step: 8
Training loss: 2.3311803340911865
Validation loss: 2.025873948169011

Epoch: 6| Step: 9
Training loss: 2.1385116577148438
Validation loss: 2.0134893873686432

Epoch: 6| Step: 10
Training loss: 2.348198652267456
Validation loss: 1.9952516119967225

Epoch: 6| Step: 11
Training loss: 2.4327569007873535
Validation loss: 2.004031330026606

Epoch: 6| Step: 12
Training loss: 2.27225923538208
Validation loss: 1.9863632981495192

Epoch: 6| Step: 13
Training loss: 1.7288658618927002
Validation loss: 2.0189588146824993

Epoch: 80| Step: 0
Training loss: 2.239927291870117
Validation loss: 1.9991785633948542

Epoch: 6| Step: 1
Training loss: 2.9498186111450195
Validation loss: 2.057538910578656

Epoch: 6| Step: 2
Training loss: 1.8695988655090332
Validation loss: 2.0114000715235227

Epoch: 6| Step: 3
Training loss: 2.292529582977295
Validation loss: 2.055754469287011

Epoch: 6| Step: 4
Training loss: 2.8993592262268066
Validation loss: 2.018476447751445

Epoch: 6| Step: 5
Training loss: 1.7063772678375244
Validation loss: 2.017566324562155

Epoch: 6| Step: 6
Training loss: 2.1271252632141113
Validation loss: 2.015416710607467

Epoch: 6| Step: 7
Training loss: 2.088804244995117
Validation loss: 1.9928916885006813

Epoch: 6| Step: 8
Training loss: 2.5530991554260254
Validation loss: 2.0026705470136417

Epoch: 6| Step: 9
Training loss: 1.8341290950775146
Validation loss: 2.006905391652097

Epoch: 6| Step: 10
Training loss: 3.0006766319274902
Validation loss: 2.0171990420228694

Epoch: 6| Step: 11
Training loss: 2.228508472442627
Validation loss: 1.9841029272284558

Epoch: 6| Step: 12
Training loss: 2.002791166305542
Validation loss: 1.9856530274114301

Epoch: 6| Step: 13
Training loss: 0.9676963090896606
Validation loss: 2.027842919031779

Epoch: 81| Step: 0
Training loss: 2.5871498584747314
Validation loss: 1.9994559403388732

Epoch: 6| Step: 1
Training loss: 1.877107858657837
Validation loss: 2.0495784513411985

Epoch: 6| Step: 2
Training loss: 2.701507568359375
Validation loss: 2.02086143596198

Epoch: 6| Step: 3
Training loss: 2.3689727783203125
Validation loss: 2.02281290741377

Epoch: 6| Step: 4
Training loss: 1.901092290878296
Validation loss: 2.0362184970609603

Epoch: 6| Step: 5
Training loss: 2.1748015880584717
Validation loss: 2.0141680176540087

Epoch: 6| Step: 6
Training loss: 3.071561098098755
Validation loss: 2.0118688306500836

Epoch: 6| Step: 7
Training loss: 1.5774741172790527
Validation loss: 1.9934731811605475

Epoch: 6| Step: 8
Training loss: 2.7058939933776855
Validation loss: 2.0429871748852473

Epoch: 6| Step: 9
Training loss: 1.5331220626831055
Validation loss: 2.0165890032245266

Epoch: 6| Step: 10
Training loss: 1.5427703857421875
Validation loss: 2.0044297300359255

Epoch: 6| Step: 11
Training loss: 2.503513813018799
Validation loss: 2.0136609923455024

Epoch: 6| Step: 12
Training loss: 2.5722265243530273
Validation loss: 1.9885733486503683

Epoch: 6| Step: 13
Training loss: 2.1036787033081055
Validation loss: 2.006619494448426

Epoch: 82| Step: 0
Training loss: 2.226599931716919
Validation loss: 1.9998088139359669

Epoch: 6| Step: 1
Training loss: 2.5382683277130127
Validation loss: 2.0286005517487884

Epoch: 6| Step: 2
Training loss: 1.9865357875823975
Validation loss: 2.0403714256901897

Epoch: 6| Step: 3
Training loss: 2.1598618030548096
Validation loss: 2.017366607983907

Epoch: 6| Step: 4
Training loss: 1.5040408372879028
Validation loss: 2.025319501917849

Epoch: 6| Step: 5
Training loss: 2.5571789741516113
Validation loss: 2.014634822004585

Epoch: 6| Step: 6
Training loss: 2.4302141666412354
Validation loss: 2.026808979690716

Epoch: 6| Step: 7
Training loss: 2.5470082759857178
Validation loss: 2.007114718037267

Epoch: 6| Step: 8
Training loss: 2.7695584297180176
Validation loss: 2.0296674133628927

Epoch: 6| Step: 9
Training loss: 1.882474422454834
Validation loss: 2.04750556330527

Epoch: 6| Step: 10
Training loss: 2.7627596855163574
Validation loss: 2.004621572391961

Epoch: 6| Step: 11
Training loss: 1.9983434677124023
Validation loss: 2.0456150552277923

Epoch: 6| Step: 12
Training loss: 1.9121044874191284
Validation loss: 1.9981877585893035

Epoch: 6| Step: 13
Training loss: 2.1586575508117676
Validation loss: 2.02593885185898

Epoch: 83| Step: 0
Training loss: 2.5534472465515137
Validation loss: 2.003193655321675

Epoch: 6| Step: 1
Training loss: 2.309764862060547
Validation loss: 2.042013704135854

Epoch: 6| Step: 2
Training loss: 2.2401227951049805
Validation loss: 2.0329414388184905

Epoch: 6| Step: 3
Training loss: 1.6575450897216797
Validation loss: 2.0249590950627483

Epoch: 6| Step: 4
Training loss: 2.425881862640381
Validation loss: 2.0175798118755384

Epoch: 6| Step: 5
Training loss: 2.6495132446289062
Validation loss: 2.0339118524264266

Epoch: 6| Step: 6
Training loss: 1.6111027002334595
Validation loss: 2.0544943681327243

Epoch: 6| Step: 7
Training loss: 2.558272123336792
Validation loss: 2.0218426296787877

Epoch: 6| Step: 8
Training loss: 2.693624496459961
Validation loss: 2.014784860354598

Epoch: 6| Step: 9
Training loss: 2.284358024597168
Validation loss: 2.001751853573707

Epoch: 6| Step: 10
Training loss: 1.6535860300064087
Validation loss: 2.0153177861244447

Epoch: 6| Step: 11
Training loss: 2.242070198059082
Validation loss: 2.0228784879048667

Epoch: 6| Step: 12
Training loss: 2.139824867248535
Validation loss: 2.0288338815012286

Epoch: 6| Step: 13
Training loss: 2.4132673740386963
Validation loss: 2.030335021275346

Epoch: 84| Step: 0
Training loss: 2.170764923095703
Validation loss: 1.992559229173968

Epoch: 6| Step: 1
Training loss: 2.88932728767395
Validation loss: 2.0150824259686213

Epoch: 6| Step: 2
Training loss: 2.622147798538208
Validation loss: 1.9893050603969122

Epoch: 6| Step: 3
Training loss: 1.942269206047058
Validation loss: 2.027812998781922

Epoch: 6| Step: 4
Training loss: 2.2341272830963135
Validation loss: 1.9871044517845236

Epoch: 6| Step: 5
Training loss: 1.8877137899398804
Validation loss: 2.015452454167028

Epoch: 6| Step: 6
Training loss: 2.0295770168304443
Validation loss: 2.002411516763831

Epoch: 6| Step: 7
Training loss: 3.007246971130371
Validation loss: 1.976317907533338

Epoch: 6| Step: 8
Training loss: 2.2008883953094482
Validation loss: 2.0014161345779256

Epoch: 6| Step: 9
Training loss: 2.363764762878418
Validation loss: 1.9946496179026942

Epoch: 6| Step: 10
Training loss: 2.213435173034668
Validation loss: 1.9992696098102036

Epoch: 6| Step: 11
Training loss: 1.806567668914795
Validation loss: 2.0187748401395735

Epoch: 6| Step: 12
Training loss: 1.4250634908676147
Validation loss: 1.9851388790274178

Epoch: 6| Step: 13
Training loss: 2.8029425144195557
Validation loss: 1.984453155148414

Epoch: 85| Step: 0
Training loss: 2.9760184288024902
Validation loss: 1.9999075589641448

Epoch: 6| Step: 1
Training loss: 1.919684648513794
Validation loss: 2.010291834031382

Epoch: 6| Step: 2
Training loss: 2.558960437774658
Validation loss: 2.006059108241912

Epoch: 6| Step: 3
Training loss: 2.297934055328369
Validation loss: 2.019860421457598

Epoch: 6| Step: 4
Training loss: 1.720308780670166
Validation loss: 2.0075939688631284

Epoch: 6| Step: 5
Training loss: 1.9197710752487183
Validation loss: 2.005708356057444

Epoch: 6| Step: 6
Training loss: 2.6125545501708984
Validation loss: 2.001623366468696

Epoch: 6| Step: 7
Training loss: 1.8546013832092285
Validation loss: 1.9983838168523644

Epoch: 6| Step: 8
Training loss: 1.6122949123382568
Validation loss: 2.0051565939380276

Epoch: 6| Step: 9
Training loss: 1.9393694400787354
Validation loss: 2.0012309320511354

Epoch: 6| Step: 10
Training loss: 2.6764307022094727
Validation loss: 2.0285790812584663

Epoch: 6| Step: 11
Training loss: 2.7622315883636475
Validation loss: 2.0461885877834853

Epoch: 6| Step: 12
Training loss: 2.319730520248413
Validation loss: 2.0119678064059188

Epoch: 6| Step: 13
Training loss: 2.2418227195739746
Validation loss: 2.030911645581645

Epoch: 86| Step: 0
Training loss: 2.6133503913879395
Validation loss: 2.0001990461862214

Epoch: 6| Step: 1
Training loss: 2.1714603900909424
Validation loss: 2.017737946202678

Epoch: 6| Step: 2
Training loss: 2.713618040084839
Validation loss: 2.045208902769191

Epoch: 6| Step: 3
Training loss: 1.536363124847412
Validation loss: 2.017974090832536

Epoch: 6| Step: 4
Training loss: 2.2781476974487305
Validation loss: 2.042239610866834

Epoch: 6| Step: 5
Training loss: 3.031864643096924
Validation loss: 2.0204460723425752

Epoch: 6| Step: 6
Training loss: 1.9237449169158936
Validation loss: 2.002837486164544

Epoch: 6| Step: 7
Training loss: 2.210690975189209
Validation loss: 2.029554881075377

Epoch: 6| Step: 8
Training loss: 1.9427664279937744
Validation loss: 2.051604668299357

Epoch: 6| Step: 9
Training loss: 2.1004343032836914
Validation loss: 2.0382687635319208

Epoch: 6| Step: 10
Training loss: 2.1708807945251465
Validation loss: 2.0071977133392007

Epoch: 6| Step: 11
Training loss: 2.4402360916137695
Validation loss: 2.0377957026163735

Epoch: 6| Step: 12
Training loss: 2.0683932304382324
Validation loss: 2.0243165967284993

Epoch: 6| Step: 13
Training loss: 1.9649863243103027
Validation loss: 2.0357234221632763

Epoch: 87| Step: 0
Training loss: 2.946895122528076
Validation loss: 2.0382584910238943

Epoch: 6| Step: 1
Training loss: 1.857384204864502
Validation loss: 2.0386819865113948

Epoch: 6| Step: 2
Training loss: 1.8234435319900513
Validation loss: 2.0625003281460015

Epoch: 6| Step: 3
Training loss: 1.9961049556732178
Validation loss: 2.0503751001050396

Epoch: 6| Step: 4
Training loss: 1.7989883422851562
Validation loss: 2.027567858337074

Epoch: 6| Step: 5
Training loss: 2.1834378242492676
Validation loss: 2.0289275082208778

Epoch: 6| Step: 6
Training loss: 1.7332243919372559
Validation loss: 2.0134290328589817

Epoch: 6| Step: 7
Training loss: 2.056715250015259
Validation loss: 1.9925294409516037

Epoch: 6| Step: 8
Training loss: 2.0995893478393555
Validation loss: 2.0311675199898342

Epoch: 6| Step: 9
Training loss: 2.6721577644348145
Validation loss: 2.0016306984809136

Epoch: 6| Step: 10
Training loss: 2.4975037574768066
Validation loss: 2.007108619136195

Epoch: 6| Step: 11
Training loss: 1.5152727365493774
Validation loss: 2.0289552263034287

Epoch: 6| Step: 12
Training loss: 3.1488447189331055
Validation loss: 2.0173994982114403

Epoch: 6| Step: 13
Training loss: 3.402224063873291
Validation loss: 2.018839077282977

Epoch: 88| Step: 0
Training loss: 2.8167333602905273
Validation loss: 2.022313374345021

Epoch: 6| Step: 1
Training loss: 2.0119261741638184
Validation loss: 1.973524050046039

Epoch: 6| Step: 2
Training loss: 1.8687547445297241
Validation loss: 2.008713568410566

Epoch: 6| Step: 3
Training loss: 1.7893515825271606
Validation loss: 2.0003510162394535

Epoch: 6| Step: 4
Training loss: 2.8061180114746094
Validation loss: 2.0190382875421995

Epoch: 6| Step: 5
Training loss: 1.9801344871520996
Validation loss: 1.9856608670244935

Epoch: 6| Step: 6
Training loss: 2.4476675987243652
Validation loss: 2.0239959839851625

Epoch: 6| Step: 7
Training loss: 2.114306926727295
Validation loss: 1.9982547016553982

Epoch: 6| Step: 8
Training loss: 2.333547353744507
Validation loss: 2.0355708111998854

Epoch: 6| Step: 9
Training loss: 2.605754852294922
Validation loss: 2.026936751539989

Epoch: 6| Step: 10
Training loss: 2.639122247695923
Validation loss: 2.0109155203706477

Epoch: 6| Step: 11
Training loss: 1.5449086427688599
Validation loss: 1.9991290979487921

Epoch: 6| Step: 12
Training loss: 2.0638089179992676
Validation loss: 2.022492024206346

Epoch: 6| Step: 13
Training loss: 2.0894086360931396
Validation loss: 1.9958634607253536

Epoch: 89| Step: 0
Training loss: 2.0235347747802734
Validation loss: 2.032782277753276

Epoch: 6| Step: 1
Training loss: 2.9023313522338867
Validation loss: 2.008708361656435

Epoch: 6| Step: 2
Training loss: 2.2146854400634766
Validation loss: 2.0105136946965287

Epoch: 6| Step: 3
Training loss: 2.5638904571533203
Validation loss: 1.988056840435151

Epoch: 6| Step: 4
Training loss: 2.2295210361480713
Validation loss: 1.993898457096469

Epoch: 6| Step: 5
Training loss: 2.678290605545044
Validation loss: 1.9935641122120682

Epoch: 6| Step: 6
Training loss: 1.4411466121673584
Validation loss: 2.019551251524238

Epoch: 6| Step: 7
Training loss: 1.9336326122283936
Validation loss: 2.0041419536836687

Epoch: 6| Step: 8
Training loss: 2.089967727661133
Validation loss: 2.0187738967198197

Epoch: 6| Step: 9
Training loss: 2.2411975860595703
Validation loss: 2.0153258077559935

Epoch: 6| Step: 10
Training loss: 1.615291714668274
Validation loss: 1.9933341049378919

Epoch: 6| Step: 11
Training loss: 2.9942784309387207
Validation loss: 2.0327320867969143

Epoch: 6| Step: 12
Training loss: 2.3169050216674805
Validation loss: 2.0106380139627764

Epoch: 6| Step: 13
Training loss: 1.9240385293960571
Validation loss: 1.9970356456695064

Epoch: 90| Step: 0
Training loss: 2.942028045654297
Validation loss: 2.0084618432547456

Epoch: 6| Step: 1
Training loss: 1.9578496217727661
Validation loss: 2.0214049508494716

Epoch: 6| Step: 2
Training loss: 1.9719938039779663
Validation loss: 2.0114455017992245

Epoch: 6| Step: 3
Training loss: 2.53324556350708
Validation loss: 2.00978192334534

Epoch: 6| Step: 4
Training loss: 2.0791594982147217
Validation loss: 2.0302838804901286

Epoch: 6| Step: 5
Training loss: 1.8766088485717773
Validation loss: 2.037843673459945

Epoch: 6| Step: 6
Training loss: 2.453704595565796
Validation loss: 2.021829576902492

Epoch: 6| Step: 7
Training loss: 1.8034143447875977
Validation loss: 2.0147225203052646

Epoch: 6| Step: 8
Training loss: 2.714749574661255
Validation loss: 2.004701997644158

Epoch: 6| Step: 9
Training loss: 2.3173251152038574
Validation loss: 1.997633598184073

Epoch: 6| Step: 10
Training loss: 2.207193374633789
Validation loss: 2.0492579590889717

Epoch: 6| Step: 11
Training loss: 2.4202771186828613
Validation loss: 2.0088625249042305

Epoch: 6| Step: 12
Training loss: 1.622687578201294
Validation loss: 1.9914668119081886

Epoch: 6| Step: 13
Training loss: 2.590367317199707
Validation loss: 2.0400735434665473

Epoch: 91| Step: 0
Training loss: 2.327542781829834
Validation loss: 2.016124943251251

Epoch: 6| Step: 1
Training loss: 2.2342753410339355
Validation loss: 2.028993345076038

Epoch: 6| Step: 2
Training loss: 2.341439962387085
Validation loss: 2.0470619432387815

Epoch: 6| Step: 3
Training loss: 1.98030686378479
Validation loss: 2.0175265548049763

Epoch: 6| Step: 4
Training loss: 2.0514349937438965
Validation loss: 2.0260824490618963

Epoch: 6| Step: 5
Training loss: 2.1273679733276367
Validation loss: 2.0113696282909763

Epoch: 6| Step: 6
Training loss: 2.122251033782959
Validation loss: 2.0246353200686875

Epoch: 6| Step: 7
Training loss: 2.790252447128296
Validation loss: 2.038078705469767

Epoch: 6| Step: 8
Training loss: 2.529667854309082
Validation loss: 2.0271121596777313

Epoch: 6| Step: 9
Training loss: 1.7589702606201172
Validation loss: 2.0406652829980336

Epoch: 6| Step: 10
Training loss: 3.216548204421997
Validation loss: 2.0698042531167307

Epoch: 6| Step: 11
Training loss: 2.0640532970428467
Validation loss: 2.0401852669254428

Epoch: 6| Step: 12
Training loss: 1.7934688329696655
Validation loss: 2.032686975694472

Epoch: 6| Step: 13
Training loss: 1.772460699081421
Validation loss: 2.023512189106275

Epoch: 92| Step: 0
Training loss: 2.5595760345458984
Validation loss: 2.028843523353659

Epoch: 6| Step: 1
Training loss: 1.645153522491455
Validation loss: 2.018724795310728

Epoch: 6| Step: 2
Training loss: 1.9239786863327026
Validation loss: 2.0400416979225735

Epoch: 6| Step: 3
Training loss: 1.9734971523284912
Validation loss: 2.017508263229042

Epoch: 6| Step: 4
Training loss: 2.552962064743042
Validation loss: 2.015886711817916

Epoch: 6| Step: 5
Training loss: 2.792816162109375
Validation loss: 2.043119590769532

Epoch: 6| Step: 6
Training loss: 2.254746675491333
Validation loss: 2.01074420380336

Epoch: 6| Step: 7
Training loss: 2.5181102752685547
Validation loss: 2.0090946151364233

Epoch: 6| Step: 8
Training loss: 2.724033832550049
Validation loss: 2.0226809645211823

Epoch: 6| Step: 9
Training loss: 2.056051731109619
Validation loss: 2.011821323825467

Epoch: 6| Step: 10
Training loss: 2.204134225845337
Validation loss: 2.0162020088523946

Epoch: 6| Step: 11
Training loss: 2.32197904586792
Validation loss: 1.980487338958248

Epoch: 6| Step: 12
Training loss: 1.581347942352295
Validation loss: 2.044014028323594

Epoch: 6| Step: 13
Training loss: 2.1244778633117676
Validation loss: 2.01368627753309

Epoch: 93| Step: 0
Training loss: 1.9776586294174194
Validation loss: 1.9913412191534554

Epoch: 6| Step: 1
Training loss: 1.5127339363098145
Validation loss: 2.019741981260238

Epoch: 6| Step: 2
Training loss: 2.2166152000427246
Validation loss: 2.0370948788940266

Epoch: 6| Step: 3
Training loss: 2.0629777908325195
Validation loss: 2.0137172386210453

Epoch: 6| Step: 4
Training loss: 1.8917659521102905
Validation loss: 2.0287122059893865

Epoch: 6| Step: 5
Training loss: 2.4172444343566895
Validation loss: 2.0087585397945937

Epoch: 6| Step: 6
Training loss: 2.225677251815796
Validation loss: 2.020125650590466

Epoch: 6| Step: 7
Training loss: 2.2721877098083496
Validation loss: 2.0119007684851207

Epoch: 6| Step: 8
Training loss: 3.120999813079834
Validation loss: 2.035664341783011

Epoch: 6| Step: 9
Training loss: 2.847583293914795
Validation loss: 2.039929847563467

Epoch: 6| Step: 10
Training loss: 2.013575792312622
Validation loss: 2.017892829833492

Epoch: 6| Step: 11
Training loss: 2.692214250564575
Validation loss: 2.0428308517702165

Epoch: 6| Step: 12
Training loss: 1.7900078296661377
Validation loss: 2.040217402160809

Epoch: 6| Step: 13
Training loss: 1.7615809440612793
Validation loss: 2.014891243750049

Epoch: 94| Step: 0
Training loss: 1.7882061004638672
Validation loss: 2.034681204826601

Epoch: 6| Step: 1
Training loss: 1.652289867401123
Validation loss: 2.0250839738435644

Epoch: 6| Step: 2
Training loss: 2.526935338973999
Validation loss: 2.0078872942155406

Epoch: 6| Step: 3
Training loss: 2.5532100200653076
Validation loss: 2.0442822056431926

Epoch: 6| Step: 4
Training loss: 2.3142945766448975
Validation loss: 2.047714779453893

Epoch: 6| Step: 5
Training loss: 1.7333801984786987
Validation loss: 2.020309066259733

Epoch: 6| Step: 6
Training loss: 2.195335626602173
Validation loss: 2.025187659007247

Epoch: 6| Step: 7
Training loss: 2.555889129638672
Validation loss: 2.0321482073876167

Epoch: 6| Step: 8
Training loss: 2.5206198692321777
Validation loss: 2.021363345525598

Epoch: 6| Step: 9
Training loss: 1.9988598823547363
Validation loss: 2.018671130621305

Epoch: 6| Step: 10
Training loss: 1.680992841720581
Validation loss: 2.0184191247468353

Epoch: 6| Step: 11
Training loss: 2.8028900623321533
Validation loss: 2.0344367950193343

Epoch: 6| Step: 12
Training loss: 2.2539572715759277
Validation loss: 2.0425612695755495

Epoch: 6| Step: 13
Training loss: 2.6212167739868164
Validation loss: 2.0094209294165335

Epoch: 95| Step: 0
Training loss: 1.697407841682434
Validation loss: 2.026147311733615

Epoch: 6| Step: 1
Training loss: 2.6381711959838867
Validation loss: 2.021669413453789

Epoch: 6| Step: 2
Training loss: 1.7395930290222168
Validation loss: 2.0395159157373572

Epoch: 6| Step: 3
Training loss: 1.607264518737793
Validation loss: 2.0132216099769837

Epoch: 6| Step: 4
Training loss: 2.135222911834717
Validation loss: 2.0446606605283675

Epoch: 6| Step: 5
Training loss: 2.167492389678955
Validation loss: 2.0163457496191866

Epoch: 6| Step: 6
Training loss: 2.639411211013794
Validation loss: 2.048728355797388

Epoch: 6| Step: 7
Training loss: 2.6921863555908203
Validation loss: 2.0365993361319266

Epoch: 6| Step: 8
Training loss: 2.7117929458618164
Validation loss: 2.0194666680469306

Epoch: 6| Step: 9
Training loss: 2.422624111175537
Validation loss: 2.049655657942577

Epoch: 6| Step: 10
Training loss: 1.96537446975708
Validation loss: 2.020464235736478

Epoch: 6| Step: 11
Training loss: 2.452575206756592
Validation loss: 2.024200321525656

Epoch: 6| Step: 12
Training loss: 2.0813241004943848
Validation loss: 2.0391030862767208

Epoch: 6| Step: 13
Training loss: 1.7798521518707275
Validation loss: 2.0063492431435535

Epoch: 96| Step: 0
Training loss: 2.955268383026123
Validation loss: 2.035119479702365

Epoch: 6| Step: 1
Training loss: 1.6644878387451172
Validation loss: 2.0537272191816762

Epoch: 6| Step: 2
Training loss: 1.8721095323562622
Validation loss: 2.024016948156459

Epoch: 6| Step: 3
Training loss: 3.1474854946136475
Validation loss: 2.0343398176213747

Epoch: 6| Step: 4
Training loss: 2.4558725357055664
Validation loss: 2.025051669407916

Epoch: 6| Step: 5
Training loss: 1.9217915534973145
Validation loss: 2.037745460387199

Epoch: 6| Step: 6
Training loss: 1.7357831001281738
Validation loss: 2.037532457741358

Epoch: 6| Step: 7
Training loss: 2.16923189163208
Validation loss: 2.0490600280864264

Epoch: 6| Step: 8
Training loss: 1.6655982732772827
Validation loss: 2.0157579529669976

Epoch: 6| Step: 9
Training loss: 2.484376907348633
Validation loss: 2.0345388202257055

Epoch: 6| Step: 10
Training loss: 2.6875362396240234
Validation loss: 2.015427117706627

Epoch: 6| Step: 11
Training loss: 1.3399591445922852
Validation loss: 2.0158669205122095

Epoch: 6| Step: 12
Training loss: 2.692117691040039
Validation loss: 2.0483302377885386

Epoch: 6| Step: 13
Training loss: 2.051657199859619
Validation loss: 2.039931725430232

Epoch: 97| Step: 0
Training loss: 2.1740634441375732
Validation loss: 2.022839347521464

Epoch: 6| Step: 1
Training loss: 2.1064374446868896
Validation loss: 2.0263146354306127

Epoch: 6| Step: 2
Training loss: 2.4763448238372803
Validation loss: 2.005317959734189

Epoch: 6| Step: 3
Training loss: 2.2801389694213867
Validation loss: 2.0093771001344085

Epoch: 6| Step: 4
Training loss: 2.3963537216186523
Validation loss: 2.037128984287221

Epoch: 6| Step: 5
Training loss: 2.3839402198791504
Validation loss: 2.0121727451201408

Epoch: 6| Step: 6
Training loss: 2.0270843505859375
Validation loss: 2.0292771144579818

Epoch: 6| Step: 7
Training loss: 2.3266730308532715
Validation loss: 2.0200268709531395

Epoch: 6| Step: 8
Training loss: 2.345895290374756
Validation loss: 2.0033521998313164

Epoch: 6| Step: 9
Training loss: 1.6697735786437988
Validation loss: 2.0033747790962138

Epoch: 6| Step: 10
Training loss: 2.214992046356201
Validation loss: 1.9995194776083833

Epoch: 6| Step: 11
Training loss: 2.5197649002075195
Validation loss: 2.0049314614265197

Epoch: 6| Step: 12
Training loss: 1.9081910848617554
Validation loss: 2.0385201490053566

Epoch: 6| Step: 13
Training loss: 2.3023338317871094
Validation loss: 2.0336279933170607

Epoch: 98| Step: 0
Training loss: 1.5603333711624146
Validation loss: 2.0196073785904916

Epoch: 6| Step: 1
Training loss: 2.4711899757385254
Validation loss: 2.0349402030309043

Epoch: 6| Step: 2
Training loss: 2.3118810653686523
Validation loss: 1.9997791244137673

Epoch: 6| Step: 3
Training loss: 2.6681718826293945
Validation loss: 1.9972686229213592

Epoch: 6| Step: 4
Training loss: 2.225797653198242
Validation loss: 2.0099496764521443

Epoch: 6| Step: 5
Training loss: 2.190107822418213
Validation loss: 2.026616722024897

Epoch: 6| Step: 6
Training loss: 1.747477412223816
Validation loss: 1.996612359118718

Epoch: 6| Step: 7
Training loss: 1.856135606765747
Validation loss: 2.030913487557442

Epoch: 6| Step: 8
Training loss: 2.216376543045044
Validation loss: 2.025082895832677

Epoch: 6| Step: 9
Training loss: 2.329572916030884
Validation loss: 2.0396261035755114

Epoch: 6| Step: 10
Training loss: 2.1577110290527344
Validation loss: 2.0048031794127597

Epoch: 6| Step: 11
Training loss: 2.413363218307495
Validation loss: 1.9887638732951174

Epoch: 6| Step: 12
Training loss: 2.261014223098755
Validation loss: 2.035922775986374

Epoch: 6| Step: 13
Training loss: 2.9778873920440674
Validation loss: 2.027891133421211

Epoch: 99| Step: 0
Training loss: 2.679063320159912
Validation loss: 2.0287609754070157

Epoch: 6| Step: 1
Training loss: 1.9981966018676758
Validation loss: 2.026990875121086

Epoch: 6| Step: 2
Training loss: 2.391493558883667
Validation loss: 2.0168494293766637

Epoch: 6| Step: 3
Training loss: 2.4495139122009277
Validation loss: 2.0400430951067197

Epoch: 6| Step: 4
Training loss: 1.5374805927276611
Validation loss: 2.0245204253863265

Epoch: 6| Step: 5
Training loss: 2.714040756225586
Validation loss: 2.0598050855821177

Epoch: 6| Step: 6
Training loss: 2.0015392303466797
Validation loss: 2.0548511525636077

Epoch: 6| Step: 7
Training loss: 1.935772180557251
Validation loss: 2.021437100184861

Epoch: 6| Step: 8
Training loss: 2.1228668689727783
Validation loss: 2.0332668442879953

Epoch: 6| Step: 9
Training loss: 1.8111109733581543
Validation loss: 2.007364216671195

Epoch: 6| Step: 10
Training loss: 2.449671745300293
Validation loss: 2.0237271811372493

Epoch: 6| Step: 11
Training loss: 2.427216053009033
Validation loss: 2.0171737619625625

Epoch: 6| Step: 12
Training loss: 1.8674285411834717
Validation loss: 2.0080172272138697

Epoch: 6| Step: 13
Training loss: 2.226699113845825
Validation loss: 2.0252565671038885

Epoch: 100| Step: 0
Training loss: 1.484562635421753
Validation loss: 2.044694418548256

Epoch: 6| Step: 1
Training loss: 2.376608371734619
Validation loss: 2.0133373711698797

Epoch: 6| Step: 2
Training loss: 2.564868450164795
Validation loss: 2.0209170977274575

Epoch: 6| Step: 3
Training loss: 2.9555695056915283
Validation loss: 2.0680443125386394

Epoch: 6| Step: 4
Training loss: 2.2923216819763184
Validation loss: 2.0479647241612917

Epoch: 6| Step: 5
Training loss: 2.0460703372955322
Validation loss: 2.021224465421451

Epoch: 6| Step: 6
Training loss: 2.4325711727142334
Validation loss: 2.0515559257999545

Epoch: 6| Step: 7
Training loss: 1.8853416442871094
Validation loss: 2.0472813870317195

Epoch: 6| Step: 8
Training loss: 2.3404853343963623
Validation loss: 2.0451747384122623

Epoch: 6| Step: 9
Training loss: 2.365562677383423
Validation loss: 2.030922684618222

Epoch: 6| Step: 10
Training loss: 2.227468729019165
Validation loss: 2.0324043381598687

Epoch: 6| Step: 11
Training loss: 2.0726094245910645
Validation loss: 2.039365638968765

Epoch: 6| Step: 12
Training loss: 1.8318569660186768
Validation loss: 2.0262360393360095

Epoch: 6| Step: 13
Training loss: 1.5132331848144531
Validation loss: 2.0294872009626

Epoch: 101| Step: 0
Training loss: 1.9642728567123413
Validation loss: 2.0036220089081795

Epoch: 6| Step: 1
Training loss: 2.417328357696533
Validation loss: 2.0219330877386112

Epoch: 6| Step: 2
Training loss: 1.5911076068878174
Validation loss: 2.0219964647805817

Epoch: 6| Step: 3
Training loss: 2.3963217735290527
Validation loss: 2.0198037880723194

Epoch: 6| Step: 4
Training loss: 2.7913942337036133
Validation loss: 2.0110296587790213

Epoch: 6| Step: 5
Training loss: 2.3115530014038086
Validation loss: 2.031959649055235

Epoch: 6| Step: 6
Training loss: 2.5676608085632324
Validation loss: 2.0043860853359265

Epoch: 6| Step: 7
Training loss: 2.5917811393737793
Validation loss: 2.0215259931420766

Epoch: 6| Step: 8
Training loss: 1.8599812984466553
Validation loss: 2.0167387352194837

Epoch: 6| Step: 9
Training loss: 1.6669058799743652
Validation loss: 2.008036882646622

Epoch: 6| Step: 10
Training loss: 2.5516390800476074
Validation loss: 2.019604249667096

Epoch: 6| Step: 11
Training loss: 1.891247034072876
Validation loss: 1.998489664446923

Epoch: 6| Step: 12
Training loss: 1.7238283157348633
Validation loss: 2.010877675907586

Epoch: 6| Step: 13
Training loss: 2.788332223892212
Validation loss: 2.0226147982382003

Epoch: 102| Step: 0
Training loss: 1.8435004949569702
Validation loss: 1.9968442186232536

Epoch: 6| Step: 1
Training loss: 2.144854784011841
Validation loss: 1.9966363317223006

Epoch: 6| Step: 2
Training loss: 2.6944336891174316
Validation loss: 2.0129456391898533

Epoch: 6| Step: 3
Training loss: 1.8505343198776245
Validation loss: 1.9635832245631883

Epoch: 6| Step: 4
Training loss: 2.390275478363037
Validation loss: 2.0136926353618665

Epoch: 6| Step: 5
Training loss: 2.4436206817626953
Validation loss: 2.0016800741995535

Epoch: 6| Step: 6
Training loss: 2.570073127746582
Validation loss: 2.01237145803308

Epoch: 6| Step: 7
Training loss: 1.9534547328948975
Validation loss: 1.9766773998096425

Epoch: 6| Step: 8
Training loss: 2.057720184326172
Validation loss: 1.9905604559888121

Epoch: 6| Step: 9
Training loss: 1.8042457103729248
Validation loss: 1.9873248005426059

Epoch: 6| Step: 10
Training loss: 2.1850533485412598
Validation loss: 2.0456121993321243

Epoch: 6| Step: 11
Training loss: 1.676013708114624
Validation loss: 2.020017147064209

Epoch: 6| Step: 12
Training loss: 2.6707992553710938
Validation loss: 1.9945656663628035

Epoch: 6| Step: 13
Training loss: 3.1930177211761475
Validation loss: 2.0224714112538162

Epoch: 103| Step: 0
Training loss: 2.1597394943237305
Validation loss: 1.992807501105852

Epoch: 6| Step: 1
Training loss: 2.4822187423706055
Validation loss: 2.023945249536986

Epoch: 6| Step: 2
Training loss: 2.4663548469543457
Validation loss: 1.982229499406712

Epoch: 6| Step: 3
Training loss: 1.8985711336135864
Validation loss: 2.0047248243003764

Epoch: 6| Step: 4
Training loss: 1.8021292686462402
Validation loss: 2.009187365090975

Epoch: 6| Step: 5
Training loss: 2.7409563064575195
Validation loss: 2.0050801077196674

Epoch: 6| Step: 6
Training loss: 2.773627758026123
Validation loss: 2.0129817480682046

Epoch: 6| Step: 7
Training loss: 1.4481055736541748
Validation loss: 2.028332466720253

Epoch: 6| Step: 8
Training loss: 2.496997833251953
Validation loss: 2.0277110171574417

Epoch: 6| Step: 9
Training loss: 2.1705334186553955
Validation loss: 2.0129266554309475

Epoch: 6| Step: 10
Training loss: 1.6112301349639893
Validation loss: 2.0083772879774853

Epoch: 6| Step: 11
Training loss: 2.3399271965026855
Validation loss: 1.992282481603725

Epoch: 6| Step: 12
Training loss: 1.9142838716506958
Validation loss: 2.0023108015778246

Epoch: 6| Step: 13
Training loss: 2.537191390991211
Validation loss: 2.021481938259576

Epoch: 104| Step: 0
Training loss: 3.065030574798584
Validation loss: 2.0126217975411365

Epoch: 6| Step: 1
Training loss: 2.1466243267059326
Validation loss: 2.01967300650894

Epoch: 6| Step: 2
Training loss: 1.6166104078292847
Validation loss: 2.00443148356612

Epoch: 6| Step: 3
Training loss: 1.6879045963287354
Validation loss: 2.0180682264348513

Epoch: 6| Step: 4
Training loss: 1.9801300764083862
Validation loss: 2.0233615944462437

Epoch: 6| Step: 5
Training loss: 2.062131404876709
Validation loss: 2.054202530973701

Epoch: 6| Step: 6
Training loss: 2.3734350204467773
Validation loss: 2.0192544806388115

Epoch: 6| Step: 7
Training loss: 2.051539421081543
Validation loss: 2.0363017000177854

Epoch: 6| Step: 8
Training loss: 2.636234760284424
Validation loss: 2.041214332785658

Epoch: 6| Step: 9
Training loss: 2.4013094902038574
Validation loss: 2.024634835540607

Epoch: 6| Step: 10
Training loss: 2.8079075813293457
Validation loss: 2.019426671407556

Epoch: 6| Step: 11
Training loss: 1.7389507293701172
Validation loss: 2.072191902386245

Epoch: 6| Step: 12
Training loss: 2.14687442779541
Validation loss: 2.037595905283446

Epoch: 6| Step: 13
Training loss: 2.1460185050964355
Validation loss: 2.0510997515852734

Epoch: 105| Step: 0
Training loss: 2.6255199909210205
Validation loss: 2.0286493993574575

Epoch: 6| Step: 1
Training loss: 1.987403392791748
Validation loss: 2.02223192491839

Epoch: 6| Step: 2
Training loss: 2.172612190246582
Validation loss: 2.0357847982837307

Epoch: 6| Step: 3
Training loss: 2.67739200592041
Validation loss: 2.008346417898773

Epoch: 6| Step: 4
Training loss: 2.1543619632720947
Validation loss: 2.016994230208858

Epoch: 6| Step: 5
Training loss: 1.5370101928710938
Validation loss: 2.047863675702003

Epoch: 6| Step: 6
Training loss: 1.8045490980148315
Validation loss: 2.019148924017465

Epoch: 6| Step: 7
Training loss: 2.4041545391082764
Validation loss: 2.0131233020495345

Epoch: 6| Step: 8
Training loss: 1.9329161643981934
Validation loss: 2.0247758165482552

Epoch: 6| Step: 9
Training loss: 2.4266905784606934
Validation loss: 2.0052459957779094

Epoch: 6| Step: 10
Training loss: 1.7771223783493042
Validation loss: 2.0452550585551927

Epoch: 6| Step: 11
Training loss: 2.598142623901367
Validation loss: 2.040002181965818

Epoch: 6| Step: 12
Training loss: 1.7745094299316406
Validation loss: 2.016827301312518

Epoch: 6| Step: 13
Training loss: 3.3150858879089355
Validation loss: 2.0277026237980014

Epoch: 106| Step: 0
Training loss: 1.9757630825042725
Validation loss: 2.0415582477405505

Epoch: 6| Step: 1
Training loss: 2.1699390411376953
Validation loss: 2.0300389028364614

Epoch: 6| Step: 2
Training loss: 2.11466121673584
Validation loss: 2.007967040102969

Epoch: 6| Step: 3
Training loss: 2.118161678314209
Validation loss: 2.0401398392133814

Epoch: 6| Step: 4
Training loss: 2.7874255180358887
Validation loss: 2.0365763736027542

Epoch: 6| Step: 5
Training loss: 2.361628532409668
Validation loss: 2.026228230486634

Epoch: 6| Step: 6
Training loss: 2.162076950073242
Validation loss: 2.004927585201879

Epoch: 6| Step: 7
Training loss: 2.1013920307159424
Validation loss: 2.0358988726010887

Epoch: 6| Step: 8
Training loss: 2.194788932800293
Validation loss: 2.0446285983567596

Epoch: 6| Step: 9
Training loss: 2.767655849456787
Validation loss: 2.0746221452630977

Epoch: 6| Step: 10
Training loss: 2.2110958099365234
Validation loss: 2.044632251544665

Epoch: 6| Step: 11
Training loss: 1.5740339756011963
Validation loss: 2.030157971125777

Epoch: 6| Step: 12
Training loss: 2.434814691543579
Validation loss: 2.0473281183550434

Epoch: 6| Step: 13
Training loss: 1.784483551979065
Validation loss: 2.043246284607918

Epoch: 107| Step: 0
Training loss: 2.241398334503174
Validation loss: 2.0496679864903933

Epoch: 6| Step: 1
Training loss: 2.1613848209381104
Validation loss: 2.0650126293141353

Epoch: 6| Step: 2
Training loss: 2.7128794193267822
Validation loss: 2.0386557732858965

Epoch: 6| Step: 3
Training loss: 2.8733696937561035
Validation loss: 2.0503360814945673

Epoch: 6| Step: 4
Training loss: 2.0046162605285645
Validation loss: 2.027000460573422

Epoch: 6| Step: 5
Training loss: 1.544658899307251
Validation loss: 2.0323591847573557

Epoch: 6| Step: 6
Training loss: 1.9457108974456787
Validation loss: 2.0126791051639024

Epoch: 6| Step: 7
Training loss: 2.810389757156372
Validation loss: 2.019417944774833

Epoch: 6| Step: 8
Training loss: 2.199097156524658
Validation loss: 2.022088159797012

Epoch: 6| Step: 9
Training loss: 1.8880958557128906
Validation loss: 2.017628159574283

Epoch: 6| Step: 10
Training loss: 2.7571983337402344
Validation loss: 2.039339109133649

Epoch: 6| Step: 11
Training loss: 1.9536097049713135
Validation loss: 2.0346921554175754

Epoch: 6| Step: 12
Training loss: 1.7095943689346313
Validation loss: 2.0372148354848227

Epoch: 6| Step: 13
Training loss: 2.30234694480896
Validation loss: 2.0027107987352597

Epoch: 108| Step: 0
Training loss: 2.1806349754333496
Validation loss: 2.0010693803910287

Epoch: 6| Step: 1
Training loss: 2.4261975288391113
Validation loss: 2.03258200230137

Epoch: 6| Step: 2
Training loss: 1.3261504173278809
Validation loss: 2.0422950713865218

Epoch: 6| Step: 3
Training loss: 2.777327299118042
Validation loss: 2.0105266712045156

Epoch: 6| Step: 4
Training loss: 2.5090949535369873
Validation loss: 2.0457687326656875

Epoch: 6| Step: 5
Training loss: 1.850543737411499
Validation loss: 2.0419533175806843

Epoch: 6| Step: 6
Training loss: 2.1134676933288574
Validation loss: 2.0529934475498814

Epoch: 6| Step: 7
Training loss: 2.088655948638916
Validation loss: 2.055626251364267

Epoch: 6| Step: 8
Training loss: 2.594614028930664
Validation loss: 2.031551512338782

Epoch: 6| Step: 9
Training loss: 1.8797317743301392
Validation loss: 2.0290496221152683

Epoch: 6| Step: 10
Training loss: 2.481255054473877
Validation loss: 2.0341527872188117

Epoch: 6| Step: 11
Training loss: 2.283811330795288
Validation loss: 2.047957084512198

Epoch: 6| Step: 12
Training loss: 2.0802555084228516
Validation loss: 2.0209727069383026

Epoch: 6| Step: 13
Training loss: 1.9217829704284668
Validation loss: 2.023489873896363

Epoch: 109| Step: 0
Training loss: 2.1563217639923096
Validation loss: 2.0342991223899265

Epoch: 6| Step: 1
Training loss: 2.403573989868164
Validation loss: 2.0442154151137157

Epoch: 6| Step: 2
Training loss: 2.152243137359619
Validation loss: 2.032091604766025

Epoch: 6| Step: 3
Training loss: 2.4200944900512695
Validation loss: 2.0271212516292447

Epoch: 6| Step: 4
Training loss: 2.400175094604492
Validation loss: 2.0359693419548774

Epoch: 6| Step: 5
Training loss: 1.6667492389678955
Validation loss: 2.0515471171307307

Epoch: 6| Step: 6
Training loss: 2.5280203819274902
Validation loss: 2.0058166724379345

Epoch: 6| Step: 7
Training loss: 2.2441887855529785
Validation loss: 2.0340941721393215

Epoch: 6| Step: 8
Training loss: 2.3234057426452637
Validation loss: 2.0298006970395326

Epoch: 6| Step: 9
Training loss: 1.8540098667144775
Validation loss: 2.0327002873984714

Epoch: 6| Step: 10
Training loss: 2.379591941833496
Validation loss: 2.0435699852564

Epoch: 6| Step: 11
Training loss: 2.6058835983276367
Validation loss: 2.030708618061517

Epoch: 6| Step: 12
Training loss: 1.9552719593048096
Validation loss: 2.055989989670374

Epoch: 6| Step: 13
Training loss: 1.3151264190673828
Validation loss: 2.041436505574052

Epoch: 110| Step: 0
Training loss: 2.080233335494995
Validation loss: 2.0420147911194833

Epoch: 6| Step: 1
Training loss: 1.7777564525604248
Validation loss: 2.0332492128495248

Epoch: 6| Step: 2
Training loss: 2.4805140495300293
Validation loss: 2.0558373671706005

Epoch: 6| Step: 3
Training loss: 2.489685297012329
Validation loss: 2.0513272490552676

Epoch: 6| Step: 4
Training loss: 1.2924151420593262
Validation loss: 2.050267360543692

Epoch: 6| Step: 5
Training loss: 2.525285243988037
Validation loss: 2.0440372472168296

Epoch: 6| Step: 6
Training loss: 1.937762975692749
Validation loss: 2.0345030074478476

Epoch: 6| Step: 7
Training loss: 2.6132702827453613
Validation loss: 2.0425643138988043

Epoch: 6| Step: 8
Training loss: 2.4695818424224854
Validation loss: 2.0372866122953353

Epoch: 6| Step: 9
Training loss: 2.0289645195007324
Validation loss: 2.032267521786433

Epoch: 6| Step: 10
Training loss: 2.8929991722106934
Validation loss: 2.0454669819083264

Epoch: 6| Step: 11
Training loss: 2.1612372398376465
Validation loss: 2.0665322798554615

Epoch: 6| Step: 12
Training loss: 2.18440842628479
Validation loss: 2.035152668594032

Epoch: 6| Step: 13
Training loss: 1.4470679759979248
Validation loss: 2.0368850154261433

Epoch: 111| Step: 0
Training loss: 2.109881639480591
Validation loss: 2.044360218509551

Epoch: 6| Step: 1
Training loss: 2.3343164920806885
Validation loss: 2.0495667380671345

Epoch: 6| Step: 2
Training loss: 2.53383731842041
Validation loss: 2.032112311291438

Epoch: 6| Step: 3
Training loss: 1.8078699111938477
Validation loss: 2.0320911843289613

Epoch: 6| Step: 4
Training loss: 2.631662368774414
Validation loss: 2.0394318360154347

Epoch: 6| Step: 5
Training loss: 1.6955456733703613
Validation loss: 2.015568612724222

Epoch: 6| Step: 6
Training loss: 2.2204198837280273
Validation loss: 2.0164663996747745

Epoch: 6| Step: 7
Training loss: 2.7576098442077637
Validation loss: 2.037490101270778

Epoch: 6| Step: 8
Training loss: 2.532313823699951
Validation loss: 2.0232787747536936

Epoch: 6| Step: 9
Training loss: 1.7966026067733765
Validation loss: 2.0076031787421114

Epoch: 6| Step: 10
Training loss: 2.964719772338867
Validation loss: 2.0482827155820784

Epoch: 6| Step: 11
Training loss: 1.580291986465454
Validation loss: 2.027668535068471

Epoch: 6| Step: 12
Training loss: 1.7679450511932373
Validation loss: 2.0443251645693215

Epoch: 6| Step: 13
Training loss: 2.157243013381958
Validation loss: 2.0190259102852113

Epoch: 112| Step: 0
Training loss: 1.5752495527267456
Validation loss: 2.0459306342627412

Epoch: 6| Step: 1
Training loss: 1.981923222541809
Validation loss: 2.0472850543196484

Epoch: 6| Step: 2
Training loss: 2.6520237922668457
Validation loss: 2.0588842181749243

Epoch: 6| Step: 3
Training loss: 2.012761116027832
Validation loss: 2.0181314868311726

Epoch: 6| Step: 4
Training loss: 2.4983959197998047
Validation loss: 2.0272270338509673

Epoch: 6| Step: 5
Training loss: 1.9872281551361084
Validation loss: 2.0112199757688787

Epoch: 6| Step: 6
Training loss: 2.3387298583984375
Validation loss: 1.9697720645576395

Epoch: 6| Step: 7
Training loss: 2.028515338897705
Validation loss: 2.0059550282775716

Epoch: 6| Step: 8
Training loss: 2.481334924697876
Validation loss: 2.01272137190706

Epoch: 6| Step: 9
Training loss: 1.6047093868255615
Validation loss: 2.0294719588372017

Epoch: 6| Step: 10
Training loss: 2.845766067504883
Validation loss: 2.0062294237075315

Epoch: 6| Step: 11
Training loss: 2.258436679840088
Validation loss: 2.001618234060144

Epoch: 6| Step: 12
Training loss: 2.166393280029297
Validation loss: 2.02179802361355

Epoch: 6| Step: 13
Training loss: 2.402341604232788
Validation loss: 2.031026994028399

Epoch: 113| Step: 0
Training loss: 2.518327236175537
Validation loss: 1.988666827960681

Epoch: 6| Step: 1
Training loss: 2.403820037841797
Validation loss: 2.014405542804349

Epoch: 6| Step: 2
Training loss: 2.777034282684326
Validation loss: 2.0397581861865137

Epoch: 6| Step: 3
Training loss: 1.9845300912857056
Validation loss: 2.0386462416700137

Epoch: 6| Step: 4
Training loss: 3.1494710445404053
Validation loss: 2.024650114838795

Epoch: 6| Step: 5
Training loss: 1.6928249597549438
Validation loss: 2.0105275428423317

Epoch: 6| Step: 6
Training loss: 2.16318941116333
Validation loss: 2.019452885914874

Epoch: 6| Step: 7
Training loss: 1.5310312509536743
Validation loss: 2.0383910466265935

Epoch: 6| Step: 8
Training loss: 1.8382840156555176
Validation loss: 2.0426514046166533

Epoch: 6| Step: 9
Training loss: 1.8564321994781494
Validation loss: 1.997329472213663

Epoch: 6| Step: 10
Training loss: 1.7525991201400757
Validation loss: 1.9909359229508268

Epoch: 6| Step: 11
Training loss: 2.266855001449585
Validation loss: 2.036898562985082

Epoch: 6| Step: 12
Training loss: 2.0224335193634033
Validation loss: 2.032835360496275

Epoch: 6| Step: 13
Training loss: 2.8885393142700195
Validation loss: 2.016087808916646

Epoch: 114| Step: 0
Training loss: 2.5551106929779053
Validation loss: 2.016888835096872

Epoch: 6| Step: 1
Training loss: 2.324956178665161
Validation loss: 1.9989548075583674

Epoch: 6| Step: 2
Training loss: 1.7847959995269775
Validation loss: 2.0305795079918316

Epoch: 6| Step: 3
Training loss: 2.555018424987793
Validation loss: 2.010978562857515

Epoch: 6| Step: 4
Training loss: 2.3611397743225098
Validation loss: 2.0394355174033874

Epoch: 6| Step: 5
Training loss: 2.140651226043701
Validation loss: 2.002113831940518

Epoch: 6| Step: 6
Training loss: 2.0757670402526855
Validation loss: 2.016865413676026

Epoch: 6| Step: 7
Training loss: 2.5875091552734375
Validation loss: 2.005285962935417

Epoch: 6| Step: 8
Training loss: 1.5689685344696045
Validation loss: 2.018778076735876

Epoch: 6| Step: 9
Training loss: 1.4873723983764648
Validation loss: 2.0291944780657367

Epoch: 6| Step: 10
Training loss: 2.023754358291626
Validation loss: 2.0096291790726366

Epoch: 6| Step: 11
Training loss: 1.9948720932006836
Validation loss: 2.057701687658987

Epoch: 6| Step: 12
Training loss: 2.7288730144500732
Validation loss: 2.021279142748925

Epoch: 6| Step: 13
Training loss: 2.531917095184326
Validation loss: 2.0444589584104476

Epoch: 115| Step: 0
Training loss: 2.4695863723754883
Validation loss: 2.0335673016886555

Epoch: 6| Step: 1
Training loss: 2.3206865787506104
Validation loss: 1.9914644341314993

Epoch: 6| Step: 2
Training loss: 2.6357641220092773
Validation loss: 2.0395950540419547

Epoch: 6| Step: 3
Training loss: 2.286698341369629
Validation loss: 2.0294200886962233

Epoch: 6| Step: 4
Training loss: 1.756047248840332
Validation loss: 2.014520824596446

Epoch: 6| Step: 5
Training loss: 2.280555248260498
Validation loss: 2.0201374177009828

Epoch: 6| Step: 6
Training loss: 2.1532692909240723
Validation loss: 2.0250847698539816

Epoch: 6| Step: 7
Training loss: 2.173903465270996
Validation loss: 2.0042332192902923

Epoch: 6| Step: 8
Training loss: 1.778516411781311
Validation loss: 2.0432526885822253

Epoch: 6| Step: 9
Training loss: 2.0924787521362305
Validation loss: 2.023074870468468

Epoch: 6| Step: 10
Training loss: 2.300872802734375
Validation loss: 2.0153921163210304

Epoch: 6| Step: 11
Training loss: 1.7658734321594238
Validation loss: 2.0371561076051448

Epoch: 6| Step: 12
Training loss: 2.305351734161377
Validation loss: 2.0421525868036414

Epoch: 6| Step: 13
Training loss: 2.2228732109069824
Validation loss: 2.047215969331803

Epoch: 116| Step: 0
Training loss: 2.359220266342163
Validation loss: 2.0226655531955022

Epoch: 6| Step: 1
Training loss: 1.8410221338272095
Validation loss: 2.0383892200326406

Epoch: 6| Step: 2
Training loss: 1.98373544216156
Validation loss: 2.0605000283128474

Epoch: 6| Step: 3
Training loss: 1.4430873394012451
Validation loss: 2.0648497432790776

Epoch: 6| Step: 4
Training loss: 2.0074350833892822
Validation loss: 2.035997195910382

Epoch: 6| Step: 5
Training loss: 2.2566189765930176
Validation loss: 2.036985728048509

Epoch: 6| Step: 6
Training loss: 2.9492111206054688
Validation loss: 2.052569931553256

Epoch: 6| Step: 7
Training loss: 2.428335189819336
Validation loss: 2.0576848676127772

Epoch: 6| Step: 8
Training loss: 2.5275516510009766
Validation loss: 2.0803194199838946

Epoch: 6| Step: 9
Training loss: 2.4110710620880127
Validation loss: 2.0568128414051507

Epoch: 6| Step: 10
Training loss: 2.6065831184387207
Validation loss: 2.0608005831318517

Epoch: 6| Step: 11
Training loss: 1.911872386932373
Validation loss: 2.059779349193778

Epoch: 6| Step: 12
Training loss: 2.058629035949707
Validation loss: 2.0517958312906246

Epoch: 6| Step: 13
Training loss: 2.053037166595459
Validation loss: 2.065961382722342

Epoch: 117| Step: 0
Training loss: 1.9879755973815918
Validation loss: 2.0335107670035413

Epoch: 6| Step: 1
Training loss: 1.8847935199737549
Validation loss: 2.0406182555742163

Epoch: 6| Step: 2
Training loss: 2.2332606315612793
Validation loss: 2.05522604527012

Epoch: 6| Step: 3
Training loss: 1.8824079036712646
Validation loss: 2.046288260849573

Epoch: 6| Step: 4
Training loss: 2.5132718086242676
Validation loss: 2.054129559506652

Epoch: 6| Step: 5
Training loss: 2.12624192237854
Validation loss: 2.02156525786205

Epoch: 6| Step: 6
Training loss: 1.8439197540283203
Validation loss: 2.03504591859797

Epoch: 6| Step: 7
Training loss: 2.221616506576538
Validation loss: 2.059879647788181

Epoch: 6| Step: 8
Training loss: 2.5234274864196777
Validation loss: 2.0337518415143414

Epoch: 6| Step: 9
Training loss: 2.9129014015197754
Validation loss: 2.037303591287264

Epoch: 6| Step: 10
Training loss: 1.8522963523864746
Validation loss: 2.0356940684779996

Epoch: 6| Step: 11
Training loss: 2.328491687774658
Validation loss: 2.060902786511247

Epoch: 6| Step: 12
Training loss: 2.1393299102783203
Validation loss: 2.027843121559389

Epoch: 6| Step: 13
Training loss: 2.2760441303253174
Validation loss: 2.0371248029893443

Epoch: 118| Step: 0
Training loss: 1.9031380414962769
Validation loss: 2.0498490000283844

Epoch: 6| Step: 1
Training loss: 2.493257522583008
Validation loss: 2.042147200594666

Epoch: 6| Step: 2
Training loss: 2.044312000274658
Validation loss: 2.040123506258893

Epoch: 6| Step: 3
Training loss: 2.158155918121338
Validation loss: 2.0444644881832983

Epoch: 6| Step: 4
Training loss: 2.392070770263672
Validation loss: 2.037655258691439

Epoch: 6| Step: 5
Training loss: 2.4147729873657227
Validation loss: 2.0531323443176928

Epoch: 6| Step: 6
Training loss: 1.4223060607910156
Validation loss: 2.0287615714534635

Epoch: 6| Step: 7
Training loss: 1.3930842876434326
Validation loss: 2.0556052269474154

Epoch: 6| Step: 8
Training loss: 2.3829963207244873
Validation loss: 2.0193873105510587

Epoch: 6| Step: 9
Training loss: 2.9457812309265137
Validation loss: 2.0524808899048836

Epoch: 6| Step: 10
Training loss: 2.714425563812256
Validation loss: 2.033684480574823

Epoch: 6| Step: 11
Training loss: 2.023826837539673
Validation loss: 2.0193911008937384

Epoch: 6| Step: 12
Training loss: 1.985642433166504
Validation loss: 2.04090827895749

Epoch: 6| Step: 13
Training loss: 2.568739175796509
Validation loss: 2.034848274723176

Epoch: 119| Step: 0
Training loss: 2.1101160049438477
Validation loss: 2.007200902508151

Epoch: 6| Step: 1
Training loss: 1.7849533557891846
Validation loss: 2.0388894042661114

Epoch: 6| Step: 2
Training loss: 2.612851142883301
Validation loss: 1.9930050783259894

Epoch: 6| Step: 3
Training loss: 1.8084101676940918
Validation loss: 2.019785511878229

Epoch: 6| Step: 4
Training loss: 2.7060468196868896
Validation loss: 2.02372903977671

Epoch: 6| Step: 5
Training loss: 2.0651159286499023
Validation loss: 2.039326819040442

Epoch: 6| Step: 6
Training loss: 2.6556191444396973
Validation loss: 2.0382602509631904

Epoch: 6| Step: 7
Training loss: 2.2979722023010254
Validation loss: 1.9986750797558857

Epoch: 6| Step: 8
Training loss: 1.7343796491622925
Validation loss: 2.005975854012274

Epoch: 6| Step: 9
Training loss: 2.5577828884124756
Validation loss: 1.9961504333762712

Epoch: 6| Step: 10
Training loss: 1.5781824588775635
Validation loss: 2.0266910470942014

Epoch: 6| Step: 11
Training loss: 2.25583553314209
Validation loss: 2.04122265179952

Epoch: 6| Step: 12
Training loss: 2.205522060394287
Validation loss: 2.0281806607400217

Epoch: 6| Step: 13
Training loss: 2.299687623977661
Validation loss: 2.0126149808206866

Epoch: 120| Step: 0
Training loss: 1.9020346403121948
Validation loss: 1.9781704948794456

Epoch: 6| Step: 1
Training loss: 2.241898536682129
Validation loss: 2.0143234934858096

Epoch: 6| Step: 2
Training loss: 2.015659809112549
Validation loss: 2.0169303160841747

Epoch: 6| Step: 3
Training loss: 2.2291927337646484
Validation loss: 2.027465481911936

Epoch: 6| Step: 4
Training loss: 3.246586561203003
Validation loss: 2.031858123758788

Epoch: 6| Step: 5
Training loss: 1.3980605602264404
Validation loss: 2.018822234164002

Epoch: 6| Step: 6
Training loss: 2.3336730003356934
Validation loss: 2.049472737055953

Epoch: 6| Step: 7
Training loss: 3.030367374420166
Validation loss: 2.0272973814318256

Epoch: 6| Step: 8
Training loss: 2.1145644187927246
Validation loss: 2.0497440420171267

Epoch: 6| Step: 9
Training loss: 2.033271074295044
Validation loss: 2.044111728668213

Epoch: 6| Step: 10
Training loss: 1.448809266090393
Validation loss: 2.0405888172887985

Epoch: 6| Step: 11
Training loss: 1.693180799484253
Validation loss: 2.0490544047406924

Epoch: 6| Step: 12
Training loss: 2.6927037239074707
Validation loss: 2.049920792220741

Epoch: 6| Step: 13
Training loss: 2.3091869354248047
Validation loss: 2.045803341814267

Epoch: 121| Step: 0
Training loss: 2.7078375816345215
Validation loss: 2.015184438356789

Epoch: 6| Step: 1
Training loss: 2.5237417221069336
Validation loss: 2.0311326467862694

Epoch: 6| Step: 2
Training loss: 1.9904569387435913
Validation loss: 2.041609605153402

Epoch: 6| Step: 3
Training loss: 2.69999623298645
Validation loss: 2.04931971334642

Epoch: 6| Step: 4
Training loss: 2.4318134784698486
Validation loss: 2.041604144598848

Epoch: 6| Step: 5
Training loss: 1.3505215644836426
Validation loss: 2.0567603931632092

Epoch: 6| Step: 6
Training loss: 2.218141555786133
Validation loss: 2.0463501637981785

Epoch: 6| Step: 7
Training loss: 1.1803200244903564
Validation loss: 2.029478698648432

Epoch: 6| Step: 8
Training loss: 1.7250139713287354
Validation loss: 2.0428657147192184

Epoch: 6| Step: 9
Training loss: 2.3237345218658447
Validation loss: 2.027880137966525

Epoch: 6| Step: 10
Training loss: 2.5669562816619873
Validation loss: 2.0125752648999615

Epoch: 6| Step: 11
Training loss: 2.815639019012451
Validation loss: 1.9879772458025204

Epoch: 6| Step: 12
Training loss: 1.8684132099151611
Validation loss: 2.0298785522419918

Epoch: 6| Step: 13
Training loss: 2.5942046642303467
Validation loss: 2.023157690161018

Epoch: 122| Step: 0
Training loss: 2.3909831047058105
Validation loss: 2.0254547160158873

Epoch: 6| Step: 1
Training loss: 1.4589354991912842
Validation loss: 2.0113681426612278

Epoch: 6| Step: 2
Training loss: 1.6155741214752197
Validation loss: 2.0524580376122588

Epoch: 6| Step: 3
Training loss: 2.80889892578125
Validation loss: 2.0317185514716694

Epoch: 6| Step: 4
Training loss: 1.795477032661438
Validation loss: 2.01212618812438

Epoch: 6| Step: 5
Training loss: 2.2634451389312744
Validation loss: 2.015444658135855

Epoch: 6| Step: 6
Training loss: 2.3488078117370605
Validation loss: 2.051414417964156

Epoch: 6| Step: 7
Training loss: 2.388278007507324
Validation loss: 2.0346761365090646

Epoch: 6| Step: 8
Training loss: 1.694042444229126
Validation loss: 2.024678450758739

Epoch: 6| Step: 9
Training loss: 2.3414406776428223
Validation loss: 2.054271568534195

Epoch: 6| Step: 10
Training loss: 2.3776822090148926
Validation loss: 2.0373673221116424

Epoch: 6| Step: 11
Training loss: 2.211571216583252
Validation loss: 2.0482751682240474

Epoch: 6| Step: 12
Training loss: 2.823258399963379
Validation loss: 2.0540140982597106

Epoch: 6| Step: 13
Training loss: 1.9157218933105469
Validation loss: 2.0600948590104298

Epoch: 123| Step: 0
Training loss: 2.3914711475372314
Validation loss: 2.047469239081106

Epoch: 6| Step: 1
Training loss: 2.3980536460876465
Validation loss: 2.0294719511462795

Epoch: 6| Step: 2
Training loss: 2.405251979827881
Validation loss: 2.037160014593473

Epoch: 6| Step: 3
Training loss: 2.0871846675872803
Validation loss: 2.030711284247778

Epoch: 6| Step: 4
Training loss: 1.9959406852722168
Validation loss: 2.062660858195315

Epoch: 6| Step: 5
Training loss: 2.756638288497925
Validation loss: 2.0848639280565324

Epoch: 6| Step: 6
Training loss: 2.413483142852783
Validation loss: 2.035218528521958

Epoch: 6| Step: 7
Training loss: 1.686234951019287
Validation loss: 2.0718347667365946

Epoch: 6| Step: 8
Training loss: 1.5579683780670166
Validation loss: 2.0509970777778217

Epoch: 6| Step: 9
Training loss: 2.6728014945983887
Validation loss: 2.0645438906967

Epoch: 6| Step: 10
Training loss: 1.623439908027649
Validation loss: 2.045538038335821

Epoch: 6| Step: 11
Training loss: 2.4597675800323486
Validation loss: 2.067639576491489

Epoch: 6| Step: 12
Training loss: 2.444157600402832
Validation loss: 2.063074673375776

Epoch: 6| Step: 13
Training loss: 1.5082348585128784
Validation loss: 2.046017510916597

Epoch: 124| Step: 0
Training loss: 2.094312906265259
Validation loss: 2.0420294910348873

Epoch: 6| Step: 1
Training loss: 1.6415854692459106
Validation loss: 2.0423149203741424

Epoch: 6| Step: 2
Training loss: 2.561358690261841
Validation loss: 2.0727506042808614

Epoch: 6| Step: 3
Training loss: 2.5624239444732666
Validation loss: 2.0459524623809324

Epoch: 6| Step: 4
Training loss: 2.3925440311431885
Validation loss: 2.0419173497025684

Epoch: 6| Step: 5
Training loss: 1.7696268558502197
Validation loss: 2.0291458740029285

Epoch: 6| Step: 6
Training loss: 2.461085319519043
Validation loss: 2.0017038314573226

Epoch: 6| Step: 7
Training loss: 2.813781261444092
Validation loss: 2.034191918629472

Epoch: 6| Step: 8
Training loss: 1.7143864631652832
Validation loss: 2.0473877537635063

Epoch: 6| Step: 9
Training loss: 2.4913158416748047
Validation loss: 2.0235292655165478

Epoch: 6| Step: 10
Training loss: 2.5697202682495117
Validation loss: 2.0412492316256285

Epoch: 6| Step: 11
Training loss: 1.6578290462493896
Validation loss: 2.0187712382244807

Epoch: 6| Step: 12
Training loss: 1.4909782409667969
Validation loss: 2.0440965108974005

Epoch: 6| Step: 13
Training loss: 2.938349485397339
Validation loss: 2.064395789177187

Epoch: 125| Step: 0
Training loss: 2.281789541244507
Validation loss: 2.0820350006062496

Epoch: 6| Step: 1
Training loss: 2.2175745964050293
Validation loss: 2.057140714378767

Epoch: 6| Step: 2
Training loss: 1.8498965501785278
Validation loss: 2.045378537588222

Epoch: 6| Step: 3
Training loss: 3.184271812438965
Validation loss: 2.046691922731297

Epoch: 6| Step: 4
Training loss: 1.9171351194381714
Validation loss: 2.0590486321398007

Epoch: 6| Step: 5
Training loss: 2.6326370239257812
Validation loss: 2.0369428985862323

Epoch: 6| Step: 6
Training loss: 2.286419153213501
Validation loss: 2.0183507652692896

Epoch: 6| Step: 7
Training loss: 1.6554869413375854
Validation loss: 2.051048892800526

Epoch: 6| Step: 8
Training loss: 1.8994581699371338
Validation loss: 2.0700715049620597

Epoch: 6| Step: 9
Training loss: 1.9516265392303467
Validation loss: 2.0169268308147306

Epoch: 6| Step: 10
Training loss: 2.875962495803833
Validation loss: 2.042204367217197

Epoch: 6| Step: 11
Training loss: 1.5566829442977905
Validation loss: 2.0447273151848906

Epoch: 6| Step: 12
Training loss: 2.4360268115997314
Validation loss: 2.0160976879058348

Epoch: 6| Step: 13
Training loss: 1.327393889427185
Validation loss: 2.0489544125013452

Epoch: 126| Step: 0
Training loss: 2.0385420322418213
Validation loss: 2.0572089674652263

Epoch: 6| Step: 1
Training loss: 2.294614315032959
Validation loss: 2.006542464738251

Epoch: 6| Step: 2
Training loss: 2.470297336578369
Validation loss: 2.069356346643099

Epoch: 6| Step: 3
Training loss: 2.5561561584472656
Validation loss: 2.0142085552215576

Epoch: 6| Step: 4
Training loss: 2.148597240447998
Validation loss: 2.0670331601173646

Epoch: 6| Step: 5
Training loss: 2.801196336746216
Validation loss: 2.037607018665601

Epoch: 6| Step: 6
Training loss: 2.077479839324951
Validation loss: 2.0174265382110432

Epoch: 6| Step: 7
Training loss: 2.161080837249756
Validation loss: 2.01626617165022

Epoch: 6| Step: 8
Training loss: 1.2934298515319824
Validation loss: 2.019798776154877

Epoch: 6| Step: 9
Training loss: 1.4538869857788086
Validation loss: 2.0554147125572286

Epoch: 6| Step: 10
Training loss: 1.9950380325317383
Validation loss: 2.0224791162757465

Epoch: 6| Step: 11
Training loss: 2.5367207527160645
Validation loss: 2.054899151607226

Epoch: 6| Step: 12
Training loss: 2.4228858947753906
Validation loss: 2.0077934624046407

Epoch: 6| Step: 13
Training loss: 2.094834327697754
Validation loss: 2.0200932051545832

Epoch: 127| Step: 0
Training loss: 2.714865207672119
Validation loss: 2.0314278500054472

Epoch: 6| Step: 1
Training loss: 2.4606871604919434
Validation loss: 2.0468438466389975

Epoch: 6| Step: 2
Training loss: 1.5491256713867188
Validation loss: 2.056852376589211

Epoch: 6| Step: 3
Training loss: 2.2652335166931152
Validation loss: 2.028718656109225

Epoch: 6| Step: 4
Training loss: 1.7341598272323608
Validation loss: 2.0493745701287382

Epoch: 6| Step: 5
Training loss: 2.503077507019043
Validation loss: 2.0345153590684295

Epoch: 6| Step: 6
Training loss: 2.8055238723754883
Validation loss: 2.0491383857624506

Epoch: 6| Step: 7
Training loss: 2.168745994567871
Validation loss: 2.0427494689982426

Epoch: 6| Step: 8
Training loss: 1.4052692651748657
Validation loss: 2.0620378935208885

Epoch: 6| Step: 9
Training loss: 2.5575265884399414
Validation loss: 2.015518178222

Epoch: 6| Step: 10
Training loss: 2.160550355911255
Validation loss: 2.0129576934281217

Epoch: 6| Step: 11
Training loss: 1.983323335647583
Validation loss: 2.0189405013156194

Epoch: 6| Step: 12
Training loss: 2.3222010135650635
Validation loss: 2.026710702526954

Epoch: 6| Step: 13
Training loss: 1.6409462690353394
Validation loss: 2.0379748062420915

Epoch: 128| Step: 0
Training loss: 1.829300880432129
Validation loss: 2.0313525071708103

Epoch: 6| Step: 1
Training loss: 1.8253333568572998
Validation loss: 2.0630432392961238

Epoch: 6| Step: 2
Training loss: 1.6850746870040894
Validation loss: 2.0664371341787358

Epoch: 6| Step: 3
Training loss: 2.024397850036621
Validation loss: 2.05697734637927

Epoch: 6| Step: 4
Training loss: 2.8363585472106934
Validation loss: 2.02194595208732

Epoch: 6| Step: 5
Training loss: 2.2024102210998535
Validation loss: 2.061266840145152

Epoch: 6| Step: 6
Training loss: 2.1360526084899902
Validation loss: 2.0282032361594577

Epoch: 6| Step: 7
Training loss: 2.389249324798584
Validation loss: 2.050539457669822

Epoch: 6| Step: 8
Training loss: 2.2240891456604004
Validation loss: 2.0860101997211413

Epoch: 6| Step: 9
Training loss: 2.1914734840393066
Validation loss: 2.049495506030257

Epoch: 6| Step: 10
Training loss: 2.508349895477295
Validation loss: 2.020765032819522

Epoch: 6| Step: 11
Training loss: 2.3886332511901855
Validation loss: 2.0271181111694663

Epoch: 6| Step: 12
Training loss: 1.8438656330108643
Validation loss: 2.046172490683935

Epoch: 6| Step: 13
Training loss: 2.7380409240722656
Validation loss: 2.0319202228259017

Epoch: 129| Step: 0
Training loss: 2.0668551921844482
Validation loss: 2.033737854291034

Epoch: 6| Step: 1
Training loss: 2.323277473449707
Validation loss: 2.065905237710604

Epoch: 6| Step: 2
Training loss: 1.4917542934417725
Validation loss: 2.0503542833430792

Epoch: 6| Step: 3
Training loss: 2.5867085456848145
Validation loss: 2.0520744067366405

Epoch: 6| Step: 4
Training loss: 2.0038232803344727
Validation loss: 2.0746799310048423

Epoch: 6| Step: 5
Training loss: 1.564821481704712
Validation loss: 2.066404929725073

Epoch: 6| Step: 6
Training loss: 2.584409713745117
Validation loss: 2.047733720912728

Epoch: 6| Step: 7
Training loss: 2.614063262939453
Validation loss: 2.016469476043537

Epoch: 6| Step: 8
Training loss: 2.3859362602233887
Validation loss: 2.039781860125962

Epoch: 6| Step: 9
Training loss: 2.27702260017395
Validation loss: 2.0301990970488517

Epoch: 6| Step: 10
Training loss: 2.3956313133239746
Validation loss: 2.0215851645315848

Epoch: 6| Step: 11
Training loss: 2.1818110942840576
Validation loss: 2.031764776475968

Epoch: 6| Step: 12
Training loss: 1.5882915258407593
Validation loss: 2.019491046987554

Epoch: 6| Step: 13
Training loss: 2.1405656337738037
Validation loss: 2.0573382710897796

Epoch: 130| Step: 0
Training loss: 2.182429790496826
Validation loss: 2.074782053629557

Epoch: 6| Step: 1
Training loss: 2.9411098957061768
Validation loss: 2.0494836607287006

Epoch: 6| Step: 2
Training loss: 1.871995449066162
Validation loss: 2.051329243567682

Epoch: 6| Step: 3
Training loss: 2.1681442260742188
Validation loss: 2.0311651358040432

Epoch: 6| Step: 4
Training loss: 1.5426170825958252
Validation loss: 2.0492245215241627

Epoch: 6| Step: 5
Training loss: 2.1869168281555176
Validation loss: 2.035246927251098

Epoch: 6| Step: 6
Training loss: 2.6605048179626465
Validation loss: 2.057721500755638

Epoch: 6| Step: 7
Training loss: 1.953014612197876
Validation loss: 2.0653441541938373

Epoch: 6| Step: 8
Training loss: 1.9607861042022705
Validation loss: 2.043092026505419

Epoch: 6| Step: 9
Training loss: 2.241203784942627
Validation loss: 2.039971907933553

Epoch: 6| Step: 10
Training loss: 2.054370403289795
Validation loss: 2.0606670456547893

Epoch: 6| Step: 11
Training loss: 2.4491584300994873
Validation loss: 2.0337957900057555

Epoch: 6| Step: 12
Training loss: 2.3114771842956543
Validation loss: 2.0667694204597065

Epoch: 6| Step: 13
Training loss: 1.692366361618042
Validation loss: 2.030928110563627

Epoch: 131| Step: 0
Training loss: 1.935722827911377
Validation loss: 2.060016211643014

Epoch: 6| Step: 1
Training loss: 2.067607879638672
Validation loss: 2.027661515820411

Epoch: 6| Step: 2
Training loss: 1.6398231983184814
Validation loss: 2.0086597563118063

Epoch: 6| Step: 3
Training loss: 2.686461925506592
Validation loss: 2.030104661500582

Epoch: 6| Step: 4
Training loss: 2.4887490272521973
Validation loss: 2.0614515940348306

Epoch: 6| Step: 5
Training loss: 2.7042253017425537
Validation loss: 2.0115571316852363

Epoch: 6| Step: 6
Training loss: 1.6492255926132202
Validation loss: 2.059165388025263

Epoch: 6| Step: 7
Training loss: 1.8657902479171753
Validation loss: 2.0199799076203377

Epoch: 6| Step: 8
Training loss: 2.066026449203491
Validation loss: 2.051500940835604

Epoch: 6| Step: 9
Training loss: 1.9707366228103638
Validation loss: 2.0119590400367655

Epoch: 6| Step: 10
Training loss: 2.7312660217285156
Validation loss: 2.0646910257236932

Epoch: 6| Step: 11
Training loss: 2.008805513381958
Validation loss: 2.042215246026234

Epoch: 6| Step: 12
Training loss: 2.251542091369629
Validation loss: 2.028879298958727

Epoch: 6| Step: 13
Training loss: 2.4372332096099854
Validation loss: 2.0126684968189528

Epoch: 132| Step: 0
Training loss: 2.1140007972717285
Validation loss: 2.051260902035621

Epoch: 6| Step: 1
Training loss: 1.548532247543335
Validation loss: 2.0105905584109727

Epoch: 6| Step: 2
Training loss: 1.9764235019683838
Validation loss: 1.9833201387877106

Epoch: 6| Step: 3
Training loss: 2.8604238033294678
Validation loss: 2.0120329985054592

Epoch: 6| Step: 4
Training loss: 2.420647382736206
Validation loss: 2.011613735588648

Epoch: 6| Step: 5
Training loss: 2.1745054721832275
Validation loss: 2.0421416938945813

Epoch: 6| Step: 6
Training loss: 1.6702874898910522
Validation loss: 2.016179087341473

Epoch: 6| Step: 7
Training loss: 2.6025991439819336
Validation loss: 1.9994564748579455

Epoch: 6| Step: 8
Training loss: 2.094959259033203
Validation loss: 2.0259259785375288

Epoch: 6| Step: 9
Training loss: 2.0212316513061523
Validation loss: 2.0240312519893853

Epoch: 6| Step: 10
Training loss: 1.7594202756881714
Validation loss: 2.0410590376905215

Epoch: 6| Step: 11
Training loss: 2.7045676708221436
Validation loss: 2.026935790174751

Epoch: 6| Step: 12
Training loss: 2.7130064964294434
Validation loss: 2.0237915746627317

Epoch: 6| Step: 13
Training loss: 1.61692214012146
Validation loss: 2.0388030775131716

Epoch: 133| Step: 0
Training loss: 2.1900250911712646
Validation loss: 2.04591864924277

Epoch: 6| Step: 1
Training loss: 2.1410326957702637
Validation loss: 2.0432619099975913

Epoch: 6| Step: 2
Training loss: 1.9033691883087158
Validation loss: 2.048801170882358

Epoch: 6| Step: 3
Training loss: 2.963042736053467
Validation loss: 2.086116454934561

Epoch: 6| Step: 4
Training loss: 2.2038731575012207
Validation loss: 2.0399020961535874

Epoch: 6| Step: 5
Training loss: 2.028225898742676
Validation loss: 2.0916030688952376

Epoch: 6| Step: 6
Training loss: 2.29307222366333
Validation loss: 2.0896469803266626

Epoch: 6| Step: 7
Training loss: 1.6826329231262207
Validation loss: 2.0590037120285856

Epoch: 6| Step: 8
Training loss: 1.2966375350952148
Validation loss: 2.0260058115887385

Epoch: 6| Step: 9
Training loss: 2.0746285915374756
Validation loss: 2.0730223091699744

Epoch: 6| Step: 10
Training loss: 2.2453677654266357
Validation loss: 2.068206771727531

Epoch: 6| Step: 11
Training loss: 2.3606035709381104
Validation loss: 2.050968334239016

Epoch: 6| Step: 12
Training loss: 2.127396583557129
Validation loss: 2.067194079840055

Epoch: 6| Step: 13
Training loss: 2.9771792888641357
Validation loss: 2.0579318692607265

Epoch: 134| Step: 0
Training loss: 2.112827777862549
Validation loss: 2.0575553191605436

Epoch: 6| Step: 1
Training loss: 2.4389312267303467
Validation loss: 2.050892009530016

Epoch: 6| Step: 2
Training loss: 2.2643744945526123
Validation loss: 2.0517717715232604

Epoch: 6| Step: 3
Training loss: 1.8617509603500366
Validation loss: 2.064792207492295

Epoch: 6| Step: 4
Training loss: 2.5233829021453857
Validation loss: 2.0325768532291537

Epoch: 6| Step: 5
Training loss: 2.058151960372925
Validation loss: 2.075778994508969

Epoch: 6| Step: 6
Training loss: 1.7929761409759521
Validation loss: 2.032500623374857

Epoch: 6| Step: 7
Training loss: 1.8302364349365234
Validation loss: 2.0234542200642247

Epoch: 6| Step: 8
Training loss: 2.1321632862091064
Validation loss: 2.0241587482472903

Epoch: 6| Step: 9
Training loss: 2.0918116569519043
Validation loss: 2.024415744248257

Epoch: 6| Step: 10
Training loss: 2.2706899642944336
Validation loss: 2.0446765371548232

Epoch: 6| Step: 11
Training loss: 2.593308448791504
Validation loss: 2.0668722198855494

Epoch: 6| Step: 12
Training loss: 2.399899482727051
Validation loss: 2.034727560576572

Epoch: 6| Step: 13
Training loss: 1.616330623626709
Validation loss: 2.0322238181226995

Epoch: 135| Step: 0
Training loss: 2.2871766090393066
Validation loss: 1.997200112189016

Epoch: 6| Step: 1
Training loss: 2.84429931640625
Validation loss: 2.0396066916886197

Epoch: 6| Step: 2
Training loss: 1.575941801071167
Validation loss: 2.0430842304742463

Epoch: 6| Step: 3
Training loss: 1.7677664756774902
Validation loss: 2.0500457722653627

Epoch: 6| Step: 4
Training loss: 2.2508015632629395
Validation loss: 2.0601677868955877

Epoch: 6| Step: 5
Training loss: 2.101621627807617
Validation loss: 2.0818272700873752

Epoch: 6| Step: 6
Training loss: 2.407407522201538
Validation loss: 2.0504283417937574

Epoch: 6| Step: 7
Training loss: 1.6766324043273926
Validation loss: 2.0393760281224407

Epoch: 6| Step: 8
Training loss: 2.3456294536590576
Validation loss: 2.0844357270066456

Epoch: 6| Step: 9
Training loss: 1.6801081895828247
Validation loss: 2.054730708881091

Epoch: 6| Step: 10
Training loss: 2.8021035194396973
Validation loss: 2.0758020929110947

Epoch: 6| Step: 11
Training loss: 2.054405689239502
Validation loss: 2.057100634421072

Epoch: 6| Step: 12
Training loss: 2.241819143295288
Validation loss: 2.068422168813726

Epoch: 6| Step: 13
Training loss: 2.5376152992248535
Validation loss: 2.051894977528562

Epoch: 136| Step: 0
Training loss: 2.048713445663452
Validation loss: 2.0600773390903266

Epoch: 6| Step: 1
Training loss: 1.8434613943099976
Validation loss: 2.0463394785440094

Epoch: 6| Step: 2
Training loss: 2.1776676177978516
Validation loss: 2.036221347829347

Epoch: 6| Step: 3
Training loss: 2.4460129737854004
Validation loss: 2.030628696564705

Epoch: 6| Step: 4
Training loss: 1.5642216205596924
Validation loss: 2.1005879550851803

Epoch: 6| Step: 5
Training loss: 2.0755672454833984
Validation loss: 2.0586755608999603

Epoch: 6| Step: 6
Training loss: 1.8088862895965576
Validation loss: 2.03220695834006

Epoch: 6| Step: 7
Training loss: 1.9274801015853882
Validation loss: 2.034254789352417

Epoch: 6| Step: 8
Training loss: 2.4598007202148438
Validation loss: 2.0586751148264897

Epoch: 6| Step: 9
Training loss: 2.7292978763580322
Validation loss: 2.0276682017951884

Epoch: 6| Step: 10
Training loss: 2.6635892391204834
Validation loss: 2.0577666964582217

Epoch: 6| Step: 11
Training loss: 1.9492907524108887
Validation loss: 2.052182610316943

Epoch: 6| Step: 12
Training loss: 2.302945613861084
Validation loss: 2.0273534495343446

Epoch: 6| Step: 13
Training loss: 2.6078274250030518
Validation loss: 2.019417380773893

Epoch: 137| Step: 0
Training loss: 2.0848851203918457
Validation loss: 2.0206366508237776

Epoch: 6| Step: 1
Training loss: 2.2308363914489746
Validation loss: 2.062708085583102

Epoch: 6| Step: 2
Training loss: 2.3710551261901855
Validation loss: 2.0185405823492233

Epoch: 6| Step: 3
Training loss: 1.8711163997650146
Validation loss: 2.0191495623639835

Epoch: 6| Step: 4
Training loss: 2.2572662830352783
Validation loss: 2.0677862628813712

Epoch: 6| Step: 5
Training loss: 1.817252278327942
Validation loss: 2.0459778616505284

Epoch: 6| Step: 6
Training loss: 2.89342999458313
Validation loss: 2.025641010653588

Epoch: 6| Step: 7
Training loss: 2.48590087890625
Validation loss: 2.0613689768698906

Epoch: 6| Step: 8
Training loss: 1.9656087160110474
Validation loss: 2.0527349864282916

Epoch: 6| Step: 9
Training loss: 2.4063217639923096
Validation loss: 2.03975329091472

Epoch: 6| Step: 10
Training loss: 2.474501609802246
Validation loss: 2.0327845914389497

Epoch: 6| Step: 11
Training loss: 1.6453328132629395
Validation loss: 2.0671574351608113

Epoch: 6| Step: 12
Training loss: 1.0709621906280518
Validation loss: 2.0489373796729633

Epoch: 6| Step: 13
Training loss: 2.7462944984436035
Validation loss: 2.0481240800631944

Epoch: 138| Step: 0
Training loss: 2.4602925777435303
Validation loss: 2.052334103533017

Epoch: 6| Step: 1
Training loss: 2.6699790954589844
Validation loss: 2.0468752871277514

Epoch: 6| Step: 2
Training loss: 1.7441246509552002
Validation loss: 2.0682726444736605

Epoch: 6| Step: 3
Training loss: 1.4997200965881348
Validation loss: 2.058033814994238

Epoch: 6| Step: 4
Training loss: 2.562711477279663
Validation loss: 2.0878842082074893

Epoch: 6| Step: 5
Training loss: 2.634247303009033
Validation loss: 2.0593239235621628

Epoch: 6| Step: 6
Training loss: 2.5650596618652344
Validation loss: 2.0671678602054553

Epoch: 6| Step: 7
Training loss: 2.1613407135009766
Validation loss: 2.0845782269713697

Epoch: 6| Step: 8
Training loss: 1.7838447093963623
Validation loss: 2.0468734284882903

Epoch: 6| Step: 9
Training loss: 2.571746349334717
Validation loss: 2.0588394903367564

Epoch: 6| Step: 10
Training loss: 1.8281276226043701
Validation loss: 2.0402943959800144

Epoch: 6| Step: 11
Training loss: 1.6883001327514648
Validation loss: 2.092808828558973

Epoch: 6| Step: 12
Training loss: 2.300682783126831
Validation loss: 2.0548933141974994

Epoch: 6| Step: 13
Training loss: 1.4930698871612549
Validation loss: 2.0634812026895504

Epoch: 139| Step: 0
Training loss: 1.1035029888153076
Validation loss: 2.0765252228706115

Epoch: 6| Step: 1
Training loss: 2.1708695888519287
Validation loss: 2.059210585009667

Epoch: 6| Step: 2
Training loss: 2.757406234741211
Validation loss: 2.0819363337691112

Epoch: 6| Step: 3
Training loss: 1.4571640491485596
Validation loss: 2.0674586270445134

Epoch: 6| Step: 4
Training loss: 2.4505510330200195
Validation loss: 2.0407033299887054

Epoch: 6| Step: 5
Training loss: 1.4586488008499146
Validation loss: 2.0561529513328307

Epoch: 6| Step: 6
Training loss: 2.8061575889587402
Validation loss: 2.082790428592313

Epoch: 6| Step: 7
Training loss: 2.391592502593994
Validation loss: 2.0825875728361067

Epoch: 6| Step: 8
Training loss: 1.9476406574249268
Validation loss: 2.069854659418906

Epoch: 6| Step: 9
Training loss: 2.0381088256835938
Validation loss: 2.0476154486338296

Epoch: 6| Step: 10
Training loss: 2.593427896499634
Validation loss: 2.0699880892230618

Epoch: 6| Step: 11
Training loss: 2.0064916610717773
Validation loss: 2.021874616222997

Epoch: 6| Step: 12
Training loss: 2.6554408073425293
Validation loss: 2.0908315566278275

Epoch: 6| Step: 13
Training loss: 2.3684043884277344
Validation loss: 2.0676689173585627

Epoch: 140| Step: 0
Training loss: 3.008173942565918
Validation loss: 2.0437234422212005

Epoch: 6| Step: 1
Training loss: 2.232250928878784
Validation loss: 2.0276677480307956

Epoch: 6| Step: 2
Training loss: 2.384460926055908
Validation loss: 2.049003556210508

Epoch: 6| Step: 3
Training loss: 2.1062231063842773
Validation loss: 2.045744667771042

Epoch: 6| Step: 4
Training loss: 1.9389140605926514
Validation loss: 2.029461685047355

Epoch: 6| Step: 5
Training loss: 1.5252118110656738
Validation loss: 2.0328603213833225

Epoch: 6| Step: 6
Training loss: 1.8820347785949707
Validation loss: 2.053044396062051

Epoch: 6| Step: 7
Training loss: 2.1161603927612305
Validation loss: 2.023700266756037

Epoch: 6| Step: 8
Training loss: 2.0325636863708496
Validation loss: 2.002907227444392

Epoch: 6| Step: 9
Training loss: 2.157656669616699
Validation loss: 2.005132959735009

Epoch: 6| Step: 10
Training loss: 2.2566139698028564
Validation loss: 2.019936136020127

Epoch: 6| Step: 11
Training loss: 2.240475654602051
Validation loss: 2.0657357246645036

Epoch: 6| Step: 12
Training loss: 2.263414144515991
Validation loss: 2.0377938952497257

Epoch: 6| Step: 13
Training loss: 2.048551321029663
Validation loss: 2.073581072591966

Epoch: 141| Step: 0
Training loss: 2.0231425762176514
Validation loss: 2.055505939709243

Epoch: 6| Step: 1
Training loss: 1.7345025539398193
Validation loss: 2.044305706536898

Epoch: 6| Step: 2
Training loss: 2.686772108078003
Validation loss: 2.023707200122136

Epoch: 6| Step: 3
Training loss: 1.87736177444458
Validation loss: 2.009831859219459

Epoch: 6| Step: 4
Training loss: 3.3377633094787598
Validation loss: 2.041332673001033

Epoch: 6| Step: 5
Training loss: 1.9447295665740967
Validation loss: 2.0789504461390997

Epoch: 6| Step: 6
Training loss: 1.6087522506713867
Validation loss: 2.0592876531744517

Epoch: 6| Step: 7
Training loss: 2.242918014526367
Validation loss: 2.0557433712866997

Epoch: 6| Step: 8
Training loss: 1.9496711492538452
Validation loss: 2.018906178012971

Epoch: 6| Step: 9
Training loss: 1.6802728176116943
Validation loss: 2.0264968641342653

Epoch: 6| Step: 10
Training loss: 2.5184173583984375
Validation loss: 2.061122671250374

Epoch: 6| Step: 11
Training loss: 2.035740852355957
Validation loss: 2.0624240803462204

Epoch: 6| Step: 12
Training loss: 2.502147674560547
Validation loss: 2.082194218071558

Epoch: 6| Step: 13
Training loss: 2.354954957962036
Validation loss: 2.0543162694541355

Epoch: 142| Step: 0
Training loss: 1.8590495586395264
Validation loss: 2.0654258984391407

Epoch: 6| Step: 1
Training loss: 1.4449706077575684
Validation loss: 2.084759167445603

Epoch: 6| Step: 2
Training loss: 2.51170015335083
Validation loss: 2.10518342192455

Epoch: 6| Step: 3
Training loss: 1.7916877269744873
Validation loss: 2.074460046265715

Epoch: 6| Step: 4
Training loss: 2.199016809463501
Validation loss: 2.0930066890614007

Epoch: 6| Step: 5
Training loss: 1.869950771331787
Validation loss: 2.052024510598952

Epoch: 6| Step: 6
Training loss: 2.2089898586273193
Validation loss: 2.057815449212187

Epoch: 6| Step: 7
Training loss: 2.0942535400390625
Validation loss: 2.0887149969736734

Epoch: 6| Step: 8
Training loss: 2.1363229751586914
Validation loss: 2.0838959678526847

Epoch: 6| Step: 9
Training loss: 2.248708486557007
Validation loss: 2.07698578475624

Epoch: 6| Step: 10
Training loss: 2.270819664001465
Validation loss: 2.047811510742352

Epoch: 6| Step: 11
Training loss: 3.0529403686523438
Validation loss: 2.0632607795858897

Epoch: 6| Step: 12
Training loss: 2.353900909423828
Validation loss: 2.07035183265645

Epoch: 6| Step: 13
Training loss: 1.8290095329284668
Validation loss: 2.055902583624727

Epoch: 143| Step: 0
Training loss: 1.7583149671554565
Validation loss: 2.0652989341366674

Epoch: 6| Step: 1
Training loss: 1.8365486860275269
Validation loss: 2.051135714336108

Epoch: 6| Step: 2
Training loss: 2.5216126441955566
Validation loss: 2.050172103348599

Epoch: 6| Step: 3
Training loss: 2.5596628189086914
Validation loss: 2.0527262918410765

Epoch: 6| Step: 4
Training loss: 1.9872030019760132
Validation loss: 2.062112631336335

Epoch: 6| Step: 5
Training loss: 1.4724948406219482
Validation loss: 2.07673067174932

Epoch: 6| Step: 6
Training loss: 2.2420454025268555
Validation loss: 2.0449811527805943

Epoch: 6| Step: 7
Training loss: 1.9500322341918945
Validation loss: 2.0458730164394585

Epoch: 6| Step: 8
Training loss: 2.0660080909729004
Validation loss: 2.067282176786853

Epoch: 6| Step: 9
Training loss: 1.732591986656189
Validation loss: 2.0685044052780315

Epoch: 6| Step: 10
Training loss: 2.358553886413574
Validation loss: 2.063084811292669

Epoch: 6| Step: 11
Training loss: 2.850301504135132
Validation loss: 2.0537410090046544

Epoch: 6| Step: 12
Training loss: 2.0993971824645996
Validation loss: 2.045603116353353

Epoch: 6| Step: 13
Training loss: 3.0395405292510986
Validation loss: 2.032085358455617

Epoch: 144| Step: 0
Training loss: 2.2137362957000732
Validation loss: 2.0630515698463685

Epoch: 6| Step: 1
Training loss: 1.7607651948928833
Validation loss: 2.036876574639351

Epoch: 6| Step: 2
Training loss: 2.510769844055176
Validation loss: 2.0314596609402726

Epoch: 6| Step: 3
Training loss: 1.7703354358673096
Validation loss: 2.04886370576838

Epoch: 6| Step: 4
Training loss: 1.7094618082046509
Validation loss: 2.0621665754625873

Epoch: 6| Step: 5
Training loss: 3.0565249919891357
Validation loss: 2.015834049511981

Epoch: 6| Step: 6
Training loss: 2.834582805633545
Validation loss: 2.034128765906057

Epoch: 6| Step: 7
Training loss: 2.0069870948791504
Validation loss: 2.03191622354651

Epoch: 6| Step: 8
Training loss: 2.1067306995391846
Validation loss: 2.0822061031095442

Epoch: 6| Step: 9
Training loss: 2.2713866233825684
Validation loss: 2.0566910133566907

Epoch: 6| Step: 10
Training loss: 2.5842390060424805
Validation loss: 2.0316320298820414

Epoch: 6| Step: 11
Training loss: 2.4845120906829834
Validation loss: 2.0275353654738395

Epoch: 6| Step: 12
Training loss: 1.0894299745559692
Validation loss: 2.0408318350392003

Epoch: 6| Step: 13
Training loss: 1.9475061893463135
Validation loss: 2.047259367922301

Epoch: 145| Step: 0
Training loss: 2.0090503692626953
Validation loss: 2.032314782501549

Epoch: 6| Step: 1
Training loss: 2.9984521865844727
Validation loss: 2.0562442092485327

Epoch: 6| Step: 2
Training loss: 2.427793264389038
Validation loss: 2.0383518588158394

Epoch: 6| Step: 3
Training loss: 2.2988405227661133
Validation loss: 2.0358749615248812

Epoch: 6| Step: 4
Training loss: 1.9602749347686768
Validation loss: 2.030003778396114

Epoch: 6| Step: 5
Training loss: 1.4103660583496094
Validation loss: 2.01598959840754

Epoch: 6| Step: 6
Training loss: 1.8023264408111572
Validation loss: 2.050516954032324

Epoch: 6| Step: 7
Training loss: 2.6093215942382812
Validation loss: 2.0602394188604047

Epoch: 6| Step: 8
Training loss: 2.2547659873962402
Validation loss: 2.048491753557677

Epoch: 6| Step: 9
Training loss: 1.8139426708221436
Validation loss: 2.022479554658295

Epoch: 6| Step: 10
Training loss: 1.5353564023971558
Validation loss: 2.0297016943654707

Epoch: 6| Step: 11
Training loss: 2.363990306854248
Validation loss: 2.0023022774727113

Epoch: 6| Step: 12
Training loss: 2.2346367835998535
Validation loss: 2.0502039027470413

Epoch: 6| Step: 13
Training loss: 1.9577020406723022
Validation loss: 2.0847651830283542

Epoch: 146| Step: 0
Training loss: 1.9711921215057373
Validation loss: 2.0198000323387886

Epoch: 6| Step: 1
Training loss: 1.9152300357818604
Validation loss: 2.027706810223159

Epoch: 6| Step: 2
Training loss: 2.700385332107544
Validation loss: 2.0482144765956427

Epoch: 6| Step: 3
Training loss: 2.815040111541748
Validation loss: 2.0564518038944533

Epoch: 6| Step: 4
Training loss: 2.7704107761383057
Validation loss: 2.051317891766948

Epoch: 6| Step: 5
Training loss: 2.7756247520446777
Validation loss: 2.0447683577896445

Epoch: 6| Step: 6
Training loss: 1.9183564186096191
Validation loss: 2.050416459319412

Epoch: 6| Step: 7
Training loss: 1.7350530624389648
Validation loss: 2.039846379269836

Epoch: 6| Step: 8
Training loss: 1.9195265769958496
Validation loss: 2.0287000517691336

Epoch: 6| Step: 9
Training loss: 1.6821131706237793
Validation loss: 2.0701203282161424

Epoch: 6| Step: 10
Training loss: 2.626546621322632
Validation loss: 2.0767024024840324

Epoch: 6| Step: 11
Training loss: 1.8559365272521973
Validation loss: 2.0524239283736034

Epoch: 6| Step: 12
Training loss: 1.3844573497772217
Validation loss: 2.0805978057205037

Epoch: 6| Step: 13
Training loss: 1.8228917121887207
Validation loss: 2.074810835622972

Epoch: 147| Step: 0
Training loss: 1.6898975372314453
Validation loss: 2.0301142405438166

Epoch: 6| Step: 1
Training loss: 1.9291120767593384
Validation loss: 2.0643617645386727

Epoch: 6| Step: 2
Training loss: 1.5991570949554443
Validation loss: 2.073258699909333

Epoch: 6| Step: 3
Training loss: 2.1555442810058594
Validation loss: 2.032130456739856

Epoch: 6| Step: 4
Training loss: 2.4107046127319336
Validation loss: 2.042946970590981

Epoch: 6| Step: 5
Training loss: 1.5171703100204468
Validation loss: 2.045029145415111

Epoch: 6| Step: 6
Training loss: 2.3992161750793457
Validation loss: 2.031776105203936

Epoch: 6| Step: 7
Training loss: 2.0982627868652344
Validation loss: 2.051344576702323

Epoch: 6| Step: 8
Training loss: 2.8511509895324707
Validation loss: 2.0486045473365375

Epoch: 6| Step: 9
Training loss: 2.7883224487304688
Validation loss: 2.0460115735248854

Epoch: 6| Step: 10
Training loss: 2.4903504848480225
Validation loss: 2.0549342888657764

Epoch: 6| Step: 11
Training loss: 2.202705144882202
Validation loss: 2.0178478276857765

Epoch: 6| Step: 12
Training loss: 1.9793201684951782
Validation loss: 2.0356908152180333

Epoch: 6| Step: 13
Training loss: 2.031538248062134
Validation loss: 2.020084245230562

Epoch: 148| Step: 0
Training loss: 2.044691324234009
Validation loss: 2.071990487396076

Epoch: 6| Step: 1
Training loss: 2.4888696670532227
Validation loss: 2.0589749736170613

Epoch: 6| Step: 2
Training loss: 2.0667519569396973
Validation loss: 2.054308141431501

Epoch: 6| Step: 3
Training loss: 2.470890522003174
Validation loss: 2.0240988526293027

Epoch: 6| Step: 4
Training loss: 2.1974363327026367
Validation loss: 2.0541317591103176

Epoch: 6| Step: 5
Training loss: 1.9073708057403564
Validation loss: 2.0267072800667054

Epoch: 6| Step: 6
Training loss: 1.6246650218963623
Validation loss: 2.0714576116172214

Epoch: 6| Step: 7
Training loss: 1.6874051094055176
Validation loss: 2.037352741405528

Epoch: 6| Step: 8
Training loss: 1.3237359523773193
Validation loss: 2.0370654752177577

Epoch: 6| Step: 9
Training loss: 2.2319107055664062
Validation loss: 2.061565032569311

Epoch: 6| Step: 10
Training loss: 2.835493564605713
Validation loss: 2.016048682633267

Epoch: 6| Step: 11
Training loss: 2.5731611251831055
Validation loss: 2.0450938850320797

Epoch: 6| Step: 12
Training loss: 2.6554689407348633
Validation loss: 2.0604317534354424

Epoch: 6| Step: 13
Training loss: 2.63448429107666
Validation loss: 2.034712419714979

Epoch: 149| Step: 0
Training loss: 2.3964791297912598
Validation loss: 2.05104487429383

Epoch: 6| Step: 1
Training loss: 1.9183645248413086
Validation loss: 2.031132162258189

Epoch: 6| Step: 2
Training loss: 2.162822723388672
Validation loss: 2.0744959410800727

Epoch: 6| Step: 3
Training loss: 2.5412211418151855
Validation loss: 2.065301800286898

Epoch: 6| Step: 4
Training loss: 1.8739445209503174
Validation loss: 2.0453467266533965

Epoch: 6| Step: 5
Training loss: 1.5936660766601562
Validation loss: 2.077930901640205

Epoch: 6| Step: 6
Training loss: 2.387021780014038
Validation loss: 2.0935819174653743

Epoch: 6| Step: 7
Training loss: 1.871687412261963
Validation loss: 2.046087400887602

Epoch: 6| Step: 8
Training loss: 2.068303108215332
Validation loss: 2.0849178286008936

Epoch: 6| Step: 9
Training loss: 2.4132461547851562
Validation loss: 2.0887588224103375

Epoch: 6| Step: 10
Training loss: 2.7260842323303223
Validation loss: 2.083109050668696

Epoch: 6| Step: 11
Training loss: 2.350512981414795
Validation loss: 2.0634931390003493

Epoch: 6| Step: 12
Training loss: 1.8485244512557983
Validation loss: 2.088400384431244

Epoch: 6| Step: 13
Training loss: 2.3068857192993164
Validation loss: 2.0859132941051195

Epoch: 150| Step: 0
Training loss: 1.7378548383712769
Validation loss: 2.069221022308514

Epoch: 6| Step: 1
Training loss: 2.789961814880371
Validation loss: 2.082663812944966

Epoch: 6| Step: 2
Training loss: 2.452401638031006
Validation loss: 2.0849809877334105

Epoch: 6| Step: 3
Training loss: 1.8277193307876587
Validation loss: 2.1156195235508743

Epoch: 6| Step: 4
Training loss: 1.5347816944122314
Validation loss: 2.090066220170708

Epoch: 6| Step: 5
Training loss: 1.5988914966583252
Validation loss: 2.055656176741405

Epoch: 6| Step: 6
Training loss: 2.2774808406829834
Validation loss: 2.0499551424416165

Epoch: 6| Step: 7
Training loss: 2.1945302486419678
Validation loss: 2.090621490632334

Epoch: 6| Step: 8
Training loss: 2.5653650760650635
Validation loss: 2.0957733482442875

Epoch: 6| Step: 9
Training loss: 2.6131820678710938
Validation loss: 2.078020885426511

Epoch: 6| Step: 10
Training loss: 2.5198278427124023
Validation loss: 2.062439642926698

Epoch: 6| Step: 11
Training loss: 1.701246738433838
Validation loss: 2.0631734453221804

Epoch: 6| Step: 12
Training loss: 1.1918017864227295
Validation loss: 2.0383116532397527

Epoch: 6| Step: 13
Training loss: 3.4867100715637207
Validation loss: 2.031164688448752

Epoch: 151| Step: 0
Training loss: 2.2937870025634766
Validation loss: 2.056077241897583

Epoch: 6| Step: 1
Training loss: 1.6320340633392334
Validation loss: 2.0417065851150022

Epoch: 6| Step: 2
Training loss: 2.1254498958587646
Validation loss: 2.0743663669914327

Epoch: 6| Step: 3
Training loss: 1.8418431282043457
Validation loss: 2.0376921597347466

Epoch: 6| Step: 4
Training loss: 1.8328937292099
Validation loss: 2.0351571190741753

Epoch: 6| Step: 5
Training loss: 1.875863790512085
Validation loss: 2.063514256990084

Epoch: 6| Step: 6
Training loss: 2.1162943840026855
Validation loss: 2.06710498820069

Epoch: 6| Step: 7
Training loss: 2.2315428256988525
Validation loss: 2.0507452667400403

Epoch: 6| Step: 8
Training loss: 2.765341281890869
Validation loss: 2.0678451484249485

Epoch: 6| Step: 9
Training loss: 2.313838005065918
Validation loss: 2.058099046830208

Epoch: 6| Step: 10
Training loss: 2.0645532608032227
Validation loss: 2.041934400476435

Epoch: 6| Step: 11
Training loss: 2.068206548690796
Validation loss: 2.0700690566852527

Epoch: 6| Step: 12
Training loss: 2.6823618412017822
Validation loss: 2.0772376445031937

Epoch: 6| Step: 13
Training loss: 2.237140655517578
Validation loss: 2.042798098697457

Epoch: 152| Step: 0
Training loss: 2.2787985801696777
Validation loss: 2.055136562675558

Epoch: 6| Step: 1
Training loss: 1.3254951238632202
Validation loss: 2.0493118609151533

Epoch: 6| Step: 2
Training loss: 2.068620204925537
Validation loss: 2.0490521461732927

Epoch: 6| Step: 3
Training loss: 1.6039320230484009
Validation loss: 2.012098257259656

Epoch: 6| Step: 4
Training loss: 1.8440990447998047
Validation loss: 2.0529062158317974

Epoch: 6| Step: 5
Training loss: 2.048104763031006
Validation loss: 2.0372756450406966

Epoch: 6| Step: 6
Training loss: 2.726665735244751
Validation loss: 2.0729857824181996

Epoch: 6| Step: 7
Training loss: 2.8109593391418457
Validation loss: 2.061956359494117

Epoch: 6| Step: 8
Training loss: 1.9787707328796387
Validation loss: 2.043752775397352

Epoch: 6| Step: 9
Training loss: 2.45353364944458
Validation loss: 2.0384449266618296

Epoch: 6| Step: 10
Training loss: 2.1102981567382812
Validation loss: 2.056388521707186

Epoch: 6| Step: 11
Training loss: 2.4727344512939453
Validation loss: 2.0265279944225023

Epoch: 6| Step: 12
Training loss: 1.9672348499298096
Validation loss: 2.036519267225778

Epoch: 6| Step: 13
Training loss: 2.192098617553711
Validation loss: 2.0823026087976273

Epoch: 153| Step: 0
Training loss: 2.088679313659668
Validation loss: 2.0626635756543887

Epoch: 6| Step: 1
Training loss: 2.947932720184326
Validation loss: 2.039077845952844

Epoch: 6| Step: 2
Training loss: 1.8823288679122925
Validation loss: 2.067725032888433

Epoch: 6| Step: 3
Training loss: 2.831167697906494
Validation loss: 2.0213862080727854

Epoch: 6| Step: 4
Training loss: 1.3189582824707031
Validation loss: 2.045459839605516

Epoch: 6| Step: 5
Training loss: 2.4739997386932373
Validation loss: 2.051970076817338

Epoch: 6| Step: 6
Training loss: 1.6495120525360107
Validation loss: 2.0517772090050483

Epoch: 6| Step: 7
Training loss: 1.8893955945968628
Validation loss: 2.054976849145787

Epoch: 6| Step: 8
Training loss: 2.327535629272461
Validation loss: 2.0202899825188423

Epoch: 6| Step: 9
Training loss: 2.782461166381836
Validation loss: 2.047106865913637

Epoch: 6| Step: 10
Training loss: 1.354492425918579
Validation loss: 2.0435820805129183

Epoch: 6| Step: 11
Training loss: 1.8983237743377686
Validation loss: 2.0182141386052614

Epoch: 6| Step: 12
Training loss: 2.294769287109375
Validation loss: 2.074325542296133

Epoch: 6| Step: 13
Training loss: 1.9450623989105225
Validation loss: 2.0340610614386936

Epoch: 154| Step: 0
Training loss: 2.004761219024658
Validation loss: 2.0842384164051344

Epoch: 6| Step: 1
Training loss: 2.5071616172790527
Validation loss: 2.0362889446238035

Epoch: 6| Step: 2
Training loss: 2.7819137573242188
Validation loss: 2.0252831392390753

Epoch: 6| Step: 3
Training loss: 1.6226614713668823
Validation loss: 2.046679717238231

Epoch: 6| Step: 4
Training loss: 2.008706569671631
Validation loss: 2.0526172396957234

Epoch: 6| Step: 5
Training loss: 2.179349184036255
Validation loss: 2.0384986272422214

Epoch: 6| Step: 6
Training loss: 1.8480734825134277
Validation loss: 2.0391097402059906

Epoch: 6| Step: 7
Training loss: 1.8599038124084473
Validation loss: 2.0135736567999727

Epoch: 6| Step: 8
Training loss: 1.9410932064056396
Validation loss: 2.019013356137019

Epoch: 6| Step: 9
Training loss: 1.8837347030639648
Validation loss: 2.0367927410269298

Epoch: 6| Step: 10
Training loss: 3.3019909858703613
Validation loss: 2.0479478887332383

Epoch: 6| Step: 11
Training loss: 1.648177981376648
Validation loss: 2.0182244777679443

Epoch: 6| Step: 12
Training loss: 1.7040709257125854
Validation loss: 2.0293495219240905

Epoch: 6| Step: 13
Training loss: 3.0049078464508057
Validation loss: 2.030222508215135

Epoch: 155| Step: 0
Training loss: 2.2208704948425293
Validation loss: 2.019401737438735

Epoch: 6| Step: 1
Training loss: 2.6818971633911133
Validation loss: 2.0253311203372095

Epoch: 6| Step: 2
Training loss: 2.325831890106201
Validation loss: 2.1100127466263308

Epoch: 6| Step: 3
Training loss: 2.338629722595215
Validation loss: 2.07716699441274

Epoch: 6| Step: 4
Training loss: 1.450270175933838
Validation loss: 2.022676888332572

Epoch: 6| Step: 5
Training loss: 1.2893664836883545
Validation loss: 2.0564398483563493

Epoch: 6| Step: 6
Training loss: 1.6247048377990723
Validation loss: 2.062652644290719

Epoch: 6| Step: 7
Training loss: 2.384706974029541
Validation loss: 2.0219324634921167

Epoch: 6| Step: 8
Training loss: 2.3605363368988037
Validation loss: 2.0675589705026276

Epoch: 6| Step: 9
Training loss: 2.745746612548828
Validation loss: 2.047914428095664

Epoch: 6| Step: 10
Training loss: 1.9335161447525024
Validation loss: 2.1162196282417542

Epoch: 6| Step: 11
Training loss: 1.8851287364959717
Validation loss: 2.083360638669742

Epoch: 6| Step: 12
Training loss: 2.002323627471924
Validation loss: 2.055558535360521

Epoch: 6| Step: 13
Training loss: 3.01175594329834
Validation loss: 2.0622716462740334

Epoch: 156| Step: 0
Training loss: 2.4240269660949707
Validation loss: 2.0933409121728714

Epoch: 6| Step: 1
Training loss: 2.149925708770752
Validation loss: 2.0781264894752094

Epoch: 6| Step: 2
Training loss: 2.1034562587738037
Validation loss: 2.072382027103055

Epoch: 6| Step: 3
Training loss: 2.6126110553741455
Validation loss: 2.047853705703571

Epoch: 6| Step: 4
Training loss: 2.378093719482422
Validation loss: 2.067757724433817

Epoch: 6| Step: 5
Training loss: 2.0474929809570312
Validation loss: 2.0776085904849473

Epoch: 6| Step: 6
Training loss: 2.5618369579315186
Validation loss: 2.07821237656378

Epoch: 6| Step: 7
Training loss: 2.386685371398926
Validation loss: 2.066052293264738

Epoch: 6| Step: 8
Training loss: 1.358237385749817
Validation loss: 2.087010469487918

Epoch: 6| Step: 9
Training loss: 1.9180185794830322
Validation loss: 2.0521770497804046

Epoch: 6| Step: 10
Training loss: 2.1324925422668457
Validation loss: 2.084208212872987

Epoch: 6| Step: 11
Training loss: 1.9493181705474854
Validation loss: 2.076423703983266

Epoch: 6| Step: 12
Training loss: 1.720776915550232
Validation loss: 2.088022170528289

Epoch: 6| Step: 13
Training loss: 2.411517381668091
Validation loss: 2.0620710337033836

Epoch: 157| Step: 0
Training loss: 2.5076684951782227
Validation loss: 2.078455909605949

Epoch: 6| Step: 1
Training loss: 2.463702440261841
Validation loss: 2.057625614186769

Epoch: 6| Step: 2
Training loss: 1.558640956878662
Validation loss: 2.0337900602689354

Epoch: 6| Step: 3
Training loss: 2.084169626235962
Validation loss: 2.077182682611609

Epoch: 6| Step: 4
Training loss: 2.593330144882202
Validation loss: 2.03650176653298

Epoch: 6| Step: 5
Training loss: 2.5554075241088867
Validation loss: 2.0582843442117014

Epoch: 6| Step: 6
Training loss: 2.7601842880249023
Validation loss: 2.071884819256362

Epoch: 6| Step: 7
Training loss: 2.6942479610443115
Validation loss: 2.048780987339635

Epoch: 6| Step: 8
Training loss: 1.5408775806427002
Validation loss: 2.05962368237075

Epoch: 6| Step: 9
Training loss: 1.6334261894226074
Validation loss: 2.0664099518970778

Epoch: 6| Step: 10
Training loss: 1.5464038848876953
Validation loss: 2.0349905721602903

Epoch: 6| Step: 11
Training loss: 1.8812637329101562
Validation loss: 2.0805369000281058

Epoch: 6| Step: 12
Training loss: 1.6830315589904785
Validation loss: 2.0796938647506056

Epoch: 6| Step: 13
Training loss: 2.5676333904266357
Validation loss: 2.0678178828249694

Epoch: 158| Step: 0
Training loss: 2.038484811782837
Validation loss: 2.0472458767634567

Epoch: 6| Step: 1
Training loss: 2.0566773414611816
Validation loss: 2.065935250251524

Epoch: 6| Step: 2
Training loss: 2.37214994430542
Validation loss: 2.049978848426573

Epoch: 6| Step: 3
Training loss: 2.1129746437072754
Validation loss: 2.0455658487094346

Epoch: 6| Step: 4
Training loss: 2.140369415283203
Validation loss: 2.02921187749473

Epoch: 6| Step: 5
Training loss: 2.3321762084960938
Validation loss: 2.0645254824751165

Epoch: 6| Step: 6
Training loss: 2.6199121475219727
Validation loss: 2.0661856294960104

Epoch: 6| Step: 7
Training loss: 1.888075590133667
Validation loss: 2.0612407345925607

Epoch: 6| Step: 8
Training loss: 1.9769792556762695
Validation loss: 2.06158834503543

Epoch: 6| Step: 9
Training loss: 2.7405052185058594
Validation loss: 2.07367036163166

Epoch: 6| Step: 10
Training loss: 1.9425938129425049
Validation loss: 2.080023616872808

Epoch: 6| Step: 11
Training loss: 1.9370825290679932
Validation loss: 2.055004330091579

Epoch: 6| Step: 12
Training loss: 1.6157623529434204
Validation loss: 2.0370532222973403

Epoch: 6| Step: 13
Training loss: 1.3621180057525635
Validation loss: 2.0384639591299076

Epoch: 159| Step: 0
Training loss: 2.11600923538208
Validation loss: 2.0729221246575795

Epoch: 6| Step: 1
Training loss: 2.239387035369873
Validation loss: 2.0682969913687757

Epoch: 6| Step: 2
Training loss: 2.273420810699463
Validation loss: 2.049766864827884

Epoch: 6| Step: 3
Training loss: 2.2357230186462402
Validation loss: 2.0713893508398407

Epoch: 6| Step: 4
Training loss: 1.6911537647247314
Validation loss: 2.054556369781494

Epoch: 6| Step: 5
Training loss: 2.8589885234832764
Validation loss: 2.0833013954982964

Epoch: 6| Step: 6
Training loss: 1.9315590858459473
Validation loss: 2.0356723313690512

Epoch: 6| Step: 7
Training loss: 2.182321786880493
Validation loss: 2.0688768458622757

Epoch: 6| Step: 8
Training loss: 2.6017954349517822
Validation loss: 2.052298976529029

Epoch: 6| Step: 9
Training loss: 2.070906400680542
Validation loss: 2.0690758510302474

Epoch: 6| Step: 10
Training loss: 1.704605221748352
Validation loss: 2.057122063893144

Epoch: 6| Step: 11
Training loss: 2.131760597229004
Validation loss: 2.054709347345496

Epoch: 6| Step: 12
Training loss: 1.718105673789978
Validation loss: 2.078465461730957

Epoch: 6| Step: 13
Training loss: 2.402894973754883
Validation loss: 2.0666390977880007

Epoch: 160| Step: 0
Training loss: 2.1051034927368164
Validation loss: 2.084101269322057

Epoch: 6| Step: 1
Training loss: 1.590516448020935
Validation loss: 2.0929678473421323

Epoch: 6| Step: 2
Training loss: 2.5692219734191895
Validation loss: 2.0523672180791057

Epoch: 6| Step: 3
Training loss: 2.5409045219421387
Validation loss: 2.0630315965221775

Epoch: 6| Step: 4
Training loss: 3.089073657989502
Validation loss: 2.0644967825182023

Epoch: 6| Step: 5
Training loss: 1.9013882875442505
Validation loss: 2.0501871211554414

Epoch: 6| Step: 6
Training loss: 1.5921745300292969
Validation loss: 2.062372147396047

Epoch: 6| Step: 7
Training loss: 1.5706589221954346
Validation loss: 2.068555373017506

Epoch: 6| Step: 8
Training loss: 1.6527091264724731
Validation loss: 2.062641630890549

Epoch: 6| Step: 9
Training loss: 1.9858026504516602
Validation loss: 2.0530760442056963

Epoch: 6| Step: 10
Training loss: 2.005652666091919
Validation loss: 2.0566334237334547

Epoch: 6| Step: 11
Training loss: 3.3222265243530273
Validation loss: 2.0791471709487257

Epoch: 6| Step: 12
Training loss: 1.7203543186187744
Validation loss: 2.0660510268262637

Epoch: 6| Step: 13
Training loss: 2.344363212585449
Validation loss: 2.065266852737755

Epoch: 161| Step: 0
Training loss: 1.78118896484375
Validation loss: 2.072247479551582

Epoch: 6| Step: 1
Training loss: 1.9275403022766113
Validation loss: 2.0475577090376165

Epoch: 6| Step: 2
Training loss: 1.944937825202942
Validation loss: 2.0449310656516784

Epoch: 6| Step: 3
Training loss: 2.3411078453063965
Validation loss: 2.039349074004799

Epoch: 6| Step: 4
Training loss: 2.3746516704559326
Validation loss: 2.027067968922277

Epoch: 6| Step: 5
Training loss: 1.713862657546997
Validation loss: 2.0767754841876287

Epoch: 6| Step: 6
Training loss: 2.454827308654785
Validation loss: 2.029371743561119

Epoch: 6| Step: 7
Training loss: 2.402259349822998
Validation loss: 2.051191411992555

Epoch: 6| Step: 8
Training loss: 1.936345100402832
Validation loss: 2.071266525535173

Epoch: 6| Step: 9
Training loss: 1.9705867767333984
Validation loss: 2.0756409270789034

Epoch: 6| Step: 10
Training loss: 2.044435739517212
Validation loss: 2.056564364382016

Epoch: 6| Step: 11
Training loss: 2.276592254638672
Validation loss: 2.054872323107976

Epoch: 6| Step: 12
Training loss: 2.744217872619629
Validation loss: 2.042326510593455

Epoch: 6| Step: 13
Training loss: 1.4212229251861572
Validation loss: 2.0243276806287867

Epoch: 162| Step: 0
Training loss: 1.6074717044830322
Validation loss: 2.056791228632773

Epoch: 6| Step: 1
Training loss: 2.5951485633850098
Validation loss: 2.076859774128083

Epoch: 6| Step: 2
Training loss: 2.5966525077819824
Validation loss: 2.058081567928355

Epoch: 6| Step: 3
Training loss: 1.3364629745483398
Validation loss: 2.0611155879112983

Epoch: 6| Step: 4
Training loss: 2.716543197631836
Validation loss: 2.077207524289367

Epoch: 6| Step: 5
Training loss: 1.7382968664169312
Validation loss: 2.019000014951152

Epoch: 6| Step: 6
Training loss: 1.953049659729004
Validation loss: 2.0311885033884356

Epoch: 6| Step: 7
Training loss: 2.184422016143799
Validation loss: 2.0361026435770015

Epoch: 6| Step: 8
Training loss: 3.1331262588500977
Validation loss: 2.075696499116959

Epoch: 6| Step: 9
Training loss: 1.8553593158721924
Validation loss: 2.0232785183896302

Epoch: 6| Step: 10
Training loss: 1.8289527893066406
Validation loss: 2.0711238563701673

Epoch: 6| Step: 11
Training loss: 2.046441078186035
Validation loss: 2.1073241849099436

Epoch: 6| Step: 12
Training loss: 1.813035488128662
Validation loss: 2.054964966671441

Epoch: 6| Step: 13
Training loss: 2.20601224899292
Validation loss: 2.0468496148304274

Epoch: 163| Step: 0
Training loss: 1.9287173748016357
Validation loss: 2.070229349597808

Epoch: 6| Step: 1
Training loss: 2.1830387115478516
Validation loss: 2.08135865196105

Epoch: 6| Step: 2
Training loss: 2.5506303310394287
Validation loss: 2.027837320040631

Epoch: 6| Step: 3
Training loss: 1.7258093357086182
Validation loss: 2.053908681356779

Epoch: 6| Step: 4
Training loss: 2.3632941246032715
Validation loss: 2.036195153831154

Epoch: 6| Step: 5
Training loss: 1.7989587783813477
Validation loss: 2.0929156708460983

Epoch: 6| Step: 6
Training loss: 2.438201904296875
Validation loss: 2.0448414228295766

Epoch: 6| Step: 7
Training loss: 2.0177648067474365
Validation loss: 2.0738260053819224

Epoch: 6| Step: 8
Training loss: 2.4511232376098633
Validation loss: 2.0705688332998626

Epoch: 6| Step: 9
Training loss: 1.9887984991073608
Validation loss: 2.052800791237944

Epoch: 6| Step: 10
Training loss: 2.64619779586792
Validation loss: 2.0611822041132117

Epoch: 6| Step: 11
Training loss: 2.0699524879455566
Validation loss: 2.042758064885293

Epoch: 6| Step: 12
Training loss: 1.6686227321624756
Validation loss: 2.081156663997199

Epoch: 6| Step: 13
Training loss: 1.4211593866348267
Validation loss: 2.0421464673934446

Epoch: 164| Step: 0
Training loss: 1.5462520122528076
Validation loss: 2.0715503384990077

Epoch: 6| Step: 1
Training loss: 1.3250477313995361
Validation loss: 2.034726204410676

Epoch: 6| Step: 2
Training loss: 2.2164649963378906
Validation loss: 2.089693050230703

Epoch: 6| Step: 3
Training loss: 2.6307950019836426
Validation loss: 2.090439801575035

Epoch: 6| Step: 4
Training loss: 1.6526732444763184
Validation loss: 2.0696471980822984

Epoch: 6| Step: 5
Training loss: 2.048980712890625
Validation loss: 2.0402623120174614

Epoch: 6| Step: 6
Training loss: 2.956951856613159
Validation loss: 2.054049914883029

Epoch: 6| Step: 7
Training loss: 2.2647323608398438
Validation loss: 2.064238530333324

Epoch: 6| Step: 8
Training loss: 2.5293846130371094
Validation loss: 2.0672233412342687

Epoch: 6| Step: 9
Training loss: 1.9501469135284424
Validation loss: 2.0712696070312173

Epoch: 6| Step: 10
Training loss: 2.5172476768493652
Validation loss: 2.1010027085581133

Epoch: 6| Step: 11
Training loss: 1.4440691471099854
Validation loss: 2.066770379261304

Epoch: 6| Step: 12
Training loss: 1.829552173614502
Validation loss: 2.0577140751705376

Epoch: 6| Step: 13
Training loss: 3.0203583240509033
Validation loss: 2.0762469383978073

Epoch: 165| Step: 0
Training loss: 1.6672673225402832
Validation loss: 2.0512190659840903

Epoch: 6| Step: 1
Training loss: 1.5577467679977417
Validation loss: 2.0461028314405874

Epoch: 6| Step: 2
Training loss: 2.21243953704834
Validation loss: 2.0406235725648942

Epoch: 6| Step: 3
Training loss: 2.6321604251861572
Validation loss: 2.0639837249632804

Epoch: 6| Step: 4
Training loss: 2.1034233570098877
Validation loss: 2.0565000490475724

Epoch: 6| Step: 5
Training loss: 1.8580563068389893
Validation loss: 2.05829369637274

Epoch: 6| Step: 6
Training loss: 1.8591105937957764
Validation loss: 2.0403636206862745

Epoch: 6| Step: 7
Training loss: 2.1581287384033203
Validation loss: 2.0691131314923688

Epoch: 6| Step: 8
Training loss: 2.1003894805908203
Validation loss: 2.0593913562836184

Epoch: 6| Step: 9
Training loss: 2.6592416763305664
Validation loss: 2.053844669813751

Epoch: 6| Step: 10
Training loss: 2.98028564453125
Validation loss: 2.0614757563478205

Epoch: 6| Step: 11
Training loss: 2.056617021560669
Validation loss: 2.0563348300995363

Epoch: 6| Step: 12
Training loss: 1.3147358894348145
Validation loss: 2.0880471762790473

Epoch: 6| Step: 13
Training loss: 2.901723861694336
Validation loss: 2.04077213041244

Epoch: 166| Step: 0
Training loss: 2.431852102279663
Validation loss: 2.0971592177626905

Epoch: 6| Step: 1
Training loss: 2.5076823234558105
Validation loss: 2.062443817815473

Epoch: 6| Step: 2
Training loss: 1.7208726406097412
Validation loss: 2.057860702596685

Epoch: 6| Step: 3
Training loss: 2.309647560119629
Validation loss: 2.0705895564889394

Epoch: 6| Step: 4
Training loss: 1.578025221824646
Validation loss: 2.0696647936298

Epoch: 6| Step: 5
Training loss: 2.043517827987671
Validation loss: 2.0463671197173414

Epoch: 6| Step: 6
Training loss: 1.2331922054290771
Validation loss: 2.04870984759382

Epoch: 6| Step: 7
Training loss: 2.3038854598999023
Validation loss: 2.075331534108808

Epoch: 6| Step: 8
Training loss: 2.284147262573242
Validation loss: 2.087430771961007

Epoch: 6| Step: 9
Training loss: 2.481417655944824
Validation loss: 2.078051895223638

Epoch: 6| Step: 10
Training loss: 1.2803148031234741
Validation loss: 2.046828152031027

Epoch: 6| Step: 11
Training loss: 2.43223237991333
Validation loss: 2.0407384749381774

Epoch: 6| Step: 12
Training loss: 2.4818620681762695
Validation loss: 2.0655242755848873

Epoch: 6| Step: 13
Training loss: 2.8103086948394775
Validation loss: 2.0437972699442217

Epoch: 167| Step: 0
Training loss: 1.9331508874893188
Validation loss: 2.0752007756181943

Epoch: 6| Step: 1
Training loss: 2.6440529823303223
Validation loss: 2.071464733410907

Epoch: 6| Step: 2
Training loss: 3.0433292388916016
Validation loss: 2.0786597959456907

Epoch: 6| Step: 3
Training loss: 2.136786937713623
Validation loss: 2.058806403990715

Epoch: 6| Step: 4
Training loss: 2.02764630317688
Validation loss: 2.034462614725995

Epoch: 6| Step: 5
Training loss: 2.3217506408691406
Validation loss: 2.061436673646332

Epoch: 6| Step: 6
Training loss: 2.2447218894958496
Validation loss: 2.0689571544688237

Epoch: 6| Step: 7
Training loss: 2.3430511951446533
Validation loss: 2.038168135509696

Epoch: 6| Step: 8
Training loss: 1.8322973251342773
Validation loss: 2.074637815516482

Epoch: 6| Step: 9
Training loss: 1.4724268913269043
Validation loss: 2.0607400581400883

Epoch: 6| Step: 10
Training loss: 2.2652716636657715
Validation loss: 2.0325034536341184

Epoch: 6| Step: 11
Training loss: 1.8693525791168213
Validation loss: 2.035869816298126

Epoch: 6| Step: 12
Training loss: 1.5101008415222168
Validation loss: 2.0322492186741163

Epoch: 6| Step: 13
Training loss: 1.6842221021652222
Validation loss: 2.048601690159049

Epoch: 168| Step: 0
Training loss: 2.575066328048706
Validation loss: 2.0190083711378035

Epoch: 6| Step: 1
Training loss: 1.1047708988189697
Validation loss: 2.064833520561136

Epoch: 6| Step: 2
Training loss: 1.7762696743011475
Validation loss: 2.062920665228239

Epoch: 6| Step: 3
Training loss: 2.1964993476867676
Validation loss: 2.094919261112008

Epoch: 6| Step: 4
Training loss: 1.7905081510543823
Validation loss: 2.0648118706159693

Epoch: 6| Step: 5
Training loss: 2.493220806121826
Validation loss: 2.0583111624563895

Epoch: 6| Step: 6
Training loss: 2.7049591541290283
Validation loss: 2.0765957537517754

Epoch: 6| Step: 7
Training loss: 2.100498914718628
Validation loss: 2.0927033039831344

Epoch: 6| Step: 8
Training loss: 2.22800612449646
Validation loss: 2.0522281328837075

Epoch: 6| Step: 9
Training loss: 1.934136152267456
Validation loss: 2.0696970955018075

Epoch: 6| Step: 10
Training loss: 2.9315171241760254
Validation loss: 2.086738104461342

Epoch: 6| Step: 11
Training loss: 2.2429606914520264
Validation loss: 2.0820518283433813

Epoch: 6| Step: 12
Training loss: 1.8027410507202148
Validation loss: 2.0841829084580943

Epoch: 6| Step: 13
Training loss: 1.1658470630645752
Validation loss: 2.075304751755089

Epoch: 169| Step: 0
Training loss: 2.1947431564331055
Validation loss: 2.084412451713316

Epoch: 6| Step: 1
Training loss: 2.317091226577759
Validation loss: 2.0349477721798803

Epoch: 6| Step: 2
Training loss: 1.8059043884277344
Validation loss: 2.066250019176032

Epoch: 6| Step: 3
Training loss: 1.868430256843567
Validation loss: 2.0678080756177186

Epoch: 6| Step: 4
Training loss: 2.396535873413086
Validation loss: 2.0957177300607004

Epoch: 6| Step: 5
Training loss: 1.8967199325561523
Validation loss: 2.0809554976801716

Epoch: 6| Step: 6
Training loss: 2.086151599884033
Validation loss: 2.055210683935432

Epoch: 6| Step: 7
Training loss: 1.735459566116333
Validation loss: 2.0775573894541752

Epoch: 6| Step: 8
Training loss: 2.319085121154785
Validation loss: 2.0698193427055114

Epoch: 6| Step: 9
Training loss: 1.9974117279052734
Validation loss: 2.0689821217649724

Epoch: 6| Step: 10
Training loss: 2.517122507095337
Validation loss: 2.067512651925446

Epoch: 6| Step: 11
Training loss: 1.4341520071029663
Validation loss: 2.053900675107074

Epoch: 6| Step: 12
Training loss: 2.4775424003601074
Validation loss: 2.040797619409459

Epoch: 6| Step: 13
Training loss: 2.805309295654297
Validation loss: 2.038399447676956

Epoch: 170| Step: 0
Training loss: 2.2919960021972656
Validation loss: 2.046607011107988

Epoch: 6| Step: 1
Training loss: 1.9408279657363892
Validation loss: 2.0504293287954023

Epoch: 6| Step: 2
Training loss: 2.315896987915039
Validation loss: 2.0191241489943637

Epoch: 6| Step: 3
Training loss: 2.0162057876586914
Validation loss: 2.0555424356973298

Epoch: 6| Step: 4
Training loss: 2.611959218978882
Validation loss: 2.058470461958198

Epoch: 6| Step: 5
Training loss: 1.8025908470153809
Validation loss: 2.051786825221072

Epoch: 6| Step: 6
Training loss: 2.53546142578125
Validation loss: 2.053992989242718

Epoch: 6| Step: 7
Training loss: 1.4589581489562988
Validation loss: 2.025630430508685

Epoch: 6| Step: 8
Training loss: 1.9040815830230713
Validation loss: 2.019323836090744

Epoch: 6| Step: 9
Training loss: 1.9815969467163086
Validation loss: 2.047577702870933

Epoch: 6| Step: 10
Training loss: 1.7940995693206787
Validation loss: 2.0614760229664464

Epoch: 6| Step: 11
Training loss: 2.347897529602051
Validation loss: 2.0674348774776665

Epoch: 6| Step: 12
Training loss: 2.5527830123901367
Validation loss: 2.043459426972174

Epoch: 6| Step: 13
Training loss: 1.228057861328125
Validation loss: 2.0324643709326304

Epoch: 171| Step: 0
Training loss: 2.015641450881958
Validation loss: 2.0506790479024253

Epoch: 6| Step: 1
Training loss: 2.74398136138916
Validation loss: 2.0387394569253408

Epoch: 6| Step: 2
Training loss: 2.7011547088623047
Validation loss: 2.0331693490346274

Epoch: 6| Step: 3
Training loss: 1.7250175476074219
Validation loss: 2.0391197563499532

Epoch: 6| Step: 4
Training loss: 2.300321578979492
Validation loss: 2.046698748424489

Epoch: 6| Step: 5
Training loss: 1.6599596738815308
Validation loss: 2.090629244363436

Epoch: 6| Step: 6
Training loss: 2.611166000366211
Validation loss: 2.072165855797388

Epoch: 6| Step: 7
Training loss: 1.9701170921325684
Validation loss: 2.0418300641480314

Epoch: 6| Step: 8
Training loss: 1.7297935485839844
Validation loss: 2.051871845799108

Epoch: 6| Step: 9
Training loss: 2.110011577606201
Validation loss: 2.0743534693153958

Epoch: 6| Step: 10
Training loss: 1.9796223640441895
Validation loss: 2.036965931615522

Epoch: 6| Step: 11
Training loss: 1.339153528213501
Validation loss: 2.068914677507134

Epoch: 6| Step: 12
Training loss: 2.0996742248535156
Validation loss: 2.054867083026517

Epoch: 6| Step: 13
Training loss: 2.7334916591644287
Validation loss: 2.0666585494113225

Epoch: 172| Step: 0
Training loss: 1.2390133142471313
Validation loss: 2.0360034409389702

Epoch: 6| Step: 1
Training loss: 2.586276054382324
Validation loss: 2.0544233399052776

Epoch: 6| Step: 2
Training loss: 1.9691135883331299
Validation loss: 2.081081308344359

Epoch: 6| Step: 3
Training loss: 2.5022623538970947
Validation loss: 2.0347216872758764

Epoch: 6| Step: 4
Training loss: 2.3140830993652344
Validation loss: 2.044191557873962

Epoch: 6| Step: 5
Training loss: 1.3645292520523071
Validation loss: 2.033511474568357

Epoch: 6| Step: 6
Training loss: 1.8390724658966064
Validation loss: 2.0494319943971533

Epoch: 6| Step: 7
Training loss: 2.466099500656128
Validation loss: 2.046514844381681

Epoch: 6| Step: 8
Training loss: 2.015603542327881
Validation loss: 2.04446740047906

Epoch: 6| Step: 9
Training loss: 2.035898208618164
Validation loss: 2.0800853160119828

Epoch: 6| Step: 10
Training loss: 1.8917855024337769
Validation loss: 2.056338611469474

Epoch: 6| Step: 11
Training loss: 2.677149534225464
Validation loss: 2.0027305285135903

Epoch: 6| Step: 12
Training loss: 2.368300676345825
Validation loss: 2.0426065460328133

Epoch: 6| Step: 13
Training loss: 2.145672559738159
Validation loss: 2.034530939594392

Epoch: 173| Step: 0
Training loss: 1.9451699256896973
Validation loss: 2.051510141741845

Epoch: 6| Step: 1
Training loss: 2.5955381393432617
Validation loss: 2.0603079565109743

Epoch: 6| Step: 2
Training loss: 2.3894801139831543
Validation loss: 2.035005692512758

Epoch: 6| Step: 3
Training loss: 1.8174090385437012
Validation loss: 2.0372225084612445

Epoch: 6| Step: 4
Training loss: 2.4368057250976562
Validation loss: 2.065575421497386

Epoch: 6| Step: 5
Training loss: 1.7482435703277588
Validation loss: 2.0631190820406844

Epoch: 6| Step: 6
Training loss: 1.8715283870697021
Validation loss: 2.021765321813604

Epoch: 6| Step: 7
Training loss: 2.730337619781494
Validation loss: 2.050221373957972

Epoch: 6| Step: 8
Training loss: 2.489492416381836
Validation loss: 2.042601307233175

Epoch: 6| Step: 9
Training loss: 1.3711447715759277
Validation loss: 2.0919964121234034

Epoch: 6| Step: 10
Training loss: 2.189847946166992
Validation loss: 2.0682879968356063

Epoch: 6| Step: 11
Training loss: 2.0664305686950684
Validation loss: 2.052457917121149

Epoch: 6| Step: 12
Training loss: 1.7433557510375977
Validation loss: 2.035179030510687

Epoch: 6| Step: 13
Training loss: 1.8952895402908325
Validation loss: 2.0410784931593042

Epoch: 174| Step: 0
Training loss: 1.6337112188339233
Validation loss: 2.042124495711378

Epoch: 6| Step: 1
Training loss: 2.0910255908966064
Validation loss: 2.04387935643555

Epoch: 6| Step: 2
Training loss: 1.7272887229919434
Validation loss: 2.0710525487058904

Epoch: 6| Step: 3
Training loss: 2.4400243759155273
Validation loss: 2.054498904494829

Epoch: 6| Step: 4
Training loss: 2.038346290588379
Validation loss: 2.090121223080543

Epoch: 6| Step: 5
Training loss: 2.0412940979003906
Validation loss: 2.060028350481423

Epoch: 6| Step: 6
Training loss: 2.5946273803710938
Validation loss: 2.0554263540493545

Epoch: 6| Step: 7
Training loss: 2.2224206924438477
Validation loss: 2.0713973891350532

Epoch: 6| Step: 8
Training loss: 2.1607370376586914
Validation loss: 2.055404829722579

Epoch: 6| Step: 9
Training loss: 2.1234025955200195
Validation loss: 2.034889110954859

Epoch: 6| Step: 10
Training loss: 1.8457696437835693
Validation loss: 2.019115842798705

Epoch: 6| Step: 11
Training loss: 1.8256146907806396
Validation loss: 2.06101167842906

Epoch: 6| Step: 12
Training loss: 2.4774436950683594
Validation loss: 2.0938781794681343

Epoch: 6| Step: 13
Training loss: 1.9547239542007446
Validation loss: 2.0562140633982997

Epoch: 175| Step: 0
Training loss: 2.012568473815918
Validation loss: 2.0722810170983754

Epoch: 6| Step: 1
Training loss: 2.068375825881958
Validation loss: 2.0282221660819104

Epoch: 6| Step: 2
Training loss: 2.428821086883545
Validation loss: 2.0867044579598213

Epoch: 6| Step: 3
Training loss: 2.4698197841644287
Validation loss: 2.052491787941225

Epoch: 6| Step: 4
Training loss: 2.175316333770752
Validation loss: 2.0494354155755814

Epoch: 6| Step: 5
Training loss: 1.7469089031219482
Validation loss: 2.0647923100379204

Epoch: 6| Step: 6
Training loss: 1.6672019958496094
Validation loss: 2.109334623941811

Epoch: 6| Step: 7
Training loss: 1.9574847221374512
Validation loss: 2.0693470047366236

Epoch: 6| Step: 8
Training loss: 1.986624002456665
Validation loss: 2.0940273884804017

Epoch: 6| Step: 9
Training loss: 1.796140193939209
Validation loss: 2.07052182638517

Epoch: 6| Step: 10
Training loss: 2.2828874588012695
Validation loss: 2.093879702270672

Epoch: 6| Step: 11
Training loss: 2.5801191329956055
Validation loss: 2.0655070786835044

Epoch: 6| Step: 12
Training loss: 1.9757977724075317
Validation loss: 2.070674104075278

Epoch: 6| Step: 13
Training loss: 2.6893367767333984
Validation loss: 2.0569552183151245

Epoch: 176| Step: 0
Training loss: 2.6158533096313477
Validation loss: 2.083328511125298

Epoch: 6| Step: 1
Training loss: 2.1503336429595947
Validation loss: 2.0670846726304744

Epoch: 6| Step: 2
Training loss: 1.9383964538574219
Validation loss: 2.068524294002082

Epoch: 6| Step: 3
Training loss: 1.9110007286071777
Validation loss: 2.0913809858342653

Epoch: 6| Step: 4
Training loss: 1.1255621910095215
Validation loss: 2.061086844372493

Epoch: 6| Step: 5
Training loss: 2.528489112854004
Validation loss: 2.0526707505667083

Epoch: 6| Step: 6
Training loss: 1.9624557495117188
Validation loss: 2.0519987203741588

Epoch: 6| Step: 7
Training loss: 2.2962350845336914
Validation loss: 2.0633532565127135

Epoch: 6| Step: 8
Training loss: 2.073823928833008
Validation loss: 2.051792360121204

Epoch: 6| Step: 9
Training loss: 2.3397040367126465
Validation loss: 2.05723544474571

Epoch: 6| Step: 10
Training loss: 2.247053861618042
Validation loss: 2.038406570752462

Epoch: 6| Step: 11
Training loss: 2.3604846000671387
Validation loss: 2.086644939197007

Epoch: 6| Step: 12
Training loss: 1.8681995868682861
Validation loss: 2.027177974741946

Epoch: 6| Step: 13
Training loss: 2.3004140853881836
Validation loss: 2.0671121433217037

Epoch: 177| Step: 0
Training loss: 2.3697447776794434
Validation loss: 2.0506429569695586

Epoch: 6| Step: 1
Training loss: 2.406865119934082
Validation loss: 2.0409054422891266

Epoch: 6| Step: 2
Training loss: 1.6087695360183716
Validation loss: 2.05151516391385

Epoch: 6| Step: 3
Training loss: 1.8998548984527588
Validation loss: 2.0721202024849514

Epoch: 6| Step: 4
Training loss: 1.709221363067627
Validation loss: 2.0590021225713913

Epoch: 6| Step: 5
Training loss: 2.439629554748535
Validation loss: 2.080261033068421

Epoch: 6| Step: 6
Training loss: 1.8218908309936523
Validation loss: 2.0318244772572673

Epoch: 6| Step: 7
Training loss: 1.9291740655899048
Validation loss: 2.0534391736471527

Epoch: 6| Step: 8
Training loss: 2.794198989868164
Validation loss: 2.0316997215312016

Epoch: 6| Step: 9
Training loss: 1.7702885866165161
Validation loss: 2.0250987596409296

Epoch: 6| Step: 10
Training loss: 2.8060340881347656
Validation loss: 2.078755554332528

Epoch: 6| Step: 11
Training loss: 1.901294469833374
Validation loss: 2.024909500152834

Epoch: 6| Step: 12
Training loss: 2.2471745014190674
Validation loss: 2.048543703171515

Epoch: 6| Step: 13
Training loss: 1.4095975160598755
Validation loss: 2.0541550997764833

Epoch: 178| Step: 0
Training loss: 1.9247660636901855
Validation loss: 2.0822544559355705

Epoch: 6| Step: 1
Training loss: 2.2756710052490234
Validation loss: 2.11774093104947

Epoch: 6| Step: 2
Training loss: 2.091609001159668
Validation loss: 2.0454141683475946

Epoch: 6| Step: 3
Training loss: 1.9710125923156738
Validation loss: 2.0601387305926253

Epoch: 6| Step: 4
Training loss: 2.129377841949463
Validation loss: 2.0902085265805646

Epoch: 6| Step: 5
Training loss: 1.7856297492980957
Validation loss: 2.0541297543433403

Epoch: 6| Step: 6
Training loss: 2.658562660217285
Validation loss: 2.0665316350998415

Epoch: 6| Step: 7
Training loss: 2.244163751602173
Validation loss: 2.0504740245880617

Epoch: 6| Step: 8
Training loss: 2.083422899246216
Validation loss: 2.0791489642153502

Epoch: 6| Step: 9
Training loss: 1.9968512058258057
Validation loss: 2.0441616158331595

Epoch: 6| Step: 10
Training loss: 2.0603795051574707
Validation loss: 2.070803898637013

Epoch: 6| Step: 11
Training loss: 2.095140218734741
Validation loss: 2.1069001818215973

Epoch: 6| Step: 12
Training loss: 1.9861640930175781
Validation loss: 2.060789995296027

Epoch: 6| Step: 13
Training loss: 1.8432211875915527
Validation loss: 2.058069227844156

Epoch: 179| Step: 0
Training loss: 2.3325395584106445
Validation loss: 2.091506863153109

Epoch: 6| Step: 1
Training loss: 1.6047122478485107
Validation loss: 2.042394256079069

Epoch: 6| Step: 2
Training loss: 1.3647185564041138
Validation loss: 2.0935443742300874

Epoch: 6| Step: 3
Training loss: 1.7015453577041626
Validation loss: 2.1050797598336333

Epoch: 6| Step: 4
Training loss: 1.5119693279266357
Validation loss: 2.1020165617747972

Epoch: 6| Step: 5
Training loss: 2.4175961017608643
Validation loss: 2.0548502322166198

Epoch: 6| Step: 6
Training loss: 2.190647602081299
Validation loss: 2.0905234967508624

Epoch: 6| Step: 7
Training loss: 2.4893109798431396
Validation loss: 2.081538245242129

Epoch: 6| Step: 8
Training loss: 2.091404914855957
Validation loss: 2.113162961057437

Epoch: 6| Step: 9
Training loss: 2.5651721954345703
Validation loss: 2.1046049492333525

Epoch: 6| Step: 10
Training loss: 2.0471363067626953
Validation loss: 2.0653061430941344

Epoch: 6| Step: 11
Training loss: 2.4978580474853516
Validation loss: 2.077417863312588

Epoch: 6| Step: 12
Training loss: 1.745492696762085
Validation loss: 2.0972412375993628

Epoch: 6| Step: 13
Training loss: 3.182645082473755
Validation loss: 2.0538792161531347

Epoch: 180| Step: 0
Training loss: 1.7609364986419678
Validation loss: 2.0645346321085447

Epoch: 6| Step: 1
Training loss: 1.560657262802124
Validation loss: 2.065483506007861

Epoch: 6| Step: 2
Training loss: 2.402906894683838
Validation loss: 2.058830371467016

Epoch: 6| Step: 3
Training loss: 2.1239371299743652
Validation loss: 2.0705994239417453

Epoch: 6| Step: 4
Training loss: 1.9322171211242676
Validation loss: 2.058973741787736

Epoch: 6| Step: 5
Training loss: 2.4704744815826416
Validation loss: 2.07237978904478

Epoch: 6| Step: 6
Training loss: 1.8412280082702637
Validation loss: 2.050563596910046

Epoch: 6| Step: 7
Training loss: 2.0823841094970703
Validation loss: 2.053453048070272

Epoch: 6| Step: 8
Training loss: 2.5172295570373535
Validation loss: 2.0758361278041715

Epoch: 6| Step: 9
Training loss: 2.050001859664917
Validation loss: 2.0599067672606437

Epoch: 6| Step: 10
Training loss: 1.9081412553787231
Validation loss: 2.0269150657038533

Epoch: 6| Step: 11
Training loss: 2.22554874420166
Validation loss: 2.046712689502265

Epoch: 6| Step: 12
Training loss: 2.207181930541992
Validation loss: 2.0293789499549457

Epoch: 6| Step: 13
Training loss: 1.8635071516036987
Validation loss: 2.104941898776639

Epoch: 181| Step: 0
Training loss: 1.787987470626831
Validation loss: 2.0462074343876173

Epoch: 6| Step: 1
Training loss: 2.0076308250427246
Validation loss: 2.040475167253966

Epoch: 6| Step: 2
Training loss: 2.438028335571289
Validation loss: 2.0516533236349783

Epoch: 6| Step: 3
Training loss: 1.7374894618988037
Validation loss: 2.043034058745189

Epoch: 6| Step: 4
Training loss: 2.636239528656006
Validation loss: 2.0254350785286195

Epoch: 6| Step: 5
Training loss: 2.600175619125366
Validation loss: 2.0722745413421304

Epoch: 6| Step: 6
Training loss: 1.7583351135253906
Validation loss: 2.039125173322616

Epoch: 6| Step: 7
Training loss: 1.7277928590774536
Validation loss: 2.042215918981901

Epoch: 6| Step: 8
Training loss: 2.630906343460083
Validation loss: 2.082901485504643

Epoch: 6| Step: 9
Training loss: 2.0487563610076904
Validation loss: 2.0551017586902907

Epoch: 6| Step: 10
Training loss: 2.22703218460083
Validation loss: 2.063461503674907

Epoch: 6| Step: 11
Training loss: 1.8442035913467407
Validation loss: 2.062950291941243

Epoch: 6| Step: 12
Training loss: 1.6142301559448242
Validation loss: 2.031576177125336

Epoch: 6| Step: 13
Training loss: 2.2704973220825195
Validation loss: 2.0521244002926733

Epoch: 182| Step: 0
Training loss: 2.522603988647461
Validation loss: 2.088847634612873

Epoch: 6| Step: 1
Training loss: 1.9580456018447876
Validation loss: 2.036517922596265

Epoch: 6| Step: 2
Training loss: 2.7380552291870117
Validation loss: 2.0304120868764897

Epoch: 6| Step: 3
Training loss: 1.8646714687347412
Validation loss: 2.0343782132671726

Epoch: 6| Step: 4
Training loss: 1.9256272315979004
Validation loss: 2.042525329897481

Epoch: 6| Step: 5
Training loss: 2.198801040649414
Validation loss: 2.054109804091915

Epoch: 6| Step: 6
Training loss: 2.329962968826294
Validation loss: 2.0849125154556765

Epoch: 6| Step: 7
Training loss: 1.6247950792312622
Validation loss: 2.043632315051171

Epoch: 6| Step: 8
Training loss: 2.0169239044189453
Validation loss: 2.0703379582333308

Epoch: 6| Step: 9
Training loss: 2.191586494445801
Validation loss: 2.0367828902377876

Epoch: 6| Step: 10
Training loss: 1.4786477088928223
Validation loss: 2.0389151778272403

Epoch: 6| Step: 11
Training loss: 2.6996283531188965
Validation loss: 2.0643214846170075

Epoch: 6| Step: 12
Training loss: 1.6206005811691284
Validation loss: 2.0429057126404135

Epoch: 6| Step: 13
Training loss: 2.3954989910125732
Validation loss: 2.056368221518814

Epoch: 183| Step: 0
Training loss: 1.813155174255371
Validation loss: 2.0738683951798307

Epoch: 6| Step: 1
Training loss: 2.517974853515625
Validation loss: 2.068647271843367

Epoch: 6| Step: 2
Training loss: 2.0650906562805176
Validation loss: 2.078027435528335

Epoch: 6| Step: 3
Training loss: 1.8994195461273193
Validation loss: 2.0872499583869852

Epoch: 6| Step: 4
Training loss: 2.091743230819702
Validation loss: 2.041913882378609

Epoch: 6| Step: 5
Training loss: 2.181123733520508
Validation loss: 2.081628203392029

Epoch: 6| Step: 6
Training loss: 2.608778476715088
Validation loss: 2.053942826486403

Epoch: 6| Step: 7
Training loss: 1.8312780857086182
Validation loss: 2.0324413686670284

Epoch: 6| Step: 8
Training loss: 1.9156882762908936
Validation loss: 2.0658115443362983

Epoch: 6| Step: 9
Training loss: 1.9171911478042603
Validation loss: 2.0691153131505495

Epoch: 6| Step: 10
Training loss: 2.0971474647521973
Validation loss: 2.081806266179649

Epoch: 6| Step: 11
Training loss: 2.115935802459717
Validation loss: 2.071549677079724

Epoch: 6| Step: 12
Training loss: 1.9858813285827637
Validation loss: 2.0811192835530927

Epoch: 6| Step: 13
Training loss: 2.3021206855773926
Validation loss: 2.092560463054206

Epoch: 184| Step: 0
Training loss: 1.1372255086898804
Validation loss: 2.087755245547141

Epoch: 6| Step: 1
Training loss: 1.7364633083343506
Validation loss: 2.1053335961475166

Epoch: 6| Step: 2
Training loss: 2.0457396507263184
Validation loss: 2.1129926853282477

Epoch: 6| Step: 3
Training loss: 2.6867847442626953
Validation loss: 2.0799366338278658

Epoch: 6| Step: 4
Training loss: 2.0625271797180176
Validation loss: 2.1168387589916104

Epoch: 6| Step: 5
Training loss: 2.201875925064087
Validation loss: 2.0777347113496516

Epoch: 6| Step: 6
Training loss: 2.147094249725342
Validation loss: 2.074205983069635

Epoch: 6| Step: 7
Training loss: 1.6921216249465942
Validation loss: 2.0855271277889127

Epoch: 6| Step: 8
Training loss: 1.7011079788208008
Validation loss: 2.0755490000529955

Epoch: 6| Step: 9
Training loss: 2.2794103622436523
Validation loss: 2.1021807629575013

Epoch: 6| Step: 10
Training loss: 2.350599765777588
Validation loss: 2.0364826212647142

Epoch: 6| Step: 11
Training loss: 2.7459216117858887
Validation loss: 2.092343482919919

Epoch: 6| Step: 12
Training loss: 2.665640354156494
Validation loss: 2.062800920137795

Epoch: 6| Step: 13
Training loss: 1.5903608798980713
Validation loss: 2.061212851155189

Epoch: 185| Step: 0
Training loss: 1.679387092590332
Validation loss: 2.0779114641169065

Epoch: 6| Step: 1
Training loss: 2.299670696258545
Validation loss: 2.0804853439331055

Epoch: 6| Step: 2
Training loss: 2.701819896697998
Validation loss: 2.0884336297230055

Epoch: 6| Step: 3
Training loss: 1.7732794284820557
Validation loss: 2.0770787474929646

Epoch: 6| Step: 4
Training loss: 2.5073554515838623
Validation loss: 2.0570878303179176

Epoch: 6| Step: 5
Training loss: 2.6901540756225586
Validation loss: 2.0725380092538814

Epoch: 6| Step: 6
Training loss: 2.287322998046875
Validation loss: 2.045587561463797

Epoch: 6| Step: 7
Training loss: 2.420560359954834
Validation loss: 2.0371636177903865

Epoch: 6| Step: 8
Training loss: 1.8270082473754883
Validation loss: 2.0701448661024853

Epoch: 6| Step: 9
Training loss: 1.246744155883789
Validation loss: 2.0686595311728855

Epoch: 6| Step: 10
Training loss: 1.262902021408081
Validation loss: 2.0842990977789766

Epoch: 6| Step: 11
Training loss: 2.511807680130005
Validation loss: 2.0560687921380483

Epoch: 6| Step: 12
Training loss: 1.872351050376892
Validation loss: 2.081756845597298

Epoch: 6| Step: 13
Training loss: 2.118232250213623
Validation loss: 2.061841041811051

Epoch: 186| Step: 0
Training loss: 1.4777019023895264
Validation loss: 2.0646362355960313

Epoch: 6| Step: 1
Training loss: 1.5840911865234375
Validation loss: 2.0688789749658234

Epoch: 6| Step: 2
Training loss: 2.8498923778533936
Validation loss: 2.0759700293182046

Epoch: 6| Step: 3
Training loss: 1.99471116065979
Validation loss: 2.033967548801053

Epoch: 6| Step: 4
Training loss: 2.519507884979248
Validation loss: 2.055960415512003

Epoch: 6| Step: 5
Training loss: 2.105937957763672
Validation loss: 2.0428191602870984

Epoch: 6| Step: 6
Training loss: 2.21234130859375
Validation loss: 2.0358142211873043

Epoch: 6| Step: 7
Training loss: 2.410146951675415
Validation loss: 2.0621740689841648

Epoch: 6| Step: 8
Training loss: 1.9874022006988525
Validation loss: 2.0701104082087034

Epoch: 6| Step: 9
Training loss: 2.5639843940734863
Validation loss: 2.0781992071418354

Epoch: 6| Step: 10
Training loss: 1.8875744342803955
Validation loss: 2.0708255293548747

Epoch: 6| Step: 11
Training loss: 1.5760570764541626
Validation loss: 2.074271099541777

Epoch: 6| Step: 12
Training loss: 2.56235408782959
Validation loss: 2.0608580766185636

Epoch: 6| Step: 13
Training loss: 1.0398832559585571
Validation loss: 2.0405257722382903

Epoch: 187| Step: 0
Training loss: 1.570196509361267
Validation loss: 2.0950604023471957

Epoch: 6| Step: 1
Training loss: 2.2173142433166504
Validation loss: 2.073570091237304

Epoch: 6| Step: 2
Training loss: 1.9436531066894531
Validation loss: 2.058227039152576

Epoch: 6| Step: 3
Training loss: 2.8193256855010986
Validation loss: 2.0647129153692596

Epoch: 6| Step: 4
Training loss: 2.7778687477111816
Validation loss: 2.0690050945487073

Epoch: 6| Step: 5
Training loss: 2.1221141815185547
Validation loss: 2.091315919353116

Epoch: 6| Step: 6
Training loss: 1.861756682395935
Validation loss: 2.060531816174907

Epoch: 6| Step: 7
Training loss: 2.036552667617798
Validation loss: 2.0904109272905576

Epoch: 6| Step: 8
Training loss: 1.14996337890625
Validation loss: 2.042763529285308

Epoch: 6| Step: 9
Training loss: 2.418612241744995
Validation loss: 2.071955703919934

Epoch: 6| Step: 10
Training loss: 2.2838382720947266
Validation loss: 2.066929732599566

Epoch: 6| Step: 11
Training loss: 2.396956443786621
Validation loss: 2.0686623921958347

Epoch: 6| Step: 12
Training loss: 1.579756259918213
Validation loss: 2.0671911213987615

Epoch: 6| Step: 13
Training loss: 2.021157741546631
Validation loss: 2.078381912682646

Epoch: 188| Step: 0
Training loss: 1.9004038572311401
Validation loss: 2.067357632421678

Epoch: 6| Step: 1
Training loss: 2.2868359088897705
Validation loss: 2.0615815590786677

Epoch: 6| Step: 2
Training loss: 1.9359984397888184
Validation loss: 2.084437270318308

Epoch: 6| Step: 3
Training loss: 1.1931679248809814
Validation loss: 2.0724902665743263

Epoch: 6| Step: 4
Training loss: 2.880659580230713
Validation loss: 2.081695346422093

Epoch: 6| Step: 5
Training loss: 2.29099178314209
Validation loss: 2.0492286220673592

Epoch: 6| Step: 6
Training loss: 1.9133422374725342
Validation loss: 2.083024617164366

Epoch: 6| Step: 7
Training loss: 2.451547384262085
Validation loss: 2.06744671124284

Epoch: 6| Step: 8
Training loss: 2.1464738845825195
Validation loss: 2.1088106055413522

Epoch: 6| Step: 9
Training loss: 3.2313194274902344
Validation loss: 2.0777157275907454

Epoch: 6| Step: 10
Training loss: 1.5651463270187378
Validation loss: 2.0667903628400577

Epoch: 6| Step: 11
Training loss: 2.471683979034424
Validation loss: 2.076305668841126

Epoch: 6| Step: 12
Training loss: 1.7143325805664062
Validation loss: 2.1049457468012327

Epoch: 6| Step: 13
Training loss: 0.9645398259162903
Validation loss: 2.12412404757674

Epoch: 189| Step: 0
Training loss: 1.7576231956481934
Validation loss: 2.0228257025441816

Epoch: 6| Step: 1
Training loss: 2.3344578742980957
Validation loss: 2.073230502425983

Epoch: 6| Step: 2
Training loss: 1.7468252182006836
Validation loss: 2.095998792238133

Epoch: 6| Step: 3
Training loss: 1.7583115100860596
Validation loss: 2.068170457757929

Epoch: 6| Step: 4
Training loss: 2.0198287963867188
Validation loss: 2.0935565399867233

Epoch: 6| Step: 5
Training loss: 2.2924399375915527
Validation loss: 2.060815062574161

Epoch: 6| Step: 6
Training loss: 2.8647446632385254
Validation loss: 2.07170166507844

Epoch: 6| Step: 7
Training loss: 1.6400730609893799
Validation loss: 2.0736073063265894

Epoch: 6| Step: 8
Training loss: 1.813440203666687
Validation loss: 2.04528594786121

Epoch: 6| Step: 9
Training loss: 2.2168116569519043
Validation loss: 2.0682939739637476

Epoch: 6| Step: 10
Training loss: 2.1355247497558594
Validation loss: 2.0691243781838367

Epoch: 6| Step: 11
Training loss: 2.0005409717559814
Validation loss: 2.057289150453383

Epoch: 6| Step: 12
Training loss: 2.2731926441192627
Validation loss: 2.0986955345317884

Epoch: 6| Step: 13
Training loss: 2.166605234146118
Validation loss: 2.0611004085950952

Epoch: 190| Step: 0
Training loss: 1.9464797973632812
Validation loss: 2.0236362206038607

Epoch: 6| Step: 1
Training loss: 1.969815969467163
Validation loss: 2.08250750905724

Epoch: 6| Step: 2
Training loss: 2.6632943153381348
Validation loss: 2.058004129317499

Epoch: 6| Step: 3
Training loss: 1.5132441520690918
Validation loss: 2.011839210346181

Epoch: 6| Step: 4
Training loss: 2.4561843872070312
Validation loss: 2.0492341300492645

Epoch: 6| Step: 5
Training loss: 2.4826629161834717
Validation loss: 2.0608881160777104

Epoch: 6| Step: 6
Training loss: 2.099606513977051
Validation loss: 2.0420212950757755

Epoch: 6| Step: 7
Training loss: 2.3985719680786133
Validation loss: 2.03111671632336

Epoch: 6| Step: 8
Training loss: 1.8726694583892822
Validation loss: 2.0492384664473997

Epoch: 6| Step: 9
Training loss: 1.8364667892456055
Validation loss: 2.0552337118374404

Epoch: 6| Step: 10
Training loss: 2.207752227783203
Validation loss: 2.009011653161818

Epoch: 6| Step: 11
Training loss: 1.3717663288116455
Validation loss: 2.0288619328570623

Epoch: 6| Step: 12
Training loss: 2.171050548553467
Validation loss: 2.0581521167550036

Epoch: 6| Step: 13
Training loss: 2.105803966522217
Validation loss: 2.052175970487697

Epoch: 191| Step: 0
Training loss: 1.6539353132247925
Validation loss: 2.054361278010953

Epoch: 6| Step: 1
Training loss: 1.5832715034484863
Validation loss: 2.0745184729176183

Epoch: 6| Step: 2
Training loss: 2.410189151763916
Validation loss: 2.0637321625986407

Epoch: 6| Step: 3
Training loss: 2.321826934814453
Validation loss: 2.0528020576764177

Epoch: 6| Step: 4
Training loss: 1.0071816444396973
Validation loss: 2.0736374419222594

Epoch: 6| Step: 5
Training loss: 2.784745216369629
Validation loss: 2.095503435339979

Epoch: 6| Step: 6
Training loss: 2.417046546936035
Validation loss: 2.0568303356888475

Epoch: 6| Step: 7
Training loss: 2.471850633621216
Validation loss: 2.0676700274149575

Epoch: 6| Step: 8
Training loss: 1.587560772895813
Validation loss: 2.117627551478724

Epoch: 6| Step: 9
Training loss: 1.8606069087982178
Validation loss: 2.0944749257897817

Epoch: 6| Step: 10
Training loss: 2.9086647033691406
Validation loss: 2.0885728123367473

Epoch: 6| Step: 11
Training loss: 1.78806471824646
Validation loss: 2.1047813353999967

Epoch: 6| Step: 12
Training loss: 1.937701940536499
Validation loss: 2.10418515564293

Epoch: 6| Step: 13
Training loss: 2.9666340351104736
Validation loss: 2.0910574787406513

Epoch: 192| Step: 0
Training loss: 1.8859288692474365
Validation loss: 2.103368725827945

Epoch: 6| Step: 1
Training loss: 1.5098817348480225
Validation loss: 2.08133327960968

Epoch: 6| Step: 2
Training loss: 1.9800057411193848
Validation loss: 2.0923985486389487

Epoch: 6| Step: 3
Training loss: 2.2540576457977295
Validation loss: 2.04630579615152

Epoch: 6| Step: 4
Training loss: 1.557462453842163
Validation loss: 2.1134248190028693

Epoch: 6| Step: 5
Training loss: 2.745374917984009
Validation loss: 2.065122732552149

Epoch: 6| Step: 6
Training loss: 1.8918843269348145
Validation loss: 2.0798964743973105

Epoch: 6| Step: 7
Training loss: 2.320312261581421
Validation loss: 2.062259461290093

Epoch: 6| Step: 8
Training loss: 2.2495217323303223
Validation loss: 2.0924442532241985

Epoch: 6| Step: 9
Training loss: 2.419430732727051
Validation loss: 2.074539746007612

Epoch: 6| Step: 10
Training loss: 1.3523924350738525
Validation loss: 2.079294340584868

Epoch: 6| Step: 11
Training loss: 2.1904897689819336
Validation loss: 2.0442333964891333

Epoch: 6| Step: 12
Training loss: 2.249927520751953
Validation loss: 2.06163279984587

Epoch: 6| Step: 13
Training loss: 2.4478445053100586
Validation loss: 2.0753603314840667

Epoch: 193| Step: 0
Training loss: 2.3905091285705566
Validation loss: 2.0738986833121187

Epoch: 6| Step: 1
Training loss: 2.148216962814331
Validation loss: 2.0864230407181608

Epoch: 6| Step: 2
Training loss: 2.6403613090515137
Validation loss: 2.109429262017691

Epoch: 6| Step: 3
Training loss: 1.2646403312683105
Validation loss: 2.0806067925627514

Epoch: 6| Step: 4
Training loss: 2.622910499572754
Validation loss: 2.0852850444855227

Epoch: 6| Step: 5
Training loss: 2.204291343688965
Validation loss: 2.0700452699456164

Epoch: 6| Step: 6
Training loss: 2.074918746948242
Validation loss: 2.083904891885737

Epoch: 6| Step: 7
Training loss: 1.9540660381317139
Validation loss: 2.065521594016783

Epoch: 6| Step: 8
Training loss: 1.64323091506958
Validation loss: 2.0333750324864543

Epoch: 6| Step: 9
Training loss: 2.2240705490112305
Validation loss: 2.066453796561046

Epoch: 6| Step: 10
Training loss: 1.8196024894714355
Validation loss: 2.0497195259217293

Epoch: 6| Step: 11
Training loss: 2.2098307609558105
Validation loss: 2.0677067900216706

Epoch: 6| Step: 12
Training loss: 2.24277400970459
Validation loss: 2.066910292512627

Epoch: 6| Step: 13
Training loss: 2.09610652923584
Validation loss: 2.0635856607908845

Epoch: 194| Step: 0
Training loss: 2.6403613090515137
Validation loss: 2.077649893299226

Epoch: 6| Step: 1
Training loss: 1.8499587774276733
Validation loss: 2.0239052182884625

Epoch: 6| Step: 2
Training loss: 2.0596230030059814
Validation loss: 2.0086376667022705

Epoch: 6| Step: 3
Training loss: 1.9630858898162842
Validation loss: 2.070217213323039

Epoch: 6| Step: 4
Training loss: 1.896895170211792
Validation loss: 2.067491803117978

Epoch: 6| Step: 5
Training loss: 1.7078967094421387
Validation loss: 2.060195117868403

Epoch: 6| Step: 6
Training loss: 3.162081718444824
Validation loss: 2.0544312718094035

Epoch: 6| Step: 7
Training loss: 2.7580318450927734
Validation loss: 2.063759885808473

Epoch: 6| Step: 8
Training loss: 1.9726511240005493
Validation loss: 2.056473365394018

Epoch: 6| Step: 9
Training loss: 1.8219099044799805
Validation loss: 2.0862887867035402

Epoch: 6| Step: 10
Training loss: 2.002253532409668
Validation loss: 2.079037515066003

Epoch: 6| Step: 11
Training loss: 1.7972509860992432
Validation loss: 2.0738305045712377

Epoch: 6| Step: 12
Training loss: 1.682431697845459
Validation loss: 2.0934580218407417

Epoch: 6| Step: 13
Training loss: 1.8677830696105957
Validation loss: 2.0684867776850218

Epoch: 195| Step: 0
Training loss: 2.3112356662750244
Validation loss: 2.090717290037422

Epoch: 6| Step: 1
Training loss: 2.1960439682006836
Validation loss: 2.115095030876898

Epoch: 6| Step: 2
Training loss: 1.4429523944854736
Validation loss: 2.0614283110505793

Epoch: 6| Step: 3
Training loss: 1.4482120275497437
Validation loss: 2.079344029067665

Epoch: 6| Step: 4
Training loss: 2.005265235900879
Validation loss: 2.089134390636157

Epoch: 6| Step: 5
Training loss: 1.7487802505493164
Validation loss: 2.0663682927367506

Epoch: 6| Step: 6
Training loss: 2.823686122894287
Validation loss: 2.099016930467339

Epoch: 6| Step: 7
Training loss: 1.2185451984405518
Validation loss: 2.083965896278299

Epoch: 6| Step: 8
Training loss: 2.613971710205078
Validation loss: 2.079614705936883

Epoch: 6| Step: 9
Training loss: 2.0634663105010986
Validation loss: 2.086614626710133

Epoch: 6| Step: 10
Training loss: 2.9172258377075195
Validation loss: 2.0983879284192155

Epoch: 6| Step: 11
Training loss: 1.9291622638702393
Validation loss: 2.074908311649035

Epoch: 6| Step: 12
Training loss: 2.391511917114258
Validation loss: 2.0688731388379167

Epoch: 6| Step: 13
Training loss: 2.266897678375244
Validation loss: 2.085421146885041

Epoch: 196| Step: 0
Training loss: 1.5096100568771362
Validation loss: 2.0751959072646273

Epoch: 6| Step: 1
Training loss: 2.2245426177978516
Validation loss: 2.0661098290515203

Epoch: 6| Step: 2
Training loss: 1.9562499523162842
Validation loss: 2.0594872979707617

Epoch: 6| Step: 3
Training loss: 2.085155487060547
Validation loss: 2.0668141739342802

Epoch: 6| Step: 4
Training loss: 1.993474006652832
Validation loss: 2.097167540622014

Epoch: 6| Step: 5
Training loss: 2.8765485286712646
Validation loss: 2.046752965578469

Epoch: 6| Step: 6
Training loss: 1.9663499593734741
Validation loss: 2.037954976481776

Epoch: 6| Step: 7
Training loss: 1.4327456951141357
Validation loss: 2.0608316724018385

Epoch: 6| Step: 8
Training loss: 2.3021435737609863
Validation loss: 2.058946450551351

Epoch: 6| Step: 9
Training loss: 2.3539252281188965
Validation loss: 2.0854291967166367

Epoch: 6| Step: 10
Training loss: 2.2777278423309326
Validation loss: 2.032415231068929

Epoch: 6| Step: 11
Training loss: 1.76515531539917
Validation loss: 2.078145957762195

Epoch: 6| Step: 12
Training loss: 1.9924933910369873
Validation loss: 2.0443039658249065

Epoch: 6| Step: 13
Training loss: 2.3501877784729004
Validation loss: 2.066929635181222

Epoch: 197| Step: 0
Training loss: 2.0211164951324463
Validation loss: 2.0971922848814275

Epoch: 6| Step: 1
Training loss: 1.3595997095108032
Validation loss: 2.0436574118111723

Epoch: 6| Step: 2
Training loss: 2.640751361846924
Validation loss: 2.071328588711318

Epoch: 6| Step: 3
Training loss: 2.012331485748291
Validation loss: 2.076801553849251

Epoch: 6| Step: 4
Training loss: 2.511573314666748
Validation loss: 2.0760321937581545

Epoch: 6| Step: 5
Training loss: 2.1710400581359863
Validation loss: 2.05234629877152

Epoch: 6| Step: 6
Training loss: 1.9308850765228271
Validation loss: 2.0563203468117663

Epoch: 6| Step: 7
Training loss: 2.519045352935791
Validation loss: 2.0785909878310336

Epoch: 6| Step: 8
Training loss: 1.707167148590088
Validation loss: 2.0600341609729234

Epoch: 6| Step: 9
Training loss: 2.0613365173339844
Validation loss: 2.0517310198917182

Epoch: 6| Step: 10
Training loss: 2.35634183883667
Validation loss: 2.026754435672555

Epoch: 6| Step: 11
Training loss: 1.5845983028411865
Validation loss: 2.062003320263278

Epoch: 6| Step: 12
Training loss: 2.308814525604248
Validation loss: 2.0783294362406575

Epoch: 6| Step: 13
Training loss: 1.6307525634765625
Validation loss: 2.07772631542657

Epoch: 198| Step: 0
Training loss: 1.4169635772705078
Validation loss: 2.0746201392143004

Epoch: 6| Step: 1
Training loss: 2.7542800903320312
Validation loss: 2.047112759723458

Epoch: 6| Step: 2
Training loss: 2.524702548980713
Validation loss: 2.0796053204485165

Epoch: 6| Step: 3
Training loss: 2.8415188789367676
Validation loss: 2.078099309757192

Epoch: 6| Step: 4
Training loss: 2.0671253204345703
Validation loss: 2.0949211543606174

Epoch: 6| Step: 5
Training loss: 2.2793867588043213
Validation loss: 2.0793741492814917

Epoch: 6| Step: 6
Training loss: 1.948581576347351
Validation loss: 2.108440004369264

Epoch: 6| Step: 7
Training loss: 2.209430694580078
Validation loss: 2.084995206966195

Epoch: 6| Step: 8
Training loss: 1.462796926498413
Validation loss: 2.070850251823343

Epoch: 6| Step: 9
Training loss: 1.713848352432251
Validation loss: 2.0446739042958906

Epoch: 6| Step: 10
Training loss: 2.458545684814453
Validation loss: 2.079865321036308

Epoch: 6| Step: 11
Training loss: 2.032115936279297
Validation loss: 2.0641448702863467

Epoch: 6| Step: 12
Training loss: 1.7765306234359741
Validation loss: 2.0757456389806603

Epoch: 6| Step: 13
Training loss: 0.9657980799674988
Validation loss: 2.099025095662763

Epoch: 199| Step: 0
Training loss: 2.4627327919006348
Validation loss: 2.0646495447363904

Epoch: 6| Step: 1
Training loss: 2.4240853786468506
Validation loss: 2.0771428897816646

Epoch: 6| Step: 2
Training loss: 2.4958157539367676
Validation loss: 2.0845851641829296

Epoch: 6| Step: 3
Training loss: 2.2881321907043457
Validation loss: 2.063514801763719

Epoch: 6| Step: 4
Training loss: 1.693144679069519
Validation loss: 2.06226178907579

Epoch: 6| Step: 5
Training loss: 1.7708961963653564
Validation loss: 2.0593658621593187

Epoch: 6| Step: 6
Training loss: 1.6866111755371094
Validation loss: 2.0720914692007084

Epoch: 6| Step: 7
Training loss: 2.335294246673584
Validation loss: 2.0305799861108103

Epoch: 6| Step: 8
Training loss: 1.592801809310913
Validation loss: 2.034740729998517

Epoch: 6| Step: 9
Training loss: 1.5066999197006226
Validation loss: 2.0855279814812446

Epoch: 6| Step: 10
Training loss: 1.996326208114624
Validation loss: 2.0510723975396927

Epoch: 6| Step: 11
Training loss: 2.567328453063965
Validation loss: 2.0551889506719445

Epoch: 6| Step: 12
Training loss: 2.0107614994049072
Validation loss: 2.057959259197276

Epoch: 6| Step: 13
Training loss: 2.257122755050659
Validation loss: 2.056085236610905

Epoch: 200| Step: 0
Training loss: 2.511314868927002
Validation loss: 2.0600847864663727

Epoch: 6| Step: 1
Training loss: 2.248039722442627
Validation loss: 2.077781705446141

Epoch: 6| Step: 2
Training loss: 1.4781663417816162
Validation loss: 2.07040435652579

Epoch: 6| Step: 3
Training loss: 2.1225521564483643
Validation loss: 2.0970044776957524

Epoch: 6| Step: 4
Training loss: 1.6727561950683594
Validation loss: 2.064034658093606

Epoch: 6| Step: 5
Training loss: 2.212639093399048
Validation loss: 2.079401962218746

Epoch: 6| Step: 6
Training loss: 1.8949978351593018
Validation loss: 2.030560948515451

Epoch: 6| Step: 7
Training loss: 1.744396448135376
Validation loss: 2.0896205415007887

Epoch: 6| Step: 8
Training loss: 2.3074350357055664
Validation loss: 2.0765211043819303

Epoch: 6| Step: 9
Training loss: 2.034473419189453
Validation loss: 2.0811279666039253

Epoch: 6| Step: 10
Training loss: 1.6774697303771973
Validation loss: 2.0635066134955293

Epoch: 6| Step: 11
Training loss: 2.2862515449523926
Validation loss: 2.0385482465067217

Epoch: 6| Step: 12
Training loss: 2.316201686859131
Validation loss: 2.079340160533946

Epoch: 6| Step: 13
Training loss: 1.9146571159362793
Validation loss: 2.073603727484262

Testing loss: 2.00636994043986
