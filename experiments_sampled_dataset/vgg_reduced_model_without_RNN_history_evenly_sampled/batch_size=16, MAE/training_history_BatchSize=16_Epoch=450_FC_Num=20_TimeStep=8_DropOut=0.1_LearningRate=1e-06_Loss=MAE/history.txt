Epoch: 1| Step: 0
Training loss: 6.403015613555908
Validation loss: 6.54057175626037

Epoch: 6| Step: 1
Training loss: 7.4705491065979
Validation loss: 6.539023696735341

Epoch: 6| Step: 2
Training loss: 5.648873805999756
Validation loss: 6.535286693162815

Epoch: 6| Step: 3
Training loss: 5.86217737197876
Validation loss: 6.530268664001136

Epoch: 6| Step: 4
Training loss: 5.670487880706787
Validation loss: 6.529083908245128

Epoch: 6| Step: 5
Training loss: 6.4162163734436035
Validation loss: 6.524817123207995

Epoch: 6| Step: 6
Training loss: 8.111390113830566
Validation loss: 6.521783003243067

Epoch: 6| Step: 7
Training loss: 5.9971771240234375
Validation loss: 6.517538368061024

Epoch: 6| Step: 8
Training loss: 6.574314117431641
Validation loss: 6.515681415475825

Epoch: 6| Step: 9
Training loss: 5.393716812133789
Validation loss: 6.512336997575657

Epoch: 6| Step: 10
Training loss: 5.758411884307861
Validation loss: 6.506007753392701

Epoch: 6| Step: 11
Training loss: 5.887674331665039
Validation loss: 6.505497865779425

Epoch: 6| Step: 12
Training loss: 6.806217670440674
Validation loss: 6.500781095156106

Epoch: 6| Step: 13
Training loss: 6.529386520385742
Validation loss: 6.498690220617479

Epoch: 2| Step: 0
Training loss: 5.981122016906738
Validation loss: 6.495997844203826

Epoch: 6| Step: 1
Training loss: 5.275607585906982
Validation loss: 6.492143918109196

Epoch: 6| Step: 2
Training loss: 6.526816368103027
Validation loss: 6.4909191593047115

Epoch: 6| Step: 3
Training loss: 5.85723876953125
Validation loss: 6.486443873374693

Epoch: 6| Step: 4
Training loss: 5.934454441070557
Validation loss: 6.483062692867812

Epoch: 6| Step: 5
Training loss: 6.577823162078857
Validation loss: 6.4807743513455955

Epoch: 6| Step: 6
Training loss: 6.200176239013672
Validation loss: 6.473816384551346

Epoch: 6| Step: 7
Training loss: 5.740179061889648
Validation loss: 6.474003345735611

Epoch: 6| Step: 8
Training loss: 6.571787357330322
Validation loss: 6.467906193066669

Epoch: 6| Step: 9
Training loss: 4.707260608673096
Validation loss: 6.467197207994358

Epoch: 6| Step: 10
Training loss: 7.346146583557129
Validation loss: 6.464410212732131

Epoch: 6| Step: 11
Training loss: 7.01698112487793
Validation loss: 6.458142977888866

Epoch: 6| Step: 12
Training loss: 7.4849853515625
Validation loss: 6.456483194904942

Epoch: 6| Step: 13
Training loss: 6.75595235824585
Validation loss: 6.45119733195151

Epoch: 3| Step: 0
Training loss: 6.02482795715332
Validation loss: 6.44691486256097

Epoch: 6| Step: 1
Training loss: 7.022648811340332
Validation loss: 6.445298851177257

Epoch: 6| Step: 2
Training loss: 7.229194164276123
Validation loss: 6.4426399815467095

Epoch: 6| Step: 3
Training loss: 5.414689064025879
Validation loss: 6.440136058356172

Epoch: 6| Step: 4
Training loss: 4.330722808837891
Validation loss: 6.436055516683927

Epoch: 6| Step: 5
Training loss: 6.022368907928467
Validation loss: 6.4317535841336815

Epoch: 6| Step: 6
Training loss: 7.296754837036133
Validation loss: 6.4305054039083505

Epoch: 6| Step: 7
Training loss: 6.646299362182617
Validation loss: 6.424910499203589

Epoch: 6| Step: 8
Training loss: 5.844018936157227
Validation loss: 6.426601307366484

Epoch: 6| Step: 9
Training loss: 5.979698181152344
Validation loss: 6.418877201695596

Epoch: 6| Step: 10
Training loss: 6.753182888031006
Validation loss: 6.414921283721924

Epoch: 6| Step: 11
Training loss: 4.492736339569092
Validation loss: 6.411737847071822

Epoch: 6| Step: 12
Training loss: 6.975095272064209
Validation loss: 6.410269783389184

Epoch: 6| Step: 13
Training loss: 7.729915142059326
Validation loss: 6.403443305723129

Epoch: 4| Step: 0
Training loss: 6.761908531188965
Validation loss: 6.4024722191595265

Epoch: 6| Step: 1
Training loss: 4.69526481628418
Validation loss: 6.396270828862344

Epoch: 6| Step: 2
Training loss: 6.0012969970703125
Validation loss: 6.393495703256258

Epoch: 6| Step: 3
Training loss: 5.7972412109375
Validation loss: 6.3931744431936615

Epoch: 6| Step: 4
Training loss: 5.594648361206055
Validation loss: 6.388968939422279

Epoch: 6| Step: 5
Training loss: 7.074128150939941
Validation loss: 6.384233715713665

Epoch: 6| Step: 6
Training loss: 6.965371131896973
Validation loss: 6.381048156369117

Epoch: 6| Step: 7
Training loss: 5.734344482421875
Validation loss: 6.377391046093356

Epoch: 6| Step: 8
Training loss: 5.56785774230957
Validation loss: 6.37463701412242

Epoch: 6| Step: 9
Training loss: 5.869598388671875
Validation loss: 6.373525255469866

Epoch: 6| Step: 10
Training loss: 6.867585182189941
Validation loss: 6.36881314041794

Epoch: 6| Step: 11
Training loss: 6.754091262817383
Validation loss: 6.363003997392552

Epoch: 6| Step: 12
Training loss: 6.407953262329102
Validation loss: 6.3604610197005735

Epoch: 6| Step: 13
Training loss: 6.372474193572998
Validation loss: 6.355495052952921

Epoch: 5| Step: 0
Training loss: 5.263960361480713
Validation loss: 6.352672238503733

Epoch: 6| Step: 1
Training loss: 6.221323490142822
Validation loss: 6.3471534329075965

Epoch: 6| Step: 2
Training loss: 6.97342586517334
Validation loss: 6.344776712438112

Epoch: 6| Step: 3
Training loss: 6.691019058227539
Validation loss: 6.342613702179284

Epoch: 6| Step: 4
Training loss: 6.0041375160217285
Validation loss: 6.336216967592957

Epoch: 6| Step: 5
Training loss: 6.456121444702148
Validation loss: 6.335463995574623

Epoch: 6| Step: 6
Training loss: 6.593018531799316
Validation loss: 6.331461409086822

Epoch: 6| Step: 7
Training loss: 5.5273756980896
Validation loss: 6.323838423657161

Epoch: 6| Step: 8
Training loss: 5.414772987365723
Validation loss: 6.322441439474782

Epoch: 6| Step: 9
Training loss: 5.8549652099609375
Validation loss: 6.3196948523162515

Epoch: 6| Step: 10
Training loss: 5.815396308898926
Validation loss: 6.314796524663126

Epoch: 6| Step: 11
Training loss: 5.212366580963135
Validation loss: 6.309386273866059

Epoch: 6| Step: 12
Training loss: 6.718700408935547
Validation loss: 6.305951097960113

Epoch: 6| Step: 13
Training loss: 7.467098712921143
Validation loss: 6.302205783064648

Epoch: 6| Step: 0
Training loss: 5.560458183288574
Validation loss: 6.2926652918579755

Epoch: 6| Step: 1
Training loss: 7.392157554626465
Validation loss: 6.292371134604177

Epoch: 6| Step: 2
Training loss: 7.408005714416504
Validation loss: 6.284558306458176

Epoch: 6| Step: 3
Training loss: 5.226616859436035
Validation loss: 6.281200619154079

Epoch: 6| Step: 4
Training loss: 6.892085075378418
Validation loss: 6.2783954681888705

Epoch: 6| Step: 5
Training loss: 6.446203231811523
Validation loss: 6.272863987953432

Epoch: 6| Step: 6
Training loss: 6.127974510192871
Validation loss: 6.265214227860974

Epoch: 6| Step: 7
Training loss: 5.467127799987793
Validation loss: 6.26410557634087

Epoch: 6| Step: 8
Training loss: 7.2236127853393555
Validation loss: 6.254137782640354

Epoch: 6| Step: 9
Training loss: 4.961505889892578
Validation loss: 6.253336327050322

Epoch: 6| Step: 10
Training loss: 4.594961166381836
Validation loss: 6.241948276437739

Epoch: 6| Step: 11
Training loss: 5.914060592651367
Validation loss: 6.242123619202645

Epoch: 6| Step: 12
Training loss: 5.498686790466309
Validation loss: 6.235353341666601

Epoch: 6| Step: 13
Training loss: 5.989530563354492
Validation loss: 6.22951772136073

Epoch: 7| Step: 0
Training loss: 4.632737636566162
Validation loss: 6.219591961112074

Epoch: 6| Step: 1
Training loss: 6.741217613220215
Validation loss: 6.217985501853368

Epoch: 6| Step: 2
Training loss: 6.138249397277832
Validation loss: 6.208474343822848

Epoch: 6| Step: 3
Training loss: 6.345159530639648
Validation loss: 6.2040531609648015

Epoch: 6| Step: 4
Training loss: 6.503110408782959
Validation loss: 6.202257689609323

Epoch: 6| Step: 5
Training loss: 5.935946464538574
Validation loss: 6.19229644344699

Epoch: 6| Step: 6
Training loss: 7.247201919555664
Validation loss: 6.186867842110255

Epoch: 6| Step: 7
Training loss: 5.980954170227051
Validation loss: 6.177772455317999

Epoch: 6| Step: 8
Training loss: 5.050785064697266
Validation loss: 6.171829720979096

Epoch: 6| Step: 9
Training loss: 6.158585071563721
Validation loss: 6.164947089328561

Epoch: 6| Step: 10
Training loss: 4.437964916229248
Validation loss: 6.161698074751003

Epoch: 6| Step: 11
Training loss: 5.406156539916992
Validation loss: 6.1496847060418895

Epoch: 6| Step: 12
Training loss: 6.57405948638916
Validation loss: 6.144515498991935

Epoch: 6| Step: 13
Training loss: 6.683436393737793
Validation loss: 6.138312811492591

Epoch: 8| Step: 0
Training loss: 5.702300548553467
Validation loss: 6.134296191635952

Epoch: 6| Step: 1
Training loss: 5.8376641273498535
Validation loss: 6.126965656075426

Epoch: 6| Step: 2
Training loss: 5.444408416748047
Validation loss: 6.120443718407744

Epoch: 6| Step: 3
Training loss: 6.5821638107299805
Validation loss: 6.110196744242022

Epoch: 6| Step: 4
Training loss: 7.696005821228027
Validation loss: 6.105567783437749

Epoch: 6| Step: 5
Training loss: 5.004091262817383
Validation loss: 6.098160200221564

Epoch: 6| Step: 6
Training loss: 5.428333282470703
Validation loss: 6.0926910625991

Epoch: 6| Step: 7
Training loss: 5.744267463684082
Validation loss: 6.084587512477752

Epoch: 6| Step: 8
Training loss: 5.597174644470215
Validation loss: 6.078195571899414

Epoch: 6| Step: 9
Training loss: 5.938313007354736
Validation loss: 6.070589752607448

Epoch: 6| Step: 10
Training loss: 5.770224571228027
Validation loss: 6.061324140076996

Epoch: 6| Step: 11
Training loss: 6.444040298461914
Validation loss: 6.055267841585221

Epoch: 6| Step: 12
Training loss: 5.762972831726074
Validation loss: 6.047107460678265

Epoch: 6| Step: 13
Training loss: 4.730449199676514
Validation loss: 6.042286401153893

Epoch: 9| Step: 0
Training loss: 7.822475910186768
Validation loss: 6.034688231765583

Epoch: 6| Step: 1
Training loss: 5.295073509216309
Validation loss: 6.0272006680888515

Epoch: 6| Step: 2
Training loss: 6.464539527893066
Validation loss: 6.0149322068819435

Epoch: 6| Step: 3
Training loss: 4.440978527069092
Validation loss: 6.008279472269038

Epoch: 6| Step: 4
Training loss: 6.598294258117676
Validation loss: 6.000557914856942

Epoch: 6| Step: 5
Training loss: 5.498373985290527
Validation loss: 5.988279624651837

Epoch: 6| Step: 6
Training loss: 5.381966590881348
Validation loss: 5.984490322810347

Epoch: 6| Step: 7
Training loss: 6.010359287261963
Validation loss: 5.975381753777945

Epoch: 6| Step: 8
Training loss: 5.625146865844727
Validation loss: 5.966912715665756

Epoch: 6| Step: 9
Training loss: 5.822726249694824
Validation loss: 5.957626414555375

Epoch: 6| Step: 10
Training loss: 5.480973720550537
Validation loss: 5.9518998002493255

Epoch: 6| Step: 11
Training loss: 5.049992084503174
Validation loss: 5.9438537269510245

Epoch: 6| Step: 12
Training loss: 5.908081531524658
Validation loss: 5.936745648743004

Epoch: 6| Step: 13
Training loss: 4.820984840393066
Validation loss: 5.924972175269999

Epoch: 10| Step: 0
Training loss: 6.686186790466309
Validation loss: 5.916224356620543

Epoch: 6| Step: 1
Training loss: 5.065952777862549
Validation loss: 5.906994055676204

Epoch: 6| Step: 2
Training loss: 5.518189907073975
Validation loss: 5.8958284008887505

Epoch: 6| Step: 3
Training loss: 6.058619499206543
Validation loss: 5.891130529424196

Epoch: 6| Step: 4
Training loss: 5.9438581466674805
Validation loss: 5.880759362251528

Epoch: 6| Step: 5
Training loss: 5.293248176574707
Validation loss: 5.866593637774067

Epoch: 6| Step: 6
Training loss: 5.173900604248047
Validation loss: 5.859792104331396

Epoch: 6| Step: 7
Training loss: 5.2322587966918945
Validation loss: 5.854201034833026

Epoch: 6| Step: 8
Training loss: 5.752459526062012
Validation loss: 5.841615482043195

Epoch: 6| Step: 9
Training loss: 5.402172565460205
Validation loss: 5.827422116392402

Epoch: 6| Step: 10
Training loss: 4.826775074005127
Validation loss: 5.821454996703773

Epoch: 6| Step: 11
Training loss: 6.450779438018799
Validation loss: 5.809279159833026

Epoch: 6| Step: 12
Training loss: 5.098189353942871
Validation loss: 5.794029646022345

Epoch: 6| Step: 13
Training loss: 6.8269782066345215
Validation loss: 5.788056317196097

Epoch: 11| Step: 0
Training loss: 6.456787109375
Validation loss: 5.777387362654491

Epoch: 6| Step: 1
Training loss: 5.977408409118652
Validation loss: 5.766028916963967

Epoch: 6| Step: 2
Training loss: 4.711019515991211
Validation loss: 5.755568894006872

Epoch: 6| Step: 3
Training loss: 5.501683235168457
Validation loss: 5.741445633672899

Epoch: 6| Step: 4
Training loss: 5.5345354080200195
Validation loss: 5.731305701758272

Epoch: 6| Step: 5
Training loss: 5.909298419952393
Validation loss: 5.7202433155428976

Epoch: 6| Step: 6
Training loss: 5.642885684967041
Validation loss: 5.710313909797258

Epoch: 6| Step: 7
Training loss: 5.531913757324219
Validation loss: 5.696696999252484

Epoch: 6| Step: 8
Training loss: 4.271439552307129
Validation loss: 5.688630606538506

Epoch: 6| Step: 9
Training loss: 5.277225494384766
Validation loss: 5.67738861678749

Epoch: 6| Step: 10
Training loss: 6.2899956703186035
Validation loss: 5.661581208628993

Epoch: 6| Step: 11
Training loss: 4.4164533615112305
Validation loss: 5.654221560365411

Epoch: 6| Step: 12
Training loss: 5.646756649017334
Validation loss: 5.640133160416798

Epoch: 6| Step: 13
Training loss: 5.5069661140441895
Validation loss: 5.629922948857789

Epoch: 12| Step: 0
Training loss: 5.151516437530518
Validation loss: 5.615151261770597

Epoch: 6| Step: 1
Training loss: 6.782629013061523
Validation loss: 5.6024331482507845

Epoch: 6| Step: 2
Training loss: 5.868196487426758
Validation loss: 5.588927915019374

Epoch: 6| Step: 3
Training loss: 4.595014572143555
Validation loss: 5.578947190315493

Epoch: 6| Step: 4
Training loss: 5.489992141723633
Validation loss: 5.562050373323502

Epoch: 6| Step: 5
Training loss: 5.7902936935424805
Validation loss: 5.551331617498911

Epoch: 6| Step: 6
Training loss: 4.876011848449707
Validation loss: 5.5336891861372095

Epoch: 6| Step: 7
Training loss: 5.919734001159668
Validation loss: 5.526925517666724

Epoch: 6| Step: 8
Training loss: 5.335284233093262
Validation loss: 5.504048142381894

Epoch: 6| Step: 9
Training loss: 5.610579490661621
Validation loss: 5.494503113531297

Epoch: 6| Step: 10
Training loss: 4.8981757164001465
Validation loss: 5.4833358282684

Epoch: 6| Step: 11
Training loss: 4.272211074829102
Validation loss: 5.465558077699395

Epoch: 6| Step: 12
Training loss: 5.223132133483887
Validation loss: 5.454088462296353

Epoch: 6| Step: 13
Training loss: 3.5392537117004395
Validation loss: 5.440113600864206

Epoch: 13| Step: 0
Training loss: 4.974435806274414
Validation loss: 5.427485225021198

Epoch: 6| Step: 1
Training loss: 5.6576690673828125
Validation loss: 5.405908887104322

Epoch: 6| Step: 2
Training loss: 7.030655860900879
Validation loss: 5.3920849318145425

Epoch: 6| Step: 3
Training loss: 4.280200958251953
Validation loss: 5.377681655268515

Epoch: 6| Step: 4
Training loss: 5.612283706665039
Validation loss: 5.365568694247995

Epoch: 6| Step: 5
Training loss: 3.8926475048065186
Validation loss: 5.354877605233141

Epoch: 6| Step: 6
Training loss: 5.264069080352783
Validation loss: 5.3317264792739705

Epoch: 6| Step: 7
Training loss: 4.888113498687744
Validation loss: 5.319102051437542

Epoch: 6| Step: 8
Training loss: 6.2228803634643555
Validation loss: 5.296169742461173

Epoch: 6| Step: 9
Training loss: 4.069051265716553
Validation loss: 5.282024091289889

Epoch: 6| Step: 10
Training loss: 5.377660274505615
Validation loss: 5.2636343689375025

Epoch: 6| Step: 11
Training loss: 5.191529273986816
Validation loss: 5.243842719703593

Epoch: 6| Step: 12
Training loss: 4.130132675170898
Validation loss: 5.241326685874693

Epoch: 6| Step: 13
Training loss: 4.116995334625244
Validation loss: 5.223909762597853

Epoch: 14| Step: 0
Training loss: 5.009675979614258
Validation loss: 5.199234203625751

Epoch: 6| Step: 1
Training loss: 4.06309175491333
Validation loss: 5.184968256181286

Epoch: 6| Step: 2
Training loss: 4.723647117614746
Validation loss: 5.158316232824839

Epoch: 6| Step: 3
Training loss: 6.051953315734863
Validation loss: 5.142564847905149

Epoch: 6| Step: 4
Training loss: 3.536235809326172
Validation loss: 5.125331258261076

Epoch: 6| Step: 5
Training loss: 3.561858892440796
Validation loss: 5.109620730082194

Epoch: 6| Step: 6
Training loss: 4.599194049835205
Validation loss: 5.099813815086119

Epoch: 6| Step: 7
Training loss: 4.698243141174316
Validation loss: 5.067115640127531

Epoch: 6| Step: 8
Training loss: 5.889361381530762
Validation loss: 5.054752719017767

Epoch: 6| Step: 9
Training loss: 4.505985260009766
Validation loss: 5.030871760460638

Epoch: 6| Step: 10
Training loss: 6.5953569412231445
Validation loss: 5.01539965598814

Epoch: 6| Step: 11
Training loss: 3.519085645675659
Validation loss: 4.987689274613575

Epoch: 6| Step: 12
Training loss: 5.668282985687256
Validation loss: 4.971383340897098

Epoch: 6| Step: 13
Training loss: 5.628849029541016
Validation loss: 4.961051274371403

Epoch: 15| Step: 0
Training loss: 4.749776363372803
Validation loss: 4.935607115427653

Epoch: 6| Step: 1
Training loss: 3.666813373565674
Validation loss: 4.906087572856616

Epoch: 6| Step: 2
Training loss: 4.401095867156982
Validation loss: 4.896158684966385

Epoch: 6| Step: 3
Training loss: 4.220730781555176
Validation loss: 4.870544982212846

Epoch: 6| Step: 4
Training loss: 4.7029194831848145
Validation loss: 4.852292368488927

Epoch: 6| Step: 5
Training loss: 5.441022872924805
Validation loss: 4.834674055858325

Epoch: 6| Step: 6
Training loss: 3.5520482063293457
Validation loss: 4.809418211701096

Epoch: 6| Step: 7
Training loss: 5.700634002685547
Validation loss: 4.791343581291937

Epoch: 6| Step: 8
Training loss: 4.998335361480713
Validation loss: 4.770375708098053

Epoch: 6| Step: 9
Training loss: 5.023365497589111
Validation loss: 4.7462820750410835

Epoch: 6| Step: 10
Training loss: 3.83235239982605
Validation loss: 4.7184454907653155

Epoch: 6| Step: 11
Training loss: 4.68250846862793
Validation loss: 4.70024311414329

Epoch: 6| Step: 12
Training loss: 4.338013172149658
Validation loss: 4.677712035435502

Epoch: 6| Step: 13
Training loss: 4.288057804107666
Validation loss: 4.659101901515838

Epoch: 16| Step: 0
Training loss: 2.937840461730957
Validation loss: 4.640390039772115

Epoch: 6| Step: 1
Training loss: 4.17156982421875
Validation loss: 4.618950041391516

Epoch: 6| Step: 2
Training loss: 4.2461137771606445
Validation loss: 4.586652550646054

Epoch: 6| Step: 3
Training loss: 4.132136344909668
Validation loss: 4.567149592984107

Epoch: 6| Step: 4
Training loss: 3.594747304916382
Validation loss: 4.539337635040283

Epoch: 6| Step: 5
Training loss: 4.51654052734375
Validation loss: 4.5158312397618445

Epoch: 6| Step: 6
Training loss: 4.813088417053223
Validation loss: 4.488425752168061

Epoch: 6| Step: 7
Training loss: 4.119062900543213
Validation loss: 4.473949334954702

Epoch: 6| Step: 8
Training loss: 3.887535810470581
Validation loss: 4.428975184758504

Epoch: 6| Step: 9
Training loss: 4.571333408355713
Validation loss: 4.421599249685964

Epoch: 6| Step: 10
Training loss: 5.291971683502197
Validation loss: 4.393509728934175

Epoch: 6| Step: 11
Training loss: 4.4891204833984375
Validation loss: 4.382244779217627

Epoch: 6| Step: 12
Training loss: 4.452805519104004
Validation loss: 4.342387476275044

Epoch: 6| Step: 13
Training loss: 4.190032958984375
Validation loss: 4.325865237943588

Epoch: 17| Step: 0
Training loss: 3.7991743087768555
Validation loss: 4.30116335550944

Epoch: 6| Step: 1
Training loss: 3.7275476455688477
Validation loss: 4.271264030087378

Epoch: 6| Step: 2
Training loss: 3.6853721141815186
Validation loss: 4.27965485665106

Epoch: 6| Step: 3
Training loss: 5.1912360191345215
Validation loss: 4.225350003088674

Epoch: 6| Step: 4
Training loss: 5.293481349945068
Validation loss: 4.191811289838565

Epoch: 6| Step: 5
Training loss: 4.239157676696777
Validation loss: 4.183221670889085

Epoch: 6| Step: 6
Training loss: 3.606926679611206
Validation loss: 4.166398212473879

Epoch: 6| Step: 7
Training loss: 3.813448429107666
Validation loss: 4.120175110396518

Epoch: 6| Step: 8
Training loss: 3.1561484336853027
Validation loss: 4.104247426473966

Epoch: 6| Step: 9
Training loss: 3.876065254211426
Validation loss: 4.0708843149164675

Epoch: 6| Step: 10
Training loss: 4.450754165649414
Validation loss: 4.053427673155261

Epoch: 6| Step: 11
Training loss: 3.0523722171783447
Validation loss: 4.0296022148542505

Epoch: 6| Step: 12
Training loss: 2.3284435272216797
Validation loss: 3.993297976832236

Epoch: 6| Step: 13
Training loss: 5.175477981567383
Validation loss: 3.9709516084322365

Epoch: 18| Step: 0
Training loss: 3.555333137512207
Validation loss: 3.9558407311798423

Epoch: 6| Step: 1
Training loss: 3.639519214630127
Validation loss: 3.9225654448232343

Epoch: 6| Step: 2
Training loss: 3.5817105770111084
Validation loss: 3.8935094802610335

Epoch: 6| Step: 3
Training loss: 4.77755069732666
Validation loss: 3.8646075238463697

Epoch: 6| Step: 4
Training loss: 3.303295135498047
Validation loss: 3.8561271082970405

Epoch: 6| Step: 5
Training loss: 3.3838539123535156
Validation loss: 3.823182946892195

Epoch: 6| Step: 6
Training loss: 4.7748613357543945
Validation loss: 3.8036469439024567

Epoch: 6| Step: 7
Training loss: 3.4057106971740723
Validation loss: 3.7627963481410855

Epoch: 6| Step: 8
Training loss: 2.940767288208008
Validation loss: 3.7487954683201288

Epoch: 6| Step: 9
Training loss: 3.7349390983581543
Validation loss: 3.7292165756225586

Epoch: 6| Step: 10
Training loss: 3.6867294311523438
Validation loss: 3.7113499513236423

Epoch: 6| Step: 11
Training loss: 2.9708967208862305
Validation loss: 3.668260943505072

Epoch: 6| Step: 12
Training loss: 3.701542854309082
Validation loss: 3.6495389066716677

Epoch: 6| Step: 13
Training loss: 3.3204336166381836
Validation loss: 3.6161605927252

Epoch: 19| Step: 0
Training loss: 2.6918835639953613
Validation loss: 3.6079881242526475

Epoch: 6| Step: 1
Training loss: 3.5537257194519043
Validation loss: 3.5911317948372132

Epoch: 6| Step: 2
Training loss: 2.6748523712158203
Validation loss: 3.5621604611796718

Epoch: 6| Step: 3
Training loss: 3.694641351699829
Validation loss: 3.5471566595057005

Epoch: 6| Step: 4
Training loss: 3.3841261863708496
Validation loss: 3.5251333149530555

Epoch: 6| Step: 5
Training loss: 2.0766780376434326
Validation loss: 3.481663409099784

Epoch: 6| Step: 6
Training loss: 5.050046920776367
Validation loss: 3.502500218729819

Epoch: 6| Step: 7
Training loss: 3.6438560485839844
Validation loss: 3.4446167125496814

Epoch: 6| Step: 8
Training loss: 3.344515800476074
Validation loss: 3.4333347633320797

Epoch: 6| Step: 9
Training loss: 3.0829060077667236
Validation loss: 3.395346536431261

Epoch: 6| Step: 10
Training loss: 4.303136825561523
Validation loss: 3.393894621120986

Epoch: 6| Step: 11
Training loss: 2.4605720043182373
Validation loss: 3.369404746640113

Epoch: 6| Step: 12
Training loss: 3.490670680999756
Validation loss: 3.3312398515721804

Epoch: 6| Step: 13
Training loss: 3.303388833999634
Validation loss: 3.3168346907502864

Epoch: 20| Step: 0
Training loss: 2.5116302967071533
Validation loss: 3.292123948374102

Epoch: 6| Step: 1
Training loss: 2.7788915634155273
Validation loss: 3.2463264952423754

Epoch: 6| Step: 2
Training loss: 3.171004295349121
Validation loss: 3.254318057849843

Epoch: 6| Step: 3
Training loss: 3.4379796981811523
Validation loss: 3.215300352342667

Epoch: 6| Step: 4
Training loss: 2.772695541381836
Validation loss: 3.2022255902649253

Epoch: 6| Step: 5
Training loss: 3.7125742435455322
Validation loss: 3.17109086180246

Epoch: 6| Step: 6
Training loss: 3.407033920288086
Validation loss: 3.146444130969304

Epoch: 6| Step: 7
Training loss: 2.2960689067840576
Validation loss: 3.143143956379224

Epoch: 6| Step: 8
Training loss: 2.5657577514648438
Validation loss: 3.10246189178959

Epoch: 6| Step: 9
Training loss: 3.491699695587158
Validation loss: 3.0982494559339298

Epoch: 6| Step: 10
Training loss: 3.27683424949646
Validation loss: 3.0775091032828055

Epoch: 6| Step: 11
Training loss: 3.259510040283203
Validation loss: 3.0579786044295116

Epoch: 6| Step: 12
Training loss: 4.019737720489502
Validation loss: 3.0485142097678235

Epoch: 6| Step: 13
Training loss: 2.1954736709594727
Validation loss: 3.004425225719329

Epoch: 21| Step: 0
Training loss: 2.206376791000366
Validation loss: 2.998369191282539

Epoch: 6| Step: 1
Training loss: 2.3808858394622803
Validation loss: 2.9717262380866596

Epoch: 6| Step: 2
Training loss: 2.3022382259368896
Validation loss: 2.925036948214295

Epoch: 6| Step: 3
Training loss: 4.169844150543213
Validation loss: 2.92922527815706

Epoch: 6| Step: 4
Training loss: 3.355858325958252
Validation loss: 2.910235176804245

Epoch: 6| Step: 5
Training loss: 2.6579761505126953
Validation loss: 2.8742258189826884

Epoch: 6| Step: 6
Training loss: 2.9401564598083496
Validation loss: 2.8644447326660156

Epoch: 6| Step: 7
Training loss: 2.627365827560425
Validation loss: 2.8359198160068964

Epoch: 6| Step: 8
Training loss: 2.682727336883545
Validation loss: 2.8217030545716644

Epoch: 6| Step: 9
Training loss: 2.9079060554504395
Validation loss: 2.8153718133126535

Epoch: 6| Step: 10
Training loss: 3.4204342365264893
Validation loss: 2.766184737605433

Epoch: 6| Step: 11
Training loss: 3.039069175720215
Validation loss: 2.7714802577931392

Epoch: 6| Step: 12
Training loss: 3.5913352966308594
Validation loss: 2.750444386595039

Epoch: 6| Step: 13
Training loss: 1.8235459327697754
Validation loss: 2.710485476319508

Epoch: 22| Step: 0
Training loss: 2.8732428550720215
Validation loss: 2.6988566075601885

Epoch: 6| Step: 1
Training loss: 3.301445960998535
Validation loss: 2.698417035482263

Epoch: 6| Step: 2
Training loss: 2.1790130138397217
Validation loss: 2.6959429376868793

Epoch: 6| Step: 3
Training loss: 3.4718992710113525
Validation loss: 2.654939805307696

Epoch: 6| Step: 4
Training loss: 2.4665088653564453
Validation loss: 2.6444265816801336

Epoch: 6| Step: 5
Training loss: 3.2371344566345215
Validation loss: 2.635920222087573

Epoch: 6| Step: 6
Training loss: 2.4634013175964355
Validation loss: 2.595590353012085

Epoch: 6| Step: 7
Training loss: 3.3765201568603516
Validation loss: 2.5861027650935675

Epoch: 6| Step: 8
Training loss: 1.8171676397323608
Validation loss: 2.5991178558718775

Epoch: 6| Step: 9
Training loss: 2.811383008956909
Validation loss: 2.5402742047463693

Epoch: 6| Step: 10
Training loss: 2.761110305786133
Validation loss: 2.541365382491901

Epoch: 6| Step: 11
Training loss: 1.798889398574829
Validation loss: 2.513494032685475

Epoch: 6| Step: 12
Training loss: 2.700751304626465
Validation loss: 2.5046692971260316

Epoch: 6| Step: 13
Training loss: 3.1264524459838867
Validation loss: 2.483008953832811

Epoch: 23| Step: 0
Training loss: 2.4924960136413574
Validation loss: 2.4775497990269817

Epoch: 6| Step: 1
Training loss: 2.853483200073242
Validation loss: 2.4851615057196668

Epoch: 6| Step: 2
Training loss: 2.040172815322876
Validation loss: 2.4712593657996065

Epoch: 6| Step: 3
Training loss: 2.2745018005371094
Validation loss: 2.4630354040412494

Epoch: 6| Step: 4
Training loss: 2.5689096450805664
Validation loss: 2.458582885803715

Epoch: 6| Step: 5
Training loss: 2.239248275756836
Validation loss: 2.431722410263554

Epoch: 6| Step: 6
Training loss: 2.7004034519195557
Validation loss: 2.426696003124278

Epoch: 6| Step: 7
Training loss: 2.1544642448425293
Validation loss: 2.424421056624382

Epoch: 6| Step: 8
Training loss: 2.615438222885132
Validation loss: 2.419463793436686

Epoch: 6| Step: 9
Training loss: 2.8566336631774902
Validation loss: 2.3450943808401785

Epoch: 6| Step: 10
Training loss: 3.3086307048797607
Validation loss: 2.391894885288772

Epoch: 6| Step: 11
Training loss: 3.3820254802703857
Validation loss: 2.368773547551965

Epoch: 6| Step: 12
Training loss: 2.1462955474853516
Validation loss: 2.387398627496535

Epoch: 6| Step: 13
Training loss: 2.8867082595825195
Validation loss: 2.3711851796796246

Epoch: 24| Step: 0
Training loss: 2.042577028274536
Validation loss: 2.3321728347450175

Epoch: 6| Step: 1
Training loss: 2.124847412109375
Validation loss: 2.3432545046652518

Epoch: 6| Step: 2
Training loss: 2.301151990890503
Validation loss: 2.3460866071844615

Epoch: 6| Step: 3
Training loss: 3.3540258407592773
Validation loss: 2.35428132805773

Epoch: 6| Step: 4
Training loss: 2.8923966884613037
Validation loss: 2.3211763802395073

Epoch: 6| Step: 5
Training loss: 1.707176685333252
Validation loss: 2.323442143778647

Epoch: 6| Step: 6
Training loss: 2.2666921615600586
Validation loss: 2.320767923067975

Epoch: 6| Step: 7
Training loss: 2.9276716709136963
Validation loss: 2.3034299394135833

Epoch: 6| Step: 8
Training loss: 2.4973807334899902
Validation loss: 2.3048588563037176

Epoch: 6| Step: 9
Training loss: 2.640202522277832
Validation loss: 2.2990110715230307

Epoch: 6| Step: 10
Training loss: 2.293564796447754
Validation loss: 2.3146364150508756

Epoch: 6| Step: 11
Training loss: 2.813342809677124
Validation loss: 2.291527389198221

Epoch: 6| Step: 12
Training loss: 2.8209214210510254
Validation loss: 2.297662401712069

Epoch: 6| Step: 13
Training loss: 2.784209966659546
Validation loss: 2.282708203920754

Epoch: 25| Step: 0
Training loss: 2.4338231086730957
Validation loss: 2.300820040446456

Epoch: 6| Step: 1
Training loss: 3.272347927093506
Validation loss: 2.292678589461952

Epoch: 6| Step: 2
Training loss: 2.4085395336151123
Validation loss: 2.266003777903895

Epoch: 6| Step: 3
Training loss: 1.7260513305664062
Validation loss: 2.272027956542148

Epoch: 6| Step: 4
Training loss: 2.6577343940734863
Validation loss: 2.2804339983130015

Epoch: 6| Step: 5
Training loss: 2.099440097808838
Validation loss: 2.276428980212058

Epoch: 6| Step: 6
Training loss: 2.634089469909668
Validation loss: 2.2838023759985484

Epoch: 6| Step: 7
Training loss: 1.9239437580108643
Validation loss: 2.2774587792734944

Epoch: 6| Step: 8
Training loss: 2.367227792739868
Validation loss: 2.3097255306859172

Epoch: 6| Step: 9
Training loss: 2.6982879638671875
Validation loss: 2.2777591854013424

Epoch: 6| Step: 10
Training loss: 2.9954018592834473
Validation loss: 2.235997551230974

Epoch: 6| Step: 11
Training loss: 2.5234780311584473
Validation loss: 2.2440102151645127

Epoch: 6| Step: 12
Training loss: 2.473630905151367
Validation loss: 2.244777274388139

Epoch: 6| Step: 13
Training loss: 3.332730293273926
Validation loss: 2.2596139343835975

Epoch: 26| Step: 0
Training loss: 2.083836555480957
Validation loss: 2.2443904081980386

Epoch: 6| Step: 1
Training loss: 2.593029022216797
Validation loss: 2.2357362278046145

Epoch: 6| Step: 2
Training loss: 2.311227560043335
Validation loss: 2.234444231115362

Epoch: 6| Step: 3
Training loss: 2.8451662063598633
Validation loss: 2.231744384252897

Epoch: 6| Step: 4
Training loss: 1.9518241882324219
Validation loss: 2.202564352302141

Epoch: 6| Step: 5
Training loss: 2.455784797668457
Validation loss: 2.2546067032762753

Epoch: 6| Step: 6
Training loss: 2.716726779937744
Validation loss: 2.24514127034013

Epoch: 6| Step: 7
Training loss: 2.1002912521362305
Validation loss: 2.2322151789101223

Epoch: 6| Step: 8
Training loss: 2.6941282749176025
Validation loss: 2.2191611323305356

Epoch: 6| Step: 9
Training loss: 2.841944456100464
Validation loss: 2.2200567440320085

Epoch: 6| Step: 10
Training loss: 2.3719849586486816
Validation loss: 2.2054533086797243

Epoch: 6| Step: 11
Training loss: 2.336378574371338
Validation loss: 2.1862112578525337

Epoch: 6| Step: 12
Training loss: 3.3910114765167236
Validation loss: 2.2591693273154636

Epoch: 6| Step: 13
Training loss: 1.9480748176574707
Validation loss: 2.190595962667978

Epoch: 27| Step: 0
Training loss: 2.155705451965332
Validation loss: 2.2264939149220786

Epoch: 6| Step: 1
Training loss: 2.8941807746887207
Validation loss: 2.183599361809351

Epoch: 6| Step: 2
Training loss: 2.7270021438598633
Validation loss: 2.2191357740791897

Epoch: 6| Step: 3
Training loss: 2.235647678375244
Validation loss: 2.1847247500573435

Epoch: 6| Step: 4
Training loss: 2.395988941192627
Validation loss: 2.1977492199149182

Epoch: 6| Step: 5
Training loss: 1.824138879776001
Validation loss: 2.193608778779225

Epoch: 6| Step: 6
Training loss: 2.7008090019226074
Validation loss: 2.2251297786671627

Epoch: 6| Step: 7
Training loss: 2.1760706901550293
Validation loss: 2.17578725917365

Epoch: 6| Step: 8
Training loss: 2.639694929122925
Validation loss: 2.2150329364243375

Epoch: 6| Step: 9
Training loss: 2.5583105087280273
Validation loss: 2.2268117525244273

Epoch: 6| Step: 10
Training loss: 1.8652583360671997
Validation loss: 2.2119605695047686

Epoch: 6| Step: 11
Training loss: 3.0309624671936035
Validation loss: 2.2072047725800545

Epoch: 6| Step: 12
Training loss: 2.903846025466919
Validation loss: 2.200514983105403

Epoch: 6| Step: 13
Training loss: 2.861077308654785
Validation loss: 2.170267438375822

Epoch: 28| Step: 0
Training loss: 2.7151899337768555
Validation loss: 2.222621467805678

Epoch: 6| Step: 1
Training loss: 2.492947578430176
Validation loss: 2.199562495754611

Epoch: 6| Step: 2
Training loss: 2.748579263687134
Validation loss: 2.1969618720393025

Epoch: 6| Step: 3
Training loss: 2.597107410430908
Validation loss: 2.2248914318699993

Epoch: 6| Step: 4
Training loss: 2.495241641998291
Validation loss: 2.1683225900896135

Epoch: 6| Step: 5
Training loss: 2.182255268096924
Validation loss: 2.167055194095899

Epoch: 6| Step: 6
Training loss: 1.844381332397461
Validation loss: 2.177552932052202

Epoch: 6| Step: 7
Training loss: 2.354154586791992
Validation loss: 2.163109323029877

Epoch: 6| Step: 8
Training loss: 2.025014877319336
Validation loss: 2.162103103053185

Epoch: 6| Step: 9
Training loss: 2.8706490993499756
Validation loss: 2.2013877309778684

Epoch: 6| Step: 10
Training loss: 2.309194803237915
Validation loss: 2.2000689403985136

Epoch: 6| Step: 11
Training loss: 3.3272829055786133
Validation loss: 2.1673937625782465

Epoch: 6| Step: 12
Training loss: 2.2387475967407227
Validation loss: 2.1967895607794485

Epoch: 6| Step: 13
Training loss: 2.4493303298950195
Validation loss: 2.153066576168101

Epoch: 29| Step: 0
Training loss: 2.3614234924316406
Validation loss: 2.18555942145727

Epoch: 6| Step: 1
Training loss: 1.8744820356369019
Validation loss: 2.1888392791953137

Epoch: 6| Step: 2
Training loss: 2.851393938064575
Validation loss: 2.1953118052533878

Epoch: 6| Step: 3
Training loss: 2.12671160697937
Validation loss: 2.1940068698698476

Epoch: 6| Step: 4
Training loss: 2.3066375255584717
Validation loss: 2.2186405427994265

Epoch: 6| Step: 5
Training loss: 2.6832046508789062
Validation loss: 2.17521402400027

Epoch: 6| Step: 6
Training loss: 2.559816360473633
Validation loss: 2.1598166701614216

Epoch: 6| Step: 7
Training loss: 2.1403398513793945
Validation loss: 2.195957109492312

Epoch: 6| Step: 8
Training loss: 2.0484375953674316
Validation loss: 2.180383559196226

Epoch: 6| Step: 9
Training loss: 2.633291482925415
Validation loss: 2.1601227457805345

Epoch: 6| Step: 10
Training loss: 2.3361949920654297
Validation loss: 2.1746779385433403

Epoch: 6| Step: 11
Training loss: 3.318249225616455
Validation loss: 2.197945915242677

Epoch: 6| Step: 12
Training loss: 2.8703536987304688
Validation loss: 2.1761249842182284

Epoch: 6| Step: 13
Training loss: 2.4005253314971924
Validation loss: 2.1956181295456423

Epoch: 30| Step: 0
Training loss: 2.539888858795166
Validation loss: 2.1889227744071715

Epoch: 6| Step: 1
Training loss: 3.084836006164551
Validation loss: 2.169146253216651

Epoch: 6| Step: 2
Training loss: 2.447702407836914
Validation loss: 2.1618655138118292

Epoch: 6| Step: 3
Training loss: 2.871713161468506
Validation loss: 2.201499487764092

Epoch: 6| Step: 4
Training loss: 2.767192840576172
Validation loss: 2.170092523738902

Epoch: 6| Step: 5
Training loss: 2.308260917663574
Validation loss: 2.1951849204237743

Epoch: 6| Step: 6
Training loss: 2.4330363273620605
Validation loss: 2.17712692804234

Epoch: 6| Step: 7
Training loss: 2.4662513732910156
Validation loss: 2.1704268993869906

Epoch: 6| Step: 8
Training loss: 1.9044520854949951
Validation loss: 2.1715606169034074

Epoch: 6| Step: 9
Training loss: 2.3302431106567383
Validation loss: 2.1510943622999292

Epoch: 6| Step: 10
Training loss: 2.1118125915527344
Validation loss: 2.164986574521629

Epoch: 6| Step: 11
Training loss: 2.4414782524108887
Validation loss: 2.172907183247228

Epoch: 6| Step: 12
Training loss: 2.884251117706299
Validation loss: 2.1911190735396517

Epoch: 6| Step: 13
Training loss: 1.611771821975708
Validation loss: 2.191601904489661

Epoch: 31| Step: 0
Training loss: 2.4175100326538086
Validation loss: 2.1407962563217326

Epoch: 6| Step: 1
Training loss: 2.542912006378174
Validation loss: 2.1854954381142893

Epoch: 6| Step: 2
Training loss: 1.6561198234558105
Validation loss: 2.1718928531933854

Epoch: 6| Step: 3
Training loss: 2.0413193702697754
Validation loss: 2.165292734740883

Epoch: 6| Step: 4
Training loss: 2.2668354511260986
Validation loss: 2.159044591329431

Epoch: 6| Step: 5
Training loss: 2.886037588119507
Validation loss: 2.147151549657186

Epoch: 6| Step: 6
Training loss: 2.916378974914551
Validation loss: 2.19207642668037

Epoch: 6| Step: 7
Training loss: 2.0550076961517334
Validation loss: 2.1703978328294653

Epoch: 6| Step: 8
Training loss: 2.714205741882324
Validation loss: 2.1390758509277017

Epoch: 6| Step: 9
Training loss: 2.2207484245300293
Validation loss: 2.154267047041206

Epoch: 6| Step: 10
Training loss: 3.137037754058838
Validation loss: 2.158922141598117

Epoch: 6| Step: 11
Training loss: 1.7208092212677002
Validation loss: 2.1204030539399836

Epoch: 6| Step: 12
Training loss: 2.8099865913391113
Validation loss: 2.133379146616946

Epoch: 6| Step: 13
Training loss: 3.5149056911468506
Validation loss: 2.1646369247026342

Epoch: 32| Step: 0
Training loss: 2.324542284011841
Validation loss: 2.1460000648293445

Epoch: 6| Step: 1
Training loss: 1.9609428644180298
Validation loss: 2.1497008903052217

Epoch: 6| Step: 2
Training loss: 2.0461628437042236
Validation loss: 2.161318107317853

Epoch: 6| Step: 3
Training loss: 3.0202372074127197
Validation loss: 2.1611138877048286

Epoch: 6| Step: 4
Training loss: 2.4766838550567627
Validation loss: 2.1619173852346276

Epoch: 6| Step: 5
Training loss: 2.595020294189453
Validation loss: 2.1295677359386156

Epoch: 6| Step: 6
Training loss: 2.8166136741638184
Validation loss: 2.1345723264960834

Epoch: 6| Step: 7
Training loss: 2.7733590602874756
Validation loss: 2.185314879622511

Epoch: 6| Step: 8
Training loss: 1.7758657932281494
Validation loss: 2.1373094128024195

Epoch: 6| Step: 9
Training loss: 2.2029426097869873
Validation loss: 2.1719906022471767

Epoch: 6| Step: 10
Training loss: 3.469672203063965
Validation loss: 2.152742724264822

Epoch: 6| Step: 11
Training loss: 2.3577919006347656
Validation loss: 2.1337804614856677

Epoch: 6| Step: 12
Training loss: 2.6317429542541504
Validation loss: 2.161406061982596

Epoch: 6| Step: 13
Training loss: 2.190685272216797
Validation loss: 2.178154209608673

Epoch: 33| Step: 0
Training loss: 2.2652528285980225
Validation loss: 2.1875302445503975

Epoch: 6| Step: 1
Training loss: 2.394599676132202
Validation loss: 2.150214825907061

Epoch: 6| Step: 2
Training loss: 2.78743577003479
Validation loss: 2.162959534634826

Epoch: 6| Step: 3
Training loss: 2.8454599380493164
Validation loss: 2.1814074747024046

Epoch: 6| Step: 4
Training loss: 2.5076208114624023
Validation loss: 2.1656569306568434

Epoch: 6| Step: 5
Training loss: 3.032871723175049
Validation loss: 2.168064658359815

Epoch: 6| Step: 6
Training loss: 2.6084139347076416
Validation loss: 2.179759366537935

Epoch: 6| Step: 7
Training loss: 2.7145981788635254
Validation loss: 2.137087006722727

Epoch: 6| Step: 8
Training loss: 2.088688850402832
Validation loss: 2.1735455425836707

Epoch: 6| Step: 9
Training loss: 2.08597469329834
Validation loss: 2.18946930157241

Epoch: 6| Step: 10
Training loss: 2.1355085372924805
Validation loss: 2.1417192105324037

Epoch: 6| Step: 11
Training loss: 2.3791728019714355
Validation loss: 2.1644934223544214

Epoch: 6| Step: 12
Training loss: 2.944176197052002
Validation loss: 2.152862823137673

Epoch: 6| Step: 13
Training loss: 1.3831133842468262
Validation loss: 2.1681324205090924

Epoch: 34| Step: 0
Training loss: 3.053835391998291
Validation loss: 2.1675243146957888

Epoch: 6| Step: 1
Training loss: 3.7416210174560547
Validation loss: 2.179686753980575

Epoch: 6| Step: 2
Training loss: 2.024977922439575
Validation loss: 2.158612714018873

Epoch: 6| Step: 3
Training loss: 2.4004170894622803
Validation loss: 2.129111679651404

Epoch: 6| Step: 4
Training loss: 1.765333890914917
Validation loss: 2.134163741142519

Epoch: 6| Step: 5
Training loss: 2.512136459350586
Validation loss: 2.178899754760086

Epoch: 6| Step: 6
Training loss: 2.452639579772949
Validation loss: 2.1834839005624094

Epoch: 6| Step: 7
Training loss: 2.243215560913086
Validation loss: 2.1684693328795897

Epoch: 6| Step: 8
Training loss: 2.324800968170166
Validation loss: 2.1119129632108953

Epoch: 6| Step: 9
Training loss: 1.8996349573135376
Validation loss: 2.163065546302385

Epoch: 6| Step: 10
Training loss: 2.231788158416748
Validation loss: 2.165637637979241

Epoch: 6| Step: 11
Training loss: 2.4612948894500732
Validation loss: 2.1470320634944464

Epoch: 6| Step: 12
Training loss: 2.4355082511901855
Validation loss: 2.184391371665462

Epoch: 6| Step: 13
Training loss: 2.9430246353149414
Validation loss: 2.189852453047229

Epoch: 35| Step: 0
Training loss: 2.3311777114868164
Validation loss: 2.155930821613599

Epoch: 6| Step: 1
Training loss: 2.4570133686065674
Validation loss: 2.1558892983262257

Epoch: 6| Step: 2
Training loss: 2.381621837615967
Validation loss: 2.1841335194085234

Epoch: 6| Step: 3
Training loss: 2.2197065353393555
Validation loss: 2.1510739505931897

Epoch: 6| Step: 4
Training loss: 2.3323094844818115
Validation loss: 2.183538347162226

Epoch: 6| Step: 5
Training loss: 2.5808916091918945
Validation loss: 2.163920428163262

Epoch: 6| Step: 6
Training loss: 2.2686307430267334
Validation loss: 2.172712113267632

Epoch: 6| Step: 7
Training loss: 3.684257984161377
Validation loss: 2.163669914327642

Epoch: 6| Step: 8
Training loss: 2.5276060104370117
Validation loss: 2.1751947377317693

Epoch: 6| Step: 9
Training loss: 3.3898768424987793
Validation loss: 2.135747658309116

Epoch: 6| Step: 10
Training loss: 1.999276876449585
Validation loss: 2.1260382898392214

Epoch: 6| Step: 11
Training loss: 1.8846373558044434
Validation loss: 2.140052508282405

Epoch: 6| Step: 12
Training loss: 1.8415040969848633
Validation loss: 2.1816056646326536

Epoch: 6| Step: 13
Training loss: 2.801325559616089
Validation loss: 2.1526065795652327

Epoch: 36| Step: 0
Training loss: 2.332940101623535
Validation loss: 2.170067048841907

Epoch: 6| Step: 1
Training loss: 2.7319984436035156
Validation loss: 2.152572666445086

Epoch: 6| Step: 2
Training loss: 2.3178741931915283
Validation loss: 2.1746633232280774

Epoch: 6| Step: 3
Training loss: 1.943169355392456
Validation loss: 2.1857980220548567

Epoch: 6| Step: 4
Training loss: 2.233189821243286
Validation loss: 2.1751708202464606

Epoch: 6| Step: 5
Training loss: 2.2642431259155273
Validation loss: 2.1715192820436213

Epoch: 6| Step: 6
Training loss: 2.1796653270721436
Validation loss: 2.16194329210507

Epoch: 6| Step: 7
Training loss: 2.5590572357177734
Validation loss: 2.1694882556956303

Epoch: 6| Step: 8
Training loss: 2.847898244857788
Validation loss: 2.157955418350876

Epoch: 6| Step: 9
Training loss: 2.521078586578369
Validation loss: 2.154000031050815

Epoch: 6| Step: 10
Training loss: 2.068685531616211
Validation loss: 2.1500000389673377

Epoch: 6| Step: 11
Training loss: 2.7716245651245117
Validation loss: 2.12421086013958

Epoch: 6| Step: 12
Training loss: 2.5977540016174316
Validation loss: 2.138861976644044

Epoch: 6| Step: 13
Training loss: 2.584122896194458
Validation loss: 2.186906745356898

Epoch: 37| Step: 0
Training loss: 2.7470948696136475
Validation loss: 2.160178243473012

Epoch: 6| Step: 1
Training loss: 1.5696519613265991
Validation loss: 2.121354618380147

Epoch: 6| Step: 2
Training loss: 2.439211845397949
Validation loss: 2.181817231639739

Epoch: 6| Step: 3
Training loss: 2.5199923515319824
Validation loss: 2.1441197497870332

Epoch: 6| Step: 4
Training loss: 1.7950383424758911
Validation loss: 2.139731086710448

Epoch: 6| Step: 5
Training loss: 2.564985990524292
Validation loss: 2.135539500944076

Epoch: 6| Step: 6
Training loss: 2.411822557449341
Validation loss: 2.124730702369444

Epoch: 6| Step: 7
Training loss: 2.4795849323272705
Validation loss: 2.1328062485623103

Epoch: 6| Step: 8
Training loss: 3.067183494567871
Validation loss: 2.1288813903767574

Epoch: 6| Step: 9
Training loss: 2.485476493835449
Validation loss: 2.110090099355226

Epoch: 6| Step: 10
Training loss: 3.3624839782714844
Validation loss: 2.143330043362033

Epoch: 6| Step: 11
Training loss: 2.100551128387451
Validation loss: 2.1601309007213962

Epoch: 6| Step: 12
Training loss: 2.5570614337921143
Validation loss: 2.1405673732039747

Epoch: 6| Step: 13
Training loss: 1.9237215518951416
Validation loss: 2.141332064905474

Epoch: 38| Step: 0
Training loss: 2.476152181625366
Validation loss: 2.129953799709197

Epoch: 6| Step: 1
Training loss: 2.0355992317199707
Validation loss: 2.1543424744759836

Epoch: 6| Step: 2
Training loss: 2.332397937774658
Validation loss: 2.1331039321038032

Epoch: 6| Step: 3
Training loss: 2.5301198959350586
Validation loss: 2.119935368978849

Epoch: 6| Step: 4
Training loss: 2.4491772651672363
Validation loss: 2.15426234404246

Epoch: 6| Step: 5
Training loss: 2.171941041946411
Validation loss: 2.153694745033018

Epoch: 6| Step: 6
Training loss: 2.8226709365844727
Validation loss: 2.1569605347930745

Epoch: 6| Step: 7
Training loss: 2.1972358226776123
Validation loss: 2.1260677870883735

Epoch: 6| Step: 8
Training loss: 2.5647358894348145
Validation loss: 2.1092659952819988

Epoch: 6| Step: 9
Training loss: 1.9890881776809692
Validation loss: 2.1134542393428024

Epoch: 6| Step: 10
Training loss: 2.1702682971954346
Validation loss: 2.1056247757327173

Epoch: 6| Step: 11
Training loss: 2.836719036102295
Validation loss: 2.159144987342178

Epoch: 6| Step: 12
Training loss: 3.0930347442626953
Validation loss: 2.131948160868819

Epoch: 6| Step: 13
Training loss: 2.529100179672241
Validation loss: 2.151012284781343

Epoch: 39| Step: 0
Training loss: 2.5674331188201904
Validation loss: 2.0992770810281076

Epoch: 6| Step: 1
Training loss: 2.928600788116455
Validation loss: 2.1282891304262224

Epoch: 6| Step: 2
Training loss: 1.723512053489685
Validation loss: 2.1408592782994753

Epoch: 6| Step: 3
Training loss: 1.9430608749389648
Validation loss: 2.120850573303879

Epoch: 6| Step: 4
Training loss: 3.061964273452759
Validation loss: 2.1211624145507812

Epoch: 6| Step: 5
Training loss: 2.121019124984741
Validation loss: 2.144357688965336

Epoch: 6| Step: 6
Training loss: 2.4994163513183594
Validation loss: 2.132579213829451

Epoch: 6| Step: 7
Training loss: 2.220827102661133
Validation loss: 2.146058128726098

Epoch: 6| Step: 8
Training loss: 2.1346349716186523
Validation loss: 2.116727199605716

Epoch: 6| Step: 9
Training loss: 2.46073579788208
Validation loss: 2.0912233808989167

Epoch: 6| Step: 10
Training loss: 2.239804267883301
Validation loss: 2.11083129144484

Epoch: 6| Step: 11
Training loss: 2.8987009525299072
Validation loss: 2.149639989740105

Epoch: 6| Step: 12
Training loss: 2.3936972618103027
Validation loss: 2.127295045442479

Epoch: 6| Step: 13
Training loss: 2.7397043704986572
Validation loss: 2.147043461440712

Epoch: 40| Step: 0
Training loss: 2.3015825748443604
Validation loss: 2.1379758696402273

Epoch: 6| Step: 1
Training loss: 2.118037223815918
Validation loss: 2.105128013959495

Epoch: 6| Step: 2
Training loss: 2.147623062133789
Validation loss: 2.1619804418215187

Epoch: 6| Step: 3
Training loss: 3.1078760623931885
Validation loss: 2.1295875182715793

Epoch: 6| Step: 4
Training loss: 1.9857795238494873
Validation loss: 2.1759600485524824

Epoch: 6| Step: 5
Training loss: 2.5223984718322754
Validation loss: 2.110262888734059

Epoch: 6| Step: 6
Training loss: 3.0595648288726807
Validation loss: 2.1328745683034263

Epoch: 6| Step: 7
Training loss: 2.403038501739502
Validation loss: 2.1328924804605465

Epoch: 6| Step: 8
Training loss: 2.373560667037964
Validation loss: 2.1563167302839217

Epoch: 6| Step: 9
Training loss: 1.813373327255249
Validation loss: 2.0840522576403875

Epoch: 6| Step: 10
Training loss: 2.231419324874878
Validation loss: 2.1280528089051605

Epoch: 6| Step: 11
Training loss: 2.3973472118377686
Validation loss: 2.104388395945231

Epoch: 6| Step: 12
Training loss: 2.520236015319824
Validation loss: 2.140153323450396

Epoch: 6| Step: 13
Training loss: 3.5641980171203613
Validation loss: 2.140990036790089

Epoch: 41| Step: 0
Training loss: 1.791724443435669
Validation loss: 2.156704625775737

Epoch: 6| Step: 1
Training loss: 2.759103775024414
Validation loss: 2.1016470488681587

Epoch: 6| Step: 2
Training loss: 2.3933298587799072
Validation loss: 2.133014759709758

Epoch: 6| Step: 3
Training loss: 2.1171040534973145
Validation loss: 2.1399366522348053

Epoch: 6| Step: 4
Training loss: 2.1903297901153564
Validation loss: 2.12411162161058

Epoch: 6| Step: 5
Training loss: 2.216118335723877
Validation loss: 2.1226131352045203

Epoch: 6| Step: 6
Training loss: 2.439202308654785
Validation loss: 2.1099346940235426

Epoch: 6| Step: 7
Training loss: 2.3794188499450684
Validation loss: 2.1537298310187554

Epoch: 6| Step: 8
Training loss: 2.3561763763427734
Validation loss: 2.1263333392399613

Epoch: 6| Step: 9
Training loss: 2.6159846782684326
Validation loss: 2.0979922843235794

Epoch: 6| Step: 10
Training loss: 2.680826187133789
Validation loss: 2.1154616058513684

Epoch: 6| Step: 11
Training loss: 2.6597979068756104
Validation loss: 2.1379449982796945

Epoch: 6| Step: 12
Training loss: 2.052168369293213
Validation loss: 2.133826001997917

Epoch: 6| Step: 13
Training loss: 3.2862918376922607
Validation loss: 2.1658563024254254

Epoch: 42| Step: 0
Training loss: 2.417827606201172
Validation loss: 2.142827092960317

Epoch: 6| Step: 1
Training loss: 1.9667587280273438
Validation loss: 2.1075573557166645

Epoch: 6| Step: 2
Training loss: 2.262615203857422
Validation loss: 2.1091044487491732

Epoch: 6| Step: 3
Training loss: 1.9701154232025146
Validation loss: 2.105521268742059

Epoch: 6| Step: 4
Training loss: 2.908120632171631
Validation loss: 2.1285515844181018

Epoch: 6| Step: 5
Training loss: 2.7237493991851807
Validation loss: 2.115656829649402

Epoch: 6| Step: 6
Training loss: 2.7212483882904053
Validation loss: 2.126870575771537

Epoch: 6| Step: 7
Training loss: 2.3836913108825684
Validation loss: 2.143520906407346

Epoch: 6| Step: 8
Training loss: 2.3490524291992188
Validation loss: 2.136858065923055

Epoch: 6| Step: 9
Training loss: 2.397658348083496
Validation loss: 2.104885067991031

Epoch: 6| Step: 10
Training loss: 2.7660200595855713
Validation loss: 2.1108740016978276

Epoch: 6| Step: 11
Training loss: 2.660829782485962
Validation loss: 2.0771421386349584

Epoch: 6| Step: 12
Training loss: 2.0023999214172363
Validation loss: 2.123054317248765

Epoch: 6| Step: 13
Training loss: 2.014104127883911
Validation loss: 2.1676692565282187

Epoch: 43| Step: 0
Training loss: 2.0264639854431152
Validation loss: 2.0822756572436263

Epoch: 6| Step: 1
Training loss: 2.1021065711975098
Validation loss: 2.1490075716408352

Epoch: 6| Step: 2
Training loss: 1.9631537199020386
Validation loss: 2.1193698490819624

Epoch: 6| Step: 3
Training loss: 2.0388007164001465
Validation loss: 2.131459620691115

Epoch: 6| Step: 4
Training loss: 2.535317897796631
Validation loss: 2.1104437138444636

Epoch: 6| Step: 5
Training loss: 2.941150665283203
Validation loss: 2.1341378919539915

Epoch: 6| Step: 6
Training loss: 2.38021183013916
Validation loss: 2.1552490213865876

Epoch: 6| Step: 7
Training loss: 2.1518709659576416
Validation loss: 2.1288543978045062

Epoch: 6| Step: 8
Training loss: 2.41670560836792
Validation loss: 2.13763242126793

Epoch: 6| Step: 9
Training loss: 2.695354461669922
Validation loss: 2.143179207719782

Epoch: 6| Step: 10
Training loss: 2.059861898422241
Validation loss: 2.1322617735914005

Epoch: 6| Step: 11
Training loss: 2.7063534259796143
Validation loss: 2.1135834058125815

Epoch: 6| Step: 12
Training loss: 2.503990650177002
Validation loss: 2.0937198464588453

Epoch: 6| Step: 13
Training loss: 3.430572509765625
Validation loss: 2.1476738170910905

Epoch: 44| Step: 0
Training loss: 2.393062114715576
Validation loss: 2.125773763143888

Epoch: 6| Step: 1
Training loss: 2.524167776107788
Validation loss: 2.1723247138402795

Epoch: 6| Step: 2
Training loss: 2.3981337547302246
Validation loss: 2.1329966975796606

Epoch: 6| Step: 3
Training loss: 2.392230987548828
Validation loss: 2.1790924277356876

Epoch: 6| Step: 4
Training loss: 2.5013012886047363
Validation loss: 2.0958177428091727

Epoch: 6| Step: 5
Training loss: 1.9871025085449219
Validation loss: 2.1761540059120423

Epoch: 6| Step: 6
Training loss: 1.8559280633926392
Validation loss: 2.103536410998273

Epoch: 6| Step: 7
Training loss: 2.8583779335021973
Validation loss: 2.1532291263662358

Epoch: 6| Step: 8
Training loss: 1.750516414642334
Validation loss: 2.134872531378141

Epoch: 6| Step: 9
Training loss: 2.392882823944092
Validation loss: 2.1294875529504593

Epoch: 6| Step: 10
Training loss: 2.6839656829833984
Validation loss: 2.086428988364435

Epoch: 6| Step: 11
Training loss: 2.2527453899383545
Validation loss: 2.1380040440508115

Epoch: 6| Step: 12
Training loss: 2.4283225536346436
Validation loss: 2.17488532681619

Epoch: 6| Step: 13
Training loss: 3.105959415435791
Validation loss: 2.1718667527680755

Epoch: 45| Step: 0
Training loss: 1.909505844116211
Validation loss: 2.152348041534424

Epoch: 6| Step: 1
Training loss: 1.6879403591156006
Validation loss: 2.1495394270907164

Epoch: 6| Step: 2
Training loss: 2.8491270542144775
Validation loss: 2.1697700690197688

Epoch: 6| Step: 3
Training loss: 2.2752432823181152
Validation loss: 2.1308496062473585

Epoch: 6| Step: 4
Training loss: 2.5515270233154297
Validation loss: 2.168659920333534

Epoch: 6| Step: 5
Training loss: 2.0138959884643555
Validation loss: 2.1482260701476887

Epoch: 6| Step: 6
Training loss: 2.287745237350464
Validation loss: 2.1304092458499375

Epoch: 6| Step: 7
Training loss: 2.6908907890319824
Validation loss: 2.1161388953526816

Epoch: 6| Step: 8
Training loss: 2.5202460289001465
Validation loss: 2.1118994823066135

Epoch: 6| Step: 9
Training loss: 2.568519115447998
Validation loss: 2.2049646416018085

Epoch: 6| Step: 10
Training loss: 2.2983531951904297
Validation loss: 2.162798732839605

Epoch: 6| Step: 11
Training loss: 3.164820671081543
Validation loss: 2.083272208449661

Epoch: 6| Step: 12
Training loss: 2.2081615924835205
Validation loss: 2.1464274673051733

Epoch: 6| Step: 13
Training loss: 2.5069074630737305
Validation loss: 2.124925139129803

Epoch: 46| Step: 0
Training loss: 3.265052080154419
Validation loss: 2.1372331573117163

Epoch: 6| Step: 1
Training loss: 2.7669050693511963
Validation loss: 2.1911558746009745

Epoch: 6| Step: 2
Training loss: 2.7232794761657715
Validation loss: 2.1587115897927234

Epoch: 6| Step: 3
Training loss: 2.2838003635406494
Validation loss: 2.148722420456589

Epoch: 6| Step: 4
Training loss: 2.3484606742858887
Validation loss: 2.1918566560232513

Epoch: 6| Step: 5
Training loss: 1.7533912658691406
Validation loss: 2.159503480439545

Epoch: 6| Step: 6
Training loss: 2.888395309448242
Validation loss: 2.1800630143893662

Epoch: 6| Step: 7
Training loss: 2.0525712966918945
Validation loss: 2.1638166032811648

Epoch: 6| Step: 8
Training loss: 1.7197673320770264
Validation loss: 2.112727507468193

Epoch: 6| Step: 9
Training loss: 2.6603755950927734
Validation loss: 2.151521780157602

Epoch: 6| Step: 10
Training loss: 2.4251348972320557
Validation loss: 2.136272753438642

Epoch: 6| Step: 11
Training loss: 1.8854436874389648
Validation loss: 2.178396963304089

Epoch: 6| Step: 12
Training loss: 2.1462464332580566
Validation loss: 2.09617349409288

Epoch: 6| Step: 13
Training loss: 2.406735420227051
Validation loss: 2.124040206273397

Epoch: 47| Step: 0
Training loss: 2.4157955646514893
Validation loss: 2.142401264559838

Epoch: 6| Step: 1
Training loss: 2.5462546348571777
Validation loss: 2.156575661833568

Epoch: 6| Step: 2
Training loss: 2.215074062347412
Validation loss: 2.1463285466676116

Epoch: 6| Step: 3
Training loss: 1.925475001335144
Validation loss: 2.1225654796887468

Epoch: 6| Step: 4
Training loss: 2.2927403450012207
Validation loss: 2.1754560239853395

Epoch: 6| Step: 5
Training loss: 2.1850342750549316
Validation loss: 2.132006022237962

Epoch: 6| Step: 6
Training loss: 2.5301828384399414
Validation loss: 2.113218794586838

Epoch: 6| Step: 7
Training loss: 2.1466305255889893
Validation loss: 2.087262092098113

Epoch: 6| Step: 8
Training loss: 3.726073741912842
Validation loss: 2.107679268365265

Epoch: 6| Step: 9
Training loss: 1.7979124784469604
Validation loss: 2.0923092185810046

Epoch: 6| Step: 10
Training loss: 2.7381808757781982
Validation loss: 2.1354494530667543

Epoch: 6| Step: 11
Training loss: 2.440091609954834
Validation loss: 2.1288132693177912

Epoch: 6| Step: 12
Training loss: 2.4169440269470215
Validation loss: 2.1043445756358485

Epoch: 6| Step: 13
Training loss: 1.7572063207626343
Validation loss: 2.1450518920857418

Epoch: 48| Step: 0
Training loss: 2.262444496154785
Validation loss: 2.109730730774582

Epoch: 6| Step: 1
Training loss: 2.9103708267211914
Validation loss: 2.11092544627446

Epoch: 6| Step: 2
Training loss: 2.8385159969329834
Validation loss: 2.1073927469150995

Epoch: 6| Step: 3
Training loss: 1.9198741912841797
Validation loss: 2.1382166826596825

Epoch: 6| Step: 4
Training loss: 2.433994770050049
Validation loss: 2.09618503175756

Epoch: 6| Step: 5
Training loss: 2.0149621963500977
Validation loss: 2.0932622596781743

Epoch: 6| Step: 6
Training loss: 2.19356107711792
Validation loss: 2.0558815925352034

Epoch: 6| Step: 7
Training loss: 2.611461877822876
Validation loss: 2.1248789833438013

Epoch: 6| Step: 8
Training loss: 1.6751739978790283
Validation loss: 2.1376289911167596

Epoch: 6| Step: 9
Training loss: 3.0880746841430664
Validation loss: 2.0880954342503704

Epoch: 6| Step: 10
Training loss: 1.7927418947219849
Validation loss: 2.0627509496545278

Epoch: 6| Step: 11
Training loss: 2.6144795417785645
Validation loss: 2.1344554526831514

Epoch: 6| Step: 12
Training loss: 2.512977123260498
Validation loss: 2.0935884265489477

Epoch: 6| Step: 13
Training loss: 2.5404183864593506
Validation loss: 2.132227655380003

Epoch: 49| Step: 0
Training loss: 2.4708492755889893
Validation loss: 2.1048061886141376

Epoch: 6| Step: 1
Training loss: 2.054635524749756
Validation loss: 2.073420460506152

Epoch: 6| Step: 2
Training loss: 1.6577799320220947
Validation loss: 2.150715321622869

Epoch: 6| Step: 3
Training loss: 2.5587592124938965
Validation loss: 2.1148312989101616

Epoch: 6| Step: 4
Training loss: 3.235898971557617
Validation loss: 2.1103674186173307

Epoch: 6| Step: 5
Training loss: 2.275752544403076
Validation loss: 2.1081416696630497

Epoch: 6| Step: 6
Training loss: 2.2279558181762695
Validation loss: 2.1294753525846746

Epoch: 6| Step: 7
Training loss: 2.272441864013672
Validation loss: 2.10840598229439

Epoch: 6| Step: 8
Training loss: 1.9704031944274902
Validation loss: 2.130413903984972

Epoch: 6| Step: 9
Training loss: 2.696645736694336
Validation loss: 2.131322717153898

Epoch: 6| Step: 10
Training loss: 2.132693290710449
Validation loss: 2.133480733440768

Epoch: 6| Step: 11
Training loss: 2.7673730850219727
Validation loss: 2.120486338933309

Epoch: 6| Step: 12
Training loss: 2.6272668838500977
Validation loss: 2.095243469361336

Epoch: 6| Step: 13
Training loss: 2.039306640625
Validation loss: 2.1203961833830802

Epoch: 50| Step: 0
Training loss: 2.319322109222412
Validation loss: 2.1553968255237868

Epoch: 6| Step: 1
Training loss: 2.71170973777771
Validation loss: 2.089687115402632

Epoch: 6| Step: 2
Training loss: 2.5848617553710938
Validation loss: 2.1162811761261313

Epoch: 6| Step: 3
Training loss: 2.366744041442871
Validation loss: 2.085182756505987

Epoch: 6| Step: 4
Training loss: 2.713575601577759
Validation loss: 2.099650509895817

Epoch: 6| Step: 5
Training loss: 2.2254018783569336
Validation loss: 2.1122268399884625

Epoch: 6| Step: 6
Training loss: 1.8638615608215332
Validation loss: 2.0777339858393513

Epoch: 6| Step: 7
Training loss: 2.682821273803711
Validation loss: 2.0902038056363343

Epoch: 6| Step: 8
Training loss: 1.9077033996582031
Validation loss: 2.0982438184881724

Epoch: 6| Step: 9
Training loss: 3.1315720081329346
Validation loss: 2.113071164777202

Epoch: 6| Step: 10
Training loss: 1.4387989044189453
Validation loss: 2.0783857145617084

Epoch: 6| Step: 11
Training loss: 2.4254229068756104
Validation loss: 2.0901109685180006

Epoch: 6| Step: 12
Training loss: 2.2169878482818604
Validation loss: 2.1071690231241207

Epoch: 6| Step: 13
Training loss: 2.6671626567840576
Validation loss: 2.0972675687523297

Epoch: 51| Step: 0
Training loss: 2.1609911918640137
Validation loss: 2.100325838212044

Epoch: 6| Step: 1
Training loss: 1.8732939958572388
Validation loss: 2.143622976477428

Epoch: 6| Step: 2
Training loss: 2.1688992977142334
Validation loss: 2.120836651453408

Epoch: 6| Step: 3
Training loss: 2.5364830493927
Validation loss: 2.1339586152825305

Epoch: 6| Step: 4
Training loss: 1.785930871963501
Validation loss: 2.1031284204093357

Epoch: 6| Step: 5
Training loss: 1.6922259330749512
Validation loss: 2.1405265074904247

Epoch: 6| Step: 6
Training loss: 2.3068525791168213
Validation loss: 2.109985407962594

Epoch: 6| Step: 7
Training loss: 2.2077999114990234
Validation loss: 2.12486945941884

Epoch: 6| Step: 8
Training loss: 2.9502508640289307
Validation loss: 2.1487608109751055

Epoch: 6| Step: 9
Training loss: 2.226736068725586
Validation loss: 2.1172275286848827

Epoch: 6| Step: 10
Training loss: 2.2172770500183105
Validation loss: 2.166078890523603

Epoch: 6| Step: 11
Training loss: 3.3471062183380127
Validation loss: 2.0988902584198983

Epoch: 6| Step: 12
Training loss: 2.6238179206848145
Validation loss: 2.1528116938888386

Epoch: 6| Step: 13
Training loss: 3.2244250774383545
Validation loss: 2.089000707031578

Epoch: 52| Step: 0
Training loss: 1.604990005493164
Validation loss: 2.152955873038179

Epoch: 6| Step: 1
Training loss: 1.9263696670532227
Validation loss: 2.143616763494348

Epoch: 6| Step: 2
Training loss: 1.3676425218582153
Validation loss: 2.082409679248769

Epoch: 6| Step: 3
Training loss: 2.712696075439453
Validation loss: 2.0838024206058954

Epoch: 6| Step: 4
Training loss: 2.7733850479125977
Validation loss: 2.1253482731439735

Epoch: 6| Step: 5
Training loss: 2.4822802543640137
Validation loss: 2.1370481726943806

Epoch: 6| Step: 6
Training loss: 2.38645076751709
Validation loss: 2.0884354845170052

Epoch: 6| Step: 7
Training loss: 2.722323179244995
Validation loss: 2.12173988229485

Epoch: 6| Step: 8
Training loss: 2.3511228561401367
Validation loss: 2.1335153836075977

Epoch: 6| Step: 9
Training loss: 2.74788236618042
Validation loss: 2.0854967255746164

Epoch: 6| Step: 10
Training loss: 1.9990618228912354
Validation loss: 2.124687674225018

Epoch: 6| Step: 11
Training loss: 2.8818745613098145
Validation loss: 2.1159181735848867

Epoch: 6| Step: 12
Training loss: 2.5191092491149902
Validation loss: 2.116436307148267

Epoch: 6| Step: 13
Training loss: 2.581688642501831
Validation loss: 2.1097017641990417

Epoch: 53| Step: 0
Training loss: 2.6702327728271484
Validation loss: 2.1481430171638407

Epoch: 6| Step: 1
Training loss: 2.9478321075439453
Validation loss: 2.1355804653577906

Epoch: 6| Step: 2
Training loss: 2.0973055362701416
Validation loss: 2.123384811544931

Epoch: 6| Step: 3
Training loss: 2.2067112922668457
Validation loss: 2.1383484025155344

Epoch: 6| Step: 4
Training loss: 2.140890121459961
Validation loss: 2.1021136686366093

Epoch: 6| Step: 5
Training loss: 2.7055420875549316
Validation loss: 2.0854257434927006

Epoch: 6| Step: 6
Training loss: 2.1008105278015137
Validation loss: 2.094327429289459

Epoch: 6| Step: 7
Training loss: 1.997873306274414
Validation loss: 2.133811912228984

Epoch: 6| Step: 8
Training loss: 2.833874225616455
Validation loss: 2.089752063956312

Epoch: 6| Step: 9
Training loss: 2.6013288497924805
Validation loss: 2.0956846385873775

Epoch: 6| Step: 10
Training loss: 2.411881446838379
Validation loss: 2.147569005207349

Epoch: 6| Step: 11
Training loss: 1.8314682245254517
Validation loss: 2.120890163606213

Epoch: 6| Step: 12
Training loss: 2.0660691261291504
Validation loss: 2.095367467531594

Epoch: 6| Step: 13
Training loss: 2.841808319091797
Validation loss: 2.132284718175088

Epoch: 54| Step: 0
Training loss: 1.4674633741378784
Validation loss: 2.108557665219871

Epoch: 6| Step: 1
Training loss: 2.38936185836792
Validation loss: 2.1543675930269304

Epoch: 6| Step: 2
Training loss: 2.071227550506592
Validation loss: 2.101829687754313

Epoch: 6| Step: 3
Training loss: 1.9178664684295654
Validation loss: 2.0954182122343328

Epoch: 6| Step: 4
Training loss: 2.6493020057678223
Validation loss: 2.097659149477559

Epoch: 6| Step: 5
Training loss: 2.8393287658691406
Validation loss: 2.0711453960787867

Epoch: 6| Step: 6
Training loss: 2.167104959487915
Validation loss: 2.0472952294093307

Epoch: 6| Step: 7
Training loss: 2.6425318717956543
Validation loss: 2.102537416642712

Epoch: 6| Step: 8
Training loss: 1.712634563446045
Validation loss: 2.1147334973017373

Epoch: 6| Step: 9
Training loss: 2.476762294769287
Validation loss: 2.159041899506764

Epoch: 6| Step: 10
Training loss: 2.664482831954956
Validation loss: 2.1061437053065144

Epoch: 6| Step: 11
Training loss: 2.5632195472717285
Validation loss: 2.1015402411901825

Epoch: 6| Step: 12
Training loss: 2.9351911544799805
Validation loss: 2.114029020391485

Epoch: 6| Step: 13
Training loss: 2.1040680408477783
Validation loss: 2.1440125255174536

Epoch: 55| Step: 0
Training loss: 3.1230807304382324
Validation loss: 2.1146110667977283

Epoch: 6| Step: 1
Training loss: 1.990813970565796
Validation loss: 2.1316564493281867

Epoch: 6| Step: 2
Training loss: 2.022490978240967
Validation loss: 2.1154463726987123

Epoch: 6| Step: 3
Training loss: 2.469513177871704
Validation loss: 2.12317422897585

Epoch: 6| Step: 4
Training loss: 2.236750364303589
Validation loss: 2.1165006160736084

Epoch: 6| Step: 5
Training loss: 1.8259763717651367
Validation loss: 2.156869860105617

Epoch: 6| Step: 6
Training loss: 2.2781457901000977
Validation loss: 2.0826596752289803

Epoch: 6| Step: 7
Training loss: 1.8245108127593994
Validation loss: 2.091911244136031

Epoch: 6| Step: 8
Training loss: 2.4331023693084717
Validation loss: 2.12009500175394

Epoch: 6| Step: 9
Training loss: 2.295210838317871
Validation loss: 2.104825504364506

Epoch: 6| Step: 10
Training loss: 2.065328598022461
Validation loss: 2.1259512337305213

Epoch: 6| Step: 11
Training loss: 2.02571439743042
Validation loss: 2.0951819727497716

Epoch: 6| Step: 12
Training loss: 2.9927353858947754
Validation loss: 2.088144471568446

Epoch: 6| Step: 13
Training loss: 3.39486026763916
Validation loss: 2.0502155006572766

Epoch: 56| Step: 0
Training loss: 2.4013967514038086
Validation loss: 2.131598598213606

Epoch: 6| Step: 1
Training loss: 2.861539363861084
Validation loss: 2.0958357126482072

Epoch: 6| Step: 2
Training loss: 2.724177360534668
Validation loss: 2.122982922420707

Epoch: 6| Step: 3
Training loss: 1.7492568492889404
Validation loss: 2.0602678893714823

Epoch: 6| Step: 4
Training loss: 1.8725018501281738
Validation loss: 2.0605769952138266

Epoch: 6| Step: 5
Training loss: 2.819570302963257
Validation loss: 2.1028541723887124

Epoch: 6| Step: 6
Training loss: 1.0422186851501465
Validation loss: 2.133202668159239

Epoch: 6| Step: 7
Training loss: 3.1069207191467285
Validation loss: 2.1049452571458716

Epoch: 6| Step: 8
Training loss: 1.8643763065338135
Validation loss: 2.0696991694870817

Epoch: 6| Step: 9
Training loss: 2.4456264972686768
Validation loss: 2.11112743039285

Epoch: 6| Step: 10
Training loss: 2.6302008628845215
Validation loss: 2.0814927906118412

Epoch: 6| Step: 11
Training loss: 2.4565186500549316
Validation loss: 2.120793870700303

Epoch: 6| Step: 12
Training loss: 2.3628411293029785
Validation loss: 2.100716845963591

Epoch: 6| Step: 13
Training loss: 3.925337076187134
Validation loss: 2.1328967002130326

Epoch: 57| Step: 0
Training loss: 2.3839612007141113
Validation loss: 2.084336766632654

Epoch: 6| Step: 1
Training loss: 2.9601683616638184
Validation loss: 2.1363701743464314

Epoch: 6| Step: 2
Training loss: 2.0321080684661865
Validation loss: 2.116625729427543

Epoch: 6| Step: 3
Training loss: 2.1862363815307617
Validation loss: 2.1089392413375196

Epoch: 6| Step: 4
Training loss: 2.1657629013061523
Validation loss: 2.107812157241247

Epoch: 6| Step: 5
Training loss: 2.210061550140381
Validation loss: 2.0911501915224138

Epoch: 6| Step: 6
Training loss: 2.0188217163085938
Validation loss: 2.0593341294155327

Epoch: 6| Step: 7
Training loss: 2.8885302543640137
Validation loss: 2.0626494115398777

Epoch: 6| Step: 8
Training loss: 2.634850025177002
Validation loss: 2.070594665824726

Epoch: 6| Step: 9
Training loss: 1.5292911529541016
Validation loss: 2.04639724762209

Epoch: 6| Step: 10
Training loss: 2.7601006031036377
Validation loss: 2.0774651996551023

Epoch: 6| Step: 11
Training loss: 2.5324501991271973
Validation loss: 2.1139502217692714

Epoch: 6| Step: 12
Training loss: 1.67098867893219
Validation loss: 2.0933159294948784

Epoch: 6| Step: 13
Training loss: 3.276970863342285
Validation loss: 2.1247780963938725

Epoch: 58| Step: 0
Training loss: 2.8625612258911133
Validation loss: 2.0711556147503596

Epoch: 6| Step: 1
Training loss: 2.49415922164917
Validation loss: 2.0757880505695137

Epoch: 6| Step: 2
Training loss: 2.760787010192871
Validation loss: 2.066890717834555

Epoch: 6| Step: 3
Training loss: 2.2423899173736572
Validation loss: 2.0824170958611274

Epoch: 6| Step: 4
Training loss: 1.9814847707748413
Validation loss: 2.08321645439312

Epoch: 6| Step: 5
Training loss: 2.0403637886047363
Validation loss: 2.11361466556467

Epoch: 6| Step: 6
Training loss: 2.461073637008667
Validation loss: 2.0859759469186105

Epoch: 6| Step: 7
Training loss: 2.507204532623291
Validation loss: 2.07959073076966

Epoch: 6| Step: 8
Training loss: 3.2526988983154297
Validation loss: 2.0526520654719365

Epoch: 6| Step: 9
Training loss: 1.7247766256332397
Validation loss: 2.108815344431067

Epoch: 6| Step: 10
Training loss: 1.815272569656372
Validation loss: 2.0489383128381546

Epoch: 6| Step: 11
Training loss: 1.8463802337646484
Validation loss: 2.116206125546527

Epoch: 6| Step: 12
Training loss: 2.940826416015625
Validation loss: 2.0914830853862147

Epoch: 6| Step: 13
Training loss: 2.0374269485473633
Validation loss: 2.1032916935541297

Epoch: 59| Step: 0
Training loss: 2.0691909790039062
Validation loss: 2.0941310979986705

Epoch: 6| Step: 1
Training loss: 2.1186447143554688
Validation loss: 2.101563661329208

Epoch: 6| Step: 2
Training loss: 2.2351291179656982
Validation loss: 2.0873676858922487

Epoch: 6| Step: 3
Training loss: 2.872464656829834
Validation loss: 2.1031074216288905

Epoch: 6| Step: 4
Training loss: 2.5695321559906006
Validation loss: 2.0991305407657417

Epoch: 6| Step: 5
Training loss: 2.1421709060668945
Validation loss: 2.1138977568636657

Epoch: 6| Step: 6
Training loss: 1.982870101928711
Validation loss: 2.076166441363673

Epoch: 6| Step: 7
Training loss: 2.325186252593994
Validation loss: 2.0557762281869048

Epoch: 6| Step: 8
Training loss: 1.9002244472503662
Validation loss: 2.0956873329736854

Epoch: 6| Step: 9
Training loss: 2.805469512939453
Validation loss: 2.123720233158399

Epoch: 6| Step: 10
Training loss: 2.0786080360412598
Validation loss: 2.073517473795081

Epoch: 6| Step: 11
Training loss: 2.6593375205993652
Validation loss: 2.128874353183213

Epoch: 6| Step: 12
Training loss: 3.0716145038604736
Validation loss: 2.092113705091579

Epoch: 6| Step: 13
Training loss: 1.9090207815170288
Validation loss: 2.1029285154035016

Epoch: 60| Step: 0
Training loss: 2.4999403953552246
Validation loss: 2.097592141038628

Epoch: 6| Step: 1
Training loss: 2.3513574600219727
Validation loss: 2.096483099845148

Epoch: 6| Step: 2
Training loss: 2.2424633502960205
Validation loss: 2.104160738247697

Epoch: 6| Step: 3
Training loss: 3.5640556812286377
Validation loss: 2.0790183287794872

Epoch: 6| Step: 4
Training loss: 2.626760482788086
Validation loss: 2.049356015779639

Epoch: 6| Step: 5
Training loss: 2.0991697311401367
Validation loss: 2.0524221184433147

Epoch: 6| Step: 6
Training loss: 1.9388999938964844
Validation loss: 2.069955354095787

Epoch: 6| Step: 7
Training loss: 2.4950671195983887
Validation loss: 2.093825296689105

Epoch: 6| Step: 8
Training loss: 2.1508500576019287
Validation loss: 2.1289637883504233

Epoch: 6| Step: 9
Training loss: 1.925727367401123
Validation loss: 2.0821032703563733

Epoch: 6| Step: 10
Training loss: 2.3623507022857666
Validation loss: 2.1408521308693835

Epoch: 6| Step: 11
Training loss: 2.1577792167663574
Validation loss: 2.100567835633473

Epoch: 6| Step: 12
Training loss: 2.0166735649108887
Validation loss: 2.101975664015739

Epoch: 6| Step: 13
Training loss: 2.316751718521118
Validation loss: 2.074630486067905

Epoch: 61| Step: 0
Training loss: 2.1307921409606934
Validation loss: 2.1255335500163417

Epoch: 6| Step: 1
Training loss: 2.216669797897339
Validation loss: 2.0966937644507295

Epoch: 6| Step: 2
Training loss: 2.6506052017211914
Validation loss: 2.08315303761472

Epoch: 6| Step: 3
Training loss: 2.022233724594116
Validation loss: 2.1057636609641452

Epoch: 6| Step: 4
Training loss: 2.1775171756744385
Validation loss: 2.0987140363262546

Epoch: 6| Step: 5
Training loss: 2.6629929542541504
Validation loss: 2.1009325852958103

Epoch: 6| Step: 6
Training loss: 2.422233819961548
Validation loss: 2.075036638526506

Epoch: 6| Step: 7
Training loss: 2.263239860534668
Validation loss: 2.0537356843230543

Epoch: 6| Step: 8
Training loss: 1.6517482995986938
Validation loss: 2.07217748190767

Epoch: 6| Step: 9
Training loss: 2.6466689109802246
Validation loss: 2.050542116165161

Epoch: 6| Step: 10
Training loss: 2.440370559692383
Validation loss: 2.078464046601326

Epoch: 6| Step: 11
Training loss: 2.4585471153259277
Validation loss: 2.0456932449853547

Epoch: 6| Step: 12
Training loss: 2.6258656978607178
Validation loss: 2.0940815889707176

Epoch: 6| Step: 13
Training loss: 1.5040284395217896
Validation loss: 2.086807973923222

Epoch: 62| Step: 0
Training loss: 2.6891074180603027
Validation loss: 2.0574559075858003

Epoch: 6| Step: 1
Training loss: 2.108755350112915
Validation loss: 2.0577365249715824

Epoch: 6| Step: 2
Training loss: 2.602327823638916
Validation loss: 2.059218409240887

Epoch: 6| Step: 3
Training loss: 2.265878677368164
Validation loss: 2.0948542574400544

Epoch: 6| Step: 4
Training loss: 2.439635753631592
Validation loss: 2.0494468417218936

Epoch: 6| Step: 5
Training loss: 2.0802769660949707
Validation loss: 2.0603919541963966

Epoch: 6| Step: 6
Training loss: 2.766421318054199
Validation loss: 2.088798843404298

Epoch: 6| Step: 7
Training loss: 2.4607272148132324
Validation loss: 2.0355809683440835

Epoch: 6| Step: 8
Training loss: 1.8152804374694824
Validation loss: 2.101181532747002

Epoch: 6| Step: 9
Training loss: 2.3403820991516113
Validation loss: 2.123818455203887

Epoch: 6| Step: 10
Training loss: 2.537534475326538
Validation loss: 2.074688060309297

Epoch: 6| Step: 11
Training loss: 1.577430248260498
Validation loss: 2.0880558516389582

Epoch: 6| Step: 12
Training loss: 2.566560745239258
Validation loss: 2.1211567873595865

Epoch: 6| Step: 13
Training loss: 2.9871511459350586
Validation loss: 2.110644264887738

Epoch: 63| Step: 0
Training loss: 1.9130349159240723
Validation loss: 2.102055027920713

Epoch: 6| Step: 1
Training loss: 1.6390628814697266
Validation loss: 2.0873594937785978

Epoch: 6| Step: 2
Training loss: 3.158857822418213
Validation loss: 2.0777325502005954

Epoch: 6| Step: 3
Training loss: 2.5427212715148926
Validation loss: 2.0701285382752777

Epoch: 6| Step: 4
Training loss: 2.1287918090820312
Validation loss: 2.0951375692121443

Epoch: 6| Step: 5
Training loss: 2.8064963817596436
Validation loss: 2.1140351923563148

Epoch: 6| Step: 6
Training loss: 2.2273099422454834
Validation loss: 2.059645096460978

Epoch: 6| Step: 7
Training loss: 2.449270248413086
Validation loss: 2.1362656393358783

Epoch: 6| Step: 8
Training loss: 1.480319857597351
Validation loss: 2.1114552328663487

Epoch: 6| Step: 9
Training loss: 3.0893826484680176
Validation loss: 2.1109909062744467

Epoch: 6| Step: 10
Training loss: 1.7692022323608398
Validation loss: 2.1326214446816394

Epoch: 6| Step: 11
Training loss: 2.404514789581299
Validation loss: 2.106002967844727

Epoch: 6| Step: 12
Training loss: 2.380394458770752
Validation loss: 2.132867233727568

Epoch: 6| Step: 13
Training loss: 2.4957735538482666
Validation loss: 2.102215313142346

Epoch: 64| Step: 0
Training loss: 2.934720754623413
Validation loss: 2.094889615171699

Epoch: 6| Step: 1
Training loss: 2.447549819946289
Validation loss: 2.07905924448403

Epoch: 6| Step: 2
Training loss: 2.1563615798950195
Validation loss: 2.0959023685865503

Epoch: 6| Step: 3
Training loss: 2.278381824493408
Validation loss: 2.0867694039498605

Epoch: 6| Step: 4
Training loss: 2.5440351963043213
Validation loss: 2.09827842250947

Epoch: 6| Step: 5
Training loss: 2.41243839263916
Validation loss: 2.0512068156273133

Epoch: 6| Step: 6
Training loss: 2.5073800086975098
Validation loss: 2.0998424765884236

Epoch: 6| Step: 7
Training loss: 2.1594886779785156
Validation loss: 2.086280051098075

Epoch: 6| Step: 8
Training loss: 2.2389142513275146
Validation loss: 2.074845378116895

Epoch: 6| Step: 9
Training loss: 1.2138373851776123
Validation loss: 2.061137673675373

Epoch: 6| Step: 10
Training loss: 2.5711004734039307
Validation loss: 2.0497093123774373

Epoch: 6| Step: 11
Training loss: 1.9965810775756836
Validation loss: 2.057563639456226

Epoch: 6| Step: 12
Training loss: 2.8069193363189697
Validation loss: 2.07421883075468

Epoch: 6| Step: 13
Training loss: 1.823198914527893
Validation loss: 2.0645064871798278

Epoch: 65| Step: 0
Training loss: 2.1719751358032227
Validation loss: 2.0855019502742316

Epoch: 6| Step: 1
Training loss: 2.314410924911499
Validation loss: 2.0701122027571484

Epoch: 6| Step: 2
Training loss: 2.179100513458252
Validation loss: 2.0421798088217296

Epoch: 6| Step: 3
Training loss: 1.5781973600387573
Validation loss: 2.057900280080816

Epoch: 6| Step: 4
Training loss: 2.2888388633728027
Validation loss: 2.0431239771586593

Epoch: 6| Step: 5
Training loss: 2.143587112426758
Validation loss: 2.0231917801723687

Epoch: 6| Step: 6
Training loss: 2.3578543663024902
Validation loss: 2.1110293519112373

Epoch: 6| Step: 7
Training loss: 2.2887651920318604
Validation loss: 2.054991443951925

Epoch: 6| Step: 8
Training loss: 2.430567979812622
Validation loss: 2.089072154414269

Epoch: 6| Step: 9
Training loss: 2.6931886672973633
Validation loss: 2.0741567201511835

Epoch: 6| Step: 10
Training loss: 2.1011672019958496
Validation loss: 2.0794620308824765

Epoch: 6| Step: 11
Training loss: 1.9495160579681396
Validation loss: 2.0565519614886214

Epoch: 6| Step: 12
Training loss: 3.1553144454956055
Validation loss: 2.1142784369889127

Epoch: 6| Step: 13
Training loss: 3.114514112472534
Validation loss: 2.0789992834932063

Epoch: 66| Step: 0
Training loss: 3.0655858516693115
Validation loss: 2.0881584587917534

Epoch: 6| Step: 1
Training loss: 2.4186651706695557
Validation loss: 2.0863589881568827

Epoch: 6| Step: 2
Training loss: 2.0999374389648438
Validation loss: 2.0368437459391933

Epoch: 6| Step: 3
Training loss: 1.446256399154663
Validation loss: 2.1051743312548568

Epoch: 6| Step: 4
Training loss: 2.3713560104370117
Validation loss: 2.0852409549938735

Epoch: 6| Step: 5
Training loss: 2.504079818725586
Validation loss: 2.1096331522028935

Epoch: 6| Step: 6
Training loss: 2.506157875061035
Validation loss: 2.0463745312024186

Epoch: 6| Step: 7
Training loss: 2.5977602005004883
Validation loss: 2.088218847910563

Epoch: 6| Step: 8
Training loss: 2.3452816009521484
Validation loss: 2.0894420941670737

Epoch: 6| Step: 9
Training loss: 1.9245994091033936
Validation loss: 2.075350025648712

Epoch: 6| Step: 10
Training loss: 2.32559871673584
Validation loss: 2.13886357379216

Epoch: 6| Step: 11
Training loss: 2.496119737625122
Validation loss: 2.125574791303245

Epoch: 6| Step: 12
Training loss: 2.3485865592956543
Validation loss: 2.1213539659336047

Epoch: 6| Step: 13
Training loss: 1.9562238454818726
Validation loss: 2.0665749606265815

Epoch: 67| Step: 0
Training loss: 2.4397811889648438
Validation loss: 2.086172811446651

Epoch: 6| Step: 1
Training loss: 2.48264741897583
Validation loss: 2.099615458519228

Epoch: 6| Step: 2
Training loss: 2.542584180831909
Validation loss: 2.069674567509723

Epoch: 6| Step: 3
Training loss: 2.125473737716675
Validation loss: 2.067900308998682

Epoch: 6| Step: 4
Training loss: 2.109863758087158
Validation loss: 2.1239044999563568

Epoch: 6| Step: 5
Training loss: 1.8668380975723267
Validation loss: 2.1065530635977305

Epoch: 6| Step: 6
Training loss: 2.2261176109313965
Validation loss: 2.040882191350383

Epoch: 6| Step: 7
Training loss: 2.4319207668304443
Validation loss: 2.0522266639176237

Epoch: 6| Step: 8
Training loss: 2.6626436710357666
Validation loss: 2.083988961353097

Epoch: 6| Step: 9
Training loss: 1.4978208541870117
Validation loss: 2.1028288705374605

Epoch: 6| Step: 10
Training loss: 2.699579954147339
Validation loss: 2.0994342462990874

Epoch: 6| Step: 11
Training loss: 2.4010677337646484
Validation loss: 2.105750190314426

Epoch: 6| Step: 12
Training loss: 1.9144166707992554
Validation loss: 2.127689866609471

Epoch: 6| Step: 13
Training loss: 3.637455940246582
Validation loss: 2.0871301799692135

Epoch: 68| Step: 0
Training loss: 2.595183849334717
Validation loss: 2.1246346786458004

Epoch: 6| Step: 1
Training loss: 2.098809242248535
Validation loss: 2.073070269758983

Epoch: 6| Step: 2
Training loss: 2.57220458984375
Validation loss: 2.111217075778592

Epoch: 6| Step: 3
Training loss: 2.1151182651519775
Validation loss: 2.089550241347282

Epoch: 6| Step: 4
Training loss: 2.568294048309326
Validation loss: 2.110596864454208

Epoch: 6| Step: 5
Training loss: 2.79313325881958
Validation loss: 2.091108195243343

Epoch: 6| Step: 6
Training loss: 2.0118794441223145
Validation loss: 2.067721882174092

Epoch: 6| Step: 7
Training loss: 2.543498992919922
Validation loss: 2.0887841678434804

Epoch: 6| Step: 8
Training loss: 1.6490172147750854
Validation loss: 2.110337454785583

Epoch: 6| Step: 9
Training loss: 2.4358787536621094
Validation loss: 2.0762715314024236

Epoch: 6| Step: 10
Training loss: 2.611961603164673
Validation loss: 2.062586756162746

Epoch: 6| Step: 11
Training loss: 2.956895589828491
Validation loss: 2.0928902933674474

Epoch: 6| Step: 12
Training loss: 1.3350200653076172
Validation loss: 2.074665350298728

Epoch: 6| Step: 13
Training loss: 2.186018943786621
Validation loss: 2.099242957689429

Epoch: 69| Step: 0
Training loss: 2.02889347076416
Validation loss: 2.0728769661277853

Epoch: 6| Step: 1
Training loss: 2.4592061042785645
Validation loss: 2.1195491718989548

Epoch: 6| Step: 2
Training loss: 2.24800443649292
Validation loss: 2.083616445141454

Epoch: 6| Step: 3
Training loss: 1.905991792678833
Validation loss: 2.1175452483597623

Epoch: 6| Step: 4
Training loss: 2.5566582679748535
Validation loss: 2.1205900804970854

Epoch: 6| Step: 5
Training loss: 2.5792253017425537
Validation loss: 2.060775245389631

Epoch: 6| Step: 6
Training loss: 1.9521276950836182
Validation loss: 2.137734656692833

Epoch: 6| Step: 7
Training loss: 2.3463315963745117
Validation loss: 2.0529170549044045

Epoch: 6| Step: 8
Training loss: 2.8644485473632812
Validation loss: 2.113779596103135

Epoch: 6| Step: 9
Training loss: 1.8713488578796387
Validation loss: 2.1052405424015497

Epoch: 6| Step: 10
Training loss: 2.2616028785705566
Validation loss: 2.0587914066929973

Epoch: 6| Step: 11
Training loss: 2.6688830852508545
Validation loss: 2.078828796263664

Epoch: 6| Step: 12
Training loss: 2.0310583114624023
Validation loss: 2.1354405059609363

Epoch: 6| Step: 13
Training loss: 3.1130213737487793
Validation loss: 2.0642640180485223

Epoch: 70| Step: 0
Training loss: 2.1028404235839844
Validation loss: 2.040459730291879

Epoch: 6| Step: 1
Training loss: 1.8060994148254395
Validation loss: 2.0985437477788618

Epoch: 6| Step: 2
Training loss: 1.8793585300445557
Validation loss: 2.0584406442539667

Epoch: 6| Step: 3
Training loss: 2.4831323623657227
Validation loss: 2.0631956246591385

Epoch: 6| Step: 4
Training loss: 2.640326499938965
Validation loss: 2.015010772212859

Epoch: 6| Step: 5
Training loss: 1.935464859008789
Validation loss: 2.0936913746659473

Epoch: 6| Step: 6
Training loss: 2.602926254272461
Validation loss: 2.0754641845662105

Epoch: 6| Step: 7
Training loss: 3.0967183113098145
Validation loss: 2.0973335722441315

Epoch: 6| Step: 8
Training loss: 2.208472728729248
Validation loss: 2.1012517354821645

Epoch: 6| Step: 9
Training loss: 2.328535556793213
Validation loss: 2.0255998437122633

Epoch: 6| Step: 10
Training loss: 2.360354423522949
Validation loss: 2.157249700638556

Epoch: 6| Step: 11
Training loss: 3.028707504272461
Validation loss: 2.0922481359974032

Epoch: 6| Step: 12
Training loss: 2.1375856399536133
Validation loss: 2.122819854367164

Epoch: 6| Step: 13
Training loss: 1.6520912647247314
Validation loss: 2.1153163243365545

Epoch: 71| Step: 0
Training loss: 2.239516258239746
Validation loss: 2.1153786618222474

Epoch: 6| Step: 1
Training loss: 3.273566246032715
Validation loss: 2.0663128270897815

Epoch: 6| Step: 2
Training loss: 2.748684883117676
Validation loss: 2.0991047659227924

Epoch: 6| Step: 3
Training loss: 2.8093080520629883
Validation loss: 2.124856141305739

Epoch: 6| Step: 4
Training loss: 2.8637468814849854
Validation loss: 2.183338144774078

Epoch: 6| Step: 5
Training loss: 2.464146375656128
Validation loss: 2.070620690622637

Epoch: 6| Step: 6
Training loss: 2.145087718963623
Validation loss: 2.0953525240703295

Epoch: 6| Step: 7
Training loss: 1.7139538526535034
Validation loss: 2.101581549131742

Epoch: 6| Step: 8
Training loss: 2.140338182449341
Validation loss: 2.136817027163762

Epoch: 6| Step: 9
Training loss: 1.8461049795150757
Validation loss: 2.1519400381272837

Epoch: 6| Step: 10
Training loss: 2.2151246070861816
Validation loss: 2.093821165382221

Epoch: 6| Step: 11
Training loss: 2.4976143836975098
Validation loss: 2.080171667119508

Epoch: 6| Step: 12
Training loss: 1.890411376953125
Validation loss: 2.066599187030587

Epoch: 6| Step: 13
Training loss: 1.588904857635498
Validation loss: 2.123609237773444

Epoch: 72| Step: 0
Training loss: 2.404271125793457
Validation loss: 2.116535771277643

Epoch: 6| Step: 1
Training loss: 2.299058437347412
Validation loss: 2.0904098813251784

Epoch: 6| Step: 2
Training loss: 2.5833053588867188
Validation loss: 2.084208457700668

Epoch: 6| Step: 3
Training loss: 2.3720054626464844
Validation loss: 2.111958872887396

Epoch: 6| Step: 4
Training loss: 2.5857059955596924
Validation loss: 2.102521893798664

Epoch: 6| Step: 5
Training loss: 2.015967607498169
Validation loss: 2.07893209303579

Epoch: 6| Step: 6
Training loss: 1.661942958831787
Validation loss: 2.107148757544897

Epoch: 6| Step: 7
Training loss: 2.028780460357666
Validation loss: 2.102981654546594

Epoch: 6| Step: 8
Training loss: 2.583601713180542
Validation loss: 2.1247073604214575

Epoch: 6| Step: 9
Training loss: 2.5490970611572266
Validation loss: 2.098275407668083

Epoch: 6| Step: 10
Training loss: 2.4351980686187744
Validation loss: 2.1249073026000813

Epoch: 6| Step: 11
Training loss: 2.203613758087158
Validation loss: 2.1499081337323753

Epoch: 6| Step: 12
Training loss: 2.409928560256958
Validation loss: 2.084982179826306

Epoch: 6| Step: 13
Training loss: 2.442431688308716
Validation loss: 2.0859825047113563

Epoch: 73| Step: 0
Training loss: 2.640881061553955
Validation loss: 2.106202419086169

Epoch: 6| Step: 1
Training loss: 2.0881638526916504
Validation loss: 2.1471282512910905

Epoch: 6| Step: 2
Training loss: 2.0938303470611572
Validation loss: 2.114427264018725

Epoch: 6| Step: 3
Training loss: 3.3929967880249023
Validation loss: 2.069555749175369

Epoch: 6| Step: 4
Training loss: 2.9109485149383545
Validation loss: 2.0905386324851745

Epoch: 6| Step: 5
Training loss: 1.7685015201568604
Validation loss: 2.1563409707879506

Epoch: 6| Step: 6
Training loss: 1.9453428983688354
Validation loss: 2.0799797773361206

Epoch: 6| Step: 7
Training loss: 2.054067373275757
Validation loss: 2.1149437683884815

Epoch: 6| Step: 8
Training loss: 1.799837350845337
Validation loss: 2.063438997473768

Epoch: 6| Step: 9
Training loss: 1.9249050617218018
Validation loss: 2.115987029126895

Epoch: 6| Step: 10
Training loss: 2.067012071609497
Validation loss: 2.1080348107122604

Epoch: 6| Step: 11
Training loss: 2.3370730876922607
Validation loss: 2.0646226226642566

Epoch: 6| Step: 12
Training loss: 2.4985342025756836
Validation loss: 2.0802853645816928

Epoch: 6| Step: 13
Training loss: 2.4631431102752686
Validation loss: 2.0697148897314586

Epoch: 74| Step: 0
Training loss: 2.203099250793457
Validation loss: 2.065193509542814

Epoch: 6| Step: 1
Training loss: 2.0522119998931885
Validation loss: 2.088448134801721

Epoch: 6| Step: 2
Training loss: 3.0422544479370117
Validation loss: 2.088372420239192

Epoch: 6| Step: 3
Training loss: 2.3548851013183594
Validation loss: 2.0923901886068363

Epoch: 6| Step: 4
Training loss: 1.937720537185669
Validation loss: 2.0610070036303614

Epoch: 6| Step: 5
Training loss: 1.959486484527588
Validation loss: 2.109923453741176

Epoch: 6| Step: 6
Training loss: 2.2273435592651367
Validation loss: 2.112825350094867

Epoch: 6| Step: 7
Training loss: 2.9825141429901123
Validation loss: 2.1279869489772345

Epoch: 6| Step: 8
Training loss: 2.2978479862213135
Validation loss: 2.0315756182516775

Epoch: 6| Step: 9
Training loss: 2.629607677459717
Validation loss: 2.021282137081187

Epoch: 6| Step: 10
Training loss: 2.4678964614868164
Validation loss: 2.0860282554421374

Epoch: 6| Step: 11
Training loss: 2.33353590965271
Validation loss: 2.1147849072692213

Epoch: 6| Step: 12
Training loss: 1.4389679431915283
Validation loss: 2.084932122179257

Epoch: 6| Step: 13
Training loss: 2.2343661785125732
Validation loss: 2.162791029099495

Epoch: 75| Step: 0
Training loss: 2.3883001804351807
Validation loss: 2.0530070694543983

Epoch: 6| Step: 1
Training loss: 2.3648996353149414
Validation loss: 2.0945523938825055

Epoch: 6| Step: 2
Training loss: 2.0200634002685547
Validation loss: 2.068136299810102

Epoch: 6| Step: 3
Training loss: 2.157687187194824
Validation loss: 2.040260099595593

Epoch: 6| Step: 4
Training loss: 2.2488620281219482
Validation loss: 2.051530263757193

Epoch: 6| Step: 5
Training loss: 2.231410026550293
Validation loss: 2.0381159115863103

Epoch: 6| Step: 6
Training loss: 2.3293845653533936
Validation loss: 2.076697823821857

Epoch: 6| Step: 7
Training loss: 2.146359920501709
Validation loss: 2.0770262979692027

Epoch: 6| Step: 8
Training loss: 2.1452953815460205
Validation loss: 2.0849670043555637

Epoch: 6| Step: 9
Training loss: 2.5967564582824707
Validation loss: 2.035153394104332

Epoch: 6| Step: 10
Training loss: 2.939365863800049
Validation loss: 2.073780193123766

Epoch: 6| Step: 11
Training loss: 2.2733843326568604
Validation loss: 2.0717861960011144

Epoch: 6| Step: 12
Training loss: 2.7506895065307617
Validation loss: 2.1160733956162647

Epoch: 6| Step: 13
Training loss: 1.1789418458938599
Validation loss: 2.0936428321305143

Epoch: 76| Step: 0
Training loss: 2.1936566829681396
Validation loss: 2.110601463625508

Epoch: 6| Step: 1
Training loss: 2.0409440994262695
Validation loss: 2.1116584347140406

Epoch: 6| Step: 2
Training loss: 2.1310529708862305
Validation loss: 2.0879797358666696

Epoch: 6| Step: 3
Training loss: 1.8450411558151245
Validation loss: 2.07776887442476

Epoch: 6| Step: 4
Training loss: 1.9257757663726807
Validation loss: 2.1150026782866447

Epoch: 6| Step: 5
Training loss: 2.279871702194214
Validation loss: 2.0897047852957122

Epoch: 6| Step: 6
Training loss: 2.7220163345336914
Validation loss: 2.1217739684607393

Epoch: 6| Step: 7
Training loss: 2.127621650695801
Validation loss: 2.0925225852638163

Epoch: 6| Step: 8
Training loss: 2.2215416431427
Validation loss: 2.10244123525517

Epoch: 6| Step: 9
Training loss: 2.4957733154296875
Validation loss: 2.1041506798036638

Epoch: 6| Step: 10
Training loss: 2.524667739868164
Validation loss: 2.084306663082492

Epoch: 6| Step: 11
Training loss: 2.498847007751465
Validation loss: 2.115346670150757

Epoch: 6| Step: 12
Training loss: 2.319956064224243
Validation loss: 2.1227760032940934

Epoch: 6| Step: 13
Training loss: 2.9440393447875977
Validation loss: 2.091079486313687

Epoch: 77| Step: 0
Training loss: 2.382749557495117
Validation loss: 2.1330867916025142

Epoch: 6| Step: 1
Training loss: 2.6788368225097656
Validation loss: 2.132023129411923

Epoch: 6| Step: 2
Training loss: 2.94504451751709
Validation loss: 2.107331250303535

Epoch: 6| Step: 3
Training loss: 2.763537883758545
Validation loss: 2.1516529283215924

Epoch: 6| Step: 4
Training loss: 1.8928111791610718
Validation loss: 2.1250927884091615

Epoch: 6| Step: 5
Training loss: 1.3537777662277222
Validation loss: 2.1630917967006726

Epoch: 6| Step: 6
Training loss: 2.321983814239502
Validation loss: 2.1072836883606447

Epoch: 6| Step: 7
Training loss: 2.0212244987487793
Validation loss: 2.1342378406114477

Epoch: 6| Step: 8
Training loss: 1.86061429977417
Validation loss: 2.144903962330152

Epoch: 6| Step: 9
Training loss: 2.393528938293457
Validation loss: 2.0985286440900577

Epoch: 6| Step: 10
Training loss: 1.668249249458313
Validation loss: 2.121270477130849

Epoch: 6| Step: 11
Training loss: 2.4861764907836914
Validation loss: 2.0970329174431424

Epoch: 6| Step: 12
Training loss: 2.5749921798706055
Validation loss: 2.0853374863183625

Epoch: 6| Step: 13
Training loss: 3.481130838394165
Validation loss: 2.103518655223231

Epoch: 78| Step: 0
Training loss: 2.7587790489196777
Validation loss: 2.0939738994003623

Epoch: 6| Step: 1
Training loss: 2.586825132369995
Validation loss: 2.1285945061714417

Epoch: 6| Step: 2
Training loss: 2.508741855621338
Validation loss: 2.1737335164059877

Epoch: 6| Step: 3
Training loss: 1.9888875484466553
Validation loss: 2.115686485844274

Epoch: 6| Step: 4
Training loss: 3.1140756607055664
Validation loss: 2.121884156298894

Epoch: 6| Step: 5
Training loss: 1.7849148511886597
Validation loss: 2.1254250541810067

Epoch: 6| Step: 6
Training loss: 1.961724042892456
Validation loss: 2.1307200052404918

Epoch: 6| Step: 7
Training loss: 2.7340500354766846
Validation loss: 2.144998122287053

Epoch: 6| Step: 8
Training loss: 2.2234654426574707
Validation loss: 2.101930249121881

Epoch: 6| Step: 9
Training loss: 2.4024548530578613
Validation loss: 2.1221466115725938

Epoch: 6| Step: 10
Training loss: 1.879995346069336
Validation loss: 2.118327781718264

Epoch: 6| Step: 11
Training loss: 2.3708529472351074
Validation loss: 2.0363409519195557

Epoch: 6| Step: 12
Training loss: 1.8949873447418213
Validation loss: 2.102761483961536

Epoch: 6| Step: 13
Training loss: 1.5313336849212646
Validation loss: 2.103429573838429

Epoch: 79| Step: 0
Training loss: 2.1279635429382324
Validation loss: 2.0938265528730167

Epoch: 6| Step: 1
Training loss: 2.3389782905578613
Validation loss: 2.075196836584358

Epoch: 6| Step: 2
Training loss: 2.8064022064208984
Validation loss: 2.0947586438989125

Epoch: 6| Step: 3
Training loss: 1.932076096534729
Validation loss: 2.113164392850732

Epoch: 6| Step: 4
Training loss: 2.3053388595581055
Validation loss: 2.1552973126852386

Epoch: 6| Step: 5
Training loss: 2.7907121181488037
Validation loss: 2.113009382319707

Epoch: 6| Step: 6
Training loss: 2.4210076332092285
Validation loss: 2.1112494673780215

Epoch: 6| Step: 7
Training loss: 2.0010886192321777
Validation loss: 2.10154866403149

Epoch: 6| Step: 8
Training loss: 2.7361464500427246
Validation loss: 2.0758112502354447

Epoch: 6| Step: 9
Training loss: 2.375786304473877
Validation loss: 2.1010276553451375

Epoch: 6| Step: 10
Training loss: 1.6035057306289673
Validation loss: 2.1314257216709915

Epoch: 6| Step: 11
Training loss: 2.14111590385437
Validation loss: 2.125939187183175

Epoch: 6| Step: 12
Training loss: 2.059617519378662
Validation loss: 2.0766471726920015

Epoch: 6| Step: 13
Training loss: 2.6494596004486084
Validation loss: 2.0790596674847346

Epoch: 80| Step: 0
Training loss: 2.9494364261627197
Validation loss: 2.0891093259216635

Epoch: 6| Step: 1
Training loss: 2.4837570190429688
Validation loss: 2.121648496197116

Epoch: 6| Step: 2
Training loss: 2.1279733180999756
Validation loss: 2.0825291987388366

Epoch: 6| Step: 3
Training loss: 2.0429162979125977
Validation loss: 2.090793401964249

Epoch: 6| Step: 4
Training loss: 2.6466963291168213
Validation loss: 2.0972886893057052

Epoch: 6| Step: 5
Training loss: 2.091172456741333
Validation loss: 2.091815112739481

Epoch: 6| Step: 6
Training loss: 1.9783594608306885
Validation loss: 2.105167047951811

Epoch: 6| Step: 7
Training loss: 2.3730411529541016
Validation loss: 2.142598549524943

Epoch: 6| Step: 8
Training loss: 2.4357247352600098
Validation loss: 2.101256024452948

Epoch: 6| Step: 9
Training loss: 2.167464256286621
Validation loss: 2.130507908841615

Epoch: 6| Step: 10
Training loss: 2.5863804817199707
Validation loss: 2.1249608993530273

Epoch: 6| Step: 11
Training loss: 2.009495258331299
Validation loss: 2.182714339225523

Epoch: 6| Step: 12
Training loss: 2.2474570274353027
Validation loss: 2.090726488380022

Epoch: 6| Step: 13
Training loss: 1.0835493803024292
Validation loss: 2.127667442444832

Epoch: 81| Step: 0
Training loss: 2.2078909873962402
Validation loss: 2.0715765517245055

Epoch: 6| Step: 1
Training loss: 1.7580115795135498
Validation loss: 2.1204619792199906

Epoch: 6| Step: 2
Training loss: 2.490290403366089
Validation loss: 2.1088103196954213

Epoch: 6| Step: 3
Training loss: 2.120450258255005
Validation loss: 2.1008591293006815

Epoch: 6| Step: 4
Training loss: 1.7585963010787964
Validation loss: 2.131507004460981

Epoch: 6| Step: 5
Training loss: 1.9892442226409912
Validation loss: 2.060626112004762

Epoch: 6| Step: 6
Training loss: 2.8332979679107666
Validation loss: 2.0571685375705844

Epoch: 6| Step: 7
Training loss: 2.23760986328125
Validation loss: 2.1103721818616314

Epoch: 6| Step: 8
Training loss: 2.8181920051574707
Validation loss: 2.1112216288043606

Epoch: 6| Step: 9
Training loss: 2.7233622074127197
Validation loss: 2.0286782967147006

Epoch: 6| Step: 10
Training loss: 2.50457763671875
Validation loss: 2.01645561187498

Epoch: 6| Step: 11
Training loss: 1.9914253950119019
Validation loss: 2.09199454194756

Epoch: 6| Step: 12
Training loss: 1.9059209823608398
Validation loss: 2.0780050780183528

Epoch: 6| Step: 13
Training loss: 2.9926517009735107
Validation loss: 2.0972231434237574

Epoch: 82| Step: 0
Training loss: 2.467320680618286
Validation loss: 2.0821232641896894

Epoch: 6| Step: 1
Training loss: 1.9304195642471313
Validation loss: 2.074224405391242

Epoch: 6| Step: 2
Training loss: 2.7746636867523193
Validation loss: 2.085771768323837

Epoch: 6| Step: 3
Training loss: 3.043520450592041
Validation loss: 2.0612938455356065

Epoch: 6| Step: 4
Training loss: 2.1340584754943848
Validation loss: 2.0852756487425936

Epoch: 6| Step: 5
Training loss: 2.1186416149139404
Validation loss: 2.01339707579664

Epoch: 6| Step: 6
Training loss: 1.7547378540039062
Validation loss: 2.089902723989179

Epoch: 6| Step: 7
Training loss: 1.8174681663513184
Validation loss: 2.0613035386608494

Epoch: 6| Step: 8
Training loss: 3.0219740867614746
Validation loss: 2.08331460337485

Epoch: 6| Step: 9
Training loss: 2.3120980262756348
Validation loss: 2.1097737832735945

Epoch: 6| Step: 10
Training loss: 1.8333238363265991
Validation loss: 2.0763987110507105

Epoch: 6| Step: 11
Training loss: 2.707913637161255
Validation loss: 2.0430290135004188

Epoch: 6| Step: 12
Training loss: 1.532585620880127
Validation loss: 2.055512156537784

Epoch: 6| Step: 13
Training loss: 2.9885807037353516
Validation loss: 2.1389215684706167

Epoch: 83| Step: 0
Training loss: 1.5652074813842773
Validation loss: 2.10394178154648

Epoch: 6| Step: 1
Training loss: 2.334550619125366
Validation loss: 2.071838407106297

Epoch: 6| Step: 2
Training loss: 2.4540629386901855
Validation loss: 2.0758281189908265

Epoch: 6| Step: 3
Training loss: 2.008897066116333
Validation loss: 2.13926040228977

Epoch: 6| Step: 4
Training loss: 2.83176326751709
Validation loss: 2.022448105196799

Epoch: 6| Step: 5
Training loss: 1.677410364151001
Validation loss: 2.0910494737727667

Epoch: 6| Step: 6
Training loss: 2.414851665496826
Validation loss: 2.097679374038532

Epoch: 6| Step: 7
Training loss: 2.4370219707489014
Validation loss: 2.1026144309710433

Epoch: 6| Step: 8
Training loss: 1.7882455587387085
Validation loss: 2.1125318747694775

Epoch: 6| Step: 9
Training loss: 2.699484348297119
Validation loss: 2.097985162529894

Epoch: 6| Step: 10
Training loss: 2.2090635299682617
Validation loss: 2.153619327852803

Epoch: 6| Step: 11
Training loss: 2.6384599208831787
Validation loss: 2.141827760204192

Epoch: 6| Step: 12
Training loss: 2.4418506622314453
Validation loss: 2.0873701585236417

Epoch: 6| Step: 13
Training loss: 2.10103440284729
Validation loss: 2.1476081007270404

Epoch: 84| Step: 0
Training loss: 2.821059226989746
Validation loss: 2.0975801150004068

Epoch: 6| Step: 1
Training loss: 1.9174002408981323
Validation loss: 2.12621884704918

Epoch: 6| Step: 2
Training loss: 2.5751571655273438
Validation loss: 2.1412296269529607

Epoch: 6| Step: 3
Training loss: 1.8299791812896729
Validation loss: 2.067868986437398

Epoch: 6| Step: 4
Training loss: 1.3499599695205688
Validation loss: 2.1223802297346053

Epoch: 6| Step: 5
Training loss: 2.3718039989471436
Validation loss: 2.125934575193672

Epoch: 6| Step: 6
Training loss: 2.8707518577575684
Validation loss: 2.0936542992950766

Epoch: 6| Step: 7
Training loss: 2.429264545440674
Validation loss: 2.144620480075959

Epoch: 6| Step: 8
Training loss: 2.118208885192871
Validation loss: 2.167614101081766

Epoch: 6| Step: 9
Training loss: 1.9132237434387207
Validation loss: 2.0910249089681976

Epoch: 6| Step: 10
Training loss: 3.1101255416870117
Validation loss: 2.0988740664656445

Epoch: 6| Step: 11
Training loss: 2.6224985122680664
Validation loss: 2.1080312498154177

Epoch: 6| Step: 12
Training loss: 2.597801685333252
Validation loss: 2.0748175997887888

Epoch: 6| Step: 13
Training loss: 1.1184422969818115
Validation loss: 2.0972430577842136

Epoch: 85| Step: 0
Training loss: 1.8876265287399292
Validation loss: 2.1067614734813733

Epoch: 6| Step: 1
Training loss: 1.7197667360305786
Validation loss: 2.1637656842508624

Epoch: 6| Step: 2
Training loss: 3.0021677017211914
Validation loss: 2.0656819420476116

Epoch: 6| Step: 3
Training loss: 2.3136143684387207
Validation loss: 2.132243602506576

Epoch: 6| Step: 4
Training loss: 2.7227234840393066
Validation loss: 2.110728208736707

Epoch: 6| Step: 5
Training loss: 2.498713493347168
Validation loss: 2.0871962026883195

Epoch: 6| Step: 6
Training loss: 2.1053924560546875
Validation loss: 2.1528049694594515

Epoch: 6| Step: 7
Training loss: 2.514289379119873
Validation loss: 2.1163713906400945

Epoch: 6| Step: 8
Training loss: 2.204606056213379
Validation loss: 2.1182217687688847

Epoch: 6| Step: 9
Training loss: 1.7163245677947998
Validation loss: 2.1321158409118652

Epoch: 6| Step: 10
Training loss: 2.392232656478882
Validation loss: 2.1252038607033352

Epoch: 6| Step: 11
Training loss: 3.009443998336792
Validation loss: 2.1136140938728087

Epoch: 6| Step: 12
Training loss: 1.6731500625610352
Validation loss: 2.147570756173903

Epoch: 6| Step: 13
Training loss: 1.587312936782837
Validation loss: 2.088088463711482

Epoch: 86| Step: 0
Training loss: 2.4681763648986816
Validation loss: 2.129479301873074

Epoch: 6| Step: 1
Training loss: 2.2853188514709473
Validation loss: 2.124270377620574

Epoch: 6| Step: 2
Training loss: 2.2609071731567383
Validation loss: 2.065436268365511

Epoch: 6| Step: 3
Training loss: 2.364262342453003
Validation loss: 2.118679593968135

Epoch: 6| Step: 4
Training loss: 2.659874439239502
Validation loss: 2.0949228130361086

Epoch: 6| Step: 5
Training loss: 2.1161890029907227
Validation loss: 2.065449001968548

Epoch: 6| Step: 6
Training loss: 1.8173816204071045
Validation loss: 2.102706129832934

Epoch: 6| Step: 7
Training loss: 1.8475666046142578
Validation loss: 2.1363957158980833

Epoch: 6| Step: 8
Training loss: 2.4240596294403076
Validation loss: 1.988367893362558

Epoch: 6| Step: 9
Training loss: 2.666226625442505
Validation loss: 2.0295337207855715

Epoch: 6| Step: 10
Training loss: 1.9901148080825806
Validation loss: 2.0529952305619434

Epoch: 6| Step: 11
Training loss: 2.6471059322357178
Validation loss: 2.116628146940662

Epoch: 6| Step: 12
Training loss: 1.9628649950027466
Validation loss: 2.087326765060425

Epoch: 6| Step: 13
Training loss: 2.3179686069488525
Validation loss: 2.078817939245573

Epoch: 87| Step: 0
Training loss: 1.971118688583374
Validation loss: 2.030198912466726

Epoch: 6| Step: 1
Training loss: 3.2031779289245605
Validation loss: 2.1260164373664447

Epoch: 6| Step: 2
Training loss: 3.021883964538574
Validation loss: 2.073385774448354

Epoch: 6| Step: 3
Training loss: 2.6548328399658203
Validation loss: 2.0864875880620812

Epoch: 6| Step: 4
Training loss: 2.5792908668518066
Validation loss: 2.078188516760385

Epoch: 6| Step: 5
Training loss: 2.4760289192199707
Validation loss: 2.0593684475908995

Epoch: 6| Step: 6
Training loss: 1.8294126987457275
Validation loss: 2.124505034057043

Epoch: 6| Step: 7
Training loss: 1.4882211685180664
Validation loss: 2.0904776909018077

Epoch: 6| Step: 8
Training loss: 2.741069793701172
Validation loss: 2.117992680559876

Epoch: 6| Step: 9
Training loss: 1.928192377090454
Validation loss: 2.1278441721393215

Epoch: 6| Step: 10
Training loss: 2.112016201019287
Validation loss: 2.1485843222628356

Epoch: 6| Step: 11
Training loss: 2.257761240005493
Validation loss: 2.1035235697223293

Epoch: 6| Step: 12
Training loss: 1.9628453254699707
Validation loss: 2.0993261465462307

Epoch: 6| Step: 13
Training loss: 1.504697322845459
Validation loss: 2.122898993953582

Epoch: 88| Step: 0
Training loss: 1.5968928337097168
Validation loss: 2.1093963141082437

Epoch: 6| Step: 1
Training loss: 2.3720598220825195
Validation loss: 2.1481113331292265

Epoch: 6| Step: 2
Training loss: 1.904705286026001
Validation loss: 2.104045933292758

Epoch: 6| Step: 3
Training loss: 2.2241594791412354
Validation loss: 2.066448953843886

Epoch: 6| Step: 4
Training loss: 2.141085147857666
Validation loss: 2.065709129456551

Epoch: 6| Step: 5
Training loss: 2.945394992828369
Validation loss: 2.144920451666719

Epoch: 6| Step: 6
Training loss: 3.052427053451538
Validation loss: 2.118428971177788

Epoch: 6| Step: 7
Training loss: 2.291043996810913
Validation loss: 2.0870662453354045

Epoch: 6| Step: 8
Training loss: 2.801048517227173
Validation loss: 2.0422391224932928

Epoch: 6| Step: 9
Training loss: 2.3509914875030518
Validation loss: 2.130033072604928

Epoch: 6| Step: 10
Training loss: 1.976730465888977
Validation loss: 2.0523277482678814

Epoch: 6| Step: 11
Training loss: 2.8232192993164062
Validation loss: 2.071705120866017

Epoch: 6| Step: 12
Training loss: 1.4396514892578125
Validation loss: 2.045533346873458

Epoch: 6| Step: 13
Training loss: 1.6159886121749878
Validation loss: 2.125660679673636

Epoch: 89| Step: 0
Training loss: 1.9836194515228271
Validation loss: 2.0586454522225166

Epoch: 6| Step: 1
Training loss: 2.8654136657714844
Validation loss: 2.0618613676358293

Epoch: 6| Step: 2
Training loss: 2.089345932006836
Validation loss: 2.0749110214171873

Epoch: 6| Step: 3
Training loss: 2.149127721786499
Validation loss: 2.108760374848561

Epoch: 6| Step: 4
Training loss: 2.9230830669403076
Validation loss: 2.095474657192025

Epoch: 6| Step: 5
Training loss: 2.2303991317749023
Validation loss: 2.09271268434422

Epoch: 6| Step: 6
Training loss: 2.4977846145629883
Validation loss: 2.073256472105621

Epoch: 6| Step: 7
Training loss: 1.7928121089935303
Validation loss: 2.0862516741598807

Epoch: 6| Step: 8
Training loss: 3.0135788917541504
Validation loss: 2.126830541959373

Epoch: 6| Step: 9
Training loss: 2.060415744781494
Validation loss: 2.1208230231397893

Epoch: 6| Step: 10
Training loss: 2.0828967094421387
Validation loss: 2.1046475236133864

Epoch: 6| Step: 11
Training loss: 1.8786590099334717
Validation loss: 2.1501701057598157

Epoch: 6| Step: 12
Training loss: 2.18113374710083
Validation loss: 2.0573623744390344

Epoch: 6| Step: 13
Training loss: 2.504084587097168
Validation loss: 2.0967023962287494

Epoch: 90| Step: 0
Training loss: 2.2044785022735596
Validation loss: 2.079647587191674

Epoch: 6| Step: 1
Training loss: 2.093294143676758
Validation loss: 2.125405252620738

Epoch: 6| Step: 2
Training loss: 2.506612777709961
Validation loss: 2.056693248851325

Epoch: 6| Step: 3
Training loss: 1.8255434036254883
Validation loss: 2.107867956161499

Epoch: 6| Step: 4
Training loss: 1.875849962234497
Validation loss: 2.059259835109916

Epoch: 6| Step: 5
Training loss: 3.322068452835083
Validation loss: 2.12045564446398

Epoch: 6| Step: 6
Training loss: 1.8359638452529907
Validation loss: 2.087678033818481

Epoch: 6| Step: 7
Training loss: 3.3904566764831543
Validation loss: 2.095500910153953

Epoch: 6| Step: 8
Training loss: 2.5126700401306152
Validation loss: 2.054631038378644

Epoch: 6| Step: 9
Training loss: 2.2502522468566895
Validation loss: 2.105602060594866

Epoch: 6| Step: 10
Training loss: 2.021718740463257
Validation loss: 2.1280634236592118

Epoch: 6| Step: 11
Training loss: 2.10636305809021
Validation loss: 2.098157336634974

Epoch: 6| Step: 12
Training loss: 1.5158040523529053
Validation loss: 2.1546941905893306

Epoch: 6| Step: 13
Training loss: 2.478764295578003
Validation loss: 2.1056069058756672

Epoch: 91| Step: 0
Training loss: 2.03999400138855
Validation loss: 2.1004070979292675

Epoch: 6| Step: 1
Training loss: 1.780975341796875
Validation loss: 2.0904449878200406

Epoch: 6| Step: 2
Training loss: 1.6646218299865723
Validation loss: 2.107337572241342

Epoch: 6| Step: 3
Training loss: 2.1617209911346436
Validation loss: 2.1216396260005173

Epoch: 6| Step: 4
Training loss: 2.350703716278076
Validation loss: 2.069651895953763

Epoch: 6| Step: 5
Training loss: 2.2979750633239746
Validation loss: 2.1152572016562186

Epoch: 6| Step: 6
Training loss: 2.380310297012329
Validation loss: 2.116054445184687

Epoch: 6| Step: 7
Training loss: 2.0415048599243164
Validation loss: 2.073136523205747

Epoch: 6| Step: 8
Training loss: 2.089322328567505
Validation loss: 2.1012607107880297

Epoch: 6| Step: 9
Training loss: 2.1371288299560547
Validation loss: 2.09975697917323

Epoch: 6| Step: 10
Training loss: 2.4771182537078857
Validation loss: 2.0964999198913574

Epoch: 6| Step: 11
Training loss: 2.7001800537109375
Validation loss: 2.0963047242933706

Epoch: 6| Step: 12
Training loss: 3.5878500938415527
Validation loss: 2.0596449400788996

Epoch: 6| Step: 13
Training loss: 2.2242281436920166
Validation loss: 2.0851955542000393

Epoch: 92| Step: 0
Training loss: 2.0336666107177734
Validation loss: 2.1007492055175123

Epoch: 6| Step: 1
Training loss: 2.1219847202301025
Validation loss: 2.057292986941594

Epoch: 6| Step: 2
Training loss: 2.3326950073242188
Validation loss: 2.042021859076715

Epoch: 6| Step: 3
Training loss: 2.2349562644958496
Validation loss: 2.0671663873939106

Epoch: 6| Step: 4
Training loss: 2.1109039783477783
Validation loss: 2.1418979808848393

Epoch: 6| Step: 5
Training loss: 2.42872953414917
Validation loss: 2.126589435403065

Epoch: 6| Step: 6
Training loss: 2.9146006107330322
Validation loss: 2.1469667188582884

Epoch: 6| Step: 7
Training loss: 1.6849238872528076
Validation loss: 2.0989759301626556

Epoch: 6| Step: 8
Training loss: 2.2559080123901367
Validation loss: 2.050001778910237

Epoch: 6| Step: 9
Training loss: 1.8736000061035156
Validation loss: 2.0958524724488616

Epoch: 6| Step: 10
Training loss: 2.8921620845794678
Validation loss: 2.0577020132413475

Epoch: 6| Step: 11
Training loss: 2.693213939666748
Validation loss: 2.0870000546978367

Epoch: 6| Step: 12
Training loss: 2.4540579319000244
Validation loss: 2.1101548312812723

Epoch: 6| Step: 13
Training loss: 1.6452243328094482
Validation loss: 2.0783081926325315

Epoch: 93| Step: 0
Training loss: 2.773078680038452
Validation loss: 2.075617472330729

Epoch: 6| Step: 1
Training loss: 2.6642088890075684
Validation loss: 2.0865348795408845

Epoch: 6| Step: 2
Training loss: 1.9934630393981934
Validation loss: 2.1069227854410806

Epoch: 6| Step: 3
Training loss: 3.1469860076904297
Validation loss: 2.0988830110078216

Epoch: 6| Step: 4
Training loss: 1.8666877746582031
Validation loss: 2.0894099948226765

Epoch: 6| Step: 5
Training loss: 2.445876121520996
Validation loss: 2.061231990014353

Epoch: 6| Step: 6
Training loss: 1.7339750528335571
Validation loss: 2.0791072845458984

Epoch: 6| Step: 7
Training loss: 2.8858234882354736
Validation loss: 2.0431962731064006

Epoch: 6| Step: 8
Training loss: 2.4652764797210693
Validation loss: 2.1144267435996764

Epoch: 6| Step: 9
Training loss: 1.9491101503372192
Validation loss: 2.093359237076134

Epoch: 6| Step: 10
Training loss: 2.1529572010040283
Validation loss: 2.096213120286183

Epoch: 6| Step: 11
Training loss: 1.9590809345245361
Validation loss: 2.1039157734122327

Epoch: 6| Step: 12
Training loss: 1.5349092483520508
Validation loss: 2.066462396293558

Epoch: 6| Step: 13
Training loss: 2.273927927017212
Validation loss: 2.0735110313661638

Epoch: 94| Step: 0
Training loss: 2.2492527961730957
Validation loss: 2.1073431814870527

Epoch: 6| Step: 1
Training loss: 2.0162436962127686
Validation loss: 2.043559234629395

Epoch: 6| Step: 2
Training loss: 2.0094406604766846
Validation loss: 2.0786074540948354

Epoch: 6| Step: 3
Training loss: 2.1215157508850098
Validation loss: 2.041259980970813

Epoch: 6| Step: 4
Training loss: 2.075652837753296
Validation loss: 2.0554518468918337

Epoch: 6| Step: 5
Training loss: 1.589834213256836
Validation loss: 2.0871380964914956

Epoch: 6| Step: 6
Training loss: 2.384693145751953
Validation loss: 2.0248953129655574

Epoch: 6| Step: 7
Training loss: 2.99013614654541
Validation loss: 2.071871687007207

Epoch: 6| Step: 8
Training loss: 3.478577136993408
Validation loss: 2.080716292063395

Epoch: 6| Step: 9
Training loss: 2.328261137008667
Validation loss: 2.112427834541567

Epoch: 6| Step: 10
Training loss: 2.2145090103149414
Validation loss: 2.0483019044322353

Epoch: 6| Step: 11
Training loss: 1.8781341314315796
Validation loss: 2.1016661326090493

Epoch: 6| Step: 12
Training loss: 1.9700109958648682
Validation loss: 2.1305987527293544

Epoch: 6| Step: 13
Training loss: 2.5850281715393066
Validation loss: 2.1536597180110153

Epoch: 95| Step: 0
Training loss: 2.3581995964050293
Validation loss: 2.0965184985950427

Epoch: 6| Step: 1
Training loss: 2.8043735027313232
Validation loss: 2.0749653282985894

Epoch: 6| Step: 2
Training loss: 1.8894072771072388
Validation loss: 2.0489374360730572

Epoch: 6| Step: 3
Training loss: 2.311631202697754
Validation loss: 2.112871321298743

Epoch: 6| Step: 4
Training loss: 3.126692295074463
Validation loss: 2.0500008085722565

Epoch: 6| Step: 5
Training loss: 2.276944637298584
Validation loss: 2.0810247108500493

Epoch: 6| Step: 6
Training loss: 1.7035646438598633
Validation loss: 2.0997136972283803

Epoch: 6| Step: 7
Training loss: 3.3898773193359375
Validation loss: 2.068509186467817

Epoch: 6| Step: 8
Training loss: 2.5922091007232666
Validation loss: 2.0827147973481046

Epoch: 6| Step: 9
Training loss: 1.7646547555923462
Validation loss: 2.0752183929566415

Epoch: 6| Step: 10
Training loss: 2.4259655475616455
Validation loss: 2.0980822040188696

Epoch: 6| Step: 11
Training loss: 1.5036287307739258
Validation loss: 2.0761552984996507

Epoch: 6| Step: 12
Training loss: 2.0665206909179688
Validation loss: 2.0294371087064027

Epoch: 6| Step: 13
Training loss: 1.0841315984725952
Validation loss: 2.0902699808920584

Epoch: 96| Step: 0
Training loss: 2.180464744567871
Validation loss: 2.0756030262157483

Epoch: 6| Step: 1
Training loss: 2.106894016265869
Validation loss: 2.046763958469514

Epoch: 6| Step: 2
Training loss: 3.2434628009796143
Validation loss: 2.089146897356997

Epoch: 6| Step: 3
Training loss: 1.3061182498931885
Validation loss: 2.1315987892048334

Epoch: 6| Step: 4
Training loss: 1.650710105895996
Validation loss: 2.0694965636858376

Epoch: 6| Step: 5
Training loss: 2.5333492755889893
Validation loss: 2.0878446063687726

Epoch: 6| Step: 6
Training loss: 2.3918774127960205
Validation loss: 2.109442244293869

Epoch: 6| Step: 7
Training loss: 1.7253987789154053
Validation loss: 2.0293771272064536

Epoch: 6| Step: 8
Training loss: 2.1671910285949707
Validation loss: 2.049298219783332

Epoch: 6| Step: 9
Training loss: 2.172300100326538
Validation loss: 2.0053956585545696

Epoch: 6| Step: 10
Training loss: 1.7300825119018555
Validation loss: 2.0425917538263465

Epoch: 6| Step: 11
Training loss: 3.057924747467041
Validation loss: 2.088657722678236

Epoch: 6| Step: 12
Training loss: 2.5293643474578857
Validation loss: 2.1003183728905133

Epoch: 6| Step: 13
Training loss: 3.2785592079162598
Validation loss: 2.1034351471931703

Epoch: 97| Step: 0
Training loss: 1.8444956541061401
Validation loss: 2.126941934708626

Epoch: 6| Step: 1
Training loss: 2.2944507598876953
Validation loss: 2.0451376335595244

Epoch: 6| Step: 2
Training loss: 2.6231069564819336
Validation loss: 2.114868785745354

Epoch: 6| Step: 3
Training loss: 2.3606796264648438
Validation loss: 2.007321306454238

Epoch: 6| Step: 4
Training loss: 2.410313129425049
Validation loss: 2.067662973557749

Epoch: 6| Step: 5
Training loss: 1.2376946210861206
Validation loss: 2.0863131015531478

Epoch: 6| Step: 6
Training loss: 2.5415048599243164
Validation loss: 2.083697081894003

Epoch: 6| Step: 7
Training loss: 2.4266085624694824
Validation loss: 2.079956569979268

Epoch: 6| Step: 8
Training loss: 2.3787612915039062
Validation loss: 2.1295858275505806

Epoch: 6| Step: 9
Training loss: 2.7288198471069336
Validation loss: 2.0732576590712353

Epoch: 6| Step: 10
Training loss: 2.4545559883117676
Validation loss: 2.0987639811731156

Epoch: 6| Step: 11
Training loss: 2.6768736839294434
Validation loss: 2.0767968162413566

Epoch: 6| Step: 12
Training loss: 1.8458309173583984
Validation loss: 2.09242513615598

Epoch: 6| Step: 13
Training loss: 1.1638562679290771
Validation loss: 2.098703574108821

Epoch: 98| Step: 0
Training loss: 3.046457290649414
Validation loss: 2.1464795809920116

Epoch: 6| Step: 1
Training loss: 2.7078542709350586
Validation loss: 2.1527859728823424

Epoch: 6| Step: 2
Training loss: 1.621849775314331
Validation loss: 2.1026163767742854

Epoch: 6| Step: 3
Training loss: 1.6756877899169922
Validation loss: 2.1265173048101444

Epoch: 6| Step: 4
Training loss: 2.4694769382476807
Validation loss: 2.0920733341606716

Epoch: 6| Step: 5
Training loss: 1.7714310884475708
Validation loss: 2.128139344594812

Epoch: 6| Step: 6
Training loss: 2.3963420391082764
Validation loss: 2.0768232255853634

Epoch: 6| Step: 7
Training loss: 2.0239453315734863
Validation loss: 2.1144726712216615

Epoch: 6| Step: 8
Training loss: 2.957737922668457
Validation loss: 2.1065916604893182

Epoch: 6| Step: 9
Training loss: 2.1846954822540283
Validation loss: 2.082804021014962

Epoch: 6| Step: 10
Training loss: 2.0270748138427734
Validation loss: 2.075709440374887

Epoch: 6| Step: 11
Training loss: 1.9313908815383911
Validation loss: 2.0740376262254614

Epoch: 6| Step: 12
Training loss: 2.5311427116394043
Validation loss: 2.1383845985576673

Epoch: 6| Step: 13
Training loss: 2.4165000915527344
Validation loss: 2.0854735733360372

Epoch: 99| Step: 0
Training loss: 2.1169869899749756
Validation loss: 2.1155129119914067

Epoch: 6| Step: 1
Training loss: 2.6693074703216553
Validation loss: 2.118796617754044

Epoch: 6| Step: 2
Training loss: 2.2017486095428467
Validation loss: 2.1337578886298725

Epoch: 6| Step: 3
Training loss: 2.9909491539001465
Validation loss: 2.103907310834495

Epoch: 6| Step: 4
Training loss: 2.5491409301757812
Validation loss: 2.1742692903805803

Epoch: 6| Step: 5
Training loss: 2.8347625732421875
Validation loss: 2.0917130888149305

Epoch: 6| Step: 6
Training loss: 1.7784054279327393
Validation loss: 2.0616026873229654

Epoch: 6| Step: 7
Training loss: 2.271160125732422
Validation loss: 2.15342039703041

Epoch: 6| Step: 8
Training loss: 1.8019843101501465
Validation loss: 2.1214326068919194

Epoch: 6| Step: 9
Training loss: 1.630737066268921
Validation loss: 2.1590561277122906

Epoch: 6| Step: 10
Training loss: 2.833385467529297
Validation loss: 2.122884190210732

Epoch: 6| Step: 11
Training loss: 2.287032127380371
Validation loss: 2.056954450504754

Epoch: 6| Step: 12
Training loss: 2.2122039794921875
Validation loss: 2.1814078669394217

Epoch: 6| Step: 13
Training loss: 1.9091033935546875
Validation loss: 2.1829427467879428

Epoch: 100| Step: 0
Training loss: 1.9781614542007446
Validation loss: 2.1201948324839273

Epoch: 6| Step: 1
Training loss: 2.15480375289917
Validation loss: 2.1465122520282702

Epoch: 6| Step: 2
Training loss: 2.874940872192383
Validation loss: 2.1312216763855307

Epoch: 6| Step: 3
Training loss: 1.7817929983139038
Validation loss: 2.0704861020529144

Epoch: 6| Step: 4
Training loss: 1.8850951194763184
Validation loss: 2.116214821415563

Epoch: 6| Step: 5
Training loss: 2.990379571914673
Validation loss: 2.093954224740305

Epoch: 6| Step: 6
Training loss: 2.4059269428253174
Validation loss: 2.093406133754279

Epoch: 6| Step: 7
Training loss: 1.8001091480255127
Validation loss: 2.0680657176561255

Epoch: 6| Step: 8
Training loss: 1.7978322505950928
Validation loss: 2.094354678225774

Epoch: 6| Step: 9
Training loss: 2.567152976989746
Validation loss: 2.1314856749708935

Epoch: 6| Step: 10
Training loss: 2.38000226020813
Validation loss: 2.0389079175969607

Epoch: 6| Step: 11
Training loss: 2.490769386291504
Validation loss: 2.117237062864406

Epoch: 6| Step: 12
Training loss: 2.272066116333008
Validation loss: 2.0624130874551754

Epoch: 6| Step: 13
Training loss: 2.8436708450317383
Validation loss: 2.0826759530651953

Epoch: 101| Step: 0
Training loss: 2.4206840991973877
Validation loss: 2.1328832436633367

Epoch: 6| Step: 1
Training loss: 2.603766918182373
Validation loss: 2.1316797528215634

Epoch: 6| Step: 2
Training loss: 2.740748405456543
Validation loss: 2.044728304750176

Epoch: 6| Step: 3
Training loss: 2.2269887924194336
Validation loss: 2.0640371435432026

Epoch: 6| Step: 4
Training loss: 1.629917025566101
Validation loss: 2.1117214182371735

Epoch: 6| Step: 5
Training loss: 1.9021813869476318
Validation loss: 2.064033512146242

Epoch: 6| Step: 6
Training loss: 2.2405524253845215
Validation loss: 2.0629153790012484

Epoch: 6| Step: 7
Training loss: 2.275118112564087
Validation loss: 2.073034647972353

Epoch: 6| Step: 8
Training loss: 2.611985921859741
Validation loss: 2.0956170200019755

Epoch: 6| Step: 9
Training loss: 2.9696035385131836
Validation loss: 2.1015385914874334

Epoch: 6| Step: 10
Training loss: 1.9213569164276123
Validation loss: 2.1211559413581766

Epoch: 6| Step: 11
Training loss: 1.56766676902771
Validation loss: 2.063441494459747

Epoch: 6| Step: 12
Training loss: 2.033019542694092
Validation loss: 2.14629634734123

Epoch: 6| Step: 13
Training loss: 2.9952199459075928
Validation loss: 2.1155113571433612

Epoch: 102| Step: 0
Training loss: 2.4960646629333496
Validation loss: 2.0407039734625045

Epoch: 6| Step: 1
Training loss: 2.3727846145629883
Validation loss: 2.15742318091854

Epoch: 6| Step: 2
Training loss: 2.5174970626831055
Validation loss: 2.1113863580970356

Epoch: 6| Step: 3
Training loss: 1.788607120513916
Validation loss: 2.0960835949067147

Epoch: 6| Step: 4
Training loss: 2.209202289581299
Validation loss: 2.0762631277884207

Epoch: 6| Step: 5
Training loss: 2.105714797973633
Validation loss: 2.0984237668334798

Epoch: 6| Step: 6
Training loss: 2.7767815589904785
Validation loss: 2.108381594381025

Epoch: 6| Step: 7
Training loss: 1.7473101615905762
Validation loss: 2.11651248316611

Epoch: 6| Step: 8
Training loss: 2.1209182739257812
Validation loss: 2.100190347240817

Epoch: 6| Step: 9
Training loss: 1.8244178295135498
Validation loss: 2.086936454619131

Epoch: 6| Step: 10
Training loss: 2.223817825317383
Validation loss: 2.093695617491199

Epoch: 6| Step: 11
Training loss: 2.783024549484253
Validation loss: 2.1055232940181607

Epoch: 6| Step: 12
Training loss: 2.527831554412842
Validation loss: 2.1209996823341615

Epoch: 6| Step: 13
Training loss: 1.8905415534973145
Validation loss: 2.066373058544692

Epoch: 103| Step: 0
Training loss: 2.815857410430908
Validation loss: 2.0557328770237584

Epoch: 6| Step: 1
Training loss: 1.8567620515823364
Validation loss: 2.0907641354427544

Epoch: 6| Step: 2
Training loss: 2.179901599884033
Validation loss: 2.098127729149275

Epoch: 6| Step: 3
Training loss: 2.8765554428100586
Validation loss: 2.1476648597307104

Epoch: 6| Step: 4
Training loss: 2.8663129806518555
Validation loss: 2.130169976142145

Epoch: 6| Step: 5
Training loss: 1.9836219549179077
Validation loss: 2.1239149467919463

Epoch: 6| Step: 6
Training loss: 2.0263354778289795
Validation loss: 2.114656985446971

Epoch: 6| Step: 7
Training loss: 2.3694891929626465
Validation loss: 2.0460972055312125

Epoch: 6| Step: 8
Training loss: 1.5950055122375488
Validation loss: 2.058100809333145

Epoch: 6| Step: 9
Training loss: 1.9737615585327148
Validation loss: 2.1464093039112706

Epoch: 6| Step: 10
Training loss: 2.401575803756714
Validation loss: 2.091388943374798

Epoch: 6| Step: 11
Training loss: 2.1290817260742188
Validation loss: 2.07930854828127

Epoch: 6| Step: 12
Training loss: 2.589729070663452
Validation loss: 2.061318917941022

Epoch: 6| Step: 13
Training loss: 2.0243520736694336
Validation loss: 2.0680884699667654

Epoch: 104| Step: 0
Training loss: 2.487015962600708
Validation loss: 2.1261308218843196

Epoch: 6| Step: 1
Training loss: 2.442005157470703
Validation loss: 2.0476170483455864

Epoch: 6| Step: 2
Training loss: 2.0444369316101074
Validation loss: 2.1197150343207904

Epoch: 6| Step: 3
Training loss: 1.6489410400390625
Validation loss: 2.1387448618488927

Epoch: 6| Step: 4
Training loss: 2.3371214866638184
Validation loss: 2.0740784714298863

Epoch: 6| Step: 5
Training loss: 2.319300413131714
Validation loss: 2.1067183684277278

Epoch: 6| Step: 6
Training loss: 2.820286750793457
Validation loss: 2.0731302410043697

Epoch: 6| Step: 7
Training loss: 1.9538185596466064
Validation loss: 2.1526337105740785

Epoch: 6| Step: 8
Training loss: 2.5673232078552246
Validation loss: 2.159385759343383

Epoch: 6| Step: 9
Training loss: 2.3255293369293213
Validation loss: 2.115631911062425

Epoch: 6| Step: 10
Training loss: 2.559443950653076
Validation loss: 2.1674549361710906

Epoch: 6| Step: 11
Training loss: 1.5060441493988037
Validation loss: 2.1479452707434215

Epoch: 6| Step: 12
Training loss: 2.151252031326294
Validation loss: 2.0896795295899913

Epoch: 6| Step: 13
Training loss: 2.0152111053466797
Validation loss: 2.1004754279249456

Epoch: 105| Step: 0
Training loss: 2.673610210418701
Validation loss: 2.129859685897827

Epoch: 6| Step: 1
Training loss: 1.6545387506484985
Validation loss: 2.1229267479271017

Epoch: 6| Step: 2
Training loss: 2.2348451614379883
Validation loss: 2.1190172382580337

Epoch: 6| Step: 3
Training loss: 2.0624735355377197
Validation loss: 2.1253513238763295

Epoch: 6| Step: 4
Training loss: 1.8046565055847168
Validation loss: 2.1227111072950464

Epoch: 6| Step: 5
Training loss: 2.932158946990967
Validation loss: 2.0537333334645917

Epoch: 6| Step: 6
Training loss: 1.7916083335876465
Validation loss: 2.0773192541573637

Epoch: 6| Step: 7
Training loss: 2.1895275115966797
Validation loss: 2.09294661911585

Epoch: 6| Step: 8
Training loss: 2.852059841156006
Validation loss: 2.1373751073755245

Epoch: 6| Step: 9
Training loss: 2.737664222717285
Validation loss: 2.115336814234334

Epoch: 6| Step: 10
Training loss: 2.6514711380004883
Validation loss: 2.1546490948687316

Epoch: 6| Step: 11
Training loss: 1.6208773851394653
Validation loss: 2.1540532573576896

Epoch: 6| Step: 12
Training loss: 2.419111490249634
Validation loss: 2.1027340376248924

Epoch: 6| Step: 13
Training loss: 1.5219663381576538
Validation loss: 2.148910730115829

Epoch: 106| Step: 0
Training loss: 1.3801836967468262
Validation loss: 2.105939030647278

Epoch: 6| Step: 1
Training loss: 1.8424270153045654
Validation loss: 2.136423546780822

Epoch: 6| Step: 2
Training loss: 1.8247079849243164
Validation loss: 2.130258278180194

Epoch: 6| Step: 3
Training loss: 3.0990519523620605
Validation loss: 2.1024622712084042

Epoch: 6| Step: 4
Training loss: 2.8183932304382324
Validation loss: 2.143303499426893

Epoch: 6| Step: 5
Training loss: 2.8295042514801025
Validation loss: 2.106248305689904

Epoch: 6| Step: 6
Training loss: 2.412860870361328
Validation loss: 2.060742050088862

Epoch: 6| Step: 7
Training loss: 2.668551206588745
Validation loss: 2.043581134529524

Epoch: 6| Step: 8
Training loss: 1.862174391746521
Validation loss: 2.0043905114614837

Epoch: 6| Step: 9
Training loss: 1.9703452587127686
Validation loss: 2.1185030321921072

Epoch: 6| Step: 10
Training loss: 2.057161808013916
Validation loss: 2.095135123498978

Epoch: 6| Step: 11
Training loss: 2.4716010093688965
Validation loss: 2.136070192501109

Epoch: 6| Step: 12
Training loss: 2.0178325176239014
Validation loss: 2.1171161692629576

Epoch: 6| Step: 13
Training loss: 2.3528494834899902
Validation loss: 2.086716121242892

Epoch: 107| Step: 0
Training loss: 1.6773992776870728
Validation loss: 2.0800524091207855

Epoch: 6| Step: 1
Training loss: 2.6079189777374268
Validation loss: 2.0941573163514495

Epoch: 6| Step: 2
Training loss: 2.326395034790039
Validation loss: 2.1084363921996085

Epoch: 6| Step: 3
Training loss: 2.338942766189575
Validation loss: 2.108807898336841

Epoch: 6| Step: 4
Training loss: 2.5149571895599365
Validation loss: 2.1197475771750174

Epoch: 6| Step: 5
Training loss: 2.4448914527893066
Validation loss: 2.119811301590294

Epoch: 6| Step: 6
Training loss: 2.2407166957855225
Validation loss: 2.13791956568277

Epoch: 6| Step: 7
Training loss: 2.4483585357666016
Validation loss: 2.0692816370276996

Epoch: 6| Step: 8
Training loss: 1.7367125749588013
Validation loss: 2.113545552376778

Epoch: 6| Step: 9
Training loss: 2.9052951335906982
Validation loss: 2.070577242041147

Epoch: 6| Step: 10
Training loss: 2.094606876373291
Validation loss: 2.0574365597899242

Epoch: 6| Step: 11
Training loss: 2.42549729347229
Validation loss: 2.082685293689851

Epoch: 6| Step: 12
Training loss: 1.7795231342315674
Validation loss: 2.05461028827134

Epoch: 6| Step: 13
Training loss: 2.144691228866577
Validation loss: 2.075727824241884

Epoch: 108| Step: 0
Training loss: 2.5203959941864014
Validation loss: 2.105989876613822

Epoch: 6| Step: 1
Training loss: 1.6393046379089355
Validation loss: 2.0993078139520462

Epoch: 6| Step: 2
Training loss: 1.925431728363037
Validation loss: 2.054921239934942

Epoch: 6| Step: 3
Training loss: 1.9588810205459595
Validation loss: 2.0896139811444026

Epoch: 6| Step: 4
Training loss: 3.081118583679199
Validation loss: 2.099327369402814

Epoch: 6| Step: 5
Training loss: 2.5909430980682373
Validation loss: 2.07482894005314

Epoch: 6| Step: 6
Training loss: 2.308358669281006
Validation loss: 2.1259447733561196

Epoch: 6| Step: 7
Training loss: 1.6650300025939941
Validation loss: 2.0719300982772664

Epoch: 6| Step: 8
Training loss: 1.7493528127670288
Validation loss: 2.060195117868403

Epoch: 6| Step: 9
Training loss: 2.426706314086914
Validation loss: 2.049318980145198

Epoch: 6| Step: 10
Training loss: 2.4023256301879883
Validation loss: 2.0680070384856193

Epoch: 6| Step: 11
Training loss: 2.715664863586426
Validation loss: 2.114010936470442

Epoch: 6| Step: 12
Training loss: 2.65733003616333
Validation loss: 2.1092082428675827

Epoch: 6| Step: 13
Training loss: 2.3945438861846924
Validation loss: 2.0579485739431074

Epoch: 109| Step: 0
Training loss: 1.8278487920761108
Validation loss: 2.140336572483022

Epoch: 6| Step: 1
Training loss: 2.461205005645752
Validation loss: 2.0927451169618996

Epoch: 6| Step: 2
Training loss: 2.0636544227600098
Validation loss: 2.083260163184135

Epoch: 6| Step: 3
Training loss: 2.1459414958953857
Validation loss: 2.1206968958659838

Epoch: 6| Step: 4
Training loss: 2.514488697052002
Validation loss: 2.1233979950668993

Epoch: 6| Step: 5
Training loss: 2.4845616817474365
Validation loss: 2.177569850798576

Epoch: 6| Step: 6
Training loss: 2.1291818618774414
Validation loss: 2.070016180315325

Epoch: 6| Step: 7
Training loss: 2.306062698364258
Validation loss: 2.1011060642939743

Epoch: 6| Step: 8
Training loss: 2.2411746978759766
Validation loss: 2.131908626966579

Epoch: 6| Step: 9
Training loss: 2.3573668003082275
Validation loss: 2.0680995692488966

Epoch: 6| Step: 10
Training loss: 2.1822726726531982
Validation loss: 2.083785478786756

Epoch: 6| Step: 11
Training loss: 2.396597385406494
Validation loss: 2.1318789938444733

Epoch: 6| Step: 12
Training loss: 2.435227870941162
Validation loss: 2.1251026943165767

Epoch: 6| Step: 13
Training loss: 2.19533634185791
Validation loss: 2.1415860652923584

Epoch: 110| Step: 0
Training loss: 2.722547769546509
Validation loss: 2.1195127118018364

Epoch: 6| Step: 1
Training loss: 2.4600303173065186
Validation loss: 2.1060156924750215

Epoch: 6| Step: 2
Training loss: 1.9427127838134766
Validation loss: 2.123094730479743

Epoch: 6| Step: 3
Training loss: 2.0931642055511475
Validation loss: 2.2018216399736303

Epoch: 6| Step: 4
Training loss: 2.2101070880889893
Validation loss: 2.1364136229279223

Epoch: 6| Step: 5
Training loss: 1.7198169231414795
Validation loss: 2.2022234932068856

Epoch: 6| Step: 6
Training loss: 1.8858582973480225
Validation loss: 2.1467077552631335

Epoch: 6| Step: 7
Training loss: 2.1177756786346436
Validation loss: 2.099096662254744

Epoch: 6| Step: 8
Training loss: 2.5152230262756348
Validation loss: 2.0958291381917973

Epoch: 6| Step: 9
Training loss: 2.4069647789001465
Validation loss: 2.125820270148657

Epoch: 6| Step: 10
Training loss: 2.5120725631713867
Validation loss: 2.1225063159901607

Epoch: 6| Step: 11
Training loss: 1.8127663135528564
Validation loss: 2.075294212628436

Epoch: 6| Step: 12
Training loss: 2.8339109420776367
Validation loss: 2.0563356338008756

Epoch: 6| Step: 13
Training loss: 1.9095979928970337
Validation loss: 2.112012231221763

Epoch: 111| Step: 0
Training loss: 2.146359920501709
Validation loss: 2.130173674193762

Epoch: 6| Step: 1
Training loss: 2.125178337097168
Validation loss: 2.1168541036626345

Epoch: 6| Step: 2
Training loss: 2.4456491470336914
Validation loss: 2.051127528631559

Epoch: 6| Step: 3
Training loss: 2.4157216548919678
Validation loss: 2.122185795537887

Epoch: 6| Step: 4
Training loss: 1.9008924961090088
Validation loss: 2.084279893546976

Epoch: 6| Step: 5
Training loss: 2.02225399017334
Validation loss: 2.1219298442204795

Epoch: 6| Step: 6
Training loss: 2.576850652694702
Validation loss: 2.0809252890207435

Epoch: 6| Step: 7
Training loss: 1.7659889459609985
Validation loss: 2.087367268018825

Epoch: 6| Step: 8
Training loss: 2.171198844909668
Validation loss: 2.1688689736909765

Epoch: 6| Step: 9
Training loss: 2.3741295337677
Validation loss: 2.1039004659139984

Epoch: 6| Step: 10
Training loss: 2.3925390243530273
Validation loss: 2.0885113823798394

Epoch: 6| Step: 11
Training loss: 2.3607969284057617
Validation loss: 2.141777701275323

Epoch: 6| Step: 12
Training loss: 2.081976890563965
Validation loss: 2.120284095887215

Epoch: 6| Step: 13
Training loss: 2.6855528354644775
Validation loss: 2.1410645643870034

Epoch: 112| Step: 0
Training loss: 3.087043046951294
Validation loss: 2.104870511639503

Epoch: 6| Step: 1
Training loss: 1.85740327835083
Validation loss: 2.0746129661478023

Epoch: 6| Step: 2
Training loss: 2.2330703735351562
Validation loss: 2.0952923810610207

Epoch: 6| Step: 3
Training loss: 2.500671863555908
Validation loss: 2.130335800109371

Epoch: 6| Step: 4
Training loss: 2.362886905670166
Validation loss: 2.1264047879044727

Epoch: 6| Step: 5
Training loss: 2.2633001804351807
Validation loss: 2.103675594893835

Epoch: 6| Step: 6
Training loss: 1.9276912212371826
Validation loss: 2.1094023130273305

Epoch: 6| Step: 7
Training loss: 2.081390380859375
Validation loss: 2.114247719446818

Epoch: 6| Step: 8
Training loss: 1.5754125118255615
Validation loss: 2.093764801179209

Epoch: 6| Step: 9
Training loss: 2.517335891723633
Validation loss: 2.1114183382321428

Epoch: 6| Step: 10
Training loss: 2.434865951538086
Validation loss: 2.091176700848405

Epoch: 6| Step: 11
Training loss: 1.9239479303359985
Validation loss: 2.1070715483798774

Epoch: 6| Step: 12
Training loss: 2.340674877166748
Validation loss: 2.1411654141641434

Epoch: 6| Step: 13
Training loss: 1.9530014991760254
Validation loss: 2.1444944925205682

Epoch: 113| Step: 0
Training loss: 2.1316018104553223
Validation loss: 2.115398217273015

Epoch: 6| Step: 1
Training loss: 2.4512524604797363
Validation loss: 2.074170563810615

Epoch: 6| Step: 2
Training loss: 2.5609397888183594
Validation loss: 2.089193344116211

Epoch: 6| Step: 3
Training loss: 3.034540891647339
Validation loss: 2.1131979175793227

Epoch: 6| Step: 4
Training loss: 1.9170994758605957
Validation loss: 2.0389015841227707

Epoch: 6| Step: 5
Training loss: 2.0695419311523438
Validation loss: 2.083068811765281

Epoch: 6| Step: 6
Training loss: 2.27626371383667
Validation loss: 2.1310826770720945

Epoch: 6| Step: 7
Training loss: 2.325993061065674
Validation loss: 2.1235754566807903

Epoch: 6| Step: 8
Training loss: 2.637606143951416
Validation loss: 2.0775837462435485

Epoch: 6| Step: 9
Training loss: 1.3889044523239136
Validation loss: 2.106902507043654

Epoch: 6| Step: 10
Training loss: 2.591014862060547
Validation loss: 2.119315738319069

Epoch: 6| Step: 11
Training loss: 2.2112936973571777
Validation loss: 2.0622570360860517

Epoch: 6| Step: 12
Training loss: 2.2368781566619873
Validation loss: 2.0890580428543912

Epoch: 6| Step: 13
Training loss: 1.574999451637268
Validation loss: 2.048781494940481

Epoch: 114| Step: 0
Training loss: 2.4908924102783203
Validation loss: 2.130205838910995

Epoch: 6| Step: 1
Training loss: 2.212531805038452
Validation loss: 2.0837376656070834

Epoch: 6| Step: 2
Training loss: 2.1862735748291016
Validation loss: 2.068856869974444

Epoch: 6| Step: 3
Training loss: 2.506120443344116
Validation loss: 2.0934023318752164

Epoch: 6| Step: 4
Training loss: 2.1081933975219727
Validation loss: 2.0449509172029394

Epoch: 6| Step: 5
Training loss: 2.2169032096862793
Validation loss: 2.0749889137924358

Epoch: 6| Step: 6
Training loss: 3.2781808376312256
Validation loss: 2.0585599983892133

Epoch: 6| Step: 7
Training loss: 1.967500925064087
Validation loss: 2.1246297000556864

Epoch: 6| Step: 8
Training loss: 2.004135847091675
Validation loss: 2.1128052460250033

Epoch: 6| Step: 9
Training loss: 1.985456943511963
Validation loss: 2.1088647791134414

Epoch: 6| Step: 10
Training loss: 2.0217950344085693
Validation loss: 2.106167603564519

Epoch: 6| Step: 11
Training loss: 2.7329208850860596
Validation loss: 2.072259890135898

Epoch: 6| Step: 12
Training loss: 1.4411195516586304
Validation loss: 2.1329908229971446

Epoch: 6| Step: 13
Training loss: 1.989845871925354
Validation loss: 2.1032746068892942

Epoch: 115| Step: 0
Training loss: 2.1753039360046387
Validation loss: 2.0889563663031465

Epoch: 6| Step: 1
Training loss: 3.194416046142578
Validation loss: 2.154663088501141

Epoch: 6| Step: 2
Training loss: 1.7633538246154785
Validation loss: 2.1036958963640275

Epoch: 6| Step: 3
Training loss: 2.129692554473877
Validation loss: 2.112832277051864

Epoch: 6| Step: 4
Training loss: 2.168480396270752
Validation loss: 2.1206414058644283

Epoch: 6| Step: 5
Training loss: 1.8992067575454712
Validation loss: 2.1042025601992043

Epoch: 6| Step: 6
Training loss: 2.708679676055908
Validation loss: 2.094333335917483

Epoch: 6| Step: 7
Training loss: 1.8455308675765991
Validation loss: 2.131558504155887

Epoch: 6| Step: 8
Training loss: 2.612053155899048
Validation loss: 2.1309726725342455

Epoch: 6| Step: 9
Training loss: 2.858799934387207
Validation loss: 2.0931806641240276

Epoch: 6| Step: 10
Training loss: 1.9552767276763916
Validation loss: 2.1491024301898096

Epoch: 6| Step: 11
Training loss: 1.4182273149490356
Validation loss: 2.132578649828511

Epoch: 6| Step: 12
Training loss: 2.2712302207946777
Validation loss: 2.114009749504828

Epoch: 6| Step: 13
Training loss: 2.834810495376587
Validation loss: 2.154962082062998

Epoch: 116| Step: 0
Training loss: 2.4703094959259033
Validation loss: 2.106945558260846

Epoch: 6| Step: 1
Training loss: 1.9831852912902832
Validation loss: 2.1077132917219594

Epoch: 6| Step: 2
Training loss: 2.973686456680298
Validation loss: 2.104847208146126

Epoch: 6| Step: 3
Training loss: 1.2649375200271606
Validation loss: 2.1234249555936424

Epoch: 6| Step: 4
Training loss: 2.9498836994171143
Validation loss: 2.0766038792107695

Epoch: 6| Step: 5
Training loss: 2.268777370452881
Validation loss: 2.0912939245982836

Epoch: 6| Step: 6
Training loss: 2.1963043212890625
Validation loss: 2.0914199198445966

Epoch: 6| Step: 7
Training loss: 1.8400421142578125
Validation loss: 2.0765134647328365

Epoch: 6| Step: 8
Training loss: 1.913910984992981
Validation loss: 2.082616780393867

Epoch: 6| Step: 9
Training loss: 2.1250555515289307
Validation loss: 2.1561649281491517

Epoch: 6| Step: 10
Training loss: 1.532992959022522
Validation loss: 2.1963487517449165

Epoch: 6| Step: 11
Training loss: 2.9686667919158936
Validation loss: 2.136733975461734

Epoch: 6| Step: 12
Training loss: 1.6938015222549438
Validation loss: 2.0799472870365268

Epoch: 6| Step: 13
Training loss: 3.457174301147461
Validation loss: 2.134124732786609

Epoch: 117| Step: 0
Training loss: 2.1252682209014893
Validation loss: 2.1456628871220413

Epoch: 6| Step: 1
Training loss: 1.735697627067566
Validation loss: 2.1039214031670683

Epoch: 6| Step: 2
Training loss: 2.2192273139953613
Validation loss: 2.1482496312869492

Epoch: 6| Step: 3
Training loss: 2.304450273513794
Validation loss: 2.1093977010378273

Epoch: 6| Step: 4
Training loss: 2.766023635864258
Validation loss: 2.1054773356324885

Epoch: 6| Step: 5
Training loss: 2.1852147579193115
Validation loss: 2.115026932890697

Epoch: 6| Step: 6
Training loss: 2.4121711254119873
Validation loss: 2.1334781723637737

Epoch: 6| Step: 7
Training loss: 2.212599277496338
Validation loss: 2.071676360663547

Epoch: 6| Step: 8
Training loss: 2.516066074371338
Validation loss: 2.0458024291582007

Epoch: 6| Step: 9
Training loss: 2.0779011249542236
Validation loss: 2.0912351992822464

Epoch: 6| Step: 10
Training loss: 2.08388614654541
Validation loss: 2.13636504450152

Epoch: 6| Step: 11
Training loss: 2.1877119541168213
Validation loss: 2.1041837456405803

Epoch: 6| Step: 12
Training loss: 2.4720048904418945
Validation loss: 2.127160761945991

Epoch: 6| Step: 13
Training loss: 1.47298264503479
Validation loss: 2.092083168286149

Epoch: 118| Step: 0
Training loss: 2.257819414138794
Validation loss: 2.1013507150834605

Epoch: 6| Step: 1
Training loss: 2.353119373321533
Validation loss: 2.130325168691656

Epoch: 6| Step: 2
Training loss: 1.7466607093811035
Validation loss: 2.1088757745681272

Epoch: 6| Step: 3
Training loss: 2.5711498260498047
Validation loss: 2.088554199023913

Epoch: 6| Step: 4
Training loss: 1.9875831604003906
Validation loss: 2.0347397558150755

Epoch: 6| Step: 5
Training loss: 1.1131527423858643
Validation loss: 2.1080927566815446

Epoch: 6| Step: 6
Training loss: 2.0658836364746094
Validation loss: 2.0549894737940964

Epoch: 6| Step: 7
Training loss: 3.1777496337890625
Validation loss: 2.126807855021569

Epoch: 6| Step: 8
Training loss: 1.7538886070251465
Validation loss: 2.0814795327442948

Epoch: 6| Step: 9
Training loss: 3.0201854705810547
Validation loss: 2.1011495244118477

Epoch: 6| Step: 10
Training loss: 2.46859073638916
Validation loss: 2.1019326025439846

Epoch: 6| Step: 11
Training loss: 2.7521612644195557
Validation loss: 2.0936879829693864

Epoch: 6| Step: 12
Training loss: 1.832385540008545
Validation loss: 2.1348169952310543

Epoch: 6| Step: 13
Training loss: 2.1221635341644287
Validation loss: 2.1630505054227767

Epoch: 119| Step: 0
Training loss: 1.9636869430541992
Validation loss: 2.1351913841821815

Epoch: 6| Step: 1
Training loss: 2.2136523723602295
Validation loss: 2.097164248907438

Epoch: 6| Step: 2
Training loss: 1.9460344314575195
Validation loss: 2.0900997602811424

Epoch: 6| Step: 3
Training loss: 2.134082317352295
Validation loss: 2.1049961556670485

Epoch: 6| Step: 4
Training loss: 1.8308706283569336
Validation loss: 2.1465256649960756

Epoch: 6| Step: 5
Training loss: 1.8639715909957886
Validation loss: 2.0962003277194117

Epoch: 6| Step: 6
Training loss: 2.83701229095459
Validation loss: 2.0943057844715733

Epoch: 6| Step: 7
Training loss: 2.8329217433929443
Validation loss: 2.1404384874528453

Epoch: 6| Step: 8
Training loss: 2.9813036918640137
Validation loss: 2.1162259168522333

Epoch: 6| Step: 9
Training loss: 2.1032986640930176
Validation loss: 2.109065919794062

Epoch: 6| Step: 10
Training loss: 1.9028208255767822
Validation loss: 2.105622381292364

Epoch: 6| Step: 11
Training loss: 2.524102210998535
Validation loss: 2.06214282589574

Epoch: 6| Step: 12
Training loss: 1.8248662948608398
Validation loss: 2.150394433288164

Epoch: 6| Step: 13
Training loss: 1.4859024286270142
Validation loss: 2.078201946391854

Epoch: 120| Step: 0
Training loss: 1.736022710800171
Validation loss: 2.095925292661113

Epoch: 6| Step: 1
Training loss: 2.317288398742676
Validation loss: 2.1026859232174453

Epoch: 6| Step: 2
Training loss: 1.306319236755371
Validation loss: 2.068633238474528

Epoch: 6| Step: 3
Training loss: 1.7332713603973389
Validation loss: 2.117905468069097

Epoch: 6| Step: 4
Training loss: 2.9657838344573975
Validation loss: 2.1706955381619033

Epoch: 6| Step: 5
Training loss: 2.3452534675598145
Validation loss: 2.0759660479842976

Epoch: 6| Step: 6
Training loss: 2.7695322036743164
Validation loss: 2.184980825711322

Epoch: 6| Step: 7
Training loss: 2.0540173053741455
Validation loss: 2.091526928768363

Epoch: 6| Step: 8
Training loss: 2.52634334564209
Validation loss: 2.12374419935288

Epoch: 6| Step: 9
Training loss: 1.7893084287643433
Validation loss: 2.1075145429180515

Epoch: 6| Step: 10
Training loss: 2.6548657417297363
Validation loss: 2.120245525913854

Epoch: 6| Step: 11
Training loss: 1.674468755722046
Validation loss: 2.0490195981917845

Epoch: 6| Step: 12
Training loss: 3.164738178253174
Validation loss: 2.0747043599364576

Epoch: 6| Step: 13
Training loss: 2.337139129638672
Validation loss: 2.117196734233569

Epoch: 121| Step: 0
Training loss: 2.136366367340088
Validation loss: 2.133161634527227

Epoch: 6| Step: 1
Training loss: 2.3128037452697754
Validation loss: 2.142335735341554

Epoch: 6| Step: 2
Training loss: 1.9185962677001953
Validation loss: 2.0806874459789646

Epoch: 6| Step: 3
Training loss: 2.260146141052246
Validation loss: 2.1552374721855245

Epoch: 6| Step: 4
Training loss: 2.8331823348999023
Validation loss: 2.0967796976848314

Epoch: 6| Step: 5
Training loss: 3.0993387699127197
Validation loss: 2.133747740458417

Epoch: 6| Step: 6
Training loss: 1.2556626796722412
Validation loss: 2.1349182641634377

Epoch: 6| Step: 7
Training loss: 2.27944278717041
Validation loss: 2.125280999368237

Epoch: 6| Step: 8
Training loss: 2.393676519393921
Validation loss: 2.1018430699584303

Epoch: 6| Step: 9
Training loss: 2.4092323780059814
Validation loss: 2.139295070402084

Epoch: 6| Step: 10
Training loss: 1.9177210330963135
Validation loss: 2.103505813947288

Epoch: 6| Step: 11
Training loss: 2.359741687774658
Validation loss: 2.159552297284526

Epoch: 6| Step: 12
Training loss: 1.8127796649932861
Validation loss: 2.1551067649677234

Epoch: 6| Step: 13
Training loss: 2.0816750526428223
Validation loss: 2.1718218057386336

Epoch: 122| Step: 0
Training loss: 1.378882646560669
Validation loss: 2.163196184301889

Epoch: 6| Step: 1
Training loss: 1.9142814874649048
Validation loss: 2.1323511805585635

Epoch: 6| Step: 2
Training loss: 2.0253610610961914
Validation loss: 2.0956517637416883

Epoch: 6| Step: 3
Training loss: 2.539257526397705
Validation loss: 2.1718808015187583

Epoch: 6| Step: 4
Training loss: 2.660047769546509
Validation loss: 2.135082406382407

Epoch: 6| Step: 5
Training loss: 2.078078269958496
Validation loss: 2.114322385480327

Epoch: 6| Step: 6
Training loss: 2.913329601287842
Validation loss: 2.1487855847163866

Epoch: 6| Step: 7
Training loss: 2.739098310470581
Validation loss: 2.1042859810654835

Epoch: 6| Step: 8
Training loss: 2.7858998775482178
Validation loss: 2.1603287061055503

Epoch: 6| Step: 9
Training loss: 2.636293411254883
Validation loss: 2.1667551007322086

Epoch: 6| Step: 10
Training loss: 2.056644916534424
Validation loss: 2.105233751317506

Epoch: 6| Step: 11
Training loss: 1.647407054901123
Validation loss: 2.1250992641654065

Epoch: 6| Step: 12
Training loss: 1.7181355953216553
Validation loss: 2.1425912585309757

Epoch: 6| Step: 13
Training loss: 2.1737115383148193
Validation loss: 2.1225626417385635

Epoch: 123| Step: 0
Training loss: 2.0002875328063965
Validation loss: 2.1171299975405455

Epoch: 6| Step: 1
Training loss: 1.7662253379821777
Validation loss: 2.0714755506925684

Epoch: 6| Step: 2
Training loss: 2.7905027866363525
Validation loss: 2.101727101110643

Epoch: 6| Step: 3
Training loss: 2.0889158248901367
Validation loss: 2.041231745032854

Epoch: 6| Step: 4
Training loss: 2.3149542808532715
Validation loss: 2.0871620485859532

Epoch: 6| Step: 5
Training loss: 2.1105222702026367
Validation loss: 2.1247909774062452

Epoch: 6| Step: 6
Training loss: 2.158352851867676
Validation loss: 2.10161171420928

Epoch: 6| Step: 7
Training loss: 2.1015963554382324
Validation loss: 2.129859438506506

Epoch: 6| Step: 8
Training loss: 2.0677013397216797
Validation loss: 2.066100505090529

Epoch: 6| Step: 9
Training loss: 2.169466018676758
Validation loss: 2.036737334343695

Epoch: 6| Step: 10
Training loss: 2.2130141258239746
Validation loss: 2.047948263024771

Epoch: 6| Step: 11
Training loss: 2.0667011737823486
Validation loss: 2.05774167788926

Epoch: 6| Step: 12
Training loss: 2.701551914215088
Validation loss: 2.114890685645483

Epoch: 6| Step: 13
Training loss: 2.8669934272766113
Validation loss: 2.099033627458798

Epoch: 124| Step: 0
Training loss: 2.5155372619628906
Validation loss: 2.10677525689525

Epoch: 6| Step: 1
Training loss: 2.681711196899414
Validation loss: 2.0571719241398636

Epoch: 6| Step: 2
Training loss: 2.1580777168273926
Validation loss: 2.0603143271579536

Epoch: 6| Step: 3
Training loss: 2.4082329273223877
Validation loss: 2.1369095463906564

Epoch: 6| Step: 4
Training loss: 1.8826755285263062
Validation loss: 2.113365609158752

Epoch: 6| Step: 5
Training loss: 2.091928005218506
Validation loss: 2.061967888186055

Epoch: 6| Step: 6
Training loss: 1.8620240688323975
Validation loss: 2.0746919826794694

Epoch: 6| Step: 7
Training loss: 2.3800554275512695
Validation loss: 2.1140379982609905

Epoch: 6| Step: 8
Training loss: 1.7918245792388916
Validation loss: 2.12767166988824

Epoch: 6| Step: 9
Training loss: 1.836887240409851
Validation loss: 2.1108897911605013

Epoch: 6| Step: 10
Training loss: 2.511033058166504
Validation loss: 2.0300609770641533

Epoch: 6| Step: 11
Training loss: 2.113980770111084
Validation loss: 2.1446599229689567

Epoch: 6| Step: 12
Training loss: 2.456033229827881
Validation loss: 2.0591347422651065

Epoch: 6| Step: 13
Training loss: 2.2103893756866455
Validation loss: 2.086009274246872

Epoch: 125| Step: 0
Training loss: 2.795552968978882
Validation loss: 2.093593766612391

Epoch: 6| Step: 1
Training loss: 2.3912835121154785
Validation loss: 2.0602968341560772

Epoch: 6| Step: 2
Training loss: 2.1735687255859375
Validation loss: 2.104612027445147

Epoch: 6| Step: 3
Training loss: 1.4706578254699707
Validation loss: 2.0776810453784083

Epoch: 6| Step: 4
Training loss: 2.462543487548828
Validation loss: 2.0691450847092496

Epoch: 6| Step: 5
Training loss: 2.01242733001709
Validation loss: 2.1306921410304245

Epoch: 6| Step: 6
Training loss: 2.3917486667633057
Validation loss: 2.104793998502916

Epoch: 6| Step: 7
Training loss: 2.7122840881347656
Validation loss: 2.153305999694332

Epoch: 6| Step: 8
Training loss: 2.709750175476074
Validation loss: 2.115018577985866

Epoch: 6| Step: 9
Training loss: 1.564979910850525
Validation loss: 2.113834386230797

Epoch: 6| Step: 10
Training loss: 2.5818042755126953
Validation loss: 2.1699155812622397

Epoch: 6| Step: 11
Training loss: 1.8210276365280151
Validation loss: 2.0897759032505814

Epoch: 6| Step: 12
Training loss: 1.9669305086135864
Validation loss: 2.1256487254173524

Epoch: 6| Step: 13
Training loss: 1.818129062652588
Validation loss: 2.110209298390214

Epoch: 126| Step: 0
Training loss: 2.5743260383605957
Validation loss: 2.1297479393661662

Epoch: 6| Step: 1
Training loss: 2.460845470428467
Validation loss: 2.0846670878830778

Epoch: 6| Step: 2
Training loss: 2.4058170318603516
Validation loss: 2.1233236302611647

Epoch: 6| Step: 3
Training loss: 2.135030746459961
Validation loss: 2.083265116137843

Epoch: 6| Step: 4
Training loss: 2.0674242973327637
Validation loss: 2.1140410054114556

Epoch: 6| Step: 5
Training loss: 2.401676654815674
Validation loss: 2.1148320244204615

Epoch: 6| Step: 6
Training loss: 1.9430081844329834
Validation loss: 2.1589705815879245

Epoch: 6| Step: 7
Training loss: 1.6536877155303955
Validation loss: 2.1309478718747377

Epoch: 6| Step: 8
Training loss: 2.390941858291626
Validation loss: 2.148731762363065

Epoch: 6| Step: 9
Training loss: 2.365304470062256
Validation loss: 2.088024531641314

Epoch: 6| Step: 10
Training loss: 2.1050124168395996
Validation loss: 2.107500840258855

Epoch: 6| Step: 11
Training loss: 1.454734444618225
Validation loss: 2.1029680980149137

Epoch: 6| Step: 12
Training loss: 2.5612802505493164
Validation loss: 2.145883696053618

Epoch: 6| Step: 13
Training loss: 2.51841402053833
Validation loss: 2.095749023140118

Epoch: 127| Step: 0
Training loss: 2.2304458618164062
Validation loss: 2.095689341586123

Epoch: 6| Step: 1
Training loss: 2.591719388961792
Validation loss: 2.1269926678749824

Epoch: 6| Step: 2
Training loss: 1.4592499732971191
Validation loss: 2.1540320227223058

Epoch: 6| Step: 3
Training loss: 2.3956360816955566
Validation loss: 2.133222759410899

Epoch: 6| Step: 4
Training loss: 1.9174184799194336
Validation loss: 2.01035580583798

Epoch: 6| Step: 5
Training loss: 2.1037721633911133
Validation loss: 2.0775557038604573

Epoch: 6| Step: 6
Training loss: 2.4188129901885986
Validation loss: 2.0402445100968882

Epoch: 6| Step: 7
Training loss: 2.8995442390441895
Validation loss: 2.1199855906988985

Epoch: 6| Step: 8
Training loss: 2.146660327911377
Validation loss: 2.1619865996863252

Epoch: 6| Step: 9
Training loss: 1.626471996307373
Validation loss: 2.07818236402286

Epoch: 6| Step: 10
Training loss: 1.9805424213409424
Validation loss: 2.132605924401232

Epoch: 6| Step: 11
Training loss: 2.4455931186676025
Validation loss: 2.1094996006258073

Epoch: 6| Step: 12
Training loss: 2.5063443183898926
Validation loss: 2.0890419252457155

Epoch: 6| Step: 13
Training loss: 3.2529661655426025
Validation loss: 2.114788032347156

Epoch: 128| Step: 0
Training loss: 2.3570735454559326
Validation loss: 2.0743946926568144

Epoch: 6| Step: 1
Training loss: 2.4848713874816895
Validation loss: 2.101087708627024

Epoch: 6| Step: 2
Training loss: 2.0495004653930664
Validation loss: 2.075543672807755

Epoch: 6| Step: 3
Training loss: 2.267087936401367
Validation loss: 2.0936540403673725

Epoch: 6| Step: 4
Training loss: 2.3967933654785156
Validation loss: 2.0678340734974032

Epoch: 6| Step: 5
Training loss: 2.6600704193115234
Validation loss: 2.080742512979815

Epoch: 6| Step: 6
Training loss: 2.1821177005767822
Validation loss: 2.1177281333554174

Epoch: 6| Step: 7
Training loss: 2.251610517501831
Validation loss: 2.09709910679889

Epoch: 6| Step: 8
Training loss: 1.8902487754821777
Validation loss: 2.1188843442547705

Epoch: 6| Step: 9
Training loss: 1.9564708471298218
Validation loss: 2.10444781344424

Epoch: 6| Step: 10
Training loss: 2.503734827041626
Validation loss: 2.0682476899957143

Epoch: 6| Step: 11
Training loss: 1.9137442111968994
Validation loss: 2.141214237418226

Epoch: 6| Step: 12
Training loss: 2.6296777725219727
Validation loss: 2.1470067385704286

Epoch: 6| Step: 13
Training loss: 1.2938607931137085
Validation loss: 2.0413672167767762

Epoch: 129| Step: 0
Training loss: 2.287419319152832
Validation loss: 2.08635611431573

Epoch: 6| Step: 1
Training loss: 1.9181487560272217
Validation loss: 2.1186187856940815

Epoch: 6| Step: 2
Training loss: 2.1894423961639404
Validation loss: 2.143619119480092

Epoch: 6| Step: 3
Training loss: 2.614665985107422
Validation loss: 2.1552141994558354

Epoch: 6| Step: 4
Training loss: 1.7926260232925415
Validation loss: 2.0807615787752214

Epoch: 6| Step: 5
Training loss: 2.1168298721313477
Validation loss: 2.094455090902185

Epoch: 6| Step: 6
Training loss: 2.110837936401367
Validation loss: 2.135021887799745

Epoch: 6| Step: 7
Training loss: 1.978144645690918
Validation loss: 2.1094585913483814

Epoch: 6| Step: 8
Training loss: 2.217858076095581
Validation loss: 2.0887749348917315

Epoch: 6| Step: 9
Training loss: 2.5578932762145996
Validation loss: 2.1151002619856145

Epoch: 6| Step: 10
Training loss: 2.4240026473999023
Validation loss: 2.1479064597878406

Epoch: 6| Step: 11
Training loss: 2.55794095993042
Validation loss: 2.1339101432472147

Epoch: 6| Step: 12
Training loss: 2.6102044582366943
Validation loss: 2.056040289581463

Epoch: 6| Step: 13
Training loss: 2.364694118499756
Validation loss: 2.1271030159406763

Epoch: 130| Step: 0
Training loss: 1.9677677154541016
Validation loss: 2.0863930140772173

Epoch: 6| Step: 1
Training loss: 2.3753018379211426
Validation loss: 2.1203155799578597

Epoch: 6| Step: 2
Training loss: 2.1239023208618164
Validation loss: 2.1330973140655027

Epoch: 6| Step: 3
Training loss: 2.0992894172668457
Validation loss: 2.0722835576662453

Epoch: 6| Step: 4
Training loss: 3.3108301162719727
Validation loss: 2.176801020099271

Epoch: 6| Step: 5
Training loss: 2.6639208793640137
Validation loss: 2.0494883355273994

Epoch: 6| Step: 6
Training loss: 1.909343957901001
Validation loss: 2.110735954776887

Epoch: 6| Step: 7
Training loss: 2.249886989593506
Validation loss: 2.1298777595643075

Epoch: 6| Step: 8
Training loss: 2.8513295650482178
Validation loss: 2.138669111395395

Epoch: 6| Step: 9
Training loss: 2.7116050720214844
Validation loss: 2.0964288762820664

Epoch: 6| Step: 10
Training loss: 2.04811429977417
Validation loss: 2.127525661581306

Epoch: 6| Step: 11
Training loss: 1.3259185552597046
Validation loss: 2.1303088639372136

Epoch: 6| Step: 12
Training loss: 2.1712870597839355
Validation loss: 2.1500739897451093

Epoch: 6| Step: 13
Training loss: 1.7741341590881348
Validation loss: 2.11423421162431

Epoch: 131| Step: 0
Training loss: 2.1148834228515625
Validation loss: 2.1033331963323776

Epoch: 6| Step: 1
Training loss: 1.4339873790740967
Validation loss: 2.1484448884123113

Epoch: 6| Step: 2
Training loss: 2.6188669204711914
Validation loss: 2.1072165325123775

Epoch: 6| Step: 3
Training loss: 1.688377857208252
Validation loss: 2.050821472239751

Epoch: 6| Step: 4
Training loss: 2.993809223175049
Validation loss: 2.051825177284979

Epoch: 6| Step: 5
Training loss: 2.3934342861175537
Validation loss: 2.127536996718376

Epoch: 6| Step: 6
Training loss: 1.8673322200775146
Validation loss: 2.1341031802597867

Epoch: 6| Step: 7
Training loss: 2.484039783477783
Validation loss: 2.0717311930912796

Epoch: 6| Step: 8
Training loss: 2.41025710105896
Validation loss: 2.0651110000507806

Epoch: 6| Step: 9
Training loss: 2.636375904083252
Validation loss: 2.090949058532715

Epoch: 6| Step: 10
Training loss: 2.1670339107513428
Validation loss: 2.1484003554108324

Epoch: 6| Step: 11
Training loss: 1.9325733184814453
Validation loss: 2.1543126285717054

Epoch: 6| Step: 12
Training loss: 2.580728530883789
Validation loss: 2.1163359944538405

Epoch: 6| Step: 13
Training loss: 1.5600939989089966
Validation loss: 2.087458736153059

Epoch: 132| Step: 0
Training loss: 1.753172755241394
Validation loss: 2.101817843734577

Epoch: 6| Step: 1
Training loss: 2.184103488922119
Validation loss: 2.049084953082505

Epoch: 6| Step: 2
Training loss: 2.356982707977295
Validation loss: 2.1388130123897264

Epoch: 6| Step: 3
Training loss: 3.0024197101593018
Validation loss: 2.1291413473826584

Epoch: 6| Step: 4
Training loss: 2.19679594039917
Validation loss: 2.1463586194540865

Epoch: 6| Step: 5
Training loss: 2.2150821685791016
Validation loss: 2.10333159149334

Epoch: 6| Step: 6
Training loss: 2.3296689987182617
Validation loss: 2.0913260188153995

Epoch: 6| Step: 7
Training loss: 2.4792580604553223
Validation loss: 2.1074362826603714

Epoch: 6| Step: 8
Training loss: 2.0336508750915527
Validation loss: 2.0490918569667365

Epoch: 6| Step: 9
Training loss: 2.1579127311706543
Validation loss: 2.138013978158274

Epoch: 6| Step: 10
Training loss: 2.439013957977295
Validation loss: 2.1377747456232705

Epoch: 6| Step: 11
Training loss: 2.270639419555664
Validation loss: 2.0799865376564766

Epoch: 6| Step: 12
Training loss: 2.3962631225585938
Validation loss: 2.1268669072017876

Epoch: 6| Step: 13
Training loss: 1.4144935607910156
Validation loss: 2.1435366856154574

Epoch: 133| Step: 0
Training loss: 2.0767455101013184
Validation loss: 2.0936868242038194

Epoch: 6| Step: 1
Training loss: 2.2304670810699463
Validation loss: 2.13658885289264

Epoch: 6| Step: 2
Training loss: 2.9198827743530273
Validation loss: 2.083830282252322

Epoch: 6| Step: 3
Training loss: 1.4404571056365967
Validation loss: 2.0745524257741947

Epoch: 6| Step: 4
Training loss: 2.5184807777404785
Validation loss: 2.0574149303538825

Epoch: 6| Step: 5
Training loss: 1.949791669845581
Validation loss: 2.061769462400867

Epoch: 6| Step: 6
Training loss: 2.5589540004730225
Validation loss: 2.061342616235056

Epoch: 6| Step: 7
Training loss: 2.731876850128174
Validation loss: 2.0537497471737605

Epoch: 6| Step: 8
Training loss: 2.5615651607513428
Validation loss: 2.074242886676583

Epoch: 6| Step: 9
Training loss: 1.6383721828460693
Validation loss: 2.078641335169474

Epoch: 6| Step: 10
Training loss: 2.3928942680358887
Validation loss: 2.060153248489544

Epoch: 6| Step: 11
Training loss: 2.325145959854126
Validation loss: 2.0984346610243603

Epoch: 6| Step: 12
Training loss: 2.382742404937744
Validation loss: 2.1275855161810435

Epoch: 6| Step: 13
Training loss: 1.5633370876312256
Validation loss: 2.093031608930198

Epoch: 134| Step: 0
Training loss: 1.7287163734436035
Validation loss: 2.0637554622465566

Epoch: 6| Step: 1
Training loss: 1.9845774173736572
Validation loss: 2.0417635389553603

Epoch: 6| Step: 2
Training loss: 2.4937548637390137
Validation loss: 2.0689892025404077

Epoch: 6| Step: 3
Training loss: 2.6462323665618896
Validation loss: 2.124638834307271

Epoch: 6| Step: 4
Training loss: 2.0532684326171875
Validation loss: 2.087104803772383

Epoch: 6| Step: 5
Training loss: 1.7074639797210693
Validation loss: 2.1154537970019924

Epoch: 6| Step: 6
Training loss: 1.827300786972046
Validation loss: 2.113803420015561

Epoch: 6| Step: 7
Training loss: 2.609018325805664
Validation loss: 2.1093489611020653

Epoch: 6| Step: 8
Training loss: 2.1714401245117188
Validation loss: 2.1342518611620833

Epoch: 6| Step: 9
Training loss: 2.0058417320251465
Validation loss: 2.0929804194358086

Epoch: 6| Step: 10
Training loss: 2.7925782203674316
Validation loss: 2.0640248252499487

Epoch: 6| Step: 11
Training loss: 2.332465171813965
Validation loss: 2.074555403442793

Epoch: 6| Step: 12
Training loss: 2.3284149169921875
Validation loss: 2.1114861247360066

Epoch: 6| Step: 13
Training loss: 2.9497878551483154
Validation loss: 2.1073987535251084

Epoch: 135| Step: 0
Training loss: 2.182455539703369
Validation loss: 2.0968304526421333

Epoch: 6| Step: 1
Training loss: 2.055420398712158
Validation loss: 2.0799531270098943

Epoch: 6| Step: 2
Training loss: 2.000570297241211
Validation loss: 2.113538113973474

Epoch: 6| Step: 3
Training loss: 1.8702250719070435
Validation loss: 2.1459137162854596

Epoch: 6| Step: 4
Training loss: 2.2332773208618164
Validation loss: 2.1401716880900885

Epoch: 6| Step: 5
Training loss: 3.0038366317749023
Validation loss: 2.046928717244056

Epoch: 6| Step: 6
Training loss: 1.7414461374282837
Validation loss: 2.139487374213434

Epoch: 6| Step: 7
Training loss: 2.0871336460113525
Validation loss: 2.1663581055979573

Epoch: 6| Step: 8
Training loss: 2.0128729343414307
Validation loss: 2.1078978238567228

Epoch: 6| Step: 9
Training loss: 1.9248477220535278
Validation loss: 2.122183140888009

Epoch: 6| Step: 10
Training loss: 2.938626766204834
Validation loss: 2.1662021683108423

Epoch: 6| Step: 11
Training loss: 2.0630009174346924
Validation loss: 2.1609718158680904

Epoch: 6| Step: 12
Training loss: 2.621837854385376
Validation loss: 2.1794844519707466

Epoch: 6| Step: 13
Training loss: 1.9594035148620605
Validation loss: 2.131371454526019

Epoch: 136| Step: 0
Training loss: 1.853722333908081
Validation loss: 2.112383762995402

Epoch: 6| Step: 1
Training loss: 2.8921589851379395
Validation loss: 2.116946135797808

Epoch: 6| Step: 2
Training loss: 1.754273533821106
Validation loss: 2.1510897554377073

Epoch: 6| Step: 3
Training loss: 2.1465868949890137
Validation loss: 2.1661527515739523

Epoch: 6| Step: 4
Training loss: 2.487776279449463
Validation loss: 2.0865845116235877

Epoch: 6| Step: 5
Training loss: 2.0637779235839844
Validation loss: 2.1592101871326403

Epoch: 6| Step: 6
Training loss: 2.6536874771118164
Validation loss: 2.1044781156765517

Epoch: 6| Step: 7
Training loss: 1.5992813110351562
Validation loss: 2.1112390231060725

Epoch: 6| Step: 8
Training loss: 1.876433253288269
Validation loss: 2.0744655593749015

Epoch: 6| Step: 9
Training loss: 2.2251267433166504
Validation loss: 2.064073839495259

Epoch: 6| Step: 10
Training loss: 2.7857837677001953
Validation loss: 2.1258406626280917

Epoch: 6| Step: 11
Training loss: 2.7122068405151367
Validation loss: 2.052975253392291

Epoch: 6| Step: 12
Training loss: 2.0311849117279053
Validation loss: 2.053426037552536

Epoch: 6| Step: 13
Training loss: 2.641885995864868
Validation loss: 2.080518066242177

Epoch: 137| Step: 0
Training loss: 2.026048421859741
Validation loss: 2.104480815190141

Epoch: 6| Step: 1
Training loss: 2.384673833847046
Validation loss: 2.0648045565492366

Epoch: 6| Step: 2
Training loss: 2.599026679992676
Validation loss: 2.122419736718619

Epoch: 6| Step: 3
Training loss: 3.0092320442199707
Validation loss: 2.1063396981967393

Epoch: 6| Step: 4
Training loss: 1.6118640899658203
Validation loss: 2.130153465014632

Epoch: 6| Step: 5
Training loss: 2.1290180683135986
Validation loss: 2.1094290748719247

Epoch: 6| Step: 6
Training loss: 2.4716713428497314
Validation loss: 2.1269758132196244

Epoch: 6| Step: 7
Training loss: 2.1908299922943115
Validation loss: 2.1213009049815517

Epoch: 6| Step: 8
Training loss: 2.2464921474456787
Validation loss: 2.0665367457174484

Epoch: 6| Step: 9
Training loss: 2.1886863708496094
Validation loss: 2.1415725600334907

Epoch: 6| Step: 10
Training loss: 1.9892882108688354
Validation loss: 2.1059982622823408

Epoch: 6| Step: 11
Training loss: 1.916983962059021
Validation loss: 2.0729507938508065

Epoch: 6| Step: 12
Training loss: 2.428398609161377
Validation loss: 2.087787171845795

Epoch: 6| Step: 13
Training loss: 1.8980135917663574
Validation loss: 2.1466868539010324

Epoch: 138| Step: 0
Training loss: 1.942159652709961
Validation loss: 2.129441402291739

Epoch: 6| Step: 1
Training loss: 1.9791592359542847
Validation loss: 2.1733261026361936

Epoch: 6| Step: 2
Training loss: 1.9538843631744385
Validation loss: 2.0736164777509627

Epoch: 6| Step: 3
Training loss: 2.1642074584960938
Validation loss: 2.075266145890759

Epoch: 6| Step: 4
Training loss: 1.936592936515808
Validation loss: 2.0560988982518515

Epoch: 6| Step: 5
Training loss: 2.2378036975860596
Validation loss: 2.058460876505862

Epoch: 6| Step: 6
Training loss: 2.223477840423584
Validation loss: 2.1111789749514673

Epoch: 6| Step: 7
Training loss: 3.6107711791992188
Validation loss: 2.0438988106225127

Epoch: 6| Step: 8
Training loss: 1.9963359832763672
Validation loss: 2.076937098656931

Epoch: 6| Step: 9
Training loss: 2.8289544582366943
Validation loss: 2.1279234706714587

Epoch: 6| Step: 10
Training loss: 1.397035002708435
Validation loss: 2.1244771685651553

Epoch: 6| Step: 11
Training loss: 2.128610610961914
Validation loss: 2.0778278714867047

Epoch: 6| Step: 12
Training loss: 2.180708885192871
Validation loss: 2.101776994684691

Epoch: 6| Step: 13
Training loss: 2.0910251140594482
Validation loss: 2.082326740346929

Epoch: 139| Step: 0
Training loss: 2.373936653137207
Validation loss: 2.10392318489731

Epoch: 6| Step: 1
Training loss: 1.7621610164642334
Validation loss: 2.0299217021593483

Epoch: 6| Step: 2
Training loss: 2.3691587448120117
Validation loss: 2.073368900565691

Epoch: 6| Step: 3
Training loss: 1.874851942062378
Validation loss: 2.1189794309677614

Epoch: 6| Step: 4
Training loss: 1.8039039373397827
Validation loss: 2.1093610819949897

Epoch: 6| Step: 5
Training loss: 1.9794855117797852
Validation loss: 2.0941498125753095

Epoch: 6| Step: 6
Training loss: 2.5088706016540527
Validation loss: 2.113604477656785

Epoch: 6| Step: 7
Training loss: 2.084035873413086
Validation loss: 2.121670569142988

Epoch: 6| Step: 8
Training loss: 2.305863857269287
Validation loss: 2.070499579111735

Epoch: 6| Step: 9
Training loss: 2.2385425567626953
Validation loss: 2.0829221830573132

Epoch: 6| Step: 10
Training loss: 2.5760064125061035
Validation loss: 2.065504325333462

Epoch: 6| Step: 11
Training loss: 2.6780405044555664
Validation loss: 2.1301295859839326

Epoch: 6| Step: 12
Training loss: 2.169288396835327
Validation loss: 2.10255886918755

Epoch: 6| Step: 13
Training loss: 2.281630039215088
Validation loss: 2.109929989742976

Epoch: 140| Step: 0
Training loss: 1.429302453994751
Validation loss: 2.122109972020631

Epoch: 6| Step: 1
Training loss: 2.084062099456787
Validation loss: 2.100652802375055

Epoch: 6| Step: 2
Training loss: 2.6711273193359375
Validation loss: 2.066908659473542

Epoch: 6| Step: 3
Training loss: 1.866331696510315
Validation loss: 2.053214515409162

Epoch: 6| Step: 4
Training loss: 2.419900894165039
Validation loss: 2.1237529811038764

Epoch: 6| Step: 5
Training loss: 3.2759313583374023
Validation loss: 2.1461103552131244

Epoch: 6| Step: 6
Training loss: 2.5524191856384277
Validation loss: 2.077107608959239

Epoch: 6| Step: 7
Training loss: 2.173463821411133
Validation loss: 2.0892204751250563

Epoch: 6| Step: 8
Training loss: 2.4705371856689453
Validation loss: 2.1474487089341685

Epoch: 6| Step: 9
Training loss: 2.040205240249634
Validation loss: 2.068117787761073

Epoch: 6| Step: 10
Training loss: 2.283545970916748
Validation loss: 2.1421242708800943

Epoch: 6| Step: 11
Training loss: 1.7371872663497925
Validation loss: 2.0829939919133342

Epoch: 6| Step: 12
Training loss: 2.202653646469116
Validation loss: 2.0553417795447895

Epoch: 6| Step: 13
Training loss: 1.6694071292877197
Validation loss: 2.1189860989970546

Epoch: 141| Step: 0
Training loss: 1.8621408939361572
Validation loss: 2.1124927459224576

Epoch: 6| Step: 1
Training loss: 1.7994370460510254
Validation loss: 2.077248091338783

Epoch: 6| Step: 2
Training loss: 2.9516820907592773
Validation loss: 2.1160319159107823

Epoch: 6| Step: 3
Training loss: 2.4211933612823486
Validation loss: 2.1153477943071755

Epoch: 6| Step: 4
Training loss: 2.1586337089538574
Validation loss: 2.173043848365866

Epoch: 6| Step: 5
Training loss: 2.501950263977051
Validation loss: 2.1577861437233548

Epoch: 6| Step: 6
Training loss: 2.1965792179107666
Validation loss: 2.1184574288706624

Epoch: 6| Step: 7
Training loss: 2.304759979248047
Validation loss: 2.1353842289217058

Epoch: 6| Step: 8
Training loss: 1.8874343633651733
Validation loss: 2.112400236950126

Epoch: 6| Step: 9
Training loss: 2.4810400009155273
Validation loss: 2.117849180775304

Epoch: 6| Step: 10
Training loss: 2.1821560859680176
Validation loss: 2.139913132113795

Epoch: 6| Step: 11
Training loss: 2.231381416320801
Validation loss: 2.119902059596072

Epoch: 6| Step: 12
Training loss: 2.1882457733154297
Validation loss: 2.1642863724821355

Epoch: 6| Step: 13
Training loss: 1.5415079593658447
Validation loss: 2.1334998069270963

Epoch: 142| Step: 0
Training loss: 2.075200080871582
Validation loss: 2.104645980301724

Epoch: 6| Step: 1
Training loss: 1.9893876314163208
Validation loss: 2.1676578598637737

Epoch: 6| Step: 2
Training loss: 2.873108148574829
Validation loss: 2.146592006888441

Epoch: 6| Step: 3
Training loss: 2.3019838333129883
Validation loss: 2.1368569276666127

Epoch: 6| Step: 4
Training loss: 2.2528882026672363
Validation loss: 2.1294868774311517

Epoch: 6| Step: 5
Training loss: 2.0056827068328857
Validation loss: 2.161932114631899

Epoch: 6| Step: 6
Training loss: 1.9435431957244873
Validation loss: 2.0761202663503666

Epoch: 6| Step: 7
Training loss: 2.9995760917663574
Validation loss: 2.0958267796424126

Epoch: 6| Step: 8
Training loss: 1.4771339893341064
Validation loss: 2.118368646149994

Epoch: 6| Step: 9
Training loss: 2.586780548095703
Validation loss: 2.086986623784547

Epoch: 6| Step: 10
Training loss: 2.2034192085266113
Validation loss: 2.0992622067851405

Epoch: 6| Step: 11
Training loss: 2.0583865642547607
Validation loss: 2.094813408390168

Epoch: 6| Step: 12
Training loss: 2.8514552116394043
Validation loss: 2.158487541701204

Epoch: 6| Step: 13
Training loss: 1.7079936265945435
Validation loss: 2.1349791660103747

Epoch: 143| Step: 0
Training loss: 2.762230396270752
Validation loss: 2.1260073813058997

Epoch: 6| Step: 1
Training loss: 2.5417118072509766
Validation loss: 2.1352368606034147

Epoch: 6| Step: 2
Training loss: 2.3888490200042725
Validation loss: 2.11893779359838

Epoch: 6| Step: 3
Training loss: 1.5982980728149414
Validation loss: 2.1119808458512828

Epoch: 6| Step: 4
Training loss: 2.1796681880950928
Validation loss: 2.0814564330603487

Epoch: 6| Step: 5
Training loss: 2.167694568634033
Validation loss: 2.144397807377641

Epoch: 6| Step: 6
Training loss: 2.2586593627929688
Validation loss: 2.1322339709087084

Epoch: 6| Step: 7
Training loss: 2.0162243843078613
Validation loss: 2.163426803004357

Epoch: 6| Step: 8
Training loss: 2.110360622406006
Validation loss: 2.0829794829891575

Epoch: 6| Step: 9
Training loss: 2.012708902359009
Validation loss: 2.1690227293199107

Epoch: 6| Step: 10
Training loss: 2.630624532699585
Validation loss: 2.078696266297371

Epoch: 6| Step: 11
Training loss: 1.901991367340088
Validation loss: 2.1506612070145144

Epoch: 6| Step: 12
Training loss: 2.202010154724121
Validation loss: 2.0606948624375048

Epoch: 6| Step: 13
Training loss: 1.3971896171569824
Validation loss: 2.1751258962897846

Epoch: 144| Step: 0
Training loss: 2.1357474327087402
Validation loss: 2.145693084245087

Epoch: 6| Step: 1
Training loss: 2.3106045722961426
Validation loss: 2.0897128633273545

Epoch: 6| Step: 2
Training loss: 1.8256889581680298
Validation loss: 2.1731594711221676

Epoch: 6| Step: 3
Training loss: 1.6804835796356201
Validation loss: 2.1302649128821587

Epoch: 6| Step: 4
Training loss: 2.72098708152771
Validation loss: 2.10035954752276

Epoch: 6| Step: 5
Training loss: 1.4973807334899902
Validation loss: 2.0943651250613633

Epoch: 6| Step: 6
Training loss: 1.3957571983337402
Validation loss: 2.1393341300308064

Epoch: 6| Step: 7
Training loss: 2.194401979446411
Validation loss: 2.1237660633620394

Epoch: 6| Step: 8
Training loss: 2.2246310710906982
Validation loss: 2.129404043638578

Epoch: 6| Step: 9
Training loss: 2.3145551681518555
Validation loss: 2.1510363112213793

Epoch: 6| Step: 10
Training loss: 2.210453987121582
Validation loss: 2.180422131733228

Epoch: 6| Step: 11
Training loss: 3.21128511428833
Validation loss: 2.1362810339978946

Epoch: 6| Step: 12
Training loss: 2.373056173324585
Validation loss: 2.1420419946793587

Epoch: 6| Step: 13
Training loss: 3.640021800994873
Validation loss: 2.1737718274516444

Epoch: 145| Step: 0
Training loss: 2.248654365539551
Validation loss: 2.142928384965466

Epoch: 6| Step: 1
Training loss: 2.0737855434417725
Validation loss: 2.143388459759374

Epoch: 6| Step: 2
Training loss: 2.3340845108032227
Validation loss: 2.0727418263753257

Epoch: 6| Step: 3
Training loss: 2.187443733215332
Validation loss: 2.137343765586935

Epoch: 6| Step: 4
Training loss: 0.8993340134620667
Validation loss: 2.1725204695937452

Epoch: 6| Step: 5
Training loss: 2.3232202529907227
Validation loss: 2.0877800590248516

Epoch: 6| Step: 6
Training loss: 2.2749083042144775
Validation loss: 2.050349816199272

Epoch: 6| Step: 7
Training loss: 1.9590176343917847
Validation loss: 2.113614536100818

Epoch: 6| Step: 8
Training loss: 2.684011697769165
Validation loss: 2.121016420343871

Epoch: 6| Step: 9
Training loss: 2.39080810546875
Validation loss: 2.0919206142425537

Epoch: 6| Step: 10
Training loss: 2.0778603553771973
Validation loss: 2.135845133053359

Epoch: 6| Step: 11
Training loss: 2.2042548656463623
Validation loss: 2.1238726826124292

Epoch: 6| Step: 12
Training loss: 2.7105727195739746
Validation loss: 2.116254315581373

Epoch: 6| Step: 13
Training loss: 2.5112111568450928
Validation loss: 2.118539293607076

Epoch: 146| Step: 0
Training loss: 2.201349973678589
Validation loss: 2.1449060619518323

Epoch: 6| Step: 1
Training loss: 2.15466570854187
Validation loss: 2.1395293692106843

Epoch: 6| Step: 2
Training loss: 2.63330340385437
Validation loss: 2.1328473873035882

Epoch: 6| Step: 3
Training loss: 2.3008875846862793
Validation loss: 2.097037664023779

Epoch: 6| Step: 4
Training loss: 2.678622245788574
Validation loss: 2.1468367038234586

Epoch: 6| Step: 5
Training loss: 2.4153027534484863
Validation loss: 2.074241393355913

Epoch: 6| Step: 6
Training loss: 3.1240181922912598
Validation loss: 2.0822034048777756

Epoch: 6| Step: 7
Training loss: 1.4272921085357666
Validation loss: 2.101378994603311

Epoch: 6| Step: 8
Training loss: 1.6949732303619385
Validation loss: 2.132970501017827

Epoch: 6| Step: 9
Training loss: 1.8878401517868042
Validation loss: 2.128688960947016

Epoch: 6| Step: 10
Training loss: 2.581307888031006
Validation loss: 2.146150201879522

Epoch: 6| Step: 11
Training loss: 1.6052229404449463
Validation loss: 2.0383228307129233

Epoch: 6| Step: 12
Training loss: 2.5808897018432617
Validation loss: 2.131923064108818

Epoch: 6| Step: 13
Training loss: 1.3999216556549072
Validation loss: 2.1328148021492908

Epoch: 147| Step: 0
Training loss: 1.8112328052520752
Validation loss: 2.1645056214383853

Epoch: 6| Step: 1
Training loss: 2.0775060653686523
Validation loss: 2.1043462625113865

Epoch: 6| Step: 2
Training loss: 2.6807165145874023
Validation loss: 2.1148205405922345

Epoch: 6| Step: 3
Training loss: 1.8660308122634888
Validation loss: 2.059764903078797

Epoch: 6| Step: 4
Training loss: 2.2884881496429443
Validation loss: 2.1281800154716737

Epoch: 6| Step: 5
Training loss: 2.2124924659729004
Validation loss: 2.1091556959254767

Epoch: 6| Step: 6
Training loss: 3.0619969367980957
Validation loss: 2.1016518813307568

Epoch: 6| Step: 7
Training loss: 2.4826908111572266
Validation loss: 2.1262034805872108

Epoch: 6| Step: 8
Training loss: 2.3050692081451416
Validation loss: 2.1246937936352146

Epoch: 6| Step: 9
Training loss: 2.1142983436584473
Validation loss: 2.120640165062361

Epoch: 6| Step: 10
Training loss: 2.330630302429199
Validation loss: 2.1206338918337257

Epoch: 6| Step: 11
Training loss: 1.8074963092803955
Validation loss: 2.0967451013544554

Epoch: 6| Step: 12
Training loss: 1.9015238285064697
Validation loss: 2.1093059355212795

Epoch: 6| Step: 13
Training loss: 2.089358329772949
Validation loss: 2.1222326370977584

Epoch: 148| Step: 0
Training loss: 1.695388913154602
Validation loss: 2.0898070412297405

Epoch: 6| Step: 1
Training loss: 2.6047611236572266
Validation loss: 2.1067251031116774

Epoch: 6| Step: 2
Training loss: 2.806994915008545
Validation loss: 2.0728599025357153

Epoch: 6| Step: 3
Training loss: 1.8353912830352783
Validation loss: 2.1422037027215444

Epoch: 6| Step: 4
Training loss: 2.0754265785217285
Validation loss: 2.1293620717140938

Epoch: 6| Step: 5
Training loss: 1.720820426940918
Validation loss: 2.0970700992050992

Epoch: 6| Step: 6
Training loss: 2.363105058670044
Validation loss: 2.104107040230946

Epoch: 6| Step: 7
Training loss: 2.285047769546509
Validation loss: 2.1015112271872898

Epoch: 6| Step: 8
Training loss: 2.021552562713623
Validation loss: 2.1012543580865346

Epoch: 6| Step: 9
Training loss: 2.2957794666290283
Validation loss: 2.075673816024616

Epoch: 6| Step: 10
Training loss: 2.7157793045043945
Validation loss: 2.080615681986655

Epoch: 6| Step: 11
Training loss: 2.0485081672668457
Validation loss: 2.068129147252729

Epoch: 6| Step: 12
Training loss: 2.1184864044189453
Validation loss: 2.0625438318457654

Epoch: 6| Step: 13
Training loss: 1.5017085075378418
Validation loss: 2.126491331285046

Epoch: 149| Step: 0
Training loss: 2.8345603942871094
Validation loss: 2.0841324342194425

Epoch: 6| Step: 1
Training loss: 2.227548599243164
Validation loss: 2.1236171350684216

Epoch: 6| Step: 2
Training loss: 1.816126823425293
Validation loss: 2.101887050495353

Epoch: 6| Step: 3
Training loss: 2.423645496368408
Validation loss: 2.12120759102606

Epoch: 6| Step: 4
Training loss: 2.030146598815918
Validation loss: 2.166564392787154

Epoch: 6| Step: 5
Training loss: 2.8160057067871094
Validation loss: 2.099068964681318

Epoch: 6| Step: 6
Training loss: 2.6581804752349854
Validation loss: 2.112378053767707

Epoch: 6| Step: 7
Training loss: 1.935139775276184
Validation loss: 2.031065184582946

Epoch: 6| Step: 8
Training loss: 1.3202333450317383
Validation loss: 2.057725129588958

Epoch: 6| Step: 9
Training loss: 1.5406944751739502
Validation loss: 2.0225975410912627

Epoch: 6| Step: 10
Training loss: 2.1577916145324707
Validation loss: 2.106540455613085

Epoch: 6| Step: 11
Training loss: 2.3463401794433594
Validation loss: 2.055466631407379

Epoch: 6| Step: 12
Training loss: 2.83650541305542
Validation loss: 2.114041495066817

Epoch: 6| Step: 13
Training loss: 2.343352794647217
Validation loss: 2.139068052332888

Epoch: 150| Step: 0
Training loss: 2.156928539276123
Validation loss: 2.1588087543364494

Epoch: 6| Step: 1
Training loss: 2.7486138343811035
Validation loss: 2.1050945379400767

Epoch: 6| Step: 2
Training loss: 1.8747280836105347
Validation loss: 2.0601852042700655

Epoch: 6| Step: 3
Training loss: 1.6911733150482178
Validation loss: 2.036248275028762

Epoch: 6| Step: 4
Training loss: 1.815708875656128
Validation loss: 2.108411692803906

Epoch: 6| Step: 5
Training loss: 2.475532054901123
Validation loss: 2.0757752003208285

Epoch: 6| Step: 6
Training loss: 2.3980493545532227
Validation loss: 2.19882619765497

Epoch: 6| Step: 7
Training loss: 2.3163671493530273
Validation loss: 2.071168432953537

Epoch: 6| Step: 8
Training loss: 2.4379842281341553
Validation loss: 2.1120374254001084

Epoch: 6| Step: 9
Training loss: 1.4974884986877441
Validation loss: 2.0600033242215394

Epoch: 6| Step: 10
Training loss: 2.6005282402038574
Validation loss: 2.103856458458849

Epoch: 6| Step: 11
Training loss: 2.613105058670044
Validation loss: 2.165593348523622

Epoch: 6| Step: 12
Training loss: 1.963112473487854
Validation loss: 2.0829377148741033

Epoch: 6| Step: 13
Training loss: 2.680722236633301
Validation loss: 2.076296515362237

Epoch: 151| Step: 0
Training loss: 2.279905319213867
Validation loss: 2.1071734325860136

Epoch: 6| Step: 1
Training loss: 2.282907247543335
Validation loss: 2.125575191231184

Epoch: 6| Step: 2
Training loss: 1.8487470149993896
Validation loss: 2.0984121599505023

Epoch: 6| Step: 3
Training loss: 1.840836763381958
Validation loss: 2.0796055101579234

Epoch: 6| Step: 4
Training loss: 2.0288310050964355
Validation loss: 2.146953167453889

Epoch: 6| Step: 5
Training loss: 2.3106393814086914
Validation loss: 2.0527444231894707

Epoch: 6| Step: 6
Training loss: 2.556033134460449
Validation loss: 2.1267895954911427

Epoch: 6| Step: 7
Training loss: 2.0645081996917725
Validation loss: 2.1448990798765615

Epoch: 6| Step: 8
Training loss: 2.0387303829193115
Validation loss: 2.130641088690809

Epoch: 6| Step: 9
Training loss: 2.2445831298828125
Validation loss: 2.1529515186945596

Epoch: 6| Step: 10
Training loss: 1.7056992053985596
Validation loss: 2.136241184767856

Epoch: 6| Step: 11
Training loss: 2.330048084259033
Validation loss: 2.09790297221112

Epoch: 6| Step: 12
Training loss: 2.870026111602783
Validation loss: 2.105170307620879

Epoch: 6| Step: 13
Training loss: 2.07098388671875
Validation loss: 2.1000276919334167

Epoch: 152| Step: 0
Training loss: 2.799020767211914
Validation loss: 2.0942298648177937

Epoch: 6| Step: 1
Training loss: 2.1858487129211426
Validation loss: 2.1077812820352535

Epoch: 6| Step: 2
Training loss: 1.5983662605285645
Validation loss: 2.0884248646356727

Epoch: 6| Step: 3
Training loss: 2.953859567642212
Validation loss: 2.1090072252417125

Epoch: 6| Step: 4
Training loss: 1.7892303466796875
Validation loss: 2.125606231791999

Epoch: 6| Step: 5
Training loss: 2.4354300498962402
Validation loss: 2.1264169190519597

Epoch: 6| Step: 6
Training loss: 2.4164271354675293
Validation loss: 2.163081522910826

Epoch: 6| Step: 7
Training loss: 1.7054121494293213
Validation loss: 2.0618659398889028

Epoch: 6| Step: 8
Training loss: 1.7145884037017822
Validation loss: 2.0917407312700824

Epoch: 6| Step: 9
Training loss: 2.4278101921081543
Validation loss: 2.1066093573006253

Epoch: 6| Step: 10
Training loss: 2.116905689239502
Validation loss: 2.1269463390432377

Epoch: 6| Step: 11
Training loss: 2.6120474338531494
Validation loss: 2.1502550545559136

Epoch: 6| Step: 12
Training loss: 2.303539752960205
Validation loss: 2.0595379414096957

Epoch: 6| Step: 13
Training loss: 2.0179672241210938
Validation loss: 2.1483507502463555

Epoch: 153| Step: 0
Training loss: 1.9402790069580078
Validation loss: 2.1463152375272525

Epoch: 6| Step: 1
Training loss: 2.248138666152954
Validation loss: 2.1288637089472946

Epoch: 6| Step: 2
Training loss: 2.2042369842529297
Validation loss: 2.0881863858110163

Epoch: 6| Step: 3
Training loss: 2.5537519454956055
Validation loss: 2.0334849101240917

Epoch: 6| Step: 4
Training loss: 1.6013853549957275
Validation loss: 2.1447367027241695

Epoch: 6| Step: 5
Training loss: 2.1592791080474854
Validation loss: 2.17239035073147

Epoch: 6| Step: 6
Training loss: 1.9883761405944824
Validation loss: 2.109386400509906

Epoch: 6| Step: 7
Training loss: 1.8606054782867432
Validation loss: 2.158723262048537

Epoch: 6| Step: 8
Training loss: 2.2895493507385254
Validation loss: 2.114034673219086

Epoch: 6| Step: 9
Training loss: 2.1530656814575195
Validation loss: 2.1504001784068283

Epoch: 6| Step: 10
Training loss: 2.492204189300537
Validation loss: 2.151846290916525

Epoch: 6| Step: 11
Training loss: 2.215080738067627
Validation loss: 2.14451838052401

Epoch: 6| Step: 12
Training loss: 2.369865894317627
Validation loss: 2.1625160953050018

Epoch: 6| Step: 13
Training loss: 2.632580518722534
Validation loss: 2.0778970180019254

Epoch: 154| Step: 0
Training loss: 1.966606855392456
Validation loss: 2.1694409052530923

Epoch: 6| Step: 1
Training loss: 1.9699506759643555
Validation loss: 2.1659548103168444

Epoch: 6| Step: 2
Training loss: 2.627910614013672
Validation loss: 2.095857257484108

Epoch: 6| Step: 3
Training loss: 1.5566258430480957
Validation loss: 2.1095147978874946

Epoch: 6| Step: 4
Training loss: 2.4041202068328857
Validation loss: 2.100284819961876

Epoch: 6| Step: 5
Training loss: 2.037163257598877
Validation loss: 2.161087856497816

Epoch: 6| Step: 6
Training loss: 2.648829460144043
Validation loss: 2.1870918581562657

Epoch: 6| Step: 7
Training loss: 2.1842551231384277
Validation loss: 2.1352575620015464

Epoch: 6| Step: 8
Training loss: 1.8232927322387695
Validation loss: 2.1315526718734414

Epoch: 6| Step: 9
Training loss: 2.4003939628601074
Validation loss: 2.1266583678542927

Epoch: 6| Step: 10
Training loss: 2.5005297660827637
Validation loss: 2.1456993062009095

Epoch: 6| Step: 11
Training loss: 2.2977397441864014
Validation loss: 2.0964664823265484

Epoch: 6| Step: 12
Training loss: 2.265601873397827
Validation loss: 2.097459247035365

Epoch: 6| Step: 13
Training loss: 2.225025177001953
Validation loss: 2.1338269877177414

Epoch: 155| Step: 0
Training loss: 2.0703468322753906
Validation loss: 2.106558617725167

Epoch: 6| Step: 1
Training loss: 2.5155346393585205
Validation loss: 2.12512642593794

Epoch: 6| Step: 2
Training loss: 1.6106139421463013
Validation loss: 2.066759083860664

Epoch: 6| Step: 3
Training loss: 1.8385627269744873
Validation loss: 2.123122094779886

Epoch: 6| Step: 4
Training loss: 2.6576807498931885
Validation loss: 2.032908325554222

Epoch: 6| Step: 5
Training loss: 1.6802315711975098
Validation loss: 2.066962900982108

Epoch: 6| Step: 6
Training loss: 2.2276315689086914
Validation loss: 2.0830944507352767

Epoch: 6| Step: 7
Training loss: 2.727017402648926
Validation loss: 2.1560203080536215

Epoch: 6| Step: 8
Training loss: 2.0377745628356934
Validation loss: 2.131861489306214

Epoch: 6| Step: 9
Training loss: 2.7453548908233643
Validation loss: 2.111336495286675

Epoch: 6| Step: 10
Training loss: 2.293525457382202
Validation loss: 2.1001662054369525

Epoch: 6| Step: 11
Training loss: 2.1432385444641113
Validation loss: 2.1553046549520185

Epoch: 6| Step: 12
Training loss: 1.6324068307876587
Validation loss: 2.03858014845079

Epoch: 6| Step: 13
Training loss: 3.047024965286255
Validation loss: 2.1352242449278473

Epoch: 156| Step: 0
Training loss: 2.5499117374420166
Validation loss: 2.1062037226974324

Epoch: 6| Step: 1
Training loss: 1.894357681274414
Validation loss: 2.1140989103624896

Epoch: 6| Step: 2
Training loss: 1.8847057819366455
Validation loss: 2.10508136082721

Epoch: 6| Step: 3
Training loss: 2.0060760974884033
Validation loss: 2.143325521099952

Epoch: 6| Step: 4
Training loss: 2.043401002883911
Validation loss: 2.0947815731007564

Epoch: 6| Step: 5
Training loss: 1.8979034423828125
Validation loss: 2.088275663314327

Epoch: 6| Step: 6
Training loss: 2.008024215698242
Validation loss: 2.1143789291381836

Epoch: 6| Step: 7
Training loss: 1.7840781211853027
Validation loss: 2.112464545875467

Epoch: 6| Step: 8
Training loss: 2.0782437324523926
Validation loss: 2.0968229873206026

Epoch: 6| Step: 9
Training loss: 2.305361747741699
Validation loss: 2.095261378954816

Epoch: 6| Step: 10
Training loss: 2.6504342555999756
Validation loss: 2.107950924545206

Epoch: 6| Step: 11
Training loss: 2.423877239227295
Validation loss: 2.068827538080113

Epoch: 6| Step: 12
Training loss: 2.4989967346191406
Validation loss: 2.1412905185453353

Epoch: 6| Step: 13
Training loss: 2.8734052181243896
Validation loss: 2.1110916624787035

Epoch: 157| Step: 0
Training loss: 2.2500925064086914
Validation loss: 2.1367083723827074

Epoch: 6| Step: 1
Training loss: 1.7814879417419434
Validation loss: 2.106351296106974

Epoch: 6| Step: 2
Training loss: 2.2953426837921143
Validation loss: 2.1116028934396724

Epoch: 6| Step: 3
Training loss: 2.7550313472747803
Validation loss: 2.1043427067418254

Epoch: 6| Step: 4
Training loss: 2.467904806137085
Validation loss: 2.048155858952512

Epoch: 6| Step: 5
Training loss: 1.7836285829544067
Validation loss: 2.111876236495151

Epoch: 6| Step: 6
Training loss: 2.5633273124694824
Validation loss: 2.149295776121078

Epoch: 6| Step: 7
Training loss: 2.0263326168060303
Validation loss: 2.0678971864843882

Epoch: 6| Step: 8
Training loss: 1.2123181819915771
Validation loss: 2.1140116196806713

Epoch: 6| Step: 9
Training loss: 2.3303213119506836
Validation loss: 2.0545626122464418

Epoch: 6| Step: 10
Training loss: 2.731666088104248
Validation loss: 2.091177466095135

Epoch: 6| Step: 11
Training loss: 2.361452102661133
Validation loss: 2.10533703911689

Epoch: 6| Step: 12
Training loss: 2.1733853816986084
Validation loss: 2.079278357567326

Epoch: 6| Step: 13
Training loss: 2.24226450920105
Validation loss: 2.116527798355267

Epoch: 158| Step: 0
Training loss: 1.9164443016052246
Validation loss: 2.1207755637425247

Epoch: 6| Step: 1
Training loss: 2.0420472621917725
Validation loss: 2.0645974374586538

Epoch: 6| Step: 2
Training loss: 2.203364849090576
Validation loss: 2.100049291887591

Epoch: 6| Step: 3
Training loss: 2.4735536575317383
Validation loss: 2.0875359248089533

Epoch: 6| Step: 4
Training loss: 1.912618637084961
Validation loss: 2.0849155649062125

Epoch: 6| Step: 5
Training loss: 2.4124250411987305
Validation loss: 2.1147540051450013

Epoch: 6| Step: 6
Training loss: 2.5541560649871826
Validation loss: 2.0903369918946297

Epoch: 6| Step: 7
Training loss: 2.72930645942688
Validation loss: 2.1113638775323027

Epoch: 6| Step: 8
Training loss: 2.464463710784912
Validation loss: 2.1191433219499487

Epoch: 6| Step: 9
Training loss: 1.8301435708999634
Validation loss: 2.1247440897008425

Epoch: 6| Step: 10
Training loss: 2.2169723510742188
Validation loss: 2.1448027510796823

Epoch: 6| Step: 11
Training loss: 1.791374683380127
Validation loss: 2.1020138725157707

Epoch: 6| Step: 12
Training loss: 2.4304661750793457
Validation loss: 2.0851930341412945

Epoch: 6| Step: 13
Training loss: 1.8873146772384644
Validation loss: 2.133521463281365

Epoch: 159| Step: 0
Training loss: 2.3512215614318848
Validation loss: 2.1191910646295034

Epoch: 6| Step: 1
Training loss: 2.2316079139709473
Validation loss: 2.1073559971265894

Epoch: 6| Step: 2
Training loss: 2.159562587738037
Validation loss: 2.0782684151844313

Epoch: 6| Step: 3
Training loss: 1.7984800338745117
Validation loss: 2.099938274711691

Epoch: 6| Step: 4
Training loss: 2.316628932952881
Validation loss: 2.1327572689261487

Epoch: 6| Step: 5
Training loss: 2.111598014831543
Validation loss: 2.14757610905555

Epoch: 6| Step: 6
Training loss: 2.64585018157959
Validation loss: 2.0689742821519093

Epoch: 6| Step: 7
Training loss: 2.297828435897827
Validation loss: 2.1381965939716627

Epoch: 6| Step: 8
Training loss: 2.2203638553619385
Validation loss: 2.144735749049853

Epoch: 6| Step: 9
Training loss: 1.771041989326477
Validation loss: 2.1155259250312723

Epoch: 6| Step: 10
Training loss: 2.2925541400909424
Validation loss: 2.1119460957024687

Epoch: 6| Step: 11
Training loss: 3.128368377685547
Validation loss: 2.103881084790794

Epoch: 6| Step: 12
Training loss: 1.4715721607208252
Validation loss: 2.0998068548017934

Epoch: 6| Step: 13
Training loss: 0.782780110836029
Validation loss: 2.1304836145011325

Epoch: 160| Step: 0
Training loss: 2.3860220909118652
Validation loss: 2.1015929637416715

Epoch: 6| Step: 1
Training loss: 2.0193636417388916
Validation loss: 2.103747994669022

Epoch: 6| Step: 2
Training loss: 1.251878023147583
Validation loss: 2.1189326060715543

Epoch: 6| Step: 3
Training loss: 2.2628660202026367
Validation loss: 2.122238237370727

Epoch: 6| Step: 4
Training loss: 2.8136560916900635
Validation loss: 2.0994467658381306

Epoch: 6| Step: 5
Training loss: 1.9731602668762207
Validation loss: 2.1122839937927904

Epoch: 6| Step: 6
Training loss: 1.843072533607483
Validation loss: 2.136058574081749

Epoch: 6| Step: 7
Training loss: 2.064725399017334
Validation loss: 2.1325537825143464

Epoch: 6| Step: 8
Training loss: 2.2890377044677734
Validation loss: 2.1330484651750132

Epoch: 6| Step: 9
Training loss: 2.4062247276306152
Validation loss: 2.076607434980331

Epoch: 6| Step: 10
Training loss: 2.1088180541992188
Validation loss: 2.109824585658248

Epoch: 6| Step: 11
Training loss: 2.7835631370544434
Validation loss: 2.083811552293839

Epoch: 6| Step: 12
Training loss: 2.276998519897461
Validation loss: 2.120196088667839

Epoch: 6| Step: 13
Training loss: 2.7149739265441895
Validation loss: 2.089396428036433

Epoch: 161| Step: 0
Training loss: 1.4870226383209229
Validation loss: 2.141961161808301

Epoch: 6| Step: 1
Training loss: 2.4993457794189453
Validation loss: 2.1269976105741275

Epoch: 6| Step: 2
Training loss: 1.8214561939239502
Validation loss: 2.1489665149360575

Epoch: 6| Step: 3
Training loss: 1.9950878620147705
Validation loss: 2.163452944447917

Epoch: 6| Step: 4
Training loss: 2.509687900543213
Validation loss: 2.14739546468181

Epoch: 6| Step: 5
Training loss: 2.6132450103759766
Validation loss: 2.0670847585124354

Epoch: 6| Step: 6
Training loss: 2.7812933921813965
Validation loss: 2.104738088064296

Epoch: 6| Step: 7
Training loss: 2.1332452297210693
Validation loss: 2.106646994108795

Epoch: 6| Step: 8
Training loss: 1.9381778240203857
Validation loss: 2.090378189599642

Epoch: 6| Step: 9
Training loss: 2.4057743549346924
Validation loss: 2.0983808117528118

Epoch: 6| Step: 10
Training loss: 2.1467936038970947
Validation loss: 2.11877247851382

Epoch: 6| Step: 11
Training loss: 1.7830448150634766
Validation loss: 2.087584500671715

Epoch: 6| Step: 12
Training loss: 1.9028313159942627
Validation loss: 2.079706491962556

Epoch: 6| Step: 13
Training loss: 2.873241901397705
Validation loss: 2.1533914663458384

Epoch: 162| Step: 0
Training loss: 2.7274904251098633
Validation loss: 2.1006364463478007

Epoch: 6| Step: 1
Training loss: 2.2990942001342773
Validation loss: 2.060979408602561

Epoch: 6| Step: 2
Training loss: 1.2771852016448975
Validation loss: 2.107112207720357

Epoch: 6| Step: 3
Training loss: 2.5952160358428955
Validation loss: 2.144674870275682

Epoch: 6| Step: 4
Training loss: 2.2717416286468506
Validation loss: 2.0574313978995047

Epoch: 6| Step: 5
Training loss: 2.2628087997436523
Validation loss: 2.1496762562823553

Epoch: 6| Step: 6
Training loss: 2.475616931915283
Validation loss: 2.144910822632492

Epoch: 6| Step: 7
Training loss: 2.073734760284424
Validation loss: 2.1208733550963865

Epoch: 6| Step: 8
Training loss: 2.3123955726623535
Validation loss: 2.1479582478923183

Epoch: 6| Step: 9
Training loss: 2.0842885971069336
Validation loss: 2.1058153965139903

Epoch: 6| Step: 10
Training loss: 2.5489449501037598
Validation loss: 2.1154958560902584

Epoch: 6| Step: 11
Training loss: 1.6959120035171509
Validation loss: 2.1230732881894676

Epoch: 6| Step: 12
Training loss: 2.2051634788513184
Validation loss: 2.078947674843573

Epoch: 6| Step: 13
Training loss: 1.7780170440673828
Validation loss: 2.176960195264509

Epoch: 163| Step: 0
Training loss: 3.118198871612549
Validation loss: 2.125213625610516

Epoch: 6| Step: 1
Training loss: 2.045548677444458
Validation loss: 2.1097799167838147

Epoch: 6| Step: 2
Training loss: 2.572869062423706
Validation loss: 2.112732243794267

Epoch: 6| Step: 3
Training loss: 2.293332099914551
Validation loss: 2.077702929896693

Epoch: 6| Step: 4
Training loss: 1.6659916639328003
Validation loss: 2.1477079083842616

Epoch: 6| Step: 5
Training loss: 2.2919135093688965
Validation loss: 2.126572160310643

Epoch: 6| Step: 6
Training loss: 2.4515912532806396
Validation loss: 2.142159728593724

Epoch: 6| Step: 7
Training loss: 2.3945021629333496
Validation loss: 2.168418845822734

Epoch: 6| Step: 8
Training loss: 2.9799203872680664
Validation loss: 2.1461436851050264

Epoch: 6| Step: 9
Training loss: 1.8596086502075195
Validation loss: 2.147966656633603

Epoch: 6| Step: 10
Training loss: 1.7126743793487549
Validation loss: 2.1171177253928235

Epoch: 6| Step: 11
Training loss: 1.2950199842453003
Validation loss: 2.1815392227583033

Epoch: 6| Step: 12
Training loss: 2.2960453033447266
Validation loss: 2.151013412783223

Epoch: 6| Step: 13
Training loss: 1.5001471042633057
Validation loss: 2.158956768692181

Epoch: 164| Step: 0
Training loss: 2.5636608600616455
Validation loss: 2.143108547374766

Epoch: 6| Step: 1
Training loss: 1.9901251792907715
Validation loss: 2.159844525398747

Epoch: 6| Step: 2
Training loss: 2.1340274810791016
Validation loss: 2.136524849040534

Epoch: 6| Step: 3
Training loss: 2.1991286277770996
Validation loss: 2.1397950495443037

Epoch: 6| Step: 4
Training loss: 2.4411768913269043
Validation loss: 2.1468749943599907

Epoch: 6| Step: 5
Training loss: 1.6613411903381348
Validation loss: 2.1454402195510043

Epoch: 6| Step: 6
Training loss: 2.0168352127075195
Validation loss: 2.11617108057904

Epoch: 6| Step: 7
Training loss: 1.780149221420288
Validation loss: 2.054706568359047

Epoch: 6| Step: 8
Training loss: 2.2512850761413574
Validation loss: 2.1158368510584675

Epoch: 6| Step: 9
Training loss: 2.8299801349639893
Validation loss: 2.106868972060501

Epoch: 6| Step: 10
Training loss: 2.433863401412964
Validation loss: 2.1404086466758483

Epoch: 6| Step: 11
Training loss: 1.9585849046707153
Validation loss: 2.118947127813934

Epoch: 6| Step: 12
Training loss: 2.2022390365600586
Validation loss: 2.12078796919956

Epoch: 6| Step: 13
Training loss: 2.1879160404205322
Validation loss: 2.1150044600168862

Epoch: 165| Step: 0
Training loss: 2.182966947555542
Validation loss: 2.147151508638936

Epoch: 6| Step: 1
Training loss: 2.3009276390075684
Validation loss: 2.046935935174265

Epoch: 6| Step: 2
Training loss: 2.3827438354492188
Validation loss: 2.1038901216240338

Epoch: 6| Step: 3
Training loss: 2.4265878200531006
Validation loss: 2.04389387817793

Epoch: 6| Step: 4
Training loss: 1.8185434341430664
Validation loss: 2.092184123172555

Epoch: 6| Step: 5
Training loss: 2.0707552433013916
Validation loss: 2.049390128863755

Epoch: 6| Step: 6
Training loss: 1.9539638757705688
Validation loss: 2.1106745991655576

Epoch: 6| Step: 7
Training loss: 2.576040744781494
Validation loss: 2.1032661340569936

Epoch: 6| Step: 8
Training loss: 2.4948034286499023
Validation loss: 2.112660300347113

Epoch: 6| Step: 9
Training loss: 2.2566704750061035
Validation loss: 2.0866814441578363

Epoch: 6| Step: 10
Training loss: 1.825819730758667
Validation loss: 2.0764091348135345

Epoch: 6| Step: 11
Training loss: 2.5010249614715576
Validation loss: 2.1289415410769883

Epoch: 6| Step: 12
Training loss: 1.5667327642440796
Validation loss: 2.0857412738184773

Epoch: 6| Step: 13
Training loss: 2.167837142944336
Validation loss: 2.077086248705464

Epoch: 166| Step: 0
Training loss: 2.1615428924560547
Validation loss: 2.03468051520727

Epoch: 6| Step: 1
Training loss: 2.3846631050109863
Validation loss: 2.0703836717913227

Epoch: 6| Step: 2
Training loss: 2.654390811920166
Validation loss: 2.065035068860618

Epoch: 6| Step: 3
Training loss: 2.643831968307495
Validation loss: 2.0037574306611092

Epoch: 6| Step: 4
Training loss: 1.9281768798828125
Validation loss: 2.0986914378340527

Epoch: 6| Step: 5
Training loss: 2.133090019226074
Validation loss: 2.14353286322727

Epoch: 6| Step: 6
Training loss: 2.281264305114746
Validation loss: 2.0829834168957126

Epoch: 6| Step: 7
Training loss: 1.665797233581543
Validation loss: 2.091394735920814

Epoch: 6| Step: 8
Training loss: 2.433912754058838
Validation loss: 2.093214945126605

Epoch: 6| Step: 9
Training loss: 1.1265606880187988
Validation loss: 2.122836591095053

Epoch: 6| Step: 10
Training loss: 2.1454620361328125
Validation loss: 2.0807904069141676

Epoch: 6| Step: 11
Training loss: 2.923281669616699
Validation loss: 2.1405639251073203

Epoch: 6| Step: 12
Training loss: 1.7484033107757568
Validation loss: 2.0905602106484036

Epoch: 6| Step: 13
Training loss: 2.1224992275238037
Validation loss: 2.0720672812513126

Epoch: 167| Step: 0
Training loss: 2.450169086456299
Validation loss: 2.0829695270907496

Epoch: 6| Step: 1
Training loss: 1.887131929397583
Validation loss: 2.0536199077483146

Epoch: 6| Step: 2
Training loss: 1.6685562133789062
Validation loss: 2.0899757454472203

Epoch: 6| Step: 3
Training loss: 2.792473077774048
Validation loss: 2.1039870990219938

Epoch: 6| Step: 4
Training loss: 1.4183735847473145
Validation loss: 2.1072538514291086

Epoch: 6| Step: 5
Training loss: 2.4580588340759277
Validation loss: 2.0545470817114717

Epoch: 6| Step: 6
Training loss: 2.678840160369873
Validation loss: 2.101839901298605

Epoch: 6| Step: 7
Training loss: 2.369636297225952
Validation loss: 2.0737220318086687

Epoch: 6| Step: 8
Training loss: 3.1295337677001953
Validation loss: 2.1564754363029235

Epoch: 6| Step: 9
Training loss: 2.0961151123046875
Validation loss: 2.0593279612961637

Epoch: 6| Step: 10
Training loss: 1.444555640220642
Validation loss: 2.116594878576135

Epoch: 6| Step: 11
Training loss: 2.08512806892395
Validation loss: 2.1233484796298447

Epoch: 6| Step: 12
Training loss: 2.229647159576416
Validation loss: 2.125504865441271

Epoch: 6| Step: 13
Training loss: 2.162029981613159
Validation loss: 2.1431103496141333

Epoch: 168| Step: 0
Training loss: 2.8097496032714844
Validation loss: 2.134050851227135

Epoch: 6| Step: 1
Training loss: 2.2730884552001953
Validation loss: 2.129942767081722

Epoch: 6| Step: 2
Training loss: 2.4015347957611084
Validation loss: 2.075304542818377

Epoch: 6| Step: 3
Training loss: 2.149264335632324
Validation loss: 2.096447585731424

Epoch: 6| Step: 4
Training loss: 2.128655195236206
Validation loss: 2.095877683290871

Epoch: 6| Step: 5
Training loss: 1.7708323001861572
Validation loss: 2.05698109826734

Epoch: 6| Step: 6
Training loss: 2.3794398307800293
Validation loss: 2.0828688785594

Epoch: 6| Step: 7
Training loss: 2.5119378566741943
Validation loss: 2.0357288852814706

Epoch: 6| Step: 8
Training loss: 1.903422474861145
Validation loss: 2.0988938180349206

Epoch: 6| Step: 9
Training loss: 2.365405559539795
Validation loss: 2.110621626659106

Epoch: 6| Step: 10
Training loss: 1.9829785823822021
Validation loss: 2.1327724200423046

Epoch: 6| Step: 11
Training loss: 1.9538134336471558
Validation loss: 2.097846620826311

Epoch: 6| Step: 12
Training loss: 1.9771137237548828
Validation loss: 2.1675202308162564

Epoch: 6| Step: 13
Training loss: 1.7328782081604004
Validation loss: 2.107486723571695

Epoch: 169| Step: 0
Training loss: 2.3683531284332275
Validation loss: 2.135347872652033

Epoch: 6| Step: 1
Training loss: 2.334243059158325
Validation loss: 2.086463958986344

Epoch: 6| Step: 2
Training loss: 1.747840166091919
Validation loss: 2.083938032068232

Epoch: 6| Step: 3
Training loss: 1.8546035289764404
Validation loss: 2.1153193635325276

Epoch: 6| Step: 4
Training loss: 2.8355941772460938
Validation loss: 2.1008770273577784

Epoch: 6| Step: 5
Training loss: 2.272542715072632
Validation loss: 2.130611071022608

Epoch: 6| Step: 6
Training loss: 2.2363336086273193
Validation loss: 2.073298159465995

Epoch: 6| Step: 7
Training loss: 2.1880311965942383
Validation loss: 2.094132402891754

Epoch: 6| Step: 8
Training loss: 2.3803696632385254
Validation loss: 2.1071468335326

Epoch: 6| Step: 9
Training loss: 1.908456802368164
Validation loss: 2.0807799549512964

Epoch: 6| Step: 10
Training loss: 3.0430660247802734
Validation loss: 2.078166748887749

Epoch: 6| Step: 11
Training loss: 1.8439396619796753
Validation loss: 2.096842932444747

Epoch: 6| Step: 12
Training loss: 1.8277616500854492
Validation loss: 2.1696689897967922

Epoch: 6| Step: 13
Training loss: 1.4704948663711548
Validation loss: 2.1108184373506935

Epoch: 170| Step: 0
Training loss: 2.2638964653015137
Validation loss: 2.0995366432333507

Epoch: 6| Step: 1
Training loss: 2.116577625274658
Validation loss: 2.115054161317887

Epoch: 6| Step: 2
Training loss: 1.8630857467651367
Validation loss: 2.14569011042195

Epoch: 6| Step: 3
Training loss: 2.7811646461486816
Validation loss: 2.126287337272398

Epoch: 6| Step: 4
Training loss: 1.6968169212341309
Validation loss: 2.1391104344398744

Epoch: 6| Step: 5
Training loss: 2.0110020637512207
Validation loss: 2.177067897653067

Epoch: 6| Step: 6
Training loss: 1.3503466844558716
Validation loss: 2.1403742451821604

Epoch: 6| Step: 7
Training loss: 2.4157936573028564
Validation loss: 2.1482970970933155

Epoch: 6| Step: 8
Training loss: 1.5119132995605469
Validation loss: 2.159175713857015

Epoch: 6| Step: 9
Training loss: 2.459425926208496
Validation loss: 2.13017935650323

Epoch: 6| Step: 10
Training loss: 2.651585578918457
Validation loss: 2.1451913720817974

Epoch: 6| Step: 11
Training loss: 2.5990407466888428
Validation loss: 2.1513268101599907

Epoch: 6| Step: 12
Training loss: 2.1710948944091797
Validation loss: 2.152729393333517

Epoch: 6| Step: 13
Training loss: 2.159409999847412
Validation loss: 2.156682583593553

Epoch: 171| Step: 0
Training loss: 2.57543683052063
Validation loss: 2.190452537228984

Epoch: 6| Step: 1
Training loss: 2.8820462226867676
Validation loss: 2.1511524210694017

Epoch: 6| Step: 2
Training loss: 2.3668441772460938
Validation loss: 2.1492157456695393

Epoch: 6| Step: 3
Training loss: 1.9990137815475464
Validation loss: 2.149458835201879

Epoch: 6| Step: 4
Training loss: 2.187558650970459
Validation loss: 2.1678336845931185

Epoch: 6| Step: 5
Training loss: 2.4675395488739014
Validation loss: 2.1153702889719317

Epoch: 6| Step: 6
Training loss: 2.0023014545440674
Validation loss: 2.1212881534330306

Epoch: 6| Step: 7
Training loss: 2.2405123710632324
Validation loss: 2.229935904984833

Epoch: 6| Step: 8
Training loss: 2.15517520904541
Validation loss: 2.1584267308635097

Epoch: 6| Step: 9
Training loss: 2.6468937397003174
Validation loss: 2.1196499614305395

Epoch: 6| Step: 10
Training loss: 1.811417818069458
Validation loss: 2.1121936152058263

Epoch: 6| Step: 11
Training loss: 1.8714280128479004
Validation loss: 2.1383532913782264

Epoch: 6| Step: 12
Training loss: 1.8639612197875977
Validation loss: 2.156290900322699

Epoch: 6| Step: 13
Training loss: 2.2052383422851562
Validation loss: 2.116930751390355

Epoch: 172| Step: 0
Training loss: 2.037259578704834
Validation loss: 2.1155586781040316

Epoch: 6| Step: 1
Training loss: 2.825977087020874
Validation loss: 2.097461490220921

Epoch: 6| Step: 2
Training loss: 1.8213531970977783
Validation loss: 2.126939255704162

Epoch: 6| Step: 3
Training loss: 2.036268711090088
Validation loss: 2.078731575319844

Epoch: 6| Step: 4
Training loss: 1.690527081489563
Validation loss: 2.127933916225228

Epoch: 6| Step: 5
Training loss: 2.0670714378356934
Validation loss: 2.139272392437022

Epoch: 6| Step: 6
Training loss: 2.1912996768951416
Validation loss: 2.09215642816277

Epoch: 6| Step: 7
Training loss: 2.1715810298919678
Validation loss: 2.110389276217389

Epoch: 6| Step: 8
Training loss: 2.500307083129883
Validation loss: 2.187814312596475

Epoch: 6| Step: 9
Training loss: 2.199580669403076
Validation loss: 2.093919083636294

Epoch: 6| Step: 10
Training loss: 2.9172706604003906
Validation loss: 2.1489358025212444

Epoch: 6| Step: 11
Training loss: 1.5929722785949707
Validation loss: 2.122252025911885

Epoch: 6| Step: 12
Training loss: 2.044471263885498
Validation loss: 2.1418820068400395

Epoch: 6| Step: 13
Training loss: 2.2304582595825195
Validation loss: 2.1695388196617045

Epoch: 173| Step: 0
Training loss: 2.2651052474975586
Validation loss: 2.0882288537999636

Epoch: 6| Step: 1
Training loss: 1.9553556442260742
Validation loss: 2.0957022097802933

Epoch: 6| Step: 2
Training loss: 2.556346893310547
Validation loss: 2.1338690788515153

Epoch: 6| Step: 3
Training loss: 2.0494654178619385
Validation loss: 2.1375009834125476

Epoch: 6| Step: 4
Training loss: 2.708402156829834
Validation loss: 2.1348450517141693

Epoch: 6| Step: 5
Training loss: 1.9594231843948364
Validation loss: 2.131955850508905

Epoch: 6| Step: 6
Training loss: 1.7658851146697998
Validation loss: 2.1450095535606466

Epoch: 6| Step: 7
Training loss: 2.2520554065704346
Validation loss: 2.136249383290609

Epoch: 6| Step: 8
Training loss: 2.237269878387451
Validation loss: 2.119911996267175

Epoch: 6| Step: 9
Training loss: 2.068844795227051
Validation loss: 2.089070006083417

Epoch: 6| Step: 10
Training loss: 2.4796905517578125
Validation loss: 2.074929339911348

Epoch: 6| Step: 11
Training loss: 1.8930001258850098
Validation loss: 2.129106039642006

Epoch: 6| Step: 12
Training loss: 1.747530460357666
Validation loss: 2.150696431436846

Epoch: 6| Step: 13
Training loss: 2.732076406478882
Validation loss: 2.0923883863674697

Epoch: 174| Step: 0
Training loss: 1.4444377422332764
Validation loss: 2.1255894784004457

Epoch: 6| Step: 1
Training loss: 2.6237635612487793
Validation loss: 2.108059726735597

Epoch: 6| Step: 2
Training loss: 2.304867744445801
Validation loss: 2.1326585046706663

Epoch: 6| Step: 3
Training loss: 1.5691908597946167
Validation loss: 2.18516275446902

Epoch: 6| Step: 4
Training loss: 2.3788704872131348
Validation loss: 2.062068781545085

Epoch: 6| Step: 5
Training loss: 2.8109850883483887
Validation loss: 2.119883078400807

Epoch: 6| Step: 6
Training loss: 2.4229307174682617
Validation loss: 2.0747540176555677

Epoch: 6| Step: 7
Training loss: 1.703850269317627
Validation loss: 2.0984804502097507

Epoch: 6| Step: 8
Training loss: 2.035181760787964
Validation loss: 2.1254006201221096

Epoch: 6| Step: 9
Training loss: 2.13346266746521
Validation loss: 2.1042956562452417

Epoch: 6| Step: 10
Training loss: 2.307382106781006
Validation loss: 2.0807547774366153

Epoch: 6| Step: 11
Training loss: 2.333461046218872
Validation loss: 2.104385014503233

Epoch: 6| Step: 12
Training loss: 2.171184778213501
Validation loss: 2.127719094676356

Epoch: 6| Step: 13
Training loss: 1.9501255750656128
Validation loss: 2.089149787861814

Epoch: 175| Step: 0
Training loss: 1.9530553817749023
Validation loss: 2.0619330521552794

Epoch: 6| Step: 1
Training loss: 1.743077039718628
Validation loss: 2.1186073364750033

Epoch: 6| Step: 2
Training loss: 2.8965725898742676
Validation loss: 2.1286656933446086

Epoch: 6| Step: 3
Training loss: 1.5001587867736816
Validation loss: 2.0479423346058017

Epoch: 6| Step: 4
Training loss: 2.044351100921631
Validation loss: 2.065057261015779

Epoch: 6| Step: 5
Training loss: 1.69312584400177
Validation loss: 2.0832012135495424

Epoch: 6| Step: 6
Training loss: 2.451305627822876
Validation loss: 2.0616987546284995

Epoch: 6| Step: 7
Training loss: 2.0613160133361816
Validation loss: 2.0160088616032756

Epoch: 6| Step: 8
Training loss: 2.006354808807373
Validation loss: 2.0991915143946165

Epoch: 6| Step: 9
Training loss: 2.0011425018310547
Validation loss: 2.0650842215425227

Epoch: 6| Step: 10
Training loss: 3.181347370147705
Validation loss: 2.0749576091766357

Epoch: 6| Step: 11
Training loss: 2.755025863647461
Validation loss: 2.079134674482448

Epoch: 6| Step: 12
Training loss: 2.2616312503814697
Validation loss: 2.1160549092036423

Epoch: 6| Step: 13
Training loss: 2.1844606399536133
Validation loss: 2.042212861840443

Epoch: 176| Step: 0
Training loss: 2.2249653339385986
Validation loss: 2.0466540487863685

Epoch: 6| Step: 1
Training loss: 2.7259535789489746
Validation loss: 2.016861205459923

Epoch: 6| Step: 2
Training loss: 1.689231038093567
Validation loss: 2.0723873825483423

Epoch: 6| Step: 3
Training loss: 2.064499855041504
Validation loss: 2.0982486970963015

Epoch: 6| Step: 4
Training loss: 2.4451799392700195
Validation loss: 2.1301585499958327

Epoch: 6| Step: 5
Training loss: 2.5078887939453125
Validation loss: 2.114344184116651

Epoch: 6| Step: 6
Training loss: 2.2213406562805176
Validation loss: 2.0865797509429274

Epoch: 6| Step: 7
Training loss: 1.80968177318573
Validation loss: 2.066946347554525

Epoch: 6| Step: 8
Training loss: 2.2836079597473145
Validation loss: 2.1628973407130085

Epoch: 6| Step: 9
Training loss: 1.7855355739593506
Validation loss: 2.1157037391457507

Epoch: 6| Step: 10
Training loss: 1.8375506401062012
Validation loss: 2.147567456768405

Epoch: 6| Step: 11
Training loss: 2.5986757278442383
Validation loss: 2.04758164446841

Epoch: 6| Step: 12
Training loss: 2.070704460144043
Validation loss: 2.1550458708117084

Epoch: 6| Step: 13
Training loss: 2.17384934425354
Validation loss: 2.097485525633699

Epoch: 177| Step: 0
Training loss: 2.666057825088501
Validation loss: 2.199069228223575

Epoch: 6| Step: 1
Training loss: 2.155439853668213
Validation loss: 2.075574671068499

Epoch: 6| Step: 2
Training loss: 2.556551456451416
Validation loss: 2.0778746656192246

Epoch: 6| Step: 3
Training loss: 2.9439544677734375
Validation loss: 2.22826636222101

Epoch: 6| Step: 4
Training loss: 1.854980230331421
Validation loss: 2.06865632149481

Epoch: 6| Step: 5
Training loss: 1.7686705589294434
Validation loss: 2.1503882805506387

Epoch: 6| Step: 6
Training loss: 1.866308569908142
Validation loss: 2.1013795457860476

Epoch: 6| Step: 7
Training loss: 1.7695165872573853
Validation loss: 2.090703402796099

Epoch: 6| Step: 8
Training loss: 1.8376864194869995
Validation loss: 2.1225354197204753

Epoch: 6| Step: 9
Training loss: 2.148432731628418
Validation loss: 2.056086512022121

Epoch: 6| Step: 10
Training loss: 2.205197334289551
Validation loss: 2.1242640172281573

Epoch: 6| Step: 11
Training loss: 2.201293468475342
Validation loss: 2.0362359810900945

Epoch: 6| Step: 12
Training loss: 2.2689247131347656
Validation loss: 2.0802715055404173

Epoch: 6| Step: 13
Training loss: 2.6112165451049805
Validation loss: 2.1226874141282934

Epoch: 178| Step: 0
Training loss: 2.407341480255127
Validation loss: 2.095425633973973

Epoch: 6| Step: 1
Training loss: 1.6358041763305664
Validation loss: 2.134420079569663

Epoch: 6| Step: 2
Training loss: 2.5582997798919678
Validation loss: 2.049791466805243

Epoch: 6| Step: 3
Training loss: 1.9805845022201538
Validation loss: 2.0843913914054952

Epoch: 6| Step: 4
Training loss: 1.4615124464035034
Validation loss: 2.095586819033469

Epoch: 6| Step: 5
Training loss: 1.8002797365188599
Validation loss: 2.093779371630761

Epoch: 6| Step: 6
Training loss: 1.6889317035675049
Validation loss: 2.1027362731195267

Epoch: 6| Step: 7
Training loss: 2.7523186206817627
Validation loss: 2.0771567590775026

Epoch: 6| Step: 8
Training loss: 2.8255605697631836
Validation loss: 2.142658269533547

Epoch: 6| Step: 9
Training loss: 2.082895278930664
Validation loss: 2.0782447886723343

Epoch: 6| Step: 10
Training loss: 2.3937249183654785
Validation loss: 2.0992164534907185

Epoch: 6| Step: 11
Training loss: 1.7979661226272583
Validation loss: 2.1354062377765612

Epoch: 6| Step: 12
Training loss: 3.0725021362304688
Validation loss: 2.0993233688416018

Epoch: 6| Step: 13
Training loss: 1.928181529045105
Validation loss: 2.152541842511905

Epoch: 179| Step: 0
Training loss: 2.1004772186279297
Validation loss: 2.1121725664343884

Epoch: 6| Step: 1
Training loss: 1.9139808416366577
Validation loss: 2.1557325881014586

Epoch: 6| Step: 2
Training loss: 1.8067137002944946
Validation loss: 2.1364142458925963

Epoch: 6| Step: 3
Training loss: 2.5218377113342285
Validation loss: 2.0950741498701033

Epoch: 6| Step: 4
Training loss: 2.407186269760132
Validation loss: 2.1067332657434608

Epoch: 6| Step: 5
Training loss: 2.4232406616210938
Validation loss: 2.126888405892157

Epoch: 6| Step: 6
Training loss: 2.1160242557525635
Validation loss: 2.107077339644073

Epoch: 6| Step: 7
Training loss: 2.089752197265625
Validation loss: 2.1364168966970136

Epoch: 6| Step: 8
Training loss: 2.2495956420898438
Validation loss: 2.1873666881233134

Epoch: 6| Step: 9
Training loss: 1.9389560222625732
Validation loss: 2.0768033227612896

Epoch: 6| Step: 10
Training loss: 2.1769771575927734
Validation loss: 2.0724731171002952

Epoch: 6| Step: 11
Training loss: 2.066866874694824
Validation loss: 2.1535964089055217

Epoch: 6| Step: 12
Training loss: 1.7489782571792603
Validation loss: 2.1739910494896675

Epoch: 6| Step: 13
Training loss: 2.8364055156707764
Validation loss: 2.183346051041798

Epoch: 180| Step: 0
Training loss: 2.5969290733337402
Validation loss: 2.1832344544831144

Epoch: 6| Step: 1
Training loss: 1.948028802871704
Validation loss: 2.07126812524693

Epoch: 6| Step: 2
Training loss: 1.5368821620941162
Validation loss: 2.036983824545337

Epoch: 6| Step: 3
Training loss: 1.3718719482421875
Validation loss: 2.1095908380323842

Epoch: 6| Step: 4
Training loss: 2.02744197845459
Validation loss: 2.0723654377845024

Epoch: 6| Step: 5
Training loss: 2.4952616691589355
Validation loss: 2.0735118055856354

Epoch: 6| Step: 6
Training loss: 2.683182716369629
Validation loss: 2.077889794944435

Epoch: 6| Step: 7
Training loss: 2.7291975021362305
Validation loss: 2.0903533581764466

Epoch: 6| Step: 8
Training loss: 2.5987367630004883
Validation loss: 2.1221640904744468

Epoch: 6| Step: 9
Training loss: 2.306211471557617
Validation loss: 2.1284723986861525

Epoch: 6| Step: 10
Training loss: 1.318246603012085
Validation loss: 2.1200787380177486

Epoch: 6| Step: 11
Training loss: 2.3139424324035645
Validation loss: 2.1074129458396667

Epoch: 6| Step: 12
Training loss: 2.141251564025879
Validation loss: 2.1059702852720856

Epoch: 6| Step: 13
Training loss: 2.325725555419922
Validation loss: 2.079797257659256

Epoch: 181| Step: 0
Training loss: 1.7780615091323853
Validation loss: 2.0805643220101633

Epoch: 6| Step: 1
Training loss: 1.745253562927246
Validation loss: 2.0966212967390656

Epoch: 6| Step: 2
Training loss: 2.020036220550537
Validation loss: 2.0957771270505843

Epoch: 6| Step: 3
Training loss: 2.3484697341918945
Validation loss: 2.1262794374137797

Epoch: 6| Step: 4
Training loss: 2.1844491958618164
Validation loss: 2.118546680737567

Epoch: 6| Step: 5
Training loss: 2.670738458633423
Validation loss: 2.0781191190083823

Epoch: 6| Step: 6
Training loss: 2.6420202255249023
Validation loss: 2.089271016018365

Epoch: 6| Step: 7
Training loss: 2.5989415645599365
Validation loss: 2.105791102173508

Epoch: 6| Step: 8
Training loss: 2.0215601921081543
Validation loss: 2.083426603706934

Epoch: 6| Step: 9
Training loss: 1.7748026847839355
Validation loss: 2.083661876698976

Epoch: 6| Step: 10
Training loss: 1.8349852561950684
Validation loss: 2.082752066273843

Epoch: 6| Step: 11
Training loss: 2.1382365226745605
Validation loss: 2.08511689401442

Epoch: 6| Step: 12
Training loss: 2.3263344764709473
Validation loss: 2.065818138020013

Epoch: 6| Step: 13
Training loss: 1.8600987195968628
Validation loss: 2.121366024017334

Epoch: 182| Step: 0
Training loss: 2.043518304824829
Validation loss: 2.110357271727695

Epoch: 6| Step: 1
Training loss: 2.2947750091552734
Validation loss: 2.054317364128687

Epoch: 6| Step: 2
Training loss: 1.8645455837249756
Validation loss: 2.0816647173256

Epoch: 6| Step: 3
Training loss: 2.8463475704193115
Validation loss: 2.057431520954255

Epoch: 6| Step: 4
Training loss: 2.270900011062622
Validation loss: 2.07267302338795

Epoch: 6| Step: 5
Training loss: 2.084019184112549
Validation loss: 2.1492420755406862

Epoch: 6| Step: 6
Training loss: 1.793266773223877
Validation loss: 2.0367725459478234

Epoch: 6| Step: 7
Training loss: 2.001047134399414
Validation loss: 2.084660827472646

Epoch: 6| Step: 8
Training loss: 2.9263722896575928
Validation loss: 2.127104272124588

Epoch: 6| Step: 9
Training loss: 1.8436648845672607
Validation loss: 2.1529711113181165

Epoch: 6| Step: 10
Training loss: 1.7570381164550781
Validation loss: 2.0816055356815295

Epoch: 6| Step: 11
Training loss: 2.1986184120178223
Validation loss: 2.132404258174281

Epoch: 6| Step: 12
Training loss: 2.869569778442383
Validation loss: 2.160327260212232

Epoch: 6| Step: 13
Training loss: 1.9271445274353027
Validation loss: 2.1234853165124052

Epoch: 183| Step: 0
Training loss: 1.9948577880859375
Validation loss: 2.1840615887795725

Epoch: 6| Step: 1
Training loss: 1.9812257289886475
Validation loss: 2.107775911208122

Epoch: 6| Step: 2
Training loss: 1.3912380933761597
Validation loss: 2.1387728721864763

Epoch: 6| Step: 3
Training loss: 2.259070634841919
Validation loss: 2.0991169765431392

Epoch: 6| Step: 4
Training loss: 1.9923679828643799
Validation loss: 2.1110380464984524

Epoch: 6| Step: 5
Training loss: 2.7247672080993652
Validation loss: 2.0824665728435723

Epoch: 6| Step: 6
Training loss: 1.9539384841918945
Validation loss: 2.1032253567890455

Epoch: 6| Step: 7
Training loss: 1.997650384902954
Validation loss: 2.096874754915955

Epoch: 6| Step: 8
Training loss: 2.1269750595092773
Validation loss: 2.1556101076064573

Epoch: 6| Step: 9
Training loss: 2.557821750640869
Validation loss: 2.1337213413689726

Epoch: 6| Step: 10
Training loss: 2.636157512664795
Validation loss: 2.069128228772071

Epoch: 6| Step: 11
Training loss: 2.239809989929199
Validation loss: 2.149322666147704

Epoch: 6| Step: 12
Training loss: 1.8900063037872314
Validation loss: 2.1862698114046486

Epoch: 6| Step: 13
Training loss: 2.618783473968506
Validation loss: 2.1364917101398593

Epoch: 184| Step: 0
Training loss: 2.4356000423431396
Validation loss: 2.1784228535108667

Epoch: 6| Step: 1
Training loss: 2.030478000640869
Validation loss: 2.0975451623239825

Epoch: 6| Step: 2
Training loss: 2.0935888290405273
Validation loss: 2.126802349603304

Epoch: 6| Step: 3
Training loss: 2.466123580932617
Validation loss: 2.1131045356873543

Epoch: 6| Step: 4
Training loss: 1.8690130710601807
Validation loss: 2.1213670340917443

Epoch: 6| Step: 5
Training loss: 1.9433696269989014
Validation loss: 2.1030817929134575

Epoch: 6| Step: 6
Training loss: 1.9692916870117188
Validation loss: 2.089931071445506

Epoch: 6| Step: 7
Training loss: 2.3406574726104736
Validation loss: 2.1053317439171577

Epoch: 6| Step: 8
Training loss: 2.2311105728149414
Validation loss: 2.161264104227866

Epoch: 6| Step: 9
Training loss: 2.517777442932129
Validation loss: 2.1168744871693272

Epoch: 6| Step: 10
Training loss: 1.8330107927322388
Validation loss: 2.12419226092677

Epoch: 6| Step: 11
Training loss: 2.1976895332336426
Validation loss: 2.150831699371338

Epoch: 6| Step: 12
Training loss: 1.8709441423416138
Validation loss: 2.1616258762216054

Epoch: 6| Step: 13
Training loss: 2.8473896980285645
Validation loss: 2.1324898940260693

Epoch: 185| Step: 0
Training loss: 2.56565523147583
Validation loss: 2.0928324550710697

Epoch: 6| Step: 1
Training loss: 1.893934965133667
Validation loss: 2.1187499210398686

Epoch: 6| Step: 2
Training loss: 2.6360678672790527
Validation loss: 2.114024149474277

Epoch: 6| Step: 3
Training loss: 2.312683582305908
Validation loss: 2.140694643861504

Epoch: 6| Step: 4
Training loss: 2.6158595085144043
Validation loss: 2.133178154627482

Epoch: 6| Step: 5
Training loss: 1.7800142765045166
Validation loss: 2.1686213836875012

Epoch: 6| Step: 6
Training loss: 1.9993722438812256
Validation loss: 2.165884002562492

Epoch: 6| Step: 7
Training loss: 1.9736058712005615
Validation loss: 2.164472956811228

Epoch: 6| Step: 8
Training loss: 2.1086363792419434
Validation loss: 2.1039018220798944

Epoch: 6| Step: 9
Training loss: 1.527077555656433
Validation loss: 2.094811137004565

Epoch: 6| Step: 10
Training loss: 2.3745713233947754
Validation loss: 2.1409038036100325

Epoch: 6| Step: 11
Training loss: 1.9190927743911743
Validation loss: 2.126385869518403

Epoch: 6| Step: 12
Training loss: 2.5311150550842285
Validation loss: 2.0958436073795443

Epoch: 6| Step: 13
Training loss: 1.6868687868118286
Validation loss: 2.108651150939285

Epoch: 186| Step: 0
Training loss: 2.4727606773376465
Validation loss: 2.1445072902146207

Epoch: 6| Step: 1
Training loss: 2.263948917388916
Validation loss: 2.1578005770201325

Epoch: 6| Step: 2
Training loss: 2.3701701164245605
Validation loss: 2.1697793096624394

Epoch: 6| Step: 3
Training loss: 2.3180761337280273
Validation loss: 2.0936862204664495

Epoch: 6| Step: 4
Training loss: 2.4411442279815674
Validation loss: 2.1197135576637844

Epoch: 6| Step: 5
Training loss: 2.5327930450439453
Validation loss: 2.124679559020586

Epoch: 6| Step: 6
Training loss: 2.0418508052825928
Validation loss: 2.0876487019241496

Epoch: 6| Step: 7
Training loss: 1.9850043058395386
Validation loss: 2.087022110980044

Epoch: 6| Step: 8
Training loss: 2.1554036140441895
Validation loss: 2.106182272716235

Epoch: 6| Step: 9
Training loss: 1.5203895568847656
Validation loss: 2.1176804573305192

Epoch: 6| Step: 10
Training loss: 1.917398452758789
Validation loss: 2.1207981455710625

Epoch: 6| Step: 11
Training loss: 1.3974308967590332
Validation loss: 2.1194530071750766

Epoch: 6| Step: 12
Training loss: 2.196760654449463
Validation loss: 2.1099758340466406

Epoch: 6| Step: 13
Training loss: 3.1969425678253174
Validation loss: 2.1287095751813663

Epoch: 187| Step: 0
Training loss: 2.402287721633911
Validation loss: 2.101359055888268

Epoch: 6| Step: 1
Training loss: 2.1174895763397217
Validation loss: 2.122087565801477

Epoch: 6| Step: 2
Training loss: 2.326195240020752
Validation loss: 2.0875254933552077

Epoch: 6| Step: 3
Training loss: 2.1972403526306152
Validation loss: 2.119120528621058

Epoch: 6| Step: 4
Training loss: 2.352720260620117
Validation loss: 2.059622367223104

Epoch: 6| Step: 5
Training loss: 2.4897568225860596
Validation loss: 2.1123726085949968

Epoch: 6| Step: 6
Training loss: 2.372570514678955
Validation loss: 2.137392051758305

Epoch: 6| Step: 7
Training loss: 2.663747787475586
Validation loss: 2.1024836929895545

Epoch: 6| Step: 8
Training loss: 1.5656745433807373
Validation loss: 2.1294023990631104

Epoch: 6| Step: 9
Training loss: 1.8116631507873535
Validation loss: 2.1301885228003226

Epoch: 6| Step: 10
Training loss: 1.9745521545410156
Validation loss: 2.1194839233993203

Epoch: 6| Step: 11
Training loss: 1.991379976272583
Validation loss: 2.1143603504344983

Epoch: 6| Step: 12
Training loss: 2.7241873741149902
Validation loss: 2.1215605325596307

Epoch: 6| Step: 13
Training loss: 1.447608232498169
Validation loss: 2.120173996494662

Epoch: 188| Step: 0
Training loss: 2.5473110675811768
Validation loss: 2.085545260419128

Epoch: 6| Step: 1
Training loss: 2.2423970699310303
Validation loss: 2.067154251119142

Epoch: 6| Step: 2
Training loss: 2.2266197204589844
Validation loss: 2.121004407123853

Epoch: 6| Step: 3
Training loss: 2.319518566131592
Validation loss: 2.130453254586907

Epoch: 6| Step: 4
Training loss: 2.7199597358703613
Validation loss: 2.088850986573004

Epoch: 6| Step: 5
Training loss: 2.264382839202881
Validation loss: 2.0809526071753552

Epoch: 6| Step: 6
Training loss: 2.4988558292388916
Validation loss: 2.104941548839692

Epoch: 6| Step: 7
Training loss: 1.380997657775879
Validation loss: 2.051786263783773

Epoch: 6| Step: 8
Training loss: 2.378568649291992
Validation loss: 2.149035128214026

Epoch: 6| Step: 9
Training loss: 2.061534881591797
Validation loss: 2.108883071971196

Epoch: 6| Step: 10
Training loss: 1.9369146823883057
Validation loss: 2.0890568956252067

Epoch: 6| Step: 11
Training loss: 1.7783312797546387
Validation loss: 2.1309923830852715

Epoch: 6| Step: 12
Training loss: 1.7672775983810425
Validation loss: 2.0990100701649985

Epoch: 6| Step: 13
Training loss: 2.7746963500976562
Validation loss: 2.0889347112306984

Epoch: 189| Step: 0
Training loss: 2.6887123584747314
Validation loss: 2.1006113021604476

Epoch: 6| Step: 1
Training loss: 2.089594602584839
Validation loss: 2.0600915698594946

Epoch: 6| Step: 2
Training loss: 1.8710308074951172
Validation loss: 2.137293246484572

Epoch: 6| Step: 3
Training loss: 3.096583127975464
Validation loss: 2.0512019870101765

Epoch: 6| Step: 4
Training loss: 2.0238850116729736
Validation loss: 2.130753206950362

Epoch: 6| Step: 5
Training loss: 2.0710363388061523
Validation loss: 2.066050773025841

Epoch: 6| Step: 6
Training loss: 2.061143159866333
Validation loss: 2.1840647625666794

Epoch: 6| Step: 7
Training loss: 2.998528242111206
Validation loss: 2.0931976969524095

Epoch: 6| Step: 8
Training loss: 2.101142406463623
Validation loss: 2.1507371920411305

Epoch: 6| Step: 9
Training loss: 2.154632329940796
Validation loss: 2.074096469468968

Epoch: 6| Step: 10
Training loss: 1.4321539402008057
Validation loss: 2.087292730167348

Epoch: 6| Step: 11
Training loss: 1.704430341720581
Validation loss: 2.1306644280751548

Epoch: 6| Step: 12
Training loss: 1.764148473739624
Validation loss: 2.0937266683065765

Epoch: 6| Step: 13
Training loss: 2.1666369438171387
Validation loss: 2.1089152405338902

Epoch: 190| Step: 0
Training loss: 2.013434410095215
Validation loss: 2.150823373948374

Epoch: 6| Step: 1
Training loss: 2.343777894973755
Validation loss: 2.175985633686025

Epoch: 6| Step: 2
Training loss: 2.248487949371338
Validation loss: 2.121395823776081

Epoch: 6| Step: 3
Training loss: 1.3733255863189697
Validation loss: 2.1187462293973534

Epoch: 6| Step: 4
Training loss: 2.0944764614105225
Validation loss: 2.060944903281427

Epoch: 6| Step: 5
Training loss: 2.468690872192383
Validation loss: 2.0690619509707213

Epoch: 6| Step: 6
Training loss: 2.4335098266601562
Validation loss: 2.1128594195970924

Epoch: 6| Step: 7
Training loss: 2.173776149749756
Validation loss: 2.153580927079724

Epoch: 6| Step: 8
Training loss: 2.9392104148864746
Validation loss: 2.135952434232158

Epoch: 6| Step: 9
Training loss: 1.413607120513916
Validation loss: 2.182886415912259

Epoch: 6| Step: 10
Training loss: 2.854217529296875
Validation loss: 2.1142495204043645

Epoch: 6| Step: 11
Training loss: 1.7853598594665527
Validation loss: 2.144304242185367

Epoch: 6| Step: 12
Training loss: 2.140195846557617
Validation loss: 2.1586070958004204

Epoch: 6| Step: 13
Training loss: 1.4589394330978394
Validation loss: 2.121302607238934

Epoch: 191| Step: 0
Training loss: 2.06781005859375
Validation loss: 2.094092303706754

Epoch: 6| Step: 1
Training loss: 2.8053903579711914
Validation loss: 2.0822586064697592

Epoch: 6| Step: 2
Training loss: 2.060883045196533
Validation loss: 2.143670723002444

Epoch: 6| Step: 3
Training loss: 1.937939167022705
Validation loss: 2.1449010449071086

Epoch: 6| Step: 4
Training loss: 2.371222734451294
Validation loss: 2.1108586685631865

Epoch: 6| Step: 5
Training loss: 2.9903979301452637
Validation loss: 2.105714310881912

Epoch: 6| Step: 6
Training loss: 2.2507996559143066
Validation loss: 2.0717127233423214

Epoch: 6| Step: 7
Training loss: 1.8760626316070557
Validation loss: 2.143650672769034

Epoch: 6| Step: 8
Training loss: 2.243058919906616
Validation loss: 2.07975011743525

Epoch: 6| Step: 9
Training loss: 1.5574426651000977
Validation loss: 2.0960764167129353

Epoch: 6| Step: 10
Training loss: 1.7428534030914307
Validation loss: 2.089782481552452

Epoch: 6| Step: 11
Training loss: 2.147514581680298
Validation loss: 2.0483305274799304

Epoch: 6| Step: 12
Training loss: 2.382110595703125
Validation loss: 2.099901827432776

Epoch: 6| Step: 13
Training loss: 2.049752712249756
Validation loss: 2.1296390205301265

Epoch: 192| Step: 0
Training loss: 2.360166072845459
Validation loss: 2.0436302538841002

Epoch: 6| Step: 1
Training loss: 1.879473090171814
Validation loss: 2.159763664327642

Epoch: 6| Step: 2
Training loss: 3.1057522296905518
Validation loss: 2.0952668677094164

Epoch: 6| Step: 3
Training loss: 1.4932857751846313
Validation loss: 2.0890847457352506

Epoch: 6| Step: 4
Training loss: 1.7785797119140625
Validation loss: 2.1004990390551987

Epoch: 6| Step: 5
Training loss: 2.6557536125183105
Validation loss: 2.091534432544503

Epoch: 6| Step: 6
Training loss: 2.0331485271453857
Validation loss: 2.124217812732984

Epoch: 6| Step: 7
Training loss: 2.4473373889923096
Validation loss: 2.0928383463172504

Epoch: 6| Step: 8
Training loss: 1.8218069076538086
Validation loss: 2.128974847896125

Epoch: 6| Step: 9
Training loss: 1.4388391971588135
Validation loss: 2.114772037793231

Epoch: 6| Step: 10
Training loss: 2.723972797393799
Validation loss: 2.1123053514829246

Epoch: 6| Step: 11
Training loss: 2.5366525650024414
Validation loss: 2.0884929703127955

Epoch: 6| Step: 12
Training loss: 1.9759129285812378
Validation loss: 2.1024122494523243

Epoch: 6| Step: 13
Training loss: 1.244092345237732
Validation loss: 2.1749898002993677

Epoch: 193| Step: 0
Training loss: 2.7905261516571045
Validation loss: 2.1562473812410907

Epoch: 6| Step: 1
Training loss: 2.5597541332244873
Validation loss: 2.0844194965977825

Epoch: 6| Step: 2
Training loss: 1.8286556005477905
Validation loss: 2.112253596705775

Epoch: 6| Step: 3
Training loss: 1.9420324563980103
Validation loss: 2.1711121707834224

Epoch: 6| Step: 4
Training loss: 1.8218203783035278
Validation loss: 2.0578072660712787

Epoch: 6| Step: 5
Training loss: 2.0544962882995605
Validation loss: 2.0838192162975187

Epoch: 6| Step: 6
Training loss: 1.9095385074615479
Validation loss: 2.083478955812352

Epoch: 6| Step: 7
Training loss: 1.8573027849197388
Validation loss: 2.14162032065853

Epoch: 6| Step: 8
Training loss: 1.9195362329483032
Validation loss: 2.1462823883179696

Epoch: 6| Step: 9
Training loss: 2.0965418815612793
Validation loss: 2.0700080907473

Epoch: 6| Step: 10
Training loss: 1.9328572750091553
Validation loss: 2.132555865472363

Epoch: 6| Step: 11
Training loss: 2.4358296394348145
Validation loss: 2.0999761268656743

Epoch: 6| Step: 12
Training loss: 2.477555751800537
Validation loss: 2.073428225773637

Epoch: 6| Step: 13
Training loss: 2.4080605506896973
Validation loss: 2.109051780034137

Epoch: 194| Step: 0
Training loss: 1.7546392679214478
Validation loss: 2.1203328191593127

Epoch: 6| Step: 1
Training loss: 2.0703883171081543
Validation loss: 2.0984997595510175

Epoch: 6| Step: 2
Training loss: 2.0515291690826416
Validation loss: 2.0822404097485285

Epoch: 6| Step: 3
Training loss: 2.575211763381958
Validation loss: 2.1404499853810957

Epoch: 6| Step: 4
Training loss: 2.040191650390625
Validation loss: 2.1095093680966284

Epoch: 6| Step: 5
Training loss: 1.9027644395828247
Validation loss: 2.1335340558841662

Epoch: 6| Step: 6
Training loss: 3.044215679168701
Validation loss: 2.1314409138053976

Epoch: 6| Step: 7
Training loss: 1.6999582052230835
Validation loss: 2.1355191200010237

Epoch: 6| Step: 8
Training loss: 2.297727108001709
Validation loss: 2.1446869616867392

Epoch: 6| Step: 9
Training loss: 2.5674610137939453
Validation loss: 2.1330221904221403

Epoch: 6| Step: 10
Training loss: 2.289625644683838
Validation loss: 2.123780979905077

Epoch: 6| Step: 11
Training loss: 2.648740768432617
Validation loss: 2.107303406602593

Epoch: 6| Step: 12
Training loss: 2.311143159866333
Validation loss: 2.145316844345421

Epoch: 6| Step: 13
Training loss: 0.8572903275489807
Validation loss: 2.123919387017527

Epoch: 195| Step: 0
Training loss: 2.198329448699951
Validation loss: 2.1011463929248113

Epoch: 6| Step: 1
Training loss: 3.0260071754455566
Validation loss: 2.0707767394281205

Epoch: 6| Step: 2
Training loss: 1.705622673034668
Validation loss: 2.11315317051385

Epoch: 6| Step: 3
Training loss: 1.7559220790863037
Validation loss: 2.161958271457303

Epoch: 6| Step: 4
Training loss: 1.8486988544464111
Validation loss: 2.071895637819844

Epoch: 6| Step: 5
Training loss: 2.1288704872131348
Validation loss: 2.063346310328412

Epoch: 6| Step: 6
Training loss: 2.0177810192108154
Validation loss: 2.078133195959112

Epoch: 6| Step: 7
Training loss: 1.967369794845581
Validation loss: 2.0972830210962603

Epoch: 6| Step: 8
Training loss: 1.7130930423736572
Validation loss: 2.073380534366895

Epoch: 6| Step: 9
Training loss: 1.7066878080368042
Validation loss: 2.1001025143490044

Epoch: 6| Step: 10
Training loss: 2.953272819519043
Validation loss: 2.0863197324096516

Epoch: 6| Step: 11
Training loss: 2.319570302963257
Validation loss: 2.048744076041765

Epoch: 6| Step: 12
Training loss: 2.186234712600708
Validation loss: 2.103957253117715

Epoch: 6| Step: 13
Training loss: 2.9267232418060303
Validation loss: 2.090529118814776

Epoch: 196| Step: 0
Training loss: 1.9289051294326782
Validation loss: 2.113030428527504

Epoch: 6| Step: 1
Training loss: 1.9300787448883057
Validation loss: 2.126126693141076

Epoch: 6| Step: 2
Training loss: 2.1812548637390137
Validation loss: 2.0989346504211426

Epoch: 6| Step: 3
Training loss: 1.8789476156234741
Validation loss: 2.1127521094455513

Epoch: 6| Step: 4
Training loss: 2.017097234725952
Validation loss: 2.1164424342493855

Epoch: 6| Step: 5
Training loss: 1.866853952407837
Validation loss: 2.10646330412998

Epoch: 6| Step: 6
Training loss: 2.2466323375701904
Validation loss: 2.1310629998483965

Epoch: 6| Step: 7
Training loss: 1.976192831993103
Validation loss: 2.1130708648312475

Epoch: 6| Step: 8
Training loss: 2.4331514835357666
Validation loss: 2.080607952610139

Epoch: 6| Step: 9
Training loss: 2.307040214538574
Validation loss: 2.09333400828864

Epoch: 6| Step: 10
Training loss: 1.8610961437225342
Validation loss: 2.057701749186362

Epoch: 6| Step: 11
Training loss: 2.424849271774292
Validation loss: 2.0972498052863666

Epoch: 6| Step: 12
Training loss: 2.5710196495056152
Validation loss: 2.136540306511746

Epoch: 6| Step: 13
Training loss: 2.2722129821777344
Validation loss: 2.111897322439378

Epoch: 197| Step: 0
Training loss: 2.5109944343566895
Validation loss: 2.104434765795226

Epoch: 6| Step: 1
Training loss: 2.184565305709839
Validation loss: 2.102885771823186

Epoch: 6| Step: 2
Training loss: 1.3562595844268799
Validation loss: 2.096447874140996

Epoch: 6| Step: 3
Training loss: 1.6441890001296997
Validation loss: 2.131700269637569

Epoch: 6| Step: 4
Training loss: 2.8809194564819336
Validation loss: 2.049410181660806

Epoch: 6| Step: 5
Training loss: 2.28378963470459
Validation loss: 2.1024787105539793

Epoch: 6| Step: 6
Training loss: 2.225576162338257
Validation loss: 2.1432716564465593

Epoch: 6| Step: 7
Training loss: 1.9427211284637451
Validation loss: 2.1392566824472077

Epoch: 6| Step: 8
Training loss: 2.29129695892334
Validation loss: 2.128995974858602

Epoch: 6| Step: 9
Training loss: 2.2761964797973633
Validation loss: 2.1430842645706667

Epoch: 6| Step: 10
Training loss: 2.068211555480957
Validation loss: 2.0965704071906304

Epoch: 6| Step: 11
Training loss: 1.805518388748169
Validation loss: 2.0870246054023824

Epoch: 6| Step: 12
Training loss: 2.4415786266326904
Validation loss: 2.10841017641047

Epoch: 6| Step: 13
Training loss: 3.234309196472168
Validation loss: 2.108532597941737

Epoch: 198| Step: 0
Training loss: 1.9991939067840576
Validation loss: 2.0564470650047384

Epoch: 6| Step: 1
Training loss: 2.5914125442504883
Validation loss: 2.062869897452734

Epoch: 6| Step: 2
Training loss: 2.982398509979248
Validation loss: 2.179903289323212

Epoch: 6| Step: 3
Training loss: 1.9550189971923828
Validation loss: 2.0913147798148533

Epoch: 6| Step: 4
Training loss: 2.0155320167541504
Validation loss: 2.129363365070794

Epoch: 6| Step: 5
Training loss: 2.0988245010375977
Validation loss: 2.1560152769088745

Epoch: 6| Step: 6
Training loss: 1.908544898033142
Validation loss: 2.1259563674208937

Epoch: 6| Step: 7
Training loss: 2.322665214538574
Validation loss: 2.113384269898938

Epoch: 6| Step: 8
Training loss: 1.9154014587402344
Validation loss: 2.027966240400909

Epoch: 6| Step: 9
Training loss: 2.155465841293335
Validation loss: 2.0045409446121543

Epoch: 6| Step: 10
Training loss: 1.9567971229553223
Validation loss: 2.1023059660388577

Epoch: 6| Step: 11
Training loss: 1.8720040321350098
Validation loss: 2.054164295555443

Epoch: 6| Step: 12
Training loss: 2.340578079223633
Validation loss: 2.0747576554616294

Epoch: 6| Step: 13
Training loss: 2.4125888347625732
Validation loss: 2.1084757312651603

Epoch: 199| Step: 0
Training loss: 1.613945484161377
Validation loss: 2.0569343707894765

Epoch: 6| Step: 1
Training loss: 2.1867318153381348
Validation loss: 2.0941754412907425

Epoch: 6| Step: 2
Training loss: 1.8842437267303467
Validation loss: 2.1371699981792

Epoch: 6| Step: 3
Training loss: 1.9198282957077026
Validation loss: 2.1098997708289855

Epoch: 6| Step: 4
Training loss: 2.14888334274292
Validation loss: 2.070677141989431

Epoch: 6| Step: 5
Training loss: 1.757140874862671
Validation loss: 2.081093301055252

Epoch: 6| Step: 6
Training loss: 2.289827346801758
Validation loss: 2.0762814988372145

Epoch: 6| Step: 7
Training loss: 2.1643943786621094
Validation loss: 2.0871777662666897

Epoch: 6| Step: 8
Training loss: 2.427290916442871
Validation loss: 2.0274722089049635

Epoch: 6| Step: 9
Training loss: 1.9135386943817139
Validation loss: 2.085342066262358

Epoch: 6| Step: 10
Training loss: 2.5902762413024902
Validation loss: 2.0973265017232587

Epoch: 6| Step: 11
Training loss: 1.8826141357421875
Validation loss: 2.134670760041924

Epoch: 6| Step: 12
Training loss: 3.12817645072937
Validation loss: 2.157265781074442

Epoch: 6| Step: 13
Training loss: 2.571035623550415
Validation loss: 2.1036130766714773

Epoch: 200| Step: 0
Training loss: 2.2425670623779297
Validation loss: 2.0676958368670557

Epoch: 6| Step: 1
Training loss: 2.1337642669677734
Validation loss: 2.0328025253870154

Epoch: 6| Step: 2
Training loss: 1.847844123840332
Validation loss: 2.0880604021010862

Epoch: 6| Step: 3
Training loss: 1.6550630331039429
Validation loss: 2.040520368083831

Epoch: 6| Step: 4
Training loss: 2.905165672302246
Validation loss: 2.112446661918394

Epoch: 6| Step: 5
Training loss: 2.7056987285614014
Validation loss: 2.157958335773919

Epoch: 6| Step: 6
Training loss: 1.9550418853759766
Validation loss: 2.0942387042507047

Epoch: 6| Step: 7
Training loss: 1.7825968265533447
Validation loss: 2.1340198337390857

Epoch: 6| Step: 8
Training loss: 2.557309150695801
Validation loss: 2.1772025605683685

Epoch: 6| Step: 9
Training loss: 1.9120464324951172
Validation loss: 2.049285884826414

Epoch: 6| Step: 10
Training loss: 2.106135368347168
Validation loss: 2.0612103733965146

Epoch: 6| Step: 11
Training loss: 1.889003038406372
Validation loss: 2.153710875459897

Epoch: 6| Step: 12
Training loss: 2.2983345985412598
Validation loss: 2.170812588866039

Epoch: 6| Step: 13
Training loss: 1.9324103593826294
Validation loss: 2.2059290178360476

Epoch: 201| Step: 0
Training loss: 1.8138854503631592
Validation loss: 2.141035085083336

Epoch: 6| Step: 1
Training loss: 2.5129899978637695
Validation loss: 2.132032299554476

Epoch: 6| Step: 2
Training loss: 2.61083984375
Validation loss: 2.124127085490893

Epoch: 6| Step: 3
Training loss: 2.2529854774475098
Validation loss: 2.147943486449539

Epoch: 6| Step: 4
Training loss: 1.1799674034118652
Validation loss: 2.157325224209857

Epoch: 6| Step: 5
Training loss: 2.1878035068511963
Validation loss: 2.1178131744425785

Epoch: 6| Step: 6
Training loss: 1.6215336322784424
Validation loss: 2.130906661351522

Epoch: 6| Step: 7
Training loss: 1.5098832845687866
Validation loss: 2.1022767584810973

Epoch: 6| Step: 8
Training loss: 2.9301352500915527
Validation loss: 2.106899301211039

Epoch: 6| Step: 9
Training loss: 2.580615997314453
Validation loss: 2.1291562703347977

Epoch: 6| Step: 10
Training loss: 1.793616533279419
Validation loss: 2.116506732920165

Epoch: 6| Step: 11
Training loss: 2.4442121982574463
Validation loss: 2.1434381533694524

Epoch: 6| Step: 12
Training loss: 2.908101797103882
Validation loss: 2.096384730390323

Epoch: 6| Step: 13
Training loss: 2.025153636932373
Validation loss: 2.1011802201629965

Epoch: 202| Step: 0
Training loss: 1.9154380559921265
Validation loss: 2.096022029076853

Epoch: 6| Step: 1
Training loss: 2.6284961700439453
Validation loss: 2.085233152553599

Epoch: 6| Step: 2
Training loss: 2.6465845108032227
Validation loss: 2.084550106397239

Epoch: 6| Step: 3
Training loss: 1.8223057985305786
Validation loss: 2.155118839715117

Epoch: 6| Step: 4
Training loss: 2.0385935306549072
Validation loss: 2.184068847728032

Epoch: 6| Step: 5
Training loss: 2.2467308044433594
Validation loss: 2.1083202926061486

Epoch: 6| Step: 6
Training loss: 1.7232239246368408
Validation loss: 2.066497923225485

Epoch: 6| Step: 7
Training loss: 2.051891803741455
Validation loss: 2.1174792243588354

Epoch: 6| Step: 8
Training loss: 2.859724521636963
Validation loss: 2.0544643273917575

Epoch: 6| Step: 9
Training loss: 2.9843504428863525
Validation loss: 2.144925514856974

Epoch: 6| Step: 10
Training loss: 1.5741746425628662
Validation loss: 2.0833965475841234

Epoch: 6| Step: 11
Training loss: 1.978922724723816
Validation loss: 2.1742319932547947

Epoch: 6| Step: 12
Training loss: 1.4837348461151123
Validation loss: 2.175942333795691

Epoch: 6| Step: 13
Training loss: 2.386420965194702
Validation loss: 2.072506081673407

Epoch: 203| Step: 0
Training loss: 1.7952392101287842
Validation loss: 2.0551366370211364

Epoch: 6| Step: 1
Training loss: 2.128218650817871
Validation loss: 2.134065828015727

Epoch: 6| Step: 2
Training loss: 2.6726746559143066
Validation loss: 2.155392751898817

Epoch: 6| Step: 3
Training loss: 2.060049057006836
Validation loss: 2.135986779325752

Epoch: 6| Step: 4
Training loss: 1.6986050605773926
Validation loss: 2.0988803345669984

Epoch: 6| Step: 5
Training loss: 2.115307092666626
Validation loss: 2.0599150837108655

Epoch: 6| Step: 6
Training loss: 1.9153558015823364
Validation loss: 2.149734717543407

Epoch: 6| Step: 7
Training loss: 1.7882553339004517
Validation loss: 2.1103534480576873

Epoch: 6| Step: 8
Training loss: 2.1938490867614746
Validation loss: 2.1376102329582296

Epoch: 6| Step: 9
Training loss: 2.7019941806793213
Validation loss: 2.101505184686312

Epoch: 6| Step: 10
Training loss: 2.798245429992676
Validation loss: 2.182943033915694

Epoch: 6| Step: 11
Training loss: 2.1920337677001953
Validation loss: 2.106826559189827

Epoch: 6| Step: 12
Training loss: 2.1195874214172363
Validation loss: 2.1089596491987987

Epoch: 6| Step: 13
Training loss: 2.0402204990386963
Validation loss: 2.11908907018682

Epoch: 204| Step: 0
Training loss: 2.427321434020996
Validation loss: 2.08456091983344

Epoch: 6| Step: 1
Training loss: 2.3964409828186035
Validation loss: 2.1171772505647395

Epoch: 6| Step: 2
Training loss: 1.8824084997177124
Validation loss: 2.1488910823739986

Epoch: 6| Step: 3
Training loss: 2.104602813720703
Validation loss: 2.124384744192964

Epoch: 6| Step: 4
Training loss: 1.9676108360290527
Validation loss: 2.069411758453615

Epoch: 6| Step: 5
Training loss: 1.908248782157898
Validation loss: 2.080437972981443

Epoch: 6| Step: 6
Training loss: 2.275588035583496
Validation loss: 2.0705325782939954

Epoch: 6| Step: 7
Training loss: 2.3583245277404785
Validation loss: 2.0916019972934516

Epoch: 6| Step: 8
Training loss: 2.1630640029907227
Validation loss: 2.1122216563070975

Epoch: 6| Step: 9
Training loss: 2.687748908996582
Validation loss: 2.1378936844487346

Epoch: 6| Step: 10
Training loss: 2.2827954292297363
Validation loss: 2.093009615457186

Epoch: 6| Step: 11
Training loss: 1.510901689529419
Validation loss: 2.1859345923187914

Epoch: 6| Step: 12
Training loss: 2.177816390991211
Validation loss: 2.0873875617980957

Epoch: 6| Step: 13
Training loss: 1.759326457977295
Validation loss: 2.0912435490597963

Epoch: 205| Step: 0
Training loss: 2.6736178398132324
Validation loss: 2.0632147353182555

Epoch: 6| Step: 1
Training loss: 1.87632417678833
Validation loss: 2.0837536934883363

Epoch: 6| Step: 2
Training loss: 1.8119524717330933
Validation loss: 2.0568705835650043

Epoch: 6| Step: 3
Training loss: 2.0500082969665527
Validation loss: 2.1305835247039795

Epoch: 6| Step: 4
Training loss: 2.1682395935058594
Validation loss: 2.121752531297745

Epoch: 6| Step: 5
Training loss: 2.1386241912841797
Validation loss: 2.1117119148213375

Epoch: 6| Step: 6
Training loss: 2.61545467376709
Validation loss: 2.1234121348268244

Epoch: 6| Step: 7
Training loss: 2.064256191253662
Validation loss: 2.083904617576189

Epoch: 6| Step: 8
Training loss: 1.7911083698272705
Validation loss: 2.0666162249862507

Epoch: 6| Step: 9
Training loss: 2.5212082862854004
Validation loss: 2.148048693133939

Epoch: 6| Step: 10
Training loss: 2.747561454772949
Validation loss: 2.1204824678359495

Epoch: 6| Step: 11
Training loss: 1.9300663471221924
Validation loss: 2.158240087570683

Epoch: 6| Step: 12
Training loss: 1.438119888305664
Validation loss: 2.1143685143481017

Epoch: 6| Step: 13
Training loss: 2.1104118824005127
Validation loss: 2.081588625907898

Epoch: 206| Step: 0
Training loss: 2.017645835876465
Validation loss: 2.0761618204014276

Epoch: 6| Step: 1
Training loss: 2.33772611618042
Validation loss: 2.131946507320609

Epoch: 6| Step: 2
Training loss: 1.9638254642486572
Validation loss: 2.115465764076479

Epoch: 6| Step: 3
Training loss: 2.371066093444824
Validation loss: 2.109254049998458

Epoch: 6| Step: 4
Training loss: 1.9003533124923706
Validation loss: 2.0235155936210387

Epoch: 6| Step: 5
Training loss: 2.574179172515869
Validation loss: 2.146774266355781

Epoch: 6| Step: 6
Training loss: 1.7747584581375122
Validation loss: 2.133198938062114

Epoch: 6| Step: 7
Training loss: 2.5938472747802734
Validation loss: 2.1492722598455285

Epoch: 6| Step: 8
Training loss: 1.8293455839157104
Validation loss: 2.076301702889063

Epoch: 6| Step: 9
Training loss: 1.085526704788208
Validation loss: 2.168544941051032

Epoch: 6| Step: 10
Training loss: 1.8560764789581299
Validation loss: 2.1644566571840675

Epoch: 6| Step: 11
Training loss: 2.911161422729492
Validation loss: 2.1079695429853214

Epoch: 6| Step: 12
Training loss: 2.3064262866973877
Validation loss: 2.0934366410778416

Epoch: 6| Step: 13
Training loss: 2.441577196121216
Validation loss: 2.0739886183892526

Epoch: 207| Step: 0
Training loss: 2.0202395915985107
Validation loss: 2.0853900832514607

Epoch: 6| Step: 1
Training loss: 1.9856815338134766
Validation loss: 2.119772198379681

Epoch: 6| Step: 2
Training loss: 2.4184558391571045
Validation loss: 2.156276443953155

Epoch: 6| Step: 3
Training loss: 1.5919253826141357
Validation loss: 2.15702235826882

Epoch: 6| Step: 4
Training loss: 2.272376537322998
Validation loss: 2.110195562403689

Epoch: 6| Step: 5
Training loss: 2.0309863090515137
Validation loss: 2.079429545710164

Epoch: 6| Step: 6
Training loss: 2.4016551971435547
Validation loss: 2.082452720211398

Epoch: 6| Step: 7
Training loss: 3.3211073875427246
Validation loss: 2.047688635446692

Epoch: 6| Step: 8
Training loss: 1.1410815715789795
Validation loss: 2.0999434891567437

Epoch: 6| Step: 9
Training loss: 2.5234241485595703
Validation loss: 2.082073030933257

Epoch: 6| Step: 10
Training loss: 2.497255802154541
Validation loss: 2.077126318408597

Epoch: 6| Step: 11
Training loss: 1.6016291379928589
Validation loss: 2.0756285549491964

Epoch: 6| Step: 12
Training loss: 2.1712160110473633
Validation loss: 2.1441617524752052

Epoch: 6| Step: 13
Training loss: 2.236279010772705
Validation loss: 2.065638074310877

Epoch: 208| Step: 0
Training loss: 1.4876084327697754
Validation loss: 2.0556061319125596

Epoch: 6| Step: 1
Training loss: 2.5904712677001953
Validation loss: 2.099275927389822

Epoch: 6| Step: 2
Training loss: 1.7334344387054443
Validation loss: 2.0805986235218663

Epoch: 6| Step: 3
Training loss: 2.6376051902770996
Validation loss: 2.098099452193065

Epoch: 6| Step: 4
Training loss: 1.9744867086410522
Validation loss: 2.08921520556173

Epoch: 6| Step: 5
Training loss: 1.6185606718063354
Validation loss: 2.120925902038492

Epoch: 6| Step: 6
Training loss: 2.00541353225708
Validation loss: 2.1128486382064

Epoch: 6| Step: 7
Training loss: 1.664391279220581
Validation loss: 2.066056889872397

Epoch: 6| Step: 8
Training loss: 1.8431944847106934
Validation loss: 2.045068948499618

Epoch: 6| Step: 9
Training loss: 2.428553819656372
Validation loss: 2.105491558710734

Epoch: 6| Step: 10
Training loss: 1.8075165748596191
Validation loss: 2.0701012393479705

Epoch: 6| Step: 11
Training loss: 2.9589943885803223
Validation loss: 2.0978833808693835

Epoch: 6| Step: 12
Training loss: 2.714995861053467
Validation loss: 2.1080185162123812

Epoch: 6| Step: 13
Training loss: 2.01572322845459
Validation loss: 2.150348581293578

Epoch: 209| Step: 0
Training loss: 2.332915782928467
Validation loss: 2.0950117341933714

Epoch: 6| Step: 1
Training loss: 1.8631118535995483
Validation loss: 2.1040112100621706

Epoch: 6| Step: 2
Training loss: 2.7577083110809326
Validation loss: 2.179172367177984

Epoch: 6| Step: 3
Training loss: 2.4265787601470947
Validation loss: 2.131197783254808

Epoch: 6| Step: 4
Training loss: 1.8701157569885254
Validation loss: 2.1616747892031105

Epoch: 6| Step: 5
Training loss: 1.4996957778930664
Validation loss: 2.082346139415618

Epoch: 6| Step: 6
Training loss: 1.9590814113616943
Validation loss: 2.1250795625871226

Epoch: 6| Step: 7
Training loss: 2.9832756519317627
Validation loss: 2.0831396592560636

Epoch: 6| Step: 8
Training loss: 1.9277424812316895
Validation loss: 2.107830488553611

Epoch: 6| Step: 9
Training loss: 2.296680450439453
Validation loss: 2.133529568231234

Epoch: 6| Step: 10
Training loss: 1.8548357486724854
Validation loss: 2.1572990750753753

Epoch: 6| Step: 11
Training loss: 2.7990646362304688
Validation loss: 2.135221735123665

Epoch: 6| Step: 12
Training loss: 1.5984303951263428
Validation loss: 2.132325404433794

Epoch: 6| Step: 13
Training loss: 2.028815507888794
Validation loss: 2.1135010078389156

Epoch: 210| Step: 0
Training loss: 2.654726028442383
Validation loss: 2.1510385351796306

Epoch: 6| Step: 1
Training loss: 2.0429952144622803
Validation loss: 2.1218421638652845

Epoch: 6| Step: 2
Training loss: 2.177668571472168
Validation loss: 2.1705457882214616

Epoch: 6| Step: 3
Training loss: 1.6848052740097046
Validation loss: 2.1170529832122145

Epoch: 6| Step: 4
Training loss: 2.1176676750183105
Validation loss: 2.1376439089416177

Epoch: 6| Step: 5
Training loss: 1.923328161239624
Validation loss: 2.1595757520327004

Epoch: 6| Step: 6
Training loss: 1.30206298828125
Validation loss: 2.076699197933238

Epoch: 6| Step: 7
Training loss: 2.27154278755188
Validation loss: 2.120848125027072

Epoch: 6| Step: 8
Training loss: 2.211864948272705
Validation loss: 2.0971880882017073

Epoch: 6| Step: 9
Training loss: 2.4645004272460938
Validation loss: 2.172996526123375

Epoch: 6| Step: 10
Training loss: 2.4375927448272705
Validation loss: 2.0756563858319352

Epoch: 6| Step: 11
Training loss: 1.6553316116333008
Validation loss: 2.1318260879926783

Epoch: 6| Step: 12
Training loss: 2.6094558238983154
Validation loss: 2.1574547752257316

Epoch: 6| Step: 13
Training loss: 2.229871988296509
Validation loss: 2.1568350920113186

Epoch: 211| Step: 0
Training loss: 2.5361337661743164
Validation loss: 2.1277286852559736

Epoch: 6| Step: 1
Training loss: 2.171245574951172
Validation loss: 2.1594852247545795

Epoch: 6| Step: 2
Training loss: 2.2696850299835205
Validation loss: 2.095780582838161

Epoch: 6| Step: 3
Training loss: 1.5599586963653564
Validation loss: 2.0926752257090744

Epoch: 6| Step: 4
Training loss: 1.52874755859375
Validation loss: 2.056959239385461

Epoch: 6| Step: 5
Training loss: 1.6960153579711914
Validation loss: 2.160184537210772

Epoch: 6| Step: 6
Training loss: 2.484468460083008
Validation loss: 2.132282482680454

Epoch: 6| Step: 7
Training loss: 2.065082550048828
Validation loss: 2.167175394232555

Epoch: 6| Step: 8
Training loss: 2.288343667984009
Validation loss: 2.11198486820344

Epoch: 6| Step: 9
Training loss: 1.6741224527359009
Validation loss: 2.1474490345165296

Epoch: 6| Step: 10
Training loss: 2.557224750518799
Validation loss: 2.102672597413422

Epoch: 6| Step: 11
Training loss: 2.3107194900512695
Validation loss: 2.078159183584234

Epoch: 6| Step: 12
Training loss: 2.197680950164795
Validation loss: 2.1129417111796718

Epoch: 6| Step: 13
Training loss: 2.2046754360198975
Validation loss: 2.1537258727576143

Epoch: 212| Step: 0
Training loss: 2.58670711517334
Validation loss: 2.1367698254123813

Epoch: 6| Step: 1
Training loss: 1.8310036659240723
Validation loss: 2.117975140130648

Epoch: 6| Step: 2
Training loss: 2.3487472534179688
Validation loss: 2.191397393903425

Epoch: 6| Step: 3
Training loss: 1.895583152770996
Validation loss: 2.118894379626038

Epoch: 6| Step: 4
Training loss: 1.9985365867614746
Validation loss: 2.1039511798530497

Epoch: 6| Step: 5
Training loss: 1.8566381931304932
Validation loss: 2.16603765180034

Epoch: 6| Step: 6
Training loss: 2.438673257827759
Validation loss: 2.161134550648351

Epoch: 6| Step: 7
Training loss: 3.184366226196289
Validation loss: 2.0749062415092223

Epoch: 6| Step: 8
Training loss: 1.748206615447998
Validation loss: 2.0871818168188936

Epoch: 6| Step: 9
Training loss: 2.3338661193847656
Validation loss: 2.0962828359296246

Epoch: 6| Step: 10
Training loss: 2.486170530319214
Validation loss: 2.1927487363097486

Epoch: 6| Step: 11
Training loss: 2.0811667442321777
Validation loss: 2.1579415593096005

Epoch: 6| Step: 12
Training loss: 1.3968708515167236
Validation loss: 2.083128503573838

Epoch: 6| Step: 13
Training loss: 1.6020925045013428
Validation loss: 2.075338173938054

Epoch: 213| Step: 0
Training loss: 2.455878257751465
Validation loss: 2.1894145601539203

Epoch: 6| Step: 1
Training loss: 2.41279673576355
Validation loss: 2.1159546272729033

Epoch: 6| Step: 2
Training loss: 2.378936767578125
Validation loss: 2.0947350519959644

Epoch: 6| Step: 3
Training loss: 2.4042465686798096
Validation loss: 2.069945971171061

Epoch: 6| Step: 4
Training loss: 1.4050321578979492
Validation loss: 2.157428462018249

Epoch: 6| Step: 5
Training loss: 1.3919743299484253
Validation loss: 2.1654914899538924

Epoch: 6| Step: 6
Training loss: 1.8987997770309448
Validation loss: 2.192959000987391

Epoch: 6| Step: 7
Training loss: 2.264326810836792
Validation loss: 2.1518649029475387

Epoch: 6| Step: 8
Training loss: 2.5174715518951416
Validation loss: 2.102769782466273

Epoch: 6| Step: 9
Training loss: 1.8102357387542725
Validation loss: 2.0942544360314646

Epoch: 6| Step: 10
Training loss: 2.33656907081604
Validation loss: 2.1622549795335337

Epoch: 6| Step: 11
Training loss: 2.397067070007324
Validation loss: 2.1475789393148115

Epoch: 6| Step: 12
Training loss: 1.9749464988708496
Validation loss: 2.0938540761188795

Epoch: 6| Step: 13
Training loss: 1.7029656171798706
Validation loss: 2.0934534303603636

Epoch: 214| Step: 0
Training loss: 1.7161203622817993
Validation loss: 2.1007941333196496

Epoch: 6| Step: 1
Training loss: 2.0218446254730225
Validation loss: 2.1017281355396396

Epoch: 6| Step: 2
Training loss: 2.269840955734253
Validation loss: 2.1314198329884517

Epoch: 6| Step: 3
Training loss: 2.173710346221924
Validation loss: 2.139836376713168

Epoch: 6| Step: 4
Training loss: 2.1073708534240723
Validation loss: 2.1194804253116732

Epoch: 6| Step: 5
Training loss: 2.344153881072998
Validation loss: 2.1201656262079873

Epoch: 6| Step: 6
Training loss: 3.485797643661499
Validation loss: 2.084218030334801

Epoch: 6| Step: 7
Training loss: 1.5492174625396729
Validation loss: 2.1394366756562264

Epoch: 6| Step: 8
Training loss: 1.7772185802459717
Validation loss: 2.1036477576019945

Epoch: 6| Step: 9
Training loss: 2.274660587310791
Validation loss: 2.1206305116735478

Epoch: 6| Step: 10
Training loss: 2.4790422916412354
Validation loss: 2.0965530539071686

Epoch: 6| Step: 11
Training loss: 2.1816797256469727
Validation loss: 2.1477940069731845

Epoch: 6| Step: 12
Training loss: 1.3574155569076538
Validation loss: 2.122044840166646

Epoch: 6| Step: 13
Training loss: 1.5294324159622192
Validation loss: 2.0947861440720095

Epoch: 215| Step: 0
Training loss: 2.0109071731567383
Validation loss: 2.1425644787408973

Epoch: 6| Step: 1
Training loss: 2.4455466270446777
Validation loss: 2.1284408197608045

Epoch: 6| Step: 2
Training loss: 2.201066017150879
Validation loss: 2.110614304901451

Epoch: 6| Step: 3
Training loss: 2.0896573066711426
Validation loss: 2.1117812125913558

Epoch: 6| Step: 4
Training loss: 1.9282957315444946
Validation loss: 2.111649659372145

Epoch: 6| Step: 5
Training loss: 2.8560879230499268
Validation loss: 2.1352691483753983

Epoch: 6| Step: 6
Training loss: 2.116044044494629
Validation loss: 2.170134962245982

Epoch: 6| Step: 7
Training loss: 2.9139866828918457
Validation loss: 2.1699048037170083

Epoch: 6| Step: 8
Training loss: 2.1179697513580322
Validation loss: 2.1637127617354035

Epoch: 6| Step: 9
Training loss: 1.4297751188278198
Validation loss: 2.15510868641638

Epoch: 6| Step: 10
Training loss: 2.105862617492676
Validation loss: 2.1238028657051826

Epoch: 6| Step: 11
Training loss: 1.7271835803985596
Validation loss: 2.1094465537737777

Epoch: 6| Step: 12
Training loss: 2.1711783409118652
Validation loss: 2.117357461683212

Epoch: 6| Step: 13
Training loss: 1.6745747327804565
Validation loss: 2.1515953028073875

Epoch: 216| Step: 0
Training loss: 2.5648069381713867
Validation loss: 2.1357964469540502

Epoch: 6| Step: 1
Training loss: 2.662235975265503
Validation loss: 2.1187718863128335

Epoch: 6| Step: 2
Training loss: 2.298571825027466
Validation loss: 2.1108536617730254

Epoch: 6| Step: 3
Training loss: 1.746298909187317
Validation loss: 2.142932491917764

Epoch: 6| Step: 4
Training loss: 1.7521681785583496
Validation loss: 2.095497046747515

Epoch: 6| Step: 5
Training loss: 2.3153135776519775
Validation loss: 2.1647589360513995

Epoch: 6| Step: 6
Training loss: 2.0815987586975098
Validation loss: 2.1758854389190674

Epoch: 6| Step: 7
Training loss: 2.52653169631958
Validation loss: 2.1754621023772867

Epoch: 6| Step: 8
Training loss: 2.1239821910858154
Validation loss: 2.0540750206157727

Epoch: 6| Step: 9
Training loss: 2.2109055519104004
Validation loss: 2.1258363800664104

Epoch: 6| Step: 10
Training loss: 2.1204984188079834
Validation loss: 2.0701252670698267

Epoch: 6| Step: 11
Training loss: 1.8063074350357056
Validation loss: 2.1337372641409598

Epoch: 6| Step: 12
Training loss: 1.8280036449432373
Validation loss: 2.1511562050029798

Epoch: 6| Step: 13
Training loss: 1.2485713958740234
Validation loss: 2.155611994445965

Epoch: 217| Step: 0
Training loss: 1.3235163688659668
Validation loss: 2.1285673918262606

Epoch: 6| Step: 1
Training loss: 2.5303902626037598
Validation loss: 2.1432896006491875

Epoch: 6| Step: 2
Training loss: 2.562483310699463
Validation loss: 2.0966478573378695

Epoch: 6| Step: 3
Training loss: 2.7486817836761475
Validation loss: 2.122032747473768

Epoch: 6| Step: 4
Training loss: 2.1139588356018066
Validation loss: 2.151319565311555

Epoch: 6| Step: 5
Training loss: 2.5116615295410156
Validation loss: 2.1703732064975205

Epoch: 6| Step: 6
Training loss: 1.6857035160064697
Validation loss: 2.041414637719431

Epoch: 6| Step: 7
Training loss: 2.188847541809082
Validation loss: 2.1222514862655313

Epoch: 6| Step: 8
Training loss: 1.918729543685913
Validation loss: 2.099619521889635

Epoch: 6| Step: 9
Training loss: 2.1030006408691406
Validation loss: 2.110326172203146

Epoch: 6| Step: 10
Training loss: 1.1989959478378296
Validation loss: 2.098941872196813

Epoch: 6| Step: 11
Training loss: 1.7604568004608154
Validation loss: 2.0754066462157876

Epoch: 6| Step: 12
Training loss: 2.368671417236328
Validation loss: 2.1225817036885086

Epoch: 6| Step: 13
Training loss: 2.695403814315796
Validation loss: 2.0881433204938005

Epoch: 218| Step: 0
Training loss: 1.632866621017456
Validation loss: 2.16459330051176

Epoch: 6| Step: 1
Training loss: 1.9474679231643677
Validation loss: 2.0924925573410524

Epoch: 6| Step: 2
Training loss: 2.0117766857147217
Validation loss: 2.134547023363011

Epoch: 6| Step: 3
Training loss: 2.5255274772644043
Validation loss: 2.1113504722554195

Epoch: 6| Step: 4
Training loss: 2.2468008995056152
Validation loss: 2.135857730783442

Epoch: 6| Step: 5
Training loss: 2.0931572914123535
Validation loss: 2.1101020715569936

Epoch: 6| Step: 6
Training loss: 2.152941942214966
Validation loss: 2.0994698757766397

Epoch: 6| Step: 7
Training loss: 2.3188281059265137
Validation loss: 2.07385754072538

Epoch: 6| Step: 8
Training loss: 1.9147437810897827
Validation loss: 2.1047829479299565

Epoch: 6| Step: 9
Training loss: 2.775761604309082
Validation loss: 2.1382211946672007

Epoch: 6| Step: 10
Training loss: 2.022150993347168
Validation loss: 2.147136736941594

Epoch: 6| Step: 11
Training loss: 1.669329285621643
Validation loss: 2.077038441934893

Epoch: 6| Step: 12
Training loss: 1.5701704025268555
Validation loss: 2.112678767532431

Epoch: 6| Step: 13
Training loss: 3.401801109313965
Validation loss: 2.1374147938143824

Epoch: 219| Step: 0
Training loss: 2.117839813232422
Validation loss: 2.1327112464494604

Epoch: 6| Step: 1
Training loss: 2.0577824115753174
Validation loss: 2.1993948516025337

Epoch: 6| Step: 2
Training loss: 2.458700180053711
Validation loss: 2.1354806538551085

Epoch: 6| Step: 3
Training loss: 2.1367862224578857
Validation loss: 2.121495803197225

Epoch: 6| Step: 4
Training loss: 1.6391732692718506
Validation loss: 2.116557659641389

Epoch: 6| Step: 5
Training loss: 2.0112953186035156
Validation loss: 2.112791484402072

Epoch: 6| Step: 6
Training loss: 2.1157784461975098
Validation loss: 2.1667458908532256

Epoch: 6| Step: 7
Training loss: 2.5965828895568848
Validation loss: 2.14809347480856

Epoch: 6| Step: 8
Training loss: 2.225238084793091
Validation loss: 2.0993444458130868

Epoch: 6| Step: 9
Training loss: 2.3124804496765137
Validation loss: 2.136340007987074

Epoch: 6| Step: 10
Training loss: 1.561846137046814
Validation loss: 2.1554449142948275

Epoch: 6| Step: 11
Training loss: 2.2732832431793213
Validation loss: 2.126003126944265

Epoch: 6| Step: 12
Training loss: 2.290597915649414
Validation loss: 2.112680947908791

Epoch: 6| Step: 13
Training loss: 1.8459349870681763
Validation loss: 2.1288231265160347

Epoch: 220| Step: 0
Training loss: 2.3983564376831055
Validation loss: 2.1197001690505655

Epoch: 6| Step: 1
Training loss: 2.4777109622955322
Validation loss: 2.1060932515769877

Epoch: 6| Step: 2
Training loss: 2.0141046047210693
Validation loss: 2.1644839420113513

Epoch: 6| Step: 3
Training loss: 2.5005970001220703
Validation loss: 2.061731981974776

Epoch: 6| Step: 4
Training loss: 1.6358524560928345
Validation loss: 2.1326244338866203

Epoch: 6| Step: 5
Training loss: 1.3531912565231323
Validation loss: 2.124770913072812

Epoch: 6| Step: 6
Training loss: 2.801079750061035
Validation loss: 2.1265207849523073

Epoch: 6| Step: 7
Training loss: 2.1166720390319824
Validation loss: 2.1031706512615247

Epoch: 6| Step: 8
Training loss: 1.2955505847930908
Validation loss: 2.1108882401579168

Epoch: 6| Step: 9
Training loss: 2.4328670501708984
Validation loss: 2.053195209913356

Epoch: 6| Step: 10
Training loss: 1.9174726009368896
Validation loss: 2.1138633604972594

Epoch: 6| Step: 11
Training loss: 2.4936106204986572
Validation loss: 2.1585895553711922

Epoch: 6| Step: 12
Training loss: 1.7867143154144287
Validation loss: 2.102762391490321

Epoch: 6| Step: 13
Training loss: 1.931770920753479
Validation loss: 2.067116250274002

Epoch: 221| Step: 0
Training loss: 2.850827693939209
Validation loss: 2.0986859503612725

Epoch: 6| Step: 1
Training loss: 1.126144528388977
Validation loss: 2.1220912600076325

Epoch: 6| Step: 2
Training loss: 2.0987415313720703
Validation loss: 2.138606620091264

Epoch: 6| Step: 3
Training loss: 1.8087351322174072
Validation loss: 2.1292828667548394

Epoch: 6| Step: 4
Training loss: 2.304750919342041
Validation loss: 2.10713364231971

Epoch: 6| Step: 5
Training loss: 2.1081855297088623
Validation loss: 2.1038274226650113

Epoch: 6| Step: 6
Training loss: 1.5901685953140259
Validation loss: 2.1360894492877427

Epoch: 6| Step: 7
Training loss: 2.3126347064971924
Validation loss: 2.1489346565738803

Epoch: 6| Step: 8
Training loss: 2.10522723197937
Validation loss: 2.1168083221681657

Epoch: 6| Step: 9
Training loss: 2.0461881160736084
Validation loss: 2.1683186254193707

Epoch: 6| Step: 10
Training loss: 2.164989948272705
Validation loss: 2.0846534467512563

Epoch: 6| Step: 11
Training loss: 2.4720358848571777
Validation loss: 2.15266594963689

Epoch: 6| Step: 12
Training loss: 2.2793116569519043
Validation loss: 2.1512049731387886

Epoch: 6| Step: 13
Training loss: 2.1769754886627197
Validation loss: 2.1098489940807386

Epoch: 222| Step: 0
Training loss: 1.868377447128296
Validation loss: 2.1130605641231743

Epoch: 6| Step: 1
Training loss: 2.6945137977600098
Validation loss: 2.1373980340137275

Epoch: 6| Step: 2
Training loss: 2.564600944519043
Validation loss: 2.1501208787323325

Epoch: 6| Step: 3
Training loss: 2.2249972820281982
Validation loss: 2.0757183541533766

Epoch: 6| Step: 4
Training loss: 2.046529769897461
Validation loss: 2.14556025433284

Epoch: 6| Step: 5
Training loss: 2.061180591583252
Validation loss: 2.155493888803708

Epoch: 6| Step: 6
Training loss: 2.163383960723877
Validation loss: 2.1506350501891105

Epoch: 6| Step: 7
Training loss: 2.4259073734283447
Validation loss: 2.068064699890793

Epoch: 6| Step: 8
Training loss: 2.6025638580322266
Validation loss: 2.0882477811587754

Epoch: 6| Step: 9
Training loss: 0.968738317489624
Validation loss: 2.0787954099716677

Epoch: 6| Step: 10
Training loss: 2.198269844055176
Validation loss: 2.106232240635862

Epoch: 6| Step: 11
Training loss: 1.6711044311523438
Validation loss: 2.139586415342105

Epoch: 6| Step: 12
Training loss: 1.192201852798462
Validation loss: 2.1259234848842827

Epoch: 6| Step: 13
Training loss: 2.349048137664795
Validation loss: 2.170031705210286

Epoch: 223| Step: 0
Training loss: 1.919278621673584
Validation loss: 2.0832416883078952

Epoch: 6| Step: 1
Training loss: 2.0461719036102295
Validation loss: 2.1246039662309872

Epoch: 6| Step: 2
Training loss: 3.053637742996216
Validation loss: 2.147035292399827

Epoch: 6| Step: 3
Training loss: 1.5548515319824219
Validation loss: 2.161222661695173

Epoch: 6| Step: 4
Training loss: 2.3838260173797607
Validation loss: 2.125310936281758

Epoch: 6| Step: 5
Training loss: 1.591678261756897
Validation loss: 2.1455250119650238

Epoch: 6| Step: 6
Training loss: 1.914711594581604
Validation loss: 2.089328235195529

Epoch: 6| Step: 7
Training loss: 2.214745044708252
Validation loss: 2.107094213526736

Epoch: 6| Step: 8
Training loss: 1.6746060848236084
Validation loss: 2.1169442694674254

Epoch: 6| Step: 9
Training loss: 2.2492291927337646
Validation loss: 2.1145618410520655

Epoch: 6| Step: 10
Training loss: 2.506704807281494
Validation loss: 2.139111618841848

Epoch: 6| Step: 11
Training loss: 1.7059109210968018
Validation loss: 2.171079143401115

Epoch: 6| Step: 12
Training loss: 2.2389163970947266
Validation loss: 2.1377334210180465

Epoch: 6| Step: 13
Training loss: 2.7245779037475586
Validation loss: 2.139364696318103

Epoch: 224| Step: 0
Training loss: 2.2991535663604736
Validation loss: 2.0797623588192846

Epoch: 6| Step: 1
Training loss: 2.1961426734924316
Validation loss: 2.0815016095356276

Epoch: 6| Step: 2
Training loss: 1.5304529666900635
Validation loss: 2.14417633446314

Epoch: 6| Step: 3
Training loss: 1.7369320392608643
Validation loss: 2.0851953901270384

Epoch: 6| Step: 4
Training loss: 1.942508578300476
Validation loss: 2.0983931351733465

Epoch: 6| Step: 5
Training loss: 2.9910049438476562
Validation loss: 2.0713125172481743

Epoch: 6| Step: 6
Training loss: 2.18109393119812
Validation loss: 2.0950631095517065

Epoch: 6| Step: 7
Training loss: 2.1801602840423584
Validation loss: 2.0677665305393997

Epoch: 6| Step: 8
Training loss: 2.095644235610962
Validation loss: 2.1620279896643853

Epoch: 6| Step: 9
Training loss: 1.8258984088897705
Validation loss: 2.0832514865424043

Epoch: 6| Step: 10
Training loss: 2.018141984939575
Validation loss: 2.0930304963101625

Epoch: 6| Step: 11
Training loss: 3.0260989665985107
Validation loss: 2.0925733145847114

Epoch: 6| Step: 12
Training loss: 1.8672841787338257
Validation loss: 2.1060696237830707

Epoch: 6| Step: 13
Training loss: 1.9291341304779053
Validation loss: 2.0795219124004407

Epoch: 225| Step: 0
Training loss: 2.4656896591186523
Validation loss: 2.0952862539599018

Epoch: 6| Step: 1
Training loss: 2.122649908065796
Validation loss: 2.0767881844633367

Epoch: 6| Step: 2
Training loss: 1.5196659564971924
Validation loss: 2.1299253291981195

Epoch: 6| Step: 3
Training loss: 2.0809807777404785
Validation loss: 2.1572241090959117

Epoch: 6| Step: 4
Training loss: 2.646542549133301
Validation loss: 2.112742370174777

Epoch: 6| Step: 5
Training loss: 1.7521823644638062
Validation loss: 2.1016231301010295

Epoch: 6| Step: 6
Training loss: 1.6740223169326782
Validation loss: 2.1014320235098563

Epoch: 6| Step: 7
Training loss: 1.5960946083068848
Validation loss: 2.1234381955157042

Epoch: 6| Step: 8
Training loss: 2.042496681213379
Validation loss: 2.1573347122438493

Epoch: 6| Step: 9
Training loss: 1.5441855192184448
Validation loss: 2.147269518144669

Epoch: 6| Step: 10
Training loss: 2.3222415447235107
Validation loss: 2.1581175558028685

Epoch: 6| Step: 11
Training loss: 2.5804481506347656
Validation loss: 2.160785816049063

Epoch: 6| Step: 12
Training loss: 2.600874185562134
Validation loss: 2.151168789914859

Epoch: 6| Step: 13
Training loss: 1.9465950727462769
Validation loss: 2.1675354306415846

Epoch: 226| Step: 0
Training loss: 2.965240478515625
Validation loss: 2.1845497482566425

Epoch: 6| Step: 1
Training loss: 1.9813379049301147
Validation loss: 2.1941560135092786

Epoch: 6| Step: 2
Training loss: 1.8046892881393433
Validation loss: 2.203748026201802

Epoch: 6| Step: 3
Training loss: 1.8057916164398193
Validation loss: 2.1712967657273814

Epoch: 6| Step: 4
Training loss: 1.9358922243118286
Validation loss: 2.1331761960060365

Epoch: 6| Step: 5
Training loss: 1.9894087314605713
Validation loss: 2.2111112199803835

Epoch: 6| Step: 6
Training loss: 2.0884580612182617
Validation loss: 2.179702680598023

Epoch: 6| Step: 7
Training loss: 1.4717934131622314
Validation loss: 2.120802597333026

Epoch: 6| Step: 8
Training loss: 1.8890103101730347
Validation loss: 2.1653340990825365

Epoch: 6| Step: 9
Training loss: 2.4591119289398193
Validation loss: 2.111335342930209

Epoch: 6| Step: 10
Training loss: 2.8011956214904785
Validation loss: 2.1372039061720653

Epoch: 6| Step: 11
Training loss: 1.7566978931427002
Validation loss: 2.1299889728587162

Epoch: 6| Step: 12
Training loss: 2.3711678981781006
Validation loss: 2.1497653120307514

Epoch: 6| Step: 13
Training loss: 1.8228211402893066
Validation loss: 2.1552341317617767

Epoch: 227| Step: 0
Training loss: 2.3181419372558594
Validation loss: 2.1739803924355456

Epoch: 6| Step: 1
Training loss: 1.484700322151184
Validation loss: 2.1530698486553725

Epoch: 6| Step: 2
Training loss: 2.8389012813568115
Validation loss: 2.150410585505988

Epoch: 6| Step: 3
Training loss: 2.0594186782836914
Validation loss: 2.1052005675531205

Epoch: 6| Step: 4
Training loss: 1.4326813220977783
Validation loss: 2.1087752003823557

Epoch: 6| Step: 5
Training loss: 2.954322099685669
Validation loss: 2.2064613578140095

Epoch: 6| Step: 6
Training loss: 1.8805168867111206
Validation loss: 2.0900470646478797

Epoch: 6| Step: 7
Training loss: 2.075709819793701
Validation loss: 2.1157639667552006

Epoch: 6| Step: 8
Training loss: 2.4983346462249756
Validation loss: 2.167752863258444

Epoch: 6| Step: 9
Training loss: 1.5481897592544556
Validation loss: 2.186897054795296

Epoch: 6| Step: 10
Training loss: 1.6072463989257812
Validation loss: 2.193755549769248

Epoch: 6| Step: 11
Training loss: 2.3372883796691895
Validation loss: 2.168003042538961

Epoch: 6| Step: 12
Training loss: 2.02055287361145
Validation loss: 2.1365330603814896

Epoch: 6| Step: 13
Training loss: 2.616115093231201
Validation loss: 2.1113761599345873

Epoch: 228| Step: 0
Training loss: 2.5166432857513428
Validation loss: 2.123978332806659

Epoch: 6| Step: 1
Training loss: 2.169325828552246
Validation loss: 2.144853468864195

Epoch: 6| Step: 2
Training loss: 2.427872657775879
Validation loss: 2.124615402631862

Epoch: 6| Step: 3
Training loss: 1.8816829919815063
Validation loss: 2.1358269568412536

Epoch: 6| Step: 4
Training loss: 2.704005241394043
Validation loss: 2.1482446783332416

Epoch: 6| Step: 5
Training loss: 1.9347811937332153
Validation loss: 2.0293761299502466

Epoch: 6| Step: 6
Training loss: 1.3828074932098389
Validation loss: 2.1293610231850737

Epoch: 6| Step: 7
Training loss: 1.7424052953720093
Validation loss: 2.1593794399692166

Epoch: 6| Step: 8
Training loss: 2.402508497238159
Validation loss: 2.1319292386372886

Epoch: 6| Step: 9
Training loss: 2.4840030670166016
Validation loss: 2.095433194150207

Epoch: 6| Step: 10
Training loss: 1.9832404851913452
Validation loss: 2.0806700875682216

Epoch: 6| Step: 11
Training loss: 2.233262538909912
Validation loss: 2.066284674470143

Epoch: 6| Step: 12
Training loss: 1.570908784866333
Validation loss: 2.1325357242297103

Epoch: 6| Step: 13
Training loss: 2.7035937309265137
Validation loss: 2.115327714591898

Epoch: 229| Step: 0
Training loss: 3.0433874130249023
Validation loss: 2.0859499554480276

Epoch: 6| Step: 1
Training loss: 2.002762794494629
Validation loss: 2.0752384072990826

Epoch: 6| Step: 2
Training loss: 1.657078742980957
Validation loss: 2.16077479111251

Epoch: 6| Step: 3
Training loss: 2.2604904174804688
Validation loss: 2.038935363933604

Epoch: 6| Step: 4
Training loss: 2.1543099880218506
Validation loss: 2.0665735685697166

Epoch: 6| Step: 5
Training loss: 2.3318660259246826
Validation loss: 2.050356923892934

Epoch: 6| Step: 6
Training loss: 2.1165664196014404
Validation loss: 2.107726840562718

Epoch: 6| Step: 7
Training loss: 1.9473711252212524
Validation loss: 2.065156562353975

Epoch: 6| Step: 8
Training loss: 2.0541701316833496
Validation loss: 2.073212840223825

Epoch: 6| Step: 9
Training loss: 1.6511173248291016
Validation loss: 2.0751218898321993

Epoch: 6| Step: 10
Training loss: 2.222900390625
Validation loss: 2.1167939119441535

Epoch: 6| Step: 11
Training loss: 2.0596251487731934
Validation loss: 2.065677019857591

Epoch: 6| Step: 12
Training loss: 2.273425579071045
Validation loss: 2.1992156736312376

Epoch: 6| Step: 13
Training loss: 2.0804355144500732
Validation loss: 2.0575612488613335

Epoch: 230| Step: 0
Training loss: 1.9962139129638672
Validation loss: 2.1218007713235836

Epoch: 6| Step: 1
Training loss: 2.117879867553711
Validation loss: 2.0967362183396534

Epoch: 6| Step: 2
Training loss: 1.7011823654174805
Validation loss: 2.0403430026064635

Epoch: 6| Step: 3
Training loss: 2.0263590812683105
Validation loss: 2.05589549515837

Epoch: 6| Step: 4
Training loss: 2.6203880310058594
Validation loss: 2.0736260914033458

Epoch: 6| Step: 5
Training loss: 1.9501714706420898
Validation loss: 2.0288485557802263

Epoch: 6| Step: 6
Training loss: 2.0963103771209717
Validation loss: 2.089347688100671

Epoch: 6| Step: 7
Training loss: 1.7689476013183594
Validation loss: 2.003604769706726

Epoch: 6| Step: 8
Training loss: 2.497990369796753
Validation loss: 2.019102047848445

Epoch: 6| Step: 9
Training loss: 1.8741202354431152
Validation loss: 2.0564472854778333

Epoch: 6| Step: 10
Training loss: 1.7774072885513306
Validation loss: 2.1295962192678966

Epoch: 6| Step: 11
Training loss: 1.5457789897918701
Validation loss: 2.1325049528511624

Epoch: 6| Step: 12
Training loss: 2.8043980598449707
Validation loss: 2.0644146011721705

Epoch: 6| Step: 13
Training loss: 2.7376186847686768
Validation loss: 2.12122247552359

Epoch: 231| Step: 0
Training loss: 2.1213741302490234
Validation loss: 2.1808196498501684

Epoch: 6| Step: 1
Training loss: 2.683234930038452
Validation loss: 2.108504456858481

Epoch: 6| Step: 2
Training loss: 2.136002540588379
Validation loss: 2.0871546294099543

Epoch: 6| Step: 3
Training loss: 1.5755583047866821
Validation loss: 2.168093906935825

Epoch: 6| Step: 4
Training loss: 1.4631481170654297
Validation loss: 2.0952218168525287

Epoch: 6| Step: 5
Training loss: 1.7171183824539185
Validation loss: 2.086150928210187

Epoch: 6| Step: 6
Training loss: 2.059683322906494
Validation loss: 2.071855778335243

Epoch: 6| Step: 7
Training loss: 2.090414047241211
Validation loss: 2.1027255583834905

Epoch: 6| Step: 8
Training loss: 1.3823827505111694
Validation loss: 2.0577790673061083

Epoch: 6| Step: 9
Training loss: 2.446977376937866
Validation loss: 2.0414403830805132

Epoch: 6| Step: 10
Training loss: 2.0660057067871094
Validation loss: 2.096691172610047

Epoch: 6| Step: 11
Training loss: 2.231855869293213
Validation loss: 2.094510750104022

Epoch: 6| Step: 12
Training loss: 3.0937085151672363
Validation loss: 2.136773552945865

Epoch: 6| Step: 13
Training loss: 2.5501863956451416
Validation loss: 2.1188814870772825

Epoch: 232| Step: 0
Training loss: 2.414400339126587
Validation loss: 2.120776205934504

Epoch: 6| Step: 1
Training loss: 1.799833059310913
Validation loss: 2.066734593401673

Epoch: 6| Step: 2
Training loss: 2.094461441040039
Validation loss: 2.097001632054647

Epoch: 6| Step: 3
Training loss: 2.4085867404937744
Validation loss: 2.117813282115485

Epoch: 6| Step: 4
Training loss: 2.7013702392578125
Validation loss: 2.120369360011111

Epoch: 6| Step: 5
Training loss: 1.8685215711593628
Validation loss: 2.1052658762983096

Epoch: 6| Step: 6
Training loss: 1.6553332805633545
Validation loss: 2.0206573240218626

Epoch: 6| Step: 7
Training loss: 2.223261833190918
Validation loss: 2.1058974240415838

Epoch: 6| Step: 8
Training loss: 2.2214763164520264
Validation loss: 2.081608182640486

Epoch: 6| Step: 9
Training loss: 2.027141571044922
Validation loss: 2.1643803376023487

Epoch: 6| Step: 10
Training loss: 1.3972997665405273
Validation loss: 2.1235441815468574

Epoch: 6| Step: 11
Training loss: 1.9085394144058228
Validation loss: 2.1756259484957625

Epoch: 6| Step: 12
Training loss: 2.0084798336029053
Validation loss: 2.087275722975372

Epoch: 6| Step: 13
Training loss: 3.216043472290039
Validation loss: 2.189913583058183

Epoch: 233| Step: 0
Training loss: 1.8329154253005981
Validation loss: 2.068144517560159

Epoch: 6| Step: 1
Training loss: 2.173828125
Validation loss: 2.1165448747655398

Epoch: 6| Step: 2
Training loss: 2.724435329437256
Validation loss: 2.086487224025111

Epoch: 6| Step: 3
Training loss: 1.7257959842681885
Validation loss: 2.145159589347019

Epoch: 6| Step: 4
Training loss: 1.88216233253479
Validation loss: 2.124521058092835

Epoch: 6| Step: 5
Training loss: 1.9033191204071045
Validation loss: 2.136733093569356

Epoch: 6| Step: 6
Training loss: 1.9099398851394653
Validation loss: 2.108851840419154

Epoch: 6| Step: 7
Training loss: 1.9973013401031494
Validation loss: 2.1183986381817888

Epoch: 6| Step: 8
Training loss: 1.8850226402282715
Validation loss: 2.17566817550249

Epoch: 6| Step: 9
Training loss: 1.6899363994598389
Validation loss: 2.13370442774988

Epoch: 6| Step: 10
Training loss: 2.3257484436035156
Validation loss: 2.0864364126677155

Epoch: 6| Step: 11
Training loss: 2.8220348358154297
Validation loss: 2.213723449296849

Epoch: 6| Step: 12
Training loss: 2.221613645553589
Validation loss: 2.1582627591266426

Epoch: 6| Step: 13
Training loss: 2.2948660850524902
Validation loss: 2.1385648250579834

Epoch: 234| Step: 0
Training loss: 1.730466365814209
Validation loss: 2.0798501096745974

Epoch: 6| Step: 1
Training loss: 1.3111824989318848
Validation loss: 2.1199917306182203

Epoch: 6| Step: 2
Training loss: 2.291308641433716
Validation loss: 2.0725371145432994

Epoch: 6| Step: 3
Training loss: 2.4382681846618652
Validation loss: 2.140549700747254

Epoch: 6| Step: 4
Training loss: 1.730107069015503
Validation loss: 2.231905327048353

Epoch: 6| Step: 5
Training loss: 1.4863165616989136
Validation loss: 2.1250812110080513

Epoch: 6| Step: 6
Training loss: 2.015451192855835
Validation loss: 2.1209264237393617

Epoch: 6| Step: 7
Training loss: 2.6657400131225586
Validation loss: 2.104746672414964

Epoch: 6| Step: 8
Training loss: 1.93309485912323
Validation loss: 2.136129907382432

Epoch: 6| Step: 9
Training loss: 1.7219207286834717
Validation loss: 2.1027593715216524

Epoch: 6| Step: 10
Training loss: 2.9423892498016357
Validation loss: 2.116264284297984

Epoch: 6| Step: 11
Training loss: 1.8305938243865967
Validation loss: 2.0997804698123725

Epoch: 6| Step: 12
Training loss: 3.008033275604248
Validation loss: 2.066330402128158

Epoch: 6| Step: 13
Training loss: 1.8969331979751587
Validation loss: 2.110297702973889

Epoch: 235| Step: 0
Training loss: 2.529913902282715
Validation loss: 2.095163022318194

Epoch: 6| Step: 1
Training loss: 3.138739585876465
Validation loss: 2.145097699216617

Epoch: 6| Step: 2
Training loss: 1.8744217157363892
Validation loss: 2.0981918406742874

Epoch: 6| Step: 3
Training loss: 1.1747496128082275
Validation loss: 2.048763482801376

Epoch: 6| Step: 4
Training loss: 1.7517213821411133
Validation loss: 2.151374041393239

Epoch: 6| Step: 5
Training loss: 1.8165448904037476
Validation loss: 2.1324988821501374

Epoch: 6| Step: 6
Training loss: 2.081028938293457
Validation loss: 2.060023444955067

Epoch: 6| Step: 7
Training loss: 2.099210023880005
Validation loss: 2.1161854997757943

Epoch: 6| Step: 8
Training loss: 1.6533989906311035
Validation loss: 2.090981920560201

Epoch: 6| Step: 9
Training loss: 2.7558202743530273
Validation loss: 2.0853575237335695

Epoch: 6| Step: 10
Training loss: 2.2782387733459473
Validation loss: 2.0919176609285417

Epoch: 6| Step: 11
Training loss: 2.244760274887085
Validation loss: 2.0927355161277195

Epoch: 6| Step: 12
Training loss: 2.219733715057373
Validation loss: 2.1493006060200353

Epoch: 6| Step: 13
Training loss: 2.1884822845458984
Validation loss: 2.0450308143451648

Epoch: 236| Step: 0
Training loss: 2.4127635955810547
Validation loss: 2.077079755003734

Epoch: 6| Step: 1
Training loss: 2.3412094116210938
Validation loss: 2.0964254358763337

Epoch: 6| Step: 2
Training loss: 1.7965826988220215
Validation loss: 2.1040966433863484

Epoch: 6| Step: 3
Training loss: 1.9070113897323608
Validation loss: 2.0527364336034304

Epoch: 6| Step: 4
Training loss: 1.6627633571624756
Validation loss: 2.128032781744516

Epoch: 6| Step: 5
Training loss: 1.7758947610855103
Validation loss: 2.0276458622306905

Epoch: 6| Step: 6
Training loss: 2.3912391662597656
Validation loss: 2.0901030020047258

Epoch: 6| Step: 7
Training loss: 2.473073720932007
Validation loss: 2.1094183127085366

Epoch: 6| Step: 8
Training loss: 1.7446513175964355
Validation loss: 2.0830940982346893

Epoch: 6| Step: 9
Training loss: 1.6110320091247559
Validation loss: 2.1265801383603002

Epoch: 6| Step: 10
Training loss: 1.4872839450836182
Validation loss: 2.1277575031403573

Epoch: 6| Step: 11
Training loss: 2.7736761569976807
Validation loss: 2.122097207653907

Epoch: 6| Step: 12
Training loss: 2.227911949157715
Validation loss: 2.1257400845968597

Epoch: 6| Step: 13
Training loss: 2.5620944499969482
Validation loss: 2.079014755064441

Epoch: 237| Step: 0
Training loss: 1.688326358795166
Validation loss: 2.164890420052313

Epoch: 6| Step: 1
Training loss: 2.1728501319885254
Validation loss: 2.103023902062447

Epoch: 6| Step: 2
Training loss: 2.78702974319458
Validation loss: 2.168169024170086

Epoch: 6| Step: 3
Training loss: 1.9377388954162598
Validation loss: 2.194031834602356

Epoch: 6| Step: 4
Training loss: 1.7099215984344482
Validation loss: 2.1575369732354277

Epoch: 6| Step: 5
Training loss: 1.98252272605896
Validation loss: 2.130559156017919

Epoch: 6| Step: 6
Training loss: 2.2441205978393555
Validation loss: 2.1347880389100764

Epoch: 6| Step: 7
Training loss: 2.2316436767578125
Validation loss: 2.094423983686714

Epoch: 6| Step: 8
Training loss: 1.6411434412002563
Validation loss: 2.165097690397693

Epoch: 6| Step: 9
Training loss: 2.3288075923919678
Validation loss: 2.122066274765999

Epoch: 6| Step: 10
Training loss: 2.1234662532806396
Validation loss: 2.0945289519525345

Epoch: 6| Step: 11
Training loss: 2.3034398555755615
Validation loss: 2.141828565187352

Epoch: 6| Step: 12
Training loss: 2.0429444313049316
Validation loss: 2.1200104964676725

Epoch: 6| Step: 13
Training loss: 2.02695894241333
Validation loss: 2.1419758207054547

Epoch: 238| Step: 0
Training loss: 2.029207706451416
Validation loss: 2.1292000842350784

Epoch: 6| Step: 1
Training loss: 2.15495228767395
Validation loss: 2.0983255460698116

Epoch: 6| Step: 2
Training loss: 1.9253268241882324
Validation loss: 2.1394172970966627

Epoch: 6| Step: 3
Training loss: 2.0183446407318115
Validation loss: 2.13304461971406

Epoch: 6| Step: 4
Training loss: 1.867506980895996
Validation loss: 2.076140152510776

Epoch: 6| Step: 5
Training loss: 3.316917896270752
Validation loss: 2.133571517082953

Epoch: 6| Step: 6
Training loss: 2.170577049255371
Validation loss: 2.0696485619391165

Epoch: 6| Step: 7
Training loss: 1.6606402397155762
Validation loss: 2.1453435523535616

Epoch: 6| Step: 8
Training loss: 2.428071975708008
Validation loss: 2.140291331916727

Epoch: 6| Step: 9
Training loss: 1.2679882049560547
Validation loss: 2.1075377105384745

Epoch: 6| Step: 10
Training loss: 2.091728687286377
Validation loss: 2.1290102786915277

Epoch: 6| Step: 11
Training loss: 2.0858402252197266
Validation loss: 2.080812256823304

Epoch: 6| Step: 12
Training loss: 2.1783347129821777
Validation loss: 2.1192407172213317

Epoch: 6| Step: 13
Training loss: 2.1761698722839355
Validation loss: 2.0923584327902844

Epoch: 239| Step: 0
Training loss: 1.72812819480896
Validation loss: 2.0439535238409556

Epoch: 6| Step: 1
Training loss: 2.5537924766540527
Validation loss: 2.1282782605899278

Epoch: 6| Step: 2
Training loss: 2.348771095275879
Validation loss: 2.156464884358068

Epoch: 6| Step: 3
Training loss: 1.8725972175598145
Validation loss: 2.15170201434884

Epoch: 6| Step: 4
Training loss: 2.578491687774658
Validation loss: 2.0745902164008028

Epoch: 6| Step: 5
Training loss: 2.203476905822754
Validation loss: 2.1176017663812123

Epoch: 6| Step: 6
Training loss: 1.7910926342010498
Validation loss: 2.096795653784147

Epoch: 6| Step: 7
Training loss: 2.5354995727539062
Validation loss: 2.119470186130975

Epoch: 6| Step: 8
Training loss: 2.2648983001708984
Validation loss: 2.1369908958353023

Epoch: 6| Step: 9
Training loss: 1.8130277395248413
Validation loss: 2.1595163370973323

Epoch: 6| Step: 10
Training loss: 1.2744297981262207
Validation loss: 2.122353498653699

Epoch: 6| Step: 11
Training loss: 2.378483533859253
Validation loss: 2.102285074931319

Epoch: 6| Step: 12
Training loss: 2.289187431335449
Validation loss: 2.106752534066477

Epoch: 6| Step: 13
Training loss: 1.7348742485046387
Validation loss: 2.124478852877053

Epoch: 240| Step: 0
Training loss: 2.146552562713623
Validation loss: 2.1148626522351335

Epoch: 6| Step: 1
Training loss: 1.8160687685012817
Validation loss: 2.1492887594366588

Epoch: 6| Step: 2
Training loss: 2.006355047225952
Validation loss: 2.0779331717439877

Epoch: 6| Step: 3
Training loss: 1.8654766082763672
Validation loss: 2.0678814072762766

Epoch: 6| Step: 4
Training loss: 2.166628360748291
Validation loss: 2.0790659484042915

Epoch: 6| Step: 5
Training loss: 2.0733063220977783
Validation loss: 2.1690691530063586

Epoch: 6| Step: 6
Training loss: 2.541879653930664
Validation loss: 2.1701001582607145

Epoch: 6| Step: 7
Training loss: 1.6377673149108887
Validation loss: 2.169158161327403

Epoch: 6| Step: 8
Training loss: 1.9206960201263428
Validation loss: 2.12305179719002

Epoch: 6| Step: 9
Training loss: 1.8816590309143066
Validation loss: 2.1085765874514015

Epoch: 6| Step: 10
Training loss: 2.2904112339019775
Validation loss: 2.088974327169439

Epoch: 6| Step: 11
Training loss: 2.091062068939209
Validation loss: 2.088348909090924

Epoch: 6| Step: 12
Training loss: 2.3279452323913574
Validation loss: 2.113221496664068

Epoch: 6| Step: 13
Training loss: 2.500498056411743
Validation loss: 2.056963410428775

Epoch: 241| Step: 0
Training loss: 1.7218579053878784
Validation loss: 2.1188509054081415

Epoch: 6| Step: 1
Training loss: 2.360126256942749
Validation loss: 2.0798459604222286

Epoch: 6| Step: 2
Training loss: 1.7583242654800415
Validation loss: 2.1278629661888204

Epoch: 6| Step: 3
Training loss: 2.374450206756592
Validation loss: 2.0964827024808494

Epoch: 6| Step: 4
Training loss: 1.2555599212646484
Validation loss: 2.0875369528288483

Epoch: 6| Step: 5
Training loss: 2.1662092208862305
Validation loss: 2.16099093549995

Epoch: 6| Step: 6
Training loss: 2.6234848499298096
Validation loss: 2.1250176275930097

Epoch: 6| Step: 7
Training loss: 1.901241421699524
Validation loss: 2.0927424661574827

Epoch: 6| Step: 8
Training loss: 2.175227642059326
Validation loss: 2.1644176719009236

Epoch: 6| Step: 9
Training loss: 2.3667778968811035
Validation loss: 2.2031549510135444

Epoch: 6| Step: 10
Training loss: 1.7434186935424805
Validation loss: 2.216645827857397

Epoch: 6| Step: 11
Training loss: 3.2282538414001465
Validation loss: 2.170940222278718

Epoch: 6| Step: 12
Training loss: 1.6155085563659668
Validation loss: 2.10295965338266

Epoch: 6| Step: 13
Training loss: 1.8717951774597168
Validation loss: 2.15809569948463

Epoch: 242| Step: 0
Training loss: 1.8601596355438232
Validation loss: 2.1404679872656382

Epoch: 6| Step: 1
Training loss: 1.6805990934371948
Validation loss: 2.1762971237141597

Epoch: 6| Step: 2
Training loss: 2.578617572784424
Validation loss: 2.149655290829238

Epoch: 6| Step: 3
Training loss: 2.319584846496582
Validation loss: 2.0880081551049345

Epoch: 6| Step: 4
Training loss: 1.7100672721862793
Validation loss: 2.1380808455969698

Epoch: 6| Step: 5
Training loss: 2.1296119689941406
Validation loss: 2.1275408883248605

Epoch: 6| Step: 6
Training loss: 2.2302868366241455
Validation loss: 2.1221659414229856

Epoch: 6| Step: 7
Training loss: 2.6959762573242188
Validation loss: 2.138017249363725

Epoch: 6| Step: 8
Training loss: 1.9219484329223633
Validation loss: 2.1036084287910053

Epoch: 6| Step: 9
Training loss: 1.9433826208114624
Validation loss: 2.109161805081111

Epoch: 6| Step: 10
Training loss: 2.657726287841797
Validation loss: 2.1196785793509534

Epoch: 6| Step: 11
Training loss: 2.1995575428009033
Validation loss: 2.1171583001331618

Epoch: 6| Step: 12
Training loss: 1.563171148300171
Validation loss: 2.0678894699260755

Epoch: 6| Step: 13
Training loss: 1.9772688150405884
Validation loss: 2.100737206397518

Epoch: 243| Step: 0
Training loss: 1.8832496404647827
Validation loss: 2.0842056710232972

Epoch: 6| Step: 1
Training loss: 2.1872286796569824
Validation loss: 2.0646717535552157

Epoch: 6| Step: 2
Training loss: 2.3021349906921387
Validation loss: 2.07466031659034

Epoch: 6| Step: 3
Training loss: 1.935668706893921
Validation loss: 2.0942405910902124

Epoch: 6| Step: 4
Training loss: 2.5757851600646973
Validation loss: 2.1015182079807406

Epoch: 6| Step: 5
Training loss: 1.5411075353622437
Validation loss: 2.1329515390498663

Epoch: 6| Step: 6
Training loss: 2.1357338428497314
Validation loss: 2.0816461937401884

Epoch: 6| Step: 7
Training loss: 1.9565582275390625
Validation loss: 2.100588124285462

Epoch: 6| Step: 8
Training loss: 1.7220094203948975
Validation loss: 2.093325784129481

Epoch: 6| Step: 9
Training loss: 2.7206358909606934
Validation loss: 2.1259151838159047

Epoch: 6| Step: 10
Training loss: 1.9016551971435547
Validation loss: 2.0629985383761826

Epoch: 6| Step: 11
Training loss: 2.1902127265930176
Validation loss: 2.0932950640237458

Epoch: 6| Step: 12
Training loss: 2.022535800933838
Validation loss: 2.08639867331392

Epoch: 6| Step: 13
Training loss: 2.0197505950927734
Validation loss: 2.1512980499575214

Epoch: 244| Step: 0
Training loss: 2.0041446685791016
Validation loss: 2.1131768944442912

Epoch: 6| Step: 1
Training loss: 2.2263784408569336
Validation loss: 2.095650433212198

Epoch: 6| Step: 2
Training loss: 2.4997398853302
Validation loss: 2.1065611634203183

Epoch: 6| Step: 3
Training loss: 1.5441970825195312
Validation loss: 2.1062230269114175

Epoch: 6| Step: 4
Training loss: 2.444408893585205
Validation loss: 2.1310390016084075

Epoch: 6| Step: 5
Training loss: 2.9496188163757324
Validation loss: 2.1420132396041707

Epoch: 6| Step: 6
Training loss: 1.4757375717163086
Validation loss: 2.1283040969602522

Epoch: 6| Step: 7
Training loss: 2.105936050415039
Validation loss: 2.0873291210461686

Epoch: 6| Step: 8
Training loss: 2.35906982421875
Validation loss: 2.1205488174192366

Epoch: 6| Step: 9
Training loss: 2.15494441986084
Validation loss: 2.1310348869651876

Epoch: 6| Step: 10
Training loss: 1.584639072418213
Validation loss: 2.0515742327577327

Epoch: 6| Step: 11
Training loss: 2.445584297180176
Validation loss: 2.133250780003045

Epoch: 6| Step: 12
Training loss: 1.8615682125091553
Validation loss: 2.1096296746243715

Epoch: 6| Step: 13
Training loss: 1.8921279907226562
Validation loss: 2.092657422506681

Epoch: 245| Step: 0
Training loss: 2.2189276218414307
Validation loss: 2.1774712736888597

Epoch: 6| Step: 1
Training loss: 1.720594048500061
Validation loss: 2.110403053222164

Epoch: 6| Step: 2
Training loss: 1.4833314418792725
Validation loss: 2.1275765972752727

Epoch: 6| Step: 3
Training loss: 1.9375121593475342
Validation loss: 2.1386928891622894

Epoch: 6| Step: 4
Training loss: 1.7933497428894043
Validation loss: 2.0915029446283975

Epoch: 6| Step: 5
Training loss: 3.0718181133270264
Validation loss: 2.0444646984018306

Epoch: 6| Step: 6
Training loss: 2.196012258529663
Validation loss: 2.143032161138391

Epoch: 6| Step: 7
Training loss: 1.5934045314788818
Validation loss: 2.1017944530774186

Epoch: 6| Step: 8
Training loss: 1.9446204900741577
Validation loss: 2.1546262002760366

Epoch: 6| Step: 9
Training loss: 2.3380699157714844
Validation loss: 2.080647830040224

Epoch: 6| Step: 10
Training loss: 2.455965280532837
Validation loss: 2.193559761970274

Epoch: 6| Step: 11
Training loss: 2.508849620819092
Validation loss: 2.1073905703842

Epoch: 6| Step: 12
Training loss: 1.6980233192443848
Validation loss: 2.159135518535491

Epoch: 6| Step: 13
Training loss: 2.091973066329956
Validation loss: 2.1400447481422016

Epoch: 246| Step: 0
Training loss: 2.4645793437957764
Validation loss: 2.0928147890234507

Epoch: 6| Step: 1
Training loss: 1.6121221780776978
Validation loss: 2.140449631598688

Epoch: 6| Step: 2
Training loss: 2.6748876571655273
Validation loss: 2.1622841768367316

Epoch: 6| Step: 3
Training loss: 2.5242152214050293
Validation loss: 2.1233886993059548

Epoch: 6| Step: 4
Training loss: 2.3157382011413574
Validation loss: 2.1172997041415145

Epoch: 6| Step: 5
Training loss: 2.1509971618652344
Validation loss: 2.0966962652821697

Epoch: 6| Step: 6
Training loss: 1.390371561050415
Validation loss: 2.17324629393957

Epoch: 6| Step: 7
Training loss: 2.0932700634002686
Validation loss: 2.1787542860995055

Epoch: 6| Step: 8
Training loss: 1.820029377937317
Validation loss: 2.1341736329499112

Epoch: 6| Step: 9
Training loss: 1.9137349128723145
Validation loss: 2.1369118690490723

Epoch: 6| Step: 10
Training loss: 2.3781771659851074
Validation loss: 2.1417465773961877

Epoch: 6| Step: 11
Training loss: 1.8471572399139404
Validation loss: 2.1600887031965357

Epoch: 6| Step: 12
Training loss: 1.94044828414917
Validation loss: 2.1319635927036242

Epoch: 6| Step: 13
Training loss: 1.378265619277954
Validation loss: 2.1717936197916665

Epoch: 247| Step: 0
Training loss: 1.3610272407531738
Validation loss: 2.0827445368612967

Epoch: 6| Step: 1
Training loss: 2.2386622428894043
Validation loss: 2.132716789040514

Epoch: 6| Step: 2
Training loss: 1.0158555507659912
Validation loss: 2.0837192663582425

Epoch: 6| Step: 3
Training loss: 1.6315548419952393
Validation loss: 2.139853495423512

Epoch: 6| Step: 4
Training loss: 2.3346939086914062
Validation loss: 2.0407417512709096

Epoch: 6| Step: 5
Training loss: 3.2131330966949463
Validation loss: 2.020733612839894

Epoch: 6| Step: 6
Training loss: 2.241351842880249
Validation loss: 2.152269794094947

Epoch: 6| Step: 7
Training loss: 1.351703405380249
Validation loss: 2.0751159678223314

Epoch: 6| Step: 8
Training loss: 2.7495555877685547
Validation loss: 2.1028766990989767

Epoch: 6| Step: 9
Training loss: 2.5594708919525146
Validation loss: 2.104907120427778

Epoch: 6| Step: 10
Training loss: 2.1869726181030273
Validation loss: 2.0958691361129924

Epoch: 6| Step: 11
Training loss: 2.3653340339660645
Validation loss: 2.0886666133839595

Epoch: 6| Step: 12
Training loss: 1.4804575443267822
Validation loss: 2.1035615910765944

Epoch: 6| Step: 13
Training loss: 2.6777548789978027
Validation loss: 2.13325910927147

Epoch: 248| Step: 0
Training loss: 2.547739267349243
Validation loss: 2.09749133740702

Epoch: 6| Step: 1
Training loss: 2.0739288330078125
Validation loss: 2.101998001016596

Epoch: 6| Step: 2
Training loss: 2.098912000656128
Validation loss: 2.136995211724312

Epoch: 6| Step: 3
Training loss: 1.991720199584961
Validation loss: 2.098009806807323

Epoch: 6| Step: 4
Training loss: 1.7775591611862183
Validation loss: 2.0882168739072737

Epoch: 6| Step: 5
Training loss: 2.324373960494995
Validation loss: 2.1344515482584634

Epoch: 6| Step: 6
Training loss: 1.8501840829849243
Validation loss: 2.2043284280325777

Epoch: 6| Step: 7
Training loss: 2.536874771118164
Validation loss: 2.0265700304380028

Epoch: 6| Step: 8
Training loss: 1.975191354751587
Validation loss: 2.146526917334526

Epoch: 6| Step: 9
Training loss: 1.7272270917892456
Validation loss: 2.095375250744563

Epoch: 6| Step: 10
Training loss: 1.8566572666168213
Validation loss: 2.1353451539111394

Epoch: 6| Step: 11
Training loss: 2.0415210723876953
Validation loss: 2.1398381315251833

Epoch: 6| Step: 12
Training loss: 1.8529692888259888
Validation loss: 2.0954869152397237

Epoch: 6| Step: 13
Training loss: 2.8468592166900635
Validation loss: 2.1137132260107223

Epoch: 249| Step: 0
Training loss: 2.274418354034424
Validation loss: 2.10585545468074

Epoch: 6| Step: 1
Training loss: 1.7908313274383545
Validation loss: 2.0734284129194034

Epoch: 6| Step: 2
Training loss: 2.41292667388916
Validation loss: 2.1347648174532

Epoch: 6| Step: 3
Training loss: 2.625394344329834
Validation loss: 2.157375838166924

Epoch: 6| Step: 4
Training loss: 1.4553301334381104
Validation loss: 2.104727719419746

Epoch: 6| Step: 5
Training loss: 1.994057297706604
Validation loss: 2.1453092892964682

Epoch: 6| Step: 6
Training loss: 2.1266205310821533
Validation loss: 2.1057440157859557

Epoch: 6| Step: 7
Training loss: 2.8640999794006348
Validation loss: 2.0986288414206555

Epoch: 6| Step: 8
Training loss: 1.7107981443405151
Validation loss: 2.0832646662189114

Epoch: 6| Step: 9
Training loss: 2.531466484069824
Validation loss: 2.1238550063102477

Epoch: 6| Step: 10
Training loss: 1.755497694015503
Validation loss: 2.0583246984789447

Epoch: 6| Step: 11
Training loss: 1.5684664249420166
Validation loss: 2.1390758381094983

Epoch: 6| Step: 12
Training loss: 1.7686998844146729
Validation loss: 2.0654447514523744

Epoch: 6| Step: 13
Training loss: 2.0530154705047607
Validation loss: 2.1600090329365065

Epoch: 250| Step: 0
Training loss: 1.9629487991333008
Validation loss: 2.138500762242143

Epoch: 6| Step: 1
Training loss: 1.9144234657287598
Validation loss: 2.1393062555661766

Epoch: 6| Step: 2
Training loss: 2.447476863861084
Validation loss: 2.11626091823783

Epoch: 6| Step: 3
Training loss: 2.0262951850891113
Validation loss: 2.098791451864345

Epoch: 6| Step: 4
Training loss: 1.7422370910644531
Validation loss: 2.1395840003926265

Epoch: 6| Step: 5
Training loss: 2.8302085399627686
Validation loss: 2.1700934645950154

Epoch: 6| Step: 6
Training loss: 1.7480279207229614
Validation loss: 2.093511043056365

Epoch: 6| Step: 7
Training loss: 1.50147545337677
Validation loss: 2.1175164509845037

Epoch: 6| Step: 8
Training loss: 2.2363524436950684
Validation loss: 2.1839543029826176

Epoch: 6| Step: 9
Training loss: 2.2771475315093994
Validation loss: 2.1267216256869736

Epoch: 6| Step: 10
Training loss: 1.7149358987808228
Validation loss: 2.134780663315968

Epoch: 6| Step: 11
Training loss: 2.1299169063568115
Validation loss: 2.1274065010009275

Epoch: 6| Step: 12
Training loss: 2.622561454772949
Validation loss: 2.0947743282523206

Epoch: 6| Step: 13
Training loss: 2.1699750423431396
Validation loss: 2.069958012591126

Epoch: 251| Step: 0
Training loss: 1.3830991983413696
Validation loss: 2.103784361193257

Epoch: 6| Step: 1
Training loss: 2.202690839767456
Validation loss: 2.1437295534277476

Epoch: 6| Step: 2
Training loss: 1.7587387561798096
Validation loss: 2.145786246945781

Epoch: 6| Step: 3
Training loss: 2.150599956512451
Validation loss: 2.1147599809913227

Epoch: 6| Step: 4
Training loss: 2.320016384124756
Validation loss: 2.0908947580604145

Epoch: 6| Step: 5
Training loss: 1.7817041873931885
Validation loss: 2.1100272260686403

Epoch: 6| Step: 6
Training loss: 2.155773639678955
Validation loss: 2.1040040280229304

Epoch: 6| Step: 7
Training loss: 1.892394781112671
Validation loss: 2.092676026846773

Epoch: 6| Step: 8
Training loss: 2.0701234340667725
Validation loss: 2.0725340612473024

Epoch: 6| Step: 9
Training loss: 1.8725743293762207
Validation loss: 2.0536847499109085

Epoch: 6| Step: 10
Training loss: 2.2281389236450195
Validation loss: 2.087204094856016

Epoch: 6| Step: 11
Training loss: 1.4542471170425415
Validation loss: 2.055267721094111

Epoch: 6| Step: 12
Training loss: 3.384974956512451
Validation loss: 2.1297881487877137

Epoch: 6| Step: 13
Training loss: 2.7677414417266846
Validation loss: 2.0797567239371677

Epoch: 252| Step: 0
Training loss: 1.9738857746124268
Validation loss: 2.069223616712837

Epoch: 6| Step: 1
Training loss: 1.99564790725708
Validation loss: 2.1166912253184984

Epoch: 6| Step: 2
Training loss: 2.2685959339141846
Validation loss: 2.0783816204276135

Epoch: 6| Step: 3
Training loss: 2.243706226348877
Validation loss: 2.134394068871775

Epoch: 6| Step: 4
Training loss: 2.4684929847717285
Validation loss: 2.1081592126559188

Epoch: 6| Step: 5
Training loss: 2.4036154747009277
Validation loss: 2.137139892065397

Epoch: 6| Step: 6
Training loss: 2.168259859085083
Validation loss: 2.0659368948269914

Epoch: 6| Step: 7
Training loss: 1.8682409524917603
Validation loss: 2.1048063693508023

Epoch: 6| Step: 8
Training loss: 2.3007583618164062
Validation loss: 2.1562001628260457

Epoch: 6| Step: 9
Training loss: 1.7722136974334717
Validation loss: 2.063359523332247

Epoch: 6| Step: 10
Training loss: 2.197381019592285
Validation loss: 2.092640079477782

Epoch: 6| Step: 11
Training loss: 1.9620835781097412
Validation loss: 2.1776129122703307

Epoch: 6| Step: 12
Training loss: 1.8326787948608398
Validation loss: 2.1175532238457793

Epoch: 6| Step: 13
Training loss: 1.90030837059021
Validation loss: 2.0901625746039936

Epoch: 253| Step: 0
Training loss: 2.000577211380005
Validation loss: 2.119552145722092

Epoch: 6| Step: 1
Training loss: 2.4233474731445312
Validation loss: 2.0999634291536067

Epoch: 6| Step: 2
Training loss: 1.3929483890533447
Validation loss: 2.0847317172634985

Epoch: 6| Step: 3
Training loss: 2.8572161197662354
Validation loss: 2.1449209720857683

Epoch: 6| Step: 4
Training loss: 1.6337099075317383
Validation loss: 2.05610433829728

Epoch: 6| Step: 5
Training loss: 2.4251492023468018
Validation loss: 2.0939724188978954

Epoch: 6| Step: 6
Training loss: 1.6115975379943848
Validation loss: 2.1176867997774513

Epoch: 6| Step: 7
Training loss: 2.155092239379883
Validation loss: 2.080112744403142

Epoch: 6| Step: 8
Training loss: 1.685765266418457
Validation loss: 2.1479229234880015

Epoch: 6| Step: 9
Training loss: 2.8878684043884277
Validation loss: 2.0883357678690264

Epoch: 6| Step: 10
Training loss: 1.3790769577026367
Validation loss: 2.0919749454785417

Epoch: 6| Step: 11
Training loss: 2.178271532058716
Validation loss: 2.1638677876482726

Epoch: 6| Step: 12
Training loss: 2.138216018676758
Validation loss: 2.0998119513193765

Epoch: 6| Step: 13
Training loss: 2.8375163078308105
Validation loss: 2.0762144980892057

Epoch: 254| Step: 0
Training loss: 1.8399157524108887
Validation loss: 2.1513473218487156

Epoch: 6| Step: 1
Training loss: 2.1679844856262207
Validation loss: 2.1265918285615983

Epoch: 6| Step: 2
Training loss: 2.5849738121032715
Validation loss: 2.076450856783057

Epoch: 6| Step: 3
Training loss: 2.3584940433502197
Validation loss: 2.1797432899475098

Epoch: 6| Step: 4
Training loss: 2.3257389068603516
Validation loss: 2.086337317702591

Epoch: 6| Step: 5
Training loss: 1.4101784229278564
Validation loss: 2.1388792786546933

Epoch: 6| Step: 6
Training loss: 1.4641988277435303
Validation loss: 2.090553968183456

Epoch: 6| Step: 7
Training loss: 1.9721403121948242
Validation loss: 2.1162814555629605

Epoch: 6| Step: 8
Training loss: 2.080332040786743
Validation loss: 2.117917690225827

Epoch: 6| Step: 9
Training loss: 2.6905083656311035
Validation loss: 2.128359653616464

Epoch: 6| Step: 10
Training loss: 1.677401065826416
Validation loss: 2.1558818073682886

Epoch: 6| Step: 11
Training loss: 1.7166111469268799
Validation loss: 2.126895308494568

Epoch: 6| Step: 12
Training loss: 2.640890121459961
Validation loss: 2.075173859955162

Epoch: 6| Step: 13
Training loss: 1.8265846967697144
Validation loss: 2.103470794616207

Epoch: 255| Step: 0
Training loss: 1.9495340585708618
Validation loss: 2.118874019192111

Epoch: 6| Step: 1
Training loss: 2.304021120071411
Validation loss: 2.1331455246094735

Epoch: 6| Step: 2
Training loss: 1.5693325996398926
Validation loss: 2.122904642935722

Epoch: 6| Step: 3
Training loss: 2.0170836448669434
Validation loss: 2.0936756416033675

Epoch: 6| Step: 4
Training loss: 1.435953974723816
Validation loss: 2.0921844333730717

Epoch: 6| Step: 5
Training loss: 2.0255911350250244
Validation loss: 2.081971158263504

Epoch: 6| Step: 6
Training loss: 2.3224382400512695
Validation loss: 2.075092669456236

Epoch: 6| Step: 7
Training loss: 2.1912474632263184
Validation loss: 2.092417409343104

Epoch: 6| Step: 8
Training loss: 2.788635730743408
Validation loss: 2.0812027146739345

Epoch: 6| Step: 9
Training loss: 1.9366657733917236
Validation loss: 2.1281470803804297

Epoch: 6| Step: 10
Training loss: 2.189655303955078
Validation loss: 2.1561115095692296

Epoch: 6| Step: 11
Training loss: 2.261101722717285
Validation loss: 2.1092119780919885

Epoch: 6| Step: 12
Training loss: 2.1975555419921875
Validation loss: 2.153224293903638

Epoch: 6| Step: 13
Training loss: 1.5036253929138184
Validation loss: 2.052961790433494

Epoch: 256| Step: 0
Training loss: 1.995479941368103
Validation loss: 2.118659491180092

Epoch: 6| Step: 1
Training loss: 2.6057238578796387
Validation loss: 2.1531780124992452

Epoch: 6| Step: 2
Training loss: 1.9546533823013306
Validation loss: 2.085896130531065

Epoch: 6| Step: 3
Training loss: 2.015040159225464
Validation loss: 2.0532021612249394

Epoch: 6| Step: 4
Training loss: 1.9147905111312866
Validation loss: 2.1389237475651566

Epoch: 6| Step: 5
Training loss: 1.973236322402954
Validation loss: 2.174315829430857

Epoch: 6| Step: 6
Training loss: 2.502741575241089
Validation loss: 2.1425550881252495

Epoch: 6| Step: 7
Training loss: 2.2427797317504883
Validation loss: 2.1403561689520396

Epoch: 6| Step: 8
Training loss: 2.701469898223877
Validation loss: 2.126967776206232

Epoch: 6| Step: 9
Training loss: 1.9267393350601196
Validation loss: 2.157097839540051

Epoch: 6| Step: 10
Training loss: 1.9158411026000977
Validation loss: 2.1865894640645673

Epoch: 6| Step: 11
Training loss: 2.136526107788086
Validation loss: 2.131973228146953

Epoch: 6| Step: 12
Training loss: 1.4950082302093506
Validation loss: 2.06479307400283

Epoch: 6| Step: 13
Training loss: 1.8575057983398438
Validation loss: 2.15392792096702

Epoch: 257| Step: 0
Training loss: 2.4494268894195557
Validation loss: 2.051785117836409

Epoch: 6| Step: 1
Training loss: 1.6297624111175537
Validation loss: 2.1219617141190397

Epoch: 6| Step: 2
Training loss: 2.0756397247314453
Validation loss: 2.1632818047718336

Epoch: 6| Step: 3
Training loss: 1.913921594619751
Validation loss: 2.105136320155154

Epoch: 6| Step: 4
Training loss: 3.002143383026123
Validation loss: 2.105089984914308

Epoch: 6| Step: 5
Training loss: 2.264662504196167
Validation loss: 2.1373777184435117

Epoch: 6| Step: 6
Training loss: 2.243649959564209
Validation loss: 2.1513700049410582

Epoch: 6| Step: 7
Training loss: 1.859386682510376
Validation loss: 2.1426037601245347

Epoch: 6| Step: 8
Training loss: 1.8769471645355225
Validation loss: 2.1384361713163313

Epoch: 6| Step: 9
Training loss: 2.580246925354004
Validation loss: 2.0912834444353656

Epoch: 6| Step: 10
Training loss: 1.7779943943023682
Validation loss: 2.113247574016612

Epoch: 6| Step: 11
Training loss: 1.4921894073486328
Validation loss: 2.0913901277767715

Epoch: 6| Step: 12
Training loss: 1.9400945901870728
Validation loss: 2.187981233801893

Epoch: 6| Step: 13
Training loss: 1.4123800992965698
Validation loss: 2.124312775109404

Epoch: 258| Step: 0
Training loss: 1.7799956798553467
Validation loss: 2.1148810309748494

Epoch: 6| Step: 1
Training loss: 2.526113271713257
Validation loss: 2.1344341924113612

Epoch: 6| Step: 2
Training loss: 2.421595573425293
Validation loss: 2.112026465836392

Epoch: 6| Step: 3
Training loss: 1.9444992542266846
Validation loss: 2.118380323533089

Epoch: 6| Step: 4
Training loss: 2.263343572616577
Validation loss: 2.095383328776206

Epoch: 6| Step: 5
Training loss: 1.6896262168884277
Validation loss: 2.125858335084813

Epoch: 6| Step: 6
Training loss: 2.0188684463500977
Validation loss: 2.0996855279450775

Epoch: 6| Step: 7
Training loss: 1.8705906867980957
Validation loss: 2.08139826661797

Epoch: 6| Step: 8
Training loss: 2.1535825729370117
Validation loss: 2.1238388425560406

Epoch: 6| Step: 9
Training loss: 2.5714056491851807
Validation loss: 2.1389281852270967

Epoch: 6| Step: 10
Training loss: 1.1633414030075073
Validation loss: 2.1111655889018888

Epoch: 6| Step: 11
Training loss: 2.5751399993896484
Validation loss: 2.1327276909223167

Epoch: 6| Step: 12
Training loss: 1.861636996269226
Validation loss: 2.1389794131760955

Epoch: 6| Step: 13
Training loss: 1.6771297454833984
Validation loss: 2.145241347692346

Epoch: 259| Step: 0
Training loss: 2.0579895973205566
Validation loss: 2.1537206403670774

Epoch: 6| Step: 1
Training loss: 2.19453763961792
Validation loss: 2.1071476372339393

Epoch: 6| Step: 2
Training loss: 1.9644379615783691
Validation loss: 2.138244398178593

Epoch: 6| Step: 3
Training loss: 1.223745346069336
Validation loss: 2.1468955906488563

Epoch: 6| Step: 4
Training loss: 1.920310139656067
Validation loss: 2.105647110169934

Epoch: 6| Step: 5
Training loss: 1.687462329864502
Validation loss: 2.1185564840993574

Epoch: 6| Step: 6
Training loss: 2.1416218280792236
Validation loss: 2.0622881215105773

Epoch: 6| Step: 7
Training loss: 2.4166083335876465
Validation loss: 2.1226673139038907

Epoch: 6| Step: 8
Training loss: 2.1009538173675537
Validation loss: 2.1347308851057485

Epoch: 6| Step: 9
Training loss: 2.315609931945801
Validation loss: 2.1603876698401665

Epoch: 6| Step: 10
Training loss: 2.370026111602783
Validation loss: 2.125689773149388

Epoch: 6| Step: 11
Training loss: 2.032061815261841
Validation loss: 2.0925372544155327

Epoch: 6| Step: 12
Training loss: 1.93025803565979
Validation loss: 2.0786376230178343

Epoch: 6| Step: 13
Training loss: 2.10455322265625
Validation loss: 2.1160387992858887

Epoch: 260| Step: 0
Training loss: 1.8355863094329834
Validation loss: 2.072531766788934

Epoch: 6| Step: 1
Training loss: 1.9866061210632324
Validation loss: 2.1694153137104486

Epoch: 6| Step: 2
Training loss: 1.957119107246399
Validation loss: 2.1312868287486415

Epoch: 6| Step: 3
Training loss: 1.547301173210144
Validation loss: 2.0858008528268464

Epoch: 6| Step: 4
Training loss: 2.320998430252075
Validation loss: 2.145241721983879

Epoch: 6| Step: 5
Training loss: 1.2581965923309326
Validation loss: 2.1316297836201166

Epoch: 6| Step: 6
Training loss: 2.134187936782837
Validation loss: 2.1204993917096044

Epoch: 6| Step: 7
Training loss: 2.862802505493164
Validation loss: 2.1071244337225474

Epoch: 6| Step: 8
Training loss: 2.1469602584838867
Validation loss: 2.1680667913088234

Epoch: 6| Step: 9
Training loss: 1.8450640439987183
Validation loss: 2.1144814927090883

Epoch: 6| Step: 10
Training loss: 1.870589017868042
Validation loss: 2.0554891478630806

Epoch: 6| Step: 11
Training loss: 2.8047313690185547
Validation loss: 2.051527823171308

Epoch: 6| Step: 12
Training loss: 1.892871618270874
Validation loss: 2.10600713247894

Epoch: 6| Step: 13
Training loss: 2.4702517986297607
Validation loss: 2.1277972190610823

Epoch: 261| Step: 0
Training loss: 2.795405387878418
Validation loss: 2.0866665314602595

Epoch: 6| Step: 1
Training loss: 2.4208016395568848
Validation loss: 2.0917709181385655

Epoch: 6| Step: 2
Training loss: 1.9253801107406616
Validation loss: 2.0724097067309963

Epoch: 6| Step: 3
Training loss: 2.0350098609924316
Validation loss: 2.1339485337657313

Epoch: 6| Step: 4
Training loss: 1.9777584075927734
Validation loss: 2.0997608835979173

Epoch: 6| Step: 5
Training loss: 2.3589348793029785
Validation loss: 2.1071405692767073

Epoch: 6| Step: 6
Training loss: 2.1664366722106934
Validation loss: 2.174671992178886

Epoch: 6| Step: 7
Training loss: 1.6113837957382202
Validation loss: 2.1592966638585573

Epoch: 6| Step: 8
Training loss: 2.3936562538146973
Validation loss: 2.1018643994485178

Epoch: 6| Step: 9
Training loss: 1.5250144004821777
Validation loss: 2.0996184220878025

Epoch: 6| Step: 10
Training loss: 1.7907748222351074
Validation loss: 2.107504662647042

Epoch: 6| Step: 11
Training loss: 2.1521334648132324
Validation loss: 2.1634421707481466

Epoch: 6| Step: 12
Training loss: 1.2771660089492798
Validation loss: 2.1402480858628468

Epoch: 6| Step: 13
Training loss: 2.249706745147705
Validation loss: 2.1014035235169115

Epoch: 262| Step: 0
Training loss: 1.5583970546722412
Validation loss: 2.100332378059305

Epoch: 6| Step: 1
Training loss: 1.7334022521972656
Validation loss: 2.187582746628792

Epoch: 6| Step: 2
Training loss: 1.5429532527923584
Validation loss: 2.201706494054487

Epoch: 6| Step: 3
Training loss: 2.1345720291137695
Validation loss: 2.0949580438675417

Epoch: 6| Step: 4
Training loss: 1.9297242164611816
Validation loss: 2.045263636496759

Epoch: 6| Step: 5
Training loss: 2.1062839031219482
Validation loss: 2.093923668707571

Epoch: 6| Step: 6
Training loss: 2.3689727783203125
Validation loss: 2.0953862846538587

Epoch: 6| Step: 7
Training loss: 2.2679176330566406
Validation loss: 2.0813671388933734

Epoch: 6| Step: 8
Training loss: 2.994154453277588
Validation loss: 2.0688906382488947

Epoch: 6| Step: 9
Training loss: 1.8233485221862793
Validation loss: 2.0936337286426174

Epoch: 6| Step: 10
Training loss: 1.9491783380508423
Validation loss: 2.0809126874451995

Epoch: 6| Step: 11
Training loss: 2.5666093826293945
Validation loss: 2.1262744229326964

Epoch: 6| Step: 12
Training loss: 2.2623066902160645
Validation loss: 2.067214222364528

Epoch: 6| Step: 13
Training loss: 1.745509147644043
Validation loss: 2.136658214753674

Epoch: 263| Step: 0
Training loss: 1.832541823387146
Validation loss: 2.1200079353906776

Epoch: 6| Step: 1
Training loss: 2.153172254562378
Validation loss: 2.118116958166963

Epoch: 6| Step: 2
Training loss: 1.6313204765319824
Validation loss: 2.1388859351476035

Epoch: 6| Step: 3
Training loss: 2.241075277328491
Validation loss: 2.0994936214980258

Epoch: 6| Step: 4
Training loss: 1.616864562034607
Validation loss: 2.105313330568293

Epoch: 6| Step: 5
Training loss: 2.0005316734313965
Validation loss: 2.0762793364063388

Epoch: 6| Step: 6
Training loss: 3.208293914794922
Validation loss: 2.125336467578847

Epoch: 6| Step: 7
Training loss: 2.293093204498291
Validation loss: 2.0954883342148154

Epoch: 6| Step: 8
Training loss: 1.9840062856674194
Validation loss: 2.0941763334376837

Epoch: 6| Step: 9
Training loss: 2.1793675422668457
Validation loss: 2.1318257367739113

Epoch: 6| Step: 10
Training loss: 1.7010650634765625
Validation loss: 2.167078087406774

Epoch: 6| Step: 11
Training loss: 1.9886723756790161
Validation loss: 2.058606746376202

Epoch: 6| Step: 12
Training loss: 1.7413406372070312
Validation loss: 2.0641829018951743

Epoch: 6| Step: 13
Training loss: 2.507286548614502
Validation loss: 2.106587371518535

Epoch: 264| Step: 0
Training loss: 2.639289379119873
Validation loss: 2.0957249441454486

Epoch: 6| Step: 1
Training loss: 1.739302396774292
Validation loss: 2.105351769795982

Epoch: 6| Step: 2
Training loss: 2.638312339782715
Validation loss: 2.184612940716487

Epoch: 6| Step: 3
Training loss: 1.9444406032562256
Validation loss: 2.1623832333472466

Epoch: 6| Step: 4
Training loss: 2.030893325805664
Validation loss: 2.1697907704179005

Epoch: 6| Step: 5
Training loss: 2.7176520824432373
Validation loss: 2.144495150094391

Epoch: 6| Step: 6
Training loss: 2.1044092178344727
Validation loss: 2.173250775183401

Epoch: 6| Step: 7
Training loss: 1.7132810354232788
Validation loss: 2.1798955573830554

Epoch: 6| Step: 8
Training loss: 1.8516770601272583
Validation loss: 2.1353299617767334

Epoch: 6| Step: 9
Training loss: 1.9826061725616455
Validation loss: 2.210722597696448

Epoch: 6| Step: 10
Training loss: 1.7673249244689941
Validation loss: 2.1262594525532057

Epoch: 6| Step: 11
Training loss: 1.6359684467315674
Validation loss: 2.104072665655485

Epoch: 6| Step: 12
Training loss: 2.1730740070343018
Validation loss: 2.1816592524128575

Epoch: 6| Step: 13
Training loss: 1.8868299722671509
Validation loss: 2.2263092046142905

Epoch: 265| Step: 0
Training loss: 2.077669143676758
Validation loss: 2.1891056337664203

Epoch: 6| Step: 1
Training loss: 1.9530797004699707
Validation loss: 2.1907355426460184

Epoch: 6| Step: 2
Training loss: 2.2567827701568604
Validation loss: 2.105641052287112

Epoch: 6| Step: 3
Training loss: 1.5330983400344849
Validation loss: 2.109302310533421

Epoch: 6| Step: 4
Training loss: 2.244370937347412
Validation loss: 2.1726627631853987

Epoch: 6| Step: 5
Training loss: 1.5661869049072266
Validation loss: 2.0908985778849614

Epoch: 6| Step: 6
Training loss: 1.7792837619781494
Validation loss: 2.2021638167801725

Epoch: 6| Step: 7
Training loss: 2.398921012878418
Validation loss: 2.102930574006932

Epoch: 6| Step: 8
Training loss: 2.851254463195801
Validation loss: 2.209386392306256

Epoch: 6| Step: 9
Training loss: 2.0159082412719727
Validation loss: 2.1431232729265766

Epoch: 6| Step: 10
Training loss: 1.7642617225646973
Validation loss: 2.1356098203248877

Epoch: 6| Step: 11
Training loss: 2.007415533065796
Validation loss: 2.1662263613875195

Epoch: 6| Step: 12
Training loss: 2.0401523113250732
Validation loss: 2.148598976032708

Epoch: 6| Step: 13
Training loss: 2.5229222774505615
Validation loss: 2.179040857540664

Epoch: 266| Step: 0
Training loss: 2.6934127807617188
Validation loss: 2.0582104370158207

Epoch: 6| Step: 1
Training loss: 2.0437004566192627
Validation loss: 2.0750950049328547

Epoch: 6| Step: 2
Training loss: 2.666811943054199
Validation loss: 2.081948882790022

Epoch: 6| Step: 3
Training loss: 2.34376859664917
Validation loss: 2.1579607725143433

Epoch: 6| Step: 4
Training loss: 1.9865233898162842
Validation loss: 2.120162130683981

Epoch: 6| Step: 5
Training loss: 1.516989827156067
Validation loss: 2.0990788628978114

Epoch: 6| Step: 6
Training loss: 1.3259189128875732
Validation loss: 2.0432075954252675

Epoch: 6| Step: 7
Training loss: 1.6692883968353271
Validation loss: 2.183843303752202

Epoch: 6| Step: 8
Training loss: 2.6646690368652344
Validation loss: 2.0887628011806036

Epoch: 6| Step: 9
Training loss: 2.368367910385132
Validation loss: 2.1538848825680312

Epoch: 6| Step: 10
Training loss: 1.942209243774414
Validation loss: 2.1155289475635817

Epoch: 6| Step: 11
Training loss: 1.981332540512085
Validation loss: 2.1344976732807774

Epoch: 6| Step: 12
Training loss: 2.235837459564209
Validation loss: 2.1263088474991503

Epoch: 6| Step: 13
Training loss: 1.1867413520812988
Validation loss: 2.1213345553285334

Epoch: 267| Step: 0
Training loss: 2.095987558364868
Validation loss: 2.136900374966283

Epoch: 6| Step: 1
Training loss: 2.7442378997802734
Validation loss: 2.0693762276762273

Epoch: 6| Step: 2
Training loss: 1.7353054285049438
Validation loss: 2.1158638423488987

Epoch: 6| Step: 3
Training loss: 1.8646998405456543
Validation loss: 2.074913142829813

Epoch: 6| Step: 4
Training loss: 2.1722464561462402
Validation loss: 2.0893872591757003

Epoch: 6| Step: 5
Training loss: 2.056118965148926
Validation loss: 2.035541328050757

Epoch: 6| Step: 6
Training loss: 1.6537437438964844
Validation loss: 2.077093308971774

Epoch: 6| Step: 7
Training loss: 1.8630465269088745
Validation loss: 2.098993323182547

Epoch: 6| Step: 8
Training loss: 1.6733319759368896
Validation loss: 2.048977082775485

Epoch: 6| Step: 9
Training loss: 1.8103196620941162
Validation loss: 2.0729377782473

Epoch: 6| Step: 10
Training loss: 1.902116298675537
Validation loss: 2.131725977825862

Epoch: 6| Step: 11
Training loss: 2.80224609375
Validation loss: 2.0918083498554845

Epoch: 6| Step: 12
Training loss: 2.138845443725586
Validation loss: 2.0876654296792965

Epoch: 6| Step: 13
Training loss: 2.125582456588745
Validation loss: 2.0780300837691112

Epoch: 268| Step: 0
Training loss: 2.2909512519836426
Validation loss: 2.122651138613301

Epoch: 6| Step: 1
Training loss: 1.9148517847061157
Validation loss: 2.130043947568504

Epoch: 6| Step: 2
Training loss: 2.1982669830322266
Validation loss: 2.1371623598119265

Epoch: 6| Step: 3
Training loss: 2.7589268684387207
Validation loss: 2.0761505121825845

Epoch: 6| Step: 4
Training loss: 2.209453821182251
Validation loss: 2.1040260522596297

Epoch: 6| Step: 5
Training loss: 1.3563839197158813
Validation loss: 2.122173427253641

Epoch: 6| Step: 6
Training loss: 2.0275750160217285
Validation loss: 2.0953725486673336

Epoch: 6| Step: 7
Training loss: 1.8525922298431396
Validation loss: 2.0668267332097536

Epoch: 6| Step: 8
Training loss: 1.5259419679641724
Validation loss: 2.091656638729957

Epoch: 6| Step: 9
Training loss: 2.046173572540283
Validation loss: 2.1383806518329087

Epoch: 6| Step: 10
Training loss: 1.5001721382141113
Validation loss: 2.1126460465051795

Epoch: 6| Step: 11
Training loss: 1.7818241119384766
Validation loss: 2.1135650270728656

Epoch: 6| Step: 12
Training loss: 3.0367257595062256
Validation loss: 2.1611381474361626

Epoch: 6| Step: 13
Training loss: 2.2887279987335205
Validation loss: 2.1515334331861107

Epoch: 269| Step: 0
Training loss: 2.0909810066223145
Validation loss: 2.0910343854658064

Epoch: 6| Step: 1
Training loss: 2.220522880554199
Validation loss: 2.080124229513189

Epoch: 6| Step: 2
Training loss: 2.5929486751556396
Validation loss: 2.181981881459554

Epoch: 6| Step: 3
Training loss: 1.8743544816970825
Validation loss: 2.0925427559883363

Epoch: 6| Step: 4
Training loss: 1.5561103820800781
Validation loss: 2.1426956140866844

Epoch: 6| Step: 5
Training loss: 1.739803671836853
Validation loss: 2.088973319658669

Epoch: 6| Step: 6
Training loss: 1.590552806854248
Validation loss: 2.0398939758218746

Epoch: 6| Step: 7
Training loss: 1.5672334432601929
Validation loss: 2.139463851528783

Epoch: 6| Step: 8
Training loss: 1.8012139797210693
Validation loss: 2.113539454757526

Epoch: 6| Step: 9
Training loss: 1.4252030849456787
Validation loss: 2.1103835746806157

Epoch: 6| Step: 10
Training loss: 2.435842990875244
Validation loss: 2.097334838682605

Epoch: 6| Step: 11
Training loss: 2.3063080310821533
Validation loss: 2.064212101762013

Epoch: 6| Step: 12
Training loss: 3.5003552436828613
Validation loss: 2.1600688785635014

Epoch: 6| Step: 13
Training loss: 1.7231783866882324
Validation loss: 2.1489558848001624

Epoch: 270| Step: 0
Training loss: 1.5866022109985352
Validation loss: 2.012083794481011

Epoch: 6| Step: 1
Training loss: 2.3848681449890137
Validation loss: 2.096870873564033

Epoch: 6| Step: 2
Training loss: 2.6400890350341797
Validation loss: 2.0505155671027397

Epoch: 6| Step: 3
Training loss: 1.629568338394165
Validation loss: 2.114866582296228

Epoch: 6| Step: 4
Training loss: 1.5681641101837158
Validation loss: 2.109412565026232

Epoch: 6| Step: 5
Training loss: 1.8793445825576782
Validation loss: 2.1413836120277323

Epoch: 6| Step: 6
Training loss: 1.8610515594482422
Validation loss: 2.1316427082143803

Epoch: 6| Step: 7
Training loss: 2.165264129638672
Validation loss: 2.1330248540447605

Epoch: 6| Step: 8
Training loss: 2.434885025024414
Validation loss: 2.1046288872277863

Epoch: 6| Step: 9
Training loss: 2.3795554637908936
Validation loss: 2.1719038922299623

Epoch: 6| Step: 10
Training loss: 1.3679046630859375
Validation loss: 2.0863099187932987

Epoch: 6| Step: 11
Training loss: 2.158332347869873
Validation loss: 2.0907757154075046

Epoch: 6| Step: 12
Training loss: 2.509265661239624
Validation loss: 2.1261809154223372

Epoch: 6| Step: 13
Training loss: 1.8233740329742432
Validation loss: 2.1239244796896495

Epoch: 271| Step: 0
Training loss: 2.3049919605255127
Validation loss: 2.1469537827276413

Epoch: 6| Step: 1
Training loss: 2.26063871383667
Validation loss: 2.171794693957093

Epoch: 6| Step: 2
Training loss: 2.1522059440612793
Validation loss: 2.134713198549004

Epoch: 6| Step: 3
Training loss: 1.8102161884307861
Validation loss: 2.1561012626976095

Epoch: 6| Step: 4
Training loss: 2.0842957496643066
Validation loss: 2.1415899338260775

Epoch: 6| Step: 5
Training loss: 2.2297401428222656
Validation loss: 2.2086228401430192

Epoch: 6| Step: 6
Training loss: 2.5361273288726807
Validation loss: 2.1551338165037093

Epoch: 6| Step: 7
Training loss: 1.8646671772003174
Validation loss: 2.1580416361490884

Epoch: 6| Step: 8
Training loss: 1.6279730796813965
Validation loss: 2.149889047427844

Epoch: 6| Step: 9
Training loss: 1.3084295988082886
Validation loss: 2.1173085115289174

Epoch: 6| Step: 10
Training loss: 1.930749773979187
Validation loss: 2.1087844423068467

Epoch: 6| Step: 11
Training loss: 2.4798636436462402
Validation loss: 2.0621303512204077

Epoch: 6| Step: 12
Training loss: 1.5953693389892578
Validation loss: 2.082559732980626

Epoch: 6| Step: 13
Training loss: 2.3134477138519287
Validation loss: 2.188951720473587

Epoch: 272| Step: 0
Training loss: 1.933537244796753
Validation loss: 2.1194062104789158

Epoch: 6| Step: 1
Training loss: 2.615384101867676
Validation loss: 2.212614208139399

Epoch: 6| Step: 2
Training loss: 2.1485869884490967
Validation loss: 2.1561228152244323

Epoch: 6| Step: 3
Training loss: 2.103567600250244
Validation loss: 2.1548197448894544

Epoch: 6| Step: 4
Training loss: 1.2734858989715576
Validation loss: 2.123069178673529

Epoch: 6| Step: 5
Training loss: 1.8821921348571777
Validation loss: 2.147724600248439

Epoch: 6| Step: 6
Training loss: 1.8805253505706787
Validation loss: 2.091142626218898

Epoch: 6| Step: 7
Training loss: 2.165858507156372
Validation loss: 2.048580064568468

Epoch: 6| Step: 8
Training loss: 2.2438392639160156
Validation loss: 2.1765108544339418

Epoch: 6| Step: 9
Training loss: 1.7842199802398682
Validation loss: 2.032803790543669

Epoch: 6| Step: 10
Training loss: 1.758442759513855
Validation loss: 2.1346626615011566

Epoch: 6| Step: 11
Training loss: 2.748401641845703
Validation loss: 2.086763813931455

Epoch: 6| Step: 12
Training loss: 1.9679019451141357
Validation loss: 2.092851238866006

Epoch: 6| Step: 13
Training loss: 1.7068413496017456
Validation loss: 2.1255138433107765

Epoch: 273| Step: 0
Training loss: 2.0383856296539307
Validation loss: 2.0789131913133847

Epoch: 6| Step: 1
Training loss: 2.304506301879883
Validation loss: 2.1550826372638827

Epoch: 6| Step: 2
Training loss: 1.9417154788970947
Validation loss: 2.0698645050807665

Epoch: 6| Step: 3
Training loss: 2.2297821044921875
Validation loss: 2.1121807431661956

Epoch: 6| Step: 4
Training loss: 1.8482067584991455
Validation loss: 2.0714090242180774

Epoch: 6| Step: 5
Training loss: 2.3506317138671875
Validation loss: 2.135834409344581

Epoch: 6| Step: 6
Training loss: 1.2832460403442383
Validation loss: 2.0594150558594735

Epoch: 6| Step: 7
Training loss: 2.224435806274414
Validation loss: 2.112307156285932

Epoch: 6| Step: 8
Training loss: 1.9702712297439575
Validation loss: 2.08160888507802

Epoch: 6| Step: 9
Training loss: 1.9264013767242432
Validation loss: 2.0781931620772167

Epoch: 6| Step: 10
Training loss: 1.921514868736267
Validation loss: 2.1332247782778997

Epoch: 6| Step: 11
Training loss: 2.8564109802246094
Validation loss: 2.0369032826474918

Epoch: 6| Step: 12
Training loss: 2.308133125305176
Validation loss: 2.0966240590618503

Epoch: 6| Step: 13
Training loss: 1.6526775360107422
Validation loss: 2.1225040958773707

Epoch: 274| Step: 0
Training loss: 2.78479266166687
Validation loss: 2.0742880298245336

Epoch: 6| Step: 1
Training loss: 2.135255813598633
Validation loss: 2.1108543360105125

Epoch: 6| Step: 2
Training loss: 2.3273849487304688
Validation loss: 2.0236695940776537

Epoch: 6| Step: 3
Training loss: 1.9705371856689453
Validation loss: 2.1142422306922173

Epoch: 6| Step: 4
Training loss: 1.8074806928634644
Validation loss: 2.1136468738637944

Epoch: 6| Step: 5
Training loss: 3.2185449600219727
Validation loss: 2.1350048049803703

Epoch: 6| Step: 6
Training loss: 1.5169919729232788
Validation loss: 2.1183690268506288

Epoch: 6| Step: 7
Training loss: 2.3113203048706055
Validation loss: 2.0760863865575483

Epoch: 6| Step: 8
Training loss: 1.7496777772903442
Validation loss: 2.12981395054889

Epoch: 6| Step: 9
Training loss: 1.6085964441299438
Validation loss: 2.1281470226985153

Epoch: 6| Step: 10
Training loss: 2.443948268890381
Validation loss: 2.156104031429496

Epoch: 6| Step: 11
Training loss: 1.9818122386932373
Validation loss: 2.094447922962968

Epoch: 6| Step: 12
Training loss: 1.1249260902404785
Validation loss: 2.1191073463809107

Epoch: 6| Step: 13
Training loss: 2.1141841411590576
Validation loss: 2.101441180834206

Epoch: 275| Step: 0
Training loss: 1.9917325973510742
Validation loss: 2.063444273446196

Epoch: 6| Step: 1
Training loss: 1.7860914468765259
Validation loss: 2.200299870583319

Epoch: 6| Step: 2
Training loss: 1.590696096420288
Validation loss: 2.161558856246292

Epoch: 6| Step: 3
Training loss: 1.6332037448883057
Validation loss: 2.098050804548366

Epoch: 6| Step: 4
Training loss: 2.376214027404785
Validation loss: 2.0650086428529475

Epoch: 6| Step: 5
Training loss: 2.3246567249298096
Validation loss: 2.1152805589860484

Epoch: 6| Step: 6
Training loss: 2.2577340602874756
Validation loss: 2.0964994045995895

Epoch: 6| Step: 7
Training loss: 2.2660393714904785
Validation loss: 2.138490835825602

Epoch: 6| Step: 8
Training loss: 2.5261728763580322
Validation loss: 2.0213226233759234

Epoch: 6| Step: 9
Training loss: 2.152374505996704
Validation loss: 2.06951585636344

Epoch: 6| Step: 10
Training loss: 2.018268585205078
Validation loss: 2.15220352654816

Epoch: 6| Step: 11
Training loss: 1.6588730812072754
Validation loss: 2.0915900174007622

Epoch: 6| Step: 12
Training loss: 2.1017112731933594
Validation loss: 2.0889825872195664

Epoch: 6| Step: 13
Training loss: 2.3971989154815674
Validation loss: 2.129309651672199

Epoch: 276| Step: 0
Training loss: 1.2607364654541016
Validation loss: 2.1062234627303256

Epoch: 6| Step: 1
Training loss: 2.0619142055511475
Validation loss: 2.1108457042324926

Epoch: 6| Step: 2
Training loss: 2.419053554534912
Validation loss: 2.0591930907259703

Epoch: 6| Step: 3
Training loss: 1.265056848526001
Validation loss: 2.0770260954415924

Epoch: 6| Step: 4
Training loss: 2.0099735260009766
Validation loss: 2.123693314931726

Epoch: 6| Step: 5
Training loss: 2.1127076148986816
Validation loss: 2.115976498972985

Epoch: 6| Step: 6
Training loss: 2.5882065296173096
Validation loss: 2.0642856321027203

Epoch: 6| Step: 7
Training loss: 2.046281337738037
Validation loss: 2.138118879769438

Epoch: 6| Step: 8
Training loss: 2.1474781036376953
Validation loss: 2.1094012875710764

Epoch: 6| Step: 9
Training loss: 2.2412869930267334
Validation loss: 2.101417374867265

Epoch: 6| Step: 10
Training loss: 2.112179756164551
Validation loss: 2.1082790641374487

Epoch: 6| Step: 11
Training loss: 2.102757215499878
Validation loss: 2.162646411567606

Epoch: 6| Step: 12
Training loss: 2.52016019821167
Validation loss: 2.131170456127454

Epoch: 6| Step: 13
Training loss: 1.4979579448699951
Validation loss: 2.1736182512775546

Epoch: 277| Step: 0
Training loss: 2.5911457538604736
Validation loss: 2.1422891309184413

Epoch: 6| Step: 1
Training loss: 1.5489097833633423
Validation loss: 2.10912234808809

Epoch: 6| Step: 2
Training loss: 2.2044925689697266
Validation loss: 2.0800616574543778

Epoch: 6| Step: 3
Training loss: 1.535532832145691
Validation loss: 2.150631868711082

Epoch: 6| Step: 4
Training loss: 2.1019535064697266
Validation loss: 2.079689757798308

Epoch: 6| Step: 5
Training loss: 2.285592555999756
Validation loss: 2.097776605236915

Epoch: 6| Step: 6
Training loss: 2.1110057830810547
Validation loss: 2.118716747530045

Epoch: 6| Step: 7
Training loss: 2.576720952987671
Validation loss: 2.1207025692027104

Epoch: 6| Step: 8
Training loss: 2.2407400608062744
Validation loss: 2.2313150769920758

Epoch: 6| Step: 9
Training loss: 1.0365431308746338
Validation loss: 2.1022792144488265

Epoch: 6| Step: 10
Training loss: 1.3482879400253296
Validation loss: 2.0556221341574066

Epoch: 6| Step: 11
Training loss: 2.1376476287841797
Validation loss: 2.1441822692912114

Epoch: 6| Step: 12
Training loss: 2.414121627807617
Validation loss: 2.124980552222139

Epoch: 6| Step: 13
Training loss: 1.886955738067627
Validation loss: 2.123300184485733

Epoch: 278| Step: 0
Training loss: 2.011591911315918
Validation loss: 2.114562214061778

Epoch: 6| Step: 1
Training loss: 2.7231974601745605
Validation loss: 2.147022963852011

Epoch: 6| Step: 2
Training loss: 1.7093288898468018
Validation loss: 2.1203702367762083

Epoch: 6| Step: 3
Training loss: 1.270613431930542
Validation loss: 2.116554844763971

Epoch: 6| Step: 4
Training loss: 1.7917542457580566
Validation loss: 2.102310925401667

Epoch: 6| Step: 5
Training loss: 2.424409866333008
Validation loss: 2.130297389081729

Epoch: 6| Step: 6
Training loss: 2.013364315032959
Validation loss: 2.110223211267943

Epoch: 6| Step: 7
Training loss: 2.2128114700317383
Validation loss: 2.163958147007932

Epoch: 6| Step: 8
Training loss: 2.160233974456787
Validation loss: 2.1597673982702275

Epoch: 6| Step: 9
Training loss: 1.4899938106536865
Validation loss: 2.0820825561400382

Epoch: 6| Step: 10
Training loss: 1.7537260055541992
Validation loss: 2.158613110101351

Epoch: 6| Step: 11
Training loss: 1.831953525543213
Validation loss: 2.154391819430936

Epoch: 6| Step: 12
Training loss: 2.3934683799743652
Validation loss: 2.1425491097152873

Epoch: 6| Step: 13
Training loss: 2.7276060581207275
Validation loss: 2.077800960950954

Epoch: 279| Step: 0
Training loss: 1.8366860151290894
Validation loss: 2.094998626298802

Epoch: 6| Step: 1
Training loss: 2.6153054237365723
Validation loss: 2.0870756487692557

Epoch: 6| Step: 2
Training loss: 2.277421712875366
Validation loss: 2.148352112821353

Epoch: 6| Step: 3
Training loss: 1.6026253700256348
Validation loss: 2.105817517926616

Epoch: 6| Step: 4
Training loss: 1.5499489307403564
Validation loss: 2.1292455786017963

Epoch: 6| Step: 5
Training loss: 1.9142282009124756
Validation loss: 2.026933272679647

Epoch: 6| Step: 6
Training loss: 2.1309847831726074
Validation loss: 2.1301896597749446

Epoch: 6| Step: 7
Training loss: 2.1525588035583496
Validation loss: 2.0520460105711416

Epoch: 6| Step: 8
Training loss: 1.6724193096160889
Validation loss: 2.026761567720803

Epoch: 6| Step: 9
Training loss: 2.0062999725341797
Validation loss: 2.1003187202638194

Epoch: 6| Step: 10
Training loss: 1.641021966934204
Validation loss: 2.074343490344222

Epoch: 6| Step: 11
Training loss: 2.6732077598571777
Validation loss: 2.056897194154801

Epoch: 6| Step: 12
Training loss: 2.1507503986358643
Validation loss: 2.168006057380348

Epoch: 6| Step: 13
Training loss: 1.7781556844711304
Validation loss: 2.054461897060435

Epoch: 280| Step: 0
Training loss: 1.4180819988250732
Validation loss: 2.1129106552370134

Epoch: 6| Step: 1
Training loss: 2.275824785232544
Validation loss: 2.1230457828890894

Epoch: 6| Step: 2
Training loss: 1.9129846096038818
Validation loss: 2.15608246608447

Epoch: 6| Step: 3
Training loss: 1.984433650970459
Validation loss: 2.1524050722840014

Epoch: 6| Step: 4
Training loss: 2.1382880210876465
Validation loss: 2.1362018046840543

Epoch: 6| Step: 5
Training loss: 2.4506120681762695
Validation loss: 2.1156186288402927

Epoch: 6| Step: 6
Training loss: 1.894481897354126
Validation loss: 2.034217826781734

Epoch: 6| Step: 7
Training loss: 1.5357189178466797
Validation loss: 2.089785001611197

Epoch: 6| Step: 8
Training loss: 2.529026508331299
Validation loss: 2.1611947974851056

Epoch: 6| Step: 9
Training loss: 1.9501433372497559
Validation loss: 2.0807804061520483

Epoch: 6| Step: 10
Training loss: 1.5874338150024414
Validation loss: 2.181868073760822

Epoch: 6| Step: 11
Training loss: 1.6970199346542358
Validation loss: 2.1294083736276113

Epoch: 6| Step: 12
Training loss: 2.702617645263672
Validation loss: 2.114052664849066

Epoch: 6| Step: 13
Training loss: 1.997567892074585
Validation loss: 2.1050391581750687

Epoch: 281| Step: 0
Training loss: 1.9495296478271484
Validation loss: 2.149070406472811

Epoch: 6| Step: 1
Training loss: 2.2637040615081787
Validation loss: 2.1152856580672728

Epoch: 6| Step: 2
Training loss: 1.7291390895843506
Validation loss: 2.1436412693351827

Epoch: 6| Step: 3
Training loss: 1.80789053440094
Validation loss: 2.163512534992669

Epoch: 6| Step: 4
Training loss: 1.8987932205200195
Validation loss: 2.148540178934733

Epoch: 6| Step: 5
Training loss: 1.5462759733200073
Validation loss: 2.1581264977814048

Epoch: 6| Step: 6
Training loss: 1.9806503057479858
Validation loss: 2.168813464462116

Epoch: 6| Step: 7
Training loss: 1.9899775981903076
Validation loss: 2.1554154029456516

Epoch: 6| Step: 8
Training loss: 1.895175576210022
Validation loss: 2.134381035322784

Epoch: 6| Step: 9
Training loss: 2.1232008934020996
Validation loss: 2.1236201832371373

Epoch: 6| Step: 10
Training loss: 2.6868386268615723
Validation loss: 2.0913976225801694

Epoch: 6| Step: 11
Training loss: 1.8672655820846558
Validation loss: 2.1329831051570114

Epoch: 6| Step: 12
Training loss: 2.2016139030456543
Validation loss: 2.115971375537175

Epoch: 6| Step: 13
Training loss: 2.670440435409546
Validation loss: 2.1524055978303314

Epoch: 282| Step: 0
Training loss: 1.7910462617874146
Validation loss: 2.0634691638331257

Epoch: 6| Step: 1
Training loss: 2.0363478660583496
Validation loss: 2.0803854132211335

Epoch: 6| Step: 2
Training loss: 1.7874598503112793
Validation loss: 2.181299090385437

Epoch: 6| Step: 3
Training loss: 1.6916208267211914
Validation loss: 2.112599161363417

Epoch: 6| Step: 4
Training loss: 1.7686213254928589
Validation loss: 2.103481090196999

Epoch: 6| Step: 5
Training loss: 2.4449684619903564
Validation loss: 2.099397954120431

Epoch: 6| Step: 6
Training loss: 1.8187607526779175
Validation loss: 2.1610011887806717

Epoch: 6| Step: 7
Training loss: 2.3208365440368652
Validation loss: 2.1771893219281266

Epoch: 6| Step: 8
Training loss: 2.002504348754883
Validation loss: 2.161341254429151

Epoch: 6| Step: 9
Training loss: 1.7551305294036865
Validation loss: 2.10467557496922

Epoch: 6| Step: 10
Training loss: 2.3793067932128906
Validation loss: 2.1304283065180623

Epoch: 6| Step: 11
Training loss: 2.1254968643188477
Validation loss: 2.109172487771639

Epoch: 6| Step: 12
Training loss: 1.4726324081420898
Validation loss: 2.1389347955744755

Epoch: 6| Step: 13
Training loss: 2.6063337326049805
Validation loss: 2.067760213728874

Epoch: 283| Step: 0
Training loss: 1.8863661289215088
Validation loss: 2.134749444582129

Epoch: 6| Step: 1
Training loss: 2.29842472076416
Validation loss: 2.141312260781565

Epoch: 6| Step: 2
Training loss: 1.9277474880218506
Validation loss: 2.1215326888586885

Epoch: 6| Step: 3
Training loss: 2.152190923690796
Validation loss: 2.116569736952423

Epoch: 6| Step: 4
Training loss: 2.005972385406494
Validation loss: 2.089678615652105

Epoch: 6| Step: 5
Training loss: 2.0824289321899414
Validation loss: 2.1659116283539803

Epoch: 6| Step: 6
Training loss: 1.6707127094268799
Validation loss: 2.1041149093258764

Epoch: 6| Step: 7
Training loss: 1.7108606100082397
Validation loss: 2.0551760324867825

Epoch: 6| Step: 8
Training loss: 2.1819229125976562
Validation loss: 2.1591672435883553

Epoch: 6| Step: 9
Training loss: 1.5480843782424927
Validation loss: 2.139186207966138

Epoch: 6| Step: 10
Training loss: 2.1623520851135254
Validation loss: 2.1266039827818513

Epoch: 6| Step: 11
Training loss: 2.4028429985046387
Validation loss: 2.1259302452046382

Epoch: 6| Step: 12
Training loss: 1.7696962356567383
Validation loss: 2.1042735448447605

Epoch: 6| Step: 13
Training loss: 2.253101348876953
Validation loss: 2.101831838648806

Epoch: 284| Step: 0
Training loss: 2.57476806640625
Validation loss: 2.133336978573953

Epoch: 6| Step: 1
Training loss: 2.22642183303833
Validation loss: 2.067661936565112

Epoch: 6| Step: 2
Training loss: 1.3981242179870605
Validation loss: 2.087962696629186

Epoch: 6| Step: 3
Training loss: 2.315600872039795
Validation loss: 2.0981851085539787

Epoch: 6| Step: 4
Training loss: 1.2492117881774902
Validation loss: 2.122289608883601

Epoch: 6| Step: 5
Training loss: 1.9872024059295654
Validation loss: 2.052590657305974

Epoch: 6| Step: 6
Training loss: 0.99639892578125
Validation loss: 2.015161671946126

Epoch: 6| Step: 7
Training loss: 2.4382729530334473
Validation loss: 2.076218174349877

Epoch: 6| Step: 8
Training loss: 2.32513165473938
Validation loss: 2.091212039352745

Epoch: 6| Step: 9
Training loss: 2.578599452972412
Validation loss: 2.1051051078304166

Epoch: 6| Step: 10
Training loss: 2.340839385986328
Validation loss: 2.1389010542182514

Epoch: 6| Step: 11
Training loss: 2.3188884258270264
Validation loss: 2.147015179357221

Epoch: 6| Step: 12
Training loss: 1.7738916873931885
Validation loss: 2.110165637026551

Epoch: 6| Step: 13
Training loss: 2.0743658542633057
Validation loss: 2.1516194112839235

Epoch: 285| Step: 0
Training loss: 2.7894935607910156
Validation loss: 2.0688120421542915

Epoch: 6| Step: 1
Training loss: 1.3534775972366333
Validation loss: 2.064901973611565

Epoch: 6| Step: 2
Training loss: 1.9678759574890137
Validation loss: 2.1289739672855665

Epoch: 6| Step: 3
Training loss: 2.636711597442627
Validation loss: 2.055464759949715

Epoch: 6| Step: 4
Training loss: 1.864764928817749
Validation loss: 2.154311159605621

Epoch: 6| Step: 5
Training loss: 1.8988137245178223
Validation loss: 2.085642030162196

Epoch: 6| Step: 6
Training loss: 1.880207896232605
Validation loss: 2.037113880598417

Epoch: 6| Step: 7
Training loss: 1.2274563312530518
Validation loss: 2.050534512407036

Epoch: 6| Step: 8
Training loss: 1.9352991580963135
Validation loss: 2.0945409062088176

Epoch: 6| Step: 9
Training loss: 2.032966375350952
Validation loss: 2.1331740130660353

Epoch: 6| Step: 10
Training loss: 2.131744861602783
Validation loss: 2.0805747791003157

Epoch: 6| Step: 11
Training loss: 1.6636618375778198
Validation loss: 2.0682914539050032

Epoch: 6| Step: 12
Training loss: 2.013062000274658
Validation loss: 2.0972236151336343

Epoch: 6| Step: 13
Training loss: 3.0221519470214844
Validation loss: 2.029768002930508

Epoch: 286| Step: 0
Training loss: 2.0200867652893066
Validation loss: 2.183061756113524

Epoch: 6| Step: 1
Training loss: 2.000786542892456
Validation loss: 2.078406705651232

Epoch: 6| Step: 2
Training loss: 2.1960506439208984
Validation loss: 2.137902202144746

Epoch: 6| Step: 3
Training loss: 2.029442310333252
Validation loss: 2.1135830058846423

Epoch: 6| Step: 4
Training loss: 1.9345755577087402
Validation loss: 2.1976411893803585

Epoch: 6| Step: 5
Training loss: 1.8504865169525146
Validation loss: 2.124380152712586

Epoch: 6| Step: 6
Training loss: 1.6404261589050293
Validation loss: 2.115544608844224

Epoch: 6| Step: 7
Training loss: 1.9337352514266968
Validation loss: 2.119928340758047

Epoch: 6| Step: 8
Training loss: 2.62416672706604
Validation loss: 2.182030462449597

Epoch: 6| Step: 9
Training loss: 1.5660505294799805
Validation loss: 2.1888446064405542

Epoch: 6| Step: 10
Training loss: 2.0497887134552
Validation loss: 2.106988154431825

Epoch: 6| Step: 11
Training loss: 2.43544602394104
Validation loss: 2.103441071766679

Epoch: 6| Step: 12
Training loss: 2.0217702388763428
Validation loss: 2.1146749040131927

Epoch: 6| Step: 13
Training loss: 1.4902158975601196
Validation loss: 2.151145282612052

Epoch: 287| Step: 0
Training loss: 2.1408519744873047
Validation loss: 2.116962491825063

Epoch: 6| Step: 1
Training loss: 2.2116270065307617
Validation loss: 2.116730013201314

Epoch: 6| Step: 2
Training loss: 1.8148467540740967
Validation loss: 2.0652678756303686

Epoch: 6| Step: 3
Training loss: 1.9835014343261719
Validation loss: 2.138335686857982

Epoch: 6| Step: 4
Training loss: 2.0810632705688477
Validation loss: 2.1036122101609425

Epoch: 6| Step: 5
Training loss: 1.6539342403411865
Validation loss: 2.1742117199846493

Epoch: 6| Step: 6
Training loss: 2.5993874073028564
Validation loss: 2.1930461775872017

Epoch: 6| Step: 7
Training loss: 2.482696056365967
Validation loss: 2.1541157781436877

Epoch: 6| Step: 8
Training loss: 2.1213934421539307
Validation loss: 2.163115692395036

Epoch: 6| Step: 9
Training loss: 1.4813148975372314
Validation loss: 2.133995634253307

Epoch: 6| Step: 10
Training loss: 1.5710217952728271
Validation loss: 2.098042167643065

Epoch: 6| Step: 11
Training loss: 2.1104140281677246
Validation loss: 2.0882452072635775

Epoch: 6| Step: 12
Training loss: 1.8975058794021606
Validation loss: 2.1485922490396807

Epoch: 6| Step: 13
Training loss: 2.525359630584717
Validation loss: 2.115465716649127

Epoch: 288| Step: 0
Training loss: 1.9694054126739502
Validation loss: 2.181013285472829

Epoch: 6| Step: 1
Training loss: 2.315277099609375
Validation loss: 2.1628404676273303

Epoch: 6| Step: 2
Training loss: 1.4780573844909668
Validation loss: 2.109254034616614

Epoch: 6| Step: 3
Training loss: 1.8673264980316162
Validation loss: 2.159954119754094

Epoch: 6| Step: 4
Training loss: 1.9738514423370361
Validation loss: 2.1431732972462973

Epoch: 6| Step: 5
Training loss: 2.301084041595459
Validation loss: 2.1441795223502704

Epoch: 6| Step: 6
Training loss: 1.8838549852371216
Validation loss: 2.147335934382613

Epoch: 6| Step: 7
Training loss: 1.417676568031311
Validation loss: 2.064644632800933

Epoch: 6| Step: 8
Training loss: 1.6558728218078613
Validation loss: 2.087471835074886

Epoch: 6| Step: 9
Training loss: 2.4564476013183594
Validation loss: 2.048751608017952

Epoch: 6| Step: 10
Training loss: 2.3269639015197754
Validation loss: 2.047217333188621

Epoch: 6| Step: 11
Training loss: 1.757833480834961
Validation loss: 2.0904692757514214

Epoch: 6| Step: 12
Training loss: 2.734504461288452
Validation loss: 2.1013362920412453

Epoch: 6| Step: 13
Training loss: 2.4553277492523193
Validation loss: 2.0722784380758963

Epoch: 289| Step: 0
Training loss: 1.7573320865631104
Validation loss: 2.0780791108326246

Epoch: 6| Step: 1
Training loss: 2.0039258003234863
Validation loss: 2.0997254233206473

Epoch: 6| Step: 2
Training loss: 1.9032812118530273
Validation loss: 2.0979001265700146

Epoch: 6| Step: 3
Training loss: 2.227159023284912
Validation loss: 2.125437921093356

Epoch: 6| Step: 4
Training loss: 2.558147430419922
Validation loss: 2.0920607607851744

Epoch: 6| Step: 5
Training loss: 2.4548568725585938
Validation loss: 2.1421964014730146

Epoch: 6| Step: 6
Training loss: 2.092548370361328
Validation loss: 2.08090219959136

Epoch: 6| Step: 7
Training loss: 1.7022374868392944
Validation loss: 2.156962361387027

Epoch: 6| Step: 8
Training loss: 1.9074712991714478
Validation loss: 2.1371814102254887

Epoch: 6| Step: 9
Training loss: 2.0928292274475098
Validation loss: 2.0077399335881716

Epoch: 6| Step: 10
Training loss: 1.5377302169799805
Validation loss: 2.1329962643243934

Epoch: 6| Step: 11
Training loss: 1.9015361070632935
Validation loss: 2.0309685904492616

Epoch: 6| Step: 12
Training loss: 1.8806345462799072
Validation loss: 2.1563883853215042

Epoch: 6| Step: 13
Training loss: 2.3399055004119873
Validation loss: 2.119532267252604

Epoch: 290| Step: 0
Training loss: 2.92156720161438
Validation loss: 2.1859230892632597

Epoch: 6| Step: 1
Training loss: 2.119781017303467
Validation loss: 2.146846722531062

Epoch: 6| Step: 2
Training loss: 1.751018762588501
Validation loss: 2.116331961847121

Epoch: 6| Step: 3
Training loss: 2.359652519226074
Validation loss: 2.1502115841834777

Epoch: 6| Step: 4
Training loss: 1.5720114707946777
Validation loss: 2.0619866130172566

Epoch: 6| Step: 5
Training loss: 1.4696507453918457
Validation loss: 2.136487323750732

Epoch: 6| Step: 6
Training loss: 1.6734812259674072
Validation loss: 2.1328408692472722

Epoch: 6| Step: 7
Training loss: 1.6302058696746826
Validation loss: 2.1333300016259633

Epoch: 6| Step: 8
Training loss: 1.4110161066055298
Validation loss: 2.13178873959408

Epoch: 6| Step: 9
Training loss: 2.4551124572753906
Validation loss: 2.1466706004194034

Epoch: 6| Step: 10
Training loss: 2.2805676460266113
Validation loss: 2.1320019537402737

Epoch: 6| Step: 11
Training loss: 2.253262996673584
Validation loss: 2.132158374273649

Epoch: 6| Step: 12
Training loss: 2.105973243713379
Validation loss: 2.117482458391497

Epoch: 6| Step: 13
Training loss: 2.267223358154297
Validation loss: 2.2148178341568157

Epoch: 291| Step: 0
Training loss: 1.3835983276367188
Validation loss: 2.1549415306378434

Epoch: 6| Step: 1
Training loss: 1.1961005926132202
Validation loss: 2.1583098006504837

Epoch: 6| Step: 2
Training loss: 2.1647651195526123
Validation loss: 2.1121976606307493

Epoch: 6| Step: 3
Training loss: 1.5132157802581787
Validation loss: 2.1156318674805346

Epoch: 6| Step: 4
Training loss: 2.2417731285095215
Validation loss: 2.129794982171828

Epoch: 6| Step: 5
Training loss: 1.8616113662719727
Validation loss: 2.0223151214661135

Epoch: 6| Step: 6
Training loss: 1.9345135688781738
Validation loss: 2.0425275653921147

Epoch: 6| Step: 7
Training loss: 2.2493934631347656
Validation loss: 2.1319787963744132

Epoch: 6| Step: 8
Training loss: 2.8725037574768066
Validation loss: 2.0965483701357277

Epoch: 6| Step: 9
Training loss: 1.7478786706924438
Validation loss: 2.1219470706037296

Epoch: 6| Step: 10
Training loss: 2.202552080154419
Validation loss: 2.097299886006181

Epoch: 6| Step: 11
Training loss: 2.8495326042175293
Validation loss: 2.114383086081474

Epoch: 6| Step: 12
Training loss: 1.5630148649215698
Validation loss: 2.090412947439378

Epoch: 6| Step: 13
Training loss: 2.2460105419158936
Validation loss: 2.0844574243791643

Epoch: 292| Step: 0
Training loss: 2.3341193199157715
Validation loss: 2.094049899808822

Epoch: 6| Step: 1
Training loss: 2.369997024536133
Validation loss: 2.1222137892118065

Epoch: 6| Step: 2
Training loss: 1.8086342811584473
Validation loss: 2.0874932043014036

Epoch: 6| Step: 3
Training loss: 2.5889225006103516
Validation loss: 2.130103059994277

Epoch: 6| Step: 4
Training loss: 1.6770461797714233
Validation loss: 2.1352139211470083

Epoch: 6| Step: 5
Training loss: 1.9674668312072754
Validation loss: 2.096408651721093

Epoch: 6| Step: 6
Training loss: 2.0087363719940186
Validation loss: 2.1217044784176733

Epoch: 6| Step: 7
Training loss: 1.5148570537567139
Validation loss: 2.143408512556425

Epoch: 6| Step: 8
Training loss: 1.8072102069854736
Validation loss: 2.1244600601093744

Epoch: 6| Step: 9
Training loss: 2.4341745376586914
Validation loss: 2.1939996416850756

Epoch: 6| Step: 10
Training loss: 1.7652711868286133
Validation loss: 2.2022578741914485

Epoch: 6| Step: 11
Training loss: 2.186011791229248
Validation loss: 2.161109257769841

Epoch: 6| Step: 12
Training loss: 1.7830207347869873
Validation loss: 2.16319772248627

Epoch: 6| Step: 13
Training loss: 1.7495505809783936
Validation loss: 2.09715897293501

Epoch: 293| Step: 0
Training loss: 1.4917452335357666
Validation loss: 2.1943539111844954

Epoch: 6| Step: 1
Training loss: 1.6243562698364258
Validation loss: 2.106755805271928

Epoch: 6| Step: 2
Training loss: 2.565540313720703
Validation loss: 2.12477873217675

Epoch: 6| Step: 3
Training loss: 1.8004533052444458
Validation loss: 2.194394088560535

Epoch: 6| Step: 4
Training loss: 2.174595832824707
Validation loss: 2.1706736215981106

Epoch: 6| Step: 5
Training loss: 1.9065804481506348
Validation loss: 2.1565463953120734

Epoch: 6| Step: 6
Training loss: 2.3904311656951904
Validation loss: 2.2052951679434827

Epoch: 6| Step: 7
Training loss: 1.8187390565872192
Validation loss: 2.1128776406729095

Epoch: 6| Step: 8
Training loss: 2.3149259090423584
Validation loss: 2.2066337088102936

Epoch: 6| Step: 9
Training loss: 2.4624838829040527
Validation loss: 2.1400378904035016

Epoch: 6| Step: 10
Training loss: 2.6177356243133545
Validation loss: 2.15783517847779

Epoch: 6| Step: 11
Training loss: 2.0024404525756836
Validation loss: 2.1594065594416794

Epoch: 6| Step: 12
Training loss: 1.4906916618347168
Validation loss: 2.1525965659849104

Epoch: 6| Step: 13
Training loss: 1.5253369808197021
Validation loss: 2.1757814217639226

Epoch: 294| Step: 0
Training loss: 2.103329658508301
Validation loss: 2.171819035724927

Epoch: 6| Step: 1
Training loss: 2.351325511932373
Validation loss: 2.119172462853052

Epoch: 6| Step: 2
Training loss: 1.4872310161590576
Validation loss: 2.1393745150617374

Epoch: 6| Step: 3
Training loss: 1.7854783535003662
Validation loss: 2.0935457137323197

Epoch: 6| Step: 4
Training loss: 2.474428653717041
Validation loss: 2.0624464750289917

Epoch: 6| Step: 5
Training loss: 1.386096715927124
Validation loss: 2.090314680530179

Epoch: 6| Step: 6
Training loss: 1.9557976722717285
Validation loss: 2.107071493261604

Epoch: 6| Step: 7
Training loss: 2.1048855781555176
Validation loss: 2.069004927912066

Epoch: 6| Step: 8
Training loss: 1.6887608766555786
Validation loss: 2.0652695907059537

Epoch: 6| Step: 9
Training loss: 2.2080178260803223
Validation loss: 2.077920780386976

Epoch: 6| Step: 10
Training loss: 2.2537012100219727
Validation loss: 2.035842272543138

Epoch: 6| Step: 11
Training loss: 2.660051107406616
Validation loss: 2.092190774538184

Epoch: 6| Step: 12
Training loss: 2.1231958866119385
Validation loss: 2.0410860866628666

Epoch: 6| Step: 13
Training loss: 2.060154914855957
Validation loss: 2.058773162544415

Epoch: 295| Step: 0
Training loss: 1.70418381690979
Validation loss: 2.101657740531429

Epoch: 6| Step: 1
Training loss: 2.006497383117676
Validation loss: 2.088058121742741

Epoch: 6| Step: 2
Training loss: 2.007281541824341
Validation loss: 2.0870688833216184

Epoch: 6| Step: 3
Training loss: 2.8833162784576416
Validation loss: 2.129680500235609

Epoch: 6| Step: 4
Training loss: 1.4889401197433472
Validation loss: 2.1411250150331886

Epoch: 6| Step: 5
Training loss: 1.9852722883224487
Validation loss: 2.111193351848151

Epoch: 6| Step: 6
Training loss: 1.885540246963501
Validation loss: 2.115156332651774

Epoch: 6| Step: 7
Training loss: 1.6852927207946777
Validation loss: 2.105565281324489

Epoch: 6| Step: 8
Training loss: 2.0828800201416016
Validation loss: 2.0603532739864883

Epoch: 6| Step: 9
Training loss: 2.1267971992492676
Validation loss: 2.142476499721568

Epoch: 6| Step: 10
Training loss: 2.393465518951416
Validation loss: 2.1215255978286907

Epoch: 6| Step: 11
Training loss: 2.358151912689209
Validation loss: 2.0993521239167903

Epoch: 6| Step: 12
Training loss: 1.9212275743484497
Validation loss: 2.1436819017574353

Epoch: 6| Step: 13
Training loss: 0.9602080583572388
Validation loss: 2.1433416399904477

Epoch: 296| Step: 0
Training loss: 1.2218966484069824
Validation loss: 2.1168062430556103

Epoch: 6| Step: 1
Training loss: 2.071743965148926
Validation loss: 2.0712827867077244

Epoch: 6| Step: 2
Training loss: 1.3711085319519043
Validation loss: 2.173764987658429

Epoch: 6| Step: 3
Training loss: 2.0301480293273926
Validation loss: 2.1606132573978876

Epoch: 6| Step: 4
Training loss: 1.9781713485717773
Validation loss: 2.155078871275789

Epoch: 6| Step: 5
Training loss: 1.5842156410217285
Validation loss: 2.0737617631112375

Epoch: 6| Step: 6
Training loss: 2.4496023654937744
Validation loss: 2.1392944910193004

Epoch: 6| Step: 7
Training loss: 2.2312698364257812
Validation loss: 2.136470893377899

Epoch: 6| Step: 8
Training loss: 2.404414653778076
Validation loss: 2.132571848489905

Epoch: 6| Step: 9
Training loss: 2.4435982704162598
Validation loss: 2.0692850620515886

Epoch: 6| Step: 10
Training loss: 2.262293815612793
Validation loss: 2.138009189277567

Epoch: 6| Step: 11
Training loss: 2.2841100692749023
Validation loss: 2.1436497960039365

Epoch: 6| Step: 12
Training loss: 2.2546775341033936
Validation loss: 2.1784798278603503

Epoch: 6| Step: 13
Training loss: 1.7348463535308838
Validation loss: 2.1207410648304927

Epoch: 297| Step: 0
Training loss: 2.402646541595459
Validation loss: 2.1557611227035522

Epoch: 6| Step: 1
Training loss: 1.7201017141342163
Validation loss: 2.119929903297014

Epoch: 6| Step: 2
Training loss: 1.8117930889129639
Validation loss: 2.180711305269631

Epoch: 6| Step: 3
Training loss: 1.5953447818756104
Validation loss: 2.195143004899384

Epoch: 6| Step: 4
Training loss: 2.5354504585266113
Validation loss: 2.1429830302474318

Epoch: 6| Step: 5
Training loss: 2.006106376647949
Validation loss: 2.125711853786181

Epoch: 6| Step: 6
Training loss: 2.3693339824676514
Validation loss: 2.0885967516130015

Epoch: 6| Step: 7
Training loss: 2.2022547721862793
Validation loss: 2.0928149659146547

Epoch: 6| Step: 8
Training loss: 2.1905016899108887
Validation loss: 2.1303063618239535

Epoch: 6| Step: 9
Training loss: 1.5431205034255981
Validation loss: 2.063274992409573

Epoch: 6| Step: 10
Training loss: 1.6688545942306519
Validation loss: 2.113164117259364

Epoch: 6| Step: 11
Training loss: 2.2189064025878906
Validation loss: 2.094530095336258

Epoch: 6| Step: 12
Training loss: 1.6363155841827393
Validation loss: 2.111178964696905

Epoch: 6| Step: 13
Training loss: 1.2371686697006226
Validation loss: 2.1292457119111092

Epoch: 298| Step: 0
Training loss: 2.0104098320007324
Validation loss: 2.12593553655891

Epoch: 6| Step: 1
Training loss: 0.898619532585144
Validation loss: 2.05068907173731

Epoch: 6| Step: 2
Training loss: 1.8578044176101685
Validation loss: 2.0900381765057965

Epoch: 6| Step: 3
Training loss: 2.119016647338867
Validation loss: 2.1844679104384555

Epoch: 6| Step: 4
Training loss: 1.9124486446380615
Validation loss: 2.1042159270214778

Epoch: 6| Step: 5
Training loss: 1.6183501482009888
Validation loss: 2.0846984924808627

Epoch: 6| Step: 6
Training loss: 2.4806387424468994
Validation loss: 2.1377938421823646

Epoch: 6| Step: 7
Training loss: 2.3487203121185303
Validation loss: 2.1898542014501428

Epoch: 6| Step: 8
Training loss: 2.135357618331909
Validation loss: 2.0972900339352187

Epoch: 6| Step: 9
Training loss: 2.1988511085510254
Validation loss: 2.203875885214857

Epoch: 6| Step: 10
Training loss: 1.3680322170257568
Validation loss: 2.1272606900943223

Epoch: 6| Step: 11
Training loss: 2.4479141235351562
Validation loss: 2.1202618383592173

Epoch: 6| Step: 12
Training loss: 2.402775287628174
Validation loss: 2.1702842327856247

Epoch: 6| Step: 13
Training loss: 1.7760668992996216
Validation loss: 2.132608070168444

Epoch: 299| Step: 0
Training loss: 2.0175204277038574
Validation loss: 2.0761980907891386

Epoch: 6| Step: 1
Training loss: 1.370489239692688
Validation loss: 2.1252418794939594

Epoch: 6| Step: 2
Training loss: 2.0622026920318604
Validation loss: 2.113344528341806

Epoch: 6| Step: 3
Training loss: 2.2034497261047363
Validation loss: 2.131859875494434

Epoch: 6| Step: 4
Training loss: 2.0092735290527344
Validation loss: 2.1737992507155224

Epoch: 6| Step: 5
Training loss: 1.8616743087768555
Validation loss: 2.144278654488184

Epoch: 6| Step: 6
Training loss: 2.428706645965576
Validation loss: 2.195447899961984

Epoch: 6| Step: 7
Training loss: 1.9005546569824219
Validation loss: 2.170146475556076

Epoch: 6| Step: 8
Training loss: 1.7008278369903564
Validation loss: 2.131436650471021

Epoch: 6| Step: 9
Training loss: 2.0237410068511963
Validation loss: 2.1333297414164387

Epoch: 6| Step: 10
Training loss: 1.91123628616333
Validation loss: 2.1371297297939176

Epoch: 6| Step: 11
Training loss: 1.574394941329956
Validation loss: 2.1194454341806392

Epoch: 6| Step: 12
Training loss: 2.6541826725006104
Validation loss: 2.143738103169267

Epoch: 6| Step: 13
Training loss: 1.9892423152923584
Validation loss: 2.1859771564442623

Epoch: 300| Step: 0
Training loss: 2.245229959487915
Validation loss: 2.131941674858011

Epoch: 6| Step: 1
Training loss: 1.8622403144836426
Validation loss: 2.096624080852796

Epoch: 6| Step: 2
Training loss: 2.871603012084961
Validation loss: 2.1258923674142487

Epoch: 6| Step: 3
Training loss: 1.7005223035812378
Validation loss: 2.0705883746506064

Epoch: 6| Step: 4
Training loss: 1.525066614151001
Validation loss: 2.0952815804430234

Epoch: 6| Step: 5
Training loss: 1.60725998878479
Validation loss: 2.1000716147884244

Epoch: 6| Step: 6
Training loss: 1.7025514841079712
Validation loss: 2.1058609101080124

Epoch: 6| Step: 7
Training loss: 2.2389333248138428
Validation loss: 2.0901283833288375

Epoch: 6| Step: 8
Training loss: 2.166865348815918
Validation loss: 2.1040200110404723

Epoch: 6| Step: 9
Training loss: 2.183094024658203
Validation loss: 2.093190896895624

Epoch: 6| Step: 10
Training loss: 1.6316852569580078
Validation loss: 2.1293766114019577

Epoch: 6| Step: 11
Training loss: 2.578164577484131
Validation loss: 2.157967341843472

Epoch: 6| Step: 12
Training loss: 1.7259595394134521
Validation loss: 2.092527497199274

Epoch: 6| Step: 13
Training loss: 1.7196474075317383
Validation loss: 2.123574423533614

Epoch: 301| Step: 0
Training loss: 1.972156286239624
Validation loss: 2.0786027985234417

Epoch: 6| Step: 1
Training loss: 2.179884910583496
Validation loss: 2.1813567992179625

Epoch: 6| Step: 2
Training loss: 2.142805576324463
Validation loss: 2.055055287576491

Epoch: 6| Step: 3
Training loss: 1.5212748050689697
Validation loss: 2.119131841967183

Epoch: 6| Step: 4
Training loss: 2.9187519550323486
Validation loss: 2.166290645958275

Epoch: 6| Step: 5
Training loss: 1.3493807315826416
Validation loss: 2.1339496181857203

Epoch: 6| Step: 6
Training loss: 2.5895423889160156
Validation loss: 2.1105853870350826

Epoch: 6| Step: 7
Training loss: 2.1339774131774902
Validation loss: 2.1505306715606363

Epoch: 6| Step: 8
Training loss: 2.497234582901001
Validation loss: 2.0986413981324885

Epoch: 6| Step: 9
Training loss: 1.3070333003997803
Validation loss: 2.097271091194563

Epoch: 6| Step: 10
Training loss: 1.6603875160217285
Validation loss: 2.128412595359228

Epoch: 6| Step: 11
Training loss: 1.6310430765151978
Validation loss: 2.0973265440233293

Epoch: 6| Step: 12
Training loss: 1.9514110088348389
Validation loss: 2.1256437429817776

Epoch: 6| Step: 13
Training loss: 1.7581634521484375
Validation loss: 2.0989894238851403

Epoch: 302| Step: 0
Training loss: 1.605813980102539
Validation loss: 2.1469439204021166

Epoch: 6| Step: 1
Training loss: 2.2314155101776123
Validation loss: 2.1051275525041806

Epoch: 6| Step: 2
Training loss: 1.1849862337112427
Validation loss: 2.083525929399716

Epoch: 6| Step: 3
Training loss: 2.3393020629882812
Validation loss: 2.1111082184699272

Epoch: 6| Step: 4
Training loss: 1.4812233448028564
Validation loss: 2.120313608518211

Epoch: 6| Step: 5
Training loss: 1.7285360097885132
Validation loss: 2.11203521297824

Epoch: 6| Step: 6
Training loss: 2.474888324737549
Validation loss: 2.126174521702592

Epoch: 6| Step: 7
Training loss: 2.0663251876831055
Validation loss: 2.0935595753372356

Epoch: 6| Step: 8
Training loss: 1.983392357826233
Validation loss: 2.146795666345986

Epoch: 6| Step: 9
Training loss: 1.7936408519744873
Validation loss: 2.082732654386951

Epoch: 6| Step: 10
Training loss: 2.47613787651062
Validation loss: 2.1000930481059576

Epoch: 6| Step: 11
Training loss: 1.8206207752227783
Validation loss: 2.171081477595914

Epoch: 6| Step: 12
Training loss: 2.2448859214782715
Validation loss: 2.1838383956622054

Epoch: 6| Step: 13
Training loss: 2.6931183338165283
Validation loss: 2.1024089590195687

Epoch: 303| Step: 0
Training loss: 1.715664029121399
Validation loss: 2.1589251282394573

Epoch: 6| Step: 1
Training loss: 1.8965516090393066
Validation loss: 2.13260252757739

Epoch: 6| Step: 2
Training loss: 2.161100149154663
Validation loss: 2.151620177812474

Epoch: 6| Step: 3
Training loss: 1.6114106178283691
Validation loss: 2.1634489028684554

Epoch: 6| Step: 4
Training loss: 2.1362202167510986
Validation loss: 2.1454048028556247

Epoch: 6| Step: 5
Training loss: 2.0163393020629883
Validation loss: 2.1293173656668714

Epoch: 6| Step: 6
Training loss: 2.2424185276031494
Validation loss: 2.1524109763483845

Epoch: 6| Step: 7
Training loss: 1.8472890853881836
Validation loss: 2.2025225598325013

Epoch: 6| Step: 8
Training loss: 2.0178539752960205
Validation loss: 2.1395464379300355

Epoch: 6| Step: 9
Training loss: 1.9094383716583252
Validation loss: 2.181138612890756

Epoch: 6| Step: 10
Training loss: 2.684009552001953
Validation loss: 2.1405212058815906

Epoch: 6| Step: 11
Training loss: 2.271907329559326
Validation loss: 2.1358489938961562

Epoch: 6| Step: 12
Training loss: 1.8596997261047363
Validation loss: 2.1560810765912457

Epoch: 6| Step: 13
Training loss: 1.7580206394195557
Validation loss: 2.1216909372678368

Epoch: 304| Step: 0
Training loss: 1.8204580545425415
Validation loss: 2.0610557166478967

Epoch: 6| Step: 1
Training loss: 1.7440311908721924
Validation loss: 2.094664865924466

Epoch: 6| Step: 2
Training loss: 2.2816925048828125
Validation loss: 2.1157158113295034

Epoch: 6| Step: 3
Training loss: 1.5919983386993408
Validation loss: 2.11911057144083

Epoch: 6| Step: 4
Training loss: 2.311584234237671
Validation loss: 2.0898972480527815

Epoch: 6| Step: 5
Training loss: 1.1708199977874756
Validation loss: 2.0296145177656606

Epoch: 6| Step: 6
Training loss: 2.4572629928588867
Validation loss: 2.0083919853292485

Epoch: 6| Step: 7
Training loss: 2.3701205253601074
Validation loss: 2.1150202020522086

Epoch: 6| Step: 8
Training loss: 2.4558966159820557
Validation loss: 2.0843621095021567

Epoch: 6| Step: 9
Training loss: 1.8666619062423706
Validation loss: 2.069495916366577

Epoch: 6| Step: 10
Training loss: 1.7980260848999023
Validation loss: 2.116967228151137

Epoch: 6| Step: 11
Training loss: 1.9378108978271484
Validation loss: 2.074750807977492

Epoch: 6| Step: 12
Training loss: 1.9476522207260132
Validation loss: 2.121476455401349

Epoch: 6| Step: 13
Training loss: 1.8475960493087769
Validation loss: 2.148668445566649

Epoch: 305| Step: 0
Training loss: 2.089066982269287
Validation loss: 2.113521087554193

Epoch: 6| Step: 1
Training loss: 1.9865542650222778
Validation loss: 2.1056868568543465

Epoch: 6| Step: 2
Training loss: 1.3547272682189941
Validation loss: 2.122051981187636

Epoch: 6| Step: 3
Training loss: 2.565253257751465
Validation loss: 2.0787389919322026

Epoch: 6| Step: 4
Training loss: 1.9934077262878418
Validation loss: 2.093997614358061

Epoch: 6| Step: 5
Training loss: 1.4986143112182617
Validation loss: 2.119510850598735

Epoch: 6| Step: 6
Training loss: 1.4019379615783691
Validation loss: 2.0792024686772335

Epoch: 6| Step: 7
Training loss: 1.906678318977356
Validation loss: 2.0604717154656687

Epoch: 6| Step: 8
Training loss: 2.5472300052642822
Validation loss: 2.1196993704765075

Epoch: 6| Step: 9
Training loss: 2.3658251762390137
Validation loss: 2.1557377589646207

Epoch: 6| Step: 10
Training loss: 1.6879329681396484
Validation loss: 2.144809874155188

Epoch: 6| Step: 11
Training loss: 2.579280376434326
Validation loss: 2.1095411316041024

Epoch: 6| Step: 12
Training loss: 1.6162909269332886
Validation loss: 2.1035706150916313

Epoch: 6| Step: 13
Training loss: 1.9496593475341797
Validation loss: 2.1794487481476157

Epoch: 306| Step: 0
Training loss: 1.9156944751739502
Validation loss: 2.2336202488150647

Epoch: 6| Step: 1
Training loss: 2.2260003089904785
Validation loss: 2.122867948265486

Epoch: 6| Step: 2
Training loss: 2.0027503967285156
Validation loss: 2.1119042442690943

Epoch: 6| Step: 3
Training loss: 1.8332116603851318
Validation loss: 2.1856177160816808

Epoch: 6| Step: 4
Training loss: 2.2138965129852295
Validation loss: 2.1040561904189405

Epoch: 6| Step: 5
Training loss: 1.787771224975586
Validation loss: 2.157764187423132

Epoch: 6| Step: 6
Training loss: 2.3005266189575195
Validation loss: 2.1896486372076054

Epoch: 6| Step: 7
Training loss: 1.9017415046691895
Validation loss: 2.1114376398824874

Epoch: 6| Step: 8
Training loss: 2.1498775482177734
Validation loss: 2.1272963439264605

Epoch: 6| Step: 9
Training loss: 2.015688180923462
Validation loss: 2.13838053518726

Epoch: 6| Step: 10
Training loss: 1.586599349975586
Validation loss: 2.0635659745944444

Epoch: 6| Step: 11
Training loss: 2.1051011085510254
Validation loss: 2.0875036383187897

Epoch: 6| Step: 12
Training loss: 1.6617779731750488
Validation loss: 2.109221112343573

Epoch: 6| Step: 13
Training loss: 1.1477255821228027
Validation loss: 2.1045481107568227

Epoch: 307| Step: 0
Training loss: 2.374363660812378
Validation loss: 2.0982015953269055

Epoch: 6| Step: 1
Training loss: 2.335665464401245
Validation loss: 2.1136882587145736

Epoch: 6| Step: 2
Training loss: 1.3262975215911865
Validation loss: 2.1154348260612896

Epoch: 6| Step: 3
Training loss: 2.4859890937805176
Validation loss: 2.13226762125569

Epoch: 6| Step: 4
Training loss: 1.8171597719192505
Validation loss: 2.093898992384634

Epoch: 6| Step: 5
Training loss: 1.5718989372253418
Validation loss: 2.0818481112039215

Epoch: 6| Step: 6
Training loss: 2.4076693058013916
Validation loss: 2.130233310884045

Epoch: 6| Step: 7
Training loss: 2.2347803115844727
Validation loss: 2.040583887407857

Epoch: 6| Step: 8
Training loss: 1.5888566970825195
Validation loss: 2.1093175706043037

Epoch: 6| Step: 9
Training loss: 1.799295425415039
Validation loss: 2.0901468261595695

Epoch: 6| Step: 10
Training loss: 1.6826204061508179
Validation loss: 2.0971815534817275

Epoch: 6| Step: 11
Training loss: 2.3763794898986816
Validation loss: 2.073186825680476

Epoch: 6| Step: 12
Training loss: 1.7183001041412354
Validation loss: 2.0785725232093566

Epoch: 6| Step: 13
Training loss: 2.159813404083252
Validation loss: 2.042157378247989

Epoch: 308| Step: 0
Training loss: 2.224264144897461
Validation loss: 2.0748503925979778

Epoch: 6| Step: 1
Training loss: 2.0363333225250244
Validation loss: 2.0974261376165573

Epoch: 6| Step: 2
Training loss: 2.453899383544922
Validation loss: 2.1292836819925616

Epoch: 6| Step: 3
Training loss: 1.9506059885025024
Validation loss: 2.1939884513937016

Epoch: 6| Step: 4
Training loss: 1.6096190214157104
Validation loss: 2.0994687900748303

Epoch: 6| Step: 5
Training loss: 2.0127930641174316
Validation loss: 2.1106220752962175

Epoch: 6| Step: 6
Training loss: 2.042790412902832
Validation loss: 2.1495288866822437

Epoch: 6| Step: 7
Training loss: 2.2188000679016113
Validation loss: 2.1228865526055776

Epoch: 6| Step: 8
Training loss: 1.07753324508667
Validation loss: 2.1044474032617386

Epoch: 6| Step: 9
Training loss: 1.9877628087997437
Validation loss: 2.1416092739310315

Epoch: 6| Step: 10
Training loss: 2.386075496673584
Validation loss: 2.1268965377602527

Epoch: 6| Step: 11
Training loss: 1.7529423236846924
Validation loss: 2.1033723097975536

Epoch: 6| Step: 12
Training loss: 1.796470046043396
Validation loss: 2.0617748819371706

Epoch: 6| Step: 13
Training loss: 2.191648244857788
Validation loss: 2.1362264848524526

Epoch: 309| Step: 0
Training loss: 2.285727024078369
Validation loss: 2.1360076089059152

Epoch: 6| Step: 1
Training loss: 1.9946813583374023
Validation loss: 2.1228498540898806

Epoch: 6| Step: 2
Training loss: 2.0305886268615723
Validation loss: 2.13148654917235

Epoch: 6| Step: 3
Training loss: 1.7729343175888062
Validation loss: 2.1504657653070267

Epoch: 6| Step: 4
Training loss: 1.9451509714126587
Validation loss: 2.224043823057605

Epoch: 6| Step: 5
Training loss: 1.7173316478729248
Validation loss: 2.1775137775687763

Epoch: 6| Step: 6
Training loss: 2.3344292640686035
Validation loss: 2.101280099602156

Epoch: 6| Step: 7
Training loss: 2.214916229248047
Validation loss: 2.1249810341865785

Epoch: 6| Step: 8
Training loss: 1.917276382446289
Validation loss: 2.0817037884907057

Epoch: 6| Step: 9
Training loss: 1.769961953163147
Validation loss: 2.131102227395581

Epoch: 6| Step: 10
Training loss: 1.602341651916504
Validation loss: 2.1148454758428756

Epoch: 6| Step: 11
Training loss: 2.536644697189331
Validation loss: 2.226448517973705

Epoch: 6| Step: 12
Training loss: 1.5551930665969849
Validation loss: 2.1189287144650697

Epoch: 6| Step: 13
Training loss: 2.4318149089813232
Validation loss: 2.2148849682141374

Epoch: 310| Step: 0
Training loss: 2.326090097427368
Validation loss: 2.110062681218629

Epoch: 6| Step: 1
Training loss: 2.039562940597534
Validation loss: 2.0794809044048352

Epoch: 6| Step: 2
Training loss: 1.7660126686096191
Validation loss: 2.091553388103362

Epoch: 6| Step: 3
Training loss: 1.8324916362762451
Validation loss: 2.1198034863318167

Epoch: 6| Step: 4
Training loss: 1.7708749771118164
Validation loss: 2.153670080246464

Epoch: 6| Step: 5
Training loss: 2.4138407707214355
Validation loss: 2.0965095155982563

Epoch: 6| Step: 6
Training loss: 1.879088044166565
Validation loss: 2.088097063443994

Epoch: 6| Step: 7
Training loss: 1.4099820852279663
Validation loss: 2.1312918509206464

Epoch: 6| Step: 8
Training loss: 1.9327722787857056
Validation loss: 2.068164058910903

Epoch: 6| Step: 9
Training loss: 2.5241150856018066
Validation loss: 2.1518401099789526

Epoch: 6| Step: 10
Training loss: 1.9726450443267822
Validation loss: 2.0449737233500325

Epoch: 6| Step: 11
Training loss: 2.0001227855682373
Validation loss: 2.1254903603625555

Epoch: 6| Step: 12
Training loss: 1.4987597465515137
Validation loss: 2.1370050420043287

Epoch: 6| Step: 13
Training loss: 1.9936926364898682
Validation loss: 2.099729279036163

Epoch: 311| Step: 0
Training loss: 1.4958997964859009
Validation loss: 2.114115268953385

Epoch: 6| Step: 1
Training loss: 2.0293264389038086
Validation loss: 2.097087780634562

Epoch: 6| Step: 2
Training loss: 2.297642230987549
Validation loss: 2.1616861333129225

Epoch: 6| Step: 3
Training loss: 1.6992578506469727
Validation loss: 2.150521675745646

Epoch: 6| Step: 4
Training loss: 1.8708378076553345
Validation loss: 2.057148628337409

Epoch: 6| Step: 5
Training loss: 1.7899436950683594
Validation loss: 2.1388252755647064

Epoch: 6| Step: 6
Training loss: 3.074336051940918
Validation loss: 2.124140980423138

Epoch: 6| Step: 7
Training loss: 2.256093978881836
Validation loss: 2.116585405923987

Epoch: 6| Step: 8
Training loss: 1.8337461948394775
Validation loss: 2.117664997295667

Epoch: 6| Step: 9
Training loss: 1.6577348709106445
Validation loss: 2.1184414714895268

Epoch: 6| Step: 10
Training loss: 2.4917402267456055
Validation loss: 2.095800825344619

Epoch: 6| Step: 11
Training loss: 1.911177158355713
Validation loss: 2.15431974780175

Epoch: 6| Step: 12
Training loss: 1.1622551679611206
Validation loss: 2.173793864506547

Epoch: 6| Step: 13
Training loss: 2.038084030151367
Validation loss: 2.110319111936836

Epoch: 312| Step: 0
Training loss: 2.1712846755981445
Validation loss: 2.1144447352296565

Epoch: 6| Step: 1
Training loss: 1.9797585010528564
Validation loss: 2.097535397416802

Epoch: 6| Step: 2
Training loss: 1.877564549446106
Validation loss: 2.1144581533247426

Epoch: 6| Step: 3
Training loss: 2.886410713195801
Validation loss: 2.075164368075709

Epoch: 6| Step: 4
Training loss: 2.635157346725464
Validation loss: 2.1401843191474996

Epoch: 6| Step: 5
Training loss: 1.659601092338562
Validation loss: 2.1129725979220484

Epoch: 6| Step: 6
Training loss: 2.135493278503418
Validation loss: 2.109455754680018

Epoch: 6| Step: 7
Training loss: 2.1189498901367188
Validation loss: 2.1742599728286907

Epoch: 6| Step: 8
Training loss: 1.5834503173828125
Validation loss: 2.058019562434125

Epoch: 6| Step: 9
Training loss: 1.9122875928878784
Validation loss: 2.1384610540123394

Epoch: 6| Step: 10
Training loss: 1.918640375137329
Validation loss: 2.1583019687283422

Epoch: 6| Step: 11
Training loss: 1.2744413614273071
Validation loss: 2.0279549911458004

Epoch: 6| Step: 12
Training loss: 2.136397123336792
Validation loss: 2.0922275153539514

Epoch: 6| Step: 13
Training loss: 1.283819317817688
Validation loss: 2.152399586093041

Epoch: 313| Step: 0
Training loss: 2.32877779006958
Validation loss: 2.140055097559447

Epoch: 6| Step: 1
Training loss: 1.7249445915222168
Validation loss: 2.1772611628296556

Epoch: 6| Step: 2
Training loss: 1.3960095643997192
Validation loss: 2.128272070679613

Epoch: 6| Step: 3
Training loss: 2.0466785430908203
Validation loss: 2.0935137758972826

Epoch: 6| Step: 4
Training loss: 2.4318788051605225
Validation loss: 2.1218033118914534

Epoch: 6| Step: 5
Training loss: 2.055708408355713
Validation loss: 2.1652692261562554

Epoch: 6| Step: 6
Training loss: 2.499807357788086
Validation loss: 2.162344335227884

Epoch: 6| Step: 7
Training loss: 2.2963480949401855
Validation loss: 2.085148580612675

Epoch: 6| Step: 8
Training loss: 1.7660117149353027
Validation loss: 2.1392305615127727

Epoch: 6| Step: 9
Training loss: 2.074650526046753
Validation loss: 2.124592555466519

Epoch: 6| Step: 10
Training loss: 1.1918569803237915
Validation loss: 2.103698925305438

Epoch: 6| Step: 11
Training loss: 2.0004162788391113
Validation loss: 2.084638754526774

Epoch: 6| Step: 12
Training loss: 1.596420407295227
Validation loss: 2.1747474183318434

Epoch: 6| Step: 13
Training loss: 2.376723289489746
Validation loss: 2.1344425524434736

Epoch: 314| Step: 0
Training loss: 1.9142533540725708
Validation loss: 2.0428570726866364

Epoch: 6| Step: 1
Training loss: 1.9646859169006348
Validation loss: 2.1421968680556103

Epoch: 6| Step: 2
Training loss: 2.509688138961792
Validation loss: 2.110516623784137

Epoch: 6| Step: 3
Training loss: 1.515608787536621
Validation loss: 2.084787340574367

Epoch: 6| Step: 4
Training loss: 2.311889410018921
Validation loss: 2.170791338848811

Epoch: 6| Step: 5
Training loss: 2.1112728118896484
Validation loss: 2.1204109602077033

Epoch: 6| Step: 6
Training loss: 2.1006112098693848
Validation loss: 2.1447952793490503

Epoch: 6| Step: 7
Training loss: 1.7678983211517334
Validation loss: 2.097106941284672

Epoch: 6| Step: 8
Training loss: 2.112412452697754
Validation loss: 2.172477641413289

Epoch: 6| Step: 9
Training loss: 1.8943074941635132
Validation loss: 2.1431888816177205

Epoch: 6| Step: 10
Training loss: 2.1124281883239746
Validation loss: 2.125891052266603

Epoch: 6| Step: 11
Training loss: 1.5995101928710938
Validation loss: 2.1179431023136264

Epoch: 6| Step: 12
Training loss: 2.259326457977295
Validation loss: 2.148563451664422

Epoch: 6| Step: 13
Training loss: 1.7483875751495361
Validation loss: 2.178465771418746

Epoch: 315| Step: 0
Training loss: 2.563525438308716
Validation loss: 2.1472532749176025

Epoch: 6| Step: 1
Training loss: 1.6347606182098389
Validation loss: 2.1551061035484396

Epoch: 6| Step: 2
Training loss: 1.35780668258667
Validation loss: 2.1278870451834893

Epoch: 6| Step: 3
Training loss: 2.1664509773254395
Validation loss: 2.1265349247122325

Epoch: 6| Step: 4
Training loss: 2.040567398071289
Validation loss: 2.0634581940148466

Epoch: 6| Step: 5
Training loss: 2.1540799140930176
Validation loss: 2.094238142813406

Epoch: 6| Step: 6
Training loss: 2.191805362701416
Validation loss: 2.0891315731950986

Epoch: 6| Step: 7
Training loss: 1.767033338546753
Validation loss: 2.1143043348866124

Epoch: 6| Step: 8
Training loss: 1.6848119497299194
Validation loss: 2.1023616995862735

Epoch: 6| Step: 9
Training loss: 2.0448648929595947
Validation loss: 2.1340295986462663

Epoch: 6| Step: 10
Training loss: 1.7024598121643066
Validation loss: 2.151324705411029

Epoch: 6| Step: 11
Training loss: 2.5957610607147217
Validation loss: 2.135198066311498

Epoch: 6| Step: 12
Training loss: 2.4221444129943848
Validation loss: 2.0713187315130748

Epoch: 6| Step: 13
Training loss: 1.2643457651138306
Validation loss: 2.0819505183927474

Epoch: 316| Step: 0
Training loss: 1.1142072677612305
Validation loss: 2.098711241957962

Epoch: 6| Step: 1
Training loss: 2.0085179805755615
Validation loss: 2.0955885353908745

Epoch: 6| Step: 2
Training loss: 2.3883259296417236
Validation loss: 2.1117403250868603

Epoch: 6| Step: 3
Training loss: 2.689781904220581
Validation loss: 2.111582762451582

Epoch: 6| Step: 4
Training loss: 1.306276559829712
Validation loss: 2.135168619053338

Epoch: 6| Step: 5
Training loss: 1.8983532190322876
Validation loss: 2.100221618529289

Epoch: 6| Step: 6
Training loss: 2.414008378982544
Validation loss: 2.1437613784625964

Epoch: 6| Step: 7
Training loss: 2.059988021850586
Validation loss: 2.097388208553355

Epoch: 6| Step: 8
Training loss: 1.974452257156372
Validation loss: 2.1248298050254903

Epoch: 6| Step: 9
Training loss: 1.4585685729980469
Validation loss: 2.1586416126579366

Epoch: 6| Step: 10
Training loss: 1.8978452682495117
Validation loss: 2.0987296770977717

Epoch: 6| Step: 11
Training loss: 1.866060495376587
Validation loss: 2.0526222182858374

Epoch: 6| Step: 12
Training loss: 2.1999316215515137
Validation loss: 2.0995821927183416

Epoch: 6| Step: 13
Training loss: 1.7761355638504028
Validation loss: 2.1173617814176824

Epoch: 317| Step: 0
Training loss: 1.5251963138580322
Validation loss: 2.113389666362475

Epoch: 6| Step: 1
Training loss: 1.8813025951385498
Validation loss: 2.0979884593717513

Epoch: 6| Step: 2
Training loss: 1.8058921098709106
Validation loss: 2.1374046776884343

Epoch: 6| Step: 3
Training loss: 1.8088562488555908
Validation loss: 2.124212908488448

Epoch: 6| Step: 4
Training loss: 2.870203733444214
Validation loss: 2.164631715384863

Epoch: 6| Step: 5
Training loss: 2.236819267272949
Validation loss: 2.1879226456406298

Epoch: 6| Step: 6
Training loss: 1.9964361190795898
Validation loss: 2.146172990081131

Epoch: 6| Step: 7
Training loss: 2.198491096496582
Validation loss: 2.1160604979402278

Epoch: 6| Step: 8
Training loss: 1.411280870437622
Validation loss: 2.1267220179239907

Epoch: 6| Step: 9
Training loss: 2.3616256713867188
Validation loss: 2.1578386150380617

Epoch: 6| Step: 10
Training loss: 1.786450743675232
Validation loss: 2.0753864831821893

Epoch: 6| Step: 11
Training loss: 1.7029783725738525
Validation loss: 2.1020258370266167

Epoch: 6| Step: 12
Training loss: 2.3126659393310547
Validation loss: 2.1215551899325464

Epoch: 6| Step: 13
Training loss: 1.797737956047058
Validation loss: 2.0178207505133843

Epoch: 318| Step: 0
Training loss: 1.988263487815857
Validation loss: 2.158810647585059

Epoch: 6| Step: 1
Training loss: 1.8855528831481934
Validation loss: 2.1297267406217513

Epoch: 6| Step: 2
Training loss: 1.9748785495758057
Validation loss: 2.1788828988229074

Epoch: 6| Step: 3
Training loss: 1.9606032371520996
Validation loss: 2.1500279108683267

Epoch: 6| Step: 4
Training loss: 1.5212576389312744
Validation loss: 2.1465330867357153

Epoch: 6| Step: 5
Training loss: 2.0747861862182617
Validation loss: 2.09539092997069

Epoch: 6| Step: 6
Training loss: 1.9055683612823486
Validation loss: 2.1463748806266376

Epoch: 6| Step: 7
Training loss: 2.6425952911376953
Validation loss: 2.1230431090119066

Epoch: 6| Step: 8
Training loss: 1.839721441268921
Validation loss: 2.2231928892033075

Epoch: 6| Step: 9
Training loss: 1.4912099838256836
Validation loss: 2.143688419813751

Epoch: 6| Step: 10
Training loss: 2.2481651306152344
Validation loss: 2.164860753602879

Epoch: 6| Step: 11
Training loss: 2.633619546890259
Validation loss: 2.211871882920624

Epoch: 6| Step: 12
Training loss: 2.453401803970337
Validation loss: 2.1812884794768466

Epoch: 6| Step: 13
Training loss: 1.282698154449463
Validation loss: 2.224660878540367

Epoch: 319| Step: 0
Training loss: 2.315582752227783
Validation loss: 2.1946298896625476

Epoch: 6| Step: 1
Training loss: 2.48532772064209
Validation loss: 2.19319135655639

Epoch: 6| Step: 2
Training loss: 2.0994136333465576
Validation loss: 2.1777870001331454

Epoch: 6| Step: 3
Training loss: 1.7668418884277344
Validation loss: 2.194314620828116

Epoch: 6| Step: 4
Training loss: 1.0992190837860107
Validation loss: 2.1514213995266984

Epoch: 6| Step: 5
Training loss: 1.4628123044967651
Validation loss: 2.1252139576019777

Epoch: 6| Step: 6
Training loss: 2.422250509262085
Validation loss: 2.192464982309649

Epoch: 6| Step: 7
Training loss: 1.6789658069610596
Validation loss: 2.181834233704434

Epoch: 6| Step: 8
Training loss: 1.868665337562561
Validation loss: 2.1242090027819396

Epoch: 6| Step: 9
Training loss: 1.928053855895996
Validation loss: 2.134151609995032

Epoch: 6| Step: 10
Training loss: 1.805275321006775
Validation loss: 2.1626541511986845

Epoch: 6| Step: 11
Training loss: 2.5061511993408203
Validation loss: 2.104892582021734

Epoch: 6| Step: 12
Training loss: 1.3937182426452637
Validation loss: 2.0522195395602973

Epoch: 6| Step: 13
Training loss: 2.3479650020599365
Validation loss: 2.079533847429419

Epoch: 320| Step: 0
Training loss: 1.9927828311920166
Validation loss: 2.074012997329876

Epoch: 6| Step: 1
Training loss: 2.438890218734741
Validation loss: 2.1176048248044905

Epoch: 6| Step: 2
Training loss: 1.2570425271987915
Validation loss: 2.175853413920249

Epoch: 6| Step: 3
Training loss: 1.7181329727172852
Validation loss: 2.0639740164561937

Epoch: 6| Step: 4
Training loss: 1.3961071968078613
Validation loss: 2.0993034954993957

Epoch: 6| Step: 5
Training loss: 2.400367498397827
Validation loss: 2.053517549268661

Epoch: 6| Step: 6
Training loss: 2.025465965270996
Validation loss: 2.091517330497824

Epoch: 6| Step: 7
Training loss: 2.0688819885253906
Validation loss: 2.147271058892691

Epoch: 6| Step: 8
Training loss: 2.31868577003479
Validation loss: 2.0936751622025684

Epoch: 6| Step: 9
Training loss: 1.7064210176467896
Validation loss: 2.1353152669886106

Epoch: 6| Step: 10
Training loss: 1.887366533279419
Validation loss: 2.1090519633344424

Epoch: 6| Step: 11
Training loss: 2.1708619594573975
Validation loss: 2.098090269232309

Epoch: 6| Step: 12
Training loss: 1.9821913242340088
Validation loss: 2.1649691904744794

Epoch: 6| Step: 13
Training loss: 1.6355348825454712
Validation loss: 2.120129321211128

Epoch: 321| Step: 0
Training loss: 2.2275404930114746
Validation loss: 2.1360011869861233

Epoch: 6| Step: 1
Training loss: 2.545276165008545
Validation loss: 2.0536470438844416

Epoch: 6| Step: 2
Training loss: 2.0156452655792236
Validation loss: 2.1302212233184488

Epoch: 6| Step: 3
Training loss: 2.155869960784912
Validation loss: 2.104081217960645

Epoch: 6| Step: 4
Training loss: 2.006985664367676
Validation loss: 2.11121230740701

Epoch: 6| Step: 5
Training loss: 2.183682918548584
Validation loss: 2.153419258773968

Epoch: 6| Step: 6
Training loss: 1.6927560567855835
Validation loss: 2.1000830152983307

Epoch: 6| Step: 7
Training loss: 1.9096298217773438
Validation loss: 2.175228129151047

Epoch: 6| Step: 8
Training loss: 1.2863476276397705
Validation loss: 2.1497842086258756

Epoch: 6| Step: 9
Training loss: 2.2138848304748535
Validation loss: 2.0825437461176226

Epoch: 6| Step: 10
Training loss: 2.423966646194458
Validation loss: 2.132808227692881

Epoch: 6| Step: 11
Training loss: 1.8744523525238037
Validation loss: 2.083315445530799

Epoch: 6| Step: 12
Training loss: 1.3023309707641602
Validation loss: 2.083667355199014

Epoch: 6| Step: 13
Training loss: 0.917425811290741
Validation loss: 2.1151553635956137

Epoch: 322| Step: 0
Training loss: 2.405884265899658
Validation loss: 2.1188465613190846

Epoch: 6| Step: 1
Training loss: 2.453997850418091
Validation loss: 2.128759608473829

Epoch: 6| Step: 2
Training loss: 1.7609046697616577
Validation loss: 2.15280419523998

Epoch: 6| Step: 3
Training loss: 1.6675398349761963
Validation loss: 2.0958407245656496

Epoch: 6| Step: 4
Training loss: 2.1367344856262207
Validation loss: 2.110990415337265

Epoch: 6| Step: 5
Training loss: 1.8644070625305176
Validation loss: 2.1438258130063295

Epoch: 6| Step: 6
Training loss: 1.9519085884094238
Validation loss: 2.091063278977589

Epoch: 6| Step: 7
Training loss: 1.9318903684616089
Validation loss: 2.163419654292445

Epoch: 6| Step: 8
Training loss: 1.9465723037719727
Validation loss: 2.1738940362007386

Epoch: 6| Step: 9
Training loss: 1.548891544342041
Validation loss: 2.117220850401027

Epoch: 6| Step: 10
Training loss: 2.0117475986480713
Validation loss: 2.1755644582932994

Epoch: 6| Step: 11
Training loss: 1.4707345962524414
Validation loss: 2.14276708069668

Epoch: 6| Step: 12
Training loss: 2.540029525756836
Validation loss: 2.088414974110101

Epoch: 6| Step: 13
Training loss: 1.8830792903900146
Validation loss: 2.116774200111307

Epoch: 323| Step: 0
Training loss: 2.126023769378662
Validation loss: 2.102698620929513

Epoch: 6| Step: 1
Training loss: 2.6609699726104736
Validation loss: 2.1418306853181575

Epoch: 6| Step: 2
Training loss: 1.956791639328003
Validation loss: 2.13144899055522

Epoch: 6| Step: 3
Training loss: 1.8450639247894287
Validation loss: 2.1391111445683304

Epoch: 6| Step: 4
Training loss: 2.3579671382904053
Validation loss: 2.0992698105432654

Epoch: 6| Step: 5
Training loss: 2.0238852500915527
Validation loss: 2.131524121889504

Epoch: 6| Step: 6
Training loss: 1.9341049194335938
Validation loss: 2.15768595921096

Epoch: 6| Step: 7
Training loss: 1.6363003253936768
Validation loss: 2.157724344602195

Epoch: 6| Step: 8
Training loss: 1.8973665237426758
Validation loss: 2.180014471853933

Epoch: 6| Step: 9
Training loss: 1.6830534934997559
Validation loss: 2.1609071864876697

Epoch: 6| Step: 10
Training loss: 1.6199336051940918
Validation loss: 2.1978074453210317

Epoch: 6| Step: 11
Training loss: 2.3415637016296387
Validation loss: 2.1328211420325824

Epoch: 6| Step: 12
Training loss: 1.8298722505569458
Validation loss: 2.13492384008182

Epoch: 6| Step: 13
Training loss: 1.283007264137268
Validation loss: 2.174274198470577

Epoch: 324| Step: 0
Training loss: 2.4273738861083984
Validation loss: 2.1598965532036236

Epoch: 6| Step: 1
Training loss: 1.652574062347412
Validation loss: 2.141436593506926

Epoch: 6| Step: 2
Training loss: 2.3576736450195312
Validation loss: 2.1511126692577074

Epoch: 6| Step: 3
Training loss: 1.8789513111114502
Validation loss: 2.0721700447861866

Epoch: 6| Step: 4
Training loss: 2.405150890350342
Validation loss: 2.101799561131385

Epoch: 6| Step: 5
Training loss: 1.3332492113113403
Validation loss: 2.155845603635234

Epoch: 6| Step: 6
Training loss: 1.716200590133667
Validation loss: 2.14744161405871

Epoch: 6| Step: 7
Training loss: 2.7860183715820312
Validation loss: 2.1301750329232987

Epoch: 6| Step: 8
Training loss: 1.3260406255722046
Validation loss: 2.118411830676499

Epoch: 6| Step: 9
Training loss: 1.923386812210083
Validation loss: 2.081415558374056

Epoch: 6| Step: 10
Training loss: 1.9162838459014893
Validation loss: 2.107085948349327

Epoch: 6| Step: 11
Training loss: 2.0294668674468994
Validation loss: 2.098394686175931

Epoch: 6| Step: 12
Training loss: 1.6972973346710205
Validation loss: 2.079130580348353

Epoch: 6| Step: 13
Training loss: 1.0146327018737793
Validation loss: 2.1121360332735124

Epoch: 325| Step: 0
Training loss: 1.3407845497131348
Validation loss: 2.083769247096072

Epoch: 6| Step: 1
Training loss: 2.084629535675049
Validation loss: 2.0659400647686375

Epoch: 6| Step: 2
Training loss: 2.662797451019287
Validation loss: 2.0913682778676352

Epoch: 6| Step: 3
Training loss: 1.9028594493865967
Validation loss: 2.13122546544639

Epoch: 6| Step: 4
Training loss: 1.5312108993530273
Validation loss: 2.1507878713710333

Epoch: 6| Step: 5
Training loss: 2.068187713623047
Validation loss: 2.137884114378242

Epoch: 6| Step: 6
Training loss: 1.9338198900222778
Validation loss: 2.057830645192054

Epoch: 6| Step: 7
Training loss: 2.241413116455078
Validation loss: 2.0689428647359214

Epoch: 6| Step: 8
Training loss: 1.950669527053833
Validation loss: 2.052463621221563

Epoch: 6| Step: 9
Training loss: 2.0318922996520996
Validation loss: 2.152646126285676

Epoch: 6| Step: 10
Training loss: 1.4251792430877686
Validation loss: 2.160652586208877

Epoch: 6| Step: 11
Training loss: 1.9916646480560303
Validation loss: 2.140241351178897

Epoch: 6| Step: 12
Training loss: 2.572045087814331
Validation loss: 2.1612024332887385

Epoch: 6| Step: 13
Training loss: 1.7415995597839355
Validation loss: 2.1309902373180596

Epoch: 326| Step: 0
Training loss: 1.7292110919952393
Validation loss: 2.1526762785450106

Epoch: 6| Step: 1
Training loss: 1.368598222732544
Validation loss: 2.1774582145034627

Epoch: 6| Step: 2
Training loss: 2.038100481033325
Validation loss: 2.1598033930665705

Epoch: 6| Step: 3
Training loss: 1.9770126342773438
Validation loss: 2.1310886926548456

Epoch: 6| Step: 4
Training loss: 1.5951926708221436
Validation loss: 2.195393919944763

Epoch: 6| Step: 5
Training loss: 1.6875571012496948
Validation loss: 2.2220047289325344

Epoch: 6| Step: 6
Training loss: 1.9085646867752075
Validation loss: 2.1866959525692846

Epoch: 6| Step: 7
Training loss: 1.6628832817077637
Validation loss: 2.150437767787646

Epoch: 6| Step: 8
Training loss: 1.994031548500061
Validation loss: 2.222724886350734

Epoch: 6| Step: 9
Training loss: 2.408906936645508
Validation loss: 2.1743789872815533

Epoch: 6| Step: 10
Training loss: 2.4229912757873535
Validation loss: 2.2478832403818765

Epoch: 6| Step: 11
Training loss: 2.2777485847473145
Validation loss: 2.1968810814683155

Epoch: 6| Step: 12
Training loss: 2.503905773162842
Validation loss: 2.211628108896235

Epoch: 6| Step: 13
Training loss: 2.756497859954834
Validation loss: 2.181553622727753

Epoch: 327| Step: 0
Training loss: 1.9782825708389282
Validation loss: 2.1948004127830587

Epoch: 6| Step: 1
Training loss: 1.5397391319274902
Validation loss: 2.142064232980051

Epoch: 6| Step: 2
Training loss: 2.011449098587036
Validation loss: 2.136948547055644

Epoch: 6| Step: 3
Training loss: 1.8761006593704224
Validation loss: 2.1580461455929663

Epoch: 6| Step: 4
Training loss: 1.500871181488037
Validation loss: 2.1280548623813096

Epoch: 6| Step: 5
Training loss: 1.0373492240905762
Validation loss: 2.1464833777437926

Epoch: 6| Step: 6
Training loss: 2.1526927947998047
Validation loss: 2.168475563808154

Epoch: 6| Step: 7
Training loss: 2.2224013805389404
Validation loss: 2.1038767535199403

Epoch: 6| Step: 8
Training loss: 1.9732882976531982
Validation loss: 2.0975682094532955

Epoch: 6| Step: 9
Training loss: 1.9171619415283203
Validation loss: 2.2073663691038727

Epoch: 6| Step: 10
Training loss: 1.4003742933273315
Validation loss: 2.0797315643679712

Epoch: 6| Step: 11
Training loss: 2.5736427307128906
Validation loss: 2.124213262270856

Epoch: 6| Step: 12
Training loss: 2.557119846343994
Validation loss: 2.077172940777194

Epoch: 6| Step: 13
Training loss: 2.546908378601074
Validation loss: 2.153954654611567

Epoch: 328| Step: 0
Training loss: 1.3789045810699463
Validation loss: 2.16459031515224

Epoch: 6| Step: 1
Training loss: 1.5635048151016235
Validation loss: 2.1017056613840084

Epoch: 6| Step: 2
Training loss: 1.4523528814315796
Validation loss: 2.0857655591862176

Epoch: 6| Step: 3
Training loss: 2.14835786819458
Validation loss: 2.129823197600662

Epoch: 6| Step: 4
Training loss: 2.173522472381592
Validation loss: 2.1318160231395433

Epoch: 6| Step: 5
Training loss: 2.001697540283203
Validation loss: 2.1349272753602717

Epoch: 6| Step: 6
Training loss: 1.5470876693725586
Validation loss: 2.075428714034378

Epoch: 6| Step: 7
Training loss: 2.4391822814941406
Validation loss: 2.1314149338711976

Epoch: 6| Step: 8
Training loss: 2.0935730934143066
Validation loss: 2.0804216938634075

Epoch: 6| Step: 9
Training loss: 2.2377371788024902
Validation loss: 2.1350137905407975

Epoch: 6| Step: 10
Training loss: 1.7762432098388672
Validation loss: 2.1415119042960544

Epoch: 6| Step: 11
Training loss: 1.9551289081573486
Validation loss: 2.091262596909718

Epoch: 6| Step: 12
Training loss: 2.0824482440948486
Validation loss: 2.1084953854160924

Epoch: 6| Step: 13
Training loss: 2.0110371112823486
Validation loss: 2.181712219792028

Epoch: 329| Step: 0
Training loss: 2.3434157371520996
Validation loss: 2.146158769566526

Epoch: 6| Step: 1
Training loss: 2.2222728729248047
Validation loss: 2.1569039578078897

Epoch: 6| Step: 2
Training loss: 1.8211296796798706
Validation loss: 2.1473596275493665

Epoch: 6| Step: 3
Training loss: 1.4521558284759521
Validation loss: 2.187902540288946

Epoch: 6| Step: 4
Training loss: 2.089134931564331
Validation loss: 2.1153567901221653

Epoch: 6| Step: 5
Training loss: 2.144108295440674
Validation loss: 2.17478500130356

Epoch: 6| Step: 6
Training loss: 2.0284769535064697
Validation loss: 2.078939009738225

Epoch: 6| Step: 7
Training loss: 3.0238213539123535
Validation loss: 2.057896655092957

Epoch: 6| Step: 8
Training loss: 2.4634857177734375
Validation loss: 2.1438282125739643

Epoch: 6| Step: 9
Training loss: 1.8186053037643433
Validation loss: 2.149785592991819

Epoch: 6| Step: 10
Training loss: 1.749582290649414
Validation loss: 2.1430100446106284

Epoch: 6| Step: 11
Training loss: 1.1913800239562988
Validation loss: 2.1196745467442337

Epoch: 6| Step: 12
Training loss: 1.429329514503479
Validation loss: 2.125263150020312

Epoch: 6| Step: 13
Training loss: 1.6769754886627197
Validation loss: 2.1136051531760924

Epoch: 330| Step: 0
Training loss: 1.5186657905578613
Validation loss: 2.156404185038741

Epoch: 6| Step: 1
Training loss: 2.599370002746582
Validation loss: 2.13847662684738

Epoch: 6| Step: 2
Training loss: 1.449568271636963
Validation loss: 2.091795350915642

Epoch: 6| Step: 3
Training loss: 2.0894598960876465
Validation loss: 2.1615972108738397

Epoch: 6| Step: 4
Training loss: 2.3344788551330566
Validation loss: 2.1303284834789973

Epoch: 6| Step: 5
Training loss: 1.8755143880844116
Validation loss: 2.123986836402647

Epoch: 6| Step: 6
Training loss: 1.6293179988861084
Validation loss: 2.1294569482085524

Epoch: 6| Step: 7
Training loss: 1.691074252128601
Validation loss: 2.167567883768389

Epoch: 6| Step: 8
Training loss: 2.3590469360351562
Validation loss: 2.117216097411289

Epoch: 6| Step: 9
Training loss: 2.7807457447052
Validation loss: 2.0886753592439877

Epoch: 6| Step: 10
Training loss: 1.7126095294952393
Validation loss: 2.141471234701013

Epoch: 6| Step: 11
Training loss: 2.1331169605255127
Validation loss: 2.164523273385981

Epoch: 6| Step: 12
Training loss: 1.4485843181610107
Validation loss: 2.1568837858015493

Epoch: 6| Step: 13
Training loss: 0.7760164737701416
Validation loss: 2.155073973440355

Epoch: 331| Step: 0
Training loss: 1.6470835208892822
Validation loss: 2.0890942260783207

Epoch: 6| Step: 1
Training loss: 2.5499515533447266
Validation loss: 2.1081089511994393

Epoch: 6| Step: 2
Training loss: 2.2320690155029297
Validation loss: 2.132913822768837

Epoch: 6| Step: 3
Training loss: 2.1373016834259033
Validation loss: 2.1578498655749905

Epoch: 6| Step: 4
Training loss: 1.7724437713623047
Validation loss: 2.16756837086011

Epoch: 6| Step: 5
Training loss: 1.8357754945755005
Validation loss: 2.1312530220195813

Epoch: 6| Step: 6
Training loss: 1.5265226364135742
Validation loss: 2.1560710553200013

Epoch: 6| Step: 7
Training loss: 1.78938889503479
Validation loss: 2.074030413422533

Epoch: 6| Step: 8
Training loss: 2.157130479812622
Validation loss: 2.12987825434695

Epoch: 6| Step: 9
Training loss: 1.443656325340271
Validation loss: 2.0992917194161365

Epoch: 6| Step: 10
Training loss: 2.690889358520508
Validation loss: 2.067612369855245

Epoch: 6| Step: 11
Training loss: 2.2572193145751953
Validation loss: 2.183211775236232

Epoch: 6| Step: 12
Training loss: 1.5639593601226807
Validation loss: 2.0965653568185787

Epoch: 6| Step: 13
Training loss: 1.5406081676483154
Validation loss: 2.112071185983637

Epoch: 332| Step: 0
Training loss: 1.583852767944336
Validation loss: 2.108878010062761

Epoch: 6| Step: 1
Training loss: 1.6407675743103027
Validation loss: 2.148893040995444

Epoch: 6| Step: 2
Training loss: 1.7562425136566162
Validation loss: 2.073091399285101

Epoch: 6| Step: 3
Training loss: 2.6552906036376953
Validation loss: 2.1255331731611684

Epoch: 6| Step: 4
Training loss: 2.0429041385650635
Validation loss: 2.204376769322221

Epoch: 6| Step: 5
Training loss: 1.9345369338989258
Validation loss: 2.105366345374815

Epoch: 6| Step: 6
Training loss: 1.7463176250457764
Validation loss: 2.0952327225797918

Epoch: 6| Step: 7
Training loss: 1.8396413326263428
Validation loss: 2.117910995278307

Epoch: 6| Step: 8
Training loss: 1.5637551546096802
Validation loss: 2.1497869953032462

Epoch: 6| Step: 9
Training loss: 1.9905178546905518
Validation loss: 2.1086796329867457

Epoch: 6| Step: 10
Training loss: 2.326723098754883
Validation loss: 2.048846895976733

Epoch: 6| Step: 11
Training loss: 1.7708570957183838
Validation loss: 2.0744311578812136

Epoch: 6| Step: 12
Training loss: 1.9039071798324585
Validation loss: 2.1390112036017963

Epoch: 6| Step: 13
Training loss: 2.120345115661621
Validation loss: 2.1134279581808273

Epoch: 333| Step: 0
Training loss: 1.651969313621521
Validation loss: 2.1161448622262604

Epoch: 6| Step: 1
Training loss: 1.6976815462112427
Validation loss: 2.0741116077669206

Epoch: 6| Step: 2
Training loss: 1.8051283359527588
Validation loss: 2.1289612400916313

Epoch: 6| Step: 3
Training loss: 1.0982996225357056
Validation loss: 2.107267834806955

Epoch: 6| Step: 4
Training loss: 2.5047006607055664
Validation loss: 2.1489109710980485

Epoch: 6| Step: 5
Training loss: 2.4880871772766113
Validation loss: 2.116598431782056

Epoch: 6| Step: 6
Training loss: 2.4474620819091797
Validation loss: 2.1020910393807197

Epoch: 6| Step: 7
Training loss: 1.7658213376998901
Validation loss: 2.098987812637001

Epoch: 6| Step: 8
Training loss: 2.8253798484802246
Validation loss: 2.0645492589601906

Epoch: 6| Step: 9
Training loss: 1.8928440809249878
Validation loss: 2.1153865450172016

Epoch: 6| Step: 10
Training loss: 1.976489543914795
Validation loss: 2.1294223364963325

Epoch: 6| Step: 11
Training loss: 2.1466219425201416
Validation loss: 2.1664808206660773

Epoch: 6| Step: 12
Training loss: 1.436587929725647
Validation loss: 2.098276222905805

Epoch: 6| Step: 13
Training loss: 1.1656689643859863
Validation loss: 2.1338203440430346

Epoch: 334| Step: 0
Training loss: 1.4585686922073364
Validation loss: 2.161268493180634

Epoch: 6| Step: 1
Training loss: 1.181537389755249
Validation loss: 2.084528802543558

Epoch: 6| Step: 2
Training loss: 1.8213692903518677
Validation loss: 2.197042149882163

Epoch: 6| Step: 3
Training loss: 1.4773797988891602
Validation loss: 2.1080637977969263

Epoch: 6| Step: 4
Training loss: 2.0105509757995605
Validation loss: 2.1574133801203903

Epoch: 6| Step: 5
Training loss: 2.4212777614593506
Validation loss: 2.17192199666013

Epoch: 6| Step: 6
Training loss: 1.7095844745635986
Validation loss: 2.198965376423251

Epoch: 6| Step: 7
Training loss: 2.059089183807373
Validation loss: 2.158028999964396

Epoch: 6| Step: 8
Training loss: 2.0665335655212402
Validation loss: 2.181713782330995

Epoch: 6| Step: 9
Training loss: 2.56502628326416
Validation loss: 2.1614237754575667

Epoch: 6| Step: 10
Training loss: 2.5466361045837402
Validation loss: 2.1863903794237363

Epoch: 6| Step: 11
Training loss: 2.1780595779418945
Validation loss: 2.0993383020483036

Epoch: 6| Step: 12
Training loss: 1.3882102966308594
Validation loss: 2.171172288156325

Epoch: 6| Step: 13
Training loss: 2.093296527862549
Validation loss: 2.1606761345299343

Epoch: 335| Step: 0
Training loss: 2.190195083618164
Validation loss: 2.171262461652038

Epoch: 6| Step: 1
Training loss: 2.229848861694336
Validation loss: 2.1308018392132175

Epoch: 6| Step: 2
Training loss: 2.167664051055908
Validation loss: 2.1311067611940446

Epoch: 6| Step: 3
Training loss: 0.977952778339386
Validation loss: 2.1442416508992515

Epoch: 6| Step: 4
Training loss: 2.0540709495544434
Validation loss: 2.179665101471768

Epoch: 6| Step: 5
Training loss: 1.5718121528625488
Validation loss: 2.086311965860346

Epoch: 6| Step: 6
Training loss: 1.5875871181488037
Validation loss: 2.150248207071776

Epoch: 6| Step: 7
Training loss: 2.2032761573791504
Validation loss: 2.071259116613737

Epoch: 6| Step: 8
Training loss: 2.2734122276306152
Validation loss: 2.132034786285893

Epoch: 6| Step: 9
Training loss: 2.1268906593322754
Validation loss: 2.1089884235012915

Epoch: 6| Step: 10
Training loss: 2.2121291160583496
Validation loss: 2.1381935957939393

Epoch: 6| Step: 11
Training loss: 1.2411800622940063
Validation loss: 2.0911498428672872

Epoch: 6| Step: 12
Training loss: 1.846095323562622
Validation loss: 2.15141123853704

Epoch: 6| Step: 13
Training loss: 2.1018455028533936
Validation loss: 2.1932900541572162

Epoch: 336| Step: 0
Training loss: 2.213853359222412
Validation loss: 2.1687786720132314

Epoch: 6| Step: 1
Training loss: 1.9427056312561035
Validation loss: 2.0992138437045518

Epoch: 6| Step: 2
Training loss: 1.6411291360855103
Validation loss: 2.1057428339476227

Epoch: 6| Step: 3
Training loss: 1.588700532913208
Validation loss: 2.135779337216449

Epoch: 6| Step: 4
Training loss: 1.7871882915496826
Validation loss: 2.147898894484325

Epoch: 6| Step: 5
Training loss: 1.9183992147445679
Validation loss: 2.1532618076570573

Epoch: 6| Step: 6
Training loss: 1.4759509563446045
Validation loss: 2.0856114856658445

Epoch: 6| Step: 7
Training loss: 1.9056410789489746
Validation loss: 2.0486320398187123

Epoch: 6| Step: 8
Training loss: 1.5000905990600586
Validation loss: 2.0426236621795164

Epoch: 6| Step: 9
Training loss: 2.1080589294433594
Validation loss: 2.0985402291820896

Epoch: 6| Step: 10
Training loss: 1.7660690546035767
Validation loss: 2.1078072901695006

Epoch: 6| Step: 11
Training loss: 3.1712114810943604
Validation loss: 2.1129234965129564

Epoch: 6| Step: 12
Training loss: 1.6936895847320557
Validation loss: 2.1303775489971204

Epoch: 6| Step: 13
Training loss: 2.7700283527374268
Validation loss: 2.111772096285256

Epoch: 337| Step: 0
Training loss: 2.045367479324341
Validation loss: 2.0992208783344557

Epoch: 6| Step: 1
Training loss: 1.6841273307800293
Validation loss: 2.1894206898186797

Epoch: 6| Step: 2
Training loss: 1.599799633026123
Validation loss: 2.122497561157391

Epoch: 6| Step: 3
Training loss: 1.93070387840271
Validation loss: 2.118593828652495

Epoch: 6| Step: 4
Training loss: 2.3978772163391113
Validation loss: 2.127790968905213

Epoch: 6| Step: 5
Training loss: 2.091439962387085
Validation loss: 2.0668042513632003

Epoch: 6| Step: 6
Training loss: 1.7523770332336426
Validation loss: 2.070424022213105

Epoch: 6| Step: 7
Training loss: 1.2868330478668213
Validation loss: 2.1578117262932563

Epoch: 6| Step: 8
Training loss: 2.30041241645813
Validation loss: 2.1447675907483665

Epoch: 6| Step: 9
Training loss: 2.326782464981079
Validation loss: 2.096574467997397

Epoch: 6| Step: 10
Training loss: 2.271712303161621
Validation loss: 2.127032861914686

Epoch: 6| Step: 11
Training loss: 1.3740209341049194
Validation loss: 2.1139298459535003

Epoch: 6| Step: 12
Training loss: 1.4922432899475098
Validation loss: 2.1245245318258963

Epoch: 6| Step: 13
Training loss: 2.4744651317596436
Validation loss: 2.1621163109297394

Epoch: 338| Step: 0
Training loss: 1.828667402267456
Validation loss: 2.160859095152988

Epoch: 6| Step: 1
Training loss: 1.6946245431900024
Validation loss: 2.1711536658707487

Epoch: 6| Step: 2
Training loss: 1.7830626964569092
Validation loss: 2.0791731854920745

Epoch: 6| Step: 3
Training loss: 1.8430066108703613
Validation loss: 2.1354864335829213

Epoch: 6| Step: 4
Training loss: 2.0012526512145996
Validation loss: 2.1205665347396687

Epoch: 6| Step: 5
Training loss: 2.3288538455963135
Validation loss: 2.146834159410128

Epoch: 6| Step: 6
Training loss: 2.5463571548461914
Validation loss: 2.1268765695633425

Epoch: 6| Step: 7
Training loss: 1.431879997253418
Validation loss: 2.146851396047941

Epoch: 6| Step: 8
Training loss: 2.173358201980591
Validation loss: 2.1055332229983423

Epoch: 6| Step: 9
Training loss: 1.8606476783752441
Validation loss: 2.0608918730930617

Epoch: 6| Step: 10
Training loss: 1.1410168409347534
Validation loss: 2.10110657189482

Epoch: 6| Step: 11
Training loss: 2.2968664169311523
Validation loss: 2.1242215389846475

Epoch: 6| Step: 12
Training loss: 1.5077422857284546
Validation loss: 2.121571763869255

Epoch: 6| Step: 13
Training loss: 2.604703187942505
Validation loss: 2.0932038830172632

Epoch: 339| Step: 0
Training loss: 2.0663185119628906
Validation loss: 2.1040765777710946

Epoch: 6| Step: 1
Training loss: 1.7256299257278442
Validation loss: 2.087680724359328

Epoch: 6| Step: 2
Training loss: 1.5717699527740479
Validation loss: 2.125147465736635

Epoch: 6| Step: 3
Training loss: 1.897665023803711
Validation loss: 2.1180242851216304

Epoch: 6| Step: 4
Training loss: 2.2497801780700684
Validation loss: 2.0492660384024344

Epoch: 6| Step: 5
Training loss: 2.5517373085021973
Validation loss: 2.090199488465504

Epoch: 6| Step: 6
Training loss: 1.7572734355926514
Validation loss: 2.124823921470232

Epoch: 6| Step: 7
Training loss: 1.8625926971435547
Validation loss: 2.0815621281182892

Epoch: 6| Step: 8
Training loss: 1.6795614957809448
Validation loss: 2.0597997711550806

Epoch: 6| Step: 9
Training loss: 2.150237560272217
Validation loss: 2.1103852436106694

Epoch: 6| Step: 10
Training loss: 1.6000699996948242
Validation loss: 2.1353752651522235

Epoch: 6| Step: 11
Training loss: 1.6040477752685547
Validation loss: 2.0854616652252855

Epoch: 6| Step: 12
Training loss: 1.410112738609314
Validation loss: 2.078224766638971

Epoch: 6| Step: 13
Training loss: 2.8142504692077637
Validation loss: 2.1100672419353197

Epoch: 340| Step: 0
Training loss: 2.0788636207580566
Validation loss: 2.03154585694754

Epoch: 6| Step: 1
Training loss: 2.229738712310791
Validation loss: 2.1394890457071285

Epoch: 6| Step: 2
Training loss: 1.916939616203308
Validation loss: 2.16096233296138

Epoch: 6| Step: 3
Training loss: 1.742919921875
Validation loss: 2.1036654595405824

Epoch: 6| Step: 4
Training loss: 2.0806884765625
Validation loss: 2.125923696384635

Epoch: 6| Step: 5
Training loss: 1.8177616596221924
Validation loss: 2.1797339044591433

Epoch: 6| Step: 6
Training loss: 1.9580965042114258
Validation loss: 2.1863515889772804

Epoch: 6| Step: 7
Training loss: 1.712761402130127
Validation loss: 2.1311715187564975

Epoch: 6| Step: 8
Training loss: 1.979047417640686
Validation loss: 2.1001187037396174

Epoch: 6| Step: 9
Training loss: 1.7400420904159546
Validation loss: 2.0856901138059554

Epoch: 6| Step: 10
Training loss: 2.5564000606536865
Validation loss: 2.1096228425220778

Epoch: 6| Step: 11
Training loss: 1.7495684623718262
Validation loss: 2.1763430615907073

Epoch: 6| Step: 12
Training loss: 1.6028058528900146
Validation loss: 2.1545924948107813

Epoch: 6| Step: 13
Training loss: 2.297065496444702
Validation loss: 2.103899171275477

Epoch: 341| Step: 0
Training loss: 2.0183000564575195
Validation loss: 2.1110076622296403

Epoch: 6| Step: 1
Training loss: 2.4406650066375732
Validation loss: 2.1044303806879188

Epoch: 6| Step: 2
Training loss: 1.8404011726379395
Validation loss: 2.1203439440778507

Epoch: 6| Step: 3
Training loss: 1.8993674516677856
Validation loss: 2.1579027355358167

Epoch: 6| Step: 4
Training loss: 1.7904694080352783
Validation loss: 2.1850404867561917

Epoch: 6| Step: 5
Training loss: 1.9082157611846924
Validation loss: 2.1640290278260426

Epoch: 6| Step: 6
Training loss: 1.2726130485534668
Validation loss: 2.149763053463351

Epoch: 6| Step: 7
Training loss: 1.8499741554260254
Validation loss: 2.131107596940892

Epoch: 6| Step: 8
Training loss: 2.184298276901245
Validation loss: 2.085119298709336

Epoch: 6| Step: 9
Training loss: 1.8384672403335571
Validation loss: 2.118034706320814

Epoch: 6| Step: 10
Training loss: 1.6593281030654907
Validation loss: 2.136026600355743

Epoch: 6| Step: 11
Training loss: 2.477235794067383
Validation loss: 2.1526780974480415

Epoch: 6| Step: 12
Training loss: 1.9808855056762695
Validation loss: 2.2112995296396236

Epoch: 6| Step: 13
Training loss: 2.219129800796509
Validation loss: 2.224766728698566

Epoch: 342| Step: 0
Training loss: 2.2851693630218506
Validation loss: 2.1635306240409933

Epoch: 6| Step: 1
Training loss: 2.002821683883667
Validation loss: 2.175284226735433

Epoch: 6| Step: 2
Training loss: 2.076653480529785
Validation loss: 2.085546839621759

Epoch: 6| Step: 3
Training loss: 1.460936427116394
Validation loss: 2.1988042939093804

Epoch: 6| Step: 4
Training loss: 1.5946381092071533
Validation loss: 2.1056603975193475

Epoch: 6| Step: 5
Training loss: 1.694319248199463
Validation loss: 2.1448086128439954

Epoch: 6| Step: 6
Training loss: 2.567389488220215
Validation loss: 2.1133658334773076

Epoch: 6| Step: 7
Training loss: 1.8012351989746094
Validation loss: 2.1013993127371675

Epoch: 6| Step: 8
Training loss: 1.7841956615447998
Validation loss: 2.1493362508794314

Epoch: 6| Step: 9
Training loss: 1.7089617252349854
Validation loss: 2.1331724889816774

Epoch: 6| Step: 10
Training loss: 1.65496826171875
Validation loss: 2.100585163280528

Epoch: 6| Step: 11
Training loss: 1.9640216827392578
Validation loss: 2.1546089264654342

Epoch: 6| Step: 12
Training loss: 1.8246479034423828
Validation loss: 2.1711321492348947

Epoch: 6| Step: 13
Training loss: 2.45180606842041
Validation loss: 2.106914327990624

Epoch: 343| Step: 0
Training loss: 1.6794270277023315
Validation loss: 2.1465352222483647

Epoch: 6| Step: 1
Training loss: 1.2080354690551758
Validation loss: 2.1315972740932176

Epoch: 6| Step: 2
Training loss: 1.9722908735275269
Validation loss: 2.076327746914279

Epoch: 6| Step: 3
Training loss: 2.4890260696411133
Validation loss: 2.1378919616822274

Epoch: 6| Step: 4
Training loss: 1.4538393020629883
Validation loss: 2.1510023840012087

Epoch: 6| Step: 5
Training loss: 2.3784823417663574
Validation loss: 2.19672707972988

Epoch: 6| Step: 6
Training loss: 2.453126907348633
Validation loss: 2.078723453706311

Epoch: 6| Step: 7
Training loss: 1.7842299938201904
Validation loss: 2.1477231697369645

Epoch: 6| Step: 8
Training loss: 2.0772080421447754
Validation loss: 2.170266453937818

Epoch: 6| Step: 9
Training loss: 2.266782760620117
Validation loss: 2.1521813023474907

Epoch: 6| Step: 10
Training loss: 2.1858983039855957
Validation loss: 2.0889585569340694

Epoch: 6| Step: 11
Training loss: 1.4177000522613525
Validation loss: 2.1075160080386746

Epoch: 6| Step: 12
Training loss: 1.59490168094635
Validation loss: 2.158505270558019

Epoch: 6| Step: 13
Training loss: 1.0198063850402832
Validation loss: 2.088932637245424

Epoch: 344| Step: 0
Training loss: 1.8759677410125732
Validation loss: 2.1410493799435195

Epoch: 6| Step: 1
Training loss: 2.1225085258483887
Validation loss: 2.1294039757021013

Epoch: 6| Step: 2
Training loss: 2.384335994720459
Validation loss: 2.137449659327025

Epoch: 6| Step: 3
Training loss: 1.5956735610961914
Validation loss: 2.1458965142567954

Epoch: 6| Step: 4
Training loss: 1.8349134922027588
Validation loss: 2.1697019171971146

Epoch: 6| Step: 5
Training loss: 2.3354034423828125
Validation loss: 2.127344072505992

Epoch: 6| Step: 6
Training loss: 1.6663053035736084
Validation loss: 2.108976992227698

Epoch: 6| Step: 7
Training loss: 1.1030203104019165
Validation loss: 2.108025791824505

Epoch: 6| Step: 8
Training loss: 1.5842337608337402
Validation loss: 2.1340394942991194

Epoch: 6| Step: 9
Training loss: 2.1166319847106934
Validation loss: 2.1765281205536215

Epoch: 6| Step: 10
Training loss: 1.8991813659667969
Validation loss: 2.147644773606331

Epoch: 6| Step: 11
Training loss: 1.7481529712677002
Validation loss: 2.14756437014508

Epoch: 6| Step: 12
Training loss: 2.3220748901367188
Validation loss: 2.1341459879311184

Epoch: 6| Step: 13
Training loss: 2.598405599594116
Validation loss: 2.134973790055962

Epoch: 345| Step: 0
Training loss: 1.3956798315048218
Validation loss: 2.102893239708357

Epoch: 6| Step: 1
Training loss: 1.8334835767745972
Validation loss: 2.0809754248588317

Epoch: 6| Step: 2
Training loss: 1.6502010822296143
Validation loss: 2.188656473672518

Epoch: 6| Step: 3
Training loss: 1.9427452087402344
Validation loss: 2.134873620925411

Epoch: 6| Step: 4
Training loss: 2.2695930004119873
Validation loss: 2.12926286010332

Epoch: 6| Step: 5
Training loss: 2.170907497406006
Validation loss: 2.141381755951912

Epoch: 6| Step: 6
Training loss: 1.4869825839996338
Validation loss: 2.136732316786243

Epoch: 6| Step: 7
Training loss: 1.8704296350479126
Validation loss: 2.11764875278678

Epoch: 6| Step: 8
Training loss: 2.521475076675415
Validation loss: 2.0894899265740507

Epoch: 6| Step: 9
Training loss: 1.8385926485061646
Validation loss: 2.13473508691275

Epoch: 6| Step: 10
Training loss: 1.5522087812423706
Validation loss: 2.0740277920999834

Epoch: 6| Step: 11
Training loss: 2.0167999267578125
Validation loss: 2.1193908747806343

Epoch: 6| Step: 12
Training loss: 1.9989714622497559
Validation loss: 2.1020064764125372

Epoch: 6| Step: 13
Training loss: 1.4021809101104736
Validation loss: 2.075067081759053

Epoch: 346| Step: 0
Training loss: 2.137838840484619
Validation loss: 2.08254559065706

Epoch: 6| Step: 1
Training loss: 2.0505223274230957
Validation loss: 2.1109458656721216

Epoch: 6| Step: 2
Training loss: 1.6412067413330078
Validation loss: 2.104065796380402

Epoch: 6| Step: 3
Training loss: 1.1803033351898193
Validation loss: 2.1067898299104426

Epoch: 6| Step: 4
Training loss: 2.291259765625
Validation loss: 2.1914166558173394

Epoch: 6| Step: 5
Training loss: 2.1566383838653564
Validation loss: 2.155357191639562

Epoch: 6| Step: 6
Training loss: 1.6410495042800903
Validation loss: 2.2360201843323244

Epoch: 6| Step: 7
Training loss: 1.6495821475982666
Validation loss: 2.070958051630246

Epoch: 6| Step: 8
Training loss: 1.8050808906555176
Validation loss: 2.2140800517092467

Epoch: 6| Step: 9
Training loss: 1.7196221351623535
Validation loss: 2.175293278950517

Epoch: 6| Step: 10
Training loss: 1.9645140171051025
Validation loss: 2.090337740477695

Epoch: 6| Step: 11
Training loss: 1.9274821281433105
Validation loss: 2.1465247907946186

Epoch: 6| Step: 12
Training loss: 2.1111161708831787
Validation loss: 2.1584838487768687

Epoch: 6| Step: 13
Training loss: 2.552481174468994
Validation loss: 2.169944381201139

Epoch: 347| Step: 0
Training loss: 1.8790342807769775
Validation loss: 2.0858402764925392

Epoch: 6| Step: 1
Training loss: 1.7392792701721191
Validation loss: 2.153681085955712

Epoch: 6| Step: 2
Training loss: 1.9906586408615112
Validation loss: 2.1729140922587407

Epoch: 6| Step: 3
Training loss: 1.8665602207183838
Validation loss: 2.141984911375148

Epoch: 6| Step: 4
Training loss: 2.1160988807678223
Validation loss: 2.1117167242111696

Epoch: 6| Step: 5
Training loss: 2.943056106567383
Validation loss: 2.1667111368589502

Epoch: 6| Step: 6
Training loss: 1.9631515741348267
Validation loss: 2.152300368073166

Epoch: 6| Step: 7
Training loss: 1.6516562700271606
Validation loss: 2.1808772394734044

Epoch: 6| Step: 8
Training loss: 2.0799694061279297
Validation loss: 2.118702739797613

Epoch: 6| Step: 9
Training loss: 1.8103251457214355
Validation loss: 2.089162749628867

Epoch: 6| Step: 10
Training loss: 2.0313925743103027
Validation loss: 2.09126309041054

Epoch: 6| Step: 11
Training loss: 0.9024971127510071
Validation loss: 2.183900999766524

Epoch: 6| Step: 12
Training loss: 2.0657200813293457
Validation loss: 2.2005127014652377

Epoch: 6| Step: 13
Training loss: 1.3425036668777466
Validation loss: 2.156818764184111

Epoch: 348| Step: 0
Training loss: 1.5382299423217773
Validation loss: 2.229240430298672

Epoch: 6| Step: 1
Training loss: 2.5462229251861572
Validation loss: 2.181159926999

Epoch: 6| Step: 2
Training loss: 1.7255496978759766
Validation loss: 2.128616626544665

Epoch: 6| Step: 3
Training loss: 2.054326295852661
Validation loss: 2.205769569643082

Epoch: 6| Step: 4
Training loss: 1.5727359056472778
Validation loss: 2.1540543148594518

Epoch: 6| Step: 5
Training loss: 1.5770384073257446
Validation loss: 2.175099031899565

Epoch: 6| Step: 6
Training loss: 2.471245765686035
Validation loss: 2.205083521463538

Epoch: 6| Step: 7
Training loss: 1.4232685565948486
Validation loss: 2.2371745763286466

Epoch: 6| Step: 8
Training loss: 2.43892765045166
Validation loss: 2.2618151326333322

Epoch: 6| Step: 9
Training loss: 2.154974937438965
Validation loss: 2.185764749844869

Epoch: 6| Step: 10
Training loss: 1.5389807224273682
Validation loss: 2.1774085824207594

Epoch: 6| Step: 11
Training loss: 1.4822384119033813
Validation loss: 2.155718611132714

Epoch: 6| Step: 12
Training loss: 2.0730044841766357
Validation loss: 2.153772518198977

Epoch: 6| Step: 13
Training loss: 2.126093864440918
Validation loss: 2.1403548589316745

Epoch: 349| Step: 0
Training loss: 2.447999954223633
Validation loss: 2.140536754362045

Epoch: 6| Step: 1
Training loss: 2.080472946166992
Validation loss: 2.1571374631697133

Epoch: 6| Step: 2
Training loss: 2.254570960998535
Validation loss: 2.080215287464921

Epoch: 6| Step: 3
Training loss: 1.256159782409668
Validation loss: 2.1530626230342413

Epoch: 6| Step: 4
Training loss: 1.1105811595916748
Validation loss: 2.1005290182687903

Epoch: 6| Step: 5
Training loss: 1.8810374736785889
Validation loss: 2.1643262370940177

Epoch: 6| Step: 6
Training loss: 1.5051207542419434
Validation loss: 2.148965681752851

Epoch: 6| Step: 7
Training loss: 2.189763307571411
Validation loss: 2.16413942972819

Epoch: 6| Step: 8
Training loss: 2.367671489715576
Validation loss: 2.1813714734969603

Epoch: 6| Step: 9
Training loss: 1.6075382232666016
Validation loss: 2.0824591113675024

Epoch: 6| Step: 10
Training loss: 1.985447883605957
Validation loss: 2.1444856864149853

Epoch: 6| Step: 11
Training loss: 1.9197614192962646
Validation loss: 2.1740513334992113

Epoch: 6| Step: 12
Training loss: 1.932410717010498
Validation loss: 2.1350648454440537

Epoch: 6| Step: 13
Training loss: 2.3554141521453857
Validation loss: 2.1445673152964604

Epoch: 350| Step: 0
Training loss: 1.3955459594726562
Validation loss: 2.0867917896598898

Epoch: 6| Step: 1
Training loss: 2.078066825866699
Validation loss: 2.0921185965179117

Epoch: 6| Step: 2
Training loss: 1.8863445520401
Validation loss: 2.1724765710933234

Epoch: 6| Step: 3
Training loss: 1.894249439239502
Validation loss: 2.0976745582395986

Epoch: 6| Step: 4
Training loss: 1.8227927684783936
Validation loss: 2.1716182834358624

Epoch: 6| Step: 5
Training loss: 1.5188801288604736
Validation loss: 2.1330503622690835

Epoch: 6| Step: 6
Training loss: 2.012307643890381
Validation loss: 2.11791895538248

Epoch: 6| Step: 7
Training loss: 2.1472487449645996
Validation loss: 2.0889917855621665

Epoch: 6| Step: 8
Training loss: 1.7727959156036377
Validation loss: 2.1439276664487776

Epoch: 6| Step: 9
Training loss: 2.114713668823242
Validation loss: 2.1154965867278395

Epoch: 6| Step: 10
Training loss: 2.3581786155700684
Validation loss: 2.151065820006914

Epoch: 6| Step: 11
Training loss: 2.23861026763916
Validation loss: 2.170962761807185

Epoch: 6| Step: 12
Training loss: 1.9113469123840332
Validation loss: 2.1577759570972894

Epoch: 6| Step: 13
Training loss: 1.8740259408950806
Validation loss: 2.221827407037058

Epoch: 351| Step: 0
Training loss: 1.6963953971862793
Validation loss: 2.123100293579922

Epoch: 6| Step: 1
Training loss: 1.9762721061706543
Validation loss: 2.1078812383836314

Epoch: 6| Step: 2
Training loss: 2.4452805519104004
Validation loss: 2.131219830564273

Epoch: 6| Step: 3
Training loss: 1.4024298191070557
Validation loss: 2.1199837141139533

Epoch: 6| Step: 4
Training loss: 2.0272786617279053
Validation loss: 2.1869503400659047

Epoch: 6| Step: 5
Training loss: 2.2439541816711426
Validation loss: 2.0671835048224336

Epoch: 6| Step: 6
Training loss: 1.9089667797088623
Validation loss: 2.19788614139762

Epoch: 6| Step: 7
Training loss: 1.561301827430725
Validation loss: 2.1432386021460257

Epoch: 6| Step: 8
Training loss: 1.5493431091308594
Validation loss: 2.1633076949786116

Epoch: 6| Step: 9
Training loss: 1.701380968093872
Validation loss: 2.1383337077274116

Epoch: 6| Step: 10
Training loss: 1.8820688724517822
Validation loss: 2.1825300429456975

Epoch: 6| Step: 11
Training loss: 2.2969954013824463
Validation loss: 2.146049076511014

Epoch: 6| Step: 12
Training loss: 1.6357725858688354
Validation loss: 2.1301515025477253

Epoch: 6| Step: 13
Training loss: 2.740326166152954
Validation loss: 2.117021929833197

Epoch: 352| Step: 0
Training loss: 1.8448768854141235
Validation loss: 2.1803447482406453

Epoch: 6| Step: 1
Training loss: 2.5620453357696533
Validation loss: 2.1623608707099833

Epoch: 6| Step: 2
Training loss: 1.7368481159210205
Validation loss: 2.094608958049487

Epoch: 6| Step: 3
Training loss: 1.3396308422088623
Validation loss: 2.1562763157711236

Epoch: 6| Step: 4
Training loss: 2.327789783477783
Validation loss: 2.1335426735621628

Epoch: 6| Step: 5
Training loss: 0.6675534844398499
Validation loss: 2.085496202591927

Epoch: 6| Step: 6
Training loss: 2.5603671073913574
Validation loss: 2.1497114089227494

Epoch: 6| Step: 7
Training loss: 1.7457160949707031
Validation loss: 2.120658561747561

Epoch: 6| Step: 8
Training loss: 1.9277222156524658
Validation loss: 2.140751297755908

Epoch: 6| Step: 9
Training loss: 2.264425277709961
Validation loss: 2.135875404521983

Epoch: 6| Step: 10
Training loss: 1.3405115604400635
Validation loss: 2.102663488798244

Epoch: 6| Step: 11
Training loss: 2.04636812210083
Validation loss: 2.0800734143103323

Epoch: 6| Step: 12
Training loss: 1.945910930633545
Validation loss: 2.1547941264285835

Epoch: 6| Step: 13
Training loss: 2.5986616611480713
Validation loss: 2.1394384702046714

Epoch: 353| Step: 0
Training loss: 1.0608928203582764
Validation loss: 2.102655799158158

Epoch: 6| Step: 1
Training loss: 1.4592735767364502
Validation loss: 2.2172395055012037

Epoch: 6| Step: 2
Training loss: 1.8236290216445923
Validation loss: 2.1449324136139243

Epoch: 6| Step: 3
Training loss: 1.5608997344970703
Validation loss: 2.075575831115887

Epoch: 6| Step: 4
Training loss: 2.074917793273926
Validation loss: 2.192044242735832

Epoch: 6| Step: 5
Training loss: 2.214317798614502
Validation loss: 2.144057681483607

Epoch: 6| Step: 6
Training loss: 1.5979700088500977
Validation loss: 2.1413479774228987

Epoch: 6| Step: 7
Training loss: 2.229867935180664
Validation loss: 2.1309317696479058

Epoch: 6| Step: 8
Training loss: 2.40879487991333
Validation loss: 2.1535974830709477

Epoch: 6| Step: 9
Training loss: 1.9932301044464111
Validation loss: 2.213743120111445

Epoch: 6| Step: 10
Training loss: 1.9768038988113403
Validation loss: 2.0943243503570557

Epoch: 6| Step: 11
Training loss: 2.5372581481933594
Validation loss: 2.152550701172121

Epoch: 6| Step: 12
Training loss: 1.738840103149414
Validation loss: 2.0934781310378865

Epoch: 6| Step: 13
Training loss: 1.704743504524231
Validation loss: 2.125435310025369

Epoch: 354| Step: 0
Training loss: 1.8513271808624268
Validation loss: 2.0577414984344156

Epoch: 6| Step: 1
Training loss: 1.8748278617858887
Validation loss: 2.144977823380501

Epoch: 6| Step: 2
Training loss: 2.023128032684326
Validation loss: 2.099188971263106

Epoch: 6| Step: 3
Training loss: 2.3111469745635986
Validation loss: 2.079132186469211

Epoch: 6| Step: 4
Training loss: 1.2180852890014648
Validation loss: 2.128347376341461

Epoch: 6| Step: 5
Training loss: 1.7861441373825073
Validation loss: 2.0989995412929083

Epoch: 6| Step: 6
Training loss: 2.1067118644714355
Validation loss: 2.1785752337466002

Epoch: 6| Step: 7
Training loss: 1.493098497390747
Validation loss: 2.116174869639899

Epoch: 6| Step: 8
Training loss: 1.6957273483276367
Validation loss: 2.1306732713535266

Epoch: 6| Step: 9
Training loss: 1.6424496173858643
Validation loss: 2.1213950162292807

Epoch: 6| Step: 10
Training loss: 2.331418991088867
Validation loss: 2.093485008003891

Epoch: 6| Step: 11
Training loss: 2.0365443229675293
Validation loss: 2.1123210922364266

Epoch: 6| Step: 12
Training loss: 2.3971104621887207
Validation loss: 2.1070095723675144

Epoch: 6| Step: 13
Training loss: 1.2476539611816406
Validation loss: 2.115187562921996

Epoch: 355| Step: 0
Training loss: 1.6782255172729492
Validation loss: 2.0954194415000176

Epoch: 6| Step: 1
Training loss: 1.7284467220306396
Validation loss: 2.111897785176513

Epoch: 6| Step: 2
Training loss: 1.4641780853271484
Validation loss: 2.0831869622712493

Epoch: 6| Step: 3
Training loss: 2.0076751708984375
Validation loss: 2.1394415850280435

Epoch: 6| Step: 4
Training loss: 1.5792763233184814
Validation loss: 2.1614742317507343

Epoch: 6| Step: 5
Training loss: 2.0679306983947754
Validation loss: 2.1560033598253803

Epoch: 6| Step: 6
Training loss: 1.520033359527588
Validation loss: 2.1721681292339037

Epoch: 6| Step: 7
Training loss: 1.4014291763305664
Validation loss: 2.2097555334850023

Epoch: 6| Step: 8
Training loss: 1.6461098194122314
Validation loss: 2.167304414574818

Epoch: 6| Step: 9
Training loss: 2.395498037338257
Validation loss: 2.1942529216889413

Epoch: 6| Step: 10
Training loss: 2.065000057220459
Validation loss: 2.193296601695399

Epoch: 6| Step: 11
Training loss: 2.1492018699645996
Validation loss: 2.160850009610576

Epoch: 6| Step: 12
Training loss: 1.7707016468048096
Validation loss: 2.138496703999017

Epoch: 6| Step: 13
Training loss: 2.8091273307800293
Validation loss: 2.141584846281236

Epoch: 356| Step: 0
Training loss: 1.303619146347046
Validation loss: 2.175784327650583

Epoch: 6| Step: 1
Training loss: 2.578521728515625
Validation loss: 2.171401664774905

Epoch: 6| Step: 2
Training loss: 1.5891597270965576
Validation loss: 2.1594884882691088

Epoch: 6| Step: 3
Training loss: 2.1664867401123047
Validation loss: 2.1192356245492094

Epoch: 6| Step: 4
Training loss: 2.1066160202026367
Validation loss: 2.1033833231977237

Epoch: 6| Step: 5
Training loss: 2.1119418144226074
Validation loss: 2.1228036649765505

Epoch: 6| Step: 6
Training loss: 1.6849467754364014
Validation loss: 2.1223861786627

Epoch: 6| Step: 7
Training loss: 1.8164585828781128
Validation loss: 2.102791283720283

Epoch: 6| Step: 8
Training loss: 1.7556352615356445
Validation loss: 2.1587768652105845

Epoch: 6| Step: 9
Training loss: 1.7184232473373413
Validation loss: 2.1284774298309

Epoch: 6| Step: 10
Training loss: 1.3217750787734985
Validation loss: 2.1895454224719795

Epoch: 6| Step: 11
Training loss: 2.0400240421295166
Validation loss: 2.10136342048645

Epoch: 6| Step: 12
Training loss: 1.869650959968567
Validation loss: 2.084335232293734

Epoch: 6| Step: 13
Training loss: 2.153275728225708
Validation loss: 2.126199983781384

Epoch: 357| Step: 0
Training loss: 1.4725662469863892
Validation loss: 2.0759829064851165

Epoch: 6| Step: 1
Training loss: 1.934687614440918
Validation loss: 2.1285866704038394

Epoch: 6| Step: 2
Training loss: 1.918964147567749
Validation loss: 2.1004869399532193

Epoch: 6| Step: 3
Training loss: 2.1422791481018066
Validation loss: 2.064245711090744

Epoch: 6| Step: 4
Training loss: 2.1372323036193848
Validation loss: 2.104758269043379

Epoch: 6| Step: 5
Training loss: 2.504220485687256
Validation loss: 2.1023025845968597

Epoch: 6| Step: 6
Training loss: 1.7515647411346436
Validation loss: 2.1100310689659527

Epoch: 6| Step: 7
Training loss: 2.1292033195495605
Validation loss: 2.1725691133929836

Epoch: 6| Step: 8
Training loss: 1.0559648275375366
Validation loss: 2.1321424643198648

Epoch: 6| Step: 9
Training loss: 1.5028488636016846
Validation loss: 2.1161962298936743

Epoch: 6| Step: 10
Training loss: 1.7981635332107544
Validation loss: 2.156521979198661

Epoch: 6| Step: 11
Training loss: 1.9148815870285034
Validation loss: 2.13585526199751

Epoch: 6| Step: 12
Training loss: 2.0808911323547363
Validation loss: 2.104530485727454

Epoch: 6| Step: 13
Training loss: 1.4436005353927612
Validation loss: 2.1291959196008663

Epoch: 358| Step: 0
Training loss: 2.0520591735839844
Validation loss: 2.1820470184408207

Epoch: 6| Step: 1
Training loss: 2.3543970584869385
Validation loss: 2.171026668240947

Epoch: 6| Step: 2
Training loss: 1.703812837600708
Validation loss: 2.157018592280726

Epoch: 6| Step: 3
Training loss: 1.9670467376708984
Validation loss: 2.1639468618618545

Epoch: 6| Step: 4
Training loss: 2.1304383277893066
Validation loss: 2.08319826023553

Epoch: 6| Step: 5
Training loss: 1.330317497253418
Validation loss: 2.2471231004243255

Epoch: 6| Step: 6
Training loss: 1.6373181343078613
Validation loss: 2.079452678721438

Epoch: 6| Step: 7
Training loss: 1.472907543182373
Validation loss: 2.152082713701392

Epoch: 6| Step: 8
Training loss: 2.207519292831421
Validation loss: 2.160851747758927

Epoch: 6| Step: 9
Training loss: 2.4507205486297607
Validation loss: 2.1490545016463085

Epoch: 6| Step: 10
Training loss: 1.5297162532806396
Validation loss: 2.1123758464731197

Epoch: 6| Step: 11
Training loss: 1.9187943935394287
Validation loss: 2.1184542256016887

Epoch: 6| Step: 12
Training loss: 1.7693356275558472
Validation loss: 2.077707670068228

Epoch: 6| Step: 13
Training loss: 1.6526728868484497
Validation loss: 2.1056525194516746

Epoch: 359| Step: 0
Training loss: 1.5120255947113037
Validation loss: 2.0705702048476025

Epoch: 6| Step: 1
Training loss: 2.4832751750946045
Validation loss: 2.1158170982073714

Epoch: 6| Step: 2
Training loss: 1.6875050067901611
Validation loss: 2.107659746241826

Epoch: 6| Step: 3
Training loss: 2.380577564239502
Validation loss: 2.1417209691898798

Epoch: 6| Step: 4
Training loss: 1.7846424579620361
Validation loss: 2.1325802213402203

Epoch: 6| Step: 5
Training loss: 1.5899624824523926
Validation loss: 2.054617012700727

Epoch: 6| Step: 6
Training loss: 2.08076548576355
Validation loss: 2.116444098052158

Epoch: 6| Step: 7
Training loss: 2.0355136394500732
Validation loss: 2.1326111350008237

Epoch: 6| Step: 8
Training loss: 1.7863304615020752
Validation loss: 2.1084137449982348

Epoch: 6| Step: 9
Training loss: 2.0347394943237305
Validation loss: 2.117707460157333

Epoch: 6| Step: 10
Training loss: 1.4584317207336426
Validation loss: 2.094658610641315

Epoch: 6| Step: 11
Training loss: 1.3242930173873901
Validation loss: 2.0975043594196277

Epoch: 6| Step: 12
Training loss: 2.244180202484131
Validation loss: 2.133402878238309

Epoch: 6| Step: 13
Training loss: 2.0212321281433105
Validation loss: 2.092449511251142

Epoch: 360| Step: 0
Training loss: 2.095437526702881
Validation loss: 2.158333663017519

Epoch: 6| Step: 1
Training loss: 2.3125782012939453
Validation loss: 2.0976611260444886

Epoch: 6| Step: 2
Training loss: 1.5743359327316284
Validation loss: 2.1585471386550577

Epoch: 6| Step: 3
Training loss: 1.5595062971115112
Validation loss: 2.1195113120540494

Epoch: 6| Step: 4
Training loss: 2.5130958557128906
Validation loss: 2.1148861544106596

Epoch: 6| Step: 5
Training loss: 2.083718776702881
Validation loss: 2.1095643248609317

Epoch: 6| Step: 6
Training loss: 2.056891441345215
Validation loss: 2.1244703236446587

Epoch: 6| Step: 7
Training loss: 2.1528024673461914
Validation loss: 2.1762702362511748

Epoch: 6| Step: 8
Training loss: 1.1079986095428467
Validation loss: 2.154876323156459

Epoch: 6| Step: 9
Training loss: 1.9164577722549438
Validation loss: 2.1246911107852893

Epoch: 6| Step: 10
Training loss: 0.9185957312583923
Validation loss: 2.1457437699840916

Epoch: 6| Step: 11
Training loss: 1.585080623626709
Validation loss: 2.1238643110439344

Epoch: 6| Step: 12
Training loss: 1.8376153707504272
Validation loss: 2.1834276042958742

Epoch: 6| Step: 13
Training loss: 2.8437986373901367
Validation loss: 2.0580040024172876

Epoch: 361| Step: 0
Training loss: 1.812922716140747
Validation loss: 2.130082203495887

Epoch: 6| Step: 1
Training loss: 2.1377367973327637
Validation loss: 2.134357549810922

Epoch: 6| Step: 2
Training loss: 1.4954837560653687
Validation loss: 2.0754329978778796

Epoch: 6| Step: 3
Training loss: 1.9996163845062256
Validation loss: 2.1293673284592165

Epoch: 6| Step: 4
Training loss: 1.1189312934875488
Validation loss: 2.1249827877167733

Epoch: 6| Step: 5
Training loss: 2.8847484588623047
Validation loss: 2.132693217646691

Epoch: 6| Step: 6
Training loss: 1.5545997619628906
Validation loss: 2.2076956059343074

Epoch: 6| Step: 7
Training loss: 1.8135700225830078
Validation loss: 2.09978493695618

Epoch: 6| Step: 8
Training loss: 1.7184878587722778
Validation loss: 2.09475387296369

Epoch: 6| Step: 9
Training loss: 1.2293680906295776
Validation loss: 2.167935327817035

Epoch: 6| Step: 10
Training loss: 2.4653377532958984
Validation loss: 2.188352679693571

Epoch: 6| Step: 11
Training loss: 1.9810303449630737
Validation loss: 2.166051418550553

Epoch: 6| Step: 12
Training loss: 2.308100700378418
Validation loss: 2.1801796318382345

Epoch: 6| Step: 13
Training loss: 1.7414264678955078
Validation loss: 2.0687333024958128

Epoch: 362| Step: 0
Training loss: 0.9631814956665039
Validation loss: 2.136348778201688

Epoch: 6| Step: 1
Training loss: 2.0440244674682617
Validation loss: 2.099034211968863

Epoch: 6| Step: 2
Training loss: 2.12164568901062
Validation loss: 2.1511506624119257

Epoch: 6| Step: 3
Training loss: 2.1900641918182373
Validation loss: 2.0831827194459978

Epoch: 6| Step: 4
Training loss: 1.9986448287963867
Validation loss: 2.085700032531574

Epoch: 6| Step: 5
Training loss: 2.129910945892334
Validation loss: 2.1678609335294334

Epoch: 6| Step: 6
Training loss: 1.9245719909667969
Validation loss: 2.1600711384127216

Epoch: 6| Step: 7
Training loss: 1.467159390449524
Validation loss: 2.164389725654356

Epoch: 6| Step: 8
Training loss: 1.0055691003799438
Validation loss: 2.089608648771881

Epoch: 6| Step: 9
Training loss: 2.053124189376831
Validation loss: 2.1096314307182067

Epoch: 6| Step: 10
Training loss: 1.9620177745819092
Validation loss: 2.125890439556491

Epoch: 6| Step: 11
Training loss: 1.625427007675171
Validation loss: 2.182622730091054

Epoch: 6| Step: 12
Training loss: 2.1006994247436523
Validation loss: 2.1061482455140803

Epoch: 6| Step: 13
Training loss: 1.8698474168777466
Validation loss: 2.170302580761653

Epoch: 363| Step: 0
Training loss: 1.7485803365707397
Validation loss: 2.099564206215643

Epoch: 6| Step: 1
Training loss: 1.5685498714447021
Validation loss: 2.1519910443213677

Epoch: 6| Step: 2
Training loss: 2.2551095485687256
Validation loss: 2.1832699109149236

Epoch: 6| Step: 3
Training loss: 1.4503567218780518
Validation loss: 2.0990782424967778

Epoch: 6| Step: 4
Training loss: 1.5966126918792725
Validation loss: 2.121341792486047

Epoch: 6| Step: 5
Training loss: 2.4178311824798584
Validation loss: 2.120476838081114

Epoch: 6| Step: 6
Training loss: 1.74253249168396
Validation loss: 2.091011595982377

Epoch: 6| Step: 7
Training loss: 1.7114615440368652
Validation loss: 2.0833971833670013

Epoch: 6| Step: 8
Training loss: 2.1201095581054688
Validation loss: 2.0973804086767216

Epoch: 6| Step: 9
Training loss: 2.4796252250671387
Validation loss: 2.138663863623014

Epoch: 6| Step: 10
Training loss: 1.494544506072998
Validation loss: 2.090824527125205

Epoch: 6| Step: 11
Training loss: 2.3261375427246094
Validation loss: 2.1293839113686674

Epoch: 6| Step: 12
Training loss: 1.7430579662322998
Validation loss: 2.1226576720514605

Epoch: 6| Step: 13
Training loss: 1.4300017356872559
Validation loss: 2.0872023464531027

Epoch: 364| Step: 0
Training loss: 1.9480602741241455
Validation loss: 2.198704675961566

Epoch: 6| Step: 1
Training loss: 1.4189801216125488
Validation loss: 2.133443192769122

Epoch: 6| Step: 2
Training loss: 2.0139310359954834
Validation loss: 2.1401803967773274

Epoch: 6| Step: 3
Training loss: 1.5506178140640259
Validation loss: 2.153896580460251

Epoch: 6| Step: 4
Training loss: 2.65282940864563
Validation loss: 2.192317255081669

Epoch: 6| Step: 5
Training loss: 2.1938514709472656
Validation loss: 2.094794709195373

Epoch: 6| Step: 6
Training loss: 2.0346839427948
Validation loss: 2.134147544060984

Epoch: 6| Step: 7
Training loss: 1.6931880712509155
Validation loss: 2.1230139911815686

Epoch: 6| Step: 8
Training loss: 1.8205351829528809
Validation loss: 2.1431220052062825

Epoch: 6| Step: 9
Training loss: 1.128147840499878
Validation loss: 2.1305456007680585

Epoch: 6| Step: 10
Training loss: 1.6090564727783203
Validation loss: 2.128804294011926

Epoch: 6| Step: 11
Training loss: 2.3387508392333984
Validation loss: 2.05758402680838

Epoch: 6| Step: 12
Training loss: 2.1313700675964355
Validation loss: 2.165390045412125

Epoch: 6| Step: 13
Training loss: 2.00992488861084
Validation loss: 2.178845524787903

Epoch: 365| Step: 0
Training loss: 1.8814725875854492
Validation loss: 2.0945175091425576

Epoch: 6| Step: 1
Training loss: 1.6930779218673706
Validation loss: 2.129967753605176

Epoch: 6| Step: 2
Training loss: 2.662217617034912
Validation loss: 2.1589734631199993

Epoch: 6| Step: 3
Training loss: 1.922999382019043
Validation loss: 2.1338555248834754

Epoch: 6| Step: 4
Training loss: 1.8414231538772583
Validation loss: 2.1373896791088964

Epoch: 6| Step: 5
Training loss: 1.451683759689331
Validation loss: 2.149622348047072

Epoch: 6| Step: 6
Training loss: 1.3222856521606445
Validation loss: 2.1281907378986316

Epoch: 6| Step: 7
Training loss: 1.7209006547927856
Validation loss: 2.128441867008004

Epoch: 6| Step: 8
Training loss: 1.9578094482421875
Validation loss: 2.119491066983951

Epoch: 6| Step: 9
Training loss: 1.999366283416748
Validation loss: 2.0864852910400717

Epoch: 6| Step: 10
Training loss: 1.7891221046447754
Validation loss: 2.130706528181671

Epoch: 6| Step: 11
Training loss: 1.1159348487854004
Validation loss: 2.0912214953412294

Epoch: 6| Step: 12
Training loss: 2.651768922805786
Validation loss: 2.1259911393606536

Epoch: 6| Step: 13
Training loss: 1.95504629611969
Validation loss: 2.111639468900619

Epoch: 366| Step: 0
Training loss: 1.535686731338501
Validation loss: 2.1015028812552012

Epoch: 6| Step: 1
Training loss: 1.9264822006225586
Validation loss: 2.1099225603124148

Epoch: 6| Step: 2
Training loss: 1.5037673711776733
Validation loss: 2.110730573695193

Epoch: 6| Step: 3
Training loss: 1.5186588764190674
Validation loss: 2.0914792809435117

Epoch: 6| Step: 4
Training loss: 1.6971739530563354
Validation loss: 2.0504192613786265

Epoch: 6| Step: 5
Training loss: 2.082242965698242
Validation loss: 2.114859063138244

Epoch: 6| Step: 6
Training loss: 2.2865395545959473
Validation loss: 2.0441350090888237

Epoch: 6| Step: 7
Training loss: 1.993748664855957
Validation loss: 2.143911002784647

Epoch: 6| Step: 8
Training loss: 1.5474344491958618
Validation loss: 2.137980112465479

Epoch: 6| Step: 9
Training loss: 1.6013100147247314
Validation loss: 2.1084346976331485

Epoch: 6| Step: 10
Training loss: 1.8368148803710938
Validation loss: 2.0904497536279822

Epoch: 6| Step: 11
Training loss: 1.8607594966888428
Validation loss: 2.1015561396075833

Epoch: 6| Step: 12
Training loss: 2.3378522396087646
Validation loss: 2.1297413328642487

Epoch: 6| Step: 13
Training loss: 2.3874692916870117
Validation loss: 2.151455230610345

Epoch: 367| Step: 0
Training loss: 1.7425851821899414
Validation loss: 2.1557220284656813

Epoch: 6| Step: 1
Training loss: 1.7163300514221191
Validation loss: 2.0671149851173483

Epoch: 6| Step: 2
Training loss: 2.2396037578582764
Validation loss: 2.11460288365682

Epoch: 6| Step: 3
Training loss: 1.3660696744918823
Validation loss: 2.1300028626636793

Epoch: 6| Step: 4
Training loss: 1.4410147666931152
Validation loss: 2.176940510349889

Epoch: 6| Step: 5
Training loss: 2.1677606105804443
Validation loss: 2.1228986324802523

Epoch: 6| Step: 6
Training loss: 1.9551374912261963
Validation loss: 2.1413939409358527

Epoch: 6| Step: 7
Training loss: 1.5570558309555054
Validation loss: 2.1704764135422243

Epoch: 6| Step: 8
Training loss: 1.7413954734802246
Validation loss: 2.1513394642901678

Epoch: 6| Step: 9
Training loss: 1.8171021938323975
Validation loss: 2.139637326681486

Epoch: 6| Step: 10
Training loss: 1.5727092027664185
Validation loss: 2.1442174732044177

Epoch: 6| Step: 11
Training loss: 2.1858372688293457
Validation loss: 2.1739665744125203

Epoch: 6| Step: 12
Training loss: 2.123791456222534
Validation loss: 2.092725307710709

Epoch: 6| Step: 13
Training loss: 2.2636098861694336
Validation loss: 2.095537559960478

Epoch: 368| Step: 0
Training loss: 1.3562989234924316
Validation loss: 2.1485940115426176

Epoch: 6| Step: 1
Training loss: 2.3381829261779785
Validation loss: 2.1998818241139895

Epoch: 6| Step: 2
Training loss: 2.15740966796875
Validation loss: 2.1859015264818744

Epoch: 6| Step: 3
Training loss: 1.8635516166687012
Validation loss: 2.122875613550986

Epoch: 6| Step: 4
Training loss: 1.7365425825119019
Validation loss: 2.202539410642398

Epoch: 6| Step: 5
Training loss: 2.2442164421081543
Validation loss: 2.1292411383762153

Epoch: 6| Step: 6
Training loss: 1.9996414184570312
Validation loss: 2.147040759363482

Epoch: 6| Step: 7
Training loss: 1.1609816551208496
Validation loss: 2.0697285206087175

Epoch: 6| Step: 8
Training loss: 1.8317466974258423
Validation loss: 2.17185729037049

Epoch: 6| Step: 9
Training loss: 1.302473545074463
Validation loss: 2.100756924639466

Epoch: 6| Step: 10
Training loss: 2.1450858116149902
Validation loss: 2.166504426669049

Epoch: 6| Step: 11
Training loss: 2.2848548889160156
Validation loss: 2.1030058450596307

Epoch: 6| Step: 12
Training loss: 1.9648356437683105
Validation loss: 2.0849703793884604

Epoch: 6| Step: 13
Training loss: 1.4841992855072021
Validation loss: 2.094162825615175

Epoch: 369| Step: 0
Training loss: 1.4423444271087646
Validation loss: 2.083302911891732

Epoch: 6| Step: 1
Training loss: 2.370265007019043
Validation loss: 2.137703182876751

Epoch: 6| Step: 2
Training loss: 1.4588273763656616
Validation loss: 2.185411012300881

Epoch: 6| Step: 3
Training loss: 2.121070384979248
Validation loss: 2.154884462715477

Epoch: 6| Step: 4
Training loss: 1.8729047775268555
Validation loss: 2.1085864369587233

Epoch: 6| Step: 5
Training loss: 2.558654308319092
Validation loss: 2.1380944790378695

Epoch: 6| Step: 6
Training loss: 1.96854567527771
Validation loss: 2.1346542143052623

Epoch: 6| Step: 7
Training loss: 1.8941041231155396
Validation loss: 2.1471464851851105

Epoch: 6| Step: 8
Training loss: 2.3296382427215576
Validation loss: 2.181704731397731

Epoch: 6| Step: 9
Training loss: 1.5391852855682373
Validation loss: 2.1718246706070437

Epoch: 6| Step: 10
Training loss: 1.0315697193145752
Validation loss: 2.198870938311341

Epoch: 6| Step: 11
Training loss: 1.947689414024353
Validation loss: 2.121464139671736

Epoch: 6| Step: 12
Training loss: 1.440826177597046
Validation loss: 2.1596985734919065

Epoch: 6| Step: 13
Training loss: 2.0989575386047363
Validation loss: 2.1773397140605475

Epoch: 370| Step: 0
Training loss: 1.3451957702636719
Validation loss: 2.1480299067753617

Epoch: 6| Step: 1
Training loss: 1.981825590133667
Validation loss: 2.209887232831729

Epoch: 6| Step: 2
Training loss: 1.915594220161438
Validation loss: 2.1729452827925324

Epoch: 6| Step: 3
Training loss: 1.5400115251541138
Validation loss: 2.1905692264597905

Epoch: 6| Step: 4
Training loss: 1.4078651666641235
Validation loss: 2.0953223448927685

Epoch: 6| Step: 5
Training loss: 1.684985876083374
Validation loss: 2.167149859090005

Epoch: 6| Step: 6
Training loss: 1.3058571815490723
Validation loss: 2.1977089374296126

Epoch: 6| Step: 7
Training loss: 1.6051193475723267
Validation loss: 2.145833533297303

Epoch: 6| Step: 8
Training loss: 2.435380458831787
Validation loss: 2.2164428311009563

Epoch: 6| Step: 9
Training loss: 2.442355155944824
Validation loss: 2.112756347143522

Epoch: 6| Step: 10
Training loss: 2.142888069152832
Validation loss: 2.069084918627175

Epoch: 6| Step: 11
Training loss: 1.9697133302688599
Validation loss: 2.1018965295566026

Epoch: 6| Step: 12
Training loss: 2.053544521331787
Validation loss: 2.135488630622946

Epoch: 6| Step: 13
Training loss: 2.1817870140075684
Validation loss: 2.109979970480806

Epoch: 371| Step: 0
Training loss: 1.4383516311645508
Validation loss: 2.084248396658128

Epoch: 6| Step: 1
Training loss: 1.3493907451629639
Validation loss: 2.0153815848853

Epoch: 6| Step: 2
Training loss: 1.8202017545700073
Validation loss: 2.105597580632856

Epoch: 6| Step: 3
Training loss: 1.7397568225860596
Validation loss: 2.0681999601343626

Epoch: 6| Step: 4
Training loss: 2.3835043907165527
Validation loss: 2.0986526576421594

Epoch: 6| Step: 5
Training loss: 1.9784440994262695
Validation loss: 2.154286810146865

Epoch: 6| Step: 6
Training loss: 2.41446852684021
Validation loss: 2.1726926424170054

Epoch: 6| Step: 7
Training loss: 1.7738902568817139
Validation loss: 2.148547093073527

Epoch: 6| Step: 8
Training loss: 1.5665993690490723
Validation loss: 2.1495961822489256

Epoch: 6| Step: 9
Training loss: 2.0357508659362793
Validation loss: 2.1530138728439168

Epoch: 6| Step: 10
Training loss: 2.149754285812378
Validation loss: 2.2111101099239883

Epoch: 6| Step: 11
Training loss: 2.0291028022766113
Validation loss: 2.1841006535355763

Epoch: 6| Step: 12
Training loss: 1.8436057567596436
Validation loss: 2.174417318836335

Epoch: 6| Step: 13
Training loss: 1.6825737953186035
Validation loss: 2.1028699336513395

Epoch: 372| Step: 0
Training loss: 1.7019667625427246
Validation loss: 2.19736805013431

Epoch: 6| Step: 1
Training loss: 2.2071967124938965
Validation loss: 2.1533797479444936

Epoch: 6| Step: 2
Training loss: 1.8937370777130127
Validation loss: 2.1258201368393435

Epoch: 6| Step: 3
Training loss: 2.4606246948242188
Validation loss: 2.1615044686102096

Epoch: 6| Step: 4
Training loss: 1.8641917705535889
Validation loss: 2.18453166689924

Epoch: 6| Step: 5
Training loss: 2.007749319076538
Validation loss: 2.149769757383613

Epoch: 6| Step: 6
Training loss: 1.5939700603485107
Validation loss: 2.1891659280305267

Epoch: 6| Step: 7
Training loss: 1.5721657276153564
Validation loss: 2.163522225554271

Epoch: 6| Step: 8
Training loss: 1.6786737442016602
Validation loss: 2.129845642274426

Epoch: 6| Step: 9
Training loss: 2.296330451965332
Validation loss: 2.0933485787401915

Epoch: 6| Step: 10
Training loss: 1.205812692642212
Validation loss: 2.1080819765726724

Epoch: 6| Step: 11
Training loss: 1.3417912721633911
Validation loss: 2.1557793822339786

Epoch: 6| Step: 12
Training loss: 2.0855941772460938
Validation loss: 2.2015479431357434

Epoch: 6| Step: 13
Training loss: 2.2746644020080566
Validation loss: 2.152575856895857

Epoch: 373| Step: 0
Training loss: 1.8588273525238037
Validation loss: 2.1162547924185313

Epoch: 6| Step: 1
Training loss: 1.0360422134399414
Validation loss: 2.146541610840828

Epoch: 6| Step: 2
Training loss: 2.278866767883301
Validation loss: 2.1087051168564828

Epoch: 6| Step: 3
Training loss: 2.4522197246551514
Validation loss: 2.1532600541268625

Epoch: 6| Step: 4
Training loss: 2.1333625316619873
Validation loss: 2.111092112397635

Epoch: 6| Step: 5
Training loss: 1.4971964359283447
Validation loss: 2.0791040376950334

Epoch: 6| Step: 6
Training loss: 1.7092499732971191
Validation loss: 2.164092827868718

Epoch: 6| Step: 7
Training loss: 2.1451313495635986
Validation loss: 2.1898407602822907

Epoch: 6| Step: 8
Training loss: 1.1237621307373047
Validation loss: 2.091450919387161

Epoch: 6| Step: 9
Training loss: 1.1238235235214233
Validation loss: 2.160307756034277

Epoch: 6| Step: 10
Training loss: 2.245223045349121
Validation loss: 2.100828177185469

Epoch: 6| Step: 11
Training loss: 2.2551913261413574
Validation loss: 2.1088510431269163

Epoch: 6| Step: 12
Training loss: 1.5518039464950562
Validation loss: 2.1309454748707433

Epoch: 6| Step: 13
Training loss: 2.4408984184265137
Validation loss: 2.1455552244699128

Epoch: 374| Step: 0
Training loss: 1.8946466445922852
Validation loss: 2.1262222464366625

Epoch: 6| Step: 1
Training loss: 1.601287841796875
Validation loss: 2.1796964753058647

Epoch: 6| Step: 2
Training loss: 1.952580213546753
Validation loss: 2.199319597213499

Epoch: 6| Step: 3
Training loss: 2.212515354156494
Validation loss: 2.093151920585222

Epoch: 6| Step: 4
Training loss: 2.5918736457824707
Validation loss: 2.1167847700016473

Epoch: 6| Step: 5
Training loss: 1.3018379211425781
Validation loss: 2.219190420642976

Epoch: 6| Step: 6
Training loss: 1.2916611433029175
Validation loss: 2.1283233755378315

Epoch: 6| Step: 7
Training loss: 1.8213527202606201
Validation loss: 2.162134006459226

Epoch: 6| Step: 8
Training loss: 1.489185094833374
Validation loss: 2.156667067158607

Epoch: 6| Step: 9
Training loss: 2.6682581901550293
Validation loss: 2.1343383122515935

Epoch: 6| Step: 10
Training loss: 1.6078941822052002
Validation loss: 2.0287414507199357

Epoch: 6| Step: 11
Training loss: 1.7672395706176758
Validation loss: 2.0728375450257333

Epoch: 6| Step: 12
Training loss: 2.1170296669006348
Validation loss: 2.164966176914912

Epoch: 6| Step: 13
Training loss: 2.141324758529663
Validation loss: 2.1296325140101935

Epoch: 375| Step: 0
Training loss: 1.8631134033203125
Validation loss: 2.1050215562184653

Epoch: 6| Step: 1
Training loss: 2.196485996246338
Validation loss: 2.1385968244203957

Epoch: 6| Step: 2
Training loss: 1.435530424118042
Validation loss: 2.154555238703246

Epoch: 6| Step: 3
Training loss: 1.7106056213378906
Validation loss: 2.168644674362675

Epoch: 6| Step: 4
Training loss: 1.2314764261245728
Validation loss: 2.1215287318793674

Epoch: 6| Step: 5
Training loss: 2.505688190460205
Validation loss: 2.1472541093826294

Epoch: 6| Step: 6
Training loss: 2.0366411209106445
Validation loss: 2.146284516139697

Epoch: 6| Step: 7
Training loss: 2.507910966873169
Validation loss: 2.1405882835388184

Epoch: 6| Step: 8
Training loss: 1.5475852489471436
Validation loss: 2.1067948354187833

Epoch: 6| Step: 9
Training loss: 1.7828130722045898
Validation loss: 2.1694274948489283

Epoch: 6| Step: 10
Training loss: 1.2658476829528809
Validation loss: 2.109337777219793

Epoch: 6| Step: 11
Training loss: 1.414379596710205
Validation loss: 2.1943904610090357

Epoch: 6| Step: 12
Training loss: 2.2127718925476074
Validation loss: 2.1720097039335515

Epoch: 6| Step: 13
Training loss: 2.3067374229431152
Validation loss: 2.229546977627662

Epoch: 376| Step: 0
Training loss: 2.241831064224243
Validation loss: 2.087579542590726

Epoch: 6| Step: 1
Training loss: 1.1267799139022827
Validation loss: 2.148852768764701

Epoch: 6| Step: 2
Training loss: 2.0299830436706543
Validation loss: 2.1769855073703233

Epoch: 6| Step: 3
Training loss: 1.5021212100982666
Validation loss: 2.1755368222472486

Epoch: 6| Step: 4
Training loss: 1.2580053806304932
Validation loss: 2.2393090468581005

Epoch: 6| Step: 5
Training loss: 2.4048550128936768
Validation loss: 2.1874071500634633

Epoch: 6| Step: 6
Training loss: 1.944775104522705
Validation loss: 2.189016483163321

Epoch: 6| Step: 7
Training loss: 3.311746120452881
Validation loss: 2.1419069510634228

Epoch: 6| Step: 8
Training loss: 1.5440309047698975
Validation loss: 2.2371465903456493

Epoch: 6| Step: 9
Training loss: 2.3216135501861572
Validation loss: 2.1348538757652364

Epoch: 6| Step: 10
Training loss: 1.8769629001617432
Validation loss: 2.1406438453223116

Epoch: 6| Step: 11
Training loss: 1.315415620803833
Validation loss: 2.1557497157845447

Epoch: 6| Step: 12
Training loss: 1.4604454040527344
Validation loss: 2.1536434350475187

Epoch: 6| Step: 13
Training loss: 1.634850263595581
Validation loss: 2.117124174230842

Epoch: 377| Step: 0
Training loss: 2.7327611446380615
Validation loss: 2.147390474555313

Epoch: 6| Step: 1
Training loss: 1.4597983360290527
Validation loss: 2.1992388207425355

Epoch: 6| Step: 2
Training loss: 1.7739877700805664
Validation loss: 2.135574512584235

Epoch: 6| Step: 3
Training loss: 1.5611517429351807
Validation loss: 2.1040454564555997

Epoch: 6| Step: 4
Training loss: 1.293929100036621
Validation loss: 2.0992606134824854

Epoch: 6| Step: 5
Training loss: 1.9228854179382324
Validation loss: 2.0883075626947547

Epoch: 6| Step: 6
Training loss: 2.0754833221435547
Validation loss: 2.0882051978059994

Epoch: 6| Step: 7
Training loss: 1.7274783849716187
Validation loss: 2.0711096538010465

Epoch: 6| Step: 8
Training loss: 2.1513991355895996
Validation loss: 2.1679131548891784

Epoch: 6| Step: 9
Training loss: 1.7972220182418823
Validation loss: 2.1365495650999007

Epoch: 6| Step: 10
Training loss: 1.8197062015533447
Validation loss: 2.1284132875421995

Epoch: 6| Step: 11
Training loss: 1.396950364112854
Validation loss: 2.0977795175326768

Epoch: 6| Step: 12
Training loss: 1.7358245849609375
Validation loss: 2.144180202996859

Epoch: 6| Step: 13
Training loss: 2.1478676795959473
Validation loss: 2.120795008956745

Epoch: 378| Step: 0
Training loss: 1.4225409030914307
Validation loss: 2.1051140292998283

Epoch: 6| Step: 1
Training loss: 1.6528310775756836
Validation loss: 2.113458189913022

Epoch: 6| Step: 2
Training loss: 1.9792335033416748
Validation loss: 2.117541233698527

Epoch: 6| Step: 3
Training loss: 2.3235981464385986
Validation loss: 2.171238596721362

Epoch: 6| Step: 4
Training loss: 1.7474340200424194
Validation loss: 2.103244666130312

Epoch: 6| Step: 5
Training loss: 2.9480643272399902
Validation loss: 2.104570911776635

Epoch: 6| Step: 6
Training loss: 2.13775634765625
Validation loss: 2.0745485431404522

Epoch: 6| Step: 7
Training loss: 1.8761417865753174
Validation loss: 2.0746290273563837

Epoch: 6| Step: 8
Training loss: 1.8712172508239746
Validation loss: 2.040777426893993

Epoch: 6| Step: 9
Training loss: 1.2074596881866455
Validation loss: 2.14869330006261

Epoch: 6| Step: 10
Training loss: 1.4677424430847168
Validation loss: 2.0821747831119004

Epoch: 6| Step: 11
Training loss: 2.0829083919525146
Validation loss: 2.1262595397169872

Epoch: 6| Step: 12
Training loss: 1.8149888515472412
Validation loss: 2.1527125617509246

Epoch: 6| Step: 13
Training loss: 2.1985349655151367
Validation loss: 2.1811127508840253

Epoch: 379| Step: 0
Training loss: 1.5100634098052979
Validation loss: 2.104668991540068

Epoch: 6| Step: 1
Training loss: 1.905102252960205
Validation loss: 2.1197352255544355

Epoch: 6| Step: 2
Training loss: 2.2212095260620117
Validation loss: 2.1805948775301696

Epoch: 6| Step: 3
Training loss: 1.7115226984024048
Validation loss: 2.1162820298184633

Epoch: 6| Step: 4
Training loss: 1.9414918422698975
Validation loss: 2.1368554612641693

Epoch: 6| Step: 5
Training loss: 1.8110342025756836
Validation loss: 2.133374250063332

Epoch: 6| Step: 6
Training loss: 2.1429479122161865
Validation loss: 2.167040745417277

Epoch: 6| Step: 7
Training loss: 2.2541651725769043
Validation loss: 2.1469220640838786

Epoch: 6| Step: 8
Training loss: 1.2462849617004395
Validation loss: 2.1855295883711947

Epoch: 6| Step: 9
Training loss: 2.432861804962158
Validation loss: 2.112290092693862

Epoch: 6| Step: 10
Training loss: 1.8222324848175049
Validation loss: 2.1541447306192048

Epoch: 6| Step: 11
Training loss: 1.8120768070220947
Validation loss: 2.1077051521629415

Epoch: 6| Step: 12
Training loss: 1.7777886390686035
Validation loss: 2.130257239905737

Epoch: 6| Step: 13
Training loss: 0.9124168753623962
Validation loss: 2.1537260637488416

Epoch: 380| Step: 0
Training loss: 2.0303292274475098
Validation loss: 2.1784212666173137

Epoch: 6| Step: 1
Training loss: 1.4526357650756836
Validation loss: 2.2229758744598715

Epoch: 6| Step: 2
Training loss: 2.253148078918457
Validation loss: 2.184606650824188

Epoch: 6| Step: 3
Training loss: 1.7853713035583496
Validation loss: 2.1718646634009575

Epoch: 6| Step: 4
Training loss: 1.6795690059661865
Validation loss: 2.123385416564121

Epoch: 6| Step: 5
Training loss: 1.9596574306488037
Validation loss: 2.1135381857554116

Epoch: 6| Step: 6
Training loss: 1.8640573024749756
Validation loss: 2.144092244486655

Epoch: 6| Step: 7
Training loss: 1.6007119417190552
Validation loss: 2.098553643431715

Epoch: 6| Step: 8
Training loss: 1.5173842906951904
Validation loss: 2.1026688596253753

Epoch: 6| Step: 9
Training loss: 1.853695034980774
Validation loss: 2.113699277242025

Epoch: 6| Step: 10
Training loss: 1.7220914363861084
Validation loss: 2.095554171069976

Epoch: 6| Step: 11
Training loss: 1.878448247909546
Validation loss: 2.081983539365953

Epoch: 6| Step: 12
Training loss: 2.203880786895752
Validation loss: 2.132919237177859

Epoch: 6| Step: 13
Training loss: 2.4464595317840576
Validation loss: 2.150402076782719

Epoch: 381| Step: 0
Training loss: 2.1301050186157227
Validation loss: 2.107026305249942

Epoch: 6| Step: 1
Training loss: 2.198336601257324
Validation loss: 2.1398481745873728

Epoch: 6| Step: 2
Training loss: 2.5904650688171387
Validation loss: 2.167740506510581

Epoch: 6| Step: 3
Training loss: 1.9231932163238525
Validation loss: 2.153818145875008

Epoch: 6| Step: 4
Training loss: 2.159883975982666
Validation loss: 2.1275562009503766

Epoch: 6| Step: 5
Training loss: 1.528047800064087
Validation loss: 2.133728760544972

Epoch: 6| Step: 6
Training loss: 1.9297044277191162
Validation loss: 2.1771115884985974

Epoch: 6| Step: 7
Training loss: 1.800865650177002
Validation loss: 2.1275904614438295

Epoch: 6| Step: 8
Training loss: 1.5963881015777588
Validation loss: 2.122031847635905

Epoch: 6| Step: 9
Training loss: 1.4376318454742432
Validation loss: 2.0459575781258206

Epoch: 6| Step: 10
Training loss: 1.9215567111968994
Validation loss: 2.100814198934904

Epoch: 6| Step: 11
Training loss: 1.1035699844360352
Validation loss: 2.094569621547576

Epoch: 6| Step: 12
Training loss: 1.9729324579238892
Validation loss: 2.1345581572542907

Epoch: 6| Step: 13
Training loss: 1.488994836807251
Validation loss: 2.099335449998097

Epoch: 382| Step: 0
Training loss: 1.729670524597168
Validation loss: 2.1763887431031916

Epoch: 6| Step: 1
Training loss: 1.9609930515289307
Validation loss: 2.0960120949693906

Epoch: 6| Step: 2
Training loss: 1.6276018619537354
Validation loss: 2.1800466506711897

Epoch: 6| Step: 3
Training loss: 1.9481539726257324
Validation loss: 2.1623385388364076

Epoch: 6| Step: 4
Training loss: 2.0950987339019775
Validation loss: 2.1283172202366654

Epoch: 6| Step: 5
Training loss: 1.9196174144744873
Validation loss: 2.1517283954927997

Epoch: 6| Step: 6
Training loss: 1.8370835781097412
Validation loss: 2.1284556850310294

Epoch: 6| Step: 7
Training loss: 1.6084473133087158
Validation loss: 2.1998934463788102

Epoch: 6| Step: 8
Training loss: 2.1399993896484375
Validation loss: 2.107983307171893

Epoch: 6| Step: 9
Training loss: 2.045970916748047
Validation loss: 2.1725903352101645

Epoch: 6| Step: 10
Training loss: 2.0370678901672363
Validation loss: 2.1943826803597073

Epoch: 6| Step: 11
Training loss: 1.7493047714233398
Validation loss: 2.241578813522093

Epoch: 6| Step: 12
Training loss: 1.9522883892059326
Validation loss: 2.191399537106996

Epoch: 6| Step: 13
Training loss: 1.3065671920776367
Validation loss: 2.1602610080472884

Epoch: 383| Step: 0
Training loss: 1.7508069276809692
Validation loss: 2.2114866497696086

Epoch: 6| Step: 1
Training loss: 2.295606851577759
Validation loss: 2.158215485593324

Epoch: 6| Step: 2
Training loss: 2.134550094604492
Validation loss: 2.1429725923845844

Epoch: 6| Step: 3
Training loss: 2.18839430809021
Validation loss: 2.146130772047145

Epoch: 6| Step: 4
Training loss: 2.269867181777954
Validation loss: 2.1483331444442912

Epoch: 6| Step: 5
Training loss: 1.4006152153015137
Validation loss: 2.0820618060327347

Epoch: 6| Step: 6
Training loss: 1.2101664543151855
Validation loss: 2.096443207033219

Epoch: 6| Step: 7
Training loss: 1.8006689548492432
Validation loss: 2.102279301612608

Epoch: 6| Step: 8
Training loss: 2.4141592979431152
Validation loss: 2.093562285105387

Epoch: 6| Step: 9
Training loss: 1.6033387184143066
Validation loss: 2.1161976629687893

Epoch: 6| Step: 10
Training loss: 1.5859553813934326
Validation loss: 2.130780863505538

Epoch: 6| Step: 11
Training loss: 1.6225218772888184
Validation loss: 2.135767072759649

Epoch: 6| Step: 12
Training loss: 1.7919496297836304
Validation loss: 2.1855231843968874

Epoch: 6| Step: 13
Training loss: 1.1337000131607056
Validation loss: 2.2095558681795673

Epoch: 384| Step: 0
Training loss: 1.4469801187515259
Validation loss: 2.1323302971419467

Epoch: 6| Step: 1
Training loss: 2.3400795459747314
Validation loss: 2.1316180767551547

Epoch: 6| Step: 2
Training loss: 1.7142274379730225
Validation loss: 2.019309265639192

Epoch: 6| Step: 3
Training loss: 1.490051031112671
Validation loss: 2.091774372644322

Epoch: 6| Step: 4
Training loss: 1.9301462173461914
Validation loss: 2.1584807313898557

Epoch: 6| Step: 5
Training loss: 1.3672161102294922
Validation loss: 2.0839775121340187

Epoch: 6| Step: 6
Training loss: 2.1146798133850098
Validation loss: 2.0940437778349845

Epoch: 6| Step: 7
Training loss: 1.998354434967041
Validation loss: 2.077557204872049

Epoch: 6| Step: 8
Training loss: 2.252335786819458
Validation loss: 2.236579333582232

Epoch: 6| Step: 9
Training loss: 1.6947791576385498
Validation loss: 2.1853869884244856

Epoch: 6| Step: 10
Training loss: 1.8343374729156494
Validation loss: 2.057039307009789

Epoch: 6| Step: 11
Training loss: 1.1725575923919678
Validation loss: 2.1591959255997852

Epoch: 6| Step: 12
Training loss: 2.587690830230713
Validation loss: 2.1839454712406283

Epoch: 6| Step: 13
Training loss: 1.8156636953353882
Validation loss: 2.213556217890914

Epoch: 385| Step: 0
Training loss: 1.722496509552002
Validation loss: 2.098666905074991

Epoch: 6| Step: 1
Training loss: 2.1582000255584717
Validation loss: 2.1693247287504134

Epoch: 6| Step: 2
Training loss: 2.070493221282959
Validation loss: 2.1328956311748875

Epoch: 6| Step: 3
Training loss: 1.5941648483276367
Validation loss: 2.1546804622937272

Epoch: 6| Step: 4
Training loss: 1.9137401580810547
Validation loss: 2.124192004562706

Epoch: 6| Step: 5
Training loss: 1.7982467412948608
Validation loss: 2.21472619810412

Epoch: 6| Step: 6
Training loss: 1.4473837614059448
Validation loss: 2.177517088510657

Epoch: 6| Step: 7
Training loss: 1.30193030834198
Validation loss: 2.164377333015524

Epoch: 6| Step: 8
Training loss: 2.257977247238159
Validation loss: 2.1259534333341863

Epoch: 6| Step: 9
Training loss: 2.0259156227111816
Validation loss: 2.1466908916350333

Epoch: 6| Step: 10
Training loss: 2.3101754188537598
Validation loss: 2.18002728749347

Epoch: 6| Step: 11
Training loss: 2.200699806213379
Validation loss: 2.054689548348868

Epoch: 6| Step: 12
Training loss: 1.6944992542266846
Validation loss: 2.1373458190630843

Epoch: 6| Step: 13
Training loss: 1.4209662675857544
Validation loss: 2.1325680543017644

Epoch: 386| Step: 0
Training loss: 1.8633431196212769
Validation loss: 2.1468007308180614

Epoch: 6| Step: 1
Training loss: 1.6404194831848145
Validation loss: 2.084235043935878

Epoch: 6| Step: 2
Training loss: 1.6758939027786255
Validation loss: 2.0381715143880537

Epoch: 6| Step: 3
Training loss: 2.8867249488830566
Validation loss: 2.098531864022696

Epoch: 6| Step: 4
Training loss: 1.6495466232299805
Validation loss: 2.0869045590841644

Epoch: 6| Step: 5
Training loss: 1.70487642288208
Validation loss: 2.1452244943188084

Epoch: 6| Step: 6
Training loss: 0.9938518404960632
Validation loss: 2.16848708480917

Epoch: 6| Step: 7
Training loss: 2.4504623413085938
Validation loss: 2.1177247852407475

Epoch: 6| Step: 8
Training loss: 1.4292106628417969
Validation loss: 2.1293900205243017

Epoch: 6| Step: 9
Training loss: 2.186917781829834
Validation loss: 2.13383589765077

Epoch: 6| Step: 10
Training loss: 1.9952516555786133
Validation loss: 2.0675955613454184

Epoch: 6| Step: 11
Training loss: 1.9118320941925049
Validation loss: 2.1060742793544645

Epoch: 6| Step: 12
Training loss: 1.2469056844711304
Validation loss: 2.084350529537406

Epoch: 6| Step: 13
Training loss: 1.3372989892959595
Validation loss: 2.1482493979956514

Epoch: 387| Step: 0
Training loss: 1.937241792678833
Validation loss: 2.137800996021558

Epoch: 6| Step: 1
Training loss: 1.9364063739776611
Validation loss: 2.221297930645686

Epoch: 6| Step: 2
Training loss: 2.816974401473999
Validation loss: 2.1422576827387654

Epoch: 6| Step: 3
Training loss: 1.6039471626281738
Validation loss: 2.1595469777302077

Epoch: 6| Step: 4
Training loss: 1.2159810066223145
Validation loss: 2.1852423068015807

Epoch: 6| Step: 5
Training loss: 1.9828660488128662
Validation loss: 2.148046474302969

Epoch: 6| Step: 6
Training loss: 2.2638378143310547
Validation loss: 2.1827000494926208

Epoch: 6| Step: 7
Training loss: 1.1791720390319824
Validation loss: 2.1949071140699488

Epoch: 6| Step: 8
Training loss: 1.9101938009262085
Validation loss: 2.1892211398770733

Epoch: 6| Step: 9
Training loss: 1.6424219608306885
Validation loss: 2.129714440273982

Epoch: 6| Step: 10
Training loss: 1.441141128540039
Validation loss: 2.1627737283706665

Epoch: 6| Step: 11
Training loss: 1.1174999475479126
Validation loss: 2.1393075386683145

Epoch: 6| Step: 12
Training loss: 2.411695957183838
Validation loss: 2.0732087242987847

Epoch: 6| Step: 13
Training loss: 2.134114980697632
Validation loss: 2.131205230630854

Epoch: 388| Step: 0
Training loss: 2.085987091064453
Validation loss: 2.1687513218131116

Epoch: 6| Step: 1
Training loss: 1.7744886875152588
Validation loss: 2.06814649797255

Epoch: 6| Step: 2
Training loss: 1.7762770652770996
Validation loss: 2.0963390232414327

Epoch: 6| Step: 3
Training loss: 1.5373094081878662
Validation loss: 2.090969829149144

Epoch: 6| Step: 4
Training loss: 1.8609580993652344
Validation loss: 2.1224244025445755

Epoch: 6| Step: 5
Training loss: 2.0154547691345215
Validation loss: 2.145307501157125

Epoch: 6| Step: 6
Training loss: 2.2867021560668945
Validation loss: 2.0840871334075928

Epoch: 6| Step: 7
Training loss: 1.6762261390686035
Validation loss: 2.1290563139864194

Epoch: 6| Step: 8
Training loss: 2.9428911209106445
Validation loss: 2.0669262332300984

Epoch: 6| Step: 9
Training loss: 1.7521142959594727
Validation loss: 2.182402845351927

Epoch: 6| Step: 10
Training loss: 1.8255622386932373
Validation loss: 2.1152745754488054

Epoch: 6| Step: 11
Training loss: 1.5911751985549927
Validation loss: 2.1329663415108957

Epoch: 6| Step: 12
Training loss: 1.4376404285430908
Validation loss: 2.0837549163449194

Epoch: 6| Step: 13
Training loss: 0.8452062010765076
Validation loss: 2.0320034501373128

Epoch: 389| Step: 0
Training loss: 2.159717559814453
Validation loss: 2.1587352086138982

Epoch: 6| Step: 1
Training loss: 1.5937438011169434
Validation loss: 2.114614535403508

Epoch: 6| Step: 2
Training loss: 1.4674220085144043
Validation loss: 2.1140481489960865

Epoch: 6| Step: 3
Training loss: 1.193222165107727
Validation loss: 2.113074820528748

Epoch: 6| Step: 4
Training loss: 1.9466155767440796
Validation loss: 2.1615684314440657

Epoch: 6| Step: 5
Training loss: 1.6922638416290283
Validation loss: 2.0981103451021257

Epoch: 6| Step: 6
Training loss: 2.3570303916931152
Validation loss: 2.143085134926663

Epoch: 6| Step: 7
Training loss: 2.120345115661621
Validation loss: 2.126388498531875

Epoch: 6| Step: 8
Training loss: 2.4701716899871826
Validation loss: 2.2107657976047967

Epoch: 6| Step: 9
Training loss: 2.004608154296875
Validation loss: 2.1292005700449788

Epoch: 6| Step: 10
Training loss: 1.4182422161102295
Validation loss: 2.1318229065146497

Epoch: 6| Step: 11
Training loss: 1.7665868997573853
Validation loss: 2.158556197279243

Epoch: 6| Step: 12
Training loss: 1.447356939315796
Validation loss: 2.152368086640553

Epoch: 6| Step: 13
Training loss: 1.9444808959960938
Validation loss: 2.1254536951741865

Epoch: 390| Step: 0
Training loss: 1.8493964672088623
Validation loss: 2.1361498755793416

Epoch: 6| Step: 1
Training loss: 1.586186170578003
Validation loss: 2.096996057418085

Epoch: 6| Step: 2
Training loss: 2.3401618003845215
Validation loss: 2.205822231949017

Epoch: 6| Step: 3
Training loss: 1.4354501962661743
Validation loss: 2.0778982459857898

Epoch: 6| Step: 4
Training loss: 1.4442662000656128
Validation loss: 2.160307192033337

Epoch: 6| Step: 5
Training loss: 1.38413667678833
Validation loss: 2.1641687065042476

Epoch: 6| Step: 6
Training loss: 1.9571243524551392
Validation loss: 2.1435501101196452

Epoch: 6| Step: 7
Training loss: 2.5985515117645264
Validation loss: 2.1847835125461703

Epoch: 6| Step: 8
Training loss: 1.738090991973877
Validation loss: 2.1653961545677594

Epoch: 6| Step: 9
Training loss: 2.0236716270446777
Validation loss: 2.1377967429417435

Epoch: 6| Step: 10
Training loss: 2.125964879989624
Validation loss: 2.1203282340880363

Epoch: 6| Step: 11
Training loss: 1.3479418754577637
Validation loss: 2.159898750243648

Epoch: 6| Step: 12
Training loss: 2.0084028244018555
Validation loss: 2.1856521175753687

Epoch: 6| Step: 13
Training loss: 0.7605910301208496
Validation loss: 2.0742553203336653

Epoch: 391| Step: 0
Training loss: 1.7043430805206299
Validation loss: 2.196947977107058

Epoch: 6| Step: 1
Training loss: 2.076136827468872
Validation loss: 2.1349501558529433

Epoch: 6| Step: 2
Training loss: 1.8493168354034424
Validation loss: 2.1083072462389545

Epoch: 6| Step: 3
Training loss: 1.6011826992034912
Validation loss: 2.132396718507172

Epoch: 6| Step: 4
Training loss: 3.27168607711792
Validation loss: 2.115909860980126

Epoch: 6| Step: 5
Training loss: 1.8562053442001343
Validation loss: 2.1110720737006075

Epoch: 6| Step: 6
Training loss: 1.2624399662017822
Validation loss: 2.1451247174252748

Epoch: 6| Step: 7
Training loss: 2.2155392169952393
Validation loss: 2.136708387764551

Epoch: 6| Step: 8
Training loss: 1.9291579723358154
Validation loss: 2.059834808431646

Epoch: 6| Step: 9
Training loss: 1.5569219589233398
Validation loss: 2.1468609507365892

Epoch: 6| Step: 10
Training loss: 1.4334707260131836
Validation loss: 2.1536318153463383

Epoch: 6| Step: 11
Training loss: 2.203207492828369
Validation loss: 2.068196451792153

Epoch: 6| Step: 12
Training loss: 0.9759284853935242
Validation loss: 2.125437810856809

Epoch: 6| Step: 13
Training loss: 0.9984201788902283
Validation loss: 2.111371067262465

Epoch: 392| Step: 0
Training loss: 2.2573089599609375
Validation loss: 2.120256695696103

Epoch: 6| Step: 1
Training loss: 1.8215575218200684
Validation loss: 2.0780795005060013

Epoch: 6| Step: 2
Training loss: 1.8084211349487305
Validation loss: 2.1350431211533083

Epoch: 6| Step: 3
Training loss: 1.6190251111984253
Validation loss: 2.0275118914983605

Epoch: 6| Step: 4
Training loss: 1.6583499908447266
Validation loss: 2.1950840860284786

Epoch: 6| Step: 5
Training loss: 1.8715529441833496
Validation loss: 2.106080899956406

Epoch: 6| Step: 6
Training loss: 2.096139430999756
Validation loss: 2.158189042921989

Epoch: 6| Step: 7
Training loss: 1.8886367082595825
Validation loss: 2.1241230323750484

Epoch: 6| Step: 8
Training loss: 1.4692751169204712
Validation loss: 2.1709752595552834

Epoch: 6| Step: 9
Training loss: 1.9971723556518555
Validation loss: 2.185312727446197

Epoch: 6| Step: 10
Training loss: 2.3042523860931396
Validation loss: 2.1411807485806045

Epoch: 6| Step: 11
Training loss: 1.0207511186599731
Validation loss: 2.0996875775757657

Epoch: 6| Step: 12
Training loss: 2.018519639968872
Validation loss: 2.129436695447532

Epoch: 6| Step: 13
Training loss: 1.0921683311462402
Validation loss: 2.1071557550020117

Epoch: 393| Step: 0
Training loss: 2.773244857788086
Validation loss: 2.080916162460081

Epoch: 6| Step: 1
Training loss: 1.9812628030776978
Validation loss: 2.0951420773742018

Epoch: 6| Step: 2
Training loss: 1.8803945779800415
Validation loss: 2.1712672172054166

Epoch: 6| Step: 3
Training loss: 1.1352417469024658
Validation loss: 2.1306426320024716

Epoch: 6| Step: 4
Training loss: 2.226640224456787
Validation loss: 2.1241723901482037

Epoch: 6| Step: 5
Training loss: 1.4451818466186523
Validation loss: 2.1283030048493417

Epoch: 6| Step: 6
Training loss: 1.4587225914001465
Validation loss: 2.077421522909595

Epoch: 6| Step: 7
Training loss: 1.3838810920715332
Validation loss: 2.159465182212091

Epoch: 6| Step: 8
Training loss: 2.0910990238189697
Validation loss: 2.126288842129451

Epoch: 6| Step: 9
Training loss: 1.3361854553222656
Validation loss: 2.110029305181196

Epoch: 6| Step: 10
Training loss: 2.686204433441162
Validation loss: 2.1107655789262507

Epoch: 6| Step: 11
Training loss: 1.5285637378692627
Validation loss: 2.144618131781137

Epoch: 6| Step: 12
Training loss: 1.100318431854248
Validation loss: 2.2000727371502946

Epoch: 6| Step: 13
Training loss: 1.8070471286773682
Validation loss: 2.0999982433934368

Epoch: 394| Step: 0
Training loss: 2.19008731842041
Validation loss: 2.182891655993718

Epoch: 6| Step: 1
Training loss: 1.5055673122406006
Validation loss: 2.1205883205577893

Epoch: 6| Step: 2
Training loss: 2.2265162467956543
Validation loss: 2.10860590909117

Epoch: 6| Step: 3
Training loss: 1.6213774681091309
Validation loss: 2.13495308609419

Epoch: 6| Step: 4
Training loss: 2.1387779712677
Validation loss: 2.1441035193781697

Epoch: 6| Step: 5
Training loss: 1.8095487356185913
Validation loss: 2.1629982635539067

Epoch: 6| Step: 6
Training loss: 1.7361289262771606
Validation loss: 2.1586894117375857

Epoch: 6| Step: 7
Training loss: 1.9794049263000488
Validation loss: 2.1304451099006076

Epoch: 6| Step: 8
Training loss: 1.4806336164474487
Validation loss: 2.1694437688396824

Epoch: 6| Step: 9
Training loss: 1.8245208263397217
Validation loss: 2.1214339810033

Epoch: 6| Step: 10
Training loss: 1.6214971542358398
Validation loss: 2.1505826391199583

Epoch: 6| Step: 11
Training loss: 1.8116099834442139
Validation loss: 2.1008095882272206

Epoch: 6| Step: 12
Training loss: 2.1765406131744385
Validation loss: 2.087704904617802

Epoch: 6| Step: 13
Training loss: 0.898560106754303
Validation loss: 2.152028550383865

Epoch: 395| Step: 0
Training loss: 2.1226894855499268
Validation loss: 2.126474516366118

Epoch: 6| Step: 1
Training loss: 2.486112594604492
Validation loss: 2.122749618304673

Epoch: 6| Step: 2
Training loss: 1.2212305068969727
Validation loss: 2.0769473993650047

Epoch: 6| Step: 3
Training loss: 1.5396322011947632
Validation loss: 2.1235082636597338

Epoch: 6| Step: 4
Training loss: 1.9076567888259888
Validation loss: 2.2151579523599274

Epoch: 6| Step: 5
Training loss: 1.6846528053283691
Validation loss: 2.165449744911604

Epoch: 6| Step: 6
Training loss: 2.24039363861084
Validation loss: 2.1096318665371148

Epoch: 6| Step: 7
Training loss: 1.1615618467330933
Validation loss: 2.101424244142348

Epoch: 6| Step: 8
Training loss: 2.159147262573242
Validation loss: 2.160323376296669

Epoch: 6| Step: 9
Training loss: 1.6311511993408203
Validation loss: 2.1480934055902625

Epoch: 6| Step: 10
Training loss: 1.1982184648513794
Validation loss: 2.2116829502967095

Epoch: 6| Step: 11
Training loss: 1.897945523262024
Validation loss: 2.088663557524322

Epoch: 6| Step: 12
Training loss: 2.2354702949523926
Validation loss: 2.166064462354106

Epoch: 6| Step: 13
Training loss: 2.633829116821289
Validation loss: 2.1641386401268745

Epoch: 396| Step: 0
Training loss: 1.6741185188293457
Validation loss: 2.1805911166693575

Epoch: 6| Step: 1
Training loss: 2.313579797744751
Validation loss: 2.149213716547976

Epoch: 6| Step: 2
Training loss: 2.721489667892456
Validation loss: 2.2167341350227274

Epoch: 6| Step: 3
Training loss: 1.702927589416504
Validation loss: 2.20874378501728

Epoch: 6| Step: 4
Training loss: 1.0112731456756592
Validation loss: 2.124281564066487

Epoch: 6| Step: 5
Training loss: 1.4117482900619507
Validation loss: 2.1947917630595546

Epoch: 6| Step: 6
Training loss: 2.1148838996887207
Validation loss: 2.182247987357519

Epoch: 6| Step: 7
Training loss: 1.986527442932129
Validation loss: 2.129992884974326

Epoch: 6| Step: 8
Training loss: 1.7474312782287598
Validation loss: 2.1232972221989788

Epoch: 6| Step: 9
Training loss: 1.3157144784927368
Validation loss: 2.1878556589926443

Epoch: 6| Step: 10
Training loss: 1.6983031034469604
Validation loss: 2.1982333467852686

Epoch: 6| Step: 11
Training loss: 1.650706171989441
Validation loss: 2.1043706017155803

Epoch: 6| Step: 12
Training loss: 1.8862006664276123
Validation loss: 2.135816317732616

Epoch: 6| Step: 13
Training loss: 1.8395905494689941
Validation loss: 2.1032176889399046

Epoch: 397| Step: 0
Training loss: 1.7895089387893677
Validation loss: 2.1500364016461115

Epoch: 6| Step: 1
Training loss: 1.9635632038116455
Validation loss: 2.1601125911999772

Epoch: 6| Step: 2
Training loss: 1.518986463546753
Validation loss: 2.072368365462108

Epoch: 6| Step: 3
Training loss: 2.025702953338623
Validation loss: 2.1686133043740385

Epoch: 6| Step: 4
Training loss: 1.7811565399169922
Validation loss: 2.1343328747698056

Epoch: 6| Step: 5
Training loss: 2.155714273452759
Validation loss: 2.112979164687536

Epoch: 6| Step: 6
Training loss: 1.9140175580978394
Validation loss: 2.1289877455721617

Epoch: 6| Step: 7
Training loss: 1.7268821001052856
Validation loss: 2.1022833649830153

Epoch: 6| Step: 8
Training loss: 2.827253818511963
Validation loss: 2.1289058654539046

Epoch: 6| Step: 9
Training loss: 1.0975264310836792
Validation loss: 2.1092028617858887

Epoch: 6| Step: 10
Training loss: 1.4910862445831299
Validation loss: 2.1537514707093597

Epoch: 6| Step: 11
Training loss: 1.8924734592437744
Validation loss: 2.14924427001707

Epoch: 6| Step: 12
Training loss: 1.356806755065918
Validation loss: 2.1804178581442883

Epoch: 6| Step: 13
Training loss: 1.3362332582473755
Validation loss: 2.1158770207435853

Epoch: 398| Step: 0
Training loss: 1.7596062421798706
Validation loss: 2.205462048130651

Epoch: 6| Step: 1
Training loss: 1.654036521911621
Validation loss: 2.174003290873702

Epoch: 6| Step: 2
Training loss: 2.2790350914001465
Validation loss: 2.150563960434288

Epoch: 6| Step: 3
Training loss: 1.5584810972213745
Validation loss: 2.117867483887621

Epoch: 6| Step: 4
Training loss: 1.385938286781311
Validation loss: 2.113679849973289

Epoch: 6| Step: 5
Training loss: 1.7763254642486572
Validation loss: 2.1699699765892437

Epoch: 6| Step: 6
Training loss: 2.002166509628296
Validation loss: 2.142674058996221

Epoch: 6| Step: 7
Training loss: 1.934638500213623
Validation loss: 2.1977708314054754

Epoch: 6| Step: 8
Training loss: 1.7196937799453735
Validation loss: 2.0841825867211945

Epoch: 6| Step: 9
Training loss: 1.7032448053359985
Validation loss: 2.1440783918544812

Epoch: 6| Step: 10
Training loss: 1.8648593425750732
Validation loss: 2.0674159347370105

Epoch: 6| Step: 11
Training loss: 1.6525769233703613
Validation loss: 2.148254668840798

Epoch: 6| Step: 12
Training loss: 1.758502721786499
Validation loss: 2.149310496545607

Epoch: 6| Step: 13
Training loss: 2.195221185684204
Validation loss: 2.1582690797826296

Epoch: 399| Step: 0
Training loss: 1.8272004127502441
Validation loss: 2.1272830706770702

Epoch: 6| Step: 1
Training loss: 1.9162272214889526
Validation loss: 2.0924549448874687

Epoch: 6| Step: 2
Training loss: 1.8307188749313354
Validation loss: 2.191751149392897

Epoch: 6| Step: 3
Training loss: 1.988160490989685
Validation loss: 2.098560699852564

Epoch: 6| Step: 4
Training loss: 1.351294994354248
Validation loss: 2.204849230345859

Epoch: 6| Step: 5
Training loss: 1.696918249130249
Validation loss: 2.2018935757298626

Epoch: 6| Step: 6
Training loss: 1.2771780490875244
Validation loss: 2.191104112132903

Epoch: 6| Step: 7
Training loss: 2.0391342639923096
Validation loss: 2.217389875842679

Epoch: 6| Step: 8
Training loss: 1.9305179119110107
Validation loss: 2.1484227975209556

Epoch: 6| Step: 9
Training loss: 1.3207941055297852
Validation loss: 2.127552511871502

Epoch: 6| Step: 10
Training loss: 2.2754881381988525
Validation loss: 2.1586837307099374

Epoch: 6| Step: 11
Training loss: 1.690634846687317
Validation loss: 2.1085345796359483

Epoch: 6| Step: 12
Training loss: 1.977346420288086
Validation loss: 2.10108474762209

Epoch: 6| Step: 13
Training loss: 2.3405873775482178
Validation loss: 2.1830996454402967

Epoch: 400| Step: 0
Training loss: 2.212616443634033
Validation loss: 2.1131476125409527

Epoch: 6| Step: 1
Training loss: 1.3553509712219238
Validation loss: 2.0800726926454933

Epoch: 6| Step: 2
Training loss: 2.4763503074645996
Validation loss: 2.0684805390655354

Epoch: 6| Step: 3
Training loss: 1.905073642730713
Validation loss: 2.1287629758158038

Epoch: 6| Step: 4
Training loss: 1.8175712823867798
Validation loss: 2.1223117689932547

Epoch: 6| Step: 5
Training loss: 2.350776433944702
Validation loss: 2.0438416593818256

Epoch: 6| Step: 6
Training loss: 1.909986972808838
Validation loss: 2.116984349425121

Epoch: 6| Step: 7
Training loss: 1.5455131530761719
Validation loss: 2.1052372071050827

Epoch: 6| Step: 8
Training loss: 1.4842963218688965
Validation loss: 2.160778295609259

Epoch: 6| Step: 9
Training loss: 2.1032068729400635
Validation loss: 2.135261680490227

Epoch: 6| Step: 10
Training loss: 1.8625346422195435
Validation loss: 2.1782302497535624

Epoch: 6| Step: 11
Training loss: 0.9572834968566895
Validation loss: 2.16116839326838

Epoch: 6| Step: 12
Training loss: 1.3675130605697632
Validation loss: 2.1463869387103665

Epoch: 6| Step: 13
Training loss: 1.8407175540924072
Validation loss: 2.0793800712913595

Epoch: 401| Step: 0
Training loss: 2.268982410430908
Validation loss: 2.120217251521285

Epoch: 6| Step: 1
Training loss: 2.4647388458251953
Validation loss: 2.0782506414639053

Epoch: 6| Step: 2
Training loss: 1.8527463674545288
Validation loss: 2.1219310324679137

Epoch: 6| Step: 3
Training loss: 1.6168923377990723
Validation loss: 2.1960845378137406

Epoch: 6| Step: 4
Training loss: 1.9000730514526367
Validation loss: 2.104845216197352

Epoch: 6| Step: 5
Training loss: 1.269223690032959
Validation loss: 2.095317820067047

Epoch: 6| Step: 6
Training loss: 1.6456589698791504
Validation loss: 2.1029602622473114

Epoch: 6| Step: 7
Training loss: 2.1469316482543945
Validation loss: 2.1251676403066164

Epoch: 6| Step: 8
Training loss: 1.9316755533218384
Validation loss: 2.1638503305373655

Epoch: 6| Step: 9
Training loss: 1.192270278930664
Validation loss: 2.0957076498257217

Epoch: 6| Step: 10
Training loss: 2.3253748416900635
Validation loss: 2.116559402917021

Epoch: 6| Step: 11
Training loss: 1.2212556600570679
Validation loss: 2.169444473840857

Epoch: 6| Step: 12
Training loss: 1.5070910453796387
Validation loss: 2.0824167459241805

Epoch: 6| Step: 13
Training loss: 2.060164213180542
Validation loss: 2.100870356764845

Epoch: 402| Step: 0
Training loss: 1.6357473134994507
Validation loss: 2.2032716120443037

Epoch: 6| Step: 1
Training loss: 1.7768938541412354
Validation loss: 2.1499464024779615

Epoch: 6| Step: 2
Training loss: 2.3208906650543213
Validation loss: 2.1243800834942888

Epoch: 6| Step: 3
Training loss: 2.1985833644866943
Validation loss: 2.19138265168795

Epoch: 6| Step: 4
Training loss: 2.0988211631774902
Validation loss: 2.2236550879734818

Epoch: 6| Step: 5
Training loss: 1.6034643650054932
Validation loss: 2.1634498873064594

Epoch: 6| Step: 6
Training loss: 1.8627376556396484
Validation loss: 2.20843667240553

Epoch: 6| Step: 7
Training loss: 1.5816383361816406
Validation loss: 2.1772443684198524

Epoch: 6| Step: 8
Training loss: 2.093085765838623
Validation loss: 2.1676422601105063

Epoch: 6| Step: 9
Training loss: 1.491537094116211
Validation loss: 2.1213042120779715

Epoch: 6| Step: 10
Training loss: 2.1708476543426514
Validation loss: 2.15845488989225

Epoch: 6| Step: 11
Training loss: 1.91734778881073
Validation loss: 2.1733074649687736

Epoch: 6| Step: 12
Training loss: 1.340731143951416
Validation loss: 2.1695839487096316

Epoch: 6| Step: 13
Training loss: 0.6429107189178467
Validation loss: 2.1848556200663247

Epoch: 403| Step: 0
Training loss: 1.7614803314208984
Validation loss: 2.1960145029970395

Epoch: 6| Step: 1
Training loss: 1.8273851871490479
Validation loss: 2.1277332434090237

Epoch: 6| Step: 2
Training loss: 1.7496013641357422
Validation loss: 2.154049124768985

Epoch: 6| Step: 3
Training loss: 1.83009934425354
Validation loss: 2.0743401358204503

Epoch: 6| Step: 4
Training loss: 1.5977513790130615
Validation loss: 2.084181539473995

Epoch: 6| Step: 5
Training loss: 1.7900091409683228
Validation loss: 2.1178620092330442

Epoch: 6| Step: 6
Training loss: 1.7912760972976685
Validation loss: 2.1045304216364378

Epoch: 6| Step: 7
Training loss: 2.777275323867798
Validation loss: 2.1038795735246394

Epoch: 6| Step: 8
Training loss: 1.7022322416305542
Validation loss: 2.13555210380144

Epoch: 6| Step: 9
Training loss: 2.21480131149292
Validation loss: 2.118963864541823

Epoch: 6| Step: 10
Training loss: 1.4467393159866333
Validation loss: 2.1261138070014214

Epoch: 6| Step: 11
Training loss: 1.4921085834503174
Validation loss: 2.1339394507869596

Epoch: 6| Step: 12
Training loss: 1.705010175704956
Validation loss: 2.1496164798736572

Epoch: 6| Step: 13
Training loss: 0.8975204825401306
Validation loss: 2.0905071304690455

Epoch: 404| Step: 0
Training loss: 1.8653168678283691
Validation loss: 2.1685968368284163

Epoch: 6| Step: 1
Training loss: 2.0935726165771484
Validation loss: 2.14111735615679

Epoch: 6| Step: 2
Training loss: 1.6778383255004883
Validation loss: 2.2255465112706667

Epoch: 6| Step: 3
Training loss: 1.599777340888977
Validation loss: 2.0817257101817797

Epoch: 6| Step: 4
Training loss: 1.614281415939331
Validation loss: 2.1371605370634343

Epoch: 6| Step: 5
Training loss: 1.765553593635559
Validation loss: 2.1721542189198155

Epoch: 6| Step: 6
Training loss: 0.9473534822463989
Validation loss: 2.0699520393084456

Epoch: 6| Step: 7
Training loss: 2.0873665809631348
Validation loss: 2.0840662961365073

Epoch: 6| Step: 8
Training loss: 2.241914749145508
Validation loss: 2.1373231385343816

Epoch: 6| Step: 9
Training loss: 2.349822759628296
Validation loss: 2.06600558757782

Epoch: 6| Step: 10
Training loss: 1.251699686050415
Validation loss: 2.1431223474523073

Epoch: 6| Step: 11
Training loss: 1.7337477207183838
Validation loss: 2.125870276522893

Epoch: 6| Step: 12
Training loss: 1.9152235984802246
Validation loss: 2.140537367072157

Epoch: 6| Step: 13
Training loss: 2.436213493347168
Validation loss: 2.1568341844825336

Epoch: 405| Step: 0
Training loss: 1.9958536624908447
Validation loss: 2.152720028354276

Epoch: 6| Step: 1
Training loss: 1.6059300899505615
Validation loss: 2.1848567198681574

Epoch: 6| Step: 2
Training loss: 1.814627766609192
Validation loss: 2.0922847358129357

Epoch: 6| Step: 3
Training loss: 1.437277913093567
Validation loss: 2.116877732738372

Epoch: 6| Step: 4
Training loss: 1.6898491382598877
Validation loss: 2.1878061909829416

Epoch: 6| Step: 5
Training loss: 1.5437979698181152
Validation loss: 2.2132527469306864

Epoch: 6| Step: 6
Training loss: 1.2307490110397339
Validation loss: 2.181919173527789

Epoch: 6| Step: 7
Training loss: 1.6851149797439575
Validation loss: 2.11224885653424

Epoch: 6| Step: 8
Training loss: 1.9152848720550537
Validation loss: 2.1321214732303413

Epoch: 6| Step: 9
Training loss: 2.239311695098877
Validation loss: 2.1534927147690968

Epoch: 6| Step: 10
Training loss: 1.9895168542861938
Validation loss: 2.156197947840537

Epoch: 6| Step: 11
Training loss: 1.4298896789550781
Validation loss: 2.20856370464448

Epoch: 6| Step: 12
Training loss: 2.3462276458740234
Validation loss: 2.2571461392987158

Epoch: 6| Step: 13
Training loss: 2.353461980819702
Validation loss: 2.149528335499507

Epoch: 406| Step: 0
Training loss: 1.616061806678772
Validation loss: 2.173420839412238

Epoch: 6| Step: 1
Training loss: 2.121533155441284
Validation loss: 2.1000985868515505

Epoch: 6| Step: 2
Training loss: 2.0248751640319824
Validation loss: 2.1482169371779247

Epoch: 6| Step: 3
Training loss: 2.0726332664489746
Validation loss: 2.1700630034169843

Epoch: 6| Step: 4
Training loss: 1.5418167114257812
Validation loss: 2.0902995819686563

Epoch: 6| Step: 5
Training loss: 1.3414907455444336
Validation loss: 2.1674198783854

Epoch: 6| Step: 6
Training loss: 2.200742721557617
Validation loss: 2.1459028720855713

Epoch: 6| Step: 7
Training loss: 1.6416587829589844
Validation loss: 2.1016109553716515

Epoch: 6| Step: 8
Training loss: 2.0340051651000977
Validation loss: 2.1964542993935208

Epoch: 6| Step: 9
Training loss: 1.4546093940734863
Validation loss: 2.1266112173757246

Epoch: 6| Step: 10
Training loss: 1.8322434425354004
Validation loss: 2.136822831246161

Epoch: 6| Step: 11
Training loss: 1.870408058166504
Validation loss: 2.1790453259662916

Epoch: 6| Step: 12
Training loss: 1.563401222229004
Validation loss: 2.0442020816187703

Epoch: 6| Step: 13
Training loss: 1.6703195571899414
Validation loss: 2.1041357940243137

Epoch: 407| Step: 0
Training loss: 2.224771499633789
Validation loss: 2.16453283063827

Epoch: 6| Step: 1
Training loss: 2.0594449043273926
Validation loss: 2.1513248207748576

Epoch: 6| Step: 2
Training loss: 1.4334566593170166
Validation loss: 2.1421573597897767

Epoch: 6| Step: 3
Training loss: 1.4116325378417969
Validation loss: 2.1664016041704404

Epoch: 6| Step: 4
Training loss: 1.8023340702056885
Validation loss: 2.143564711334885

Epoch: 6| Step: 5
Training loss: 1.538414478302002
Validation loss: 2.071085297933189

Epoch: 6| Step: 6
Training loss: 1.4343652725219727
Validation loss: 2.0771249827518257

Epoch: 6| Step: 7
Training loss: 2.21091365814209
Validation loss: 2.1018675322173745

Epoch: 6| Step: 8
Training loss: 1.8844114542007446
Validation loss: 2.129422490314771

Epoch: 6| Step: 9
Training loss: 1.5766327381134033
Validation loss: 2.0140828304393317

Epoch: 6| Step: 10
Training loss: 1.8566652536392212
Validation loss: 2.128059797389533

Epoch: 6| Step: 11
Training loss: 1.7469888925552368
Validation loss: 2.0995895298578406

Epoch: 6| Step: 12
Training loss: 2.054943084716797
Validation loss: 2.101767160559213

Epoch: 6| Step: 13
Training loss: 1.5840363502502441
Validation loss: 2.2281310340409637

Epoch: 408| Step: 0
Training loss: 1.7101503610610962
Validation loss: 2.088414346018145

Epoch: 6| Step: 1
Training loss: 2.122734546661377
Validation loss: 2.079852448996677

Epoch: 6| Step: 2
Training loss: 2.495833396911621
Validation loss: 2.126512340320054

Epoch: 6| Step: 3
Training loss: 2.2060790061950684
Validation loss: 2.1089763013265466

Epoch: 6| Step: 4
Training loss: 1.385852575302124
Validation loss: 2.215790169213408

Epoch: 6| Step: 5
Training loss: 1.2572399377822876
Validation loss: 2.140689831908031

Epoch: 6| Step: 6
Training loss: 1.6826398372650146
Validation loss: 2.1837100828847578

Epoch: 6| Step: 7
Training loss: 1.160315990447998
Validation loss: 2.1439092005452802

Epoch: 6| Step: 8
Training loss: 2.0008575916290283
Validation loss: 2.1280579323409707

Epoch: 6| Step: 9
Training loss: 1.821862816810608
Validation loss: 2.1016140125131093

Epoch: 6| Step: 10
Training loss: 1.870410680770874
Validation loss: 2.07039891007126

Epoch: 6| Step: 11
Training loss: 1.5067814588546753
Validation loss: 2.1448686225439912

Epoch: 6| Step: 12
Training loss: 1.887783408164978
Validation loss: 2.138217200515091

Epoch: 6| Step: 13
Training loss: 2.0541796684265137
Validation loss: 2.157462530238654

Epoch: 409| Step: 0
Training loss: 2.352734088897705
Validation loss: 2.144198033117479

Epoch: 6| Step: 1
Training loss: 1.4613208770751953
Validation loss: 2.0871804452711538

Epoch: 6| Step: 2
Training loss: 1.839789867401123
Validation loss: 2.142262710038052

Epoch: 6| Step: 3
Training loss: 1.2670891284942627
Validation loss: 2.081806840435151

Epoch: 6| Step: 4
Training loss: 2.0710625648498535
Validation loss: 2.129251305774976

Epoch: 6| Step: 5
Training loss: 1.3666733503341675
Validation loss: 2.092708559446437

Epoch: 6| Step: 6
Training loss: 2.0087695121765137
Validation loss: 2.2205013203364548

Epoch: 6| Step: 7
Training loss: 2.2507848739624023
Validation loss: 2.139716944386882

Epoch: 6| Step: 8
Training loss: 1.5946834087371826
Validation loss: 2.0998538027527514

Epoch: 6| Step: 9
Training loss: 2.492511749267578
Validation loss: 2.106453000858266

Epoch: 6| Step: 10
Training loss: 1.8174657821655273
Validation loss: 2.1547500574460594

Epoch: 6| Step: 11
Training loss: 1.3717496395111084
Validation loss: 2.152597268422445

Epoch: 6| Step: 12
Training loss: 1.4323766231536865
Validation loss: 2.1765296049015497

Epoch: 6| Step: 13
Training loss: 1.7252745628356934
Validation loss: 2.168899051604732

Epoch: 410| Step: 0
Training loss: 2.220400810241699
Validation loss: 2.1443212057954524

Epoch: 6| Step: 1
Training loss: 1.4266998767852783
Validation loss: 2.0817702124195714

Epoch: 6| Step: 2
Training loss: 2.266240119934082
Validation loss: 2.1349276304244995

Epoch: 6| Step: 3
Training loss: 1.496302604675293
Validation loss: 2.1673842348078245

Epoch: 6| Step: 4
Training loss: 1.565502643585205
Validation loss: 2.130395245808427

Epoch: 6| Step: 5
Training loss: 2.1081082820892334
Validation loss: 2.196880268794234

Epoch: 6| Step: 6
Training loss: 1.7605488300323486
Validation loss: 2.170478477272936

Epoch: 6| Step: 7
Training loss: 1.6618847846984863
Validation loss: 2.1103658342874176

Epoch: 6| Step: 8
Training loss: 1.33085036277771
Validation loss: 2.14441248678392

Epoch: 6| Step: 9
Training loss: 2.227116346359253
Validation loss: 2.0387306726107033

Epoch: 6| Step: 10
Training loss: 2.1386542320251465
Validation loss: 2.1089680066672702

Epoch: 6| Step: 11
Training loss: 1.899118423461914
Validation loss: 2.109726047003141

Epoch: 6| Step: 12
Training loss: 1.9875590801239014
Validation loss: 2.121549132049725

Epoch: 6| Step: 13
Training loss: 0.9376193284988403
Validation loss: 2.0712909929213987

Epoch: 411| Step: 0
Training loss: 1.7476766109466553
Validation loss: 2.079023368896977

Epoch: 6| Step: 1
Training loss: 2.2244458198547363
Validation loss: 2.186006369129304

Epoch: 6| Step: 2
Training loss: 1.486388087272644
Validation loss: 2.0494296960933234

Epoch: 6| Step: 3
Training loss: 1.8634495735168457
Validation loss: 2.0810042273613716

Epoch: 6| Step: 4
Training loss: 1.3894367218017578
Validation loss: 2.0423001525222615

Epoch: 6| Step: 5
Training loss: 1.6154773235321045
Validation loss: 2.108940629548924

Epoch: 6| Step: 6
Training loss: 1.5667049884796143
Validation loss: 2.1082967276214273

Epoch: 6| Step: 7
Training loss: 2.4055745601654053
Validation loss: 2.154347999121553

Epoch: 6| Step: 8
Training loss: 1.6477572917938232
Validation loss: 2.142002106994711

Epoch: 6| Step: 9
Training loss: 2.0264499187469482
Validation loss: 2.086749328080044

Epoch: 6| Step: 10
Training loss: 1.4962689876556396
Validation loss: 2.105039600403078

Epoch: 6| Step: 11
Training loss: 2.2331838607788086
Validation loss: 2.1300294514625304

Epoch: 6| Step: 12
Training loss: 1.7635318040847778
Validation loss: 2.117860838931094

Epoch: 6| Step: 13
Training loss: 0.8725770115852356
Validation loss: 2.1670260634473575

Epoch: 412| Step: 0
Training loss: 1.9279427528381348
Validation loss: 2.1616417105479906

Epoch: 6| Step: 1
Training loss: 1.6185302734375
Validation loss: 2.158746850106024

Epoch: 6| Step: 2
Training loss: 1.8700871467590332
Validation loss: 2.0979154930319837

Epoch: 6| Step: 3
Training loss: 1.5379747152328491
Validation loss: 2.1734665465611283

Epoch: 6| Step: 4
Training loss: 2.369046211242676
Validation loss: 2.120666671824712

Epoch: 6| Step: 5
Training loss: 1.7308610677719116
Validation loss: 2.1697833204782135

Epoch: 6| Step: 6
Training loss: 1.6196980476379395
Validation loss: 2.112020766863259

Epoch: 6| Step: 7
Training loss: 1.69999361038208
Validation loss: 2.2077539684951946

Epoch: 6| Step: 8
Training loss: 1.835601806640625
Validation loss: 2.161282075348721

Epoch: 6| Step: 9
Training loss: 1.5185672044754028
Validation loss: 2.1290450378130843

Epoch: 6| Step: 10
Training loss: 1.815326452255249
Validation loss: 2.193932787064583

Epoch: 6| Step: 11
Training loss: 1.7131266593933105
Validation loss: 2.1287291934413295

Epoch: 6| Step: 12
Training loss: 1.3553708791732788
Validation loss: 2.1699526732967747

Epoch: 6| Step: 13
Training loss: 2.117044687271118
Validation loss: 2.1774273815975396

Epoch: 413| Step: 0
Training loss: 1.8085808753967285
Validation loss: 2.1528514098095637

Epoch: 6| Step: 1
Training loss: 1.9210455417633057
Validation loss: 2.158053472477903

Epoch: 6| Step: 2
Training loss: 1.3372597694396973
Validation loss: 2.1764141282727643

Epoch: 6| Step: 3
Training loss: 1.9585895538330078
Validation loss: 2.163143806560065

Epoch: 6| Step: 4
Training loss: 1.9382140636444092
Validation loss: 2.0259762066666798

Epoch: 6| Step: 5
Training loss: 1.963472604751587
Validation loss: 2.152437707429291

Epoch: 6| Step: 6
Training loss: 1.1620490550994873
Validation loss: 2.0999006148307555

Epoch: 6| Step: 7
Training loss: 1.5842941999435425
Validation loss: 2.1829861825512302

Epoch: 6| Step: 8
Training loss: 1.4376531839370728
Validation loss: 2.0953219167647825

Epoch: 6| Step: 9
Training loss: 2.1886441707611084
Validation loss: 2.0724962014023975

Epoch: 6| Step: 10
Training loss: 1.4012141227722168
Validation loss: 2.0719419012787523

Epoch: 6| Step: 11
Training loss: 1.7018407583236694
Validation loss: 2.1560207028542795

Epoch: 6| Step: 12
Training loss: 2.670750141143799
Validation loss: 2.1766311865980907

Epoch: 6| Step: 13
Training loss: 1.5419906377792358
Validation loss: 2.1805791777949177

Epoch: 414| Step: 0
Training loss: 1.904920220375061
Validation loss: 2.135375888116898

Epoch: 6| Step: 1
Training loss: 1.8895130157470703
Validation loss: 2.175550135233069

Epoch: 6| Step: 2
Training loss: 1.5247230529785156
Validation loss: 2.1450188467579503

Epoch: 6| Step: 3
Training loss: 1.5999224185943604
Validation loss: 2.1684420185704387

Epoch: 6| Step: 4
Training loss: 1.4029115438461304
Validation loss: 2.245614751692741

Epoch: 6| Step: 5
Training loss: 2.161102771759033
Validation loss: 2.123893150719263

Epoch: 6| Step: 6
Training loss: 2.28773832321167
Validation loss: 2.1237449569086873

Epoch: 6| Step: 7
Training loss: 1.2828668355941772
Validation loss: 2.2071302424194994

Epoch: 6| Step: 8
Training loss: 1.5189182758331299
Validation loss: 2.1329631472146637

Epoch: 6| Step: 9
Training loss: 1.6619869470596313
Validation loss: 2.149972128611739

Epoch: 6| Step: 10
Training loss: 2.608696460723877
Validation loss: 2.217143148504278

Epoch: 6| Step: 11
Training loss: 1.5776114463806152
Validation loss: 2.139125500955889

Epoch: 6| Step: 12
Training loss: 1.535679817199707
Validation loss: 2.204390074617119

Epoch: 6| Step: 13
Training loss: 1.7607988119125366
Validation loss: 2.124369821240825

Epoch: 415| Step: 0
Training loss: 1.4427878856658936
Validation loss: 2.152985744578864

Epoch: 6| Step: 1
Training loss: 1.1665663719177246
Validation loss: 2.176726484811434

Epoch: 6| Step: 2
Training loss: 2.1173343658447266
Validation loss: 2.0834981344079457

Epoch: 6| Step: 3
Training loss: 1.5170047283172607
Validation loss: 2.1442474780544156

Epoch: 6| Step: 4
Training loss: 1.6002122163772583
Validation loss: 2.1873489579846783

Epoch: 6| Step: 5
Training loss: 1.0175570249557495
Validation loss: 2.1518423916191183

Epoch: 6| Step: 6
Training loss: 2.003513813018799
Validation loss: 2.131002403074695

Epoch: 6| Step: 7
Training loss: 2.326249837875366
Validation loss: 2.1441643481613486

Epoch: 6| Step: 8
Training loss: 2.2556405067443848
Validation loss: 2.1964285219869306

Epoch: 6| Step: 9
Training loss: 2.2358431816101074
Validation loss: 2.1858292830887662

Epoch: 6| Step: 10
Training loss: 2.035703659057617
Validation loss: 2.127153468388383

Epoch: 6| Step: 11
Training loss: 1.5334337949752808
Validation loss: 2.053436508742712

Epoch: 6| Step: 12
Training loss: 1.646174669265747
Validation loss: 2.126083461187219

Epoch: 6| Step: 13
Training loss: 1.8300824165344238
Validation loss: 2.1325090572398198

Epoch: 416| Step: 0
Training loss: 2.535827159881592
Validation loss: 2.1666125443673905

Epoch: 6| Step: 1
Training loss: 1.8648254871368408
Validation loss: 2.159394152702824

Epoch: 6| Step: 2
Training loss: 1.48240327835083
Validation loss: 2.091942557724573

Epoch: 6| Step: 3
Training loss: 2.0044326782226562
Validation loss: 2.1148331101222704

Epoch: 6| Step: 4
Training loss: 1.3927909135818481
Validation loss: 2.141367509800901

Epoch: 6| Step: 5
Training loss: 2.0470850467681885
Validation loss: 2.108783480941608

Epoch: 6| Step: 6
Training loss: 1.7810931205749512
Validation loss: 2.0625602737549813

Epoch: 6| Step: 7
Training loss: 2.0610108375549316
Validation loss: 2.144201644005314

Epoch: 6| Step: 8
Training loss: 1.6451565027236938
Validation loss: 2.1223332343562955

Epoch: 6| Step: 9
Training loss: 1.6448408365249634
Validation loss: 2.1360202604724514

Epoch: 6| Step: 10
Training loss: 1.396277904510498
Validation loss: 2.1601927485517276

Epoch: 6| Step: 11
Training loss: 1.5876115560531616
Validation loss: 2.1899295878666702

Epoch: 6| Step: 12
Training loss: 1.8486812114715576
Validation loss: 2.185676374743062

Epoch: 6| Step: 13
Training loss: 1.439013123512268
Validation loss: 2.1786306852935464

Epoch: 417| Step: 0
Training loss: 2.1824493408203125
Validation loss: 2.0817052305385633

Epoch: 6| Step: 1
Training loss: 2.0981364250183105
Validation loss: 2.2001483824945267

Epoch: 6| Step: 2
Training loss: 2.182598114013672
Validation loss: 2.2008998727285736

Epoch: 6| Step: 3
Training loss: 1.7332453727722168
Validation loss: 2.1714245196311706

Epoch: 6| Step: 4
Training loss: 1.557631492614746
Validation loss: 2.1177654407357656

Epoch: 6| Step: 5
Training loss: 1.3255529403686523
Validation loss: 2.142878673409903

Epoch: 6| Step: 6
Training loss: 1.2651218175888062
Validation loss: 2.09258073119707

Epoch: 6| Step: 7
Training loss: 1.8518257141113281
Validation loss: 2.138676339580167

Epoch: 6| Step: 8
Training loss: 1.2496025562286377
Validation loss: 2.105882595944148

Epoch: 6| Step: 9
Training loss: 1.860044002532959
Validation loss: 2.185000608044286

Epoch: 6| Step: 10
Training loss: 2.2720601558685303
Validation loss: 2.120754352179907

Epoch: 6| Step: 11
Training loss: 1.664039134979248
Validation loss: 2.1618550618489585

Epoch: 6| Step: 12
Training loss: 1.2437595129013062
Validation loss: 2.132945881094984

Epoch: 6| Step: 13
Training loss: 2.019331932067871
Validation loss: 2.2529626584822133

Epoch: 418| Step: 0
Training loss: 1.2626020908355713
Validation loss: 2.0925927033988376

Epoch: 6| Step: 1
Training loss: 2.300351619720459
Validation loss: 2.1608691805152485

Epoch: 6| Step: 2
Training loss: 1.8083915710449219
Validation loss: 2.1630827919129403

Epoch: 6| Step: 3
Training loss: 1.3594856262207031
Validation loss: 2.1395048813153337

Epoch: 6| Step: 4
Training loss: 1.5056837797164917
Validation loss: 2.1661076186805643

Epoch: 6| Step: 5
Training loss: 1.674835205078125
Validation loss: 2.159092039190313

Epoch: 6| Step: 6
Training loss: 2.2078120708465576
Validation loss: 2.149993286337904

Epoch: 6| Step: 7
Training loss: 1.6091454029083252
Validation loss: 2.125336448351542

Epoch: 6| Step: 8
Training loss: 2.047699451446533
Validation loss: 2.159835143755841

Epoch: 6| Step: 9
Training loss: 2.0167417526245117
Validation loss: 2.124675896859938

Epoch: 6| Step: 10
Training loss: 2.027707576751709
Validation loss: 2.1072135740710842

Epoch: 6| Step: 11
Training loss: 1.32340407371521
Validation loss: 2.169760923231802

Epoch: 6| Step: 12
Training loss: 1.9499125480651855
Validation loss: 2.1754909766617643

Epoch: 6| Step: 13
Training loss: 1.6499624252319336
Validation loss: 2.1729800496050107

Epoch: 419| Step: 0
Training loss: 1.5397796630859375
Validation loss: 2.153113426700715

Epoch: 6| Step: 1
Training loss: 1.8688268661499023
Validation loss: 2.0956963185341126

Epoch: 6| Step: 2
Training loss: 2.306570529937744
Validation loss: 2.1500677895802323

Epoch: 6| Step: 3
Training loss: 1.0295827388763428
Validation loss: 2.1315786453985397

Epoch: 6| Step: 4
Training loss: 1.8871119022369385
Validation loss: 2.113941538718439

Epoch: 6| Step: 5
Training loss: 2.41886568069458
Validation loss: 2.1524836786331667

Epoch: 6| Step: 6
Training loss: 1.9846255779266357
Validation loss: 2.1557658026295323

Epoch: 6| Step: 7
Training loss: 1.8278613090515137
Validation loss: 2.1490360229246077

Epoch: 6| Step: 8
Training loss: 1.486715316772461
Validation loss: 2.1905461126758206

Epoch: 6| Step: 9
Training loss: 1.353054404258728
Validation loss: 2.06924432580189

Epoch: 6| Step: 10
Training loss: 1.8658041954040527
Validation loss: 2.1572042152445805

Epoch: 6| Step: 11
Training loss: 1.9557081460952759
Validation loss: 2.137156632638747

Epoch: 6| Step: 12
Training loss: 1.953611135482788
Validation loss: 2.1927880394843315

Epoch: 6| Step: 13
Training loss: 1.3845616579055786
Validation loss: 2.241763791730327

Epoch: 420| Step: 0
Training loss: 1.8376401662826538
Validation loss: 2.061224488801854

Epoch: 6| Step: 1
Training loss: 1.7711113691329956
Validation loss: 2.165850490652105

Epoch: 6| Step: 2
Training loss: 1.5714155435562134
Validation loss: 2.158923841291858

Epoch: 6| Step: 3
Training loss: 1.8899247646331787
Validation loss: 2.0843576462038103

Epoch: 6| Step: 4
Training loss: 1.3023042678833008
Validation loss: 2.1097011053433983

Epoch: 6| Step: 5
Training loss: 1.899198293685913
Validation loss: 2.097342707777536

Epoch: 6| Step: 6
Training loss: 1.4082657098770142
Validation loss: 2.125251611073812

Epoch: 6| Step: 7
Training loss: 1.8003077507019043
Validation loss: 2.199645580783967

Epoch: 6| Step: 8
Training loss: 1.2534672021865845
Validation loss: 2.079371411313293

Epoch: 6| Step: 9
Training loss: 1.3100254535675049
Validation loss: 2.1186344431292627

Epoch: 6| Step: 10
Training loss: 2.055694103240967
Validation loss: 2.079205011808744

Epoch: 6| Step: 11
Training loss: 2.7272517681121826
Validation loss: 2.141978609946466

Epoch: 6| Step: 12
Training loss: 1.722699761390686
Validation loss: 2.154627024486501

Epoch: 6| Step: 13
Training loss: 1.6771937608718872
Validation loss: 2.1812167167663574

Epoch: 421| Step: 0
Training loss: 1.8194477558135986
Validation loss: 2.1099973147915256

Epoch: 6| Step: 1
Training loss: 1.7975599765777588
Validation loss: 2.0477863024639826

Epoch: 6| Step: 2
Training loss: 1.7250384092330933
Validation loss: 2.122326188190009

Epoch: 6| Step: 3
Training loss: 1.2850773334503174
Validation loss: 2.1216533863416283

Epoch: 6| Step: 4
Training loss: 1.965166449546814
Validation loss: 2.1511857714704288

Epoch: 6| Step: 5
Training loss: 2.0310428142547607
Validation loss: 2.1517173936290126

Epoch: 6| Step: 6
Training loss: 1.5903226137161255
Validation loss: 2.0970988632530294

Epoch: 6| Step: 7
Training loss: 1.743706464767456
Validation loss: 2.143857584204725

Epoch: 6| Step: 8
Training loss: 1.3518500328063965
Validation loss: 2.1417238840492825

Epoch: 6| Step: 9
Training loss: 1.5199594497680664
Validation loss: 2.1428572311196277

Epoch: 6| Step: 10
Training loss: 2.2683265209198
Validation loss: 2.142334354821072

Epoch: 6| Step: 11
Training loss: 1.238158106803894
Validation loss: 2.1574023564656577

Epoch: 6| Step: 12
Training loss: 1.7289395332336426
Validation loss: 2.1292033990224204

Epoch: 6| Step: 13
Training loss: 2.678328514099121
Validation loss: 2.226560687506071

Epoch: 422| Step: 0
Training loss: 1.824965000152588
Validation loss: 2.13384816210757

Epoch: 6| Step: 1
Training loss: 1.482290267944336
Validation loss: 2.08376117162807

Epoch: 6| Step: 2
Training loss: 1.606781244277954
Validation loss: 2.146387061765117

Epoch: 6| Step: 3
Training loss: 1.520676851272583
Validation loss: 2.157281523109764

Epoch: 6| Step: 4
Training loss: 1.475655436515808
Validation loss: 2.1373443680424846

Epoch: 6| Step: 5
Training loss: 2.634969472885132
Validation loss: 2.1583952685838104

Epoch: 6| Step: 6
Training loss: 1.5621470212936401
Validation loss: 2.110433022181193

Epoch: 6| Step: 7
Training loss: 1.803996205329895
Validation loss: 2.118877908234955

Epoch: 6| Step: 8
Training loss: 2.81302809715271
Validation loss: 2.101786595518871

Epoch: 6| Step: 9
Training loss: 1.556169033050537
Validation loss: 2.1031023507477133

Epoch: 6| Step: 10
Training loss: 1.0660234689712524
Validation loss: 2.1385822475597425

Epoch: 6| Step: 11
Training loss: 2.303654670715332
Validation loss: 2.08749956469382

Epoch: 6| Step: 12
Training loss: 1.2089852094650269
Validation loss: 2.090068027537356

Epoch: 6| Step: 13
Training loss: 1.1995925903320312
Validation loss: 2.100188752656342

Epoch: 423| Step: 0
Training loss: 1.886432409286499
Validation loss: 2.118401268477081

Epoch: 6| Step: 1
Training loss: 1.429861307144165
Validation loss: 2.152570597587093

Epoch: 6| Step: 2
Training loss: 1.37057626247406
Validation loss: 2.0893570492344518

Epoch: 6| Step: 3
Training loss: 1.913274884223938
Validation loss: 2.178324337928526

Epoch: 6| Step: 4
Training loss: 1.6911273002624512
Validation loss: 2.1929891878558743

Epoch: 6| Step: 5
Training loss: 1.2915273904800415
Validation loss: 2.1079347043909054

Epoch: 6| Step: 6
Training loss: 1.7310864925384521
Validation loss: 2.114205793667865

Epoch: 6| Step: 7
Training loss: 1.6232209205627441
Validation loss: 2.141601526609031

Epoch: 6| Step: 8
Training loss: 1.6991028785705566
Validation loss: 2.091457461798063

Epoch: 6| Step: 9
Training loss: 1.7210471630096436
Validation loss: 2.149823045217863

Epoch: 6| Step: 10
Training loss: 1.7327709197998047
Validation loss: 2.1216664032269548

Epoch: 6| Step: 11
Training loss: 2.3262312412261963
Validation loss: 2.1634810945039153

Epoch: 6| Step: 12
Training loss: 1.8712656497955322
Validation loss: 2.114853907656926

Epoch: 6| Step: 13
Training loss: 2.2622246742248535
Validation loss: 2.1284514140057307

Epoch: 424| Step: 0
Training loss: 2.860116958618164
Validation loss: 2.132242243777039

Epoch: 6| Step: 1
Training loss: 1.494317650794983
Validation loss: 2.1052802249949467

Epoch: 6| Step: 2
Training loss: 1.333253264427185
Validation loss: 2.1457357509161836

Epoch: 6| Step: 3
Training loss: 2.294846534729004
Validation loss: 2.150448118486712

Epoch: 6| Step: 4
Training loss: 1.7863019704818726
Validation loss: 2.1549078854181434

Epoch: 6| Step: 5
Training loss: 1.459494709968567
Validation loss: 2.1816895802815757

Epoch: 6| Step: 6
Training loss: 1.782433032989502
Validation loss: 2.1671776592090564

Epoch: 6| Step: 7
Training loss: 1.8279376029968262
Validation loss: 2.186901100220219

Epoch: 6| Step: 8
Training loss: 1.2445253133773804
Validation loss: 2.120135812349217

Epoch: 6| Step: 9
Training loss: 1.5034881830215454
Validation loss: 2.189299311689151

Epoch: 6| Step: 10
Training loss: 2.2085022926330566
Validation loss: 2.1617051734719226

Epoch: 6| Step: 11
Training loss: 1.4519150257110596
Validation loss: 2.109018192496351

Epoch: 6| Step: 12
Training loss: 1.4482592344284058
Validation loss: 2.036073515492101

Epoch: 6| Step: 13
Training loss: 1.44199538230896
Validation loss: 2.0935652576467043

Epoch: 425| Step: 0
Training loss: 2.1477251052856445
Validation loss: 2.1278002133933445

Epoch: 6| Step: 1
Training loss: 1.5914021730422974
Validation loss: 2.146120454675408

Epoch: 6| Step: 2
Training loss: 1.7755982875823975
Validation loss: 2.085525320422265

Epoch: 6| Step: 3
Training loss: 1.8047605752944946
Validation loss: 2.097236269263811

Epoch: 6| Step: 4
Training loss: 1.6092709302902222
Validation loss: 2.1427487096478863

Epoch: 6| Step: 5
Training loss: 1.0863902568817139
Validation loss: 2.149780237546531

Epoch: 6| Step: 6
Training loss: 1.9434435367584229
Validation loss: 2.13195865384994

Epoch: 6| Step: 7
Training loss: 1.7287397384643555
Validation loss: 2.1016809658337663

Epoch: 6| Step: 8
Training loss: 1.9349170923233032
Validation loss: 2.1027346836623324

Epoch: 6| Step: 9
Training loss: 1.8300063610076904
Validation loss: 2.156062920888265

Epoch: 6| Step: 10
Training loss: 1.4646718502044678
Validation loss: 2.1657088828343216

Epoch: 6| Step: 11
Training loss: 1.8650598526000977
Validation loss: 2.1812000941204768

Epoch: 6| Step: 12
Training loss: 1.3494677543640137
Validation loss: 2.117070277531942

Epoch: 6| Step: 13
Training loss: 2.1983697414398193
Validation loss: 2.1067514393919256

Epoch: 426| Step: 0
Training loss: 2.6372275352478027
Validation loss: 2.159562905629476

Epoch: 6| Step: 1
Training loss: 1.7747724056243896
Validation loss: 2.1798799102024367

Epoch: 6| Step: 2
Training loss: 1.8582062721252441
Validation loss: 2.0971054236094155

Epoch: 6| Step: 3
Training loss: 0.9577321410179138
Validation loss: 2.1135039278255996

Epoch: 6| Step: 4
Training loss: 1.5214974880218506
Validation loss: 2.1649734845725437

Epoch: 6| Step: 5
Training loss: 1.441641092300415
Validation loss: 2.1502132851590394

Epoch: 6| Step: 6
Training loss: 1.6635034084320068
Validation loss: 2.160512549902803

Epoch: 6| Step: 7
Training loss: 1.3830293416976929
Validation loss: 2.1941803142588627

Epoch: 6| Step: 8
Training loss: 1.9482262134552002
Validation loss: 2.1754095913261495

Epoch: 6| Step: 9
Training loss: 2.2016263008117676
Validation loss: 2.157276920093003

Epoch: 6| Step: 10
Training loss: 2.013186454772949
Validation loss: 2.164313772673248

Epoch: 6| Step: 11
Training loss: 1.1626876592636108
Validation loss: 2.123276597710066

Epoch: 6| Step: 12
Training loss: 1.9449219703674316
Validation loss: 2.1841200705497497

Epoch: 6| Step: 13
Training loss: 1.1978882551193237
Validation loss: 2.1210558952823764

Epoch: 427| Step: 0
Training loss: 2.0229153633117676
Validation loss: 2.1678457580586916

Epoch: 6| Step: 1
Training loss: 1.8812429904937744
Validation loss: 2.1449221795605076

Epoch: 6| Step: 2
Training loss: 2.056734323501587
Validation loss: 2.1665718273449968

Epoch: 6| Step: 3
Training loss: 1.3638627529144287
Validation loss: 2.1568710752712783

Epoch: 6| Step: 4
Training loss: 1.512912631034851
Validation loss: 2.1864673963157077

Epoch: 6| Step: 5
Training loss: 1.506065011024475
Validation loss: 2.1642132907785396

Epoch: 6| Step: 6
Training loss: 1.543363332748413
Validation loss: 2.151270317774947

Epoch: 6| Step: 7
Training loss: 1.6994911432266235
Validation loss: 2.1065142449512275

Epoch: 6| Step: 8
Training loss: 1.3129087686538696
Validation loss: 2.108247172447943

Epoch: 6| Step: 9
Training loss: 1.4666168689727783
Validation loss: 2.147272689368135

Epoch: 6| Step: 10
Training loss: 2.0745630264282227
Validation loss: 2.09601076187626

Epoch: 6| Step: 11
Training loss: 2.1941661834716797
Validation loss: 2.1395138720030427

Epoch: 6| Step: 12
Training loss: 1.4149177074432373
Validation loss: 2.2013614357158704

Epoch: 6| Step: 13
Training loss: 1.386730670928955
Validation loss: 2.143283353056959

Epoch: 428| Step: 0
Training loss: 1.8651801347732544
Validation loss: 2.0876812473420174

Epoch: 6| Step: 1
Training loss: 1.2218819856643677
Validation loss: 2.192159216891053

Epoch: 6| Step: 2
Training loss: 2.1090052127838135
Validation loss: 2.1104219011081162

Epoch: 6| Step: 3
Training loss: 2.0116043090820312
Validation loss: 2.0882360371210242

Epoch: 6| Step: 4
Training loss: 1.9416799545288086
Validation loss: 2.1409598563307073

Epoch: 6| Step: 5
Training loss: 1.861324667930603
Validation loss: 2.180608244352443

Epoch: 6| Step: 6
Training loss: 1.460113286972046
Validation loss: 2.1867683907990814

Epoch: 6| Step: 7
Training loss: 1.3016397953033447
Validation loss: 2.119158378211401

Epoch: 6| Step: 8
Training loss: 1.7581474781036377
Validation loss: 2.192474580580188

Epoch: 6| Step: 9
Training loss: 1.5676205158233643
Validation loss: 2.1786005368796726

Epoch: 6| Step: 10
Training loss: 1.458343267440796
Validation loss: 2.094371498271983

Epoch: 6| Step: 11
Training loss: 1.713170051574707
Validation loss: 2.1324611325417795

Epoch: 6| Step: 12
Training loss: 1.8211162090301514
Validation loss: 2.1181492036388767

Epoch: 6| Step: 13
Training loss: 2.4622087478637695
Validation loss: 2.146716789532733

Epoch: 429| Step: 0
Training loss: 0.8779648542404175
Validation loss: 2.0822927233993367

Epoch: 6| Step: 1
Training loss: 1.9805939197540283
Validation loss: 2.1520319472077074

Epoch: 6| Step: 2
Training loss: 1.7985239028930664
Validation loss: 2.180444919934837

Epoch: 6| Step: 3
Training loss: 2.464578628540039
Validation loss: 2.1225581912584204

Epoch: 6| Step: 4
Training loss: 1.4137945175170898
Validation loss: 2.0558819796449397

Epoch: 6| Step: 5
Training loss: 1.7407610416412354
Validation loss: 2.1223828766935613

Epoch: 6| Step: 6
Training loss: 1.9788663387298584
Validation loss: 2.0735060450851277

Epoch: 6| Step: 7
Training loss: 2.0380678176879883
Validation loss: 2.047942720433717

Epoch: 6| Step: 8
Training loss: 1.3201444149017334
Validation loss: 2.0940516969209075

Epoch: 6| Step: 9
Training loss: 1.4181630611419678
Validation loss: 2.1056571493866625

Epoch: 6| Step: 10
Training loss: 2.101417064666748
Validation loss: 2.0922635024593723

Epoch: 6| Step: 11
Training loss: 2.0123562812805176
Validation loss: 2.0815665337347213

Epoch: 6| Step: 12
Training loss: 1.9393339157104492
Validation loss: 2.071753763383435

Epoch: 6| Step: 13
Training loss: 1.8196277618408203
Validation loss: 2.095971599701912

Epoch: 430| Step: 0
Training loss: 2.312453508377075
Validation loss: 2.116463707339379

Epoch: 6| Step: 1
Training loss: 1.1713786125183105
Validation loss: 2.1033236544619323

Epoch: 6| Step: 2
Training loss: 1.7600996494293213
Validation loss: 2.1063922271933606

Epoch: 6| Step: 3
Training loss: 1.8107905387878418
Validation loss: 2.1345534350282405

Epoch: 6| Step: 4
Training loss: 1.3116258382797241
Validation loss: 2.2048137111048542

Epoch: 6| Step: 5
Training loss: 2.0172767639160156
Validation loss: 2.077565076530621

Epoch: 6| Step: 6
Training loss: 1.9360849857330322
Validation loss: 2.0891317270135366

Epoch: 6| Step: 7
Training loss: 1.3597172498703003
Validation loss: 2.1533333281035065

Epoch: 6| Step: 8
Training loss: 1.1964507102966309
Validation loss: 2.1661522939640987

Epoch: 6| Step: 9
Training loss: 1.9299039840698242
Validation loss: 2.1088285292348554

Epoch: 6| Step: 10
Training loss: 2.7988173961639404
Validation loss: 2.1557176049037645

Epoch: 6| Step: 11
Training loss: 2.080601453781128
Validation loss: 2.0796729185247935

Epoch: 6| Step: 12
Training loss: 1.5197803974151611
Validation loss: 2.153706242961268

Epoch: 6| Step: 13
Training loss: 1.2015137672424316
Validation loss: 2.091422742412936

Epoch: 431| Step: 0
Training loss: 1.757537603378296
Validation loss: 2.1002993211951306

Epoch: 6| Step: 1
Training loss: 0.9622601270675659
Validation loss: 2.0813192475226616

Epoch: 6| Step: 2
Training loss: 1.7885105609893799
Validation loss: 2.069254054818102

Epoch: 6| Step: 3
Training loss: 1.656569004058838
Validation loss: 2.078711437922652

Epoch: 6| Step: 4
Training loss: 1.8176714181900024
Validation loss: 2.1247714334918606

Epoch: 6| Step: 5
Training loss: 2.0455431938171387
Validation loss: 2.091636134732154

Epoch: 6| Step: 6
Training loss: 1.3626797199249268
Validation loss: 2.190095365688365

Epoch: 6| Step: 7
Training loss: 2.2015323638916016
Validation loss: 2.0857531216836747

Epoch: 6| Step: 8
Training loss: 1.4934102296829224
Validation loss: 2.1582337938329226

Epoch: 6| Step: 9
Training loss: 2.151704788208008
Validation loss: 2.1326571664502545

Epoch: 6| Step: 10
Training loss: 2.161830186843872
Validation loss: 2.164012162916122

Epoch: 6| Step: 11
Training loss: 1.457387924194336
Validation loss: 2.0895979301903838

Epoch: 6| Step: 12
Training loss: 1.383430004119873
Validation loss: 2.132941246032715

Epoch: 6| Step: 13
Training loss: 1.6644240617752075
Validation loss: 2.12232990418711

Epoch: 432| Step: 0
Training loss: 2.6863601207733154
Validation loss: 2.1400980103400444

Epoch: 6| Step: 1
Training loss: 2.1079087257385254
Validation loss: 2.1105919256005237

Epoch: 6| Step: 2
Training loss: 1.3297593593597412
Validation loss: 2.2257669484743507

Epoch: 6| Step: 3
Training loss: 2.120570182800293
Validation loss: 2.1135349786409767

Epoch: 6| Step: 4
Training loss: 1.4937561750411987
Validation loss: 2.1111556842762935

Epoch: 6| Step: 5
Training loss: 1.5806169509887695
Validation loss: 2.0892384462459113

Epoch: 6| Step: 6
Training loss: 1.845711350440979
Validation loss: 2.12772249919112

Epoch: 6| Step: 7
Training loss: 1.1058017015457153
Validation loss: 2.108904687307214

Epoch: 6| Step: 8
Training loss: 1.1930618286132812
Validation loss: 2.1474215958708074

Epoch: 6| Step: 9
Training loss: 1.5811187028884888
Validation loss: 2.0778779047791676

Epoch: 6| Step: 10
Training loss: 2.4099230766296387
Validation loss: 2.1068835463575137

Epoch: 6| Step: 11
Training loss: 1.3394908905029297
Validation loss: 2.0716863588620256

Epoch: 6| Step: 12
Training loss: 1.7830498218536377
Validation loss: 2.127643797987251

Epoch: 6| Step: 13
Training loss: 1.2762476205825806
Validation loss: 2.0848338757791827

Epoch: 433| Step: 0
Training loss: 1.8346649408340454
Validation loss: 2.181874220089246

Epoch: 6| Step: 1
Training loss: 1.836836576461792
Validation loss: 2.128594116498065

Epoch: 6| Step: 2
Training loss: 2.7559075355529785
Validation loss: 2.128378701466386

Epoch: 6| Step: 3
Training loss: 1.3329240083694458
Validation loss: 2.028693574731068

Epoch: 6| Step: 4
Training loss: 1.444338083267212
Validation loss: 2.0844731177053144

Epoch: 6| Step: 5
Training loss: 1.8307554721832275
Validation loss: 2.124845927761447

Epoch: 6| Step: 6
Training loss: 1.7236266136169434
Validation loss: 2.079432092687135

Epoch: 6| Step: 7
Training loss: 2.0027379989624023
Validation loss: 2.0991888610265588

Epoch: 6| Step: 8
Training loss: 1.8907265663146973
Validation loss: 2.143293349973617

Epoch: 6| Step: 9
Training loss: 1.3927147388458252
Validation loss: 2.1322057606071554

Epoch: 6| Step: 10
Training loss: 1.5440517663955688
Validation loss: 2.1124730315259708

Epoch: 6| Step: 11
Training loss: 1.3820476531982422
Validation loss: 2.1216920755242787

Epoch: 6| Step: 12
Training loss: 1.774444580078125
Validation loss: 2.136573509503436

Epoch: 6| Step: 13
Training loss: 1.3418015241622925
Validation loss: 2.149272431609451

Epoch: 434| Step: 0
Training loss: 2.1823174953460693
Validation loss: 2.1031927216437554

Epoch: 6| Step: 1
Training loss: 1.696306824684143
Validation loss: 2.125764368682779

Epoch: 6| Step: 2
Training loss: 1.5589494705200195
Validation loss: 2.1808440992909093

Epoch: 6| Step: 3
Training loss: 1.491199016571045
Validation loss: 2.1304729471924486

Epoch: 6| Step: 4
Training loss: 1.60245943069458
Validation loss: 2.2070767930758897

Epoch: 6| Step: 5
Training loss: 1.4040789604187012
Validation loss: 2.1576476917471936

Epoch: 6| Step: 6
Training loss: 2.4662396907806396
Validation loss: 2.1606595926387335

Epoch: 6| Step: 7
Training loss: 1.621888279914856
Validation loss: 2.1714713906729095

Epoch: 6| Step: 8
Training loss: 2.089449882507324
Validation loss: 2.13639630681725

Epoch: 6| Step: 9
Training loss: 1.0798598527908325
Validation loss: 2.094592058530418

Epoch: 6| Step: 10
Training loss: 1.585953712463379
Validation loss: 2.1358439999241985

Epoch: 6| Step: 11
Training loss: 2.0728893280029297
Validation loss: 2.16638933971364

Epoch: 6| Step: 12
Training loss: 2.0729243755340576
Validation loss: 2.1774121330630396

Epoch: 6| Step: 13
Training loss: 1.6565972566604614
Validation loss: 2.1378770887210803

Epoch: 435| Step: 0
Training loss: 1.4670747518539429
Validation loss: 2.1310767986441173

Epoch: 6| Step: 1
Training loss: 1.838240146636963
Validation loss: 2.147775334696616

Epoch: 6| Step: 2
Training loss: 1.4853307008743286
Validation loss: 2.064273267663935

Epoch: 6| Step: 3
Training loss: 2.0511646270751953
Validation loss: 2.1970517148253736

Epoch: 6| Step: 4
Training loss: 1.5699598789215088
Validation loss: 2.129660839675575

Epoch: 6| Step: 5
Training loss: 1.2354803085327148
Validation loss: 2.0728804885700183

Epoch: 6| Step: 6
Training loss: 2.168795347213745
Validation loss: 2.1504255007672053

Epoch: 6| Step: 7
Training loss: 1.7205390930175781
Validation loss: 2.096977235168539

Epoch: 6| Step: 8
Training loss: 2.3266148567199707
Validation loss: 2.1554593655370895

Epoch: 6| Step: 9
Training loss: 1.2688125371932983
Validation loss: 2.2110385510229293

Epoch: 6| Step: 10
Training loss: 1.2797220945358276
Validation loss: 2.0922923472619828

Epoch: 6| Step: 11
Training loss: 2.4592092037200928
Validation loss: 2.1276449836710447

Epoch: 6| Step: 12
Training loss: 1.5996413230895996
Validation loss: 2.2153905155838176

Epoch: 6| Step: 13
Training loss: 1.4973477125167847
Validation loss: 2.1187470241259505

Epoch: 436| Step: 0
Training loss: 1.7543296813964844
Validation loss: 2.1040285428365073

Epoch: 6| Step: 1
Training loss: 1.7111060619354248
Validation loss: 2.1517452680936424

Epoch: 6| Step: 2
Training loss: 2.020404577255249
Validation loss: 2.098702061560846

Epoch: 6| Step: 3
Training loss: 1.921215534210205
Validation loss: 2.1521410711349978

Epoch: 6| Step: 4
Training loss: 2.147867202758789
Validation loss: 2.1077298131040347

Epoch: 6| Step: 5
Training loss: 1.4735071659088135
Validation loss: 2.1193918720368417

Epoch: 6| Step: 6
Training loss: 1.1476263999938965
Validation loss: 2.1346529440213273

Epoch: 6| Step: 7
Training loss: 1.816200613975525
Validation loss: 2.1873487516116072

Epoch: 6| Step: 8
Training loss: 2.198853015899658
Validation loss: 2.1184990726491457

Epoch: 6| Step: 9
Training loss: 1.5300559997558594
Validation loss: 2.1703520487713557

Epoch: 6| Step: 10
Training loss: 1.8978627920150757
Validation loss: 2.129382910266999

Epoch: 6| Step: 11
Training loss: 1.4863964319229126
Validation loss: 2.100581213992129

Epoch: 6| Step: 12
Training loss: 1.4880883693695068
Validation loss: 2.1322048402601674

Epoch: 6| Step: 13
Training loss: 1.8191626071929932
Validation loss: 2.1135642272169872

Epoch: 437| Step: 0
Training loss: 1.9168920516967773
Validation loss: 2.12756976901844

Epoch: 6| Step: 1
Training loss: 2.010172128677368
Validation loss: 2.1073712046428392

Epoch: 6| Step: 2
Training loss: 2.0099191665649414
Validation loss: 2.2027232595669326

Epoch: 6| Step: 3
Training loss: 1.7540040016174316
Validation loss: 2.135465721930227

Epoch: 6| Step: 4
Training loss: 0.9261558055877686
Validation loss: 2.0625157920263146

Epoch: 6| Step: 5
Training loss: 2.488614559173584
Validation loss: 2.1244476149159093

Epoch: 6| Step: 6
Training loss: 2.255239963531494
Validation loss: 2.1150268816178843

Epoch: 6| Step: 7
Training loss: 1.9401240348815918
Validation loss: 2.1682312052737

Epoch: 6| Step: 8
Training loss: 1.441896915435791
Validation loss: 2.1938695997320194

Epoch: 6| Step: 9
Training loss: 1.189113736152649
Validation loss: 2.1283310036505423

Epoch: 6| Step: 10
Training loss: 1.773162841796875
Validation loss: 2.0486980484377955

Epoch: 6| Step: 11
Training loss: 1.0277811288833618
Validation loss: 2.1182058408696163

Epoch: 6| Step: 12
Training loss: 1.6890028715133667
Validation loss: 2.123310787703401

Epoch: 6| Step: 13
Training loss: 1.5408058166503906
Validation loss: 2.1278270316380326

Epoch: 438| Step: 0
Training loss: 1.9087128639221191
Validation loss: 2.13913240227648

Epoch: 6| Step: 1
Training loss: 1.7865996360778809
Validation loss: 2.1322431410512617

Epoch: 6| Step: 2
Training loss: 2.016035795211792
Validation loss: 2.2295712783772457

Epoch: 6| Step: 3
Training loss: 2.2990221977233887
Validation loss: 2.155394317001425

Epoch: 6| Step: 4
Training loss: 1.9985871315002441
Validation loss: 2.1907108214593705

Epoch: 6| Step: 5
Training loss: 1.5199692249298096
Validation loss: 2.1714136805585635

Epoch: 6| Step: 6
Training loss: 1.8363046646118164
Validation loss: 2.1300032138824463

Epoch: 6| Step: 7
Training loss: 2.2027225494384766
Validation loss: 2.1554026052515995

Epoch: 6| Step: 8
Training loss: 1.369936466217041
Validation loss: 2.150086264456472

Epoch: 6| Step: 9
Training loss: 1.7794040441513062
Validation loss: 2.1330148097007506

Epoch: 6| Step: 10
Training loss: 0.7046273946762085
Validation loss: 2.1041610574209564

Epoch: 6| Step: 11
Training loss: 1.8848941326141357
Validation loss: 2.0865176070121025

Epoch: 6| Step: 12
Training loss: 1.8857779502868652
Validation loss: 2.0620101613383137

Epoch: 6| Step: 13
Training loss: 0.7079346179962158
Validation loss: 2.1292204113416773

Epoch: 439| Step: 0
Training loss: 1.2199667692184448
Validation loss: 2.1440803671395905

Epoch: 6| Step: 1
Training loss: 1.8302302360534668
Validation loss: 2.110190046730862

Epoch: 6| Step: 2
Training loss: 0.7845262289047241
Validation loss: 2.1022699879061792

Epoch: 6| Step: 3
Training loss: 2.49672794342041
Validation loss: 2.125133906641314

Epoch: 6| Step: 4
Training loss: 2.2059242725372314
Validation loss: 2.1137810150782266

Epoch: 6| Step: 5
Training loss: 2.00466251373291
Validation loss: 2.0977813569448327

Epoch: 6| Step: 6
Training loss: 2.270501136779785
Validation loss: 2.1033933060143584

Epoch: 6| Step: 7
Training loss: 0.937775731086731
Validation loss: 2.1099965841539445

Epoch: 6| Step: 8
Training loss: 1.2304835319519043
Validation loss: 2.15209602027811

Epoch: 6| Step: 9
Training loss: 2.0106911659240723
Validation loss: 2.1466638067717194

Epoch: 6| Step: 10
Training loss: 1.8313798904418945
Validation loss: 2.1881056344637306

Epoch: 6| Step: 11
Training loss: 1.6034011840820312
Validation loss: 2.116192038341235

Epoch: 6| Step: 12
Training loss: 1.6901602745056152
Validation loss: 2.1839617939405542

Epoch: 6| Step: 13
Training loss: 2.064727306365967
Validation loss: 2.1274448261466077

Epoch: 440| Step: 0
Training loss: 2.2633228302001953
Validation loss: 2.186976666091591

Epoch: 6| Step: 1
Training loss: 2.511702060699463
Validation loss: 2.2074466982195453

Epoch: 6| Step: 2
Training loss: 1.543485164642334
Validation loss: 2.131900538680374

Epoch: 6| Step: 3
Training loss: 1.507685899734497
Validation loss: 2.2217587988863707

Epoch: 6| Step: 4
Training loss: 1.5662868022918701
Validation loss: 2.147676714005009

Epoch: 6| Step: 5
Training loss: 1.4759413003921509
Validation loss: 2.0608011343145884

Epoch: 6| Step: 6
Training loss: 1.2860991954803467
Validation loss: 2.1007987350545902

Epoch: 6| Step: 7
Training loss: 1.3565939664840698
Validation loss: 2.1281204659451722

Epoch: 6| Step: 8
Training loss: 2.0389585494995117
Validation loss: 2.115939901721093

Epoch: 6| Step: 9
Training loss: 1.6068787574768066
Validation loss: 2.1753903563304613

Epoch: 6| Step: 10
Training loss: 1.93841552734375
Validation loss: 2.182158350944519

Epoch: 6| Step: 11
Training loss: 1.7135862112045288
Validation loss: 2.130371839769425

Epoch: 6| Step: 12
Training loss: 1.7719318866729736
Validation loss: 2.108564579358665

Epoch: 6| Step: 13
Training loss: 1.527951955795288
Validation loss: 2.1452344438081146

Epoch: 441| Step: 0
Training loss: 1.4550690650939941
Validation loss: 2.087389060246047

Epoch: 6| Step: 1
Training loss: 1.5304920673370361
Validation loss: 2.0961376954150457

Epoch: 6| Step: 2
Training loss: 2.162484884262085
Validation loss: 2.0897031881475963

Epoch: 6| Step: 3
Training loss: 1.682741403579712
Validation loss: 2.0900194029654227

Epoch: 6| Step: 4
Training loss: 1.5709689855575562
Validation loss: 2.0592997304854856

Epoch: 6| Step: 5
Training loss: 1.6020920276641846
Validation loss: 2.1293823911297705

Epoch: 6| Step: 6
Training loss: 1.6657074689865112
Validation loss: 2.2019938679151636

Epoch: 6| Step: 7
Training loss: 2.061687469482422
Validation loss: 2.115942385888869

Epoch: 6| Step: 8
Training loss: 1.8519318103790283
Validation loss: 2.117948057830975

Epoch: 6| Step: 9
Training loss: 1.9806318283081055
Validation loss: 2.117785858851607

Epoch: 6| Step: 10
Training loss: 1.8029109239578247
Validation loss: 2.1315376656029814

Epoch: 6| Step: 11
Training loss: 2.221346139907837
Validation loss: 2.0654826817973966

Epoch: 6| Step: 12
Training loss: 1.284446358680725
Validation loss: 2.2033837661948255

Epoch: 6| Step: 13
Training loss: 1.2289700508117676
Validation loss: 2.16316625636111

Epoch: 442| Step: 0
Training loss: 1.6648433208465576
Validation loss: 2.179675499598185

Epoch: 6| Step: 1
Training loss: 1.686389684677124
Validation loss: 2.0998246772314912

Epoch: 6| Step: 2
Training loss: 1.7487791776657104
Validation loss: 2.1221719762330413

Epoch: 6| Step: 3
Training loss: 1.28910231590271
Validation loss: 2.1755270047854354

Epoch: 6| Step: 4
Training loss: 1.7168397903442383
Validation loss: 2.042202639323409

Epoch: 6| Step: 5
Training loss: 1.4129000902175903
Validation loss: 2.134100875546855

Epoch: 6| Step: 6
Training loss: 1.8735644817352295
Validation loss: 2.109250130191926

Epoch: 6| Step: 7
Training loss: 1.693356990814209
Validation loss: 2.1011363331989577

Epoch: 6| Step: 8
Training loss: 1.5480234622955322
Validation loss: 2.052351733689667

Epoch: 6| Step: 9
Training loss: 1.5192406177520752
Validation loss: 2.112581532488587

Epoch: 6| Step: 10
Training loss: 1.830337643623352
Validation loss: 2.1579860666746735

Epoch: 6| Step: 11
Training loss: 2.073028802871704
Validation loss: 2.1494494740680983

Epoch: 6| Step: 12
Training loss: 1.9369648694992065
Validation loss: 2.04540087843454

Epoch: 6| Step: 13
Training loss: 1.9664530754089355
Validation loss: 2.206543658369331

Epoch: 443| Step: 0
Training loss: 1.36212956905365
Validation loss: 2.1633522946347474

Epoch: 6| Step: 1
Training loss: 1.8839912414550781
Validation loss: 2.153172936490787

Epoch: 6| Step: 2
Training loss: 2.372159719467163
Validation loss: 2.1528545964148735

Epoch: 6| Step: 3
Training loss: 2.3544440269470215
Validation loss: 2.124672310326689

Epoch: 6| Step: 4
Training loss: 1.5624173879623413
Validation loss: 2.1134204274864605

Epoch: 6| Step: 5
Training loss: 1.2071583271026611
Validation loss: 2.1419229763810352

Epoch: 6| Step: 6
Training loss: 1.7020466327667236
Validation loss: 2.1243193277748684

Epoch: 6| Step: 7
Training loss: 0.8901026248931885
Validation loss: 2.0965444400746334

Epoch: 6| Step: 8
Training loss: 1.8343510627746582
Validation loss: 2.1713372558675785

Epoch: 6| Step: 9
Training loss: 1.3180065155029297
Validation loss: 2.116992263383763

Epoch: 6| Step: 10
Training loss: 2.2286312580108643
Validation loss: 2.0875872142853273

Epoch: 6| Step: 11
Training loss: 1.8198641538619995
Validation loss: 2.0873165361342894

Epoch: 6| Step: 12
Training loss: 2.0176167488098145
Validation loss: 2.16514487676723

Epoch: 6| Step: 13
Training loss: 1.5520881414413452
Validation loss: 2.170959570074594

Epoch: 444| Step: 0
Training loss: 1.7291314601898193
Validation loss: 2.1431747328850532

Epoch: 6| Step: 1
Training loss: 1.5278927087783813
Validation loss: 2.1675845294870357

Epoch: 6| Step: 2
Training loss: 1.6604526042938232
Validation loss: 2.115825870985626

Epoch: 6| Step: 3
Training loss: 2.153444528579712
Validation loss: 2.1522706298417944

Epoch: 6| Step: 4
Training loss: 1.7627233266830444
Validation loss: 2.1390800501710627

Epoch: 6| Step: 5
Training loss: 1.6830697059631348
Validation loss: 2.110839961677469

Epoch: 6| Step: 6
Training loss: 1.2097322940826416
Validation loss: 2.1083336286647345

Epoch: 6| Step: 7
Training loss: 2.036824941635132
Validation loss: 2.1739406713875393

Epoch: 6| Step: 8
Training loss: 1.8198819160461426
Validation loss: 2.155737428254979

Epoch: 6| Step: 9
Training loss: 1.963366150856018
Validation loss: 2.092896769123693

Epoch: 6| Step: 10
Training loss: 1.043529748916626
Validation loss: 2.1717405883214806

Epoch: 6| Step: 11
Training loss: 1.5081638097763062
Validation loss: 2.1563854960985083

Epoch: 6| Step: 12
Training loss: 1.633406639099121
Validation loss: 2.1253132089491813

Epoch: 6| Step: 13
Training loss: 1.7937322854995728
Validation loss: 2.1716046999859553

Epoch: 445| Step: 0
Training loss: 2.2545275688171387
Validation loss: 2.0888603553977063

Epoch: 6| Step: 1
Training loss: 1.7327251434326172
Validation loss: 2.0551150550124464

Epoch: 6| Step: 2
Training loss: 0.6215230226516724
Validation loss: 2.104315168114119

Epoch: 6| Step: 3
Training loss: 1.4213182926177979
Validation loss: 2.0975226484319216

Epoch: 6| Step: 4
Training loss: 1.6400588750839233
Validation loss: 2.1206713389324885

Epoch: 6| Step: 5
Training loss: 1.586419701576233
Validation loss: 2.173561134646016

Epoch: 6| Step: 6
Training loss: 1.984677791595459
Validation loss: 2.0948732693990073

Epoch: 6| Step: 7
Training loss: 2.0371341705322266
Validation loss: 2.1480959397490307

Epoch: 6| Step: 8
Training loss: 1.474792718887329
Validation loss: 2.173369587108653

Epoch: 6| Step: 9
Training loss: 1.8057414293289185
Validation loss: 2.1766739224874847

Epoch: 6| Step: 10
Training loss: 1.824089527130127
Validation loss: 2.1332738886597338

Epoch: 6| Step: 11
Training loss: 2.429324150085449
Validation loss: 2.181474449814007

Epoch: 6| Step: 12
Training loss: 2.0920753479003906
Validation loss: 2.1825112181325115

Epoch: 6| Step: 13
Training loss: 1.271834373474121
Validation loss: 2.116548152380092

Epoch: 446| Step: 0
Training loss: 2.0210981369018555
Validation loss: 2.1928113147776616

Epoch: 6| Step: 1
Training loss: 2.482976198196411
Validation loss: 2.12469542923794

Epoch: 6| Step: 2
Training loss: 1.4003751277923584
Validation loss: 2.1531881619525213

Epoch: 6| Step: 3
Training loss: 1.2714251279830933
Validation loss: 2.1314400831858316

Epoch: 6| Step: 4
Training loss: 1.2927381992340088
Validation loss: 2.1910507602076374

Epoch: 6| Step: 5
Training loss: 1.1322050094604492
Validation loss: 2.095967750395498

Epoch: 6| Step: 6
Training loss: 2.6030466556549072
Validation loss: 2.139739562106389

Epoch: 6| Step: 7
Training loss: 2.1346700191497803
Validation loss: 2.084241977301977

Epoch: 6| Step: 8
Training loss: 1.341491937637329
Validation loss: 2.0922553911004016

Epoch: 6| Step: 9
Training loss: 1.3162763118743896
Validation loss: 2.1459672553564912

Epoch: 6| Step: 10
Training loss: 1.6899083852767944
Validation loss: 2.146535918276797

Epoch: 6| Step: 11
Training loss: 1.6356258392333984
Validation loss: 2.127164531779546

Epoch: 6| Step: 12
Training loss: 2.0512852668762207
Validation loss: 2.1244478558981292

Epoch: 6| Step: 13
Training loss: 1.5634478330612183
Validation loss: 2.1980755636768956

Epoch: 447| Step: 0
Training loss: 1.3690742254257202
Validation loss: 2.1518065775594404

Epoch: 6| Step: 1
Training loss: 1.874992847442627
Validation loss: 2.1900194588527886

Epoch: 6| Step: 2
Training loss: 1.407965898513794
Validation loss: 2.1699735374860865

Epoch: 6| Step: 3
Training loss: 1.7590456008911133
Validation loss: 2.177262944559897

Epoch: 6| Step: 4
Training loss: 1.8682770729064941
Validation loss: 2.1480619574105866

Epoch: 6| Step: 5
Training loss: 1.6670730113983154
Validation loss: 2.1741702736064954

Epoch: 6| Step: 6
Training loss: 1.367337703704834
Validation loss: 2.1512363854274956

Epoch: 6| Step: 7
Training loss: 1.820631980895996
Validation loss: 2.16340531200491

Epoch: 6| Step: 8
Training loss: 1.5618876218795776
Validation loss: 2.1281521871525753

Epoch: 6| Step: 9
Training loss: 1.4948915243148804
Validation loss: 2.1384159621372016

Epoch: 6| Step: 10
Training loss: 1.6744458675384521
Validation loss: 2.149298455125542

Epoch: 6| Step: 11
Training loss: 2.2596306800842285
Validation loss: 2.1637378174771547

Epoch: 6| Step: 12
Training loss: 1.6700247526168823
Validation loss: 2.112281730098109

Epoch: 6| Step: 13
Training loss: 1.0285508632659912
Validation loss: 2.062767590245893

Epoch: 448| Step: 0
Training loss: 1.8005938529968262
Validation loss: 2.1523198466147146

Epoch: 6| Step: 1
Training loss: 1.9391264915466309
Validation loss: 2.0723588338462253

Epoch: 6| Step: 2
Training loss: 1.7625963687896729
Validation loss: 2.023670611842986

Epoch: 6| Step: 3
Training loss: 1.467408537864685
Validation loss: 2.0167451955938853

Epoch: 6| Step: 4
Training loss: 1.2721920013427734
Validation loss: 2.096094218633508

Epoch: 6| Step: 5
Training loss: 1.7745623588562012
Validation loss: 2.1095397485199796

Epoch: 6| Step: 6
Training loss: 1.8524537086486816
Validation loss: 2.106600051285118

Epoch: 6| Step: 7
Training loss: 2.414787769317627
Validation loss: 2.197634907178981

Epoch: 6| Step: 8
Training loss: 1.7757418155670166
Validation loss: 2.11114050111463

Epoch: 6| Step: 9
Training loss: 1.7065144777297974
Validation loss: 2.062716971161545

Epoch: 6| Step: 10
Training loss: 1.5790492296218872
Validation loss: 2.124952385502477

Epoch: 6| Step: 11
Training loss: 1.103868842124939
Validation loss: 2.0985157361594577

Epoch: 6| Step: 12
Training loss: 2.063554525375366
Validation loss: 2.1077831124746673

Epoch: 6| Step: 13
Training loss: 1.559658408164978
Validation loss: 2.1565531120505383

Epoch: 449| Step: 0
Training loss: 1.6780637502670288
Validation loss: 2.1239964962005615

Epoch: 6| Step: 1
Training loss: 1.9180006980895996
Validation loss: 2.074539548607283

Epoch: 6| Step: 2
Training loss: 1.8225018978118896
Validation loss: 2.1435779422842045

Epoch: 6| Step: 3
Training loss: 1.2421793937683105
Validation loss: 2.1040878295898438

Epoch: 6| Step: 4
Training loss: 1.9823808670043945
Validation loss: 2.0930161617135488

Epoch: 6| Step: 5
Training loss: 1.8918274641036987
Validation loss: 2.131793286210747

Epoch: 6| Step: 6
Training loss: 1.8032639026641846
Validation loss: 2.1255466438108876

Epoch: 6| Step: 7
Training loss: 1.690740942955017
Validation loss: 2.130677966661351

Epoch: 6| Step: 8
Training loss: 1.370117425918579
Validation loss: 2.1071250207962526

Epoch: 6| Step: 9
Training loss: 1.1804542541503906
Validation loss: 2.094364761024393

Epoch: 6| Step: 10
Training loss: 1.4961856603622437
Validation loss: 2.1509885852054884

Epoch: 6| Step: 11
Training loss: 1.319319486618042
Validation loss: 2.0962945107490785

Epoch: 6| Step: 12
Training loss: 2.069403886795044
Validation loss: 2.1496381323824645

Epoch: 6| Step: 13
Training loss: 1.5369902849197388
Validation loss: 2.1874937613805137

Epoch: 450| Step: 0
Training loss: 1.8899376392364502
Validation loss: 2.1364185271724576

Epoch: 6| Step: 1
Training loss: 1.8709769248962402
Validation loss: 2.0605860115379415

Epoch: 6| Step: 2
Training loss: 1.5985246896743774
Validation loss: 2.161997886114223

Epoch: 6| Step: 3
Training loss: 1.840065360069275
Validation loss: 2.1740905956555436

Epoch: 6| Step: 4
Training loss: 1.5649268627166748
Validation loss: 2.161855178494607

Epoch: 6| Step: 5
Training loss: 1.6953277587890625
Validation loss: 2.111192200773506

Epoch: 6| Step: 6
Training loss: 2.1740894317626953
Validation loss: 2.1670176290696666

Epoch: 6| Step: 7
Training loss: 1.0686800479888916
Validation loss: 2.0799755601472754

Epoch: 6| Step: 8
Training loss: 1.4225883483886719
Validation loss: 2.10649876440725

Epoch: 6| Step: 9
Training loss: 2.080564260482788
Validation loss: 2.0353679144254295

Epoch: 6| Step: 10
Training loss: 2.3343653678894043
Validation loss: 2.175575497329876

Epoch: 6| Step: 11
Training loss: 1.1494343280792236
Validation loss: 2.130670086030037

Epoch: 6| Step: 12
Training loss: 1.250899314880371
Validation loss: 2.12268501968794

Epoch: 6| Step: 13
Training loss: 1.440093994140625
Validation loss: 2.1050317479718115

Testing loss: 2.1663021829393174
