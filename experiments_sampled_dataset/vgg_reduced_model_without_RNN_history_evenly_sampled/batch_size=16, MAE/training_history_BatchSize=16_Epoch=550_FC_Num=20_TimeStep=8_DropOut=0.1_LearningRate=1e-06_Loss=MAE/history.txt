Epoch: 1| Step: 0
Training loss: 4.686502933502197
Validation loss: 4.838521747178929

Epoch: 6| Step: 1
Training loss: 4.403284072875977
Validation loss: 4.83625304314398

Epoch: 6| Step: 2
Training loss: 4.646572113037109
Validation loss: 4.832280697361115

Epoch: 6| Step: 3
Training loss: 4.532844543457031
Validation loss: 4.83133929262879

Epoch: 6| Step: 4
Training loss: 3.698540687561035
Validation loss: 4.828146596108714

Epoch: 6| Step: 5
Training loss: 4.815042972564697
Validation loss: 4.827460683802123

Epoch: 6| Step: 6
Training loss: 3.5822033882141113
Validation loss: 4.82250258743122

Epoch: 6| Step: 7
Training loss: 5.136667251586914
Validation loss: 4.823679001100602

Epoch: 6| Step: 8
Training loss: 5.807106018066406
Validation loss: 4.817057009666197

Epoch: 6| Step: 9
Training loss: 3.645543336868286
Validation loss: 4.814961782065771

Epoch: 6| Step: 10
Training loss: 4.653553009033203
Validation loss: 4.81221015478975

Epoch: 6| Step: 11
Training loss: 3.6861000061035156
Validation loss: 4.809801506739791

Epoch: 6| Step: 12
Training loss: 5.848252296447754
Validation loss: 4.8076705983890005

Epoch: 6| Step: 13
Training loss: 6.119096279144287
Validation loss: 4.801414469236969

Epoch: 2| Step: 0
Training loss: 4.498512268066406
Validation loss: 4.801157759081933

Epoch: 6| Step: 1
Training loss: 4.708356857299805
Validation loss: 4.79946324645832

Epoch: 6| Step: 2
Training loss: 4.559001445770264
Validation loss: 4.796196260759907

Epoch: 6| Step: 3
Training loss: 5.007530212402344
Validation loss: 4.792686231674686

Epoch: 6| Step: 4
Training loss: 3.571031093597412
Validation loss: 4.788759264894711

Epoch: 6| Step: 5
Training loss: 4.93133544921875
Validation loss: 4.788007090168614

Epoch: 6| Step: 6
Training loss: 4.205263137817383
Validation loss: 4.786126716162569

Epoch: 6| Step: 7
Training loss: 3.9609272480010986
Validation loss: 4.7831832516577935

Epoch: 6| Step: 8
Training loss: 4.1123528480529785
Validation loss: 4.777071393946166

Epoch: 6| Step: 9
Training loss: 5.860912322998047
Validation loss: 4.776571945477557

Epoch: 6| Step: 10
Training loss: 4.944046974182129
Validation loss: 4.775852808388331

Epoch: 6| Step: 11
Training loss: 4.6294403076171875
Validation loss: 4.771839413591611

Epoch: 6| Step: 12
Training loss: 4.690073013305664
Validation loss: 4.765293459738454

Epoch: 6| Step: 13
Training loss: 4.235692977905273
Validation loss: 4.764636506316482

Epoch: 3| Step: 0
Training loss: 4.293670177459717
Validation loss: 4.764081267900364

Epoch: 6| Step: 1
Training loss: 5.041563510894775
Validation loss: 4.75874533448168

Epoch: 6| Step: 2
Training loss: 4.576397895812988
Validation loss: 4.755363049045686

Epoch: 6| Step: 3
Training loss: 4.961367607116699
Validation loss: 4.751366889604959

Epoch: 6| Step: 4
Training loss: 5.727927207946777
Validation loss: 4.751250082446683

Epoch: 6| Step: 5
Training loss: 3.5922203063964844
Validation loss: 4.7467100850997435

Epoch: 6| Step: 6
Training loss: 4.465450286865234
Validation loss: 4.746090335230673

Epoch: 6| Step: 7
Training loss: 4.638943195343018
Validation loss: 4.743438290011499

Epoch: 6| Step: 8
Training loss: 4.975480079650879
Validation loss: 4.739269656519736

Epoch: 6| Step: 9
Training loss: 3.807323455810547
Validation loss: 4.736537553930796

Epoch: 6| Step: 10
Training loss: 4.947009563446045
Validation loss: 4.733361318547239

Epoch: 6| Step: 11
Training loss: 4.369688034057617
Validation loss: 4.729296376628261

Epoch: 6| Step: 12
Training loss: 3.586503028869629
Validation loss: 4.725837394755374

Epoch: 6| Step: 13
Training loss: 4.481012344360352
Validation loss: 4.722970039613785

Epoch: 4| Step: 0
Training loss: 4.307230472564697
Validation loss: 4.7194703214912

Epoch: 6| Step: 1
Training loss: 5.763535499572754
Validation loss: 4.717742689194218

Epoch: 6| Step: 2
Training loss: 5.868472099304199
Validation loss: 4.714839284138013

Epoch: 6| Step: 3
Training loss: 3.0312814712524414
Validation loss: 4.708753898579587

Epoch: 6| Step: 4
Training loss: 3.4566264152526855
Validation loss: 4.705505714621595

Epoch: 6| Step: 5
Training loss: 5.024001121520996
Validation loss: 4.703742314410466

Epoch: 6| Step: 6
Training loss: 4.3018693923950195
Validation loss: 4.699516604023595

Epoch: 6| Step: 7
Training loss: 4.464385986328125
Validation loss: 4.695566433732227

Epoch: 6| Step: 8
Training loss: 5.071191787719727
Validation loss: 4.692084220147902

Epoch: 6| Step: 9
Training loss: 4.375261306762695
Validation loss: 4.688236672391174

Epoch: 6| Step: 10
Training loss: 3.38606333732605
Validation loss: 4.684933885451286

Epoch: 6| Step: 11
Training loss: 4.437327861785889
Validation loss: 4.68170714634721

Epoch: 6| Step: 12
Training loss: 4.167104244232178
Validation loss: 4.674152358885734

Epoch: 6| Step: 13
Training loss: 5.80856466293335
Validation loss: 4.674016624368647

Epoch: 5| Step: 0
Training loss: 5.291471481323242
Validation loss: 4.669788673359861

Epoch: 6| Step: 1
Training loss: 5.649899482727051
Validation loss: 4.669230486757012

Epoch: 6| Step: 2
Training loss: 4.346490383148193
Validation loss: 4.661057118446596

Epoch: 6| Step: 3
Training loss: 3.204188346862793
Validation loss: 4.6602509201213875

Epoch: 6| Step: 4
Training loss: 4.135597229003906
Validation loss: 4.655346137221142

Epoch: 6| Step: 5
Training loss: 3.540653705596924
Validation loss: 4.648815262702204

Epoch: 6| Step: 6
Training loss: 4.4458160400390625
Validation loss: 4.649401700624856

Epoch: 6| Step: 7
Training loss: 4.9997429847717285
Validation loss: 4.644475667707382

Epoch: 6| Step: 8
Training loss: 4.803691387176514
Validation loss: 4.642083127011535

Epoch: 6| Step: 9
Training loss: 3.8485143184661865
Validation loss: 4.634322915025937

Epoch: 6| Step: 10
Training loss: 4.696755409240723
Validation loss: 4.633500196600473

Epoch: 6| Step: 11
Training loss: 5.113864898681641
Validation loss: 4.628340054583806

Epoch: 6| Step: 12
Training loss: 2.989542007446289
Validation loss: 4.622504347114153

Epoch: 6| Step: 13
Training loss: 5.618025779724121
Validation loss: 4.621600981681578

Epoch: 6| Step: 0
Training loss: 5.22292423248291
Validation loss: 4.618226148748911

Epoch: 6| Step: 1
Training loss: 4.1310248374938965
Validation loss: 4.611637782025081

Epoch: 6| Step: 2
Training loss: 4.896456718444824
Validation loss: 4.610160161090153

Epoch: 6| Step: 3
Training loss: 4.405759811401367
Validation loss: 4.606853977326424

Epoch: 6| Step: 4
Training loss: 3.9572083950042725
Validation loss: 4.601256585890247

Epoch: 6| Step: 5
Training loss: 4.507676124572754
Validation loss: 4.593467517565656

Epoch: 6| Step: 6
Training loss: 4.126948833465576
Validation loss: 4.59153018459197

Epoch: 6| Step: 7
Training loss: 4.502815246582031
Validation loss: 4.58620152678541

Epoch: 6| Step: 8
Training loss: 4.5125885009765625
Validation loss: 4.580487933210147

Epoch: 6| Step: 9
Training loss: 4.281963348388672
Validation loss: 4.573931442793979

Epoch: 6| Step: 10
Training loss: 4.782594680786133
Validation loss: 4.568876594625493

Epoch: 6| Step: 11
Training loss: 4.168964385986328
Validation loss: 4.5642750391396145

Epoch: 6| Step: 12
Training loss: 3.5710363388061523
Validation loss: 4.558972707358739

Epoch: 6| Step: 13
Training loss: 4.16256856918335
Validation loss: 4.55664324760437

Epoch: 7| Step: 0
Training loss: 2.7455408573150635
Validation loss: 4.55333790727841

Epoch: 6| Step: 1
Training loss: 4.621891975402832
Validation loss: 4.545741388874669

Epoch: 6| Step: 2
Training loss: 5.146448135375977
Validation loss: 4.540829038107267

Epoch: 6| Step: 3
Training loss: 5.440341949462891
Validation loss: 4.535965068365938

Epoch: 6| Step: 4
Training loss: 3.8363375663757324
Validation loss: 4.531261926056237

Epoch: 6| Step: 5
Training loss: 3.127838611602783
Validation loss: 4.524650563475906

Epoch: 6| Step: 6
Training loss: 4.521660327911377
Validation loss: 4.518818311793829

Epoch: 6| Step: 7
Training loss: 4.856166362762451
Validation loss: 4.516196943098499

Epoch: 6| Step: 8
Training loss: 4.452620983123779
Validation loss: 4.511273055948237

Epoch: 6| Step: 9
Training loss: 3.1646060943603516
Validation loss: 4.506381455288138

Epoch: 6| Step: 10
Training loss: 5.256862640380859
Validation loss: 4.499926556823074

Epoch: 6| Step: 11
Training loss: 4.558333396911621
Validation loss: 4.4893997561547065

Epoch: 6| Step: 12
Training loss: 3.9641647338867188
Validation loss: 4.492526203073481

Epoch: 6| Step: 13
Training loss: 4.998018741607666
Validation loss: 4.484120825285553

Epoch: 8| Step: 0
Training loss: 5.052082538604736
Validation loss: 4.48085226551179

Epoch: 6| Step: 1
Training loss: 3.7882790565490723
Validation loss: 4.473376915019045

Epoch: 6| Step: 2
Training loss: 3.879271984100342
Validation loss: 4.463659886390932

Epoch: 6| Step: 3
Training loss: 4.304131507873535
Validation loss: 4.458396386074764

Epoch: 6| Step: 4
Training loss: 3.705018997192383
Validation loss: 4.456642720007127

Epoch: 6| Step: 5
Training loss: 3.7972896099090576
Validation loss: 4.443729103252452

Epoch: 6| Step: 6
Training loss: 3.9963901042938232
Validation loss: 4.442258922002649

Epoch: 6| Step: 7
Training loss: 4.056980133056641
Validation loss: 4.429964342424946

Epoch: 6| Step: 8
Training loss: 4.857450485229492
Validation loss: 4.428463151378017

Epoch: 6| Step: 9
Training loss: 4.148979663848877
Validation loss: 4.425462092122724

Epoch: 6| Step: 10
Training loss: 3.786503791809082
Validation loss: 4.414069462847966

Epoch: 6| Step: 11
Training loss: 3.836561679840088
Validation loss: 4.410234210311725

Epoch: 6| Step: 12
Training loss: 6.019782543182373
Validation loss: 4.405079749322707

Epoch: 6| Step: 13
Training loss: 3.9321534633636475
Validation loss: 4.398097566379014

Epoch: 9| Step: 0
Training loss: 3.3553872108459473
Validation loss: 4.3864763270142255

Epoch: 6| Step: 1
Training loss: 4.579616546630859
Validation loss: 4.3827690001456965

Epoch: 6| Step: 2
Training loss: 4.481233596801758
Validation loss: 4.3764220822242

Epoch: 6| Step: 3
Training loss: 3.6705234050750732
Validation loss: 4.370903491973877

Epoch: 6| Step: 4
Training loss: 4.880407333374023
Validation loss: 4.362555309008527

Epoch: 6| Step: 5
Training loss: 3.9647114276885986
Validation loss: 4.352975565900085

Epoch: 6| Step: 6
Training loss: 3.6243114471435547
Validation loss: 4.348494009305072

Epoch: 6| Step: 7
Training loss: 3.5855464935302734
Validation loss: 4.338151367761755

Epoch: 6| Step: 8
Training loss: 3.343879461288452
Validation loss: 4.328631298516386

Epoch: 6| Step: 9
Training loss: 5.146049499511719
Validation loss: 4.321014768333845

Epoch: 6| Step: 10
Training loss: 4.490867614746094
Validation loss: 4.316213284769366

Epoch: 6| Step: 11
Training loss: 3.933711051940918
Validation loss: 4.308589881466281

Epoch: 6| Step: 12
Training loss: 4.147134780883789
Validation loss: 4.296499775302026

Epoch: 6| Step: 13
Training loss: 5.320045471191406
Validation loss: 4.292285821771109

Epoch: 10| Step: 0
Training loss: 3.5179967880249023
Validation loss: 4.281862787021104

Epoch: 6| Step: 1
Training loss: 4.63834285736084
Validation loss: 4.276778872295092

Epoch: 6| Step: 2
Training loss: 4.302676200866699
Validation loss: 4.270307381947835

Epoch: 6| Step: 3
Training loss: 3.7862117290496826
Validation loss: 4.258051672289448

Epoch: 6| Step: 4
Training loss: 4.242442607879639
Validation loss: 4.251919295198174

Epoch: 6| Step: 5
Training loss: 3.457167387008667
Validation loss: 4.239429555913453

Epoch: 6| Step: 6
Training loss: 3.4681875705718994
Validation loss: 4.23328427345522

Epoch: 6| Step: 7
Training loss: 3.886782169342041
Validation loss: 4.22632025646907

Epoch: 6| Step: 8
Training loss: 3.853264808654785
Validation loss: 4.215960492369949

Epoch: 6| Step: 9
Training loss: 3.5656349658966064
Validation loss: 4.206390662859845

Epoch: 6| Step: 10
Training loss: 5.211158752441406
Validation loss: 4.192653358623546

Epoch: 6| Step: 11
Training loss: 4.173584461212158
Validation loss: 4.188989439318257

Epoch: 6| Step: 12
Training loss: 3.9594898223876953
Validation loss: 4.175324040074503

Epoch: 6| Step: 13
Training loss: 4.898319721221924
Validation loss: 4.171715762025567

Epoch: 11| Step: 0
Training loss: 4.4058732986450195
Validation loss: 4.161704714580249

Epoch: 6| Step: 1
Training loss: 3.7623391151428223
Validation loss: 4.14860104232706

Epoch: 6| Step: 2
Training loss: 4.915650367736816
Validation loss: 4.142186446856427

Epoch: 6| Step: 3
Training loss: 3.605477809906006
Validation loss: 4.132518153036794

Epoch: 6| Step: 4
Training loss: 3.292585611343384
Validation loss: 4.128878906208982

Epoch: 6| Step: 5
Training loss: 3.273191452026367
Validation loss: 4.114523744070402

Epoch: 6| Step: 6
Training loss: 3.0799670219421387
Validation loss: 4.1024336302152244

Epoch: 6| Step: 7
Training loss: 3.951692819595337
Validation loss: 4.090394112371629

Epoch: 6| Step: 8
Training loss: 3.805359125137329
Validation loss: 4.079571616265081

Epoch: 6| Step: 9
Training loss: 3.8070478439331055
Validation loss: 4.070976821325159

Epoch: 6| Step: 10
Training loss: 3.9977495670318604
Validation loss: 4.059953717775242

Epoch: 6| Step: 11
Training loss: 3.8128623962402344
Validation loss: 4.048945498722856

Epoch: 6| Step: 12
Training loss: 4.914931774139404
Validation loss: 4.035648143419656

Epoch: 6| Step: 13
Training loss: 4.744133472442627
Validation loss: 4.02700388047003

Epoch: 12| Step: 0
Training loss: 4.149740219116211
Validation loss: 4.017529774737614

Epoch: 6| Step: 1
Training loss: 3.611539363861084
Validation loss: 4.012626242893998

Epoch: 6| Step: 2
Training loss: 3.178187608718872
Validation loss: 4.003689278838455

Epoch: 6| Step: 3
Training loss: 4.694973945617676
Validation loss: 3.9809526858791227

Epoch: 6| Step: 4
Training loss: 4.525626182556152
Validation loss: 3.9724228177019345

Epoch: 6| Step: 5
Training loss: 3.821653127670288
Validation loss: 3.964461916236467

Epoch: 6| Step: 6
Training loss: 3.169623374938965
Validation loss: 3.952423193121469

Epoch: 6| Step: 7
Training loss: 3.3631317615509033
Validation loss: 3.937429420409664

Epoch: 6| Step: 8
Training loss: 4.01511812210083
Validation loss: 3.9262811317238757

Epoch: 6| Step: 9
Training loss: 3.7484352588653564
Validation loss: 3.911246489453059

Epoch: 6| Step: 10
Training loss: 5.07395076751709
Validation loss: 3.913009792245844

Epoch: 6| Step: 11
Training loss: 3.4376606941223145
Validation loss: 3.8964323330950994

Epoch: 6| Step: 12
Training loss: 2.7298171520233154
Validation loss: 3.883797845532817

Epoch: 6| Step: 13
Training loss: 3.487212657928467
Validation loss: 3.868454446074783

Epoch: 13| Step: 0
Training loss: 3.2213876247406006
Validation loss: 3.8578763572118615

Epoch: 6| Step: 1
Training loss: 3.5350472927093506
Validation loss: 3.8500508339174333

Epoch: 6| Step: 2
Training loss: 4.69350004196167
Validation loss: 3.8363840221076884

Epoch: 6| Step: 3
Training loss: 3.5851786136627197
Validation loss: 3.817868104545019

Epoch: 6| Step: 4
Training loss: 3.9077131748199463
Validation loss: 3.816732580943774

Epoch: 6| Step: 5
Training loss: 4.767034530639648
Validation loss: 3.794460937541018

Epoch: 6| Step: 6
Training loss: 2.631220579147339
Validation loss: 3.777752120007751

Epoch: 6| Step: 7
Training loss: 3.8649747371673584
Validation loss: 3.7732789952267884

Epoch: 6| Step: 8
Training loss: 4.13363790512085
Validation loss: 3.7570469199970202

Epoch: 6| Step: 9
Training loss: 3.88965106010437
Validation loss: 3.7474869912670505

Epoch: 6| Step: 10
Training loss: 3.1409270763397217
Validation loss: 3.734724167854555

Epoch: 6| Step: 11
Training loss: 3.5678882598876953
Validation loss: 3.7221788898591073

Epoch: 6| Step: 12
Training loss: 2.445589065551758
Validation loss: 3.701374371846517

Epoch: 6| Step: 13
Training loss: 3.9844911098480225
Validation loss: 3.6957670386119554

Epoch: 14| Step: 0
Training loss: 3.315154552459717
Validation loss: 3.68288000681067

Epoch: 6| Step: 1
Training loss: 2.1767027378082275
Validation loss: 3.669509680040421

Epoch: 6| Step: 2
Training loss: 2.9508063793182373
Validation loss: 3.663562649039812

Epoch: 6| Step: 3
Training loss: 3.9797122478485107
Validation loss: 3.6423567956493748

Epoch: 6| Step: 4
Training loss: 2.9999046325683594
Validation loss: 3.629180395474998

Epoch: 6| Step: 5
Training loss: 3.050804615020752
Validation loss: 3.608883626999394

Epoch: 6| Step: 6
Training loss: 3.856750249862671
Validation loss: 3.6053403321132866

Epoch: 6| Step: 7
Training loss: 4.596649169921875
Validation loss: 3.585686932327927

Epoch: 6| Step: 8
Training loss: 4.268668174743652
Validation loss: 3.572512460011308

Epoch: 6| Step: 9
Training loss: 4.054196357727051
Validation loss: 3.5591942289824128

Epoch: 6| Step: 10
Training loss: 3.757337808609009
Validation loss: 3.547832904323455

Epoch: 6| Step: 11
Training loss: 3.129638671875
Validation loss: 3.526743288963072

Epoch: 6| Step: 12
Training loss: 3.985671281814575
Validation loss: 3.5135163799408944

Epoch: 6| Step: 13
Training loss: 2.2695116996765137
Validation loss: 3.500770248392577

Epoch: 15| Step: 0
Training loss: 3.780975818634033
Validation loss: 3.4861917803364415

Epoch: 6| Step: 1
Training loss: 2.891481876373291
Validation loss: 3.4556974313592397

Epoch: 6| Step: 2
Training loss: 3.344355583190918
Validation loss: 3.4596288178556707

Epoch: 6| Step: 3
Training loss: 3.295830726623535
Validation loss: 3.4378537465167303

Epoch: 6| Step: 4
Training loss: 3.8080997467041016
Validation loss: 3.412597381940452

Epoch: 6| Step: 5
Training loss: 2.5517067909240723
Validation loss: 3.4000105755303496

Epoch: 6| Step: 6
Training loss: 4.289223670959473
Validation loss: 3.390216286464404

Epoch: 6| Step: 7
Training loss: 2.5097763538360596
Validation loss: 3.3792621730476298

Epoch: 6| Step: 8
Training loss: 3.1893234252929688
Validation loss: 3.347461736330422

Epoch: 6| Step: 9
Training loss: 3.1088194847106934
Validation loss: 3.3371373248356644

Epoch: 6| Step: 10
Training loss: 4.142327308654785
Validation loss: 3.3308904504263275

Epoch: 6| Step: 11
Training loss: 3.319882869720459
Validation loss: 3.3015807726049937

Epoch: 6| Step: 12
Training loss: 2.9753711223602295
Validation loss: 3.283087864998848

Epoch: 6| Step: 13
Training loss: 3.322281837463379
Validation loss: 3.2823836547072216

Epoch: 16| Step: 0
Training loss: 3.4468307495117188
Validation loss: 3.2462829338606967

Epoch: 6| Step: 1
Training loss: 3.5486178398132324
Validation loss: 3.2347950243180796

Epoch: 6| Step: 2
Training loss: 3.924006223678589
Validation loss: 3.2148036905514297

Epoch: 6| Step: 3
Training loss: 2.311324119567871
Validation loss: 3.204981901312387

Epoch: 6| Step: 4
Training loss: 3.0429491996765137
Validation loss: 3.1778315574892106

Epoch: 6| Step: 5
Training loss: 2.740021228790283
Validation loss: 3.162668466567993

Epoch: 6| Step: 6
Training loss: 2.040928363800049
Validation loss: 3.1467498502423688

Epoch: 6| Step: 7
Training loss: 2.9002432823181152
Validation loss: 3.128648578479726

Epoch: 6| Step: 8
Training loss: 2.715897798538208
Validation loss: 3.1233564422976587

Epoch: 6| Step: 9
Training loss: 2.942180871963501
Validation loss: 3.096060529831917

Epoch: 6| Step: 10
Training loss: 3.9808132648468018
Validation loss: 3.0844484119005102

Epoch: 6| Step: 11
Training loss: 3.139634132385254
Validation loss: 3.0708202572279077

Epoch: 6| Step: 12
Training loss: 4.22490119934082
Validation loss: 3.04818158764993

Epoch: 6| Step: 13
Training loss: 2.5098800659179688
Validation loss: 3.026400371264386

Epoch: 17| Step: 0
Training loss: 3.2927169799804688
Validation loss: 3.013937270769509

Epoch: 6| Step: 1
Training loss: 2.731109142303467
Validation loss: 2.995413144429525

Epoch: 6| Step: 2
Training loss: 3.574812412261963
Validation loss: 2.9945223767270326

Epoch: 6| Step: 3
Training loss: 3.4097490310668945
Validation loss: 2.960014702171408

Epoch: 6| Step: 4
Training loss: 3.8391757011413574
Validation loss: 2.9526807390233523

Epoch: 6| Step: 5
Training loss: 2.827010154724121
Validation loss: 2.9199701406622447

Epoch: 6| Step: 6
Training loss: 1.8689613342285156
Validation loss: 2.907683890352967

Epoch: 6| Step: 7
Training loss: 3.6823785305023193
Validation loss: 2.877558708190918

Epoch: 6| Step: 8
Training loss: 3.6467461585998535
Validation loss: 2.8614768059022966

Epoch: 6| Step: 9
Training loss: 2.1595287322998047
Validation loss: 2.84351546020918

Epoch: 6| Step: 10
Training loss: 2.508854389190674
Validation loss: 2.818674364397603

Epoch: 6| Step: 11
Training loss: 2.5113000869750977
Validation loss: 2.812321803903067

Epoch: 6| Step: 12
Training loss: 2.8247103691101074
Validation loss: 2.804751983252905

Epoch: 6| Step: 13
Training loss: 2.6122987270355225
Validation loss: 2.784194387415404

Epoch: 18| Step: 0
Training loss: 3.158254861831665
Validation loss: 2.767708965527114

Epoch: 6| Step: 1
Training loss: 3.2596402168273926
Validation loss: 2.735204468491257

Epoch: 6| Step: 2
Training loss: 2.9109175205230713
Validation loss: 2.7317116286164973

Epoch: 6| Step: 3
Training loss: 2.353426933288574
Validation loss: 2.7207368830198884

Epoch: 6| Step: 4
Training loss: 2.820650577545166
Validation loss: 2.6813873526870564

Epoch: 6| Step: 5
Training loss: 3.556368350982666
Validation loss: 2.676300048828125

Epoch: 6| Step: 6
Training loss: 2.349827766418457
Validation loss: 2.653680214317896

Epoch: 6| Step: 7
Training loss: 3.4098167419433594
Validation loss: 2.639701315151748

Epoch: 6| Step: 8
Training loss: 2.342529058456421
Validation loss: 2.6115416403739684

Epoch: 6| Step: 9
Training loss: 2.5579285621643066
Validation loss: 2.5827282423614175

Epoch: 6| Step: 10
Training loss: 2.822688102722168
Validation loss: 2.5758171748089533

Epoch: 6| Step: 11
Training loss: 2.9839234352111816
Validation loss: 2.5682171621630268

Epoch: 6| Step: 12
Training loss: 2.279913902282715
Validation loss: 2.5404620068047636

Epoch: 6| Step: 13
Training loss: 2.3791794776916504
Validation loss: 2.526169705134566

Epoch: 19| Step: 0
Training loss: 2.709681510925293
Validation loss: 2.5092860216735513

Epoch: 6| Step: 1
Training loss: 2.9320130348205566
Validation loss: 2.5084476419674453

Epoch: 6| Step: 2
Training loss: 2.788940906524658
Validation loss: 2.50093319595501

Epoch: 6| Step: 3
Training loss: 2.8464879989624023
Validation loss: 2.4907164163486932

Epoch: 6| Step: 4
Training loss: 2.520662784576416
Validation loss: 2.4481114187548236

Epoch: 6| Step: 5
Training loss: 2.8938193321228027
Validation loss: 2.427076344848961

Epoch: 6| Step: 6
Training loss: 2.7538228034973145
Validation loss: 2.4336433282462497

Epoch: 6| Step: 7
Training loss: 1.9425560235977173
Validation loss: 2.39725080356803

Epoch: 6| Step: 8
Training loss: 3.0741593837738037
Validation loss: 2.4057662307575183

Epoch: 6| Step: 9
Training loss: 2.843214750289917
Validation loss: 2.379758906620805

Epoch: 6| Step: 10
Training loss: 2.507855176925659
Validation loss: 2.3819064171083513

Epoch: 6| Step: 11
Training loss: 2.3330588340759277
Validation loss: 2.3668097731887654

Epoch: 6| Step: 12
Training loss: 2.2580835819244385
Validation loss: 2.3616571041845504

Epoch: 6| Step: 13
Training loss: 2.8876078128814697
Validation loss: 2.3239722559528966

Epoch: 20| Step: 0
Training loss: 2.372812271118164
Validation loss: 2.319837434317476

Epoch: 6| Step: 1
Training loss: 2.2589266300201416
Validation loss: 2.3238371623459684

Epoch: 6| Step: 2
Training loss: 2.567045211791992
Validation loss: 2.298008907225824

Epoch: 6| Step: 3
Training loss: 2.836843252182007
Validation loss: 2.2900755354153213

Epoch: 6| Step: 4
Training loss: 2.487367630004883
Validation loss: 2.2995994860126125

Epoch: 6| Step: 5
Training loss: 2.2313241958618164
Validation loss: 2.2811943920709754

Epoch: 6| Step: 6
Training loss: 2.2703137397766113
Validation loss: 2.280116601656842

Epoch: 6| Step: 7
Training loss: 2.5031678676605225
Validation loss: 2.261622505803262

Epoch: 6| Step: 8
Training loss: 3.820327043533325
Validation loss: 2.245212499813367

Epoch: 6| Step: 9
Training loss: 2.0317392349243164
Validation loss: 2.246557653591197

Epoch: 6| Step: 10
Training loss: 2.5094194412231445
Validation loss: 2.23253418168714

Epoch: 6| Step: 11
Training loss: 2.727658271789551
Validation loss: 2.225765824317932

Epoch: 6| Step: 12
Training loss: 2.8618664741516113
Validation loss: 2.1980280119885682

Epoch: 6| Step: 13
Training loss: 1.62357497215271
Validation loss: 2.213997403780619

Epoch: 21| Step: 0
Training loss: 2.2942185401916504
Validation loss: 2.185403613634007

Epoch: 6| Step: 1
Training loss: 3.416905403137207
Validation loss: 2.199964907861525

Epoch: 6| Step: 2
Training loss: 2.4087252616882324
Validation loss: 2.1829873079894693

Epoch: 6| Step: 3
Training loss: 2.7074739933013916
Validation loss: 2.159775341710737

Epoch: 6| Step: 4
Training loss: 2.2182791233062744
Validation loss: 2.160265399563697

Epoch: 6| Step: 5
Training loss: 1.8584803342819214
Validation loss: 2.1587145456703762

Epoch: 6| Step: 6
Training loss: 2.9163646697998047
Validation loss: 2.163298437672277

Epoch: 6| Step: 7
Training loss: 1.7969220876693726
Validation loss: 2.147241994898806

Epoch: 6| Step: 8
Training loss: 3.11049485206604
Validation loss: 2.143622757286154

Epoch: 6| Step: 9
Training loss: 2.183250904083252
Validation loss: 2.1445218850207586

Epoch: 6| Step: 10
Training loss: 2.8934402465820312
Validation loss: 2.137378531117593

Epoch: 6| Step: 11
Training loss: 1.6613843441009521
Validation loss: 2.1128425239234843

Epoch: 6| Step: 12
Training loss: 2.554091453552246
Validation loss: 2.141382159725312

Epoch: 6| Step: 13
Training loss: 3.0388553142547607
Validation loss: 2.130141861977116

Epoch: 22| Step: 0
Training loss: 2.759416103363037
Validation loss: 2.1305067718669934

Epoch: 6| Step: 1
Training loss: 2.2896487712860107
Validation loss: 2.1168559687111967

Epoch: 6| Step: 2
Training loss: 2.655017375946045
Validation loss: 2.107951970510585

Epoch: 6| Step: 3
Training loss: 2.467139720916748
Validation loss: 2.1387433364827144

Epoch: 6| Step: 4
Training loss: 2.8897016048431396
Validation loss: 2.129446603918588

Epoch: 6| Step: 5
Training loss: 2.4759578704833984
Validation loss: 2.109403089810443

Epoch: 6| Step: 6
Training loss: 2.4004340171813965
Validation loss: 2.1034353574117026

Epoch: 6| Step: 7
Training loss: 2.603318691253662
Validation loss: 2.1135058992652485

Epoch: 6| Step: 8
Training loss: 2.353247880935669
Validation loss: 2.0918073372174333

Epoch: 6| Step: 9
Training loss: 2.9375572204589844
Validation loss: 2.0946678576930875

Epoch: 6| Step: 10
Training loss: 1.8855552673339844
Validation loss: 2.097377695063109

Epoch: 6| Step: 11
Training loss: 1.6345614194869995
Validation loss: 2.1134210812148226

Epoch: 6| Step: 12
Training loss: 2.722590684890747
Validation loss: 2.1000229107436312

Epoch: 6| Step: 13
Training loss: 2.146677255630493
Validation loss: 2.1023579310345393

Epoch: 23| Step: 0
Training loss: 2.521800994873047
Validation loss: 2.0969729090249665

Epoch: 6| Step: 1
Training loss: 2.799562454223633
Validation loss: 2.1119067720187608

Epoch: 6| Step: 2
Training loss: 1.825622320175171
Validation loss: 2.1127823988596597

Epoch: 6| Step: 3
Training loss: 2.477405071258545
Validation loss: 2.1027990156604397

Epoch: 6| Step: 4
Training loss: 2.8591127395629883
Validation loss: 2.1151310564369283

Epoch: 6| Step: 5
Training loss: 2.3881311416625977
Validation loss: 2.1173535162402737

Epoch: 6| Step: 6
Training loss: 2.639453172683716
Validation loss: 2.1165856545971287

Epoch: 6| Step: 7
Training loss: 2.3525376319885254
Validation loss: 2.1188788619092715

Epoch: 6| Step: 8
Training loss: 2.3768014907836914
Validation loss: 2.1077808385254233

Epoch: 6| Step: 9
Training loss: 2.5323562622070312
Validation loss: 2.112407389507499

Epoch: 6| Step: 10
Training loss: 2.586967706680298
Validation loss: 2.108848420522546

Epoch: 6| Step: 11
Training loss: 2.619312047958374
Validation loss: 2.104436674425679

Epoch: 6| Step: 12
Training loss: 2.025756597518921
Validation loss: 2.0953138169421943

Epoch: 6| Step: 13
Training loss: 1.770126461982727
Validation loss: 2.105313390813848

Epoch: 24| Step: 0
Training loss: 1.9790551662445068
Validation loss: 2.1014295124238536

Epoch: 6| Step: 1
Training loss: 2.164985179901123
Validation loss: 2.1013613644466607

Epoch: 6| Step: 2
Training loss: 1.9909377098083496
Validation loss: 2.1130035231190343

Epoch: 6| Step: 3
Training loss: 3.44480562210083
Validation loss: 2.097480356052358

Epoch: 6| Step: 4
Training loss: 2.1993918418884277
Validation loss: 2.0940226970180387

Epoch: 6| Step: 5
Training loss: 2.1832752227783203
Validation loss: 2.0872703752210064

Epoch: 6| Step: 6
Training loss: 2.588623046875
Validation loss: 2.1020256524444907

Epoch: 6| Step: 7
Training loss: 2.920440196990967
Validation loss: 2.103955009932159

Epoch: 6| Step: 8
Training loss: 2.6764814853668213
Validation loss: 2.0795986754919893

Epoch: 6| Step: 9
Training loss: 2.6235432624816895
Validation loss: 2.0771802650984896

Epoch: 6| Step: 10
Training loss: 2.3484041690826416
Validation loss: 2.0877581642520044

Epoch: 6| Step: 11
Training loss: 2.556419849395752
Validation loss: 2.1017663273760068

Epoch: 6| Step: 12
Training loss: 2.4601340293884277
Validation loss: 2.0967524205484698

Epoch: 6| Step: 13
Training loss: 2.064082622528076
Validation loss: 2.1011412182161884

Epoch: 25| Step: 0
Training loss: 2.2579236030578613
Validation loss: 2.086500765174948

Epoch: 6| Step: 1
Training loss: 2.1693203449249268
Validation loss: 2.0769369230475476

Epoch: 6| Step: 2
Training loss: 2.2490220069885254
Validation loss: 2.0933160064040974

Epoch: 6| Step: 3
Training loss: 2.387068748474121
Validation loss: 2.0766804731020363

Epoch: 6| Step: 4
Training loss: 2.3962454795837402
Validation loss: 2.077875878221245

Epoch: 6| Step: 5
Training loss: 2.676295280456543
Validation loss: 2.0916651512986872

Epoch: 6| Step: 6
Training loss: 2.949695110321045
Validation loss: 2.083867488368865

Epoch: 6| Step: 7
Training loss: 2.494767904281616
Validation loss: 2.0752805176601616

Epoch: 6| Step: 8
Training loss: 2.4403939247131348
Validation loss: 2.0814807709827217

Epoch: 6| Step: 9
Training loss: 1.7445087432861328
Validation loss: 2.079476882052678

Epoch: 6| Step: 10
Training loss: 2.9265153408050537
Validation loss: 2.089056654642987

Epoch: 6| Step: 11
Training loss: 2.147716999053955
Validation loss: 2.0814482704285653

Epoch: 6| Step: 12
Training loss: 2.817452907562256
Validation loss: 2.087490197150938

Epoch: 6| Step: 13
Training loss: 2.3976240158081055
Validation loss: 2.0850807928269908

Epoch: 26| Step: 0
Training loss: 3.081444263458252
Validation loss: 2.081052421241678

Epoch: 6| Step: 1
Training loss: 2.511815071105957
Validation loss: 2.084912553910286

Epoch: 6| Step: 2
Training loss: 2.4630370140075684
Validation loss: 2.065722701370075

Epoch: 6| Step: 3
Training loss: 3.2975564002990723
Validation loss: 2.104476034000356

Epoch: 6| Step: 4
Training loss: 1.9066823720932007
Validation loss: 2.073593624176518

Epoch: 6| Step: 5
Training loss: 2.144519329071045
Validation loss: 2.094214734210763

Epoch: 6| Step: 6
Training loss: 2.4270176887512207
Validation loss: 2.0589677890141806

Epoch: 6| Step: 7
Training loss: 2.8937010765075684
Validation loss: 2.0837328972355014

Epoch: 6| Step: 8
Training loss: 2.0583136081695557
Validation loss: 2.074714611935359

Epoch: 6| Step: 9
Training loss: 2.657336950302124
Validation loss: 2.073937685258927

Epoch: 6| Step: 10
Training loss: 1.964677333831787
Validation loss: 2.064294945809149

Epoch: 6| Step: 11
Training loss: 2.529566764831543
Validation loss: 2.082510809744558

Epoch: 6| Step: 12
Training loss: 2.3526060581207275
Validation loss: 2.056379915565573

Epoch: 6| Step: 13
Training loss: 1.415104627609253
Validation loss: 2.0632524849266134

Epoch: 27| Step: 0
Training loss: 2.5630359649658203
Validation loss: 2.061903574133432

Epoch: 6| Step: 1
Training loss: 3.025120735168457
Validation loss: 2.0675733063810613

Epoch: 6| Step: 2
Training loss: 2.2768216133117676
Validation loss: 2.0649529733965473

Epoch: 6| Step: 3
Training loss: 2.695805549621582
Validation loss: 2.0646691373599473

Epoch: 6| Step: 4
Training loss: 2.2850160598754883
Validation loss: 2.044347516952022

Epoch: 6| Step: 5
Training loss: 2.956219434738159
Validation loss: 2.040818243898371

Epoch: 6| Step: 6
Training loss: 2.07357120513916
Validation loss: 2.0562614138408373

Epoch: 6| Step: 7
Training loss: 1.962032675743103
Validation loss: 2.0790182980157996

Epoch: 6| Step: 8
Training loss: 2.320734739303589
Validation loss: 2.0813484768713675

Epoch: 6| Step: 9
Training loss: 2.3564453125
Validation loss: 2.074742014690112

Epoch: 6| Step: 10
Training loss: 2.415431261062622
Validation loss: 2.080066288671186

Epoch: 6| Step: 11
Training loss: 2.397587776184082
Validation loss: 2.0732281874584895

Epoch: 6| Step: 12
Training loss: 2.4333841800689697
Validation loss: 2.0905547359938264

Epoch: 6| Step: 13
Training loss: 1.941026210784912
Validation loss: 2.071877541080598

Epoch: 28| Step: 0
Training loss: 2.1017532348632812
Validation loss: 2.08083079707238

Epoch: 6| Step: 1
Training loss: 1.9381669759750366
Validation loss: 2.0713130299763014

Epoch: 6| Step: 2
Training loss: 1.8815878629684448
Validation loss: 2.0478238879993396

Epoch: 6| Step: 3
Training loss: 2.481926918029785
Validation loss: 2.0674321318185456

Epoch: 6| Step: 4
Training loss: 2.5177388191223145
Validation loss: 2.0598964114342966

Epoch: 6| Step: 5
Training loss: 2.090184450149536
Validation loss: 2.053473754595685

Epoch: 6| Step: 6
Training loss: 2.255100727081299
Validation loss: 2.070204019546509

Epoch: 6| Step: 7
Training loss: 2.6960935592651367
Validation loss: 2.066233745185278

Epoch: 6| Step: 8
Training loss: 3.069490909576416
Validation loss: 2.0400732371114914

Epoch: 6| Step: 9
Training loss: 2.480414390563965
Validation loss: 2.0628200641242405

Epoch: 6| Step: 10
Training loss: 2.4858856201171875
Validation loss: 2.0709224336890766

Epoch: 6| Step: 11
Training loss: 2.3472208976745605
Validation loss: 2.024430831273397

Epoch: 6| Step: 12
Training loss: 2.7535133361816406
Validation loss: 2.052358873428837

Epoch: 6| Step: 13
Training loss: 3.0089635848999023
Validation loss: 2.051756394806729

Epoch: 29| Step: 0
Training loss: 2.0335021018981934
Validation loss: 2.0657489402319795

Epoch: 6| Step: 1
Training loss: 2.371784210205078
Validation loss: 2.042119268448122

Epoch: 6| Step: 2
Training loss: 2.2727320194244385
Validation loss: 2.0493536751757384

Epoch: 6| Step: 3
Training loss: 2.4522342681884766
Validation loss: 2.0379200750781643

Epoch: 6| Step: 4
Training loss: 1.591507911682129
Validation loss: 2.0473259264423

Epoch: 6| Step: 5
Training loss: 2.0785605907440186
Validation loss: 2.0849025557118077

Epoch: 6| Step: 6
Training loss: 2.4198524951934814
Validation loss: 2.0294454238748036

Epoch: 6| Step: 7
Training loss: 3.6684045791625977
Validation loss: 2.037822792606969

Epoch: 6| Step: 8
Training loss: 2.9641788005828857
Validation loss: 2.0136792275213424

Epoch: 6| Step: 9
Training loss: 2.8123414516448975
Validation loss: 2.0406030480579664

Epoch: 6| Step: 10
Training loss: 2.4319183826446533
Validation loss: 2.0492391124848397

Epoch: 6| Step: 11
Training loss: 2.7388486862182617
Validation loss: 2.034175906130063

Epoch: 6| Step: 12
Training loss: 1.631103754043579
Validation loss: 2.039955691624713

Epoch: 6| Step: 13
Training loss: 2.2780628204345703
Validation loss: 2.074689357511459

Epoch: 30| Step: 0
Training loss: 2.8184080123901367
Validation loss: 2.0485260691694034

Epoch: 6| Step: 1
Training loss: 2.3451123237609863
Validation loss: 2.0349877572828725

Epoch: 6| Step: 2
Training loss: 2.7486484050750732
Validation loss: 2.0516672749673166

Epoch: 6| Step: 3
Training loss: 2.840114116668701
Validation loss: 2.0534172634924612

Epoch: 6| Step: 4
Training loss: 2.666719913482666
Validation loss: 2.0735681928614134

Epoch: 6| Step: 5
Training loss: 2.2535717487335205
Validation loss: 2.0525658669010287

Epoch: 6| Step: 6
Training loss: 2.402420997619629
Validation loss: 2.0749372269517634

Epoch: 6| Step: 7
Training loss: 1.816479206085205
Validation loss: 2.0734343195474274

Epoch: 6| Step: 8
Training loss: 2.2747128009796143
Validation loss: 2.0619041560798563

Epoch: 6| Step: 9
Training loss: 1.9844615459442139
Validation loss: 2.0588009177997546

Epoch: 6| Step: 10
Training loss: 2.7548294067382812
Validation loss: 2.066973372172284

Epoch: 6| Step: 11
Training loss: 3.0401480197906494
Validation loss: 2.04437336614055

Epoch: 6| Step: 12
Training loss: 1.8205255270004272
Validation loss: 2.05316129807503

Epoch: 6| Step: 13
Training loss: 1.8345979452133179
Validation loss: 2.0673566402927523

Epoch: 31| Step: 0
Training loss: 2.5629305839538574
Validation loss: 2.0689176615848335

Epoch: 6| Step: 1
Training loss: 2.2488319873809814
Validation loss: 2.0687259794563375

Epoch: 6| Step: 2
Training loss: 2.135984420776367
Validation loss: 2.0559049985742055

Epoch: 6| Step: 3
Training loss: 2.646451234817505
Validation loss: 2.0836376464495094

Epoch: 6| Step: 4
Training loss: 2.784587860107422
Validation loss: 2.0754746442200034

Epoch: 6| Step: 5
Training loss: 2.208955764770508
Validation loss: 2.079459265996051

Epoch: 6| Step: 6
Training loss: 2.567838191986084
Validation loss: 2.06449096433578

Epoch: 6| Step: 7
Training loss: 2.490504741668701
Validation loss: 2.0566792513734553

Epoch: 6| Step: 8
Training loss: 2.315741539001465
Validation loss: 2.0714088152813654

Epoch: 6| Step: 9
Training loss: 3.131990432739258
Validation loss: 2.0488631853493313

Epoch: 6| Step: 10
Training loss: 2.2208120822906494
Validation loss: 2.0636265739317863

Epoch: 6| Step: 11
Training loss: 2.592869520187378
Validation loss: 2.069837486872109

Epoch: 6| Step: 12
Training loss: 2.0549821853637695
Validation loss: 2.0581596948767222

Epoch: 6| Step: 13
Training loss: 1.1906206607818604
Validation loss: 2.0525806027074016

Epoch: 32| Step: 0
Training loss: 2.581798553466797
Validation loss: 2.0604438269010155

Epoch: 6| Step: 1
Training loss: 2.0594983100891113
Validation loss: 2.042651237980012

Epoch: 6| Step: 2
Training loss: 2.398171901702881
Validation loss: 2.0710534344437304

Epoch: 6| Step: 3
Training loss: 2.0331170558929443
Validation loss: 2.078986014089277

Epoch: 6| Step: 4
Training loss: 2.2611308097839355
Validation loss: 2.0592994049031246

Epoch: 6| Step: 5
Training loss: 2.5917513370513916
Validation loss: 2.054010614272087

Epoch: 6| Step: 6
Training loss: 2.2386019229888916
Validation loss: 2.0621885612446773

Epoch: 6| Step: 7
Training loss: 2.9938888549804688
Validation loss: 2.0866941598153885

Epoch: 6| Step: 8
Training loss: 2.322812557220459
Validation loss: 2.0817041397094727

Epoch: 6| Step: 9
Training loss: 2.1013436317443848
Validation loss: 2.0453927081118346

Epoch: 6| Step: 10
Training loss: 2.676898241043091
Validation loss: 2.063558247781569

Epoch: 6| Step: 11
Training loss: 2.5410237312316895
Validation loss: 2.062704840014058

Epoch: 6| Step: 12
Training loss: 2.535674571990967
Validation loss: 2.069258297643354

Epoch: 6| Step: 13
Training loss: 2.088012218475342
Validation loss: 2.066370597449682

Epoch: 33| Step: 0
Training loss: 2.294405221939087
Validation loss: 2.0642566937272266

Epoch: 6| Step: 1
Training loss: 2.7384023666381836
Validation loss: 2.0644215768383396

Epoch: 6| Step: 2
Training loss: 1.4380139112472534
Validation loss: 2.0579445208272626

Epoch: 6| Step: 3
Training loss: 2.675373077392578
Validation loss: 2.0593292200437157

Epoch: 6| Step: 4
Training loss: 2.2501635551452637
Validation loss: 2.0564747138689925

Epoch: 6| Step: 5
Training loss: 2.4080610275268555
Validation loss: 2.0756861009905414

Epoch: 6| Step: 6
Training loss: 1.6323655843734741
Validation loss: 2.0503916407144196

Epoch: 6| Step: 7
Training loss: 2.378201961517334
Validation loss: 2.0605186467529624

Epoch: 6| Step: 8
Training loss: 2.0022623538970947
Validation loss: 2.039530537461722

Epoch: 6| Step: 9
Training loss: 3.0541605949401855
Validation loss: 2.049357932101014

Epoch: 6| Step: 10
Training loss: 2.2074027061462402
Validation loss: 2.036907216554047

Epoch: 6| Step: 11
Training loss: 2.6657919883728027
Validation loss: 2.060191901781226

Epoch: 6| Step: 12
Training loss: 3.5096559524536133
Validation loss: 2.0526769366315616

Epoch: 6| Step: 13
Training loss: 2.0193991661071777
Validation loss: 2.062793964980751

Epoch: 34| Step: 0
Training loss: 2.2020609378814697
Validation loss: 2.0253829494599374

Epoch: 6| Step: 1
Training loss: 2.2191643714904785
Validation loss: 2.043586754029797

Epoch: 6| Step: 2
Training loss: 1.8746564388275146
Validation loss: 2.05184075396548

Epoch: 6| Step: 3
Training loss: 2.220919370651245
Validation loss: 2.0630944262268724

Epoch: 6| Step: 4
Training loss: 2.2060370445251465
Validation loss: 2.044458004736131

Epoch: 6| Step: 5
Training loss: 2.5807061195373535
Validation loss: 2.033482656683973

Epoch: 6| Step: 6
Training loss: 2.42059326171875
Validation loss: 2.016925078566356

Epoch: 6| Step: 7
Training loss: 2.843217372894287
Validation loss: 2.0273516383222354

Epoch: 6| Step: 8
Training loss: 2.232889175415039
Validation loss: 2.051599992218838

Epoch: 6| Step: 9
Training loss: 2.554455518722534
Validation loss: 2.0553606299943823

Epoch: 6| Step: 10
Training loss: 2.5095765590667725
Validation loss: 2.0529284541324904

Epoch: 6| Step: 11
Training loss: 2.7597246170043945
Validation loss: 2.0590953160357732

Epoch: 6| Step: 12
Training loss: 2.630239725112915
Validation loss: 2.05181666984353

Epoch: 6| Step: 13
Training loss: 2.2525417804718018
Validation loss: 2.0288914480516986

Epoch: 35| Step: 0
Training loss: 2.46759033203125
Validation loss: 2.0255999142123806

Epoch: 6| Step: 1
Training loss: 2.072357654571533
Validation loss: 2.049730505994571

Epoch: 6| Step: 2
Training loss: 1.7916678190231323
Validation loss: 2.047973800730962

Epoch: 6| Step: 3
Training loss: 2.2806382179260254
Validation loss: 2.046828539140763

Epoch: 6| Step: 4
Training loss: 2.238449811935425
Validation loss: 2.0345865347052134

Epoch: 6| Step: 5
Training loss: 2.5458099842071533
Validation loss: 2.0508398176521383

Epoch: 6| Step: 6
Training loss: 2.4216413497924805
Validation loss: 2.0137891397681287

Epoch: 6| Step: 7
Training loss: 2.2286195755004883
Validation loss: 2.055456180726328

Epoch: 6| Step: 8
Training loss: 2.5562987327575684
Validation loss: 2.048124913246401

Epoch: 6| Step: 9
Training loss: 2.473918914794922
Validation loss: 2.069281265299807

Epoch: 6| Step: 10
Training loss: 2.627558708190918
Validation loss: 2.045455471161873

Epoch: 6| Step: 11
Training loss: 2.8329508304595947
Validation loss: 2.0347536968928512

Epoch: 6| Step: 12
Training loss: 3.0458381175994873
Validation loss: 2.055580590360908

Epoch: 6| Step: 13
Training loss: 1.814368724822998
Validation loss: 2.0497138384849793

Epoch: 36| Step: 0
Training loss: 2.1969306468963623
Validation loss: 2.0290610944071124

Epoch: 6| Step: 1
Training loss: 2.312828540802002
Validation loss: 2.0446479602526595

Epoch: 6| Step: 2
Training loss: 2.753053665161133
Validation loss: 2.059145786428964

Epoch: 6| Step: 3
Training loss: 2.3939645290374756
Validation loss: 2.0648714009151665

Epoch: 6| Step: 4
Training loss: 1.8481152057647705
Validation loss: 2.0183043249191774

Epoch: 6| Step: 5
Training loss: 3.072175979614258
Validation loss: 2.036716341972351

Epoch: 6| Step: 6
Training loss: 3.2329764366149902
Validation loss: 2.0416790439236547

Epoch: 6| Step: 7
Training loss: 2.1834168434143066
Validation loss: 2.0369246493103685

Epoch: 6| Step: 8
Training loss: 2.5141468048095703
Validation loss: 2.034144724569013

Epoch: 6| Step: 9
Training loss: 2.0634186267852783
Validation loss: 2.0274090869452364

Epoch: 6| Step: 10
Training loss: 2.723263740539551
Validation loss: 2.020968467958512

Epoch: 6| Step: 11
Training loss: 1.072069764137268
Validation loss: 2.024029786868762

Epoch: 6| Step: 12
Training loss: 2.727322578430176
Validation loss: 2.0198221719393166

Epoch: 6| Step: 13
Training loss: 2.7800092697143555
Validation loss: 2.017718658652357

Epoch: 37| Step: 0
Training loss: 1.9687111377716064
Validation loss: 2.0528373231169996

Epoch: 6| Step: 1
Training loss: 2.796598434448242
Validation loss: 2.0370050681534635

Epoch: 6| Step: 2
Training loss: 1.9330801963806152
Validation loss: 2.0466311926482827

Epoch: 6| Step: 3
Training loss: 2.575235366821289
Validation loss: 2.0478166867327947

Epoch: 6| Step: 4
Training loss: 1.951721429824829
Validation loss: 2.059812617558305

Epoch: 6| Step: 5
Training loss: 2.131588935852051
Validation loss: 2.0215977981526363

Epoch: 6| Step: 6
Training loss: 3.2738659381866455
Validation loss: 2.038426688922349

Epoch: 6| Step: 7
Training loss: 1.8656600713729858
Validation loss: 2.0162756263568835

Epoch: 6| Step: 8
Training loss: 2.1206369400024414
Validation loss: 2.0446336679561163

Epoch: 6| Step: 9
Training loss: 2.9416089057922363
Validation loss: 2.0521023709286927

Epoch: 6| Step: 10
Training loss: 1.9341211318969727
Validation loss: 2.032031128483434

Epoch: 6| Step: 11
Training loss: 2.8061792850494385
Validation loss: 2.0310901288063294

Epoch: 6| Step: 12
Training loss: 2.7446794509887695
Validation loss: 2.0223747555927565

Epoch: 6| Step: 13
Training loss: 2.162038564682007
Validation loss: 2.0306945052198184

Epoch: 38| Step: 0
Training loss: 2.613010883331299
Validation loss: 2.048137177703201

Epoch: 6| Step: 1
Training loss: 2.299656867980957
Validation loss: 2.0473619955842213

Epoch: 6| Step: 2
Training loss: 2.8542892932891846
Validation loss: 2.0490648131216727

Epoch: 6| Step: 3
Training loss: 2.112666130065918
Validation loss: 2.06666612368758

Epoch: 6| Step: 4
Training loss: 2.37970232963562
Validation loss: 2.047418244423405

Epoch: 6| Step: 5
Training loss: 2.5857203006744385
Validation loss: 2.0494037161591234

Epoch: 6| Step: 6
Training loss: 2.062758445739746
Validation loss: 2.033862293407481

Epoch: 6| Step: 7
Training loss: 2.5955023765563965
Validation loss: 2.0438354105077763

Epoch: 6| Step: 8
Training loss: 2.7948389053344727
Validation loss: 2.050014567631547

Epoch: 6| Step: 9
Training loss: 2.636950969696045
Validation loss: 2.0425029980239047

Epoch: 6| Step: 10
Training loss: 1.8547601699829102
Validation loss: 2.0408899514905867

Epoch: 6| Step: 11
Training loss: 2.000979423522949
Validation loss: 2.029161032810006

Epoch: 6| Step: 12
Training loss: 2.19992733001709
Validation loss: 2.0551530802121727

Epoch: 6| Step: 13
Training loss: 2.188999652862549
Validation loss: 2.0512273619251866

Epoch: 39| Step: 0
Training loss: 2.3170995712280273
Validation loss: 2.029438441799533

Epoch: 6| Step: 1
Training loss: 2.3449199199676514
Validation loss: 2.0337412485512356

Epoch: 6| Step: 2
Training loss: 2.049001455307007
Validation loss: 2.0558932481273526

Epoch: 6| Step: 3
Training loss: 2.1880698204040527
Validation loss: 2.030619708440637

Epoch: 6| Step: 4
Training loss: 2.2639195919036865
Validation loss: 2.046887943821569

Epoch: 6| Step: 5
Training loss: 2.3917930126190186
Validation loss: 2.0254345132458593

Epoch: 6| Step: 6
Training loss: 2.741090774536133
Validation loss: 2.0172595465055077

Epoch: 6| Step: 7
Training loss: 2.394163131713867
Validation loss: 2.036516671539635

Epoch: 6| Step: 8
Training loss: 2.796314001083374
Validation loss: 2.02620013811255

Epoch: 6| Step: 9
Training loss: 2.616719961166382
Validation loss: 2.0040026262242305

Epoch: 6| Step: 10
Training loss: 2.300487756729126
Validation loss: 2.040210271394381

Epoch: 6| Step: 11
Training loss: 2.0805823802948
Validation loss: 2.0496684402547856

Epoch: 6| Step: 12
Training loss: 2.548121929168701
Validation loss: 2.0358422904886226

Epoch: 6| Step: 13
Training loss: 2.050828456878662
Validation loss: 2.022620274815508

Epoch: 40| Step: 0
Training loss: 2.2081403732299805
Validation loss: 2.053773392913162

Epoch: 6| Step: 1
Training loss: 1.797675371170044
Validation loss: 2.037242188248583

Epoch: 6| Step: 2
Training loss: 2.357950210571289
Validation loss: 2.0314630359731694

Epoch: 6| Step: 3
Training loss: 2.4544215202331543
Validation loss: 2.02682739175776

Epoch: 6| Step: 4
Training loss: 2.329629421234131
Validation loss: 2.021640487896499

Epoch: 6| Step: 5
Training loss: 1.643364429473877
Validation loss: 2.03467123739181

Epoch: 6| Step: 6
Training loss: 2.6340415477752686
Validation loss: 2.0587247225546066

Epoch: 6| Step: 7
Training loss: 2.5561211109161377
Validation loss: 2.0345703235236545

Epoch: 6| Step: 8
Training loss: 2.88077974319458
Validation loss: 2.0178606202525478

Epoch: 6| Step: 9
Training loss: 2.6261181831359863
Validation loss: 2.0498874854016047

Epoch: 6| Step: 10
Training loss: 2.497438430786133
Validation loss: 2.0410338729940434

Epoch: 6| Step: 11
Training loss: 1.2968932390213013
Validation loss: 2.043170946900563

Epoch: 6| Step: 12
Training loss: 2.906604528427124
Validation loss: 2.0101548125666957

Epoch: 6| Step: 13
Training loss: 3.430769920349121
Validation loss: 2.038855657782606

Epoch: 41| Step: 0
Training loss: 1.7105519771575928
Validation loss: 2.046990704792802

Epoch: 6| Step: 1
Training loss: 2.971602201461792
Validation loss: 2.0453864951287546

Epoch: 6| Step: 2
Training loss: 2.491156578063965
Validation loss: 2.0416499696752077

Epoch: 6| Step: 3
Training loss: 1.733213186264038
Validation loss: 2.0438980389666814

Epoch: 6| Step: 4
Training loss: 2.523590564727783
Validation loss: 2.0379560993563746

Epoch: 6| Step: 5
Training loss: 2.42431640625
Validation loss: 2.028772150316546

Epoch: 6| Step: 6
Training loss: 2.0437331199645996
Validation loss: 2.049885863898903

Epoch: 6| Step: 7
Training loss: 2.806439161300659
Validation loss: 2.039725452341059

Epoch: 6| Step: 8
Training loss: 2.850747585296631
Validation loss: 2.0373728608572357

Epoch: 6| Step: 9
Training loss: 1.9222091436386108
Validation loss: 2.0485564585654967

Epoch: 6| Step: 10
Training loss: 1.9356982707977295
Validation loss: 2.036060820343674

Epoch: 6| Step: 11
Training loss: 3.1095590591430664
Validation loss: 2.0163495720073743

Epoch: 6| Step: 12
Training loss: 2.3017830848693848
Validation loss: 2.0355691166334253

Epoch: 6| Step: 13
Training loss: 2.2362260818481445
Validation loss: 2.0228470166524253

Epoch: 42| Step: 0
Training loss: 2.425919532775879
Validation loss: 2.034147790683213

Epoch: 6| Step: 1
Training loss: 1.6543197631835938
Validation loss: 2.0299723891801733

Epoch: 6| Step: 2
Training loss: 2.122175693511963
Validation loss: 2.0208844869367537

Epoch: 6| Step: 3
Training loss: 1.7849500179290771
Validation loss: 2.0093586150036065

Epoch: 6| Step: 4
Training loss: 2.8594555854797363
Validation loss: 2.0332769629775838

Epoch: 6| Step: 5
Training loss: 1.5853540897369385
Validation loss: 2.032935884691054

Epoch: 6| Step: 6
Training loss: 2.011507987976074
Validation loss: 2.028883457183838

Epoch: 6| Step: 7
Training loss: 2.481154441833496
Validation loss: 2.0621796064479376

Epoch: 6| Step: 8
Training loss: 3.1121630668640137
Validation loss: 2.0295928268022436

Epoch: 6| Step: 9
Training loss: 2.375562906265259
Validation loss: 2.041744074513835

Epoch: 6| Step: 10
Training loss: 3.114424228668213
Validation loss: 2.025466647199405

Epoch: 6| Step: 11
Training loss: 2.3498783111572266
Validation loss: 2.0344976250843336

Epoch: 6| Step: 12
Training loss: 2.0836076736450195
Validation loss: 2.022299833195184

Epoch: 6| Step: 13
Training loss: 3.2581255435943604
Validation loss: 2.0473248830405613

Epoch: 43| Step: 0
Training loss: 2.4446849822998047
Validation loss: 2.0220106058223273

Epoch: 6| Step: 1
Training loss: 2.0406806468963623
Validation loss: 2.0125425131090227

Epoch: 6| Step: 2
Training loss: 2.8381118774414062
Validation loss: 2.047633385145536

Epoch: 6| Step: 3
Training loss: 2.777691125869751
Validation loss: 2.0315156508517522

Epoch: 6| Step: 4
Training loss: 2.450212001800537
Validation loss: 2.0300295904118526

Epoch: 6| Step: 5
Training loss: 1.6506922245025635
Validation loss: 2.035962084288238

Epoch: 6| Step: 6
Training loss: 1.5223422050476074
Validation loss: 2.050742918445218

Epoch: 6| Step: 7
Training loss: 2.8076491355895996
Validation loss: 2.0344178022876864

Epoch: 6| Step: 8
Training loss: 2.4602880477905273
Validation loss: 2.0317242196811143

Epoch: 6| Step: 9
Training loss: 2.6629912853240967
Validation loss: 2.0114098966762586

Epoch: 6| Step: 10
Training loss: 2.8002634048461914
Validation loss: 2.044206932026853

Epoch: 6| Step: 11
Training loss: 2.4476478099823
Validation loss: 2.0457807305038616

Epoch: 6| Step: 12
Training loss: 1.3785507678985596
Validation loss: 2.039189470711575

Epoch: 6| Step: 13
Training loss: 2.735403537750244
Validation loss: 2.0252893522221553

Epoch: 44| Step: 0
Training loss: 1.8343329429626465
Validation loss: 2.0465496163214407

Epoch: 6| Step: 1
Training loss: 2.412128448486328
Validation loss: 2.040374778932141

Epoch: 6| Step: 2
Training loss: 2.3224170207977295
Validation loss: 2.050661620273385

Epoch: 6| Step: 3
Training loss: 2.201061725616455
Validation loss: 2.030581283312972

Epoch: 6| Step: 4
Training loss: 2.110431432723999
Validation loss: 2.005135570802996

Epoch: 6| Step: 5
Training loss: 2.00529146194458
Validation loss: 2.0273215450266355

Epoch: 6| Step: 6
Training loss: 2.538604974746704
Validation loss: 2.030849108131983

Epoch: 6| Step: 7
Training loss: 2.411421775817871
Validation loss: 2.026207777761644

Epoch: 6| Step: 8
Training loss: 2.044149875640869
Validation loss: 2.0308316625574583

Epoch: 6| Step: 9
Training loss: 2.69185209274292
Validation loss: 2.0289750278636975

Epoch: 6| Step: 10
Training loss: 2.7125437259674072
Validation loss: 2.022695328599663

Epoch: 6| Step: 11
Training loss: 2.02923846244812
Validation loss: 2.033946862784765

Epoch: 6| Step: 12
Training loss: 2.643918514251709
Validation loss: 2.0407596993189987

Epoch: 6| Step: 13
Training loss: 3.377204418182373
Validation loss: 2.013328259991061

Epoch: 45| Step: 0
Training loss: 1.3841032981872559
Validation loss: 2.0535214601024503

Epoch: 6| Step: 1
Training loss: 2.494744300842285
Validation loss: 2.0408500497059157

Epoch: 6| Step: 2
Training loss: 2.0103273391723633
Validation loss: 2.0266101193684403

Epoch: 6| Step: 3
Training loss: 2.369861125946045
Validation loss: 2.0190605886520876

Epoch: 6| Step: 4
Training loss: 1.9300832748413086
Validation loss: 2.02665437036945

Epoch: 6| Step: 5
Training loss: 2.6778721809387207
Validation loss: 2.0320715596598964

Epoch: 6| Step: 6
Training loss: 2.5166516304016113
Validation loss: 2.006568638227319

Epoch: 6| Step: 7
Training loss: 2.8060524463653564
Validation loss: 2.040107757814469

Epoch: 6| Step: 8
Training loss: 2.6651198863983154
Validation loss: 2.0131363996895413

Epoch: 6| Step: 9
Training loss: 2.207418441772461
Validation loss: 2.001896881288098

Epoch: 6| Step: 10
Training loss: 2.708448648452759
Validation loss: 2.0141602716138287

Epoch: 6| Step: 11
Training loss: 2.495636463165283
Validation loss: 2.0191667618290072

Epoch: 6| Step: 12
Training loss: 2.1536898612976074
Validation loss: 2.0165993949418426

Epoch: 6| Step: 13
Training loss: 2.8373537063598633
Validation loss: 2.023809245837632

Epoch: 46| Step: 0
Training loss: 1.8708412647247314
Validation loss: 2.0115186181119693

Epoch: 6| Step: 1
Training loss: 2.281351089477539
Validation loss: 2.0249118548567577

Epoch: 6| Step: 2
Training loss: 2.199662685394287
Validation loss: 2.028898572409025

Epoch: 6| Step: 3
Training loss: 2.677638053894043
Validation loss: 2.028471087896696

Epoch: 6| Step: 4
Training loss: 1.985536813735962
Validation loss: 2.021940428723571

Epoch: 6| Step: 5
Training loss: 2.3536033630371094
Validation loss: 2.02853972424743

Epoch: 6| Step: 6
Training loss: 2.5405452251434326
Validation loss: 2.00721396938447

Epoch: 6| Step: 7
Training loss: 2.8700919151306152
Validation loss: 2.015985914455947

Epoch: 6| Step: 8
Training loss: 2.590559959411621
Validation loss: 2.038470091358308

Epoch: 6| Step: 9
Training loss: 2.576742649078369
Validation loss: 2.03911695941802

Epoch: 6| Step: 10
Training loss: 1.662698745727539
Validation loss: 2.0526483033293035

Epoch: 6| Step: 11
Training loss: 2.253643035888672
Validation loss: 2.047929044692747

Epoch: 6| Step: 12
Training loss: 2.0954031944274902
Validation loss: 2.022377719161331

Epoch: 6| Step: 13
Training loss: 3.1384198665618896
Validation loss: 2.0197709068175285

Epoch: 47| Step: 0
Training loss: 1.9576637744903564
Validation loss: 2.023542352901992

Epoch: 6| Step: 1
Training loss: 2.7011356353759766
Validation loss: 2.02480830941149

Epoch: 6| Step: 2
Training loss: 2.49564266204834
Validation loss: 2.031591474369008

Epoch: 6| Step: 3
Training loss: 1.7304377555847168
Validation loss: 2.0354036233758412

Epoch: 6| Step: 4
Training loss: 1.8041709661483765
Validation loss: 2.0200634425686252

Epoch: 6| Step: 5
Training loss: 2.5360841751098633
Validation loss: 2.039789092156195

Epoch: 6| Step: 6
Training loss: 1.55588698387146
Validation loss: 2.0384099304035144

Epoch: 6| Step: 7
Training loss: 2.9213619232177734
Validation loss: 2.037623454165715

Epoch: 6| Step: 8
Training loss: 2.09597110748291
Validation loss: 2.033485315179312

Epoch: 6| Step: 9
Training loss: 3.1564626693725586
Validation loss: 2.0180145937909364

Epoch: 6| Step: 10
Training loss: 2.001903533935547
Validation loss: 2.03152677705211

Epoch: 6| Step: 11
Training loss: 2.7349987030029297
Validation loss: 2.0459033084172074

Epoch: 6| Step: 12
Training loss: 2.420297622680664
Validation loss: 2.0535138371170207

Epoch: 6| Step: 13
Training loss: 2.816530227661133
Validation loss: 2.035703370648046

Epoch: 48| Step: 0
Training loss: 2.756357192993164
Validation loss: 2.023192213427636

Epoch: 6| Step: 1
Training loss: 1.9408149719238281
Validation loss: 2.052157905793959

Epoch: 6| Step: 2
Training loss: 2.8070504665374756
Validation loss: 2.0259124784059424

Epoch: 6| Step: 3
Training loss: 2.5211215019226074
Validation loss: 2.0120989943063385

Epoch: 6| Step: 4
Training loss: 2.299375295639038
Validation loss: 2.0276993500289096

Epoch: 6| Step: 5
Training loss: 1.829750418663025
Validation loss: 2.0385401736023607

Epoch: 6| Step: 6
Training loss: 2.1029534339904785
Validation loss: 2.052274875743415

Epoch: 6| Step: 7
Training loss: 2.76465106010437
Validation loss: 2.042103749449535

Epoch: 6| Step: 8
Training loss: 2.495622158050537
Validation loss: 2.0402336248787503

Epoch: 6| Step: 9
Training loss: 2.167818307876587
Validation loss: 2.01954149687162

Epoch: 6| Step: 10
Training loss: 1.573347568511963
Validation loss: 2.035432989879321

Epoch: 6| Step: 11
Training loss: 2.674851894378662
Validation loss: 2.0312089945680354

Epoch: 6| Step: 12
Training loss: 2.1622540950775146
Validation loss: 2.0326465663089546

Epoch: 6| Step: 13
Training loss: 2.87551212310791
Validation loss: 2.0175719389351467

Epoch: 49| Step: 0
Training loss: 2.161104202270508
Validation loss: 2.0423633103729575

Epoch: 6| Step: 1
Training loss: 2.6297645568847656
Validation loss: 1.998667565725183

Epoch: 6| Step: 2
Training loss: 1.8838648796081543
Validation loss: 2.0164299908504693

Epoch: 6| Step: 3
Training loss: 2.3259024620056152
Validation loss: 2.0172217020424466

Epoch: 6| Step: 4
Training loss: 2.4078688621520996
Validation loss: 1.991713434137324

Epoch: 6| Step: 5
Training loss: 3.828223705291748
Validation loss: 2.0185306636236047

Epoch: 6| Step: 6
Training loss: 2.1783056259155273
Validation loss: 1.996278965344993

Epoch: 6| Step: 7
Training loss: 2.1698217391967773
Validation loss: 2.026155869166056

Epoch: 6| Step: 8
Training loss: 1.8161643743515015
Validation loss: 2.034973403458954

Epoch: 6| Step: 9
Training loss: 2.412130832672119
Validation loss: 2.0040170710573912

Epoch: 6| Step: 10
Training loss: 2.5564980506896973
Validation loss: 2.0036433204527824

Epoch: 6| Step: 11
Training loss: 1.8952319622039795
Validation loss: 1.9890306867578977

Epoch: 6| Step: 12
Training loss: 2.210055351257324
Validation loss: 2.021334332804526

Epoch: 6| Step: 13
Training loss: 2.1276698112487793
Validation loss: 2.008775705932289

Epoch: 50| Step: 0
Training loss: 2.416238307952881
Validation loss: 2.0329382957950717

Epoch: 6| Step: 1
Training loss: 2.3263278007507324
Validation loss: 2.0127779642740884

Epoch: 6| Step: 2
Training loss: 2.6615638732910156
Validation loss: 2.01706124121143

Epoch: 6| Step: 3
Training loss: 2.410922050476074
Validation loss: 2.0121313974421513

Epoch: 6| Step: 4
Training loss: 2.086693286895752
Validation loss: 2.0046861222995225

Epoch: 6| Step: 5
Training loss: 2.6344847679138184
Validation loss: 2.0320454515436643

Epoch: 6| Step: 6
Training loss: 2.2572531700134277
Validation loss: 1.9793639670136154

Epoch: 6| Step: 7
Training loss: 2.213087320327759
Validation loss: 2.0200644603339573

Epoch: 6| Step: 8
Training loss: 1.900583028793335
Validation loss: 2.0046349866415865

Epoch: 6| Step: 9
Training loss: 2.3588175773620605
Validation loss: 1.9871552605782785

Epoch: 6| Step: 10
Training loss: 2.559985876083374
Validation loss: 1.9892978514394453

Epoch: 6| Step: 11
Training loss: 1.7270795106887817
Validation loss: 1.9906591061622865

Epoch: 6| Step: 12
Training loss: 2.679361343383789
Validation loss: 1.9951928533533567

Epoch: 6| Step: 13
Training loss: 2.607346296310425
Validation loss: 1.9905784489006124

Epoch: 51| Step: 0
Training loss: 2.1429405212402344
Validation loss: 2.025685046308784

Epoch: 6| Step: 1
Training loss: 1.7845537662506104
Validation loss: 2.000260711998068

Epoch: 6| Step: 2
Training loss: 2.203902006149292
Validation loss: 2.0044753577119563

Epoch: 6| Step: 3
Training loss: 2.027442455291748
Validation loss: 1.9948982897625174

Epoch: 6| Step: 4
Training loss: 2.2173662185668945
Validation loss: 1.9979683468418736

Epoch: 6| Step: 5
Training loss: 2.5204689502716064
Validation loss: 2.0033764236716816

Epoch: 6| Step: 6
Training loss: 2.3855395317077637
Validation loss: 2.006006207517398

Epoch: 6| Step: 7
Training loss: 2.4943454265594482
Validation loss: 1.9955916737997403

Epoch: 6| Step: 8
Training loss: 2.0916476249694824
Validation loss: 1.998333707932503

Epoch: 6| Step: 9
Training loss: 2.9133739471435547
Validation loss: 2.014446889200518

Epoch: 6| Step: 10
Training loss: 2.9415345191955566
Validation loss: 2.001651408851788

Epoch: 6| Step: 11
Training loss: 1.782871961593628
Validation loss: 2.0013555672860917

Epoch: 6| Step: 12
Training loss: 2.3136940002441406
Validation loss: 1.9979934974383282

Epoch: 6| Step: 13
Training loss: 3.027904748916626
Validation loss: 1.9997005129373202

Epoch: 52| Step: 0
Training loss: 2.0449330806732178
Validation loss: 2.0006862801890217

Epoch: 6| Step: 1
Training loss: 2.4263522624969482
Validation loss: 1.9916872452664118

Epoch: 6| Step: 2
Training loss: 2.412524461746216
Validation loss: 2.0084549560341785

Epoch: 6| Step: 3
Training loss: 2.68294095993042
Validation loss: 2.0171116270044798

Epoch: 6| Step: 4
Training loss: 1.9025076627731323
Validation loss: 2.0157012862543904

Epoch: 6| Step: 5
Training loss: 1.9924352169036865
Validation loss: 1.9957853555679321

Epoch: 6| Step: 6
Training loss: 2.7043800354003906
Validation loss: 2.0138744718285015

Epoch: 6| Step: 7
Training loss: 2.784743309020996
Validation loss: 1.9688806533813477

Epoch: 6| Step: 8
Training loss: 2.326495885848999
Validation loss: 2.0141583335015083

Epoch: 6| Step: 9
Training loss: 2.4067959785461426
Validation loss: 1.9988171797926708

Epoch: 6| Step: 10
Training loss: 1.829310655593872
Validation loss: 1.9861423725722938

Epoch: 6| Step: 11
Training loss: 2.4895291328430176
Validation loss: 2.0072663291808097

Epoch: 6| Step: 12
Training loss: 1.7888903617858887
Validation loss: 2.0158199225702593

Epoch: 6| Step: 13
Training loss: 2.4226205348968506
Validation loss: 2.0063496174350863

Epoch: 53| Step: 0
Training loss: 2.1082091331481934
Validation loss: 1.997203291103404

Epoch: 6| Step: 1
Training loss: 2.0672974586486816
Validation loss: 2.0212481714064077

Epoch: 6| Step: 2
Training loss: 2.637532949447632
Validation loss: 2.01950599685792

Epoch: 6| Step: 3
Training loss: 2.3092823028564453
Validation loss: 1.9981190953203427

Epoch: 6| Step: 4
Training loss: 1.879464864730835
Validation loss: 2.006787674401396

Epoch: 6| Step: 5
Training loss: 2.4677536487579346
Validation loss: 2.0008631060200353

Epoch: 6| Step: 6
Training loss: 2.5796844959259033
Validation loss: 2.023191696854048

Epoch: 6| Step: 7
Training loss: 2.7819700241088867
Validation loss: 2.0265531911644885

Epoch: 6| Step: 8
Training loss: 1.893646001815796
Validation loss: 2.038558616433092

Epoch: 6| Step: 9
Training loss: 2.269855260848999
Validation loss: 2.028642133999896

Epoch: 6| Step: 10
Training loss: 2.7476305961608887
Validation loss: 2.039433886927943

Epoch: 6| Step: 11
Training loss: 1.7204184532165527
Validation loss: 2.0148118106267785

Epoch: 6| Step: 12
Training loss: 2.358933925628662
Validation loss: 2.0189169747855074

Epoch: 6| Step: 13
Training loss: 2.7019548416137695
Validation loss: 2.0187377596414215

Epoch: 54| Step: 0
Training loss: 2.3179543018341064
Validation loss: 1.9955680460058234

Epoch: 6| Step: 1
Training loss: 2.308544397354126
Validation loss: 2.0353008367682017

Epoch: 6| Step: 2
Training loss: 2.4319698810577393
Validation loss: 2.0433363004397322

Epoch: 6| Step: 3
Training loss: 2.406953811645508
Validation loss: 2.0336868045150593

Epoch: 6| Step: 4
Training loss: 2.5270605087280273
Validation loss: 2.035805079244798

Epoch: 6| Step: 5
Training loss: 1.6425435543060303
Validation loss: 2.003710364782682

Epoch: 6| Step: 6
Training loss: 2.2241718769073486
Validation loss: 2.007045166466826

Epoch: 6| Step: 7
Training loss: 3.347113609313965
Validation loss: 1.9869039879050305

Epoch: 6| Step: 8
Training loss: 2.592472791671753
Validation loss: 1.9932320143586846

Epoch: 6| Step: 9
Training loss: 3.0640175342559814
Validation loss: 2.009516413493823

Epoch: 6| Step: 10
Training loss: 2.1804864406585693
Validation loss: 2.0156966229920745

Epoch: 6| Step: 11
Training loss: 1.569534182548523
Validation loss: 2.0193950553094187

Epoch: 6| Step: 12
Training loss: 1.5140671730041504
Validation loss: 2.0073934408926193

Epoch: 6| Step: 13
Training loss: 2.6600732803344727
Validation loss: 1.9944159138587214

Epoch: 55| Step: 0
Training loss: 2.2413346767425537
Validation loss: 1.9879074737589846

Epoch: 6| Step: 1
Training loss: 2.8226146697998047
Validation loss: 2.0126503052250033

Epoch: 6| Step: 2
Training loss: 2.1651062965393066
Validation loss: 1.9774045328940115

Epoch: 6| Step: 3
Training loss: 2.1168205738067627
Validation loss: 1.9956768251234485

Epoch: 6| Step: 4
Training loss: 1.9538214206695557
Validation loss: 2.0104215196383897

Epoch: 6| Step: 5
Training loss: 2.281860828399658
Validation loss: 1.9963958776125343

Epoch: 6| Step: 6
Training loss: 2.756195068359375
Validation loss: 1.9891881276202459

Epoch: 6| Step: 7
Training loss: 1.9731261730194092
Validation loss: 1.9801611003055368

Epoch: 6| Step: 8
Training loss: 3.023444890975952
Validation loss: 2.012489470102454

Epoch: 6| Step: 9
Training loss: 2.7741315364837646
Validation loss: 1.9857049065251504

Epoch: 6| Step: 10
Training loss: 2.0722005367279053
Validation loss: 2.0082157260628155

Epoch: 6| Step: 11
Training loss: 1.9870423078536987
Validation loss: 1.9892813287755495

Epoch: 6| Step: 12
Training loss: 1.525217890739441
Validation loss: 2.0142125314281834

Epoch: 6| Step: 13
Training loss: 2.8572587966918945
Validation loss: 1.9918388256462671

Epoch: 56| Step: 0
Training loss: 1.3848741054534912
Validation loss: 1.9963647511697584

Epoch: 6| Step: 1
Training loss: 1.8791773319244385
Validation loss: 2.005199393918437

Epoch: 6| Step: 2
Training loss: 2.7371530532836914
Validation loss: 1.9946283191762946

Epoch: 6| Step: 3
Training loss: 3.0815157890319824
Validation loss: 2.010043035271347

Epoch: 6| Step: 4
Training loss: 2.0345468521118164
Validation loss: 1.974251280548752

Epoch: 6| Step: 5
Training loss: 2.033651828765869
Validation loss: 1.9888166509648806

Epoch: 6| Step: 6
Training loss: 2.427316665649414
Validation loss: 1.9874111503683112

Epoch: 6| Step: 7
Training loss: 2.205643653869629
Validation loss: 1.995880687108604

Epoch: 6| Step: 8
Training loss: 3.1018524169921875
Validation loss: 1.9861668950767928

Epoch: 6| Step: 9
Training loss: 2.127378463745117
Validation loss: 2.008449117342631

Epoch: 6| Step: 10
Training loss: 2.4081602096557617
Validation loss: 1.9819256208276237

Epoch: 6| Step: 11
Training loss: 2.741408348083496
Validation loss: 1.995236409607754

Epoch: 6| Step: 12
Training loss: 1.5512768030166626
Validation loss: 1.9827220824456984

Epoch: 6| Step: 13
Training loss: 2.585292100906372
Validation loss: 1.998622481540967

Epoch: 57| Step: 0
Training loss: 2.181657075881958
Validation loss: 2.008861695566485

Epoch: 6| Step: 1
Training loss: 2.6445999145507812
Validation loss: 2.020041245286183

Epoch: 6| Step: 2
Training loss: 2.5003459453582764
Validation loss: 2.0063985393893335

Epoch: 6| Step: 3
Training loss: 2.316147804260254
Validation loss: 1.993861093316027

Epoch: 6| Step: 4
Training loss: 1.8182554244995117
Validation loss: 1.9850656909327353

Epoch: 6| Step: 5
Training loss: 2.940397262573242
Validation loss: 1.9731193973172096

Epoch: 6| Step: 6
Training loss: 2.045900583267212
Validation loss: 1.9963598302615586

Epoch: 6| Step: 7
Training loss: 1.9326114654541016
Validation loss: 2.007580466167901

Epoch: 6| Step: 8
Training loss: 2.1867716312408447
Validation loss: 2.0012009297647784

Epoch: 6| Step: 9
Training loss: 2.515652656555176
Validation loss: 1.9905453010271954

Epoch: 6| Step: 10
Training loss: 1.4512797594070435
Validation loss: 1.998875005270845

Epoch: 6| Step: 11
Training loss: 2.4599356651306152
Validation loss: 1.988866380465928

Epoch: 6| Step: 12
Training loss: 2.9948315620422363
Validation loss: 2.0132367726295226

Epoch: 6| Step: 13
Training loss: 2.398879289627075
Validation loss: 1.9625372655930058

Epoch: 58| Step: 0
Training loss: 1.7800657749176025
Validation loss: 1.9780480579663349

Epoch: 6| Step: 1
Training loss: 1.9357973337173462
Validation loss: 1.9841327103235389

Epoch: 6| Step: 2
Training loss: 2.8391480445861816
Validation loss: 1.995121326497806

Epoch: 6| Step: 3
Training loss: 2.521975040435791
Validation loss: 2.008571602964914

Epoch: 6| Step: 4
Training loss: 2.282597780227661
Validation loss: 1.9946922845737909

Epoch: 6| Step: 5
Training loss: 2.000284194946289
Validation loss: 1.9885854964615197

Epoch: 6| Step: 6
Training loss: 1.8612536191940308
Validation loss: 2.0123019628627326

Epoch: 6| Step: 7
Training loss: 3.3020949363708496
Validation loss: 1.9778752262874315

Epoch: 6| Step: 8
Training loss: 2.3572683334350586
Validation loss: 2.0143333109476234

Epoch: 6| Step: 9
Training loss: 2.375965118408203
Validation loss: 1.9942739817403978

Epoch: 6| Step: 10
Training loss: 2.4051690101623535
Validation loss: 2.0079415229059037

Epoch: 6| Step: 11
Training loss: 2.158812999725342
Validation loss: 2.0259719164140764

Epoch: 6| Step: 12
Training loss: 2.1703543663024902
Validation loss: 2.0256296152709634

Epoch: 6| Step: 13
Training loss: 2.0317916870117188
Validation loss: 2.0021011521739345

Epoch: 59| Step: 0
Training loss: 1.9475449323654175
Validation loss: 2.0264674437943326

Epoch: 6| Step: 1
Training loss: 1.7821223735809326
Validation loss: 2.0091376842991

Epoch: 6| Step: 2
Training loss: 2.662702798843384
Validation loss: 1.9944621388630202

Epoch: 6| Step: 3
Training loss: 2.065709352493286
Validation loss: 2.0258807648894606

Epoch: 6| Step: 4
Training loss: 2.4984445571899414
Validation loss: 2.0093242455554265

Epoch: 6| Step: 5
Training loss: 2.3202686309814453
Validation loss: 2.0196967535121466

Epoch: 6| Step: 6
Training loss: 2.8239598274230957
Validation loss: 2.0093154112497964

Epoch: 6| Step: 7
Training loss: 2.052069902420044
Validation loss: 1.9970190858328214

Epoch: 6| Step: 8
Training loss: 2.5791664123535156
Validation loss: 1.9759751353212582

Epoch: 6| Step: 9
Training loss: 2.915022850036621
Validation loss: 1.99853640730663

Epoch: 6| Step: 10
Training loss: 2.1825194358825684
Validation loss: 1.9862504031068535

Epoch: 6| Step: 11
Training loss: 1.8249189853668213
Validation loss: 1.9964252723160612

Epoch: 6| Step: 12
Training loss: 1.9906429052352905
Validation loss: 1.999597680184149

Epoch: 6| Step: 13
Training loss: 2.755048990249634
Validation loss: 1.9892045092839066

Epoch: 60| Step: 0
Training loss: 1.812869668006897
Validation loss: 2.005437310023974

Epoch: 6| Step: 1
Training loss: 2.353386878967285
Validation loss: 2.0037257773901826

Epoch: 6| Step: 2
Training loss: 2.099574565887451
Validation loss: 1.9974107793582383

Epoch: 6| Step: 3
Training loss: 1.7525670528411865
Validation loss: 1.9845425287882488

Epoch: 6| Step: 4
Training loss: 2.955731153488159
Validation loss: 2.0179821368186706

Epoch: 6| Step: 5
Training loss: 2.882617950439453
Validation loss: 1.987809370922786

Epoch: 6| Step: 6
Training loss: 2.3394219875335693
Validation loss: 2.0035109109775995

Epoch: 6| Step: 7
Training loss: 2.6139941215515137
Validation loss: 2.0116336909673547

Epoch: 6| Step: 8
Training loss: 1.7603609561920166
Validation loss: 1.9984405732923938

Epoch: 6| Step: 9
Training loss: 2.3297996520996094
Validation loss: 2.0139257779685398

Epoch: 6| Step: 10
Training loss: 2.472299575805664
Validation loss: 2.0065180601612216

Epoch: 6| Step: 11
Training loss: 2.0487136840820312
Validation loss: 1.9965876776684996

Epoch: 6| Step: 12
Training loss: 2.1995599269866943
Validation loss: 2.0184053323602162

Epoch: 6| Step: 13
Training loss: 2.706812858581543
Validation loss: 2.006648660987936

Epoch: 61| Step: 0
Training loss: 2.168696403503418
Validation loss: 1.997531326868201

Epoch: 6| Step: 1
Training loss: 3.042027711868286
Validation loss: 1.9692656070955339

Epoch: 6| Step: 2
Training loss: 2.709519386291504
Validation loss: 1.9950415716376355

Epoch: 6| Step: 3
Training loss: 2.296499729156494
Validation loss: 1.9919473240452428

Epoch: 6| Step: 4
Training loss: 2.4245100021362305
Validation loss: 2.0361420351971864

Epoch: 6| Step: 5
Training loss: 1.7017202377319336
Validation loss: 1.9962687133460917

Epoch: 6| Step: 6
Training loss: 2.3055214881896973
Validation loss: 2.0059008623964045

Epoch: 6| Step: 7
Training loss: 2.4762353897094727
Validation loss: 2.019131386151878

Epoch: 6| Step: 8
Training loss: 2.235647439956665
Validation loss: 1.9947058821237216

Epoch: 6| Step: 9
Training loss: 2.523782968521118
Validation loss: 2.0081405819103284

Epoch: 6| Step: 10
Training loss: 1.8051469326019287
Validation loss: 1.9925504243502052

Epoch: 6| Step: 11
Training loss: 1.998945951461792
Validation loss: 1.969822391386955

Epoch: 6| Step: 12
Training loss: 1.7058947086334229
Validation loss: 1.9995334161225187

Epoch: 6| Step: 13
Training loss: 3.2176756858825684
Validation loss: 1.968141774977407

Epoch: 62| Step: 0
Training loss: 2.627650260925293
Validation loss: 1.9707241853078206

Epoch: 6| Step: 1
Training loss: 2.0294744968414307
Validation loss: 1.9858507546045447

Epoch: 6| Step: 2
Training loss: 2.278790235519409
Validation loss: 1.992804350391511

Epoch: 6| Step: 3
Training loss: 2.029273748397827
Validation loss: 1.9901739076901508

Epoch: 6| Step: 4
Training loss: 2.4335620403289795
Validation loss: 2.001085471081477

Epoch: 6| Step: 5
Training loss: 2.170567035675049
Validation loss: 1.9913260706009404

Epoch: 6| Step: 6
Training loss: 3.030360221862793
Validation loss: 1.978320558865865

Epoch: 6| Step: 7
Training loss: 1.5562794208526611
Validation loss: 1.9934871914566203

Epoch: 6| Step: 8
Training loss: 3.2408461570739746
Validation loss: 1.9982446188567786

Epoch: 6| Step: 9
Training loss: 2.6931204795837402
Validation loss: 1.955681549605503

Epoch: 6| Step: 10
Training loss: 1.687605857849121
Validation loss: 2.005067583053343

Epoch: 6| Step: 11
Training loss: 2.476592540740967
Validation loss: 2.008088804060413

Epoch: 6| Step: 12
Training loss: 2.042287826538086
Validation loss: 1.9915019453212779

Epoch: 6| Step: 13
Training loss: 1.4402459859848022
Validation loss: 1.9975012681817497

Epoch: 63| Step: 0
Training loss: 2.669158935546875
Validation loss: 1.9987419446309407

Epoch: 6| Step: 1
Training loss: 2.2477543354034424
Validation loss: 2.001319639144405

Epoch: 6| Step: 2
Training loss: 1.8387629985809326
Validation loss: 1.9897366031523673

Epoch: 6| Step: 3
Training loss: 2.586561918258667
Validation loss: 2.005001550079674

Epoch: 6| Step: 4
Training loss: 1.0978507995605469
Validation loss: 2.008667379297236

Epoch: 6| Step: 5
Training loss: 2.0917487144470215
Validation loss: 2.006513662235711

Epoch: 6| Step: 6
Training loss: 3.038839340209961
Validation loss: 2.0071821853678715

Epoch: 6| Step: 7
Training loss: 1.9790844917297363
Validation loss: 2.0151008585447907

Epoch: 6| Step: 8
Training loss: 2.449772596359253
Validation loss: 1.9827591552529285

Epoch: 6| Step: 9
Training loss: 2.5488922595977783
Validation loss: 1.9739077039944228

Epoch: 6| Step: 10
Training loss: 2.7349326610565186
Validation loss: 2.0039869252071587

Epoch: 6| Step: 11
Training loss: 2.263072967529297
Validation loss: 2.0107666113043345

Epoch: 6| Step: 12
Training loss: 2.339531660079956
Validation loss: 2.0224469041311615

Epoch: 6| Step: 13
Training loss: 2.345130443572998
Validation loss: 2.0192970998825563

Epoch: 64| Step: 0
Training loss: 2.1608829498291016
Validation loss: 2.0036373420428206

Epoch: 6| Step: 1
Training loss: 2.5127999782562256
Validation loss: 2.0227151557963383

Epoch: 6| Step: 2
Training loss: 2.0201616287231445
Validation loss: 2.0128257877083233

Epoch: 6| Step: 3
Training loss: 2.2997801303863525
Validation loss: 2.0162274222220145

Epoch: 6| Step: 4
Training loss: 2.4309771060943604
Validation loss: 1.9848292643024075

Epoch: 6| Step: 5
Training loss: 1.8592076301574707
Validation loss: 1.9882370656536472

Epoch: 6| Step: 6
Training loss: 1.5583467483520508
Validation loss: 1.958279496879988

Epoch: 6| Step: 7
Training loss: 2.4598774909973145
Validation loss: 2.0021667377923125

Epoch: 6| Step: 8
Training loss: 2.392821788787842
Validation loss: 1.973397607444435

Epoch: 6| Step: 9
Training loss: 3.346151113510132
Validation loss: 1.992066414125504

Epoch: 6| Step: 10
Training loss: 1.8506181240081787
Validation loss: 1.9931633421169814

Epoch: 6| Step: 11
Training loss: 2.229504346847534
Validation loss: 1.9725882007229714

Epoch: 6| Step: 12
Training loss: 2.201107978820801
Validation loss: 1.9679603089568436

Epoch: 6| Step: 13
Training loss: 3.351856231689453
Validation loss: 1.9947226483334777

Epoch: 65| Step: 0
Training loss: 1.8486257791519165
Validation loss: 2.004967713868746

Epoch: 6| Step: 1
Training loss: 1.7477550506591797
Validation loss: 1.9704548953681864

Epoch: 6| Step: 2
Training loss: 2.551683187484741
Validation loss: 1.980790966300554

Epoch: 6| Step: 3
Training loss: 3.1660256385803223
Validation loss: 2.0024750283969346

Epoch: 6| Step: 4
Training loss: 2.2624337673187256
Validation loss: 2.0097088403599237

Epoch: 6| Step: 5
Training loss: 2.833336353302002
Validation loss: 2.0029936528974965

Epoch: 6| Step: 6
Training loss: 1.8635389804840088
Validation loss: 1.9856272846139886

Epoch: 6| Step: 7
Training loss: 2.494772434234619
Validation loss: 2.0122370027726695

Epoch: 6| Step: 8
Training loss: 2.6490020751953125
Validation loss: 2.0145768478352535

Epoch: 6| Step: 9
Training loss: 2.1776440143585205
Validation loss: 2.018367939097907

Epoch: 6| Step: 10
Training loss: 2.0587234497070312
Validation loss: 2.0208749796754573

Epoch: 6| Step: 11
Training loss: 1.6500468254089355
Validation loss: 2.0274701541469944

Epoch: 6| Step: 12
Training loss: 2.5656628608703613
Validation loss: 1.9999562617271178

Epoch: 6| Step: 13
Training loss: 2.2730417251586914
Validation loss: 1.9862256665383615

Epoch: 66| Step: 0
Training loss: 2.0576114654541016
Validation loss: 1.9846564800508562

Epoch: 6| Step: 1
Training loss: 2.7905421257019043
Validation loss: 1.9992914456193165

Epoch: 6| Step: 2
Training loss: 1.4207167625427246
Validation loss: 2.01908677880482

Epoch: 6| Step: 3
Training loss: 1.7962079048156738
Validation loss: 2.0092726445967153

Epoch: 6| Step: 4
Training loss: 2.5044445991516113
Validation loss: 2.0098541821202924

Epoch: 6| Step: 5
Training loss: 2.3209493160247803
Validation loss: 2.018867269639046

Epoch: 6| Step: 6
Training loss: 2.5714406967163086
Validation loss: 2.017553042340022

Epoch: 6| Step: 7
Training loss: 1.8604614734649658
Validation loss: 1.9988048538084953

Epoch: 6| Step: 8
Training loss: 1.8626573085784912
Validation loss: 1.998763939385773

Epoch: 6| Step: 9
Training loss: 3.069777488708496
Validation loss: 2.0173342074117353

Epoch: 6| Step: 10
Training loss: 2.0051021575927734
Validation loss: 2.029511200484409

Epoch: 6| Step: 11
Training loss: 2.3917670249938965
Validation loss: 2.002913764728013

Epoch: 6| Step: 12
Training loss: 2.455115795135498
Validation loss: 2.015626972721469

Epoch: 6| Step: 13
Training loss: 2.8970696926116943
Validation loss: 1.9986657532312537

Epoch: 67| Step: 0
Training loss: 1.7576603889465332
Validation loss: 2.00428101324266

Epoch: 6| Step: 1
Training loss: 2.1294877529144287
Validation loss: 2.0042158595977293

Epoch: 6| Step: 2
Training loss: 2.469115972518921
Validation loss: 2.0117281470247494

Epoch: 6| Step: 3
Training loss: 1.6124670505523682
Validation loss: 1.9839015545383576

Epoch: 6| Step: 4
Training loss: 2.437896251678467
Validation loss: 1.9735407239647322

Epoch: 6| Step: 5
Training loss: 1.9089411497116089
Validation loss: 1.9743506370052215

Epoch: 6| Step: 6
Training loss: 3.076523780822754
Validation loss: 1.9740162459752892

Epoch: 6| Step: 7
Training loss: 1.581671953201294
Validation loss: 1.977842277096164

Epoch: 6| Step: 8
Training loss: 2.840825080871582
Validation loss: 1.9691065408850228

Epoch: 6| Step: 9
Training loss: 2.296445608139038
Validation loss: 1.983395593140715

Epoch: 6| Step: 10
Training loss: 3.174453020095825
Validation loss: 2.0057651906885128

Epoch: 6| Step: 11
Training loss: 2.4829087257385254
Validation loss: 1.9692367533201813

Epoch: 6| Step: 12
Training loss: 2.1095871925354004
Validation loss: 1.9836502882742113

Epoch: 6| Step: 13
Training loss: 2.0401978492736816
Validation loss: 2.0051047635334793

Epoch: 68| Step: 0
Training loss: 1.8897888660430908
Validation loss: 1.9901973509019422

Epoch: 6| Step: 1
Training loss: 2.419307231903076
Validation loss: 1.9771952859817012

Epoch: 6| Step: 2
Training loss: 1.6636426448822021
Validation loss: 2.0007338549501155

Epoch: 6| Step: 3
Training loss: 2.420701742172241
Validation loss: 1.9870711988018406

Epoch: 6| Step: 4
Training loss: 2.442437171936035
Validation loss: 2.002582464166867

Epoch: 6| Step: 5
Training loss: 2.6296544075012207
Validation loss: 2.003386716688833

Epoch: 6| Step: 6
Training loss: 2.2185258865356445
Validation loss: 1.9734824575403684

Epoch: 6| Step: 7
Training loss: 2.109476089477539
Validation loss: 2.0196515001276487

Epoch: 6| Step: 8
Training loss: 2.459855318069458
Validation loss: 2.02775005884068

Epoch: 6| Step: 9
Training loss: 2.3896162509918213
Validation loss: 2.0032705876135055

Epoch: 6| Step: 10
Training loss: 2.423243522644043
Validation loss: 1.9959349632263184

Epoch: 6| Step: 11
Training loss: 2.5256385803222656
Validation loss: 1.993390788314163

Epoch: 6| Step: 12
Training loss: 2.3716025352478027
Validation loss: 2.0013203774729083

Epoch: 6| Step: 13
Training loss: 1.7595208883285522
Validation loss: 2.0153984523588613

Epoch: 69| Step: 0
Training loss: 2.896472215652466
Validation loss: 2.0086338263685986

Epoch: 6| Step: 1
Training loss: 2.276757001876831
Validation loss: 1.9981009114173152

Epoch: 6| Step: 2
Training loss: 2.7605576515197754
Validation loss: 2.014950368994026

Epoch: 6| Step: 3
Training loss: 2.035581111907959
Validation loss: 2.0031859643997683

Epoch: 6| Step: 4
Training loss: 2.9581785202026367
Validation loss: 1.9805119960538802

Epoch: 6| Step: 5
Training loss: 1.9381011724472046
Validation loss: 1.9811051199513097

Epoch: 6| Step: 6
Training loss: 2.404106616973877
Validation loss: 2.016651563746955

Epoch: 6| Step: 7
Training loss: 1.6944935321807861
Validation loss: 2.00063028002298

Epoch: 6| Step: 8
Training loss: 1.9899711608886719
Validation loss: 1.9963726459010955

Epoch: 6| Step: 9
Training loss: 2.6136679649353027
Validation loss: 1.9889804983651767

Epoch: 6| Step: 10
Training loss: 2.352609872817993
Validation loss: 1.992300602697557

Epoch: 6| Step: 11
Training loss: 1.854224443435669
Validation loss: 2.0059666428514706

Epoch: 6| Step: 12
Training loss: 1.8716259002685547
Validation loss: 2.0000079447223293

Epoch: 6| Step: 13
Training loss: 2.4250903129577637
Validation loss: 1.9980722319695257

Epoch: 70| Step: 0
Training loss: 2.056600570678711
Validation loss: 1.9954516362118464

Epoch: 6| Step: 1
Training loss: 2.0577027797698975
Validation loss: 1.9813183135883783

Epoch: 6| Step: 2
Training loss: 2.546886444091797
Validation loss: 1.9804934558048044

Epoch: 6| Step: 3
Training loss: 2.6804513931274414
Validation loss: 2.007194810016181

Epoch: 6| Step: 4
Training loss: 1.7271671295166016
Validation loss: 1.9848687123226862

Epoch: 6| Step: 5
Training loss: 2.243642568588257
Validation loss: 1.9838701140496038

Epoch: 6| Step: 6
Training loss: 2.508047103881836
Validation loss: 1.999582673913689

Epoch: 6| Step: 7
Training loss: 2.446284532546997
Validation loss: 2.004646876806854

Epoch: 6| Step: 8
Training loss: 2.0709667205810547
Validation loss: 2.0102195714109685

Epoch: 6| Step: 9
Training loss: 1.7817106246948242
Validation loss: 1.9809922184995425

Epoch: 6| Step: 10
Training loss: 2.4227819442749023
Validation loss: 2.0107419311359362

Epoch: 6| Step: 11
Training loss: 2.225189685821533
Validation loss: 1.9783923869491906

Epoch: 6| Step: 12
Training loss: 2.4732842445373535
Validation loss: 1.9744775807985695

Epoch: 6| Step: 13
Training loss: 2.7531890869140625
Validation loss: 1.9829585654761201

Epoch: 71| Step: 0
Training loss: 3.2099344730377197
Validation loss: 2.006413318777597

Epoch: 6| Step: 1
Training loss: 2.6601243019104004
Validation loss: 1.9894388157834288

Epoch: 6| Step: 2
Training loss: 2.166790008544922
Validation loss: 2.02031877733046

Epoch: 6| Step: 3
Training loss: 2.2287240028381348
Validation loss: 1.9947948032809841

Epoch: 6| Step: 4
Training loss: 2.414142370223999
Validation loss: 1.9810841262981456

Epoch: 6| Step: 5
Training loss: 2.2575278282165527
Validation loss: 2.0196041599396737

Epoch: 6| Step: 6
Training loss: 2.0429129600524902
Validation loss: 2.004993745075759

Epoch: 6| Step: 7
Training loss: 2.126112937927246
Validation loss: 1.971740222746326

Epoch: 6| Step: 8
Training loss: 2.1875858306884766
Validation loss: 1.9820111541337864

Epoch: 6| Step: 9
Training loss: 1.9166600704193115
Validation loss: 1.9806064277566888

Epoch: 6| Step: 10
Training loss: 2.1430068016052246
Validation loss: 1.9780695489657822

Epoch: 6| Step: 11
Training loss: 2.5517334938049316
Validation loss: 1.961478942184038

Epoch: 6| Step: 12
Training loss: 2.2351903915405273
Validation loss: 1.987360503083916

Epoch: 6| Step: 13
Training loss: 1.6228047609329224
Validation loss: 2.0004951774433093

Epoch: 72| Step: 0
Training loss: 2.3329367637634277
Validation loss: 1.9885595870274368

Epoch: 6| Step: 1
Training loss: 2.005793809890747
Validation loss: 1.988113449465844

Epoch: 6| Step: 2
Training loss: 3.3291025161743164
Validation loss: 1.9796352617202266

Epoch: 6| Step: 3
Training loss: 2.0070159435272217
Validation loss: 1.9945165405991256

Epoch: 6| Step: 4
Training loss: 1.940709114074707
Validation loss: 2.011985981336204

Epoch: 6| Step: 5
Training loss: 1.6571627855300903
Validation loss: 1.989802638689677

Epoch: 6| Step: 6
Training loss: 2.519204616546631
Validation loss: 2.036727049017465

Epoch: 6| Step: 7
Training loss: 1.9161077737808228
Validation loss: 2.007326131225914

Epoch: 6| Step: 8
Training loss: 1.9888380765914917
Validation loss: 2.002259423655848

Epoch: 6| Step: 9
Training loss: 1.8205320835113525
Validation loss: 2.0061007827840824

Epoch: 6| Step: 10
Training loss: 2.1316757202148438
Validation loss: 2.014379511597336

Epoch: 6| Step: 11
Training loss: 2.9335381984710693
Validation loss: 2.002543859584357

Epoch: 6| Step: 12
Training loss: 2.6959164142608643
Validation loss: 2.0242179414277435

Epoch: 6| Step: 13
Training loss: 2.61342716217041
Validation loss: 2.0047928056409283

Epoch: 73| Step: 0
Training loss: 1.7413593530654907
Validation loss: 1.9999297613738685

Epoch: 6| Step: 1
Training loss: 2.7343194484710693
Validation loss: 1.9972621087105042

Epoch: 6| Step: 2
Training loss: 1.8264542818069458
Validation loss: 2.033301011208565

Epoch: 6| Step: 3
Training loss: 2.4596683979034424
Validation loss: 2.004831139759351

Epoch: 6| Step: 4
Training loss: 2.6812691688537598
Validation loss: 1.9994295374039681

Epoch: 6| Step: 5
Training loss: 2.2138822078704834
Validation loss: 1.997103826974028

Epoch: 6| Step: 6
Training loss: 2.6797242164611816
Validation loss: 1.9858727044956659

Epoch: 6| Step: 7
Training loss: 2.316105365753174
Validation loss: 2.0050099383118334

Epoch: 6| Step: 8
Training loss: 1.5665273666381836
Validation loss: 1.995124052929622

Epoch: 6| Step: 9
Training loss: 1.9520578384399414
Validation loss: 1.9850723884438957

Epoch: 6| Step: 10
Training loss: 2.091654062271118
Validation loss: 1.9908703578415738

Epoch: 6| Step: 11
Training loss: 2.0599069595336914
Validation loss: 1.9631821955403974

Epoch: 6| Step: 12
Training loss: 2.6919636726379395
Validation loss: 2.0001163328847578

Epoch: 6| Step: 13
Training loss: 3.1347529888153076
Validation loss: 1.9928224778944446

Epoch: 74| Step: 0
Training loss: 2.6765811443328857
Validation loss: 2.0116105682106427

Epoch: 6| Step: 1
Training loss: 1.3259303569793701
Validation loss: 1.9828971688465407

Epoch: 6| Step: 2
Training loss: 3.119932174682617
Validation loss: 1.9854607325728222

Epoch: 6| Step: 3
Training loss: 1.9129047393798828
Validation loss: 1.975076506214757

Epoch: 6| Step: 4
Training loss: 1.9332139492034912
Validation loss: 1.9918773840832453

Epoch: 6| Step: 5
Training loss: 2.1703572273254395
Validation loss: 2.0019389801127936

Epoch: 6| Step: 6
Training loss: 3.0549826622009277
Validation loss: 1.9809241282042636

Epoch: 6| Step: 7
Training loss: 2.294588565826416
Validation loss: 1.984881103679698

Epoch: 6| Step: 8
Training loss: 2.4013724327087402
Validation loss: 2.014195878018615

Epoch: 6| Step: 9
Training loss: 1.7911685705184937
Validation loss: 2.0171027632169825

Epoch: 6| Step: 10
Training loss: 2.810567855834961
Validation loss: 2.000280912204455

Epoch: 6| Step: 11
Training loss: 2.348731517791748
Validation loss: 2.0275297536644885

Epoch: 6| Step: 12
Training loss: 1.7551586627960205
Validation loss: 1.9908574268382082

Epoch: 6| Step: 13
Training loss: 2.0527987480163574
Validation loss: 1.9826304246020574

Epoch: 75| Step: 0
Training loss: 2.1486763954162598
Validation loss: 2.013222268832627

Epoch: 6| Step: 1
Training loss: 2.544437885284424
Validation loss: 2.0244777279515422

Epoch: 6| Step: 2
Training loss: 2.4866271018981934
Validation loss: 1.9912975782989173

Epoch: 6| Step: 3
Training loss: 2.3293263912200928
Validation loss: 2.0122436746474235

Epoch: 6| Step: 4
Training loss: 1.909595012664795
Validation loss: 2.005046183063138

Epoch: 6| Step: 5
Training loss: 2.3931591510772705
Validation loss: 2.016397363396101

Epoch: 6| Step: 6
Training loss: 2.467024326324463
Validation loss: 1.9751405151941444

Epoch: 6| Step: 7
Training loss: 2.3819003105163574
Validation loss: 1.9838363585933563

Epoch: 6| Step: 8
Training loss: 2.189544200897217
Validation loss: 1.9768244322910105

Epoch: 6| Step: 9
Training loss: 2.4238576889038086
Validation loss: 1.9968081507631528

Epoch: 6| Step: 10
Training loss: 1.9518262147903442
Validation loss: 1.9933545589447021

Epoch: 6| Step: 11
Training loss: 2.544796943664551
Validation loss: 1.9920101332408127

Epoch: 6| Step: 12
Training loss: 1.35924232006073
Validation loss: 2.0085170525376514

Epoch: 6| Step: 13
Training loss: 3.000671148300171
Validation loss: 1.9734123060780187

Epoch: 76| Step: 0
Training loss: 2.4091737270355225
Validation loss: 1.995812282767347

Epoch: 6| Step: 1
Training loss: 1.9914957284927368
Validation loss: 1.9941300897188083

Epoch: 6| Step: 2
Training loss: 2.520442485809326
Validation loss: 1.986932712216531

Epoch: 6| Step: 3
Training loss: 3.149928331375122
Validation loss: 2.007860606716525

Epoch: 6| Step: 4
Training loss: 2.19673490524292
Validation loss: 1.9947241711360153

Epoch: 6| Step: 5
Training loss: 2.4637763500213623
Validation loss: 1.9831682405164164

Epoch: 6| Step: 6
Training loss: 2.0076942443847656
Validation loss: 1.986262482981528

Epoch: 6| Step: 7
Training loss: 1.784308671951294
Validation loss: 1.9639347676307923

Epoch: 6| Step: 8
Training loss: 2.002079963684082
Validation loss: 1.9773692225897184

Epoch: 6| Step: 9
Training loss: 1.4484457969665527
Validation loss: 1.9810167307494788

Epoch: 6| Step: 10
Training loss: 3.0862314701080322
Validation loss: 1.9852344400139266

Epoch: 6| Step: 11
Training loss: 2.2060883045196533
Validation loss: 2.0015647154982372

Epoch: 6| Step: 12
Training loss: 2.61104679107666
Validation loss: 2.0060860636413738

Epoch: 6| Step: 13
Training loss: 1.8747471570968628
Validation loss: 1.9986044232563307

Epoch: 77| Step: 0
Training loss: 2.3553836345672607
Validation loss: 1.9983984014039398

Epoch: 6| Step: 1
Training loss: 2.093761682510376
Validation loss: 1.9942586421966553

Epoch: 6| Step: 2
Training loss: 1.6466660499572754
Validation loss: 1.9805048460601478

Epoch: 6| Step: 3
Training loss: 2.201486349105835
Validation loss: 2.0232235834162724

Epoch: 6| Step: 4
Training loss: 1.7556989192962646
Validation loss: 2.0032766198599212

Epoch: 6| Step: 5
Training loss: 1.7418899536132812
Validation loss: 2.009138850755589

Epoch: 6| Step: 6
Training loss: 2.9151411056518555
Validation loss: 2.0243216688914965

Epoch: 6| Step: 7
Training loss: 2.2507920265197754
Validation loss: 2.0183430794746644

Epoch: 6| Step: 8
Training loss: 2.4796228408813477
Validation loss: 2.036599983451187

Epoch: 6| Step: 9
Training loss: 1.942447304725647
Validation loss: 2.0280037387724845

Epoch: 6| Step: 10
Training loss: 2.5574159622192383
Validation loss: 2.0334986896925074

Epoch: 6| Step: 11
Training loss: 2.032883644104004
Validation loss: 2.006891199337539

Epoch: 6| Step: 12
Training loss: 3.0448312759399414
Validation loss: 2.0124612674918225

Epoch: 6| Step: 13
Training loss: 3.0706393718719482
Validation loss: 2.020209432930075

Epoch: 78| Step: 0
Training loss: 2.1388018131256104
Validation loss: 2.0190629369469097

Epoch: 6| Step: 1
Training loss: 2.3699493408203125
Validation loss: 2.0021711677633305

Epoch: 6| Step: 2
Training loss: 1.9139643907546997
Validation loss: 2.019834421014273

Epoch: 6| Step: 3
Training loss: 2.624422550201416
Validation loss: 2.005312523534221

Epoch: 6| Step: 4
Training loss: 2.7386717796325684
Validation loss: 1.9918591335255613

Epoch: 6| Step: 5
Training loss: 2.2004711627960205
Validation loss: 2.023060465371737

Epoch: 6| Step: 6
Training loss: 2.6008667945861816
Validation loss: 2.010681741981096

Epoch: 6| Step: 7
Training loss: 2.0837132930755615
Validation loss: 2.0224158981794953

Epoch: 6| Step: 8
Training loss: 1.966185212135315
Validation loss: 2.0123090974746214

Epoch: 6| Step: 9
Training loss: 2.5476326942443848
Validation loss: 2.015563113715059

Epoch: 6| Step: 10
Training loss: 2.3166513442993164
Validation loss: 2.010872911381465

Epoch: 6| Step: 11
Training loss: 2.35884165763855
Validation loss: 1.9841572392371394

Epoch: 6| Step: 12
Training loss: 1.9524321556091309
Validation loss: 1.9977546097129903

Epoch: 6| Step: 13
Training loss: 1.7453068494796753
Validation loss: 1.9865682125091553

Epoch: 79| Step: 0
Training loss: 2.080368995666504
Validation loss: 2.0036385187538723

Epoch: 6| Step: 1
Training loss: 2.1133809089660645
Validation loss: 2.013622608236087

Epoch: 6| Step: 2
Training loss: 1.7466320991516113
Validation loss: 2.008892487454158

Epoch: 6| Step: 3
Training loss: 2.633636474609375
Validation loss: 2.004226883252462

Epoch: 6| Step: 4
Training loss: 2.5587570667266846
Validation loss: 1.9881287659368208

Epoch: 6| Step: 5
Training loss: 2.2484498023986816
Validation loss: 1.9791109510647353

Epoch: 6| Step: 6
Training loss: 3.050842523574829
Validation loss: 1.99565762858237

Epoch: 6| Step: 7
Training loss: 1.5623095035552979
Validation loss: 1.987160708314629

Epoch: 6| Step: 8
Training loss: 2.1813862323760986
Validation loss: 1.9884381191704863

Epoch: 6| Step: 9
Training loss: 2.587376594543457
Validation loss: 2.013858608020249

Epoch: 6| Step: 10
Training loss: 2.9789834022521973
Validation loss: 1.9847480917489657

Epoch: 6| Step: 11
Training loss: 1.9296469688415527
Validation loss: 2.0011185420456754

Epoch: 6| Step: 12
Training loss: 2.2317657470703125
Validation loss: 1.9947442944331835

Epoch: 6| Step: 13
Training loss: 1.5802912712097168
Validation loss: 2.0012430862713884

Epoch: 80| Step: 0
Training loss: 2.701004981994629
Validation loss: 2.010501923099641

Epoch: 6| Step: 1
Training loss: 2.427615165710449
Validation loss: 1.9898256319825367

Epoch: 6| Step: 2
Training loss: 2.681368827819824
Validation loss: 1.9714342573637604

Epoch: 6| Step: 3
Training loss: 1.7281403541564941
Validation loss: 2.0137085068610405

Epoch: 6| Step: 4
Training loss: 2.3960742950439453
Validation loss: 1.9770240245326873

Epoch: 6| Step: 5
Training loss: 2.5840201377868652
Validation loss: 2.0180983517759588

Epoch: 6| Step: 6
Training loss: 2.073331356048584
Validation loss: 1.9821517980226906

Epoch: 6| Step: 7
Training loss: 1.847977638244629
Validation loss: 1.9823729043365808

Epoch: 6| Step: 8
Training loss: 1.9685144424438477
Validation loss: 2.0057353576024375

Epoch: 6| Step: 9
Training loss: 2.706430673599243
Validation loss: 2.00295824902032

Epoch: 6| Step: 10
Training loss: 2.6543259620666504
Validation loss: 1.994858976333372

Epoch: 6| Step: 11
Training loss: 1.9688184261322021
Validation loss: 1.996917922009704

Epoch: 6| Step: 12
Training loss: 2.276278257369995
Validation loss: 1.9800676222770446

Epoch: 6| Step: 13
Training loss: 1.1966304779052734
Validation loss: 1.9794601112283685

Epoch: 81| Step: 0
Training loss: 2.3245415687561035
Validation loss: 2.0126939435159006

Epoch: 6| Step: 1
Training loss: 2.3935086727142334
Validation loss: 1.9999537467956543

Epoch: 6| Step: 2
Training loss: 1.6189287900924683
Validation loss: 2.0151021378014677

Epoch: 6| Step: 3
Training loss: 2.2560813426971436
Validation loss: 1.9923901724559006

Epoch: 6| Step: 4
Training loss: 1.4617856740951538
Validation loss: 2.0095766282850698

Epoch: 6| Step: 5
Training loss: 2.962031126022339
Validation loss: 1.9951197049951042

Epoch: 6| Step: 6
Training loss: 2.6233978271484375
Validation loss: 2.0033582743778022

Epoch: 6| Step: 7
Training loss: 2.170974016189575
Validation loss: 2.008174464266787

Epoch: 6| Step: 8
Training loss: 3.075509548187256
Validation loss: 1.9886241087349512

Epoch: 6| Step: 9
Training loss: 2.65095853805542
Validation loss: 2.042556796022641

Epoch: 6| Step: 10
Training loss: 2.586740732192993
Validation loss: 2.027233877489644

Epoch: 6| Step: 11
Training loss: 1.685420274734497
Validation loss: 2.0073733714319046

Epoch: 6| Step: 12
Training loss: 2.2983713150024414
Validation loss: 2.009935680256095

Epoch: 6| Step: 13
Training loss: 1.5260154008865356
Validation loss: 2.02494909686427

Epoch: 82| Step: 0
Training loss: 2.7672367095947266
Validation loss: 2.021240347175188

Epoch: 6| Step: 1
Training loss: 3.3154101371765137
Validation loss: 2.011450227870736

Epoch: 6| Step: 2
Training loss: 1.8578037023544312
Validation loss: 2.018298399063849

Epoch: 6| Step: 3
Training loss: 2.3323171138763428
Validation loss: 2.044494116178123

Epoch: 6| Step: 4
Training loss: 2.048893451690674
Validation loss: 2.0021964183417698

Epoch: 6| Step: 5
Training loss: 1.9782192707061768
Validation loss: 2.0126343811711958

Epoch: 6| Step: 6
Training loss: 2.3369390964508057
Validation loss: 2.003787020201324

Epoch: 6| Step: 7
Training loss: 1.9276933670043945
Validation loss: 1.9912670427753079

Epoch: 6| Step: 8
Training loss: 1.66263747215271
Validation loss: 2.0286423852366786

Epoch: 6| Step: 9
Training loss: 2.8989648818969727
Validation loss: 2.015716181006483

Epoch: 6| Step: 10
Training loss: 1.9869873523712158
Validation loss: 2.0298152892820296

Epoch: 6| Step: 11
Training loss: 2.120285749435425
Validation loss: 2.0039265668520363

Epoch: 6| Step: 12
Training loss: 2.392902374267578
Validation loss: 2.008905185166226

Epoch: 6| Step: 13
Training loss: 1.7862792015075684
Validation loss: 2.0464090775418025

Epoch: 83| Step: 0
Training loss: 1.8783469200134277
Validation loss: 2.0184860588401876

Epoch: 6| Step: 1
Training loss: 1.5219156742095947
Validation loss: 2.0369767578699256

Epoch: 6| Step: 2
Training loss: 2.426358461380005
Validation loss: 2.0141730898170063

Epoch: 6| Step: 3
Training loss: 2.1771719455718994
Validation loss: 1.9871654382316015

Epoch: 6| Step: 4
Training loss: 2.5050315856933594
Validation loss: 2.002009581494075

Epoch: 6| Step: 5
Training loss: 2.443636894226074
Validation loss: 1.985176004389281

Epoch: 6| Step: 6
Training loss: 2.1270017623901367
Validation loss: 2.0121947937114264

Epoch: 6| Step: 7
Training loss: 1.7261098623275757
Validation loss: 2.0042293430656515

Epoch: 6| Step: 8
Training loss: 2.1516284942626953
Validation loss: 2.010802630455263

Epoch: 6| Step: 9
Training loss: 1.8694324493408203
Validation loss: 2.0133540873886435

Epoch: 6| Step: 10
Training loss: 2.8394107818603516
Validation loss: 1.9984037504401257

Epoch: 6| Step: 11
Training loss: 2.5864319801330566
Validation loss: 2.03999021104587

Epoch: 6| Step: 12
Training loss: 2.2369284629821777
Validation loss: 2.0299977282042145

Epoch: 6| Step: 13
Training loss: 3.5690219402313232
Validation loss: 2.018423552154213

Epoch: 84| Step: 0
Training loss: 3.4607057571411133
Validation loss: 2.0021576214862127

Epoch: 6| Step: 1
Training loss: 2.860102653503418
Validation loss: 2.021971630793746

Epoch: 6| Step: 2
Training loss: 1.6814210414886475
Validation loss: 2.0144745393465926

Epoch: 6| Step: 3
Training loss: 2.692492723464966
Validation loss: 2.0090633182115454

Epoch: 6| Step: 4
Training loss: 2.2356767654418945
Validation loss: 2.012165536162674

Epoch: 6| Step: 5
Training loss: 3.4211971759796143
Validation loss: 2.026934200717557

Epoch: 6| Step: 6
Training loss: 1.6640112400054932
Validation loss: 2.0124940333827848

Epoch: 6| Step: 7
Training loss: 1.8742735385894775
Validation loss: 2.0149356139603483

Epoch: 6| Step: 8
Training loss: 2.5032730102539062
Validation loss: 2.045159947487616

Epoch: 6| Step: 9
Training loss: 1.612226963043213
Validation loss: 2.012278531187324

Epoch: 6| Step: 10
Training loss: 1.276491403579712
Validation loss: 2.0251981955702587

Epoch: 6| Step: 11
Training loss: 2.6166884899139404
Validation loss: 2.0327712771713093

Epoch: 6| Step: 12
Training loss: 1.6274404525756836
Validation loss: 2.031810365697389

Epoch: 6| Step: 13
Training loss: 1.8721404075622559
Validation loss: 2.0155941183849047

Epoch: 85| Step: 0
Training loss: 2.7708606719970703
Validation loss: 2.036230298780626

Epoch: 6| Step: 1
Training loss: 2.0279436111450195
Validation loss: 2.0370371598069386

Epoch: 6| Step: 2
Training loss: 2.198401927947998
Validation loss: 2.0198718578584733

Epoch: 6| Step: 3
Training loss: 2.1777868270874023
Validation loss: 2.0281549884426977

Epoch: 6| Step: 4
Training loss: 2.6993250846862793
Validation loss: 2.019259887356912

Epoch: 6| Step: 5
Training loss: 1.802277684211731
Validation loss: 1.9940133043514785

Epoch: 6| Step: 6
Training loss: 2.438572406768799
Validation loss: 2.0045651338433705

Epoch: 6| Step: 7
Training loss: 2.101020336151123
Validation loss: 2.0141860541476997

Epoch: 6| Step: 8
Training loss: 2.3811118602752686
Validation loss: 2.006904912251298

Epoch: 6| Step: 9
Training loss: 1.9123733043670654
Validation loss: 2.008544329674013

Epoch: 6| Step: 10
Training loss: 2.303366184234619
Validation loss: 2.021254024197978

Epoch: 6| Step: 11
Training loss: 2.0941858291625977
Validation loss: 2.029822127793425

Epoch: 6| Step: 12
Training loss: 2.4744417667388916
Validation loss: 2.0143020652955577

Epoch: 6| Step: 13
Training loss: 2.312758445739746
Validation loss: 2.0101186511337117

Epoch: 86| Step: 0
Training loss: 1.977963924407959
Validation loss: 2.024261538700391

Epoch: 6| Step: 1
Training loss: 2.264679431915283
Validation loss: 1.9985690245064356

Epoch: 6| Step: 2
Training loss: 2.1806044578552246
Validation loss: 2.0275429717956053

Epoch: 6| Step: 3
Training loss: 2.120532512664795
Validation loss: 2.0266611781171573

Epoch: 6| Step: 4
Training loss: 2.5382466316223145
Validation loss: 1.9895492663947485

Epoch: 6| Step: 5
Training loss: 2.197606086730957
Validation loss: 2.0141370911752023

Epoch: 6| Step: 6
Training loss: 2.0519161224365234
Validation loss: 2.0245226301172727

Epoch: 6| Step: 7
Training loss: 2.1336655616760254
Validation loss: 2.0264040936705885

Epoch: 6| Step: 8
Training loss: 2.700493097305298
Validation loss: 2.026757024949597

Epoch: 6| Step: 9
Training loss: 2.63603138923645
Validation loss: 2.022030758601363

Epoch: 6| Step: 10
Training loss: 2.2985422611236572
Validation loss: 2.020933578091283

Epoch: 6| Step: 11
Training loss: 1.8224663734436035
Validation loss: 2.039145149210448

Epoch: 6| Step: 12
Training loss: 2.3971662521362305
Validation loss: 1.9962255724014775

Epoch: 6| Step: 13
Training loss: 2.441725492477417
Validation loss: 2.038552056076706

Epoch: 87| Step: 0
Training loss: 1.9578443765640259
Validation loss: 2.0108508051082654

Epoch: 6| Step: 1
Training loss: 2.6927602291107178
Validation loss: 2.0114515314819994

Epoch: 6| Step: 2
Training loss: 3.1941308975219727
Validation loss: 2.027176798030894

Epoch: 6| Step: 3
Training loss: 2.709476947784424
Validation loss: 1.9952603873386179

Epoch: 6| Step: 4
Training loss: 1.8838531970977783
Validation loss: 2.0134980537558116

Epoch: 6| Step: 5
Training loss: 1.3575466871261597
Validation loss: 2.0183020202062463

Epoch: 6| Step: 6
Training loss: 2.5437817573547363
Validation loss: 2.009974770648505

Epoch: 6| Step: 7
Training loss: 2.351454734802246
Validation loss: 2.026970294214064

Epoch: 6| Step: 8
Training loss: 2.912602186203003
Validation loss: 1.998905917649628

Epoch: 6| Step: 9
Training loss: 1.6989068984985352
Validation loss: 2.0073095495982836

Epoch: 6| Step: 10
Training loss: 2.4325942993164062
Validation loss: 2.0075610427446264

Epoch: 6| Step: 11
Training loss: 1.3050950765609741
Validation loss: 2.025998377030896

Epoch: 6| Step: 12
Training loss: 2.329761028289795
Validation loss: 2.0157980918884277

Epoch: 6| Step: 13
Training loss: 2.2996444702148438
Validation loss: 2.0028233681955645

Epoch: 88| Step: 0
Training loss: 2.5058436393737793
Validation loss: 2.011363214062106

Epoch: 6| Step: 1
Training loss: 2.238804340362549
Validation loss: 1.9974013490061606

Epoch: 6| Step: 2
Training loss: 2.3839778900146484
Validation loss: 1.9938014489348217

Epoch: 6| Step: 3
Training loss: 2.6544344425201416
Validation loss: 1.999201830997262

Epoch: 6| Step: 4
Training loss: 1.9579474925994873
Validation loss: 2.0243064767570904

Epoch: 6| Step: 5
Training loss: 1.9852097034454346
Validation loss: 2.0255163843913744

Epoch: 6| Step: 6
Training loss: 2.7457776069641113
Validation loss: 2.0146221089106735

Epoch: 6| Step: 7
Training loss: 1.8346149921417236
Validation loss: 2.032387879586989

Epoch: 6| Step: 8
Training loss: 1.5902485847473145
Validation loss: 2.025829238276328

Epoch: 6| Step: 9
Training loss: 2.5730929374694824
Validation loss: 2.0487925160315728

Epoch: 6| Step: 10
Training loss: 2.202831983566284
Validation loss: 2.0444296508707027

Epoch: 6| Step: 11
Training loss: 2.497671365737915
Validation loss: 2.0512262928870415

Epoch: 6| Step: 12
Training loss: 2.531083106994629
Validation loss: 2.058751097289465

Epoch: 6| Step: 13
Training loss: 2.000591993331909
Validation loss: 2.0282196844777753

Epoch: 89| Step: 0
Training loss: 2.2134499549865723
Validation loss: 2.0487661515512774

Epoch: 6| Step: 1
Training loss: 2.1749534606933594
Validation loss: 2.0128633488890944

Epoch: 6| Step: 2
Training loss: 2.5513296127319336
Validation loss: 2.03799617931407

Epoch: 6| Step: 3
Training loss: 1.5798157453536987
Validation loss: 2.0409543693706556

Epoch: 6| Step: 4
Training loss: 1.626307487487793
Validation loss: 2.0015602739908362

Epoch: 6| Step: 5
Training loss: 1.6147477626800537
Validation loss: 2.043021901961296

Epoch: 6| Step: 6
Training loss: 3.06674861907959
Validation loss: 2.0328295743593605

Epoch: 6| Step: 7
Training loss: 2.5685315132141113
Validation loss: 2.0049723630310385

Epoch: 6| Step: 8
Training loss: 1.798095941543579
Validation loss: 2.0307956869884203

Epoch: 6| Step: 9
Training loss: 3.2452352046966553
Validation loss: 2.008918939098235

Epoch: 6| Step: 10
Training loss: 1.9922459125518799
Validation loss: 2.0034665356400194

Epoch: 6| Step: 11
Training loss: 2.622645854949951
Validation loss: 2.009940803691905

Epoch: 6| Step: 12
Training loss: 2.441779613494873
Validation loss: 2.013149097401609

Epoch: 6| Step: 13
Training loss: 1.7903772592544556
Validation loss: 2.002424350348852

Epoch: 90| Step: 0
Training loss: 2.7637948989868164
Validation loss: 2.0196282978980773

Epoch: 6| Step: 1
Training loss: 2.1959028244018555
Validation loss: 2.008115117267896

Epoch: 6| Step: 2
Training loss: 2.869051456451416
Validation loss: 2.00160680150473

Epoch: 6| Step: 3
Training loss: 2.346339225769043
Validation loss: 2.005176971035619

Epoch: 6| Step: 4
Training loss: 2.327284097671509
Validation loss: 2.0086674305700485

Epoch: 6| Step: 5
Training loss: 2.3887345790863037
Validation loss: 1.9850808061579222

Epoch: 6| Step: 6
Training loss: 2.4741272926330566
Validation loss: 1.9910568921796736

Epoch: 6| Step: 7
Training loss: 2.2399816513061523
Validation loss: 1.9842301196949457

Epoch: 6| Step: 8
Training loss: 2.7309396266937256
Validation loss: 2.034808187074559

Epoch: 6| Step: 9
Training loss: 2.320591926574707
Validation loss: 2.0195052495566745

Epoch: 6| Step: 10
Training loss: 1.2263007164001465
Validation loss: 1.981305835067585

Epoch: 6| Step: 11
Training loss: 1.772723913192749
Validation loss: 1.9956458383990872

Epoch: 6| Step: 12
Training loss: 2.165470600128174
Validation loss: 1.9883216375945716

Epoch: 6| Step: 13
Training loss: 1.601176381111145
Validation loss: 1.9884277800078034

Epoch: 91| Step: 0
Training loss: 1.7454994916915894
Validation loss: 1.9908518893744356

Epoch: 6| Step: 1
Training loss: 2.5328621864318848
Validation loss: 2.0383883086583947

Epoch: 6| Step: 2
Training loss: 2.1772520542144775
Validation loss: 2.002138081417289

Epoch: 6| Step: 3
Training loss: 2.7451822757720947
Validation loss: 1.9981719857902938

Epoch: 6| Step: 4
Training loss: 2.422503709793091
Validation loss: 2.021913084932553

Epoch: 6| Step: 5
Training loss: 1.8810536861419678
Validation loss: 2.0004618590877903

Epoch: 6| Step: 6
Training loss: 2.5390138626098633
Validation loss: 1.994766027696671

Epoch: 6| Step: 7
Training loss: 2.7707362174987793
Validation loss: 2.014071297901933

Epoch: 6| Step: 8
Training loss: 2.6492271423339844
Validation loss: 2.013747376780356

Epoch: 6| Step: 9
Training loss: 1.4036729335784912
Validation loss: 2.0182119325924943

Epoch: 6| Step: 10
Training loss: 2.366763114929199
Validation loss: 2.0085044266075216

Epoch: 6| Step: 11
Training loss: 2.0730903148651123
Validation loss: 2.0058936842026247

Epoch: 6| Step: 12
Training loss: 2.4209861755371094
Validation loss: 2.0025062073943434

Epoch: 6| Step: 13
Training loss: 1.7633105516433716
Validation loss: 2.02960019470543

Epoch: 92| Step: 0
Training loss: 2.115459442138672
Validation loss: 2.014199592733896

Epoch: 6| Step: 1
Training loss: 2.170184373855591
Validation loss: 2.008082639786505

Epoch: 6| Step: 2
Training loss: 2.3742613792419434
Validation loss: 2.0290395085529616

Epoch: 6| Step: 3
Training loss: 2.6186575889587402
Validation loss: 2.0292467660801385

Epoch: 6| Step: 4
Training loss: 2.020138740539551
Validation loss: 2.0307247254156295

Epoch: 6| Step: 5
Training loss: 1.85260009765625
Validation loss: 2.0179802986883346

Epoch: 6| Step: 6
Training loss: 1.90152907371521
Validation loss: 2.010188933341734

Epoch: 6| Step: 7
Training loss: 2.915449857711792
Validation loss: 2.020709083926293

Epoch: 6| Step: 8
Training loss: 1.9595515727996826
Validation loss: 2.020104064736315

Epoch: 6| Step: 9
Training loss: 2.481079578399658
Validation loss: 2.0258383904733965

Epoch: 6| Step: 10
Training loss: 1.8759633302688599
Validation loss: 2.006137776118453

Epoch: 6| Step: 11
Training loss: 2.2507944107055664
Validation loss: 2.0169978936513266

Epoch: 6| Step: 12
Training loss: 2.578223466873169
Validation loss: 1.9944704066040695

Epoch: 6| Step: 13
Training loss: 2.5271782875061035
Validation loss: 2.002501497986496

Epoch: 93| Step: 0
Training loss: 2.671797275543213
Validation loss: 2.0146507499038533

Epoch: 6| Step: 1
Training loss: 2.701219081878662
Validation loss: 1.9984055488340315

Epoch: 6| Step: 2
Training loss: 2.1977715492248535
Validation loss: 1.9985501817477647

Epoch: 6| Step: 3
Training loss: 2.353821277618408
Validation loss: 1.9946745467442337

Epoch: 6| Step: 4
Training loss: 2.0797457695007324
Validation loss: 2.008326575320254

Epoch: 6| Step: 5
Training loss: 2.6330766677856445
Validation loss: 1.982588880805559

Epoch: 6| Step: 6
Training loss: 1.9548696279525757
Validation loss: 1.979751125458748

Epoch: 6| Step: 7
Training loss: 2.512511730194092
Validation loss: 1.9838089007203297

Epoch: 6| Step: 8
Training loss: 2.252987861633301
Validation loss: 1.9989785968616445

Epoch: 6| Step: 9
Training loss: 2.183319091796875
Validation loss: 2.000467026105491

Epoch: 6| Step: 10
Training loss: 1.7560038566589355
Validation loss: 1.9628224270318144

Epoch: 6| Step: 11
Training loss: 1.8474538326263428
Validation loss: 1.9918689368873514

Epoch: 6| Step: 12
Training loss: 2.4261996746063232
Validation loss: 2.0006277791915403

Epoch: 6| Step: 13
Training loss: 2.1585702896118164
Validation loss: 1.9949787611602454

Epoch: 94| Step: 0
Training loss: 2.0260438919067383
Validation loss: 1.983081938118063

Epoch: 6| Step: 1
Training loss: 1.7265191078186035
Validation loss: 1.9928972977463917

Epoch: 6| Step: 2
Training loss: 2.5092287063598633
Validation loss: 1.9919395703141407

Epoch: 6| Step: 3
Training loss: 2.8367929458618164
Validation loss: 1.9942676098115983

Epoch: 6| Step: 4
Training loss: 2.5746521949768066
Validation loss: 2.028967408723729

Epoch: 6| Step: 5
Training loss: 2.4053659439086914
Validation loss: 1.994358471644822

Epoch: 6| Step: 6
Training loss: 2.6830294132232666
Validation loss: 2.0382326533717494

Epoch: 6| Step: 7
Training loss: 2.474179744720459
Validation loss: 1.9937070467138802

Epoch: 6| Step: 8
Training loss: 2.183742046356201
Validation loss: 2.007482647895813

Epoch: 6| Step: 9
Training loss: 2.1460394859313965
Validation loss: 2.0094701372167116

Epoch: 6| Step: 10
Training loss: 2.1107869148254395
Validation loss: 2.030447398462603

Epoch: 6| Step: 11
Training loss: 1.877960443496704
Validation loss: 2.014845250755228

Epoch: 6| Step: 12
Training loss: 2.3264248371124268
Validation loss: 2.030790208488382

Epoch: 6| Step: 13
Training loss: 1.0663059949874878
Validation loss: 2.027909569842841

Epoch: 95| Step: 0
Training loss: 1.7617239952087402
Validation loss: 2.058113944145941

Epoch: 6| Step: 1
Training loss: 2.5009217262268066
Validation loss: 2.035467005545093

Epoch: 6| Step: 2
Training loss: 2.0197806358337402
Validation loss: 2.012164969598093

Epoch: 6| Step: 3
Training loss: 1.9237922430038452
Validation loss: 2.030048390870453

Epoch: 6| Step: 4
Training loss: 2.362795352935791
Validation loss: 2.0400652423981698

Epoch: 6| Step: 5
Training loss: 2.150813102722168
Validation loss: 2.0320602770774596

Epoch: 6| Step: 6
Training loss: 2.0258629322052
Validation loss: 1.9967103645365725

Epoch: 6| Step: 7
Training loss: 2.5863091945648193
Validation loss: 2.0192346457512147

Epoch: 6| Step: 8
Training loss: 2.9637367725372314
Validation loss: 1.9989114333224554

Epoch: 6| Step: 9
Training loss: 3.145660877227783
Validation loss: 2.035716715679374

Epoch: 6| Step: 10
Training loss: 1.5367109775543213
Validation loss: 2.028265763354558

Epoch: 6| Step: 11
Training loss: 2.114325523376465
Validation loss: 2.007947779470874

Epoch: 6| Step: 12
Training loss: 1.9276835918426514
Validation loss: 2.027594357408503

Epoch: 6| Step: 13
Training loss: 2.496993064880371
Validation loss: 2.0037566897689656

Epoch: 96| Step: 0
Training loss: 1.6351237297058105
Validation loss: 2.0238361743188675

Epoch: 6| Step: 1
Training loss: 1.844689965248108
Validation loss: 2.0199055876783145

Epoch: 6| Step: 2
Training loss: 2.0721511840820312
Validation loss: 2.022895689933531

Epoch: 6| Step: 3
Training loss: 2.8927292823791504
Validation loss: 1.9747995381714196

Epoch: 6| Step: 4
Training loss: 1.9339134693145752
Validation loss: 1.9900111357371013

Epoch: 6| Step: 5
Training loss: 2.757297992706299
Validation loss: 1.9924882432465911

Epoch: 6| Step: 6
Training loss: 1.5057870149612427
Validation loss: 1.995975125220514

Epoch: 6| Step: 7
Training loss: 2.531221389770508
Validation loss: 1.983212335135347

Epoch: 6| Step: 8
Training loss: 2.5823872089385986
Validation loss: 1.9762748543934157

Epoch: 6| Step: 9
Training loss: 1.8989591598510742
Validation loss: 1.9869694107322282

Epoch: 6| Step: 10
Training loss: 1.7601238489151
Validation loss: 2.0056880750963764

Epoch: 6| Step: 11
Training loss: 2.5763356685638428
Validation loss: 2.0000586330249743

Epoch: 6| Step: 12
Training loss: 3.1244359016418457
Validation loss: 1.9839216714264245

Epoch: 6| Step: 13
Training loss: 2.636763572692871
Validation loss: 1.9835953622735956

Epoch: 97| Step: 0
Training loss: 1.8964524269104004
Validation loss: 2.013816361786217

Epoch: 6| Step: 1
Training loss: 2.692317008972168
Validation loss: 2.006875558566022

Epoch: 6| Step: 2
Training loss: 1.9903571605682373
Validation loss: 2.010251073427098

Epoch: 6| Step: 3
Training loss: 1.2447829246520996
Validation loss: 2.004856454428806

Epoch: 6| Step: 4
Training loss: 3.0824971199035645
Validation loss: 2.005272424349221

Epoch: 6| Step: 5
Training loss: 1.4711496829986572
Validation loss: 2.00481354805731

Epoch: 6| Step: 6
Training loss: 2.787989616394043
Validation loss: 2.0173825397286365

Epoch: 6| Step: 7
Training loss: 2.5220236778259277
Validation loss: 2.027828735689963

Epoch: 6| Step: 8
Training loss: 1.8542066812515259
Validation loss: 2.0120663309610016

Epoch: 6| Step: 9
Training loss: 3.0123143196105957
Validation loss: 2.0032359489830593

Epoch: 6| Step: 10
Training loss: 2.2954206466674805
Validation loss: 2.004700736332965

Epoch: 6| Step: 11
Training loss: 2.3731844425201416
Validation loss: 2.0157193137753393

Epoch: 6| Step: 12
Training loss: 2.4760146141052246
Validation loss: 2.0018602750634633

Epoch: 6| Step: 13
Training loss: 1.728983998298645
Validation loss: 2.0207447492948143

Epoch: 98| Step: 0
Training loss: 2.4258294105529785
Validation loss: 2.0068477635742514

Epoch: 6| Step: 1
Training loss: 2.6567375659942627
Validation loss: 2.020152284253028

Epoch: 6| Step: 2
Training loss: 2.214899778366089
Validation loss: 2.030930881859154

Epoch: 6| Step: 3
Training loss: 2.3028085231781006
Validation loss: 2.034658590952555

Epoch: 6| Step: 4
Training loss: 1.6991913318634033
Validation loss: 1.9939814511165823

Epoch: 6| Step: 5
Training loss: 2.521451711654663
Validation loss: 1.9968453709797194

Epoch: 6| Step: 6
Training loss: 1.869105339050293
Validation loss: 2.0141749176927792

Epoch: 6| Step: 7
Training loss: 2.7353432178497314
Validation loss: 2.0259360882543747

Epoch: 6| Step: 8
Training loss: 1.9319473505020142
Validation loss: 2.0276611133288314

Epoch: 6| Step: 9
Training loss: 2.3490147590637207
Validation loss: 2.0329248994909306

Epoch: 6| Step: 10
Training loss: 2.5333707332611084
Validation loss: 2.0068285298603836

Epoch: 6| Step: 11
Training loss: 1.8935258388519287
Validation loss: 2.0260986820344002

Epoch: 6| Step: 12
Training loss: 1.5655789375305176
Validation loss: 2.0328099022629442

Epoch: 6| Step: 13
Training loss: 2.9600470066070557
Validation loss: 1.9970133791687668

Epoch: 99| Step: 0
Training loss: 2.502450466156006
Validation loss: 2.0327164831981865

Epoch: 6| Step: 1
Training loss: 3.447920322418213
Validation loss: 2.025220504371069

Epoch: 6| Step: 2
Training loss: 2.00711989402771
Validation loss: 2.009203164808212

Epoch: 6| Step: 3
Training loss: 1.578399658203125
Validation loss: 2.0213239833872807

Epoch: 6| Step: 4
Training loss: 1.7330505847930908
Validation loss: 2.0234265532544864

Epoch: 6| Step: 5
Training loss: 2.449145793914795
Validation loss: 2.0396243320998324

Epoch: 6| Step: 6
Training loss: 2.186140298843384
Validation loss: 2.0273743573055474

Epoch: 6| Step: 7
Training loss: 1.8472890853881836
Validation loss: 2.0367310995696695

Epoch: 6| Step: 8
Training loss: 1.8512897491455078
Validation loss: 2.0341840546618224

Epoch: 6| Step: 9
Training loss: 2.311816453933716
Validation loss: 2.005107190019341

Epoch: 6| Step: 10
Training loss: 2.60760498046875
Validation loss: 2.0335154148840133

Epoch: 6| Step: 11
Training loss: 2.3468828201293945
Validation loss: 2.0304386551662157

Epoch: 6| Step: 12
Training loss: 2.1693191528320312
Validation loss: 2.017614492806055

Epoch: 6| Step: 13
Training loss: 2.7135190963745117
Validation loss: 2.0356998405148907

Epoch: 100| Step: 0
Training loss: 2.089864730834961
Validation loss: 2.020453776082685

Epoch: 6| Step: 1
Training loss: 2.2848949432373047
Validation loss: 2.0059688809097453

Epoch: 6| Step: 2
Training loss: 2.6695804595947266
Validation loss: 2.0301543217833324

Epoch: 6| Step: 3
Training loss: 1.8986153602600098
Validation loss: 2.012282520212153

Epoch: 6| Step: 4
Training loss: 2.37391996383667
Validation loss: 1.999554580257785

Epoch: 6| Step: 5
Training loss: 2.1654491424560547
Validation loss: 2.0180968135915776

Epoch: 6| Step: 6
Training loss: 2.050981044769287
Validation loss: 1.9964664930938392

Epoch: 6| Step: 7
Training loss: 1.7345993518829346
Validation loss: 1.9966061166537705

Epoch: 6| Step: 8
Training loss: 1.919324278831482
Validation loss: 1.9980203233739382

Epoch: 6| Step: 9
Training loss: 2.0565152168273926
Validation loss: 2.010956243802142

Epoch: 6| Step: 10
Training loss: 2.7837791442871094
Validation loss: 2.0019665918042584

Epoch: 6| Step: 11
Training loss: 2.3244214057922363
Validation loss: 1.9889278565683672

Epoch: 6| Step: 12
Training loss: 2.395759105682373
Validation loss: 1.9894534451987154

Epoch: 6| Step: 13
Training loss: 2.711177349090576
Validation loss: 1.983135486161837

Epoch: 101| Step: 0
Training loss: 2.4016876220703125
Validation loss: 1.989884182971011

Epoch: 6| Step: 1
Training loss: 2.193751335144043
Validation loss: 1.9731823346948112

Epoch: 6| Step: 2
Training loss: 1.8442113399505615
Validation loss: 2.0094976784080587

Epoch: 6| Step: 3
Training loss: 2.595475196838379
Validation loss: 1.990644843347611

Epoch: 6| Step: 4
Training loss: 1.8654364347457886
Validation loss: 2.0036986873995875

Epoch: 6| Step: 5
Training loss: 2.973615884780884
Validation loss: 1.9794561375853836

Epoch: 6| Step: 6
Training loss: 1.6189756393432617
Validation loss: 1.9997322110719578

Epoch: 6| Step: 7
Training loss: 2.678168773651123
Validation loss: 2.021205840572234

Epoch: 6| Step: 8
Training loss: 1.855870008468628
Validation loss: 2.022797151278424

Epoch: 6| Step: 9
Training loss: 2.472935199737549
Validation loss: 2.007173935572306

Epoch: 6| Step: 10
Training loss: 1.9746208190917969
Validation loss: 2.0015909056509695

Epoch: 6| Step: 11
Training loss: 2.109842300415039
Validation loss: 2.0254761403606785

Epoch: 6| Step: 12
Training loss: 2.388791084289551
Validation loss: 2.0362379409933604

Epoch: 6| Step: 13
Training loss: 2.8527822494506836
Validation loss: 2.0059917678115187

Epoch: 102| Step: 0
Training loss: 1.8250653743743896
Validation loss: 2.0090577153749365

Epoch: 6| Step: 1
Training loss: 2.4891505241394043
Validation loss: 2.0095090866088867

Epoch: 6| Step: 2
Training loss: 2.5435993671417236
Validation loss: 2.039237876092234

Epoch: 6| Step: 3
Training loss: 2.5731441974639893
Validation loss: 1.9975724515094553

Epoch: 6| Step: 4
Training loss: 2.6492042541503906
Validation loss: 2.0081111872068016

Epoch: 6| Step: 5
Training loss: 1.8014862537384033
Validation loss: 2.0136014748645086

Epoch: 6| Step: 6
Training loss: 2.629384994506836
Validation loss: 2.0130553168635212

Epoch: 6| Step: 7
Training loss: 1.6837494373321533
Validation loss: 2.0257139923751994

Epoch: 6| Step: 8
Training loss: 2.370238780975342
Validation loss: 2.04888633630609

Epoch: 6| Step: 9
Training loss: 2.2404956817626953
Validation loss: 2.0074199656004548

Epoch: 6| Step: 10
Training loss: 2.4362196922302246
Validation loss: 2.050340788338774

Epoch: 6| Step: 11
Training loss: 2.274820327758789
Validation loss: 2.013370793352845

Epoch: 6| Step: 12
Training loss: 2.392606258392334
Validation loss: 2.015076055321642

Epoch: 6| Step: 13
Training loss: 1.0476213693618774
Validation loss: 2.033275270974764

Epoch: 103| Step: 0
Training loss: 2.6188106536865234
Validation loss: 2.0087821586157686

Epoch: 6| Step: 1
Training loss: 2.2752766609191895
Validation loss: 2.0510823252380534

Epoch: 6| Step: 2
Training loss: 2.0297207832336426
Validation loss: 2.040094176928202

Epoch: 6| Step: 3
Training loss: 2.26853609085083
Validation loss: 2.033064209004884

Epoch: 6| Step: 4
Training loss: 2.086287021636963
Validation loss: 2.0460623028457805

Epoch: 6| Step: 5
Training loss: 2.284367322921753
Validation loss: 2.0556405539153726

Epoch: 6| Step: 6
Training loss: 2.6847152709960938
Validation loss: 2.017531564158778

Epoch: 6| Step: 7
Training loss: 2.3714139461517334
Validation loss: 2.037836241465743

Epoch: 6| Step: 8
Training loss: 2.1507515907287598
Validation loss: 2.0597879181626024

Epoch: 6| Step: 9
Training loss: 1.8990142345428467
Validation loss: 2.0516992602297055

Epoch: 6| Step: 10
Training loss: 1.9628028869628906
Validation loss: 2.0288024435761156

Epoch: 6| Step: 11
Training loss: 2.2627615928649902
Validation loss: 2.0137398499314503

Epoch: 6| Step: 12
Training loss: 2.5054092407226562
Validation loss: 2.0292354296612483

Epoch: 6| Step: 13
Training loss: 1.5728583335876465
Validation loss: 2.017650581175281

Epoch: 104| Step: 0
Training loss: 2.297132968902588
Validation loss: 2.012494461510771

Epoch: 6| Step: 1
Training loss: 2.244490385055542
Validation loss: 2.006363446994494

Epoch: 6| Step: 2
Training loss: 2.860361337661743
Validation loss: 2.0050069414159304

Epoch: 6| Step: 3
Training loss: 2.996894359588623
Validation loss: 2.0144175457698044

Epoch: 6| Step: 4
Training loss: 2.116213798522949
Validation loss: 1.9794090306887062

Epoch: 6| Step: 5
Training loss: 2.7754855155944824
Validation loss: 2.0116413665074173

Epoch: 6| Step: 6
Training loss: 1.795928955078125
Validation loss: 1.9802630883391186

Epoch: 6| Step: 7
Training loss: 2.262824535369873
Validation loss: 2.0107715334943546

Epoch: 6| Step: 8
Training loss: 2.3147056102752686
Validation loss: 1.9928534312914776

Epoch: 6| Step: 9
Training loss: 2.606564521789551
Validation loss: 2.026877728841638

Epoch: 6| Step: 10
Training loss: 2.1657357215881348
Validation loss: 2.0177957345080633

Epoch: 6| Step: 11
Training loss: 1.48667573928833
Validation loss: 1.979053581914594

Epoch: 6| Step: 12
Training loss: 1.424424648284912
Validation loss: 2.004283038518762

Epoch: 6| Step: 13
Training loss: 1.702517032623291
Validation loss: 2.0146935447569816

Epoch: 105| Step: 0
Training loss: 1.8613080978393555
Validation loss: 2.010532703450931

Epoch: 6| Step: 1
Training loss: 3.29449200630188
Validation loss: 1.9898622548708351

Epoch: 6| Step: 2
Training loss: 2.079448699951172
Validation loss: 2.0131756233912643

Epoch: 6| Step: 3
Training loss: 2.1702914237976074
Validation loss: 1.9808768200617966

Epoch: 6| Step: 4
Training loss: 2.2344040870666504
Validation loss: 2.0019652100019556

Epoch: 6| Step: 5
Training loss: 1.9618396759033203
Validation loss: 1.9909164726093251

Epoch: 6| Step: 6
Training loss: 1.966599702835083
Validation loss: 2.0125574501611854

Epoch: 6| Step: 7
Training loss: 2.177424430847168
Validation loss: 1.996117558530582

Epoch: 6| Step: 8
Training loss: 2.1921677589416504
Validation loss: 1.9938133173091437

Epoch: 6| Step: 9
Training loss: 2.276395320892334
Validation loss: 1.988779391011884

Epoch: 6| Step: 10
Training loss: 1.8008822202682495
Validation loss: 1.9960593895245624

Epoch: 6| Step: 11
Training loss: 2.4410147666931152
Validation loss: 1.9815292076397968

Epoch: 6| Step: 12
Training loss: 2.4611752033233643
Validation loss: 2.011733865225187

Epoch: 6| Step: 13
Training loss: 2.4514081478118896
Validation loss: 1.9611363513495332

Epoch: 106| Step: 0
Training loss: 2.229750394821167
Validation loss: 1.989092961434395

Epoch: 6| Step: 1
Training loss: 2.194127082824707
Validation loss: 1.98321924542868

Epoch: 6| Step: 2
Training loss: 1.467450499534607
Validation loss: 2.0047568864719842

Epoch: 6| Step: 3
Training loss: 2.6849312782287598
Validation loss: 2.0011752061946417

Epoch: 6| Step: 4
Training loss: 2.3052761554718018
Validation loss: 2.0031457652327833

Epoch: 6| Step: 5
Training loss: 2.5372085571289062
Validation loss: 2.028431425812424

Epoch: 6| Step: 6
Training loss: 2.754927158355713
Validation loss: 2.001822307545652

Epoch: 6| Step: 7
Training loss: 1.667891502380371
Validation loss: 2.0214936310245144

Epoch: 6| Step: 8
Training loss: 1.777595043182373
Validation loss: 2.0069775812087522

Epoch: 6| Step: 9
Training loss: 1.9106509685516357
Validation loss: 2.0123784477992723

Epoch: 6| Step: 10
Training loss: 2.638737201690674
Validation loss: 2.0101648633198073

Epoch: 6| Step: 11
Training loss: 2.3111274242401123
Validation loss: 1.9913939686231716

Epoch: 6| Step: 12
Training loss: 2.151012420654297
Validation loss: 2.0075332733892624

Epoch: 6| Step: 13
Training loss: 2.9319851398468018
Validation loss: 2.020323165001408

Epoch: 107| Step: 0
Training loss: 2.1048264503479004
Validation loss: 2.0251119341901553

Epoch: 6| Step: 1
Training loss: 1.9992468357086182
Validation loss: 2.0137361762344197

Epoch: 6| Step: 2
Training loss: 2.5541117191314697
Validation loss: 2.0408342756250852

Epoch: 6| Step: 3
Training loss: 2.006699323654175
Validation loss: 2.0521278945348596

Epoch: 6| Step: 4
Training loss: 2.237975597381592
Validation loss: 2.0219028611336984

Epoch: 6| Step: 5
Training loss: 2.195880651473999
Validation loss: 2.0592354561692927

Epoch: 6| Step: 6
Training loss: 1.9770538806915283
Validation loss: 2.0305004273691485

Epoch: 6| Step: 7
Training loss: 2.09429669380188
Validation loss: 2.0169284676992767

Epoch: 6| Step: 8
Training loss: 2.3679866790771484
Validation loss: 2.038654902929901

Epoch: 6| Step: 9
Training loss: 2.331023693084717
Validation loss: 2.027077724856715

Epoch: 6| Step: 10
Training loss: 2.5764036178588867
Validation loss: 2.036604250631025

Epoch: 6| Step: 11
Training loss: 2.1294915676116943
Validation loss: 2.038308364088817

Epoch: 6| Step: 12
Training loss: 2.11847186088562
Validation loss: 2.0487574428640385

Epoch: 6| Step: 13
Training loss: 2.8216450214385986
Validation loss: 2.0157376143240158

Epoch: 108| Step: 0
Training loss: 1.890317440032959
Validation loss: 2.0368857306818806

Epoch: 6| Step: 1
Training loss: 2.621824264526367
Validation loss: 2.034080946317283

Epoch: 6| Step: 2
Training loss: 2.0843656063079834
Validation loss: 2.0305398971803728

Epoch: 6| Step: 3
Training loss: 1.8281159400939941
Validation loss: 2.043462893014313

Epoch: 6| Step: 4
Training loss: 2.950927734375
Validation loss: 2.0224957696853147

Epoch: 6| Step: 5
Training loss: 1.6205532550811768
Validation loss: 2.0471039087541643

Epoch: 6| Step: 6
Training loss: 2.053304672241211
Validation loss: 2.0195189881068405

Epoch: 6| Step: 7
Training loss: 2.5061872005462646
Validation loss: 2.040015184751121

Epoch: 6| Step: 8
Training loss: 2.8154191970825195
Validation loss: 2.060871808759628

Epoch: 6| Step: 9
Training loss: 2.10196590423584
Validation loss: 2.0242641254137923

Epoch: 6| Step: 10
Training loss: 2.4227514266967773
Validation loss: 2.0109965391056512

Epoch: 6| Step: 11
Training loss: 1.8443217277526855
Validation loss: 2.0072567744921614

Epoch: 6| Step: 12
Training loss: 2.4876132011413574
Validation loss: 2.0330982541525238

Epoch: 6| Step: 13
Training loss: 2.0780816078186035
Validation loss: 2.032344574569374

Epoch: 109| Step: 0
Training loss: 2.3500730991363525
Validation loss: 2.0205879083243747

Epoch: 6| Step: 1
Training loss: 2.406270980834961
Validation loss: 2.019140041002663

Epoch: 6| Step: 2
Training loss: 2.2322611808776855
Validation loss: 2.01566368661901

Epoch: 6| Step: 3
Training loss: 1.8845478296279907
Validation loss: 2.0142106843251053

Epoch: 6| Step: 4
Training loss: 1.6225415468215942
Validation loss: 2.0125609367124495

Epoch: 6| Step: 5
Training loss: 2.220186710357666
Validation loss: 2.014707751171563

Epoch: 6| Step: 6
Training loss: 2.683189868927002
Validation loss: 2.0510304320243096

Epoch: 6| Step: 7
Training loss: 2.1212778091430664
Validation loss: 2.0020797855110577

Epoch: 6| Step: 8
Training loss: 2.654679775238037
Validation loss: 2.0131337514487644

Epoch: 6| Step: 9
Training loss: 1.7745088338851929
Validation loss: 2.022054608150195

Epoch: 6| Step: 10
Training loss: 2.7019572257995605
Validation loss: 2.0223635063376477

Epoch: 6| Step: 11
Training loss: 2.0613136291503906
Validation loss: 2.0386380995473554

Epoch: 6| Step: 12
Training loss: 1.9156525135040283
Validation loss: 2.0401694774627686

Epoch: 6| Step: 13
Training loss: 2.852585792541504
Validation loss: 2.026362563974114

Epoch: 110| Step: 0
Training loss: 2.3349194526672363
Validation loss: 2.0126947690081853

Epoch: 6| Step: 1
Training loss: 2.7222414016723633
Validation loss: 2.0129976580219884

Epoch: 6| Step: 2
Training loss: 2.133242607116699
Validation loss: 2.0201425578004573

Epoch: 6| Step: 3
Training loss: 1.8466668128967285
Validation loss: 2.0239290550190914

Epoch: 6| Step: 4
Training loss: 2.3569397926330566
Validation loss: 2.022892713546753

Epoch: 6| Step: 5
Training loss: 2.323678493499756
Validation loss: 2.032328506951691

Epoch: 6| Step: 6
Training loss: 2.53981876373291
Validation loss: 1.9997665625746532

Epoch: 6| Step: 7
Training loss: 1.8147916793823242
Validation loss: 2.022496433668239

Epoch: 6| Step: 8
Training loss: 2.1285834312438965
Validation loss: 2.037413776561778

Epoch: 6| Step: 9
Training loss: 2.322366714477539
Validation loss: 2.043041858621823

Epoch: 6| Step: 10
Training loss: 1.2839187383651733
Validation loss: 2.027240668573687

Epoch: 6| Step: 11
Training loss: 2.562946319580078
Validation loss: 2.0246988650291198

Epoch: 6| Step: 12
Training loss: 2.385708808898926
Validation loss: 2.035845443766604

Epoch: 6| Step: 13
Training loss: 2.374617576599121
Validation loss: 2.0108434961688135

Epoch: 111| Step: 0
Training loss: 2.507450580596924
Validation loss: 2.012577636267549

Epoch: 6| Step: 1
Training loss: 2.5496606826782227
Validation loss: 2.048670830265168

Epoch: 6| Step: 2
Training loss: 2.1368408203125
Validation loss: 2.0390362637017363

Epoch: 6| Step: 3
Training loss: 2.6242356300354004
Validation loss: 2.0339975921056603

Epoch: 6| Step: 4
Training loss: 2.1588492393493652
Validation loss: 2.0431367735708914

Epoch: 6| Step: 5
Training loss: 2.2796239852905273
Validation loss: 2.006874310073032

Epoch: 6| Step: 6
Training loss: 2.509676456451416
Validation loss: 2.0148006921173423

Epoch: 6| Step: 7
Training loss: 1.8236067295074463
Validation loss: 2.0302612576433408

Epoch: 6| Step: 8
Training loss: 2.1292357444763184
Validation loss: 2.022224008396108

Epoch: 6| Step: 9
Training loss: 2.341465473175049
Validation loss: 2.022968312745453

Epoch: 6| Step: 10
Training loss: 1.818061351776123
Validation loss: 2.038171773315758

Epoch: 6| Step: 11
Training loss: 1.6259523630142212
Validation loss: 2.036931937740695

Epoch: 6| Step: 12
Training loss: 2.2044119834899902
Validation loss: 2.034789582734467

Epoch: 6| Step: 13
Training loss: 2.663405179977417
Validation loss: 2.041126492202923

Epoch: 112| Step: 0
Training loss: 2.222499132156372
Validation loss: 2.036733546564656

Epoch: 6| Step: 1
Training loss: 2.3069825172424316
Validation loss: 2.039004668112724

Epoch: 6| Step: 2
Training loss: 2.1391067504882812
Validation loss: 2.025726656759939

Epoch: 6| Step: 3
Training loss: 1.8256562948226929
Validation loss: 2.0471799194171862

Epoch: 6| Step: 4
Training loss: 2.083556652069092
Validation loss: 2.022629322544221

Epoch: 6| Step: 5
Training loss: 1.994667410850525
Validation loss: 2.039602102771882

Epoch: 6| Step: 6
Training loss: 2.273193836212158
Validation loss: 2.0308631286826184

Epoch: 6| Step: 7
Training loss: 2.589521884918213
Validation loss: 2.0140077606324227

Epoch: 6| Step: 8
Training loss: 2.223235607147217
Validation loss: 2.023350178554494

Epoch: 6| Step: 9
Training loss: 1.9422452449798584
Validation loss: 2.0260052065695486

Epoch: 6| Step: 10
Training loss: 2.903167724609375
Validation loss: 2.0382103086799703

Epoch: 6| Step: 11
Training loss: 1.9177899360656738
Validation loss: 2.032884786205907

Epoch: 6| Step: 12
Training loss: 2.259512424468994
Validation loss: 2.024806930172828

Epoch: 6| Step: 13
Training loss: 2.6637587547302246
Validation loss: 2.020780204444803

Epoch: 113| Step: 0
Training loss: 2.0400660037994385
Validation loss: 2.0376016401475474

Epoch: 6| Step: 1
Training loss: 2.1345372200012207
Validation loss: 2.0228318347725818

Epoch: 6| Step: 2
Training loss: 2.2874691486358643
Validation loss: 2.0487951117177166

Epoch: 6| Step: 3
Training loss: 2.1844234466552734
Validation loss: 2.0377715223579

Epoch: 6| Step: 4
Training loss: 2.485175371170044
Validation loss: 2.018526256725352

Epoch: 6| Step: 5
Training loss: 1.613342046737671
Validation loss: 2.0181408377103907

Epoch: 6| Step: 6
Training loss: 2.799102306365967
Validation loss: 2.007340887541412

Epoch: 6| Step: 7
Training loss: 1.9319767951965332
Validation loss: 2.018917945123488

Epoch: 6| Step: 8
Training loss: 2.1746673583984375
Validation loss: 2.018029756443475

Epoch: 6| Step: 9
Training loss: 1.5830678939819336
Validation loss: 2.010014034086658

Epoch: 6| Step: 10
Training loss: 2.43900203704834
Validation loss: 2.01932986961898

Epoch: 6| Step: 11
Training loss: 2.4680864810943604
Validation loss: 2.025141946731075

Epoch: 6| Step: 12
Training loss: 2.610720157623291
Validation loss: 1.9970829948302238

Epoch: 6| Step: 13
Training loss: 2.450993537902832
Validation loss: 2.0105537522223687

Epoch: 114| Step: 0
Training loss: 1.6618114709854126
Validation loss: 2.011665951821112

Epoch: 6| Step: 1
Training loss: 1.570091724395752
Validation loss: 2.012804139044977

Epoch: 6| Step: 2
Training loss: 1.8215386867523193
Validation loss: 2.020700772603353

Epoch: 6| Step: 3
Training loss: 2.2796578407287598
Validation loss: 2.023238565332146

Epoch: 6| Step: 4
Training loss: 2.5415537357330322
Validation loss: 2.006207327688894

Epoch: 6| Step: 5
Training loss: 3.421988010406494
Validation loss: 2.0185234931207474

Epoch: 6| Step: 6
Training loss: 2.121175765991211
Validation loss: 2.0266407715376986

Epoch: 6| Step: 7
Training loss: 1.6136289834976196
Validation loss: 2.010390507277622

Epoch: 6| Step: 8
Training loss: 2.533315658569336
Validation loss: 2.007088586848269

Epoch: 6| Step: 9
Training loss: 2.854362726211548
Validation loss: 2.0041019762715986

Epoch: 6| Step: 10
Training loss: 1.6457589864730835
Validation loss: 2.006324965466735

Epoch: 6| Step: 11
Training loss: 2.76009464263916
Validation loss: 1.985464499842736

Epoch: 6| Step: 12
Training loss: 2.494359016418457
Validation loss: 2.0240952302050847

Epoch: 6| Step: 13
Training loss: 1.6433889865875244
Validation loss: 2.028544299064144

Epoch: 115| Step: 0
Training loss: 1.4940266609191895
Validation loss: 2.007633416883407

Epoch: 6| Step: 1
Training loss: 2.734118700027466
Validation loss: 2.037138558203174

Epoch: 6| Step: 2
Training loss: 2.258228063583374
Validation loss: 2.017396294942466

Epoch: 6| Step: 3
Training loss: 2.178227424621582
Validation loss: 1.9916872888483026

Epoch: 6| Step: 4
Training loss: 1.7910327911376953
Validation loss: 2.010783008349839

Epoch: 6| Step: 5
Training loss: 2.498051643371582
Validation loss: 2.0162986452861498

Epoch: 6| Step: 6
Training loss: 1.5190882682800293
Validation loss: 2.019543766975403

Epoch: 6| Step: 7
Training loss: 2.719102382659912
Validation loss: 2.0201935639945408

Epoch: 6| Step: 8
Training loss: 2.876394748687744
Validation loss: 2.014043482401038

Epoch: 6| Step: 9
Training loss: 2.0547409057617188
Validation loss: 2.011388655631773

Epoch: 6| Step: 10
Training loss: 2.7665061950683594
Validation loss: 2.0170108631093013

Epoch: 6| Step: 11
Training loss: 1.951429843902588
Validation loss: 2.0190220186787267

Epoch: 6| Step: 12
Training loss: 2.5076537132263184
Validation loss: 2.048151636636385

Epoch: 6| Step: 13
Training loss: 1.2395278215408325
Validation loss: 2.0099508147085867

Epoch: 116| Step: 0
Training loss: 2.506145715713501
Validation loss: 2.0164878394014094

Epoch: 6| Step: 1
Training loss: 3.170327663421631
Validation loss: 2.0170427919715963

Epoch: 6| Step: 2
Training loss: 2.395595073699951
Validation loss: 2.016018888001801

Epoch: 6| Step: 3
Training loss: 1.9038015604019165
Validation loss: 2.0223711946959138

Epoch: 6| Step: 4
Training loss: 1.6039772033691406
Validation loss: 1.9869550146082395

Epoch: 6| Step: 5
Training loss: 2.0976948738098145
Validation loss: 2.0120905701832106

Epoch: 6| Step: 6
Training loss: 2.506429672241211
Validation loss: 1.9928320953922887

Epoch: 6| Step: 7
Training loss: 2.1148810386657715
Validation loss: 2.0073399133579706

Epoch: 6| Step: 8
Training loss: 1.9755163192749023
Validation loss: 1.980832871570382

Epoch: 6| Step: 9
Training loss: 2.107968807220459
Validation loss: 2.001799366807425

Epoch: 6| Step: 10
Training loss: 2.2067580223083496
Validation loss: 2.0039481706516717

Epoch: 6| Step: 11
Training loss: 2.4677767753601074
Validation loss: 2.0077157610206195

Epoch: 6| Step: 12
Training loss: 2.2332816123962402
Validation loss: 2.013281323576486

Epoch: 6| Step: 13
Training loss: 1.5411735773086548
Validation loss: 1.9889886738151632

Epoch: 117| Step: 0
Training loss: 2.955946922302246
Validation loss: 2.021389074223016

Epoch: 6| Step: 1
Training loss: 2.1262452602386475
Validation loss: 2.019489412666649

Epoch: 6| Step: 2
Training loss: 2.1503820419311523
Validation loss: 2.030569912284933

Epoch: 6| Step: 3
Training loss: 2.153451442718506
Validation loss: 2.027095446022608

Epoch: 6| Step: 4
Training loss: 1.713226556777954
Validation loss: 2.0091275451003865

Epoch: 6| Step: 5
Training loss: 2.1078338623046875
Validation loss: 2.02831393800756

Epoch: 6| Step: 6
Training loss: 1.7416367530822754
Validation loss: 2.0367935178100423

Epoch: 6| Step: 7
Training loss: 2.6082329750061035
Validation loss: 2.029205882421104

Epoch: 6| Step: 8
Training loss: 2.3726584911346436
Validation loss: 2.0586716385297876

Epoch: 6| Step: 9
Training loss: 1.5856547355651855
Validation loss: 2.0346369922802015

Epoch: 6| Step: 10
Training loss: 2.119594097137451
Validation loss: 2.042938550313314

Epoch: 6| Step: 11
Training loss: 2.483494758605957
Validation loss: 2.0437399930851434

Epoch: 6| Step: 12
Training loss: 2.423126220703125
Validation loss: 2.0385610775281022

Epoch: 6| Step: 13
Training loss: 2.979022264480591
Validation loss: 2.0120085952102498

Epoch: 118| Step: 0
Training loss: 1.9468530416488647
Validation loss: 2.05270609676197

Epoch: 6| Step: 1
Training loss: 2.901184558868408
Validation loss: 2.022644253187282

Epoch: 6| Step: 2
Training loss: 2.7364282608032227
Validation loss: 2.0433774814810803

Epoch: 6| Step: 3
Training loss: 2.023024559020996
Validation loss: 2.0260994588175127

Epoch: 6| Step: 4
Training loss: 1.9972814321517944
Validation loss: 2.0382243356397076

Epoch: 6| Step: 5
Training loss: 2.254061222076416
Validation loss: 2.0171930802765714

Epoch: 6| Step: 6
Training loss: 2.5155954360961914
Validation loss: 2.0137822448566394

Epoch: 6| Step: 7
Training loss: 2.2490875720977783
Validation loss: 2.0277080317979217

Epoch: 6| Step: 8
Training loss: 2.277165412902832
Validation loss: 2.0298787445150395

Epoch: 6| Step: 9
Training loss: 2.289832830429077
Validation loss: 2.003206476088493

Epoch: 6| Step: 10
Training loss: 1.5737779140472412
Validation loss: 2.0186921294017504

Epoch: 6| Step: 11
Training loss: 1.6125996112823486
Validation loss: 2.023628547627439

Epoch: 6| Step: 12
Training loss: 2.271764039993286
Validation loss: 2.027179353980608

Epoch: 6| Step: 13
Training loss: 2.658618688583374
Validation loss: 2.042435088465291

Epoch: 119| Step: 0
Training loss: 2.5597996711730957
Validation loss: 2.0235431412214875

Epoch: 6| Step: 1
Training loss: 2.3091588020324707
Validation loss: 2.0191837510754986

Epoch: 6| Step: 2
Training loss: 2.1698994636535645
Validation loss: 2.0102010183436896

Epoch: 6| Step: 3
Training loss: 1.8550844192504883
Validation loss: 2.0465537489101453

Epoch: 6| Step: 4
Training loss: 2.2595388889312744
Validation loss: 2.0432467229904665

Epoch: 6| Step: 5
Training loss: 2.5500380992889404
Validation loss: 2.0140747767622753

Epoch: 6| Step: 6
Training loss: 2.781113386154175
Validation loss: 2.035122735525972

Epoch: 6| Step: 7
Training loss: 1.7546437978744507
Validation loss: 2.0284620651634793

Epoch: 6| Step: 8
Training loss: 2.4435079097747803
Validation loss: 2.036016648815524

Epoch: 6| Step: 9
Training loss: 2.0931396484375
Validation loss: 2.028959375555797

Epoch: 6| Step: 10
Training loss: 1.7393157482147217
Validation loss: 2.012797996562014

Epoch: 6| Step: 11
Training loss: 1.6937392950057983
Validation loss: 2.011599636846973

Epoch: 6| Step: 12
Training loss: 2.52923321723938
Validation loss: 2.0142231372094925

Epoch: 6| Step: 13
Training loss: 2.843390464782715
Validation loss: 2.0177876180218113

Epoch: 120| Step: 0
Training loss: 1.9918174743652344
Validation loss: 2.020459359691989

Epoch: 6| Step: 1
Training loss: 1.543158769607544
Validation loss: 2.023344325762923

Epoch: 6| Step: 2
Training loss: 2.0830843448638916
Validation loss: 2.0401234819043066

Epoch: 6| Step: 3
Training loss: 1.8974798917770386
Validation loss: 2.0306714939814743

Epoch: 6| Step: 4
Training loss: 2.38818097114563
Validation loss: 2.034121790239888

Epoch: 6| Step: 5
Training loss: 1.990673542022705
Validation loss: 2.0218157011975526

Epoch: 6| Step: 6
Training loss: 2.038836717605591
Validation loss: 2.0161659640650593

Epoch: 6| Step: 7
Training loss: 2.509676694869995
Validation loss: 2.035155132252683

Epoch: 6| Step: 8
Training loss: 2.5926458835601807
Validation loss: 2.0231001787288214

Epoch: 6| Step: 9
Training loss: 2.1522789001464844
Validation loss: 2.0465435238294702

Epoch: 6| Step: 10
Training loss: 2.499346971511841
Validation loss: 2.0201802663905646

Epoch: 6| Step: 11
Training loss: 2.3456339836120605
Validation loss: 2.0200926462809243

Epoch: 6| Step: 12
Training loss: 3.255850315093994
Validation loss: 2.0145850719944125

Epoch: 6| Step: 13
Training loss: 1.5989243984222412
Validation loss: 2.0395609563396824

Epoch: 121| Step: 0
Training loss: 2.205465793609619
Validation loss: 2.0262916882832847

Epoch: 6| Step: 1
Training loss: 2.0697832107543945
Validation loss: 1.997468053653676

Epoch: 6| Step: 2
Training loss: 2.5273983478546143
Validation loss: 2.017158676219243

Epoch: 6| Step: 3
Training loss: 2.371501922607422
Validation loss: 2.0326993542332805

Epoch: 6| Step: 4
Training loss: 1.8589816093444824
Validation loss: 2.0114164634417464

Epoch: 6| Step: 5
Training loss: 2.3009605407714844
Validation loss: 2.052076716576853

Epoch: 6| Step: 6
Training loss: 2.058034658432007
Validation loss: 2.0165676506616736

Epoch: 6| Step: 7
Training loss: 2.1450178623199463
Validation loss: 2.0246278162925475

Epoch: 6| Step: 8
Training loss: 2.062755584716797
Validation loss: 2.0410974333363194

Epoch: 6| Step: 9
Training loss: 2.7745394706726074
Validation loss: 2.000747303808889

Epoch: 6| Step: 10
Training loss: 1.902921438217163
Validation loss: 2.01837242803266

Epoch: 6| Step: 11
Training loss: 2.858264923095703
Validation loss: 2.03499557382317

Epoch: 6| Step: 12
Training loss: 2.317434072494507
Validation loss: 2.0076557282478578

Epoch: 6| Step: 13
Training loss: 1.3153518438339233
Validation loss: 2.0125971507000666

Epoch: 122| Step: 0
Training loss: 2.9226584434509277
Validation loss: 2.032297170290383

Epoch: 6| Step: 1
Training loss: 2.1411705017089844
Validation loss: 2.0478971081395305

Epoch: 6| Step: 2
Training loss: 2.066188335418701
Validation loss: 2.0080884272052395

Epoch: 6| Step: 3
Training loss: 1.686469554901123
Validation loss: 1.992584482316048

Epoch: 6| Step: 4
Training loss: 2.4146809577941895
Validation loss: 2.0400913056506904

Epoch: 6| Step: 5
Training loss: 1.8780425786972046
Validation loss: 2.0306804590327765

Epoch: 6| Step: 6
Training loss: 1.840149164199829
Validation loss: 2.0264961591330906

Epoch: 6| Step: 7
Training loss: 2.5014562606811523
Validation loss: 2.0251580592124694

Epoch: 6| Step: 8
Training loss: 2.226766347885132
Validation loss: 2.0007171784677813

Epoch: 6| Step: 9
Training loss: 2.5013747215270996
Validation loss: 2.0119292274598153

Epoch: 6| Step: 10
Training loss: 1.9330166578292847
Validation loss: 1.9933390540461386

Epoch: 6| Step: 11
Training loss: 2.6921138763427734
Validation loss: 2.0043285405764015

Epoch: 6| Step: 12
Training loss: 1.9133355617523193
Validation loss: 2.0090010909624

Epoch: 6| Step: 13
Training loss: 2.457825183868408
Validation loss: 1.9976549007559334

Epoch: 123| Step: 0
Training loss: 1.7009620666503906
Validation loss: 2.011326143818517

Epoch: 6| Step: 1
Training loss: 2.307455062866211
Validation loss: 2.0040993177762596

Epoch: 6| Step: 2
Training loss: 1.6681880950927734
Validation loss: 2.0206629448039557

Epoch: 6| Step: 3
Training loss: 2.5442538261413574
Validation loss: 2.009687260914874

Epoch: 6| Step: 4
Training loss: 2.0262062549591064
Validation loss: 1.989973509183494

Epoch: 6| Step: 5
Training loss: 2.704216718673706
Validation loss: 2.005595555869482

Epoch: 6| Step: 6
Training loss: 2.634045124053955
Validation loss: 2.022068715864612

Epoch: 6| Step: 7
Training loss: 1.3451380729675293
Validation loss: 2.0009630392956477

Epoch: 6| Step: 8
Training loss: 2.2528128623962402
Validation loss: 2.025493867935673

Epoch: 6| Step: 9
Training loss: 1.5975124835968018
Validation loss: 2.0042871505983415

Epoch: 6| Step: 10
Training loss: 2.80051851272583
Validation loss: 1.979016593707505

Epoch: 6| Step: 11
Training loss: 3.0363330841064453
Validation loss: 2.023829011506932

Epoch: 6| Step: 12
Training loss: 1.7528462409973145
Validation loss: 2.0047860735206195

Epoch: 6| Step: 13
Training loss: 2.967169761657715
Validation loss: 1.9939714734272291

Epoch: 124| Step: 0
Training loss: 2.312603712081909
Validation loss: 2.0061342459852978

Epoch: 6| Step: 1
Training loss: 1.3972889184951782
Validation loss: 2.011227987145865

Epoch: 6| Step: 2
Training loss: 2.228524923324585
Validation loss: 2.0332575100724415

Epoch: 6| Step: 3
Training loss: 2.389699935913086
Validation loss: 2.027353859716846

Epoch: 6| Step: 4
Training loss: 1.637338638305664
Validation loss: 1.9855236648231425

Epoch: 6| Step: 5
Training loss: 2.9597716331481934
Validation loss: 2.000801399189939

Epoch: 6| Step: 6
Training loss: 1.911517858505249
Validation loss: 2.017275848696309

Epoch: 6| Step: 7
Training loss: 2.3633437156677246
Validation loss: 2.0068138504541047

Epoch: 6| Step: 8
Training loss: 2.274857759475708
Validation loss: 2.0102306078839045

Epoch: 6| Step: 9
Training loss: 2.338674545288086
Validation loss: 1.9987066304811867

Epoch: 6| Step: 10
Training loss: 1.942702054977417
Validation loss: 2.0114118040248914

Epoch: 6| Step: 11
Training loss: 2.816396951675415
Validation loss: 2.0191448196288078

Epoch: 6| Step: 12
Training loss: 2.113159656524658
Validation loss: 1.9986633869909471

Epoch: 6| Step: 13
Training loss: 2.1354284286499023
Validation loss: 2.0208503661617154

Epoch: 125| Step: 0
Training loss: 2.2558369636535645
Validation loss: 2.0013049981927358

Epoch: 6| Step: 1
Training loss: 2.1203577518463135
Validation loss: 2.0140144325071767

Epoch: 6| Step: 2
Training loss: 1.482602834701538
Validation loss: 2.0329681365720687

Epoch: 6| Step: 3
Training loss: 2.5370798110961914
Validation loss: 2.000214071683986

Epoch: 6| Step: 4
Training loss: 2.258403778076172
Validation loss: 2.023397634106298

Epoch: 6| Step: 5
Training loss: 2.136308193206787
Validation loss: 2.021853188032745

Epoch: 6| Step: 6
Training loss: 2.189234733581543
Validation loss: 2.025355387759465

Epoch: 6| Step: 7
Training loss: 1.884296178817749
Validation loss: 2.0225311991988972

Epoch: 6| Step: 8
Training loss: 2.366940498352051
Validation loss: 2.0105661435793807

Epoch: 6| Step: 9
Training loss: 2.0345401763916016
Validation loss: 2.0378864913858394

Epoch: 6| Step: 10
Training loss: 1.8681297302246094
Validation loss: 2.036939009543388

Epoch: 6| Step: 11
Training loss: 3.191842794418335
Validation loss: 2.0351498460256927

Epoch: 6| Step: 12
Training loss: 2.3481249809265137
Validation loss: 2.0194444476917224

Epoch: 6| Step: 13
Training loss: 2.412261486053467
Validation loss: 2.026352390166252

Epoch: 126| Step: 0
Training loss: 1.8612735271453857
Validation loss: 2.0194938362285657

Epoch: 6| Step: 1
Training loss: 1.7518364191055298
Validation loss: 2.014313554251066

Epoch: 6| Step: 2
Training loss: 1.8750133514404297
Validation loss: 2.0221761811164116

Epoch: 6| Step: 3
Training loss: 3.2514615058898926
Validation loss: 2.031187052367836

Epoch: 6| Step: 4
Training loss: 3.0482771396636963
Validation loss: 2.0077998022879324

Epoch: 6| Step: 5
Training loss: 2.421724796295166
Validation loss: 2.017780118091132

Epoch: 6| Step: 6
Training loss: 1.750394582748413
Validation loss: 1.9845857479239022

Epoch: 6| Step: 7
Training loss: 1.9595344066619873
Validation loss: 1.9887244086111746

Epoch: 6| Step: 8
Training loss: 1.9475414752960205
Validation loss: 2.031290358112704

Epoch: 6| Step: 9
Training loss: 1.8062344789505005
Validation loss: 2.0162653051396853

Epoch: 6| Step: 10
Training loss: 2.770763397216797
Validation loss: 2.016159124271844

Epoch: 6| Step: 11
Training loss: 2.024134397506714
Validation loss: 2.0233951409657798

Epoch: 6| Step: 12
Training loss: 2.40791916847229
Validation loss: 2.0105085372924805

Epoch: 6| Step: 13
Training loss: 1.983307957649231
Validation loss: 2.029873473669893

Epoch: 127| Step: 0
Training loss: 3.2641913890838623
Validation loss: 2.0253748304100445

Epoch: 6| Step: 1
Training loss: 1.0698318481445312
Validation loss: 2.019473356585349

Epoch: 6| Step: 2
Training loss: 2.0988762378692627
Validation loss: 2.0209952259576447

Epoch: 6| Step: 3
Training loss: 2.696200370788574
Validation loss: 1.9988017441124044

Epoch: 6| Step: 4
Training loss: 1.70046865940094
Validation loss: 2.0164731651224117

Epoch: 6| Step: 5
Training loss: 2.464240074157715
Validation loss: 2.0172037783489434

Epoch: 6| Step: 6
Training loss: 2.817349672317505
Validation loss: 2.0200458598393265

Epoch: 6| Step: 7
Training loss: 1.408463716506958
Validation loss: 2.0185079318220898

Epoch: 6| Step: 8
Training loss: 2.107785701751709
Validation loss: 2.0060948800015193

Epoch: 6| Step: 9
Training loss: 2.0128238201141357
Validation loss: 2.0354819208063106

Epoch: 6| Step: 10
Training loss: 2.696580648422241
Validation loss: 2.0025413805438625

Epoch: 6| Step: 11
Training loss: 2.1182010173797607
Validation loss: 2.0127060451815204

Epoch: 6| Step: 12
Training loss: 2.4185938835144043
Validation loss: 2.0127913054599555

Epoch: 6| Step: 13
Training loss: 1.8344001770019531
Validation loss: 2.0158377014180666

Epoch: 128| Step: 0
Training loss: 2.9282209873199463
Validation loss: 2.0132707267679195

Epoch: 6| Step: 1
Training loss: 2.543612480163574
Validation loss: 2.0247376593210364

Epoch: 6| Step: 2
Training loss: 2.3816957473754883
Validation loss: 2.0312187440933718

Epoch: 6| Step: 3
Training loss: 2.1943001747131348
Validation loss: 2.0100391116193546

Epoch: 6| Step: 4
Training loss: 1.8589413166046143
Validation loss: 2.008792741324312

Epoch: 6| Step: 5
Training loss: 2.193187713623047
Validation loss: 2.002594394068564

Epoch: 6| Step: 6
Training loss: 2.260575532913208
Validation loss: 2.0031336661308043

Epoch: 6| Step: 7
Training loss: 3.177699565887451
Validation loss: 1.9823909203211467

Epoch: 6| Step: 8
Training loss: 1.9737329483032227
Validation loss: 1.9928170122126097

Epoch: 6| Step: 9
Training loss: 2.335103988647461
Validation loss: 2.015511005155502

Epoch: 6| Step: 10
Training loss: 1.790832757949829
Validation loss: 2.0239413374213764

Epoch: 6| Step: 11
Training loss: 2.0421359539031982
Validation loss: 1.9828792361802952

Epoch: 6| Step: 12
Training loss: 1.6533501148223877
Validation loss: 2.0176124957300003

Epoch: 6| Step: 13
Training loss: 1.0912469625473022
Validation loss: 2.0278390197343725

Epoch: 129| Step: 0
Training loss: 2.0450022220611572
Validation loss: 1.997393177401635

Epoch: 6| Step: 1
Training loss: 1.6411106586456299
Validation loss: 2.037958563015025

Epoch: 6| Step: 2
Training loss: 2.1351399421691895
Validation loss: 2.0232574516727078

Epoch: 6| Step: 3
Training loss: 2.282341241836548
Validation loss: 2.040796136343351

Epoch: 6| Step: 4
Training loss: 2.624570846557617
Validation loss: 2.0237245123873473

Epoch: 6| Step: 5
Training loss: 2.1417737007141113
Validation loss: 2.0480663161123953

Epoch: 6| Step: 6
Training loss: 1.9587470293045044
Validation loss: 2.0525704801723523

Epoch: 6| Step: 7
Training loss: 2.115492105484009
Validation loss: 2.039442685342604

Epoch: 6| Step: 8
Training loss: 2.739016056060791
Validation loss: 2.023133295838551

Epoch: 6| Step: 9
Training loss: 2.2194247245788574
Validation loss: 2.062640574670607

Epoch: 6| Step: 10
Training loss: 2.291292667388916
Validation loss: 2.0377178089593047

Epoch: 6| Step: 11
Training loss: 2.2859458923339844
Validation loss: 2.050209214610438

Epoch: 6| Step: 12
Training loss: 2.4724271297454834
Validation loss: 2.0761285148641115

Epoch: 6| Step: 13
Training loss: 1.8636183738708496
Validation loss: 2.0565245382247435

Epoch: 130| Step: 0
Training loss: 2.550887107849121
Validation loss: 2.077544435378044

Epoch: 6| Step: 1
Training loss: 2.313206434249878
Validation loss: 2.0481610490429785

Epoch: 6| Step: 2
Training loss: 2.552849769592285
Validation loss: 2.029185072068245

Epoch: 6| Step: 3
Training loss: 2.499464511871338
Validation loss: 2.0393097246846845

Epoch: 6| Step: 4
Training loss: 1.419569730758667
Validation loss: 2.0580473561440744

Epoch: 6| Step: 5
Training loss: 1.8882371187210083
Validation loss: 2.0681579395007064

Epoch: 6| Step: 6
Training loss: 2.1363940238952637
Validation loss: 2.0285838175845403

Epoch: 6| Step: 7
Training loss: 2.1365771293640137
Validation loss: 2.020641424322641

Epoch: 6| Step: 8
Training loss: 2.3827662467956543
Validation loss: 2.0435488300938762

Epoch: 6| Step: 9
Training loss: 2.275845527648926
Validation loss: 2.0588076242836575

Epoch: 6| Step: 10
Training loss: 1.807711124420166
Validation loss: 2.045772207680569

Epoch: 6| Step: 11
Training loss: 2.67620849609375
Validation loss: 2.0039065832732827

Epoch: 6| Step: 12
Training loss: 2.263978958129883
Validation loss: 2.0525318114988265

Epoch: 6| Step: 13
Training loss: 1.8137274980545044
Validation loss: 2.0299033477742183

Epoch: 131| Step: 0
Training loss: 1.3921425342559814
Validation loss: 2.038259188334147

Epoch: 6| Step: 1
Training loss: 2.3909740447998047
Validation loss: 2.01303219667045

Epoch: 6| Step: 2
Training loss: 2.878805637359619
Validation loss: 2.041949472119731

Epoch: 6| Step: 3
Training loss: 2.936023235321045
Validation loss: 2.038236964133478

Epoch: 6| Step: 4
Training loss: 2.695143222808838
Validation loss: 2.020812508880451

Epoch: 6| Step: 5
Training loss: 1.5489732027053833
Validation loss: 2.022411325926422

Epoch: 6| Step: 6
Training loss: 1.8993605375289917
Validation loss: 2.023977792391213

Epoch: 6| Step: 7
Training loss: 2.70225191116333
Validation loss: 2.020441564180518

Epoch: 6| Step: 8
Training loss: 1.6567249298095703
Validation loss: 2.02559232711792

Epoch: 6| Step: 9
Training loss: 2.6325485706329346
Validation loss: 1.9985425984987648

Epoch: 6| Step: 10
Training loss: 2.6456754207611084
Validation loss: 2.020515985386346

Epoch: 6| Step: 11
Training loss: 2.091610908508301
Validation loss: 2.0324707364523285

Epoch: 6| Step: 12
Training loss: 1.502865195274353
Validation loss: 2.015794082354474

Epoch: 6| Step: 13
Training loss: 1.7915899753570557
Validation loss: 2.0206677990574993

Epoch: 132| Step: 0
Training loss: 1.691962718963623
Validation loss: 2.020915315997216

Epoch: 6| Step: 1
Training loss: 2.371159076690674
Validation loss: 2.033898256158316

Epoch: 6| Step: 2
Training loss: 1.8965826034545898
Validation loss: 2.0267202879792903

Epoch: 6| Step: 3
Training loss: 2.261333703994751
Validation loss: 2.020639354182828

Epoch: 6| Step: 4
Training loss: 2.1607580184936523
Validation loss: 2.0135644994756228

Epoch: 6| Step: 5
Training loss: 1.7984137535095215
Validation loss: 2.01229424886806

Epoch: 6| Step: 6
Training loss: 1.9678478240966797
Validation loss: 2.0279698692342287

Epoch: 6| Step: 7
Training loss: 1.6858112812042236
Validation loss: 2.0054701476968746

Epoch: 6| Step: 8
Training loss: 2.386265277862549
Validation loss: 2.034492766985329

Epoch: 6| Step: 9
Training loss: 2.7167725563049316
Validation loss: 2.005694117597354

Epoch: 6| Step: 10
Training loss: 2.4262032508850098
Validation loss: 2.042931338792206

Epoch: 6| Step: 11
Training loss: 1.8766385316848755
Validation loss: 2.0012191393042125

Epoch: 6| Step: 12
Training loss: 3.0215086936950684
Validation loss: 2.030290117827795

Epoch: 6| Step: 13
Training loss: 2.406107187271118
Validation loss: 2.0444770948861235

Epoch: 133| Step: 0
Training loss: 2.8186073303222656
Validation loss: 2.021500789990989

Epoch: 6| Step: 1
Training loss: 2.5991640090942383
Validation loss: 2.024408963418776

Epoch: 6| Step: 2
Training loss: 2.624887466430664
Validation loss: 2.012445103737616

Epoch: 6| Step: 3
Training loss: 1.4104052782058716
Validation loss: 2.034709674055858

Epoch: 6| Step: 4
Training loss: 1.8706237077713013
Validation loss: 2.0341555380052134

Epoch: 6| Step: 5
Training loss: 1.7897555828094482
Validation loss: 2.0274543159751484

Epoch: 6| Step: 6
Training loss: 2.175818920135498
Validation loss: 2.0435899585805912

Epoch: 6| Step: 7
Training loss: 2.467210531234741
Validation loss: 2.0088268428720455

Epoch: 6| Step: 8
Training loss: 2.3310623168945312
Validation loss: 2.0341227234050794

Epoch: 6| Step: 9
Training loss: 1.8003058433532715
Validation loss: 2.0325371578175533

Epoch: 6| Step: 10
Training loss: 2.2134556770324707
Validation loss: 2.0220743802285965

Epoch: 6| Step: 11
Training loss: 2.0232105255126953
Validation loss: 2.030816049985988

Epoch: 6| Step: 12
Training loss: 2.070307493209839
Validation loss: 2.075392933302028

Epoch: 6| Step: 13
Training loss: 3.0158565044403076
Validation loss: 2.036741136222757

Epoch: 134| Step: 0
Training loss: 1.6687792539596558
Validation loss: 2.023703311079292

Epoch: 6| Step: 1
Training loss: 1.191303014755249
Validation loss: 2.0438860436921478

Epoch: 6| Step: 2
Training loss: 2.449366331100464
Validation loss: 2.0176491942456973

Epoch: 6| Step: 3
Training loss: 2.027261734008789
Validation loss: 2.005766277672142

Epoch: 6| Step: 4
Training loss: 2.7410683631896973
Validation loss: 2.026473235058528

Epoch: 6| Step: 5
Training loss: 2.1774446964263916
Validation loss: 2.0577940530674432

Epoch: 6| Step: 6
Training loss: 1.8063174486160278
Validation loss: 2.029781199270679

Epoch: 6| Step: 7
Training loss: 1.7103173732757568
Validation loss: 2.042138409870927

Epoch: 6| Step: 8
Training loss: 2.6594302654266357
Validation loss: 2.0138043677935036

Epoch: 6| Step: 9
Training loss: 1.9501047134399414
Validation loss: 2.0125767620660926

Epoch: 6| Step: 10
Training loss: 3.1530139446258545
Validation loss: 2.0026909023202877

Epoch: 6| Step: 11
Training loss: 2.494236469268799
Validation loss: 2.0404590663089546

Epoch: 6| Step: 12
Training loss: 2.8143649101257324
Validation loss: 2.0108381484144475

Epoch: 6| Step: 13
Training loss: 2.168712615966797
Validation loss: 2.015347506410332

Epoch: 135| Step: 0
Training loss: 2.798478603363037
Validation loss: 2.033221576803474

Epoch: 6| Step: 1
Training loss: 1.8104567527770996
Validation loss: 2.043799223438386

Epoch: 6| Step: 2
Training loss: 2.323936700820923
Validation loss: 2.0170309376972977

Epoch: 6| Step: 3
Training loss: 1.866194725036621
Validation loss: 2.0262609848412136

Epoch: 6| Step: 4
Training loss: 2.425386905670166
Validation loss: 2.011102625118789

Epoch: 6| Step: 5
Training loss: 1.9966557025909424
Validation loss: 2.035275759235505

Epoch: 6| Step: 6
Training loss: 1.7806017398834229
Validation loss: 2.013793251847708

Epoch: 6| Step: 7
Training loss: 2.5574164390563965
Validation loss: 2.00990770452766

Epoch: 6| Step: 8
Training loss: 2.7005953788757324
Validation loss: 2.028857948959515

Epoch: 6| Step: 9
Training loss: 2.108314037322998
Validation loss: 2.02181311063869

Epoch: 6| Step: 10
Training loss: 2.8157289028167725
Validation loss: 2.0328519831421556

Epoch: 6| Step: 11
Training loss: 1.4170267581939697
Validation loss: 2.021527185234972

Epoch: 6| Step: 12
Training loss: 1.932561993598938
Validation loss: 2.0562661283759662

Epoch: 6| Step: 13
Training loss: 2.3662824630737305
Validation loss: 2.0324081990026657

Epoch: 136| Step: 0
Training loss: 2.343794822692871
Validation loss: 2.0413901780241277

Epoch: 6| Step: 1
Training loss: 1.6539138555526733
Validation loss: 2.0143556928121917

Epoch: 6| Step: 2
Training loss: 2.7159135341644287
Validation loss: 2.0358897601404498

Epoch: 6| Step: 3
Training loss: 2.0334901809692383
Validation loss: 2.0346775926569456

Epoch: 6| Step: 4
Training loss: 1.8708853721618652
Validation loss: 2.0250667038784234

Epoch: 6| Step: 5
Training loss: 2.3902244567871094
Validation loss: 2.048244645518641

Epoch: 6| Step: 6
Training loss: 2.5250964164733887
Validation loss: 2.047886553631034

Epoch: 6| Step: 7
Training loss: 1.8550148010253906
Validation loss: 2.022956801999

Epoch: 6| Step: 8
Training loss: 2.808197498321533
Validation loss: 2.0300139663039998

Epoch: 6| Step: 9
Training loss: 2.1584548950195312
Validation loss: 2.0169451236724854

Epoch: 6| Step: 10
Training loss: 2.456493377685547
Validation loss: 2.027881904314923

Epoch: 6| Step: 11
Training loss: 2.1625022888183594
Validation loss: 2.00569950508815

Epoch: 6| Step: 12
Training loss: 1.9895579814910889
Validation loss: 2.0031786503330355

Epoch: 6| Step: 13
Training loss: 1.7768739461898804
Validation loss: 2.006228323905699

Epoch: 137| Step: 0
Training loss: 1.9544564485549927
Validation loss: 2.0254962059759323

Epoch: 6| Step: 1
Training loss: 1.710827350616455
Validation loss: 2.0208328564961753

Epoch: 6| Step: 2
Training loss: 2.2563862800598145
Validation loss: 2.0103164308814594

Epoch: 6| Step: 3
Training loss: 2.1333839893341064
Validation loss: 2.041086640409244

Epoch: 6| Step: 4
Training loss: 2.6907906532287598
Validation loss: 2.0264981562091458

Epoch: 6| Step: 5
Training loss: 1.5036262273788452
Validation loss: 2.0578725927619526

Epoch: 6| Step: 6
Training loss: 2.309314727783203
Validation loss: 2.044731988701769

Epoch: 6| Step: 7
Training loss: 2.581754446029663
Validation loss: 2.0318458823747534

Epoch: 6| Step: 8
Training loss: 2.0932955741882324
Validation loss: 2.052769164885244

Epoch: 6| Step: 9
Training loss: 2.766742706298828
Validation loss: 2.0650723788046066

Epoch: 6| Step: 10
Training loss: 2.184445381164551
Validation loss: 2.023751767732764

Epoch: 6| Step: 11
Training loss: 1.7573966979980469
Validation loss: 2.051581234060308

Epoch: 6| Step: 12
Training loss: 2.379816770553589
Validation loss: 2.0367397698022986

Epoch: 6| Step: 13
Training loss: 2.8554863929748535
Validation loss: 2.0402106649132183

Epoch: 138| Step: 0
Training loss: 2.0878090858459473
Validation loss: 2.016665043369416

Epoch: 6| Step: 1
Training loss: 1.851961612701416
Validation loss: 2.0476124414833645

Epoch: 6| Step: 2
Training loss: 2.819218158721924
Validation loss: 2.0591870354067896

Epoch: 6| Step: 3
Training loss: 1.8715622425079346
Validation loss: 2.045129624746179

Epoch: 6| Step: 4
Training loss: 2.3662896156311035
Validation loss: 2.0351472798214165

Epoch: 6| Step: 5
Training loss: 2.397156238555908
Validation loss: 2.0114174735161567

Epoch: 6| Step: 6
Training loss: 2.5141615867614746
Validation loss: 2.0351576600023495

Epoch: 6| Step: 7
Training loss: 1.6864099502563477
Validation loss: 2.0335253912915467

Epoch: 6| Step: 8
Training loss: 2.2741942405700684
Validation loss: 2.0287323164683517

Epoch: 6| Step: 9
Training loss: 2.009749412536621
Validation loss: 2.0340394255935506

Epoch: 6| Step: 10
Training loss: 3.243649959564209
Validation loss: 2.0046275482382825

Epoch: 6| Step: 11
Training loss: 1.839314579963684
Validation loss: 1.999792956536816

Epoch: 6| Step: 12
Training loss: 1.797313928604126
Validation loss: 2.0219215577648533

Epoch: 6| Step: 13
Training loss: 1.889756679534912
Validation loss: 1.9820959773114932

Epoch: 139| Step: 0
Training loss: 2.4389185905456543
Validation loss: 2.033436511152534

Epoch: 6| Step: 1
Training loss: 1.6735131740570068
Validation loss: 2.032380122010426

Epoch: 6| Step: 2
Training loss: 3.2057838439941406
Validation loss: 2.0211006595242407

Epoch: 6| Step: 3
Training loss: 1.8797378540039062
Validation loss: 2.030993979464295

Epoch: 6| Step: 4
Training loss: 1.9001226425170898
Validation loss: 2.010196106408232

Epoch: 6| Step: 5
Training loss: 2.117603302001953
Validation loss: 2.024806712263374

Epoch: 6| Step: 6
Training loss: 2.4149718284606934
Validation loss: 1.9981755953963085

Epoch: 6| Step: 7
Training loss: 2.833575487136841
Validation loss: 2.0161726808035247

Epoch: 6| Step: 8
Training loss: 2.0091166496276855
Validation loss: 2.0190851585839384

Epoch: 6| Step: 9
Training loss: 2.0394344329833984
Validation loss: 2.015705244515532

Epoch: 6| Step: 10
Training loss: 1.9105641841888428
Validation loss: 2.0147618862890426

Epoch: 6| Step: 11
Training loss: 2.707590341567993
Validation loss: 2.031341255352061

Epoch: 6| Step: 12
Training loss: 1.9443598985671997
Validation loss: 2.0324878102989605

Epoch: 6| Step: 13
Training loss: 1.4619007110595703
Validation loss: 2.034381763909453

Epoch: 140| Step: 0
Training loss: 2.3829174041748047
Validation loss: 2.0354015058086765

Epoch: 6| Step: 1
Training loss: 2.4524433612823486
Validation loss: 2.0196571503916094

Epoch: 6| Step: 2
Training loss: 1.7436962127685547
Validation loss: 2.025424518892842

Epoch: 6| Step: 3
Training loss: 1.7684587240219116
Validation loss: 2.0348033494846796

Epoch: 6| Step: 4
Training loss: 2.1318299770355225
Validation loss: 2.0434495864375943

Epoch: 6| Step: 5
Training loss: 2.1920039653778076
Validation loss: 2.04718142555606

Epoch: 6| Step: 6
Training loss: 2.3850719928741455
Validation loss: 2.049930969874064

Epoch: 6| Step: 7
Training loss: 2.2069947719573975
Validation loss: 2.0535347589882473

Epoch: 6| Step: 8
Training loss: 2.7033424377441406
Validation loss: 2.043985338621242

Epoch: 6| Step: 9
Training loss: 1.9379040002822876
Validation loss: 2.03572775215231

Epoch: 6| Step: 10
Training loss: 2.1432175636291504
Validation loss: 2.0516982886099044

Epoch: 6| Step: 11
Training loss: 2.0849111080169678
Validation loss: 2.036185851661108

Epoch: 6| Step: 12
Training loss: 2.747375011444092
Validation loss: 2.0095699218011673

Epoch: 6| Step: 13
Training loss: 1.8051552772521973
Validation loss: 2.02733628724211

Epoch: 141| Step: 0
Training loss: 1.9419076442718506
Validation loss: 2.034878166772986

Epoch: 6| Step: 1
Training loss: 1.7352631092071533
Validation loss: 2.0255132003497054

Epoch: 6| Step: 2
Training loss: 2.004690647125244
Validation loss: 2.011671899467386

Epoch: 6| Step: 3
Training loss: 2.7337594032287598
Validation loss: 2.0295289306230444

Epoch: 6| Step: 4
Training loss: 2.447774887084961
Validation loss: 2.0361170461100917

Epoch: 6| Step: 5
Training loss: 1.730147361755371
Validation loss: 2.0334909346795853

Epoch: 6| Step: 6
Training loss: 2.3507895469665527
Validation loss: 2.018890437259469

Epoch: 6| Step: 7
Training loss: 2.97731351852417
Validation loss: 2.0289713900576354

Epoch: 6| Step: 8
Training loss: 1.9003791809082031
Validation loss: 2.0245640611135833

Epoch: 6| Step: 9
Training loss: 2.1076536178588867
Validation loss: 2.0489810769275953

Epoch: 6| Step: 10
Training loss: 2.540487766265869
Validation loss: 2.0288825483732325

Epoch: 6| Step: 11
Training loss: 1.919999361038208
Validation loss: 2.037616427226733

Epoch: 6| Step: 12
Training loss: 1.9953330755233765
Validation loss: 2.0225223290022982

Epoch: 6| Step: 13
Training loss: 2.4435529708862305
Validation loss: 2.051148263357019

Epoch: 142| Step: 0
Training loss: 3.0552611351013184
Validation loss: 2.042551702068698

Epoch: 6| Step: 1
Training loss: 2.2460925579071045
Validation loss: 2.0471612176587506

Epoch: 6| Step: 2
Training loss: 1.7466410398483276
Validation loss: 2.039419283149063

Epoch: 6| Step: 3
Training loss: 1.9201200008392334
Validation loss: 2.0007117909769856

Epoch: 6| Step: 4
Training loss: 1.8972904682159424
Validation loss: 2.022893797966742

Epoch: 6| Step: 5
Training loss: 2.3273770809173584
Validation loss: 2.0325797296339467

Epoch: 6| Step: 6
Training loss: 2.2445173263549805
Validation loss: 2.0290532099303378

Epoch: 6| Step: 7
Training loss: 2.746492385864258
Validation loss: 2.004288286291143

Epoch: 6| Step: 8
Training loss: 1.8392149209976196
Validation loss: 2.023745770095497

Epoch: 6| Step: 9
Training loss: 2.28831148147583
Validation loss: 2.018342373191669

Epoch: 6| Step: 10
Training loss: 2.2161402702331543
Validation loss: 2.0081393205991356

Epoch: 6| Step: 11
Training loss: 1.519443392753601
Validation loss: 2.0272850810840564

Epoch: 6| Step: 12
Training loss: 2.15364670753479
Validation loss: 2.0259517546622985

Epoch: 6| Step: 13
Training loss: 3.1953392028808594
Validation loss: 1.9989973396383307

Epoch: 143| Step: 0
Training loss: 1.6045525074005127
Validation loss: 2.0335968425196986

Epoch: 6| Step: 1
Training loss: 2.5301997661590576
Validation loss: 2.0219262876818256

Epoch: 6| Step: 2
Training loss: 2.3276243209838867
Validation loss: 2.0282429161892144

Epoch: 6| Step: 3
Training loss: 2.584594249725342
Validation loss: 2.044506844653878

Epoch: 6| Step: 4
Training loss: 2.0366687774658203
Validation loss: 2.019980437012129

Epoch: 6| Step: 5
Training loss: 2.248324394226074
Validation loss: 2.0347937358322965

Epoch: 6| Step: 6
Training loss: 1.3268415927886963
Validation loss: 2.042370867985551

Epoch: 6| Step: 7
Training loss: 2.615123748779297
Validation loss: 2.064985393196024

Epoch: 6| Step: 8
Training loss: 2.105222702026367
Validation loss: 2.0545495979247557

Epoch: 6| Step: 9
Training loss: 2.11622953414917
Validation loss: 2.03517605668755

Epoch: 6| Step: 10
Training loss: 2.4107675552368164
Validation loss: 2.0365592792469966

Epoch: 6| Step: 11
Training loss: 1.860931396484375
Validation loss: 2.021565515507934

Epoch: 6| Step: 12
Training loss: 2.61393141746521
Validation loss: 2.0638930207939556

Epoch: 6| Step: 13
Training loss: 2.449711322784424
Validation loss: 2.049533592757358

Epoch: 144| Step: 0
Training loss: 2.5665078163146973
Validation loss: 2.0529374512293006

Epoch: 6| Step: 1
Training loss: 2.451979160308838
Validation loss: 2.054406754432186

Epoch: 6| Step: 2
Training loss: 3.074347972869873
Validation loss: 2.0519095197800667

Epoch: 6| Step: 3
Training loss: 2.390615940093994
Validation loss: 2.046986751658942

Epoch: 6| Step: 4
Training loss: 2.1475095748901367
Validation loss: 2.0685014750367854

Epoch: 6| Step: 5
Training loss: 2.0845818519592285
Validation loss: 2.0429024055439937

Epoch: 6| Step: 6
Training loss: 1.9770771265029907
Validation loss: 2.0453853530268513

Epoch: 6| Step: 7
Training loss: 2.1222920417785645
Validation loss: 2.0267644505346976

Epoch: 6| Step: 8
Training loss: 1.9719276428222656
Validation loss: 2.044492708739414

Epoch: 6| Step: 9
Training loss: 1.811293363571167
Validation loss: 2.0391452517560733

Epoch: 6| Step: 10
Training loss: 1.2601737976074219
Validation loss: 2.0225743298889487

Epoch: 6| Step: 11
Training loss: 2.1467626094818115
Validation loss: 2.028845046156196

Epoch: 6| Step: 12
Training loss: 2.6817739009857178
Validation loss: 2.035908747744817

Epoch: 6| Step: 13
Training loss: 2.1348512172698975
Validation loss: 2.015248724209365

Epoch: 145| Step: 0
Training loss: 2.5310254096984863
Validation loss: 2.0171019236246743

Epoch: 6| Step: 1
Training loss: 2.139207601547241
Validation loss: 2.0425638101434194

Epoch: 6| Step: 2
Training loss: 2.549670457839966
Validation loss: 2.030495564142863

Epoch: 6| Step: 3
Training loss: 2.0750842094421387
Validation loss: 2.031987444047005

Epoch: 6| Step: 4
Training loss: 2.3027093410491943
Validation loss: 2.042222122992239

Epoch: 6| Step: 5
Training loss: 1.3136664628982544
Validation loss: 2.0391954324578725

Epoch: 6| Step: 6
Training loss: 2.584571361541748
Validation loss: 2.022854963938395

Epoch: 6| Step: 7
Training loss: 3.0968902111053467
Validation loss: 2.0260336219623523

Epoch: 6| Step: 8
Training loss: 2.0808398723602295
Validation loss: 2.0481406129816526

Epoch: 6| Step: 9
Training loss: 2.410043239593506
Validation loss: 2.049489180246989

Epoch: 6| Step: 10
Training loss: 1.8781256675720215
Validation loss: 2.0288491184993456

Epoch: 6| Step: 11
Training loss: 1.6367371082305908
Validation loss: 2.0468613716863815

Epoch: 6| Step: 12
Training loss: 2.103374719619751
Validation loss: 2.0315384787897908

Epoch: 6| Step: 13
Training loss: 1.9875562191009521
Validation loss: 2.0526477072828557

Epoch: 146| Step: 0
Training loss: 2.0618293285369873
Validation loss: 2.0320687396551973

Epoch: 6| Step: 1
Training loss: 1.2691161632537842
Validation loss: 2.0258854909609725

Epoch: 6| Step: 2
Training loss: 1.8864301443099976
Validation loss: 2.0375087274018155

Epoch: 6| Step: 3
Training loss: 2.2320094108581543
Validation loss: 2.0197555454828406

Epoch: 6| Step: 4
Training loss: 1.6261534690856934
Validation loss: 2.0079895155404204

Epoch: 6| Step: 5
Training loss: 2.345822811126709
Validation loss: 2.0215048174704275

Epoch: 6| Step: 6
Training loss: 2.3894553184509277
Validation loss: 2.023520741411435

Epoch: 6| Step: 7
Training loss: 2.5738558769226074
Validation loss: 2.022526915355395

Epoch: 6| Step: 8
Training loss: 2.0835256576538086
Validation loss: 2.0238964878102785

Epoch: 6| Step: 9
Training loss: 2.30127215385437
Validation loss: 2.022277162921044

Epoch: 6| Step: 10
Training loss: 2.4135901927948
Validation loss: 2.012576219856098

Epoch: 6| Step: 11
Training loss: 2.2055506706237793
Validation loss: 2.0391068920012443

Epoch: 6| Step: 12
Training loss: 3.1102616786956787
Validation loss: 2.03581755135649

Epoch: 6| Step: 13
Training loss: 2.4628562927246094
Validation loss: 2.0168574035808606

Epoch: 147| Step: 0
Training loss: 2.6385340690612793
Validation loss: 2.036486905108216

Epoch: 6| Step: 1
Training loss: 2.273411750793457
Validation loss: 2.035955721332181

Epoch: 6| Step: 2
Training loss: 2.8531441688537598
Validation loss: 2.0334241723501556

Epoch: 6| Step: 3
Training loss: 2.0205867290496826
Validation loss: 2.0557237107266664

Epoch: 6| Step: 4
Training loss: 1.9759182929992676
Validation loss: 2.0495275348745365

Epoch: 6| Step: 5
Training loss: 2.535027027130127
Validation loss: 2.062622331803845

Epoch: 6| Step: 6
Training loss: 2.2458102703094482
Validation loss: 2.0398749471992574

Epoch: 6| Step: 7
Training loss: 1.3461647033691406
Validation loss: 2.0460112440970635

Epoch: 6| Step: 8
Training loss: 2.1637511253356934
Validation loss: 2.0590185862715527

Epoch: 6| Step: 9
Training loss: 2.0029993057250977
Validation loss: 2.073103530432588

Epoch: 6| Step: 10
Training loss: 2.4411861896514893
Validation loss: 2.0322011055484897

Epoch: 6| Step: 11
Training loss: 1.9570435285568237
Validation loss: 2.0417710222223753

Epoch: 6| Step: 12
Training loss: 2.44073486328125
Validation loss: 2.0401383881927817

Epoch: 6| Step: 13
Training loss: 1.3391926288604736
Validation loss: 2.037581323295511

Epoch: 148| Step: 0
Training loss: 2.0589308738708496
Validation loss: 2.040427090019308

Epoch: 6| Step: 1
Training loss: 1.8342100381851196
Validation loss: 2.0295322761740735

Epoch: 6| Step: 2
Training loss: 2.2496533393859863
Validation loss: 2.0216667088129188

Epoch: 6| Step: 3
Training loss: 2.52827787399292
Validation loss: 2.034180504019542

Epoch: 6| Step: 4
Training loss: 1.4375150203704834
Validation loss: 2.0169320106506348

Epoch: 6| Step: 5
Training loss: 2.0169878005981445
Validation loss: 2.0163508961277623

Epoch: 6| Step: 6
Training loss: 2.658334732055664
Validation loss: 2.027890423292755

Epoch: 6| Step: 7
Training loss: 2.827317237854004
Validation loss: 2.017368934487784

Epoch: 6| Step: 8
Training loss: 2.8203861713409424
Validation loss: 2.040667644111059

Epoch: 6| Step: 9
Training loss: 2.3042163848876953
Validation loss: 2.025516143409155

Epoch: 6| Step: 10
Training loss: 2.0127882957458496
Validation loss: 2.0262403872705277

Epoch: 6| Step: 11
Training loss: 2.019136905670166
Validation loss: 2.0496389673602198

Epoch: 6| Step: 12
Training loss: 2.1672396659851074
Validation loss: 2.0338325141578593

Epoch: 6| Step: 13
Training loss: 1.4065908193588257
Validation loss: 2.0518080957474245

Epoch: 149| Step: 0
Training loss: 1.7973283529281616
Validation loss: 2.062535185967722

Epoch: 6| Step: 1
Training loss: 2.0826869010925293
Validation loss: 2.0295431101193993

Epoch: 6| Step: 2
Training loss: 2.321971893310547
Validation loss: 2.0244156058116625

Epoch: 6| Step: 3
Training loss: 2.318557024002075
Validation loss: 2.052213133022349

Epoch: 6| Step: 4
Training loss: 2.068777084350586
Validation loss: 2.041539962573718

Epoch: 6| Step: 5
Training loss: 2.064659833908081
Validation loss: 2.035316046848092

Epoch: 6| Step: 6
Training loss: 1.3766835927963257
Validation loss: 2.045238261581749

Epoch: 6| Step: 7
Training loss: 2.7448089122772217
Validation loss: 2.0289492440480057

Epoch: 6| Step: 8
Training loss: 2.347506523132324
Validation loss: 2.052530159232437

Epoch: 6| Step: 9
Training loss: 2.2525930404663086
Validation loss: 2.04209723395686

Epoch: 6| Step: 10
Training loss: 1.789021611213684
Validation loss: 2.05036521855221

Epoch: 6| Step: 11
Training loss: 2.1139607429504395
Validation loss: 2.0398924055919854

Epoch: 6| Step: 12
Training loss: 2.281853199005127
Validation loss: 2.066748306315432

Epoch: 6| Step: 13
Training loss: 3.8522284030914307
Validation loss: 2.035620225373135

Epoch: 150| Step: 0
Training loss: 1.4854379892349243
Validation loss: 2.0347860795195385

Epoch: 6| Step: 1
Training loss: 1.7723908424377441
Validation loss: 2.0428582955432195

Epoch: 6| Step: 2
Training loss: 1.755699872970581
Validation loss: 2.0359429800382225

Epoch: 6| Step: 3
Training loss: 2.1485280990600586
Validation loss: 2.018229902431529

Epoch: 6| Step: 4
Training loss: 2.428473472595215
Validation loss: 2.015762456001774

Epoch: 6| Step: 5
Training loss: 2.769314765930176
Validation loss: 2.0366139604199316

Epoch: 6| Step: 6
Training loss: 1.9102833271026611
Validation loss: 2.0264315400072324

Epoch: 6| Step: 7
Training loss: 2.5566916465759277
Validation loss: 2.054864519385881

Epoch: 6| Step: 8
Training loss: 3.462158679962158
Validation loss: 2.0244850574001187

Epoch: 6| Step: 9
Training loss: 1.3225497007369995
Validation loss: 2.0211498788608018

Epoch: 6| Step: 10
Training loss: 1.9756850004196167
Validation loss: 2.0324538138604935

Epoch: 6| Step: 11
Training loss: 2.4772613048553467
Validation loss: 2.035607950661772

Epoch: 6| Step: 12
Training loss: 2.3192379474639893
Validation loss: 2.0453589808556343

Epoch: 6| Step: 13
Training loss: 2.3425333499908447
Validation loss: 2.045228224928661

Epoch: 151| Step: 0
Training loss: 2.7665581703186035
Validation loss: 2.02176219929931

Epoch: 6| Step: 1
Training loss: 3.3394675254821777
Validation loss: 2.025316571676603

Epoch: 6| Step: 2
Training loss: 2.2434234619140625
Validation loss: 2.0304210109095417

Epoch: 6| Step: 3
Training loss: 1.9106355905532837
Validation loss: 2.048020370544926

Epoch: 6| Step: 4
Training loss: 2.3044323921203613
Validation loss: 2.0155650044000275

Epoch: 6| Step: 5
Training loss: 1.8223649263381958
Validation loss: 2.0382455882205757

Epoch: 6| Step: 6
Training loss: 1.8612161874771118
Validation loss: 2.0287125290081067

Epoch: 6| Step: 7
Training loss: 2.471536636352539
Validation loss: 2.0623867870658956

Epoch: 6| Step: 8
Training loss: 2.836171865463257
Validation loss: 2.0604870319366455

Epoch: 6| Step: 9
Training loss: 1.4430937767028809
Validation loss: 2.023501782007115

Epoch: 6| Step: 10
Training loss: 1.4374921321868896
Validation loss: 2.0475184404721825

Epoch: 6| Step: 11
Training loss: 1.8997485637664795
Validation loss: 2.0456369000096477

Epoch: 6| Step: 12
Training loss: 2.2221646308898926
Validation loss: 2.0334936341931744

Epoch: 6| Step: 13
Training loss: 1.9431370496749878
Validation loss: 2.0520580327639015

Epoch: 152| Step: 0
Training loss: 2.4181864261627197
Validation loss: 2.050764091553227

Epoch: 6| Step: 1
Training loss: 2.284179925918579
Validation loss: 2.054037892690269

Epoch: 6| Step: 2
Training loss: 1.8526424169540405
Validation loss: 2.0426800712462394

Epoch: 6| Step: 3
Training loss: 1.9487180709838867
Validation loss: 2.050436101933961

Epoch: 6| Step: 4
Training loss: 1.732646107673645
Validation loss: 2.031118672381165

Epoch: 6| Step: 5
Training loss: 1.601861596107483
Validation loss: 2.0360220273335776

Epoch: 6| Step: 6
Training loss: 2.3134279251098633
Validation loss: 2.0256855052004576

Epoch: 6| Step: 7
Training loss: 2.7369630336761475
Validation loss: 2.042123935555899

Epoch: 6| Step: 8
Training loss: 2.3196773529052734
Validation loss: 2.031231935306262

Epoch: 6| Step: 9
Training loss: 2.1220571994781494
Validation loss: 2.0307236871411725

Epoch: 6| Step: 10
Training loss: 2.3723130226135254
Validation loss: 2.042930567136375

Epoch: 6| Step: 11
Training loss: 1.9346121549606323
Validation loss: 2.0514920885844896

Epoch: 6| Step: 12
Training loss: 2.907960891723633
Validation loss: 2.0189553576131023

Epoch: 6| Step: 13
Training loss: 2.1874420642852783
Validation loss: 2.0142732243384085

Epoch: 153| Step: 0
Training loss: 2.03208065032959
Validation loss: 2.0300087416043846

Epoch: 6| Step: 1
Training loss: 1.5657384395599365
Validation loss: 2.027901211092549

Epoch: 6| Step: 2
Training loss: 2.744208574295044
Validation loss: 2.0355417164423133

Epoch: 6| Step: 3
Training loss: 1.885761022567749
Validation loss: 2.0311456226533458

Epoch: 6| Step: 4
Training loss: 2.2039268016815186
Validation loss: 2.001351600052208

Epoch: 6| Step: 5
Training loss: 2.5787549018859863
Validation loss: 2.018835372822259

Epoch: 6| Step: 6
Training loss: 2.101715564727783
Validation loss: 2.0454592922682404

Epoch: 6| Step: 7
Training loss: 2.7902419567108154
Validation loss: 2.047230815374723

Epoch: 6| Step: 8
Training loss: 2.2874860763549805
Validation loss: 2.047571510396978

Epoch: 6| Step: 9
Training loss: 1.6623461246490479
Validation loss: 2.0362089039177023

Epoch: 6| Step: 10
Training loss: 2.021573305130005
Validation loss: 2.0422549555378575

Epoch: 6| Step: 11
Training loss: 2.778160333633423
Validation loss: 2.036553798183318

Epoch: 6| Step: 12
Training loss: 1.8658771514892578
Validation loss: 2.0380787541789394

Epoch: 6| Step: 13
Training loss: 1.8893473148345947
Validation loss: 2.03556126932944

Epoch: 154| Step: 0
Training loss: 2.398073434829712
Validation loss: 2.0327103394334034

Epoch: 6| Step: 1
Training loss: 1.9039356708526611
Validation loss: 2.009881745102585

Epoch: 6| Step: 2
Training loss: 1.5930556058883667
Validation loss: 2.0293111493510585

Epoch: 6| Step: 3
Training loss: 2.3613367080688477
Validation loss: 2.0239268938700357

Epoch: 6| Step: 4
Training loss: 2.615616798400879
Validation loss: 2.0269155002409414

Epoch: 6| Step: 5
Training loss: 2.0874276161193848
Validation loss: 2.0270441629553355

Epoch: 6| Step: 6
Training loss: 1.8120453357696533
Validation loss: 2.015930587245572

Epoch: 6| Step: 7
Training loss: 2.4392716884613037
Validation loss: 2.0192655171117475

Epoch: 6| Step: 8
Training loss: 1.8209532499313354
Validation loss: 2.02491731028403

Epoch: 6| Step: 9
Training loss: 2.3297808170318604
Validation loss: 2.0525836124215076

Epoch: 6| Step: 10
Training loss: 2.9433646202087402
Validation loss: 2.082775717140526

Epoch: 6| Step: 11
Training loss: 1.6754071712493896
Validation loss: 2.035688538705149

Epoch: 6| Step: 12
Training loss: 2.197547674179077
Validation loss: 2.048264172769362

Epoch: 6| Step: 13
Training loss: 2.771535634994507
Validation loss: 2.0418740651940785

Epoch: 155| Step: 0
Training loss: 1.846079707145691
Validation loss: 2.0430298236108597

Epoch: 6| Step: 1
Training loss: 1.827928900718689
Validation loss: 2.0148429332240934

Epoch: 6| Step: 2
Training loss: 2.366121768951416
Validation loss: 2.0287310769481044

Epoch: 6| Step: 3
Training loss: 2.2403018474578857
Validation loss: 2.042624586371965

Epoch: 6| Step: 4
Training loss: 1.8131765127182007
Validation loss: 2.0366808445222917

Epoch: 6| Step: 5
Training loss: 2.6705479621887207
Validation loss: 2.0457845093101583

Epoch: 6| Step: 6
Training loss: 1.8892585039138794
Validation loss: 2.0114538541404148

Epoch: 6| Step: 7
Training loss: 2.3804378509521484
Validation loss: 2.026778044239167

Epoch: 6| Step: 8
Training loss: 2.3316898345947266
Validation loss: 2.03976337627698

Epoch: 6| Step: 9
Training loss: 2.5266494750976562
Validation loss: 2.0160381409429733

Epoch: 6| Step: 10
Training loss: 2.479783535003662
Validation loss: 2.040876801295947

Epoch: 6| Step: 11
Training loss: 2.4182775020599365
Validation loss: 2.001384073688138

Epoch: 6| Step: 12
Training loss: 1.873963713645935
Validation loss: 1.987599242118097

Epoch: 6| Step: 13
Training loss: 1.953511118888855
Validation loss: 2.017483977861302

Epoch: 156| Step: 0
Training loss: 2.3767855167388916
Validation loss: 2.0083499082954983

Epoch: 6| Step: 1
Training loss: 2.2546815872192383
Validation loss: 2.0069540367331555

Epoch: 6| Step: 2
Training loss: 2.6730668544769287
Validation loss: 2.017676608536833

Epoch: 6| Step: 3
Training loss: 2.0084729194641113
Validation loss: 2.016092928506995

Epoch: 6| Step: 4
Training loss: 1.7995140552520752
Validation loss: 2.026117656820564

Epoch: 6| Step: 5
Training loss: 1.9023298025131226
Validation loss: 2.036345830527685

Epoch: 6| Step: 6
Training loss: 2.4540257453918457
Validation loss: 2.013997972652476

Epoch: 6| Step: 7
Training loss: 1.9645086526870728
Validation loss: 2.0521699126048754

Epoch: 6| Step: 8
Training loss: 1.6811721324920654
Validation loss: 2.025747419685446

Epoch: 6| Step: 9
Training loss: 3.0381429195404053
Validation loss: 2.046814350671666

Epoch: 6| Step: 10
Training loss: 2.2442030906677246
Validation loss: 2.041500304334907

Epoch: 6| Step: 11
Training loss: 2.000058889389038
Validation loss: 2.0129535505848546

Epoch: 6| Step: 12
Training loss: 2.1489222049713135
Validation loss: 2.0084551175435386

Epoch: 6| Step: 13
Training loss: 1.9144452810287476
Validation loss: 2.033549763823068

Epoch: 157| Step: 0
Training loss: 2.5548367500305176
Validation loss: 2.052502711613973

Epoch: 6| Step: 1
Training loss: 1.9048700332641602
Validation loss: 2.0481193450189408

Epoch: 6| Step: 2
Training loss: 2.229210138320923
Validation loss: 2.065852201113137

Epoch: 6| Step: 3
Training loss: 1.9031728506088257
Validation loss: 2.0514768221045054

Epoch: 6| Step: 4
Training loss: 2.086388349533081
Validation loss: 2.053879525071831

Epoch: 6| Step: 5
Training loss: 2.0044896602630615
Validation loss: 2.0518014995000695

Epoch: 6| Step: 6
Training loss: 2.2425193786621094
Validation loss: 2.0474641861454135

Epoch: 6| Step: 7
Training loss: 2.623663902282715
Validation loss: 2.0510944166491107

Epoch: 6| Step: 8
Training loss: 1.89707612991333
Validation loss: 2.073232002155755

Epoch: 6| Step: 9
Training loss: 2.521547317504883
Validation loss: 2.0497139218033

Epoch: 6| Step: 10
Training loss: 2.389712333679199
Validation loss: 2.063669297002977

Epoch: 6| Step: 11
Training loss: 2.2090513706207275
Validation loss: 2.068587087815808

Epoch: 6| Step: 12
Training loss: 2.0119853019714355
Validation loss: 2.0302402844993015

Epoch: 6| Step: 13
Training loss: 1.745033860206604
Validation loss: 2.0580456487594114

Epoch: 158| Step: 0
Training loss: 1.7391777038574219
Validation loss: 2.0652317718792985

Epoch: 6| Step: 1
Training loss: 1.9624401330947876
Validation loss: 2.0707772034470753

Epoch: 6| Step: 2
Training loss: 1.688159465789795
Validation loss: 2.0518887030181063

Epoch: 6| Step: 3
Training loss: 2.243215322494507
Validation loss: 2.038040284187563

Epoch: 6| Step: 4
Training loss: 2.3639345169067383
Validation loss: 2.0347777156419653

Epoch: 6| Step: 5
Training loss: 2.2081737518310547
Validation loss: 2.0398718208395024

Epoch: 6| Step: 6
Training loss: 2.2176311016082764
Validation loss: 2.050376517798311

Epoch: 6| Step: 7
Training loss: 2.612234592437744
Validation loss: 2.0168071921153734

Epoch: 6| Step: 8
Training loss: 2.461513042449951
Validation loss: 2.0376566840756323

Epoch: 6| Step: 9
Training loss: 2.636343002319336
Validation loss: 2.0321249141488025

Epoch: 6| Step: 10
Training loss: 1.7123184204101562
Validation loss: 2.037235221555156

Epoch: 6| Step: 11
Training loss: 1.9907152652740479
Validation loss: 1.9959442410417783

Epoch: 6| Step: 12
Training loss: 2.0995254516601562
Validation loss: 2.011763762402278

Epoch: 6| Step: 13
Training loss: 2.593467950820923
Validation loss: 2.0137970139903407

Epoch: 159| Step: 0
Training loss: 2.5444233417510986
Validation loss: 2.0249210429447952

Epoch: 6| Step: 1
Training loss: 1.8325605392456055
Validation loss: 2.0510770313201414

Epoch: 6| Step: 2
Training loss: 2.6165270805358887
Validation loss: 2.0303834471651303

Epoch: 6| Step: 3
Training loss: 2.666494846343994
Validation loss: 2.056194081101366

Epoch: 6| Step: 4
Training loss: 2.3022029399871826
Validation loss: 2.04337481785846

Epoch: 6| Step: 5
Training loss: 1.235030174255371
Validation loss: 2.054652298650434

Epoch: 6| Step: 6
Training loss: 2.021010398864746
Validation loss: 2.0236682648299844

Epoch: 6| Step: 7
Training loss: 1.9275484085083008
Validation loss: 2.038072580932289

Epoch: 6| Step: 8
Training loss: 2.5066933631896973
Validation loss: 2.060866791714904

Epoch: 6| Step: 9
Training loss: 2.2281267642974854
Validation loss: 2.0487633110374532

Epoch: 6| Step: 10
Training loss: 2.240243911743164
Validation loss: 2.0491298488391343

Epoch: 6| Step: 11
Training loss: 2.592679023742676
Validation loss: 2.0611943455152613

Epoch: 6| Step: 12
Training loss: 1.8615705966949463
Validation loss: 2.033404609208466

Epoch: 6| Step: 13
Training loss: 1.7158474922180176
Validation loss: 2.020909244014371

Epoch: 160| Step: 0
Training loss: 2.2920339107513428
Validation loss: 2.0492620134866364

Epoch: 6| Step: 1
Training loss: 1.9815956354141235
Validation loss: 2.0616248730690248

Epoch: 6| Step: 2
Training loss: 1.8772491216659546
Validation loss: 2.061004343853202

Epoch: 6| Step: 3
Training loss: 1.9683260917663574
Validation loss: 2.0360031550930393

Epoch: 6| Step: 4
Training loss: 1.9837700128555298
Validation loss: 2.030351649048508

Epoch: 6| Step: 5
Training loss: 2.841911554336548
Validation loss: 2.045609894619193

Epoch: 6| Step: 6
Training loss: 1.854947805404663
Validation loss: 2.050129125195165

Epoch: 6| Step: 7
Training loss: 2.0280098915100098
Validation loss: 2.0071651986850205

Epoch: 6| Step: 8
Training loss: 1.431103229522705
Validation loss: 2.0065267137301865

Epoch: 6| Step: 9
Training loss: 2.675989866256714
Validation loss: 2.027908996869159

Epoch: 6| Step: 10
Training loss: 2.6241207122802734
Validation loss: 2.04016387590798

Epoch: 6| Step: 11
Training loss: 2.519608497619629
Validation loss: 2.024022161319692

Epoch: 6| Step: 12
Training loss: 2.299239158630371
Validation loss: 2.0335587814290035

Epoch: 6| Step: 13
Training loss: 2.148939847946167
Validation loss: 2.049992243448893

Epoch: 161| Step: 0
Training loss: 2.0544567108154297
Validation loss: 2.0395406702513337

Epoch: 6| Step: 1
Training loss: 2.1294302940368652
Validation loss: 2.02655396410214

Epoch: 6| Step: 2
Training loss: 1.9261748790740967
Validation loss: 2.0138156478123

Epoch: 6| Step: 3
Training loss: 1.9038341045379639
Validation loss: 2.0363636247573362

Epoch: 6| Step: 4
Training loss: 2.0352869033813477
Validation loss: 2.033995118192447

Epoch: 6| Step: 5
Training loss: 2.571704387664795
Validation loss: 2.0221264682790285

Epoch: 6| Step: 6
Training loss: 2.173241376876831
Validation loss: 2.020187945776088

Epoch: 6| Step: 7
Training loss: 1.617232084274292
Validation loss: 2.021037196600309

Epoch: 6| Step: 8
Training loss: 1.7940058708190918
Validation loss: 2.0390251990287536

Epoch: 6| Step: 9
Training loss: 2.9666082859039307
Validation loss: 2.024548513914949

Epoch: 6| Step: 10
Training loss: 2.848816394805908
Validation loss: 2.0272071605087607

Epoch: 6| Step: 11
Training loss: 1.745259165763855
Validation loss: 2.0481603709600305

Epoch: 6| Step: 12
Training loss: 2.5308775901794434
Validation loss: 2.02672516915106

Epoch: 6| Step: 13
Training loss: 2.2748937606811523
Validation loss: 2.0178525345299834

Epoch: 162| Step: 0
Training loss: 2.2253940105438232
Validation loss: 2.022147060722433

Epoch: 6| Step: 1
Training loss: 2.8042073249816895
Validation loss: 2.0579218249167166

Epoch: 6| Step: 2
Training loss: 1.7656407356262207
Validation loss: 2.034710894348801

Epoch: 6| Step: 3
Training loss: 2.02866792678833
Validation loss: 2.0449677769855787

Epoch: 6| Step: 4
Training loss: 2.3909621238708496
Validation loss: 2.050999255590541

Epoch: 6| Step: 5
Training loss: 1.7965694665908813
Validation loss: 2.0506059046714538

Epoch: 6| Step: 6
Training loss: 2.1146609783172607
Validation loss: 2.084234296634633

Epoch: 6| Step: 7
Training loss: 2.292917013168335
Validation loss: 2.053122913965615

Epoch: 6| Step: 8
Training loss: 2.08231258392334
Validation loss: 2.0638313985640004

Epoch: 6| Step: 9
Training loss: 2.2350425720214844
Validation loss: 2.0566503617071334

Epoch: 6| Step: 10
Training loss: 2.658613681793213
Validation loss: 2.063784001975931

Epoch: 6| Step: 11
Training loss: 1.9446806907653809
Validation loss: 2.0599761483489827

Epoch: 6| Step: 12
Training loss: 2.074699878692627
Validation loss: 2.0632466680260113

Epoch: 6| Step: 13
Training loss: 2.024350643157959
Validation loss: 2.0454095012398175

Epoch: 163| Step: 0
Training loss: 2.2394092082977295
Validation loss: 2.0535944213149366

Epoch: 6| Step: 1
Training loss: 1.9316935539245605
Validation loss: 2.0396949360447545

Epoch: 6| Step: 2
Training loss: 1.7255806922912598
Validation loss: 2.0453371822193103

Epoch: 6| Step: 3
Training loss: 2.6596832275390625
Validation loss: 2.0261551128920687

Epoch: 6| Step: 4
Training loss: 1.781869649887085
Validation loss: 2.055225767115111

Epoch: 6| Step: 5
Training loss: 2.1652445793151855
Validation loss: 2.032372784870927

Epoch: 6| Step: 6
Training loss: 1.9083586931228638
Validation loss: 2.0388876058722056

Epoch: 6| Step: 7
Training loss: 1.9547570943832397
Validation loss: 2.041271427626251

Epoch: 6| Step: 8
Training loss: 2.4179322719573975
Validation loss: 2.059129725220383

Epoch: 6| Step: 9
Training loss: 1.8663016557693481
Validation loss: 2.0401138362064155

Epoch: 6| Step: 10
Training loss: 2.3451106548309326
Validation loss: 2.0396713005599154

Epoch: 6| Step: 11
Training loss: 2.790144443511963
Validation loss: 2.0198226026309434

Epoch: 6| Step: 12
Training loss: 2.384162425994873
Validation loss: 2.0761474153046966

Epoch: 6| Step: 13
Training loss: 2.3755364418029785
Validation loss: 2.0324110702801774

Epoch: 164| Step: 0
Training loss: 2.4070279598236084
Validation loss: 2.0692390139384935

Epoch: 6| Step: 1
Training loss: 2.0679311752319336
Validation loss: 2.0474964187991236

Epoch: 6| Step: 2
Training loss: 2.5427377223968506
Validation loss: 2.055996543617659

Epoch: 6| Step: 3
Training loss: 2.0071558952331543
Validation loss: 2.0181662677436747

Epoch: 6| Step: 4
Training loss: 1.839836597442627
Validation loss: 2.0553067858501146

Epoch: 6| Step: 5
Training loss: 1.9698197841644287
Validation loss: 2.0640808971979285

Epoch: 6| Step: 6
Training loss: 2.0481202602386475
Validation loss: 2.05036590432608

Epoch: 6| Step: 7
Training loss: 2.715658664703369
Validation loss: 2.083488766865064

Epoch: 6| Step: 8
Training loss: 1.563796043395996
Validation loss: 2.0429584364737234

Epoch: 6| Step: 9
Training loss: 2.228527069091797
Validation loss: 2.0429654198308147

Epoch: 6| Step: 10
Training loss: 1.4672236442565918
Validation loss: 2.0585056799714283

Epoch: 6| Step: 11
Training loss: 2.453059673309326
Validation loss: 2.0884742711179998

Epoch: 6| Step: 12
Training loss: 2.4478302001953125
Validation loss: 2.058125762529271

Epoch: 6| Step: 13
Training loss: 3.020697593688965
Validation loss: 2.0452707582904446

Epoch: 165| Step: 0
Training loss: 2.2726521492004395
Validation loss: 2.0328276003560712

Epoch: 6| Step: 1
Training loss: 1.9187442064285278
Validation loss: 2.0403713154536423

Epoch: 6| Step: 2
Training loss: 2.246286392211914
Validation loss: 2.0493116635148243

Epoch: 6| Step: 3
Training loss: 1.7546114921569824
Validation loss: 2.0470794721316268

Epoch: 6| Step: 4
Training loss: 1.8045533895492554
Validation loss: 2.020655375654979

Epoch: 6| Step: 5
Training loss: 2.742893695831299
Validation loss: 2.0215716438908733

Epoch: 6| Step: 6
Training loss: 2.5856289863586426
Validation loss: 2.0107634375172276

Epoch: 6| Step: 7
Training loss: 2.554098606109619
Validation loss: 2.0545346916362806

Epoch: 6| Step: 8
Training loss: 1.8894462585449219
Validation loss: 2.041098457510753

Epoch: 6| Step: 9
Training loss: 2.2134673595428467
Validation loss: 2.054774225399058

Epoch: 6| Step: 10
Training loss: 2.16359281539917
Validation loss: 2.0076914154073244

Epoch: 6| Step: 11
Training loss: 1.989542007446289
Validation loss: 2.0559120126949844

Epoch: 6| Step: 12
Training loss: 1.8994193077087402
Validation loss: 2.0573822221448346

Epoch: 6| Step: 13
Training loss: 2.379437208175659
Validation loss: 2.060054184288107

Epoch: 166| Step: 0
Training loss: 2.8111963272094727
Validation loss: 2.048026213081934

Epoch: 6| Step: 1
Training loss: 2.829117774963379
Validation loss: 2.0290284028617283

Epoch: 6| Step: 2
Training loss: 2.2032852172851562
Validation loss: 2.063307262236072

Epoch: 6| Step: 3
Training loss: 2.0934412479400635
Validation loss: 2.038729034444337

Epoch: 6| Step: 4
Training loss: 2.2267332077026367
Validation loss: 2.0278008086707002

Epoch: 6| Step: 5
Training loss: 2.239102840423584
Validation loss: 2.047239262570617

Epoch: 6| Step: 6
Training loss: 1.9420660734176636
Validation loss: 2.04047481988066

Epoch: 6| Step: 7
Training loss: 1.715504765510559
Validation loss: 2.065192316168098

Epoch: 6| Step: 8
Training loss: 1.9098548889160156
Validation loss: 2.068346623451479

Epoch: 6| Step: 9
Training loss: 1.7645816802978516
Validation loss: 2.0655286081375612

Epoch: 6| Step: 10
Training loss: 2.3376307487487793
Validation loss: 2.0679910195771085

Epoch: 6| Step: 11
Training loss: 2.4144673347473145
Validation loss: 2.0595907318976616

Epoch: 6| Step: 12
Training loss: 2.002405881881714
Validation loss: 2.049898442401681

Epoch: 6| Step: 13
Training loss: 1.8406732082366943
Validation loss: 2.055787335159958

Epoch: 167| Step: 0
Training loss: 2.7958152294158936
Validation loss: 2.0359272239028767

Epoch: 6| Step: 1
Training loss: 2.170771598815918
Validation loss: 2.053653100485443

Epoch: 6| Step: 2
Training loss: 1.73172926902771
Validation loss: 2.046393302179152

Epoch: 6| Step: 3
Training loss: 2.197509765625
Validation loss: 2.0273630067866337

Epoch: 6| Step: 4
Training loss: 2.131013870239258
Validation loss: 2.0412122921277116

Epoch: 6| Step: 5
Training loss: 1.2049696445465088
Validation loss: 2.0563255304931314

Epoch: 6| Step: 6
Training loss: 2.5802650451660156
Validation loss: 2.0449139392504128

Epoch: 6| Step: 7
Training loss: 1.9090931415557861
Validation loss: 2.0287931401242494

Epoch: 6| Step: 8
Training loss: 2.185020685195923
Validation loss: 2.0563931054966424

Epoch: 6| Step: 9
Training loss: 1.8667665719985962
Validation loss: 2.0444351780799126

Epoch: 6| Step: 10
Training loss: 2.4929418563842773
Validation loss: 2.054435909435313

Epoch: 6| Step: 11
Training loss: 2.5298900604248047
Validation loss: 2.0364121032017533

Epoch: 6| Step: 12
Training loss: 2.1281347274780273
Validation loss: 2.043240903526224

Epoch: 6| Step: 13
Training loss: 2.5658717155456543
Validation loss: 2.025110997179503

Epoch: 168| Step: 0
Training loss: 2.497952938079834
Validation loss: 2.054772864105881

Epoch: 6| Step: 1
Training loss: 1.922257661819458
Validation loss: 2.056853678918654

Epoch: 6| Step: 2
Training loss: 3.1739864349365234
Validation loss: 2.033932348733307

Epoch: 6| Step: 3
Training loss: 1.802795171737671
Validation loss: 2.031710617003902

Epoch: 6| Step: 4
Training loss: 1.6921355724334717
Validation loss: 2.0406914295688754

Epoch: 6| Step: 5
Training loss: 2.3847970962524414
Validation loss: 2.038945072440691

Epoch: 6| Step: 6
Training loss: 2.0328640937805176
Validation loss: 2.0239544260886406

Epoch: 6| Step: 7
Training loss: 1.9153964519500732
Validation loss: 2.0044667746431086

Epoch: 6| Step: 8
Training loss: 2.2151761054992676
Validation loss: 2.0364840235761417

Epoch: 6| Step: 9
Training loss: 1.3339225053787231
Validation loss: 2.027616811055009

Epoch: 6| Step: 10
Training loss: 2.240457773208618
Validation loss: 2.0409087160582184

Epoch: 6| Step: 11
Training loss: 2.2777786254882812
Validation loss: 2.046822101839127

Epoch: 6| Step: 12
Training loss: 2.5432019233703613
Validation loss: 2.0430765510887228

Epoch: 6| Step: 13
Training loss: 2.36755633354187
Validation loss: 2.0301118627671273

Epoch: 169| Step: 0
Training loss: 1.5233533382415771
Validation loss: 2.0450094182004213

Epoch: 6| Step: 1
Training loss: 1.5142167806625366
Validation loss: 2.0469444182611283

Epoch: 6| Step: 2
Training loss: 2.831469774246216
Validation loss: 2.069821793545959

Epoch: 6| Step: 3
Training loss: 2.3616011142730713
Validation loss: 2.0239868830609065

Epoch: 6| Step: 4
Training loss: 2.377497911453247
Validation loss: 2.0578765817867812

Epoch: 6| Step: 5
Training loss: 1.8380510807037354
Validation loss: 2.036930566192955

Epoch: 6| Step: 6
Training loss: 2.2456066608428955
Validation loss: 2.0598755831359536

Epoch: 6| Step: 7
Training loss: 2.383070230484009
Validation loss: 2.0361771532284316

Epoch: 6| Step: 8
Training loss: 2.7327675819396973
Validation loss: 2.0296509060808408

Epoch: 6| Step: 9
Training loss: 1.7626821994781494
Validation loss: 2.006838507549737

Epoch: 6| Step: 10
Training loss: 2.188189744949341
Validation loss: 2.0109904940410326

Epoch: 6| Step: 11
Training loss: 2.027276039123535
Validation loss: 2.0438204773010744

Epoch: 6| Step: 12
Training loss: 2.2758350372314453
Validation loss: 2.02733628724211

Epoch: 6| Step: 13
Training loss: 2.4478836059570312
Validation loss: 2.0448894193095546

Epoch: 170| Step: 0
Training loss: 2.175858497619629
Validation loss: 2.0217034752650926

Epoch: 6| Step: 1
Training loss: 2.41701602935791
Validation loss: 2.0226306120554605

Epoch: 6| Step: 2
Training loss: 2.2152092456817627
Validation loss: 2.0322102718455817

Epoch: 6| Step: 3
Training loss: 1.5063161849975586
Validation loss: 2.0582758816339637

Epoch: 6| Step: 4
Training loss: 2.493194580078125
Validation loss: 2.0391555627187095

Epoch: 6| Step: 5
Training loss: 2.6862447261810303
Validation loss: 2.030503826756631

Epoch: 6| Step: 6
Training loss: 2.823652744293213
Validation loss: 2.04509739721975

Epoch: 6| Step: 7
Training loss: 2.044597864151001
Validation loss: 2.073787558463312

Epoch: 6| Step: 8
Training loss: 1.4126081466674805
Validation loss: 2.0487411124731905

Epoch: 6| Step: 9
Training loss: 2.427769660949707
Validation loss: 2.0700290164639874

Epoch: 6| Step: 10
Training loss: 1.5765292644500732
Validation loss: 2.0466487766594015

Epoch: 6| Step: 11
Training loss: 2.7617969512939453
Validation loss: 2.060982426007589

Epoch: 6| Step: 12
Training loss: 1.858675479888916
Validation loss: 2.0566488491591586

Epoch: 6| Step: 13
Training loss: 2.2469654083251953
Validation loss: 2.063149929046631

Epoch: 171| Step: 0
Training loss: 2.714754581451416
Validation loss: 2.0452754587255497

Epoch: 6| Step: 1
Training loss: 2.238975763320923
Validation loss: 2.0733176354439027

Epoch: 6| Step: 2
Training loss: 2.6793017387390137
Validation loss: 2.0554632294562554

Epoch: 6| Step: 3
Training loss: 2.0753250122070312
Validation loss: 2.0849245184211322

Epoch: 6| Step: 4
Training loss: 1.8777865171432495
Validation loss: 2.1032160994827107

Epoch: 6| Step: 5
Training loss: 2.1183857917785645
Validation loss: 2.077908762039677

Epoch: 6| Step: 6
Training loss: 1.6755410432815552
Validation loss: 2.0839832444344797

Epoch: 6| Step: 7
Training loss: 2.2521989345550537
Validation loss: 2.0814009917679654

Epoch: 6| Step: 8
Training loss: 2.0631237030029297
Validation loss: 2.091405459629592

Epoch: 6| Step: 9
Training loss: 1.9851287603378296
Validation loss: 2.0783521667603524

Epoch: 6| Step: 10
Training loss: 1.7729638814926147
Validation loss: 2.0658887970832085

Epoch: 6| Step: 11
Training loss: 2.5825936794281006
Validation loss: 2.0560887846895444

Epoch: 6| Step: 12
Training loss: 2.3756232261657715
Validation loss: 2.0978543527664675

Epoch: 6| Step: 13
Training loss: 1.898680567741394
Validation loss: 2.0688043255959787

Epoch: 172| Step: 0
Training loss: 1.325514793395996
Validation loss: 2.0521894103737286

Epoch: 6| Step: 1
Training loss: 3.1154561042785645
Validation loss: 2.0464886465380268

Epoch: 6| Step: 2
Training loss: 1.9793119430541992
Validation loss: 2.057887924614773

Epoch: 6| Step: 3
Training loss: 1.7911765575408936
Validation loss: 2.066136875460225

Epoch: 6| Step: 4
Training loss: 1.6625757217407227
Validation loss: 2.0478164611324186

Epoch: 6| Step: 5
Training loss: 2.098878860473633
Validation loss: 2.065223986102689

Epoch: 6| Step: 6
Training loss: 2.194647789001465
Validation loss: 2.0425063640840593

Epoch: 6| Step: 7
Training loss: 1.6771785020828247
Validation loss: 2.0536851934207383

Epoch: 6| Step: 8
Training loss: 1.5389840602874756
Validation loss: 2.02434346752782

Epoch: 6| Step: 9
Training loss: 2.7673912048339844
Validation loss: 2.0240209538449525

Epoch: 6| Step: 10
Training loss: 2.657205820083618
Validation loss: 2.047712372195336

Epoch: 6| Step: 11
Training loss: 2.052401542663574
Validation loss: 2.0374963180993193

Epoch: 6| Step: 12
Training loss: 3.034259796142578
Validation loss: 2.0563389255154516

Epoch: 6| Step: 13
Training loss: 2.67659854888916
Validation loss: 2.0502451235248196

Epoch: 173| Step: 0
Training loss: 2.0968127250671387
Validation loss: 2.045602486979577

Epoch: 6| Step: 1
Training loss: 1.9180902242660522
Validation loss: 2.0156104013484013

Epoch: 6| Step: 2
Training loss: 2.7294459342956543
Validation loss: 2.036831448155065

Epoch: 6| Step: 3
Training loss: 2.285013198852539
Validation loss: 2.0626239110064764

Epoch: 6| Step: 4
Training loss: 1.579067349433899
Validation loss: 2.0274970287917764

Epoch: 6| Step: 5
Training loss: 2.3363595008850098
Validation loss: 2.024236238130959

Epoch: 6| Step: 6
Training loss: 1.763459324836731
Validation loss: 2.05310554914577

Epoch: 6| Step: 7
Training loss: 2.4465105533599854
Validation loss: 2.016362823465819

Epoch: 6| Step: 8
Training loss: 2.685547351837158
Validation loss: 2.0267588630799325

Epoch: 6| Step: 9
Training loss: 1.597183108329773
Validation loss: 2.03907504645727

Epoch: 6| Step: 10
Training loss: 1.895416021347046
Validation loss: 2.0539074097910235

Epoch: 6| Step: 11
Training loss: 2.694667100906372
Validation loss: 2.0196997363080262

Epoch: 6| Step: 12
Training loss: 2.7579503059387207
Validation loss: 2.0152250259153304

Epoch: 6| Step: 13
Training loss: 1.0272527933120728
Validation loss: 2.035374633727535

Epoch: 174| Step: 0
Training loss: 2.238417387008667
Validation loss: 2.0447968590644097

Epoch: 6| Step: 1
Training loss: 2.6164979934692383
Validation loss: 2.042560600465344

Epoch: 6| Step: 2
Training loss: 2.670875072479248
Validation loss: 2.053842993192775

Epoch: 6| Step: 3
Training loss: 1.6345428228378296
Validation loss: 2.0448690383665022

Epoch: 6| Step: 4
Training loss: 1.6612489223480225
Validation loss: 2.034486783448086

Epoch: 6| Step: 5
Training loss: 2.206974506378174
Validation loss: 2.0472508861172583

Epoch: 6| Step: 6
Training loss: 1.8222475051879883
Validation loss: 2.0237541262821486

Epoch: 6| Step: 7
Training loss: 2.1937105655670166
Validation loss: 2.0590245364814677

Epoch: 6| Step: 8
Training loss: 1.8303287029266357
Validation loss: 2.0896957228260655

Epoch: 6| Step: 9
Training loss: 2.1153650283813477
Validation loss: 2.057763158634145

Epoch: 6| Step: 10
Training loss: 2.8609719276428223
Validation loss: 2.073739702983569

Epoch: 6| Step: 11
Training loss: 1.7039334774017334
Validation loss: 2.0705922470297864

Epoch: 6| Step: 12
Training loss: 2.345134735107422
Validation loss: 2.062708657274964

Epoch: 6| Step: 13
Training loss: 2.7997853755950928
Validation loss: 2.0598055316555883

Epoch: 175| Step: 0
Training loss: 2.180091619491577
Validation loss: 2.0680632181065057

Epoch: 6| Step: 1
Training loss: 2.2429778575897217
Validation loss: 2.049611096741051

Epoch: 6| Step: 2
Training loss: 2.2169790267944336
Validation loss: 2.0491989735634095

Epoch: 6| Step: 3
Training loss: 2.242708683013916
Validation loss: 2.0638088359627673

Epoch: 6| Step: 4
Training loss: 2.5017380714416504
Validation loss: 2.0447316310739003

Epoch: 6| Step: 5
Training loss: 1.5297585725784302
Validation loss: 2.052696256227391

Epoch: 6| Step: 6
Training loss: 2.1094446182250977
Validation loss: 2.0594627190661687

Epoch: 6| Step: 7
Training loss: 1.8945527076721191
Validation loss: 2.0673536728787165

Epoch: 6| Step: 8
Training loss: 2.569875717163086
Validation loss: 2.0373380825083744

Epoch: 6| Step: 9
Training loss: 3.0359981060028076
Validation loss: 2.0363698108221895

Epoch: 6| Step: 10
Training loss: 2.23905611038208
Validation loss: 2.038590923432381

Epoch: 6| Step: 11
Training loss: 1.9219999313354492
Validation loss: 2.061786202974217

Epoch: 6| Step: 12
Training loss: 1.6992957592010498
Validation loss: 2.0528636593972482

Epoch: 6| Step: 13
Training loss: 1.7985998392105103
Validation loss: 2.0683484846545803

Epoch: 176| Step: 0
Training loss: 2.6016039848327637
Validation loss: 2.0611713419678392

Epoch: 6| Step: 1
Training loss: 2.478959083557129
Validation loss: 2.080039844718031

Epoch: 6| Step: 2
Training loss: 1.6585497856140137
Validation loss: 2.0746066057553856

Epoch: 6| Step: 3
Training loss: 1.7800590991973877
Validation loss: 2.057167342914048

Epoch: 6| Step: 4
Training loss: 2.4292142391204834
Validation loss: 2.049725849141357

Epoch: 6| Step: 5
Training loss: 2.5099432468414307
Validation loss: 2.032728895064323

Epoch: 6| Step: 6
Training loss: 2.0763955116271973
Validation loss: 2.0676883369363765

Epoch: 6| Step: 7
Training loss: 2.6085398197174072
Validation loss: 2.056524956098167

Epoch: 6| Step: 8
Training loss: 1.9745289087295532
Validation loss: 2.0415192829665316

Epoch: 6| Step: 9
Training loss: 2.3721132278442383
Validation loss: 2.0274775515320482

Epoch: 6| Step: 10
Training loss: 1.6114733219146729
Validation loss: 2.0680577985702024

Epoch: 6| Step: 11
Training loss: 1.895592451095581
Validation loss: 2.0664867149886263

Epoch: 6| Step: 12
Training loss: 2.1169605255126953
Validation loss: 2.020567968327512

Epoch: 6| Step: 13
Training loss: 1.9170335531234741
Validation loss: 2.033395000683364

Epoch: 177| Step: 0
Training loss: 1.8679709434509277
Validation loss: 2.0534703282899756

Epoch: 6| Step: 1
Training loss: 2.17732834815979
Validation loss: 2.0649894668209936

Epoch: 6| Step: 2
Training loss: 1.4131126403808594
Validation loss: 2.067896291773806

Epoch: 6| Step: 3
Training loss: 2.0406594276428223
Validation loss: 2.0613174335930937

Epoch: 6| Step: 4
Training loss: 2.451694965362549
Validation loss: 2.088150316669095

Epoch: 6| Step: 5
Training loss: 1.7660335302352905
Validation loss: 2.0638982877936414

Epoch: 6| Step: 6
Training loss: 2.9706172943115234
Validation loss: 2.0668589966271513

Epoch: 6| Step: 7
Training loss: 2.15579891204834
Validation loss: 2.062416366351548

Epoch: 6| Step: 8
Training loss: 1.4632563591003418
Validation loss: 2.062693408740464

Epoch: 6| Step: 9
Training loss: 2.9219489097595215
Validation loss: 2.0629047629653767

Epoch: 6| Step: 10
Training loss: 3.137608051300049
Validation loss: 2.039527985357469

Epoch: 6| Step: 11
Training loss: 1.314063310623169
Validation loss: 2.0565594088646675

Epoch: 6| Step: 12
Training loss: 2.215059518814087
Validation loss: 2.0549038084604407

Epoch: 6| Step: 13
Training loss: 2.247457265853882
Validation loss: 2.062398715685773

Epoch: 178| Step: 0
Training loss: 1.8598816394805908
Validation loss: 2.045826987553668

Epoch: 6| Step: 1
Training loss: 1.9665017127990723
Validation loss: 2.0623528316456783

Epoch: 6| Step: 2
Training loss: 2.042309045791626
Validation loss: 2.0706265011141376

Epoch: 6| Step: 3
Training loss: 1.2115131616592407
Validation loss: 2.0658803819328226

Epoch: 6| Step: 4
Training loss: 2.6298775672912598
Validation loss: 2.0457528560392317

Epoch: 6| Step: 5
Training loss: 2.3694169521331787
Validation loss: 2.068359218617921

Epoch: 6| Step: 6
Training loss: 1.9792540073394775
Validation loss: 2.030165538992933

Epoch: 6| Step: 7
Training loss: 2.5853705406188965
Validation loss: 2.029423136864939

Epoch: 6| Step: 8
Training loss: 2.165379762649536
Validation loss: 2.0191173617557814

Epoch: 6| Step: 9
Training loss: 1.95747971534729
Validation loss: 2.0455416479418354

Epoch: 6| Step: 10
Training loss: 2.264814615249634
Validation loss: 2.010324319203695

Epoch: 6| Step: 11
Training loss: 2.802295207977295
Validation loss: 2.03327484925588

Epoch: 6| Step: 12
Training loss: 2.5170111656188965
Validation loss: 1.9947784946810814

Epoch: 6| Step: 13
Training loss: 1.7607455253601074
Validation loss: 2.043276907295309

Epoch: 179| Step: 0
Training loss: 2.0151751041412354
Validation loss: 2.0398954088969896

Epoch: 6| Step: 1
Training loss: 2.076193332672119
Validation loss: 2.0395719953762588

Epoch: 6| Step: 2
Training loss: 2.0953261852264404
Validation loss: 2.056057991520051

Epoch: 6| Step: 3
Training loss: 2.6173181533813477
Validation loss: 2.060578712853052

Epoch: 6| Step: 4
Training loss: 2.871166706085205
Validation loss: 2.070256128106066

Epoch: 6| Step: 5
Training loss: 1.3881111145019531
Validation loss: 2.0472809806946786

Epoch: 6| Step: 6
Training loss: 1.8596367835998535
Validation loss: 2.032588529330428

Epoch: 6| Step: 7
Training loss: 1.5519556999206543
Validation loss: 2.0359983803123556

Epoch: 6| Step: 8
Training loss: 2.0196280479431152
Validation loss: 2.0615678256557834

Epoch: 6| Step: 9
Training loss: 1.9374983310699463
Validation loss: 2.050936109276228

Epoch: 6| Step: 10
Training loss: 1.7034246921539307
Validation loss: 2.038926077145402

Epoch: 6| Step: 11
Training loss: 2.447547674179077
Validation loss: 2.0303267650706793

Epoch: 6| Step: 12
Training loss: 3.40863299369812
Validation loss: 2.0269305834206204

Epoch: 6| Step: 13
Training loss: 2.0239500999450684
Validation loss: 2.0421409094205467

Epoch: 180| Step: 0
Training loss: 2.8370676040649414
Validation loss: 2.0413357083515455

Epoch: 6| Step: 1
Training loss: 1.6971790790557861
Validation loss: 2.046973566855154

Epoch: 6| Step: 2
Training loss: 2.063753366470337
Validation loss: 2.0267532897251908

Epoch: 6| Step: 3
Training loss: 2.228701114654541
Validation loss: 2.017222539071114

Epoch: 6| Step: 4
Training loss: 3.062154769897461
Validation loss: 2.0567237497657858

Epoch: 6| Step: 5
Training loss: 2.00541353225708
Validation loss: 2.022700632772138

Epoch: 6| Step: 6
Training loss: 1.859992265701294
Validation loss: 2.0283182154419603

Epoch: 6| Step: 7
Training loss: 2.1490087509155273
Validation loss: 2.053954844833702

Epoch: 6| Step: 8
Training loss: 2.00101900100708
Validation loss: 2.019595376906856

Epoch: 6| Step: 9
Training loss: 1.9462804794311523
Validation loss: 2.0370485269895164

Epoch: 6| Step: 10
Training loss: 2.491487979888916
Validation loss: 2.0288128109388452

Epoch: 6| Step: 11
Training loss: 1.5757018327713013
Validation loss: 2.027505317041951

Epoch: 6| Step: 12
Training loss: 2.530099391937256
Validation loss: 2.0268523872539563

Epoch: 6| Step: 13
Training loss: 1.3779633045196533
Validation loss: 2.049581507200836

Epoch: 181| Step: 0
Training loss: 1.551598310470581
Validation loss: 2.0587651345037643

Epoch: 6| Step: 1
Training loss: 2.4302637577056885
Validation loss: 2.0551797369475007

Epoch: 6| Step: 2
Training loss: 2.919252634048462
Validation loss: 2.0474616872367037

Epoch: 6| Step: 3
Training loss: 1.8885836601257324
Validation loss: 2.0612384042432232

Epoch: 6| Step: 4
Training loss: 2.2253024578094482
Validation loss: 2.0649144239323114

Epoch: 6| Step: 5
Training loss: 1.6946558952331543
Validation loss: 2.0553430588014665

Epoch: 6| Step: 6
Training loss: 2.7520620822906494
Validation loss: 2.057702429832951

Epoch: 6| Step: 7
Training loss: 2.022459030151367
Validation loss: 2.058360861193749

Epoch: 6| Step: 8
Training loss: 1.60740065574646
Validation loss: 2.0612758897965953

Epoch: 6| Step: 9
Training loss: 2.4385669231414795
Validation loss: 2.0889746207062916

Epoch: 6| Step: 10
Training loss: 2.688486337661743
Validation loss: 2.073183295547321

Epoch: 6| Step: 11
Training loss: 2.2881321907043457
Validation loss: 2.073278619397071

Epoch: 6| Step: 12
Training loss: 1.7198013067245483
Validation loss: 2.0707854404244372

Epoch: 6| Step: 13
Training loss: 1.890056848526001
Validation loss: 2.0527757213961695

Epoch: 182| Step: 0
Training loss: 2.411351203918457
Validation loss: 2.082270663271668

Epoch: 6| Step: 1
Training loss: 2.2289979457855225
Validation loss: 2.08114763100942

Epoch: 6| Step: 2
Training loss: 1.8711934089660645
Validation loss: 2.075806586973129

Epoch: 6| Step: 3
Training loss: 1.691021203994751
Validation loss: 2.0596382874314503

Epoch: 6| Step: 4
Training loss: 2.426304340362549
Validation loss: 2.0803749407491376

Epoch: 6| Step: 5
Training loss: 2.400265693664551
Validation loss: 2.0724001392241447

Epoch: 6| Step: 6
Training loss: 1.562288522720337
Validation loss: 2.0531551402102233

Epoch: 6| Step: 7
Training loss: 1.481852412223816
Validation loss: 2.081151675152522

Epoch: 6| Step: 8
Training loss: 2.5903754234313965
Validation loss: 2.0662300689246065

Epoch: 6| Step: 9
Training loss: 2.636141777038574
Validation loss: 2.074084876686014

Epoch: 6| Step: 10
Training loss: 2.310359001159668
Validation loss: 2.0667321476885068

Epoch: 6| Step: 11
Training loss: 2.5826470851898193
Validation loss: 2.0563594551496607

Epoch: 6| Step: 12
Training loss: 1.7085371017456055
Validation loss: 2.0725018491027174

Epoch: 6| Step: 13
Training loss: 2.211341619491577
Validation loss: 2.0523001250400337

Epoch: 183| Step: 0
Training loss: 2.084775924682617
Validation loss: 2.0427693525950112

Epoch: 6| Step: 1
Training loss: 2.6181507110595703
Validation loss: 2.05652634046411

Epoch: 6| Step: 2
Training loss: 2.1584935188293457
Validation loss: 2.0621317330227105

Epoch: 6| Step: 3
Training loss: 1.6120115518569946
Validation loss: 2.054967717457843

Epoch: 6| Step: 4
Training loss: 2.2261526584625244
Validation loss: 2.045129763182773

Epoch: 6| Step: 5
Training loss: 1.4796335697174072
Validation loss: 2.049456695074676

Epoch: 6| Step: 6
Training loss: 2.7446770668029785
Validation loss: 2.0590577330640567

Epoch: 6| Step: 7
Training loss: 2.2295446395874023
Validation loss: 2.0368457263515842

Epoch: 6| Step: 8
Training loss: 2.416294574737549
Validation loss: 2.0729742614171838

Epoch: 6| Step: 9
Training loss: 2.4917807579040527
Validation loss: 2.0390721649251957

Epoch: 6| Step: 10
Training loss: 2.1612160205841064
Validation loss: 2.0441041018373225

Epoch: 6| Step: 11
Training loss: 1.6768426895141602
Validation loss: 2.0497433408614127

Epoch: 6| Step: 12
Training loss: 2.6062440872192383
Validation loss: 2.0699720254508396

Epoch: 6| Step: 13
Training loss: 1.5982699394226074
Validation loss: 2.059906582678518

Epoch: 184| Step: 0
Training loss: 2.381521701812744
Validation loss: 2.053904310349495

Epoch: 6| Step: 1
Training loss: 2.2141590118408203
Validation loss: 2.049646923618932

Epoch: 6| Step: 2
Training loss: 1.4331104755401611
Validation loss: 2.0409368968779042

Epoch: 6| Step: 3
Training loss: 2.249798536300659
Validation loss: 2.0331117722295944

Epoch: 6| Step: 4
Training loss: 2.5127036571502686
Validation loss: 2.0393179988348358

Epoch: 6| Step: 5
Training loss: 2.0198605060577393
Validation loss: 2.0023864046219857

Epoch: 6| Step: 6
Training loss: 2.216454029083252
Validation loss: 2.0258979489726405

Epoch: 6| Step: 7
Training loss: 1.9848233461380005
Validation loss: 2.0367831286563667

Epoch: 6| Step: 8
Training loss: 2.8046746253967285
Validation loss: 2.0218949138477282

Epoch: 6| Step: 9
Training loss: 1.4221763610839844
Validation loss: 2.047791370781519

Epoch: 6| Step: 10
Training loss: 2.2874622344970703
Validation loss: 2.0413244052599837

Epoch: 6| Step: 11
Training loss: 2.7579848766326904
Validation loss: 2.0297276537905455

Epoch: 6| Step: 12
Training loss: 2.308145761489868
Validation loss: 2.0441018099425943

Epoch: 6| Step: 13
Training loss: 1.2416021823883057
Validation loss: 2.0385402018024075

Epoch: 185| Step: 0
Training loss: 2.2708141803741455
Validation loss: 2.039519576616185

Epoch: 6| Step: 1
Training loss: 1.9343899488449097
Validation loss: 2.0421644282597367

Epoch: 6| Step: 2
Training loss: 2.0701589584350586
Validation loss: 2.0517661417684248

Epoch: 6| Step: 3
Training loss: 1.967759609222412
Validation loss: 2.050072395673362

Epoch: 6| Step: 4
Training loss: 2.88542103767395
Validation loss: 2.0366131285185456

Epoch: 6| Step: 5
Training loss: 1.8318791389465332
Validation loss: 2.049618023698048

Epoch: 6| Step: 6
Training loss: 2.911405324935913
Validation loss: 2.047411628948745

Epoch: 6| Step: 7
Training loss: 2.277660846710205
Validation loss: 2.0449465013319448

Epoch: 6| Step: 8
Training loss: 2.5200932025909424
Validation loss: 2.042695060853035

Epoch: 6| Step: 9
Training loss: 2.372729539871216
Validation loss: 2.053626257886169

Epoch: 6| Step: 10
Training loss: 1.3873062133789062
Validation loss: 2.0588858563412904

Epoch: 6| Step: 11
Training loss: 1.817139744758606
Validation loss: 2.049969726993192

Epoch: 6| Step: 12
Training loss: 2.0253849029541016
Validation loss: 2.0388571728942213

Epoch: 6| Step: 13
Training loss: 1.871915578842163
Validation loss: 2.050204277038574

Epoch: 186| Step: 0
Training loss: 1.7696423530578613
Validation loss: 2.0569438011415544

Epoch: 6| Step: 1
Training loss: 2.588723659515381
Validation loss: 2.0299575764645814

Epoch: 6| Step: 2
Training loss: 2.3833396434783936
Validation loss: 2.0422018420311714

Epoch: 6| Step: 3
Training loss: 1.8746778964996338
Validation loss: 2.0503791506572435

Epoch: 6| Step: 4
Training loss: 2.1270694732666016
Validation loss: 2.040916130106936

Epoch: 6| Step: 5
Training loss: 1.7806994915008545
Validation loss: 2.050774610170754

Epoch: 6| Step: 6
Training loss: 2.048931121826172
Validation loss: 2.058360153628934

Epoch: 6| Step: 7
Training loss: 2.018597364425659
Validation loss: 2.0612201318945935

Epoch: 6| Step: 8
Training loss: 2.3232266902923584
Validation loss: 2.0684141676913024

Epoch: 6| Step: 9
Training loss: 2.322408676147461
Validation loss: 2.0660798934198197

Epoch: 6| Step: 10
Training loss: 2.145115613937378
Validation loss: 2.0742705573317823

Epoch: 6| Step: 11
Training loss: 1.6920362710952759
Validation loss: 2.025380757547194

Epoch: 6| Step: 12
Training loss: 2.543865919113159
Validation loss: 2.057293289451189

Epoch: 6| Step: 13
Training loss: 2.7022907733917236
Validation loss: 2.030035085575555

Epoch: 187| Step: 0
Training loss: 2.2628769874572754
Validation loss: 2.0320214379218315

Epoch: 6| Step: 1
Training loss: 2.2709269523620605
Validation loss: 2.041745275579473

Epoch: 6| Step: 2
Training loss: 2.0351085662841797
Validation loss: 2.060105800628662

Epoch: 6| Step: 3
Training loss: 1.9213584661483765
Validation loss: 2.0197764981177544

Epoch: 6| Step: 4
Training loss: 2.366454601287842
Validation loss: 2.0485729094474547

Epoch: 6| Step: 5
Training loss: 1.734988808631897
Validation loss: 2.0565383511204876

Epoch: 6| Step: 6
Training loss: 2.4686408042907715
Validation loss: 2.0387366792207122

Epoch: 6| Step: 7
Training loss: 1.75251042842865
Validation loss: 2.0561513106028237

Epoch: 6| Step: 8
Training loss: 1.9328442811965942
Validation loss: 2.0244246016266527

Epoch: 6| Step: 9
Training loss: 1.7927507162094116
Validation loss: 2.032548375027154

Epoch: 6| Step: 10
Training loss: 2.44783878326416
Validation loss: 2.06011543222653

Epoch: 6| Step: 11
Training loss: 2.431607246398926
Validation loss: 2.059648939358291

Epoch: 6| Step: 12
Training loss: 2.5681850910186768
Validation loss: 2.041154287194693

Epoch: 6| Step: 13
Training loss: 2.226008892059326
Validation loss: 2.0617938349323888

Epoch: 188| Step: 0
Training loss: 1.8713123798370361
Validation loss: 2.0610028492507113

Epoch: 6| Step: 1
Training loss: 1.7661068439483643
Validation loss: 2.0275892070544663

Epoch: 6| Step: 2
Training loss: 2.0111374855041504
Validation loss: 2.022581852892394

Epoch: 6| Step: 3
Training loss: 1.9297122955322266
Validation loss: 2.040335447557511

Epoch: 6| Step: 4
Training loss: 2.041499137878418
Validation loss: 2.0520844126260407

Epoch: 6| Step: 5
Training loss: 2.0255661010742188
Validation loss: 2.0279488666083223

Epoch: 6| Step: 6
Training loss: 2.016780376434326
Validation loss: 2.0361000030271468

Epoch: 6| Step: 7
Training loss: 3.1395514011383057
Validation loss: 2.0346250918603714

Epoch: 6| Step: 8
Training loss: 2.421926498413086
Validation loss: 2.0323980316039054

Epoch: 6| Step: 9
Training loss: 2.363236427307129
Validation loss: 2.0548963854389806

Epoch: 6| Step: 10
Training loss: 2.3279671669006348
Validation loss: 2.0316147163350093

Epoch: 6| Step: 11
Training loss: 1.8120808601379395
Validation loss: 2.0212960166315876

Epoch: 6| Step: 12
Training loss: 2.820432186126709
Validation loss: 2.0252274646553943

Epoch: 6| Step: 13
Training loss: 1.0909066200256348
Validation loss: 2.0389232148406324

Epoch: 189| Step: 0
Training loss: 2.5241425037384033
Validation loss: 2.0216534278726064

Epoch: 6| Step: 1
Training loss: 1.6297039985656738
Validation loss: 2.029779317558453

Epoch: 6| Step: 2
Training loss: 1.7563871145248413
Validation loss: 2.0347438999401626

Epoch: 6| Step: 3
Training loss: 2.2614564895629883
Validation loss: 2.045027558521558

Epoch: 6| Step: 4
Training loss: 2.0779073238372803
Validation loss: 2.062667408297139

Epoch: 6| Step: 5
Training loss: 2.6048574447631836
Validation loss: 2.0506013131910756

Epoch: 6| Step: 6
Training loss: 2.6346731185913086
Validation loss: 2.0606972504687566

Epoch: 6| Step: 7
Training loss: 1.7689487934112549
Validation loss: 2.044119591354042

Epoch: 6| Step: 8
Training loss: 1.9719433784484863
Validation loss: 2.060719464414863

Epoch: 6| Step: 9
Training loss: 1.643269658088684
Validation loss: 2.0434622764587402

Epoch: 6| Step: 10
Training loss: 2.209693431854248
Validation loss: 2.031765235367642

Epoch: 6| Step: 11
Training loss: 2.407620429992676
Validation loss: 2.0429639918829805

Epoch: 6| Step: 12
Training loss: 2.4869234561920166
Validation loss: 2.04611494464259

Epoch: 6| Step: 13
Training loss: 2.241868495941162
Validation loss: 2.014689782614349

Epoch: 190| Step: 0
Training loss: 1.814452886581421
Validation loss: 2.0376124997292795

Epoch: 6| Step: 1
Training loss: 1.933756709098816
Validation loss: 2.0656340840042278

Epoch: 6| Step: 2
Training loss: 1.1990067958831787
Validation loss: 2.0513357347057712

Epoch: 6| Step: 3
Training loss: 2.4612584114074707
Validation loss: 2.0597292172011508

Epoch: 6| Step: 4
Training loss: 2.322125196456909
Validation loss: 2.056944090832946

Epoch: 6| Step: 5
Training loss: 2.1420817375183105
Validation loss: 2.0567430629525134

Epoch: 6| Step: 6
Training loss: 2.3851187229156494
Validation loss: 2.027511509515906

Epoch: 6| Step: 7
Training loss: 1.7699785232543945
Validation loss: 2.0471875129207486

Epoch: 6| Step: 8
Training loss: 2.6080403327941895
Validation loss: 2.0407150663355345

Epoch: 6| Step: 9
Training loss: 1.9220983982086182
Validation loss: 2.0440196580784296

Epoch: 6| Step: 10
Training loss: 2.050680637359619
Validation loss: 2.030833690397201

Epoch: 6| Step: 11
Training loss: 2.221518039703369
Validation loss: 2.0397937451639483

Epoch: 6| Step: 12
Training loss: 2.5112249851226807
Validation loss: 2.051205499197847

Epoch: 6| Step: 13
Training loss: 2.93700909614563
Validation loss: 2.030876548059525

Epoch: 191| Step: 0
Training loss: 2.5403852462768555
Validation loss: 2.055797633304391

Epoch: 6| Step: 1
Training loss: 2.9416964054107666
Validation loss: 2.045648028773646

Epoch: 6| Step: 2
Training loss: 2.0504262447357178
Validation loss: 2.0246643661170878

Epoch: 6| Step: 3
Training loss: 1.4092938899993896
Validation loss: 2.0524009299534622

Epoch: 6| Step: 4
Training loss: 2.398038625717163
Validation loss: 2.0379778146743774

Epoch: 6| Step: 5
Training loss: 2.2810745239257812
Validation loss: 2.0418687071851505

Epoch: 6| Step: 6
Training loss: 1.531738042831421
Validation loss: 2.032477545481856

Epoch: 6| Step: 7
Training loss: 2.2631711959838867
Validation loss: 2.051066685748357

Epoch: 6| Step: 8
Training loss: 2.1143064498901367
Validation loss: 2.0641384278574297

Epoch: 6| Step: 9
Training loss: 1.8173184394836426
Validation loss: 2.0366572333920385

Epoch: 6| Step: 10
Training loss: 3.0647549629211426
Validation loss: 2.0516551156197824

Epoch: 6| Step: 11
Training loss: 1.5417721271514893
Validation loss: 2.060590254363193

Epoch: 6| Step: 12
Training loss: 1.8518526554107666
Validation loss: 2.063738125626759

Epoch: 6| Step: 13
Training loss: 2.144089460372925
Validation loss: 2.0698848168055215

Epoch: 192| Step: 0
Training loss: 2.0399153232574463
Validation loss: 2.061016373736884

Epoch: 6| Step: 1
Training loss: 1.9348453283309937
Validation loss: 2.0445675337186424

Epoch: 6| Step: 2
Training loss: 1.9512251615524292
Validation loss: 2.0519678208135788

Epoch: 6| Step: 3
Training loss: 1.9504055976867676
Validation loss: 2.055245635330036

Epoch: 6| Step: 4
Training loss: 1.156365156173706
Validation loss: 2.047099441610357

Epoch: 6| Step: 5
Training loss: 1.9220466613769531
Validation loss: 2.0434532101436327

Epoch: 6| Step: 6
Training loss: 2.797982692718506
Validation loss: 2.062153177876626

Epoch: 6| Step: 7
Training loss: 2.5859529972076416
Validation loss: 2.034378672158846

Epoch: 6| Step: 8
Training loss: 2.520717144012451
Validation loss: 2.040374461040702

Epoch: 6| Step: 9
Training loss: 3.0476245880126953
Validation loss: 2.0638030472622124

Epoch: 6| Step: 10
Training loss: 2.2346200942993164
Validation loss: 2.055084313115766

Epoch: 6| Step: 11
Training loss: 2.3740830421447754
Validation loss: 2.0672066929519817

Epoch: 6| Step: 12
Training loss: 1.328906774520874
Validation loss: 2.045116270742109

Epoch: 6| Step: 13
Training loss: 2.3407986164093018
Validation loss: 2.050041308967016

Epoch: 193| Step: 0
Training loss: 2.2088863849639893
Validation loss: 2.0409856598864318

Epoch: 6| Step: 1
Training loss: 3.2165699005126953
Validation loss: 2.0350329145308463

Epoch: 6| Step: 2
Training loss: 1.6817244291305542
Validation loss: 2.042922786487046

Epoch: 6| Step: 3
Training loss: 2.2160837650299072
Validation loss: 2.0536937226531324

Epoch: 6| Step: 4
Training loss: 2.1785850524902344
Validation loss: 2.0586670316675657

Epoch: 6| Step: 5
Training loss: 1.5654369592666626
Validation loss: 2.077298366895286

Epoch: 6| Step: 6
Training loss: 1.5842483043670654
Validation loss: 2.0684478077837216

Epoch: 6| Step: 7
Training loss: 2.991164207458496
Validation loss: 2.073714122977308

Epoch: 6| Step: 8
Training loss: 2.4848554134368896
Validation loss: 2.061982213809926

Epoch: 6| Step: 9
Training loss: 2.2669944763183594
Validation loss: 2.085754204821843

Epoch: 6| Step: 10
Training loss: 1.8891524076461792
Validation loss: 2.0953556132572952

Epoch: 6| Step: 11
Training loss: 2.228562831878662
Validation loss: 2.0536740364566928

Epoch: 6| Step: 12
Training loss: 1.8488318920135498
Validation loss: 2.071613304076656

Epoch: 6| Step: 13
Training loss: 1.1752057075500488
Validation loss: 2.0748639863024474

Epoch: 194| Step: 0
Training loss: 2.877230167388916
Validation loss: 2.0741765114568893

Epoch: 6| Step: 1
Training loss: 1.685515284538269
Validation loss: 2.0596748936560845

Epoch: 6| Step: 2
Training loss: 1.9334964752197266
Validation loss: 2.0390267372131348

Epoch: 6| Step: 3
Training loss: 2.8765811920166016
Validation loss: 2.0855353647662747

Epoch: 6| Step: 4
Training loss: 2.353304386138916
Validation loss: 2.0585057825170536

Epoch: 6| Step: 5
Training loss: 2.0066077709198
Validation loss: 2.040147368625928

Epoch: 6| Step: 6
Training loss: 2.061324119567871
Validation loss: 2.06332294658948

Epoch: 6| Step: 7
Training loss: 1.6243207454681396
Validation loss: 2.0690229618421165

Epoch: 6| Step: 8
Training loss: 1.6390031576156616
Validation loss: 2.0346576552237234

Epoch: 6| Step: 9
Training loss: 2.5250186920166016
Validation loss: 2.0507581772342807

Epoch: 6| Step: 10
Training loss: 2.0041933059692383
Validation loss: 2.0322507491675754

Epoch: 6| Step: 11
Training loss: 2.0039143562316895
Validation loss: 2.0409906115583194

Epoch: 6| Step: 12
Training loss: 2.602748155593872
Validation loss: 2.0474984325388426

Epoch: 6| Step: 13
Training loss: 1.3224749565124512
Validation loss: 2.0492515166600547

Epoch: 195| Step: 0
Training loss: 2.180363178253174
Validation loss: 2.0451448296987884

Epoch: 6| Step: 1
Training loss: 1.6795247793197632
Validation loss: 2.0562703891467025

Epoch: 6| Step: 2
Training loss: 2.7077558040618896
Validation loss: 2.036118516357996

Epoch: 6| Step: 3
Training loss: 2.4462108612060547
Validation loss: 2.0465507648324452

Epoch: 6| Step: 4
Training loss: 2.5441160202026367
Validation loss: 2.0810979540630052

Epoch: 6| Step: 5
Training loss: 1.9789001941680908
Validation loss: 2.030337882298295

Epoch: 6| Step: 6
Training loss: 1.4701201915740967
Validation loss: 2.041974498379615

Epoch: 6| Step: 7
Training loss: 2.1326749324798584
Validation loss: 2.0499869033854496

Epoch: 6| Step: 8
Training loss: 2.505916118621826
Validation loss: 2.026025838749383

Epoch: 6| Step: 9
Training loss: 2.137610912322998
Validation loss: 2.0546150104973906

Epoch: 6| Step: 10
Training loss: 1.9851338863372803
Validation loss: 2.045086083873626

Epoch: 6| Step: 11
Training loss: 2.22536563873291
Validation loss: 2.056653404748568

Epoch: 6| Step: 12
Training loss: 2.0756449699401855
Validation loss: 2.0442260837042205

Epoch: 6| Step: 13
Training loss: 1.7951780557632446
Validation loss: 2.070795756514354

Epoch: 196| Step: 0
Training loss: 2.5509531497955322
Validation loss: 2.0459206924643567

Epoch: 6| Step: 1
Training loss: 1.8343980312347412
Validation loss: 2.03437138629216

Epoch: 6| Step: 2
Training loss: 2.0282697677612305
Validation loss: 2.03086273131832

Epoch: 6| Step: 3
Training loss: 2.19852352142334
Validation loss: 2.049658754820465

Epoch: 6| Step: 4
Training loss: 2.6537094116210938
Validation loss: 2.055214843442363

Epoch: 6| Step: 5
Training loss: 2.7424967288970947
Validation loss: 2.0450314244916363

Epoch: 6| Step: 6
Training loss: 1.6299262046813965
Validation loss: 2.075087410147472

Epoch: 6| Step: 7
Training loss: 1.8466508388519287
Validation loss: 2.0367916027704873

Epoch: 6| Step: 8
Training loss: 2.2873849868774414
Validation loss: 2.040880021228585

Epoch: 6| Step: 9
Training loss: 1.5634355545043945
Validation loss: 2.050738015482503

Epoch: 6| Step: 10
Training loss: 1.5824642181396484
Validation loss: 2.054616935791508

Epoch: 6| Step: 11
Training loss: 2.4443368911743164
Validation loss: 2.0321188870296685

Epoch: 6| Step: 12
Training loss: 2.4705169200897217
Validation loss: 2.0143932937293925

Epoch: 6| Step: 13
Training loss: 2.069807767868042
Validation loss: 2.022264067844678

Epoch: 197| Step: 0
Training loss: 2.003068208694458
Validation loss: 2.067579686000783

Epoch: 6| Step: 1
Training loss: 1.8115214109420776
Validation loss: 2.0255422348617227

Epoch: 6| Step: 2
Training loss: 2.913870334625244
Validation loss: 2.046795170794251

Epoch: 6| Step: 3
Training loss: 3.0351247787475586
Validation loss: 2.049876061818933

Epoch: 6| Step: 4
Training loss: 2.1081271171569824
Validation loss: 2.036412057056222

Epoch: 6| Step: 5
Training loss: 1.4491502046585083
Validation loss: 2.044478985571092

Epoch: 6| Step: 6
Training loss: 1.8321547508239746
Validation loss: 2.0547100728557957

Epoch: 6| Step: 7
Training loss: 1.5470120906829834
Validation loss: 2.060381591960948

Epoch: 6| Step: 8
Training loss: 2.077983856201172
Validation loss: 2.0313171135481967

Epoch: 6| Step: 9
Training loss: 1.6034719944000244
Validation loss: 2.0409190782936673

Epoch: 6| Step: 10
Training loss: 2.489949941635132
Validation loss: 2.050588628297211

Epoch: 6| Step: 11
Training loss: 2.6174049377441406
Validation loss: 2.058654446755686

Epoch: 6| Step: 12
Training loss: 2.070858955383301
Validation loss: 2.036209624300721

Epoch: 6| Step: 13
Training loss: 2.917856216430664
Validation loss: 2.0258521469690467

Epoch: 198| Step: 0
Training loss: 1.7040436267852783
Validation loss: 2.0367603584002425

Epoch: 6| Step: 1
Training loss: 2.5027964115142822
Validation loss: 2.030481587174118

Epoch: 6| Step: 2
Training loss: 2.1897311210632324
Validation loss: 2.0235085423274706

Epoch: 6| Step: 3
Training loss: 2.6169142723083496
Validation loss: 2.04882453462129

Epoch: 6| Step: 4
Training loss: 2.084756374359131
Validation loss: 2.0305775544976674

Epoch: 6| Step: 5
Training loss: 2.037377119064331
Validation loss: 2.0283003789122387

Epoch: 6| Step: 6
Training loss: 1.7707479000091553
Validation loss: 2.0203676480118946

Epoch: 6| Step: 7
Training loss: 1.5699265003204346
Validation loss: 2.0224493831716557

Epoch: 6| Step: 8
Training loss: 2.0271811485290527
Validation loss: 2.0602162050944504

Epoch: 6| Step: 9
Training loss: 2.6144168376922607
Validation loss: 2.042473964793708

Epoch: 6| Step: 10
Training loss: 1.6538383960723877
Validation loss: 2.044270246259628

Epoch: 6| Step: 11
Training loss: 2.4611449241638184
Validation loss: 2.033958635022563

Epoch: 6| Step: 12
Training loss: 2.414836883544922
Validation loss: 2.0316501996850453

Epoch: 6| Step: 13
Training loss: 2.597593307495117
Validation loss: 2.032972260188031

Epoch: 199| Step: 0
Training loss: 1.9799702167510986
Validation loss: 2.043647450785483

Epoch: 6| Step: 1
Training loss: 2.9300153255462646
Validation loss: 2.0262183450883433

Epoch: 6| Step: 2
Training loss: 2.612149238586426
Validation loss: 2.0361344737391316

Epoch: 6| Step: 3
Training loss: 1.871071457862854
Validation loss: 2.0647858752999255

Epoch: 6| Step: 4
Training loss: 1.8604737520217896
Validation loss: 2.040554265822134

Epoch: 6| Step: 5
Training loss: 2.0514140129089355
Validation loss: 2.0709617971092142

Epoch: 6| Step: 6
Training loss: 1.5814753770828247
Validation loss: 2.05788073232097

Epoch: 6| Step: 7
Training loss: 2.1037120819091797
Validation loss: 2.0591392132543747

Epoch: 6| Step: 8
Training loss: 2.8639559745788574
Validation loss: 2.1023356401792137

Epoch: 6| Step: 9
Training loss: 2.095261812210083
Validation loss: 2.07580179168332

Epoch: 6| Step: 10
Training loss: 1.9860007762908936
Validation loss: 2.0808940382413965

Epoch: 6| Step: 11
Training loss: 2.1102871894836426
Validation loss: 2.086140389083534

Epoch: 6| Step: 12
Training loss: 1.8186653852462769
Validation loss: 2.060726264471649

Epoch: 6| Step: 13
Training loss: 2.142498254776001
Validation loss: 2.0719837655303297

Epoch: 200| Step: 0
Training loss: 2.741422414779663
Validation loss: 2.0660574641278995

Epoch: 6| Step: 1
Training loss: 1.521338939666748
Validation loss: 2.0715761030873945

Epoch: 6| Step: 2
Training loss: 1.7843406200408936
Validation loss: 2.067138204010584

Epoch: 6| Step: 3
Training loss: 2.3992807865142822
Validation loss: 2.0688178436730498

Epoch: 6| Step: 4
Training loss: 2.8210244178771973
Validation loss: 2.0509593473967684

Epoch: 6| Step: 5
Training loss: 2.1920857429504395
Validation loss: 2.061465017257198

Epoch: 6| Step: 6
Training loss: 1.9458260536193848
Validation loss: 2.068351730223625

Epoch: 6| Step: 7
Training loss: 2.4178075790405273
Validation loss: 2.0417799385645057

Epoch: 6| Step: 8
Training loss: 1.8093476295471191
Validation loss: 2.0503642917961202

Epoch: 6| Step: 9
Training loss: 1.3068606853485107
Validation loss: 2.058688789285639

Epoch: 6| Step: 10
Training loss: 2.329435348510742
Validation loss: 2.0532592035109

Epoch: 6| Step: 11
Training loss: 2.1029281616210938
Validation loss: 2.089005720230841

Epoch: 6| Step: 12
Training loss: 2.5495972633361816
Validation loss: 2.06137696132865

Epoch: 6| Step: 13
Training loss: 1.7118042707443237
Validation loss: 2.0421568129652288

Epoch: 201| Step: 0
Training loss: 2.1418490409851074
Validation loss: 2.036535838598846

Epoch: 6| Step: 1
Training loss: 2.259312629699707
Validation loss: 2.0569122632344565

Epoch: 6| Step: 2
Training loss: 2.6345982551574707
Validation loss: 2.0695442666289625

Epoch: 6| Step: 3
Training loss: 2.6466732025146484
Validation loss: 2.0635974381559636

Epoch: 6| Step: 4
Training loss: 2.7917540073394775
Validation loss: 2.0625354666863718

Epoch: 6| Step: 5
Training loss: 2.2930264472961426
Validation loss: 2.041947865998873

Epoch: 6| Step: 6
Training loss: 1.1392760276794434
Validation loss: 2.0740413101770545

Epoch: 6| Step: 7
Training loss: 1.8987715244293213
Validation loss: 2.073051283436437

Epoch: 6| Step: 8
Training loss: 2.2064104080200195
Validation loss: 2.065426331694408

Epoch: 6| Step: 9
Training loss: 1.9395462274551392
Validation loss: 2.0583857874716482

Epoch: 6| Step: 10
Training loss: 1.6840765476226807
Validation loss: 2.051842240877049

Epoch: 6| Step: 11
Training loss: 2.1679880619049072
Validation loss: 2.0535752850194133

Epoch: 6| Step: 12
Training loss: 2.1543655395507812
Validation loss: 2.0633544460419686

Epoch: 6| Step: 13
Training loss: 1.9333932399749756
Validation loss: 2.048048310382392

Epoch: 202| Step: 0
Training loss: 2.2406082153320312
Validation loss: 2.0671164733107372

Epoch: 6| Step: 1
Training loss: 2.2889671325683594
Validation loss: 2.054113477788946

Epoch: 6| Step: 2
Training loss: 2.5718297958374023
Validation loss: 2.0559874350024807

Epoch: 6| Step: 3
Training loss: 2.20617413520813
Validation loss: 2.0348486182510213

Epoch: 6| Step: 4
Training loss: 2.6094164848327637
Validation loss: 2.0456881753859983

Epoch: 6| Step: 5
Training loss: 1.4081361293792725
Validation loss: 2.0414532640928864

Epoch: 6| Step: 6
Training loss: 2.268446445465088
Validation loss: 2.0419726282037716

Epoch: 6| Step: 7
Training loss: 2.2592782974243164
Validation loss: 2.027634870621466

Epoch: 6| Step: 8
Training loss: 1.900596022605896
Validation loss: 2.03553024671411

Epoch: 6| Step: 9
Training loss: 1.8382129669189453
Validation loss: 1.9918131418125604

Epoch: 6| Step: 10
Training loss: 2.5205910205841064
Validation loss: 2.0156443670231807

Epoch: 6| Step: 11
Training loss: 1.2480093240737915
Validation loss: 2.03248929977417

Epoch: 6| Step: 12
Training loss: 2.0850605964660645
Validation loss: 2.034803936558385

Epoch: 6| Step: 13
Training loss: 2.7440242767333984
Validation loss: 2.022227269346996

Epoch: 203| Step: 0
Training loss: 1.4247736930847168
Validation loss: 2.0451150145581973

Epoch: 6| Step: 1
Training loss: 2.415356159210205
Validation loss: 2.040264178347844

Epoch: 6| Step: 2
Training loss: 1.9344956874847412
Validation loss: 2.041739882961396

Epoch: 6| Step: 3
Training loss: 1.93381667137146
Validation loss: 2.0458665893923853

Epoch: 6| Step: 4
Training loss: 2.6206696033477783
Validation loss: 2.018602917271276

Epoch: 6| Step: 5
Training loss: 2.1333160400390625
Validation loss: 2.0401328302198842

Epoch: 6| Step: 6
Training loss: 2.7099874019622803
Validation loss: 2.012693230823804

Epoch: 6| Step: 7
Training loss: 2.1393580436706543
Validation loss: 2.0261290073394775

Epoch: 6| Step: 8
Training loss: 1.828647255897522
Validation loss: 2.0409572303936048

Epoch: 6| Step: 9
Training loss: 1.9764809608459473
Validation loss: 2.0455351209127777

Epoch: 6| Step: 10
Training loss: 2.6367506980895996
Validation loss: 2.0439625837469615

Epoch: 6| Step: 11
Training loss: 1.7812074422836304
Validation loss: 2.03906112973408

Epoch: 6| Step: 12
Training loss: 2.2309374809265137
Validation loss: 2.048724456499982

Epoch: 6| Step: 13
Training loss: 2.303755760192871
Validation loss: 2.0642169983156267

Epoch: 204| Step: 0
Training loss: 2.4494152069091797
Validation loss: 2.0384917438671155

Epoch: 6| Step: 1
Training loss: 2.76689076423645
Validation loss: 2.0630250823113228

Epoch: 6| Step: 2
Training loss: 1.9167966842651367
Validation loss: 2.0615828947354387

Epoch: 6| Step: 3
Training loss: 2.0356192588806152
Validation loss: 2.0641023612791494

Epoch: 6| Step: 4
Training loss: 2.4015190601348877
Validation loss: 2.042874611834044

Epoch: 6| Step: 5
Training loss: 1.868180513381958
Validation loss: 2.0543294388760804

Epoch: 6| Step: 6
Training loss: 2.2235159873962402
Validation loss: 2.0667512288657566

Epoch: 6| Step: 7
Training loss: 2.4929637908935547
Validation loss: 2.078098325319188

Epoch: 6| Step: 8
Training loss: 2.3070642948150635
Validation loss: 2.033864689129655

Epoch: 6| Step: 9
Training loss: 1.268601655960083
Validation loss: 2.0654575222282

Epoch: 6| Step: 10
Training loss: 1.699117660522461
Validation loss: 2.071585116847869

Epoch: 6| Step: 11
Training loss: 2.176347255706787
Validation loss: 2.086784282038289

Epoch: 6| Step: 12
Training loss: 1.957038164138794
Validation loss: 2.077815055847168

Epoch: 6| Step: 13
Training loss: 2.0249834060668945
Validation loss: 2.0884072652427097

Epoch: 205| Step: 0
Training loss: 2.2423763275146484
Validation loss: 2.0537305929327525

Epoch: 6| Step: 1
Training loss: 1.9503856897354126
Validation loss: 2.059066632742523

Epoch: 6| Step: 2
Training loss: 2.3886120319366455
Validation loss: 2.0434427210079726

Epoch: 6| Step: 3
Training loss: 2.654888391494751
Validation loss: 2.0771189761418167

Epoch: 6| Step: 4
Training loss: 2.5395467281341553
Validation loss: 2.0851842434175554

Epoch: 6| Step: 5
Training loss: 2.362429618835449
Validation loss: 2.0575597901498117

Epoch: 6| Step: 6
Training loss: 1.9750181436538696
Validation loss: 2.06387932198022

Epoch: 6| Step: 7
Training loss: 2.017922878265381
Validation loss: 2.0810824312189573

Epoch: 6| Step: 8
Training loss: 1.979233980178833
Validation loss: 2.0468983034933768

Epoch: 6| Step: 9
Training loss: 1.8055205345153809
Validation loss: 2.0815019402452695

Epoch: 6| Step: 10
Training loss: 1.8481252193450928
Validation loss: 2.0586568258141957

Epoch: 6| Step: 11
Training loss: 2.1716034412384033
Validation loss: 2.065000408439226

Epoch: 6| Step: 12
Training loss: 1.9256224632263184
Validation loss: 2.058825890223185

Epoch: 6| Step: 13
Training loss: 2.079899787902832
Validation loss: 2.054039837211691

Epoch: 206| Step: 0
Training loss: 2.066727876663208
Validation loss: 2.068658521098475

Epoch: 6| Step: 1
Training loss: 1.6866285800933838
Validation loss: 2.059791172704389

Epoch: 6| Step: 2
Training loss: 2.0693283081054688
Validation loss: 2.061909420515901

Epoch: 6| Step: 3
Training loss: 2.369039297103882
Validation loss: 2.0684549680320163

Epoch: 6| Step: 4
Training loss: 2.2527990341186523
Validation loss: 2.0785002810980684

Epoch: 6| Step: 5
Training loss: 2.285611391067505
Validation loss: 2.055059794456728

Epoch: 6| Step: 6
Training loss: 2.5010054111480713
Validation loss: 2.041881822770642

Epoch: 6| Step: 7
Training loss: 3.0480551719665527
Validation loss: 2.016494075457255

Epoch: 6| Step: 8
Training loss: 1.5138883590698242
Validation loss: 2.044735124034266

Epoch: 6| Step: 9
Training loss: 1.8206532001495361
Validation loss: 2.0666686078553558

Epoch: 6| Step: 10
Training loss: 2.0878028869628906
Validation loss: 2.0341046997295913

Epoch: 6| Step: 11
Training loss: 1.9627366065979004
Validation loss: 2.0521900551293486

Epoch: 6| Step: 12
Training loss: 2.323540687561035
Validation loss: 2.0666064472608667

Epoch: 6| Step: 13
Training loss: 1.398301601409912
Validation loss: 2.077362827075425

Epoch: 207| Step: 0
Training loss: 2.1869969367980957
Validation loss: 2.063996086838425

Epoch: 6| Step: 1
Training loss: 1.5212055444717407
Validation loss: 2.048769010010586

Epoch: 6| Step: 2
Training loss: 1.4084203243255615
Validation loss: 2.076543616992171

Epoch: 6| Step: 3
Training loss: 2.1113409996032715
Validation loss: 2.0528895188403387

Epoch: 6| Step: 4
Training loss: 1.7444674968719482
Validation loss: 2.0552012664015575

Epoch: 6| Step: 5
Training loss: 2.3260951042175293
Validation loss: 2.0670639878960064

Epoch: 6| Step: 6
Training loss: 2.152019500732422
Validation loss: 2.0615219839157595

Epoch: 6| Step: 7
Training loss: 2.507544994354248
Validation loss: 2.046609535012194

Epoch: 6| Step: 8
Training loss: 2.165306568145752
Validation loss: 2.0276688273235033

Epoch: 6| Step: 9
Training loss: 2.7112507820129395
Validation loss: 2.045239012728455

Epoch: 6| Step: 10
Training loss: 3.1082539558410645
Validation loss: 2.058793660133116

Epoch: 6| Step: 11
Training loss: 1.4254190921783447
Validation loss: 2.0554549873516126

Epoch: 6| Step: 12
Training loss: 1.8130178451538086
Validation loss: 2.0628322734627673

Epoch: 6| Step: 13
Training loss: 2.727280616760254
Validation loss: 2.081235122937028

Epoch: 208| Step: 0
Training loss: 2.1970205307006836
Validation loss: 2.0630515211371967

Epoch: 6| Step: 1
Training loss: 1.6662781238555908
Validation loss: 2.0629642240462767

Epoch: 6| Step: 2
Training loss: 2.2618942260742188
Validation loss: 2.0344101434112876

Epoch: 6| Step: 3
Training loss: 2.5788915157318115
Validation loss: 2.02480718012779

Epoch: 6| Step: 4
Training loss: 1.7649719715118408
Validation loss: 2.0639295449820896

Epoch: 6| Step: 5
Training loss: 1.6289968490600586
Validation loss: 2.05220127618441

Epoch: 6| Step: 6
Training loss: 2.532440423965454
Validation loss: 2.0747442706938712

Epoch: 6| Step: 7
Training loss: 1.7696442604064941
Validation loss: 2.054976127480948

Epoch: 6| Step: 8
Training loss: 2.832355499267578
Validation loss: 2.0548112982062885

Epoch: 6| Step: 9
Training loss: 1.887667179107666
Validation loss: 2.045767696954871

Epoch: 6| Step: 10
Training loss: 1.9871160984039307
Validation loss: 2.033738959220148

Epoch: 6| Step: 11
Training loss: 2.438776969909668
Validation loss: 2.041674429370511

Epoch: 6| Step: 12
Training loss: 2.1627957820892334
Validation loss: 2.0301718737489436

Epoch: 6| Step: 13
Training loss: 1.8976917266845703
Validation loss: 2.071088562729538

Epoch: 209| Step: 0
Training loss: 1.8731904029846191
Validation loss: 2.05839277339238

Epoch: 6| Step: 1
Training loss: 2.2723617553710938
Validation loss: 2.0606314059226745

Epoch: 6| Step: 2
Training loss: 2.5506234169006348
Validation loss: 2.031157003935947

Epoch: 6| Step: 3
Training loss: 1.5762052536010742
Validation loss: 2.0646681862492717

Epoch: 6| Step: 4
Training loss: 1.972867488861084
Validation loss: 2.0322905766066683

Epoch: 6| Step: 5
Training loss: 2.1774377822875977
Validation loss: 2.076846807233749

Epoch: 6| Step: 6
Training loss: 2.098651885986328
Validation loss: 2.053448025898267

Epoch: 6| Step: 7
Training loss: 1.9480540752410889
Validation loss: 2.0773213268608175

Epoch: 6| Step: 8
Training loss: 2.1387126445770264
Validation loss: 2.055949777685186

Epoch: 6| Step: 9
Training loss: 2.2448320388793945
Validation loss: 2.0643207949976765

Epoch: 6| Step: 10
Training loss: 2.9377081394195557
Validation loss: 2.0303584965326453

Epoch: 6| Step: 11
Training loss: 1.913570523262024
Validation loss: 2.061865319487869

Epoch: 6| Step: 12
Training loss: 1.9183969497680664
Validation loss: 2.06559931847357

Epoch: 6| Step: 13
Training loss: 2.245553493499756
Validation loss: 2.0566572194458335

Epoch: 210| Step: 0
Training loss: 2.393951892852783
Validation loss: 2.0455042085339947

Epoch: 6| Step: 1
Training loss: 1.8697136640548706
Validation loss: 2.047296944484916

Epoch: 6| Step: 2
Training loss: 1.8098081350326538
Validation loss: 2.0263820899430143

Epoch: 6| Step: 3
Training loss: 2.461411237716675
Validation loss: 2.061878196654781

Epoch: 6| Step: 4
Training loss: 2.5486884117126465
Validation loss: 2.0494725909284366

Epoch: 6| Step: 5
Training loss: 2.3308660984039307
Validation loss: 2.08406388631431

Epoch: 6| Step: 6
Training loss: 2.1516265869140625
Validation loss: 2.091707735933283

Epoch: 6| Step: 7
Training loss: 0.9553689956665039
Validation loss: 2.0857333598598355

Epoch: 6| Step: 8
Training loss: 1.9185173511505127
Validation loss: 2.0705712264583958

Epoch: 6| Step: 9
Training loss: 2.186255693435669
Validation loss: 2.0666979653860933

Epoch: 6| Step: 10
Training loss: 2.1743252277374268
Validation loss: 2.0671695945083455

Epoch: 6| Step: 11
Training loss: 2.149773120880127
Validation loss: 2.0597385629530875

Epoch: 6| Step: 12
Training loss: 2.2722368240356445
Validation loss: 2.0483621217871226

Epoch: 6| Step: 13
Training loss: 2.81577467918396
Validation loss: 2.05616133956499

Epoch: 211| Step: 0
Training loss: 2.4940261840820312
Validation loss: 2.0684651738853863

Epoch: 6| Step: 1
Training loss: 2.471231460571289
Validation loss: 2.0765364657166185

Epoch: 6| Step: 2
Training loss: 1.8257979154586792
Validation loss: 2.049336667983763

Epoch: 6| Step: 3
Training loss: 2.2713663578033447
Validation loss: 2.060095651175386

Epoch: 6| Step: 4
Training loss: 1.9645971059799194
Validation loss: 2.0904231943109983

Epoch: 6| Step: 5
Training loss: 2.279313564300537
Validation loss: 2.066003657156421

Epoch: 6| Step: 6
Training loss: 1.991028070449829
Validation loss: 2.064493111384812

Epoch: 6| Step: 7
Training loss: 1.4055405855178833
Validation loss: 2.063847711009364

Epoch: 6| Step: 8
Training loss: 2.521726131439209
Validation loss: 2.0473745381960304

Epoch: 6| Step: 9
Training loss: 2.2106845378875732
Validation loss: 2.0648982499235418

Epoch: 6| Step: 10
Training loss: 2.193859100341797
Validation loss: 2.0529336993412306

Epoch: 6| Step: 11
Training loss: 1.861114501953125
Validation loss: 2.0134602515928206

Epoch: 6| Step: 12
Training loss: 1.9241042137145996
Validation loss: 2.0560892730630855

Epoch: 6| Step: 13
Training loss: 2.2703490257263184
Validation loss: 2.0509048533696

Epoch: 212| Step: 0
Training loss: 1.3548774719238281
Validation loss: 2.060841611636582

Epoch: 6| Step: 1
Training loss: 1.426008701324463
Validation loss: 2.0598113716289563

Epoch: 6| Step: 2
Training loss: 2.2591845989227295
Validation loss: 2.0521788033105994

Epoch: 6| Step: 3
Training loss: 2.8034110069274902
Validation loss: 2.0624479555314585

Epoch: 6| Step: 4
Training loss: 2.7025768756866455
Validation loss: 2.0292807497004026

Epoch: 6| Step: 5
Training loss: 2.251237392425537
Validation loss: 2.0333389620627127

Epoch: 6| Step: 6
Training loss: 1.9570701122283936
Validation loss: 2.039442129032586

Epoch: 6| Step: 7
Training loss: 2.0904541015625
Validation loss: 2.0109396275653633

Epoch: 6| Step: 8
Training loss: 2.0039114952087402
Validation loss: 2.0379311653875534

Epoch: 6| Step: 9
Training loss: 2.4149341583251953
Validation loss: 2.0396354377910657

Epoch: 6| Step: 10
Training loss: 2.257239818572998
Validation loss: 2.041700674641517

Epoch: 6| Step: 11
Training loss: 2.0496668815612793
Validation loss: 2.0352160084632134

Epoch: 6| Step: 12
Training loss: 1.7892321348190308
Validation loss: 2.022649267668365

Epoch: 6| Step: 13
Training loss: 2.1279356479644775
Validation loss: 2.04713692972737

Epoch: 213| Step: 0
Training loss: 2.017378330230713
Validation loss: 2.030510837031949

Epoch: 6| Step: 1
Training loss: 2.930056095123291
Validation loss: 2.04775575412217

Epoch: 6| Step: 2
Training loss: 2.2343335151672363
Validation loss: 2.048740936863807

Epoch: 6| Step: 3
Training loss: 1.7051721811294556
Validation loss: 2.060778933186685

Epoch: 6| Step: 4
Training loss: 2.090505361557007
Validation loss: 2.0438763967124363

Epoch: 6| Step: 5
Training loss: 2.4269003868103027
Validation loss: 2.076196478259179

Epoch: 6| Step: 6
Training loss: 2.094494342803955
Validation loss: 2.04957309333227

Epoch: 6| Step: 7
Training loss: 2.3629322052001953
Validation loss: 2.052626920002763

Epoch: 6| Step: 8
Training loss: 2.111041307449341
Validation loss: 2.063137656898909

Epoch: 6| Step: 9
Training loss: 1.906148910522461
Validation loss: 2.0673843840117097

Epoch: 6| Step: 10
Training loss: 1.2167143821716309
Validation loss: 2.0341267188390098

Epoch: 6| Step: 11
Training loss: 2.0748958587646484
Validation loss: 2.0385135130215715

Epoch: 6| Step: 12
Training loss: 2.5252299308776855
Validation loss: 2.0559743476170365

Epoch: 6| Step: 13
Training loss: 1.3014060258865356
Validation loss: 2.0284117062886557

Epoch: 214| Step: 0
Training loss: 2.5589959621429443
Validation loss: 2.028280540179181

Epoch: 6| Step: 1
Training loss: 1.737561821937561
Validation loss: 2.0446248285232054

Epoch: 6| Step: 2
Training loss: 2.212996006011963
Validation loss: 2.0807116711011497

Epoch: 6| Step: 3
Training loss: 1.4325356483459473
Validation loss: 2.056503342043969

Epoch: 6| Step: 4
Training loss: 2.587759494781494
Validation loss: 2.0381005143606536

Epoch: 6| Step: 5
Training loss: 1.8876292705535889
Validation loss: 2.0380448243951284

Epoch: 6| Step: 6
Training loss: 2.134521484375
Validation loss: 2.0675190712815974

Epoch: 6| Step: 7
Training loss: 2.6488819122314453
Validation loss: 2.0296993486342894

Epoch: 6| Step: 8
Training loss: 2.2881851196289062
Validation loss: 2.075993545593754

Epoch: 6| Step: 9
Training loss: 2.192216157913208
Validation loss: 2.06529680631494

Epoch: 6| Step: 10
Training loss: 2.319042205810547
Validation loss: 2.068210260842436

Epoch: 6| Step: 11
Training loss: 2.1126608848571777
Validation loss: 2.0673544996528217

Epoch: 6| Step: 12
Training loss: 1.9760117530822754
Validation loss: 2.083531662981997

Epoch: 6| Step: 13
Training loss: 1.5206326246261597
Validation loss: 2.054845130571755

Epoch: 215| Step: 0
Training loss: 2.452791690826416
Validation loss: 2.0253867718481247

Epoch: 6| Step: 1
Training loss: 1.8220951557159424
Validation loss: 2.0605896942077147

Epoch: 6| Step: 2
Training loss: 2.554614543914795
Validation loss: 2.064282489079301

Epoch: 6| Step: 3
Training loss: 1.8609991073608398
Validation loss: 2.065568424040271

Epoch: 6| Step: 4
Training loss: 1.8127546310424805
Validation loss: 2.0410412165426437

Epoch: 6| Step: 5
Training loss: 2.334623336791992
Validation loss: 2.0644189311612036

Epoch: 6| Step: 6
Training loss: 1.4842833280563354
Validation loss: 2.051871471507575

Epoch: 6| Step: 7
Training loss: 1.4550244808197021
Validation loss: 2.058722076877471

Epoch: 6| Step: 8
Training loss: 2.3169503211975098
Validation loss: 2.066876103801112

Epoch: 6| Step: 9
Training loss: 3.0395851135253906
Validation loss: 2.048944309193601

Epoch: 6| Step: 10
Training loss: 1.8993078470230103
Validation loss: 2.0463312364393667

Epoch: 6| Step: 11
Training loss: 2.40582537651062
Validation loss: 2.056463723541588

Epoch: 6| Step: 12
Training loss: 2.466365337371826
Validation loss: 2.053800316267116

Epoch: 6| Step: 13
Training loss: 1.6474357843399048
Validation loss: 2.0498545503103607

Epoch: 216| Step: 0
Training loss: 2.5250282287597656
Validation loss: 2.035603170753807

Epoch: 6| Step: 1
Training loss: 2.4565608501434326
Validation loss: 2.0548071489539197

Epoch: 6| Step: 2
Training loss: 2.4246296882629395
Validation loss: 2.090353772204409

Epoch: 6| Step: 3
Training loss: 2.2748913764953613
Validation loss: 2.0785228116537935

Epoch: 6| Step: 4
Training loss: 1.8336358070373535
Validation loss: 2.069028808224586

Epoch: 6| Step: 5
Training loss: 1.675398588180542
Validation loss: 2.0741400641779744

Epoch: 6| Step: 6
Training loss: 2.539102554321289
Validation loss: 2.048233298845189

Epoch: 6| Step: 7
Training loss: 1.9694218635559082
Validation loss: 2.0951113188138573

Epoch: 6| Step: 8
Training loss: 1.7947955131530762
Validation loss: 2.0844179122678694

Epoch: 6| Step: 9
Training loss: 1.5162732601165771
Validation loss: 2.0553984770210842

Epoch: 6| Step: 10
Training loss: 2.874889850616455
Validation loss: 2.070105077118002

Epoch: 6| Step: 11
Training loss: 1.3134853839874268
Validation loss: 2.0666263475213

Epoch: 6| Step: 12
Training loss: 2.6880290508270264
Validation loss: 2.0739255169386506

Epoch: 6| Step: 13
Training loss: 1.7848480939865112
Validation loss: 2.058263155721849

Epoch: 217| Step: 0
Training loss: 1.944676160812378
Validation loss: 2.0517222894135343

Epoch: 6| Step: 1
Training loss: 1.8197182416915894
Validation loss: 2.0527045624230498

Epoch: 6| Step: 2
Training loss: 2.342161178588867
Validation loss: 2.0759228147486204

Epoch: 6| Step: 3
Training loss: 1.7745535373687744
Validation loss: 2.0555794995318175

Epoch: 6| Step: 4
Training loss: 1.6648011207580566
Validation loss: 2.0826810688100834

Epoch: 6| Step: 5
Training loss: 1.9508247375488281
Validation loss: 2.073868405434393

Epoch: 6| Step: 6
Training loss: 1.4009758234024048
Validation loss: 2.064436535681448

Epoch: 6| Step: 7
Training loss: 2.4558746814727783
Validation loss: 2.066174717359645

Epoch: 6| Step: 8
Training loss: 2.3967742919921875
Validation loss: 2.070507267470001

Epoch: 6| Step: 9
Training loss: 2.479254961013794
Validation loss: 2.0649246836221344

Epoch: 6| Step: 10
Training loss: 2.399125099182129
Validation loss: 2.068060839047996

Epoch: 6| Step: 11
Training loss: 2.8961198329925537
Validation loss: 2.0510160615367274

Epoch: 6| Step: 12
Training loss: 2.103956699371338
Validation loss: 2.075705729505067

Epoch: 6| Step: 13
Training loss: 1.92343008518219
Validation loss: 2.053878717525031

Epoch: 218| Step: 0
Training loss: 1.9116754531860352
Validation loss: 2.088090827388148

Epoch: 6| Step: 1
Training loss: 2.0535454750061035
Validation loss: 2.048525878178176

Epoch: 6| Step: 2
Training loss: 1.5274333953857422
Validation loss: 2.0531773285199235

Epoch: 6| Step: 3
Training loss: 2.2611820697784424
Validation loss: 2.0994159918959423

Epoch: 6| Step: 4
Training loss: 2.2779431343078613
Validation loss: 2.088497834820901

Epoch: 6| Step: 5
Training loss: 1.7028558254241943
Validation loss: 2.034844711262693

Epoch: 6| Step: 6
Training loss: 2.6079726219177246
Validation loss: 2.0540219763273835

Epoch: 6| Step: 7
Training loss: 2.498424768447876
Validation loss: 2.074253607821721

Epoch: 6| Step: 8
Training loss: 1.757164478302002
Validation loss: 2.0828162290716685

Epoch: 6| Step: 9
Training loss: 2.2048392295837402
Validation loss: 2.0488762855529785

Epoch: 6| Step: 10
Training loss: 2.2546143531799316
Validation loss: 2.0202365716298423

Epoch: 6| Step: 11
Training loss: 2.814453601837158
Validation loss: 2.0483218854473484

Epoch: 6| Step: 12
Training loss: 1.6777596473693848
Validation loss: 2.0531567540220035

Epoch: 6| Step: 13
Training loss: 1.8794375658035278
Validation loss: 2.0678981760496735

Epoch: 219| Step: 0
Training loss: 1.8323218822479248
Validation loss: 2.072379640353623

Epoch: 6| Step: 1
Training loss: 2.392322540283203
Validation loss: 2.0711537817473054

Epoch: 6| Step: 2
Training loss: 1.9200993776321411
Validation loss: 2.020167491769278

Epoch: 6| Step: 3
Training loss: 1.77684485912323
Validation loss: 2.0703171017349407

Epoch: 6| Step: 4
Training loss: 2.0975160598754883
Validation loss: 2.091311139445151

Epoch: 6| Step: 5
Training loss: 2.674506664276123
Validation loss: 2.0570498922819733

Epoch: 6| Step: 6
Training loss: 1.7460381984710693
Validation loss: 2.0758366277140956

Epoch: 6| Step: 7
Training loss: 1.7794110774993896
Validation loss: 2.072459343940981

Epoch: 6| Step: 8
Training loss: 2.6813549995422363
Validation loss: 2.0696158255300214

Epoch: 6| Step: 9
Training loss: 1.9669153690338135
Validation loss: 2.0646486128530195

Epoch: 6| Step: 10
Training loss: 2.7480077743530273
Validation loss: 2.066932637204406

Epoch: 6| Step: 11
Training loss: 1.4656327962875366
Validation loss: 2.0630041886401433

Epoch: 6| Step: 12
Training loss: 1.8113542795181274
Validation loss: 2.0565485992739276

Epoch: 6| Step: 13
Training loss: 3.028811454772949
Validation loss: 2.081110095465055

Epoch: 220| Step: 0
Training loss: 2.465761661529541
Validation loss: 2.0708757318476194

Epoch: 6| Step: 1
Training loss: 1.5544793605804443
Validation loss: 2.0829919076734975

Epoch: 6| Step: 2
Training loss: 1.9041990041732788
Validation loss: 2.0711178882147676

Epoch: 6| Step: 3
Training loss: 2.5451152324676514
Validation loss: 2.066737800516108

Epoch: 6| Step: 4
Training loss: 1.7819843292236328
Validation loss: 2.039597672800864

Epoch: 6| Step: 5
Training loss: 2.3064980506896973
Validation loss: 2.0762577415794454

Epoch: 6| Step: 6
Training loss: 1.7107807397842407
Validation loss: 2.0636926517691663

Epoch: 6| Step: 7
Training loss: 2.444859504699707
Validation loss: 2.062513587295368

Epoch: 6| Step: 8
Training loss: 1.3136149644851685
Validation loss: 2.077602619765907

Epoch: 6| Step: 9
Training loss: 1.8178123235702515
Validation loss: 2.0491904815038047

Epoch: 6| Step: 10
Training loss: 2.576870918273926
Validation loss: 2.100040889555408

Epoch: 6| Step: 11
Training loss: 1.9684170484542847
Validation loss: 2.0692615509033203

Epoch: 6| Step: 12
Training loss: 2.631682872772217
Validation loss: 2.0604224538290374

Epoch: 6| Step: 13
Training loss: 2.5801596641540527
Validation loss: 2.063731936998265

Epoch: 221| Step: 0
Training loss: 2.396921157836914
Validation loss: 2.052957832172353

Epoch: 6| Step: 1
Training loss: 2.0351321697235107
Validation loss: 2.0375176514348676

Epoch: 6| Step: 2
Training loss: 2.457768201828003
Validation loss: 2.0561860992062475

Epoch: 6| Step: 3
Training loss: 1.6126790046691895
Validation loss: 2.0577564290774766

Epoch: 6| Step: 4
Training loss: 1.9258654117584229
Validation loss: 2.0773505267276557

Epoch: 6| Step: 5
Training loss: 2.3922982215881348
Validation loss: 2.041615214399112

Epoch: 6| Step: 6
Training loss: 2.4245448112487793
Validation loss: 2.005704031195692

Epoch: 6| Step: 7
Training loss: 1.7220534086227417
Validation loss: 2.0468783583692325

Epoch: 6| Step: 8
Training loss: 2.0973572731018066
Validation loss: 2.0670653261164182

Epoch: 6| Step: 9
Training loss: 1.553396463394165
Validation loss: 2.058236150331395

Epoch: 6| Step: 10
Training loss: 2.058521270751953
Validation loss: 2.0784137825812063

Epoch: 6| Step: 11
Training loss: 2.370410203933716
Validation loss: 2.0653277238210044

Epoch: 6| Step: 12
Training loss: 2.518397808074951
Validation loss: 2.0680821454653175

Epoch: 6| Step: 13
Training loss: 1.8189241886138916
Validation loss: 2.052423607918524

Epoch: 222| Step: 0
Training loss: 1.4703887701034546
Validation loss: 2.0948648555304414

Epoch: 6| Step: 1
Training loss: 2.987123966217041
Validation loss: 2.042808089205014

Epoch: 6| Step: 2
Training loss: 1.804924726486206
Validation loss: 2.017062376904231

Epoch: 6| Step: 3
Training loss: 2.0760903358459473
Validation loss: 2.0352478693890315

Epoch: 6| Step: 4
Training loss: 2.0884392261505127
Validation loss: 2.061112912752295

Epoch: 6| Step: 5
Training loss: 1.8921154737472534
Validation loss: 2.060903174902803

Epoch: 6| Step: 6
Training loss: 2.1174116134643555
Validation loss: 2.0487794517188944

Epoch: 6| Step: 7
Training loss: 2.6692280769348145
Validation loss: 2.0442635987394597

Epoch: 6| Step: 8
Training loss: 1.7691823244094849
Validation loss: 2.0657852349742765

Epoch: 6| Step: 9
Training loss: 1.9307392835617065
Validation loss: 2.0811306661175144

Epoch: 6| Step: 10
Training loss: 2.5017380714416504
Validation loss: 2.0609365945221274

Epoch: 6| Step: 11
Training loss: 2.5653295516967773
Validation loss: 2.0668544666741484

Epoch: 6| Step: 12
Training loss: 2.2547035217285156
Validation loss: 2.0568416682622765

Epoch: 6| Step: 13
Training loss: 0.9435603022575378
Validation loss: 2.075823950511153

Epoch: 223| Step: 0
Training loss: 1.8757143020629883
Validation loss: 2.0609473207945466

Epoch: 6| Step: 1
Training loss: 1.8044683933258057
Validation loss: 2.064507507508801

Epoch: 6| Step: 2
Training loss: 1.715576171875
Validation loss: 2.0431466217963927

Epoch: 6| Step: 3
Training loss: 1.42689847946167
Validation loss: 2.0833914087664698

Epoch: 6| Step: 4
Training loss: 1.51326322555542
Validation loss: 2.088767405479185

Epoch: 6| Step: 5
Training loss: 2.210639476776123
Validation loss: 2.0708801208003873

Epoch: 6| Step: 6
Training loss: 2.565976858139038
Validation loss: 2.0551340246713288

Epoch: 6| Step: 7
Training loss: 2.740339756011963
Validation loss: 2.098226352404523

Epoch: 6| Step: 8
Training loss: 2.908510446548462
Validation loss: 2.090339396589546

Epoch: 6| Step: 9
Training loss: 1.4914543628692627
Validation loss: 2.0612184898827666

Epoch: 6| Step: 10
Training loss: 2.6718971729278564
Validation loss: 2.0674133608418126

Epoch: 6| Step: 11
Training loss: 2.144037961959839
Validation loss: 2.077603724695021

Epoch: 6| Step: 12
Training loss: 2.258305072784424
Validation loss: 2.0758279510723647

Epoch: 6| Step: 13
Training loss: 1.9517130851745605
Validation loss: 2.069502115249634

Epoch: 224| Step: 0
Training loss: 1.9305510520935059
Validation loss: 2.0303432813254734

Epoch: 6| Step: 1
Training loss: 2.7524256706237793
Validation loss: 2.056042707094582

Epoch: 6| Step: 2
Training loss: 2.012946605682373
Validation loss: 2.072002826198455

Epoch: 6| Step: 3
Training loss: 1.701228380203247
Validation loss: 2.0592883709938294

Epoch: 6| Step: 4
Training loss: 1.7945034503936768
Validation loss: 2.061226552532565

Epoch: 6| Step: 5
Training loss: 2.272583246231079
Validation loss: 2.0613418625247095

Epoch: 6| Step: 6
Training loss: 1.8155062198638916
Validation loss: 2.045700130924102

Epoch: 6| Step: 7
Training loss: 2.563410758972168
Validation loss: 2.054264545440674

Epoch: 6| Step: 8
Training loss: 2.31233286857605
Validation loss: 2.0457305228838356

Epoch: 6| Step: 9
Training loss: 1.4890236854553223
Validation loss: 2.06186915469426

Epoch: 6| Step: 10
Training loss: 1.6648287773132324
Validation loss: 2.028766485952562

Epoch: 6| Step: 11
Training loss: 2.3316681385040283
Validation loss: 2.035667798852408

Epoch: 6| Step: 12
Training loss: 2.7205252647399902
Validation loss: 2.0500460106839418

Epoch: 6| Step: 13
Training loss: 1.9335297346115112
Validation loss: 2.0493436910772838

Epoch: 225| Step: 0
Training loss: 2.2718677520751953
Validation loss: 2.0280625140795143

Epoch: 6| Step: 1
Training loss: 1.3788877725601196
Validation loss: 2.04783659724779

Epoch: 6| Step: 2
Training loss: 1.8947250843048096
Validation loss: 2.029784457657927

Epoch: 6| Step: 3
Training loss: 1.7629680633544922
Validation loss: 2.0346612058660036

Epoch: 6| Step: 4
Training loss: 2.2671685218811035
Validation loss: 2.034496486827891

Epoch: 6| Step: 5
Training loss: 2.8837294578552246
Validation loss: 2.0505496135321994

Epoch: 6| Step: 6
Training loss: 1.8252499103546143
Validation loss: 2.0525428005444106

Epoch: 6| Step: 7
Training loss: 2.475337505340576
Validation loss: 2.0671529667351836

Epoch: 6| Step: 8
Training loss: 1.908646821975708
Validation loss: 2.0900906798660115

Epoch: 6| Step: 9
Training loss: 1.9251654148101807
Validation loss: 2.0488544612802486

Epoch: 6| Step: 10
Training loss: 1.9294688701629639
Validation loss: 2.051350444875738

Epoch: 6| Step: 11
Training loss: 2.074002504348755
Validation loss: 2.0375030220195813

Epoch: 6| Step: 12
Training loss: 2.1694676876068115
Validation loss: 2.086933655123557

Epoch: 6| Step: 13
Training loss: 3.1750636100769043
Validation loss: 2.0548435872600925

Epoch: 226| Step: 0
Training loss: 2.2758536338806152
Validation loss: 2.064103900745351

Epoch: 6| Step: 1
Training loss: 1.8359310626983643
Validation loss: 2.0513728562221734

Epoch: 6| Step: 2
Training loss: 2.422649621963501
Validation loss: 2.080346966302523

Epoch: 6| Step: 3
Training loss: 2.7331221103668213
Validation loss: 2.0756800623350244

Epoch: 6| Step: 4
Training loss: 1.9881840944290161
Validation loss: 2.1000843817187893

Epoch: 6| Step: 5
Training loss: 2.43154239654541
Validation loss: 2.0787235113882248

Epoch: 6| Step: 6
Training loss: 1.7375332117080688
Validation loss: 2.1111060047662384

Epoch: 6| Step: 7
Training loss: 2.384056568145752
Validation loss: 2.085718627898924

Epoch: 6| Step: 8
Training loss: 2.8745031356811523
Validation loss: 2.0597273252343618

Epoch: 6| Step: 9
Training loss: 2.0873398780822754
Validation loss: 2.0745523527104366

Epoch: 6| Step: 10
Training loss: 1.5687470436096191
Validation loss: 2.035391740901496

Epoch: 6| Step: 11
Training loss: 1.820066213607788
Validation loss: 2.0781656926678074

Epoch: 6| Step: 12
Training loss: 1.6462697982788086
Validation loss: 2.0737499216551423

Epoch: 6| Step: 13
Training loss: 1.119936227798462
Validation loss: 2.077619929467478

Epoch: 227| Step: 0
Training loss: 1.9904279708862305
Validation loss: 2.0556207318459787

Epoch: 6| Step: 1
Training loss: 2.5755934715270996
Validation loss: 2.0896806755373554

Epoch: 6| Step: 2
Training loss: 2.670659303665161
Validation loss: 2.076506108366033

Epoch: 6| Step: 3
Training loss: 2.075502634048462
Validation loss: 2.06854949971681

Epoch: 6| Step: 4
Training loss: 2.1428489685058594
Validation loss: 2.058778232143771

Epoch: 6| Step: 5
Training loss: 2.026829481124878
Validation loss: 2.07187452367557

Epoch: 6| Step: 6
Training loss: 2.0708982944488525
Validation loss: 2.0578769201873452

Epoch: 6| Step: 7
Training loss: 1.637009620666504
Validation loss: 2.063370698241777

Epoch: 6| Step: 8
Training loss: 1.6778744459152222
Validation loss: 2.0439778156177972

Epoch: 6| Step: 9
Training loss: 2.4380300045013428
Validation loss: 2.0594847497119697

Epoch: 6| Step: 10
Training loss: 2.367112159729004
Validation loss: 2.059859045090214

Epoch: 6| Step: 11
Training loss: 2.0419747829437256
Validation loss: 2.0536626244104035

Epoch: 6| Step: 12
Training loss: 1.8644559383392334
Validation loss: 2.0628958184231996

Epoch: 6| Step: 13
Training loss: 1.7189558744430542
Validation loss: 2.068579744267207

Epoch: 228| Step: 0
Training loss: 1.772001028060913
Validation loss: 2.0711560480056272

Epoch: 6| Step: 1
Training loss: 1.5160616636276245
Validation loss: 2.0744762215563046

Epoch: 6| Step: 2
Training loss: 2.302372455596924
Validation loss: 2.045169066357356

Epoch: 6| Step: 3
Training loss: 1.615384817123413
Validation loss: 2.0426301494721444

Epoch: 6| Step: 4
Training loss: 2.6686315536499023
Validation loss: 2.043890760790917

Epoch: 6| Step: 5
Training loss: 2.5739336013793945
Validation loss: 2.0634965255696285

Epoch: 6| Step: 6
Training loss: 2.8761532306671143
Validation loss: 2.0566141836104856

Epoch: 6| Step: 7
Training loss: 2.2391698360443115
Validation loss: 2.0663715152330298

Epoch: 6| Step: 8
Training loss: 1.9846850633621216
Validation loss: 2.036821917821002

Epoch: 6| Step: 9
Training loss: 1.932564377784729
Validation loss: 2.043787051272649

Epoch: 6| Step: 10
Training loss: 2.2863876819610596
Validation loss: 2.0291772632188696

Epoch: 6| Step: 11
Training loss: 1.420240044593811
Validation loss: 2.061877889017905

Epoch: 6| Step: 12
Training loss: 2.149290084838867
Validation loss: 2.0650521273254068

Epoch: 6| Step: 13
Training loss: 2.0575764179229736
Validation loss: 2.046459280034547

Epoch: 229| Step: 0
Training loss: 1.5483442544937134
Validation loss: 2.0611172747868363

Epoch: 6| Step: 1
Training loss: 2.1532695293426514
Validation loss: 2.0506765483528056

Epoch: 6| Step: 2
Training loss: 2.359356641769409
Validation loss: 2.03664767742157

Epoch: 6| Step: 3
Training loss: 1.57331383228302
Validation loss: 2.0446983716821157

Epoch: 6| Step: 4
Training loss: 2.275864839553833
Validation loss: 2.028812728902345

Epoch: 6| Step: 5
Training loss: 2.4519433975219727
Validation loss: 2.0323190765996135

Epoch: 6| Step: 6
Training loss: 1.9393298625946045
Validation loss: 2.0537300250863515

Epoch: 6| Step: 7
Training loss: 1.6061944961547852
Validation loss: 2.027988031346311

Epoch: 6| Step: 8
Training loss: 1.7672172784805298
Validation loss: 2.025659376575101

Epoch: 6| Step: 9
Training loss: 1.6980869770050049
Validation loss: 2.034629761531789

Epoch: 6| Step: 10
Training loss: 2.517951488494873
Validation loss: 2.032487110425067

Epoch: 6| Step: 11
Training loss: 2.520420551300049
Validation loss: 2.054494865479008

Epoch: 6| Step: 12
Training loss: 2.4193930625915527
Validation loss: 2.050874715210289

Epoch: 6| Step: 13
Training loss: 3.142483711242676
Validation loss: 2.0357102604322534

Epoch: 230| Step: 0
Training loss: 1.9074660539627075
Validation loss: 2.0278963427389822

Epoch: 6| Step: 1
Training loss: 2.4877030849456787
Validation loss: 2.0459439831395305

Epoch: 6| Step: 2
Training loss: 2.4914541244506836
Validation loss: 2.0130572011393886

Epoch: 6| Step: 3
Training loss: 2.241515636444092
Validation loss: 2.0470307514231694

Epoch: 6| Step: 4
Training loss: 2.312596559524536
Validation loss: 2.059715469678243

Epoch: 6| Step: 5
Training loss: 2.1072278022766113
Validation loss: 2.0396814410404494

Epoch: 6| Step: 6
Training loss: 2.6677403450012207
Validation loss: 2.053750197092692

Epoch: 6| Step: 7
Training loss: 1.7030264139175415
Validation loss: 2.0481937149519562

Epoch: 6| Step: 8
Training loss: 1.6419283151626587
Validation loss: 2.0611420728827037

Epoch: 6| Step: 9
Training loss: 1.8240642547607422
Validation loss: 2.0759817272104244

Epoch: 6| Step: 10
Training loss: 1.8074421882629395
Validation loss: 2.0729576105712564

Epoch: 6| Step: 11
Training loss: 2.0286855697631836
Validation loss: 2.0367266234531196

Epoch: 6| Step: 12
Training loss: 2.045319080352783
Validation loss: 2.0592007752387755

Epoch: 6| Step: 13
Training loss: 1.529866337776184
Validation loss: 2.066089989036642

Epoch: 231| Step: 0
Training loss: 2.072206735610962
Validation loss: 2.051254585225095

Epoch: 6| Step: 1
Training loss: 1.6498509645462036
Validation loss: 2.082809236741835

Epoch: 6| Step: 2
Training loss: 2.8520236015319824
Validation loss: 2.0865578651428223

Epoch: 6| Step: 3
Training loss: 2.093761444091797
Validation loss: 2.0684650162214875

Epoch: 6| Step: 4
Training loss: 1.71262788772583
Validation loss: 2.1000931455243017

Epoch: 6| Step: 5
Training loss: 2.64815616607666
Validation loss: 2.0851790033360964

Epoch: 6| Step: 6
Training loss: 2.5581140518188477
Validation loss: 2.1030072717256445

Epoch: 6| Step: 7
Training loss: 2.535322666168213
Validation loss: 2.107161991057857

Epoch: 6| Step: 8
Training loss: 2.248828172683716
Validation loss: 2.0842577757373935

Epoch: 6| Step: 9
Training loss: 1.917596459388733
Validation loss: 2.078611639238173

Epoch: 6| Step: 10
Training loss: 1.6226983070373535
Validation loss: 2.088937659417429

Epoch: 6| Step: 11
Training loss: 1.97098708152771
Validation loss: 2.077691225595372

Epoch: 6| Step: 12
Training loss: 1.9031801223754883
Validation loss: 2.0731497580005276

Epoch: 6| Step: 13
Training loss: 1.0549037456512451
Validation loss: 2.1007139605860554

Epoch: 232| Step: 0
Training loss: 2.6608712673187256
Validation loss: 2.0698803701708393

Epoch: 6| Step: 1
Training loss: 1.9932650327682495
Validation loss: 2.0729807346097884

Epoch: 6| Step: 2
Training loss: 2.736802339553833
Validation loss: 2.0775132909897835

Epoch: 6| Step: 3
Training loss: 2.3757686614990234
Validation loss: 2.060395686857162

Epoch: 6| Step: 4
Training loss: 2.22397518157959
Validation loss: 2.074989595720845

Epoch: 6| Step: 5
Training loss: 1.8331212997436523
Validation loss: 2.0862834863765265

Epoch: 6| Step: 6
Training loss: 2.5130462646484375
Validation loss: 2.053475320980113

Epoch: 6| Step: 7
Training loss: 1.9787771701812744
Validation loss: 2.0508040728107577

Epoch: 6| Step: 8
Training loss: 1.645882248878479
Validation loss: 2.026423297902589

Epoch: 6| Step: 9
Training loss: 1.8242950439453125
Validation loss: 2.0509445872358096

Epoch: 6| Step: 10
Training loss: 1.7453551292419434
Validation loss: 2.0544706442022838

Epoch: 6| Step: 11
Training loss: 1.9986085891723633
Validation loss: 2.0536181901090886

Epoch: 6| Step: 12
Training loss: 1.844560980796814
Validation loss: 2.04141144598684

Epoch: 6| Step: 13
Training loss: 1.8961963653564453
Validation loss: 2.0505434928401822

Epoch: 233| Step: 0
Training loss: 2.144375801086426
Validation loss: 2.051370028526552

Epoch: 6| Step: 1
Training loss: 2.5348477363586426
Validation loss: 2.0731029177224762

Epoch: 6| Step: 2
Training loss: 1.871321201324463
Validation loss: 2.0411329782137306

Epoch: 6| Step: 3
Training loss: 2.3061461448669434
Validation loss: 2.058355119920546

Epoch: 6| Step: 4
Training loss: 1.7181453704833984
Validation loss: 2.060499652739494

Epoch: 6| Step: 5
Training loss: 1.686575174331665
Validation loss: 2.0701094263343403

Epoch: 6| Step: 6
Training loss: 1.7970473766326904
Validation loss: 2.0690636122098534

Epoch: 6| Step: 7
Training loss: 2.0093131065368652
Validation loss: 2.0919182198022

Epoch: 6| Step: 8
Training loss: 2.7148852348327637
Validation loss: 2.059106634509179

Epoch: 6| Step: 9
Training loss: 2.194005250930786
Validation loss: 2.0588633270673853

Epoch: 6| Step: 10
Training loss: 2.487743854522705
Validation loss: 2.062485747439887

Epoch: 6| Step: 11
Training loss: 2.453096866607666
Validation loss: 2.068100339622908

Epoch: 6| Step: 12
Training loss: 1.8735570907592773
Validation loss: 2.06907763788777

Epoch: 6| Step: 13
Training loss: 1.1609121561050415
Validation loss: 2.0755970285784815

Epoch: 234| Step: 0
Training loss: 2.2993669509887695
Validation loss: 2.0543936811467653

Epoch: 6| Step: 1
Training loss: 2.227301597595215
Validation loss: 2.0416163847010624

Epoch: 6| Step: 2
Training loss: 1.6238218545913696
Validation loss: 2.065272287655902

Epoch: 6| Step: 3
Training loss: 1.777958631515503
Validation loss: 2.071444567813668

Epoch: 6| Step: 4
Training loss: 1.5434675216674805
Validation loss: 2.06685592538567

Epoch: 6| Step: 5
Training loss: 1.9041162729263306
Validation loss: 2.0709755036138717

Epoch: 6| Step: 6
Training loss: 2.1682629585266113
Validation loss: 2.0855487572249545

Epoch: 6| Step: 7
Training loss: 1.816551923751831
Validation loss: 2.0661520381127634

Epoch: 6| Step: 8
Training loss: 2.3075008392333984
Validation loss: 2.0629891836515037

Epoch: 6| Step: 9
Training loss: 2.7246384620666504
Validation loss: 2.0450606217948337

Epoch: 6| Step: 10
Training loss: 2.1542539596557617
Validation loss: 2.0416418865162838

Epoch: 6| Step: 11
Training loss: 2.1208415031433105
Validation loss: 2.069857471732683

Epoch: 6| Step: 12
Training loss: 2.031680107116699
Validation loss: 2.0352499190197197

Epoch: 6| Step: 13
Training loss: 2.8423242568969727
Validation loss: 2.045361085604596

Epoch: 235| Step: 0
Training loss: 2.4392852783203125
Validation loss: 2.0725421290243826

Epoch: 6| Step: 1
Training loss: 2.9975900650024414
Validation loss: 2.0283995879593717

Epoch: 6| Step: 2
Training loss: 1.8627921342849731
Validation loss: 2.039035117754372

Epoch: 6| Step: 3
Training loss: 2.5887155532836914
Validation loss: 2.0179790553226264

Epoch: 6| Step: 4
Training loss: 1.5562769174575806
Validation loss: 2.04445384394738

Epoch: 6| Step: 5
Training loss: 1.8461649417877197
Validation loss: 2.024997857309157

Epoch: 6| Step: 6
Training loss: 2.2017135620117188
Validation loss: 2.0531097586436937

Epoch: 6| Step: 7
Training loss: 1.799931287765503
Validation loss: 2.0594815490066365

Epoch: 6| Step: 8
Training loss: 2.568696975708008
Validation loss: 2.026083642436612

Epoch: 6| Step: 9
Training loss: 1.0742425918579102
Validation loss: 2.0513964365887385

Epoch: 6| Step: 10
Training loss: 1.9294562339782715
Validation loss: 2.011582620682255

Epoch: 6| Step: 11
Training loss: 1.6097633838653564
Validation loss: 2.0484861814847557

Epoch: 6| Step: 12
Training loss: 2.8557486534118652
Validation loss: 2.035315180337557

Epoch: 6| Step: 13
Training loss: 1.8570283651351929
Validation loss: 2.0162924233303277

Epoch: 236| Step: 0
Training loss: 2.2931199073791504
Validation loss: 2.0269280607982347

Epoch: 6| Step: 1
Training loss: 2.14377498626709
Validation loss: 2.057461166894564

Epoch: 6| Step: 2
Training loss: 2.2630388736724854
Validation loss: 2.0530909107577417

Epoch: 6| Step: 3
Training loss: 2.315385103225708
Validation loss: 2.059158432868219

Epoch: 6| Step: 4
Training loss: 2.2736051082611084
Validation loss: 2.0412151864779893

Epoch: 6| Step: 5
Training loss: 2.1090633869171143
Validation loss: 2.069778216782437

Epoch: 6| Step: 6
Training loss: 2.0389597415924072
Validation loss: 2.038505243998702

Epoch: 6| Step: 7
Training loss: 1.7993969917297363
Validation loss: 2.0447881067952802

Epoch: 6| Step: 8
Training loss: 1.8107062578201294
Validation loss: 2.0545024641098513

Epoch: 6| Step: 9
Training loss: 1.8332304954528809
Validation loss: 2.0278889376630067

Epoch: 6| Step: 10
Training loss: 2.4318299293518066
Validation loss: 2.055843967263417

Epoch: 6| Step: 11
Training loss: 2.17382550239563
Validation loss: 2.0417619546254477

Epoch: 6| Step: 12
Training loss: 1.6767432689666748
Validation loss: 2.073978998327768

Epoch: 6| Step: 13
Training loss: 1.5928159952163696
Validation loss: 2.081728161022227

Epoch: 237| Step: 0
Training loss: 1.367784857749939
Validation loss: 2.0299671490987143

Epoch: 6| Step: 1
Training loss: 1.9705877304077148
Validation loss: 2.0440903273961877

Epoch: 6| Step: 2
Training loss: 1.660772681236267
Validation loss: 2.0795443263105167

Epoch: 6| Step: 3
Training loss: 2.384401321411133
Validation loss: 2.063343750533237

Epoch: 6| Step: 4
Training loss: 2.516813039779663
Validation loss: 2.0633571763192453

Epoch: 6| Step: 5
Training loss: 1.5822621583938599
Validation loss: 2.0656421466540267

Epoch: 6| Step: 6
Training loss: 1.8180912733078003
Validation loss: 2.0160376166784637

Epoch: 6| Step: 7
Training loss: 2.2580530643463135
Validation loss: 2.03409985316697

Epoch: 6| Step: 8
Training loss: 2.2236499786376953
Validation loss: 2.0450974279834377

Epoch: 6| Step: 9
Training loss: 2.473344087600708
Validation loss: 2.0579964794138426

Epoch: 6| Step: 10
Training loss: 1.9439753293991089
Validation loss: 2.0708135827895133

Epoch: 6| Step: 11
Training loss: 2.5078303813934326
Validation loss: 2.0204296291515393

Epoch: 6| Step: 12
Training loss: 1.940983533859253
Validation loss: 2.042852658097462

Epoch: 6| Step: 13
Training loss: 2.640315055847168
Validation loss: 2.0402786129264423

Epoch: 238| Step: 0
Training loss: 1.8744832277297974
Validation loss: 2.0553142973171767

Epoch: 6| Step: 1
Training loss: 1.9219857454299927
Validation loss: 2.0614317681199763

Epoch: 6| Step: 2
Training loss: 1.9978083372116089
Validation loss: 2.0842673496533464

Epoch: 6| Step: 3
Training loss: 2.0450549125671387
Validation loss: 2.0613462873684463

Epoch: 6| Step: 4
Training loss: 2.2948858737945557
Validation loss: 2.042994619697653

Epoch: 6| Step: 5
Training loss: 2.269606113433838
Validation loss: 2.08360226949056

Epoch: 6| Step: 6
Training loss: 2.261885166168213
Validation loss: 2.0481555961793467

Epoch: 6| Step: 7
Training loss: 1.7098274230957031
Validation loss: 2.0530851528208744

Epoch: 6| Step: 8
Training loss: 1.6339364051818848
Validation loss: 2.0177532485736314

Epoch: 6| Step: 9
Training loss: 2.609722375869751
Validation loss: 2.0680865754363356

Epoch: 6| Step: 10
Training loss: 1.7507106065750122
Validation loss: 2.060485488624983

Epoch: 6| Step: 11
Training loss: 2.311602830886841
Validation loss: 2.0825687121319514

Epoch: 6| Step: 12
Training loss: 2.2057454586029053
Validation loss: 2.067758403798585

Epoch: 6| Step: 13
Training loss: 2.1892542839050293
Validation loss: 2.051395126568374

Epoch: 239| Step: 0
Training loss: 1.4476232528686523
Validation loss: 2.035702605401316

Epoch: 6| Step: 1
Training loss: 1.7635655403137207
Validation loss: 2.052584448168355

Epoch: 6| Step: 2
Training loss: 3.0322072505950928
Validation loss: 2.065390286907073

Epoch: 6| Step: 3
Training loss: 2.073610305786133
Validation loss: 2.066020650248374

Epoch: 6| Step: 4
Training loss: 1.4797337055206299
Validation loss: 2.061466227295578

Epoch: 6| Step: 5
Training loss: 1.3639345169067383
Validation loss: 2.0525614138572448

Epoch: 6| Step: 6
Training loss: 1.9015542268753052
Validation loss: 2.05764449796369

Epoch: 6| Step: 7
Training loss: 2.144052743911743
Validation loss: 2.0418150194229616

Epoch: 6| Step: 8
Training loss: 2.135469913482666
Validation loss: 2.058996077506773

Epoch: 6| Step: 9
Training loss: 1.995588779449463
Validation loss: 2.0787057671495663

Epoch: 6| Step: 10
Training loss: 2.311117172241211
Validation loss: 2.0537881030831286

Epoch: 6| Step: 11
Training loss: 2.7307353019714355
Validation loss: 2.0605307727731685

Epoch: 6| Step: 12
Training loss: 2.6270649433135986
Validation loss: 2.0898591767075243

Epoch: 6| Step: 13
Training loss: 2.249455690383911
Validation loss: 2.0775176760970906

Epoch: 240| Step: 0
Training loss: 2.37431001663208
Validation loss: 2.046126711753107

Epoch: 6| Step: 1
Training loss: 1.6250687837600708
Validation loss: 2.058037257963611

Epoch: 6| Step: 2
Training loss: 2.0060057640075684
Validation loss: 2.0670537897335586

Epoch: 6| Step: 3
Training loss: 1.814969539642334
Validation loss: 2.0678153525116625

Epoch: 6| Step: 4
Training loss: 2.488677978515625
Validation loss: 2.0526938835779824

Epoch: 6| Step: 5
Training loss: 2.4027886390686035
Validation loss: 2.0910317743978193

Epoch: 6| Step: 6
Training loss: 2.1698648929595947
Validation loss: 2.0664011329732914

Epoch: 6| Step: 7
Training loss: 2.397728204727173
Validation loss: 2.0126045596215034

Epoch: 6| Step: 8
Training loss: 2.516512393951416
Validation loss: 2.0586014075945784

Epoch: 6| Step: 9
Training loss: 2.0680251121520996
Validation loss: 2.0258952879136607

Epoch: 6| Step: 10
Training loss: 1.5759053230285645
Validation loss: 2.0330458559015745

Epoch: 6| Step: 11
Training loss: 1.6608784198760986
Validation loss: 2.0709513630918277

Epoch: 6| Step: 12
Training loss: 1.819929838180542
Validation loss: 2.0599248511816866

Epoch: 6| Step: 13
Training loss: 2.4456534385681152
Validation loss: 2.063187022362986

Epoch: 241| Step: 0
Training loss: 1.5090504884719849
Validation loss: 2.0621269825966126

Epoch: 6| Step: 1
Training loss: 2.4794936180114746
Validation loss: 2.0741459169695453

Epoch: 6| Step: 2
Training loss: 2.4104995727539062
Validation loss: 2.034894658673194

Epoch: 6| Step: 3
Training loss: 1.5465060472488403
Validation loss: 2.0597289736552904

Epoch: 6| Step: 4
Training loss: 1.5151581764221191
Validation loss: 2.0647912217724707

Epoch: 6| Step: 5
Training loss: 1.329101800918579
Validation loss: 2.071088798584477

Epoch: 6| Step: 6
Training loss: 2.054452896118164
Validation loss: 2.0831070433380785

Epoch: 6| Step: 7
Training loss: 2.012727737426758
Validation loss: 2.056016714342179

Epoch: 6| Step: 8
Training loss: 2.6226186752319336
Validation loss: 2.035985351890646

Epoch: 6| Step: 9
Training loss: 2.244710683822632
Validation loss: 2.0772247955363285

Epoch: 6| Step: 10
Training loss: 2.2429819107055664
Validation loss: 2.075639154321404

Epoch: 6| Step: 11
Training loss: 2.5910720825195312
Validation loss: 2.057444815994591

Epoch: 6| Step: 12
Training loss: 2.294638156890869
Validation loss: 2.078379765633614

Epoch: 6| Step: 13
Training loss: 2.0001213550567627
Validation loss: 2.0832576905527422

Epoch: 242| Step: 0
Training loss: 1.9391517639160156
Validation loss: 2.0787062798776934

Epoch: 6| Step: 1
Training loss: 1.6373640298843384
Validation loss: 2.100324075709107

Epoch: 6| Step: 2
Training loss: 2.1476011276245117
Validation loss: 2.0572071408712738

Epoch: 6| Step: 3
Training loss: 2.014326333999634
Validation loss: 2.087123001775434

Epoch: 6| Step: 4
Training loss: 2.1228973865509033
Validation loss: 2.0470469074864543

Epoch: 6| Step: 5
Training loss: 1.9459590911865234
Validation loss: 2.093757052575388

Epoch: 6| Step: 6
Training loss: 1.9835436344146729
Validation loss: 2.0598970202989477

Epoch: 6| Step: 7
Training loss: 1.9952502250671387
Validation loss: 2.0701167506556355

Epoch: 6| Step: 8
Training loss: 2.0515012741088867
Validation loss: 2.0792182081489154

Epoch: 6| Step: 9
Training loss: 2.1533167362213135
Validation loss: 2.059804254962552

Epoch: 6| Step: 10
Training loss: 2.089691400527954
Validation loss: 2.0599150721744826

Epoch: 6| Step: 11
Training loss: 2.3265888690948486
Validation loss: 2.0374443454127156

Epoch: 6| Step: 12
Training loss: 2.010873317718506
Validation loss: 2.056063167510494

Epoch: 6| Step: 13
Training loss: 2.6688032150268555
Validation loss: 2.0728963190509426

Epoch: 243| Step: 0
Training loss: 1.8598531484603882
Validation loss: 2.069263114724108

Epoch: 6| Step: 1
Training loss: 1.4844751358032227
Validation loss: 2.0651591452219153

Epoch: 6| Step: 2
Training loss: 1.9090012311935425
Validation loss: 2.050824596035865

Epoch: 6| Step: 3
Training loss: 1.7485407590866089
Validation loss: 2.0846418026954896

Epoch: 6| Step: 4
Training loss: 1.8868911266326904
Validation loss: 2.0929765227020427

Epoch: 6| Step: 5
Training loss: 2.117549419403076
Validation loss: 2.091279199046473

Epoch: 6| Step: 6
Training loss: 2.6861705780029297
Validation loss: 2.076887943411386

Epoch: 6| Step: 7
Training loss: 1.8045711517333984
Validation loss: 2.0791534992956344

Epoch: 6| Step: 8
Training loss: 2.2757458686828613
Validation loss: 2.05439789577197

Epoch: 6| Step: 9
Training loss: 3.103170871734619
Validation loss: 2.050240603826379

Epoch: 6| Step: 10
Training loss: 1.954483985900879
Validation loss: 2.064602267357611

Epoch: 6| Step: 11
Training loss: 2.505466938018799
Validation loss: 2.047027071317037

Epoch: 6| Step: 12
Training loss: 1.471997857093811
Validation loss: 2.059984199462398

Epoch: 6| Step: 13
Training loss: 2.3196535110473633
Validation loss: 2.0745276225510465

Epoch: 244| Step: 0
Training loss: 2.543142318725586
Validation loss: 2.0827667482437624

Epoch: 6| Step: 1
Training loss: 1.2597899436950684
Validation loss: 2.0797094132310603

Epoch: 6| Step: 2
Training loss: 2.468324661254883
Validation loss: 2.081221080595447

Epoch: 6| Step: 3
Training loss: 2.435533285140991
Validation loss: 2.0748046931400093

Epoch: 6| Step: 4
Training loss: 1.8327763080596924
Validation loss: 2.0642521304468953

Epoch: 6| Step: 5
Training loss: 2.3301119804382324
Validation loss: 2.0731664011555333

Epoch: 6| Step: 6
Training loss: 2.062135696411133
Validation loss: 2.0673126430921656

Epoch: 6| Step: 7
Training loss: 1.910203218460083
Validation loss: 2.0956955904601724

Epoch: 6| Step: 8
Training loss: 2.2826974391937256
Validation loss: 2.082669258117676

Epoch: 6| Step: 9
Training loss: 1.9197659492492676
Validation loss: 2.075336935699627

Epoch: 6| Step: 10
Training loss: 1.5979256629943848
Validation loss: 2.038816113625803

Epoch: 6| Step: 11
Training loss: 2.1830692291259766
Validation loss: 2.0799667348143873

Epoch: 6| Step: 12
Training loss: 1.9877989292144775
Validation loss: 2.07413802864731

Epoch: 6| Step: 13
Training loss: 2.3838298320770264
Validation loss: 2.078837974097139

Epoch: 245| Step: 0
Training loss: 2.403684139251709
Validation loss: 2.0458657844092256

Epoch: 6| Step: 1
Training loss: 1.991657018661499
Validation loss: 2.045930084361825

Epoch: 6| Step: 2
Training loss: 2.1754016876220703
Validation loss: 2.019205013910929

Epoch: 6| Step: 3
Training loss: 2.1622800827026367
Validation loss: 2.0622132952495287

Epoch: 6| Step: 4
Training loss: 2.51012921333313
Validation loss: 2.07519055181934

Epoch: 6| Step: 5
Training loss: 1.7429119348526
Validation loss: 2.069674902064826

Epoch: 6| Step: 6
Training loss: 1.9255642890930176
Validation loss: 2.0688984701710362

Epoch: 6| Step: 7
Training loss: 2.7206900119781494
Validation loss: 2.046037745732133

Epoch: 6| Step: 8
Training loss: 2.607408046722412
Validation loss: 2.0631367211700766

Epoch: 6| Step: 9
Training loss: 1.8022336959838867
Validation loss: 2.0978443238043014

Epoch: 6| Step: 10
Training loss: 2.2559142112731934
Validation loss: 2.067317485809326

Epoch: 6| Step: 11
Training loss: 1.3878486156463623
Validation loss: 2.0842531650297103

Epoch: 6| Step: 12
Training loss: 1.5643433332443237
Validation loss: 2.054548725005119

Epoch: 6| Step: 13
Training loss: 1.4109342098236084
Validation loss: 2.094750778649443

Epoch: 246| Step: 0
Training loss: 1.9207534790039062
Validation loss: 2.08396900597439

Epoch: 6| Step: 1
Training loss: 2.254892110824585
Validation loss: 2.06323379342274

Epoch: 6| Step: 2
Training loss: 1.8852043151855469
Validation loss: 2.094252065945697

Epoch: 6| Step: 3
Training loss: 2.269862413406372
Validation loss: 2.087522499022945

Epoch: 6| Step: 4
Training loss: 2.732088088989258
Validation loss: 2.073271207911994

Epoch: 6| Step: 5
Training loss: 1.8189071416854858
Validation loss: 2.076978821908274

Epoch: 6| Step: 6
Training loss: 1.6979986429214478
Validation loss: 2.06999001836264

Epoch: 6| Step: 7
Training loss: 2.178072452545166
Validation loss: 2.0468820923118183

Epoch: 6| Step: 8
Training loss: 1.6881654262542725
Validation loss: 2.021719001954602

Epoch: 6| Step: 9
Training loss: 2.5796713829040527
Validation loss: 2.0666401796443488

Epoch: 6| Step: 10
Training loss: 1.7416465282440186
Validation loss: 2.063935790010678

Epoch: 6| Step: 11
Training loss: 2.130976915359497
Validation loss: 2.0437169587740334

Epoch: 6| Step: 12
Training loss: 2.109325408935547
Validation loss: 2.068722750550957

Epoch: 6| Step: 13
Training loss: 1.5880688428878784
Validation loss: 2.057382547727195

Epoch: 247| Step: 0
Training loss: 1.8495354652404785
Validation loss: 2.0541869376295354

Epoch: 6| Step: 1
Training loss: 2.4373292922973633
Validation loss: 2.026566918178271

Epoch: 6| Step: 2
Training loss: 2.1609795093536377
Validation loss: 2.0599859017197804

Epoch: 6| Step: 3
Training loss: 2.668281078338623
Validation loss: 2.0452150965249665

Epoch: 6| Step: 4
Training loss: 1.8917149305343628
Validation loss: 2.0738525441897813

Epoch: 6| Step: 5
Training loss: 1.8088288307189941
Validation loss: 2.0625768707644556

Epoch: 6| Step: 6
Training loss: 2.1311633586883545
Validation loss: 2.0770097932507916

Epoch: 6| Step: 7
Training loss: 1.982010841369629
Validation loss: 2.067561249579153

Epoch: 6| Step: 8
Training loss: 2.4147348403930664
Validation loss: 2.0488534076239473

Epoch: 6| Step: 9
Training loss: 1.7547653913497925
Validation loss: 2.070504767920381

Epoch: 6| Step: 10
Training loss: 1.8355846405029297
Validation loss: 2.0813316581069783

Epoch: 6| Step: 11
Training loss: 1.7744028568267822
Validation loss: 2.0381815869321107

Epoch: 6| Step: 12
Training loss: 1.9367566108703613
Validation loss: 2.0816320655166463

Epoch: 6| Step: 13
Training loss: 2.5353126525878906
Validation loss: 2.061544742635501

Epoch: 248| Step: 0
Training loss: 2.3381152153015137
Validation loss: 2.083197768016528

Epoch: 6| Step: 1
Training loss: 2.45235013961792
Validation loss: 2.056426760970905

Epoch: 6| Step: 2
Training loss: 1.2819616794586182
Validation loss: 2.0652645198247765

Epoch: 6| Step: 3
Training loss: 2.119368076324463
Validation loss: 2.0694033279213855

Epoch: 6| Step: 4
Training loss: 1.9116259813308716
Validation loss: 2.081959498825894

Epoch: 6| Step: 5
Training loss: 1.858394742012024
Validation loss: 2.053164787189935

Epoch: 6| Step: 6
Training loss: 2.0876917839050293
Validation loss: 2.0720220099213305

Epoch: 6| Step: 7
Training loss: 2.711528778076172
Validation loss: 2.0864696246321484

Epoch: 6| Step: 8
Training loss: 1.6308197975158691
Validation loss: 2.0849096211053992

Epoch: 6| Step: 9
Training loss: 2.5551140308380127
Validation loss: 2.041396507652857

Epoch: 6| Step: 10
Training loss: 1.9855459928512573
Validation loss: 2.0657480237304524

Epoch: 6| Step: 11
Training loss: 1.9970258474349976
Validation loss: 2.087696090821297

Epoch: 6| Step: 12
Training loss: 2.352766275405884
Validation loss: 2.036380257657779

Epoch: 6| Step: 13
Training loss: 1.291888952255249
Validation loss: 2.0427722046452184

Epoch: 249| Step: 0
Training loss: 1.8209600448608398
Validation loss: 2.022498687108358

Epoch: 6| Step: 1
Training loss: 1.7458765506744385
Validation loss: 2.0478197477197133

Epoch: 6| Step: 2
Training loss: 2.481935501098633
Validation loss: 2.077138329064974

Epoch: 6| Step: 3
Training loss: 2.609506130218506
Validation loss: 2.0877387831288

Epoch: 6| Step: 4
Training loss: 1.4335964918136597
Validation loss: 2.067586079720528

Epoch: 6| Step: 5
Training loss: 1.8365591764450073
Validation loss: 2.0728407367583244

Epoch: 6| Step: 6
Training loss: 2.0569796562194824
Validation loss: 2.061235973911901

Epoch: 6| Step: 7
Training loss: 1.6094555854797363
Validation loss: 2.0725802093423824

Epoch: 6| Step: 8
Training loss: 2.279010772705078
Validation loss: 2.10083447476869

Epoch: 6| Step: 9
Training loss: 1.6818642616271973
Validation loss: 2.056379448982977

Epoch: 6| Step: 10
Training loss: 2.6704373359680176
Validation loss: 2.090061095453078

Epoch: 6| Step: 11
Training loss: 1.652574062347412
Validation loss: 2.057847066592145

Epoch: 6| Step: 12
Training loss: 3.005582094192505
Validation loss: 2.0612897552469724

Epoch: 6| Step: 13
Training loss: 1.9437795877456665
Validation loss: 2.0897149475671912

Epoch: 250| Step: 0
Training loss: 1.8227301836013794
Validation loss: 2.082487788251651

Epoch: 6| Step: 1
Training loss: 1.6449227333068848
Validation loss: 2.054158649136943

Epoch: 6| Step: 2
Training loss: 2.166285514831543
Validation loss: 2.0711302039443806

Epoch: 6| Step: 3
Training loss: 2.1766650676727295
Validation loss: 2.092718629426854

Epoch: 6| Step: 4
Training loss: 2.239053726196289
Validation loss: 2.08664196537387

Epoch: 6| Step: 5
Training loss: 1.973281979560852
Validation loss: 2.081759254137675

Epoch: 6| Step: 6
Training loss: 1.6080094575881958
Validation loss: 2.082811327390773

Epoch: 6| Step: 7
Training loss: 1.9945203065872192
Validation loss: 2.0901052951812744

Epoch: 6| Step: 8
Training loss: 1.995276927947998
Validation loss: 2.032426295741912

Epoch: 6| Step: 9
Training loss: 2.162050247192383
Validation loss: 2.06650794834219

Epoch: 6| Step: 10
Training loss: 2.1092169284820557
Validation loss: 2.0537917780619797

Epoch: 6| Step: 11
Training loss: 2.0760865211486816
Validation loss: 2.0406404438839165

Epoch: 6| Step: 12
Training loss: 3.190244674682617
Validation loss: 2.062091612046765

Epoch: 6| Step: 13
Training loss: 0.892349362373352
Validation loss: 2.0518322170421643

Epoch: 251| Step: 0
Training loss: 1.371320128440857
Validation loss: 2.046703336059406

Epoch: 6| Step: 1
Training loss: 1.8446221351623535
Validation loss: 2.0713145681606826

Epoch: 6| Step: 2
Training loss: 2.2822699546813965
Validation loss: 2.0648409358916746

Epoch: 6| Step: 3
Training loss: 1.4135184288024902
Validation loss: 2.061465455639747

Epoch: 6| Step: 4
Training loss: 1.2824333906173706
Validation loss: 2.0422704706909838

Epoch: 6| Step: 5
Training loss: 3.1759135723114014
Validation loss: 2.085352636152698

Epoch: 6| Step: 6
Training loss: 2.3814334869384766
Validation loss: 2.048888606409873

Epoch: 6| Step: 7
Training loss: 2.5842056274414062
Validation loss: 2.0542780776177683

Epoch: 6| Step: 8
Training loss: 2.2314300537109375
Validation loss: 2.07620935029881

Epoch: 6| Step: 9
Training loss: 1.8427038192749023
Validation loss: 2.067682845618135

Epoch: 6| Step: 10
Training loss: 2.1468167304992676
Validation loss: 2.06277007954095

Epoch: 6| Step: 11
Training loss: 1.5553514957427979
Validation loss: 2.0543892075938563

Epoch: 6| Step: 12
Training loss: 2.446268320083618
Validation loss: 2.0401421875082035

Epoch: 6| Step: 13
Training loss: 2.260673999786377
Validation loss: 2.0567004244814635

Epoch: 252| Step: 0
Training loss: 2.271397113800049
Validation loss: 2.0792473644338627

Epoch: 6| Step: 1
Training loss: 1.6092305183410645
Validation loss: 2.0646811557072464

Epoch: 6| Step: 2
Training loss: 2.112354278564453
Validation loss: 2.095054200900498

Epoch: 6| Step: 3
Training loss: 1.845923662185669
Validation loss: 2.0810737943136566

Epoch: 6| Step: 4
Training loss: 2.480083465576172
Validation loss: 2.0476310381325344

Epoch: 6| Step: 5
Training loss: 2.292959213256836
Validation loss: 2.0772320173119985

Epoch: 6| Step: 6
Training loss: 1.6586108207702637
Validation loss: 2.0702680182713333

Epoch: 6| Step: 7
Training loss: 1.5855998992919922
Validation loss: 2.0640833582929385

Epoch: 6| Step: 8
Training loss: 2.536548137664795
Validation loss: 2.0498021751321773

Epoch: 6| Step: 9
Training loss: 2.8282079696655273
Validation loss: 2.0658892944294918

Epoch: 6| Step: 10
Training loss: 1.7443487644195557
Validation loss: 2.067856736080621

Epoch: 6| Step: 11
Training loss: 1.806426763534546
Validation loss: 2.085364910864061

Epoch: 6| Step: 12
Training loss: 1.9192626476287842
Validation loss: 2.1020553868304015

Epoch: 6| Step: 13
Training loss: 2.25492000579834
Validation loss: 2.081536933939944

Epoch: 253| Step: 0
Training loss: 2.1729180812835693
Validation loss: 2.0858939129819154

Epoch: 6| Step: 1
Training loss: 1.844496488571167
Validation loss: 2.104192142845482

Epoch: 6| Step: 2
Training loss: 2.780301332473755
Validation loss: 2.0797639675037836

Epoch: 6| Step: 3
Training loss: 2.147496223449707
Validation loss: 2.0672359312734296

Epoch: 6| Step: 4
Training loss: 1.6852184534072876
Validation loss: 2.0646195232227282

Epoch: 6| Step: 5
Training loss: 2.0435142517089844
Validation loss: 2.102372629668123

Epoch: 6| Step: 6
Training loss: 2.316190481185913
Validation loss: 2.088870565096537

Epoch: 6| Step: 7
Training loss: 1.6823828220367432
Validation loss: 2.08047479198825

Epoch: 6| Step: 8
Training loss: 2.4587230682373047
Validation loss: 2.061055898666382

Epoch: 6| Step: 9
Training loss: 2.3804116249084473
Validation loss: 2.0715653255421627

Epoch: 6| Step: 10
Training loss: 1.3544056415557861
Validation loss: 2.078934657958246

Epoch: 6| Step: 11
Training loss: 1.6821659803390503
Validation loss: 2.052693736168646

Epoch: 6| Step: 12
Training loss: 2.32346248626709
Validation loss: 2.0773903939031784

Epoch: 6| Step: 13
Training loss: 2.1432266235351562
Validation loss: 2.072120629331117

Epoch: 254| Step: 0
Training loss: 1.2810989618301392
Validation loss: 2.0784916954655803

Epoch: 6| Step: 1
Training loss: 2.5507047176361084
Validation loss: 2.0854592656576507

Epoch: 6| Step: 2
Training loss: 1.946478247642517
Validation loss: 2.0882018855822984

Epoch: 6| Step: 3
Training loss: 1.4820458889007568
Validation loss: 2.094076254034555

Epoch: 6| Step: 4
Training loss: 2.164518356323242
Validation loss: 2.0974546914459555

Epoch: 6| Step: 5
Training loss: 2.451406240463257
Validation loss: 2.0845861409300115

Epoch: 6| Step: 6
Training loss: 1.8844659328460693
Validation loss: 2.0754542350769043

Epoch: 6| Step: 7
Training loss: 2.297610282897949
Validation loss: 2.0633354494648595

Epoch: 6| Step: 8
Training loss: 1.6440203189849854
Validation loss: 2.053609114821239

Epoch: 6| Step: 9
Training loss: 2.5226168632507324
Validation loss: 2.066200784457627

Epoch: 6| Step: 10
Training loss: 2.2720742225646973
Validation loss: 2.0565872474383284

Epoch: 6| Step: 11
Training loss: 1.8301942348480225
Validation loss: 2.0515559347726966

Epoch: 6| Step: 12
Training loss: 2.1610212326049805
Validation loss: 2.0818873425965667

Epoch: 6| Step: 13
Training loss: 2.4961283206939697
Validation loss: 2.0485953438666558

Epoch: 255| Step: 0
Training loss: 2.124014377593994
Validation loss: 2.053987733779415

Epoch: 6| Step: 1
Training loss: 1.9990392923355103
Validation loss: 2.038039271549512

Epoch: 6| Step: 2
Training loss: 1.564446210861206
Validation loss: 2.064421425583542

Epoch: 6| Step: 3
Training loss: 2.076296329498291
Validation loss: 2.0527879781620477

Epoch: 6| Step: 4
Training loss: 1.8211889266967773
Validation loss: 2.0786749162981586

Epoch: 6| Step: 5
Training loss: 1.8547768592834473
Validation loss: 2.0588989565449376

Epoch: 6| Step: 6
Training loss: 2.4952101707458496
Validation loss: 2.040378893575361

Epoch: 6| Step: 7
Training loss: 2.4122474193573
Validation loss: 2.064542381994186

Epoch: 6| Step: 8
Training loss: 2.227473258972168
Validation loss: 2.065945311259198

Epoch: 6| Step: 9
Training loss: 2.2545857429504395
Validation loss: 2.0824260686033513

Epoch: 6| Step: 10
Training loss: 2.8227767944335938
Validation loss: 2.058492217012631

Epoch: 6| Step: 11
Training loss: 1.459045648574829
Validation loss: 2.079977257277376

Epoch: 6| Step: 12
Training loss: 1.7285552024841309
Validation loss: 2.082807082001881

Epoch: 6| Step: 13
Training loss: 1.8551063537597656
Validation loss: 2.087304166568223

Epoch: 256| Step: 0
Training loss: 2.229349136352539
Validation loss: 2.0784279390047957

Epoch: 6| Step: 1
Training loss: 2.5902233123779297
Validation loss: 2.0510576207150697

Epoch: 6| Step: 2
Training loss: 1.7204577922821045
Validation loss: 2.116177684517317

Epoch: 6| Step: 3
Training loss: 1.9349497556686401
Validation loss: 2.0451700841226885

Epoch: 6| Step: 4
Training loss: 2.048036575317383
Validation loss: 2.050535950609433

Epoch: 6| Step: 5
Training loss: 2.483595609664917
Validation loss: 2.063231788655763

Epoch: 6| Step: 6
Training loss: 1.8281564712524414
Validation loss: 2.075461483770801

Epoch: 6| Step: 7
Training loss: 2.2049121856689453
Validation loss: 2.0318433212977585

Epoch: 6| Step: 8
Training loss: 2.553912878036499
Validation loss: 2.048730150345833

Epoch: 6| Step: 9
Training loss: 1.5949537754058838
Validation loss: 2.0333585559680896

Epoch: 6| Step: 10
Training loss: 1.7009533643722534
Validation loss: 2.0800172385349067

Epoch: 6| Step: 11
Training loss: 1.7407344579696655
Validation loss: 2.02201811985303

Epoch: 6| Step: 12
Training loss: 2.03446364402771
Validation loss: 2.0435675421068744

Epoch: 6| Step: 13
Training loss: 1.913195252418518
Validation loss: 2.054046566768359

Epoch: 257| Step: 0
Training loss: 2.365083694458008
Validation loss: 2.053569991101501

Epoch: 6| Step: 1
Training loss: 2.6572675704956055
Validation loss: 2.0744313104178316

Epoch: 6| Step: 2
Training loss: 2.016268253326416
Validation loss: 2.0730150643215386

Epoch: 6| Step: 3
Training loss: 2.4128737449645996
Validation loss: 2.059514348224927

Epoch: 6| Step: 4
Training loss: 2.05946683883667
Validation loss: 2.054168274325709

Epoch: 6| Step: 5
Training loss: 1.6325148344039917
Validation loss: 2.097391515649775

Epoch: 6| Step: 6
Training loss: 2.077213764190674
Validation loss: 2.0968493671827417

Epoch: 6| Step: 7
Training loss: 1.6608622074127197
Validation loss: 2.0750004553025767

Epoch: 6| Step: 8
Training loss: 1.6128389835357666
Validation loss: 2.0736912706846833

Epoch: 6| Step: 9
Training loss: 2.253054141998291
Validation loss: 2.093705338816489

Epoch: 6| Step: 10
Training loss: 1.7240731716156006
Validation loss: 2.0599832919336136

Epoch: 6| Step: 11
Training loss: 2.052219867706299
Validation loss: 2.108910363207581

Epoch: 6| Step: 12
Training loss: 2.104808807373047
Validation loss: 2.077070677152244

Epoch: 6| Step: 13
Training loss: 1.7106698751449585
Validation loss: 2.109093927568005

Epoch: 258| Step: 0
Training loss: 2.364626884460449
Validation loss: 2.095874781249672

Epoch: 6| Step: 1
Training loss: 1.7457995414733887
Validation loss: 2.078831375286143

Epoch: 6| Step: 2
Training loss: 1.4298851490020752
Validation loss: 2.0733918451493785

Epoch: 6| Step: 3
Training loss: 1.020671010017395
Validation loss: 2.055200425527429

Epoch: 6| Step: 4
Training loss: 1.64146089553833
Validation loss: 2.0784357299086866

Epoch: 6| Step: 5
Training loss: 2.428539276123047
Validation loss: 2.0963828204780497

Epoch: 6| Step: 6
Training loss: 2.1166415214538574
Validation loss: 2.062699548659786

Epoch: 6| Step: 7
Training loss: 2.481703281402588
Validation loss: 2.073306886098718

Epoch: 6| Step: 8
Training loss: 2.3851122856140137
Validation loss: 2.048219657713367

Epoch: 6| Step: 9
Training loss: 2.602381706237793
Validation loss: 2.040175086708479

Epoch: 6| Step: 10
Training loss: 2.4861011505126953
Validation loss: 2.0622312317612352

Epoch: 6| Step: 11
Training loss: 2.3036580085754395
Validation loss: 2.0464416319324124

Epoch: 6| Step: 12
Training loss: 1.9447646141052246
Validation loss: 2.0446676438854587

Epoch: 6| Step: 13
Training loss: 2.0338597297668457
Validation loss: 2.0652483304341636

Epoch: 259| Step: 0
Training loss: 2.326260566711426
Validation loss: 2.074569659848367

Epoch: 6| Step: 1
Training loss: 2.2258524894714355
Validation loss: 2.0511378370305544

Epoch: 6| Step: 2
Training loss: 2.3704299926757812
Validation loss: 2.0544423211005425

Epoch: 6| Step: 3
Training loss: 1.7335262298583984
Validation loss: 2.0749174112914712

Epoch: 6| Step: 4
Training loss: 1.4740957021713257
Validation loss: 2.065453880576677

Epoch: 6| Step: 5
Training loss: 1.9804280996322632
Validation loss: 2.088266859772385

Epoch: 6| Step: 6
Training loss: 2.0856504440307617
Validation loss: 2.0417502285331808

Epoch: 6| Step: 7
Training loss: 3.142453193664551
Validation loss: 2.06569073020771

Epoch: 6| Step: 8
Training loss: 1.6072490215301514
Validation loss: 2.0891352315102854

Epoch: 6| Step: 9
Training loss: 2.249919891357422
Validation loss: 2.0721441930340183

Epoch: 6| Step: 10
Training loss: 1.4472525119781494
Validation loss: 2.0527121290083854

Epoch: 6| Step: 11
Training loss: 1.5986950397491455
Validation loss: 2.0664777319918395

Epoch: 6| Step: 12
Training loss: 1.8051941394805908
Validation loss: 2.0878789911987963

Epoch: 6| Step: 13
Training loss: 2.99489688873291
Validation loss: 2.063857225961583

Epoch: 260| Step: 0
Training loss: 2.1364684104919434
Validation loss: 2.061472644088089

Epoch: 6| Step: 1
Training loss: 1.9659792184829712
Validation loss: 2.086466661063574

Epoch: 6| Step: 2
Training loss: 1.672192931175232
Validation loss: 2.051340436422697

Epoch: 6| Step: 3
Training loss: 2.4395742416381836
Validation loss: 2.055992631502049

Epoch: 6| Step: 4
Training loss: 2.340174436569214
Validation loss: 2.065462541836564

Epoch: 6| Step: 5
Training loss: 2.866783618927002
Validation loss: 2.0480121361312045

Epoch: 6| Step: 6
Training loss: 1.7254219055175781
Validation loss: 2.0831250003589097

Epoch: 6| Step: 7
Training loss: 1.2479077577590942
Validation loss: 2.061406156068207

Epoch: 6| Step: 8
Training loss: 1.7690271139144897
Validation loss: 2.0576638624232304

Epoch: 6| Step: 9
Training loss: 1.832430124282837
Validation loss: 2.062073522998441

Epoch: 6| Step: 10
Training loss: 1.9489669799804688
Validation loss: 2.083568965235064

Epoch: 6| Step: 11
Training loss: 2.602266550064087
Validation loss: 2.0627719125440045

Epoch: 6| Step: 12
Training loss: 2.2275121212005615
Validation loss: 2.069068567727202

Epoch: 6| Step: 13
Training loss: 2.308669328689575
Validation loss: 2.0441215551027687

Epoch: 261| Step: 0
Training loss: 1.906470775604248
Validation loss: 2.0652923635257188

Epoch: 6| Step: 1
Training loss: 1.928122639656067
Validation loss: 2.0367425616069506

Epoch: 6| Step: 2
Training loss: 2.256152868270874
Validation loss: 2.060139251011674

Epoch: 6| Step: 3
Training loss: 1.818295955657959
Validation loss: 2.0705929802310084

Epoch: 6| Step: 4
Training loss: 1.9588913917541504
Validation loss: 2.0643159522805163

Epoch: 6| Step: 5
Training loss: 2.6828629970550537
Validation loss: 2.0692293438860165

Epoch: 6| Step: 6
Training loss: 1.47254478931427
Validation loss: 2.0527668537632113

Epoch: 6| Step: 7
Training loss: 2.678030014038086
Validation loss: 2.0525867349358013

Epoch: 6| Step: 8
Training loss: 2.1456751823425293
Validation loss: 2.0600906072124356

Epoch: 6| Step: 9
Training loss: 2.31844162940979
Validation loss: 2.060716575191867

Epoch: 6| Step: 10
Training loss: 1.4227886199951172
Validation loss: 2.0516666648208455

Epoch: 6| Step: 11
Training loss: 1.9479265213012695
Validation loss: 2.0510149245621054

Epoch: 6| Step: 12
Training loss: 1.411272406578064
Validation loss: 2.0451400433817217

Epoch: 6| Step: 13
Training loss: 3.1369028091430664
Validation loss: 2.079446615711335

Epoch: 262| Step: 0
Training loss: 2.6090965270996094
Validation loss: 2.056895395760895

Epoch: 6| Step: 1
Training loss: 2.343611717224121
Validation loss: 2.095530125402635

Epoch: 6| Step: 2
Training loss: 2.132213830947876
Validation loss: 2.061096429824829

Epoch: 6| Step: 3
Training loss: 2.132073402404785
Validation loss: 2.0820521052165697

Epoch: 6| Step: 4
Training loss: 1.6645569801330566
Validation loss: 2.062066232004473

Epoch: 6| Step: 5
Training loss: 1.57790207862854
Validation loss: 2.104885462791689

Epoch: 6| Step: 6
Training loss: 2.7144546508789062
Validation loss: 2.0965249358966784

Epoch: 6| Step: 7
Training loss: 2.518767833709717
Validation loss: 2.0832577200346094

Epoch: 6| Step: 8
Training loss: 2.309048891067505
Validation loss: 2.1038870068006617

Epoch: 6| Step: 9
Training loss: 1.4656710624694824
Validation loss: 2.087955185162124

Epoch: 6| Step: 10
Training loss: 1.6357342004776
Validation loss: 2.065874586823166

Epoch: 6| Step: 11
Training loss: 1.47819185256958
Validation loss: 2.084925215731385

Epoch: 6| Step: 12
Training loss: 2.453594207763672
Validation loss: 2.087865698722101

Epoch: 6| Step: 13
Training loss: 1.3754396438598633
Validation loss: 2.0663734623180923

Epoch: 263| Step: 0
Training loss: 1.7826220989227295
Validation loss: 2.0592466182606195

Epoch: 6| Step: 1
Training loss: 1.4240916967391968
Validation loss: 2.0877331174829954

Epoch: 6| Step: 2
Training loss: 2.2495551109313965
Validation loss: 2.0632534924373833

Epoch: 6| Step: 3
Training loss: 1.9647109508514404
Validation loss: 2.0332717677598358

Epoch: 6| Step: 4
Training loss: 2.08505916595459
Validation loss: 2.067694338419104

Epoch: 6| Step: 5
Training loss: 1.913712501525879
Validation loss: 2.058003435852707

Epoch: 6| Step: 6
Training loss: 2.47023868560791
Validation loss: 2.0687249501546225

Epoch: 6| Step: 7
Training loss: 1.5608794689178467
Validation loss: 2.064989746257823

Epoch: 6| Step: 8
Training loss: 1.713763952255249
Validation loss: 2.043587633358535

Epoch: 6| Step: 9
Training loss: 1.8585647344589233
Validation loss: 2.067851886954359

Epoch: 6| Step: 10
Training loss: 2.167747735977173
Validation loss: 2.0867607029535438

Epoch: 6| Step: 11
Training loss: 2.4892730712890625
Validation loss: 2.066178532056911

Epoch: 6| Step: 12
Training loss: 2.6283535957336426
Validation loss: 2.054372174765474

Epoch: 6| Step: 13
Training loss: 2.3855245113372803
Validation loss: 2.0795269999452817

Epoch: 264| Step: 0
Training loss: 2.4010276794433594
Validation loss: 2.0661018471564017

Epoch: 6| Step: 1
Training loss: 2.137542247772217
Validation loss: 2.1124950070534982

Epoch: 6| Step: 2
Training loss: 2.429731845855713
Validation loss: 2.069184867284631

Epoch: 6| Step: 3
Training loss: 1.2890198230743408
Validation loss: 2.0639146015208256

Epoch: 6| Step: 4
Training loss: 1.901540994644165
Validation loss: 2.0951917068932646

Epoch: 6| Step: 5
Training loss: 1.572792410850525
Validation loss: 2.0662165675111996

Epoch: 6| Step: 6
Training loss: 1.776045799255371
Validation loss: 2.0569338631886307

Epoch: 6| Step: 7
Training loss: 2.166043281555176
Validation loss: 2.0761961129403885

Epoch: 6| Step: 8
Training loss: 2.2516274452209473
Validation loss: 2.0683158700184157

Epoch: 6| Step: 9
Training loss: 2.405341625213623
Validation loss: 2.064670431998468

Epoch: 6| Step: 10
Training loss: 1.5578043460845947
Validation loss: 2.0897557850806945

Epoch: 6| Step: 11
Training loss: 1.714329719543457
Validation loss: 2.0491407417481944

Epoch: 6| Step: 12
Training loss: 2.331517457962036
Validation loss: 2.0545541035231722

Epoch: 6| Step: 13
Training loss: 2.7193288803100586
Validation loss: 2.0722209151073168

Epoch: 265| Step: 0
Training loss: 2.0583112239837646
Validation loss: 2.065695365269979

Epoch: 6| Step: 1
Training loss: 2.167593240737915
Validation loss: 2.0812228366892827

Epoch: 6| Step: 2
Training loss: 1.687916874885559
Validation loss: 2.0755157701430784

Epoch: 6| Step: 3
Training loss: 1.626250147819519
Validation loss: 2.044189296742921

Epoch: 6| Step: 4
Training loss: 3.105313301086426
Validation loss: 2.0401648385550386

Epoch: 6| Step: 5
Training loss: 2.590097427368164
Validation loss: 2.0955992744814966

Epoch: 6| Step: 6
Training loss: 1.3989490270614624
Validation loss: 2.102352073115687

Epoch: 6| Step: 7
Training loss: 1.87100088596344
Validation loss: 2.057520261374853

Epoch: 6| Step: 8
Training loss: 1.881691575050354
Validation loss: 2.100178272493424

Epoch: 6| Step: 9
Training loss: 2.277050733566284
Validation loss: 2.0271153603830645

Epoch: 6| Step: 10
Training loss: 2.0073158740997314
Validation loss: 2.0817769419762397

Epoch: 6| Step: 11
Training loss: 1.5576139688491821
Validation loss: 2.084784353933027

Epoch: 6| Step: 12
Training loss: 1.8708102703094482
Validation loss: 2.0236248636758454

Epoch: 6| Step: 13
Training loss: 2.405306816101074
Validation loss: 2.0739505893440655

Epoch: 266| Step: 0
Training loss: 1.7849477529525757
Validation loss: 2.08756507724844

Epoch: 6| Step: 1
Training loss: 1.7140721082687378
Validation loss: 2.1027926655225855

Epoch: 6| Step: 2
Training loss: 2.1451098918914795
Validation loss: 2.08528233087191

Epoch: 6| Step: 3
Training loss: 1.8603850603103638
Validation loss: 2.06608844828862

Epoch: 6| Step: 4
Training loss: 2.2884559631347656
Validation loss: 2.083746953677106

Epoch: 6| Step: 5
Training loss: 2.095386028289795
Validation loss: 2.0989629786501647

Epoch: 6| Step: 6
Training loss: 1.966934323310852
Validation loss: 2.101423733977861

Epoch: 6| Step: 7
Training loss: 1.776684284210205
Validation loss: 2.1009541890954457

Epoch: 6| Step: 8
Training loss: 2.410325527191162
Validation loss: 2.112631815736012

Epoch: 6| Step: 9
Training loss: 1.8291294574737549
Validation loss: 2.068955732930091

Epoch: 6| Step: 10
Training loss: 1.7936334609985352
Validation loss: 2.079755729244601

Epoch: 6| Step: 11
Training loss: 2.976958751678467
Validation loss: 2.050694365655222

Epoch: 6| Step: 12
Training loss: 2.1948485374450684
Validation loss: 2.052433903499316

Epoch: 6| Step: 13
Training loss: 1.0247881412506104
Validation loss: 2.0431498173744447

Epoch: 267| Step: 0
Training loss: 1.5133148431777954
Validation loss: 2.057070298861432

Epoch: 6| Step: 1
Training loss: 1.774982213973999
Validation loss: 2.052709256449053

Epoch: 6| Step: 2
Training loss: 2.018406391143799
Validation loss: 2.0637425414977537

Epoch: 6| Step: 3
Training loss: 2.292210340499878
Validation loss: 2.0635066955320296

Epoch: 6| Step: 4
Training loss: 2.6262454986572266
Validation loss: 2.0447208471195673

Epoch: 6| Step: 5
Training loss: 2.5392422676086426
Validation loss: 2.065108811983498

Epoch: 6| Step: 6
Training loss: 2.3662643432617188
Validation loss: 2.0783040574801865

Epoch: 6| Step: 7
Training loss: 1.220494031906128
Validation loss: 2.0795944480485815

Epoch: 6| Step: 8
Training loss: 2.319972515106201
Validation loss: 2.033062267047103

Epoch: 6| Step: 9
Training loss: 1.5796865224838257
Validation loss: 2.058307014485841

Epoch: 6| Step: 10
Training loss: 2.0539777278900146
Validation loss: 2.0939643434298936

Epoch: 6| Step: 11
Training loss: 2.3748087882995605
Validation loss: 2.0865005382927517

Epoch: 6| Step: 12
Training loss: 1.8833913803100586
Validation loss: 2.0791611197174236

Epoch: 6| Step: 13
Training loss: 1.6948201656341553
Validation loss: 2.06408405047591

Epoch: 268| Step: 0
Training loss: 1.8831603527069092
Validation loss: 2.0748572657185216

Epoch: 6| Step: 1
Training loss: 2.2456209659576416
Validation loss: 2.091518070108147

Epoch: 6| Step: 2
Training loss: 1.9837403297424316
Validation loss: 2.083196947651525

Epoch: 6| Step: 3
Training loss: 2.666656494140625
Validation loss: 2.0424791702660183

Epoch: 6| Step: 4
Training loss: 2.2426564693450928
Validation loss: 2.0861253148765972

Epoch: 6| Step: 5
Training loss: 1.8731130361557007
Validation loss: 2.0438884509507047

Epoch: 6| Step: 6
Training loss: 1.937174916267395
Validation loss: 2.018073897207937

Epoch: 6| Step: 7
Training loss: 2.115137815475464
Validation loss: 2.0719559243930283

Epoch: 6| Step: 8
Training loss: 1.612205147743225
Validation loss: 2.0702295739163636

Epoch: 6| Step: 9
Training loss: 2.0991499423980713
Validation loss: 2.059131832532985

Epoch: 6| Step: 10
Training loss: 1.7355313301086426
Validation loss: 2.066965897878011

Epoch: 6| Step: 11
Training loss: 2.2409048080444336
Validation loss: 2.0612720212628766

Epoch: 6| Step: 12
Training loss: 1.8320788145065308
Validation loss: 2.0660699336759505

Epoch: 6| Step: 13
Training loss: 1.994874119758606
Validation loss: 2.0759657095837336

Epoch: 269| Step: 0
Training loss: 2.542015314102173
Validation loss: 2.09807232118422

Epoch: 6| Step: 1
Training loss: 2.254976511001587
Validation loss: 2.1041093180256505

Epoch: 6| Step: 2
Training loss: 2.45314359664917
Validation loss: 2.0910287416109474

Epoch: 6| Step: 3
Training loss: 1.7512744665145874
Validation loss: 2.0909654683964227

Epoch: 6| Step: 4
Training loss: 2.3017184734344482
Validation loss: 2.0832565305053548

Epoch: 6| Step: 5
Training loss: 2.172346591949463
Validation loss: 2.0768144720344135

Epoch: 6| Step: 6
Training loss: 1.3362867832183838
Validation loss: 2.0638088923628612

Epoch: 6| Step: 7
Training loss: 1.316798210144043
Validation loss: 2.06687952369772

Epoch: 6| Step: 8
Training loss: 2.8206491470336914
Validation loss: 2.0877357452146468

Epoch: 6| Step: 9
Training loss: 1.761927843093872
Validation loss: 2.0929120843128493

Epoch: 6| Step: 10
Training loss: 1.377039909362793
Validation loss: 2.0775894490621423

Epoch: 6| Step: 11
Training loss: 2.394465923309326
Validation loss: 2.100959872686735

Epoch: 6| Step: 12
Training loss: 1.861662745475769
Validation loss: 2.1019637482140654

Epoch: 6| Step: 13
Training loss: 2.001359462738037
Validation loss: 2.098241904730438

Epoch: 270| Step: 0
Training loss: 1.9022706747055054
Validation loss: 2.102831458532682

Epoch: 6| Step: 1
Training loss: 2.6039812564849854
Validation loss: 2.0845839169717606

Epoch: 6| Step: 2
Training loss: 1.8120086193084717
Validation loss: 2.0906387221428657

Epoch: 6| Step: 3
Training loss: 1.9108388423919678
Validation loss: 2.083045680035827

Epoch: 6| Step: 4
Training loss: 1.5632296800613403
Validation loss: 2.094047784805298

Epoch: 6| Step: 5
Training loss: 1.8976645469665527
Validation loss: 2.073718883657968

Epoch: 6| Step: 6
Training loss: 2.2432034015655518
Validation loss: 2.053393276788855

Epoch: 6| Step: 7
Training loss: 2.20267915725708
Validation loss: 2.054282008960683

Epoch: 6| Step: 8
Training loss: 1.5944249629974365
Validation loss: 2.0922385133722776

Epoch: 6| Step: 9
Training loss: 2.110020160675049
Validation loss: 2.10259562025788

Epoch: 6| Step: 10
Training loss: 2.4190149307250977
Validation loss: 2.0609467491026847

Epoch: 6| Step: 11
Training loss: 1.564154863357544
Validation loss: 2.0698820647372993

Epoch: 6| Step: 12
Training loss: 2.4412341117858887
Validation loss: 2.0697827903173303

Epoch: 6| Step: 13
Training loss: 2.022895336151123
Validation loss: 2.0839453627986293

Epoch: 271| Step: 0
Training loss: 1.2813549041748047
Validation loss: 2.0591042413506457

Epoch: 6| Step: 1
Training loss: 1.7393306493759155
Validation loss: 2.073858077808093

Epoch: 6| Step: 2
Training loss: 1.794912338256836
Validation loss: 2.0913643144792124

Epoch: 6| Step: 3
Training loss: 2.0558927059173584
Validation loss: 2.063961390526064

Epoch: 6| Step: 4
Training loss: 1.132792592048645
Validation loss: 2.0960061511685772

Epoch: 6| Step: 5
Training loss: 2.398374557495117
Validation loss: 2.0783469394970964

Epoch: 6| Step: 6
Training loss: 1.758663535118103
Validation loss: 2.061537511887089

Epoch: 6| Step: 7
Training loss: 2.7709150314331055
Validation loss: 2.0680917591177006

Epoch: 6| Step: 8
Training loss: 1.728028655052185
Validation loss: 2.070774387287837

Epoch: 6| Step: 9
Training loss: 2.4894113540649414
Validation loss: 2.0725092554605133

Epoch: 6| Step: 10
Training loss: 2.3750593662261963
Validation loss: 2.0908520811347553

Epoch: 6| Step: 11
Training loss: 2.5813822746276855
Validation loss: 2.0503842548657487

Epoch: 6| Step: 12
Training loss: 2.612396001815796
Validation loss: 2.09043853000928

Epoch: 6| Step: 13
Training loss: 1.4845579862594604
Validation loss: 2.0507082105964742

Epoch: 272| Step: 0
Training loss: 2.311401605606079
Validation loss: 2.073945940181773

Epoch: 6| Step: 1
Training loss: 1.8315610885620117
Validation loss: 2.0951042482929845

Epoch: 6| Step: 2
Training loss: 1.4254504442214966
Validation loss: 2.054411603558448

Epoch: 6| Step: 3
Training loss: 2.1744847297668457
Validation loss: 2.0469114780426025

Epoch: 6| Step: 4
Training loss: 1.726283311843872
Validation loss: 2.0940882646909325

Epoch: 6| Step: 5
Training loss: 1.401857614517212
Validation loss: 2.091129569597142

Epoch: 6| Step: 6
Training loss: 1.7121930122375488
Validation loss: 2.0875692739281604

Epoch: 6| Step: 7
Training loss: 2.6708030700683594
Validation loss: 2.0857866579486477

Epoch: 6| Step: 8
Training loss: 1.666864037513733
Validation loss: 2.0835423251634

Epoch: 6| Step: 9
Training loss: 2.2861826419830322
Validation loss: 2.053429759958739

Epoch: 6| Step: 10
Training loss: 2.072330951690674
Validation loss: 2.1017814656739593

Epoch: 6| Step: 11
Training loss: 2.1696484088897705
Validation loss: 2.11031416667405

Epoch: 6| Step: 12
Training loss: 2.3955793380737305
Validation loss: 2.07173857765813

Epoch: 6| Step: 13
Training loss: 2.4896740913391113
Validation loss: 2.058155805833878

Epoch: 273| Step: 0
Training loss: 1.6983736753463745
Validation loss: 2.0877351466045586

Epoch: 6| Step: 1
Training loss: 2.3550503253936768
Validation loss: 2.0652021233753493

Epoch: 6| Step: 2
Training loss: 2.148021697998047
Validation loss: 2.0334731340408325

Epoch: 6| Step: 3
Training loss: 2.2441651821136475
Validation loss: 2.0541984547850904

Epoch: 6| Step: 4
Training loss: 1.838462233543396
Validation loss: 2.0455178227475894

Epoch: 6| Step: 5
Training loss: 1.955078125
Validation loss: 2.062634309132894

Epoch: 6| Step: 6
Training loss: 2.4311511516571045
Validation loss: 2.055099753923314

Epoch: 6| Step: 7
Training loss: 1.8063313961029053
Validation loss: 2.0682529185407903

Epoch: 6| Step: 8
Training loss: 1.8766717910766602
Validation loss: 2.0692298207231747

Epoch: 6| Step: 9
Training loss: 2.913578510284424
Validation loss: 2.0685740722123014

Epoch: 6| Step: 10
Training loss: 1.5080177783966064
Validation loss: 2.075407628090151

Epoch: 6| Step: 11
Training loss: 2.032865524291992
Validation loss: 2.0714375331837642

Epoch: 6| Step: 12
Training loss: 1.4388160705566406
Validation loss: 2.0697730318192513

Epoch: 6| Step: 13
Training loss: 2.0858983993530273
Validation loss: 2.067406545403183

Epoch: 274| Step: 0
Training loss: 1.614031195640564
Validation loss: 2.0541063880407684

Epoch: 6| Step: 1
Training loss: 2.1101794242858887
Validation loss: 2.0684917665296987

Epoch: 6| Step: 2
Training loss: 1.4907188415527344
Validation loss: 2.0419978582730858

Epoch: 6| Step: 3
Training loss: 1.9427787065505981
Validation loss: 2.084634498883319

Epoch: 6| Step: 4
Training loss: 2.395388603210449
Validation loss: 2.045657668062436

Epoch: 6| Step: 5
Training loss: 3.1207568645477295
Validation loss: 2.0471430965649184

Epoch: 6| Step: 6
Training loss: 1.4548276662826538
Validation loss: 2.0956930383559196

Epoch: 6| Step: 7
Training loss: 1.4607012271881104
Validation loss: 2.0655563262201126

Epoch: 6| Step: 8
Training loss: 2.652017831802368
Validation loss: 2.071594129326523

Epoch: 6| Step: 9
Training loss: 2.2951037883758545
Validation loss: 2.050882621478009

Epoch: 6| Step: 10
Training loss: 1.8021974563598633
Validation loss: 2.061680406652471

Epoch: 6| Step: 11
Training loss: 2.1059398651123047
Validation loss: 2.079661210378011

Epoch: 6| Step: 12
Training loss: 2.0154407024383545
Validation loss: 2.0640541020260064

Epoch: 6| Step: 13
Training loss: 1.551997184753418
Validation loss: 2.0817345226964643

Epoch: 275| Step: 0
Training loss: 2.0218312740325928
Validation loss: 2.05363788143281

Epoch: 6| Step: 1
Training loss: 2.3651576042175293
Validation loss: 2.084231004920057

Epoch: 6| Step: 2
Training loss: 1.7387903928756714
Validation loss: 2.0820742063624884

Epoch: 6| Step: 3
Training loss: 1.7457420825958252
Validation loss: 2.0966877527134393

Epoch: 6| Step: 4
Training loss: 1.4880212545394897
Validation loss: 2.067816711241199

Epoch: 6| Step: 5
Training loss: 1.4055161476135254
Validation loss: 2.086706857527456

Epoch: 6| Step: 6
Training loss: 2.3035011291503906
Validation loss: 2.0690281198870752

Epoch: 6| Step: 7
Training loss: 1.8077404499053955
Validation loss: 2.0724154800497074

Epoch: 6| Step: 8
Training loss: 2.5437350273132324
Validation loss: 2.0843198658317648

Epoch: 6| Step: 9
Training loss: 1.9269822835922241
Validation loss: 2.068582709117602

Epoch: 6| Step: 10
Training loss: 2.413179874420166
Validation loss: 2.0704344985305623

Epoch: 6| Step: 11
Training loss: 2.2821109294891357
Validation loss: 2.0881350168617825

Epoch: 6| Step: 12
Training loss: 2.256594181060791
Validation loss: 2.103662702345079

Epoch: 6| Step: 13
Training loss: 1.907889485359192
Validation loss: 2.082819607950026

Epoch: 276| Step: 0
Training loss: 1.5531420707702637
Validation loss: 2.0918509626901276

Epoch: 6| Step: 1
Training loss: 1.7524495124816895
Validation loss: 2.086025091909593

Epoch: 6| Step: 2
Training loss: 2.018653392791748
Validation loss: 2.060503413600306

Epoch: 6| Step: 3
Training loss: 1.8493037223815918
Validation loss: 2.0775110926679385

Epoch: 6| Step: 4
Training loss: 2.2805933952331543
Validation loss: 2.0649609206825175

Epoch: 6| Step: 5
Training loss: 1.7666707038879395
Validation loss: 2.093234660804913

Epoch: 6| Step: 6
Training loss: 2.6269278526306152
Validation loss: 2.0779848919119885

Epoch: 6| Step: 7
Training loss: 2.0009615421295166
Validation loss: 2.0607913809437908

Epoch: 6| Step: 8
Training loss: 2.201381206512451
Validation loss: 2.0450995686233684

Epoch: 6| Step: 9
Training loss: 2.2549822330474854
Validation loss: 2.0553993102042907

Epoch: 6| Step: 10
Training loss: 1.7381279468536377
Validation loss: 2.0929698867182576

Epoch: 6| Step: 11
Training loss: 2.1129417419433594
Validation loss: 2.05399029613823

Epoch: 6| Step: 12
Training loss: 1.7992125749588013
Validation loss: 2.102499464506744

Epoch: 6| Step: 13
Training loss: 2.2323248386383057
Validation loss: 2.0767234397190872

Epoch: 277| Step: 0
Training loss: 1.2676254510879517
Validation loss: 2.0695719026750132

Epoch: 6| Step: 1
Training loss: 1.384129524230957
Validation loss: 2.089446606174592

Epoch: 6| Step: 2
Training loss: 2.0113742351531982
Validation loss: 2.087217459114649

Epoch: 6| Step: 3
Training loss: 1.8121047019958496
Validation loss: 2.0809047324683076

Epoch: 6| Step: 4
Training loss: 1.7663767337799072
Validation loss: 2.1128236529647664

Epoch: 6| Step: 5
Training loss: 2.618180274963379
Validation loss: 2.1112586477751374

Epoch: 6| Step: 6
Training loss: 2.0274791717529297
Validation loss: 2.1056941145209858

Epoch: 6| Step: 7
Training loss: 2.1479036808013916
Validation loss: 2.1065346438397645

Epoch: 6| Step: 8
Training loss: 1.6599271297454834
Validation loss: 2.1189799898414203

Epoch: 6| Step: 9
Training loss: 1.8989593982696533
Validation loss: 2.082316888275967

Epoch: 6| Step: 10
Training loss: 2.278024673461914
Validation loss: 2.088546786257016

Epoch: 6| Step: 11
Training loss: 2.3836631774902344
Validation loss: 2.0890903985628517

Epoch: 6| Step: 12
Training loss: 1.9525253772735596
Validation loss: 2.0999137457980903

Epoch: 6| Step: 13
Training loss: 3.6373252868652344
Validation loss: 2.0897319124590967

Epoch: 278| Step: 0
Training loss: 2.6148791313171387
Validation loss: 2.107059919705955

Epoch: 6| Step: 1
Training loss: 2.2201662063598633
Validation loss: 2.1027110353592904

Epoch: 6| Step: 2
Training loss: 1.8346266746520996
Validation loss: 2.094203902829078

Epoch: 6| Step: 3
Training loss: 2.064502239227295
Validation loss: 2.0988709131876626

Epoch: 6| Step: 4
Training loss: 2.552243232727051
Validation loss: 2.0364905788052465

Epoch: 6| Step: 5
Training loss: 1.9863526821136475
Validation loss: 2.0903002497970418

Epoch: 6| Step: 6
Training loss: 2.2573609352111816
Validation loss: 2.0784108228580926

Epoch: 6| Step: 7
Training loss: 1.5511665344238281
Validation loss: 2.0788519100476335

Epoch: 6| Step: 8
Training loss: 2.592385768890381
Validation loss: 2.086859969682591

Epoch: 6| Step: 9
Training loss: 1.5345194339752197
Validation loss: 2.0997732429094214

Epoch: 6| Step: 10
Training loss: 1.6457678079605103
Validation loss: 2.099737098140101

Epoch: 6| Step: 11
Training loss: 1.8962962627410889
Validation loss: 2.087051009619108

Epoch: 6| Step: 12
Training loss: 1.219658374786377
Validation loss: 2.0713269531085925

Epoch: 6| Step: 13
Training loss: 2.156832218170166
Validation loss: 2.0697519907387356

Epoch: 279| Step: 0
Training loss: 2.422894239425659
Validation loss: 2.0332806443655365

Epoch: 6| Step: 1
Training loss: 1.7627962827682495
Validation loss: 2.0636734911190566

Epoch: 6| Step: 2
Training loss: 2.471083164215088
Validation loss: 2.07559839499894

Epoch: 6| Step: 3
Training loss: 1.4321767091751099
Validation loss: 2.069609095973353

Epoch: 6| Step: 4
Training loss: 2.1987814903259277
Validation loss: 2.0522461757865003

Epoch: 6| Step: 5
Training loss: 1.7071051597595215
Validation loss: 2.0385136065944547

Epoch: 6| Step: 6
Training loss: 1.8589866161346436
Validation loss: 2.059255302593272

Epoch: 6| Step: 7
Training loss: 2.2289209365844727
Validation loss: 2.049898147583008

Epoch: 6| Step: 8
Training loss: 1.7667264938354492
Validation loss: 2.0724028746287027

Epoch: 6| Step: 9
Training loss: 1.7325063943862915
Validation loss: 2.0840100011517926

Epoch: 6| Step: 10
Training loss: 2.140794277191162
Validation loss: 2.0297302174311813

Epoch: 6| Step: 11
Training loss: 1.6697982549667358
Validation loss: 2.081032988845661

Epoch: 6| Step: 12
Training loss: 2.3335041999816895
Validation loss: 2.076140273001886

Epoch: 6| Step: 13
Training loss: 2.5239174365997314
Validation loss: 2.0772893121165614

Epoch: 280| Step: 0
Training loss: 2.1624817848205566
Validation loss: 2.058101136197326

Epoch: 6| Step: 1
Training loss: 1.9887075424194336
Validation loss: 2.0858679189476916

Epoch: 6| Step: 2
Training loss: 1.8379839658737183
Validation loss: 2.039541741853119

Epoch: 6| Step: 3
Training loss: 2.4593191146850586
Validation loss: 2.0746553123638196

Epoch: 6| Step: 4
Training loss: 2.05411958694458
Validation loss: 2.0592499189479376

Epoch: 6| Step: 5
Training loss: 1.723567247390747
Validation loss: 2.0627895068096858

Epoch: 6| Step: 6
Training loss: 2.2933502197265625
Validation loss: 2.0662390429486512

Epoch: 6| Step: 7
Training loss: 2.4454450607299805
Validation loss: 2.0866642587928363

Epoch: 6| Step: 8
Training loss: 2.18688702583313
Validation loss: 2.0708325768029816

Epoch: 6| Step: 9
Training loss: 1.9457554817199707
Validation loss: 2.0794428779232885

Epoch: 6| Step: 10
Training loss: 2.080348014831543
Validation loss: 2.095398119700852

Epoch: 6| Step: 11
Training loss: 1.4875091314315796
Validation loss: 2.0651764600507674

Epoch: 6| Step: 12
Training loss: 1.1843630075454712
Validation loss: 2.074408474788871

Epoch: 6| Step: 13
Training loss: 2.179220676422119
Validation loss: 2.0879016871093423

Epoch: 281| Step: 0
Training loss: 2.2626655101776123
Validation loss: 2.0773864241056543

Epoch: 6| Step: 1
Training loss: 1.8316686153411865
Validation loss: 2.0602805845199095

Epoch: 6| Step: 2
Training loss: 1.8326654434204102
Validation loss: 2.076419538067233

Epoch: 6| Step: 3
Training loss: 1.6635074615478516
Validation loss: 2.1091761396777247

Epoch: 6| Step: 4
Training loss: 2.1680970191955566
Validation loss: 2.0706378093329807

Epoch: 6| Step: 5
Training loss: 1.8231126070022583
Validation loss: 2.082673934198195

Epoch: 6| Step: 6
Training loss: 2.493781805038452
Validation loss: 2.068720281765025

Epoch: 6| Step: 7
Training loss: 2.411991596221924
Validation loss: 2.0645449776803293

Epoch: 6| Step: 8
Training loss: 1.9961555004119873
Validation loss: 2.0880928577915316

Epoch: 6| Step: 9
Training loss: 2.1355669498443604
Validation loss: 2.0884156970567602

Epoch: 6| Step: 10
Training loss: 1.9275524616241455
Validation loss: 2.0913997568109983

Epoch: 6| Step: 11
Training loss: 2.123871326446533
Validation loss: 2.1095376719710646

Epoch: 6| Step: 12
Training loss: 1.4825072288513184
Validation loss: 2.0774259900534027

Epoch: 6| Step: 13
Training loss: 1.8692660331726074
Validation loss: 2.067808935719152

Epoch: 282| Step: 0
Training loss: 2.32600736618042
Validation loss: 2.084742643499887

Epoch: 6| Step: 1
Training loss: 1.4096485376358032
Validation loss: 2.0617529499915337

Epoch: 6| Step: 2
Training loss: 1.4079450368881226
Validation loss: 2.079360051821637

Epoch: 6| Step: 3
Training loss: 1.824081301689148
Validation loss: 2.053954747415358

Epoch: 6| Step: 4
Training loss: 2.261791229248047
Validation loss: 2.0652908432868218

Epoch: 6| Step: 5
Training loss: 1.7966365814208984
Validation loss: 2.1027172355241674

Epoch: 6| Step: 6
Training loss: 2.497885227203369
Validation loss: 2.069488386954031

Epoch: 6| Step: 7
Training loss: 2.0592498779296875
Validation loss: 2.1092533834518923

Epoch: 6| Step: 8
Training loss: 2.5609891414642334
Validation loss: 2.065979452543361

Epoch: 6| Step: 9
Training loss: 2.120685577392578
Validation loss: 2.1069423870373796

Epoch: 6| Step: 10
Training loss: 2.462003707885742
Validation loss: 2.078201855382612

Epoch: 6| Step: 11
Training loss: 2.0225892066955566
Validation loss: 2.1132018181585495

Epoch: 6| Step: 12
Training loss: 1.245820164680481
Validation loss: 2.1031786062384166

Epoch: 6| Step: 13
Training loss: 2.0472283363342285
Validation loss: 2.063245200341748

Epoch: 283| Step: 0
Training loss: 1.9949727058410645
Validation loss: 2.1137873998252292

Epoch: 6| Step: 1
Training loss: 1.5480117797851562
Validation loss: 2.1191048160676034

Epoch: 6| Step: 2
Training loss: 1.4358779191970825
Validation loss: 2.100737988307912

Epoch: 6| Step: 3
Training loss: 1.7876417636871338
Validation loss: 2.095841642348997

Epoch: 6| Step: 4
Training loss: 1.9323978424072266
Validation loss: 2.0474914684090564

Epoch: 6| Step: 5
Training loss: 2.0403337478637695
Validation loss: 2.0818850865928074

Epoch: 6| Step: 6
Training loss: 2.2818751335144043
Validation loss: 2.1190330443843717

Epoch: 6| Step: 7
Training loss: 2.1534109115600586
Validation loss: 2.1104134718577066

Epoch: 6| Step: 8
Training loss: 2.665870189666748
Validation loss: 2.105466519632647

Epoch: 6| Step: 9
Training loss: 2.071621894836426
Validation loss: 2.0897184777003464

Epoch: 6| Step: 10
Training loss: 1.8974404335021973
Validation loss: 2.112847499949958

Epoch: 6| Step: 11
Training loss: 1.6835991144180298
Validation loss: 2.098001754412087

Epoch: 6| Step: 12
Training loss: 2.431049346923828
Validation loss: 2.1247273247729064

Epoch: 6| Step: 13
Training loss: 2.1912739276885986
Validation loss: 2.1017740593161633

Epoch: 284| Step: 0
Training loss: 1.947623372077942
Validation loss: 2.0861926078796387

Epoch: 6| Step: 1
Training loss: 1.4656211137771606
Validation loss: 2.055112167071271

Epoch: 6| Step: 2
Training loss: 2.18656587600708
Validation loss: 2.1068423973616732

Epoch: 6| Step: 3
Training loss: 1.9129878282546997
Validation loss: 2.0737609671008204

Epoch: 6| Step: 4
Training loss: 1.8993189334869385
Validation loss: 2.0593089365190074

Epoch: 6| Step: 5
Training loss: 1.9558392763137817
Validation loss: 2.046071348651763

Epoch: 6| Step: 6
Training loss: 2.401962995529175
Validation loss: 2.0980041719252065

Epoch: 6| Step: 7
Training loss: 2.4380998611450195
Validation loss: 2.0775277255683817

Epoch: 6| Step: 8
Training loss: 1.621976375579834
Validation loss: 2.039810302436993

Epoch: 6| Step: 9
Training loss: 2.2562711238861084
Validation loss: 2.0703508046365555

Epoch: 6| Step: 10
Training loss: 1.7173547744750977
Validation loss: 2.0837019258929836

Epoch: 6| Step: 11
Training loss: 1.777413249015808
Validation loss: 2.0460839784273537

Epoch: 6| Step: 12
Training loss: 2.1870718002319336
Validation loss: 2.065528569682952

Epoch: 6| Step: 13
Training loss: 2.2817537784576416
Validation loss: 2.0876049405785015

Epoch: 285| Step: 0
Training loss: 1.9451980590820312
Validation loss: 2.0890417509181525

Epoch: 6| Step: 1
Training loss: 2.98677134513855
Validation loss: 2.049366403651494

Epoch: 6| Step: 2
Training loss: 2.1427712440490723
Validation loss: 2.088661265629594

Epoch: 6| Step: 3
Training loss: 1.5327776670455933
Validation loss: 2.063352623293477

Epoch: 6| Step: 4
Training loss: 1.7227243185043335
Validation loss: 2.0674976764186734

Epoch: 6| Step: 5
Training loss: 1.753482699394226
Validation loss: 2.0747865374370287

Epoch: 6| Step: 6
Training loss: 2.2666521072387695
Validation loss: 2.0623698029466855

Epoch: 6| Step: 7
Training loss: 1.84269118309021
Validation loss: 2.049086704049059

Epoch: 6| Step: 8
Training loss: 1.7154122591018677
Validation loss: 2.054614149114137

Epoch: 6| Step: 9
Training loss: 2.064748764038086
Validation loss: 2.0850159532280377

Epoch: 6| Step: 10
Training loss: 1.7680249214172363
Validation loss: 2.0734859179424983

Epoch: 6| Step: 11
Training loss: 2.1328370571136475
Validation loss: 2.0721459875824633

Epoch: 6| Step: 12
Training loss: 2.2511534690856934
Validation loss: 2.09191035198909

Epoch: 6| Step: 13
Training loss: 1.5335865020751953
Validation loss: 2.0723107796843334

Epoch: 286| Step: 0
Training loss: 1.8227870464324951
Validation loss: 2.064992827753867

Epoch: 6| Step: 1
Training loss: 2.2802000045776367
Validation loss: 2.061348912536457

Epoch: 6| Step: 2
Training loss: 1.9702532291412354
Validation loss: 2.0833544090229976

Epoch: 6| Step: 3
Training loss: 1.108155369758606
Validation loss: 2.0444973617471676

Epoch: 6| Step: 4
Training loss: 2.333376407623291
Validation loss: 2.0545631480473343

Epoch: 6| Step: 5
Training loss: 1.9524164199829102
Validation loss: 2.0900755902772308

Epoch: 6| Step: 6
Training loss: 1.9765825271606445
Validation loss: 2.075538791635985

Epoch: 6| Step: 7
Training loss: 2.3146815299987793
Validation loss: 2.063691882676976

Epoch: 6| Step: 8
Training loss: 2.1707305908203125
Validation loss: 2.0716188594859135

Epoch: 6| Step: 9
Training loss: 1.9509660005569458
Validation loss: 2.0774651804277973

Epoch: 6| Step: 10
Training loss: 1.872230052947998
Validation loss: 2.0941072728044245

Epoch: 6| Step: 11
Training loss: 2.415400505065918
Validation loss: 2.079621943094397

Epoch: 6| Step: 12
Training loss: 1.4409184455871582
Validation loss: 2.0846702437247

Epoch: 6| Step: 13
Training loss: 2.627213954925537
Validation loss: 2.0998975320528914

Epoch: 287| Step: 0
Training loss: 1.2013485431671143
Validation loss: 2.0726789146341305

Epoch: 6| Step: 1
Training loss: 1.9605915546417236
Validation loss: 2.065859945871497

Epoch: 6| Step: 2
Training loss: 1.6790271997451782
Validation loss: 2.0905023467156196

Epoch: 6| Step: 3
Training loss: 2.6443252563476562
Validation loss: 2.096618890762329

Epoch: 6| Step: 4
Training loss: 2.4382333755493164
Validation loss: 2.1124766129319386

Epoch: 6| Step: 5
Training loss: 2.0605039596557617
Validation loss: 2.121272348588513

Epoch: 6| Step: 6
Training loss: 2.431703567504883
Validation loss: 2.070033645117155

Epoch: 6| Step: 7
Training loss: 1.7756016254425049
Validation loss: 2.0946685344942155

Epoch: 6| Step: 8
Training loss: 2.1280322074890137
Validation loss: 2.063684917265369

Epoch: 6| Step: 9
Training loss: 2.0139970779418945
Validation loss: 2.0694901007477955

Epoch: 6| Step: 10
Training loss: 2.2252840995788574
Validation loss: 2.0804087987510105

Epoch: 6| Step: 11
Training loss: 1.7535096406936646
Validation loss: 2.071259758805716

Epoch: 6| Step: 12
Training loss: 1.9298458099365234
Validation loss: 2.0835197023166123

Epoch: 6| Step: 13
Training loss: 1.84527587890625
Validation loss: 2.092435097181669

Epoch: 288| Step: 0
Training loss: 1.7180490493774414
Validation loss: 2.0692969599077777

Epoch: 6| Step: 1
Training loss: 2.082728147506714
Validation loss: 2.0731712259272093

Epoch: 6| Step: 2
Training loss: 3.635840892791748
Validation loss: 2.0713025626315864

Epoch: 6| Step: 3
Training loss: 0.8108639717102051
Validation loss: 2.0759292661502795

Epoch: 6| Step: 4
Training loss: 2.1017279624938965
Validation loss: 2.0554586277213147

Epoch: 6| Step: 5
Training loss: 2.3525543212890625
Validation loss: 2.0576264601881786

Epoch: 6| Step: 6
Training loss: 2.167695999145508
Validation loss: 2.059713086774272

Epoch: 6| Step: 7
Training loss: 1.7294535636901855
Validation loss: 2.042217613548361

Epoch: 6| Step: 8
Training loss: 2.2840888500213623
Validation loss: 2.0731183559663835

Epoch: 6| Step: 9
Training loss: 1.8380151987075806
Validation loss: 2.0988935962800057

Epoch: 6| Step: 10
Training loss: 1.9096602201461792
Validation loss: 2.075316336847121

Epoch: 6| Step: 11
Training loss: 1.4446747303009033
Validation loss: 2.084062171238725

Epoch: 6| Step: 12
Training loss: 1.6539989709854126
Validation loss: 2.070089881138135

Epoch: 6| Step: 13
Training loss: 2.1557776927948
Validation loss: 2.0674263174815843

Epoch: 289| Step: 0
Training loss: 2.543808937072754
Validation loss: 2.079265835464642

Epoch: 6| Step: 1
Training loss: 2.547985076904297
Validation loss: 2.0902665763772945

Epoch: 6| Step: 2
Training loss: 1.931705355644226
Validation loss: 2.106495681629386

Epoch: 6| Step: 3
Training loss: 1.9391517639160156
Validation loss: 2.0504735182690363

Epoch: 6| Step: 4
Training loss: 1.7874178886413574
Validation loss: 2.073307711591003

Epoch: 6| Step: 5
Training loss: 2.002688407897949
Validation loss: 2.057597029593683

Epoch: 6| Step: 6
Training loss: 2.2687933444976807
Validation loss: 2.056493269499912

Epoch: 6| Step: 7
Training loss: 1.611953854560852
Validation loss: 2.063762826304282

Epoch: 6| Step: 8
Training loss: 1.8771554231643677
Validation loss: 2.1082683224831857

Epoch: 6| Step: 9
Training loss: 2.313631057739258
Validation loss: 2.0559659619485178

Epoch: 6| Step: 10
Training loss: 1.4142444133758545
Validation loss: 2.0965387436651413

Epoch: 6| Step: 11
Training loss: 1.7909908294677734
Validation loss: 2.0687796441457604

Epoch: 6| Step: 12
Training loss: 2.425861358642578
Validation loss: 2.072104674513622

Epoch: 6| Step: 13
Training loss: 1.311787486076355
Validation loss: 2.0913686495955273

Epoch: 290| Step: 0
Training loss: 1.7768139839172363
Validation loss: 2.0670562687740532

Epoch: 6| Step: 1
Training loss: 1.3077893257141113
Validation loss: 2.0733933564155334

Epoch: 6| Step: 2
Training loss: 2.5433337688446045
Validation loss: 2.0903083009104573

Epoch: 6| Step: 3
Training loss: 1.7991869449615479
Validation loss: 2.0685091377586446

Epoch: 6| Step: 4
Training loss: 1.6345140933990479
Validation loss: 2.117923810917844

Epoch: 6| Step: 5
Training loss: 1.5588505268096924
Validation loss: 2.089356904388756

Epoch: 6| Step: 6
Training loss: 2.193976879119873
Validation loss: 2.056013495691361

Epoch: 6| Step: 7
Training loss: 2.077058792114258
Validation loss: 2.0463194462560836

Epoch: 6| Step: 8
Training loss: 2.1061434745788574
Validation loss: 2.0694137029750372

Epoch: 6| Step: 9
Training loss: 2.133033275604248
Validation loss: 2.0655619252112603

Epoch: 6| Step: 10
Training loss: 2.0780839920043945
Validation loss: 2.062650051168216

Epoch: 6| Step: 11
Training loss: 2.0532875061035156
Validation loss: 2.0831579495501775

Epoch: 6| Step: 12
Training loss: 2.418790340423584
Validation loss: 2.0685759436699653

Epoch: 6| Step: 13
Training loss: 2.2999320030212402
Validation loss: 2.071167940734535

Epoch: 291| Step: 0
Training loss: 2.391448736190796
Validation loss: 2.0610776844845025

Epoch: 6| Step: 1
Training loss: 2.8315653800964355
Validation loss: 2.0500095326413392

Epoch: 6| Step: 2
Training loss: 1.9674806594848633
Validation loss: 2.0764073684651363

Epoch: 6| Step: 3
Training loss: 1.9673727750778198
Validation loss: 2.0886778626390683

Epoch: 6| Step: 4
Training loss: 2.26603364944458
Validation loss: 2.0688945170371764

Epoch: 6| Step: 5
Training loss: 1.788428544998169
Validation loss: 2.075767368398687

Epoch: 6| Step: 6
Training loss: 1.9789930582046509
Validation loss: 2.0712956715655584

Epoch: 6| Step: 7
Training loss: 2.4703407287597656
Validation loss: 2.086564375508216

Epoch: 6| Step: 8
Training loss: 1.22893226146698
Validation loss: 2.091115508028256

Epoch: 6| Step: 9
Training loss: 1.378419041633606
Validation loss: 2.0844865768186507

Epoch: 6| Step: 10
Training loss: 2.9147701263427734
Validation loss: 2.07334917078736

Epoch: 6| Step: 11
Training loss: 1.3625515699386597
Validation loss: 2.0791358127388904

Epoch: 6| Step: 12
Training loss: 1.092405080795288
Validation loss: 2.037854817605788

Epoch: 6| Step: 13
Training loss: 1.9936392307281494
Validation loss: 2.0725387680915093

Epoch: 292| Step: 0
Training loss: 1.8247830867767334
Validation loss: 2.10019378764655

Epoch: 6| Step: 1
Training loss: 2.076639175415039
Validation loss: 2.0697401236462336

Epoch: 6| Step: 2
Training loss: 3.0007503032684326
Validation loss: 2.0771213641730686

Epoch: 6| Step: 3
Training loss: 2.0351076126098633
Validation loss: 2.078325463879493

Epoch: 6| Step: 4
Training loss: 1.5740995407104492
Validation loss: 2.087001718500609

Epoch: 6| Step: 5
Training loss: 1.9238622188568115
Validation loss: 2.0515073922372635

Epoch: 6| Step: 6
Training loss: 2.2080140113830566
Validation loss: 2.043148030516922

Epoch: 6| Step: 7
Training loss: 1.61509108543396
Validation loss: 2.065008662080252

Epoch: 6| Step: 8
Training loss: 2.4510245323181152
Validation loss: 2.0594614116094445

Epoch: 6| Step: 9
Training loss: 2.173816680908203
Validation loss: 2.0571309417806645

Epoch: 6| Step: 10
Training loss: 1.8989524841308594
Validation loss: 2.0511857578831334

Epoch: 6| Step: 11
Training loss: 2.1022565364837646
Validation loss: 2.08009635889402

Epoch: 6| Step: 12
Training loss: 1.119112253189087
Validation loss: 2.0477159100194133

Epoch: 6| Step: 13
Training loss: 1.3357149362564087
Validation loss: 2.0845624195632113

Epoch: 293| Step: 0
Training loss: 2.4062960147857666
Validation loss: 2.0646332438274095

Epoch: 6| Step: 1
Training loss: 2.2534799575805664
Validation loss: 2.074880628175633

Epoch: 6| Step: 2
Training loss: 1.782777190208435
Validation loss: 2.0743786417027956

Epoch: 6| Step: 3
Training loss: 2.1809911727905273
Validation loss: 2.081193704758921

Epoch: 6| Step: 4
Training loss: 1.3576939105987549
Validation loss: 2.1200981242682344

Epoch: 6| Step: 5
Training loss: 2.255169630050659
Validation loss: 2.083805335465298

Epoch: 6| Step: 6
Training loss: 2.0793542861938477
Validation loss: 2.095742670438623

Epoch: 6| Step: 7
Training loss: 1.636857509613037
Validation loss: 2.0812098351857995

Epoch: 6| Step: 8
Training loss: 1.8302478790283203
Validation loss: 2.110092259222461

Epoch: 6| Step: 9
Training loss: 1.7676022052764893
Validation loss: 2.0789552862926195

Epoch: 6| Step: 10
Training loss: 1.7550756931304932
Validation loss: 2.1074888552388837

Epoch: 6| Step: 11
Training loss: 2.3195574283599854
Validation loss: 2.0861402737197055

Epoch: 6| Step: 12
Training loss: 2.55692982673645
Validation loss: 2.0890394923507527

Epoch: 6| Step: 13
Training loss: 0.9615692496299744
Validation loss: 2.0799261113648773

Epoch: 294| Step: 0
Training loss: 2.00350284576416
Validation loss: 2.075820968997094

Epoch: 6| Step: 1
Training loss: 2.4900059700012207
Validation loss: 2.077113487387216

Epoch: 6| Step: 2
Training loss: 1.5673125982284546
Validation loss: 2.0967476996042396

Epoch: 6| Step: 3
Training loss: 2.02758526802063
Validation loss: 2.1029256107986614

Epoch: 6| Step: 4
Training loss: 2.155190944671631
Validation loss: 2.0909299158280894

Epoch: 6| Step: 5
Training loss: 2.663273334503174
Validation loss: 2.101227121968423

Epoch: 6| Step: 6
Training loss: 2.0592856407165527
Validation loss: 2.0770407184477775

Epoch: 6| Step: 7
Training loss: 1.7719390392303467
Validation loss: 2.0943608771088305

Epoch: 6| Step: 8
Training loss: 1.7646089792251587
Validation loss: 2.081060504400602

Epoch: 6| Step: 9
Training loss: 1.5851919651031494
Validation loss: 2.0881257339190413

Epoch: 6| Step: 10
Training loss: 1.0586888790130615
Validation loss: 2.0325101985726306

Epoch: 6| Step: 11
Training loss: 2.3894448280334473
Validation loss: 2.0478683223006544

Epoch: 6| Step: 12
Training loss: 1.9444319009780884
Validation loss: 2.057215722658301

Epoch: 6| Step: 13
Training loss: 2.7999472618103027
Validation loss: 2.055253246779083

Epoch: 295| Step: 0
Training loss: 1.75173020362854
Validation loss: 2.0734554785554127

Epoch: 6| Step: 1
Training loss: 2.2571396827697754
Validation loss: 2.0901688760326755

Epoch: 6| Step: 2
Training loss: 1.6805287599563599
Validation loss: 2.0941857650715816

Epoch: 6| Step: 3
Training loss: 1.6756173372268677
Validation loss: 2.107508069725447

Epoch: 6| Step: 4
Training loss: 2.39208984375
Validation loss: 2.07972655885963

Epoch: 6| Step: 5
Training loss: 1.9990417957305908
Validation loss: 2.0873473331492436

Epoch: 6| Step: 6
Training loss: 1.5530166625976562
Validation loss: 2.0432116382865497

Epoch: 6| Step: 7
Training loss: 1.7629168033599854
Validation loss: 2.064165246102118

Epoch: 6| Step: 8
Training loss: 2.1218371391296387
Validation loss: 2.057382063199115

Epoch: 6| Step: 9
Training loss: 2.1500720977783203
Validation loss: 2.0961082186750186

Epoch: 6| Step: 10
Training loss: 1.9620909690856934
Validation loss: 2.0754367202840824

Epoch: 6| Step: 11
Training loss: 2.103060483932495
Validation loss: 2.102090729180203

Epoch: 6| Step: 12
Training loss: 2.0495877265930176
Validation loss: 2.085396146261564

Epoch: 6| Step: 13
Training loss: 2.3561620712280273
Validation loss: 2.0888768267887894

Epoch: 296| Step: 0
Training loss: 1.8842260837554932
Validation loss: 2.08672676035153

Epoch: 6| Step: 1
Training loss: 2.1243648529052734
Validation loss: 2.0914289079686648

Epoch: 6| Step: 2
Training loss: 2.405501365661621
Validation loss: 2.0726372964920534

Epoch: 6| Step: 3
Training loss: 2.006762742996216
Validation loss: 2.0661774245641564

Epoch: 6| Step: 4
Training loss: 1.754945993423462
Validation loss: 2.111328814619331

Epoch: 6| Step: 5
Training loss: 2.2351584434509277
Validation loss: 2.0778019364162157

Epoch: 6| Step: 6
Training loss: 2.6724438667297363
Validation loss: 2.0684015558611963

Epoch: 6| Step: 7
Training loss: 2.349231481552124
Validation loss: 2.085048388409358

Epoch: 6| Step: 8
Training loss: 2.3285470008850098
Validation loss: 2.1085778487625944

Epoch: 6| Step: 9
Training loss: 1.582605004310608
Validation loss: 2.10249428338902

Epoch: 6| Step: 10
Training loss: 1.8729774951934814
Validation loss: 2.087245689925327

Epoch: 6| Step: 11
Training loss: 1.6812989711761475
Validation loss: 2.0863746596920874

Epoch: 6| Step: 12
Training loss: 1.3169641494750977
Validation loss: 2.098691572425186

Epoch: 6| Step: 13
Training loss: 1.1849422454833984
Validation loss: 2.074612171419205

Epoch: 297| Step: 0
Training loss: 2.04764723777771
Validation loss: 2.081903874233205

Epoch: 6| Step: 1
Training loss: 2.6867008209228516
Validation loss: 2.073827143638365

Epoch: 6| Step: 2
Training loss: 2.0109052658081055
Validation loss: 2.1101685390677503

Epoch: 6| Step: 3
Training loss: 1.6810563802719116
Validation loss: 2.0715122556173675

Epoch: 6| Step: 4
Training loss: 1.832942247390747
Validation loss: 2.113180122067851

Epoch: 6| Step: 5
Training loss: 1.745338797569275
Validation loss: 2.0273127466119747

Epoch: 6| Step: 6
Training loss: 1.8170095682144165
Validation loss: 2.110638782542239

Epoch: 6| Step: 7
Training loss: 1.610520839691162
Validation loss: 2.068058721480831

Epoch: 6| Step: 8
Training loss: 2.143908977508545
Validation loss: 2.113726296732503

Epoch: 6| Step: 9
Training loss: 1.9917110204696655
Validation loss: 2.0784533408380326

Epoch: 6| Step: 10
Training loss: 1.9668678045272827
Validation loss: 2.0596890975070257

Epoch: 6| Step: 11
Training loss: 2.0979056358337402
Validation loss: 2.0962887220485236

Epoch: 6| Step: 12
Training loss: 1.6117173433303833
Validation loss: 2.067954978635234

Epoch: 6| Step: 13
Training loss: 2.572108030319214
Validation loss: 2.1056038102796

Epoch: 298| Step: 0
Training loss: 2.0127487182617188
Validation loss: 2.0752452714468843

Epoch: 6| Step: 1
Training loss: 1.3221323490142822
Validation loss: 2.106676850267636

Epoch: 6| Step: 2
Training loss: 2.4047813415527344
Validation loss: 2.0883509523125103

Epoch: 6| Step: 3
Training loss: 1.4731088876724243
Validation loss: 2.1005799334536315

Epoch: 6| Step: 4
Training loss: 2.029069423675537
Validation loss: 2.0998320361619354

Epoch: 6| Step: 5
Training loss: 1.537278413772583
Validation loss: 2.061659123307915

Epoch: 6| Step: 6
Training loss: 2.312234401702881
Validation loss: 2.059106371736014

Epoch: 6| Step: 7
Training loss: 1.8598048686981201
Validation loss: 2.0854483368576213

Epoch: 6| Step: 8
Training loss: 2.6371026039123535
Validation loss: 2.100116773318219

Epoch: 6| Step: 9
Training loss: 1.4867719411849976
Validation loss: 2.073985125428887

Epoch: 6| Step: 10
Training loss: 2.3319649696350098
Validation loss: 2.095041519852095

Epoch: 6| Step: 11
Training loss: 1.9967221021652222
Validation loss: 2.0776587109411917

Epoch: 6| Step: 12
Training loss: 2.5489330291748047
Validation loss: 2.0973184595825853

Epoch: 6| Step: 13
Training loss: 1.562942624092102
Validation loss: 2.0888686205751155

Epoch: 299| Step: 0
Training loss: 1.5234800577163696
Validation loss: 2.0774897554869294

Epoch: 6| Step: 1
Training loss: 1.9247113466262817
Validation loss: 2.0888282598987704

Epoch: 6| Step: 2
Training loss: 1.3543388843536377
Validation loss: 2.060599655233404

Epoch: 6| Step: 3
Training loss: 1.8411152362823486
Validation loss: 2.0850181169407342

Epoch: 6| Step: 4
Training loss: 2.4942057132720947
Validation loss: 2.0696792294902187

Epoch: 6| Step: 5
Training loss: 2.065704345703125
Validation loss: 2.0952417530039305

Epoch: 6| Step: 6
Training loss: 2.337813377380371
Validation loss: 2.0882777475541636

Epoch: 6| Step: 7
Training loss: 1.855003833770752
Validation loss: 2.0829165853479856

Epoch: 6| Step: 8
Training loss: 2.558206558227539
Validation loss: 2.110010024039976

Epoch: 6| Step: 9
Training loss: 1.6027162075042725
Validation loss: 2.089380213009414

Epoch: 6| Step: 10
Training loss: 1.5978684425354004
Validation loss: 2.0532508973152406

Epoch: 6| Step: 11
Training loss: 1.596554160118103
Validation loss: 2.070390732057633

Epoch: 6| Step: 12
Training loss: 2.1712512969970703
Validation loss: 2.0773073857830417

Epoch: 6| Step: 13
Training loss: 2.746351957321167
Validation loss: 2.0895770570283294

Epoch: 300| Step: 0
Training loss: 1.8066840171813965
Validation loss: 2.0740787598394577

Epoch: 6| Step: 1
Training loss: 1.8819366693496704
Validation loss: 2.093594633122926

Epoch: 6| Step: 2
Training loss: 2.6072444915771484
Validation loss: 2.0984344931058985

Epoch: 6| Step: 3
Training loss: 2.2383251190185547
Validation loss: 2.0911907944627988

Epoch: 6| Step: 4
Training loss: 1.4733308553695679
Validation loss: 2.091098106035622

Epoch: 6| Step: 5
Training loss: 2.5453972816467285
Validation loss: 2.111267405171548

Epoch: 6| Step: 6
Training loss: 1.333634853363037
Validation loss: 2.102360689511863

Epoch: 6| Step: 7
Training loss: 2.0112204551696777
Validation loss: 2.097755601329188

Epoch: 6| Step: 8
Training loss: 2.0887293815612793
Validation loss: 2.090298621885238

Epoch: 6| Step: 9
Training loss: 1.6924412250518799
Validation loss: 2.1147200433156823

Epoch: 6| Step: 10
Training loss: 1.165408968925476
Validation loss: 2.0998595927351262

Epoch: 6| Step: 11
Training loss: 2.872279167175293
Validation loss: 2.0880704220905097

Epoch: 6| Step: 12
Training loss: 2.1785736083984375
Validation loss: 2.084495787979454

Epoch: 6| Step: 13
Training loss: 1.2720109224319458
Validation loss: 2.0876728001461236

Epoch: 301| Step: 0
Training loss: 1.7325688600540161
Validation loss: 2.1207207069602063

Epoch: 6| Step: 1
Training loss: 2.030154228210449
Validation loss: 2.086264573117738

Epoch: 6| Step: 2
Training loss: 2.003147602081299
Validation loss: 2.0917795229983587

Epoch: 6| Step: 3
Training loss: 1.956074833869934
Validation loss: 2.0531767055552494

Epoch: 6| Step: 4
Training loss: 1.6496250629425049
Validation loss: 2.0640054569449475

Epoch: 6| Step: 5
Training loss: 2.103755474090576
Validation loss: 2.0877112214283278

Epoch: 6| Step: 6
Training loss: 1.793479084968567
Validation loss: 2.08048572591556

Epoch: 6| Step: 7
Training loss: 2.1687171459198
Validation loss: 2.0340679102046515

Epoch: 6| Step: 8
Training loss: 2.4119272232055664
Validation loss: 2.090000098751437

Epoch: 6| Step: 9
Training loss: 1.2890090942382812
Validation loss: 2.0655998119743924

Epoch: 6| Step: 10
Training loss: 1.8958611488342285
Validation loss: 2.0694183303463842

Epoch: 6| Step: 11
Training loss: 1.912038803100586
Validation loss: 2.082358237235777

Epoch: 6| Step: 12
Training loss: 2.4501278400421143
Validation loss: 2.0947589822994765

Epoch: 6| Step: 13
Training loss: 2.19449520111084
Validation loss: 2.089290890642392

Epoch: 302| Step: 0
Training loss: 2.218214511871338
Validation loss: 2.0526759163025887

Epoch: 6| Step: 1
Training loss: 1.5713412761688232
Validation loss: 2.1049619592646116

Epoch: 6| Step: 2
Training loss: 2.7712323665618896
Validation loss: 2.0608278500136508

Epoch: 6| Step: 3
Training loss: 1.4480568170547485
Validation loss: 2.0706072622729885

Epoch: 6| Step: 4
Training loss: 2.1355862617492676
Validation loss: 2.0913672139567714

Epoch: 6| Step: 5
Training loss: 2.6055808067321777
Validation loss: 2.055892841790312

Epoch: 6| Step: 6
Training loss: 2.0517396926879883
Validation loss: 2.062110888060703

Epoch: 6| Step: 7
Training loss: 2.071152687072754
Validation loss: 2.0972140245540167

Epoch: 6| Step: 8
Training loss: 1.6684017181396484
Validation loss: 2.0623151384374148

Epoch: 6| Step: 9
Training loss: 1.6805505752563477
Validation loss: 2.067341658376878

Epoch: 6| Step: 10
Training loss: 1.675397276878357
Validation loss: 2.110403140385946

Epoch: 6| Step: 11
Training loss: 1.9401135444641113
Validation loss: 2.0935324789375387

Epoch: 6| Step: 12
Training loss: 1.9708983898162842
Validation loss: 2.0879848849388862

Epoch: 6| Step: 13
Training loss: 1.1615219116210938
Validation loss: 2.0837184280477543

Epoch: 303| Step: 0
Training loss: 2.026535987854004
Validation loss: 2.068696937253398

Epoch: 6| Step: 1
Training loss: 1.4168500900268555
Validation loss: 2.06010300882401

Epoch: 6| Step: 2
Training loss: 2.3007588386535645
Validation loss: 2.0709904688660816

Epoch: 6| Step: 3
Training loss: 2.350703239440918
Validation loss: 2.047674637968822

Epoch: 6| Step: 4
Training loss: 1.740993618965149
Validation loss: 2.0453431375565065

Epoch: 6| Step: 5
Training loss: 1.2648749351501465
Validation loss: 2.088673669804809

Epoch: 6| Step: 6
Training loss: 2.2957849502563477
Validation loss: 2.0703314952952887

Epoch: 6| Step: 7
Training loss: 1.8785228729248047
Validation loss: 2.0872203893558954

Epoch: 6| Step: 8
Training loss: 1.4579827785491943
Validation loss: 2.10558307555414

Epoch: 6| Step: 9
Training loss: 2.1207544803619385
Validation loss: 2.0963463655082126

Epoch: 6| Step: 10
Training loss: 2.3051939010620117
Validation loss: 2.076906404187602

Epoch: 6| Step: 11
Training loss: 1.757997751235962
Validation loss: 2.081098764173446

Epoch: 6| Step: 12
Training loss: 2.4020767211914062
Validation loss: 2.09648101047803

Epoch: 6| Step: 13
Training loss: 1.9615857601165771
Validation loss: 2.0961183271100445

Epoch: 304| Step: 0
Training loss: 1.9821438789367676
Validation loss: 2.05210103014464

Epoch: 6| Step: 1
Training loss: 2.403386116027832
Validation loss: 2.06386084582216

Epoch: 6| Step: 2
Training loss: 2.0152640342712402
Validation loss: 2.085587038788744

Epoch: 6| Step: 3
Training loss: 1.8985118865966797
Validation loss: 2.057878314807851

Epoch: 6| Step: 4
Training loss: 1.9025462865829468
Validation loss: 2.087997095559233

Epoch: 6| Step: 5
Training loss: 2.355562210083008
Validation loss: 2.0763528218833347

Epoch: 6| Step: 6
Training loss: 1.723135232925415
Validation loss: 2.1199913999085784

Epoch: 6| Step: 7
Training loss: 2.4121813774108887
Validation loss: 2.082553143142372

Epoch: 6| Step: 8
Training loss: 2.0600242614746094
Validation loss: 2.1227483877571682

Epoch: 6| Step: 9
Training loss: 1.3098421096801758
Validation loss: 2.0771650140003493

Epoch: 6| Step: 10
Training loss: 1.6468838453292847
Validation loss: 2.091047033186882

Epoch: 6| Step: 11
Training loss: 1.8622369766235352
Validation loss: 2.1081588217007217

Epoch: 6| Step: 12
Training loss: 2.5683932304382324
Validation loss: 2.090331619785678

Epoch: 6| Step: 13
Training loss: 1.0588308572769165
Validation loss: 2.0976316441771803

Epoch: 305| Step: 0
Training loss: 1.6685025691986084
Validation loss: 2.0716116069465556

Epoch: 6| Step: 1
Training loss: 2.1574409008026123
Validation loss: 2.0732589050005843

Epoch: 6| Step: 2
Training loss: 2.247990846633911
Validation loss: 2.1141783088766117

Epoch: 6| Step: 3
Training loss: 2.0805675983428955
Validation loss: 2.095902837732787

Epoch: 6| Step: 4
Training loss: 1.6863938570022583
Validation loss: 2.042117985345984

Epoch: 6| Step: 5
Training loss: 2.4370875358581543
Validation loss: 2.066162481102892

Epoch: 6| Step: 6
Training loss: 2.063772201538086
Validation loss: 2.082307081068716

Epoch: 6| Step: 7
Training loss: 1.6565723419189453
Validation loss: 2.0775222304046794

Epoch: 6| Step: 8
Training loss: 1.6067227125167847
Validation loss: 2.0605597290941464

Epoch: 6| Step: 9
Training loss: 2.342860460281372
Validation loss: 2.0627627885469826

Epoch: 6| Step: 10
Training loss: 1.869567632675171
Validation loss: 2.0716995116203063

Epoch: 6| Step: 11
Training loss: 1.6729934215545654
Validation loss: 2.0587148461290585

Epoch: 6| Step: 12
Training loss: 2.0563132762908936
Validation loss: 2.082925218407826

Epoch: 6| Step: 13
Training loss: 2.1614205837249756
Validation loss: 2.063628109552527

Epoch: 306| Step: 0
Training loss: 1.6799626350402832
Validation loss: 2.078600578410651

Epoch: 6| Step: 1
Training loss: 1.6602445840835571
Validation loss: 2.06497162131853

Epoch: 6| Step: 2
Training loss: 2.390563726425171
Validation loss: 2.047326385333974

Epoch: 6| Step: 3
Training loss: 1.4789518117904663
Validation loss: 2.060527193930841

Epoch: 6| Step: 4
Training loss: 2.5450329780578613
Validation loss: 2.0800534473952426

Epoch: 6| Step: 5
Training loss: 1.3505725860595703
Validation loss: 2.051961455293881

Epoch: 6| Step: 6
Training loss: 2.312129020690918
Validation loss: 2.0505035154281126

Epoch: 6| Step: 7
Training loss: 1.8565278053283691
Validation loss: 2.0756169160207114

Epoch: 6| Step: 8
Training loss: 1.7779885530471802
Validation loss: 2.069765570343182

Epoch: 6| Step: 9
Training loss: 2.1419053077697754
Validation loss: 2.0898699016981226

Epoch: 6| Step: 10
Training loss: 2.190042018890381
Validation loss: 2.072963321080772

Epoch: 6| Step: 11
Training loss: 2.0208239555358887
Validation loss: 2.079673619680507

Epoch: 6| Step: 12
Training loss: 1.9238502979278564
Validation loss: 2.0513204220802552

Epoch: 6| Step: 13
Training loss: 1.8579362630844116
Validation loss: 2.095664967772781

Epoch: 307| Step: 0
Training loss: 1.3940221071243286
Validation loss: 2.0581698943209905

Epoch: 6| Step: 1
Training loss: 2.666728973388672
Validation loss: 2.0490937489335255

Epoch: 6| Step: 2
Training loss: 2.164125919342041
Validation loss: 2.091729567896935

Epoch: 6| Step: 3
Training loss: 1.1696089506149292
Validation loss: 2.0895677945947133

Epoch: 6| Step: 4
Training loss: 1.6120305061340332
Validation loss: 2.0693423927471204

Epoch: 6| Step: 5
Training loss: 1.234199047088623
Validation loss: 2.041556001991354

Epoch: 6| Step: 6
Training loss: 2.8291001319885254
Validation loss: 2.0766005490415838

Epoch: 6| Step: 7
Training loss: 1.8544251918792725
Validation loss: 2.0588422770141275

Epoch: 6| Step: 8
Training loss: 1.667909860610962
Validation loss: 2.085156540716848

Epoch: 6| Step: 9
Training loss: 2.1297810077667236
Validation loss: 2.0944842305234683

Epoch: 6| Step: 10
Training loss: 2.162659168243408
Validation loss: 2.102010456464624

Epoch: 6| Step: 11
Training loss: 2.037273645401001
Validation loss: 2.089690669890373

Epoch: 6| Step: 12
Training loss: 2.469686985015869
Validation loss: 2.069361694397465

Epoch: 6| Step: 13
Training loss: 1.7401856184005737
Validation loss: 2.0677695992172405

Epoch: 308| Step: 0
Training loss: 1.6171928644180298
Validation loss: 2.0854559624066917

Epoch: 6| Step: 1
Training loss: 2.1560473442077637
Validation loss: 2.102858909996607

Epoch: 6| Step: 2
Training loss: 1.7174451351165771
Validation loss: 2.074575121684741

Epoch: 6| Step: 3
Training loss: 2.5179576873779297
Validation loss: 2.084332778889646

Epoch: 6| Step: 4
Training loss: 2.0470399856567383
Validation loss: 2.0573888030103458

Epoch: 6| Step: 5
Training loss: 1.8398245573043823
Validation loss: 2.0801908636605866

Epoch: 6| Step: 6
Training loss: 1.9058268070220947
Validation loss: 2.086306219459862

Epoch: 6| Step: 7
Training loss: 2.1239655017852783
Validation loss: 2.085443050630631

Epoch: 6| Step: 8
Training loss: 1.2444764375686646
Validation loss: 2.077372802201138

Epoch: 6| Step: 9
Training loss: 1.8527183532714844
Validation loss: 2.06788319541562

Epoch: 6| Step: 10
Training loss: 2.188595771789551
Validation loss: 2.0657328046778196

Epoch: 6| Step: 11
Training loss: 2.560486078262329
Validation loss: 2.084633875918645

Epoch: 6| Step: 12
Training loss: 1.6920210123062134
Validation loss: 2.0630443890889487

Epoch: 6| Step: 13
Training loss: 2.0702579021453857
Validation loss: 2.0652395243285806

Epoch: 309| Step: 0
Training loss: 2.496455192565918
Validation loss: 2.085920456917055

Epoch: 6| Step: 1
Training loss: 2.320080518722534
Validation loss: 2.0884988179770847

Epoch: 6| Step: 2
Training loss: 2.1485586166381836
Validation loss: 2.094529946645101

Epoch: 6| Step: 3
Training loss: 1.6687520742416382
Validation loss: 2.0642823608972694

Epoch: 6| Step: 4
Training loss: 1.496995449066162
Validation loss: 2.0931003760266047

Epoch: 6| Step: 5
Training loss: 2.1567487716674805
Validation loss: 2.0764225452176985

Epoch: 6| Step: 6
Training loss: 1.950497031211853
Validation loss: 2.0774392799664567

Epoch: 6| Step: 7
Training loss: 1.5041654109954834
Validation loss: 2.1069375238110943

Epoch: 6| Step: 8
Training loss: 1.8992056846618652
Validation loss: 2.0642679763096634

Epoch: 6| Step: 9
Training loss: 1.8518877029418945
Validation loss: 2.1037592067513415

Epoch: 6| Step: 10
Training loss: 2.6192378997802734
Validation loss: 2.078046820497

Epoch: 6| Step: 11
Training loss: 2.177527904510498
Validation loss: 2.101041196494974

Epoch: 6| Step: 12
Training loss: 1.4323800802230835
Validation loss: 2.0849166249716156

Epoch: 6| Step: 13
Training loss: 0.9922525882720947
Validation loss: 2.0973934909348846

Epoch: 310| Step: 0
Training loss: 1.7405614852905273
Validation loss: 2.088788050477223

Epoch: 6| Step: 1
Training loss: 2.225634813308716
Validation loss: 2.112836394258725

Epoch: 6| Step: 2
Training loss: 1.5200002193450928
Validation loss: 2.093988431397305

Epoch: 6| Step: 3
Training loss: 1.8148884773254395
Validation loss: 2.0903561551083802

Epoch: 6| Step: 4
Training loss: 2.299816846847534
Validation loss: 2.0842522498100036

Epoch: 6| Step: 5
Training loss: 1.606783390045166
Validation loss: 2.078537312887048

Epoch: 6| Step: 6
Training loss: 1.8286750316619873
Validation loss: 2.1137823673986618

Epoch: 6| Step: 7
Training loss: 2.095978260040283
Validation loss: 2.0864319955149004

Epoch: 6| Step: 8
Training loss: 2.1852848529815674
Validation loss: 2.065249361017699

Epoch: 6| Step: 9
Training loss: 2.352417230606079
Validation loss: 2.0672567916172806

Epoch: 6| Step: 10
Training loss: 1.7937073707580566
Validation loss: 2.06305443856024

Epoch: 6| Step: 11
Training loss: 1.8002451658248901
Validation loss: 2.1051714266500166

Epoch: 6| Step: 12
Training loss: 1.5962283611297607
Validation loss: 2.0958776038180114

Epoch: 6| Step: 13
Training loss: 2.37032151222229
Validation loss: 2.0383878805304088

Epoch: 311| Step: 0
Training loss: 1.914282202720642
Validation loss: 2.0735872817295853

Epoch: 6| Step: 1
Training loss: 2.4329001903533936
Validation loss: 2.0696962469367572

Epoch: 6| Step: 2
Training loss: 1.5449345111846924
Validation loss: 2.0973265376142276

Epoch: 6| Step: 3
Training loss: 2.2233963012695312
Validation loss: 2.060698760453091

Epoch: 6| Step: 4
Training loss: 2.120997428894043
Validation loss: 2.082319091725093

Epoch: 6| Step: 5
Training loss: 1.5394678115844727
Validation loss: 2.080147594533941

Epoch: 6| Step: 6
Training loss: 1.9063371419906616
Validation loss: 2.0762581504801267

Epoch: 6| Step: 7
Training loss: 1.5606167316436768
Validation loss: 2.05782046369327

Epoch: 6| Step: 8
Training loss: 2.4339661598205566
Validation loss: 2.093394184625277

Epoch: 6| Step: 9
Training loss: 2.0756027698516846
Validation loss: 2.101796115598371

Epoch: 6| Step: 10
Training loss: 1.514899492263794
Validation loss: 2.0763399549709853

Epoch: 6| Step: 11
Training loss: 2.216801404953003
Validation loss: 2.084173035878007

Epoch: 6| Step: 12
Training loss: 1.472205638885498
Validation loss: 2.081748939329578

Epoch: 6| Step: 13
Training loss: 2.027337074279785
Validation loss: 2.0884186067888812

Epoch: 312| Step: 0
Training loss: 2.0678153038024902
Validation loss: 2.1069701871564313

Epoch: 6| Step: 1
Training loss: 2.6699655055999756
Validation loss: 2.115322874438378

Epoch: 6| Step: 2
Training loss: 1.479909896850586
Validation loss: 2.135342518488566

Epoch: 6| Step: 3
Training loss: 1.6702959537506104
Validation loss: 2.066333834842969

Epoch: 6| Step: 4
Training loss: 1.5755071640014648
Validation loss: 2.0529573566170147

Epoch: 6| Step: 5
Training loss: 1.6654565334320068
Validation loss: 2.0787182854067896

Epoch: 6| Step: 6
Training loss: 2.804164409637451
Validation loss: 2.0893124893147457

Epoch: 6| Step: 7
Training loss: 2.0099804401397705
Validation loss: 2.0850166069564

Epoch: 6| Step: 8
Training loss: 1.1845428943634033
Validation loss: 2.125612453747821

Epoch: 6| Step: 9
Training loss: 2.3056890964508057
Validation loss: 2.1145140611997215

Epoch: 6| Step: 10
Training loss: 1.7425706386566162
Validation loss: 2.1028585485232774

Epoch: 6| Step: 11
Training loss: 1.5837364196777344
Validation loss: 2.1390107139464347

Epoch: 6| Step: 12
Training loss: 2.005507707595825
Validation loss: 2.1006795052559144

Epoch: 6| Step: 13
Training loss: 2.3904106616973877
Validation loss: 2.1022456845929547

Epoch: 313| Step: 0
Training loss: 1.9143401384353638
Validation loss: 2.097891387119088

Epoch: 6| Step: 1
Training loss: 2.2639496326446533
Validation loss: 2.111606741464266

Epoch: 6| Step: 2
Training loss: 1.7342123985290527
Validation loss: 2.0897321111412457

Epoch: 6| Step: 3
Training loss: 2.36104154586792
Validation loss: 2.0805378754933677

Epoch: 6| Step: 4
Training loss: 1.7599278688430786
Validation loss: 2.0782832817364763

Epoch: 6| Step: 5
Training loss: 1.5359182357788086
Validation loss: 2.1018777713980725

Epoch: 6| Step: 6
Training loss: 2.3270368576049805
Validation loss: 2.1055929840251966

Epoch: 6| Step: 7
Training loss: 1.9819313287734985
Validation loss: 2.078482324077237

Epoch: 6| Step: 8
Training loss: 1.2570698261260986
Validation loss: 2.0949051226339033

Epoch: 6| Step: 9
Training loss: 1.7871496677398682
Validation loss: 2.089639967487704

Epoch: 6| Step: 10
Training loss: 1.514878749847412
Validation loss: 2.0966186779801563

Epoch: 6| Step: 11
Training loss: 2.244105100631714
Validation loss: 2.0806176585535847

Epoch: 6| Step: 12
Training loss: 2.3356733322143555
Validation loss: 2.0731491529813377

Epoch: 6| Step: 13
Training loss: 2.6461336612701416
Validation loss: 2.1078068671687955

Epoch: 314| Step: 0
Training loss: 1.7276198863983154
Validation loss: 2.0711405725889307

Epoch: 6| Step: 1
Training loss: 2.188075542449951
Validation loss: 2.0685089993220505

Epoch: 6| Step: 2
Training loss: 1.5880697965621948
Validation loss: 2.076660510032408

Epoch: 6| Step: 3
Training loss: 2.032322883605957
Validation loss: 2.0660006077058855

Epoch: 6| Step: 4
Training loss: 2.470836639404297
Validation loss: 2.063956770845639

Epoch: 6| Step: 5
Training loss: 1.2667763233184814
Validation loss: 2.047368079103449

Epoch: 6| Step: 6
Training loss: 1.8106181621551514
Validation loss: 2.0752774592368834

Epoch: 6| Step: 7
Training loss: 2.0152876377105713
Validation loss: 2.076819917207123

Epoch: 6| Step: 8
Training loss: 1.7087756395339966
Validation loss: 2.0757699012756348

Epoch: 6| Step: 9
Training loss: 1.9373059272766113
Validation loss: 2.099058699864213

Epoch: 6| Step: 10
Training loss: 2.351768970489502
Validation loss: 2.065183421616913

Epoch: 6| Step: 11
Training loss: 1.8940110206604004
Validation loss: 2.077746368223621

Epoch: 6| Step: 12
Training loss: 1.9083070755004883
Validation loss: 2.0785886920908445

Epoch: 6| Step: 13
Training loss: 1.73582923412323
Validation loss: 2.0792353294228993

Epoch: 315| Step: 0
Training loss: 2.53584623336792
Validation loss: 2.1139289640611216

Epoch: 6| Step: 1
Training loss: 2.1032838821411133
Validation loss: 2.0557723865714124

Epoch: 6| Step: 2
Training loss: 2.6429224014282227
Validation loss: 2.0923402027417253

Epoch: 6| Step: 3
Training loss: 1.5651261806488037
Validation loss: 2.088609769780149

Epoch: 6| Step: 4
Training loss: 1.8376235961914062
Validation loss: 2.0989057005092664

Epoch: 6| Step: 5
Training loss: 2.0205159187316895
Validation loss: 2.123627954913724

Epoch: 6| Step: 6
Training loss: 1.8542847633361816
Validation loss: 2.1215406515265025

Epoch: 6| Step: 7
Training loss: 1.4140233993530273
Validation loss: 2.1046265684148318

Epoch: 6| Step: 8
Training loss: 2.2319793701171875
Validation loss: 2.133573116794709

Epoch: 6| Step: 9
Training loss: 1.8056405782699585
Validation loss: 2.1031259977689354

Epoch: 6| Step: 10
Training loss: 1.257380723953247
Validation loss: 2.1052699524869203

Epoch: 6| Step: 11
Training loss: 1.720741868019104
Validation loss: 2.0729109574389715

Epoch: 6| Step: 12
Training loss: 1.636542558670044
Validation loss: 2.1247687544873965

Epoch: 6| Step: 13
Training loss: 2.563717842102051
Validation loss: 2.1102737534430718

Epoch: 316| Step: 0
Training loss: 1.4126806259155273
Validation loss: 2.084715043344805

Epoch: 6| Step: 1
Training loss: 1.5750267505645752
Validation loss: 2.0799440824857323

Epoch: 6| Step: 2
Training loss: 1.2797425985336304
Validation loss: 2.0640260378519693

Epoch: 6| Step: 3
Training loss: 1.842771291732788
Validation loss: 2.0889487830541467

Epoch: 6| Step: 4
Training loss: 1.5282814502716064
Validation loss: 2.0561110383720806

Epoch: 6| Step: 5
Training loss: 2.0316500663757324
Validation loss: 2.072915842456202

Epoch: 6| Step: 6
Training loss: 2.5984883308410645
Validation loss: 2.0592993190211635

Epoch: 6| Step: 7
Training loss: 2.0595436096191406
Validation loss: 2.072901733459965

Epoch: 6| Step: 8
Training loss: 2.118175506591797
Validation loss: 2.0584530292018766

Epoch: 6| Step: 9
Training loss: 2.6851069927215576
Validation loss: 2.077109738062787

Epoch: 6| Step: 10
Training loss: 2.0659291744232178
Validation loss: 2.0585978684886808

Epoch: 6| Step: 11
Training loss: 2.283435344696045
Validation loss: 2.0852951208750405

Epoch: 6| Step: 12
Training loss: 2.192946434020996
Validation loss: 2.0860141810550483

Epoch: 6| Step: 13
Training loss: 1.5876353979110718
Validation loss: 2.0630736786832093

Epoch: 317| Step: 0
Training loss: 1.9389853477478027
Validation loss: 2.063479681168833

Epoch: 6| Step: 1
Training loss: 2.016326427459717
Validation loss: 2.092257813740802

Epoch: 6| Step: 2
Training loss: 1.802577257156372
Validation loss: 2.1052176695997997

Epoch: 6| Step: 3
Training loss: 2.144566774368286
Validation loss: 2.0388777666194464

Epoch: 6| Step: 4
Training loss: 2.184889793395996
Validation loss: 2.0723466514259257

Epoch: 6| Step: 5
Training loss: 2.2526018619537354
Validation loss: 2.061013421704692

Epoch: 6| Step: 6
Training loss: 2.253499984741211
Validation loss: 2.085596071776523

Epoch: 6| Step: 7
Training loss: 2.38671875
Validation loss: 2.0729429311649774

Epoch: 6| Step: 8
Training loss: 1.5581527948379517
Validation loss: 2.094576676686605

Epoch: 6| Step: 9
Training loss: 1.5289528369903564
Validation loss: 2.074633358627237

Epoch: 6| Step: 10
Training loss: 1.7762069702148438
Validation loss: 2.0896112047215945

Epoch: 6| Step: 11
Training loss: 2.0956289768218994
Validation loss: 2.1161658276793776

Epoch: 6| Step: 12
Training loss: 1.3111830949783325
Validation loss: 2.097123884385632

Epoch: 6| Step: 13
Training loss: 1.6028109788894653
Validation loss: 2.0593649289941274

Epoch: 318| Step: 0
Training loss: 1.8346855640411377
Validation loss: 2.0895019910668813

Epoch: 6| Step: 1
Training loss: 2.4368531703948975
Validation loss: 2.090640578218686

Epoch: 6| Step: 2
Training loss: 1.6227636337280273
Validation loss: 2.087996693067653

Epoch: 6| Step: 3
Training loss: 2.9678120613098145
Validation loss: 2.075490072209348

Epoch: 6| Step: 4
Training loss: 1.724429965019226
Validation loss: 2.1065045838714926

Epoch: 6| Step: 5
Training loss: 1.6443836688995361
Validation loss: 2.0859270659826135

Epoch: 6| Step: 6
Training loss: 1.75846529006958
Validation loss: 2.1036387951143327

Epoch: 6| Step: 7
Training loss: 2.0827205181121826
Validation loss: 2.1262642811703425

Epoch: 6| Step: 8
Training loss: 1.7852866649627686
Validation loss: 2.077021063015025

Epoch: 6| Step: 9
Training loss: 1.835484504699707
Validation loss: 2.114120153970616

Epoch: 6| Step: 10
Training loss: 1.9063148498535156
Validation loss: 2.0749473828141407

Epoch: 6| Step: 11
Training loss: 1.9015228748321533
Validation loss: 2.073920340948207

Epoch: 6| Step: 12
Training loss: 1.4843863248825073
Validation loss: 2.071200780971076

Epoch: 6| Step: 13
Training loss: 1.6422405242919922
Validation loss: 2.0606118107354767

Epoch: 319| Step: 0
Training loss: 1.3811089992523193
Validation loss: 2.0624223473251506

Epoch: 6| Step: 1
Training loss: 2.434706926345825
Validation loss: 2.0780608448930966

Epoch: 6| Step: 2
Training loss: 2.3935251235961914
Validation loss: 2.1260177602050123

Epoch: 6| Step: 3
Training loss: 2.1314549446105957
Validation loss: 2.060282794378137

Epoch: 6| Step: 4
Training loss: 1.6392571926116943
Validation loss: 2.069251980832828

Epoch: 6| Step: 5
Training loss: 1.5941624641418457
Validation loss: 2.043840282706804

Epoch: 6| Step: 6
Training loss: 1.496764898300171
Validation loss: 2.103956135370398

Epoch: 6| Step: 7
Training loss: 2.19417142868042
Validation loss: 2.0872456553161784

Epoch: 6| Step: 8
Training loss: 1.3693833351135254
Validation loss: 2.0627503510444396

Epoch: 6| Step: 9
Training loss: 1.7551236152648926
Validation loss: 2.0769246137270363

Epoch: 6| Step: 10
Training loss: 1.5929330587387085
Validation loss: 2.0541479408100085

Epoch: 6| Step: 11
Training loss: 2.5928616523742676
Validation loss: 2.0963244630444433

Epoch: 6| Step: 12
Training loss: 2.470015525817871
Validation loss: 2.0795085276326826

Epoch: 6| Step: 13
Training loss: 1.9739354848861694
Validation loss: 2.077782784738848

Epoch: 320| Step: 0
Training loss: 1.5559310913085938
Validation loss: 2.0749122622192546

Epoch: 6| Step: 1
Training loss: 1.6128287315368652
Validation loss: 2.114235164016806

Epoch: 6| Step: 2
Training loss: 1.9884690046310425
Validation loss: 2.0421974402602

Epoch: 6| Step: 3
Training loss: 2.3253073692321777
Validation loss: 2.131050402118314

Epoch: 6| Step: 4
Training loss: 2.399643898010254
Validation loss: 2.0713439718369515

Epoch: 6| Step: 5
Training loss: 2.326056480407715
Validation loss: 2.104850402442358

Epoch: 6| Step: 6
Training loss: 2.6482627391815186
Validation loss: 2.103158886714648

Epoch: 6| Step: 7
Training loss: 1.1113460063934326
Validation loss: 2.117332108559147

Epoch: 6| Step: 8
Training loss: 1.8391906023025513
Validation loss: 2.0966888063697406

Epoch: 6| Step: 9
Training loss: 2.0590810775756836
Validation loss: 2.10790273322854

Epoch: 6| Step: 10
Training loss: 1.3932703733444214
Validation loss: 2.11938726773826

Epoch: 6| Step: 11
Training loss: 1.5083178281784058
Validation loss: 2.115340655849826

Epoch: 6| Step: 12
Training loss: 1.659960389137268
Validation loss: 2.1159563859303794

Epoch: 6| Step: 13
Training loss: 2.9403445720672607
Validation loss: 2.0857676357351322

Epoch: 321| Step: 0
Training loss: 1.3732964992523193
Validation loss: 2.1196910847899733

Epoch: 6| Step: 1
Training loss: 1.8952124118804932
Validation loss: 2.1602428625988703

Epoch: 6| Step: 2
Training loss: 1.7836313247680664
Validation loss: 2.0802574234624065

Epoch: 6| Step: 3
Training loss: 1.9846525192260742
Validation loss: 2.0612027645111084

Epoch: 6| Step: 4
Training loss: 1.7381598949432373
Validation loss: 2.1168074146393807

Epoch: 6| Step: 5
Training loss: 1.8966360092163086
Validation loss: 2.1062648629629486

Epoch: 6| Step: 6
Training loss: 2.45200514793396
Validation loss: 2.08930960265539

Epoch: 6| Step: 7
Training loss: 2.166201114654541
Validation loss: 2.0780259050348753

Epoch: 6| Step: 8
Training loss: 2.678919792175293
Validation loss: 2.1078131519338137

Epoch: 6| Step: 9
Training loss: 1.8242794275283813
Validation loss: 2.0504803349894862

Epoch: 6| Step: 10
Training loss: 2.296599864959717
Validation loss: 2.0684350152169504

Epoch: 6| Step: 11
Training loss: 1.2663464546203613
Validation loss: 2.0967911315220658

Epoch: 6| Step: 12
Training loss: 1.630707025527954
Validation loss: 2.0480389928305023

Epoch: 6| Step: 13
Training loss: 2.6300549507141113
Validation loss: 2.090991694440124

Epoch: 322| Step: 0
Training loss: 2.0508551597595215
Validation loss: 2.097704654098839

Epoch: 6| Step: 1
Training loss: 2.0787346363067627
Validation loss: 2.100829649997014

Epoch: 6| Step: 2
Training loss: 1.8082530498504639
Validation loss: 2.0980944838575137

Epoch: 6| Step: 3
Training loss: 2.077882766723633
Validation loss: 2.0735084946437548

Epoch: 6| Step: 4
Training loss: 2.8445303440093994
Validation loss: 2.0739983115144955

Epoch: 6| Step: 5
Training loss: 1.6995456218719482
Validation loss: 2.0587842105537333

Epoch: 6| Step: 6
Training loss: 1.8775545358657837
Validation loss: 2.0704534361439366

Epoch: 6| Step: 7
Training loss: 1.4132193326950073
Validation loss: 2.0696339427783923

Epoch: 6| Step: 8
Training loss: 1.9341943264007568
Validation loss: 2.0780977767000914

Epoch: 6| Step: 9
Training loss: 1.435190200805664
Validation loss: 2.103229384268484

Epoch: 6| Step: 10
Training loss: 2.0182313919067383
Validation loss: 2.071105695539905

Epoch: 6| Step: 11
Training loss: 2.1491143703460693
Validation loss: 2.0585952369115685

Epoch: 6| Step: 12
Training loss: 2.118704080581665
Validation loss: 2.0978299058893675

Epoch: 6| Step: 13
Training loss: 0.832332968711853
Validation loss: 2.104635324529422

Epoch: 323| Step: 0
Training loss: 2.415609359741211
Validation loss: 2.0933013116159747

Epoch: 6| Step: 1
Training loss: 2.176574230194092
Validation loss: 2.0892361389693392

Epoch: 6| Step: 2
Training loss: 1.8992195129394531
Validation loss: 2.0563784427540277

Epoch: 6| Step: 3
Training loss: 1.6762208938598633
Validation loss: 2.091054959963727

Epoch: 6| Step: 4
Training loss: 1.4273874759674072
Validation loss: 2.078943271790781

Epoch: 6| Step: 5
Training loss: 1.6855597496032715
Validation loss: 2.103259322463825

Epoch: 6| Step: 6
Training loss: 1.719612956047058
Validation loss: 2.104531744475006

Epoch: 6| Step: 7
Training loss: 2.075561046600342
Validation loss: 2.099280849579842

Epoch: 6| Step: 8
Training loss: 2.3908934593200684
Validation loss: 2.0691938964269494

Epoch: 6| Step: 9
Training loss: 1.9906662702560425
Validation loss: 2.1123863368906

Epoch: 6| Step: 10
Training loss: 2.1014533042907715
Validation loss: 2.1191094754844584

Epoch: 6| Step: 11
Training loss: 1.1526355743408203
Validation loss: 2.0950824855476298

Epoch: 6| Step: 12
Training loss: 2.0740952491760254
Validation loss: 2.097823607024326

Epoch: 6| Step: 13
Training loss: 2.3728342056274414
Validation loss: 2.1113578068312777

Epoch: 324| Step: 0
Training loss: 1.9160643815994263
Validation loss: 2.076982336659585

Epoch: 6| Step: 1
Training loss: 1.9262008666992188
Validation loss: 2.0655759431982554

Epoch: 6| Step: 2
Training loss: 1.8942933082580566
Validation loss: 2.0786182854765203

Epoch: 6| Step: 3
Training loss: 1.3437789678573608
Validation loss: 2.0681529301469044

Epoch: 6| Step: 4
Training loss: 2.5190842151641846
Validation loss: 2.0765776993125997

Epoch: 6| Step: 5
Training loss: 2.349497079849243
Validation loss: 2.0556738914981967

Epoch: 6| Step: 6
Training loss: 2.1569621562957764
Validation loss: 2.0821407520642845

Epoch: 6| Step: 7
Training loss: 1.825980305671692
Validation loss: 2.08467327010247

Epoch: 6| Step: 8
Training loss: 2.0365185737609863
Validation loss: 2.073634937245359

Epoch: 6| Step: 9
Training loss: 1.5379855632781982
Validation loss: 2.073247435272381

Epoch: 6| Step: 10
Training loss: 1.4794319868087769
Validation loss: 2.11793226708648

Epoch: 6| Step: 11
Training loss: 1.8555569648742676
Validation loss: 2.0995638806332826

Epoch: 6| Step: 12
Training loss: 2.045471429824829
Validation loss: 2.111039903856093

Epoch: 6| Step: 13
Training loss: 1.7690280675888062
Validation loss: 2.0776927778797765

Epoch: 325| Step: 0
Training loss: 1.184836745262146
Validation loss: 2.0619098089074575

Epoch: 6| Step: 1
Training loss: 2.131260395050049
Validation loss: 2.101735386797177

Epoch: 6| Step: 2
Training loss: 1.6826765537261963
Validation loss: 2.0759749079263337

Epoch: 6| Step: 3
Training loss: 2.246185779571533
Validation loss: 2.075542116677889

Epoch: 6| Step: 4
Training loss: 2.440667152404785
Validation loss: 2.097496591588502

Epoch: 6| Step: 5
Training loss: 2.1476874351501465
Validation loss: 2.1052066869633173

Epoch: 6| Step: 6
Training loss: 2.194983959197998
Validation loss: 2.074457346752126

Epoch: 6| Step: 7
Training loss: 1.688294768333435
Validation loss: 2.095178992517533

Epoch: 6| Step: 8
Training loss: 1.8494030237197876
Validation loss: 2.058926707954817

Epoch: 6| Step: 9
Training loss: 1.280593752861023
Validation loss: 2.0432285365237983

Epoch: 6| Step: 10
Training loss: 1.9914021492004395
Validation loss: 2.101548546104021

Epoch: 6| Step: 11
Training loss: 1.7202301025390625
Validation loss: 2.0881931704859578

Epoch: 6| Step: 12
Training loss: 1.520850658416748
Validation loss: 2.0838694110993417

Epoch: 6| Step: 13
Training loss: 2.48050856590271
Validation loss: 2.09334332840417

Epoch: 326| Step: 0
Training loss: 1.57735276222229
Validation loss: 2.0867898643657727

Epoch: 6| Step: 1
Training loss: 1.8511228561401367
Validation loss: 2.0873025078927316

Epoch: 6| Step: 2
Training loss: 2.3748154640197754
Validation loss: 2.1191386099784606

Epoch: 6| Step: 3
Training loss: 1.2331870794296265
Validation loss: 2.0772440356592976

Epoch: 6| Step: 4
Training loss: 1.8219047784805298
Validation loss: 2.101180935418734

Epoch: 6| Step: 5
Training loss: 2.2071585655212402
Validation loss: 2.072224514458769

Epoch: 6| Step: 6
Training loss: 2.063917636871338
Validation loss: 2.09731795454538

Epoch: 6| Step: 7
Training loss: 1.6128568649291992
Validation loss: 2.060623122799781

Epoch: 6| Step: 8
Training loss: 2.0393404960632324
Validation loss: 2.0825719064281834

Epoch: 6| Step: 9
Training loss: 2.0854411125183105
Validation loss: 2.107426372907495

Epoch: 6| Step: 10
Training loss: 1.8785393238067627
Validation loss: 2.136045407223445

Epoch: 6| Step: 11
Training loss: 1.9447675943374634
Validation loss: 2.1003383949238765

Epoch: 6| Step: 12
Training loss: 2.084315061569214
Validation loss: 2.0738007330125376

Epoch: 6| Step: 13
Training loss: 1.6471121311187744
Validation loss: 2.099934152377549

Epoch: 327| Step: 0
Training loss: 1.8515329360961914
Validation loss: 2.101676159007575

Epoch: 6| Step: 1
Training loss: 1.9929436445236206
Validation loss: 2.111622784727363

Epoch: 6| Step: 2
Training loss: 1.8685837984085083
Validation loss: 2.110264966564794

Epoch: 6| Step: 3
Training loss: 1.430903673171997
Validation loss: 2.0983631149415047

Epoch: 6| Step: 4
Training loss: 2.015592098236084
Validation loss: 2.0850087711887975

Epoch: 6| Step: 5
Training loss: 2.210383892059326
Validation loss: 2.078402829426591

Epoch: 6| Step: 6
Training loss: 2.1497769355773926
Validation loss: 2.068688980994686

Epoch: 6| Step: 7
Training loss: 1.5848431587219238
Validation loss: 2.0768409159875687

Epoch: 6| Step: 8
Training loss: 1.3889812231063843
Validation loss: 2.057568306564003

Epoch: 6| Step: 9
Training loss: 2.340733766555786
Validation loss: 2.1021258523387294

Epoch: 6| Step: 10
Training loss: 1.8064435720443726
Validation loss: 2.0541035539360455

Epoch: 6| Step: 11
Training loss: 1.734582543373108
Validation loss: 2.095309647180701

Epoch: 6| Step: 12
Training loss: 1.807805061340332
Validation loss: 2.0764081708846556

Epoch: 6| Step: 13
Training loss: 3.192607879638672
Validation loss: 2.0939121553974767

Epoch: 328| Step: 0
Training loss: 1.6360960006713867
Validation loss: 2.076979537164011

Epoch: 6| Step: 1
Training loss: 1.9663225412368774
Validation loss: 2.1130259293381886

Epoch: 6| Step: 2
Training loss: 1.7720123529434204
Validation loss: 2.12980293971236

Epoch: 6| Step: 3
Training loss: 2.020967960357666
Validation loss: 2.098028254765336

Epoch: 6| Step: 4
Training loss: 1.7707631587982178
Validation loss: 2.088487030357443

Epoch: 6| Step: 5
Training loss: 1.9424189329147339
Validation loss: 2.0903192694469164

Epoch: 6| Step: 6
Training loss: 2.201197624206543
Validation loss: 2.0973993398809947

Epoch: 6| Step: 7
Training loss: 2.4741873741149902
Validation loss: 2.0960517942264514

Epoch: 6| Step: 8
Training loss: 1.402051329612732
Validation loss: 2.091945667420664

Epoch: 6| Step: 9
Training loss: 1.8233895301818848
Validation loss: 2.0667789174664404

Epoch: 6| Step: 10
Training loss: 2.444085121154785
Validation loss: 2.0704771113652054

Epoch: 6| Step: 11
Training loss: 1.7892961502075195
Validation loss: 2.0962864711720455

Epoch: 6| Step: 12
Training loss: 1.7864880561828613
Validation loss: 2.0709870887059036

Epoch: 6| Step: 13
Training loss: 1.490675449371338
Validation loss: 2.096322182686098

Epoch: 329| Step: 0
Training loss: 2.1561694145202637
Validation loss: 2.0651595054134244

Epoch: 6| Step: 1
Training loss: 1.5888960361480713
Validation loss: 2.082879884268648

Epoch: 6| Step: 2
Training loss: 2.384000778198242
Validation loss: 2.1232330965739425

Epoch: 6| Step: 3
Training loss: 1.8532419204711914
Validation loss: 2.08988058054319

Epoch: 6| Step: 4
Training loss: 2.089688301086426
Validation loss: 2.1327801814643284

Epoch: 6| Step: 5
Training loss: 1.8594248294830322
Validation loss: 2.14461019474973

Epoch: 6| Step: 6
Training loss: 1.9497768878936768
Validation loss: 2.118836118328956

Epoch: 6| Step: 7
Training loss: 1.4166202545166016
Validation loss: 2.1167314411491476

Epoch: 6| Step: 8
Training loss: 1.523094892501831
Validation loss: 2.097173272922475

Epoch: 6| Step: 9
Training loss: 1.9062025547027588
Validation loss: 2.103641712537376

Epoch: 6| Step: 10
Training loss: 1.6682556867599487
Validation loss: 2.1149645223412463

Epoch: 6| Step: 11
Training loss: 1.6025891304016113
Validation loss: 2.108186747438164

Epoch: 6| Step: 12
Training loss: 2.4592809677124023
Validation loss: 2.088127477194673

Epoch: 6| Step: 13
Training loss: 3.1115784645080566
Validation loss: 2.089771439952235

Epoch: 330| Step: 0
Training loss: 1.8680360317230225
Validation loss: 2.0819708993357997

Epoch: 6| Step: 1
Training loss: 1.92118239402771
Validation loss: 2.119768488791681

Epoch: 6| Step: 2
Training loss: 1.43409264087677
Validation loss: 2.1052141625394105

Epoch: 6| Step: 3
Training loss: 1.6141884326934814
Validation loss: 2.0635448604501705

Epoch: 6| Step: 4
Training loss: 2.6380221843719482
Validation loss: 2.0752453278469782

Epoch: 6| Step: 5
Training loss: 2.7055790424346924
Validation loss: 2.1124849909095356

Epoch: 6| Step: 6
Training loss: 1.744502067565918
Validation loss: 2.085721926022601

Epoch: 6| Step: 7
Training loss: 1.784921646118164
Validation loss: 2.0853455630681847

Epoch: 6| Step: 8
Training loss: 1.7050188779830933
Validation loss: 2.084964745788164

Epoch: 6| Step: 9
Training loss: 1.8024065494537354
Validation loss: 2.0565068619225615

Epoch: 6| Step: 10
Training loss: 1.857008457183838
Validation loss: 2.0924036220837663

Epoch: 6| Step: 11
Training loss: 1.646705150604248
Validation loss: 2.0961126999188493

Epoch: 6| Step: 12
Training loss: 1.7635583877563477
Validation loss: 2.0731917683796217

Epoch: 6| Step: 13
Training loss: 1.810965657234192
Validation loss: 2.0840410263307634

Epoch: 331| Step: 0
Training loss: 1.5996484756469727
Validation loss: 2.104569983738725

Epoch: 6| Step: 1
Training loss: 1.7267482280731201
Validation loss: 2.096747407349207

Epoch: 6| Step: 2
Training loss: 2.263908863067627
Validation loss: 2.0917529418904293

Epoch: 6| Step: 3
Training loss: 1.7618439197540283
Validation loss: 2.09647871089238

Epoch: 6| Step: 4
Training loss: 2.50283145904541
Validation loss: 2.0568054183836906

Epoch: 6| Step: 5
Training loss: 1.5520143508911133
Validation loss: 2.0959381749553065

Epoch: 6| Step: 6
Training loss: 2.2835233211517334
Validation loss: 2.0948567749351583

Epoch: 6| Step: 7
Training loss: 1.9944267272949219
Validation loss: 2.0789237240309357

Epoch: 6| Step: 8
Training loss: 1.1573090553283691
Validation loss: 2.0721429996593024

Epoch: 6| Step: 9
Training loss: 1.3934619426727295
Validation loss: 2.111689567565918

Epoch: 6| Step: 10
Training loss: 2.1076254844665527
Validation loss: 2.0739862380489225

Epoch: 6| Step: 11
Training loss: 2.949460983276367
Validation loss: 2.1326077702224895

Epoch: 6| Step: 12
Training loss: 1.6899784803390503
Validation loss: 2.0990728280877553

Epoch: 6| Step: 13
Training loss: 1.5941417217254639
Validation loss: 2.070790470287364

Epoch: 332| Step: 0
Training loss: 2.54176926612854
Validation loss: 2.1054459874347975

Epoch: 6| Step: 1
Training loss: 1.5007551908493042
Validation loss: 2.0847823722388155

Epoch: 6| Step: 2
Training loss: 1.9691803455352783
Validation loss: 2.0904616117477417

Epoch: 6| Step: 3
Training loss: 1.7100496292114258
Validation loss: 2.082121341459213

Epoch: 6| Step: 4
Training loss: 1.9531149864196777
Validation loss: 2.0713859655523814

Epoch: 6| Step: 5
Training loss: 2.0669431686401367
Validation loss: 2.0911003056392876

Epoch: 6| Step: 6
Training loss: 1.7247068881988525
Validation loss: 2.1132344815038864

Epoch: 6| Step: 7
Training loss: 2.140763282775879
Validation loss: 2.1193888777045795

Epoch: 6| Step: 8
Training loss: 1.851097583770752
Validation loss: 2.0935478364267657

Epoch: 6| Step: 9
Training loss: 1.4927008152008057
Validation loss: 2.099956161232405

Epoch: 6| Step: 10
Training loss: 1.079281210899353
Validation loss: 2.1013222894360943

Epoch: 6| Step: 11
Training loss: 1.7348363399505615
Validation loss: 2.1198430599704867

Epoch: 6| Step: 12
Training loss: 2.297934055328369
Validation loss: 2.0895238512305805

Epoch: 6| Step: 13
Training loss: 2.786794424057007
Validation loss: 2.1273012597073793

Epoch: 333| Step: 0
Training loss: 1.8627389669418335
Validation loss: 2.120884979924848

Epoch: 6| Step: 1
Training loss: 2.1842949390411377
Validation loss: 2.125065367708924

Epoch: 6| Step: 2
Training loss: 1.3056867122650146
Validation loss: 2.0992231202381912

Epoch: 6| Step: 3
Training loss: 1.7348637580871582
Validation loss: 2.104467990577862

Epoch: 6| Step: 4
Training loss: 2.0034337043762207
Validation loss: 2.0985656989518033

Epoch: 6| Step: 5
Training loss: 1.6538944244384766
Validation loss: 2.0559059061029905

Epoch: 6| Step: 6
Training loss: 1.6519029140472412
Validation loss: 2.1539672600325717

Epoch: 6| Step: 7
Training loss: 1.9279673099517822
Validation loss: 2.1370528680022045

Epoch: 6| Step: 8
Training loss: 2.0377845764160156
Validation loss: 2.1041903265060915

Epoch: 6| Step: 9
Training loss: 1.8080308437347412
Validation loss: 2.086279279442244

Epoch: 6| Step: 10
Training loss: 2.0444536209106445
Validation loss: 2.0760058395324217

Epoch: 6| Step: 11
Training loss: 2.1644411087036133
Validation loss: 2.0677923438369588

Epoch: 6| Step: 12
Training loss: 2.0288002490997314
Validation loss: 2.1122250454400175

Epoch: 6| Step: 13
Training loss: 1.9644614458084106
Validation loss: 2.073926910277336

Epoch: 334| Step: 0
Training loss: 2.0330638885498047
Validation loss: 2.0796639483462096

Epoch: 6| Step: 1
Training loss: 1.635119915008545
Validation loss: 2.1054696652197067

Epoch: 6| Step: 2
Training loss: 1.7966008186340332
Validation loss: 2.1030522251641877

Epoch: 6| Step: 3
Training loss: 2.510957956314087
Validation loss: 2.094647229358714

Epoch: 6| Step: 4
Training loss: 1.5070600509643555
Validation loss: 2.0769806138930784

Epoch: 6| Step: 5
Training loss: 2.138522148132324
Validation loss: 2.101982916555097

Epoch: 6| Step: 6
Training loss: 1.9466784000396729
Validation loss: 2.1016454389018397

Epoch: 6| Step: 7
Training loss: 1.560960054397583
Validation loss: 2.0827002307420135

Epoch: 6| Step: 8
Training loss: 1.8777644634246826
Validation loss: 2.132685876661731

Epoch: 6| Step: 9
Training loss: 2.29638409614563
Validation loss: 2.050399737973367

Epoch: 6| Step: 10
Training loss: 2.6517844200134277
Validation loss: 2.0815783713453557

Epoch: 6| Step: 11
Training loss: 0.9815604090690613
Validation loss: 2.1078280928314372

Epoch: 6| Step: 12
Training loss: 1.6766571998596191
Validation loss: 2.0870089787308888

Epoch: 6| Step: 13
Training loss: 1.4577983617782593
Validation loss: 2.0799860057010444

Epoch: 335| Step: 0
Training loss: 2.032824993133545
Validation loss: 2.0781395127696376

Epoch: 6| Step: 1
Training loss: 2.0778427124023438
Validation loss: 2.0509240729834444

Epoch: 6| Step: 2
Training loss: 1.308435320854187
Validation loss: 2.069873598314101

Epoch: 6| Step: 3
Training loss: 1.5325343608856201
Validation loss: 2.120030521064676

Epoch: 6| Step: 4
Training loss: 2.6304709911346436
Validation loss: 2.121954528234338

Epoch: 6| Step: 5
Training loss: 1.526347279548645
Validation loss: 2.0575017788076915

Epoch: 6| Step: 6
Training loss: 1.8330166339874268
Validation loss: 2.125594198062856

Epoch: 6| Step: 7
Training loss: 1.4109795093536377
Validation loss: 2.0825695555697203

Epoch: 6| Step: 8
Training loss: 2.121370792388916
Validation loss: 2.1029574153243855

Epoch: 6| Step: 9
Training loss: 2.1812005043029785
Validation loss: 2.0939687682736303

Epoch: 6| Step: 10
Training loss: 2.3169679641723633
Validation loss: 2.1040137660118843

Epoch: 6| Step: 11
Training loss: 2.1407089233398438
Validation loss: 2.1021714287419475

Epoch: 6| Step: 12
Training loss: 1.6584123373031616
Validation loss: 2.08442424702388

Epoch: 6| Step: 13
Training loss: 2.000316858291626
Validation loss: 2.0826608545036724

Epoch: 336| Step: 0
Training loss: 1.6348069906234741
Validation loss: 2.0722952042856524

Epoch: 6| Step: 1
Training loss: 2.065377712249756
Validation loss: 2.0929697649453276

Epoch: 6| Step: 2
Training loss: 2.2108490467071533
Validation loss: 2.0841041841814594

Epoch: 6| Step: 3
Training loss: 2.2253384590148926
Validation loss: 2.1121576293822257

Epoch: 6| Step: 4
Training loss: 2.09340238571167
Validation loss: 2.0793924203483005

Epoch: 6| Step: 5
Training loss: 1.5568103790283203
Validation loss: 2.0595793262604745

Epoch: 6| Step: 6
Training loss: 1.9647274017333984
Validation loss: 2.1187752998003395

Epoch: 6| Step: 7
Training loss: 1.8794461488723755
Validation loss: 2.0747956524613085

Epoch: 6| Step: 8
Training loss: 1.8465608358383179
Validation loss: 2.080230236053467

Epoch: 6| Step: 9
Training loss: 1.9348578453063965
Validation loss: 2.1170634415841874

Epoch: 6| Step: 10
Training loss: 1.4390206336975098
Validation loss: 2.097586129301338

Epoch: 6| Step: 11
Training loss: 2.4876177310943604
Validation loss: 2.1091676322362756

Epoch: 6| Step: 12
Training loss: 1.454626202583313
Validation loss: 2.1125819862529798

Epoch: 6| Step: 13
Training loss: 1.4510648250579834
Validation loss: 2.1070519467835784

Epoch: 337| Step: 0
Training loss: 1.5537588596343994
Validation loss: 2.116258462270101

Epoch: 6| Step: 1
Training loss: 1.6643595695495605
Validation loss: 2.118507380126625

Epoch: 6| Step: 2
Training loss: 1.8122005462646484
Validation loss: 2.046511688540059

Epoch: 6| Step: 3
Training loss: 2.2469422817230225
Validation loss: 2.127719825313937

Epoch: 6| Step: 4
Training loss: 2.409891366958618
Validation loss: 2.129571763418054

Epoch: 6| Step: 5
Training loss: 2.198639392852783
Validation loss: 2.1234565281098887

Epoch: 6| Step: 6
Training loss: 2.0379996299743652
Validation loss: 2.081837700259301

Epoch: 6| Step: 7
Training loss: 1.8747564554214478
Validation loss: 2.124410634399742

Epoch: 6| Step: 8
Training loss: 1.3635090589523315
Validation loss: 2.1454733392243743

Epoch: 6| Step: 9
Training loss: 2.170424222946167
Validation loss: 2.0921150022937405

Epoch: 6| Step: 10
Training loss: 1.7462061643600464
Validation loss: 2.1139726433702695

Epoch: 6| Step: 11
Training loss: 1.8331868648529053
Validation loss: 2.1074539999808035

Epoch: 6| Step: 12
Training loss: 1.587385892868042
Validation loss: 2.120923520416342

Epoch: 6| Step: 13
Training loss: 1.4660156965255737
Validation loss: 2.0795658583282144

Epoch: 338| Step: 0
Training loss: 1.7698184251785278
Validation loss: 2.0882208911321496

Epoch: 6| Step: 1
Training loss: 2.3012149333953857
Validation loss: 2.072808911723475

Epoch: 6| Step: 2
Training loss: 1.333370327949524
Validation loss: 2.1052142573941137

Epoch: 6| Step: 3
Training loss: 2.3274407386779785
Validation loss: 2.1340696042583835

Epoch: 6| Step: 4
Training loss: 0.5136595964431763
Validation loss: 2.126798470815023

Epoch: 6| Step: 5
Training loss: 1.721215009689331
Validation loss: 2.045011322985413

Epoch: 6| Step: 6
Training loss: 2.5641837120056152
Validation loss: 2.0723661274038334

Epoch: 6| Step: 7
Training loss: 1.2803716659545898
Validation loss: 2.1061987415436776

Epoch: 6| Step: 8
Training loss: 1.6678035259246826
Validation loss: 2.0564501298371183

Epoch: 6| Step: 9
Training loss: 2.6751062870025635
Validation loss: 2.0872553240868355

Epoch: 6| Step: 10
Training loss: 2.2222886085510254
Validation loss: 2.0645136756281697

Epoch: 6| Step: 11
Training loss: 2.0649938583374023
Validation loss: 2.09693217790255

Epoch: 6| Step: 12
Training loss: 2.058190107345581
Validation loss: 2.0939837796713716

Epoch: 6| Step: 13
Training loss: 2.2652370929718018
Validation loss: 2.077027866917272

Epoch: 339| Step: 0
Training loss: 1.5539488792419434
Validation loss: 2.0667003585446264

Epoch: 6| Step: 1
Training loss: 2.518137216567993
Validation loss: 2.11027023612812

Epoch: 6| Step: 2
Training loss: 1.3343291282653809
Validation loss: 2.0846025379755164

Epoch: 6| Step: 3
Training loss: 2.2840933799743652
Validation loss: 2.077373840475595

Epoch: 6| Step: 4
Training loss: 1.9558732509613037
Validation loss: 2.1057730041524416

Epoch: 6| Step: 5
Training loss: 1.5311558246612549
Validation loss: 2.1022528679140153

Epoch: 6| Step: 6
Training loss: 1.683121681213379
Validation loss: 2.0887236607972013

Epoch: 6| Step: 7
Training loss: 1.5470237731933594
Validation loss: 2.109614836272373

Epoch: 6| Step: 8
Training loss: 2.053398609161377
Validation loss: 2.1146318348505164

Epoch: 6| Step: 9
Training loss: 2.181137800216675
Validation loss: 2.0916282797372467

Epoch: 6| Step: 10
Training loss: 2.039231300354004
Validation loss: 2.122572318200142

Epoch: 6| Step: 11
Training loss: 1.776796817779541
Validation loss: 2.0787389188684444

Epoch: 6| Step: 12
Training loss: 1.8170013427734375
Validation loss: 2.1015778023709535

Epoch: 6| Step: 13
Training loss: 1.8749383687973022
Validation loss: 2.1055213815422467

Epoch: 340| Step: 0
Training loss: 1.998468041419983
Validation loss: 2.1049002575617966

Epoch: 6| Step: 1
Training loss: 2.687347412109375
Validation loss: 2.112961560167292

Epoch: 6| Step: 2
Training loss: 1.1490429639816284
Validation loss: 2.0924893617630005

Epoch: 6| Step: 3
Training loss: 2.134324550628662
Validation loss: 2.071184840253604

Epoch: 6| Step: 4
Training loss: 1.9459035396575928
Validation loss: 2.1221788224353584

Epoch: 6| Step: 5
Training loss: 1.9090547561645508
Validation loss: 2.1197584700840775

Epoch: 6| Step: 6
Training loss: 1.143401861190796
Validation loss: 2.102634959323432

Epoch: 6| Step: 7
Training loss: 2.2060017585754395
Validation loss: 2.1147920470083914

Epoch: 6| Step: 8
Training loss: 1.5499696731567383
Validation loss: 2.0860265749757008

Epoch: 6| Step: 9
Training loss: 1.8691071271896362
Validation loss: 2.084639846637685

Epoch: 6| Step: 10
Training loss: 2.331759214401245
Validation loss: 2.1032908513981807

Epoch: 6| Step: 11
Training loss: 2.0846662521362305
Validation loss: 2.0492299500332085

Epoch: 6| Step: 12
Training loss: 1.8211591243743896
Validation loss: 2.125801117189469

Epoch: 6| Step: 13
Training loss: 1.3235403299331665
Validation loss: 2.1091633842837427

Epoch: 341| Step: 0
Training loss: 2.0023436546325684
Validation loss: 2.1187208878096713

Epoch: 6| Step: 1
Training loss: 2.465162754058838
Validation loss: 2.103146558166832

Epoch: 6| Step: 2
Training loss: 2.6498637199401855
Validation loss: 2.067272889998651

Epoch: 6| Step: 3
Training loss: 2.1255626678466797
Validation loss: 2.1318615290426437

Epoch: 6| Step: 4
Training loss: 2.075779914855957
Validation loss: 2.131834222424415

Epoch: 6| Step: 5
Training loss: 2.1435611248016357
Validation loss: 2.1424133034162622

Epoch: 6| Step: 6
Training loss: 1.9533755779266357
Validation loss: 2.0911983546390327

Epoch: 6| Step: 7
Training loss: 1.4484851360321045
Validation loss: 2.096651469507525

Epoch: 6| Step: 8
Training loss: 1.2992444038391113
Validation loss: 2.115373247413225

Epoch: 6| Step: 9
Training loss: 1.4361904859542847
Validation loss: 2.117283667287519

Epoch: 6| Step: 10
Training loss: 1.7884409427642822
Validation loss: 2.110089450754145

Epoch: 6| Step: 11
Training loss: 1.309361457824707
Validation loss: 2.162127633248606

Epoch: 6| Step: 12
Training loss: 2.169076919555664
Validation loss: 2.1076962691481396

Epoch: 6| Step: 13
Training loss: 1.3568388223648071
Validation loss: 2.118988452419158

Epoch: 342| Step: 0
Training loss: 1.5336556434631348
Validation loss: 2.0870690884128695

Epoch: 6| Step: 1
Training loss: 1.9748395681381226
Validation loss: 2.0818604679517847

Epoch: 6| Step: 2
Training loss: 2.4577584266662598
Validation loss: 2.1007360540410525

Epoch: 6| Step: 3
Training loss: 1.355712652206421
Validation loss: 2.0945527733013196

Epoch: 6| Step: 4
Training loss: 1.6174299716949463
Validation loss: 2.112941575306718

Epoch: 6| Step: 5
Training loss: 2.585517406463623
Validation loss: 2.072166774862556

Epoch: 6| Step: 6
Training loss: 1.689436435699463
Validation loss: 2.1143042989956435

Epoch: 6| Step: 7
Training loss: 1.9058893918991089
Validation loss: 2.0787902237266622

Epoch: 6| Step: 8
Training loss: 1.1996688842773438
Validation loss: 2.097676960370874

Epoch: 6| Step: 9
Training loss: 2.156040668487549
Validation loss: 2.0937229177003265

Epoch: 6| Step: 10
Training loss: 1.8333203792572021
Validation loss: 2.088730001962313

Epoch: 6| Step: 11
Training loss: 1.789433479309082
Validation loss: 2.090130038158868

Epoch: 6| Step: 12
Training loss: 1.8003132343292236
Validation loss: 2.0954581781100203

Epoch: 6| Step: 13
Training loss: 2.0604453086853027
Validation loss: 2.0653248243434454

Epoch: 343| Step: 0
Training loss: 1.3712602853775024
Validation loss: 2.1024247882186726

Epoch: 6| Step: 1
Training loss: 1.7798922061920166
Validation loss: 2.099242324470192

Epoch: 6| Step: 2
Training loss: 1.4254626035690308
Validation loss: 2.0819704955623997

Epoch: 6| Step: 3
Training loss: 1.1346476078033447
Validation loss: 2.0948406829628894

Epoch: 6| Step: 4
Training loss: 2.1056041717529297
Validation loss: 2.090838378475558

Epoch: 6| Step: 5
Training loss: 2.1839191913604736
Validation loss: 2.0758102632338002

Epoch: 6| Step: 6
Training loss: 2.107222557067871
Validation loss: 2.1141218331552323

Epoch: 6| Step: 7
Training loss: 1.5559437274932861
Validation loss: 2.1004501414555374

Epoch: 6| Step: 8
Training loss: 1.8850902318954468
Validation loss: 2.1048524969367572

Epoch: 6| Step: 9
Training loss: 2.212392568588257
Validation loss: 2.1056057073736705

Epoch: 6| Step: 10
Training loss: 2.0614936351776123
Validation loss: 2.0750087845710015

Epoch: 6| Step: 11
Training loss: 1.757238507270813
Validation loss: 2.0926813438374507

Epoch: 6| Step: 12
Training loss: 2.806239604949951
Validation loss: 2.0905456209695465

Epoch: 6| Step: 13
Training loss: 1.4744131565093994
Validation loss: 2.1416732085648404

Epoch: 344| Step: 0
Training loss: 2.1991381645202637
Validation loss: 2.1096312410087994

Epoch: 6| Step: 1
Training loss: 1.3951057195663452
Validation loss: 2.1704036317845827

Epoch: 6| Step: 2
Training loss: 2.1988725662231445
Validation loss: 2.1158832375721266

Epoch: 6| Step: 3
Training loss: 1.5766727924346924
Validation loss: 2.1516151376949844

Epoch: 6| Step: 4
Training loss: 1.3078969717025757
Validation loss: 2.115138194894278

Epoch: 6| Step: 5
Training loss: 1.954321265220642
Validation loss: 2.138146023596487

Epoch: 6| Step: 6
Training loss: 1.3126521110534668
Validation loss: 2.1318975546026744

Epoch: 6| Step: 7
Training loss: 2.2032785415649414
Validation loss: 2.0925692883870934

Epoch: 6| Step: 8
Training loss: 2.094550132751465
Validation loss: 2.0999940197954894

Epoch: 6| Step: 9
Training loss: 2.0480432510375977
Validation loss: 2.113895288077734

Epoch: 6| Step: 10
Training loss: 1.9726381301879883
Validation loss: 2.112137456094065

Epoch: 6| Step: 11
Training loss: 2.1537234783172607
Validation loss: 2.1357048224377375

Epoch: 6| Step: 12
Training loss: 2.084054946899414
Validation loss: 2.100179180022209

Epoch: 6| Step: 13
Training loss: 1.3352917432785034
Validation loss: 2.119755245024158

Epoch: 345| Step: 0
Training loss: 2.013267755508423
Validation loss: 2.0954816226036317

Epoch: 6| Step: 1
Training loss: 1.7361217737197876
Validation loss: 2.1040398190098424

Epoch: 6| Step: 2
Training loss: 1.861001968383789
Validation loss: 2.098459561665853

Epoch: 6| Step: 3
Training loss: 1.6168400049209595
Validation loss: 2.0664415308224258

Epoch: 6| Step: 4
Training loss: 1.5228805541992188
Validation loss: 2.1348391630316295

Epoch: 6| Step: 5
Training loss: 1.6582574844360352
Validation loss: 2.075189600708664

Epoch: 6| Step: 6
Training loss: 1.7257777452468872
Validation loss: 2.1244253804606776

Epoch: 6| Step: 7
Training loss: 1.4306460618972778
Validation loss: 2.0873095963590886

Epoch: 6| Step: 8
Training loss: 1.6474167108535767
Validation loss: 2.1158567577280025

Epoch: 6| Step: 9
Training loss: 1.8340492248535156
Validation loss: 2.075457519100558

Epoch: 6| Step: 10
Training loss: 2.822455883026123
Validation loss: 2.1025985184536187

Epoch: 6| Step: 11
Training loss: 2.019974946975708
Validation loss: 2.1316709633796447

Epoch: 6| Step: 12
Training loss: 2.3723649978637695
Validation loss: 2.068589260501246

Epoch: 6| Step: 13
Training loss: 2.189864158630371
Validation loss: 2.073085723384734

Epoch: 346| Step: 0
Training loss: 2.2556519508361816
Validation loss: 2.074541546965158

Epoch: 6| Step: 1
Training loss: 2.356438636779785
Validation loss: 2.0873427583325292

Epoch: 6| Step: 2
Training loss: 1.704026460647583
Validation loss: 2.116328913678405

Epoch: 6| Step: 3
Training loss: 0.8024629354476929
Validation loss: 2.115185546618636

Epoch: 6| Step: 4
Training loss: 1.2525343894958496
Validation loss: 2.0859451460581955

Epoch: 6| Step: 5
Training loss: 2.1893980503082275
Validation loss: 2.1261446796437746

Epoch: 6| Step: 6
Training loss: 2.2059030532836914
Validation loss: 2.110417607010052

Epoch: 6| Step: 7
Training loss: 1.8219943046569824
Validation loss: 2.131332541024813

Epoch: 6| Step: 8
Training loss: 2.090606689453125
Validation loss: 2.1453514675940237

Epoch: 6| Step: 9
Training loss: 2.280301570892334
Validation loss: 2.0980597644723873

Epoch: 6| Step: 10
Training loss: 1.9186570644378662
Validation loss: 2.098837434604604

Epoch: 6| Step: 11
Training loss: 1.3841228485107422
Validation loss: 2.1199202665718655

Epoch: 6| Step: 12
Training loss: 1.9567208290100098
Validation loss: 2.1055269754061134

Epoch: 6| Step: 13
Training loss: 1.696502923965454
Validation loss: 2.1333316551741732

Epoch: 347| Step: 0
Training loss: 1.6973286867141724
Validation loss: 2.1069961914452175

Epoch: 6| Step: 1
Training loss: 1.797645092010498
Validation loss: 2.097378598746433

Epoch: 6| Step: 2
Training loss: 2.190324068069458
Validation loss: 2.1013580240229124

Epoch: 6| Step: 3
Training loss: 1.1867470741271973
Validation loss: 2.09998732484797

Epoch: 6| Step: 4
Training loss: 2.1041412353515625
Validation loss: 2.088082123828191

Epoch: 6| Step: 5
Training loss: 1.8363096714019775
Validation loss: 2.1126098504630466

Epoch: 6| Step: 6
Training loss: 2.410159111022949
Validation loss: 2.1030365344016784

Epoch: 6| Step: 7
Training loss: 1.4702248573303223
Validation loss: 2.0961390259445354

Epoch: 6| Step: 8
Training loss: 1.499954104423523
Validation loss: 2.139481447076285

Epoch: 6| Step: 9
Training loss: 1.724725365638733
Validation loss: 2.107064643213826

Epoch: 6| Step: 10
Training loss: 1.5310626029968262
Validation loss: 2.087654536770236

Epoch: 6| Step: 11
Training loss: 2.309058427810669
Validation loss: 2.127961266425348

Epoch: 6| Step: 12
Training loss: 2.3559231758117676
Validation loss: 2.0887915306193854

Epoch: 6| Step: 13
Training loss: 2.0396273136138916
Validation loss: 2.070793572292533

Epoch: 348| Step: 0
Training loss: 1.7764924764633179
Validation loss: 2.1115336136151384

Epoch: 6| Step: 1
Training loss: 1.9105221033096313
Validation loss: 2.089750341189805

Epoch: 6| Step: 2
Training loss: 1.9717402458190918
Validation loss: 2.1043438206436815

Epoch: 6| Step: 3
Training loss: 1.9231019020080566
Validation loss: 2.0854152043660483

Epoch: 6| Step: 4
Training loss: 2.2028961181640625
Validation loss: 2.0590434715312016

Epoch: 6| Step: 5
Training loss: 2.0095643997192383
Validation loss: 2.1057196342816917

Epoch: 6| Step: 6
Training loss: 1.8701896667480469
Validation loss: 2.081090796378351

Epoch: 6| Step: 7
Training loss: 1.6456115245819092
Validation loss: 2.0557942621169554

Epoch: 6| Step: 8
Training loss: 1.9354422092437744
Validation loss: 2.059514235424739

Epoch: 6| Step: 9
Training loss: 2.182258367538452
Validation loss: 2.1246179778088807

Epoch: 6| Step: 10
Training loss: 1.982342004776001
Validation loss: 2.0891766727611585

Epoch: 6| Step: 11
Training loss: 1.3690721988677979
Validation loss: 2.0792540683541247

Epoch: 6| Step: 12
Training loss: 1.5485057830810547
Validation loss: 2.077106245102421

Epoch: 6| Step: 13
Training loss: 1.8223135471343994
Validation loss: 2.0895698352526595

Epoch: 349| Step: 0
Training loss: 1.8887243270874023
Validation loss: 2.1237387375165055

Epoch: 6| Step: 1
Training loss: 1.9515128135681152
Validation loss: 2.088558640531314

Epoch: 6| Step: 2
Training loss: 1.1609182357788086
Validation loss: 2.112648904964488

Epoch: 6| Step: 3
Training loss: 1.9495264291763306
Validation loss: 2.074531910240009

Epoch: 6| Step: 4
Training loss: 1.670426845550537
Validation loss: 2.088143569166942

Epoch: 6| Step: 5
Training loss: 2.012071132659912
Validation loss: 2.127742698115687

Epoch: 6| Step: 6
Training loss: 2.052823543548584
Validation loss: 2.1174625042946107

Epoch: 6| Step: 7
Training loss: 1.91973876953125
Validation loss: 2.098779768072149

Epoch: 6| Step: 8
Training loss: 1.2863471508026123
Validation loss: 2.1198438264990367

Epoch: 6| Step: 9
Training loss: 2.3374576568603516
Validation loss: 2.1200837678806757

Epoch: 6| Step: 10
Training loss: 1.5450847148895264
Validation loss: 2.117032979124336

Epoch: 6| Step: 11
Training loss: 1.7199958562850952
Validation loss: 2.130152146021525

Epoch: 6| Step: 12
Training loss: 2.339456558227539
Validation loss: 2.105745277097148

Epoch: 6| Step: 13
Training loss: 2.623713970184326
Validation loss: 2.093417424027638

Epoch: 350| Step: 0
Training loss: 2.2712037563323975
Validation loss: 2.113760030397805

Epoch: 6| Step: 1
Training loss: 2.485306978225708
Validation loss: 2.1129520657241985

Epoch: 6| Step: 2
Training loss: 2.121792793273926
Validation loss: 2.087971762944293

Epoch: 6| Step: 3
Training loss: 1.0784378051757812
Validation loss: 2.094691986678749

Epoch: 6| Step: 4
Training loss: 1.8193132877349854
Validation loss: 2.0958931292257

Epoch: 6| Step: 5
Training loss: 1.5376222133636475
Validation loss: 2.091823980372439

Epoch: 6| Step: 6
Training loss: 1.927868127822876
Validation loss: 2.1134472816221175

Epoch: 6| Step: 7
Training loss: 1.488002061843872
Validation loss: 2.096102714538574

Epoch: 6| Step: 8
Training loss: 1.663264274597168
Validation loss: 2.1186488238714074

Epoch: 6| Step: 9
Training loss: 1.7871060371398926
Validation loss: 2.1377643949242047

Epoch: 6| Step: 10
Training loss: 1.9275438785552979
Validation loss: 2.1255579968934417

Epoch: 6| Step: 11
Training loss: 1.922191858291626
Validation loss: 2.1021109191320275

Epoch: 6| Step: 12
Training loss: 1.3803714513778687
Validation loss: 2.102482743160699

Epoch: 6| Step: 13
Training loss: 2.610130548477173
Validation loss: 2.1000282405525126

Epoch: 351| Step: 0
Training loss: 2.6891160011291504
Validation loss: 2.091663165759015

Epoch: 6| Step: 1
Training loss: 1.4019248485565186
Validation loss: 2.1053535835717314

Epoch: 6| Step: 2
Training loss: 1.5028566122055054
Validation loss: 2.1031447738729496

Epoch: 6| Step: 3
Training loss: 1.692124843597412
Validation loss: 2.073748564207426

Epoch: 6| Step: 4
Training loss: 2.158080577850342
Validation loss: 2.0733878279245026

Epoch: 6| Step: 5
Training loss: 1.7569972276687622
Validation loss: 2.1029072230862034

Epoch: 6| Step: 6
Training loss: 1.6122353076934814
Validation loss: 2.122311152437682

Epoch: 6| Step: 7
Training loss: 1.7326000928878784
Validation loss: 2.1335005247464744

Epoch: 6| Step: 8
Training loss: 1.7701034545898438
Validation loss: 2.080181319226501

Epoch: 6| Step: 9
Training loss: 2.115279197692871
Validation loss: 2.095066503811908

Epoch: 6| Step: 10
Training loss: 1.730502963066101
Validation loss: 2.129225477095573

Epoch: 6| Step: 11
Training loss: 2.1651363372802734
Validation loss: 2.1228974429509972

Epoch: 6| Step: 12
Training loss: 1.830565094947815
Validation loss: 2.1268278296275804

Epoch: 6| Step: 13
Training loss: 2.3075053691864014
Validation loss: 2.1107926381531583

Epoch: 352| Step: 0
Training loss: 1.9542806148529053
Validation loss: 2.1388739103912027

Epoch: 6| Step: 1
Training loss: 1.7976881265640259
Validation loss: 2.1045211540755404

Epoch: 6| Step: 2
Training loss: 1.8549320697784424
Validation loss: 2.127674315565376

Epoch: 6| Step: 3
Training loss: 1.403428316116333
Validation loss: 2.082507621857428

Epoch: 6| Step: 4
Training loss: 1.6320348978042603
Validation loss: 2.109284241994222

Epoch: 6| Step: 5
Training loss: 1.7128283977508545
Validation loss: 2.1230990963597454

Epoch: 6| Step: 6
Training loss: 1.8758975267410278
Validation loss: 2.1138657600648942

Epoch: 6| Step: 7
Training loss: 2.0572524070739746
Validation loss: 2.080657994875344

Epoch: 6| Step: 8
Training loss: 1.8933229446411133
Validation loss: 2.075093392402895

Epoch: 6| Step: 9
Training loss: 1.707915186882019
Validation loss: 2.131150935285835

Epoch: 6| Step: 10
Training loss: 1.9637119770050049
Validation loss: 2.125494021241383

Epoch: 6| Step: 11
Training loss: 2.4211325645446777
Validation loss: 2.064730885208294

Epoch: 6| Step: 12
Training loss: 2.207726240158081
Validation loss: 2.1171902661682456

Epoch: 6| Step: 13
Training loss: 1.215029001235962
Validation loss: 2.0905906795173563

Epoch: 353| Step: 0
Training loss: 1.7766108512878418
Validation loss: 2.0980688307874944

Epoch: 6| Step: 1
Training loss: 2.4354639053344727
Validation loss: 2.115120760856136

Epoch: 6| Step: 2
Training loss: 1.5327987670898438
Validation loss: 2.1146893168008454

Epoch: 6| Step: 3
Training loss: 1.8947498798370361
Validation loss: 2.1033926894587855

Epoch: 6| Step: 4
Training loss: 1.8825715780258179
Validation loss: 2.1285578153466664

Epoch: 6| Step: 5
Training loss: 1.7153204679489136
Validation loss: 2.1317345634583504

Epoch: 6| Step: 6
Training loss: 1.9202967882156372
Validation loss: 2.1256840023943173

Epoch: 6| Step: 7
Training loss: 2.232846736907959
Validation loss: 2.1514233876300115

Epoch: 6| Step: 8
Training loss: 1.7142698764801025
Validation loss: 2.143406915408309

Epoch: 6| Step: 9
Training loss: 1.5353546142578125
Validation loss: 2.16646485687584

Epoch: 6| Step: 10
Training loss: 1.4283998012542725
Validation loss: 2.134721668817664

Epoch: 6| Step: 11
Training loss: 2.1528990268707275
Validation loss: 2.118732270374093

Epoch: 6| Step: 12
Training loss: 1.979315161705017
Validation loss: 2.171579530162196

Epoch: 6| Step: 13
Training loss: 2.2145254611968994
Validation loss: 2.125084300195017

Epoch: 354| Step: 0
Training loss: 1.6070935726165771
Validation loss: 2.1435405015945435

Epoch: 6| Step: 1
Training loss: 1.5816073417663574
Validation loss: 2.1207149887597687

Epoch: 6| Step: 2
Training loss: 1.988097906112671
Validation loss: 2.1322437742704987

Epoch: 6| Step: 3
Training loss: 1.8802481889724731
Validation loss: 2.0874360466516144

Epoch: 6| Step: 4
Training loss: 1.6094129085540771
Validation loss: 2.1383933380085933

Epoch: 6| Step: 5
Training loss: 1.5087049007415771
Validation loss: 2.1189088231773785

Epoch: 6| Step: 6
Training loss: 2.0547075271606445
Validation loss: 2.0893416814906622

Epoch: 6| Step: 7
Training loss: 2.44085693359375
Validation loss: 2.117096339502642

Epoch: 6| Step: 8
Training loss: 2.362417221069336
Validation loss: 2.081533255115632

Epoch: 6| Step: 9
Training loss: 1.3192058801651
Validation loss: 2.1062935090834096

Epoch: 6| Step: 10
Training loss: 1.3768473863601685
Validation loss: 2.110058976757911

Epoch: 6| Step: 11
Training loss: 2.080061435699463
Validation loss: 2.060774903143606

Epoch: 6| Step: 12
Training loss: 1.7592467069625854
Validation loss: 2.1055498558987855

Epoch: 6| Step: 13
Training loss: 2.16335129737854
Validation loss: 2.0679902709940428

Epoch: 355| Step: 0
Training loss: 2.216416835784912
Validation loss: 2.099105904179235

Epoch: 6| Step: 1
Training loss: 1.8409091234207153
Validation loss: 2.0944669605583273

Epoch: 6| Step: 2
Training loss: 1.258455753326416
Validation loss: 2.054358640024739

Epoch: 6| Step: 3
Training loss: 1.493694543838501
Validation loss: 2.142691130279213

Epoch: 6| Step: 4
Training loss: 1.7935841083526611
Validation loss: 2.1347550346005346

Epoch: 6| Step: 5
Training loss: 1.4446144104003906
Validation loss: 2.1205241372508388

Epoch: 6| Step: 6
Training loss: 1.8342870473861694
Validation loss: 2.0850432406189623

Epoch: 6| Step: 7
Training loss: 2.690671443939209
Validation loss: 2.1057122074147707

Epoch: 6| Step: 8
Training loss: 1.3195734024047852
Validation loss: 2.1031919025605723

Epoch: 6| Step: 9
Training loss: 2.7703371047973633
Validation loss: 2.1119641539871052

Epoch: 6| Step: 10
Training loss: 2.3056039810180664
Validation loss: 2.1150909828883346

Epoch: 6| Step: 11
Training loss: 1.3305940628051758
Validation loss: 2.146701348725186

Epoch: 6| Step: 12
Training loss: 2.1894454956054688
Validation loss: 2.07553437448317

Epoch: 6| Step: 13
Training loss: 0.999333918094635
Validation loss: 2.0974267426357476

Epoch: 356| Step: 0
Training loss: 2.220412254333496
Validation loss: 2.1196224510028796

Epoch: 6| Step: 1
Training loss: 2.0744285583496094
Validation loss: 2.1109358162008305

Epoch: 6| Step: 2
Training loss: 1.6788818836212158
Validation loss: 2.0986109984818326

Epoch: 6| Step: 3
Training loss: 2.3402247428894043
Validation loss: 2.1301155372332503

Epoch: 6| Step: 4
Training loss: 2.207953453063965
Validation loss: 2.118185338153634

Epoch: 6| Step: 5
Training loss: 1.7862993478775024
Validation loss: 2.131869443001286

Epoch: 6| Step: 6
Training loss: 1.7863446474075317
Validation loss: 2.1275939364587106

Epoch: 6| Step: 7
Training loss: 1.3561216592788696
Validation loss: 2.1363911833814395

Epoch: 6| Step: 8
Training loss: 1.913780927658081
Validation loss: 2.1537088860747633

Epoch: 6| Step: 9
Training loss: 1.4350645542144775
Validation loss: 2.1290297251875683

Epoch: 6| Step: 10
Training loss: 2.3198440074920654
Validation loss: 2.1318581386279036

Epoch: 6| Step: 11
Training loss: 1.8139119148254395
Validation loss: 2.15575732210631

Epoch: 6| Step: 12
Training loss: 1.3214553594589233
Validation loss: 2.141024507502074

Epoch: 6| Step: 13
Training loss: 2.078791856765747
Validation loss: 2.105378989250429

Epoch: 357| Step: 0
Training loss: 1.8133180141448975
Validation loss: 2.1127240862897647

Epoch: 6| Step: 1
Training loss: 2.344503402709961
Validation loss: 2.1436325991025535

Epoch: 6| Step: 2
Training loss: 2.2690134048461914
Validation loss: 2.112465548258956

Epoch: 6| Step: 3
Training loss: 1.230595350265503
Validation loss: 2.1254647354925833

Epoch: 6| Step: 4
Training loss: 2.165989875793457
Validation loss: 2.0821384358149704

Epoch: 6| Step: 5
Training loss: 2.0030059814453125
Validation loss: 2.116866260446528

Epoch: 6| Step: 6
Training loss: 1.7359975576400757
Validation loss: 2.0649899731400194

Epoch: 6| Step: 7
Training loss: 1.9398436546325684
Validation loss: 2.089273952668713

Epoch: 6| Step: 8
Training loss: 1.294447660446167
Validation loss: 2.0991587856764435

Epoch: 6| Step: 9
Training loss: 1.6837025880813599
Validation loss: 2.0584360681554323

Epoch: 6| Step: 10
Training loss: 1.7576253414154053
Validation loss: 2.10275786922824

Epoch: 6| Step: 11
Training loss: 1.5136816501617432
Validation loss: 2.0870919535236974

Epoch: 6| Step: 12
Training loss: 2.691915512084961
Validation loss: 2.093538740629791

Epoch: 6| Step: 13
Training loss: 0.9092728495597839
Validation loss: 2.1038788441688783

Epoch: 358| Step: 0
Training loss: 1.542342185974121
Validation loss: 2.037830214346609

Epoch: 6| Step: 1
Training loss: 1.6937904357910156
Validation loss: 2.101644949246478

Epoch: 6| Step: 2
Training loss: 1.8949573040008545
Validation loss: 2.1204577235765356

Epoch: 6| Step: 3
Training loss: 2.093655586242676
Validation loss: 2.1130575146726382

Epoch: 6| Step: 4
Training loss: 1.4999420642852783
Validation loss: 2.097726801390289

Epoch: 6| Step: 5
Training loss: 1.84895658493042
Validation loss: 2.050478514804635

Epoch: 6| Step: 6
Training loss: 1.0897972583770752
Validation loss: 2.0979158762962586

Epoch: 6| Step: 7
Training loss: 1.7073301076889038
Validation loss: 2.0704075649220455

Epoch: 6| Step: 8
Training loss: 1.6978925466537476
Validation loss: 2.0787721064782914

Epoch: 6| Step: 9
Training loss: 1.711323857307434
Validation loss: 2.0893605293766147

Epoch: 6| Step: 10
Training loss: 2.0660195350646973
Validation loss: 2.1188094244208386

Epoch: 6| Step: 11
Training loss: 2.1441192626953125
Validation loss: 2.1109329154414516

Epoch: 6| Step: 12
Training loss: 2.8931641578674316
Validation loss: 2.1172560440596713

Epoch: 6| Step: 13
Training loss: 1.6569552421569824
Validation loss: 2.1113548483899844

Epoch: 359| Step: 0
Training loss: 1.2730274200439453
Validation loss: 2.1283329097173547

Epoch: 6| Step: 1
Training loss: 2.484160900115967
Validation loss: 2.1005958792983845

Epoch: 6| Step: 2
Training loss: 1.620172381401062
Validation loss: 2.1309675042347243

Epoch: 6| Step: 3
Training loss: 1.2252973318099976
Validation loss: 2.0779340985000774

Epoch: 6| Step: 4
Training loss: 1.4045511484146118
Validation loss: 2.111725245752642

Epoch: 6| Step: 5
Training loss: 2.359772205352783
Validation loss: 2.103813514914564

Epoch: 6| Step: 6
Training loss: 1.8965270519256592
Validation loss: 2.1533974319375973

Epoch: 6| Step: 7
Training loss: 1.926255464553833
Validation loss: 2.1354477251729658

Epoch: 6| Step: 8
Training loss: 1.6886286735534668
Validation loss: 2.0829756593191497

Epoch: 6| Step: 9
Training loss: 1.7128101587295532
Validation loss: 2.110188156045893

Epoch: 6| Step: 10
Training loss: 2.268918752670288
Validation loss: 2.0951000003404516

Epoch: 6| Step: 11
Training loss: 1.9740519523620605
Validation loss: 2.1287645319456696

Epoch: 6| Step: 12
Training loss: 2.240067958831787
Validation loss: 2.088273638038225

Epoch: 6| Step: 13
Training loss: 1.185853362083435
Validation loss: 2.099687091765865

Epoch: 360| Step: 0
Training loss: 1.57686185836792
Validation loss: 2.1350856891242405

Epoch: 6| Step: 1
Training loss: 2.1278719902038574
Validation loss: 2.117034855709281

Epoch: 6| Step: 2
Training loss: 1.4403917789459229
Validation loss: 2.089632685466479

Epoch: 6| Step: 3
Training loss: 1.6438508033752441
Validation loss: 2.1301620339834564

Epoch: 6| Step: 4
Training loss: 1.2753056287765503
Validation loss: 2.097522288240412

Epoch: 6| Step: 5
Training loss: 1.9868547916412354
Validation loss: 2.121363501394949

Epoch: 6| Step: 6
Training loss: 1.8981671333312988
Validation loss: 2.088314607579221

Epoch: 6| Step: 7
Training loss: 2.0586957931518555
Validation loss: 2.0881945804883073

Epoch: 6| Step: 8
Training loss: 1.9362411499023438
Validation loss: 2.124512880079208

Epoch: 6| Step: 9
Training loss: 1.7016853094100952
Validation loss: 2.1004836995114564

Epoch: 6| Step: 10
Training loss: 2.5078623294830322
Validation loss: 2.1169591872922835

Epoch: 6| Step: 11
Training loss: 1.901172161102295
Validation loss: 2.1029910964350544

Epoch: 6| Step: 12
Training loss: 1.9869648218154907
Validation loss: 2.1417181530306415

Epoch: 6| Step: 13
Training loss: 1.5985093116760254
Validation loss: 2.090606552298351

Epoch: 361| Step: 0
Training loss: 1.4728323221206665
Validation loss: 2.110388507125198

Epoch: 6| Step: 1
Training loss: 2.0591423511505127
Validation loss: 2.076660781778315

Epoch: 6| Step: 2
Training loss: 1.2282994985580444
Validation loss: 2.1402312235165666

Epoch: 6| Step: 3
Training loss: 1.6803772449493408
Validation loss: 2.093257870725406

Epoch: 6| Step: 4
Training loss: 2.311727285385132
Validation loss: 2.1257880041676183

Epoch: 6| Step: 5
Training loss: 2.022764205932617
Validation loss: 2.1008975428919636

Epoch: 6| Step: 6
Training loss: 1.3853514194488525
Validation loss: 2.086935871390886

Epoch: 6| Step: 7
Training loss: 2.202026128768921
Validation loss: 2.099020764391909

Epoch: 6| Step: 8
Training loss: 1.7779316902160645
Validation loss: 2.1218824527596913

Epoch: 6| Step: 9
Training loss: 2.1634812355041504
Validation loss: 2.0893245538075766

Epoch: 6| Step: 10
Training loss: 2.2203781604766846
Validation loss: 2.118708873307833

Epoch: 6| Step: 11
Training loss: 1.365619421005249
Validation loss: 2.109638980639878

Epoch: 6| Step: 12
Training loss: 2.1284236907958984
Validation loss: 2.135582297079025

Epoch: 6| Step: 13
Training loss: 1.6839373111724854
Validation loss: 2.0821988505701863

Epoch: 362| Step: 0
Training loss: 2.2706105709075928
Validation loss: 2.102400343905213

Epoch: 6| Step: 1
Training loss: 2.160153865814209
Validation loss: 2.0904351793309695

Epoch: 6| Step: 2
Training loss: 2.215813398361206
Validation loss: 2.0864780026097454

Epoch: 6| Step: 3
Training loss: 1.3998799324035645
Validation loss: 2.1231944919914327

Epoch: 6| Step: 4
Training loss: 1.6684026718139648
Validation loss: 2.141255876069428

Epoch: 6| Step: 5
Training loss: 1.700547695159912
Validation loss: 2.1198770666635163

Epoch: 6| Step: 6
Training loss: 2.231890916824341
Validation loss: 2.08986238766742

Epoch: 6| Step: 7
Training loss: 1.6906468868255615
Validation loss: 2.0837795272950204

Epoch: 6| Step: 8
Training loss: 1.8217239379882812
Validation loss: 2.0728701301800307

Epoch: 6| Step: 9
Training loss: 1.2771168947219849
Validation loss: 2.12346181690052

Epoch: 6| Step: 10
Training loss: 2.368800640106201
Validation loss: 2.0687685948546215

Epoch: 6| Step: 11
Training loss: 1.674756407737732
Validation loss: 2.097766609602077

Epoch: 6| Step: 12
Training loss: 1.339080810546875
Validation loss: 2.1163198588996806

Epoch: 6| Step: 13
Training loss: 1.7728402614593506
Validation loss: 2.1183603245724916

Epoch: 363| Step: 0
Training loss: 1.2657099962234497
Validation loss: 2.1073834280813895

Epoch: 6| Step: 1
Training loss: 2.2366058826446533
Validation loss: 2.0791678967014438

Epoch: 6| Step: 2
Training loss: 1.9542815685272217
Validation loss: 2.0759679348238054

Epoch: 6| Step: 3
Training loss: 1.2138442993164062
Validation loss: 2.110885852126665

Epoch: 6| Step: 4
Training loss: 1.8682646751403809
Validation loss: 2.1416963044033257

Epoch: 6| Step: 5
Training loss: 1.072035789489746
Validation loss: 2.109194986281856

Epoch: 6| Step: 6
Training loss: 2.0296099185943604
Validation loss: 2.1115858990658998

Epoch: 6| Step: 7
Training loss: 2.4800033569335938
Validation loss: 2.1173790911192536

Epoch: 6| Step: 8
Training loss: 1.8963342905044556
Validation loss: 2.118578892882152

Epoch: 6| Step: 9
Training loss: 1.884670615196228
Validation loss: 2.156674413270848

Epoch: 6| Step: 10
Training loss: 2.1982619762420654
Validation loss: 2.145051215284614

Epoch: 6| Step: 11
Training loss: 1.4953430891036987
Validation loss: 2.1213705578157978

Epoch: 6| Step: 12
Training loss: 2.213804006576538
Validation loss: 2.127099060243176

Epoch: 6| Step: 13
Training loss: 1.9544906616210938
Validation loss: 2.1270107582051265

Epoch: 364| Step: 0
Training loss: 2.2339584827423096
Validation loss: 2.1392457049380065

Epoch: 6| Step: 1
Training loss: 1.5865176916122437
Validation loss: 2.1272689809081373

Epoch: 6| Step: 2
Training loss: 1.2650883197784424
Validation loss: 2.1088506560171805

Epoch: 6| Step: 3
Training loss: 2.553140640258789
Validation loss: 2.098092779036491

Epoch: 6| Step: 4
Training loss: 2.025347948074341
Validation loss: 2.0929919763277938

Epoch: 6| Step: 5
Training loss: 1.7419233322143555
Validation loss: 2.1429944730574086

Epoch: 6| Step: 6
Training loss: 2.329111099243164
Validation loss: 2.130873680114746

Epoch: 6| Step: 7
Training loss: 1.8630084991455078
Validation loss: 2.134511770740632

Epoch: 6| Step: 8
Training loss: 2.069026470184326
Validation loss: 2.1468981927441013

Epoch: 6| Step: 9
Training loss: 1.6291534900665283
Validation loss: 2.14381149507338

Epoch: 6| Step: 10
Training loss: 1.6566846370697021
Validation loss: 2.109352022088984

Epoch: 6| Step: 11
Training loss: 1.4529740810394287
Validation loss: 2.15432894486253

Epoch: 6| Step: 12
Training loss: 1.5107789039611816
Validation loss: 2.106721276878029

Epoch: 6| Step: 13
Training loss: 1.3580503463745117
Validation loss: 2.0837396639649586

Epoch: 365| Step: 0
Training loss: 1.6222914457321167
Validation loss: 2.0958270770247265

Epoch: 6| Step: 1
Training loss: 1.6978739500045776
Validation loss: 2.100246278188562

Epoch: 6| Step: 2
Training loss: 1.2658195495605469
Validation loss: 2.1011113838482927

Epoch: 6| Step: 3
Training loss: 1.3755097389221191
Validation loss: 2.1278507530048327

Epoch: 6| Step: 4
Training loss: 1.4758151769638062
Validation loss: 2.0761846239848802

Epoch: 6| Step: 5
Training loss: 2.3485236167907715
Validation loss: 2.0720698474555888

Epoch: 6| Step: 6
Training loss: 2.304295539855957
Validation loss: 2.075646536324614

Epoch: 6| Step: 7
Training loss: 2.2628843784332275
Validation loss: 2.069037002901877

Epoch: 6| Step: 8
Training loss: 2.5041587352752686
Validation loss: 2.092932220428221

Epoch: 6| Step: 9
Training loss: 1.8491971492767334
Validation loss: 2.0818654542328208

Epoch: 6| Step: 10
Training loss: 1.2954764366149902
Validation loss: 2.088630607051234

Epoch: 6| Step: 11
Training loss: 1.6383371353149414
Validation loss: 2.060183153357557

Epoch: 6| Step: 12
Training loss: 2.2793965339660645
Validation loss: 2.086622299686555

Epoch: 6| Step: 13
Training loss: 1.8277519941329956
Validation loss: 2.1127896103807675

Epoch: 366| Step: 0
Training loss: 2.7818336486816406
Validation loss: 2.081407070159912

Epoch: 6| Step: 1
Training loss: 1.2566696405410767
Validation loss: 2.111363390440582

Epoch: 6| Step: 2
Training loss: 1.8193438053131104
Validation loss: 2.098245125944896

Epoch: 6| Step: 3
Training loss: 1.4824491739273071
Validation loss: 2.119383899114465

Epoch: 6| Step: 4
Training loss: 2.2460575103759766
Validation loss: 2.1315071685339815

Epoch: 6| Step: 5
Training loss: 1.501841425895691
Validation loss: 2.101602926049181

Epoch: 6| Step: 6
Training loss: 1.864591360092163
Validation loss: 2.148907079491564

Epoch: 6| Step: 7
Training loss: 1.9205710887908936
Validation loss: 2.0897570604919107

Epoch: 6| Step: 8
Training loss: 1.66118323802948
Validation loss: 2.137146185803157

Epoch: 6| Step: 9
Training loss: 1.4546751976013184
Validation loss: 2.1249023816918813

Epoch: 6| Step: 10
Training loss: 1.9206910133361816
Validation loss: 2.132984302377188

Epoch: 6| Step: 11
Training loss: 1.2740817070007324
Validation loss: 2.115604108379733

Epoch: 6| Step: 12
Training loss: 2.152108669281006
Validation loss: 2.0991618274360575

Epoch: 6| Step: 13
Training loss: 1.8984990119934082
Validation loss: 2.128374863696355

Epoch: 367| Step: 0
Training loss: 2.2424726486206055
Validation loss: 2.124416446173063

Epoch: 6| Step: 1
Training loss: 1.543442964553833
Validation loss: 2.141196004806026

Epoch: 6| Step: 2
Training loss: 1.8615553379058838
Validation loss: 2.127399407407289

Epoch: 6| Step: 3
Training loss: 1.5858960151672363
Validation loss: 2.1229530457527406

Epoch: 6| Step: 4
Training loss: 2.144273042678833
Validation loss: 2.149428936742967

Epoch: 6| Step: 5
Training loss: 0.9714308977127075
Validation loss: 2.122324692305698

Epoch: 6| Step: 6
Training loss: 2.1119766235351562
Validation loss: 2.0949402073378205

Epoch: 6| Step: 7
Training loss: 1.5176210403442383
Validation loss: 2.099346025015718

Epoch: 6| Step: 8
Training loss: 1.7866270542144775
Validation loss: 2.1492289022732805

Epoch: 6| Step: 9
Training loss: 1.7313649654388428
Validation loss: 2.0991045608315417

Epoch: 6| Step: 10
Training loss: 2.1133692264556885
Validation loss: 2.1078324779387443

Epoch: 6| Step: 11
Training loss: 2.0850870609283447
Validation loss: 2.1244730872492634

Epoch: 6| Step: 12
Training loss: 2.0479516983032227
Validation loss: 2.1425487713147233

Epoch: 6| Step: 13
Training loss: 1.139777660369873
Validation loss: 2.145560141532652

Epoch: 368| Step: 0
Training loss: 1.9919538497924805
Validation loss: 2.074072740411246

Epoch: 6| Step: 1
Training loss: 1.0872180461883545
Validation loss: 2.0940663199270926

Epoch: 6| Step: 2
Training loss: 1.9379141330718994
Validation loss: 2.0816495059638895

Epoch: 6| Step: 3
Training loss: 2.2327027320861816
Validation loss: 2.1562612569460304

Epoch: 6| Step: 4
Training loss: 2.3394625186920166
Validation loss: 2.092271738154914

Epoch: 6| Step: 5
Training loss: 1.4545676708221436
Validation loss: 2.107928099170808

Epoch: 6| Step: 6
Training loss: 1.984432578086853
Validation loss: 2.126351228324316

Epoch: 6| Step: 7
Training loss: 1.4903814792633057
Validation loss: 2.084637200960549

Epoch: 6| Step: 8
Training loss: 1.6704366207122803
Validation loss: 2.1280878820726947

Epoch: 6| Step: 9
Training loss: 2.0180320739746094
Validation loss: 2.089528195319637

Epoch: 6| Step: 10
Training loss: 2.367581367492676
Validation loss: 2.0432880745139173

Epoch: 6| Step: 11
Training loss: 1.818174123764038
Validation loss: 2.13550191925418

Epoch: 6| Step: 12
Training loss: 1.4913134574890137
Validation loss: 2.1264111406059674

Epoch: 6| Step: 13
Training loss: 1.6817326545715332
Validation loss: 2.123659533839072

Epoch: 369| Step: 0
Training loss: 1.443821668624878
Validation loss: 2.1032796072703537

Epoch: 6| Step: 1
Training loss: 2.331489086151123
Validation loss: 2.0813403309032483

Epoch: 6| Step: 2
Training loss: 2.6199612617492676
Validation loss: 2.14019872296241

Epoch: 6| Step: 3
Training loss: 2.181985855102539
Validation loss: 2.1073733311827465

Epoch: 6| Step: 4
Training loss: 1.5019463300704956
Validation loss: 2.1271342564654607

Epoch: 6| Step: 5
Training loss: 1.999433994293213
Validation loss: 2.0969464701990925

Epoch: 6| Step: 6
Training loss: 1.6015632152557373
Validation loss: 2.118385902015112

Epoch: 6| Step: 7
Training loss: 1.3267018795013428
Validation loss: 2.116825578033283

Epoch: 6| Step: 8
Training loss: 1.0298757553100586
Validation loss: 2.1160231533870903

Epoch: 6| Step: 9
Training loss: 1.7181003093719482
Validation loss: 2.1499636724431026

Epoch: 6| Step: 10
Training loss: 2.4822120666503906
Validation loss: 2.12367598472103

Epoch: 6| Step: 11
Training loss: 1.2595034837722778
Validation loss: 2.084680900778822

Epoch: 6| Step: 12
Training loss: 2.541780948638916
Validation loss: 2.1329726865214687

Epoch: 6| Step: 13
Training loss: 1.1430705785751343
Validation loss: 2.1450094484513804

Epoch: 370| Step: 0
Training loss: 1.6496237516403198
Validation loss: 2.1065541210994927

Epoch: 6| Step: 1
Training loss: 2.03299617767334
Validation loss: 2.1163672913787184

Epoch: 6| Step: 2
Training loss: 1.7268725633621216
Validation loss: 2.1333881655047016

Epoch: 6| Step: 3
Training loss: 1.5545284748077393
Validation loss: 2.0825716500641196

Epoch: 6| Step: 4
Training loss: 2.018620729446411
Validation loss: 2.135490289298437

Epoch: 6| Step: 5
Training loss: 1.3449609279632568
Validation loss: 2.1240545190790647

Epoch: 6| Step: 6
Training loss: 1.8640245199203491
Validation loss: 2.113948691275812

Epoch: 6| Step: 7
Training loss: 2.001516580581665
Validation loss: 2.0638621955789547

Epoch: 6| Step: 8
Training loss: 2.4828004837036133
Validation loss: 2.102938013692056

Epoch: 6| Step: 9
Training loss: 1.6486234664916992
Validation loss: 2.0902161316205095

Epoch: 6| Step: 10
Training loss: 1.3324685096740723
Validation loss: 2.0878428002839446

Epoch: 6| Step: 11
Training loss: 1.8616812229156494
Validation loss: 2.112834915038078

Epoch: 6| Step: 12
Training loss: 2.1337552070617676
Validation loss: 2.1334001838520007

Epoch: 6| Step: 13
Training loss: 1.546421766281128
Validation loss: 2.116346954017557

Epoch: 371| Step: 0
Training loss: 1.9658088684082031
Validation loss: 2.070856004632929

Epoch: 6| Step: 1
Training loss: 1.623155951499939
Validation loss: 2.133960546985749

Epoch: 6| Step: 2
Training loss: 1.791586995124817
Validation loss: 2.0973726049546273

Epoch: 6| Step: 3
Training loss: 1.930689811706543
Validation loss: 2.1213126464556624

Epoch: 6| Step: 4
Training loss: 1.8490337133407593
Validation loss: 2.1418796969998266

Epoch: 6| Step: 5
Training loss: 1.2126798629760742
Validation loss: 2.1278140288527294

Epoch: 6| Step: 6
Training loss: 2.1562843322753906
Validation loss: 2.1467528625201155

Epoch: 6| Step: 7
Training loss: 0.983314573764801
Validation loss: 2.1120561886859197

Epoch: 6| Step: 8
Training loss: 2.0420374870300293
Validation loss: 2.108011071399976

Epoch: 6| Step: 9
Training loss: 2.338361978530884
Validation loss: 2.1011620336963284

Epoch: 6| Step: 10
Training loss: 1.8541922569274902
Validation loss: 2.1143861380956506

Epoch: 6| Step: 11
Training loss: 1.2908779382705688
Validation loss: 2.1140225164351927

Epoch: 6| Step: 12
Training loss: 1.6770782470703125
Validation loss: 2.0946924122430945

Epoch: 6| Step: 13
Training loss: 2.6824123859405518
Validation loss: 2.0857918211208877

Epoch: 372| Step: 0
Training loss: 1.883692979812622
Validation loss: 2.1112661515512774

Epoch: 6| Step: 1
Training loss: 1.8438392877578735
Validation loss: 2.1245619737973778

Epoch: 6| Step: 2
Training loss: 1.5912423133850098
Validation loss: 2.1357764351752495

Epoch: 6| Step: 3
Training loss: 2.2167484760284424
Validation loss: 2.1278426749731905

Epoch: 6| Step: 4
Training loss: 2.237708330154419
Validation loss: 2.111288703897948

Epoch: 6| Step: 5
Training loss: 2.1909430027008057
Validation loss: 2.149143868877042

Epoch: 6| Step: 6
Training loss: 1.460308313369751
Validation loss: 2.133636878382775

Epoch: 6| Step: 7
Training loss: 1.631525993347168
Validation loss: 2.0827750787940076

Epoch: 6| Step: 8
Training loss: 1.8172158002853394
Validation loss: 2.1174533213338544

Epoch: 6| Step: 9
Training loss: 1.6863477230072021
Validation loss: 2.1356785438394033

Epoch: 6| Step: 10
Training loss: 1.7405989170074463
Validation loss: 2.1251712768308577

Epoch: 6| Step: 11
Training loss: 1.0771981477737427
Validation loss: 2.1255225481525546

Epoch: 6| Step: 12
Training loss: 2.089263677597046
Validation loss: 2.1172549109305105

Epoch: 6| Step: 13
Training loss: 1.809195637702942
Validation loss: 2.11945895097589

Epoch: 373| Step: 0
Training loss: 1.8549339771270752
Validation loss: 2.1393962201251777

Epoch: 6| Step: 1
Training loss: 2.6321828365325928
Validation loss: 2.134198537436865

Epoch: 6| Step: 2
Training loss: 1.612267017364502
Validation loss: 2.117307404036163

Epoch: 6| Step: 3
Training loss: 2.0864052772521973
Validation loss: 2.12289535742934

Epoch: 6| Step: 4
Training loss: 1.3288660049438477
Validation loss: 2.1046684736846597

Epoch: 6| Step: 5
Training loss: 0.9110891819000244
Validation loss: 2.097038827916627

Epoch: 6| Step: 6
Training loss: 1.3743536472320557
Validation loss: 2.0672239616353023

Epoch: 6| Step: 7
Training loss: 2.2241036891937256
Validation loss: 2.090685341947822

Epoch: 6| Step: 8
Training loss: 1.8153424263000488
Validation loss: 2.070868399835402

Epoch: 6| Step: 9
Training loss: 1.4954566955566406
Validation loss: 2.1036973281573226

Epoch: 6| Step: 10
Training loss: 1.843732237815857
Validation loss: 2.087986848687613

Epoch: 6| Step: 11
Training loss: 1.7924723625183105
Validation loss: 2.1001753345612557

Epoch: 6| Step: 12
Training loss: 1.826098084449768
Validation loss: 2.0804492196729107

Epoch: 6| Step: 13
Training loss: 2.9046943187713623
Validation loss: 2.1082640783761137

Epoch: 374| Step: 0
Training loss: 2.308208465576172
Validation loss: 2.1023342327405046

Epoch: 6| Step: 1
Training loss: 1.723456621170044
Validation loss: 2.1157623516616

Epoch: 6| Step: 2
Training loss: 1.9910931587219238
Validation loss: 2.139620122089181

Epoch: 6| Step: 3
Training loss: 1.8618210554122925
Validation loss: 2.113903331500228

Epoch: 6| Step: 4
Training loss: 1.3828699588775635
Validation loss: 2.152219203210646

Epoch: 6| Step: 5
Training loss: 2.022510528564453
Validation loss: 2.17448664224276

Epoch: 6| Step: 6
Training loss: 1.8319529294967651
Validation loss: 2.1670533482746412

Epoch: 6| Step: 7
Training loss: 1.9206860065460205
Validation loss: 2.1416780461547194

Epoch: 6| Step: 8
Training loss: 2.025887966156006
Validation loss: 2.176194388379333

Epoch: 6| Step: 9
Training loss: 1.178968906402588
Validation loss: 2.157465365625197

Epoch: 6| Step: 10
Training loss: 2.170055866241455
Validation loss: 2.1999822713995494

Epoch: 6| Step: 11
Training loss: 1.7518055438995361
Validation loss: 2.1332999275576685

Epoch: 6| Step: 12
Training loss: 1.2998765707015991
Validation loss: 2.135320318642483

Epoch: 6| Step: 13
Training loss: 1.8637654781341553
Validation loss: 2.139232858534782

Epoch: 375| Step: 0
Training loss: 1.6613733768463135
Validation loss: 2.1575573157238703

Epoch: 6| Step: 1
Training loss: 1.0799763202667236
Validation loss: 2.130034931244389

Epoch: 6| Step: 2
Training loss: 1.6751184463500977
Validation loss: 2.128579919056226

Epoch: 6| Step: 3
Training loss: 0.9924953579902649
Validation loss: 2.1141254004611763

Epoch: 6| Step: 4
Training loss: 2.322258710861206
Validation loss: 2.110057246300482

Epoch: 6| Step: 5
Training loss: 2.053219795227051
Validation loss: 2.096143299533475

Epoch: 6| Step: 6
Training loss: 2.4346799850463867
Validation loss: 2.0772788768173545

Epoch: 6| Step: 7
Training loss: 2.054687023162842
Validation loss: 2.1101096060968216

Epoch: 6| Step: 8
Training loss: 1.5731430053710938
Validation loss: 2.097305446542719

Epoch: 6| Step: 9
Training loss: 2.3185276985168457
Validation loss: 2.1197535773759246

Epoch: 6| Step: 10
Training loss: 1.8814632892608643
Validation loss: 2.1339796281629995

Epoch: 6| Step: 11
Training loss: 1.271573781967163
Validation loss: 2.061441772727556

Epoch: 6| Step: 12
Training loss: 2.091259002685547
Validation loss: 2.081974152595766

Epoch: 6| Step: 13
Training loss: 2.2489264011383057
Validation loss: 2.0812559768717778

Epoch: 376| Step: 0
Training loss: 1.51023268699646
Validation loss: 2.1008870858018116

Epoch: 6| Step: 1
Training loss: 1.5494760274887085
Validation loss: 2.11463071966684

Epoch: 6| Step: 2
Training loss: 1.785372257232666
Validation loss: 2.125839840981268

Epoch: 6| Step: 3
Training loss: 2.132704257965088
Validation loss: 2.114095009783263

Epoch: 6| Step: 4
Training loss: 2.179868698120117
Validation loss: 2.1079253227479997

Epoch: 6| Step: 5
Training loss: 2.0727498531341553
Validation loss: 2.0784690328823623

Epoch: 6| Step: 6
Training loss: 2.281560182571411
Validation loss: 2.127162436003326

Epoch: 6| Step: 7
Training loss: 1.6725552082061768
Validation loss: 2.1169634711357856

Epoch: 6| Step: 8
Training loss: 1.6727781295776367
Validation loss: 2.1210646065332557

Epoch: 6| Step: 9
Training loss: 2.3799054622650146
Validation loss: 2.130285738616861

Epoch: 6| Step: 10
Training loss: 1.6319425106048584
Validation loss: 2.0788200529672767

Epoch: 6| Step: 11
Training loss: 1.242414951324463
Validation loss: 2.146967536659651

Epoch: 6| Step: 12
Training loss: 1.2813456058502197
Validation loss: 2.134056511745658

Epoch: 6| Step: 13
Training loss: 1.5278055667877197
Validation loss: 2.148501201342511

Epoch: 377| Step: 0
Training loss: 0.9049784541130066
Validation loss: 2.112735112508138

Epoch: 6| Step: 1
Training loss: 1.858454704284668
Validation loss: 2.1248793986535843

Epoch: 6| Step: 2
Training loss: 2.0060741901397705
Validation loss: 2.1206733718995125

Epoch: 6| Step: 3
Training loss: 2.5611510276794434
Validation loss: 2.156650891868017

Epoch: 6| Step: 4
Training loss: 1.6649812459945679
Validation loss: 2.0911312539090394

Epoch: 6| Step: 5
Training loss: 1.4761452674865723
Validation loss: 2.1199920946551907

Epoch: 6| Step: 6
Training loss: 2.2390568256378174
Validation loss: 2.171344300752045

Epoch: 6| Step: 7
Training loss: 1.4718586206436157
Validation loss: 2.147806444475728

Epoch: 6| Step: 8
Training loss: 1.6245622634887695
Validation loss: 2.1603480590287076

Epoch: 6| Step: 9
Training loss: 2.091177463531494
Validation loss: 2.114982687016969

Epoch: 6| Step: 10
Training loss: 2.0156946182250977
Validation loss: 2.113213082795502

Epoch: 6| Step: 11
Training loss: 2.200775384902954
Validation loss: 2.143030071771273

Epoch: 6| Step: 12
Training loss: 1.708667278289795
Validation loss: 2.1383602747353176

Epoch: 6| Step: 13
Training loss: 1.4842733144760132
Validation loss: 2.0937108224438084

Epoch: 378| Step: 0
Training loss: 0.9782509803771973
Validation loss: 2.104737030562534

Epoch: 6| Step: 1
Training loss: 1.7697415351867676
Validation loss: 2.110117825128699

Epoch: 6| Step: 2
Training loss: 1.575792670249939
Validation loss: 2.099207047493227

Epoch: 6| Step: 3
Training loss: 1.860350251197815
Validation loss: 2.1422998623181413

Epoch: 6| Step: 4
Training loss: 1.8277690410614014
Validation loss: 2.091648009515578

Epoch: 6| Step: 5
Training loss: 1.765372633934021
Validation loss: 2.082968432416198

Epoch: 6| Step: 6
Training loss: 1.8811781406402588
Validation loss: 2.082443311650266

Epoch: 6| Step: 7
Training loss: 1.434316635131836
Validation loss: 2.115330047504876

Epoch: 6| Step: 8
Training loss: 1.685306429862976
Validation loss: 2.0821346006085797

Epoch: 6| Step: 9
Training loss: 1.777268886566162
Validation loss: 2.1064112391523135

Epoch: 6| Step: 10
Training loss: 2.3093061447143555
Validation loss: 2.1377490681986653

Epoch: 6| Step: 11
Training loss: 2.688561201095581
Validation loss: 2.1220352752234346

Epoch: 6| Step: 12
Training loss: 1.9221601486206055
Validation loss: 2.117630849602402

Epoch: 6| Step: 13
Training loss: 1.2140617370605469
Validation loss: 2.121237534348683

Epoch: 379| Step: 0
Training loss: 1.933019757270813
Validation loss: 2.099986204537012

Epoch: 6| Step: 1
Training loss: 1.5599327087402344
Validation loss: 2.1229301319327405

Epoch: 6| Step: 2
Training loss: 1.4976667165756226
Validation loss: 2.0990821110304965

Epoch: 6| Step: 3
Training loss: 1.4984221458435059
Validation loss: 2.139061499667424

Epoch: 6| Step: 4
Training loss: 2.0076446533203125
Validation loss: 2.092178665181642

Epoch: 6| Step: 5
Training loss: 2.1309452056884766
Validation loss: 2.1176925602779595

Epoch: 6| Step: 6
Training loss: 1.888056993484497
Validation loss: 2.1284606277301745

Epoch: 6| Step: 7
Training loss: 1.8522312641143799
Validation loss: 2.1461963704837266

Epoch: 6| Step: 8
Training loss: 2.262136697769165
Validation loss: 2.1296141711614465

Epoch: 6| Step: 9
Training loss: 1.3478171825408936
Validation loss: 2.1416330017069334

Epoch: 6| Step: 10
Training loss: 1.696046233177185
Validation loss: 2.1398583996680474

Epoch: 6| Step: 11
Training loss: 2.1341662406921387
Validation loss: 2.168335219865204

Epoch: 6| Step: 12
Training loss: 1.5420715808868408
Validation loss: 2.145228676898505

Epoch: 6| Step: 13
Training loss: 1.521653652191162
Validation loss: 2.1587624626774944

Epoch: 380| Step: 0
Training loss: 1.7325685024261475
Validation loss: 2.1216900399936143

Epoch: 6| Step: 1
Training loss: 1.3881969451904297
Validation loss: 2.131035115129204

Epoch: 6| Step: 2
Training loss: 1.7030625343322754
Validation loss: 2.133971122003371

Epoch: 6| Step: 3
Training loss: 1.5781561136245728
Validation loss: 2.0826766234572216

Epoch: 6| Step: 4
Training loss: 2.013087511062622
Validation loss: 2.1164380811875865

Epoch: 6| Step: 5
Training loss: 1.069928765296936
Validation loss: 2.0885066909174763

Epoch: 6| Step: 6
Training loss: 1.972385048866272
Validation loss: 2.111503408801171

Epoch: 6| Step: 7
Training loss: 1.9238872528076172
Validation loss: 2.061138323558274

Epoch: 6| Step: 8
Training loss: 2.0460052490234375
Validation loss: 2.1062529920249857

Epoch: 6| Step: 9
Training loss: 1.7985992431640625
Validation loss: 2.117200618149132

Epoch: 6| Step: 10
Training loss: 1.5919594764709473
Validation loss: 2.1225907277035456

Epoch: 6| Step: 11
Training loss: 2.432582139968872
Validation loss: 2.116441934339462

Epoch: 6| Step: 12
Training loss: 2.1231651306152344
Validation loss: 2.1004752215518745

Epoch: 6| Step: 13
Training loss: 1.4685215950012207
Validation loss: 2.102634537604547

Epoch: 381| Step: 0
Training loss: 2.0758533477783203
Validation loss: 2.1542490579748668

Epoch: 6| Step: 1
Training loss: 1.7944071292877197
Validation loss: 2.112655185884045

Epoch: 6| Step: 2
Training loss: 1.8734654188156128
Validation loss: 2.125128374304823

Epoch: 6| Step: 3
Training loss: 1.828378677368164
Validation loss: 2.0853217417193997

Epoch: 6| Step: 4
Training loss: 2.4970312118530273
Validation loss: 2.1142229700601227

Epoch: 6| Step: 5
Training loss: 2.0025315284729004
Validation loss: 2.1197919602035196

Epoch: 6| Step: 6
Training loss: 1.2476686239242554
Validation loss: 2.1082372639768865

Epoch: 6| Step: 7
Training loss: 1.3438873291015625
Validation loss: 2.111212174097697

Epoch: 6| Step: 8
Training loss: 1.2553327083587646
Validation loss: 2.103066336724066

Epoch: 6| Step: 9
Training loss: 1.61025071144104
Validation loss: 2.110068077682167

Epoch: 6| Step: 10
Training loss: 2.189188241958618
Validation loss: 2.0867241377471597

Epoch: 6| Step: 11
Training loss: 1.2904658317565918
Validation loss: 2.1535672628751366

Epoch: 6| Step: 12
Training loss: 2.031167507171631
Validation loss: 2.116615952983979

Epoch: 6| Step: 13
Training loss: 2.3264541625976562
Validation loss: 2.1343247095743814

Epoch: 382| Step: 0
Training loss: 2.0537166595458984
Validation loss: 2.097455042664723

Epoch: 6| Step: 1
Training loss: 2.5574471950531006
Validation loss: 2.091933540118638

Epoch: 6| Step: 2
Training loss: 1.913928508758545
Validation loss: 2.126768660801713

Epoch: 6| Step: 3
Training loss: 1.0727193355560303
Validation loss: 2.1393023460142073

Epoch: 6| Step: 4
Training loss: 2.2306466102600098
Validation loss: 2.135481278101603

Epoch: 6| Step: 5
Training loss: 1.6984055042266846
Validation loss: 2.089612332723474

Epoch: 6| Step: 6
Training loss: 1.9468178749084473
Validation loss: 2.1325069512090375

Epoch: 6| Step: 7
Training loss: 1.7806284427642822
Validation loss: 2.118961223991968

Epoch: 6| Step: 8
Training loss: 1.6676928997039795
Validation loss: 2.0855042934417725

Epoch: 6| Step: 9
Training loss: 1.2650132179260254
Validation loss: 2.1258241938006495

Epoch: 6| Step: 10
Training loss: 1.2176060676574707
Validation loss: 2.138657731394614

Epoch: 6| Step: 11
Training loss: 1.5204813480377197
Validation loss: 2.1512450146418747

Epoch: 6| Step: 12
Training loss: 2.3675405979156494
Validation loss: 2.138804321647972

Epoch: 6| Step: 13
Training loss: 1.5506362915039062
Validation loss: 2.1393840441139798

Epoch: 383| Step: 0
Training loss: 1.8622251749038696
Validation loss: 2.1314824755473802

Epoch: 6| Step: 1
Training loss: 2.6470398902893066
Validation loss: 2.0869907038186186

Epoch: 6| Step: 2
Training loss: 1.5571374893188477
Validation loss: 2.125258961031514

Epoch: 6| Step: 3
Training loss: 1.193995475769043
Validation loss: 2.1544650446984077

Epoch: 6| Step: 4
Training loss: 1.0302931070327759
Validation loss: 2.1060875256856284

Epoch: 6| Step: 5
Training loss: 2.435370445251465
Validation loss: 2.1623139637772755

Epoch: 6| Step: 6
Training loss: 1.9894658327102661
Validation loss: 2.0979054281788487

Epoch: 6| Step: 7
Training loss: 0.9658986926078796
Validation loss: 2.109884677394744

Epoch: 6| Step: 8
Training loss: 1.4402337074279785
Validation loss: 2.1552344599077777

Epoch: 6| Step: 9
Training loss: 1.4011380672454834
Validation loss: 2.1798073450724282

Epoch: 6| Step: 10
Training loss: 1.9672808647155762
Validation loss: 2.1301187648568103

Epoch: 6| Step: 11
Training loss: 2.475466728210449
Validation loss: 2.1470416028012513

Epoch: 6| Step: 12
Training loss: 2.1510448455810547
Validation loss: 2.1310649635971233

Epoch: 6| Step: 13
Training loss: 1.4225794076919556
Validation loss: 2.1428386626705045

Epoch: 384| Step: 0
Training loss: 1.8949133157730103
Validation loss: 2.091205632814797

Epoch: 6| Step: 1
Training loss: 1.6090941429138184
Validation loss: 2.1354512501788396

Epoch: 6| Step: 2
Training loss: 1.6053917407989502
Validation loss: 2.1239700778838126

Epoch: 6| Step: 3
Training loss: 1.4565833806991577
Validation loss: 2.1060798219455186

Epoch: 6| Step: 4
Training loss: 1.7720930576324463
Validation loss: 2.063771919537616

Epoch: 6| Step: 5
Training loss: 1.9445302486419678
Validation loss: 2.0492739831247637

Epoch: 6| Step: 6
Training loss: 2.1345367431640625
Validation loss: 2.1221063367782103

Epoch: 6| Step: 7
Training loss: 2.654179811477661
Validation loss: 2.1432960546144875

Epoch: 6| Step: 8
Training loss: 1.9348366260528564
Validation loss: 2.08045914224399

Epoch: 6| Step: 9
Training loss: 1.902918815612793
Validation loss: 2.0805371038375364

Epoch: 6| Step: 10
Training loss: 1.473796010017395
Validation loss: 2.095979652097148

Epoch: 6| Step: 11
Training loss: 1.4647343158721924
Validation loss: 2.0943976038245746

Epoch: 6| Step: 12
Training loss: 1.3860700130462646
Validation loss: 2.150291327507265

Epoch: 6| Step: 13
Training loss: 0.9795702695846558
Validation loss: 2.1048941227697555

Epoch: 385| Step: 0
Training loss: 1.4427292346954346
Validation loss: 2.104098337952809

Epoch: 6| Step: 1
Training loss: 1.674011468887329
Validation loss: 2.109128023988457

Epoch: 6| Step: 2
Training loss: 1.4583362340927124
Validation loss: 2.0990690428723573

Epoch: 6| Step: 3
Training loss: 1.6726030111312866
Validation loss: 2.1183642828336327

Epoch: 6| Step: 4
Training loss: 2.075946569442749
Validation loss: 2.1344968426612114

Epoch: 6| Step: 5
Training loss: 2.167482852935791
Validation loss: 2.120736070858535

Epoch: 6| Step: 6
Training loss: 1.4262140989303589
Validation loss: 2.107293031548941

Epoch: 6| Step: 7
Training loss: 1.9323201179504395
Validation loss: 2.126389385551535

Epoch: 6| Step: 8
Training loss: 2.4569287300109863
Validation loss: 2.1307209999330583

Epoch: 6| Step: 9
Training loss: 1.7017977237701416
Validation loss: 2.1349561342629055

Epoch: 6| Step: 10
Training loss: 1.8814854621887207
Validation loss: 2.11398454635374

Epoch: 6| Step: 11
Training loss: 1.542409896850586
Validation loss: 2.131961017526606

Epoch: 6| Step: 12
Training loss: 1.665693759918213
Validation loss: 2.0885441303253174

Epoch: 6| Step: 13
Training loss: 1.8092079162597656
Validation loss: 2.1595663255260837

Epoch: 386| Step: 0
Training loss: 1.101597547531128
Validation loss: 2.128635770531111

Epoch: 6| Step: 1
Training loss: 1.5499074459075928
Validation loss: 2.1404136252659622

Epoch: 6| Step: 2
Training loss: 1.4707738161087036
Validation loss: 2.1282497862333893

Epoch: 6| Step: 3
Training loss: 1.7889063358306885
Validation loss: 2.146859306161122

Epoch: 6| Step: 4
Training loss: 2.0643703937530518
Validation loss: 2.1403129998073784

Epoch: 6| Step: 5
Training loss: 1.9461302757263184
Validation loss: 2.1262332188185824

Epoch: 6| Step: 6
Training loss: 1.791790246963501
Validation loss: 2.1301623172657465

Epoch: 6| Step: 7
Training loss: 2.451436996459961
Validation loss: 2.1535669488291584

Epoch: 6| Step: 8
Training loss: 1.937058448791504
Validation loss: 2.1059377424178587

Epoch: 6| Step: 9
Training loss: 1.2666239738464355
Validation loss: 2.1147087517605034

Epoch: 6| Step: 10
Training loss: 2.247116804122925
Validation loss: 2.130930792900824

Epoch: 6| Step: 11
Training loss: 1.5376315116882324
Validation loss: 2.133962926044259

Epoch: 6| Step: 12
Training loss: 1.8602081537246704
Validation loss: 2.114295459562732

Epoch: 6| Step: 13
Training loss: 1.412426471710205
Validation loss: 2.125763862363754

Epoch: 387| Step: 0
Training loss: 1.7122793197631836
Validation loss: 2.114834580370175

Epoch: 6| Step: 1
Training loss: 1.2558772563934326
Validation loss: 2.1095700751068773

Epoch: 6| Step: 2
Training loss: 1.8802762031555176
Validation loss: 2.1082053184509277

Epoch: 6| Step: 3
Training loss: 2.2700486183166504
Validation loss: 2.103300843187558

Epoch: 6| Step: 4
Training loss: 1.9611399173736572
Validation loss: 2.118630245167722

Epoch: 6| Step: 5
Training loss: 1.5623698234558105
Validation loss: 2.134186396034815

Epoch: 6| Step: 6
Training loss: 1.2358119487762451
Validation loss: 2.1615013563504784

Epoch: 6| Step: 7
Training loss: 2.0146658420562744
Validation loss: 2.1483337212634344

Epoch: 6| Step: 8
Training loss: 2.1836626529693604
Validation loss: 2.181178556975498

Epoch: 6| Step: 9
Training loss: 1.2520008087158203
Validation loss: 2.1013899695488716

Epoch: 6| Step: 10
Training loss: 1.9406230449676514
Validation loss: 2.1188109510688373

Epoch: 6| Step: 11
Training loss: 1.8261022567749023
Validation loss: 2.129945872932352

Epoch: 6| Step: 12
Training loss: 1.4027694463729858
Validation loss: 2.1159889903119815

Epoch: 6| Step: 13
Training loss: 2.296628713607788
Validation loss: 2.1226571772688176

Epoch: 388| Step: 0
Training loss: 2.1030211448669434
Validation loss: 2.116034212932792

Epoch: 6| Step: 1
Training loss: 1.4547500610351562
Validation loss: 2.083964765712779

Epoch: 6| Step: 2
Training loss: 2.041895866394043
Validation loss: 2.147372909771499

Epoch: 6| Step: 3
Training loss: 1.6789528131484985
Validation loss: 2.1331537974778043

Epoch: 6| Step: 4
Training loss: 1.906015157699585
Validation loss: 2.1527859510913974

Epoch: 6| Step: 5
Training loss: 1.9961154460906982
Validation loss: 2.146094088913292

Epoch: 6| Step: 6
Training loss: 1.505690097808838
Validation loss: 2.146677952940746

Epoch: 6| Step: 7
Training loss: 1.6415190696716309
Validation loss: 2.118518114089966

Epoch: 6| Step: 8
Training loss: 2.224104404449463
Validation loss: 2.137271842648906

Epoch: 6| Step: 9
Training loss: 1.6225903034210205
Validation loss: 2.1371484379614554

Epoch: 6| Step: 10
Training loss: 1.649367094039917
Validation loss: 2.104167640850108

Epoch: 6| Step: 11
Training loss: 1.2461782693862915
Validation loss: 2.139526556896907

Epoch: 6| Step: 12
Training loss: 2.1054327487945557
Validation loss: 2.156357252469627

Epoch: 6| Step: 13
Training loss: 1.3751325607299805
Validation loss: 2.082434949054513

Epoch: 389| Step: 0
Training loss: 2.2431468963623047
Validation loss: 2.1543705078863327

Epoch: 6| Step: 1
Training loss: 1.3845500946044922
Validation loss: 2.1255144765300136

Epoch: 6| Step: 2
Training loss: 1.6360620260238647
Validation loss: 2.1301445909725722

Epoch: 6| Step: 3
Training loss: 1.371890664100647
Validation loss: 2.110214876872237

Epoch: 6| Step: 4
Training loss: 1.8704497814178467
Validation loss: 2.149628399520792

Epoch: 6| Step: 5
Training loss: 2.7137560844421387
Validation loss: 2.1439252438083773

Epoch: 6| Step: 6
Training loss: 1.5566322803497314
Validation loss: 2.1691305662996028

Epoch: 6| Step: 7
Training loss: 1.176910161972046
Validation loss: 2.1161518443015312

Epoch: 6| Step: 8
Training loss: 1.9026256799697876
Validation loss: 2.1368117409367717

Epoch: 6| Step: 9
Training loss: 1.3476076126098633
Validation loss: 2.135395519195064

Epoch: 6| Step: 10
Training loss: 1.6901016235351562
Validation loss: 2.1010511588024836

Epoch: 6| Step: 11
Training loss: 1.9987359046936035
Validation loss: 2.122591281449923

Epoch: 6| Step: 12
Training loss: 1.80939781665802
Validation loss: 2.0806987106159167

Epoch: 6| Step: 13
Training loss: 1.1300705671310425
Validation loss: 2.12416741283991

Epoch: 390| Step: 0
Training loss: 1.6773405075073242
Validation loss: 2.1078624110068045

Epoch: 6| Step: 1
Training loss: 1.636863350868225
Validation loss: 2.1130066135878205

Epoch: 6| Step: 2
Training loss: 1.5722600221633911
Validation loss: 2.0668557536217476

Epoch: 6| Step: 3
Training loss: 1.8768073320388794
Validation loss: 2.101591758830573

Epoch: 6| Step: 4
Training loss: 2.1797423362731934
Validation loss: 2.1337457190277758

Epoch: 6| Step: 5
Training loss: 1.7902376651763916
Validation loss: 2.1137943870277813

Epoch: 6| Step: 6
Training loss: 2.4685823917388916
Validation loss: 2.1648639837900796

Epoch: 6| Step: 7
Training loss: 2.0463194847106934
Validation loss: 2.072066940287108

Epoch: 6| Step: 8
Training loss: 1.6429097652435303
Validation loss: 2.127609381111719

Epoch: 6| Step: 9
Training loss: 0.8979694843292236
Validation loss: 2.12397930442646

Epoch: 6| Step: 10
Training loss: 1.0396301746368408
Validation loss: 2.1329608450653734

Epoch: 6| Step: 11
Training loss: 1.9205453395843506
Validation loss: 2.1516201162850983

Epoch: 6| Step: 12
Training loss: 1.4929088354110718
Validation loss: 2.1038451117853962

Epoch: 6| Step: 13
Training loss: 2.0695645809173584
Validation loss: 2.1371245743125997

Epoch: 391| Step: 0
Training loss: 1.6340246200561523
Validation loss: 2.1530620859515284

Epoch: 6| Step: 1
Training loss: 2.085308074951172
Validation loss: 2.1367106514592327

Epoch: 6| Step: 2
Training loss: 1.4479682445526123
Validation loss: 2.158114117960776

Epoch: 6| Step: 3
Training loss: 1.870613694190979
Validation loss: 2.1243883435444166

Epoch: 6| Step: 4
Training loss: 1.740116834640503
Validation loss: 2.1862851445392897

Epoch: 6| Step: 5
Training loss: 1.2025532722473145
Validation loss: 2.1555907982651905

Epoch: 6| Step: 6
Training loss: 2.138140916824341
Validation loss: 2.1453943252563477

Epoch: 6| Step: 7
Training loss: 2.3118066787719727
Validation loss: 2.171315198303551

Epoch: 6| Step: 8
Training loss: 1.8147884607315063
Validation loss: 2.1373151220301145

Epoch: 6| Step: 9
Training loss: 1.6342958211898804
Validation loss: 2.1408261150442143

Epoch: 6| Step: 10
Training loss: 2.2260971069335938
Validation loss: 2.144169328033283

Epoch: 6| Step: 11
Training loss: 2.2279858589172363
Validation loss: 2.1161624795647076

Epoch: 6| Step: 12
Training loss: 0.819221019744873
Validation loss: 2.143701785354204

Epoch: 6| Step: 13
Training loss: 1.4280563592910767
Validation loss: 2.1235823451831775

Epoch: 392| Step: 0
Training loss: 1.4945091009140015
Validation loss: 2.1331922597782587

Epoch: 6| Step: 1
Training loss: 1.2829480171203613
Validation loss: 2.149115325302206

Epoch: 6| Step: 2
Training loss: 2.279289722442627
Validation loss: 2.1370789684275144

Epoch: 6| Step: 3
Training loss: 1.645524024963379
Validation loss: 2.131363891786145

Epoch: 6| Step: 4
Training loss: 1.3283137083053589
Validation loss: 2.125467167105726

Epoch: 6| Step: 5
Training loss: 1.726487398147583
Validation loss: 2.0861162793251777

Epoch: 6| Step: 6
Training loss: 1.963188648223877
Validation loss: 2.132430790573038

Epoch: 6| Step: 7
Training loss: 1.6410813331604004
Validation loss: 2.0912301309647097

Epoch: 6| Step: 8
Training loss: 1.9753391742706299
Validation loss: 2.107756183993432

Epoch: 6| Step: 9
Training loss: 2.0449929237365723
Validation loss: 2.0808715153765935

Epoch: 6| Step: 10
Training loss: 1.2010525465011597
Validation loss: 2.0713789283588366

Epoch: 6| Step: 11
Training loss: 2.348649263381958
Validation loss: 2.111110269382436

Epoch: 6| Step: 12
Training loss: 1.8917721509933472
Validation loss: 2.129412871535106

Epoch: 6| Step: 13
Training loss: 1.8414775133132935
Validation loss: 2.159354398327489

Epoch: 393| Step: 0
Training loss: 1.2110472917556763
Validation loss: 2.084374012485627

Epoch: 6| Step: 1
Training loss: 1.1383342742919922
Validation loss: 2.082637063918575

Epoch: 6| Step: 2
Training loss: 1.988431692123413
Validation loss: 2.1072824398676553

Epoch: 6| Step: 3
Training loss: 1.3446815013885498
Validation loss: 2.104469786408127

Epoch: 6| Step: 4
Training loss: 2.093080997467041
Validation loss: 2.122143260894283

Epoch: 6| Step: 5
Training loss: 2.260951280593872
Validation loss: 2.1267997731444654

Epoch: 6| Step: 6
Training loss: 1.8809293508529663
Validation loss: 2.1326759374269875

Epoch: 6| Step: 7
Training loss: 1.5456206798553467
Validation loss: 2.0997094044121365

Epoch: 6| Step: 8
Training loss: 2.544257640838623
Validation loss: 2.150124857502599

Epoch: 6| Step: 9
Training loss: 1.7341580390930176
Validation loss: 2.161558956228277

Epoch: 6| Step: 10
Training loss: 1.4756920337677002
Validation loss: 2.1423432288631314

Epoch: 6| Step: 11
Training loss: 2.184445381164551
Validation loss: 2.140378285479802

Epoch: 6| Step: 12
Training loss: 1.4139736890792847
Validation loss: 2.161436742351901

Epoch: 6| Step: 13
Training loss: 2.1968607902526855
Validation loss: 2.1149131469829108

Epoch: 394| Step: 0
Training loss: 1.2106274366378784
Validation loss: 2.135717207385648

Epoch: 6| Step: 1
Training loss: 2.1833338737487793
Validation loss: 2.1054879414137972

Epoch: 6| Step: 2
Training loss: 1.0422817468643188
Validation loss: 2.119665076655726

Epoch: 6| Step: 3
Training loss: 1.7174205780029297
Validation loss: 2.1033028876909645

Epoch: 6| Step: 4
Training loss: 1.8728965520858765
Validation loss: 2.098682645828493

Epoch: 6| Step: 5
Training loss: 1.6377151012420654
Validation loss: 2.1271680785763647

Epoch: 6| Step: 6
Training loss: 2.4527904987335205
Validation loss: 2.0939294856081725

Epoch: 6| Step: 7
Training loss: 2.0457355976104736
Validation loss: 2.1295139712672078

Epoch: 6| Step: 8
Training loss: 1.5299303531646729
Validation loss: 2.1080955766862437

Epoch: 6| Step: 9
Training loss: 1.6822260618209839
Validation loss: 2.11158259196948

Epoch: 6| Step: 10
Training loss: 1.890465497970581
Validation loss: 2.106654131284324

Epoch: 6| Step: 11
Training loss: 1.4371813535690308
Validation loss: 2.094394906874626

Epoch: 6| Step: 12
Training loss: 1.7837506532669067
Validation loss: 2.1047663996296544

Epoch: 6| Step: 13
Training loss: 2.3465261459350586
Validation loss: 2.126407256690405

Epoch: 395| Step: 0
Training loss: 1.002967119216919
Validation loss: 2.106863703778995

Epoch: 6| Step: 1
Training loss: 1.775848388671875
Validation loss: 2.1223384539286294

Epoch: 6| Step: 2
Training loss: 2.2306907176971436
Validation loss: 2.1326024096499205

Epoch: 6| Step: 3
Training loss: 2.463087320327759
Validation loss: 2.105525314166982

Epoch: 6| Step: 4
Training loss: 1.4045424461364746
Validation loss: 2.129944078383907

Epoch: 6| Step: 5
Training loss: 1.4736924171447754
Validation loss: 2.122413243016889

Epoch: 6| Step: 6
Training loss: 1.5697309970855713
Validation loss: 2.108538140532791

Epoch: 6| Step: 7
Training loss: 1.337598204612732
Validation loss: 2.1532471103052937

Epoch: 6| Step: 8
Training loss: 1.2534282207489014
Validation loss: 2.161468921169158

Epoch: 6| Step: 9
Training loss: 1.9576541185379028
Validation loss: 2.126039997223885

Epoch: 6| Step: 10
Training loss: 2.0908026695251465
Validation loss: 2.1097051200046333

Epoch: 6| Step: 11
Training loss: 1.7918487787246704
Validation loss: 2.158717889939585

Epoch: 6| Step: 12
Training loss: 2.0595996379852295
Validation loss: 2.1326218420459377

Epoch: 6| Step: 13
Training loss: 1.995069980621338
Validation loss: 2.136922759394492

Epoch: 396| Step: 0
Training loss: 2.205454111099243
Validation loss: 2.1698456989821566

Epoch: 6| Step: 1
Training loss: 1.727086067199707
Validation loss: 2.1437085277290753

Epoch: 6| Step: 2
Training loss: 1.6355504989624023
Validation loss: 2.1573184485076577

Epoch: 6| Step: 3
Training loss: 1.59429132938385
Validation loss: 2.143987686403336

Epoch: 6| Step: 4
Training loss: 1.348182201385498
Validation loss: 2.1861335282684653

Epoch: 6| Step: 5
Training loss: 1.4050259590148926
Validation loss: 2.1190146246264057

Epoch: 6| Step: 6
Training loss: 1.504727840423584
Validation loss: 2.1466864270548665

Epoch: 6| Step: 7
Training loss: 2.3463363647460938
Validation loss: 2.165569115710515

Epoch: 6| Step: 8
Training loss: 1.4152438640594482
Validation loss: 2.1067183915004937

Epoch: 6| Step: 9
Training loss: 1.697965145111084
Validation loss: 2.1210486017247683

Epoch: 6| Step: 10
Training loss: 2.1343765258789062
Validation loss: 2.1281698006455616

Epoch: 6| Step: 11
Training loss: 2.0005125999450684
Validation loss: 2.1869947243762273

Epoch: 6| Step: 12
Training loss: 1.8878183364868164
Validation loss: 2.1781351438132663

Epoch: 6| Step: 13
Training loss: 1.2486978769302368
Validation loss: 2.1610867413141395

Epoch: 397| Step: 0
Training loss: 1.2747459411621094
Validation loss: 2.105881389751229

Epoch: 6| Step: 1
Training loss: 1.3273963928222656
Validation loss: 2.128553093120616

Epoch: 6| Step: 2
Training loss: 1.0877803564071655
Validation loss: 2.1357362424173663

Epoch: 6| Step: 3
Training loss: 2.1067354679107666
Validation loss: 2.1476574123546643

Epoch: 6| Step: 4
Training loss: 2.233344078063965
Validation loss: 2.145366591791953

Epoch: 6| Step: 5
Training loss: 1.6293636560440063
Validation loss: 2.162070414071442

Epoch: 6| Step: 6
Training loss: 2.0550007820129395
Validation loss: 2.1341834581026466

Epoch: 6| Step: 7
Training loss: 1.4131726026535034
Validation loss: 2.131805355830859

Epoch: 6| Step: 8
Training loss: 1.6113910675048828
Validation loss: 2.1646819037775837

Epoch: 6| Step: 9
Training loss: 1.860170602798462
Validation loss: 2.1423502429839103

Epoch: 6| Step: 10
Training loss: 2.219898223876953
Validation loss: 2.120251460741925

Epoch: 6| Step: 11
Training loss: 1.719754695892334
Validation loss: 2.130059230712152

Epoch: 6| Step: 12
Training loss: 1.5950921773910522
Validation loss: 2.1422526682576826

Epoch: 6| Step: 13
Training loss: 2.4514317512512207
Validation loss: 2.180607549605831

Epoch: 398| Step: 0
Training loss: 1.6443486213684082
Validation loss: 2.1524725960146998

Epoch: 6| Step: 1
Training loss: 1.6346876621246338
Validation loss: 2.1078577131353398

Epoch: 6| Step: 2
Training loss: 2.2818446159362793
Validation loss: 2.1405297658776723

Epoch: 6| Step: 3
Training loss: 2.1249287128448486
Validation loss: 2.12572080345564

Epoch: 6| Step: 4
Training loss: 1.43802809715271
Validation loss: 2.1390825394661195

Epoch: 6| Step: 5
Training loss: 2.0414228439331055
Validation loss: 2.0951070836795274

Epoch: 6| Step: 6
Training loss: 1.6558704376220703
Validation loss: 2.0713338390473397

Epoch: 6| Step: 7
Training loss: 2.127072334289551
Validation loss: 2.1384757744368685

Epoch: 6| Step: 8
Training loss: 1.9838273525238037
Validation loss: 2.145565652078198

Epoch: 6| Step: 9
Training loss: 1.1502153873443604
Validation loss: 2.158658273758427

Epoch: 6| Step: 10
Training loss: 1.798103928565979
Validation loss: 2.1428959984933176

Epoch: 6| Step: 11
Training loss: 1.5501787662506104
Validation loss: 2.110115497343002

Epoch: 6| Step: 12
Training loss: 1.3881075382232666
Validation loss: 2.1321320354297595

Epoch: 6| Step: 13
Training loss: 1.4600167274475098
Validation loss: 2.1373636107290945

Epoch: 399| Step: 0
Training loss: 1.4314050674438477
Validation loss: 2.144441968651228

Epoch: 6| Step: 1
Training loss: 1.8820395469665527
Validation loss: 2.1312575852999123

Epoch: 6| Step: 2
Training loss: 1.6145522594451904
Validation loss: 2.1241994275841662

Epoch: 6| Step: 3
Training loss: 1.5708308219909668
Validation loss: 2.1240493302704184

Epoch: 6| Step: 4
Training loss: 1.6265649795532227
Validation loss: 2.150707326909547

Epoch: 6| Step: 5
Training loss: 1.40671706199646
Validation loss: 2.1460803683086107

Epoch: 6| Step: 6
Training loss: 1.83894681930542
Validation loss: 2.158309478913584

Epoch: 6| Step: 7
Training loss: 1.8916867971420288
Validation loss: 2.1880153930315407

Epoch: 6| Step: 8
Training loss: 1.571415901184082
Validation loss: 2.1567930854776853

Epoch: 6| Step: 9
Training loss: 1.6366257667541504
Validation loss: 2.1228410197842504

Epoch: 6| Step: 10
Training loss: 1.8194775581359863
Validation loss: 2.1634533046394266

Epoch: 6| Step: 11
Training loss: 1.832149863243103
Validation loss: 2.160357190716651

Epoch: 6| Step: 12
Training loss: 2.049100399017334
Validation loss: 2.1441170759098505

Epoch: 6| Step: 13
Training loss: 1.9389487504959106
Validation loss: 2.1541460637123353

Epoch: 400| Step: 0
Training loss: 1.4466001987457275
Validation loss: 2.133382974132415

Epoch: 6| Step: 1
Training loss: 2.072080373764038
Validation loss: 2.1804466247558594

Epoch: 6| Step: 2
Training loss: 1.94850492477417
Validation loss: 2.1613197275387344

Epoch: 6| Step: 3
Training loss: 1.598821997642517
Validation loss: 2.1281834674137894

Epoch: 6| Step: 4
Training loss: 1.6111218929290771
Validation loss: 2.1720646427523707

Epoch: 6| Step: 5
Training loss: 1.8599247932434082
Validation loss: 2.118024951668196

Epoch: 6| Step: 6
Training loss: 1.478547215461731
Validation loss: 2.183232189506613

Epoch: 6| Step: 7
Training loss: 2.59517240524292
Validation loss: 2.1263355465345484

Epoch: 6| Step: 8
Training loss: 1.3463983535766602
Validation loss: 2.1743935795240503

Epoch: 6| Step: 9
Training loss: 1.9914798736572266
Validation loss: 2.166715621948242

Epoch: 6| Step: 10
Training loss: 1.3925617933273315
Validation loss: 2.1579935089234383

Epoch: 6| Step: 11
Training loss: 1.268328070640564
Validation loss: 2.12527786531756

Epoch: 6| Step: 12
Training loss: 1.7184761762619019
Validation loss: 2.168114503224691

Epoch: 6| Step: 13
Training loss: 1.5544880628585815
Validation loss: 2.1801640936123428

Epoch: 401| Step: 0
Training loss: 1.247680425643921
Validation loss: 2.1282024511726956

Epoch: 6| Step: 1
Training loss: 1.5432589054107666
Validation loss: 2.136981652628991

Epoch: 6| Step: 2
Training loss: 1.7746429443359375
Validation loss: 2.1315258062014015

Epoch: 6| Step: 3
Training loss: 1.8157310485839844
Validation loss: 2.1286424052330757

Epoch: 6| Step: 4
Training loss: 2.3885350227355957
Validation loss: 2.1665093898773193

Epoch: 6| Step: 5
Training loss: 1.9271881580352783
Validation loss: 2.1141249287512993

Epoch: 6| Step: 6
Training loss: 1.473001480102539
Validation loss: 2.1151964126094693

Epoch: 6| Step: 7
Training loss: 1.9625369310379028
Validation loss: 2.1374874960991646

Epoch: 6| Step: 8
Training loss: 1.8682656288146973
Validation loss: 2.088463112872134

Epoch: 6| Step: 9
Training loss: 1.3697738647460938
Validation loss: 2.1484236768496934

Epoch: 6| Step: 10
Training loss: 1.822234869003296
Validation loss: 2.10900277732521

Epoch: 6| Step: 11
Training loss: 1.345470666885376
Validation loss: 2.154787645545057

Epoch: 6| Step: 12
Training loss: 1.5404605865478516
Validation loss: 2.1211635566526845

Epoch: 6| Step: 13
Training loss: 1.9418737888336182
Validation loss: 2.155226775394973

Epoch: 402| Step: 0
Training loss: 1.2714722156524658
Validation loss: 2.1452898376731464

Epoch: 6| Step: 1
Training loss: 1.6616147756576538
Validation loss: 2.1201618230471047

Epoch: 6| Step: 2
Training loss: 1.7824552059173584
Validation loss: 2.191168515912948

Epoch: 6| Step: 3
Training loss: 1.7964813709259033
Validation loss: 2.176179778191351

Epoch: 6| Step: 4
Training loss: 1.7309657335281372
Validation loss: 2.1190052801562893

Epoch: 6| Step: 5
Training loss: 2.0662131309509277
Validation loss: 2.125639900084465

Epoch: 6| Step: 6
Training loss: 1.3344521522521973
Validation loss: 2.1542869357652563

Epoch: 6| Step: 7
Training loss: 1.7097141742706299
Validation loss: 2.1717378734260477

Epoch: 6| Step: 8
Training loss: 2.2117018699645996
Validation loss: 2.1257713071761595

Epoch: 6| Step: 9
Training loss: 0.7768262624740601
Validation loss: 2.1332140020144883

Epoch: 6| Step: 10
Training loss: 1.935943603515625
Validation loss: 2.161730827823762

Epoch: 6| Step: 11
Training loss: 2.1664862632751465
Validation loss: 2.1556722989646335

Epoch: 6| Step: 12
Training loss: 1.9264495372772217
Validation loss: 2.1746667661974506

Epoch: 6| Step: 13
Training loss: 1.3488826751708984
Validation loss: 2.1653590330513577

Epoch: 403| Step: 0
Training loss: 1.6133456230163574
Validation loss: 2.138195268569454

Epoch: 6| Step: 1
Training loss: 1.2834830284118652
Validation loss: 2.115377001864936

Epoch: 6| Step: 2
Training loss: 1.8913609981536865
Validation loss: 2.138779406906456

Epoch: 6| Step: 3
Training loss: 1.8143730163574219
Validation loss: 2.2019888406158774

Epoch: 6| Step: 4
Training loss: 0.976239800453186
Validation loss: 2.1338947652488627

Epoch: 6| Step: 5
Training loss: 1.4530282020568848
Validation loss: 2.171014931894118

Epoch: 6| Step: 6
Training loss: 1.7588496208190918
Validation loss: 2.14277385639888

Epoch: 6| Step: 7
Training loss: 1.932775616645813
Validation loss: 2.1996905496043544

Epoch: 6| Step: 8
Training loss: 2.199143886566162
Validation loss: 2.187847022087343

Epoch: 6| Step: 9
Training loss: 1.7922409772872925
Validation loss: 2.1498166373980943

Epoch: 6| Step: 10
Training loss: 1.32924485206604
Validation loss: 2.1719254806477535

Epoch: 6| Step: 11
Training loss: 2.47861909866333
Validation loss: 2.1741203672142437

Epoch: 6| Step: 12
Training loss: 1.4183133840560913
Validation loss: 2.1696226071285944

Epoch: 6| Step: 13
Training loss: 1.623223900794983
Validation loss: 2.1456414422681256

Epoch: 404| Step: 0
Training loss: 1.9497584104537964
Validation loss: 2.0883068448753765

Epoch: 6| Step: 1
Training loss: 1.926187515258789
Validation loss: 2.1322440152527182

Epoch: 6| Step: 2
Training loss: 1.5320360660552979
Validation loss: 2.1039142442005936

Epoch: 6| Step: 3
Training loss: 1.5808119773864746
Validation loss: 2.1126373044906126

Epoch: 6| Step: 4
Training loss: 1.6704351902008057
Validation loss: 2.1361724945806686

Epoch: 6| Step: 5
Training loss: 1.6424202919006348
Validation loss: 2.146065568411222

Epoch: 6| Step: 6
Training loss: 1.6999008655548096
Validation loss: 2.140294777449741

Epoch: 6| Step: 7
Training loss: 1.3057029247283936
Validation loss: 2.176549611553069

Epoch: 6| Step: 8
Training loss: 1.9388316869735718
Validation loss: 2.1300433322947514

Epoch: 6| Step: 9
Training loss: 1.2479333877563477
Validation loss: 2.1636338080129316

Epoch: 6| Step: 10
Training loss: 1.3730199337005615
Validation loss: 2.1507129605098436

Epoch: 6| Step: 11
Training loss: 2.0507161617279053
Validation loss: 2.126016657839539

Epoch: 6| Step: 12
Training loss: 2.0942776203155518
Validation loss: 2.1813735397913123

Epoch: 6| Step: 13
Training loss: 2.2553067207336426
Validation loss: 2.191797561542962

Epoch: 405| Step: 0
Training loss: 1.4750357866287231
Validation loss: 2.1308871648644887

Epoch: 6| Step: 1
Training loss: 1.4511582851409912
Validation loss: 2.142557318492602

Epoch: 6| Step: 2
Training loss: 2.100703477859497
Validation loss: 2.169928120028588

Epoch: 6| Step: 3
Training loss: 1.7118618488311768
Validation loss: 2.1575368886352866

Epoch: 6| Step: 4
Training loss: 0.9715808629989624
Validation loss: 2.0957351858897875

Epoch: 6| Step: 5
Training loss: 2.131939172744751
Validation loss: 2.1107428278974307

Epoch: 6| Step: 6
Training loss: 1.0383237600326538
Validation loss: 2.1037386745534916

Epoch: 6| Step: 7
Training loss: 1.7992069721221924
Validation loss: 2.153282492391525

Epoch: 6| Step: 8
Training loss: 2.0963551998138428
Validation loss: 2.108609163632957

Epoch: 6| Step: 9
Training loss: 1.794631004333496
Validation loss: 2.127762024120618

Epoch: 6| Step: 10
Training loss: 1.6112258434295654
Validation loss: 2.1154663075682936

Epoch: 6| Step: 11
Training loss: 2.0912303924560547
Validation loss: 2.0913846544040147

Epoch: 6| Step: 12
Training loss: 1.6574223041534424
Validation loss: 2.1276169374424923

Epoch: 6| Step: 13
Training loss: 2.177598714828491
Validation loss: 2.132098941392796

Epoch: 406| Step: 0
Training loss: 1.6532189846038818
Validation loss: 2.093671685905867

Epoch: 6| Step: 1
Training loss: 1.0885089635849
Validation loss: 2.144663118547009

Epoch: 6| Step: 2
Training loss: 1.3488472700119019
Validation loss: 2.1506765042581866

Epoch: 6| Step: 3
Training loss: 1.7866984605789185
Validation loss: 2.133001281369117

Epoch: 6| Step: 4
Training loss: 1.7579035758972168
Validation loss: 2.1663517798146894

Epoch: 6| Step: 5
Training loss: 1.1732609272003174
Validation loss: 2.146853414914941

Epoch: 6| Step: 6
Training loss: 1.9248387813568115
Validation loss: 2.1295675295655445

Epoch: 6| Step: 7
Training loss: 1.7899917364120483
Validation loss: 2.2078609620371172

Epoch: 6| Step: 8
Training loss: 1.655583381652832
Validation loss: 2.162550772390058

Epoch: 6| Step: 9
Training loss: 2.1145594120025635
Validation loss: 2.1588729837889313

Epoch: 6| Step: 10
Training loss: 2.3464913368225098
Validation loss: 2.116930628335604

Epoch: 6| Step: 11
Training loss: 1.371044635772705
Validation loss: 2.186692396799723

Epoch: 6| Step: 12
Training loss: 2.1323328018188477
Validation loss: 2.1889446781527613

Epoch: 6| Step: 13
Training loss: 1.9289449453353882
Validation loss: 2.130247377580212

Epoch: 407| Step: 0
Training loss: 1.1474261283874512
Validation loss: 2.156704512975549

Epoch: 6| Step: 1
Training loss: 1.4244084358215332
Validation loss: 2.187861878384826

Epoch: 6| Step: 2
Training loss: 2.567842960357666
Validation loss: 2.118385321350508

Epoch: 6| Step: 3
Training loss: 1.2472180128097534
Validation loss: 2.1305967325805337

Epoch: 6| Step: 4
Training loss: 2.1030259132385254
Validation loss: 2.176424604590221

Epoch: 6| Step: 5
Training loss: 1.9460933208465576
Validation loss: 2.1487549735653784

Epoch: 6| Step: 6
Training loss: 1.9569250345230103
Validation loss: 2.1406770983049945

Epoch: 6| Step: 7
Training loss: 1.0610504150390625
Validation loss: 2.1458299826550227

Epoch: 6| Step: 8
Training loss: 1.3754076957702637
Validation loss: 2.1691917475833686

Epoch: 6| Step: 9
Training loss: 1.1845049858093262
Validation loss: 2.1584245645871727

Epoch: 6| Step: 10
Training loss: 2.04467511177063
Validation loss: 2.1051694731558523

Epoch: 6| Step: 11
Training loss: 1.722281575202942
Validation loss: 2.1116790822757188

Epoch: 6| Step: 12
Training loss: 2.156883478164673
Validation loss: 2.1566595531279042

Epoch: 6| Step: 13
Training loss: 1.8714741468429565
Validation loss: 2.1513209676229827

Epoch: 408| Step: 0
Training loss: 1.8458771705627441
Validation loss: 2.150653954475157

Epoch: 6| Step: 1
Training loss: 1.9158246517181396
Validation loss: 2.2007712805142967

Epoch: 6| Step: 2
Training loss: 1.4187405109405518
Validation loss: 2.1657273179741314

Epoch: 6| Step: 3
Training loss: 2.3468635082244873
Validation loss: 2.118177451113219

Epoch: 6| Step: 4
Training loss: 1.5884883403778076
Validation loss: 2.1042556608876875

Epoch: 6| Step: 5
Training loss: 2.598029613494873
Validation loss: 2.1606970243556525

Epoch: 6| Step: 6
Training loss: 1.3091425895690918
Validation loss: 2.163221049052413

Epoch: 6| Step: 7
Training loss: 1.188405990600586
Validation loss: 2.0960260155380412

Epoch: 6| Step: 8
Training loss: 1.7419084310531616
Validation loss: 2.1464960677649385

Epoch: 6| Step: 9
Training loss: 2.179856300354004
Validation loss: 2.1382780626255977

Epoch: 6| Step: 10
Training loss: 1.1736326217651367
Validation loss: 2.175039450327555

Epoch: 6| Step: 11
Training loss: 1.2600258588790894
Validation loss: 2.125306330701356

Epoch: 6| Step: 12
Training loss: 1.9457755088806152
Validation loss: 2.1016421266781387

Epoch: 6| Step: 13
Training loss: 1.879477620124817
Validation loss: 2.131663847995061

Epoch: 409| Step: 0
Training loss: 1.5599842071533203
Validation loss: 2.1264313831124255

Epoch: 6| Step: 1
Training loss: 1.6157646179199219
Validation loss: 2.145104335200402

Epoch: 6| Step: 2
Training loss: 1.6192766427993774
Validation loss: 2.1220808464993715

Epoch: 6| Step: 3
Training loss: 1.9759801626205444
Validation loss: 2.131531006546431

Epoch: 6| Step: 4
Training loss: 1.1917014122009277
Validation loss: 2.1388435825224845

Epoch: 6| Step: 5
Training loss: 2.168534278869629
Validation loss: 2.1436346538605227

Epoch: 6| Step: 6
Training loss: 1.7850440740585327
Validation loss: 2.1459662760457685

Epoch: 6| Step: 7
Training loss: 1.475353479385376
Validation loss: 2.1497980856126353

Epoch: 6| Step: 8
Training loss: 1.1238431930541992
Validation loss: 2.0866965388738983

Epoch: 6| Step: 9
Training loss: 1.764914631843567
Validation loss: 2.123057482063129

Epoch: 6| Step: 10
Training loss: 2.2481870651245117
Validation loss: 2.1853355771751812

Epoch: 6| Step: 11
Training loss: 1.984199047088623
Validation loss: 2.1838042659144246

Epoch: 6| Step: 12
Training loss: 1.6980905532836914
Validation loss: 2.165694405955653

Epoch: 6| Step: 13
Training loss: 1.8240103721618652
Validation loss: 2.154978471417581

Epoch: 410| Step: 0
Training loss: 1.101803183555603
Validation loss: 2.1739952769330753

Epoch: 6| Step: 1
Training loss: 2.3621201515197754
Validation loss: 2.186911698310606

Epoch: 6| Step: 2
Training loss: 1.6407634019851685
Validation loss: 2.159078380113007

Epoch: 6| Step: 3
Training loss: 2.017651081085205
Validation loss: 2.1324986257860736

Epoch: 6| Step: 4
Training loss: 2.394474983215332
Validation loss: 2.1193957521069433

Epoch: 6| Step: 5
Training loss: 1.4477412700653076
Validation loss: 2.1771964924309843

Epoch: 6| Step: 6
Training loss: 1.6698319911956787
Validation loss: 2.1941272468977076

Epoch: 6| Step: 7
Training loss: 1.7411456108093262
Validation loss: 2.138111733621167

Epoch: 6| Step: 8
Training loss: 1.4341628551483154
Validation loss: 2.194261350939351

Epoch: 6| Step: 9
Training loss: 2.0953900814056396
Validation loss: 2.1285982080685195

Epoch: 6| Step: 10
Training loss: 1.5385808944702148
Validation loss: 2.1462402395022813

Epoch: 6| Step: 11
Training loss: 1.6073335409164429
Validation loss: 2.1375866910462737

Epoch: 6| Step: 12
Training loss: 1.4369840621948242
Validation loss: 2.1437963542117866

Epoch: 6| Step: 13
Training loss: 1.1509137153625488
Validation loss: 2.1332382143184705

Epoch: 411| Step: 0
Training loss: 1.9629290103912354
Validation loss: 2.1292235671832995

Epoch: 6| Step: 1
Training loss: 2.111698627471924
Validation loss: 2.1076810847046556

Epoch: 6| Step: 2
Training loss: 1.4597774744033813
Validation loss: 2.1672291909494708

Epoch: 6| Step: 3
Training loss: 1.194093942642212
Validation loss: 2.119583373428673

Epoch: 6| Step: 4
Training loss: 1.8215038776397705
Validation loss: 2.126260947155696

Epoch: 6| Step: 5
Training loss: 1.8349668979644775
Validation loss: 2.1097735948460077

Epoch: 6| Step: 6
Training loss: 1.7588790655136108
Validation loss: 2.1434518932014384

Epoch: 6| Step: 7
Training loss: 1.5601425170898438
Validation loss: 2.1344722060747046

Epoch: 6| Step: 8
Training loss: 1.809918999671936
Validation loss: 2.1682743692910798

Epoch: 6| Step: 9
Training loss: 1.447331190109253
Validation loss: 2.187879649541711

Epoch: 6| Step: 10
Training loss: 2.125458240509033
Validation loss: 2.1353504939745833

Epoch: 6| Step: 11
Training loss: 1.021020770072937
Validation loss: 2.201885461807251

Epoch: 6| Step: 12
Training loss: 2.235124349594116
Validation loss: 2.1861989523774836

Epoch: 6| Step: 13
Training loss: 1.3219926357269287
Validation loss: 2.1198257054052045

Epoch: 412| Step: 0
Training loss: 1.975906252861023
Validation loss: 2.1800837388602634

Epoch: 6| Step: 1
Training loss: 1.4045790433883667
Validation loss: 2.1217913063623572

Epoch: 6| Step: 2
Training loss: 1.5555280447006226
Validation loss: 2.1439630087985786

Epoch: 6| Step: 3
Training loss: 1.3887040615081787
Validation loss: 2.1781330826461955

Epoch: 6| Step: 4
Training loss: 1.6712329387664795
Validation loss: 2.1765641679045973

Epoch: 6| Step: 5
Training loss: 1.1816309690475464
Validation loss: 2.163430026782456

Epoch: 6| Step: 6
Training loss: 1.5647190809249878
Validation loss: 2.174430021675684

Epoch: 6| Step: 7
Training loss: 2.295116901397705
Validation loss: 2.173870712198237

Epoch: 6| Step: 8
Training loss: 1.9677472114562988
Validation loss: 2.170792237404854

Epoch: 6| Step: 9
Training loss: 2.033168315887451
Validation loss: 2.174060489541741

Epoch: 6| Step: 10
Training loss: 1.8007248640060425
Validation loss: 2.1471047132245955

Epoch: 6| Step: 11
Training loss: 1.4646776914596558
Validation loss: 2.126109710303686

Epoch: 6| Step: 12
Training loss: 1.4323334693908691
Validation loss: 2.1257666516047653

Epoch: 6| Step: 13
Training loss: 2.04386305809021
Validation loss: 2.149976950819774

Epoch: 413| Step: 0
Training loss: 1.611637830734253
Validation loss: 2.1306566986986386

Epoch: 6| Step: 1
Training loss: 1.3088228702545166
Validation loss: 2.2059716691253004

Epoch: 6| Step: 2
Training loss: 1.73388671875
Validation loss: 2.1331916983409593

Epoch: 6| Step: 3
Training loss: 1.535768747329712
Validation loss: 2.1331795646298315

Epoch: 6| Step: 4
Training loss: 1.281446099281311
Validation loss: 2.173975593300276

Epoch: 6| Step: 5
Training loss: 1.691455602645874
Validation loss: 2.1290897989785798

Epoch: 6| Step: 6
Training loss: 1.5080361366271973
Validation loss: 2.122954947974092

Epoch: 6| Step: 7
Training loss: 2.404106616973877
Validation loss: 2.110828879059002

Epoch: 6| Step: 8
Training loss: 1.815495491027832
Validation loss: 2.1579102828938472

Epoch: 6| Step: 9
Training loss: 2.3579888343811035
Validation loss: 2.1499756971995034

Epoch: 6| Step: 10
Training loss: 1.8248456716537476
Validation loss: 2.1564497281146306

Epoch: 6| Step: 11
Training loss: 1.4195502996444702
Validation loss: 2.1540322713954474

Epoch: 6| Step: 12
Training loss: 1.6720407009124756
Validation loss: 2.1462391602095736

Epoch: 6| Step: 13
Training loss: 1.746944546699524
Validation loss: 2.1536571389885357

Epoch: 414| Step: 0
Training loss: 1.5157370567321777
Validation loss: 2.137000681251608

Epoch: 6| Step: 1
Training loss: 1.3228001594543457
Validation loss: 2.1455448827435895

Epoch: 6| Step: 2
Training loss: 2.029021739959717
Validation loss: 2.151776598345849

Epoch: 6| Step: 3
Training loss: 1.681486964225769
Validation loss: 2.1958041191101074

Epoch: 6| Step: 4
Training loss: 1.475292682647705
Validation loss: 2.184369420492521

Epoch: 6| Step: 5
Training loss: 1.4201611280441284
Validation loss: 2.142709965346962

Epoch: 6| Step: 6
Training loss: 2.474721670150757
Validation loss: 2.1622733582732496

Epoch: 6| Step: 7
Training loss: 1.3329963684082031
Validation loss: 2.1480881949906707

Epoch: 6| Step: 8
Training loss: 1.7236584424972534
Validation loss: 2.143484459128431

Epoch: 6| Step: 9
Training loss: 2.0936431884765625
Validation loss: 2.1284379036195817

Epoch: 6| Step: 10
Training loss: 1.7305293083190918
Validation loss: 2.1610646376045803

Epoch: 6| Step: 11
Training loss: 1.5452971458435059
Validation loss: 2.174771355044457

Epoch: 6| Step: 12
Training loss: 1.727142333984375
Validation loss: 2.149865645234303

Epoch: 6| Step: 13
Training loss: 1.4441943168640137
Validation loss: 2.168846094480125

Epoch: 415| Step: 0
Training loss: 1.8642971515655518
Validation loss: 2.173904540718243

Epoch: 6| Step: 1
Training loss: 0.9919536113739014
Validation loss: 2.132117586751138

Epoch: 6| Step: 2
Training loss: 1.1526386737823486
Validation loss: 2.161892362820205

Epoch: 6| Step: 3
Training loss: 1.8322376012802124
Validation loss: 2.1420570893954207

Epoch: 6| Step: 4
Training loss: 1.609944224357605
Validation loss: 2.106604319746776

Epoch: 6| Step: 5
Training loss: 1.3645836114883423
Validation loss: 2.19505504638918

Epoch: 6| Step: 6
Training loss: 2.18410587310791
Validation loss: 2.1689547210611324

Epoch: 6| Step: 7
Training loss: 1.2449885606765747
Validation loss: 2.155487877066417

Epoch: 6| Step: 8
Training loss: 1.1453635692596436
Validation loss: 2.122659562736429

Epoch: 6| Step: 9
Training loss: 2.327514171600342
Validation loss: 2.1581272438008297

Epoch: 6| Step: 10
Training loss: 1.6440238952636719
Validation loss: 2.1609811065017537

Epoch: 6| Step: 11
Training loss: 2.450467109680176
Validation loss: 2.1598454880458053

Epoch: 6| Step: 12
Training loss: 2.0448484420776367
Validation loss: 2.1182326270687963

Epoch: 6| Step: 13
Training loss: 1.7224154472351074
Validation loss: 2.1500499376686673

Epoch: 416| Step: 0
Training loss: 1.4372360706329346
Validation loss: 2.179375486989175

Epoch: 6| Step: 1
Training loss: 2.0704402923583984
Validation loss: 2.118931726742816

Epoch: 6| Step: 2
Training loss: 1.7805546522140503
Validation loss: 2.16544323326439

Epoch: 6| Step: 3
Training loss: 1.6300134658813477
Validation loss: 2.162313272876124

Epoch: 6| Step: 4
Training loss: 1.6355006694793701
Validation loss: 2.1709634796265633

Epoch: 6| Step: 5
Training loss: 1.2795277833938599
Validation loss: 2.191494731492894

Epoch: 6| Step: 6
Training loss: 1.6518362760543823
Validation loss: 2.136080952100856

Epoch: 6| Step: 7
Training loss: 1.270405650138855
Validation loss: 2.136060683957992

Epoch: 6| Step: 8
Training loss: 1.1507819890975952
Validation loss: 2.168155006183091

Epoch: 6| Step: 9
Training loss: 2.3932199478149414
Validation loss: 2.123430291811625

Epoch: 6| Step: 10
Training loss: 1.890420913696289
Validation loss: 2.1319649001603485

Epoch: 6| Step: 11
Training loss: 1.4525625705718994
Validation loss: 2.1793469485416206

Epoch: 6| Step: 12
Training loss: 1.986842155456543
Validation loss: 2.18731100584871

Epoch: 6| Step: 13
Training loss: 0.5328748226165771
Validation loss: 2.168337957833403

Epoch: 417| Step: 0
Training loss: 1.2269113063812256
Validation loss: 2.184575734599944

Epoch: 6| Step: 1
Training loss: 1.7532522678375244
Validation loss: 2.207564958962061

Epoch: 6| Step: 2
Training loss: 1.1648623943328857
Validation loss: 2.1765613171362106

Epoch: 6| Step: 3
Training loss: 1.9283262491226196
Validation loss: 2.135143388984024

Epoch: 6| Step: 4
Training loss: 1.854433536529541
Validation loss: 2.2016337033241027

Epoch: 6| Step: 5
Training loss: 1.8880712985992432
Validation loss: 2.1505863948534896

Epoch: 6| Step: 6
Training loss: 2.0303092002868652
Validation loss: 2.164352556710602

Epoch: 6| Step: 7
Training loss: 2.104278564453125
Validation loss: 2.143823068629029

Epoch: 6| Step: 8
Training loss: 2.2454566955566406
Validation loss: 2.1984647473981305

Epoch: 6| Step: 9
Training loss: 1.4239921569824219
Validation loss: 2.1752118615693945

Epoch: 6| Step: 10
Training loss: 1.6513845920562744
Validation loss: 2.132980197988531

Epoch: 6| Step: 11
Training loss: 1.9895083904266357
Validation loss: 2.150824705759684

Epoch: 6| Step: 12
Training loss: 1.1639043092727661
Validation loss: 2.163488141952022

Epoch: 6| Step: 13
Training loss: 1.2149969339370728
Validation loss: 2.13464081159202

Epoch: 418| Step: 0
Training loss: 1.8786368370056152
Validation loss: 2.148928890946091

Epoch: 6| Step: 1
Training loss: 1.4633709192276
Validation loss: 2.1503219604492188

Epoch: 6| Step: 2
Training loss: 1.986701250076294
Validation loss: 2.1420403885585007

Epoch: 6| Step: 3
Training loss: 1.728509545326233
Validation loss: 2.0975515201527584

Epoch: 6| Step: 4
Training loss: 1.4995498657226562
Validation loss: 2.1628123585895827

Epoch: 6| Step: 5
Training loss: 1.1845629215240479
Validation loss: 2.141054703343299

Epoch: 6| Step: 6
Training loss: 1.9409934282302856
Validation loss: 2.124383508518178

Epoch: 6| Step: 7
Training loss: 1.7117705345153809
Validation loss: 2.1413371204048075

Epoch: 6| Step: 8
Training loss: 2.0106334686279297
Validation loss: 2.1719882065250027

Epoch: 6| Step: 9
Training loss: 1.9549062252044678
Validation loss: 2.1635626182761243

Epoch: 6| Step: 10
Training loss: 1.857973337173462
Validation loss: 2.1473340167794177

Epoch: 6| Step: 11
Training loss: 1.5270578861236572
Validation loss: 2.1442728427148636

Epoch: 6| Step: 12
Training loss: 1.3237898349761963
Validation loss: 2.1560235510590258

Epoch: 6| Step: 13
Training loss: 1.9672105312347412
Validation loss: 2.179665418081386

Epoch: 419| Step: 0
Training loss: 1.9594663381576538
Validation loss: 2.204117239162486

Epoch: 6| Step: 1
Training loss: 1.462294101715088
Validation loss: 2.1916028543185164

Epoch: 6| Step: 2
Training loss: 1.2278485298156738
Validation loss: 2.180076778575938

Epoch: 6| Step: 3
Training loss: 1.8615937232971191
Validation loss: 2.162625123095769

Epoch: 6| Step: 4
Training loss: 2.014885902404785
Validation loss: 2.1912850282525502

Epoch: 6| Step: 5
Training loss: 1.9443442821502686
Validation loss: 2.188504571555763

Epoch: 6| Step: 6
Training loss: 1.4100122451782227
Validation loss: 2.22469525952493

Epoch: 6| Step: 7
Training loss: 1.289772391319275
Validation loss: 2.2126801449765443

Epoch: 6| Step: 8
Training loss: 2.154181718826294
Validation loss: 2.215222671467771

Epoch: 6| Step: 9
Training loss: 1.9058550596237183
Validation loss: 2.200186916576919

Epoch: 6| Step: 10
Training loss: 1.891090989112854
Validation loss: 2.1827417855621665

Epoch: 6| Step: 11
Training loss: 1.5995032787322998
Validation loss: 2.1768941533180977

Epoch: 6| Step: 12
Training loss: 0.6780853271484375
Validation loss: 2.1250670443299

Epoch: 6| Step: 13
Training loss: 1.3571398258209229
Validation loss: 2.1258504723989837

Epoch: 420| Step: 0
Training loss: 2.3931713104248047
Validation loss: 2.1358532982487834

Epoch: 6| Step: 1
Training loss: 1.0676666498184204
Validation loss: 2.174908335490893

Epoch: 6| Step: 2
Training loss: 1.7585082054138184
Validation loss: 2.1316888306730535

Epoch: 6| Step: 3
Training loss: 1.3677701950073242
Validation loss: 2.147036455010855

Epoch: 6| Step: 4
Training loss: 2.123199701309204
Validation loss: 2.110557879171064

Epoch: 6| Step: 5
Training loss: 1.8335778713226318
Validation loss: 2.151019122010918

Epoch: 6| Step: 6
Training loss: 1.7966581583023071
Validation loss: 2.161635609083278

Epoch: 6| Step: 7
Training loss: 1.2846184968948364
Validation loss: 2.1169383192575104

Epoch: 6| Step: 8
Training loss: 1.0650235414505005
Validation loss: 2.1311434956007105

Epoch: 6| Step: 9
Training loss: 2.38564133644104
Validation loss: 2.1379673634805987

Epoch: 6| Step: 10
Training loss: 1.537070393562317
Validation loss: 2.147629649408402

Epoch: 6| Step: 11
Training loss: 1.405032753944397
Validation loss: 2.1481678588415987

Epoch: 6| Step: 12
Training loss: 1.5017772912979126
Validation loss: 2.1307201539316485

Epoch: 6| Step: 13
Training loss: 2.3186283111572266
Validation loss: 2.1545993384494575

Epoch: 421| Step: 0
Training loss: 1.9994679689407349
Validation loss: 2.119222669191258

Epoch: 6| Step: 1
Training loss: 1.082158088684082
Validation loss: 2.165014108022054

Epoch: 6| Step: 2
Training loss: 1.804842472076416
Validation loss: 2.1101404274663618

Epoch: 6| Step: 3
Training loss: 2.1273255348205566
Validation loss: 2.1675020930587605

Epoch: 6| Step: 4
Training loss: 1.4914770126342773
Validation loss: 2.135919435049898

Epoch: 6| Step: 5
Training loss: 1.8730800151824951
Validation loss: 2.1334633391390563

Epoch: 6| Step: 6
Training loss: 1.509348750114441
Validation loss: 2.2402031293479343

Epoch: 6| Step: 7
Training loss: 1.5584893226623535
Validation loss: 2.151618238418333

Epoch: 6| Step: 8
Training loss: 1.4256705045700073
Validation loss: 2.1497832075242074

Epoch: 6| Step: 9
Training loss: 1.6771752834320068
Validation loss: 2.130825740034862

Epoch: 6| Step: 10
Training loss: 2.0461344718933105
Validation loss: 2.140290319278676

Epoch: 6| Step: 11
Training loss: 1.619206190109253
Validation loss: 2.1396721921941286

Epoch: 6| Step: 12
Training loss: 1.161097526550293
Validation loss: 2.1606514351342314

Epoch: 6| Step: 13
Training loss: 1.4845705032348633
Validation loss: 2.1405065777481243

Epoch: 422| Step: 0
Training loss: 1.5889192819595337
Validation loss: 2.2028292507253666

Epoch: 6| Step: 1
Training loss: 1.8784794807434082
Validation loss: 2.119015975665021

Epoch: 6| Step: 2
Training loss: 1.6394720077514648
Validation loss: 2.152879058673818

Epoch: 6| Step: 3
Training loss: 2.197791814804077
Validation loss: 2.1613373038589314

Epoch: 6| Step: 4
Training loss: 1.9273557662963867
Validation loss: 2.1587951388410342

Epoch: 6| Step: 5
Training loss: 1.3506875038146973
Validation loss: 2.137935971701017

Epoch: 6| Step: 6
Training loss: 1.3960156440734863
Validation loss: 2.1258328999242475

Epoch: 6| Step: 7
Training loss: 1.7638105154037476
Validation loss: 2.1719753690945205

Epoch: 6| Step: 8
Training loss: 1.5833168029785156
Validation loss: 2.1455080637367825

Epoch: 6| Step: 9
Training loss: 1.9801782369613647
Validation loss: 2.1684432644997873

Epoch: 6| Step: 10
Training loss: 1.5522444248199463
Validation loss: 2.1634600649597826

Epoch: 6| Step: 11
Training loss: 1.8502633571624756
Validation loss: 2.169461901469897

Epoch: 6| Step: 12
Training loss: 0.9994536638259888
Validation loss: 2.1345474335455124

Epoch: 6| Step: 13
Training loss: 1.2733523845672607
Validation loss: 2.1552273509322957

Epoch: 423| Step: 0
Training loss: 2.7677409648895264
Validation loss: 2.1390310436166744

Epoch: 6| Step: 1
Training loss: 1.4647717475891113
Validation loss: 2.199280825994348

Epoch: 6| Step: 2
Training loss: 1.3451608419418335
Validation loss: 2.1946287590970277

Epoch: 6| Step: 3
Training loss: 1.8374322652816772
Validation loss: 2.14827795438869

Epoch: 6| Step: 4
Training loss: 2.04673433303833
Validation loss: 2.175196023397548

Epoch: 6| Step: 5
Training loss: 1.5277917385101318
Validation loss: 2.1786844832922823

Epoch: 6| Step: 6
Training loss: 2.228452205657959
Validation loss: 2.1829332074811383

Epoch: 6| Step: 7
Training loss: 1.803301453590393
Validation loss: 2.189522376624487

Epoch: 6| Step: 8
Training loss: 1.7579039335250854
Validation loss: 2.1738939657006213

Epoch: 6| Step: 9
Training loss: 0.6739687919616699
Validation loss: 2.1639805916816957

Epoch: 6| Step: 10
Training loss: 1.5875523090362549
Validation loss: 2.1741394304460093

Epoch: 6| Step: 11
Training loss: 0.8999062776565552
Validation loss: 2.1427030178808395

Epoch: 6| Step: 12
Training loss: 1.16867196559906
Validation loss: 2.1149037704672864

Epoch: 6| Step: 13
Training loss: 1.594038486480713
Validation loss: 2.1485065567877983

Epoch: 424| Step: 0
Training loss: 1.908128023147583
Validation loss: 2.1613334045615247

Epoch: 6| Step: 1
Training loss: 1.9151906967163086
Validation loss: 2.131760222937471

Epoch: 6| Step: 2
Training loss: 1.061759114265442
Validation loss: 2.172034348210981

Epoch: 6| Step: 3
Training loss: 1.4654412269592285
Validation loss: 2.1426011695656726

Epoch: 6| Step: 4
Training loss: 1.6553895473480225
Validation loss: 2.156437914858582

Epoch: 6| Step: 5
Training loss: 2.1280226707458496
Validation loss: 2.1479773341968493

Epoch: 6| Step: 6
Training loss: 1.9512403011322021
Validation loss: 2.142209963131976

Epoch: 6| Step: 7
Training loss: 1.4664130210876465
Validation loss: 2.1548728673688826

Epoch: 6| Step: 8
Training loss: 1.7816407680511475
Validation loss: 2.1890139964319046

Epoch: 6| Step: 9
Training loss: 0.7951816916465759
Validation loss: 2.122105267740065

Epoch: 6| Step: 10
Training loss: 1.7653343677520752
Validation loss: 2.140330647909513

Epoch: 6| Step: 11
Training loss: 1.619079828262329
Validation loss: 2.1564076074989895

Epoch: 6| Step: 12
Training loss: 1.5121409893035889
Validation loss: 2.1402330347286758

Epoch: 6| Step: 13
Training loss: 2.3759961128234863
Validation loss: 2.18123193581899

Epoch: 425| Step: 0
Training loss: 1.2341115474700928
Validation loss: 2.134031818759057

Epoch: 6| Step: 1
Training loss: 1.5599265098571777
Validation loss: 2.1783114838343796

Epoch: 6| Step: 2
Training loss: 2.02931547164917
Validation loss: 2.153273040248502

Epoch: 6| Step: 3
Training loss: 1.8358339071273804
Validation loss: 2.1542985977665072

Epoch: 6| Step: 4
Training loss: 2.309309959411621
Validation loss: 2.141350669245566

Epoch: 6| Step: 5
Training loss: 1.3959753513336182
Validation loss: 2.103151736720916

Epoch: 6| Step: 6
Training loss: 2.1358981132507324
Validation loss: 2.1506807111924693

Epoch: 6| Step: 7
Training loss: 1.1857695579528809
Validation loss: 2.1010301010583037

Epoch: 6| Step: 8
Training loss: 1.4548964500427246
Validation loss: 2.1234037927401963

Epoch: 6| Step: 9
Training loss: 1.2955964803695679
Validation loss: 2.105513095855713

Epoch: 6| Step: 10
Training loss: 1.893819808959961
Validation loss: 2.1357426938190254

Epoch: 6| Step: 11
Training loss: 1.5497393608093262
Validation loss: 2.1582934138595418

Epoch: 6| Step: 12
Training loss: 1.628875970840454
Validation loss: 2.107489821731403

Epoch: 6| Step: 13
Training loss: 1.8683809041976929
Validation loss: 2.1676517250717326

Epoch: 426| Step: 0
Training loss: 1.1556949615478516
Validation loss: 2.152936448333084

Epoch: 6| Step: 1
Training loss: 1.8316519260406494
Validation loss: 2.1280731565208844

Epoch: 6| Step: 2
Training loss: 1.346494436264038
Validation loss: 2.18196851207364

Epoch: 6| Step: 3
Training loss: 1.583661437034607
Validation loss: 2.1669230256029355

Epoch: 6| Step: 4
Training loss: 1.9915533065795898
Validation loss: 2.1571616562463904

Epoch: 6| Step: 5
Training loss: 1.778653621673584
Validation loss: 2.166615798909177

Epoch: 6| Step: 6
Training loss: 1.8000013828277588
Validation loss: 2.1727641461997904

Epoch: 6| Step: 7
Training loss: 1.2124496698379517
Validation loss: 2.2083780278441725

Epoch: 6| Step: 8
Training loss: 1.6625336408615112
Validation loss: 2.200706515260922

Epoch: 6| Step: 9
Training loss: 2.1830830574035645
Validation loss: 2.186303950125171

Epoch: 6| Step: 10
Training loss: 1.8198944330215454
Validation loss: 2.1704455678180983

Epoch: 6| Step: 11
Training loss: 1.9680814743041992
Validation loss: 2.188743893818189

Epoch: 6| Step: 12
Training loss: 1.5501630306243896
Validation loss: 2.178993998035308

Epoch: 6| Step: 13
Training loss: 1.2038630247116089
Validation loss: 2.192010515479631

Epoch: 427| Step: 0
Training loss: 1.056077241897583
Validation loss: 2.1431860936585294

Epoch: 6| Step: 1
Training loss: 1.8585833311080933
Validation loss: 2.155647547014298

Epoch: 6| Step: 2
Training loss: 1.940229892730713
Validation loss: 2.118882075432808

Epoch: 6| Step: 3
Training loss: 1.9916397333145142
Validation loss: 2.1527924383840253

Epoch: 6| Step: 4
Training loss: 1.9817869663238525
Validation loss: 2.1285326198865007

Epoch: 6| Step: 5
Training loss: 1.5532598495483398
Validation loss: 2.128658369023313

Epoch: 6| Step: 6
Training loss: 1.5688488483428955
Validation loss: 2.1486229153089624

Epoch: 6| Step: 7
Training loss: 1.3522605895996094
Validation loss: 2.126308537298633

Epoch: 6| Step: 8
Training loss: 1.2538508176803589
Validation loss: 2.149143709931322

Epoch: 6| Step: 9
Training loss: 1.9580767154693604
Validation loss: 2.1418712382675498

Epoch: 6| Step: 10
Training loss: 2.0831856727600098
Validation loss: 2.115473880562731

Epoch: 6| Step: 11
Training loss: 1.4616285562515259
Validation loss: 2.1242436491033083

Epoch: 6| Step: 12
Training loss: 1.5191617012023926
Validation loss: 2.0803772839166785

Epoch: 6| Step: 13
Training loss: 1.733510136604309
Validation loss: 2.1159836323030534

Epoch: 428| Step: 0
Training loss: 1.640445590019226
Validation loss: 2.1530714752853557

Epoch: 6| Step: 1
Training loss: 1.7231976985931396
Validation loss: 2.0992236291208575

Epoch: 6| Step: 2
Training loss: 1.9878137111663818
Validation loss: 2.1772695536254556

Epoch: 6| Step: 3
Training loss: 1.755368709564209
Validation loss: 2.1395394597002255

Epoch: 6| Step: 4
Training loss: 1.8773505687713623
Validation loss: 2.1792280109979774

Epoch: 6| Step: 5
Training loss: 1.2866538763046265
Validation loss: 2.1776738371900333

Epoch: 6| Step: 6
Training loss: 1.1469701528549194
Validation loss: 2.1584749170528945

Epoch: 6| Step: 7
Training loss: 1.791231632232666
Validation loss: 2.1597084076173845

Epoch: 6| Step: 8
Training loss: 2.5542969703674316
Validation loss: 2.1660932661384664

Epoch: 6| Step: 9
Training loss: 1.219530701637268
Validation loss: 2.1522260724857287

Epoch: 6| Step: 10
Training loss: 1.4634613990783691
Validation loss: 2.1848140506334204

Epoch: 6| Step: 11
Training loss: 1.5016899108886719
Validation loss: 2.1702863964983212

Epoch: 6| Step: 12
Training loss: 1.5624027252197266
Validation loss: 2.2005165417989097

Epoch: 6| Step: 13
Training loss: 1.206915259361267
Validation loss: 2.2113036289009997

Epoch: 429| Step: 0
Training loss: 1.885912537574768
Validation loss: 2.1965024984011086

Epoch: 6| Step: 1
Training loss: 1.6125967502593994
Validation loss: 2.174500629466067

Epoch: 6| Step: 2
Training loss: 1.1766470670700073
Validation loss: 2.143350544796195

Epoch: 6| Step: 3
Training loss: 1.6662709712982178
Validation loss: 2.1572642018718104

Epoch: 6| Step: 4
Training loss: 1.402657389640808
Validation loss: 2.090652165874358

Epoch: 6| Step: 5
Training loss: 3.0867624282836914
Validation loss: 2.1608008287286244

Epoch: 6| Step: 6
Training loss: 1.5106722116470337
Validation loss: 2.142461435769194

Epoch: 6| Step: 7
Training loss: 1.5470250844955444
Validation loss: 2.13002715187688

Epoch: 6| Step: 8
Training loss: 1.4141970872879028
Validation loss: 2.161252731918007

Epoch: 6| Step: 9
Training loss: 1.6118969917297363
Validation loss: 2.1352984533515027

Epoch: 6| Step: 10
Training loss: 0.8412197828292847
Validation loss: 2.1706145553178686

Epoch: 6| Step: 11
Training loss: 1.8078622817993164
Validation loss: 2.1629878705547703

Epoch: 6| Step: 12
Training loss: 2.1146693229675293
Validation loss: 2.134044239597936

Epoch: 6| Step: 13
Training loss: 1.798765778541565
Validation loss: 2.1339870755390455

Epoch: 430| Step: 0
Training loss: 1.4996836185455322
Validation loss: 2.157989799335439

Epoch: 6| Step: 1
Training loss: 2.041825532913208
Validation loss: 2.1599173545837402

Epoch: 6| Step: 2
Training loss: 1.9013638496398926
Validation loss: 2.146935489869887

Epoch: 6| Step: 3
Training loss: 1.0350990295410156
Validation loss: 2.1370891447990172

Epoch: 6| Step: 4
Training loss: 1.7678391933441162
Validation loss: 2.178100275736983

Epoch: 6| Step: 5
Training loss: 0.9832017421722412
Validation loss: 2.1715435366476736

Epoch: 6| Step: 6
Training loss: 1.1666864156723022
Validation loss: 2.1646534986393426

Epoch: 6| Step: 7
Training loss: 1.8653947114944458
Validation loss: 2.17102716302359

Epoch: 6| Step: 8
Training loss: 1.6483603715896606
Validation loss: 2.127216390384141

Epoch: 6| Step: 9
Training loss: 2.076671600341797
Validation loss: 2.1465884870098484

Epoch: 6| Step: 10
Training loss: 1.8077807426452637
Validation loss: 2.1904101243583103

Epoch: 6| Step: 11
Training loss: 2.4122262001037598
Validation loss: 2.164343346831619

Epoch: 6| Step: 12
Training loss: 1.6363093852996826
Validation loss: 2.153643549129527

Epoch: 6| Step: 13
Training loss: 1.463623285293579
Validation loss: 2.2119382325039116

Epoch: 431| Step: 0
Training loss: 1.642248272895813
Validation loss: 2.1787169543645715

Epoch: 6| Step: 1
Training loss: 1.6124941110610962
Validation loss: 2.1744946920743553

Epoch: 6| Step: 2
Training loss: 1.0177767276763916
Validation loss: 2.1344799482694237

Epoch: 6| Step: 3
Training loss: 1.68204927444458
Validation loss: 2.1750032927400325

Epoch: 6| Step: 4
Training loss: 1.3649039268493652
Validation loss: 2.131011357871435

Epoch: 6| Step: 5
Training loss: 1.9191133975982666
Validation loss: 2.1475264474909794

Epoch: 6| Step: 6
Training loss: 1.65523099899292
Validation loss: 2.183500566790181

Epoch: 6| Step: 7
Training loss: 1.9809186458587646
Validation loss: 2.163631767354986

Epoch: 6| Step: 8
Training loss: 1.8023483753204346
Validation loss: 2.1991149892089186

Epoch: 6| Step: 9
Training loss: 1.4587599039077759
Validation loss: 2.129422546714865

Epoch: 6| Step: 10
Training loss: 1.9552581310272217
Validation loss: 2.1746176750429216

Epoch: 6| Step: 11
Training loss: 1.789257526397705
Validation loss: 2.1565324260342504

Epoch: 6| Step: 12
Training loss: 1.419267177581787
Validation loss: 2.157980167737571

Epoch: 6| Step: 13
Training loss: 1.1074837446212769
Validation loss: 2.1665041139048915

Epoch: 432| Step: 0
Training loss: 1.8323767185211182
Validation loss: 2.1342622426248368

Epoch: 6| Step: 1
Training loss: 1.2684940099716187
Validation loss: 2.1780776413538123

Epoch: 6| Step: 2
Training loss: 1.6397370100021362
Validation loss: 2.108500229415073

Epoch: 6| Step: 3
Training loss: 1.838489055633545
Validation loss: 2.170990538853471

Epoch: 6| Step: 4
Training loss: 1.1067521572113037
Validation loss: 2.1627192766435686

Epoch: 6| Step: 5
Training loss: 1.0285221338272095
Validation loss: 2.182336345795662

Epoch: 6| Step: 6
Training loss: 1.1688350439071655
Validation loss: 2.130004403411701

Epoch: 6| Step: 7
Training loss: 1.6187729835510254
Validation loss: 2.2149760774386826

Epoch: 6| Step: 8
Training loss: 2.1034674644470215
Validation loss: 2.1939371452536633

Epoch: 6| Step: 9
Training loss: 1.933147668838501
Validation loss: 2.1581340246303107

Epoch: 6| Step: 10
Training loss: 1.8182692527770996
Validation loss: 2.147659827304143

Epoch: 6| Step: 11
Training loss: 1.3282612562179565
Validation loss: 2.1570050075489986

Epoch: 6| Step: 12
Training loss: 1.7989304065704346
Validation loss: 2.159350718221357

Epoch: 6| Step: 13
Training loss: 3.177617073059082
Validation loss: 2.1304028470029115

Epoch: 433| Step: 0
Training loss: 1.643468976020813
Validation loss: 2.1166808015556744

Epoch: 6| Step: 1
Training loss: 2.2366814613342285
Validation loss: 2.1336187060161302

Epoch: 6| Step: 2
Training loss: 1.4826072454452515
Validation loss: 2.168746930296703

Epoch: 6| Step: 3
Training loss: 1.5923479795455933
Validation loss: 2.195148783345376

Epoch: 6| Step: 4
Training loss: 0.8257083892822266
Validation loss: 2.185551530571394

Epoch: 6| Step: 5
Training loss: 1.419014811515808
Validation loss: 2.141973216046569

Epoch: 6| Step: 6
Training loss: 2.2066357135772705
Validation loss: 2.1094478894305486

Epoch: 6| Step: 7
Training loss: 1.7572157382965088
Validation loss: 2.1485981377222205

Epoch: 6| Step: 8
Training loss: 1.8547106981277466
Validation loss: 2.1242159489662416

Epoch: 6| Step: 9
Training loss: 1.1485826969146729
Validation loss: 2.16633851041076

Epoch: 6| Step: 10
Training loss: 1.6205817461013794
Validation loss: 2.168511236867597

Epoch: 6| Step: 11
Training loss: 1.5760161876678467
Validation loss: 2.1518590834832962

Epoch: 6| Step: 12
Training loss: 1.5932859182357788
Validation loss: 2.165593090877738

Epoch: 6| Step: 13
Training loss: 2.3490171432495117
Validation loss: 2.1887535510524625

Epoch: 434| Step: 0
Training loss: 1.0593974590301514
Validation loss: 2.187891766589175

Epoch: 6| Step: 1
Training loss: 1.508177399635315
Validation loss: 2.1569817578920754

Epoch: 6| Step: 2
Training loss: 1.5458650588989258
Validation loss: 2.1812199841263475

Epoch: 6| Step: 3
Training loss: 1.1290442943572998
Validation loss: 2.182571998206518

Epoch: 6| Step: 4
Training loss: 2.1682891845703125
Validation loss: 2.1671265555966284

Epoch: 6| Step: 5
Training loss: 1.4950149059295654
Validation loss: 2.173424228545158

Epoch: 6| Step: 6
Training loss: 1.7392654418945312
Validation loss: 2.164664977340288

Epoch: 6| Step: 7
Training loss: 1.6047344207763672
Validation loss: 2.154182275136312

Epoch: 6| Step: 8
Training loss: 1.69179368019104
Validation loss: 2.1439780342963433

Epoch: 6| Step: 9
Training loss: 1.5937045812606812
Validation loss: 2.1923933593175744

Epoch: 6| Step: 10
Training loss: 1.4323081970214844
Validation loss: 2.1887403995760026

Epoch: 6| Step: 11
Training loss: 2.478332757949829
Validation loss: 2.1258338753895094

Epoch: 6| Step: 12
Training loss: 1.7625696659088135
Validation loss: 2.161286074628112

Epoch: 6| Step: 13
Training loss: 1.8885372877120972
Validation loss: 2.164440965139738

Epoch: 435| Step: 0
Training loss: 1.8247355222702026
Validation loss: 2.1706551556946128

Epoch: 6| Step: 1
Training loss: 1.8851906061172485
Validation loss: 2.164249248402093

Epoch: 6| Step: 2
Training loss: 1.6184675693511963
Validation loss: 2.163728093588224

Epoch: 6| Step: 3
Training loss: 1.9718049764633179
Validation loss: 2.145470142364502

Epoch: 6| Step: 4
Training loss: 1.1520661115646362
Validation loss: 2.1670345337160173

Epoch: 6| Step: 5
Training loss: 2.0877227783203125
Validation loss: 2.157301310570009

Epoch: 6| Step: 6
Training loss: 1.7214266061782837
Validation loss: 2.1458861725304716

Epoch: 6| Step: 7
Training loss: 1.221245527267456
Validation loss: 2.145795545270366

Epoch: 6| Step: 8
Training loss: 1.8507364988327026
Validation loss: 2.160491020448746

Epoch: 6| Step: 9
Training loss: 1.5031051635742188
Validation loss: 2.1530270179112754

Epoch: 6| Step: 10
Training loss: 1.8172718286514282
Validation loss: 2.159985702524903

Epoch: 6| Step: 11
Training loss: 1.065659523010254
Validation loss: 2.2065831935533913

Epoch: 6| Step: 12
Training loss: 1.230311632156372
Validation loss: 2.1242782005699734

Epoch: 6| Step: 13
Training loss: 1.9431275129318237
Validation loss: 2.155483061267484

Epoch: 436| Step: 0
Training loss: 1.633063554763794
Validation loss: 2.1808414869411017

Epoch: 6| Step: 1
Training loss: 1.4554698467254639
Validation loss: 2.1756890948100756

Epoch: 6| Step: 2
Training loss: 2.1078226566314697
Validation loss: 2.1716319873768795

Epoch: 6| Step: 3
Training loss: 1.9753212928771973
Validation loss: 2.169417396668465

Epoch: 6| Step: 4
Training loss: 1.564842700958252
Validation loss: 2.1952363957640944

Epoch: 6| Step: 5
Training loss: 1.7659496068954468
Validation loss: 2.1460092580446632

Epoch: 6| Step: 6
Training loss: 1.663745641708374
Validation loss: 2.144298673957907

Epoch: 6| Step: 7
Training loss: 1.8417017459869385
Validation loss: 2.1636675916692263

Epoch: 6| Step: 8
Training loss: 1.1265486478805542
Validation loss: 2.158031202131702

Epoch: 6| Step: 9
Training loss: 1.5291767120361328
Validation loss: 2.156535335766372

Epoch: 6| Step: 10
Training loss: 1.49006986618042
Validation loss: 2.118725497235534

Epoch: 6| Step: 11
Training loss: 1.724452018737793
Validation loss: 2.1713883030799126

Epoch: 6| Step: 12
Training loss: 1.537597894668579
Validation loss: 2.2020961059037076

Epoch: 6| Step: 13
Training loss: 1.10918128490448
Validation loss: 2.154323932945087

Epoch: 437| Step: 0
Training loss: 1.2997410297393799
Validation loss: 2.135746434170713

Epoch: 6| Step: 1
Training loss: 2.3588690757751465
Validation loss: 2.1255528644848893

Epoch: 6| Step: 2
Training loss: 2.1896018981933594
Validation loss: 2.145648282061341

Epoch: 6| Step: 3
Training loss: 2.6087892055511475
Validation loss: 2.1921510670774724

Epoch: 6| Step: 4
Training loss: 1.0284476280212402
Validation loss: 2.183868372312156

Epoch: 6| Step: 5
Training loss: 1.555859088897705
Validation loss: 2.1924432682734665

Epoch: 6| Step: 6
Training loss: 2.591850519180298
Validation loss: 2.171692402132096

Epoch: 6| Step: 7
Training loss: 1.4124401807785034
Validation loss: 2.1320646860266246

Epoch: 6| Step: 8
Training loss: 1.431868076324463
Validation loss: 2.1611433759812386

Epoch: 6| Step: 9
Training loss: 1.3650975227355957
Validation loss: 2.1822265758309314

Epoch: 6| Step: 10
Training loss: 0.9020166397094727
Validation loss: 2.1722966599208053

Epoch: 6| Step: 11
Training loss: 1.0571683645248413
Validation loss: 2.1575191097874797

Epoch: 6| Step: 12
Training loss: 1.6120398044586182
Validation loss: 2.18548341976699

Epoch: 6| Step: 13
Training loss: 1.314420223236084
Validation loss: 2.181614295128853

Epoch: 438| Step: 0
Training loss: 1.1309553384780884
Validation loss: 2.15707036500336

Epoch: 6| Step: 1
Training loss: 2.113435745239258
Validation loss: 2.153224998904813

Epoch: 6| Step: 2
Training loss: 1.2632505893707275
Validation loss: 2.2096162534529165

Epoch: 6| Step: 3
Training loss: 1.8581695556640625
Validation loss: 2.2062863098677767

Epoch: 6| Step: 4
Training loss: 2.0259041786193848
Validation loss: 2.1588810797660583

Epoch: 6| Step: 5
Training loss: 1.9072940349578857
Validation loss: 2.205472489838959

Epoch: 6| Step: 6
Training loss: 1.5126850605010986
Validation loss: 2.1894539504922848

Epoch: 6| Step: 7
Training loss: 1.033046007156372
Validation loss: 2.1780275837067635

Epoch: 6| Step: 8
Training loss: 1.445023775100708
Validation loss: 2.1379398991984706

Epoch: 6| Step: 9
Training loss: 1.3979978561401367
Validation loss: 2.1652672713802708

Epoch: 6| Step: 10
Training loss: 1.6782957315444946
Validation loss: 2.1288488962317027

Epoch: 6| Step: 11
Training loss: 1.6263989210128784
Validation loss: 2.1459335921913065

Epoch: 6| Step: 12
Training loss: 1.9056071043014526
Validation loss: 2.1642121935403473

Epoch: 6| Step: 13
Training loss: 1.5388498306274414
Validation loss: 2.1569198562252905

Epoch: 439| Step: 0
Training loss: 1.2850375175476074
Validation loss: 2.166537082323464

Epoch: 6| Step: 1
Training loss: 1.4786936044692993
Validation loss: 2.1283370064150904

Epoch: 6| Step: 2
Training loss: 2.1618306636810303
Validation loss: 2.168475727881155

Epoch: 6| Step: 3
Training loss: 1.4200247526168823
Validation loss: 2.161892188492642

Epoch: 6| Step: 4
Training loss: 1.5682305097579956
Validation loss: 2.14123385952365

Epoch: 6| Step: 5
Training loss: 2.0019750595092773
Validation loss: 2.1287322403282247

Epoch: 6| Step: 6
Training loss: 1.9363632202148438
Validation loss: 2.157486911742918

Epoch: 6| Step: 7
Training loss: 1.2930442094802856
Validation loss: 2.165918255365023

Epoch: 6| Step: 8
Training loss: 1.5519640445709229
Validation loss: 2.1487519279603036

Epoch: 6| Step: 9
Training loss: 1.529942274093628
Validation loss: 2.1614472648148895

Epoch: 6| Step: 10
Training loss: 1.584041953086853
Validation loss: 2.167357661390817

Epoch: 6| Step: 11
Training loss: 1.5993967056274414
Validation loss: 2.1428210145683697

Epoch: 6| Step: 12
Training loss: 1.916067361831665
Validation loss: 2.1887486160442395

Epoch: 6| Step: 13
Training loss: 0.8364397287368774
Validation loss: 2.1289213113887335

Epoch: 440| Step: 0
Training loss: 1.6121766567230225
Validation loss: 2.1912389391212055

Epoch: 6| Step: 1
Training loss: 1.9199929237365723
Validation loss: 2.1894447444587626

Epoch: 6| Step: 2
Training loss: 1.933797001838684
Validation loss: 2.1859073587643203

Epoch: 6| Step: 3
Training loss: 1.665393352508545
Validation loss: 2.1971097838494087

Epoch: 6| Step: 4
Training loss: 1.8962411880493164
Validation loss: 2.1465103933888097

Epoch: 6| Step: 5
Training loss: 2.0668349266052246
Validation loss: 2.167362343880438

Epoch: 6| Step: 6
Training loss: 1.168066143989563
Validation loss: 2.1871610854261663

Epoch: 6| Step: 7
Training loss: 1.1243442296981812
Validation loss: 2.1505767324919343

Epoch: 6| Step: 8
Training loss: 1.4741499423980713
Validation loss: 2.156410345467188

Epoch: 6| Step: 9
Training loss: 1.29030179977417
Validation loss: 2.1513569713920675

Epoch: 6| Step: 10
Training loss: 1.6064465045928955
Validation loss: 2.1206717696241153

Epoch: 6| Step: 11
Training loss: 1.4478815793991089
Validation loss: 2.1631176958801928

Epoch: 6| Step: 12
Training loss: 1.156003475189209
Validation loss: 2.163303641862767

Epoch: 6| Step: 13
Training loss: 2.877309799194336
Validation loss: 2.1785293548337874

Epoch: 441| Step: 0
Training loss: 1.1010382175445557
Validation loss: 2.20771836849951

Epoch: 6| Step: 1
Training loss: 1.9775207042694092
Validation loss: 2.2383878307957805

Epoch: 6| Step: 2
Training loss: 1.3222126960754395
Validation loss: 2.175622414517146

Epoch: 6| Step: 3
Training loss: 1.6633596420288086
Validation loss: 2.20576504225372

Epoch: 6| Step: 4
Training loss: 1.9260118007659912
Validation loss: 2.1828841727267028

Epoch: 6| Step: 5
Training loss: 1.410871982574463
Validation loss: 2.185027430134435

Epoch: 6| Step: 6
Training loss: 1.1559689044952393
Validation loss: 2.1703941463142313

Epoch: 6| Step: 7
Training loss: 1.0324126482009888
Validation loss: 2.154428271837132

Epoch: 6| Step: 8
Training loss: 1.7650480270385742
Validation loss: 2.199318378202377

Epoch: 6| Step: 9
Training loss: 2.6698946952819824
Validation loss: 2.161362253209596

Epoch: 6| Step: 10
Training loss: 2.4985501766204834
Validation loss: 2.16054860238106

Epoch: 6| Step: 11
Training loss: 1.7378939390182495
Validation loss: 2.15669112308051

Epoch: 6| Step: 12
Training loss: 1.7739953994750977
Validation loss: 2.152641393805063

Epoch: 6| Step: 13
Training loss: 0.877101480960846
Validation loss: 2.142761709869549

Epoch: 442| Step: 0
Training loss: 1.0633728504180908
Validation loss: 2.197392076574346

Epoch: 6| Step: 1
Training loss: 2.062908887863159
Validation loss: 2.132264575650615

Epoch: 6| Step: 2
Training loss: 1.0477218627929688
Validation loss: 2.1284124479498914

Epoch: 6| Step: 3
Training loss: 1.8395473957061768
Validation loss: 2.162784778943626

Epoch: 6| Step: 4
Training loss: 1.4403407573699951
Validation loss: 2.1388940734248005

Epoch: 6| Step: 5
Training loss: 1.1935228109359741
Validation loss: 2.1697641611099243

Epoch: 6| Step: 6
Training loss: 1.229861855506897
Validation loss: 2.1940439836953276

Epoch: 6| Step: 7
Training loss: 1.7403876781463623
Validation loss: 2.172348858207785

Epoch: 6| Step: 8
Training loss: 2.1825385093688965
Validation loss: 2.1732866892250637

Epoch: 6| Step: 9
Training loss: 1.3954203128814697
Validation loss: 2.2170100571006857

Epoch: 6| Step: 10
Training loss: 2.145904064178467
Validation loss: 2.177919513435774

Epoch: 6| Step: 11
Training loss: 1.8615195751190186
Validation loss: 2.1822377071585706

Epoch: 6| Step: 12
Training loss: 1.4657057523727417
Validation loss: 2.1707519997832594

Epoch: 6| Step: 13
Training loss: 2.8448550701141357
Validation loss: 2.1906427029640443

Epoch: 443| Step: 0
Training loss: 1.9145878553390503
Validation loss: 2.2004657765870452

Epoch: 6| Step: 1
Training loss: 1.7922143936157227
Validation loss: 2.2022025867175032

Epoch: 6| Step: 2
Training loss: 2.0125679969787598
Validation loss: 2.173859001487814

Epoch: 6| Step: 3
Training loss: 1.3996509313583374
Validation loss: 2.1993919341794905

Epoch: 6| Step: 4
Training loss: 1.2576963901519775
Validation loss: 2.146993766548813

Epoch: 6| Step: 5
Training loss: 1.8906604051589966
Validation loss: 2.2082247772524433

Epoch: 6| Step: 6
Training loss: 1.4570947885513306
Validation loss: 2.1419266116234565

Epoch: 6| Step: 7
Training loss: 1.4995090961456299
Validation loss: 2.156543900889735

Epoch: 6| Step: 8
Training loss: 1.1950806379318237
Validation loss: 2.1841084008575766

Epoch: 6| Step: 9
Training loss: 2.488853931427002
Validation loss: 2.1388036730468913

Epoch: 6| Step: 10
Training loss: 1.6265978813171387
Validation loss: 2.1573221914229856

Epoch: 6| Step: 11
Training loss: 1.4792633056640625
Validation loss: 2.1196320287642942

Epoch: 6| Step: 12
Training loss: 0.963756799697876
Validation loss: 2.191307242198657

Epoch: 6| Step: 13
Training loss: 1.4886207580566406
Validation loss: 2.168359251432521

Epoch: 444| Step: 0
Training loss: 1.6779780387878418
Validation loss: 2.1141293869223645

Epoch: 6| Step: 1
Training loss: 1.751088261604309
Validation loss: 2.146314867081181

Epoch: 6| Step: 2
Training loss: 1.0173225402832031
Validation loss: 2.2099947698654665

Epoch: 6| Step: 3
Training loss: 2.221888303756714
Validation loss: 2.1430989260314615

Epoch: 6| Step: 4
Training loss: 1.4096554517745972
Validation loss: 2.1995281686065016

Epoch: 6| Step: 5
Training loss: 1.263688325881958
Validation loss: 2.181023620790051

Epoch: 6| Step: 6
Training loss: 1.58823823928833
Validation loss: 2.138422825003183

Epoch: 6| Step: 7
Training loss: 1.3287187814712524
Validation loss: 2.172989623520964

Epoch: 6| Step: 8
Training loss: 1.690873146057129
Validation loss: 2.1866485893085437

Epoch: 6| Step: 9
Training loss: 2.1063501834869385
Validation loss: 2.1764248032723703

Epoch: 6| Step: 10
Training loss: 1.6040093898773193
Validation loss: 2.1580845950752177

Epoch: 6| Step: 11
Training loss: 1.3801970481872559
Validation loss: 2.135575884131975

Epoch: 6| Step: 12
Training loss: 1.9004061222076416
Validation loss: 2.1623656185724403

Epoch: 6| Step: 13
Training loss: 1.831491470336914
Validation loss: 2.1862407204925374

Epoch: 445| Step: 0
Training loss: 2.2834272384643555
Validation loss: 2.1206250472735335

Epoch: 6| Step: 1
Training loss: 1.6008168458938599
Validation loss: 2.194484226165279

Epoch: 6| Step: 2
Training loss: 1.4499356746673584
Validation loss: 2.14391666330317

Epoch: 6| Step: 3
Training loss: 1.269188404083252
Validation loss: 2.1637519687734623

Epoch: 6| Step: 4
Training loss: 1.5582892894744873
Validation loss: 2.1111957667976298

Epoch: 6| Step: 5
Training loss: 2.3064205646514893
Validation loss: 2.1145572303443827

Epoch: 6| Step: 6
Training loss: 0.8743748664855957
Validation loss: 2.1350060073278283

Epoch: 6| Step: 7
Training loss: 1.4469585418701172
Validation loss: 2.154073458845897

Epoch: 6| Step: 8
Training loss: 2.1210222244262695
Validation loss: 2.183113992855113

Epoch: 6| Step: 9
Training loss: 1.338575839996338
Validation loss: 2.139507216791953

Epoch: 6| Step: 10
Training loss: 1.2036008834838867
Validation loss: 2.1337267314234087

Epoch: 6| Step: 11
Training loss: 1.9155099391937256
Validation loss: 2.1811237758205784

Epoch: 6| Step: 12
Training loss: 1.678825855255127
Validation loss: 2.1957877002736574

Epoch: 6| Step: 13
Training loss: 1.5149048566818237
Validation loss: 2.212320271358695

Epoch: 446| Step: 0
Training loss: 0.9646807312965393
Validation loss: 2.1520909673424176

Epoch: 6| Step: 1
Training loss: 1.9162300825119019
Validation loss: 2.1966878867918447

Epoch: 6| Step: 2
Training loss: 2.2276880741119385
Validation loss: 2.15776232493821

Epoch: 6| Step: 3
Training loss: 1.4737262725830078
Validation loss: 2.1855927154582035

Epoch: 6| Step: 4
Training loss: 1.3032996654510498
Validation loss: 2.1755572339539886

Epoch: 6| Step: 5
Training loss: 1.6296521425247192
Validation loss: 2.1541829903920493

Epoch: 6| Step: 6
Training loss: 1.552438735961914
Validation loss: 2.116791013748415

Epoch: 6| Step: 7
Training loss: 1.1410149335861206
Validation loss: 2.140241584470195

Epoch: 6| Step: 8
Training loss: 1.6487382650375366
Validation loss: 2.1625800107115056

Epoch: 6| Step: 9
Training loss: 1.445427417755127
Validation loss: 2.201909238292325

Epoch: 6| Step: 10
Training loss: 2.194305419921875
Validation loss: 2.161294569251358

Epoch: 6| Step: 11
Training loss: 1.9148250818252563
Validation loss: 2.135909813706593

Epoch: 6| Step: 12
Training loss: 1.5308507680892944
Validation loss: 2.1507280667622886

Epoch: 6| Step: 13
Training loss: 1.6850717067718506
Validation loss: 2.162088292901234

Epoch: 447| Step: 0
Training loss: 1.545771598815918
Validation loss: 2.1866538293900026

Epoch: 6| Step: 1
Training loss: 1.2719132900238037
Validation loss: 2.1722503656982095

Epoch: 6| Step: 2
Training loss: 1.8231914043426514
Validation loss: 2.170726501813499

Epoch: 6| Step: 3
Training loss: 1.5730171203613281
Validation loss: 2.1974298569463913

Epoch: 6| Step: 4
Training loss: 1.5068819522857666
Validation loss: 2.174040707208777

Epoch: 6| Step: 5
Training loss: 1.975290298461914
Validation loss: 2.1993702585979173

Epoch: 6| Step: 6
Training loss: 1.9027988910675049
Validation loss: 2.1732919600702103

Epoch: 6| Step: 7
Training loss: 1.7258415222167969
Validation loss: 2.1752388323507

Epoch: 6| Step: 8
Training loss: 1.4112316370010376
Validation loss: 2.1059105562907394

Epoch: 6| Step: 9
Training loss: 1.4696664810180664
Validation loss: 2.1992215225773473

Epoch: 6| Step: 10
Training loss: 1.439411997795105
Validation loss: 2.1634802433752243

Epoch: 6| Step: 11
Training loss: 2.131464958190918
Validation loss: 2.1723979442350325

Epoch: 6| Step: 12
Training loss: 1.3692269325256348
Validation loss: 2.170696017562702

Epoch: 6| Step: 13
Training loss: 1.282285451889038
Validation loss: 2.2328011733229443

Epoch: 448| Step: 0
Training loss: 1.468032717704773
Validation loss: 2.179617012700727

Epoch: 6| Step: 1
Training loss: 0.9911112785339355
Validation loss: 2.1827532988722607

Epoch: 6| Step: 2
Training loss: 1.49287748336792
Validation loss: 2.1515439043762865

Epoch: 6| Step: 3
Training loss: 1.4704351425170898
Validation loss: 2.2275281849727837

Epoch: 6| Step: 4
Training loss: 1.2914526462554932
Validation loss: 2.2209861573352607

Epoch: 6| Step: 5
Training loss: 1.2585372924804688
Validation loss: 2.220596339112969

Epoch: 6| Step: 6
Training loss: 1.5049867630004883
Validation loss: 2.2190721291367725

Epoch: 6| Step: 7
Training loss: 1.7264137268066406
Validation loss: 2.1672298190414265

Epoch: 6| Step: 8
Training loss: 1.4237960577011108
Validation loss: 2.174924260826521

Epoch: 6| Step: 9
Training loss: 2.1586146354675293
Validation loss: 2.1726575154130177

Epoch: 6| Step: 10
Training loss: 2.376746416091919
Validation loss: 2.1647629942945255

Epoch: 6| Step: 11
Training loss: 2.117614269256592
Validation loss: 2.1382014584797684

Epoch: 6| Step: 12
Training loss: 1.4537981748580933
Validation loss: 2.143289799331337

Epoch: 6| Step: 13
Training loss: 2.021867275238037
Validation loss: 2.1711018739208097

Epoch: 449| Step: 0
Training loss: 1.256156325340271
Validation loss: 2.102916738038422

Epoch: 6| Step: 1
Training loss: 1.6561963558197021
Validation loss: 2.1838243494751635

Epoch: 6| Step: 2
Training loss: 1.468520998954773
Validation loss: 2.1666563633949525

Epoch: 6| Step: 3
Training loss: 1.2279549837112427
Validation loss: 2.1429587512887935

Epoch: 6| Step: 4
Training loss: 1.504518747329712
Validation loss: 2.1251899824347547

Epoch: 6| Step: 5
Training loss: 2.2695276737213135
Validation loss: 2.149074585207047

Epoch: 6| Step: 6
Training loss: 1.2215710878372192
Validation loss: 2.0860795410730506

Epoch: 6| Step: 7
Training loss: 1.8700133562088013
Validation loss: 2.176466049686555

Epoch: 6| Step: 8
Training loss: 1.7008601427078247
Validation loss: 2.1703350031247703

Epoch: 6| Step: 9
Training loss: 1.1509426832199097
Validation loss: 2.1544609621006954

Epoch: 6| Step: 10
Training loss: 1.7520620822906494
Validation loss: 2.1802636192690943

Epoch: 6| Step: 11
Training loss: 1.7151288986206055
Validation loss: 2.134073016464069

Epoch: 6| Step: 12
Training loss: 2.13435697555542
Validation loss: 2.159806602744646

Epoch: 6| Step: 13
Training loss: 1.509401798248291
Validation loss: 2.1532799325963503

Epoch: 450| Step: 0
Training loss: 1.6331062316894531
Validation loss: 2.1549507366713656

Epoch: 6| Step: 1
Training loss: 1.3517186641693115
Validation loss: 2.194979506154214

Epoch: 6| Step: 2
Training loss: 1.5443804264068604
Validation loss: 2.1940817935492403

Epoch: 6| Step: 3
Training loss: 2.35892915725708
Validation loss: 2.133787703770463

Epoch: 6| Step: 4
Training loss: 1.1326407194137573
Validation loss: 2.1474690347589473

Epoch: 6| Step: 5
Training loss: 1.5831918716430664
Validation loss: 2.1768385851255028

Epoch: 6| Step: 6
Training loss: 1.370953917503357
Validation loss: 2.152256578527471

Epoch: 6| Step: 7
Training loss: 1.6351282596588135
Validation loss: 2.1425094117400465

Epoch: 6| Step: 8
Training loss: 1.305647373199463
Validation loss: 2.170573460158481

Epoch: 6| Step: 9
Training loss: 1.720202922821045
Validation loss: 2.1274306184502056

Epoch: 6| Step: 10
Training loss: 1.8484070301055908
Validation loss: 2.169819620347792

Epoch: 6| Step: 11
Training loss: 1.7370954751968384
Validation loss: 2.1345334719586115

Epoch: 6| Step: 12
Training loss: 1.5317656993865967
Validation loss: 2.1492842371745775

Epoch: 6| Step: 13
Training loss: 1.3558818101882935
Validation loss: 2.17364570658694

Epoch: 451| Step: 0
Training loss: 1.3245069980621338
Validation loss: 2.205876842621834

Epoch: 6| Step: 1
Training loss: 1.628280520439148
Validation loss: 2.207925029980239

Epoch: 6| Step: 2
Training loss: 1.8105132579803467
Validation loss: 2.156550886810467

Epoch: 6| Step: 3
Training loss: 1.7287538051605225
Validation loss: 2.158174208415452

Epoch: 6| Step: 4
Training loss: 1.7671622037887573
Validation loss: 2.181721007952126

Epoch: 6| Step: 5
Training loss: 1.3266955614089966
Validation loss: 2.1507393698538504

Epoch: 6| Step: 6
Training loss: 1.4915432929992676
Validation loss: 2.1633016037684616

Epoch: 6| Step: 7
Training loss: 2.1627132892608643
Validation loss: 2.1672033635518884

Epoch: 6| Step: 8
Training loss: 1.5430021286010742
Validation loss: 2.1523699529709353

Epoch: 6| Step: 9
Training loss: 1.0075831413269043
Validation loss: 2.1713502368619366

Epoch: 6| Step: 10
Training loss: 1.7834244966506958
Validation loss: 2.1891901031617196

Epoch: 6| Step: 11
Training loss: 1.6961324214935303
Validation loss: 2.2239974929440405

Epoch: 6| Step: 12
Training loss: 1.7455940246582031
Validation loss: 2.152703597981443

Epoch: 6| Step: 13
Training loss: 1.2379064559936523
Validation loss: 2.1817337313006

Epoch: 452| Step: 0
Training loss: 1.0968109369277954
Validation loss: 2.1770370993562924

Epoch: 6| Step: 1
Training loss: 1.9149324893951416
Validation loss: 2.1875080267588296

Epoch: 6| Step: 2
Training loss: 1.423365592956543
Validation loss: 2.1678433495183147

Epoch: 6| Step: 3
Training loss: 1.0908310413360596
Validation loss: 2.1557494132749495

Epoch: 6| Step: 4
Training loss: 0.8913755416870117
Validation loss: 2.1814697762971282

Epoch: 6| Step: 5
Training loss: 2.580418586730957
Validation loss: 2.104462613341629

Epoch: 6| Step: 6
Training loss: 1.2439141273498535
Validation loss: 2.129202537639167

Epoch: 6| Step: 7
Training loss: 1.9921625852584839
Validation loss: 2.1790839728488716

Epoch: 6| Step: 8
Training loss: 1.7345261573791504
Validation loss: 2.1235954684595906

Epoch: 6| Step: 9
Training loss: 1.9432300329208374
Validation loss: 2.1382663019241823

Epoch: 6| Step: 10
Training loss: 1.6549766063690186
Validation loss: 2.1959201828125985

Epoch: 6| Step: 11
Training loss: 1.615748643875122
Validation loss: 2.126443471959842

Epoch: 6| Step: 12
Training loss: 1.6523864269256592
Validation loss: 2.1713106837323917

Epoch: 6| Step: 13
Training loss: 1.4606974124908447
Validation loss: 2.151077455089938

Epoch: 453| Step: 0
Training loss: 1.4076519012451172
Validation loss: 2.189371608918713

Epoch: 6| Step: 1
Training loss: 1.6470766067504883
Validation loss: 2.1461246372551046

Epoch: 6| Step: 2
Training loss: 2.105853319168091
Validation loss: 2.1717820808451664

Epoch: 6| Step: 3
Training loss: 1.6649746894836426
Validation loss: 2.1904849031920075

Epoch: 6| Step: 4
Training loss: 1.2972912788391113
Validation loss: 2.225981104758478

Epoch: 6| Step: 5
Training loss: 1.4671283960342407
Validation loss: 2.1907816189591602

Epoch: 6| Step: 6
Training loss: 0.9896574020385742
Validation loss: 2.1976581465813423

Epoch: 6| Step: 7
Training loss: 1.301693320274353
Validation loss: 2.1785249171718473

Epoch: 6| Step: 8
Training loss: 1.9952192306518555
Validation loss: 2.1848020553588867

Epoch: 6| Step: 9
Training loss: 1.4947518110275269
Validation loss: 2.193429990481305

Epoch: 6| Step: 10
Training loss: 2.07540225982666
Validation loss: 2.1952594352024857

Epoch: 6| Step: 11
Training loss: 1.6260238885879517
Validation loss: 2.208869634136077

Epoch: 6| Step: 12
Training loss: 1.610166311264038
Validation loss: 2.197826485480032

Epoch: 6| Step: 13
Training loss: 2.1613149642944336
Validation loss: 2.143858402006088

Epoch: 454| Step: 0
Training loss: 1.2801249027252197
Validation loss: 2.1484017269585722

Epoch: 6| Step: 1
Training loss: 1.3521286249160767
Validation loss: 2.191403260795019

Epoch: 6| Step: 2
Training loss: 1.8989344835281372
Validation loss: 2.144744212909411

Epoch: 6| Step: 3
Training loss: 1.5331377983093262
Validation loss: 2.195967694764496

Epoch: 6| Step: 4
Training loss: 1.0046581029891968
Validation loss: 2.215540203996884

Epoch: 6| Step: 5
Training loss: 1.8782681226730347
Validation loss: 2.1689995604176677

Epoch: 6| Step: 6
Training loss: 1.5410399436950684
Validation loss: 2.1830701340911207

Epoch: 6| Step: 7
Training loss: 2.4106454849243164
Validation loss: 2.1491812711120932

Epoch: 6| Step: 8
Training loss: 1.7350971698760986
Validation loss: 2.1356672522842244

Epoch: 6| Step: 9
Training loss: 1.1617631912231445
Validation loss: 2.178463437223947

Epoch: 6| Step: 10
Training loss: 1.8245315551757812
Validation loss: 2.1454272193293416

Epoch: 6| Step: 11
Training loss: 1.086912751197815
Validation loss: 2.1699070469025643

Epoch: 6| Step: 12
Training loss: 2.2962806224823
Validation loss: 2.175433225529168

Epoch: 6| Step: 13
Training loss: 1.4007208347320557
Validation loss: 2.1971178400901055

Epoch: 455| Step: 0
Training loss: 0.9094506502151489
Validation loss: 2.188061301426221

Epoch: 6| Step: 1
Training loss: 1.5801657438278198
Validation loss: 2.2088691239715903

Epoch: 6| Step: 2
Training loss: 1.1663910150527954
Validation loss: 2.1757554956661758

Epoch: 6| Step: 3
Training loss: 1.9726139307022095
Validation loss: 2.1204308937954646

Epoch: 6| Step: 4
Training loss: 1.2096729278564453
Validation loss: 2.1734920586309125

Epoch: 6| Step: 5
Training loss: 1.6133286952972412
Validation loss: 2.1510426741774364

Epoch: 6| Step: 6
Training loss: 1.3493170738220215
Validation loss: 2.1547416346047514

Epoch: 6| Step: 7
Training loss: 1.7740976810455322
Validation loss: 2.2037791834082654

Epoch: 6| Step: 8
Training loss: 1.2496371269226074
Validation loss: 2.132931774662387

Epoch: 6| Step: 9
Training loss: 1.6655523777008057
Validation loss: 2.2403988684377363

Epoch: 6| Step: 10
Training loss: 2.401082992553711
Validation loss: 2.197866669265173

Epoch: 6| Step: 11
Training loss: 1.291499376296997
Validation loss: 2.1430091575909684

Epoch: 6| Step: 12
Training loss: 2.4302549362182617
Validation loss: 2.1531484524408975

Epoch: 6| Step: 13
Training loss: 1.8324198722839355
Validation loss: 2.173273409566572

Epoch: 456| Step: 0
Training loss: 1.4012985229492188
Validation loss: 2.184856976232221

Epoch: 6| Step: 1
Training loss: 1.4300496578216553
Validation loss: 2.1639503420040174

Epoch: 6| Step: 2
Training loss: 1.7364639043807983
Validation loss: 2.192400032474149

Epoch: 6| Step: 3
Training loss: 1.3919048309326172
Validation loss: 2.140804898354315

Epoch: 6| Step: 4
Training loss: 1.3407620191574097
Validation loss: 2.1553976997252433

Epoch: 6| Step: 5
Training loss: 1.602063536643982
Validation loss: 2.2326260279583674

Epoch: 6| Step: 6
Training loss: 1.8562816381454468
Validation loss: 2.157634222379295

Epoch: 6| Step: 7
Training loss: 1.4494361877441406
Validation loss: 2.1762386803985923

Epoch: 6| Step: 8
Training loss: 2.115907669067383
Validation loss: 2.207466411334212

Epoch: 6| Step: 9
Training loss: 1.8569293022155762
Validation loss: 2.185364397623206

Epoch: 6| Step: 10
Training loss: 1.3530223369598389
Validation loss: 2.21592527820218

Epoch: 6| Step: 11
Training loss: 1.4234981536865234
Validation loss: 2.118826904604512

Epoch: 6| Step: 12
Training loss: 1.8427188396453857
Validation loss: 2.1862710932249665

Epoch: 6| Step: 13
Training loss: 0.8918068408966064
Validation loss: 2.2063362931692474

Epoch: 457| Step: 0
Training loss: 2.5584588050842285
Validation loss: 2.188025488648363

Epoch: 6| Step: 1
Training loss: 1.2625364065170288
Validation loss: 2.187664685710784

Epoch: 6| Step: 2
Training loss: 1.107182502746582
Validation loss: 2.1811467396315707

Epoch: 6| Step: 3
Training loss: 2.263009548187256
Validation loss: 2.202883025651337

Epoch: 6| Step: 4
Training loss: 1.6365368366241455
Validation loss: 2.1693123976389566

Epoch: 6| Step: 5
Training loss: 1.291410207748413
Validation loss: 2.155667599811349

Epoch: 6| Step: 6
Training loss: 1.1847591400146484
Validation loss: 2.2209514725592827

Epoch: 6| Step: 7
Training loss: 1.1222528219223022
Validation loss: 2.1708479081430743

Epoch: 6| Step: 8
Training loss: 2.120894432067871
Validation loss: 2.1682008107503257

Epoch: 6| Step: 9
Training loss: 2.1270248889923096
Validation loss: 2.165090448112898

Epoch: 6| Step: 10
Training loss: 0.9526474475860596
Validation loss: 2.1906420774357294

Epoch: 6| Step: 11
Training loss: 1.3741319179534912
Validation loss: 2.1444180960296304

Epoch: 6| Step: 12
Training loss: 2.50543212890625
Validation loss: 2.1671876804803007

Epoch: 6| Step: 13
Training loss: 0.8286292552947998
Validation loss: 2.1711421551242953

Epoch: 458| Step: 0
Training loss: 2.264820098876953
Validation loss: 2.172252901138798

Epoch: 6| Step: 1
Training loss: 1.1285619735717773
Validation loss: 2.095584700184484

Epoch: 6| Step: 2
Training loss: 1.3475496768951416
Validation loss: 2.1361140320377965

Epoch: 6| Step: 3
Training loss: 1.1964976787567139
Validation loss: 2.094144808348789

Epoch: 6| Step: 4
Training loss: 2.8035318851470947
Validation loss: 2.173056387132214

Epoch: 6| Step: 5
Training loss: 1.3500303030014038
Validation loss: 2.12992049032642

Epoch: 6| Step: 6
Training loss: 2.154453754425049
Validation loss: 2.1196133654604674

Epoch: 6| Step: 7
Training loss: 1.2680995464324951
Validation loss: 2.150273346131848

Epoch: 6| Step: 8
Training loss: 1.3912969827651978
Validation loss: 2.16221938338331

Epoch: 6| Step: 9
Training loss: 1.4427647590637207
Validation loss: 2.1568746387317614

Epoch: 6| Step: 10
Training loss: 1.5900909900665283
Validation loss: 2.15391521300039

Epoch: 6| Step: 11
Training loss: 1.4733555316925049
Validation loss: 2.175907386246548

Epoch: 6| Step: 12
Training loss: 1.2977079153060913
Validation loss: 2.1789648507231023

Epoch: 6| Step: 13
Training loss: 1.5019278526306152
Validation loss: 2.1668839582832913

Epoch: 459| Step: 0
Training loss: 1.1780774593353271
Validation loss: 2.1855240355255785

Epoch: 6| Step: 1
Training loss: 1.921273112297058
Validation loss: 2.1260574633075344

Epoch: 6| Step: 2
Training loss: 1.3440443277359009
Validation loss: 2.161208014334402

Epoch: 6| Step: 3
Training loss: 1.5594249963760376
Validation loss: 2.1671520112663187

Epoch: 6| Step: 4
Training loss: 1.8964484930038452
Validation loss: 2.174470645125194

Epoch: 6| Step: 5
Training loss: 1.8473594188690186
Validation loss: 2.179097294807434

Epoch: 6| Step: 6
Training loss: 1.6063523292541504
Validation loss: 2.168697959633284

Epoch: 6| Step: 7
Training loss: 2.128127098083496
Validation loss: 2.162735487825127

Epoch: 6| Step: 8
Training loss: 0.965186595916748
Validation loss: 2.171954354932231

Epoch: 6| Step: 9
Training loss: 1.6562623977661133
Validation loss: 2.136348006545856

Epoch: 6| Step: 10
Training loss: 1.4834692478179932
Validation loss: 2.2146288694873935

Epoch: 6| Step: 11
Training loss: 0.9901171922683716
Validation loss: 2.15233584373228

Epoch: 6| Step: 12
Training loss: 1.2008496522903442
Validation loss: 2.1851653334914998

Epoch: 6| Step: 13
Training loss: 2.5743982791900635
Validation loss: 2.190347179289787

Epoch: 460| Step: 0
Training loss: 1.2886781692504883
Validation loss: 2.1786989909346386

Epoch: 6| Step: 1
Training loss: 0.9076511859893799
Validation loss: 2.187929641815924

Epoch: 6| Step: 2
Training loss: 2.024327278137207
Validation loss: 2.1920786134658323

Epoch: 6| Step: 3
Training loss: 1.539084792137146
Validation loss: 2.161443096335216

Epoch: 6| Step: 4
Training loss: 1.873579740524292
Validation loss: 2.147626728139898

Epoch: 6| Step: 5
Training loss: 1.4233732223510742
Validation loss: 2.1499329920737975

Epoch: 6| Step: 6
Training loss: 1.715789556503296
Validation loss: 2.1592074953099734

Epoch: 6| Step: 7
Training loss: 1.1222484111785889
Validation loss: 2.140571250710436

Epoch: 6| Step: 8
Training loss: 1.5477592945098877
Validation loss: 2.1571343457827004

Epoch: 6| Step: 9
Training loss: 1.4373033046722412
Validation loss: 2.1743139528459117

Epoch: 6| Step: 10
Training loss: 2.3764846324920654
Validation loss: 2.152989947667686

Epoch: 6| Step: 11
Training loss: 1.3446977138519287
Validation loss: 2.1543421027480916

Epoch: 6| Step: 12
Training loss: 1.7620806694030762
Validation loss: 2.1112579991740565

Epoch: 6| Step: 13
Training loss: 1.8492521047592163
Validation loss: 2.159006134156258

Epoch: 461| Step: 0
Training loss: 1.7877558469772339
Validation loss: 2.2162052892869517

Epoch: 6| Step: 1
Training loss: 1.7450218200683594
Validation loss: 2.1581725561490623

Epoch: 6| Step: 2
Training loss: 1.5035922527313232
Validation loss: 2.1524574871986144

Epoch: 6| Step: 3
Training loss: 1.6011810302734375
Validation loss: 2.174172252737066

Epoch: 6| Step: 4
Training loss: 1.2146103382110596
Validation loss: 2.1865811424870647

Epoch: 6| Step: 5
Training loss: 1.6479144096374512
Validation loss: 2.185860836377708

Epoch: 6| Step: 6
Training loss: 1.1332128047943115
Validation loss: 2.1831955589273924

Epoch: 6| Step: 7
Training loss: 1.7966479063034058
Validation loss: 2.159269393131297

Epoch: 6| Step: 8
Training loss: 1.0055949687957764
Validation loss: 2.2086055868415424

Epoch: 6| Step: 9
Training loss: 1.7447236776351929
Validation loss: 2.217198189868722

Epoch: 6| Step: 10
Training loss: 1.5850017070770264
Validation loss: 2.1904973855582615

Epoch: 6| Step: 11
Training loss: 1.6916829347610474
Validation loss: 2.200876916608503

Epoch: 6| Step: 12
Training loss: 1.7598811388015747
Validation loss: 2.179309860352547

Epoch: 6| Step: 13
Training loss: 2.25814151763916
Validation loss: 2.1568135343572146

Epoch: 462| Step: 0
Training loss: 1.294131875038147
Validation loss: 2.1880363648937595

Epoch: 6| Step: 1
Training loss: 1.0260522365570068
Validation loss: 2.16204462897393

Epoch: 6| Step: 2
Training loss: 1.621488332748413
Validation loss: 2.186787566831035

Epoch: 6| Step: 3
Training loss: 1.871480941772461
Validation loss: 2.15453815203841

Epoch: 6| Step: 4
Training loss: 1.127497911453247
Validation loss: 2.221402252874067

Epoch: 6| Step: 5
Training loss: 1.714473009109497
Validation loss: 2.1972663171829714

Epoch: 6| Step: 6
Training loss: 0.7021479606628418
Validation loss: 2.2128356861811813

Epoch: 6| Step: 7
Training loss: 1.8495625257492065
Validation loss: 2.1963934975285686

Epoch: 6| Step: 8
Training loss: 1.5322424173355103
Validation loss: 2.1634130964996996

Epoch: 6| Step: 9
Training loss: 1.6300463676452637
Validation loss: 2.1782542300480667

Epoch: 6| Step: 10
Training loss: 2.3021669387817383
Validation loss: 2.2114738572028374

Epoch: 6| Step: 11
Training loss: 1.3722944259643555
Validation loss: 2.1998184906539096

Epoch: 6| Step: 12
Training loss: 1.7904479503631592
Validation loss: 2.223671031254594

Epoch: 6| Step: 13
Training loss: 2.6461384296417236
Validation loss: 2.2008518916304394

Epoch: 463| Step: 0
Training loss: 2.314600944519043
Validation loss: 2.17925250914789

Epoch: 6| Step: 1
Training loss: 1.6874163150787354
Validation loss: 2.1590598937003844

Epoch: 6| Step: 2
Training loss: 1.2274019718170166
Validation loss: 2.145509381448069

Epoch: 6| Step: 3
Training loss: 1.3059405088424683
Validation loss: 2.1440578160747403

Epoch: 6| Step: 4
Training loss: 1.4927492141723633
Validation loss: 2.1609012516595985

Epoch: 6| Step: 5
Training loss: 1.387619972229004
Validation loss: 2.157375026774663

Epoch: 6| Step: 6
Training loss: 1.737174391746521
Validation loss: 2.1723527703233945

Epoch: 6| Step: 7
Training loss: 1.6773250102996826
Validation loss: 2.1303403928715694

Epoch: 6| Step: 8
Training loss: 1.8550962209701538
Validation loss: 2.1346752361584733

Epoch: 6| Step: 9
Training loss: 1.828245997428894
Validation loss: 2.195019418193448

Epoch: 6| Step: 10
Training loss: 1.40218186378479
Validation loss: 2.107212543487549

Epoch: 6| Step: 11
Training loss: 1.229515552520752
Validation loss: 2.1432232164567515

Epoch: 6| Step: 12
Training loss: 1.4284735918045044
Validation loss: 2.1632393175555813

Epoch: 6| Step: 13
Training loss: 1.3386554718017578
Validation loss: 2.1218452351067656

Epoch: 464| Step: 0
Training loss: 2.0502305030822754
Validation loss: 2.1626217685719973

Epoch: 6| Step: 1
Training loss: 1.3426443338394165
Validation loss: 2.1462599308260026

Epoch: 6| Step: 2
Training loss: 1.5355279445648193
Validation loss: 2.161629730655301

Epoch: 6| Step: 3
Training loss: 1.9989194869995117
Validation loss: 2.1359546466540267

Epoch: 6| Step: 4
Training loss: 1.4692692756652832
Validation loss: 2.204590453896471

Epoch: 6| Step: 5
Training loss: 1.1668146848678589
Validation loss: 2.1868981212698

Epoch: 6| Step: 6
Training loss: 0.7301191091537476
Validation loss: 2.173057181860811

Epoch: 6| Step: 7
Training loss: 1.9254376888275146
Validation loss: 2.1760773633116033

Epoch: 6| Step: 8
Training loss: 1.3023852109909058
Validation loss: 2.1521343159419235

Epoch: 6| Step: 9
Training loss: 1.2487505674362183
Validation loss: 2.1748436420194563

Epoch: 6| Step: 10
Training loss: 2.5002450942993164
Validation loss: 2.204031798147386

Epoch: 6| Step: 11
Training loss: 1.633018136024475
Validation loss: 2.1747503819004184

Epoch: 6| Step: 12
Training loss: 1.6253913640975952
Validation loss: 2.2346104011740735

Epoch: 6| Step: 13
Training loss: 1.47335684299469
Validation loss: 2.2220324726514917

Epoch: 465| Step: 0
Training loss: 2.2863945960998535
Validation loss: 2.163220936252225

Epoch: 6| Step: 1
Training loss: 1.3533306121826172
Validation loss: 2.1924872116375993

Epoch: 6| Step: 2
Training loss: 2.448493480682373
Validation loss: 2.2059964774757304

Epoch: 6| Step: 3
Training loss: 1.6044865846633911
Validation loss: 2.13042631969657

Epoch: 6| Step: 4
Training loss: 1.7338991165161133
Validation loss: 2.1871584102671635

Epoch: 6| Step: 5
Training loss: 1.0892442464828491
Validation loss: 2.1891358129439817

Epoch: 6| Step: 6
Training loss: 1.1016786098480225
Validation loss: 2.15347945561973

Epoch: 6| Step: 7
Training loss: 1.3045178651809692
Validation loss: 2.1676860086379515

Epoch: 6| Step: 8
Training loss: 1.5843698978424072
Validation loss: 2.214520387752082

Epoch: 6| Step: 9
Training loss: 1.6020114421844482
Validation loss: 2.1710304470472437

Epoch: 6| Step: 10
Training loss: 1.2513169050216675
Validation loss: 2.1911939638917164

Epoch: 6| Step: 11
Training loss: 1.8627920150756836
Validation loss: 2.174589216068227

Epoch: 6| Step: 12
Training loss: 1.8796870708465576
Validation loss: 2.2149564002149846

Epoch: 6| Step: 13
Training loss: 1.0637295246124268
Validation loss: 2.176876555206955

Epoch: 466| Step: 0
Training loss: 1.057056188583374
Validation loss: 2.196764182018977

Epoch: 6| Step: 1
Training loss: 0.9599114656448364
Validation loss: 2.194065829759003

Epoch: 6| Step: 2
Training loss: 1.12355375289917
Validation loss: 2.193135542254294

Epoch: 6| Step: 3
Training loss: 1.7628991603851318
Validation loss: 2.1574287106913905

Epoch: 6| Step: 4
Training loss: 2.337416648864746
Validation loss: 2.216030074704078

Epoch: 6| Step: 5
Training loss: 2.249073028564453
Validation loss: 2.120798610871838

Epoch: 6| Step: 6
Training loss: 2.071934223175049
Validation loss: 2.147490883386263

Epoch: 6| Step: 7
Training loss: 1.2159202098846436
Validation loss: 2.2049496994223645

Epoch: 6| Step: 8
Training loss: 2.191389560699463
Validation loss: 2.160452773494105

Epoch: 6| Step: 9
Training loss: 1.0851972103118896
Validation loss: 2.118124913143855

Epoch: 6| Step: 10
Training loss: 1.6382756233215332
Validation loss: 2.175010468370171

Epoch: 6| Step: 11
Training loss: 1.5923771858215332
Validation loss: 2.1709049824745423

Epoch: 6| Step: 12
Training loss: 1.5247013568878174
Validation loss: 2.1664127175525953

Epoch: 6| Step: 13
Training loss: 0.9458052515983582
Validation loss: 2.1965858487672705

Epoch: 467| Step: 0
Training loss: 1.233116865158081
Validation loss: 2.201686151566044

Epoch: 6| Step: 1
Training loss: 2.143296957015991
Validation loss: 2.1428300334561254

Epoch: 6| Step: 2
Training loss: 1.9987249374389648
Validation loss: 2.164630628401233

Epoch: 6| Step: 3
Training loss: 1.8985958099365234
Validation loss: 2.1142095699105212

Epoch: 6| Step: 4
Training loss: 1.562511682510376
Validation loss: 2.148434564631472

Epoch: 6| Step: 5
Training loss: 1.3938179016113281
Validation loss: 2.193125363319151

Epoch: 6| Step: 6
Training loss: 1.8536607027053833
Validation loss: 2.182496557953537

Epoch: 6| Step: 7
Training loss: 1.35239839553833
Validation loss: 2.182371142090008

Epoch: 6| Step: 8
Training loss: 1.2082703113555908
Validation loss: 2.1673495410591044

Epoch: 6| Step: 9
Training loss: 1.837450623512268
Validation loss: 2.2155438161665395

Epoch: 6| Step: 10
Training loss: 1.6414371728897095
Validation loss: 2.1713925407778834

Epoch: 6| Step: 11
Training loss: 1.287841796875
Validation loss: 2.206630109458841

Epoch: 6| Step: 12
Training loss: 1.2470803260803223
Validation loss: 2.2295161524126605

Epoch: 6| Step: 13
Training loss: 0.9908521175384521
Validation loss: 2.19527857277983

Epoch: 468| Step: 0
Training loss: 1.5513859987258911
Validation loss: 2.2132048119780836

Epoch: 6| Step: 1
Training loss: 2.043160915374756
Validation loss: 2.1833295296597224

Epoch: 6| Step: 2
Training loss: 2.118438959121704
Validation loss: 2.1949915732106855

Epoch: 6| Step: 3
Training loss: 1.5035144090652466
Validation loss: 2.1338489145360966

Epoch: 6| Step: 4
Training loss: 0.9659368991851807
Validation loss: 2.1973801402635473

Epoch: 6| Step: 5
Training loss: 1.5567939281463623
Validation loss: 2.178768616850658

Epoch: 6| Step: 6
Training loss: 1.58933424949646
Validation loss: 2.176845840228501

Epoch: 6| Step: 7
Training loss: 1.3347901105880737
Validation loss: 2.133655216104241

Epoch: 6| Step: 8
Training loss: 1.2039227485656738
Validation loss: 2.166339405121342

Epoch: 6| Step: 9
Training loss: 1.1483720541000366
Validation loss: 2.2055022588340183

Epoch: 6| Step: 10
Training loss: 1.756160020828247
Validation loss: 2.171308058564381

Epoch: 6| Step: 11
Training loss: 1.3406293392181396
Validation loss: 2.1750452428735714

Epoch: 6| Step: 12
Training loss: 2.236175775527954
Validation loss: 2.1920730606202157

Epoch: 6| Step: 13
Training loss: 1.6785614490509033
Validation loss: 2.1927192698242846

Epoch: 469| Step: 0
Training loss: 1.8454923629760742
Validation loss: 2.2109996067580355

Epoch: 6| Step: 1
Training loss: 1.9333584308624268
Validation loss: 2.171579227652601

Epoch: 6| Step: 2
Training loss: 1.5663650035858154
Validation loss: 2.168370754488053

Epoch: 6| Step: 3
Training loss: 1.4160881042480469
Validation loss: 2.1634366512298584

Epoch: 6| Step: 4
Training loss: 1.423669457435608
Validation loss: 2.167850225202499

Epoch: 6| Step: 5
Training loss: 1.32535719871521
Validation loss: 2.1701052060691257

Epoch: 6| Step: 6
Training loss: 1.61875581741333
Validation loss: 2.15337017274672

Epoch: 6| Step: 7
Training loss: 1.2488830089569092
Validation loss: 2.1742673868774087

Epoch: 6| Step: 8
Training loss: 1.7410550117492676
Validation loss: 2.1726524035135903

Epoch: 6| Step: 9
Training loss: 1.3986282348632812
Validation loss: 2.190116931033391

Epoch: 6| Step: 10
Training loss: 1.999077558517456
Validation loss: 2.1791668066414456

Epoch: 6| Step: 11
Training loss: 1.8304977416992188
Validation loss: 2.116773020836615

Epoch: 6| Step: 12
Training loss: 0.8364420533180237
Validation loss: 2.158750493039367

Epoch: 6| Step: 13
Training loss: 1.7776618003845215
Validation loss: 2.2110935257327173

Epoch: 470| Step: 0
Training loss: 1.1938440799713135
Validation loss: 2.151666223361928

Epoch: 6| Step: 1
Training loss: 1.907346487045288
Validation loss: 2.171885636544997

Epoch: 6| Step: 2
Training loss: 1.4741027355194092
Validation loss: 2.1644768868723223

Epoch: 6| Step: 3
Training loss: 1.7314739227294922
Validation loss: 2.1408638313252437

Epoch: 6| Step: 4
Training loss: 1.4317728281021118
Validation loss: 2.1416523020754576

Epoch: 6| Step: 5
Training loss: 1.0898947715759277
Validation loss: 2.2032425365140362

Epoch: 6| Step: 6
Training loss: 1.3536205291748047
Validation loss: 2.1989000945962887

Epoch: 6| Step: 7
Training loss: 1.313490390777588
Validation loss: 2.1651804652265323

Epoch: 6| Step: 8
Training loss: 1.9020154476165771
Validation loss: 2.200473813600438

Epoch: 6| Step: 9
Training loss: 1.650467872619629
Validation loss: 2.2052526115089335

Epoch: 6| Step: 10
Training loss: 2.184196949005127
Validation loss: 2.1634424963305072

Epoch: 6| Step: 11
Training loss: 1.749717354774475
Validation loss: 2.158128821721641

Epoch: 6| Step: 12
Training loss: 1.3021283149719238
Validation loss: 2.169389001784786

Epoch: 6| Step: 13
Training loss: 1.1775296926498413
Validation loss: 2.2053349505188646

Epoch: 471| Step: 0
Training loss: 1.9439606666564941
Validation loss: 2.217460250341764

Epoch: 6| Step: 1
Training loss: 1.7133445739746094
Validation loss: 2.17785551727459

Epoch: 6| Step: 2
Training loss: 1.4197349548339844
Validation loss: 2.2186362371649793

Epoch: 6| Step: 3
Training loss: 1.5952415466308594
Validation loss: 2.1897289958051456

Epoch: 6| Step: 4
Training loss: 1.6725642681121826
Validation loss: 2.2117717753174486

Epoch: 6| Step: 5
Training loss: 1.306526780128479
Validation loss: 2.226782730830613

Epoch: 6| Step: 6
Training loss: 1.9156889915466309
Validation loss: 2.1337633504662463

Epoch: 6| Step: 7
Training loss: 0.6607030034065247
Validation loss: 2.2039474876978065

Epoch: 6| Step: 8
Training loss: 1.6366668939590454
Validation loss: 2.153965268083798

Epoch: 6| Step: 9
Training loss: 1.4702109098434448
Validation loss: 2.1780192262382916

Epoch: 6| Step: 10
Training loss: 1.6454098224639893
Validation loss: 2.1849884602331344

Epoch: 6| Step: 11
Training loss: 1.5006639957427979
Validation loss: 2.1684558827389955

Epoch: 6| Step: 12
Training loss: 1.922703742980957
Validation loss: 2.1753987368716987

Epoch: 6| Step: 13
Training loss: 1.4179649353027344
Validation loss: 2.1367716020153416

Epoch: 472| Step: 0
Training loss: 1.802362322807312
Validation loss: 2.159190289435848

Epoch: 6| Step: 1
Training loss: 1.1037302017211914
Validation loss: 2.175702618014428

Epoch: 6| Step: 2
Training loss: 1.4485869407653809
Validation loss: 2.1370351019726006

Epoch: 6| Step: 3
Training loss: 0.9697719812393188
Validation loss: 2.1299435348920923

Epoch: 6| Step: 4
Training loss: 1.7554712295532227
Validation loss: 2.12671414754724

Epoch: 6| Step: 5
Training loss: 1.959043025970459
Validation loss: 2.2042051669090026

Epoch: 6| Step: 6
Training loss: 0.8370603919029236
Validation loss: 2.185678981965588

Epoch: 6| Step: 7
Training loss: 1.3502295017242432
Validation loss: 2.114871989014328

Epoch: 6| Step: 8
Training loss: 1.7360347509384155
Validation loss: 2.1251137615532003

Epoch: 6| Step: 9
Training loss: 2.0190000534057617
Validation loss: 2.1566367072443806

Epoch: 6| Step: 10
Training loss: 1.6046454906463623
Validation loss: 2.1518595103294618

Epoch: 6| Step: 11
Training loss: 0.9882919788360596
Validation loss: 2.158868476908694

Epoch: 6| Step: 12
Training loss: 1.3012080192565918
Validation loss: 2.154393752415975

Epoch: 6| Step: 13
Training loss: 3.0174314975738525
Validation loss: 2.191290073497321

Epoch: 473| Step: 0
Training loss: 0.9327666163444519
Validation loss: 2.178181744390918

Epoch: 6| Step: 1
Training loss: 1.4604641199111938
Validation loss: 2.2326796439386185

Epoch: 6| Step: 2
Training loss: 1.735056757926941
Validation loss: 2.1702757766169887

Epoch: 6| Step: 3
Training loss: 0.6930321455001831
Validation loss: 2.156774003018615

Epoch: 6| Step: 4
Training loss: 2.1814804077148438
Validation loss: 2.1729621733388593

Epoch: 6| Step: 5
Training loss: 2.0398073196411133
Validation loss: 2.1622593556680987

Epoch: 6| Step: 6
Training loss: 2.070950984954834
Validation loss: 2.196959746781216

Epoch: 6| Step: 7
Training loss: 1.8165727853775024
Validation loss: 2.212476599601007

Epoch: 6| Step: 8
Training loss: 1.4894264936447144
Validation loss: 2.1449748187936764

Epoch: 6| Step: 9
Training loss: 1.0902659893035889
Validation loss: 2.155244823425047

Epoch: 6| Step: 10
Training loss: 1.527876377105713
Validation loss: 2.1260198290630052

Epoch: 6| Step: 11
Training loss: 1.9440581798553467
Validation loss: 2.166060370783652

Epoch: 6| Step: 12
Training loss: 1.3253647089004517
Validation loss: 2.2125215325304257

Epoch: 6| Step: 13
Training loss: 1.5451514720916748
Validation loss: 2.1595882677262828

Epoch: 474| Step: 0
Training loss: 1.234824299812317
Validation loss: 2.1711691861511557

Epoch: 6| Step: 1
Training loss: 1.27542245388031
Validation loss: 2.16812995044134

Epoch: 6| Step: 2
Training loss: 2.024815082550049
Validation loss: 2.154264424436836

Epoch: 6| Step: 3
Training loss: 1.9903308153152466
Validation loss: 2.16277604205634

Epoch: 6| Step: 4
Training loss: 1.7820730209350586
Validation loss: 2.146998469547559

Epoch: 6| Step: 5
Training loss: 1.4379082918167114
Validation loss: 2.2120325180792038

Epoch: 6| Step: 6
Training loss: 1.1239731311798096
Validation loss: 2.1431801293485906

Epoch: 6| Step: 7
Training loss: 1.141787052154541
Validation loss: 2.172775664637166

Epoch: 6| Step: 8
Training loss: 1.8610844612121582
Validation loss: 2.1740986916326706

Epoch: 6| Step: 9
Training loss: 1.8215370178222656
Validation loss: 2.158973919448032

Epoch: 6| Step: 10
Training loss: 1.4135184288024902
Validation loss: 2.1649600831411218

Epoch: 6| Step: 11
Training loss: 1.3088103532791138
Validation loss: 2.1630424645639237

Epoch: 6| Step: 12
Training loss: 1.0814040899276733
Validation loss: 2.1701226311345256

Epoch: 6| Step: 13
Training loss: 2.6737074851989746
Validation loss: 2.165848673030894

Epoch: 475| Step: 0
Training loss: 1.5039377212524414
Validation loss: 2.176504288950274

Epoch: 6| Step: 1
Training loss: 2.1327123641967773
Validation loss: 2.168884887490221

Epoch: 6| Step: 2
Training loss: 1.8407055139541626
Validation loss: 2.1767959851090626

Epoch: 6| Step: 3
Training loss: 1.6186683177947998
Validation loss: 2.1681371863170336

Epoch: 6| Step: 4
Training loss: 1.8731045722961426
Validation loss: 2.1564528865198933

Epoch: 6| Step: 5
Training loss: 1.156099796295166
Validation loss: 2.1861771127229095

Epoch: 6| Step: 6
Training loss: 1.2489674091339111
Validation loss: 2.18612398639802

Epoch: 6| Step: 7
Training loss: 1.302117109298706
Validation loss: 2.177597879081644

Epoch: 6| Step: 8
Training loss: 1.6269729137420654
Validation loss: 2.2074054312962357

Epoch: 6| Step: 9
Training loss: 1.3545700311660767
Validation loss: 2.1623791302404096

Epoch: 6| Step: 10
Training loss: 1.922032356262207
Validation loss: 2.1382530030383857

Epoch: 6| Step: 11
Training loss: 1.0544543266296387
Validation loss: 2.201836516780238

Epoch: 6| Step: 12
Training loss: 1.3285540342330933
Validation loss: 2.1747156625152915

Epoch: 6| Step: 13
Training loss: 1.8723746538162231
Validation loss: 2.1745506332766626

Epoch: 476| Step: 0
Training loss: 1.7114577293395996
Validation loss: 2.1979525807083293

Epoch: 6| Step: 1
Training loss: 1.8490214347839355
Validation loss: 2.183266129544986

Epoch: 6| Step: 2
Training loss: 1.1660966873168945
Validation loss: 2.1702314704977055

Epoch: 6| Step: 3
Training loss: 1.363661289215088
Validation loss: 2.196815347158781

Epoch: 6| Step: 4
Training loss: 1.637099266052246
Validation loss: 2.197271696982845

Epoch: 6| Step: 5
Training loss: 0.9351029992103577
Validation loss: 2.184053559457102

Epoch: 6| Step: 6
Training loss: 1.4823378324508667
Validation loss: 2.1839266272001367

Epoch: 6| Step: 7
Training loss: 1.2029895782470703
Validation loss: 2.1784402298670944

Epoch: 6| Step: 8
Training loss: 1.3848237991333008
Validation loss: 2.18111918305838

Epoch: 6| Step: 9
Training loss: 2.275972843170166
Validation loss: 2.209152267825219

Epoch: 6| Step: 10
Training loss: 1.7584376335144043
Validation loss: 2.1685743075545116

Epoch: 6| Step: 11
Training loss: 1.642289161682129
Validation loss: 2.21006005297425

Epoch: 6| Step: 12
Training loss: 1.395036220550537
Validation loss: 2.2484325567881265

Epoch: 6| Step: 13
Training loss: 2.105160713195801
Validation loss: 2.178075926278227

Epoch: 477| Step: 0
Training loss: 1.3757553100585938
Validation loss: 2.191690029636506

Epoch: 6| Step: 1
Training loss: 2.3159589767456055
Validation loss: 2.189493320321524

Epoch: 6| Step: 2
Training loss: 1.4105110168457031
Validation loss: 2.18342298717909

Epoch: 6| Step: 3
Training loss: 1.1150643825531006
Validation loss: 2.176892840734092

Epoch: 6| Step: 4
Training loss: 1.7614340782165527
Validation loss: 2.210901552631009

Epoch: 6| Step: 5
Training loss: 1.234717845916748
Validation loss: 2.193886460796479

Epoch: 6| Step: 6
Training loss: 1.7113263607025146
Validation loss: 2.19959774837699

Epoch: 6| Step: 7
Training loss: 1.3163061141967773
Validation loss: 2.178300439670522

Epoch: 6| Step: 8
Training loss: 1.6558504104614258
Validation loss: 2.188024164527975

Epoch: 6| Step: 9
Training loss: 1.5652878284454346
Validation loss: 2.1776408046804447

Epoch: 6| Step: 10
Training loss: 1.104842185974121
Validation loss: 2.188679487474503

Epoch: 6| Step: 11
Training loss: 1.7664387226104736
Validation loss: 2.2187631104582097

Epoch: 6| Step: 12
Training loss: 1.5128318071365356
Validation loss: 2.194328805451752

Epoch: 6| Step: 13
Training loss: 2.0119683742523193
Validation loss: 2.2039568065315165

Epoch: 478| Step: 0
Training loss: 1.6156196594238281
Validation loss: 2.224865787772722

Epoch: 6| Step: 1
Training loss: 1.8802862167358398
Validation loss: 2.1867379219301286

Epoch: 6| Step: 2
Training loss: 1.432537317276001
Validation loss: 2.203770660584973

Epoch: 6| Step: 3
Training loss: 2.035066604614258
Validation loss: 2.14258679907809

Epoch: 6| Step: 4
Training loss: 1.1507858037948608
Validation loss: 2.1832986929083384

Epoch: 6| Step: 5
Training loss: 1.6982927322387695
Validation loss: 2.1712885274681994

Epoch: 6| Step: 6
Training loss: 2.241574287414551
Validation loss: 2.189290936275195

Epoch: 6| Step: 7
Training loss: 1.0817148685455322
Validation loss: 2.1331833652270737

Epoch: 6| Step: 8
Training loss: 1.6438043117523193
Validation loss: 2.1596636387609665

Epoch: 6| Step: 9
Training loss: 1.1413642168045044
Validation loss: 2.137510315064461

Epoch: 6| Step: 10
Training loss: 1.822941780090332
Validation loss: 2.1905792567037765

Epoch: 6| Step: 11
Training loss: 1.2114876508712769
Validation loss: 2.1807647494859594

Epoch: 6| Step: 12
Training loss: 1.3009164333343506
Validation loss: 2.218464897524926

Epoch: 6| Step: 13
Training loss: 1.3670827150344849
Validation loss: 2.2025537811299807

Epoch: 479| Step: 0
Training loss: 1.5838638544082642
Validation loss: 2.1960230796567854

Epoch: 6| Step: 1
Training loss: 0.8474390506744385
Validation loss: 2.233476943867181

Epoch: 6| Step: 2
Training loss: 1.3225553035736084
Validation loss: 2.2058581998271327

Epoch: 6| Step: 3
Training loss: 2.307903528213501
Validation loss: 2.193907586477136

Epoch: 6| Step: 4
Training loss: 1.161358118057251
Validation loss: 2.1763187967320925

Epoch: 6| Step: 5
Training loss: 1.734915018081665
Validation loss: 2.22429685695197

Epoch: 6| Step: 6
Training loss: 1.480445146560669
Validation loss: 2.185714614006781

Epoch: 6| Step: 7
Training loss: 1.598073959350586
Validation loss: 2.1804317402583298

Epoch: 6| Step: 8
Training loss: 1.6335978507995605
Validation loss: 2.1786143241390103

Epoch: 6| Step: 9
Training loss: 1.101846694946289
Validation loss: 2.2305024490561536

Epoch: 6| Step: 10
Training loss: 1.714585304260254
Validation loss: 2.2308904919573056

Epoch: 6| Step: 11
Training loss: 1.3469295501708984
Validation loss: 2.1609856005637877

Epoch: 6| Step: 12
Training loss: 2.2042365074157715
Validation loss: 2.1721322613377727

Epoch: 6| Step: 13
Training loss: 1.628204107284546
Validation loss: 2.2038704784967567

Epoch: 480| Step: 0
Training loss: 0.8898570537567139
Validation loss: 2.160125950331329

Epoch: 6| Step: 1
Training loss: 1.1760921478271484
Validation loss: 2.1534752973946194

Epoch: 6| Step: 2
Training loss: 1.648982286453247
Validation loss: 2.2247353446099067

Epoch: 6| Step: 3
Training loss: 2.0760490894317627
Validation loss: 2.1769319272810415

Epoch: 6| Step: 4
Training loss: 1.7725571393966675
Validation loss: 2.199019075721823

Epoch: 6| Step: 5
Training loss: 1.273301362991333
Validation loss: 2.182881628313372

Epoch: 6| Step: 6
Training loss: 1.6533477306365967
Validation loss: 2.1999252624409174

Epoch: 6| Step: 7
Training loss: 1.1059870719909668
Validation loss: 2.1668027549661617

Epoch: 6| Step: 8
Training loss: 1.764405608177185
Validation loss: 2.1649282850244993

Epoch: 6| Step: 9
Training loss: 1.5139493942260742
Validation loss: 2.184283556476716

Epoch: 6| Step: 10
Training loss: 1.887341022491455
Validation loss: 2.204166744344978

Epoch: 6| Step: 11
Training loss: 1.0916789770126343
Validation loss: 2.186605356072867

Epoch: 6| Step: 12
Training loss: 1.6767399311065674
Validation loss: 2.1427402073337185

Epoch: 6| Step: 13
Training loss: 1.4928817749023438
Validation loss: 2.1462824882999545

Epoch: 481| Step: 0
Training loss: 1.851184606552124
Validation loss: 2.1528509047723587

Epoch: 6| Step: 1
Training loss: 1.1875996589660645
Validation loss: 2.114574017063264

Epoch: 6| Step: 2
Training loss: 1.395029902458191
Validation loss: 2.152993400891622

Epoch: 6| Step: 3
Training loss: 1.778199315071106
Validation loss: 2.155391817451805

Epoch: 6| Step: 4
Training loss: 1.4579037427902222
Validation loss: 2.226609686369537

Epoch: 6| Step: 5
Training loss: 2.1086783409118652
Validation loss: 2.1960768725282405

Epoch: 6| Step: 6
Training loss: 2.0516932010650635
Validation loss: 2.226635048466344

Epoch: 6| Step: 7
Training loss: 1.3241355419158936
Validation loss: 2.156202185538507

Epoch: 6| Step: 8
Training loss: 1.0904583930969238
Validation loss: 2.174879627843057

Epoch: 6| Step: 9
Training loss: 0.8367304801940918
Validation loss: 2.1825033169920727

Epoch: 6| Step: 10
Training loss: 2.080496311187744
Validation loss: 2.1622579072111394

Epoch: 6| Step: 11
Training loss: 1.8156752586364746
Validation loss: 2.17723257823657

Epoch: 6| Step: 12
Training loss: 1.1976771354675293
Validation loss: 2.155102356787651

Epoch: 6| Step: 13
Training loss: 1.22685968875885
Validation loss: 2.1951215382545226

Epoch: 482| Step: 0
Training loss: 1.3292064666748047
Validation loss: 2.1530559908959175

Epoch: 6| Step: 1
Training loss: 1.070465087890625
Validation loss: 2.1996770956182994

Epoch: 6| Step: 2
Training loss: 1.4046316146850586
Validation loss: 2.2102559817734586

Epoch: 6| Step: 3
Training loss: 1.4468213319778442
Validation loss: 2.1950113837436964

Epoch: 6| Step: 4
Training loss: 1.6934614181518555
Validation loss: 2.2183271966954714

Epoch: 6| Step: 5
Training loss: 1.8347702026367188
Validation loss: 2.17271682523912

Epoch: 6| Step: 6
Training loss: 2.0363540649414062
Validation loss: 2.189417992868731

Epoch: 6| Step: 7
Training loss: 1.9649993181228638
Validation loss: 2.1326708973094983

Epoch: 6| Step: 8
Training loss: 1.7563579082489014
Validation loss: 2.1587286738939184

Epoch: 6| Step: 9
Training loss: 0.9420871734619141
Validation loss: 2.1932205051504154

Epoch: 6| Step: 10
Training loss: 1.3091613054275513
Validation loss: 2.2190356972397014

Epoch: 6| Step: 11
Training loss: 2.112901449203491
Validation loss: 2.1858169135226997

Epoch: 6| Step: 12
Training loss: 1.1807541847229004
Validation loss: 2.228929135107225

Epoch: 6| Step: 13
Training loss: 0.9597410559654236
Validation loss: 2.1614487760810444

Epoch: 483| Step: 0
Training loss: 1.5278178453445435
Validation loss: 2.19228938318068

Epoch: 6| Step: 1
Training loss: 1.9383914470672607
Validation loss: 2.18468205646802

Epoch: 6| Step: 2
Training loss: 1.7437337636947632
Validation loss: 2.2231277137674312

Epoch: 6| Step: 3
Training loss: 0.9676527976989746
Validation loss: 2.1370890973716654

Epoch: 6| Step: 4
Training loss: 1.8144328594207764
Validation loss: 2.1613783477455057

Epoch: 6| Step: 5
Training loss: 1.0986931324005127
Validation loss: 2.1507450226814515

Epoch: 6| Step: 6
Training loss: 1.7648241519927979
Validation loss: 2.2088594590463946

Epoch: 6| Step: 7
Training loss: 1.808672547340393
Validation loss: 2.1941479611140426

Epoch: 6| Step: 8
Training loss: 1.619436502456665
Validation loss: 2.189073142185006

Epoch: 6| Step: 9
Training loss: 1.758589267730713
Validation loss: 2.201827710674655

Epoch: 6| Step: 10
Training loss: 1.3658301830291748
Validation loss: 2.163491195248019

Epoch: 6| Step: 11
Training loss: 1.413011908531189
Validation loss: 2.160711690943728

Epoch: 6| Step: 12
Training loss: 1.1589182615280151
Validation loss: 2.2013074531350085

Epoch: 6| Step: 13
Training loss: 1.21129310131073
Validation loss: 2.188040869210356

Epoch: 484| Step: 0
Training loss: 1.2655649185180664
Validation loss: 2.1450615826473443

Epoch: 6| Step: 1
Training loss: 1.2490116357803345
Validation loss: 2.1928696722112675

Epoch: 6| Step: 2
Training loss: 2.1469671726226807
Validation loss: 2.213605198808896

Epoch: 6| Step: 3
Training loss: 1.9956743717193604
Validation loss: 2.180980525990968

Epoch: 6| Step: 4
Training loss: 1.1887801885604858
Validation loss: 2.171486085461032

Epoch: 6| Step: 5
Training loss: 1.1931647062301636
Validation loss: 2.167563787070654

Epoch: 6| Step: 6
Training loss: 1.7654420137405396
Validation loss: 2.2258277003483107

Epoch: 6| Step: 7
Training loss: 1.6144917011260986
Validation loss: 2.19212160828293

Epoch: 6| Step: 8
Training loss: 1.7612218856811523
Validation loss: 2.1752339742516957

Epoch: 6| Step: 9
Training loss: 1.2546546459197998
Validation loss: 2.130202447214434

Epoch: 6| Step: 10
Training loss: 1.2965552806854248
Validation loss: 2.1509624655528734

Epoch: 6| Step: 11
Training loss: 1.7991209030151367
Validation loss: 2.2339653289446266

Epoch: 6| Step: 12
Training loss: 1.0928504467010498
Validation loss: 2.152608435641053

Epoch: 6| Step: 13
Training loss: 1.6846210956573486
Validation loss: 2.1369894986511557

Epoch: 485| Step: 0
Training loss: 0.9951278567314148
Validation loss: 2.191910279694424

Epoch: 6| Step: 1
Training loss: 1.402000904083252
Validation loss: 2.189954803835961

Epoch: 6| Step: 2
Training loss: 1.1021497249603271
Validation loss: 2.1333736270986576

Epoch: 6| Step: 3
Training loss: 1.1771825551986694
Validation loss: 2.1308382582920853

Epoch: 6| Step: 4
Training loss: 1.6057839393615723
Validation loss: 2.2334566885425198

Epoch: 6| Step: 5
Training loss: 1.5443527698516846
Validation loss: 2.1609114908402964

Epoch: 6| Step: 6
Training loss: 1.327059030532837
Validation loss: 2.195356479255102

Epoch: 6| Step: 7
Training loss: 1.7600836753845215
Validation loss: 2.201887325573993

Epoch: 6| Step: 8
Training loss: 1.9798057079315186
Validation loss: 2.164070695959112

Epoch: 6| Step: 9
Training loss: 2.2725753784179688
Validation loss: 2.195992005768643

Epoch: 6| Step: 10
Training loss: 1.6669692993164062
Validation loss: 2.2335106993234284

Epoch: 6| Step: 11
Training loss: 1.5526785850524902
Validation loss: 2.1772491624278407

Epoch: 6| Step: 12
Training loss: 1.2779204845428467
Validation loss: 2.2531114752574632

Epoch: 6| Step: 13
Training loss: 1.4146946668624878
Validation loss: 2.1757349096318728

Epoch: 486| Step: 0
Training loss: 2.0177762508392334
Validation loss: 2.2062847434833484

Epoch: 6| Step: 1
Training loss: 1.626174807548523
Validation loss: 2.167161908200992

Epoch: 6| Step: 2
Training loss: 1.552809238433838
Validation loss: 2.2107412430547897

Epoch: 6| Step: 3
Training loss: 1.8669003248214722
Validation loss: 2.13233644090673

Epoch: 6| Step: 4
Training loss: 1.802163004875183
Validation loss: 2.1631062351247317

Epoch: 6| Step: 5
Training loss: 1.0674114227294922
Validation loss: 2.1666961716067408

Epoch: 6| Step: 6
Training loss: 2.1246590614318848
Validation loss: 2.2108761533614127

Epoch: 6| Step: 7
Training loss: 1.278876781463623
Validation loss: 2.2036814997273106

Epoch: 6| Step: 8
Training loss: 1.0027954578399658
Validation loss: 2.2120490561249437

Epoch: 6| Step: 9
Training loss: 1.8616604804992676
Validation loss: 2.1539832135682464

Epoch: 6| Step: 10
Training loss: 1.4888191223144531
Validation loss: 2.1861509200065368

Epoch: 6| Step: 11
Training loss: 0.9984410405158997
Validation loss: 2.1826619717382614

Epoch: 6| Step: 12
Training loss: 1.2780840396881104
Validation loss: 2.181574284389455

Epoch: 6| Step: 13
Training loss: 1.0625470876693726
Validation loss: 2.210964136226203

Epoch: 487| Step: 0
Training loss: 1.2439978122711182
Validation loss: 2.1348557613229238

Epoch: 6| Step: 1
Training loss: 0.9368544816970825
Validation loss: 2.194912854061332

Epoch: 6| Step: 2
Training loss: 1.473902940750122
Validation loss: 2.1783219563063754

Epoch: 6| Step: 3
Training loss: 1.6803133487701416
Validation loss: 2.13299423392101

Epoch: 6| Step: 4
Training loss: 1.554771900177002
Validation loss: 2.1523709886817524

Epoch: 6| Step: 5
Training loss: 1.4570704698562622
Validation loss: 2.2119322053847776

Epoch: 6| Step: 6
Training loss: 1.3109023571014404
Validation loss: 2.1778492504550564

Epoch: 6| Step: 7
Training loss: 1.5363956689834595
Validation loss: 2.217327692175424

Epoch: 6| Step: 8
Training loss: 1.722710371017456
Validation loss: 2.1953027914929133

Epoch: 6| Step: 9
Training loss: 1.8051505088806152
Validation loss: 2.195395995211858

Epoch: 6| Step: 10
Training loss: 1.711740255355835
Validation loss: 2.1692678697647585

Epoch: 6| Step: 11
Training loss: 1.4292365312576294
Validation loss: 2.213037963836424

Epoch: 6| Step: 12
Training loss: 1.890401005744934
Validation loss: 2.2436526231868292

Epoch: 6| Step: 13
Training loss: 1.1550649404525757
Validation loss: 2.159186681111654

Epoch: 488| Step: 0
Training loss: 1.3756216764450073
Validation loss: 2.183730492027857

Epoch: 6| Step: 1
Training loss: 1.6802992820739746
Validation loss: 2.186731133409726

Epoch: 6| Step: 2
Training loss: 1.5584592819213867
Validation loss: 2.203206741681663

Epoch: 6| Step: 3
Training loss: 1.5238492488861084
Validation loss: 2.264427959278066

Epoch: 6| Step: 4
Training loss: 0.9069547653198242
Validation loss: 2.235785848350935

Epoch: 6| Step: 5
Training loss: 1.013253927230835
Validation loss: 2.2551019832652104

Epoch: 6| Step: 6
Training loss: 1.8830264806747437
Validation loss: 2.2480754698476484

Epoch: 6| Step: 7
Training loss: 1.5245435237884521
Validation loss: 2.179344915574597

Epoch: 6| Step: 8
Training loss: 1.550276756286621
Validation loss: 2.2220667895450386

Epoch: 6| Step: 9
Training loss: 1.319446325302124
Validation loss: 2.1932439906622774

Epoch: 6| Step: 10
Training loss: 1.3551876544952393
Validation loss: 2.1822350922451226

Epoch: 6| Step: 11
Training loss: 2.295619249343872
Validation loss: 2.136948508601035

Epoch: 6| Step: 12
Training loss: 1.6196359395980835
Validation loss: 2.1956676437008764

Epoch: 6| Step: 13
Training loss: 1.6721851825714111
Validation loss: 2.197429662109703

Epoch: 489| Step: 0
Training loss: 1.717325210571289
Validation loss: 2.1883709558876614

Epoch: 6| Step: 1
Training loss: 1.390742540359497
Validation loss: 2.200762815372918

Epoch: 6| Step: 2
Training loss: 1.7332394123077393
Validation loss: 2.1567371455571984

Epoch: 6| Step: 3
Training loss: 1.927729845046997
Validation loss: 2.166598040570495

Epoch: 6| Step: 4
Training loss: 1.2981419563293457
Validation loss: 2.224185871821578

Epoch: 6| Step: 5
Training loss: 1.645660161972046
Validation loss: 2.1790865980168825

Epoch: 6| Step: 6
Training loss: 2.0905532836914062
Validation loss: 2.2314120056808635

Epoch: 6| Step: 7
Training loss: 0.8031377196311951
Validation loss: 2.1717649454711587

Epoch: 6| Step: 8
Training loss: 2.291081666946411
Validation loss: 2.1753198010947115

Epoch: 6| Step: 9
Training loss: 1.237290859222412
Validation loss: 2.1673775667785318

Epoch: 6| Step: 10
Training loss: 1.4686793088912964
Validation loss: 2.2275818804258942

Epoch: 6| Step: 11
Training loss: 1.9399912357330322
Validation loss: 2.1855393789147817

Epoch: 6| Step: 12
Training loss: 0.8247300386428833
Validation loss: 2.1959370977135113

Epoch: 6| Step: 13
Training loss: 0.5762498378753662
Validation loss: 2.236577244215114

Epoch: 490| Step: 0
Training loss: 1.144215703010559
Validation loss: 2.2076357769709762

Epoch: 6| Step: 1
Training loss: 1.216411828994751
Validation loss: 2.1811417328414096

Epoch: 6| Step: 2
Training loss: 1.395318865776062
Validation loss: 2.17903834004556

Epoch: 6| Step: 3
Training loss: 2.091672897338867
Validation loss: 2.1785805712464037

Epoch: 6| Step: 4
Training loss: 1.5211278200149536
Validation loss: 2.219766918049064

Epoch: 6| Step: 5
Training loss: 1.0461782217025757
Validation loss: 2.1881972794891684

Epoch: 6| Step: 6
Training loss: 1.2617958784103394
Validation loss: 2.170229770803964

Epoch: 6| Step: 7
Training loss: 1.6798357963562012
Validation loss: 2.1760095011803413

Epoch: 6| Step: 8
Training loss: 1.7443149089813232
Validation loss: 2.2097738968428744

Epoch: 6| Step: 9
Training loss: 2.1071887016296387
Validation loss: 2.1987016406110538

Epoch: 6| Step: 10
Training loss: 1.799739956855774
Validation loss: 2.206919918778122

Epoch: 6| Step: 11
Training loss: 1.6287806034088135
Validation loss: 2.180334775678573

Epoch: 6| Step: 12
Training loss: 1.563615083694458
Validation loss: 2.1901668758802515

Epoch: 6| Step: 13
Training loss: 1.1267220973968506
Validation loss: 2.213241172093217

Epoch: 491| Step: 0
Training loss: 1.663402795791626
Validation loss: 2.1637328029960714

Epoch: 6| Step: 1
Training loss: 1.9266653060913086
Validation loss: 2.2005006151814617

Epoch: 6| Step: 2
Training loss: 0.9170660376548767
Validation loss: 2.2045880825288835

Epoch: 6| Step: 3
Training loss: 1.0809186697006226
Validation loss: 2.196349097836402

Epoch: 6| Step: 4
Training loss: 1.8645962476730347
Validation loss: 2.1969986243914534

Epoch: 6| Step: 5
Training loss: 1.3860194683074951
Validation loss: 2.2012685575792865

Epoch: 6| Step: 6
Training loss: 1.6891419887542725
Validation loss: 2.2072183265480945

Epoch: 6| Step: 7
Training loss: 1.2212926149368286
Validation loss: 2.192833087777579

Epoch: 6| Step: 8
Training loss: 1.4454400539398193
Validation loss: 2.178184886132517

Epoch: 6| Step: 9
Training loss: 1.270796298980713
Validation loss: 2.188922748770765

Epoch: 6| Step: 10
Training loss: 1.4023041725158691
Validation loss: 2.191202025259695

Epoch: 6| Step: 11
Training loss: 1.3176811933517456
Validation loss: 2.1991089236351753

Epoch: 6| Step: 12
Training loss: 2.176546573638916
Validation loss: 2.1670201978375836

Epoch: 6| Step: 13
Training loss: 1.5226421356201172
Validation loss: 2.202807946871686

Epoch: 492| Step: 0
Training loss: 1.4174448251724243
Validation loss: 2.2195070392342022

Epoch: 6| Step: 1
Training loss: 1.797145128250122
Validation loss: 2.212212070342033

Epoch: 6| Step: 2
Training loss: 1.4477547407150269
Validation loss: 2.1979525243082354

Epoch: 6| Step: 3
Training loss: 1.7855464220046997
Validation loss: 2.157578586250223

Epoch: 6| Step: 4
Training loss: 1.1231402158737183
Validation loss: 2.1581873663010134

Epoch: 6| Step: 5
Training loss: 1.6622638702392578
Validation loss: 2.2080978552500405

Epoch: 6| Step: 6
Training loss: 1.218329668045044
Validation loss: 2.1711750274063437

Epoch: 6| Step: 7
Training loss: 1.4686942100524902
Validation loss: 2.1837094881201304

Epoch: 6| Step: 8
Training loss: 1.3277075290679932
Validation loss: 2.1446920825589086

Epoch: 6| Step: 9
Training loss: 2.0676238536834717
Validation loss: 2.1656802751684703

Epoch: 6| Step: 10
Training loss: 1.3474358320236206
Validation loss: 2.1831218811773483

Epoch: 6| Step: 11
Training loss: 1.0848634243011475
Validation loss: 2.203087591355847

Epoch: 6| Step: 12
Training loss: 1.7570359706878662
Validation loss: 2.1843262052023285

Epoch: 6| Step: 13
Training loss: 1.4820913076400757
Validation loss: 2.2118952697323215

Epoch: 493| Step: 0
Training loss: 0.783461332321167
Validation loss: 2.20902673147058

Epoch: 6| Step: 1
Training loss: 1.67861807346344
Validation loss: 2.230586621069139

Epoch: 6| Step: 2
Training loss: 1.2256903648376465
Validation loss: 2.241497505095697

Epoch: 6| Step: 3
Training loss: 1.7299162149429321
Validation loss: 2.1889393944894113

Epoch: 6| Step: 4
Training loss: 1.9477092027664185
Validation loss: 2.199434834141885

Epoch: 6| Step: 5
Training loss: 1.0971226692199707
Validation loss: 2.266646792811732

Epoch: 6| Step: 6
Training loss: 1.691176176071167
Validation loss: 2.2289535845479658

Epoch: 6| Step: 7
Training loss: 1.2287113666534424
Validation loss: 2.2314288744362454

Epoch: 6| Step: 8
Training loss: 1.2014813423156738
Validation loss: 2.2498194748355496

Epoch: 6| Step: 9
Training loss: 2.426680564880371
Validation loss: 2.1699698445617512

Epoch: 6| Step: 10
Training loss: 1.5928850173950195
Validation loss: 2.1485863180570703

Epoch: 6| Step: 11
Training loss: 1.3461453914642334
Validation loss: 2.170034917452002

Epoch: 6| Step: 12
Training loss: 1.2280099391937256
Validation loss: 2.2051015643663305

Epoch: 6| Step: 13
Training loss: 2.2277514934539795
Validation loss: 2.182152791689801

Epoch: 494| Step: 0
Training loss: 0.8791999816894531
Validation loss: 2.1396040583169587

Epoch: 6| Step: 1
Training loss: 1.0527994632720947
Validation loss: 2.200677410248787

Epoch: 6| Step: 2
Training loss: 1.7168031930923462
Validation loss: 2.1829071250013126

Epoch: 6| Step: 3
Training loss: 1.5912129878997803
Validation loss: 2.140711786926434

Epoch: 6| Step: 4
Training loss: 2.0212268829345703
Validation loss: 2.206351193048621

Epoch: 6| Step: 5
Training loss: 1.0930211544036865
Validation loss: 2.198089263772452

Epoch: 6| Step: 6
Training loss: 1.7563447952270508
Validation loss: 2.157040101225658

Epoch: 6| Step: 7
Training loss: 2.129481792449951
Validation loss: 2.203973288177162

Epoch: 6| Step: 8
Training loss: 1.4710991382598877
Validation loss: 2.15071617146974

Epoch: 6| Step: 9
Training loss: 1.8548625707626343
Validation loss: 2.1577408775206535

Epoch: 6| Step: 10
Training loss: 1.5898016691207886
Validation loss: 2.1587534002078477

Epoch: 6| Step: 11
Training loss: 1.1742864847183228
Validation loss: 2.217307207404926

Epoch: 6| Step: 12
Training loss: 0.9250859022140503
Validation loss: 2.145114473117295

Epoch: 6| Step: 13
Training loss: 1.567400336265564
Validation loss: 2.155984563212241

Epoch: 495| Step: 0
Training loss: 0.9719727039337158
Validation loss: 2.145001842129615

Epoch: 6| Step: 1
Training loss: 1.343721866607666
Validation loss: 2.2220332212345575

Epoch: 6| Step: 2
Training loss: 1.109548568725586
Validation loss: 2.206990195858863

Epoch: 6| Step: 3
Training loss: 1.8841325044631958
Validation loss: 2.2274667204067273

Epoch: 6| Step: 4
Training loss: 1.3240247964859009
Validation loss: 2.208012716744536

Epoch: 6| Step: 5
Training loss: 1.6838163137435913
Validation loss: 2.1924654629922684

Epoch: 6| Step: 6
Training loss: 1.6582783460617065
Validation loss: 2.200744293069327

Epoch: 6| Step: 7
Training loss: 1.6080899238586426
Validation loss: 2.1392122942914247

Epoch: 6| Step: 8
Training loss: 1.8503949642181396
Validation loss: 2.1689643680408435

Epoch: 6| Step: 9
Training loss: 1.3880822658538818
Validation loss: 2.1802350282669067

Epoch: 6| Step: 10
Training loss: 1.9013162851333618
Validation loss: 2.217743730032316

Epoch: 6| Step: 11
Training loss: 1.7235506772994995
Validation loss: 2.2112273247011247

Epoch: 6| Step: 12
Training loss: 0.9978917837142944
Validation loss: 2.1650664985820813

Epoch: 6| Step: 13
Training loss: 1.4846779108047485
Validation loss: 2.220310840555417

Epoch: 496| Step: 0
Training loss: 1.8189595937728882
Validation loss: 2.2228871237847114

Epoch: 6| Step: 1
Training loss: 1.1390964984893799
Validation loss: 2.150452998376662

Epoch: 6| Step: 2
Training loss: 1.0357005596160889
Validation loss: 2.195015889342113

Epoch: 6| Step: 3
Training loss: 1.2738261222839355
Validation loss: 2.23136015476719

Epoch: 6| Step: 4
Training loss: 1.623647689819336
Validation loss: 2.2335522200471614

Epoch: 6| Step: 5
Training loss: 1.5595275163650513
Validation loss: 2.2324247116683633

Epoch: 6| Step: 6
Training loss: 1.2118948698043823
Validation loss: 2.2010439826596166

Epoch: 6| Step: 7
Training loss: 1.2395083904266357
Validation loss: 2.2732244114721976

Epoch: 6| Step: 8
Training loss: 2.3227972984313965
Validation loss: 2.2279901812153478

Epoch: 6| Step: 9
Training loss: 1.7628469467163086
Validation loss: 2.2132104417329193

Epoch: 6| Step: 10
Training loss: 1.3992950916290283
Validation loss: 2.173213833121843

Epoch: 6| Step: 11
Training loss: 1.7968859672546387
Validation loss: 2.1853234434640534

Epoch: 6| Step: 12
Training loss: 0.9782873392105103
Validation loss: 2.153055279485641

Epoch: 6| Step: 13
Training loss: 1.9578280448913574
Validation loss: 2.223208745320638

Epoch: 497| Step: 0
Training loss: 1.7277107238769531
Validation loss: 2.129079535443296

Epoch: 6| Step: 1
Training loss: 1.4029676914215088
Validation loss: 2.127897593282884

Epoch: 6| Step: 2
Training loss: 1.6113966703414917
Validation loss: 2.184230027660247

Epoch: 6| Step: 3
Training loss: 1.2982831001281738
Validation loss: 2.1647413994676326

Epoch: 6| Step: 4
Training loss: 1.1101763248443604
Validation loss: 2.1984836183568484

Epoch: 6| Step: 5
Training loss: 1.6783018112182617
Validation loss: 2.1994665309947026

Epoch: 6| Step: 6
Training loss: 1.3258320093154907
Validation loss: 2.1374394073281238

Epoch: 6| Step: 7
Training loss: 1.2442290782928467
Validation loss: 2.172618258383966

Epoch: 6| Step: 8
Training loss: 2.208775043487549
Validation loss: 2.148104052389822

Epoch: 6| Step: 9
Training loss: 1.880913257598877
Validation loss: 2.2134935394410165

Epoch: 6| Step: 10
Training loss: 1.8287814855575562
Validation loss: 2.1961249766811246

Epoch: 6| Step: 11
Training loss: 1.1898256540298462
Validation loss: 2.1903449719952

Epoch: 6| Step: 12
Training loss: 1.220482349395752
Validation loss: 2.2099951800479682

Epoch: 6| Step: 13
Training loss: 0.9674800038337708
Validation loss: 2.2246880121128534

Epoch: 498| Step: 0
Training loss: 1.7156994342803955
Validation loss: 2.1781471403696204

Epoch: 6| Step: 1
Training loss: 1.66061532497406
Validation loss: 2.1995674102537093

Epoch: 6| Step: 2
Training loss: 1.1113550662994385
Validation loss: 2.1524458726247153

Epoch: 6| Step: 3
Training loss: 1.3333081007003784
Validation loss: 2.1978787811853553

Epoch: 6| Step: 4
Training loss: 1.9665311574935913
Validation loss: 2.2002088856953446

Epoch: 6| Step: 5
Training loss: 1.2480576038360596
Validation loss: 2.160400080424483

Epoch: 6| Step: 6
Training loss: 1.8993778228759766
Validation loss: 2.2326099975134737

Epoch: 6| Step: 7
Training loss: 1.0698492527008057
Validation loss: 2.216884433582265

Epoch: 6| Step: 8
Training loss: 1.3262585401535034
Validation loss: 2.1825495842964417

Epoch: 6| Step: 9
Training loss: 1.2252459526062012
Validation loss: 2.148564361756848

Epoch: 6| Step: 10
Training loss: 1.4906407594680786
Validation loss: 2.191113004120447

Epoch: 6| Step: 11
Training loss: 1.8645421266555786
Validation loss: 2.193818258982833

Epoch: 6| Step: 12
Training loss: 1.5201833248138428
Validation loss: 2.233091938880182

Epoch: 6| Step: 13
Training loss: 2.209681510925293
Validation loss: 2.1974284136167137

Epoch: 499| Step: 0
Training loss: 1.3307006359100342
Validation loss: 2.1899065945738103

Epoch: 6| Step: 1
Training loss: 1.4717063903808594
Validation loss: 2.2394275511464765

Epoch: 6| Step: 2
Training loss: 1.2085564136505127
Validation loss: 2.1956921367235083

Epoch: 6| Step: 3
Training loss: 1.4924352169036865
Validation loss: 2.20527845557018

Epoch: 6| Step: 4
Training loss: 0.969659149646759
Validation loss: 2.195292680494247

Epoch: 6| Step: 5
Training loss: 1.6563136577606201
Validation loss: 2.20714089562816

Epoch: 6| Step: 6
Training loss: 1.927814245223999
Validation loss: 2.1783898517649662

Epoch: 6| Step: 7
Training loss: 1.5952955484390259
Validation loss: 2.1931872637041154

Epoch: 6| Step: 8
Training loss: 1.440298318862915
Validation loss: 2.2122307208276566

Epoch: 6| Step: 9
Training loss: 1.9821887016296387
Validation loss: 2.1999735986032793

Epoch: 6| Step: 10
Training loss: 1.636809229850769
Validation loss: 2.18431761956984

Epoch: 6| Step: 11
Training loss: 1.4354206323623657
Validation loss: 2.17498843900619

Epoch: 6| Step: 12
Training loss: 1.3809823989868164
Validation loss: 2.2150032571567

Epoch: 6| Step: 13
Training loss: 1.899819254875183
Validation loss: 2.16637816480411

Epoch: 500| Step: 0
Training loss: 1.519193172454834
Validation loss: 2.148330127039263

Epoch: 6| Step: 1
Training loss: 1.2797777652740479
Validation loss: 2.1796868860080676

Epoch: 6| Step: 2
Training loss: 1.4613807201385498
Validation loss: 2.2016803013381137

Epoch: 6| Step: 3
Training loss: 1.9006637334823608
Validation loss: 2.141476592709941

Epoch: 6| Step: 4
Training loss: 1.138434648513794
Validation loss: 2.159825424994192

Epoch: 6| Step: 5
Training loss: 1.8846018314361572
Validation loss: 2.183389472705062

Epoch: 6| Step: 6
Training loss: 1.077995777130127
Validation loss: 2.2114436370070263

Epoch: 6| Step: 7
Training loss: 2.035191774368286
Validation loss: 2.1512077598161596

Epoch: 6| Step: 8
Training loss: 1.641319990158081
Validation loss: 2.1440896500823317

Epoch: 6| Step: 9
Training loss: 1.5637495517730713
Validation loss: 2.2281599480618715

Epoch: 6| Step: 10
Training loss: 1.370049238204956
Validation loss: 2.1406660156865276

Epoch: 6| Step: 11
Training loss: 1.213562250137329
Validation loss: 2.14664279260943

Epoch: 6| Step: 12
Training loss: 1.5715792179107666
Validation loss: 2.1374888727741856

Epoch: 6| Step: 13
Training loss: 1.4298449754714966
Validation loss: 2.184404262932398

Epoch: 501| Step: 0
Training loss: 1.202607274055481
Validation loss: 2.2097550130659536

Epoch: 6| Step: 1
Training loss: 2.0750436782836914
Validation loss: 2.2149562348601637

Epoch: 6| Step: 2
Training loss: 1.887829303741455
Validation loss: 2.1971901027105187

Epoch: 6| Step: 3
Training loss: 1.212751030921936
Validation loss: 2.1912204321994575

Epoch: 6| Step: 4
Training loss: 1.5525245666503906
Validation loss: 2.1723303128314275

Epoch: 6| Step: 5
Training loss: 1.4410961866378784
Validation loss: 2.1768986037982407

Epoch: 6| Step: 6
Training loss: 1.9944167137145996
Validation loss: 2.165146780270402

Epoch: 6| Step: 7
Training loss: 1.6505777835845947
Validation loss: 2.1860002163917787

Epoch: 6| Step: 8
Training loss: 1.7953921556472778
Validation loss: 2.1616109583967473

Epoch: 6| Step: 9
Training loss: 1.0425441265106201
Validation loss: 2.1785154522106214

Epoch: 6| Step: 10
Training loss: 1.2406264543533325
Validation loss: 2.188225741027504

Epoch: 6| Step: 11
Training loss: 1.5468969345092773
Validation loss: 2.19537377613847

Epoch: 6| Step: 12
Training loss: 1.2378394603729248
Validation loss: 2.26153237588944

Epoch: 6| Step: 13
Training loss: 1.222449779510498
Validation loss: 2.2323389078981135

Epoch: 502| Step: 0
Training loss: 1.820433259010315
Validation loss: 2.241165645660893

Epoch: 6| Step: 1
Training loss: 0.8551173210144043
Validation loss: 2.219569311347059

Epoch: 6| Step: 2
Training loss: 1.2563965320587158
Validation loss: 2.2373443829116

Epoch: 6| Step: 3
Training loss: 1.1333919763565063
Validation loss: 2.1722959703014744

Epoch: 6| Step: 4
Training loss: 1.5946829319000244
Validation loss: 2.1999141772588096

Epoch: 6| Step: 5
Training loss: 1.7364356517791748
Validation loss: 2.1805778088108188

Epoch: 6| Step: 6
Training loss: 1.407707691192627
Validation loss: 2.1696027427591305

Epoch: 6| Step: 7
Training loss: 1.7635210752487183
Validation loss: 2.2218964881794427

Epoch: 6| Step: 8
Training loss: 1.724191427230835
Validation loss: 2.203141002244847

Epoch: 6| Step: 9
Training loss: 1.5218627452850342
Validation loss: 2.1949733354712047

Epoch: 6| Step: 10
Training loss: 1.1314834356307983
Validation loss: 2.1694599941212642

Epoch: 6| Step: 11
Training loss: 1.8401813507080078
Validation loss: 2.1767860407470376

Epoch: 6| Step: 12
Training loss: 1.7195210456848145
Validation loss: 2.1683882000625774

Epoch: 6| Step: 13
Training loss: 0.853086531162262
Validation loss: 2.1942870693822063

Epoch: 503| Step: 0
Training loss: 1.7546706199645996
Validation loss: 2.1888194596895607

Epoch: 6| Step: 1
Training loss: 1.6618860960006714
Validation loss: 2.229979025420322

Epoch: 6| Step: 2
Training loss: 1.5776324272155762
Validation loss: 2.1693426921803463

Epoch: 6| Step: 3
Training loss: 1.7595000267028809
Validation loss: 2.1866392243293022

Epoch: 6| Step: 4
Training loss: 0.7587634921073914
Validation loss: 2.1799530239515406

Epoch: 6| Step: 5
Training loss: 1.9548325538635254
Validation loss: 2.143030474262853

Epoch: 6| Step: 6
Training loss: 0.8830950856208801
Validation loss: 2.1916411948460404

Epoch: 6| Step: 7
Training loss: 1.3668293952941895
Validation loss: 2.15824322290318

Epoch: 6| Step: 8
Training loss: 1.8487628698349
Validation loss: 2.143696092790173

Epoch: 6| Step: 9
Training loss: 1.97341787815094
Validation loss: 2.170132279396057

Epoch: 6| Step: 10
Training loss: 1.247955560684204
Validation loss: 2.1742487569009104

Epoch: 6| Step: 11
Training loss: 0.7753338813781738
Validation loss: 2.224359732802196

Epoch: 6| Step: 12
Training loss: 1.2157617807388306
Validation loss: 2.190392791583974

Epoch: 6| Step: 13
Training loss: 2.0568816661834717
Validation loss: 2.1761502860694804

Epoch: 504| Step: 0
Training loss: 1.6293022632598877
Validation loss: 2.203892737306574

Epoch: 6| Step: 1
Training loss: 1.898591160774231
Validation loss: 2.192383372655479

Epoch: 6| Step: 2
Training loss: 1.5442641973495483
Validation loss: 2.168852554854526

Epoch: 6| Step: 3
Training loss: 1.1743543148040771
Validation loss: 2.1423440620463383

Epoch: 6| Step: 4
Training loss: 1.3840327262878418
Validation loss: 2.251300674612804

Epoch: 6| Step: 5
Training loss: 0.9727776050567627
Validation loss: 2.1921325370829594

Epoch: 6| Step: 6
Training loss: 1.810789942741394
Validation loss: 2.178603264593309

Epoch: 6| Step: 7
Training loss: 1.3621554374694824
Validation loss: 2.202500145922425

Epoch: 6| Step: 8
Training loss: 1.1683104038238525
Validation loss: 2.203784919554187

Epoch: 6| Step: 9
Training loss: 1.6806695461273193
Validation loss: 2.2004702104035245

Epoch: 6| Step: 10
Training loss: 0.8821194171905518
Validation loss: 2.1773192574900966

Epoch: 6| Step: 11
Training loss: 1.5606341361999512
Validation loss: 2.2193822629990114

Epoch: 6| Step: 12
Training loss: 1.897261142730713
Validation loss: 2.188151313412574

Epoch: 6| Step: 13
Training loss: 1.6146149635314941
Validation loss: 2.21388574313092

Epoch: 505| Step: 0
Training loss: 1.8067570924758911
Validation loss: 2.16902373554886

Epoch: 6| Step: 1
Training loss: 1.6205400228500366
Validation loss: 2.2514356515740834

Epoch: 6| Step: 2
Training loss: 1.8196618556976318
Validation loss: 2.1803739545165852

Epoch: 6| Step: 3
Training loss: 1.5472153425216675
Validation loss: 2.212367484646459

Epoch: 6| Step: 4
Training loss: 1.2883888483047485
Validation loss: 2.1871777093538673

Epoch: 6| Step: 5
Training loss: 1.395058035850525
Validation loss: 2.1712663353130384

Epoch: 6| Step: 6
Training loss: 1.5382293462753296
Validation loss: 2.2054860053523893

Epoch: 6| Step: 7
Training loss: 0.8957663774490356
Validation loss: 2.207309669063937

Epoch: 6| Step: 8
Training loss: 1.5003013610839844
Validation loss: 2.1859869674969743

Epoch: 6| Step: 9
Training loss: 1.437974214553833
Validation loss: 2.130802121213687

Epoch: 6| Step: 10
Training loss: 1.9614390134811401
Validation loss: 2.2188549810840237

Epoch: 6| Step: 11
Training loss: 1.5951119661331177
Validation loss: 2.1882562457874255

Epoch: 6| Step: 12
Training loss: 0.8795587420463562
Validation loss: 2.2257485274345643

Epoch: 6| Step: 13
Training loss: 1.1988615989685059
Validation loss: 2.221846911215013

Epoch: 506| Step: 0
Training loss: 1.6986461877822876
Validation loss: 2.1472858331536733

Epoch: 6| Step: 1
Training loss: 1.9721064567565918
Validation loss: 2.2225692169640654

Epoch: 6| Step: 2
Training loss: 1.0913546085357666
Validation loss: 2.144753292042722

Epoch: 6| Step: 3
Training loss: 1.241608738899231
Validation loss: 2.211590156760267

Epoch: 6| Step: 4
Training loss: 1.087585210800171
Validation loss: 2.1576290617706957

Epoch: 6| Step: 5
Training loss: 1.7537083625793457
Validation loss: 2.1425250896843533

Epoch: 6| Step: 6
Training loss: 2.048849582672119
Validation loss: 2.182634427983274

Epoch: 6| Step: 7
Training loss: 1.1528375148773193
Validation loss: 2.2019049941852527

Epoch: 6| Step: 8
Training loss: 1.006005883216858
Validation loss: 2.17469133100202

Epoch: 6| Step: 9
Training loss: 1.8651881217956543
Validation loss: 2.211052607464534

Epoch: 6| Step: 10
Training loss: 1.4316353797912598
Validation loss: 2.1860409846869846

Epoch: 6| Step: 11
Training loss: 1.8496782779693604
Validation loss: 2.184914106963783

Epoch: 6| Step: 12
Training loss: 0.7846829295158386
Validation loss: 2.1907083872825868

Epoch: 6| Step: 13
Training loss: 1.287082314491272
Validation loss: 2.1857359204241025

Epoch: 507| Step: 0
Training loss: 0.8379212617874146
Validation loss: 2.1871620916551158

Epoch: 6| Step: 1
Training loss: 1.6615190505981445
Validation loss: 2.1972137728045062

Epoch: 6| Step: 2
Training loss: 1.527604579925537
Validation loss: 2.2111945972647717

Epoch: 6| Step: 3
Training loss: 0.9356371164321899
Validation loss: 2.2431327527569187

Epoch: 6| Step: 4
Training loss: 1.255922555923462
Validation loss: 2.2178382309534217

Epoch: 6| Step: 5
Training loss: 2.2001776695251465
Validation loss: 2.195369474349483

Epoch: 6| Step: 6
Training loss: 1.5664927959442139
Validation loss: 2.222252304835986

Epoch: 6| Step: 7
Training loss: 1.5017621517181396
Validation loss: 2.1970055923667005

Epoch: 6| Step: 8
Training loss: 2.009469509124756
Validation loss: 2.2349109342021327

Epoch: 6| Step: 9
Training loss: 0.7188264727592468
Validation loss: 2.265509251625307

Epoch: 6| Step: 10
Training loss: 1.7760626077651978
Validation loss: 2.2571607533321587

Epoch: 6| Step: 11
Training loss: 1.9120310544967651
Validation loss: 2.247908984461138

Epoch: 6| Step: 12
Training loss: 1.2745318412780762
Validation loss: 2.193947361361596

Epoch: 6| Step: 13
Training loss: 2.1335763931274414
Validation loss: 2.211040840354017

Epoch: 508| Step: 0
Training loss: 1.2379939556121826
Validation loss: 2.2162602306694112

Epoch: 6| Step: 1
Training loss: 1.2621502876281738
Validation loss: 2.1945036226703274

Epoch: 6| Step: 2
Training loss: 1.177276849746704
Validation loss: 2.1946345683067077

Epoch: 6| Step: 3
Training loss: 1.2713654041290283
Validation loss: 2.203869850404801

Epoch: 6| Step: 4
Training loss: 1.5245678424835205
Validation loss: 2.2037233767970914

Epoch: 6| Step: 5
Training loss: 1.8770923614501953
Validation loss: 2.1897448775588826

Epoch: 6| Step: 6
Training loss: 1.9450085163116455
Validation loss: 2.2370415400433283

Epoch: 6| Step: 7
Training loss: 1.260442852973938
Validation loss: 2.2162606357246317

Epoch: 6| Step: 8
Training loss: 1.4458277225494385
Validation loss: 2.1500118547870266

Epoch: 6| Step: 9
Training loss: 1.0726820230484009
Validation loss: 2.19337357500548

Epoch: 6| Step: 10
Training loss: 1.7408915758132935
Validation loss: 2.2410997011328257

Epoch: 6| Step: 11
Training loss: 1.6343343257904053
Validation loss: 2.206545033762532

Epoch: 6| Step: 12
Training loss: 1.5995543003082275
Validation loss: 2.1385574392093125

Epoch: 6| Step: 13
Training loss: 1.1482374668121338
Validation loss: 2.1776049367843138

Epoch: 509| Step: 0
Training loss: 1.9917216300964355
Validation loss: 2.2019068835884013

Epoch: 6| Step: 1
Training loss: 1.0720716714859009
Validation loss: 2.204930527235872

Epoch: 6| Step: 2
Training loss: 1.3705010414123535
Validation loss: 2.1415522636905795

Epoch: 6| Step: 3
Training loss: 0.9413000345230103
Validation loss: 2.206522249406384

Epoch: 6| Step: 4
Training loss: 1.1014615297317505
Validation loss: 2.1573608793238157

Epoch: 6| Step: 5
Training loss: 1.6414682865142822
Validation loss: 2.165970830507176

Epoch: 6| Step: 6
Training loss: 1.2885308265686035
Validation loss: 2.196597832505421

Epoch: 6| Step: 7
Training loss: 1.373396396636963
Validation loss: 2.2181914673056653

Epoch: 6| Step: 8
Training loss: 2.04182767868042
Validation loss: 2.2009592133183635

Epoch: 6| Step: 9
Training loss: 1.5769611597061157
Validation loss: 2.193267148028138

Epoch: 6| Step: 10
Training loss: 1.3167178630828857
Validation loss: 2.1637604723694506

Epoch: 6| Step: 11
Training loss: 1.296212911605835
Validation loss: 2.20754075050354

Epoch: 6| Step: 12
Training loss: 1.6549122333526611
Validation loss: 2.18006831343456

Epoch: 6| Step: 13
Training loss: 1.9151204824447632
Validation loss: 2.185526324856666

Epoch: 510| Step: 0
Training loss: 1.3990192413330078
Validation loss: 2.2085725325410084

Epoch: 6| Step: 1
Training loss: 1.4799766540527344
Validation loss: 2.1816392021794475

Epoch: 6| Step: 2
Training loss: 1.3894469738006592
Validation loss: 2.158784694569085

Epoch: 6| Step: 3
Training loss: 1.2904917001724243
Validation loss: 2.165919839694936

Epoch: 6| Step: 4
Training loss: 1.9104527235031128
Validation loss: 2.171951005535741

Epoch: 6| Step: 5
Training loss: 1.351205825805664
Validation loss: 2.1752427213935444

Epoch: 6| Step: 6
Training loss: 1.0982953310012817
Validation loss: 2.2470133740414857

Epoch: 6| Step: 7
Training loss: 1.4347472190856934
Validation loss: 2.2149238253152497

Epoch: 6| Step: 8
Training loss: 1.481612205505371
Validation loss: 2.212883718552128

Epoch: 6| Step: 9
Training loss: 1.5456488132476807
Validation loss: 2.185303052266439

Epoch: 6| Step: 10
Training loss: 1.3707090616226196
Validation loss: 2.202445314776513

Epoch: 6| Step: 11
Training loss: 2.005188465118408
Validation loss: 2.217882146117508

Epoch: 6| Step: 12
Training loss: 1.348593831062317
Validation loss: 2.229536501310205

Epoch: 6| Step: 13
Training loss: 1.7829358577728271
Validation loss: 2.1728341528164443

Epoch: 511| Step: 0
Training loss: 1.2484314441680908
Validation loss: 2.210774181991495

Epoch: 6| Step: 1
Training loss: 1.1650636196136475
Validation loss: 2.2077566064814085

Epoch: 6| Step: 2
Training loss: 1.1436411142349243
Validation loss: 2.1790483510622414

Epoch: 6| Step: 3
Training loss: 2.0982630252838135
Validation loss: 2.1627738091253463

Epoch: 6| Step: 4
Training loss: 0.7785352468490601
Validation loss: 2.194305912140877

Epoch: 6| Step: 5
Training loss: 1.4776039123535156
Validation loss: 2.192564433620822

Epoch: 6| Step: 6
Training loss: 2.3520634174346924
Validation loss: 2.2026173786450456

Epoch: 6| Step: 7
Training loss: 1.7423439025878906
Validation loss: 2.2333248494773783

Epoch: 6| Step: 8
Training loss: 1.1477855443954468
Validation loss: 2.1574232757732434

Epoch: 6| Step: 9
Training loss: 1.6570088863372803
Validation loss: 2.170339486932242

Epoch: 6| Step: 10
Training loss: 1.9793906211853027
Validation loss: 2.187744589262111

Epoch: 6| Step: 11
Training loss: 1.3669739961624146
Validation loss: 2.253088962647223

Epoch: 6| Step: 12
Training loss: 0.9279417395591736
Validation loss: 2.21784863164348

Epoch: 6| Step: 13
Training loss: 1.0028222799301147
Validation loss: 2.2271029513369323

Epoch: 512| Step: 0
Training loss: 0.9794676303863525
Validation loss: 2.214276859837194

Epoch: 6| Step: 1
Training loss: 1.5717766284942627
Validation loss: 2.189029232148201

Epoch: 6| Step: 2
Training loss: 1.6329386234283447
Validation loss: 2.1976312693729194

Epoch: 6| Step: 3
Training loss: 0.8403393030166626
Validation loss: 2.1751485511820805

Epoch: 6| Step: 4
Training loss: 1.7173476219177246
Validation loss: 2.2204839901257585

Epoch: 6| Step: 5
Training loss: 1.810684323310852
Validation loss: 2.130140341738219

Epoch: 6| Step: 6
Training loss: 1.8826429843902588
Validation loss: 2.2282213113641225

Epoch: 6| Step: 7
Training loss: 1.250093698501587
Validation loss: 2.2344848802012782

Epoch: 6| Step: 8
Training loss: 1.436941146850586
Validation loss: 2.209566377824353

Epoch: 6| Step: 9
Training loss: 1.34337317943573
Validation loss: 2.2077288909624984

Epoch: 6| Step: 10
Training loss: 2.1261510848999023
Validation loss: 2.173872623392331

Epoch: 6| Step: 11
Training loss: 1.3715227842330933
Validation loss: 2.191141461813322

Epoch: 6| Step: 12
Training loss: 1.4249902963638306
Validation loss: 2.176049760592881

Epoch: 6| Step: 13
Training loss: 1.1563035249710083
Validation loss: 2.1838354923391856

Epoch: 513| Step: 0
Training loss: 1.5834834575653076
Validation loss: 2.162758101699173

Epoch: 6| Step: 1
Training loss: 1.9247043132781982
Validation loss: 2.1908778811013825

Epoch: 6| Step: 2
Training loss: 0.7625436782836914
Validation loss: 2.1684227399928595

Epoch: 6| Step: 3
Training loss: 1.3063724040985107
Validation loss: 2.1679541513484013

Epoch: 6| Step: 4
Training loss: 0.8777418732643127
Validation loss: 2.210763574928366

Epoch: 6| Step: 5
Training loss: 1.9822996854782104
Validation loss: 2.186705288066659

Epoch: 6| Step: 6
Training loss: 1.085944652557373
Validation loss: 2.2046253578637236

Epoch: 6| Step: 7
Training loss: 1.2589318752288818
Validation loss: 2.236920964333319

Epoch: 6| Step: 8
Training loss: 1.5580724477767944
Validation loss: 2.2116991499418854

Epoch: 6| Step: 9
Training loss: 1.441847801208496
Validation loss: 2.158230099626767

Epoch: 6| Step: 10
Training loss: 1.8228001594543457
Validation loss: 2.170793588443469

Epoch: 6| Step: 11
Training loss: 1.6085178852081299
Validation loss: 2.244947429626219

Epoch: 6| Step: 12
Training loss: 1.8795243501663208
Validation loss: 2.2079906668714298

Epoch: 6| Step: 13
Training loss: 1.451707124710083
Validation loss: 2.185674264866819

Epoch: 514| Step: 0
Training loss: 1.8458940982818604
Validation loss: 2.25913986339364

Epoch: 6| Step: 1
Training loss: 1.9691894054412842
Validation loss: 2.2325863043467202

Epoch: 6| Step: 2
Training loss: 1.416203260421753
Validation loss: 2.193907812077512

Epoch: 6| Step: 3
Training loss: 1.6655685901641846
Validation loss: 2.16177136154585

Epoch: 6| Step: 4
Training loss: 1.6431052684783936
Validation loss: 2.212543038911717

Epoch: 6| Step: 5
Training loss: 0.9614758491516113
Validation loss: 2.22413291469697

Epoch: 6| Step: 6
Training loss: 1.1172802448272705
Validation loss: 2.198759178961477

Epoch: 6| Step: 7
Training loss: 1.8552411794662476
Validation loss: 2.2358645059729136

Epoch: 6| Step: 8
Training loss: 1.3293087482452393
Validation loss: 2.2261038031629337

Epoch: 6| Step: 9
Training loss: 1.4765841960906982
Validation loss: 2.188454460072261

Epoch: 6| Step: 10
Training loss: 1.9064149856567383
Validation loss: 2.2291573478329565

Epoch: 6| Step: 11
Training loss: 0.6196186542510986
Validation loss: 2.2353312174479165

Epoch: 6| Step: 12
Training loss: 1.5927953720092773
Validation loss: 2.2308121958086566

Epoch: 6| Step: 13
Training loss: 1.0654171705245972
Validation loss: 2.1575346531406527

Epoch: 515| Step: 0
Training loss: 1.496789574623108
Validation loss: 2.2203154666449434

Epoch: 6| Step: 1
Training loss: 1.0790342092514038
Validation loss: 2.238641103108724

Epoch: 6| Step: 2
Training loss: 1.3819551467895508
Validation loss: 2.2286602809864986

Epoch: 6| Step: 3
Training loss: 1.6001453399658203
Validation loss: 2.217548560070735

Epoch: 6| Step: 4
Training loss: 1.889794111251831
Validation loss: 2.2278261082146757

Epoch: 6| Step: 5
Training loss: 1.781001091003418
Validation loss: 2.2071927952510055

Epoch: 6| Step: 6
Training loss: 1.1710293292999268
Validation loss: 2.1965168560704877

Epoch: 6| Step: 7
Training loss: 1.6037678718566895
Validation loss: 2.1928495860868886

Epoch: 6| Step: 8
Training loss: 1.093627691268921
Validation loss: 2.2325847430895736

Epoch: 6| Step: 9
Training loss: 1.6144899129867554
Validation loss: 2.1601898798378567

Epoch: 6| Step: 10
Training loss: 1.217647671699524
Validation loss: 2.1975557522107194

Epoch: 6| Step: 11
Training loss: 1.381180763244629
Validation loss: 2.192910364879075

Epoch: 6| Step: 12
Training loss: 1.8682115077972412
Validation loss: 2.15942483563577

Epoch: 6| Step: 13
Training loss: 1.4406899213790894
Validation loss: 2.1415392634689168

Epoch: 516| Step: 0
Training loss: 1.576263189315796
Validation loss: 2.184680600320139

Epoch: 6| Step: 1
Training loss: 1.5848701000213623
Validation loss: 2.1798200081753474

Epoch: 6| Step: 2
Training loss: 1.0885735750198364
Validation loss: 2.2016098409570675

Epoch: 6| Step: 3
Training loss: 1.1660850048065186
Validation loss: 2.1974589311948387

Epoch: 6| Step: 4
Training loss: 1.1941230297088623
Validation loss: 2.1916522236280542

Epoch: 6| Step: 5
Training loss: 1.2223179340362549
Validation loss: 2.1991524721986506

Epoch: 6| Step: 6
Training loss: 1.4883403778076172
Validation loss: 2.1682816397759224

Epoch: 6| Step: 7
Training loss: 2.534797191619873
Validation loss: 2.189078556594028

Epoch: 6| Step: 8
Training loss: 1.0959538221359253
Validation loss: 2.1873154281288065

Epoch: 6| Step: 9
Training loss: 1.2872475385665894
Validation loss: 2.187412210690078

Epoch: 6| Step: 10
Training loss: 1.1193203926086426
Validation loss: 2.233087767836868

Epoch: 6| Step: 11
Training loss: 1.9007048606872559
Validation loss: 2.213360840274442

Epoch: 6| Step: 12
Training loss: 1.9628095626831055
Validation loss: 2.1833596716644945

Epoch: 6| Step: 13
Training loss: 1.3774373531341553
Validation loss: 2.1532862776069233

Epoch: 517| Step: 0
Training loss: 1.853177785873413
Validation loss: 2.1705225616373043

Epoch: 6| Step: 1
Training loss: 1.7933824062347412
Validation loss: 2.1994008453943397

Epoch: 6| Step: 2
Training loss: 1.1599411964416504
Validation loss: 2.194384119843924

Epoch: 6| Step: 3
Training loss: 0.9298148155212402
Validation loss: 2.212359041296026

Epoch: 6| Step: 4
Training loss: 1.025726556777954
Validation loss: 2.1719863863401514

Epoch: 6| Step: 5
Training loss: 1.157494068145752
Validation loss: 2.203183589443084

Epoch: 6| Step: 6
Training loss: 2.014047622680664
Validation loss: 2.182616456862419

Epoch: 6| Step: 7
Training loss: 1.1172780990600586
Validation loss: 2.1937565470254548

Epoch: 6| Step: 8
Training loss: 1.026711106300354
Validation loss: 2.16696584609247

Epoch: 6| Step: 9
Training loss: 1.563563346862793
Validation loss: 2.222683934755223

Epoch: 6| Step: 10
Training loss: 1.4301517009735107
Validation loss: 2.1749033915099276

Epoch: 6| Step: 11
Training loss: 1.3162028789520264
Validation loss: 2.205645195899471

Epoch: 6| Step: 12
Training loss: 1.495016098022461
Validation loss: 2.1891459880336637

Epoch: 6| Step: 13
Training loss: 2.157710313796997
Validation loss: 2.1469385470113447

Epoch: 518| Step: 0
Training loss: 1.3372796773910522
Validation loss: 2.2001500001517673

Epoch: 6| Step: 1
Training loss: 1.029728889465332
Validation loss: 2.210549682699224

Epoch: 6| Step: 2
Training loss: 1.9916083812713623
Validation loss: 2.1647219119533414

Epoch: 6| Step: 3
Training loss: 1.22784423828125
Validation loss: 2.2110823610777497

Epoch: 6| Step: 4
Training loss: 1.822487711906433
Validation loss: 2.1796189238948207

Epoch: 6| Step: 5
Training loss: 1.6388260126113892
Validation loss: 2.2117970182049658

Epoch: 6| Step: 6
Training loss: 1.8819619417190552
Validation loss: 2.238362435371645

Epoch: 6| Step: 7
Training loss: 0.9037739038467407
Validation loss: 2.2057924039902224

Epoch: 6| Step: 8
Training loss: 1.3729602098464966
Validation loss: 2.183900240928896

Epoch: 6| Step: 9
Training loss: 1.7710614204406738
Validation loss: 2.2234369247190413

Epoch: 6| Step: 10
Training loss: 1.1952893733978271
Validation loss: 2.2007526710469234

Epoch: 6| Step: 11
Training loss: 1.4077143669128418
Validation loss: 2.176964912363278

Epoch: 6| Step: 12
Training loss: 1.2425482273101807
Validation loss: 2.229641683640019

Epoch: 6| Step: 13
Training loss: 1.114625334739685
Validation loss: 2.1856442266894924

Epoch: 519| Step: 0
Training loss: 1.4214413166046143
Validation loss: 2.173481374658564

Epoch: 6| Step: 1
Training loss: 0.9981242418289185
Validation loss: 2.2553760428582468

Epoch: 6| Step: 2
Training loss: 1.5251189470291138
Validation loss: 2.1901586901757026

Epoch: 6| Step: 3
Training loss: 1.3091508150100708
Validation loss: 2.1804245120735577

Epoch: 6| Step: 4
Training loss: 1.0940935611724854
Validation loss: 2.228383296279497

Epoch: 6| Step: 5
Training loss: 2.179018497467041
Validation loss: 2.212713841469057

Epoch: 6| Step: 6
Training loss: 1.1262764930725098
Validation loss: 2.226739570658694

Epoch: 6| Step: 7
Training loss: 1.3304102420806885
Validation loss: 2.221116094179051

Epoch: 6| Step: 8
Training loss: 1.746301293373108
Validation loss: 2.156903812962194

Epoch: 6| Step: 9
Training loss: 1.7439417839050293
Validation loss: 2.1892849399197485

Epoch: 6| Step: 10
Training loss: 1.9346346855163574
Validation loss: 2.191871284156717

Epoch: 6| Step: 11
Training loss: 0.9510350227355957
Validation loss: 2.1914977924798125

Epoch: 6| Step: 12
Training loss: 1.2138375043869019
Validation loss: 2.204409855668263

Epoch: 6| Step: 13
Training loss: 1.477190375328064
Validation loss: 2.177814816915861

Epoch: 520| Step: 0
Training loss: 1.2459152936935425
Validation loss: 2.2025216779401227

Epoch: 6| Step: 1
Training loss: 1.2096636295318604
Validation loss: 2.1797512064697924

Epoch: 6| Step: 2
Training loss: 1.3814128637313843
Validation loss: 2.2052747793095087

Epoch: 6| Step: 3
Training loss: 2.103179693222046
Validation loss: 2.1761371525385047

Epoch: 6| Step: 4
Training loss: 1.5934982299804688
Validation loss: 2.209721665228567

Epoch: 6| Step: 5
Training loss: 1.453533411026001
Validation loss: 2.187673081633865

Epoch: 6| Step: 6
Training loss: 1.573826551437378
Validation loss: 2.196654171072027

Epoch: 6| Step: 7
Training loss: 2.0096213817596436
Validation loss: 2.161637939432616

Epoch: 6| Step: 8
Training loss: 1.3955025672912598
Validation loss: 2.174369027537684

Epoch: 6| Step: 9
Training loss: 0.9105629920959473
Validation loss: 2.1805253490324943

Epoch: 6| Step: 10
Training loss: 1.7518746852874756
Validation loss: 2.177702696092667

Epoch: 6| Step: 11
Training loss: 1.3718243837356567
Validation loss: 2.1861610925325783

Epoch: 6| Step: 12
Training loss: 1.0465171337127686
Validation loss: 2.1816001092233965

Epoch: 6| Step: 13
Training loss: 0.7199441194534302
Validation loss: 2.2302425497321674

Epoch: 521| Step: 0
Training loss: 1.5296120643615723
Validation loss: 2.1714757937257008

Epoch: 6| Step: 1
Training loss: 1.7513139247894287
Validation loss: 2.2171070626986924

Epoch: 6| Step: 2
Training loss: 1.3003621101379395
Validation loss: 2.1838805252505886

Epoch: 6| Step: 3
Training loss: 1.846811294555664
Validation loss: 2.2077567910635345

Epoch: 6| Step: 4
Training loss: 1.4270308017730713
Validation loss: 2.242696951794368

Epoch: 6| Step: 5
Training loss: 1.381895899772644
Validation loss: 2.2609877176182245

Epoch: 6| Step: 6
Training loss: 1.4183473587036133
Validation loss: 2.21065233343391

Epoch: 6| Step: 7
Training loss: 1.179746389389038
Validation loss: 2.2001985221780758

Epoch: 6| Step: 8
Training loss: 0.822235643863678
Validation loss: 2.209535905109939

Epoch: 6| Step: 9
Training loss: 1.3602755069732666
Validation loss: 2.236204001211351

Epoch: 6| Step: 10
Training loss: 1.3691328763961792
Validation loss: 2.223643256771949

Epoch: 6| Step: 11
Training loss: 2.063631057739258
Validation loss: 2.239952133547875

Epoch: 6| Step: 12
Training loss: 1.2812435626983643
Validation loss: 2.197657799208036

Epoch: 6| Step: 13
Training loss: 1.304018497467041
Validation loss: 2.206026359270978

Epoch: 522| Step: 0
Training loss: 1.393784761428833
Validation loss: 2.2091347914870068

Epoch: 6| Step: 1
Training loss: 0.979276180267334
Validation loss: 2.173767343644173

Epoch: 6| Step: 2
Training loss: 1.8963623046875
Validation loss: 2.19054203520539

Epoch: 6| Step: 3
Training loss: 1.7577588558197021
Validation loss: 2.18417130490785

Epoch: 6| Step: 4
Training loss: 1.2177678346633911
Validation loss: 2.198721919008481

Epoch: 6| Step: 5
Training loss: 1.4406424760818481
Validation loss: 2.179335714668356

Epoch: 6| Step: 6
Training loss: 1.0409882068634033
Validation loss: 2.216834637426561

Epoch: 6| Step: 7
Training loss: 2.3313045501708984
Validation loss: 2.2135685297750656

Epoch: 6| Step: 8
Training loss: 1.7773798704147339
Validation loss: 2.1487425501628588

Epoch: 6| Step: 9
Training loss: 1.2015293836593628
Validation loss: 2.2050056098609843

Epoch: 6| Step: 10
Training loss: 1.4205310344696045
Validation loss: 2.1597718628503944

Epoch: 6| Step: 11
Training loss: 0.7059735059738159
Validation loss: 2.2132615325271443

Epoch: 6| Step: 12
Training loss: 1.4229142665863037
Validation loss: 2.1967402171063166

Epoch: 6| Step: 13
Training loss: 1.6544137001037598
Validation loss: 2.2191372289452502

Epoch: 523| Step: 0
Training loss: 1.9683083295822144
Validation loss: 2.1948509344490628

Epoch: 6| Step: 1
Training loss: 0.5826905369758606
Validation loss: 2.1728789037273777

Epoch: 6| Step: 2
Training loss: 1.2111165523529053
Validation loss: 2.1648117457666705

Epoch: 6| Step: 3
Training loss: 1.981407642364502
Validation loss: 2.179913008084861

Epoch: 6| Step: 4
Training loss: 1.8228017091751099
Validation loss: 2.1803627937070784

Epoch: 6| Step: 5
Training loss: 1.2789170742034912
Validation loss: 2.159397868699925

Epoch: 6| Step: 6
Training loss: 1.0975916385650635
Validation loss: 2.230698882892568

Epoch: 6| Step: 7
Training loss: 1.9956607818603516
Validation loss: 2.1741338301730413

Epoch: 6| Step: 8
Training loss: 1.0826873779296875
Validation loss: 2.1883330383608417

Epoch: 6| Step: 9
Training loss: 1.4282112121582031
Validation loss: 2.191795749049033

Epoch: 6| Step: 10
Training loss: 1.1505600214004517
Validation loss: 2.175438524574362

Epoch: 6| Step: 11
Training loss: 1.5192700624465942
Validation loss: 2.205292247956799

Epoch: 6| Step: 12
Training loss: 0.910128116607666
Validation loss: 2.2273436797562467

Epoch: 6| Step: 13
Training loss: 2.914644956588745
Validation loss: 2.2141575813293457

Epoch: 524| Step: 0
Training loss: 0.897903561592102
Validation loss: 2.194385661873766

Epoch: 6| Step: 1
Training loss: 1.2449949979782104
Validation loss: 2.171999826226183

Epoch: 6| Step: 2
Training loss: 1.3231148719787598
Validation loss: 2.165605983426494

Epoch: 6| Step: 3
Training loss: 2.2102255821228027
Validation loss: 2.211191269659227

Epoch: 6| Step: 4
Training loss: 1.5098869800567627
Validation loss: 2.184198558971446

Epoch: 6| Step: 5
Training loss: 2.6293106079101562
Validation loss: 2.1665892601013184

Epoch: 6| Step: 6
Training loss: 1.4938287734985352
Validation loss: 2.226567009443878

Epoch: 6| Step: 7
Training loss: 1.1435847282409668
Validation loss: 2.2260896903212353

Epoch: 6| Step: 8
Training loss: 1.237532615661621
Validation loss: 2.20928128047656

Epoch: 6| Step: 9
Training loss: 1.3489253520965576
Validation loss: 2.212161761458202

Epoch: 6| Step: 10
Training loss: 1.176746129989624
Validation loss: 2.182108481725057

Epoch: 6| Step: 11
Training loss: 1.0673567056655884
Validation loss: 2.2249412331529843

Epoch: 6| Step: 12
Training loss: 0.9270983338356018
Validation loss: 2.220663998716621

Epoch: 6| Step: 13
Training loss: 1.9935855865478516
Validation loss: 2.2179826562122633

Epoch: 525| Step: 0
Training loss: 1.3022284507751465
Validation loss: 2.1699073186484714

Epoch: 6| Step: 1
Training loss: 1.6815623044967651
Validation loss: 2.174716839226343

Epoch: 6| Step: 2
Training loss: 1.2971646785736084
Validation loss: 2.1642901589793544

Epoch: 6| Step: 3
Training loss: 1.0297272205352783
Validation loss: 2.1777715144618863

Epoch: 6| Step: 4
Training loss: 1.0960688591003418
Validation loss: 2.1981419863239413

Epoch: 6| Step: 5
Training loss: 1.7169885635375977
Validation loss: 2.237145403380035

Epoch: 6| Step: 6
Training loss: 1.6538742780685425
Validation loss: 2.2073173676767657

Epoch: 6| Step: 7
Training loss: 1.782395362854004
Validation loss: 2.203909940617059

Epoch: 6| Step: 8
Training loss: 1.017215609550476
Validation loss: 2.2283920036849154

Epoch: 6| Step: 9
Training loss: 1.4875726699829102
Validation loss: 2.2122819654403196

Epoch: 6| Step: 10
Training loss: 1.399564266204834
Validation loss: 2.185015016986478

Epoch: 6| Step: 11
Training loss: 1.800051212310791
Validation loss: 2.1212290615163822

Epoch: 6| Step: 12
Training loss: 1.6530981063842773
Validation loss: 2.225104921607561

Epoch: 6| Step: 13
Training loss: 1.3233388662338257
Validation loss: 2.1837483529121644

Epoch: 526| Step: 0
Training loss: 1.5599430799484253
Validation loss: 2.2022311251650573

Epoch: 6| Step: 1
Training loss: 0.9943057298660278
Validation loss: 2.1549895501905874

Epoch: 6| Step: 2
Training loss: 1.4720046520233154
Validation loss: 2.1668201774679203

Epoch: 6| Step: 3
Training loss: 1.3408071994781494
Validation loss: 2.229026045850528

Epoch: 6| Step: 4
Training loss: 1.6074440479278564
Validation loss: 2.1963539200444377

Epoch: 6| Step: 5
Training loss: 1.4458646774291992
Validation loss: 2.248798886934916

Epoch: 6| Step: 6
Training loss: 1.6559226512908936
Validation loss: 2.2059439587336716

Epoch: 6| Step: 7
Training loss: 1.4477479457855225
Validation loss: 2.1887490210994596

Epoch: 6| Step: 8
Training loss: 1.8877174854278564
Validation loss: 2.2145344493209675

Epoch: 6| Step: 9
Training loss: 1.3210740089416504
Validation loss: 2.1733923727466213

Epoch: 6| Step: 10
Training loss: 1.3795725107192993
Validation loss: 2.141103862434305

Epoch: 6| Step: 11
Training loss: 1.153959035873413
Validation loss: 2.188158442897181

Epoch: 6| Step: 12
Training loss: 1.5750099420547485
Validation loss: 2.231974627382012

Epoch: 6| Step: 13
Training loss: 1.2981162071228027
Validation loss: 2.2126018949734267

Epoch: 527| Step: 0
Training loss: 1.6055868864059448
Validation loss: 2.2395674643977994

Epoch: 6| Step: 1
Training loss: 1.1023435592651367
Validation loss: 2.21403996662427

Epoch: 6| Step: 2
Training loss: 1.174256443977356
Validation loss: 2.2013498108874083

Epoch: 6| Step: 3
Training loss: 2.1813161373138428
Validation loss: 2.208302867028021

Epoch: 6| Step: 4
Training loss: 1.6553655862808228
Validation loss: 2.2309656707189416

Epoch: 6| Step: 5
Training loss: 1.1676006317138672
Validation loss: 2.2178430467523556

Epoch: 6| Step: 6
Training loss: 1.161780595779419
Validation loss: 2.2001888918620285

Epoch: 6| Step: 7
Training loss: 1.4937114715576172
Validation loss: 2.2027670901308776

Epoch: 6| Step: 8
Training loss: 1.8887717723846436
Validation loss: 2.238174856349986

Epoch: 6| Step: 9
Training loss: 1.5495121479034424
Validation loss: 2.2017379499250844

Epoch: 6| Step: 10
Training loss: 1.040176510810852
Validation loss: 2.1989185348633797

Epoch: 6| Step: 11
Training loss: 1.3358961343765259
Validation loss: 2.1847306169489378

Epoch: 6| Step: 12
Training loss: 1.2336453199386597
Validation loss: 2.203037351690313

Epoch: 6| Step: 13
Training loss: 1.9137262105941772
Validation loss: 2.2174690282473

Epoch: 528| Step: 0
Training loss: 1.623305082321167
Validation loss: 2.1714404090758292

Epoch: 6| Step: 1
Training loss: 1.5224647521972656
Validation loss: 2.180459758286835

Epoch: 6| Step: 2
Training loss: 1.2896430492401123
Validation loss: 2.1879203383640577

Epoch: 6| Step: 3
Training loss: 1.2748103141784668
Validation loss: 2.1813019885811755

Epoch: 6| Step: 4
Training loss: 0.8808475136756897
Validation loss: 2.1591958422814646

Epoch: 6| Step: 5
Training loss: 1.3355311155319214
Validation loss: 2.2463625656661166

Epoch: 6| Step: 6
Training loss: 1.475456714630127
Validation loss: 2.2324931647187922

Epoch: 6| Step: 7
Training loss: 1.848702311515808
Validation loss: 2.2369547249168478

Epoch: 6| Step: 8
Training loss: 1.2611418962478638
Validation loss: 2.2015595256641345

Epoch: 6| Step: 9
Training loss: 2.031013011932373
Validation loss: 2.2165453062262586

Epoch: 6| Step: 10
Training loss: 1.0643292665481567
Validation loss: 2.170056140551003

Epoch: 6| Step: 11
Training loss: 1.8460131883621216
Validation loss: 2.220922641856696

Epoch: 6| Step: 12
Training loss: 1.3097810745239258
Validation loss: 2.2141694125308784

Epoch: 6| Step: 13
Training loss: 1.1763646602630615
Validation loss: 2.1777311704492055

Epoch: 529| Step: 0
Training loss: 1.985480785369873
Validation loss: 2.22290031115214

Epoch: 6| Step: 1
Training loss: 0.9433243870735168
Validation loss: 2.1758352928264166

Epoch: 6| Step: 2
Training loss: 1.2880226373672485
Validation loss: 2.111374988350817

Epoch: 6| Step: 3
Training loss: 1.7105681896209717
Validation loss: 2.1779684251354587

Epoch: 6| Step: 4
Training loss: 1.3945780992507935
Validation loss: 2.1738793144943895

Epoch: 6| Step: 5
Training loss: 1.0460997819900513
Validation loss: 2.2023675493014756

Epoch: 6| Step: 6
Training loss: 1.6457421779632568
Validation loss: 2.18857749559546

Epoch: 6| Step: 7
Training loss: 1.3722281455993652
Validation loss: 2.175854649595035

Epoch: 6| Step: 8
Training loss: 1.5440247058868408
Validation loss: 2.1898094146482405

Epoch: 6| Step: 9
Training loss: 1.3428363800048828
Validation loss: 2.236043550634897

Epoch: 6| Step: 10
Training loss: 1.6494709253311157
Validation loss: 2.145277129706516

Epoch: 6| Step: 11
Training loss: 1.5420676469802856
Validation loss: 2.2074680546278596

Epoch: 6| Step: 12
Training loss: 1.4346469640731812
Validation loss: 2.188597515065183

Epoch: 6| Step: 13
Training loss: 1.3706289529800415
Validation loss: 2.194853890326715

Epoch: 530| Step: 0
Training loss: 0.7150776982307434
Validation loss: 2.2344305874198995

Epoch: 6| Step: 1
Training loss: 1.5370864868164062
Validation loss: 2.16136166357225

Epoch: 6| Step: 2
Training loss: 1.7485119104385376
Validation loss: 2.186250079062677

Epoch: 6| Step: 3
Training loss: 1.9636688232421875
Validation loss: 2.153307560951479

Epoch: 6| Step: 4
Training loss: 1.7217737436294556
Validation loss: 2.1822242890634844

Epoch: 6| Step: 5
Training loss: 1.7850587368011475
Validation loss: 2.1800240752517537

Epoch: 6| Step: 6
Training loss: 0.8283654451370239
Validation loss: 2.2262856011749594

Epoch: 6| Step: 7
Training loss: 1.0766549110412598
Validation loss: 2.209753058289969

Epoch: 6| Step: 8
Training loss: 1.6646983623504639
Validation loss: 2.2142939875202794

Epoch: 6| Step: 9
Training loss: 1.5672369003295898
Validation loss: 2.174069716084388

Epoch: 6| Step: 10
Training loss: 1.092381238937378
Validation loss: 2.1837800779650287

Epoch: 6| Step: 11
Training loss: 1.9026768207550049
Validation loss: 2.1819428333672146

Epoch: 6| Step: 12
Training loss: 0.964812159538269
Validation loss: 2.263053683824437

Epoch: 6| Step: 13
Training loss: 1.4208577871322632
Validation loss: 2.201454166443117

Epoch: 531| Step: 0
Training loss: 1.2586934566497803
Validation loss: 2.212080583777479

Epoch: 6| Step: 1
Training loss: 1.3335609436035156
Validation loss: 2.152417948169093

Epoch: 6| Step: 2
Training loss: 1.4555330276489258
Validation loss: 2.1809248001344743

Epoch: 6| Step: 3
Training loss: 1.6532914638519287
Validation loss: 2.2007475309474493

Epoch: 6| Step: 4
Training loss: 1.1540658473968506
Validation loss: 2.19848620763389

Epoch: 6| Step: 5
Training loss: 1.7363722324371338
Validation loss: 2.2025746722375192

Epoch: 6| Step: 6
Training loss: 1.4287035465240479
Validation loss: 2.169859973333215

Epoch: 6| Step: 7
Training loss: 1.1194965839385986
Validation loss: 2.214378064678561

Epoch: 6| Step: 8
Training loss: 2.0595366954803467
Validation loss: 2.1865511889098794

Epoch: 6| Step: 9
Training loss: 1.6565533876419067
Validation loss: 2.186170329329788

Epoch: 6| Step: 10
Training loss: 1.3273683786392212
Validation loss: 2.225438943473242

Epoch: 6| Step: 11
Training loss: 1.286736011505127
Validation loss: 2.215822265994164

Epoch: 6| Step: 12
Training loss: 1.3932256698608398
Validation loss: 2.2380288288157475

Epoch: 6| Step: 13
Training loss: 0.9747498631477356
Validation loss: 2.1478488701646046

Epoch: 532| Step: 0
Training loss: 1.6730146408081055
Validation loss: 2.232611443406792

Epoch: 6| Step: 1
Training loss: 1.0380520820617676
Validation loss: 2.207394310223159

Epoch: 6| Step: 2
Training loss: 0.9523591995239258
Validation loss: 2.244167771390689

Epoch: 6| Step: 3
Training loss: 1.5190166234970093
Validation loss: 2.1956329140611874

Epoch: 6| Step: 4
Training loss: 1.2091550827026367
Validation loss: 2.2007776742340415

Epoch: 6| Step: 5
Training loss: 2.0124616622924805
Validation loss: 2.215145331557079

Epoch: 6| Step: 6
Training loss: 0.8174574375152588
Validation loss: 2.2157222660638953

Epoch: 6| Step: 7
Training loss: 1.5539194345474243
Validation loss: 2.2374527633831067

Epoch: 6| Step: 8
Training loss: 1.3175649642944336
Validation loss: 2.2298353795082337

Epoch: 6| Step: 9
Training loss: 1.2009031772613525
Validation loss: 2.277603232732383

Epoch: 6| Step: 10
Training loss: 1.435333013534546
Validation loss: 2.1685762507941133

Epoch: 6| Step: 11
Training loss: 1.754372477531433
Validation loss: 2.240188847305954

Epoch: 6| Step: 12
Training loss: 2.4619364738464355
Validation loss: 2.2287898537933186

Epoch: 6| Step: 13
Training loss: 1.5130903720855713
Validation loss: 2.1935726493917485

Epoch: 533| Step: 0
Training loss: 1.3876546621322632
Validation loss: 2.2029411715845906

Epoch: 6| Step: 1
Training loss: 1.356785774230957
Validation loss: 2.245071357296359

Epoch: 6| Step: 2
Training loss: 1.9337832927703857
Validation loss: 2.203816249806394

Epoch: 6| Step: 3
Training loss: 1.8508541584014893
Validation loss: 2.1589557227268013

Epoch: 6| Step: 4
Training loss: 1.4204895496368408
Validation loss: 2.2105428070150395

Epoch: 6| Step: 5
Training loss: 1.6588237285614014
Validation loss: 2.2038191928658435

Epoch: 6| Step: 6
Training loss: 1.340878963470459
Validation loss: 2.1851828226479153

Epoch: 6| Step: 7
Training loss: 0.6369106769561768
Validation loss: 2.2321195858781055

Epoch: 6| Step: 8
Training loss: 1.5763177871704102
Validation loss: 2.2292473085464968

Epoch: 6| Step: 9
Training loss: 1.059267282485962
Validation loss: 2.1824876646841727

Epoch: 6| Step: 10
Training loss: 1.586667537689209
Validation loss: 2.210250803219375

Epoch: 6| Step: 11
Training loss: 1.1472058296203613
Validation loss: 2.1811783621388097

Epoch: 6| Step: 12
Training loss: 1.5074937343597412
Validation loss: 2.1709971761190765

Epoch: 6| Step: 13
Training loss: 1.5704792737960815
Validation loss: 2.207433460861124

Epoch: 534| Step: 0
Training loss: 1.4534881114959717
Validation loss: 2.222162264649586

Epoch: 6| Step: 1
Training loss: 1.4786311388015747
Validation loss: 2.218302483199745

Epoch: 6| Step: 2
Training loss: 2.223090887069702
Validation loss: 2.167037393457146

Epoch: 6| Step: 3
Training loss: 1.1555743217468262
Validation loss: 2.1798514832732496

Epoch: 6| Step: 4
Training loss: 1.8914718627929688
Validation loss: 2.163026048291114

Epoch: 6| Step: 5
Training loss: 0.9483330845832825
Validation loss: 2.1806093595361196

Epoch: 6| Step: 6
Training loss: 1.4313888549804688
Validation loss: 2.1870503861417054

Epoch: 6| Step: 7
Training loss: 1.1415380239486694
Validation loss: 2.1862068163451327

Epoch: 6| Step: 8
Training loss: 1.2463405132293701
Validation loss: 2.2197921968275502

Epoch: 6| Step: 9
Training loss: 1.5118448734283447
Validation loss: 2.1611651707721014

Epoch: 6| Step: 10
Training loss: 1.5767056941986084
Validation loss: 2.1832902534033662

Epoch: 6| Step: 11
Training loss: 1.573655605316162
Validation loss: 2.2317927037515948

Epoch: 6| Step: 12
Training loss: 1.4795336723327637
Validation loss: 2.220187697359311

Epoch: 6| Step: 13
Training loss: 0.9118393659591675
Validation loss: 2.221340820353518

Epoch: 535| Step: 0
Training loss: 1.2782351970672607
Validation loss: 2.199898273714127

Epoch: 6| Step: 1
Training loss: 1.6216691732406616
Validation loss: 2.169395136576827

Epoch: 6| Step: 2
Training loss: 1.5677971839904785
Validation loss: 2.2068835458447857

Epoch: 6| Step: 3
Training loss: 1.5626161098480225
Validation loss: 2.2424930936546734

Epoch: 6| Step: 4
Training loss: 0.9160699248313904
Validation loss: 2.2310718464595016

Epoch: 6| Step: 5
Training loss: 1.6062569618225098
Validation loss: 2.282600502814016

Epoch: 6| Step: 6
Training loss: 1.3662772178649902
Validation loss: 2.244769225838364

Epoch: 6| Step: 7
Training loss: 1.4138354063034058
Validation loss: 2.196059742281514

Epoch: 6| Step: 8
Training loss: 1.484572410583496
Validation loss: 2.1937969705109954

Epoch: 6| Step: 9
Training loss: 1.2124688625335693
Validation loss: 2.2051803860613095

Epoch: 6| Step: 10
Training loss: 1.0906708240509033
Validation loss: 2.2210810402388215

Epoch: 6| Step: 11
Training loss: 1.5756361484527588
Validation loss: 2.2118547834375852

Epoch: 6| Step: 12
Training loss: 1.9605913162231445
Validation loss: 2.216836949830414

Epoch: 6| Step: 13
Training loss: 0.9179966449737549
Validation loss: 2.1678818143824095

Epoch: 536| Step: 0
Training loss: 0.9305728673934937
Validation loss: 2.1379262990848993

Epoch: 6| Step: 1
Training loss: 1.7610085010528564
Validation loss: 2.180119511901691

Epoch: 6| Step: 2
Training loss: 1.701720952987671
Validation loss: 2.17283264283211

Epoch: 6| Step: 3
Training loss: 1.1110260486602783
Validation loss: 2.1545036300536125

Epoch: 6| Step: 4
Training loss: 1.8903552293777466
Validation loss: 2.1918498867301532

Epoch: 6| Step: 5
Training loss: 2.0766592025756836
Validation loss: 2.1738821947446434

Epoch: 6| Step: 6
Training loss: 1.4204779863357544
Validation loss: 2.167738065924696

Epoch: 6| Step: 7
Training loss: 1.2863324880599976
Validation loss: 2.18440536145241

Epoch: 6| Step: 8
Training loss: 0.8010732531547546
Validation loss: 2.267844077079527

Epoch: 6| Step: 9
Training loss: 2.117330551147461
Validation loss: 2.221151210928476

Epoch: 6| Step: 10
Training loss: 1.591208815574646
Validation loss: 2.2061867842110257

Epoch: 6| Step: 11
Training loss: 0.8136987090110779
Validation loss: 2.2040496795408187

Epoch: 6| Step: 12
Training loss: 1.0194509029388428
Validation loss: 2.2206776603575675

Epoch: 6| Step: 13
Training loss: 1.5230841636657715
Validation loss: 2.1829422289325344

Epoch: 537| Step: 0
Training loss: 1.7143505811691284
Validation loss: 2.197111624543385

Epoch: 6| Step: 1
Training loss: 2.3325695991516113
Validation loss: 2.2340132369790027

Epoch: 6| Step: 2
Training loss: 1.0062700510025024
Validation loss: 2.244907917514924

Epoch: 6| Step: 3
Training loss: 1.3453543186187744
Validation loss: 2.232143130353702

Epoch: 6| Step: 4
Training loss: 1.0790340900421143
Validation loss: 2.173340453896471

Epoch: 6| Step: 5
Training loss: 1.447859764099121
Validation loss: 2.2044814581512124

Epoch: 6| Step: 6
Training loss: 2.3432226181030273
Validation loss: 2.2638461641086045

Epoch: 6| Step: 7
Training loss: 1.0018261671066284
Validation loss: 2.2309689252607283

Epoch: 6| Step: 8
Training loss: 0.9964697957038879
Validation loss: 2.2173240979512534

Epoch: 6| Step: 9
Training loss: 1.1024253368377686
Validation loss: 2.239190815597452

Epoch: 6| Step: 10
Training loss: 1.2235944271087646
Validation loss: 2.2088521526705835

Epoch: 6| Step: 11
Training loss: 1.7177717685699463
Validation loss: 2.213429138224612

Epoch: 6| Step: 12
Training loss: 1.175081729888916
Validation loss: 2.233531908322406

Epoch: 6| Step: 13
Training loss: 1.246473789215088
Validation loss: 2.2347810370947725

Epoch: 538| Step: 0
Training loss: 1.5455342531204224
Validation loss: 2.14995527139274

Epoch: 6| Step: 1
Training loss: 1.6253398656845093
Validation loss: 2.16529094788336

Epoch: 6| Step: 2
Training loss: 1.1970489025115967
Validation loss: 2.1838764221437517

Epoch: 6| Step: 3
Training loss: 1.2024941444396973
Validation loss: 2.1488961173642065

Epoch: 6| Step: 4
Training loss: 1.9239153861999512
Validation loss: 2.1551777675587642

Epoch: 6| Step: 5
Training loss: 1.3559956550598145
Validation loss: 2.1898732877546743

Epoch: 6| Step: 6
Training loss: 1.334238052368164
Validation loss: 2.182884144526656

Epoch: 6| Step: 7
Training loss: 1.5131056308746338
Validation loss: 2.200914147079632

Epoch: 6| Step: 8
Training loss: 1.0560201406478882
Validation loss: 2.2193281214724303

Epoch: 6| Step: 9
Training loss: 1.635563850402832
Validation loss: 2.176578293564499

Epoch: 6| Step: 10
Training loss: 1.4175667762756348
Validation loss: 2.2114344361007854

Epoch: 6| Step: 11
Training loss: 1.162163496017456
Validation loss: 2.2131592125021

Epoch: 6| Step: 12
Training loss: 1.490524411201477
Validation loss: 2.1940874450950214

Epoch: 6| Step: 13
Training loss: 1.7125669717788696
Validation loss: 2.1985084010708715

Epoch: 539| Step: 0
Training loss: 0.9103121161460876
Validation loss: 2.251363718381492

Epoch: 6| Step: 1
Training loss: 1.3247900009155273
Validation loss: 2.1796104113260903

Epoch: 6| Step: 2
Training loss: 1.4473698139190674
Validation loss: 2.191377429551976

Epoch: 6| Step: 3
Training loss: 1.0429880619049072
Validation loss: 2.2081313312694593

Epoch: 6| Step: 4
Training loss: 0.8762261271476746
Validation loss: 2.1829555906275266

Epoch: 6| Step: 5
Training loss: 1.6336586475372314
Validation loss: 2.234470676350337

Epoch: 6| Step: 6
Training loss: 1.2609074115753174
Validation loss: 2.220914271570021

Epoch: 6| Step: 7
Training loss: 1.2702925205230713
Validation loss: 2.198308753710921

Epoch: 6| Step: 8
Training loss: 1.9122148752212524
Validation loss: 2.178830644135834

Epoch: 6| Step: 9
Training loss: 1.5814539194107056
Validation loss: 2.2090491069260465

Epoch: 6| Step: 10
Training loss: 1.907257318496704
Validation loss: 2.2132060502165105

Epoch: 6| Step: 11
Training loss: 1.5372180938720703
Validation loss: 2.241790827884469

Epoch: 6| Step: 12
Training loss: 1.267927885055542
Validation loss: 2.2449624358966784

Epoch: 6| Step: 13
Training loss: 1.5344762802124023
Validation loss: 2.218904964385494

Epoch: 540| Step: 0
Training loss: 1.8832072019577026
Validation loss: 2.2193839601291123

Epoch: 6| Step: 1
Training loss: 1.7666085958480835
Validation loss: 2.215094377917628

Epoch: 6| Step: 2
Training loss: 0.5855569243431091
Validation loss: 2.1743715091418196

Epoch: 6| Step: 3
Training loss: 1.8984862565994263
Validation loss: 2.2476989364111297

Epoch: 6| Step: 4
Training loss: 0.6287513971328735
Validation loss: 2.1954268511905464

Epoch: 6| Step: 5
Training loss: 1.5638751983642578
Validation loss: 2.20752655049806

Epoch: 6| Step: 6
Training loss: 1.2754251956939697
Validation loss: 2.192131765427128

Epoch: 6| Step: 7
Training loss: 1.0263323783874512
Validation loss: 2.21858355434992

Epoch: 6| Step: 8
Training loss: 1.009498119354248
Validation loss: 2.184874693552653

Epoch: 6| Step: 9
Training loss: 1.6381170749664307
Validation loss: 2.2512483135346444

Epoch: 6| Step: 10
Training loss: 1.7725794315338135
Validation loss: 2.2191200640893753

Epoch: 6| Step: 11
Training loss: 1.8405182361602783
Validation loss: 2.262910214803552

Epoch: 6| Step: 12
Training loss: 1.236478567123413
Validation loss: 2.205532540557205

Epoch: 6| Step: 13
Training loss: 1.0863865613937378
Validation loss: 2.159311886756651

Epoch: 541| Step: 0
Training loss: 2.2247889041900635
Validation loss: 2.2133344117031304

Epoch: 6| Step: 1
Training loss: 1.725235939025879
Validation loss: 2.213313535977435

Epoch: 6| Step: 2
Training loss: 1.2866358757019043
Validation loss: 2.1410711067979054

Epoch: 6| Step: 3
Training loss: 1.340193748474121
Validation loss: 2.2003220230020504

Epoch: 6| Step: 4
Training loss: 1.7290034294128418
Validation loss: 2.2484237378643406

Epoch: 6| Step: 5
Training loss: 1.138035774230957
Validation loss: 2.1653853847134497

Epoch: 6| Step: 6
Training loss: 1.4772191047668457
Validation loss: 2.1969113837006273

Epoch: 6| Step: 7
Training loss: 0.892410397529602
Validation loss: 2.194811790220199

Epoch: 6| Step: 8
Training loss: 1.6216959953308105
Validation loss: 2.1651537085092194

Epoch: 6| Step: 9
Training loss: 0.7929273843765259
Validation loss: 2.2124244102867703

Epoch: 6| Step: 10
Training loss: 2.2692580223083496
Validation loss: 2.183645148431101

Epoch: 6| Step: 11
Training loss: 1.5191960334777832
Validation loss: 2.2295628875814457

Epoch: 6| Step: 12
Training loss: 0.6736077070236206
Validation loss: 2.1905717285730506

Epoch: 6| Step: 13
Training loss: 1.1479086875915527
Validation loss: 2.2175246746309343

Epoch: 542| Step: 0
Training loss: 0.8789006471633911
Validation loss: 2.1666067031122025

Epoch: 6| Step: 1
Training loss: 1.6199097633361816
Validation loss: 2.1895484962771015

Epoch: 6| Step: 2
Training loss: 1.7566145658493042
Validation loss: 2.2083112039873676

Epoch: 6| Step: 3
Training loss: 1.1841716766357422
Validation loss: 2.2132503268539265

Epoch: 6| Step: 4
Training loss: 2.0171637535095215
Validation loss: 2.233395068876205

Epoch: 6| Step: 5
Training loss: 1.4426703453063965
Validation loss: 2.195357225274527

Epoch: 6| Step: 6
Training loss: 1.1084613800048828
Validation loss: 2.1486354540753108

Epoch: 6| Step: 7
Training loss: 1.4710919857025146
Validation loss: 2.202562383426133

Epoch: 6| Step: 8
Training loss: 1.2559993267059326
Validation loss: 2.2211312478588474

Epoch: 6| Step: 9
Training loss: 1.157813549041748
Validation loss: 2.214030988754765

Epoch: 6| Step: 10
Training loss: 1.8739838600158691
Validation loss: 2.217071061493248

Epoch: 6| Step: 11
Training loss: 1.1914455890655518
Validation loss: 2.2333754160070933

Epoch: 6| Step: 12
Training loss: 0.9320113062858582
Validation loss: 2.1859490986793273

Epoch: 6| Step: 13
Training loss: 1.4116312265396118
Validation loss: 2.2009433802737983

Epoch: 543| Step: 0
Training loss: 0.9245450496673584
Validation loss: 2.1923491954803467

Epoch: 6| Step: 1
Training loss: 1.3978244066238403
Validation loss: 2.161104953417214

Epoch: 6| Step: 2
Training loss: 2.0962295532226562
Validation loss: 2.2058603584125476

Epoch: 6| Step: 3
Training loss: 1.3282469511032104
Validation loss: 2.1738352314118417

Epoch: 6| Step: 4
Training loss: 1.643723964691162
Validation loss: 2.2047124934452835

Epoch: 6| Step: 5
Training loss: 1.4417450428009033
Validation loss: 2.230988388420433

Epoch: 6| Step: 6
Training loss: 1.3691661357879639
Validation loss: 2.1908915427423294

Epoch: 6| Step: 7
Training loss: 1.0720856189727783
Validation loss: 2.2015306257432505

Epoch: 6| Step: 8
Training loss: 1.3402845859527588
Validation loss: 2.1813940130254275

Epoch: 6| Step: 9
Training loss: 1.9419043064117432
Validation loss: 2.1783847065382105

Epoch: 6| Step: 10
Training loss: 0.9982051849365234
Validation loss: 2.181076870169691

Epoch: 6| Step: 11
Training loss: 1.5497097969055176
Validation loss: 2.2274226373241794

Epoch: 6| Step: 12
Training loss: 1.6816891431808472
Validation loss: 2.175817028168709

Epoch: 6| Step: 13
Training loss: 0.860621988773346
Validation loss: 2.18179593547698

Epoch: 544| Step: 0
Training loss: 1.2096278667449951
Validation loss: 2.1683987468801518

Epoch: 6| Step: 1
Training loss: 1.5823405981063843
Validation loss: 2.191674740083756

Epoch: 6| Step: 2
Training loss: 0.9449437856674194
Validation loss: 2.194056200724776

Epoch: 6| Step: 3
Training loss: 1.0815622806549072
Validation loss: 2.2771567298519995

Epoch: 6| Step: 4
Training loss: 0.955237865447998
Validation loss: 2.13911525664791

Epoch: 6| Step: 5
Training loss: 1.7951122522354126
Validation loss: 2.260089078257161

Epoch: 6| Step: 6
Training loss: 0.9700801968574524
Validation loss: 2.2000480595455376

Epoch: 6| Step: 7
Training loss: 1.3931736946105957
Validation loss: 2.275440549337736

Epoch: 6| Step: 8
Training loss: 1.3405758142471313
Validation loss: 2.217505915190584

Epoch: 6| Step: 9
Training loss: 1.9061715602874756
Validation loss: 2.1620272513358825

Epoch: 6| Step: 10
Training loss: 1.4117443561553955
Validation loss: 2.2053868616780927

Epoch: 6| Step: 11
Training loss: 1.4841450452804565
Validation loss: 2.246972078918129

Epoch: 6| Step: 12
Training loss: 1.8544883728027344
Validation loss: 2.17631890696864

Epoch: 6| Step: 13
Training loss: 1.285165786743164
Validation loss: 2.185271837378061

Epoch: 545| Step: 0
Training loss: 1.1427605152130127
Validation loss: 2.180190458092638

Epoch: 6| Step: 1
Training loss: 1.0522297620773315
Validation loss: 2.212516141194169

Epoch: 6| Step: 2
Training loss: 1.223752498626709
Validation loss: 2.2338775460438063

Epoch: 6| Step: 3
Training loss: 1.7942941188812256
Validation loss: 2.2337941636321363

Epoch: 6| Step: 4
Training loss: 1.1650993824005127
Validation loss: 2.212754529009583

Epoch: 6| Step: 5
Training loss: 1.864877700805664
Validation loss: 2.222877816487384

Epoch: 6| Step: 6
Training loss: 1.6295926570892334
Validation loss: 2.1888055416845504

Epoch: 6| Step: 7
Training loss: 1.3955862522125244
Validation loss: 2.214294666885048

Epoch: 6| Step: 8
Training loss: 0.9350244402885437
Validation loss: 2.2065146225754932

Epoch: 6| Step: 9
Training loss: 1.4681954383850098
Validation loss: 2.1862656839432253

Epoch: 6| Step: 10
Training loss: 0.9951126575469971
Validation loss: 2.158110176363299

Epoch: 6| Step: 11
Training loss: 1.685632586479187
Validation loss: 2.1906187047240553

Epoch: 6| Step: 12
Training loss: 1.6526638269424438
Validation loss: 2.22414461258919

Epoch: 6| Step: 13
Training loss: 2.2399182319641113
Validation loss: 2.187412720854564

Epoch: 546| Step: 0
Training loss: 1.5713226795196533
Validation loss: 2.1911871458894465

Epoch: 6| Step: 1
Training loss: 1.5972025394439697
Validation loss: 2.2206450329031995

Epoch: 6| Step: 2
Training loss: 0.9394932389259338
Validation loss: 2.2044030825297036

Epoch: 6| Step: 3
Training loss: 1.2973557710647583
Validation loss: 2.1969865060621694

Epoch: 6| Step: 4
Training loss: 1.7178709506988525
Validation loss: 2.2053466868656937

Epoch: 6| Step: 5
Training loss: 1.7858431339263916
Validation loss: 2.209449186119982

Epoch: 6| Step: 6
Training loss: 0.9635911583900452
Validation loss: 2.199373601585306

Epoch: 6| Step: 7
Training loss: 1.1177778244018555
Validation loss: 2.1567044463208926

Epoch: 6| Step: 8
Training loss: 1.3838119506835938
Validation loss: 2.16165389040465

Epoch: 6| Step: 9
Training loss: 1.903897762298584
Validation loss: 2.2015436541649605

Epoch: 6| Step: 10
Training loss: 1.3280749320983887
Validation loss: 2.1779732088888846

Epoch: 6| Step: 11
Training loss: 1.165708065032959
Validation loss: 2.163938690257329

Epoch: 6| Step: 12
Training loss: 1.513451099395752
Validation loss: 2.20825764184357

Epoch: 6| Step: 13
Training loss: 1.6038265228271484
Validation loss: 2.1896010355282853

Epoch: 547| Step: 0
Training loss: 1.5872231721878052
Validation loss: 2.1542996411682456

Epoch: 6| Step: 1
Training loss: 1.611533522605896
Validation loss: 2.162723207986483

Epoch: 6| Step: 2
Training loss: 1.3904696702957153
Validation loss: 2.2075457906210296

Epoch: 6| Step: 3
Training loss: 1.7570157051086426
Validation loss: 2.200471947270055

Epoch: 6| Step: 4
Training loss: 1.7606377601623535
Validation loss: 2.1845942287034887

Epoch: 6| Step: 5
Training loss: 1.128078579902649
Validation loss: 2.156992438018963

Epoch: 6| Step: 6
Training loss: 1.2491309642791748
Validation loss: 2.165475942755258

Epoch: 6| Step: 7
Training loss: 0.7186179757118225
Validation loss: 2.1742605573387555

Epoch: 6| Step: 8
Training loss: 1.5961227416992188
Validation loss: 2.183989355641027

Epoch: 6| Step: 9
Training loss: 0.9965768456459045
Validation loss: 2.213767497770248

Epoch: 6| Step: 10
Training loss: 1.445939540863037
Validation loss: 2.182406794640326

Epoch: 6| Step: 11
Training loss: 2.1610915660858154
Validation loss: 2.170720395221505

Epoch: 6| Step: 12
Training loss: 0.6783602237701416
Validation loss: 2.2085519503521662

Epoch: 6| Step: 13
Training loss: 0.7845947742462158
Validation loss: 2.240447917292195

Epoch: 548| Step: 0
Training loss: 1.368476390838623
Validation loss: 2.2180760983497865

Epoch: 6| Step: 1
Training loss: 1.479697823524475
Validation loss: 2.1971752694858018

Epoch: 6| Step: 2
Training loss: 1.6023679971694946
Validation loss: 2.200938176083308

Epoch: 6| Step: 3
Training loss: 1.2304409742355347
Validation loss: 2.2332845298192834

Epoch: 6| Step: 4
Training loss: 1.1198772192001343
Validation loss: 2.244533900291689

Epoch: 6| Step: 5
Training loss: 0.94300377368927
Validation loss: 2.219898650723119

Epoch: 6| Step: 6
Training loss: 2.417656660079956
Validation loss: 2.197030154607629

Epoch: 6| Step: 7
Training loss: 0.817350447177887
Validation loss: 2.165015092460058

Epoch: 6| Step: 8
Training loss: 1.575657844543457
Validation loss: 2.20218349272205

Epoch: 6| Step: 9
Training loss: 1.634423851966858
Validation loss: 2.224230606068847

Epoch: 6| Step: 10
Training loss: 1.8366470336914062
Validation loss: 2.1951022917224514

Epoch: 6| Step: 11
Training loss: 0.9662559032440186
Validation loss: 2.1624980177930606

Epoch: 6| Step: 12
Training loss: 1.450851559638977
Validation loss: 2.2205006666080926

Epoch: 6| Step: 13
Training loss: 1.5372881889343262
Validation loss: 2.2255999580506356

Epoch: 549| Step: 0
Training loss: 1.3146822452545166
Validation loss: 2.209665447153071

Epoch: 6| Step: 1
Training loss: 2.476057529449463
Validation loss: 2.2103738438698555

Epoch: 6| Step: 2
Training loss: 1.1953181028366089
Validation loss: 2.2011518516848163

Epoch: 6| Step: 3
Training loss: 1.3470120429992676
Validation loss: 2.210508697776384

Epoch: 6| Step: 4
Training loss: 1.333240032196045
Validation loss: 2.215140317075996

Epoch: 6| Step: 5
Training loss: 1.3829929828643799
Validation loss: 2.2219664691596903

Epoch: 6| Step: 6
Training loss: 1.6026105880737305
Validation loss: 2.1926405173476025

Epoch: 6| Step: 7
Training loss: 1.9545111656188965
Validation loss: 2.1700977997113298

Epoch: 6| Step: 8
Training loss: 1.2325364351272583
Validation loss: 2.2331353720798286

Epoch: 6| Step: 9
Training loss: 1.5553288459777832
Validation loss: 2.163440965837048

Epoch: 6| Step: 10
Training loss: 0.8142141699790955
Validation loss: 2.2041460185922603

Epoch: 6| Step: 11
Training loss: 1.0249829292297363
Validation loss: 2.2327735603496595

Epoch: 6| Step: 12
Training loss: 1.3318893909454346
Validation loss: 2.215192151326005

Epoch: 6| Step: 13
Training loss: 0.7899034023284912
Validation loss: 2.2213687845455703

Epoch: 550| Step: 0
Training loss: 1.2043836116790771
Validation loss: 2.1693213191083682

Epoch: 6| Step: 1
Training loss: 1.3442468643188477
Validation loss: 2.197378389296993

Epoch: 6| Step: 2
Training loss: 1.3056787252426147
Validation loss: 2.199702247496574

Epoch: 6| Step: 3
Training loss: 1.5089011192321777
Validation loss: 2.164426993298274

Epoch: 6| Step: 4
Training loss: 1.4158231019973755
Validation loss: 2.154699851107854

Epoch: 6| Step: 5
Training loss: 1.417947769165039
Validation loss: 2.2040711474675003

Epoch: 6| Step: 6
Training loss: 1.6701569557189941
Validation loss: 2.168841682454591

Epoch: 6| Step: 7
Training loss: 1.0240012407302856
Validation loss: 2.1985314430729037

Epoch: 6| Step: 8
Training loss: 1.262172818183899
Validation loss: 2.2086472101109003

Epoch: 6| Step: 9
Training loss: 1.4584349393844604
Validation loss: 2.2054047276896815

Epoch: 6| Step: 10
Training loss: 2.0850703716278076
Validation loss: 2.225847883891034

Epoch: 6| Step: 11
Training loss: 1.7504379749298096
Validation loss: 2.184897086953604

Epoch: 6| Step: 12
Training loss: 0.960952877998352
Validation loss: 2.2175217238805627

Epoch: 6| Step: 13
Training loss: 0.6152200102806091
Validation loss: 2.173969304689797

Testing loss: 2.075800997681088
