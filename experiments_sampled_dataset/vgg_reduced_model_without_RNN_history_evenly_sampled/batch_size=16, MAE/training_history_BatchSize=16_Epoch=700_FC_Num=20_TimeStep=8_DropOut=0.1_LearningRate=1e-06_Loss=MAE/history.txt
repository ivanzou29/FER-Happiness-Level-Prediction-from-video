Epoch: 1| Step: 0
Training loss: 6.139898777008057
Validation loss: 5.303018457146101

Epoch: 6| Step: 1
Training loss: 4.975661277770996
Validation loss: 5.298963741589618

Epoch: 6| Step: 2
Training loss: 6.113659858703613
Validation loss: 5.294273058573405

Epoch: 6| Step: 3
Training loss: 4.304402828216553
Validation loss: 5.290281172721617

Epoch: 6| Step: 4
Training loss: 4.384912490844727
Validation loss: 5.285398308948804

Epoch: 6| Step: 5
Training loss: 4.293283462524414
Validation loss: 5.280879943601547

Epoch: 6| Step: 6
Training loss: 4.622300148010254
Validation loss: 5.27728465295607

Epoch: 6| Step: 7
Training loss: 3.8401906490325928
Validation loss: 5.2744128268252135

Epoch: 6| Step: 8
Training loss: 3.991312265396118
Validation loss: 5.267566973163236

Epoch: 6| Step: 9
Training loss: 3.973863124847412
Validation loss: 5.268495713510821

Epoch: 6| Step: 10
Training loss: 5.4171881675720215
Validation loss: 5.261895769385881

Epoch: 6| Step: 11
Training loss: 7.143475532531738
Validation loss: 5.257387791910479

Epoch: 6| Step: 12
Training loss: 6.004436016082764
Validation loss: 5.251743619159986

Epoch: 6| Step: 13
Training loss: 6.397739410400391
Validation loss: 5.249621842497138

Epoch: 2| Step: 0
Training loss: 5.98857307434082
Validation loss: 5.2464883660757415

Epoch: 6| Step: 1
Training loss: 4.982833385467529
Validation loss: 5.24310803157027

Epoch: 6| Step: 2
Training loss: 5.857861518859863
Validation loss: 5.237038207310502

Epoch: 6| Step: 3
Training loss: 5.350004196166992
Validation loss: 5.234245684839064

Epoch: 6| Step: 4
Training loss: 4.6294026374816895
Validation loss: 5.230278481719314

Epoch: 6| Step: 5
Training loss: 5.055266380310059
Validation loss: 5.223308552977859

Epoch: 6| Step: 6
Training loss: 5.081935405731201
Validation loss: 5.220956105057911

Epoch: 6| Step: 7
Training loss: 5.475028038024902
Validation loss: 5.217809718142274

Epoch: 6| Step: 8
Training loss: 4.353644847869873
Validation loss: 5.21224429017754

Epoch: 6| Step: 9
Training loss: 5.238409996032715
Validation loss: 5.208976668696249

Epoch: 6| Step: 10
Training loss: 3.873509645462036
Validation loss: 5.205150404284077

Epoch: 6| Step: 11
Training loss: 4.582860469818115
Validation loss: 5.199834833862961

Epoch: 6| Step: 12
Training loss: 5.069791793823242
Validation loss: 5.195709643825408

Epoch: 6| Step: 13
Training loss: 4.4159722328186035
Validation loss: 5.19191111287763

Epoch: 3| Step: 0
Training loss: 4.478006362915039
Validation loss: 5.185992804906702

Epoch: 6| Step: 1
Training loss: 4.856170654296875
Validation loss: 5.183476850550662

Epoch: 6| Step: 2
Training loss: 5.400847434997559
Validation loss: 5.177585699224985

Epoch: 6| Step: 3
Training loss: 5.028812885284424
Validation loss: 5.174497922261556

Epoch: 6| Step: 4
Training loss: 4.974160194396973
Validation loss: 5.168357408174905

Epoch: 6| Step: 5
Training loss: 6.0109357833862305
Validation loss: 5.162090081040577

Epoch: 6| Step: 6
Training loss: 3.7241950035095215
Validation loss: 5.159393741238501

Epoch: 6| Step: 7
Training loss: 4.7349534034729
Validation loss: 5.153434655999624

Epoch: 6| Step: 8
Training loss: 4.634481430053711
Validation loss: 5.147282113311111

Epoch: 6| Step: 9
Training loss: 4.70176887512207
Validation loss: 5.143816486481698

Epoch: 6| Step: 10
Training loss: 5.595010757446289
Validation loss: 5.139363688807333

Epoch: 6| Step: 11
Training loss: 5.191195487976074
Validation loss: 5.133609592273671

Epoch: 6| Step: 12
Training loss: 5.413191318511963
Validation loss: 5.128224839446365

Epoch: 6| Step: 13
Training loss: 4.260886192321777
Validation loss: 5.122770053084179

Epoch: 4| Step: 0
Training loss: 5.312383651733398
Validation loss: 5.119689115913966

Epoch: 6| Step: 1
Training loss: 6.0111188888549805
Validation loss: 5.113651629417173

Epoch: 6| Step: 2
Training loss: 5.067928791046143
Validation loss: 5.108713775552729

Epoch: 6| Step: 3
Training loss: 5.043736457824707
Validation loss: 5.102432589377126

Epoch: 6| Step: 4
Training loss: 6.114628314971924
Validation loss: 5.096673057925317

Epoch: 6| Step: 5
Training loss: 4.201866149902344
Validation loss: 5.091774161143969

Epoch: 6| Step: 6
Training loss: 3.825368642807007
Validation loss: 5.0838691188443095

Epoch: 6| Step: 7
Training loss: 3.968442916870117
Validation loss: 5.081565149368778

Epoch: 6| Step: 8
Training loss: 3.781942844390869
Validation loss: 5.076256352086221

Epoch: 6| Step: 9
Training loss: 3.864196300506592
Validation loss: 5.069679265381188

Epoch: 6| Step: 10
Training loss: 5.366232872009277
Validation loss: 5.066212956623365

Epoch: 6| Step: 11
Training loss: 5.85815954208374
Validation loss: 5.0597639288953555

Epoch: 6| Step: 12
Training loss: 4.2946858406066895
Validation loss: 5.054013400949458

Epoch: 6| Step: 13
Training loss: 6.150790691375732
Validation loss: 5.048039236376362

Epoch: 5| Step: 0
Training loss: 4.64003324508667
Validation loss: 5.040810138948502

Epoch: 6| Step: 1
Training loss: 4.140659332275391
Validation loss: 5.035468327101841

Epoch: 6| Step: 2
Training loss: 5.453041076660156
Validation loss: 5.030485414689587

Epoch: 6| Step: 3
Training loss: 4.576044082641602
Validation loss: 5.020949348326652

Epoch: 6| Step: 4
Training loss: 5.200559616088867
Validation loss: 5.018260561009889

Epoch: 6| Step: 5
Training loss: 5.246212482452393
Validation loss: 5.013278202344012

Epoch: 6| Step: 6
Training loss: 5.582512855529785
Validation loss: 5.006316379834247

Epoch: 6| Step: 7
Training loss: 5.299228668212891
Validation loss: 4.998789859074418

Epoch: 6| Step: 8
Training loss: 4.338726997375488
Validation loss: 4.992347158411498

Epoch: 6| Step: 9
Training loss: 5.881704807281494
Validation loss: 4.98712989335419

Epoch: 6| Step: 10
Training loss: 4.929008483886719
Validation loss: 4.982526994520618

Epoch: 6| Step: 11
Training loss: 3.281585454940796
Validation loss: 4.975996991639496

Epoch: 6| Step: 12
Training loss: 4.193071365356445
Validation loss: 4.96695186245826

Epoch: 6| Step: 13
Training loss: 4.028757095336914
Validation loss: 4.962010691242833

Epoch: 6| Step: 0
Training loss: 3.637133836746216
Validation loss: 4.953863759194651

Epoch: 6| Step: 1
Training loss: 4.941221237182617
Validation loss: 4.94501866063764

Epoch: 6| Step: 2
Training loss: 4.6973724365234375
Validation loss: 4.941161314646403

Epoch: 6| Step: 3
Training loss: 4.634390354156494
Validation loss: 4.935153156198481

Epoch: 6| Step: 4
Training loss: 5.736140251159668
Validation loss: 4.926695500650713

Epoch: 6| Step: 5
Training loss: 5.141300201416016
Validation loss: 4.919041310587237

Epoch: 6| Step: 6
Training loss: 3.312539577484131
Validation loss: 4.912491506145846

Epoch: 6| Step: 7
Training loss: 5.729730606079102
Validation loss: 4.906118931308869

Epoch: 6| Step: 8
Training loss: 5.104971408843994
Validation loss: 4.900730825239612

Epoch: 6| Step: 9
Training loss: 5.846260070800781
Validation loss: 4.894593361885317

Epoch: 6| Step: 10
Training loss: 3.8133881092071533
Validation loss: 4.885279429856167

Epoch: 6| Step: 11
Training loss: 3.9946017265319824
Validation loss: 4.877121602335284

Epoch: 6| Step: 12
Training loss: 4.3137922286987305
Validation loss: 4.867702289294171

Epoch: 6| Step: 13
Training loss: 5.058919429779053
Validation loss: 4.8620775130487255

Epoch: 7| Step: 0
Training loss: 4.313098907470703
Validation loss: 4.851841680465206

Epoch: 6| Step: 1
Training loss: 5.117701053619385
Validation loss: 4.847615108695082

Epoch: 6| Step: 2
Training loss: 5.196699142456055
Validation loss: 4.839177341871364

Epoch: 6| Step: 3
Training loss: 4.379681587219238
Validation loss: 4.832114527302403

Epoch: 6| Step: 4
Training loss: 3.4403164386749268
Validation loss: 4.827652726122128

Epoch: 6| Step: 5
Training loss: 4.49244499206543
Validation loss: 4.814988797710788

Epoch: 6| Step: 6
Training loss: 5.398165702819824
Validation loss: 4.808687953538792

Epoch: 6| Step: 7
Training loss: 3.8456344604492188
Validation loss: 4.800207840499057

Epoch: 6| Step: 8
Training loss: 3.85471510887146
Validation loss: 4.793320830150317

Epoch: 6| Step: 9
Training loss: 5.253329277038574
Validation loss: 4.785062507916522

Epoch: 6| Step: 10
Training loss: 5.134828567504883
Validation loss: 4.772407265119655

Epoch: 6| Step: 11
Training loss: 5.087721824645996
Validation loss: 4.766438186809581

Epoch: 6| Step: 12
Training loss: 3.8353750705718994
Validation loss: 4.75779196523851

Epoch: 6| Step: 13
Training loss: 5.188301086425781
Validation loss: 4.748564222807525

Epoch: 8| Step: 0
Training loss: 5.478388786315918
Validation loss: 4.739187568746587

Epoch: 6| Step: 1
Training loss: 3.953289031982422
Validation loss: 4.730032482454853

Epoch: 6| Step: 2
Training loss: 4.417484283447266
Validation loss: 4.723734281396353

Epoch: 6| Step: 3
Training loss: 3.686718463897705
Validation loss: 4.713597989851428

Epoch: 6| Step: 4
Training loss: 4.538773536682129
Validation loss: 4.7041627617292505

Epoch: 6| Step: 5
Training loss: 5.586289405822754
Validation loss: 4.696520331085369

Epoch: 6| Step: 6
Training loss: 4.451722621917725
Validation loss: 4.684883184330438

Epoch: 6| Step: 7
Training loss: 3.8972485065460205
Validation loss: 4.678351838101623

Epoch: 6| Step: 8
Training loss: 5.632034778594971
Validation loss: 4.666159486257902

Epoch: 6| Step: 9
Training loss: 3.656729221343994
Validation loss: 4.655789739342146

Epoch: 6| Step: 10
Training loss: 3.9523768424987793
Validation loss: 4.648888803297473

Epoch: 6| Step: 11
Training loss: 4.619668006896973
Validation loss: 4.637616680514428

Epoch: 6| Step: 12
Training loss: 4.724431037902832
Validation loss: 4.625834424008605

Epoch: 6| Step: 13
Training loss: 3.4858601093292236
Validation loss: 4.6184303324709655

Epoch: 9| Step: 0
Training loss: 4.777820587158203
Validation loss: 4.602317156330232

Epoch: 6| Step: 1
Training loss: 3.7346267700195312
Validation loss: 4.593657898646529

Epoch: 6| Step: 2
Training loss: 3.830019235610962
Validation loss: 4.588007957704606

Epoch: 6| Step: 3
Training loss: 4.353908061981201
Validation loss: 4.575157329600344

Epoch: 6| Step: 4
Training loss: 4.295853614807129
Validation loss: 4.561727087984803

Epoch: 6| Step: 5
Training loss: 4.018451690673828
Validation loss: 4.551394462585449

Epoch: 6| Step: 6
Training loss: 4.920651435852051
Validation loss: 4.5448267024050475

Epoch: 6| Step: 7
Training loss: 5.131765365600586
Validation loss: 4.526849767213227

Epoch: 6| Step: 8
Training loss: 5.125244140625
Validation loss: 4.5151150047138175

Epoch: 6| Step: 9
Training loss: 3.4896399974823
Validation loss: 4.506105812647009

Epoch: 6| Step: 10
Training loss: 4.698975086212158
Validation loss: 4.494320602827175

Epoch: 6| Step: 11
Training loss: 4.337610244750977
Validation loss: 4.482214584145495

Epoch: 6| Step: 12
Training loss: 3.8636679649353027
Validation loss: 4.464682886677403

Epoch: 6| Step: 13
Training loss: 3.4799485206604004
Validation loss: 4.453642063243414

Epoch: 10| Step: 0
Training loss: 3.9476585388183594
Validation loss: 4.440310175700854

Epoch: 6| Step: 1
Training loss: 4.172789573669434
Validation loss: 4.436308881287934

Epoch: 6| Step: 2
Training loss: 5.784609794616699
Validation loss: 4.419736380218177

Epoch: 6| Step: 3
Training loss: 4.465438365936279
Validation loss: 4.406485762647403

Epoch: 6| Step: 4
Training loss: 5.177997589111328
Validation loss: 4.393837903135566

Epoch: 6| Step: 5
Training loss: 3.3209915161132812
Validation loss: 4.380836953399002

Epoch: 6| Step: 6
Training loss: 3.990494728088379
Validation loss: 4.370031087629257

Epoch: 6| Step: 7
Training loss: 4.20981502532959
Validation loss: 4.353122434308452

Epoch: 6| Step: 8
Training loss: 4.614348411560059
Validation loss: 4.344854006203272

Epoch: 6| Step: 9
Training loss: 4.085807800292969
Validation loss: 4.3346542850617436

Epoch: 6| Step: 10
Training loss: 4.749763488769531
Validation loss: 4.3148915818942495

Epoch: 6| Step: 11
Training loss: 2.7884764671325684
Validation loss: 4.297933875873524

Epoch: 6| Step: 12
Training loss: 3.28076171875
Validation loss: 4.283622239225654

Epoch: 6| Step: 13
Training loss: 2.9826884269714355
Validation loss: 4.27596906436387

Epoch: 11| Step: 0
Training loss: 4.942708492279053
Validation loss: 4.259321135859335

Epoch: 6| Step: 1
Training loss: 3.2752232551574707
Validation loss: 4.2437594167647825

Epoch: 6| Step: 2
Training loss: 5.207597732543945
Validation loss: 4.2323813694779595

Epoch: 6| Step: 3
Training loss: 4.97186279296875
Validation loss: 4.213213961611512

Epoch: 6| Step: 4
Training loss: 4.050239086151123
Validation loss: 4.206471258594144

Epoch: 6| Step: 5
Training loss: 4.2112836837768555
Validation loss: 4.192408915488951

Epoch: 6| Step: 6
Training loss: 2.7638051509857178
Validation loss: 4.1735053934076785

Epoch: 6| Step: 7
Training loss: 3.7525458335876465
Validation loss: 4.160626367856097

Epoch: 6| Step: 8
Training loss: 3.3136401176452637
Validation loss: 4.139596046939973

Epoch: 6| Step: 9
Training loss: 3.317554473876953
Validation loss: 4.128901548283075

Epoch: 6| Step: 10
Training loss: 4.1875319480896
Validation loss: 4.11651276516658

Epoch: 6| Step: 11
Training loss: 4.0043559074401855
Validation loss: 4.098677958211591

Epoch: 6| Step: 12
Training loss: 3.992311477661133
Validation loss: 4.08175358721005

Epoch: 6| Step: 13
Training loss: 3.464498519897461
Validation loss: 4.0578892102805515

Epoch: 12| Step: 0
Training loss: 4.145553112030029
Validation loss: 4.051146448299449

Epoch: 6| Step: 1
Training loss: 4.3455986976623535
Validation loss: 4.0386018394142065

Epoch: 6| Step: 2
Training loss: 3.3844926357269287
Validation loss: 4.016986636705296

Epoch: 6| Step: 3
Training loss: 4.398429870605469
Validation loss: 4.005469706750685

Epoch: 6| Step: 4
Training loss: 3.481632709503174
Validation loss: 3.993720377645185

Epoch: 6| Step: 5
Training loss: 4.333596229553223
Validation loss: 3.971999029959402

Epoch: 6| Step: 6
Training loss: 4.580699920654297
Validation loss: 3.958450017436858

Epoch: 6| Step: 7
Training loss: 2.6873779296875
Validation loss: 3.9466506076115433

Epoch: 6| Step: 8
Training loss: 3.9575047492980957
Validation loss: 3.9291773560226604

Epoch: 6| Step: 9
Training loss: 4.652782917022705
Validation loss: 3.906661182321528

Epoch: 6| Step: 10
Training loss: 3.951982259750366
Validation loss: 3.8987979632551952

Epoch: 6| Step: 11
Training loss: 2.823514461517334
Validation loss: 3.872456324997769

Epoch: 6| Step: 12
Training loss: 2.879027843475342
Validation loss: 3.8638604661469818

Epoch: 6| Step: 13
Training loss: 3.2593958377838135
Validation loss: 3.8430208595850135

Epoch: 13| Step: 0
Training loss: 2.970646381378174
Validation loss: 3.8285970175138084

Epoch: 6| Step: 1
Training loss: 3.071964740753174
Validation loss: 3.8199055066672702

Epoch: 6| Step: 2
Training loss: 5.513362407684326
Validation loss: 3.7928775049025014

Epoch: 6| Step: 3
Training loss: 3.050863027572632
Validation loss: 3.7799110566416094

Epoch: 6| Step: 4
Training loss: 4.165719509124756
Validation loss: 3.7661682764689126

Epoch: 6| Step: 5
Training loss: 4.38238000869751
Validation loss: 3.7403333161466863

Epoch: 6| Step: 6
Training loss: 3.3868935108184814
Validation loss: 3.730638709119571

Epoch: 6| Step: 7
Training loss: 3.1793642044067383
Validation loss: 3.7073320778467322

Epoch: 6| Step: 8
Training loss: 3.3739562034606934
Validation loss: 3.6925584167562504

Epoch: 6| Step: 9
Training loss: 3.7575395107269287
Validation loss: 3.6727525290622505

Epoch: 6| Step: 10
Training loss: 3.4273176193237305
Validation loss: 3.6608863902348343

Epoch: 6| Step: 11
Training loss: 3.34748911857605
Validation loss: 3.6430268133840253

Epoch: 6| Step: 12
Training loss: 3.1660594940185547
Validation loss: 3.625822636388963

Epoch: 6| Step: 13
Training loss: 3.6039018630981445
Validation loss: 3.610111439099876

Epoch: 14| Step: 0
Training loss: 2.7912333011627197
Validation loss: 3.5931704172524075

Epoch: 6| Step: 1
Training loss: 4.186091423034668
Validation loss: 3.5747239000053814

Epoch: 6| Step: 2
Training loss: 3.139542818069458
Validation loss: 3.5566884138250865

Epoch: 6| Step: 3
Training loss: 3.9648678302764893
Validation loss: 3.538333608258155

Epoch: 6| Step: 4
Training loss: 3.4490885734558105
Validation loss: 3.516798396264353

Epoch: 6| Step: 5
Training loss: 3.0637717247009277
Validation loss: 3.5046937696395384

Epoch: 6| Step: 6
Training loss: 3.6998794078826904
Validation loss: 3.4877660889779367

Epoch: 6| Step: 7
Training loss: 3.078913688659668
Validation loss: 3.467461960290068

Epoch: 6| Step: 8
Training loss: 3.6663966178894043
Validation loss: 3.4438852187125915

Epoch: 6| Step: 9
Training loss: 3.297478199005127
Validation loss: 3.4333384113927043

Epoch: 6| Step: 10
Training loss: 3.3347678184509277
Validation loss: 3.405570658304358

Epoch: 6| Step: 11
Training loss: 3.775435209274292
Validation loss: 3.3865296686849287

Epoch: 6| Step: 12
Training loss: 3.0867583751678467
Validation loss: 3.3740696266133297

Epoch: 6| Step: 13
Training loss: 2.536137580871582
Validation loss: 3.349734060225948

Epoch: 15| Step: 0
Training loss: 4.167572021484375
Validation loss: 3.3289088741425545

Epoch: 6| Step: 1
Training loss: 4.03285026550293
Validation loss: 3.3080198482800554

Epoch: 6| Step: 2
Training loss: 3.019693613052368
Validation loss: 3.297035660794986

Epoch: 6| Step: 3
Training loss: 3.4785587787628174
Validation loss: 3.2744828859965005

Epoch: 6| Step: 4
Training loss: 3.1082990169525146
Validation loss: 3.2442436525898595

Epoch: 6| Step: 5
Training loss: 3.0116310119628906
Validation loss: 3.2227105197086128

Epoch: 6| Step: 6
Training loss: 2.5531649589538574
Validation loss: 3.211391423338203

Epoch: 6| Step: 7
Training loss: 4.468031883239746
Validation loss: 3.1783562244907504

Epoch: 6| Step: 8
Training loss: 2.594428777694702
Validation loss: 3.1623421945879535

Epoch: 6| Step: 9
Training loss: 3.0556740760803223
Validation loss: 3.1312469205548688

Epoch: 6| Step: 10
Training loss: 2.7005650997161865
Validation loss: 3.1115365130926973

Epoch: 6| Step: 11
Training loss: 2.3980839252471924
Validation loss: 3.100566153885216

Epoch: 6| Step: 12
Training loss: 3.1183042526245117
Validation loss: 3.0785218874613443

Epoch: 6| Step: 13
Training loss: 2.486025094985962
Validation loss: 3.0537982525364047

Epoch: 16| Step: 0
Training loss: 2.389451503753662
Validation loss: 3.0392529092809206

Epoch: 6| Step: 1
Training loss: 3.4785609245300293
Validation loss: 3.0289518448614303

Epoch: 6| Step: 2
Training loss: 3.2238283157348633
Validation loss: 2.9850209810400523

Epoch: 6| Step: 3
Training loss: 2.3426175117492676
Validation loss: 2.9760188133485856

Epoch: 6| Step: 4
Training loss: 3.4909276962280273
Validation loss: 2.9506900874517297

Epoch: 6| Step: 5
Training loss: 3.625999689102173
Validation loss: 2.9417550768903507

Epoch: 6| Step: 6
Training loss: 3.1086013317108154
Validation loss: 2.9083873020705355

Epoch: 6| Step: 7
Training loss: 3.72025203704834
Validation loss: 2.900539034156389

Epoch: 6| Step: 8
Training loss: 2.86720609664917
Validation loss: 2.8850006262461343

Epoch: 6| Step: 9
Training loss: 2.8366446495056152
Validation loss: 2.8557506325424358

Epoch: 6| Step: 10
Training loss: 3.1187374591827393
Validation loss: 2.8271615095036005

Epoch: 6| Step: 11
Training loss: 2.4665920734405518
Validation loss: 2.8047510270149476

Epoch: 6| Step: 12
Training loss: 2.455227851867676
Validation loss: 2.788895196812127

Epoch: 6| Step: 13
Training loss: 2.5034899711608887
Validation loss: 2.774837023468428

Epoch: 17| Step: 0
Training loss: 2.472557544708252
Validation loss: 2.757802371055849

Epoch: 6| Step: 1
Training loss: 3.6573996543884277
Validation loss: 2.7501255132818736

Epoch: 6| Step: 2
Training loss: 3.239633560180664
Validation loss: 2.7273878641025995

Epoch: 6| Step: 3
Training loss: 3.211171865463257
Validation loss: 2.7063338090014715

Epoch: 6| Step: 4
Training loss: 2.35461163520813
Validation loss: 2.713300456282913

Epoch: 6| Step: 5
Training loss: 2.92375111579895
Validation loss: 2.6733997842316986

Epoch: 6| Step: 6
Training loss: 2.9422740936279297
Validation loss: 2.6643166875326507

Epoch: 6| Step: 7
Training loss: 2.4306271076202393
Validation loss: 2.648877792460944

Epoch: 6| Step: 8
Training loss: 2.547475814819336
Validation loss: 2.6306155138118292

Epoch: 6| Step: 9
Training loss: 2.565992832183838
Validation loss: 2.6212716205145723

Epoch: 6| Step: 10
Training loss: 3.2443501949310303
Validation loss: 2.616882185782156

Epoch: 6| Step: 11
Training loss: 2.5215625762939453
Validation loss: 2.5818447989802205

Epoch: 6| Step: 12
Training loss: 2.936074733734131
Validation loss: 2.568704343611194

Epoch: 6| Step: 13
Training loss: 2.102240562438965
Validation loss: 2.5734475581876692

Epoch: 18| Step: 0
Training loss: 1.6955853700637817
Validation loss: 2.5538533938828336

Epoch: 6| Step: 1
Training loss: 2.447908401489258
Validation loss: 2.5327714540625132

Epoch: 6| Step: 2
Training loss: 2.975200653076172
Validation loss: 2.524468534736223

Epoch: 6| Step: 3
Training loss: 3.3432912826538086
Validation loss: 2.514049999175533

Epoch: 6| Step: 4
Training loss: 2.6628048419952393
Validation loss: 2.5070192557509228

Epoch: 6| Step: 5
Training loss: 2.94814395904541
Validation loss: 2.4934565200600574

Epoch: 6| Step: 6
Training loss: 2.7069196701049805
Validation loss: 2.475985260419948

Epoch: 6| Step: 7
Training loss: 2.3812127113342285
Validation loss: 2.4658663503585325

Epoch: 6| Step: 8
Training loss: 2.5509910583496094
Validation loss: 2.4531202213738554

Epoch: 6| Step: 9
Training loss: 3.051424980163574
Validation loss: 2.4404157489858647

Epoch: 6| Step: 10
Training loss: 3.232283592224121
Validation loss: 2.4155708307861

Epoch: 6| Step: 11
Training loss: 2.2189366817474365
Validation loss: 2.391984478119881

Epoch: 6| Step: 12
Training loss: 2.4615087509155273
Validation loss: 2.3887155491818666

Epoch: 6| Step: 13
Training loss: 2.94937801361084
Validation loss: 2.3763375205378376

Epoch: 19| Step: 0
Training loss: 3.0499343872070312
Validation loss: 2.388754258873642

Epoch: 6| Step: 1
Training loss: 2.767317771911621
Validation loss: 2.3591088966656755

Epoch: 6| Step: 2
Training loss: 2.501232624053955
Validation loss: 2.333323770953763

Epoch: 6| Step: 3
Training loss: 2.372551679611206
Validation loss: 2.325695394187845

Epoch: 6| Step: 4
Training loss: 2.455116033554077
Validation loss: 2.32358726122046

Epoch: 6| Step: 5
Training loss: 2.517397403717041
Validation loss: 2.3003593747333815

Epoch: 6| Step: 6
Training loss: 2.8817601203918457
Validation loss: 2.3090451660976616

Epoch: 6| Step: 7
Training loss: 2.6049559116363525
Validation loss: 2.3047583949181343

Epoch: 6| Step: 8
Training loss: 2.332577705383301
Validation loss: 2.292340237607238

Epoch: 6| Step: 9
Training loss: 2.383582592010498
Validation loss: 2.280519708510368

Epoch: 6| Step: 10
Training loss: 2.5612447261810303
Validation loss: 2.2748524040304203

Epoch: 6| Step: 11
Training loss: 2.761091709136963
Validation loss: 2.27779955761407

Epoch: 6| Step: 12
Training loss: 2.421354293823242
Validation loss: 2.25132611233701

Epoch: 6| Step: 13
Training loss: 1.7337548732757568
Validation loss: 2.2592491155029624

Epoch: 20| Step: 0
Training loss: 2.63932728767395
Validation loss: 2.2497483248351724

Epoch: 6| Step: 1
Training loss: 2.1340322494506836
Validation loss: 2.241293909729168

Epoch: 6| Step: 2
Training loss: 2.8793258666992188
Validation loss: 2.2365421659202984

Epoch: 6| Step: 3
Training loss: 1.970717191696167
Validation loss: 2.2359233620346233

Epoch: 6| Step: 4
Training loss: 2.6732394695281982
Validation loss: 2.2433395821561097

Epoch: 6| Step: 5
Training loss: 2.5797030925750732
Validation loss: 2.2317687926753873

Epoch: 6| Step: 6
Training loss: 1.690172553062439
Validation loss: 2.232216078747985

Epoch: 6| Step: 7
Training loss: 2.626835823059082
Validation loss: 2.2145387177826255

Epoch: 6| Step: 8
Training loss: 2.409520149230957
Validation loss: 2.233894225089781

Epoch: 6| Step: 9
Training loss: 2.3611538410186768
Validation loss: 2.2140765523397796

Epoch: 6| Step: 10
Training loss: 3.4889237880706787
Validation loss: 2.1980228808618363

Epoch: 6| Step: 11
Training loss: 2.8606228828430176
Validation loss: 2.2183929028049594

Epoch: 6| Step: 12
Training loss: 2.4166369438171387
Validation loss: 2.2272830676007014

Epoch: 6| Step: 13
Training loss: 2.3659305572509766
Validation loss: 2.200953460508777

Epoch: 21| Step: 0
Training loss: 2.2017030715942383
Validation loss: 2.213332978628015

Epoch: 6| Step: 1
Training loss: 2.3159255981445312
Validation loss: 2.1806524056260304

Epoch: 6| Step: 2
Training loss: 1.9573140144348145
Validation loss: 2.1843139228000434

Epoch: 6| Step: 3
Training loss: 2.1397764682769775
Validation loss: 2.1979921684470227

Epoch: 6| Step: 4
Training loss: 2.215198516845703
Validation loss: 2.1726594637799006

Epoch: 6| Step: 5
Training loss: 3.0764589309692383
Validation loss: 2.188092612451123

Epoch: 6| Step: 6
Training loss: 2.843177080154419
Validation loss: 2.1697144815998692

Epoch: 6| Step: 7
Training loss: 2.134603977203369
Validation loss: 2.1894736289978027

Epoch: 6| Step: 8
Training loss: 2.9456653594970703
Validation loss: 2.1457893540782313

Epoch: 6| Step: 9
Training loss: 2.841578722000122
Validation loss: 2.1681590503261936

Epoch: 6| Step: 10
Training loss: 2.893557548522949
Validation loss: 2.161864778046967

Epoch: 6| Step: 11
Training loss: 2.4250688552856445
Validation loss: 2.1579699747024046

Epoch: 6| Step: 12
Training loss: 2.515477180480957
Validation loss: 2.1390251267340874

Epoch: 6| Step: 13
Training loss: 2.0199930667877197
Validation loss: 2.165703594043691

Epoch: 22| Step: 0
Training loss: 1.2960331439971924
Validation loss: 2.16125125141554

Epoch: 6| Step: 1
Training loss: 2.9815053939819336
Validation loss: 2.1696347164851364

Epoch: 6| Step: 2
Training loss: 1.9715170860290527
Validation loss: 2.1456801096598306

Epoch: 6| Step: 3
Training loss: 2.821377754211426
Validation loss: 2.144058829994612

Epoch: 6| Step: 4
Training loss: 3.0808639526367188
Validation loss: 2.1738479214329876

Epoch: 6| Step: 5
Training loss: 2.5097551345825195
Validation loss: 2.16221272817222

Epoch: 6| Step: 6
Training loss: 2.391225814819336
Validation loss: 2.1706653846207487

Epoch: 6| Step: 7
Training loss: 2.5359067916870117
Validation loss: 2.1684963036608953

Epoch: 6| Step: 8
Training loss: 2.0132434368133545
Validation loss: 2.1595115097620154

Epoch: 6| Step: 9
Training loss: 2.7578835487365723
Validation loss: 2.137460608636179

Epoch: 6| Step: 10
Training loss: 2.8113975524902344
Validation loss: 2.143192366887164

Epoch: 6| Step: 11
Training loss: 2.822016477584839
Validation loss: 2.139340169968144

Epoch: 6| Step: 12
Training loss: 2.551849365234375
Validation loss: 2.1500047817025134

Epoch: 6| Step: 13
Training loss: 2.191115140914917
Validation loss: 2.141473782959805

Epoch: 23| Step: 0
Training loss: 2.3512802124023438
Validation loss: 2.144370778914421

Epoch: 6| Step: 1
Training loss: 1.9101225137710571
Validation loss: 2.15472577464196

Epoch: 6| Step: 2
Training loss: 2.713052272796631
Validation loss: 2.1396820006832

Epoch: 6| Step: 3
Training loss: 2.4626080989837646
Validation loss: 2.150543120599562

Epoch: 6| Step: 4
Training loss: 1.9174039363861084
Validation loss: 2.1281618943778415

Epoch: 6| Step: 5
Training loss: 2.9895167350769043
Validation loss: 2.100820097872006

Epoch: 6| Step: 6
Training loss: 2.309926748275757
Validation loss: 2.120082450169389

Epoch: 6| Step: 7
Training loss: 3.3611338138580322
Validation loss: 2.140727291824997

Epoch: 6| Step: 8
Training loss: 2.926271438598633
Validation loss: 2.1363847819707726

Epoch: 6| Step: 9
Training loss: 2.8223752975463867
Validation loss: 2.1239265139384935

Epoch: 6| Step: 10
Training loss: 1.503974437713623
Validation loss: 2.101732072009835

Epoch: 6| Step: 11
Training loss: 2.7492241859436035
Validation loss: 2.1233625527351134

Epoch: 6| Step: 12
Training loss: 2.323660373687744
Validation loss: 2.1265235895751626

Epoch: 6| Step: 13
Training loss: 2.3819539546966553
Validation loss: 2.13171281737666

Epoch: 24| Step: 0
Training loss: 2.7517495155334473
Validation loss: 2.113470523588119

Epoch: 6| Step: 1
Training loss: 2.5347495079040527
Validation loss: 2.1332063854381604

Epoch: 6| Step: 2
Training loss: 2.5727572441101074
Validation loss: 2.1299933310477965

Epoch: 6| Step: 3
Training loss: 2.4186768531799316
Validation loss: 2.1104088034681094

Epoch: 6| Step: 4
Training loss: 1.6993944644927979
Validation loss: 2.1267531956395795

Epoch: 6| Step: 5
Training loss: 2.875638246536255
Validation loss: 2.115804338967928

Epoch: 6| Step: 6
Training loss: 2.072802782058716
Validation loss: 2.1044499566478114

Epoch: 6| Step: 7
Training loss: 2.561162233352661
Validation loss: 2.10594739067939

Epoch: 6| Step: 8
Training loss: 3.185622215270996
Validation loss: 2.1230445728507092

Epoch: 6| Step: 9
Training loss: 2.641207695007324
Validation loss: 2.0946219172528995

Epoch: 6| Step: 10
Training loss: 2.3909566402435303
Validation loss: 2.135887863815472

Epoch: 6| Step: 11
Training loss: 2.6353964805603027
Validation loss: 2.1156872626273864

Epoch: 6| Step: 12
Training loss: 2.326995372772217
Validation loss: 2.112312659140556

Epoch: 6| Step: 13
Training loss: 1.868837833404541
Validation loss: 2.1170432862415107

Epoch: 25| Step: 0
Training loss: 2.264615058898926
Validation loss: 2.1187945027505197

Epoch: 6| Step: 1
Training loss: 2.1942548751831055
Validation loss: 2.113936680619435

Epoch: 6| Step: 2
Training loss: 2.1892032623291016
Validation loss: 2.0993057386849516

Epoch: 6| Step: 3
Training loss: 1.956444263458252
Validation loss: 2.1000364160024994

Epoch: 6| Step: 4
Training loss: 2.8691720962524414
Validation loss: 2.0982707636330717

Epoch: 6| Step: 5
Training loss: 3.1584978103637695
Validation loss: 2.1051116374231156

Epoch: 6| Step: 6
Training loss: 2.3108391761779785
Validation loss: 2.117977903735253

Epoch: 6| Step: 7
Training loss: 2.7140276432037354
Validation loss: 2.108610136534578

Epoch: 6| Step: 8
Training loss: 2.9360525608062744
Validation loss: 2.1064176854266914

Epoch: 6| Step: 9
Training loss: 1.972941279411316
Validation loss: 2.1190971841094313

Epoch: 6| Step: 10
Training loss: 2.1516170501708984
Validation loss: 2.1155780746090795

Epoch: 6| Step: 11
Training loss: 2.9322803020477295
Validation loss: 2.105607650613272

Epoch: 6| Step: 12
Training loss: 2.2891619205474854
Validation loss: 2.13233878022881

Epoch: 6| Step: 13
Training loss: 3.1536571979522705
Validation loss: 2.0924233134074877

Epoch: 26| Step: 0
Training loss: 2.240995407104492
Validation loss: 2.1132285825667845

Epoch: 6| Step: 1
Training loss: 2.7270867824554443
Validation loss: 2.0939696886206187

Epoch: 6| Step: 2
Training loss: 3.100740432739258
Validation loss: 2.0851925009040424

Epoch: 6| Step: 3
Training loss: 2.230252981185913
Validation loss: 2.088989752595143

Epoch: 6| Step: 4
Training loss: 2.7962937355041504
Validation loss: 2.1212338221970426

Epoch: 6| Step: 5
Training loss: 2.415778398513794
Validation loss: 2.110770642116506

Epoch: 6| Step: 6
Training loss: 2.2299840450286865
Validation loss: 2.1101401006021807

Epoch: 6| Step: 7
Training loss: 2.4241387844085693
Validation loss: 2.0917779527684695

Epoch: 6| Step: 8
Training loss: 2.1015918254852295
Validation loss: 2.1058134622471307

Epoch: 6| Step: 9
Training loss: 2.4424166679382324
Validation loss: 2.10752341183283

Epoch: 6| Step: 10
Training loss: 2.4382898807525635
Validation loss: 2.0992609839285574

Epoch: 6| Step: 11
Training loss: 2.419403553009033
Validation loss: 2.107939948317825

Epoch: 6| Step: 12
Training loss: 2.5780763626098633
Validation loss: 2.1093104654742825

Epoch: 6| Step: 13
Training loss: 2.4418716430664062
Validation loss: 2.1023162795651342

Epoch: 27| Step: 0
Training loss: 2.9515814781188965
Validation loss: 2.1200808504576325

Epoch: 6| Step: 1
Training loss: 2.119006633758545
Validation loss: 2.110923279998123

Epoch: 6| Step: 2
Training loss: 2.2943100929260254
Validation loss: 2.1115422210385724

Epoch: 6| Step: 3
Training loss: 2.3555455207824707
Validation loss: 2.1028563668650966

Epoch: 6| Step: 4
Training loss: 2.078415870666504
Validation loss: 2.1075576454080562

Epoch: 6| Step: 5
Training loss: 2.571526050567627
Validation loss: 2.0926505878407466

Epoch: 6| Step: 6
Training loss: 2.44968318939209
Validation loss: 2.103171105025917

Epoch: 6| Step: 7
Training loss: 2.5122227668762207
Validation loss: 2.0970736985565512

Epoch: 6| Step: 8
Training loss: 2.1504404544830322
Validation loss: 2.1154906506179483

Epoch: 6| Step: 9
Training loss: 1.795590877532959
Validation loss: 2.09143723980073

Epoch: 6| Step: 10
Training loss: 2.5913753509521484
Validation loss: 2.108108884544783

Epoch: 6| Step: 11
Training loss: 3.022876739501953
Validation loss: 2.0945177590975197

Epoch: 6| Step: 12
Training loss: 3.083408832550049
Validation loss: 2.1026456150957333

Epoch: 6| Step: 13
Training loss: 2.4390902519226074
Validation loss: 2.09226962443321

Epoch: 28| Step: 0
Training loss: 2.816880702972412
Validation loss: 2.0964606397895404

Epoch: 6| Step: 1
Training loss: 2.657058000564575
Validation loss: 2.1024454921804447

Epoch: 6| Step: 2
Training loss: 3.0003767013549805
Validation loss: 2.10623360449268

Epoch: 6| Step: 3
Training loss: 2.5105087757110596
Validation loss: 2.1115132890721804

Epoch: 6| Step: 4
Training loss: 3.254554033279419
Validation loss: 2.1151838071884645

Epoch: 6| Step: 5
Training loss: 1.6388633251190186
Validation loss: 2.084983474464827

Epoch: 6| Step: 6
Training loss: 2.583137035369873
Validation loss: 2.08506868731591

Epoch: 6| Step: 7
Training loss: 2.0105977058410645
Validation loss: 2.089821050243993

Epoch: 6| Step: 8
Training loss: 1.5718554258346558
Validation loss: 2.0895742036963023

Epoch: 6| Step: 9
Training loss: 2.4873311519622803
Validation loss: 2.074004424515591

Epoch: 6| Step: 10
Training loss: 2.466052532196045
Validation loss: 2.1206267303036106

Epoch: 6| Step: 11
Training loss: 2.279348850250244
Validation loss: 2.1100497066333728

Epoch: 6| Step: 12
Training loss: 3.2503812313079834
Validation loss: 2.0940742569585002

Epoch: 6| Step: 13
Training loss: 1.356720209121704
Validation loss: 2.0784124289789507

Epoch: 29| Step: 0
Training loss: 1.7641499042510986
Validation loss: 2.1093028527434154

Epoch: 6| Step: 1
Training loss: 2.980922222137451
Validation loss: 2.0930118304426952

Epoch: 6| Step: 2
Training loss: 1.998924970626831
Validation loss: 2.0871579018972253

Epoch: 6| Step: 3
Training loss: 2.304086208343506
Validation loss: 2.0944932712021695

Epoch: 6| Step: 4
Training loss: 1.793394923210144
Validation loss: 2.08089118747301

Epoch: 6| Step: 5
Training loss: 2.4877231121063232
Validation loss: 2.093412494146696

Epoch: 6| Step: 6
Training loss: 2.5635414123535156
Validation loss: 2.09634022174343

Epoch: 6| Step: 7
Training loss: 2.7218308448791504
Validation loss: 2.092059948111093

Epoch: 6| Step: 8
Training loss: 2.516415596008301
Validation loss: 2.07691087261323

Epoch: 6| Step: 9
Training loss: 2.2583353519439697
Validation loss: 2.089791368412715

Epoch: 6| Step: 10
Training loss: 2.816326141357422
Validation loss: 2.0945226876966414

Epoch: 6| Step: 11
Training loss: 2.7922589778900146
Validation loss: 2.0813252695145144

Epoch: 6| Step: 12
Training loss: 2.5935349464416504
Validation loss: 2.0998322476622877

Epoch: 6| Step: 13
Training loss: 2.758419990539551
Validation loss: 2.102688950877036

Epoch: 30| Step: 0
Training loss: 2.4056575298309326
Validation loss: 2.063800811767578

Epoch: 6| Step: 1
Training loss: 2.7589826583862305
Validation loss: 2.0952814599519134

Epoch: 6| Step: 2
Training loss: 2.6359505653381348
Validation loss: 2.089766836935474

Epoch: 6| Step: 3
Training loss: 2.195883274078369
Validation loss: 2.0736511535541986

Epoch: 6| Step: 4
Training loss: 2.0508265495300293
Validation loss: 2.1038731874958163

Epoch: 6| Step: 5
Training loss: 2.22945499420166
Validation loss: 2.073348652931952

Epoch: 6| Step: 6
Training loss: 2.5746798515319824
Validation loss: 2.1061854362487793

Epoch: 6| Step: 7
Training loss: 2.8691325187683105
Validation loss: 2.0903802200030257

Epoch: 6| Step: 8
Training loss: 2.6388492584228516
Validation loss: 2.097396924931516

Epoch: 6| Step: 9
Training loss: 2.3672962188720703
Validation loss: 2.0796421343280422

Epoch: 6| Step: 10
Training loss: 2.6584150791168213
Validation loss: 2.0772117658327987

Epoch: 6| Step: 11
Training loss: 2.336790084838867
Validation loss: 2.101393368936354

Epoch: 6| Step: 12
Training loss: 2.310236692428589
Validation loss: 2.110863616389613

Epoch: 6| Step: 13
Training loss: 2.054348945617676
Validation loss: 2.0870209945145475

Epoch: 31| Step: 0
Training loss: 3.124818801879883
Validation loss: 2.071461805733301

Epoch: 6| Step: 1
Training loss: 2.2728004455566406
Validation loss: 2.113961012132706

Epoch: 6| Step: 2
Training loss: 2.422968864440918
Validation loss: 2.0749698787607174

Epoch: 6| Step: 3
Training loss: 2.113406181335449
Validation loss: 2.0869516864899667

Epoch: 6| Step: 4
Training loss: 2.291628837585449
Validation loss: 2.096484920029999

Epoch: 6| Step: 5
Training loss: 3.2755885124206543
Validation loss: 2.0817922738290604

Epoch: 6| Step: 6
Training loss: 2.872411012649536
Validation loss: 2.0713121480839227

Epoch: 6| Step: 7
Training loss: 2.0810835361480713
Validation loss: 2.065455669997841

Epoch: 6| Step: 8
Training loss: 2.373972177505493
Validation loss: 2.076797826315767

Epoch: 6| Step: 9
Training loss: 2.489086151123047
Validation loss: 2.094632221806434

Epoch: 6| Step: 10
Training loss: 2.8363876342773438
Validation loss: 2.05990477659369

Epoch: 6| Step: 11
Training loss: 2.236281394958496
Validation loss: 2.1094785018633773

Epoch: 6| Step: 12
Training loss: 1.7699263095855713
Validation loss: 2.105912290593629

Epoch: 6| Step: 13
Training loss: 1.6814632415771484
Validation loss: 2.0948785069168254

Epoch: 32| Step: 0
Training loss: 2.7631921768188477
Validation loss: 2.0703233134362007

Epoch: 6| Step: 1
Training loss: 2.1909031867980957
Validation loss: 2.0810166917821413

Epoch: 6| Step: 2
Training loss: 2.6619272232055664
Validation loss: 2.093356059443566

Epoch: 6| Step: 3
Training loss: 2.82307505607605
Validation loss: 2.0931727552926667

Epoch: 6| Step: 4
Training loss: 2.441412925720215
Validation loss: 2.084236942311769

Epoch: 6| Step: 5
Training loss: 2.5356948375701904
Validation loss: 2.0851522312369397

Epoch: 6| Step: 6
Training loss: 2.3253655433654785
Validation loss: 2.1010078409666657

Epoch: 6| Step: 7
Training loss: 2.676278829574585
Validation loss: 2.08709337506243

Epoch: 6| Step: 8
Training loss: 2.1558022499084473
Validation loss: 2.089961846669515

Epoch: 6| Step: 9
Training loss: 2.497790575027466
Validation loss: 2.09518967264442

Epoch: 6| Step: 10
Training loss: 2.448221206665039
Validation loss: 2.100276656048272

Epoch: 6| Step: 11
Training loss: 2.1875052452087402
Validation loss: 2.0796502444051925

Epoch: 6| Step: 12
Training loss: 2.391237497329712
Validation loss: 2.0940078343114545

Epoch: 6| Step: 13
Training loss: 1.5048480033874512
Validation loss: 2.094992232579057

Epoch: 33| Step: 0
Training loss: 1.8445411920547485
Validation loss: 2.062113283782877

Epoch: 6| Step: 1
Training loss: 2.6332225799560547
Validation loss: 2.0778000072766374

Epoch: 6| Step: 2
Training loss: 2.7381105422973633
Validation loss: 2.109887978082062

Epoch: 6| Step: 3
Training loss: 2.1830251216888428
Validation loss: 2.0869556421874673

Epoch: 6| Step: 4
Training loss: 2.361870050430298
Validation loss: 2.080181401263001

Epoch: 6| Step: 5
Training loss: 1.7587964534759521
Validation loss: 2.092431242747973

Epoch: 6| Step: 6
Training loss: 2.4261937141418457
Validation loss: 2.078305308536817

Epoch: 6| Step: 7
Training loss: 2.520648956298828
Validation loss: 2.067856729671519

Epoch: 6| Step: 8
Training loss: 2.454073667526245
Validation loss: 2.0635880372857534

Epoch: 6| Step: 9
Training loss: 2.996166706085205
Validation loss: 2.0904206575885897

Epoch: 6| Step: 10
Training loss: 2.481494903564453
Validation loss: 2.069259807627688

Epoch: 6| Step: 11
Training loss: 2.594494581222534
Validation loss: 2.046553634828137

Epoch: 6| Step: 12
Training loss: 1.7599830627441406
Validation loss: 2.0783013028483235

Epoch: 6| Step: 13
Training loss: 3.8817715644836426
Validation loss: 2.075995268360261

Epoch: 34| Step: 0
Training loss: 2.388309955596924
Validation loss: 2.0678748084652807

Epoch: 6| Step: 1
Training loss: 2.346066474914551
Validation loss: 2.063798978764524

Epoch: 6| Step: 2
Training loss: 2.3325672149658203
Validation loss: 2.0783941899576495

Epoch: 6| Step: 3
Training loss: 2.2858030796051025
Validation loss: 2.0710981610000774

Epoch: 6| Step: 4
Training loss: 2.799563407897949
Validation loss: 2.0592871712100123

Epoch: 6| Step: 5
Training loss: 2.447498321533203
Validation loss: 2.0959732724774267

Epoch: 6| Step: 6
Training loss: 2.49721622467041
Validation loss: 2.091994103565011

Epoch: 6| Step: 7
Training loss: 2.0538291931152344
Validation loss: 2.074110648965323

Epoch: 6| Step: 8
Training loss: 2.379295587539673
Validation loss: 2.1070117142892655

Epoch: 6| Step: 9
Training loss: 2.3286995887756348
Validation loss: 2.072868304867898

Epoch: 6| Step: 10
Training loss: 3.024564027786255
Validation loss: 2.0922782523657686

Epoch: 6| Step: 11
Training loss: 2.896542549133301
Validation loss: 2.109524287203307

Epoch: 6| Step: 12
Training loss: 1.8418669700622559
Validation loss: 2.091238872979277

Epoch: 6| Step: 13
Training loss: 2.3403422832489014
Validation loss: 2.0958334271625807

Epoch: 35| Step: 0
Training loss: 2.098212718963623
Validation loss: 2.0929699918275237

Epoch: 6| Step: 1
Training loss: 2.350374221801758
Validation loss: 2.0878071951609787

Epoch: 6| Step: 2
Training loss: 2.4884636402130127
Validation loss: 2.06018816783864

Epoch: 6| Step: 3
Training loss: 2.5027859210968018
Validation loss: 2.0793558910328853

Epoch: 6| Step: 4
Training loss: 3.5005712509155273
Validation loss: 2.072152678684522

Epoch: 6| Step: 5
Training loss: 2.4135196208953857
Validation loss: 2.0781561584882837

Epoch: 6| Step: 6
Training loss: 2.6009716987609863
Validation loss: 2.077424536469162

Epoch: 6| Step: 7
Training loss: 2.158334732055664
Validation loss: 2.067520033928656

Epoch: 6| Step: 8
Training loss: 3.024411678314209
Validation loss: 2.1062111290552283

Epoch: 6| Step: 9
Training loss: 2.4859580993652344
Validation loss: 2.0706122100994153

Epoch: 6| Step: 10
Training loss: 1.899216651916504
Validation loss: 2.0808571051525813

Epoch: 6| Step: 11
Training loss: 2.376471519470215
Validation loss: 2.080096706267326

Epoch: 6| Step: 12
Training loss: 2.0706188678741455
Validation loss: 2.0832572752429592

Epoch: 6| Step: 13
Training loss: 1.407233715057373
Validation loss: 2.0716680557497087

Epoch: 36| Step: 0
Training loss: 1.7606654167175293
Validation loss: 2.067600183589484

Epoch: 6| Step: 1
Training loss: 2.0756187438964844
Validation loss: 2.0769650231125536

Epoch: 6| Step: 2
Training loss: 1.940870761871338
Validation loss: 2.077606678009033

Epoch: 6| Step: 3
Training loss: 2.1729025840759277
Validation loss: 2.0748499952336794

Epoch: 6| Step: 4
Training loss: 3.1114048957824707
Validation loss: 2.077542389592817

Epoch: 6| Step: 5
Training loss: 1.649709701538086
Validation loss: 2.0727090784298476

Epoch: 6| Step: 6
Training loss: 3.1755807399749756
Validation loss: 2.083774594850438

Epoch: 6| Step: 7
Training loss: 3.083611011505127
Validation loss: 2.0518896887379308

Epoch: 6| Step: 8
Training loss: 2.9795713424682617
Validation loss: 2.0400388599723898

Epoch: 6| Step: 9
Training loss: 2.329768180847168
Validation loss: 2.063151345458082

Epoch: 6| Step: 10
Training loss: 2.9684691429138184
Validation loss: 2.058406631151835

Epoch: 6| Step: 11
Training loss: 1.7217686176300049
Validation loss: 2.0888302467202626

Epoch: 6| Step: 12
Training loss: 2.540743350982666
Validation loss: 2.0587251455553117

Epoch: 6| Step: 13
Training loss: 2.2411153316497803
Validation loss: 2.079309648083102

Epoch: 37| Step: 0
Training loss: 2.8083395957946777
Validation loss: 2.066404534924415

Epoch: 6| Step: 1
Training loss: 1.8321844339370728
Validation loss: 2.0784813306664907

Epoch: 6| Step: 2
Training loss: 1.9591748714447021
Validation loss: 2.058927776992962

Epoch: 6| Step: 3
Training loss: 2.7318921089172363
Validation loss: 2.061257887912053

Epoch: 6| Step: 4
Training loss: 2.378864288330078
Validation loss: 2.0620814574662076

Epoch: 6| Step: 5
Training loss: 3.0263595581054688
Validation loss: 2.0480878583846556

Epoch: 6| Step: 6
Training loss: 2.343430519104004
Validation loss: 2.0439953496379237

Epoch: 6| Step: 7
Training loss: 2.3802695274353027
Validation loss: 2.0493829737427416

Epoch: 6| Step: 8
Training loss: 2.0092873573303223
Validation loss: 2.014984033441031

Epoch: 6| Step: 9
Training loss: 2.388015031814575
Validation loss: 2.051016640919511

Epoch: 6| Step: 10
Training loss: 2.135315179824829
Validation loss: 2.048610500110093

Epoch: 6| Step: 11
Training loss: 2.667680025100708
Validation loss: 2.0489102076458674

Epoch: 6| Step: 12
Training loss: 2.8152997493743896
Validation loss: 2.034218043409368

Epoch: 6| Step: 13
Training loss: 2.8103370666503906
Validation loss: 2.0639961881022297

Epoch: 38| Step: 0
Training loss: 1.8850083351135254
Validation loss: 2.040436493453159

Epoch: 6| Step: 1
Training loss: 2.4118099212646484
Validation loss: 2.0565724885591896

Epoch: 6| Step: 2
Training loss: 2.7858245372772217
Validation loss: 2.052941891454881

Epoch: 6| Step: 3
Training loss: 2.0309572219848633
Validation loss: 2.0560577992470033

Epoch: 6| Step: 4
Training loss: 3.0358967781066895
Validation loss: 2.053897032173731

Epoch: 6| Step: 5
Training loss: 2.5162670612335205
Validation loss: 2.0533918026954896

Epoch: 6| Step: 6
Training loss: 2.57496976852417
Validation loss: 2.0455056236636255

Epoch: 6| Step: 7
Training loss: 1.8870669603347778
Validation loss: 2.0627465555744786

Epoch: 6| Step: 8
Training loss: 2.411341667175293
Validation loss: 2.069157890094224

Epoch: 6| Step: 9
Training loss: 2.845390796661377
Validation loss: 2.0511494554499143

Epoch: 6| Step: 10
Training loss: 2.3920626640319824
Validation loss: 2.06812786030513

Epoch: 6| Step: 11
Training loss: 1.6324446201324463
Validation loss: 2.0715406812647337

Epoch: 6| Step: 12
Training loss: 2.6903038024902344
Validation loss: 2.071521984633579

Epoch: 6| Step: 13
Training loss: 2.8417577743530273
Validation loss: 2.0653489558927474

Epoch: 39| Step: 0
Training loss: 2.142899513244629
Validation loss: 2.0801090399424234

Epoch: 6| Step: 1
Training loss: 2.71134090423584
Validation loss: 2.065517863919658

Epoch: 6| Step: 2
Training loss: 2.098632335662842
Validation loss: 2.048203338858902

Epoch: 6| Step: 3
Training loss: 2.649862289428711
Validation loss: 2.0649027016855057

Epoch: 6| Step: 4
Training loss: 2.8072428703308105
Validation loss: 2.040766505784886

Epoch: 6| Step: 5
Training loss: 2.352968454360962
Validation loss: 2.037964588852339

Epoch: 6| Step: 6
Training loss: 2.950775146484375
Validation loss: 2.0567710861083

Epoch: 6| Step: 7
Training loss: 2.3211474418640137
Validation loss: 2.0487192484640304

Epoch: 6| Step: 8
Training loss: 2.1529622077941895
Validation loss: 2.0520345626338834

Epoch: 6| Step: 9
Training loss: 2.564570426940918
Validation loss: 2.0506178563640964

Epoch: 6| Step: 10
Training loss: 2.3329291343688965
Validation loss: 2.070113680695975

Epoch: 6| Step: 11
Training loss: 1.891687035560608
Validation loss: 2.0751415350103892

Epoch: 6| Step: 12
Training loss: 2.5817277431488037
Validation loss: 2.0800528295578493

Epoch: 6| Step: 13
Training loss: 1.7303787469863892
Validation loss: 2.043548427602296

Epoch: 40| Step: 0
Training loss: 2.527437210083008
Validation loss: 2.0595614807580107

Epoch: 6| Step: 1
Training loss: 2.6210885047912598
Validation loss: 2.0470562237565235

Epoch: 6| Step: 2
Training loss: 2.698413610458374
Validation loss: 2.058770369457942

Epoch: 6| Step: 3
Training loss: 2.3074185848236084
Validation loss: 2.0631340729293

Epoch: 6| Step: 4
Training loss: 2.3452911376953125
Validation loss: 2.0483384939932052

Epoch: 6| Step: 5
Training loss: 1.4913678169250488
Validation loss: 2.072453943631982

Epoch: 6| Step: 6
Training loss: 1.8230587244033813
Validation loss: 2.0524371311228764

Epoch: 6| Step: 7
Training loss: 2.6541025638580322
Validation loss: 2.080359597359934

Epoch: 6| Step: 8
Training loss: 3.405611991882324
Validation loss: 2.0495322647915093

Epoch: 6| Step: 9
Training loss: 2.0367045402526855
Validation loss: 2.0781137635630946

Epoch: 6| Step: 10
Training loss: 2.154872417449951
Validation loss: 2.0222226765847977

Epoch: 6| Step: 11
Training loss: 2.889068365097046
Validation loss: 2.079575769362911

Epoch: 6| Step: 12
Training loss: 2.226536512374878
Validation loss: 2.0789971915624474

Epoch: 6| Step: 13
Training loss: 2.3020641803741455
Validation loss: 2.0774158200910016

Epoch: 41| Step: 0
Training loss: 2.9458138942718506
Validation loss: 2.059253177335185

Epoch: 6| Step: 1
Training loss: 2.0329384803771973
Validation loss: 2.0482855150776524

Epoch: 6| Step: 2
Training loss: 2.0629615783691406
Validation loss: 2.06540600715145

Epoch: 6| Step: 3
Training loss: 3.012591600418091
Validation loss: 2.0467259614698348

Epoch: 6| Step: 4
Training loss: 1.8236066102981567
Validation loss: 2.054681844608758

Epoch: 6| Step: 5
Training loss: 3.032766342163086
Validation loss: 2.042039323878545

Epoch: 6| Step: 6
Training loss: 2.6340465545654297
Validation loss: 2.0551963531842796

Epoch: 6| Step: 7
Training loss: 3.0046377182006836
Validation loss: 2.054401674578267

Epoch: 6| Step: 8
Training loss: 2.968615770339966
Validation loss: 2.0734199811053533

Epoch: 6| Step: 9
Training loss: 2.2490177154541016
Validation loss: 2.0403581562862603

Epoch: 6| Step: 10
Training loss: 2.1422626972198486
Validation loss: 2.0553628501071723

Epoch: 6| Step: 11
Training loss: 2.156670570373535
Validation loss: 2.0517203936012844

Epoch: 6| Step: 12
Training loss: 1.2312180995941162
Validation loss: 2.0420165587497014

Epoch: 6| Step: 13
Training loss: 1.5615458488464355
Validation loss: 2.0437964059973277

Epoch: 42| Step: 0
Training loss: 2.8794612884521484
Validation loss: 2.0436815433604743

Epoch: 6| Step: 1
Training loss: 1.672133207321167
Validation loss: 2.036960527461062

Epoch: 6| Step: 2
Training loss: 2.2420566082000732
Validation loss: 2.0359137827350247

Epoch: 6| Step: 3
Training loss: 1.9288544654846191
Validation loss: 2.0594945876829085

Epoch: 6| Step: 4
Training loss: 2.1547813415527344
Validation loss: 2.077081113733271

Epoch: 6| Step: 5
Training loss: 2.6111278533935547
Validation loss: 2.051287817698653

Epoch: 6| Step: 6
Training loss: 2.886996269226074
Validation loss: 2.044543825170045

Epoch: 6| Step: 7
Training loss: 2.569589614868164
Validation loss: 2.0458061643826064

Epoch: 6| Step: 8
Training loss: 3.234410285949707
Validation loss: 2.040773291741648

Epoch: 6| Step: 9
Training loss: 2.5739526748657227
Validation loss: 2.0389312133994153

Epoch: 6| Step: 10
Training loss: 1.8890395164489746
Validation loss: 2.034753655874601

Epoch: 6| Step: 11
Training loss: 1.980220913887024
Validation loss: 2.024958218297651

Epoch: 6| Step: 12
Training loss: 2.091587543487549
Validation loss: 2.040508029281452

Epoch: 6| Step: 13
Training loss: 2.596644401550293
Validation loss: 2.0451173423438944

Epoch: 43| Step: 0
Training loss: 2.0074520111083984
Validation loss: 2.040678026855633

Epoch: 6| Step: 1
Training loss: 2.536278009414673
Validation loss: 2.0448999430543635

Epoch: 6| Step: 2
Training loss: 2.178079128265381
Validation loss: 2.045515914117136

Epoch: 6| Step: 3
Training loss: 1.9709023237228394
Validation loss: 2.069470013341596

Epoch: 6| Step: 4
Training loss: 2.3291115760803223
Validation loss: 2.050065263625114

Epoch: 6| Step: 5
Training loss: 2.9054150581359863
Validation loss: 2.0359729489972516

Epoch: 6| Step: 6
Training loss: 2.7425193786621094
Validation loss: 2.039820099389681

Epoch: 6| Step: 7
Training loss: 2.210071325302124
Validation loss: 2.037398102462933

Epoch: 6| Step: 8
Training loss: 2.416201591491699
Validation loss: 2.0332694104922715

Epoch: 6| Step: 9
Training loss: 1.9306119680404663
Validation loss: 2.041400154431661

Epoch: 6| Step: 10
Training loss: 2.615947723388672
Validation loss: 2.048220096095916

Epoch: 6| Step: 11
Training loss: 2.729036569595337
Validation loss: 2.035528488056634

Epoch: 6| Step: 12
Training loss: 2.2831084728240967
Validation loss: 2.026246234934817

Epoch: 6| Step: 13
Training loss: 2.107451915740967
Validation loss: 2.050604579269245

Epoch: 44| Step: 0
Training loss: 2.8503453731536865
Validation loss: 2.0371424318641744

Epoch: 6| Step: 1
Training loss: 2.3176541328430176
Validation loss: 2.0309327571622786

Epoch: 6| Step: 2
Training loss: 3.169311046600342
Validation loss: 2.023155394420829

Epoch: 6| Step: 3
Training loss: 2.148078441619873
Validation loss: 2.0509992927633305

Epoch: 6| Step: 4
Training loss: 2.6079604625701904
Validation loss: 2.038189309899525

Epoch: 6| Step: 5
Training loss: 2.2178778648376465
Validation loss: 2.0443875764005925

Epoch: 6| Step: 6
Training loss: 2.058828592300415
Validation loss: 2.059756768647061

Epoch: 6| Step: 7
Training loss: 2.2079927921295166
Validation loss: 2.0656055737567205

Epoch: 6| Step: 8
Training loss: 2.0375895500183105
Validation loss: 2.065684888952522

Epoch: 6| Step: 9
Training loss: 2.389470100402832
Validation loss: 2.066275450491136

Epoch: 6| Step: 10
Training loss: 1.9050569534301758
Validation loss: 2.060807135797316

Epoch: 6| Step: 11
Training loss: 2.329592227935791
Validation loss: 2.0419798076793714

Epoch: 6| Step: 12
Training loss: 2.696014404296875
Validation loss: 2.051941115369079

Epoch: 6| Step: 13
Training loss: 2.8575830459594727
Validation loss: 2.061955508365426

Epoch: 45| Step: 0
Training loss: 2.4277091026306152
Validation loss: 2.0582444398633895

Epoch: 6| Step: 1
Training loss: 1.6089814901351929
Validation loss: 2.0413364543709704

Epoch: 6| Step: 2
Training loss: 1.8837854862213135
Validation loss: 2.068086490836195

Epoch: 6| Step: 3
Training loss: 2.280802011489868
Validation loss: 2.0498398785950034

Epoch: 6| Step: 4
Training loss: 2.324954032897949
Validation loss: 2.0474217245655675

Epoch: 6| Step: 5
Training loss: 2.516716957092285
Validation loss: 2.0426561755518757

Epoch: 6| Step: 6
Training loss: 2.4616241455078125
Validation loss: 2.036662179936645

Epoch: 6| Step: 7
Training loss: 2.129244327545166
Validation loss: 2.0508793605271207

Epoch: 6| Step: 8
Training loss: 2.202700138092041
Validation loss: 2.027616398308867

Epoch: 6| Step: 9
Training loss: 2.3976571559906006
Validation loss: 2.0690604345772856

Epoch: 6| Step: 10
Training loss: 2.328549385070801
Validation loss: 2.0576534322513047

Epoch: 6| Step: 11
Training loss: 3.2097764015197754
Validation loss: 2.0661020599385744

Epoch: 6| Step: 12
Training loss: 2.8209989070892334
Validation loss: 2.0663026122636694

Epoch: 6| Step: 13
Training loss: 2.701781749725342
Validation loss: 2.0742306196561424

Epoch: 46| Step: 0
Training loss: 2.1557037830352783
Validation loss: 2.0582960549221245

Epoch: 6| Step: 1
Training loss: 2.320566177368164
Validation loss: 2.048228353582403

Epoch: 6| Step: 2
Training loss: 2.75671648979187
Validation loss: 2.0579155004152687

Epoch: 6| Step: 3
Training loss: 2.3545210361480713
Validation loss: 2.0485189294302337

Epoch: 6| Step: 4
Training loss: 1.8186798095703125
Validation loss: 2.0360652451874106

Epoch: 6| Step: 5
Training loss: 1.9138562679290771
Validation loss: 2.0268439144216557

Epoch: 6| Step: 6
Training loss: 2.558354139328003
Validation loss: 2.0521709380611295

Epoch: 6| Step: 7
Training loss: 2.0249972343444824
Validation loss: 2.046004133839761

Epoch: 6| Step: 8
Training loss: 2.321815013885498
Validation loss: 2.021830704904372

Epoch: 6| Step: 9
Training loss: 2.5377516746520996
Validation loss: 2.038845759566112

Epoch: 6| Step: 10
Training loss: 2.336310625076294
Validation loss: 2.047122075993528

Epoch: 6| Step: 11
Training loss: 2.776124954223633
Validation loss: 2.0244244272990892

Epoch: 6| Step: 12
Training loss: 2.8838343620300293
Validation loss: 2.0423763387946674

Epoch: 6| Step: 13
Training loss: 2.537973403930664
Validation loss: 2.036912862972547

Epoch: 47| Step: 0
Training loss: 3.0948874950408936
Validation loss: 2.041570210969576

Epoch: 6| Step: 1
Training loss: 2.88057279586792
Validation loss: 2.0219415644163727

Epoch: 6| Step: 2
Training loss: 2.2474300861358643
Validation loss: 2.023454427719116

Epoch: 6| Step: 3
Training loss: 1.9314519166946411
Validation loss: 2.0230677102201726

Epoch: 6| Step: 4
Training loss: 2.077380895614624
Validation loss: 1.9986300788899904

Epoch: 6| Step: 5
Training loss: 2.3413264751434326
Validation loss: 2.040205088994836

Epoch: 6| Step: 6
Training loss: 2.0654661655426025
Validation loss: 2.0097312247881325

Epoch: 6| Step: 7
Training loss: 2.2839436531066895
Validation loss: 2.026759280953356

Epoch: 6| Step: 8
Training loss: 2.4792943000793457
Validation loss: 2.0250543637942244

Epoch: 6| Step: 9
Training loss: 2.467839241027832
Validation loss: 2.05130942662557

Epoch: 6| Step: 10
Training loss: 3.1105918884277344
Validation loss: 2.0055302112333235

Epoch: 6| Step: 11
Training loss: 2.323399782180786
Validation loss: 2.023422448865829

Epoch: 6| Step: 12
Training loss: 1.9270110130310059
Validation loss: 2.0203267835801646

Epoch: 6| Step: 13
Training loss: 1.6332658529281616
Validation loss: 2.031291142586739

Epoch: 48| Step: 0
Training loss: 2.246764659881592
Validation loss: 2.031146186654286

Epoch: 6| Step: 1
Training loss: 2.5227370262145996
Validation loss: 2.045279610541559

Epoch: 6| Step: 2
Training loss: 2.4267778396606445
Validation loss: 2.0147128079527166

Epoch: 6| Step: 3
Training loss: 1.8162167072296143
Validation loss: 2.0041523287373204

Epoch: 6| Step: 4
Training loss: 2.2535345554351807
Validation loss: 2.0175449155992076

Epoch: 6| Step: 5
Training loss: 3.0043652057647705
Validation loss: 2.027196240681474

Epoch: 6| Step: 6
Training loss: 1.6620886325836182
Validation loss: 2.031695067241628

Epoch: 6| Step: 7
Training loss: 1.8328864574432373
Validation loss: 2.017494536215259

Epoch: 6| Step: 8
Training loss: 2.535950183868408
Validation loss: 2.0184786435096496

Epoch: 6| Step: 9
Training loss: 2.6738815307617188
Validation loss: 2.0145613044820805

Epoch: 6| Step: 10
Training loss: 1.8054683208465576
Validation loss: 2.0181208554134575

Epoch: 6| Step: 11
Training loss: 2.6011366844177246
Validation loss: 2.034738920068228

Epoch: 6| Step: 12
Training loss: 3.011166572570801
Validation loss: 2.0218100252971856

Epoch: 6| Step: 13
Training loss: 2.797999143600464
Validation loss: 2.0402605008053523

Epoch: 49| Step: 0
Training loss: 2.825101137161255
Validation loss: 2.025206285138284

Epoch: 6| Step: 1
Training loss: 2.369175910949707
Validation loss: 2.0486914009176274

Epoch: 6| Step: 2
Training loss: 2.2455801963806152
Validation loss: 2.0476604661633893

Epoch: 6| Step: 3
Training loss: 1.8974225521087646
Validation loss: 2.0407591942817933

Epoch: 6| Step: 4
Training loss: 2.3047308921813965
Validation loss: 2.0373437122632096

Epoch: 6| Step: 5
Training loss: 2.771437883377075
Validation loss: 2.0459200823178856

Epoch: 6| Step: 6
Training loss: 1.9322134256362915
Validation loss: 2.0508763713221394

Epoch: 6| Step: 7
Training loss: 2.5487022399902344
Validation loss: 2.053616467342582

Epoch: 6| Step: 8
Training loss: 2.5167551040649414
Validation loss: 2.043263594309489

Epoch: 6| Step: 9
Training loss: 2.0158846378326416
Validation loss: 2.037288628598695

Epoch: 6| Step: 10
Training loss: 2.032963752746582
Validation loss: 2.0514423770289265

Epoch: 6| Step: 11
Training loss: 2.6931304931640625
Validation loss: 2.0388860933242308

Epoch: 6| Step: 12
Training loss: 2.5277323722839355
Validation loss: 2.0546379627720004

Epoch: 6| Step: 13
Training loss: 2.2733681201934814
Validation loss: 2.032630599955077

Epoch: 50| Step: 0
Training loss: 2.4309654235839844
Validation loss: 2.047194826987482

Epoch: 6| Step: 1
Training loss: 2.363518714904785
Validation loss: 2.0407328682561077

Epoch: 6| Step: 2
Training loss: 1.7884914875030518
Validation loss: 2.043849842522734

Epoch: 6| Step: 3
Training loss: 2.6857142448425293
Validation loss: 2.0336204164771625

Epoch: 6| Step: 4
Training loss: 2.0338454246520996
Validation loss: 2.0476729254568777

Epoch: 6| Step: 5
Training loss: 2.4875893592834473
Validation loss: 2.0380810050554174

Epoch: 6| Step: 6
Training loss: 1.874382734298706
Validation loss: 2.03539696175565

Epoch: 6| Step: 7
Training loss: 2.731328010559082
Validation loss: 2.0645075780089184

Epoch: 6| Step: 8
Training loss: 3.8169381618499756
Validation loss: 2.0214957011643278

Epoch: 6| Step: 9
Training loss: 2.0964035987854004
Validation loss: 2.045720197821176

Epoch: 6| Step: 10
Training loss: 1.7819206714630127
Validation loss: 2.0419570117868404

Epoch: 6| Step: 11
Training loss: 2.844916820526123
Validation loss: 2.0244776664241666

Epoch: 6| Step: 12
Training loss: 1.8656760454177856
Validation loss: 2.0275307323343013

Epoch: 6| Step: 13
Training loss: 1.8836877346038818
Validation loss: 2.0351520251202326

Epoch: 51| Step: 0
Training loss: 2.8434746265411377
Validation loss: 2.0230878117263957

Epoch: 6| Step: 1
Training loss: 2.7306385040283203
Validation loss: 2.0276679838857343

Epoch: 6| Step: 2
Training loss: 2.8539323806762695
Validation loss: 2.033231557056468

Epoch: 6| Step: 3
Training loss: 2.418025493621826
Validation loss: 2.025187800007482

Epoch: 6| Step: 4
Training loss: 2.0459959506988525
Validation loss: 2.0369356383559523

Epoch: 6| Step: 5
Training loss: 2.790863037109375
Validation loss: 2.0281913665033158

Epoch: 6| Step: 6
Training loss: 2.4475154876708984
Validation loss: 2.040556667953409

Epoch: 6| Step: 7
Training loss: 2.2372865676879883
Validation loss: 2.0234606163476103

Epoch: 6| Step: 8
Training loss: 2.242915391921997
Validation loss: 2.020996683387346

Epoch: 6| Step: 9
Training loss: 2.304215431213379
Validation loss: 2.0190517005100044

Epoch: 6| Step: 10
Training loss: 2.064685583114624
Validation loss: 2.023515864085126

Epoch: 6| Step: 11
Training loss: 1.5705349445343018
Validation loss: 2.033160947984265

Epoch: 6| Step: 12
Training loss: 1.7441043853759766
Validation loss: 2.0387115427242812

Epoch: 6| Step: 13
Training loss: 2.689791679382324
Validation loss: 2.0261443609832437

Epoch: 52| Step: 0
Training loss: 2.237940788269043
Validation loss: 2.03035674172063

Epoch: 6| Step: 1
Training loss: 3.1090474128723145
Validation loss: 2.0281430623864614

Epoch: 6| Step: 2
Training loss: 1.8780007362365723
Validation loss: 2.032566503811908

Epoch: 6| Step: 3
Training loss: 2.378507614135742
Validation loss: 2.0543263266163487

Epoch: 6| Step: 4
Training loss: 2.5976831912994385
Validation loss: 2.01341425987982

Epoch: 6| Step: 5
Training loss: 2.2704238891601562
Validation loss: 2.0461278269367833

Epoch: 6| Step: 6
Training loss: 2.044290065765381
Validation loss: 2.016828683114821

Epoch: 6| Step: 7
Training loss: 2.2957675457000732
Validation loss: 2.0281751130216863

Epoch: 6| Step: 8
Training loss: 2.737637519836426
Validation loss: 2.0221430229884323

Epoch: 6| Step: 9
Training loss: 1.7623836994171143
Validation loss: 2.01215971157115

Epoch: 6| Step: 10
Training loss: 2.264296531677246
Validation loss: 1.9965775038606377

Epoch: 6| Step: 11
Training loss: 2.367548704147339
Validation loss: 2.006912972337456

Epoch: 6| Step: 12
Training loss: 2.2808902263641357
Validation loss: 2.019747362341932

Epoch: 6| Step: 13
Training loss: 2.5270910263061523
Validation loss: 2.0276352820857877

Epoch: 53| Step: 0
Training loss: 1.9746713638305664
Validation loss: 2.0433383244340138

Epoch: 6| Step: 1
Training loss: 1.8638168573379517
Validation loss: 2.0198079232246644

Epoch: 6| Step: 2
Training loss: 2.102604866027832
Validation loss: 2.0358645146892917

Epoch: 6| Step: 3
Training loss: 2.064243793487549
Validation loss: 2.03843000114605

Epoch: 6| Step: 4
Training loss: 1.6284961700439453
Validation loss: 2.036944535470778

Epoch: 6| Step: 5
Training loss: 2.6835737228393555
Validation loss: 1.9991047536173174

Epoch: 6| Step: 6
Training loss: 2.1124942302703857
Validation loss: 2.039580216971777

Epoch: 6| Step: 7
Training loss: 2.5203680992126465
Validation loss: 2.0404785756141908

Epoch: 6| Step: 8
Training loss: 2.5621609687805176
Validation loss: 2.029031830449258

Epoch: 6| Step: 9
Training loss: 2.847318649291992
Validation loss: 2.033147540143741

Epoch: 6| Step: 10
Training loss: 3.248904228210449
Validation loss: 2.0219100547093216

Epoch: 6| Step: 11
Training loss: 2.587320327758789
Validation loss: 2.0432469050089517

Epoch: 6| Step: 12
Training loss: 1.7843416929244995
Validation loss: 2.0183758197292203

Epoch: 6| Step: 13
Training loss: 2.7540626525878906
Validation loss: 2.023357755394392

Epoch: 54| Step: 0
Training loss: 2.302732467651367
Validation loss: 2.0244475321103166

Epoch: 6| Step: 1
Training loss: 2.2403268814086914
Validation loss: 2.035873797632033

Epoch: 6| Step: 2
Training loss: 1.7950482368469238
Validation loss: 2.0461620758938532

Epoch: 6| Step: 3
Training loss: 1.6155163049697876
Validation loss: 2.0127711501172794

Epoch: 6| Step: 4
Training loss: 2.665459156036377
Validation loss: 2.050861097151233

Epoch: 6| Step: 5
Training loss: 3.04837965965271
Validation loss: 2.0255775631115003

Epoch: 6| Step: 6
Training loss: 2.436981678009033
Validation loss: 2.0397123393192085

Epoch: 6| Step: 7
Training loss: 2.024839401245117
Validation loss: 2.0193164399875108

Epoch: 6| Step: 8
Training loss: 2.544090747833252
Validation loss: 2.030641378894929

Epoch: 6| Step: 9
Training loss: 2.5054595470428467
Validation loss: 2.0338866813208467

Epoch: 6| Step: 10
Training loss: 2.474677562713623
Validation loss: 2.026056651146181

Epoch: 6| Step: 11
Training loss: 2.1483047008514404
Validation loss: 2.017903588151419

Epoch: 6| Step: 12
Training loss: 2.3911213874816895
Validation loss: 2.0116096158181467

Epoch: 6| Step: 13
Training loss: 2.3046255111694336
Validation loss: 2.0428540322088424

Epoch: 55| Step: 0
Training loss: 1.9996871948242188
Validation loss: 2.0466980113778064

Epoch: 6| Step: 1
Training loss: 3.003170967102051
Validation loss: 2.062251660131639

Epoch: 6| Step: 2
Training loss: 1.9816759824752808
Validation loss: 2.0519574201235207

Epoch: 6| Step: 3
Training loss: 2.587067127227783
Validation loss: 2.044478891998209

Epoch: 6| Step: 4
Training loss: 2.497854709625244
Validation loss: 2.0491704889523086

Epoch: 6| Step: 5
Training loss: 2.803147077560425
Validation loss: 2.0405975131578344

Epoch: 6| Step: 6
Training loss: 1.7429730892181396
Validation loss: 2.0392550960663827

Epoch: 6| Step: 7
Training loss: 2.2574636936187744
Validation loss: 2.054491096927274

Epoch: 6| Step: 8
Training loss: 2.6510677337646484
Validation loss: 2.050582124340919

Epoch: 6| Step: 9
Training loss: 2.677626132965088
Validation loss: 2.0735287884230256

Epoch: 6| Step: 10
Training loss: 1.984241008758545
Validation loss: 2.079323672479199

Epoch: 6| Step: 11
Training loss: 2.052051067352295
Validation loss: 2.0733626542552823

Epoch: 6| Step: 12
Training loss: 1.9552823305130005
Validation loss: 2.059336139309791

Epoch: 6| Step: 13
Training loss: 2.21233868598938
Validation loss: 2.0720114041400213

Epoch: 56| Step: 0
Training loss: 2.3506245613098145
Validation loss: 2.0597471114127868

Epoch: 6| Step: 1
Training loss: 1.9355841875076294
Validation loss: 2.0536170877436155

Epoch: 6| Step: 2
Training loss: 3.5156452655792236
Validation loss: 2.035508668550881

Epoch: 6| Step: 3
Training loss: 1.6363720893859863
Validation loss: 2.0688998468460573

Epoch: 6| Step: 4
Training loss: 2.016261577606201
Validation loss: 2.0598760202366817

Epoch: 6| Step: 5
Training loss: 1.8627336025238037
Validation loss: 2.0472460049454884

Epoch: 6| Step: 6
Training loss: 2.4525697231292725
Validation loss: 2.0268348634883924

Epoch: 6| Step: 7
Training loss: 2.1180996894836426
Validation loss: 2.0249275289556032

Epoch: 6| Step: 8
Training loss: 2.135364055633545
Validation loss: 2.037163019180298

Epoch: 6| Step: 9
Training loss: 2.671069860458374
Validation loss: 2.034046998587988

Epoch: 6| Step: 10
Training loss: 1.9562962055206299
Validation loss: 2.0361258406792917

Epoch: 6| Step: 11
Training loss: 2.5861423015594482
Validation loss: 2.0501708381919452

Epoch: 6| Step: 12
Training loss: 2.510897159576416
Validation loss: 2.044235357674219

Epoch: 6| Step: 13
Training loss: 3.164794445037842
Validation loss: 2.03988738213816

Epoch: 57| Step: 0
Training loss: 2.0563220977783203
Validation loss: 2.036558053826773

Epoch: 6| Step: 1
Training loss: 2.038341522216797
Validation loss: 2.020935353412423

Epoch: 6| Step: 2
Training loss: 1.5347648859024048
Validation loss: 2.0549627375859085

Epoch: 6| Step: 3
Training loss: 2.414066791534424
Validation loss: 2.0644325825475875

Epoch: 6| Step: 4
Training loss: 2.5778932571411133
Validation loss: 2.0371189425068517

Epoch: 6| Step: 5
Training loss: 2.6253442764282227
Validation loss: 2.0291112135815363

Epoch: 6| Step: 6
Training loss: 2.9756367206573486
Validation loss: 2.0461604390093076

Epoch: 6| Step: 7
Training loss: 2.182185173034668
Validation loss: 2.0283321296015093

Epoch: 6| Step: 8
Training loss: 2.0888447761535645
Validation loss: 2.0397339687552503

Epoch: 6| Step: 9
Training loss: 2.036937952041626
Validation loss: 2.0111378418501986

Epoch: 6| Step: 10
Training loss: 2.2654881477355957
Validation loss: 1.9960424823145713

Epoch: 6| Step: 11
Training loss: 2.4940056800842285
Validation loss: 2.025062422598562

Epoch: 6| Step: 12
Training loss: 2.660724639892578
Validation loss: 2.03416133311487

Epoch: 6| Step: 13
Training loss: 2.745032548904419
Validation loss: 2.0268448424595658

Epoch: 58| Step: 0
Training loss: 2.4982457160949707
Validation loss: 2.026683674063734

Epoch: 6| Step: 1
Training loss: 2.1128382682800293
Validation loss: 2.0383010923221545

Epoch: 6| Step: 2
Training loss: 2.445979118347168
Validation loss: 2.0120236694171862

Epoch: 6| Step: 3
Training loss: 1.743636131286621
Validation loss: 2.038944305912141

Epoch: 6| Step: 4
Training loss: 3.601195812225342
Validation loss: 2.02829400954708

Epoch: 6| Step: 5
Training loss: 2.355720043182373
Validation loss: 2.0396595783131097

Epoch: 6| Step: 6
Training loss: 2.2303004264831543
Validation loss: 2.011372817459927

Epoch: 6| Step: 7
Training loss: 2.5140814781188965
Validation loss: 2.039943710450203

Epoch: 6| Step: 8
Training loss: 2.2083592414855957
Validation loss: 2.0532131412977814

Epoch: 6| Step: 9
Training loss: 1.981445550918579
Validation loss: 2.070973906465756

Epoch: 6| Step: 10
Training loss: 1.7417967319488525
Validation loss: 2.030472763123051

Epoch: 6| Step: 11
Training loss: 2.220686674118042
Validation loss: 2.0404972312270955

Epoch: 6| Step: 12
Training loss: 2.7608110904693604
Validation loss: 2.0185643306342502

Epoch: 6| Step: 13
Training loss: 1.9345155954360962
Validation loss: 2.048174371001541

Epoch: 59| Step: 0
Training loss: 1.868593692779541
Validation loss: 2.049662797681747

Epoch: 6| Step: 1
Training loss: 2.3674330711364746
Validation loss: 2.056067515445012

Epoch: 6| Step: 2
Training loss: 2.728543996810913
Validation loss: 2.050810347321213

Epoch: 6| Step: 3
Training loss: 2.7298972606658936
Validation loss: 2.040874227400749

Epoch: 6| Step: 4
Training loss: 2.2332892417907715
Validation loss: 2.0446869839904127

Epoch: 6| Step: 5
Training loss: 1.843855619430542
Validation loss: 2.0400428310517342

Epoch: 6| Step: 6
Training loss: 2.1470775604248047
Validation loss: 2.0242694654772357

Epoch: 6| Step: 7
Training loss: 2.1651177406311035
Validation loss: 2.015447384567671

Epoch: 6| Step: 8
Training loss: 2.2046098709106445
Validation loss: 2.0264292250397387

Epoch: 6| Step: 9
Training loss: 2.8050310611724854
Validation loss: 2.0342151990500827

Epoch: 6| Step: 10
Training loss: 2.225898027420044
Validation loss: 2.0231291914498932

Epoch: 6| Step: 11
Training loss: 2.813683032989502
Validation loss: 2.012032537050145

Epoch: 6| Step: 12
Training loss: 1.7357726097106934
Validation loss: 2.0291731690847747

Epoch: 6| Step: 13
Training loss: 2.998141288757324
Validation loss: 2.019766381991807

Epoch: 60| Step: 0
Training loss: 1.591073751449585
Validation loss: 2.0428058844740673

Epoch: 6| Step: 1
Training loss: 2.9646964073181152
Validation loss: 2.0230597975433513

Epoch: 6| Step: 2
Training loss: 2.452134609222412
Validation loss: 2.0432869747120845

Epoch: 6| Step: 3
Training loss: 1.893818736076355
Validation loss: 2.018399812841928

Epoch: 6| Step: 4
Training loss: 2.6748878955841064
Validation loss: 2.044194418896911

Epoch: 6| Step: 5
Training loss: 2.954387664794922
Validation loss: 2.0604002885921027

Epoch: 6| Step: 6
Training loss: 2.928809404373169
Validation loss: 2.050032878434786

Epoch: 6| Step: 7
Training loss: 1.9194458723068237
Validation loss: 2.048190595001303

Epoch: 6| Step: 8
Training loss: 2.42680025100708
Validation loss: 2.048609595144949

Epoch: 6| Step: 9
Training loss: 2.2902255058288574
Validation loss: 2.0673399240739885

Epoch: 6| Step: 10
Training loss: 2.1497695446014404
Validation loss: 2.063313449582746

Epoch: 6| Step: 11
Training loss: 2.0239241123199463
Validation loss: 2.0722755821802283

Epoch: 6| Step: 12
Training loss: 2.0676283836364746
Validation loss: 2.075355727185485

Epoch: 6| Step: 13
Training loss: 2.03415584564209
Validation loss: 2.054316997528076

Epoch: 61| Step: 0
Training loss: 2.0384397506713867
Validation loss: 2.0486682050971576

Epoch: 6| Step: 1
Training loss: 1.7030128240585327
Validation loss: 2.0506423058048373

Epoch: 6| Step: 2
Training loss: 2.013655662536621
Validation loss: 2.044491175682314

Epoch: 6| Step: 3
Training loss: 2.1888248920440674
Validation loss: 2.0610651636636383

Epoch: 6| Step: 4
Training loss: 2.3547675609588623
Validation loss: 2.0528309319608953

Epoch: 6| Step: 5
Training loss: 1.7823278903961182
Validation loss: 2.049042276156846

Epoch: 6| Step: 6
Training loss: 3.0380563735961914
Validation loss: 2.0417622776441675

Epoch: 6| Step: 7
Training loss: 1.9949734210968018
Validation loss: 2.043143274963543

Epoch: 6| Step: 8
Training loss: 2.6525301933288574
Validation loss: 2.0569239662539576

Epoch: 6| Step: 9
Training loss: 2.7714123725891113
Validation loss: 2.0259464594625656

Epoch: 6| Step: 10
Training loss: 2.9523606300354004
Validation loss: 2.0429597029121975

Epoch: 6| Step: 11
Training loss: 1.7923853397369385
Validation loss: 1.9954031564856087

Epoch: 6| Step: 12
Training loss: 2.603543758392334
Validation loss: 2.0178300488379692

Epoch: 6| Step: 13
Training loss: 2.640397071838379
Validation loss: 2.0089110136032104

Epoch: 62| Step: 0
Training loss: 2.2493913173675537
Validation loss: 2.0285899177674325

Epoch: 6| Step: 1
Training loss: 3.192300319671631
Validation loss: 2.0104645221464095

Epoch: 6| Step: 2
Training loss: 1.9055781364440918
Validation loss: 2.0170417280607325

Epoch: 6| Step: 3
Training loss: 2.170724391937256
Validation loss: 2.0193649286864908

Epoch: 6| Step: 4
Training loss: 2.5423941612243652
Validation loss: 2.0263443967347503

Epoch: 6| Step: 5
Training loss: 3.1268978118896484
Validation loss: 2.0024941377742316

Epoch: 6| Step: 6
Training loss: 2.384139060974121
Validation loss: 2.0281463899920062

Epoch: 6| Step: 7
Training loss: 2.293239116668701
Validation loss: 2.033155442566

Epoch: 6| Step: 8
Training loss: 2.511012554168701
Validation loss: 2.0145942049641765

Epoch: 6| Step: 9
Training loss: 1.852518081665039
Validation loss: 2.022333857833698

Epoch: 6| Step: 10
Training loss: 1.4743822813034058
Validation loss: 2.0221146281047533

Epoch: 6| Step: 11
Training loss: 2.1304831504821777
Validation loss: 2.0257651190603934

Epoch: 6| Step: 12
Training loss: 2.44992995262146
Validation loss: 2.0215825573090584

Epoch: 6| Step: 13
Training loss: 1.4982458353042603
Validation loss: 2.036966182852304

Epoch: 63| Step: 0
Training loss: 2.0481410026550293
Validation loss: 2.0239008793266873

Epoch: 6| Step: 1
Training loss: 1.9811265468597412
Validation loss: 2.0409687052490892

Epoch: 6| Step: 2
Training loss: 2.8540971279144287
Validation loss: 2.0379982379175003

Epoch: 6| Step: 3
Training loss: 2.7124600410461426
Validation loss: 2.01002792004616

Epoch: 6| Step: 4
Training loss: 2.30020809173584
Validation loss: 2.0456322252109485

Epoch: 6| Step: 5
Training loss: 2.4767632484436035
Validation loss: 2.011182559433804

Epoch: 6| Step: 6
Training loss: 2.7586097717285156
Validation loss: 1.9970972461085166

Epoch: 6| Step: 7
Training loss: 2.3706398010253906
Validation loss: 2.009838725930901

Epoch: 6| Step: 8
Training loss: 2.0166521072387695
Validation loss: 2.000073895659498

Epoch: 6| Step: 9
Training loss: 1.8973288536071777
Validation loss: 1.9933985279452415

Epoch: 6| Step: 10
Training loss: 2.8726024627685547
Validation loss: 2.014472084660684

Epoch: 6| Step: 11
Training loss: 1.4988996982574463
Validation loss: 2.0068173895600023

Epoch: 6| Step: 12
Training loss: 2.165308713912964
Validation loss: 1.990445536951865

Epoch: 6| Step: 13
Training loss: 2.2594592571258545
Validation loss: 2.024129973944797

Epoch: 64| Step: 0
Training loss: 2.3756866455078125
Validation loss: 2.001298817255164

Epoch: 6| Step: 1
Training loss: 2.5177340507507324
Validation loss: 2.005213527269261

Epoch: 6| Step: 2
Training loss: 2.3191709518432617
Validation loss: 2.0025742028349187

Epoch: 6| Step: 3
Training loss: 2.3995628356933594
Validation loss: 2.022217789003926

Epoch: 6| Step: 4
Training loss: 2.0994274616241455
Validation loss: 2.0064203867348294

Epoch: 6| Step: 5
Training loss: 2.383330821990967
Validation loss: 2.0171545141486713

Epoch: 6| Step: 6
Training loss: 2.8463363647460938
Validation loss: 2.032793575717557

Epoch: 6| Step: 7
Training loss: 2.1460185050964355
Validation loss: 2.029519689980374

Epoch: 6| Step: 8
Training loss: 2.465026378631592
Validation loss: 2.0268025757164083

Epoch: 6| Step: 9
Training loss: 2.2371463775634766
Validation loss: 2.0140910584439515

Epoch: 6| Step: 10
Training loss: 1.9901728630065918
Validation loss: 2.0423079267624886

Epoch: 6| Step: 11
Training loss: 2.1561167240142822
Validation loss: 2.0248069686274373

Epoch: 6| Step: 12
Training loss: 2.2709734439849854
Validation loss: 2.02020961623038

Epoch: 6| Step: 13
Training loss: 1.5151623487472534
Validation loss: 2.026238444030926

Epoch: 65| Step: 0
Training loss: 2.1365108489990234
Validation loss: 2.0273819943910003

Epoch: 6| Step: 1
Training loss: 2.137974262237549
Validation loss: 2.053082585334778

Epoch: 6| Step: 2
Training loss: 2.263047218322754
Validation loss: 2.0606713512892365

Epoch: 6| Step: 3
Training loss: 2.1580491065979004
Validation loss: 2.0387031544921217

Epoch: 6| Step: 4
Training loss: 2.6800055503845215
Validation loss: 2.03921543013665

Epoch: 6| Step: 5
Training loss: 2.225975513458252
Validation loss: 2.0441743635362193

Epoch: 6| Step: 6
Training loss: 2.877220630645752
Validation loss: 2.0530876433977516

Epoch: 6| Step: 7
Training loss: 2.1746063232421875
Validation loss: 2.0582510963562997

Epoch: 6| Step: 8
Training loss: 1.8813040256500244
Validation loss: 2.050691673832555

Epoch: 6| Step: 9
Training loss: 2.892636775970459
Validation loss: 2.0383106226562173

Epoch: 6| Step: 10
Training loss: 2.202789783477783
Validation loss: 2.0554734763278755

Epoch: 6| Step: 11
Training loss: 2.8415472507476807
Validation loss: 2.0370837219299807

Epoch: 6| Step: 12
Training loss: 1.6580966711044312
Validation loss: 2.0569934421969998

Epoch: 6| Step: 13
Training loss: 1.795403003692627
Validation loss: 2.074913168466219

Epoch: 66| Step: 0
Training loss: 2.4765748977661133
Validation loss: 2.039237081363637

Epoch: 6| Step: 1
Training loss: 2.511375904083252
Validation loss: 2.05078532362497

Epoch: 6| Step: 2
Training loss: 2.7831716537475586
Validation loss: 2.040752803125689

Epoch: 6| Step: 3
Training loss: 2.226919651031494
Validation loss: 2.043407960604596

Epoch: 6| Step: 4
Training loss: 2.484982967376709
Validation loss: 2.064613083357452

Epoch: 6| Step: 5
Training loss: 2.3618321418762207
Validation loss: 2.0532174905141196

Epoch: 6| Step: 6
Training loss: 2.378661632537842
Validation loss: 2.033786094316872

Epoch: 6| Step: 7
Training loss: 1.466324806213379
Validation loss: 2.040357658939977

Epoch: 6| Step: 8
Training loss: 1.7245533466339111
Validation loss: 2.041785365791731

Epoch: 6| Step: 9
Training loss: 2.6470794677734375
Validation loss: 2.05124891701565

Epoch: 6| Step: 10
Training loss: 1.9286887645721436
Validation loss: 2.0543319538075435

Epoch: 6| Step: 11
Training loss: 2.634434700012207
Validation loss: 2.0831452787563367

Epoch: 6| Step: 12
Training loss: 2.597702980041504
Validation loss: 2.045348708347608

Epoch: 6| Step: 13
Training loss: 1.5995877981185913
Validation loss: 2.0379554610098563

Epoch: 67| Step: 0
Training loss: 2.2573189735412598
Validation loss: 2.0224496574812036

Epoch: 6| Step: 1
Training loss: 2.3301219940185547
Validation loss: 2.0355116808286278

Epoch: 6| Step: 2
Training loss: 2.2402796745300293
Validation loss: 2.0486468409979217

Epoch: 6| Step: 3
Training loss: 2.2046923637390137
Validation loss: 2.0134537796820364

Epoch: 6| Step: 4
Training loss: 1.426934003829956
Validation loss: 2.041970832373506

Epoch: 6| Step: 5
Training loss: 2.0384445190429688
Validation loss: 2.0272839787185832

Epoch: 6| Step: 6
Training loss: 2.465705156326294
Validation loss: 2.042069204391972

Epoch: 6| Step: 7
Training loss: 2.1147525310516357
Validation loss: 2.0064244013960644

Epoch: 6| Step: 8
Training loss: 2.289243698120117
Validation loss: 2.049303582919541

Epoch: 6| Step: 9
Training loss: 1.851402997970581
Validation loss: 2.0408119616969937

Epoch: 6| Step: 10
Training loss: 3.1300313472747803
Validation loss: 2.032106143172069

Epoch: 6| Step: 11
Training loss: 3.608120918273926
Validation loss: 2.042039005987106

Epoch: 6| Step: 12
Training loss: 2.2902703285217285
Validation loss: 2.0338867684846282

Epoch: 6| Step: 13
Training loss: 1.5039514303207397
Validation loss: 2.047429223214426

Epoch: 68| Step: 0
Training loss: 2.1523494720458984
Validation loss: 2.027964045924525

Epoch: 6| Step: 1
Training loss: 1.9874176979064941
Validation loss: 2.0426346153341313

Epoch: 6| Step: 2
Training loss: 2.410243511199951
Validation loss: 2.0323817576131513

Epoch: 6| Step: 3
Training loss: 2.275907516479492
Validation loss: 2.0373999329023462

Epoch: 6| Step: 4
Training loss: 3.1778347492218018
Validation loss: 2.0380464997342838

Epoch: 6| Step: 5
Training loss: 2.070483684539795
Validation loss: 2.000268846429804

Epoch: 6| Step: 6
Training loss: 2.326455593109131
Validation loss: 2.011885819896575

Epoch: 6| Step: 7
Training loss: 2.759298324584961
Validation loss: 2.025063286545456

Epoch: 6| Step: 8
Training loss: 1.615119457244873
Validation loss: 2.034947492743051

Epoch: 6| Step: 9
Training loss: 1.6474367380142212
Validation loss: 2.050731958881501

Epoch: 6| Step: 10
Training loss: 1.9995174407958984
Validation loss: 2.0249503709936656

Epoch: 6| Step: 11
Training loss: 2.542846202850342
Validation loss: 2.0254144194305583

Epoch: 6| Step: 12
Training loss: 2.645915985107422
Validation loss: 2.0465761948657293

Epoch: 6| Step: 13
Training loss: 2.251622438430786
Validation loss: 2.0243321362362114

Epoch: 69| Step: 0
Training loss: 1.9387913942337036
Validation loss: 2.028290779359879

Epoch: 6| Step: 1
Training loss: 2.288004159927368
Validation loss: 2.027557824247627

Epoch: 6| Step: 2
Training loss: 2.0423669815063477
Validation loss: 2.0291651371986634

Epoch: 6| Step: 3
Training loss: 2.2801802158355713
Validation loss: 2.019993778197996

Epoch: 6| Step: 4
Training loss: 2.319091796875
Validation loss: 2.0467109808357815

Epoch: 6| Step: 5
Training loss: 2.6883544921875
Validation loss: 2.0564865860887753

Epoch: 6| Step: 6
Training loss: 2.227072238922119
Validation loss: 2.0474901583886917

Epoch: 6| Step: 7
Training loss: 2.2393884658813477
Validation loss: 2.0316913794445735

Epoch: 6| Step: 8
Training loss: 2.041567325592041
Validation loss: 2.0357525079481062

Epoch: 6| Step: 9
Training loss: 2.371849536895752
Validation loss: 2.0588738033848424

Epoch: 6| Step: 10
Training loss: 2.380354166030884
Validation loss: 2.040024422830151

Epoch: 6| Step: 11
Training loss: 2.1571695804595947
Validation loss: 2.03363811585211

Epoch: 6| Step: 12
Training loss: 3.1054985523223877
Validation loss: 2.049724740366782

Epoch: 6| Step: 13
Training loss: 1.6779671907424927
Validation loss: 2.017457192943942

Epoch: 70| Step: 0
Training loss: 2.3079042434692383
Validation loss: 2.0432253089002383

Epoch: 6| Step: 1
Training loss: 2.061378002166748
Validation loss: 2.029524628834058

Epoch: 6| Step: 2
Training loss: 2.6341614723205566
Validation loss: 2.0459735931888705

Epoch: 6| Step: 3
Training loss: 2.9025444984436035
Validation loss: 2.05720345435604

Epoch: 6| Step: 4
Training loss: 2.405128002166748
Validation loss: 2.051035442659932

Epoch: 6| Step: 5
Training loss: 3.049999713897705
Validation loss: 2.0473031933589647

Epoch: 6| Step: 6
Training loss: 1.764143466949463
Validation loss: 2.0562533050455074

Epoch: 6| Step: 7
Training loss: 1.8594943284988403
Validation loss: 2.0481337757520777

Epoch: 6| Step: 8
Training loss: 2.228118658065796
Validation loss: 2.0473902699767903

Epoch: 6| Step: 9
Training loss: 2.1862196922302246
Validation loss: 2.0952373602057017

Epoch: 6| Step: 10
Training loss: 2.0776662826538086
Validation loss: 2.054153101418608

Epoch: 6| Step: 11
Training loss: 1.8683228492736816
Validation loss: 2.093049249341411

Epoch: 6| Step: 12
Training loss: 2.2703847885131836
Validation loss: 2.048240876966907

Epoch: 6| Step: 13
Training loss: 2.8810932636260986
Validation loss: 2.0485843894302205

Epoch: 71| Step: 0
Training loss: 2.2636027336120605
Validation loss: 2.0567041109966975

Epoch: 6| Step: 1
Training loss: 3.0514163970947266
Validation loss: 2.0357857622126097

Epoch: 6| Step: 2
Training loss: 2.0256333351135254
Validation loss: 2.039468716549617

Epoch: 6| Step: 3
Training loss: 1.7229368686676025
Validation loss: 2.047082345972779

Epoch: 6| Step: 4
Training loss: 2.5649287700653076
Validation loss: 2.0319008904118694

Epoch: 6| Step: 5
Training loss: 1.4394328594207764
Validation loss: 2.021022178793466

Epoch: 6| Step: 6
Training loss: 2.4427242279052734
Validation loss: 2.056370240385814

Epoch: 6| Step: 7
Training loss: 2.6690609455108643
Validation loss: 2.0153317797568535

Epoch: 6| Step: 8
Training loss: 2.642155647277832
Validation loss: 2.054851328172991

Epoch: 6| Step: 9
Training loss: 2.458864688873291
Validation loss: 2.03748405620616

Epoch: 6| Step: 10
Training loss: 1.6182805299758911
Validation loss: 2.029528324322034

Epoch: 6| Step: 11
Training loss: 2.1377310752868652
Validation loss: 2.0357797120207097

Epoch: 6| Step: 12
Training loss: 2.668107271194458
Validation loss: 2.0487741795919274

Epoch: 6| Step: 13
Training loss: 1.9752774238586426
Validation loss: 2.0190908191024617

Epoch: 72| Step: 0
Training loss: 2.1250686645507812
Validation loss: 2.0502236658527004

Epoch: 6| Step: 1
Training loss: 2.008545398712158
Validation loss: 2.0476667291374615

Epoch: 6| Step: 2
Training loss: 1.7789368629455566
Validation loss: 2.030207085353072

Epoch: 6| Step: 3
Training loss: 2.3283019065856934
Validation loss: 2.0206750285240913

Epoch: 6| Step: 4
Training loss: 2.3457605838775635
Validation loss: 2.0244425009655695

Epoch: 6| Step: 5
Training loss: 2.3501105308532715
Validation loss: 2.022045568753314

Epoch: 6| Step: 6
Training loss: 2.4263784885406494
Validation loss: 2.029713241002893

Epoch: 6| Step: 7
Training loss: 1.950005292892456
Validation loss: 2.03264678934569

Epoch: 6| Step: 8
Training loss: 3.12245512008667
Validation loss: 2.041349285392351

Epoch: 6| Step: 9
Training loss: 2.164280414581299
Validation loss: 2.030703721507903

Epoch: 6| Step: 10
Training loss: 2.978233814239502
Validation loss: 2.0255979978910057

Epoch: 6| Step: 11
Training loss: 2.0730624198913574
Validation loss: 2.018436703630673

Epoch: 6| Step: 12
Training loss: 2.393275737762451
Validation loss: 2.0211314462846324

Epoch: 6| Step: 13
Training loss: 1.8618426322937012
Validation loss: 2.0323184087712276

Epoch: 73| Step: 0
Training loss: 2.7451038360595703
Validation loss: 2.036280865310341

Epoch: 6| Step: 1
Training loss: 2.019636869430542
Validation loss: 2.045283741848443

Epoch: 6| Step: 2
Training loss: 1.9911515712738037
Validation loss: 2.026008181674506

Epoch: 6| Step: 3
Training loss: 2.8130362033843994
Validation loss: 2.068602964442263

Epoch: 6| Step: 4
Training loss: 2.949051856994629
Validation loss: 2.065969838890978

Epoch: 6| Step: 5
Training loss: 1.8881502151489258
Validation loss: 2.052315858102614

Epoch: 6| Step: 6
Training loss: 2.4911437034606934
Validation loss: 2.0506455180465535

Epoch: 6| Step: 7
Training loss: 2.0803632736206055
Validation loss: 2.054028440547246

Epoch: 6| Step: 8
Training loss: 1.8015192747116089
Validation loss: 2.0471094321179133

Epoch: 6| Step: 9
Training loss: 2.2581050395965576
Validation loss: 2.0690881411234536

Epoch: 6| Step: 10
Training loss: 2.7549326419830322
Validation loss: 2.053863139562709

Epoch: 6| Step: 11
Training loss: 2.0292587280273438
Validation loss: 2.0737262054156234

Epoch: 6| Step: 12
Training loss: 1.934523344039917
Validation loss: 2.0441094803553757

Epoch: 6| Step: 13
Training loss: 2.016676664352417
Validation loss: 2.0611481999838226

Epoch: 74| Step: 0
Training loss: 2.3828811645507812
Validation loss: 2.0711106228572067

Epoch: 6| Step: 1
Training loss: 2.3846170902252197
Validation loss: 2.0692662398020425

Epoch: 6| Step: 2
Training loss: 2.2172436714172363
Validation loss: 2.0472627737188853

Epoch: 6| Step: 3
Training loss: 1.5473058223724365
Validation loss: 2.0537361188601424

Epoch: 6| Step: 4
Training loss: 2.193619966506958
Validation loss: 2.0462053770660074

Epoch: 6| Step: 5
Training loss: 2.189727783203125
Validation loss: 2.0454497247613888

Epoch: 6| Step: 6
Training loss: 2.405461072921753
Validation loss: 2.05366975004955

Epoch: 6| Step: 7
Training loss: 2.3912415504455566
Validation loss: 2.043569826310681

Epoch: 6| Step: 8
Training loss: 2.4634933471679688
Validation loss: 2.043850989751918

Epoch: 6| Step: 9
Training loss: 2.9421961307525635
Validation loss: 2.0528678227496404

Epoch: 6| Step: 10
Training loss: 2.24518084526062
Validation loss: 2.050578450643888

Epoch: 6| Step: 11
Training loss: 2.0612473487854004
Validation loss: 2.0494579115221576

Epoch: 6| Step: 12
Training loss: 2.0231704711914062
Validation loss: 2.0576997700557915

Epoch: 6| Step: 13
Training loss: 2.6292150020599365
Validation loss: 2.0410457605956704

Epoch: 75| Step: 0
Training loss: 2.141899585723877
Validation loss: 2.04265409387568

Epoch: 6| Step: 1
Training loss: 2.8253915309906006
Validation loss: 2.0528273505549275

Epoch: 6| Step: 2
Training loss: 2.5167226791381836
Validation loss: 2.040407317940907

Epoch: 6| Step: 3
Training loss: 2.553431272506714
Validation loss: 2.0358881258195445

Epoch: 6| Step: 4
Training loss: 2.174222946166992
Validation loss: 2.0388276923087334

Epoch: 6| Step: 5
Training loss: 2.6974058151245117
Validation loss: 2.0338115089683124

Epoch: 6| Step: 6
Training loss: 2.4146995544433594
Validation loss: 2.0521990996535107

Epoch: 6| Step: 7
Training loss: 1.9073245525360107
Validation loss: 2.051156614416389

Epoch: 6| Step: 8
Training loss: 2.2771706581115723
Validation loss: 2.0383371973550446

Epoch: 6| Step: 9
Training loss: 2.3751494884490967
Validation loss: 2.062216551073136

Epoch: 6| Step: 10
Training loss: 1.7651126384735107
Validation loss: 2.0408362983375468

Epoch: 6| Step: 11
Training loss: 2.011324405670166
Validation loss: 2.0526952384620585

Epoch: 6| Step: 12
Training loss: 2.479414463043213
Validation loss: 2.049450420564221

Epoch: 6| Step: 13
Training loss: 1.2017415761947632
Validation loss: 2.045686298801053

Epoch: 76| Step: 0
Training loss: 2.243718147277832
Validation loss: 2.0514747096646215

Epoch: 6| Step: 1
Training loss: 2.091797351837158
Validation loss: 2.0562640287542857

Epoch: 6| Step: 2
Training loss: 2.463157892227173
Validation loss: 2.0580281096120037

Epoch: 6| Step: 3
Training loss: 2.1162197589874268
Validation loss: 2.0372249541744107

Epoch: 6| Step: 4
Training loss: 2.520596504211426
Validation loss: 2.003455505576185

Epoch: 6| Step: 5
Training loss: 1.7353966236114502
Validation loss: 2.0300623268209477

Epoch: 6| Step: 6
Training loss: 2.3914778232574463
Validation loss: 2.022852791252957

Epoch: 6| Step: 7
Training loss: 1.9847395420074463
Validation loss: 2.016221915521929

Epoch: 6| Step: 8
Training loss: 2.6750097274780273
Validation loss: 2.0209589914609025

Epoch: 6| Step: 9
Training loss: 2.3369760513305664
Validation loss: 2.0194880116370415

Epoch: 6| Step: 10
Training loss: 2.3390891551971436
Validation loss: 2.029142156724007

Epoch: 6| Step: 11
Training loss: 2.249239921569824
Validation loss: 2.012291266072181

Epoch: 6| Step: 12
Training loss: 2.5059096813201904
Validation loss: 1.9999149281491515

Epoch: 6| Step: 13
Training loss: 2.0647265911102295
Validation loss: 2.009593866204703

Epoch: 77| Step: 0
Training loss: 2.7713353633880615
Validation loss: 2.0224532940054454

Epoch: 6| Step: 1
Training loss: 1.9029808044433594
Validation loss: 2.010241646920481

Epoch: 6| Step: 2
Training loss: 1.7383973598480225
Validation loss: 2.0200259147151822

Epoch: 6| Step: 3
Training loss: 1.6652023792266846
Validation loss: 2.034864043676725

Epoch: 6| Step: 4
Training loss: 2.214860200881958
Validation loss: 1.9964688401068411

Epoch: 6| Step: 5
Training loss: 2.2261815071105957
Validation loss: 2.025559017735143

Epoch: 6| Step: 6
Training loss: 2.605461597442627
Validation loss: 2.0187588007219377

Epoch: 6| Step: 7
Training loss: 2.712153911590576
Validation loss: 2.0202029366647043

Epoch: 6| Step: 8
Training loss: 2.8572795391082764
Validation loss: 2.021136135183355

Epoch: 6| Step: 9
Training loss: 2.1438019275665283
Validation loss: 2.0282591414707962

Epoch: 6| Step: 10
Training loss: 1.7333908081054688
Validation loss: 2.0358368965887252

Epoch: 6| Step: 11
Training loss: 2.2043488025665283
Validation loss: 2.0388634743229037

Epoch: 6| Step: 12
Training loss: 2.893019437789917
Validation loss: 2.020076294099131

Epoch: 6| Step: 13
Training loss: 2.1663010120391846
Validation loss: 2.0349953200227473

Epoch: 78| Step: 0
Training loss: 2.4668426513671875
Validation loss: 2.0488525975135063

Epoch: 6| Step: 1
Training loss: 2.8091917037963867
Validation loss: 2.03592058150999

Epoch: 6| Step: 2
Training loss: 1.371034860610962
Validation loss: 2.0172485869417907

Epoch: 6| Step: 3
Training loss: 2.428034782409668
Validation loss: 2.0469183511631464

Epoch: 6| Step: 4
Training loss: 2.3501830101013184
Validation loss: 2.058347826362938

Epoch: 6| Step: 5
Training loss: 1.7029422521591187
Validation loss: 2.076551834742228

Epoch: 6| Step: 6
Training loss: 1.4812078475952148
Validation loss: 2.0705691729822466

Epoch: 6| Step: 7
Training loss: 2.6723179817199707
Validation loss: 2.0481120437704106

Epoch: 6| Step: 8
Training loss: 2.2314090728759766
Validation loss: 2.055706347188642

Epoch: 6| Step: 9
Training loss: 1.9510481357574463
Validation loss: 2.0516698565534366

Epoch: 6| Step: 10
Training loss: 2.007141590118408
Validation loss: 2.0656343403682915

Epoch: 6| Step: 11
Training loss: 2.9798574447631836
Validation loss: 2.0594078392110844

Epoch: 6| Step: 12
Training loss: 2.7445695400238037
Validation loss: 2.056684801655431

Epoch: 6| Step: 13
Training loss: 2.9109301567077637
Validation loss: 2.069256249294486

Epoch: 79| Step: 0
Training loss: 1.8110028505325317
Validation loss: 2.0365527957998295

Epoch: 6| Step: 1
Training loss: 2.7801830768585205
Validation loss: 2.065329638860559

Epoch: 6| Step: 2
Training loss: 2.8671460151672363
Validation loss: 2.0550792601800736

Epoch: 6| Step: 3
Training loss: 2.4460318088531494
Validation loss: 2.0464867494439565

Epoch: 6| Step: 4
Training loss: 2.5546905994415283
Validation loss: 2.0459737752073552

Epoch: 6| Step: 5
Training loss: 2.365168333053589
Validation loss: 2.0473392548099643

Epoch: 6| Step: 6
Training loss: 1.6043791770935059
Validation loss: 2.0315864521970033

Epoch: 6| Step: 7
Training loss: 1.935962200164795
Validation loss: 2.04997915990891

Epoch: 6| Step: 8
Training loss: 2.5002899169921875
Validation loss: 2.048678236622964

Epoch: 6| Step: 9
Training loss: 2.1877007484436035
Validation loss: 2.037301835193429

Epoch: 6| Step: 10
Training loss: 2.4263088703155518
Validation loss: 2.051973772305314

Epoch: 6| Step: 11
Training loss: 2.932589530944824
Validation loss: 2.0457854194025837

Epoch: 6| Step: 12
Training loss: 1.6076765060424805
Validation loss: 2.064091972125474

Epoch: 6| Step: 13
Training loss: 1.7106661796569824
Validation loss: 2.047242928576726

Epoch: 80| Step: 0
Training loss: 2.449314832687378
Validation loss: 2.0401602522019417

Epoch: 6| Step: 1
Training loss: 2.460969924926758
Validation loss: 2.0681845911087526

Epoch: 6| Step: 2
Training loss: 1.8060030937194824
Validation loss: 2.0353990088226976

Epoch: 6| Step: 3
Training loss: 2.1719162464141846
Validation loss: 2.038508406249426

Epoch: 6| Step: 4
Training loss: 2.210268974304199
Validation loss: 2.049093423351165

Epoch: 6| Step: 5
Training loss: 2.328010082244873
Validation loss: 2.0428454645218386

Epoch: 6| Step: 6
Training loss: 2.119896411895752
Validation loss: 2.0251036574763637

Epoch: 6| Step: 7
Training loss: 2.2165353298187256
Validation loss: 2.0179657269549627

Epoch: 6| Step: 8
Training loss: 1.9009230136871338
Validation loss: 2.0347895891435686

Epoch: 6| Step: 9
Training loss: 2.1437721252441406
Validation loss: 2.027188313904629

Epoch: 6| Step: 10
Training loss: 2.275831937789917
Validation loss: 2.0249158759270944

Epoch: 6| Step: 11
Training loss: 3.0751023292541504
Validation loss: 1.996066206245012

Epoch: 6| Step: 12
Training loss: 2.3536171913146973
Validation loss: 2.016265300012404

Epoch: 6| Step: 13
Training loss: 1.6975754499435425
Validation loss: 2.0269152887405886

Epoch: 81| Step: 0
Training loss: 2.1548643112182617
Validation loss: 2.024564112386396

Epoch: 6| Step: 1
Training loss: 2.6482534408569336
Validation loss: 2.0291389573004937

Epoch: 6| Step: 2
Training loss: 1.4734567403793335
Validation loss: 2.0201078473880725

Epoch: 6| Step: 3
Training loss: 2.544795036315918
Validation loss: 2.013831183474551

Epoch: 6| Step: 4
Training loss: 2.004223108291626
Validation loss: 1.9993738820475917

Epoch: 6| Step: 5
Training loss: 1.9395759105682373
Validation loss: 2.0105803769121886

Epoch: 6| Step: 6
Training loss: 2.705920696258545
Validation loss: 2.0190911049483926

Epoch: 6| Step: 7
Training loss: 2.3781447410583496
Validation loss: 2.029121429689469

Epoch: 6| Step: 8
Training loss: 2.663501262664795
Validation loss: 1.9933807542247157

Epoch: 6| Step: 9
Training loss: 2.441568374633789
Validation loss: 2.032432488215867

Epoch: 6| Step: 10
Training loss: 2.701934337615967
Validation loss: 2.0108375062224684

Epoch: 6| Step: 11
Training loss: 1.7924025058746338
Validation loss: 2.0239415091852986

Epoch: 6| Step: 12
Training loss: 2.0803306102752686
Validation loss: 2.0345269044240317

Epoch: 6| Step: 13
Training loss: 1.6824443340301514
Validation loss: 2.017904476452899

Epoch: 82| Step: 0
Training loss: 1.8333868980407715
Validation loss: 2.032312418824883

Epoch: 6| Step: 1
Training loss: 2.21235990524292
Validation loss: 2.032789227783039

Epoch: 6| Step: 2
Training loss: 1.8823935985565186
Validation loss: 2.0264522721690517

Epoch: 6| Step: 3
Training loss: 2.5924386978149414
Validation loss: 2.013441962580527

Epoch: 6| Step: 4
Training loss: 2.0912485122680664
Validation loss: 2.0431733439045567

Epoch: 6| Step: 5
Training loss: 2.3661675453186035
Validation loss: 2.0445431996417303

Epoch: 6| Step: 6
Training loss: 2.931605339050293
Validation loss: 2.0334679260048816

Epoch: 6| Step: 7
Training loss: 2.4770667552948
Validation loss: 2.040399774428337

Epoch: 6| Step: 8
Training loss: 2.1168601512908936
Validation loss: 2.04264094239922

Epoch: 6| Step: 9
Training loss: 1.5704302787780762
Validation loss: 2.0484169516512143

Epoch: 6| Step: 10
Training loss: 1.7670435905456543
Validation loss: 2.048374629789783

Epoch: 6| Step: 11
Training loss: 2.836848258972168
Validation loss: 2.0319395014034805

Epoch: 6| Step: 12
Training loss: 2.431920051574707
Validation loss: 2.0407180196495465

Epoch: 6| Step: 13
Training loss: 2.510678768157959
Validation loss: 2.0387475849479757

Epoch: 83| Step: 0
Training loss: 2.3104443550109863
Validation loss: 2.038208547458854

Epoch: 6| Step: 1
Training loss: 2.2316465377807617
Validation loss: 2.0630458772823377

Epoch: 6| Step: 2
Training loss: 2.3396189212799072
Validation loss: 2.016293018094955

Epoch: 6| Step: 3
Training loss: 2.4919705390930176
Validation loss: 2.0436478353315786

Epoch: 6| Step: 4
Training loss: 2.138277053833008
Validation loss: 2.0342017937732

Epoch: 6| Step: 5
Training loss: 1.9303224086761475
Validation loss: 2.0569499102971887

Epoch: 6| Step: 6
Training loss: 2.3662054538726807
Validation loss: 2.0667525337588404

Epoch: 6| Step: 7
Training loss: 2.9963631629943848
Validation loss: 2.064514152465328

Epoch: 6| Step: 8
Training loss: 1.910506248474121
Validation loss: 2.0655414365953013

Epoch: 6| Step: 9
Training loss: 2.1705362796783447
Validation loss: 2.0622847695504465

Epoch: 6| Step: 10
Training loss: 2.1292498111724854
Validation loss: 2.0686371557174192

Epoch: 6| Step: 11
Training loss: 2.311983823776245
Validation loss: 2.0519322990089335

Epoch: 6| Step: 12
Training loss: 2.602397918701172
Validation loss: 2.0438410441080728

Epoch: 6| Step: 13
Training loss: 1.0861029624938965
Validation loss: 2.042213632214454

Epoch: 84| Step: 0
Training loss: 2.690235137939453
Validation loss: 2.0396735770728

Epoch: 6| Step: 1
Training loss: 2.6131839752197266
Validation loss: 2.040040405847693

Epoch: 6| Step: 2
Training loss: 1.814218521118164
Validation loss: 2.019183148619949

Epoch: 6| Step: 3
Training loss: 1.831505537033081
Validation loss: 2.0362018090422436

Epoch: 6| Step: 4
Training loss: 2.569523334503174
Validation loss: 2.050200209822706

Epoch: 6| Step: 5
Training loss: 2.257688522338867
Validation loss: 2.029797887289396

Epoch: 6| Step: 6
Training loss: 2.9240283966064453
Validation loss: 2.04284865625443

Epoch: 6| Step: 7
Training loss: 2.235508680343628
Validation loss: 2.0404459866144324

Epoch: 6| Step: 8
Training loss: 1.8579473495483398
Validation loss: 2.0647463670340915

Epoch: 6| Step: 9
Training loss: 2.227997064590454
Validation loss: 2.02950349930794

Epoch: 6| Step: 10
Training loss: 1.6849592924118042
Validation loss: 2.0396082106456963

Epoch: 6| Step: 11
Training loss: 2.689614772796631
Validation loss: 2.029178592466539

Epoch: 6| Step: 12
Training loss: 1.9855809211730957
Validation loss: 2.0282735965585195

Epoch: 6| Step: 13
Training loss: 1.9779614210128784
Validation loss: 2.0399297847542712

Epoch: 85| Step: 0
Training loss: 2.1449663639068604
Validation loss: 2.0228412689701205

Epoch: 6| Step: 1
Training loss: 1.731528401374817
Validation loss: 2.038158103983889

Epoch: 6| Step: 2
Training loss: 2.222198009490967
Validation loss: 2.0307802051626225

Epoch: 6| Step: 3
Training loss: 2.998619556427002
Validation loss: 2.0160207979140745

Epoch: 6| Step: 4
Training loss: 1.533402442932129
Validation loss: 2.0296517315731255

Epoch: 6| Step: 5
Training loss: 2.376600503921509
Validation loss: 1.999185747997735

Epoch: 6| Step: 6
Training loss: 2.3701913356781006
Validation loss: 2.0182998539299093

Epoch: 6| Step: 7
Training loss: 2.5701444149017334
Validation loss: 2.017234880437133

Epoch: 6| Step: 8
Training loss: 2.0700414180755615
Validation loss: 2.0296216011047363

Epoch: 6| Step: 9
Training loss: 2.915158987045288
Validation loss: 2.031330180424516

Epoch: 6| Step: 10
Training loss: 1.7888075113296509
Validation loss: 2.0447852816633

Epoch: 6| Step: 11
Training loss: 2.22739839553833
Validation loss: 2.028164496985815

Epoch: 6| Step: 12
Training loss: 2.5320894718170166
Validation loss: 2.024194040606099

Epoch: 6| Step: 13
Training loss: 1.7960915565490723
Validation loss: 2.0188368264064995

Epoch: 86| Step: 0
Training loss: 2.0484726428985596
Validation loss: 2.020766573567544

Epoch: 6| Step: 1
Training loss: 2.721043586730957
Validation loss: 2.018539651747673

Epoch: 6| Step: 2
Training loss: 2.1948060989379883
Validation loss: 2.049838968502578

Epoch: 6| Step: 3
Training loss: 2.5427374839782715
Validation loss: 2.0525267957359232

Epoch: 6| Step: 4
Training loss: 1.8429677486419678
Validation loss: 2.0395689805348716

Epoch: 6| Step: 5
Training loss: 1.9538246393203735
Validation loss: 2.0513808727264404

Epoch: 6| Step: 6
Training loss: 2.3287887573242188
Validation loss: 2.0484873197411977

Epoch: 6| Step: 7
Training loss: 2.3338470458984375
Validation loss: 2.0507309231706845

Epoch: 6| Step: 8
Training loss: 1.4908250570297241
Validation loss: 2.045595568995322

Epoch: 6| Step: 9
Training loss: 2.8138415813446045
Validation loss: 2.0300906396681264

Epoch: 6| Step: 10
Training loss: 2.3379197120666504
Validation loss: 2.0487071878166607

Epoch: 6| Step: 11
Training loss: 2.186213493347168
Validation loss: 2.0397329356080744

Epoch: 6| Step: 12
Training loss: 2.5116734504699707
Validation loss: 2.0688109038978495

Epoch: 6| Step: 13
Training loss: 2.1321399211883545
Validation loss: 2.0374324885747765

Epoch: 87| Step: 0
Training loss: 2.5811285972595215
Validation loss: 2.0414521822365383

Epoch: 6| Step: 1
Training loss: 2.0417165756225586
Validation loss: 2.058074197461528

Epoch: 6| Step: 2
Training loss: 2.1014392375946045
Validation loss: 2.0475538828039683

Epoch: 6| Step: 3
Training loss: 2.549668788909912
Validation loss: 2.0457412324925905

Epoch: 6| Step: 4
Training loss: 2.444317102432251
Validation loss: 2.0444338988232356

Epoch: 6| Step: 5
Training loss: 1.776490330696106
Validation loss: 2.054171298139839

Epoch: 6| Step: 6
Training loss: 1.9703582525253296
Validation loss: 2.048974524262131

Epoch: 6| Step: 7
Training loss: 2.1383557319641113
Validation loss: 2.046638757951798

Epoch: 6| Step: 8
Training loss: 2.308411121368408
Validation loss: 2.0328356501876668

Epoch: 6| Step: 9
Training loss: 2.0032455921173096
Validation loss: 2.0597419379859843

Epoch: 6| Step: 10
Training loss: 2.4827473163604736
Validation loss: 2.02517548940515

Epoch: 6| Step: 11
Training loss: 2.4080934524536133
Validation loss: 2.0489523474888136

Epoch: 6| Step: 12
Training loss: 2.3624267578125
Validation loss: 2.0342650105876308

Epoch: 6| Step: 13
Training loss: 2.35080623626709
Validation loss: 2.0682327619162937

Epoch: 88| Step: 0
Training loss: 2.2608819007873535
Validation loss: 2.029203817408572

Epoch: 6| Step: 1
Training loss: 2.092923402786255
Validation loss: 2.0489489468195106

Epoch: 6| Step: 2
Training loss: 1.6009905338287354
Validation loss: 2.059842032770957

Epoch: 6| Step: 3
Training loss: 2.3616795539855957
Validation loss: 2.0480458967147337

Epoch: 6| Step: 4
Training loss: 2.256772756576538
Validation loss: 2.047729730606079

Epoch: 6| Step: 5
Training loss: 2.2347028255462646
Validation loss: 2.027237514013885

Epoch: 6| Step: 6
Training loss: 2.4628512859344482
Validation loss: 2.048891757124214

Epoch: 6| Step: 7
Training loss: 2.2616209983825684
Validation loss: 2.0313706205737208

Epoch: 6| Step: 8
Training loss: 1.9790053367614746
Validation loss: 2.032474513976805

Epoch: 6| Step: 9
Training loss: 1.5400760173797607
Validation loss: 2.0229658657504666

Epoch: 6| Step: 10
Training loss: 2.4733986854553223
Validation loss: 2.0368036762360604

Epoch: 6| Step: 11
Training loss: 2.9400124549865723
Validation loss: 2.0313166392746793

Epoch: 6| Step: 12
Training loss: 2.588069438934326
Validation loss: 2.03592392834284

Epoch: 6| Step: 13
Training loss: 2.4101293087005615
Validation loss: 2.025831401989024

Epoch: 89| Step: 0
Training loss: 2.841614246368408
Validation loss: 2.016025694467688

Epoch: 6| Step: 1
Training loss: 2.7854833602905273
Validation loss: 2.0449687742417857

Epoch: 6| Step: 2
Training loss: 1.8769091367721558
Validation loss: 2.0338130740709204

Epoch: 6| Step: 3
Training loss: 2.247303009033203
Validation loss: 2.024199808797529

Epoch: 6| Step: 4
Training loss: 1.8200645446777344
Validation loss: 2.04644561582996

Epoch: 6| Step: 5
Training loss: 2.1525192260742188
Validation loss: 2.0336374851965133

Epoch: 6| Step: 6
Training loss: 1.292710542678833
Validation loss: 2.05801575158232

Epoch: 6| Step: 7
Training loss: 1.0211158990859985
Validation loss: 2.060684702729666

Epoch: 6| Step: 8
Training loss: 2.342266798019409
Validation loss: 2.0470719875827914

Epoch: 6| Step: 9
Training loss: 2.822234869003296
Validation loss: 2.060420657998772

Epoch: 6| Step: 10
Training loss: 2.2986817359924316
Validation loss: 2.0593112245682748

Epoch: 6| Step: 11
Training loss: 2.370818853378296
Validation loss: 2.0490750189750426

Epoch: 6| Step: 12
Training loss: 2.8516016006469727
Validation loss: 2.0611961451909875

Epoch: 6| Step: 13
Training loss: 3.0746028423309326
Validation loss: 2.0708494776038715

Epoch: 90| Step: 0
Training loss: 2.660597085952759
Validation loss: 2.0259729367430492

Epoch: 6| Step: 1
Training loss: 1.9857347011566162
Validation loss: 2.0373924368171283

Epoch: 6| Step: 2
Training loss: 1.7808747291564941
Validation loss: 2.018293780665244

Epoch: 6| Step: 3
Training loss: 1.5867228507995605
Validation loss: 2.0762613306763353

Epoch: 6| Step: 4
Training loss: 2.6469216346740723
Validation loss: 2.0583765801563056

Epoch: 6| Step: 5
Training loss: 1.9511672258377075
Validation loss: 2.05399489402771

Epoch: 6| Step: 6
Training loss: 2.6504061222076416
Validation loss: 2.0547487633202666

Epoch: 6| Step: 7
Training loss: 2.817326784133911
Validation loss: 2.0486705700556436

Epoch: 6| Step: 8
Training loss: 2.119473695755005
Validation loss: 2.079061887597525

Epoch: 6| Step: 9
Training loss: 2.3555097579956055
Validation loss: 2.0551241149184523

Epoch: 6| Step: 10
Training loss: 2.52286958694458
Validation loss: 2.072875198497567

Epoch: 6| Step: 11
Training loss: 2.455873966217041
Validation loss: 2.050296523237741

Epoch: 6| Step: 12
Training loss: 1.3630304336547852
Validation loss: 2.0444100159470753

Epoch: 6| Step: 13
Training loss: 2.9926395416259766
Validation loss: 2.0586478043627996

Epoch: 91| Step: 0
Training loss: 2.2255680561065674
Validation loss: 2.0491219951260473

Epoch: 6| Step: 1
Training loss: 1.8101059198379517
Validation loss: 2.031365922702256

Epoch: 6| Step: 2
Training loss: 1.548195481300354
Validation loss: 2.037841817384125

Epoch: 6| Step: 3
Training loss: 2.6246190071105957
Validation loss: 2.063404301161407

Epoch: 6| Step: 4
Training loss: 2.0672850608825684
Validation loss: 2.0440352398862123

Epoch: 6| Step: 5
Training loss: 2.1731998920440674
Validation loss: 2.030508689982917

Epoch: 6| Step: 6
Training loss: 2.4792892932891846
Validation loss: 2.0557711765330327

Epoch: 6| Step: 7
Training loss: 2.1573686599731445
Validation loss: 2.029506701295094

Epoch: 6| Step: 8
Training loss: 2.7382144927978516
Validation loss: 2.0436915607862574

Epoch: 6| Step: 9
Training loss: 2.0643277168273926
Validation loss: 2.0516733456683416

Epoch: 6| Step: 10
Training loss: 2.292249917984009
Validation loss: 2.0471419826630624

Epoch: 6| Step: 11
Training loss: 2.154597759246826
Validation loss: 2.023241344318595

Epoch: 6| Step: 12
Training loss: 2.412776231765747
Validation loss: 2.0471043099639235

Epoch: 6| Step: 13
Training loss: 2.683194160461426
Validation loss: 2.036653226421725

Epoch: 92| Step: 0
Training loss: 2.283602476119995
Validation loss: 2.033514242018423

Epoch: 6| Step: 1
Training loss: 2.391223907470703
Validation loss: 2.048708720873761

Epoch: 6| Step: 2
Training loss: 2.6138384342193604
Validation loss: 2.02232406344465

Epoch: 6| Step: 3
Training loss: 2.144430637359619
Validation loss: 2.0445130743006223

Epoch: 6| Step: 4
Training loss: 2.391171932220459
Validation loss: 2.0287707313414542

Epoch: 6| Step: 5
Training loss: 2.065826892852783
Validation loss: 2.037294937718299

Epoch: 6| Step: 6
Training loss: 2.3403210639953613
Validation loss: 2.0467147173420077

Epoch: 6| Step: 7
Training loss: 1.9828274250030518
Validation loss: 2.0240520610604236

Epoch: 6| Step: 8
Training loss: 1.997600793838501
Validation loss: 2.043803817482405

Epoch: 6| Step: 9
Training loss: 2.408282995223999
Validation loss: 2.0517946417613695

Epoch: 6| Step: 10
Training loss: 1.2821019887924194
Validation loss: 2.0215906917407946

Epoch: 6| Step: 11
Training loss: 2.147618293762207
Validation loss: 2.025518566049555

Epoch: 6| Step: 12
Training loss: 2.655534505844116
Validation loss: 2.0223822709052794

Epoch: 6| Step: 13
Training loss: 2.617321491241455
Validation loss: 2.016129909023162

Epoch: 93| Step: 0
Training loss: 1.345984935760498
Validation loss: 2.025616785531403

Epoch: 6| Step: 1
Training loss: 1.7691001892089844
Validation loss: 2.011864694215918

Epoch: 6| Step: 2
Training loss: 1.8173539638519287
Validation loss: 2.0562831650498095

Epoch: 6| Step: 3
Training loss: 2.1245477199554443
Validation loss: 2.0371596582474245

Epoch: 6| Step: 4
Training loss: 1.8128716945648193
Validation loss: 2.042303930046738

Epoch: 6| Step: 5
Training loss: 2.2991254329681396
Validation loss: 2.081963699351075

Epoch: 6| Step: 6
Training loss: 1.9057559967041016
Validation loss: 2.075761431006975

Epoch: 6| Step: 7
Training loss: 2.4992456436157227
Validation loss: 2.03698036747594

Epoch: 6| Step: 8
Training loss: 3.427365303039551
Validation loss: 2.05115496471364

Epoch: 6| Step: 9
Training loss: 2.5018186569213867
Validation loss: 2.0564837301931074

Epoch: 6| Step: 10
Training loss: 2.0522756576538086
Validation loss: 2.0452801322424286

Epoch: 6| Step: 11
Training loss: 2.910463333129883
Validation loss: 2.0355241170493503

Epoch: 6| Step: 12
Training loss: 2.492683172225952
Validation loss: 2.0730268480957195

Epoch: 6| Step: 13
Training loss: 2.5367932319641113
Validation loss: 2.05383966558723

Epoch: 94| Step: 0
Training loss: 2.1620819568634033
Validation loss: 2.040360966036397

Epoch: 6| Step: 1
Training loss: 2.894123077392578
Validation loss: 2.077294618852677

Epoch: 6| Step: 2
Training loss: 2.23203706741333
Validation loss: 2.0553064705223165

Epoch: 6| Step: 3
Training loss: 2.170729637145996
Validation loss: 2.062240574949531

Epoch: 6| Step: 4
Training loss: 1.9738024473190308
Validation loss: 2.0656144336987565

Epoch: 6| Step: 5
Training loss: 2.055903911590576
Validation loss: 2.0641453817326534

Epoch: 6| Step: 6
Training loss: 2.9377565383911133
Validation loss: 2.0486280277211177

Epoch: 6| Step: 7
Training loss: 2.251215934753418
Validation loss: 2.0664461620392336

Epoch: 6| Step: 8
Training loss: 2.031090497970581
Validation loss: 2.0560262100670927

Epoch: 6| Step: 9
Training loss: 1.5796996355056763
Validation loss: 2.0550420655999133

Epoch: 6| Step: 10
Training loss: 2.1129584312438965
Validation loss: 2.0472316780397968

Epoch: 6| Step: 11
Training loss: 2.181725025177002
Validation loss: 2.0619496504465737

Epoch: 6| Step: 12
Training loss: 2.585820198059082
Validation loss: 2.0441019035154775

Epoch: 6| Step: 13
Training loss: 1.8808403015136719
Validation loss: 2.058343102855067

Epoch: 95| Step: 0
Training loss: 2.500498056411743
Validation loss: 2.0637989697917813

Epoch: 6| Step: 1
Training loss: 2.6144776344299316
Validation loss: 2.0682697898598126

Epoch: 6| Step: 2
Training loss: 2.42911958694458
Validation loss: 2.0475663690156836

Epoch: 6| Step: 3
Training loss: 2.5742480754852295
Validation loss: 2.036201197613952

Epoch: 6| Step: 4
Training loss: 2.7556262016296387
Validation loss: 2.065855704328065

Epoch: 6| Step: 5
Training loss: 2.3163907527923584
Validation loss: 2.038337899792579

Epoch: 6| Step: 6
Training loss: 2.6612889766693115
Validation loss: 2.0332225343232513

Epoch: 6| Step: 7
Training loss: 2.1610307693481445
Validation loss: 2.048286707170548

Epoch: 6| Step: 8
Training loss: 2.4049646854400635
Validation loss: 2.0435433772302445

Epoch: 6| Step: 9
Training loss: 1.950148582458496
Validation loss: 2.0407925639101254

Epoch: 6| Step: 10
Training loss: 1.7012466192245483
Validation loss: 2.049776884817308

Epoch: 6| Step: 11
Training loss: 1.9567886590957642
Validation loss: 2.045422932153107

Epoch: 6| Step: 12
Training loss: 1.6777000427246094
Validation loss: 2.0278349025275118

Epoch: 6| Step: 13
Training loss: 1.5363249778747559
Validation loss: 2.03875107021742

Epoch: 96| Step: 0
Training loss: 1.9151356220245361
Validation loss: 2.0383459970515263

Epoch: 6| Step: 1
Training loss: 2.775899887084961
Validation loss: 2.0253073156520887

Epoch: 6| Step: 2
Training loss: 2.464400291442871
Validation loss: 2.0181602124244935

Epoch: 6| Step: 3
Training loss: 2.4587574005126953
Validation loss: 2.0394969319784515

Epoch: 6| Step: 4
Training loss: 2.3718228340148926
Validation loss: 2.03333616769442

Epoch: 6| Step: 5
Training loss: 2.2915937900543213
Validation loss: 2.043898494012894

Epoch: 6| Step: 6
Training loss: 2.6519346237182617
Validation loss: 2.017256421427573

Epoch: 6| Step: 7
Training loss: 2.144831657409668
Validation loss: 2.004776349631689

Epoch: 6| Step: 8
Training loss: 2.2407784461975098
Validation loss: 2.035759069586313

Epoch: 6| Step: 9
Training loss: 1.9275251626968384
Validation loss: 2.027874764575753

Epoch: 6| Step: 10
Training loss: 2.067317485809326
Validation loss: 2.0223224111782607

Epoch: 6| Step: 11
Training loss: 1.7661129236221313
Validation loss: 2.0071781924975816

Epoch: 6| Step: 12
Training loss: 2.090864896774292
Validation loss: 2.0322993429758216

Epoch: 6| Step: 13
Training loss: 1.9297016859054565
Validation loss: 2.0209947068204164

Epoch: 97| Step: 0
Training loss: 2.3979997634887695
Validation loss: 2.022663973992871

Epoch: 6| Step: 1
Training loss: 2.4811110496520996
Validation loss: 2.0165179711516186

Epoch: 6| Step: 2
Training loss: 2.5474400520324707
Validation loss: 2.0082099488986436

Epoch: 6| Step: 3
Training loss: 2.231471300125122
Validation loss: 2.0159145247551704

Epoch: 6| Step: 4
Training loss: 1.914841651916504
Validation loss: 2.0357911638034287

Epoch: 6| Step: 5
Training loss: 2.6093482971191406
Validation loss: 2.001055622613558

Epoch: 6| Step: 6
Training loss: 2.2490768432617188
Validation loss: 2.031209925169586

Epoch: 6| Step: 7
Training loss: 1.9000849723815918
Validation loss: 2.0419985594287997

Epoch: 6| Step: 8
Training loss: 1.9315332174301147
Validation loss: 2.059326967885417

Epoch: 6| Step: 9
Training loss: 2.1696524620056152
Validation loss: 2.04117299279859

Epoch: 6| Step: 10
Training loss: 2.4679269790649414
Validation loss: 2.055744242924516

Epoch: 6| Step: 11
Training loss: 2.2568483352661133
Validation loss: 2.052635314644024

Epoch: 6| Step: 12
Training loss: 2.149280548095703
Validation loss: 2.0568942100771013

Epoch: 6| Step: 13
Training loss: 1.9313443899154663
Validation loss: 2.0591922395972797

Epoch: 98| Step: 0
Training loss: 2.4565019607543945
Validation loss: 2.081692777654176

Epoch: 6| Step: 1
Training loss: 1.8774659633636475
Validation loss: 2.065982413548295

Epoch: 6| Step: 2
Training loss: 2.304661273956299
Validation loss: 2.0750639771902435

Epoch: 6| Step: 3
Training loss: 1.9357757568359375
Validation loss: 2.090622341761025

Epoch: 6| Step: 4
Training loss: 2.6392807960510254
Validation loss: 2.079788000352921

Epoch: 6| Step: 5
Training loss: 2.0973496437072754
Validation loss: 2.062979926345169

Epoch: 6| Step: 6
Training loss: 1.9586180448532104
Validation loss: 2.089723644718047

Epoch: 6| Step: 7
Training loss: 2.860640048980713
Validation loss: 2.0761943158283027

Epoch: 6| Step: 8
Training loss: 2.8623740673065186
Validation loss: 2.0784215158031834

Epoch: 6| Step: 9
Training loss: 2.0814220905303955
Validation loss: 2.102885825659639

Epoch: 6| Step: 10
Training loss: 2.0705370903015137
Validation loss: 2.075385137270856

Epoch: 6| Step: 11
Training loss: 2.888397216796875
Validation loss: 2.067304557369601

Epoch: 6| Step: 12
Training loss: 1.2123277187347412
Validation loss: 2.0746560468468616

Epoch: 6| Step: 13
Training loss: 1.8398083448410034
Validation loss: 2.0785353401655793

Epoch: 99| Step: 0
Training loss: 2.5596466064453125
Validation loss: 2.1211762915375414

Epoch: 6| Step: 1
Training loss: 1.4152183532714844
Validation loss: 2.057712044767154

Epoch: 6| Step: 2
Training loss: 2.701561450958252
Validation loss: 2.091343664353894

Epoch: 6| Step: 3
Training loss: 2.055809736251831
Validation loss: 2.0622002078640844

Epoch: 6| Step: 4
Training loss: 1.7922589778900146
Validation loss: 2.0769874690681376

Epoch: 6| Step: 5
Training loss: 2.1340365409851074
Validation loss: 2.0847414924252416

Epoch: 6| Step: 6
Training loss: 2.912202835083008
Validation loss: 2.077400671538486

Epoch: 6| Step: 7
Training loss: 2.0260989665985107
Validation loss: 2.06339688967633

Epoch: 6| Step: 8
Training loss: 2.326655864715576
Validation loss: 2.0472576720740205

Epoch: 6| Step: 9
Training loss: 2.4669528007507324
Validation loss: 2.0607135154867686

Epoch: 6| Step: 10
Training loss: 2.3436832427978516
Validation loss: 2.064201254998484

Epoch: 6| Step: 11
Training loss: 2.483283519744873
Validation loss: 2.0504270420279553

Epoch: 6| Step: 12
Training loss: 1.9250214099884033
Validation loss: 2.0670496340720885

Epoch: 6| Step: 13
Training loss: 1.6814799308776855
Validation loss: 2.0642180276173416

Epoch: 100| Step: 0
Training loss: 1.7909142971038818
Validation loss: 2.072297530789529

Epoch: 6| Step: 1
Training loss: 2.1999948024749756
Validation loss: 2.020294472735415

Epoch: 6| Step: 2
Training loss: 2.405949115753174
Validation loss: 2.0402977261492

Epoch: 6| Step: 3
Training loss: 2.658982992172241
Validation loss: 2.0677626081692275

Epoch: 6| Step: 4
Training loss: 2.4090676307678223
Validation loss: 2.057211870788246

Epoch: 6| Step: 5
Training loss: 2.0829310417175293
Validation loss: 2.047368698222663

Epoch: 6| Step: 6
Training loss: 2.446098804473877
Validation loss: 2.0648645713765132

Epoch: 6| Step: 7
Training loss: 2.553719997406006
Validation loss: 2.0599600192039245

Epoch: 6| Step: 8
Training loss: 1.9804940223693848
Validation loss: 2.0600790605750134

Epoch: 6| Step: 9
Training loss: 1.8744884729385376
Validation loss: 2.0627994332262265

Epoch: 6| Step: 10
Training loss: 1.8188416957855225
Validation loss: 2.050957046529298

Epoch: 6| Step: 11
Training loss: 1.9255006313323975
Validation loss: 2.0635835329691568

Epoch: 6| Step: 12
Training loss: 2.6688199043273926
Validation loss: 2.0629331655399774

Epoch: 6| Step: 13
Training loss: 2.434353828430176
Validation loss: 2.0589960236703195

Epoch: 101| Step: 0
Training loss: 2.661731719970703
Validation loss: 2.047212444325929

Epoch: 6| Step: 1
Training loss: 2.0482497215270996
Validation loss: 2.038257888568345

Epoch: 6| Step: 2
Training loss: 2.1242411136627197
Validation loss: 2.0360401099728

Epoch: 6| Step: 3
Training loss: 1.8859127759933472
Validation loss: 2.047926961734731

Epoch: 6| Step: 4
Training loss: 2.458455801010132
Validation loss: 2.0577257140990226

Epoch: 6| Step: 5
Training loss: 2.614396333694458
Validation loss: 2.0182398467935543

Epoch: 6| Step: 6
Training loss: 2.2435812950134277
Validation loss: 2.0486824768845753

Epoch: 6| Step: 7
Training loss: 1.9266797304153442
Validation loss: 2.040779161196883

Epoch: 6| Step: 8
Training loss: 2.2905821800231934
Validation loss: 2.0457817175055064

Epoch: 6| Step: 9
Training loss: 2.7382078170776367
Validation loss: 2.0584192865638324

Epoch: 6| Step: 10
Training loss: 1.582731008529663
Validation loss: 2.014516028024817

Epoch: 6| Step: 11
Training loss: 2.6277456283569336
Validation loss: 2.025209642225696

Epoch: 6| Step: 12
Training loss: 1.5214862823486328
Validation loss: 2.0373489818265362

Epoch: 6| Step: 13
Training loss: 3.179621696472168
Validation loss: 2.0312163009438464

Epoch: 102| Step: 0
Training loss: 1.8509650230407715
Validation loss: 2.039198778008902

Epoch: 6| Step: 1
Training loss: 2.229787826538086
Validation loss: 2.0575681194182365

Epoch: 6| Step: 2
Training loss: 2.7929208278656006
Validation loss: 2.0086254304455173

Epoch: 6| Step: 3
Training loss: 2.6582791805267334
Validation loss: 2.005061557216029

Epoch: 6| Step: 4
Training loss: 2.5986180305480957
Validation loss: 2.0174492456579722

Epoch: 6| Step: 5
Training loss: 1.6313564777374268
Validation loss: 2.044489650316136

Epoch: 6| Step: 6
Training loss: 1.9976191520690918
Validation loss: 2.032128764737037

Epoch: 6| Step: 7
Training loss: 2.1614279747009277
Validation loss: 2.049757542148713

Epoch: 6| Step: 8
Training loss: 2.2930262088775635
Validation loss: 2.027778228123983

Epoch: 6| Step: 9
Training loss: 1.9636907577514648
Validation loss: 2.041734592888945

Epoch: 6| Step: 10
Training loss: 2.722857713699341
Validation loss: 2.049296545725997

Epoch: 6| Step: 11
Training loss: 1.9761953353881836
Validation loss: 2.0549087421868437

Epoch: 6| Step: 12
Training loss: 2.486403465270996
Validation loss: 2.0469936029885405

Epoch: 6| Step: 13
Training loss: 1.4006538391113281
Validation loss: 2.0392406589241436

Epoch: 103| Step: 0
Training loss: 2.143268585205078
Validation loss: 2.0396539985492663

Epoch: 6| Step: 1
Training loss: 1.8930106163024902
Validation loss: 2.038928924068328

Epoch: 6| Step: 2
Training loss: 2.4633846282958984
Validation loss: 2.044876362687798

Epoch: 6| Step: 3
Training loss: 2.3420679569244385
Validation loss: 2.0213014938498057

Epoch: 6| Step: 4
Training loss: 1.3748490810394287
Validation loss: 2.0240370227444555

Epoch: 6| Step: 5
Training loss: 2.954298496246338
Validation loss: 2.02434443402034

Epoch: 6| Step: 6
Training loss: 2.2699573040008545
Validation loss: 2.0139752869964926

Epoch: 6| Step: 7
Training loss: 2.3501410484313965
Validation loss: 2.0289000106114212

Epoch: 6| Step: 8
Training loss: 2.668886661529541
Validation loss: 2.052263170160273

Epoch: 6| Step: 9
Training loss: 2.304507255554199
Validation loss: 2.0507131327864943

Epoch: 6| Step: 10
Training loss: 1.057168960571289
Validation loss: 2.0318694947868265

Epoch: 6| Step: 11
Training loss: 2.7687878608703613
Validation loss: 2.0501333834022604

Epoch: 6| Step: 12
Training loss: 2.401918888092041
Validation loss: 2.0626476823642688

Epoch: 6| Step: 13
Training loss: 2.2624120712280273
Validation loss: 2.062751236782279

Epoch: 104| Step: 0
Training loss: 3.44047212600708
Validation loss: 2.044432455493558

Epoch: 6| Step: 1
Training loss: 1.6816012859344482
Validation loss: 2.0434708723457913

Epoch: 6| Step: 2
Training loss: 1.8224294185638428
Validation loss: 2.062130889584941

Epoch: 6| Step: 3
Training loss: 3.2271549701690674
Validation loss: 2.052361680615333

Epoch: 6| Step: 4
Training loss: 2.651923656463623
Validation loss: 2.0356587902192147

Epoch: 6| Step: 5
Training loss: 2.0483102798461914
Validation loss: 2.074272117307109

Epoch: 6| Step: 6
Training loss: 2.019810438156128
Validation loss: 2.074705805829776

Epoch: 6| Step: 7
Training loss: 2.632044792175293
Validation loss: 2.0729437425572383

Epoch: 6| Step: 8
Training loss: 1.9250551462173462
Validation loss: 2.0562543228108394

Epoch: 6| Step: 9
Training loss: 2.3368170261383057
Validation loss: 2.065115746631417

Epoch: 6| Step: 10
Training loss: 1.5956523418426514
Validation loss: 2.068396178624963

Epoch: 6| Step: 11
Training loss: 1.6182247400283813
Validation loss: 2.065038522084554

Epoch: 6| Step: 12
Training loss: 2.094183921813965
Validation loss: 2.0802236846698228

Epoch: 6| Step: 13
Training loss: 1.7656288146972656
Validation loss: 2.0595252372885264

Epoch: 105| Step: 0
Training loss: 2.554360866546631
Validation loss: 2.0604431372816845

Epoch: 6| Step: 1
Training loss: 2.1530728340148926
Validation loss: 2.057254957896407

Epoch: 6| Step: 2
Training loss: 1.9619147777557373
Validation loss: 2.076200380120226

Epoch: 6| Step: 3
Training loss: 2.4325878620147705
Validation loss: 2.051067236931093

Epoch: 6| Step: 4
Training loss: 3.327721118927002
Validation loss: 2.0468944785415486

Epoch: 6| Step: 5
Training loss: 1.780029535293579
Validation loss: 2.040803320946232

Epoch: 6| Step: 6
Training loss: 2.198876142501831
Validation loss: 2.0429773779325586

Epoch: 6| Step: 7
Training loss: 1.1000645160675049
Validation loss: 2.0523733554347867

Epoch: 6| Step: 8
Training loss: 2.7708935737609863
Validation loss: 2.0400102856338664

Epoch: 6| Step: 9
Training loss: 2.248793601989746
Validation loss: 2.0500756643151723

Epoch: 6| Step: 10
Training loss: 1.8662339448928833
Validation loss: 2.046754083325786

Epoch: 6| Step: 11
Training loss: 2.286785364151001
Validation loss: 2.0548581346388786

Epoch: 6| Step: 12
Training loss: 2.517648696899414
Validation loss: 2.0377292915057112

Epoch: 6| Step: 13
Training loss: 2.001413106918335
Validation loss: 2.045977399554304

Epoch: 106| Step: 0
Training loss: 1.8200567960739136
Validation loss: 2.063629020926773

Epoch: 6| Step: 1
Training loss: 1.7097809314727783
Validation loss: 2.047266742234589

Epoch: 6| Step: 2
Training loss: 1.7341282367706299
Validation loss: 2.0404363204074163

Epoch: 6| Step: 3
Training loss: 2.4808945655822754
Validation loss: 2.0370706178808726

Epoch: 6| Step: 4
Training loss: 2.1576967239379883
Validation loss: 2.031860589981079

Epoch: 6| Step: 5
Training loss: 1.9652165174484253
Validation loss: 2.0384296396727204

Epoch: 6| Step: 6
Training loss: 2.0613675117492676
Validation loss: 2.0403276207626506

Epoch: 6| Step: 7
Training loss: 3.1045565605163574
Validation loss: 2.0404788729965047

Epoch: 6| Step: 8
Training loss: 1.78545343875885
Validation loss: 2.054688806174904

Epoch: 6| Step: 9
Training loss: 2.0373287200927734
Validation loss: 2.0326025024537118

Epoch: 6| Step: 10
Training loss: 2.7042529582977295
Validation loss: 2.0298117758125387

Epoch: 6| Step: 11
Training loss: 2.38625168800354
Validation loss: 2.0280881351040256

Epoch: 6| Step: 12
Training loss: 2.2570395469665527
Validation loss: 2.0197228770102225

Epoch: 6| Step: 13
Training loss: 3.225083351135254
Validation loss: 2.0581095987750637

Epoch: 107| Step: 0
Training loss: 2.2332911491394043
Validation loss: 2.0354614949995473

Epoch: 6| Step: 1
Training loss: 2.42350697517395
Validation loss: 2.042248220853908

Epoch: 6| Step: 2
Training loss: 1.3274681568145752
Validation loss: 2.0445292739457983

Epoch: 6| Step: 3
Training loss: 2.479440212249756
Validation loss: 2.065025064253038

Epoch: 6| Step: 4
Training loss: 3.155683994293213
Validation loss: 2.0542186614005797

Epoch: 6| Step: 5
Training loss: 2.7252261638641357
Validation loss: 2.034485299100158

Epoch: 6| Step: 6
Training loss: 2.3377466201782227
Validation loss: 2.034011963875063

Epoch: 6| Step: 7
Training loss: 1.8221815824508667
Validation loss: 2.060648113168696

Epoch: 6| Step: 8
Training loss: 1.893916130065918
Validation loss: 2.05395144800986

Epoch: 6| Step: 9
Training loss: 2.087407112121582
Validation loss: 2.0493213592037076

Epoch: 6| Step: 10
Training loss: 2.1052427291870117
Validation loss: 2.0299938955614643

Epoch: 6| Step: 11
Training loss: 1.7327419519424438
Validation loss: 2.0463197154383503

Epoch: 6| Step: 12
Training loss: 2.4968042373657227
Validation loss: 2.0332604582591722

Epoch: 6| Step: 13
Training loss: 2.5723884105682373
Validation loss: 2.059698970087113

Epoch: 108| Step: 0
Training loss: 2.0946545600891113
Validation loss: 2.019697073967226

Epoch: 6| Step: 1
Training loss: 1.8371528387069702
Validation loss: 2.0501443673205633

Epoch: 6| Step: 2
Training loss: 2.4353413581848145
Validation loss: 2.064467507023965

Epoch: 6| Step: 3
Training loss: 3.1143991947174072
Validation loss: 2.045344824432045

Epoch: 6| Step: 4
Training loss: 1.8156886100769043
Validation loss: 2.0372701485951743

Epoch: 6| Step: 5
Training loss: 2.6931629180908203
Validation loss: 2.05832794661163

Epoch: 6| Step: 6
Training loss: 2.2927074432373047
Validation loss: 2.0597004095713296

Epoch: 6| Step: 7
Training loss: 1.338158369064331
Validation loss: 2.0495418784438924

Epoch: 6| Step: 8
Training loss: 2.5535714626312256
Validation loss: 2.05723056485576

Epoch: 6| Step: 9
Training loss: 2.3464012145996094
Validation loss: 2.0496205078658236

Epoch: 6| Step: 10
Training loss: 2.128784656524658
Validation loss: 2.0568764850657475

Epoch: 6| Step: 11
Training loss: 2.148974657058716
Validation loss: 2.052111094997775

Epoch: 6| Step: 12
Training loss: 2.0869510173797607
Validation loss: 2.05033532522058

Epoch: 6| Step: 13
Training loss: 2.270900011062622
Validation loss: 2.0313365203078075

Epoch: 109| Step: 0
Training loss: 2.626347064971924
Validation loss: 2.075278642357037

Epoch: 6| Step: 1
Training loss: 2.225154161453247
Validation loss: 2.0474534265456663

Epoch: 6| Step: 2
Training loss: 1.5853490829467773
Validation loss: 2.0443488974725046

Epoch: 6| Step: 3
Training loss: 1.562393069267273
Validation loss: 2.0490776723431003

Epoch: 6| Step: 4
Training loss: 3.192164897918701
Validation loss: 2.0104995222501856

Epoch: 6| Step: 5
Training loss: 1.4682376384735107
Validation loss: 2.0300820360901537

Epoch: 6| Step: 6
Training loss: 2.160830020904541
Validation loss: 2.0147270669219313

Epoch: 6| Step: 7
Training loss: 2.046288251876831
Validation loss: 2.0411535642480336

Epoch: 6| Step: 8
Training loss: 2.009460926055908
Validation loss: 2.044753222055333

Epoch: 6| Step: 9
Training loss: 2.798793077468872
Validation loss: 2.019629850182482

Epoch: 6| Step: 10
Training loss: 2.2591629028320312
Validation loss: 2.0530069412723666

Epoch: 6| Step: 11
Training loss: 2.1330392360687256
Validation loss: 2.0190280522069624

Epoch: 6| Step: 12
Training loss: 2.7751598358154297
Validation loss: 2.050428282830023

Epoch: 6| Step: 13
Training loss: 2.0989933013916016
Validation loss: 2.0465954836978706

Epoch: 110| Step: 0
Training loss: 2.383021831512451
Validation loss: 2.0434460075952674

Epoch: 6| Step: 1
Training loss: 2.4319560527801514
Validation loss: 2.027450689705469

Epoch: 6| Step: 2
Training loss: 2.3346877098083496
Validation loss: 2.0486973383093394

Epoch: 6| Step: 3
Training loss: 2.22896409034729
Validation loss: 2.0326752739567913

Epoch: 6| Step: 4
Training loss: 1.399817705154419
Validation loss: 2.029748276997638

Epoch: 6| Step: 5
Training loss: 2.6088013648986816
Validation loss: 2.036129718185753

Epoch: 6| Step: 6
Training loss: 2.807875156402588
Validation loss: 2.03334984215357

Epoch: 6| Step: 7
Training loss: 2.053649425506592
Validation loss: 2.0325591282177995

Epoch: 6| Step: 8
Training loss: 2.531977653503418
Validation loss: 2.023748056862944

Epoch: 6| Step: 9
Training loss: 2.248411178588867
Validation loss: 2.030322181281223

Epoch: 6| Step: 10
Training loss: 1.9842569828033447
Validation loss: 2.0357955681380404

Epoch: 6| Step: 11
Training loss: 1.9649653434753418
Validation loss: 2.0235404224805933

Epoch: 6| Step: 12
Training loss: 2.004945755004883
Validation loss: 2.0126573257548834

Epoch: 6| Step: 13
Training loss: 1.9151380062103271
Validation loss: 2.0242583982406126

Epoch: 111| Step: 0
Training loss: 2.14953351020813
Validation loss: 2.064245018907773

Epoch: 6| Step: 1
Training loss: 2.4091243743896484
Validation loss: 2.0457965148392545

Epoch: 6| Step: 2
Training loss: 1.435504674911499
Validation loss: 2.0599602691588865

Epoch: 6| Step: 3
Training loss: 2.902644395828247
Validation loss: 2.0719275936003654

Epoch: 6| Step: 4
Training loss: 2.3916661739349365
Validation loss: 2.051039513721261

Epoch: 6| Step: 5
Training loss: 1.1021592617034912
Validation loss: 2.0906105515777424

Epoch: 6| Step: 6
Training loss: 2.1549575328826904
Validation loss: 2.08669771686677

Epoch: 6| Step: 7
Training loss: 1.9699794054031372
Validation loss: 2.0820435759841756

Epoch: 6| Step: 8
Training loss: 2.1351866722106934
Validation loss: 2.0817564251602336

Epoch: 6| Step: 9
Training loss: 2.3612523078918457
Validation loss: 2.0868698114989908

Epoch: 6| Step: 10
Training loss: 2.209552526473999
Validation loss: 2.0955108929705877

Epoch: 6| Step: 11
Training loss: 3.3580784797668457
Validation loss: 2.0903962658297632

Epoch: 6| Step: 12
Training loss: 2.4308712482452393
Validation loss: 2.0894809205044984

Epoch: 6| Step: 13
Training loss: 2.0738136768341064
Validation loss: 2.0882610454354236

Epoch: 112| Step: 0
Training loss: 2.7838821411132812
Validation loss: 2.0752126247652116

Epoch: 6| Step: 1
Training loss: 2.581146478652954
Validation loss: 2.0614150929194626

Epoch: 6| Step: 2
Training loss: 2.43076753616333
Validation loss: 2.0787534047198553

Epoch: 6| Step: 3
Training loss: 2.4571919441223145
Validation loss: 2.072287236490557

Epoch: 6| Step: 4
Training loss: 2.227001905441284
Validation loss: 2.070594485088061

Epoch: 6| Step: 5
Training loss: 1.917981505393982
Validation loss: 2.0888378389420046

Epoch: 6| Step: 6
Training loss: 1.9857221841812134
Validation loss: 2.0797272702699066

Epoch: 6| Step: 7
Training loss: 1.3209383487701416
Validation loss: 2.0747249049525105

Epoch: 6| Step: 8
Training loss: 1.9190858602523804
Validation loss: 2.0663533505573066

Epoch: 6| Step: 9
Training loss: 2.381840229034424
Validation loss: 2.041708752673159

Epoch: 6| Step: 10
Training loss: 2.3075549602508545
Validation loss: 2.0681317878025833

Epoch: 6| Step: 11
Training loss: 2.293336868286133
Validation loss: 2.0746092719416462

Epoch: 6| Step: 12
Training loss: 1.8637924194335938
Validation loss: 2.0704803030977965

Epoch: 6| Step: 13
Training loss: 2.986903667449951
Validation loss: 2.0670704008430563

Epoch: 113| Step: 0
Training loss: 3.1576480865478516
Validation loss: 2.0541634713449786

Epoch: 6| Step: 1
Training loss: 1.638707160949707
Validation loss: 2.0768844389146373

Epoch: 6| Step: 2
Training loss: 2.7588863372802734
Validation loss: 2.0489956948064987

Epoch: 6| Step: 3
Training loss: 2.568380355834961
Validation loss: 2.040597579812491

Epoch: 6| Step: 4
Training loss: 2.064537525177002
Validation loss: 2.052595237249969

Epoch: 6| Step: 5
Training loss: 2.430896759033203
Validation loss: 2.057973495093725

Epoch: 6| Step: 6
Training loss: 1.8949081897735596
Validation loss: 2.063378354554535

Epoch: 6| Step: 7
Training loss: 2.357956647872925
Validation loss: 2.055312418168591

Epoch: 6| Step: 8
Training loss: 2.0817348957061768
Validation loss: 2.053385829412809

Epoch: 6| Step: 9
Training loss: 1.9936883449554443
Validation loss: 2.0335117975870767

Epoch: 6| Step: 10
Training loss: 2.2465124130249023
Validation loss: 2.043082824317358

Epoch: 6| Step: 11
Training loss: 2.3764028549194336
Validation loss: 2.0315829284729494

Epoch: 6| Step: 12
Training loss: 1.7962899208068848
Validation loss: 2.02824709492345

Epoch: 6| Step: 13
Training loss: 1.3724766969680786
Validation loss: 2.0483648161734305

Epoch: 114| Step: 0
Training loss: 2.394890308380127
Validation loss: 2.056622969206943

Epoch: 6| Step: 1
Training loss: 1.9686062335968018
Validation loss: 2.037379672450404

Epoch: 6| Step: 2
Training loss: 2.458782196044922
Validation loss: 2.026965948843187

Epoch: 6| Step: 3
Training loss: 2.1454310417175293
Validation loss: 2.0204748607450917

Epoch: 6| Step: 4
Training loss: 2.253547191619873
Validation loss: 2.022884773951705

Epoch: 6| Step: 5
Training loss: 2.1957197189331055
Validation loss: 2.037961385583365

Epoch: 6| Step: 6
Training loss: 2.06038498878479
Validation loss: 2.0047227439060005

Epoch: 6| Step: 7
Training loss: 2.3747267723083496
Validation loss: 2.031378701169004

Epoch: 6| Step: 8
Training loss: 1.960750699043274
Validation loss: 2.022415904588597

Epoch: 6| Step: 9
Training loss: 2.066028594970703
Validation loss: 2.013794160658313

Epoch: 6| Step: 10
Training loss: 2.3313469886779785
Validation loss: 2.023032792152897

Epoch: 6| Step: 11
Training loss: 2.1572470664978027
Validation loss: 2.033623267245549

Epoch: 6| Step: 12
Training loss: 2.32289981842041
Validation loss: 2.046782733291708

Epoch: 6| Step: 13
Training loss: 2.4182169437408447
Validation loss: 2.022659445321688

Epoch: 115| Step: 0
Training loss: 2.5795364379882812
Validation loss: 2.0230901087484052

Epoch: 6| Step: 1
Training loss: 1.9043846130371094
Validation loss: 2.0530250636480187

Epoch: 6| Step: 2
Training loss: 2.0644893646240234
Validation loss: 2.0456286502140824

Epoch: 6| Step: 3
Training loss: 2.133948802947998
Validation loss: 2.048700858187932

Epoch: 6| Step: 4
Training loss: 2.3543152809143066
Validation loss: 2.053628739490304

Epoch: 6| Step: 5
Training loss: 2.827908515930176
Validation loss: 2.0507052021641887

Epoch: 6| Step: 6
Training loss: 1.6469603776931763
Validation loss: 2.068401144396874

Epoch: 6| Step: 7
Training loss: 2.203385353088379
Validation loss: 2.063543265865695

Epoch: 6| Step: 8
Training loss: 1.9647423028945923
Validation loss: 2.0409867507155224

Epoch: 6| Step: 9
Training loss: 1.9043132066726685
Validation loss: 2.0715899749468734

Epoch: 6| Step: 10
Training loss: 2.990323781967163
Validation loss: 2.046021189740909

Epoch: 6| Step: 11
Training loss: 2.0832386016845703
Validation loss: 2.049556896250735

Epoch: 6| Step: 12
Training loss: 2.087440252304077
Validation loss: 2.0758826591635264

Epoch: 6| Step: 13
Training loss: 1.9925932884216309
Validation loss: 2.084855615451772

Epoch: 116| Step: 0
Training loss: 2.2320713996887207
Validation loss: 2.049360085559148

Epoch: 6| Step: 1
Training loss: 2.418610095977783
Validation loss: 2.0433637711309616

Epoch: 6| Step: 2
Training loss: 1.9785114526748657
Validation loss: 2.096161057872157

Epoch: 6| Step: 3
Training loss: 2.3200690746307373
Validation loss: 2.0391187155118553

Epoch: 6| Step: 4
Training loss: 2.1947734355926514
Validation loss: 2.044301768784882

Epoch: 6| Step: 5
Training loss: 2.3969123363494873
Validation loss: 2.0386685607253865

Epoch: 6| Step: 6
Training loss: 1.564664363861084
Validation loss: 2.0424686144757014

Epoch: 6| Step: 7
Training loss: 2.539233922958374
Validation loss: 2.043964102704038

Epoch: 6| Step: 8
Training loss: 1.8242034912109375
Validation loss: 2.0644983001934585

Epoch: 6| Step: 9
Training loss: 2.7915406227111816
Validation loss: 2.0499841961809384

Epoch: 6| Step: 10
Training loss: 1.8480780124664307
Validation loss: 2.0460436049328057

Epoch: 6| Step: 11
Training loss: 2.2796096801757812
Validation loss: 2.064102626615955

Epoch: 6| Step: 12
Training loss: 1.9573588371276855
Validation loss: 2.0591443379720054

Epoch: 6| Step: 13
Training loss: 2.8923442363739014
Validation loss: 2.057854216585877

Epoch: 117| Step: 0
Training loss: 2.3648691177368164
Validation loss: 2.076414708168276

Epoch: 6| Step: 1
Training loss: 1.964577317237854
Validation loss: 2.0728983520179667

Epoch: 6| Step: 2
Training loss: 3.1810779571533203
Validation loss: 2.042567373603903

Epoch: 6| Step: 3
Training loss: 1.898207187652588
Validation loss: 2.0545173216891546

Epoch: 6| Step: 4
Training loss: 1.8934663534164429
Validation loss: 2.0335954337991695

Epoch: 6| Step: 5
Training loss: 2.171276330947876
Validation loss: 2.042854243709195

Epoch: 6| Step: 6
Training loss: 2.5254321098327637
Validation loss: 2.049682124968498

Epoch: 6| Step: 7
Training loss: 2.2759780883789062
Validation loss: 2.0330850385850474

Epoch: 6| Step: 8
Training loss: 2.441079616546631
Validation loss: 2.0500006829538653

Epoch: 6| Step: 9
Training loss: 2.223686456680298
Validation loss: 2.0371624282611314

Epoch: 6| Step: 10
Training loss: 2.0222442150115967
Validation loss: 2.037730368234778

Epoch: 6| Step: 11
Training loss: 1.9182285070419312
Validation loss: 2.0353114246040263

Epoch: 6| Step: 12
Training loss: 2.3169891834259033
Validation loss: 2.05070633785699

Epoch: 6| Step: 13
Training loss: 1.3382196426391602
Validation loss: 2.0423461903807936

Epoch: 118| Step: 0
Training loss: 2.337512493133545
Validation loss: 2.0428318156990954

Epoch: 6| Step: 1
Training loss: 1.896706461906433
Validation loss: 2.030152584916802

Epoch: 6| Step: 2
Training loss: 2.6221280097961426
Validation loss: 2.0438793154173

Epoch: 6| Step: 3
Training loss: 2.541442394256592
Validation loss: 2.0453020218879945

Epoch: 6| Step: 4
Training loss: 2.031944751739502
Validation loss: 2.02822809321906

Epoch: 6| Step: 5
Training loss: 2.581397771835327
Validation loss: 2.058727534868384

Epoch: 6| Step: 6
Training loss: 2.2034318447113037
Validation loss: 2.0464666223013275

Epoch: 6| Step: 7
Training loss: 1.4534344673156738
Validation loss: 2.0787002348130748

Epoch: 6| Step: 8
Training loss: 2.950145721435547
Validation loss: 2.0465889028323594

Epoch: 6| Step: 9
Training loss: 2.543339729309082
Validation loss: 2.069668539108769

Epoch: 6| Step: 10
Training loss: 1.9755160808563232
Validation loss: 2.064824729837397

Epoch: 6| Step: 11
Training loss: 2.2430763244628906
Validation loss: 2.075017567603819

Epoch: 6| Step: 12
Training loss: 1.3103766441345215
Validation loss: 2.0723568252337876

Epoch: 6| Step: 13
Training loss: 2.018718719482422
Validation loss: 2.0901769156097085

Epoch: 119| Step: 0
Training loss: 2.7989258766174316
Validation loss: 2.075050856477471

Epoch: 6| Step: 1
Training loss: 2.188666820526123
Validation loss: 2.0657257495387906

Epoch: 6| Step: 2
Training loss: 2.462759017944336
Validation loss: 2.064360326336276

Epoch: 6| Step: 3
Training loss: 2.147202491760254
Validation loss: 2.0594945671737834

Epoch: 6| Step: 4
Training loss: 1.8330974578857422
Validation loss: 2.041091752308671

Epoch: 6| Step: 5
Training loss: 2.0590548515319824
Validation loss: 2.0424759131605907

Epoch: 6| Step: 6
Training loss: 1.9388750791549683
Validation loss: 2.0430588324864707

Epoch: 6| Step: 7
Training loss: 2.83071231842041
Validation loss: 2.0552963210690405

Epoch: 6| Step: 8
Training loss: 1.2616055011749268
Validation loss: 2.0463303378833237

Epoch: 6| Step: 9
Training loss: 2.501157283782959
Validation loss: 2.070894620751822

Epoch: 6| Step: 10
Training loss: 2.6276297569274902
Validation loss: 2.057424552979008

Epoch: 6| Step: 11
Training loss: 2.435482978820801
Validation loss: 2.051877257644489

Epoch: 6| Step: 12
Training loss: 1.887506127357483
Validation loss: 2.055702817055487

Epoch: 6| Step: 13
Training loss: 1.7936596870422363
Validation loss: 2.070151793059482

Epoch: 120| Step: 0
Training loss: 1.8432729244232178
Validation loss: 2.0533444804529988

Epoch: 6| Step: 1
Training loss: 1.9309585094451904
Validation loss: 2.072305597284789

Epoch: 6| Step: 2
Training loss: 2.789306640625
Validation loss: 2.0589450046580327

Epoch: 6| Step: 3
Training loss: 1.7390787601470947
Validation loss: 2.0662383315383748

Epoch: 6| Step: 4
Training loss: 1.8854643106460571
Validation loss: 2.0626569460797053

Epoch: 6| Step: 5
Training loss: 2.1727561950683594
Validation loss: 2.066695233826996

Epoch: 6| Step: 6
Training loss: 2.857027053833008
Validation loss: 2.0634450271565425

Epoch: 6| Step: 7
Training loss: 2.8661789894104004
Validation loss: 2.0877835186578895

Epoch: 6| Step: 8
Training loss: 2.485609769821167
Validation loss: 2.0874799246429117

Epoch: 6| Step: 9
Training loss: 1.6050708293914795
Validation loss: 2.0827675634814846

Epoch: 6| Step: 10
Training loss: 2.4037938117980957
Validation loss: 2.087090233320831

Epoch: 6| Step: 11
Training loss: 2.4894464015960693
Validation loss: 2.0928532923421552

Epoch: 6| Step: 12
Training loss: 2.3026506900787354
Validation loss: 2.122891510686567

Epoch: 6| Step: 13
Training loss: 1.1329489946365356
Validation loss: 2.1201730543567288

Epoch: 121| Step: 0
Training loss: 2.569441556930542
Validation loss: 2.095652593079434

Epoch: 6| Step: 1
Training loss: 2.8434834480285645
Validation loss: 2.0995168121912147

Epoch: 6| Step: 2
Training loss: 2.164501667022705
Validation loss: 2.0949017386282645

Epoch: 6| Step: 3
Training loss: 1.944270372390747
Validation loss: 2.0932494158385904

Epoch: 6| Step: 4
Training loss: 1.6664986610412598
Validation loss: 2.1107075522022862

Epoch: 6| Step: 5
Training loss: 2.026073932647705
Validation loss: 2.089406000670566

Epoch: 6| Step: 6
Training loss: 1.9519257545471191
Validation loss: 2.0811579778630245

Epoch: 6| Step: 7
Training loss: 2.569736957550049
Validation loss: 2.0916141874046734

Epoch: 6| Step: 8
Training loss: 2.352827548980713
Validation loss: 2.092396492599159

Epoch: 6| Step: 9
Training loss: 2.2194013595581055
Validation loss: 2.0919630399314304

Epoch: 6| Step: 10
Training loss: 1.9288901090621948
Validation loss: 2.0891296158554735

Epoch: 6| Step: 11
Training loss: 2.1454501152038574
Validation loss: 2.1013699090608986

Epoch: 6| Step: 12
Training loss: 2.3241100311279297
Validation loss: 2.0849907641769736

Epoch: 6| Step: 13
Training loss: 1.9503040313720703
Validation loss: 2.0613261986804265

Epoch: 122| Step: 0
Training loss: 2.1006832122802734
Validation loss: 2.075201890801871

Epoch: 6| Step: 1
Training loss: 2.173837184906006
Validation loss: 2.089977361822641

Epoch: 6| Step: 2
Training loss: 2.1338958740234375
Validation loss: 2.057429826387795

Epoch: 6| Step: 3
Training loss: 2.7103612422943115
Validation loss: 2.050691850723759

Epoch: 6| Step: 4
Training loss: 1.0114611387252808
Validation loss: 2.053269068400065

Epoch: 6| Step: 5
Training loss: 1.4006847143173218
Validation loss: 2.0532746456002675

Epoch: 6| Step: 6
Training loss: 3.0399110317230225
Validation loss: 2.059387376231532

Epoch: 6| Step: 7
Training loss: 2.105804443359375
Validation loss: 2.0346075001583306

Epoch: 6| Step: 8
Training loss: 2.3547325134277344
Validation loss: 2.0301178745044175

Epoch: 6| Step: 9
Training loss: 1.8260947465896606
Validation loss: 2.0516086803969515

Epoch: 6| Step: 10
Training loss: 2.8781142234802246
Validation loss: 2.058982769648234

Epoch: 6| Step: 11
Training loss: 2.7097482681274414
Validation loss: 2.061677316183685

Epoch: 6| Step: 12
Training loss: 2.4408764839172363
Validation loss: 2.0624626759559876

Epoch: 6| Step: 13
Training loss: 1.7738028764724731
Validation loss: 2.053304172331287

Epoch: 123| Step: 0
Training loss: 2.4542322158813477
Validation loss: 2.0570131476207445

Epoch: 6| Step: 1
Training loss: 2.97481632232666
Validation loss: 2.0725252461689774

Epoch: 6| Step: 2
Training loss: 1.5276018381118774
Validation loss: 2.0445803032126477

Epoch: 6| Step: 3
Training loss: 2.326474666595459
Validation loss: 2.048507293065389

Epoch: 6| Step: 4
Training loss: 2.538571357727051
Validation loss: 2.0529816637757006

Epoch: 6| Step: 5
Training loss: 1.0596222877502441
Validation loss: 2.0513746648706417

Epoch: 6| Step: 6
Training loss: 1.5790367126464844
Validation loss: 2.0732589908825454

Epoch: 6| Step: 7
Training loss: 2.80643892288208
Validation loss: 2.045340455988402

Epoch: 6| Step: 8
Training loss: 1.3036727905273438
Validation loss: 2.0596164195768294

Epoch: 6| Step: 9
Training loss: 2.9468274116516113
Validation loss: 2.0439567078826246

Epoch: 6| Step: 10
Training loss: 1.81252920627594
Validation loss: 2.0583614841584237

Epoch: 6| Step: 11
Training loss: 2.5463132858276367
Validation loss: 2.0594235030553674

Epoch: 6| Step: 12
Training loss: 2.6130263805389404
Validation loss: 2.0524246000474498

Epoch: 6| Step: 13
Training loss: 2.066950798034668
Validation loss: 2.07449250067434

Epoch: 124| Step: 0
Training loss: 2.411174774169922
Validation loss: 2.0462270744385256

Epoch: 6| Step: 1
Training loss: 2.354313373565674
Validation loss: 2.0618913853040306

Epoch: 6| Step: 2
Training loss: 2.937924861907959
Validation loss: 2.076502271877822

Epoch: 6| Step: 3
Training loss: 1.7798885107040405
Validation loss: 2.0913674241753033

Epoch: 6| Step: 4
Training loss: 2.393812656402588
Validation loss: 2.1017357687796316

Epoch: 6| Step: 5
Training loss: 2.1537344455718994
Validation loss: 2.0798104116993565

Epoch: 6| Step: 6
Training loss: 2.2114484310150146
Validation loss: 2.086533825884583

Epoch: 6| Step: 7
Training loss: 2.9373815059661865
Validation loss: 2.1002179448322584

Epoch: 6| Step: 8
Training loss: 1.7303974628448486
Validation loss: 2.062118125218217

Epoch: 6| Step: 9
Training loss: 1.767608880996704
Validation loss: 2.0838721131765716

Epoch: 6| Step: 10
Training loss: 1.9137389659881592
Validation loss: 2.09306029863255

Epoch: 6| Step: 11
Training loss: 2.3068976402282715
Validation loss: 2.112879512130573

Epoch: 6| Step: 12
Training loss: 2.2454519271850586
Validation loss: 2.1232859562802058

Epoch: 6| Step: 13
Training loss: 1.3182721138000488
Validation loss: 2.1171665294196016

Epoch: 125| Step: 0
Training loss: 1.8836108446121216
Validation loss: 2.1064876074432046

Epoch: 6| Step: 1
Training loss: 2.0973260402679443
Validation loss: 2.0870671374823457

Epoch: 6| Step: 2
Training loss: 2.050577163696289
Validation loss: 2.0892385077732865

Epoch: 6| Step: 3
Training loss: 2.247593879699707
Validation loss: 2.0909742488655993

Epoch: 6| Step: 4
Training loss: 2.3690459728240967
Validation loss: 2.066858603108314

Epoch: 6| Step: 5
Training loss: 2.9629039764404297
Validation loss: 2.083164243287938

Epoch: 6| Step: 6
Training loss: 1.414374828338623
Validation loss: 2.0880153191986905

Epoch: 6| Step: 7
Training loss: 2.286208152770996
Validation loss: 2.0851383824502268

Epoch: 6| Step: 8
Training loss: 2.1477253437042236
Validation loss: 2.0675756469849618

Epoch: 6| Step: 9
Training loss: 2.5976686477661133
Validation loss: 2.082514424477854

Epoch: 6| Step: 10
Training loss: 2.775754451751709
Validation loss: 2.088032223845041

Epoch: 6| Step: 11
Training loss: 2.4869940280914307
Validation loss: 2.084661024872975

Epoch: 6| Step: 12
Training loss: 1.8745925426483154
Validation loss: 2.0644062642128236

Epoch: 6| Step: 13
Training loss: 1.119463562965393
Validation loss: 2.0709525154482935

Epoch: 126| Step: 0
Training loss: 1.9900078773498535
Validation loss: 2.077074637977026

Epoch: 6| Step: 1
Training loss: 2.011434555053711
Validation loss: 2.057500148332247

Epoch: 6| Step: 2
Training loss: 2.818352222442627
Validation loss: 2.0745161105227727

Epoch: 6| Step: 3
Training loss: 1.6624693870544434
Validation loss: 2.062355485013736

Epoch: 6| Step: 4
Training loss: 2.590660810470581
Validation loss: 2.093543832020093

Epoch: 6| Step: 5
Training loss: 2.089097023010254
Validation loss: 2.080259317992836

Epoch: 6| Step: 6
Training loss: 2.235114097595215
Validation loss: 2.0661774168732348

Epoch: 6| Step: 7
Training loss: 2.042646646499634
Validation loss: 2.085296041222029

Epoch: 6| Step: 8
Training loss: 1.9039571285247803
Validation loss: 2.080564142555319

Epoch: 6| Step: 9
Training loss: 2.418339729309082
Validation loss: 2.0710666179656982

Epoch: 6| Step: 10
Training loss: 2.2502567768096924
Validation loss: 2.0499989858237644

Epoch: 6| Step: 11
Training loss: 1.7859877347946167
Validation loss: 2.0576795826676073

Epoch: 6| Step: 12
Training loss: 2.7491538524627686
Validation loss: 2.0792304597875124

Epoch: 6| Step: 13
Training loss: 1.7174931764602661
Validation loss: 2.071995871041411

Epoch: 127| Step: 0
Training loss: 2.228586196899414
Validation loss: 2.0821646182767806

Epoch: 6| Step: 1
Training loss: 2.475344657897949
Validation loss: 2.044259718669358

Epoch: 6| Step: 2
Training loss: 1.5099220275878906
Validation loss: 2.0486147506262666

Epoch: 6| Step: 3
Training loss: 1.684826135635376
Validation loss: 2.095096920126228

Epoch: 6| Step: 4
Training loss: 3.5537002086639404
Validation loss: 2.0589913270806752

Epoch: 6| Step: 5
Training loss: 2.544170379638672
Validation loss: 2.0653368375634633

Epoch: 6| Step: 6
Training loss: 2.059199333190918
Validation loss: 2.0629103696474465

Epoch: 6| Step: 7
Training loss: 1.8017460107803345
Validation loss: 2.031660554229572

Epoch: 6| Step: 8
Training loss: 2.2702231407165527
Validation loss: 2.0472246575099167

Epoch: 6| Step: 9
Training loss: 2.6987130641937256
Validation loss: 2.047034678920623

Epoch: 6| Step: 10
Training loss: 1.9857556819915771
Validation loss: 2.0509349530743015

Epoch: 6| Step: 11
Training loss: 1.6419557332992554
Validation loss: 2.0199560452533025

Epoch: 6| Step: 12
Training loss: 2.0818090438842773
Validation loss: 2.0385317058973413

Epoch: 6| Step: 13
Training loss: 2.0250205993652344
Validation loss: 2.0683102582090642

Epoch: 128| Step: 0
Training loss: 1.6552989482879639
Validation loss: 2.0483448492583407

Epoch: 6| Step: 1
Training loss: 2.5926520824432373
Validation loss: 2.0456512922881753

Epoch: 6| Step: 2
Training loss: 3.201768398284912
Validation loss: 2.0361561916207753

Epoch: 6| Step: 3
Training loss: 1.5370643138885498
Validation loss: 2.07451997264739

Epoch: 6| Step: 4
Training loss: 2.3475847244262695
Validation loss: 2.0854610153423843

Epoch: 6| Step: 5
Training loss: 1.7171517610549927
Validation loss: 2.0423387571047713

Epoch: 6| Step: 6
Training loss: 2.3397724628448486
Validation loss: 2.055016226665948

Epoch: 6| Step: 7
Training loss: 1.6981984376907349
Validation loss: 2.0551259517669678

Epoch: 6| Step: 8
Training loss: 1.7069141864776611
Validation loss: 2.0976087149753364

Epoch: 6| Step: 9
Training loss: 2.6072864532470703
Validation loss: 2.080064273649646

Epoch: 6| Step: 10
Training loss: 2.7584362030029297
Validation loss: 2.081822952916545

Epoch: 6| Step: 11
Training loss: 2.045340061187744
Validation loss: 2.0643235560386413

Epoch: 6| Step: 12
Training loss: 2.5954110622406006
Validation loss: 2.0685700703692693

Epoch: 6| Step: 13
Training loss: 1.5481600761413574
Validation loss: 2.0847382673653225

Epoch: 129| Step: 0
Training loss: 2.2242629528045654
Validation loss: 2.0634050100080428

Epoch: 6| Step: 1
Training loss: 2.418281316757202
Validation loss: 2.0696556209236063

Epoch: 6| Step: 2
Training loss: 1.8949116468429565
Validation loss: 2.0795237800126434

Epoch: 6| Step: 3
Training loss: 2.5136356353759766
Validation loss: 2.069724395710935

Epoch: 6| Step: 4
Training loss: 2.333177089691162
Validation loss: 2.085744442478303

Epoch: 6| Step: 5
Training loss: 2.1745526790618896
Validation loss: 2.0941086558885473

Epoch: 6| Step: 6
Training loss: 2.1963109970092773
Validation loss: 2.1027690261922856

Epoch: 6| Step: 7
Training loss: 1.9588923454284668
Validation loss: 2.108242655313143

Epoch: 6| Step: 8
Training loss: 2.5102827548980713
Validation loss: 2.1182090120930828

Epoch: 6| Step: 9
Training loss: 2.385816812515259
Validation loss: 2.0835414432710215

Epoch: 6| Step: 10
Training loss: 1.2700436115264893
Validation loss: 2.1173794192652546

Epoch: 6| Step: 11
Training loss: 2.037529945373535
Validation loss: 2.1171534087068293

Epoch: 6| Step: 12
Training loss: 1.792578935623169
Validation loss: 2.106581764836465

Epoch: 6| Step: 13
Training loss: 3.2339882850646973
Validation loss: 2.0902911437455045

Epoch: 130| Step: 0
Training loss: 1.5695303678512573
Validation loss: 2.08089812724821

Epoch: 6| Step: 1
Training loss: 2.211174249649048
Validation loss: 2.116229470058154

Epoch: 6| Step: 2
Training loss: 1.9057505130767822
Validation loss: 2.109805526271943

Epoch: 6| Step: 3
Training loss: 2.451981782913208
Validation loss: 2.0828233585562757

Epoch: 6| Step: 4
Training loss: 1.6713016033172607
Validation loss: 2.0861069617732877

Epoch: 6| Step: 5
Training loss: 2.477254867553711
Validation loss: 2.0660836619715535

Epoch: 6| Step: 6
Training loss: 2.882617712020874
Validation loss: 2.0775375840484456

Epoch: 6| Step: 7
Training loss: 2.877631664276123
Validation loss: 2.0857726886708248

Epoch: 6| Step: 8
Training loss: 2.2525839805603027
Validation loss: 2.0784133518895795

Epoch: 6| Step: 9
Training loss: 2.4960546493530273
Validation loss: 2.0741971103093957

Epoch: 6| Step: 10
Training loss: 2.0471889972686768
Validation loss: 2.064893627679476

Epoch: 6| Step: 11
Training loss: 2.281062126159668
Validation loss: 2.075529698402651

Epoch: 6| Step: 12
Training loss: 1.4983806610107422
Validation loss: 2.066953848767024

Epoch: 6| Step: 13
Training loss: 2.0056521892547607
Validation loss: 2.04931475270179

Epoch: 131| Step: 0
Training loss: 1.3086493015289307
Validation loss: 2.061133256522558

Epoch: 6| Step: 1
Training loss: 1.949604868888855
Validation loss: 2.042534956368067

Epoch: 6| Step: 2
Training loss: 1.9440972805023193
Validation loss: 2.075282842882218

Epoch: 6| Step: 3
Training loss: 1.7795661687850952
Validation loss: 2.084982306726517

Epoch: 6| Step: 4
Training loss: 2.5871925354003906
Validation loss: 2.061373825996153

Epoch: 6| Step: 5
Training loss: 2.6916708946228027
Validation loss: 2.0598937414025746

Epoch: 6| Step: 6
Training loss: 2.2274112701416016
Validation loss: 2.050864488847794

Epoch: 6| Step: 7
Training loss: 4.176313877105713
Validation loss: 2.0454934771342943

Epoch: 6| Step: 8
Training loss: 2.5601229667663574
Validation loss: 2.0735166995756087

Epoch: 6| Step: 9
Training loss: 1.5071563720703125
Validation loss: 2.0811498318949053

Epoch: 6| Step: 10
Training loss: 2.3243820667266846
Validation loss: 2.071393835929132

Epoch: 6| Step: 11
Training loss: 1.6085704565048218
Validation loss: 2.093258609053909

Epoch: 6| Step: 12
Training loss: 2.13832950592041
Validation loss: 2.0499322234943347

Epoch: 6| Step: 13
Training loss: 1.6589322090148926
Validation loss: 2.0865783588860625

Epoch: 132| Step: 0
Training loss: 3.022815704345703
Validation loss: 2.079832802536667

Epoch: 6| Step: 1
Training loss: 1.8598629236221313
Validation loss: 2.0844439973113356

Epoch: 6| Step: 2
Training loss: 2.106477737426758
Validation loss: 2.0864075409468783

Epoch: 6| Step: 3
Training loss: 2.012302875518799
Validation loss: 2.0885204269040014

Epoch: 6| Step: 4
Training loss: 2.8430471420288086
Validation loss: 2.07519014932776

Epoch: 6| Step: 5
Training loss: 1.8843475580215454
Validation loss: 2.054532607396444

Epoch: 6| Step: 6
Training loss: 2.2199487686157227
Validation loss: 2.082205234035369

Epoch: 6| Step: 7
Training loss: 2.049182415008545
Validation loss: 2.059614034109218

Epoch: 6| Step: 8
Training loss: 1.4164659976959229
Validation loss: 2.078252097611786

Epoch: 6| Step: 9
Training loss: 2.0446722507476807
Validation loss: 2.0532475927824616

Epoch: 6| Step: 10
Training loss: 1.9876104593276978
Validation loss: 2.0704839742311867

Epoch: 6| Step: 11
Training loss: 3.039015293121338
Validation loss: 2.0810458237125027

Epoch: 6| Step: 12
Training loss: 2.1049599647521973
Validation loss: 2.0793727777337514

Epoch: 6| Step: 13
Training loss: 1.7687755823135376
Validation loss: 2.08006707058158

Epoch: 133| Step: 0
Training loss: 1.7826390266418457
Validation loss: 2.0886032812057005

Epoch: 6| Step: 1
Training loss: 2.09977650642395
Validation loss: 2.10399882255062

Epoch: 6| Step: 2
Training loss: 1.4790188074111938
Validation loss: 2.085732365167269

Epoch: 6| Step: 3
Training loss: 2.651895523071289
Validation loss: 2.111999209209155

Epoch: 6| Step: 4
Training loss: 2.715707302093506
Validation loss: 2.092356902296825

Epoch: 6| Step: 5
Training loss: 1.6588635444641113
Validation loss: 2.143706629353185

Epoch: 6| Step: 6
Training loss: 2.3385040760040283
Validation loss: 2.1024955139365247

Epoch: 6| Step: 7
Training loss: 2.4867963790893555
Validation loss: 2.1276208636581257

Epoch: 6| Step: 8
Training loss: 2.3980724811553955
Validation loss: 2.112154769641097

Epoch: 6| Step: 9
Training loss: 2.522813558578491
Validation loss: 2.1115691020924556

Epoch: 6| Step: 10
Training loss: 2.2555360794067383
Validation loss: 2.1057295978710218

Epoch: 6| Step: 11
Training loss: 2.1143198013305664
Validation loss: 2.1258981868784916

Epoch: 6| Step: 12
Training loss: 1.7589679956436157
Validation loss: 2.098938777882566

Epoch: 6| Step: 13
Training loss: 2.281313896179199
Validation loss: 2.1175152524825065

Epoch: 134| Step: 0
Training loss: 3.0196971893310547
Validation loss: 2.1131440747168755

Epoch: 6| Step: 1
Training loss: 2.431689739227295
Validation loss: 2.106985084472164

Epoch: 6| Step: 2
Training loss: 1.6504855155944824
Validation loss: 2.1028652562890002

Epoch: 6| Step: 3
Training loss: 2.625945806503296
Validation loss: 2.1045179264519804

Epoch: 6| Step: 4
Training loss: 1.9164855480194092
Validation loss: 2.0802834828694663

Epoch: 6| Step: 5
Training loss: 3.093339443206787
Validation loss: 2.101148154145928

Epoch: 6| Step: 6
Training loss: 1.9567110538482666
Validation loss: 2.0736204860030965

Epoch: 6| Step: 7
Training loss: 2.1769070625305176
Validation loss: 2.0893321652566232

Epoch: 6| Step: 8
Training loss: 1.8649177551269531
Validation loss: 2.064986069997152

Epoch: 6| Step: 9
Training loss: 1.8437179327011108
Validation loss: 2.0707769957921838

Epoch: 6| Step: 10
Training loss: 2.2176735401153564
Validation loss: 2.0617246371443554

Epoch: 6| Step: 11
Training loss: 2.140127182006836
Validation loss: 2.073057907883839

Epoch: 6| Step: 12
Training loss: 1.7587358951568604
Validation loss: 2.0577932301387993

Epoch: 6| Step: 13
Training loss: 1.858741283416748
Validation loss: 2.0591792662938437

Epoch: 135| Step: 0
Training loss: 1.6626172065734863
Validation loss: 2.074915273215181

Epoch: 6| Step: 1
Training loss: 2.337268829345703
Validation loss: 2.058772207588278

Epoch: 6| Step: 2
Training loss: 2.4253244400024414
Validation loss: 2.0674822766293763

Epoch: 6| Step: 3
Training loss: 2.3139567375183105
Validation loss: 2.0624740585204093

Epoch: 6| Step: 4
Training loss: 1.6464887857437134
Validation loss: 2.053533423331476

Epoch: 6| Step: 5
Training loss: 2.598170757293701
Validation loss: 2.0676286400005384

Epoch: 6| Step: 6
Training loss: 2.6160247325897217
Validation loss: 2.060315424396146

Epoch: 6| Step: 7
Training loss: 2.060197114944458
Validation loss: 2.0552873047449256

Epoch: 6| Step: 8
Training loss: 2.1077828407287598
Validation loss: 2.050099206227128

Epoch: 6| Step: 9
Training loss: 2.69120454788208
Validation loss: 2.0663474631565872

Epoch: 6| Step: 10
Training loss: 2.1071410179138184
Validation loss: 2.0573500228184525

Epoch: 6| Step: 11
Training loss: 1.279646635055542
Validation loss: 2.0506747922589703

Epoch: 6| Step: 12
Training loss: 2.3129827976226807
Validation loss: 2.070038882634973

Epoch: 6| Step: 13
Training loss: 2.650773763656616
Validation loss: 2.068655606239073

Epoch: 136| Step: 0
Training loss: 2.0600767135620117
Validation loss: 2.065288056609451

Epoch: 6| Step: 1
Training loss: 1.8754398822784424
Validation loss: 2.074528519825269

Epoch: 6| Step: 2
Training loss: 2.1292788982391357
Validation loss: 2.0614037770096973

Epoch: 6| Step: 3
Training loss: 3.0221915245056152
Validation loss: 2.081761083295268

Epoch: 6| Step: 4
Training loss: 1.9016602039337158
Validation loss: 2.0627697552404096

Epoch: 6| Step: 5
Training loss: 2.225816488265991
Validation loss: 2.056184079057427

Epoch: 6| Step: 6
Training loss: 2.273353338241577
Validation loss: 2.0517914731015443

Epoch: 6| Step: 7
Training loss: 1.77017343044281
Validation loss: 2.06246207990954

Epoch: 6| Step: 8
Training loss: 2.0363941192626953
Validation loss: 2.059683874089231

Epoch: 6| Step: 9
Training loss: 1.715919017791748
Validation loss: 2.0445287381449053

Epoch: 6| Step: 10
Training loss: 2.290808916091919
Validation loss: 2.075072165458433

Epoch: 6| Step: 11
Training loss: 2.726713180541992
Validation loss: 2.0520461477259153

Epoch: 6| Step: 12
Training loss: 1.8634769916534424
Validation loss: 2.085600701711511

Epoch: 6| Step: 13
Training loss: 2.950209856033325
Validation loss: 2.073695231509465

Epoch: 137| Step: 0
Training loss: 1.8004050254821777
Validation loss: 2.0662994410402034

Epoch: 6| Step: 1
Training loss: 2.219235897064209
Validation loss: 2.0816244668858026

Epoch: 6| Step: 2
Training loss: 1.7530181407928467
Validation loss: 2.0574209779821415

Epoch: 6| Step: 3
Training loss: 2.8165810108184814
Validation loss: 2.0939886044430476

Epoch: 6| Step: 4
Training loss: 2.543086528778076
Validation loss: 2.068654498746318

Epoch: 6| Step: 5
Training loss: 1.6097002029418945
Validation loss: 2.093606533542756

Epoch: 6| Step: 6
Training loss: 2.129983425140381
Validation loss: 2.082549807845905

Epoch: 6| Step: 7
Training loss: 2.087003707885742
Validation loss: 2.0768433283734065

Epoch: 6| Step: 8
Training loss: 2.8124780654907227
Validation loss: 2.0828018534568047

Epoch: 6| Step: 9
Training loss: 2.0237576961517334
Validation loss: 2.079537997963608

Epoch: 6| Step: 10
Training loss: 2.4083824157714844
Validation loss: 2.1062174509930354

Epoch: 6| Step: 11
Training loss: 1.4405839443206787
Validation loss: 2.096224666923605

Epoch: 6| Step: 12
Training loss: 1.9762072563171387
Validation loss: 2.085571260862453

Epoch: 6| Step: 13
Training loss: 3.265255928039551
Validation loss: 2.094699075145106

Epoch: 138| Step: 0
Training loss: 2.1808042526245117
Validation loss: 2.099803334923201

Epoch: 6| Step: 1
Training loss: 2.8095006942749023
Validation loss: 2.0861751853778796

Epoch: 6| Step: 2
Training loss: 2.2559828758239746
Validation loss: 2.093693669124316

Epoch: 6| Step: 3
Training loss: 2.123889446258545
Validation loss: 2.115086591371926

Epoch: 6| Step: 4
Training loss: 1.7702850103378296
Validation loss: 2.0959924613275835

Epoch: 6| Step: 5
Training loss: 2.0913944244384766
Validation loss: 2.0844801497715775

Epoch: 6| Step: 6
Training loss: 1.6183021068572998
Validation loss: 2.1004451756836264

Epoch: 6| Step: 7
Training loss: 2.0615592002868652
Validation loss: 2.1028921309337822

Epoch: 6| Step: 8
Training loss: 2.48146653175354
Validation loss: 2.099272810002809

Epoch: 6| Step: 9
Training loss: 1.7228419780731201
Validation loss: 2.095994634013022

Epoch: 6| Step: 10
Training loss: 2.5897722244262695
Validation loss: 2.1080714348823792

Epoch: 6| Step: 11
Training loss: 2.5706911087036133
Validation loss: 2.0840621738023657

Epoch: 6| Step: 12
Training loss: 1.7549004554748535
Validation loss: 2.0837833035376763

Epoch: 6| Step: 13
Training loss: 2.264410972595215
Validation loss: 2.11061607381349

Epoch: 139| Step: 0
Training loss: 2.734506607055664
Validation loss: 2.07699510358995

Epoch: 6| Step: 1
Training loss: 2.1849586963653564
Validation loss: 2.0854752115024033

Epoch: 6| Step: 2
Training loss: 2.4707257747650146
Validation loss: 2.081879213292112

Epoch: 6| Step: 3
Training loss: 2.6652376651763916
Validation loss: 2.092391433254365

Epoch: 6| Step: 4
Training loss: 2.2363953590393066
Validation loss: 2.0788525663396364

Epoch: 6| Step: 5
Training loss: 2.267054557800293
Validation loss: 2.0806428040227583

Epoch: 6| Step: 6
Training loss: 1.9226162433624268
Validation loss: 2.0789589881896973

Epoch: 6| Step: 7
Training loss: 1.8818848133087158
Validation loss: 2.0830419858296714

Epoch: 6| Step: 8
Training loss: 1.558031439781189
Validation loss: 2.0848129872352845

Epoch: 6| Step: 9
Training loss: 2.9149746894836426
Validation loss: 2.0947833548309984

Epoch: 6| Step: 10
Training loss: 2.2340505123138428
Validation loss: 2.088348465581094

Epoch: 6| Step: 11
Training loss: 2.096956729888916
Validation loss: 2.0641614544776177

Epoch: 6| Step: 12
Training loss: 1.017390251159668
Validation loss: 2.0960988229320896

Epoch: 6| Step: 13
Training loss: 1.824697494506836
Validation loss: 2.106294975485853

Epoch: 140| Step: 0
Training loss: 2.255905866622925
Validation loss: 2.0953299896691435

Epoch: 6| Step: 1
Training loss: 1.8714207410812378
Validation loss: 2.107247879428248

Epoch: 6| Step: 2
Training loss: 2.3252978324890137
Validation loss: 2.0857593551758797

Epoch: 6| Step: 3
Training loss: 1.890195608139038
Validation loss: 2.070420862526022

Epoch: 6| Step: 4
Training loss: 2.8459362983703613
Validation loss: 2.0749056057263444

Epoch: 6| Step: 5
Training loss: 1.712817907333374
Validation loss: 2.09990426545502

Epoch: 6| Step: 6
Training loss: 2.1276509761810303
Validation loss: 2.1177755427616898

Epoch: 6| Step: 7
Training loss: 2.3357813358306885
Validation loss: 2.048675048735834

Epoch: 6| Step: 8
Training loss: 2.2807726860046387
Validation loss: 2.0722743362508793

Epoch: 6| Step: 9
Training loss: 2.5826950073242188
Validation loss: 2.0959993639299945

Epoch: 6| Step: 10
Training loss: 1.7644010782241821
Validation loss: 2.073168049576462

Epoch: 6| Step: 11
Training loss: 2.31828236579895
Validation loss: 2.068437067411279

Epoch: 6| Step: 12
Training loss: 2.0442099571228027
Validation loss: 2.0904055744089107

Epoch: 6| Step: 13
Training loss: 2.0152347087860107
Validation loss: 2.0511151231745237

Epoch: 141| Step: 0
Training loss: 1.6390159130096436
Validation loss: 2.083139313164578

Epoch: 6| Step: 1
Training loss: 2.749387741088867
Validation loss: 2.091655295382264

Epoch: 6| Step: 2
Training loss: 1.854623794555664
Validation loss: 2.0705502879235054

Epoch: 6| Step: 3
Training loss: 3.0050127506256104
Validation loss: 2.0803685495930333

Epoch: 6| Step: 4
Training loss: 2.4996156692504883
Validation loss: 2.0940390620180356

Epoch: 6| Step: 5
Training loss: 1.4599782228469849
Validation loss: 2.090521776547996

Epoch: 6| Step: 6
Training loss: 2.418181896209717
Validation loss: 2.0851285867793585

Epoch: 6| Step: 7
Training loss: 1.9946593046188354
Validation loss: 2.1134521871484737

Epoch: 6| Step: 8
Training loss: 2.548048973083496
Validation loss: 2.0985034050480014

Epoch: 6| Step: 9
Training loss: 2.401081085205078
Validation loss: 2.086902815808532

Epoch: 6| Step: 10
Training loss: 1.7516392469406128
Validation loss: 2.0739619296084166

Epoch: 6| Step: 11
Training loss: 1.8382766246795654
Validation loss: 2.09554950908948

Epoch: 6| Step: 12
Training loss: 2.6568260192871094
Validation loss: 2.0876225027986752

Epoch: 6| Step: 13
Training loss: 1.3150389194488525
Validation loss: 2.065414656874954

Epoch: 142| Step: 0
Training loss: 1.6899487972259521
Validation loss: 2.0861518998299875

Epoch: 6| Step: 1
Training loss: 2.5893185138702393
Validation loss: 2.064738635093935

Epoch: 6| Step: 2
Training loss: 2.3663809299468994
Validation loss: 2.072383963933555

Epoch: 6| Step: 3
Training loss: 2.2057008743286133
Validation loss: 2.0839899701456868

Epoch: 6| Step: 4
Training loss: 2.379497528076172
Validation loss: 2.0723844856344242

Epoch: 6| Step: 5
Training loss: 2.2958710193634033
Validation loss: 2.0920432562469156

Epoch: 6| Step: 6
Training loss: 2.644866466522217
Validation loss: 2.0905625512523036

Epoch: 6| Step: 7
Training loss: 1.830706000328064
Validation loss: 2.091476801903017

Epoch: 6| Step: 8
Training loss: 1.8955131769180298
Validation loss: 2.096655104749946

Epoch: 6| Step: 9
Training loss: 2.5561187267303467
Validation loss: 2.0739262744944584

Epoch: 6| Step: 10
Training loss: 1.7927472591400146
Validation loss: 2.073879631616736

Epoch: 6| Step: 11
Training loss: 2.5088706016540527
Validation loss: 2.116188874808691

Epoch: 6| Step: 12
Training loss: 1.8100123405456543
Validation loss: 2.1058376232783

Epoch: 6| Step: 13
Training loss: 1.943550705909729
Validation loss: 2.0722059793369745

Epoch: 143| Step: 0
Training loss: 2.243251085281372
Validation loss: 2.086739851582435

Epoch: 6| Step: 1
Training loss: 3.0320558547973633
Validation loss: 2.070477234419956

Epoch: 6| Step: 2
Training loss: 2.2726287841796875
Validation loss: 2.1016702523795505

Epoch: 6| Step: 3
Training loss: 2.107206344604492
Validation loss: 2.0732282694949897

Epoch: 6| Step: 4
Training loss: 1.6662302017211914
Validation loss: 2.0750892751960346

Epoch: 6| Step: 5
Training loss: 1.7786056995391846
Validation loss: 2.066748816479919

Epoch: 6| Step: 6
Training loss: 2.144548177719116
Validation loss: 2.0839777813162854

Epoch: 6| Step: 7
Training loss: 1.8377876281738281
Validation loss: 2.081420129345309

Epoch: 6| Step: 8
Training loss: 2.213913917541504
Validation loss: 2.0773327119888796

Epoch: 6| Step: 9
Training loss: 1.3147492408752441
Validation loss: 2.0626329324578725

Epoch: 6| Step: 10
Training loss: 2.382608413696289
Validation loss: 2.052370978939918

Epoch: 6| Step: 11
Training loss: 2.5770316123962402
Validation loss: 2.0647039567270586

Epoch: 6| Step: 12
Training loss: 2.747041940689087
Validation loss: 2.0715384701246857

Epoch: 6| Step: 13
Training loss: 1.6891326904296875
Validation loss: 2.073691442448606

Epoch: 144| Step: 0
Training loss: 2.410860538482666
Validation loss: 2.055676060338174

Epoch: 6| Step: 1
Training loss: 1.776414155960083
Validation loss: 2.0991991796801166

Epoch: 6| Step: 2
Training loss: 2.35223388671875
Validation loss: 2.0752421707235356

Epoch: 6| Step: 3
Training loss: 3.524916172027588
Validation loss: 2.0587150948022

Epoch: 6| Step: 4
Training loss: 2.6261157989501953
Validation loss: 2.0470556341191775

Epoch: 6| Step: 5
Training loss: 2.8627166748046875
Validation loss: 2.074768973935035

Epoch: 6| Step: 6
Training loss: 1.7095143795013428
Validation loss: 2.0379653041080763

Epoch: 6| Step: 7
Training loss: 2.0589759349823
Validation loss: 2.0561394460739626

Epoch: 6| Step: 8
Training loss: 2.079211711883545
Validation loss: 2.062856181975334

Epoch: 6| Step: 9
Training loss: 1.8366925716400146
Validation loss: 2.039422554354514

Epoch: 6| Step: 10
Training loss: 2.387054443359375
Validation loss: 2.062607434488112

Epoch: 6| Step: 11
Training loss: 1.8798367977142334
Validation loss: 2.0482488011801117

Epoch: 6| Step: 12
Training loss: 1.2192496061325073
Validation loss: 2.071822376661403

Epoch: 6| Step: 13
Training loss: 1.3260776996612549
Validation loss: 2.0388168609270485

Epoch: 145| Step: 0
Training loss: 2.3150906562805176
Validation loss: 2.0581126546347015

Epoch: 6| Step: 1
Training loss: 1.81758713722229
Validation loss: 2.05486467576796

Epoch: 6| Step: 2
Training loss: 1.5387022495269775
Validation loss: 2.0715169598979335

Epoch: 6| Step: 3
Training loss: 2.011669397354126
Validation loss: 2.081698217699605

Epoch: 6| Step: 4
Training loss: 2.4284815788269043
Validation loss: 2.068965365809779

Epoch: 6| Step: 5
Training loss: 2.4065656661987305
Validation loss: 2.086710041569125

Epoch: 6| Step: 6
Training loss: 2.0393519401550293
Validation loss: 2.077503852946784

Epoch: 6| Step: 7
Training loss: 2.1128718852996826
Validation loss: 2.111259696304157

Epoch: 6| Step: 8
Training loss: 1.6303588151931763
Validation loss: 2.0824167190059537

Epoch: 6| Step: 9
Training loss: 2.4458374977111816
Validation loss: 2.0901385891822075

Epoch: 6| Step: 10
Training loss: 2.585598945617676
Validation loss: 2.064019459550099

Epoch: 6| Step: 11
Training loss: 2.247361421585083
Validation loss: 2.095942122961885

Epoch: 6| Step: 12
Training loss: 2.3909411430358887
Validation loss: 2.0947234656221125

Epoch: 6| Step: 13
Training loss: 2.7562918663024902
Validation loss: 2.0994246775104153

Epoch: 146| Step: 0
Training loss: 2.456068754196167
Validation loss: 2.097509576428321

Epoch: 6| Step: 1
Training loss: 2.1018331050872803
Validation loss: 2.0822193878953175

Epoch: 6| Step: 2
Training loss: 2.67624568939209
Validation loss: 2.0934880548907864

Epoch: 6| Step: 3
Training loss: 1.616173505783081
Validation loss: 2.0713670010207803

Epoch: 6| Step: 4
Training loss: 1.7412495613098145
Validation loss: 2.090875453846429

Epoch: 6| Step: 5
Training loss: 2.13112735748291
Validation loss: 2.082963506380717

Epoch: 6| Step: 6
Training loss: 2.018043041229248
Validation loss: 2.077842515002015

Epoch: 6| Step: 7
Training loss: 2.297187566757202
Validation loss: 2.08142565911816

Epoch: 6| Step: 8
Training loss: 2.2128448486328125
Validation loss: 2.1313336562084895

Epoch: 6| Step: 9
Training loss: 2.164767265319824
Validation loss: 2.086104139204948

Epoch: 6| Step: 10
Training loss: 2.409670829772949
Validation loss: 2.084709311044344

Epoch: 6| Step: 11
Training loss: 1.606459379196167
Validation loss: 2.0802542830026276

Epoch: 6| Step: 12
Training loss: 2.6240553855895996
Validation loss: 2.099110275186518

Epoch: 6| Step: 13
Training loss: 2.619516372680664
Validation loss: 2.0645353537733837

Epoch: 147| Step: 0
Training loss: 1.3344162702560425
Validation loss: 2.071929411221576

Epoch: 6| Step: 1
Training loss: 1.527274489402771
Validation loss: 2.0841084090612267

Epoch: 6| Step: 2
Training loss: 2.6051025390625
Validation loss: 2.068592168951547

Epoch: 6| Step: 3
Training loss: 1.61333167552948
Validation loss: 2.079395012188983

Epoch: 6| Step: 4
Training loss: 2.0416910648345947
Validation loss: 2.090133951556298

Epoch: 6| Step: 5
Training loss: 2.4703006744384766
Validation loss: 2.0840171652455486

Epoch: 6| Step: 6
Training loss: 2.457989454269409
Validation loss: 2.0826476350907357

Epoch: 6| Step: 7
Training loss: 2.891796827316284
Validation loss: 2.0810671955026607

Epoch: 6| Step: 8
Training loss: 1.9438791275024414
Validation loss: 2.0946169963446994

Epoch: 6| Step: 9
Training loss: 1.7490365505218506
Validation loss: 2.089851115339546

Epoch: 6| Step: 10
Training loss: 2.181699752807617
Validation loss: 2.1032345961498957

Epoch: 6| Step: 11
Training loss: 2.9702773094177246
Validation loss: 2.0788690223488757

Epoch: 6| Step: 12
Training loss: 2.3848137855529785
Validation loss: 2.115187268103323

Epoch: 6| Step: 13
Training loss: 1.9441865682601929
Validation loss: 2.0929343764499952

Epoch: 148| Step: 0
Training loss: 1.8099117279052734
Validation loss: 2.097645139181486

Epoch: 6| Step: 1
Training loss: 2.6415908336639404
Validation loss: 2.111501407879655

Epoch: 6| Step: 2
Training loss: 2.2560548782348633
Validation loss: 2.102528674628145

Epoch: 6| Step: 3
Training loss: 2.3197741508483887
Validation loss: 2.084081812571454

Epoch: 6| Step: 4
Training loss: 2.1845171451568604
Validation loss: 2.097303205920804

Epoch: 6| Step: 5
Training loss: 2.348036766052246
Validation loss: 2.1095446053371636

Epoch: 6| Step: 6
Training loss: 2.0398216247558594
Validation loss: 2.1013744505502845

Epoch: 6| Step: 7
Training loss: 2.02846360206604
Validation loss: 2.1080460010036344

Epoch: 6| Step: 8
Training loss: 1.6698718070983887
Validation loss: 2.112489879772227

Epoch: 6| Step: 9
Training loss: 3.027817487716675
Validation loss: 2.1317955063235376

Epoch: 6| Step: 10
Training loss: 2.2239768505096436
Validation loss: 2.122815324414161

Epoch: 6| Step: 11
Training loss: 1.4099857807159424
Validation loss: 2.103772051872746

Epoch: 6| Step: 12
Training loss: 1.9589385986328125
Validation loss: 2.1160210127471597

Epoch: 6| Step: 13
Training loss: 2.5092811584472656
Validation loss: 2.1115815511313816

Epoch: 149| Step: 0
Training loss: 1.8596631288528442
Validation loss: 2.089990492789976

Epoch: 6| Step: 1
Training loss: 2.480072021484375
Validation loss: 2.1021292132716023

Epoch: 6| Step: 2
Training loss: 2.0827243328094482
Validation loss: 2.1265036623965026

Epoch: 6| Step: 3
Training loss: 2.083571672439575
Validation loss: 2.109674543462774

Epoch: 6| Step: 4
Training loss: 1.8181204795837402
Validation loss: 2.09568432582322

Epoch: 6| Step: 5
Training loss: 2.242734432220459
Validation loss: 2.1138810252630584

Epoch: 6| Step: 6
Training loss: 2.234622001647949
Validation loss: 2.1064049787418817

Epoch: 6| Step: 7
Training loss: 1.773392915725708
Validation loss: 2.0997042976399904

Epoch: 6| Step: 8
Training loss: 2.16546893119812
Validation loss: 2.113074110400292

Epoch: 6| Step: 9
Training loss: 2.4380784034729004
Validation loss: 2.0665064306669336

Epoch: 6| Step: 10
Training loss: 1.854844331741333
Validation loss: 2.0869452312428463

Epoch: 6| Step: 11
Training loss: 2.3433828353881836
Validation loss: 2.1269487732200214

Epoch: 6| Step: 12
Training loss: 2.312049388885498
Validation loss: 2.088407511352211

Epoch: 6| Step: 13
Training loss: 2.6354870796203613
Validation loss: 2.0944836575497865

Epoch: 150| Step: 0
Training loss: 2.110410213470459
Validation loss: 2.10184363267755

Epoch: 6| Step: 1
Training loss: 2.1917717456817627
Validation loss: 2.0898615301296277

Epoch: 6| Step: 2
Training loss: 2.293804168701172
Validation loss: 2.0894907238662883

Epoch: 6| Step: 3
Training loss: 2.5898361206054688
Validation loss: 2.099588946629596

Epoch: 6| Step: 4
Training loss: 1.467668056488037
Validation loss: 2.0828540889165734

Epoch: 6| Step: 5
Training loss: 1.8566675186157227
Validation loss: 2.089632213756602

Epoch: 6| Step: 6
Training loss: 1.8673150539398193
Validation loss: 2.0793498716046734

Epoch: 6| Step: 7
Training loss: 2.1757659912109375
Validation loss: 2.0727927748874952

Epoch: 6| Step: 8
Training loss: 2.732290744781494
Validation loss: 2.0654063891339045

Epoch: 6| Step: 9
Training loss: 2.1872615814208984
Validation loss: 2.0721187360825075

Epoch: 6| Step: 10
Training loss: 2.3300204277038574
Validation loss: 2.066503196634272

Epoch: 6| Step: 11
Training loss: 2.4911551475524902
Validation loss: 2.0707615319118706

Epoch: 6| Step: 12
Training loss: 1.9576663970947266
Validation loss: 2.0676889470828477

Epoch: 6| Step: 13
Training loss: 1.6866259574890137
Validation loss: 2.0610935149654264

Epoch: 151| Step: 0
Training loss: 2.0662264823913574
Validation loss: 2.06922209647394

Epoch: 6| Step: 1
Training loss: 1.6107940673828125
Validation loss: 2.0681231637154855

Epoch: 6| Step: 2
Training loss: 2.7292191982269287
Validation loss: 2.04817593994961

Epoch: 6| Step: 3
Training loss: 1.9022372961044312
Validation loss: 2.084321445034396

Epoch: 6| Step: 4
Training loss: 2.173135280609131
Validation loss: 2.068460997714791

Epoch: 6| Step: 5
Training loss: 2.5070314407348633
Validation loss: 2.0861691582587456

Epoch: 6| Step: 6
Training loss: 2.1853063106536865
Validation loss: 2.075659624991878

Epoch: 6| Step: 7
Training loss: 2.256246566772461
Validation loss: 2.063217124631328

Epoch: 6| Step: 8
Training loss: 1.736411690711975
Validation loss: 2.0838167193115398

Epoch: 6| Step: 9
Training loss: 1.4526453018188477
Validation loss: 2.0888707022513113

Epoch: 6| Step: 10
Training loss: 2.112283229827881
Validation loss: 2.102739505870368

Epoch: 6| Step: 11
Training loss: 2.4555397033691406
Validation loss: 2.0998922804350495

Epoch: 6| Step: 12
Training loss: 2.960832118988037
Validation loss: 2.0796986728586178

Epoch: 6| Step: 13
Training loss: 2.448676586151123
Validation loss: 2.1018528822929627

Epoch: 152| Step: 0
Training loss: 2.560746669769287
Validation loss: 2.10312605673267

Epoch: 6| Step: 1
Training loss: 2.2059996128082275
Validation loss: 2.1049901900752896

Epoch: 6| Step: 2
Training loss: 2.652273416519165
Validation loss: 2.0938256043259815

Epoch: 6| Step: 3
Training loss: 2.415874481201172
Validation loss: 2.0928347162021104

Epoch: 6| Step: 4
Training loss: 2.4807915687561035
Validation loss: 2.084674827514156

Epoch: 6| Step: 5
Training loss: 1.5572700500488281
Validation loss: 2.071123764079104

Epoch: 6| Step: 6
Training loss: 1.7997584342956543
Validation loss: 2.051754782276769

Epoch: 6| Step: 7
Training loss: 1.8438775539398193
Validation loss: 2.0723607258130143

Epoch: 6| Step: 8
Training loss: 1.8537250757217407
Validation loss: 2.109037119855163

Epoch: 6| Step: 9
Training loss: 2.9395360946655273
Validation loss: 2.0673733911206646

Epoch: 6| Step: 10
Training loss: 1.819136381149292
Validation loss: 2.098995538168056

Epoch: 6| Step: 11
Training loss: 1.4698282480239868
Validation loss: 2.0847115311571347

Epoch: 6| Step: 12
Training loss: 2.766233444213867
Validation loss: 2.0738519519887944

Epoch: 6| Step: 13
Training loss: 1.7746758460998535
Validation loss: 2.0737604069453415

Epoch: 153| Step: 0
Training loss: 3.1456644535064697
Validation loss: 2.0779489240338727

Epoch: 6| Step: 1
Training loss: 2.830919027328491
Validation loss: 2.0899778360961587

Epoch: 6| Step: 2
Training loss: 2.359323501586914
Validation loss: 2.1066003627674554

Epoch: 6| Step: 3
Training loss: 1.7064499855041504
Validation loss: 2.0796377658843994

Epoch: 6| Step: 4
Training loss: 2.6795830726623535
Validation loss: 2.1024661576876076

Epoch: 6| Step: 5
Training loss: 2.5246191024780273
Validation loss: 2.103426056523477

Epoch: 6| Step: 6
Training loss: 1.8678878545761108
Validation loss: 2.11153244972229

Epoch: 6| Step: 7
Training loss: 1.8377020359039307
Validation loss: 2.0983994519838722

Epoch: 6| Step: 8
Training loss: 1.6389567852020264
Validation loss: 2.120013303654168

Epoch: 6| Step: 9
Training loss: 1.7812256813049316
Validation loss: 2.1203594464127735

Epoch: 6| Step: 10
Training loss: 1.8355389833450317
Validation loss: 2.1263034356537687

Epoch: 6| Step: 11
Training loss: 2.068918466567993
Validation loss: 2.1135575796968196

Epoch: 6| Step: 12
Training loss: 2.4070587158203125
Validation loss: 2.1102975568463727

Epoch: 6| Step: 13
Training loss: 1.4868190288543701
Validation loss: 2.101662779367098

Epoch: 154| Step: 0
Training loss: 2.073075771331787
Validation loss: 2.104656204100578

Epoch: 6| Step: 1
Training loss: 2.678165912628174
Validation loss: 2.1218636587101924

Epoch: 6| Step: 2
Training loss: 2.4288575649261475
Validation loss: 2.100825012371104

Epoch: 6| Step: 3
Training loss: 2.53533935546875
Validation loss: 2.1439458426608833

Epoch: 6| Step: 4
Training loss: 1.8660571575164795
Validation loss: 2.0910630110771424

Epoch: 6| Step: 5
Training loss: 2.025609016418457
Validation loss: 2.1143875378434376

Epoch: 6| Step: 6
Training loss: 1.9598536491394043
Validation loss: 2.083985440192684

Epoch: 6| Step: 7
Training loss: 1.6565711498260498
Validation loss: 2.0907508275842153

Epoch: 6| Step: 8
Training loss: 2.7994279861450195
Validation loss: 2.0915319163312196

Epoch: 6| Step: 9
Training loss: 1.6020565032958984
Validation loss: 2.1052946672644666

Epoch: 6| Step: 10
Training loss: 1.8415297269821167
Validation loss: 2.0553607325400076

Epoch: 6| Step: 11
Training loss: 1.798498511314392
Validation loss: 2.068966791193972

Epoch: 6| Step: 12
Training loss: 2.903826951980591
Validation loss: 2.0972691735913678

Epoch: 6| Step: 13
Training loss: 1.7764750719070435
Validation loss: 2.092248788443945

Epoch: 155| Step: 0
Training loss: 2.0693957805633545
Validation loss: 2.077074889213808

Epoch: 6| Step: 1
Training loss: 1.850168228149414
Validation loss: 2.071341770951466

Epoch: 6| Step: 2
Training loss: 1.42063570022583
Validation loss: 2.0618314153404644

Epoch: 6| Step: 3
Training loss: 2.395174503326416
Validation loss: 2.0647761501291746

Epoch: 6| Step: 4
Training loss: 2.505490779876709
Validation loss: 2.077591057746641

Epoch: 6| Step: 5
Training loss: 2.643357276916504
Validation loss: 2.043780606280091

Epoch: 6| Step: 6
Training loss: 2.0201621055603027
Validation loss: 2.0623374369836625

Epoch: 6| Step: 7
Training loss: 2.023453712463379
Validation loss: 2.056032984487472

Epoch: 6| Step: 8
Training loss: 2.0707290172576904
Validation loss: 2.0611928406582085

Epoch: 6| Step: 9
Training loss: 2.37795352935791
Validation loss: 2.083009858285227

Epoch: 6| Step: 10
Training loss: 2.260361671447754
Validation loss: 2.0658263493609685

Epoch: 6| Step: 11
Training loss: 2.081224203109741
Validation loss: 2.058347084188974

Epoch: 6| Step: 12
Training loss: 2.07702374458313
Validation loss: 2.054408043943426

Epoch: 6| Step: 13
Training loss: 3.023799180984497
Validation loss: 2.072932425365653

Epoch: 156| Step: 0
Training loss: 2.4916796684265137
Validation loss: 2.0652668117195048

Epoch: 6| Step: 1
Training loss: 1.6074817180633545
Validation loss: 2.065992281001101

Epoch: 6| Step: 2
Training loss: 1.8108323812484741
Validation loss: 2.075949493274894

Epoch: 6| Step: 3
Training loss: 2.0403714179992676
Validation loss: 2.079430427602542

Epoch: 6| Step: 4
Training loss: 1.6541281938552856
Validation loss: 2.075971980248728

Epoch: 6| Step: 5
Training loss: 1.8709361553192139
Validation loss: 2.076691515984074

Epoch: 6| Step: 6
Training loss: 2.571765184402466
Validation loss: 2.0779517773658998

Epoch: 6| Step: 7
Training loss: 2.5169386863708496
Validation loss: 2.055441597456573

Epoch: 6| Step: 8
Training loss: 2.2189600467681885
Validation loss: 2.063667966473487

Epoch: 6| Step: 9
Training loss: 2.0697884559631348
Validation loss: 2.045509079451202

Epoch: 6| Step: 10
Training loss: 2.162343740463257
Validation loss: 2.073844284139654

Epoch: 6| Step: 11
Training loss: 2.5138659477233887
Validation loss: 2.087717786911995

Epoch: 6| Step: 12
Training loss: 2.0760984420776367
Validation loss: 2.069929402361634

Epoch: 6| Step: 13
Training loss: 2.646977663040161
Validation loss: 2.0772368061927056

Epoch: 157| Step: 0
Training loss: 2.1789536476135254
Validation loss: 2.078512689118744

Epoch: 6| Step: 1
Training loss: 2.201892852783203
Validation loss: 2.0618559250267605

Epoch: 6| Step: 2
Training loss: 2.612586498260498
Validation loss: 2.058826945161307

Epoch: 6| Step: 3
Training loss: 2.844064712524414
Validation loss: 2.0972373165110105

Epoch: 6| Step: 4
Training loss: 1.3907387256622314
Validation loss: 2.0679640359775995

Epoch: 6| Step: 5
Training loss: 2.1849076747894287
Validation loss: 2.082184724910285

Epoch: 6| Step: 6
Training loss: 2.1621830463409424
Validation loss: 2.076361612607074

Epoch: 6| Step: 7
Training loss: 1.4224753379821777
Validation loss: 2.076284844388244

Epoch: 6| Step: 8
Training loss: 1.9170517921447754
Validation loss: 2.0948289927615913

Epoch: 6| Step: 9
Training loss: 2.1618380546569824
Validation loss: 2.0461996370746243

Epoch: 6| Step: 10
Training loss: 2.4531702995300293
Validation loss: 2.0469085196013093

Epoch: 6| Step: 11
Training loss: 2.367550849914551
Validation loss: 2.0992952008401193

Epoch: 6| Step: 12
Training loss: 2.193807601928711
Validation loss: 2.071819284910797

Epoch: 6| Step: 13
Training loss: 2.186325788497925
Validation loss: 2.059567041294549

Epoch: 158| Step: 0
Training loss: 2.508321762084961
Validation loss: 2.0470155592887633

Epoch: 6| Step: 1
Training loss: 1.8856594562530518
Validation loss: 2.0803703082505094

Epoch: 6| Step: 2
Training loss: 1.7263915538787842
Validation loss: 2.1030333362599856

Epoch: 6| Step: 3
Training loss: 2.0763392448425293
Validation loss: 2.0897977147051083

Epoch: 6| Step: 4
Training loss: 2.1025078296661377
Validation loss: 2.074826991686257

Epoch: 6| Step: 5
Training loss: 2.3964083194732666
Validation loss: 2.0933829533156527

Epoch: 6| Step: 6
Training loss: 1.7483444213867188
Validation loss: 2.0928898447303363

Epoch: 6| Step: 7
Training loss: 1.9626269340515137
Validation loss: 2.08838302089322

Epoch: 6| Step: 8
Training loss: 2.4700927734375
Validation loss: 2.0974968710253314

Epoch: 6| Step: 9
Training loss: 2.202749729156494
Validation loss: 2.0840938014368855

Epoch: 6| Step: 10
Training loss: 2.543984889984131
Validation loss: 2.0999970333550566

Epoch: 6| Step: 11
Training loss: 2.3967642784118652
Validation loss: 2.1062871410000708

Epoch: 6| Step: 12
Training loss: 2.1031525135040283
Validation loss: 2.1165909459514003

Epoch: 6| Step: 13
Training loss: 1.6772540807724
Validation loss: 2.098316490009267

Epoch: 159| Step: 0
Training loss: 2.0111403465270996
Validation loss: 2.099638722276175

Epoch: 6| Step: 1
Training loss: 2.8468055725097656
Validation loss: 2.1092475870604157

Epoch: 6| Step: 2
Training loss: 2.007148504257202
Validation loss: 2.115397253344136

Epoch: 6| Step: 3
Training loss: 1.8502421379089355
Validation loss: 2.0827658842968684

Epoch: 6| Step: 4
Training loss: 2.2650012969970703
Validation loss: 2.0975620259520826

Epoch: 6| Step: 5
Training loss: 2.406602382659912
Validation loss: 2.075619166897189

Epoch: 6| Step: 6
Training loss: 1.7385025024414062
Validation loss: 2.0963583505281838

Epoch: 6| Step: 7
Training loss: 3.1029839515686035
Validation loss: 2.0989367910610732

Epoch: 6| Step: 8
Training loss: 2.471534490585327
Validation loss: 2.1035555895938667

Epoch: 6| Step: 9
Training loss: 1.8217835426330566
Validation loss: 2.075594461092385

Epoch: 6| Step: 10
Training loss: 1.6497958898544312
Validation loss: 2.096493201871072

Epoch: 6| Step: 11
Training loss: 1.6246943473815918
Validation loss: 2.079389738780196

Epoch: 6| Step: 12
Training loss: 2.1705121994018555
Validation loss: 2.0991686505656086

Epoch: 6| Step: 13
Training loss: 2.231719493865967
Validation loss: 2.0802716773043395

Epoch: 160| Step: 0
Training loss: 1.9480466842651367
Validation loss: 2.1039055060314875

Epoch: 6| Step: 1
Training loss: 2.3791685104370117
Validation loss: 2.0983179615389917

Epoch: 6| Step: 2
Training loss: 2.8832831382751465
Validation loss: 2.0933653359772055

Epoch: 6| Step: 3
Training loss: 2.419121742248535
Validation loss: 2.084332654553075

Epoch: 6| Step: 4
Training loss: 2.703134298324585
Validation loss: 2.0932564209866267

Epoch: 6| Step: 5
Training loss: 1.934781551361084
Validation loss: 2.113424560075165

Epoch: 6| Step: 6
Training loss: 2.102159023284912
Validation loss: 2.090346695274435

Epoch: 6| Step: 7
Training loss: 1.5731709003448486
Validation loss: 2.1179727328720914

Epoch: 6| Step: 8
Training loss: 2.1212334632873535
Validation loss: 2.103991993011967

Epoch: 6| Step: 9
Training loss: 2.1355135440826416
Validation loss: 2.1196471209167154

Epoch: 6| Step: 10
Training loss: 1.5897079706192017
Validation loss: 2.1112645210758334

Epoch: 6| Step: 11
Training loss: 1.8560707569122314
Validation loss: 2.098711911068168

Epoch: 6| Step: 12
Training loss: 2.5674915313720703
Validation loss: 2.083546253942674

Epoch: 6| Step: 13
Training loss: 1.6394587755203247
Validation loss: 2.1072592530199277

Epoch: 161| Step: 0
Training loss: 1.7367607355117798
Validation loss: 2.086283399212745

Epoch: 6| Step: 1
Training loss: 2.759826183319092
Validation loss: 2.1039072775071666

Epoch: 6| Step: 2
Training loss: 1.8376476764678955
Validation loss: 2.1271213280257357

Epoch: 6| Step: 3
Training loss: 2.073758125305176
Validation loss: 2.1096300873705136

Epoch: 6| Step: 4
Training loss: 1.9209227561950684
Validation loss: 2.1134693750771145

Epoch: 6| Step: 5
Training loss: 2.3506245613098145
Validation loss: 2.1092719762556014

Epoch: 6| Step: 6
Training loss: 2.0870096683502197
Validation loss: 2.116128474153498

Epoch: 6| Step: 7
Training loss: 1.1154018640518188
Validation loss: 2.132654854046401

Epoch: 6| Step: 8
Training loss: 1.8102293014526367
Validation loss: 2.118955112272693

Epoch: 6| Step: 9
Training loss: 3.7580373287200928
Validation loss: 2.1207645323968705

Epoch: 6| Step: 10
Training loss: 1.9651501178741455
Validation loss: 2.1431168099885345

Epoch: 6| Step: 11
Training loss: 2.934528112411499
Validation loss: 2.1190508821959138

Epoch: 6| Step: 12
Training loss: 1.8281664848327637
Validation loss: 2.158148960400653

Epoch: 6| Step: 13
Training loss: 1.5490753650665283
Validation loss: 2.1489546273344304

Epoch: 162| Step: 0
Training loss: 1.7751365900039673
Validation loss: 2.117335642537763

Epoch: 6| Step: 1
Training loss: 1.8057066202163696
Validation loss: 2.1124611054697344

Epoch: 6| Step: 2
Training loss: 2.149275064468384
Validation loss: 2.137474401022798

Epoch: 6| Step: 3
Training loss: 2.065843105316162
Validation loss: 2.1612630377533617

Epoch: 6| Step: 4
Training loss: 1.8335075378417969
Validation loss: 2.1073704727234377

Epoch: 6| Step: 5
Training loss: 2.2642288208007812
Validation loss: 2.119227106853198

Epoch: 6| Step: 6
Training loss: 2.538198947906494
Validation loss: 2.0997477731397076

Epoch: 6| Step: 7
Training loss: 2.3599853515625
Validation loss: 2.0976292035912953

Epoch: 6| Step: 8
Training loss: 2.254305601119995
Validation loss: 2.0601445808205554

Epoch: 6| Step: 9
Training loss: 2.0655112266540527
Validation loss: 2.072867352475402

Epoch: 6| Step: 10
Training loss: 2.0981292724609375
Validation loss: 2.084797211872634

Epoch: 6| Step: 11
Training loss: 1.9384561777114868
Validation loss: 2.078640798086761

Epoch: 6| Step: 12
Training loss: 2.322122097015381
Validation loss: 2.0912358889015774

Epoch: 6| Step: 13
Training loss: 2.6351158618927
Validation loss: 2.0785588487502067

Epoch: 163| Step: 0
Training loss: 1.6964919567108154
Validation loss: 2.0900095034671087

Epoch: 6| Step: 1
Training loss: 2.221787214279175
Validation loss: 2.100554007355885

Epoch: 6| Step: 2
Training loss: 2.7122678756713867
Validation loss: 2.0816469718051214

Epoch: 6| Step: 3
Training loss: 2.0528383255004883
Validation loss: 2.0774947545861684

Epoch: 6| Step: 4
Training loss: 2.866450309753418
Validation loss: 2.0797781021364274

Epoch: 6| Step: 5
Training loss: 1.7308845520019531
Validation loss: 2.083336196919923

Epoch: 6| Step: 6
Training loss: 2.1906895637512207
Validation loss: 2.0797975550415697

Epoch: 6| Step: 7
Training loss: 2.3379340171813965
Validation loss: 2.104526376211515

Epoch: 6| Step: 8
Training loss: 2.3783223628997803
Validation loss: 2.0783332752925094

Epoch: 6| Step: 9
Training loss: 2.1598873138427734
Validation loss: 2.067586545021303

Epoch: 6| Step: 10
Training loss: 1.727372169494629
Validation loss: 2.0717118658045286

Epoch: 6| Step: 11
Training loss: 1.7993757724761963
Validation loss: 2.0463713830517185

Epoch: 6| Step: 12
Training loss: 2.221590995788574
Validation loss: 2.086102674084325

Epoch: 6| Step: 13
Training loss: 1.4691734313964844
Validation loss: 2.0817091682905793

Epoch: 164| Step: 0
Training loss: 2.5206503868103027
Validation loss: 2.080046187164963

Epoch: 6| Step: 1
Training loss: 1.7337980270385742
Validation loss: 2.057027929572649

Epoch: 6| Step: 2
Training loss: 1.8901677131652832
Validation loss: 2.0991182122179257

Epoch: 6| Step: 3
Training loss: 2.2222187519073486
Validation loss: 2.0918226703520744

Epoch: 6| Step: 4
Training loss: 1.901238203048706
Validation loss: 2.0832239709874636

Epoch: 6| Step: 5
Training loss: 2.4687092304229736
Validation loss: 2.072172854536323

Epoch: 6| Step: 6
Training loss: 2.7723512649536133
Validation loss: 2.0835383694658995

Epoch: 6| Step: 7
Training loss: 1.9060935974121094
Validation loss: 2.097300144933885

Epoch: 6| Step: 8
Training loss: 1.1112163066864014
Validation loss: 2.1090518620706376

Epoch: 6| Step: 9
Training loss: 1.8999671936035156
Validation loss: 2.1190396995954615

Epoch: 6| Step: 10
Training loss: 2.58699369430542
Validation loss: 2.1338743804603495

Epoch: 6| Step: 11
Training loss: 1.8176292181015015
Validation loss: 2.0884116618863997

Epoch: 6| Step: 12
Training loss: 2.293074131011963
Validation loss: 2.0926157582190728

Epoch: 6| Step: 13
Training loss: 3.0549142360687256
Validation loss: 2.1037696433323685

Epoch: 165| Step: 0
Training loss: 1.3927624225616455
Validation loss: 2.1426406111768497

Epoch: 6| Step: 1
Training loss: 1.6520230770111084
Validation loss: 2.0806847272380704

Epoch: 6| Step: 2
Training loss: 2.395406723022461
Validation loss: 2.12336044157705

Epoch: 6| Step: 3
Training loss: 2.3508944511413574
Validation loss: 2.1168067404018935

Epoch: 6| Step: 4
Training loss: 2.479118824005127
Validation loss: 2.0965313091072986

Epoch: 6| Step: 5
Training loss: 2.748316764831543
Validation loss: 2.11141739865785

Epoch: 6| Step: 6
Training loss: 2.0429327487945557
Validation loss: 2.127035197391305

Epoch: 6| Step: 7
Training loss: 2.4159703254699707
Validation loss: 2.1301440769626248

Epoch: 6| Step: 8
Training loss: 2.4755685329437256
Validation loss: 2.1464418339472946

Epoch: 6| Step: 9
Training loss: 1.9690313339233398
Validation loss: 2.1331382220791233

Epoch: 6| Step: 10
Training loss: 1.665778636932373
Validation loss: 2.1353418621965634

Epoch: 6| Step: 11
Training loss: 1.8658106327056885
Validation loss: 2.132445909643686

Epoch: 6| Step: 12
Training loss: 2.452387809753418
Validation loss: 2.1313593451694777

Epoch: 6| Step: 13
Training loss: 1.485021710395813
Validation loss: 2.119622788121623

Epoch: 166| Step: 0
Training loss: 2.370022773742676
Validation loss: 2.13016523597061

Epoch: 6| Step: 1
Training loss: 2.3727712631225586
Validation loss: 2.1219453350190194

Epoch: 6| Step: 2
Training loss: 1.578187108039856
Validation loss: 2.0995820619726695

Epoch: 6| Step: 3
Training loss: 2.3672287464141846
Validation loss: 2.081883945772725

Epoch: 6| Step: 4
Training loss: 2.1479663848876953
Validation loss: 2.1104697001877653

Epoch: 6| Step: 5
Training loss: 2.139443874359131
Validation loss: 2.109905239074461

Epoch: 6| Step: 6
Training loss: 1.6822432279586792
Validation loss: 2.101700880194223

Epoch: 6| Step: 7
Training loss: 2.9685416221618652
Validation loss: 2.090282388912734

Epoch: 6| Step: 8
Training loss: 2.3503599166870117
Validation loss: 2.0889650237175728

Epoch: 6| Step: 9
Training loss: 1.8919020891189575
Validation loss: 2.095881203169464

Epoch: 6| Step: 10
Training loss: 1.6278259754180908
Validation loss: 2.0890444504317416

Epoch: 6| Step: 11
Training loss: 1.4191654920578003
Validation loss: 2.089002619507492

Epoch: 6| Step: 12
Training loss: 2.2866530418395996
Validation loss: 2.084448229882025

Epoch: 6| Step: 13
Training loss: 3.240532159805298
Validation loss: 2.1005939258042203

Epoch: 167| Step: 0
Training loss: 1.2345942258834839
Validation loss: 2.086931954147995

Epoch: 6| Step: 1
Training loss: 3.276106357574463
Validation loss: 2.0964167579527824

Epoch: 6| Step: 2
Training loss: 2.1552329063415527
Validation loss: 2.0697418130854124

Epoch: 6| Step: 3
Training loss: 1.9979994297027588
Validation loss: 2.109427244432511

Epoch: 6| Step: 4
Training loss: 2.0530500411987305
Validation loss: 2.070943986215899

Epoch: 6| Step: 5
Training loss: 2.012723684310913
Validation loss: 2.079805370300047

Epoch: 6| Step: 6
Training loss: 2.614243984222412
Validation loss: 2.0683327323646954

Epoch: 6| Step: 7
Training loss: 2.1667470932006836
Validation loss: 2.0887746246912147

Epoch: 6| Step: 8
Training loss: 1.9734212160110474
Validation loss: 2.0980226967924382

Epoch: 6| Step: 9
Training loss: 2.402116298675537
Validation loss: 2.0844342977769914

Epoch: 6| Step: 10
Training loss: 1.3116999864578247
Validation loss: 2.0714413299355456

Epoch: 6| Step: 11
Training loss: 1.8917241096496582
Validation loss: 2.073219942790206

Epoch: 6| Step: 12
Training loss: 2.362424850463867
Validation loss: 2.0794571471470658

Epoch: 6| Step: 13
Training loss: 2.8805525302886963
Validation loss: 2.065212993211644

Epoch: 168| Step: 0
Training loss: 1.9698455333709717
Validation loss: 2.090668729556504

Epoch: 6| Step: 1
Training loss: 2.3480076789855957
Validation loss: 2.0804492799184655

Epoch: 6| Step: 2
Training loss: 3.021566390991211
Validation loss: 2.0966747935100267

Epoch: 6| Step: 3
Training loss: 1.7025489807128906
Validation loss: 2.093144675736786

Epoch: 6| Step: 4
Training loss: 2.3236069679260254
Validation loss: 2.0978930868128294

Epoch: 6| Step: 5
Training loss: 1.9434789419174194
Validation loss: 2.099392401274814

Epoch: 6| Step: 6
Training loss: 2.4528417587280273
Validation loss: 2.0808216230843657

Epoch: 6| Step: 7
Training loss: 2.0515236854553223
Validation loss: 2.0986016181207474

Epoch: 6| Step: 8
Training loss: 2.0846822261810303
Validation loss: 2.0930667513160297

Epoch: 6| Step: 9
Training loss: 1.9966676235198975
Validation loss: 2.069980070155154

Epoch: 6| Step: 10
Training loss: 1.6544983386993408
Validation loss: 2.0813165274999474

Epoch: 6| Step: 11
Training loss: 2.0036160945892334
Validation loss: 2.0759729005957164

Epoch: 6| Step: 12
Training loss: 2.179306983947754
Validation loss: 2.073354317295936

Epoch: 6| Step: 13
Training loss: 2.072572708129883
Validation loss: 2.0598039473256757

Epoch: 169| Step: 0
Training loss: 1.782715916633606
Validation loss: 2.0943563651013117

Epoch: 6| Step: 1
Training loss: 2.235128164291382
Validation loss: 2.1002122279136413

Epoch: 6| Step: 2
Training loss: 2.2965948581695557
Validation loss: 2.0977100377441733

Epoch: 6| Step: 3
Training loss: 2.343550205230713
Validation loss: 2.101889112944244

Epoch: 6| Step: 4
Training loss: 1.8157985210418701
Validation loss: 2.098192822548651

Epoch: 6| Step: 5
Training loss: 1.6376664638519287
Validation loss: 2.0683724085489907

Epoch: 6| Step: 6
Training loss: 1.9876046180725098
Validation loss: 2.0564927913809337

Epoch: 6| Step: 7
Training loss: 2.6821656227111816
Validation loss: 2.0794414422845326

Epoch: 6| Step: 8
Training loss: 2.578012466430664
Validation loss: 2.109218434620929

Epoch: 6| Step: 9
Training loss: 2.124051094055176
Validation loss: 2.099337972620482

Epoch: 6| Step: 10
Training loss: 2.736285924911499
Validation loss: 2.0884698770379506

Epoch: 6| Step: 11
Training loss: 2.0910661220550537
Validation loss: 2.100336710611979

Epoch: 6| Step: 12
Training loss: 1.564562439918518
Validation loss: 2.072934842878772

Epoch: 6| Step: 13
Training loss: 1.5863181352615356
Validation loss: 2.1058764021883727

Epoch: 170| Step: 0
Training loss: 2.491328716278076
Validation loss: 2.1121350488355084

Epoch: 6| Step: 1
Training loss: 1.8517580032348633
Validation loss: 2.09982398504852

Epoch: 6| Step: 2
Training loss: 2.43131685256958
Validation loss: 2.111905182561567

Epoch: 6| Step: 3
Training loss: 2.1127548217773438
Validation loss: 2.105781101411389

Epoch: 6| Step: 4
Training loss: 2.253401279449463
Validation loss: 2.1395904582033873

Epoch: 6| Step: 5
Training loss: 1.8065601587295532
Validation loss: 2.101673103147937

Epoch: 6| Step: 6
Training loss: 1.873094916343689
Validation loss: 2.1554443220938406

Epoch: 6| Step: 7
Training loss: 2.5244953632354736
Validation loss: 2.1305627886966994

Epoch: 6| Step: 8
Training loss: 1.640089988708496
Validation loss: 2.1318263828113513

Epoch: 6| Step: 9
Training loss: 2.2514233589172363
Validation loss: 2.1369531308451006

Epoch: 6| Step: 10
Training loss: 2.252401351928711
Validation loss: 2.127852430907629

Epoch: 6| Step: 11
Training loss: 2.454841136932373
Validation loss: 2.1178833233412875

Epoch: 6| Step: 12
Training loss: 1.843090295791626
Validation loss: 2.1123508676405875

Epoch: 6| Step: 13
Training loss: 1.9298185110092163
Validation loss: 2.139617463593842

Epoch: 171| Step: 0
Training loss: 1.7516337633132935
Validation loss: 2.118147829527496

Epoch: 6| Step: 1
Training loss: 1.534392237663269
Validation loss: 2.1313374273238646

Epoch: 6| Step: 2
Training loss: 2.4476404190063477
Validation loss: 2.1109170618877617

Epoch: 6| Step: 3
Training loss: 2.191098213195801
Validation loss: 2.0966256818463727

Epoch: 6| Step: 4
Training loss: 2.557699203491211
Validation loss: 2.0925538629613896

Epoch: 6| Step: 5
Training loss: 1.7270941734313965
Validation loss: 2.0957848718089442

Epoch: 6| Step: 6
Training loss: 2.0109434127807617
Validation loss: 2.1164093427760626

Epoch: 6| Step: 7
Training loss: 2.1256725788116455
Validation loss: 2.1094280417247484

Epoch: 6| Step: 8
Training loss: 2.1197328567504883
Validation loss: 2.0754222792963826

Epoch: 6| Step: 9
Training loss: 2.286309242248535
Validation loss: 2.078617057492656

Epoch: 6| Step: 10
Training loss: 2.008129119873047
Validation loss: 2.07748471536944

Epoch: 6| Step: 11
Training loss: 2.1712679862976074
Validation loss: 2.0692041522713116

Epoch: 6| Step: 12
Training loss: 2.0974178314208984
Validation loss: 2.0783035691066454

Epoch: 6| Step: 13
Training loss: 3.132516622543335
Validation loss: 2.106284991387398

Epoch: 172| Step: 0
Training loss: 2.5823283195495605
Validation loss: 2.0768100523179576

Epoch: 6| Step: 1
Training loss: 1.7922979593276978
Validation loss: 2.0940329259441746

Epoch: 6| Step: 2
Training loss: 2.4414875507354736
Validation loss: 2.065864360460671

Epoch: 6| Step: 3
Training loss: 2.167685031890869
Validation loss: 2.0906891399814236

Epoch: 6| Step: 4
Training loss: 1.8483413457870483
Validation loss: 2.0917471531898744

Epoch: 6| Step: 5
Training loss: 1.9205739498138428
Validation loss: 2.0938025418148247

Epoch: 6| Step: 6
Training loss: 2.030088186264038
Validation loss: 2.11900491868296

Epoch: 6| Step: 7
Training loss: 1.977186679840088
Validation loss: 2.0927359660466514

Epoch: 6| Step: 8
Training loss: 2.5192179679870605
Validation loss: 2.1003564147539038

Epoch: 6| Step: 9
Training loss: 2.249338150024414
Validation loss: 2.093134803156699

Epoch: 6| Step: 10
Training loss: 1.8230679035186768
Validation loss: 2.093185464541117

Epoch: 6| Step: 11
Training loss: 2.21240234375
Validation loss: 2.092001356104369

Epoch: 6| Step: 12
Training loss: 1.748779296875
Validation loss: 2.091349001853697

Epoch: 6| Step: 13
Training loss: 2.629082679748535
Validation loss: 2.111456794123496

Epoch: 173| Step: 0
Training loss: 2.9938578605651855
Validation loss: 2.074715801464614

Epoch: 6| Step: 1
Training loss: 2.7342631816864014
Validation loss: 2.11835991438999

Epoch: 6| Step: 2
Training loss: 1.8450993299484253
Validation loss: 2.0681753222660353

Epoch: 6| Step: 3
Training loss: 1.7691144943237305
Validation loss: 2.061669611161755

Epoch: 6| Step: 4
Training loss: 1.5077219009399414
Validation loss: 2.0772046786482616

Epoch: 6| Step: 5
Training loss: 1.3775112628936768
Validation loss: 2.0795248375144055

Epoch: 6| Step: 6
Training loss: 1.92146897315979
Validation loss: 2.0892538255260837

Epoch: 6| Step: 7
Training loss: 2.5715556144714355
Validation loss: 2.08113274523007

Epoch: 6| Step: 8
Training loss: 2.196901321411133
Validation loss: 2.0543597769993607

Epoch: 6| Step: 9
Training loss: 2.0829989910125732
Validation loss: 2.0826451457956785

Epoch: 6| Step: 10
Training loss: 2.3387184143066406
Validation loss: 2.0738878967941448

Epoch: 6| Step: 11
Training loss: 2.585475206375122
Validation loss: 2.07926175414875

Epoch: 6| Step: 12
Training loss: 2.2494606971740723
Validation loss: 2.083372510889525

Epoch: 6| Step: 13
Training loss: 1.4134186506271362
Validation loss: 2.085406567460747

Epoch: 174| Step: 0
Training loss: 2.806593418121338
Validation loss: 2.106332302093506

Epoch: 6| Step: 1
Training loss: 2.9292614459991455
Validation loss: 2.0892790825136247

Epoch: 6| Step: 2
Training loss: 2.087466239929199
Validation loss: 2.0941466054608746

Epoch: 6| Step: 3
Training loss: 2.299224376678467
Validation loss: 2.0712612521263862

Epoch: 6| Step: 4
Training loss: 1.7845855951309204
Validation loss: 2.1012619349264328

Epoch: 6| Step: 5
Training loss: 1.8620017766952515
Validation loss: 2.094290551318917

Epoch: 6| Step: 6
Training loss: 2.4548754692077637
Validation loss: 2.077131804599557

Epoch: 6| Step: 7
Training loss: 1.5197994709014893
Validation loss: 2.0507387615019277

Epoch: 6| Step: 8
Training loss: 1.8569798469543457
Validation loss: 2.0793865624294487

Epoch: 6| Step: 9
Training loss: 2.1186184883117676
Validation loss: 2.093352658774263

Epoch: 6| Step: 10
Training loss: 1.185600757598877
Validation loss: 2.0836401690718946

Epoch: 6| Step: 11
Training loss: 2.374559164047241
Validation loss: 2.0837893998751076

Epoch: 6| Step: 12
Training loss: 2.1083226203918457
Validation loss: 2.082183801999656

Epoch: 6| Step: 13
Training loss: 2.2195181846618652
Validation loss: 2.1008645052550943

Epoch: 175| Step: 0
Training loss: 2.0213513374328613
Validation loss: 2.091685559159966

Epoch: 6| Step: 1
Training loss: 2.2604875564575195
Validation loss: 2.117233999313847

Epoch: 6| Step: 2
Training loss: 1.6254901885986328
Validation loss: 2.0930708198137182

Epoch: 6| Step: 3
Training loss: 2.373483657836914
Validation loss: 2.0983240322400163

Epoch: 6| Step: 4
Training loss: 2.350780963897705
Validation loss: 2.1024123161069808

Epoch: 6| Step: 5
Training loss: 1.7737610340118408
Validation loss: 2.1321346734159734

Epoch: 6| Step: 6
Training loss: 2.068981647491455
Validation loss: 2.11745544146466

Epoch: 6| Step: 7
Training loss: 1.6579387187957764
Validation loss: 2.095958955826298

Epoch: 6| Step: 8
Training loss: 2.688533306121826
Validation loss: 2.115600550046531

Epoch: 6| Step: 9
Training loss: 1.8555163145065308
Validation loss: 2.1347081686860774

Epoch: 6| Step: 10
Training loss: 1.6145687103271484
Validation loss: 2.1361865253858667

Epoch: 6| Step: 11
Training loss: 2.280083179473877
Validation loss: 2.12451926354439

Epoch: 6| Step: 12
Training loss: 2.2284927368164062
Validation loss: 2.1090626908886816

Epoch: 6| Step: 13
Training loss: 3.2468252182006836
Validation loss: 2.1298442861085296

Epoch: 176| Step: 0
Training loss: 2.117941379547119
Validation loss: 2.117699247534557

Epoch: 6| Step: 1
Training loss: 1.6236835718154907
Validation loss: 2.10589167892292

Epoch: 6| Step: 2
Training loss: 2.02017879486084
Validation loss: 2.1400110721588135

Epoch: 6| Step: 3
Training loss: 2.4058475494384766
Validation loss: 2.1187441528484388

Epoch: 6| Step: 4
Training loss: 2.1485745906829834
Validation loss: 2.1187044856368855

Epoch: 6| Step: 5
Training loss: 2.593383312225342
Validation loss: 2.0904050975717525

Epoch: 6| Step: 6
Training loss: 2.0283687114715576
Validation loss: 2.1066496320950088

Epoch: 6| Step: 7
Training loss: 1.8627243041992188
Validation loss: 2.144240894625264

Epoch: 6| Step: 8
Training loss: 2.081331253051758
Validation loss: 2.107353771886518

Epoch: 6| Step: 9
Training loss: 1.9625790119171143
Validation loss: 2.129453302711569

Epoch: 6| Step: 10
Training loss: 1.5720750093460083
Validation loss: 2.1291460183358963

Epoch: 6| Step: 11
Training loss: 2.4242143630981445
Validation loss: 2.116998416121288

Epoch: 6| Step: 12
Training loss: 2.8195996284484863
Validation loss: 2.1043653590704805

Epoch: 6| Step: 13
Training loss: 2.103708267211914
Validation loss: 2.1249068629357124

Epoch: 177| Step: 0
Training loss: 2.3843154907226562
Validation loss: 2.1324660214044715

Epoch: 6| Step: 1
Training loss: 1.873888373374939
Validation loss: 2.1436157059925858

Epoch: 6| Step: 2
Training loss: 1.6907435655593872
Validation loss: 2.109730105246267

Epoch: 6| Step: 3
Training loss: 2.1270816326141357
Validation loss: 2.12284271178707

Epoch: 6| Step: 4
Training loss: 2.500056028366089
Validation loss: 2.1267443446702856

Epoch: 6| Step: 5
Training loss: 2.6058669090270996
Validation loss: 2.102653923855033

Epoch: 6| Step: 6
Training loss: 2.1042966842651367
Validation loss: 2.1055004558255597

Epoch: 6| Step: 7
Training loss: 2.5888166427612305
Validation loss: 2.098526167613204

Epoch: 6| Step: 8
Training loss: 1.5690783262252808
Validation loss: 2.108899490807646

Epoch: 6| Step: 9
Training loss: 1.70615553855896
Validation loss: 2.102198193150182

Epoch: 6| Step: 10
Training loss: 2.227043867111206
Validation loss: 2.10049186342506

Epoch: 6| Step: 11
Training loss: 2.2232303619384766
Validation loss: 2.0998451479019655

Epoch: 6| Step: 12
Training loss: 1.9086661338806152
Validation loss: 2.104524914936353

Epoch: 6| Step: 13
Training loss: 1.9263992309570312
Validation loss: 2.1023432311191352

Epoch: 178| Step: 0
Training loss: 2.3908743858337402
Validation loss: 2.111857129681495

Epoch: 6| Step: 1
Training loss: 1.8061667680740356
Validation loss: 2.1047239406134493

Epoch: 6| Step: 2
Training loss: 1.3472687005996704
Validation loss: 2.0869453645521596

Epoch: 6| Step: 3
Training loss: 2.133676052093506
Validation loss: 2.0725303772957093

Epoch: 6| Step: 4
Training loss: 2.3455071449279785
Validation loss: 2.098619520023305

Epoch: 6| Step: 5
Training loss: 1.847002625465393
Validation loss: 2.087914833458521

Epoch: 6| Step: 6
Training loss: 2.247431755065918
Validation loss: 2.0733469865655385

Epoch: 6| Step: 7
Training loss: 2.473844289779663
Validation loss: 2.0990075693335584

Epoch: 6| Step: 8
Training loss: 3.0918993949890137
Validation loss: 2.0830492922054824

Epoch: 6| Step: 9
Training loss: 1.5446672439575195
Validation loss: 2.076754698189356

Epoch: 6| Step: 10
Training loss: 2.1153836250305176
Validation loss: 2.0841265724551294

Epoch: 6| Step: 11
Training loss: 2.604334831237793
Validation loss: 2.0938788255055747

Epoch: 6| Step: 12
Training loss: 1.4244576692581177
Validation loss: 2.0648663531067553

Epoch: 6| Step: 13
Training loss: 2.1926231384277344
Validation loss: 2.1106693667750203

Epoch: 179| Step: 0
Training loss: 3.122393846511841
Validation loss: 2.0964980330518497

Epoch: 6| Step: 1
Training loss: 2.517939567565918
Validation loss: 2.1127762973949475

Epoch: 6| Step: 2
Training loss: 2.279876232147217
Validation loss: 2.0967051854697605

Epoch: 6| Step: 3
Training loss: 2.1544036865234375
Validation loss: 2.1127921124940277

Epoch: 6| Step: 4
Training loss: 1.7230722904205322
Validation loss: 2.077736098279235

Epoch: 6| Step: 5
Training loss: 1.8597676753997803
Validation loss: 2.080149273718557

Epoch: 6| Step: 6
Training loss: 1.7133746147155762
Validation loss: 2.094625688368274

Epoch: 6| Step: 7
Training loss: 1.0427522659301758
Validation loss: 2.091835262954876

Epoch: 6| Step: 8
Training loss: 2.5008649826049805
Validation loss: 2.093053784421695

Epoch: 6| Step: 9
Training loss: 1.919294834136963
Validation loss: 2.0801390781197497

Epoch: 6| Step: 10
Training loss: 2.314030408859253
Validation loss: 2.111045327237857

Epoch: 6| Step: 11
Training loss: 2.349705696105957
Validation loss: 2.0973263017592894

Epoch: 6| Step: 12
Training loss: 1.6608631610870361
Validation loss: 2.1147106680818784

Epoch: 6| Step: 13
Training loss: 2.290158748626709
Validation loss: 2.114779423641902

Epoch: 180| Step: 0
Training loss: 2.074881076812744
Validation loss: 2.1384867186187417

Epoch: 6| Step: 1
Training loss: 1.7582976818084717
Validation loss: 2.1122694605140278

Epoch: 6| Step: 2
Training loss: 1.7843623161315918
Validation loss: 2.0950017641949397

Epoch: 6| Step: 3
Training loss: 1.9551057815551758
Validation loss: 2.124589340661162

Epoch: 6| Step: 4
Training loss: 2.3587570190429688
Validation loss: 2.1131993609090007

Epoch: 6| Step: 5
Training loss: 2.8903756141662598
Validation loss: 2.1252162789785736

Epoch: 6| Step: 6
Training loss: 1.6698275804519653
Validation loss: 2.1387760716099895

Epoch: 6| Step: 7
Training loss: 1.8118396997451782
Validation loss: 2.12188063129302

Epoch: 6| Step: 8
Training loss: 1.8955742120742798
Validation loss: 2.1144298789321736

Epoch: 6| Step: 9
Training loss: 2.621309280395508
Validation loss: 2.12858913278067

Epoch: 6| Step: 10
Training loss: 2.533825397491455
Validation loss: 2.1065295216857747

Epoch: 6| Step: 11
Training loss: 2.1062419414520264
Validation loss: 2.1425631725659935

Epoch: 6| Step: 12
Training loss: 2.2233057022094727
Validation loss: 2.114082054425311

Epoch: 6| Step: 13
Training loss: 1.4401367902755737
Validation loss: 2.1156322161356607

Epoch: 181| Step: 0
Training loss: 1.7158424854278564
Validation loss: 2.115980525170603

Epoch: 6| Step: 1
Training loss: 2.333878517150879
Validation loss: 2.134285399990697

Epoch: 6| Step: 2
Training loss: 1.6881221532821655
Validation loss: 2.0774363253706243

Epoch: 6| Step: 3
Training loss: 2.1952412128448486
Validation loss: 2.1013010266006633

Epoch: 6| Step: 4
Training loss: 1.7290189266204834
Validation loss: 2.1091571341278734

Epoch: 6| Step: 5
Training loss: 2.1684370040893555
Validation loss: 2.0740073598841184

Epoch: 6| Step: 6
Training loss: 2.334136486053467
Validation loss: 2.0965560187575636

Epoch: 6| Step: 7
Training loss: 2.136141538619995
Validation loss: 2.105210442696848

Epoch: 6| Step: 8
Training loss: 2.0756092071533203
Validation loss: 2.079466128862032

Epoch: 6| Step: 9
Training loss: 2.2567296028137207
Validation loss: 2.0847862151361283

Epoch: 6| Step: 10
Training loss: 2.172675132751465
Validation loss: 2.078059264408645

Epoch: 6| Step: 11
Training loss: 2.4274492263793945
Validation loss: 2.0904048963259627

Epoch: 6| Step: 12
Training loss: 1.698731780052185
Validation loss: 2.088228098807796

Epoch: 6| Step: 13
Training loss: 3.0416836738586426
Validation loss: 2.0768981274738105

Epoch: 182| Step: 0
Training loss: 2.0798192024230957
Validation loss: 2.090775923062396

Epoch: 6| Step: 1
Training loss: 1.9761183261871338
Validation loss: 2.098482015312359

Epoch: 6| Step: 2
Training loss: 1.888900637626648
Validation loss: 2.0835895769057737

Epoch: 6| Step: 3
Training loss: 1.854123830795288
Validation loss: 2.0604345490855556

Epoch: 6| Step: 4
Training loss: 2.115236759185791
Validation loss: 2.0654740641194005

Epoch: 6| Step: 5
Training loss: 2.4639368057250977
Validation loss: 2.0614639366826704

Epoch: 6| Step: 6
Training loss: 1.6500027179718018
Validation loss: 2.0871574148055045

Epoch: 6| Step: 7
Training loss: 1.5488159656524658
Validation loss: 2.1100775067524244

Epoch: 6| Step: 8
Training loss: 1.6406683921813965
Validation loss: 2.1068727098485476

Epoch: 6| Step: 9
Training loss: 2.2394509315490723
Validation loss: 2.0904195603503974

Epoch: 6| Step: 10
Training loss: 2.157805919647217
Validation loss: 2.10782532025409

Epoch: 6| Step: 11
Training loss: 2.7565693855285645
Validation loss: 2.1065481298713276

Epoch: 6| Step: 12
Training loss: 2.4431357383728027
Validation loss: 2.096604888157178

Epoch: 6| Step: 13
Training loss: 2.4386491775512695
Validation loss: 2.0915359015105874

Epoch: 183| Step: 0
Training loss: 2.1612956523895264
Validation loss: 2.0644341668775006

Epoch: 6| Step: 1
Training loss: 1.6301448345184326
Validation loss: 2.1032657456654373

Epoch: 6| Step: 2
Training loss: 2.6501340866088867
Validation loss: 2.072504133306524

Epoch: 6| Step: 3
Training loss: 2.1438724994659424
Validation loss: 2.0934825046088106

Epoch: 6| Step: 4
Training loss: 2.3768060207366943
Validation loss: 2.0905669363596107

Epoch: 6| Step: 5
Training loss: 2.1109213829040527
Validation loss: 2.080303269047891

Epoch: 6| Step: 6
Training loss: 1.9582083225250244
Validation loss: 2.0859155962544103

Epoch: 6| Step: 7
Training loss: 2.0593957901000977
Validation loss: 2.081958814333844

Epoch: 6| Step: 8
Training loss: 2.1637837886810303
Validation loss: 2.071283683981947

Epoch: 6| Step: 9
Training loss: 2.324881076812744
Validation loss: 2.071201592363337

Epoch: 6| Step: 10
Training loss: 1.7781531810760498
Validation loss: 2.1141260131712882

Epoch: 6| Step: 11
Training loss: 1.4960048198699951
Validation loss: 2.119095717706988

Epoch: 6| Step: 12
Training loss: 2.4596214294433594
Validation loss: 2.095335122077696

Epoch: 6| Step: 13
Training loss: 2.144568681716919
Validation loss: 2.101900804427362

Epoch: 184| Step: 0
Training loss: 1.8541728258132935
Validation loss: 2.1065292717308126

Epoch: 6| Step: 1
Training loss: 2.593282699584961
Validation loss: 2.1245774838232223

Epoch: 6| Step: 2
Training loss: 2.0503346920013428
Validation loss: 2.0978583161548903

Epoch: 6| Step: 3
Training loss: 2.168025493621826
Validation loss: 2.1396295562867196

Epoch: 6| Step: 4
Training loss: 1.4354979991912842
Validation loss: 2.1249687902389036

Epoch: 6| Step: 5
Training loss: 2.533430576324463
Validation loss: 2.138129065113683

Epoch: 6| Step: 6
Training loss: 2.1512603759765625
Validation loss: 2.1167665168803227

Epoch: 6| Step: 7
Training loss: 1.7955213785171509
Validation loss: 2.1179197552383586

Epoch: 6| Step: 8
Training loss: 2.4024477005004883
Validation loss: 2.1390758791277484

Epoch: 6| Step: 9
Training loss: 2.2917251586914062
Validation loss: 2.1441307042234685

Epoch: 6| Step: 10
Training loss: 2.1842727661132812
Validation loss: 2.1170895535458802

Epoch: 6| Step: 11
Training loss: 2.0907959938049316
Validation loss: 2.131134278030806

Epoch: 6| Step: 12
Training loss: 1.6482212543487549
Validation loss: 2.1567637048741823

Epoch: 6| Step: 13
Training loss: 2.2085864543914795
Validation loss: 2.128956953684489

Epoch: 185| Step: 0
Training loss: 2.264116048812866
Validation loss: 2.112552313394444

Epoch: 6| Step: 1
Training loss: 2.288163900375366
Validation loss: 2.115443955185593

Epoch: 6| Step: 2
Training loss: 3.0187149047851562
Validation loss: 2.132219664512142

Epoch: 6| Step: 3
Training loss: 1.9618725776672363
Validation loss: 2.1359721217104184

Epoch: 6| Step: 4
Training loss: 1.7714885473251343
Validation loss: 2.11106841282178

Epoch: 6| Step: 5
Training loss: 2.324686050415039
Validation loss: 2.1001480471703315

Epoch: 6| Step: 6
Training loss: 1.4634225368499756
Validation loss: 2.1062988991378457

Epoch: 6| Step: 7
Training loss: 2.439802646636963
Validation loss: 2.096409733577441

Epoch: 6| Step: 8
Training loss: 2.2752599716186523
Validation loss: 2.0921540016769082

Epoch: 6| Step: 9
Training loss: 2.6717777252197266
Validation loss: 2.08639399338794

Epoch: 6| Step: 10
Training loss: 1.894704818725586
Validation loss: 2.1010245943582184

Epoch: 6| Step: 11
Training loss: 1.5419046878814697
Validation loss: 2.091280221939087

Epoch: 6| Step: 12
Training loss: 1.4617795944213867
Validation loss: 2.09473596080657

Epoch: 6| Step: 13
Training loss: 1.627930998802185
Validation loss: 2.0882100110412924

Epoch: 186| Step: 0
Training loss: 2.2930796146392822
Validation loss: 2.0871289186580206

Epoch: 6| Step: 1
Training loss: 2.86605167388916
Validation loss: 2.0840724834831814

Epoch: 6| Step: 2
Training loss: 2.047567844390869
Validation loss: 2.091547030274586

Epoch: 6| Step: 3
Training loss: 1.1150627136230469
Validation loss: 2.0714322495204147

Epoch: 6| Step: 4
Training loss: 1.2716960906982422
Validation loss: 2.0912805590578305

Epoch: 6| Step: 5
Training loss: 2.370166540145874
Validation loss: 2.0755826888545865

Epoch: 6| Step: 6
Training loss: 2.687959671020508
Validation loss: 2.0813339448744252

Epoch: 6| Step: 7
Training loss: 2.3784475326538086
Validation loss: 2.065513910785798

Epoch: 6| Step: 8
Training loss: 1.974321961402893
Validation loss: 2.093389462399226

Epoch: 6| Step: 9
Training loss: 2.2979068756103516
Validation loss: 2.0834883541189213

Epoch: 6| Step: 10
Training loss: 2.29490327835083
Validation loss: 2.097902718410697

Epoch: 6| Step: 11
Training loss: 1.70849609375
Validation loss: 2.0630996150355183

Epoch: 6| Step: 12
Training loss: 1.9121224880218506
Validation loss: 2.099628843286986

Epoch: 6| Step: 13
Training loss: 2.238612174987793
Validation loss: 2.068047910608271

Epoch: 187| Step: 0
Training loss: 2.0288872718811035
Validation loss: 2.091864583312824

Epoch: 6| Step: 1
Training loss: 2.1175875663757324
Validation loss: 2.0863771874417543

Epoch: 6| Step: 2
Training loss: 1.610785961151123
Validation loss: 2.123228633275596

Epoch: 6| Step: 3
Training loss: 2.3341379165649414
Validation loss: 2.124392694042575

Epoch: 6| Step: 4
Training loss: 2.1438393592834473
Validation loss: 2.134007825646349

Epoch: 6| Step: 5
Training loss: 1.4509505033493042
Validation loss: 2.1151496876952467

Epoch: 6| Step: 6
Training loss: 2.5477640628814697
Validation loss: 2.1357006847217517

Epoch: 6| Step: 7
Training loss: 1.6319154500961304
Validation loss: 2.1432607532829366

Epoch: 6| Step: 8
Training loss: 2.020808696746826
Validation loss: 2.1010888366289038

Epoch: 6| Step: 9
Training loss: 2.213141918182373
Validation loss: 2.084310762343868

Epoch: 6| Step: 10
Training loss: 2.329355239868164
Validation loss: 2.114916862339102

Epoch: 6| Step: 11
Training loss: 2.0194058418273926
Validation loss: 2.1187260381637083

Epoch: 6| Step: 12
Training loss: 1.9805418252944946
Validation loss: 2.12475908699856

Epoch: 6| Step: 13
Training loss: 3.2510011196136475
Validation loss: 2.124665485915317

Epoch: 188| Step: 0
Training loss: 1.7985764741897583
Validation loss: 2.1415596495392504

Epoch: 6| Step: 1
Training loss: 1.6925913095474243
Validation loss: 2.1174651166444183

Epoch: 6| Step: 2
Training loss: 2.00380277633667
Validation loss: 2.106029515625328

Epoch: 6| Step: 3
Training loss: 1.7612497806549072
Validation loss: 2.1137905992487425

Epoch: 6| Step: 4
Training loss: 2.2753214836120605
Validation loss: 2.123003354636572

Epoch: 6| Step: 5
Training loss: 2.4329259395599365
Validation loss: 2.117401494774767

Epoch: 6| Step: 6
Training loss: 2.483506679534912
Validation loss: 2.0943136074209727

Epoch: 6| Step: 7
Training loss: 2.2563250064849854
Validation loss: 2.1060567671252834

Epoch: 6| Step: 8
Training loss: 1.2109460830688477
Validation loss: 2.049613570654264

Epoch: 6| Step: 9
Training loss: 2.9345011711120605
Validation loss: 2.073780923761347

Epoch: 6| Step: 10
Training loss: 2.2716023921966553
Validation loss: 2.0886572253319526

Epoch: 6| Step: 11
Training loss: 1.8023878335952759
Validation loss: 2.1134449820364676

Epoch: 6| Step: 12
Training loss: 1.8762290477752686
Validation loss: 2.0794175645356536

Epoch: 6| Step: 13
Training loss: 2.4555962085723877
Validation loss: 2.1035994457942184

Epoch: 189| Step: 0
Training loss: 2.442732572555542
Validation loss: 2.1121936562240764

Epoch: 6| Step: 1
Training loss: 2.498842239379883
Validation loss: 2.0761086274218816

Epoch: 6| Step: 2
Training loss: 2.040829658508301
Validation loss: 2.0859191110057216

Epoch: 6| Step: 3
Training loss: 2.333172082901001
Validation loss: 2.0976295496827815

Epoch: 6| Step: 4
Training loss: 1.651158332824707
Validation loss: 2.1304977119609876

Epoch: 6| Step: 5
Training loss: 2.533874273300171
Validation loss: 2.095902012240502

Epoch: 6| Step: 6
Training loss: 1.9875683784484863
Validation loss: 2.083437435088619

Epoch: 6| Step: 7
Training loss: 2.010540008544922
Validation loss: 2.1170274467878443

Epoch: 6| Step: 8
Training loss: 1.3969507217407227
Validation loss: 2.0989165331727717

Epoch: 6| Step: 9
Training loss: 1.4272598028182983
Validation loss: 2.0936034020557197

Epoch: 6| Step: 10
Training loss: 1.9322830438613892
Validation loss: 2.102004844655273

Epoch: 6| Step: 11
Training loss: 2.7968623638153076
Validation loss: 2.095025763716749

Epoch: 6| Step: 12
Training loss: 1.8072354793548584
Validation loss: 2.1083696644793273

Epoch: 6| Step: 13
Training loss: 2.564016342163086
Validation loss: 2.108496601863574

Epoch: 190| Step: 0
Training loss: 2.58030366897583
Validation loss: 2.092496092601489

Epoch: 6| Step: 1
Training loss: 2.4120349884033203
Validation loss: 2.1131256139406593

Epoch: 6| Step: 2
Training loss: 2.69065260887146
Validation loss: 2.1036381003677205

Epoch: 6| Step: 3
Training loss: 1.94804847240448
Validation loss: 2.1034737389574767

Epoch: 6| Step: 4
Training loss: 1.6658939123153687
Validation loss: 2.117567736615417

Epoch: 6| Step: 5
Training loss: 2.192514181137085
Validation loss: 2.0668413408340944

Epoch: 6| Step: 6
Training loss: 1.9565473794937134
Validation loss: 2.1119360975039903

Epoch: 6| Step: 7
Training loss: 1.5689218044281006
Validation loss: 2.093717869891915

Epoch: 6| Step: 8
Training loss: 1.788682460784912
Validation loss: 2.1172169254672144

Epoch: 6| Step: 9
Training loss: 2.0846662521362305
Validation loss: 2.1038500455117997

Epoch: 6| Step: 10
Training loss: 2.593696117401123
Validation loss: 2.0967898497017483

Epoch: 6| Step: 11
Training loss: 2.1480555534362793
Validation loss: 2.105031159616286

Epoch: 6| Step: 12
Training loss: 1.7192292213439941
Validation loss: 2.127885935127094

Epoch: 6| Step: 13
Training loss: 1.1669108867645264
Validation loss: 2.087668377866027

Epoch: 191| Step: 0
Training loss: 2.6627449989318848
Validation loss: 2.1025479275693177

Epoch: 6| Step: 1
Training loss: 2.091177463531494
Validation loss: 2.0622229473565215

Epoch: 6| Step: 2
Training loss: 2.2267208099365234
Validation loss: 2.1034511507198377

Epoch: 6| Step: 3
Training loss: 2.641073226928711
Validation loss: 2.081881361622964

Epoch: 6| Step: 4
Training loss: 2.2651853561401367
Validation loss: 2.0798377503630934

Epoch: 6| Step: 5
Training loss: 2.1447081565856934
Validation loss: 2.0922781677656275

Epoch: 6| Step: 6
Training loss: 1.6755555868148804
Validation loss: 2.0703911858220256

Epoch: 6| Step: 7
Training loss: 2.4164774417877197
Validation loss: 2.079899311065674

Epoch: 6| Step: 8
Training loss: 1.9333975315093994
Validation loss: 2.068372141930365

Epoch: 6| Step: 9
Training loss: 1.7211155891418457
Validation loss: 2.0688525117853636

Epoch: 6| Step: 10
Training loss: 2.2413182258605957
Validation loss: 2.099911441085159

Epoch: 6| Step: 11
Training loss: 1.8454997539520264
Validation loss: 2.064332764635804

Epoch: 6| Step: 12
Training loss: 1.383117437362671
Validation loss: 2.0620011078414096

Epoch: 6| Step: 13
Training loss: 2.310746192932129
Validation loss: 2.0710886204114525

Epoch: 192| Step: 0
Training loss: 2.4534542560577393
Validation loss: 2.102145807717436

Epoch: 6| Step: 1
Training loss: 1.8761794567108154
Validation loss: 2.0570599007350143

Epoch: 6| Step: 2
Training loss: 2.493875741958618
Validation loss: 2.0704453837487007

Epoch: 6| Step: 3
Training loss: 1.8420870304107666
Validation loss: 2.0888825847256567

Epoch: 6| Step: 4
Training loss: 1.8689281940460205
Validation loss: 2.1251570755435574

Epoch: 6| Step: 5
Training loss: 2.3062117099761963
Validation loss: 2.120101349328154

Epoch: 6| Step: 6
Training loss: 2.7053353786468506
Validation loss: 2.1079163628239788

Epoch: 6| Step: 7
Training loss: 1.819067120552063
Validation loss: 2.091180045117614

Epoch: 6| Step: 8
Training loss: 1.9936190843582153
Validation loss: 2.0971926668638825

Epoch: 6| Step: 9
Training loss: 1.9170018434524536
Validation loss: 2.0957914936927056

Epoch: 6| Step: 10
Training loss: 2.712653636932373
Validation loss: 2.1117085051792923

Epoch: 6| Step: 11
Training loss: 1.0034899711608887
Validation loss: 2.1041844762781614

Epoch: 6| Step: 12
Training loss: 2.013031482696533
Validation loss: 2.107800317066972

Epoch: 6| Step: 13
Training loss: 2.0467960834503174
Validation loss: 2.1259770483099003

Epoch: 193| Step: 0
Training loss: 1.7502511739730835
Validation loss: 2.0961236389734412

Epoch: 6| Step: 1
Training loss: 2.562807321548462
Validation loss: 2.16961456114246

Epoch: 6| Step: 2
Training loss: 2.4851818084716797
Validation loss: 2.119008638525522

Epoch: 6| Step: 3
Training loss: 1.9535812139511108
Validation loss: 2.1150079093953615

Epoch: 6| Step: 4
Training loss: 2.2943525314331055
Validation loss: 2.114768285905161

Epoch: 6| Step: 5
Training loss: 2.1421642303466797
Validation loss: 2.1316551341805408

Epoch: 6| Step: 6
Training loss: 1.5914580821990967
Validation loss: 2.1068458428946872

Epoch: 6| Step: 7
Training loss: 1.918888807296753
Validation loss: 2.0940884415821364

Epoch: 6| Step: 8
Training loss: 3.2837367057800293
Validation loss: 2.079601385260141

Epoch: 6| Step: 9
Training loss: 1.7522356510162354
Validation loss: 2.090939708935317

Epoch: 6| Step: 10
Training loss: 2.0623245239257812
Validation loss: 2.107963390247796

Epoch: 6| Step: 11
Training loss: 1.3737902641296387
Validation loss: 2.1169838623334

Epoch: 6| Step: 12
Training loss: 1.9931384325027466
Validation loss: 2.1083568667852752

Epoch: 6| Step: 13
Training loss: 2.0537948608398438
Validation loss: 2.1040324857158046

Epoch: 194| Step: 0
Training loss: 2.5917792320251465
Validation loss: 2.104043206860942

Epoch: 6| Step: 1
Training loss: 1.8485772609710693
Validation loss: 2.1065817366364183

Epoch: 6| Step: 2
Training loss: 2.3420615196228027
Validation loss: 2.099860300299942

Epoch: 6| Step: 3
Training loss: 2.2852375507354736
Validation loss: 2.1140620503374326

Epoch: 6| Step: 4
Training loss: 1.966513752937317
Validation loss: 2.113771197616413

Epoch: 6| Step: 5
Training loss: 1.7442505359649658
Validation loss: 2.1355509193994666

Epoch: 6| Step: 6
Training loss: 2.3156580924987793
Validation loss: 2.1046592599602154

Epoch: 6| Step: 7
Training loss: 2.1898391246795654
Validation loss: 2.131690256057247

Epoch: 6| Step: 8
Training loss: 2.1004104614257812
Validation loss: 2.147402378820604

Epoch: 6| Step: 9
Training loss: 1.998692512512207
Validation loss: 2.1124215677220333

Epoch: 6| Step: 10
Training loss: 1.4012988805770874
Validation loss: 2.126392182483468

Epoch: 6| Step: 11
Training loss: 1.744032382965088
Validation loss: 2.119185491274762

Epoch: 6| Step: 12
Training loss: 2.734732151031494
Validation loss: 2.1131823242351575

Epoch: 6| Step: 13
Training loss: 2.1895227432250977
Validation loss: 2.123787659470753

Epoch: 195| Step: 0
Training loss: 1.9951972961425781
Validation loss: 2.0854052215494137

Epoch: 6| Step: 1
Training loss: 2.339952230453491
Validation loss: 2.0749698954243816

Epoch: 6| Step: 2
Training loss: 1.8579368591308594
Validation loss: 2.081545014535227

Epoch: 6| Step: 3
Training loss: 2.564692258834839
Validation loss: 2.076189684611495

Epoch: 6| Step: 4
Training loss: 1.809903621673584
Validation loss: 2.121993726299655

Epoch: 6| Step: 5
Training loss: 2.5694010257720947
Validation loss: 2.0635470882538827

Epoch: 6| Step: 6
Training loss: 1.3778167963027954
Validation loss: 2.0883125976849626

Epoch: 6| Step: 7
Training loss: 1.9964118003845215
Validation loss: 2.086966529969246

Epoch: 6| Step: 8
Training loss: 2.3540380001068115
Validation loss: 2.090962517646051

Epoch: 6| Step: 9
Training loss: 2.272810935974121
Validation loss: 2.107748777635636

Epoch: 6| Step: 10
Training loss: 2.0630264282226562
Validation loss: 2.0962504007483043

Epoch: 6| Step: 11
Training loss: 2.040443181991577
Validation loss: 2.0769615173339844

Epoch: 6| Step: 12
Training loss: 1.9407984018325806
Validation loss: 2.071681129035129

Epoch: 6| Step: 13
Training loss: 2.087747097015381
Validation loss: 2.0696916375108945

Epoch: 196| Step: 0
Training loss: 1.895696997642517
Validation loss: 2.102416822987218

Epoch: 6| Step: 1
Training loss: 1.6757797002792358
Validation loss: 2.110269541381508

Epoch: 6| Step: 2
Training loss: 1.9093624353408813
Validation loss: 2.0910069096472954

Epoch: 6| Step: 3
Training loss: 2.294882297515869
Validation loss: 2.1347419754151375

Epoch: 6| Step: 4
Training loss: 1.61615788936615
Validation loss: 2.0946549241260817

Epoch: 6| Step: 5
Training loss: 2.364072322845459
Validation loss: 2.097609296921761

Epoch: 6| Step: 6
Training loss: 2.103121280670166
Validation loss: 2.1108472680532806

Epoch: 6| Step: 7
Training loss: 2.3449645042419434
Validation loss: 2.1128160581793836

Epoch: 6| Step: 8
Training loss: 1.526599645614624
Validation loss: 2.082296117659538

Epoch: 6| Step: 9
Training loss: 2.4293808937072754
Validation loss: 2.1324653728033907

Epoch: 6| Step: 10
Training loss: 2.185525894165039
Validation loss: 2.123808604414745

Epoch: 6| Step: 11
Training loss: 2.70888352394104
Validation loss: 2.0950443872841458

Epoch: 6| Step: 12
Training loss: 1.5494354963302612
Validation loss: 2.0915206863034155

Epoch: 6| Step: 13
Training loss: 2.2986674308776855
Validation loss: 2.1217520890697354

Epoch: 197| Step: 0
Training loss: 2.4639196395874023
Validation loss: 2.1393339172486336

Epoch: 6| Step: 1
Training loss: 1.931475281715393
Validation loss: 2.104459383154428

Epoch: 6| Step: 2
Training loss: 2.3173604011535645
Validation loss: 2.142060725919662

Epoch: 6| Step: 3
Training loss: 2.708343505859375
Validation loss: 2.1087785433697444

Epoch: 6| Step: 4
Training loss: 1.922076940536499
Validation loss: 2.1168719107104885

Epoch: 6| Step: 5
Training loss: 1.3306185007095337
Validation loss: 2.0984116549132974

Epoch: 6| Step: 6
Training loss: 1.9793365001678467
Validation loss: 2.1226488723549792

Epoch: 6| Step: 7
Training loss: 2.526719570159912
Validation loss: 2.1004882217735372

Epoch: 6| Step: 8
Training loss: 2.246338367462158
Validation loss: 2.123956113733271

Epoch: 6| Step: 9
Training loss: 2.032121181488037
Validation loss: 2.112546037602168

Epoch: 6| Step: 10
Training loss: 2.229482889175415
Validation loss: 2.109681988275179

Epoch: 6| Step: 11
Training loss: 1.7820184230804443
Validation loss: 2.1170906533477125

Epoch: 6| Step: 12
Training loss: 2.340878963470459
Validation loss: 2.1235866495358047

Epoch: 6| Step: 13
Training loss: 0.7740068435668945
Validation loss: 2.089974973791389

Epoch: 198| Step: 0
Training loss: 1.6704989671707153
Validation loss: 2.0918587843577066

Epoch: 6| Step: 1
Training loss: 2.3248326778411865
Validation loss: 2.08756463373861

Epoch: 6| Step: 2
Training loss: 2.0394058227539062
Validation loss: 2.0771904094244844

Epoch: 6| Step: 3
Training loss: 1.9784821271896362
Validation loss: 2.1093300875797065

Epoch: 6| Step: 4
Training loss: 2.4383039474487305
Validation loss: 2.0794336872716106

Epoch: 6| Step: 5
Training loss: 1.886515498161316
Validation loss: 2.100601247561875

Epoch: 6| Step: 6
Training loss: 1.1737496852874756
Validation loss: 2.0777981024916454

Epoch: 6| Step: 7
Training loss: 2.414154529571533
Validation loss: 2.0912194072559314

Epoch: 6| Step: 8
Training loss: 2.281238079071045
Validation loss: 2.0914361758898665

Epoch: 6| Step: 9
Training loss: 2.515084743499756
Validation loss: 2.0803856747124785

Epoch: 6| Step: 10
Training loss: 1.8909070491790771
Validation loss: 2.095978154931017

Epoch: 6| Step: 11
Training loss: 2.2352895736694336
Validation loss: 2.123611742450345

Epoch: 6| Step: 12
Training loss: 1.9220846891403198
Validation loss: 2.085511285771606

Epoch: 6| Step: 13
Training loss: 2.462804079055786
Validation loss: 2.0979926714333157

Epoch: 199| Step: 0
Training loss: 2.285015821456909
Validation loss: 2.096315122419788

Epoch: 6| Step: 1
Training loss: 1.8790273666381836
Validation loss: 2.1129296364322787

Epoch: 6| Step: 2
Training loss: 2.4770822525024414
Validation loss: 2.096589534513412

Epoch: 6| Step: 3
Training loss: 1.7676286697387695
Validation loss: 2.112450917561849

Epoch: 6| Step: 4
Training loss: 2.5495457649230957
Validation loss: 2.117824326279343

Epoch: 6| Step: 5
Training loss: 1.862076759338379
Validation loss: 2.1193487516013523

Epoch: 6| Step: 6
Training loss: 2.0978140830993652
Validation loss: 2.0932661205209713

Epoch: 6| Step: 7
Training loss: 2.033344030380249
Validation loss: 2.124877046513301

Epoch: 6| Step: 8
Training loss: 1.8892344236373901
Validation loss: 2.1437398490085395

Epoch: 6| Step: 9
Training loss: 2.4014718532562256
Validation loss: 2.108963615150862

Epoch: 6| Step: 10
Training loss: 2.043015241622925
Validation loss: 2.103871618547747

Epoch: 6| Step: 11
Training loss: 2.014090061187744
Validation loss: 2.099853789934548

Epoch: 6| Step: 12
Training loss: 1.547333002090454
Validation loss: 2.121154236537154

Epoch: 6| Step: 13
Training loss: 1.7757655382156372
Validation loss: 2.101365484217162

Epoch: 200| Step: 0
Training loss: 1.8445582389831543
Validation loss: 2.104945889083288

Epoch: 6| Step: 1
Training loss: 1.8404865264892578
Validation loss: 2.1224476188741703

Epoch: 6| Step: 2
Training loss: 2.0588841438293457
Validation loss: 2.0905423882187053

Epoch: 6| Step: 3
Training loss: 2.8596549034118652
Validation loss: 2.120447204959008

Epoch: 6| Step: 4
Training loss: 1.8092026710510254
Validation loss: 2.115089535713196

Epoch: 6| Step: 5
Training loss: 2.33174991607666
Validation loss: 2.1107564972292994

Epoch: 6| Step: 6
Training loss: 2.036459445953369
Validation loss: 2.0954577538274948

Epoch: 6| Step: 7
Training loss: 2.509469747543335
Validation loss: 2.114684427938154

Epoch: 6| Step: 8
Training loss: 1.9043638706207275
Validation loss: 2.090375764395601

Epoch: 6| Step: 9
Training loss: 1.7807799577713013
Validation loss: 2.091236338820509

Epoch: 6| Step: 10
Training loss: 2.143371343612671
Validation loss: 2.0922664724370486

Epoch: 6| Step: 11
Training loss: 1.2665038108825684
Validation loss: 2.0612366507130284

Epoch: 6| Step: 12
Training loss: 2.5971522331237793
Validation loss: 2.107469290815374

Epoch: 6| Step: 13
Training loss: 1.5683826208114624
Validation loss: 2.092823854056738

Epoch: 201| Step: 0
Training loss: 2.1769795417785645
Validation loss: 2.0768807677812475

Epoch: 6| Step: 1
Training loss: 1.690436601638794
Validation loss: 2.113708822957931

Epoch: 6| Step: 2
Training loss: 1.9283056259155273
Validation loss: 2.096057835445609

Epoch: 6| Step: 3
Training loss: 1.6992133855819702
Validation loss: 2.122616831974317

Epoch: 6| Step: 4
Training loss: 1.8010780811309814
Validation loss: 2.0897595613233504

Epoch: 6| Step: 5
Training loss: 1.4523879289627075
Validation loss: 2.080912838699997

Epoch: 6| Step: 6
Training loss: 2.445049524307251
Validation loss: 2.084102189669045

Epoch: 6| Step: 7
Training loss: 2.6112537384033203
Validation loss: 2.0590807571206042

Epoch: 6| Step: 8
Training loss: 2.777146339416504
Validation loss: 2.0872274573131273

Epoch: 6| Step: 9
Training loss: 2.087193250656128
Validation loss: 2.109874807378297

Epoch: 6| Step: 10
Training loss: 2.359166383743286
Validation loss: 2.119808658476799

Epoch: 6| Step: 11
Training loss: 2.006988048553467
Validation loss: 2.077798843383789

Epoch: 6| Step: 12
Training loss: 1.6959724426269531
Validation loss: 2.0896588269100396

Epoch: 6| Step: 13
Training loss: 2.3423330783843994
Validation loss: 2.125634729221303

Epoch: 202| Step: 0
Training loss: 1.6237993240356445
Validation loss: 2.1056822833194526

Epoch: 6| Step: 1
Training loss: 2.3125271797180176
Validation loss: 2.119522717691237

Epoch: 6| Step: 2
Training loss: 1.8351476192474365
Validation loss: 2.124264581229097

Epoch: 6| Step: 3
Training loss: 2.4905033111572266
Validation loss: 2.1075888256872854

Epoch: 6| Step: 4
Training loss: 1.7048563957214355
Validation loss: 2.1196110222929265

Epoch: 6| Step: 5
Training loss: 2.4140968322753906
Validation loss: 2.1057704148753995

Epoch: 6| Step: 6
Training loss: 2.881216049194336
Validation loss: 2.140640620262392

Epoch: 6| Step: 7
Training loss: 1.470663070678711
Validation loss: 2.1639397169954036

Epoch: 6| Step: 8
Training loss: 1.5076186656951904
Validation loss: 2.1622376877774476

Epoch: 6| Step: 9
Training loss: 2.0442309379577637
Validation loss: 2.138816482277327

Epoch: 6| Step: 10
Training loss: 1.7098751068115234
Validation loss: 2.1577293565196376

Epoch: 6| Step: 11
Training loss: 2.4690909385681152
Validation loss: 2.1232025854049192

Epoch: 6| Step: 12
Training loss: 2.411109447479248
Validation loss: 2.136174964648421

Epoch: 6| Step: 13
Training loss: 2.392756938934326
Validation loss: 2.12874283072769

Epoch: 203| Step: 0
Training loss: 1.476242184638977
Validation loss: 2.137111319008694

Epoch: 6| Step: 1
Training loss: 2.6741981506347656
Validation loss: 2.1236462387987363

Epoch: 6| Step: 2
Training loss: 1.2973573207855225
Validation loss: 2.106222624419838

Epoch: 6| Step: 3
Training loss: 2.2346396446228027
Validation loss: 2.136813526512474

Epoch: 6| Step: 4
Training loss: 1.7867658138275146
Validation loss: 2.085953668881488

Epoch: 6| Step: 5
Training loss: 2.367349624633789
Validation loss: 2.1123698065357823

Epoch: 6| Step: 6
Training loss: 2.506781816482544
Validation loss: 2.098800472033921

Epoch: 6| Step: 7
Training loss: 2.0338096618652344
Validation loss: 2.1206195739007767

Epoch: 6| Step: 8
Training loss: 1.4885921478271484
Validation loss: 2.099978026523385

Epoch: 6| Step: 9
Training loss: 2.0581700801849365
Validation loss: 2.0848421845384824

Epoch: 6| Step: 10
Training loss: 2.303609848022461
Validation loss: 2.1187415943350842

Epoch: 6| Step: 11
Training loss: 2.154073476791382
Validation loss: 2.1092475293785014

Epoch: 6| Step: 12
Training loss: 1.9137970209121704
Validation loss: 2.0914278338032384

Epoch: 6| Step: 13
Training loss: 2.7689201831817627
Validation loss: 2.1159137141320015

Epoch: 204| Step: 0
Training loss: 1.7399404048919678
Validation loss: 2.0811127244785266

Epoch: 6| Step: 1
Training loss: 2.4351253509521484
Validation loss: 2.1025126493105324

Epoch: 6| Step: 2
Training loss: 2.70733642578125
Validation loss: 2.1277124112652195

Epoch: 6| Step: 3
Training loss: 2.8430871963500977
Validation loss: 2.115489431606826

Epoch: 6| Step: 4
Training loss: 1.5842039585113525
Validation loss: 2.1200471052559475

Epoch: 6| Step: 5
Training loss: 1.849627137184143
Validation loss: 2.1244597614452405

Epoch: 6| Step: 6
Training loss: 2.0423851013183594
Validation loss: 2.1252407207283923

Epoch: 6| Step: 7
Training loss: 1.483991026878357
Validation loss: 2.1376959239282916

Epoch: 6| Step: 8
Training loss: 2.5149028301239014
Validation loss: 2.0750994772039433

Epoch: 6| Step: 9
Training loss: 1.5563846826553345
Validation loss: 2.129759097612032

Epoch: 6| Step: 10
Training loss: 2.3185935020446777
Validation loss: 2.1243053200424358

Epoch: 6| Step: 11
Training loss: 2.1096105575561523
Validation loss: 2.1056278341559955

Epoch: 6| Step: 12
Training loss: 2.24647855758667
Validation loss: 2.1069955902714885

Epoch: 6| Step: 13
Training loss: 1.3365209102630615
Validation loss: 2.1235968233436666

Epoch: 205| Step: 0
Training loss: 1.6552350521087646
Validation loss: 2.087876242976035

Epoch: 6| Step: 1
Training loss: 1.7039375305175781
Validation loss: 2.1175488143838863

Epoch: 6| Step: 2
Training loss: 1.4100956916809082
Validation loss: 2.0984646863834833

Epoch: 6| Step: 3
Training loss: 1.9610306024551392
Validation loss: 2.1315135904537734

Epoch: 6| Step: 4
Training loss: 1.8181400299072266
Validation loss: 2.0965212647632887

Epoch: 6| Step: 5
Training loss: 1.5321731567382812
Validation loss: 2.102094324686194

Epoch: 6| Step: 6
Training loss: 2.315460681915283
Validation loss: 2.0672420532472673

Epoch: 6| Step: 7
Training loss: 2.030515670776367
Validation loss: 2.0810054220179075

Epoch: 6| Step: 8
Training loss: 2.3023695945739746
Validation loss: 2.076921852686072

Epoch: 6| Step: 9
Training loss: 2.7482995986938477
Validation loss: 2.0792578151149135

Epoch: 6| Step: 10
Training loss: 2.821390151977539
Validation loss: 2.091194887315073

Epoch: 6| Step: 11
Training loss: 2.223649501800537
Validation loss: 2.109383826614708

Epoch: 6| Step: 12
Training loss: 2.2497568130493164
Validation loss: 2.1129164875194593

Epoch: 6| Step: 13
Training loss: 1.99147629737854
Validation loss: 2.0597400806283437

Epoch: 206| Step: 0
Training loss: 2.0214877128601074
Validation loss: 2.109952096016176

Epoch: 6| Step: 1
Training loss: 1.8810012340545654
Validation loss: 2.1056523053876814

Epoch: 6| Step: 2
Training loss: 1.8506641387939453
Validation loss: 2.1038542460369807

Epoch: 6| Step: 3
Training loss: 1.482520580291748
Validation loss: 2.1272201409903904

Epoch: 6| Step: 4
Training loss: 2.831080913543701
Validation loss: 2.099158715176326

Epoch: 6| Step: 5
Training loss: 3.039412498474121
Validation loss: 2.1000522798107517

Epoch: 6| Step: 6
Training loss: 1.9126672744750977
Validation loss: 2.1305405529596473

Epoch: 6| Step: 7
Training loss: 1.6175854206085205
Validation loss: 2.102439647079796

Epoch: 6| Step: 8
Training loss: 2.3895821571350098
Validation loss: 2.0925048692252046

Epoch: 6| Step: 9
Training loss: 1.7781317234039307
Validation loss: 2.10933921926765

Epoch: 6| Step: 10
Training loss: 2.37691068649292
Validation loss: 2.108734946097097

Epoch: 6| Step: 11
Training loss: 2.129426956176758
Validation loss: 2.080816691921603

Epoch: 6| Step: 12
Training loss: 1.727550983428955
Validation loss: 2.081836538930093

Epoch: 6| Step: 13
Training loss: 2.028639078140259
Validation loss: 2.0643600417721655

Epoch: 207| Step: 0
Training loss: 1.7847316265106201
Validation loss: 2.0725218506269556

Epoch: 6| Step: 1
Training loss: 1.5007063150405884
Validation loss: 2.0993494038940756

Epoch: 6| Step: 2
Training loss: 1.329789638519287
Validation loss: 2.0793534171196724

Epoch: 6| Step: 3
Training loss: 3.3462090492248535
Validation loss: 2.111547993075463

Epoch: 6| Step: 4
Training loss: 2.5247368812561035
Validation loss: 2.096232165572464

Epoch: 6| Step: 5
Training loss: 2.1034321784973145
Validation loss: 2.0909984534786594

Epoch: 6| Step: 6
Training loss: 1.8528180122375488
Validation loss: 2.1056047934357838

Epoch: 6| Step: 7
Training loss: 3.150808811187744
Validation loss: 2.1069514828343547

Epoch: 6| Step: 8
Training loss: 1.7499130964279175
Validation loss: 2.1020794171158985

Epoch: 6| Step: 9
Training loss: 1.7331637144088745
Validation loss: 2.1131251678671887

Epoch: 6| Step: 10
Training loss: 2.3980228900909424
Validation loss: 2.1108499547486663

Epoch: 6| Step: 11
Training loss: 1.681753158569336
Validation loss: 2.1354513988699964

Epoch: 6| Step: 12
Training loss: 1.8185341358184814
Validation loss: 2.117072131044121

Epoch: 6| Step: 13
Training loss: 1.5485641956329346
Validation loss: 2.1293824872662945

Epoch: 208| Step: 0
Training loss: 1.4996798038482666
Validation loss: 2.1047988732655845

Epoch: 6| Step: 1
Training loss: 1.8859715461730957
Validation loss: 2.106853569707563

Epoch: 6| Step: 2
Training loss: 1.9587994813919067
Validation loss: 2.099734329408215

Epoch: 6| Step: 3
Training loss: 2.316047430038452
Validation loss: 2.1218441173594487

Epoch: 6| Step: 4
Training loss: 2.565333366394043
Validation loss: 2.1332866632810203

Epoch: 6| Step: 5
Training loss: 2.6057019233703613
Validation loss: 2.0878753251926874

Epoch: 6| Step: 6
Training loss: 1.9935128688812256
Validation loss: 2.106057816936124

Epoch: 6| Step: 7
Training loss: 1.8975775241851807
Validation loss: 2.1252627500923733

Epoch: 6| Step: 8
Training loss: 2.6437721252441406
Validation loss: 2.095802576311173

Epoch: 6| Step: 9
Training loss: 1.8142822980880737
Validation loss: 2.1017084172976914

Epoch: 6| Step: 10
Training loss: 1.2638871669769287
Validation loss: 2.127443819917658

Epoch: 6| Step: 11
Training loss: 2.098912000656128
Validation loss: 2.1360020868239866

Epoch: 6| Step: 12
Training loss: 1.8412256240844727
Validation loss: 2.115513055555282

Epoch: 6| Step: 13
Training loss: 2.6693217754364014
Validation loss: 2.111763567052862

Epoch: 209| Step: 0
Training loss: 1.5908913612365723
Validation loss: 2.0973546992066088

Epoch: 6| Step: 1
Training loss: 2.813277244567871
Validation loss: 2.0994527468117337

Epoch: 6| Step: 2
Training loss: 2.3170745372772217
Validation loss: 2.102624072823473

Epoch: 6| Step: 3
Training loss: 1.9924122095108032
Validation loss: 2.113688903470193

Epoch: 6| Step: 4
Training loss: 2.7096352577209473
Validation loss: 2.0986099089345625

Epoch: 6| Step: 5
Training loss: 2.030505418777466
Validation loss: 2.1178924268291843

Epoch: 6| Step: 6
Training loss: 1.733890175819397
Validation loss: 2.084028854165026

Epoch: 6| Step: 7
Training loss: 2.2322709560394287
Validation loss: 2.0969254688550065

Epoch: 6| Step: 8
Training loss: 1.6157021522521973
Validation loss: 2.1060892292248306

Epoch: 6| Step: 9
Training loss: 1.9598612785339355
Validation loss: 2.091019292031565

Epoch: 6| Step: 10
Training loss: 1.902362585067749
Validation loss: 2.089132152577882

Epoch: 6| Step: 11
Training loss: 1.3964447975158691
Validation loss: 2.07699090819205

Epoch: 6| Step: 12
Training loss: 2.3710105419158936
Validation loss: 2.0720265526925363

Epoch: 6| Step: 13
Training loss: 2.017529010772705
Validation loss: 2.095513266901816

Epoch: 210| Step: 0
Training loss: 1.966635823249817
Validation loss: 2.0800942823451054

Epoch: 6| Step: 1
Training loss: 2.267660617828369
Validation loss: 2.0703991446443784

Epoch: 6| Step: 2
Training loss: 2.244734287261963
Validation loss: 2.09867339493126

Epoch: 6| Step: 3
Training loss: 2.1427595615386963
Validation loss: 2.0822155552525676

Epoch: 6| Step: 4
Training loss: 1.9662394523620605
Validation loss: 2.082638717466785

Epoch: 6| Step: 5
Training loss: 1.8369497060775757
Validation loss: 2.0858056417075534

Epoch: 6| Step: 6
Training loss: 2.2941746711730957
Validation loss: 2.0897469225750176

Epoch: 6| Step: 7
Training loss: 1.9138270616531372
Validation loss: 2.05576156544429

Epoch: 6| Step: 8
Training loss: 1.7565888166427612
Validation loss: 2.103817916685535

Epoch: 6| Step: 9
Training loss: 1.7106356620788574
Validation loss: 2.1027458021717687

Epoch: 6| Step: 10
Training loss: 2.212435722351074
Validation loss: 2.097394976564633

Epoch: 6| Step: 11
Training loss: 2.4080309867858887
Validation loss: 2.1128855187405824

Epoch: 6| Step: 12
Training loss: 1.6984574794769287
Validation loss: 2.0993254005268054

Epoch: 6| Step: 13
Training loss: 2.5251564979553223
Validation loss: 2.091151281069684

Epoch: 211| Step: 0
Training loss: 1.4286381006240845
Validation loss: 2.123601564797022

Epoch: 6| Step: 1
Training loss: 1.9729187488555908
Validation loss: 2.093426944107138

Epoch: 6| Step: 2
Training loss: 2.266728401184082
Validation loss: 2.1355403546364076

Epoch: 6| Step: 3
Training loss: 1.7471210956573486
Validation loss: 2.1194125426712858

Epoch: 6| Step: 4
Training loss: 1.4452474117279053
Validation loss: 2.1247363654516076

Epoch: 6| Step: 5
Training loss: 2.4406466484069824
Validation loss: 2.127292243383264

Epoch: 6| Step: 6
Training loss: 1.6925841569900513
Validation loss: 2.130532721037506

Epoch: 6| Step: 7
Training loss: 2.502610683441162
Validation loss: 2.0815675181727253

Epoch: 6| Step: 8
Training loss: 2.334322452545166
Validation loss: 2.149286339359899

Epoch: 6| Step: 9
Training loss: 2.249377727508545
Validation loss: 2.1298111510533158

Epoch: 6| Step: 10
Training loss: 1.8504846096038818
Validation loss: 2.1175823493670394

Epoch: 6| Step: 11
Training loss: 2.393979787826538
Validation loss: 2.093347828875306

Epoch: 6| Step: 12
Training loss: 2.1207594871520996
Validation loss: 2.0930658027689946

Epoch: 6| Step: 13
Training loss: 2.051663398742676
Validation loss: 2.099148222195205

Epoch: 212| Step: 0
Training loss: 1.995548963546753
Validation loss: 2.069876111963744

Epoch: 6| Step: 1
Training loss: 2.537856340408325
Validation loss: 2.080107431257925

Epoch: 6| Step: 2
Training loss: 1.8431663513183594
Validation loss: 2.093960408241518

Epoch: 6| Step: 3
Training loss: 2.638608455657959
Validation loss: 2.090481951672544

Epoch: 6| Step: 4
Training loss: 2.4452342987060547
Validation loss: 2.0988439026699273

Epoch: 6| Step: 5
Training loss: 2.575883388519287
Validation loss: 2.064147549290811

Epoch: 6| Step: 6
Training loss: 1.5826966762542725
Validation loss: 2.104177233993366

Epoch: 6| Step: 7
Training loss: 1.5314223766326904
Validation loss: 2.0828076126754924

Epoch: 6| Step: 8
Training loss: 1.6710976362228394
Validation loss: 2.086364360265834

Epoch: 6| Step: 9
Training loss: 1.621777892112732
Validation loss: 2.088100197494671

Epoch: 6| Step: 10
Training loss: 1.9908525943756104
Validation loss: 2.0746286684466946

Epoch: 6| Step: 11
Training loss: 2.1333887577056885
Validation loss: 2.1138725229488906

Epoch: 6| Step: 12
Training loss: 1.997901439666748
Validation loss: 2.0752390482092418

Epoch: 6| Step: 13
Training loss: 2.2275824546813965
Validation loss: 2.1120210591182915

Epoch: 213| Step: 0
Training loss: 1.9844133853912354
Validation loss: 2.063892128647015

Epoch: 6| Step: 1
Training loss: 2.377854824066162
Validation loss: 2.100739645701583

Epoch: 6| Step: 2
Training loss: 2.0851080417633057
Validation loss: 2.069111398471299

Epoch: 6| Step: 3
Training loss: 2.262373924255371
Validation loss: 2.074668199785294

Epoch: 6| Step: 4
Training loss: 1.7796449661254883
Validation loss: 2.0632278047582155

Epoch: 6| Step: 5
Training loss: 2.402358055114746
Validation loss: 2.10126760954498

Epoch: 6| Step: 6
Training loss: 2.1481199264526367
Validation loss: 2.108592064149918

Epoch: 6| Step: 7
Training loss: 1.4891281127929688
Validation loss: 2.093126427742743

Epoch: 6| Step: 8
Training loss: 1.7678683996200562
Validation loss: 2.079434299981722

Epoch: 6| Step: 9
Training loss: 2.604975938796997
Validation loss: 2.08660598211391

Epoch: 6| Step: 10
Training loss: 2.030025005340576
Validation loss: 2.1404232440456266

Epoch: 6| Step: 11
Training loss: 1.6649714708328247
Validation loss: 2.074014840587493

Epoch: 6| Step: 12
Training loss: 1.6319985389709473
Validation loss: 2.0894331175793885

Epoch: 6| Step: 13
Training loss: 2.266226053237915
Validation loss: 2.122808053929319

Epoch: 214| Step: 0
Training loss: 1.9719758033752441
Validation loss: 2.090407612503216

Epoch: 6| Step: 1
Training loss: 1.9546630382537842
Validation loss: 2.112139186551494

Epoch: 6| Step: 2
Training loss: 2.837584972381592
Validation loss: 2.096566113092566

Epoch: 6| Step: 3
Training loss: 1.9890506267547607
Validation loss: 2.092477672843523

Epoch: 6| Step: 4
Training loss: 1.7766242027282715
Validation loss: 2.1126881619935394

Epoch: 6| Step: 5
Training loss: 2.2927863597869873
Validation loss: 2.0752753749970467

Epoch: 6| Step: 6
Training loss: 2.031416893005371
Validation loss: 2.096860803583617

Epoch: 6| Step: 7
Training loss: 1.8999204635620117
Validation loss: 2.1096613471226027

Epoch: 6| Step: 8
Training loss: 2.2245187759399414
Validation loss: 2.10049819561743

Epoch: 6| Step: 9
Training loss: 2.1126184463500977
Validation loss: 2.0849008803726523

Epoch: 6| Step: 10
Training loss: 2.0215401649475098
Validation loss: 2.0884762630667737

Epoch: 6| Step: 11
Training loss: 1.9309091567993164
Validation loss: 2.090543347020303

Epoch: 6| Step: 12
Training loss: 1.756256341934204
Validation loss: 2.100514260671472

Epoch: 6| Step: 13
Training loss: 1.4249632358551025
Validation loss: 2.099446590228747

Epoch: 215| Step: 0
Training loss: 1.971099853515625
Validation loss: 2.0919598148715113

Epoch: 6| Step: 1
Training loss: 1.8931148052215576
Validation loss: 2.1100834954169487

Epoch: 6| Step: 2
Training loss: 2.22715425491333
Validation loss: 2.1008734908155215

Epoch: 6| Step: 3
Training loss: 1.9841535091400146
Validation loss: 2.116420485640085

Epoch: 6| Step: 4
Training loss: 2.2575554847717285
Validation loss: 2.1018845855548816

Epoch: 6| Step: 5
Training loss: 2.488783121109009
Validation loss: 2.1198118040638585

Epoch: 6| Step: 6
Training loss: 1.9206418991088867
Validation loss: 2.116732488396347

Epoch: 6| Step: 7
Training loss: 2.094604969024658
Validation loss: 2.1093737515070106

Epoch: 6| Step: 8
Training loss: 2.144742250442505
Validation loss: 2.12942914296222

Epoch: 6| Step: 9
Training loss: 1.5424721240997314
Validation loss: 2.1295514286205335

Epoch: 6| Step: 10
Training loss: 1.8336055278778076
Validation loss: 2.117096031865766

Epoch: 6| Step: 11
Training loss: 2.1862244606018066
Validation loss: 2.1004007554823354

Epoch: 6| Step: 12
Training loss: 1.5890285968780518
Validation loss: 2.1261734219007593

Epoch: 6| Step: 13
Training loss: 2.99761700630188
Validation loss: 2.135400761840164

Epoch: 216| Step: 0
Training loss: 2.0203309059143066
Validation loss: 2.081160755567653

Epoch: 6| Step: 1
Training loss: 2.0903501510620117
Validation loss: 2.0990228755499727

Epoch: 6| Step: 2
Training loss: 1.3849468231201172
Validation loss: 2.1170356760742846

Epoch: 6| Step: 3
Training loss: 2.3322770595550537
Validation loss: 2.116847425378779

Epoch: 6| Step: 4
Training loss: 2.1035921573638916
Validation loss: 2.093624641818385

Epoch: 6| Step: 5
Training loss: 1.7734479904174805
Validation loss: 2.1025838134109334

Epoch: 6| Step: 6
Training loss: 1.770944356918335
Validation loss: 2.1014303814980293

Epoch: 6| Step: 7
Training loss: 2.284256935119629
Validation loss: 2.09154599712741

Epoch: 6| Step: 8
Training loss: 1.902662754058838
Validation loss: 2.0808278873402584

Epoch: 6| Step: 9
Training loss: 1.7526613473892212
Validation loss: 2.1054397424062095

Epoch: 6| Step: 10
Training loss: 2.746213436126709
Validation loss: 2.0591715971628823

Epoch: 6| Step: 11
Training loss: 2.286665439605713
Validation loss: 2.07702927179234

Epoch: 6| Step: 12
Training loss: 1.935036063194275
Validation loss: 2.088212982300789

Epoch: 6| Step: 13
Training loss: 2.2006406784057617
Validation loss: 2.076340126734908

Epoch: 217| Step: 0
Training loss: 2.561342716217041
Validation loss: 2.105100322795171

Epoch: 6| Step: 1
Training loss: 1.7739670276641846
Validation loss: 2.0903857177303684

Epoch: 6| Step: 2
Training loss: 2.4374518394470215
Validation loss: 2.0964254845855055

Epoch: 6| Step: 3
Training loss: 1.8018381595611572
Validation loss: 2.1131286082729215

Epoch: 6| Step: 4
Training loss: 1.6249732971191406
Validation loss: 2.072560412909395

Epoch: 6| Step: 5
Training loss: 1.5399293899536133
Validation loss: 2.070204178492228

Epoch: 6| Step: 6
Training loss: 2.050342082977295
Validation loss: 2.0697196939940095

Epoch: 6| Step: 7
Training loss: 1.957808494567871
Validation loss: 2.0965486598271195

Epoch: 6| Step: 8
Training loss: 3.021230697631836
Validation loss: 2.0824602444966636

Epoch: 6| Step: 9
Training loss: 2.650404453277588
Validation loss: 2.0990700337194625

Epoch: 6| Step: 10
Training loss: 1.4350272417068481
Validation loss: 2.080903176338442

Epoch: 6| Step: 11
Training loss: 1.623840093612671
Validation loss: 2.083299436876851

Epoch: 6| Step: 12
Training loss: 1.9139111042022705
Validation loss: 2.0915818265689317

Epoch: 6| Step: 13
Training loss: 2.197047710418701
Validation loss: 2.1287305842163744

Epoch: 218| Step: 0
Training loss: 2.2236480712890625
Validation loss: 2.0920256850539998

Epoch: 6| Step: 1
Training loss: 3.2431490421295166
Validation loss: 2.080598238975771

Epoch: 6| Step: 2
Training loss: 2.3709051609039307
Validation loss: 2.1150010042293097

Epoch: 6| Step: 3
Training loss: 2.0309505462646484
Validation loss: 2.0951311434468916

Epoch: 6| Step: 4
Training loss: 2.256700277328491
Validation loss: 2.066839089957617

Epoch: 6| Step: 5
Training loss: 1.9872618913650513
Validation loss: 2.1224442425594536

Epoch: 6| Step: 6
Training loss: 2.5280163288116455
Validation loss: 2.109953772637152

Epoch: 6| Step: 7
Training loss: 1.639538049697876
Validation loss: 2.098463443017775

Epoch: 6| Step: 8
Training loss: 1.209761619567871
Validation loss: 2.116691379136937

Epoch: 6| Step: 9
Training loss: 2.0775370597839355
Validation loss: 2.116684539343721

Epoch: 6| Step: 10
Training loss: 1.2449369430541992
Validation loss: 2.093125645832349

Epoch: 6| Step: 11
Training loss: 1.8531172275543213
Validation loss: 2.110474383959206

Epoch: 6| Step: 12
Training loss: 1.9086439609527588
Validation loss: 2.1131453526917325

Epoch: 6| Step: 13
Training loss: 1.7285501956939697
Validation loss: 2.1236648162206015

Epoch: 219| Step: 0
Training loss: 2.0362839698791504
Validation loss: 2.066704237332908

Epoch: 6| Step: 1
Training loss: 2.154909133911133
Validation loss: 2.0933726538893995

Epoch: 6| Step: 2
Training loss: 2.1712276935577393
Validation loss: 2.1044121865303285

Epoch: 6| Step: 3
Training loss: 2.068288564682007
Validation loss: 2.1068649830356723

Epoch: 6| Step: 4
Training loss: 1.9411684274673462
Validation loss: 2.1419812197326333

Epoch: 6| Step: 5
Training loss: 2.157242774963379
Validation loss: 2.103399702297744

Epoch: 6| Step: 6
Training loss: 2.238422155380249
Validation loss: 2.111981268851988

Epoch: 6| Step: 7
Training loss: 2.1455836296081543
Validation loss: 2.0931318985518588

Epoch: 6| Step: 8
Training loss: 2.039161205291748
Validation loss: 2.0902056668394353

Epoch: 6| Step: 9
Training loss: 1.5801043510437012
Validation loss: 2.116002946771601

Epoch: 6| Step: 10
Training loss: 1.9934426546096802
Validation loss: 2.0702524210817073

Epoch: 6| Step: 11
Training loss: 1.7562487125396729
Validation loss: 2.1175606430217786

Epoch: 6| Step: 12
Training loss: 2.0265774726867676
Validation loss: 2.082856637175365

Epoch: 6| Step: 13
Training loss: 2.133723258972168
Validation loss: 2.089155667571611

Epoch: 220| Step: 0
Training loss: 2.9730281829833984
Validation loss: 2.0722537630347797

Epoch: 6| Step: 1
Training loss: 2.4991655349731445
Validation loss: 2.065683541759368

Epoch: 6| Step: 2
Training loss: 2.037198543548584
Validation loss: 2.0998093415332097

Epoch: 6| Step: 3
Training loss: 1.9217722415924072
Validation loss: 2.1053717085110244

Epoch: 6| Step: 4
Training loss: 1.8213129043579102
Validation loss: 2.096886398971722

Epoch: 6| Step: 5
Training loss: 2.276289701461792
Validation loss: 2.090264671592302

Epoch: 6| Step: 6
Training loss: 1.81602942943573
Validation loss: 2.090409662133904

Epoch: 6| Step: 7
Training loss: 2.040297508239746
Validation loss: 2.098611044627364

Epoch: 6| Step: 8
Training loss: 1.805130958557129
Validation loss: 2.043377266135267

Epoch: 6| Step: 9
Training loss: 1.840202808380127
Validation loss: 2.0918325621594667

Epoch: 6| Step: 10
Training loss: 1.9337716102600098
Validation loss: 2.0675998528798423

Epoch: 6| Step: 11
Training loss: 1.6502454280853271
Validation loss: 2.084340023738082

Epoch: 6| Step: 12
Training loss: 2.0378458499908447
Validation loss: 2.0856051855189826

Epoch: 6| Step: 13
Training loss: 1.9895223379135132
Validation loss: 2.0801074120306198

Epoch: 221| Step: 0
Training loss: 2.515871286392212
Validation loss: 2.1123352178963284

Epoch: 6| Step: 1
Training loss: 1.448591709136963
Validation loss: 2.1095965408509776

Epoch: 6| Step: 2
Training loss: 1.7089875936508179
Validation loss: 2.1218477910564792

Epoch: 6| Step: 3
Training loss: 1.9408376216888428
Validation loss: 2.0996787958247687

Epoch: 6| Step: 4
Training loss: 1.4042085409164429
Validation loss: 2.1195433088528213

Epoch: 6| Step: 5
Training loss: 2.839547634124756
Validation loss: 2.137339393297831

Epoch: 6| Step: 6
Training loss: 1.7183539867401123
Validation loss: 2.134009245903261

Epoch: 6| Step: 7
Training loss: 1.9699472188949585
Validation loss: 2.0942987165143414

Epoch: 6| Step: 8
Training loss: 1.7412848472595215
Validation loss: 2.141727719255673

Epoch: 6| Step: 9
Training loss: 2.6588101387023926
Validation loss: 2.1270066435619066

Epoch: 6| Step: 10
Training loss: 2.496893882751465
Validation loss: 2.1041098371628792

Epoch: 6| Step: 11
Training loss: 1.3835833072662354
Validation loss: 2.103410533679429

Epoch: 6| Step: 12
Training loss: 2.417698860168457
Validation loss: 2.1246946986003588

Epoch: 6| Step: 13
Training loss: 2.494312047958374
Validation loss: 2.1344776820111018

Epoch: 222| Step: 0
Training loss: 2.153730869293213
Validation loss: 2.120983455770759

Epoch: 6| Step: 1
Training loss: 1.7643650770187378
Validation loss: 2.128887884078487

Epoch: 6| Step: 2
Training loss: 2.55136775970459
Validation loss: 2.1350151415794127

Epoch: 6| Step: 3
Training loss: 1.7758105993270874
Validation loss: 2.1149608294169107

Epoch: 6| Step: 4
Training loss: 1.5352842807769775
Validation loss: 2.0996946647603023

Epoch: 6| Step: 5
Training loss: 2.2741916179656982
Validation loss: 2.1031948597200456

Epoch: 6| Step: 6
Training loss: 1.4269530773162842
Validation loss: 2.121833009104575

Epoch: 6| Step: 7
Training loss: 1.952290415763855
Validation loss: 2.1253910679971018

Epoch: 6| Step: 8
Training loss: 1.3884990215301514
Validation loss: 2.1277100950159054

Epoch: 6| Step: 9
Training loss: 1.713089942932129
Validation loss: 2.111799837440573

Epoch: 6| Step: 10
Training loss: 3.1494874954223633
Validation loss: 2.1199931175478044

Epoch: 6| Step: 11
Training loss: 1.966750144958496
Validation loss: 2.1143913807407504

Epoch: 6| Step: 12
Training loss: 2.490495443344116
Validation loss: 2.1228892341736825

Epoch: 6| Step: 13
Training loss: 2.380608081817627
Validation loss: 2.093598073528659

Epoch: 223| Step: 0
Training loss: 1.599749207496643
Validation loss: 2.09209789511978

Epoch: 6| Step: 1
Training loss: 1.8675103187561035
Validation loss: 2.102178709481352

Epoch: 6| Step: 2
Training loss: 2.1185054779052734
Validation loss: 2.0981235375968357

Epoch: 6| Step: 3
Training loss: 1.903969645500183
Validation loss: 2.1070426151316655

Epoch: 6| Step: 4
Training loss: 1.9447582960128784
Validation loss: 2.0910514080396263

Epoch: 6| Step: 5
Training loss: 1.2359272241592407
Validation loss: 2.105940277858447

Epoch: 6| Step: 6
Training loss: 2.4484426975250244
Validation loss: 2.0880271119456135

Epoch: 6| Step: 7
Training loss: 2.83176326751709
Validation loss: 2.0672159374401136

Epoch: 6| Step: 8
Training loss: 2.089346408843994
Validation loss: 2.111409043753019

Epoch: 6| Step: 9
Training loss: 1.925660490989685
Validation loss: 2.0938011779580066

Epoch: 6| Step: 10
Training loss: 2.0598304271698
Validation loss: 2.1199499868577525

Epoch: 6| Step: 11
Training loss: 2.490079164505005
Validation loss: 2.105001402157609

Epoch: 6| Step: 12
Training loss: 2.191272258758545
Validation loss: 2.082394278177651

Epoch: 6| Step: 13
Training loss: 1.34147047996521
Validation loss: 2.0869623384168072

Epoch: 224| Step: 0
Training loss: 2.3342299461364746
Validation loss: 2.1003968356758036

Epoch: 6| Step: 1
Training loss: 2.2409119606018066
Validation loss: 2.077370605161113

Epoch: 6| Step: 2
Training loss: 2.370845079421997
Validation loss: 2.104458491007487

Epoch: 6| Step: 3
Training loss: 1.731053113937378
Validation loss: 2.096118406582904

Epoch: 6| Step: 4
Training loss: 1.8098456859588623
Validation loss: 2.1046170880717616

Epoch: 6| Step: 5
Training loss: 1.421602725982666
Validation loss: 2.0961183476191696

Epoch: 6| Step: 6
Training loss: 2.4359612464904785
Validation loss: 2.1085245968193136

Epoch: 6| Step: 7
Training loss: 1.6108102798461914
Validation loss: 2.0953075937045518

Epoch: 6| Step: 8
Training loss: 2.4034199714660645
Validation loss: 2.1288109107684066

Epoch: 6| Step: 9
Training loss: 1.960066556930542
Validation loss: 2.107972273262598

Epoch: 6| Step: 10
Training loss: 1.833793044090271
Validation loss: 2.0802257189186673

Epoch: 6| Step: 11
Training loss: 1.994375228881836
Validation loss: 2.0793223201587634

Epoch: 6| Step: 12
Training loss: 1.9099746942520142
Validation loss: 2.1237547320704304

Epoch: 6| Step: 13
Training loss: 2.684370994567871
Validation loss: 2.0910449592016076

Epoch: 225| Step: 0
Training loss: 2.7080438137054443
Validation loss: 2.0866804328016055

Epoch: 6| Step: 1
Training loss: 2.311093330383301
Validation loss: 2.1245346376972813

Epoch: 6| Step: 2
Training loss: 2.091362476348877
Validation loss: 2.114350723963912

Epoch: 6| Step: 3
Training loss: 1.7494993209838867
Validation loss: 2.10311189774544

Epoch: 6| Step: 4
Training loss: 1.360365390777588
Validation loss: 2.1157552452497583

Epoch: 6| Step: 5
Training loss: 1.7357547283172607
Validation loss: 2.118695218075988

Epoch: 6| Step: 6
Training loss: 1.5225789546966553
Validation loss: 2.0912180600627774

Epoch: 6| Step: 7
Training loss: 2.661407947540283
Validation loss: 2.10284565084724

Epoch: 6| Step: 8
Training loss: 2.5780022144317627
Validation loss: 2.0913825086368028

Epoch: 6| Step: 9
Training loss: 2.300103187561035
Validation loss: 2.0858634902584936

Epoch: 6| Step: 10
Training loss: 1.756774663925171
Validation loss: 2.0995722073380665

Epoch: 6| Step: 11
Training loss: 1.3658089637756348
Validation loss: 2.099101138371293

Epoch: 6| Step: 12
Training loss: 2.2224626541137695
Validation loss: 2.1055567700375795

Epoch: 6| Step: 13
Training loss: 1.901145100593567
Validation loss: 2.0931762187711653

Epoch: 226| Step: 0
Training loss: 1.9919703006744385
Validation loss: 2.071227853016187

Epoch: 6| Step: 1
Training loss: 2.118170738220215
Validation loss: 2.1100096676939275

Epoch: 6| Step: 2
Training loss: 2.1323306560516357
Validation loss: 2.138100367720409

Epoch: 6| Step: 3
Training loss: 1.7102959156036377
Validation loss: 2.124318581755443

Epoch: 6| Step: 4
Training loss: 1.9296281337738037
Validation loss: 2.105251318664961

Epoch: 6| Step: 5
Training loss: 2.0249176025390625
Validation loss: 2.099103637920913

Epoch: 6| Step: 6
Training loss: 2.4239327907562256
Validation loss: 2.129466369587888

Epoch: 6| Step: 7
Training loss: 2.4626338481903076
Validation loss: 2.0641503821137133

Epoch: 6| Step: 8
Training loss: 2.036048412322998
Validation loss: 2.116793196688416

Epoch: 6| Step: 9
Training loss: 2.2337613105773926
Validation loss: 2.12225874265035

Epoch: 6| Step: 10
Training loss: 1.5409605503082275
Validation loss: 2.1364999586536038

Epoch: 6| Step: 11
Training loss: 2.0628609657287598
Validation loss: 2.1166561008781515

Epoch: 6| Step: 12
Training loss: 1.8987200260162354
Validation loss: 2.1287523905436196

Epoch: 6| Step: 13
Training loss: 1.195138931274414
Validation loss: 2.1202280136846725

Epoch: 227| Step: 0
Training loss: 1.5446593761444092
Validation loss: 2.0896296885705765

Epoch: 6| Step: 1
Training loss: 1.916630744934082
Validation loss: 2.094875115220265

Epoch: 6| Step: 2
Training loss: 2.0383412837982178
Validation loss: 2.0945260268385693

Epoch: 6| Step: 3
Training loss: 2.250011920928955
Validation loss: 2.0998709406903995

Epoch: 6| Step: 4
Training loss: 1.9860568046569824
Validation loss: 2.1052148470314602

Epoch: 6| Step: 5
Training loss: 1.6072206497192383
Validation loss: 2.114499286938739

Epoch: 6| Step: 6
Training loss: 2.0858120918273926
Validation loss: 2.09564693127909

Epoch: 6| Step: 7
Training loss: 2.485534191131592
Validation loss: 2.0812335757799048

Epoch: 6| Step: 8
Training loss: 1.8801418542861938
Validation loss: 2.0915852426200785

Epoch: 6| Step: 9
Training loss: 1.9592125415802002
Validation loss: 2.097725095287446

Epoch: 6| Step: 10
Training loss: 1.998997449874878
Validation loss: 2.097792021689876

Epoch: 6| Step: 11
Training loss: 2.573277473449707
Validation loss: 2.0595708585554555

Epoch: 6| Step: 12
Training loss: 1.801350712776184
Validation loss: 2.0968911058159283

Epoch: 6| Step: 13
Training loss: 2.351912021636963
Validation loss: 2.0985446976077173

Epoch: 228| Step: 0
Training loss: 2.171739101409912
Validation loss: 2.0837746615050943

Epoch: 6| Step: 1
Training loss: 1.469854474067688
Validation loss: 2.074453164172429

Epoch: 6| Step: 2
Training loss: 2.1251273155212402
Validation loss: 2.1027630554732455

Epoch: 6| Step: 3
Training loss: 1.6255990266799927
Validation loss: 2.109823408947196

Epoch: 6| Step: 4
Training loss: 1.992255687713623
Validation loss: 2.109167936027691

Epoch: 6| Step: 5
Training loss: 2.421720027923584
Validation loss: 2.0847338271397415

Epoch: 6| Step: 6
Training loss: 2.6598033905029297
Validation loss: 2.093092638959167

Epoch: 6| Step: 7
Training loss: 2.154470920562744
Validation loss: 2.112511509208269

Epoch: 6| Step: 8
Training loss: 1.859691858291626
Validation loss: 2.0768317022631244

Epoch: 6| Step: 9
Training loss: 1.7629971504211426
Validation loss: 2.1076031782293834

Epoch: 6| Step: 10
Training loss: 1.9883878231048584
Validation loss: 2.0821487749776533

Epoch: 6| Step: 11
Training loss: 1.7026469707489014
Validation loss: 2.0783146965888237

Epoch: 6| Step: 12
Training loss: 2.0023386478424072
Validation loss: 2.107483261375017

Epoch: 6| Step: 13
Training loss: 2.14827823638916
Validation loss: 2.1236260039832002

Epoch: 229| Step: 0
Training loss: 2.316262722015381
Validation loss: 2.1207641850235643

Epoch: 6| Step: 1
Training loss: 1.2797833681106567
Validation loss: 2.092653259154289

Epoch: 6| Step: 2
Training loss: 1.9629402160644531
Validation loss: 2.05400675342929

Epoch: 6| Step: 3
Training loss: 1.9235265254974365
Validation loss: 2.1080736498678885

Epoch: 6| Step: 4
Training loss: 2.446107864379883
Validation loss: 2.076327985332858

Epoch: 6| Step: 5
Training loss: 1.8655414581298828
Validation loss: 2.1107879018270843

Epoch: 6| Step: 6
Training loss: 2.1433053016662598
Validation loss: 2.119307174477526

Epoch: 6| Step: 7
Training loss: 1.9010982513427734
Validation loss: 2.1067154228046374

Epoch: 6| Step: 8
Training loss: 1.9953207969665527
Validation loss: 2.102213116102321

Epoch: 6| Step: 9
Training loss: 1.7479984760284424
Validation loss: 2.089728573317169

Epoch: 6| Step: 10
Training loss: 1.8221004009246826
Validation loss: 2.075133869724889

Epoch: 6| Step: 11
Training loss: 2.361082077026367
Validation loss: 2.072309547855008

Epoch: 6| Step: 12
Training loss: 2.361428737640381
Validation loss: 2.11096969983911

Epoch: 6| Step: 13
Training loss: 2.2608249187469482
Validation loss: 2.110659747995356

Epoch: 230| Step: 0
Training loss: 1.706728458404541
Validation loss: 2.0978103568477016

Epoch: 6| Step: 1
Training loss: 1.8839178085327148
Validation loss: 2.1249723049902145

Epoch: 6| Step: 2
Training loss: 1.9781255722045898
Validation loss: 2.1117034342981156

Epoch: 6| Step: 3
Training loss: 1.8675096035003662
Validation loss: 2.114604707687132

Epoch: 6| Step: 4
Training loss: 2.3664255142211914
Validation loss: 2.126769511930404

Epoch: 6| Step: 5
Training loss: 1.95072340965271
Validation loss: 2.1596465418415685

Epoch: 6| Step: 6
Training loss: 1.9877082109451294
Validation loss: 2.1434014279355287

Epoch: 6| Step: 7
Training loss: 2.0546374320983887
Validation loss: 2.1477462117389967

Epoch: 6| Step: 8
Training loss: 2.1010074615478516
Validation loss: 2.132859427441833

Epoch: 6| Step: 9
Training loss: 2.7476789951324463
Validation loss: 2.1484382716558312

Epoch: 6| Step: 10
Training loss: 1.8891425132751465
Validation loss: 2.1363283652131275

Epoch: 6| Step: 11
Training loss: 1.792616844177246
Validation loss: 2.1147773278656827

Epoch: 6| Step: 12
Training loss: 2.341310977935791
Validation loss: 2.1172205440459715

Epoch: 6| Step: 13
Training loss: 1.3810181617736816
Validation loss: 2.0999607924492127

Epoch: 231| Step: 0
Training loss: 1.8173850774765015
Validation loss: 2.1475650584825905

Epoch: 6| Step: 1
Training loss: 2.2183966636657715
Validation loss: 2.0866882108872935

Epoch: 6| Step: 2
Training loss: 1.9157512187957764
Validation loss: 2.1397041889929

Epoch: 6| Step: 3
Training loss: 2.7488951683044434
Validation loss: 2.1049482066144227

Epoch: 6| Step: 4
Training loss: 1.8832728862762451
Validation loss: 2.1193407248425227

Epoch: 6| Step: 5
Training loss: 1.9066059589385986
Validation loss: 2.117801009967763

Epoch: 6| Step: 6
Training loss: 2.1485180854797363
Validation loss: 2.099801121219512

Epoch: 6| Step: 7
Training loss: 1.5780904293060303
Validation loss: 2.108900905937277

Epoch: 6| Step: 8
Training loss: 1.8458826541900635
Validation loss: 2.0774328529193835

Epoch: 6| Step: 9
Training loss: 2.0365335941314697
Validation loss: 2.0998017531569286

Epoch: 6| Step: 10
Training loss: 2.205665111541748
Validation loss: 2.103544772312205

Epoch: 6| Step: 11
Training loss: 1.6576690673828125
Validation loss: 2.104048575124433

Epoch: 6| Step: 12
Training loss: 2.0712811946868896
Validation loss: 2.090872646659933

Epoch: 6| Step: 13
Training loss: 2.2169578075408936
Validation loss: 2.106183126408567

Epoch: 232| Step: 0
Training loss: 1.6284663677215576
Validation loss: 2.0966238142341695

Epoch: 6| Step: 1
Training loss: 2.1342973709106445
Validation loss: 2.1097416813655565

Epoch: 6| Step: 2
Training loss: 2.525228977203369
Validation loss: 2.112587223770798

Epoch: 6| Step: 3
Training loss: 1.8460253477096558
Validation loss: 2.1139213782484814

Epoch: 6| Step: 4
Training loss: 2.196190357208252
Validation loss: 2.097131916271743

Epoch: 6| Step: 5
Training loss: 1.871781349182129
Validation loss: 2.090123174011066

Epoch: 6| Step: 6
Training loss: 2.8992397785186768
Validation loss: 2.0647141907804754

Epoch: 6| Step: 7
Training loss: 1.800344705581665
Validation loss: 2.086071205395524

Epoch: 6| Step: 8
Training loss: 2.2937469482421875
Validation loss: 2.0644850500168337

Epoch: 6| Step: 9
Training loss: 1.9340691566467285
Validation loss: 2.073713215448523

Epoch: 6| Step: 10
Training loss: 1.9620870351791382
Validation loss: 2.0937815071434103

Epoch: 6| Step: 11
Training loss: 1.5965832471847534
Validation loss: 2.06772183346492

Epoch: 6| Step: 12
Training loss: 1.9374091625213623
Validation loss: 2.1072933250857937

Epoch: 6| Step: 13
Training loss: 1.2944878339767456
Validation loss: 2.102617903422284

Epoch: 233| Step: 0
Training loss: 2.25722599029541
Validation loss: 2.090588811905153

Epoch: 6| Step: 1
Training loss: 1.8751530647277832
Validation loss: 2.1024727488076813

Epoch: 6| Step: 2
Training loss: 1.4571869373321533
Validation loss: 2.107337023622246

Epoch: 6| Step: 3
Training loss: 2.1620068550109863
Validation loss: 2.0919491834537958

Epoch: 6| Step: 4
Training loss: 2.3424768447875977
Validation loss: 2.133584542941022

Epoch: 6| Step: 5
Training loss: 1.5283842086791992
Validation loss: 2.1426943553391324

Epoch: 6| Step: 6
Training loss: 2.094729423522949
Validation loss: 2.1372919621006137

Epoch: 6| Step: 7
Training loss: 1.7869395017623901
Validation loss: 2.1317479328442643

Epoch: 6| Step: 8
Training loss: 2.244203805923462
Validation loss: 2.1168277212368545

Epoch: 6| Step: 9
Training loss: 2.145131826400757
Validation loss: 2.1266842503701486

Epoch: 6| Step: 10
Training loss: 2.4043948650360107
Validation loss: 2.129993918121502

Epoch: 6| Step: 11
Training loss: 1.4520245790481567
Validation loss: 2.1291185040627756

Epoch: 6| Step: 12
Training loss: 2.1294283866882324
Validation loss: 2.116207786785659

Epoch: 6| Step: 13
Training loss: 2.422673463821411
Validation loss: 2.1121682223453315

Epoch: 234| Step: 0
Training loss: 1.922861933708191
Validation loss: 2.123545777413153

Epoch: 6| Step: 1
Training loss: 1.5567831993103027
Validation loss: 2.1192351618120746

Epoch: 6| Step: 2
Training loss: 2.407118082046509
Validation loss: 2.120188661800918

Epoch: 6| Step: 3
Training loss: 1.7357462644577026
Validation loss: 2.1366461271880777

Epoch: 6| Step: 4
Training loss: 2.2275547981262207
Validation loss: 2.1091275727877052

Epoch: 6| Step: 5
Training loss: 1.9301592111587524
Validation loss: 2.113033699732955

Epoch: 6| Step: 6
Training loss: 2.6037650108337402
Validation loss: 2.1138121927938154

Epoch: 6| Step: 7
Training loss: 2.00068998336792
Validation loss: 2.0926484190007693

Epoch: 6| Step: 8
Training loss: 1.8169240951538086
Validation loss: 2.0853931955111924

Epoch: 6| Step: 9
Training loss: 1.6240191459655762
Validation loss: 2.1117687250978205

Epoch: 6| Step: 10
Training loss: 2.4975314140319824
Validation loss: 2.0821507438536613

Epoch: 6| Step: 11
Training loss: 1.4856373071670532
Validation loss: 2.107308413392754

Epoch: 6| Step: 12
Training loss: 2.1820144653320312
Validation loss: 2.092952125815935

Epoch: 6| Step: 13
Training loss: 2.68483567237854
Validation loss: 2.118751714306493

Epoch: 235| Step: 0
Training loss: 1.7506697177886963
Validation loss: 2.0864913130319245

Epoch: 6| Step: 1
Training loss: 2.4149422645568848
Validation loss: 2.1027026445634904

Epoch: 6| Step: 2
Training loss: 1.657623052597046
Validation loss: 2.1114660065661193

Epoch: 6| Step: 3
Training loss: 1.4583404064178467
Validation loss: 2.1129349803411834

Epoch: 6| Step: 4
Training loss: 2.0626749992370605
Validation loss: 2.1134300680570703

Epoch: 6| Step: 5
Training loss: 2.083542585372925
Validation loss: 2.1058362889033493

Epoch: 6| Step: 6
Training loss: 1.726234793663025
Validation loss: 2.1212920322213122

Epoch: 6| Step: 7
Training loss: 1.9408842325210571
Validation loss: 2.0983099937438965

Epoch: 6| Step: 8
Training loss: 2.880282163619995
Validation loss: 2.0794967566767046

Epoch: 6| Step: 9
Training loss: 1.963663101196289
Validation loss: 2.107050593181323

Epoch: 6| Step: 10
Training loss: 2.5564451217651367
Validation loss: 2.1158704937145276

Epoch: 6| Step: 11
Training loss: 1.7579843997955322
Validation loss: 2.0911485328469226

Epoch: 6| Step: 12
Training loss: 1.5714170932769775
Validation loss: 2.1242987161041587

Epoch: 6| Step: 13
Training loss: 2.324901819229126
Validation loss: 2.0981856571730746

Epoch: 236| Step: 0
Training loss: 2.080083131790161
Validation loss: 2.122166165741541

Epoch: 6| Step: 1
Training loss: 2.13348126411438
Validation loss: 2.1331997391998128

Epoch: 6| Step: 2
Training loss: 1.8805075883865356
Validation loss: 2.103083360579706

Epoch: 6| Step: 3
Training loss: 2.1743991374969482
Validation loss: 2.0993409541345414

Epoch: 6| Step: 4
Training loss: 2.3219127655029297
Validation loss: 2.1044686237970986

Epoch: 6| Step: 5
Training loss: 2.2334048748016357
Validation loss: 2.0791336515898347

Epoch: 6| Step: 6
Training loss: 2.0397300720214844
Validation loss: 2.1060027486534527

Epoch: 6| Step: 7
Training loss: 2.5776901245117188
Validation loss: 2.097552191826605

Epoch: 6| Step: 8
Training loss: 1.972137689590454
Validation loss: 2.114568769290883

Epoch: 6| Step: 9
Training loss: 1.3776895999908447
Validation loss: 2.077652923522457

Epoch: 6| Step: 10
Training loss: 1.748679757118225
Validation loss: 2.064220941194924

Epoch: 6| Step: 11
Training loss: 1.5049850940704346
Validation loss: 2.086225341725093

Epoch: 6| Step: 12
Training loss: 1.8748459815979004
Validation loss: 2.1077933388371624

Epoch: 6| Step: 13
Training loss: 2.106818437576294
Validation loss: 2.0922518981400358

Epoch: 237| Step: 0
Training loss: 1.6463820934295654
Validation loss: 2.079201426557315

Epoch: 6| Step: 1
Training loss: 1.5390015840530396
Validation loss: 2.1400810698027253

Epoch: 6| Step: 2
Training loss: 1.340409517288208
Validation loss: 2.0912546483419274

Epoch: 6| Step: 3
Training loss: 2.4878034591674805
Validation loss: 2.074234513826268

Epoch: 6| Step: 4
Training loss: 2.150937557220459
Validation loss: 2.0826944176868727

Epoch: 6| Step: 5
Training loss: 1.587599277496338
Validation loss: 2.1158550272705736

Epoch: 6| Step: 6
Training loss: 1.5854568481445312
Validation loss: 2.1045188134716404

Epoch: 6| Step: 7
Training loss: 2.042140483856201
Validation loss: 2.0829023033060055

Epoch: 6| Step: 8
Training loss: 2.4696707725524902
Validation loss: 2.0916814829713557

Epoch: 6| Step: 9
Training loss: 1.939215898513794
Validation loss: 2.1336580835362917

Epoch: 6| Step: 10
Training loss: 2.638190269470215
Validation loss: 2.1094359838834373

Epoch: 6| Step: 11
Training loss: 1.9491217136383057
Validation loss: 2.1303689172191005

Epoch: 6| Step: 12
Training loss: 2.322183609008789
Validation loss: 2.08774910947328

Epoch: 6| Step: 13
Training loss: 2.431410074234009
Validation loss: 2.132478383279616

Epoch: 238| Step: 0
Training loss: 1.623744249343872
Validation loss: 2.0710102793990925

Epoch: 6| Step: 1
Training loss: 1.49447500705719
Validation loss: 2.0994021123455417

Epoch: 6| Step: 2
Training loss: 2.0727057456970215
Validation loss: 2.1055953605200655

Epoch: 6| Step: 3
Training loss: 3.2986412048339844
Validation loss: 2.1244230731841056

Epoch: 6| Step: 4
Training loss: 3.336209297180176
Validation loss: 2.1092465269950127

Epoch: 6| Step: 5
Training loss: 1.5475200414657593
Validation loss: 2.1230858372103785

Epoch: 6| Step: 6
Training loss: 1.2088172435760498
Validation loss: 2.1011379098379486

Epoch: 6| Step: 7
Training loss: 1.9563363790512085
Validation loss: 2.11262648336349

Epoch: 6| Step: 8
Training loss: 1.917529821395874
Validation loss: 2.119141665838098

Epoch: 6| Step: 9
Training loss: 2.2536416053771973
Validation loss: 2.146857071948308

Epoch: 6| Step: 10
Training loss: 2.086162567138672
Validation loss: 2.1064644411046016

Epoch: 6| Step: 11
Training loss: 1.6844260692596436
Validation loss: 2.1231853218488794

Epoch: 6| Step: 12
Training loss: 1.286989688873291
Validation loss: 2.119417898116573

Epoch: 6| Step: 13
Training loss: 2.215665578842163
Validation loss: 2.135726018618512

Epoch: 239| Step: 0
Training loss: 1.7057197093963623
Validation loss: 2.0933834673256

Epoch: 6| Step: 1
Training loss: 2.0975453853607178
Validation loss: 2.1145608604595227

Epoch: 6| Step: 2
Training loss: 2.003159523010254
Validation loss: 2.1155803972674954

Epoch: 6| Step: 3
Training loss: 1.5929538011550903
Validation loss: 2.108507976737074

Epoch: 6| Step: 4
Training loss: 2.4506425857543945
Validation loss: 2.099379616398965

Epoch: 6| Step: 5
Training loss: 1.9053704738616943
Validation loss: 2.095773694335773

Epoch: 6| Step: 6
Training loss: 2.0220465660095215
Validation loss: 2.0758126474195913

Epoch: 6| Step: 7
Training loss: 2.182025194168091
Validation loss: 2.094815223447738

Epoch: 6| Step: 8
Training loss: 1.9644553661346436
Validation loss: 2.082867376265987

Epoch: 6| Step: 9
Training loss: 2.1473355293273926
Validation loss: 2.09271216136153

Epoch: 6| Step: 10
Training loss: 1.6559951305389404
Validation loss: 2.1004132224667456

Epoch: 6| Step: 11
Training loss: 2.399242877960205
Validation loss: 2.086974069636355

Epoch: 6| Step: 12
Training loss: 1.6621921062469482
Validation loss: 2.0746742756136003

Epoch: 6| Step: 13
Training loss: 1.8508306741714478
Validation loss: 2.0899062810405606

Epoch: 240| Step: 0
Training loss: 2.2814435958862305
Validation loss: 2.0676860219688824

Epoch: 6| Step: 1
Training loss: 1.8622812032699585
Validation loss: 2.0744248359434065

Epoch: 6| Step: 2
Training loss: 1.5335369110107422
Validation loss: 2.0707786877950034

Epoch: 6| Step: 3
Training loss: 1.98746919631958
Validation loss: 2.0522897192226943

Epoch: 6| Step: 4
Training loss: 1.96010422706604
Validation loss: 2.0744891781960764

Epoch: 6| Step: 5
Training loss: 1.642958164215088
Validation loss: 2.0721049718959357

Epoch: 6| Step: 6
Training loss: 2.0069422721862793
Validation loss: 2.0715162138785086

Epoch: 6| Step: 7
Training loss: 1.7724097967147827
Validation loss: 2.0971696376800537

Epoch: 6| Step: 8
Training loss: 1.8443973064422607
Validation loss: 2.1016157416887182

Epoch: 6| Step: 9
Training loss: 2.2715325355529785
Validation loss: 2.0922989114638297

Epoch: 6| Step: 10
Training loss: 2.727989435195923
Validation loss: 2.067505185322095

Epoch: 6| Step: 11
Training loss: 2.440871238708496
Validation loss: 2.119131072874992

Epoch: 6| Step: 12
Training loss: 2.0001227855682373
Validation loss: 2.1017558805404173

Epoch: 6| Step: 13
Training loss: 1.3444974422454834
Validation loss: 2.102523357637467

Epoch: 241| Step: 0
Training loss: 2.2186222076416016
Validation loss: 2.136670691992647

Epoch: 6| Step: 1
Training loss: 2.4384114742279053
Validation loss: 2.1052515660562823

Epoch: 6| Step: 2
Training loss: 1.7505674362182617
Validation loss: 2.0906204151850876

Epoch: 6| Step: 3
Training loss: 1.723393201828003
Validation loss: 2.0886607272650606

Epoch: 6| Step: 4
Training loss: 1.6535346508026123
Validation loss: 2.109092197110576

Epoch: 6| Step: 5
Training loss: 1.7920746803283691
Validation loss: 2.1259049241260817

Epoch: 6| Step: 6
Training loss: 1.8855332136154175
Validation loss: 2.095513584793255

Epoch: 6| Step: 7
Training loss: 1.4556119441986084
Validation loss: 2.139557653857816

Epoch: 6| Step: 8
Training loss: 2.7231979370117188
Validation loss: 2.1307287498186995

Epoch: 6| Step: 9
Training loss: 2.548090934753418
Validation loss: 2.15000254877152

Epoch: 6| Step: 10
Training loss: 1.9236972332000732
Validation loss: 2.135056129065893

Epoch: 6| Step: 11
Training loss: 2.270618438720703
Validation loss: 2.1223538511542865

Epoch: 6| Step: 12
Training loss: 1.7139744758605957
Validation loss: 2.1299342980948825

Epoch: 6| Step: 13
Training loss: 1.7666610479354858
Validation loss: 2.131403899961902

Epoch: 242| Step: 0
Training loss: 1.8592275381088257
Validation loss: 2.1051550475499963

Epoch: 6| Step: 1
Training loss: 2.0750699043273926
Validation loss: 2.1165527066876813

Epoch: 6| Step: 2
Training loss: 1.7939815521240234
Validation loss: 2.0652291967022802

Epoch: 6| Step: 3
Training loss: 1.7955069541931152
Validation loss: 2.070748142016831

Epoch: 6| Step: 4
Training loss: 1.6722915172576904
Validation loss: 2.1209929297047276

Epoch: 6| Step: 5
Training loss: 2.1768364906311035
Validation loss: 2.1087016392779607

Epoch: 6| Step: 6
Training loss: 1.8457326889038086
Validation loss: 2.1028233651191957

Epoch: 6| Step: 7
Training loss: 2.554731607437134
Validation loss: 2.098698946737474

Epoch: 6| Step: 8
Training loss: 1.1911852359771729
Validation loss: 2.0847567883870934

Epoch: 6| Step: 9
Training loss: 2.109297513961792
Validation loss: 2.097125146978645

Epoch: 6| Step: 10
Training loss: 2.117357015609741
Validation loss: 2.1042430644394248

Epoch: 6| Step: 11
Training loss: 2.583972692489624
Validation loss: 2.082188544734832

Epoch: 6| Step: 12
Training loss: 1.8071671724319458
Validation loss: 2.0678563041071736

Epoch: 6| Step: 13
Training loss: 2.2796037197113037
Validation loss: 2.0632104437838317

Epoch: 243| Step: 0
Training loss: 1.8816076517105103
Validation loss: 2.1023110394836753

Epoch: 6| Step: 1
Training loss: 1.5782105922698975
Validation loss: 2.064379803596004

Epoch: 6| Step: 2
Training loss: 2.3149101734161377
Validation loss: 2.0784607189957813

Epoch: 6| Step: 3
Training loss: 2.082399368286133
Validation loss: 2.0885444815440843

Epoch: 6| Step: 4
Training loss: 1.3035997152328491
Validation loss: 2.090781964281554

Epoch: 6| Step: 5
Training loss: 2.068591594696045
Validation loss: 2.0856397639038744

Epoch: 6| Step: 6
Training loss: 1.8307998180389404
Validation loss: 2.0927952643363708

Epoch: 6| Step: 7
Training loss: 1.5303730964660645
Validation loss: 2.0862373100814

Epoch: 6| Step: 8
Training loss: 2.9823455810546875
Validation loss: 2.0656697211727018

Epoch: 6| Step: 9
Training loss: 2.3108253479003906
Validation loss: 2.050148647318604

Epoch: 6| Step: 10
Training loss: 1.6584542989730835
Validation loss: 2.0595845996692614

Epoch: 6| Step: 11
Training loss: 2.3468923568725586
Validation loss: 2.087154173081921

Epoch: 6| Step: 12
Training loss: 2.2124385833740234
Validation loss: 2.084196408589681

Epoch: 6| Step: 13
Training loss: 1.309713363647461
Validation loss: 2.0802663103226693

Epoch: 244| Step: 0
Training loss: 2.0532360076904297
Validation loss: 2.0908870427839217

Epoch: 6| Step: 1
Training loss: 2.157334804534912
Validation loss: 2.0996824823400027

Epoch: 6| Step: 2
Training loss: 1.749105453491211
Validation loss: 2.089595945932532

Epoch: 6| Step: 3
Training loss: 1.7774035930633545
Validation loss: 2.0823725884960544

Epoch: 6| Step: 4
Training loss: 2.112049102783203
Validation loss: 2.128308101366925

Epoch: 6| Step: 5
Training loss: 1.8556479215621948
Validation loss: 2.129041611507375

Epoch: 6| Step: 6
Training loss: 1.9232853651046753
Validation loss: 2.1022186715115785

Epoch: 6| Step: 7
Training loss: 1.8329503536224365
Validation loss: 2.124926819596239

Epoch: 6| Step: 8
Training loss: 2.8375444412231445
Validation loss: 2.114713979023759

Epoch: 6| Step: 9
Training loss: 1.7031956911087036
Validation loss: 2.1250233996299004

Epoch: 6| Step: 10
Training loss: 1.645768404006958
Validation loss: 2.101671841836745

Epoch: 6| Step: 11
Training loss: 2.1967830657958984
Validation loss: 2.1191041085027877

Epoch: 6| Step: 12
Training loss: 1.6546522378921509
Validation loss: 2.1009289551806707

Epoch: 6| Step: 13
Training loss: 2.1972906589508057
Validation loss: 2.0979024018010786

Epoch: 245| Step: 0
Training loss: 1.4634146690368652
Validation loss: 2.12924926511703

Epoch: 6| Step: 1
Training loss: 2.1219117641448975
Validation loss: 2.1105303661797636

Epoch: 6| Step: 2
Training loss: 2.105856418609619
Validation loss: 2.109495552637244

Epoch: 6| Step: 3
Training loss: 2.134455919265747
Validation loss: 2.145847321838461

Epoch: 6| Step: 4
Training loss: 2.3221864700317383
Validation loss: 2.16745844194966

Epoch: 6| Step: 5
Training loss: 2.4061129093170166
Validation loss: 2.1506071936699653

Epoch: 6| Step: 6
Training loss: 2.253446102142334
Validation loss: 2.1618941855686966

Epoch: 6| Step: 7
Training loss: 1.734084963798523
Validation loss: 2.1540200761569444

Epoch: 6| Step: 8
Training loss: 2.0561037063598633
Validation loss: 2.155061426983085

Epoch: 6| Step: 9
Training loss: 2.1034278869628906
Validation loss: 2.1765023021287817

Epoch: 6| Step: 10
Training loss: 2.0618607997894287
Validation loss: 2.1444493762908445

Epoch: 6| Step: 11
Training loss: 1.8727142810821533
Validation loss: 2.141161059820524

Epoch: 6| Step: 12
Training loss: 1.5789800882339478
Validation loss: 2.161464851389649

Epoch: 6| Step: 13
Training loss: 1.853644847869873
Validation loss: 2.1257784879335793

Epoch: 246| Step: 0
Training loss: 1.0563063621520996
Validation loss: 2.128776788711548

Epoch: 6| Step: 1
Training loss: 3.069647789001465
Validation loss: 2.1137410094661098

Epoch: 6| Step: 2
Training loss: 1.6642251014709473
Validation loss: 2.108093620628439

Epoch: 6| Step: 3
Training loss: 2.315145254135132
Validation loss: 2.0897489645147838

Epoch: 6| Step: 4
Training loss: 1.7689876556396484
Validation loss: 2.086315587002744

Epoch: 6| Step: 5
Training loss: 1.7570465803146362
Validation loss: 2.0739572855734054

Epoch: 6| Step: 6
Training loss: 2.4930357933044434
Validation loss: 2.0610910179794475

Epoch: 6| Step: 7
Training loss: 1.7696373462677002
Validation loss: 2.0842034432195846

Epoch: 6| Step: 8
Training loss: 1.4529643058776855
Validation loss: 2.0684905385458343

Epoch: 6| Step: 9
Training loss: 2.212674140930176
Validation loss: 2.06575959215882

Epoch: 6| Step: 10
Training loss: 2.7562732696533203
Validation loss: 2.082599974447681

Epoch: 6| Step: 11
Training loss: 1.7200169563293457
Validation loss: 2.1025745561045985

Epoch: 6| Step: 12
Training loss: 1.7038578987121582
Validation loss: 2.074796312598772

Epoch: 6| Step: 13
Training loss: 2.643993854522705
Validation loss: 2.0749970738605787

Epoch: 247| Step: 0
Training loss: 2.3190579414367676
Validation loss: 2.1037903652396253

Epoch: 6| Step: 1
Training loss: 1.9104113578796387
Validation loss: 2.1052967681679675

Epoch: 6| Step: 2
Training loss: 1.7715003490447998
Validation loss: 2.10529685789539

Epoch: 6| Step: 3
Training loss: 2.6848883628845215
Validation loss: 2.1085916590946976

Epoch: 6| Step: 4
Training loss: 1.898829460144043
Validation loss: 2.114523651779339

Epoch: 6| Step: 5
Training loss: 2.0618205070495605
Validation loss: 2.121391886024065

Epoch: 6| Step: 6
Training loss: 1.333280324935913
Validation loss: 2.109841513377364

Epoch: 6| Step: 7
Training loss: 1.3878452777862549
Validation loss: 2.1040428479512534

Epoch: 6| Step: 8
Training loss: 2.1196131706237793
Validation loss: 2.119623386731712

Epoch: 6| Step: 9
Training loss: 2.308539867401123
Validation loss: 2.119101106479604

Epoch: 6| Step: 10
Training loss: 2.013406753540039
Validation loss: 2.128071223535845

Epoch: 6| Step: 11
Training loss: 2.171538829803467
Validation loss: 2.1206349852264568

Epoch: 6| Step: 12
Training loss: 1.626879096031189
Validation loss: 2.111256545589816

Epoch: 6| Step: 13
Training loss: 2.081265687942505
Validation loss: 2.1324303970542005

Epoch: 248| Step: 0
Training loss: 1.7969226837158203
Validation loss: 2.149036184433968

Epoch: 6| Step: 1
Training loss: 2.2041990756988525
Validation loss: 2.157461004872476

Epoch: 6| Step: 2
Training loss: 2.4553749561309814
Validation loss: 2.0849109964986003

Epoch: 6| Step: 3
Training loss: 2.7896342277526855
Validation loss: 2.1161405117281022

Epoch: 6| Step: 4
Training loss: 1.8846735954284668
Validation loss: 2.141541552800004

Epoch: 6| Step: 5
Training loss: 2.358170747756958
Validation loss: 2.126402501137026

Epoch: 6| Step: 6
Training loss: 1.8105725049972534
Validation loss: 2.1468672560107325

Epoch: 6| Step: 7
Training loss: 1.7643355131149292
Validation loss: 2.0921882583249

Epoch: 6| Step: 8
Training loss: 1.3549249172210693
Validation loss: 2.153524793604369

Epoch: 6| Step: 9
Training loss: 1.6441230773925781
Validation loss: 2.1244707953545356

Epoch: 6| Step: 10
Training loss: 2.170436382293701
Validation loss: 2.1174452663749777

Epoch: 6| Step: 11
Training loss: 1.3061926364898682
Validation loss: 2.087977017125776

Epoch: 6| Step: 12
Training loss: 1.9620676040649414
Validation loss: 2.0772471043371383

Epoch: 6| Step: 13
Training loss: 2.0147721767425537
Validation loss: 2.111224241154168

Epoch: 249| Step: 0
Training loss: 2.155874729156494
Validation loss: 2.104291862057101

Epoch: 6| Step: 1
Training loss: 1.8808543682098389
Validation loss: 2.1119596419795865

Epoch: 6| Step: 2
Training loss: 2.168415069580078
Validation loss: 2.1031388262266755

Epoch: 6| Step: 3
Training loss: 2.476829767227173
Validation loss: 2.1062964982883905

Epoch: 6| Step: 4
Training loss: 1.4622302055358887
Validation loss: 2.0952668484821113

Epoch: 6| Step: 5
Training loss: 2.5503950119018555
Validation loss: 2.1150528320702175

Epoch: 6| Step: 6
Training loss: 2.0551161766052246
Validation loss: 2.123844903002503

Epoch: 6| Step: 7
Training loss: 2.0573081970214844
Validation loss: 2.107891146854688

Epoch: 6| Step: 8
Training loss: 1.8430007696151733
Validation loss: 2.1365251130955194

Epoch: 6| Step: 9
Training loss: 2.478422164916992
Validation loss: 2.122663764543431

Epoch: 6| Step: 10
Training loss: 1.6335605382919312
Validation loss: 2.0865205564806537

Epoch: 6| Step: 11
Training loss: 1.5267162322998047
Validation loss: 2.1261537562134447

Epoch: 6| Step: 12
Training loss: 1.8190473318099976
Validation loss: 2.084676060625302

Epoch: 6| Step: 13
Training loss: 1.1113591194152832
Validation loss: 2.124857697435605

Epoch: 250| Step: 0
Training loss: 2.7421116828918457
Validation loss: 2.0819840379940566

Epoch: 6| Step: 1
Training loss: 2.0977745056152344
Validation loss: 2.0993583381816907

Epoch: 6| Step: 2
Training loss: 2.2435498237609863
Validation loss: 2.0547104804746565

Epoch: 6| Step: 3
Training loss: 1.5237315893173218
Validation loss: 2.1035487728734172

Epoch: 6| Step: 4
Training loss: 1.8692188262939453
Validation loss: 2.1108036643715313

Epoch: 6| Step: 5
Training loss: 1.575177550315857
Validation loss: 2.067376253425434

Epoch: 6| Step: 6
Training loss: 1.2716491222381592
Validation loss: 2.06665866092969

Epoch: 6| Step: 7
Training loss: 1.9844858646392822
Validation loss: 2.076337606676163

Epoch: 6| Step: 8
Training loss: 1.9621294736862183
Validation loss: 2.081606472692182

Epoch: 6| Step: 9
Training loss: 2.7749643325805664
Validation loss: 2.1058602320250643

Epoch: 6| Step: 10
Training loss: 1.8151309490203857
Validation loss: 2.082485624538955

Epoch: 6| Step: 11
Training loss: 1.9516493082046509
Validation loss: 2.110421505025638

Epoch: 6| Step: 12
Training loss: 2.2283225059509277
Validation loss: 2.082500526981969

Epoch: 6| Step: 13
Training loss: 1.7935125827789307
Validation loss: 2.1094773430978098

Epoch: 251| Step: 0
Training loss: 1.6593523025512695
Validation loss: 2.1045872895948348

Epoch: 6| Step: 1
Training loss: 1.426391839981079
Validation loss: 2.1165370659161638

Epoch: 6| Step: 2
Training loss: 2.091313362121582
Validation loss: 2.0907316759068477

Epoch: 6| Step: 3
Training loss: 2.290863513946533
Validation loss: 2.1329159108541345

Epoch: 6| Step: 4
Training loss: 1.768530011177063
Validation loss: 2.0895746433606712

Epoch: 6| Step: 5
Training loss: 2.7986202239990234
Validation loss: 2.1405117216930596

Epoch: 6| Step: 6
Training loss: 2.2134792804718018
Validation loss: 2.141079787285097

Epoch: 6| Step: 7
Training loss: 1.8980618715286255
Validation loss: 2.1154373102290656

Epoch: 6| Step: 8
Training loss: 1.7330796718597412
Validation loss: 2.12702715012335

Epoch: 6| Step: 9
Training loss: 2.086447238922119
Validation loss: 2.134521653575282

Epoch: 6| Step: 10
Training loss: 1.8703421354293823
Validation loss: 2.1104277923542965

Epoch: 6| Step: 11
Training loss: 1.790562629699707
Validation loss: 2.10075984462615

Epoch: 6| Step: 12
Training loss: 1.941138744354248
Validation loss: 2.0912871386415217

Epoch: 6| Step: 13
Training loss: 2.50384783744812
Validation loss: 2.0893570479526313

Epoch: 252| Step: 0
Training loss: 1.971463918685913
Validation loss: 2.0979338538262153

Epoch: 6| Step: 1
Training loss: 2.376507520675659
Validation loss: 2.135354898309195

Epoch: 6| Step: 2
Training loss: 1.8476276397705078
Validation loss: 2.125257181864913

Epoch: 6| Step: 3
Training loss: 1.439180612564087
Validation loss: 2.080870377120151

Epoch: 6| Step: 4
Training loss: 2.269011974334717
Validation loss: 2.084604319705758

Epoch: 6| Step: 5
Training loss: 1.9963788986206055
Validation loss: 2.1108775267037014

Epoch: 6| Step: 6
Training loss: 2.601198673248291
Validation loss: 2.1000964603116437

Epoch: 6| Step: 7
Training loss: 2.06961727142334
Validation loss: 2.0937115658995924

Epoch: 6| Step: 8
Training loss: 2.2448930740356445
Validation loss: 2.082094712923932

Epoch: 6| Step: 9
Training loss: 1.458784818649292
Validation loss: 2.093910426221868

Epoch: 6| Step: 10
Training loss: 1.3640103340148926
Validation loss: 2.0988280055343465

Epoch: 6| Step: 11
Training loss: 1.9687654972076416
Validation loss: 2.0858462907934703

Epoch: 6| Step: 12
Training loss: 1.9096245765686035
Validation loss: 2.111660485626549

Epoch: 6| Step: 13
Training loss: 2.2088420391082764
Validation loss: 2.0993072755875124

Epoch: 253| Step: 0
Training loss: 2.1310853958129883
Validation loss: 2.113331938302645

Epoch: 6| Step: 1
Training loss: 1.234450101852417
Validation loss: 2.1040576991214546

Epoch: 6| Step: 2
Training loss: 1.8151582479476929
Validation loss: 2.083876891802716

Epoch: 6| Step: 3
Training loss: 2.0030698776245117
Validation loss: 2.11132804424532

Epoch: 6| Step: 4
Training loss: 1.993443489074707
Validation loss: 2.116587613218574

Epoch: 6| Step: 5
Training loss: 1.6788263320922852
Validation loss: 2.0936823955146213

Epoch: 6| Step: 6
Training loss: 2.013103485107422
Validation loss: 2.1298370771510626

Epoch: 6| Step: 7
Training loss: 1.364621877670288
Validation loss: 2.08291523174573

Epoch: 6| Step: 8
Training loss: 2.74729061126709
Validation loss: 2.088926584489884

Epoch: 6| Step: 9
Training loss: 1.5767195224761963
Validation loss: 2.0902714370399393

Epoch: 6| Step: 10
Training loss: 2.168274402618408
Validation loss: 2.085610693500888

Epoch: 6| Step: 11
Training loss: 2.2134828567504883
Validation loss: 2.061753508865192

Epoch: 6| Step: 12
Training loss: 2.1457924842834473
Validation loss: 2.080576801812777

Epoch: 6| Step: 13
Training loss: 2.453883647918701
Validation loss: 2.094021536970651

Epoch: 254| Step: 0
Training loss: 0.8327183127403259
Validation loss: 2.1080328290180494

Epoch: 6| Step: 1
Training loss: 2.073568344116211
Validation loss: 2.1062211554537535

Epoch: 6| Step: 2
Training loss: 1.9453771114349365
Validation loss: 2.0967810435961654

Epoch: 6| Step: 3
Training loss: 1.7989554405212402
Validation loss: 2.077435060213971

Epoch: 6| Step: 4
Training loss: 2.1059176921844482
Validation loss: 2.084693747182046

Epoch: 6| Step: 5
Training loss: 2.5451712608337402
Validation loss: 2.1058850108936267

Epoch: 6| Step: 6
Training loss: 2.0823206901550293
Validation loss: 2.1274332833546463

Epoch: 6| Step: 7
Training loss: 2.181914806365967
Validation loss: 2.139460080413408

Epoch: 6| Step: 8
Training loss: 1.6416215896606445
Validation loss: 2.132474227618146

Epoch: 6| Step: 9
Training loss: 1.6995337009429932
Validation loss: 2.1380857139505367

Epoch: 6| Step: 10
Training loss: 1.9405474662780762
Validation loss: 2.12875545665782

Epoch: 6| Step: 11
Training loss: 2.8389477729797363
Validation loss: 2.1258088901478756

Epoch: 6| Step: 12
Training loss: 2.225019931793213
Validation loss: 2.1383823886994393

Epoch: 6| Step: 13
Training loss: 1.9032495021820068
Validation loss: 2.131344497844737

Epoch: 255| Step: 0
Training loss: 1.821075201034546
Validation loss: 2.144917536807317

Epoch: 6| Step: 1
Training loss: 2.29736328125
Validation loss: 2.102603268879716

Epoch: 6| Step: 2
Training loss: 2.2408642768859863
Validation loss: 2.1121669635977796

Epoch: 6| Step: 3
Training loss: 0.8412025570869446
Validation loss: 2.089292259626491

Epoch: 6| Step: 4
Training loss: 2.277942657470703
Validation loss: 2.09392850757927

Epoch: 6| Step: 5
Training loss: 2.090604066848755
Validation loss: 2.0895583629608154

Epoch: 6| Step: 6
Training loss: 1.8120620250701904
Validation loss: 2.0760561163707445

Epoch: 6| Step: 7
Training loss: 2.358079195022583
Validation loss: 2.105318146367227

Epoch: 6| Step: 8
Training loss: 1.9558364152908325
Validation loss: 2.0902054450845204

Epoch: 6| Step: 9
Training loss: 2.1100211143493652
Validation loss: 2.0544911482000865

Epoch: 6| Step: 10
Training loss: 1.8453192710876465
Validation loss: 2.101584533209442

Epoch: 6| Step: 11
Training loss: 2.1023917198181152
Validation loss: 2.0789668970210577

Epoch: 6| Step: 12
Training loss: 2.2463624477386475
Validation loss: 2.0804193917141167

Epoch: 6| Step: 13
Training loss: 1.2080779075622559
Validation loss: 2.080141798142464

Epoch: 256| Step: 0
Training loss: 2.0498499870300293
Validation loss: 2.099018314833282

Epoch: 6| Step: 1
Training loss: 2.2278480529785156
Validation loss: 2.100520710791311

Epoch: 6| Step: 2
Training loss: 1.9448895454406738
Validation loss: 2.085838125598046

Epoch: 6| Step: 3
Training loss: 1.4790798425674438
Validation loss: 2.0873452719821723

Epoch: 6| Step: 4
Training loss: 2.393524646759033
Validation loss: 2.080045871837165

Epoch: 6| Step: 5
Training loss: 2.3945350646972656
Validation loss: 2.1090857444270963

Epoch: 6| Step: 6
Training loss: 1.753288745880127
Validation loss: 2.079896543615608

Epoch: 6| Step: 7
Training loss: 1.545699119567871
Validation loss: 2.086419141420754

Epoch: 6| Step: 8
Training loss: 1.4218392372131348
Validation loss: 2.0625238380124493

Epoch: 6| Step: 9
Training loss: 2.837996244430542
Validation loss: 2.109775648322157

Epoch: 6| Step: 10
Training loss: 2.174156665802002
Validation loss: 2.076843107900312

Epoch: 6| Step: 11
Training loss: 2.16454815864563
Validation loss: 2.1078957819169566

Epoch: 6| Step: 12
Training loss: 1.3717912435531616
Validation loss: 2.0998660159367386

Epoch: 6| Step: 13
Training loss: 1.711609959602356
Validation loss: 2.1103869304862073

Epoch: 257| Step: 0
Training loss: 2.130976676940918
Validation loss: 2.115020498152702

Epoch: 6| Step: 1
Training loss: 1.6160088777542114
Validation loss: 2.109756545353961

Epoch: 6| Step: 2
Training loss: 1.4690823554992676
Validation loss: 2.1266278451488865

Epoch: 6| Step: 3
Training loss: 0.8823316097259521
Validation loss: 2.088344730356688

Epoch: 6| Step: 4
Training loss: 1.3482623100280762
Validation loss: 2.0989530522336244

Epoch: 6| Step: 5
Training loss: 2.2351715564727783
Validation loss: 2.0851173349606094

Epoch: 6| Step: 6
Training loss: 1.8490667343139648
Validation loss: 2.0964270137971446

Epoch: 6| Step: 7
Training loss: 2.6640944480895996
Validation loss: 2.116593578810333

Epoch: 6| Step: 8
Training loss: 2.029217481613159
Validation loss: 2.1016450338466193

Epoch: 6| Step: 9
Training loss: 2.89656925201416
Validation loss: 2.0895721027928014

Epoch: 6| Step: 10
Training loss: 1.83846116065979
Validation loss: 2.0943491228165163

Epoch: 6| Step: 11
Training loss: 1.9555065631866455
Validation loss: 2.063378505809333

Epoch: 6| Step: 12
Training loss: 2.3626952171325684
Validation loss: 2.1099612341132215

Epoch: 6| Step: 13
Training loss: 2.7452609539031982
Validation loss: 2.0978163019303353

Epoch: 258| Step: 0
Training loss: 1.1085938215255737
Validation loss: 2.1379636590198805

Epoch: 6| Step: 1
Training loss: 1.4148977994918823
Validation loss: 2.0933364027289936

Epoch: 6| Step: 2
Training loss: 2.629270076751709
Validation loss: 2.0843926065711567

Epoch: 6| Step: 3
Training loss: 2.104400157928467
Validation loss: 2.1067092175124795

Epoch: 6| Step: 4
Training loss: 2.1464343070983887
Validation loss: 2.0801789709316787

Epoch: 6| Step: 5
Training loss: 2.5594773292541504
Validation loss: 2.0990261339372203

Epoch: 6| Step: 6
Training loss: 1.4866169691085815
Validation loss: 2.110216257392719

Epoch: 6| Step: 7
Training loss: 1.5980669260025024
Validation loss: 2.1191579885380243

Epoch: 6| Step: 8
Training loss: 1.8193005323410034
Validation loss: 2.0988800012937157

Epoch: 6| Step: 9
Training loss: 2.115304470062256
Validation loss: 2.137700855091054

Epoch: 6| Step: 10
Training loss: 2.0745046138763428
Validation loss: 2.1099959009437153

Epoch: 6| Step: 11
Training loss: 2.9721338748931885
Validation loss: 2.1305300740785498

Epoch: 6| Step: 12
Training loss: 1.87679922580719
Validation loss: 2.100199378946776

Epoch: 6| Step: 13
Training loss: 1.3918923139572144
Validation loss: 2.130485878195814

Epoch: 259| Step: 0
Training loss: 2.458306312561035
Validation loss: 2.071623904730684

Epoch: 6| Step: 1
Training loss: 1.84708571434021
Validation loss: 2.1059877693012194

Epoch: 6| Step: 2
Training loss: 1.5320113897323608
Validation loss: 2.102714066864342

Epoch: 6| Step: 3
Training loss: 2.222611427307129
Validation loss: 2.088901132665655

Epoch: 6| Step: 4
Training loss: 2.028636932373047
Validation loss: 2.0760446517698226

Epoch: 6| Step: 5
Training loss: 1.5653162002563477
Validation loss: 2.1019792236307615

Epoch: 6| Step: 6
Training loss: 1.3748828172683716
Validation loss: 2.0848273308046403

Epoch: 6| Step: 7
Training loss: 1.9434126615524292
Validation loss: 2.096721597897109

Epoch: 6| Step: 8
Training loss: 1.724870204925537
Validation loss: 2.0762776585035425

Epoch: 6| Step: 9
Training loss: 2.4058732986450195
Validation loss: 2.075651499532884

Epoch: 6| Step: 10
Training loss: 2.036663770675659
Validation loss: 2.1253034863420712

Epoch: 6| Step: 11
Training loss: 2.0200083255767822
Validation loss: 2.07774124094235

Epoch: 6| Step: 12
Training loss: 2.262270450592041
Validation loss: 2.10504573904058

Epoch: 6| Step: 13
Training loss: 2.07448148727417
Validation loss: 2.0769062029418124

Epoch: 260| Step: 0
Training loss: 2.1086878776550293
Validation loss: 2.11362386006181

Epoch: 6| Step: 1
Training loss: 2.394099712371826
Validation loss: 2.119705525777673

Epoch: 6| Step: 2
Training loss: 1.6868892908096313
Validation loss: 2.0995956595226

Epoch: 6| Step: 3
Training loss: 1.9704549312591553
Validation loss: 2.0864528802133377

Epoch: 6| Step: 4
Training loss: 2.146148204803467
Validation loss: 2.084072915456628

Epoch: 6| Step: 5
Training loss: 1.8001353740692139
Validation loss: 2.132186682634456

Epoch: 6| Step: 6
Training loss: 1.7595396041870117
Validation loss: 2.1155729550187305

Epoch: 6| Step: 7
Training loss: 2.487429141998291
Validation loss: 2.1324399773792555

Epoch: 6| Step: 8
Training loss: 2.282933235168457
Validation loss: 2.1164016210904686

Epoch: 6| Step: 9
Training loss: 1.4544076919555664
Validation loss: 2.120733534136126

Epoch: 6| Step: 10
Training loss: 1.779296636581421
Validation loss: 2.090357385655885

Epoch: 6| Step: 11
Training loss: 1.5037803649902344
Validation loss: 2.0825650371531004

Epoch: 6| Step: 12
Training loss: 1.8947372436523438
Validation loss: 2.106159071768484

Epoch: 6| Step: 13
Training loss: 2.0482077598571777
Validation loss: 2.07855849881326

Epoch: 261| Step: 0
Training loss: 1.8791747093200684
Validation loss: 2.0919100930613856

Epoch: 6| Step: 1
Training loss: 1.8769874572753906
Validation loss: 2.0614215712393484

Epoch: 6| Step: 2
Training loss: 1.6495251655578613
Validation loss: 2.0829029365252425

Epoch: 6| Step: 3
Training loss: 1.8076642751693726
Validation loss: 2.090247549036498

Epoch: 6| Step: 4
Training loss: 1.2990403175354004
Validation loss: 2.110465649635561

Epoch: 6| Step: 5
Training loss: 2.1925296783447266
Validation loss: 2.1140990385445217

Epoch: 6| Step: 6
Training loss: 2.216156482696533
Validation loss: 2.1093315078366186

Epoch: 6| Step: 7
Training loss: 2.8492507934570312
Validation loss: 2.12577127128519

Epoch: 6| Step: 8
Training loss: 1.9855996370315552
Validation loss: 2.101467301768641

Epoch: 6| Step: 9
Training loss: 2.595214366912842
Validation loss: 2.0916648346890687

Epoch: 6| Step: 10
Training loss: 1.8233532905578613
Validation loss: 2.1033587276294665

Epoch: 6| Step: 11
Training loss: 1.829850673675537
Validation loss: 2.0972801562278502

Epoch: 6| Step: 12
Training loss: 1.917271375656128
Validation loss: 2.1126104093367055

Epoch: 6| Step: 13
Training loss: 1.3465394973754883
Validation loss: 2.116985890173143

Epoch: 262| Step: 0
Training loss: 2.260859489440918
Validation loss: 2.090988359143657

Epoch: 6| Step: 1
Training loss: 2.3563835620880127
Validation loss: 2.114323869828255

Epoch: 6| Step: 2
Training loss: 1.9072949886322021
Validation loss: 2.093379447537084

Epoch: 6| Step: 3
Training loss: 2.155747175216675
Validation loss: 2.1068294022672918

Epoch: 6| Step: 4
Training loss: 2.360337734222412
Validation loss: 2.0818686049471617

Epoch: 6| Step: 5
Training loss: 1.4998970031738281
Validation loss: 2.092218816921275

Epoch: 6| Step: 6
Training loss: 0.8023250102996826
Validation loss: 2.091144754040626

Epoch: 6| Step: 7
Training loss: 1.168076992034912
Validation loss: 2.1002851250351116

Epoch: 6| Step: 8
Training loss: 1.6012442111968994
Validation loss: 2.118758024707917

Epoch: 6| Step: 9
Training loss: 2.4995150566101074
Validation loss: 2.0684493972409155

Epoch: 6| Step: 10
Training loss: 1.9872952699661255
Validation loss: 2.068547769259381

Epoch: 6| Step: 11
Training loss: 2.536288261413574
Validation loss: 2.074639331909918

Epoch: 6| Step: 12
Training loss: 2.36720871925354
Validation loss: 2.081963945460576

Epoch: 6| Step: 13
Training loss: 1.349509358406067
Validation loss: 2.0913585616696264

Epoch: 263| Step: 0
Training loss: 1.7184207439422607
Validation loss: 2.1092079019033783

Epoch: 6| Step: 1
Training loss: 2.050624370574951
Validation loss: 2.0882285333448842

Epoch: 6| Step: 2
Training loss: 2.2726237773895264
Validation loss: 2.1011251941803963

Epoch: 6| Step: 3
Training loss: 1.566685676574707
Validation loss: 2.0910178371655044

Epoch: 6| Step: 4
Training loss: 2.3765602111816406
Validation loss: 2.099546492740672

Epoch: 6| Step: 5
Training loss: 2.220231056213379
Validation loss: 2.1257129458970923

Epoch: 6| Step: 6
Training loss: 1.593264102935791
Validation loss: 2.103214153679468

Epoch: 6| Step: 7
Training loss: 2.170464515686035
Validation loss: 2.1053522966241323

Epoch: 6| Step: 8
Training loss: 1.9965237379074097
Validation loss: 2.0915589717126664

Epoch: 6| Step: 9
Training loss: 2.3122801780700684
Validation loss: 2.105384211386404

Epoch: 6| Step: 10
Training loss: 1.5529670715332031
Validation loss: 2.1418834117151078

Epoch: 6| Step: 11
Training loss: 1.6152502298355103
Validation loss: 2.1519675677822483

Epoch: 6| Step: 12
Training loss: 1.7379661798477173
Validation loss: 2.1527377443928875

Epoch: 6| Step: 13
Training loss: 2.2368035316467285
Validation loss: 2.1278276828027542

Epoch: 264| Step: 0
Training loss: 1.8432480096817017
Validation loss: 2.1172013385321504

Epoch: 6| Step: 1
Training loss: 1.7080148458480835
Validation loss: 2.0973224703983595

Epoch: 6| Step: 2
Training loss: 1.8434014320373535
Validation loss: 2.0919987129908737

Epoch: 6| Step: 3
Training loss: 1.9011224508285522
Validation loss: 2.1107050936709166

Epoch: 6| Step: 4
Training loss: 1.5410116910934448
Validation loss: 2.1088916665764263

Epoch: 6| Step: 5
Training loss: 1.6014087200164795
Validation loss: 2.098545417990736

Epoch: 6| Step: 6
Training loss: 2.767587184906006
Validation loss: 2.079469034748693

Epoch: 6| Step: 7
Training loss: 1.7132527828216553
Validation loss: 2.0940610567728677

Epoch: 6| Step: 8
Training loss: 2.0939574241638184
Validation loss: 2.0922286164376045

Epoch: 6| Step: 9
Training loss: 2.3913097381591797
Validation loss: 2.0897691454938663

Epoch: 6| Step: 10
Training loss: 1.5424692630767822
Validation loss: 2.0920160303833666

Epoch: 6| Step: 11
Training loss: 2.65897798538208
Validation loss: 2.0916288591200307

Epoch: 6| Step: 12
Training loss: 2.188331365585327
Validation loss: 2.10584621531989

Epoch: 6| Step: 13
Training loss: 1.1634881496429443
Validation loss: 2.0832247170068885

Epoch: 265| Step: 0
Training loss: 1.9488520622253418
Validation loss: 2.0931990633728685

Epoch: 6| Step: 1
Training loss: 1.664543867111206
Validation loss: 2.098270764914892

Epoch: 6| Step: 2
Training loss: 1.849968433380127
Validation loss: 2.071908635477866

Epoch: 6| Step: 3
Training loss: 2.1106433868408203
Validation loss: 2.1016269755619827

Epoch: 6| Step: 4
Training loss: 2.3471384048461914
Validation loss: 2.0917867768195366

Epoch: 6| Step: 5
Training loss: 1.4860610961914062
Validation loss: 2.1089584622331845

Epoch: 6| Step: 6
Training loss: 1.3262555599212646
Validation loss: 2.0676961098947833

Epoch: 6| Step: 7
Training loss: 2.1488983631134033
Validation loss: 2.066814225207093

Epoch: 6| Step: 8
Training loss: 1.482344627380371
Validation loss: 2.1203052843770673

Epoch: 6| Step: 9
Training loss: 1.7066643238067627
Validation loss: 2.0623403108248146

Epoch: 6| Step: 10
Training loss: 1.9352490901947021
Validation loss: 2.0743433480621665

Epoch: 6| Step: 11
Training loss: 2.5047550201416016
Validation loss: 2.0673569171659407

Epoch: 6| Step: 12
Training loss: 2.0168802738189697
Validation loss: 2.094425698762299

Epoch: 6| Step: 13
Training loss: 2.645777702331543
Validation loss: 2.0685820605165217

Epoch: 266| Step: 0
Training loss: 2.425967216491699
Validation loss: 2.086431490477695

Epoch: 6| Step: 1
Training loss: 1.278700351715088
Validation loss: 2.1003765726602204

Epoch: 6| Step: 2
Training loss: 2.3584647178649902
Validation loss: 2.108415613892258

Epoch: 6| Step: 3
Training loss: 1.735586166381836
Validation loss: 2.0966948975798902

Epoch: 6| Step: 4
Training loss: 2.5637617111206055
Validation loss: 2.049685003936932

Epoch: 6| Step: 5
Training loss: 1.8289881944656372
Validation loss: 2.1277644608610418

Epoch: 6| Step: 6
Training loss: 1.9080548286437988
Validation loss: 2.100414870887674

Epoch: 6| Step: 7
Training loss: 2.221442699432373
Validation loss: 2.089446635656459

Epoch: 6| Step: 8
Training loss: 1.7172490358352661
Validation loss: 2.102720154229031

Epoch: 6| Step: 9
Training loss: 1.7827372550964355
Validation loss: 2.08708579181343

Epoch: 6| Step: 10
Training loss: 2.1427953243255615
Validation loss: 2.069870869318644

Epoch: 6| Step: 11
Training loss: 1.958791732788086
Validation loss: 2.100437730871221

Epoch: 6| Step: 12
Training loss: 1.9488497972488403
Validation loss: 2.102303445980113

Epoch: 6| Step: 13
Training loss: 1.359011173248291
Validation loss: 2.0731349811759046

Epoch: 267| Step: 0
Training loss: 2.4555630683898926
Validation loss: 2.1210896494568034

Epoch: 6| Step: 1
Training loss: 1.6789324283599854
Validation loss: 2.0849154585151264

Epoch: 6| Step: 2
Training loss: 1.4308894872665405
Validation loss: 2.104280050082873

Epoch: 6| Step: 3
Training loss: 1.417808175086975
Validation loss: 2.1153528972338607

Epoch: 6| Step: 4
Training loss: 2.595870018005371
Validation loss: 2.096128124062733

Epoch: 6| Step: 5
Training loss: 2.0723466873168945
Validation loss: 2.0961748810224634

Epoch: 6| Step: 6
Training loss: 2.1238110065460205
Validation loss: 2.097040630155994

Epoch: 6| Step: 7
Training loss: 2.304381847381592
Validation loss: 2.103200702257054

Epoch: 6| Step: 8
Training loss: 1.8532054424285889
Validation loss: 2.112170011766495

Epoch: 6| Step: 9
Training loss: 1.8077421188354492
Validation loss: 2.081611203890975

Epoch: 6| Step: 10
Training loss: 1.612989902496338
Validation loss: 2.1089489383082234

Epoch: 6| Step: 11
Training loss: 2.466723918914795
Validation loss: 2.130289921196558

Epoch: 6| Step: 12
Training loss: 1.6102666854858398
Validation loss: 2.110664895785752

Epoch: 6| Step: 13
Training loss: 1.7888249158859253
Validation loss: 2.103423046809371

Epoch: 268| Step: 0
Training loss: 2.364759922027588
Validation loss: 2.098653562607304

Epoch: 6| Step: 1
Training loss: 1.7538329362869263
Validation loss: 2.088974383569533

Epoch: 6| Step: 2
Training loss: 1.4788053035736084
Validation loss: 2.1253484910534275

Epoch: 6| Step: 3
Training loss: 1.9941867589950562
Validation loss: 2.103076051640254

Epoch: 6| Step: 4
Training loss: 1.8813612461090088
Validation loss: 2.088437425192966

Epoch: 6| Step: 5
Training loss: 2.5089073181152344
Validation loss: 2.106459899615216

Epoch: 6| Step: 6
Training loss: 1.8041833639144897
Validation loss: 2.124422465601275

Epoch: 6| Step: 7
Training loss: 2.0741701126098633
Validation loss: 2.0871928866191576

Epoch: 6| Step: 8
Training loss: 1.7681405544281006
Validation loss: 2.112626052671863

Epoch: 6| Step: 9
Training loss: 1.8549596071243286
Validation loss: 2.0859049674003356

Epoch: 6| Step: 10
Training loss: 1.8800275325775146
Validation loss: 2.117775329979517

Epoch: 6| Step: 11
Training loss: 2.251688003540039
Validation loss: 2.107022036788284

Epoch: 6| Step: 12
Training loss: 1.8681046962738037
Validation loss: 2.104418428995276

Epoch: 6| Step: 13
Training loss: 1.5807234048843384
Validation loss: 2.110494634156586

Epoch: 269| Step: 0
Training loss: 1.647776484489441
Validation loss: 2.113715705051217

Epoch: 6| Step: 1
Training loss: 2.1675217151641846
Validation loss: 2.1020920661187943

Epoch: 6| Step: 2
Training loss: 1.8083542585372925
Validation loss: 2.138417657985482

Epoch: 6| Step: 3
Training loss: 1.4588145017623901
Validation loss: 2.130082872606093

Epoch: 6| Step: 4
Training loss: 1.8855271339416504
Validation loss: 2.1212074307985205

Epoch: 6| Step: 5
Training loss: 2.575705051422119
Validation loss: 2.113695457417478

Epoch: 6| Step: 6
Training loss: 2.5721819400787354
Validation loss: 2.1389057841352237

Epoch: 6| Step: 7
Training loss: 1.7310426235198975
Validation loss: 2.1242131122978787

Epoch: 6| Step: 8
Training loss: 2.473505735397339
Validation loss: 2.1367943363804973

Epoch: 6| Step: 9
Training loss: 1.8231302499771118
Validation loss: 2.117878075568907

Epoch: 6| Step: 10
Training loss: 1.7483680248260498
Validation loss: 2.1231591393870692

Epoch: 6| Step: 11
Training loss: 1.6351059675216675
Validation loss: 2.1150010196111535

Epoch: 6| Step: 12
Training loss: 1.6282718181610107
Validation loss: 2.1096024333789782

Epoch: 6| Step: 13
Training loss: 1.8963792324066162
Validation loss: 2.1069610541866672

Epoch: 270| Step: 0
Training loss: 1.971861720085144
Validation loss: 2.0939567473626908

Epoch: 6| Step: 1
Training loss: 2.4380171298980713
Validation loss: 2.076846506005974

Epoch: 6| Step: 2
Training loss: 1.7117626667022705
Validation loss: 2.0958244095566454

Epoch: 6| Step: 3
Training loss: 1.745849609375
Validation loss: 2.0940594544974704

Epoch: 6| Step: 4
Training loss: 1.784284234046936
Validation loss: 2.124852752172819

Epoch: 6| Step: 5
Training loss: 1.6792163848876953
Validation loss: 2.096784217383272

Epoch: 6| Step: 6
Training loss: 1.6634700298309326
Validation loss: 2.0924670375803465

Epoch: 6| Step: 7
Training loss: 1.7280473709106445
Validation loss: 2.0830730661269157

Epoch: 6| Step: 8
Training loss: 2.8077969551086426
Validation loss: 2.0668132805055186

Epoch: 6| Step: 9
Training loss: 1.5397663116455078
Validation loss: 2.08786573461307

Epoch: 6| Step: 10
Training loss: 1.7270097732543945
Validation loss: 2.107464828798848

Epoch: 6| Step: 11
Training loss: 1.7510968446731567
Validation loss: 2.0692398086670907

Epoch: 6| Step: 12
Training loss: 2.475160598754883
Validation loss: 2.0544092732091106

Epoch: 6| Step: 13
Training loss: 2.083648204803467
Validation loss: 2.0816737631315827

Epoch: 271| Step: 0
Training loss: 1.7512729167938232
Validation loss: 2.091977968010851

Epoch: 6| Step: 1
Training loss: 1.5440772771835327
Validation loss: 2.088718996253065

Epoch: 6| Step: 2
Training loss: 1.3301481008529663
Validation loss: 2.114213566626272

Epoch: 6| Step: 3
Training loss: 2.4363913536071777
Validation loss: 2.0577587401995094

Epoch: 6| Step: 4
Training loss: 2.222996234893799
Validation loss: 2.0761053151981805

Epoch: 6| Step: 5
Training loss: 1.9062999486923218
Validation loss: 2.1070207536861463

Epoch: 6| Step: 6
Training loss: 1.60915207862854
Validation loss: 2.1502314459893013

Epoch: 6| Step: 7
Training loss: 1.6855779886245728
Validation loss: 2.083213072951122

Epoch: 6| Step: 8
Training loss: 2.0061309337615967
Validation loss: 2.1217397336036927

Epoch: 6| Step: 9
Training loss: 2.3901820182800293
Validation loss: 2.128686067878559

Epoch: 6| Step: 10
Training loss: 2.2026607990264893
Validation loss: 2.0911561635232743

Epoch: 6| Step: 11
Training loss: 2.09175968170166
Validation loss: 2.0985580516117874

Epoch: 6| Step: 12
Training loss: 2.109469175338745
Validation loss: 2.1022198418135285

Epoch: 6| Step: 13
Training loss: 1.621870517730713
Validation loss: 2.1137194671938495

Epoch: 272| Step: 0
Training loss: 2.0328683853149414
Validation loss: 2.0970358797298965

Epoch: 6| Step: 1
Training loss: 2.053441047668457
Validation loss: 2.0911041946821314

Epoch: 6| Step: 2
Training loss: 1.4287099838256836
Validation loss: 2.1228867743604924

Epoch: 6| Step: 3
Training loss: 1.3501909971237183
Validation loss: 2.1299738550698883

Epoch: 6| Step: 4
Training loss: 1.5802066326141357
Validation loss: 2.110852397898192

Epoch: 6| Step: 5
Training loss: 2.024130344390869
Validation loss: 2.1090046795465613

Epoch: 6| Step: 6
Training loss: 2.513099193572998
Validation loss: 2.1578146770436275

Epoch: 6| Step: 7
Training loss: 1.9748740196228027
Validation loss: 2.1194151319483274

Epoch: 6| Step: 8
Training loss: 2.342935800552368
Validation loss: 2.121010293242752

Epoch: 6| Step: 9
Training loss: 1.2851475477218628
Validation loss: 2.130368822364397

Epoch: 6| Step: 10
Training loss: 2.189415454864502
Validation loss: 2.113154839443904

Epoch: 6| Step: 11
Training loss: 1.6476531028747559
Validation loss: 2.10392306312438

Epoch: 6| Step: 12
Training loss: 2.0512850284576416
Validation loss: 2.0939263028483235

Epoch: 6| Step: 13
Training loss: 2.957155704498291
Validation loss: 2.1049629513935377

Epoch: 273| Step: 0
Training loss: 1.9755899906158447
Validation loss: 2.0777780535400554

Epoch: 6| Step: 1
Training loss: 1.9738339185714722
Validation loss: 2.1059297336045133

Epoch: 6| Step: 2
Training loss: 1.8092124462127686
Validation loss: 2.088093379492401

Epoch: 6| Step: 3
Training loss: 2.5304641723632812
Validation loss: 2.121168759561354

Epoch: 6| Step: 4
Training loss: 1.7299528121948242
Validation loss: 2.1149883475354923

Epoch: 6| Step: 5
Training loss: 1.457688570022583
Validation loss: 2.084056870911711

Epoch: 6| Step: 6
Training loss: 2.2541258335113525
Validation loss: 2.0896445820408482

Epoch: 6| Step: 7
Training loss: 1.6054832935333252
Validation loss: 2.0710443809468257

Epoch: 6| Step: 8
Training loss: 1.7027854919433594
Validation loss: 2.1088806967581473

Epoch: 6| Step: 9
Training loss: 1.6451809406280518
Validation loss: 2.0968580950972853

Epoch: 6| Step: 10
Training loss: 2.132791042327881
Validation loss: 2.111450595240439

Epoch: 6| Step: 11
Training loss: 2.13435959815979
Validation loss: 2.1113112613719

Epoch: 6| Step: 12
Training loss: 1.7358381748199463
Validation loss: 2.114193865047988

Epoch: 6| Step: 13
Training loss: 2.471989154815674
Validation loss: 2.0995093173878168

Epoch: 274| Step: 0
Training loss: 2.036860466003418
Validation loss: 2.1142235084246566

Epoch: 6| Step: 1
Training loss: 1.528649091720581
Validation loss: 2.1053770101198586

Epoch: 6| Step: 2
Training loss: 1.8011445999145508
Validation loss: 2.099729343127179

Epoch: 6| Step: 3
Training loss: 2.0116422176361084
Validation loss: 2.101805161404353

Epoch: 6| Step: 4
Training loss: 2.2103915214538574
Validation loss: 2.1084673866148917

Epoch: 6| Step: 5
Training loss: 1.7698407173156738
Validation loss: 2.0841611649400447

Epoch: 6| Step: 6
Training loss: 1.2502976655960083
Validation loss: 2.1090226634856193

Epoch: 6| Step: 7
Training loss: 1.9783244132995605
Validation loss: 2.085188070933024

Epoch: 6| Step: 8
Training loss: 1.497737169265747
Validation loss: 2.1110241002933954

Epoch: 6| Step: 9
Training loss: 2.563159942626953
Validation loss: 2.1107127294745496

Epoch: 6| Step: 10
Training loss: 2.654872417449951
Validation loss: 2.120637555276194

Epoch: 6| Step: 11
Training loss: 2.0816450119018555
Validation loss: 2.0751540635221746

Epoch: 6| Step: 12
Training loss: 1.977771520614624
Validation loss: 2.0962961437881633

Epoch: 6| Step: 13
Training loss: 1.215123176574707
Validation loss: 2.078339269084315

Epoch: 275| Step: 0
Training loss: 1.3129544258117676
Validation loss: 2.091318617584885

Epoch: 6| Step: 1
Training loss: 2.285766124725342
Validation loss: 2.0842428758580196

Epoch: 6| Step: 2
Training loss: 1.6351337432861328
Validation loss: 2.089596691951957

Epoch: 6| Step: 3
Training loss: 2.297651767730713
Validation loss: 2.0713026754317747

Epoch: 6| Step: 4
Training loss: 1.8514602184295654
Validation loss: 2.1058084631478913

Epoch: 6| Step: 5
Training loss: 1.6865407228469849
Validation loss: 2.0704221058917303

Epoch: 6| Step: 6
Training loss: 1.7448465824127197
Validation loss: 2.139603614807129

Epoch: 6| Step: 7
Training loss: 2.4784023761749268
Validation loss: 2.077334378355293

Epoch: 6| Step: 8
Training loss: 1.9790916442871094
Validation loss: 2.1076538357683408

Epoch: 6| Step: 9
Training loss: 2.273226737976074
Validation loss: 2.1069251568086687

Epoch: 6| Step: 10
Training loss: 1.9458087682724
Validation loss: 2.088996374478904

Epoch: 6| Step: 11
Training loss: 1.550761103630066
Validation loss: 2.1003509362538657

Epoch: 6| Step: 12
Training loss: 2.040555477142334
Validation loss: 2.1323204527619066

Epoch: 6| Step: 13
Training loss: 2.1039533615112305
Validation loss: 2.1037021362653343

Epoch: 276| Step: 0
Training loss: 2.2682065963745117
Validation loss: 2.1181356855618056

Epoch: 6| Step: 1
Training loss: 1.5140583515167236
Validation loss: 2.1250296638857935

Epoch: 6| Step: 2
Training loss: 2.3855128288269043
Validation loss: 2.1078593166925574

Epoch: 6| Step: 3
Training loss: 2.0817041397094727
Validation loss: 2.10758372019696

Epoch: 6| Step: 4
Training loss: 1.7204995155334473
Validation loss: 2.0915320381041496

Epoch: 6| Step: 5
Training loss: 2.3473143577575684
Validation loss: 2.131768762424428

Epoch: 6| Step: 6
Training loss: 2.5337181091308594
Validation loss: 2.1483054750709125

Epoch: 6| Step: 7
Training loss: 2.235689878463745
Validation loss: 2.126382784176898

Epoch: 6| Step: 8
Training loss: 1.7831809520721436
Validation loss: 2.1339706246570875

Epoch: 6| Step: 9
Training loss: 1.308859944343567
Validation loss: 2.1504980005243772

Epoch: 6| Step: 10
Training loss: 1.582533836364746
Validation loss: 2.1178132308426725

Epoch: 6| Step: 11
Training loss: 1.949711799621582
Validation loss: 2.113176599625618

Epoch: 6| Step: 12
Training loss: 1.6632263660430908
Validation loss: 2.1129545998829666

Epoch: 6| Step: 13
Training loss: 1.6138434410095215
Validation loss: 2.092497856386246

Epoch: 277| Step: 0
Training loss: 1.604062795639038
Validation loss: 2.13516144598684

Epoch: 6| Step: 1
Training loss: 1.2213844060897827
Validation loss: 2.116107770191726

Epoch: 6| Step: 2
Training loss: 1.8732621669769287
Validation loss: 2.0921566947813957

Epoch: 6| Step: 3
Training loss: 1.9077118635177612
Validation loss: 2.140466267062772

Epoch: 6| Step: 4
Training loss: 3.353241443634033
Validation loss: 2.101083747802242

Epoch: 6| Step: 5
Training loss: 1.6630971431732178
Validation loss: 2.123242267998316

Epoch: 6| Step: 6
Training loss: 1.264216661453247
Validation loss: 2.082112127734769

Epoch: 6| Step: 7
Training loss: 2.1691789627075195
Validation loss: 2.080977750080888

Epoch: 6| Step: 8
Training loss: 2.085192918777466
Validation loss: 2.103756179091751

Epoch: 6| Step: 9
Training loss: 1.8656195402145386
Validation loss: 2.13647186627952

Epoch: 6| Step: 10
Training loss: 1.8675687313079834
Validation loss: 2.092146065927321

Epoch: 6| Step: 11
Training loss: 1.5429543256759644
Validation loss: 2.1018486651041175

Epoch: 6| Step: 12
Training loss: 2.2424633502960205
Validation loss: 2.1237010725082888

Epoch: 6| Step: 13
Training loss: 2.1874923706054688
Validation loss: 2.0792114914104505

Epoch: 278| Step: 0
Training loss: 2.3117008209228516
Validation loss: 2.079261302947998

Epoch: 6| Step: 1
Training loss: 1.7958933115005493
Validation loss: 2.10481588045756

Epoch: 6| Step: 2
Training loss: 2.2753429412841797
Validation loss: 2.088173213825431

Epoch: 6| Step: 3
Training loss: 1.9578577280044556
Validation loss: 2.0484637034836637

Epoch: 6| Step: 4
Training loss: 1.552459955215454
Validation loss: 2.0997843896189043

Epoch: 6| Step: 5
Training loss: 2.137603282928467
Validation loss: 2.0733367755848873

Epoch: 6| Step: 6
Training loss: 1.5223824977874756
Validation loss: 2.114366676217766

Epoch: 6| Step: 7
Training loss: 1.7120040655136108
Validation loss: 2.083481341279963

Epoch: 6| Step: 8
Training loss: 2.049440622329712
Validation loss: 2.0688717852356615

Epoch: 6| Step: 9
Training loss: 1.4397891759872437
Validation loss: 2.0736748403118503

Epoch: 6| Step: 10
Training loss: 2.2161591053009033
Validation loss: 2.1052432008968887

Epoch: 6| Step: 11
Training loss: 2.020150661468506
Validation loss: 2.0681706564400786

Epoch: 6| Step: 12
Training loss: 2.0117673873901367
Validation loss: 2.106416110069521

Epoch: 6| Step: 13
Training loss: 2.212496042251587
Validation loss: 2.0790655536036335

Epoch: 279| Step: 0
Training loss: 2.4569010734558105
Validation loss: 2.0661823390632548

Epoch: 6| Step: 1
Training loss: 2.251776695251465
Validation loss: 2.111640258501935

Epoch: 6| Step: 2
Training loss: 1.7165961265563965
Validation loss: 2.114051462501608

Epoch: 6| Step: 3
Training loss: 1.6818206310272217
Validation loss: 2.071536765303663

Epoch: 6| Step: 4
Training loss: 1.8026031255722046
Validation loss: 2.112535935576244

Epoch: 6| Step: 5
Training loss: 1.507090449333191
Validation loss: 2.097752568542316

Epoch: 6| Step: 6
Training loss: 1.1780831813812256
Validation loss: 2.1171140170866445

Epoch: 6| Step: 7
Training loss: 2.938075304031372
Validation loss: 2.1303351104900403

Epoch: 6| Step: 8
Training loss: 1.879805326461792
Validation loss: 2.108195181815855

Epoch: 6| Step: 9
Training loss: 1.8380227088928223
Validation loss: 2.148034828965382

Epoch: 6| Step: 10
Training loss: 2.1323282718658447
Validation loss: 2.121217063678208

Epoch: 6| Step: 11
Training loss: 1.385160207748413
Validation loss: 2.136852183649617

Epoch: 6| Step: 12
Training loss: 1.9758316278457642
Validation loss: 2.1228735780203216

Epoch: 6| Step: 13
Training loss: 2.2444121837615967
Validation loss: 2.1094745948750484

Epoch: 280| Step: 0
Training loss: 2.755702495574951
Validation loss: 2.0995786292578584

Epoch: 6| Step: 1
Training loss: 1.9076673984527588
Validation loss: 2.0992405158217236

Epoch: 6| Step: 2
Training loss: 1.9439748525619507
Validation loss: 2.065465582314358

Epoch: 6| Step: 3
Training loss: 2.025489330291748
Validation loss: 2.0893328600032355

Epoch: 6| Step: 4
Training loss: 1.4122769832611084
Validation loss: 2.0985675396457797

Epoch: 6| Step: 5
Training loss: 1.6606035232543945
Validation loss: 2.0986917211163427

Epoch: 6| Step: 6
Training loss: 2.8315272331237793
Validation loss: 2.07249052422021

Epoch: 6| Step: 7
Training loss: 1.8202886581420898
Validation loss: 2.078421938803888

Epoch: 6| Step: 8
Training loss: 0.8408372402191162
Validation loss: 2.0983561341480543

Epoch: 6| Step: 9
Training loss: 1.4180546998977661
Validation loss: 2.0816688178687968

Epoch: 6| Step: 10
Training loss: 3.0107569694519043
Validation loss: 2.107323638854488

Epoch: 6| Step: 11
Training loss: 1.61971116065979
Validation loss: 2.07604972393282

Epoch: 6| Step: 12
Training loss: 1.5050116777420044
Validation loss: 2.0976351409830074

Epoch: 6| Step: 13
Training loss: 1.639945387840271
Validation loss: 2.1060744562456684

Epoch: 281| Step: 0
Training loss: 1.5548715591430664
Validation loss: 2.1099878139393304

Epoch: 6| Step: 1
Training loss: 2.493042469024658
Validation loss: 2.093609743220832

Epoch: 6| Step: 2
Training loss: 1.6156611442565918
Validation loss: 2.112551071310556

Epoch: 6| Step: 3
Training loss: 2.661085605621338
Validation loss: 2.1190139734616844

Epoch: 6| Step: 4
Training loss: 2.1887149810791016
Validation loss: 2.0654100679582164

Epoch: 6| Step: 5
Training loss: 1.8905863761901855
Validation loss: 2.0915990952522523

Epoch: 6| Step: 6
Training loss: 1.7219111919403076
Validation loss: 2.098418394724528

Epoch: 6| Step: 7
Training loss: 1.7241935729980469
Validation loss: 2.0833444351791055

Epoch: 6| Step: 8
Training loss: 2.5914368629455566
Validation loss: 2.0806234139268116

Epoch: 6| Step: 9
Training loss: 1.5220363140106201
Validation loss: 2.108817256906981

Epoch: 6| Step: 10
Training loss: 1.7691751718521118
Validation loss: 2.0999070572596725

Epoch: 6| Step: 11
Training loss: 1.6384413242340088
Validation loss: 2.1226053545551915

Epoch: 6| Step: 12
Training loss: 1.772397756576538
Validation loss: 2.100316063050301

Epoch: 6| Step: 13
Training loss: 1.7332913875579834
Validation loss: 2.1050043208624727

Epoch: 282| Step: 0
Training loss: 1.983171820640564
Validation loss: 2.1093956808890066

Epoch: 6| Step: 1
Training loss: 1.4172884225845337
Validation loss: 2.115026411189828

Epoch: 6| Step: 2
Training loss: 2.0711402893066406
Validation loss: 2.1151389639864684

Epoch: 6| Step: 3
Training loss: 0.9365883469581604
Validation loss: 2.1223605063653763

Epoch: 6| Step: 4
Training loss: 1.9009027481079102
Validation loss: 2.0763853467920774

Epoch: 6| Step: 5
Training loss: 2.7347159385681152
Validation loss: 2.1072847227896414

Epoch: 6| Step: 6
Training loss: 1.2227504253387451
Validation loss: 2.104992628097534

Epoch: 6| Step: 7
Training loss: 2.3638291358947754
Validation loss: 2.1023312422537033

Epoch: 6| Step: 8
Training loss: 2.129427909851074
Validation loss: 2.1163901154712965

Epoch: 6| Step: 9
Training loss: 1.503091812133789
Validation loss: 2.122945918831774

Epoch: 6| Step: 10
Training loss: 2.3890485763549805
Validation loss: 2.1239902883447628

Epoch: 6| Step: 11
Training loss: 2.6850461959838867
Validation loss: 2.0940447943184965

Epoch: 6| Step: 12
Training loss: 1.4140863418579102
Validation loss: 2.121094815192684

Epoch: 6| Step: 13
Training loss: 1.9127055406570435
Validation loss: 2.0909292992725166

Epoch: 283| Step: 0
Training loss: 1.9105457067489624
Validation loss: 2.086984938190829

Epoch: 6| Step: 1
Training loss: 2.4800124168395996
Validation loss: 2.105342809871961

Epoch: 6| Step: 2
Training loss: 1.6149466037750244
Validation loss: 2.0970010501082226

Epoch: 6| Step: 3
Training loss: 1.6864197254180908
Validation loss: 2.1169566851790234

Epoch: 6| Step: 4
Training loss: 1.6795775890350342
Validation loss: 2.094655611181772

Epoch: 6| Step: 5
Training loss: 2.6962180137634277
Validation loss: 2.088458712382983

Epoch: 6| Step: 6
Training loss: 2.2263293266296387
Validation loss: 2.100693392497237

Epoch: 6| Step: 7
Training loss: 2.378998041152954
Validation loss: 2.091383825066269

Epoch: 6| Step: 8
Training loss: 1.8036186695098877
Validation loss: 2.0955530033316663

Epoch: 6| Step: 9
Training loss: 0.9390552639961243
Validation loss: 2.0858829444454563

Epoch: 6| Step: 10
Training loss: 2.101091146469116
Validation loss: 2.0553343680597123

Epoch: 6| Step: 11
Training loss: 1.4982154369354248
Validation loss: 2.100325779248309

Epoch: 6| Step: 12
Training loss: 1.899107575416565
Validation loss: 2.0765080093055643

Epoch: 6| Step: 13
Training loss: 1.6989563703536987
Validation loss: 2.0779381644341255

Epoch: 284| Step: 0
Training loss: 2.7840521335601807
Validation loss: 2.0970767287797827

Epoch: 6| Step: 1
Training loss: 1.6630719900131226
Validation loss: 2.078013345759402

Epoch: 6| Step: 2
Training loss: 2.1693015098571777
Validation loss: 2.0589671955313733

Epoch: 6| Step: 3
Training loss: 2.1362407207489014
Validation loss: 2.0629694615640948

Epoch: 6| Step: 4
Training loss: 0.949471116065979
Validation loss: 2.1036437557589625

Epoch: 6| Step: 5
Training loss: 2.431020736694336
Validation loss: 2.0674304218702417

Epoch: 6| Step: 6
Training loss: 1.4553297758102417
Validation loss: 2.0885317223046416

Epoch: 6| Step: 7
Training loss: 2.1164469718933105
Validation loss: 2.0738711664753575

Epoch: 6| Step: 8
Training loss: 2.4123783111572266
Validation loss: 2.08232008769948

Epoch: 6| Step: 9
Training loss: 1.6409235000610352
Validation loss: 2.079550197047572

Epoch: 6| Step: 10
Training loss: 1.9974197149276733
Validation loss: 2.0856526346616846

Epoch: 6| Step: 11
Training loss: 1.5305700302124023
Validation loss: 2.0859687828248545

Epoch: 6| Step: 12
Training loss: 1.609375
Validation loss: 2.0831382248991277

Epoch: 6| Step: 13
Training loss: 2.197113513946533
Validation loss: 2.0858174203544535

Epoch: 285| Step: 0
Training loss: 1.9519184827804565
Validation loss: 2.0630756321773736

Epoch: 6| Step: 1
Training loss: 2.2983579635620117
Validation loss: 2.124147771507181

Epoch: 6| Step: 2
Training loss: 1.5476858615875244
Validation loss: 2.1121404888809368

Epoch: 6| Step: 3
Training loss: 1.6000759601593018
Validation loss: 2.1122196810219878

Epoch: 6| Step: 4
Training loss: 2.3418564796447754
Validation loss: 2.15085768699646

Epoch: 6| Step: 5
Training loss: 1.3579554557800293
Validation loss: 2.145196053289598

Epoch: 6| Step: 6
Training loss: 1.8221962451934814
Validation loss: 2.1387946169863463

Epoch: 6| Step: 7
Training loss: 2.219099521636963
Validation loss: 2.1650922682977494

Epoch: 6| Step: 8
Training loss: 1.84323251247406
Validation loss: 2.135319709777832

Epoch: 6| Step: 9
Training loss: 2.1561272144317627
Validation loss: 2.148164080035302

Epoch: 6| Step: 10
Training loss: 1.6578631401062012
Validation loss: 2.1645405369420208

Epoch: 6| Step: 11
Training loss: 2.311859130859375
Validation loss: 2.139532076415195

Epoch: 6| Step: 12
Training loss: 2.1409454345703125
Validation loss: 2.124241554608909

Epoch: 6| Step: 13
Training loss: 1.28238844871521
Validation loss: 2.124730065304746

Epoch: 286| Step: 0
Training loss: 1.6133754253387451
Validation loss: 2.1010810764887

Epoch: 6| Step: 1
Training loss: 2.2711029052734375
Validation loss: 2.1440680334644933

Epoch: 6| Step: 2
Training loss: 1.5181703567504883
Validation loss: 2.0775662058143207

Epoch: 6| Step: 3
Training loss: 2.6348276138305664
Validation loss: 2.0812975437410417

Epoch: 6| Step: 4
Training loss: 1.800083875656128
Validation loss: 2.131547604837725

Epoch: 6| Step: 5
Training loss: 1.640000581741333
Validation loss: 2.072803533205422

Epoch: 6| Step: 6
Training loss: 2.1330223083496094
Validation loss: 2.1063355681716756

Epoch: 6| Step: 7
Training loss: 1.611691951751709
Validation loss: 2.083824106442031

Epoch: 6| Step: 8
Training loss: 1.5567622184753418
Validation loss: 2.0546333507824968

Epoch: 6| Step: 9
Training loss: 1.9910225868225098
Validation loss: 2.100446213958084

Epoch: 6| Step: 10
Training loss: 2.3241076469421387
Validation loss: 2.090892582811335

Epoch: 6| Step: 11
Training loss: 1.8177037239074707
Validation loss: 2.0801797733511975

Epoch: 6| Step: 12
Training loss: 1.819782018661499
Validation loss: 2.106471259106872

Epoch: 6| Step: 13
Training loss: 1.6694707870483398
Validation loss: 2.094753557635892

Epoch: 287| Step: 0
Training loss: 1.6219041347503662
Validation loss: 2.0945650377581195

Epoch: 6| Step: 1
Training loss: 2.026470184326172
Validation loss: 2.064721130555676

Epoch: 6| Step: 2
Training loss: 1.8802638053894043
Validation loss: 2.077272166487991

Epoch: 6| Step: 3
Training loss: 2.136958599090576
Validation loss: 2.1076728810546217

Epoch: 6| Step: 4
Training loss: 2.7178711891174316
Validation loss: 2.143911643694806

Epoch: 6| Step: 5
Training loss: 0.7370486259460449
Validation loss: 2.120412926520071

Epoch: 6| Step: 6
Training loss: 1.8704040050506592
Validation loss: 2.0828294036208943

Epoch: 6| Step: 7
Training loss: 2.334120273590088
Validation loss: 2.119396985218089

Epoch: 6| Step: 8
Training loss: 1.8778852224349976
Validation loss: 2.1295095477052914

Epoch: 6| Step: 9
Training loss: 2.108840227127075
Validation loss: 2.1069788214980916

Epoch: 6| Step: 10
Training loss: 1.8030918836593628
Validation loss: 2.1215394350790207

Epoch: 6| Step: 11
Training loss: 1.6424623727798462
Validation loss: 2.1483533074778896

Epoch: 6| Step: 12
Training loss: 1.8657668828964233
Validation loss: 2.146234147010311

Epoch: 6| Step: 13
Training loss: 2.0549962520599365
Validation loss: 2.1449641540486324

Epoch: 288| Step: 0
Training loss: 2.100287437438965
Validation loss: 2.1169825600039576

Epoch: 6| Step: 1
Training loss: 1.739344596862793
Validation loss: 2.1384510122319704

Epoch: 6| Step: 2
Training loss: 1.988397479057312
Validation loss: 2.133970777193705

Epoch: 6| Step: 3
Training loss: 2.4505019187927246
Validation loss: 2.122803088157408

Epoch: 6| Step: 4
Training loss: 1.500888705253601
Validation loss: 2.1363171454398864

Epoch: 6| Step: 5
Training loss: 2.528259515762329
Validation loss: 2.1195301317399546

Epoch: 6| Step: 6
Training loss: 1.8947772979736328
Validation loss: 2.153374179717033

Epoch: 6| Step: 7
Training loss: 2.078794002532959
Validation loss: 2.1698888476176927

Epoch: 6| Step: 8
Training loss: 1.8970533609390259
Validation loss: 2.1661439300865255

Epoch: 6| Step: 9
Training loss: 1.5815718173980713
Validation loss: 2.1453260567880448

Epoch: 6| Step: 10
Training loss: 1.1455104351043701
Validation loss: 2.1553711275900564

Epoch: 6| Step: 11
Training loss: 1.630082130432129
Validation loss: 2.140088099305348

Epoch: 6| Step: 12
Training loss: 1.917171597480774
Validation loss: 2.137859341918781

Epoch: 6| Step: 13
Training loss: 2.040029287338257
Validation loss: 2.120540513787218

Epoch: 289| Step: 0
Training loss: 2.2328500747680664
Validation loss: 2.1080839582668838

Epoch: 6| Step: 1
Training loss: 1.5287903547286987
Validation loss: 2.1167719466711885

Epoch: 6| Step: 2
Training loss: 2.040132999420166
Validation loss: 2.0964888629092964

Epoch: 6| Step: 3
Training loss: 2.0310616493225098
Validation loss: 2.1292925496255197

Epoch: 6| Step: 4
Training loss: 2.0205881595611572
Validation loss: 2.082347967291391

Epoch: 6| Step: 5
Training loss: 2.0524492263793945
Validation loss: 2.0743094964693953

Epoch: 6| Step: 6
Training loss: 2.2319116592407227
Validation loss: 2.0882345579003774

Epoch: 6| Step: 7
Training loss: 1.5987586975097656
Validation loss: 2.0946915816235285

Epoch: 6| Step: 8
Training loss: 2.0756678581237793
Validation loss: 2.086625576019287

Epoch: 6| Step: 9
Training loss: 2.299156427383423
Validation loss: 2.0993647293377946

Epoch: 6| Step: 10
Training loss: 1.911108136177063
Validation loss: 2.06998816228682

Epoch: 6| Step: 11
Training loss: 1.5867910385131836
Validation loss: 2.0735209142008135

Epoch: 6| Step: 12
Training loss: 1.3609265089035034
Validation loss: 2.094005964135611

Epoch: 6| Step: 13
Training loss: 1.3822884559631348
Validation loss: 2.092611571793915

Epoch: 290| Step: 0
Training loss: 2.3630564212799072
Validation loss: 2.1024354657819195

Epoch: 6| Step: 1
Training loss: 2.2949728965759277
Validation loss: 2.0829836142960416

Epoch: 6| Step: 2
Training loss: 2.432687282562256
Validation loss: 2.0894118496166763

Epoch: 6| Step: 3
Training loss: 2.458566665649414
Validation loss: 2.072617471859019

Epoch: 6| Step: 4
Training loss: 1.9248312711715698
Validation loss: 2.08388053858152

Epoch: 6| Step: 5
Training loss: 1.7159786224365234
Validation loss: 2.080220291691442

Epoch: 6| Step: 6
Training loss: 1.538508415222168
Validation loss: 2.0890468487175564

Epoch: 6| Step: 7
Training loss: 2.007319450378418
Validation loss: 2.1087850088714273

Epoch: 6| Step: 8
Training loss: 1.7763367891311646
Validation loss: 2.0770714564989974

Epoch: 6| Step: 9
Training loss: 1.7772064208984375
Validation loss: 2.0497714050354494

Epoch: 6| Step: 10
Training loss: 1.7340173721313477
Validation loss: 2.1015794097736316

Epoch: 6| Step: 11
Training loss: 1.2103979587554932
Validation loss: 2.1015973552580802

Epoch: 6| Step: 12
Training loss: 1.8972501754760742
Validation loss: 2.0795799301516626

Epoch: 6| Step: 13
Training loss: 1.2235184907913208
Validation loss: 2.1060419390278478

Epoch: 291| Step: 0
Training loss: 2.569828510284424
Validation loss: 2.132704411783526

Epoch: 6| Step: 1
Training loss: 1.3914750814437866
Validation loss: 2.092235037075576

Epoch: 6| Step: 2
Training loss: 1.6112799644470215
Validation loss: 2.072495578437723

Epoch: 6| Step: 3
Training loss: 1.651066780090332
Validation loss: 2.1097746228659027

Epoch: 6| Step: 4
Training loss: 1.382637619972229
Validation loss: 2.107976713488179

Epoch: 6| Step: 5
Training loss: 2.2152063846588135
Validation loss: 2.1044381613372476

Epoch: 6| Step: 6
Training loss: 2.1923365592956543
Validation loss: 2.09471873570514

Epoch: 6| Step: 7
Training loss: 2.7490034103393555
Validation loss: 2.081663795696792

Epoch: 6| Step: 8
Training loss: 1.4396703243255615
Validation loss: 2.084155645421756

Epoch: 6| Step: 9
Training loss: 1.8018450736999512
Validation loss: 2.10794045207321

Epoch: 6| Step: 10
Training loss: 1.700317621231079
Validation loss: 2.0935101380912204

Epoch: 6| Step: 11
Training loss: 1.746385097503662
Validation loss: 2.0768175791668635

Epoch: 6| Step: 12
Training loss: 2.1008405685424805
Validation loss: 2.0870226096081477

Epoch: 6| Step: 13
Training loss: 2.047377586364746
Validation loss: 2.069486697514852

Epoch: 292| Step: 0
Training loss: 1.346855640411377
Validation loss: 2.0801644273983535

Epoch: 6| Step: 1
Training loss: 1.8828197717666626
Validation loss: 2.063651630955358

Epoch: 6| Step: 2
Training loss: 2.1057004928588867
Validation loss: 2.079164033295006

Epoch: 6| Step: 3
Training loss: 2.0099377632141113
Validation loss: 2.1115413250461703

Epoch: 6| Step: 4
Training loss: 1.7373254299163818
Validation loss: 2.107926999368975

Epoch: 6| Step: 5
Training loss: 2.0168490409851074
Validation loss: 2.1000636469933296

Epoch: 6| Step: 6
Training loss: 1.207161545753479
Validation loss: 2.0998283432376

Epoch: 6| Step: 7
Training loss: 1.6943063735961914
Validation loss: 2.113983661897721

Epoch: 6| Step: 8
Training loss: 2.313058853149414
Validation loss: 2.101318109420038

Epoch: 6| Step: 9
Training loss: 1.5778366327285767
Validation loss: 2.1059915698984617

Epoch: 6| Step: 10
Training loss: 2.0420241355895996
Validation loss: 2.110862103841638

Epoch: 6| Step: 11
Training loss: 2.026562213897705
Validation loss: 2.1024701826034056

Epoch: 6| Step: 12
Training loss: 2.1660122871398926
Validation loss: 2.1042044214023057

Epoch: 6| Step: 13
Training loss: 2.3419501781463623
Validation loss: 2.101732692410869

Epoch: 293| Step: 0
Training loss: 1.8280229568481445
Validation loss: 2.10714530175732

Epoch: 6| Step: 1
Training loss: 2.2494559288024902
Validation loss: 2.1110893231566235

Epoch: 6| Step: 2
Training loss: 2.4856600761413574
Validation loss: 2.0773018624192927

Epoch: 6| Step: 3
Training loss: 1.7152255773544312
Validation loss: 2.127806935259091

Epoch: 6| Step: 4
Training loss: 1.6648495197296143
Validation loss: 2.1179012508802515

Epoch: 6| Step: 5
Training loss: 2.2374978065490723
Validation loss: 2.0903719958438667

Epoch: 6| Step: 6
Training loss: 1.7781012058258057
Validation loss: 2.1164263294589136

Epoch: 6| Step: 7
Training loss: 2.246567726135254
Validation loss: 2.1155596061419417

Epoch: 6| Step: 8
Training loss: 1.309008002281189
Validation loss: 2.119314983326902

Epoch: 6| Step: 9
Training loss: 1.879387617111206
Validation loss: 2.0937662880907775

Epoch: 6| Step: 10
Training loss: 1.451155662536621
Validation loss: 2.0926509262413107

Epoch: 6| Step: 11
Training loss: 1.1739474534988403
Validation loss: 2.061796065299742

Epoch: 6| Step: 12
Training loss: 2.236614942550659
Validation loss: 2.0861966225408737

Epoch: 6| Step: 13
Training loss: 1.770868182182312
Validation loss: 2.0535704089749243

Epoch: 294| Step: 0
Training loss: 1.940378189086914
Validation loss: 2.095865890543948

Epoch: 6| Step: 1
Training loss: 1.5001189708709717
Validation loss: 2.117750798502276

Epoch: 6| Step: 2
Training loss: 2.1279146671295166
Validation loss: 2.077417012183897

Epoch: 6| Step: 3
Training loss: 2.4106998443603516
Validation loss: 2.0725814168171217

Epoch: 6| Step: 4
Training loss: 1.4866913557052612
Validation loss: 2.122768353390437

Epoch: 6| Step: 5
Training loss: 1.8085415363311768
Validation loss: 2.095929378463376

Epoch: 6| Step: 6
Training loss: 2.388949155807495
Validation loss: 2.1006488671866794

Epoch: 6| Step: 7
Training loss: 2.2191104888916016
Validation loss: 2.110223226649787

Epoch: 6| Step: 8
Training loss: 2.2257630825042725
Validation loss: 2.11567892694986

Epoch: 6| Step: 9
Training loss: 1.7998979091644287
Validation loss: 2.114378083136774

Epoch: 6| Step: 10
Training loss: 1.8816689252853394
Validation loss: 2.1361789575187107

Epoch: 6| Step: 11
Training loss: 1.3894633054733276
Validation loss: 2.147262055386779

Epoch: 6| Step: 12
Training loss: 1.8401515483856201
Validation loss: 2.1120102021002

Epoch: 6| Step: 13
Training loss: 1.390491008758545
Validation loss: 2.1435860433886127

Epoch: 295| Step: 0
Training loss: 1.7080085277557373
Validation loss: 2.0718725701814056

Epoch: 6| Step: 1
Training loss: 1.8831696510314941
Validation loss: 2.0763782352529545

Epoch: 6| Step: 2
Training loss: 1.598841667175293
Validation loss: 2.094654101197438

Epoch: 6| Step: 3
Training loss: 2.477820873260498
Validation loss: 2.0937174186911633

Epoch: 6| Step: 4
Training loss: 1.604574203491211
Validation loss: 2.08570836692728

Epoch: 6| Step: 5
Training loss: 2.6297149658203125
Validation loss: 2.084244728088379

Epoch: 6| Step: 6
Training loss: 1.3512200117111206
Validation loss: 2.076217071984404

Epoch: 6| Step: 7
Training loss: 2.1437597274780273
Validation loss: 2.0550140206531813

Epoch: 6| Step: 8
Training loss: 1.935018539428711
Validation loss: 2.0521074828281196

Epoch: 6| Step: 9
Training loss: 1.4895259141921997
Validation loss: 2.0940935739906887

Epoch: 6| Step: 10
Training loss: 1.793513536453247
Validation loss: 2.076080241510945

Epoch: 6| Step: 11
Training loss: 1.8755437135696411
Validation loss: 2.071251734610527

Epoch: 6| Step: 12
Training loss: 2.177187919616699
Validation loss: 2.0794729058460524

Epoch: 6| Step: 13
Training loss: 1.786773681640625
Validation loss: 2.077493421493038

Epoch: 296| Step: 0
Training loss: 1.6268272399902344
Validation loss: 2.085932352209604

Epoch: 6| Step: 1
Training loss: 1.9383431673049927
Validation loss: 2.091956442402255

Epoch: 6| Step: 2
Training loss: 2.205909490585327
Validation loss: 2.083155955037763

Epoch: 6| Step: 3
Training loss: 2.6133599281311035
Validation loss: 2.1172369398096555

Epoch: 6| Step: 4
Training loss: 1.7641680240631104
Validation loss: 2.0959454403128674

Epoch: 6| Step: 5
Training loss: 1.5539512634277344
Validation loss: 2.1271218920266755

Epoch: 6| Step: 6
Training loss: 1.768879771232605
Validation loss: 2.08719648597061

Epoch: 6| Step: 7
Training loss: 1.081477403640747
Validation loss: 2.0950866386454594

Epoch: 6| Step: 8
Training loss: 1.793039321899414
Validation loss: 2.139794723961943

Epoch: 6| Step: 9
Training loss: 2.5400757789611816
Validation loss: 2.155369914988036

Epoch: 6| Step: 10
Training loss: 1.8070886135101318
Validation loss: 2.1161622937007616

Epoch: 6| Step: 11
Training loss: 1.5772227048873901
Validation loss: 2.1061572515836327

Epoch: 6| Step: 12
Training loss: 1.9709810018539429
Validation loss: 2.132277763018044

Epoch: 6| Step: 13
Training loss: 1.48612642288208
Validation loss: 2.139165598859069

Epoch: 297| Step: 0
Training loss: 1.922753095626831
Validation loss: 2.1074439889641217

Epoch: 6| Step: 1
Training loss: 1.7537117004394531
Validation loss: 2.0974010613656815

Epoch: 6| Step: 2
Training loss: 1.7142343521118164
Validation loss: 2.0955864255146315

Epoch: 6| Step: 3
Training loss: 1.7724435329437256
Validation loss: 2.1050234251124884

Epoch: 6| Step: 4
Training loss: 2.3273816108703613
Validation loss: 2.0916463303309616

Epoch: 6| Step: 5
Training loss: 1.9289186000823975
Validation loss: 2.096513999405728

Epoch: 6| Step: 6
Training loss: 1.778541088104248
Validation loss: 2.0835265369825464

Epoch: 6| Step: 7
Training loss: 1.425155758857727
Validation loss: 2.103109928869432

Epoch: 6| Step: 8
Training loss: 1.850148320198059
Validation loss: 2.1122497332993375

Epoch: 6| Step: 9
Training loss: 1.3959643840789795
Validation loss: 2.0687242374625257

Epoch: 6| Step: 10
Training loss: 1.931957483291626
Validation loss: 2.111312399628342

Epoch: 6| Step: 11
Training loss: 2.158754348754883
Validation loss: 2.071366020428237

Epoch: 6| Step: 12
Training loss: 2.08317494392395
Validation loss: 2.0712177779084895

Epoch: 6| Step: 13
Training loss: 2.5361557006835938
Validation loss: 2.110771212526547

Epoch: 298| Step: 0
Training loss: 1.1079695224761963
Validation loss: 2.079212374584649

Epoch: 6| Step: 1
Training loss: 1.9020848274230957
Validation loss: 2.0712416120754775

Epoch: 6| Step: 2
Training loss: 1.6267168521881104
Validation loss: 2.0704218546549478

Epoch: 6| Step: 3
Training loss: 1.360445261001587
Validation loss: 2.080129179903256

Epoch: 6| Step: 4
Training loss: 2.0833632946014404
Validation loss: 2.0578809925304946

Epoch: 6| Step: 5
Training loss: 1.4506573677062988
Validation loss: 2.0925705407255437

Epoch: 6| Step: 6
Training loss: 2.1876699924468994
Validation loss: 2.1167365607394966

Epoch: 6| Step: 7
Training loss: 1.7453126907348633
Validation loss: 2.0902803405638664

Epoch: 6| Step: 8
Training loss: 1.7916555404663086
Validation loss: 2.067545488316526

Epoch: 6| Step: 9
Training loss: 2.3203630447387695
Validation loss: 2.098637583435223

Epoch: 6| Step: 10
Training loss: 1.8368604183197021
Validation loss: 2.07458617097588

Epoch: 6| Step: 11
Training loss: 2.441579818725586
Validation loss: 2.103784804703087

Epoch: 6| Step: 12
Training loss: 2.2508955001831055
Validation loss: 2.072574534723836

Epoch: 6| Step: 13
Training loss: 2.3444182872772217
Validation loss: 2.0921775705070904

Epoch: 299| Step: 0
Training loss: 1.6539446115493774
Validation loss: 2.1120828531121694

Epoch: 6| Step: 1
Training loss: 1.6736892461776733
Validation loss: 2.134426680944299

Epoch: 6| Step: 2
Training loss: 1.9780570268630981
Validation loss: 2.121616635271298

Epoch: 6| Step: 3
Training loss: 1.8019123077392578
Validation loss: 2.1188820433873

Epoch: 6| Step: 4
Training loss: 1.9058024883270264
Validation loss: 2.123007094988259

Epoch: 6| Step: 5
Training loss: 1.5496017932891846
Validation loss: 2.1070819721427014

Epoch: 6| Step: 6
Training loss: 1.0599430799484253
Validation loss: 2.1542677828060683

Epoch: 6| Step: 7
Training loss: 2.2041356563568115
Validation loss: 2.105706048268144

Epoch: 6| Step: 8
Training loss: 2.016615867614746
Validation loss: 2.09427164318741

Epoch: 6| Step: 9
Training loss: 2.4709372520446777
Validation loss: 2.0960825848323044

Epoch: 6| Step: 10
Training loss: 1.8116942644119263
Validation loss: 2.122144509387273

Epoch: 6| Step: 11
Training loss: 2.266866445541382
Validation loss: 2.1213544901981147

Epoch: 6| Step: 12
Training loss: 1.8993804454803467
Validation loss: 2.1068578958511353

Epoch: 6| Step: 13
Training loss: 2.187546491622925
Validation loss: 2.1246060325253393

Epoch: 300| Step: 0
Training loss: 1.5448379516601562
Validation loss: 2.1381255657442155

Epoch: 6| Step: 1
Training loss: 1.823004961013794
Validation loss: 2.0814533823279926

Epoch: 6| Step: 2
Training loss: 1.7752954959869385
Validation loss: 2.1055474563311507

Epoch: 6| Step: 3
Training loss: 1.5781474113464355
Validation loss: 2.122157560881748

Epoch: 6| Step: 4
Training loss: 1.347459077835083
Validation loss: 2.0819008914373254

Epoch: 6| Step: 5
Training loss: 2.097984790802002
Validation loss: 2.113189285801303

Epoch: 6| Step: 6
Training loss: 1.9611363410949707
Validation loss: 2.1245582052456435

Epoch: 6| Step: 7
Training loss: 2.409700870513916
Validation loss: 2.125021929381996

Epoch: 6| Step: 8
Training loss: 2.3373498916625977
Validation loss: 2.1448264301464124

Epoch: 6| Step: 9
Training loss: 1.87615168094635
Validation loss: 2.0976412591113838

Epoch: 6| Step: 10
Training loss: 2.036159038543701
Validation loss: 2.1065156972536476

Epoch: 6| Step: 11
Training loss: 2.1244218349456787
Validation loss: 2.084201717889437

Epoch: 6| Step: 12
Training loss: 1.403428316116333
Validation loss: 2.075802465920807

Epoch: 6| Step: 13
Training loss: 1.8854607343673706
Validation loss: 2.073177686301611

Epoch: 301| Step: 0
Training loss: 1.55271315574646
Validation loss: 2.119146872592229

Epoch: 6| Step: 1
Training loss: 1.8738973140716553
Validation loss: 2.1140946342099096

Epoch: 6| Step: 2
Training loss: 2.6152007579803467
Validation loss: 2.0954797332004835

Epoch: 6| Step: 3
Training loss: 2.1748905181884766
Validation loss: 2.1015036362473682

Epoch: 6| Step: 4
Training loss: 1.258089303970337
Validation loss: 2.0813956081226306

Epoch: 6| Step: 5
Training loss: 1.664987325668335
Validation loss: 2.088243181987475

Epoch: 6| Step: 6
Training loss: 2.0828990936279297
Validation loss: 2.124137904054375

Epoch: 6| Step: 7
Training loss: 1.8592884540557861
Validation loss: 2.124944463852913

Epoch: 6| Step: 8
Training loss: 1.4906246662139893
Validation loss: 2.127716838672597

Epoch: 6| Step: 9
Training loss: 2.0477025508880615
Validation loss: 2.1320202735162552

Epoch: 6| Step: 10
Training loss: 1.6418430805206299
Validation loss: 2.0968985365283106

Epoch: 6| Step: 11
Training loss: 1.7781107425689697
Validation loss: 2.1544794395405757

Epoch: 6| Step: 12
Training loss: 2.251540184020996
Validation loss: 2.124239203750446

Epoch: 6| Step: 13
Training loss: 2.1899287700653076
Validation loss: 2.1009863038216867

Epoch: 302| Step: 0
Training loss: 1.8460485935211182
Validation loss: 2.1408217504460323

Epoch: 6| Step: 1
Training loss: 2.2802257537841797
Validation loss: 2.0990180776965235

Epoch: 6| Step: 2
Training loss: 1.734470009803772
Validation loss: 2.1033876762595227

Epoch: 6| Step: 3
Training loss: 2.0446434020996094
Validation loss: 2.1169750690460205

Epoch: 6| Step: 4
Training loss: 1.6221342086791992
Validation loss: 2.118381679698985

Epoch: 6| Step: 5
Training loss: 2.2257256507873535
Validation loss: 2.079859668208707

Epoch: 6| Step: 6
Training loss: 1.2130470275878906
Validation loss: 2.1052773280810286

Epoch: 6| Step: 7
Training loss: 1.6700992584228516
Validation loss: 2.1382757489399244

Epoch: 6| Step: 8
Training loss: 1.949082851409912
Validation loss: 2.102457400291197

Epoch: 6| Step: 9
Training loss: 2.3351945877075195
Validation loss: 2.1179989063611595

Epoch: 6| Step: 10
Training loss: 1.209007740020752
Validation loss: 2.117755448946389

Epoch: 6| Step: 11
Training loss: 1.901493787765503
Validation loss: 2.1363193296617076

Epoch: 6| Step: 12
Training loss: 2.0501935482025146
Validation loss: 2.0685498970811085

Epoch: 6| Step: 13
Training loss: 1.8127530813217163
Validation loss: 2.0857719452150407

Epoch: 303| Step: 0
Training loss: 1.7734445333480835
Validation loss: 2.108188416368218

Epoch: 6| Step: 1
Training loss: 1.6395540237426758
Validation loss: 2.098326885572044

Epoch: 6| Step: 2
Training loss: 2.643772840499878
Validation loss: 2.1268757209982923

Epoch: 6| Step: 3
Training loss: 2.1777515411376953
Validation loss: 2.0936948407080864

Epoch: 6| Step: 4
Training loss: 2.521472215652466
Validation loss: 2.081074075032306

Epoch: 6| Step: 5
Training loss: 1.7300914525985718
Validation loss: 2.099112505553871

Epoch: 6| Step: 6
Training loss: 2.178157329559326
Validation loss: 2.1055555241082304

Epoch: 6| Step: 7
Training loss: 1.8504294157028198
Validation loss: 2.1038785826775337

Epoch: 6| Step: 8
Training loss: 2.202320098876953
Validation loss: 2.1132924454186552

Epoch: 6| Step: 9
Training loss: 1.2656241655349731
Validation loss: 2.078280774495935

Epoch: 6| Step: 10
Training loss: 1.8665037155151367
Validation loss: 2.0970963611397693

Epoch: 6| Step: 11
Training loss: 1.746293544769287
Validation loss: 2.087574887019332

Epoch: 6| Step: 12
Training loss: 1.2979419231414795
Validation loss: 2.100826468518985

Epoch: 6| Step: 13
Training loss: 1.2975451946258545
Validation loss: 2.0880327378549883

Epoch: 304| Step: 0
Training loss: 1.9890215396881104
Validation loss: 2.079668616735807

Epoch: 6| Step: 1
Training loss: 1.6639270782470703
Validation loss: 2.1068139422324395

Epoch: 6| Step: 2
Training loss: 2.245345115661621
Validation loss: 2.109313021423996

Epoch: 6| Step: 3
Training loss: 1.159765362739563
Validation loss: 2.120140742230159

Epoch: 6| Step: 4
Training loss: 2.4478564262390137
Validation loss: 2.105923160429924

Epoch: 6| Step: 5
Training loss: 1.5131585597991943
Validation loss: 2.1477389335632324

Epoch: 6| Step: 6
Training loss: 1.8406076431274414
Validation loss: 2.1134772736539125

Epoch: 6| Step: 7
Training loss: 1.9956258535385132
Validation loss: 2.139224044738277

Epoch: 6| Step: 8
Training loss: 1.267298936843872
Validation loss: 2.147446587521543

Epoch: 6| Step: 9
Training loss: 2.5134968757629395
Validation loss: 2.148152889743928

Epoch: 6| Step: 10
Training loss: 2.0825188159942627
Validation loss: 2.1303150474384265

Epoch: 6| Step: 11
Training loss: 2.0755224227905273
Validation loss: 2.152776882212649

Epoch: 6| Step: 12
Training loss: 1.7081882953643799
Validation loss: 2.149745125924387

Epoch: 6| Step: 13
Training loss: 1.5200104713439941
Validation loss: 2.141450814021531

Epoch: 305| Step: 0
Training loss: 1.6479302644729614
Validation loss: 2.1435921525442474

Epoch: 6| Step: 1
Training loss: 2.141967296600342
Validation loss: 2.1113524231859433

Epoch: 6| Step: 2
Training loss: 1.6225636005401611
Validation loss: 2.1214826953026558

Epoch: 6| Step: 3
Training loss: 2.0540378093719482
Validation loss: 2.140446309120424

Epoch: 6| Step: 4
Training loss: 2.093583106994629
Validation loss: 2.13545782719889

Epoch: 6| Step: 5
Training loss: 2.239800453186035
Validation loss: 2.133235062322309

Epoch: 6| Step: 6
Training loss: 1.3468732833862305
Validation loss: 2.1332053138363745

Epoch: 6| Step: 7
Training loss: 1.2206637859344482
Validation loss: 2.1398356499210482

Epoch: 6| Step: 8
Training loss: 1.8698281049728394
Validation loss: 2.131955946645429

Epoch: 6| Step: 9
Training loss: 1.899164080619812
Validation loss: 2.1165770766555623

Epoch: 6| Step: 10
Training loss: 1.4784493446350098
Validation loss: 2.111731634345106

Epoch: 6| Step: 11
Training loss: 2.1070101261138916
Validation loss: 2.1194957276826263

Epoch: 6| Step: 12
Training loss: 2.017827272415161
Validation loss: 2.103358394356184

Epoch: 6| Step: 13
Training loss: 2.132845878601074
Validation loss: 2.1123545785104074

Epoch: 306| Step: 0
Training loss: 1.6138584613800049
Validation loss: 2.117880323881744

Epoch: 6| Step: 1
Training loss: 1.5735507011413574
Validation loss: 2.111630416685535

Epoch: 6| Step: 2
Training loss: 2.2473902702331543
Validation loss: 2.1101441178270566

Epoch: 6| Step: 3
Training loss: 2.173635482788086
Validation loss: 2.1246488940331245

Epoch: 6| Step: 4
Training loss: 1.5701278448104858
Validation loss: 2.119007995051722

Epoch: 6| Step: 5
Training loss: 2.127725839614868
Validation loss: 2.119144762715986

Epoch: 6| Step: 6
Training loss: 1.964608907699585
Validation loss: 2.1147425200349543

Epoch: 6| Step: 7
Training loss: 1.3801944255828857
Validation loss: 2.1145554024686097

Epoch: 6| Step: 8
Training loss: 2.0683469772338867
Validation loss: 2.0956485579090733

Epoch: 6| Step: 9
Training loss: 1.7872947454452515
Validation loss: 2.0829990012671358

Epoch: 6| Step: 10
Training loss: 1.6356858015060425
Validation loss: 2.092336090662146

Epoch: 6| Step: 11
Training loss: 2.175847053527832
Validation loss: 2.1042380358583186

Epoch: 6| Step: 12
Training loss: 1.643113374710083
Validation loss: 2.1027683545184392

Epoch: 6| Step: 13
Training loss: 2.148864507675171
Validation loss: 2.09419951387631

Epoch: 307| Step: 0
Training loss: 1.9324442148208618
Validation loss: 2.119216686935835

Epoch: 6| Step: 1
Training loss: 1.6255624294281006
Validation loss: 2.0653689933079544

Epoch: 6| Step: 2
Training loss: 2.009758472442627
Validation loss: 2.076815212926557

Epoch: 6| Step: 3
Training loss: 1.7035245895385742
Validation loss: 2.107245636242692

Epoch: 6| Step: 4
Training loss: 2.0675172805786133
Validation loss: 2.153650003094827

Epoch: 6| Step: 5
Training loss: 1.14231538772583
Validation loss: 2.1236906666909494

Epoch: 6| Step: 6
Training loss: 1.812759280204773
Validation loss: 2.1245207812196467

Epoch: 6| Step: 7
Training loss: 1.6362864971160889
Validation loss: 2.1144563677490398

Epoch: 6| Step: 8
Training loss: 1.9816468954086304
Validation loss: 2.114985368585074

Epoch: 6| Step: 9
Training loss: 2.033115863800049
Validation loss: 2.1189362284957722

Epoch: 6| Step: 10
Training loss: 1.527511477470398
Validation loss: 2.114774437360866

Epoch: 6| Step: 11
Training loss: 2.1483516693115234
Validation loss: 2.0975851346087713

Epoch: 6| Step: 12
Training loss: 1.8836809396743774
Validation loss: 2.151700396691599

Epoch: 6| Step: 13
Training loss: 2.7346365451812744
Validation loss: 2.1510079304377236

Epoch: 308| Step: 0
Training loss: 1.9503083229064941
Validation loss: 2.1224674576072284

Epoch: 6| Step: 1
Training loss: 1.5691429376602173
Validation loss: 2.1246330763704036

Epoch: 6| Step: 2
Training loss: 2.3951356410980225
Validation loss: 2.127776686863233

Epoch: 6| Step: 3
Training loss: 1.4784139394760132
Validation loss: 2.1245221502037457

Epoch: 6| Step: 4
Training loss: 2.4184517860412598
Validation loss: 2.1461408343366397

Epoch: 6| Step: 5
Training loss: 2.119943380355835
Validation loss: 2.096838761401433

Epoch: 6| Step: 6
Training loss: 1.5949351787567139
Validation loss: 2.081072297147525

Epoch: 6| Step: 7
Training loss: 1.9014050960540771
Validation loss: 2.1480626060116674

Epoch: 6| Step: 8
Training loss: 1.7992875576019287
Validation loss: 2.1235260091802126

Epoch: 6| Step: 9
Training loss: 2.0420968532562256
Validation loss: 2.12023413565851

Epoch: 6| Step: 10
Training loss: 1.6682507991790771
Validation loss: 2.1001022810577066

Epoch: 6| Step: 11
Training loss: 1.123793601989746
Validation loss: 2.0971496361558155

Epoch: 6| Step: 12
Training loss: 1.7054681777954102
Validation loss: 2.124347722658547

Epoch: 6| Step: 13
Training loss: 2.2077646255493164
Validation loss: 2.1013400990475892

Epoch: 309| Step: 0
Training loss: 2.3546857833862305
Validation loss: 2.098766919105284

Epoch: 6| Step: 1
Training loss: 2.062089681625366
Validation loss: 2.0976816543968777

Epoch: 6| Step: 2
Training loss: 2.262972593307495
Validation loss: 2.109816417899183

Epoch: 6| Step: 3
Training loss: 1.81087064743042
Validation loss: 2.092281952981026

Epoch: 6| Step: 4
Training loss: 2.182295560836792
Validation loss: 2.118026841071344

Epoch: 6| Step: 5
Training loss: 1.6537946462631226
Validation loss: 2.103983425324963

Epoch: 6| Step: 6
Training loss: 1.4252005815505981
Validation loss: 2.1026827699394635

Epoch: 6| Step: 7
Training loss: 1.517379641532898
Validation loss: 2.0969720822508617

Epoch: 6| Step: 8
Training loss: 1.6525682210922241
Validation loss: 2.0773211909878637

Epoch: 6| Step: 9
Training loss: 1.622933268547058
Validation loss: 2.1143729379100185

Epoch: 6| Step: 10
Training loss: 1.0703837871551514
Validation loss: 2.106671030803393

Epoch: 6| Step: 11
Training loss: 2.119455337524414
Validation loss: 2.0945335588147564

Epoch: 6| Step: 12
Training loss: 1.7831976413726807
Validation loss: 2.13109879468077

Epoch: 6| Step: 13
Training loss: 2.3826663494110107
Validation loss: 2.110160381563248

Epoch: 310| Step: 0
Training loss: 1.7896199226379395
Validation loss: 2.0916996720016643

Epoch: 6| Step: 1
Training loss: 1.9618871212005615
Validation loss: 2.096040807744508

Epoch: 6| Step: 2
Training loss: 2.026559591293335
Validation loss: 2.1085867779229277

Epoch: 6| Step: 3
Training loss: 1.420832633972168
Validation loss: 2.0910422725062214

Epoch: 6| Step: 4
Training loss: 1.44711172580719
Validation loss: 2.083208067442781

Epoch: 6| Step: 5
Training loss: 1.8467614650726318
Validation loss: 2.1250881828287596

Epoch: 6| Step: 6
Training loss: 1.3846808671951294
Validation loss: 2.1401639625590336

Epoch: 6| Step: 7
Training loss: 2.192952871322632
Validation loss: 2.1369419226082425

Epoch: 6| Step: 8
Training loss: 1.6510043144226074
Validation loss: 2.121234974553508

Epoch: 6| Step: 9
Training loss: 2.088817596435547
Validation loss: 2.155502414190641

Epoch: 6| Step: 10
Training loss: 2.119601249694824
Validation loss: 2.136074144353149

Epoch: 6| Step: 11
Training loss: 1.2408838272094727
Validation loss: 2.151015399604715

Epoch: 6| Step: 12
Training loss: 2.913365364074707
Validation loss: 2.1357119596132668

Epoch: 6| Step: 13
Training loss: 1.4290720224380493
Validation loss: 2.1211629759880806

Epoch: 311| Step: 0
Training loss: 2.0730786323547363
Validation loss: 2.1034806056689193

Epoch: 6| Step: 1
Training loss: 1.9104523658752441
Validation loss: 2.145449394820839

Epoch: 6| Step: 2
Training loss: 1.9150104522705078
Validation loss: 2.1191001207597795

Epoch: 6| Step: 3
Training loss: 2.002584218978882
Validation loss: 2.1060415019271193

Epoch: 6| Step: 4
Training loss: 1.1182866096496582
Validation loss: 2.1205771328300558

Epoch: 6| Step: 5
Training loss: 1.6297178268432617
Validation loss: 2.1171593999349945

Epoch: 6| Step: 6
Training loss: 2.3665902614593506
Validation loss: 2.114823959207022

Epoch: 6| Step: 7
Training loss: 1.7097718715667725
Validation loss: 2.141620333476733

Epoch: 6| Step: 8
Training loss: 1.6867327690124512
Validation loss: 2.1291813632493377

Epoch: 6| Step: 9
Training loss: 1.5817387104034424
Validation loss: 2.1355235294629167

Epoch: 6| Step: 10
Training loss: 1.2241871356964111
Validation loss: 2.151360639961817

Epoch: 6| Step: 11
Training loss: 2.0947611331939697
Validation loss: 2.0911619291510632

Epoch: 6| Step: 12
Training loss: 2.3628835678100586
Validation loss: 2.1252539850050405

Epoch: 6| Step: 13
Training loss: 2.0260303020477295
Validation loss: 2.1126196461339153

Epoch: 312| Step: 0
Training loss: 1.6086313724517822
Validation loss: 2.1031312147776284

Epoch: 6| Step: 1
Training loss: 2.2458667755126953
Validation loss: 2.0704847715234243

Epoch: 6| Step: 2
Training loss: 1.4416427612304688
Validation loss: 2.0819764496177755

Epoch: 6| Step: 3
Training loss: 1.7237937450408936
Validation loss: 2.09252667427063

Epoch: 6| Step: 4
Training loss: 1.6863428354263306
Validation loss: 2.0878885612692883

Epoch: 6| Step: 5
Training loss: 1.7953660488128662
Validation loss: 2.0776646034691924

Epoch: 6| Step: 6
Training loss: 2.0084266662597656
Validation loss: 2.083931464020924

Epoch: 6| Step: 7
Training loss: 2.0699357986450195
Validation loss: 2.0658710425899875

Epoch: 6| Step: 8
Training loss: 1.55189049243927
Validation loss: 2.1088117155977475

Epoch: 6| Step: 9
Training loss: 1.9781978130340576
Validation loss: 2.117437493416571

Epoch: 6| Step: 10
Training loss: 1.8269413709640503
Validation loss: 2.096647298464211

Epoch: 6| Step: 11
Training loss: 1.4957048892974854
Validation loss: 2.08927652400027

Epoch: 6| Step: 12
Training loss: 2.25866436958313
Validation loss: 2.0936331966871857

Epoch: 6| Step: 13
Training loss: 2.4705939292907715
Validation loss: 2.123292657636827

Epoch: 313| Step: 0
Training loss: 1.6040364503860474
Validation loss: 2.097827675522015

Epoch: 6| Step: 1
Training loss: 2.5616793632507324
Validation loss: 2.0686925611188336

Epoch: 6| Step: 2
Training loss: 2.0489649772644043
Validation loss: 2.101843521159182

Epoch: 6| Step: 3
Training loss: 1.7677980661392212
Validation loss: 2.0981106065934703

Epoch: 6| Step: 4
Training loss: 1.499906063079834
Validation loss: 2.1054550678499284

Epoch: 6| Step: 5
Training loss: 1.552241325378418
Validation loss: 2.0943173311089955

Epoch: 6| Step: 6
Training loss: 1.8987877368927002
Validation loss: 2.1027952701814714

Epoch: 6| Step: 7
Training loss: 2.3764142990112305
Validation loss: 2.0650270139017413

Epoch: 6| Step: 8
Training loss: 2.0654242038726807
Validation loss: 2.120490958613734

Epoch: 6| Step: 9
Training loss: 2.442455768585205
Validation loss: 2.0844408747970418

Epoch: 6| Step: 10
Training loss: 1.1479218006134033
Validation loss: 2.1097322330679944

Epoch: 6| Step: 11
Training loss: 1.9075982570648193
Validation loss: 2.094203299091708

Epoch: 6| Step: 12
Training loss: 1.0583393573760986
Validation loss: 2.1479792107817945

Epoch: 6| Step: 13
Training loss: 1.604125738143921
Validation loss: 2.1245506399421283

Epoch: 314| Step: 0
Training loss: 2.1128053665161133
Validation loss: 2.12028589043566

Epoch: 6| Step: 1
Training loss: 1.7724136114120483
Validation loss: 2.101966283654654

Epoch: 6| Step: 2
Training loss: 1.292766809463501
Validation loss: 2.1110936672456804

Epoch: 6| Step: 3
Training loss: 1.5701563358306885
Validation loss: 2.1015495331056657

Epoch: 6| Step: 4
Training loss: 1.6930735111236572
Validation loss: 2.1165559958386164

Epoch: 6| Step: 5
Training loss: 1.9356179237365723
Validation loss: 2.0817939940319268

Epoch: 6| Step: 6
Training loss: 1.9233875274658203
Validation loss: 2.104529232107183

Epoch: 6| Step: 7
Training loss: 1.6610283851623535
Validation loss: 2.0720553398132324

Epoch: 6| Step: 8
Training loss: 2.1045498847961426
Validation loss: 2.1275974332645373

Epoch: 6| Step: 9
Training loss: 1.7421557903289795
Validation loss: 2.0883044453077417

Epoch: 6| Step: 10
Training loss: 2.754411220550537
Validation loss: 2.119158593557214

Epoch: 6| Step: 11
Training loss: 1.2802064418792725
Validation loss: 2.1186219979357976

Epoch: 6| Step: 12
Training loss: 1.9170831441879272
Validation loss: 2.109688412758612

Epoch: 6| Step: 13
Training loss: 1.7730644941329956
Validation loss: 2.0824602816694524

Epoch: 315| Step: 0
Training loss: 2.267120838165283
Validation loss: 2.0944854213345434

Epoch: 6| Step: 1
Training loss: 1.5230731964111328
Validation loss: 2.114290116935648

Epoch: 6| Step: 2
Training loss: 2.1687235832214355
Validation loss: 2.0795619333944013

Epoch: 6| Step: 3
Training loss: 1.6093336343765259
Validation loss: 2.114962403492261

Epoch: 6| Step: 4
Training loss: 1.726792335510254
Validation loss: 2.1199893707870157

Epoch: 6| Step: 5
Training loss: 1.8344106674194336
Validation loss: 2.098882621334445

Epoch: 6| Step: 6
Training loss: 2.012477159500122
Validation loss: 2.1035732428232827

Epoch: 6| Step: 7
Training loss: 1.702010154724121
Validation loss: 2.099391798819265

Epoch: 6| Step: 8
Training loss: 1.8674267530441284
Validation loss: 2.0778600067220707

Epoch: 6| Step: 9
Training loss: 1.9277268648147583
Validation loss: 2.103686865939889

Epoch: 6| Step: 10
Training loss: 1.5776302814483643
Validation loss: 2.127722050554009

Epoch: 6| Step: 11
Training loss: 2.458913803100586
Validation loss: 2.102759956031717

Epoch: 6| Step: 12
Training loss: 1.3685195446014404
Validation loss: 2.1253998561572005

Epoch: 6| Step: 13
Training loss: 1.1146798133850098
Validation loss: 2.1561664483880483

Epoch: 316| Step: 0
Training loss: 2.1493701934814453
Validation loss: 2.120020474157026

Epoch: 6| Step: 1
Training loss: 2.0412728786468506
Validation loss: 2.1471092508685206

Epoch: 6| Step: 2
Training loss: 1.6217775344848633
Validation loss: 2.151285635527744

Epoch: 6| Step: 3
Training loss: 1.8211002349853516
Validation loss: 2.1472212191550963

Epoch: 6| Step: 4
Training loss: 1.3507479429244995
Validation loss: 2.1174967468425794

Epoch: 6| Step: 5
Training loss: 1.6489479541778564
Validation loss: 2.1305293190863823

Epoch: 6| Step: 6
Training loss: 2.4886207580566406
Validation loss: 2.1275889245412682

Epoch: 6| Step: 7
Training loss: 2.053973913192749
Validation loss: 2.120348522740026

Epoch: 6| Step: 8
Training loss: 1.3187496662139893
Validation loss: 2.103299169130223

Epoch: 6| Step: 9
Training loss: 1.7105674743652344
Validation loss: 2.130141588949388

Epoch: 6| Step: 10
Training loss: 1.515815258026123
Validation loss: 2.083187021234984

Epoch: 6| Step: 11
Training loss: 1.8008108139038086
Validation loss: 2.097860215812601

Epoch: 6| Step: 12
Training loss: 2.216231107711792
Validation loss: 2.089830670305478

Epoch: 6| Step: 13
Training loss: 1.9915902614593506
Validation loss: 2.127009532784903

Epoch: 317| Step: 0
Training loss: 1.9792368412017822
Validation loss: 2.1027126004618983

Epoch: 6| Step: 1
Training loss: 1.9925620555877686
Validation loss: 2.0781305451546945

Epoch: 6| Step: 2
Training loss: 2.3511953353881836
Validation loss: 2.132533347734841

Epoch: 6| Step: 3
Training loss: 1.3536630868911743
Validation loss: 2.1480539691063667

Epoch: 6| Step: 4
Training loss: 1.6685867309570312
Validation loss: 2.113267319176787

Epoch: 6| Step: 5
Training loss: 1.2413992881774902
Validation loss: 2.131909990823397

Epoch: 6| Step: 6
Training loss: 1.4101696014404297
Validation loss: 2.125191355264315

Epoch: 6| Step: 7
Training loss: 1.8801045417785645
Validation loss: 2.1096104421923236

Epoch: 6| Step: 8
Training loss: 1.5473239421844482
Validation loss: 2.101443067673714

Epoch: 6| Step: 9
Training loss: 2.4741322994232178
Validation loss: 2.1007261660791214

Epoch: 6| Step: 10
Training loss: 2.4850919246673584
Validation loss: 2.0793280319500993

Epoch: 6| Step: 11
Training loss: 1.6677322387695312
Validation loss: 2.096814960561773

Epoch: 6| Step: 12
Training loss: 1.9091730117797852
Validation loss: 2.102601692240725

Epoch: 6| Step: 13
Training loss: 1.9503350257873535
Validation loss: 2.117547529999928

Epoch: 318| Step: 0
Training loss: 1.3864290714263916
Validation loss: 2.137023525853311

Epoch: 6| Step: 1
Training loss: 2.158449649810791
Validation loss: 2.117757845950383

Epoch: 6| Step: 2
Training loss: 1.997380018234253
Validation loss: 2.1082117557525635

Epoch: 6| Step: 3
Training loss: 1.840157151222229
Validation loss: 2.1045878856412825

Epoch: 6| Step: 4
Training loss: 1.4116244316101074
Validation loss: 2.074752999890235

Epoch: 6| Step: 5
Training loss: 1.9267103672027588
Validation loss: 2.1129824474293697

Epoch: 6| Step: 6
Training loss: 1.6643753051757812
Validation loss: 2.0845273233229116

Epoch: 6| Step: 7
Training loss: 1.7163128852844238
Validation loss: 2.11345773871227

Epoch: 6| Step: 8
Training loss: 2.4720239639282227
Validation loss: 2.1262498312099005

Epoch: 6| Step: 9
Training loss: 2.042008638381958
Validation loss: 2.1276287776167675

Epoch: 6| Step: 10
Training loss: 1.9611704349517822
Validation loss: 2.125400981595439

Epoch: 6| Step: 11
Training loss: 1.8957078456878662
Validation loss: 2.13758711917426

Epoch: 6| Step: 12
Training loss: 1.4403529167175293
Validation loss: 2.146831217632499

Epoch: 6| Step: 13
Training loss: 1.3700250387191772
Validation loss: 2.1372491441747195

Epoch: 319| Step: 0
Training loss: 1.7357968091964722
Validation loss: 2.122235590411771

Epoch: 6| Step: 1
Training loss: 1.8101738691329956
Validation loss: 2.1694916307285266

Epoch: 6| Step: 2
Training loss: 2.3473758697509766
Validation loss: 2.134422720119517

Epoch: 6| Step: 3
Training loss: 1.7107337713241577
Validation loss: 2.1219643969689646

Epoch: 6| Step: 4
Training loss: 2.14223051071167
Validation loss: 2.1268411938862135

Epoch: 6| Step: 5
Training loss: 1.3227070569992065
Validation loss: 2.1076155208772227

Epoch: 6| Step: 6
Training loss: 1.4394716024398804
Validation loss: 2.1424208264197073

Epoch: 6| Step: 7
Training loss: 1.9968277215957642
Validation loss: 2.110520796109271

Epoch: 6| Step: 8
Training loss: 1.8790748119354248
Validation loss: 2.0959376545362574

Epoch: 6| Step: 9
Training loss: 1.693737268447876
Validation loss: 2.1068670813755324

Epoch: 6| Step: 10
Training loss: 1.70365571975708
Validation loss: 2.132339880030642

Epoch: 6| Step: 11
Training loss: 1.829777479171753
Validation loss: 2.125926644571366

Epoch: 6| Step: 12
Training loss: 1.7237052917480469
Validation loss: 2.1333099129379436

Epoch: 6| Step: 13
Training loss: 2.559354543685913
Validation loss: 2.0841493042566444

Epoch: 320| Step: 0
Training loss: 1.6842519044876099
Validation loss: 2.137308577055572

Epoch: 6| Step: 1
Training loss: 1.603097915649414
Validation loss: 2.132115516611325

Epoch: 6| Step: 2
Training loss: 2.20403790473938
Validation loss: 2.102304812400572

Epoch: 6| Step: 3
Training loss: 1.8837924003601074
Validation loss: 2.101035605194748

Epoch: 6| Step: 4
Training loss: 1.5686366558074951
Validation loss: 2.118168315579814

Epoch: 6| Step: 5
Training loss: 1.858245849609375
Validation loss: 2.121377937255367

Epoch: 6| Step: 6
Training loss: 1.8535728454589844
Validation loss: 2.1190395752588906

Epoch: 6| Step: 7
Training loss: 1.8286778926849365
Validation loss: 2.113039614051901

Epoch: 6| Step: 8
Training loss: 1.667746901512146
Validation loss: 2.1285056632052184

Epoch: 6| Step: 9
Training loss: 1.6375198364257812
Validation loss: 2.099468077382734

Epoch: 6| Step: 10
Training loss: 2.171914577484131
Validation loss: 2.133888521502095

Epoch: 6| Step: 11
Training loss: 2.143362522125244
Validation loss: 2.1014791098974084

Epoch: 6| Step: 12
Training loss: 1.7253321409225464
Validation loss: 2.1103389340062297

Epoch: 6| Step: 13
Training loss: 1.973543405532837
Validation loss: 2.100474969033272

Epoch: 321| Step: 0
Training loss: 1.7735095024108887
Validation loss: 2.091085366023484

Epoch: 6| Step: 1
Training loss: 2.537715196609497
Validation loss: 2.129071856057772

Epoch: 6| Step: 2
Training loss: 1.2170065641403198
Validation loss: 2.108265721669761

Epoch: 6| Step: 3
Training loss: 1.9542195796966553
Validation loss: 2.1215283639969362

Epoch: 6| Step: 4
Training loss: 2.0458755493164062
Validation loss: 2.1525256992668234

Epoch: 6| Step: 5
Training loss: 1.8402868509292603
Validation loss: 2.1228094780316917

Epoch: 6| Step: 6
Training loss: 1.6630892753601074
Validation loss: 2.117109703761275

Epoch: 6| Step: 7
Training loss: 1.653793454170227
Validation loss: 2.132385330815469

Epoch: 6| Step: 8
Training loss: 1.3904290199279785
Validation loss: 2.139175361202609

Epoch: 6| Step: 9
Training loss: 2.082012414932251
Validation loss: 2.1583893786194506

Epoch: 6| Step: 10
Training loss: 2.1801838874816895
Validation loss: 2.1214258440079226

Epoch: 6| Step: 11
Training loss: 1.4506611824035645
Validation loss: 2.154704386188138

Epoch: 6| Step: 12
Training loss: 2.2595088481903076
Validation loss: 2.158779546778689

Epoch: 6| Step: 13
Training loss: 1.416111946105957
Validation loss: 2.1307584124226726

Epoch: 322| Step: 0
Training loss: 1.8697139024734497
Validation loss: 2.1331902652658443

Epoch: 6| Step: 1
Training loss: 1.1280176639556885
Validation loss: 2.130898855065787

Epoch: 6| Step: 2
Training loss: 1.429955244064331
Validation loss: 2.1315878052865305

Epoch: 6| Step: 3
Training loss: 1.7700538635253906
Validation loss: 2.115338038372737

Epoch: 6| Step: 4
Training loss: 1.6780822277069092
Validation loss: 2.1156624465860348

Epoch: 6| Step: 5
Training loss: 2.460775136947632
Validation loss: 2.0706744476031234

Epoch: 6| Step: 6
Training loss: 2.1822688579559326
Validation loss: 2.0786010244841218

Epoch: 6| Step: 7
Training loss: 1.8674366474151611
Validation loss: 2.091989747939571

Epoch: 6| Step: 8
Training loss: 1.4861139059066772
Validation loss: 2.0713129915216917

Epoch: 6| Step: 9
Training loss: 2.1629586219787598
Validation loss: 2.072355984359659

Epoch: 6| Step: 10
Training loss: 1.8825792074203491
Validation loss: 2.0981291929880777

Epoch: 6| Step: 11
Training loss: 2.619137763977051
Validation loss: 2.078219211229714

Epoch: 6| Step: 12
Training loss: 1.7276852130889893
Validation loss: 2.1108814798375612

Epoch: 6| Step: 13
Training loss: 1.672017216682434
Validation loss: 2.1063331198948685

Epoch: 323| Step: 0
Training loss: 2.158151626586914
Validation loss: 2.1145771498321206

Epoch: 6| Step: 1
Training loss: 1.6936991214752197
Validation loss: 2.1326783703219507

Epoch: 6| Step: 2
Training loss: 1.4405884742736816
Validation loss: 2.1246927604880383

Epoch: 6| Step: 3
Training loss: 1.8809469938278198
Validation loss: 2.1362567229937484

Epoch: 6| Step: 4
Training loss: 1.6916275024414062
Validation loss: 2.099618552833475

Epoch: 6| Step: 5
Training loss: 1.9082188606262207
Validation loss: 2.1138890379218647

Epoch: 6| Step: 6
Training loss: 1.3183422088623047
Validation loss: 2.1264881831343456

Epoch: 6| Step: 7
Training loss: 2.7679433822631836
Validation loss: 2.1351778071413756

Epoch: 6| Step: 8
Training loss: 1.4864015579223633
Validation loss: 2.1304863575966126

Epoch: 6| Step: 9
Training loss: 1.9722551107406616
Validation loss: 2.135682882801179

Epoch: 6| Step: 10
Training loss: 1.1344785690307617
Validation loss: 2.1564010650880876

Epoch: 6| Step: 11
Training loss: 1.5320065021514893
Validation loss: 2.147824720669818

Epoch: 6| Step: 12
Training loss: 2.2545382976531982
Validation loss: 2.1423564751942954

Epoch: 6| Step: 13
Training loss: 2.252169609069824
Validation loss: 2.116942278800472

Epoch: 324| Step: 0
Training loss: 1.7384709119796753
Validation loss: 2.1415676391252907

Epoch: 6| Step: 1
Training loss: 1.4426350593566895
Validation loss: 2.144186048097508

Epoch: 6| Step: 2
Training loss: 2.1515650749206543
Validation loss: 2.134658396884959

Epoch: 6| Step: 3
Training loss: 1.5599026679992676
Validation loss: 2.139938586501665

Epoch: 6| Step: 4
Training loss: 1.9985182285308838
Validation loss: 2.1547891632203133

Epoch: 6| Step: 5
Training loss: 2.2920162677764893
Validation loss: 2.1151710992218344

Epoch: 6| Step: 6
Training loss: 0.8095395565032959
Validation loss: 2.125396720824703

Epoch: 6| Step: 7
Training loss: 1.74020516872406
Validation loss: 2.129656308440752

Epoch: 6| Step: 8
Training loss: 2.04085636138916
Validation loss: 2.1098364527507494

Epoch: 6| Step: 9
Training loss: 1.9551125764846802
Validation loss: 2.094207602162515

Epoch: 6| Step: 10
Training loss: 1.7814152240753174
Validation loss: 2.112450547115777

Epoch: 6| Step: 11
Training loss: 1.339501976966858
Validation loss: 2.097517858269394

Epoch: 6| Step: 12
Training loss: 2.4135003089904785
Validation loss: 2.117444602392053

Epoch: 6| Step: 13
Training loss: 2.744569778442383
Validation loss: 2.0863101149118073

Epoch: 325| Step: 0
Training loss: 1.6375596523284912
Validation loss: 2.082216852454729

Epoch: 6| Step: 1
Training loss: 1.8370380401611328
Validation loss: 2.127832180710249

Epoch: 6| Step: 2
Training loss: 1.712817907333374
Validation loss: 2.11149832253815

Epoch: 6| Step: 3
Training loss: 1.9780299663543701
Validation loss: 2.0660934371332966

Epoch: 6| Step: 4
Training loss: 1.9216355085372925
Validation loss: 2.116698449657809

Epoch: 6| Step: 5
Training loss: 1.2526280879974365
Validation loss: 2.1113957743490896

Epoch: 6| Step: 6
Training loss: 0.8549236059188843
Validation loss: 2.120955636424403

Epoch: 6| Step: 7
Training loss: 1.4678423404693604
Validation loss: 2.091813774519069

Epoch: 6| Step: 8
Training loss: 1.8322092294692993
Validation loss: 2.1118172035422376

Epoch: 6| Step: 9
Training loss: 1.7520567178726196
Validation loss: 2.1026265941640383

Epoch: 6| Step: 10
Training loss: 2.208311080932617
Validation loss: 2.136269695015364

Epoch: 6| Step: 11
Training loss: 1.9961671829223633
Validation loss: 2.052404203722554

Epoch: 6| Step: 12
Training loss: 2.670670986175537
Validation loss: 2.110657112572783

Epoch: 6| Step: 13
Training loss: 3.0784268379211426
Validation loss: 2.0802726643059843

Epoch: 326| Step: 0
Training loss: 2.081965923309326
Validation loss: 2.1060192866991927

Epoch: 6| Step: 1
Training loss: 1.9258335828781128
Validation loss: 2.123009030536939

Epoch: 6| Step: 2
Training loss: 1.2218953371047974
Validation loss: 2.0920062283033967

Epoch: 6| Step: 3
Training loss: 2.002603530883789
Validation loss: 2.112183347825081

Epoch: 6| Step: 4
Training loss: 2.7777156829833984
Validation loss: 2.144839782868662

Epoch: 6| Step: 5
Training loss: 1.7791948318481445
Validation loss: 2.1102432384285876

Epoch: 6| Step: 6
Training loss: 1.6902925968170166
Validation loss: 2.0732280669673795

Epoch: 6| Step: 7
Training loss: 1.5698754787445068
Validation loss: 2.113504711017814

Epoch: 6| Step: 8
Training loss: 1.7040138244628906
Validation loss: 2.1041568991958455

Epoch: 6| Step: 9
Training loss: 1.984776258468628
Validation loss: 2.1126358560336533

Epoch: 6| Step: 10
Training loss: 1.4434831142425537
Validation loss: 2.1280471970958095

Epoch: 6| Step: 11
Training loss: 1.9069218635559082
Validation loss: 2.1258899011919574

Epoch: 6| Step: 12
Training loss: 1.36721932888031
Validation loss: 2.1351115293400262

Epoch: 6| Step: 13
Training loss: 1.3660597801208496
Validation loss: 2.1249125247360556

Epoch: 327| Step: 0
Training loss: 1.8247365951538086
Validation loss: 2.1184699509733464

Epoch: 6| Step: 1
Training loss: 1.4742460250854492
Validation loss: 2.135008824768887

Epoch: 6| Step: 2
Training loss: 1.4322779178619385
Validation loss: 2.1647561532194897

Epoch: 6| Step: 3
Training loss: 2.29439115524292
Validation loss: 2.13723248563787

Epoch: 6| Step: 4
Training loss: 1.5783072710037231
Validation loss: 2.1500399676702355

Epoch: 6| Step: 5
Training loss: 1.8086087703704834
Validation loss: 2.1313484740513626

Epoch: 6| Step: 6
Training loss: 1.1453274488449097
Validation loss: 2.0860562093796267

Epoch: 6| Step: 7
Training loss: 2.2021701335906982
Validation loss: 2.1180862752340173

Epoch: 6| Step: 8
Training loss: 1.694603681564331
Validation loss: 2.1516475959490706

Epoch: 6| Step: 9
Training loss: 1.7932473421096802
Validation loss: 2.1502578027786745

Epoch: 6| Step: 10
Training loss: 1.5966061353683472
Validation loss: 2.116481283659576

Epoch: 6| Step: 11
Training loss: 2.138632297515869
Validation loss: 2.1217345409495856

Epoch: 6| Step: 12
Training loss: 2.172250270843506
Validation loss: 2.145919825441094

Epoch: 6| Step: 13
Training loss: 2.755707025527954
Validation loss: 2.1106022198994956

Epoch: 328| Step: 0
Training loss: 1.852405071258545
Validation loss: 2.119975507900279

Epoch: 6| Step: 1
Training loss: 2.155039072036743
Validation loss: 2.0998038502149683

Epoch: 6| Step: 2
Training loss: 1.806025743484497
Validation loss: 2.114417706766436

Epoch: 6| Step: 3
Training loss: 1.4825897216796875
Validation loss: 2.1070142253752677

Epoch: 6| Step: 4
Training loss: 1.4630780220031738
Validation loss: 2.105379885242831

Epoch: 6| Step: 5
Training loss: 2.1000540256500244
Validation loss: 2.0918638539570633

Epoch: 6| Step: 6
Training loss: 2.170321464538574
Validation loss: 2.0751558132069086

Epoch: 6| Step: 7
Training loss: 1.5409997701644897
Validation loss: 2.0902897824523268

Epoch: 6| Step: 8
Training loss: 1.5926188230514526
Validation loss: 2.081085740879018

Epoch: 6| Step: 9
Training loss: 1.2844328880310059
Validation loss: 2.0906374428861882

Epoch: 6| Step: 10
Training loss: 2.6149890422821045
Validation loss: 2.0924862379668863

Epoch: 6| Step: 11
Training loss: 1.6062918901443481
Validation loss: 2.0513972877174296

Epoch: 6| Step: 12
Training loss: 1.7573015689849854
Validation loss: 2.120679973274149

Epoch: 6| Step: 13
Training loss: 2.2086527347564697
Validation loss: 2.0794383389975435

Epoch: 329| Step: 0
Training loss: 1.7590121030807495
Validation loss: 2.1250214153720486

Epoch: 6| Step: 1
Training loss: 1.1500887870788574
Validation loss: 2.1113506222283966

Epoch: 6| Step: 2
Training loss: 1.6267048120498657
Validation loss: 2.1293089415437434

Epoch: 6| Step: 3
Training loss: 2.181934356689453
Validation loss: 2.111182301275192

Epoch: 6| Step: 4
Training loss: 1.9217479228973389
Validation loss: 2.1140698681595507

Epoch: 6| Step: 5
Training loss: 1.2809020280838013
Validation loss: 2.0915035329839236

Epoch: 6| Step: 6
Training loss: 1.6705299615859985
Validation loss: 2.065868402040133

Epoch: 6| Step: 7
Training loss: 2.067638635635376
Validation loss: 2.119977266557755

Epoch: 6| Step: 8
Training loss: 1.8916523456573486
Validation loss: 2.1624604527668287

Epoch: 6| Step: 9
Training loss: 1.8411222696304321
Validation loss: 2.12108217259889

Epoch: 6| Step: 10
Training loss: 1.932086706161499
Validation loss: 2.114207212642957

Epoch: 6| Step: 11
Training loss: 1.2608058452606201
Validation loss: 2.1673359870910645

Epoch: 6| Step: 12
Training loss: 2.550508499145508
Validation loss: 2.1493450826214207

Epoch: 6| Step: 13
Training loss: 2.8113932609558105
Validation loss: 2.145156329677951

Epoch: 330| Step: 0
Training loss: 1.7373958826065063
Validation loss: 2.140526392126596

Epoch: 6| Step: 1
Training loss: 1.2313008308410645
Validation loss: 2.125372766166605

Epoch: 6| Step: 2
Training loss: 1.7363011837005615
Validation loss: 2.1255937250711585

Epoch: 6| Step: 3
Training loss: 2.4922759532928467
Validation loss: 2.1078022192883235

Epoch: 6| Step: 4
Training loss: 1.9822114706039429
Validation loss: 2.1003099936310963

Epoch: 6| Step: 5
Training loss: 1.8399410247802734
Validation loss: 2.10155842637503

Epoch: 6| Step: 6
Training loss: 1.114449143409729
Validation loss: 2.1043547404709684

Epoch: 6| Step: 7
Training loss: 2.0837368965148926
Validation loss: 2.098909342160789

Epoch: 6| Step: 8
Training loss: 1.2523771524429321
Validation loss: 2.144150480147331

Epoch: 6| Step: 9
Training loss: 1.998056173324585
Validation loss: 2.0931708889622844

Epoch: 6| Step: 10
Training loss: 1.939762830734253
Validation loss: 2.0898243919495614

Epoch: 6| Step: 11
Training loss: 2.0193114280700684
Validation loss: 2.0764189753481137

Epoch: 6| Step: 12
Training loss: 1.850846290588379
Validation loss: 2.1207044457876556

Epoch: 6| Step: 13
Training loss: 1.9119973182678223
Validation loss: 2.082768505619418

Epoch: 331| Step: 0
Training loss: 2.0192906856536865
Validation loss: 2.0596378413579797

Epoch: 6| Step: 1
Training loss: 1.7115309238433838
Validation loss: 2.093240730224117

Epoch: 6| Step: 2
Training loss: 1.938315987586975
Validation loss: 2.1022807282786213

Epoch: 6| Step: 3
Training loss: 2.3402976989746094
Validation loss: 2.1047135770961805

Epoch: 6| Step: 4
Training loss: 1.7394309043884277
Validation loss: 2.1174907761235393

Epoch: 6| Step: 5
Training loss: 0.7877281904220581
Validation loss: 2.1000212033589682

Epoch: 6| Step: 6
Training loss: 1.4812848567962646
Validation loss: 2.1231774835176367

Epoch: 6| Step: 7
Training loss: 2.108825922012329
Validation loss: 2.133808430805001

Epoch: 6| Step: 8
Training loss: 2.075843334197998
Validation loss: 2.1414051748091176

Epoch: 6| Step: 9
Training loss: 2.044783592224121
Validation loss: 2.132486903539268

Epoch: 6| Step: 10
Training loss: 1.8387279510498047
Validation loss: 2.1446982506782777

Epoch: 6| Step: 11
Training loss: 2.580002784729004
Validation loss: 2.151014648458009

Epoch: 6| Step: 12
Training loss: 1.3131365776062012
Validation loss: 2.1732351344118834

Epoch: 6| Step: 13
Training loss: 0.9950226545333862
Validation loss: 2.15424903105664

Epoch: 332| Step: 0
Training loss: 2.179750442504883
Validation loss: 2.1610952910556587

Epoch: 6| Step: 1
Training loss: 1.5400433540344238
Validation loss: 2.148981216133282

Epoch: 6| Step: 2
Training loss: 1.7575628757476807
Validation loss: 2.16347865135439

Epoch: 6| Step: 3
Training loss: 1.9196538925170898
Validation loss: 2.135260502497355

Epoch: 6| Step: 4
Training loss: 2.1262893676757812
Validation loss: 2.102800497444727

Epoch: 6| Step: 5
Training loss: 1.6801425218582153
Validation loss: 2.0854453438071796

Epoch: 6| Step: 6
Training loss: 1.2659326791763306
Validation loss: 2.0886684028051232

Epoch: 6| Step: 7
Training loss: 1.4735089540481567
Validation loss: 2.127185662587484

Epoch: 6| Step: 8
Training loss: 1.7054386138916016
Validation loss: 2.0990282117679553

Epoch: 6| Step: 9
Training loss: 1.8603756427764893
Validation loss: 2.0889431866266395

Epoch: 6| Step: 10
Training loss: 1.4403585195541382
Validation loss: 2.1101134541214153

Epoch: 6| Step: 11
Training loss: 2.3326520919799805
Validation loss: 2.125151470143308

Epoch: 6| Step: 12
Training loss: 2.199920654296875
Validation loss: 2.0759536835455124

Epoch: 6| Step: 13
Training loss: 2.08559513092041
Validation loss: 2.1473378699312926

Epoch: 333| Step: 0
Training loss: 1.723533272743225
Validation loss: 2.1348161261568785

Epoch: 6| Step: 1
Training loss: 2.3654932975769043
Validation loss: 2.1124002997593214

Epoch: 6| Step: 2
Training loss: 2.2845144271850586
Validation loss: 2.1438736043950564

Epoch: 6| Step: 3
Training loss: 1.886826515197754
Validation loss: 2.1616460584825083

Epoch: 6| Step: 4
Training loss: 1.6743873357772827
Validation loss: 2.15460636795208

Epoch: 6| Step: 5
Training loss: 1.3471026420593262
Validation loss: 2.129944637257566

Epoch: 6| Step: 6
Training loss: 1.2913665771484375
Validation loss: 2.143327454084991

Epoch: 6| Step: 7
Training loss: 2.113292694091797
Validation loss: 2.159817559744722

Epoch: 6| Step: 8
Training loss: 1.6012961864471436
Validation loss: 2.1372474880628687

Epoch: 6| Step: 9
Training loss: 1.4458074569702148
Validation loss: 2.1125874160438456

Epoch: 6| Step: 10
Training loss: 1.741989254951477
Validation loss: 2.100790813405027

Epoch: 6| Step: 11
Training loss: 1.611551284790039
Validation loss: 2.11757981136281

Epoch: 6| Step: 12
Training loss: 1.7624359130859375
Validation loss: 2.1574354479389806

Epoch: 6| Step: 13
Training loss: 2.7278976440429688
Validation loss: 2.110199564246721

Epoch: 334| Step: 0
Training loss: 1.487062692642212
Validation loss: 2.127821078864477

Epoch: 6| Step: 1
Training loss: 1.415279746055603
Validation loss: 2.124424902341699

Epoch: 6| Step: 2
Training loss: 1.2082926034927368
Validation loss: 2.1262028653134584

Epoch: 6| Step: 3
Training loss: 2.332287311553955
Validation loss: 2.124959748278382

Epoch: 6| Step: 4
Training loss: 2.254085063934326
Validation loss: 2.1091070239261915

Epoch: 6| Step: 5
Training loss: 2.0617918968200684
Validation loss: 2.104636856304702

Epoch: 6| Step: 6
Training loss: 1.7892515659332275
Validation loss: 2.1044155423359205

Epoch: 6| Step: 7
Training loss: 1.7600927352905273
Validation loss: 2.1187055495477494

Epoch: 6| Step: 8
Training loss: 1.8446500301361084
Validation loss: 2.1285624452816543

Epoch: 6| Step: 9
Training loss: 2.0654702186584473
Validation loss: 2.1069870020753596

Epoch: 6| Step: 10
Training loss: 2.046901226043701
Validation loss: 2.099565326526601

Epoch: 6| Step: 11
Training loss: 1.9463787078857422
Validation loss: 2.115024471795687

Epoch: 6| Step: 12
Training loss: 1.62570321559906
Validation loss: 2.1165263460528467

Epoch: 6| Step: 13
Training loss: 0.8828637003898621
Validation loss: 2.125054027444573

Epoch: 335| Step: 0
Training loss: 1.5547105073928833
Validation loss: 2.108094166683894

Epoch: 6| Step: 1
Training loss: 1.4651024341583252
Validation loss: 2.108685388359972

Epoch: 6| Step: 2
Training loss: 1.5497708320617676
Validation loss: 2.1255084763291063

Epoch: 6| Step: 3
Training loss: 2.1201348304748535
Validation loss: 2.1313510710193264

Epoch: 6| Step: 4
Training loss: 1.6844873428344727
Validation loss: 2.1314930377467984

Epoch: 6| Step: 5
Training loss: 2.1754603385925293
Validation loss: 2.0901585855791645

Epoch: 6| Step: 6
Training loss: 1.4750697612762451
Validation loss: 2.1115954511909076

Epoch: 6| Step: 7
Training loss: 2.2551584243774414
Validation loss: 2.105985023642099

Epoch: 6| Step: 8
Training loss: 1.8516080379486084
Validation loss: 2.1299602318835515

Epoch: 6| Step: 9
Training loss: 2.2974064350128174
Validation loss: 2.113873158731768

Epoch: 6| Step: 10
Training loss: 2.1389431953430176
Validation loss: 2.0894945001089447

Epoch: 6| Step: 11
Training loss: 1.3326265811920166
Validation loss: 2.1280882563642276

Epoch: 6| Step: 12
Training loss: 1.6286311149597168
Validation loss: 2.135066432337607

Epoch: 6| Step: 13
Training loss: 1.5903202295303345
Validation loss: 2.087573648780905

Epoch: 336| Step: 0
Training loss: 2.397948741912842
Validation loss: 2.1061772479805896

Epoch: 6| Step: 1
Training loss: 1.1998999118804932
Validation loss: 2.1220996533670733

Epoch: 6| Step: 2
Training loss: 1.5159311294555664
Validation loss: 2.1377032008222354

Epoch: 6| Step: 3
Training loss: 2.4964470863342285
Validation loss: 2.1166254474270727

Epoch: 6| Step: 4
Training loss: 2.103489398956299
Validation loss: 2.1063504244691584

Epoch: 6| Step: 5
Training loss: 2.2178454399108887
Validation loss: 2.1102567436874553

Epoch: 6| Step: 6
Training loss: 1.1998240947723389
Validation loss: 2.1164097785949707

Epoch: 6| Step: 7
Training loss: 1.6082916259765625
Validation loss: 2.1313905292941677

Epoch: 6| Step: 8
Training loss: 1.8146463632583618
Validation loss: 2.1224565185526365

Epoch: 6| Step: 9
Training loss: 1.9772623777389526
Validation loss: 2.0911376117378153

Epoch: 6| Step: 10
Training loss: 0.9188277125358582
Validation loss: 2.1081342850961993

Epoch: 6| Step: 11
Training loss: 2.1794304847717285
Validation loss: 2.105481090084199

Epoch: 6| Step: 12
Training loss: 2.1042990684509277
Validation loss: 2.089708197501398

Epoch: 6| Step: 13
Training loss: 1.08393394947052
Validation loss: 2.074126938337921

Epoch: 337| Step: 0
Training loss: 2.4894521236419678
Validation loss: 2.0778728326161704

Epoch: 6| Step: 1
Training loss: 1.6284481287002563
Validation loss: 2.109634291741156

Epoch: 6| Step: 2
Training loss: 2.041449546813965
Validation loss: 2.086517713403189

Epoch: 6| Step: 3
Training loss: 1.5506970882415771
Validation loss: 2.1155245457926104

Epoch: 6| Step: 4
Training loss: 1.9069619178771973
Validation loss: 2.1087093558362735

Epoch: 6| Step: 5
Training loss: 2.1096434593200684
Validation loss: 2.104413551668967

Epoch: 6| Step: 6
Training loss: 1.2403831481933594
Validation loss: 2.102630438343171

Epoch: 6| Step: 7
Training loss: 1.880363941192627
Validation loss: 2.1468894917477845

Epoch: 6| Step: 8
Training loss: 1.57765793800354
Validation loss: 2.0737742685502574

Epoch: 6| Step: 9
Training loss: 1.4851603507995605
Validation loss: 2.1385681962454193

Epoch: 6| Step: 10
Training loss: 1.9891384840011597
Validation loss: 2.167809150552237

Epoch: 6| Step: 11
Training loss: 1.5369622707366943
Validation loss: 2.119758176547225

Epoch: 6| Step: 12
Training loss: 1.4462428092956543
Validation loss: 2.135492435065649

Epoch: 6| Step: 13
Training loss: 2.1367409229278564
Validation loss: 2.139918483713622

Epoch: 338| Step: 0
Training loss: 2.055572509765625
Validation loss: 2.183259210278911

Epoch: 6| Step: 1
Training loss: 2.110111713409424
Validation loss: 2.112394348267586

Epoch: 6| Step: 2
Training loss: 1.7447457313537598
Validation loss: 2.135956146383798

Epoch: 6| Step: 3
Training loss: 1.5546958446502686
Validation loss: 2.147583323140298

Epoch: 6| Step: 4
Training loss: 1.7668856382369995
Validation loss: 2.1534425673946256

Epoch: 6| Step: 5
Training loss: 2.1067912578582764
Validation loss: 2.1176982720692954

Epoch: 6| Step: 6
Training loss: 1.6526436805725098
Validation loss: 2.173034780768938

Epoch: 6| Step: 7
Training loss: 1.6565930843353271
Validation loss: 2.1588394949513097

Epoch: 6| Step: 8
Training loss: 2.219534158706665
Validation loss: 2.1503377037663616

Epoch: 6| Step: 9
Training loss: 1.111843466758728
Validation loss: 2.128788850640738

Epoch: 6| Step: 10
Training loss: 2.266143321990967
Validation loss: 2.1324267131026073

Epoch: 6| Step: 11
Training loss: 1.4652681350708008
Validation loss: 2.150807011512018

Epoch: 6| Step: 12
Training loss: 1.7366178035736084
Validation loss: 2.139765365149385

Epoch: 6| Step: 13
Training loss: 2.1235601902008057
Validation loss: 2.1127262269296954

Epoch: 339| Step: 0
Training loss: 2.027949333190918
Validation loss: 2.102519727522327

Epoch: 6| Step: 1
Training loss: 1.5261499881744385
Validation loss: 2.109055516540363

Epoch: 6| Step: 2
Training loss: 2.4810338020324707
Validation loss: 2.0947464512240503

Epoch: 6| Step: 3
Training loss: 1.852510929107666
Validation loss: 2.0976873854155182

Epoch: 6| Step: 4
Training loss: 1.9382504224777222
Validation loss: 2.1302196684704033

Epoch: 6| Step: 5
Training loss: 1.8446630239486694
Validation loss: 2.1138295717136835

Epoch: 6| Step: 6
Training loss: 1.4928712844848633
Validation loss: 2.056335885037658

Epoch: 6| Step: 7
Training loss: 1.452658772468567
Validation loss: 2.121718757896013

Epoch: 6| Step: 8
Training loss: 1.594626784324646
Validation loss: 2.079909268245902

Epoch: 6| Step: 9
Training loss: 2.064251184463501
Validation loss: 2.0776735198113228

Epoch: 6| Step: 10
Training loss: 1.1389411687850952
Validation loss: 2.0837396908831853

Epoch: 6| Step: 11
Training loss: 2.4490647315979004
Validation loss: 2.110129997294436

Epoch: 6| Step: 12
Training loss: 1.4471771717071533
Validation loss: 2.0881202015825497

Epoch: 6| Step: 13
Training loss: 1.7438091039657593
Validation loss: 2.0645738224829397

Epoch: 340| Step: 0
Training loss: 2.046029567718506
Validation loss: 2.098013153640173

Epoch: 6| Step: 1
Training loss: 2.280536413192749
Validation loss: 2.08241040988635

Epoch: 6| Step: 2
Training loss: 1.896328091621399
Validation loss: 2.139763597519167

Epoch: 6| Step: 3
Training loss: 1.626645803451538
Validation loss: 2.1056991161838656

Epoch: 6| Step: 4
Training loss: 2.4203343391418457
Validation loss: 2.1173830109257854

Epoch: 6| Step: 5
Training loss: 1.5929203033447266
Validation loss: 2.146243320998325

Epoch: 6| Step: 6
Training loss: 1.1869776248931885
Validation loss: 2.115763007953603

Epoch: 6| Step: 7
Training loss: 1.7652397155761719
Validation loss: 2.144503434499105

Epoch: 6| Step: 8
Training loss: 1.3107757568359375
Validation loss: 2.127985869684527

Epoch: 6| Step: 9
Training loss: 1.2425618171691895
Validation loss: 2.100940878673266

Epoch: 6| Step: 10
Training loss: 2.499713659286499
Validation loss: 2.156194640744117

Epoch: 6| Step: 11
Training loss: 1.4569156169891357
Validation loss: 2.157802853533017

Epoch: 6| Step: 12
Training loss: 1.7465311288833618
Validation loss: 2.15575377146403

Epoch: 6| Step: 13
Training loss: 1.92476224899292
Validation loss: 2.169736864746258

Epoch: 341| Step: 0
Training loss: 1.8437368869781494
Validation loss: 2.163033543094512

Epoch: 6| Step: 1
Training loss: 1.2493406534194946
Validation loss: 2.171292669029646

Epoch: 6| Step: 2
Training loss: 2.151318073272705
Validation loss: 2.190314708217498

Epoch: 6| Step: 3
Training loss: 1.849729061126709
Validation loss: 2.1710800509299

Epoch: 6| Step: 4
Training loss: 1.8042556047439575
Validation loss: 2.1743927565954064

Epoch: 6| Step: 5
Training loss: 1.2185707092285156
Validation loss: 2.1846612268878567

Epoch: 6| Step: 6
Training loss: 1.894434928894043
Validation loss: 2.187959481311101

Epoch: 6| Step: 7
Training loss: 2.142240047454834
Validation loss: 2.192380908996828

Epoch: 6| Step: 8
Training loss: 1.8259351253509521
Validation loss: 2.148756465604228

Epoch: 6| Step: 9
Training loss: 1.8257215023040771
Validation loss: 2.1333448553598053

Epoch: 6| Step: 10
Training loss: 1.6220102310180664
Validation loss: 2.1588076250527495

Epoch: 6| Step: 11
Training loss: 2.0679094791412354
Validation loss: 2.1577747098861204

Epoch: 6| Step: 12
Training loss: 1.6614108085632324
Validation loss: 2.133880002524263

Epoch: 6| Step: 13
Training loss: 1.9089107513427734
Validation loss: 2.1169025333978797

Epoch: 342| Step: 0
Training loss: 1.639845848083496
Validation loss: 2.1401141138486963

Epoch: 6| Step: 1
Training loss: 2.6785738468170166
Validation loss: 2.141011652126107

Epoch: 6| Step: 2
Training loss: 2.286428928375244
Validation loss: 2.137536794908585

Epoch: 6| Step: 3
Training loss: 1.5259357690811157
Validation loss: 2.11962987274252

Epoch: 6| Step: 4
Training loss: 1.0668927431106567
Validation loss: 2.133634332687624

Epoch: 6| Step: 5
Training loss: 2.0453619956970215
Validation loss: 2.0864092790952293

Epoch: 6| Step: 6
Training loss: 1.9030437469482422
Validation loss: 2.090166905874847

Epoch: 6| Step: 7
Training loss: 1.0783321857452393
Validation loss: 2.0694871435883226

Epoch: 6| Step: 8
Training loss: 1.2004573345184326
Validation loss: 2.0819584169695453

Epoch: 6| Step: 9
Training loss: 1.7314586639404297
Validation loss: 2.063123418438819

Epoch: 6| Step: 10
Training loss: 1.7189302444458008
Validation loss: 2.1276575032100884

Epoch: 6| Step: 11
Training loss: 2.121307373046875
Validation loss: 2.1198037439777004

Epoch: 6| Step: 12
Training loss: 1.9270274639129639
Validation loss: 2.1245759674297866

Epoch: 6| Step: 13
Training loss: 2.2652482986450195
Validation loss: 2.0903885377350675

Epoch: 343| Step: 0
Training loss: 1.691176176071167
Validation loss: 2.1215399888253983

Epoch: 6| Step: 1
Training loss: 1.629433512687683
Validation loss: 2.0883613606934905

Epoch: 6| Step: 2
Training loss: 1.5091025829315186
Validation loss: 2.1409639671284664

Epoch: 6| Step: 3
Training loss: 2.021043300628662
Validation loss: 2.144913693910004

Epoch: 6| Step: 4
Training loss: 2.4654288291931152
Validation loss: 2.125250859927106

Epoch: 6| Step: 5
Training loss: 1.7579123973846436
Validation loss: 2.115128490232652

Epoch: 6| Step: 6
Training loss: 1.4608006477355957
Validation loss: 2.1172573361345517

Epoch: 6| Step: 7
Training loss: 2.0310311317443848
Validation loss: 2.106620519391952

Epoch: 6| Step: 8
Training loss: 1.6450440883636475
Validation loss: 2.141142902835723

Epoch: 6| Step: 9
Training loss: 1.3916356563568115
Validation loss: 2.104431608671783

Epoch: 6| Step: 10
Training loss: 1.633878469467163
Validation loss: 2.126404308503674

Epoch: 6| Step: 11
Training loss: 2.1401591300964355
Validation loss: 2.115848897605814

Epoch: 6| Step: 12
Training loss: 1.4319939613342285
Validation loss: 2.0991006666614163

Epoch: 6| Step: 13
Training loss: 2.1210243701934814
Validation loss: 2.0829267501831055

Epoch: 344| Step: 0
Training loss: 1.8618625402450562
Validation loss: 2.1128087812854397

Epoch: 6| Step: 1
Training loss: 1.3163975477218628
Validation loss: 2.134098010678445

Epoch: 6| Step: 2
Training loss: 1.439025640487671
Validation loss: 2.074740207323464

Epoch: 6| Step: 3
Training loss: 1.4606072902679443
Validation loss: 2.117830402107649

Epoch: 6| Step: 4
Training loss: 2.020026206970215
Validation loss: 2.1463486994466474

Epoch: 6| Step: 5
Training loss: 2.5344786643981934
Validation loss: 2.1183368031696608

Epoch: 6| Step: 6
Training loss: 2.037179946899414
Validation loss: 2.1281976456283243

Epoch: 6| Step: 7
Training loss: 1.3243181705474854
Validation loss: 2.124987235633276

Epoch: 6| Step: 8
Training loss: 1.0862219333648682
Validation loss: 2.1481394434487946

Epoch: 6| Step: 9
Training loss: 2.323411464691162
Validation loss: 2.1142548694405505

Epoch: 6| Step: 10
Training loss: 1.2988426685333252
Validation loss: 2.1113628366942048

Epoch: 6| Step: 11
Training loss: 2.472996711730957
Validation loss: 2.108710722256732

Epoch: 6| Step: 12
Training loss: 1.5026893615722656
Validation loss: 2.131171549520185

Epoch: 6| Step: 13
Training loss: 2.0988616943359375
Validation loss: 2.146476235440982

Epoch: 345| Step: 0
Training loss: 1.6430528163909912
Validation loss: 2.10058775255757

Epoch: 6| Step: 1
Training loss: 1.4820877313613892
Validation loss: 2.135169936764625

Epoch: 6| Step: 2
Training loss: 1.3385502099990845
Validation loss: 2.143119381320092

Epoch: 6| Step: 3
Training loss: 1.957092046737671
Validation loss: 2.133282712710801

Epoch: 6| Step: 4
Training loss: 1.575437307357788
Validation loss: 2.138598063940643

Epoch: 6| Step: 5
Training loss: 1.5773072242736816
Validation loss: 2.1096605280394196

Epoch: 6| Step: 6
Training loss: 2.536755323410034
Validation loss: 2.135000551900556

Epoch: 6| Step: 7
Training loss: 1.8369460105895996
Validation loss: 2.122721779731012

Epoch: 6| Step: 8
Training loss: 2.4735937118530273
Validation loss: 2.105896347312517

Epoch: 6| Step: 9
Training loss: 2.0472817420959473
Validation loss: 2.114988714136103

Epoch: 6| Step: 10
Training loss: 2.0257608890533447
Validation loss: 2.097878656079692

Epoch: 6| Step: 11
Training loss: 1.429255485534668
Validation loss: 2.1233434292577926

Epoch: 6| Step: 12
Training loss: 1.4997901916503906
Validation loss: 2.1212494937322472

Epoch: 6| Step: 13
Training loss: 1.5368523597717285
Validation loss: 2.1094835778718353

Epoch: 346| Step: 0
Training loss: 1.368574619293213
Validation loss: 2.118424795007193

Epoch: 6| Step: 1
Training loss: 2.3116455078125
Validation loss: 2.1262469394232637

Epoch: 6| Step: 2
Training loss: 1.5666989088058472
Validation loss: 2.091878301353865

Epoch: 6| Step: 3
Training loss: 2.0508646965026855
Validation loss: 2.0820732898609613

Epoch: 6| Step: 4
Training loss: 1.2727305889129639
Validation loss: 2.0800609780896093

Epoch: 6| Step: 5
Training loss: 2.1127729415893555
Validation loss: 2.1171547135999127

Epoch: 6| Step: 6
Training loss: 1.9328761100769043
Validation loss: 2.110387973887946

Epoch: 6| Step: 7
Training loss: 1.4749048948287964
Validation loss: 2.0938108723650695

Epoch: 6| Step: 8
Training loss: 1.5825434923171997
Validation loss: 2.101671190672023

Epoch: 6| Step: 9
Training loss: 1.4341681003570557
Validation loss: 2.1390199507436445

Epoch: 6| Step: 10
Training loss: 2.4718332290649414
Validation loss: 2.1052611463813373

Epoch: 6| Step: 11
Training loss: 1.4090960025787354
Validation loss: 2.1018389988971014

Epoch: 6| Step: 12
Training loss: 1.8053276538848877
Validation loss: 2.109318238432689

Epoch: 6| Step: 13
Training loss: 1.7286545038223267
Validation loss: 2.1514555959291357

Epoch: 347| Step: 0
Training loss: 2.0046844482421875
Validation loss: 2.1078497607220887

Epoch: 6| Step: 1
Training loss: 1.7390786409378052
Validation loss: 2.1288716318786784

Epoch: 6| Step: 2
Training loss: 2.137908458709717
Validation loss: 2.087773379459176

Epoch: 6| Step: 3
Training loss: 2.235550880432129
Validation loss: 2.1190305807257213

Epoch: 6| Step: 4
Training loss: 1.807328462600708
Validation loss: 2.0809957083835395

Epoch: 6| Step: 5
Training loss: 1.6345350742340088
Validation loss: 2.10031920607372

Epoch: 6| Step: 6
Training loss: 1.680556058883667
Validation loss: 2.1121377765491443

Epoch: 6| Step: 7
Training loss: 1.9703395366668701
Validation loss: 2.1181735479703514

Epoch: 6| Step: 8
Training loss: 1.1327649354934692
Validation loss: 2.1159796740419123

Epoch: 6| Step: 9
Training loss: 1.8770942687988281
Validation loss: 2.100467328102358

Epoch: 6| Step: 10
Training loss: 1.925647497177124
Validation loss: 2.0813190860133015

Epoch: 6| Step: 11
Training loss: 1.5807483196258545
Validation loss: 2.138143882956556

Epoch: 6| Step: 12
Training loss: 1.1307222843170166
Validation loss: 2.0855485713610085

Epoch: 6| Step: 13
Training loss: 1.6496565341949463
Validation loss: 2.09891479117896

Epoch: 348| Step: 0
Training loss: 1.415811538696289
Validation loss: 2.1300074464531353

Epoch: 6| Step: 1
Training loss: 1.3991942405700684
Validation loss: 2.126334374950778

Epoch: 6| Step: 2
Training loss: 1.5631581544876099
Validation loss: 2.158790373033093

Epoch: 6| Step: 3
Training loss: 1.627119779586792
Validation loss: 2.121010590625066

Epoch: 6| Step: 4
Training loss: 1.92578125
Validation loss: 2.117678065453806

Epoch: 6| Step: 5
Training loss: 1.8847824335098267
Validation loss: 2.1452906772654545

Epoch: 6| Step: 6
Training loss: 1.7955708503723145
Validation loss: 2.124805711930798

Epoch: 6| Step: 7
Training loss: 2.1353931427001953
Validation loss: 2.1269136936433855

Epoch: 6| Step: 8
Training loss: 1.776841640472412
Validation loss: 2.121291148406203

Epoch: 6| Step: 9
Training loss: 1.7208373546600342
Validation loss: 2.130291103034891

Epoch: 6| Step: 10
Training loss: 1.830458164215088
Validation loss: 2.1409991223325013

Epoch: 6| Step: 11
Training loss: 1.8099637031555176
Validation loss: 2.0976539324688654

Epoch: 6| Step: 12
Training loss: 1.775200366973877
Validation loss: 2.1096810730554725

Epoch: 6| Step: 13
Training loss: 2.3647096157073975
Validation loss: 2.0761747180774646

Epoch: 349| Step: 0
Training loss: 1.5566147565841675
Validation loss: 2.1038455040224138

Epoch: 6| Step: 1
Training loss: 2.0295157432556152
Validation loss: 2.1629882358735606

Epoch: 6| Step: 2
Training loss: 1.6040078401565552
Validation loss: 2.1051254836461877

Epoch: 6| Step: 3
Training loss: 1.7160298824310303
Validation loss: 2.0893514117886944

Epoch: 6| Step: 4
Training loss: 1.094806432723999
Validation loss: 2.0854369568568405

Epoch: 6| Step: 5
Training loss: 1.4979236125946045
Validation loss: 2.1065149102159726

Epoch: 6| Step: 6
Training loss: 2.140897274017334
Validation loss: 2.106112951873451

Epoch: 6| Step: 7
Training loss: 2.0117886066436768
Validation loss: 2.0952492708800943

Epoch: 6| Step: 8
Training loss: 1.399804711341858
Validation loss: 2.119047312326329

Epoch: 6| Step: 9
Training loss: 2.3006234169006348
Validation loss: 2.1161966580216602

Epoch: 6| Step: 10
Training loss: 1.3133692741394043
Validation loss: 2.150593629447363

Epoch: 6| Step: 11
Training loss: 2.3148159980773926
Validation loss: 2.143398578448962

Epoch: 6| Step: 12
Training loss: 1.639875054359436
Validation loss: 2.116375677047237

Epoch: 6| Step: 13
Training loss: 2.232734441757202
Validation loss: 2.1322007589442755

Epoch: 350| Step: 0
Training loss: 1.9636512994766235
Validation loss: 2.14334895021172

Epoch: 6| Step: 1
Training loss: 2.1321604251861572
Validation loss: 2.139840687474897

Epoch: 6| Step: 2
Training loss: 1.5928603410720825
Validation loss: 2.140295631142073

Epoch: 6| Step: 3
Training loss: 1.8531181812286377
Validation loss: 2.135613554267473

Epoch: 6| Step: 4
Training loss: 2.355299472808838
Validation loss: 2.1454035543626353

Epoch: 6| Step: 5
Training loss: 1.6031265258789062
Validation loss: 2.166862769793439

Epoch: 6| Step: 6
Training loss: 1.6595842838287354
Validation loss: 2.180263853842212

Epoch: 6| Step: 7
Training loss: 1.6997802257537842
Validation loss: 2.1935957759939213

Epoch: 6| Step: 8
Training loss: 1.6092524528503418
Validation loss: 2.1536193534892094

Epoch: 6| Step: 9
Training loss: 1.251863718032837
Validation loss: 2.149735040562127

Epoch: 6| Step: 10
Training loss: 1.5510668754577637
Validation loss: 2.142353662880518

Epoch: 6| Step: 11
Training loss: 1.8725532293319702
Validation loss: 2.155091069077933

Epoch: 6| Step: 12
Training loss: 2.149228096008301
Validation loss: 2.1283564952112015

Epoch: 6| Step: 13
Training loss: 1.7660014629364014
Validation loss: 2.100850675695686

Epoch: 351| Step: 0
Training loss: 1.6101068258285522
Validation loss: 2.1592509554278467

Epoch: 6| Step: 1
Training loss: 2.1256537437438965
Validation loss: 2.1409544919126775

Epoch: 6| Step: 2
Training loss: 2.4420745372772217
Validation loss: 2.1113988250814457

Epoch: 6| Step: 3
Training loss: 1.2011010646820068
Validation loss: 2.099002512552405

Epoch: 6| Step: 4
Training loss: 1.9033347368240356
Validation loss: 2.105440716589651

Epoch: 6| Step: 5
Training loss: 1.3854998350143433
Validation loss: 2.126020972446729

Epoch: 6| Step: 6
Training loss: 1.436846137046814
Validation loss: 2.0965100308900237

Epoch: 6| Step: 7
Training loss: 1.8022606372833252
Validation loss: 2.1298221593262046

Epoch: 6| Step: 8
Training loss: 1.2516896724700928
Validation loss: 2.1039845405086393

Epoch: 6| Step: 9
Training loss: 1.7465530633926392
Validation loss: 2.1050941918485906

Epoch: 6| Step: 10
Training loss: 2.0613784790039062
Validation loss: 2.102922481875266

Epoch: 6| Step: 11
Training loss: 1.9005260467529297
Validation loss: 2.0894064134167087

Epoch: 6| Step: 12
Training loss: 1.9769655466079712
Validation loss: 2.096995871554139

Epoch: 6| Step: 13
Training loss: 1.8900460004806519
Validation loss: 2.101959968125948

Epoch: 352| Step: 0
Training loss: 1.2322742938995361
Validation loss: 2.0961627421840543

Epoch: 6| Step: 1
Training loss: 1.584839105606079
Validation loss: 2.0986481481982815

Epoch: 6| Step: 2
Training loss: 1.9972922801971436
Validation loss: 2.0959978603547618

Epoch: 6| Step: 3
Training loss: 1.7712031602859497
Validation loss: 2.110303371183334

Epoch: 6| Step: 4
Training loss: 1.6118748188018799
Validation loss: 2.1423597669088714

Epoch: 6| Step: 5
Training loss: 1.9040977954864502
Validation loss: 2.1219321489334106

Epoch: 6| Step: 6
Training loss: 1.3374714851379395
Validation loss: 2.1224263521932785

Epoch: 6| Step: 7
Training loss: 1.9047126770019531
Validation loss: 2.12676679190769

Epoch: 6| Step: 8
Training loss: 1.123069167137146
Validation loss: 2.139319955661733

Epoch: 6| Step: 9
Training loss: 2.534585952758789
Validation loss: 2.132415730466125

Epoch: 6| Step: 10
Training loss: 2.2900986671447754
Validation loss: 2.1599707706000215

Epoch: 6| Step: 11
Training loss: 1.9786067008972168
Validation loss: 2.164368011618173

Epoch: 6| Step: 12
Training loss: 1.6878529787063599
Validation loss: 2.1526034262872513

Epoch: 6| Step: 13
Training loss: 1.6202683448791504
Validation loss: 2.159876190206056

Epoch: 353| Step: 0
Training loss: 1.3631845712661743
Validation loss: 2.1326939470024517

Epoch: 6| Step: 1
Training loss: 1.1709723472595215
Validation loss: 2.1772634572880243

Epoch: 6| Step: 2
Training loss: 1.8426094055175781
Validation loss: 2.1684212582085722

Epoch: 6| Step: 3
Training loss: 1.4305909872055054
Validation loss: 2.150068753509111

Epoch: 6| Step: 4
Training loss: 1.6558096408843994
Validation loss: 2.1553394871373333

Epoch: 6| Step: 5
Training loss: 1.8180170059204102
Validation loss: 2.123597074580449

Epoch: 6| Step: 6
Training loss: 2.0270681381225586
Validation loss: 2.1380700219062065

Epoch: 6| Step: 7
Training loss: 1.6295311450958252
Validation loss: 2.1020212199098323

Epoch: 6| Step: 8
Training loss: 1.852139949798584
Validation loss: 2.1646683549368255

Epoch: 6| Step: 9
Training loss: 1.8201299905776978
Validation loss: 2.1124274833228

Epoch: 6| Step: 10
Training loss: 2.0511298179626465
Validation loss: 2.1213775834729596

Epoch: 6| Step: 11
Training loss: 1.5932023525238037
Validation loss: 2.090995661674007

Epoch: 6| Step: 12
Training loss: 2.2686991691589355
Validation loss: 2.1201812426249185

Epoch: 6| Step: 13
Training loss: 2.1913366317749023
Validation loss: 2.122673028258867

Epoch: 354| Step: 0
Training loss: 2.6912178993225098
Validation loss: 2.0960509546341433

Epoch: 6| Step: 1
Training loss: 1.4425888061523438
Validation loss: 2.102484013444634

Epoch: 6| Step: 2
Training loss: 2.0417747497558594
Validation loss: 2.080586107828284

Epoch: 6| Step: 3
Training loss: 1.8910388946533203
Validation loss: 2.0792594571267404

Epoch: 6| Step: 4
Training loss: 1.1635851860046387
Validation loss: 2.119487177941107

Epoch: 6| Step: 5
Training loss: 1.703703761100769
Validation loss: 2.108522750998056

Epoch: 6| Step: 6
Training loss: 1.436370849609375
Validation loss: 2.087766085901568

Epoch: 6| Step: 7
Training loss: 1.4299521446228027
Validation loss: 2.140665295303509

Epoch: 6| Step: 8
Training loss: 2.102267265319824
Validation loss: 2.0516027122415523

Epoch: 6| Step: 9
Training loss: 1.1287977695465088
Validation loss: 2.128570795059204

Epoch: 6| Step: 10
Training loss: 2.185404062271118
Validation loss: 2.121733693666356

Epoch: 6| Step: 11
Training loss: 1.6005939245224
Validation loss: 2.0566128517991755

Epoch: 6| Step: 12
Training loss: 1.6737172603607178
Validation loss: 2.136525425859677

Epoch: 6| Step: 13
Training loss: 2.172372579574585
Validation loss: 2.11799104239351

Epoch: 355| Step: 0
Training loss: 1.5564366579055786
Validation loss: 2.0720978424113285

Epoch: 6| Step: 1
Training loss: 1.8996914625167847
Validation loss: 2.1081169753946285

Epoch: 6| Step: 2
Training loss: 1.535530686378479
Validation loss: 2.122062652341781

Epoch: 6| Step: 3
Training loss: 1.5648210048675537
Validation loss: 2.1386356071759294

Epoch: 6| Step: 4
Training loss: 1.9932376146316528
Validation loss: 2.1696501239653556

Epoch: 6| Step: 5
Training loss: 1.9043083190917969
Validation loss: 2.0992385828366844

Epoch: 6| Step: 6
Training loss: 1.9976890087127686
Validation loss: 2.1163668927325996

Epoch: 6| Step: 7
Training loss: 1.2427161931991577
Validation loss: 2.135115833692653

Epoch: 6| Step: 8
Training loss: 1.9579088687896729
Validation loss: 2.10915441923244

Epoch: 6| Step: 9
Training loss: 1.2699625492095947
Validation loss: 2.1221991098055275

Epoch: 6| Step: 10
Training loss: 1.9559826850891113
Validation loss: 2.119148682522517

Epoch: 6| Step: 11
Training loss: 1.685175895690918
Validation loss: 2.1154440346584527

Epoch: 6| Step: 12
Training loss: 1.5059535503387451
Validation loss: 2.1270392389707666

Epoch: 6| Step: 13
Training loss: 2.610180616378784
Validation loss: 2.135732420029179

Epoch: 356| Step: 0
Training loss: 1.633300542831421
Validation loss: 2.123595437695903

Epoch: 6| Step: 1
Training loss: 1.2335270643234253
Validation loss: 2.0842952933362735

Epoch: 6| Step: 2
Training loss: 1.8795872926712036
Validation loss: 2.1131399844282415

Epoch: 6| Step: 3
Training loss: 1.5659410953521729
Validation loss: 2.0930077811723113

Epoch: 6| Step: 4
Training loss: 1.927609920501709
Validation loss: 2.1174232344473563

Epoch: 6| Step: 5
Training loss: 1.8801746368408203
Validation loss: 2.120952304973397

Epoch: 6| Step: 6
Training loss: 1.6127467155456543
Validation loss: 2.127042938304204

Epoch: 6| Step: 7
Training loss: 1.5779335498809814
Validation loss: 2.105579096783874

Epoch: 6| Step: 8
Training loss: 2.561685085296631
Validation loss: 2.1181116020807655

Epoch: 6| Step: 9
Training loss: 2.1788785457611084
Validation loss: 2.1260665360317437

Epoch: 6| Step: 10
Training loss: 1.1331490278244019
Validation loss: 2.139425439219321

Epoch: 6| Step: 11
Training loss: 2.0120298862457275
Validation loss: 2.124117684620683

Epoch: 6| Step: 12
Training loss: 1.787177562713623
Validation loss: 2.128928271673059

Epoch: 6| Step: 13
Training loss: 1.613847255706787
Validation loss: 2.1093556804041707

Epoch: 357| Step: 0
Training loss: 2.095768928527832
Validation loss: 2.1594132582346597

Epoch: 6| Step: 1
Training loss: 1.5804191827774048
Validation loss: 2.106257545050754

Epoch: 6| Step: 2
Training loss: 1.7213211059570312
Validation loss: 2.1600994525417203

Epoch: 6| Step: 3
Training loss: 1.3712503910064697
Validation loss: 2.1012580676745345

Epoch: 6| Step: 4
Training loss: 2.153700590133667
Validation loss: 2.081192931821269

Epoch: 6| Step: 5
Training loss: 1.709382176399231
Validation loss: 2.1502974366628997

Epoch: 6| Step: 6
Training loss: 1.342634916305542
Validation loss: 2.156386952246389

Epoch: 6| Step: 7
Training loss: 1.9819293022155762
Validation loss: 2.1035549025381766

Epoch: 6| Step: 8
Training loss: 1.7366033792495728
Validation loss: 2.10367485015623

Epoch: 6| Step: 9
Training loss: 1.3852694034576416
Validation loss: 2.1248920553474018

Epoch: 6| Step: 10
Training loss: 1.8261017799377441
Validation loss: 2.122214304503574

Epoch: 6| Step: 11
Training loss: 1.7096226215362549
Validation loss: 2.1002790171612977

Epoch: 6| Step: 12
Training loss: 2.0249929428100586
Validation loss: 2.10949775736819

Epoch: 6| Step: 13
Training loss: 1.9304898977279663
Validation loss: 2.1042360439095447

Epoch: 358| Step: 0
Training loss: 1.6172263622283936
Validation loss: 2.1318959907818864

Epoch: 6| Step: 1
Training loss: 2.2759337425231934
Validation loss: 2.1015374429764284

Epoch: 6| Step: 2
Training loss: 1.5927939414978027
Validation loss: 2.0766291156891854

Epoch: 6| Step: 3
Training loss: 1.6790430545806885
Validation loss: 2.1212721409336215

Epoch: 6| Step: 4
Training loss: 1.8419337272644043
Validation loss: 2.1187022386058683

Epoch: 6| Step: 5
Training loss: 2.112147092819214
Validation loss: 2.125856771264025

Epoch: 6| Step: 6
Training loss: 1.510785460472107
Validation loss: 2.0897799461118636

Epoch: 6| Step: 7
Training loss: 1.5828430652618408
Validation loss: 2.112479184263496

Epoch: 6| Step: 8
Training loss: 2.0056145191192627
Validation loss: 2.1126087506612143

Epoch: 6| Step: 9
Training loss: 1.5897715091705322
Validation loss: 2.0650630509981545

Epoch: 6| Step: 10
Training loss: 2.680748462677002
Validation loss: 2.1004375539800173

Epoch: 6| Step: 11
Training loss: 0.9793346524238586
Validation loss: 2.1234535017321186

Epoch: 6| Step: 12
Training loss: 1.3885843753814697
Validation loss: 2.093956167979907

Epoch: 6| Step: 13
Training loss: 1.4300494194030762
Validation loss: 2.134943921078918

Epoch: 359| Step: 0
Training loss: 1.6119112968444824
Validation loss: 2.1176649191046275

Epoch: 6| Step: 1
Training loss: 1.5820598602294922
Validation loss: 2.1191137042096866

Epoch: 6| Step: 2
Training loss: 2.026566505432129
Validation loss: 2.123382532468406

Epoch: 6| Step: 3
Training loss: 2.089536428451538
Validation loss: 2.1468965366322506

Epoch: 6| Step: 4
Training loss: 1.7471628189086914
Validation loss: 2.1318091295098744

Epoch: 6| Step: 5
Training loss: 1.7381441593170166
Validation loss: 2.131033214189673

Epoch: 6| Step: 6
Training loss: 1.2065778970718384
Validation loss: 2.138764060953612

Epoch: 6| Step: 7
Training loss: 1.758568525314331
Validation loss: 2.1587493291465183

Epoch: 6| Step: 8
Training loss: 2.2875447273254395
Validation loss: 2.1528743979751424

Epoch: 6| Step: 9
Training loss: 1.9589426517486572
Validation loss: 2.1585633985457884

Epoch: 6| Step: 10
Training loss: 1.6573646068572998
Validation loss: 2.135906578392111

Epoch: 6| Step: 11
Training loss: 1.6753852367401123
Validation loss: 2.1207809371332966

Epoch: 6| Step: 12
Training loss: 1.260379672050476
Validation loss: 2.1290454595319686

Epoch: 6| Step: 13
Training loss: 2.043252944946289
Validation loss: 2.1144357240328224

Epoch: 360| Step: 0
Training loss: 1.6210260391235352
Validation loss: 2.0977975732536724

Epoch: 6| Step: 1
Training loss: 1.55817711353302
Validation loss: 2.110021565550117

Epoch: 6| Step: 2
Training loss: 1.5141061544418335
Validation loss: 2.1386161337616625

Epoch: 6| Step: 3
Training loss: 1.565469741821289
Validation loss: 2.127194271292738

Epoch: 6| Step: 4
Training loss: 1.810958743095398
Validation loss: 2.0930489929773475

Epoch: 6| Step: 5
Training loss: 1.9653451442718506
Validation loss: 2.1109242387997207

Epoch: 6| Step: 6
Training loss: 1.9984440803527832
Validation loss: 2.109046451507076

Epoch: 6| Step: 7
Training loss: 1.3800654411315918
Validation loss: 2.0827144653566423

Epoch: 6| Step: 8
Training loss: 2.117257833480835
Validation loss: 2.0646067998742543

Epoch: 6| Step: 9
Training loss: 2.255777359008789
Validation loss: 2.0438445306593374

Epoch: 6| Step: 10
Training loss: 2.1879525184631348
Validation loss: 2.1044660486200804

Epoch: 6| Step: 11
Training loss: 1.2877448797225952
Validation loss: 2.10391067945829

Epoch: 6| Step: 12
Training loss: 1.527557373046875
Validation loss: 2.075452963511149

Epoch: 6| Step: 13
Training loss: 1.6877822875976562
Validation loss: 2.1210547903532624

Epoch: 361| Step: 0
Training loss: 1.527824878692627
Validation loss: 2.0907367275607203

Epoch: 6| Step: 1
Training loss: 1.4345824718475342
Validation loss: 2.0821605061972015

Epoch: 6| Step: 2
Training loss: 1.9709551334381104
Validation loss: 2.0870476153589066

Epoch: 6| Step: 3
Training loss: 1.7922112941741943
Validation loss: 2.082982038938871

Epoch: 6| Step: 4
Training loss: 1.973455786705017
Validation loss: 2.070904352331674

Epoch: 6| Step: 5
Training loss: 1.2023868560791016
Validation loss: 2.1197008830244823

Epoch: 6| Step: 6
Training loss: 1.5225417613983154
Validation loss: 2.1191875447509108

Epoch: 6| Step: 7
Training loss: 1.0964913368225098
Validation loss: 2.0887764910215973

Epoch: 6| Step: 8
Training loss: 2.029240131378174
Validation loss: 2.095319067278216

Epoch: 6| Step: 9
Training loss: 2.21931529045105
Validation loss: 2.090157985687256

Epoch: 6| Step: 10
Training loss: 1.5708574056625366
Validation loss: 2.1721427722643782

Epoch: 6| Step: 11
Training loss: 1.8481658697128296
Validation loss: 2.1214574485696773

Epoch: 6| Step: 12
Training loss: 2.0528624057769775
Validation loss: 2.068522232835011

Epoch: 6| Step: 13
Training loss: 1.480043649673462
Validation loss: 2.1300513103444088

Epoch: 362| Step: 0
Training loss: 1.4811732769012451
Validation loss: 2.09869396814736

Epoch: 6| Step: 1
Training loss: 2.059830665588379
Validation loss: 2.141783542530511

Epoch: 6| Step: 2
Training loss: 1.5789681673049927
Validation loss: 2.1321179764245146

Epoch: 6| Step: 3
Training loss: 1.159792423248291
Validation loss: 2.1345294367882515

Epoch: 6| Step: 4
Training loss: 1.5251870155334473
Validation loss: 2.138535638009348

Epoch: 6| Step: 5
Training loss: 2.056297779083252
Validation loss: 2.124386187522642

Epoch: 6| Step: 6
Training loss: 1.4959008693695068
Validation loss: 2.1308901732967747

Epoch: 6| Step: 7
Training loss: 1.3894530534744263
Validation loss: 2.132027131254955

Epoch: 6| Step: 8
Training loss: 2.0661494731903076
Validation loss: 2.115607310366887

Epoch: 6| Step: 9
Training loss: 2.0019688606262207
Validation loss: 2.1361941599076792

Epoch: 6| Step: 10
Training loss: 1.796050786972046
Validation loss: 2.133515032388831

Epoch: 6| Step: 11
Training loss: 1.7412793636322021
Validation loss: 2.127631546348654

Epoch: 6| Step: 12
Training loss: 1.762627124786377
Validation loss: 2.1534278956792687

Epoch: 6| Step: 13
Training loss: 2.472151517868042
Validation loss: 2.155132785920174

Epoch: 363| Step: 0
Training loss: 1.2923786640167236
Validation loss: 2.1811163015263055

Epoch: 6| Step: 1
Training loss: 1.8025271892547607
Validation loss: 2.1455256118569324

Epoch: 6| Step: 2
Training loss: 1.7667899131774902
Validation loss: 2.1432315713615826

Epoch: 6| Step: 3
Training loss: 2.0063815116882324
Validation loss: 2.102778219407605

Epoch: 6| Step: 4
Training loss: 1.8843700885772705
Validation loss: 2.1509222663858885

Epoch: 6| Step: 5
Training loss: 1.0645887851715088
Validation loss: 2.1379342617527133

Epoch: 6| Step: 6
Training loss: 2.468209981918335
Validation loss: 2.120171029080627

Epoch: 6| Step: 7
Training loss: 1.4255588054656982
Validation loss: 2.1342795151536182

Epoch: 6| Step: 8
Training loss: 1.6963133811950684
Validation loss: 2.1185584119571153

Epoch: 6| Step: 9
Training loss: 2.4256277084350586
Validation loss: 2.1044374691542758

Epoch: 6| Step: 10
Training loss: 1.280912160873413
Validation loss: 2.1155818047062045

Epoch: 6| Step: 11
Training loss: 1.719556450843811
Validation loss: 2.127048869286814

Epoch: 6| Step: 12
Training loss: 1.612966537475586
Validation loss: 2.105632710200484

Epoch: 6| Step: 13
Training loss: 1.4075769186019897
Validation loss: 2.1052363790491575

Epoch: 364| Step: 0
Training loss: 1.6972057819366455
Validation loss: 2.102788384242724

Epoch: 6| Step: 1
Training loss: 2.206557035446167
Validation loss: 2.134198542564146

Epoch: 6| Step: 2
Training loss: 1.7163512706756592
Validation loss: 2.09521907888433

Epoch: 6| Step: 3
Training loss: 1.7251676321029663
Validation loss: 2.0672803271201348

Epoch: 6| Step: 4
Training loss: 1.9510090351104736
Validation loss: 2.1070226712893416

Epoch: 6| Step: 5
Training loss: 2.1022753715515137
Validation loss: 2.087009258167718

Epoch: 6| Step: 6
Training loss: 1.3833491802215576
Validation loss: 2.13784469327619

Epoch: 6| Step: 7
Training loss: 1.7242529392242432
Validation loss: 2.101323507165396

Epoch: 6| Step: 8
Training loss: 1.7306581735610962
Validation loss: 2.1029950854598836

Epoch: 6| Step: 9
Training loss: 1.9471441507339478
Validation loss: 2.0807930423367407

Epoch: 6| Step: 10
Training loss: 1.9078314304351807
Validation loss: 2.1009691248657885

Epoch: 6| Step: 11
Training loss: 1.6014857292175293
Validation loss: 2.1322378125242007

Epoch: 6| Step: 12
Training loss: 1.197916030883789
Validation loss: 2.122050759612873

Epoch: 6| Step: 13
Training loss: 1.083791732788086
Validation loss: 2.154935279200154

Epoch: 365| Step: 0
Training loss: 2.0109634399414062
Validation loss: 2.153834778775451

Epoch: 6| Step: 1
Training loss: 1.1720755100250244
Validation loss: 2.125749149630147

Epoch: 6| Step: 2
Training loss: 1.7035191059112549
Validation loss: 2.150086223438222

Epoch: 6| Step: 3
Training loss: 1.9432451725006104
Validation loss: 2.1733588377634683

Epoch: 6| Step: 4
Training loss: 1.9309883117675781
Validation loss: 2.1595323701058664

Epoch: 6| Step: 5
Training loss: 1.8969142436981201
Validation loss: 2.1818698619001653

Epoch: 6| Step: 6
Training loss: 2.0998077392578125
Validation loss: 2.1332735733319352

Epoch: 6| Step: 7
Training loss: 1.2913683652877808
Validation loss: 2.149474725928358

Epoch: 6| Step: 8
Training loss: 1.950474500656128
Validation loss: 2.123487067478959

Epoch: 6| Step: 9
Training loss: 1.365818977355957
Validation loss: 2.162475028345662

Epoch: 6| Step: 10
Training loss: 2.0739593505859375
Validation loss: 2.105455499823375

Epoch: 6| Step: 11
Training loss: 1.8774727582931519
Validation loss: 2.130910268393896

Epoch: 6| Step: 12
Training loss: 1.3857089281082153
Validation loss: 2.107406149628342

Epoch: 6| Step: 13
Training loss: 1.2386133670806885
Validation loss: 2.108326271016111

Epoch: 366| Step: 0
Training loss: 1.4501097202301025
Validation loss: 2.1193370178181636

Epoch: 6| Step: 1
Training loss: 1.272815227508545
Validation loss: 2.0863366139832364

Epoch: 6| Step: 2
Training loss: 1.8226420879364014
Validation loss: 2.134109967498369

Epoch: 6| Step: 3
Training loss: 1.7207783460617065
Validation loss: 2.0691308154854724

Epoch: 6| Step: 4
Training loss: 1.3472343683242798
Validation loss: 2.148924514811526

Epoch: 6| Step: 5
Training loss: 1.9281235933303833
Validation loss: 2.105701526006063

Epoch: 6| Step: 6
Training loss: 2.5724129676818848
Validation loss: 2.1394155768937964

Epoch: 6| Step: 7
Training loss: 1.7418134212493896
Validation loss: 2.082600801221786

Epoch: 6| Step: 8
Training loss: 0.8747773170471191
Validation loss: 2.1077244179223174

Epoch: 6| Step: 9
Training loss: 1.8020986318588257
Validation loss: 2.096093544396021

Epoch: 6| Step: 10
Training loss: 1.6502668857574463
Validation loss: 2.1281978314922703

Epoch: 6| Step: 11
Training loss: 2.2318732738494873
Validation loss: 2.105948976291123

Epoch: 6| Step: 12
Training loss: 2.0827527046203613
Validation loss: 2.118077439646567

Epoch: 6| Step: 13
Training loss: 1.4701824188232422
Validation loss: 2.1372857824448617

Epoch: 367| Step: 0
Training loss: 1.2214276790618896
Validation loss: 2.159482463713615

Epoch: 6| Step: 1
Training loss: 1.9110946655273438
Validation loss: 2.105339063111172

Epoch: 6| Step: 2
Training loss: 2.4384989738464355
Validation loss: 2.1313708930887203

Epoch: 6| Step: 3
Training loss: 2.5818982124328613
Validation loss: 2.097587295757827

Epoch: 6| Step: 4
Training loss: 1.2364108562469482
Validation loss: 2.109555830237686

Epoch: 6| Step: 5
Training loss: 1.2292811870574951
Validation loss: 2.106038913931898

Epoch: 6| Step: 6
Training loss: 1.9398510456085205
Validation loss: 2.126029542697373

Epoch: 6| Step: 7
Training loss: 1.593719720840454
Validation loss: 2.081321806036016

Epoch: 6| Step: 8
Training loss: 1.7336218357086182
Validation loss: 2.1472165405109362

Epoch: 6| Step: 9
Training loss: 1.6145172119140625
Validation loss: 2.1188631211557696

Epoch: 6| Step: 10
Training loss: 1.5194567441940308
Validation loss: 2.0817740373713995

Epoch: 6| Step: 11
Training loss: 1.9385769367218018
Validation loss: 2.1190543995108655

Epoch: 6| Step: 12
Training loss: 1.4157156944274902
Validation loss: 2.126345105068658

Epoch: 6| Step: 13
Training loss: 2.0178937911987305
Validation loss: 2.0984052458117084

Epoch: 368| Step: 0
Training loss: 1.0082749128341675
Validation loss: 2.1132678626686014

Epoch: 6| Step: 1
Training loss: 1.949037790298462
Validation loss: 2.113553923945273

Epoch: 6| Step: 2
Training loss: 1.5569891929626465
Validation loss: 2.162393457146101

Epoch: 6| Step: 3
Training loss: 1.0691404342651367
Validation loss: 2.1130047818665862

Epoch: 6| Step: 4
Training loss: 2.342010498046875
Validation loss: 2.1741380640255508

Epoch: 6| Step: 5
Training loss: 1.7215735912322998
Validation loss: 2.111701241103552

Epoch: 6| Step: 6
Training loss: 1.9791343212127686
Validation loss: 2.1390262111540763

Epoch: 6| Step: 7
Training loss: 1.8449407815933228
Validation loss: 2.1330027272624354

Epoch: 6| Step: 8
Training loss: 1.067413568496704
Validation loss: 2.1539741498167797

Epoch: 6| Step: 9
Training loss: 2.631068229675293
Validation loss: 2.135709342136178

Epoch: 6| Step: 10
Training loss: 1.6043739318847656
Validation loss: 2.14542479156166

Epoch: 6| Step: 11
Training loss: 1.6090636253356934
Validation loss: 2.1598709834519254

Epoch: 6| Step: 12
Training loss: 2.190101385116577
Validation loss: 2.1504494784980692

Epoch: 6| Step: 13
Training loss: 1.2945733070373535
Validation loss: 2.0925482601247807

Epoch: 369| Step: 0
Training loss: 1.9864510297775269
Validation loss: 2.1002320371648318

Epoch: 6| Step: 1
Training loss: 1.6837644577026367
Validation loss: 2.149720363719489

Epoch: 6| Step: 2
Training loss: 1.8525735139846802
Validation loss: 2.111855258223831

Epoch: 6| Step: 3
Training loss: 1.285298466682434
Validation loss: 2.054885953985235

Epoch: 6| Step: 4
Training loss: 2.3028531074523926
Validation loss: 2.1081468776990007

Epoch: 6| Step: 5
Training loss: 2.2730445861816406
Validation loss: 2.072049012748144

Epoch: 6| Step: 6
Training loss: 1.8299726247787476
Validation loss: 2.1065963404152983

Epoch: 6| Step: 7
Training loss: 1.238775610923767
Validation loss: 2.104069407268237

Epoch: 6| Step: 8
Training loss: 1.4053490161895752
Validation loss: 2.079099657715008

Epoch: 6| Step: 9
Training loss: 1.6984773874282837
Validation loss: 2.132390078677926

Epoch: 6| Step: 10
Training loss: 1.980701208114624
Validation loss: 2.112318123540571

Epoch: 6| Step: 11
Training loss: 1.3331303596496582
Validation loss: 2.1154718219593005

Epoch: 6| Step: 12
Training loss: 1.4075307846069336
Validation loss: 2.1395350015291603

Epoch: 6| Step: 13
Training loss: 1.822486400604248
Validation loss: 2.108717273640376

Epoch: 370| Step: 0
Training loss: 1.7014553546905518
Validation loss: 2.117897969420238

Epoch: 6| Step: 1
Training loss: 1.1527881622314453
Validation loss: 2.101807563535629

Epoch: 6| Step: 2
Training loss: 1.856895089149475
Validation loss: 2.16812801361084

Epoch: 6| Step: 3
Training loss: 2.634463310241699
Validation loss: 2.21105630167069

Epoch: 6| Step: 4
Training loss: 1.4822630882263184
Validation loss: 2.1160312903824674

Epoch: 6| Step: 5
Training loss: 1.9811357259750366
Validation loss: 2.129695479587842

Epoch: 6| Step: 6
Training loss: 1.3774558305740356
Validation loss: 2.111727895275239

Epoch: 6| Step: 7
Training loss: 1.592780590057373
Validation loss: 2.0904028505407353

Epoch: 6| Step: 8
Training loss: 2.426393508911133
Validation loss: 2.173813368684502

Epoch: 6| Step: 9
Training loss: 1.215599775314331
Validation loss: 2.155590316300751

Epoch: 6| Step: 10
Training loss: 1.2038650512695312
Validation loss: 2.13963681908064

Epoch: 6| Step: 11
Training loss: 2.0971789360046387
Validation loss: 2.123647133509318

Epoch: 6| Step: 12
Training loss: 1.257615566253662
Validation loss: 2.1159874008547876

Epoch: 6| Step: 13
Training loss: 2.189791440963745
Validation loss: 2.1085852884477183

Epoch: 371| Step: 0
Training loss: 0.7304213047027588
Validation loss: 2.113932994104201

Epoch: 6| Step: 1
Training loss: 1.4712684154510498
Validation loss: 2.125484593452946

Epoch: 6| Step: 2
Training loss: 1.79329252243042
Validation loss: 2.113968886354918

Epoch: 6| Step: 3
Training loss: 1.4044533967971802
Validation loss: 2.099413248800462

Epoch: 6| Step: 4
Training loss: 1.6816883087158203
Validation loss: 2.1089721213104906

Epoch: 6| Step: 5
Training loss: 1.4367625713348389
Validation loss: 2.1176018740541194

Epoch: 6| Step: 6
Training loss: 2.5858545303344727
Validation loss: 2.132033368592621

Epoch: 6| Step: 7
Training loss: 2.0028867721557617
Validation loss: 2.1060164308035247

Epoch: 6| Step: 8
Training loss: 1.6476227045059204
Validation loss: 2.09466968300522

Epoch: 6| Step: 9
Training loss: 2.336317777633667
Validation loss: 2.0885611862264652

Epoch: 6| Step: 10
Training loss: 1.5696288347244263
Validation loss: 2.106038162785192

Epoch: 6| Step: 11
Training loss: 2.3794188499450684
Validation loss: 2.07913940183578

Epoch: 6| Step: 12
Training loss: 1.6910126209259033
Validation loss: 2.086049954096476

Epoch: 6| Step: 13
Training loss: 1.7317979335784912
Validation loss: 2.1072653878119683

Epoch: 372| Step: 0
Training loss: 1.903390884399414
Validation loss: 2.1241719979111866

Epoch: 6| Step: 1
Training loss: 1.7339653968811035
Validation loss: 2.123167953183574

Epoch: 6| Step: 2
Training loss: 1.3694416284561157
Validation loss: 2.12205139283211

Epoch: 6| Step: 3
Training loss: 1.8177754878997803
Validation loss: 2.0870788405018468

Epoch: 6| Step: 4
Training loss: 1.5013960599899292
Validation loss: 2.1120618312589583

Epoch: 6| Step: 5
Training loss: 1.8084548711776733
Validation loss: 2.1074010582380396

Epoch: 6| Step: 6
Training loss: 2.035696268081665
Validation loss: 2.1417241737406743

Epoch: 6| Step: 7
Training loss: 1.2380393743515015
Validation loss: 2.1261464190739456

Epoch: 6| Step: 8
Training loss: 1.3477630615234375
Validation loss: 2.1540496349334717

Epoch: 6| Step: 9
Training loss: 1.3125042915344238
Validation loss: 2.1198199359319543

Epoch: 6| Step: 10
Training loss: 1.4840800762176514
Validation loss: 2.127309282620748

Epoch: 6| Step: 11
Training loss: 1.9761265516281128
Validation loss: 2.1453614260560725

Epoch: 6| Step: 12
Training loss: 2.5013413429260254
Validation loss: 2.146011398684594

Epoch: 6| Step: 13
Training loss: 1.5956645011901855
Validation loss: 2.1276807528670116

Epoch: 373| Step: 0
Training loss: 1.562919020652771
Validation loss: 2.1432077859037664

Epoch: 6| Step: 1
Training loss: 1.893165111541748
Validation loss: 2.1296146685077297

Epoch: 6| Step: 2
Training loss: 2.182241678237915
Validation loss: 2.1364346986175864

Epoch: 6| Step: 3
Training loss: 1.4935379028320312
Validation loss: 2.1703283991864932

Epoch: 6| Step: 4
Training loss: 1.5830389261245728
Validation loss: 2.196205364760532

Epoch: 6| Step: 5
Training loss: 1.6300430297851562
Validation loss: 2.127702938613071

Epoch: 6| Step: 6
Training loss: 1.5639011859893799
Validation loss: 2.181251670724602

Epoch: 6| Step: 7
Training loss: 2.611959457397461
Validation loss: 2.1373656078051497

Epoch: 6| Step: 8
Training loss: 1.1467745304107666
Validation loss: 2.159604380207677

Epoch: 6| Step: 9
Training loss: 2.130488872528076
Validation loss: 2.1515705559843328

Epoch: 6| Step: 10
Training loss: 1.1378295421600342
Validation loss: 2.1646238962809243

Epoch: 6| Step: 11
Training loss: 1.9632081985473633
Validation loss: 2.150736093521118

Epoch: 6| Step: 12
Training loss: 1.699577808380127
Validation loss: 2.092237541752477

Epoch: 6| Step: 13
Training loss: 1.5072046518325806
Validation loss: 2.1224121842333066

Epoch: 374| Step: 0
Training loss: 1.4481847286224365
Validation loss: 2.089083215241791

Epoch: 6| Step: 1
Training loss: 2.1461968421936035
Validation loss: 2.1296097616995535

Epoch: 6| Step: 2
Training loss: 1.5335878133773804
Validation loss: 2.0926421444903136

Epoch: 6| Step: 3
Training loss: 1.2441990375518799
Validation loss: 2.1335408213318034

Epoch: 6| Step: 4
Training loss: 2.1836533546447754
Validation loss: 2.1308030902698474

Epoch: 6| Step: 5
Training loss: 1.6627140045166016
Validation loss: 2.1146066573358353

Epoch: 6| Step: 6
Training loss: 2.318634510040283
Validation loss: 2.1216592006785895

Epoch: 6| Step: 7
Training loss: 2.322871446609497
Validation loss: 2.1543941215802263

Epoch: 6| Step: 8
Training loss: 0.9236741662025452
Validation loss: 2.1074694048973823

Epoch: 6| Step: 9
Training loss: 1.6638715267181396
Validation loss: 2.0880880637835433

Epoch: 6| Step: 10
Training loss: 1.3985533714294434
Validation loss: 2.1482001337953793

Epoch: 6| Step: 11
Training loss: 1.7486995458602905
Validation loss: 2.1115871296134046

Epoch: 6| Step: 12
Training loss: 1.82581627368927
Validation loss: 2.1252009509712138

Epoch: 6| Step: 13
Training loss: 1.5127519369125366
Validation loss: 2.0917252609806676

Epoch: 375| Step: 0
Training loss: 2.198284149169922
Validation loss: 2.1537635659658783

Epoch: 6| Step: 1
Training loss: 1.225082278251648
Validation loss: 2.1150833009391703

Epoch: 6| Step: 2
Training loss: 1.3592336177825928
Validation loss: 2.1257868633475354

Epoch: 6| Step: 3
Training loss: 1.3446578979492188
Validation loss: 2.1123432113278295

Epoch: 6| Step: 4
Training loss: 1.0753226280212402
Validation loss: 2.154672626526125

Epoch: 6| Step: 5
Training loss: 1.7065380811691284
Validation loss: 2.1093186870698006

Epoch: 6| Step: 6
Training loss: 1.401842474937439
Validation loss: 2.1212550414505826

Epoch: 6| Step: 7
Training loss: 2.45708966255188
Validation loss: 2.100807871869815

Epoch: 6| Step: 8
Training loss: 2.2144670486450195
Validation loss: 2.1095122637287265

Epoch: 6| Step: 9
Training loss: 2.3688204288482666
Validation loss: 2.121338423862252

Epoch: 6| Step: 10
Training loss: 1.8949369192123413
Validation loss: 2.094438465692664

Epoch: 6| Step: 11
Training loss: 1.4345500469207764
Validation loss: 2.1290212305643226

Epoch: 6| Step: 12
Training loss: 1.5191158056259155
Validation loss: 2.0815365647756927

Epoch: 6| Step: 13
Training loss: 1.4386093616485596
Validation loss: 2.1271843410307363

Epoch: 376| Step: 0
Training loss: 1.6798638105392456
Validation loss: 2.1464366246295232

Epoch: 6| Step: 1
Training loss: 1.0953823328018188
Validation loss: 2.128288858680315

Epoch: 6| Step: 2
Training loss: 1.196001648902893
Validation loss: 2.1290636882987073

Epoch: 6| Step: 3
Training loss: 2.583904504776001
Validation loss: 2.139592247624551

Epoch: 6| Step: 4
Training loss: 1.5254932641983032
Validation loss: 2.1399616913128923

Epoch: 6| Step: 5
Training loss: 1.3325539827346802
Validation loss: 2.1117190468695854

Epoch: 6| Step: 6
Training loss: 2.473055124282837
Validation loss: 2.1109245002910657

Epoch: 6| Step: 7
Training loss: 1.3530997037887573
Validation loss: 2.1450018164932088

Epoch: 6| Step: 8
Training loss: 2.313507556915283
Validation loss: 2.1334914392040623

Epoch: 6| Step: 9
Training loss: 1.363631248474121
Validation loss: 2.1619520738560665

Epoch: 6| Step: 10
Training loss: 1.4075663089752197
Validation loss: 2.1219492009890977

Epoch: 6| Step: 11
Training loss: 1.4292008876800537
Validation loss: 2.1547790624762095

Epoch: 6| Step: 12
Training loss: 2.097527503967285
Validation loss: 2.1636731393875612

Epoch: 6| Step: 13
Training loss: 1.7472337484359741
Validation loss: 2.1307357088212044

Epoch: 377| Step: 0
Training loss: 2.2408366203308105
Validation loss: 2.1446754855494343

Epoch: 6| Step: 1
Training loss: 1.5728808641433716
Validation loss: 2.1364869186955113

Epoch: 6| Step: 2
Training loss: 1.2264432907104492
Validation loss: 2.127274992645428

Epoch: 6| Step: 3
Training loss: 1.991919994354248
Validation loss: 2.129782497241933

Epoch: 6| Step: 4
Training loss: 1.2289659976959229
Validation loss: 2.1430815471115934

Epoch: 6| Step: 5
Training loss: 1.589972734451294
Validation loss: 2.097052107575119

Epoch: 6| Step: 6
Training loss: 1.590900182723999
Validation loss: 2.139321101609097

Epoch: 6| Step: 7
Training loss: 1.3146106004714966
Validation loss: 2.129355784385435

Epoch: 6| Step: 8
Training loss: 2.1158952713012695
Validation loss: 2.1258476203487766

Epoch: 6| Step: 9
Training loss: 1.7084565162658691
Validation loss: 2.1208869308553715

Epoch: 6| Step: 10
Training loss: 1.7059330940246582
Validation loss: 2.134176984910042

Epoch: 6| Step: 11
Training loss: 1.1925902366638184
Validation loss: 2.1243452923272246

Epoch: 6| Step: 12
Training loss: 2.322845935821533
Validation loss: 2.0752172636729416

Epoch: 6| Step: 13
Training loss: 1.8297699689865112
Validation loss: 2.1257062265949864

Epoch: 378| Step: 0
Training loss: 1.7275067567825317
Validation loss: 2.1221890193159862

Epoch: 6| Step: 1
Training loss: 1.8094897270202637
Validation loss: 2.094418696177903

Epoch: 6| Step: 2
Training loss: 2.1347084045410156
Validation loss: 2.07110603778593

Epoch: 6| Step: 3
Training loss: 1.7209136486053467
Validation loss: 2.0915800961115028

Epoch: 6| Step: 4
Training loss: 1.7223670482635498
Validation loss: 2.09629915606591

Epoch: 6| Step: 5
Training loss: 1.3245398998260498
Validation loss: 2.0952447742544194

Epoch: 6| Step: 6
Training loss: 1.7825523614883423
Validation loss: 2.0935500719214

Epoch: 6| Step: 7
Training loss: 1.5054656267166138
Validation loss: 2.050756444213211

Epoch: 6| Step: 8
Training loss: 1.909879446029663
Validation loss: 2.0755941611464306

Epoch: 6| Step: 9
Training loss: 2.0169425010681152
Validation loss: 2.0851200139650734

Epoch: 6| Step: 10
Training loss: 1.1904860734939575
Validation loss: 2.0912525641020907

Epoch: 6| Step: 11
Training loss: 0.9379134178161621
Validation loss: 2.105658579898137

Epoch: 6| Step: 12
Training loss: 2.044792652130127
Validation loss: 2.090097096658522

Epoch: 6| Step: 13
Training loss: 2.1526143550872803
Validation loss: 2.0936096176024406

Epoch: 379| Step: 0
Training loss: 2.1749393939971924
Validation loss: 2.071244602562279

Epoch: 6| Step: 1
Training loss: 2.3515450954437256
Validation loss: 2.0772703001576085

Epoch: 6| Step: 2
Training loss: 1.8309963941574097
Validation loss: 2.1055530348131732

Epoch: 6| Step: 3
Training loss: 1.8972814083099365
Validation loss: 2.090426503971059

Epoch: 6| Step: 4
Training loss: 1.7562271356582642
Validation loss: 2.1441212187531176

Epoch: 6| Step: 5
Training loss: 1.443255066871643
Validation loss: 2.131087641562185

Epoch: 6| Step: 6
Training loss: 1.3010096549987793
Validation loss: 2.1150445989383164

Epoch: 6| Step: 7
Training loss: 0.9517430067062378
Validation loss: 2.0894839302186043

Epoch: 6| Step: 8
Training loss: 1.6392767429351807
Validation loss: 2.0993520418802896

Epoch: 6| Step: 9
Training loss: 1.7990740537643433
Validation loss: 2.1236829091143865

Epoch: 6| Step: 10
Training loss: 1.1553845405578613
Validation loss: 2.134063493820929

Epoch: 6| Step: 11
Training loss: 1.7803782224655151
Validation loss: 2.1023406187693277

Epoch: 6| Step: 12
Training loss: 1.7906075716018677
Validation loss: 2.1234343949184624

Epoch: 6| Step: 13
Training loss: 1.2032825946807861
Validation loss: 2.1073204035400064

Epoch: 380| Step: 0
Training loss: 2.0946273803710938
Validation loss: 2.110190922214139

Epoch: 6| Step: 1
Training loss: 1.8978270292282104
Validation loss: 2.138700387811148

Epoch: 6| Step: 2
Training loss: 1.2942044734954834
Validation loss: 2.1258531667852916

Epoch: 6| Step: 3
Training loss: 1.6701377630233765
Validation loss: 2.0997725584173716

Epoch: 6| Step: 4
Training loss: 0.9252636432647705
Validation loss: 2.0941763565104496

Epoch: 6| Step: 5
Training loss: 2.3348565101623535
Validation loss: 2.114509787610782

Epoch: 6| Step: 6
Training loss: 1.5238239765167236
Validation loss: 2.1025508796015093

Epoch: 6| Step: 7
Training loss: 1.9978272914886475
Validation loss: 2.1215386685504707

Epoch: 6| Step: 8
Training loss: 1.2753851413726807
Validation loss: 2.1345422421732256

Epoch: 6| Step: 9
Training loss: 1.6880168914794922
Validation loss: 2.1147791211323073

Epoch: 6| Step: 10
Training loss: 1.8103173971176147
Validation loss: 2.124644746062576

Epoch: 6| Step: 11
Training loss: 1.748800277709961
Validation loss: 2.1039854608556277

Epoch: 6| Step: 12
Training loss: 1.5835390090942383
Validation loss: 2.118368414140517

Epoch: 6| Step: 13
Training loss: 1.7375439405441284
Validation loss: 2.132179461499696

Epoch: 381| Step: 0
Training loss: 1.201111078262329
Validation loss: 2.110033704388526

Epoch: 6| Step: 1
Training loss: 1.670924425125122
Validation loss: 2.0972748776917816

Epoch: 6| Step: 2
Training loss: 1.8964942693710327
Validation loss: 2.089393997705111

Epoch: 6| Step: 3
Training loss: 0.9840407371520996
Validation loss: 2.127239264467711

Epoch: 6| Step: 4
Training loss: 1.4815260171890259
Validation loss: 2.087755596765908

Epoch: 6| Step: 5
Training loss: 1.7872493267059326
Validation loss: 2.0900110326787478

Epoch: 6| Step: 6
Training loss: 2.2052297592163086
Validation loss: 2.122529488737865

Epoch: 6| Step: 7
Training loss: 1.5651334524154663
Validation loss: 2.1245086423812376

Epoch: 6| Step: 8
Training loss: 2.0510096549987793
Validation loss: 2.124613749083652

Epoch: 6| Step: 9
Training loss: 1.6244821548461914
Validation loss: 2.0826369024092153

Epoch: 6| Step: 10
Training loss: 2.2498278617858887
Validation loss: 2.105030873770355

Epoch: 6| Step: 11
Training loss: 1.9815282821655273
Validation loss: 2.119402975164434

Epoch: 6| Step: 12
Training loss: 1.1468677520751953
Validation loss: 2.0911810462192824

Epoch: 6| Step: 13
Training loss: 1.8075447082519531
Validation loss: 2.1270302418739564

Epoch: 382| Step: 0
Training loss: 2.175701856613159
Validation loss: 2.1587769395561627

Epoch: 6| Step: 1
Training loss: 1.5930218696594238
Validation loss: 2.134353591549781

Epoch: 6| Step: 2
Training loss: 1.5876601934432983
Validation loss: 2.1323702450721496

Epoch: 6| Step: 3
Training loss: 1.2910139560699463
Validation loss: 2.1398497396899807

Epoch: 6| Step: 4
Training loss: 1.1950973272323608
Validation loss: 2.146292619807746

Epoch: 6| Step: 5
Training loss: 1.0902836322784424
Validation loss: 2.1344412860049995

Epoch: 6| Step: 6
Training loss: 1.9437930583953857
Validation loss: 2.166032511700866

Epoch: 6| Step: 7
Training loss: 2.907733917236328
Validation loss: 2.176151342289422

Epoch: 6| Step: 8
Training loss: 1.8085147142410278
Validation loss: 2.1355334763885825

Epoch: 6| Step: 9
Training loss: 1.7500054836273193
Validation loss: 2.1167211647956603

Epoch: 6| Step: 10
Training loss: 1.652629017829895
Validation loss: 2.1435175224017073

Epoch: 6| Step: 11
Training loss: 1.6444001197814941
Validation loss: 2.1172409493436097

Epoch: 6| Step: 12
Training loss: 1.5098795890808105
Validation loss: 2.125900753082768

Epoch: 6| Step: 13
Training loss: 1.32566237449646
Validation loss: 2.1165469590053765

Epoch: 383| Step: 0
Training loss: 1.7832176685333252
Validation loss: 2.106954055447732

Epoch: 6| Step: 1
Training loss: 2.02891206741333
Validation loss: 2.10766694366291

Epoch: 6| Step: 2
Training loss: 1.6022158861160278
Validation loss: 2.089667550979122

Epoch: 6| Step: 3
Training loss: 2.0593507289886475
Validation loss: 2.134652659457217

Epoch: 6| Step: 4
Training loss: 2.039762020111084
Validation loss: 2.0962346933221303

Epoch: 6| Step: 5
Training loss: 2.087826728820801
Validation loss: 2.1449821533695346

Epoch: 6| Step: 6
Training loss: 1.674922227859497
Validation loss: 2.1144639868890085

Epoch: 6| Step: 7
Training loss: 1.4193313121795654
Validation loss: 2.1178951289064143

Epoch: 6| Step: 8
Training loss: 2.0879909992218018
Validation loss: 2.1771042090590282

Epoch: 6| Step: 9
Training loss: 1.4936918020248413
Validation loss: 2.130765225297661

Epoch: 6| Step: 10
Training loss: 1.2606866359710693
Validation loss: 2.141199399066228

Epoch: 6| Step: 11
Training loss: 1.3376107215881348
Validation loss: 2.102360448529643

Epoch: 6| Step: 12
Training loss: 1.5256468057632446
Validation loss: 2.1340141040022655

Epoch: 6| Step: 13
Training loss: 1.2061659097671509
Validation loss: 2.1183003302543395

Epoch: 384| Step: 0
Training loss: 2.0294857025146484
Validation loss: 2.0943472180315243

Epoch: 6| Step: 1
Training loss: 2.1069207191467285
Validation loss: 2.1127131728715796

Epoch: 6| Step: 2
Training loss: 1.823960304260254
Validation loss: 2.1136792552086616

Epoch: 6| Step: 3
Training loss: 1.442697286605835
Validation loss: 2.1280691239141647

Epoch: 6| Step: 4
Training loss: 1.648906946182251
Validation loss: 2.145526119457778

Epoch: 6| Step: 5
Training loss: 1.7477943897247314
Validation loss: 2.1672534737535702

Epoch: 6| Step: 6
Training loss: 1.656956672668457
Validation loss: 2.1204897306298696

Epoch: 6| Step: 7
Training loss: 1.446428894996643
Validation loss: 2.084965491807589

Epoch: 6| Step: 8
Training loss: 1.4011509418487549
Validation loss: 2.0971106662545154

Epoch: 6| Step: 9
Training loss: 1.6552640199661255
Validation loss: 2.14555819701123

Epoch: 6| Step: 10
Training loss: 1.4292266368865967
Validation loss: 2.1259946156573553

Epoch: 6| Step: 11
Training loss: 1.9960737228393555
Validation loss: 2.122084871415169

Epoch: 6| Step: 12
Training loss: 1.276969075202942
Validation loss: 2.128492239982851

Epoch: 6| Step: 13
Training loss: 2.2244656085968018
Validation loss: 2.143834767803069

Epoch: 385| Step: 0
Training loss: 2.1822736263275146
Validation loss: 2.1130549779502292

Epoch: 6| Step: 1
Training loss: 1.385928988456726
Validation loss: 2.1654014279765468

Epoch: 6| Step: 2
Training loss: 1.4523539543151855
Validation loss: 2.1318213862757527

Epoch: 6| Step: 3
Training loss: 0.9092602729797363
Validation loss: 2.1197553014242523

Epoch: 6| Step: 4
Training loss: 1.8051592111587524
Validation loss: 2.1473515174722158

Epoch: 6| Step: 5
Training loss: 2.1716060638427734
Validation loss: 2.1363739287981423

Epoch: 6| Step: 6
Training loss: 1.0275202989578247
Validation loss: 2.172295424246019

Epoch: 6| Step: 7
Training loss: 2.0786476135253906
Validation loss: 2.12570833903487

Epoch: 6| Step: 8
Training loss: 1.7175248861312866
Validation loss: 2.1167512491185176

Epoch: 6| Step: 9
Training loss: 1.6187994480133057
Validation loss: 2.1512905269540767

Epoch: 6| Step: 10
Training loss: 1.9303550720214844
Validation loss: 2.0933476289113364

Epoch: 6| Step: 11
Training loss: 2.136791229248047
Validation loss: 2.1484307935160976

Epoch: 6| Step: 12
Training loss: 1.5890381336212158
Validation loss: 2.1234535401867283

Epoch: 6| Step: 13
Training loss: 1.1496434211730957
Validation loss: 2.0991619210089407

Epoch: 386| Step: 0
Training loss: 1.118941068649292
Validation loss: 2.1208077656325472

Epoch: 6| Step: 1
Training loss: 1.2016701698303223
Validation loss: 2.096341017753847

Epoch: 6| Step: 2
Training loss: 1.4333417415618896
Validation loss: 2.131537486148137

Epoch: 6| Step: 3
Training loss: 1.7125744819641113
Validation loss: 2.1435365241060973

Epoch: 6| Step: 4
Training loss: 1.531412959098816
Validation loss: 2.1009068232710644

Epoch: 6| Step: 5
Training loss: 2.358870029449463
Validation loss: 2.118366849037909

Epoch: 6| Step: 6
Training loss: 1.5952506065368652
Validation loss: 2.10578905382464

Epoch: 6| Step: 7
Training loss: 2.063754081726074
Validation loss: 2.0567316880790134

Epoch: 6| Step: 8
Training loss: 1.1772053241729736
Validation loss: 2.099499507616925

Epoch: 6| Step: 9
Training loss: 1.804624080657959
Validation loss: 2.0651238169721378

Epoch: 6| Step: 10
Training loss: 1.8205525875091553
Validation loss: 2.103414538086102

Epoch: 6| Step: 11
Training loss: 1.579969048500061
Validation loss: 2.0917836825052896

Epoch: 6| Step: 12
Training loss: 1.8390929698944092
Validation loss: 2.12158307977902

Epoch: 6| Step: 13
Training loss: 2.700009346008301
Validation loss: 2.1060703287842455

Epoch: 387| Step: 0
Training loss: 2.3089358806610107
Validation loss: 2.148551453826248

Epoch: 6| Step: 1
Training loss: 1.5898243188858032
Validation loss: 2.1165203355973765

Epoch: 6| Step: 2
Training loss: 1.4200901985168457
Validation loss: 2.136074639135791

Epoch: 6| Step: 3
Training loss: 1.9501996040344238
Validation loss: 2.1148761087848293

Epoch: 6| Step: 4
Training loss: 2.1437132358551025
Validation loss: 2.1327131358526086

Epoch: 6| Step: 5
Training loss: 0.8465324640274048
Validation loss: 2.1270026571007183

Epoch: 6| Step: 6
Training loss: 2.0091969966888428
Validation loss: 2.138033802791308

Epoch: 6| Step: 7
Training loss: 2.0211455821990967
Validation loss: 2.1467621659719818

Epoch: 6| Step: 8
Training loss: 1.2956042289733887
Validation loss: 2.126132784351226

Epoch: 6| Step: 9
Training loss: 1.6109048128128052
Validation loss: 2.1397213461578533

Epoch: 6| Step: 10
Training loss: 0.9903003573417664
Validation loss: 2.1273425907217045

Epoch: 6| Step: 11
Training loss: 1.9417784214019775
Validation loss: 2.110531565963581

Epoch: 6| Step: 12
Training loss: 1.3943023681640625
Validation loss: 2.0942616565253145

Epoch: 6| Step: 13
Training loss: 1.686343789100647
Validation loss: 2.098711727767862

Epoch: 388| Step: 0
Training loss: 1.5148756504058838
Validation loss: 2.0956776513848254

Epoch: 6| Step: 1
Training loss: 1.5572319030761719
Validation loss: 2.089289729313184

Epoch: 6| Step: 2
Training loss: 1.4905612468719482
Validation loss: 2.120511051147215

Epoch: 6| Step: 3
Training loss: 1.7630999088287354
Validation loss: 2.086099487479015

Epoch: 6| Step: 4
Training loss: 1.637425422668457
Validation loss: 2.1410595268331547

Epoch: 6| Step: 5
Training loss: 2.0796148777008057
Validation loss: 2.1146360994667135

Epoch: 6| Step: 6
Training loss: 1.9943898916244507
Validation loss: 2.101188628904281

Epoch: 6| Step: 7
Training loss: 2.0293869972229004
Validation loss: 2.1489400517555977

Epoch: 6| Step: 8
Training loss: 1.5593920946121216
Validation loss: 2.074704452227521

Epoch: 6| Step: 9
Training loss: 1.851982593536377
Validation loss: 2.1297949488444994

Epoch: 6| Step: 10
Training loss: 1.1275219917297363
Validation loss: 2.1591632109816357

Epoch: 6| Step: 11
Training loss: 1.5839262008666992
Validation loss: 2.136730094109812

Epoch: 6| Step: 12
Training loss: 1.7440428733825684
Validation loss: 2.1422271805424846

Epoch: 6| Step: 13
Training loss: 1.3739879131317139
Validation loss: 2.1392430618245113

Epoch: 389| Step: 0
Training loss: 1.5865659713745117
Validation loss: 2.126864260242831

Epoch: 6| Step: 1
Training loss: 1.688821792602539
Validation loss: 2.0477203322995092

Epoch: 6| Step: 2
Training loss: 1.5190222263336182
Validation loss: 2.0564470675683792

Epoch: 6| Step: 3
Training loss: 1.8475900888442993
Validation loss: 2.0963018196885304

Epoch: 6| Step: 4
Training loss: 1.1199404001235962
Validation loss: 2.133635574771512

Epoch: 6| Step: 5
Training loss: 1.732640266418457
Validation loss: 2.0975282474230696

Epoch: 6| Step: 6
Training loss: 1.4951051473617554
Validation loss: 2.104534040215195

Epoch: 6| Step: 7
Training loss: 1.7591125965118408
Validation loss: 2.0785823611802954

Epoch: 6| Step: 8
Training loss: 1.5827631950378418
Validation loss: 2.0984204174369894

Epoch: 6| Step: 9
Training loss: 1.9449834823608398
Validation loss: 2.132846906620969

Epoch: 6| Step: 10
Training loss: 0.9851531982421875
Validation loss: 2.1446967612030687

Epoch: 6| Step: 11
Training loss: 1.8436366319656372
Validation loss: 2.116298447373093

Epoch: 6| Step: 12
Training loss: 2.6493334770202637
Validation loss: 2.143306806523313

Epoch: 6| Step: 13
Training loss: 1.213124394416809
Validation loss: 2.0836763253775974

Epoch: 390| Step: 0
Training loss: 1.7139780521392822
Validation loss: 2.094993681036016

Epoch: 6| Step: 1
Training loss: 1.7322518825531006
Validation loss: 2.1602721419385684

Epoch: 6| Step: 2
Training loss: 1.184821367263794
Validation loss: 2.103238680029428

Epoch: 6| Step: 3
Training loss: 2.105766534805298
Validation loss: 2.1143921498329408

Epoch: 6| Step: 4
Training loss: 1.784618854522705
Validation loss: 2.120316118322393

Epoch: 6| Step: 5
Training loss: 1.6490898132324219
Validation loss: 2.1715782739782847

Epoch: 6| Step: 6
Training loss: 1.1445121765136719
Validation loss: 2.1080717015010055

Epoch: 6| Step: 7
Training loss: 3.0369176864624023
Validation loss: 2.114124959514987

Epoch: 6| Step: 8
Training loss: 1.5093616247177124
Validation loss: 2.1376797742741083

Epoch: 6| Step: 9
Training loss: 1.5030816793441772
Validation loss: 2.142154982013087

Epoch: 6| Step: 10
Training loss: 1.3759682178497314
Validation loss: 2.1158583318033526

Epoch: 6| Step: 11
Training loss: 1.7279207706451416
Validation loss: 2.1288008792425996

Epoch: 6| Step: 12
Training loss: 1.3246010541915894
Validation loss: 2.105803749894583

Epoch: 6| Step: 13
Training loss: 1.0966572761535645
Validation loss: 2.1052441878985335

Epoch: 391| Step: 0
Training loss: 1.6643257141113281
Validation loss: 2.113311145895271

Epoch: 6| Step: 1
Training loss: 1.3353984355926514
Validation loss: 2.108347169814571

Epoch: 6| Step: 2
Training loss: 1.6319416761398315
Validation loss: 2.1326321812086206

Epoch: 6| Step: 3
Training loss: 1.6337653398513794
Validation loss: 2.1362768860273462

Epoch: 6| Step: 4
Training loss: 2.271040678024292
Validation loss: 2.0994222715336788

Epoch: 6| Step: 5
Training loss: 1.6394612789154053
Validation loss: 2.083943251640566

Epoch: 6| Step: 6
Training loss: 1.5425703525543213
Validation loss: 2.0974385353826706

Epoch: 6| Step: 7
Training loss: 1.7406444549560547
Validation loss: 2.12188224382298

Epoch: 6| Step: 8
Training loss: 1.2138113975524902
Validation loss: 2.094961744482799

Epoch: 6| Step: 9
Training loss: 1.4639021158218384
Validation loss: 2.081479505826068

Epoch: 6| Step: 10
Training loss: 1.4099231958389282
Validation loss: 2.130979525145664

Epoch: 6| Step: 11
Training loss: 1.9079711437225342
Validation loss: 2.1137022536288024

Epoch: 6| Step: 12
Training loss: 2.5031955242156982
Validation loss: 2.1265038597968315

Epoch: 6| Step: 13
Training loss: 1.475695013999939
Validation loss: 2.133845152393464

Epoch: 392| Step: 0
Training loss: 1.9233895540237427
Validation loss: 2.115340276431012

Epoch: 6| Step: 1
Training loss: 1.0393449068069458
Validation loss: 2.1319315997503137

Epoch: 6| Step: 2
Training loss: 2.766498565673828
Validation loss: 2.1198755207882134

Epoch: 6| Step: 3
Training loss: 1.623472809791565
Validation loss: 2.1312474230284333

Epoch: 6| Step: 4
Training loss: 1.7026090621948242
Validation loss: 2.137269189280848

Epoch: 6| Step: 5
Training loss: 1.8827258348464966
Validation loss: 2.1236530221918577

Epoch: 6| Step: 6
Training loss: 1.4527027606964111
Validation loss: 2.128866569970244

Epoch: 6| Step: 7
Training loss: 1.2856483459472656
Validation loss: 2.1167209148406982

Epoch: 6| Step: 8
Training loss: 1.4866169691085815
Validation loss: 2.17983183809506

Epoch: 6| Step: 9
Training loss: 1.6904513835906982
Validation loss: 2.1376132772814844

Epoch: 6| Step: 10
Training loss: 1.1416469812393188
Validation loss: 2.1251308507816766

Epoch: 6| Step: 11
Training loss: 1.6322343349456787
Validation loss: 2.131178620041058

Epoch: 6| Step: 12
Training loss: 1.8630032539367676
Validation loss: 2.116051335488596

Epoch: 6| Step: 13
Training loss: 2.3090200424194336
Validation loss: 2.1465364809959167

Epoch: 393| Step: 0
Training loss: 2.3887970447540283
Validation loss: 2.1088430650772585

Epoch: 6| Step: 1
Training loss: 1.677797794342041
Validation loss: 2.1033075791533276

Epoch: 6| Step: 2
Training loss: 1.8825024366378784
Validation loss: 2.128546949355833

Epoch: 6| Step: 3
Training loss: 1.479238748550415
Validation loss: 2.1267779168262275

Epoch: 6| Step: 4
Training loss: 1.907449722290039
Validation loss: 2.074736815626903

Epoch: 6| Step: 5
Training loss: 1.702038288116455
Validation loss: 2.0874535422171316

Epoch: 6| Step: 6
Training loss: 1.1397082805633545
Validation loss: 2.1083686351776123

Epoch: 6| Step: 7
Training loss: 2.2495598793029785
Validation loss: 2.1176257723121235

Epoch: 6| Step: 8
Training loss: 2.300037384033203
Validation loss: 2.0712435155786495

Epoch: 6| Step: 9
Training loss: 1.1955785751342773
Validation loss: 2.1168775455926054

Epoch: 6| Step: 10
Training loss: 1.0962436199188232
Validation loss: 2.1060360041997765

Epoch: 6| Step: 11
Training loss: 1.9566832780838013
Validation loss: 2.0651126574444514

Epoch: 6| Step: 12
Training loss: 1.1413979530334473
Validation loss: 2.1019808118061354

Epoch: 6| Step: 13
Training loss: 0.782941997051239
Validation loss: 2.118316287635475

Epoch: 394| Step: 0
Training loss: 1.293899655342102
Validation loss: 2.120737491115447

Epoch: 6| Step: 1
Training loss: 0.9979379177093506
Validation loss: 2.1260349878700833

Epoch: 6| Step: 2
Training loss: 1.8780620098114014
Validation loss: 2.1326346653763966

Epoch: 6| Step: 3
Training loss: 1.9721686840057373
Validation loss: 2.1708896775399484

Epoch: 6| Step: 4
Training loss: 1.5604724884033203
Validation loss: 2.156005281274037

Epoch: 6| Step: 5
Training loss: 1.5819116830825806
Validation loss: 2.1084160958566973

Epoch: 6| Step: 6
Training loss: 2.0786666870117188
Validation loss: 2.140918080524732

Epoch: 6| Step: 7
Training loss: 2.21590518951416
Validation loss: 2.125802065736504

Epoch: 6| Step: 8
Training loss: 1.9730992317199707
Validation loss: 2.1311867083272626

Epoch: 6| Step: 9
Training loss: 1.4451371431350708
Validation loss: 2.127029667618454

Epoch: 6| Step: 10
Training loss: 2.0042576789855957
Validation loss: 2.1381845115333475

Epoch: 6| Step: 11
Training loss: 1.3939261436462402
Validation loss: 2.13968458226932

Epoch: 6| Step: 12
Training loss: 1.4139430522918701
Validation loss: 2.1303702131394417

Epoch: 6| Step: 13
Training loss: 1.165635585784912
Validation loss: 2.0906802967030513

Epoch: 395| Step: 0
Training loss: 1.5597519874572754
Validation loss: 2.0962220468828754

Epoch: 6| Step: 1
Training loss: 1.463033676147461
Validation loss: 2.0924097132939163

Epoch: 6| Step: 2
Training loss: 1.6478557586669922
Validation loss: 2.1136109059856785

Epoch: 6| Step: 3
Training loss: 2.300856113433838
Validation loss: 2.109679386179934

Epoch: 6| Step: 4
Training loss: 1.5042822360992432
Validation loss: 2.1109988407422136

Epoch: 6| Step: 5
Training loss: 1.5627597570419312
Validation loss: 2.08718958721366

Epoch: 6| Step: 6
Training loss: 2.651160478591919
Validation loss: 2.109073108242404

Epoch: 6| Step: 7
Training loss: 1.669133186340332
Validation loss: 2.131323501627932

Epoch: 6| Step: 8
Training loss: 1.6078805923461914
Validation loss: 2.094715879809472

Epoch: 6| Step: 9
Training loss: 2.108423948287964
Validation loss: 2.1190462984064573

Epoch: 6| Step: 10
Training loss: 1.4009442329406738
Validation loss: 2.1259187447127474

Epoch: 6| Step: 11
Training loss: 1.7308521270751953
Validation loss: 2.1312813374304

Epoch: 6| Step: 12
Training loss: 1.0666661262512207
Validation loss: 2.1057804425557456

Epoch: 6| Step: 13
Training loss: 0.5514175891876221
Validation loss: 2.0842541571586364

Epoch: 396| Step: 0
Training loss: 1.9368412494659424
Validation loss: 2.102775107147873

Epoch: 6| Step: 1
Training loss: 2.070303440093994
Validation loss: 2.100729403957244

Epoch: 6| Step: 2
Training loss: 1.691460371017456
Validation loss: 2.102327246819773

Epoch: 6| Step: 3
Training loss: 1.710432767868042
Validation loss: 2.155094923511628

Epoch: 6| Step: 4
Training loss: 0.9138600826263428
Validation loss: 2.1361366343754593

Epoch: 6| Step: 5
Training loss: 1.943533182144165
Validation loss: 2.1233176339057183

Epoch: 6| Step: 6
Training loss: 1.320480227470398
Validation loss: 2.128909149477559

Epoch: 6| Step: 7
Training loss: 1.962283968925476
Validation loss: 2.1313286289092033

Epoch: 6| Step: 8
Training loss: 1.372363567352295
Validation loss: 2.158588852933658

Epoch: 6| Step: 9
Training loss: 1.4794816970825195
Validation loss: 2.1076406304554274

Epoch: 6| Step: 10
Training loss: 2.331932306289673
Validation loss: 2.1474657007443008

Epoch: 6| Step: 11
Training loss: 1.3862909078598022
Validation loss: 2.1246162101786625

Epoch: 6| Step: 12
Training loss: 1.628628134727478
Validation loss: 2.1080118251103226

Epoch: 6| Step: 13
Training loss: 1.148165225982666
Validation loss: 2.139691355407879

Epoch: 397| Step: 0
Training loss: 1.3510297536849976
Validation loss: 2.118243214904621

Epoch: 6| Step: 1
Training loss: 1.460421085357666
Validation loss: 2.1113005620177074

Epoch: 6| Step: 2
Training loss: 1.6907964944839478
Validation loss: 2.1361375060132755

Epoch: 6| Step: 3
Training loss: 2.005929946899414
Validation loss: 2.0911081196159444

Epoch: 6| Step: 4
Training loss: 0.8836109638214111
Validation loss: 2.1220838921044463

Epoch: 6| Step: 5
Training loss: 1.3234068155288696
Validation loss: 2.0580975035185456

Epoch: 6| Step: 6
Training loss: 1.6934633255004883
Validation loss: 2.1156298319498696

Epoch: 6| Step: 7
Training loss: 1.66507887840271
Validation loss: 2.113184175183696

Epoch: 6| Step: 8
Training loss: 1.3918423652648926
Validation loss: 2.109819958286901

Epoch: 6| Step: 9
Training loss: 1.7900677919387817
Validation loss: 2.114238605704359

Epoch: 6| Step: 10
Training loss: 2.296471357345581
Validation loss: 2.083610773086548

Epoch: 6| Step: 11
Training loss: 1.6562073230743408
Validation loss: 2.153203461759834

Epoch: 6| Step: 12
Training loss: 2.359484910964966
Validation loss: 2.1003057059421333

Epoch: 6| Step: 13
Training loss: 1.615702509880066
Validation loss: 2.0985835521451888

Epoch: 398| Step: 0
Training loss: 1.3226172924041748
Validation loss: 2.137624297090756

Epoch: 6| Step: 1
Training loss: 1.362804651260376
Validation loss: 2.117574058553224

Epoch: 6| Step: 2
Training loss: 1.3129619359970093
Validation loss: 2.092736223692535

Epoch: 6| Step: 3
Training loss: 1.7701964378356934
Validation loss: 2.094155923012764

Epoch: 6| Step: 4
Training loss: 1.568412184715271
Validation loss: 2.149603548870292

Epoch: 6| Step: 5
Training loss: 1.7504889965057373
Validation loss: 2.0875448155146774

Epoch: 6| Step: 6
Training loss: 1.8416821956634521
Validation loss: 2.1241221645826935

Epoch: 6| Step: 7
Training loss: 1.9067682027816772
Validation loss: 2.0800800592668596

Epoch: 6| Step: 8
Training loss: 2.017266035079956
Validation loss: 2.1584815517548592

Epoch: 6| Step: 9
Training loss: 1.2040867805480957
Validation loss: 2.1249600123333674

Epoch: 6| Step: 10
Training loss: 1.856976866722107
Validation loss: 2.135069981698067

Epoch: 6| Step: 11
Training loss: 2.0685057640075684
Validation loss: 2.1084839618334206

Epoch: 6| Step: 12
Training loss: 1.677019476890564
Validation loss: 2.090960956388904

Epoch: 6| Step: 13
Training loss: 1.9032121896743774
Validation loss: 2.1163679451070805

Epoch: 399| Step: 0
Training loss: 1.5365550518035889
Validation loss: 2.108378137311628

Epoch: 6| Step: 1
Training loss: 1.4899364709854126
Validation loss: 2.096323372215353

Epoch: 6| Step: 2
Training loss: 1.6033000946044922
Validation loss: 2.092426274412422

Epoch: 6| Step: 3
Training loss: 2.410079002380371
Validation loss: 2.123652886318904

Epoch: 6| Step: 4
Training loss: 1.1803441047668457
Validation loss: 2.083869953309336

Epoch: 6| Step: 5
Training loss: 1.8634086847305298
Validation loss: 2.13254480079938

Epoch: 6| Step: 6
Training loss: 2.1784448623657227
Validation loss: 2.134918720491471

Epoch: 6| Step: 7
Training loss: 1.7663792371749878
Validation loss: 2.136301555941182

Epoch: 6| Step: 8
Training loss: 1.8995625972747803
Validation loss: 2.1376773670155513

Epoch: 6| Step: 9
Training loss: 1.5481338500976562
Validation loss: 2.153279553177536

Epoch: 6| Step: 10
Training loss: 1.258689045906067
Validation loss: 2.133560360118907

Epoch: 6| Step: 11
Training loss: 1.9238395690917969
Validation loss: 2.1693568050220446

Epoch: 6| Step: 12
Training loss: 1.1160564422607422
Validation loss: 2.098344285001037

Epoch: 6| Step: 13
Training loss: 1.3722550868988037
Validation loss: 2.1454109812295563

Epoch: 400| Step: 0
Training loss: 1.493058443069458
Validation loss: 2.1508073165852535

Epoch: 6| Step: 1
Training loss: 2.78585147857666
Validation loss: 2.1041437118284163

Epoch: 6| Step: 2
Training loss: 2.310482978820801
Validation loss: 2.1279160540591002

Epoch: 6| Step: 3
Training loss: 1.8293702602386475
Validation loss: 2.1027856616563696

Epoch: 6| Step: 4
Training loss: 0.9262291193008423
Validation loss: 2.1377218820715465

Epoch: 6| Step: 5
Training loss: 1.001821756362915
Validation loss: 2.1286957879220285

Epoch: 6| Step: 6
Training loss: 2.014796495437622
Validation loss: 2.0887092236549623

Epoch: 6| Step: 7
Training loss: 1.6001510620117188
Validation loss: 2.1307522161032564

Epoch: 6| Step: 8
Training loss: 1.1657509803771973
Validation loss: 2.138609941287707

Epoch: 6| Step: 9
Training loss: 1.593064785003662
Validation loss: 2.1131703956152803

Epoch: 6| Step: 10
Training loss: 2.030489921569824
Validation loss: 2.1232041799893944

Epoch: 6| Step: 11
Training loss: 1.203932523727417
Validation loss: 2.1686676317645657

Epoch: 6| Step: 12
Training loss: 1.1019032001495361
Validation loss: 2.128421365573842

Epoch: 6| Step: 13
Training loss: 2.1691575050354004
Validation loss: 2.141309876595774

Epoch: 401| Step: 0
Training loss: 1.9174768924713135
Validation loss: 2.1444694662606842

Epoch: 6| Step: 1
Training loss: 2.423191547393799
Validation loss: 2.119307884605982

Epoch: 6| Step: 2
Training loss: 1.5552635192871094
Validation loss: 2.1018293262809835

Epoch: 6| Step: 3
Training loss: 1.2505707740783691
Validation loss: 2.089580815325501

Epoch: 6| Step: 4
Training loss: 1.3040339946746826
Validation loss: 2.121667359464912

Epoch: 6| Step: 5
Training loss: 0.9476516246795654
Validation loss: 2.114797951072775

Epoch: 6| Step: 6
Training loss: 1.7183372974395752
Validation loss: 2.0974053670001287

Epoch: 6| Step: 7
Training loss: 1.7965528964996338
Validation loss: 2.1142905117363058

Epoch: 6| Step: 8
Training loss: 1.0653738975524902
Validation loss: 2.1054586223376694

Epoch: 6| Step: 9
Training loss: 1.4240257740020752
Validation loss: 2.12338960811656

Epoch: 6| Step: 10
Training loss: 1.9149621725082397
Validation loss: 2.126664423173474

Epoch: 6| Step: 11
Training loss: 1.6845335960388184
Validation loss: 2.1043852375399683

Epoch: 6| Step: 12
Training loss: 2.1776301860809326
Validation loss: 2.113918196770453

Epoch: 6| Step: 13
Training loss: 1.9075238704681396
Validation loss: 2.0830340398255216

Epoch: 402| Step: 0
Training loss: 1.501907467842102
Validation loss: 2.063089427127633

Epoch: 6| Step: 1
Training loss: 1.5369720458984375
Validation loss: 2.12496167613614

Epoch: 6| Step: 2
Training loss: 2.1491236686706543
Validation loss: 2.1059164565096617

Epoch: 6| Step: 3
Training loss: 2.5443880558013916
Validation loss: 2.132917473393102

Epoch: 6| Step: 4
Training loss: 1.3758686780929565
Validation loss: 2.1188241307453444

Epoch: 6| Step: 5
Training loss: 1.4255328178405762
Validation loss: 2.1421213432024886

Epoch: 6| Step: 6
Training loss: 1.3255727291107178
Validation loss: 2.1211450433218353

Epoch: 6| Step: 7
Training loss: 2.1864013671875
Validation loss: 2.0693960138546523

Epoch: 6| Step: 8
Training loss: 2.2174034118652344
Validation loss: 2.133612799388106

Epoch: 6| Step: 9
Training loss: 1.6715104579925537
Validation loss: 2.1200853240105415

Epoch: 6| Step: 10
Training loss: 1.1000804901123047
Validation loss: 2.114723279911985

Epoch: 6| Step: 11
Training loss: 1.6179251670837402
Validation loss: 2.164078058735017

Epoch: 6| Step: 12
Training loss: 0.8956568241119385
Validation loss: 2.1315024860443605

Epoch: 6| Step: 13
Training loss: 1.4600889682769775
Validation loss: 2.1169474663272982

Epoch: 403| Step: 0
Training loss: 1.5182063579559326
Validation loss: 2.1134116931628157

Epoch: 6| Step: 1
Training loss: 1.305833101272583
Validation loss: 2.1407362799490652

Epoch: 6| Step: 2
Training loss: 1.4742329120635986
Validation loss: 2.139161435506677

Epoch: 6| Step: 3
Training loss: 1.8792049884796143
Validation loss: 2.127043302341174

Epoch: 6| Step: 4
Training loss: 1.713409662246704
Validation loss: 2.1177184671484013

Epoch: 6| Step: 5
Training loss: 1.4895650148391724
Validation loss: 2.1251991897500973

Epoch: 6| Step: 6
Training loss: 2.131774425506592
Validation loss: 2.140519303660239

Epoch: 6| Step: 7
Training loss: 1.3137931823730469
Validation loss: 2.1421050435753277

Epoch: 6| Step: 8
Training loss: 2.1405723094940186
Validation loss: 2.1186522694044214

Epoch: 6| Step: 9
Training loss: 2.0151760578155518
Validation loss: 2.1173030061106526

Epoch: 6| Step: 10
Training loss: 1.4381102323532104
Validation loss: 2.102413995291597

Epoch: 6| Step: 11
Training loss: 1.6857128143310547
Validation loss: 2.1075255511909403

Epoch: 6| Step: 12
Training loss: 1.3916540145874023
Validation loss: 2.106287475555174

Epoch: 6| Step: 13
Training loss: 1.4006149768829346
Validation loss: 2.08933654908211

Epoch: 404| Step: 0
Training loss: 1.4033645391464233
Validation loss: 2.0811438368212793

Epoch: 6| Step: 1
Training loss: 1.1976242065429688
Validation loss: 2.1097265456312444

Epoch: 6| Step: 2
Training loss: 1.6854852437973022
Validation loss: 2.1344761002448296

Epoch: 6| Step: 3
Training loss: 1.6576595306396484
Validation loss: 2.1016217893169773

Epoch: 6| Step: 4
Training loss: 1.1789079904556274
Validation loss: 2.107695758983653

Epoch: 6| Step: 5
Training loss: 1.362748622894287
Validation loss: 2.075243247452603

Epoch: 6| Step: 6
Training loss: 1.9918498992919922
Validation loss: 2.1122887596007316

Epoch: 6| Step: 7
Training loss: 2.3671326637268066
Validation loss: 2.124896612218631

Epoch: 6| Step: 8
Training loss: 1.7354354858398438
Validation loss: 2.1156898467771468

Epoch: 6| Step: 9
Training loss: 2.0642666816711426
Validation loss: 2.0758639099777385

Epoch: 6| Step: 10
Training loss: 1.5411077737808228
Validation loss: 2.0929072569775324

Epoch: 6| Step: 11
Training loss: 1.2335597276687622
Validation loss: 2.1141774116023893

Epoch: 6| Step: 12
Training loss: 1.7336208820343018
Validation loss: 2.1161421229762416

Epoch: 6| Step: 13
Training loss: 1.848448634147644
Validation loss: 2.134318720909857

Epoch: 405| Step: 0
Training loss: 1.2241497039794922
Validation loss: 2.1069821849946053

Epoch: 6| Step: 1
Training loss: 1.7922972440719604
Validation loss: 2.1289542746800247

Epoch: 6| Step: 2
Training loss: 2.1009483337402344
Validation loss: 2.097315811341809

Epoch: 6| Step: 3
Training loss: 1.9732904434204102
Validation loss: 2.14086821258709

Epoch: 6| Step: 4
Training loss: 1.1271508932113647
Validation loss: 2.1203573955002653

Epoch: 6| Step: 5
Training loss: 1.88728928565979
Validation loss: 2.1057718697414605

Epoch: 6| Step: 6
Training loss: 1.2285454273223877
Validation loss: 2.1468323328161754

Epoch: 6| Step: 7
Training loss: 1.0328750610351562
Validation loss: 2.141105503164312

Epoch: 6| Step: 8
Training loss: 2.0884008407592773
Validation loss: 2.1315499749234927

Epoch: 6| Step: 9
Training loss: 1.5730737447738647
Validation loss: 2.151062014282391

Epoch: 6| Step: 10
Training loss: 1.493835210800171
Validation loss: 2.106338475340156

Epoch: 6| Step: 11
Training loss: 1.9908994436264038
Validation loss: 2.114899096950408

Epoch: 6| Step: 12
Training loss: 1.0268874168395996
Validation loss: 2.1243650554328837

Epoch: 6| Step: 13
Training loss: 2.544966220855713
Validation loss: 2.1513218982245332

Epoch: 406| Step: 0
Training loss: 1.7460215091705322
Validation loss: 2.14065134140753

Epoch: 6| Step: 1
Training loss: 1.4868773221969604
Validation loss: 2.0957976977030435

Epoch: 6| Step: 2
Training loss: 1.7317453622817993
Validation loss: 2.1753439646895214

Epoch: 6| Step: 3
Training loss: 1.66560959815979
Validation loss: 2.1318520192177064

Epoch: 6| Step: 4
Training loss: 1.9203346967697144
Validation loss: 2.1275105399470173

Epoch: 6| Step: 5
Training loss: 1.6834073066711426
Validation loss: 2.1007121916740172

Epoch: 6| Step: 6
Training loss: 2.5134148597717285
Validation loss: 2.056163690423453

Epoch: 6| Step: 7
Training loss: 0.9280520677566528
Validation loss: 2.095264555305563

Epoch: 6| Step: 8
Training loss: 1.3295905590057373
Validation loss: 2.092130148282615

Epoch: 6| Step: 9
Training loss: 1.356582522392273
Validation loss: 2.1063074091429352

Epoch: 6| Step: 10
Training loss: 2.0800909996032715
Validation loss: 2.1262298578857095

Epoch: 6| Step: 11
Training loss: 1.3295388221740723
Validation loss: 2.1228933808624104

Epoch: 6| Step: 12
Training loss: 1.580916166305542
Validation loss: 2.1194565911446848

Epoch: 6| Step: 13
Training loss: 1.5678317546844482
Validation loss: 2.109100091841913

Epoch: 407| Step: 0
Training loss: 1.4197494983673096
Validation loss: 2.122061764040301

Epoch: 6| Step: 1
Training loss: 2.136538028717041
Validation loss: 2.1499760766183176

Epoch: 6| Step: 2
Training loss: 1.3127906322479248
Validation loss: 2.121028025945028

Epoch: 6| Step: 3
Training loss: 1.8206028938293457
Validation loss: 2.1650618660834526

Epoch: 6| Step: 4
Training loss: 1.9711264371871948
Validation loss: 2.1214025174417803

Epoch: 6| Step: 5
Training loss: 1.627432107925415
Validation loss: 2.158652123584542

Epoch: 6| Step: 6
Training loss: 0.9699476957321167
Validation loss: 2.152007201666473

Epoch: 6| Step: 7
Training loss: 1.1183862686157227
Validation loss: 2.167371516586632

Epoch: 6| Step: 8
Training loss: 2.162254810333252
Validation loss: 2.1766214191272693

Epoch: 6| Step: 9
Training loss: 1.5937037467956543
Validation loss: 2.1542012973498275

Epoch: 6| Step: 10
Training loss: 2.1938490867614746
Validation loss: 2.157144956691291

Epoch: 6| Step: 11
Training loss: 1.3806449174880981
Validation loss: 2.175156201085737

Epoch: 6| Step: 12
Training loss: 2.033285617828369
Validation loss: 2.1447777619925876

Epoch: 6| Step: 13
Training loss: 1.5330003499984741
Validation loss: 2.1166050152112077

Epoch: 408| Step: 0
Training loss: 1.7560358047485352
Validation loss: 2.0793590750745548

Epoch: 6| Step: 1
Training loss: 1.4782154560089111
Validation loss: 2.167529090758293

Epoch: 6| Step: 2
Training loss: 0.9857900738716125
Validation loss: 2.08043417110238

Epoch: 6| Step: 3
Training loss: 1.7654036283493042
Validation loss: 2.1053414780606508

Epoch: 6| Step: 4
Training loss: 1.7901265621185303
Validation loss: 2.0837914200239283

Epoch: 6| Step: 5
Training loss: 1.5653725862503052
Validation loss: 2.11672620619497

Epoch: 6| Step: 6
Training loss: 1.6399846076965332
Validation loss: 2.1199829155398953

Epoch: 6| Step: 7
Training loss: 2.034296989440918
Validation loss: 2.085123159552133

Epoch: 6| Step: 8
Training loss: 1.8329352140426636
Validation loss: 2.1221826461053666

Epoch: 6| Step: 9
Training loss: 0.9962661266326904
Validation loss: 2.0963863813748924

Epoch: 6| Step: 10
Training loss: 1.5621953010559082
Validation loss: 2.1166311258910806

Epoch: 6| Step: 11
Training loss: 1.6224477291107178
Validation loss: 2.1301849926671674

Epoch: 6| Step: 12
Training loss: 2.1114554405212402
Validation loss: 2.10375871709598

Epoch: 6| Step: 13
Training loss: 1.9757264852523804
Validation loss: 2.1217842845506567

Epoch: 409| Step: 0
Training loss: 2.3895535469055176
Validation loss: 2.142044812120417

Epoch: 6| Step: 1
Training loss: 1.674333095550537
Validation loss: 2.1427267700113277

Epoch: 6| Step: 2
Training loss: 1.3063526153564453
Validation loss: 2.1521356182713665

Epoch: 6| Step: 3
Training loss: 1.2390034198760986
Validation loss: 2.174929695744668

Epoch: 6| Step: 4
Training loss: 1.6747956275939941
Validation loss: 2.152280169148599

Epoch: 6| Step: 5
Training loss: 1.2552846670150757
Validation loss: 2.1551219622294107

Epoch: 6| Step: 6
Training loss: 1.4796591997146606
Validation loss: 2.1407239103829987

Epoch: 6| Step: 7
Training loss: 1.6714357137680054
Validation loss: 2.1183218853448027

Epoch: 6| Step: 8
Training loss: 1.9150073528289795
Validation loss: 2.1378395275403093

Epoch: 6| Step: 9
Training loss: 1.0115915536880493
Validation loss: 2.1410253483762025

Epoch: 6| Step: 10
Training loss: 1.7391411066055298
Validation loss: 2.1195104506707962

Epoch: 6| Step: 11
Training loss: 1.7598979473114014
Validation loss: 2.094853562693442

Epoch: 6| Step: 12
Training loss: 1.6575946807861328
Validation loss: 2.0955602174164145

Epoch: 6| Step: 13
Training loss: 2.2995433807373047
Validation loss: 2.1060288759969894

Epoch: 410| Step: 0
Training loss: 1.8069841861724854
Validation loss: 2.111869660756921

Epoch: 6| Step: 1
Training loss: 1.501744270324707
Validation loss: 2.099487159841804

Epoch: 6| Step: 2
Training loss: 1.196822166442871
Validation loss: 2.171830077325144

Epoch: 6| Step: 3
Training loss: 2.6567223072052
Validation loss: 2.0912091437206475

Epoch: 6| Step: 4
Training loss: 1.1146528720855713
Validation loss: 2.090356737054804

Epoch: 6| Step: 5
Training loss: 1.3875869512557983
Validation loss: 2.145708541716299

Epoch: 6| Step: 6
Training loss: 0.9865188598632812
Validation loss: 2.124509965219805

Epoch: 6| Step: 7
Training loss: 1.4159040451049805
Validation loss: 2.1330025093529814

Epoch: 6| Step: 8
Training loss: 1.6956901550292969
Validation loss: 2.1257584197546846

Epoch: 6| Step: 9
Training loss: 1.6488971710205078
Validation loss: 2.101827016440771

Epoch: 6| Step: 10
Training loss: 2.4032201766967773
Validation loss: 2.0757507278073217

Epoch: 6| Step: 11
Training loss: 1.4572654962539673
Validation loss: 2.0854707661495415

Epoch: 6| Step: 12
Training loss: 1.43415367603302
Validation loss: 2.147333916797433

Epoch: 6| Step: 13
Training loss: 2.0466151237487793
Validation loss: 2.130220890045166

Epoch: 411| Step: 0
Training loss: 1.9083918333053589
Validation loss: 2.1215273667407293

Epoch: 6| Step: 1
Training loss: 1.5099892616271973
Validation loss: 2.1410168781075427

Epoch: 6| Step: 2
Training loss: 1.2988098859786987
Validation loss: 2.171648451077041

Epoch: 6| Step: 3
Training loss: 2.235037326812744
Validation loss: 2.1327261130015054

Epoch: 6| Step: 4
Training loss: 2.008988380432129
Validation loss: 2.1722446872342016

Epoch: 6| Step: 5
Training loss: 1.438144326210022
Validation loss: 2.160988898687465

Epoch: 6| Step: 6
Training loss: 2.396101236343384
Validation loss: 2.16010070103471

Epoch: 6| Step: 7
Training loss: 1.1891326904296875
Validation loss: 2.164248220382198

Epoch: 6| Step: 8
Training loss: 1.7373099327087402
Validation loss: 2.126169871258479

Epoch: 6| Step: 9
Training loss: 1.5030620098114014
Validation loss: 2.140819776442743

Epoch: 6| Step: 10
Training loss: 0.792025089263916
Validation loss: 2.1165711559275144

Epoch: 6| Step: 11
Training loss: 1.2797117233276367
Validation loss: 2.134466443010556

Epoch: 6| Step: 12
Training loss: 1.7835195064544678
Validation loss: 2.118683591965706

Epoch: 6| Step: 13
Training loss: 1.8796942234039307
Validation loss: 2.1472553322392125

Epoch: 412| Step: 0
Training loss: 1.6831767559051514
Validation loss: 2.1129864646542456

Epoch: 6| Step: 1
Training loss: 1.3809295892715454
Validation loss: 2.110846698925059

Epoch: 6| Step: 2
Training loss: 1.0998194217681885
Validation loss: 2.1472645703182427

Epoch: 6| Step: 3
Training loss: 1.614314079284668
Validation loss: 2.1311181847767164

Epoch: 6| Step: 4
Training loss: 1.3675014972686768
Validation loss: 2.1325402926373225

Epoch: 6| Step: 5
Training loss: 1.2516669034957886
Validation loss: 2.107712135520033

Epoch: 6| Step: 6
Training loss: 1.9139710664749146
Validation loss: 2.0887028209624754

Epoch: 6| Step: 7
Training loss: 1.5519992113113403
Validation loss: 2.0965623342862694

Epoch: 6| Step: 8
Training loss: 1.6857390403747559
Validation loss: 2.115620049097205

Epoch: 6| Step: 9
Training loss: 2.4098143577575684
Validation loss: 2.1201498380271335

Epoch: 6| Step: 10
Training loss: 1.6668351888656616
Validation loss: 2.1221975511120212

Epoch: 6| Step: 11
Training loss: 1.6465433835983276
Validation loss: 2.109932564919995

Epoch: 6| Step: 12
Training loss: 1.1053251028060913
Validation loss: 2.1477470551767657

Epoch: 6| Step: 13
Training loss: 3.1212832927703857
Validation loss: 2.113150983728388

Epoch: 413| Step: 0
Training loss: 1.6934409141540527
Validation loss: 2.1220699433357484

Epoch: 6| Step: 1
Training loss: 1.709436058998108
Validation loss: 2.123847287188294

Epoch: 6| Step: 2
Training loss: 1.6935858726501465
Validation loss: 2.1016633561862412

Epoch: 6| Step: 3
Training loss: 1.6813888549804688
Validation loss: 2.164968131690897

Epoch: 6| Step: 4
Training loss: 2.461378574371338
Validation loss: 2.1803502190497612

Epoch: 6| Step: 5
Training loss: 1.8600366115570068
Validation loss: 2.1181806082366617

Epoch: 6| Step: 6
Training loss: 1.7558188438415527
Validation loss: 2.1509051656210296

Epoch: 6| Step: 7
Training loss: 0.8386693000793457
Validation loss: 2.1827814091918287

Epoch: 6| Step: 8
Training loss: 1.1384352445602417
Validation loss: 2.1385295621810423

Epoch: 6| Step: 9
Training loss: 1.3826217651367188
Validation loss: 2.110524651824787

Epoch: 6| Step: 10
Training loss: 1.5456315279006958
Validation loss: 2.1444529423149685

Epoch: 6| Step: 11
Training loss: 2.1852118968963623
Validation loss: 2.127831341117941

Epoch: 6| Step: 12
Training loss: 1.5766175985336304
Validation loss: 2.1232588496259464

Epoch: 6| Step: 13
Training loss: 0.8920583724975586
Validation loss: 2.1175058093122257

Epoch: 414| Step: 0
Training loss: 0.8804787397384644
Validation loss: 2.1022196918405514

Epoch: 6| Step: 1
Training loss: 1.4893832206726074
Validation loss: 2.1238511775129583

Epoch: 6| Step: 2
Training loss: 1.3578401803970337
Validation loss: 2.117128954138807

Epoch: 6| Step: 3
Training loss: 2.0576064586639404
Validation loss: 2.110264096208798

Epoch: 6| Step: 4
Training loss: 2.160968780517578
Validation loss: 2.0932841685510453

Epoch: 6| Step: 5
Training loss: 1.3771648406982422
Validation loss: 2.091522098869406

Epoch: 6| Step: 6
Training loss: 1.6388254165649414
Validation loss: 2.126147416330153

Epoch: 6| Step: 7
Training loss: 1.4560167789459229
Validation loss: 2.085097889746389

Epoch: 6| Step: 8
Training loss: 1.2924768924713135
Validation loss: 2.093352863865514

Epoch: 6| Step: 9
Training loss: 2.2258245944976807
Validation loss: 2.0785229641904115

Epoch: 6| Step: 10
Training loss: 1.295426368713379
Validation loss: 2.130092038903185

Epoch: 6| Step: 11
Training loss: 1.8790253400802612
Validation loss: 2.1294755640850274

Epoch: 6| Step: 12
Training loss: 1.8996562957763672
Validation loss: 2.1000787045366023

Epoch: 6| Step: 13
Training loss: 1.2394957542419434
Validation loss: 2.1453293279934953

Epoch: 415| Step: 0
Training loss: 1.9979469776153564
Validation loss: 2.1092459899122997

Epoch: 6| Step: 1
Training loss: 2.133906841278076
Validation loss: 2.1138709347735167

Epoch: 6| Step: 2
Training loss: 1.3336224555969238
Validation loss: 2.079094922670754

Epoch: 6| Step: 3
Training loss: 1.437892198562622
Validation loss: 2.090055424679992

Epoch: 6| Step: 4
Training loss: 1.5773077011108398
Validation loss: 2.149820420049852

Epoch: 6| Step: 5
Training loss: 2.0905141830444336
Validation loss: 2.109461244716439

Epoch: 6| Step: 6
Training loss: 1.3253016471862793
Validation loss: 2.1315115703049528

Epoch: 6| Step: 7
Training loss: 1.2925525903701782
Validation loss: 2.131317061762656

Epoch: 6| Step: 8
Training loss: 2.229928493499756
Validation loss: 2.107444235073623

Epoch: 6| Step: 9
Training loss: 2.1220850944519043
Validation loss: 2.124822433276843

Epoch: 6| Step: 10
Training loss: 1.6853797435760498
Validation loss: 2.152051309103607

Epoch: 6| Step: 11
Training loss: 0.9741942286491394
Validation loss: 2.137759993153234

Epoch: 6| Step: 12
Training loss: 1.3752672672271729
Validation loss: 2.1096702109101

Epoch: 6| Step: 13
Training loss: 0.8385475277900696
Validation loss: 2.104156906886767

Epoch: 416| Step: 0
Training loss: 2.1687588691711426
Validation loss: 2.1202305427161594

Epoch: 6| Step: 1
Training loss: 1.1590111255645752
Validation loss: 2.1140191990842103

Epoch: 6| Step: 2
Training loss: 1.4118953943252563
Validation loss: 2.1446516334369616

Epoch: 6| Step: 3
Training loss: 1.4876809120178223
Validation loss: 2.115954311945105

Epoch: 6| Step: 4
Training loss: 1.2245604991912842
Validation loss: 2.098799038958806

Epoch: 6| Step: 5
Training loss: 2.0725293159484863
Validation loss: 2.1138474505434752

Epoch: 6| Step: 6
Training loss: 1.5284843444824219
Validation loss: 2.157077794433922

Epoch: 6| Step: 7
Training loss: 1.662402868270874
Validation loss: 2.1082292884908695

Epoch: 6| Step: 8
Training loss: 1.9195451736450195
Validation loss: 2.1081675021879134

Epoch: 6| Step: 9
Training loss: 1.2138874530792236
Validation loss: 2.143749643397588

Epoch: 6| Step: 10
Training loss: 2.051384449005127
Validation loss: 2.119530846995692

Epoch: 6| Step: 11
Training loss: 1.379832148551941
Validation loss: 2.116570529117379

Epoch: 6| Step: 12
Training loss: 1.9154560565948486
Validation loss: 2.118931398596815

Epoch: 6| Step: 13
Training loss: 1.655160903930664
Validation loss: 2.0901756773712816

Epoch: 417| Step: 0
Training loss: 1.35275137424469
Validation loss: 2.098430082362185

Epoch: 6| Step: 1
Training loss: 1.8574442863464355
Validation loss: 2.1197562038257556

Epoch: 6| Step: 2
Training loss: 1.6642709970474243
Validation loss: 2.1041943193763815

Epoch: 6| Step: 3
Training loss: 0.7546391487121582
Validation loss: 2.149889599892401

Epoch: 6| Step: 4
Training loss: 2.1545891761779785
Validation loss: 2.147650045733298

Epoch: 6| Step: 5
Training loss: 1.559705138206482
Validation loss: 2.1204717261816866

Epoch: 6| Step: 6
Training loss: 1.2815697193145752
Validation loss: 2.125559296659244

Epoch: 6| Step: 7
Training loss: 1.293157696723938
Validation loss: 2.1124425857297835

Epoch: 6| Step: 8
Training loss: 1.4040968418121338
Validation loss: 2.0888602913066907

Epoch: 6| Step: 9
Training loss: 1.3975749015808105
Validation loss: 2.105618066685174

Epoch: 6| Step: 10
Training loss: 2.0195930004119873
Validation loss: 2.1117553839119534

Epoch: 6| Step: 11
Training loss: 1.6122100353240967
Validation loss: 2.095981256936186

Epoch: 6| Step: 12
Training loss: 1.9846348762512207
Validation loss: 2.1117638541806127

Epoch: 6| Step: 13
Training loss: 2.4646835327148438
Validation loss: 2.104145383322111

Epoch: 418| Step: 0
Training loss: 2.0032687187194824
Validation loss: 2.1299626314511864

Epoch: 6| Step: 1
Training loss: 1.1289584636688232
Validation loss: 2.132249565534694

Epoch: 6| Step: 2
Training loss: 2.1362569332122803
Validation loss: 2.143858327660509

Epoch: 6| Step: 3
Training loss: 2.1345419883728027
Validation loss: 2.1268652459626556

Epoch: 6| Step: 4
Training loss: 1.0929597616195679
Validation loss: 2.1514467577780447

Epoch: 6| Step: 5
Training loss: 2.061767101287842
Validation loss: 2.1278257959632465

Epoch: 6| Step: 6
Training loss: 1.6588939428329468
Validation loss: 2.122968053305021

Epoch: 6| Step: 7
Training loss: 1.899444580078125
Validation loss: 2.129230030121342

Epoch: 6| Step: 8
Training loss: 1.2623498439788818
Validation loss: 2.106467044481667

Epoch: 6| Step: 9
Training loss: 1.4089844226837158
Validation loss: 2.09053817102986

Epoch: 6| Step: 10
Training loss: 1.250114917755127
Validation loss: 2.1038071160675376

Epoch: 6| Step: 11
Training loss: 1.839690923690796
Validation loss: 2.1087756105648574

Epoch: 6| Step: 12
Training loss: 1.3973325490951538
Validation loss: 2.1276307106018066

Epoch: 6| Step: 13
Training loss: 1.02028226852417
Validation loss: 2.152863138465471

Epoch: 419| Step: 0
Training loss: 1.8023600578308105
Validation loss: 2.107812871215164

Epoch: 6| Step: 1
Training loss: 1.4582164287567139
Validation loss: 2.0908647544922365

Epoch: 6| Step: 2
Training loss: 1.0904178619384766
Validation loss: 2.1108289085408694

Epoch: 6| Step: 3
Training loss: 2.173671007156372
Validation loss: 2.1312876952591764

Epoch: 6| Step: 4
Training loss: 1.1293927431106567
Validation loss: 2.067087474689689

Epoch: 6| Step: 5
Training loss: 0.7496797442436218
Validation loss: 2.080069770095169

Epoch: 6| Step: 6
Training loss: 1.9893522262573242
Validation loss: 2.0825562682203067

Epoch: 6| Step: 7
Training loss: 1.5589300394058228
Validation loss: 2.0906028234830467

Epoch: 6| Step: 8
Training loss: 2.094067096710205
Validation loss: 2.123663627973167

Epoch: 6| Step: 9
Training loss: 1.8662045001983643
Validation loss: 2.1129023234049478

Epoch: 6| Step: 10
Training loss: 1.7793292999267578
Validation loss: 2.085834715956001

Epoch: 6| Step: 11
Training loss: 1.9989830255508423
Validation loss: 2.075117991816613

Epoch: 6| Step: 12
Training loss: 1.2935847043991089
Validation loss: 2.0858748369319464

Epoch: 6| Step: 13
Training loss: 1.3700823783874512
Validation loss: 2.103852443797614

Epoch: 420| Step: 0
Training loss: 1.257624864578247
Validation loss: 2.0978821708310034

Epoch: 6| Step: 1
Training loss: 1.3819636106491089
Validation loss: 2.114844117113339

Epoch: 6| Step: 2
Training loss: 1.4098196029663086
Validation loss: 2.0794962349758355

Epoch: 6| Step: 3
Training loss: 1.409593105316162
Validation loss: 2.0891429173049105

Epoch: 6| Step: 4
Training loss: 1.8986895084381104
Validation loss: 2.13077542602375

Epoch: 6| Step: 5
Training loss: 1.5559810400009155
Validation loss: 2.1246089576393046

Epoch: 6| Step: 6
Training loss: 2.035316228866577
Validation loss: 2.1006131056816346

Epoch: 6| Step: 7
Training loss: 1.488260269165039
Validation loss: 2.148821851258637

Epoch: 6| Step: 8
Training loss: 1.2380330562591553
Validation loss: 2.113990900337055

Epoch: 6| Step: 9
Training loss: 2.0836198329925537
Validation loss: 2.1334996223449707

Epoch: 6| Step: 10
Training loss: 1.6792811155319214
Validation loss: 2.1326212036994194

Epoch: 6| Step: 11
Training loss: 1.8286923170089722
Validation loss: 2.0806830160079466

Epoch: 6| Step: 12
Training loss: 1.425647497177124
Validation loss: 2.0763484188305434

Epoch: 6| Step: 13
Training loss: 2.2497663497924805
Validation loss: 2.1013643690334853

Epoch: 421| Step: 0
Training loss: 1.380751609802246
Validation loss: 2.1185094348845945

Epoch: 6| Step: 1
Training loss: 1.5643718242645264
Validation loss: 2.137709386887089

Epoch: 6| Step: 2
Training loss: 1.664424180984497
Validation loss: 2.095433763278428

Epoch: 6| Step: 3
Training loss: 1.8094297647476196
Validation loss: 2.0828485142800117

Epoch: 6| Step: 4
Training loss: 2.1745917797088623
Validation loss: 2.091015124833712

Epoch: 6| Step: 5
Training loss: 2.1215295791625977
Validation loss: 2.1164427752135904

Epoch: 6| Step: 6
Training loss: 1.2923088073730469
Validation loss: 2.107929206663562

Epoch: 6| Step: 7
Training loss: 1.2620713710784912
Validation loss: 2.124279001707672

Epoch: 6| Step: 8
Training loss: 1.198732614517212
Validation loss: 2.116813918595673

Epoch: 6| Step: 9
Training loss: 1.3532211780548096
Validation loss: 2.1218394258970856

Epoch: 6| Step: 10
Training loss: 1.8622033596038818
Validation loss: 2.107605459869549

Epoch: 6| Step: 11
Training loss: 1.945992350578308
Validation loss: 2.1025730204838577

Epoch: 6| Step: 12
Training loss: 1.5006195306777954
Validation loss: 2.1165060740645214

Epoch: 6| Step: 13
Training loss: 1.43329918384552
Validation loss: 2.0965008069110174

Epoch: 422| Step: 0
Training loss: 1.4494493007659912
Validation loss: 2.0965163746187763

Epoch: 6| Step: 1
Training loss: 1.5646083354949951
Validation loss: 2.119465681814378

Epoch: 6| Step: 2
Training loss: 0.9542126655578613
Validation loss: 2.119402914918879

Epoch: 6| Step: 3
Training loss: 1.3651492595672607
Validation loss: 2.111776141710179

Epoch: 6| Step: 4
Training loss: 1.8765006065368652
Validation loss: 2.103195257084344

Epoch: 6| Step: 5
Training loss: 1.2570338249206543
Validation loss: 2.1516629572837584

Epoch: 6| Step: 6
Training loss: 1.479250192642212
Validation loss: 2.063699822272024

Epoch: 6| Step: 7
Training loss: 1.247758388519287
Validation loss: 2.110457403685457

Epoch: 6| Step: 8
Training loss: 2.62041974067688
Validation loss: 2.130611842678439

Epoch: 6| Step: 9
Training loss: 2.711574077606201
Validation loss: 2.1161437085879746

Epoch: 6| Step: 10
Training loss: 1.5852961540222168
Validation loss: 2.11288337169155

Epoch: 6| Step: 11
Training loss: 1.240619421005249
Validation loss: 2.1181545565205235

Epoch: 6| Step: 12
Training loss: 2.111577033996582
Validation loss: 2.11457432341832

Epoch: 6| Step: 13
Training loss: 0.7038729786872864
Validation loss: 2.1174189634220575

Epoch: 423| Step: 0
Training loss: 1.5821104049682617
Validation loss: 2.110300240978118

Epoch: 6| Step: 1
Training loss: 1.4205020666122437
Validation loss: 2.124946258401358

Epoch: 6| Step: 2
Training loss: 1.78922700881958
Validation loss: 2.103113273138641

Epoch: 6| Step: 3
Training loss: 0.7979760766029358
Validation loss: 2.1241471690516316

Epoch: 6| Step: 4
Training loss: 1.6306896209716797
Validation loss: 2.0995023865853586

Epoch: 6| Step: 5
Training loss: 1.25187087059021
Validation loss: 2.1079317600496355

Epoch: 6| Step: 6
Training loss: 1.6889877319335938
Validation loss: 2.134474023695915

Epoch: 6| Step: 7
Training loss: 1.7911044359207153
Validation loss: 2.136837864434847

Epoch: 6| Step: 8
Training loss: 1.159470796585083
Validation loss: 2.1299072311770533

Epoch: 6| Step: 9
Training loss: 2.3636372089385986
Validation loss: 2.1308111939378964

Epoch: 6| Step: 10
Training loss: 1.5401462316513062
Validation loss: 2.108072219356414

Epoch: 6| Step: 11
Training loss: 1.267570972442627
Validation loss: 2.095123326906594

Epoch: 6| Step: 12
Training loss: 2.182166576385498
Validation loss: 2.134955470279981

Epoch: 6| Step: 13
Training loss: 1.316201090812683
Validation loss: 2.1158821121338875

Epoch: 424| Step: 0
Training loss: 1.0306882858276367
Validation loss: 2.1266750494639077

Epoch: 6| Step: 1
Training loss: 1.7234479188919067
Validation loss: 2.10458714987642

Epoch: 6| Step: 2
Training loss: 1.486565113067627
Validation loss: 2.1190922196193407

Epoch: 6| Step: 3
Training loss: 2.0876431465148926
Validation loss: 2.1405601527101252

Epoch: 6| Step: 4
Training loss: 1.9165596961975098
Validation loss: 2.1645123394586707

Epoch: 6| Step: 5
Training loss: 1.6391806602478027
Validation loss: 2.1345154239285375

Epoch: 6| Step: 6
Training loss: 1.793130874633789
Validation loss: 2.18534335782451

Epoch: 6| Step: 7
Training loss: 2.3081510066986084
Validation loss: 2.1278203379723335

Epoch: 6| Step: 8
Training loss: 1.5513036251068115
Validation loss: 2.115761387732721

Epoch: 6| Step: 9
Training loss: 1.423069953918457
Validation loss: 2.0824247124374553

Epoch: 6| Step: 10
Training loss: 1.3732125759124756
Validation loss: 2.148120523780905

Epoch: 6| Step: 11
Training loss: 1.2989230155944824
Validation loss: 2.1042638337740334

Epoch: 6| Step: 12
Training loss: 1.290004014968872
Validation loss: 2.1159467107506207

Epoch: 6| Step: 13
Training loss: 1.2105803489685059
Validation loss: 2.1075341368234284

Epoch: 425| Step: 0
Training loss: 2.157494068145752
Validation loss: 2.094587472177321

Epoch: 6| Step: 1
Training loss: 2.24806809425354
Validation loss: 2.1332283558384066

Epoch: 6| Step: 2
Training loss: 1.1299526691436768
Validation loss: 2.1148393179780696

Epoch: 6| Step: 3
Training loss: 2.1257598400115967
Validation loss: 2.17836489728702

Epoch: 6| Step: 4
Training loss: 1.125213861465454
Validation loss: 2.17459003643323

Epoch: 6| Step: 5
Training loss: 1.9315351247787476
Validation loss: 2.1419007867895146

Epoch: 6| Step: 6
Training loss: 1.911268949508667
Validation loss: 2.1443358877653718

Epoch: 6| Step: 7
Training loss: 1.8760247230529785
Validation loss: 2.1422880516257337

Epoch: 6| Step: 8
Training loss: 1.6915929317474365
Validation loss: 2.1460667733223207

Epoch: 6| Step: 9
Training loss: 1.5371546745300293
Validation loss: 2.110208842062181

Epoch: 6| Step: 10
Training loss: 1.1944692134857178
Validation loss: 2.1346789124191448

Epoch: 6| Step: 11
Training loss: 1.0066381692886353
Validation loss: 2.126035592889273

Epoch: 6| Step: 12
Training loss: 1.1337295770645142
Validation loss: 2.1482169051324167

Epoch: 6| Step: 13
Training loss: 1.4671881198883057
Validation loss: 2.1153277684283514

Epoch: 426| Step: 0
Training loss: 2.093393325805664
Validation loss: 2.1412554146141134

Epoch: 6| Step: 1
Training loss: 1.7957322597503662
Validation loss: 2.137290326497888

Epoch: 6| Step: 2
Training loss: 2.3831517696380615
Validation loss: 2.0996922318653395

Epoch: 6| Step: 3
Training loss: 1.9549779891967773
Validation loss: 2.074319020394356

Epoch: 6| Step: 4
Training loss: 1.4687634706497192
Validation loss: 2.0735761914201962

Epoch: 6| Step: 5
Training loss: 1.2708179950714111
Validation loss: 2.0945068174792874

Epoch: 6| Step: 6
Training loss: 0.8076983690261841
Validation loss: 2.055385289653655

Epoch: 6| Step: 7
Training loss: 1.4058219194412231
Validation loss: 2.1030238674532984

Epoch: 6| Step: 8
Training loss: 1.5578500032424927
Validation loss: 2.0736851692199707

Epoch: 6| Step: 9
Training loss: 1.6353949308395386
Validation loss: 2.0910683396042034

Epoch: 6| Step: 10
Training loss: 1.474214792251587
Validation loss: 2.095075315044772

Epoch: 6| Step: 11
Training loss: 1.3998876810073853
Validation loss: 2.1266684250165055

Epoch: 6| Step: 12
Training loss: 1.811481237411499
Validation loss: 2.0827532173484884

Epoch: 6| Step: 13
Training loss: 1.30934476852417
Validation loss: 2.1244783952671993

Epoch: 427| Step: 0
Training loss: 0.9486799240112305
Validation loss: 2.072366109458349

Epoch: 6| Step: 1
Training loss: 2.2816057205200195
Validation loss: 2.1609825498314312

Epoch: 6| Step: 2
Training loss: 1.3381552696228027
Validation loss: 2.1442588503642748

Epoch: 6| Step: 3
Training loss: 1.3592697381973267
Validation loss: 2.130483619628414

Epoch: 6| Step: 4
Training loss: 1.5328702926635742
Validation loss: 2.144629011871994

Epoch: 6| Step: 5
Training loss: 1.7907426357269287
Validation loss: 2.1563828914396224

Epoch: 6| Step: 6
Training loss: 1.8161242008209229
Validation loss: 2.1457830936677995

Epoch: 6| Step: 7
Training loss: 1.2258919477462769
Validation loss: 2.161754492790468

Epoch: 6| Step: 8
Training loss: 1.8594090938568115
Validation loss: 2.1431440973794587

Epoch: 6| Step: 9
Training loss: 1.720625638961792
Validation loss: 2.1537359145379837

Epoch: 6| Step: 10
Training loss: 1.470242977142334
Validation loss: 2.1573548496410413

Epoch: 6| Step: 11
Training loss: 1.8674819469451904
Validation loss: 2.1502909378338884

Epoch: 6| Step: 12
Training loss: 1.940746784210205
Validation loss: 2.1305425910539526

Epoch: 6| Step: 13
Training loss: 1.244201898574829
Validation loss: 2.128712995077974

Epoch: 428| Step: 0
Training loss: 1.5175098180770874
Validation loss: 2.123749033097298

Epoch: 6| Step: 1
Training loss: 1.6182966232299805
Validation loss: 2.106051800071552

Epoch: 6| Step: 2
Training loss: 1.4023411273956299
Validation loss: 2.1028186672477314

Epoch: 6| Step: 3
Training loss: 2.3895390033721924
Validation loss: 2.081889139708652

Epoch: 6| Step: 4
Training loss: 1.324705958366394
Validation loss: 2.139152874228775

Epoch: 6| Step: 5
Training loss: 1.9870232343673706
Validation loss: 2.1108994304492907

Epoch: 6| Step: 6
Training loss: 1.2556002140045166
Validation loss: 2.1074547178001812

Epoch: 6| Step: 7
Training loss: 1.8676233291625977
Validation loss: 2.105471246985979

Epoch: 6| Step: 8
Training loss: 1.3092710971832275
Validation loss: 2.1403716482141966

Epoch: 6| Step: 9
Training loss: 1.4900991916656494
Validation loss: 2.11509753939926

Epoch: 6| Step: 10
Training loss: 1.4118824005126953
Validation loss: 2.0754672788804576

Epoch: 6| Step: 11
Training loss: 1.698034405708313
Validation loss: 2.0964361262577835

Epoch: 6| Step: 12
Training loss: 1.2732739448547363
Validation loss: 2.1122140474216913

Epoch: 6| Step: 13
Training loss: 2.0320284366607666
Validation loss: 2.083290564116611

Epoch: 429| Step: 0
Training loss: 1.0330597162246704
Validation loss: 2.1237864673778577

Epoch: 6| Step: 1
Training loss: 1.5773210525512695
Validation loss: 2.0655546893355665

Epoch: 6| Step: 2
Training loss: 1.434653878211975
Validation loss: 2.0414085439456406

Epoch: 6| Step: 3
Training loss: 1.9676401615142822
Validation loss: 2.0941785920050835

Epoch: 6| Step: 4
Training loss: 1.2156351804733276
Validation loss: 2.0731979364989908

Epoch: 6| Step: 5
Training loss: 1.6296769380569458
Validation loss: 2.1210164126529487

Epoch: 6| Step: 6
Training loss: 1.4288069009780884
Validation loss: 2.093423710074476

Epoch: 6| Step: 7
Training loss: 2.2215957641601562
Validation loss: 2.139226390469459

Epoch: 6| Step: 8
Training loss: 1.3978441953659058
Validation loss: 2.1095604050544

Epoch: 6| Step: 9
Training loss: 2.5790281295776367
Validation loss: 2.167825911634712

Epoch: 6| Step: 10
Training loss: 2.0621306896209717
Validation loss: 2.149444901815025

Epoch: 6| Step: 11
Training loss: 1.3286106586456299
Validation loss: 2.143620970428631

Epoch: 6| Step: 12
Training loss: 1.4674931764602661
Validation loss: 2.145218579999862

Epoch: 6| Step: 13
Training loss: 1.1546902656555176
Validation loss: 2.1081284720410585

Epoch: 430| Step: 0
Training loss: 1.0759978294372559
Validation loss: 2.1286977926890054

Epoch: 6| Step: 1
Training loss: 1.4857804775238037
Validation loss: 2.1283491221807336

Epoch: 6| Step: 2
Training loss: 2.5231070518493652
Validation loss: 2.1060617777609054

Epoch: 6| Step: 3
Training loss: 1.5580544471740723
Validation loss: 2.091309224405596

Epoch: 6| Step: 4
Training loss: 1.5148937702178955
Validation loss: 2.10940985269444

Epoch: 6| Step: 5
Training loss: 1.1796693801879883
Validation loss: 2.0848999331074376

Epoch: 6| Step: 6
Training loss: 1.4512279033660889
Validation loss: 2.1184122664954073

Epoch: 6| Step: 7
Training loss: 2.0710291862487793
Validation loss: 2.0826852078078897

Epoch: 6| Step: 8
Training loss: 1.771956205368042
Validation loss: 2.0967377231967066

Epoch: 6| Step: 9
Training loss: 1.760528802871704
Validation loss: 2.143126708205028

Epoch: 6| Step: 10
Training loss: 1.0842788219451904
Validation loss: 2.120323592616666

Epoch: 6| Step: 11
Training loss: 1.499239444732666
Validation loss: 2.1403317348931425

Epoch: 6| Step: 12
Training loss: 1.7889680862426758
Validation loss: 2.074700815703279

Epoch: 6| Step: 13
Training loss: 2.1751980781555176
Validation loss: 2.1030042838024836

Epoch: 431| Step: 0
Training loss: 1.3796463012695312
Validation loss: 2.078427812104584

Epoch: 6| Step: 1
Training loss: 0.9118692278862
Validation loss: 2.1023462895424134

Epoch: 6| Step: 2
Training loss: 1.8032199144363403
Validation loss: 2.067764828282018

Epoch: 6| Step: 3
Training loss: 3.0622270107269287
Validation loss: 2.079006976978753

Epoch: 6| Step: 4
Training loss: 1.8224701881408691
Validation loss: 2.087400036473428

Epoch: 6| Step: 5
Training loss: 1.3789139986038208
Validation loss: 2.121913279256513

Epoch: 6| Step: 6
Training loss: 1.9463131427764893
Validation loss: 2.152452631663251

Epoch: 6| Step: 7
Training loss: 1.7527309656143188
Validation loss: 2.138134305195142

Epoch: 6| Step: 8
Training loss: 1.8417786359786987
Validation loss: 2.091297185549172

Epoch: 6| Step: 9
Training loss: 1.3986728191375732
Validation loss: 2.1177340874107937

Epoch: 6| Step: 10
Training loss: 1.318528413772583
Validation loss: 2.0623277438584195

Epoch: 6| Step: 11
Training loss: 0.927985429763794
Validation loss: 2.0929807001544583

Epoch: 6| Step: 12
Training loss: 1.460404634475708
Validation loss: 2.1088890516629784

Epoch: 6| Step: 13
Training loss: 1.1263949871063232
Validation loss: 2.1001367312605663

Epoch: 432| Step: 0
Training loss: 1.400964617729187
Validation loss: 2.162906087854857

Epoch: 6| Step: 1
Training loss: 1.188666820526123
Validation loss: 2.14262068399819

Epoch: 6| Step: 2
Training loss: 1.6887816190719604
Validation loss: 2.173060817103232

Epoch: 6| Step: 3
Training loss: 1.3277316093444824
Validation loss: 2.1326696539437897

Epoch: 6| Step: 4
Training loss: 1.3867067098617554
Validation loss: 2.1261051239505893

Epoch: 6| Step: 5
Training loss: 1.5233430862426758
Validation loss: 2.1472430049732165

Epoch: 6| Step: 6
Training loss: 2.182168483734131
Validation loss: 2.1513893963188253

Epoch: 6| Step: 7
Training loss: 2.144925594329834
Validation loss: 2.1450391636099866

Epoch: 6| Step: 8
Training loss: 1.8614122867584229
Validation loss: 2.132357928060716

Epoch: 6| Step: 9
Training loss: 1.3263533115386963
Validation loss: 2.1412063362777873

Epoch: 6| Step: 10
Training loss: 1.4063124656677246
Validation loss: 2.1338540892447195

Epoch: 6| Step: 11
Training loss: 1.9093266725540161
Validation loss: 2.125350844475531

Epoch: 6| Step: 12
Training loss: 1.4685425758361816
Validation loss: 2.0774246274784045

Epoch: 6| Step: 13
Training loss: 1.608778953552246
Validation loss: 2.1148252512819026

Epoch: 433| Step: 0
Training loss: 2.418537139892578
Validation loss: 2.0758474347411946

Epoch: 6| Step: 1
Training loss: 1.3106399774551392
Validation loss: 2.0917688287714475

Epoch: 6| Step: 2
Training loss: 1.4637866020202637
Validation loss: 2.1522027343832035

Epoch: 6| Step: 3
Training loss: 1.664370059967041
Validation loss: 2.0559852277078936

Epoch: 6| Step: 4
Training loss: 1.3883558511734009
Validation loss: 2.111384686603341

Epoch: 6| Step: 5
Training loss: 1.2794979810714722
Validation loss: 2.1414229972388155

Epoch: 6| Step: 6
Training loss: 1.4060255289077759
Validation loss: 2.1125201845681794

Epoch: 6| Step: 7
Training loss: 1.3758243322372437
Validation loss: 2.106763785885226

Epoch: 6| Step: 8
Training loss: 2.0845320224761963
Validation loss: 2.092059807110858

Epoch: 6| Step: 9
Training loss: 1.350711703300476
Validation loss: 2.079255992366422

Epoch: 6| Step: 10
Training loss: 1.9249482154846191
Validation loss: 2.083382321942237

Epoch: 6| Step: 11
Training loss: 1.5962055921554565
Validation loss: 2.1327575406720563

Epoch: 6| Step: 12
Training loss: 1.649590253829956
Validation loss: 2.130079520645962

Epoch: 6| Step: 13
Training loss: 0.9008805751800537
Validation loss: 2.1483831649185507

Epoch: 434| Step: 0
Training loss: 2.205390214920044
Validation loss: 2.1333062289863505

Epoch: 6| Step: 1
Training loss: 1.1121515035629272
Validation loss: 2.1262641875974593

Epoch: 6| Step: 2
Training loss: 1.4026498794555664
Validation loss: 2.118605295817057

Epoch: 6| Step: 3
Training loss: 1.5752522945404053
Validation loss: 2.0813639548517044

Epoch: 6| Step: 4
Training loss: 1.2220895290374756
Validation loss: 2.1395415541946248

Epoch: 6| Step: 5
Training loss: 1.4605952501296997
Validation loss: 2.132798530722177

Epoch: 6| Step: 6
Training loss: 0.9287265539169312
Validation loss: 2.1571485470700007

Epoch: 6| Step: 7
Training loss: 2.8903374671936035
Validation loss: 2.105316133909328

Epoch: 6| Step: 8
Training loss: 1.3013582229614258
Validation loss: 2.136762325481702

Epoch: 6| Step: 9
Training loss: 1.0316333770751953
Validation loss: 2.1167288057265745

Epoch: 6| Step: 10
Training loss: 1.3887711763381958
Validation loss: 2.096598267555237

Epoch: 6| Step: 11
Training loss: 2.1867144107818604
Validation loss: 2.1155757134960544

Epoch: 6| Step: 12
Training loss: 1.6068271398544312
Validation loss: 2.1491708076128395

Epoch: 6| Step: 13
Training loss: 1.6498206853866577
Validation loss: 2.075778830435968

Epoch: 435| Step: 0
Training loss: 1.2886579036712646
Validation loss: 2.0936161805224676

Epoch: 6| Step: 1
Training loss: 1.2271018028259277
Validation loss: 2.1491245531266734

Epoch: 6| Step: 2
Training loss: 0.9623900055885315
Validation loss: 2.0834297236575874

Epoch: 6| Step: 3
Training loss: 1.5177041292190552
Validation loss: 2.108336235887261

Epoch: 6| Step: 4
Training loss: 2.0455379486083984
Validation loss: 2.0891201611488097

Epoch: 6| Step: 5
Training loss: 1.7260487079620361
Validation loss: 2.1226486031727125

Epoch: 6| Step: 6
Training loss: 1.6742477416992188
Validation loss: 2.08769331952577

Epoch: 6| Step: 7
Training loss: 1.4768621921539307
Validation loss: 2.0909649031136626

Epoch: 6| Step: 8
Training loss: 2.1204137802124023
Validation loss: 2.1020111089111655

Epoch: 6| Step: 9
Training loss: 1.2507355213165283
Validation loss: 2.0692484763360794

Epoch: 6| Step: 10
Training loss: 1.8140630722045898
Validation loss: 2.100851878043144

Epoch: 6| Step: 11
Training loss: 1.2014119625091553
Validation loss: 2.1307145536586805

Epoch: 6| Step: 12
Training loss: 1.7678717374801636
Validation loss: 2.0915198146655993

Epoch: 6| Step: 13
Training loss: 2.203380584716797
Validation loss: 2.1233300188536286

Epoch: 436| Step: 0
Training loss: 1.161723017692566
Validation loss: 2.091399595301638

Epoch: 6| Step: 1
Training loss: 1.5461245775222778
Validation loss: 2.0720003599761636

Epoch: 6| Step: 2
Training loss: 1.5695592164993286
Validation loss: 2.096306029186454

Epoch: 6| Step: 3
Training loss: 2.6050362586975098
Validation loss: 2.094146574697187

Epoch: 6| Step: 4
Training loss: 2.330423355102539
Validation loss: 2.097699680636006

Epoch: 6| Step: 5
Training loss: 1.3945941925048828
Validation loss: 2.0882262875956874

Epoch: 6| Step: 6
Training loss: 1.2996188402175903
Validation loss: 2.125232877269868

Epoch: 6| Step: 7
Training loss: 2.136901378631592
Validation loss: 2.1291624628087527

Epoch: 6| Step: 8
Training loss: 1.505050539970398
Validation loss: 2.1668404584289878

Epoch: 6| Step: 9
Training loss: 1.5282578468322754
Validation loss: 2.1214298727691814

Epoch: 6| Step: 10
Training loss: 0.5750057697296143
Validation loss: 2.1179114285335747

Epoch: 6| Step: 11
Training loss: 1.3849414587020874
Validation loss: 2.106619643908675

Epoch: 6| Step: 12
Training loss: 1.067373275756836
Validation loss: 2.120740698229882

Epoch: 6| Step: 13
Training loss: 2.319125175476074
Validation loss: 2.095404730048231

Epoch: 437| Step: 0
Training loss: 1.499720573425293
Validation loss: 2.13677139436045

Epoch: 6| Step: 1
Training loss: 1.9402506351470947
Validation loss: 2.128465606320289

Epoch: 6| Step: 2
Training loss: 2.012612819671631
Validation loss: 2.1283313305147233

Epoch: 6| Step: 3
Training loss: 1.1731377840042114
Validation loss: 2.1211736573967883

Epoch: 6| Step: 4
Training loss: 1.0474610328674316
Validation loss: 2.14113687956205

Epoch: 6| Step: 5
Training loss: 1.5736185312271118
Validation loss: 2.1404944376278947

Epoch: 6| Step: 6
Training loss: 0.8804835081100464
Validation loss: 2.1043028088026148

Epoch: 6| Step: 7
Training loss: 1.0084278583526611
Validation loss: 2.1272229815042145

Epoch: 6| Step: 8
Training loss: 2.1787776947021484
Validation loss: 2.171760364245343

Epoch: 6| Step: 9
Training loss: 2.0368294715881348
Validation loss: 2.157038998860185

Epoch: 6| Step: 10
Training loss: 1.5108044147491455
Validation loss: 2.1378384713203675

Epoch: 6| Step: 11
Training loss: 1.7750742435455322
Validation loss: 2.1785662943317043

Epoch: 6| Step: 12
Training loss: 1.6707439422607422
Validation loss: 2.113523752458634

Epoch: 6| Step: 13
Training loss: 2.2656595706939697
Validation loss: 2.090313442291752

Epoch: 438| Step: 0
Training loss: 1.777637004852295
Validation loss: 2.112285844741329

Epoch: 6| Step: 1
Training loss: 1.9150196313858032
Validation loss: 2.0893513617977018

Epoch: 6| Step: 2
Training loss: 2.0931568145751953
Validation loss: 2.1365823002271753

Epoch: 6| Step: 3
Training loss: 1.7695856094360352
Validation loss: 2.0700242134832565

Epoch: 6| Step: 4
Training loss: 1.5793862342834473
Validation loss: 2.096124028646818

Epoch: 6| Step: 5
Training loss: 1.4888391494750977
Validation loss: 2.1171911557515464

Epoch: 6| Step: 6
Training loss: 1.1258450746536255
Validation loss: 2.1031624412023895

Epoch: 6| Step: 7
Training loss: 2.2657737731933594
Validation loss: 2.093399945125785

Epoch: 6| Step: 8
Training loss: 1.5790977478027344
Validation loss: 2.0558941184833484

Epoch: 6| Step: 9
Training loss: 1.4291958808898926
Validation loss: 2.1201960066313386

Epoch: 6| Step: 10
Training loss: 1.1662932634353638
Validation loss: 2.1515146224729476

Epoch: 6| Step: 11
Training loss: 1.0038114786148071
Validation loss: 2.120236542917067

Epoch: 6| Step: 12
Training loss: 1.3308814764022827
Validation loss: 2.0978466913264286

Epoch: 6| Step: 13
Training loss: 1.6315200328826904
Validation loss: 2.1107714394087433

Epoch: 439| Step: 0
Training loss: 1.487293004989624
Validation loss: 2.058338325510743

Epoch: 6| Step: 1
Training loss: 2.0366454124450684
Validation loss: 2.077665436652399

Epoch: 6| Step: 2
Training loss: 1.743809461593628
Validation loss: 2.092372079049387

Epoch: 6| Step: 3
Training loss: 1.4148743152618408
Validation loss: 2.103142588369308

Epoch: 6| Step: 4
Training loss: 1.2182767391204834
Validation loss: 2.1248279207496235

Epoch: 6| Step: 5
Training loss: 1.8401037454605103
Validation loss: 2.145235853810464

Epoch: 6| Step: 6
Training loss: 1.4027025699615479
Validation loss: 2.1272898207428637

Epoch: 6| Step: 7
Training loss: 1.575467586517334
Validation loss: 2.1456511533388527

Epoch: 6| Step: 8
Training loss: 1.5023603439331055
Validation loss: 2.0949318139783797

Epoch: 6| Step: 9
Training loss: 1.05299973487854
Validation loss: 2.0773071037825717

Epoch: 6| Step: 10
Training loss: 1.5532362461090088
Validation loss: 2.088830687666452

Epoch: 6| Step: 11
Training loss: 1.5263805389404297
Validation loss: 2.084051186038602

Epoch: 6| Step: 12
Training loss: 1.965205430984497
Validation loss: 2.119958882690758

Epoch: 6| Step: 13
Training loss: 1.5547771453857422
Validation loss: 2.0836121189978813

Epoch: 440| Step: 0
Training loss: 2.3089427947998047
Validation loss: 2.065912705595775

Epoch: 6| Step: 1
Training loss: 1.016991376876831
Validation loss: 2.1148749500192623

Epoch: 6| Step: 2
Training loss: 1.3085938692092896
Validation loss: 2.097137822899767

Epoch: 6| Step: 3
Training loss: 1.399749994277954
Validation loss: 2.0962491958372054

Epoch: 6| Step: 4
Training loss: 1.372135877609253
Validation loss: 2.126696328963003

Epoch: 6| Step: 5
Training loss: 1.4144712686538696
Validation loss: 2.1014506175953853

Epoch: 6| Step: 6
Training loss: 1.6836544275283813
Validation loss: 2.1523771132192304

Epoch: 6| Step: 7
Training loss: 1.9646941423416138
Validation loss: 2.0808242726069626

Epoch: 6| Step: 8
Training loss: 1.7056446075439453
Validation loss: 2.115183607224495

Epoch: 6| Step: 9
Training loss: 1.8779733180999756
Validation loss: 2.0854130560351956

Epoch: 6| Step: 10
Training loss: 1.750625729560852
Validation loss: 2.101513695973222

Epoch: 6| Step: 11
Training loss: 1.6743688583374023
Validation loss: 2.06684733334408

Epoch: 6| Step: 12
Training loss: 1.0745468139648438
Validation loss: 2.111249631451022

Epoch: 6| Step: 13
Training loss: 1.5139803886413574
Validation loss: 2.0986246831955446

Epoch: 441| Step: 0
Training loss: 1.7001723051071167
Validation loss: 2.111019101194156

Epoch: 6| Step: 1
Training loss: 1.434403896331787
Validation loss: 2.1372685329888457

Epoch: 6| Step: 2
Training loss: 1.6732850074768066
Validation loss: 2.0907859443336405

Epoch: 6| Step: 3
Training loss: 1.7569833993911743
Validation loss: 2.123279410023843

Epoch: 6| Step: 4
Training loss: 1.441216230392456
Validation loss: 2.1177434049626833

Epoch: 6| Step: 5
Training loss: 2.3843703269958496
Validation loss: 2.1136945242522867

Epoch: 6| Step: 6
Training loss: 1.322235345840454
Validation loss: 2.1152040702040478

Epoch: 6| Step: 7
Training loss: 1.0279532670974731
Validation loss: 2.112081627691946

Epoch: 6| Step: 8
Training loss: 1.6380975246429443
Validation loss: 2.1286507075832737

Epoch: 6| Step: 9
Training loss: 1.8123042583465576
Validation loss: 2.125816256769242

Epoch: 6| Step: 10
Training loss: 1.1098806858062744
Validation loss: 2.149822283816594

Epoch: 6| Step: 11
Training loss: 1.7330710887908936
Validation loss: 2.1353424800339567

Epoch: 6| Step: 12
Training loss: 1.6903388500213623
Validation loss: 2.0724406652553107

Epoch: 6| Step: 13
Training loss: 1.192908763885498
Validation loss: 2.1470451380616877

Epoch: 442| Step: 0
Training loss: 1.8267152309417725
Validation loss: 2.1137434974793465

Epoch: 6| Step: 1
Training loss: 1.4621084928512573
Validation loss: 2.1338203517339562

Epoch: 6| Step: 2
Training loss: 1.7138935327529907
Validation loss: 2.1088035081022527

Epoch: 6| Step: 3
Training loss: 1.5475735664367676
Validation loss: 2.099157210319273

Epoch: 6| Step: 4
Training loss: 1.6831361055374146
Validation loss: 2.1219044398236018

Epoch: 6| Step: 5
Training loss: 1.5898022651672363
Validation loss: 2.1095113728636052

Epoch: 6| Step: 6
Training loss: 1.9103634357452393
Validation loss: 2.141552891782535

Epoch: 6| Step: 7
Training loss: 1.341436505317688
Validation loss: 2.108672018974058

Epoch: 6| Step: 8
Training loss: 1.287682294845581
Validation loss: 2.1315365696466095

Epoch: 6| Step: 9
Training loss: 1.2954797744750977
Validation loss: 2.134020105484993

Epoch: 6| Step: 10
Training loss: 1.5116075277328491
Validation loss: 2.11383250195493

Epoch: 6| Step: 11
Training loss: 1.6564629077911377
Validation loss: 2.103925330664522

Epoch: 6| Step: 12
Training loss: 1.9814282655715942
Validation loss: 2.0518842256197365

Epoch: 6| Step: 13
Training loss: 1.6449103355407715
Validation loss: 2.099654350229489

Epoch: 443| Step: 0
Training loss: 1.2804571390151978
Validation loss: 2.1050850909243346

Epoch: 6| Step: 1
Training loss: 1.0285745859146118
Validation loss: 2.0820082310707337

Epoch: 6| Step: 2
Training loss: 2.044342041015625
Validation loss: 2.1196401503778275

Epoch: 6| Step: 3
Training loss: 0.9087479114532471
Validation loss: 2.1270361946475123

Epoch: 6| Step: 4
Training loss: 1.5833820104599
Validation loss: 2.113142572423463

Epoch: 6| Step: 5
Training loss: 1.6510860919952393
Validation loss: 2.0887203703644457

Epoch: 6| Step: 6
Training loss: 1.9977155923843384
Validation loss: 2.1109188577180267

Epoch: 6| Step: 7
Training loss: 1.3027244806289673
Validation loss: 2.151276896076818

Epoch: 6| Step: 8
Training loss: 1.7398297786712646
Validation loss: 2.1222749833137757

Epoch: 6| Step: 9
Training loss: 1.6561788320541382
Validation loss: 2.125420944665068

Epoch: 6| Step: 10
Training loss: 1.4830784797668457
Validation loss: 2.132435293607814

Epoch: 6| Step: 11
Training loss: 2.2433319091796875
Validation loss: 2.1105998036681966

Epoch: 6| Step: 12
Training loss: 1.7858622074127197
Validation loss: 2.121456092403781

Epoch: 6| Step: 13
Training loss: 0.9672114849090576
Validation loss: 2.1272612489679807

Epoch: 444| Step: 0
Training loss: 1.4064836502075195
Validation loss: 2.124197962463543

Epoch: 6| Step: 1
Training loss: 1.2714662551879883
Validation loss: 2.142930071841004

Epoch: 6| Step: 2
Training loss: 1.8787572383880615
Validation loss: 2.1645316949454685

Epoch: 6| Step: 3
Training loss: 1.4165880680084229
Validation loss: 2.1124424293477047

Epoch: 6| Step: 4
Training loss: 2.1752684116363525
Validation loss: 2.140617339841781

Epoch: 6| Step: 5
Training loss: 1.2004255056381226
Validation loss: 2.088266308589648

Epoch: 6| Step: 6
Training loss: 1.814296007156372
Validation loss: 2.140571414783437

Epoch: 6| Step: 7
Training loss: 1.3068326711654663
Validation loss: 2.1271914730789843

Epoch: 6| Step: 8
Training loss: 1.1820281744003296
Validation loss: 2.104280574347383

Epoch: 6| Step: 9
Training loss: 1.2171335220336914
Validation loss: 2.109305388184004

Epoch: 6| Step: 10
Training loss: 2.2283730506896973
Validation loss: 2.0860480544387654

Epoch: 6| Step: 11
Training loss: 1.6650002002716064
Validation loss: 2.090323632763278

Epoch: 6| Step: 12
Training loss: 1.589712142944336
Validation loss: 2.0415809333965345

Epoch: 6| Step: 13
Training loss: 1.3502897024154663
Validation loss: 2.121337575297202

Epoch: 445| Step: 0
Training loss: 1.4783498048782349
Validation loss: 2.134248072101224

Epoch: 6| Step: 1
Training loss: 1.350682020187378
Validation loss: 2.0936719140698834

Epoch: 6| Step: 2
Training loss: 2.313506841659546
Validation loss: 2.1540186084726805

Epoch: 6| Step: 3
Training loss: 1.7945976257324219
Validation loss: 2.113716143433766

Epoch: 6| Step: 4
Training loss: 1.897459626197815
Validation loss: 2.1112216441862044

Epoch: 6| Step: 5
Training loss: 1.545363187789917
Validation loss: 2.1373174382794287

Epoch: 6| Step: 6
Training loss: 1.2040565013885498
Validation loss: 2.088652741524481

Epoch: 6| Step: 7
Training loss: 0.8160265684127808
Validation loss: 2.1564609824970202

Epoch: 6| Step: 8
Training loss: 1.842801570892334
Validation loss: 2.098556403190859

Epoch: 6| Step: 9
Training loss: 1.2251577377319336
Validation loss: 2.151627581606629

Epoch: 6| Step: 10
Training loss: 1.502634048461914
Validation loss: 2.120922009150187

Epoch: 6| Step: 11
Training loss: 1.5673327445983887
Validation loss: 2.1413055978795534

Epoch: 6| Step: 12
Training loss: 1.128814697265625
Validation loss: 2.122109358028699

Epoch: 6| Step: 13
Training loss: 2.1751606464385986
Validation loss: 2.108359557326122

Epoch: 446| Step: 0
Training loss: 1.216238021850586
Validation loss: 2.117802054651322

Epoch: 6| Step: 1
Training loss: 1.8495723009109497
Validation loss: 2.0891501288260184

Epoch: 6| Step: 2
Training loss: 1.674041748046875
Validation loss: 2.1064696632405764

Epoch: 6| Step: 3
Training loss: 1.785626769065857
Validation loss: 2.115354276472522

Epoch: 6| Step: 4
Training loss: 1.6486737728118896
Validation loss: 2.111170873847059

Epoch: 6| Step: 5
Training loss: 1.0496219396591187
Validation loss: 2.0650880311125066

Epoch: 6| Step: 6
Training loss: 1.7974070310592651
Validation loss: 2.094502008089455

Epoch: 6| Step: 7
Training loss: 1.49021315574646
Validation loss: 2.071465448666644

Epoch: 6| Step: 8
Training loss: 1.7306427955627441
Validation loss: 2.122797526339049

Epoch: 6| Step: 9
Training loss: 1.492538571357727
Validation loss: 2.1019035488046627

Epoch: 6| Step: 10
Training loss: 1.3546130657196045
Validation loss: 2.1308750465352047

Epoch: 6| Step: 11
Training loss: 1.844707727432251
Validation loss: 2.1187241103059504

Epoch: 6| Step: 12
Training loss: 1.5298798084259033
Validation loss: 2.0952546211981002

Epoch: 6| Step: 13
Training loss: 1.347665786743164
Validation loss: 2.135914450050682

Epoch: 447| Step: 0
Training loss: 1.6881355047225952
Validation loss: 2.1072299121528544

Epoch: 6| Step: 1
Training loss: 1.9456324577331543
Validation loss: 2.1196148536538564

Epoch: 6| Step: 2
Training loss: 1.9290788173675537
Validation loss: 2.17970533012062

Epoch: 6| Step: 3
Training loss: 1.6906554698944092
Validation loss: 2.1659255091862013

Epoch: 6| Step: 4
Training loss: 1.4510928392410278
Validation loss: 2.1265657858182023

Epoch: 6| Step: 5
Training loss: 1.5182645320892334
Validation loss: 2.1267292050905127

Epoch: 6| Step: 6
Training loss: 2.4258084297180176
Validation loss: 2.1891500988314228

Epoch: 6| Step: 7
Training loss: 1.0583837032318115
Validation loss: 2.156018139213644

Epoch: 6| Step: 8
Training loss: 1.7349812984466553
Validation loss: 2.1422660632800032

Epoch: 6| Step: 9
Training loss: 1.5378679037094116
Validation loss: 2.131962796693207

Epoch: 6| Step: 10
Training loss: 1.6498048305511475
Validation loss: 2.1275606052849882

Epoch: 6| Step: 11
Training loss: 1.1311144828796387
Validation loss: 2.1451421681270806

Epoch: 6| Step: 12
Training loss: 1.1261473894119263
Validation loss: 2.114062052901073

Epoch: 6| Step: 13
Training loss: 0.8962118625640869
Validation loss: 2.09701136747996

Epoch: 448| Step: 0
Training loss: 1.8621426820755005
Validation loss: 2.1018831499161257

Epoch: 6| Step: 1
Training loss: 1.8756194114685059
Validation loss: 2.110611746388097

Epoch: 6| Step: 2
Training loss: 1.1959693431854248
Validation loss: 2.0970616084273144

Epoch: 6| Step: 3
Training loss: 1.471614122390747
Validation loss: 2.0827702168495423

Epoch: 6| Step: 4
Training loss: 0.8540016412734985
Validation loss: 2.1195450700739378

Epoch: 6| Step: 5
Training loss: 1.9413610696792603
Validation loss: 2.0656569388604935

Epoch: 6| Step: 6
Training loss: 1.7483851909637451
Validation loss: 2.0907783149391093

Epoch: 6| Step: 7
Training loss: 1.5195037126541138
Validation loss: 2.0759304595249954

Epoch: 6| Step: 8
Training loss: 1.6309726238250732
Validation loss: 2.126554955718338

Epoch: 6| Step: 9
Training loss: 1.9628275632858276
Validation loss: 2.1087162853569112

Epoch: 6| Step: 10
Training loss: 1.3037574291229248
Validation loss: 2.084435828270451

Epoch: 6| Step: 11
Training loss: 1.587913990020752
Validation loss: 2.1003742089835544

Epoch: 6| Step: 12
Training loss: 1.0661271810531616
Validation loss: 2.133446378092612

Epoch: 6| Step: 13
Training loss: 1.682478427886963
Validation loss: 2.111494151494836

Epoch: 449| Step: 0
Training loss: 1.7394673824310303
Validation loss: 2.108243788442304

Epoch: 6| Step: 1
Training loss: 1.4527888298034668
Validation loss: 2.1243231655448995

Epoch: 6| Step: 2
Training loss: 1.4230666160583496
Validation loss: 2.1258836689815728

Epoch: 6| Step: 3
Training loss: 1.6950058937072754
Validation loss: 2.1112931107962005

Epoch: 6| Step: 4
Training loss: 1.417639970779419
Validation loss: 2.097989184882051

Epoch: 6| Step: 5
Training loss: 1.7324802875518799
Validation loss: 2.0925681629488544

Epoch: 6| Step: 6
Training loss: 1.948328971862793
Validation loss: 2.086785961222905

Epoch: 6| Step: 7
Training loss: 1.1905215978622437
Validation loss: 2.103063557737617

Epoch: 6| Step: 8
Training loss: 1.8231828212738037
Validation loss: 2.119675149199783

Epoch: 6| Step: 9
Training loss: 1.4773650169372559
Validation loss: 2.078479725827453

Epoch: 6| Step: 10
Training loss: 1.3125613927841187
Validation loss: 2.099567505621141

Epoch: 6| Step: 11
Training loss: 1.8083808422088623
Validation loss: 2.1378069975042857

Epoch: 6| Step: 12
Training loss: 1.458184003829956
Validation loss: 2.1151081977352018

Epoch: 6| Step: 13
Training loss: 1.6229207515716553
Validation loss: 2.100872849905363

Epoch: 450| Step: 0
Training loss: 1.3922719955444336
Validation loss: 2.0876308692398893

Epoch: 6| Step: 1
Training loss: 1.3121144771575928
Validation loss: 2.1229355373690204

Epoch: 6| Step: 2
Training loss: 1.050185203552246
Validation loss: 2.0964624471561883

Epoch: 6| Step: 3
Training loss: 1.2330418825149536
Validation loss: 2.096357249444531

Epoch: 6| Step: 4
Training loss: 1.572037935256958
Validation loss: 2.0890876221400436

Epoch: 6| Step: 5
Training loss: 1.6872174739837646
Validation loss: 2.0911040331727717

Epoch: 6| Step: 6
Training loss: 1.175072193145752
Validation loss: 2.12419524756811

Epoch: 6| Step: 7
Training loss: 1.7914565801620483
Validation loss: 2.097496771043347

Epoch: 6| Step: 8
Training loss: 1.9262053966522217
Validation loss: 2.133101023653502

Epoch: 6| Step: 9
Training loss: 1.5627503395080566
Validation loss: 2.1580857974226757

Epoch: 6| Step: 10
Training loss: 1.3899060487747192
Validation loss: 2.1348219379301994

Epoch: 6| Step: 11
Training loss: 1.9185725450515747
Validation loss: 2.092917711504044

Epoch: 6| Step: 12
Training loss: 1.8345059156417847
Validation loss: 2.098801984581896

Epoch: 6| Step: 13
Training loss: 2.2129781246185303
Validation loss: 2.106384902872065

Epoch: 451| Step: 0
Training loss: 1.1177295446395874
Validation loss: 2.1032023404234197

Epoch: 6| Step: 1
Training loss: 1.4161773920059204
Validation loss: 2.127564755819177

Epoch: 6| Step: 2
Training loss: 1.2829601764678955
Validation loss: 2.097992968815629

Epoch: 6| Step: 3
Training loss: 1.3052468299865723
Validation loss: 2.0922102530797324

Epoch: 6| Step: 4
Training loss: 1.2115144729614258
Validation loss: 2.076203150133933

Epoch: 6| Step: 5
Training loss: 1.190751314163208
Validation loss: 2.096545321967012

Epoch: 6| Step: 6
Training loss: 1.6211278438568115
Validation loss: 2.1274114347273305

Epoch: 6| Step: 7
Training loss: 2.4637198448181152
Validation loss: 2.1097022564180437

Epoch: 6| Step: 8
Training loss: 1.7555814981460571
Validation loss: 2.0642388943702943

Epoch: 6| Step: 9
Training loss: 1.6695746183395386
Validation loss: 2.056073634855209

Epoch: 6| Step: 10
Training loss: 1.4420825242996216
Validation loss: 2.0871040603165985

Epoch: 6| Step: 11
Training loss: 1.1004232168197632
Validation loss: 2.0971560298755603

Epoch: 6| Step: 12
Training loss: 3.0827417373657227
Validation loss: 2.070379969894245

Epoch: 6| Step: 13
Training loss: 1.2217501401901245
Validation loss: 2.116207088193586

Epoch: 452| Step: 0
Training loss: 0.9161290526390076
Validation loss: 2.1184316386458693

Epoch: 6| Step: 1
Training loss: 1.3026217222213745
Validation loss: 2.1141804930984334

Epoch: 6| Step: 2
Training loss: 1.1980477571487427
Validation loss: 2.105622127491941

Epoch: 6| Step: 3
Training loss: 1.9995546340942383
Validation loss: 2.057239524779781

Epoch: 6| Step: 4
Training loss: 2.030759334564209
Validation loss: 2.124684049237159

Epoch: 6| Step: 5
Training loss: 1.4070093631744385
Validation loss: 2.113536660389234

Epoch: 6| Step: 6
Training loss: 1.5086426734924316
Validation loss: 2.1157353334529425

Epoch: 6| Step: 7
Training loss: 1.9745285511016846
Validation loss: 2.0759191359243085

Epoch: 6| Step: 8
Training loss: 1.8377609252929688
Validation loss: 2.099917427186043

Epoch: 6| Step: 9
Training loss: 1.4242618083953857
Validation loss: 2.112843495543285

Epoch: 6| Step: 10
Training loss: 1.4890739917755127
Validation loss: 2.106590791415143

Epoch: 6| Step: 11
Training loss: 1.2018362283706665
Validation loss: 2.0963779136698735

Epoch: 6| Step: 12
Training loss: 1.5094232559204102
Validation loss: 2.153378294360253

Epoch: 6| Step: 13
Training loss: 1.8181207180023193
Validation loss: 2.0814402757152433

Epoch: 453| Step: 0
Training loss: 1.6183726787567139
Validation loss: 2.0910077633396273

Epoch: 6| Step: 1
Training loss: 1.4437932968139648
Validation loss: 2.109111926888907

Epoch: 6| Step: 2
Training loss: 1.9157190322875977
Validation loss: 2.113976420894746

Epoch: 6| Step: 3
Training loss: 2.40506911277771
Validation loss: 2.1535412432045065

Epoch: 6| Step: 4
Training loss: 1.1249175071716309
Validation loss: 2.150616699649442

Epoch: 6| Step: 5
Training loss: 1.3805983066558838
Validation loss: 2.167023884352817

Epoch: 6| Step: 6
Training loss: 1.4182974100112915
Validation loss: 2.1303023420354372

Epoch: 6| Step: 7
Training loss: 1.869971513748169
Validation loss: 2.1397350731716362

Epoch: 6| Step: 8
Training loss: 1.1304993629455566
Validation loss: 2.1255313581035984

Epoch: 6| Step: 9
Training loss: 1.5022953748703003
Validation loss: 2.1363548130117436

Epoch: 6| Step: 10
Training loss: 1.453984022140503
Validation loss: 2.0918340836801836

Epoch: 6| Step: 11
Training loss: 1.8377710580825806
Validation loss: 2.1111690998077393

Epoch: 6| Step: 12
Training loss: 1.712830662727356
Validation loss: 2.1230091510280484

Epoch: 6| Step: 13
Training loss: 1.0376173257827759
Validation loss: 2.0402495732871433

Epoch: 454| Step: 0
Training loss: 1.5289242267608643
Validation loss: 2.0892045882440384

Epoch: 6| Step: 1
Training loss: 2.4332432746887207
Validation loss: 2.082539940393099

Epoch: 6| Step: 2
Training loss: 1.2531567811965942
Validation loss: 2.0820503132317656

Epoch: 6| Step: 3
Training loss: 1.8226149082183838
Validation loss: 2.1012842219362975

Epoch: 6| Step: 4
Training loss: 1.1487447023391724
Validation loss: 2.10307538893915

Epoch: 6| Step: 5
Training loss: 1.5989620685577393
Validation loss: 2.1044037598435597

Epoch: 6| Step: 6
Training loss: 1.5611302852630615
Validation loss: 2.147453245296273

Epoch: 6| Step: 7
Training loss: 0.9066884517669678
Validation loss: 2.0877708350458453

Epoch: 6| Step: 8
Training loss: 1.3096685409545898
Validation loss: 2.0965458193132953

Epoch: 6| Step: 9
Training loss: 1.704511284828186
Validation loss: 2.0702028274536133

Epoch: 6| Step: 10
Training loss: 1.6191236972808838
Validation loss: 2.085651510505266

Epoch: 6| Step: 11
Training loss: 2.0555646419525146
Validation loss: 2.1233503305783836

Epoch: 6| Step: 12
Training loss: 1.1627399921417236
Validation loss: 2.0772781192615466

Epoch: 6| Step: 13
Training loss: 1.3855156898498535
Validation loss: 2.0933389176604567

Epoch: 455| Step: 0
Training loss: 1.6855392456054688
Validation loss: 2.0792482514535227

Epoch: 6| Step: 1
Training loss: 0.8045835494995117
Validation loss: 2.1146171400623937

Epoch: 6| Step: 2
Training loss: 1.0690990686416626
Validation loss: 2.090015886932291

Epoch: 6| Step: 3
Training loss: 1.2037041187286377
Validation loss: 2.139722640796374

Epoch: 6| Step: 4
Training loss: 1.7573325634002686
Validation loss: 2.1199023672329482

Epoch: 6| Step: 5
Training loss: 1.5450472831726074
Validation loss: 2.1434547503789267

Epoch: 6| Step: 6
Training loss: 1.362538456916809
Validation loss: 2.1096281659218574

Epoch: 6| Step: 7
Training loss: 2.048624038696289
Validation loss: 2.0682019725922616

Epoch: 6| Step: 8
Training loss: 1.6292377710342407
Validation loss: 2.106822895747359

Epoch: 6| Step: 9
Training loss: 1.9753609895706177
Validation loss: 2.099767665709219

Epoch: 6| Step: 10
Training loss: 1.38983952999115
Validation loss: 2.0947671141675723

Epoch: 6| Step: 11
Training loss: 2.0791664123535156
Validation loss: 2.079788297735235

Epoch: 6| Step: 12
Training loss: 1.115233063697815
Validation loss: 2.1023472944895425

Epoch: 6| Step: 13
Training loss: 1.529934287071228
Validation loss: 2.0855298939571587

Epoch: 456| Step: 0
Training loss: 1.0104970932006836
Validation loss: 2.0603876959893013

Epoch: 6| Step: 1
Training loss: 1.8216800689697266
Validation loss: 2.066756397165278

Epoch: 6| Step: 2
Training loss: 1.3483567237854004
Validation loss: 2.060648698960581

Epoch: 6| Step: 3
Training loss: 1.2870519161224365
Validation loss: 2.083999567134406

Epoch: 6| Step: 4
Training loss: 1.7286452054977417
Validation loss: 2.0772549247228973

Epoch: 6| Step: 5
Training loss: 1.8556690216064453
Validation loss: 2.1116426247422413

Epoch: 6| Step: 6
Training loss: 1.8348803520202637
Validation loss: 2.074763972272155

Epoch: 6| Step: 7
Training loss: 1.3712676763534546
Validation loss: 2.0995941982474378

Epoch: 6| Step: 8
Training loss: 1.3500720262527466
Validation loss: 2.0912150003576793

Epoch: 6| Step: 9
Training loss: 2.3298892974853516
Validation loss: 2.070548898430281

Epoch: 6| Step: 10
Training loss: 1.428077220916748
Validation loss: 2.059182874618038

Epoch: 6| Step: 11
Training loss: 1.5984277725219727
Validation loss: 2.0691643479049846

Epoch: 6| Step: 12
Training loss: 1.340131163597107
Validation loss: 2.055977741877238

Epoch: 6| Step: 13
Training loss: 1.7192119359970093
Validation loss: 2.126299532510901

Epoch: 457| Step: 0
Training loss: 1.8250784873962402
Validation loss: 2.078664046461864

Epoch: 6| Step: 1
Training loss: 1.2518904209136963
Validation loss: 2.112684517778376

Epoch: 6| Step: 2
Training loss: 0.9442234039306641
Validation loss: 2.1371056572083504

Epoch: 6| Step: 3
Training loss: 1.7741122245788574
Validation loss: 2.1279930606965096

Epoch: 6| Step: 4
Training loss: 1.8995013236999512
Validation loss: 2.144072858236169

Epoch: 6| Step: 5
Training loss: 1.3647336959838867
Validation loss: 2.1264847940014255

Epoch: 6| Step: 6
Training loss: 1.563720941543579
Validation loss: 2.188114960988363

Epoch: 6| Step: 7
Training loss: 1.6456859111785889
Validation loss: 2.1630212542831257

Epoch: 6| Step: 8
Training loss: 1.3149114847183228
Validation loss: 2.1792797657751266

Epoch: 6| Step: 9
Training loss: 1.3351930379867554
Validation loss: 2.152948974281229

Epoch: 6| Step: 10
Training loss: 1.2842872142791748
Validation loss: 2.1701712813428653

Epoch: 6| Step: 11
Training loss: 2.024576425552368
Validation loss: 2.143359450883763

Epoch: 6| Step: 12
Training loss: 1.9879546165466309
Validation loss: 2.1241181242850518

Epoch: 6| Step: 13
Training loss: 1.7994670867919922
Validation loss: 2.1444089284507175

Epoch: 458| Step: 0
Training loss: 2.157956123352051
Validation loss: 2.140624769272343

Epoch: 6| Step: 1
Training loss: 1.6961922645568848
Validation loss: 2.093775100605462

Epoch: 6| Step: 2
Training loss: 1.1786465644836426
Validation loss: 2.0873806912411927

Epoch: 6| Step: 3
Training loss: 1.904462218284607
Validation loss: 2.0710276890826482

Epoch: 6| Step: 4
Training loss: 1.0555434226989746
Validation loss: 2.074531380848218

Epoch: 6| Step: 5
Training loss: 1.0779118537902832
Validation loss: 2.1005396894229356

Epoch: 6| Step: 6
Training loss: 0.9597302079200745
Validation loss: 2.0907001854271017

Epoch: 6| Step: 7
Training loss: 2.8398942947387695
Validation loss: 2.0571003831842893

Epoch: 6| Step: 8
Training loss: 1.2454432249069214
Validation loss: 2.0672564916713263

Epoch: 6| Step: 9
Training loss: 1.1976590156555176
Validation loss: 2.1186317038792435

Epoch: 6| Step: 10
Training loss: 2.1914587020874023
Validation loss: 2.068247666922949

Epoch: 6| Step: 11
Training loss: 1.4390738010406494
Validation loss: 2.1159449136385353

Epoch: 6| Step: 12
Training loss: 1.2484629154205322
Validation loss: 2.0921190772005307

Epoch: 6| Step: 13
Training loss: 1.8471159934997559
Validation loss: 2.0418282298631567

Epoch: 459| Step: 0
Training loss: 2.067099094390869
Validation loss: 2.0865485642545964

Epoch: 6| Step: 1
Training loss: 1.4865925312042236
Validation loss: 2.0940127270196074

Epoch: 6| Step: 2
Training loss: 1.8237853050231934
Validation loss: 2.1047287987124537

Epoch: 6| Step: 3
Training loss: 1.3812928199768066
Validation loss: 2.1125829065999677

Epoch: 6| Step: 4
Training loss: 1.2569074630737305
Validation loss: 2.084666503373013

Epoch: 6| Step: 5
Training loss: 1.667740821838379
Validation loss: 2.1349937326164654

Epoch: 6| Step: 6
Training loss: 2.2026708126068115
Validation loss: 2.0846191670304988

Epoch: 6| Step: 7
Training loss: 1.268315315246582
Validation loss: 2.128379237267279

Epoch: 6| Step: 8
Training loss: 1.114831805229187
Validation loss: 2.1217485589365803

Epoch: 6| Step: 9
Training loss: 1.7114276885986328
Validation loss: 2.0907459630761096

Epoch: 6| Step: 10
Training loss: 1.6439149379730225
Validation loss: 2.112867142564507

Epoch: 6| Step: 11
Training loss: 1.4212486743927002
Validation loss: 2.1295274508896695

Epoch: 6| Step: 12
Training loss: 1.4648447036743164
Validation loss: 2.0984438439851165

Epoch: 6| Step: 13
Training loss: 1.5266262292861938
Validation loss: 2.132756954880171

Epoch: 460| Step: 0
Training loss: 1.9944831132888794
Validation loss: 2.1305521611244447

Epoch: 6| Step: 1
Training loss: 2.043504476547241
Validation loss: 2.1199635972258863

Epoch: 6| Step: 2
Training loss: 1.7443766593933105
Validation loss: 2.119978112559165

Epoch: 6| Step: 3
Training loss: 1.1143457889556885
Validation loss: 2.1466848875886653

Epoch: 6| Step: 4
Training loss: 1.3940024375915527
Validation loss: 2.127242604891459

Epoch: 6| Step: 5
Training loss: 1.5121575593948364
Validation loss: 2.1647568736025082

Epoch: 6| Step: 6
Training loss: 1.9571995735168457
Validation loss: 2.0779801825041413

Epoch: 6| Step: 7
Training loss: 1.8305130004882812
Validation loss: 2.0980382798820414

Epoch: 6| Step: 8
Training loss: 0.700849175453186
Validation loss: 2.0773698104325162

Epoch: 6| Step: 9
Training loss: 1.6591615676879883
Validation loss: 2.068415984030693

Epoch: 6| Step: 10
Training loss: 0.9443908333778381
Validation loss: 2.1114743422436457

Epoch: 6| Step: 11
Training loss: 1.6995967626571655
Validation loss: 2.0926799594715075

Epoch: 6| Step: 12
Training loss: 1.5621732473373413
Validation loss: 2.0963786391801733

Epoch: 6| Step: 13
Training loss: 1.6415143013000488
Validation loss: 2.0888852227118706

Epoch: 461| Step: 0
Training loss: 1.833100438117981
Validation loss: 2.127633520351943

Epoch: 6| Step: 1
Training loss: 1.6407924890518188
Validation loss: 2.081470101110397

Epoch: 6| Step: 2
Training loss: 1.045973300933838
Validation loss: 2.1087707768204393

Epoch: 6| Step: 3
Training loss: 1.5820682048797607
Validation loss: 2.0916186814667075

Epoch: 6| Step: 4
Training loss: 1.9440447092056274
Validation loss: 2.071215542413855

Epoch: 6| Step: 5
Training loss: 1.4347331523895264
Validation loss: 2.118688723092438

Epoch: 6| Step: 6
Training loss: 1.246540904045105
Validation loss: 2.1223450578669065

Epoch: 6| Step: 7
Training loss: 1.1582863330841064
Validation loss: 2.0962647225267146

Epoch: 6| Step: 8
Training loss: 1.6307363510131836
Validation loss: 2.1167879053341445

Epoch: 6| Step: 9
Training loss: 2.046022891998291
Validation loss: 2.0941029415335706

Epoch: 6| Step: 10
Training loss: 2.2756383419036865
Validation loss: 2.1295886039733887

Epoch: 6| Step: 11
Training loss: 1.1255106925964355
Validation loss: 2.0674617675042923

Epoch: 6| Step: 12
Training loss: 1.247342586517334
Validation loss: 2.1319684700299333

Epoch: 6| Step: 13
Training loss: 1.039048433303833
Validation loss: 2.115413014606763

Epoch: 462| Step: 0
Training loss: 1.2902195453643799
Validation loss: 2.1034267563973703

Epoch: 6| Step: 1
Training loss: 1.4312801361083984
Validation loss: 2.0847248108156267

Epoch: 6| Step: 2
Training loss: 1.488970398902893
Validation loss: 2.1249234637906476

Epoch: 6| Step: 3
Training loss: 1.8034677505493164
Validation loss: 2.06936639611439

Epoch: 6| Step: 4
Training loss: 1.5843532085418701
Validation loss: 2.068574679795132

Epoch: 6| Step: 5
Training loss: 1.5335016250610352
Validation loss: 2.088096942952884

Epoch: 6| Step: 6
Training loss: 1.5151336193084717
Validation loss: 2.0722134908040366

Epoch: 6| Step: 7
Training loss: 1.6600494384765625
Validation loss: 2.0839371783759004

Epoch: 6| Step: 8
Training loss: 1.7647912502288818
Validation loss: 2.0356845753167265

Epoch: 6| Step: 9
Training loss: 1.7498550415039062
Validation loss: 2.0775157482393327

Epoch: 6| Step: 10
Training loss: 1.554459571838379
Validation loss: 2.101490992371754

Epoch: 6| Step: 11
Training loss: 1.6258955001831055
Validation loss: 2.0928939491189937

Epoch: 6| Step: 12
Training loss: 1.3720675706863403
Validation loss: 2.085603542225335

Epoch: 6| Step: 13
Training loss: 1.2232153415679932
Validation loss: 2.0933453959803425

Epoch: 463| Step: 0
Training loss: 1.8201855421066284
Validation loss: 2.1466816163832143

Epoch: 6| Step: 1
Training loss: 1.2564585208892822
Validation loss: 2.116515028861261

Epoch: 6| Step: 2
Training loss: 1.1540358066558838
Validation loss: 2.166988008765764

Epoch: 6| Step: 3
Training loss: 2.1661558151245117
Validation loss: 2.121446978661322

Epoch: 6| Step: 4
Training loss: 1.6164417266845703
Validation loss: 2.169139669787499

Epoch: 6| Step: 5
Training loss: 1.2596313953399658
Validation loss: 2.1407401305372997

Epoch: 6| Step: 6
Training loss: 1.4132174253463745
Validation loss: 2.129065987884357

Epoch: 6| Step: 7
Training loss: 2.100834846496582
Validation loss: 2.1499423826894453

Epoch: 6| Step: 8
Training loss: 0.793179452419281
Validation loss: 2.1777622289555048

Epoch: 6| Step: 9
Training loss: 1.5042282342910767
Validation loss: 2.186206897099813

Epoch: 6| Step: 10
Training loss: 1.477645993232727
Validation loss: 2.1496840958954184

Epoch: 6| Step: 11
Training loss: 1.8092983961105347
Validation loss: 2.099846798886535

Epoch: 6| Step: 12
Training loss: 1.7429063320159912
Validation loss: 2.1275917458277878

Epoch: 6| Step: 13
Training loss: 1.7025011777877808
Validation loss: 2.11472773936487

Epoch: 464| Step: 0
Training loss: 1.02096688747406
Validation loss: 2.0883797394332064

Epoch: 6| Step: 1
Training loss: 1.303216576576233
Validation loss: 2.1173142643385034

Epoch: 6| Step: 2
Training loss: 1.3810503482818604
Validation loss: 2.0791829080991846

Epoch: 6| Step: 3
Training loss: 2.1376943588256836
Validation loss: 2.1525392827167305

Epoch: 6| Step: 4
Training loss: 1.5270977020263672
Validation loss: 2.045838068890315

Epoch: 6| Step: 5
Training loss: 1.5514203310012817
Validation loss: 2.1265853989508843

Epoch: 6| Step: 6
Training loss: 2.180953025817871
Validation loss: 2.069430705039732

Epoch: 6| Step: 7
Training loss: 2.4399256706237793
Validation loss: 2.0650167721574024

Epoch: 6| Step: 8
Training loss: 1.5554838180541992
Validation loss: 2.045933408121909

Epoch: 6| Step: 9
Training loss: 1.0528504848480225
Validation loss: 2.089868748059837

Epoch: 6| Step: 10
Training loss: 1.788332223892212
Validation loss: 2.062217522692937

Epoch: 6| Step: 11
Training loss: 1.1315135955810547
Validation loss: 2.112802541384133

Epoch: 6| Step: 12
Training loss: 1.4383823871612549
Validation loss: 2.0783646568175285

Epoch: 6| Step: 13
Training loss: 1.0661646127700806
Validation loss: 2.085834272446171

Epoch: 465| Step: 0
Training loss: 1.3496270179748535
Validation loss: 2.118304180842574

Epoch: 6| Step: 1
Training loss: 1.233672857284546
Validation loss: 2.0745281070791264

Epoch: 6| Step: 2
Training loss: 1.4476590156555176
Validation loss: 2.1165802299335437

Epoch: 6| Step: 3
Training loss: 1.886581301689148
Validation loss: 2.0898767273913146

Epoch: 6| Step: 4
Training loss: 1.5701217651367188
Validation loss: 2.167367617289225

Epoch: 6| Step: 5
Training loss: 1.5025999546051025
Validation loss: 2.0910007287097234

Epoch: 6| Step: 6
Training loss: 1.4820044040679932
Validation loss: 2.1592314115134617

Epoch: 6| Step: 7
Training loss: 1.3123254776000977
Validation loss: 2.127252951745064

Epoch: 6| Step: 8
Training loss: 1.9317164421081543
Validation loss: 2.120064368811987

Epoch: 6| Step: 9
Training loss: 2.4665939807891846
Validation loss: 2.1476241721901843

Epoch: 6| Step: 10
Training loss: 1.3038012981414795
Validation loss: 2.127158646942467

Epoch: 6| Step: 11
Training loss: 1.590651273727417
Validation loss: 2.1160978091660367

Epoch: 6| Step: 12
Training loss: 1.0900307893753052
Validation loss: 2.137119904641182

Epoch: 6| Step: 13
Training loss: 1.3911677598953247
Validation loss: 2.105909885898713

Epoch: 466| Step: 0
Training loss: 1.9269745349884033
Validation loss: 2.125038170045422

Epoch: 6| Step: 1
Training loss: 1.7005345821380615
Validation loss: 2.106544276719452

Epoch: 6| Step: 2
Training loss: 1.654284119606018
Validation loss: 2.065861221282713

Epoch: 6| Step: 3
Training loss: 1.4228041172027588
Validation loss: 2.0807243444586314

Epoch: 6| Step: 4
Training loss: 1.8390636444091797
Validation loss: 2.1120915464175645

Epoch: 6| Step: 5
Training loss: 1.2190407514572144
Validation loss: 2.061275912869361

Epoch: 6| Step: 6
Training loss: 1.279617428779602
Validation loss: 2.092162432209138

Epoch: 6| Step: 7
Training loss: 2.198399543762207
Validation loss: 2.045778077135804

Epoch: 6| Step: 8
Training loss: 1.121610164642334
Validation loss: 2.0796968449828444

Epoch: 6| Step: 9
Training loss: 1.3627018928527832
Validation loss: 2.055957322479576

Epoch: 6| Step: 10
Training loss: 1.3186736106872559
Validation loss: 2.092708278727788

Epoch: 6| Step: 11
Training loss: 1.7011570930480957
Validation loss: 2.0957561218610374

Epoch: 6| Step: 12
Training loss: 1.1048729419708252
Validation loss: 2.047430484525619

Epoch: 6| Step: 13
Training loss: 1.7329939603805542
Validation loss: 2.117656930800407

Epoch: 467| Step: 0
Training loss: 1.401388168334961
Validation loss: 2.127996280629148

Epoch: 6| Step: 1
Training loss: 1.6944124698638916
Validation loss: 2.0963077058074293

Epoch: 6| Step: 2
Training loss: 1.3651981353759766
Validation loss: 2.0995850357958066

Epoch: 6| Step: 3
Training loss: 2.334667682647705
Validation loss: 2.148114571007349

Epoch: 6| Step: 4
Training loss: 1.7868452072143555
Validation loss: 2.150533219819428

Epoch: 6| Step: 5
Training loss: 1.3505277633666992
Validation loss: 2.1251577049173336

Epoch: 6| Step: 6
Training loss: 1.7018675804138184
Validation loss: 2.1411515897320164

Epoch: 6| Step: 7
Training loss: 1.388493537902832
Validation loss: 2.1291676772538053

Epoch: 6| Step: 8
Training loss: 1.0799555778503418
Validation loss: 2.117374784202986

Epoch: 6| Step: 9
Training loss: 1.335721492767334
Validation loss: 2.103417440127301

Epoch: 6| Step: 10
Training loss: 1.641757845878601
Validation loss: 2.118011630991454

Epoch: 6| Step: 11
Training loss: 1.2195111513137817
Validation loss: 2.1532205535519506

Epoch: 6| Step: 12
Training loss: 1.6660974025726318
Validation loss: 2.1080435078631163

Epoch: 6| Step: 13
Training loss: 1.605309009552002
Validation loss: 2.0842650654495403

Epoch: 468| Step: 0
Training loss: 1.4551479816436768
Validation loss: 2.0880041853074105

Epoch: 6| Step: 1
Training loss: 1.9205563068389893
Validation loss: 2.068334012903193

Epoch: 6| Step: 2
Training loss: 1.9141530990600586
Validation loss: 2.1043045802782943

Epoch: 6| Step: 3
Training loss: 1.6464316844940186
Validation loss: 2.0646746081690632

Epoch: 6| Step: 4
Training loss: 1.1255440711975098
Validation loss: 2.107757285077085

Epoch: 6| Step: 5
Training loss: 1.4587452411651611
Validation loss: 2.0471867976650113

Epoch: 6| Step: 6
Training loss: 1.3645267486572266
Validation loss: 2.0740275177904355

Epoch: 6| Step: 7
Training loss: 1.2376532554626465
Validation loss: 2.0969276351313435

Epoch: 6| Step: 8
Training loss: 1.6252028942108154
Validation loss: 2.1274062895005748

Epoch: 6| Step: 9
Training loss: 1.3992011547088623
Validation loss: 2.0868035080612346

Epoch: 6| Step: 10
Training loss: 1.5456600189208984
Validation loss: 2.0928920635613064

Epoch: 6| Step: 11
Training loss: 1.7414376735687256
Validation loss: 2.0879372178867297

Epoch: 6| Step: 12
Training loss: 1.8324977159500122
Validation loss: 2.12466836103829

Epoch: 6| Step: 13
Training loss: 1.7597129344940186
Validation loss: 2.0732227294675765

Epoch: 469| Step: 0
Training loss: 1.2585276365280151
Validation loss: 2.1028060477267028

Epoch: 6| Step: 1
Training loss: 0.7020399570465088
Validation loss: 2.105314626488634

Epoch: 6| Step: 2
Training loss: 2.075282096862793
Validation loss: 2.0654436593414633

Epoch: 6| Step: 3
Training loss: 1.476127028465271
Validation loss: 2.107334562527236

Epoch: 6| Step: 4
Training loss: 1.3611316680908203
Validation loss: 2.1371081593216106

Epoch: 6| Step: 5
Training loss: 1.2076019048690796
Validation loss: 2.106492693706225

Epoch: 6| Step: 6
Training loss: 1.644369125366211
Validation loss: 2.1110516568665862

Epoch: 6| Step: 7
Training loss: 1.7758674621582031
Validation loss: 2.1095632430045836

Epoch: 6| Step: 8
Training loss: 1.7766833305358887
Validation loss: 2.092438756778676

Epoch: 6| Step: 9
Training loss: 1.960863709449768
Validation loss: 2.098529149127263

Epoch: 6| Step: 10
Training loss: 2.002553939819336
Validation loss: 2.075181007385254

Epoch: 6| Step: 11
Training loss: 1.57804536819458
Validation loss: 2.1295038192502913

Epoch: 6| Step: 12
Training loss: 1.004278302192688
Validation loss: 2.078563574821718

Epoch: 6| Step: 13
Training loss: 1.6935738325119019
Validation loss: 2.091514293865491

Epoch: 470| Step: 0
Training loss: 2.538198947906494
Validation loss: 2.111468853489045

Epoch: 6| Step: 1
Training loss: 0.9802961945533752
Validation loss: 2.0730622455637944

Epoch: 6| Step: 2
Training loss: 1.10560941696167
Validation loss: 2.0830558910164783

Epoch: 6| Step: 3
Training loss: 1.3192837238311768
Validation loss: 2.0780812719816804

Epoch: 6| Step: 4
Training loss: 1.00179123878479
Validation loss: 2.080056328927317

Epoch: 6| Step: 5
Training loss: 1.7111380100250244
Validation loss: 2.060352248530234

Epoch: 6| Step: 6
Training loss: 1.3048169612884521
Validation loss: 2.1365272614263717

Epoch: 6| Step: 7
Training loss: 1.1319628953933716
Validation loss: 2.097597242683493

Epoch: 6| Step: 8
Training loss: 1.4668456315994263
Validation loss: 2.0990175418956305

Epoch: 6| Step: 9
Training loss: 1.4634294509887695
Validation loss: 2.093370004366803

Epoch: 6| Step: 10
Training loss: 2.0558323860168457
Validation loss: 2.0948685805002847

Epoch: 6| Step: 11
Training loss: 1.6757408380508423
Validation loss: 2.0790163829762447

Epoch: 6| Step: 12
Training loss: 2.0070509910583496
Validation loss: 2.118407451978294

Epoch: 6| Step: 13
Training loss: 1.7033171653747559
Validation loss: 2.116781703887447

Epoch: 471| Step: 0
Training loss: 2.251478910446167
Validation loss: 2.1187295157422303

Epoch: 6| Step: 1
Training loss: 2.019653558731079
Validation loss: 2.1224726476976947

Epoch: 6| Step: 2
Training loss: 1.5316884517669678
Validation loss: 2.0729764840936147

Epoch: 6| Step: 3
Training loss: 1.575720191001892
Validation loss: 2.0948284582425187

Epoch: 6| Step: 4
Training loss: 1.3373911380767822
Validation loss: 2.073548824556412

Epoch: 6| Step: 5
Training loss: 0.75617915391922
Validation loss: 2.094571159731957

Epoch: 6| Step: 6
Training loss: 1.4017730951309204
Validation loss: 2.09744748761577

Epoch: 6| Step: 7
Training loss: 1.39052152633667
Validation loss: 2.110877429285357

Epoch: 6| Step: 8
Training loss: 1.5099525451660156
Validation loss: 2.11524563066421

Epoch: 6| Step: 9
Training loss: 0.9731740951538086
Validation loss: 2.060561586451787

Epoch: 6| Step: 10
Training loss: 1.408747673034668
Validation loss: 2.134123303556955

Epoch: 6| Step: 11
Training loss: 1.4067938327789307
Validation loss: 2.093255037902504

Epoch: 6| Step: 12
Training loss: 1.645660400390625
Validation loss: 2.047982397899833

Epoch: 6| Step: 13
Training loss: 2.3646156787872314
Validation loss: 2.0913705107986287

Epoch: 472| Step: 0
Training loss: 1.2714581489562988
Validation loss: 2.110922118668915

Epoch: 6| Step: 1
Training loss: 2.0309863090515137
Validation loss: 2.121761273312312

Epoch: 6| Step: 2
Training loss: 1.2491426467895508
Validation loss: 2.0973850860390613

Epoch: 6| Step: 3
Training loss: 1.3965545892715454
Validation loss: 2.0862096432716615

Epoch: 6| Step: 4
Training loss: 1.3373734951019287
Validation loss: 2.0819031551320064

Epoch: 6| Step: 5
Training loss: 0.8932271003723145
Validation loss: 2.0822088667141494

Epoch: 6| Step: 6
Training loss: 1.0509371757507324
Validation loss: 2.1159082010228145

Epoch: 6| Step: 7
Training loss: 1.7340662479400635
Validation loss: 2.092571376472391

Epoch: 6| Step: 8
Training loss: 1.4439897537231445
Validation loss: 2.090149866637363

Epoch: 6| Step: 9
Training loss: 1.8517204523086548
Validation loss: 2.0944555100574287

Epoch: 6| Step: 10
Training loss: 1.534761667251587
Validation loss: 2.084870174366941

Epoch: 6| Step: 11
Training loss: 1.4924170970916748
Validation loss: 2.0891489880059355

Epoch: 6| Step: 12
Training loss: 1.7989630699157715
Validation loss: 2.1611971829527166

Epoch: 6| Step: 13
Training loss: 2.0636918544769287
Validation loss: 2.126431906095115

Epoch: 473| Step: 0
Training loss: 1.4762293100357056
Validation loss: 2.10969256072916

Epoch: 6| Step: 1
Training loss: 1.4975543022155762
Validation loss: 2.0930024808452976

Epoch: 6| Step: 2
Training loss: 1.284407138824463
Validation loss: 2.11770345446884

Epoch: 6| Step: 3
Training loss: 1.4769999980926514
Validation loss: 2.1436191399892173

Epoch: 6| Step: 4
Training loss: 1.1198697090148926
Validation loss: 2.0875151336833997

Epoch: 6| Step: 5
Training loss: 1.443420171737671
Validation loss: 2.061875243340769

Epoch: 6| Step: 6
Training loss: 1.9640166759490967
Validation loss: 2.108883762872347

Epoch: 6| Step: 7
Training loss: 2.6219711303710938
Validation loss: 2.0754672429894887

Epoch: 6| Step: 8
Training loss: 1.5681713819503784
Validation loss: 2.0796468232267644

Epoch: 6| Step: 9
Training loss: 1.069800615310669
Validation loss: 2.081856886545817

Epoch: 6| Step: 10
Training loss: 1.5454094409942627
Validation loss: 2.1039941490337415

Epoch: 6| Step: 11
Training loss: 1.5701501369476318
Validation loss: 2.120043941723403

Epoch: 6| Step: 12
Training loss: 1.4480494260787964
Validation loss: 2.0777468514698807

Epoch: 6| Step: 13
Training loss: 1.2671303749084473
Validation loss: 2.093482834036632

Epoch: 474| Step: 0
Training loss: 1.2570927143096924
Validation loss: 2.103940595862686

Epoch: 6| Step: 1
Training loss: 1.4614923000335693
Validation loss: 2.0750030522705405

Epoch: 6| Step: 2
Training loss: 1.1600958108901978
Validation loss: 2.1088958658197874

Epoch: 6| Step: 3
Training loss: 1.842760443687439
Validation loss: 2.1018188102270967

Epoch: 6| Step: 4
Training loss: 1.4770562648773193
Validation loss: 2.0993967543366137

Epoch: 6| Step: 5
Training loss: 1.3268868923187256
Validation loss: 2.117487766409433

Epoch: 6| Step: 6
Training loss: 1.661049723625183
Validation loss: 2.110109143359687

Epoch: 6| Step: 7
Training loss: 1.4085369110107422
Validation loss: 2.1686184995917865

Epoch: 6| Step: 8
Training loss: 2.1442489624023438
Validation loss: 2.152379757614546

Epoch: 6| Step: 9
Training loss: 1.808013916015625
Validation loss: 2.1296642018902685

Epoch: 6| Step: 10
Training loss: 1.3228023052215576
Validation loss: 2.1140849410846667

Epoch: 6| Step: 11
Training loss: 0.7023048400878906
Validation loss: 2.1292138035579393

Epoch: 6| Step: 12
Training loss: 1.672581672668457
Validation loss: 2.1396096009080128

Epoch: 6| Step: 13
Training loss: 2.264526128768921
Validation loss: 2.104268293226919

Epoch: 475| Step: 0
Training loss: 1.4084687232971191
Validation loss: 2.083205871684577

Epoch: 6| Step: 1
Training loss: 1.5422420501708984
Validation loss: 2.1345667723686463

Epoch: 6| Step: 2
Training loss: 1.1850167512893677
Validation loss: 2.0324027833118232

Epoch: 6| Step: 3
Training loss: 1.3047215938568115
Validation loss: 2.0787029843176565

Epoch: 6| Step: 4
Training loss: 1.5028635263442993
Validation loss: 2.0822823355274815

Epoch: 6| Step: 5
Training loss: 1.5784212350845337
Validation loss: 2.0904185951396985

Epoch: 6| Step: 6
Training loss: 1.9777636528015137
Validation loss: 2.0711544162483624

Epoch: 6| Step: 7
Training loss: 1.2741683721542358
Validation loss: 2.119506641100812

Epoch: 6| Step: 8
Training loss: 2.5982460975646973
Validation loss: 2.066671868806244

Epoch: 6| Step: 9
Training loss: 1.3670434951782227
Validation loss: 2.097864261237524

Epoch: 6| Step: 10
Training loss: 1.075336217880249
Validation loss: 2.0792305277239893

Epoch: 6| Step: 11
Training loss: 1.4374665021896362
Validation loss: 2.0755760567162627

Epoch: 6| Step: 12
Training loss: 1.5174551010131836
Validation loss: 2.1190828072127474

Epoch: 6| Step: 13
Training loss: 1.7453408241271973
Validation loss: 2.059763195694134

Epoch: 476| Step: 0
Training loss: 1.2818386554718018
Validation loss: 2.0710491839275567

Epoch: 6| Step: 1
Training loss: 1.8199775218963623
Validation loss: 2.0955626862023466

Epoch: 6| Step: 2
Training loss: 1.7582778930664062
Validation loss: 2.1338865192987586

Epoch: 6| Step: 3
Training loss: 1.7664086818695068
Validation loss: 2.1574793836121917

Epoch: 6| Step: 4
Training loss: 1.309581995010376
Validation loss: 2.113873856042021

Epoch: 6| Step: 5
Training loss: 1.3161447048187256
Validation loss: 2.156610861901314

Epoch: 6| Step: 6
Training loss: 1.9546562433242798
Validation loss: 2.1464270340499056

Epoch: 6| Step: 7
Training loss: 1.3833274841308594
Validation loss: 2.1496923738910305

Epoch: 6| Step: 8
Training loss: 1.4538486003875732
Validation loss: 2.137783877311214

Epoch: 6| Step: 9
Training loss: 1.2543708086013794
Validation loss: 2.151738992301367

Epoch: 6| Step: 10
Training loss: 1.5705642700195312
Validation loss: 2.093066958970921

Epoch: 6| Step: 11
Training loss: 1.387467861175537
Validation loss: 2.122348532881788

Epoch: 6| Step: 12
Training loss: 1.7179439067840576
Validation loss: 2.115354031644842

Epoch: 6| Step: 13
Training loss: 1.4769644737243652
Validation loss: 2.095188538233439

Epoch: 477| Step: 0
Training loss: 0.9219327569007874
Validation loss: 2.102695829124861

Epoch: 6| Step: 1
Training loss: 0.9824232459068298
Validation loss: 2.076317761534004

Epoch: 6| Step: 2
Training loss: 1.333778738975525
Validation loss: 2.0720189245798255

Epoch: 6| Step: 3
Training loss: 1.5801573991775513
Validation loss: 2.1037011697728145

Epoch: 6| Step: 4
Training loss: 1.6126172542572021
Validation loss: 2.047173423151816

Epoch: 6| Step: 5
Training loss: 1.45884370803833
Validation loss: 2.0172530194764495

Epoch: 6| Step: 6
Training loss: 1.79066801071167
Validation loss: 2.120608572036989

Epoch: 6| Step: 7
Training loss: 1.2919269800186157
Validation loss: 2.0506707224794614

Epoch: 6| Step: 8
Training loss: 1.564683437347412
Validation loss: 2.0641568655608804

Epoch: 6| Step: 9
Training loss: 1.9308785200119019
Validation loss: 2.109238942464193

Epoch: 6| Step: 10
Training loss: 1.871742606163025
Validation loss: 2.0925261974334717

Epoch: 6| Step: 11
Training loss: 0.980931282043457
Validation loss: 2.0532015856876167

Epoch: 6| Step: 12
Training loss: 2.1954212188720703
Validation loss: 2.0860866436394314

Epoch: 6| Step: 13
Training loss: 1.257002353668213
Validation loss: 2.05339491110976

Epoch: 478| Step: 0
Training loss: 2.356670379638672
Validation loss: 2.077682379753359

Epoch: 6| Step: 1
Training loss: 1.2258057594299316
Validation loss: 2.06258919162135

Epoch: 6| Step: 2
Training loss: 1.5134233236312866
Validation loss: 2.1044039572438886

Epoch: 6| Step: 3
Training loss: 1.4794527292251587
Validation loss: 2.119702507090825

Epoch: 6| Step: 4
Training loss: 1.0269858837127686
Validation loss: 2.1096274737388856

Epoch: 6| Step: 5
Training loss: 1.8773481845855713
Validation loss: 2.103084166844686

Epoch: 6| Step: 6
Training loss: 1.5889389514923096
Validation loss: 2.076173333711522

Epoch: 6| Step: 7
Training loss: 1.94118070602417
Validation loss: 2.078175724193614

Epoch: 6| Step: 8
Training loss: 1.6030550003051758
Validation loss: 2.094972087490943

Epoch: 6| Step: 9
Training loss: 1.525248408317566
Validation loss: 2.103860032173895

Epoch: 6| Step: 10
Training loss: 1.1637110710144043
Validation loss: 2.1359260966700893

Epoch: 6| Step: 11
Training loss: 1.3054121732711792
Validation loss: 2.060371386107578

Epoch: 6| Step: 12
Training loss: 1.2159799337387085
Validation loss: 2.124645802282518

Epoch: 6| Step: 13
Training loss: 1.4177032709121704
Validation loss: 2.101824570727605

Epoch: 479| Step: 0
Training loss: 1.1763453483581543
Validation loss: 2.052371912105109

Epoch: 6| Step: 1
Training loss: 1.6491044759750366
Validation loss: 2.0800436837698824

Epoch: 6| Step: 2
Training loss: 1.382477045059204
Validation loss: 2.089479843775431

Epoch: 6| Step: 3
Training loss: 1.8609373569488525
Validation loss: 2.074897402076311

Epoch: 6| Step: 4
Training loss: 1.9181581735610962
Validation loss: 2.092790384446421

Epoch: 6| Step: 5
Training loss: 1.7092931270599365
Validation loss: 2.0588091163225073

Epoch: 6| Step: 6
Training loss: 1.3820905685424805
Validation loss: 2.069271969538863

Epoch: 6| Step: 7
Training loss: 1.4120430946350098
Validation loss: 2.0624023368281703

Epoch: 6| Step: 8
Training loss: 1.0567638874053955
Validation loss: 2.075406139896762

Epoch: 6| Step: 9
Training loss: 2.1622366905212402
Validation loss: 2.107355684362432

Epoch: 6| Step: 10
Training loss: 1.4301552772521973
Validation loss: 2.077124882769841

Epoch: 6| Step: 11
Training loss: 1.5289154052734375
Validation loss: 2.0431295441042994

Epoch: 6| Step: 12
Training loss: 1.662813425064087
Validation loss: 2.1020449207675074

Epoch: 6| Step: 13
Training loss: 0.7941089868545532
Validation loss: 2.0850106900738132

Epoch: 480| Step: 0
Training loss: 0.5203686952590942
Validation loss: 2.09275064545293

Epoch: 6| Step: 1
Training loss: 1.3505430221557617
Validation loss: 2.1030672506619523

Epoch: 6| Step: 2
Training loss: 1.8729029893875122
Validation loss: 2.078947631261682

Epoch: 6| Step: 3
Training loss: 1.8288023471832275
Validation loss: 2.1081508949238765

Epoch: 6| Step: 4
Training loss: 2.0091607570648193
Validation loss: 2.123730062156595

Epoch: 6| Step: 5
Training loss: 1.9416321516036987
Validation loss: 2.1076056444516746

Epoch: 6| Step: 6
Training loss: 1.6393234729766846
Validation loss: 2.1370687125831522

Epoch: 6| Step: 7
Training loss: 1.618694543838501
Validation loss: 2.1047090432977162

Epoch: 6| Step: 8
Training loss: 1.3741669654846191
Validation loss: 2.1195743673591205

Epoch: 6| Step: 9
Training loss: 1.1094589233398438
Validation loss: 2.0917318277461554

Epoch: 6| Step: 10
Training loss: 1.8064697980880737
Validation loss: 2.0896643695010932

Epoch: 6| Step: 11
Training loss: 1.5553499460220337
Validation loss: 2.0714530252641246

Epoch: 6| Step: 12
Training loss: 1.5291576385498047
Validation loss: 2.1207565415290093

Epoch: 6| Step: 13
Training loss: 0.9433911442756653
Validation loss: 2.082686960056264

Epoch: 481| Step: 0
Training loss: 0.9590457081794739
Validation loss: 2.088403788946008

Epoch: 6| Step: 1
Training loss: 1.703903079032898
Validation loss: 2.0436471867304977

Epoch: 6| Step: 2
Training loss: 1.4734408855438232
Validation loss: 2.103543953229022

Epoch: 6| Step: 3
Training loss: 1.7647085189819336
Validation loss: 2.0644822325757755

Epoch: 6| Step: 4
Training loss: 1.3920764923095703
Validation loss: 2.0297245799854235

Epoch: 6| Step: 5
Training loss: 1.7774248123168945
Validation loss: 2.0925882606096167

Epoch: 6| Step: 6
Training loss: 1.7786533832550049
Validation loss: 2.0834356200310493

Epoch: 6| Step: 7
Training loss: 1.7125091552734375
Validation loss: 2.072632997266708

Epoch: 6| Step: 8
Training loss: 1.5108909606933594
Validation loss: 2.0612230044539257

Epoch: 6| Step: 9
Training loss: 0.828741729259491
Validation loss: 2.0387843360183058

Epoch: 6| Step: 10
Training loss: 1.501955270767212
Validation loss: 2.100031319484916

Epoch: 6| Step: 11
Training loss: 1.3747692108154297
Validation loss: 2.032741012111787

Epoch: 6| Step: 12
Training loss: 2.024547815322876
Validation loss: 2.125270756342078

Epoch: 6| Step: 13
Training loss: 0.8606907725334167
Validation loss: 2.069843771637127

Epoch: 482| Step: 0
Training loss: 1.5519906282424927
Validation loss: 2.094878701753514

Epoch: 6| Step: 1
Training loss: 1.6327040195465088
Validation loss: 2.0635319166286017

Epoch: 6| Step: 2
Training loss: 1.3430286645889282
Validation loss: 2.0837377361072007

Epoch: 6| Step: 3
Training loss: 1.3230277299880981
Validation loss: 2.1136772222416376

Epoch: 6| Step: 4
Training loss: 1.4190118312835693
Validation loss: 2.0932175549127723

Epoch: 6| Step: 5
Training loss: 1.2436580657958984
Validation loss: 2.068440342462191

Epoch: 6| Step: 6
Training loss: 1.9065704345703125
Validation loss: 2.0943390451451784

Epoch: 6| Step: 7
Training loss: 1.4528005123138428
Validation loss: 2.1322203759224183

Epoch: 6| Step: 8
Training loss: 0.9286800622940063
Validation loss: 2.160410282432392

Epoch: 6| Step: 9
Training loss: 1.4776639938354492
Validation loss: 2.1346142522750364

Epoch: 6| Step: 10
Training loss: 2.3190441131591797
Validation loss: 2.128886217712074

Epoch: 6| Step: 11
Training loss: 1.260528802871704
Validation loss: 2.1481496877567743

Epoch: 6| Step: 12
Training loss: 1.9519968032836914
Validation loss: 2.059632520521841

Epoch: 6| Step: 13
Training loss: 0.9022464752197266
Validation loss: 2.08406041770853

Epoch: 483| Step: 0
Training loss: 1.9180306196212769
Validation loss: 2.09189651602058

Epoch: 6| Step: 1
Training loss: 1.2283495664596558
Validation loss: 2.09132920926617

Epoch: 6| Step: 2
Training loss: 1.40372633934021
Validation loss: 2.089165928543255

Epoch: 6| Step: 3
Training loss: 2.3080148696899414
Validation loss: 2.103606193296371

Epoch: 6| Step: 4
Training loss: 1.4984593391418457
Validation loss: 2.0995639729243454

Epoch: 6| Step: 5
Training loss: 0.9766514301300049
Validation loss: 2.10370603043546

Epoch: 6| Step: 6
Training loss: 1.659253716468811
Validation loss: 2.0678669867977018

Epoch: 6| Step: 7
Training loss: 1.189274787902832
Validation loss: 2.062216046035931

Epoch: 6| Step: 8
Training loss: 1.6618841886520386
Validation loss: 2.047171095366119

Epoch: 6| Step: 9
Training loss: 1.9260690212249756
Validation loss: 2.060662777193131

Epoch: 6| Step: 10
Training loss: 1.021024465560913
Validation loss: 2.069517153565602

Epoch: 6| Step: 11
Training loss: 1.4348359107971191
Validation loss: 2.0726429236832487

Epoch: 6| Step: 12
Training loss: 1.8920241594314575
Validation loss: 2.1381955249335176

Epoch: 6| Step: 13
Training loss: 1.6006771326065063
Validation loss: 2.0661433486528296

Epoch: 484| Step: 0
Training loss: 1.4246793985366821
Validation loss: 2.093678794881349

Epoch: 6| Step: 1
Training loss: 1.230539083480835
Validation loss: 2.089233188218968

Epoch: 6| Step: 2
Training loss: 1.9370183944702148
Validation loss: 2.074804361148547

Epoch: 6| Step: 3
Training loss: 1.645282506942749
Validation loss: 2.0588687581400715

Epoch: 6| Step: 4
Training loss: 1.0213634967803955
Validation loss: 2.0844790858607136

Epoch: 6| Step: 5
Training loss: 1.2863914966583252
Validation loss: 2.0889973871169554

Epoch: 6| Step: 6
Training loss: 1.8970496654510498
Validation loss: 2.1150288876666816

Epoch: 6| Step: 7
Training loss: 1.1094138622283936
Validation loss: 2.1092916098974084

Epoch: 6| Step: 8
Training loss: 1.2401078939437866
Validation loss: 2.093687580477807

Epoch: 6| Step: 9
Training loss: 1.851707100868225
Validation loss: 2.0434892049399753

Epoch: 6| Step: 10
Training loss: 2.0273823738098145
Validation loss: 2.0871251424153647

Epoch: 6| Step: 11
Training loss: 2.21212100982666
Validation loss: 2.13775574263706

Epoch: 6| Step: 12
Training loss: 1.0588618516921997
Validation loss: 2.094133533457274

Epoch: 6| Step: 13
Training loss: 1.389229416847229
Validation loss: 2.0915830084072646

Epoch: 485| Step: 0
Training loss: 1.6281424760818481
Validation loss: 2.0906710214512323

Epoch: 6| Step: 1
Training loss: 1.3528163433074951
Validation loss: 2.1228286515000048

Epoch: 6| Step: 2
Training loss: 1.5991196632385254
Validation loss: 2.120103823241367

Epoch: 6| Step: 3
Training loss: 1.5336846113204956
Validation loss: 2.0907237888664327

Epoch: 6| Step: 4
Training loss: 2.1644649505615234
Validation loss: 2.1266164754026677

Epoch: 6| Step: 5
Training loss: 1.2714979648590088
Validation loss: 2.1243357196930917

Epoch: 6| Step: 6
Training loss: 1.8497679233551025
Validation loss: 2.119369496581375

Epoch: 6| Step: 7
Training loss: 1.6743121147155762
Validation loss: 2.0950216106189194

Epoch: 6| Step: 8
Training loss: 0.9955586194992065
Validation loss: 2.0730450666078957

Epoch: 6| Step: 9
Training loss: 0.8717358112335205
Validation loss: 2.052170809879098

Epoch: 6| Step: 10
Training loss: 0.9896270632743835
Validation loss: 2.0901392429105696

Epoch: 6| Step: 11
Training loss: 1.8693549633026123
Validation loss: 2.0622776336567377

Epoch: 6| Step: 12
Training loss: 1.5050970315933228
Validation loss: 2.1189014783469577

Epoch: 6| Step: 13
Training loss: 1.5454133749008179
Validation loss: 2.1019684653128348

Epoch: 486| Step: 0
Training loss: 1.2265352010726929
Validation loss: 2.091656123438189

Epoch: 6| Step: 1
Training loss: 1.4202916622161865
Validation loss: 2.0570650613436134

Epoch: 6| Step: 2
Training loss: 1.5473250150680542
Validation loss: 2.0309390252636326

Epoch: 6| Step: 3
Training loss: 1.507234811782837
Validation loss: 2.1179013982895882

Epoch: 6| Step: 4
Training loss: 1.8903744220733643
Validation loss: 2.1073202881761777

Epoch: 6| Step: 5
Training loss: 1.7507685422897339
Validation loss: 2.1099219745205295

Epoch: 6| Step: 6
Training loss: 1.4648377895355225
Validation loss: 2.1031733815388014

Epoch: 6| Step: 7
Training loss: 1.7051812410354614
Validation loss: 2.131553662720547

Epoch: 6| Step: 8
Training loss: 1.2284749746322632
Validation loss: 2.1000055151600994

Epoch: 6| Step: 9
Training loss: 1.4333133697509766
Validation loss: 2.1379394710704847

Epoch: 6| Step: 10
Training loss: 1.9052767753601074
Validation loss: 2.0413956795969317

Epoch: 6| Step: 11
Training loss: 0.8724554777145386
Validation loss: 2.134531900446902

Epoch: 6| Step: 12
Training loss: 1.2799609899520874
Validation loss: 2.120520660954137

Epoch: 6| Step: 13
Training loss: 2.0817065238952637
Validation loss: 2.122446495999572

Epoch: 487| Step: 0
Training loss: 1.4792884588241577
Validation loss: 2.0685435520705355

Epoch: 6| Step: 1
Training loss: 1.2747687101364136
Validation loss: 2.118003647814515

Epoch: 6| Step: 2
Training loss: 2.127655506134033
Validation loss: 2.1217569099959506

Epoch: 6| Step: 3
Training loss: 1.7747364044189453
Validation loss: 2.096895715241791

Epoch: 6| Step: 4
Training loss: 1.4140350818634033
Validation loss: 2.1253246876501266

Epoch: 6| Step: 5
Training loss: 1.8005990982055664
Validation loss: 2.0925143085500246

Epoch: 6| Step: 6
Training loss: 0.968580961227417
Validation loss: 2.1055839766738234

Epoch: 6| Step: 7
Training loss: 1.234876275062561
Validation loss: 2.096982325277021

Epoch: 6| Step: 8
Training loss: 1.5416404008865356
Validation loss: 2.07582845610957

Epoch: 6| Step: 9
Training loss: 1.401195764541626
Validation loss: 2.1133829778240574

Epoch: 6| Step: 10
Training loss: 1.8483757972717285
Validation loss: 2.1442949336062194

Epoch: 6| Step: 11
Training loss: 1.0368283987045288
Validation loss: 2.0980661120466007

Epoch: 6| Step: 12
Training loss: 1.8581807613372803
Validation loss: 2.1109408588819605

Epoch: 6| Step: 13
Training loss: 0.889271080493927
Validation loss: 2.101810038730662

Epoch: 488| Step: 0
Training loss: 1.2035375833511353
Validation loss: 2.115177659578221

Epoch: 6| Step: 1
Training loss: 2.068530321121216
Validation loss: 2.1250139231322915

Epoch: 6| Step: 2
Training loss: 1.9463365077972412
Validation loss: 2.1458777202072965

Epoch: 6| Step: 3
Training loss: 1.2200311422348022
Validation loss: 2.0657376525222615

Epoch: 6| Step: 4
Training loss: 1.1274079084396362
Validation loss: 2.1268993910922798

Epoch: 6| Step: 5
Training loss: 0.8827677965164185
Validation loss: 2.1162803762702533

Epoch: 6| Step: 6
Training loss: 1.3724466562271118
Validation loss: 2.0901824684553247

Epoch: 6| Step: 7
Training loss: 1.6580266952514648
Validation loss: 2.1389911443956438

Epoch: 6| Step: 8
Training loss: 1.5239795446395874
Validation loss: 2.123459901860965

Epoch: 6| Step: 9
Training loss: 2.1176209449768066
Validation loss: 2.1132987160836496

Epoch: 6| Step: 10
Training loss: 1.0758056640625
Validation loss: 2.0533346309456775

Epoch: 6| Step: 11
Training loss: 1.566243290901184
Validation loss: 2.100602002554042

Epoch: 6| Step: 12
Training loss: 1.6715673208236694
Validation loss: 2.057731138762607

Epoch: 6| Step: 13
Training loss: 1.5259851217269897
Validation loss: 2.083508865807646

Epoch: 489| Step: 0
Training loss: 1.2021570205688477
Validation loss: 2.0755376841432307

Epoch: 6| Step: 1
Training loss: 1.5249005556106567
Validation loss: 2.0550852232081915

Epoch: 6| Step: 2
Training loss: 1.5005297660827637
Validation loss: 2.1044473801889727

Epoch: 6| Step: 3
Training loss: 1.4941078424453735
Validation loss: 2.1043712503166607

Epoch: 6| Step: 4
Training loss: 2.4756674766540527
Validation loss: 2.08629641097079

Epoch: 6| Step: 5
Training loss: 2.0984973907470703
Validation loss: 2.095830789176367

Epoch: 6| Step: 6
Training loss: 1.915696144104004
Validation loss: 2.0699132027164584

Epoch: 6| Step: 7
Training loss: 1.4029842615127563
Validation loss: 2.0755103698340793

Epoch: 6| Step: 8
Training loss: 1.8769927024841309
Validation loss: 2.0922821849905033

Epoch: 6| Step: 9
Training loss: 0.9798818230628967
Validation loss: 2.061190926900474

Epoch: 6| Step: 10
Training loss: 0.9123468399047852
Validation loss: 2.060737239417209

Epoch: 6| Step: 11
Training loss: 1.269636869430542
Validation loss: 2.0585745714044057

Epoch: 6| Step: 12
Training loss: 1.086330771446228
Validation loss: 2.0434722336389686

Epoch: 6| Step: 13
Training loss: 1.2832261323928833
Validation loss: 2.059138162161714

Epoch: 490| Step: 0
Training loss: 2.0734779834747314
Validation loss: 2.0986918659620386

Epoch: 6| Step: 1
Training loss: 1.4650425910949707
Validation loss: 2.1303624030082458

Epoch: 6| Step: 2
Training loss: 0.933838427066803
Validation loss: 2.0456164395937355

Epoch: 6| Step: 3
Training loss: 1.7817347049713135
Validation loss: 2.0670073134924776

Epoch: 6| Step: 4
Training loss: 1.6336199045181274
Validation loss: 2.0839740871101298

Epoch: 6| Step: 5
Training loss: 1.6847622394561768
Validation loss: 2.078367817786432

Epoch: 6| Step: 6
Training loss: 0.9721025824546814
Validation loss: 2.0603431501696186

Epoch: 6| Step: 7
Training loss: 1.4909484386444092
Validation loss: 2.061640538195128

Epoch: 6| Step: 8
Training loss: 1.0838085412979126
Validation loss: 2.06276301927464

Epoch: 6| Step: 9
Training loss: 2.0737905502319336
Validation loss: 2.048876059952603

Epoch: 6| Step: 10
Training loss: 1.6375439167022705
Validation loss: 2.0593311889197237

Epoch: 6| Step: 11
Training loss: 1.0566898584365845
Validation loss: 2.10810080523132

Epoch: 6| Step: 12
Training loss: 1.6208455562591553
Validation loss: 2.085541218839666

Epoch: 6| Step: 13
Training loss: 1.5481313467025757
Validation loss: 2.0821918441403295

Epoch: 491| Step: 0
Training loss: 1.3953797817230225
Validation loss: 2.0788572962566088

Epoch: 6| Step: 1
Training loss: 2.4077579975128174
Validation loss: 2.1069234981331775

Epoch: 6| Step: 2
Training loss: 1.2896926403045654
Validation loss: 2.064851495527452

Epoch: 6| Step: 3
Training loss: 0.943231463432312
Validation loss: 2.0368829414408696

Epoch: 6| Step: 4
Training loss: 0.5935624837875366
Validation loss: 2.0661435114440097

Epoch: 6| Step: 5
Training loss: 1.442458152770996
Validation loss: 2.0877606638016237

Epoch: 6| Step: 6
Training loss: 1.6886749267578125
Validation loss: 2.0807460559311735

Epoch: 6| Step: 7
Training loss: 2.3675308227539062
Validation loss: 2.1428542906238186

Epoch: 6| Step: 8
Training loss: 1.1390529870986938
Validation loss: 2.0361595205081406

Epoch: 6| Step: 9
Training loss: 1.3554093837738037
Validation loss: 2.051103966210478

Epoch: 6| Step: 10
Training loss: 1.51511549949646
Validation loss: 2.051345843140797

Epoch: 6| Step: 11
Training loss: 2.1549668312072754
Validation loss: 2.0645748953665457

Epoch: 6| Step: 12
Training loss: 1.5333932638168335
Validation loss: 2.076105640780541

Epoch: 6| Step: 13
Training loss: 1.077303171157837
Validation loss: 2.099281508435485

Epoch: 492| Step: 0
Training loss: 1.3784279823303223
Validation loss: 2.0884525622090986

Epoch: 6| Step: 1
Training loss: 1.3952691555023193
Validation loss: 2.087461030611428

Epoch: 6| Step: 2
Training loss: 1.3038675785064697
Validation loss: 2.1358514396093224

Epoch: 6| Step: 3
Training loss: 1.8586357831954956
Validation loss: 2.0236363795495804

Epoch: 6| Step: 4
Training loss: 0.8716670274734497
Validation loss: 2.1259102436804

Epoch: 6| Step: 5
Training loss: 1.7382612228393555
Validation loss: 2.098918801994734

Epoch: 6| Step: 6
Training loss: 1.4509685039520264
Validation loss: 2.096714599158174

Epoch: 6| Step: 7
Training loss: 1.4063599109649658
Validation loss: 2.066222010120269

Epoch: 6| Step: 8
Training loss: 1.5105421543121338
Validation loss: 2.11465795065767

Epoch: 6| Step: 9
Training loss: 1.1162580251693726
Validation loss: 2.0930111895325365

Epoch: 6| Step: 10
Training loss: 1.388427495956421
Validation loss: 2.1007910748963714

Epoch: 6| Step: 11
Training loss: 1.3341383934020996
Validation loss: 2.0503800876678957

Epoch: 6| Step: 12
Training loss: 2.1161081790924072
Validation loss: 2.115146122952943

Epoch: 6| Step: 13
Training loss: 2.1397571563720703
Validation loss: 2.078425761192076

Epoch: 493| Step: 0
Training loss: 1.1473331451416016
Validation loss: 2.078932087908509

Epoch: 6| Step: 1
Training loss: 1.3526462316513062
Validation loss: 2.122140642135374

Epoch: 6| Step: 2
Training loss: 1.2148586511611938
Validation loss: 2.1272065588223037

Epoch: 6| Step: 3
Training loss: 1.698760747909546
Validation loss: 2.0907633740414857

Epoch: 6| Step: 4
Training loss: 2.001370429992676
Validation loss: 2.1080857656335317

Epoch: 6| Step: 5
Training loss: 1.5667569637298584
Validation loss: 2.0620077322888117

Epoch: 6| Step: 6
Training loss: 0.8511680960655212
Validation loss: 2.124226326583534

Epoch: 6| Step: 7
Training loss: 2.0311026573181152
Validation loss: 2.073038255014727

Epoch: 6| Step: 8
Training loss: 2.099320650100708
Validation loss: 2.090346218437277

Epoch: 6| Step: 9
Training loss: 1.6064345836639404
Validation loss: 2.0747473701353996

Epoch: 6| Step: 10
Training loss: 1.4156806468963623
Validation loss: 2.0981731953159457

Epoch: 6| Step: 11
Training loss: 1.6371368169784546
Validation loss: 2.0979728852548907

Epoch: 6| Step: 12
Training loss: 1.1241507530212402
Validation loss: 2.090668744938348

Epoch: 6| Step: 13
Training loss: 1.3896230459213257
Validation loss: 2.0774393671302387

Epoch: 494| Step: 0
Training loss: 1.4772558212280273
Validation loss: 2.055860834736978

Epoch: 6| Step: 1
Training loss: 1.4757168292999268
Validation loss: 2.065040660160844

Epoch: 6| Step: 2
Training loss: 1.9049839973449707
Validation loss: 2.04952311259444

Epoch: 6| Step: 3
Training loss: 2.153636932373047
Validation loss: 2.022584899779289

Epoch: 6| Step: 4
Training loss: 0.7947800755500793
Validation loss: 2.0718000934969996

Epoch: 6| Step: 5
Training loss: 1.812129259109497
Validation loss: 2.051893885417651

Epoch: 6| Step: 6
Training loss: 1.4430370330810547
Validation loss: 2.040310857116535

Epoch: 6| Step: 7
Training loss: 1.064298391342163
Validation loss: 2.073827202602099

Epoch: 6| Step: 8
Training loss: 1.1355140209197998
Validation loss: 2.045879812650783

Epoch: 6| Step: 9
Training loss: 2.1830077171325684
Validation loss: 2.087281314275598

Epoch: 6| Step: 10
Training loss: 1.2849338054656982
Validation loss: 2.0722000214361374

Epoch: 6| Step: 11
Training loss: 0.7141094207763672
Validation loss: 2.0295375124100716

Epoch: 6| Step: 12
Training loss: 1.402388334274292
Validation loss: 2.0455052365538893

Epoch: 6| Step: 13
Training loss: 1.8586260080337524
Validation loss: 2.0714837402425785

Epoch: 495| Step: 0
Training loss: 1.091936707496643
Validation loss: 2.0814777446049515

Epoch: 6| Step: 1
Training loss: 1.5624969005584717
Validation loss: 2.0789686915695027

Epoch: 6| Step: 2
Training loss: 1.273353099822998
Validation loss: 2.0791529327310543

Epoch: 6| Step: 3
Training loss: 1.19464910030365
Validation loss: 2.1358358283196726

Epoch: 6| Step: 4
Training loss: 1.7803642749786377
Validation loss: 2.103046714618642

Epoch: 6| Step: 5
Training loss: 1.7847840785980225
Validation loss: 2.0929065840218657

Epoch: 6| Step: 6
Training loss: 1.265753149986267
Validation loss: 2.076908524318408

Epoch: 6| Step: 7
Training loss: 2.1290676593780518
Validation loss: 2.1260355031618507

Epoch: 6| Step: 8
Training loss: 1.1181576251983643
Validation loss: 2.120042818848805

Epoch: 6| Step: 9
Training loss: 1.7030160427093506
Validation loss: 2.055957617298249

Epoch: 6| Step: 10
Training loss: 1.1233313083648682
Validation loss: 2.047426723664807

Epoch: 6| Step: 11
Training loss: 2.076465129852295
Validation loss: 2.100625035583332

Epoch: 6| Step: 12
Training loss: 1.3701682090759277
Validation loss: 2.0649061587549027

Epoch: 6| Step: 13
Training loss: 1.4229017496109009
Validation loss: 2.0776237262192594

Epoch: 496| Step: 0
Training loss: 1.6950857639312744
Validation loss: 2.0908663503585325

Epoch: 6| Step: 1
Training loss: 1.1938600540161133
Validation loss: 2.0827472671385734

Epoch: 6| Step: 2
Training loss: 1.5531024932861328
Validation loss: 2.079511114346084

Epoch: 6| Step: 3
Training loss: 1.905416488647461
Validation loss: 2.0571154830276326

Epoch: 6| Step: 4
Training loss: 2.350111484527588
Validation loss: 2.0822030305862427

Epoch: 6| Step: 5
Training loss: 1.1732430458068848
Validation loss: 2.0355505456206617

Epoch: 6| Step: 6
Training loss: 1.8644545078277588
Validation loss: 2.0939552860875286

Epoch: 6| Step: 7
Training loss: 1.0129939317703247
Validation loss: 2.1089338359012397

Epoch: 6| Step: 8
Training loss: 1.6165250539779663
Validation loss: 2.1122402286016815

Epoch: 6| Step: 9
Training loss: 1.4006779193878174
Validation loss: 2.0846969927510908

Epoch: 6| Step: 10
Training loss: 1.5204222202301025
Validation loss: 2.0254666805267334

Epoch: 6| Step: 11
Training loss: 0.9333570599555969
Validation loss: 2.105231752959631

Epoch: 6| Step: 12
Training loss: 1.1716372966766357
Validation loss: 2.05161052878185

Epoch: 6| Step: 13
Training loss: 1.5530420541763306
Validation loss: 2.0867805827048516

Epoch: 497| Step: 0
Training loss: 1.9055722951889038
Validation loss: 2.156344690630513

Epoch: 6| Step: 1
Training loss: 1.6519215106964111
Validation loss: 2.1027706259040424

Epoch: 6| Step: 2
Training loss: 1.3952488899230957
Validation loss: 2.140401447972944

Epoch: 6| Step: 3
Training loss: 1.4943575859069824
Validation loss: 2.1357762159839755

Epoch: 6| Step: 4
Training loss: 1.0550026893615723
Validation loss: 2.1352305155928417

Epoch: 6| Step: 5
Training loss: 2.361351728439331
Validation loss: 2.1236177311148694

Epoch: 6| Step: 6
Training loss: 1.801835060119629
Validation loss: 2.1246888073541785

Epoch: 6| Step: 7
Training loss: 1.7487602233886719
Validation loss: 2.1217920164908133

Epoch: 6| Step: 8
Training loss: 0.8226478695869446
Validation loss: 2.114602506801646

Epoch: 6| Step: 9
Training loss: 1.341858148574829
Validation loss: 2.0721133985827045

Epoch: 6| Step: 10
Training loss: 1.1549888849258423
Validation loss: 2.0998154455615627

Epoch: 6| Step: 11
Training loss: 1.052689790725708
Validation loss: 2.093425231595193

Epoch: 6| Step: 12
Training loss: 1.4866786003112793
Validation loss: 2.076994953616973

Epoch: 6| Step: 13
Training loss: 1.840749740600586
Validation loss: 2.1000049396227767

Epoch: 498| Step: 0
Training loss: 1.8353800773620605
Validation loss: 2.088992487999701

Epoch: 6| Step: 1
Training loss: 1.7074060440063477
Validation loss: 2.06651149898447

Epoch: 6| Step: 2
Training loss: 1.8060009479522705
Validation loss: 2.0237271196098736

Epoch: 6| Step: 3
Training loss: 2.0665230751037598
Validation loss: 2.1129000635557276

Epoch: 6| Step: 4
Training loss: 1.8115636110305786
Validation loss: 2.0913516526581137

Epoch: 6| Step: 5
Training loss: 1.138427734375
Validation loss: 2.069023343824571

Epoch: 6| Step: 6
Training loss: 1.496950626373291
Validation loss: 2.0571807020454

Epoch: 6| Step: 7
Training loss: 1.5945557355880737
Validation loss: 2.0890510159154094

Epoch: 6| Step: 8
Training loss: 1.3382554054260254
Validation loss: 2.042618679743941

Epoch: 6| Step: 9
Training loss: 0.9415607452392578
Validation loss: 2.0446159506356842

Epoch: 6| Step: 10
Training loss: 1.3857650756835938
Validation loss: 2.0363174638440533

Epoch: 6| Step: 11
Training loss: 1.573758602142334
Validation loss: 2.0736154561401694

Epoch: 6| Step: 12
Training loss: 1.3639798164367676
Validation loss: 2.006599667251751

Epoch: 6| Step: 13
Training loss: 1.1189290285110474
Validation loss: 2.076184331729848

Epoch: 499| Step: 0
Training loss: 2.017503499984741
Validation loss: 2.0619922632812173

Epoch: 6| Step: 1
Training loss: 1.1926896572113037
Validation loss: 2.111516862787226

Epoch: 6| Step: 2
Training loss: 1.4620651006698608
Validation loss: 2.105647481897826

Epoch: 6| Step: 3
Training loss: 1.6846184730529785
Validation loss: 2.0902035056903796

Epoch: 6| Step: 4
Training loss: 1.1293714046478271
Validation loss: 2.0760124114251908

Epoch: 6| Step: 5
Training loss: 1.3424872159957886
Validation loss: 2.090057893465924

Epoch: 6| Step: 6
Training loss: 1.6494477987289429
Validation loss: 2.0914243523792555

Epoch: 6| Step: 7
Training loss: 1.6377789974212646
Validation loss: 2.1043478852959088

Epoch: 6| Step: 8
Training loss: 1.2535076141357422
Validation loss: 2.0901456853394866

Epoch: 6| Step: 9
Training loss: 1.5201267004013062
Validation loss: 2.053480020133398

Epoch: 6| Step: 10
Training loss: 1.5790021419525146
Validation loss: 2.066978008516373

Epoch: 6| Step: 11
Training loss: 1.3985440731048584
Validation loss: 2.090350768899405

Epoch: 6| Step: 12
Training loss: 1.2566006183624268
Validation loss: 2.072736568348382

Epoch: 6| Step: 13
Training loss: 1.8233076333999634
Validation loss: 2.0765496261658205

Epoch: 500| Step: 0
Training loss: 1.455140471458435
Validation loss: 2.015376232003653

Epoch: 6| Step: 1
Training loss: 1.495987892150879
Validation loss: 2.0505661990052912

Epoch: 6| Step: 2
Training loss: 1.650285243988037
Validation loss: 2.0832719008127847

Epoch: 6| Step: 3
Training loss: 1.5899357795715332
Validation loss: 2.040295946982599

Epoch: 6| Step: 4
Training loss: 0.777531623840332
Validation loss: 2.0755139076581566

Epoch: 6| Step: 5
Training loss: 1.3130441904067993
Validation loss: 2.047816753387451

Epoch: 6| Step: 6
Training loss: 2.5528388023376465
Validation loss: 2.071434344014814

Epoch: 6| Step: 7
Training loss: 0.8972539901733398
Validation loss: 2.072034307705459

Epoch: 6| Step: 8
Training loss: 1.8243497610092163
Validation loss: 2.07950504877234

Epoch: 6| Step: 9
Training loss: 1.2438311576843262
Validation loss: 2.08538556098938

Epoch: 6| Step: 10
Training loss: 1.583411455154419
Validation loss: 2.0742389091881375

Epoch: 6| Step: 11
Training loss: 0.6904329061508179
Validation loss: 2.108896770784932

Epoch: 6| Step: 12
Training loss: 1.8708410263061523
Validation loss: 2.1157138039988856

Epoch: 6| Step: 13
Training loss: 2.0170578956604004
Validation loss: 2.1410612149905135

Epoch: 501| Step: 0
Training loss: 1.0489178895950317
Validation loss: 2.0536465721745647

Epoch: 6| Step: 1
Training loss: 1.727243423461914
Validation loss: 2.090923252926078

Epoch: 6| Step: 2
Training loss: 0.8320778608322144
Validation loss: 2.0978321516385643

Epoch: 6| Step: 3
Training loss: 1.5611335039138794
Validation loss: 2.0926009519125826

Epoch: 6| Step: 4
Training loss: 1.4484184980392456
Validation loss: 2.1061949614555604

Epoch: 6| Step: 5
Training loss: 2.479884147644043
Validation loss: 2.1101760300256873

Epoch: 6| Step: 6
Training loss: 1.7823913097381592
Validation loss: 2.084825672129149

Epoch: 6| Step: 7
Training loss: 1.6470242738723755
Validation loss: 2.070633296043642

Epoch: 6| Step: 8
Training loss: 0.97281813621521
Validation loss: 2.0528994106477305

Epoch: 6| Step: 9
Training loss: 1.43522310256958
Validation loss: 2.066209032971372

Epoch: 6| Step: 10
Training loss: 1.5485700368881226
Validation loss: 2.084357742340334

Epoch: 6| Step: 11
Training loss: 1.2017006874084473
Validation loss: 2.0526120842144056

Epoch: 6| Step: 12
Training loss: 1.5633338689804077
Validation loss: 2.060881230138963

Epoch: 6| Step: 13
Training loss: 1.516701340675354
Validation loss: 2.0817852763719458

Epoch: 502| Step: 0
Training loss: 1.063035011291504
Validation loss: 2.050413111204742

Epoch: 6| Step: 1
Training loss: 1.1886898279190063
Validation loss: 2.1324151280105754

Epoch: 6| Step: 2
Training loss: 1.1535013914108276
Validation loss: 2.0581242333176317

Epoch: 6| Step: 3
Training loss: 2.2981319427490234
Validation loss: 2.070858068363641

Epoch: 6| Step: 4
Training loss: 1.7257695198059082
Validation loss: 2.0653958756436586

Epoch: 6| Step: 5
Training loss: 1.9278026819229126
Validation loss: 2.0708896703617548

Epoch: 6| Step: 6
Training loss: 1.3176838159561157
Validation loss: 2.099214969142791

Epoch: 6| Step: 7
Training loss: 2.3403127193450928
Validation loss: 2.0879940153450094

Epoch: 6| Step: 8
Training loss: 1.4621107578277588
Validation loss: 2.0814939173319007

Epoch: 6| Step: 9
Training loss: 1.5267274379730225
Validation loss: 2.0739684566374748

Epoch: 6| Step: 10
Training loss: 1.2030680179595947
Validation loss: 2.1012612030070317

Epoch: 6| Step: 11
Training loss: 1.200665831565857
Validation loss: 2.0705525516181864

Epoch: 6| Step: 12
Training loss: 1.0739002227783203
Validation loss: 2.082145226899014

Epoch: 6| Step: 13
Training loss: 1.1494941711425781
Validation loss: 2.013184711497317

Epoch: 503| Step: 0
Training loss: 1.3542098999023438
Validation loss: 2.0813133332037155

Epoch: 6| Step: 1
Training loss: 2.4142231941223145
Validation loss: 2.083681716713854

Epoch: 6| Step: 2
Training loss: 1.9752755165100098
Validation loss: 2.1090513711334555

Epoch: 6| Step: 3
Training loss: 0.9331846833229065
Validation loss: 2.082999780613889

Epoch: 6| Step: 4
Training loss: 1.959899663925171
Validation loss: 2.0996442558944866

Epoch: 6| Step: 5
Training loss: 1.3050005435943604
Validation loss: 2.0656086078254123

Epoch: 6| Step: 6
Training loss: 1.1548322439193726
Validation loss: 2.06617598636176

Epoch: 6| Step: 7
Training loss: 0.9404099583625793
Validation loss: 2.0550573871981714

Epoch: 6| Step: 8
Training loss: 1.5493226051330566
Validation loss: 2.0499745184375393

Epoch: 6| Step: 9
Training loss: 1.6214969158172607
Validation loss: 2.0581237282804263

Epoch: 6| Step: 10
Training loss: 0.777531623840332
Validation loss: 2.042676132212403

Epoch: 6| Step: 11
Training loss: 1.3387995958328247
Validation loss: 2.0493071412527435

Epoch: 6| Step: 12
Training loss: 1.783825397491455
Validation loss: 2.0842901506731586

Epoch: 6| Step: 13
Training loss: 1.2997902631759644
Validation loss: 2.087817645842029

Epoch: 504| Step: 0
Training loss: 1.3856465816497803
Validation loss: 2.087253778211532

Epoch: 6| Step: 1
Training loss: 1.3069243431091309
Validation loss: 2.009993783889278

Epoch: 6| Step: 2
Training loss: 1.3164684772491455
Validation loss: 2.041917931648993

Epoch: 6| Step: 3
Training loss: 1.8968400955200195
Validation loss: 2.114203791464529

Epoch: 6| Step: 4
Training loss: 2.268782615661621
Validation loss: 2.0921832540983796

Epoch: 6| Step: 5
Training loss: 1.3491911888122559
Validation loss: 2.101290697692543

Epoch: 6| Step: 6
Training loss: 1.3124202489852905
Validation loss: 2.070601870936732

Epoch: 6| Step: 7
Training loss: 1.2456443309783936
Validation loss: 2.1130693766378585

Epoch: 6| Step: 8
Training loss: 1.338441252708435
Validation loss: 2.0606992142174834

Epoch: 6| Step: 9
Training loss: 1.224384069442749
Validation loss: 2.1178143562809115

Epoch: 6| Step: 10
Training loss: 1.8614766597747803
Validation loss: 2.078243834998018

Epoch: 6| Step: 11
Training loss: 1.454542636871338
Validation loss: 2.0959047284177554

Epoch: 6| Step: 12
Training loss: 1.2018547058105469
Validation loss: 2.0792066999661025

Epoch: 6| Step: 13
Training loss: 1.6759686470031738
Validation loss: 2.1025352888209845

Epoch: 505| Step: 0
Training loss: 1.049786925315857
Validation loss: 2.1227647912117744

Epoch: 6| Step: 1
Training loss: 1.7983208894729614
Validation loss: 2.08319588117702

Epoch: 6| Step: 2
Training loss: 1.1346766948699951
Validation loss: 2.0976059616252942

Epoch: 6| Step: 3
Training loss: 1.5141351222991943
Validation loss: 2.099523457147742

Epoch: 6| Step: 4
Training loss: 0.8697103261947632
Validation loss: 2.0361289465299217

Epoch: 6| Step: 5
Training loss: 1.4720873832702637
Validation loss: 2.093320720939226

Epoch: 6| Step: 6
Training loss: 1.6304527521133423
Validation loss: 2.089185953140259

Epoch: 6| Step: 7
Training loss: 1.7451839447021484
Validation loss: 2.0471094885180072

Epoch: 6| Step: 8
Training loss: 1.8501126766204834
Validation loss: 2.0714260942192486

Epoch: 6| Step: 9
Training loss: 1.6146667003631592
Validation loss: 2.0823360566169984

Epoch: 6| Step: 10
Training loss: 1.26593816280365
Validation loss: 2.0601591217902397

Epoch: 6| Step: 11
Training loss: 1.769517421722412
Validation loss: 2.101232356922601

Epoch: 6| Step: 12
Training loss: 1.6672958135604858
Validation loss: 2.0774711755014237

Epoch: 6| Step: 13
Training loss: 0.7435200214385986
Validation loss: 2.0914856464632097

Epoch: 506| Step: 0
Training loss: 1.5403417348861694
Validation loss: 2.0857413225276495

Epoch: 6| Step: 1
Training loss: 0.8968866467475891
Validation loss: 2.069122081161827

Epoch: 6| Step: 2
Training loss: 1.1399729251861572
Validation loss: 2.13823962724337

Epoch: 6| Step: 3
Training loss: 1.9902942180633545
Validation loss: 2.0897226154163318

Epoch: 6| Step: 4
Training loss: 1.6657931804656982
Validation loss: 2.1069013469962665

Epoch: 6| Step: 5
Training loss: 2.202695608139038
Validation loss: 2.102624603497085

Epoch: 6| Step: 6
Training loss: 1.3638858795166016
Validation loss: 2.158331576214042

Epoch: 6| Step: 7
Training loss: 1.23716402053833
Validation loss: 2.1183804670969644

Epoch: 6| Step: 8
Training loss: 1.3074662685394287
Validation loss: 2.0819870861627723

Epoch: 6| Step: 9
Training loss: 1.134432077407837
Validation loss: 2.1088425882401003

Epoch: 6| Step: 10
Training loss: 1.080643653869629
Validation loss: 2.119614824171989

Epoch: 6| Step: 11
Training loss: 1.3524932861328125
Validation loss: 2.1203229606792493

Epoch: 6| Step: 12
Training loss: 1.7871485948562622
Validation loss: 2.04314850735408

Epoch: 6| Step: 13
Training loss: 2.224351644515991
Validation loss: 2.0388211075977614

Epoch: 507| Step: 0
Training loss: 1.5719313621520996
Validation loss: 2.0947197509068314

Epoch: 6| Step: 1
Training loss: 1.645442008972168
Validation loss: 2.074951269293344

Epoch: 6| Step: 2
Training loss: 1.203611135482788
Validation loss: 2.0525246935506023

Epoch: 6| Step: 3
Training loss: 1.9487261772155762
Validation loss: 2.056072868326659

Epoch: 6| Step: 4
Training loss: 1.9406135082244873
Validation loss: 2.0512673547191005

Epoch: 6| Step: 5
Training loss: 1.8251845836639404
Validation loss: 2.077860314358947

Epoch: 6| Step: 6
Training loss: 1.5303521156311035
Validation loss: 2.0842393508521457

Epoch: 6| Step: 7
Training loss: 1.7495672702789307
Validation loss: 2.069510882900607

Epoch: 6| Step: 8
Training loss: 1.1750308275222778
Validation loss: 2.065563763341596

Epoch: 6| Step: 9
Training loss: 1.0253055095672607
Validation loss: 2.1117403340596024

Epoch: 6| Step: 10
Training loss: 1.63695228099823
Validation loss: 2.0584060312599264

Epoch: 6| Step: 11
Training loss: 1.4476299285888672
Validation loss: 2.056889427605496

Epoch: 6| Step: 12
Training loss: 1.0478264093399048
Validation loss: 2.10391463259215

Epoch: 6| Step: 13
Training loss: 0.9511225819587708
Validation loss: 2.0932509976048626

Epoch: 508| Step: 0
Training loss: 1.3594892024993896
Validation loss: 2.049353781566825

Epoch: 6| Step: 1
Training loss: 1.2079403400421143
Validation loss: 2.110919528110053

Epoch: 6| Step: 2
Training loss: 1.3941007852554321
Validation loss: 2.1001695971335135

Epoch: 6| Step: 3
Training loss: 1.2714219093322754
Validation loss: 2.11098160025894

Epoch: 6| Step: 4
Training loss: 2.106786012649536
Validation loss: 2.058007574850513

Epoch: 6| Step: 5
Training loss: 1.8144789934158325
Validation loss: 2.04367567646888

Epoch: 6| Step: 6
Training loss: 0.9557175636291504
Validation loss: 2.0349439754280993

Epoch: 6| Step: 7
Training loss: 2.467306137084961
Validation loss: 2.104379064293318

Epoch: 6| Step: 8
Training loss: 1.2422537803649902
Validation loss: 2.0295966645722747

Epoch: 6| Step: 9
Training loss: 1.5768388509750366
Validation loss: 2.083727841736168

Epoch: 6| Step: 10
Training loss: 1.4453604221343994
Validation loss: 2.074193936522289

Epoch: 6| Step: 11
Training loss: 0.9431599378585815
Validation loss: 2.0842367808024087

Epoch: 6| Step: 12
Training loss: 1.666229486465454
Validation loss: 2.0588784038379626

Epoch: 6| Step: 13
Training loss: 1.3497445583343506
Validation loss: 2.139024597342296

Epoch: 509| Step: 0
Training loss: 1.4906315803527832
Validation loss: 2.112195045717301

Epoch: 6| Step: 1
Training loss: 1.4462285041809082
Validation loss: 2.059454748707433

Epoch: 6| Step: 2
Training loss: 1.5504372119903564
Validation loss: 2.1017480281091507

Epoch: 6| Step: 3
Training loss: 1.2488579750061035
Validation loss: 2.0672254254741054

Epoch: 6| Step: 4
Training loss: 1.1558878421783447
Validation loss: 2.07839854942855

Epoch: 6| Step: 5
Training loss: 1.6234562397003174
Validation loss: 2.098747617454939

Epoch: 6| Step: 6
Training loss: 1.705894112586975
Validation loss: 2.122825022666685

Epoch: 6| Step: 7
Training loss: 1.663585901260376
Validation loss: 2.0859662537933676

Epoch: 6| Step: 8
Training loss: 1.829066276550293
Validation loss: 2.083287118583597

Epoch: 6| Step: 9
Training loss: 1.052241563796997
Validation loss: 2.079491892168599

Epoch: 6| Step: 10
Training loss: 1.6210687160491943
Validation loss: 2.0458323109534478

Epoch: 6| Step: 11
Training loss: 1.5584650039672852
Validation loss: 2.071210589460147

Epoch: 6| Step: 12
Training loss: 1.3604236841201782
Validation loss: 2.0654574312189573

Epoch: 6| Step: 13
Training loss: 0.8742305040359497
Validation loss: 2.117873082878769

Epoch: 510| Step: 0
Training loss: 1.4361460208892822
Validation loss: 2.0388073152111423

Epoch: 6| Step: 1
Training loss: 0.9850403070449829
Validation loss: 2.0613745950883433

Epoch: 6| Step: 2
Training loss: 1.9699355363845825
Validation loss: 2.061255997227084

Epoch: 6| Step: 3
Training loss: 1.0836275815963745
Validation loss: 2.0946235554192656

Epoch: 6| Step: 4
Training loss: 1.4234048128128052
Validation loss: 2.087649554334661

Epoch: 6| Step: 5
Training loss: 1.5803769826889038
Validation loss: 2.053562820598643

Epoch: 6| Step: 6
Training loss: 1.3967634439468384
Validation loss: 2.1085996140715895

Epoch: 6| Step: 7
Training loss: 0.9677902460098267
Validation loss: 2.0959962016792706

Epoch: 6| Step: 8
Training loss: 1.3497556447982788
Validation loss: 2.0625742199600383

Epoch: 6| Step: 9
Training loss: 1.5051085948944092
Validation loss: 2.0607335003473426

Epoch: 6| Step: 10
Training loss: 2.025453567504883
Validation loss: 2.076185113640242

Epoch: 6| Step: 11
Training loss: 1.5788731575012207
Validation loss: 2.1099579577804892

Epoch: 6| Step: 12
Training loss: 1.5743234157562256
Validation loss: 2.1101956162401425

Epoch: 6| Step: 13
Training loss: 1.2501158714294434
Validation loss: 2.090478676621632

Epoch: 511| Step: 0
Training loss: 1.080075740814209
Validation loss: 2.0729758098561275

Epoch: 6| Step: 1
Training loss: 1.3195523023605347
Validation loss: 2.1122895145928986

Epoch: 6| Step: 2
Training loss: 1.7006375789642334
Validation loss: 2.095947604025564

Epoch: 6| Step: 3
Training loss: 1.3212523460388184
Validation loss: 2.0897150090945664

Epoch: 6| Step: 4
Training loss: 1.8668177127838135
Validation loss: 2.073494724048081

Epoch: 6| Step: 5
Training loss: 1.4047188758850098
Validation loss: 2.105184087189295

Epoch: 6| Step: 6
Training loss: 1.4260494709014893
Validation loss: 2.0532135860894316

Epoch: 6| Step: 7
Training loss: 0.923001766204834
Validation loss: 2.070195121149863

Epoch: 6| Step: 8
Training loss: 1.573244571685791
Validation loss: 2.1043290733009257

Epoch: 6| Step: 9
Training loss: 2.5209298133850098
Validation loss: 2.107475479443868

Epoch: 6| Step: 10
Training loss: 0.8673583269119263
Validation loss: 2.077260043031426

Epoch: 6| Step: 11
Training loss: 1.778944969177246
Validation loss: 2.0746375796615437

Epoch: 6| Step: 12
Training loss: 1.216137409210205
Validation loss: 2.0535489410482426

Epoch: 6| Step: 13
Training loss: 1.9511727094650269
Validation loss: 2.0658444153365267

Epoch: 512| Step: 0
Training loss: 1.800244688987732
Validation loss: 2.0898750879431285

Epoch: 6| Step: 1
Training loss: 1.3499705791473389
Validation loss: 2.0618347711460565

Epoch: 6| Step: 2
Training loss: 1.1440497636795044
Validation loss: 2.0604525061063867

Epoch: 6| Step: 3
Training loss: 1.4640196561813354
Validation loss: 2.04619949863803

Epoch: 6| Step: 4
Training loss: 1.3652437925338745
Validation loss: 2.0692756304176907

Epoch: 6| Step: 5
Training loss: 1.457735538482666
Validation loss: 2.0845281462515555

Epoch: 6| Step: 6
Training loss: 2.0286879539489746
Validation loss: 2.0534002216913367

Epoch: 6| Step: 7
Training loss: 2.720773696899414
Validation loss: 2.021151218363034

Epoch: 6| Step: 8
Training loss: 1.338019847869873
Validation loss: 2.054988461156045

Epoch: 6| Step: 9
Training loss: 0.7231331467628479
Validation loss: 2.109006145949005

Epoch: 6| Step: 10
Training loss: 1.1198093891143799
Validation loss: 2.060990652730388

Epoch: 6| Step: 11
Training loss: 1.6553380489349365
Validation loss: 2.061448730448241

Epoch: 6| Step: 12
Training loss: 1.4149285554885864
Validation loss: 2.091250201707245

Epoch: 6| Step: 13
Training loss: 1.2002050876617432
Validation loss: 2.063543572220751

Epoch: 513| Step: 0
Training loss: 1.2868924140930176
Validation loss: 2.084544115169074

Epoch: 6| Step: 1
Training loss: 1.6724745035171509
Validation loss: 2.0962120051025064

Epoch: 6| Step: 2
Training loss: 1.4925117492675781
Validation loss: 2.113240338140918

Epoch: 6| Step: 3
Training loss: 0.9600974321365356
Validation loss: 2.0706401883914904

Epoch: 6| Step: 4
Training loss: 1.4180246591567993
Validation loss: 2.1479537358847995

Epoch: 6| Step: 5
Training loss: 1.7866562604904175
Validation loss: 2.0949955755664456

Epoch: 6| Step: 6
Training loss: 1.8085192441940308
Validation loss: 2.071307489948888

Epoch: 6| Step: 7
Training loss: 1.8012512922286987
Validation loss: 2.0902018136875604

Epoch: 6| Step: 8
Training loss: 1.032294511795044
Validation loss: 2.132522947044783

Epoch: 6| Step: 9
Training loss: 1.428460955619812
Validation loss: 2.1316497838625343

Epoch: 6| Step: 10
Training loss: 1.7847130298614502
Validation loss: 2.0831994395102225

Epoch: 6| Step: 11
Training loss: 1.4497058391571045
Validation loss: 2.0747977828466766

Epoch: 6| Step: 12
Training loss: 1.4259237051010132
Validation loss: 2.0872874875222482

Epoch: 6| Step: 13
Training loss: 0.7258415818214417
Validation loss: 2.0936675661353656

Epoch: 514| Step: 0
Training loss: 1.5815391540527344
Validation loss: 2.015252629915873

Epoch: 6| Step: 1
Training loss: 1.1774194240570068
Validation loss: 2.044977749547651

Epoch: 6| Step: 2
Training loss: 1.4643458127975464
Validation loss: 2.0775327631222305

Epoch: 6| Step: 3
Training loss: 0.8498212695121765
Validation loss: 2.0887212214931363

Epoch: 6| Step: 4
Training loss: 1.5840786695480347
Validation loss: 2.0335474321919103

Epoch: 6| Step: 5
Training loss: 1.549099326133728
Validation loss: 2.0559854456173476

Epoch: 6| Step: 6
Training loss: 1.691409707069397
Validation loss: 2.037776239456669

Epoch: 6| Step: 7
Training loss: 1.801571249961853
Validation loss: 2.0427613027634157

Epoch: 6| Step: 8
Training loss: 1.1944016218185425
Validation loss: 2.0313941432583715

Epoch: 6| Step: 9
Training loss: 0.7013352513313293
Validation loss: 2.1091458797454834

Epoch: 6| Step: 10
Training loss: 1.8884363174438477
Validation loss: 2.102011913894325

Epoch: 6| Step: 11
Training loss: 1.5886187553405762
Validation loss: 2.0424296291925574

Epoch: 6| Step: 12
Training loss: 1.6086616516113281
Validation loss: 2.0023098658489924

Epoch: 6| Step: 13
Training loss: 1.7648329734802246
Validation loss: 2.057353742661015

Epoch: 515| Step: 0
Training loss: 1.76251220703125
Validation loss: 2.030420413581274

Epoch: 6| Step: 1
Training loss: 1.7126719951629639
Validation loss: 2.075726306566628

Epoch: 6| Step: 2
Training loss: 1.2601748704910278
Validation loss: 2.103401214845719

Epoch: 6| Step: 3
Training loss: 1.6101475954055786
Validation loss: 2.0777832897760535

Epoch: 6| Step: 4
Training loss: 1.1681591272354126
Validation loss: 2.0941553269663165

Epoch: 6| Step: 5
Training loss: 1.0643619298934937
Validation loss: 2.0315161802435435

Epoch: 6| Step: 6
Training loss: 1.2751553058624268
Validation loss: 2.0815050550686416

Epoch: 6| Step: 7
Training loss: 2.2900197505950928
Validation loss: 2.0892272892818657

Epoch: 6| Step: 8
Training loss: 1.3818440437316895
Validation loss: 2.0576267703886955

Epoch: 6| Step: 9
Training loss: 1.3553721904754639
Validation loss: 2.0187543912600447

Epoch: 6| Step: 10
Training loss: 1.8466535806655884
Validation loss: 2.0593139548455515

Epoch: 6| Step: 11
Training loss: 1.3807575702667236
Validation loss: 2.0146148653440576

Epoch: 6| Step: 12
Training loss: 0.8902924656867981
Validation loss: 2.0326066440151584

Epoch: 6| Step: 13
Training loss: 0.874731719493866
Validation loss: 2.0455589525161253

Epoch: 516| Step: 0
Training loss: 1.0912632942199707
Validation loss: 2.05478306739561

Epoch: 6| Step: 1
Training loss: 1.4124913215637207
Validation loss: 2.0387531070299048

Epoch: 6| Step: 2
Training loss: 1.2520898580551147
Validation loss: 2.0948227669603083

Epoch: 6| Step: 3
Training loss: 1.3295255899429321
Validation loss: 2.03291404375466

Epoch: 6| Step: 4
Training loss: 1.109557867050171
Validation loss: 2.0437689288969962

Epoch: 6| Step: 5
Training loss: 1.4864695072174072
Validation loss: 2.1210592818516556

Epoch: 6| Step: 6
Training loss: 2.2335267066955566
Validation loss: 2.0403818507348337

Epoch: 6| Step: 7
Training loss: 1.9467681646347046
Validation loss: 2.081793964550059

Epoch: 6| Step: 8
Training loss: 1.208088994026184
Validation loss: 2.0678694299472276

Epoch: 6| Step: 9
Training loss: 1.6654565334320068
Validation loss: 2.0721402604092836

Epoch: 6| Step: 10
Training loss: 1.5851377248764038
Validation loss: 2.0801136186045985

Epoch: 6| Step: 11
Training loss: 1.0256381034851074
Validation loss: 2.0732290949872745

Epoch: 6| Step: 12
Training loss: 1.1944880485534668
Validation loss: 2.055214499914518

Epoch: 6| Step: 13
Training loss: 1.4888218641281128
Validation loss: 2.047643120570849

Epoch: 517| Step: 0
Training loss: 1.2897109985351562
Validation loss: 2.071393305255521

Epoch: 6| Step: 1
Training loss: 1.0062388181686401
Validation loss: 2.113658571756014

Epoch: 6| Step: 2
Training loss: 1.6009865999221802
Validation loss: 2.063768381713539

Epoch: 6| Step: 3
Training loss: 1.2550458908081055
Validation loss: 2.0490987916146555

Epoch: 6| Step: 4
Training loss: 1.2481741905212402
Validation loss: 2.0802249139355076

Epoch: 6| Step: 5
Training loss: 1.6284101009368896
Validation loss: 2.041422825987621

Epoch: 6| Step: 6
Training loss: 1.569732666015625
Validation loss: 2.0412665451726606

Epoch: 6| Step: 7
Training loss: 1.1832809448242188
Validation loss: 2.0653361146168043

Epoch: 6| Step: 8
Training loss: 1.7377173900604248
Validation loss: 2.1008083243523874

Epoch: 6| Step: 9
Training loss: 1.1600511074066162
Validation loss: 2.071020926198652

Epoch: 6| Step: 10
Training loss: 1.6874055862426758
Validation loss: 2.0520006405409945

Epoch: 6| Step: 11
Training loss: 2.5371294021606445
Validation loss: 2.01719327639508

Epoch: 6| Step: 12
Training loss: 1.109968900680542
Validation loss: 2.0720824849221016

Epoch: 6| Step: 13
Training loss: 1.7110086679458618
Validation loss: 2.0717083407986547

Epoch: 518| Step: 0
Training loss: 1.3313530683517456
Validation loss: 2.035289115803216

Epoch: 6| Step: 1
Training loss: 1.61479914188385
Validation loss: 2.0709610267352034

Epoch: 6| Step: 2
Training loss: 1.468690276145935
Validation loss: 2.048842619824153

Epoch: 6| Step: 3
Training loss: 0.8382286429405212
Validation loss: 2.060962256564889

Epoch: 6| Step: 4
Training loss: 1.3208503723144531
Validation loss: 2.0522750564800796

Epoch: 6| Step: 5
Training loss: 1.855545997619629
Validation loss: 2.138241534592003

Epoch: 6| Step: 6
Training loss: 1.6443991661071777
Validation loss: 2.0474213451467533

Epoch: 6| Step: 7
Training loss: 1.5652902126312256
Validation loss: 2.09564644546919

Epoch: 6| Step: 8
Training loss: 1.1087839603424072
Validation loss: 2.0847762528286187

Epoch: 6| Step: 9
Training loss: 1.2424795627593994
Validation loss: 2.055665482756912

Epoch: 6| Step: 10
Training loss: 1.545393466949463
Validation loss: 2.0361314255704164

Epoch: 6| Step: 11
Training loss: 1.8249702453613281
Validation loss: 2.0707379976908364

Epoch: 6| Step: 12
Training loss: 1.068994402885437
Validation loss: 2.0171389092681227

Epoch: 6| Step: 13
Training loss: 1.9879932403564453
Validation loss: 2.0535156419200282

Epoch: 519| Step: 0
Training loss: 1.6094930171966553
Validation loss: 2.046176838618453

Epoch: 6| Step: 1
Training loss: 1.7449380159378052
Validation loss: 2.069809703416722

Epoch: 6| Step: 2
Training loss: 2.1070151329040527
Validation loss: 2.039301444125432

Epoch: 6| Step: 3
Training loss: 0.7550947666168213
Validation loss: 2.0476457765025478

Epoch: 6| Step: 4
Training loss: 1.1508092880249023
Validation loss: 2.0733598791142946

Epoch: 6| Step: 5
Training loss: 1.3893237113952637
Validation loss: 2.060962241183045

Epoch: 6| Step: 6
Training loss: 1.2718780040740967
Validation loss: 2.041084143423265

Epoch: 6| Step: 7
Training loss: 1.8095276355743408
Validation loss: 2.068477999779486

Epoch: 6| Step: 8
Training loss: 1.3640714883804321
Validation loss: 2.052371125067434

Epoch: 6| Step: 9
Training loss: 1.9639019966125488
Validation loss: 2.1041367643622944

Epoch: 6| Step: 10
Training loss: 0.6492630243301392
Validation loss: 2.056955652852212

Epoch: 6| Step: 11
Training loss: 1.700783371925354
Validation loss: 2.0876037177219184

Epoch: 6| Step: 12
Training loss: 1.0996320247650146
Validation loss: 2.071664817871586

Epoch: 6| Step: 13
Training loss: 1.5024925470352173
Validation loss: 2.0696211796934887

Epoch: 520| Step: 0
Training loss: 1.7067536115646362
Validation loss: 2.076004889703566

Epoch: 6| Step: 1
Training loss: 1.1599082946777344
Validation loss: 2.0461192464315765

Epoch: 6| Step: 2
Training loss: 1.4165070056915283
Validation loss: 2.0794106170695317

Epoch: 6| Step: 3
Training loss: 1.2446753978729248
Validation loss: 2.0544932298762824

Epoch: 6| Step: 4
Training loss: 1.4802429676055908
Validation loss: 2.1017419484353836

Epoch: 6| Step: 5
Training loss: 1.103672981262207
Validation loss: 2.014960168510355

Epoch: 6| Step: 6
Training loss: 1.3250079154968262
Validation loss: 2.083797767598142

Epoch: 6| Step: 7
Training loss: 1.2259178161621094
Validation loss: 1.9993313051039172

Epoch: 6| Step: 8
Training loss: 1.819197654724121
Validation loss: 2.067702685633013

Epoch: 6| Step: 9
Training loss: 1.2950905561447144
Validation loss: 2.044487032839047

Epoch: 6| Step: 10
Training loss: 1.6495211124420166
Validation loss: 2.042974784810056

Epoch: 6| Step: 11
Training loss: 2.573638439178467
Validation loss: 2.036460575237069

Epoch: 6| Step: 12
Training loss: 1.2801296710968018
Validation loss: 2.0563082605279903

Epoch: 6| Step: 13
Training loss: 1.0909817218780518
Validation loss: 2.0914403674423054

Epoch: 521| Step: 0
Training loss: 1.4603596925735474
Validation loss: 2.094779864434273

Epoch: 6| Step: 1
Training loss: 1.4818263053894043
Validation loss: 2.094626244678292

Epoch: 6| Step: 2
Training loss: 2.115334987640381
Validation loss: 2.0497935882178684

Epoch: 6| Step: 3
Training loss: 1.6022484302520752
Validation loss: 2.118744247703142

Epoch: 6| Step: 4
Training loss: 1.430171012878418
Validation loss: 2.086687539213447

Epoch: 6| Step: 5
Training loss: 1.3314203023910522
Validation loss: 2.0556262334187827

Epoch: 6| Step: 6
Training loss: 0.9991555213928223
Validation loss: 2.1008376126648276

Epoch: 6| Step: 7
Training loss: 1.877630591392517
Validation loss: 2.110094752362979

Epoch: 6| Step: 8
Training loss: 1.9404423236846924
Validation loss: 2.1103201707204184

Epoch: 6| Step: 9
Training loss: 0.920861005783081
Validation loss: 2.0936314444388113

Epoch: 6| Step: 10
Training loss: 1.7836531400680542
Validation loss: 2.1051122193695395

Epoch: 6| Step: 11
Training loss: 1.0077242851257324
Validation loss: 2.062303323899546

Epoch: 6| Step: 12
Training loss: 1.3450195789337158
Validation loss: 2.060324089501494

Epoch: 6| Step: 13
Training loss: 0.8364361524581909
Validation loss: 2.050982573980926

Epoch: 522| Step: 0
Training loss: 0.5911673307418823
Validation loss: 2.0886024505861345

Epoch: 6| Step: 1
Training loss: 1.346585988998413
Validation loss: 2.0531401326579433

Epoch: 6| Step: 2
Training loss: 1.1394565105438232
Validation loss: 2.0298501599219536

Epoch: 6| Step: 3
Training loss: 1.5927460193634033
Validation loss: 2.0954509178797402

Epoch: 6| Step: 4
Training loss: 1.335972547531128
Validation loss: 2.0569476094297183

Epoch: 6| Step: 5
Training loss: 2.0432872772216797
Validation loss: 2.0948876283502065

Epoch: 6| Step: 6
Training loss: 1.7825067043304443
Validation loss: 2.020427046283599

Epoch: 6| Step: 7
Training loss: 1.1889251470565796
Validation loss: 2.0315242416115216

Epoch: 6| Step: 8
Training loss: 1.6785719394683838
Validation loss: 2.0433669923454203

Epoch: 6| Step: 9
Training loss: 0.8559440970420837
Validation loss: 2.0896326367573073

Epoch: 6| Step: 10
Training loss: 1.588318943977356
Validation loss: 2.0796605387041645

Epoch: 6| Step: 11
Training loss: 0.8356174230575562
Validation loss: 2.048457826337507

Epoch: 6| Step: 12
Training loss: 1.856863021850586
Validation loss: 2.074735636352211

Epoch: 6| Step: 13
Training loss: 3.2651655673980713
Validation loss: 2.090876163974885

Epoch: 523| Step: 0
Training loss: 1.9397621154785156
Validation loss: 2.0617489955758534

Epoch: 6| Step: 1
Training loss: 1.3890011310577393
Validation loss: 2.0225378915827763

Epoch: 6| Step: 2
Training loss: 1.1360975503921509
Validation loss: 2.060614561521879

Epoch: 6| Step: 3
Training loss: 1.2729772329330444
Validation loss: 2.0750556440763575

Epoch: 6| Step: 4
Training loss: 1.328974723815918
Validation loss: 2.0670076557385024

Epoch: 6| Step: 5
Training loss: 1.236283779144287
Validation loss: 2.0882833003997803

Epoch: 6| Step: 6
Training loss: 1.6168491840362549
Validation loss: 2.080607032263151

Epoch: 6| Step: 7
Training loss: 1.2072653770446777
Validation loss: 2.0936281732333604

Epoch: 6| Step: 8
Training loss: 1.7126803398132324
Validation loss: 2.050861571424751

Epoch: 6| Step: 9
Training loss: 2.011660099029541
Validation loss: 2.054385413405716

Epoch: 6| Step: 10
Training loss: 1.246748685836792
Validation loss: 2.053192336072204

Epoch: 6| Step: 11
Training loss: 1.4828460216522217
Validation loss: 2.0760679116813083

Epoch: 6| Step: 12
Training loss: 1.6516895294189453
Validation loss: 2.0737247620859454

Epoch: 6| Step: 13
Training loss: 1.3570493459701538
Validation loss: 2.0698167431739067

Epoch: 524| Step: 0
Training loss: 1.680267572402954
Validation loss: 2.0565597216288247

Epoch: 6| Step: 1
Training loss: 1.0535030364990234
Validation loss: 2.1189656334538616

Epoch: 6| Step: 2
Training loss: 1.0078518390655518
Validation loss: 2.0980417010604695

Epoch: 6| Step: 3
Training loss: 1.8189282417297363
Validation loss: 2.0756756080094205

Epoch: 6| Step: 4
Training loss: 1.5361419916152954
Validation loss: 2.141700686946992

Epoch: 6| Step: 5
Training loss: 1.8596805334091187
Validation loss: 2.0829076702876756

Epoch: 6| Step: 6
Training loss: 1.681993007659912
Validation loss: 2.072236568697037

Epoch: 6| Step: 7
Training loss: 1.2948803901672363
Validation loss: 2.0889556074655182

Epoch: 6| Step: 8
Training loss: 1.433864951133728
Validation loss: 2.019185685342358

Epoch: 6| Step: 9
Training loss: 1.1309003829956055
Validation loss: 2.035693330149497

Epoch: 6| Step: 10
Training loss: 1.911064863204956
Validation loss: 2.0874548599284184

Epoch: 6| Step: 11
Training loss: 0.6593271493911743
Validation loss: 2.0506956782392276

Epoch: 6| Step: 12
Training loss: 2.016204357147217
Validation loss: 2.046423522374963

Epoch: 6| Step: 13
Training loss: 1.2705278396606445
Validation loss: 2.0471675754875265

Epoch: 525| Step: 0
Training loss: 1.063718318939209
Validation loss: 2.0677976915913243

Epoch: 6| Step: 1
Training loss: 1.6546486616134644
Validation loss: 2.054945763721261

Epoch: 6| Step: 2
Training loss: 1.6004281044006348
Validation loss: 2.013842841630341

Epoch: 6| Step: 3
Training loss: 1.436931848526001
Validation loss: 2.102723043452027

Epoch: 6| Step: 4
Training loss: 1.257921814918518
Validation loss: 2.1073187910100466

Epoch: 6| Step: 5
Training loss: 1.052950143814087
Validation loss: 2.0860504770791657

Epoch: 6| Step: 6
Training loss: 1.2545911073684692
Validation loss: 2.021554576453342

Epoch: 6| Step: 7
Training loss: 1.1015841960906982
Validation loss: 2.0875329740585817

Epoch: 6| Step: 8
Training loss: 1.6201348304748535
Validation loss: 2.0950004349472704

Epoch: 6| Step: 9
Training loss: 1.7724329233169556
Validation loss: 2.013709406698904

Epoch: 6| Step: 10
Training loss: 1.524510145187378
Validation loss: 2.084102140959873

Epoch: 6| Step: 11
Training loss: 1.7723066806793213
Validation loss: 2.0487179089617986

Epoch: 6| Step: 12
Training loss: 1.414064645767212
Validation loss: 2.1025909377682592

Epoch: 6| Step: 13
Training loss: 1.0078039169311523
Validation loss: 2.0713437834093646

Epoch: 526| Step: 0
Training loss: 1.490789771080017
Validation loss: 2.0784791797719975

Epoch: 6| Step: 1
Training loss: 1.2259509563446045
Validation loss: 2.053946189982917

Epoch: 6| Step: 2
Training loss: 1.2708778381347656
Validation loss: 2.067860116240799

Epoch: 6| Step: 3
Training loss: 1.7399275302886963
Validation loss: 2.046595932334982

Epoch: 6| Step: 4
Training loss: 1.8022515773773193
Validation loss: 2.079721038059522

Epoch: 6| Step: 5
Training loss: 1.6002180576324463
Validation loss: 2.030748439091508

Epoch: 6| Step: 6
Training loss: 1.25571870803833
Validation loss: 2.030262472809002

Epoch: 6| Step: 7
Training loss: 1.7308919429779053
Validation loss: 2.071891277067123

Epoch: 6| Step: 8
Training loss: 1.177612066268921
Validation loss: 2.045381792130009

Epoch: 6| Step: 9
Training loss: 1.9041608572006226
Validation loss: 2.0686699780084754

Epoch: 6| Step: 10
Training loss: 1.1603078842163086
Validation loss: 2.058902120077482

Epoch: 6| Step: 11
Training loss: 1.6401768922805786
Validation loss: 2.030342250741938

Epoch: 6| Step: 12
Training loss: 1.222998857498169
Validation loss: 2.0393463193729358

Epoch: 6| Step: 13
Training loss: 1.1126117706298828
Validation loss: 2.0907020402211014

Epoch: 527| Step: 0
Training loss: 0.93593430519104
Validation loss: 2.080383212335648

Epoch: 6| Step: 1
Training loss: 1.2080211639404297
Validation loss: 2.0656443693304576

Epoch: 6| Step: 2
Training loss: 1.4410629272460938
Validation loss: 2.0714035905817503

Epoch: 6| Step: 3
Training loss: 1.0513272285461426
Validation loss: 2.111814614265196

Epoch: 6| Step: 4
Training loss: 1.0579581260681152
Validation loss: 2.048640925397155

Epoch: 6| Step: 5
Training loss: 1.3300236463546753
Validation loss: 2.0270484673079623

Epoch: 6| Step: 6
Training loss: 1.3579480648040771
Validation loss: 2.113302949936159

Epoch: 6| Step: 7
Training loss: 1.0268521308898926
Validation loss: 2.0805746586092058

Epoch: 6| Step: 8
Training loss: 2.1649203300476074
Validation loss: 2.0941397400312525

Epoch: 6| Step: 9
Training loss: 2.3239667415618896
Validation loss: 2.084815130438856

Epoch: 6| Step: 10
Training loss: 1.6550978422164917
Validation loss: 2.086708585421244

Epoch: 6| Step: 11
Training loss: 1.6990656852722168
Validation loss: 2.1233300675628004

Epoch: 6| Step: 12
Training loss: 1.2086957693099976
Validation loss: 2.1236698191653014

Epoch: 6| Step: 13
Training loss: 2.3209919929504395
Validation loss: 2.1370163271504063

Epoch: 528| Step: 0
Training loss: 1.6942038536071777
Validation loss: 2.078989303240212

Epoch: 6| Step: 1
Training loss: 0.8023931980133057
Validation loss: 2.0355427675349738

Epoch: 6| Step: 2
Training loss: 1.3415805101394653
Validation loss: 2.0668883772306543

Epoch: 6| Step: 3
Training loss: 0.9076594114303589
Validation loss: 2.0573095121691303

Epoch: 6| Step: 4
Training loss: 1.2275431156158447
Validation loss: 2.0543718402103712

Epoch: 6| Step: 5
Training loss: 1.7955238819122314
Validation loss: 2.057535627836822

Epoch: 6| Step: 6
Training loss: 1.1037932634353638
Validation loss: 2.0398639863537205

Epoch: 6| Step: 7
Training loss: 1.285036325454712
Validation loss: 2.068604830772646

Epoch: 6| Step: 8
Training loss: 1.8421604633331299
Validation loss: 2.0609689797124555

Epoch: 6| Step: 9
Training loss: 1.7324965000152588
Validation loss: 2.069687686940675

Epoch: 6| Step: 10
Training loss: 1.0126503705978394
Validation loss: 2.063078054817774

Epoch: 6| Step: 11
Training loss: 2.5460774898529053
Validation loss: 2.0713408095862276

Epoch: 6| Step: 12
Training loss: 1.4956578016281128
Validation loss: 2.0678358129275742

Epoch: 6| Step: 13
Training loss: 1.393515706062317
Validation loss: 2.066218267204941

Epoch: 529| Step: 0
Training loss: 0.8331419825553894
Validation loss: 2.038389736606229

Epoch: 6| Step: 1
Training loss: 1.5283520221710205
Validation loss: 2.0511733203805904

Epoch: 6| Step: 2
Training loss: 2.3578643798828125
Validation loss: 2.03076163927714

Epoch: 6| Step: 3
Training loss: 1.1725292205810547
Validation loss: 2.057412423113341

Epoch: 6| Step: 4
Training loss: 0.8430439233779907
Validation loss: 2.0544423890370194

Epoch: 6| Step: 5
Training loss: 1.5973896980285645
Validation loss: 2.125160189085109

Epoch: 6| Step: 6
Training loss: 0.5399115085601807
Validation loss: 2.0845379931952364

Epoch: 6| Step: 7
Training loss: 1.7239596843719482
Validation loss: 2.1132761688642603

Epoch: 6| Step: 8
Training loss: 1.5266778469085693
Validation loss: 2.1103667623253277

Epoch: 6| Step: 9
Training loss: 1.783665657043457
Validation loss: 2.093886420290957

Epoch: 6| Step: 10
Training loss: 1.3784165382385254
Validation loss: 2.1006668101074877

Epoch: 6| Step: 11
Training loss: 1.9919135570526123
Validation loss: 2.0922409129399124

Epoch: 6| Step: 12
Training loss: 1.2618696689605713
Validation loss: 2.0316088430343138

Epoch: 6| Step: 13
Training loss: 1.547884225845337
Validation loss: 2.0332151407836587

Epoch: 530| Step: 0
Training loss: 1.1916496753692627
Validation loss: 2.0264112449461416

Epoch: 6| Step: 1
Training loss: 0.9279952645301819
Validation loss: 2.0475829378251107

Epoch: 6| Step: 2
Training loss: 2.013601303100586
Validation loss: 2.110740557793648

Epoch: 6| Step: 3
Training loss: 1.395771861076355
Validation loss: 2.0422510306040444

Epoch: 6| Step: 4
Training loss: 1.5536527633666992
Validation loss: 2.0220241264630388

Epoch: 6| Step: 5
Training loss: 1.2201306819915771
Validation loss: 2.045110712769211

Epoch: 6| Step: 6
Training loss: 1.573429822921753
Validation loss: 1.9921511437303276

Epoch: 6| Step: 7
Training loss: 1.5366346836090088
Validation loss: 2.032932243039531

Epoch: 6| Step: 8
Training loss: 1.221104383468628
Validation loss: 2.0258547734188777

Epoch: 6| Step: 9
Training loss: 0.6664690971374512
Validation loss: 2.0503077558291856

Epoch: 6| Step: 10
Training loss: 1.9399361610412598
Validation loss: 2.0414220415135866

Epoch: 6| Step: 11
Training loss: 1.263960838317871
Validation loss: 2.04342342704855

Epoch: 6| Step: 12
Training loss: 2.385544776916504
Validation loss: 2.0539895232005785

Epoch: 6| Step: 13
Training loss: 1.2936607599258423
Validation loss: 2.0830719727341847

Epoch: 531| Step: 0
Training loss: 1.019331455230713
Validation loss: 2.0156047805663078

Epoch: 6| Step: 1
Training loss: 0.5979556441307068
Validation loss: 2.0749758904980076

Epoch: 6| Step: 2
Training loss: 1.3715137243270874
Validation loss: 2.0765624277053343

Epoch: 6| Step: 3
Training loss: 2.1541836261749268
Validation loss: 2.064840598772931

Epoch: 6| Step: 4
Training loss: 1.735219120979309
Validation loss: 2.106748952660509

Epoch: 6| Step: 5
Training loss: 1.4609935283660889
Validation loss: 2.092716847696612

Epoch: 6| Step: 6
Training loss: 2.0317420959472656
Validation loss: 2.0610005496650614

Epoch: 6| Step: 7
Training loss: 1.0995535850524902
Validation loss: 2.0506390909994803

Epoch: 6| Step: 8
Training loss: 1.9274137020111084
Validation loss: 2.0515759555242394

Epoch: 6| Step: 9
Training loss: 1.76254141330719
Validation loss: 2.067043291625156

Epoch: 6| Step: 10
Training loss: 1.2935692071914673
Validation loss: 2.05841064453125

Epoch: 6| Step: 11
Training loss: 1.145263910293579
Validation loss: 2.018342289873349

Epoch: 6| Step: 12
Training loss: 1.4709336757659912
Validation loss: 2.0753795946798017

Epoch: 6| Step: 13
Training loss: 1.0950337648391724
Validation loss: 2.063140462803584

Epoch: 532| Step: 0
Training loss: 1.8426222801208496
Validation loss: 2.051932032390307

Epoch: 6| Step: 1
Training loss: 0.9066537618637085
Validation loss: 2.077564611229845

Epoch: 6| Step: 2
Training loss: 1.9317772388458252
Validation loss: 2.063526204837266

Epoch: 6| Step: 3
Training loss: 1.33961820602417
Validation loss: 2.081195499307366

Epoch: 6| Step: 4
Training loss: 1.126084327697754
Validation loss: 2.0548621454546527

Epoch: 6| Step: 5
Training loss: 1.083357334136963
Validation loss: 2.062107697609932

Epoch: 6| Step: 6
Training loss: 1.351290225982666
Validation loss: 2.0654367682754353

Epoch: 6| Step: 7
Training loss: 1.8377207517623901
Validation loss: 2.04663356145223

Epoch: 6| Step: 8
Training loss: 1.6072975397109985
Validation loss: 2.03792764038168

Epoch: 6| Step: 9
Training loss: 1.4756765365600586
Validation loss: 2.0480668813951555

Epoch: 6| Step: 10
Training loss: 1.1197290420532227
Validation loss: 2.075074529135099

Epoch: 6| Step: 11
Training loss: 1.2648735046386719
Validation loss: 2.071644295928299

Epoch: 6| Step: 12
Training loss: 1.252833604812622
Validation loss: 2.079413688311013

Epoch: 6| Step: 13
Training loss: 2.2822299003601074
Validation loss: 2.0206172056095575

Epoch: 533| Step: 0
Training loss: 1.2285678386688232
Validation loss: 2.125981743617724

Epoch: 6| Step: 1
Training loss: 1.6015169620513916
Validation loss: 2.0723423522005797

Epoch: 6| Step: 2
Training loss: 2.011528491973877
Validation loss: 2.059220939554194

Epoch: 6| Step: 3
Training loss: 1.0474212169647217
Validation loss: 2.0842968494661394

Epoch: 6| Step: 4
Training loss: 0.8207954168319702
Validation loss: 2.0766377051671348

Epoch: 6| Step: 5
Training loss: 1.9299646615982056
Validation loss: 2.1064202477855067

Epoch: 6| Step: 6
Training loss: 0.9731818437576294
Validation loss: 2.078136021091092

Epoch: 6| Step: 7
Training loss: 1.3722155094146729
Validation loss: 2.0624996564721547

Epoch: 6| Step: 8
Training loss: 1.3812651634216309
Validation loss: 2.105856510900682

Epoch: 6| Step: 9
Training loss: 1.5940589904785156
Validation loss: 2.112697333417913

Epoch: 6| Step: 10
Training loss: 1.8212547302246094
Validation loss: 2.1200788982452883

Epoch: 6| Step: 11
Training loss: 1.5777428150177002
Validation loss: 2.078121890303909

Epoch: 6| Step: 12
Training loss: 1.4013642072677612
Validation loss: 2.1376262300757953

Epoch: 6| Step: 13
Training loss: 0.889389157295227
Validation loss: 2.0941688424797467

Epoch: 534| Step: 0
Training loss: 1.0264822244644165
Validation loss: 2.0906124678991174

Epoch: 6| Step: 1
Training loss: 1.2125606536865234
Validation loss: 2.0731951677671043

Epoch: 6| Step: 2
Training loss: 1.3826719522476196
Validation loss: 2.092420483148226

Epoch: 6| Step: 3
Training loss: 2.0114028453826904
Validation loss: 2.0896830263958184

Epoch: 6| Step: 4
Training loss: 1.525327205657959
Validation loss: 2.1059425800077376

Epoch: 6| Step: 5
Training loss: 1.6011114120483398
Validation loss: 2.0342973509142475

Epoch: 6| Step: 6
Training loss: 1.5075578689575195
Validation loss: 2.0598466114331315

Epoch: 6| Step: 7
Training loss: 1.4170944690704346
Validation loss: 2.0482998996652584

Epoch: 6| Step: 8
Training loss: 1.2750577926635742
Validation loss: 2.0434568235951085

Epoch: 6| Step: 9
Training loss: 0.8514165282249451
Validation loss: 2.0477835055320495

Epoch: 6| Step: 10
Training loss: 0.748704731464386
Validation loss: 2.112171710178416

Epoch: 6| Step: 11
Training loss: 2.3320817947387695
Validation loss: 2.0586323533006894

Epoch: 6| Step: 12
Training loss: 1.8334195613861084
Validation loss: 2.0822939360013573

Epoch: 6| Step: 13
Training loss: 1.7706983089447021
Validation loss: 2.103264070326282

Epoch: 535| Step: 0
Training loss: 1.058638572692871
Validation loss: 2.0597498570719073

Epoch: 6| Step: 1
Training loss: 0.8322803378105164
Validation loss: 2.0326277632867136

Epoch: 6| Step: 2
Training loss: 1.4258811473846436
Validation loss: 2.0464309774419314

Epoch: 6| Step: 3
Training loss: 1.5680606365203857
Validation loss: 2.0767345172102734

Epoch: 6| Step: 4
Training loss: 0.9697046875953674
Validation loss: 2.125957122413061

Epoch: 6| Step: 5
Training loss: 1.6517481803894043
Validation loss: 2.094384503620927

Epoch: 6| Step: 6
Training loss: 1.2927896976470947
Validation loss: 2.10164209078717

Epoch: 6| Step: 7
Training loss: 1.8574457168579102
Validation loss: 2.1065040531978814

Epoch: 6| Step: 8
Training loss: 1.893362283706665
Validation loss: 2.1380963274227676

Epoch: 6| Step: 9
Training loss: 1.4661325216293335
Validation loss: 2.1055274342977874

Epoch: 6| Step: 10
Training loss: 1.8543035984039307
Validation loss: 2.0755265425610285

Epoch: 6| Step: 11
Training loss: 1.657257318496704
Validation loss: 2.101805611323285

Epoch: 6| Step: 12
Training loss: 1.544318437576294
Validation loss: 2.0920455583962063

Epoch: 6| Step: 13
Training loss: 1.610434889793396
Validation loss: 2.0660984234143327

Epoch: 536| Step: 0
Training loss: 1.6517765522003174
Validation loss: 2.0591016315644786

Epoch: 6| Step: 1
Training loss: 1.0850095748901367
Validation loss: 2.0460772181069977

Epoch: 6| Step: 2
Training loss: 2.03792667388916
Validation loss: 2.062113090228009

Epoch: 6| Step: 3
Training loss: 0.8073031902313232
Validation loss: 2.0832956785796792

Epoch: 6| Step: 4
Training loss: 1.6262134313583374
Validation loss: 2.0403538057881017

Epoch: 6| Step: 5
Training loss: 1.6337676048278809
Validation loss: 2.0840831751464517

Epoch: 6| Step: 6
Training loss: 1.7347948551177979
Validation loss: 2.0405953596997004

Epoch: 6| Step: 7
Training loss: 1.289891004562378
Validation loss: 2.068804899851481

Epoch: 6| Step: 8
Training loss: 1.4581186771392822
Validation loss: 2.0581245089089997

Epoch: 6| Step: 9
Training loss: 1.5406204462051392
Validation loss: 2.0661511626294864

Epoch: 6| Step: 10
Training loss: 1.3941997289657593
Validation loss: 2.0619580643151396

Epoch: 6| Step: 11
Training loss: 1.0088939666748047
Validation loss: 2.0839790682638846

Epoch: 6| Step: 12
Training loss: 1.5325422286987305
Validation loss: 2.100973583036853

Epoch: 6| Step: 13
Training loss: 0.8277895450592041
Validation loss: 2.0374690332720355

Epoch: 537| Step: 0
Training loss: 1.1924952268600464
Validation loss: 2.03745142234269

Epoch: 6| Step: 1
Training loss: 1.666596531867981
Validation loss: 2.1202498007846136

Epoch: 6| Step: 2
Training loss: 0.8156341910362244
Validation loss: 2.017620955744097

Epoch: 6| Step: 3
Training loss: 1.3571751117706299
Validation loss: 2.0897653256693194

Epoch: 6| Step: 4
Training loss: 1.6894927024841309
Validation loss: 2.10653123804318

Epoch: 6| Step: 5
Training loss: 1.4754019975662231
Validation loss: 2.0719616413116455

Epoch: 6| Step: 6
Training loss: 1.728503704071045
Validation loss: 2.0823477750183432

Epoch: 6| Step: 7
Training loss: 1.4530141353607178
Validation loss: 2.0524965178581978

Epoch: 6| Step: 8
Training loss: 0.903056263923645
Validation loss: 2.0794372738048597

Epoch: 6| Step: 9
Training loss: 1.6680331230163574
Validation loss: 2.1012443355334702

Epoch: 6| Step: 10
Training loss: 1.1692956686019897
Validation loss: 2.029833265530166

Epoch: 6| Step: 11
Training loss: 1.631830096244812
Validation loss: 2.0603845516840615

Epoch: 6| Step: 12
Training loss: 1.3081976175308228
Validation loss: 2.1189314011604554

Epoch: 6| Step: 13
Training loss: 1.7363953590393066
Validation loss: 2.0406801918501496

Epoch: 538| Step: 0
Training loss: 1.1753473281860352
Validation loss: 2.08887376323823

Epoch: 6| Step: 1
Training loss: 2.133380889892578
Validation loss: 2.035689392397481

Epoch: 6| Step: 2
Training loss: 1.89204740524292
Validation loss: 2.079401659709151

Epoch: 6| Step: 3
Training loss: 0.4989224076271057
Validation loss: 2.0831278267727105

Epoch: 6| Step: 4
Training loss: 1.768370270729065
Validation loss: 2.0506290440918296

Epoch: 6| Step: 5
Training loss: 0.9017915725708008
Validation loss: 2.0280452787235217

Epoch: 6| Step: 6
Training loss: 1.7800590991973877
Validation loss: 2.0639236998814408

Epoch: 6| Step: 7
Training loss: 1.391313076019287
Validation loss: 2.101026850361978

Epoch: 6| Step: 8
Training loss: 1.2753229141235352
Validation loss: 2.068388474884854

Epoch: 6| Step: 9
Training loss: 2.509695291519165
Validation loss: 2.0693640888378186

Epoch: 6| Step: 10
Training loss: 0.711363673210144
Validation loss: 2.1167955911287697

Epoch: 6| Step: 11
Training loss: 1.325783371925354
Validation loss: 2.058398836402483

Epoch: 6| Step: 12
Training loss: 1.001363754272461
Validation loss: 2.1088286228077386

Epoch: 6| Step: 13
Training loss: 1.5093028545379639
Validation loss: 2.0745433312590404

Epoch: 539| Step: 0
Training loss: 1.0618873834609985
Validation loss: 2.1181574483071604

Epoch: 6| Step: 1
Training loss: 1.260335922241211
Validation loss: 2.0880895583860335

Epoch: 6| Step: 2
Training loss: 0.8630924224853516
Validation loss: 2.0873530013586885

Epoch: 6| Step: 3
Training loss: 1.9797329902648926
Validation loss: 2.060246535526809

Epoch: 6| Step: 4
Training loss: 1.2412478923797607
Validation loss: 2.074836971939251

Epoch: 6| Step: 5
Training loss: 1.2824726104736328
Validation loss: 2.0593334679962485

Epoch: 6| Step: 6
Training loss: 2.0354390144348145
Validation loss: 2.0616661656287407

Epoch: 6| Step: 7
Training loss: 1.1600627899169922
Validation loss: 2.0730396201533656

Epoch: 6| Step: 8
Training loss: 1.4617626667022705
Validation loss: 2.054648219898183

Epoch: 6| Step: 9
Training loss: 1.5615479946136475
Validation loss: 2.047573551054924

Epoch: 6| Step: 10
Training loss: 1.524147868156433
Validation loss: 1.9986319926477247

Epoch: 6| Step: 11
Training loss: 1.6165653467178345
Validation loss: 2.0546061044098227

Epoch: 6| Step: 12
Training loss: 1.3924671411514282
Validation loss: 2.01643314028299

Epoch: 6| Step: 13
Training loss: 1.4765491485595703
Validation loss: 2.0413496058474303

Epoch: 540| Step: 0
Training loss: 1.8681994676589966
Validation loss: 2.04461000298941

Epoch: 6| Step: 1
Training loss: 1.5548384189605713
Validation loss: 2.013283778262395

Epoch: 6| Step: 2
Training loss: 1.3200223445892334
Validation loss: 2.0336613257726035

Epoch: 6| Step: 3
Training loss: 1.844489336013794
Validation loss: 2.064844932607425

Epoch: 6| Step: 4
Training loss: 1.7199292182922363
Validation loss: 2.0320387463415823

Epoch: 6| Step: 5
Training loss: 1.1408138275146484
Validation loss: 2.0379829534920315

Epoch: 6| Step: 6
Training loss: 0.6414703130722046
Validation loss: 2.0513095048166092

Epoch: 6| Step: 7
Training loss: 1.2670929431915283
Validation loss: 2.0667809594062065

Epoch: 6| Step: 8
Training loss: 1.4436029195785522
Validation loss: 2.077147232588901

Epoch: 6| Step: 9
Training loss: 1.2601574659347534
Validation loss: 2.052775211231683

Epoch: 6| Step: 10
Training loss: 1.0628526210784912
Validation loss: 2.119463341210478

Epoch: 6| Step: 11
Training loss: 1.2329152822494507
Validation loss: 2.0868581956432712

Epoch: 6| Step: 12
Training loss: 1.824919581413269
Validation loss: 2.07639241731295

Epoch: 6| Step: 13
Training loss: 1.755760669708252
Validation loss: 2.112973000413628

Epoch: 541| Step: 0
Training loss: 1.260469913482666
Validation loss: 2.0743148275600967

Epoch: 6| Step: 1
Training loss: 0.6846925020217896
Validation loss: 2.059256067840002

Epoch: 6| Step: 2
Training loss: 1.2294535636901855
Validation loss: 2.037643112162108

Epoch: 6| Step: 3
Training loss: 1.9703590869903564
Validation loss: 2.050246302799512

Epoch: 6| Step: 4
Training loss: 0.9255106449127197
Validation loss: 2.086871349683372

Epoch: 6| Step: 5
Training loss: 1.7070246934890747
Validation loss: 2.055139833881009

Epoch: 6| Step: 6
Training loss: 0.942003607749939
Validation loss: 2.060676100433514

Epoch: 6| Step: 7
Training loss: 1.2628166675567627
Validation loss: 2.0977947968308643

Epoch: 6| Step: 8
Training loss: 1.5098633766174316
Validation loss: 2.072898116163028

Epoch: 6| Step: 9
Training loss: 1.381311058998108
Validation loss: 2.05439918784685

Epoch: 6| Step: 10
Training loss: 1.7128161191940308
Validation loss: 2.062680487991661

Epoch: 6| Step: 11
Training loss: 2.1416075229644775
Validation loss: 2.0481748760387464

Epoch: 6| Step: 12
Training loss: 1.6115081310272217
Validation loss: 2.070632591042467

Epoch: 6| Step: 13
Training loss: 1.6687299013137817
Validation loss: 2.064969947261195

Epoch: 542| Step: 0
Training loss: 1.1306002140045166
Validation loss: 2.0643880495461087

Epoch: 6| Step: 1
Training loss: 0.6991648077964783
Validation loss: 2.051688410902536

Epoch: 6| Step: 2
Training loss: 1.272133708000183
Validation loss: 1.9883120239421885

Epoch: 6| Step: 3
Training loss: 1.818640112876892
Validation loss: 2.0364695646429576

Epoch: 6| Step: 4
Training loss: 1.3013911247253418
Validation loss: 2.0724581441571637

Epoch: 6| Step: 5
Training loss: 0.78311687707901
Validation loss: 2.0808554157134025

Epoch: 6| Step: 6
Training loss: 1.583674430847168
Validation loss: 2.0184501588985486

Epoch: 6| Step: 7
Training loss: 1.892293930053711
Validation loss: 2.022596228507257

Epoch: 6| Step: 8
Training loss: 1.391944169998169
Validation loss: 2.055798260114526

Epoch: 6| Step: 9
Training loss: 0.9670156836509705
Validation loss: 2.051529743338144

Epoch: 6| Step: 10
Training loss: 2.0289764404296875
Validation loss: 2.0333690848401798

Epoch: 6| Step: 11
Training loss: 1.3109874725341797
Validation loss: 2.054540777719149

Epoch: 6| Step: 12
Training loss: 1.7948381900787354
Validation loss: 2.071025284387732

Epoch: 6| Step: 13
Training loss: 2.0402297973632812
Validation loss: 2.0301344061410553

Epoch: 543| Step: 0
Training loss: 0.9598156809806824
Validation loss: 2.0305059776511243

Epoch: 6| Step: 1
Training loss: 1.5599522590637207
Validation loss: 2.0667252438042754

Epoch: 6| Step: 2
Training loss: 0.9892586469650269
Validation loss: 2.0802680061709498

Epoch: 6| Step: 3
Training loss: 1.5206871032714844
Validation loss: 2.067564877130652

Epoch: 6| Step: 4
Training loss: 1.9756817817687988
Validation loss: 2.0818506568990727

Epoch: 6| Step: 5
Training loss: 2.4570274353027344
Validation loss: 2.0492659089385823

Epoch: 6| Step: 6
Training loss: 1.18895423412323
Validation loss: 2.0973803997039795

Epoch: 6| Step: 7
Training loss: 0.9442756772041321
Validation loss: 2.0794020519461682

Epoch: 6| Step: 8
Training loss: 1.0534855127334595
Validation loss: 2.090440934704196

Epoch: 6| Step: 9
Training loss: 1.694676399230957
Validation loss: 2.0887378210662515

Epoch: 6| Step: 10
Training loss: 0.7883149981498718
Validation loss: 2.107112870421461

Epoch: 6| Step: 11
Training loss: 1.7171382904052734
Validation loss: 2.0619969034707673

Epoch: 6| Step: 12
Training loss: 1.9709415435791016
Validation loss: 2.0457591728497575

Epoch: 6| Step: 13
Training loss: 1.0739902257919312
Validation loss: 2.0740005752091766

Epoch: 544| Step: 0
Training loss: 1.3474066257476807
Validation loss: 2.1228934539261686

Epoch: 6| Step: 1
Training loss: 1.546338677406311
Validation loss: 2.1047173212933283

Epoch: 6| Step: 2
Training loss: 0.9396675825119019
Validation loss: 2.039252596516763

Epoch: 6| Step: 3
Training loss: 1.0489248037338257
Validation loss: 2.0423396095152824

Epoch: 6| Step: 4
Training loss: 1.6607534885406494
Validation loss: 2.058866681591157

Epoch: 6| Step: 5
Training loss: 1.4522144794464111
Validation loss: 2.026624086082623

Epoch: 6| Step: 6
Training loss: 1.6405516862869263
Validation loss: 2.03155477200785

Epoch: 6| Step: 7
Training loss: 1.5138843059539795
Validation loss: 2.0078557678448257

Epoch: 6| Step: 8
Training loss: 1.555126667022705
Validation loss: 2.0796913664828063

Epoch: 6| Step: 9
Training loss: 1.6391087770462036
Validation loss: 2.060233798078311

Epoch: 6| Step: 10
Training loss: 1.7768008708953857
Validation loss: 2.0601507374035415

Epoch: 6| Step: 11
Training loss: 1.4068492650985718
Validation loss: 2.085437361912061

Epoch: 6| Step: 12
Training loss: 1.244276762008667
Validation loss: 2.086920976638794

Epoch: 6| Step: 13
Training loss: 1.580073356628418
Validation loss: 2.1037424969416794

Epoch: 545| Step: 0
Training loss: 1.5504770278930664
Validation loss: 2.1027773887880388

Epoch: 6| Step: 1
Training loss: 1.3726447820663452
Validation loss: 2.073182434164068

Epoch: 6| Step: 2
Training loss: 1.502447485923767
Validation loss: 2.0690017400249356

Epoch: 6| Step: 3
Training loss: 1.6971098184585571
Validation loss: 2.0439893507188365

Epoch: 6| Step: 4
Training loss: 1.0907886028289795
Validation loss: 2.0662239097779795

Epoch: 6| Step: 5
Training loss: 1.2107672691345215
Validation loss: 2.0525664693565777

Epoch: 6| Step: 6
Training loss: 1.9737716913223267
Validation loss: 2.0761337523819297

Epoch: 6| Step: 7
Training loss: 1.0547394752502441
Validation loss: 2.0645750799486713

Epoch: 6| Step: 8
Training loss: 1.0968334674835205
Validation loss: 2.0652337484462286

Epoch: 6| Step: 9
Training loss: 1.8905876874923706
Validation loss: 2.06448523588078

Epoch: 6| Step: 10
Training loss: 1.5792887210845947
Validation loss: 2.043154944655716

Epoch: 6| Step: 11
Training loss: 0.8643984794616699
Validation loss: 2.0865665904937254

Epoch: 6| Step: 12
Training loss: 1.8856781721115112
Validation loss: 2.065737626885855

Epoch: 6| Step: 13
Training loss: 1.0817925930023193
Validation loss: 2.0677699940178984

Epoch: 546| Step: 0
Training loss: 1.4170520305633545
Validation loss: 2.089272386284285

Epoch: 6| Step: 1
Training loss: 2.048491954803467
Validation loss: 2.0785432554060415

Epoch: 6| Step: 2
Training loss: 0.7654268741607666
Validation loss: 2.0872653389489777

Epoch: 6| Step: 3
Training loss: 1.5929176807403564
Validation loss: 2.05732314561003

Epoch: 6| Step: 4
Training loss: 1.390090823173523
Validation loss: 2.0594309145404446

Epoch: 6| Step: 5
Training loss: 1.5458310842514038
Validation loss: 2.0284893525544034

Epoch: 6| Step: 6
Training loss: 0.9960882663726807
Validation loss: 2.073633700288752

Epoch: 6| Step: 7
Training loss: 1.0711528062820435
Validation loss: 2.052686177274232

Epoch: 6| Step: 8
Training loss: 1.9932917356491089
Validation loss: 2.0511110418586322

Epoch: 6| Step: 9
Training loss: 1.462172508239746
Validation loss: 2.0432440401405416

Epoch: 6| Step: 10
Training loss: 1.247877836227417
Validation loss: 2.047585791157138

Epoch: 6| Step: 11
Training loss: 1.8505151271820068
Validation loss: 2.014804526041913

Epoch: 6| Step: 12
Training loss: 1.1426582336425781
Validation loss: 2.0519577790332097

Epoch: 6| Step: 13
Training loss: 1.9574421644210815
Validation loss: 2.064785954772785

Epoch: 547| Step: 0
Training loss: 1.147981882095337
Validation loss: 2.005116642162364

Epoch: 6| Step: 1
Training loss: 1.730858564376831
Validation loss: 2.035191471858691

Epoch: 6| Step: 2
Training loss: 0.9318876266479492
Validation loss: 2.0942794994641374

Epoch: 6| Step: 3
Training loss: 1.904189109802246
Validation loss: 2.087660233179728

Epoch: 6| Step: 4
Training loss: 1.4166514873504639
Validation loss: 2.085898458316762

Epoch: 6| Step: 5
Training loss: 1.1562747955322266
Validation loss: 2.0487757523854575

Epoch: 6| Step: 6
Training loss: 2.29286527633667
Validation loss: 2.0735498705217914

Epoch: 6| Step: 7
Training loss: 1.3197308778762817
Validation loss: 2.1243661603619977

Epoch: 6| Step: 8
Training loss: 0.923981785774231
Validation loss: 2.045827965582571

Epoch: 6| Step: 9
Training loss: 1.6460356712341309
Validation loss: 2.103798403534838

Epoch: 6| Step: 10
Training loss: 1.9477112293243408
Validation loss: 2.084752757062194

Epoch: 6| Step: 11
Training loss: 0.9835852980613708
Validation loss: 2.085863369767384

Epoch: 6| Step: 12
Training loss: 1.6599977016448975
Validation loss: 2.0594759730882544

Epoch: 6| Step: 13
Training loss: 0.6476985812187195
Validation loss: 2.054251011981759

Epoch: 548| Step: 0
Training loss: 0.8186157941818237
Validation loss: 2.0847559949403167

Epoch: 6| Step: 1
Training loss: 0.9119603037834167
Validation loss: 2.096548311171993

Epoch: 6| Step: 2
Training loss: 1.735687017440796
Validation loss: 2.072019136080178

Epoch: 6| Step: 3
Training loss: 2.082486867904663
Validation loss: 2.0310160588192683

Epoch: 6| Step: 4
Training loss: 1.2955245971679688
Validation loss: 2.0468415598715506

Epoch: 6| Step: 5
Training loss: 1.4682496786117554
Validation loss: 2.065910936683737

Epoch: 6| Step: 6
Training loss: 0.9752629399299622
Validation loss: 2.0685304377668645

Epoch: 6| Step: 7
Training loss: 1.2622147798538208
Validation loss: 2.0452359440506145

Epoch: 6| Step: 8
Training loss: 1.3817170858383179
Validation loss: 2.0067455563493954

Epoch: 6| Step: 9
Training loss: 1.631179928779602
Validation loss: 2.063513699398246

Epoch: 6| Step: 10
Training loss: 1.4171147346496582
Validation loss: 2.05574103324644

Epoch: 6| Step: 11
Training loss: 1.5668615102767944
Validation loss: 2.0822185047211184

Epoch: 6| Step: 12
Training loss: 1.6271507740020752
Validation loss: 2.0700831746542327

Epoch: 6| Step: 13
Training loss: 1.2843108177185059
Validation loss: 2.0204964350628596

Epoch: 549| Step: 0
Training loss: 1.0955417156219482
Validation loss: 2.078905733682776

Epoch: 6| Step: 1
Training loss: 0.9679242968559265
Validation loss: 2.033396105612478

Epoch: 6| Step: 2
Training loss: 1.692148208618164
Validation loss: 2.0013327380662322

Epoch: 6| Step: 3
Training loss: 1.4895129203796387
Validation loss: 2.0706334549893617

Epoch: 6| Step: 4
Training loss: 1.225287675857544
Validation loss: 2.0360732847644436

Epoch: 6| Step: 5
Training loss: 1.5606038570404053
Validation loss: 2.0485764562442736

Epoch: 6| Step: 6
Training loss: 1.746253252029419
Validation loss: 2.055670202419322

Epoch: 6| Step: 7
Training loss: 1.4522087574005127
Validation loss: 2.0350230919417513

Epoch: 6| Step: 8
Training loss: 0.9591105580329895
Validation loss: 2.0727108524691675

Epoch: 6| Step: 9
Training loss: 1.9874628782272339
Validation loss: 2.0853141418067356

Epoch: 6| Step: 10
Training loss: 1.4969687461853027
Validation loss: 2.0855055111710743

Epoch: 6| Step: 11
Training loss: 1.5921242237091064
Validation loss: 2.085678408222814

Epoch: 6| Step: 12
Training loss: 1.346557855606079
Validation loss: 2.1257171028403827

Epoch: 6| Step: 13
Training loss: 1.7673213481903076
Validation loss: 2.1208596896099787

Epoch: 550| Step: 0
Training loss: 1.9355437755584717
Validation loss: 2.144665320714315

Epoch: 6| Step: 1
Training loss: 1.7352468967437744
Validation loss: 2.1328472873216033

Epoch: 6| Step: 2
Training loss: 1.3772552013397217
Validation loss: 2.115098580237358

Epoch: 6| Step: 3
Training loss: 1.4025710821151733
Validation loss: 2.130155340317757

Epoch: 6| Step: 4
Training loss: 1.6086046695709229
Validation loss: 2.1432768734552528

Epoch: 6| Step: 5
Training loss: 1.3917261362075806
Validation loss: 2.1029410259698027

Epoch: 6| Step: 6
Training loss: 2.003748655319214
Validation loss: 2.126064928629065

Epoch: 6| Step: 7
Training loss: 0.9256715178489685
Validation loss: 2.0562316833003873

Epoch: 6| Step: 8
Training loss: 0.6179298162460327
Validation loss: 2.0983007595103276

Epoch: 6| Step: 9
Training loss: 1.3654334545135498
Validation loss: 2.0245118089901504

Epoch: 6| Step: 10
Training loss: 1.2367980480194092
Validation loss: 2.075732247803801

Epoch: 6| Step: 11
Training loss: 0.8130930662155151
Validation loss: 2.018492134668494

Epoch: 6| Step: 12
Training loss: 2.1305928230285645
Validation loss: 1.9907011011595368

Epoch: 6| Step: 13
Training loss: 1.4713472127914429
Validation loss: 2.0881648858388266

Epoch: 551| Step: 0
Training loss: 1.6137725114822388
Validation loss: 1.9817247454838087

Epoch: 6| Step: 1
Training loss: 1.5255999565124512
Validation loss: 2.072057757326352

Epoch: 6| Step: 2
Training loss: 1.321746587753296
Validation loss: 2.031682275956677

Epoch: 6| Step: 3
Training loss: 1.2924578189849854
Validation loss: 2.0371077393972747

Epoch: 6| Step: 4
Training loss: 1.532825231552124
Validation loss: 2.0099744899298555

Epoch: 6| Step: 5
Training loss: 1.6102361679077148
Validation loss: 2.0306166525809997

Epoch: 6| Step: 6
Training loss: 1.9018194675445557
Validation loss: 2.0524012055448306

Epoch: 6| Step: 7
Training loss: 1.4608896970748901
Validation loss: 2.0391533003058484

Epoch: 6| Step: 8
Training loss: 1.1938259601593018
Validation loss: 2.03172331471597

Epoch: 6| Step: 9
Training loss: 0.5680602788925171
Validation loss: 2.08445825371691

Epoch: 6| Step: 10
Training loss: 1.5604240894317627
Validation loss: 2.0368889198508313

Epoch: 6| Step: 11
Training loss: 0.9667329788208008
Validation loss: 2.0405740571278397

Epoch: 6| Step: 12
Training loss: 1.5889577865600586
Validation loss: 2.106305529994349

Epoch: 6| Step: 13
Training loss: 1.6086769104003906
Validation loss: 2.041302275914018

Epoch: 552| Step: 0
Training loss: 1.6212317943572998
Validation loss: 2.057381522270941

Epoch: 6| Step: 1
Training loss: 1.1991156339645386
Validation loss: 2.0622907761604554

Epoch: 6| Step: 2
Training loss: 2.015693187713623
Validation loss: 2.0873901613297

Epoch: 6| Step: 3
Training loss: 1.0744075775146484
Validation loss: 2.0822834173838296

Epoch: 6| Step: 4
Training loss: 1.0051116943359375
Validation loss: 2.049348715812929

Epoch: 6| Step: 5
Training loss: 2.551910161972046
Validation loss: 2.054171081512205

Epoch: 6| Step: 6
Training loss: 1.5763726234436035
Validation loss: 2.0613389245925413

Epoch: 6| Step: 7
Training loss: 2.308483123779297
Validation loss: 2.074066291573227

Epoch: 6| Step: 8
Training loss: 1.0991326570510864
Validation loss: 2.0842441576783375

Epoch: 6| Step: 9
Training loss: 0.7830818891525269
Validation loss: 2.060556343806687

Epoch: 6| Step: 10
Training loss: 0.8540695905685425
Validation loss: 2.1268471325597456

Epoch: 6| Step: 11
Training loss: 1.8365222215652466
Validation loss: 2.0915645322492047

Epoch: 6| Step: 12
Training loss: 0.9316579699516296
Validation loss: 2.0825997911473757

Epoch: 6| Step: 13
Training loss: 0.7409528493881226
Validation loss: 2.063668388192372

Epoch: 553| Step: 0
Training loss: 1.5113880634307861
Validation loss: 2.0805208913741575

Epoch: 6| Step: 1
Training loss: 1.5330679416656494
Validation loss: 2.058582203362578

Epoch: 6| Step: 2
Training loss: 1.8790042400360107
Validation loss: 2.049601388233964

Epoch: 6| Step: 3
Training loss: 1.2607747316360474
Validation loss: 2.0555108029355287

Epoch: 6| Step: 4
Training loss: 2.0359978675842285
Validation loss: 2.089402098809519

Epoch: 6| Step: 5
Training loss: 1.3380935192108154
Validation loss: 2.054091934234865

Epoch: 6| Step: 6
Training loss: 1.165755271911621
Validation loss: 2.040977047335717

Epoch: 6| Step: 7
Training loss: 1.4863314628601074
Validation loss: 2.0389860727453746

Epoch: 6| Step: 8
Training loss: 0.9271110892295837
Validation loss: 2.0372304275471675

Epoch: 6| Step: 9
Training loss: 1.4443614482879639
Validation loss: 2.0262387285950365

Epoch: 6| Step: 10
Training loss: 1.0476570129394531
Validation loss: 1.9974654797584779

Epoch: 6| Step: 11
Training loss: 1.6354455947875977
Validation loss: 2.004083518059023

Epoch: 6| Step: 12
Training loss: 1.5058786869049072
Validation loss: 2.0253905532180623

Epoch: 6| Step: 13
Training loss: 0.7437894344329834
Validation loss: 2.0509047367239512

Epoch: 554| Step: 0
Training loss: 1.5059080123901367
Validation loss: 2.0598177909851074

Epoch: 6| Step: 1
Training loss: 1.5914530754089355
Validation loss: 2.069805247809297

Epoch: 6| Step: 2
Training loss: 1.354297399520874
Validation loss: 2.057174745426383

Epoch: 6| Step: 3
Training loss: 1.3989192247390747
Validation loss: 2.076142167532316

Epoch: 6| Step: 4
Training loss: 1.4796619415283203
Validation loss: 2.0211474459658385

Epoch: 6| Step: 5
Training loss: 1.3236000537872314
Validation loss: 2.073793242054601

Epoch: 6| Step: 6
Training loss: 1.8450994491577148
Validation loss: 2.056934313107562

Epoch: 6| Step: 7
Training loss: 1.2450132369995117
Validation loss: 2.1238776458207

Epoch: 6| Step: 8
Training loss: 1.1880031824111938
Validation loss: 2.068932528136879

Epoch: 6| Step: 9
Training loss: 0.9929050803184509
Validation loss: 2.0535750696735997

Epoch: 6| Step: 10
Training loss: 1.3425815105438232
Validation loss: 2.1003082003644717

Epoch: 6| Step: 11
Training loss: 1.2854746580123901
Validation loss: 2.0434189791320474

Epoch: 6| Step: 12
Training loss: 1.663833737373352
Validation loss: 2.066482477290656

Epoch: 6| Step: 13
Training loss: 1.1685638427734375
Validation loss: 2.0104925401749147

Epoch: 555| Step: 0
Training loss: 1.142347812652588
Validation loss: 2.0321873105982298

Epoch: 6| Step: 1
Training loss: 1.8438117504119873
Validation loss: 2.0497478362052672

Epoch: 6| Step: 2
Training loss: 1.2710740566253662
Validation loss: 2.0732211195012575

Epoch: 6| Step: 3
Training loss: 1.9171504974365234
Validation loss: 2.0452929453183244

Epoch: 6| Step: 4
Training loss: 1.6451793909072876
Validation loss: 2.0461461390218427

Epoch: 6| Step: 5
Training loss: 0.761347770690918
Validation loss: 2.0438373986110894

Epoch: 6| Step: 6
Training loss: 1.1579561233520508
Validation loss: 2.0372270179051224

Epoch: 6| Step: 7
Training loss: 1.376908779144287
Validation loss: 2.0606375419965355

Epoch: 6| Step: 8
Training loss: 2.221489906311035
Validation loss: 2.029082134205808

Epoch: 6| Step: 9
Training loss: 1.2367459535598755
Validation loss: 2.0292671700959564

Epoch: 6| Step: 10
Training loss: 1.4033288955688477
Validation loss: 2.0363981467421337

Epoch: 6| Step: 11
Training loss: 1.4432177543640137
Validation loss: 2.0581689778194634

Epoch: 6| Step: 12
Training loss: 0.9857560992240906
Validation loss: 2.0271915235827045

Epoch: 6| Step: 13
Training loss: 0.8642539978027344
Validation loss: 2.0573986204721595

Epoch: 556| Step: 0
Training loss: 0.9755516648292542
Validation loss: 2.114969707945342

Epoch: 6| Step: 1
Training loss: 1.6392560005187988
Validation loss: 2.0824677123818347

Epoch: 6| Step: 2
Training loss: 0.877591609954834
Validation loss: 2.084560086650233

Epoch: 6| Step: 3
Training loss: 1.4939768314361572
Validation loss: 2.0496239482715564

Epoch: 6| Step: 4
Training loss: 1.3537265062332153
Validation loss: 2.0818094925213884

Epoch: 6| Step: 5
Training loss: 1.6088083982467651
Validation loss: 2.0657001977325766

Epoch: 6| Step: 6
Training loss: 2.225748062133789
Validation loss: 2.08881825400937

Epoch: 6| Step: 7
Training loss: 1.746830701828003
Validation loss: 2.1239478741922686

Epoch: 6| Step: 8
Training loss: 1.027665376663208
Validation loss: 2.0906038591938634

Epoch: 6| Step: 9
Training loss: 1.5589358806610107
Validation loss: 2.110747445014215

Epoch: 6| Step: 10
Training loss: 1.8106834888458252
Validation loss: 2.05854816590586

Epoch: 6| Step: 11
Training loss: 0.4183587431907654
Validation loss: 2.0729557365499516

Epoch: 6| Step: 12
Training loss: 1.4854575395584106
Validation loss: 2.045993225548857

Epoch: 6| Step: 13
Training loss: 1.6954996585845947
Validation loss: 2.0264342510572044

Epoch: 557| Step: 0
Training loss: 1.516683578491211
Validation loss: 2.031613326841785

Epoch: 6| Step: 1
Training loss: 1.7204821109771729
Validation loss: 2.038126912168277

Epoch: 6| Step: 2
Training loss: 1.7677841186523438
Validation loss: 2.035308280298787

Epoch: 6| Step: 3
Training loss: 1.5384316444396973
Validation loss: 2.0379538779617636

Epoch: 6| Step: 4
Training loss: 1.33900785446167
Validation loss: 2.053865255848054

Epoch: 6| Step: 5
Training loss: 1.1508033275604248
Validation loss: 2.0367987925006497

Epoch: 6| Step: 6
Training loss: 1.1034373044967651
Validation loss: 2.0815161287143664

Epoch: 6| Step: 7
Training loss: 1.4120419025421143
Validation loss: 2.0948107422039075

Epoch: 6| Step: 8
Training loss: 1.2507855892181396
Validation loss: 2.0414734578901723

Epoch: 6| Step: 9
Training loss: 0.9745227694511414
Validation loss: 2.0774453250310754

Epoch: 6| Step: 10
Training loss: 1.5394760370254517
Validation loss: 2.110094811326714

Epoch: 6| Step: 11
Training loss: 0.9606705904006958
Validation loss: 2.098548881469234

Epoch: 6| Step: 12
Training loss: 2.3614466190338135
Validation loss: 2.060244419241464

Epoch: 6| Step: 13
Training loss: 1.1726597547531128
Validation loss: 2.0906403192909817

Epoch: 558| Step: 0
Training loss: 1.262793779373169
Validation loss: 2.0811973617922876

Epoch: 6| Step: 1
Training loss: 1.3926770687103271
Validation loss: 2.1154725474696003

Epoch: 6| Step: 2
Training loss: 1.0536887645721436
Validation loss: 2.0814428124376523

Epoch: 6| Step: 3
Training loss: 1.6598670482635498
Validation loss: 2.0529258904918546

Epoch: 6| Step: 4
Training loss: 1.0121221542358398
Validation loss: 1.998101903546241

Epoch: 6| Step: 5
Training loss: 1.2253543138504028
Validation loss: 2.0538463515620076

Epoch: 6| Step: 6
Training loss: 1.435265302658081
Validation loss: 2.063932094522702

Epoch: 6| Step: 7
Training loss: 2.1213746070861816
Validation loss: 2.095742356392645

Epoch: 6| Step: 8
Training loss: 1.4252800941467285
Validation loss: 2.0300047282249696

Epoch: 6| Step: 9
Training loss: 0.9845496416091919
Validation loss: 2.0212808065516974

Epoch: 6| Step: 10
Training loss: 1.8321912288665771
Validation loss: 2.060174858698281

Epoch: 6| Step: 11
Training loss: 1.3782804012298584
Validation loss: 2.0532505409691924

Epoch: 6| Step: 12
Training loss: 1.8046352863311768
Validation loss: 2.024396788689398

Epoch: 6| Step: 13
Training loss: 1.3640285730361938
Validation loss: 2.065188712971185

Epoch: 559| Step: 0
Training loss: 1.4005991220474243
Validation loss: 2.0536656700154787

Epoch: 6| Step: 1
Training loss: 1.5171198844909668
Validation loss: 2.0313800432348765

Epoch: 6| Step: 2
Training loss: 1.8926939964294434
Validation loss: 2.07974664626583

Epoch: 6| Step: 3
Training loss: 1.2760246992111206
Validation loss: 2.0801175435384116

Epoch: 6| Step: 4
Training loss: 0.9787790775299072
Validation loss: 2.0735350167879494

Epoch: 6| Step: 5
Training loss: 1.0291173458099365
Validation loss: 2.0408685438094603

Epoch: 6| Step: 6
Training loss: 1.7026362419128418
Validation loss: 2.061747517637027

Epoch: 6| Step: 7
Training loss: 2.4211297035217285
Validation loss: 2.066939889743764

Epoch: 6| Step: 8
Training loss: 1.3611478805541992
Validation loss: 2.063936045092921

Epoch: 6| Step: 9
Training loss: 0.8578771352767944
Validation loss: 2.076889379050142

Epoch: 6| Step: 10
Training loss: 1.6282012462615967
Validation loss: 2.0847616452042774

Epoch: 6| Step: 11
Training loss: 0.9732479453086853
Validation loss: 2.1219864993967037

Epoch: 6| Step: 12
Training loss: 1.3083596229553223
Validation loss: 2.0688259524683796

Epoch: 6| Step: 13
Training loss: 0.8031923174858093
Validation loss: 2.0755431703341904

Epoch: 560| Step: 0
Training loss: 1.682632565498352
Validation loss: 2.0633218980604604

Epoch: 6| Step: 1
Training loss: 1.1264302730560303
Validation loss: 2.042407108891395

Epoch: 6| Step: 2
Training loss: 1.1560006141662598
Validation loss: 2.0346799947882213

Epoch: 6| Step: 3
Training loss: 1.12160062789917
Validation loss: 2.0553586136910225

Epoch: 6| Step: 4
Training loss: 1.6232351064682007
Validation loss: 2.0569562296713553

Epoch: 6| Step: 5
Training loss: 1.1775459051132202
Validation loss: 2.087769180215815

Epoch: 6| Step: 6
Training loss: 2.026242971420288
Validation loss: 2.033340428465156

Epoch: 6| Step: 7
Training loss: 1.055291771888733
Validation loss: 2.0527933464255383

Epoch: 6| Step: 8
Training loss: 1.3188157081604004
Validation loss: 2.058860355807889

Epoch: 6| Step: 9
Training loss: 1.7734956741333008
Validation loss: 2.028755892989456

Epoch: 6| Step: 10
Training loss: 1.2348062992095947
Validation loss: 2.0139333971085085

Epoch: 6| Step: 11
Training loss: 1.3183094263076782
Validation loss: 2.0778810798480944

Epoch: 6| Step: 12
Training loss: 1.5767923593521118
Validation loss: 2.0742688640471427

Epoch: 6| Step: 13
Training loss: 1.511737585067749
Validation loss: 2.011489601545436

Epoch: 561| Step: 0
Training loss: 1.2578327655792236
Validation loss: 2.0622812560809556

Epoch: 6| Step: 1
Training loss: 1.487363576889038
Validation loss: 2.0333035735673803

Epoch: 6| Step: 2
Training loss: 1.5766258239746094
Validation loss: 2.1038183012316303

Epoch: 6| Step: 3
Training loss: 1.7426413297653198
Validation loss: 2.044220344994658

Epoch: 6| Step: 4
Training loss: 1.0043658018112183
Validation loss: 2.031738004376811

Epoch: 6| Step: 5
Training loss: 1.421766996383667
Validation loss: 2.0398601229472826

Epoch: 6| Step: 6
Training loss: 1.7230244874954224
Validation loss: 2.057093470327316

Epoch: 6| Step: 7
Training loss: 1.570019006729126
Validation loss: 2.05820264867557

Epoch: 6| Step: 8
Training loss: 0.7165042161941528
Validation loss: 2.0732616814233924

Epoch: 6| Step: 9
Training loss: 1.2231305837631226
Validation loss: 2.0567487747438493

Epoch: 6| Step: 10
Training loss: 1.5013190507888794
Validation loss: 2.027890661711334

Epoch: 6| Step: 11
Training loss: 1.75567626953125
Validation loss: 2.071788937814774

Epoch: 6| Step: 12
Training loss: 1.2799952030181885
Validation loss: 2.054870746468985

Epoch: 6| Step: 13
Training loss: 1.324082851409912
Validation loss: 2.0300941095557263

Epoch: 562| Step: 0
Training loss: 0.6177974939346313
Validation loss: 2.0351936150622625

Epoch: 6| Step: 1
Training loss: 1.8355059623718262
Validation loss: 2.0668529810444003

Epoch: 6| Step: 2
Training loss: 1.7128952741622925
Validation loss: 2.055220286051432

Epoch: 6| Step: 3
Training loss: 1.3705865144729614
Validation loss: 2.057997818916075

Epoch: 6| Step: 4
Training loss: 1.3278748989105225
Validation loss: 2.0362322061292586

Epoch: 6| Step: 5
Training loss: 1.9077738523483276
Validation loss: 2.0295212230374737

Epoch: 6| Step: 6
Training loss: 1.7572684288024902
Validation loss: 2.047762155532837

Epoch: 6| Step: 7
Training loss: 1.0163607597351074
Validation loss: 2.0649682116764847

Epoch: 6| Step: 8
Training loss: 1.92474365234375
Validation loss: 2.085118414253317

Epoch: 6| Step: 9
Training loss: 0.40893447399139404
Validation loss: 2.1056115550379597

Epoch: 6| Step: 10
Training loss: 2.1841981410980225
Validation loss: 2.08309184223093

Epoch: 6| Step: 11
Training loss: 1.11294424533844
Validation loss: 2.077183913159114

Epoch: 6| Step: 12
Training loss: 1.2990907430648804
Validation loss: 2.1246512756552747

Epoch: 6| Step: 13
Training loss: 0.8034060001373291
Validation loss: 2.1179392389071885

Epoch: 563| Step: 0
Training loss: 1.1975305080413818
Validation loss: 2.0570236124018186

Epoch: 6| Step: 1
Training loss: 2.128741979598999
Validation loss: 2.114088858327558

Epoch: 6| Step: 2
Training loss: 1.121946930885315
Validation loss: 2.132502108491877

Epoch: 6| Step: 3
Training loss: 1.1824085712432861
Validation loss: 2.08072276653782

Epoch: 6| Step: 4
Training loss: 1.1770578622817993
Validation loss: 2.110789633566333

Epoch: 6| Step: 5
Training loss: 1.3593016862869263
Validation loss: 2.0839257573568695

Epoch: 6| Step: 6
Training loss: 1.9483447074890137
Validation loss: 2.046287703257735

Epoch: 6| Step: 7
Training loss: 1.2073044776916504
Validation loss: 2.03211308551091

Epoch: 6| Step: 8
Training loss: 1.8353643417358398
Validation loss: 2.0609314005862

Epoch: 6| Step: 9
Training loss: 1.3082011938095093
Validation loss: 2.033398747444153

Epoch: 6| Step: 10
Training loss: 1.2472925186157227
Validation loss: 2.073488939192987

Epoch: 6| Step: 11
Training loss: 1.5320594310760498
Validation loss: 1.9876466233243224

Epoch: 6| Step: 12
Training loss: 1.2091388702392578
Validation loss: 2.052641321254033

Epoch: 6| Step: 13
Training loss: 0.9184426069259644
Validation loss: 2.037334052465295

Epoch: 564| Step: 0
Training loss: 1.4628819227218628
Validation loss: 2.042223658612979

Epoch: 6| Step: 1
Training loss: 1.4928467273712158
Validation loss: 2.08656410888959

Epoch: 6| Step: 2
Training loss: 1.507584571838379
Validation loss: 2.066019832447011

Epoch: 6| Step: 3
Training loss: 1.015613079071045
Validation loss: 2.024824155274258

Epoch: 6| Step: 4
Training loss: 1.4539480209350586
Validation loss: 2.066401884760908

Epoch: 6| Step: 5
Training loss: 1.4898325204849243
Validation loss: 2.036379006601149

Epoch: 6| Step: 6
Training loss: 0.9662380814552307
Validation loss: 2.0277019111059045

Epoch: 6| Step: 7
Training loss: 1.5531013011932373
Validation loss: 2.008145570755005

Epoch: 6| Step: 8
Training loss: 2.0483384132385254
Validation loss: 2.017488248886601

Epoch: 6| Step: 9
Training loss: 1.4478623867034912
Validation loss: 2.079078023151685

Epoch: 6| Step: 10
Training loss: 1.8573460578918457
Validation loss: 2.065267288556663

Epoch: 6| Step: 11
Training loss: 0.7448713183403015
Validation loss: 2.0634200842149797

Epoch: 6| Step: 12
Training loss: 1.0771454572677612
Validation loss: 2.05960419870192

Epoch: 6| Step: 13
Training loss: 1.6042194366455078
Validation loss: 2.072328828996228

Epoch: 565| Step: 0
Training loss: 1.3033560514450073
Validation loss: 2.115629324349024

Epoch: 6| Step: 1
Training loss: 1.6103624105453491
Validation loss: 2.0773657726985153

Epoch: 6| Step: 2
Training loss: 1.3944522142410278
Validation loss: 2.0959966567254837

Epoch: 6| Step: 3
Training loss: 1.5332289934158325
Validation loss: 2.0942239863898164

Epoch: 6| Step: 4
Training loss: 1.1913692951202393
Validation loss: 2.0643766208361556

Epoch: 6| Step: 5
Training loss: 1.5987048149108887
Validation loss: 2.0775830912333664

Epoch: 6| Step: 6
Training loss: 1.6186473369598389
Validation loss: 2.001464687367921

Epoch: 6| Step: 7
Training loss: 0.8231291770935059
Validation loss: 2.0442635192666003

Epoch: 6| Step: 8
Training loss: 1.4223908185958862
Validation loss: 2.080636038575121

Epoch: 6| Step: 9
Training loss: 1.4540009498596191
Validation loss: 2.0829288882593953

Epoch: 6| Step: 10
Training loss: 1.1271213293075562
Validation loss: 2.033135529487364

Epoch: 6| Step: 11
Training loss: 1.3447999954223633
Validation loss: 2.0595437660012195

Epoch: 6| Step: 12
Training loss: 1.7827461957931519
Validation loss: 2.024246682402908

Epoch: 6| Step: 13
Training loss: 0.4878493547439575
Validation loss: 2.0435797527272213

Epoch: 566| Step: 0
Training loss: 0.8697245717048645
Validation loss: 2.021988202166814

Epoch: 6| Step: 1
Training loss: 1.8556511402130127
Validation loss: 2.041998613265253

Epoch: 6| Step: 2
Training loss: 1.0455292463302612
Validation loss: 2.0332397414791967

Epoch: 6| Step: 3
Training loss: 1.1817775964736938
Validation loss: 2.026104727099019

Epoch: 6| Step: 4
Training loss: 1.51826012134552
Validation loss: 2.0326804191835466

Epoch: 6| Step: 5
Training loss: 1.6841133832931519
Validation loss: 2.0536491012060516

Epoch: 6| Step: 6
Training loss: 1.5426095724105835
Validation loss: 2.036171160718446

Epoch: 6| Step: 7
Training loss: 0.8769135475158691
Validation loss: 2.041818900774884

Epoch: 6| Step: 8
Training loss: 1.733561396598816
Validation loss: 2.0407427113543273

Epoch: 6| Step: 9
Training loss: 1.4027653932571411
Validation loss: 2.030822105305169

Epoch: 6| Step: 10
Training loss: 1.875512957572937
Validation loss: 2.036801879123975

Epoch: 6| Step: 11
Training loss: 1.2719076871871948
Validation loss: 2.0416610189663467

Epoch: 6| Step: 12
Training loss: 1.4621949195861816
Validation loss: 2.0359003364398913

Epoch: 6| Step: 13
Training loss: 0.7734287977218628
Validation loss: 2.074145104295464

Epoch: 567| Step: 0
Training loss: 1.2772364616394043
Validation loss: 2.057400672666488

Epoch: 6| Step: 1
Training loss: 1.3119134902954102
Validation loss: 2.020110350783153

Epoch: 6| Step: 2
Training loss: 1.8633184432983398
Validation loss: 2.0345761699061238

Epoch: 6| Step: 3
Training loss: 1.4366376399993896
Validation loss: 2.0541080121071107

Epoch: 6| Step: 4
Training loss: 1.4151523113250732
Validation loss: 2.0566712733237975

Epoch: 6| Step: 5
Training loss: 1.351030945777893
Validation loss: 2.0438258955555577

Epoch: 6| Step: 6
Training loss: 1.2345151901245117
Validation loss: 2.063122800601426

Epoch: 6| Step: 7
Training loss: 0.8878576755523682
Validation loss: 2.085715973249046

Epoch: 6| Step: 8
Training loss: 1.7744855880737305
Validation loss: 2.067344750127485

Epoch: 6| Step: 9
Training loss: 1.4453905820846558
Validation loss: 2.055542794607019

Epoch: 6| Step: 10
Training loss: 0.765424907207489
Validation loss: 2.0662983361110894

Epoch: 6| Step: 11
Training loss: 1.6649789810180664
Validation loss: 2.0448244912649995

Epoch: 6| Step: 12
Training loss: 1.3481786251068115
Validation loss: 2.0368907784902923

Epoch: 6| Step: 13
Training loss: 1.6284618377685547
Validation loss: 2.052508420841668

Epoch: 568| Step: 0
Training loss: 1.789157748222351
Validation loss: 2.016008657793845

Epoch: 6| Step: 1
Training loss: 1.269751787185669
Validation loss: 2.0601438066010833

Epoch: 6| Step: 2
Training loss: 0.9466034173965454
Validation loss: 2.028636065862512

Epoch: 6| Step: 3
Training loss: 1.3550012111663818
Validation loss: 2.0848812723672516

Epoch: 6| Step: 4
Training loss: 1.4170863628387451
Validation loss: 2.065858684560304

Epoch: 6| Step: 5
Training loss: 1.3480486869812012
Validation loss: 2.0732671650507117

Epoch: 6| Step: 6
Training loss: 0.8450554609298706
Validation loss: 2.037585504593388

Epoch: 6| Step: 7
Training loss: 1.4268276691436768
Validation loss: 2.0430649108784174

Epoch: 6| Step: 8
Training loss: 2.0941872596740723
Validation loss: 2.082774757057108

Epoch: 6| Step: 9
Training loss: 1.3903491497039795
Validation loss: 2.035915131209999

Epoch: 6| Step: 10
Training loss: 0.9723217487335205
Validation loss: 1.9852437742294804

Epoch: 6| Step: 11
Training loss: 1.6616783142089844
Validation loss: 2.011046286552183

Epoch: 6| Step: 12
Training loss: 1.5269393920898438
Validation loss: 2.0443025212134085

Epoch: 6| Step: 13
Training loss: 1.7689740657806396
Validation loss: 2.013665040334066

Epoch: 569| Step: 0
Training loss: 1.553310751914978
Validation loss: 2.028676129156543

Epoch: 6| Step: 1
Training loss: 1.3430057764053345
Validation loss: 2.031624171041673

Epoch: 6| Step: 2
Training loss: 1.2421208620071411
Validation loss: 2.044820329194428

Epoch: 6| Step: 3
Training loss: 1.9429694414138794
Validation loss: 2.073672345889512

Epoch: 6| Step: 4
Training loss: 1.8379348516464233
Validation loss: 2.0696407800079673

Epoch: 6| Step: 5
Training loss: 1.1591814756393433
Validation loss: 2.0389236122049312

Epoch: 6| Step: 6
Training loss: 1.7772339582443237
Validation loss: 2.0693444974960817

Epoch: 6| Step: 7
Training loss: 1.4276471138000488
Validation loss: 2.0972327724579842

Epoch: 6| Step: 8
Training loss: 0.7188408374786377
Validation loss: 2.05328159306639

Epoch: 6| Step: 9
Training loss: 1.6991819143295288
Validation loss: 2.096289934650544

Epoch: 6| Step: 10
Training loss: 1.161612868309021
Validation loss: 2.045177784017337

Epoch: 6| Step: 11
Training loss: 1.025803565979004
Validation loss: 2.0459974632468274

Epoch: 6| Step: 12
Training loss: 1.5157564878463745
Validation loss: 2.055668987253661

Epoch: 6| Step: 13
Training loss: 0.9510475993156433
Validation loss: 2.0660142642195507

Epoch: 570| Step: 0
Training loss: 1.2704691886901855
Validation loss: 2.0510053660279963

Epoch: 6| Step: 1
Training loss: 1.2640630006790161
Validation loss: 2.07066055779816

Epoch: 6| Step: 2
Training loss: 1.7618048191070557
Validation loss: 2.03321906059019

Epoch: 6| Step: 3
Training loss: 0.7253617644309998
Validation loss: 2.028918702115295

Epoch: 6| Step: 4
Training loss: 1.2397534847259521
Validation loss: 2.0737673774842293

Epoch: 6| Step: 5
Training loss: 1.3018999099731445
Validation loss: 2.0659207092818392

Epoch: 6| Step: 6
Training loss: 1.0793557167053223
Validation loss: 2.019911737852199

Epoch: 6| Step: 7
Training loss: 1.5907118320465088
Validation loss: 2.010190484344318

Epoch: 6| Step: 8
Training loss: 1.7287620306015015
Validation loss: 2.0521103335965063

Epoch: 6| Step: 9
Training loss: 0.7762356996536255
Validation loss: 1.9979352233230427

Epoch: 6| Step: 10
Training loss: 1.344367504119873
Validation loss: 2.0881540980390323

Epoch: 6| Step: 11
Training loss: 2.1688730716705322
Validation loss: 2.003766514921701

Epoch: 6| Step: 12
Training loss: 2.1152021884918213
Validation loss: 2.0555788624671196

Epoch: 6| Step: 13
Training loss: 1.3108084201812744
Validation loss: 2.0256997641696723

Epoch: 571| Step: 0
Training loss: 1.1838314533233643
Validation loss: 2.046487682609148

Epoch: 6| Step: 1
Training loss: 2.183032274246216
Validation loss: 2.0997894938274095

Epoch: 6| Step: 2
Training loss: 1.0091431140899658
Validation loss: 2.047035688995033

Epoch: 6| Step: 3
Training loss: 1.2210259437561035
Validation loss: 2.0328127671313543

Epoch: 6| Step: 4
Training loss: 1.0535527467727661
Validation loss: 1.9989207688198294

Epoch: 6| Step: 5
Training loss: 1.1597166061401367
Validation loss: 1.9939912711420367

Epoch: 6| Step: 6
Training loss: 1.5233962535858154
Validation loss: 2.0235275068590717

Epoch: 6| Step: 7
Training loss: 1.4132461547851562
Validation loss: 2.036509060090588

Epoch: 6| Step: 8
Training loss: 1.0921874046325684
Validation loss: 2.072722558052309

Epoch: 6| Step: 9
Training loss: 1.5220074653625488
Validation loss: 2.0355006776830202

Epoch: 6| Step: 10
Training loss: 2.183370590209961
Validation loss: 2.0680529917440107

Epoch: 6| Step: 11
Training loss: 1.8004769086837769
Validation loss: 2.0490423094841743

Epoch: 6| Step: 12
Training loss: 0.9078295230865479
Validation loss: 2.020945019619439

Epoch: 6| Step: 13
Training loss: 1.0017070770263672
Validation loss: 2.073419823441454

Epoch: 572| Step: 0
Training loss: 1.6122686862945557
Validation loss: 2.0305464472821964

Epoch: 6| Step: 1
Training loss: 2.083754062652588
Validation loss: 2.081113317961334

Epoch: 6| Step: 2
Training loss: 1.1589064598083496
Validation loss: 2.05005080469193

Epoch: 6| Step: 3
Training loss: 0.7063099145889282
Validation loss: 2.028597511270995

Epoch: 6| Step: 4
Training loss: 1.3446600437164307
Validation loss: 2.0319549601565123

Epoch: 6| Step: 5
Training loss: 1.2564311027526855
Validation loss: 2.019433776537577

Epoch: 6| Step: 6
Training loss: 1.7317051887512207
Validation loss: 2.055448947414275

Epoch: 6| Step: 7
Training loss: 1.2152849435806274
Validation loss: 2.039203228489045

Epoch: 6| Step: 8
Training loss: 1.4001383781433105
Validation loss: 2.068124435281241

Epoch: 6| Step: 9
Training loss: 0.6323696374893188
Validation loss: 2.0558662517096407

Epoch: 6| Step: 10
Training loss: 1.312760591506958
Validation loss: 2.057595060717675

Epoch: 6| Step: 11
Training loss: 1.5081913471221924
Validation loss: 2.0252848389328166

Epoch: 6| Step: 12
Training loss: 1.4617074728012085
Validation loss: 2.060924913293572

Epoch: 6| Step: 13
Training loss: 1.7034797668457031
Validation loss: 2.0282360430686706

Epoch: 573| Step: 0
Training loss: 1.237757921218872
Validation loss: 2.026472945367136

Epoch: 6| Step: 1
Training loss: 1.203559160232544
Validation loss: 2.102151927127633

Epoch: 6| Step: 2
Training loss: 0.8494576215744019
Validation loss: 2.0319395219126055

Epoch: 6| Step: 3
Training loss: 1.5436913967132568
Validation loss: 2.035135551165509

Epoch: 6| Step: 4
Training loss: 1.3652331829071045
Validation loss: 2.033706139492732

Epoch: 6| Step: 5
Training loss: 1.0144633054733276
Validation loss: 2.018301445950744

Epoch: 6| Step: 6
Training loss: 1.9032255411148071
Validation loss: 2.032633327668713

Epoch: 6| Step: 7
Training loss: 1.7754894495010376
Validation loss: 2.0543539652260403

Epoch: 6| Step: 8
Training loss: 1.5792325735092163
Validation loss: 2.003828788316378

Epoch: 6| Step: 9
Training loss: 1.1621984243392944
Validation loss: 2.035285985598

Epoch: 6| Step: 10
Training loss: 1.3380725383758545
Validation loss: 2.031755252551007

Epoch: 6| Step: 11
Training loss: 1.7115473747253418
Validation loss: 2.029337429231213

Epoch: 6| Step: 12
Training loss: 1.2709059715270996
Validation loss: 2.0317362662284606

Epoch: 6| Step: 13
Training loss: 2.0896525382995605
Validation loss: 2.0442738879111504

Epoch: 574| Step: 0
Training loss: 1.1510872840881348
Validation loss: 2.017316250390904

Epoch: 6| Step: 1
Training loss: 1.2800030708312988
Validation loss: 2.0842678777633177

Epoch: 6| Step: 2
Training loss: 1.913500428199768
Validation loss: 2.064209199720813

Epoch: 6| Step: 3
Training loss: 1.2912545204162598
Validation loss: 2.0759424009630756

Epoch: 6| Step: 4
Training loss: 1.0376499891281128
Validation loss: 2.0777587839352187

Epoch: 6| Step: 5
Training loss: 1.8955602645874023
Validation loss: 2.0927106334317114

Epoch: 6| Step: 6
Training loss: 1.4580092430114746
Validation loss: 2.118593967089089

Epoch: 6| Step: 7
Training loss: 0.9402720332145691
Validation loss: 2.1100041276665142

Epoch: 6| Step: 8
Training loss: 1.2570641040802002
Validation loss: 2.067418941887476

Epoch: 6| Step: 9
Training loss: 1.8336951732635498
Validation loss: 2.0662901670702043

Epoch: 6| Step: 10
Training loss: 1.8884488344192505
Validation loss: 2.080088648744809

Epoch: 6| Step: 11
Training loss: 1.0352777242660522
Validation loss: 2.0497315314508255

Epoch: 6| Step: 12
Training loss: 1.085410714149475
Validation loss: 2.0851866865670807

Epoch: 6| Step: 13
Training loss: 1.3282103538513184
Validation loss: 2.029835110069603

Epoch: 575| Step: 0
Training loss: 1.0950504541397095
Validation loss: 2.038675046736194

Epoch: 6| Step: 1
Training loss: 1.148411512374878
Validation loss: 2.077170023354151

Epoch: 6| Step: 2
Training loss: 1.5982081890106201
Validation loss: 2.013227306386476

Epoch: 6| Step: 3
Training loss: 1.421398401260376
Validation loss: 2.047624844376759

Epoch: 6| Step: 4
Training loss: 1.2106235027313232
Validation loss: 2.0382423349606094

Epoch: 6| Step: 5
Training loss: 1.772682785987854
Validation loss: 2.0402247367366666

Epoch: 6| Step: 6
Training loss: 1.0742734670639038
Validation loss: 2.079280981453516

Epoch: 6| Step: 7
Training loss: 1.6584373712539673
Validation loss: 2.0782253332035516

Epoch: 6| Step: 8
Training loss: 1.472365140914917
Validation loss: 2.0420031547546387

Epoch: 6| Step: 9
Training loss: 0.721524178981781
Validation loss: 2.026784776359476

Epoch: 6| Step: 10
Training loss: 1.0955443382263184
Validation loss: 2.0603315471321024

Epoch: 6| Step: 11
Training loss: 1.5368138551712036
Validation loss: 2.0514013844151653

Epoch: 6| Step: 12
Training loss: 1.928122639656067
Validation loss: 2.0504058868654313

Epoch: 6| Step: 13
Training loss: 1.4126925468444824
Validation loss: 2.100983094143611

Epoch: 576| Step: 0
Training loss: 1.3191170692443848
Validation loss: 2.0098135702071653

Epoch: 6| Step: 1
Training loss: 0.8148508071899414
Validation loss: 2.015006834460843

Epoch: 6| Step: 2
Training loss: 1.7085219621658325
Validation loss: 2.067924258529499

Epoch: 6| Step: 3
Training loss: 1.5938276052474976
Validation loss: 2.0521817232972834

Epoch: 6| Step: 4
Training loss: 1.384436845779419
Validation loss: 2.0228502263305006

Epoch: 6| Step: 5
Training loss: 1.3102054595947266
Validation loss: 2.013430900471185

Epoch: 6| Step: 6
Training loss: 1.0464773178100586
Validation loss: 2.0730002259695404

Epoch: 6| Step: 7
Training loss: 1.2406002283096313
Validation loss: 2.0049346108590402

Epoch: 6| Step: 8
Training loss: 1.3903589248657227
Validation loss: 2.018088804778232

Epoch: 6| Step: 9
Training loss: 1.8113343715667725
Validation loss: 2.0175900715653614

Epoch: 6| Step: 10
Training loss: 1.6411302089691162
Validation loss: 2.043412762303506

Epoch: 6| Step: 11
Training loss: 1.8407607078552246
Validation loss: 2.0217426002666516

Epoch: 6| Step: 12
Training loss: 1.0503404140472412
Validation loss: 2.0068519012902373

Epoch: 6| Step: 13
Training loss: 1.1096327304840088
Validation loss: 2.0657920606674685

Epoch: 577| Step: 0
Training loss: 1.475226640701294
Validation loss: 2.0040087238434823

Epoch: 6| Step: 1
Training loss: 1.065849781036377
Validation loss: 2.033203632600846

Epoch: 6| Step: 2
Training loss: 1.2550945281982422
Validation loss: 2.0468080402702413

Epoch: 6| Step: 3
Training loss: 1.6600691080093384
Validation loss: 2.016080238485849

Epoch: 6| Step: 4
Training loss: 1.9867653846740723
Validation loss: 2.0708327677942093

Epoch: 6| Step: 5
Training loss: 1.648435354232788
Validation loss: 2.026659224622993

Epoch: 6| Step: 6
Training loss: 1.262075424194336
Validation loss: 1.9969328475254837

Epoch: 6| Step: 7
Training loss: 0.947144091129303
Validation loss: 2.0414273790133897

Epoch: 6| Step: 8
Training loss: 0.9698306918144226
Validation loss: 2.0573990280910204

Epoch: 6| Step: 9
Training loss: 1.4996289014816284
Validation loss: 1.9845891819205335

Epoch: 6| Step: 10
Training loss: 1.2889132499694824
Validation loss: 2.07833452891278

Epoch: 6| Step: 11
Training loss: 1.7433280944824219
Validation loss: 2.0484640265023835

Epoch: 6| Step: 12
Training loss: 1.3477704524993896
Validation loss: 2.051783732188645

Epoch: 6| Step: 13
Training loss: 0.5551031231880188
Validation loss: 2.067879271763627

Epoch: 578| Step: 0
Training loss: 2.164710760116577
Validation loss: 2.0746890229563557

Epoch: 6| Step: 1
Training loss: 0.7878857851028442
Validation loss: 2.0751321059401318

Epoch: 6| Step: 2
Training loss: 1.4782180786132812
Validation loss: 2.064992603435311

Epoch: 6| Step: 3
Training loss: 1.6558403968811035
Validation loss: 2.0696204618741105

Epoch: 6| Step: 4
Training loss: 1.018164873123169
Validation loss: 2.053771975219891

Epoch: 6| Step: 5
Training loss: 1.3461978435516357
Validation loss: 2.094349262534931

Epoch: 6| Step: 6
Training loss: 1.2496767044067383
Validation loss: 2.0305493198415285

Epoch: 6| Step: 7
Training loss: 1.226830005645752
Validation loss: 2.04715621343223

Epoch: 6| Step: 8
Training loss: 0.9193794131278992
Validation loss: 2.0358011722564697

Epoch: 6| Step: 9
Training loss: 1.2675343751907349
Validation loss: 2.0352427908169326

Epoch: 6| Step: 10
Training loss: 1.5704255104064941
Validation loss: 2.0251411161115094

Epoch: 6| Step: 11
Training loss: 1.5354351997375488
Validation loss: 2.032633468668948

Epoch: 6| Step: 12
Training loss: 1.6002687215805054
Validation loss: 2.0462118733313774

Epoch: 6| Step: 13
Training loss: 1.5386524200439453
Validation loss: 2.023718427586299

Epoch: 579| Step: 0
Training loss: 1.0805284976959229
Validation loss: 2.01071870967906

Epoch: 6| Step: 1
Training loss: 1.6149370670318604
Validation loss: 2.0576423368146344

Epoch: 6| Step: 2
Training loss: 0.8136906027793884
Validation loss: 2.056481910008256

Epoch: 6| Step: 3
Training loss: 1.6098902225494385
Validation loss: 2.0292582396538026

Epoch: 6| Step: 4
Training loss: 1.4841725826263428
Validation loss: 2.078238553898309

Epoch: 6| Step: 5
Training loss: 1.4850788116455078
Validation loss: 2.058538002352561

Epoch: 6| Step: 6
Training loss: 1.5740312337875366
Validation loss: 2.031111151941361

Epoch: 6| Step: 7
Training loss: 2.1993260383605957
Validation loss: 2.0451160964145454

Epoch: 6| Step: 8
Training loss: 1.0677549839019775
Validation loss: 2.0780496058925504

Epoch: 6| Step: 9
Training loss: 1.236188530921936
Validation loss: 2.084240145580743

Epoch: 6| Step: 10
Training loss: 1.376836895942688
Validation loss: 2.0582567722566667

Epoch: 6| Step: 11
Training loss: 1.413245439529419
Validation loss: 2.0458327326723325

Epoch: 6| Step: 12
Training loss: 1.3951389789581299
Validation loss: 1.9973560494761313

Epoch: 6| Step: 13
Training loss: 0.8943727016448975
Validation loss: 2.0157146300038984

Epoch: 580| Step: 0
Training loss: 1.3729385137557983
Validation loss: 2.043125298715407

Epoch: 6| Step: 1
Training loss: 1.269249677658081
Validation loss: 2.037352531186996

Epoch: 6| Step: 2
Training loss: 1.373048186302185
Validation loss: 2.0275180391086045

Epoch: 6| Step: 3
Training loss: 1.9169920682907104
Validation loss: 2.0727333791794313

Epoch: 6| Step: 4
Training loss: 1.0666701793670654
Validation loss: 1.9932396937442083

Epoch: 6| Step: 5
Training loss: 1.4652767181396484
Validation loss: 2.0221645742334347

Epoch: 6| Step: 6
Training loss: 1.2000885009765625
Validation loss: 2.031376765620324

Epoch: 6| Step: 7
Training loss: 1.5913256406784058
Validation loss: 1.9950793827733686

Epoch: 6| Step: 8
Training loss: 1.292755365371704
Validation loss: 2.0481916909576743

Epoch: 6| Step: 9
Training loss: 1.3771114349365234
Validation loss: 2.01553911419325

Epoch: 6| Step: 10
Training loss: 1.265770673751831
Validation loss: 2.043019494702739

Epoch: 6| Step: 11
Training loss: 1.4741004705429077
Validation loss: 2.023496250952444

Epoch: 6| Step: 12
Training loss: 1.357356309890747
Validation loss: 2.0503547806893625

Epoch: 6| Step: 13
Training loss: 1.483449101448059
Validation loss: 2.0598126867766022

Epoch: 581| Step: 0
Training loss: 1.3403148651123047
Validation loss: 1.984975766110164

Epoch: 6| Step: 1
Training loss: 1.6764726638793945
Validation loss: 2.0359543074843702

Epoch: 6| Step: 2
Training loss: 1.345766544342041
Validation loss: 2.0079111130006853

Epoch: 6| Step: 3
Training loss: 1.5089714527130127
Validation loss: 2.064915572443316

Epoch: 6| Step: 4
Training loss: 1.0465326309204102
Validation loss: 2.0489143786891812

Epoch: 6| Step: 5
Training loss: 1.7323722839355469
Validation loss: 2.0342409251838602

Epoch: 6| Step: 6
Training loss: 1.3651645183563232
Validation loss: 2.03288278015711

Epoch: 6| Step: 7
Training loss: 1.783071517944336
Validation loss: 2.0276937536014024

Epoch: 6| Step: 8
Training loss: 1.2952711582183838
Validation loss: 2.0417314806292133

Epoch: 6| Step: 9
Training loss: 1.7474069595336914
Validation loss: 2.0354275049701815

Epoch: 6| Step: 10
Training loss: 1.6075196266174316
Validation loss: 2.0488214902980353

Epoch: 6| Step: 11
Training loss: 0.7045974135398865
Validation loss: 2.0174189690620667

Epoch: 6| Step: 12
Training loss: 1.0160253047943115
Validation loss: 2.044742415028234

Epoch: 6| Step: 13
Training loss: 1.3245068788528442
Validation loss: 2.057567870745095

Epoch: 582| Step: 0
Training loss: 1.6889925003051758
Validation loss: 2.075544898227979

Epoch: 6| Step: 1
Training loss: 1.3471330404281616
Validation loss: 2.102739526379493

Epoch: 6| Step: 2
Training loss: 1.4588618278503418
Validation loss: 2.0969697019105316

Epoch: 6| Step: 3
Training loss: 1.6866776943206787
Validation loss: 2.0851163633408083

Epoch: 6| Step: 4
Training loss: 1.3030691146850586
Validation loss: 2.137713422057449

Epoch: 6| Step: 5
Training loss: 1.6862174272537231
Validation loss: 2.126514591196532

Epoch: 6| Step: 6
Training loss: 1.1729170083999634
Validation loss: 2.133746685520295

Epoch: 6| Step: 7
Training loss: 0.9470663070678711
Validation loss: 2.108688437810508

Epoch: 6| Step: 8
Training loss: 1.1654300689697266
Validation loss: 2.1603139702991774

Epoch: 6| Step: 9
Training loss: 2.2700107097625732
Validation loss: 2.151615874741667

Epoch: 6| Step: 10
Training loss: 0.8287506103515625
Validation loss: 2.096108671157591

Epoch: 6| Step: 11
Training loss: 1.1265062093734741
Validation loss: 2.105460766823061

Epoch: 6| Step: 12
Training loss: 1.8074440956115723
Validation loss: 2.0914171639309136

Epoch: 6| Step: 13
Training loss: 0.8710930347442627
Validation loss: 2.071315585926015

Epoch: 583| Step: 0
Training loss: 0.995183527469635
Validation loss: 2.0129463685456144

Epoch: 6| Step: 1
Training loss: 1.8386940956115723
Validation loss: 2.0471525269169963

Epoch: 6| Step: 2
Training loss: 1.0861146450042725
Validation loss: 2.004540865139295

Epoch: 6| Step: 3
Training loss: 1.7347958087921143
Validation loss: 2.030437497682469

Epoch: 6| Step: 4
Training loss: 1.4206712245941162
Validation loss: 2.0478739687191543

Epoch: 6| Step: 5
Training loss: 1.4146080017089844
Validation loss: 2.0097607951010428

Epoch: 6| Step: 6
Training loss: 1.6249067783355713
Validation loss: 2.005829447059221

Epoch: 6| Step: 7
Training loss: 1.4551377296447754
Validation loss: 2.0275025316464004

Epoch: 6| Step: 8
Training loss: 1.1996502876281738
Validation loss: 2.0105243549552014

Epoch: 6| Step: 9
Training loss: 1.929416537284851
Validation loss: 1.9936677640484226

Epoch: 6| Step: 10
Training loss: 1.0151246786117554
Validation loss: 2.0572044285394813

Epoch: 6| Step: 11
Training loss: 1.409811019897461
Validation loss: 2.0195375232286352

Epoch: 6| Step: 12
Training loss: 1.6575632095336914
Validation loss: 1.9887887354820006

Epoch: 6| Step: 13
Training loss: 0.8194457292556763
Validation loss: 2.0110631732530493

Epoch: 584| Step: 0
Training loss: 1.4071615934371948
Validation loss: 2.0126497540422665

Epoch: 6| Step: 1
Training loss: 1.511867880821228
Validation loss: 2.0517588482108167

Epoch: 6| Step: 2
Training loss: 1.5265871286392212
Validation loss: 2.016596132709134

Epoch: 6| Step: 3
Training loss: 1.461671233177185
Validation loss: 2.069745902092226

Epoch: 6| Step: 4
Training loss: 1.3362609148025513
Validation loss: 2.0536909308484805

Epoch: 6| Step: 5
Training loss: 1.450225591659546
Validation loss: 2.07165450690895

Epoch: 6| Step: 6
Training loss: 1.0053058862686157
Validation loss: 2.1336247972262803

Epoch: 6| Step: 7
Training loss: 1.2947031259536743
Validation loss: 2.150701048553631

Epoch: 6| Step: 8
Training loss: 1.3487132787704468
Validation loss: 2.047558061538204

Epoch: 6| Step: 9
Training loss: 1.8411136865615845
Validation loss: 2.0414814949035645

Epoch: 6| Step: 10
Training loss: 1.3529925346374512
Validation loss: 2.039701420773742

Epoch: 6| Step: 11
Training loss: 1.2353824377059937
Validation loss: 2.041693918166622

Epoch: 6| Step: 12
Training loss: 1.3562450408935547
Validation loss: 2.038665217737998

Epoch: 6| Step: 13
Training loss: 1.098686695098877
Validation loss: 2.0616108832820768

Epoch: 585| Step: 0
Training loss: 1.30349600315094
Validation loss: 2.0405429819578766

Epoch: 6| Step: 1
Training loss: 1.86496901512146
Validation loss: 2.081279491865507

Epoch: 6| Step: 2
Training loss: 1.105832576751709
Validation loss: 2.0376162631537325

Epoch: 6| Step: 3
Training loss: 2.1536951065063477
Validation loss: 2.0753230253855386

Epoch: 6| Step: 4
Training loss: 1.0288246870040894
Validation loss: 2.0246302620057137

Epoch: 6| Step: 5
Training loss: 1.3681869506835938
Validation loss: 2.036123557757306

Epoch: 6| Step: 6
Training loss: 1.7048137187957764
Validation loss: 2.000625700078985

Epoch: 6| Step: 7
Training loss: 1.1843266487121582
Validation loss: 2.0118002558267243

Epoch: 6| Step: 8
Training loss: 1.4434584379196167
Validation loss: 2.03077297313239

Epoch: 6| Step: 9
Training loss: 1.0526704788208008
Validation loss: 2.0037925243377686

Epoch: 6| Step: 10
Training loss: 1.1811648607254028
Validation loss: 2.041136044327931

Epoch: 6| Step: 11
Training loss: 1.2836791276931763
Validation loss: 2.0643761260535127

Epoch: 6| Step: 12
Training loss: 1.3740521669387817
Validation loss: 2.0704460733680317

Epoch: 6| Step: 13
Training loss: 0.438740074634552
Validation loss: 1.9937175396950013

Epoch: 586| Step: 0
Training loss: 1.8880665302276611
Validation loss: 2.0465767921939975

Epoch: 6| Step: 1
Training loss: 1.051369309425354
Validation loss: 2.06657604248293

Epoch: 6| Step: 2
Training loss: 1.8577123880386353
Validation loss: 2.06261137993105

Epoch: 6| Step: 3
Training loss: 1.6336524486541748
Validation loss: 2.0645499549886233

Epoch: 6| Step: 4
Training loss: 1.2300982475280762
Validation loss: 2.125694992721722

Epoch: 6| Step: 5
Training loss: 1.0592105388641357
Validation loss: 2.124063230329944

Epoch: 6| Step: 6
Training loss: 1.8312289714813232
Validation loss: 2.089978139887574

Epoch: 6| Step: 7
Training loss: 1.467587947845459
Validation loss: 2.1094024309548

Epoch: 6| Step: 8
Training loss: 0.8891990780830383
Validation loss: 2.0827851603108067

Epoch: 6| Step: 9
Training loss: 1.2897034883499146
Validation loss: 2.0674163410740514

Epoch: 6| Step: 10
Training loss: 1.1317710876464844
Validation loss: 2.0665649906281502

Epoch: 6| Step: 11
Training loss: 0.8331519961357117
Validation loss: 2.0722240760762203

Epoch: 6| Step: 12
Training loss: 1.8041677474975586
Validation loss: 2.0084639415946057

Epoch: 6| Step: 13
Training loss: 1.1573641300201416
Validation loss: 2.0026079890548543

Epoch: 587| Step: 0
Training loss: 1.1805917024612427
Validation loss: 2.024835253274569

Epoch: 6| Step: 1
Training loss: 1.1519825458526611
Validation loss: 2.0187706434598534

Epoch: 6| Step: 2
Training loss: 1.6712393760681152
Validation loss: 2.0092668046233473

Epoch: 6| Step: 3
Training loss: 1.6943938732147217
Validation loss: 2.0143616032856766

Epoch: 6| Step: 4
Training loss: 1.778849482536316
Validation loss: 2.0710044009711153

Epoch: 6| Step: 5
Training loss: 1.8755943775177002
Validation loss: 2.0312290294196016

Epoch: 6| Step: 6
Training loss: 1.3122657537460327
Validation loss: 2.0044700535394813

Epoch: 6| Step: 7
Training loss: 0.623282790184021
Validation loss: 2.077723568485629

Epoch: 6| Step: 8
Training loss: 1.2811909914016724
Validation loss: 2.0398216529559066

Epoch: 6| Step: 9
Training loss: 1.356618881225586
Validation loss: 2.0214304334373883

Epoch: 6| Step: 10
Training loss: 1.2763391733169556
Validation loss: 2.0130912565415904

Epoch: 6| Step: 11
Training loss: 0.9039558172225952
Validation loss: 2.042538740301645

Epoch: 6| Step: 12
Training loss: 1.449688196182251
Validation loss: 2.042930392808812

Epoch: 6| Step: 13
Training loss: 1.6443911790847778
Validation loss: 2.0339058291527534

Epoch: 588| Step: 0
Training loss: 1.7032172679901123
Validation loss: 2.0036690606865832

Epoch: 6| Step: 1
Training loss: 1.1937260627746582
Validation loss: 2.0315769949266986

Epoch: 6| Step: 2
Training loss: 1.2415542602539062
Validation loss: 2.022199325664069

Epoch: 6| Step: 3
Training loss: 1.7751853466033936
Validation loss: 2.0266748461672055

Epoch: 6| Step: 4
Training loss: 1.5222246646881104
Validation loss: 2.067158906690536

Epoch: 6| Step: 5
Training loss: 1.6136722564697266
Validation loss: 2.0431872721641295

Epoch: 6| Step: 6
Training loss: 0.9996218085289001
Validation loss: 2.042275624890481

Epoch: 6| Step: 7
Training loss: 0.7954901456832886
Validation loss: 2.0654191740097536

Epoch: 6| Step: 8
Training loss: 1.4498944282531738
Validation loss: 2.062806878038632

Epoch: 6| Step: 9
Training loss: 1.1725637912750244
Validation loss: 2.0867009265448457

Epoch: 6| Step: 10
Training loss: 1.3167788982391357
Validation loss: 2.088718318170117

Epoch: 6| Step: 11
Training loss: 0.8144189119338989
Validation loss: 2.0337422842620523

Epoch: 6| Step: 12
Training loss: 1.7967373132705688
Validation loss: 2.042935181689519

Epoch: 6| Step: 13
Training loss: 1.546196460723877
Validation loss: 2.05464332847185

Epoch: 589| Step: 0
Training loss: 1.4274603128433228
Validation loss: 2.0363763852785994

Epoch: 6| Step: 1
Training loss: 1.0279462337493896
Validation loss: 2.0509923863154587

Epoch: 6| Step: 2
Training loss: 1.6614680290222168
Validation loss: 2.004632615273999

Epoch: 6| Step: 3
Training loss: 1.415292501449585
Validation loss: 2.034023654076361

Epoch: 6| Step: 4
Training loss: 1.1466559171676636
Validation loss: 2.0091616825390886

Epoch: 6| Step: 5
Training loss: 1.0005502700805664
Validation loss: 2.038755402770094

Epoch: 6| Step: 6
Training loss: 0.9760926961898804
Validation loss: 2.040567869781166

Epoch: 6| Step: 7
Training loss: 1.1452763080596924
Validation loss: 2.0440312034340313

Epoch: 6| Step: 8
Training loss: 1.3002238273620605
Validation loss: 2.0390529017294607

Epoch: 6| Step: 9
Training loss: 1.6480635404586792
Validation loss: 2.056424461385255

Epoch: 6| Step: 10
Training loss: 1.0484675168991089
Validation loss: 2.034325365097292

Epoch: 6| Step: 11
Training loss: 1.5373733043670654
Validation loss: 2.041558113149417

Epoch: 6| Step: 12
Training loss: 1.8840346336364746
Validation loss: 2.008649023630286

Epoch: 6| Step: 13
Training loss: 1.5703043937683105
Validation loss: 2.060006559536021

Epoch: 590| Step: 0
Training loss: 1.7342619895935059
Validation loss: 2.046078330727034

Epoch: 6| Step: 1
Training loss: 0.6959769129753113
Validation loss: 2.0483909191623813

Epoch: 6| Step: 2
Training loss: 1.1286466121673584
Validation loss: 2.071642662889214

Epoch: 6| Step: 3
Training loss: 1.9801945686340332
Validation loss: 2.028134105026081

Epoch: 6| Step: 4
Training loss: 1.8658885955810547
Validation loss: 2.0460664995255007

Epoch: 6| Step: 5
Training loss: 1.8499561548233032
Validation loss: 2.087800928341445

Epoch: 6| Step: 6
Training loss: 1.1225616931915283
Validation loss: 2.0562669179772817

Epoch: 6| Step: 7
Training loss: 1.2385547161102295
Validation loss: 2.1216826951631935

Epoch: 6| Step: 8
Training loss: 0.8711421489715576
Validation loss: 2.0400501220457015

Epoch: 6| Step: 9
Training loss: 1.0293471813201904
Validation loss: 2.094265966005223

Epoch: 6| Step: 10
Training loss: 1.3856152296066284
Validation loss: 2.0617643928015106

Epoch: 6| Step: 11
Training loss: 1.2134307622909546
Validation loss: 2.066063807856652

Epoch: 6| Step: 12
Training loss: 1.0866036415100098
Validation loss: 2.0580640531355336

Epoch: 6| Step: 13
Training loss: 1.2581896781921387
Validation loss: 2.039223873487083

Epoch: 591| Step: 0
Training loss: 1.1975090503692627
Validation loss: 2.0490309064106276

Epoch: 6| Step: 1
Training loss: 1.4535465240478516
Validation loss: 2.0217274978596675

Epoch: 6| Step: 2
Training loss: 0.6759850978851318
Validation loss: 2.034716858658739

Epoch: 6| Step: 3
Training loss: 1.026059627532959
Validation loss: 2.0184202732578402

Epoch: 6| Step: 4
Training loss: 1.8594741821289062
Validation loss: 2.0786892739675378

Epoch: 6| Step: 5
Training loss: 1.0955009460449219
Validation loss: 2.025777942390852

Epoch: 6| Step: 6
Training loss: 1.9556798934936523
Validation loss: 2.0084839405552035

Epoch: 6| Step: 7
Training loss: 1.4285128116607666
Validation loss: 2.027681312253398

Epoch: 6| Step: 8
Training loss: 1.705193042755127
Validation loss: 2.0102182742088073

Epoch: 6| Step: 9
Training loss: 1.2417426109313965
Validation loss: 2.0412152480053645

Epoch: 6| Step: 10
Training loss: 1.6080255508422852
Validation loss: 2.0583889356223484

Epoch: 6| Step: 11
Training loss: 1.3614537715911865
Validation loss: 2.064778802215412

Epoch: 6| Step: 12
Training loss: 0.899590790271759
Validation loss: 2.0672188215358283

Epoch: 6| Step: 13
Training loss: 1.3619916439056396
Validation loss: 2.0463029979377665

Epoch: 592| Step: 0
Training loss: 1.2643835544586182
Validation loss: 2.080681877751504

Epoch: 6| Step: 1
Training loss: 1.5036019086837769
Validation loss: 2.0774480770992976

Epoch: 6| Step: 2
Training loss: 0.7652444243431091
Validation loss: 2.0334312351801063

Epoch: 6| Step: 3
Training loss: 1.6684080362319946
Validation loss: 2.0473162345988776

Epoch: 6| Step: 4
Training loss: 1.0780531167984009
Validation loss: 2.0211120972069363

Epoch: 6| Step: 5
Training loss: 1.2153207063674927
Validation loss: 2.0023826283793293

Epoch: 6| Step: 6
Training loss: 1.544769525527954
Validation loss: 2.0377289249051

Epoch: 6| Step: 7
Training loss: 0.9917096495628357
Validation loss: 2.0319696241809475

Epoch: 6| Step: 8
Training loss: 1.1242656707763672
Validation loss: 2.067558491101829

Epoch: 6| Step: 9
Training loss: 1.8649446964263916
Validation loss: 2.0274642693099154

Epoch: 6| Step: 10
Training loss: 1.8658989667892456
Validation loss: 2.0754605147146408

Epoch: 6| Step: 11
Training loss: 1.197082281112671
Validation loss: 2.079248619335954

Epoch: 6| Step: 12
Training loss: 1.1915507316589355
Validation loss: 2.044344658492714

Epoch: 6| Step: 13
Training loss: 1.990342617034912
Validation loss: 2.068686915982154

Epoch: 593| Step: 0
Training loss: 0.8792970180511475
Validation loss: 2.06724299153974

Epoch: 6| Step: 1
Training loss: 1.0400946140289307
Validation loss: 2.029998322968842

Epoch: 6| Step: 2
Training loss: 1.3023583889007568
Validation loss: 2.0088333058100876

Epoch: 6| Step: 3
Training loss: 0.8381457924842834
Validation loss: 2.0599242230897308

Epoch: 6| Step: 4
Training loss: 1.5078097581863403
Validation loss: 2.0422905234880346

Epoch: 6| Step: 5
Training loss: 1.3841381072998047
Validation loss: 2.0099610077437533

Epoch: 6| Step: 6
Training loss: 1.4951192140579224
Validation loss: 2.06218905602732

Epoch: 6| Step: 7
Training loss: 1.2066805362701416
Validation loss: 2.0222012586491083

Epoch: 6| Step: 8
Training loss: 1.9309002161026
Validation loss: 2.0201153973097443

Epoch: 6| Step: 9
Training loss: 1.5277459621429443
Validation loss: 2.0560634431018623

Epoch: 6| Step: 10
Training loss: 1.3175477981567383
Validation loss: 2.0530913978494625

Epoch: 6| Step: 11
Training loss: 1.5157279968261719
Validation loss: 2.0292012806861632

Epoch: 6| Step: 12
Training loss: 1.5350885391235352
Validation loss: 2.0354364533578195

Epoch: 6| Step: 13
Training loss: 1.189353108406067
Validation loss: 2.039063745929349

Epoch: 594| Step: 0
Training loss: 1.7712421417236328
Validation loss: 2.043113115013287

Epoch: 6| Step: 1
Training loss: 1.035292148590088
Validation loss: 2.0695262673080608

Epoch: 6| Step: 2
Training loss: 1.4509541988372803
Validation loss: 2.025595224031838

Epoch: 6| Step: 3
Training loss: 1.6484804153442383
Validation loss: 2.0855726195919897

Epoch: 6| Step: 4
Training loss: 1.4322290420532227
Validation loss: 2.1279407111547326

Epoch: 6| Step: 5
Training loss: 1.6879031658172607
Validation loss: 2.057717446357973

Epoch: 6| Step: 6
Training loss: 1.9651390314102173
Validation loss: 2.092650446840512

Epoch: 6| Step: 7
Training loss: 1.4559547901153564
Validation loss: 2.050020420423118

Epoch: 6| Step: 8
Training loss: 1.1299552917480469
Validation loss: 2.060328486145184

Epoch: 6| Step: 9
Training loss: 1.133025884628296
Validation loss: 2.106391427337482

Epoch: 6| Step: 10
Training loss: 1.556433916091919
Validation loss: 2.0665695872358096

Epoch: 6| Step: 11
Training loss: 0.8158403635025024
Validation loss: 2.063932967442338

Epoch: 6| Step: 12
Training loss: 0.8247435092926025
Validation loss: 2.0309970378875732

Epoch: 6| Step: 13
Training loss: 0.6184524893760681
Validation loss: 2.064830131428216

Epoch: 595| Step: 0
Training loss: 1.3727202415466309
Validation loss: 2.0385066950193016

Epoch: 6| Step: 1
Training loss: 1.3161911964416504
Validation loss: 2.0349976298629597

Epoch: 6| Step: 2
Training loss: 1.2213213443756104
Validation loss: 2.029175744261793

Epoch: 6| Step: 3
Training loss: 1.4788364171981812
Validation loss: 2.0253208580837456

Epoch: 6| Step: 4
Training loss: 1.3166447877883911
Validation loss: 2.0136223300810783

Epoch: 6| Step: 5
Training loss: 1.341381549835205
Validation loss: 2.0411106181401077

Epoch: 6| Step: 6
Training loss: 1.4796041250228882
Validation loss: 2.0315416756496636

Epoch: 6| Step: 7
Training loss: 1.5061182975769043
Validation loss: 2.018731845322476

Epoch: 6| Step: 8
Training loss: 1.5433379411697388
Validation loss: 2.086901334024245

Epoch: 6| Step: 9
Training loss: 1.8136625289916992
Validation loss: 2.055536357305383

Epoch: 6| Step: 10
Training loss: 1.5704938173294067
Validation loss: 2.045347677764072

Epoch: 6| Step: 11
Training loss: 0.9363248944282532
Validation loss: 2.0376476036605013

Epoch: 6| Step: 12
Training loss: 0.9392081499099731
Validation loss: 2.089454253514608

Epoch: 6| Step: 13
Training loss: 0.9616597294807434
Validation loss: 2.0345976980783607

Epoch: 596| Step: 0
Training loss: 1.2150039672851562
Validation loss: 1.9985919652446624

Epoch: 6| Step: 1
Training loss: 0.5808840990066528
Validation loss: 2.0150606837323917

Epoch: 6| Step: 2
Training loss: 1.3431036472320557
Validation loss: 2.053926916532619

Epoch: 6| Step: 3
Training loss: 1.5473034381866455
Validation loss: 2.034832849297472

Epoch: 6| Step: 4
Training loss: 1.4871301651000977
Validation loss: 2.0121967356692076

Epoch: 6| Step: 5
Training loss: 1.2386747598648071
Validation loss: 1.9847142132379676

Epoch: 6| Step: 6
Training loss: 1.1822600364685059
Validation loss: 1.956422444312803

Epoch: 6| Step: 7
Training loss: 1.0542774200439453
Validation loss: 2.040921905989288

Epoch: 6| Step: 8
Training loss: 1.7564561367034912
Validation loss: 1.990500186079292

Epoch: 6| Step: 9
Training loss: 0.9627050161361694
Validation loss: 2.0068834109972884

Epoch: 6| Step: 10
Training loss: 1.8442237377166748
Validation loss: 2.020968967868436

Epoch: 6| Step: 11
Training loss: 1.6383979320526123
Validation loss: 2.0569202951205674

Epoch: 6| Step: 12
Training loss: 1.5127328634262085
Validation loss: 1.9966218163890224

Epoch: 6| Step: 13
Training loss: 1.8055739402770996
Validation loss: 1.9903286657025736

Epoch: 597| Step: 0
Training loss: 1.361833930015564
Validation loss: 2.001238710136824

Epoch: 6| Step: 1
Training loss: 1.6999239921569824
Validation loss: 2.0166151433862667

Epoch: 6| Step: 2
Training loss: 1.7522510290145874
Validation loss: 1.9973806091534194

Epoch: 6| Step: 3
Training loss: 1.0459675788879395
Validation loss: 2.073713078293749

Epoch: 6| Step: 4
Training loss: 2.1277098655700684
Validation loss: 2.03336662630881

Epoch: 6| Step: 5
Training loss: 1.0387685298919678
Validation loss: 2.0559584286905106

Epoch: 6| Step: 6
Training loss: 1.1033897399902344
Validation loss: 2.003119073888307

Epoch: 6| Step: 7
Training loss: 1.6717700958251953
Validation loss: 2.073413274621451

Epoch: 6| Step: 8
Training loss: 1.0865287780761719
Validation loss: 2.027633003009263

Epoch: 6| Step: 9
Training loss: 1.1423120498657227
Validation loss: 2.038376851748395

Epoch: 6| Step: 10
Training loss: 1.4694510698318481
Validation loss: 2.0258729175854753

Epoch: 6| Step: 11
Training loss: 1.2366576194763184
Validation loss: 2.0734163432992916

Epoch: 6| Step: 12
Training loss: 0.5927879214286804
Validation loss: 2.079263582024523

Epoch: 6| Step: 13
Training loss: 1.232680082321167
Validation loss: 2.0361518308680546

Epoch: 598| Step: 0
Training loss: 0.8432954549789429
Validation loss: 2.060441429897021

Epoch: 6| Step: 1
Training loss: 1.2323405742645264
Validation loss: 2.078924213686297

Epoch: 6| Step: 2
Training loss: 1.3559067249298096
Validation loss: 2.0731208080886514

Epoch: 6| Step: 3
Training loss: 0.8376753330230713
Validation loss: 2.0201148615088513

Epoch: 6| Step: 4
Training loss: 2.3988616466522217
Validation loss: 1.9898946964612572

Epoch: 6| Step: 5
Training loss: 1.1202921867370605
Validation loss: 2.007556276936685

Epoch: 6| Step: 6
Training loss: 1.2308664321899414
Validation loss: 2.066424959449358

Epoch: 6| Step: 7
Training loss: 1.4563742876052856
Validation loss: 2.03015657137799

Epoch: 6| Step: 8
Training loss: 1.160164475440979
Validation loss: 2.054816234496332

Epoch: 6| Step: 9
Training loss: 1.4135925769805908
Validation loss: 1.9849359655892977

Epoch: 6| Step: 10
Training loss: 2.1355581283569336
Validation loss: 1.9804641559559812

Epoch: 6| Step: 11
Training loss: 1.2846930027008057
Validation loss: 2.014128479906308

Epoch: 6| Step: 12
Training loss: 1.2811291217803955
Validation loss: 2.0077590903928204

Epoch: 6| Step: 13
Training loss: 1.07462477684021
Validation loss: 2.0159878051409157

Epoch: 599| Step: 0
Training loss: 1.7215063571929932
Validation loss: 2.03622466774397

Epoch: 6| Step: 1
Training loss: 1.3587613105773926
Validation loss: 2.0497227227816017

Epoch: 6| Step: 2
Training loss: 1.2128335237503052
Validation loss: 2.071337169216525

Epoch: 6| Step: 3
Training loss: 1.0590028762817383
Validation loss: 2.0220872689318914

Epoch: 6| Step: 4
Training loss: 1.8315088748931885
Validation loss: 2.0905232660232054

Epoch: 6| Step: 5
Training loss: 2.076326847076416
Validation loss: 2.0264100874623945

Epoch: 6| Step: 6
Training loss: 1.329930305480957
Validation loss: 2.0724820347242456

Epoch: 6| Step: 7
Training loss: 0.8693234920501709
Validation loss: 2.0710959947237404

Epoch: 6| Step: 8
Training loss: 1.4536337852478027
Validation loss: 2.07111334031628

Epoch: 6| Step: 9
Training loss: 1.233466625213623
Validation loss: 2.0176074863761984

Epoch: 6| Step: 10
Training loss: 1.0229578018188477
Validation loss: 2.059233098901728

Epoch: 6| Step: 11
Training loss: 1.6040846109390259
Validation loss: 2.001885619214786

Epoch: 6| Step: 12
Training loss: 1.122492790222168
Validation loss: 2.0762668463491623

Epoch: 6| Step: 13
Training loss: 0.9131613969802856
Validation loss: 2.066968507664178

Epoch: 600| Step: 0
Training loss: 1.1079444885253906
Validation loss: 2.038129042553645

Epoch: 6| Step: 1
Training loss: 1.2017796039581299
Validation loss: 2.067843771749927

Epoch: 6| Step: 2
Training loss: 1.681220293045044
Validation loss: 2.0175295363190355

Epoch: 6| Step: 3
Training loss: 1.0103569030761719
Validation loss: 1.9857950466935352

Epoch: 6| Step: 4
Training loss: 2.319868564605713
Validation loss: 2.0557300301008326

Epoch: 6| Step: 5
Training loss: 1.1623129844665527
Validation loss: 1.9766484742523522

Epoch: 6| Step: 6
Training loss: 0.884636402130127
Validation loss: 2.0334660173744283

Epoch: 6| Step: 7
Training loss: 0.7285785675048828
Validation loss: 1.968795955822032

Epoch: 6| Step: 8
Training loss: 1.3766839504241943
Validation loss: 2.0687747463103263

Epoch: 6| Step: 9
Training loss: 1.6542694568634033
Validation loss: 2.0162509461884857

Epoch: 6| Step: 10
Training loss: 1.682631492614746
Validation loss: 2.0320340830792665

Epoch: 6| Step: 11
Training loss: 1.448103427886963
Validation loss: 2.031724383754115

Epoch: 6| Step: 12
Training loss: 1.1211590766906738
Validation loss: 2.0283374914558987

Epoch: 6| Step: 13
Training loss: 1.050923466682434
Validation loss: 2.0313085958521855

Epoch: 601| Step: 0
Training loss: 1.7116782665252686
Validation loss: 2.054688858729537

Epoch: 6| Step: 1
Training loss: 1.4517743587493896
Validation loss: 2.060101577030715

Epoch: 6| Step: 2
Training loss: 1.461927890777588
Validation loss: 2.057825785811229

Epoch: 6| Step: 3
Training loss: 1.1151282787322998
Validation loss: 2.044881179768552

Epoch: 6| Step: 4
Training loss: 1.2440742254257202
Validation loss: 2.0750149603812926

Epoch: 6| Step: 5
Training loss: 1.1205470561981201
Validation loss: 2.0053953534813336

Epoch: 6| Step: 6
Training loss: 1.3377994298934937
Validation loss: 2.0909588003671296

Epoch: 6| Step: 7
Training loss: 0.9694480895996094
Validation loss: 2.0475216565593595

Epoch: 6| Step: 8
Training loss: 1.9364124536514282
Validation loss: 2.0236395635912494

Epoch: 6| Step: 9
Training loss: 1.2262442111968994
Validation loss: 2.02421792732772

Epoch: 6| Step: 10
Training loss: 0.8609376549720764
Validation loss: 2.063376219041886

Epoch: 6| Step: 11
Training loss: 1.5308427810668945
Validation loss: 1.995047402638261

Epoch: 6| Step: 12
Training loss: 1.2382526397705078
Validation loss: 2.036159861472345

Epoch: 6| Step: 13
Training loss: 2.0084102153778076
Validation loss: 2.006859234584275

Epoch: 602| Step: 0
Training loss: 0.8038378953933716
Validation loss: 2.0098863135101976

Epoch: 6| Step: 1
Training loss: 0.6424154043197632
Validation loss: 2.0151711792074223

Epoch: 6| Step: 2
Training loss: 1.191818118095398
Validation loss: 2.0370856895241687

Epoch: 6| Step: 3
Training loss: 1.137932538986206
Validation loss: 2.014105539168081

Epoch: 6| Step: 4
Training loss: 1.8770484924316406
Validation loss: 1.9958606432842951

Epoch: 6| Step: 5
Training loss: 1.7660367488861084
Validation loss: 2.0052112994655484

Epoch: 6| Step: 6
Training loss: 0.9307279586791992
Validation loss: 2.0032077284269434

Epoch: 6| Step: 7
Training loss: 1.493835210800171
Validation loss: 2.033576785877187

Epoch: 6| Step: 8
Training loss: 1.5068387985229492
Validation loss: 2.026566328540925

Epoch: 6| Step: 9
Training loss: 1.7789034843444824
Validation loss: 2.0317654519952755

Epoch: 6| Step: 10
Training loss: 1.7969574928283691
Validation loss: 2.074579367073633

Epoch: 6| Step: 11
Training loss: 0.9614364504814148
Validation loss: 2.018946281043432

Epoch: 6| Step: 12
Training loss: 1.5903403759002686
Validation loss: 2.0219955662245392

Epoch: 6| Step: 13
Training loss: 0.9099569320678711
Validation loss: 2.0587067424610095

Epoch: 603| Step: 0
Training loss: 1.4239757061004639
Validation loss: 1.9973164578919769

Epoch: 6| Step: 1
Training loss: 0.8618392944335938
Validation loss: 2.007656620394799

Epoch: 6| Step: 2
Training loss: 0.8162696361541748
Validation loss: 2.0464675836665656

Epoch: 6| Step: 3
Training loss: 1.6548402309417725
Validation loss: 2.0357429801776843

Epoch: 6| Step: 4
Training loss: 1.685309648513794
Validation loss: 2.0676335211723083

Epoch: 6| Step: 5
Training loss: 1.5905001163482666
Validation loss: 2.0518882556628157

Epoch: 6| Step: 6
Training loss: 1.6427549123764038
Validation loss: 2.032123924583517

Epoch: 6| Step: 7
Training loss: 1.4776389598846436
Validation loss: 2.0561717787096576

Epoch: 6| Step: 8
Training loss: 0.987919807434082
Validation loss: 2.0491540739613194

Epoch: 6| Step: 9
Training loss: 1.0512968301773071
Validation loss: 2.0162265146932294

Epoch: 6| Step: 10
Training loss: 1.5498030185699463
Validation loss: 2.0188695256428053

Epoch: 6| Step: 11
Training loss: 1.122446060180664
Validation loss: 1.9855340565404584

Epoch: 6| Step: 12
Training loss: 1.6589868068695068
Validation loss: 2.00565488876835

Epoch: 6| Step: 13
Training loss: 1.2378923892974854
Validation loss: 1.9849768941120436

Epoch: 604| Step: 0
Training loss: 1.3581832647323608
Validation loss: 2.0420011512694822

Epoch: 6| Step: 1
Training loss: 1.1727685928344727
Validation loss: 2.0382364283325853

Epoch: 6| Step: 2
Training loss: 1.244207739830017
Validation loss: 2.02681997001812

Epoch: 6| Step: 3
Training loss: 1.448205590248108
Validation loss: 2.0503717289176038

Epoch: 6| Step: 4
Training loss: 1.2518501281738281
Validation loss: 2.00825354232583

Epoch: 6| Step: 5
Training loss: 1.1465959548950195
Validation loss: 1.9975631006302372

Epoch: 6| Step: 6
Training loss: 0.853562593460083
Validation loss: 2.023070030314948

Epoch: 6| Step: 7
Training loss: 1.401397466659546
Validation loss: 2.011292355034941

Epoch: 6| Step: 8
Training loss: 1.6396561861038208
Validation loss: 2.0486893153959707

Epoch: 6| Step: 9
Training loss: 1.80799400806427
Validation loss: 2.0828087547773957

Epoch: 6| Step: 10
Training loss: 1.7578619718551636
Validation loss: 2.083579978635234

Epoch: 6| Step: 11
Training loss: 1.190351128578186
Validation loss: 2.0260888197088756

Epoch: 6| Step: 12
Training loss: 0.7932431697845459
Validation loss: 2.032134673928702

Epoch: 6| Step: 13
Training loss: 1.3158526420593262
Validation loss: 2.0307518564244753

Epoch: 605| Step: 0
Training loss: 1.451858639717102
Validation loss: 2.0054330787351056

Epoch: 6| Step: 1
Training loss: 1.2863214015960693
Validation loss: 2.0194897728581584

Epoch: 6| Step: 2
Training loss: 1.3722374439239502
Validation loss: 2.0105441142153997

Epoch: 6| Step: 3
Training loss: 1.3253517150878906
Validation loss: 2.071777432195602

Epoch: 6| Step: 4
Training loss: 1.4516881704330444
Validation loss: 1.9987286226723784

Epoch: 6| Step: 5
Training loss: 0.9365753531455994
Validation loss: 2.029257088579157

Epoch: 6| Step: 6
Training loss: 1.0225105285644531
Validation loss: 2.0199043468762468

Epoch: 6| Step: 7
Training loss: 1.0191848278045654
Validation loss: 2.0215969547148673

Epoch: 6| Step: 8
Training loss: 1.4180675745010376
Validation loss: 2.018622341976371

Epoch: 6| Step: 9
Training loss: 1.6245598793029785
Validation loss: 1.9813115340407177

Epoch: 6| Step: 10
Training loss: 1.2809336185455322
Validation loss: 2.0351008651077107

Epoch: 6| Step: 11
Training loss: 1.078538179397583
Validation loss: 2.0233974597787343

Epoch: 6| Step: 12
Training loss: 1.4671003818511963
Validation loss: 2.03823527725794

Epoch: 6| Step: 13
Training loss: 1.6205754280090332
Validation loss: 2.048530637577016

Epoch: 606| Step: 0
Training loss: 0.8799517154693604
Validation loss: 2.0279849754866732

Epoch: 6| Step: 1
Training loss: 1.4518060684204102
Validation loss: 2.0905573547527356

Epoch: 6| Step: 2
Training loss: 1.5444256067276
Validation loss: 2.0098625459978656

Epoch: 6| Step: 3
Training loss: 1.1614983081817627
Validation loss: 2.046336800821366

Epoch: 6| Step: 4
Training loss: 1.3240063190460205
Validation loss: 2.0613507429758706

Epoch: 6| Step: 5
Training loss: 1.4162302017211914
Validation loss: 2.011429132953767

Epoch: 6| Step: 6
Training loss: 1.122902512550354
Validation loss: 2.0602286656697593

Epoch: 6| Step: 7
Training loss: 1.525646686553955
Validation loss: 2.024127370567732

Epoch: 6| Step: 8
Training loss: 0.9550870656967163
Validation loss: 2.0415052803613807

Epoch: 6| Step: 9
Training loss: 1.6127870082855225
Validation loss: 2.0343053751094367

Epoch: 6| Step: 10
Training loss: 1.000252366065979
Validation loss: 2.0357665349078435

Epoch: 6| Step: 11
Training loss: 1.764999270439148
Validation loss: 2.0360125828814764

Epoch: 6| Step: 12
Training loss: 1.529691219329834
Validation loss: 2.020548451331354

Epoch: 6| Step: 13
Training loss: 1.18656587600708
Validation loss: 2.0041355471457205

Epoch: 607| Step: 0
Training loss: 1.807189702987671
Validation loss: 2.0353631409265662

Epoch: 6| Step: 1
Training loss: 1.6217851638793945
Validation loss: 2.04719776491965

Epoch: 6| Step: 2
Training loss: 1.1452178955078125
Validation loss: 2.0494719961638093

Epoch: 6| Step: 3
Training loss: 1.748400330543518
Validation loss: 2.034798588163109

Epoch: 6| Step: 4
Training loss: 1.130740761756897
Validation loss: 2.003910413352392

Epoch: 6| Step: 5
Training loss: 0.5234022736549377
Validation loss: 2.040632091542726

Epoch: 6| Step: 6
Training loss: 0.9329537153244019
Validation loss: 2.0079890604942077

Epoch: 6| Step: 7
Training loss: 1.2709293365478516
Validation loss: 2.040475171099427

Epoch: 6| Step: 8
Training loss: 1.309082269668579
Validation loss: 2.0812993382894867

Epoch: 6| Step: 9
Training loss: 1.2599750757217407
Validation loss: 2.061985454251689

Epoch: 6| Step: 10
Training loss: 1.0958552360534668
Validation loss: 2.0476930192721787

Epoch: 6| Step: 11
Training loss: 2.056809186935425
Validation loss: 2.0520129652433496

Epoch: 6| Step: 12
Training loss: 1.5155969858169556
Validation loss: 2.1070465887746503

Epoch: 6| Step: 13
Training loss: 1.504575252532959
Validation loss: 2.0396758920402935

Epoch: 608| Step: 0
Training loss: 2.0056862831115723
Validation loss: 2.0920326145746375

Epoch: 6| Step: 1
Training loss: 1.2851409912109375
Validation loss: 2.0586847271970523

Epoch: 6| Step: 2
Training loss: 1.4923678636550903
Validation loss: 2.0530925386695453

Epoch: 6| Step: 3
Training loss: 1.79799222946167
Validation loss: 2.0855674769288752

Epoch: 6| Step: 4
Training loss: 1.158259630203247
Validation loss: 2.0296999562171196

Epoch: 6| Step: 5
Training loss: 1.0080633163452148
Validation loss: 2.0585226025632632

Epoch: 6| Step: 6
Training loss: 1.8271069526672363
Validation loss: 2.0504753589630127

Epoch: 6| Step: 7
Training loss: 1.2074341773986816
Validation loss: 2.0248691779310986

Epoch: 6| Step: 8
Training loss: 1.4076899290084839
Validation loss: 2.045624786807645

Epoch: 6| Step: 9
Training loss: 1.864908218383789
Validation loss: 2.0712545417970225

Epoch: 6| Step: 10
Training loss: 1.1314013004302979
Validation loss: 1.9910622950523131

Epoch: 6| Step: 11
Training loss: 0.7554812431335449
Validation loss: 1.9971725351067

Epoch: 6| Step: 12
Training loss: 1.2013030052185059
Validation loss: 2.013424014532438

Epoch: 6| Step: 13
Training loss: 0.7324350476264954
Validation loss: 2.019422690073649

Epoch: 609| Step: 0
Training loss: 0.6579744219779968
Validation loss: 2.060313391429122

Epoch: 6| Step: 1
Training loss: 1.2932815551757812
Validation loss: 2.050553421820364

Epoch: 6| Step: 2
Training loss: 0.9603226184844971
Validation loss: 2.093592366864604

Epoch: 6| Step: 3
Training loss: 1.0357723236083984
Validation loss: 2.048380349272041

Epoch: 6| Step: 4
Training loss: 1.5233769416809082
Validation loss: 2.0690651298851095

Epoch: 6| Step: 5
Training loss: 1.8523797988891602
Validation loss: 2.02605926862327

Epoch: 6| Step: 6
Training loss: 1.4028103351593018
Validation loss: 2.0628805288704495

Epoch: 6| Step: 7
Training loss: 1.5110982656478882
Validation loss: 2.016106629884371

Epoch: 6| Step: 8
Training loss: 1.967149257659912
Validation loss: 2.0511764070039153

Epoch: 6| Step: 9
Training loss: 1.080512523651123
Validation loss: 2.076668099690509

Epoch: 6| Step: 10
Training loss: 0.9119834899902344
Validation loss: 2.069356278706622

Epoch: 6| Step: 11
Training loss: 1.676530361175537
Validation loss: 2.059683338288338

Epoch: 6| Step: 12
Training loss: 1.3679306507110596
Validation loss: 2.0072116428805935

Epoch: 6| Step: 13
Training loss: 1.4834520816802979
Validation loss: 2.016047372612902

Epoch: 610| Step: 0
Training loss: 1.5421807765960693
Validation loss: 2.0233688226310154

Epoch: 6| Step: 1
Training loss: 1.273247480392456
Validation loss: 2.0401729999050016

Epoch: 6| Step: 2
Training loss: 1.2945494651794434
Validation loss: 2.0581080131633307

Epoch: 6| Step: 3
Training loss: 1.0290658473968506
Validation loss: 2.009121384671939

Epoch: 6| Step: 4
Training loss: 1.6654669046401978
Validation loss: 2.015200827070462

Epoch: 6| Step: 5
Training loss: 1.3985369205474854
Validation loss: 2.010335168530864

Epoch: 6| Step: 6
Training loss: 0.9788646101951599
Validation loss: 1.96256439147457

Epoch: 6| Step: 7
Training loss: 1.5487401485443115
Validation loss: 2.02966332691972

Epoch: 6| Step: 8
Training loss: 1.2409617900848389
Validation loss: 2.050636563249814

Epoch: 6| Step: 9
Training loss: 0.7696093320846558
Validation loss: 2.0003473092150945

Epoch: 6| Step: 10
Training loss: 1.0378206968307495
Validation loss: 1.9567699022190546

Epoch: 6| Step: 11
Training loss: 1.91607666015625
Validation loss: 2.0777979896914576

Epoch: 6| Step: 12
Training loss: 1.5375895500183105
Validation loss: 2.0413774046846616

Epoch: 6| Step: 13
Training loss: 1.1226004362106323
Validation loss: 2.0401950292689826

Epoch: 611| Step: 0
Training loss: 1.0275368690490723
Validation loss: 2.031258656132606

Epoch: 6| Step: 1
Training loss: 1.332188367843628
Validation loss: 2.04531789595081

Epoch: 6| Step: 2
Training loss: 0.9064429998397827
Validation loss: 2.0112413539681384

Epoch: 6| Step: 3
Training loss: 2.1030242443084717
Validation loss: 2.0740313735059512

Epoch: 6| Step: 4
Training loss: 1.7604315280914307
Validation loss: 2.0376889962022022

Epoch: 6| Step: 5
Training loss: 1.117741346359253
Validation loss: 2.0920069499682357

Epoch: 6| Step: 6
Training loss: 0.9116276502609253
Validation loss: 2.0842851028647473

Epoch: 6| Step: 7
Training loss: 1.4772909879684448
Validation loss: 2.0102449194077523

Epoch: 6| Step: 8
Training loss: 1.1581705808639526
Validation loss: 2.0537364611061673

Epoch: 6| Step: 9
Training loss: 1.35028076171875
Validation loss: 2.0403852437132146

Epoch: 6| Step: 10
Training loss: 0.795116126537323
Validation loss: 2.046486487952612

Epoch: 6| Step: 11
Training loss: 1.4246007204055786
Validation loss: 2.000864258376501

Epoch: 6| Step: 12
Training loss: 2.069819450378418
Validation loss: 2.046996984430539

Epoch: 6| Step: 13
Training loss: 1.1755534410476685
Validation loss: 2.017883858373088

Epoch: 612| Step: 0
Training loss: 2.023059129714966
Validation loss: 1.9977124147517706

Epoch: 6| Step: 1
Training loss: 1.9915380477905273
Validation loss: 1.9820026941196893

Epoch: 6| Step: 2
Training loss: 1.0969480276107788
Validation loss: 2.016124972733118

Epoch: 6| Step: 3
Training loss: 0.9944913387298584
Validation loss: 2.0433244653927383

Epoch: 6| Step: 4
Training loss: 0.965071976184845
Validation loss: 2.0008269612507155

Epoch: 6| Step: 5
Training loss: 1.2146968841552734
Validation loss: 2.0024814221166793

Epoch: 6| Step: 6
Training loss: 1.8208949565887451
Validation loss: 2.0663437663867907

Epoch: 6| Step: 7
Training loss: 0.8869264125823975
Validation loss: 2.0320762690677436

Epoch: 6| Step: 8
Training loss: 1.287405252456665
Validation loss: 2.019840585288181

Epoch: 6| Step: 9
Training loss: 1.5726768970489502
Validation loss: 2.0235221873047533

Epoch: 6| Step: 10
Training loss: 1.7420318126678467
Validation loss: 2.0618604818979898

Epoch: 6| Step: 11
Training loss: 1.1283211708068848
Validation loss: 2.0141001106590353

Epoch: 6| Step: 12
Training loss: 0.6282265186309814
Validation loss: 2.0482402770749983

Epoch: 6| Step: 13
Training loss: 1.332703709602356
Validation loss: 2.0251103934421333

Epoch: 613| Step: 0
Training loss: 1.4732310771942139
Validation loss: 2.013759705328172

Epoch: 6| Step: 1
Training loss: 1.244699239730835
Validation loss: 2.0663247275096115

Epoch: 6| Step: 2
Training loss: 1.0799425840377808
Validation loss: 2.0153830077058528

Epoch: 6| Step: 3
Training loss: 0.768765926361084
Validation loss: 2.048191815294245

Epoch: 6| Step: 4
Training loss: 1.5754992961883545
Validation loss: 2.0436724590998825

Epoch: 6| Step: 5
Training loss: 1.1355323791503906
Validation loss: 2.0220050850222187

Epoch: 6| Step: 6
Training loss: 1.7058930397033691
Validation loss: 2.0113420435177383

Epoch: 6| Step: 7
Training loss: 1.4720059633255005
Validation loss: 2.036436393696775

Epoch: 6| Step: 8
Training loss: 0.6022380590438843
Validation loss: 2.046869263854078

Epoch: 6| Step: 9
Training loss: 1.4966964721679688
Validation loss: 2.041128025260023

Epoch: 6| Step: 10
Training loss: 1.452928066253662
Validation loss: 2.0214216709136963

Epoch: 6| Step: 11
Training loss: 1.514209508895874
Validation loss: 2.049628396188059

Epoch: 6| Step: 12
Training loss: 1.4456686973571777
Validation loss: 2.034432480412145

Epoch: 6| Step: 13
Training loss: 1.4023473262786865
Validation loss: 2.0578506787618003

Epoch: 614| Step: 0
Training loss: 1.404092788696289
Validation loss: 2.0123662282061834

Epoch: 6| Step: 1
Training loss: 1.4687191247940063
Validation loss: 2.056277087939683

Epoch: 6| Step: 2
Training loss: 1.0712792873382568
Validation loss: 2.027043911718553

Epoch: 6| Step: 3
Training loss: 1.1800549030303955
Validation loss: 2.04168717322811

Epoch: 6| Step: 4
Training loss: 1.3134492635726929
Validation loss: 2.0016882086312897

Epoch: 6| Step: 5
Training loss: 1.3297640085220337
Validation loss: 2.0321434108159875

Epoch: 6| Step: 6
Training loss: 1.4686675071716309
Validation loss: 2.049315068029588

Epoch: 6| Step: 7
Training loss: 1.2311182022094727
Validation loss: 1.996137349836288

Epoch: 6| Step: 8
Training loss: 0.900691568851471
Validation loss: 2.0445956312200075

Epoch: 6| Step: 9
Training loss: 1.8339790105819702
Validation loss: 2.0590010163604573

Epoch: 6| Step: 10
Training loss: 1.3619000911712646
Validation loss: 1.9955876335020988

Epoch: 6| Step: 11
Training loss: 1.101435661315918
Validation loss: 2.023463054369855

Epoch: 6| Step: 12
Training loss: 1.3642666339874268
Validation loss: 2.0041397617709253

Epoch: 6| Step: 13
Training loss: 1.1975386142730713
Validation loss: 2.005263037579034

Epoch: 615| Step: 0
Training loss: 1.0193151235580444
Validation loss: 2.025101602718394

Epoch: 6| Step: 1
Training loss: 1.2290756702423096
Validation loss: 1.9987497329711914

Epoch: 6| Step: 2
Training loss: 1.382027268409729
Validation loss: 2.0154195882940806

Epoch: 6| Step: 3
Training loss: 1.3545866012573242
Validation loss: 2.033817666833119

Epoch: 6| Step: 4
Training loss: 1.5236139297485352
Validation loss: 2.041743331058051

Epoch: 6| Step: 5
Training loss: 1.2690951824188232
Validation loss: 2.0390086661102953

Epoch: 6| Step: 6
Training loss: 0.8658754229545593
Validation loss: 2.00396861696756

Epoch: 6| Step: 7
Training loss: 1.3804914951324463
Validation loss: 2.016837518702271

Epoch: 6| Step: 8
Training loss: 1.584582805633545
Validation loss: 1.989444286592545

Epoch: 6| Step: 9
Training loss: 1.368838906288147
Validation loss: 1.9813521600538684

Epoch: 6| Step: 10
Training loss: 1.7241703271865845
Validation loss: 2.039052729965538

Epoch: 6| Step: 11
Training loss: 1.3097217082977295
Validation loss: 2.001271945174022

Epoch: 6| Step: 12
Training loss: 1.1944290399551392
Validation loss: 2.0441342963967273

Epoch: 6| Step: 13
Training loss: 1.4699482917785645
Validation loss: 2.0574172107122277

Epoch: 616| Step: 0
Training loss: 0.9890455603599548
Validation loss: 2.0171722212145404

Epoch: 6| Step: 1
Training loss: 1.881210207939148
Validation loss: 2.03660499921409

Epoch: 6| Step: 2
Training loss: 1.365788221359253
Validation loss: 1.9608851837855514

Epoch: 6| Step: 3
Training loss: 0.42628365755081177
Validation loss: 2.0143760494006577

Epoch: 6| Step: 4
Training loss: 1.003911018371582
Validation loss: 2.0429373056657854

Epoch: 6| Step: 5
Training loss: 1.401076316833496
Validation loss: 2.0358741847417687

Epoch: 6| Step: 6
Training loss: 1.0698961019515991
Validation loss: 1.960387751620303

Epoch: 6| Step: 7
Training loss: 1.483867883682251
Validation loss: 2.0165742212726223

Epoch: 6| Step: 8
Training loss: 1.593918800354004
Validation loss: 2.0190693537394204

Epoch: 6| Step: 9
Training loss: 1.90975022315979
Validation loss: 2.049346488009217

Epoch: 6| Step: 10
Training loss: 1.2973302602767944
Validation loss: 2.061678432649182

Epoch: 6| Step: 11
Training loss: 1.5804100036621094
Validation loss: 2.048350795622795

Epoch: 6| Step: 12
Training loss: 1.4116061925888062
Validation loss: 2.0228798671435286

Epoch: 6| Step: 13
Training loss: 1.0975290536880493
Validation loss: 2.057583167988767

Epoch: 617| Step: 0
Training loss: 1.5266833305358887
Validation loss: 2.0626011266503284

Epoch: 6| Step: 1
Training loss: 1.3354116678237915
Validation loss: 2.028672388804856

Epoch: 6| Step: 2
Training loss: 0.9904593825340271
Validation loss: 2.04562500856256

Epoch: 6| Step: 3
Training loss: 1.2713899612426758
Validation loss: 2.0187759540414296

Epoch: 6| Step: 4
Training loss: 1.34151291847229
Validation loss: 2.0147890903616466

Epoch: 6| Step: 5
Training loss: 0.9945744276046753
Validation loss: 2.0229018734347437

Epoch: 6| Step: 6
Training loss: 0.9588629007339478
Validation loss: 2.0032302384735434

Epoch: 6| Step: 7
Training loss: 1.1766111850738525
Validation loss: 1.989688838681867

Epoch: 6| Step: 8
Training loss: 0.8605488538742065
Validation loss: 2.034936269124349

Epoch: 6| Step: 9
Training loss: 1.0154848098754883
Validation loss: 2.0309327187076693

Epoch: 6| Step: 10
Training loss: 2.3318932056427
Validation loss: 2.040385664150279

Epoch: 6| Step: 11
Training loss: 1.3206968307495117
Validation loss: 2.0216537060276156

Epoch: 6| Step: 12
Training loss: 1.65647554397583
Validation loss: 1.9973704071455105

Epoch: 6| Step: 13
Training loss: 2.1952977180480957
Validation loss: 2.0195813384107364

Epoch: 618| Step: 0
Training loss: 1.7827816009521484
Validation loss: 1.9962327275224911

Epoch: 6| Step: 1
Training loss: 1.3642067909240723
Validation loss: 2.0428981268277733

Epoch: 6| Step: 2
Training loss: 1.9173815250396729
Validation loss: 2.0448230107625327

Epoch: 6| Step: 3
Training loss: 1.2752933502197266
Validation loss: 2.0749722603828675

Epoch: 6| Step: 4
Training loss: 1.7538034915924072
Validation loss: 2.0421516151838404

Epoch: 6| Step: 5
Training loss: 0.9908315539360046
Validation loss: 2.060334354318598

Epoch: 6| Step: 6
Training loss: 1.1257013082504272
Validation loss: 2.016092969525245

Epoch: 6| Step: 7
Training loss: 1.267685890197754
Validation loss: 2.022611956442556

Epoch: 6| Step: 8
Training loss: 1.0894646644592285
Validation loss: 2.0943405871750205

Epoch: 6| Step: 9
Training loss: 1.44490647315979
Validation loss: 2.0662576665160475

Epoch: 6| Step: 10
Training loss: 0.6033244132995605
Validation loss: 2.0500645150420485

Epoch: 6| Step: 11
Training loss: 1.665172815322876
Validation loss: 2.0502777150882188

Epoch: 6| Step: 12
Training loss: 0.9593290090560913
Validation loss: 2.0495473005438365

Epoch: 6| Step: 13
Training loss: 1.2241724729537964
Validation loss: 2.016965618697546

Epoch: 619| Step: 0
Training loss: 0.5554327964782715
Validation loss: 2.038164410539853

Epoch: 6| Step: 1
Training loss: 1.5201016664505005
Validation loss: 2.0217867166765275

Epoch: 6| Step: 2
Training loss: 1.9661955833435059
Validation loss: 2.0172088915301907

Epoch: 6| Step: 3
Training loss: 0.855525553226471
Validation loss: 1.9985270859092794

Epoch: 6| Step: 4
Training loss: 1.8521003723144531
Validation loss: 2.042557026750298

Epoch: 6| Step: 5
Training loss: 0.822464108467102
Validation loss: 1.9944074769173898

Epoch: 6| Step: 6
Training loss: 1.4745938777923584
Validation loss: 1.9908267041688323

Epoch: 6| Step: 7
Training loss: 1.3144114017486572
Validation loss: 2.0268348288792435

Epoch: 6| Step: 8
Training loss: 1.3402103185653687
Validation loss: 2.046630113355575

Epoch: 6| Step: 9
Training loss: 1.561711311340332
Validation loss: 2.010640399430388

Epoch: 6| Step: 10
Training loss: 1.13227117061615
Validation loss: 2.0051504053095335

Epoch: 6| Step: 11
Training loss: 1.6706128120422363
Validation loss: 1.9920956985924834

Epoch: 6| Step: 12
Training loss: 1.266013503074646
Validation loss: 1.9911155136682654

Epoch: 6| Step: 13
Training loss: 1.1370340585708618
Validation loss: 2.0133866981793473

Epoch: 620| Step: 0
Training loss: 0.7429690361022949
Validation loss: 2.038772098479732

Epoch: 6| Step: 1
Training loss: 2.519247531890869
Validation loss: 1.9969521543031097

Epoch: 6| Step: 2
Training loss: 1.3258259296417236
Validation loss: 2.020432556829145

Epoch: 6| Step: 3
Training loss: 1.2069231271743774
Validation loss: 2.036926006758085

Epoch: 6| Step: 4
Training loss: 1.6182453632354736
Validation loss: 2.0048039779868176

Epoch: 6| Step: 5
Training loss: 0.8110539317131042
Validation loss: 2.031890241048669

Epoch: 6| Step: 6
Training loss: 1.2542043924331665
Validation loss: 2.0600180292642243

Epoch: 6| Step: 7
Training loss: 1.2519891262054443
Validation loss: 2.03065005681848

Epoch: 6| Step: 8
Training loss: 1.5888609886169434
Validation loss: 2.0733280104975544

Epoch: 6| Step: 9
Training loss: 1.3716392517089844
Validation loss: 2.0652704649074103

Epoch: 6| Step: 10
Training loss: 0.6815069317817688
Validation loss: 2.0477022560693885

Epoch: 6| Step: 11
Training loss: 1.643231987953186
Validation loss: 2.011853498797263

Epoch: 6| Step: 12
Training loss: 1.1185250282287598
Validation loss: 2.0443904169144167

Epoch: 6| Step: 13
Training loss: 1.138185977935791
Validation loss: 2.030611930354949

Epoch: 621| Step: 0
Training loss: 1.3487274646759033
Validation loss: 2.049400609026673

Epoch: 6| Step: 1
Training loss: 1.2385601997375488
Validation loss: 2.020259611068233

Epoch: 6| Step: 2
Training loss: 0.8474216461181641
Validation loss: 2.0164727164853002

Epoch: 6| Step: 3
Training loss: 1.5562455654144287
Validation loss: 2.035497889723829

Epoch: 6| Step: 4
Training loss: 1.9681850671768188
Validation loss: 2.0587971120752315

Epoch: 6| Step: 5
Training loss: 1.1611415147781372
Validation loss: 2.0280623897429435

Epoch: 6| Step: 6
Training loss: 0.8603546023368835
Validation loss: 1.9864918865183347

Epoch: 6| Step: 7
Training loss: 1.5177414417266846
Validation loss: 2.063014862357929

Epoch: 6| Step: 8
Training loss: 1.7410714626312256
Validation loss: 2.034801265244843

Epoch: 6| Step: 9
Training loss: 1.4632728099822998
Validation loss: 1.9960692454409856

Epoch: 6| Step: 10
Training loss: 1.0020606517791748
Validation loss: 2.0657391240519862

Epoch: 6| Step: 11
Training loss: 1.3842822313308716
Validation loss: 2.06723230244011

Epoch: 6| Step: 12
Training loss: 0.754392147064209
Validation loss: 2.0326771428508144

Epoch: 6| Step: 13
Training loss: 1.6003085374832153
Validation loss: 2.0205125103714647

Epoch: 622| Step: 0
Training loss: 0.9735112190246582
Validation loss: 2.051177668315108

Epoch: 6| Step: 1
Training loss: 1.4974305629730225
Validation loss: 2.0671061187662105

Epoch: 6| Step: 2
Training loss: 1.740721344947815
Validation loss: 2.0288162897991877

Epoch: 6| Step: 3
Training loss: 1.5578105449676514
Validation loss: 2.046837697746933

Epoch: 6| Step: 4
Training loss: 0.9302099943161011
Validation loss: 2.030078696948226

Epoch: 6| Step: 5
Training loss: 1.5940057039260864
Validation loss: 2.0238110890952488

Epoch: 6| Step: 6
Training loss: 1.1539087295532227
Validation loss: 2.0386721754586823

Epoch: 6| Step: 7
Training loss: 1.2576842308044434
Validation loss: 2.014760637796053

Epoch: 6| Step: 8
Training loss: 1.4672980308532715
Validation loss: 2.017651911704771

Epoch: 6| Step: 9
Training loss: 0.917282223701477
Validation loss: 2.10188824899735

Epoch: 6| Step: 10
Training loss: 2.2253687381744385
Validation loss: 2.063959575468494

Epoch: 6| Step: 11
Training loss: 0.6789815425872803
Validation loss: 2.0039288100375923

Epoch: 6| Step: 12
Training loss: 1.3595753908157349
Validation loss: 2.078020977717574

Epoch: 6| Step: 13
Training loss: 0.8476189374923706
Validation loss: 2.0370266463166926

Epoch: 623| Step: 0
Training loss: 0.9196699857711792
Validation loss: 2.0239713217622493

Epoch: 6| Step: 1
Training loss: 1.431736946105957
Validation loss: 1.9994519269594582

Epoch: 6| Step: 2
Training loss: 1.4293415546417236
Validation loss: 2.0361573055226314

Epoch: 6| Step: 3
Training loss: 1.3808484077453613
Validation loss: 2.0416315012080695

Epoch: 6| Step: 4
Training loss: 1.1418653726577759
Validation loss: 2.0610698064168296

Epoch: 6| Step: 5
Training loss: 1.1640632152557373
Validation loss: 2.0403216782436577

Epoch: 6| Step: 6
Training loss: 1.526932954788208
Validation loss: 2.025685602618802

Epoch: 6| Step: 7
Training loss: 1.711410403251648
Validation loss: 2.0070639912800123

Epoch: 6| Step: 8
Training loss: 1.0940935611724854
Validation loss: 2.021541016076201

Epoch: 6| Step: 9
Training loss: 1.3622430562973022
Validation loss: 2.049117454918482

Epoch: 6| Step: 10
Training loss: 1.6854451894760132
Validation loss: 2.0168816415212487

Epoch: 6| Step: 11
Training loss: 0.7495496273040771
Validation loss: 2.041408209390538

Epoch: 6| Step: 12
Training loss: 1.2611775398254395
Validation loss: 2.0376232939381755

Epoch: 6| Step: 13
Training loss: 0.7769137024879456
Validation loss: 2.016255250541113

Epoch: 624| Step: 0
Training loss: 1.6027545928955078
Validation loss: 1.9957472047498148

Epoch: 6| Step: 1
Training loss: 1.0150084495544434
Validation loss: 1.967272925120528

Epoch: 6| Step: 2
Training loss: 1.025292992591858
Validation loss: 2.013282947642829

Epoch: 6| Step: 3
Training loss: 0.7490037679672241
Validation loss: 2.022170506497865

Epoch: 6| Step: 4
Training loss: 1.3655073642730713
Validation loss: 1.9959797243918143

Epoch: 6| Step: 5
Training loss: 1.8334753513336182
Validation loss: 2.037413889361966

Epoch: 6| Step: 6
Training loss: 1.2188020944595337
Validation loss: 2.018759180140752

Epoch: 6| Step: 7
Training loss: 1.6300026178359985
Validation loss: 1.9880977240941857

Epoch: 6| Step: 8
Training loss: 1.4521043300628662
Validation loss: 2.030641467340531

Epoch: 6| Step: 9
Training loss: 1.096937656402588
Validation loss: 1.9790797618127638

Epoch: 6| Step: 10
Training loss: 1.263707160949707
Validation loss: 1.990658849798223

Epoch: 6| Step: 11
Training loss: 0.8936190605163574
Validation loss: 2.0016450830685195

Epoch: 6| Step: 12
Training loss: 1.4073214530944824
Validation loss: 2.0190803094576766

Epoch: 6| Step: 13
Training loss: 2.2202446460723877
Validation loss: 2.019967721354577

Epoch: 625| Step: 0
Training loss: 1.5047825574874878
Validation loss: 2.0275465083378617

Epoch: 6| Step: 1
Training loss: 0.6504315733909607
Validation loss: 2.076271337847556

Epoch: 6| Step: 2
Training loss: 1.5927308797836304
Validation loss: 2.0675448679154917

Epoch: 6| Step: 3
Training loss: 1.9709718227386475
Validation loss: 2.0659195146253033

Epoch: 6| Step: 4
Training loss: 1.0872581005096436
Validation loss: 2.031246080193468

Epoch: 6| Step: 5
Training loss: 1.2434906959533691
Validation loss: 2.082303341998849

Epoch: 6| Step: 6
Training loss: 1.4849765300750732
Validation loss: 2.1045051954125844

Epoch: 6| Step: 7
Training loss: 1.5058989524841309
Validation loss: 2.0881482055110316

Epoch: 6| Step: 8
Training loss: 1.3520294427871704
Validation loss: 2.0726319846286567

Epoch: 6| Step: 9
Training loss: 0.8851796984672546
Validation loss: 2.0685175029180383

Epoch: 6| Step: 10
Training loss: 1.070267677307129
Validation loss: 2.0412992200543805

Epoch: 6| Step: 11
Training loss: 1.6104276180267334
Validation loss: 2.0467369325699343

Epoch: 6| Step: 12
Training loss: 1.27805495262146
Validation loss: 2.048531732251567

Epoch: 6| Step: 13
Training loss: 1.3485028743743896
Validation loss: 2.03526807344088

Epoch: 626| Step: 0
Training loss: 0.8445644974708557
Validation loss: 2.020623956957171

Epoch: 6| Step: 1
Training loss: 0.5966777205467224
Validation loss: 2.059841057305695

Epoch: 6| Step: 2
Training loss: 1.7105662822723389
Validation loss: 2.0367818365814867

Epoch: 6| Step: 3
Training loss: 1.4136712551116943
Validation loss: 2.035595714405019

Epoch: 6| Step: 4
Training loss: 0.8191705942153931
Validation loss: 2.009712983203191

Epoch: 6| Step: 5
Training loss: 1.846853256225586
Validation loss: 2.036860037875432

Epoch: 6| Step: 6
Training loss: 1.3777318000793457
Validation loss: 2.0253854156822286

Epoch: 6| Step: 7
Training loss: 1.8020654916763306
Validation loss: 1.985142836006739

Epoch: 6| Step: 8
Training loss: 1.9294840097427368
Validation loss: 2.038670988493068

Epoch: 6| Step: 9
Training loss: 0.810318112373352
Validation loss: 2.0195783120329662

Epoch: 6| Step: 10
Training loss: 1.4494242668151855
Validation loss: 2.0254694043949084

Epoch: 6| Step: 11
Training loss: 1.119307041168213
Validation loss: 2.0351134115649807

Epoch: 6| Step: 12
Training loss: 0.8699955940246582
Validation loss: 2.040933327008319

Epoch: 6| Step: 13
Training loss: 1.4278597831726074
Validation loss: 2.0313374406547955

Epoch: 627| Step: 0
Training loss: 1.4737902879714966
Validation loss: 2.013164319017882

Epoch: 6| Step: 1
Training loss: 1.1639667749404907
Validation loss: 2.037408938971899

Epoch: 6| Step: 2
Training loss: 1.4221192598342896
Validation loss: 2.0342958588753977

Epoch: 6| Step: 3
Training loss: 0.7669425010681152
Validation loss: 2.040167111222462

Epoch: 6| Step: 4
Training loss: 1.3730071783065796
Validation loss: 2.0354494433249197

Epoch: 6| Step: 5
Training loss: 0.9277545809745789
Validation loss: 2.0492019089319373

Epoch: 6| Step: 6
Training loss: 1.6153669357299805
Validation loss: 2.029110788017191

Epoch: 6| Step: 7
Training loss: 1.5862793922424316
Validation loss: 2.034459014092722

Epoch: 6| Step: 8
Training loss: 1.7871919870376587
Validation loss: 2.0160118302991314

Epoch: 6| Step: 9
Training loss: 1.2412775754928589
Validation loss: 2.020686939198484

Epoch: 6| Step: 10
Training loss: 1.0104000568389893
Validation loss: 1.9973805988988569

Epoch: 6| Step: 11
Training loss: 1.8324419260025024
Validation loss: 2.0029087399923675

Epoch: 6| Step: 12
Training loss: 0.982452929019928
Validation loss: 2.024546451466058

Epoch: 6| Step: 13
Training loss: 1.10200834274292
Validation loss: 2.0638298629432597

Epoch: 628| Step: 0
Training loss: 1.171925663948059
Validation loss: 1.9882974714361212

Epoch: 6| Step: 1
Training loss: 1.4656922817230225
Validation loss: 2.035803969188403

Epoch: 6| Step: 2
Training loss: 1.8154191970825195
Validation loss: 2.0319359379429973

Epoch: 6| Step: 3
Training loss: 1.4271879196166992
Validation loss: 2.050868699627538

Epoch: 6| Step: 4
Training loss: 1.4198572635650635
Validation loss: 2.0311301292911654

Epoch: 6| Step: 5
Training loss: 1.2912204265594482
Validation loss: 2.0919606044728267

Epoch: 6| Step: 6
Training loss: 1.7104911804199219
Validation loss: 2.0235330712410713

Epoch: 6| Step: 7
Training loss: 1.1978466510772705
Validation loss: 2.070117087774379

Epoch: 6| Step: 8
Training loss: 1.1298582553863525
Validation loss: 2.010355452055572

Epoch: 6| Step: 9
Training loss: 0.5230446457862854
Validation loss: 1.9941495310875677

Epoch: 6| Step: 10
Training loss: 0.8346447944641113
Validation loss: 2.0255761774637366

Epoch: 6| Step: 11
Training loss: 1.7231495380401611
Validation loss: 2.0498915590265745

Epoch: 6| Step: 12
Training loss: 1.4532012939453125
Validation loss: 2.004898678871893

Epoch: 6| Step: 13
Training loss: 0.6668881177902222
Validation loss: 2.0258804982708347

Epoch: 629| Step: 0
Training loss: 1.7789361476898193
Validation loss: 2.0243708241370415

Epoch: 6| Step: 1
Training loss: 1.3078306913375854
Validation loss: 2.0328381587100286

Epoch: 6| Step: 2
Training loss: 0.6226326823234558
Validation loss: 2.0522111833736463

Epoch: 6| Step: 3
Training loss: 1.3239786624908447
Validation loss: 2.0545369296945553

Epoch: 6| Step: 4
Training loss: 1.8170442581176758
Validation loss: 2.0486589836817917

Epoch: 6| Step: 5
Training loss: 1.2240259647369385
Validation loss: 2.0491818689530894

Epoch: 6| Step: 6
Training loss: 1.5178228616714478
Validation loss: 2.026346593774775

Epoch: 6| Step: 7
Training loss: 0.8924329876899719
Validation loss: 2.042701380227202

Epoch: 6| Step: 8
Training loss: 1.68672776222229
Validation loss: 2.030379359440137

Epoch: 6| Step: 9
Training loss: 0.8957192301750183
Validation loss: 1.988633890305796

Epoch: 6| Step: 10
Training loss: 1.453842282295227
Validation loss: 2.030259393876599

Epoch: 6| Step: 11
Training loss: 1.2698338031768799
Validation loss: 2.0192957924258326

Epoch: 6| Step: 12
Training loss: 1.1710420846939087
Validation loss: 2.0083747909915064

Epoch: 6| Step: 13
Training loss: 0.7416067719459534
Validation loss: 1.9957176305914437

Epoch: 630| Step: 0
Training loss: 1.1286014318466187
Validation loss: 2.01888229385499

Epoch: 6| Step: 1
Training loss: 1.230748176574707
Validation loss: 1.9918333253552836

Epoch: 6| Step: 2
Training loss: 1.3965976238250732
Validation loss: 2.0104793579347673

Epoch: 6| Step: 3
Training loss: 1.6991088390350342
Validation loss: 2.034074144978677

Epoch: 6| Step: 4
Training loss: 1.7067562341690063
Validation loss: 2.0400763955167545

Epoch: 6| Step: 5
Training loss: 1.210029125213623
Validation loss: 2.014920808935678

Epoch: 6| Step: 6
Training loss: 0.8845750093460083
Validation loss: 2.0294188350759526

Epoch: 6| Step: 7
Training loss: 1.218435287475586
Validation loss: 2.0400574963579894

Epoch: 6| Step: 8
Training loss: 1.0755133628845215
Validation loss: 2.0355692871155275

Epoch: 6| Step: 9
Training loss: 1.4256408214569092
Validation loss: 2.0349886135388444

Epoch: 6| Step: 10
Training loss: 0.8662171959877014
Validation loss: 2.038492377086352

Epoch: 6| Step: 11
Training loss: 1.3942660093307495
Validation loss: 2.0409042271234656

Epoch: 6| Step: 12
Training loss: 1.5634517669677734
Validation loss: 2.043721088799097

Epoch: 6| Step: 13
Training loss: 1.3689100742340088
Validation loss: 1.9941292680719847

Epoch: 631| Step: 0
Training loss: 1.3569198846817017
Validation loss: 2.006857907900246

Epoch: 6| Step: 1
Training loss: 1.148820161819458
Validation loss: 2.038142483721497

Epoch: 6| Step: 2
Training loss: 1.0229566097259521
Validation loss: 2.0358455540031515

Epoch: 6| Step: 3
Training loss: 1.0403437614440918
Validation loss: 2.034691946480864

Epoch: 6| Step: 4
Training loss: 0.8878344893455505
Validation loss: 2.071134344224007

Epoch: 6| Step: 5
Training loss: 1.9756231307983398
Validation loss: 2.05961674515919

Epoch: 6| Step: 6
Training loss: 1.3983091115951538
Validation loss: 2.0412380720979426

Epoch: 6| Step: 7
Training loss: 1.692138671875
Validation loss: 2.0096431701414046

Epoch: 6| Step: 8
Training loss: 1.3297557830810547
Validation loss: 2.003858344529265

Epoch: 6| Step: 9
Training loss: 1.4952548742294312
Validation loss: 2.0272015140902613

Epoch: 6| Step: 10
Training loss: 0.9176673889160156
Validation loss: 2.0202915130123014

Epoch: 6| Step: 11
Training loss: 1.263509750366211
Validation loss: 1.9805767638708955

Epoch: 6| Step: 12
Training loss: 1.3590145111083984
Validation loss: 2.037375242479386

Epoch: 6| Step: 13
Training loss: 1.1072306632995605
Validation loss: 2.0252572503141177

Epoch: 632| Step: 0
Training loss: 1.0387229919433594
Validation loss: 2.00341175704874

Epoch: 6| Step: 1
Training loss: 1.4222831726074219
Validation loss: 2.046442395897322

Epoch: 6| Step: 2
Training loss: 1.108471393585205
Validation loss: 2.0259608350774294

Epoch: 6| Step: 3
Training loss: 1.3840843439102173
Validation loss: 2.0458116198098786

Epoch: 6| Step: 4
Training loss: 1.1981056928634644
Validation loss: 2.007333177392201

Epoch: 6| Step: 5
Training loss: 1.2517080307006836
Validation loss: 2.0496654279770388

Epoch: 6| Step: 6
Training loss: 1.088706374168396
Validation loss: 2.0387044029851116

Epoch: 6| Step: 7
Training loss: 1.2366385459899902
Validation loss: 2.0494914080507014

Epoch: 6| Step: 8
Training loss: 1.2640204429626465
Validation loss: 2.0708815051663305

Epoch: 6| Step: 9
Training loss: 1.615293264389038
Validation loss: 2.0202637667297036

Epoch: 6| Step: 10
Training loss: 1.4623255729675293
Validation loss: 2.0171699664926015

Epoch: 6| Step: 11
Training loss: 1.4612723588943481
Validation loss: 2.035246031258696

Epoch: 6| Step: 12
Training loss: 0.7904555797576904
Validation loss: 2.0370560064110705

Epoch: 6| Step: 13
Training loss: 1.245335578918457
Validation loss: 2.0389222714208786

Epoch: 633| Step: 0
Training loss: 1.8016772270202637
Validation loss: 2.0256717230684016

Epoch: 6| Step: 1
Training loss: 0.9438852071762085
Validation loss: 2.033342485786766

Epoch: 6| Step: 2
Training loss: 0.7848984599113464
Validation loss: 2.0143729666227936

Epoch: 6| Step: 3
Training loss: 1.805046796798706
Validation loss: 2.0201854654537734

Epoch: 6| Step: 4
Training loss: 0.7831922769546509
Validation loss: 2.046395763274162

Epoch: 6| Step: 5
Training loss: 1.3312256336212158
Validation loss: 2.0281739670743226

Epoch: 6| Step: 6
Training loss: 1.1333465576171875
Validation loss: 2.0401611725489297

Epoch: 6| Step: 7
Training loss: 1.4578096866607666
Validation loss: 2.017368537123485

Epoch: 6| Step: 8
Training loss: 1.406041145324707
Validation loss: 2.053598592358251

Epoch: 6| Step: 9
Training loss: 1.4337437152862549
Validation loss: 1.9999505242993754

Epoch: 6| Step: 10
Training loss: 1.255077838897705
Validation loss: 1.999337939805882

Epoch: 6| Step: 11
Training loss: 1.298213005065918
Validation loss: 2.0015666100286666

Epoch: 6| Step: 12
Training loss: 1.455091118812561
Validation loss: 1.997862546674667

Epoch: 6| Step: 13
Training loss: 1.211944341659546
Validation loss: 2.0184175275987193

Epoch: 634| Step: 0
Training loss: 1.3176333904266357
Validation loss: 2.026856105814698

Epoch: 6| Step: 1
Training loss: 0.8963204026222229
Validation loss: 2.0078426971230456

Epoch: 6| Step: 2
Training loss: 1.285348892211914
Validation loss: 2.0163902851843063

Epoch: 6| Step: 3
Training loss: 1.0181727409362793
Validation loss: 2.0167724214574343

Epoch: 6| Step: 4
Training loss: 0.798481822013855
Validation loss: 2.0129593098035423

Epoch: 6| Step: 5
Training loss: 1.7080812454223633
Validation loss: 2.018577088591873

Epoch: 6| Step: 6
Training loss: 1.4325568675994873
Validation loss: 2.006484907160523

Epoch: 6| Step: 7
Training loss: 0.9679484367370605
Validation loss: 2.035390850036375

Epoch: 6| Step: 8
Training loss: 1.7525519132614136
Validation loss: 2.0591340116275254

Epoch: 6| Step: 9
Training loss: 1.276591181755066
Validation loss: 2.0120486956770702

Epoch: 6| Step: 10
Training loss: 2.2166295051574707
Validation loss: 2.0304649440191125

Epoch: 6| Step: 11
Training loss: 1.4142117500305176
Validation loss: 2.010985497505434

Epoch: 6| Step: 12
Training loss: 1.0214414596557617
Validation loss: 1.9860585812599427

Epoch: 6| Step: 13
Training loss: 0.8942639231681824
Validation loss: 2.0328875241741056

Epoch: 635| Step: 0
Training loss: 1.191719889640808
Validation loss: 2.015849477501326

Epoch: 6| Step: 1
Training loss: 1.4680075645446777
Validation loss: 1.9989238823613813

Epoch: 6| Step: 2
Training loss: 1.0306923389434814
Validation loss: 2.0411137983363163

Epoch: 6| Step: 3
Training loss: 1.419664740562439
Validation loss: 2.0098994931867047

Epoch: 6| Step: 4
Training loss: 1.0004650354385376
Validation loss: 2.046846112897319

Epoch: 6| Step: 5
Training loss: 0.9134794473648071
Validation loss: 2.0008908292298675

Epoch: 6| Step: 6
Training loss: 1.8380118608474731
Validation loss: 1.9855818671564902

Epoch: 6| Step: 7
Training loss: 1.063401460647583
Validation loss: 2.006762836569099

Epoch: 6| Step: 8
Training loss: 1.0169448852539062
Validation loss: 2.0226799352194673

Epoch: 6| Step: 9
Training loss: 1.4123469591140747
Validation loss: 2.0267881578014744

Epoch: 6| Step: 10
Training loss: 1.0743257999420166
Validation loss: 2.0284930044604885

Epoch: 6| Step: 11
Training loss: 2.059990644454956
Validation loss: 1.9856268577678229

Epoch: 6| Step: 12
Training loss: 1.3819770812988281
Validation loss: 1.9815828954019854

Epoch: 6| Step: 13
Training loss: 1.2641645669937134
Validation loss: 2.044158694564655

Epoch: 636| Step: 0
Training loss: 1.83762788772583
Validation loss: 2.03924867158295

Epoch: 6| Step: 1
Training loss: 1.2724729776382446
Validation loss: 2.0297058487451203

Epoch: 6| Step: 2
Training loss: 1.2055516242980957
Validation loss: 2.034303112696576

Epoch: 6| Step: 3
Training loss: 1.1511123180389404
Validation loss: 2.007483272142308

Epoch: 6| Step: 4
Training loss: 1.6441457271575928
Validation loss: 2.0616023630224247

Epoch: 6| Step: 5
Training loss: 1.9733885526657104
Validation loss: 2.045427724879275

Epoch: 6| Step: 6
Training loss: 1.1669695377349854
Validation loss: 2.063937388440614

Epoch: 6| Step: 7
Training loss: 0.8882141709327698
Validation loss: 2.0443799136787333

Epoch: 6| Step: 8
Training loss: 0.7261260747909546
Validation loss: 2.0405909463923466

Epoch: 6| Step: 9
Training loss: 0.9576659798622131
Validation loss: 2.0402251699919343

Epoch: 6| Step: 10
Training loss: 1.162095069885254
Validation loss: 2.106320003027557

Epoch: 6| Step: 11
Training loss: 1.4259289503097534
Validation loss: 2.0295353781792427

Epoch: 6| Step: 12
Training loss: 1.1149225234985352
Validation loss: 2.0376727119568856

Epoch: 6| Step: 13
Training loss: 1.466201663017273
Validation loss: 2.039227234419956

Epoch: 637| Step: 0
Training loss: 1.0397655963897705
Validation loss: 2.020469988546064

Epoch: 6| Step: 1
Training loss: 2.165809392929077
Validation loss: 1.9841666683073966

Epoch: 6| Step: 2
Training loss: 0.8195230960845947
Validation loss: 2.0276111300273607

Epoch: 6| Step: 3
Training loss: 1.3858528137207031
Validation loss: 2.0139649670611144

Epoch: 6| Step: 4
Training loss: 1.3299144506454468
Validation loss: 2.0133312491960424

Epoch: 6| Step: 5
Training loss: 0.7917194366455078
Validation loss: 2.06677871365701

Epoch: 6| Step: 6
Training loss: 1.40224289894104
Validation loss: 2.0149054091463805

Epoch: 6| Step: 7
Training loss: 0.9388285875320435
Validation loss: 1.9917188895645963

Epoch: 6| Step: 8
Training loss: 1.980020523071289
Validation loss: 2.0472200109112646

Epoch: 6| Step: 9
Training loss: 0.959944486618042
Validation loss: 1.982126074452554

Epoch: 6| Step: 10
Training loss: 1.4082272052764893
Validation loss: 1.9846587540000997

Epoch: 6| Step: 11
Training loss: 1.2066335678100586
Validation loss: 1.9673346037505774

Epoch: 6| Step: 12
Training loss: 1.5603938102722168
Validation loss: 1.9500742138073008

Epoch: 6| Step: 13
Training loss: 1.482771635055542
Validation loss: 2.024709500292296

Epoch: 638| Step: 0
Training loss: 2.421835422515869
Validation loss: 1.9749993073043002

Epoch: 6| Step: 1
Training loss: 0.7162259817123413
Validation loss: 2.026289072088016

Epoch: 6| Step: 2
Training loss: 1.0455241203308105
Validation loss: 2.0049478315537974

Epoch: 6| Step: 3
Training loss: 1.050873875617981
Validation loss: 2.066858148062101

Epoch: 6| Step: 4
Training loss: 1.8776171207427979
Validation loss: 1.9962658689868065

Epoch: 6| Step: 5
Training loss: 1.3693875074386597
Validation loss: 2.0153966821650022

Epoch: 6| Step: 6
Training loss: 0.8701010942459106
Validation loss: 2.0068079156260334

Epoch: 6| Step: 7
Training loss: 1.3475662469863892
Validation loss: 2.0177004388583604

Epoch: 6| Step: 8
Training loss: 0.8396371006965637
Validation loss: 2.0071651281849032

Epoch: 6| Step: 9
Training loss: 1.0617525577545166
Validation loss: 1.9637498804318008

Epoch: 6| Step: 10
Training loss: 1.1416308879852295
Validation loss: 2.0213895356783302

Epoch: 6| Step: 11
Training loss: 1.5299588441848755
Validation loss: 2.0167653868275304

Epoch: 6| Step: 12
Training loss: 1.613722562789917
Validation loss: 2.02307875182039

Epoch: 6| Step: 13
Training loss: 1.4720546007156372
Validation loss: 2.0267883039289907

Epoch: 639| Step: 0
Training loss: 1.6467044353485107
Validation loss: 2.0527345954730944

Epoch: 6| Step: 1
Training loss: 1.7620351314544678
Validation loss: 1.9978752033684843

Epoch: 6| Step: 2
Training loss: 1.4529900550842285
Validation loss: 2.023877742469952

Epoch: 6| Step: 3
Training loss: 0.9228264093399048
Validation loss: 2.0204434805018927

Epoch: 6| Step: 4
Training loss: 0.609805703163147
Validation loss: 2.060594818925345

Epoch: 6| Step: 5
Training loss: 0.7870171666145325
Validation loss: 2.0397973163153535

Epoch: 6| Step: 6
Training loss: 1.113804817199707
Validation loss: 2.059465718525712

Epoch: 6| Step: 7
Training loss: 1.1781437397003174
Validation loss: 2.0360311641488025

Epoch: 6| Step: 8
Training loss: 1.1872073411941528
Validation loss: 2.053401106147356

Epoch: 6| Step: 9
Training loss: 1.3136427402496338
Validation loss: 2.0733016998537126

Epoch: 6| Step: 10
Training loss: 2.046516180038452
Validation loss: 2.0006428303257113

Epoch: 6| Step: 11
Training loss: 0.8780660629272461
Validation loss: 2.0357075340004376

Epoch: 6| Step: 12
Training loss: 1.741998553276062
Validation loss: 1.9597757862460228

Epoch: 6| Step: 13
Training loss: 1.8950453996658325
Validation loss: 2.03812288981612

Epoch: 640| Step: 0
Training loss: 0.9198095798492432
Validation loss: 2.0076457633767077

Epoch: 6| Step: 1
Training loss: 1.8152515888214111
Validation loss: 1.9924648423348703

Epoch: 6| Step: 2
Training loss: 0.9043918251991272
Validation loss: 1.9478035870418753

Epoch: 6| Step: 3
Training loss: 1.4308030605316162
Validation loss: 2.020566127633536

Epoch: 6| Step: 4
Training loss: 1.4064782857894897
Validation loss: 2.0165433345302457

Epoch: 6| Step: 5
Training loss: 1.3182411193847656
Validation loss: 1.9953203919113323

Epoch: 6| Step: 6
Training loss: 1.084132194519043
Validation loss: 2.020797352637014

Epoch: 6| Step: 7
Training loss: 1.9010659456253052
Validation loss: 1.987075000680903

Epoch: 6| Step: 8
Training loss: 1.2840118408203125
Validation loss: 2.0223236724894535

Epoch: 6| Step: 9
Training loss: 0.8999624252319336
Validation loss: 1.9340219587408087

Epoch: 6| Step: 10
Training loss: 1.4339419603347778
Validation loss: 2.020788856731948

Epoch: 6| Step: 11
Training loss: 1.2222813367843628
Validation loss: 1.9928186426880539

Epoch: 6| Step: 12
Training loss: 0.7514075040817261
Validation loss: 1.9688042927813787

Epoch: 6| Step: 13
Training loss: 1.3453606367111206
Validation loss: 2.003734997523728

Epoch: 641| Step: 0
Training loss: 0.6696745157241821
Validation loss: 1.978919849600843

Epoch: 6| Step: 1
Training loss: 1.634954810142517
Validation loss: 2.011889999912631

Epoch: 6| Step: 2
Training loss: 1.4117822647094727
Validation loss: 2.014120323683626

Epoch: 6| Step: 3
Training loss: 1.5466556549072266
Validation loss: 2.0019003011847056

Epoch: 6| Step: 4
Training loss: 0.8648155927658081
Validation loss: 2.04253537167785

Epoch: 6| Step: 5
Training loss: 1.2164936065673828
Validation loss: 2.062910411947517

Epoch: 6| Step: 6
Training loss: 1.2802488803863525
Validation loss: 2.0190079635189426

Epoch: 6| Step: 7
Training loss: 1.1893290281295776
Validation loss: 2.057635994367702

Epoch: 6| Step: 8
Training loss: 1.560291051864624
Validation loss: 2.0322939247213383

Epoch: 6| Step: 9
Training loss: 1.1208608150482178
Validation loss: 2.002962117554039

Epoch: 6| Step: 10
Training loss: 1.3973468542099
Validation loss: 2.021060589821108

Epoch: 6| Step: 11
Training loss: 1.4248690605163574
Validation loss: 2.0089917439286427

Epoch: 6| Step: 12
Training loss: 0.9358527660369873
Validation loss: 1.9941134042637323

Epoch: 6| Step: 13
Training loss: 1.9754096269607544
Validation loss: 2.0227775676276094

Epoch: 642| Step: 0
Training loss: 1.811246395111084
Validation loss: 2.0287654963872765

Epoch: 6| Step: 1
Training loss: 1.7127881050109863
Validation loss: 2.032194052973101

Epoch: 6| Step: 2
Training loss: 1.2143607139587402
Validation loss: 1.9873792714970087

Epoch: 6| Step: 3
Training loss: 1.5504481792449951
Validation loss: 2.0288832251743605

Epoch: 6| Step: 4
Training loss: 1.034289002418518
Validation loss: 1.9982047388630528

Epoch: 6| Step: 5
Training loss: 1.2554786205291748
Validation loss: 1.9919102935380832

Epoch: 6| Step: 6
Training loss: 1.5280176401138306
Validation loss: 2.0300786110662643

Epoch: 6| Step: 7
Training loss: 1.759187936782837
Validation loss: 1.9866498542088333

Epoch: 6| Step: 8
Training loss: 1.303870439529419
Validation loss: 1.9485452751959524

Epoch: 6| Step: 9
Training loss: 1.1578190326690674
Validation loss: 2.0181863090043426

Epoch: 6| Step: 10
Training loss: 0.6489295363426208
Validation loss: 1.9510905140189714

Epoch: 6| Step: 11
Training loss: 0.5628315210342407
Validation loss: 2.0457055158512567

Epoch: 6| Step: 12
Training loss: 1.364433765411377
Validation loss: 2.007765741758449

Epoch: 6| Step: 13
Training loss: 0.9397312998771667
Validation loss: 2.01843846741543

Epoch: 643| Step: 0
Training loss: 2.129077196121216
Validation loss: 2.012795986667756

Epoch: 6| Step: 1
Training loss: 1.4261736869812012
Validation loss: 2.020881801523188

Epoch: 6| Step: 2
Training loss: 0.8493956327438354
Validation loss: 1.9931118795948644

Epoch: 6| Step: 3
Training loss: 0.9405480623245239
Validation loss: 1.970210462488154

Epoch: 6| Step: 4
Training loss: 1.4628756046295166
Validation loss: 2.0730099370402675

Epoch: 6| Step: 5
Training loss: 1.0877690315246582
Validation loss: 2.0679633630219327

Epoch: 6| Step: 6
Training loss: 1.5588406324386597
Validation loss: 1.9843773303493377

Epoch: 6| Step: 7
Training loss: 0.7345626950263977
Validation loss: 2.048589455184116

Epoch: 6| Step: 8
Training loss: 0.9259535670280457
Validation loss: 1.9821931034006097

Epoch: 6| Step: 9
Training loss: 1.1239374876022339
Validation loss: 2.0926062522395963

Epoch: 6| Step: 10
Training loss: 1.7580716609954834
Validation loss: 2.0456203799093924

Epoch: 6| Step: 11
Training loss: 1.2537322044372559
Validation loss: 2.024742982720816

Epoch: 6| Step: 12
Training loss: 0.9985628128051758
Validation loss: 2.009862005069692

Epoch: 6| Step: 13
Training loss: 1.347646951675415
Validation loss: 2.0596888770339308

Epoch: 644| Step: 0
Training loss: 1.709685206413269
Validation loss: 2.057048838625672

Epoch: 6| Step: 1
Training loss: 1.3677246570587158
Validation loss: 2.017033315473987

Epoch: 6| Step: 2
Training loss: 0.7912254333496094
Validation loss: 2.0395851994073517

Epoch: 6| Step: 3
Training loss: 0.8060735464096069
Validation loss: 2.0474135798792683

Epoch: 6| Step: 4
Training loss: 0.7792290449142456
Validation loss: 2.0480032556800434

Epoch: 6| Step: 5
Training loss: 1.0101442337036133
Validation loss: 2.0087899367014566

Epoch: 6| Step: 6
Training loss: 0.8334748148918152
Validation loss: 2.038432800641624

Epoch: 6| Step: 7
Training loss: 1.68278169631958
Validation loss: 2.056685116983229

Epoch: 6| Step: 8
Training loss: 2.114783763885498
Validation loss: 2.040603745368219

Epoch: 6| Step: 9
Training loss: 1.1819570064544678
Validation loss: 2.0293075333359423

Epoch: 6| Step: 10
Training loss: 1.376574993133545
Validation loss: 2.017041375560145

Epoch: 6| Step: 11
Training loss: 1.9385148286819458
Validation loss: 1.9972136046296807

Epoch: 6| Step: 12
Training loss: 1.097747564315796
Validation loss: 1.996932844961843

Epoch: 6| Step: 13
Training loss: 1.2616791725158691
Validation loss: 1.9821440186551822

Epoch: 645| Step: 0
Training loss: 0.7536629438400269
Validation loss: 1.9682912647083242

Epoch: 6| Step: 1
Training loss: 1.6510355472564697
Validation loss: 2.0225325194738244

Epoch: 6| Step: 2
Training loss: 1.6498737335205078
Validation loss: 2.0084050880965365

Epoch: 6| Step: 3
Training loss: 0.9968554973602295
Validation loss: 1.9625386256043629

Epoch: 6| Step: 4
Training loss: 0.824272871017456
Validation loss: 1.996682132444074

Epoch: 6| Step: 5
Training loss: 1.8998249769210815
Validation loss: 2.0276144755783903

Epoch: 6| Step: 6
Training loss: 0.8256811499595642
Validation loss: 2.079718161654729

Epoch: 6| Step: 7
Training loss: 1.785941481590271
Validation loss: 2.068194007360807

Epoch: 6| Step: 8
Training loss: 1.0228898525238037
Validation loss: 2.0367106263355543

Epoch: 6| Step: 9
Training loss: 1.389296531677246
Validation loss: 2.0147506690794423

Epoch: 6| Step: 10
Training loss: 1.3184806108474731
Validation loss: 2.037448242146482

Epoch: 6| Step: 11
Training loss: 2.0290703773498535
Validation loss: 2.06010454188111

Epoch: 6| Step: 12
Training loss: 0.6498015522956848
Validation loss: 2.0238905978459183

Epoch: 6| Step: 13
Training loss: 1.069713830947876
Validation loss: 2.0221143794316117

Epoch: 646| Step: 0
Training loss: 1.1975834369659424
Validation loss: 2.026802593661893

Epoch: 6| Step: 1
Training loss: 1.6236052513122559
Validation loss: 1.9990066956448298

Epoch: 6| Step: 2
Training loss: 1.470174789428711
Validation loss: 2.0107239959060506

Epoch: 6| Step: 3
Training loss: 1.0626240968704224
Validation loss: 1.9650680275373562

Epoch: 6| Step: 4
Training loss: 0.949971079826355
Validation loss: 1.9823428776956373

Epoch: 6| Step: 5
Training loss: 1.1945124864578247
Validation loss: 2.011293608655212

Epoch: 6| Step: 6
Training loss: 0.6572322845458984
Validation loss: 2.0023846318644862

Epoch: 6| Step: 7
Training loss: 1.6316877603530884
Validation loss: 1.9683284144247732

Epoch: 6| Step: 8
Training loss: 1.3301453590393066
Validation loss: 1.9790496877444688

Epoch: 6| Step: 9
Training loss: 1.7915358543395996
Validation loss: 1.9923353656645744

Epoch: 6| Step: 10
Training loss: 1.0362980365753174
Validation loss: 1.9818962543241438

Epoch: 6| Step: 11
Training loss: 1.2799952030181885
Validation loss: 1.971938689549764

Epoch: 6| Step: 12
Training loss: 1.315250039100647
Validation loss: 2.0008886860262964

Epoch: 6| Step: 13
Training loss: 0.9999154210090637
Validation loss: 2.048934592995592

Epoch: 647| Step: 0
Training loss: 1.502838134765625
Validation loss: 2.0112986744091077

Epoch: 6| Step: 1
Training loss: 1.2909387350082397
Validation loss: 2.0854981253224034

Epoch: 6| Step: 2
Training loss: 0.6957165002822876
Validation loss: 2.027941806342012

Epoch: 6| Step: 3
Training loss: 1.1338683366775513
Validation loss: 2.024218507992324

Epoch: 6| Step: 4
Training loss: 1.8870153427124023
Validation loss: 2.026574612945639

Epoch: 6| Step: 5
Training loss: 1.7126102447509766
Validation loss: 1.9994378602632912

Epoch: 6| Step: 6
Training loss: 1.5288619995117188
Validation loss: 2.0285130918666883

Epoch: 6| Step: 7
Training loss: 1.5639111995697021
Validation loss: 2.033311874635758

Epoch: 6| Step: 8
Training loss: 1.0746442079544067
Validation loss: 1.9958892996593187

Epoch: 6| Step: 9
Training loss: 1.3812065124511719
Validation loss: 2.0605491899674937

Epoch: 6| Step: 10
Training loss: 1.1550116539001465
Validation loss: 2.0302396384618615

Epoch: 6| Step: 11
Training loss: 0.6396627426147461
Validation loss: 2.0291269145986086

Epoch: 6| Step: 12
Training loss: 1.2672163248062134
Validation loss: 2.0267442631465133

Epoch: 6| Step: 13
Training loss: 1.1250554323196411
Validation loss: 2.0083650773571384

Epoch: 648| Step: 0
Training loss: 1.7037907838821411
Validation loss: 1.9869150295052478

Epoch: 6| Step: 1
Training loss: 1.2959680557250977
Validation loss: 2.0307649284280758

Epoch: 6| Step: 2
Training loss: 1.463308572769165
Validation loss: 2.011075637673819

Epoch: 6| Step: 3
Training loss: 1.6588973999023438
Validation loss: 2.0125610213125906

Epoch: 6| Step: 4
Training loss: 0.9898298978805542
Validation loss: 1.9977019781707435

Epoch: 6| Step: 5
Training loss: 1.1234816312789917
Validation loss: 1.9771805988845004

Epoch: 6| Step: 6
Training loss: 1.1757192611694336
Validation loss: 1.9854540619798886

Epoch: 6| Step: 7
Training loss: 0.8583011031150818
Validation loss: 2.025152260257352

Epoch: 6| Step: 8
Training loss: 1.6288915872573853
Validation loss: 1.954125024939096

Epoch: 6| Step: 9
Training loss: 0.946945071220398
Validation loss: 1.985401270210102

Epoch: 6| Step: 10
Training loss: 1.4362969398498535
Validation loss: 1.9668307804292249

Epoch: 6| Step: 11
Training loss: 1.1828410625457764
Validation loss: 2.0310121543945803

Epoch: 6| Step: 12
Training loss: 1.6194956302642822
Validation loss: 2.0216058018387004

Epoch: 6| Step: 13
Training loss: 1.6143349409103394
Validation loss: 1.9858844895516672

Epoch: 649| Step: 0
Training loss: 0.9581139087677002
Validation loss: 2.010903496896067

Epoch: 6| Step: 1
Training loss: 1.1196229457855225
Validation loss: 2.0334445763659734

Epoch: 6| Step: 2
Training loss: 0.8603630065917969
Validation loss: 2.0332181504977647

Epoch: 6| Step: 3
Training loss: 1.1380218267440796
Validation loss: 2.063947635312234

Epoch: 6| Step: 4
Training loss: 2.066210985183716
Validation loss: 2.058129466989989

Epoch: 6| Step: 5
Training loss: 1.2779685258865356
Validation loss: 2.1405003968105523

Epoch: 6| Step: 6
Training loss: 1.6650432348251343
Validation loss: 2.0917127888689757

Epoch: 6| Step: 7
Training loss: 1.4444940090179443
Validation loss: 2.0647469528259768

Epoch: 6| Step: 8
Training loss: 1.0757105350494385
Validation loss: 2.1159575934051187

Epoch: 6| Step: 9
Training loss: 1.8522629737854004
Validation loss: 2.050895861400071

Epoch: 6| Step: 10
Training loss: 1.350098967552185
Validation loss: 2.041537238705543

Epoch: 6| Step: 11
Training loss: 1.0084450244903564
Validation loss: 2.038876405326269

Epoch: 6| Step: 12
Training loss: 1.2704412937164307
Validation loss: 1.9821461580132926

Epoch: 6| Step: 13
Training loss: 1.1915255784988403
Validation loss: 2.043479533605678

Epoch: 650| Step: 0
Training loss: 1.2795482873916626
Validation loss: 1.9972308361402122

Epoch: 6| Step: 1
Training loss: 1.054135799407959
Validation loss: 2.0226733838358233

Epoch: 6| Step: 2
Training loss: 2.2423501014709473
Validation loss: 1.9771296234541043

Epoch: 6| Step: 3
Training loss: 1.1452313661575317
Validation loss: 1.956179198398385

Epoch: 6| Step: 4
Training loss: 1.3837053775787354
Validation loss: 2.0057559192821546

Epoch: 6| Step: 5
Training loss: 1.0542330741882324
Validation loss: 2.0287759175864597

Epoch: 6| Step: 6
Training loss: 1.436652660369873
Validation loss: 1.973615771980696

Epoch: 6| Step: 7
Training loss: 1.0485574007034302
Validation loss: 2.016754558009486

Epoch: 6| Step: 8
Training loss: 0.8628782033920288
Validation loss: 1.9688106941920456

Epoch: 6| Step: 9
Training loss: 1.4845784902572632
Validation loss: 2.0010923211292555

Epoch: 6| Step: 10
Training loss: 0.9389311075210571
Validation loss: 1.9986778023422405

Epoch: 6| Step: 11
Training loss: 0.8600881099700928
Validation loss: 2.020996651341838

Epoch: 6| Step: 12
Training loss: 1.5771375894546509
Validation loss: 2.0325508579131095

Epoch: 6| Step: 13
Training loss: 1.1987969875335693
Validation loss: 2.007471230722243

Epoch: 651| Step: 0
Training loss: 1.3064048290252686
Validation loss: 1.9947070434529295

Epoch: 6| Step: 1
Training loss: 1.1591918468475342
Validation loss: 1.9831532227095736

Epoch: 6| Step: 2
Training loss: 1.3749427795410156
Validation loss: 2.025941720572851

Epoch: 6| Step: 3
Training loss: 1.6729626655578613
Validation loss: 2.0554572074644026

Epoch: 6| Step: 4
Training loss: 1.641201376914978
Validation loss: 1.9880013952973068

Epoch: 6| Step: 5
Training loss: 1.092879295349121
Validation loss: 2.014403030436526

Epoch: 6| Step: 6
Training loss: 0.6432185173034668
Validation loss: 2.003628500046269

Epoch: 6| Step: 7
Training loss: 0.9801260232925415
Validation loss: 2.023186686218426

Epoch: 6| Step: 8
Training loss: 1.0368740558624268
Validation loss: 1.9865646003394999

Epoch: 6| Step: 9
Training loss: 1.3642244338989258
Validation loss: 2.032868372496738

Epoch: 6| Step: 10
Training loss: 1.237815260887146
Validation loss: 1.9820199756212131

Epoch: 6| Step: 11
Training loss: 0.914294421672821
Validation loss: 1.990868458183863

Epoch: 6| Step: 12
Training loss: 1.4750165939331055
Validation loss: 2.036272123295774

Epoch: 6| Step: 13
Training loss: 1.8011927604675293
Validation loss: 1.9857465823491414

Epoch: 652| Step: 0
Training loss: 1.1226327419281006
Validation loss: 2.000714155935472

Epoch: 6| Step: 1
Training loss: 1.471060037612915
Validation loss: 2.016868074735006

Epoch: 6| Step: 2
Training loss: 1.0553185939788818
Validation loss: 2.025412428763605

Epoch: 6| Step: 3
Training loss: 1.3133901357650757
Validation loss: 1.9965034210553734

Epoch: 6| Step: 4
Training loss: 1.1021299362182617
Validation loss: 2.032181642388785

Epoch: 6| Step: 5
Training loss: 0.9691219925880432
Validation loss: 2.034324975423915

Epoch: 6| Step: 6
Training loss: 1.331579327583313
Validation loss: 2.0264588479072816

Epoch: 6| Step: 7
Training loss: 1.380063772201538
Validation loss: 2.0729093397817304

Epoch: 6| Step: 8
Training loss: 0.9319266676902771
Validation loss: 2.0495402402775262

Epoch: 6| Step: 9
Training loss: 1.4336405992507935
Validation loss: 2.047709171490003

Epoch: 6| Step: 10
Training loss: 1.2769367694854736
Validation loss: 2.0326132492352555

Epoch: 6| Step: 11
Training loss: 1.669280767440796
Validation loss: 2.047269158465888

Epoch: 6| Step: 12
Training loss: 1.260444164276123
Validation loss: 2.033075294186992

Epoch: 6| Step: 13
Training loss: 1.7816729545593262
Validation loss: 2.0736902144647416

Epoch: 653| Step: 0
Training loss: 0.9756672978401184
Validation loss: 1.9956509426075926

Epoch: 6| Step: 1
Training loss: 1.7950258255004883
Validation loss: 1.993013043557444

Epoch: 6| Step: 2
Training loss: 1.723914623260498
Validation loss: 1.9569418122691493

Epoch: 6| Step: 3
Training loss: 1.5800979137420654
Validation loss: 1.9723857936038767

Epoch: 6| Step: 4
Training loss: 0.7413046956062317
Validation loss: 1.9682309037895613

Epoch: 6| Step: 5
Training loss: 0.735482394695282
Validation loss: 2.0055328966468893

Epoch: 6| Step: 6
Training loss: 1.0158337354660034
Validation loss: 1.966837440767596

Epoch: 6| Step: 7
Training loss: 1.3759944438934326
Validation loss: 1.9674211625129945

Epoch: 6| Step: 8
Training loss: 1.1994553804397583
Validation loss: 2.0168695296010664

Epoch: 6| Step: 9
Training loss: 1.4633536338806152
Validation loss: 1.9805888129818825

Epoch: 6| Step: 10
Training loss: 0.9843072295188904
Validation loss: 2.044894472245247

Epoch: 6| Step: 11
Training loss: 2.050713062286377
Validation loss: 2.048827773781233

Epoch: 6| Step: 12
Training loss: 1.244565725326538
Validation loss: 1.9893189348200315

Epoch: 6| Step: 13
Training loss: 1.0958166122436523
Validation loss: 2.0561190241126606

Epoch: 654| Step: 0
Training loss: 0.9185872077941895
Validation loss: 2.0549748943698023

Epoch: 6| Step: 1
Training loss: 0.8811343312263489
Validation loss: 2.017799113386421

Epoch: 6| Step: 2
Training loss: 1.3504638671875
Validation loss: 1.9918644799981067

Epoch: 6| Step: 3
Training loss: 1.009128451347351
Validation loss: 2.06103342066529

Epoch: 6| Step: 4
Training loss: 1.177445650100708
Validation loss: 1.992348688904957

Epoch: 6| Step: 5
Training loss: 1.952279806137085
Validation loss: 2.0002167558157318

Epoch: 6| Step: 6
Training loss: 0.9033603072166443
Validation loss: 2.008863951570244

Epoch: 6| Step: 7
Training loss: 1.5836156606674194
Validation loss: 2.0094482001437934

Epoch: 6| Step: 8
Training loss: 0.8967337608337402
Validation loss: 2.0153103297756565

Epoch: 6| Step: 9
Training loss: 0.7605842351913452
Validation loss: 2.0188713086548673

Epoch: 6| Step: 10
Training loss: 1.659695029258728
Validation loss: 1.9914947209819671

Epoch: 6| Step: 11
Training loss: 1.1752336025238037
Validation loss: 2.025384392789615

Epoch: 6| Step: 12
Training loss: 1.5684432983398438
Validation loss: 2.0294034891231085

Epoch: 6| Step: 13
Training loss: 1.6470288038253784
Validation loss: 2.020275144166844

Epoch: 655| Step: 0
Training loss: 1.856162190437317
Validation loss: 2.047918353029477

Epoch: 6| Step: 1
Training loss: 1.2917356491088867
Validation loss: 2.0148841129836215

Epoch: 6| Step: 2
Training loss: 1.3768596649169922
Validation loss: 2.0121947808932235

Epoch: 6| Step: 3
Training loss: 0.8061063289642334
Validation loss: 1.9807100654930196

Epoch: 6| Step: 4
Training loss: 1.239906668663025
Validation loss: 2.0160168229892688

Epoch: 6| Step: 5
Training loss: 0.7608603239059448
Validation loss: 1.99584065457826

Epoch: 6| Step: 6
Training loss: 1.4247541427612305
Validation loss: 1.9960482069241103

Epoch: 6| Step: 7
Training loss: 1.163057565689087
Validation loss: 2.0117020427539782

Epoch: 6| Step: 8
Training loss: 1.0375983715057373
Validation loss: 2.0709059802434777

Epoch: 6| Step: 9
Training loss: 1.3715996742248535
Validation loss: 2.0391756719158542

Epoch: 6| Step: 10
Training loss: 2.087510585784912
Validation loss: 2.054979323059

Epoch: 6| Step: 11
Training loss: 1.1466872692108154
Validation loss: 2.009712888348487

Epoch: 6| Step: 12
Training loss: 0.9818509817123413
Validation loss: 1.994047603299541

Epoch: 6| Step: 13
Training loss: 0.8695419430732727
Validation loss: 1.9745520942954606

Epoch: 656| Step: 0
Training loss: 1.0669082403182983
Validation loss: 1.9959650155036681

Epoch: 6| Step: 1
Training loss: 1.251592755317688
Validation loss: 1.9988676758222683

Epoch: 6| Step: 2
Training loss: 1.0586273670196533
Validation loss: 2.0306099512243785

Epoch: 6| Step: 3
Training loss: 1.362712025642395
Validation loss: 1.990563477239301

Epoch: 6| Step: 4
Training loss: 1.203498363494873
Validation loss: 1.9480064722799486

Epoch: 6| Step: 5
Training loss: 1.216160535812378
Validation loss: 1.9959521114185292

Epoch: 6| Step: 6
Training loss: 1.4808263778686523
Validation loss: 2.00385275963814

Epoch: 6| Step: 7
Training loss: 1.2432461977005005
Validation loss: 1.97750380475034

Epoch: 6| Step: 8
Training loss: 2.270498275756836
Validation loss: 1.9498723117254113

Epoch: 6| Step: 9
Training loss: 0.8557040691375732
Validation loss: 2.011435998383389

Epoch: 6| Step: 10
Training loss: 1.0495507717132568
Validation loss: 2.0451224414251183

Epoch: 6| Step: 11
Training loss: 1.4370336532592773
Validation loss: 1.9974139377635012

Epoch: 6| Step: 12
Training loss: 1.6434619426727295
Validation loss: 2.0124554736639864

Epoch: 6| Step: 13
Training loss: 0.5903294682502747
Validation loss: 2.002322571251982

Epoch: 657| Step: 0
Training loss: 1.2409043312072754
Validation loss: 2.019562430279229

Epoch: 6| Step: 1
Training loss: 1.1816174983978271
Validation loss: 2.0633851200021724

Epoch: 6| Step: 2
Training loss: 0.9344523549079895
Validation loss: 2.0467307849596907

Epoch: 6| Step: 3
Training loss: 1.3445115089416504
Validation loss: 2.0707513350312428

Epoch: 6| Step: 4
Training loss: 1.6848957538604736
Validation loss: 2.082148330186003

Epoch: 6| Step: 5
Training loss: 0.8445848822593689
Validation loss: 2.017079755824099

Epoch: 6| Step: 6
Training loss: 1.365699291229248
Validation loss: 2.108398974582713

Epoch: 6| Step: 7
Training loss: 1.54823637008667
Validation loss: 2.0344181624791955

Epoch: 6| Step: 8
Training loss: 1.1067686080932617
Validation loss: 2.022944281178136

Epoch: 6| Step: 9
Training loss: 1.2667737007141113
Validation loss: 2.039510625664906

Epoch: 6| Step: 10
Training loss: 1.3696808815002441
Validation loss: 2.0615907894667758

Epoch: 6| Step: 11
Training loss: 1.2335031032562256
Validation loss: 2.019725057386583

Epoch: 6| Step: 12
Training loss: 1.094783902168274
Validation loss: 2.038805607826479

Epoch: 6| Step: 13
Training loss: 1.0341229438781738
Validation loss: 1.9663988172367055

Epoch: 658| Step: 0
Training loss: 1.0231794118881226
Validation loss: 1.986024123366161

Epoch: 6| Step: 1
Training loss: 1.245861530303955
Validation loss: 1.9511586107233518

Epoch: 6| Step: 2
Training loss: 1.1876527070999146
Validation loss: 2.0033774914280063

Epoch: 6| Step: 3
Training loss: 1.4470528364181519
Validation loss: 1.9784380658980338

Epoch: 6| Step: 4
Training loss: 1.0477385520935059
Validation loss: 1.9708323145425448

Epoch: 6| Step: 5
Training loss: 1.27915358543396
Validation loss: 1.9649647692198395

Epoch: 6| Step: 6
Training loss: 0.9996917247772217
Validation loss: 2.0167198437516407

Epoch: 6| Step: 7
Training loss: 1.1489604711532593
Validation loss: 1.979535933463804

Epoch: 6| Step: 8
Training loss: 1.095747470855713
Validation loss: 1.9951070162557787

Epoch: 6| Step: 9
Training loss: 1.5423247814178467
Validation loss: 1.9824583556062432

Epoch: 6| Step: 10
Training loss: 1.4518351554870605
Validation loss: 2.0052018268134004

Epoch: 6| Step: 11
Training loss: 1.1183955669403076
Validation loss: 1.9856006599241687

Epoch: 6| Step: 12
Training loss: 1.6745942831039429
Validation loss: 2.010395070557953

Epoch: 6| Step: 13
Training loss: 1.6906661987304688
Validation loss: 2.0527128506732244

Epoch: 659| Step: 0
Training loss: 1.5875228643417358
Validation loss: 2.1029766375018704

Epoch: 6| Step: 1
Training loss: 1.729755163192749
Validation loss: 2.0586060836750972

Epoch: 6| Step: 2
Training loss: 1.5052409172058105
Validation loss: 2.0958006305079304

Epoch: 6| Step: 3
Training loss: 1.9819415807724
Validation loss: 2.153531559052006

Epoch: 6| Step: 4
Training loss: 1.6401848793029785
Validation loss: 2.0978034465543685

Epoch: 6| Step: 5
Training loss: 0.9305341839790344
Validation loss: 2.0626684722080024

Epoch: 6| Step: 6
Training loss: 1.0661811828613281
Validation loss: 2.1289909398683937

Epoch: 6| Step: 7
Training loss: 1.1042208671569824
Validation loss: 2.0333204807773715

Epoch: 6| Step: 8
Training loss: 1.1145966053009033
Validation loss: 2.0680508793041272

Epoch: 6| Step: 9
Training loss: 0.8933859467506409
Validation loss: 2.0137349623505787

Epoch: 6| Step: 10
Training loss: 1.1099762916564941
Validation loss: 2.0242132550926617

Epoch: 6| Step: 11
Training loss: 0.9372583627700806
Validation loss: 2.00824466828377

Epoch: 6| Step: 12
Training loss: 1.2938001155853271
Validation loss: 2.0133546193440757

Epoch: 6| Step: 13
Training loss: 1.2928905487060547
Validation loss: 1.996923113381991

Epoch: 660| Step: 0
Training loss: 1.203153133392334
Validation loss: 1.9840799403446976

Epoch: 6| Step: 1
Training loss: 1.0240583419799805
Validation loss: 2.0112873764448267

Epoch: 6| Step: 2
Training loss: 0.8924121260643005
Validation loss: 2.006951114182831

Epoch: 6| Step: 3
Training loss: 1.3393093347549438
Validation loss: 2.031181791777252

Epoch: 6| Step: 4
Training loss: 1.6075563430786133
Validation loss: 2.0316048540094847

Epoch: 6| Step: 5
Training loss: 0.8340190649032593
Validation loss: 2.0174526437636344

Epoch: 6| Step: 6
Training loss: 1.2587004899978638
Validation loss: 2.01731530568933

Epoch: 6| Step: 7
Training loss: 1.6916441917419434
Validation loss: 1.998518814322769

Epoch: 6| Step: 8
Training loss: 1.196824312210083
Validation loss: 2.010313505767494

Epoch: 6| Step: 9
Training loss: 1.1047677993774414
Validation loss: 1.9851449920285134

Epoch: 6| Step: 10
Training loss: 1.4368597269058228
Validation loss: 2.0277531147003174

Epoch: 6| Step: 11
Training loss: 1.0328205823898315
Validation loss: 1.9653728482543782

Epoch: 6| Step: 12
Training loss: 1.7247092723846436
Validation loss: 2.005810711973457

Epoch: 6| Step: 13
Training loss: 0.8370696902275085
Validation loss: 2.021523931975006

Epoch: 661| Step: 0
Training loss: 1.229068636894226
Validation loss: 2.0194067442288963

Epoch: 6| Step: 1
Training loss: 1.0989820957183838
Validation loss: 1.9944804624844623

Epoch: 6| Step: 2
Training loss: 1.8843896389007568
Validation loss: 2.016157473287275

Epoch: 6| Step: 3
Training loss: 0.7630352973937988
Validation loss: 1.9804356110993253

Epoch: 6| Step: 4
Training loss: 1.3448727130889893
Validation loss: 2.020261167198099

Epoch: 6| Step: 5
Training loss: 1.1625044345855713
Validation loss: 1.9881387666989399

Epoch: 6| Step: 6
Training loss: 1.114192008972168
Validation loss: 1.989351866065815

Epoch: 6| Step: 7
Training loss: 0.8121221661567688
Validation loss: 2.018004189255417

Epoch: 6| Step: 8
Training loss: 1.0871189832687378
Validation loss: 1.9644829996170536

Epoch: 6| Step: 9
Training loss: 1.288593053817749
Validation loss: 1.9715549638194423

Epoch: 6| Step: 10
Training loss: 1.365741491317749
Validation loss: 1.9875339961821032

Epoch: 6| Step: 11
Training loss: 1.8260005712509155
Validation loss: 2.0626589969922136

Epoch: 6| Step: 12
Training loss: 1.1226576566696167
Validation loss: 1.9967238621045185

Epoch: 6| Step: 13
Training loss: 1.650182843208313
Validation loss: 2.0236427399419967

Epoch: 662| Step: 0
Training loss: 1.457566261291504
Validation loss: 2.0042797352678035

Epoch: 6| Step: 1
Training loss: 0.9066756963729858
Validation loss: 2.0635781288146973

Epoch: 6| Step: 2
Training loss: 2.1786489486694336
Validation loss: 2.001939901741602

Epoch: 6| Step: 3
Training loss: 0.7470487356185913
Validation loss: 1.9990454361002932

Epoch: 6| Step: 4
Training loss: 0.8565595149993896
Validation loss: 2.0087950639827277

Epoch: 6| Step: 5
Training loss: 1.2352794408798218
Validation loss: 2.0274877317490114

Epoch: 6| Step: 6
Training loss: 1.3347501754760742
Validation loss: 2.0132102735580935

Epoch: 6| Step: 7
Training loss: 1.397089958190918
Validation loss: 1.9980518817901611

Epoch: 6| Step: 8
Training loss: 1.054417610168457
Validation loss: 1.9494352930335588

Epoch: 6| Step: 9
Training loss: 0.9723683595657349
Validation loss: 1.9831366667183496

Epoch: 6| Step: 10
Training loss: 0.979067325592041
Validation loss: 1.9795208720750705

Epoch: 6| Step: 11
Training loss: 1.3093153238296509
Validation loss: 1.9668757787314795

Epoch: 6| Step: 12
Training loss: 1.334110975265503
Validation loss: 2.012024229572665

Epoch: 6| Step: 13
Training loss: 1.824724793434143
Validation loss: 2.001900338357495

Epoch: 663| Step: 0
Training loss: 1.8405990600585938
Validation loss: 2.0073829607297013

Epoch: 6| Step: 1
Training loss: 1.507279396057129
Validation loss: 1.9981875957981232

Epoch: 6| Step: 2
Training loss: 0.5081045627593994
Validation loss: 2.0164763555731824

Epoch: 6| Step: 3
Training loss: 1.4152886867523193
Validation loss: 2.002056970391222

Epoch: 6| Step: 4
Training loss: 1.133965015411377
Validation loss: 2.0146412593062206

Epoch: 6| Step: 5
Training loss: 1.4589905738830566
Validation loss: 1.9965347859167284

Epoch: 6| Step: 6
Training loss: 0.8489962816238403
Validation loss: 1.9956066813520206

Epoch: 6| Step: 7
Training loss: 1.653676986694336
Validation loss: 2.032409491077546

Epoch: 6| Step: 8
Training loss: 1.3672595024108887
Validation loss: 1.9795591292842742

Epoch: 6| Step: 9
Training loss: 1.2039225101470947
Validation loss: 2.027993690583014

Epoch: 6| Step: 10
Training loss: 1.316345453262329
Validation loss: 1.9792126378705424

Epoch: 6| Step: 11
Training loss: 0.8422921299934387
Validation loss: 1.955345307627032

Epoch: 6| Step: 12
Training loss: 0.7438622117042542
Validation loss: 2.0370929138634795

Epoch: 6| Step: 13
Training loss: 1.9195772409439087
Validation loss: 2.0183239342063986

Epoch: 664| Step: 0
Training loss: 0.7699995040893555
Validation loss: 2.0132518314546153

Epoch: 6| Step: 1
Training loss: 1.296196460723877
Validation loss: 1.9969590876692085

Epoch: 6| Step: 2
Training loss: 1.0650322437286377
Validation loss: 1.950295457275965

Epoch: 6| Step: 3
Training loss: 2.0100326538085938
Validation loss: 1.9798728291706373

Epoch: 6| Step: 4
Training loss: 0.9513822793960571
Validation loss: 2.0659713898935625

Epoch: 6| Step: 5
Training loss: 1.2120671272277832
Validation loss: 1.9593118890639274

Epoch: 6| Step: 6
Training loss: 1.5370811223983765
Validation loss: 1.9978849593029226

Epoch: 6| Step: 7
Training loss: 1.4782873392105103
Validation loss: 1.9847844800641459

Epoch: 6| Step: 8
Training loss: 1.252293586730957
Validation loss: 1.975950571798509

Epoch: 6| Step: 9
Training loss: 1.2932345867156982
Validation loss: 1.9757098805519842

Epoch: 6| Step: 10
Training loss: 1.2246390581130981
Validation loss: 2.003873468727194

Epoch: 6| Step: 11
Training loss: 1.1476328372955322
Validation loss: 1.9861092682807677

Epoch: 6| Step: 12
Training loss: 0.9676903486251831
Validation loss: 1.994420818103257

Epoch: 6| Step: 13
Training loss: 1.4881559610366821
Validation loss: 2.0153206086927846

Epoch: 665| Step: 0
Training loss: 1.049692153930664
Validation loss: 2.0427940955726047

Epoch: 6| Step: 1
Training loss: 0.7501022815704346
Validation loss: 2.057658641569076

Epoch: 6| Step: 2
Training loss: 0.8683229684829712
Validation loss: 2.052289248794638

Epoch: 6| Step: 3
Training loss: 2.1581687927246094
Validation loss: 2.088585592085315

Epoch: 6| Step: 4
Training loss: 1.7176086902618408
Validation loss: 2.0340507517578783

Epoch: 6| Step: 5
Training loss: 1.723069667816162
Validation loss: 2.055901168495096

Epoch: 6| Step: 6
Training loss: 1.0429285764694214
Validation loss: 2.043605168660482

Epoch: 6| Step: 7
Training loss: 0.9838698506355286
Validation loss: 2.0003640959339757

Epoch: 6| Step: 8
Training loss: 0.8818432092666626
Validation loss: 2.0397298092483194

Epoch: 6| Step: 9
Training loss: 1.8213629722595215
Validation loss: 2.0196422889668453

Epoch: 6| Step: 10
Training loss: 1.08917236328125
Validation loss: 2.0071144257822344

Epoch: 6| Step: 11
Training loss: 1.2119317054748535
Validation loss: 1.9818745723334692

Epoch: 6| Step: 12
Training loss: 1.0435112714767456
Validation loss: 1.9725926768395208

Epoch: 6| Step: 13
Training loss: 1.1698269844055176
Validation loss: 1.9763087213680308

Epoch: 666| Step: 0
Training loss: 2.017914056777954
Validation loss: 1.9701112162682317

Epoch: 6| Step: 1
Training loss: 1.133985996246338
Validation loss: 1.95947314077808

Epoch: 6| Step: 2
Training loss: 0.8657077550888062
Validation loss: 1.9985634216698267

Epoch: 6| Step: 3
Training loss: 1.5380377769470215
Validation loss: 1.96683201225855

Epoch: 6| Step: 4
Training loss: 0.8305574655532837
Validation loss: 1.992225100917201

Epoch: 6| Step: 5
Training loss: 1.4719741344451904
Validation loss: 1.9879078570232596

Epoch: 6| Step: 6
Training loss: 1.4100546836853027
Validation loss: 1.973238665570495

Epoch: 6| Step: 7
Training loss: 1.2598357200622559
Validation loss: 2.001500580900459

Epoch: 6| Step: 8
Training loss: 1.4305126667022705
Validation loss: 2.028378430233207

Epoch: 6| Step: 9
Training loss: 0.8515048027038574
Validation loss: 2.0356318745561826

Epoch: 6| Step: 10
Training loss: 0.9355984330177307
Validation loss: 1.9976003772468978

Epoch: 6| Step: 11
Training loss: 0.9831990599632263
Validation loss: 2.0238583908286145

Epoch: 6| Step: 12
Training loss: 1.714860439300537
Validation loss: 2.0289432053924887

Epoch: 6| Step: 13
Training loss: 0.8902308940887451
Validation loss: 1.9926769374519266

Epoch: 667| Step: 0
Training loss: 2.0657339096069336
Validation loss: 1.9775070349375408

Epoch: 6| Step: 1
Training loss: 0.8809555172920227
Validation loss: 1.9948767513357184

Epoch: 6| Step: 2
Training loss: 0.7972941398620605
Validation loss: 2.007127751586258

Epoch: 6| Step: 3
Training loss: 1.4209253787994385
Validation loss: 1.9565353803737189

Epoch: 6| Step: 4
Training loss: 2.0894503593444824
Validation loss: 1.9822029464988298

Epoch: 6| Step: 5
Training loss: 1.011998176574707
Validation loss: 1.9546905127904748

Epoch: 6| Step: 6
Training loss: 1.2796051502227783
Validation loss: 2.0340061521017425

Epoch: 6| Step: 7
Training loss: 1.7801051139831543
Validation loss: 1.9987106464242423

Epoch: 6| Step: 8
Training loss: 1.0133426189422607
Validation loss: 2.044455761550575

Epoch: 6| Step: 9
Training loss: 1.0722073316574097
Validation loss: 1.979100541401935

Epoch: 6| Step: 10
Training loss: 0.9642091393470764
Validation loss: 1.9608857682956162

Epoch: 6| Step: 11
Training loss: 0.7155361175537109
Validation loss: 1.9910600287939912

Epoch: 6| Step: 12
Training loss: 1.26632821559906
Validation loss: 2.052011856468775

Epoch: 6| Step: 13
Training loss: 1.0467817783355713
Validation loss: 2.014657735824585

Epoch: 668| Step: 0
Training loss: 1.2885459661483765
Validation loss: 2.0208424432303316

Epoch: 6| Step: 1
Training loss: 1.2107521295547485
Validation loss: 1.986470289127801

Epoch: 6| Step: 2
Training loss: 1.0293335914611816
Validation loss: 2.0413001891105407

Epoch: 6| Step: 3
Training loss: 0.7505166530609131
Validation loss: 1.9981606339895597

Epoch: 6| Step: 4
Training loss: 0.9597790241241455
Validation loss: 2.061320424079895

Epoch: 6| Step: 5
Training loss: 1.9278666973114014
Validation loss: 2.0135595208855084

Epoch: 6| Step: 6
Training loss: 1.39617919921875
Validation loss: 1.9558674981517177

Epoch: 6| Step: 7
Training loss: 1.0308496952056885
Validation loss: 2.0155335959567817

Epoch: 6| Step: 8
Training loss: 1.0302422046661377
Validation loss: 1.9916107141843407

Epoch: 6| Step: 9
Training loss: 1.1348226070404053
Validation loss: 1.975834410677674

Epoch: 6| Step: 10
Training loss: 1.019682765007019
Validation loss: 1.963140982453541

Epoch: 6| Step: 11
Training loss: 1.6824506521224976
Validation loss: 1.9653312378032233

Epoch: 6| Step: 12
Training loss: 1.6862634420394897
Validation loss: 2.052185253430438

Epoch: 6| Step: 13
Training loss: 1.1098090410232544
Validation loss: 1.970368722433685

Epoch: 669| Step: 0
Training loss: 1.0235239267349243
Validation loss: 2.0216195057797175

Epoch: 6| Step: 1
Training loss: 1.2147259712219238
Validation loss: 1.99927512163757

Epoch: 6| Step: 2
Training loss: 1.0528218746185303
Validation loss: 2.0191317271160822

Epoch: 6| Step: 3
Training loss: 1.122419834136963
Validation loss: 2.0339862928595593

Epoch: 6| Step: 4
Training loss: 1.2738268375396729
Validation loss: 2.032864583435879

Epoch: 6| Step: 5
Training loss: 0.9101901054382324
Validation loss: 2.033086912606352

Epoch: 6| Step: 6
Training loss: 1.5542603731155396
Validation loss: 2.0257350911376295

Epoch: 6| Step: 7
Training loss: 1.6127283573150635
Validation loss: 1.9992364298912786

Epoch: 6| Step: 8
Training loss: 1.0253477096557617
Validation loss: 2.0335430816937516

Epoch: 6| Step: 9
Training loss: 1.7062500715255737
Validation loss: 2.0163544198518157

Epoch: 6| Step: 10
Training loss: 1.4552586078643799
Validation loss: 1.9779892172864688

Epoch: 6| Step: 11
Training loss: 1.2523740530014038
Validation loss: 1.9876642457900509

Epoch: 6| Step: 12
Training loss: 0.8937668204307556
Validation loss: 2.0210307772441576

Epoch: 6| Step: 13
Training loss: 1.3701534271240234
Validation loss: 1.9755524076441282

Epoch: 670| Step: 0
Training loss: 2.3446669578552246
Validation loss: 1.9906674636307584

Epoch: 6| Step: 1
Training loss: 1.4780527353286743
Validation loss: 2.0003839333852134

Epoch: 6| Step: 2
Training loss: 1.051600456237793
Validation loss: 1.9959286451339722

Epoch: 6| Step: 3
Training loss: 1.2522540092468262
Validation loss: 2.001586780753187

Epoch: 6| Step: 4
Training loss: 1.0496811866760254
Validation loss: 2.0153064573964765

Epoch: 6| Step: 5
Training loss: 0.8201532363891602
Validation loss: 2.043545796025184

Epoch: 6| Step: 6
Training loss: 0.9022783041000366
Validation loss: 2.0090940178081556

Epoch: 6| Step: 7
Training loss: 1.134214997291565
Validation loss: 2.0635294862972793

Epoch: 6| Step: 8
Training loss: 1.051529884338379
Validation loss: 2.0366555977893133

Epoch: 6| Step: 9
Training loss: 1.129098653793335
Validation loss: 1.9891643370351484

Epoch: 6| Step: 10
Training loss: 1.2205967903137207
Validation loss: 2.037099274255896

Epoch: 6| Step: 11
Training loss: 1.065518856048584
Validation loss: 2.0246636662431943

Epoch: 6| Step: 12
Training loss: 1.1558752059936523
Validation loss: 1.961421315388013

Epoch: 6| Step: 13
Training loss: 1.5948525667190552
Validation loss: 1.9863848135035524

Epoch: 671| Step: 0
Training loss: 1.0641802549362183
Validation loss: 2.014792829431513

Epoch: 6| Step: 1
Training loss: 1.0779011249542236
Validation loss: 1.9848538034705705

Epoch: 6| Step: 2
Training loss: 1.3135219812393188
Validation loss: 2.001510391953171

Epoch: 6| Step: 3
Training loss: 1.3159533739089966
Validation loss: 1.9924390444191553

Epoch: 6| Step: 4
Training loss: 1.1476068496704102
Validation loss: 1.931194346438172

Epoch: 6| Step: 5
Training loss: 1.531394124031067
Validation loss: 1.9737808755649033

Epoch: 6| Step: 6
Training loss: 1.1241905689239502
Validation loss: 1.9840116218854023

Epoch: 6| Step: 7
Training loss: 1.2299354076385498
Validation loss: 1.9938115496789255

Epoch: 6| Step: 8
Training loss: 1.1300617456436157
Validation loss: 1.9554216336178523

Epoch: 6| Step: 9
Training loss: 1.5837678909301758
Validation loss: 1.9884871487976403

Epoch: 6| Step: 10
Training loss: 1.3157179355621338
Validation loss: 1.978711696081264

Epoch: 6| Step: 11
Training loss: 0.8647618293762207
Validation loss: 1.9710221931498537

Epoch: 6| Step: 12
Training loss: 1.1769005060195923
Validation loss: 2.0448431532870055

Epoch: 6| Step: 13
Training loss: 1.1810399293899536
Validation loss: 1.9559712922701271

Epoch: 672| Step: 0
Training loss: 0.9290958046913147
Validation loss: 1.9970043833537767

Epoch: 6| Step: 1
Training loss: 1.7861878871917725
Validation loss: 1.993931963879575

Epoch: 6| Step: 2
Training loss: 0.912787914276123
Validation loss: 1.9660405881943241

Epoch: 6| Step: 3
Training loss: 1.2157219648361206
Validation loss: 2.031958318525745

Epoch: 6| Step: 4
Training loss: 1.1915624141693115
Validation loss: 2.019532416456489

Epoch: 6| Step: 5
Training loss: 0.9478947520256042
Validation loss: 2.0604614762849707

Epoch: 6| Step: 6
Training loss: 1.3390547037124634
Validation loss: 2.01416899055563

Epoch: 6| Step: 7
Training loss: 1.1581261157989502
Validation loss: 2.028004200227799

Epoch: 6| Step: 8
Training loss: 1.45265531539917
Validation loss: 1.9857195064585695

Epoch: 6| Step: 9
Training loss: 1.047971248626709
Validation loss: 2.013844745133513

Epoch: 6| Step: 10
Training loss: 0.9247848391532898
Validation loss: 1.9835645806404851

Epoch: 6| Step: 11
Training loss: 0.9807629585266113
Validation loss: 2.0385416246229604

Epoch: 6| Step: 12
Training loss: 1.7771689891815186
Validation loss: 1.9623717184989684

Epoch: 6| Step: 13
Training loss: 1.7541637420654297
Validation loss: 1.985836693035659

Epoch: 673| Step: 0
Training loss: 0.9063991904258728
Validation loss: 2.0391407576940392

Epoch: 6| Step: 1
Training loss: 1.3584222793579102
Validation loss: 2.0243245658054145

Epoch: 6| Step: 2
Training loss: 1.2669906616210938
Validation loss: 2.002369737112394

Epoch: 6| Step: 3
Training loss: 1.3869524002075195
Validation loss: 2.0138520553547847

Epoch: 6| Step: 4
Training loss: 1.0500900745391846
Validation loss: 2.0449666079654487

Epoch: 6| Step: 5
Training loss: 0.8186012506484985
Validation loss: 2.007762811517203

Epoch: 6| Step: 6
Training loss: 1.463140845298767
Validation loss: 2.043681213932653

Epoch: 6| Step: 7
Training loss: 1.4883321523666382
Validation loss: 2.0740365905146443

Epoch: 6| Step: 8
Training loss: 1.2440948486328125
Validation loss: 2.0292645962007585

Epoch: 6| Step: 9
Training loss: 1.3199527263641357
Validation loss: 2.0032185636540896

Epoch: 6| Step: 10
Training loss: 0.8823699951171875
Validation loss: 2.0272615096902333

Epoch: 6| Step: 11
Training loss: 1.8576624393463135
Validation loss: 2.0441474042912966

Epoch: 6| Step: 12
Training loss: 1.3408159017562866
Validation loss: 1.9575981657992128

Epoch: 6| Step: 13
Training loss: 0.4774574637413025
Validation loss: 1.9975132250016736

Epoch: 674| Step: 0
Training loss: 1.9152328968048096
Validation loss: 2.013142490899691

Epoch: 6| Step: 1
Training loss: 1.4182662963867188
Validation loss: 1.9501919566944081

Epoch: 6| Step: 2
Training loss: 0.9255586266517639
Validation loss: 2.03350930829202

Epoch: 6| Step: 3
Training loss: 0.9566956758499146
Validation loss: 2.0069682764750656

Epoch: 6| Step: 4
Training loss: 0.6776725649833679
Validation loss: 2.0101927313753354

Epoch: 6| Step: 5
Training loss: 0.9917362332344055
Validation loss: 2.015683515097505

Epoch: 6| Step: 6
Training loss: 1.841791033744812
Validation loss: 2.025216402546052

Epoch: 6| Step: 7
Training loss: 1.4304133653640747
Validation loss: 2.010059618180798

Epoch: 6| Step: 8
Training loss: 1.0278260707855225
Validation loss: 2.101137104854789

Epoch: 6| Step: 9
Training loss: 1.657167911529541
Validation loss: 2.0282856136239986

Epoch: 6| Step: 10
Training loss: 1.0858557224273682
Validation loss: 1.9895277664225588

Epoch: 6| Step: 11
Training loss: 1.2192567586898804
Validation loss: 2.0514959135363178

Epoch: 6| Step: 12
Training loss: 0.8372088670730591
Validation loss: 2.044955130546324

Epoch: 6| Step: 13
Training loss: 0.9757088422775269
Validation loss: 1.9835824479338944

Epoch: 675| Step: 0
Training loss: 1.4266178607940674
Validation loss: 2.005953017101493

Epoch: 6| Step: 1
Training loss: 1.0634825229644775
Validation loss: 2.027888327516535

Epoch: 6| Step: 2
Training loss: 1.2534373998641968
Validation loss: 1.9966520032575052

Epoch: 6| Step: 3
Training loss: 0.67741858959198
Validation loss: 1.9738625928919802

Epoch: 6| Step: 4
Training loss: 1.2232331037521362
Validation loss: 2.046406654901402

Epoch: 6| Step: 5
Training loss: 1.8375846147537231
Validation loss: 1.9660709083721202

Epoch: 6| Step: 6
Training loss: 1.0923025608062744
Validation loss: 1.9684240997478526

Epoch: 6| Step: 7
Training loss: 1.6381251811981201
Validation loss: 2.0043708650014733

Epoch: 6| Step: 8
Training loss: 1.5180070400238037
Validation loss: 1.9966228187725108

Epoch: 6| Step: 9
Training loss: 1.3176378011703491
Validation loss: 1.997283815055765

Epoch: 6| Step: 10
Training loss: 1.3475720882415771
Validation loss: 1.9633564128670642

Epoch: 6| Step: 11
Training loss: 1.0494413375854492
Validation loss: 1.989866538714337

Epoch: 6| Step: 12
Training loss: 0.9078483581542969
Validation loss: 1.9554283413835751

Epoch: 6| Step: 13
Training loss: 1.0303304195404053
Validation loss: 1.9514790094026955

Epoch: 676| Step: 0
Training loss: 1.7244199514389038
Validation loss: 1.990916085499589

Epoch: 6| Step: 1
Training loss: 1.466982364654541
Validation loss: 1.9589298694364485

Epoch: 6| Step: 2
Training loss: 0.9161808490753174
Validation loss: 1.9895834717699277

Epoch: 6| Step: 3
Training loss: 1.1799296140670776
Validation loss: 2.0316001087106685

Epoch: 6| Step: 4
Training loss: 1.1783478260040283
Validation loss: 1.9841462348097114

Epoch: 6| Step: 5
Training loss: 1.3774884939193726
Validation loss: 2.0294341887197187

Epoch: 6| Step: 6
Training loss: 0.9647375345230103
Validation loss: 1.9871375663306123

Epoch: 6| Step: 7
Training loss: 1.2599114179611206
Validation loss: 2.0337701125811507

Epoch: 6| Step: 8
Training loss: 1.0960874557495117
Validation loss: 2.021766180633217

Epoch: 6| Step: 9
Training loss: 1.4754137992858887
Validation loss: 2.0038398465802594

Epoch: 6| Step: 10
Training loss: 0.9236282110214233
Validation loss: 2.004618206331807

Epoch: 6| Step: 11
Training loss: 1.260803461074829
Validation loss: 2.006180760680988

Epoch: 6| Step: 12
Training loss: 0.90589839220047
Validation loss: 1.9610359848186534

Epoch: 6| Step: 13
Training loss: 1.095628023147583
Validation loss: 2.0075674774826213

Epoch: 677| Step: 0
Training loss: 1.8326019048690796
Validation loss: 1.9867393816671064

Epoch: 6| Step: 1
Training loss: 1.1854372024536133
Validation loss: 1.9834886853412916

Epoch: 6| Step: 2
Training loss: 1.9097968339920044
Validation loss: 2.0082860915891585

Epoch: 6| Step: 3
Training loss: 1.0492247343063354
Validation loss: 1.987582827127108

Epoch: 6| Step: 4
Training loss: 0.9767862558364868
Validation loss: 1.9831447011681014

Epoch: 6| Step: 5
Training loss: 1.2281675338745117
Validation loss: 2.0248391564174364

Epoch: 6| Step: 6
Training loss: 0.7382786870002747
Validation loss: 1.9316884740706413

Epoch: 6| Step: 7
Training loss: 1.413669228553772
Validation loss: 1.9207935153797109

Epoch: 6| Step: 8
Training loss: 1.1492811441421509
Validation loss: 1.9680323587950839

Epoch: 6| Step: 9
Training loss: 0.6271350979804993
Validation loss: 1.989743628809529

Epoch: 6| Step: 10
Training loss: 1.032547950744629
Validation loss: 1.9943581640079457

Epoch: 6| Step: 11
Training loss: 1.0927958488464355
Validation loss: 1.9621070969489314

Epoch: 6| Step: 12
Training loss: 1.6485992670059204
Validation loss: 2.0103775019286783

Epoch: 6| Step: 13
Training loss: 1.0694130659103394
Validation loss: 2.016601821427704

Epoch: 678| Step: 0
Training loss: 1.4043056964874268
Validation loss: 1.9950475423566756

Epoch: 6| Step: 1
Training loss: 1.867972731590271
Validation loss: 2.0537261193798435

Epoch: 6| Step: 2
Training loss: 1.8324923515319824
Validation loss: 2.0429651762849543

Epoch: 6| Step: 3
Training loss: 0.8193296790122986
Validation loss: 2.0000555874198995

Epoch: 6| Step: 4
Training loss: 1.1673535108566284
Validation loss: 2.036796595460625

Epoch: 6| Step: 5
Training loss: 1.1079738140106201
Validation loss: 2.0389068331769717

Epoch: 6| Step: 6
Training loss: 1.3886046409606934
Validation loss: 1.9610624390263711

Epoch: 6| Step: 7
Training loss: 0.943536639213562
Validation loss: 2.024818415282875

Epoch: 6| Step: 8
Training loss: 0.8618464469909668
Validation loss: 1.98328766258814

Epoch: 6| Step: 9
Training loss: 1.6184715032577515
Validation loss: 1.9867125147132463

Epoch: 6| Step: 10
Training loss: 1.1109466552734375
Validation loss: 1.9858310107261903

Epoch: 6| Step: 11
Training loss: 1.0308715105056763
Validation loss: 2.005425032748971

Epoch: 6| Step: 12
Training loss: 1.2325785160064697
Validation loss: 2.0241048976939213

Epoch: 6| Step: 13
Training loss: 1.081289291381836
Validation loss: 1.9799434164518952

Epoch: 679| Step: 0
Training loss: 1.452521800994873
Validation loss: 1.9435765973983272

Epoch: 6| Step: 1
Training loss: 1.0588743686676025
Validation loss: 1.965327319278512

Epoch: 6| Step: 2
Training loss: 1.277046799659729
Validation loss: 1.9787200766225015

Epoch: 6| Step: 3
Training loss: 1.2646045684814453
Validation loss: 1.9911270397965626

Epoch: 6| Step: 4
Training loss: 0.9873663187026978
Validation loss: 2.013929177356023

Epoch: 6| Step: 5
Training loss: 1.1917724609375
Validation loss: 2.0517181196520404

Epoch: 6| Step: 6
Training loss: 1.8507561683654785
Validation loss: 1.9723795960026402

Epoch: 6| Step: 7
Training loss: 0.8414855599403381
Validation loss: 2.0392850240071616

Epoch: 6| Step: 8
Training loss: 1.1605664491653442
Validation loss: 2.011702040190338

Epoch: 6| Step: 9
Training loss: 1.4042550325393677
Validation loss: 1.9897751385165798

Epoch: 6| Step: 10
Training loss: 0.9929490089416504
Validation loss: 2.042081538067069

Epoch: 6| Step: 11
Training loss: 1.324833869934082
Validation loss: 2.0229249077458538

Epoch: 6| Step: 12
Training loss: 0.8742581605911255
Validation loss: 1.9659894435636458

Epoch: 6| Step: 13
Training loss: 1.4078309535980225
Validation loss: 2.0177070427966375

Epoch: 680| Step: 0
Training loss: 1.049893856048584
Validation loss: 1.9690230802823139

Epoch: 6| Step: 1
Training loss: 1.5916244983673096
Validation loss: 1.9692445108967442

Epoch: 6| Step: 2
Training loss: 0.9029361009597778
Validation loss: 2.0150606555323445

Epoch: 6| Step: 3
Training loss: 1.474694013595581
Validation loss: 1.9868937974335046

Epoch: 6| Step: 4
Training loss: 1.1213579177856445
Validation loss: 1.9562465554924422

Epoch: 6| Step: 5
Training loss: 1.4259586334228516
Validation loss: 2.0282430930804183

Epoch: 6| Step: 6
Training loss: 0.9886840581893921
Validation loss: 1.9395795227378927

Epoch: 6| Step: 7
Training loss: 1.6875513792037964
Validation loss: 2.00032655654415

Epoch: 6| Step: 8
Training loss: 1.444893479347229
Validation loss: 1.9660255280874108

Epoch: 6| Step: 9
Training loss: 1.2435733079910278
Validation loss: 2.0066054662068686

Epoch: 6| Step: 10
Training loss: 1.0777688026428223
Validation loss: 1.9749527387721564

Epoch: 6| Step: 11
Training loss: 1.173660159111023
Validation loss: 2.00403308099316

Epoch: 6| Step: 12
Training loss: 0.8354860544204712
Validation loss: 1.940670382591986

Epoch: 6| Step: 13
Training loss: 1.3157910108566284
Validation loss: 2.003802658409201

Epoch: 681| Step: 0
Training loss: 0.8112268447875977
Validation loss: 1.9720441243981803

Epoch: 6| Step: 1
Training loss: 1.5951082706451416
Validation loss: 2.024073931478685

Epoch: 6| Step: 2
Training loss: 1.4137859344482422
Validation loss: 2.074295574618924

Epoch: 6| Step: 3
Training loss: 0.8893181085586548
Validation loss: 2.0476798024228824

Epoch: 6| Step: 4
Training loss: 1.2635679244995117
Validation loss: 2.0130861497694448

Epoch: 6| Step: 5
Training loss: 1.210328459739685
Validation loss: 2.021666652412825

Epoch: 6| Step: 6
Training loss: 1.1736159324645996
Validation loss: 2.0249313462165093

Epoch: 6| Step: 7
Training loss: 1.8639037609100342
Validation loss: 2.0485460899209462

Epoch: 6| Step: 8
Training loss: 0.5584230422973633
Validation loss: 2.0750623967057917

Epoch: 6| Step: 9
Training loss: 1.584802269935608
Validation loss: 2.058833029962355

Epoch: 6| Step: 10
Training loss: 0.9801418781280518
Validation loss: 2.0589713588837655

Epoch: 6| Step: 11
Training loss: 1.2631070613861084
Validation loss: 2.0486733887785222

Epoch: 6| Step: 12
Training loss: 1.37357759475708
Validation loss: 2.0783614855940624

Epoch: 6| Step: 13
Training loss: 1.4384666681289673
Validation loss: 2.02000944588774

Epoch: 682| Step: 0
Training loss: 0.8682116270065308
Validation loss: 2.067014535268148

Epoch: 6| Step: 1
Training loss: 1.4124335050582886
Validation loss: 1.9400199843991188

Epoch: 6| Step: 2
Training loss: 0.6212573051452637
Validation loss: 2.0233638876227924

Epoch: 6| Step: 3
Training loss: 1.1585664749145508
Validation loss: 1.9932488010775657

Epoch: 6| Step: 4
Training loss: 1.0702078342437744
Validation loss: 2.0336610360812117

Epoch: 6| Step: 5
Training loss: 1.2069003582000732
Validation loss: 1.9486063834159606

Epoch: 6| Step: 6
Training loss: 0.9114013910293579
Validation loss: 1.9740824366128573

Epoch: 6| Step: 7
Training loss: 0.9506430625915527
Validation loss: 1.965129970222391

Epoch: 6| Step: 8
Training loss: 2.275470733642578
Validation loss: 1.9926707026779011

Epoch: 6| Step: 9
Training loss: 1.3266360759735107
Validation loss: 1.9732162029512468

Epoch: 6| Step: 10
Training loss: 1.0408402681350708
Validation loss: 1.9809435285547727

Epoch: 6| Step: 11
Training loss: 1.272664189338684
Validation loss: 2.0236669663460023

Epoch: 6| Step: 12
Training loss: 1.6755534410476685
Validation loss: 1.97999559679339

Epoch: 6| Step: 13
Training loss: 1.224099040031433
Validation loss: 1.9776119673123924

Epoch: 683| Step: 0
Training loss: 1.625140905380249
Validation loss: 1.9831216053296161

Epoch: 6| Step: 1
Training loss: 0.8948033452033997
Validation loss: 1.9998977620114562

Epoch: 6| Step: 2
Training loss: 1.2494875192642212
Validation loss: 2.0035525778288483

Epoch: 6| Step: 3
Training loss: 0.9535723328590393
Validation loss: 1.9515609689938125

Epoch: 6| Step: 4
Training loss: 1.2875406742095947
Validation loss: 1.9736369297068606

Epoch: 6| Step: 5
Training loss: 1.2767205238342285
Validation loss: 2.0257383815703855

Epoch: 6| Step: 6
Training loss: 1.6162066459655762
Validation loss: 1.9990909727670814

Epoch: 6| Step: 7
Training loss: 0.8232362866401672
Validation loss: 2.0314221817960023

Epoch: 6| Step: 8
Training loss: 1.4445888996124268
Validation loss: 2.009328631944554

Epoch: 6| Step: 9
Training loss: 1.6522140502929688
Validation loss: 1.953941220878273

Epoch: 6| Step: 10
Training loss: 1.121631383895874
Validation loss: 2.0140905751976916

Epoch: 6| Step: 11
Training loss: 1.3347413539886475
Validation loss: 2.013560348941434

Epoch: 6| Step: 12
Training loss: 0.8050763607025146
Validation loss: 1.970577432263282

Epoch: 6| Step: 13
Training loss: 1.2418960332870483
Validation loss: 2.0004395900234098

Epoch: 684| Step: 0
Training loss: 2.0282163619995117
Validation loss: 1.9854743557591592

Epoch: 6| Step: 1
Training loss: 1.0029187202453613
Validation loss: 2.0518113374710083

Epoch: 6| Step: 2
Training loss: 0.7674735188484192
Validation loss: 1.9791771904114754

Epoch: 6| Step: 3
Training loss: 0.7761582732200623
Validation loss: 2.006020035794986

Epoch: 6| Step: 4
Training loss: 1.045678973197937
Validation loss: 2.0112375290163103

Epoch: 6| Step: 5
Training loss: 1.2055878639221191
Validation loss: 1.9871811148940877

Epoch: 6| Step: 6
Training loss: 1.6274421215057373
Validation loss: 2.007481716012442

Epoch: 6| Step: 7
Training loss: 1.5492475032806396
Validation loss: 1.9897799081699823

Epoch: 6| Step: 8
Training loss: 1.2309530973434448
Validation loss: 2.050462781742055

Epoch: 6| Step: 9
Training loss: 1.4728859663009644
Validation loss: 1.9883453845977783

Epoch: 6| Step: 10
Training loss: 0.7831929922103882
Validation loss: 1.9813306613634991

Epoch: 6| Step: 11
Training loss: 1.6104501485824585
Validation loss: 2.0368090060449417

Epoch: 6| Step: 12
Training loss: 0.9962514638900757
Validation loss: 2.011430650629023

Epoch: 6| Step: 13
Training loss: 0.7106766104698181
Validation loss: 2.0217681482274044

Epoch: 685| Step: 0
Training loss: 1.3129682540893555
Validation loss: 1.9885508014309792

Epoch: 6| Step: 1
Training loss: 0.8127526044845581
Validation loss: 1.965270919184531

Epoch: 6| Step: 2
Training loss: 1.2962408065795898
Validation loss: 1.9977327136583225

Epoch: 6| Step: 3
Training loss: 0.9743397831916809
Validation loss: 1.9755797680988108

Epoch: 6| Step: 4
Training loss: 1.475616693496704
Validation loss: 2.0078377672421035

Epoch: 6| Step: 5
Training loss: 0.7884300351142883
Validation loss: 1.964501775721068

Epoch: 6| Step: 6
Training loss: 1.867179036140442
Validation loss: 1.9728912640643377

Epoch: 6| Step: 7
Training loss: 1.488088607788086
Validation loss: 2.0430576621845202

Epoch: 6| Step: 8
Training loss: 1.0284702777862549
Validation loss: 2.0265948644248386

Epoch: 6| Step: 9
Training loss: 0.9008390307426453
Validation loss: 2.0261747978066884

Epoch: 6| Step: 10
Training loss: 0.9986491799354553
Validation loss: 2.0478142692196752

Epoch: 6| Step: 11
Training loss: 1.65540611743927
Validation loss: 2.0604574936692432

Epoch: 6| Step: 12
Training loss: 0.9667183756828308
Validation loss: 1.9549822589402557

Epoch: 6| Step: 13
Training loss: 1.4021944999694824
Validation loss: 2.040124730397296

Epoch: 686| Step: 0
Training loss: 1.5120283365249634
Validation loss: 2.0105888279535438

Epoch: 6| Step: 1
Training loss: 1.0709750652313232
Validation loss: 2.0027519092764905

Epoch: 6| Step: 2
Training loss: 1.528764247894287
Validation loss: 2.0196313294031287

Epoch: 6| Step: 3
Training loss: 1.254533290863037
Validation loss: 2.0091437896092734

Epoch: 6| Step: 4
Training loss: 0.9399048686027527
Validation loss: 1.9660855800874772

Epoch: 6| Step: 5
Training loss: 0.8757377862930298
Validation loss: 2.040398547726293

Epoch: 6| Step: 6
Training loss: 1.0286225080490112
Validation loss: 1.9549904741266722

Epoch: 6| Step: 7
Training loss: 1.3395800590515137
Validation loss: 2.023417293384511

Epoch: 6| Step: 8
Training loss: 0.8893799185752869
Validation loss: 2.026033848844549

Epoch: 6| Step: 9
Training loss: 1.233034372329712
Validation loss: 2.0331999076310026

Epoch: 6| Step: 10
Training loss: 1.6963812112808228
Validation loss: 1.9634491576943347

Epoch: 6| Step: 11
Training loss: 1.2179946899414062
Validation loss: 1.997740953199325

Epoch: 6| Step: 12
Training loss: 1.69875967502594
Validation loss: 1.9505192772034676

Epoch: 6| Step: 13
Training loss: 0.6549835801124573
Validation loss: 1.9824793261866416

Epoch: 687| Step: 0
Training loss: 0.9691606760025024
Validation loss: 1.9880320513120262

Epoch: 6| Step: 1
Training loss: 1.1211705207824707
Validation loss: 1.9443482942478632

Epoch: 6| Step: 2
Training loss: 1.0247002840042114
Validation loss: 1.9252970987750637

Epoch: 6| Step: 3
Training loss: 0.9969933032989502
Validation loss: 1.961524490387209

Epoch: 6| Step: 4
Training loss: 1.58655846118927
Validation loss: 1.9740598842661867

Epoch: 6| Step: 5
Training loss: 1.034095048904419
Validation loss: 1.9786362314736972

Epoch: 6| Step: 6
Training loss: 1.911637783050537
Validation loss: 1.9544832039904851

Epoch: 6| Step: 7
Training loss: 1.2882497310638428
Validation loss: 1.9720607047439904

Epoch: 6| Step: 8
Training loss: 1.2438839673995972
Validation loss: 2.0110971773824384

Epoch: 6| Step: 9
Training loss: 1.2198364734649658
Validation loss: 2.0031007618032475

Epoch: 6| Step: 10
Training loss: 0.737810492515564
Validation loss: 1.9775393060458604

Epoch: 6| Step: 11
Training loss: 0.7952902913093567
Validation loss: 2.014466688197146

Epoch: 6| Step: 12
Training loss: 1.3563966751098633
Validation loss: 2.0334681067415463

Epoch: 6| Step: 13
Training loss: 1.8532652854919434
Validation loss: 1.9914503161625197

Epoch: 688| Step: 0
Training loss: 0.5489630699157715
Validation loss: 1.9819184323792816

Epoch: 6| Step: 1
Training loss: 1.2319066524505615
Validation loss: 2.0117363481111425

Epoch: 6| Step: 2
Training loss: 1.189752459526062
Validation loss: 2.0058276127743464

Epoch: 6| Step: 3
Training loss: 1.1527953147888184
Validation loss: 1.9162919136785692

Epoch: 6| Step: 4
Training loss: 1.0397616624832153
Validation loss: 1.9670996499317948

Epoch: 6| Step: 5
Training loss: 0.7209581136703491
Validation loss: 2.020433771994806

Epoch: 6| Step: 6
Training loss: 1.2031211853027344
Validation loss: 1.9717787414468744

Epoch: 6| Step: 7
Training loss: 1.6590999364852905
Validation loss: 1.9910699936651415

Epoch: 6| Step: 8
Training loss: 1.4275490045547485
Validation loss: 1.9023837709939608

Epoch: 6| Step: 9
Training loss: 1.6115672588348389
Validation loss: 1.9961074424046341

Epoch: 6| Step: 10
Training loss: 1.995598554611206
Validation loss: 1.9585370658546366

Epoch: 6| Step: 11
Training loss: 1.5238217115402222
Validation loss: 1.9748772466054527

Epoch: 6| Step: 12
Training loss: 0.6715151071548462
Validation loss: 1.947354708948443

Epoch: 6| Step: 13
Training loss: 1.3495758771896362
Validation loss: 2.0007774881137315

Epoch: 689| Step: 0
Training loss: 0.6800792217254639
Validation loss: 1.949936148940876

Epoch: 6| Step: 1
Training loss: 1.4026931524276733
Validation loss: 1.963430917391213

Epoch: 6| Step: 2
Training loss: 1.303324818611145
Validation loss: 1.9569805155518234

Epoch: 6| Step: 3
Training loss: 0.9162498712539673
Validation loss: 1.9758921246374808

Epoch: 6| Step: 4
Training loss: 2.0985188484191895
Validation loss: 1.966620893888576

Epoch: 6| Step: 5
Training loss: 1.0095094442367554
Validation loss: 2.002209517263597

Epoch: 6| Step: 6
Training loss: 1.4741637706756592
Validation loss: 1.9873092270666552

Epoch: 6| Step: 7
Training loss: 1.5008686780929565
Validation loss: 1.967387694184498

Epoch: 6| Step: 8
Training loss: 0.7564245462417603
Validation loss: 1.9513293568805983

Epoch: 6| Step: 9
Training loss: 0.7961807250976562
Validation loss: 1.9613608890964138

Epoch: 6| Step: 10
Training loss: 1.2259207963943481
Validation loss: 1.9712998956762335

Epoch: 6| Step: 11
Training loss: 1.0640766620635986
Validation loss: 1.991048478311108

Epoch: 6| Step: 12
Training loss: 1.427126169204712
Validation loss: 1.9992873053396902

Epoch: 6| Step: 13
Training loss: 1.2483633756637573
Validation loss: 1.9500590767911685

Epoch: 690| Step: 0
Training loss: 1.6830304861068726
Validation loss: 1.9378193168229954

Epoch: 6| Step: 1
Training loss: 1.411290168762207
Validation loss: 1.9798160547851233

Epoch: 6| Step: 2
Training loss: 1.7432548999786377
Validation loss: 1.9664200121356594

Epoch: 6| Step: 3
Training loss: 0.8516700267791748
Validation loss: 1.9992104268843127

Epoch: 6| Step: 4
Training loss: 0.5712298154830933
Validation loss: 1.975605167368407

Epoch: 6| Step: 5
Training loss: 1.1704643964767456
Validation loss: 1.9166038087619248

Epoch: 6| Step: 6
Training loss: 1.1258656978607178
Validation loss: 1.945811830541139

Epoch: 6| Step: 7
Training loss: 0.9915350079536438
Validation loss: 1.9359667583178448

Epoch: 6| Step: 8
Training loss: 1.0672626495361328
Validation loss: 1.954645481160892

Epoch: 6| Step: 9
Training loss: 1.5005686283111572
Validation loss: 2.0040411462065992

Epoch: 6| Step: 10
Training loss: 0.9265162944793701
Validation loss: 2.0550650935019217

Epoch: 6| Step: 11
Training loss: 1.2093982696533203
Validation loss: 2.0045885514187556

Epoch: 6| Step: 12
Training loss: 1.3740572929382324
Validation loss: 2.02947618756243

Epoch: 6| Step: 13
Training loss: 1.4574356079101562
Validation loss: 2.0075596878605504

Epoch: 691| Step: 0
Training loss: 1.7970590591430664
Validation loss: 2.0213958627434185

Epoch: 6| Step: 1
Training loss: 0.8771606683731079
Validation loss: 2.03254884289157

Epoch: 6| Step: 2
Training loss: 1.190584421157837
Validation loss: 1.9696124061461417

Epoch: 6| Step: 3
Training loss: 0.6351526379585266
Validation loss: 2.028333781867899

Epoch: 6| Step: 4
Training loss: 1.5204278230667114
Validation loss: 2.0295407643882175

Epoch: 6| Step: 5
Training loss: 1.3140486478805542
Validation loss: 2.0344324752848637

Epoch: 6| Step: 6
Training loss: 0.9027893543243408
Validation loss: 2.0045874541805637

Epoch: 6| Step: 7
Training loss: 0.7879692316055298
Validation loss: 1.95336014481001

Epoch: 6| Step: 8
Training loss: 0.7490020990371704
Validation loss: 2.015102278801703

Epoch: 6| Step: 9
Training loss: 1.2066099643707275
Validation loss: 1.9807168155588128

Epoch: 6| Step: 10
Training loss: 1.917168378829956
Validation loss: 1.9596924422889628

Epoch: 6| Step: 11
Training loss: 1.4950087070465088
Validation loss: 1.9673307505987023

Epoch: 6| Step: 12
Training loss: 1.4470109939575195
Validation loss: 2.008507056902814

Epoch: 6| Step: 13
Training loss: 1.1982038021087646
Validation loss: 1.9960601086257606

Epoch: 692| Step: 0
Training loss: 1.021512508392334
Validation loss: 1.974930860662973

Epoch: 6| Step: 1
Training loss: 1.692692518234253
Validation loss: 1.9923828853073942

Epoch: 6| Step: 2
Training loss: 1.3703398704528809
Validation loss: 1.9824429788897115

Epoch: 6| Step: 3
Training loss: 0.986575722694397
Validation loss: 1.9593963956320157

Epoch: 6| Step: 4
Training loss: 0.4612192213535309
Validation loss: 1.9765703896040558

Epoch: 6| Step: 5
Training loss: 1.22038996219635
Validation loss: 2.0102667039440525

Epoch: 6| Step: 6
Training loss: 1.1973248720169067
Validation loss: 2.0062420586104035

Epoch: 6| Step: 7
Training loss: 1.8339239358901978
Validation loss: 2.0164393622388124

Epoch: 6| Step: 8
Training loss: 1.6850826740264893
Validation loss: 2.027561222353289

Epoch: 6| Step: 9
Training loss: 0.6257573366165161
Validation loss: 2.0314968709022767

Epoch: 6| Step: 10
Training loss: 1.2561123371124268
Validation loss: 2.023255399478379

Epoch: 6| Step: 11
Training loss: 1.3766083717346191
Validation loss: 2.0245189474475

Epoch: 6| Step: 12
Training loss: 1.433464527130127
Validation loss: 1.9922852246992049

Epoch: 6| Step: 13
Training loss: 0.6065228581428528
Validation loss: 2.0388228765097995

Epoch: 693| Step: 0
Training loss: 1.1871604919433594
Validation loss: 1.976277547497903

Epoch: 6| Step: 1
Training loss: 0.7378300428390503
Validation loss: 2.025472270545139

Epoch: 6| Step: 2
Training loss: 1.433206558227539
Validation loss: 1.9797587651078419

Epoch: 6| Step: 3
Training loss: 1.9386142492294312
Validation loss: 2.001537920326315

Epoch: 6| Step: 4
Training loss: 1.1006094217300415
Validation loss: 1.9602281137179303

Epoch: 6| Step: 5
Training loss: 1.2831180095672607
Validation loss: 1.9891371752626152

Epoch: 6| Step: 6
Training loss: 0.5400698781013489
Validation loss: 2.015494091536409

Epoch: 6| Step: 7
Training loss: 1.371566653251648
Validation loss: 2.009572263686888

Epoch: 6| Step: 8
Training loss: 1.0856139659881592
Validation loss: 1.9855478425179758

Epoch: 6| Step: 9
Training loss: 1.2485579252243042
Validation loss: 2.0002182747728083

Epoch: 6| Step: 10
Training loss: 1.51912260055542
Validation loss: 1.955152242414413

Epoch: 6| Step: 11
Training loss: 0.629828929901123
Validation loss: 1.9480552070884294

Epoch: 6| Step: 12
Training loss: 1.3059378862380981
Validation loss: 1.972569828392357

Epoch: 6| Step: 13
Training loss: 0.9711711406707764
Validation loss: 1.9626047867600636

Epoch: 694| Step: 0
Training loss: 1.3273931741714478
Validation loss: 1.9528989548324256

Epoch: 6| Step: 1
Training loss: 1.1033520698547363
Validation loss: 1.9981098803140784

Epoch: 6| Step: 2
Training loss: 0.8093645572662354
Validation loss: 1.9850722717982467

Epoch: 6| Step: 3
Training loss: 1.5816409587860107
Validation loss: 1.958552481025778

Epoch: 6| Step: 4
Training loss: 1.24337899684906
Validation loss: 1.9575120223465787

Epoch: 6| Step: 5
Training loss: 1.2257620096206665
Validation loss: 1.9799312545407204

Epoch: 6| Step: 6
Training loss: 1.6681983470916748
Validation loss: 1.9739438769637898

Epoch: 6| Step: 7
Training loss: 1.2699732780456543
Validation loss: 1.9593891046380485

Epoch: 6| Step: 8
Training loss: 1.1434615850448608
Validation loss: 2.0045580889589045

Epoch: 6| Step: 9
Training loss: 1.6528828144073486
Validation loss: 2.001050704268999

Epoch: 6| Step: 10
Training loss: 1.12115478515625
Validation loss: 2.0227304632945726

Epoch: 6| Step: 11
Training loss: 0.8543757796287537
Validation loss: 2.0523362236638225

Epoch: 6| Step: 12
Training loss: 0.9771603345870972
Validation loss: 1.9940257687722482

Epoch: 6| Step: 13
Training loss: 0.8000444173812866
Validation loss: 2.0964117844899497

Epoch: 695| Step: 0
Training loss: 1.0647425651550293
Validation loss: 2.0157516707656202

Epoch: 6| Step: 1
Training loss: 1.401893138885498
Validation loss: 2.1024378679131948

Epoch: 6| Step: 2
Training loss: 1.314745545387268
Validation loss: 2.0251958626572804

Epoch: 6| Step: 3
Training loss: 1.4279961585998535
Validation loss: 2.0490503952067387

Epoch: 6| Step: 4
Training loss: 1.2385590076446533
Validation loss: 2.040970654897792

Epoch: 6| Step: 5
Training loss: 0.6656780242919922
Validation loss: 2.0643614440835933

Epoch: 6| Step: 6
Training loss: 1.199289083480835
Validation loss: 1.9589702672855829

Epoch: 6| Step: 7
Training loss: 1.1437957286834717
Validation loss: 1.9755478879456878

Epoch: 6| Step: 8
Training loss: 2.2227869033813477
Validation loss: 1.997337169544671

Epoch: 6| Step: 9
Training loss: 1.4741497039794922
Validation loss: 1.9543520840265418

Epoch: 6| Step: 10
Training loss: 1.2826735973358154
Validation loss: 1.9351468278515724

Epoch: 6| Step: 11
Training loss: 0.9936691522598267
Validation loss: 2.0161113521104217

Epoch: 6| Step: 12
Training loss: 1.0534186363220215
Validation loss: 1.9532539280512

Epoch: 6| Step: 13
Training loss: 1.096962571144104
Validation loss: 1.9785882529392038

Epoch: 696| Step: 0
Training loss: 0.9706027507781982
Validation loss: 1.9586803874661844

Epoch: 6| Step: 1
Training loss: 0.8896299600601196
Validation loss: 1.9787778649278867

Epoch: 6| Step: 2
Training loss: 1.3639267683029175
Validation loss: 1.9695334857509983

Epoch: 6| Step: 3
Training loss: 1.5903351306915283
Validation loss: 1.9715487110999323

Epoch: 6| Step: 4
Training loss: 1.7656359672546387
Validation loss: 1.979930131666122

Epoch: 6| Step: 5
Training loss: 0.7834486961364746
Validation loss: 1.9794992400753884

Epoch: 6| Step: 6
Training loss: 1.9641538858413696
Validation loss: 1.9951751129601591

Epoch: 6| Step: 7
Training loss: 0.8998183012008667
Validation loss: 1.9925157306014851

Epoch: 6| Step: 8
Training loss: 0.9162101745605469
Validation loss: 1.9994592794808008

Epoch: 6| Step: 9
Training loss: 1.1029187440872192
Validation loss: 1.9669976875346193

Epoch: 6| Step: 10
Training loss: 0.9542907476425171
Validation loss: 2.006021022796631

Epoch: 6| Step: 11
Training loss: 1.5223356485366821
Validation loss: 2.0236645744692896

Epoch: 6| Step: 12
Training loss: 1.0317803621292114
Validation loss: 1.9962023176172727

Epoch: 6| Step: 13
Training loss: 0.9621853232383728
Validation loss: 1.9892878558046074

Epoch: 697| Step: 0
Training loss: 1.0053596496582031
Validation loss: 2.0011809615678686

Epoch: 6| Step: 1
Training loss: 0.7606607675552368
Validation loss: 1.9864793951793382

Epoch: 6| Step: 2
Training loss: 1.54685640335083
Validation loss: 1.9805161145425612

Epoch: 6| Step: 3
Training loss: 1.3225951194763184
Validation loss: 2.0023224084608016

Epoch: 6| Step: 4
Training loss: 1.3133141994476318
Validation loss: 1.946699559047658

Epoch: 6| Step: 5
Training loss: 1.0664416551589966
Validation loss: 2.021423710289822

Epoch: 6| Step: 6
Training loss: 1.604447841644287
Validation loss: 1.94042145821356

Epoch: 6| Step: 7
Training loss: 0.9618357419967651
Validation loss: 1.956836740175883

Epoch: 6| Step: 8
Training loss: 1.5201072692871094
Validation loss: 1.9818593584081179

Epoch: 6| Step: 9
Training loss: 1.5477211475372314
Validation loss: 1.9943104174829298

Epoch: 6| Step: 10
Training loss: 0.8821933269500732
Validation loss: 1.9330122060673212

Epoch: 6| Step: 11
Training loss: 1.0250160694122314
Validation loss: 1.9574784668543006

Epoch: 6| Step: 12
Training loss: 1.16208815574646
Validation loss: 2.044772401932747

Epoch: 6| Step: 13
Training loss: 0.6849669814109802
Validation loss: 1.9925872792479813

Epoch: 698| Step: 0
Training loss: 0.801802933216095
Validation loss: 1.9913409858621576

Epoch: 6| Step: 1
Training loss: 0.6328303813934326
Validation loss: 2.0372765935877317

Epoch: 6| Step: 2
Training loss: 1.0714961290359497
Validation loss: 1.9950416934105657

Epoch: 6| Step: 3
Training loss: 1.4079492092132568
Validation loss: 2.01713341154078

Epoch: 6| Step: 4
Training loss: 1.6029155254364014
Validation loss: 2.037272937836186

Epoch: 6| Step: 5
Training loss: 1.437199592590332
Validation loss: 2.016328086135208

Epoch: 6| Step: 6
Training loss: 0.8209272623062134
Validation loss: 1.999492940082345

Epoch: 6| Step: 7
Training loss: 1.4830422401428223
Validation loss: 1.967571960982456

Epoch: 6| Step: 8
Training loss: 1.4074561595916748
Validation loss: 1.955773143358128

Epoch: 6| Step: 9
Training loss: 1.2127702236175537
Validation loss: 1.980629651777206

Epoch: 6| Step: 10
Training loss: 1.4191656112670898
Validation loss: 1.9590964714686077

Epoch: 6| Step: 11
Training loss: 0.8459222316741943
Validation loss: 1.9709260130441317

Epoch: 6| Step: 12
Training loss: 1.0499873161315918
Validation loss: 1.9198797056751866

Epoch: 6| Step: 13
Training loss: 1.4619951248168945
Validation loss: 1.9451161905001568

Epoch: 699| Step: 0
Training loss: 0.9223334193229675
Validation loss: 1.9507996946252801

Epoch: 6| Step: 1
Training loss: 1.3534345626831055
Validation loss: 1.9570354415524391

Epoch: 6| Step: 2
Training loss: 0.8547835946083069
Validation loss: 1.9720762160516554

Epoch: 6| Step: 3
Training loss: 1.4689381122589111
Validation loss: 2.028758689921389

Epoch: 6| Step: 4
Training loss: 1.2430410385131836
Validation loss: 1.9876742132248417

Epoch: 6| Step: 5
Training loss: 1.4569671154022217
Validation loss: 2.035404723177674

Epoch: 6| Step: 6
Training loss: 1.454535961151123
Validation loss: 1.9454995637298913

Epoch: 6| Step: 7
Training loss: 0.8474382162094116
Validation loss: 1.9851560823379024

Epoch: 6| Step: 8
Training loss: 1.311275601387024
Validation loss: 1.959412795241161

Epoch: 6| Step: 9
Training loss: 1.4354076385498047
Validation loss: 1.9959607611420334

Epoch: 6| Step: 10
Training loss: 0.7356871962547302
Validation loss: 1.9719240870527042

Epoch: 6| Step: 11
Training loss: 1.4836872816085815
Validation loss: 1.9664756264737857

Epoch: 6| Step: 12
Training loss: 0.9225031733512878
Validation loss: 1.980722378658992

Epoch: 6| Step: 13
Training loss: 1.3302167654037476
Validation loss: 1.9771813410584644

Epoch: 700| Step: 0
Training loss: 1.5840885639190674
Validation loss: 1.9416416178467453

Epoch: 6| Step: 1
Training loss: 1.1601366996765137
Validation loss: 1.9628055377673077

Epoch: 6| Step: 2
Training loss: 0.8251591324806213
Validation loss: 1.98897849488002

Epoch: 6| Step: 3
Training loss: 1.6882309913635254
Validation loss: 1.9527828667753486

Epoch: 6| Step: 4
Training loss: 1.3110988140106201
Validation loss: 1.997426507293537

Epoch: 6| Step: 5
Training loss: 1.320261836051941
Validation loss: 1.9524947212588402

Epoch: 6| Step: 6
Training loss: 1.3092310428619385
Validation loss: 1.9552411686989568

Epoch: 6| Step: 7
Training loss: 0.7986261248588562
Validation loss: 1.9591699479728617

Epoch: 6| Step: 8
Training loss: 0.9274513721466064
Validation loss: 1.9579935637853478

Epoch: 6| Step: 9
Training loss: 1.3234955072402954
Validation loss: 1.9906882996200232

Epoch: 6| Step: 10
Training loss: 0.8608625531196594
Validation loss: 2.0561467870589225

Epoch: 6| Step: 11
Training loss: 1.0149304866790771
Validation loss: 1.9971006583142024

Epoch: 6| Step: 12
Training loss: 1.6050076484680176
Validation loss: 1.992226626283379

Epoch: 6| Step: 13
Training loss: 0.9108155369758606
Validation loss: 2.0257351911196144

Testing loss: 2.0602906187375387
