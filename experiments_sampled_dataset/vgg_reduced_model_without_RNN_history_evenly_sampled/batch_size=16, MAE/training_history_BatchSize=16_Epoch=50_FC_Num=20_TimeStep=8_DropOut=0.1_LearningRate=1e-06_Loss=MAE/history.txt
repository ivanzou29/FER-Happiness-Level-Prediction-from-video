Epoch: 1| Step: 0
Training loss: 3.1426143646240234
Validation loss: 2.979788382848104

Epoch: 6| Step: 1
Training loss: 2.9550020694732666
Validation loss: 2.9704771067506526

Epoch: 6| Step: 2
Training loss: 3.4525821208953857
Validation loss: 2.968149318489977

Epoch: 6| Step: 3
Training loss: 3.797805070877075
Validation loss: 2.966277919789796

Epoch: 6| Step: 4
Training loss: 2.9172677993774414
Validation loss: 2.965002421409853

Epoch: 6| Step: 5
Training loss: 1.9447709321975708
Validation loss: 2.9646208235012588

Epoch: 6| Step: 6
Training loss: 3.050861358642578
Validation loss: 2.964121659596761

Epoch: 6| Step: 7
Training loss: 3.186574935913086
Validation loss: 2.959760037801599

Epoch: 6| Step: 8
Training loss: 2.406073570251465
Validation loss: 2.9582124012772755

Epoch: 6| Step: 9
Training loss: 2.256115436553955
Validation loss: 2.9546711316672702

Epoch: 6| Step: 10
Training loss: 3.754258871078491
Validation loss: 2.953766530559909

Epoch: 6| Step: 11
Training loss: 3.141148090362549
Validation loss: 2.9536021858133297

Epoch: 6| Step: 12
Training loss: 2.746767520904541
Validation loss: 2.947420950858824

Epoch: 6| Step: 13
Training loss: 4.458868980407715
Validation loss: 2.949248380558465

Epoch: 2| Step: 0
Training loss: 3.339906692504883
Validation loss: 2.950178236089727

Epoch: 6| Step: 1
Training loss: 2.945983409881592
Validation loss: 2.945538141394174

Epoch: 6| Step: 2
Training loss: 2.5803983211517334
Validation loss: 2.9422608908786567

Epoch: 6| Step: 3
Training loss: 3.0315725803375244
Validation loss: 2.939477805168398

Epoch: 6| Step: 4
Training loss: 3.3042218685150146
Validation loss: 2.941332824768559

Epoch: 6| Step: 5
Training loss: 2.6044163703918457
Validation loss: 2.93957120116039

Epoch: 6| Step: 6
Training loss: 3.495800018310547
Validation loss: 2.9346105334579304

Epoch: 6| Step: 7
Training loss: 2.1778151988983154
Validation loss: 2.9369093089975338

Epoch: 6| Step: 8
Training loss: 2.6284170150756836
Validation loss: 2.935736951007638

Epoch: 6| Step: 9
Training loss: 4.088445663452148
Validation loss: 2.932321310043335

Epoch: 6| Step: 10
Training loss: 3.475393295288086
Validation loss: 2.9260072964493946

Epoch: 6| Step: 11
Training loss: 2.63866925239563
Validation loss: 2.928163997588619

Epoch: 6| Step: 12
Training loss: 2.520050525665283
Validation loss: 2.9255892461346042

Epoch: 6| Step: 13
Training loss: 3.8402090072631836
Validation loss: 2.9230562153682915

Epoch: 3| Step: 0
Training loss: 2.3491127490997314
Validation loss: 2.923528891737743

Epoch: 6| Step: 1
Training loss: 3.1788244247436523
Validation loss: 2.916678310722433

Epoch: 6| Step: 2
Training loss: 2.9355063438415527
Validation loss: 2.9171580781218824

Epoch: 6| Step: 3
Training loss: 2.5609796047210693
Validation loss: 2.915085551559284

Epoch: 6| Step: 4
Training loss: 2.4927430152893066
Validation loss: 2.9150056172442693

Epoch: 6| Step: 5
Training loss: 3.197655439376831
Validation loss: 2.9155935036238803

Epoch: 6| Step: 6
Training loss: 3.087275505065918
Validation loss: 2.9143982036139375

Epoch: 6| Step: 7
Training loss: 3.4551162719726562
Validation loss: 2.9084923472455753

Epoch: 6| Step: 8
Training loss: 1.9809467792510986
Validation loss: 2.9079149820471324

Epoch: 6| Step: 9
Training loss: 3.534982442855835
Validation loss: 2.9071125010008454

Epoch: 6| Step: 10
Training loss: 3.2469801902770996
Validation loss: 2.906497424648654

Epoch: 6| Step: 11
Training loss: 3.745955228805542
Validation loss: 2.901404934544717

Epoch: 6| Step: 12
Training loss: 2.9042506217956543
Validation loss: 2.9028994267986667

Epoch: 6| Step: 13
Training loss: 3.657888650894165
Validation loss: 2.897442853578957

Epoch: 4| Step: 0
Training loss: 2.6626839637756348
Validation loss: 2.895698796036423

Epoch: 6| Step: 1
Training loss: 3.4096994400024414
Validation loss: 2.895318272293255

Epoch: 6| Step: 2
Training loss: 3.234687089920044
Validation loss: 2.890960580559187

Epoch: 6| Step: 3
Training loss: 2.760784149169922
Validation loss: 2.888838001476821

Epoch: 6| Step: 4
Training loss: 2.531803607940674
Validation loss: 2.888863604555848

Epoch: 6| Step: 5
Training loss: 3.1091620922088623
Validation loss: 2.8828255899490847

Epoch: 6| Step: 6
Training loss: 2.616673231124878
Validation loss: 2.8820838133494058

Epoch: 6| Step: 7
Training loss: 2.7249395847320557
Validation loss: 2.8781247420977523

Epoch: 6| Step: 8
Training loss: 3.038215398788452
Validation loss: 2.87823579131916

Epoch: 6| Step: 9
Training loss: 3.275418758392334
Validation loss: 2.8784193223522556

Epoch: 6| Step: 10
Training loss: 2.9758429527282715
Validation loss: 2.8737036976762997

Epoch: 6| Step: 11
Training loss: 3.523848056793213
Validation loss: 2.8696995524949926

Epoch: 6| Step: 12
Training loss: 3.234009265899658
Validation loss: 2.8651156681840138

Epoch: 6| Step: 13
Training loss: 2.4476232528686523
Validation loss: 2.8615967663385535

Epoch: 5| Step: 0
Training loss: 3.1041479110717773
Validation loss: 2.862089369886665

Epoch: 6| Step: 1
Training loss: 3.304546594619751
Validation loss: 2.8614634236981793

Epoch: 6| Step: 2
Training loss: 4.027144432067871
Validation loss: 2.8553766999193417

Epoch: 6| Step: 3
Training loss: 2.3964195251464844
Validation loss: 2.8547222075923795

Epoch: 6| Step: 4
Training loss: 3.005229949951172
Validation loss: 2.8505337187038955

Epoch: 6| Step: 5
Training loss: 2.150740623474121
Validation loss: 2.8494313814306773

Epoch: 6| Step: 6
Training loss: 2.334273338317871
Validation loss: 2.844036022822062

Epoch: 6| Step: 7
Training loss: 2.8911232948303223
Validation loss: 2.8419003537906113

Epoch: 6| Step: 8
Training loss: 3.0064194202423096
Validation loss: 2.8430006375876804

Epoch: 6| Step: 9
Training loss: 3.2520499229431152
Validation loss: 2.8328434908261864

Epoch: 6| Step: 10
Training loss: 2.4825644493103027
Validation loss: 2.829968039707471

Epoch: 6| Step: 11
Training loss: 3.1935231685638428
Validation loss: 2.82765087773723

Epoch: 6| Step: 12
Training loss: 3.1772899627685547
Validation loss: 2.825802456948065

Epoch: 6| Step: 13
Training loss: 3.1409826278686523
Validation loss: 2.8226646889922438

Epoch: 6| Step: 0
Training loss: 3.6373372077941895
Validation loss: 2.8172688074009393

Epoch: 6| Step: 1
Training loss: 2.850653886795044
Validation loss: 2.813460034708823

Epoch: 6| Step: 2
Training loss: 3.073613405227661
Validation loss: 2.8117485918024534

Epoch: 6| Step: 3
Training loss: 2.6650519371032715
Validation loss: 2.808210926671182

Epoch: 6| Step: 4
Training loss: 2.4566171169281006
Validation loss: 2.8092979564461658

Epoch: 6| Step: 5
Training loss: 2.834444046020508
Validation loss: 2.7993620467442337

Epoch: 6| Step: 6
Training loss: 3.1545844078063965
Validation loss: 2.7982574098853656

Epoch: 6| Step: 7
Training loss: 2.562782049179077
Validation loss: 2.7916736013145855

Epoch: 6| Step: 8
Training loss: 4.021539688110352
Validation loss: 2.791791862057101

Epoch: 6| Step: 9
Training loss: 2.236208438873291
Validation loss: 2.7867722716382755

Epoch: 6| Step: 10
Training loss: 2.8664937019348145
Validation loss: 2.788144706397928

Epoch: 6| Step: 11
Training loss: 3.281782627105713
Validation loss: 2.7815672223285963

Epoch: 6| Step: 12
Training loss: 2.6471879482269287
Validation loss: 2.7752589897442888

Epoch: 6| Step: 13
Training loss: 2.490166425704956
Validation loss: 2.773864964003204

Epoch: 7| Step: 0
Training loss: 1.9289648532867432
Validation loss: 2.7690775138075634

Epoch: 6| Step: 1
Training loss: 2.511054039001465
Validation loss: 2.7678010566260225

Epoch: 6| Step: 2
Training loss: 2.666473865509033
Validation loss: 2.7606857566423315

Epoch: 6| Step: 3
Training loss: 2.7742462158203125
Validation loss: 2.7580646827656734

Epoch: 6| Step: 4
Training loss: 3.472738265991211
Validation loss: 2.753178006859236

Epoch: 6| Step: 5
Training loss: 3.203838348388672
Validation loss: 2.7499796549479165

Epoch: 6| Step: 6
Training loss: 2.8261685371398926
Validation loss: 2.7475520641573015

Epoch: 6| Step: 7
Training loss: 3.1980552673339844
Validation loss: 2.7429873481873543

Epoch: 6| Step: 8
Training loss: 3.3427815437316895
Validation loss: 2.7394445737202964

Epoch: 6| Step: 9
Training loss: 2.253035545349121
Validation loss: 2.7397750923710484

Epoch: 6| Step: 10
Training loss: 3.8293442726135254
Validation loss: 2.7318776910023024

Epoch: 6| Step: 11
Training loss: 3.2955689430236816
Validation loss: 2.7292619264254006

Epoch: 6| Step: 12
Training loss: 2.405411720275879
Validation loss: 2.7228485435567875

Epoch: 6| Step: 13
Training loss: 2.6305131912231445
Validation loss: 2.720763985828687

Epoch: 8| Step: 0
Training loss: 2.7337646484375
Validation loss: 2.7153560166717856

Epoch: 6| Step: 1
Training loss: 2.4444499015808105
Validation loss: 2.710810384442729

Epoch: 6| Step: 2
Training loss: 3.1336703300476074
Validation loss: 2.712685315839706

Epoch: 6| Step: 3
Training loss: 3.0550436973571777
Validation loss: 2.70563163808597

Epoch: 6| Step: 4
Training loss: 3.168766975402832
Validation loss: 2.7037770645592802

Epoch: 6| Step: 5
Training loss: 3.086566686630249
Validation loss: 2.698927035895727

Epoch: 6| Step: 6
Training loss: 2.937129497528076
Validation loss: 2.6918488035919848

Epoch: 6| Step: 7
Training loss: 2.700324296951294
Validation loss: 2.6923764008347706

Epoch: 6| Step: 8
Training loss: 2.104623794555664
Validation loss: 2.688323620826967

Epoch: 6| Step: 9
Training loss: 3.033313751220703
Validation loss: 2.684563987998552

Epoch: 6| Step: 10
Training loss: 3.0324957370758057
Validation loss: 2.6792022848642

Epoch: 6| Step: 11
Training loss: 2.701953887939453
Validation loss: 2.6792562084813274

Epoch: 6| Step: 12
Training loss: 3.0496697425842285
Validation loss: 2.671374515820575

Epoch: 6| Step: 13
Training loss: 2.6734063625335693
Validation loss: 2.669832170650523

Epoch: 9| Step: 0
Training loss: 2.7345054149627686
Validation loss: 2.6680761255243772

Epoch: 6| Step: 1
Training loss: 2.8642311096191406
Validation loss: 2.657584967151765

Epoch: 6| Step: 2
Training loss: 1.7963225841522217
Validation loss: 2.653668357479957

Epoch: 6| Step: 3
Training loss: 2.838897705078125
Validation loss: 2.6600369253466205

Epoch: 6| Step: 4
Training loss: 3.7510790824890137
Validation loss: 2.6474254259499173

Epoch: 6| Step: 5
Training loss: 2.580874443054199
Validation loss: 2.644635644010318

Epoch: 6| Step: 6
Training loss: 3.275120735168457
Validation loss: 2.636075017272785

Epoch: 6| Step: 7
Training loss: 2.447723388671875
Validation loss: 2.6329123204754246

Epoch: 6| Step: 8
Training loss: 3.276315689086914
Validation loss: 2.630545472586027

Epoch: 6| Step: 9
Training loss: 2.7647483348846436
Validation loss: 2.6242663860321045

Epoch: 6| Step: 10
Training loss: 2.2172207832336426
Validation loss: 2.6216339436910485

Epoch: 6| Step: 11
Training loss: 2.160818576812744
Validation loss: 2.6166789095888854

Epoch: 6| Step: 12
Training loss: 3.391934871673584
Validation loss: 2.6100799909202

Epoch: 6| Step: 13
Training loss: 3.596696138381958
Validation loss: 2.613323277042758

Epoch: 10| Step: 0
Training loss: 2.213491201400757
Validation loss: 2.602043472310548

Epoch: 6| Step: 1
Training loss: 3.652272939682007
Validation loss: 2.6006652565412622

Epoch: 6| Step: 2
Training loss: 2.7393383979797363
Validation loss: 2.594751819487541

Epoch: 6| Step: 3
Training loss: 2.4330568313598633
Validation loss: 2.5888622319826515

Epoch: 6| Step: 4
Training loss: 3.255563974380493
Validation loss: 2.5818370439672984

Epoch: 6| Step: 5
Training loss: 2.8194777965545654
Validation loss: 2.579568621932819

Epoch: 6| Step: 6
Training loss: 2.876772880554199
Validation loss: 2.5747611009946434

Epoch: 6| Step: 7
Training loss: 3.4076998233795166
Validation loss: 2.574166723476943

Epoch: 6| Step: 8
Training loss: 2.266533613204956
Validation loss: 2.5649226532187512

Epoch: 6| Step: 9
Training loss: 2.8448615074157715
Validation loss: 2.5646144856688795

Epoch: 6| Step: 10
Training loss: 1.8254716396331787
Validation loss: 2.5621348427188013

Epoch: 6| Step: 11
Training loss: 2.719602346420288
Validation loss: 2.554959438180411

Epoch: 6| Step: 12
Training loss: 2.9789700508117676
Validation loss: 2.550121348391297

Epoch: 6| Step: 13
Training loss: 2.709181785583496
Validation loss: 2.542164364168721

Epoch: 11| Step: 0
Training loss: 3.2178053855895996
Validation loss: 2.5354415319299184

Epoch: 6| Step: 1
Training loss: 2.306356430053711
Validation loss: 2.5377103974742274

Epoch: 6| Step: 2
Training loss: 2.6558334827423096
Validation loss: 2.5296032428741455

Epoch: 6| Step: 3
Training loss: 2.9049932956695557
Validation loss: 2.523894927834952

Epoch: 6| Step: 4
Training loss: 2.2787070274353027
Validation loss: 2.51526931793459

Epoch: 6| Step: 5
Training loss: 2.3463470935821533
Validation loss: 2.5104869027291574

Epoch: 6| Step: 6
Training loss: 2.3934688568115234
Validation loss: 2.505283304440078

Epoch: 6| Step: 7
Training loss: 2.743373394012451
Validation loss: 2.500383689839353

Epoch: 6| Step: 8
Training loss: 3.026118278503418
Validation loss: 2.490763653991043

Epoch: 6| Step: 9
Training loss: 2.1800851821899414
Validation loss: 2.4891061013744724

Epoch: 6| Step: 10
Training loss: 3.3472516536712646
Validation loss: 2.493989472748131

Epoch: 6| Step: 11
Training loss: 3.3819897174835205
Validation loss: 2.4868150936659945

Epoch: 6| Step: 12
Training loss: 3.121736526489258
Validation loss: 2.482317909117668

Epoch: 6| Step: 13
Training loss: 2.121182680130005
Validation loss: 2.4746183861968336

Epoch: 12| Step: 0
Training loss: 1.9431374073028564
Validation loss: 2.4685351002600884

Epoch: 6| Step: 1
Training loss: 2.749692916870117
Validation loss: 2.4647407070282967

Epoch: 6| Step: 2
Training loss: 2.2768163681030273
Validation loss: 2.459658004904306

Epoch: 6| Step: 3
Training loss: 3.3844871520996094
Validation loss: 2.461987567204301

Epoch: 6| Step: 4
Training loss: 2.5797533988952637
Validation loss: 2.449998906863633

Epoch: 6| Step: 5
Training loss: 2.78014874458313
Validation loss: 2.4502408273758425

Epoch: 6| Step: 6
Training loss: 2.719666004180908
Validation loss: 2.4508466874399493

Epoch: 6| Step: 7
Training loss: 3.622124671936035
Validation loss: 2.4430123426580943

Epoch: 6| Step: 8
Training loss: 2.606506586074829
Validation loss: 2.4338966774684128

Epoch: 6| Step: 9
Training loss: 2.372036933898926
Validation loss: 2.4248787920962096

Epoch: 6| Step: 10
Training loss: 2.5679540634155273
Validation loss: 2.4219173269887126

Epoch: 6| Step: 11
Training loss: 2.371504306793213
Validation loss: 2.4154622606051865

Epoch: 6| Step: 12
Training loss: 3.0445749759674072
Validation loss: 2.410032892739901

Epoch: 6| Step: 13
Training loss: 2.6153509616851807
Validation loss: 2.408298989777924

Epoch: 13| Step: 0
Training loss: 2.646686553955078
Validation loss: 2.393220378506568

Epoch: 6| Step: 1
Training loss: 2.5032196044921875
Validation loss: 2.3963234193863405

Epoch: 6| Step: 2
Training loss: 3.046579599380493
Validation loss: 2.383850089965328

Epoch: 6| Step: 3
Training loss: 2.444296360015869
Validation loss: 2.3697350076449815

Epoch: 6| Step: 4
Training loss: 2.6067464351654053
Validation loss: 2.375163091126309

Epoch: 6| Step: 5
Training loss: 2.9692625999450684
Validation loss: 2.368601224755728

Epoch: 6| Step: 6
Training loss: 2.93316650390625
Validation loss: 2.358224243246099

Epoch: 6| Step: 7
Training loss: 2.428731918334961
Validation loss: 2.345534054181909

Epoch: 6| Step: 8
Training loss: 2.9373364448547363
Validation loss: 2.3425514954392628

Epoch: 6| Step: 9
Training loss: 2.5123236179351807
Validation loss: 2.3355449245822046

Epoch: 6| Step: 10
Training loss: 2.64437198638916
Validation loss: 2.33899938419301

Epoch: 6| Step: 11
Training loss: 3.0004196166992188
Validation loss: 2.330333414898124

Epoch: 6| Step: 12
Training loss: 2.175856113433838
Validation loss: 2.329491074367236

Epoch: 6| Step: 13
Training loss: 1.9334155321121216
Validation loss: 2.3244276918390745

Epoch: 14| Step: 0
Training loss: 2.822817802429199
Validation loss: 2.3152962628231255

Epoch: 6| Step: 1
Training loss: 2.970150947570801
Validation loss: 2.3046678881491385

Epoch: 6| Step: 2
Training loss: 2.4001667499542236
Validation loss: 2.3048295538912535

Epoch: 6| Step: 3
Training loss: 2.297750949859619
Validation loss: 2.2943823235009306

Epoch: 6| Step: 4
Training loss: 1.7870960235595703
Validation loss: 2.2897799373954855

Epoch: 6| Step: 5
Training loss: 3.0305747985839844
Validation loss: 2.292482004370741

Epoch: 6| Step: 6
Training loss: 3.2182412147521973
Validation loss: 2.2774947586879937

Epoch: 6| Step: 7
Training loss: 2.4400432109832764
Validation loss: 2.265533111428702

Epoch: 6| Step: 8
Training loss: 2.5569562911987305
Validation loss: 2.255514734534807

Epoch: 6| Step: 9
Training loss: 2.531500816345215
Validation loss: 2.25760083301093

Epoch: 6| Step: 10
Training loss: 2.898818016052246
Validation loss: 2.2602475868758334

Epoch: 6| Step: 11
Training loss: 1.9580838680267334
Validation loss: 2.249784323476976

Epoch: 6| Step: 12
Training loss: 2.348222255706787
Validation loss: 2.2524349125482703

Epoch: 6| Step: 13
Training loss: 3.3868515491485596
Validation loss: 2.2374467003730034

Epoch: 15| Step: 0
Training loss: 2.511209487915039
Validation loss: 2.2223825223984255

Epoch: 6| Step: 1
Training loss: 2.4774041175842285
Validation loss: 2.2278630348943893

Epoch: 6| Step: 2
Training loss: 2.3492465019226074
Validation loss: 2.2241856077665925

Epoch: 6| Step: 3
Training loss: 2.658569812774658
Validation loss: 2.228872150503179

Epoch: 6| Step: 4
Training loss: 2.670426845550537
Validation loss: 2.2181815152527182

Epoch: 6| Step: 5
Training loss: 2.845017433166504
Validation loss: 2.206089637612784

Epoch: 6| Step: 6
Training loss: 2.76298189163208
Validation loss: 2.2192840524899062

Epoch: 6| Step: 7
Training loss: 2.6014599800109863
Validation loss: 2.197389487297304

Epoch: 6| Step: 8
Training loss: 2.698369264602661
Validation loss: 2.1995265535129014

Epoch: 6| Step: 9
Training loss: 2.9480814933776855
Validation loss: 2.194468726393997

Epoch: 6| Step: 10
Training loss: 2.8582937717437744
Validation loss: 2.1890696812701482

Epoch: 6| Step: 11
Training loss: 2.0105600357055664
Validation loss: 2.1824895899782897

Epoch: 6| Step: 12
Training loss: 2.2999167442321777
Validation loss: 2.185199068438622

Epoch: 6| Step: 13
Training loss: 1.7692731618881226
Validation loss: 2.178421971618488

Epoch: 16| Step: 0
Training loss: 2.217257022857666
Validation loss: 2.162047299005652

Epoch: 6| Step: 1
Training loss: 2.483659029006958
Validation loss: 2.1698548511792253

Epoch: 6| Step: 2
Training loss: 2.6921825408935547
Validation loss: 2.1681128189127934

Epoch: 6| Step: 3
Training loss: 2.4271483421325684
Validation loss: 2.158459242954049

Epoch: 6| Step: 4
Training loss: 2.7367515563964844
Validation loss: 2.1609977547840407

Epoch: 6| Step: 5
Training loss: 2.9639644622802734
Validation loss: 2.15200138092041

Epoch: 6| Step: 6
Training loss: 2.1386961936950684
Validation loss: 2.143763942103232

Epoch: 6| Step: 7
Training loss: 2.3446741104125977
Validation loss: 2.1488335312053723

Epoch: 6| Step: 8
Training loss: 3.2258028984069824
Validation loss: 2.151722361964564

Epoch: 6| Step: 9
Training loss: 2.2639689445495605
Validation loss: 2.148056178964594

Epoch: 6| Step: 10
Training loss: 2.079009532928467
Validation loss: 2.1296372387998845

Epoch: 6| Step: 11
Training loss: 2.2452051639556885
Validation loss: 2.1331281661987305

Epoch: 6| Step: 12
Training loss: 2.750239849090576
Validation loss: 2.124175863881265

Epoch: 6| Step: 13
Training loss: 2.7082769870758057
Validation loss: 2.1170686470564974

Epoch: 17| Step: 0
Training loss: 1.8887768983840942
Validation loss: 2.1193569808877926

Epoch: 6| Step: 1
Training loss: 2.244513988494873
Validation loss: 2.1087500792677685

Epoch: 6| Step: 2
Training loss: 2.4007272720336914
Validation loss: 2.1113445566546534

Epoch: 6| Step: 3
Training loss: 2.4808430671691895
Validation loss: 2.1026925861194568

Epoch: 6| Step: 4
Training loss: 3.0068917274475098
Validation loss: 2.112396991381081

Epoch: 6| Step: 5
Training loss: 2.219935655593872
Validation loss: 2.113716276743079

Epoch: 6| Step: 6
Training loss: 2.4397358894348145
Validation loss: 2.1133171230234127

Epoch: 6| Step: 7
Training loss: 2.26597261428833
Validation loss: 2.0870942402911443

Epoch: 6| Step: 8
Training loss: 2.5743401050567627
Validation loss: 2.094006274336128

Epoch: 6| Step: 9
Training loss: 2.775158405303955
Validation loss: 2.0877738793691

Epoch: 6| Step: 10
Training loss: 3.1978321075439453
Validation loss: 2.1021581824107836

Epoch: 6| Step: 11
Training loss: 2.472043752670288
Validation loss: 2.0994143114295056

Epoch: 6| Step: 12
Training loss: 2.5937249660491943
Validation loss: 2.0827771245792346

Epoch: 6| Step: 13
Training loss: 1.8516343832015991
Validation loss: 2.0928428890884563

Epoch: 18| Step: 0
Training loss: 1.8999483585357666
Validation loss: 2.0865394479484967

Epoch: 6| Step: 1
Training loss: 1.785601258277893
Validation loss: 2.071340009730349

Epoch: 6| Step: 2
Training loss: 2.2006306648254395
Validation loss: 2.07786585182272

Epoch: 6| Step: 3
Training loss: 2.734067916870117
Validation loss: 2.0592992792847338

Epoch: 6| Step: 4
Training loss: 2.9095308780670166
Validation loss: 2.0737680671035603

Epoch: 6| Step: 5
Training loss: 2.0759189128875732
Validation loss: 2.067480489771853

Epoch: 6| Step: 6
Training loss: 1.6316580772399902
Validation loss: 2.060054135578935

Epoch: 6| Step: 7
Training loss: 2.7269539833068848
Validation loss: 2.060333287844094

Epoch: 6| Step: 8
Training loss: 3.2961363792419434
Validation loss: 2.070330686466668

Epoch: 6| Step: 9
Training loss: 2.6185426712036133
Validation loss: 2.056810350828273

Epoch: 6| Step: 10
Training loss: 2.9144492149353027
Validation loss: 2.0589355422604467

Epoch: 6| Step: 11
Training loss: 2.5188605785369873
Validation loss: 2.0385325172896027

Epoch: 6| Step: 12
Training loss: 2.5117011070251465
Validation loss: 2.052047651301148

Epoch: 6| Step: 13
Training loss: 2.7074661254882812
Validation loss: 2.0395664732943297

Epoch: 19| Step: 0
Training loss: 2.107849597930908
Validation loss: 2.041084806124369

Epoch: 6| Step: 1
Training loss: 2.2912168502807617
Validation loss: 2.028647904754967

Epoch: 6| Step: 2
Training loss: 3.071343183517456
Validation loss: 2.036617071397843

Epoch: 6| Step: 3
Training loss: 2.1479949951171875
Validation loss: 2.0205817812232563

Epoch: 6| Step: 4
Training loss: 3.0537071228027344
Validation loss: 2.026202045461183

Epoch: 6| Step: 5
Training loss: 2.404512882232666
Validation loss: 2.0236926437706075

Epoch: 6| Step: 6
Training loss: 1.8277078866958618
Validation loss: 2.0176487917541177

Epoch: 6| Step: 7
Training loss: 2.7410151958465576
Validation loss: 2.018954800021264

Epoch: 6| Step: 8
Training loss: 1.736038327217102
Validation loss: 2.00644277885396

Epoch: 6| Step: 9
Training loss: 2.763326406478882
Validation loss: 2.0144590485480522

Epoch: 6| Step: 10
Training loss: 2.2441415786743164
Validation loss: 2.018338657194568

Epoch: 6| Step: 11
Training loss: 2.5413951873779297
Validation loss: 2.012325156119562

Epoch: 6| Step: 12
Training loss: 2.4933948516845703
Validation loss: 2.0001877277128157

Epoch: 6| Step: 13
Training loss: 3.1879539489746094
Validation loss: 2.010500290060556

Epoch: 20| Step: 0
Training loss: 2.5901238918304443
Validation loss: 2.0047018040892897

Epoch: 6| Step: 1
Training loss: 2.5313916206359863
Validation loss: 1.9982278077833113

Epoch: 6| Step: 2
Training loss: 2.1610734462738037
Validation loss: 2.0103040433699086

Epoch: 6| Step: 3
Training loss: 2.566060781478882
Validation loss: 1.9992927223123529

Epoch: 6| Step: 4
Training loss: 2.090564727783203
Validation loss: 2.0060886836821035

Epoch: 6| Step: 5
Training loss: 1.6818749904632568
Validation loss: 2.0136662939543366

Epoch: 6| Step: 6
Training loss: 2.4971933364868164
Validation loss: 2.0013525819265716

Epoch: 6| Step: 7
Training loss: 2.896077871322632
Validation loss: 2.0149254414343063

Epoch: 6| Step: 8
Training loss: 2.4237141609191895
Validation loss: 2.010689732848957

Epoch: 6| Step: 9
Training loss: 2.007601022720337
Validation loss: 2.0068128185887493

Epoch: 6| Step: 10
Training loss: 2.898092746734619
Validation loss: 1.996558359874192

Epoch: 6| Step: 11
Training loss: 2.504068613052368
Validation loss: 2.0055538556909047

Epoch: 6| Step: 12
Training loss: 2.6596503257751465
Validation loss: 1.9995214554571337

Epoch: 6| Step: 13
Training loss: 2.7265870571136475
Validation loss: 1.988266985903504

Epoch: 21| Step: 0
Training loss: 2.391663074493408
Validation loss: 1.9908325172239734

Epoch: 6| Step: 1
Training loss: 1.4232761859893799
Validation loss: 1.9929424152579358

Epoch: 6| Step: 2
Training loss: 2.0089783668518066
Validation loss: 1.9875680169751566

Epoch: 6| Step: 3
Training loss: 2.6188366413116455
Validation loss: 1.9918817807269353

Epoch: 6| Step: 4
Training loss: 3.0246663093566895
Validation loss: 1.9929720842710106

Epoch: 6| Step: 5
Training loss: 2.594196319580078
Validation loss: 1.9899358608389413

Epoch: 6| Step: 6
Training loss: 2.646899700164795
Validation loss: 1.9906550568919028

Epoch: 6| Step: 7
Training loss: 3.184906482696533
Validation loss: 2.000309383997353

Epoch: 6| Step: 8
Training loss: 2.1729846000671387
Validation loss: 1.9986280292593024

Epoch: 6| Step: 9
Training loss: 2.6318790912628174
Validation loss: 1.997242396877658

Epoch: 6| Step: 10
Training loss: 2.002633810043335
Validation loss: 1.9847783760357929

Epoch: 6| Step: 11
Training loss: 2.4923033714294434
Validation loss: 1.998183201718074

Epoch: 6| Step: 12
Training loss: 2.4259514808654785
Validation loss: 1.9889493911497054

Epoch: 6| Step: 13
Training loss: 2.2693209648132324
Validation loss: 2.012732549380231

Epoch: 22| Step: 0
Training loss: 2.7685816287994385
Validation loss: 1.9997287399025374

Epoch: 6| Step: 1
Training loss: 2.445201873779297
Validation loss: 2.0039327259986632

Epoch: 6| Step: 2
Training loss: 2.0460081100463867
Validation loss: 1.9970743835613292

Epoch: 6| Step: 3
Training loss: 2.3787245750427246
Validation loss: 1.996601640537221

Epoch: 6| Step: 4
Training loss: 3.0176682472229004
Validation loss: 2.00279652431447

Epoch: 6| Step: 5
Training loss: 2.352534294128418
Validation loss: 1.9894040605073333

Epoch: 6| Step: 6
Training loss: 2.537790536880493
Validation loss: 2.0141966060925554

Epoch: 6| Step: 7
Training loss: 2.08487606048584
Validation loss: 2.007489853007819

Epoch: 6| Step: 8
Training loss: 1.7374999523162842
Validation loss: 2.0089667599688292

Epoch: 6| Step: 9
Training loss: 2.4869658946990967
Validation loss: 2.0098291584240493

Epoch: 6| Step: 10
Training loss: 3.1641993522644043
Validation loss: 2.0163571373108895

Epoch: 6| Step: 11
Training loss: 2.4242477416992188
Validation loss: 2.018060573967554

Epoch: 6| Step: 12
Training loss: 2.1691248416900635
Validation loss: 2.027385378396639

Epoch: 6| Step: 13
Training loss: 2.26725697517395
Validation loss: 2.0085356184231338

Epoch: 23| Step: 0
Training loss: 2.2565994262695312
Validation loss: 2.022408985322522

Epoch: 6| Step: 1
Training loss: 2.108123302459717
Validation loss: 2.0167818223276446

Epoch: 6| Step: 2
Training loss: 2.370478868484497
Validation loss: 2.0114598146048923

Epoch: 6| Step: 3
Training loss: 2.753580093383789
Validation loss: 2.017528736463157

Epoch: 6| Step: 4
Training loss: 2.5763511657714844
Validation loss: 2.017066942748203

Epoch: 6| Step: 5
Training loss: 2.3494694232940674
Validation loss: 2.0065829728239324

Epoch: 6| Step: 6
Training loss: 2.5441806316375732
Validation loss: 2.011262357875865

Epoch: 6| Step: 7
Training loss: 2.3793132305145264
Validation loss: 2.012052312974007

Epoch: 6| Step: 8
Training loss: 2.5291988849639893
Validation loss: 2.0040218727563017

Epoch: 6| Step: 9
Training loss: 2.1667938232421875
Validation loss: 2.002680701594199

Epoch: 6| Step: 10
Training loss: 1.596855640411377
Validation loss: 2.0228138815972114

Epoch: 6| Step: 11
Training loss: 2.529934883117676
Validation loss: 2.0140447449940506

Epoch: 6| Step: 12
Training loss: 3.056694984436035
Validation loss: 2.013618096228569

Epoch: 6| Step: 13
Training loss: 2.6041784286499023
Validation loss: 2.013456834259854

Epoch: 24| Step: 0
Training loss: 2.322266101837158
Validation loss: 2.0189101132013465

Epoch: 6| Step: 1
Training loss: 2.1889138221740723
Validation loss: 2.001785170647406

Epoch: 6| Step: 2
Training loss: 2.565868616104126
Validation loss: 1.9972456591103667

Epoch: 6| Step: 3
Training loss: 2.331052303314209
Validation loss: 1.9969932468988563

Epoch: 6| Step: 4
Training loss: 2.249547004699707
Validation loss: 2.011659781138102

Epoch: 6| Step: 5
Training loss: 2.9920949935913086
Validation loss: 1.990460172776253

Epoch: 6| Step: 6
Training loss: 2.5319929122924805
Validation loss: 1.9783546232408094

Epoch: 6| Step: 7
Training loss: 2.8079123497009277
Validation loss: 1.9882293132043654

Epoch: 6| Step: 8
Training loss: 2.708554983139038
Validation loss: 1.9724731996495237

Epoch: 6| Step: 9
Training loss: 1.9154865741729736
Validation loss: 1.9919207737010012

Epoch: 6| Step: 10
Training loss: 2.0018739700317383
Validation loss: 1.9882177870760682

Epoch: 6| Step: 11
Training loss: 2.864302635192871
Validation loss: 1.9908460314555834

Epoch: 6| Step: 12
Training loss: 2.279951333999634
Validation loss: 1.9717472650671517

Epoch: 6| Step: 13
Training loss: 1.823681354522705
Validation loss: 1.995317087378553

Epoch: 25| Step: 0
Training loss: 1.8817943334579468
Validation loss: 2.0015709682177474

Epoch: 6| Step: 1
Training loss: 3.2375845909118652
Validation loss: 1.9827123034384944

Epoch: 6| Step: 2
Training loss: 1.232496738433838
Validation loss: 1.9913447364684074

Epoch: 6| Step: 3
Training loss: 2.2374086380004883
Validation loss: 1.9892170557411768

Epoch: 6| Step: 4
Training loss: 2.4488277435302734
Validation loss: 1.9856020942811043

Epoch: 6| Step: 5
Training loss: 2.594482898712158
Validation loss: 1.9902724527543592

Epoch: 6| Step: 6
Training loss: 2.9045350551605225
Validation loss: 1.9932357854740594

Epoch: 6| Step: 7
Training loss: 2.4830009937286377
Validation loss: 1.9966797085218533

Epoch: 6| Step: 8
Training loss: 2.120333433151245
Validation loss: 1.9974505029698855

Epoch: 6| Step: 9
Training loss: 2.6679763793945312
Validation loss: 1.9973707699006604

Epoch: 6| Step: 10
Training loss: 2.8757636547088623
Validation loss: 2.0075022238557056

Epoch: 6| Step: 11
Training loss: 2.4853272438049316
Validation loss: 1.9998141770721765

Epoch: 6| Step: 12
Training loss: 2.2582898139953613
Validation loss: 2.0010278494127336

Epoch: 6| Step: 13
Training loss: 2.190445899963379
Validation loss: 1.9985867097813597

Epoch: 26| Step: 0
Training loss: 2.050105571746826
Validation loss: 2.0042743605952107

Epoch: 6| Step: 1
Training loss: 2.6745729446411133
Validation loss: 2.0009583465514647

Epoch: 6| Step: 2
Training loss: 1.7493902444839478
Validation loss: 2.006432787064583

Epoch: 6| Step: 3
Training loss: 2.7516322135925293
Validation loss: 1.9968899975540817

Epoch: 6| Step: 4
Training loss: 2.2841897010803223
Validation loss: 1.9992606819316905

Epoch: 6| Step: 5
Training loss: 2.4574832916259766
Validation loss: 2.004084840897591

Epoch: 6| Step: 6
Training loss: 2.192996025085449
Validation loss: 1.995559779546594

Epoch: 6| Step: 7
Training loss: 3.232416868209839
Validation loss: 1.9980050876576414

Epoch: 6| Step: 8
Training loss: 2.8632264137268066
Validation loss: 1.989490952543033

Epoch: 6| Step: 9
Training loss: 2.070376396179199
Validation loss: 1.985701484064902

Epoch: 6| Step: 10
Training loss: 2.071622848510742
Validation loss: 2.0039400823654665

Epoch: 6| Step: 11
Training loss: 2.426156759262085
Validation loss: 1.9938574862736527

Epoch: 6| Step: 12
Training loss: 1.9894983768463135
Validation loss: 2.0046404407870386

Epoch: 6| Step: 13
Training loss: 3.1716651916503906
Validation loss: 1.9916926519845122

Epoch: 27| Step: 0
Training loss: 1.9870595932006836
Validation loss: 1.9786001610499557

Epoch: 6| Step: 1
Training loss: 2.2721641063690186
Validation loss: 1.9888528880252634

Epoch: 6| Step: 2
Training loss: 2.24764084815979
Validation loss: 1.9902750689496276

Epoch: 6| Step: 3
Training loss: 2.1027214527130127
Validation loss: 1.9983180287063762

Epoch: 6| Step: 4
Training loss: 1.8646941184997559
Validation loss: 2.003437465237033

Epoch: 6| Step: 5
Training loss: 2.7129716873168945
Validation loss: 1.9776692544260333

Epoch: 6| Step: 6
Training loss: 2.2496914863586426
Validation loss: 1.9879379477552188

Epoch: 6| Step: 7
Training loss: 2.570466995239258
Validation loss: 2.0054999192555747

Epoch: 6| Step: 8
Training loss: 2.590986728668213
Validation loss: 1.9996680559650544

Epoch: 6| Step: 9
Training loss: 3.1667189598083496
Validation loss: 2.000021598672354

Epoch: 6| Step: 10
Training loss: 2.2100324630737305
Validation loss: 2.002540192296428

Epoch: 6| Step: 11
Training loss: 1.9643690586090088
Validation loss: 2.006692886352539

Epoch: 6| Step: 12
Training loss: 3.050088882446289
Validation loss: 1.9932903551286267

Epoch: 6| Step: 13
Training loss: 2.9286794662475586
Validation loss: 1.9987334410349529

Epoch: 28| Step: 0
Training loss: 2.579035520553589
Validation loss: 2.002616825924125

Epoch: 6| Step: 1
Training loss: 2.464083194732666
Validation loss: 1.9925584895636446

Epoch: 6| Step: 2
Training loss: 2.2846479415893555
Validation loss: 1.997214674949646

Epoch: 6| Step: 3
Training loss: 2.1473212242126465
Validation loss: 1.9973057059831516

Epoch: 6| Step: 4
Training loss: 2.231203079223633
Validation loss: 2.000594603118076

Epoch: 6| Step: 5
Training loss: 2.1566927433013916
Validation loss: 2.002246423434186

Epoch: 6| Step: 6
Training loss: 1.9608712196350098
Validation loss: 1.9961861154084564

Epoch: 6| Step: 7
Training loss: 2.7141799926757812
Validation loss: 2.0066795810576408

Epoch: 6| Step: 8
Training loss: 2.1900200843811035
Validation loss: 1.9849438218660251

Epoch: 6| Step: 9
Training loss: 2.7231216430664062
Validation loss: 2.0017241752275856

Epoch: 6| Step: 10
Training loss: 2.4821503162384033
Validation loss: 2.0033249137222127

Epoch: 6| Step: 11
Training loss: 2.733308792114258
Validation loss: 1.9866643541602678

Epoch: 6| Step: 12
Training loss: 2.2026829719543457
Validation loss: 1.9855269706377419

Epoch: 6| Step: 13
Training loss: 2.9209680557250977
Validation loss: 1.97575758605875

Epoch: 29| Step: 0
Training loss: 1.8579728603363037
Validation loss: 1.9786625869812504

Epoch: 6| Step: 1
Training loss: 2.2462878227233887
Validation loss: 1.9935559611166678

Epoch: 6| Step: 2
Training loss: 2.2611083984375
Validation loss: 1.9861447093307332

Epoch: 6| Step: 3
Training loss: 2.853793144226074
Validation loss: 1.9966299251843524

Epoch: 6| Step: 4
Training loss: 2.6116929054260254
Validation loss: 1.9773781940501223

Epoch: 6| Step: 5
Training loss: 2.301560401916504
Validation loss: 1.986011738418251

Epoch: 6| Step: 6
Training loss: 2.615216016769409
Validation loss: 1.9859020222899735

Epoch: 6| Step: 7
Training loss: 2.785457134246826
Validation loss: 1.9809498658744238

Epoch: 6| Step: 8
Training loss: 2.6106348037719727
Validation loss: 1.9910543323844991

Epoch: 6| Step: 9
Training loss: 2.605307102203369
Validation loss: 1.9832476415941793

Epoch: 6| Step: 10
Training loss: 2.1626017093658447
Validation loss: 1.9720318163594892

Epoch: 6| Step: 11
Training loss: 2.4024834632873535
Validation loss: 1.9864519949882262

Epoch: 6| Step: 12
Training loss: 1.7440297603607178
Validation loss: 1.980873102782875

Epoch: 6| Step: 13
Training loss: 2.294480800628662
Validation loss: 1.9884886344273884

Epoch: 30| Step: 0
Training loss: 2.2625534534454346
Validation loss: 1.9872260375689434

Epoch: 6| Step: 1
Training loss: 2.1755595207214355
Validation loss: 1.9729857278126541

Epoch: 6| Step: 2
Training loss: 2.181561231613159
Validation loss: 1.9819305865995345

Epoch: 6| Step: 3
Training loss: 2.529118776321411
Validation loss: 1.9872490949528192

Epoch: 6| Step: 4
Training loss: 2.212858200073242
Validation loss: 1.975723098683101

Epoch: 6| Step: 5
Training loss: 2.3927512168884277
Validation loss: 1.9785022697141093

Epoch: 6| Step: 6
Training loss: 2.3363239765167236
Validation loss: 1.9887937332994194

Epoch: 6| Step: 7
Training loss: 2.300708770751953
Validation loss: 1.968603285410071

Epoch: 6| Step: 8
Training loss: 2.845749855041504
Validation loss: 1.9879483997180898

Epoch: 6| Step: 9
Training loss: 2.918027877807617
Validation loss: 1.994161832717157

Epoch: 6| Step: 10
Training loss: 2.3045010566711426
Validation loss: 1.9804298826443252

Epoch: 6| Step: 11
Training loss: 2.080867290496826
Validation loss: 1.9781591533332743

Epoch: 6| Step: 12
Training loss: 2.191619396209717
Validation loss: 1.991696826873287

Epoch: 6| Step: 13
Training loss: 3.056377649307251
Validation loss: 1.9872102199062225

Epoch: 31| Step: 0
Training loss: 2.5371859073638916
Validation loss: 1.9859191192093717

Epoch: 6| Step: 1
Training loss: 2.2668814659118652
Validation loss: 1.9797396993124357

Epoch: 6| Step: 2
Training loss: 2.25746488571167
Validation loss: 1.9902229437264063

Epoch: 6| Step: 3
Training loss: 1.6298158168792725
Validation loss: 1.9820138972292665

Epoch: 6| Step: 4
Training loss: 2.355609893798828
Validation loss: 2.0028750358089322

Epoch: 6| Step: 5
Training loss: 2.5191664695739746
Validation loss: 2.004926238008725

Epoch: 6| Step: 6
Training loss: 2.6448659896850586
Validation loss: 2.0025176155951714

Epoch: 6| Step: 7
Training loss: 2.684703826904297
Validation loss: 1.9912613181657688

Epoch: 6| Step: 8
Training loss: 2.98455810546875
Validation loss: 2.008331048873163

Epoch: 6| Step: 9
Training loss: 1.957633137702942
Validation loss: 2.0020671954718967

Epoch: 6| Step: 10
Training loss: 2.8151638507843018
Validation loss: 2.0053804702656244

Epoch: 6| Step: 11
Training loss: 2.201707601547241
Validation loss: 1.99757356028403

Epoch: 6| Step: 12
Training loss: 2.1285548210144043
Validation loss: 2.0091425513708465

Epoch: 6| Step: 13
Training loss: 2.6734983921051025
Validation loss: 2.0178081245832544

Epoch: 32| Step: 0
Training loss: 2.1252355575561523
Validation loss: 2.0120964357929845

Epoch: 6| Step: 1
Training loss: 2.4822216033935547
Validation loss: 2.002625419247535

Epoch: 6| Step: 2
Training loss: 2.6466681957244873
Validation loss: 1.986634559528802

Epoch: 6| Step: 3
Training loss: 3.1371395587921143
Validation loss: 1.9878700266602218

Epoch: 6| Step: 4
Training loss: 1.6269636154174805
Validation loss: 1.995556551923034

Epoch: 6| Step: 5
Training loss: 2.7030553817749023
Validation loss: 1.998348907757831

Epoch: 6| Step: 6
Training loss: 2.7290966510772705
Validation loss: 1.979391554350494

Epoch: 6| Step: 7
Training loss: 1.5739704370498657
Validation loss: 1.9945479490423714

Epoch: 6| Step: 8
Training loss: 2.3415045738220215
Validation loss: 1.9983272283307967

Epoch: 6| Step: 9
Training loss: 2.6441149711608887
Validation loss: 2.0027644711156047

Epoch: 6| Step: 10
Training loss: 2.18991756439209
Validation loss: 1.9973614523487706

Epoch: 6| Step: 11
Training loss: 2.52091646194458
Validation loss: 1.99273899421897

Epoch: 6| Step: 12
Training loss: 2.25101900100708
Validation loss: 1.9926547042785152

Epoch: 6| Step: 13
Training loss: 2.4214770793914795
Validation loss: 1.9812096523982223

Epoch: 33| Step: 0
Training loss: 2.953658103942871
Validation loss: 1.9759887226166264

Epoch: 6| Step: 1
Training loss: 1.8820115327835083
Validation loss: 1.9978770748261483

Epoch: 6| Step: 2
Training loss: 2.3131155967712402
Validation loss: 1.985053539276123

Epoch: 6| Step: 3
Training loss: 1.8436391353607178
Validation loss: 1.9732613717356036

Epoch: 6| Step: 4
Training loss: 2.3522913455963135
Validation loss: 1.97692064316042

Epoch: 6| Step: 5
Training loss: 2.4862427711486816
Validation loss: 1.9689148126109954

Epoch: 6| Step: 6
Training loss: 1.9158371686935425
Validation loss: 1.9792595166032032

Epoch: 6| Step: 7
Training loss: 2.583125591278076
Validation loss: 1.9713327525764384

Epoch: 6| Step: 8
Training loss: 2.6083593368530273
Validation loss: 1.964128408380734

Epoch: 6| Step: 9
Training loss: 2.7719950675964355
Validation loss: 1.9784739722487747

Epoch: 6| Step: 10
Training loss: 2.5612030029296875
Validation loss: 1.9791041061442385

Epoch: 6| Step: 11
Training loss: 2.0695438385009766
Validation loss: 1.9611625658568514

Epoch: 6| Step: 12
Training loss: 2.3312134742736816
Validation loss: 1.959761429858464

Epoch: 6| Step: 13
Training loss: 2.8425133228302
Validation loss: 1.985240811942726

Epoch: 34| Step: 0
Training loss: 1.8589552640914917
Validation loss: 1.9744716075158888

Epoch: 6| Step: 1
Training loss: 2.9256889820098877
Validation loss: 1.974143128241262

Epoch: 6| Step: 2
Training loss: 2.7246906757354736
Validation loss: 1.9776752994906517

Epoch: 6| Step: 3
Training loss: 2.3929009437561035
Validation loss: 1.992819457925776

Epoch: 6| Step: 4
Training loss: 2.461057662963867
Validation loss: 1.9831530817093388

Epoch: 6| Step: 5
Training loss: 2.872734785079956
Validation loss: 1.975036307047772

Epoch: 6| Step: 6
Training loss: 2.324420690536499
Validation loss: 1.9744097391764324

Epoch: 6| Step: 7
Training loss: 2.434089183807373
Validation loss: 1.9624079811957575

Epoch: 6| Step: 8
Training loss: 1.958435297012329
Validation loss: 1.9795118480600336

Epoch: 6| Step: 9
Training loss: 2.576772451400757
Validation loss: 1.9800986974470076

Epoch: 6| Step: 10
Training loss: 2.185458183288574
Validation loss: 1.987344200893115

Epoch: 6| Step: 11
Training loss: 2.5361690521240234
Validation loss: 1.9829158859868203

Epoch: 6| Step: 12
Training loss: 1.8696492910385132
Validation loss: 1.9644278787797498

Epoch: 6| Step: 13
Training loss: 1.9056752920150757
Validation loss: 1.9740515434613792

Epoch: 35| Step: 0
Training loss: 2.5274600982666016
Validation loss: 1.9879033860339914

Epoch: 6| Step: 1
Training loss: 1.7403476238250732
Validation loss: 1.9895235915337839

Epoch: 6| Step: 2
Training loss: 3.0185728073120117
Validation loss: 1.990862774592574

Epoch: 6| Step: 3
Training loss: 2.1708664894104004
Validation loss: 1.9960772157997213

Epoch: 6| Step: 4
Training loss: 2.3248209953308105
Validation loss: 1.9989458591707292

Epoch: 6| Step: 5
Training loss: 2.1383888721466064
Validation loss: 1.9914402308002594

Epoch: 6| Step: 6
Training loss: 2.4321231842041016
Validation loss: 1.9795199427553403

Epoch: 6| Step: 7
Training loss: 3.037696123123169
Validation loss: 1.9856656674415833

Epoch: 6| Step: 8
Training loss: 2.28686261177063
Validation loss: 1.9917012568443053

Epoch: 6| Step: 9
Training loss: 1.9195383787155151
Validation loss: 1.9831170176946988

Epoch: 6| Step: 10
Training loss: 3.069000482559204
Validation loss: 2.002814039107292

Epoch: 6| Step: 11
Training loss: 2.1676549911499023
Validation loss: 1.9862018785169047

Epoch: 6| Step: 12
Training loss: 1.9729681015014648
Validation loss: 1.9959350939719909

Epoch: 6| Step: 13
Training loss: 2.122481107711792
Validation loss: 2.0054247212666336

Epoch: 36| Step: 0
Training loss: 2.7783617973327637
Validation loss: 1.9880800772738714

Epoch: 6| Step: 1
Training loss: 2.8009448051452637
Validation loss: 1.994427845042239

Epoch: 6| Step: 2
Training loss: 2.107800245285034
Validation loss: 1.9984851524394045

Epoch: 6| Step: 3
Training loss: 1.7230175733566284
Validation loss: 2.0010564173421552

Epoch: 6| Step: 4
Training loss: 2.9409031867980957
Validation loss: 1.9742665829197052

Epoch: 6| Step: 5
Training loss: 2.3695645332336426
Validation loss: 1.982105016708374

Epoch: 6| Step: 6
Training loss: 2.3641576766967773
Validation loss: 1.9958049597278718

Epoch: 6| Step: 7
Training loss: 2.6002230644226074
Validation loss: 2.0019381930751186

Epoch: 6| Step: 8
Training loss: 2.214843273162842
Validation loss: 1.9931738197162587

Epoch: 6| Step: 9
Training loss: 2.729663848876953
Validation loss: 2.0050351542811238

Epoch: 6| Step: 10
Training loss: 1.9400235414505005
Validation loss: 1.9871520983275546

Epoch: 6| Step: 11
Training loss: 1.9659829139709473
Validation loss: 1.9958372141725274

Epoch: 6| Step: 12
Training loss: 2.113999843597412
Validation loss: 1.983977456246653

Epoch: 6| Step: 13
Training loss: 2.662921667098999
Validation loss: 1.9995611713778587

Epoch: 37| Step: 0
Training loss: 2.458874225616455
Validation loss: 1.9840262615552513

Epoch: 6| Step: 1
Training loss: 2.2489423751831055
Validation loss: 1.9905741112206572

Epoch: 6| Step: 2
Training loss: 2.5924229621887207
Validation loss: 1.995056229252969

Epoch: 6| Step: 3
Training loss: 2.2229185104370117
Validation loss: 1.994350120585452

Epoch: 6| Step: 4
Training loss: 2.920241594314575
Validation loss: 2.0110692747177614

Epoch: 6| Step: 5
Training loss: 2.7889633178710938
Validation loss: 2.0066992595631588

Epoch: 6| Step: 6
Training loss: 2.348154067993164
Validation loss: 1.9737300539529452

Epoch: 6| Step: 7
Training loss: 2.0424838066101074
Validation loss: 1.9906037545973254

Epoch: 6| Step: 8
Training loss: 2.475332260131836
Validation loss: 1.9925335696948472

Epoch: 6| Step: 9
Training loss: 2.0816969871520996
Validation loss: 1.989336008666664

Epoch: 6| Step: 10
Training loss: 2.1724693775177
Validation loss: 2.002606336788465

Epoch: 6| Step: 11
Training loss: 2.222665309906006
Validation loss: 1.990392695191086

Epoch: 6| Step: 12
Training loss: 2.072125196456909
Validation loss: 1.9976564453494163

Epoch: 6| Step: 13
Training loss: 2.649655342102051
Validation loss: 1.987449433213921

Epoch: 38| Step: 0
Training loss: 2.0419440269470215
Validation loss: 2.000156456424344

Epoch: 6| Step: 1
Training loss: 2.704416275024414
Validation loss: 1.9821847587503412

Epoch: 6| Step: 2
Training loss: 2.3534727096557617
Validation loss: 1.9870862345541678

Epoch: 6| Step: 3
Training loss: 2.247037887573242
Validation loss: 1.9741852091204735

Epoch: 6| Step: 4
Training loss: 2.3602347373962402
Validation loss: 1.9969492894346996

Epoch: 6| Step: 5
Training loss: 3.253020763397217
Validation loss: 1.9831979825932493

Epoch: 6| Step: 6
Training loss: 2.3086845874786377
Validation loss: 1.995958221855984

Epoch: 6| Step: 7
Training loss: 2.193176031112671
Validation loss: 1.9862040037749915

Epoch: 6| Step: 8
Training loss: 2.744159698486328
Validation loss: 1.9807249333268853

Epoch: 6| Step: 9
Training loss: 2.725388526916504
Validation loss: 1.9795435551674134

Epoch: 6| Step: 10
Training loss: 2.083385944366455
Validation loss: 1.9787037705862394

Epoch: 6| Step: 11
Training loss: 1.6879844665527344
Validation loss: 1.97646467403699

Epoch: 6| Step: 12
Training loss: 2.218087911605835
Validation loss: 1.9932082250554075

Epoch: 6| Step: 13
Training loss: 1.7449438571929932
Validation loss: 1.976065194734963

Epoch: 39| Step: 0
Training loss: 2.4865059852600098
Validation loss: 1.9801395157332062

Epoch: 6| Step: 1
Training loss: 2.0448379516601562
Validation loss: 1.9725523969178558

Epoch: 6| Step: 2
Training loss: 2.123307704925537
Validation loss: 1.9781310366046043

Epoch: 6| Step: 3
Training loss: 2.288135051727295
Validation loss: 1.9842978959442468

Epoch: 6| Step: 4
Training loss: 2.2135257720947266
Validation loss: 1.993001793020515

Epoch: 6| Step: 5
Training loss: 1.8931622505187988
Validation loss: 1.9825222312763173

Epoch: 6| Step: 6
Training loss: 2.5147151947021484
Validation loss: 1.97049283084049

Epoch: 6| Step: 7
Training loss: 1.7657668590545654
Validation loss: 1.9966705563247844

Epoch: 6| Step: 8
Training loss: 2.6382508277893066
Validation loss: 1.994145865081459

Epoch: 6| Step: 9
Training loss: 2.6309759616851807
Validation loss: 1.9866930669353855

Epoch: 6| Step: 10
Training loss: 3.378450870513916
Validation loss: 2.0001133577798003

Epoch: 6| Step: 11
Training loss: 2.323305606842041
Validation loss: 1.991170000004512

Epoch: 6| Step: 12
Training loss: 2.1013197898864746
Validation loss: 1.9797250750244304

Epoch: 6| Step: 13
Training loss: 2.64542555809021
Validation loss: 1.9819685015627133

Epoch: 40| Step: 0
Training loss: 2.138068199157715
Validation loss: 1.9941682315641833

Epoch: 6| Step: 1
Training loss: 2.0790610313415527
Validation loss: 1.9907981439303326

Epoch: 6| Step: 2
Training loss: 2.6519265174865723
Validation loss: 1.9843178641411565

Epoch: 6| Step: 3
Training loss: 2.067495346069336
Validation loss: 1.9930464836858934

Epoch: 6| Step: 4
Training loss: 2.402778148651123
Validation loss: 1.9809617009214175

Epoch: 6| Step: 5
Training loss: 2.28287410736084
Validation loss: 1.979746034068446

Epoch: 6| Step: 6
Training loss: 2.957953929901123
Validation loss: 1.9781596788796045

Epoch: 6| Step: 7
Training loss: 1.7240115404129028
Validation loss: 1.9798563423977102

Epoch: 6| Step: 8
Training loss: 2.968104124069214
Validation loss: 1.9750738579739806

Epoch: 6| Step: 9
Training loss: 1.6477679014205933
Validation loss: 1.9762237738537531

Epoch: 6| Step: 10
Training loss: 2.4835610389709473
Validation loss: 1.9711280330534904

Epoch: 6| Step: 11
Training loss: 2.6810221672058105
Validation loss: 1.9933849521862563

Epoch: 6| Step: 12
Training loss: 2.2470664978027344
Validation loss: 1.9880847648907733

Epoch: 6| Step: 13
Training loss: 2.698758840560913
Validation loss: 1.986005001170661

Epoch: 41| Step: 0
Training loss: 2.4252967834472656
Validation loss: 1.9880197125096475

Epoch: 6| Step: 1
Training loss: 2.5493102073669434
Validation loss: 1.9920725450720838

Epoch: 6| Step: 2
Training loss: 2.52707576751709
Validation loss: 2.0118290634565454

Epoch: 6| Step: 3
Training loss: 2.1384494304656982
Validation loss: 1.9842159735259188

Epoch: 6| Step: 4
Training loss: 2.6426033973693848
Validation loss: 1.9872196105218702

Epoch: 6| Step: 5
Training loss: 1.9612469673156738
Validation loss: 1.9781255055499334

Epoch: 6| Step: 6
Training loss: 2.5154690742492676
Validation loss: 1.9875531478594708

Epoch: 6| Step: 7
Training loss: 2.175477981567383
Validation loss: 1.991895060385427

Epoch: 6| Step: 8
Training loss: 2.3623735904693604
Validation loss: 1.9987484896054832

Epoch: 6| Step: 9
Training loss: 1.9315980672836304
Validation loss: 1.9930461837399391

Epoch: 6| Step: 10
Training loss: 2.4968762397766113
Validation loss: 1.9910645202923847

Epoch: 6| Step: 11
Training loss: 2.180323600769043
Validation loss: 1.9871239277624315

Epoch: 6| Step: 12
Training loss: 2.1925594806671143
Validation loss: 1.9857431175888225

Epoch: 6| Step: 13
Training loss: 3.119089365005493
Validation loss: 1.9828968637733049

Epoch: 42| Step: 0
Training loss: 2.2719881534576416
Validation loss: 1.9802438982071415

Epoch: 6| Step: 1
Training loss: 1.6692218780517578
Validation loss: 1.996502645554081

Epoch: 6| Step: 2
Training loss: 2.3331992626190186
Validation loss: 1.9804292827524164

Epoch: 6| Step: 3
Training loss: 2.493380069732666
Validation loss: 1.995973325544788

Epoch: 6| Step: 4
Training loss: 2.0891377925872803
Validation loss: 1.9865184086625294

Epoch: 6| Step: 5
Training loss: 2.8451297283172607
Validation loss: 1.9751207136338758

Epoch: 6| Step: 6
Training loss: 2.2112903594970703
Validation loss: 1.9743465761984549

Epoch: 6| Step: 7
Training loss: 2.4452290534973145
Validation loss: 1.9731534155466224

Epoch: 6| Step: 8
Training loss: 2.229132652282715
Validation loss: 1.9910841936706214

Epoch: 6| Step: 9
Training loss: 2.3098957538604736
Validation loss: 1.995859185854594

Epoch: 6| Step: 10
Training loss: 2.4322195053100586
Validation loss: 1.9840627677979008

Epoch: 6| Step: 11
Training loss: 2.5978283882141113
Validation loss: 1.9928416987901092

Epoch: 6| Step: 12
Training loss: 2.3067574501037598
Validation loss: 1.9795133990626181

Epoch: 6| Step: 13
Training loss: 2.772629976272583
Validation loss: 1.9645361464510682

Epoch: 43| Step: 0
Training loss: 2.1964364051818848
Validation loss: 1.972160323973625

Epoch: 6| Step: 1
Training loss: 2.3138089179992676
Validation loss: 1.9925887238594793

Epoch: 6| Step: 2
Training loss: 3.2497286796569824
Validation loss: 1.9844881770431355

Epoch: 6| Step: 3
Training loss: 2.0877790451049805
Validation loss: 1.9710050526485647

Epoch: 6| Step: 4
Training loss: 1.9565668106079102
Validation loss: 1.9800489205186085

Epoch: 6| Step: 5
Training loss: 2.2330775260925293
Validation loss: 1.98775553318762

Epoch: 6| Step: 6
Training loss: 1.7758166790008545
Validation loss: 1.968334686371588

Epoch: 6| Step: 7
Training loss: 2.938368797302246
Validation loss: 1.9714774252266012

Epoch: 6| Step: 8
Training loss: 2.2291343212127686
Validation loss: 1.9878586466594408

Epoch: 6| Step: 9
Training loss: 2.4685328006744385
Validation loss: 1.9823778842085151

Epoch: 6| Step: 10
Training loss: 2.8927011489868164
Validation loss: 1.9820998137997043

Epoch: 6| Step: 11
Training loss: 2.333950996398926
Validation loss: 1.9822030785263225

Epoch: 6| Step: 12
Training loss: 2.2270264625549316
Validation loss: 1.963173391998455

Epoch: 6| Step: 13
Training loss: 1.4112716913223267
Validation loss: 1.9875423036595827

Epoch: 44| Step: 0
Training loss: 2.262895107269287
Validation loss: 1.9802868314968642

Epoch: 6| Step: 1
Training loss: 2.0539956092834473
Validation loss: 1.986790354533862

Epoch: 6| Step: 2
Training loss: 2.0893001556396484
Validation loss: 1.9626129788737143

Epoch: 6| Step: 3
Training loss: 2.379040241241455
Validation loss: 1.9801351267804381

Epoch: 6| Step: 4
Training loss: 2.3318800926208496
Validation loss: 1.9797262094354118

Epoch: 6| Step: 5
Training loss: 2.9790189266204834
Validation loss: 1.9900308988427604

Epoch: 6| Step: 6
Training loss: 2.5645101070404053
Validation loss: 1.9768408562547417

Epoch: 6| Step: 7
Training loss: 1.8028523921966553
Validation loss: 1.985601161115913

Epoch: 6| Step: 8
Training loss: 2.4642882347106934
Validation loss: 1.986592520949661

Epoch: 6| Step: 9
Training loss: 2.0990898609161377
Validation loss: 1.980396011824249

Epoch: 6| Step: 10
Training loss: 2.386216640472412
Validation loss: 1.9945477234419955

Epoch: 6| Step: 11
Training loss: 2.6281590461730957
Validation loss: 1.9898860608377764

Epoch: 6| Step: 12
Training loss: 2.622309684753418
Validation loss: 1.9868842581266999

Epoch: 6| Step: 13
Training loss: 1.6774696111679077
Validation loss: 1.9866115739268642

Epoch: 45| Step: 0
Training loss: 1.8686308860778809
Validation loss: 1.9846819728933356

Epoch: 6| Step: 1
Training loss: 2.2349560260772705
Validation loss: 1.9914647020319456

Epoch: 6| Step: 2
Training loss: 2.368180513381958
Validation loss: 1.994150229679641

Epoch: 6| Step: 3
Training loss: 2.5796756744384766
Validation loss: 1.978892780119373

Epoch: 6| Step: 4
Training loss: 2.4195547103881836
Validation loss: 1.9967623423504572

Epoch: 6| Step: 5
Training loss: 1.8193004131317139
Validation loss: 1.9912056333275252

Epoch: 6| Step: 6
Training loss: 2.364534378051758
Validation loss: 1.9889121260694278

Epoch: 6| Step: 7
Training loss: 2.9665732383728027
Validation loss: 1.9843666220224032

Epoch: 6| Step: 8
Training loss: 1.9466230869293213
Validation loss: 1.99241772261999

Epoch: 6| Step: 9
Training loss: 2.5618486404418945
Validation loss: 1.9794414017790107

Epoch: 6| Step: 10
Training loss: 1.5519731044769287
Validation loss: 1.9669889224472867

Epoch: 6| Step: 11
Training loss: 2.2002387046813965
Validation loss: 1.9824457027578866

Epoch: 6| Step: 12
Training loss: 3.1199111938476562
Validation loss: 1.9903509565578994

Epoch: 6| Step: 13
Training loss: 2.8608720302581787
Validation loss: 1.9937159938196982

Epoch: 46| Step: 0
Training loss: 2.4282376766204834
Validation loss: 1.9914439570519231

Epoch: 6| Step: 1
Training loss: 2.445394277572632
Validation loss: 1.9875117450632074

Epoch: 6| Step: 2
Training loss: 2.7781424522399902
Validation loss: 1.978245658259238

Epoch: 6| Step: 3
Training loss: 1.6987642049789429
Validation loss: 1.9830550493732575

Epoch: 6| Step: 4
Training loss: 2.4946141242980957
Validation loss: 1.981848096334806

Epoch: 6| Step: 5
Training loss: 1.9153008460998535
Validation loss: 1.9851743969866025

Epoch: 6| Step: 6
Training loss: 2.0742177963256836
Validation loss: 1.982060622143489

Epoch: 6| Step: 7
Training loss: 2.107491970062256
Validation loss: 1.971412645873203

Epoch: 6| Step: 8
Training loss: 1.8422014713287354
Validation loss: 1.9701975571211947

Epoch: 6| Step: 9
Training loss: 2.1651904582977295
Validation loss: 1.9742462827313332

Epoch: 6| Step: 10
Training loss: 3.105833053588867
Validation loss: 1.9910181530060307

Epoch: 6| Step: 11
Training loss: 2.5735106468200684
Validation loss: 1.979013257129218

Epoch: 6| Step: 12
Training loss: 2.3007607460021973
Validation loss: 1.970073926833368

Epoch: 6| Step: 13
Training loss: 2.8972909450531006
Validation loss: 1.968565023073586

Epoch: 47| Step: 0
Training loss: 1.9251238107681274
Validation loss: 1.9860366980234783

Epoch: 6| Step: 1
Training loss: 1.820662021636963
Validation loss: 1.9672847742675452

Epoch: 6| Step: 2
Training loss: 1.874535083770752
Validation loss: 1.9699641786595827

Epoch: 6| Step: 3
Training loss: 3.4752328395843506
Validation loss: 1.976051486948485

Epoch: 6| Step: 4
Training loss: 2.0288918018341064
Validation loss: 1.9736667345928889

Epoch: 6| Step: 5
Training loss: 2.778921604156494
Validation loss: 1.9764330489661104

Epoch: 6| Step: 6
Training loss: 2.1240506172180176
Validation loss: 1.9654460043035529

Epoch: 6| Step: 7
Training loss: 2.5150704383850098
Validation loss: 1.972062736429194

Epoch: 6| Step: 8
Training loss: 2.4696860313415527
Validation loss: 1.978842963454544

Epoch: 6| Step: 9
Training loss: 2.6137609481811523
Validation loss: 1.9685823943025322

Epoch: 6| Step: 10
Training loss: 2.3241782188415527
Validation loss: 1.9721584422613985

Epoch: 6| Step: 11
Training loss: 1.8696004152297974
Validation loss: 1.9665124211260068

Epoch: 6| Step: 12
Training loss: 2.317833423614502
Validation loss: 1.9853416796653502

Epoch: 6| Step: 13
Training loss: 2.5664455890655518
Validation loss: 1.979136251634167

Epoch: 48| Step: 0
Training loss: 1.9094079732894897
Validation loss: 1.9830895277761644

Epoch: 6| Step: 1
Training loss: 2.3653924465179443
Validation loss: 1.9651233496204499

Epoch: 6| Step: 2
Training loss: 2.3494813442230225
Validation loss: 1.971886691226754

Epoch: 6| Step: 3
Training loss: 2.236511707305908
Validation loss: 1.9673072573959187

Epoch: 6| Step: 4
Training loss: 2.5004630088806152
Validation loss: 1.9685256455534248

Epoch: 6| Step: 5
Training loss: 2.8619189262390137
Validation loss: 1.9666744791051394

Epoch: 6| Step: 6
Training loss: 2.286929130554199
Validation loss: 1.9693201588046165

Epoch: 6| Step: 7
Training loss: 2.3801538944244385
Validation loss: 1.9723297998469362

Epoch: 6| Step: 8
Training loss: 2.646393060684204
Validation loss: 1.9649920386652793

Epoch: 6| Step: 9
Training loss: 1.9989423751831055
Validation loss: 1.9879205893444758

Epoch: 6| Step: 10
Training loss: 2.339704990386963
Validation loss: 1.9679555123852146

Epoch: 6| Step: 11
Training loss: 2.161210536956787
Validation loss: 1.9627265346947538

Epoch: 6| Step: 12
Training loss: 2.283684253692627
Validation loss: 1.966342669661327

Epoch: 6| Step: 13
Training loss: 1.9797558784484863
Validation loss: 1.953144778487503

Epoch: 49| Step: 0
Training loss: 2.2519443035125732
Validation loss: 1.959935716403428

Epoch: 6| Step: 1
Training loss: 2.1209757328033447
Validation loss: 1.9724584548704085

Epoch: 6| Step: 2
Training loss: 1.5890896320343018
Validation loss: 1.965068091628372

Epoch: 6| Step: 3
Training loss: 2.1915621757507324
Validation loss: 1.9722665176596692

Epoch: 6| Step: 4
Training loss: 2.6028671264648438
Validation loss: 1.9766263961791992

Epoch: 6| Step: 5
Training loss: 2.636704683303833
Validation loss: 1.9812799474244476

Epoch: 6| Step: 6
Training loss: 2.1345407962799072
Validation loss: 1.993198335811656

Epoch: 6| Step: 7
Training loss: 2.2066361904144287
Validation loss: 1.973800657897867

Epoch: 6| Step: 8
Training loss: 2.4874629974365234
Validation loss: 1.9732557881262995

Epoch: 6| Step: 9
Training loss: 2.4047014713287354
Validation loss: 1.9824006736919444

Epoch: 6| Step: 10
Training loss: 2.267294406890869
Validation loss: 1.971539822957849

Epoch: 6| Step: 11
Training loss: 2.7445926666259766
Validation loss: 1.9665657192148187

Epoch: 6| Step: 12
Training loss: 2.2087349891662598
Validation loss: 1.9561873815392936

Epoch: 6| Step: 13
Training loss: 2.7535243034362793
Validation loss: 1.9727883877292756

Epoch: 50| Step: 0
Training loss: 2.007798671722412
Validation loss: 1.9658488201838669

Epoch: 6| Step: 1
Training loss: 2.5018720626831055
Validation loss: 1.9567590875010337

Epoch: 6| Step: 2
Training loss: 2.635056495666504
Validation loss: 1.9659322589956305

Epoch: 6| Step: 3
Training loss: 2.1637933254241943
Validation loss: 1.9640146506729947

Epoch: 6| Step: 4
Training loss: 2.473904609680176
Validation loss: 1.9799840450286865

Epoch: 6| Step: 5
Training loss: 2.766165256500244
Validation loss: 1.9841441441607732

Epoch: 6| Step: 6
Training loss: 2.1189541816711426
Validation loss: 1.9762860446847894

Epoch: 6| Step: 7
Training loss: 2.771900177001953
Validation loss: 1.9788046549725276

Epoch: 6| Step: 8
Training loss: 1.8713467121124268
Validation loss: 1.9879416406795543

Epoch: 6| Step: 9
Training loss: 2.6213901042938232
Validation loss: 2.0051484454062676

Epoch: 6| Step: 10
Training loss: 2.4077019691467285
Validation loss: 1.972262337643613

Epoch: 6| Step: 11
Training loss: 2.1473348140716553
Validation loss: 1.988692597676349

Epoch: 6| Step: 12
Training loss: 1.8156765699386597
Validation loss: 1.9835410182194044

Epoch: 6| Step: 13
Training loss: 1.864635705947876
Validation loss: 1.9758814688651793

Testing loss: 2.2188242329491508
