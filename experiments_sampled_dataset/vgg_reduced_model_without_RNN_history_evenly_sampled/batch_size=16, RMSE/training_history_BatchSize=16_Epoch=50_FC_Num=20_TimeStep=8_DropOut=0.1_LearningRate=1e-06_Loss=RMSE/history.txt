Epoch: 1| Step: 0
Training loss: 8.103934342716178
Validation loss: 7.508174130720664

Epoch: 6| Step: 1
Training loss: 8.185408230378568
Validation loss: 7.50696239187424

Epoch: 6| Step: 2
Training loss: 7.078750414301843
Validation loss: 7.5066631620956965

Epoch: 6| Step: 3
Training loss: 8.127873308801373
Validation loss: 7.503361638381398

Epoch: 6| Step: 4
Training loss: 7.764240594342497
Validation loss: 7.499449583249255

Epoch: 6| Step: 5
Training loss: 6.393978218487774
Validation loss: 7.495022167103061

Epoch: 6| Step: 6
Training loss: 7.796956461326077
Validation loss: 7.491419542881918

Epoch: 6| Step: 7
Training loss: 7.452414552748365
Validation loss: 7.4918391493522885

Epoch: 6| Step: 8
Training loss: 7.32147787256954
Validation loss: 7.485007759313968

Epoch: 6| Step: 9
Training loss: 7.528535599079118
Validation loss: 7.483195346155991

Epoch: 6| Step: 10
Training loss: 7.193736944509901
Validation loss: 7.482244627805977

Epoch: 6| Step: 11
Training loss: 7.038987983876532
Validation loss: 7.4784635684707625

Epoch: 6| Step: 12
Training loss: 7.427809099758887
Validation loss: 7.471394029036586

Epoch: 6| Step: 13
Training loss: 6.501242592221884
Validation loss: 7.4696859373225335

Epoch: 2| Step: 0
Training loss: 6.948584147527713
Validation loss: 7.468013466756667

Epoch: 6| Step: 1
Training loss: 7.418810016803887
Validation loss: 7.4662640382100856

Epoch: 6| Step: 2
Training loss: 8.710925238220069
Validation loss: 7.4621751626873785

Epoch: 6| Step: 3
Training loss: 6.504126192790103
Validation loss: 7.459944240739206

Epoch: 6| Step: 4
Training loss: 7.989306932929457
Validation loss: 7.454213567221996

Epoch: 6| Step: 5
Training loss: 7.390246133589805
Validation loss: 7.4533368651080325

Epoch: 6| Step: 6
Training loss: 6.659495820444633
Validation loss: 7.4527676493808785

Epoch: 6| Step: 7
Training loss: 7.019205178152852
Validation loss: 7.448940237456672

Epoch: 6| Step: 8
Training loss: 7.917678714779273
Validation loss: 7.443224204140427

Epoch: 6| Step: 9
Training loss: 7.673817934343577
Validation loss: 7.4422797829846346

Epoch: 6| Step: 10
Training loss: 6.4921663469872
Validation loss: 7.438968994908838

Epoch: 6| Step: 11
Training loss: 8.266296936298774
Validation loss: 7.4358343236170725

Epoch: 6| Step: 12
Training loss: 7.465532064518085
Validation loss: 7.431435493403371

Epoch: 6| Step: 13
Training loss: 6.921785444450996
Validation loss: 7.426852710768017

Epoch: 3| Step: 0
Training loss: 7.870068171398577
Validation loss: 7.424696375654702

Epoch: 6| Step: 1
Training loss: 6.984687405625027
Validation loss: 7.422903171168881

Epoch: 6| Step: 2
Training loss: 6.5031202603148275
Validation loss: 7.418117872973971

Epoch: 6| Step: 3
Training loss: 8.032003285745503
Validation loss: 7.417809092724236

Epoch: 6| Step: 4
Training loss: 7.403692262557402
Validation loss: 7.414623313155013

Epoch: 6| Step: 5
Training loss: 7.625683863256083
Validation loss: 7.4083528348879515

Epoch: 6| Step: 6
Training loss: 6.580160156898135
Validation loss: 7.406228968165242

Epoch: 6| Step: 7
Training loss: 7.8233927968315395
Validation loss: 7.401187333422925

Epoch: 6| Step: 8
Training loss: 6.342912590491472
Validation loss: 7.399519782876747

Epoch: 6| Step: 9
Training loss: 8.188588776157925
Validation loss: 7.3949693585637055

Epoch: 6| Step: 10
Training loss: 7.616103438484364
Validation loss: 7.394062194011094

Epoch: 6| Step: 11
Training loss: 7.652586515897797
Validation loss: 7.388746536815906

Epoch: 6| Step: 12
Training loss: 7.528510264114342
Validation loss: 7.384627931883675

Epoch: 6| Step: 13
Training loss: 6.4746650520796125
Validation loss: 7.385183104478497

Epoch: 4| Step: 0
Training loss: 7.100881613140575
Validation loss: 7.376330659378696

Epoch: 6| Step: 1
Training loss: 8.535482509496571
Validation loss: 7.3718388566115784

Epoch: 6| Step: 2
Training loss: 8.54570554442131
Validation loss: 7.369374742016179

Epoch: 6| Step: 3
Training loss: 7.0774281139758735
Validation loss: 7.363901989028405

Epoch: 6| Step: 4
Training loss: 7.684390547939486
Validation loss: 7.3646053910238765

Epoch: 6| Step: 5
Training loss: 7.066032943860416
Validation loss: 7.360579064953473

Epoch: 6| Step: 6
Training loss: 6.291313649899061
Validation loss: 7.35581368870974

Epoch: 6| Step: 7
Training loss: 6.345249543750107
Validation loss: 7.353551070609392

Epoch: 6| Step: 8
Training loss: 8.007560971659457
Validation loss: 7.348182104950446

Epoch: 6| Step: 9
Training loss: 7.2924749598499865
Validation loss: 7.346186318709275

Epoch: 6| Step: 10
Training loss: 5.6971846068973715
Validation loss: 7.342401458634166

Epoch: 6| Step: 11
Training loss: 7.548917821669561
Validation loss: 7.337230112224176

Epoch: 6| Step: 12
Training loss: 6.837891182876298
Validation loss: 7.335419907082085

Epoch: 6| Step: 13
Training loss: 8.485376681776751
Validation loss: 7.332218340833646

Epoch: 5| Step: 0
Training loss: 8.448637217042481
Validation loss: 7.329333367640678

Epoch: 6| Step: 1
Training loss: 6.487254925694478
Validation loss: 7.322027416362977

Epoch: 6| Step: 2
Training loss: 7.109803172202515
Validation loss: 7.319206716448149

Epoch: 6| Step: 3
Training loss: 6.769924286682393
Validation loss: 7.317865700654139

Epoch: 6| Step: 4
Training loss: 7.153411168898259
Validation loss: 7.310779243913311

Epoch: 6| Step: 5
Training loss: 7.317894404931552
Validation loss: 7.308873199474752

Epoch: 6| Step: 6
Training loss: 6.955035617937362
Validation loss: 7.3038744388136285

Epoch: 6| Step: 7
Training loss: 7.171504258357288
Validation loss: 7.3021620448831905

Epoch: 6| Step: 8
Training loss: 7.1348506359567265
Validation loss: 7.298595726844368

Epoch: 6| Step: 9
Training loss: 7.163158829831063
Validation loss: 7.28872650732866

Epoch: 6| Step: 10
Training loss: 7.7635048134541265
Validation loss: 7.287290932200472

Epoch: 6| Step: 11
Training loss: 7.195558757067864
Validation loss: 7.28276816623496

Epoch: 6| Step: 12
Training loss: 7.3160981023268885
Validation loss: 7.279749432290064

Epoch: 6| Step: 13
Training loss: 8.094522446700406
Validation loss: 7.275951144785869

Epoch: 6| Step: 0
Training loss: 7.055715086861351
Validation loss: 7.271105635821356

Epoch: 6| Step: 1
Training loss: 7.4322301322530056
Validation loss: 7.266892337521792

Epoch: 6| Step: 2
Training loss: 8.883826795927478
Validation loss: 7.264746545919304

Epoch: 6| Step: 3
Training loss: 6.483523393344163
Validation loss: 7.255243353706203

Epoch: 6| Step: 4
Training loss: 7.726672843862614
Validation loss: 7.2558226946324265

Epoch: 6| Step: 5
Training loss: 6.756553576739517
Validation loss: 7.243265299059082

Epoch: 6| Step: 6
Training loss: 7.896438239956126
Validation loss: 7.2492773355690145

Epoch: 6| Step: 7
Training loss: 6.832782475047655
Validation loss: 7.244935130394908

Epoch: 6| Step: 8
Training loss: 6.683460762667294
Validation loss: 7.234720839191793

Epoch: 6| Step: 9
Training loss: 8.785931734059108
Validation loss: 7.234415967813724

Epoch: 6| Step: 10
Training loss: 7.448183993008039
Validation loss: 7.230410528049124

Epoch: 6| Step: 11
Training loss: 5.404356873085818
Validation loss: 7.224572944758291

Epoch: 6| Step: 12
Training loss: 4.9553052273538345
Validation loss: 7.219658373145953

Epoch: 6| Step: 13
Training loss: 7.995412464869991
Validation loss: 7.213799366372538

Epoch: 7| Step: 0
Training loss: 7.215480840340733
Validation loss: 7.208102415379953

Epoch: 6| Step: 1
Training loss: 7.304659821972964
Validation loss: 7.205308711969347

Epoch: 6| Step: 2
Training loss: 6.33635713102525
Validation loss: 7.197069523346626

Epoch: 6| Step: 3
Training loss: 5.206043787944649
Validation loss: 7.194215757466348

Epoch: 6| Step: 4
Training loss: 6.4850109110249985
Validation loss: 7.188074258242646

Epoch: 6| Step: 5
Training loss: 9.01403519548105
Validation loss: 7.187261003013521

Epoch: 6| Step: 6
Training loss: 7.571105600547944
Validation loss: 7.183973434331704

Epoch: 6| Step: 7
Training loss: 6.825306465618183
Validation loss: 7.178316497223382

Epoch: 6| Step: 8
Training loss: 8.561100977746488
Validation loss: 7.172716737321638

Epoch: 6| Step: 9
Training loss: 7.164149026961791
Validation loss: 7.168630093017852

Epoch: 6| Step: 10
Training loss: 7.3048230163733
Validation loss: 7.164304586785217

Epoch: 6| Step: 11
Training loss: 7.057634956672144
Validation loss: 7.159097448474246

Epoch: 6| Step: 12
Training loss: 5.737833502889812
Validation loss: 7.150602267344307

Epoch: 6| Step: 13
Training loss: 7.765891241348989
Validation loss: 7.1455601700051155

Epoch: 8| Step: 0
Training loss: 7.314369940698551
Validation loss: 7.139503560221303

Epoch: 6| Step: 1
Training loss: 6.693445147812698
Validation loss: 7.137629396737481

Epoch: 6| Step: 2
Training loss: 7.6524235096660105
Validation loss: 7.129893092393073

Epoch: 6| Step: 3
Training loss: 8.126283514906948
Validation loss: 7.126781961127022

Epoch: 6| Step: 4
Training loss: 7.56494605489534
Validation loss: 7.120404520041249

Epoch: 6| Step: 5
Training loss: 6.737096533080472
Validation loss: 7.114750880883055

Epoch: 6| Step: 6
Training loss: 6.5121859249594705
Validation loss: 7.108388895428033

Epoch: 6| Step: 7
Training loss: 7.639610925324145
Validation loss: 7.1069908380539415

Epoch: 6| Step: 8
Training loss: 5.09993419978759
Validation loss: 7.096625508478282

Epoch: 6| Step: 9
Training loss: 6.213571817517305
Validation loss: 7.093707748546739

Epoch: 6| Step: 10
Training loss: 6.250774488146261
Validation loss: 7.085526080524358

Epoch: 6| Step: 11
Training loss: 8.16736999389568
Validation loss: 7.087332941853445

Epoch: 6| Step: 12
Training loss: 7.658047959327709
Validation loss: 7.079444148594754

Epoch: 6| Step: 13
Training loss: 6.696312632692403
Validation loss: 7.0694613489933555

Epoch: 9| Step: 0
Training loss: 7.525075066784529
Validation loss: 7.067448488188906

Epoch: 6| Step: 1
Training loss: 6.907197222761277
Validation loss: 7.060928409442226

Epoch: 6| Step: 2
Training loss: 6.905450144575569
Validation loss: 7.056330105768202

Epoch: 6| Step: 3
Training loss: 7.622327993021759
Validation loss: 7.049972634432198

Epoch: 6| Step: 4
Training loss: 6.847945368789516
Validation loss: 7.041334153715314

Epoch: 6| Step: 5
Training loss: 6.196477677019957
Validation loss: 7.0403715883093305

Epoch: 6| Step: 6
Training loss: 6.333905478617481
Validation loss: 7.03507703682202

Epoch: 6| Step: 7
Training loss: 6.276819592985038
Validation loss: 7.027112401619281

Epoch: 6| Step: 8
Training loss: 7.106848366271217
Validation loss: 7.022759695050995

Epoch: 6| Step: 9
Training loss: 7.5087097457484955
Validation loss: 7.01087899109711

Epoch: 6| Step: 10
Training loss: 6.512954713612133
Validation loss: 7.008615831458689

Epoch: 6| Step: 11
Training loss: 7.877001795581721
Validation loss: 7.001997579168395

Epoch: 6| Step: 12
Training loss: 7.325934694824411
Validation loss: 6.992625528560273

Epoch: 6| Step: 13
Training loss: 6.732990166760483
Validation loss: 6.986357337180331

Epoch: 10| Step: 0
Training loss: 7.974890403831579
Validation loss: 6.983453851783178

Epoch: 6| Step: 1
Training loss: 6.530400709210084
Validation loss: 6.98101717849809

Epoch: 6| Step: 2
Training loss: 5.091360830725178
Validation loss: 6.97605488045713

Epoch: 6| Step: 3
Training loss: 7.040173645045453
Validation loss: 6.960409953823601

Epoch: 6| Step: 4
Training loss: 6.075175768660293
Validation loss: 6.959477335062921

Epoch: 6| Step: 5
Training loss: 6.95488505857419
Validation loss: 6.953243326229044

Epoch: 6| Step: 6
Training loss: 7.723957729703983
Validation loss: 6.947869335749522

Epoch: 6| Step: 7
Training loss: 7.128252592036083
Validation loss: 6.938588901046317

Epoch: 6| Step: 8
Training loss: 7.128749463173145
Validation loss: 6.9295848720405635

Epoch: 6| Step: 9
Training loss: 7.8895961581732745
Validation loss: 6.922841077373276

Epoch: 6| Step: 10
Training loss: 6.460487580691835
Validation loss: 6.924211591815058

Epoch: 6| Step: 11
Training loss: 6.6691508750946245
Validation loss: 6.911358956062849

Epoch: 6| Step: 12
Training loss: 6.609773808705264
Validation loss: 6.908468080048627

Epoch: 6| Step: 13
Training loss: 7.095203670833927
Validation loss: 6.899490025860697

Epoch: 11| Step: 0
Training loss: 6.416807528184071
Validation loss: 6.893047693464682

Epoch: 6| Step: 1
Training loss: 7.2366109404079495
Validation loss: 6.88700071675488

Epoch: 6| Step: 2
Training loss: 6.8537396546278275
Validation loss: 6.88059210490415

Epoch: 6| Step: 3
Training loss: 7.7256221681183375
Validation loss: 6.868028323586202

Epoch: 6| Step: 4
Training loss: 6.940563453425478
Validation loss: 6.8632040185270595

Epoch: 6| Step: 5
Training loss: 6.669207788000855
Validation loss: 6.856030082176298

Epoch: 6| Step: 6
Training loss: 6.415432336499933
Validation loss: 6.841490481131293

Epoch: 6| Step: 7
Training loss: 7.138051710835563
Validation loss: 6.845102337363797

Epoch: 6| Step: 8
Training loss: 7.096149055713137
Validation loss: 6.832705084940684

Epoch: 6| Step: 9
Training loss: 7.579019961650817
Validation loss: 6.824297564692078

Epoch: 6| Step: 10
Training loss: 7.4768982177108585
Validation loss: 6.818700775154986

Epoch: 6| Step: 11
Training loss: 6.461577488708011
Validation loss: 6.809129353574577

Epoch: 6| Step: 12
Training loss: 4.69747067834657
Validation loss: 6.795493858359199

Epoch: 6| Step: 13
Training loss: 5.708942278753454
Validation loss: 6.796561086022972

Epoch: 12| Step: 0
Training loss: 6.338878245469672
Validation loss: 6.779890298849161

Epoch: 6| Step: 1
Training loss: 6.8209170917952475
Validation loss: 6.774940957922082

Epoch: 6| Step: 2
Training loss: 7.513888152430559
Validation loss: 6.766321006581111

Epoch: 6| Step: 3
Training loss: 6.853843457177735
Validation loss: 6.762878619906343

Epoch: 6| Step: 4
Training loss: 5.182517358922892
Validation loss: 6.751579570800181

Epoch: 6| Step: 5
Training loss: 6.386335280919136
Validation loss: 6.741897432467471

Epoch: 6| Step: 6
Training loss: 7.278765995532801
Validation loss: 6.737549383417881

Epoch: 6| Step: 7
Training loss: 7.327133274278759
Validation loss: 6.721157195827815

Epoch: 6| Step: 8
Training loss: 7.4264336329025555
Validation loss: 6.723886665458013

Epoch: 6| Step: 9
Training loss: 5.834573813648608
Validation loss: 6.710895191571012

Epoch: 6| Step: 10
Training loss: 7.086511624429457
Validation loss: 6.705689576977234

Epoch: 6| Step: 11
Training loss: 6.01828712909759
Validation loss: 6.70494688213811

Epoch: 6| Step: 12
Training loss: 5.754211210519947
Validation loss: 6.693527447988606

Epoch: 6| Step: 13
Training loss: 8.213757989647613
Validation loss: 6.672001139052709

Epoch: 13| Step: 0
Training loss: 7.5176872231626355
Validation loss: 6.677549260850309

Epoch: 6| Step: 1
Training loss: 6.951038793419095
Validation loss: 6.659299712687782

Epoch: 6| Step: 2
Training loss: 5.819508910549149
Validation loss: 6.656773256760818

Epoch: 6| Step: 3
Training loss: 6.813115363370112
Validation loss: 6.634670385663026

Epoch: 6| Step: 4
Training loss: 5.456735372202065
Validation loss: 6.631316628705681

Epoch: 6| Step: 5
Training loss: 6.538117371213645
Validation loss: 6.63066731044191

Epoch: 6| Step: 6
Training loss: 6.681109075246549
Validation loss: 6.6202787206868114

Epoch: 6| Step: 7
Training loss: 6.630946531551651
Validation loss: 6.605998323428449

Epoch: 6| Step: 8
Training loss: 6.488782740440361
Validation loss: 6.603813714989886

Epoch: 6| Step: 9
Training loss: 4.820856147169216
Validation loss: 6.581813614520969

Epoch: 6| Step: 10
Training loss: 6.402293104398526
Validation loss: 6.581373167716737

Epoch: 6| Step: 11
Training loss: 7.088841828309959
Validation loss: 6.575786722648079

Epoch: 6| Step: 12
Training loss: 7.270140460938657
Validation loss: 6.576372576050613

Epoch: 6| Step: 13
Training loss: 7.690100253360699
Validation loss: 6.558054678754867

Epoch: 14| Step: 0
Training loss: 5.715124095994521
Validation loss: 6.55213792533192

Epoch: 6| Step: 1
Training loss: 6.718176528941721
Validation loss: 6.54029884352785

Epoch: 6| Step: 2
Training loss: 6.758474046376658
Validation loss: 6.5236431684538045

Epoch: 6| Step: 3
Training loss: 5.69701285810126
Validation loss: 6.51456983781921

Epoch: 6| Step: 4
Training loss: 7.506789122825438
Validation loss: 6.506426821576082

Epoch: 6| Step: 5
Training loss: 7.045740006556461
Validation loss: 6.502625177438768

Epoch: 6| Step: 6
Training loss: 5.399594835693549
Validation loss: 6.4948093033719125

Epoch: 6| Step: 7
Training loss: 6.784820601046052
Validation loss: 6.485619434788157

Epoch: 6| Step: 8
Training loss: 6.470431049498062
Validation loss: 6.463418166245209

Epoch: 6| Step: 9
Training loss: 6.370018602281174
Validation loss: 6.466460296074715

Epoch: 6| Step: 10
Training loss: 5.905333432725044
Validation loss: 6.455607845489109

Epoch: 6| Step: 11
Training loss: 6.832909206471059
Validation loss: 6.440337025368579

Epoch: 6| Step: 12
Training loss: 6.311296102710896
Validation loss: 6.4319158145266595

Epoch: 6| Step: 13
Training loss: 6.9343631285281715
Validation loss: 6.4229025241651305

Epoch: 15| Step: 0
Training loss: 5.692178332153611
Validation loss: 6.413659026805081

Epoch: 6| Step: 1
Training loss: 7.282849835977564
Validation loss: 6.4067277387538635

Epoch: 6| Step: 2
Training loss: 6.2510124912311085
Validation loss: 6.397003712347004

Epoch: 6| Step: 3
Training loss: 6.676717747178495
Validation loss: 6.384862009456131

Epoch: 6| Step: 4
Training loss: 7.028721876228914
Validation loss: 6.383667669111345

Epoch: 6| Step: 5
Training loss: 7.326792776858066
Validation loss: 6.378051085593301

Epoch: 6| Step: 6
Training loss: 5.857342746527044
Validation loss: 6.353024940926869

Epoch: 6| Step: 7
Training loss: 5.311501263254643
Validation loss: 6.349169739826658

Epoch: 6| Step: 8
Training loss: 6.813697639674243
Validation loss: 6.331551608294106

Epoch: 6| Step: 9
Training loss: 6.48645045145868
Validation loss: 6.327111626694697

Epoch: 6| Step: 10
Training loss: 6.636786574476857
Validation loss: 6.3113198994140465

Epoch: 6| Step: 11
Training loss: 6.292357080569612
Validation loss: 6.311257926411404

Epoch: 6| Step: 12
Training loss: 4.411615662394623
Validation loss: 6.3074453010733444

Epoch: 6| Step: 13
Training loss: 5.711334924398353
Validation loss: 6.29460740085093

Epoch: 16| Step: 0
Training loss: 5.947952546536464
Validation loss: 6.273802639455637

Epoch: 6| Step: 1
Training loss: 6.201341040999689
Validation loss: 6.257627388505048

Epoch: 6| Step: 2
Training loss: 5.7391291148419175
Validation loss: 6.266032087486996

Epoch: 6| Step: 3
Training loss: 5.603241949355532
Validation loss: 6.254417095685276

Epoch: 6| Step: 4
Training loss: 5.925861073951484
Validation loss: 6.250636711913224

Epoch: 6| Step: 5
Training loss: 5.7943379487568984
Validation loss: 6.234565973113285

Epoch: 6| Step: 6
Training loss: 6.152312747937763
Validation loss: 6.225319930439991

Epoch: 6| Step: 7
Training loss: 7.01404823986702
Validation loss: 6.212765163644688

Epoch: 6| Step: 8
Training loss: 6.276163803326172
Validation loss: 6.186490893618892

Epoch: 6| Step: 9
Training loss: 6.735290889900898
Validation loss: 6.198328352136796

Epoch: 6| Step: 10
Training loss: 6.848575650004743
Validation loss: 6.177792780769831

Epoch: 6| Step: 11
Training loss: 6.177268460240563
Validation loss: 6.163758578570335

Epoch: 6| Step: 12
Training loss: 6.621527571517851
Validation loss: 6.154220153965846

Epoch: 6| Step: 13
Training loss: 4.550549677249146
Validation loss: 6.141571123165277

Epoch: 17| Step: 0
Training loss: 5.397663331451607
Validation loss: 6.1335532174859875

Epoch: 6| Step: 1
Training loss: 5.947564198683436
Validation loss: 6.108103416890436

Epoch: 6| Step: 2
Training loss: 6.430118513898729
Validation loss: 6.119887229855777

Epoch: 6| Step: 3
Training loss: 6.142494285993825
Validation loss: 6.109081867110379

Epoch: 6| Step: 4
Training loss: 6.087956731374324
Validation loss: 6.0801841528658525

Epoch: 6| Step: 5
Training loss: 6.292566837142244
Validation loss: 6.0665857104570655

Epoch: 6| Step: 6
Training loss: 5.35724528623478
Validation loss: 6.053172510611078

Epoch: 6| Step: 7
Training loss: 5.367888958665091
Validation loss: 6.0604992715408486

Epoch: 6| Step: 8
Training loss: 5.609147176127315
Validation loss: 6.057492683935113

Epoch: 6| Step: 9
Training loss: 6.384680485150446
Validation loss: 6.0528020648200815

Epoch: 6| Step: 10
Training loss: 6.659214845948579
Validation loss: 6.039072382577828

Epoch: 6| Step: 11
Training loss: 6.961054226188833
Validation loss: 6.015458751267536

Epoch: 6| Step: 12
Training loss: 5.991705565487685
Validation loss: 5.99277490303539

Epoch: 6| Step: 13
Training loss: 5.137090795699616
Validation loss: 5.992500833162229

Epoch: 18| Step: 0
Training loss: 5.806094998856132
Validation loss: 5.979407292316611

Epoch: 6| Step: 1
Training loss: 5.705646783003864
Validation loss: 5.966807815624704

Epoch: 6| Step: 2
Training loss: 6.476028843740656
Validation loss: 5.941557491235867

Epoch: 6| Step: 3
Training loss: 7.122153533403302
Validation loss: 5.934851823881429

Epoch: 6| Step: 4
Training loss: 5.471532843854358
Validation loss: 5.921434170089803

Epoch: 6| Step: 5
Training loss: 4.8657051878528
Validation loss: 5.901680683227152

Epoch: 6| Step: 6
Training loss: 5.021936741219716
Validation loss: 5.89887230393843

Epoch: 6| Step: 7
Training loss: 5.954575569664369
Validation loss: 5.868551345226035

Epoch: 6| Step: 8
Training loss: 4.853267842958306
Validation loss: 5.869707265277781

Epoch: 6| Step: 9
Training loss: 6.2874476284629255
Validation loss: 5.859811041683079

Epoch: 6| Step: 10
Training loss: 5.592478176001034
Validation loss: 5.8382166408608125

Epoch: 6| Step: 11
Training loss: 5.531324483079019
Validation loss: 5.809116860463426

Epoch: 6| Step: 12
Training loss: 6.329036392702783
Validation loss: 5.825207732854169

Epoch: 6| Step: 13
Training loss: 7.07955897881165
Validation loss: 5.8110602240026905

Epoch: 19| Step: 0
Training loss: 5.497337216911514
Validation loss: 5.786112568763927

Epoch: 6| Step: 1
Training loss: 4.913735674495383
Validation loss: 5.769869042536562

Epoch: 6| Step: 2
Training loss: 4.72932028275883
Validation loss: 5.757338454218572

Epoch: 6| Step: 3
Training loss: 5.829652151523594
Validation loss: 5.740676036497566

Epoch: 6| Step: 4
Training loss: 6.2269702045591
Validation loss: 5.735663830540219

Epoch: 6| Step: 5
Training loss: 4.960760639071801
Validation loss: 5.730335185191922

Epoch: 6| Step: 6
Training loss: 6.162219256647088
Validation loss: 5.71011969263156

Epoch: 6| Step: 7
Training loss: 5.666703317561086
Validation loss: 5.6786753678292605

Epoch: 6| Step: 8
Training loss: 6.162922452796213
Validation loss: 5.669120003546948

Epoch: 6| Step: 9
Training loss: 6.784058441972017
Validation loss: 5.661899397509541

Epoch: 6| Step: 10
Training loss: 5.526607655822556
Validation loss: 5.661320871395126

Epoch: 6| Step: 11
Training loss: 5.773873236580416
Validation loss: 5.61478434747023

Epoch: 6| Step: 12
Training loss: 5.640299357051734
Validation loss: 5.618859306158397

Epoch: 6| Step: 13
Training loss: 4.446031777059412
Validation loss: 5.6001544714276985

Epoch: 20| Step: 0
Training loss: 5.7173390133056134
Validation loss: 5.57095845269777

Epoch: 6| Step: 1
Training loss: 5.11073028601554
Validation loss: 5.565378653336566

Epoch: 6| Step: 2
Training loss: 6.026152833678674
Validation loss: 5.535358730674034

Epoch: 6| Step: 3
Training loss: 6.251979666942254
Validation loss: 5.551820309155959

Epoch: 6| Step: 4
Training loss: 5.843312619410677
Validation loss: 5.51040133124751

Epoch: 6| Step: 5
Training loss: 3.9498449898737498
Validation loss: 5.519634202815716

Epoch: 6| Step: 6
Training loss: 5.276437225526508
Validation loss: 5.466029084649249

Epoch: 6| Step: 7
Training loss: 5.5097998963175545
Validation loss: 5.470605615212807

Epoch: 6| Step: 8
Training loss: 5.908616656498967
Validation loss: 5.458335237080795

Epoch: 6| Step: 9
Training loss: 4.968945385432225
Validation loss: 5.450564820711844

Epoch: 6| Step: 10
Training loss: 4.765244565693772
Validation loss: 5.423063204681468

Epoch: 6| Step: 11
Training loss: 5.978903557529938
Validation loss: 5.40219630959319

Epoch: 6| Step: 12
Training loss: 4.786473830083501
Validation loss: 5.385697371435349

Epoch: 6| Step: 13
Training loss: 6.340403609079266
Validation loss: 5.3585978480009

Epoch: 21| Step: 0
Training loss: 5.3345886580994275
Validation loss: 5.342629726452084

Epoch: 6| Step: 1
Training loss: 4.2649587033990395
Validation loss: 5.305317831502171

Epoch: 6| Step: 2
Training loss: 5.644470763624878
Validation loss: 5.303091598537914

Epoch: 6| Step: 3
Training loss: 5.248819854336901
Validation loss: 5.29502690779219

Epoch: 6| Step: 4
Training loss: 5.57087796672934
Validation loss: 5.263416858345907

Epoch: 6| Step: 5
Training loss: 5.324980313976596
Validation loss: 5.241607505312787

Epoch: 6| Step: 6
Training loss: 4.7142542965985665
Validation loss: 5.244294006875185

Epoch: 6| Step: 7
Training loss: 4.645914370709583
Validation loss: 5.209522745809278

Epoch: 6| Step: 8
Training loss: 6.219640926778381
Validation loss: 5.18634167541268

Epoch: 6| Step: 9
Training loss: 4.958491069090574
Validation loss: 5.141089218857328

Epoch: 6| Step: 10
Training loss: 5.080929964504453
Validation loss: 5.178429357185331

Epoch: 6| Step: 11
Training loss: 5.311513652115687
Validation loss: 5.158836303301673

Epoch: 6| Step: 12
Training loss: 5.265297174861036
Validation loss: 5.121178371421475

Epoch: 6| Step: 13
Training loss: 5.178727971609502
Validation loss: 5.131859833217273

Epoch: 22| Step: 0
Training loss: 4.126130382672662
Validation loss: 5.06388577750703

Epoch: 6| Step: 1
Training loss: 4.687719111089906
Validation loss: 5.044415461482997

Epoch: 6| Step: 2
Training loss: 5.784132450238696
Validation loss: 5.033027711415518

Epoch: 6| Step: 3
Training loss: 5.627484938314542
Validation loss: 4.995106917770597

Epoch: 6| Step: 4
Training loss: 4.161925148433368
Validation loss: 5.0070345134157845

Epoch: 6| Step: 5
Training loss: 5.385397147973977
Validation loss: 4.982234287726754

Epoch: 6| Step: 6
Training loss: 4.359407158189519
Validation loss: 4.969859830934312

Epoch: 6| Step: 7
Training loss: 4.710858345948307
Validation loss: 4.941192787063962

Epoch: 6| Step: 8
Training loss: 3.9030911299837108
Validation loss: 4.930620868964141

Epoch: 6| Step: 9
Training loss: 5.381323177890124
Validation loss: 4.885306587485993

Epoch: 6| Step: 10
Training loss: 4.912702266033175
Validation loss: 4.84948633415102

Epoch: 6| Step: 11
Training loss: 4.74559780716437
Validation loss: 4.845363231592991

Epoch: 6| Step: 12
Training loss: 5.476696758284335
Validation loss: 4.81934640305205

Epoch: 6| Step: 13
Training loss: 5.2735738552973155
Validation loss: 4.80502048141951

Epoch: 23| Step: 0
Training loss: 5.684470239547118
Validation loss: 4.7682852181905115

Epoch: 6| Step: 1
Training loss: 3.3740634325144008
Validation loss: 4.775239713570774

Epoch: 6| Step: 2
Training loss: 4.981363660408295
Validation loss: 4.7306904945438895

Epoch: 6| Step: 3
Training loss: 4.526354861937102
Validation loss: 4.742661572131852

Epoch: 6| Step: 4
Training loss: 4.074141972550785
Validation loss: 4.657467768954924

Epoch: 6| Step: 5
Training loss: 3.947788179398613
Validation loss: 4.670996372858298

Epoch: 6| Step: 6
Training loss: 5.992729868707322
Validation loss: 4.638241734265789

Epoch: 6| Step: 7
Training loss: 4.512083149515812
Validation loss: 4.623510799982948

Epoch: 6| Step: 8
Training loss: 4.181357818262592
Validation loss: 4.584330027358741

Epoch: 6| Step: 9
Training loss: 4.4359287112727745
Validation loss: 4.578812336999427

Epoch: 6| Step: 10
Training loss: 5.173179991963169
Validation loss: 4.536813068272802

Epoch: 6| Step: 11
Training loss: 4.677673415899771
Validation loss: 4.496332848323981

Epoch: 6| Step: 12
Training loss: 4.5003108870881725
Validation loss: 4.47955013540549

Epoch: 6| Step: 13
Training loss: 3.842515700735703
Validation loss: 4.481397738871563

Epoch: 24| Step: 0
Training loss: 4.878229098825208
Validation loss: 4.443802506649924

Epoch: 6| Step: 1
Training loss: 3.7204497483854326
Validation loss: 4.428650188322219

Epoch: 6| Step: 2
Training loss: 3.960551286336186
Validation loss: 4.371302545574822

Epoch: 6| Step: 3
Training loss: 3.505474985455926
Validation loss: 4.376794690138794

Epoch: 6| Step: 4
Training loss: 4.416842451136239
Validation loss: 4.371137504927179

Epoch: 6| Step: 5
Training loss: 5.356243319601836
Validation loss: 4.356255706629421

Epoch: 6| Step: 6
Training loss: 4.043019700765908
Validation loss: 4.26660018291961

Epoch: 6| Step: 7
Training loss: 4.275458212048579
Validation loss: 4.266483319544944

Epoch: 6| Step: 8
Training loss: 4.526511193940339
Validation loss: 4.238147344960064

Epoch: 6| Step: 9
Training loss: 4.678277059465075
Validation loss: 4.25787947617946

Epoch: 6| Step: 10
Training loss: 4.604831745333594
Validation loss: 4.204381650364432

Epoch: 6| Step: 11
Training loss: 3.2510193913332333
Validation loss: 4.196799482150356

Epoch: 6| Step: 12
Training loss: 4.516159712340041
Validation loss: 4.148474061853993

Epoch: 6| Step: 13
Training loss: 3.5383154478503034
Validation loss: 4.10719569488231

Epoch: 25| Step: 0
Training loss: 3.4715766730496957
Validation loss: 4.101530025293066

Epoch: 6| Step: 1
Training loss: 3.2137753459890916
Validation loss: 4.077682379945595

Epoch: 6| Step: 2
Training loss: 5.17735769771633
Validation loss: 3.980158298250924

Epoch: 6| Step: 3
Training loss: 3.838505710690479
Validation loss: 3.998401412137731

Epoch: 6| Step: 4
Training loss: 4.356143533070609
Validation loss: 3.925115422195795

Epoch: 6| Step: 5
Training loss: 2.881875151959136
Validation loss: 3.9145953675935443

Epoch: 6| Step: 6
Training loss: 3.4526839168766084
Validation loss: 3.917920114731061

Epoch: 6| Step: 7
Training loss: 4.091546783452043
Validation loss: 3.917758893212493

Epoch: 6| Step: 8
Training loss: 4.227626025071438
Validation loss: 3.883353529505308

Epoch: 6| Step: 9
Training loss: 3.729866146927933
Validation loss: 3.8157376965726724

Epoch: 6| Step: 10
Training loss: 4.510138640376804
Validation loss: 3.816654683031728

Epoch: 6| Step: 11
Training loss: 3.9132806602412087
Validation loss: 3.8167185354857125

Epoch: 6| Step: 12
Training loss: 3.8016128179228117
Validation loss: 3.7502272670338237

Epoch: 6| Step: 13
Training loss: 3.4636759720005093
Validation loss: 3.742720233488512

Epoch: 26| Step: 0
Training loss: 3.7827462002641403
Validation loss: 3.7278789392061316

Epoch: 6| Step: 1
Training loss: 3.61165741594647
Validation loss: 3.6914101071892893

Epoch: 6| Step: 2
Training loss: 4.462050317498523
Validation loss: 3.6674782469156106

Epoch: 6| Step: 3
Training loss: 3.1083386098153856
Validation loss: 3.639802790161643

Epoch: 6| Step: 4
Training loss: 3.5564722296763382
Validation loss: 3.6066614633375216

Epoch: 6| Step: 5
Training loss: 4.180143356420281
Validation loss: 3.585454044722917

Epoch: 6| Step: 6
Training loss: 3.3428103829118867
Validation loss: 3.5785827530198557

Epoch: 6| Step: 7
Training loss: 4.104110071918378
Validation loss: 3.5348921279262773

Epoch: 6| Step: 8
Training loss: 2.9440896002361665
Validation loss: 3.532011919280609

Epoch: 6| Step: 9
Training loss: 3.0872708687336057
Validation loss: 3.5157020449200425

Epoch: 6| Step: 10
Training loss: 3.4229040819348087
Validation loss: 3.4602764723082293

Epoch: 6| Step: 11
Training loss: 4.277620879649651
Validation loss: 3.432773043509992

Epoch: 6| Step: 12
Training loss: 3.076574874395823
Validation loss: 3.38111043698929

Epoch: 6| Step: 13
Training loss: 2.8472684117320703
Validation loss: 3.3985471714132665

Epoch: 27| Step: 0
Training loss: 3.526542023281131
Validation loss: 3.3371909313329975

Epoch: 6| Step: 1
Training loss: 3.798995316854243
Validation loss: 3.336864633377842

Epoch: 6| Step: 2
Training loss: 3.2310517418135487
Validation loss: 3.332333368366915

Epoch: 6| Step: 3
Training loss: 3.0657768624087054
Validation loss: 3.3067750632767856

Epoch: 6| Step: 4
Training loss: 3.797306365952299
Validation loss: 3.2963081879219684

Epoch: 6| Step: 5
Training loss: 3.024561788802177
Validation loss: 3.2702982140628603

Epoch: 6| Step: 6
Training loss: 3.2977084150528606
Validation loss: 3.217679374642407

Epoch: 6| Step: 7
Training loss: 4.350578374888208
Validation loss: 3.2190924260320686

Epoch: 6| Step: 8
Training loss: 2.2746088215642035
Validation loss: 3.1933936818278803

Epoch: 6| Step: 9
Training loss: 3.4194536395086605
Validation loss: 3.214365048625003

Epoch: 6| Step: 10
Training loss: 2.982093777999151
Validation loss: 3.1926476021917662

Epoch: 6| Step: 11
Training loss: 3.0505864939636314
Validation loss: 3.173979611349378

Epoch: 6| Step: 12
Training loss: 3.5041978729588203
Validation loss: 3.147101341432131

Epoch: 6| Step: 13
Training loss: 3.088736739707157
Validation loss: 3.1325818089589483

Epoch: 28| Step: 0
Training loss: 3.4200819360387773
Validation loss: 3.1820989053969098

Epoch: 6| Step: 1
Training loss: 3.068104500872075
Validation loss: 3.107035129529876

Epoch: 6| Step: 2
Training loss: 3.007562641813732
Validation loss: 3.0837457797282815

Epoch: 6| Step: 3
Training loss: 3.83967287259666
Validation loss: 3.03178800682625

Epoch: 6| Step: 4
Training loss: 3.080766038628319
Validation loss: 3.0227642763455487

Epoch: 6| Step: 5
Training loss: 3.3454117968244255
Validation loss: 3.032426174381671

Epoch: 6| Step: 6
Training loss: 2.1874676293294066
Validation loss: 3.043181544609655

Epoch: 6| Step: 7
Training loss: 2.9941907904615994
Validation loss: 3.0415134489672933

Epoch: 6| Step: 8
Training loss: 3.385045677789689
Validation loss: 3.047562056897062

Epoch: 6| Step: 9
Training loss: 3.6402072912445496
Validation loss: 3.0249338604333995

Epoch: 6| Step: 10
Training loss: 2.0239985214800957
Validation loss: 2.9336962119088077

Epoch: 6| Step: 11
Training loss: 2.859494066104512
Validation loss: 2.8962593629859104

Epoch: 6| Step: 12
Training loss: 3.3396609964619257
Validation loss: 2.9322897356754405

Epoch: 6| Step: 13
Training loss: 3.0383036237203336
Validation loss: 2.8675405830279206

Epoch: 29| Step: 0
Training loss: 3.4694944390498246
Validation loss: 2.986539856437799

Epoch: 6| Step: 1
Training loss: 3.715625636531432
Validation loss: 2.915967830022328

Epoch: 6| Step: 2
Training loss: 2.969396099255689
Validation loss: 2.923336600326157

Epoch: 6| Step: 3
Training loss: 3.1505062604707876
Validation loss: 2.9868761897010216

Epoch: 6| Step: 4
Training loss: 3.0607000238385487
Validation loss: 2.866964073939153

Epoch: 6| Step: 5
Training loss: 3.143946167909665
Validation loss: 2.9091410649329212

Epoch: 6| Step: 6
Training loss: 3.3361539033475793
Validation loss: 2.854474104947779

Epoch: 6| Step: 7
Training loss: 3.5961717489809835
Validation loss: 2.8998687671307524

Epoch: 6| Step: 8
Training loss: 2.930850517852387
Validation loss: 2.8729348882541275

Epoch: 6| Step: 9
Training loss: 2.93657588626465
Validation loss: 2.928305624304085

Epoch: 6| Step: 10
Training loss: 3.1433239627292586
Validation loss: 2.867910571081473

Epoch: 6| Step: 11
Training loss: 2.357868648439403
Validation loss: 2.826969996614628

Epoch: 6| Step: 12
Training loss: 2.2082452456581727
Validation loss: 2.80396101131843

Epoch: 6| Step: 13
Training loss: 3.0285227983739853
Validation loss: 2.847574874930817

Epoch: 30| Step: 0
Training loss: 3.0679809414645884
Validation loss: 2.7979830212283643

Epoch: 6| Step: 1
Training loss: 3.9111614631051115
Validation loss: 2.7756405524646093

Epoch: 6| Step: 2
Training loss: 2.3890862592834265
Validation loss: 2.874952400601748

Epoch: 6| Step: 3
Training loss: 3.032764803527571
Validation loss: 2.851999002363437

Epoch: 6| Step: 4
Training loss: 2.6418768268666426
Validation loss: 2.7516013821754255

Epoch: 6| Step: 5
Training loss: 2.7673241519627103
Validation loss: 2.8476200663844216

Epoch: 6| Step: 6
Training loss: 3.3378697679826717
Validation loss: 2.786245681396533

Epoch: 6| Step: 7
Training loss: 3.122819673958849
Validation loss: 2.7949262805457784

Epoch: 6| Step: 8
Training loss: 3.422368819604682
Validation loss: 2.839300889560425

Epoch: 6| Step: 9
Training loss: 3.6344087764780966
Validation loss: 2.859694200103097

Epoch: 6| Step: 10
Training loss: 2.8597461897261653
Validation loss: 2.756779739919338

Epoch: 6| Step: 11
Training loss: 3.585884309926868
Validation loss: 2.800860911915324

Epoch: 6| Step: 12
Training loss: 2.4775966085773495
Validation loss: 2.781472463952452

Epoch: 6| Step: 13
Training loss: 2.5024459317794445
Validation loss: 2.810966485630741

Epoch: 31| Step: 0
Training loss: 3.3814978038076204
Validation loss: 2.8504046521479998

Epoch: 6| Step: 1
Training loss: 3.0180312918221985
Validation loss: 2.7843519322349324

Epoch: 6| Step: 2
Training loss: 3.3287742590369436
Validation loss: 2.7620763911318598

Epoch: 6| Step: 3
Training loss: 3.455694976997804
Validation loss: 2.834096314222984

Epoch: 6| Step: 4
Training loss: 2.7572118521104274
Validation loss: 2.8222788398286536

Epoch: 6| Step: 5
Training loss: 3.050608533593246
Validation loss: 2.7651406252086264

Epoch: 6| Step: 6
Training loss: 2.786087971729942
Validation loss: 2.740394862931092

Epoch: 6| Step: 7
Training loss: 2.418574292801907
Validation loss: 2.8027473251891393

Epoch: 6| Step: 8
Training loss: 3.353779804041855
Validation loss: 2.7916357736312296

Epoch: 6| Step: 9
Training loss: 2.4772004951337347
Validation loss: 2.7604920924711793

Epoch: 6| Step: 10
Training loss: 2.625724510844225
Validation loss: 2.800290507453645

Epoch: 6| Step: 11
Training loss: 3.0799850807819436
Validation loss: 2.8319880348786723

Epoch: 6| Step: 12
Training loss: 3.4307929062857045
Validation loss: 2.7421236052091205

Epoch: 6| Step: 13
Training loss: 2.499315740403171
Validation loss: 2.832635953542681

Epoch: 32| Step: 0
Training loss: 2.1363964779246083
Validation loss: 2.7337242690521775

Epoch: 6| Step: 1
Training loss: 3.886818613274244
Validation loss: 2.7945426785211693

Epoch: 6| Step: 2
Training loss: 3.5269381774727555
Validation loss: 2.791648199515926

Epoch: 6| Step: 3
Training loss: 2.7858059033150218
Validation loss: 2.812223661968809

Epoch: 6| Step: 4
Training loss: 2.9889253607805086
Validation loss: 2.782499448646852

Epoch: 6| Step: 5
Training loss: 3.3071980781029153
Validation loss: 2.739318594993834

Epoch: 6| Step: 6
Training loss: 2.8258895891222764
Validation loss: 2.732330549902175

Epoch: 6| Step: 7
Training loss: 3.305835858026657
Validation loss: 2.812563887477809

Epoch: 6| Step: 8
Training loss: 2.8418764083586994
Validation loss: 2.7196044927471994

Epoch: 6| Step: 9
Training loss: 2.849542440526431
Validation loss: 2.8052459891075987

Epoch: 6| Step: 10
Training loss: 3.1390679138653383
Validation loss: 2.7274615883963125

Epoch: 6| Step: 11
Training loss: 2.7394578177317928
Validation loss: 2.7427007153254697

Epoch: 6| Step: 12
Training loss: 3.1691397162057275
Validation loss: 2.719791319015373

Epoch: 6| Step: 13
Training loss: 2.1470333435212736
Validation loss: 2.710462306725012

Epoch: 33| Step: 0
Training loss: 2.7941299692124333
Validation loss: 2.7272121422869406

Epoch: 6| Step: 1
Training loss: 2.523983167105524
Validation loss: 2.7459693121630417

Epoch: 6| Step: 2
Training loss: 3.2534582372306255
Validation loss: 2.7190361999132615

Epoch: 6| Step: 3
Training loss: 2.43651932771447
Validation loss: 2.6816315793402725

Epoch: 6| Step: 4
Training loss: 2.7912262716279863
Validation loss: 2.7106602298738087

Epoch: 6| Step: 5
Training loss: 3.2925661684887904
Validation loss: 2.7260413345959336

Epoch: 6| Step: 6
Training loss: 1.8035575995663717
Validation loss: 2.712014619601166

Epoch: 6| Step: 7
Training loss: 2.5927727018595945
Validation loss: 2.8037001935838637

Epoch: 6| Step: 8
Training loss: 3.694379563745846
Validation loss: 2.808461303682357

Epoch: 6| Step: 9
Training loss: 2.9693272079703785
Validation loss: 2.7923115674287837

Epoch: 6| Step: 10
Training loss: 3.8599032762495424
Validation loss: 2.764563688989869

Epoch: 6| Step: 11
Training loss: 2.9124671312040995
Validation loss: 2.7466989647113946

Epoch: 6| Step: 12
Training loss: 3.5340552876006157
Validation loss: 2.776085168450365

Epoch: 6| Step: 13
Training loss: 3.538726992840561
Validation loss: 2.7145861436392087

Epoch: 34| Step: 0
Training loss: 2.7904744995133144
Validation loss: 2.797021204471024

Epoch: 6| Step: 1
Training loss: 2.8335771642745917
Validation loss: 2.7479559898820365

Epoch: 6| Step: 2
Training loss: 2.335179847146268
Validation loss: 2.7697530363440968

Epoch: 6| Step: 3
Training loss: 3.233143742564349
Validation loss: 2.761189741904158

Epoch: 6| Step: 4
Training loss: 3.7115878850292496
Validation loss: 2.6898120856211287

Epoch: 6| Step: 5
Training loss: 3.587361636799891
Validation loss: 2.8154620288742187

Epoch: 6| Step: 6
Training loss: 3.432631217743375
Validation loss: 2.7508279853475535

Epoch: 6| Step: 7
Training loss: 3.073895021719711
Validation loss: 2.7206763002866663

Epoch: 6| Step: 8
Training loss: 2.964569199707768
Validation loss: 2.735636935523436

Epoch: 6| Step: 9
Training loss: 2.983115524638193
Validation loss: 2.7972924420569623

Epoch: 6| Step: 10
Training loss: 2.3059030204621815
Validation loss: 2.677053431659988

Epoch: 6| Step: 11
Training loss: 2.7389993855091643
Validation loss: 2.7545210413386916

Epoch: 6| Step: 12
Training loss: 2.9965488928655883
Validation loss: 2.743481802508713

Epoch: 6| Step: 13
Training loss: 3.0395113655200383
Validation loss: 2.8497900902258766

Epoch: 35| Step: 0
Training loss: 2.6445770485094453
Validation loss: 2.7742024017568556

Epoch: 6| Step: 1
Training loss: 3.3854219094260287
Validation loss: 2.682670512666245

Epoch: 6| Step: 2
Training loss: 2.4425971704713865
Validation loss: 2.787848551519055

Epoch: 6| Step: 3
Training loss: 3.2065365371418864
Validation loss: 2.6952631102452638

Epoch: 6| Step: 4
Training loss: 3.015384486593666
Validation loss: 2.7848363937548832

Epoch: 6| Step: 5
Training loss: 3.008036657130303
Validation loss: 2.7421447294344956

Epoch: 6| Step: 6
Training loss: 2.5878942180104776
Validation loss: 2.684956814644407

Epoch: 6| Step: 7
Training loss: 2.879871387788885
Validation loss: 2.810993366201248

Epoch: 6| Step: 8
Training loss: 2.7238253870383664
Validation loss: 2.7685818492903085

Epoch: 6| Step: 9
Training loss: 2.566095388505212
Validation loss: 2.770485585926663

Epoch: 6| Step: 10
Training loss: 3.6226944003915
Validation loss: 2.7684752470168963

Epoch: 6| Step: 11
Training loss: 3.4677160973240913
Validation loss: 2.71741410814145

Epoch: 6| Step: 12
Training loss: 3.4042139530204993
Validation loss: 2.7501906508792624

Epoch: 6| Step: 13
Training loss: 2.9923121174890297
Validation loss: 2.780346509709578

Epoch: 36| Step: 0
Training loss: 2.602759833213516
Validation loss: 2.7582126622140613

Epoch: 6| Step: 1
Training loss: 2.511798009022354
Validation loss: 2.72417859509803

Epoch: 6| Step: 2
Training loss: 3.614930076714305
Validation loss: 2.770208138499939

Epoch: 6| Step: 3
Training loss: 3.0990225819998662
Validation loss: 2.7437304889225267

Epoch: 6| Step: 4
Training loss: 3.280266023873358
Validation loss: 2.772831196469043

Epoch: 6| Step: 5
Training loss: 3.420895231541104
Validation loss: 2.765411065560778

Epoch: 6| Step: 6
Training loss: 3.15183213252641
Validation loss: 2.74013002679478

Epoch: 6| Step: 7
Training loss: 2.543135255205576
Validation loss: 2.6999730275742704

Epoch: 6| Step: 8
Training loss: 2.972347930278003
Validation loss: 2.7472189025096823

Epoch: 6| Step: 9
Training loss: 2.745878599157478
Validation loss: 2.7552722683351116

Epoch: 6| Step: 10
Training loss: 2.724776505570697
Validation loss: 2.7791973308311744

Epoch: 6| Step: 11
Training loss: 3.0463752532366586
Validation loss: 2.6792397317664545

Epoch: 6| Step: 12
Training loss: 2.9825062917817253
Validation loss: 2.7440945972910136

Epoch: 6| Step: 13
Training loss: 2.8989359383375413
Validation loss: 2.7166188394629693

Epoch: 37| Step: 0
Training loss: 3.2062166505979115
Validation loss: 2.7344679424938447

Epoch: 6| Step: 1
Training loss: 3.2861538527836824
Validation loss: 2.7646211563894605

Epoch: 6| Step: 2
Training loss: 2.7100186508494106
Validation loss: 2.785243262098873

Epoch: 6| Step: 3
Training loss: 2.486023170246595
Validation loss: 2.7309066090656677

Epoch: 6| Step: 4
Training loss: 3.174452612841199
Validation loss: 2.8134400896499256

Epoch: 6| Step: 5
Training loss: 2.3038086330757754
Validation loss: 2.7753829369973206

Epoch: 6| Step: 6
Training loss: 3.2084248682481054
Validation loss: 2.7392552388046627

Epoch: 6| Step: 7
Training loss: 1.987467841122122
Validation loss: 2.75087639239117

Epoch: 6| Step: 8
Training loss: 3.978538756567819
Validation loss: 2.717505560946031

Epoch: 6| Step: 9
Training loss: 3.187959376125374
Validation loss: 2.732315276838343

Epoch: 6| Step: 10
Training loss: 3.214364035726944
Validation loss: 2.720044342909509

Epoch: 6| Step: 11
Training loss: 2.9846127400397884
Validation loss: 2.753565681348448

Epoch: 6| Step: 12
Training loss: 2.792247673799439
Validation loss: 2.8111679568834917

Epoch: 6| Step: 13
Training loss: 3.358950849858863
Validation loss: 2.721351685630553

Epoch: 38| Step: 0
Training loss: 3.593165209086217
Validation loss: 2.7570382102942816

Epoch: 6| Step: 1
Training loss: 2.9471782572786096
Validation loss: 2.7371971162471675

Epoch: 6| Step: 2
Training loss: 2.9800079509449824
Validation loss: 2.798365305152903

Epoch: 6| Step: 3
Training loss: 3.2093497478676554
Validation loss: 2.741171504518117

Epoch: 6| Step: 4
Training loss: 2.6161506079153583
Validation loss: 2.7607894716918575

Epoch: 6| Step: 5
Training loss: 2.988614411575073
Validation loss: 2.7836350311055544

Epoch: 6| Step: 6
Training loss: 2.8810207515712007
Validation loss: 2.758868151870597

Epoch: 6| Step: 7
Training loss: 3.1942754802154836
Validation loss: 2.71296533731119

Epoch: 6| Step: 8
Training loss: 2.322466226420477
Validation loss: 2.797062391670771

Epoch: 6| Step: 9
Training loss: 2.562884604271525
Validation loss: 2.7210661522820048

Epoch: 6| Step: 10
Training loss: 2.63708276567128
Validation loss: 2.7473244157046866

Epoch: 6| Step: 11
Training loss: 2.9090172503639504
Validation loss: 2.8023805531940416

Epoch: 6| Step: 12
Training loss: 3.960655789260897
Validation loss: 2.7372120511240916

Epoch: 6| Step: 13
Training loss: 2.5975737365008214
Validation loss: 2.8092681665155896

Epoch: 39| Step: 0
Training loss: 3.387699112899641
Validation loss: 2.7380068350398106

Epoch: 6| Step: 1
Training loss: 2.529800942170517
Validation loss: 2.7207096879121115

Epoch: 6| Step: 2
Training loss: 3.0889108747009364
Validation loss: 2.730986983722363

Epoch: 6| Step: 3
Training loss: 3.6140893310923063
Validation loss: 2.762334643394616

Epoch: 6| Step: 4
Training loss: 3.0352093509069533
Validation loss: 2.8037571651297384

Epoch: 6| Step: 5
Training loss: 3.4969651825076697
Validation loss: 2.7546124944072266

Epoch: 6| Step: 6
Training loss: 2.6822300184751637
Validation loss: 2.7110096779201176

Epoch: 6| Step: 7
Training loss: 2.786747674388194
Validation loss: 2.751381772583226

Epoch: 6| Step: 8
Training loss: 2.7597407443145956
Validation loss: 2.7206648195149907

Epoch: 6| Step: 9
Training loss: 2.6225280021285267
Validation loss: 2.713024270920378

Epoch: 6| Step: 10
Training loss: 3.2228377967329185
Validation loss: 2.6861178542117043

Epoch: 6| Step: 11
Training loss: 3.4345101965967935
Validation loss: 2.7907373212706537

Epoch: 6| Step: 12
Training loss: 2.574856344863882
Validation loss: 2.747577125684817

Epoch: 6| Step: 13
Training loss: 2.4148781395410013
Validation loss: 2.7395231054030167

Epoch: 40| Step: 0
Training loss: 3.466932765822605
Validation loss: 2.765323075293634

Epoch: 6| Step: 1
Training loss: 2.882758907657339
Validation loss: 2.7912246652341204

Epoch: 6| Step: 2
Training loss: 2.8764182200139503
Validation loss: 2.7586027724297164

Epoch: 6| Step: 3
Training loss: 3.7264294230693795
Validation loss: 2.779515140940162

Epoch: 6| Step: 4
Training loss: 3.002563017502258
Validation loss: 2.7741662368648647

Epoch: 6| Step: 5
Training loss: 2.0879040995092564
Validation loss: 2.7813460916564305

Epoch: 6| Step: 6
Training loss: 2.720264144721855
Validation loss: 2.7105038057103186

Epoch: 6| Step: 7
Training loss: 3.504731114150573
Validation loss: 2.7280803695610434

Epoch: 6| Step: 8
Training loss: 3.2424931025964794
Validation loss: 2.7706164443936934

Epoch: 6| Step: 9
Training loss: 2.944835998683639
Validation loss: 2.7553255332405704

Epoch: 6| Step: 10
Training loss: 2.7095298960406105
Validation loss: 2.7534892188636366

Epoch: 6| Step: 11
Training loss: 3.2385043261806703
Validation loss: 2.796131397472435

Epoch: 6| Step: 12
Training loss: 2.66172083526252
Validation loss: 2.687366605339917

Epoch: 6| Step: 13
Training loss: 2.9745229707267935
Validation loss: 2.806076182696062

Epoch: 41| Step: 0
Training loss: 2.912714505789458
Validation loss: 2.804363954060211

Epoch: 6| Step: 1
Training loss: 2.8825693415616445
Validation loss: 2.8016355212883703

Epoch: 6| Step: 2
Training loss: 2.907937821071114
Validation loss: 2.779179942797365

Epoch: 6| Step: 3
Training loss: 2.987715364618187
Validation loss: 2.7951859129702914

Epoch: 6| Step: 4
Training loss: 2.33711299854516
Validation loss: 2.7458727751537335

Epoch: 6| Step: 5
Training loss: 3.2678171493381925
Validation loss: 2.7622133141047422

Epoch: 6| Step: 6
Training loss: 3.409471161182917
Validation loss: 2.774272965140842

Epoch: 6| Step: 7
Training loss: 3.077139604725898
Validation loss: 2.7463286663492745

Epoch: 6| Step: 8
Training loss: 3.262535422414188
Validation loss: 2.726174440208102

Epoch: 6| Step: 9
Training loss: 2.9963046202377854
Validation loss: 2.7254364323858544

Epoch: 6| Step: 10
Training loss: 3.4306553059506095
Validation loss: 2.811384458819437

Epoch: 6| Step: 11
Training loss: 2.8067980292772297
Validation loss: 2.7781761339782016

Epoch: 6| Step: 12
Training loss: 2.6520569861202823
Validation loss: 2.7253850779394724

Epoch: 6| Step: 13
Training loss: 2.755725362589192
Validation loss: 2.762370238372099

Epoch: 42| Step: 0
Training loss: 3.10610130153705
Validation loss: 2.7396509343186715

Epoch: 6| Step: 1
Training loss: 3.4834727671579766
Validation loss: 2.7469356631849

Epoch: 6| Step: 2
Training loss: 3.033572536161501
Validation loss: 2.7197754024404004

Epoch: 6| Step: 3
Training loss: 2.9590554408235876
Validation loss: 2.796954544026102

Epoch: 6| Step: 4
Training loss: 3.503495106130334
Validation loss: 2.7809464751175303

Epoch: 6| Step: 5
Training loss: 2.4429929414288813
Validation loss: 2.715651512066142

Epoch: 6| Step: 6
Training loss: 2.957953809293688
Validation loss: 2.739272939228486

Epoch: 6| Step: 7
Training loss: 2.895593281042548
Validation loss: 2.7446865869506922

Epoch: 6| Step: 8
Training loss: 2.639407808468926
Validation loss: 2.7834183804528556

Epoch: 6| Step: 9
Training loss: 3.8586617864838457
Validation loss: 2.753090554660056

Epoch: 6| Step: 10
Training loss: 3.094056855984383
Validation loss: 2.7292131239797595

Epoch: 6| Step: 11
Training loss: 2.842272699640394
Validation loss: 2.7840968383221227

Epoch: 6| Step: 12
Training loss: 2.3253071776889116
Validation loss: 2.7505369100419235

Epoch: 6| Step: 13
Training loss: 2.429663556830379
Validation loss: 2.7504056359165427

Epoch: 43| Step: 0
Training loss: 1.7451160262263554
Validation loss: 2.7033027658284157

Epoch: 6| Step: 1
Training loss: 2.5379241739163185
Validation loss: 2.6634326488926967

Epoch: 6| Step: 2
Training loss: 3.6461652913420024
Validation loss: 2.791320653222098

Epoch: 6| Step: 3
Training loss: 2.453674546421069
Validation loss: 2.6723783036154014

Epoch: 6| Step: 4
Training loss: 3.5752990757613743
Validation loss: 2.751630324054289

Epoch: 6| Step: 5
Training loss: 2.7071971759889633
Validation loss: 2.725833370222421

Epoch: 6| Step: 6
Training loss: 3.8354148741798557
Validation loss: 2.814635989975399

Epoch: 6| Step: 7
Training loss: 2.753631534807459
Validation loss: 2.7787486441558946

Epoch: 6| Step: 8
Training loss: 3.5687292415730005
Validation loss: 2.7656941832499595

Epoch: 6| Step: 9
Training loss: 2.3168341770491194
Validation loss: 2.716223570103014

Epoch: 6| Step: 10
Training loss: 2.59632185313562
Validation loss: 2.764413304805683

Epoch: 6| Step: 11
Training loss: 2.8983792610178267
Validation loss: 2.7366280166792265

Epoch: 6| Step: 12
Training loss: 3.2820036976181486
Validation loss: 2.7575589960274463

Epoch: 6| Step: 13
Training loss: 2.1480355181465782
Validation loss: 2.770732326055899

Epoch: 44| Step: 0
Training loss: 3.0738798194578485
Validation loss: 2.8054295163667766

Epoch: 6| Step: 1
Training loss: 1.9474140137480738
Validation loss: 2.7372543855220486

Epoch: 6| Step: 2
Training loss: 2.2612187124336747
Validation loss: 2.8194175956828857

Epoch: 6| Step: 3
Training loss: 3.5888026142149956
Validation loss: 2.7223135423135467

Epoch: 6| Step: 4
Training loss: 3.009837076080421
Validation loss: 2.7936179969957666

Epoch: 6| Step: 5
Training loss: 2.8611998024766434
Validation loss: 2.6741981541240305

Epoch: 6| Step: 6
Training loss: 2.4335059675179167
Validation loss: 2.749366567976064

Epoch: 6| Step: 7
Training loss: 3.1926786951345747
Validation loss: 2.8111598104349937

Epoch: 6| Step: 8
Training loss: 3.435016914337137
Validation loss: 2.762881831396919

Epoch: 6| Step: 9
Training loss: 3.2637127840045315
Validation loss: 2.7212141857167995

Epoch: 6| Step: 10
Training loss: 2.564471904979312
Validation loss: 2.7139379404762294

Epoch: 6| Step: 11
Training loss: 2.2348798701625143
Validation loss: 2.745796496182961

Epoch: 6| Step: 12
Training loss: 3.5859113039875816
Validation loss: 2.7156611835764317

Epoch: 6| Step: 13
Training loss: 4.086491796995214
Validation loss: 2.7996509200358703

Epoch: 45| Step: 0
Training loss: 2.6879468147204606
Validation loss: 2.7746017302548163

Epoch: 6| Step: 1
Training loss: 3.015621837555013
Validation loss: 2.7262513659897634

Epoch: 6| Step: 2
Training loss: 2.6166181713720937
Validation loss: 2.8083354776376144

Epoch: 6| Step: 3
Training loss: 2.984010843957828
Validation loss: 2.7466699979379396

Epoch: 6| Step: 4
Training loss: 3.041777273457615
Validation loss: 2.773560155490013

Epoch: 6| Step: 5
Training loss: 3.4003390199271974
Validation loss: 2.7897277169252694

Epoch: 6| Step: 6
Training loss: 2.4474015255250485
Validation loss: 2.7266738332460725

Epoch: 6| Step: 7
Training loss: 3.218123587976421
Validation loss: 2.808470734999974

Epoch: 6| Step: 8
Training loss: 3.047417695058276
Validation loss: 2.801794044891336

Epoch: 6| Step: 9
Training loss: 3.44971833115851
Validation loss: 2.826068163539815

Epoch: 6| Step: 10
Training loss: 3.302522712300218
Validation loss: 2.7758206915576698

Epoch: 6| Step: 11
Training loss: 2.884630906478985
Validation loss: 2.7445292531379133

Epoch: 6| Step: 12
Training loss: 2.5055716417035425
Validation loss: 2.7138378136097296

Epoch: 6| Step: 13
Training loss: 2.4020154278948183
Validation loss: 2.7555343912949066

Epoch: 46| Step: 0
Training loss: 3.1205359045138166
Validation loss: 2.734935183473833

Epoch: 6| Step: 1
Training loss: 3.122588791451421
Validation loss: 2.80595174441813

Epoch: 6| Step: 2
Training loss: 3.7276632734495494
Validation loss: 2.736480462950504

Epoch: 6| Step: 3
Training loss: 2.7204185714944824
Validation loss: 2.7779279232123004

Epoch: 6| Step: 4
Training loss: 2.58732443319846
Validation loss: 2.6669244186621466

Epoch: 6| Step: 5
Training loss: 2.4062289943025914
Validation loss: 2.7982984660140398

Epoch: 6| Step: 6
Training loss: 2.549619448071922
Validation loss: 2.722303856768355

Epoch: 6| Step: 7
Training loss: 3.110887322627104
Validation loss: 2.669510869184119

Epoch: 6| Step: 8
Training loss: 2.431402649782103
Validation loss: 2.6856260660825337

Epoch: 6| Step: 9
Training loss: 3.416918784042958
Validation loss: 2.7838703535185245

Epoch: 6| Step: 10
Training loss: 2.136074715304119
Validation loss: 2.717764626240877

Epoch: 6| Step: 11
Training loss: 2.974242901033906
Validation loss: 2.776430421657035

Epoch: 6| Step: 12
Training loss: 3.0091313628924654
Validation loss: 2.7263267465235304

Epoch: 6| Step: 13
Training loss: 4.139936742621819
Validation loss: 2.7518153700994774

Epoch: 47| Step: 0
Training loss: 3.1249655149464437
Validation loss: 2.809183485567805

Epoch: 6| Step: 1
Training loss: 2.894158260802995
Validation loss: 2.818941530931394

Epoch: 6| Step: 2
Training loss: 2.709600993128263
Validation loss: 2.7851185566768994

Epoch: 6| Step: 3
Training loss: 2.967177446377452
Validation loss: 2.725708925398446

Epoch: 6| Step: 4
Training loss: 2.624500136238977
Validation loss: 2.774575465442526

Epoch: 6| Step: 5
Training loss: 2.4124639953140283
Validation loss: 2.7823851885235187

Epoch: 6| Step: 6
Training loss: 2.978228886044264
Validation loss: 2.7515515977793834

Epoch: 6| Step: 7
Training loss: 2.9061522108464004
Validation loss: 2.727176105348263

Epoch: 6| Step: 8
Training loss: 2.694316646870504
Validation loss: 2.748076689246391

Epoch: 6| Step: 9
Training loss: 2.587782740233545
Validation loss: 2.738558149094895

Epoch: 6| Step: 10
Training loss: 3.6606745887225545
Validation loss: 2.8129864753926546

Epoch: 6| Step: 11
Training loss: 3.3644682841910023
Validation loss: 2.7672698923618

Epoch: 6| Step: 12
Training loss: 3.1754821411264906
Validation loss: 2.7198978575662442

Epoch: 6| Step: 13
Training loss: 3.4205882819094056
Validation loss: 2.7487813798245995

Epoch: 48| Step: 0
Training loss: 3.1804051444642347
Validation loss: 2.6771416188343053

Epoch: 6| Step: 1
Training loss: 3.206769256484017
Validation loss: 2.7543939369688597

Epoch: 6| Step: 2
Training loss: 3.3755800667060414
Validation loss: 2.7028808796488564

Epoch: 6| Step: 3
Training loss: 2.910999641840397
Validation loss: 2.7713365837205255

Epoch: 6| Step: 4
Training loss: 4.101937064370163
Validation loss: 2.6862125961894123

Epoch: 6| Step: 5
Training loss: 3.23843026364777
Validation loss: 2.707675180538596

Epoch: 6| Step: 6
Training loss: 2.648616638426761
Validation loss: 2.775158710998215

Epoch: 6| Step: 7
Training loss: 2.944220464412678
Validation loss: 2.7610634477708813

Epoch: 6| Step: 8
Training loss: 2.855337492173888
Validation loss: 2.731825369465678

Epoch: 6| Step: 9
Training loss: 3.178020668380296
Validation loss: 2.757977625932935

Epoch: 6| Step: 10
Training loss: 2.3573880955662934
Validation loss: 2.70386565398639

Epoch: 6| Step: 11
Training loss: 2.2754227926575448
Validation loss: 2.698030744402269

Epoch: 6| Step: 12
Training loss: 2.7917500004263225
Validation loss: 2.8091214103193956

Epoch: 6| Step: 13
Training loss: 2.1690255553453515
Validation loss: 2.6786132025207996

Epoch: 49| Step: 0
Training loss: 3.0541290787434745
Validation loss: 2.788484815889506

Epoch: 6| Step: 1
Training loss: 2.186469134891236
Validation loss: 2.8546248995457377

Epoch: 6| Step: 2
Training loss: 3.390134011154489
Validation loss: 2.7409670506934507

Epoch: 6| Step: 3
Training loss: 3.00232638121521
Validation loss: 2.7846785987498532

Epoch: 6| Step: 4
Training loss: 3.4118294472770954
Validation loss: 2.7369039224723752

Epoch: 6| Step: 5
Training loss: 2.962349507175197
Validation loss: 2.782492066824718

Epoch: 6| Step: 6
Training loss: 3.3212688190815745
Validation loss: 2.7677247859345977

Epoch: 6| Step: 7
Training loss: 3.086636621014529
Validation loss: 2.7521053358198015

Epoch: 6| Step: 8
Training loss: 3.019357693558819
Validation loss: 2.7329288991442557

Epoch: 6| Step: 9
Training loss: 3.105846914622141
Validation loss: 2.7882339535083815

Epoch: 6| Step: 10
Training loss: 3.2192373554929086
Validation loss: 2.79456394316826

Epoch: 6| Step: 11
Training loss: 2.5122720871223096
Validation loss: 2.668345282256943

Epoch: 6| Step: 12
Training loss: 2.541125964408728
Validation loss: 2.7363016933092004

Epoch: 6| Step: 13
Training loss: 3.0183204108273514
Validation loss: 2.7206116816813646

Epoch: 50| Step: 0
Training loss: 2.8825458517009235
Validation loss: 2.787924346600111

Epoch: 6| Step: 1
Training loss: 3.4257923852441605
Validation loss: 2.7663360732758027

Epoch: 6| Step: 2
Training loss: 3.5248376470743192
Validation loss: 2.7334404604988327

Epoch: 6| Step: 3
Training loss: 2.414177555441098
Validation loss: 2.772874690065308

Epoch: 6| Step: 4
Training loss: 2.630568093853289
Validation loss: 2.7190622874778425

Epoch: 6| Step: 5
Training loss: 3.2735412144220106
Validation loss: 2.745584007462444

Epoch: 6| Step: 6
Training loss: 2.5513995649427854
Validation loss: 2.686446822725641

Epoch: 6| Step: 7
Training loss: 3.023073475138172
Validation loss: 2.7447654615615615

Epoch: 6| Step: 8
Training loss: 2.429668070724667
Validation loss: 2.805964037469591

Epoch: 6| Step: 9
Training loss: 2.359051410640394
Validation loss: 2.746169972170382

Epoch: 6| Step: 10
Training loss: 3.2997981847838416
Validation loss: 2.723952312192641

Epoch: 6| Step: 11
Training loss: 3.4845014472221645
Validation loss: 2.7011566668255154

Epoch: 6| Step: 12
Training loss: 3.2315717702949724
Validation loss: 2.595731049605375

Epoch: 6| Step: 13
Training loss: 3.3384091514120082
Validation loss: 2.7181122658590278

Testing loss: 2.875575180383085
