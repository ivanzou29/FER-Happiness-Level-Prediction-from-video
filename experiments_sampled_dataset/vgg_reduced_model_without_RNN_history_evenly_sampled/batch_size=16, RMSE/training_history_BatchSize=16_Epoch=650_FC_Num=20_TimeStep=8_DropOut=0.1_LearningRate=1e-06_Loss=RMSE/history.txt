Epoch: 1| Step: 0
Training loss: 7.5021438077823115
Validation loss: 7.058672568522454

Epoch: 6| Step: 1
Training loss: 6.070066469133371
Validation loss: 7.054172488939577

Epoch: 6| Step: 2
Training loss: 6.735213296142242
Validation loss: 7.048857939397026

Epoch: 6| Step: 3
Training loss: 6.434199403698392
Validation loss: 7.040303031686476

Epoch: 6| Step: 4
Training loss: 7.562109566690555
Validation loss: 7.033685518253557

Epoch: 6| Step: 5
Training loss: 7.445382949479785
Validation loss: 7.030453461406285

Epoch: 6| Step: 6
Training loss: 7.0416635667542025
Validation loss: 7.025867261105248

Epoch: 6| Step: 7
Training loss: 6.989910483817181
Validation loss: 7.0193575192857445

Epoch: 6| Step: 8
Training loss: 6.799503914184027
Validation loss: 7.019733973736663

Epoch: 6| Step: 9
Training loss: 6.481563831997025
Validation loss: 7.014265113026086

Epoch: 6| Step: 10
Training loss: 7.730157615564809
Validation loss: 7.004910538289011

Epoch: 6| Step: 11
Training loss: 7.443359631248356
Validation loss: 6.997474466785262

Epoch: 6| Step: 12
Training loss: 7.082636121955946
Validation loss: 6.996871559727615

Epoch: 6| Step: 13
Training loss: 6.343063242152431
Validation loss: 6.988281660870331

Epoch: 2| Step: 0
Training loss: 7.568294102541113
Validation loss: 6.987057961378937

Epoch: 6| Step: 1
Training loss: 7.345190288449657
Validation loss: 6.9807465980112005

Epoch: 6| Step: 2
Training loss: 7.13237634936043
Validation loss: 6.977595831297665

Epoch: 6| Step: 3
Training loss: 7.18617143376696
Validation loss: 6.973015646092592

Epoch: 6| Step: 4
Training loss: 6.695628707344897
Validation loss: 6.964785371790324

Epoch: 6| Step: 5
Training loss: 6.927526504757748
Validation loss: 6.961225325601927

Epoch: 6| Step: 6
Training loss: 7.235612470937746
Validation loss: 6.955569097392229

Epoch: 6| Step: 7
Training loss: 6.68472717413195
Validation loss: 6.951935411015733

Epoch: 6| Step: 8
Training loss: 7.796796962676229
Validation loss: 6.947852651826933

Epoch: 6| Step: 9
Training loss: 6.7850443688602615
Validation loss: 6.942395502954551

Epoch: 6| Step: 10
Training loss: 5.78697852798837
Validation loss: 6.939445618182827

Epoch: 6| Step: 11
Training loss: 6.216867746709602
Validation loss: 6.931092476530343

Epoch: 6| Step: 12
Training loss: 7.04199211978661
Validation loss: 6.930024421912965

Epoch: 6| Step: 13
Training loss: 6.217154906926379
Validation loss: 6.917339265067612

Epoch: 3| Step: 0
Training loss: 6.510768187124666
Validation loss: 6.918514401743989

Epoch: 6| Step: 1
Training loss: 7.520081909626399
Validation loss: 6.911191212875165

Epoch: 6| Step: 2
Training loss: 7.161735464571556
Validation loss: 6.910208088340864

Epoch: 6| Step: 3
Training loss: 6.546244807172999
Validation loss: 6.904292618290615

Epoch: 6| Step: 4
Training loss: 6.980849637237207
Validation loss: 6.904553330214871

Epoch: 6| Step: 5
Training loss: 7.333434566608242
Validation loss: 6.8928487091232675

Epoch: 6| Step: 6
Training loss: 7.575204817517725
Validation loss: 6.8930592556062456

Epoch: 6| Step: 7
Training loss: 7.038496699652251
Validation loss: 6.885185782049119

Epoch: 6| Step: 8
Training loss: 6.334282184931442
Validation loss: 6.8784026733603225

Epoch: 6| Step: 9
Training loss: 7.025102292873877
Validation loss: 6.875401322778773

Epoch: 6| Step: 10
Training loss: 6.846673489090227
Validation loss: 6.870659719458306

Epoch: 6| Step: 11
Training loss: 6.347158033332529
Validation loss: 6.864176984934842

Epoch: 6| Step: 12
Training loss: 5.721561595390174
Validation loss: 6.858716906383367

Epoch: 6| Step: 13
Training loss: 7.206111264113346
Validation loss: 6.8530683966908414

Epoch: 4| Step: 0
Training loss: 6.251135761061557
Validation loss: 6.850465780466879

Epoch: 6| Step: 1
Training loss: 6.707608517491594
Validation loss: 6.845595555929555

Epoch: 6| Step: 2
Training loss: 7.024209800072154
Validation loss: 6.8416849728324225

Epoch: 6| Step: 3
Training loss: 6.921030100628705
Validation loss: 6.838814156876313

Epoch: 6| Step: 4
Training loss: 7.476313253012994
Validation loss: 6.827937679378124

Epoch: 6| Step: 5
Training loss: 7.601742404169303
Validation loss: 6.823679738293221

Epoch: 6| Step: 6
Training loss: 6.783065904349164
Validation loss: 6.8217516859774125

Epoch: 6| Step: 7
Training loss: 7.104072756626674
Validation loss: 6.813213896904499

Epoch: 6| Step: 8
Training loss: 5.977968456972535
Validation loss: 6.804834827294559

Epoch: 6| Step: 9
Training loss: 6.180915180082874
Validation loss: 6.800588679664951

Epoch: 6| Step: 10
Training loss: 6.853058637514273
Validation loss: 6.795414706577421

Epoch: 6| Step: 11
Training loss: 6.840583242791692
Validation loss: 6.789832663692886

Epoch: 6| Step: 12
Training loss: 6.617920457764866
Validation loss: 6.785559558731228

Epoch: 6| Step: 13
Training loss: 6.66650145643884
Validation loss: 6.776264757883332

Epoch: 5| Step: 0
Training loss: 6.455089057763057
Validation loss: 6.776242736217722

Epoch: 6| Step: 1
Training loss: 7.215516261970297
Validation loss: 6.76992518339857

Epoch: 6| Step: 2
Training loss: 6.718747445039485
Validation loss: 6.765096632476765

Epoch: 6| Step: 3
Training loss: 6.533591110956959
Validation loss: 6.756651282351124

Epoch: 6| Step: 4
Training loss: 7.807659144762967
Validation loss: 6.749978664399416

Epoch: 6| Step: 5
Training loss: 6.381418923468874
Validation loss: 6.743704779808801

Epoch: 6| Step: 6
Training loss: 6.414201964930932
Validation loss: 6.7411692442420375

Epoch: 6| Step: 7
Training loss: 6.204308384937066
Validation loss: 6.734827786669565

Epoch: 6| Step: 8
Training loss: 6.619543167440293
Validation loss: 6.727390346555573

Epoch: 6| Step: 9
Training loss: 7.39836660349149
Validation loss: 6.720516029776673

Epoch: 6| Step: 10
Training loss: 6.725102318194538
Validation loss: 6.7234010120789005

Epoch: 6| Step: 11
Training loss: 6.045610004754677
Validation loss: 6.705251055043596

Epoch: 6| Step: 12
Training loss: 6.360323298652271
Validation loss: 6.700407816499704

Epoch: 6| Step: 13
Training loss: 7.304130002539258
Validation loss: 6.699791918287371

Epoch: 6| Step: 0
Training loss: 7.104024965843802
Validation loss: 6.689287917496299

Epoch: 6| Step: 1
Training loss: 6.9513109905473724
Validation loss: 6.685462270890539

Epoch: 6| Step: 2
Training loss: 6.275241084235984
Validation loss: 6.676831363642899

Epoch: 6| Step: 3
Training loss: 6.768336785578683
Validation loss: 6.673661581095599

Epoch: 6| Step: 4
Training loss: 7.625945235901369
Validation loss: 6.664021149628578

Epoch: 6| Step: 5
Training loss: 5.652967649244793
Validation loss: 6.656983543061471

Epoch: 6| Step: 6
Training loss: 5.881281963914202
Validation loss: 6.650466762917193

Epoch: 6| Step: 7
Training loss: 7.534981590607955
Validation loss: 6.647417749161547

Epoch: 6| Step: 8
Training loss: 6.948877301546856
Validation loss: 6.640570547615339

Epoch: 6| Step: 9
Training loss: 6.155272120542656
Validation loss: 6.631491720372083

Epoch: 6| Step: 10
Training loss: 6.545680991022284
Validation loss: 6.61764403258213

Epoch: 6| Step: 11
Training loss: 7.181094292263192
Validation loss: 6.615942978946938

Epoch: 6| Step: 12
Training loss: 5.051582715377217
Validation loss: 6.610226867976422

Epoch: 6| Step: 13
Training loss: 6.7647755290004765
Validation loss: 6.594220463712043

Epoch: 7| Step: 0
Training loss: 6.534054386805816
Validation loss: 6.589475388329269

Epoch: 6| Step: 1
Training loss: 6.513432049089441
Validation loss: 6.5822638560291775

Epoch: 6| Step: 2
Training loss: 5.734094929936838
Validation loss: 6.574632496527057

Epoch: 6| Step: 3
Training loss: 6.335223100041144
Validation loss: 6.560692657345762

Epoch: 6| Step: 4
Training loss: 6.98899630390069
Validation loss: 6.5607737031012165

Epoch: 6| Step: 5
Training loss: 7.152775749856441
Validation loss: 6.553034077044482

Epoch: 6| Step: 6
Training loss: 5.214147125462771
Validation loss: 6.537062515543842

Epoch: 6| Step: 7
Training loss: 5.868387274862121
Validation loss: 6.5381933563751815

Epoch: 6| Step: 8
Training loss: 6.034706192765959
Validation loss: 6.527598142832259

Epoch: 6| Step: 9
Training loss: 6.615358930957593
Validation loss: 6.518777470198538

Epoch: 6| Step: 10
Training loss: 6.633998589567001
Validation loss: 6.51534310940473

Epoch: 6| Step: 11
Training loss: 6.353638707307652
Validation loss: 6.506040191474902

Epoch: 6| Step: 12
Training loss: 8.153082104500996
Validation loss: 6.500053998724424

Epoch: 6| Step: 13
Training loss: 7.011298461898921
Validation loss: 6.489268456174725

Epoch: 8| Step: 0
Training loss: 5.26821410145085
Validation loss: 6.47613167628347

Epoch: 6| Step: 1
Training loss: 6.446051094044419
Validation loss: 6.46393935680889

Epoch: 6| Step: 2
Training loss: 6.435288725380075
Validation loss: 6.460089826209202

Epoch: 6| Step: 3
Training loss: 5.964848546474005
Validation loss: 6.451025963920879

Epoch: 6| Step: 4
Training loss: 4.9365136815247315
Validation loss: 6.436854960080077

Epoch: 6| Step: 5
Training loss: 6.093370005179361
Validation loss: 6.430395360076843

Epoch: 6| Step: 6
Training loss: 6.8401097758446445
Validation loss: 6.425674595480536

Epoch: 6| Step: 7
Training loss: 6.889900290511003
Validation loss: 6.411958727128414

Epoch: 6| Step: 8
Training loss: 7.640283994339487
Validation loss: 6.40293503097949

Epoch: 6| Step: 9
Training loss: 7.848222285848924
Validation loss: 6.389537040013965

Epoch: 6| Step: 10
Training loss: 5.908255100494522
Validation loss: 6.386785925046872

Epoch: 6| Step: 11
Training loss: 6.556259530554173
Validation loss: 6.3722547104841185

Epoch: 6| Step: 12
Training loss: 6.165446736407075
Validation loss: 6.362860903045571

Epoch: 6| Step: 13
Training loss: 5.72925274408585
Validation loss: 6.3484368671942715

Epoch: 9| Step: 0
Training loss: 6.281542719003355
Validation loss: 6.34519939917792

Epoch: 6| Step: 1
Training loss: 4.953650991146817
Validation loss: 6.333927111594348

Epoch: 6| Step: 2
Training loss: 7.33244121789375
Validation loss: 6.327358287819511

Epoch: 6| Step: 3
Training loss: 6.900642984258163
Validation loss: 6.313742371712438

Epoch: 6| Step: 4
Training loss: 7.014697856853795
Validation loss: 6.300007118029658

Epoch: 6| Step: 5
Training loss: 5.92401390400658
Validation loss: 6.291420642541318

Epoch: 6| Step: 6
Training loss: 6.259056243931449
Validation loss: 6.279938470844581

Epoch: 6| Step: 7
Training loss: 6.251372224848199
Validation loss: 6.277687080568585

Epoch: 6| Step: 8
Training loss: 6.4858955530819555
Validation loss: 6.260869942735137

Epoch: 6| Step: 9
Training loss: 5.0781518553977385
Validation loss: 6.243193699356921

Epoch: 6| Step: 10
Training loss: 6.15593645100948
Validation loss: 6.243392000778071

Epoch: 6| Step: 11
Training loss: 5.4967496110538905
Validation loss: 6.238697686046892

Epoch: 6| Step: 12
Training loss: 5.940440202835712
Validation loss: 6.2225843269022

Epoch: 6| Step: 13
Training loss: 7.845006591327298
Validation loss: 6.2106120796107485

Epoch: 10| Step: 0
Training loss: 5.887024606354242
Validation loss: 6.205060531308931

Epoch: 6| Step: 1
Training loss: 4.757380122941121
Validation loss: 6.1816222496260504

Epoch: 6| Step: 2
Training loss: 6.067148844801854
Validation loss: 6.180772284508187

Epoch: 6| Step: 3
Training loss: 7.461859297604458
Validation loss: 6.165440951686717

Epoch: 6| Step: 4
Training loss: 6.1114682565230005
Validation loss: 6.162582745751901

Epoch: 6| Step: 5
Training loss: 6.295597221277628
Validation loss: 6.148599325968804

Epoch: 6| Step: 6
Training loss: 6.516280692427237
Validation loss: 6.140025273459067

Epoch: 6| Step: 7
Training loss: 5.723729368240551
Validation loss: 6.135428194664427

Epoch: 6| Step: 8
Training loss: 6.090521480488914
Validation loss: 6.1179020169332805

Epoch: 6| Step: 9
Training loss: 5.30571394190731
Validation loss: 6.10719725655814

Epoch: 6| Step: 10
Training loss: 5.393123147371552
Validation loss: 6.09242815016865

Epoch: 6| Step: 11
Training loss: 7.291884617045894
Validation loss: 6.090872772702254

Epoch: 6| Step: 12
Training loss: 6.037215844964582
Validation loss: 6.0803702309604315

Epoch: 6| Step: 13
Training loss: 6.4374229648758465
Validation loss: 6.057443698779543

Epoch: 11| Step: 0
Training loss: 6.327631877005681
Validation loss: 6.05541525106818

Epoch: 6| Step: 1
Training loss: 6.112280269488093
Validation loss: 6.045911018448771

Epoch: 6| Step: 2
Training loss: 7.104311168763457
Validation loss: 6.024253698303137

Epoch: 6| Step: 3
Training loss: 6.435656829959768
Validation loss: 6.0063263994154

Epoch: 6| Step: 4
Training loss: 5.648791881118167
Validation loss: 6.00616208381842

Epoch: 6| Step: 5
Training loss: 6.426855082196781
Validation loss: 5.985137305721429

Epoch: 6| Step: 6
Training loss: 3.953871584870145
Validation loss: 5.986905209323517

Epoch: 6| Step: 7
Training loss: 5.017025380706609
Validation loss: 5.985157338034552

Epoch: 6| Step: 8
Training loss: 6.263044858213623
Validation loss: 5.960466530382082

Epoch: 6| Step: 9
Training loss: 6.4672672949746275
Validation loss: 5.947852485330145

Epoch: 6| Step: 10
Training loss: 6.461543247374834
Validation loss: 5.934572343689382

Epoch: 6| Step: 11
Training loss: 5.632361448220315
Validation loss: 5.934973601842273

Epoch: 6| Step: 12
Training loss: 4.924106249582531
Validation loss: 5.916209357320416

Epoch: 6| Step: 13
Training loss: 6.307204640988017
Validation loss: 5.903118320062352

Epoch: 12| Step: 0
Training loss: 6.649185084841635
Validation loss: 5.888209447647006

Epoch: 6| Step: 1
Training loss: 5.752975357488261
Validation loss: 5.893726717664636

Epoch: 6| Step: 2
Training loss: 5.419055568434797
Validation loss: 5.867137548188328

Epoch: 6| Step: 3
Training loss: 5.496686457468604
Validation loss: 5.871228004063355

Epoch: 6| Step: 4
Training loss: 4.082093160789482
Validation loss: 5.85396479442235

Epoch: 6| Step: 5
Training loss: 5.229388512190099
Validation loss: 5.831639054646757

Epoch: 6| Step: 6
Training loss: 6.296019843936655
Validation loss: 5.825445023339167

Epoch: 6| Step: 7
Training loss: 5.587577611055646
Validation loss: 5.816871674195782

Epoch: 6| Step: 8
Training loss: 6.214300509530731
Validation loss: 5.810013405782264

Epoch: 6| Step: 9
Training loss: 5.24751295490674
Validation loss: 5.788935199208235

Epoch: 6| Step: 10
Training loss: 6.537851018581114
Validation loss: 5.781993374954995

Epoch: 6| Step: 11
Training loss: 6.4277284402509824
Validation loss: 5.771221528842678

Epoch: 6| Step: 12
Training loss: 6.035121169497558
Validation loss: 5.760635904374226

Epoch: 6| Step: 13
Training loss: 6.186318949486471
Validation loss: 5.74023881965157

Epoch: 13| Step: 0
Training loss: 5.275380682203236
Validation loss: 5.736444528613084

Epoch: 6| Step: 1
Training loss: 6.119713194864801
Validation loss: 5.716121034112665

Epoch: 6| Step: 2
Training loss: 5.366566273636797
Validation loss: 5.719431316034067

Epoch: 6| Step: 3
Training loss: 6.074312323435199
Validation loss: 5.686707221537208

Epoch: 6| Step: 4
Training loss: 5.986871343114357
Validation loss: 5.6741032431668055

Epoch: 6| Step: 5
Training loss: 6.303583173690716
Validation loss: 5.678043166551925

Epoch: 6| Step: 6
Training loss: 5.943120605004981
Validation loss: 5.649653094305924

Epoch: 6| Step: 7
Training loss: 5.455863549179061
Validation loss: 5.630965498898083

Epoch: 6| Step: 8
Training loss: 5.189750642758165
Validation loss: 5.641005365657389

Epoch: 6| Step: 9
Training loss: 5.374882186663054
Validation loss: 5.623458000125019

Epoch: 6| Step: 10
Training loss: 5.290000573142008
Validation loss: 5.596449702299429

Epoch: 6| Step: 11
Training loss: 5.664821137233346
Validation loss: 5.579497325280508

Epoch: 6| Step: 12
Training loss: 5.392220523614828
Validation loss: 5.5752974553847645

Epoch: 6| Step: 13
Training loss: 5.533540757822377
Validation loss: 5.573984246001876

Epoch: 14| Step: 0
Training loss: 6.608003803261316
Validation loss: 5.559923364945227

Epoch: 6| Step: 1
Training loss: 5.350765330396361
Validation loss: 5.533085092184234

Epoch: 6| Step: 2
Training loss: 4.685449380563955
Validation loss: 5.505963266976163

Epoch: 6| Step: 3
Training loss: 5.793606805935085
Validation loss: 5.5111978332586915

Epoch: 6| Step: 4
Training loss: 6.78584380062095
Validation loss: 5.496213243288971

Epoch: 6| Step: 5
Training loss: 4.620390992567008
Validation loss: 5.483134018966298

Epoch: 6| Step: 6
Training loss: 5.034598995176908
Validation loss: 5.473346042968779

Epoch: 6| Step: 7
Training loss: 5.7682953726683985
Validation loss: 5.441714021044246

Epoch: 6| Step: 8
Training loss: 5.881278072213157
Validation loss: 5.4288706449134905

Epoch: 6| Step: 9
Training loss: 4.94695892166408
Validation loss: 5.442527339434276

Epoch: 6| Step: 10
Training loss: 5.3389314040918014
Validation loss: 5.423425575476963

Epoch: 6| Step: 11
Training loss: 5.143128872307981
Validation loss: 5.403537356823175

Epoch: 6| Step: 12
Training loss: 4.743836268669621
Validation loss: 5.36959533182887

Epoch: 6| Step: 13
Training loss: 5.356822660050495
Validation loss: 5.380811925474542

Epoch: 15| Step: 0
Training loss: 4.5387914579951705
Validation loss: 5.369975541132949

Epoch: 6| Step: 1
Training loss: 6.030409996555997
Validation loss: 5.332096561472271

Epoch: 6| Step: 2
Training loss: 4.509898848319141
Validation loss: 5.325455848154341

Epoch: 6| Step: 3
Training loss: 5.798174524781418
Validation loss: 5.311171170648798

Epoch: 6| Step: 4
Training loss: 6.087394020990992
Validation loss: 5.296348747701681

Epoch: 6| Step: 5
Training loss: 5.698975106169722
Validation loss: 5.262757358460008

Epoch: 6| Step: 6
Training loss: 5.544175729672029
Validation loss: 5.264905506802897

Epoch: 6| Step: 7
Training loss: 4.632595115051606
Validation loss: 5.240542621126389

Epoch: 6| Step: 8
Training loss: 3.692566058705029
Validation loss: 5.218673830272902

Epoch: 6| Step: 9
Training loss: 5.287038486260545
Validation loss: 5.245825878288761

Epoch: 6| Step: 10
Training loss: 5.530259900461314
Validation loss: 5.194111263862905

Epoch: 6| Step: 11
Training loss: 5.310852692957502
Validation loss: 5.167474268110849

Epoch: 6| Step: 12
Training loss: 5.085464572745964
Validation loss: 5.187086956463529

Epoch: 6| Step: 13
Training loss: 5.615496936796241
Validation loss: 5.142163291841738

Epoch: 16| Step: 0
Training loss: 4.32698743723418
Validation loss: 5.138050330131397

Epoch: 6| Step: 1
Training loss: 5.160354367884868
Validation loss: 5.122884628440659

Epoch: 6| Step: 2
Training loss: 5.550509269649572
Validation loss: 5.1292770550731746

Epoch: 6| Step: 3
Training loss: 5.793768119577923
Validation loss: 5.104325918794238

Epoch: 6| Step: 4
Training loss: 5.348817263200558
Validation loss: 5.0689705076170934

Epoch: 6| Step: 5
Training loss: 4.338907520244962
Validation loss: 5.066814108183711

Epoch: 6| Step: 6
Training loss: 4.837058681495648
Validation loss: 5.059176742908496

Epoch: 6| Step: 7
Training loss: 5.617145734480509
Validation loss: 5.032722874613151

Epoch: 6| Step: 8
Training loss: 5.648069926393672
Validation loss: 5.028795509185983

Epoch: 6| Step: 9
Training loss: 4.799561385141989
Validation loss: 4.9956951190624865

Epoch: 6| Step: 10
Training loss: 5.102451872012236
Validation loss: 4.9462821515395445

Epoch: 6| Step: 11
Training loss: 4.189915430130482
Validation loss: 4.9736506005200365

Epoch: 6| Step: 12
Training loss: 4.447075197668767
Validation loss: 4.942898145380118

Epoch: 6| Step: 13
Training loss: 5.12838689029578
Validation loss: 4.926297868880117

Epoch: 17| Step: 0
Training loss: 5.300305181389949
Validation loss: 4.895999121057103

Epoch: 6| Step: 1
Training loss: 4.1670035162504195
Validation loss: 4.89249933159824

Epoch: 6| Step: 2
Training loss: 5.1356860148869945
Validation loss: 4.881720398282243

Epoch: 6| Step: 3
Training loss: 3.8924170354038945
Validation loss: 4.857831495827196

Epoch: 6| Step: 4
Training loss: 5.017480239715211
Validation loss: 4.853143001637877

Epoch: 6| Step: 5
Training loss: 5.315634128354155
Validation loss: 4.814693554567011

Epoch: 6| Step: 6
Training loss: 5.499308802781456
Validation loss: 4.792549072738805

Epoch: 6| Step: 7
Training loss: 5.084247736167526
Validation loss: 4.752031564329613

Epoch: 6| Step: 8
Training loss: 4.017642690596893
Validation loss: 4.752573267259897

Epoch: 6| Step: 9
Training loss: 4.935565231403834
Validation loss: 4.748581722588053

Epoch: 6| Step: 10
Training loss: 3.6589491572782036
Validation loss: 4.7474672293022175

Epoch: 6| Step: 11
Training loss: 5.058933650199815
Validation loss: 4.703384461483905

Epoch: 6| Step: 12
Training loss: 6.030796804844146
Validation loss: 4.688609662807661

Epoch: 6| Step: 13
Training loss: 2.3608863486726497
Validation loss: 4.657613782078896

Epoch: 18| Step: 0
Training loss: 4.894171942867113
Validation loss: 4.673485539537771

Epoch: 6| Step: 1
Training loss: 5.276382098899668
Validation loss: 4.619142498692475

Epoch: 6| Step: 2
Training loss: 4.409801161385736
Validation loss: 4.612605376437312

Epoch: 6| Step: 3
Training loss: 4.443617566331025
Validation loss: 4.590367276948231

Epoch: 6| Step: 4
Training loss: 4.874999413123462
Validation loss: 4.57297960822449

Epoch: 6| Step: 5
Training loss: 4.701315902576672
Validation loss: 4.549977604971944

Epoch: 6| Step: 6
Training loss: 3.1778070011292034
Validation loss: 4.5182298891552115

Epoch: 6| Step: 7
Training loss: 4.903784648802998
Validation loss: 4.509641131879833

Epoch: 6| Step: 8
Training loss: 4.340641363894416
Validation loss: 4.493025167797494

Epoch: 6| Step: 9
Training loss: 5.524509266597238
Validation loss: 4.472170267168699

Epoch: 6| Step: 10
Training loss: 4.245004298339393
Validation loss: 4.441112988040711

Epoch: 6| Step: 11
Training loss: 4.309498502581246
Validation loss: 4.454395356365213

Epoch: 6| Step: 12
Training loss: 4.06370596958926
Validation loss: 4.393117090636916

Epoch: 6| Step: 13
Training loss: 4.4100325561152145
Validation loss: 4.367469701139634

Epoch: 19| Step: 0
Training loss: 5.5627228767234715
Validation loss: 4.379264593018349

Epoch: 6| Step: 1
Training loss: 4.786452311725447
Validation loss: 4.356186809638498

Epoch: 6| Step: 2
Training loss: 4.741582137406404
Validation loss: 4.309147167943469

Epoch: 6| Step: 3
Training loss: 5.388511884857632
Validation loss: 4.314800985549268

Epoch: 6| Step: 4
Training loss: 4.595589198213364
Validation loss: 4.301590941546435

Epoch: 6| Step: 5
Training loss: 3.8552417939548174
Validation loss: 4.266932296816085

Epoch: 6| Step: 6
Training loss: 3.7812941367355624
Validation loss: 4.248645355457729

Epoch: 6| Step: 7
Training loss: 3.849369190606219
Validation loss: 4.22867964328633

Epoch: 6| Step: 8
Training loss: 3.9819915224652793
Validation loss: 4.2008807824785235

Epoch: 6| Step: 9
Training loss: 3.649661787902635
Validation loss: 4.171279451156004

Epoch: 6| Step: 10
Training loss: 4.178297264411085
Validation loss: 4.1805132619371665

Epoch: 6| Step: 11
Training loss: 3.9070509432773277
Validation loss: 4.1270938206740615

Epoch: 6| Step: 12
Training loss: 3.7132545706193625
Validation loss: 4.141765615848075

Epoch: 6| Step: 13
Training loss: 3.2194149478603014
Validation loss: 4.086584663090964

Epoch: 20| Step: 0
Training loss: 3.584778974628148
Validation loss: 4.076862008090023

Epoch: 6| Step: 1
Training loss: 4.525477869924001
Validation loss: 4.052805573991599

Epoch: 6| Step: 2
Training loss: 3.694039058831981
Validation loss: 4.061376944297325

Epoch: 6| Step: 3
Training loss: 3.676485324605691
Validation loss: 4.007051835277063

Epoch: 6| Step: 4
Training loss: 4.22160909339109
Validation loss: 3.9892139574938557

Epoch: 6| Step: 5
Training loss: 3.8270284522448996
Validation loss: 3.950406596206427

Epoch: 6| Step: 6
Training loss: 4.602821579390104
Validation loss: 3.917193764586192

Epoch: 6| Step: 7
Training loss: 4.403023045417383
Validation loss: 3.925516797862527

Epoch: 6| Step: 8
Training loss: 3.53903716964583
Validation loss: 3.865554965156731

Epoch: 6| Step: 9
Training loss: 4.450712494120719
Validation loss: 3.862388887103786

Epoch: 6| Step: 10
Training loss: 4.017094324753259
Validation loss: 3.851492160297182

Epoch: 6| Step: 11
Training loss: 4.1887234850493655
Validation loss: 3.824451270070302

Epoch: 6| Step: 12
Training loss: 2.921221165251525
Validation loss: 3.7907514895433745

Epoch: 6| Step: 13
Training loss: 4.1391737211958475
Validation loss: 3.7977692370409293

Epoch: 21| Step: 0
Training loss: 3.7484964535439333
Validation loss: 3.794488589455812

Epoch: 6| Step: 1
Training loss: 3.6975163346059383
Validation loss: 3.7609652690381274

Epoch: 6| Step: 2
Training loss: 2.7744852155606714
Validation loss: 3.7390500831979767

Epoch: 6| Step: 3
Training loss: 3.652040324127423
Validation loss: 3.6992573733103997

Epoch: 6| Step: 4
Training loss: 3.8870075367745796
Validation loss: 3.652021446569666

Epoch: 6| Step: 5
Training loss: 4.078910430455983
Validation loss: 3.659482897606432

Epoch: 6| Step: 6
Training loss: 3.4107759137745144
Validation loss: 3.7010568811575335

Epoch: 6| Step: 7
Training loss: 3.5281758388373814
Validation loss: 3.6265998679034777

Epoch: 6| Step: 8
Training loss: 3.877811765354839
Validation loss: 3.6011446967913012

Epoch: 6| Step: 9
Training loss: 3.5655544638447965
Validation loss: 3.5927055778002033

Epoch: 6| Step: 10
Training loss: 3.396535196302503
Validation loss: 3.5463104355278756

Epoch: 6| Step: 11
Training loss: 3.876586589254053
Validation loss: 3.5318287788832916

Epoch: 6| Step: 12
Training loss: 4.224636012543159
Validation loss: 3.5025223785535937

Epoch: 6| Step: 13
Training loss: 4.417317228567893
Validation loss: 3.45233866522582

Epoch: 22| Step: 0
Training loss: 3.4291430065007793
Validation loss: 3.4624275798486663

Epoch: 6| Step: 1
Training loss: 4.18607317400975
Validation loss: 3.4735922339701615

Epoch: 6| Step: 2
Training loss: 3.3105552290639433
Validation loss: 3.4382400655735874

Epoch: 6| Step: 3
Training loss: 3.217242878774904
Validation loss: 3.401771954826595

Epoch: 6| Step: 4
Training loss: 3.155747930799699
Validation loss: 3.3862752159288543

Epoch: 6| Step: 5
Training loss: 3.7192586342594116
Validation loss: 3.3682466054782543

Epoch: 6| Step: 6
Training loss: 3.5061107152245077
Validation loss: 3.333006088026457

Epoch: 6| Step: 7
Training loss: 2.9985591289268267
Validation loss: 3.3705044319232527

Epoch: 6| Step: 8
Training loss: 3.7641885003979705
Validation loss: 3.3050318879625538

Epoch: 6| Step: 9
Training loss: 3.8133421421171585
Validation loss: 3.3251760272891207

Epoch: 6| Step: 10
Training loss: 3.2275779179298825
Validation loss: 3.303266572127909

Epoch: 6| Step: 11
Training loss: 3.7776719496121838
Validation loss: 3.25263085226228

Epoch: 6| Step: 12
Training loss: 3.214065698632265
Validation loss: 3.2583223171555127

Epoch: 6| Step: 13
Training loss: 3.3700322925593853
Validation loss: 3.2302519155901774

Epoch: 23| Step: 0
Training loss: 3.5725141619220753
Validation loss: 3.203451952791339

Epoch: 6| Step: 1
Training loss: 3.4939400117961776
Validation loss: 3.1955273674307607

Epoch: 6| Step: 2
Training loss: 3.429499523251238
Validation loss: 3.1604686976913174

Epoch: 6| Step: 3
Training loss: 2.991930918237725
Validation loss: 3.1217678558312993

Epoch: 6| Step: 4
Training loss: 3.4003144791966053
Validation loss: 3.1380343240536344

Epoch: 6| Step: 5
Training loss: 2.3111436319915977
Validation loss: 3.141719959671233

Epoch: 6| Step: 6
Training loss: 4.08085873935096
Validation loss: 3.1110286898274513

Epoch: 6| Step: 7
Training loss: 3.1256792474687227
Validation loss: 3.064900783000957

Epoch: 6| Step: 8
Training loss: 2.6722565317187414
Validation loss: 3.0081337164751303

Epoch: 6| Step: 9
Training loss: 3.560303395662375
Validation loss: 3.063254369996106

Epoch: 6| Step: 10
Training loss: 3.058222683629499
Validation loss: 3.0252832598243713

Epoch: 6| Step: 11
Training loss: 2.819148534103236
Validation loss: 3.0285920716499755

Epoch: 6| Step: 12
Training loss: 3.57633467615677
Validation loss: 3.0005365015035745

Epoch: 6| Step: 13
Training loss: 3.5335220184568588
Validation loss: 2.9941894410824736

Epoch: 24| Step: 0
Training loss: 3.7530159584232634
Validation loss: 2.9407211024548987

Epoch: 6| Step: 1
Training loss: 3.635096203398059
Validation loss: 3.0027878311683724

Epoch: 6| Step: 2
Training loss: 4.329208293539656
Validation loss: 2.9997762063343782

Epoch: 6| Step: 3
Training loss: 2.3409353012341474
Validation loss: 2.9894819202067686

Epoch: 6| Step: 4
Training loss: 2.537168577001252
Validation loss: 2.9682708396725808

Epoch: 6| Step: 5
Training loss: 2.796913359821178
Validation loss: 2.9313504631153395

Epoch: 6| Step: 6
Training loss: 3.4812771150639064
Validation loss: 2.93024881477991

Epoch: 6| Step: 7
Training loss: 3.0161314227766085
Validation loss: 2.9259432418645694

Epoch: 6| Step: 8
Training loss: 3.371592037288284
Validation loss: 2.9348112633290273

Epoch: 6| Step: 9
Training loss: 3.2535697698925397
Validation loss: 2.8774838999803003

Epoch: 6| Step: 10
Training loss: 2.5735829426303045
Validation loss: 2.8934700518378498

Epoch: 6| Step: 11
Training loss: 2.739740306771312
Validation loss: 2.854842160306662

Epoch: 6| Step: 12
Training loss: 2.444144753185442
Validation loss: 2.8836138349902174

Epoch: 6| Step: 13
Training loss: 3.229704059471638
Validation loss: 2.84138341433898

Epoch: 25| Step: 0
Training loss: 2.7700069218077403
Validation loss: 2.8462304412263313

Epoch: 6| Step: 1
Training loss: 3.2419514397779645
Validation loss: 2.822756697618238

Epoch: 6| Step: 2
Training loss: 2.8158203870105596
Validation loss: 2.8563807209692325

Epoch: 6| Step: 3
Training loss: 3.0439514218839077
Validation loss: 2.875324757920713

Epoch: 6| Step: 4
Training loss: 3.591578482646492
Validation loss: 2.849881215364563

Epoch: 6| Step: 5
Training loss: 3.5437453658462177
Validation loss: 2.8263870162926086

Epoch: 6| Step: 6
Training loss: 3.1405806656929878
Validation loss: 2.8299821208506626

Epoch: 6| Step: 7
Training loss: 2.51141127725949
Validation loss: 2.7942208580547714

Epoch: 6| Step: 8
Training loss: 3.3962381195770366
Validation loss: 2.7848439516355197

Epoch: 6| Step: 9
Training loss: 2.58721357593926
Validation loss: 2.802509344247709

Epoch: 6| Step: 10
Training loss: 2.3948343156753316
Validation loss: 2.8387621860621253

Epoch: 6| Step: 11
Training loss: 3.6320881439301993
Validation loss: 2.7817973526630175

Epoch: 6| Step: 12
Training loss: 2.2688581876995118
Validation loss: 2.8173135254112758

Epoch: 6| Step: 13
Training loss: 4.0489173949245805
Validation loss: 2.770843628586591

Epoch: 26| Step: 0
Training loss: 3.8474418464216815
Validation loss: 2.7970764716385386

Epoch: 6| Step: 1
Training loss: 3.0639981089454174
Validation loss: 2.7794655207859287

Epoch: 6| Step: 2
Training loss: 3.1538511923916133
Validation loss: 2.7591549021009967

Epoch: 6| Step: 3
Training loss: 3.2312255858452676
Validation loss: 2.771486297162521

Epoch: 6| Step: 4
Training loss: 3.3971434486248397
Validation loss: 2.739313876343276

Epoch: 6| Step: 5
Training loss: 2.9825062917817253
Validation loss: 2.7506676951229063

Epoch: 6| Step: 6
Training loss: 1.8968788938780887
Validation loss: 2.7425804897814334

Epoch: 6| Step: 7
Training loss: 2.524181244552931
Validation loss: 2.733682220406614

Epoch: 6| Step: 8
Training loss: 3.357046908598866
Validation loss: 2.8005783632969403

Epoch: 6| Step: 9
Training loss: 2.8400203854541117
Validation loss: 2.741351965342155

Epoch: 6| Step: 10
Training loss: 2.974162097548672
Validation loss: 2.7441858195576767

Epoch: 6| Step: 11
Training loss: 2.824004570106288
Validation loss: 2.754612323628915

Epoch: 6| Step: 12
Training loss: 2.801718157450721
Validation loss: 2.7943453205653674

Epoch: 6| Step: 13
Training loss: 3.6660640105690794
Validation loss: 2.7134177600645635

Epoch: 27| Step: 0
Training loss: 2.8616324096951677
Validation loss: 2.669882963850155

Epoch: 6| Step: 1
Training loss: 3.2065121489615453
Validation loss: 2.7547327448383645

Epoch: 6| Step: 2
Training loss: 2.732450145605181
Validation loss: 2.6851992649848153

Epoch: 6| Step: 3
Training loss: 2.5791653470316906
Validation loss: 2.7401934076652443

Epoch: 6| Step: 4
Training loss: 2.398789569474698
Validation loss: 2.739230422642208

Epoch: 6| Step: 5
Training loss: 2.680821126147806
Validation loss: 2.729675056494946

Epoch: 6| Step: 6
Training loss: 3.0288867980316674
Validation loss: 2.715610412719341

Epoch: 6| Step: 7
Training loss: 3.62300199496293
Validation loss: 2.7180305880379256

Epoch: 6| Step: 8
Training loss: 3.2831265850778615
Validation loss: 2.740604387377156

Epoch: 6| Step: 9
Training loss: 2.979888099515202
Validation loss: 2.7483466782077963

Epoch: 6| Step: 10
Training loss: 3.0279893149889103
Validation loss: 2.7087393147970635

Epoch: 6| Step: 11
Training loss: 3.2279191755648857
Validation loss: 2.7499613707915924

Epoch: 6| Step: 12
Training loss: 3.4485512386728363
Validation loss: 2.6946232386858315

Epoch: 6| Step: 13
Training loss: 2.639639856886951
Validation loss: 2.741524131985392

Epoch: 28| Step: 0
Training loss: 2.974644961930101
Validation loss: 2.73777742136251

Epoch: 6| Step: 1
Training loss: 3.3990849722206806
Validation loss: 2.7706849552469692

Epoch: 6| Step: 2
Training loss: 2.918915090854338
Validation loss: 2.765442461372285

Epoch: 6| Step: 3
Training loss: 2.9125797702850864
Validation loss: 2.7216456834966993

Epoch: 6| Step: 4
Training loss: 2.7794434756058872
Validation loss: 2.7139794599954774

Epoch: 6| Step: 5
Training loss: 2.9538770252992625
Validation loss: 2.731923815157609

Epoch: 6| Step: 6
Training loss: 3.7415414144937738
Validation loss: 2.733230219923709

Epoch: 6| Step: 7
Training loss: 3.3307804027172803
Validation loss: 2.69407736554913

Epoch: 6| Step: 8
Training loss: 3.642388829280448
Validation loss: 2.732317050161967

Epoch: 6| Step: 9
Training loss: 2.6936544874920094
Validation loss: 2.706829994790465

Epoch: 6| Step: 10
Training loss: 2.499068086500317
Validation loss: 2.7221624467093744

Epoch: 6| Step: 11
Training loss: 2.528584996495703
Validation loss: 2.7318969790969714

Epoch: 6| Step: 12
Training loss: 2.4042229970308298
Validation loss: 2.740789748512173

Epoch: 6| Step: 13
Training loss: 2.7599650079471614
Validation loss: 2.6898509848709615

Epoch: 29| Step: 0
Training loss: 3.1567767619585183
Validation loss: 2.742267685182857

Epoch: 6| Step: 1
Training loss: 2.807362420506266
Validation loss: 2.7548656637064264

Epoch: 6| Step: 2
Training loss: 3.2711225896037313
Validation loss: 2.7403326187015606

Epoch: 6| Step: 3
Training loss: 2.860133336300253
Validation loss: 2.7253658358813895

Epoch: 6| Step: 4
Training loss: 3.0115629519527265
Validation loss: 2.754641990966704

Epoch: 6| Step: 5
Training loss: 3.2180351278261927
Validation loss: 2.692555760478916

Epoch: 6| Step: 6
Training loss: 1.861637438024138
Validation loss: 2.6902350416408836

Epoch: 6| Step: 7
Training loss: 3.297185223343343
Validation loss: 2.7375294780656496

Epoch: 6| Step: 8
Training loss: 2.726950893775498
Validation loss: 2.740259432797049

Epoch: 6| Step: 9
Training loss: 3.2615722623355325
Validation loss: 2.70975739939801

Epoch: 6| Step: 10
Training loss: 2.3548335140851973
Validation loss: 2.729977806017922

Epoch: 6| Step: 11
Training loss: 2.8767164331097073
Validation loss: 2.7041379230604212

Epoch: 6| Step: 12
Training loss: 3.2616950668114737
Validation loss: 2.714784932379141

Epoch: 6| Step: 13
Training loss: 4.215622258167775
Validation loss: 2.687812332964104

Epoch: 30| Step: 0
Training loss: 3.3667851537369207
Validation loss: 2.6914304879261297

Epoch: 6| Step: 1
Training loss: 3.1216947241922623
Validation loss: 2.773859896190241

Epoch: 6| Step: 2
Training loss: 3.005199853277996
Validation loss: 2.7448764076623906

Epoch: 6| Step: 3
Training loss: 3.0361194628707
Validation loss: 2.703197191156307

Epoch: 6| Step: 4
Training loss: 2.1191007970767664
Validation loss: 2.7256470427501807

Epoch: 6| Step: 5
Training loss: 2.990978664106554
Validation loss: 2.7247796969751756

Epoch: 6| Step: 6
Training loss: 3.4842759190999675
Validation loss: 2.6977646040853975

Epoch: 6| Step: 7
Training loss: 2.9214697572108057
Validation loss: 2.7121887742618185

Epoch: 6| Step: 8
Training loss: 3.276159788750509
Validation loss: 2.7469342408766195

Epoch: 6| Step: 9
Training loss: 3.379807192252143
Validation loss: 2.7107228310584284

Epoch: 6| Step: 10
Training loss: 2.379095862337704
Validation loss: 2.7367221716342023

Epoch: 6| Step: 11
Training loss: 2.6961550073067557
Validation loss: 2.7458567744847953

Epoch: 6| Step: 12
Training loss: 2.246711659230913
Validation loss: 2.714005562160974

Epoch: 6| Step: 13
Training loss: 3.4984891900438972
Validation loss: 2.737430687045265

Epoch: 31| Step: 0
Training loss: 3.0819842162127267
Validation loss: 2.7083135406932044

Epoch: 6| Step: 1
Training loss: 2.442327658157485
Validation loss: 2.7223452703550137

Epoch: 6| Step: 2
Training loss: 3.239498926434852
Validation loss: 2.7012027713234548

Epoch: 6| Step: 3
Training loss: 2.500321176878848
Validation loss: 2.676718611874876

Epoch: 6| Step: 4
Training loss: 2.144594174210614
Validation loss: 2.7382731947293912

Epoch: 6| Step: 5
Training loss: 2.8755078074588556
Validation loss: 2.714604888863928

Epoch: 6| Step: 6
Training loss: 3.3934179659958423
Validation loss: 2.702017975739236

Epoch: 6| Step: 7
Training loss: 3.285711252910091
Validation loss: 2.7037862177291982

Epoch: 6| Step: 8
Training loss: 3.0293651895303224
Validation loss: 2.741417602537626

Epoch: 6| Step: 9
Training loss: 3.3466999196937315
Validation loss: 2.739929149943122

Epoch: 6| Step: 10
Training loss: 3.2829236802924613
Validation loss: 2.7540958010870193

Epoch: 6| Step: 11
Training loss: 2.8978631203643275
Validation loss: 2.7171919972759095

Epoch: 6| Step: 12
Training loss: 3.338442859982797
Validation loss: 2.7158793436839495

Epoch: 6| Step: 13
Training loss: 2.4041969160780687
Validation loss: 2.699378595584287

Epoch: 32| Step: 0
Training loss: 2.752747117261111
Validation loss: 2.697222511831048

Epoch: 6| Step: 1
Training loss: 3.3482364966246188
Validation loss: 2.729485776728873

Epoch: 6| Step: 2
Training loss: 2.216666949661734
Validation loss: 2.753273944793263

Epoch: 6| Step: 3
Training loss: 2.8857636684902697
Validation loss: 2.7147158210378115

Epoch: 6| Step: 4
Training loss: 3.608577887960037
Validation loss: 2.7228407842065465

Epoch: 6| Step: 5
Training loss: 2.241873263891998
Validation loss: 2.6421749340158387

Epoch: 6| Step: 6
Training loss: 2.814553846030196
Validation loss: 2.701341133241415

Epoch: 6| Step: 7
Training loss: 3.2430027683562663
Validation loss: 2.732865876056292

Epoch: 6| Step: 8
Training loss: 3.248277060770123
Validation loss: 2.7004733761062036

Epoch: 6| Step: 9
Training loss: 3.1864843807463163
Validation loss: 2.7229278980241327

Epoch: 6| Step: 10
Training loss: 3.07243557197431
Validation loss: 2.7397397902516403

Epoch: 6| Step: 11
Training loss: 2.7758931209096254
Validation loss: 2.7238713393726

Epoch: 6| Step: 12
Training loss: 3.348665848572095
Validation loss: 2.732207915430178

Epoch: 6| Step: 13
Training loss: 2.3738894626815026
Validation loss: 2.7518353672064406

Epoch: 33| Step: 0
Training loss: 2.817933069505059
Validation loss: 2.7088873972487626

Epoch: 6| Step: 1
Training loss: 3.1270122915623517
Validation loss: 2.7070866961625772

Epoch: 6| Step: 2
Training loss: 3.1652657940522264
Validation loss: 2.686841169963159

Epoch: 6| Step: 3
Training loss: 3.0681500378642164
Validation loss: 2.6967802255868905

Epoch: 6| Step: 4
Training loss: 2.4107628650917374
Validation loss: 2.6862267771353685

Epoch: 6| Step: 5
Training loss: 3.457928246975415
Validation loss: 2.748457132761494

Epoch: 6| Step: 6
Training loss: 2.454750640076514
Validation loss: 2.697526963877628

Epoch: 6| Step: 7
Training loss: 3.299172997163071
Validation loss: 2.71667164631542

Epoch: 6| Step: 8
Training loss: 3.0389683569126555
Validation loss: 2.7066474681212567

Epoch: 6| Step: 9
Training loss: 2.866289627060791
Validation loss: 2.7245297286848285

Epoch: 6| Step: 10
Training loss: 3.0025487245644804
Validation loss: 2.71568699675843

Epoch: 6| Step: 11
Training loss: 2.6664859789986313
Validation loss: 2.723352819092311

Epoch: 6| Step: 12
Training loss: 3.60688358869705
Validation loss: 2.681122458930892

Epoch: 6| Step: 13
Training loss: 2.29397607671474
Validation loss: 2.7143256264844777

Epoch: 34| Step: 0
Training loss: 2.733901936617652
Validation loss: 2.7094512626310983

Epoch: 6| Step: 1
Training loss: 3.4227976491385292
Validation loss: 2.7174703877351996

Epoch: 6| Step: 2
Training loss: 3.370855117431968
Validation loss: 2.7277620836335585

Epoch: 6| Step: 3
Training loss: 2.5979030405853236
Validation loss: 2.710242953848721

Epoch: 6| Step: 4
Training loss: 3.8191582744011483
Validation loss: 2.712112168006423

Epoch: 6| Step: 5
Training loss: 3.2350416003327975
Validation loss: 2.6883908631775832

Epoch: 6| Step: 6
Training loss: 2.904494709185409
Validation loss: 2.7480628890379424

Epoch: 6| Step: 7
Training loss: 2.6682875793206833
Validation loss: 2.6780651927515153

Epoch: 6| Step: 8
Training loss: 2.446223762539137
Validation loss: 2.7189925022811234

Epoch: 6| Step: 9
Training loss: 2.338769529211162
Validation loss: 2.7054574825628874

Epoch: 6| Step: 10
Training loss: 2.9764610934067264
Validation loss: 2.708190541885052

Epoch: 6| Step: 11
Training loss: 3.2890680091068765
Validation loss: 2.7390665167062775

Epoch: 6| Step: 12
Training loss: 2.7089219749651288
Validation loss: 2.696562049039359

Epoch: 6| Step: 13
Training loss: 3.580114219804064
Validation loss: 2.720625296041501

Epoch: 35| Step: 0
Training loss: 2.625189274821474
Validation loss: 2.775984389822743

Epoch: 6| Step: 1
Training loss: 2.650839377568955
Validation loss: 2.70411570367142

Epoch: 6| Step: 2
Training loss: 3.123087793861079
Validation loss: 2.716582540732875

Epoch: 6| Step: 3
Training loss: 2.612322028271884
Validation loss: 2.6898566919022904

Epoch: 6| Step: 4
Training loss: 2.5242333825270813
Validation loss: 2.6733973029058196

Epoch: 6| Step: 5
Training loss: 3.6079259828981094
Validation loss: 2.7352149641279806

Epoch: 6| Step: 6
Training loss: 2.639447824501902
Validation loss: 2.69407938766415

Epoch: 6| Step: 7
Training loss: 3.5810219310950733
Validation loss: 2.673468966772447

Epoch: 6| Step: 8
Training loss: 2.5171141392953316
Validation loss: 2.677395649459218

Epoch: 6| Step: 9
Training loss: 2.726630966944578
Validation loss: 2.7129562458467538

Epoch: 6| Step: 10
Training loss: 3.670569394712009
Validation loss: 2.6825338106007015

Epoch: 6| Step: 11
Training loss: 2.322208952472906
Validation loss: 2.750207411214826

Epoch: 6| Step: 12
Training loss: 3.4359561574445836
Validation loss: 2.740856759160215

Epoch: 6| Step: 13
Training loss: 3.685594874778514
Validation loss: 2.685344336127724

Epoch: 36| Step: 0
Training loss: 3.1261710452329274
Validation loss: 2.6912073814133226

Epoch: 6| Step: 1
Training loss: 3.0048782105607432
Validation loss: 2.7158424786070348

Epoch: 6| Step: 2
Training loss: 1.8968802136219152
Validation loss: 2.7120800773164184

Epoch: 6| Step: 3
Training loss: 3.275698079264043
Validation loss: 2.701538648520044

Epoch: 6| Step: 4
Training loss: 2.8406843491870597
Validation loss: 2.6982831713535353

Epoch: 6| Step: 5
Training loss: 2.2691259235596015
Validation loss: 2.685589851997577

Epoch: 6| Step: 6
Training loss: 2.5106918585119993
Validation loss: 2.6831122344611003

Epoch: 6| Step: 7
Training loss: 3.364095520622891
Validation loss: 2.760818318179827

Epoch: 6| Step: 8
Training loss: 3.4716677379804897
Validation loss: 2.6883776834853887

Epoch: 6| Step: 9
Training loss: 3.377572386196782
Validation loss: 2.717260565413979

Epoch: 6| Step: 10
Training loss: 3.3529126842221193
Validation loss: 2.7089321398988764

Epoch: 6| Step: 11
Training loss: 2.9899795393738104
Validation loss: 2.7299527618415325

Epoch: 6| Step: 12
Training loss: 2.9876662076420337
Validation loss: 2.717378752609448

Epoch: 6| Step: 13
Training loss: 2.407455637712249
Validation loss: 2.699423587962588

Epoch: 37| Step: 0
Training loss: 2.4652054849212353
Validation loss: 2.699981832803961

Epoch: 6| Step: 1
Training loss: 4.351841477606442
Validation loss: 2.711878010394166

Epoch: 6| Step: 2
Training loss: 3.0037144871333634
Validation loss: 2.7220616287686634

Epoch: 6| Step: 3
Training loss: 3.531474688648143
Validation loss: 2.702199057134005

Epoch: 6| Step: 4
Training loss: 2.4000556780396636
Validation loss: 2.732549520109379

Epoch: 6| Step: 5
Training loss: 2.4266357882424994
Validation loss: 2.68556287415811

Epoch: 6| Step: 6
Training loss: 3.235037473199179
Validation loss: 2.7011901059046086

Epoch: 6| Step: 7
Training loss: 2.8098769778001125
Validation loss: 2.6574214458585064

Epoch: 6| Step: 8
Training loss: 3.201877704703361
Validation loss: 2.7010139408068516

Epoch: 6| Step: 9
Training loss: 2.0688316951421415
Validation loss: 2.7217610269316914

Epoch: 6| Step: 10
Training loss: 2.0175081667445265
Validation loss: 2.719448544411681

Epoch: 6| Step: 11
Training loss: 3.7518734384838837
Validation loss: 2.6907964685060772

Epoch: 6| Step: 12
Training loss: 3.1443744501861413
Validation loss: 2.698025126875765

Epoch: 6| Step: 13
Training loss: 1.6472298777236005
Validation loss: 2.6925654073582006

Epoch: 38| Step: 0
Training loss: 3.3005472134115856
Validation loss: 2.6996598124732545

Epoch: 6| Step: 1
Training loss: 2.2669030103696213
Validation loss: 2.7029321172447

Epoch: 6| Step: 2
Training loss: 3.0763461012169384
Validation loss: 2.693979136510701

Epoch: 6| Step: 3
Training loss: 2.7666368950157345
Validation loss: 2.7366270330515157

Epoch: 6| Step: 4
Training loss: 3.3087269149338123
Validation loss: 2.7022067066834086

Epoch: 6| Step: 5
Training loss: 3.4227959773928163
Validation loss: 2.7093183412723696

Epoch: 6| Step: 6
Training loss: 3.4038231279836912
Validation loss: 2.6528511881909767

Epoch: 6| Step: 7
Training loss: 2.141449484098174
Validation loss: 2.7054550216934037

Epoch: 6| Step: 8
Training loss: 3.0719794099435607
Validation loss: 2.692481280684798

Epoch: 6| Step: 9
Training loss: 3.4244124528118185
Validation loss: 2.7547181878644267

Epoch: 6| Step: 10
Training loss: 3.1721873763784023
Validation loss: 2.700815524323864

Epoch: 6| Step: 11
Training loss: 2.9750732541081355
Validation loss: 2.692147222643322

Epoch: 6| Step: 12
Training loss: 2.587186114304742
Validation loss: 2.7109759883211764

Epoch: 6| Step: 13
Training loss: 2.4044068448461906
Validation loss: 2.7247825327306177

Epoch: 39| Step: 0
Training loss: 3.2465652508989753
Validation loss: 2.7138428023285415

Epoch: 6| Step: 1
Training loss: 2.897590945431798
Validation loss: 2.7158238627518645

Epoch: 6| Step: 2
Training loss: 2.6666558583358437
Validation loss: 2.700078073654232

Epoch: 6| Step: 3
Training loss: 3.098571257366062
Validation loss: 2.719564871852049

Epoch: 6| Step: 4
Training loss: 2.9637214235161333
Validation loss: 2.679727378531023

Epoch: 6| Step: 5
Training loss: 2.99252883119645
Validation loss: 2.738859574109058

Epoch: 6| Step: 6
Training loss: 3.996258416237081
Validation loss: 2.6381118464419253

Epoch: 6| Step: 7
Training loss: 2.69708414869111
Validation loss: 2.689621326856238

Epoch: 6| Step: 8
Training loss: 2.770504198149299
Validation loss: 2.6819815300575756

Epoch: 6| Step: 9
Training loss: 2.533868918354707
Validation loss: 2.7110598172087776

Epoch: 6| Step: 10
Training loss: 2.942883043532338
Validation loss: 2.7289334344450933

Epoch: 6| Step: 11
Training loss: 2.93148333631396
Validation loss: 2.6978925719004607

Epoch: 6| Step: 12
Training loss: 3.1957961185150285
Validation loss: 2.669074494919245

Epoch: 6| Step: 13
Training loss: 3.0113499832498136
Validation loss: 2.709017231040177

Epoch: 40| Step: 0
Training loss: 3.3203372011948833
Validation loss: 2.7108840759806396

Epoch: 6| Step: 1
Training loss: 2.9184164702118025
Validation loss: 2.7041737702471984

Epoch: 6| Step: 2
Training loss: 2.5574268271679563
Validation loss: 2.744698905011703

Epoch: 6| Step: 3
Training loss: 2.2893209994959007
Validation loss: 2.71639177250337

Epoch: 6| Step: 4
Training loss: 3.6180911820004664
Validation loss: 2.7386804580240978

Epoch: 6| Step: 5
Training loss: 2.395858521259977
Validation loss: 2.6782874471015683

Epoch: 6| Step: 6
Training loss: 3.2637929933858114
Validation loss: 2.675898245623561

Epoch: 6| Step: 7
Training loss: 2.9695478471484353
Validation loss: 2.704671634103778

Epoch: 6| Step: 8
Training loss: 2.9725417166462353
Validation loss: 2.7046318759699424

Epoch: 6| Step: 9
Training loss: 2.739371481320286
Validation loss: 2.6825263572515534

Epoch: 6| Step: 10
Training loss: 2.593791455776341
Validation loss: 2.76438644889754

Epoch: 6| Step: 11
Training loss: 3.6446292451070454
Validation loss: 2.6707974995623993

Epoch: 6| Step: 12
Training loss: 2.9372704598856063
Validation loss: 2.693731984115193

Epoch: 6| Step: 13
Training loss: 3.3689254913198146
Validation loss: 2.6470602354616553

Epoch: 41| Step: 0
Training loss: 2.7328382260751294
Validation loss: 2.7090302232564993

Epoch: 6| Step: 1
Training loss: 2.8639473133888456
Validation loss: 2.7343705006458396

Epoch: 6| Step: 2
Training loss: 3.101293134162572
Validation loss: 2.7426115552508574

Epoch: 6| Step: 3
Training loss: 3.0126202887741256
Validation loss: 2.6997648436772024

Epoch: 6| Step: 4
Training loss: 3.184267686527452
Validation loss: 2.7458218617434373

Epoch: 6| Step: 5
Training loss: 2.5719738261076097
Validation loss: 2.7042216520263462

Epoch: 6| Step: 6
Training loss: 2.460714856930136
Validation loss: 2.7030494959648323

Epoch: 6| Step: 7
Training loss: 3.2913045241334102
Validation loss: 2.7060498274769076

Epoch: 6| Step: 8
Training loss: 2.995551626006032
Validation loss: 2.6927344363643586

Epoch: 6| Step: 9
Training loss: 3.430456818169155
Validation loss: 2.7088748425240756

Epoch: 6| Step: 10
Training loss: 3.132584485058667
Validation loss: 2.715525829333419

Epoch: 6| Step: 11
Training loss: 3.1627434135514974
Validation loss: 2.696730260002449

Epoch: 6| Step: 12
Training loss: 2.831519687094427
Validation loss: 2.6826502164400226

Epoch: 6| Step: 13
Training loss: 2.2905066820008466
Validation loss: 2.702293240050769

Epoch: 42| Step: 0
Training loss: 3.3052995263828127
Validation loss: 2.693049462653923

Epoch: 6| Step: 1
Training loss: 2.9156604302677134
Validation loss: 2.6952752870354084

Epoch: 6| Step: 2
Training loss: 2.7174737499832715
Validation loss: 2.6935530736426947

Epoch: 6| Step: 3
Training loss: 3.0404068589249453
Validation loss: 2.71567058789533

Epoch: 6| Step: 4
Training loss: 2.8225602679242217
Validation loss: 2.6968822833104404

Epoch: 6| Step: 5
Training loss: 3.3154722590234416
Validation loss: 2.730026538627781

Epoch: 6| Step: 6
Training loss: 2.9262186495060134
Validation loss: 2.7334083360255517

Epoch: 6| Step: 7
Training loss: 2.5356439200756293
Validation loss: 2.69649294791118

Epoch: 6| Step: 8
Training loss: 2.9510710501473154
Validation loss: 2.704376604306614

Epoch: 6| Step: 9
Training loss: 3.029992226065052
Validation loss: 2.6813491753610696

Epoch: 6| Step: 10
Training loss: 3.089256954295496
Validation loss: 2.6690553060218125

Epoch: 6| Step: 11
Training loss: 3.2544777174875614
Validation loss: 2.6845491057570845

Epoch: 6| Step: 12
Training loss: 3.12835162672799
Validation loss: 2.721216145272438

Epoch: 6| Step: 13
Training loss: 2.3286203971013366
Validation loss: 2.702395813395393

Epoch: 43| Step: 0
Training loss: 2.98921936867839
Validation loss: 2.706673739497951

Epoch: 6| Step: 1
Training loss: 2.469483664904068
Validation loss: 2.6785964789735397

Epoch: 6| Step: 2
Training loss: 2.755589872790867
Validation loss: 2.7060075288020937

Epoch: 6| Step: 3
Training loss: 3.598614924268634
Validation loss: 2.67214160340608

Epoch: 6| Step: 4
Training loss: 3.2088485568298397
Validation loss: 2.6803594224152687

Epoch: 6| Step: 5
Training loss: 2.2232801369628006
Validation loss: 2.668604422317231

Epoch: 6| Step: 6
Training loss: 2.8027954520239664
Validation loss: 2.6725199938610715

Epoch: 6| Step: 7
Training loss: 2.5505008280486705
Validation loss: 2.702823624723732

Epoch: 6| Step: 8
Training loss: 3.016564099445668
Validation loss: 2.705284653393832

Epoch: 6| Step: 9
Training loss: 2.698659217795293
Validation loss: 2.665680142037769

Epoch: 6| Step: 10
Training loss: 3.234114484384854
Validation loss: 2.687655113191058

Epoch: 6| Step: 11
Training loss: 3.0377878688460784
Validation loss: 2.711835981297799

Epoch: 6| Step: 12
Training loss: 3.8319997679246423
Validation loss: 2.7057158481383374

Epoch: 6| Step: 13
Training loss: 3.0564098917007887
Validation loss: 2.7086513348371133

Epoch: 44| Step: 0
Training loss: 3.339264615358705
Validation loss: 2.759029577807641

Epoch: 6| Step: 1
Training loss: 3.020008439311179
Validation loss: 2.729465745026655

Epoch: 6| Step: 2
Training loss: 3.193150915405454
Validation loss: 2.6912830700307655

Epoch: 6| Step: 3
Training loss: 2.680027620400965
Validation loss: 2.7208888507109905

Epoch: 6| Step: 4
Training loss: 3.060080370377377
Validation loss: 2.7161214056953615

Epoch: 6| Step: 5
Training loss: 2.2931935396761864
Validation loss: 2.696050310916632

Epoch: 6| Step: 6
Training loss: 3.8292711682980727
Validation loss: 2.6880362944526466

Epoch: 6| Step: 7
Training loss: 3.1743713477425954
Validation loss: 2.702490543450132

Epoch: 6| Step: 8
Training loss: 3.1852593119651105
Validation loss: 2.7275944564601913

Epoch: 6| Step: 9
Training loss: 2.1784926116586933
Validation loss: 2.6956330234674497

Epoch: 6| Step: 10
Training loss: 2.729635523545249
Validation loss: 2.7645623054251494

Epoch: 6| Step: 11
Training loss: 2.843921698113364
Validation loss: 2.7221871990383786

Epoch: 6| Step: 12
Training loss: 2.7472077846201297
Validation loss: 2.7091346924544655

Epoch: 6| Step: 13
Training loss: 2.3613507417237813
Validation loss: 2.7192371607569767

Epoch: 45| Step: 0
Training loss: 3.0130009278233643
Validation loss: 2.706161800950732

Epoch: 6| Step: 1
Training loss: 2.946525991571489
Validation loss: 2.6919721171081776

Epoch: 6| Step: 2
Training loss: 2.8592582637116775
Validation loss: 2.7062891746651996

Epoch: 6| Step: 3
Training loss: 2.5899624114088966
Validation loss: 2.664129589134489

Epoch: 6| Step: 4
Training loss: 3.3111811477570536
Validation loss: 2.70829747620377

Epoch: 6| Step: 5
Training loss: 2.773384888915606
Validation loss: 2.709565360610761

Epoch: 6| Step: 6
Training loss: 3.3866549687171013
Validation loss: 2.6371192599386553

Epoch: 6| Step: 7
Training loss: 3.1002365083612378
Validation loss: 2.6991402896731187

Epoch: 6| Step: 8
Training loss: 2.618490412917623
Validation loss: 2.6555160444636097

Epoch: 6| Step: 9
Training loss: 3.305683680240902
Validation loss: 2.7096462774733427

Epoch: 6| Step: 10
Training loss: 2.7241661230790593
Validation loss: 2.691968072567787

Epoch: 6| Step: 11
Training loss: 3.0803778290300814
Validation loss: 2.6645222669718107

Epoch: 6| Step: 12
Training loss: 2.450526714148983
Validation loss: 2.703216607137654

Epoch: 6| Step: 13
Training loss: 3.277899348344671
Validation loss: 2.6848395262628335

Epoch: 46| Step: 0
Training loss: 3.272765607320357
Validation loss: 2.70955279010444

Epoch: 6| Step: 1
Training loss: 2.351282147396143
Validation loss: 2.6813172232312783

Epoch: 6| Step: 2
Training loss: 2.6556234181705323
Validation loss: 2.6974839290153962

Epoch: 6| Step: 3
Training loss: 3.9390541521443176
Validation loss: 2.7293159903041473

Epoch: 6| Step: 4
Training loss: 2.9273519336187985
Validation loss: 2.6953043106047425

Epoch: 6| Step: 5
Training loss: 2.7787468607923835
Validation loss: 2.708733836836552

Epoch: 6| Step: 6
Training loss: 2.333880791699894
Validation loss: 2.677929804063507

Epoch: 6| Step: 7
Training loss: 2.5898111608880017
Validation loss: 2.713444994770248

Epoch: 6| Step: 8
Training loss: 2.6768643379934285
Validation loss: 2.6719637783297965

Epoch: 6| Step: 9
Training loss: 3.1168743540333104
Validation loss: 2.699726366452402

Epoch: 6| Step: 10
Training loss: 2.865475010664578
Validation loss: 2.681471711246193

Epoch: 6| Step: 11
Training loss: 3.0340915221439997
Validation loss: 2.6966594700370146

Epoch: 6| Step: 12
Training loss: 2.9050228030020544
Validation loss: 2.709391892691536

Epoch: 6| Step: 13
Training loss: 3.462491136670388
Validation loss: 2.771854384289533

Epoch: 47| Step: 0
Training loss: 2.2737722248754895
Validation loss: 2.6614234995404122

Epoch: 6| Step: 1
Training loss: 3.0633026939522954
Validation loss: 2.710930360214488

Epoch: 6| Step: 2
Training loss: 3.101300514360241
Validation loss: 2.718458442674699

Epoch: 6| Step: 3
Training loss: 2.5558393488977877
Validation loss: 2.6879666536889157

Epoch: 6| Step: 4
Training loss: 2.343575941616212
Validation loss: 2.7025015284647864

Epoch: 6| Step: 5
Training loss: 3.276641806905619
Validation loss: 2.7066187338366094

Epoch: 6| Step: 6
Training loss: 3.858590729753386
Validation loss: 2.7164808079008527

Epoch: 6| Step: 7
Training loss: 2.9488905161923626
Validation loss: 2.7360854286035265

Epoch: 6| Step: 8
Training loss: 2.7806018545602647
Validation loss: 2.6697779170449376

Epoch: 6| Step: 9
Training loss: 3.146762752709263
Validation loss: 2.6895906520721784

Epoch: 6| Step: 10
Training loss: 2.6787758213352717
Validation loss: 2.71342876319823

Epoch: 6| Step: 11
Training loss: 3.4588375566578966
Validation loss: 2.6769515804293023

Epoch: 6| Step: 12
Training loss: 2.911655935680032
Validation loss: 2.7718250422252093

Epoch: 6| Step: 13
Training loss: 2.4330555426313336
Validation loss: 2.7123933472772186

Epoch: 48| Step: 0
Training loss: 2.3375997593445494
Validation loss: 2.6728862486380853

Epoch: 6| Step: 1
Training loss: 2.757346138141692
Validation loss: 2.7173076212741485

Epoch: 6| Step: 2
Training loss: 1.7170497460687775
Validation loss: 2.663871369268677

Epoch: 6| Step: 3
Training loss: 3.209157037065934
Validation loss: 2.690629795043464

Epoch: 6| Step: 4
Training loss: 2.9565634111726182
Validation loss: 2.693002794946718

Epoch: 6| Step: 5
Training loss: 3.8884927199674357
Validation loss: 2.6940570724703283

Epoch: 6| Step: 6
Training loss: 3.32641299634324
Validation loss: 2.7235827521849862

Epoch: 6| Step: 7
Training loss: 2.5073243613832723
Validation loss: 2.718964681988308

Epoch: 6| Step: 8
Training loss: 2.932269695373577
Validation loss: 2.6703067387561368

Epoch: 6| Step: 9
Training loss: 3.1372237125650866
Validation loss: 2.7340048722004853

Epoch: 6| Step: 10
Training loss: 3.616456586182958
Validation loss: 2.7479357816894034

Epoch: 6| Step: 11
Training loss: 3.1734153878264735
Validation loss: 2.7079746270678684

Epoch: 6| Step: 12
Training loss: 2.2424963761622516
Validation loss: 2.6651662093689388

Epoch: 6| Step: 13
Training loss: 2.7247262799740546
Validation loss: 2.7033538560252808

Epoch: 49| Step: 0
Training loss: 3.3385132755177276
Validation loss: 2.722780098994181

Epoch: 6| Step: 1
Training loss: 2.341961394346077
Validation loss: 2.7275550653569396

Epoch: 6| Step: 2
Training loss: 3.9616091909212594
Validation loss: 2.7122309472351898

Epoch: 6| Step: 3
Training loss: 3.6991109862537304
Validation loss: 2.6947126280105236

Epoch: 6| Step: 4
Training loss: 3.3123138663340597
Validation loss: 2.747229738536008

Epoch: 6| Step: 5
Training loss: 3.06115381665296
Validation loss: 2.6884924011895084

Epoch: 6| Step: 6
Training loss: 3.0201833793088326
Validation loss: 2.692702413211175

Epoch: 6| Step: 7
Training loss: 3.0929562870245717
Validation loss: 2.686283758798001

Epoch: 6| Step: 8
Training loss: 1.9927690442560364
Validation loss: 2.669525377975942

Epoch: 6| Step: 9
Training loss: 2.4447414718652385
Validation loss: 2.734875667459234

Epoch: 6| Step: 10
Training loss: 2.3709054083391323
Validation loss: 2.6781461098515607

Epoch: 6| Step: 11
Training loss: 2.603044517344516
Validation loss: 2.673830229544016

Epoch: 6| Step: 12
Training loss: 2.758328743399713
Validation loss: 2.714047505707714

Epoch: 6| Step: 13
Training loss: 2.0978877616439164
Validation loss: 2.7051637410831195

Epoch: 50| Step: 0
Training loss: 2.4652343053671157
Validation loss: 2.6939673059623757

Epoch: 6| Step: 1
Training loss: 3.2514740462143576
Validation loss: 2.715570510753169

Epoch: 6| Step: 2
Training loss: 2.6308366283178213
Validation loss: 2.7088647587648027

Epoch: 6| Step: 3
Training loss: 2.6841986139720113
Validation loss: 2.6736989335067776

Epoch: 6| Step: 4
Training loss: 2.5653863793570406
Validation loss: 2.7279718133869597

Epoch: 6| Step: 5
Training loss: 3.271921904044623
Validation loss: 2.718608601228469

Epoch: 6| Step: 6
Training loss: 2.948635665145255
Validation loss: 2.7047160446084306

Epoch: 6| Step: 7
Training loss: 3.1973780738663375
Validation loss: 2.7023531311836364

Epoch: 6| Step: 8
Training loss: 3.1381636506606276
Validation loss: 2.6989014877787114

Epoch: 6| Step: 9
Training loss: 3.7691149229694854
Validation loss: 2.701207840321581

Epoch: 6| Step: 10
Training loss: 3.0539823142528255
Validation loss: 2.726475714814313

Epoch: 6| Step: 11
Training loss: 2.886764670537161
Validation loss: 2.638834022720873

Epoch: 6| Step: 12
Training loss: 2.5345010483860566
Validation loss: 2.666127150958955

Epoch: 6| Step: 13
Training loss: 2.085067739141019
Validation loss: 2.69818565410942

Epoch: 51| Step: 0
Training loss: 3.1179816207295117
Validation loss: 2.71900131616119

Epoch: 6| Step: 1
Training loss: 2.796763668295265
Validation loss: 2.7005608611529657

Epoch: 6| Step: 2
Training loss: 2.356518057796284
Validation loss: 2.684559397355816

Epoch: 6| Step: 3
Training loss: 2.758621486199198
Validation loss: 2.69297379321948

Epoch: 6| Step: 4
Training loss: 3.1875933465191943
Validation loss: 2.6801058429729965

Epoch: 6| Step: 5
Training loss: 3.4247734997332446
Validation loss: 2.6825843167930086

Epoch: 6| Step: 6
Training loss: 3.071411246824355
Validation loss: 2.6891644573198463

Epoch: 6| Step: 7
Training loss: 2.9504702306427664
Validation loss: 2.714176309641933

Epoch: 6| Step: 8
Training loss: 3.038829333620444
Validation loss: 2.7249868974034803

Epoch: 6| Step: 9
Training loss: 3.2531819539210196
Validation loss: 2.7101884500786664

Epoch: 6| Step: 10
Training loss: 2.848906484593516
Validation loss: 2.669130283900313

Epoch: 6| Step: 11
Training loss: 3.1782541254419336
Validation loss: 2.706632394902023

Epoch: 6| Step: 12
Training loss: 2.6990147029084732
Validation loss: 2.675687276915959

Epoch: 6| Step: 13
Training loss: 1.935377127000901
Validation loss: 2.6898144226037535

Epoch: 52| Step: 0
Training loss: 2.606017917023998
Validation loss: 2.74995642149284

Epoch: 6| Step: 1
Training loss: 3.1226872850850964
Validation loss: 2.702512779046638

Epoch: 6| Step: 2
Training loss: 1.8779126750236945
Validation loss: 2.713524260701398

Epoch: 6| Step: 3
Training loss: 2.6678932369152033
Validation loss: 2.685842530921144

Epoch: 6| Step: 4
Training loss: 3.2072773140890414
Validation loss: 2.6625639120601274

Epoch: 6| Step: 5
Training loss: 2.4052882068225503
Validation loss: 2.6860720500820774

Epoch: 6| Step: 6
Training loss: 3.582189125899946
Validation loss: 2.66329296828066

Epoch: 6| Step: 7
Training loss: 2.8323804337533454
Validation loss: 2.7124323130317327

Epoch: 6| Step: 8
Training loss: 3.222675633227693
Validation loss: 2.729772591759212

Epoch: 6| Step: 9
Training loss: 2.921151627535737
Validation loss: 2.7259177513309236

Epoch: 6| Step: 10
Training loss: 3.2500322780473443
Validation loss: 2.6514745513136635

Epoch: 6| Step: 11
Training loss: 3.523443995975165
Validation loss: 2.6878578933124517

Epoch: 6| Step: 12
Training loss: 2.548565824027195
Validation loss: 2.718379032039117

Epoch: 6| Step: 13
Training loss: 3.2008052706777304
Validation loss: 2.6903221554201417

Epoch: 53| Step: 0
Training loss: 3.1619097132378666
Validation loss: 2.683648433755968

Epoch: 6| Step: 1
Training loss: 2.96815709668443
Validation loss: 2.734324551305929

Epoch: 6| Step: 2
Training loss: 2.7852634232754596
Validation loss: 2.6570184531049033

Epoch: 6| Step: 3
Training loss: 3.204593228906962
Validation loss: 2.682722722529776

Epoch: 6| Step: 4
Training loss: 3.0469166288221876
Validation loss: 2.6859282838729786

Epoch: 6| Step: 5
Training loss: 3.0541236142345958
Validation loss: 2.7255188900160268

Epoch: 6| Step: 6
Training loss: 3.083774397637165
Validation loss: 2.692446319487975

Epoch: 6| Step: 7
Training loss: 2.8547278824712845
Validation loss: 2.6362814482516

Epoch: 6| Step: 8
Training loss: 3.5194074162281024
Validation loss: 2.67264574792606

Epoch: 6| Step: 9
Training loss: 2.6109822514258387
Validation loss: 2.6912014505273216

Epoch: 6| Step: 10
Training loss: 2.4890916304191784
Validation loss: 2.729083457216227

Epoch: 6| Step: 11
Training loss: 2.453290897275342
Validation loss: 2.6956762799842258

Epoch: 6| Step: 12
Training loss: 2.7896437266400222
Validation loss: 2.7062677430916864

Epoch: 6| Step: 13
Training loss: 3.3006924047307065
Validation loss: 2.643238653463695

Epoch: 54| Step: 0
Training loss: 2.830736503603264
Validation loss: 2.6806149661486995

Epoch: 6| Step: 1
Training loss: 2.70232198617668
Validation loss: 2.698481353649104

Epoch: 6| Step: 2
Training loss: 2.302691820833743
Validation loss: 2.703347396071533

Epoch: 6| Step: 3
Training loss: 2.9486259622589666
Validation loss: 2.7318250353827853

Epoch: 6| Step: 4
Training loss: 3.462350939905846
Validation loss: 2.691863655230556

Epoch: 6| Step: 5
Training loss: 2.5424143103279033
Validation loss: 2.6997279000442878

Epoch: 6| Step: 6
Training loss: 2.942937485316409
Validation loss: 2.6854145957311077

Epoch: 6| Step: 7
Training loss: 3.0544389784614343
Validation loss: 2.675465274169817

Epoch: 6| Step: 8
Training loss: 2.947592098489401
Validation loss: 2.689234078504667

Epoch: 6| Step: 9
Training loss: 3.2709757941903512
Validation loss: 2.6659758635049315

Epoch: 6| Step: 10
Training loss: 2.5987340082407737
Validation loss: 2.705249104749784

Epoch: 6| Step: 11
Training loss: 2.788613333984662
Validation loss: 2.69543483385767

Epoch: 6| Step: 12
Training loss: 2.40608670559963
Validation loss: 2.711719320412419

Epoch: 6| Step: 13
Training loss: 3.672193407903351
Validation loss: 2.6692814204228394

Epoch: 55| Step: 0
Training loss: 3.0281212774200705
Validation loss: 2.700374317390368

Epoch: 6| Step: 1
Training loss: 2.8134950361138555
Validation loss: 2.7200213439376624

Epoch: 6| Step: 2
Training loss: 2.9722163793520275
Validation loss: 2.6488042760097237

Epoch: 6| Step: 3
Training loss: 4.152356381903998
Validation loss: 2.6900844619512627

Epoch: 6| Step: 4
Training loss: 2.572660075583627
Validation loss: 2.7283887176311574

Epoch: 6| Step: 5
Training loss: 3.1616070297105145
Validation loss: 2.6746358299068183

Epoch: 6| Step: 6
Training loss: 3.0511407188589805
Validation loss: 2.6605986552124503

Epoch: 6| Step: 7
Training loss: 2.5684227765166394
Validation loss: 2.71035585129887

Epoch: 6| Step: 8
Training loss: 3.032325946942138
Validation loss: 2.7349870138071313

Epoch: 6| Step: 9
Training loss: 2.6833736768102563
Validation loss: 2.6972278287789515

Epoch: 6| Step: 10
Training loss: 2.9039074060059575
Validation loss: 2.681144497875795

Epoch: 6| Step: 11
Training loss: 2.335176886285165
Validation loss: 2.6978416053921164

Epoch: 6| Step: 12
Training loss: 2.8830227245397153
Validation loss: 2.7142150816746993

Epoch: 6| Step: 13
Training loss: 2.2846944228171644
Validation loss: 2.693918753731028

Epoch: 56| Step: 0
Training loss: 3.1451604936218516
Validation loss: 2.668375544118249

Epoch: 6| Step: 1
Training loss: 2.336795406939868
Validation loss: 2.663697909656021

Epoch: 6| Step: 2
Training loss: 3.2511095940508214
Validation loss: 2.6662807307097736

Epoch: 6| Step: 3
Training loss: 2.6113383507653185
Validation loss: 2.7164766210130193

Epoch: 6| Step: 4
Training loss: 2.4848996933892633
Validation loss: 2.7128136303189083

Epoch: 6| Step: 5
Training loss: 3.2637842274291557
Validation loss: 2.730355666386759

Epoch: 6| Step: 6
Training loss: 2.8960316176190175
Validation loss: 2.63819648439637

Epoch: 6| Step: 7
Training loss: 2.262564650818469
Validation loss: 2.7004948726512215

Epoch: 6| Step: 8
Training loss: 2.7838085279063187
Validation loss: 2.669528449127879

Epoch: 6| Step: 9
Training loss: 3.196203429382978
Validation loss: 2.7044315835273274

Epoch: 6| Step: 10
Training loss: 3.201937720603881
Validation loss: 2.7495094278459016

Epoch: 6| Step: 11
Training loss: 3.5929467671902393
Validation loss: 2.674569959960874

Epoch: 6| Step: 12
Training loss: 2.5034423017426017
Validation loss: 2.6859209516168043

Epoch: 6| Step: 13
Training loss: 3.5553939620358195
Validation loss: 2.6998372110903897

Epoch: 57| Step: 0
Training loss: 3.4739877832051866
Validation loss: 2.6899888537538486

Epoch: 6| Step: 1
Training loss: 2.7369878873435094
Validation loss: 2.6756084221352974

Epoch: 6| Step: 2
Training loss: 2.923374709123243
Validation loss: 2.6495977085542903

Epoch: 6| Step: 3
Training loss: 1.9629581572649102
Validation loss: 2.748375356802361

Epoch: 6| Step: 4
Training loss: 3.076420190870535
Validation loss: 2.666054069490969

Epoch: 6| Step: 5
Training loss: 3.2207906235745534
Validation loss: 2.6550632689870586

Epoch: 6| Step: 6
Training loss: 2.6426171908201193
Validation loss: 2.691644191530644

Epoch: 6| Step: 7
Training loss: 2.7595337421381574
Validation loss: 2.718649445907726

Epoch: 6| Step: 8
Training loss: 3.0766652320150363
Validation loss: 2.677396344613429

Epoch: 6| Step: 9
Training loss: 3.2894101355588043
Validation loss: 2.6497306274317536

Epoch: 6| Step: 10
Training loss: 3.166802018602428
Validation loss: 2.6884377349072124

Epoch: 6| Step: 11
Training loss: 2.0099651508251926
Validation loss: 2.7120009100238485

Epoch: 6| Step: 12
Training loss: 3.8026666620512217
Validation loss: 2.7333750425478422

Epoch: 6| Step: 13
Training loss: 2.166312029743449
Validation loss: 2.6968697791654486

Epoch: 58| Step: 0
Training loss: 3.304378846817274
Validation loss: 2.661190494763797

Epoch: 6| Step: 1
Training loss: 2.9381734197863083
Validation loss: 2.6941260034177588

Epoch: 6| Step: 2
Training loss: 2.4372722812799767
Validation loss: 2.7247406829280005

Epoch: 6| Step: 3
Training loss: 2.6858417806828863
Validation loss: 2.7039632043581245

Epoch: 6| Step: 4
Training loss: 2.6282585445770614
Validation loss: 2.7009958890510117

Epoch: 6| Step: 5
Training loss: 2.810629413339154
Validation loss: 2.6797769379050402

Epoch: 6| Step: 6
Training loss: 2.885267912591342
Validation loss: 2.700427595223842

Epoch: 6| Step: 7
Training loss: 3.203554896837384
Validation loss: 2.7099358984845376

Epoch: 6| Step: 8
Training loss: 3.6135876664838587
Validation loss: 2.72603784843386

Epoch: 6| Step: 9
Training loss: 2.6410467950848817
Validation loss: 2.6436102518408813

Epoch: 6| Step: 10
Training loss: 3.289599449564372
Validation loss: 2.6929909248864297

Epoch: 6| Step: 11
Training loss: 2.839960948514418
Validation loss: 2.6297873377053187

Epoch: 6| Step: 12
Training loss: 2.5955087604760667
Validation loss: 2.68715411567238

Epoch: 6| Step: 13
Training loss: 2.9740899497245765
Validation loss: 2.63606841762783

Epoch: 59| Step: 0
Training loss: 3.5897843747215
Validation loss: 2.6850243202657555

Epoch: 6| Step: 1
Training loss: 2.8759220137547574
Validation loss: 2.6807830359169476

Epoch: 6| Step: 2
Training loss: 2.434574425575647
Validation loss: 2.6710627142143033

Epoch: 6| Step: 3
Training loss: 2.2482117858374178
Validation loss: 2.6536675143888577

Epoch: 6| Step: 4
Training loss: 2.2306318607582876
Validation loss: 2.662393617562839

Epoch: 6| Step: 5
Training loss: 4.283468520904534
Validation loss: 2.6986422712580693

Epoch: 6| Step: 6
Training loss: 3.173438076994039
Validation loss: 2.6893200026192883

Epoch: 6| Step: 7
Training loss: 2.6013033167861934
Validation loss: 2.6819937795750874

Epoch: 6| Step: 8
Training loss: 2.5024554591831025
Validation loss: 2.7051698716445443

Epoch: 6| Step: 9
Training loss: 3.1301634283330526
Validation loss: 2.6604798054095

Epoch: 6| Step: 10
Training loss: 2.7733085494890295
Validation loss: 2.655060875346171

Epoch: 6| Step: 11
Training loss: 2.6148775297410074
Validation loss: 2.693457224979987

Epoch: 6| Step: 12
Training loss: 2.8035436651436236
Validation loss: 2.7508253600365

Epoch: 6| Step: 13
Training loss: 3.395145338765027
Validation loss: 2.677050386378276

Epoch: 60| Step: 0
Training loss: 3.1358132011287037
Validation loss: 2.6849454207968613

Epoch: 6| Step: 1
Training loss: 2.8858879246194498
Validation loss: 2.7085522117548195

Epoch: 6| Step: 2
Training loss: 2.1843538820831276
Validation loss: 2.7226161207909674

Epoch: 6| Step: 3
Training loss: 2.800627508692266
Validation loss: 2.7054467777169444

Epoch: 6| Step: 4
Training loss: 2.715142849699607
Validation loss: 2.6663218472051033

Epoch: 6| Step: 5
Training loss: 3.2021372691079253
Validation loss: 2.715597948551127

Epoch: 6| Step: 6
Training loss: 2.7316268625980533
Validation loss: 2.6952230126243193

Epoch: 6| Step: 7
Training loss: 3.403202618571118
Validation loss: 2.7104501310087357

Epoch: 6| Step: 8
Training loss: 2.8534469439565715
Validation loss: 2.6920724068147006

Epoch: 6| Step: 9
Training loss: 2.6074055989075338
Validation loss: 2.6925150931518558

Epoch: 6| Step: 10
Training loss: 3.0820968485572804
Validation loss: 2.67947297385725

Epoch: 6| Step: 11
Training loss: 3.2766383142754902
Validation loss: 2.7139898421375483

Epoch: 6| Step: 12
Training loss: 3.5112078913563693
Validation loss: 2.6766587754624154

Epoch: 6| Step: 13
Training loss: 2.1508436011752012
Validation loss: 2.67393808161176

Epoch: 61| Step: 0
Training loss: 2.7897965349503355
Validation loss: 2.68225949382911

Epoch: 6| Step: 1
Training loss: 3.702575771630545
Validation loss: 2.6820954517566475

Epoch: 6| Step: 2
Training loss: 3.6263609337497242
Validation loss: 2.685544215464837

Epoch: 6| Step: 3
Training loss: 2.3267140049021733
Validation loss: 2.7032192900657406

Epoch: 6| Step: 4
Training loss: 2.781337179467799
Validation loss: 2.7296392840509816

Epoch: 6| Step: 5
Training loss: 2.1553981038013283
Validation loss: 2.693412803968225

Epoch: 6| Step: 6
Training loss: 2.8958221728066373
Validation loss: 2.6970906398051677

Epoch: 6| Step: 7
Training loss: 3.2581008307846413
Validation loss: 2.7358215321696457

Epoch: 6| Step: 8
Training loss: 3.256012124069473
Validation loss: 2.7264768563095636

Epoch: 6| Step: 9
Training loss: 2.354099869132076
Validation loss: 2.664944298887478

Epoch: 6| Step: 10
Training loss: 2.378085792007759
Validation loss: 2.7177559300349574

Epoch: 6| Step: 11
Training loss: 3.073849259581524
Validation loss: 2.666012940211437

Epoch: 6| Step: 12
Training loss: 3.0810237344919043
Validation loss: 2.704363602057064

Epoch: 6| Step: 13
Training loss: 2.886063063801577
Validation loss: 2.688392813282112

Epoch: 62| Step: 0
Training loss: 3.142164318088358
Validation loss: 2.65135698751819

Epoch: 6| Step: 1
Training loss: 2.6468507407561828
Validation loss: 2.7206656713401602

Epoch: 6| Step: 2
Training loss: 2.3711040062973194
Validation loss: 2.653610116864236

Epoch: 6| Step: 3
Training loss: 2.490011861995034
Validation loss: 2.70306827566974

Epoch: 6| Step: 4
Training loss: 2.866894449750591
Validation loss: 2.708416320501176

Epoch: 6| Step: 5
Training loss: 3.8369074758549346
Validation loss: 2.6915984709680973

Epoch: 6| Step: 6
Training loss: 2.4717866594851072
Validation loss: 2.7396696493443495

Epoch: 6| Step: 7
Training loss: 2.4845719169453786
Validation loss: 2.6416780687839614

Epoch: 6| Step: 8
Training loss: 2.96983333698012
Validation loss: 2.6695127476103795

Epoch: 6| Step: 9
Training loss: 2.446388373576718
Validation loss: 2.684578947178421

Epoch: 6| Step: 10
Training loss: 3.1674974422549886
Validation loss: 2.6682655062412945

Epoch: 6| Step: 11
Training loss: 3.6369025719687853
Validation loss: 2.69053890084845

Epoch: 6| Step: 12
Training loss: 2.406067680288505
Validation loss: 2.6814899154716705

Epoch: 6| Step: 13
Training loss: 3.2777912620942367
Validation loss: 2.64573467678874

Epoch: 63| Step: 0
Training loss: 2.87368512147176
Validation loss: 2.6920937076113387

Epoch: 6| Step: 1
Training loss: 3.854926012172759
Validation loss: 2.6602272288160336

Epoch: 6| Step: 2
Training loss: 2.7964686093163724
Validation loss: 2.6830091498696

Epoch: 6| Step: 3
Training loss: 2.5714876682817285
Validation loss: 2.6797393484799996

Epoch: 6| Step: 4
Training loss: 2.9957704929203843
Validation loss: 2.7295579577326836

Epoch: 6| Step: 5
Training loss: 3.224292316711299
Validation loss: 2.69036792530659

Epoch: 6| Step: 6
Training loss: 2.5768855034139717
Validation loss: 2.7012915405286995

Epoch: 6| Step: 7
Training loss: 3.334462324320005
Validation loss: 2.707535175691171

Epoch: 6| Step: 8
Training loss: 3.139440664295369
Validation loss: 2.6991078353224975

Epoch: 6| Step: 9
Training loss: 3.065089629513415
Validation loss: 2.6805017715179753

Epoch: 6| Step: 10
Training loss: 2.603659394766819
Validation loss: 2.6790244109222114

Epoch: 6| Step: 11
Training loss: 2.6691958731693863
Validation loss: 2.678197630169517

Epoch: 6| Step: 12
Training loss: 1.9286349124652478
Validation loss: 2.6897894571957766

Epoch: 6| Step: 13
Training loss: 2.9245121932210063
Validation loss: 2.6674645528706153

Epoch: 64| Step: 0
Training loss: 3.384682788044338
Validation loss: 2.669046653779866

Epoch: 6| Step: 1
Training loss: 3.503946667696447
Validation loss: 2.6986369675466864

Epoch: 6| Step: 2
Training loss: 2.379945725214813
Validation loss: 2.731464227347244

Epoch: 6| Step: 3
Training loss: 3.2547068624154014
Validation loss: 2.7030774117721204

Epoch: 6| Step: 4
Training loss: 2.5714420515040124
Validation loss: 2.6962949508186305

Epoch: 6| Step: 5
Training loss: 2.6464830236677823
Validation loss: 2.682403836093728

Epoch: 6| Step: 6
Training loss: 2.5217177255742933
Validation loss: 2.7140371048945124

Epoch: 6| Step: 7
Training loss: 2.9078117194320723
Validation loss: 2.688878613201523

Epoch: 6| Step: 8
Training loss: 2.4954805531341164
Validation loss: 2.727010955021785

Epoch: 6| Step: 9
Training loss: 2.6902209856950003
Validation loss: 2.665381454184421

Epoch: 6| Step: 10
Training loss: 3.078786401320503
Validation loss: 2.686057168725669

Epoch: 6| Step: 11
Training loss: 2.5390249396260307
Validation loss: 2.6943349384326125

Epoch: 6| Step: 12
Training loss: 2.747502233002773
Validation loss: 2.719568855554553

Epoch: 6| Step: 13
Training loss: 3.654425010697781
Validation loss: 2.69540224738833

Epoch: 65| Step: 0
Training loss: 2.7718137474130367
Validation loss: 2.696903451058839

Epoch: 6| Step: 1
Training loss: 3.5709268053982455
Validation loss: 2.626693019454699

Epoch: 6| Step: 2
Training loss: 2.540357429706793
Validation loss: 2.6589750833082255

Epoch: 6| Step: 3
Training loss: 3.119308629584306
Validation loss: 2.6739614088790034

Epoch: 6| Step: 4
Training loss: 2.3232033956014235
Validation loss: 2.7274996358195733

Epoch: 6| Step: 5
Training loss: 2.0750462952010933
Validation loss: 2.716878571038398

Epoch: 6| Step: 6
Training loss: 3.3415520119598336
Validation loss: 2.6784037685318425

Epoch: 6| Step: 7
Training loss: 2.996944301786447
Validation loss: 2.6734984725524056

Epoch: 6| Step: 8
Training loss: 2.7392476290753223
Validation loss: 2.6699058147614454

Epoch: 6| Step: 9
Training loss: 3.645252610232551
Validation loss: 2.65504719514982

Epoch: 6| Step: 10
Training loss: 2.6383615758865853
Validation loss: 2.7352267587344827

Epoch: 6| Step: 11
Training loss: 2.1205949565671696
Validation loss: 2.701060063876093

Epoch: 6| Step: 12
Training loss: 3.41208422017774
Validation loss: 2.704973864964483

Epoch: 6| Step: 13
Training loss: 2.9995172430077934
Validation loss: 2.698966159787758

Epoch: 66| Step: 0
Training loss: 2.6968703038958246
Validation loss: 2.6478533899121857

Epoch: 6| Step: 1
Training loss: 2.5288792563651445
Validation loss: 2.649085511979759

Epoch: 6| Step: 2
Training loss: 3.5595634805747194
Validation loss: 2.7051085786729296

Epoch: 6| Step: 3
Training loss: 2.4201980199268736
Validation loss: 2.6476645375471617

Epoch: 6| Step: 4
Training loss: 3.0375031145495863
Validation loss: 2.661240825615395

Epoch: 6| Step: 5
Training loss: 2.6982455452046605
Validation loss: 2.686631230404305

Epoch: 6| Step: 6
Training loss: 3.1361916599191737
Validation loss: 2.6334144534878186

Epoch: 6| Step: 7
Training loss: 2.928147544489069
Validation loss: 2.7196212313673906

Epoch: 6| Step: 8
Training loss: 2.3243757948190673
Validation loss: 2.67020833325243

Epoch: 6| Step: 9
Training loss: 3.161011531790697
Validation loss: 2.7265537180842743

Epoch: 6| Step: 10
Training loss: 3.0163412083645844
Validation loss: 2.7171123826246197

Epoch: 6| Step: 11
Training loss: 2.3991980325393776
Validation loss: 2.604341921579966

Epoch: 6| Step: 12
Training loss: 3.616116655662314
Validation loss: 2.64059551717929

Epoch: 6| Step: 13
Training loss: 2.5713797443537683
Validation loss: 2.7461446219613714

Epoch: 67| Step: 0
Training loss: 3.3507710836251405
Validation loss: 2.6883721430557337

Epoch: 6| Step: 1
Training loss: 3.0779364668527407
Validation loss: 2.7031120566957365

Epoch: 6| Step: 2
Training loss: 2.4151651277815156
Validation loss: 2.616368565320316

Epoch: 6| Step: 3
Training loss: 2.2877278782472508
Validation loss: 2.7081622802508174

Epoch: 6| Step: 4
Training loss: 2.3418110265614422
Validation loss: 2.691858741015184

Epoch: 6| Step: 5
Training loss: 2.512394981656698
Validation loss: 2.6601444521372786

Epoch: 6| Step: 6
Training loss: 2.492832973205346
Validation loss: 2.650683991118179

Epoch: 6| Step: 7
Training loss: 2.7705251957398787
Validation loss: 2.6989376486323

Epoch: 6| Step: 8
Training loss: 2.4725282946318585
Validation loss: 2.680803127765929

Epoch: 6| Step: 9
Training loss: 4.002815686082491
Validation loss: 2.623792178047186

Epoch: 6| Step: 10
Training loss: 2.1131758742934297
Validation loss: 2.693479774050194

Epoch: 6| Step: 11
Training loss: 3.258927042563242
Validation loss: 2.638779489148966

Epoch: 6| Step: 12
Training loss: 3.3974234635670455
Validation loss: 2.7066396786284717

Epoch: 6| Step: 13
Training loss: 3.915521954933394
Validation loss: 2.6730513517075747

Epoch: 68| Step: 0
Training loss: 2.9944215407603405
Validation loss: 2.722604013551782

Epoch: 6| Step: 1
Training loss: 2.5064784033906653
Validation loss: 2.6590191714186537

Epoch: 6| Step: 2
Training loss: 4.228802043561842
Validation loss: 2.652579531028264

Epoch: 6| Step: 3
Training loss: 3.0486990921506143
Validation loss: 2.6760119635790347

Epoch: 6| Step: 4
Training loss: 2.2294992454306812
Validation loss: 2.679545123904306

Epoch: 6| Step: 5
Training loss: 2.8599496066048675
Validation loss: 2.712095887811338

Epoch: 6| Step: 6
Training loss: 2.7274431702788657
Validation loss: 2.7139105680782794

Epoch: 6| Step: 7
Training loss: 3.499130413475996
Validation loss: 2.6251643618191207

Epoch: 6| Step: 8
Training loss: 2.2538527246000375
Validation loss: 2.7050026991754152

Epoch: 6| Step: 9
Training loss: 2.760921638412983
Validation loss: 2.6723080859589707

Epoch: 6| Step: 10
Training loss: 2.70755382959847
Validation loss: 2.7012044758593663

Epoch: 6| Step: 11
Training loss: 3.176091440590031
Validation loss: 2.6650478662735253

Epoch: 6| Step: 12
Training loss: 2.625722694822319
Validation loss: 2.7233868855599557

Epoch: 6| Step: 13
Training loss: 2.4977647325273886
Validation loss: 2.6818809174867915

Epoch: 69| Step: 0
Training loss: 3.0303047515401866
Validation loss: 2.6997188380704333

Epoch: 6| Step: 1
Training loss: 2.6847529010979043
Validation loss: 2.675575072474966

Epoch: 6| Step: 2
Training loss: 2.369635496478189
Validation loss: 2.702297556590293

Epoch: 6| Step: 3
Training loss: 3.122410426080544
Validation loss: 2.65488516230726

Epoch: 6| Step: 4
Training loss: 2.930460998150654
Validation loss: 2.6940821082390927

Epoch: 6| Step: 5
Training loss: 2.9601742206026995
Validation loss: 2.6525165299151654

Epoch: 6| Step: 6
Training loss: 3.0270134333402883
Validation loss: 2.729593372467171

Epoch: 6| Step: 7
Training loss: 3.7402713465046085
Validation loss: 2.669630414552017

Epoch: 6| Step: 8
Training loss: 3.3662081044193184
Validation loss: 2.6875444405218407

Epoch: 6| Step: 9
Training loss: 3.0077319642221307
Validation loss: 2.7040296628472684

Epoch: 6| Step: 10
Training loss: 2.2590547200094173
Validation loss: 2.680041968949577

Epoch: 6| Step: 11
Training loss: 3.184464748566591
Validation loss: 2.6889436177980537

Epoch: 6| Step: 12
Training loss: 2.289971389258618
Validation loss: 2.6465438619947323

Epoch: 6| Step: 13
Training loss: 2.4349781586844395
Validation loss: 2.7091142694386225

Epoch: 70| Step: 0
Training loss: 2.949668839827352
Validation loss: 2.6595451305091737

Epoch: 6| Step: 1
Training loss: 2.4451208069956833
Validation loss: 2.6990117241987015

Epoch: 6| Step: 2
Training loss: 2.5737222705030924
Validation loss: 2.6843263785219147

Epoch: 6| Step: 3
Training loss: 3.537810855862064
Validation loss: 2.6769884208464845

Epoch: 6| Step: 4
Training loss: 2.4463337968402317
Validation loss: 2.6920808879192495

Epoch: 6| Step: 5
Training loss: 2.7421958466753313
Validation loss: 2.6809184555088863

Epoch: 6| Step: 6
Training loss: 3.5703157053459353
Validation loss: 2.6781196074491853

Epoch: 6| Step: 7
Training loss: 2.4897464289106708
Validation loss: 2.7101476301801566

Epoch: 6| Step: 8
Training loss: 3.462165838429125
Validation loss: 2.6987727518151448

Epoch: 6| Step: 9
Training loss: 2.6070577417204537
Validation loss: 2.733182739877198

Epoch: 6| Step: 10
Training loss: 2.7472742617257246
Validation loss: 2.6495229723185063

Epoch: 6| Step: 11
Training loss: 2.7292316128135066
Validation loss: 2.6789923583375392

Epoch: 6| Step: 12
Training loss: 2.9829190682287274
Validation loss: 2.6788106527897035

Epoch: 6| Step: 13
Training loss: 2.3441096729230497
Validation loss: 2.6978980319637484

Epoch: 71| Step: 0
Training loss: 3.3633583760030223
Validation loss: 2.655714927215748

Epoch: 6| Step: 1
Training loss: 2.4041242250853707
Validation loss: 2.65604313835719

Epoch: 6| Step: 2
Training loss: 2.788575458476239
Validation loss: 2.6890208011480206

Epoch: 6| Step: 3
Training loss: 3.3043333905469936
Validation loss: 2.696401150375472

Epoch: 6| Step: 4
Training loss: 2.766970377265458
Validation loss: 2.7035093245894326

Epoch: 6| Step: 5
Training loss: 2.6756474148213067
Validation loss: 2.6706332804493176

Epoch: 6| Step: 6
Training loss: 2.581735937454609
Validation loss: 2.6927687521412995

Epoch: 6| Step: 7
Training loss: 2.793594396981457
Validation loss: 2.7009036641371362

Epoch: 6| Step: 8
Training loss: 3.839000962555614
Validation loss: 2.6828163440642476

Epoch: 6| Step: 9
Training loss: 2.7331248886209565
Validation loss: 2.680146453720699

Epoch: 6| Step: 10
Training loss: 2.9687083994309797
Validation loss: 2.6673272766915446

Epoch: 6| Step: 11
Training loss: 2.9112885800430472
Validation loss: 2.701254757286771

Epoch: 6| Step: 12
Training loss: 2.5381391049284114
Validation loss: 2.6802213068914256

Epoch: 6| Step: 13
Training loss: 2.6116763262964655
Validation loss: 2.672971486922315

Epoch: 72| Step: 0
Training loss: 2.3331188943508647
Validation loss: 2.6886729156083122

Epoch: 6| Step: 1
Training loss: 3.2935299649656984
Validation loss: 2.7039600699216653

Epoch: 6| Step: 2
Training loss: 2.0281738463457653
Validation loss: 2.6845038182430376

Epoch: 6| Step: 3
Training loss: 3.600593883483909
Validation loss: 2.6393742519948526

Epoch: 6| Step: 4
Training loss: 3.3854643050534463
Validation loss: 2.7121145888062754

Epoch: 6| Step: 5
Training loss: 2.2666844488830167
Validation loss: 2.6890860034642676

Epoch: 6| Step: 6
Training loss: 2.840427008213599
Validation loss: 2.7056546414410354

Epoch: 6| Step: 7
Training loss: 2.1965673803757446
Validation loss: 2.658873472894616

Epoch: 6| Step: 8
Training loss: 2.9398125818421526
Validation loss: 2.675753605113477

Epoch: 6| Step: 9
Training loss: 2.717489893244362
Validation loss: 2.6752607080723103

Epoch: 6| Step: 10
Training loss: 2.7555328543387634
Validation loss: 2.641330419679567

Epoch: 6| Step: 11
Training loss: 3.528878284788601
Validation loss: 2.6527721745214

Epoch: 6| Step: 12
Training loss: 3.516173731047597
Validation loss: 2.678616877696177

Epoch: 6| Step: 13
Training loss: 2.760553656483773
Validation loss: 2.659035070841937

Epoch: 73| Step: 0
Training loss: 3.2999585813755217
Validation loss: 2.621313742366585

Epoch: 6| Step: 1
Training loss: 2.578645780734531
Validation loss: 2.702841078100487

Epoch: 6| Step: 2
Training loss: 3.1386196129749733
Validation loss: 2.6935212815111957

Epoch: 6| Step: 3
Training loss: 2.9335674178037574
Validation loss: 2.665017054862869

Epoch: 6| Step: 4
Training loss: 2.7818789681736504
Validation loss: 2.6587327138758443

Epoch: 6| Step: 5
Training loss: 2.4137134484833034
Validation loss: 2.6821551276935063

Epoch: 6| Step: 6
Training loss: 2.1960078865562807
Validation loss: 2.6717160843362264

Epoch: 6| Step: 7
Training loss: 3.292731406639778
Validation loss: 2.690655089943491

Epoch: 6| Step: 8
Training loss: 2.506469462006459
Validation loss: 2.7042018450922827

Epoch: 6| Step: 9
Training loss: 3.806459989220448
Validation loss: 2.6451377319234277

Epoch: 6| Step: 10
Training loss: 2.2286029233558486
Validation loss: 2.6974144951010484

Epoch: 6| Step: 11
Training loss: 2.5056848740269086
Validation loss: 2.6346588666533566

Epoch: 6| Step: 12
Training loss: 2.9586585139259256
Validation loss: 2.6182516756492435

Epoch: 6| Step: 13
Training loss: 3.2235181730884417
Validation loss: 2.6817295694942556

Epoch: 74| Step: 0
Training loss: 2.606086074467411
Validation loss: 2.7041601925127483

Epoch: 6| Step: 1
Training loss: 2.697186512377305
Validation loss: 2.690078854514978

Epoch: 6| Step: 2
Training loss: 2.997156225858056
Validation loss: 2.683888990646978

Epoch: 6| Step: 3
Training loss: 2.613550739619741
Validation loss: 2.65300866153649

Epoch: 6| Step: 4
Training loss: 2.7329769375131954
Validation loss: 2.646309122280389

Epoch: 6| Step: 5
Training loss: 2.8563055855248387
Validation loss: 2.6713871865874315

Epoch: 6| Step: 6
Training loss: 3.0725802135006983
Validation loss: 2.67388566330811

Epoch: 6| Step: 7
Training loss: 2.8209730732581635
Validation loss: 2.678447970422788

Epoch: 6| Step: 8
Training loss: 2.597643951157445
Validation loss: 2.6683991890209606

Epoch: 6| Step: 9
Training loss: 3.0617727856492523
Validation loss: 2.665409232617132

Epoch: 6| Step: 10
Training loss: 3.1712327128334987
Validation loss: 2.724712552499347

Epoch: 6| Step: 11
Training loss: 3.389497631062604
Validation loss: 2.7199719165079688

Epoch: 6| Step: 12
Training loss: 2.983924392315049
Validation loss: 2.6644133390713507

Epoch: 6| Step: 13
Training loss: 2.0719963855196384
Validation loss: 2.6636103226262415

Epoch: 75| Step: 0
Training loss: 2.9051475484805214
Validation loss: 2.664763325752352

Epoch: 6| Step: 1
Training loss: 3.277960881724225
Validation loss: 2.69421712866329

Epoch: 6| Step: 2
Training loss: 3.3689389375773064
Validation loss: 2.716680606444159

Epoch: 6| Step: 3
Training loss: 2.826881936381279
Validation loss: 2.655557849904953

Epoch: 6| Step: 4
Training loss: 2.613883686049235
Validation loss: 2.6697785095159765

Epoch: 6| Step: 5
Training loss: 2.375216825525981
Validation loss: 2.6702163931968115

Epoch: 6| Step: 6
Training loss: 2.3405528323528944
Validation loss: 2.6713135234950824

Epoch: 6| Step: 7
Training loss: 2.2599746224995627
Validation loss: 2.6726463157810016

Epoch: 6| Step: 8
Training loss: 2.4094232220406893
Validation loss: 2.69988281492474

Epoch: 6| Step: 9
Training loss: 2.8018891977515903
Validation loss: 2.6627375538583578

Epoch: 6| Step: 10
Training loss: 3.0925509508603075
Validation loss: 2.6599787416656477

Epoch: 6| Step: 11
Training loss: 4.126214744419567
Validation loss: 2.711172724140314

Epoch: 6| Step: 12
Training loss: 2.4749493564857423
Validation loss: 2.6696723706004044

Epoch: 6| Step: 13
Training loss: 2.8045570959521515
Validation loss: 2.6432360415589264

Epoch: 76| Step: 0
Training loss: 2.0945940736073227
Validation loss: 2.6629721219532407

Epoch: 6| Step: 1
Training loss: 3.558807333138367
Validation loss: 2.674695424989851

Epoch: 6| Step: 2
Training loss: 2.92124369119886
Validation loss: 2.6704216164350005

Epoch: 6| Step: 3
Training loss: 2.6691920323099048
Validation loss: 2.6596608585690875

Epoch: 6| Step: 4
Training loss: 3.054242269942884
Validation loss: 2.6371719453374984

Epoch: 6| Step: 5
Training loss: 2.854602771121754
Validation loss: 2.682802460433617

Epoch: 6| Step: 6
Training loss: 2.9153014302991713
Validation loss: 2.6767902509902477

Epoch: 6| Step: 7
Training loss: 2.987732122493382
Validation loss: 2.7086008499836

Epoch: 6| Step: 8
Training loss: 3.3347042761319825
Validation loss: 2.6446896656138295

Epoch: 6| Step: 9
Training loss: 3.0860759462614897
Validation loss: 2.676954975373147

Epoch: 6| Step: 10
Training loss: 2.4628393181486774
Validation loss: 2.6435402437027458

Epoch: 6| Step: 11
Training loss: 2.789719277208709
Validation loss: 2.6834691891920914

Epoch: 6| Step: 12
Training loss: 2.984402002342257
Validation loss: 2.6690003607353376

Epoch: 6| Step: 13
Training loss: 2.376250891286491
Validation loss: 2.6903889013228377

Epoch: 77| Step: 0
Training loss: 2.5211023444616445
Validation loss: 2.6678862980794036

Epoch: 6| Step: 1
Training loss: 2.730558685873554
Validation loss: 2.6707107414704514

Epoch: 6| Step: 2
Training loss: 2.761501881071269
Validation loss: 2.644140589746968

Epoch: 6| Step: 3
Training loss: 3.8108236661068635
Validation loss: 2.6856377873251396

Epoch: 6| Step: 4
Training loss: 2.2157228262628577
Validation loss: 2.6608126595421098

Epoch: 6| Step: 5
Training loss: 2.6016438789355347
Validation loss: 2.64715334164183

Epoch: 6| Step: 6
Training loss: 2.6203751467254484
Validation loss: 2.6961198522287804

Epoch: 6| Step: 7
Training loss: 3.317316548177238
Validation loss: 2.6852749110061747

Epoch: 6| Step: 8
Training loss: 2.531361801127367
Validation loss: 2.6650233960976966

Epoch: 6| Step: 9
Training loss: 2.7515258890604986
Validation loss: 2.636712346526847

Epoch: 6| Step: 10
Training loss: 3.3668569592873645
Validation loss: 2.6754696311183412

Epoch: 6| Step: 11
Training loss: 2.234760384569323
Validation loss: 2.6804734101856322

Epoch: 6| Step: 12
Training loss: 3.139707364824142
Validation loss: 2.6626366762726796

Epoch: 6| Step: 13
Training loss: 3.5604079947115825
Validation loss: 2.636232475429803

Epoch: 78| Step: 0
Training loss: 3.024359195397538
Validation loss: 2.7171858891215557

Epoch: 6| Step: 1
Training loss: 3.014168026640563
Validation loss: 2.7209326149339184

Epoch: 6| Step: 2
Training loss: 2.6059752834081857
Validation loss: 2.707189864406249

Epoch: 6| Step: 3
Training loss: 2.431850537657712
Validation loss: 2.6803440387641193

Epoch: 6| Step: 4
Training loss: 3.5228674315372053
Validation loss: 2.6598919429723415

Epoch: 6| Step: 5
Training loss: 2.021647718528936
Validation loss: 2.677787672464902

Epoch: 6| Step: 6
Training loss: 3.663123817827665
Validation loss: 2.725674776967282

Epoch: 6| Step: 7
Training loss: 2.411750056264708
Validation loss: 2.7035012946777384

Epoch: 6| Step: 8
Training loss: 3.0840346251942394
Validation loss: 2.6866467803489433

Epoch: 6| Step: 9
Training loss: 1.9950702230384614
Validation loss: 2.674866786043762

Epoch: 6| Step: 10
Training loss: 3.456102287350576
Validation loss: 2.70777030248126

Epoch: 6| Step: 11
Training loss: 2.5802499972323947
Validation loss: 2.6830696912217182

Epoch: 6| Step: 12
Training loss: 3.2422307390753784
Validation loss: 2.678490019975813

Epoch: 6| Step: 13
Training loss: 2.6275380897846263
Validation loss: 2.683391766385486

Epoch: 79| Step: 0
Training loss: 2.5935348973071104
Validation loss: 2.6277279300817034

Epoch: 6| Step: 1
Training loss: 2.6338212885032557
Validation loss: 2.65657385939515

Epoch: 6| Step: 2
Training loss: 2.968082071758189
Validation loss: 2.652758492186343

Epoch: 6| Step: 3
Training loss: 2.943553125880831
Validation loss: 2.7127245492179273

Epoch: 6| Step: 4
Training loss: 3.0522833922418107
Validation loss: 2.68351397876641

Epoch: 6| Step: 5
Training loss: 2.5170524764594178
Validation loss: 2.703392143167689

Epoch: 6| Step: 6
Training loss: 2.2682113091999105
Validation loss: 2.684143718885212

Epoch: 6| Step: 7
Training loss: 3.207408590106911
Validation loss: 2.6923389926904298

Epoch: 6| Step: 8
Training loss: 2.641846143078959
Validation loss: 2.6705513024612544

Epoch: 6| Step: 9
Training loss: 4.009089156893361
Validation loss: 2.6526495219195034

Epoch: 6| Step: 10
Training loss: 3.4211749749952416
Validation loss: 2.6604987439534473

Epoch: 6| Step: 11
Training loss: 2.9130589288577817
Validation loss: 2.706002233842129

Epoch: 6| Step: 12
Training loss: 2.320401584957313
Validation loss: 2.6956243081710585

Epoch: 6| Step: 13
Training loss: 2.2292776585217418
Validation loss: 2.6794264581432095

Epoch: 80| Step: 0
Training loss: 2.794662879443818
Validation loss: 2.7067678926838945

Epoch: 6| Step: 1
Training loss: 2.668663816824859
Validation loss: 2.7110755750253794

Epoch: 6| Step: 2
Training loss: 2.6605440324861394
Validation loss: 2.6651158694419355

Epoch: 6| Step: 3
Training loss: 3.3153341872291326
Validation loss: 2.6647751262548973

Epoch: 6| Step: 4
Training loss: 2.805823051072003
Validation loss: 2.678168199134561

Epoch: 6| Step: 5
Training loss: 3.2845202906564435
Validation loss: 2.685804367772366

Epoch: 6| Step: 6
Training loss: 3.306273600560779
Validation loss: 2.660291026412136

Epoch: 6| Step: 7
Training loss: 2.4827689491711187
Validation loss: 2.711630673237477

Epoch: 6| Step: 8
Training loss: 2.9785598101230852
Validation loss: 2.6443832767335222

Epoch: 6| Step: 9
Training loss: 3.1040846709275036
Validation loss: 2.6829042959451614

Epoch: 6| Step: 10
Training loss: 2.5008009581189996
Validation loss: 2.6504647970493016

Epoch: 6| Step: 11
Training loss: 3.2313076346180685
Validation loss: 2.6876616399547277

Epoch: 6| Step: 12
Training loss: 2.3122673948683126
Validation loss: 2.6548401692937573

Epoch: 6| Step: 13
Training loss: 3.0017785522292506
Validation loss: 2.6350520816168794

Epoch: 81| Step: 0
Training loss: 2.7220164002787035
Validation loss: 2.698131540527936

Epoch: 6| Step: 1
Training loss: 2.83439993884167
Validation loss: 2.6495534946347443

Epoch: 6| Step: 2
Training loss: 3.4327367900127204
Validation loss: 2.703498167291884

Epoch: 6| Step: 3
Training loss: 2.212582895913521
Validation loss: 2.644413058572462

Epoch: 6| Step: 4
Training loss: 2.5440696759129175
Validation loss: 2.6869154759723686

Epoch: 6| Step: 5
Training loss: 2.9202256060674543
Validation loss: 2.6679892592864785

Epoch: 6| Step: 6
Training loss: 3.0079174469313004
Validation loss: 2.6927126931651677

Epoch: 6| Step: 7
Training loss: 3.1944131121734376
Validation loss: 2.653323388882076

Epoch: 6| Step: 8
Training loss: 2.9017762236387554
Validation loss: 2.7131215921536347

Epoch: 6| Step: 9
Training loss: 3.231896376752119
Validation loss: 2.714430764551095

Epoch: 6| Step: 10
Training loss: 2.5314991204390034
Validation loss: 2.704919618966535

Epoch: 6| Step: 11
Training loss: 2.8853674011064303
Validation loss: 2.6646242478995417

Epoch: 6| Step: 12
Training loss: 2.9551368601648025
Validation loss: 2.6310015180637043

Epoch: 6| Step: 13
Training loss: 1.8948226232727912
Validation loss: 2.683395394412841

Epoch: 82| Step: 0
Training loss: 2.660690724459644
Validation loss: 2.7216942987295933

Epoch: 6| Step: 1
Training loss: 2.7596829476900493
Validation loss: 2.6379494944646393

Epoch: 6| Step: 2
Training loss: 2.3864022652278
Validation loss: 2.6767813958098636

Epoch: 6| Step: 3
Training loss: 2.9786667482153537
Validation loss: 2.6031039412929085

Epoch: 6| Step: 4
Training loss: 2.786387809265
Validation loss: 2.7275224824411177

Epoch: 6| Step: 5
Training loss: 2.2762255794382003
Validation loss: 2.7007145331546094

Epoch: 6| Step: 6
Training loss: 2.773190769449914
Validation loss: 2.6689912539856016

Epoch: 6| Step: 7
Training loss: 2.8198152140684147
Validation loss: 2.659135378382489

Epoch: 6| Step: 8
Training loss: 2.689999327535439
Validation loss: 2.660691299683694

Epoch: 6| Step: 9
Training loss: 2.9121404859798585
Validation loss: 2.6742427763914205

Epoch: 6| Step: 10
Training loss: 4.166240873833249
Validation loss: 2.6122550669371565

Epoch: 6| Step: 11
Training loss: 2.861821863064773
Validation loss: 2.6967186943967536

Epoch: 6| Step: 12
Training loss: 2.6627640678299898
Validation loss: 2.675879533910439

Epoch: 6| Step: 13
Training loss: 2.688640529899327
Validation loss: 2.658561159531246

Epoch: 83| Step: 0
Training loss: 2.94649313983931
Validation loss: 2.6330244202329456

Epoch: 6| Step: 1
Training loss: 3.1886914588282904
Validation loss: 2.6715682023354113

Epoch: 6| Step: 2
Training loss: 3.0082167316639747
Validation loss: 2.6669424386122653

Epoch: 6| Step: 3
Training loss: 3.2532140538231844
Validation loss: 2.681093889977339

Epoch: 6| Step: 4
Training loss: 2.469572871725434
Validation loss: 2.7273675602300824

Epoch: 6| Step: 5
Training loss: 3.279092715316926
Validation loss: 2.717547772160238

Epoch: 6| Step: 6
Training loss: 2.6205805860304388
Validation loss: 2.6368920695630713

Epoch: 6| Step: 7
Training loss: 2.6973074344209396
Validation loss: 2.6849632548728883

Epoch: 6| Step: 8
Training loss: 2.776609342455793
Validation loss: 2.62516181396278

Epoch: 6| Step: 9
Training loss: 3.3967817109465965
Validation loss: 2.642832290352652

Epoch: 6| Step: 10
Training loss: 2.2716760267520586
Validation loss: 2.630175026303309

Epoch: 6| Step: 11
Training loss: 2.467688609976077
Validation loss: 2.63484697865422

Epoch: 6| Step: 12
Training loss: 2.746738407006732
Validation loss: 2.662816876435837

Epoch: 6| Step: 13
Training loss: 2.384190095503927
Validation loss: 2.663834513456529

Epoch: 84| Step: 0
Training loss: 2.543268845250138
Validation loss: 2.6313566268171766

Epoch: 6| Step: 1
Training loss: 2.7366873418915225
Validation loss: 2.6993115220711585

Epoch: 6| Step: 2
Training loss: 3.1718142649280665
Validation loss: 2.6499854872776902

Epoch: 6| Step: 3
Training loss: 2.694455571714237
Validation loss: 2.677728646919399

Epoch: 6| Step: 4
Training loss: 3.1015480483172446
Validation loss: 2.648621163434102

Epoch: 6| Step: 5
Training loss: 3.2550203721775715
Validation loss: 2.687012405214889

Epoch: 6| Step: 6
Training loss: 2.9145605566749495
Validation loss: 2.6711386905173184

Epoch: 6| Step: 7
Training loss: 3.3515717477381886
Validation loss: 2.651755181182025

Epoch: 6| Step: 8
Training loss: 2.4438155104497947
Validation loss: 2.648936370454932

Epoch: 6| Step: 9
Training loss: 2.6135320386307614
Validation loss: 2.652599665437821

Epoch: 6| Step: 10
Training loss: 2.369496443807586
Validation loss: 2.720635359768905

Epoch: 6| Step: 11
Training loss: 2.4504718404014736
Validation loss: 2.6432663590870584

Epoch: 6| Step: 12
Training loss: 2.9321537470976264
Validation loss: 2.701020935960313

Epoch: 6| Step: 13
Training loss: 3.9385323760535065
Validation loss: 2.699331871095999

Epoch: 85| Step: 0
Training loss: 3.0834040418885533
Validation loss: 2.6283800091219174

Epoch: 6| Step: 1
Training loss: 1.8577995357590464
Validation loss: 2.7011136281008494

Epoch: 6| Step: 2
Training loss: 3.031476356470772
Validation loss: 2.6832421330926652

Epoch: 6| Step: 3
Training loss: 2.8870656136752446
Validation loss: 2.663140376208774

Epoch: 6| Step: 4
Training loss: 2.78769699563811
Validation loss: 2.6704624608543512

Epoch: 6| Step: 5
Training loss: 2.651900196769382
Validation loss: 2.6893682279761744

Epoch: 6| Step: 6
Training loss: 2.526514214954893
Validation loss: 2.7042801950640603

Epoch: 6| Step: 7
Training loss: 3.191846688740521
Validation loss: 2.660175969525969

Epoch: 6| Step: 8
Training loss: 2.9224148011984323
Validation loss: 2.680770531270848

Epoch: 6| Step: 9
Training loss: 2.5884470215552873
Validation loss: 2.703911294171055

Epoch: 6| Step: 10
Training loss: 2.1507981526590183
Validation loss: 2.659121798203572

Epoch: 6| Step: 11
Training loss: 3.143129479387436
Validation loss: 2.683344786929149

Epoch: 6| Step: 12
Training loss: 3.8156493889906327
Validation loss: 2.655699765703364

Epoch: 6| Step: 13
Training loss: 2.4094965447668035
Validation loss: 2.6677915606497216

Epoch: 86| Step: 0
Training loss: 3.1507270761037462
Validation loss: 2.696221295993039

Epoch: 6| Step: 1
Training loss: 3.0958771761993895
Validation loss: 2.7098250553970824

Epoch: 6| Step: 2
Training loss: 3.254308632177027
Validation loss: 2.663215872926739

Epoch: 6| Step: 3
Training loss: 3.250830030820164
Validation loss: 2.6677133911846993

Epoch: 6| Step: 4
Training loss: 3.3912175798958013
Validation loss: 2.6523695859348932

Epoch: 6| Step: 5
Training loss: 2.397397688829653
Validation loss: 2.65493975275497

Epoch: 6| Step: 6
Training loss: 3.127782269736799
Validation loss: 2.6719664062876696

Epoch: 6| Step: 7
Training loss: 2.2380422095033317
Validation loss: 2.7010373208736875

Epoch: 6| Step: 8
Training loss: 2.753352029643032
Validation loss: 2.6474466970630415

Epoch: 6| Step: 9
Training loss: 3.218534443868766
Validation loss: 2.69714137052188

Epoch: 6| Step: 10
Training loss: 2.1529267727827723
Validation loss: 2.656275682126127

Epoch: 6| Step: 11
Training loss: 2.4903472515778122
Validation loss: 2.6189270360670482

Epoch: 6| Step: 12
Training loss: 2.586041220806279
Validation loss: 2.6097143437781902

Epoch: 6| Step: 13
Training loss: 2.5875540575655562
Validation loss: 2.648111810071635

Epoch: 87| Step: 0
Training loss: 2.849391832212018
Validation loss: 2.641001613880871

Epoch: 6| Step: 1
Training loss: 2.4105216418602144
Validation loss: 2.685345430189119

Epoch: 6| Step: 2
Training loss: 2.194822535020906
Validation loss: 2.6428988766175316

Epoch: 6| Step: 3
Training loss: 2.926548448519724
Validation loss: 2.695027352673563

Epoch: 6| Step: 4
Training loss: 3.097719516565066
Validation loss: 2.6513516772078334

Epoch: 6| Step: 5
Training loss: 3.2846978374612865
Validation loss: 2.678050807765146

Epoch: 6| Step: 6
Training loss: 3.4286320828567662
Validation loss: 2.677980763733794

Epoch: 6| Step: 7
Training loss: 2.491869963025393
Validation loss: 2.6753775693088855

Epoch: 6| Step: 8
Training loss: 2.9466449344345693
Validation loss: 2.6265793994061406

Epoch: 6| Step: 9
Training loss: 3.9309633280873504
Validation loss: 2.6716063692495817

Epoch: 6| Step: 10
Training loss: 2.174984688540529
Validation loss: 2.6331327334949512

Epoch: 6| Step: 11
Training loss: 2.8903128790527783
Validation loss: 2.622507272703977

Epoch: 6| Step: 12
Training loss: 2.66519883607498
Validation loss: 2.6545399845588573

Epoch: 6| Step: 13
Training loss: 2.3592073494670918
Validation loss: 2.6604313175358416

Epoch: 88| Step: 0
Training loss: 2.93839493774759
Validation loss: 2.6866793437178167

Epoch: 6| Step: 1
Training loss: 2.7209028292587574
Validation loss: 2.6348728440986635

Epoch: 6| Step: 2
Training loss: 2.629250763174383
Validation loss: 2.655127531499991

Epoch: 6| Step: 3
Training loss: 3.2078337507477728
Validation loss: 2.6340151326171837

Epoch: 6| Step: 4
Training loss: 2.252041843913172
Validation loss: 2.673738974227132

Epoch: 6| Step: 5
Training loss: 2.963494397117708
Validation loss: 2.640714104698692

Epoch: 6| Step: 6
Training loss: 3.2149398622479852
Validation loss: 2.64070408588541

Epoch: 6| Step: 7
Training loss: 2.6863849899576975
Validation loss: 2.640110994697046

Epoch: 6| Step: 8
Training loss: 3.7146764932198044
Validation loss: 2.644494123194159

Epoch: 6| Step: 9
Training loss: 2.5883142894659192
Validation loss: 2.7020923302366793

Epoch: 6| Step: 10
Training loss: 2.659248723798587
Validation loss: 2.6941175125745653

Epoch: 6| Step: 11
Training loss: 2.3530615404141204
Validation loss: 2.6193611719160583

Epoch: 6| Step: 12
Training loss: 2.8025244232120787
Validation loss: 2.7079625622912227

Epoch: 6| Step: 13
Training loss: 3.345076253389631
Validation loss: 2.679984571424437

Epoch: 89| Step: 0
Training loss: 3.2831201945672195
Validation loss: 2.6476409030637598

Epoch: 6| Step: 1
Training loss: 3.382917653623317
Validation loss: 2.648599523665977

Epoch: 6| Step: 2
Training loss: 2.8217385192513165
Validation loss: 2.7131217395587233

Epoch: 6| Step: 3
Training loss: 2.6881632319172666
Validation loss: 2.6582140953249467

Epoch: 6| Step: 4
Training loss: 2.8514344069046866
Validation loss: 2.6518465568914213

Epoch: 6| Step: 5
Training loss: 2.7993627810866273
Validation loss: 2.670427451390299

Epoch: 6| Step: 6
Training loss: 2.39043011837156
Validation loss: 2.677511303018777

Epoch: 6| Step: 7
Training loss: 2.764555298567987
Validation loss: 2.675220704502509

Epoch: 6| Step: 8
Training loss: 2.5013086708428243
Validation loss: 2.6667242281095183

Epoch: 6| Step: 9
Training loss: 2.8517196820977464
Validation loss: 2.7043598338956314

Epoch: 6| Step: 10
Training loss: 3.2746920491807736
Validation loss: 2.7071047783285014

Epoch: 6| Step: 11
Training loss: 2.403976555441789
Validation loss: 2.689106882705584

Epoch: 6| Step: 12
Training loss: 2.969212225015689
Validation loss: 2.6877688735808567

Epoch: 6| Step: 13
Training loss: 2.4074945575339655
Validation loss: 2.71668447924895

Epoch: 90| Step: 0
Training loss: 3.0086722594274766
Validation loss: 2.6784927783988244

Epoch: 6| Step: 1
Training loss: 2.3597468405248874
Validation loss: 2.649963186290428

Epoch: 6| Step: 2
Training loss: 3.0667948288328257
Validation loss: 2.6555957246572603

Epoch: 6| Step: 3
Training loss: 3.3512113516150186
Validation loss: 2.672965069112776

Epoch: 6| Step: 4
Training loss: 3.4551256002956476
Validation loss: 2.6444476485164747

Epoch: 6| Step: 5
Training loss: 2.4055896199638322
Validation loss: 2.6600259155033688

Epoch: 6| Step: 6
Training loss: 2.009390125840656
Validation loss: 2.6634847695206356

Epoch: 6| Step: 7
Training loss: 3.9934931521736106
Validation loss: 2.639538133463444

Epoch: 6| Step: 8
Training loss: 2.9596550008403044
Validation loss: 2.6590608764708423

Epoch: 6| Step: 9
Training loss: 2.5279519529967645
Validation loss: 2.6762954250233237

Epoch: 6| Step: 10
Training loss: 2.4804755743939095
Validation loss: 2.6254287570753925

Epoch: 6| Step: 11
Training loss: 2.8112902264666233
Validation loss: 2.6782839160106287

Epoch: 6| Step: 12
Training loss: 2.269113420115528
Validation loss: 2.6370994632708866

Epoch: 6| Step: 13
Training loss: 3.0127241185818954
Validation loss: 2.6846197041663546

Epoch: 91| Step: 0
Training loss: 2.522481542393099
Validation loss: 2.644476221718111

Epoch: 6| Step: 1
Training loss: 2.768797009071161
Validation loss: 2.634842152693054

Epoch: 6| Step: 2
Training loss: 2.565435449472498
Validation loss: 2.675359116512339

Epoch: 6| Step: 3
Training loss: 3.469748413463774
Validation loss: 2.6728458642392123

Epoch: 6| Step: 4
Training loss: 3.281214395965689
Validation loss: 2.6127100045685303

Epoch: 6| Step: 5
Training loss: 3.017655237687851
Validation loss: 2.6776189512851096

Epoch: 6| Step: 6
Training loss: 3.556810889235219
Validation loss: 2.7237267455851115

Epoch: 6| Step: 7
Training loss: 2.0682356872174017
Validation loss: 2.671574952163259

Epoch: 6| Step: 8
Training loss: 2.8573407717685235
Validation loss: 2.6686653980473456

Epoch: 6| Step: 9
Training loss: 2.990514382097376
Validation loss: 2.6585896822978983

Epoch: 6| Step: 10
Training loss: 3.1300535920158943
Validation loss: 2.639707726006033

Epoch: 6| Step: 11
Training loss: 2.1612832852608537
Validation loss: 2.6760928900737895

Epoch: 6| Step: 12
Training loss: 2.434766165532689
Validation loss: 2.648036753561939

Epoch: 6| Step: 13
Training loss: 2.2579168275799164
Validation loss: 2.707200639064313

Epoch: 92| Step: 0
Training loss: 2.7207641156570106
Validation loss: 2.6799210723717692

Epoch: 6| Step: 1
Training loss: 3.141190207565435
Validation loss: 2.6331559374061246

Epoch: 6| Step: 2
Training loss: 2.969262329867359
Validation loss: 2.657498153654858

Epoch: 6| Step: 3
Training loss: 2.7245362193359868
Validation loss: 2.7001582807621256

Epoch: 6| Step: 4
Training loss: 2.7896514185335537
Validation loss: 2.6878175216416857

Epoch: 6| Step: 5
Training loss: 3.237425172154608
Validation loss: 2.6527797201665955

Epoch: 6| Step: 6
Training loss: 2.5862926227787235
Validation loss: 2.7000252408800374

Epoch: 6| Step: 7
Training loss: 2.4072277510139055
Validation loss: 2.6964200933271156

Epoch: 6| Step: 8
Training loss: 3.126751523306733
Validation loss: 2.6773009382768445

Epoch: 6| Step: 9
Training loss: 2.909116254501038
Validation loss: 2.649485935780427

Epoch: 6| Step: 10
Training loss: 3.1382613515947146
Validation loss: 2.7020450549449975

Epoch: 6| Step: 11
Training loss: 2.7631238414224413
Validation loss: 2.668717640304526

Epoch: 6| Step: 12
Training loss: 1.9833971152214327
Validation loss: 2.6321838978076277

Epoch: 6| Step: 13
Training loss: 3.390953364491144
Validation loss: 2.6769639161693966

Epoch: 93| Step: 0
Training loss: 2.5259687170657372
Validation loss: 2.699846030531515

Epoch: 6| Step: 1
Training loss: 2.29031181744547
Validation loss: 2.6163428020788544

Epoch: 6| Step: 2
Training loss: 3.071483592557607
Validation loss: 2.6826079387123025

Epoch: 6| Step: 3
Training loss: 3.2428560234149515
Validation loss: 2.6461898147565526

Epoch: 6| Step: 4
Training loss: 3.071812697561713
Validation loss: 2.6651509390598913

Epoch: 6| Step: 5
Training loss: 1.715803151704344
Validation loss: 2.68060791678868

Epoch: 6| Step: 6
Training loss: 3.0180442474741676
Validation loss: 2.6296546693628082

Epoch: 6| Step: 7
Training loss: 2.687443045079176
Validation loss: 2.6991562790163233

Epoch: 6| Step: 8
Training loss: 3.3002624465156325
Validation loss: 2.675350353377752

Epoch: 6| Step: 9
Training loss: 3.0557319436072334
Validation loss: 2.664489221142781

Epoch: 6| Step: 10
Training loss: 2.75542720701712
Validation loss: 2.644733429648329

Epoch: 6| Step: 11
Training loss: 2.755300096066627
Validation loss: 2.7003719942934206

Epoch: 6| Step: 12
Training loss: 2.5319917322056975
Validation loss: 2.6418072308269362

Epoch: 6| Step: 13
Training loss: 3.9133144128223987
Validation loss: 2.6761681564628312

Epoch: 94| Step: 0
Training loss: 3.2293811521772398
Validation loss: 2.670181024309447

Epoch: 6| Step: 1
Training loss: 2.4709542007431886
Validation loss: 2.612768173525558

Epoch: 6| Step: 2
Training loss: 3.604626591320383
Validation loss: 2.637939796547003

Epoch: 6| Step: 3
Training loss: 2.4449794164621976
Validation loss: 2.635121148787175

Epoch: 6| Step: 4
Training loss: 2.899546778549381
Validation loss: 2.6965798623791066

Epoch: 6| Step: 5
Training loss: 3.317028477037915
Validation loss: 2.688769342903032

Epoch: 6| Step: 6
Training loss: 3.266961367282659
Validation loss: 2.6731863756191476

Epoch: 6| Step: 7
Training loss: 2.428298111369748
Validation loss: 2.6483672719526723

Epoch: 6| Step: 8
Training loss: 2.8248883689497517
Validation loss: 2.6823605366192598

Epoch: 6| Step: 9
Training loss: 2.73820166805496
Validation loss: 2.6725762682368757

Epoch: 6| Step: 10
Training loss: 2.807948350034666
Validation loss: 2.6291389259362345

Epoch: 6| Step: 11
Training loss: 2.4289820588392756
Validation loss: 2.6683631907717844

Epoch: 6| Step: 12
Training loss: 2.451451696708537
Validation loss: 2.7087340308557297

Epoch: 6| Step: 13
Training loss: 2.582042607500314
Validation loss: 2.683489674590822

Epoch: 95| Step: 0
Training loss: 2.069725327627734
Validation loss: 2.6554318108333117

Epoch: 6| Step: 1
Training loss: 2.551744918703073
Validation loss: 2.638929560257404

Epoch: 6| Step: 2
Training loss: 3.3738172365988763
Validation loss: 2.6489486798746094

Epoch: 6| Step: 3
Training loss: 2.751084287333262
Validation loss: 2.6568077510394663

Epoch: 6| Step: 4
Training loss: 2.7524296691113728
Validation loss: 2.6429268118129063

Epoch: 6| Step: 5
Training loss: 2.7821829441945476
Validation loss: 2.6693840454648083

Epoch: 6| Step: 6
Training loss: 3.531091061956572
Validation loss: 2.6207839520857776

Epoch: 6| Step: 7
Training loss: 3.093308080071376
Validation loss: 2.6511054893286454

Epoch: 6| Step: 8
Training loss: 2.40500757418449
Validation loss: 2.7017757925922026

Epoch: 6| Step: 9
Training loss: 3.430913545271427
Validation loss: 2.673584949365587

Epoch: 6| Step: 10
Training loss: 1.926557775090991
Validation loss: 2.6944196199723214

Epoch: 6| Step: 11
Training loss: 2.823407026167605
Validation loss: 2.656048241420022

Epoch: 6| Step: 12
Training loss: 2.960584151389056
Validation loss: 2.651150810679597

Epoch: 6| Step: 13
Training loss: 3.382595980368665
Validation loss: 2.6738224000566206

Epoch: 96| Step: 0
Training loss: 2.4362876028776954
Validation loss: 2.6283406848718696

Epoch: 6| Step: 1
Training loss: 2.43315167032005
Validation loss: 2.702293864289219

Epoch: 6| Step: 2
Training loss: 1.554029469233952
Validation loss: 2.640245787445635

Epoch: 6| Step: 3
Training loss: 3.5213925671788737
Validation loss: 2.646090281784176

Epoch: 6| Step: 4
Training loss: 2.662628951554231
Validation loss: 2.6543950523430464

Epoch: 6| Step: 5
Training loss: 2.3427958262790147
Validation loss: 2.597648578774031

Epoch: 6| Step: 6
Training loss: 2.828015404363869
Validation loss: 2.680341391282796

Epoch: 6| Step: 7
Training loss: 2.9392380138275143
Validation loss: 2.6482381597740106

Epoch: 6| Step: 8
Training loss: 2.9143329730062195
Validation loss: 2.7030705955010075

Epoch: 6| Step: 9
Training loss: 3.154514855567972
Validation loss: 2.6423917043321126

Epoch: 6| Step: 10
Training loss: 3.100979151985676
Validation loss: 2.675417569574981

Epoch: 6| Step: 11
Training loss: 3.76381630415018
Validation loss: 2.6832098767447707

Epoch: 6| Step: 12
Training loss: 2.8286621258109053
Validation loss: 2.6347365485253778

Epoch: 6| Step: 13
Training loss: 2.9684089866334573
Validation loss: 2.6348283344384233

Epoch: 97| Step: 0
Training loss: 3.6790348454178616
Validation loss: 2.6989345985971362

Epoch: 6| Step: 1
Training loss: 2.0070272015760553
Validation loss: 2.6410509234309303

Epoch: 6| Step: 2
Training loss: 2.367415716167471
Validation loss: 2.5974850814324437

Epoch: 6| Step: 3
Training loss: 3.126854460742385
Validation loss: 2.6654464739798214

Epoch: 6| Step: 4
Training loss: 3.31891974465855
Validation loss: 2.7021787837784577

Epoch: 6| Step: 5
Training loss: 2.3430439203356968
Validation loss: 2.645229057106243

Epoch: 6| Step: 6
Training loss: 2.875712430835754
Validation loss: 2.6789249256052114

Epoch: 6| Step: 7
Training loss: 2.8614834375510383
Validation loss: 2.6667680650578265

Epoch: 6| Step: 8
Training loss: 3.434055614112187
Validation loss: 2.5953162542562205

Epoch: 6| Step: 9
Training loss: 2.4642803436915792
Validation loss: 2.694600156886881

Epoch: 6| Step: 10
Training loss: 3.0095306641435653
Validation loss: 2.6725302233865675

Epoch: 6| Step: 11
Training loss: 2.4483528127429888
Validation loss: 2.629735229660342

Epoch: 6| Step: 12
Training loss: 2.322490248151494
Validation loss: 2.6498780844163816

Epoch: 6| Step: 13
Training loss: 2.420255648768433
Validation loss: 2.6568241394056353

Epoch: 98| Step: 0
Training loss: 2.6166432284461605
Validation loss: 2.7062946452593417

Epoch: 6| Step: 1
Training loss: 2.1336567643483138
Validation loss: 2.6578900740873586

Epoch: 6| Step: 2
Training loss: 2.693856816486261
Validation loss: 2.7104826685091115

Epoch: 6| Step: 3
Training loss: 3.7054430953281208
Validation loss: 2.663158035747846

Epoch: 6| Step: 4
Training loss: 2.627599428221126
Validation loss: 2.6159536593644885

Epoch: 6| Step: 5
Training loss: 2.5107828297955193
Validation loss: 2.7143970418559586

Epoch: 6| Step: 6
Training loss: 3.7134875079142984
Validation loss: 2.6851534222717115

Epoch: 6| Step: 7
Training loss: 2.3444971546717985
Validation loss: 2.6608312488664887

Epoch: 6| Step: 8
Training loss: 2.7417852644695575
Validation loss: 2.6535381876685693

Epoch: 6| Step: 9
Training loss: 2.55987786836164
Validation loss: 2.718454648784268

Epoch: 6| Step: 10
Training loss: 2.868264310524624
Validation loss: 2.6610804598730287

Epoch: 6| Step: 11
Training loss: 2.5766689928578104
Validation loss: 2.607671350380732

Epoch: 6| Step: 12
Training loss: 2.9819607381301987
Validation loss: 2.6640198964928583

Epoch: 6| Step: 13
Training loss: 3.2830087943492345
Validation loss: 2.65156844660992

Epoch: 99| Step: 0
Training loss: 3.0048401252756856
Validation loss: 2.6607363132296524

Epoch: 6| Step: 1
Training loss: 2.6962558146039566
Validation loss: 2.677520618242331

Epoch: 6| Step: 2
Training loss: 3.271176524694577
Validation loss: 2.652520280874739

Epoch: 6| Step: 3
Training loss: 3.6043826499713583
Validation loss: 2.635144324487727

Epoch: 6| Step: 4
Training loss: 3.144977646886232
Validation loss: 2.648261464631571

Epoch: 6| Step: 5
Training loss: 2.802647690977664
Validation loss: 2.652822868513582

Epoch: 6| Step: 6
Training loss: 3.3039199262341823
Validation loss: 2.688042128366713

Epoch: 6| Step: 7
Training loss: 2.168201001073168
Validation loss: 2.6540982994000544

Epoch: 6| Step: 8
Training loss: 2.2111425944929812
Validation loss: 2.614690428320409

Epoch: 6| Step: 9
Training loss: 3.1023015984135927
Validation loss: 2.6450296514786675

Epoch: 6| Step: 10
Training loss: 2.4867131968108747
Validation loss: 2.616564780143816

Epoch: 6| Step: 11
Training loss: 2.1994260212605576
Validation loss: 2.664485992162488

Epoch: 6| Step: 12
Training loss: 2.4468378056881845
Validation loss: 2.673321914391716

Epoch: 6| Step: 13
Training loss: 2.536088628020481
Validation loss: 2.679663266834409

Epoch: 100| Step: 0
Training loss: 3.4720963840993924
Validation loss: 2.6597182879301076

Epoch: 6| Step: 1
Training loss: 2.6871592283441896
Validation loss: 2.671463951122482

Epoch: 6| Step: 2
Training loss: 2.9301980349435115
Validation loss: 2.650832112664485

Epoch: 6| Step: 3
Training loss: 2.99556197280209
Validation loss: 2.6594327096514605

Epoch: 6| Step: 4
Training loss: 3.0633026939522954
Validation loss: 2.6836962786208347

Epoch: 6| Step: 5
Training loss: 2.647590974536064
Validation loss: 2.619550898208855

Epoch: 6| Step: 6
Training loss: 3.113769339827205
Validation loss: 2.6651651397287233

Epoch: 6| Step: 7
Training loss: 2.2329853778433826
Validation loss: 2.6365492510654898

Epoch: 6| Step: 8
Training loss: 2.5152147799749223
Validation loss: 2.6272307145314846

Epoch: 6| Step: 9
Training loss: 2.3188782443135483
Validation loss: 2.6939008152587536

Epoch: 6| Step: 10
Training loss: 2.755114913731587
Validation loss: 2.658464747441021

Epoch: 6| Step: 11
Training loss: 2.8974986239439073
Validation loss: 2.6634841948998824

Epoch: 6| Step: 12
Training loss: 3.077325862417072
Validation loss: 2.648373647245511

Epoch: 6| Step: 13
Training loss: 2.8769640640703438
Validation loss: 2.657801281897257

Epoch: 101| Step: 0
Training loss: 2.7520054527273055
Validation loss: 2.659277014570049

Epoch: 6| Step: 1
Training loss: 2.5013376472059083
Validation loss: 2.649995141112938

Epoch: 6| Step: 2
Training loss: 3.8892002177884093
Validation loss: 2.6965774827739515

Epoch: 6| Step: 3
Training loss: 2.020929262171894
Validation loss: 2.6720189543485233

Epoch: 6| Step: 4
Training loss: 3.095306159238757
Validation loss: 2.6058949585926516

Epoch: 6| Step: 5
Training loss: 3.0902978922633406
Validation loss: 2.6009899611716207

Epoch: 6| Step: 6
Training loss: 2.4690188490873126
Validation loss: 2.612670866394088

Epoch: 6| Step: 7
Training loss: 3.196197909399511
Validation loss: 2.657281677914484

Epoch: 6| Step: 8
Training loss: 2.65526733173259
Validation loss: 2.7159036161763477

Epoch: 6| Step: 9
Training loss: 2.441015007713656
Validation loss: 2.634701366953474

Epoch: 6| Step: 10
Training loss: 2.8302712068581197
Validation loss: 2.6428878892815812

Epoch: 6| Step: 11
Training loss: 2.6724763606197324
Validation loss: 2.6642115867026868

Epoch: 6| Step: 12
Training loss: 2.3659366538434625
Validation loss: 2.656541988048889

Epoch: 6| Step: 13
Training loss: 3.380901968878859
Validation loss: 2.6434036492301956

Epoch: 102| Step: 0
Training loss: 3.298917165020959
Validation loss: 2.660381199269494

Epoch: 6| Step: 1
Training loss: 3.237312641392944
Validation loss: 2.6396694805220386

Epoch: 6| Step: 2
Training loss: 2.6983683636350873
Validation loss: 2.6846713695393207

Epoch: 6| Step: 3
Training loss: 3.6134689034886533
Validation loss: 2.6178994750829907

Epoch: 6| Step: 4
Training loss: 2.2133928555600866
Validation loss: 2.670181320980311

Epoch: 6| Step: 5
Training loss: 3.5013986245328965
Validation loss: 2.672684916205176

Epoch: 6| Step: 6
Training loss: 2.8468882253697676
Validation loss: 2.6558258586634866

Epoch: 6| Step: 7
Training loss: 2.4306507225176324
Validation loss: 2.6578989835261244

Epoch: 6| Step: 8
Training loss: 3.0002924458696003
Validation loss: 2.6508417943638323

Epoch: 6| Step: 9
Training loss: 2.759438788950057
Validation loss: 2.6714592815156806

Epoch: 6| Step: 10
Training loss: 2.6372606864941948
Validation loss: 2.655512030318848

Epoch: 6| Step: 11
Training loss: 2.1843131693765026
Validation loss: 2.6107165188199764

Epoch: 6| Step: 12
Training loss: 2.3153033405070778
Validation loss: 2.669052655027038

Epoch: 6| Step: 13
Training loss: 2.1818776492843344
Validation loss: 2.708074268290842

Epoch: 103| Step: 0
Training loss: 2.7469452450811387
Validation loss: 2.653900271148005

Epoch: 6| Step: 1
Training loss: 3.179035091718851
Validation loss: 2.6420409538492056

Epoch: 6| Step: 2
Training loss: 2.5682914231742835
Validation loss: 2.666527476895333

Epoch: 6| Step: 3
Training loss: 3.1657164971853935
Validation loss: 2.6311705276841444

Epoch: 6| Step: 4
Training loss: 3.013939104575012
Validation loss: 2.7093224081695717

Epoch: 6| Step: 5
Training loss: 2.136853871091832
Validation loss: 2.6307549859586916

Epoch: 6| Step: 6
Training loss: 3.0632617548015997
Validation loss: 2.6396804987356917

Epoch: 6| Step: 7
Training loss: 2.50977949442909
Validation loss: 2.6454697574652073

Epoch: 6| Step: 8
Training loss: 3.028653950350974
Validation loss: 2.6281875246869797

Epoch: 6| Step: 9
Training loss: 1.9953824024308078
Validation loss: 2.684706071984939

Epoch: 6| Step: 10
Training loss: 2.8230321562581135
Validation loss: 2.6842784761238665

Epoch: 6| Step: 11
Training loss: 3.5083420657474336
Validation loss: 2.6602563360205993

Epoch: 6| Step: 12
Training loss: 2.3489446421109332
Validation loss: 2.622395556999844

Epoch: 6| Step: 13
Training loss: 2.8891951040037127
Validation loss: 2.641405020844961

Epoch: 104| Step: 0
Training loss: 2.6785403095435867
Validation loss: 2.627394873381145

Epoch: 6| Step: 1
Training loss: 3.2307251317644092
Validation loss: 2.6431972467586573

Epoch: 6| Step: 2
Training loss: 2.3888611114227567
Validation loss: 2.680332392887419

Epoch: 6| Step: 3
Training loss: 2.137889813130784
Validation loss: 2.6533836694053807

Epoch: 6| Step: 4
Training loss: 3.316132766716263
Validation loss: 2.6517094380064297

Epoch: 6| Step: 5
Training loss: 1.7893058244909195
Validation loss: 2.649129535325398

Epoch: 6| Step: 6
Training loss: 3.4355631139912544
Validation loss: 2.6784991308007644

Epoch: 6| Step: 7
Training loss: 2.920365213782783
Validation loss: 2.6655381555347017

Epoch: 6| Step: 8
Training loss: 3.3499874513305667
Validation loss: 2.6619325015592294

Epoch: 6| Step: 9
Training loss: 2.397164967092496
Validation loss: 2.6367621524205593

Epoch: 6| Step: 10
Training loss: 2.9216964585532925
Validation loss: 2.678260015695857

Epoch: 6| Step: 11
Training loss: 2.644231737043297
Validation loss: 2.7073536870403707

Epoch: 6| Step: 12
Training loss: 2.933119571728726
Validation loss: 2.730330275448403

Epoch: 6| Step: 13
Training loss: 2.7290287613909947
Validation loss: 2.7168483370531455

Epoch: 105| Step: 0
Training loss: 2.5445878694563726
Validation loss: 2.669219108378514

Epoch: 6| Step: 1
Training loss: 2.2569075622153347
Validation loss: 2.625894875939334

Epoch: 6| Step: 2
Training loss: 2.663123538650939
Validation loss: 2.6872410173681827

Epoch: 6| Step: 3
Training loss: 2.9634483783075343
Validation loss: 2.663901415860125

Epoch: 6| Step: 4
Training loss: 2.6929332017004803
Validation loss: 2.6681862908796607

Epoch: 6| Step: 5
Training loss: 3.320805196670807
Validation loss: 2.660988819343101

Epoch: 6| Step: 6
Training loss: 2.3143997636912936
Validation loss: 2.6922440397050815

Epoch: 6| Step: 7
Training loss: 3.4064030044209144
Validation loss: 2.627335839786255

Epoch: 6| Step: 8
Training loss: 2.9463224020321177
Validation loss: 2.6935226406531965

Epoch: 6| Step: 9
Training loss: 2.988514371268412
Validation loss: 2.6056431643393436

Epoch: 6| Step: 10
Training loss: 2.81095462304032
Validation loss: 2.682978344067618

Epoch: 6| Step: 11
Training loss: 2.6621376758171023
Validation loss: 2.647300949446525

Epoch: 6| Step: 12
Training loss: 3.2886611802370944
Validation loss: 2.6457663290117703

Epoch: 6| Step: 13
Training loss: 2.1953770095198277
Validation loss: 2.6577612364253973

Epoch: 106| Step: 0
Training loss: 2.828727362959803
Validation loss: 2.6714857828174674

Epoch: 6| Step: 1
Training loss: 2.74609409728394
Validation loss: 2.620727851939124

Epoch: 6| Step: 2
Training loss: 3.117561795892504
Validation loss: 2.690255774741714

Epoch: 6| Step: 3
Training loss: 2.9427801522912373
Validation loss: 2.635704470014451

Epoch: 6| Step: 4
Training loss: 2.761747238681297
Validation loss: 2.629461303268959

Epoch: 6| Step: 5
Training loss: 2.4356864638351676
Validation loss: 2.6430508360916343

Epoch: 6| Step: 6
Training loss: 2.182144257172873
Validation loss: 2.5935548960267796

Epoch: 6| Step: 7
Training loss: 2.7439453924378503
Validation loss: 2.6803799669696113

Epoch: 6| Step: 8
Training loss: 3.111578845634103
Validation loss: 2.711866345846679

Epoch: 6| Step: 9
Training loss: 2.135976156737448
Validation loss: 2.639078651417218

Epoch: 6| Step: 10
Training loss: 3.0478604801515647
Validation loss: 2.6426942390822297

Epoch: 6| Step: 11
Training loss: 2.8636431081563067
Validation loss: 2.669215619076161

Epoch: 6| Step: 12
Training loss: 3.03632488360981
Validation loss: 2.6454605978166543

Epoch: 6| Step: 13
Training loss: 3.6528537985687657
Validation loss: 2.6548275694910357

Epoch: 107| Step: 0
Training loss: 2.4852901668497265
Validation loss: 2.7006928086388045

Epoch: 6| Step: 1
Training loss: 2.6086939305493297
Validation loss: 2.6834187760835753

Epoch: 6| Step: 2
Training loss: 3.4191239677240484
Validation loss: 2.673668458626582

Epoch: 6| Step: 3
Training loss: 2.696860579256509
Validation loss: 2.642373270523871

Epoch: 6| Step: 4
Training loss: 2.465265446544008
Validation loss: 2.6357250577124276

Epoch: 6| Step: 5
Training loss: 2.9727597112108044
Validation loss: 2.6520172715134525

Epoch: 6| Step: 6
Training loss: 3.6994677805234173
Validation loss: 2.658668649393144

Epoch: 6| Step: 7
Training loss: 2.9570225421973837
Validation loss: 2.5973969573071702

Epoch: 6| Step: 8
Training loss: 2.457856202025001
Validation loss: 2.628933472812316

Epoch: 6| Step: 9
Training loss: 2.6593347925179125
Validation loss: 2.6343041193544465

Epoch: 6| Step: 10
Training loss: 2.8540431272032376
Validation loss: 2.6758589883351274

Epoch: 6| Step: 11
Training loss: 2.5263974807627645
Validation loss: 2.615640321119374

Epoch: 6| Step: 12
Training loss: 2.5582062638957113
Validation loss: 2.693718296646094

Epoch: 6| Step: 13
Training loss: 2.897895207018255
Validation loss: 2.6534047194395756

Epoch: 108| Step: 0
Training loss: 2.6063956423529255
Validation loss: 2.621282260409168

Epoch: 6| Step: 1
Training loss: 2.731462246048243
Validation loss: 2.663095850932291

Epoch: 6| Step: 2
Training loss: 3.40182235349041
Validation loss: 2.663127632773905

Epoch: 6| Step: 3
Training loss: 2.239179873534612
Validation loss: 2.6371415003902086

Epoch: 6| Step: 4
Training loss: 2.9431740361355496
Validation loss: 2.672786654744542

Epoch: 6| Step: 5
Training loss: 2.85422974305634
Validation loss: 2.667049146597233

Epoch: 6| Step: 6
Training loss: 3.4796358047297318
Validation loss: 2.656339047680802

Epoch: 6| Step: 7
Training loss: 2.6841441649194793
Validation loss: 2.709895045454859

Epoch: 6| Step: 8
Training loss: 2.474310491828611
Validation loss: 2.621534117217642

Epoch: 6| Step: 9
Training loss: 2.9270613229451223
Validation loss: 2.6285377927708753

Epoch: 6| Step: 10
Training loss: 2.760006645028781
Validation loss: 2.6365485743119224

Epoch: 6| Step: 11
Training loss: 2.6176744605859614
Validation loss: 2.6701215867410615

Epoch: 6| Step: 12
Training loss: 2.1308148429266267
Validation loss: 2.645036147246468

Epoch: 6| Step: 13
Training loss: 3.576281209927495
Validation loss: 2.6389503807181627

Epoch: 109| Step: 0
Training loss: 2.905949894987058
Validation loss: 2.645854045530728

Epoch: 6| Step: 1
Training loss: 3.3041993269843526
Validation loss: 2.6491005429605274

Epoch: 6| Step: 2
Training loss: 3.070261559294333
Validation loss: 2.646190653741128

Epoch: 6| Step: 3
Training loss: 2.836402203446612
Validation loss: 2.611091324894083

Epoch: 6| Step: 4
Training loss: 2.951628129026512
Validation loss: 2.646481606947781

Epoch: 6| Step: 5
Training loss: 2.325465174254898
Validation loss: 2.638626789151629

Epoch: 6| Step: 6
Training loss: 2.5310431501854302
Validation loss: 2.7009376250683106

Epoch: 6| Step: 7
Training loss: 2.5902816379258136
Validation loss: 2.6698449451386956

Epoch: 6| Step: 8
Training loss: 2.7017649498048755
Validation loss: 2.6965440197699952

Epoch: 6| Step: 9
Training loss: 2.025460075578196
Validation loss: 2.6588836739313217

Epoch: 6| Step: 10
Training loss: 3.401820391094539
Validation loss: 2.664949823570645

Epoch: 6| Step: 11
Training loss: 2.548471617338734
Validation loss: 2.6444670120953337

Epoch: 6| Step: 12
Training loss: 2.9028632005922255
Validation loss: 2.648941248162472

Epoch: 6| Step: 13
Training loss: 3.10090872458589
Validation loss: 2.6880234334742648

Epoch: 110| Step: 0
Training loss: 2.7194714520725705
Validation loss: 2.661385903268808

Epoch: 6| Step: 1
Training loss: 3.0594012094686187
Validation loss: 2.6484013301262097

Epoch: 6| Step: 2
Training loss: 2.4591309713549916
Validation loss: 2.6436575926649986

Epoch: 6| Step: 3
Training loss: 2.9768686212234665
Validation loss: 2.6792484458195585

Epoch: 6| Step: 4
Training loss: 3.6072665575067693
Validation loss: 2.6590655774917176

Epoch: 6| Step: 5
Training loss: 2.5880494497253395
Validation loss: 2.628476518171493

Epoch: 6| Step: 6
Training loss: 3.147097015883109
Validation loss: 2.6508442832057137

Epoch: 6| Step: 7
Training loss: 3.0418909242776335
Validation loss: 2.677501076246666

Epoch: 6| Step: 8
Training loss: 2.1931685978710673
Validation loss: 2.6551835478699877

Epoch: 6| Step: 9
Training loss: 2.7452806378655805
Validation loss: 2.6732498927127963

Epoch: 6| Step: 10
Training loss: 2.0312402578266977
Validation loss: 2.6632838699302472

Epoch: 6| Step: 11
Training loss: 2.121713003455171
Validation loss: 2.6665407761216797

Epoch: 6| Step: 12
Training loss: 3.270933955562293
Validation loss: 2.69455129638273

Epoch: 6| Step: 13
Training loss: 3.0308601679298808
Validation loss: 2.681350973786453

Epoch: 111| Step: 0
Training loss: 3.0660463935940205
Validation loss: 2.6438218747888107

Epoch: 6| Step: 1
Training loss: 2.3931622971472413
Validation loss: 2.6737346029525524

Epoch: 6| Step: 2
Training loss: 2.8630700755602123
Validation loss: 2.682783914413116

Epoch: 6| Step: 3
Training loss: 2.4342183249987595
Validation loss: 2.6692259044852804

Epoch: 6| Step: 4
Training loss: 3.2894298502360595
Validation loss: 2.6677988043553995

Epoch: 6| Step: 5
Training loss: 2.9658857482182914
Validation loss: 2.6539776148935887

Epoch: 6| Step: 6
Training loss: 2.6956786860624193
Validation loss: 2.638369236592992

Epoch: 6| Step: 7
Training loss: 2.6040823248874565
Validation loss: 2.6488711554165456

Epoch: 6| Step: 8
Training loss: 3.068455102739699
Validation loss: 2.618586803796857

Epoch: 6| Step: 9
Training loss: 2.7933610547252328
Validation loss: 2.6813594801978766

Epoch: 6| Step: 10
Training loss: 3.4887342340433634
Validation loss: 2.612595085599595

Epoch: 6| Step: 11
Training loss: 2.6214226460937438
Validation loss: 2.6680228459774398

Epoch: 6| Step: 12
Training loss: 2.143563029418563
Validation loss: 2.6866394080680505

Epoch: 6| Step: 13
Training loss: 2.9424544413369023
Validation loss: 2.6817988445429144

Epoch: 112| Step: 0
Training loss: 3.1901835196869515
Validation loss: 2.6840666111493294

Epoch: 6| Step: 1
Training loss: 3.1296722579333505
Validation loss: 2.6768645142107492

Epoch: 6| Step: 2
Training loss: 3.339379850595026
Validation loss: 2.6382630001217935

Epoch: 6| Step: 3
Training loss: 2.5235846036662952
Validation loss: 2.650278642871807

Epoch: 6| Step: 4
Training loss: 2.749503524353466
Validation loss: 2.6668504832989854

Epoch: 6| Step: 5
Training loss: 2.1170796159234757
Validation loss: 2.637530871359681

Epoch: 6| Step: 6
Training loss: 2.6572653232426586
Validation loss: 2.6169050715374538

Epoch: 6| Step: 7
Training loss: 2.404989630821541
Validation loss: 2.680381370076587

Epoch: 6| Step: 8
Training loss: 3.7044026548879665
Validation loss: 2.6864890190462223

Epoch: 6| Step: 9
Training loss: 2.484660582052972
Validation loss: 2.6611278646558025

Epoch: 6| Step: 10
Training loss: 2.7150433583599836
Validation loss: 2.6640247581309753

Epoch: 6| Step: 11
Training loss: 2.0741421960184407
Validation loss: 2.652132549917826

Epoch: 6| Step: 12
Training loss: 2.682963334710635
Validation loss: 2.655756359810888

Epoch: 6| Step: 13
Training loss: 2.8928532440589856
Validation loss: 2.6294003963124166

Epoch: 113| Step: 0
Training loss: 3.1633195923271304
Validation loss: 2.6389487923769304

Epoch: 6| Step: 1
Training loss: 2.193617848820208
Validation loss: 2.7052271716785876

Epoch: 6| Step: 2
Training loss: 2.812828214355893
Validation loss: 2.6086277222360423

Epoch: 6| Step: 3
Training loss: 2.8891904828373924
Validation loss: 2.64180167909579

Epoch: 6| Step: 4
Training loss: 2.8491684152159484
Validation loss: 2.6030203595429384

Epoch: 6| Step: 5
Training loss: 2.131973940147892
Validation loss: 2.6102416242769553

Epoch: 6| Step: 6
Training loss: 2.774273641564806
Validation loss: 2.6978462625935937

Epoch: 6| Step: 7
Training loss: 2.8011901642087014
Validation loss: 2.725836679832619

Epoch: 6| Step: 8
Training loss: 2.812414040841352
Validation loss: 2.6458421170378994

Epoch: 6| Step: 9
Training loss: 3.2196034901694235
Validation loss: 2.654953840990906

Epoch: 6| Step: 10
Training loss: 3.2127404267703743
Validation loss: 2.6063669743028117

Epoch: 6| Step: 11
Training loss: 2.3256029639241924
Validation loss: 2.6171189498923475

Epoch: 6| Step: 12
Training loss: 3.0921728564624527
Validation loss: 2.6249947516119816

Epoch: 6| Step: 13
Training loss: 2.6648913573544957
Validation loss: 2.687594851598816

Epoch: 114| Step: 0
Training loss: 3.6386509074140916
Validation loss: 2.641973562889089

Epoch: 6| Step: 1
Training loss: 3.296100832905995
Validation loss: 2.6663354493632974

Epoch: 6| Step: 2
Training loss: 2.1867290773246664
Validation loss: 2.608183808653665

Epoch: 6| Step: 3
Training loss: 2.795919585472761
Validation loss: 2.6408620146566437

Epoch: 6| Step: 4
Training loss: 2.9478480103027196
Validation loss: 2.654998937327389

Epoch: 6| Step: 5
Training loss: 2.3787097066733103
Validation loss: 2.6588851047730384

Epoch: 6| Step: 6
Training loss: 2.819641709799858
Validation loss: 2.6684576129660322

Epoch: 6| Step: 7
Training loss: 3.543956211017618
Validation loss: 2.671632086076411

Epoch: 6| Step: 8
Training loss: 2.12722616833863
Validation loss: 2.6768260334357334

Epoch: 6| Step: 9
Training loss: 2.4806250335239706
Validation loss: 2.591221289984799

Epoch: 6| Step: 10
Training loss: 2.8360101359499645
Validation loss: 2.6290261721947936

Epoch: 6| Step: 11
Training loss: 2.3503664339762858
Validation loss: 2.6423260764781005

Epoch: 6| Step: 12
Training loss: 2.632073182575636
Validation loss: 2.6200995460767507

Epoch: 6| Step: 13
Training loss: 2.337693488940773
Validation loss: 2.6367762813877347

Epoch: 115| Step: 0
Training loss: 2.99182891689086
Validation loss: 2.6972541301232535

Epoch: 6| Step: 1
Training loss: 2.5397465650022872
Validation loss: 2.6609837170842248

Epoch: 6| Step: 2
Training loss: 2.939336973411133
Validation loss: 2.6167148839854035

Epoch: 6| Step: 3
Training loss: 2.6738730650441784
Validation loss: 2.635785032150246

Epoch: 6| Step: 4
Training loss: 2.9649699992162555
Validation loss: 2.6625505679355266

Epoch: 6| Step: 5
Training loss: 2.7258051391499376
Validation loss: 2.6257995290257563

Epoch: 6| Step: 6
Training loss: 3.139751255849482
Validation loss: 2.6348468871945543

Epoch: 6| Step: 7
Training loss: 3.527703588978861
Validation loss: 2.656503887939659

Epoch: 6| Step: 8
Training loss: 2.2900827887616475
Validation loss: 2.670983481031359

Epoch: 6| Step: 9
Training loss: 2.5281420807326263
Validation loss: 2.6847221153045684

Epoch: 6| Step: 10
Training loss: 2.6469623429660962
Validation loss: 2.674681797294125

Epoch: 6| Step: 11
Training loss: 2.9736703353543916
Validation loss: 2.659846302140759

Epoch: 6| Step: 12
Training loss: 2.849268996870657
Validation loss: 2.695334604584928

Epoch: 6| Step: 13
Training loss: 1.8232700405026356
Validation loss: 2.6318184043389596

Epoch: 116| Step: 0
Training loss: 2.9702186565634947
Validation loss: 2.6493899481949046

Epoch: 6| Step: 1
Training loss: 2.21213900535984
Validation loss: 2.6772292955904873

Epoch: 6| Step: 2
Training loss: 2.3515366460956777
Validation loss: 2.6615953432845134

Epoch: 6| Step: 3
Training loss: 3.1504687248146355
Validation loss: 2.6075698476874836

Epoch: 6| Step: 4
Training loss: 2.796318126627873
Validation loss: 2.684220413722442

Epoch: 6| Step: 5
Training loss: 3.0974659807185914
Validation loss: 2.6599648679821444

Epoch: 6| Step: 6
Training loss: 3.0141803661060074
Validation loss: 2.6384928464588375

Epoch: 6| Step: 7
Training loss: 2.618173897314613
Validation loss: 2.6453517300772056

Epoch: 6| Step: 8
Training loss: 3.209906865132493
Validation loss: 2.636068946681005

Epoch: 6| Step: 9
Training loss: 2.6888855312350968
Validation loss: 2.6628432326901232

Epoch: 6| Step: 10
Training loss: 2.5830548864448697
Validation loss: 2.6781645061131916

Epoch: 6| Step: 11
Training loss: 2.266811086691298
Validation loss: 2.6189294010634354

Epoch: 6| Step: 12
Training loss: 2.778056164672908
Validation loss: 2.652039460494499

Epoch: 6| Step: 13
Training loss: 3.536895020855129
Validation loss: 2.6939619825793293

Epoch: 117| Step: 0
Training loss: 2.692819343408568
Validation loss: 2.6936059943411395

Epoch: 6| Step: 1
Training loss: 2.856064511208999
Validation loss: 2.6485234534979205

Epoch: 6| Step: 2
Training loss: 2.039500923816783
Validation loss: 2.564806514644112

Epoch: 6| Step: 3
Training loss: 2.7456084646052257
Validation loss: 2.6737403405486044

Epoch: 6| Step: 4
Training loss: 2.4275249903420875
Validation loss: 2.6834371858770916

Epoch: 6| Step: 5
Training loss: 2.8234703581375262
Validation loss: 2.6834137499109425

Epoch: 6| Step: 6
Training loss: 3.018029395868465
Validation loss: 2.6206902431370462

Epoch: 6| Step: 7
Training loss: 2.1055541295449633
Validation loss: 2.714800096315651

Epoch: 6| Step: 8
Training loss: 3.545512067777221
Validation loss: 2.612020388415046

Epoch: 6| Step: 9
Training loss: 3.1053345465302162
Validation loss: 2.692897286754096

Epoch: 6| Step: 10
Training loss: 3.1143158422490167
Validation loss: 2.6325511883635726

Epoch: 6| Step: 11
Training loss: 3.11646753854797
Validation loss: 2.627428062791055

Epoch: 6| Step: 12
Training loss: 2.7970215316832925
Validation loss: 2.63056170610648

Epoch: 6| Step: 13
Training loss: 2.7125947926917466
Validation loss: 2.6423713669832947

Epoch: 118| Step: 0
Training loss: 3.0954293981408316
Validation loss: 2.6655599126577987

Epoch: 6| Step: 1
Training loss: 2.8072887036102077
Validation loss: 2.5549154860701404

Epoch: 6| Step: 2
Training loss: 3.0373938522315838
Validation loss: 2.669181942703968

Epoch: 6| Step: 3
Training loss: 2.9757780708502315
Validation loss: 2.6167199177676457

Epoch: 6| Step: 4
Training loss: 2.4004740564731755
Validation loss: 2.6292845746297053

Epoch: 6| Step: 5
Training loss: 2.787893269256881
Validation loss: 2.5849663028737058

Epoch: 6| Step: 6
Training loss: 1.956254024318663
Validation loss: 2.6786595323315168

Epoch: 6| Step: 7
Training loss: 2.4446265870446244
Validation loss: 2.664977145716614

Epoch: 6| Step: 8
Training loss: 3.457871984632944
Validation loss: 2.6825007907400003

Epoch: 6| Step: 9
Training loss: 3.2318339663150453
Validation loss: 2.650088932110763

Epoch: 6| Step: 10
Training loss: 2.4714313866168496
Validation loss: 2.6480936910246595

Epoch: 6| Step: 11
Training loss: 3.126353924231565
Validation loss: 2.6969883979536466

Epoch: 6| Step: 12
Training loss: 2.326260223120231
Validation loss: 2.659045412020317

Epoch: 6| Step: 13
Training loss: 3.1859396312906676
Validation loss: 2.654901837744574

Epoch: 119| Step: 0
Training loss: 2.146656754907191
Validation loss: 2.619139974091371

Epoch: 6| Step: 1
Training loss: 2.370062665151106
Validation loss: 2.6393138914220424

Epoch: 6| Step: 2
Training loss: 2.3429936523742265
Validation loss: 2.7383208669065477

Epoch: 6| Step: 3
Training loss: 2.5836119552815267
Validation loss: 2.654170847524184

Epoch: 6| Step: 4
Training loss: 3.2376217970159353
Validation loss: 2.668325447283567

Epoch: 6| Step: 5
Training loss: 3.183207145573222
Validation loss: 2.6173978595804983

Epoch: 6| Step: 6
Training loss: 2.303054903741645
Validation loss: 2.723179063028622

Epoch: 6| Step: 7
Training loss: 2.3217390921697847
Validation loss: 2.5856233767928134

Epoch: 6| Step: 8
Training loss: 3.2490549914401794
Validation loss: 2.68442326373077

Epoch: 6| Step: 9
Training loss: 3.4557065677933982
Validation loss: 2.7279277138210265

Epoch: 6| Step: 10
Training loss: 1.694718850261026
Validation loss: 2.662232132961022

Epoch: 6| Step: 11
Training loss: 3.341250046581264
Validation loss: 2.643828121409894

Epoch: 6| Step: 12
Training loss: 3.153658416664142
Validation loss: 2.6606104833401565

Epoch: 6| Step: 13
Training loss: 3.212914519525509
Validation loss: 2.6946646372012504

Epoch: 120| Step: 0
Training loss: 2.4365126737612948
Validation loss: 2.664613696504711

Epoch: 6| Step: 1
Training loss: 3.757968954846272
Validation loss: 2.679134168622185

Epoch: 6| Step: 2
Training loss: 2.3592692976761938
Validation loss: 2.6300772880496734

Epoch: 6| Step: 3
Training loss: 2.882028033615886
Validation loss: 2.681623867274639

Epoch: 6| Step: 4
Training loss: 2.7915484465054536
Validation loss: 2.6179455524524267

Epoch: 6| Step: 5
Training loss: 2.585566929198978
Validation loss: 2.6370223166767204

Epoch: 6| Step: 6
Training loss: 2.802926533455171
Validation loss: 2.6860455543003674

Epoch: 6| Step: 7
Training loss: 2.0460897788657055
Validation loss: 2.6283376241160683

Epoch: 6| Step: 8
Training loss: 2.7566675505661693
Validation loss: 2.7117235850771744

Epoch: 6| Step: 9
Training loss: 2.172005080025705
Validation loss: 2.647726773978592

Epoch: 6| Step: 10
Training loss: 3.258853444168493
Validation loss: 2.6348630385331093

Epoch: 6| Step: 11
Training loss: 2.737697130882877
Validation loss: 2.6997624673541205

Epoch: 6| Step: 12
Training loss: 3.3321355734053233
Validation loss: 2.7008502870116247

Epoch: 6| Step: 13
Training loss: 2.5511707984035397
Validation loss: 2.6516710862193364

Epoch: 121| Step: 0
Training loss: 3.234829340918646
Validation loss: 2.6825664516107954

Epoch: 6| Step: 1
Training loss: 3.0889196738150604
Validation loss: 2.669657501539099

Epoch: 6| Step: 2
Training loss: 3.193556174650669
Validation loss: 2.644090176266777

Epoch: 6| Step: 3
Training loss: 2.834723935419296
Validation loss: 2.656437042426191

Epoch: 6| Step: 4
Training loss: 2.3248206120679287
Validation loss: 2.642567065510737

Epoch: 6| Step: 5
Training loss: 2.101526196247771
Validation loss: 2.6996171525285937

Epoch: 6| Step: 6
Training loss: 2.4056987378699177
Validation loss: 2.6198040125600466

Epoch: 6| Step: 7
Training loss: 3.5765822637102747
Validation loss: 2.610782899027304

Epoch: 6| Step: 8
Training loss: 2.1494661954860117
Validation loss: 2.6028638026116644

Epoch: 6| Step: 9
Training loss: 2.52142669588125
Validation loss: 2.61411478253039

Epoch: 6| Step: 10
Training loss: 3.0762030318362625
Validation loss: 2.65272863201837

Epoch: 6| Step: 11
Training loss: 2.23391462798481
Validation loss: 2.6351955385412724

Epoch: 6| Step: 12
Training loss: 2.5980937388587844
Validation loss: 2.683083752144869

Epoch: 6| Step: 13
Training loss: 3.6639120563130994
Validation loss: 2.64203922860928

Epoch: 122| Step: 0
Training loss: 3.031261011477261
Validation loss: 2.597634325806969

Epoch: 6| Step: 1
Training loss: 2.33174507263782
Validation loss: 2.7121635677116105

Epoch: 6| Step: 2
Training loss: 3.030207818587386
Validation loss: 2.6679871664701467

Epoch: 6| Step: 3
Training loss: 2.721824924082811
Validation loss: 2.6389086589997373

Epoch: 6| Step: 4
Training loss: 2.279441848498451
Validation loss: 2.707478382789858

Epoch: 6| Step: 5
Training loss: 2.6885171783959785
Validation loss: 2.6571699948817886

Epoch: 6| Step: 6
Training loss: 3.7453854461046565
Validation loss: 2.60139980051916

Epoch: 6| Step: 7
Training loss: 2.7548506179437493
Validation loss: 2.677289926467332

Epoch: 6| Step: 8
Training loss: 3.012374153516041
Validation loss: 2.660781109228464

Epoch: 6| Step: 9
Training loss: 1.9725556300722822
Validation loss: 2.6743441297402084

Epoch: 6| Step: 10
Training loss: 2.834195024691893
Validation loss: 2.6443555391859612

Epoch: 6| Step: 11
Training loss: 2.7624911208894707
Validation loss: 2.6473329034786257

Epoch: 6| Step: 12
Training loss: 2.9009858724729423
Validation loss: 2.6597425418503358

Epoch: 6| Step: 13
Training loss: 2.618402364230815
Validation loss: 2.6506693714581804

Epoch: 123| Step: 0
Training loss: 2.9232688475934023
Validation loss: 2.6415171190547015

Epoch: 6| Step: 1
Training loss: 3.38433733044739
Validation loss: 2.6762722349657335

Epoch: 6| Step: 2
Training loss: 2.772070061358361
Validation loss: 2.6698844963402815

Epoch: 6| Step: 3
Training loss: 2.741323829557715
Validation loss: 2.653549931817098

Epoch: 6| Step: 4
Training loss: 2.491291327471061
Validation loss: 2.6591206576813424

Epoch: 6| Step: 5
Training loss: 3.224563089982402
Validation loss: 2.660563274097669

Epoch: 6| Step: 6
Training loss: 2.3007325457095633
Validation loss: 2.6644569427097116

Epoch: 6| Step: 7
Training loss: 3.079298386361103
Validation loss: 2.66412429177366

Epoch: 6| Step: 8
Training loss: 3.1619980847270264
Validation loss: 2.696156690311812

Epoch: 6| Step: 9
Training loss: 2.603122735909786
Validation loss: 2.6826336112347384

Epoch: 6| Step: 10
Training loss: 2.0128142401787374
Validation loss: 2.713528494186572

Epoch: 6| Step: 11
Training loss: 2.474577291592285
Validation loss: 2.6229827423192904

Epoch: 6| Step: 12
Training loss: 3.3605490828500972
Validation loss: 2.6370059676007416

Epoch: 6| Step: 13
Training loss: 2.1662573305458324
Validation loss: 2.7150062099882746

Epoch: 124| Step: 0
Training loss: 3.233156278684948
Validation loss: 2.6288202655649235

Epoch: 6| Step: 1
Training loss: 2.4991887683745464
Validation loss: 2.6398223056931043

Epoch: 6| Step: 2
Training loss: 2.6706810676229606
Validation loss: 2.672000356507764

Epoch: 6| Step: 3
Training loss: 3.3583920482365075
Validation loss: 2.684395361172058

Epoch: 6| Step: 4
Training loss: 1.7455469423099503
Validation loss: 2.684396572132127

Epoch: 6| Step: 5
Training loss: 2.3625313570070974
Validation loss: 2.6217460876271126

Epoch: 6| Step: 6
Training loss: 2.662473053415255
Validation loss: 2.6260022966352525

Epoch: 6| Step: 7
Training loss: 3.335663330818532
Validation loss: 2.6342890603913265

Epoch: 6| Step: 8
Training loss: 2.8331991799701957
Validation loss: 2.5991973822912606

Epoch: 6| Step: 9
Training loss: 3.27902742225137
Validation loss: 2.65650745087624

Epoch: 6| Step: 10
Training loss: 1.8201481167813527
Validation loss: 2.587925661344793

Epoch: 6| Step: 11
Training loss: 1.8799372836061203
Validation loss: 2.6752417906604236

Epoch: 6| Step: 12
Training loss: 2.9983617760109853
Validation loss: 2.6405210659608636

Epoch: 6| Step: 13
Training loss: 3.6588743523779628
Validation loss: 2.636219596087851

Epoch: 125| Step: 0
Training loss: 3.2332275124238823
Validation loss: 2.6387774363155287

Epoch: 6| Step: 1
Training loss: 3.4136363446575406
Validation loss: 2.668389470146812

Epoch: 6| Step: 2
Training loss: 2.639775066041043
Validation loss: 2.685716166271826

Epoch: 6| Step: 3
Training loss: 3.0984735360793674
Validation loss: 2.664767212439216

Epoch: 6| Step: 4
Training loss: 2.6593553230821785
Validation loss: 2.653450149340827

Epoch: 6| Step: 5
Training loss: 2.65682169428017
Validation loss: 2.624576569610912

Epoch: 6| Step: 6
Training loss: 2.3289710434145015
Validation loss: 2.672426997294408

Epoch: 6| Step: 7
Training loss: 2.523001145939032
Validation loss: 2.6238994234693953

Epoch: 6| Step: 8
Training loss: 2.4870133695530656
Validation loss: 2.6541241887670153

Epoch: 6| Step: 9
Training loss: 2.8314863430517674
Validation loss: 2.638603462351363

Epoch: 6| Step: 10
Training loss: 3.1251669266940203
Validation loss: 2.6575312516881877

Epoch: 6| Step: 11
Training loss: 2.73293296936666
Validation loss: 2.6405717388426457

Epoch: 6| Step: 12
Training loss: 2.848725043769581
Validation loss: 2.7329737453625196

Epoch: 6| Step: 13
Training loss: 2.6568983296563795
Validation loss: 2.7108632188321446

Epoch: 126| Step: 0
Training loss: 2.3329781761538526
Validation loss: 2.6577276628152737

Epoch: 6| Step: 1
Training loss: 2.769863867323782
Validation loss: 2.63568705158658

Epoch: 6| Step: 2
Training loss: 2.6001562034928316
Validation loss: 2.5890599588575065

Epoch: 6| Step: 3
Training loss: 2.9448246640404445
Validation loss: 2.6584235740350906

Epoch: 6| Step: 4
Training loss: 2.535715943610342
Validation loss: 2.674979493153903

Epoch: 6| Step: 5
Training loss: 2.2326605561587503
Validation loss: 2.70026773388535

Epoch: 6| Step: 6
Training loss: 3.5929495541996466
Validation loss: 2.652909531281783

Epoch: 6| Step: 7
Training loss: 2.779579947043588
Validation loss: 2.6228085573640785

Epoch: 6| Step: 8
Training loss: 2.3120582777287986
Validation loss: 2.7034126492400294

Epoch: 6| Step: 9
Training loss: 3.7291611541764134
Validation loss: 2.618763834410915

Epoch: 6| Step: 10
Training loss: 1.9572654477390663
Validation loss: 2.6514999702976816

Epoch: 6| Step: 11
Training loss: 3.765530913511123
Validation loss: 2.719317320332258

Epoch: 6| Step: 12
Training loss: 2.3147550361826537
Validation loss: 2.6587930491732266

Epoch: 6| Step: 13
Training loss: 2.6597761199067342
Validation loss: 2.655600388370536

Epoch: 127| Step: 0
Training loss: 2.3678041164918873
Validation loss: 2.656063121999503

Epoch: 6| Step: 1
Training loss: 2.1854521839127354
Validation loss: 2.5935998303099455

Epoch: 6| Step: 2
Training loss: 3.316854385993347
Validation loss: 2.6127309878520735

Epoch: 6| Step: 3
Training loss: 3.6480636895291902
Validation loss: 2.6356906601713854

Epoch: 6| Step: 4
Training loss: 3.315029402152233
Validation loss: 2.6293622680540825

Epoch: 6| Step: 5
Training loss: 2.4349822710711693
Validation loss: 2.6363058506917914

Epoch: 6| Step: 6
Training loss: 2.275337290650414
Validation loss: 2.6426130552197686

Epoch: 6| Step: 7
Training loss: 2.5003713332011395
Validation loss: 2.6419067369090787

Epoch: 6| Step: 8
Training loss: 2.6319239897144215
Validation loss: 2.663257133960845

Epoch: 6| Step: 9
Training loss: 2.971257004526987
Validation loss: 2.6170584619748984

Epoch: 6| Step: 10
Training loss: 3.295154574622304
Validation loss: 2.654340385982179

Epoch: 6| Step: 11
Training loss: 3.045012075716575
Validation loss: 2.6469384387725223

Epoch: 6| Step: 12
Training loss: 2.3289675628054276
Validation loss: 2.630513935170109

Epoch: 6| Step: 13
Training loss: 2.539563220609195
Validation loss: 2.5822492101684977

Epoch: 128| Step: 0
Training loss: 2.02374548022665
Validation loss: 2.6446705353424846

Epoch: 6| Step: 1
Training loss: 2.413593826970598
Validation loss: 2.65561963201408

Epoch: 6| Step: 2
Training loss: 2.475539901877191
Validation loss: 2.657403898693173

Epoch: 6| Step: 3
Training loss: 2.105048256182778
Validation loss: 2.654109809250907

Epoch: 6| Step: 4
Training loss: 3.3094232053190624
Validation loss: 2.636862917855107

Epoch: 6| Step: 5
Training loss: 2.646295091680018
Validation loss: 2.610436649260922

Epoch: 6| Step: 6
Training loss: 2.5015465720990226
Validation loss: 2.631539318198399

Epoch: 6| Step: 7
Training loss: 2.503384397403265
Validation loss: 2.6099749528695697

Epoch: 6| Step: 8
Training loss: 2.9902763139510795
Validation loss: 2.668380388693518

Epoch: 6| Step: 9
Training loss: 2.687006350578978
Validation loss: 2.681232331536095

Epoch: 6| Step: 10
Training loss: 2.5913893286515104
Validation loss: 2.666452242193077

Epoch: 6| Step: 11
Training loss: 4.130644202433757
Validation loss: 2.6334956094075768

Epoch: 6| Step: 12
Training loss: 2.8863807655869307
Validation loss: 2.6288528060289504

Epoch: 6| Step: 13
Training loss: 2.2541585215799214
Validation loss: 2.647846518617398

Epoch: 129| Step: 0
Training loss: 2.3767525079677227
Validation loss: 2.640738621506459

Epoch: 6| Step: 1
Training loss: 2.181506420027252
Validation loss: 2.6438645574761974

Epoch: 6| Step: 2
Training loss: 2.629147114708732
Validation loss: 2.6498173410234056

Epoch: 6| Step: 3
Training loss: 2.0979249238726476
Validation loss: 2.676125419009043

Epoch: 6| Step: 4
Training loss: 2.7227061635153063
Validation loss: 2.671863243328069

Epoch: 6| Step: 5
Training loss: 2.092536688588953
Validation loss: 2.679766769525864

Epoch: 6| Step: 6
Training loss: 3.082260220027641
Validation loss: 2.6560463862884225

Epoch: 6| Step: 7
Training loss: 2.606889283153226
Validation loss: 2.696105220309093

Epoch: 6| Step: 8
Training loss: 3.3262980286557986
Validation loss: 2.6871590251349904

Epoch: 6| Step: 9
Training loss: 3.1245150380534996
Validation loss: 2.664257479913266

Epoch: 6| Step: 10
Training loss: 4.2151166175285395
Validation loss: 2.6868645693549364

Epoch: 6| Step: 11
Training loss: 2.38553831187314
Validation loss: 2.6482604597989594

Epoch: 6| Step: 12
Training loss: 3.0955004123298666
Validation loss: 2.6553518076014027

Epoch: 6| Step: 13
Training loss: 2.019999525428943
Validation loss: 2.6395708457944767

Epoch: 130| Step: 0
Training loss: 2.9903992570683275
Validation loss: 2.5942281832520604

Epoch: 6| Step: 1
Training loss: 2.3931707652496317
Validation loss: 2.678498408176322

Epoch: 6| Step: 2
Training loss: 3.766795376179314
Validation loss: 2.7238107486514367

Epoch: 6| Step: 3
Training loss: 2.2404438110470397
Validation loss: 2.6735876677821118

Epoch: 6| Step: 4
Training loss: 1.9576921698512697
Validation loss: 2.6339778050251326

Epoch: 6| Step: 5
Training loss: 3.2496387574364336
Validation loss: 2.6111074111023242

Epoch: 6| Step: 6
Training loss: 2.5364398263703896
Validation loss: 2.624508711648846

Epoch: 6| Step: 7
Training loss: 3.800922512710807
Validation loss: 2.658370630420086

Epoch: 6| Step: 8
Training loss: 2.615571117871591
Validation loss: 2.6404168948091673

Epoch: 6| Step: 9
Training loss: 2.591539751075138
Validation loss: 2.719621671583133

Epoch: 6| Step: 10
Training loss: 2.4510347244374056
Validation loss: 2.63684235751375

Epoch: 6| Step: 11
Training loss: 2.453435404388773
Validation loss: 2.623668885926015

Epoch: 6| Step: 12
Training loss: 2.5976743310284736
Validation loss: 2.64415381444877

Epoch: 6| Step: 13
Training loss: 2.783359713248534
Validation loss: 2.6930261893505736

Epoch: 131| Step: 0
Training loss: 3.6152376724137447
Validation loss: 2.6428595113432856

Epoch: 6| Step: 1
Training loss: 2.1339477200740595
Validation loss: 2.6122393410986984

Epoch: 6| Step: 2
Training loss: 2.32958958789102
Validation loss: 2.6458576770683497

Epoch: 6| Step: 3
Training loss: 3.3010265372063916
Validation loss: 2.7035867947538303

Epoch: 6| Step: 4
Training loss: 3.2543136140188875
Validation loss: 2.6918720550895467

Epoch: 6| Step: 5
Training loss: 2.4593117808804545
Validation loss: 2.652064034037855

Epoch: 6| Step: 6
Training loss: 3.4725065767625525
Validation loss: 2.6539136075699004

Epoch: 6| Step: 7
Training loss: 2.13181815530977
Validation loss: 2.6132355269428134

Epoch: 6| Step: 8
Training loss: 2.202236889333648
Validation loss: 2.62607656885566

Epoch: 6| Step: 9
Training loss: 3.0782870332313004
Validation loss: 2.628620446114398

Epoch: 6| Step: 10
Training loss: 2.7042099203246726
Validation loss: 2.654989440731971

Epoch: 6| Step: 11
Training loss: 2.8123652955751703
Validation loss: 2.6568306497583225

Epoch: 6| Step: 12
Training loss: 2.921544673423392
Validation loss: 2.663949832874036

Epoch: 6| Step: 13
Training loss: 1.999837213090224
Validation loss: 2.59187628165393

Epoch: 132| Step: 0
Training loss: 2.587943045607053
Validation loss: 2.630169725860683

Epoch: 6| Step: 1
Training loss: 3.000017801867755
Validation loss: 2.657755780718497

Epoch: 6| Step: 2
Training loss: 2.8412192685117943
Validation loss: 2.59171879930954

Epoch: 6| Step: 3
Training loss: 2.562757246549589
Validation loss: 2.6309572595941018

Epoch: 6| Step: 4
Training loss: 2.8551878575719614
Validation loss: 2.6687282499217777

Epoch: 6| Step: 5
Training loss: 2.466957793797489
Validation loss: 2.6216402316886733

Epoch: 6| Step: 6
Training loss: 3.2113433358663146
Validation loss: 2.7103111056670626

Epoch: 6| Step: 7
Training loss: 2.1472987260742844
Validation loss: 2.654591592181046

Epoch: 6| Step: 8
Training loss: 2.9491598969707273
Validation loss: 2.6619496952816197

Epoch: 6| Step: 9
Training loss: 2.721385949540903
Validation loss: 2.687841923552814

Epoch: 6| Step: 10
Training loss: 2.919527630679955
Validation loss: 2.61811686780094

Epoch: 6| Step: 11
Training loss: 2.4290085607497973
Validation loss: 2.6212495995570038

Epoch: 6| Step: 12
Training loss: 3.2919228047698015
Validation loss: 2.6094502563510114

Epoch: 6| Step: 13
Training loss: 2.4345351552127057
Validation loss: 2.6353724797510285

Epoch: 133| Step: 0
Training loss: 2.472341122667148
Validation loss: 2.6408639911212797

Epoch: 6| Step: 1
Training loss: 2.6582309292608137
Validation loss: 2.651636665914813

Epoch: 6| Step: 2
Training loss: 2.4157712746533826
Validation loss: 2.6898174953706397

Epoch: 6| Step: 3
Training loss: 2.751467053362578
Validation loss: 2.6438963174166945

Epoch: 6| Step: 4
Training loss: 2.852431742246823
Validation loss: 2.64423571498875

Epoch: 6| Step: 5
Training loss: 2.6611585255351784
Validation loss: 2.6439223076514082

Epoch: 6| Step: 6
Training loss: 3.1871023491044324
Validation loss: 2.652427667058722

Epoch: 6| Step: 7
Training loss: 3.622035557345388
Validation loss: 2.6117096693215376

Epoch: 6| Step: 8
Training loss: 1.9151501115176315
Validation loss: 2.6261315785375907

Epoch: 6| Step: 9
Training loss: 2.740144060621891
Validation loss: 2.6262932114999322

Epoch: 6| Step: 10
Training loss: 3.287721917962508
Validation loss: 2.6539545910974374

Epoch: 6| Step: 11
Training loss: 3.0803920704379806
Validation loss: 2.682638781259603

Epoch: 6| Step: 12
Training loss: 2.605950764188759
Validation loss: 2.6381457012693184

Epoch: 6| Step: 13
Training loss: 2.520787976910421
Validation loss: 2.6283563309550697

Epoch: 134| Step: 0
Training loss: 3.3351896997857753
Validation loss: 2.632674298219835

Epoch: 6| Step: 1
Training loss: 3.754401611924735
Validation loss: 2.6700198129027353

Epoch: 6| Step: 2
Training loss: 2.183745732076718
Validation loss: 2.6409890640563916

Epoch: 6| Step: 3
Training loss: 2.420004830158552
Validation loss: 2.652132639814756

Epoch: 6| Step: 4
Training loss: 3.2953927563462146
Validation loss: 2.6265157229078

Epoch: 6| Step: 5
Training loss: 2.570358507851914
Validation loss: 2.621387560646126

Epoch: 6| Step: 6
Training loss: 2.4701649920381077
Validation loss: 2.6746347525516803

Epoch: 6| Step: 7
Training loss: 2.7167649311790263
Validation loss: 2.6588609384859065

Epoch: 6| Step: 8
Training loss: 2.810956234575301
Validation loss: 2.65996570454948

Epoch: 6| Step: 9
Training loss: 2.071988560943252
Validation loss: 2.653919770546802

Epoch: 6| Step: 10
Training loss: 2.783885864039293
Validation loss: 2.6226756645391966

Epoch: 6| Step: 11
Training loss: 2.3924788723035664
Validation loss: 2.6458924971375084

Epoch: 6| Step: 12
Training loss: 2.9836407302390002
Validation loss: 2.6169007219055143

Epoch: 6| Step: 13
Training loss: 2.94989450557035
Validation loss: 2.6964668197830353

Epoch: 135| Step: 0
Training loss: 1.7751494223872417
Validation loss: 2.6986623678882466

Epoch: 6| Step: 1
Training loss: 2.5446138232111655
Validation loss: 2.638205780043324

Epoch: 6| Step: 2
Training loss: 3.1380560697526776
Validation loss: 2.6304827777314754

Epoch: 6| Step: 3
Training loss: 2.7232272234928736
Validation loss: 2.662574793167428

Epoch: 6| Step: 4
Training loss: 2.7078695829420325
Validation loss: 2.6586127479173873

Epoch: 6| Step: 5
Training loss: 2.1962588839495103
Validation loss: 2.67617651649687

Epoch: 6| Step: 6
Training loss: 2.7376754460658668
Validation loss: 2.678923822222943

Epoch: 6| Step: 7
Training loss: 2.6825929244158946
Validation loss: 2.613046773522071

Epoch: 6| Step: 8
Training loss: 3.0414449184182937
Validation loss: 2.6604823685865595

Epoch: 6| Step: 9
Training loss: 2.4593356292946904
Validation loss: 2.663527078400222

Epoch: 6| Step: 10
Training loss: 3.3794970751062734
Validation loss: 2.6994471926349664

Epoch: 6| Step: 11
Training loss: 2.386229819306874
Validation loss: 2.652987985225391

Epoch: 6| Step: 12
Training loss: 3.2770857771961164
Validation loss: 2.705643709023809

Epoch: 6| Step: 13
Training loss: 3.0760027545276705
Validation loss: 2.6624312785618356

Epoch: 136| Step: 0
Training loss: 2.6990929669498755
Validation loss: 2.6403381450093923

Epoch: 6| Step: 1
Training loss: 3.04805165580972
Validation loss: 2.651847221040292

Epoch: 6| Step: 2
Training loss: 2.2903788560542235
Validation loss: 2.66168472550159

Epoch: 6| Step: 3
Training loss: 2.7390322886496574
Validation loss: 2.6490606369321315

Epoch: 6| Step: 4
Training loss: 2.3812903373285454
Validation loss: 2.611660567524784

Epoch: 6| Step: 5
Training loss: 2.2684515848759093
Validation loss: 2.652138583638367

Epoch: 6| Step: 6
Training loss: 2.913068586522246
Validation loss: 2.6626620782394066

Epoch: 6| Step: 7
Training loss: 2.5175923301941174
Validation loss: 2.700106634482472

Epoch: 6| Step: 8
Training loss: 2.5727298581238722
Validation loss: 2.6309745495328873

Epoch: 6| Step: 9
Training loss: 3.2067815983161867
Validation loss: 2.6080633910770783

Epoch: 6| Step: 10
Training loss: 2.6432723820102324
Validation loss: 2.6986459087069754

Epoch: 6| Step: 11
Training loss: 3.3557008034664313
Validation loss: 2.639861763842982

Epoch: 6| Step: 12
Training loss: 2.592075036881875
Validation loss: 2.6812299421345025

Epoch: 6| Step: 13
Training loss: 4.110381376666344
Validation loss: 2.653894079146059

Epoch: 137| Step: 0
Training loss: 3.521354651746118
Validation loss: 2.7013683663294357

Epoch: 6| Step: 1
Training loss: 2.8162211914214463
Validation loss: 2.641171527887958

Epoch: 6| Step: 2
Training loss: 2.9082165699193916
Validation loss: 2.6354528769400467

Epoch: 6| Step: 3
Training loss: 2.937072560480061
Validation loss: 2.602577998424865

Epoch: 6| Step: 4
Training loss: 2.365223891646875
Validation loss: 2.642711553120115

Epoch: 6| Step: 5
Training loss: 2.660354763695903
Validation loss: 2.6286329579502126

Epoch: 6| Step: 6
Training loss: 3.091937526412254
Validation loss: 2.607875597288946

Epoch: 6| Step: 7
Training loss: 2.3688147463039675
Validation loss: 2.6379348936379063

Epoch: 6| Step: 8
Training loss: 3.148928469105013
Validation loss: 2.6966570277576505

Epoch: 6| Step: 9
Training loss: 2.8647130948356168
Validation loss: 2.6693668372024577

Epoch: 6| Step: 10
Training loss: 1.5860822639729628
Validation loss: 2.699525194376225

Epoch: 6| Step: 11
Training loss: 2.905407527105203
Validation loss: 2.644686186599859

Epoch: 6| Step: 12
Training loss: 2.1558656211689278
Validation loss: 2.6606565037042955

Epoch: 6| Step: 13
Training loss: 3.1521304600821853
Validation loss: 2.656308251067333

Epoch: 138| Step: 0
Training loss: 2.2123453894436063
Validation loss: 2.600173906279631

Epoch: 6| Step: 1
Training loss: 2.9362049900598466
Validation loss: 2.682427169064483

Epoch: 6| Step: 2
Training loss: 2.3043396768120736
Validation loss: 2.6519879907450483

Epoch: 6| Step: 3
Training loss: 3.3487470133997013
Validation loss: 2.6716704919691323

Epoch: 6| Step: 4
Training loss: 2.942238415132175
Validation loss: 2.677293403331385

Epoch: 6| Step: 5
Training loss: 2.83350480252679
Validation loss: 2.6357431192934455

Epoch: 6| Step: 6
Training loss: 2.6699138381714262
Validation loss: 2.6487040379391735

Epoch: 6| Step: 7
Training loss: 2.4962996754600897
Validation loss: 2.664685048211402

Epoch: 6| Step: 8
Training loss: 3.2437058168316466
Validation loss: 2.669314660473613

Epoch: 6| Step: 9
Training loss: 3.109277618263458
Validation loss: 2.679055013390384

Epoch: 6| Step: 10
Training loss: 2.67397159166446
Validation loss: 2.659663416752005

Epoch: 6| Step: 11
Training loss: 2.7247808805788347
Validation loss: 2.65315072238617

Epoch: 6| Step: 12
Training loss: 2.558687118107953
Validation loss: 2.6213899703652066

Epoch: 6| Step: 13
Training loss: 2.3611539487754953
Validation loss: 2.644418939282646

Epoch: 139| Step: 0
Training loss: 2.622957797607927
Validation loss: 2.6391294306773365

Epoch: 6| Step: 1
Training loss: 2.515837855840937
Validation loss: 2.6491538590931456

Epoch: 6| Step: 2
Training loss: 2.2913009582946398
Validation loss: 2.6670896043503536

Epoch: 6| Step: 3
Training loss: 1.733519747075578
Validation loss: 2.6382094123915554

Epoch: 6| Step: 4
Training loss: 3.3686784952533424
Validation loss: 2.647793848103196

Epoch: 6| Step: 5
Training loss: 2.1916314483636485
Validation loss: 2.659647104679115

Epoch: 6| Step: 6
Training loss: 2.5574672869159087
Validation loss: 2.7406044154400235

Epoch: 6| Step: 7
Training loss: 2.85310117412868
Validation loss: 2.614572686215898

Epoch: 6| Step: 8
Training loss: 2.9610115786824944
Validation loss: 2.5982343216930195

Epoch: 6| Step: 9
Training loss: 2.685520241345204
Validation loss: 2.632496231999296

Epoch: 6| Step: 10
Training loss: 3.0489610622243046
Validation loss: 2.6612456470541894

Epoch: 6| Step: 11
Training loss: 3.223120231750642
Validation loss: 2.630571695816425

Epoch: 6| Step: 12
Training loss: 3.2561245943548296
Validation loss: 2.64317609506491

Epoch: 6| Step: 13
Training loss: 3.0118332184289893
Validation loss: 2.6694010365702474

Epoch: 140| Step: 0
Training loss: 3.232542541648808
Validation loss: 2.6263792142442592

Epoch: 6| Step: 1
Training loss: 3.059615508962377
Validation loss: 2.672920895961422

Epoch: 6| Step: 2
Training loss: 2.9517597897912387
Validation loss: 2.631987481797101

Epoch: 6| Step: 3
Training loss: 1.9610066800623775
Validation loss: 2.660704934480667

Epoch: 6| Step: 4
Training loss: 1.7948326777729957
Validation loss: 2.7080138258605086

Epoch: 6| Step: 5
Training loss: 3.0481361322315044
Validation loss: 2.6496668619565042

Epoch: 6| Step: 6
Training loss: 2.294045918265339
Validation loss: 2.6791288894467384

Epoch: 6| Step: 7
Training loss: 2.9125098625310817
Validation loss: 2.6176210957995485

Epoch: 6| Step: 8
Training loss: 3.5397361131146883
Validation loss: 2.678942173908671

Epoch: 6| Step: 9
Training loss: 2.9738693268523684
Validation loss: 2.6892873091675678

Epoch: 6| Step: 10
Training loss: 2.917520307324757
Validation loss: 2.6196240693795914

Epoch: 6| Step: 11
Training loss: 2.9084216792142668
Validation loss: 2.696073921350753

Epoch: 6| Step: 12
Training loss: 2.1945222674491873
Validation loss: 2.701373556490593

Epoch: 6| Step: 13
Training loss: 2.2258446322541956
Validation loss: 2.671038869258548

Epoch: 141| Step: 0
Training loss: 3.2403628442830077
Validation loss: 2.684158234540522

Epoch: 6| Step: 1
Training loss: 2.9102452206932443
Validation loss: 2.6091842714295876

Epoch: 6| Step: 2
Training loss: 2.8762894102444516
Validation loss: 2.663564391315565

Epoch: 6| Step: 3
Training loss: 2.563294729414183
Validation loss: 2.636421959025165

Epoch: 6| Step: 4
Training loss: 2.7782929377221244
Validation loss: 2.660885522707235

Epoch: 6| Step: 5
Training loss: 2.879650004365816
Validation loss: 2.684832495633804

Epoch: 6| Step: 6
Training loss: 2.6252582967925138
Validation loss: 2.6459223831018486

Epoch: 6| Step: 7
Training loss: 2.613407331541373
Validation loss: 2.6302386522246266

Epoch: 6| Step: 8
Training loss: 2.941694146767301
Validation loss: 2.6665802301990484

Epoch: 6| Step: 9
Training loss: 3.05792205567506
Validation loss: 2.6353706771869665

Epoch: 6| Step: 10
Training loss: 2.2496159543661385
Validation loss: 2.6390526814803494

Epoch: 6| Step: 11
Training loss: 2.8763371550789207
Validation loss: 2.5958742214515547

Epoch: 6| Step: 12
Training loss: 2.6979960917168113
Validation loss: 2.6337740667812355

Epoch: 6| Step: 13
Training loss: 2.4886241538831797
Validation loss: 2.6326079275877206

Epoch: 142| Step: 0
Training loss: 3.0242962862017007
Validation loss: 2.6605310222295633

Epoch: 6| Step: 1
Training loss: 2.5754719348015973
Validation loss: 2.633116928859355

Epoch: 6| Step: 2
Training loss: 2.199003327627817
Validation loss: 2.651435804539559

Epoch: 6| Step: 3
Training loss: 2.248164699989756
Validation loss: 2.6461887267888606

Epoch: 6| Step: 4
Training loss: 3.4173937853455887
Validation loss: 2.6499592730534136

Epoch: 6| Step: 5
Training loss: 1.9613468305269008
Validation loss: 2.6323998313652957

Epoch: 6| Step: 6
Training loss: 2.765472407899775
Validation loss: 2.657560102881521

Epoch: 6| Step: 7
Training loss: 3.0257685544087196
Validation loss: 2.641918877244636

Epoch: 6| Step: 8
Training loss: 2.853013596965962
Validation loss: 2.631666598487528

Epoch: 6| Step: 9
Training loss: 2.3068837191970655
Validation loss: 2.6301079872960265

Epoch: 6| Step: 10
Training loss: 2.591657414884909
Validation loss: 2.6918934393741667

Epoch: 6| Step: 11
Training loss: 3.147153985575434
Validation loss: 2.6890655006370547

Epoch: 6| Step: 12
Training loss: 3.081778744409174
Validation loss: 2.7116336872474176

Epoch: 6| Step: 13
Training loss: 2.3956720270228082
Validation loss: 2.6251812182337453

Epoch: 143| Step: 0
Training loss: 2.9281460788745695
Validation loss: 2.600311654590706

Epoch: 6| Step: 1
Training loss: 2.638761867566982
Validation loss: 2.6440064493323163

Epoch: 6| Step: 2
Training loss: 2.8633295448050196
Validation loss: 2.640620592354765

Epoch: 6| Step: 3
Training loss: 3.103443718683982
Validation loss: 2.6072097468965834

Epoch: 6| Step: 4
Training loss: 1.8720734963865076
Validation loss: 2.6675758683309696

Epoch: 6| Step: 5
Training loss: 3.2050025461457565
Validation loss: 2.648954876662004

Epoch: 6| Step: 6
Training loss: 2.979579247847196
Validation loss: 2.6451060973776324

Epoch: 6| Step: 7
Training loss: 2.4675815569570085
Validation loss: 2.6968979405019295

Epoch: 6| Step: 8
Training loss: 2.285773091326109
Validation loss: 2.6592813758685

Epoch: 6| Step: 9
Training loss: 2.1997639876262465
Validation loss: 2.675620883836413

Epoch: 6| Step: 10
Training loss: 2.6926785632811443
Validation loss: 2.681593648803505

Epoch: 6| Step: 11
Training loss: 2.6493470197182347
Validation loss: 2.6406879217315202

Epoch: 6| Step: 12
Training loss: 2.930795688844751
Validation loss: 2.7398569647360325

Epoch: 6| Step: 13
Training loss: 3.913900710852801
Validation loss: 2.5969663461451473

Epoch: 144| Step: 0
Training loss: 2.9988211858901903
Validation loss: 2.656333787864549

Epoch: 6| Step: 1
Training loss: 3.294968618842631
Validation loss: 2.6715236908528257

Epoch: 6| Step: 2
Training loss: 2.7360374410644037
Validation loss: 2.6147698191804034

Epoch: 6| Step: 3
Training loss: 3.085271913239656
Validation loss: 2.656614146646092

Epoch: 6| Step: 4
Training loss: 2.1096290717935795
Validation loss: 2.618986633618468

Epoch: 6| Step: 5
Training loss: 2.6504962312577662
Validation loss: 2.649105668106762

Epoch: 6| Step: 6
Training loss: 2.620866063514517
Validation loss: 2.658500519550267

Epoch: 6| Step: 7
Training loss: 2.874477670739092
Validation loss: 2.5799360838013774

Epoch: 6| Step: 8
Training loss: 2.701292000814301
Validation loss: 2.690881022269527

Epoch: 6| Step: 9
Training loss: 2.371101190847571
Validation loss: 2.6076910765071797

Epoch: 6| Step: 10
Training loss: 2.9376895924521302
Validation loss: 2.7166787323217294

Epoch: 6| Step: 11
Training loss: 2.27081693124243
Validation loss: 2.6297571075221025

Epoch: 6| Step: 12
Training loss: 2.902310562457462
Validation loss: 2.6591151960867085

Epoch: 6| Step: 13
Training loss: 2.929068945117869
Validation loss: 2.6454106824076944

Epoch: 145| Step: 0
Training loss: 2.581060876452805
Validation loss: 2.6559651501369848

Epoch: 6| Step: 1
Training loss: 3.316920659549029
Validation loss: 2.641816304160713

Epoch: 6| Step: 2
Training loss: 2.6086126801522815
Validation loss: 2.652216242640844

Epoch: 6| Step: 3
Training loss: 3.0387568381392236
Validation loss: 2.6178260236134996

Epoch: 6| Step: 4
Training loss: 2.3220911882880166
Validation loss: 2.6264756035493275

Epoch: 6| Step: 5
Training loss: 3.3847533686394513
Validation loss: 2.6429118766712225

Epoch: 6| Step: 6
Training loss: 2.694382128262542
Validation loss: 2.671126845185965

Epoch: 6| Step: 7
Training loss: 2.6161146099929202
Validation loss: 2.6587904978665806

Epoch: 6| Step: 8
Training loss: 2.424887770582518
Validation loss: 2.61498706424558

Epoch: 6| Step: 9
Training loss: 2.347773645801261
Validation loss: 2.639514676313444

Epoch: 6| Step: 10
Training loss: 2.424144641211847
Validation loss: 2.6069462967000505

Epoch: 6| Step: 11
Training loss: 2.565784303502937
Validation loss: 2.6769119861598125

Epoch: 6| Step: 12
Training loss: 2.538209930479369
Validation loss: 2.608527986471661

Epoch: 6| Step: 13
Training loss: 3.791780672699944
Validation loss: 2.659343383812436

Epoch: 146| Step: 0
Training loss: 3.000176265624554
Validation loss: 2.669931513401217

Epoch: 6| Step: 1
Training loss: 2.8430523697856414
Validation loss: 2.6198758752100644

Epoch: 6| Step: 2
Training loss: 3.203232033034525
Validation loss: 2.6580994760997134

Epoch: 6| Step: 3
Training loss: 3.3383714431159266
Validation loss: 2.6980753269279005

Epoch: 6| Step: 4
Training loss: 2.713132294120202
Validation loss: 2.647788562597979

Epoch: 6| Step: 5
Training loss: 2.4325731810238262
Validation loss: 2.674450991014313

Epoch: 6| Step: 6
Training loss: 2.8944974786639044
Validation loss: 2.6375722873184566

Epoch: 6| Step: 7
Training loss: 2.2916503443281178
Validation loss: 2.717116283119442

Epoch: 6| Step: 8
Training loss: 2.609416207542091
Validation loss: 2.668276238234885

Epoch: 6| Step: 9
Training loss: 3.2740509987822355
Validation loss: 2.6689366301244983

Epoch: 6| Step: 10
Training loss: 2.4381805839157886
Validation loss: 2.6309827355153317

Epoch: 6| Step: 11
Training loss: 2.2180316460624656
Validation loss: 2.704834231158316

Epoch: 6| Step: 12
Training loss: 2.970498624104321
Validation loss: 2.640449109341556

Epoch: 6| Step: 13
Training loss: 2.5803289067773663
Validation loss: 2.6084780866923003

Epoch: 147| Step: 0
Training loss: 2.990220660994842
Validation loss: 2.698925281293037

Epoch: 6| Step: 1
Training loss: 2.56179772034543
Validation loss: 2.6592809998947775

Epoch: 6| Step: 2
Training loss: 2.3704100979129326
Validation loss: 2.664301242944062

Epoch: 6| Step: 3
Training loss: 2.3294323828210284
Validation loss: 2.643401989858005

Epoch: 6| Step: 4
Training loss: 2.1586732378257434
Validation loss: 2.648332516366343

Epoch: 6| Step: 5
Training loss: 3.350915521807369
Validation loss: 2.677266335188709

Epoch: 6| Step: 6
Training loss: 2.665338026298652
Validation loss: 2.629340188004368

Epoch: 6| Step: 7
Training loss: 2.4529357642787915
Validation loss: 2.6342199285832324

Epoch: 6| Step: 8
Training loss: 3.552072623824963
Validation loss: 2.5881605485293426

Epoch: 6| Step: 9
Training loss: 2.2679864612693295
Validation loss: 2.654251702988434

Epoch: 6| Step: 10
Training loss: 3.2964153240523957
Validation loss: 2.6736071779729746

Epoch: 6| Step: 11
Training loss: 2.0246701996292744
Validation loss: 2.678126807903894

Epoch: 6| Step: 12
Training loss: 2.9483819241686042
Validation loss: 2.5673305792134378

Epoch: 6| Step: 13
Training loss: 3.25935484604717
Validation loss: 2.64295039921263

Epoch: 148| Step: 0
Training loss: 2.5769181634700633
Validation loss: 2.6507200544067704

Epoch: 6| Step: 1
Training loss: 1.9801852834110178
Validation loss: 2.603286573446416

Epoch: 6| Step: 2
Training loss: 2.4090992295986853
Validation loss: 2.66070275499905

Epoch: 6| Step: 3
Training loss: 3.420846723622465
Validation loss: 2.696190846529778

Epoch: 6| Step: 4
Training loss: 2.5345387698692754
Validation loss: 2.645820096032636

Epoch: 6| Step: 5
Training loss: 2.8477848479193546
Validation loss: 2.636907510324502

Epoch: 6| Step: 6
Training loss: 2.7358413688114838
Validation loss: 2.6130358039036157

Epoch: 6| Step: 7
Training loss: 2.6516765041716304
Validation loss: 2.6125455313917443

Epoch: 6| Step: 8
Training loss: 2.6970270425630978
Validation loss: 2.5934882261087275

Epoch: 6| Step: 9
Training loss: 3.515051222708796
Validation loss: 2.6476303507976695

Epoch: 6| Step: 10
Training loss: 2.412110758792619
Validation loss: 2.638939179734819

Epoch: 6| Step: 11
Training loss: 2.5049284040380653
Validation loss: 2.630756535395044

Epoch: 6| Step: 12
Training loss: 3.253085505734085
Validation loss: 2.640283053609897

Epoch: 6| Step: 13
Training loss: 2.7219918752600885
Validation loss: 2.6722083333270295

Epoch: 149| Step: 0
Training loss: 3.032423912911527
Validation loss: 2.673646380110148

Epoch: 6| Step: 1
Training loss: 2.5473750273024427
Validation loss: 2.704727510616145

Epoch: 6| Step: 2
Training loss: 2.9287775279504484
Validation loss: 2.631529846540209

Epoch: 6| Step: 3
Training loss: 2.419782756165547
Validation loss: 2.6684920593598074

Epoch: 6| Step: 4
Training loss: 2.191990629941864
Validation loss: 2.6873765742049383

Epoch: 6| Step: 5
Training loss: 3.2679397191402675
Validation loss: 2.6961387800413985

Epoch: 6| Step: 6
Training loss: 2.183759925265103
Validation loss: 2.6712715135675285

Epoch: 6| Step: 7
Training loss: 2.791177925105228
Validation loss: 2.6555692298607916

Epoch: 6| Step: 8
Training loss: 2.9469630627707164
Validation loss: 2.6606114088331654

Epoch: 6| Step: 9
Training loss: 3.518416589149131
Validation loss: 2.700016628063778

Epoch: 6| Step: 10
Training loss: 2.4185007523840523
Validation loss: 2.675618762496035

Epoch: 6| Step: 11
Training loss: 2.5060605974048173
Validation loss: 2.664482349452371

Epoch: 6| Step: 12
Training loss: 3.0378880131305475
Validation loss: 2.6564124977550914

Epoch: 6| Step: 13
Training loss: 2.948957782845472
Validation loss: 2.659266090083734

Epoch: 150| Step: 0
Training loss: 2.4990173315917983
Validation loss: 2.665054319982825

Epoch: 6| Step: 1
Training loss: 2.786889177805188
Validation loss: 2.5781343113745687

Epoch: 6| Step: 2
Training loss: 2.986557726519447
Validation loss: 2.66959095081575

Epoch: 6| Step: 3
Training loss: 3.59814396802691
Validation loss: 2.6579298446574455

Epoch: 6| Step: 4
Training loss: 2.9517227961327874
Validation loss: 2.6387360246989044

Epoch: 6| Step: 5
Training loss: 2.125359336539994
Validation loss: 2.6735284593734834

Epoch: 6| Step: 6
Training loss: 2.2650841429114714
Validation loss: 2.668699465191034

Epoch: 6| Step: 7
Training loss: 2.3521473306261926
Validation loss: 2.6856895820236626

Epoch: 6| Step: 8
Training loss: 2.797920159635733
Validation loss: 2.6355262544522238

Epoch: 6| Step: 9
Training loss: 3.1224429540867322
Validation loss: 2.6202131692423487

Epoch: 6| Step: 10
Training loss: 2.9846228052284505
Validation loss: 2.6451275292422247

Epoch: 6| Step: 11
Training loss: 2.4188600539766405
Validation loss: 2.6604208333467216

Epoch: 6| Step: 12
Training loss: 2.420739282913855
Validation loss: 2.635776850383435

Epoch: 6| Step: 13
Training loss: 2.4000740556417623
Validation loss: 2.6806269828212885

Epoch: 151| Step: 0
Training loss: 3.097234747784827
Validation loss: 2.675038318208165

Epoch: 6| Step: 1
Training loss: 3.2779003666369473
Validation loss: 2.6609124877194232

Epoch: 6| Step: 2
Training loss: 2.833692602679319
Validation loss: 2.576511671036209

Epoch: 6| Step: 3
Training loss: 2.8647387283253916
Validation loss: 2.6571995832383584

Epoch: 6| Step: 4
Training loss: 2.5019641789617246
Validation loss: 2.6461061242240462

Epoch: 6| Step: 5
Training loss: 2.7379389615608063
Validation loss: 2.596211607177457

Epoch: 6| Step: 6
Training loss: 1.7595162506046846
Validation loss: 2.665722895003043

Epoch: 6| Step: 7
Training loss: 2.858498193937448
Validation loss: 2.709933137064671

Epoch: 6| Step: 8
Training loss: 2.5497489581232666
Validation loss: 2.635168575963861

Epoch: 6| Step: 9
Training loss: 3.0091918952987915
Validation loss: 2.6447534735437124

Epoch: 6| Step: 10
Training loss: 2.3784690417587906
Validation loss: 2.619604692449554

Epoch: 6| Step: 11
Training loss: 2.9060042082512583
Validation loss: 2.6819851270149497

Epoch: 6| Step: 12
Training loss: 2.695350182311316
Validation loss: 2.6601012134193764

Epoch: 6| Step: 13
Training loss: 2.440649882835704
Validation loss: 2.588866677518235

Epoch: 152| Step: 0
Training loss: 2.505316897846752
Validation loss: 2.711069644105636

Epoch: 6| Step: 1
Training loss: 2.5619550916441844
Validation loss: 2.643401948155476

Epoch: 6| Step: 2
Training loss: 3.4474302257976395
Validation loss: 2.6394755339792795

Epoch: 6| Step: 3
Training loss: 3.4938956569819655
Validation loss: 2.6718454273570815

Epoch: 6| Step: 4
Training loss: 2.359706526952253
Validation loss: 2.660968012354786

Epoch: 6| Step: 5
Training loss: 1.9757205542023724
Validation loss: 2.6402867102875156

Epoch: 6| Step: 6
Training loss: 3.4384823869234964
Validation loss: 2.6533425157051824

Epoch: 6| Step: 7
Training loss: 2.265562701190886
Validation loss: 2.596050550340308

Epoch: 6| Step: 8
Training loss: 2.6203320188028516
Validation loss: 2.6557923011296536

Epoch: 6| Step: 9
Training loss: 2.529282924068668
Validation loss: 2.6196142845371533

Epoch: 6| Step: 10
Training loss: 1.96299763098412
Validation loss: 2.6660553099367976

Epoch: 6| Step: 11
Training loss: 3.202904074888827
Validation loss: 2.6668541564198387

Epoch: 6| Step: 12
Training loss: 2.987556399527287
Validation loss: 2.6078010101852676

Epoch: 6| Step: 13
Training loss: 2.123310764059054
Validation loss: 2.610660400697383

Epoch: 153| Step: 0
Training loss: 2.1944813088111914
Validation loss: 2.6470549572079887

Epoch: 6| Step: 1
Training loss: 2.3828984479568462
Validation loss: 2.6206719027075485

Epoch: 6| Step: 2
Training loss: 3.0937697284724504
Validation loss: 2.651739973826868

Epoch: 6| Step: 3
Training loss: 2.7157743107844396
Validation loss: 2.6227017863773923

Epoch: 6| Step: 4
Training loss: 2.7868128660931935
Validation loss: 2.6198836839089332

Epoch: 6| Step: 5
Training loss: 3.2528257556666813
Validation loss: 2.552821407778208

Epoch: 6| Step: 6
Training loss: 2.832385147607869
Validation loss: 2.5944857531708014

Epoch: 6| Step: 7
Training loss: 3.4053956806546415
Validation loss: 2.6494976969233495

Epoch: 6| Step: 8
Training loss: 2.4464529869603515
Validation loss: 2.6383946642653497

Epoch: 6| Step: 9
Training loss: 2.7687279487231184
Validation loss: 2.661801330883609

Epoch: 6| Step: 10
Training loss: 2.392072351675558
Validation loss: 2.6449297079802974

Epoch: 6| Step: 11
Training loss: 2.8016482917172487
Validation loss: 2.670780850420925

Epoch: 6| Step: 12
Training loss: 2.8788494378828733
Validation loss: 2.6535059924361053

Epoch: 6| Step: 13
Training loss: 2.32768880354918
Validation loss: 2.6781334110159087

Epoch: 154| Step: 0
Training loss: 2.4962584153187755
Validation loss: 2.645887254826487

Epoch: 6| Step: 1
Training loss: 2.5324591115378996
Validation loss: 2.675369743391552

Epoch: 6| Step: 2
Training loss: 2.8495841074209607
Validation loss: 2.6876124820889253

Epoch: 6| Step: 3
Training loss: 2.694070457992774
Validation loss: 2.6274371145529454

Epoch: 6| Step: 4
Training loss: 2.443038712034366
Validation loss: 2.6773958112788785

Epoch: 6| Step: 5
Training loss: 2.5273116756803606
Validation loss: 2.5872435521298387

Epoch: 6| Step: 6
Training loss: 2.1711543143034664
Validation loss: 2.690393571425306

Epoch: 6| Step: 7
Training loss: 2.9251902330925885
Validation loss: 2.6900889334063547

Epoch: 6| Step: 8
Training loss: 2.580204904980333
Validation loss: 2.688839152611272

Epoch: 6| Step: 9
Training loss: 2.556839809133594
Validation loss: 2.6389366888939003

Epoch: 6| Step: 10
Training loss: 2.937194808364804
Validation loss: 2.6611586787086345

Epoch: 6| Step: 11
Training loss: 3.3933330919107028
Validation loss: 2.649031412517309

Epoch: 6| Step: 12
Training loss: 3.1486937463573064
Validation loss: 2.6356897536486588

Epoch: 6| Step: 13
Training loss: 2.732276590887187
Validation loss: 2.6789407556935023

Epoch: 155| Step: 0
Training loss: 3.3739828767008446
Validation loss: 2.627976656223415

Epoch: 6| Step: 1
Training loss: 2.3487586862059353
Validation loss: 2.6625063659477863

Epoch: 6| Step: 2
Training loss: 3.2046090014592865
Validation loss: 2.682712670433769

Epoch: 6| Step: 3
Training loss: 2.533165665984126
Validation loss: 2.6809848378821513

Epoch: 6| Step: 4
Training loss: 2.9930428261030144
Validation loss: 2.644535451428774

Epoch: 6| Step: 5
Training loss: 2.9068971959252745
Validation loss: 2.62695128640585

Epoch: 6| Step: 6
Training loss: 2.7140344524965743
Validation loss: 2.68657923247626

Epoch: 6| Step: 7
Training loss: 2.011410706277411
Validation loss: 2.663457058125203

Epoch: 6| Step: 8
Training loss: 3.3493684999033073
Validation loss: 2.654023175050416

Epoch: 6| Step: 9
Training loss: 2.4601692090339755
Validation loss: 2.6518831863383885

Epoch: 6| Step: 10
Training loss: 2.582353026499843
Validation loss: 2.628131990807652

Epoch: 6| Step: 11
Training loss: 2.687395670440427
Validation loss: 2.703717222535189

Epoch: 6| Step: 12
Training loss: 2.609419862281591
Validation loss: 2.7098269153384646

Epoch: 6| Step: 13
Training loss: 1.8435883531993378
Validation loss: 2.6868711738927575

Epoch: 156| Step: 0
Training loss: 2.729966975700535
Validation loss: 2.720664834591545

Epoch: 6| Step: 1
Training loss: 2.800901444967128
Validation loss: 2.6432783098722648

Epoch: 6| Step: 2
Training loss: 3.0633758538096663
Validation loss: 2.6746388165937054

Epoch: 6| Step: 3
Training loss: 2.6487542697211395
Validation loss: 2.561494171163169

Epoch: 6| Step: 4
Training loss: 2.500763395103298
Validation loss: 2.663622940556439

Epoch: 6| Step: 5
Training loss: 3.118413468973696
Validation loss: 2.6555884061538237

Epoch: 6| Step: 6
Training loss: 2.152600060240672
Validation loss: 2.620806386917259

Epoch: 6| Step: 7
Training loss: 3.5316777603193605
Validation loss: 2.575511551662168

Epoch: 6| Step: 8
Training loss: 2.40334253405513
Validation loss: 2.5786247069938075

Epoch: 6| Step: 9
Training loss: 2.3891070165285146
Validation loss: 2.6745726428693963

Epoch: 6| Step: 10
Training loss: 3.262667836516305
Validation loss: 2.6590017124099505

Epoch: 6| Step: 11
Training loss: 2.340144728724998
Validation loss: 2.619415792167146

Epoch: 6| Step: 12
Training loss: 2.6804347650680023
Validation loss: 2.6699223320518897

Epoch: 6| Step: 13
Training loss: 2.3551102044304013
Validation loss: 2.688669903510687

Epoch: 157| Step: 0
Training loss: 2.5961465449651664
Validation loss: 2.6461427391577117

Epoch: 6| Step: 1
Training loss: 3.2749678282577137
Validation loss: 2.6276907892788235

Epoch: 6| Step: 2
Training loss: 2.36022953953828
Validation loss: 2.7122275548574115

Epoch: 6| Step: 3
Training loss: 2.2845804646532146
Validation loss: 2.683093062354061

Epoch: 6| Step: 4
Training loss: 2.820172166370988
Validation loss: 2.6889388569876145

Epoch: 6| Step: 5
Training loss: 2.6417770130043126
Validation loss: 2.6932837047540885

Epoch: 6| Step: 6
Training loss: 2.469540915972611
Validation loss: 2.681911016101238

Epoch: 6| Step: 7
Training loss: 3.505926700041233
Validation loss: 2.6360341223072496

Epoch: 6| Step: 8
Training loss: 2.7973799436169187
Validation loss: 2.6878939428349122

Epoch: 6| Step: 9
Training loss: 2.9702831927062183
Validation loss: 2.6887605605459584

Epoch: 6| Step: 10
Training loss: 2.7241108975011947
Validation loss: 2.6799204544013153

Epoch: 6| Step: 11
Training loss: 2.496362328444717
Validation loss: 2.663115213690213

Epoch: 6| Step: 12
Training loss: 2.6545411840288105
Validation loss: 2.6752646992927733

Epoch: 6| Step: 13
Training loss: 2.23210519595391
Validation loss: 2.6195392325968454

Epoch: 158| Step: 0
Training loss: 3.423274341980056
Validation loss: 2.6430179427696334

Epoch: 6| Step: 1
Training loss: 2.798096800170609
Validation loss: 2.719236734620678

Epoch: 6| Step: 2
Training loss: 2.8505859375
Validation loss: 2.705259509498899

Epoch: 6| Step: 3
Training loss: 1.9257119187570524
Validation loss: 2.6254939695147126

Epoch: 6| Step: 4
Training loss: 2.2060158883609446
Validation loss: 2.654082379096088

Epoch: 6| Step: 5
Training loss: 2.4030147452789032
Validation loss: 2.6110650461552884

Epoch: 6| Step: 6
Training loss: 2.4418854021993672
Validation loss: 2.6511300125421062

Epoch: 6| Step: 7
Training loss: 2.8286359968150774
Validation loss: 2.654783150074314

Epoch: 6| Step: 8
Training loss: 2.1291499287145825
Validation loss: 2.705703826349476

Epoch: 6| Step: 9
Training loss: 3.252091248474329
Validation loss: 2.6674657186575823

Epoch: 6| Step: 10
Training loss: 3.015483002951412
Validation loss: 2.5818882607644826

Epoch: 6| Step: 11
Training loss: 1.961759964704819
Validation loss: 2.6510404794741387

Epoch: 6| Step: 12
Training loss: 3.1520030843264597
Validation loss: 2.6332860022865967

Epoch: 6| Step: 13
Training loss: 3.11474957655051
Validation loss: 2.6302610229815886

Epoch: 159| Step: 0
Training loss: 2.7400278134570217
Validation loss: 2.608288260675289

Epoch: 6| Step: 1
Training loss: 2.6358798578694875
Validation loss: 2.65483975406516

Epoch: 6| Step: 2
Training loss: 2.4964064520115747
Validation loss: 2.658560282021487

Epoch: 6| Step: 3
Training loss: 2.563408109205083
Validation loss: 2.6199439177467445

Epoch: 6| Step: 4
Training loss: 3.302535995760818
Validation loss: 2.6732140547266092

Epoch: 6| Step: 5
Training loss: 2.6234395066345066
Validation loss: 2.6899719069173162

Epoch: 6| Step: 6
Training loss: 2.0748932454786817
Validation loss: 2.6606246730734453

Epoch: 6| Step: 7
Training loss: 3.3485331327209793
Validation loss: 2.64165165663588

Epoch: 6| Step: 8
Training loss: 2.426386611763693
Validation loss: 2.6567105129934103

Epoch: 6| Step: 9
Training loss: 2.4370681184461245
Validation loss: 2.653523131586395

Epoch: 6| Step: 10
Training loss: 2.9217201232662124
Validation loss: 2.6604539181463798

Epoch: 6| Step: 11
Training loss: 2.5349452984567957
Validation loss: 2.7249778371095728

Epoch: 6| Step: 12
Training loss: 2.515427291398618
Validation loss: 2.624145834691508

Epoch: 6| Step: 13
Training loss: 2.393161998272492
Validation loss: 2.639337917121565

Epoch: 160| Step: 0
Training loss: 3.319147313934945
Validation loss: 2.640836911679697

Epoch: 6| Step: 1
Training loss: 2.8092003009524937
Validation loss: 2.650151739421682

Epoch: 6| Step: 2
Training loss: 3.2520560583371534
Validation loss: 2.618461244811135

Epoch: 6| Step: 3
Training loss: 2.369133681171553
Validation loss: 2.6534678414880952

Epoch: 6| Step: 4
Training loss: 1.8506699998428897
Validation loss: 2.680564897215513

Epoch: 6| Step: 5
Training loss: 2.6285967935203134
Validation loss: 2.625380844404925

Epoch: 6| Step: 6
Training loss: 2.451596895733955
Validation loss: 2.657435709055312

Epoch: 6| Step: 7
Training loss: 3.358174522058892
Validation loss: 2.678870192320612

Epoch: 6| Step: 8
Training loss: 2.6204105402075752
Validation loss: 2.6858323606887593

Epoch: 6| Step: 9
Training loss: 2.620758990358876
Validation loss: 2.5972871902965213

Epoch: 6| Step: 10
Training loss: 2.7463783344604313
Validation loss: 2.6293244219983

Epoch: 6| Step: 11
Training loss: 2.3361212106376277
Validation loss: 2.578802921165962

Epoch: 6| Step: 12
Training loss: 2.4365291129067166
Validation loss: 2.6178950703052712

Epoch: 6| Step: 13
Training loss: 3.394546420960057
Validation loss: 2.6395568357085692

Epoch: 161| Step: 0
Training loss: 2.922681890852925
Validation loss: 2.641920874266755

Epoch: 6| Step: 1
Training loss: 2.0759647011227376
Validation loss: 2.6459424741864286

Epoch: 6| Step: 2
Training loss: 1.887185238493998
Validation loss: 2.6670993375732888

Epoch: 6| Step: 3
Training loss: 2.7890397613196853
Validation loss: 2.5962036917307327

Epoch: 6| Step: 4
Training loss: 2.8947042189589576
Validation loss: 2.6797927658302876

Epoch: 6| Step: 5
Training loss: 3.0390450837486975
Validation loss: 2.697245818785502

Epoch: 6| Step: 6
Training loss: 2.1392201735439054
Validation loss: 2.6492375743076684

Epoch: 6| Step: 7
Training loss: 2.4125199312167487
Validation loss: 2.6443185737569315

Epoch: 6| Step: 8
Training loss: 2.6250448677224836
Validation loss: 2.5764518442052156

Epoch: 6| Step: 9
Training loss: 2.9940541473262607
Validation loss: 2.5874819848407054

Epoch: 6| Step: 10
Training loss: 2.7269835051431826
Validation loss: 2.640170132989818

Epoch: 6| Step: 11
Training loss: 3.1467165349252344
Validation loss: 2.653100463687251

Epoch: 6| Step: 12
Training loss: 3.2189893911281087
Validation loss: 2.661247643059861

Epoch: 6| Step: 13
Training loss: 3.06971249529528
Validation loss: 2.6416016420799533

Epoch: 162| Step: 0
Training loss: 3.196355299783429
Validation loss: 2.654434057249239

Epoch: 6| Step: 1
Training loss: 2.4356075667808947
Validation loss: 2.6599253032511667

Epoch: 6| Step: 2
Training loss: 2.3774989182462747
Validation loss: 2.678933804801485

Epoch: 6| Step: 3
Training loss: 2.4504792348078794
Validation loss: 2.632872497453366

Epoch: 6| Step: 4
Training loss: 2.937712641385214
Validation loss: 2.6429155636618273

Epoch: 6| Step: 5
Training loss: 2.3760584430250047
Validation loss: 2.6168135220155966

Epoch: 6| Step: 6
Training loss: 2.6379713459902527
Validation loss: 2.643267472504486

Epoch: 6| Step: 7
Training loss: 2.6381341144808292
Validation loss: 2.5992720949654387

Epoch: 6| Step: 8
Training loss: 2.634212404711045
Validation loss: 2.6670389518002677

Epoch: 6| Step: 9
Training loss: 2.8937262317843064
Validation loss: 2.672143828723021

Epoch: 6| Step: 10
Training loss: 2.717223692658973
Validation loss: 2.6428181782413094

Epoch: 6| Step: 11
Training loss: 3.472168071748434
Validation loss: 2.635551911878241

Epoch: 6| Step: 12
Training loss: 1.9641128909885408
Validation loss: 2.6400651449311727

Epoch: 6| Step: 13
Training loss: 3.191315704518016
Validation loss: 2.604989911464681

Epoch: 163| Step: 0
Training loss: 2.828510068527894
Validation loss: 2.691725688081378

Epoch: 6| Step: 1
Training loss: 2.6025368638592963
Validation loss: 2.7038604970531326

Epoch: 6| Step: 2
Training loss: 2.922164494661843
Validation loss: 2.70057554867237

Epoch: 6| Step: 3
Training loss: 2.6955530916171107
Validation loss: 2.6468781819295204

Epoch: 6| Step: 4
Training loss: 2.7862907763338707
Validation loss: 2.6592250457359032

Epoch: 6| Step: 5
Training loss: 2.8002985454527076
Validation loss: 2.6669462432997046

Epoch: 6| Step: 6
Training loss: 2.502571500048301
Validation loss: 2.7643188132156493

Epoch: 6| Step: 7
Training loss: 2.2996576800812423
Validation loss: 2.617209243745311

Epoch: 6| Step: 8
Training loss: 2.777776713900892
Validation loss: 2.6574799259259443

Epoch: 6| Step: 9
Training loss: 2.220602202659462
Validation loss: 2.7312976993593083

Epoch: 6| Step: 10
Training loss: 2.944547437470015
Validation loss: 2.698725441170974

Epoch: 6| Step: 11
Training loss: 3.4523068662815315
Validation loss: 2.664878047972609

Epoch: 6| Step: 12
Training loss: 2.6074758231193353
Validation loss: 2.6648375085422265

Epoch: 6| Step: 13
Training loss: 1.7548408991542808
Validation loss: 2.696206964136059

Epoch: 164| Step: 0
Training loss: 2.2779521358508696
Validation loss: 2.610439675518633

Epoch: 6| Step: 1
Training loss: 3.554607818045797
Validation loss: 2.7318246130869355

Epoch: 6| Step: 2
Training loss: 2.849832590105246
Validation loss: 2.667705630234083

Epoch: 6| Step: 3
Training loss: 2.4826306631193553
Validation loss: 2.622499613073918

Epoch: 6| Step: 4
Training loss: 2.0744235697338866
Validation loss: 2.6769973002410925

Epoch: 6| Step: 5
Training loss: 2.5831590921850576
Validation loss: 2.620351113479259

Epoch: 6| Step: 6
Training loss: 3.42554197269595
Validation loss: 2.5948322705371174

Epoch: 6| Step: 7
Training loss: 2.9274521094231942
Validation loss: 2.6141218278099743

Epoch: 6| Step: 8
Training loss: 2.3809809415103365
Validation loss: 2.636751142429711

Epoch: 6| Step: 9
Training loss: 2.3851306082993107
Validation loss: 2.6777243913008575

Epoch: 6| Step: 10
Training loss: 2.7211865435847233
Validation loss: 2.7076641824283665

Epoch: 6| Step: 11
Training loss: 3.428026496633463
Validation loss: 2.6043815422418404

Epoch: 6| Step: 12
Training loss: 1.6600552157905069
Validation loss: 2.598526539855975

Epoch: 6| Step: 13
Training loss: 2.964496175021366
Validation loss: 2.6184255126546203

Epoch: 165| Step: 0
Training loss: 2.7915144541983024
Validation loss: 2.610843513680258

Epoch: 6| Step: 1
Training loss: 2.4414869127299736
Validation loss: 2.618650631002308

Epoch: 6| Step: 2
Training loss: 2.5478820681984606
Validation loss: 2.6868578789282127

Epoch: 6| Step: 3
Training loss: 2.556889789233613
Validation loss: 2.63343389040553

Epoch: 6| Step: 4
Training loss: 2.7309984558335767
Validation loss: 2.6670006349331534

Epoch: 6| Step: 5
Training loss: 2.8233650573995868
Validation loss: 2.625415640181403

Epoch: 6| Step: 6
Training loss: 3.9383597267957233
Validation loss: 2.704258065008168

Epoch: 6| Step: 7
Training loss: 2.5382939980310937
Validation loss: 2.640229730207969

Epoch: 6| Step: 8
Training loss: 2.10492989575136
Validation loss: 2.693824222823984

Epoch: 6| Step: 9
Training loss: 2.955143959940803
Validation loss: 2.7222630739826554

Epoch: 6| Step: 10
Training loss: 2.0937973700331685
Validation loss: 2.657697687741787

Epoch: 6| Step: 11
Training loss: 2.182474958662855
Validation loss: 2.646571368344516

Epoch: 6| Step: 12
Training loss: 3.0810806877864914
Validation loss: 2.6213100826940323

Epoch: 6| Step: 13
Training loss: 2.405559093814369
Validation loss: 2.648620956300245

Epoch: 166| Step: 0
Training loss: 3.0335637336953383
Validation loss: 2.609043762746519

Epoch: 6| Step: 1
Training loss: 2.23784767731579
Validation loss: 2.6382436327922094

Epoch: 6| Step: 2
Training loss: 2.4042066344889745
Validation loss: 2.637291546112993

Epoch: 6| Step: 3
Training loss: 2.6638059073013713
Validation loss: 2.5908020975498998

Epoch: 6| Step: 4
Training loss: 2.989110574769398
Validation loss: 2.6553437483971125

Epoch: 6| Step: 5
Training loss: 2.827939022124417
Validation loss: 2.639794092914569

Epoch: 6| Step: 6
Training loss: 2.8018332916974398
Validation loss: 2.6467673045530513

Epoch: 6| Step: 7
Training loss: 2.772334779540937
Validation loss: 2.6982309951209538

Epoch: 6| Step: 8
Training loss: 3.0603421452544333
Validation loss: 2.6938798380385713

Epoch: 6| Step: 9
Training loss: 3.0555721475169983
Validation loss: 2.681196869882312

Epoch: 6| Step: 10
Training loss: 2.0193123615813513
Validation loss: 2.714007212370867

Epoch: 6| Step: 11
Training loss: 2.5718106712556
Validation loss: 2.6702797399603155

Epoch: 6| Step: 12
Training loss: 3.0864436639872106
Validation loss: 2.598086587950803

Epoch: 6| Step: 13
Training loss: 1.8040416271879518
Validation loss: 2.6482983275913905

Epoch: 167| Step: 0
Training loss: 2.8423153119239712
Validation loss: 2.6329977401778475

Epoch: 6| Step: 1
Training loss: 2.6518846431919165
Validation loss: 2.68100741631189

Epoch: 6| Step: 2
Training loss: 3.4336140255551815
Validation loss: 2.6517059324311374

Epoch: 6| Step: 3
Training loss: 2.93044163470943
Validation loss: 2.657046309321226

Epoch: 6| Step: 4
Training loss: 2.8186177157130663
Validation loss: 2.6734052007641225

Epoch: 6| Step: 5
Training loss: 3.0109768954492493
Validation loss: 2.6071804211208556

Epoch: 6| Step: 6
Training loss: 3.065625833711501
Validation loss: 2.626200396126088

Epoch: 6| Step: 7
Training loss: 2.664328016546506
Validation loss: 2.6349079611120185

Epoch: 6| Step: 8
Training loss: 3.047110054534992
Validation loss: 2.654426451598282

Epoch: 6| Step: 9
Training loss: 2.4086497836999006
Validation loss: 2.661394617020239

Epoch: 6| Step: 10
Training loss: 2.1575388719011874
Validation loss: 2.6107612146845427

Epoch: 6| Step: 11
Training loss: 2.4417329859487933
Validation loss: 2.6419494505369636

Epoch: 6| Step: 12
Training loss: 1.802522227326166
Validation loss: 2.7697878612441

Epoch: 6| Step: 13
Training loss: 2.6083313459524886
Validation loss: 2.6464174178382533

Epoch: 168| Step: 0
Training loss: 2.3636474325681145
Validation loss: 2.667735278558275

Epoch: 6| Step: 1
Training loss: 2.997844080325701
Validation loss: 2.6611219134544553

Epoch: 6| Step: 2
Training loss: 2.3822101769787287
Validation loss: 2.706514364544663

Epoch: 6| Step: 3
Training loss: 2.2015913366482747
Validation loss: 2.649576248021097

Epoch: 6| Step: 4
Training loss: 3.444057936842332
Validation loss: 2.631452530815577

Epoch: 6| Step: 5
Training loss: 2.3961219171510884
Validation loss: 2.6718337175708213

Epoch: 6| Step: 6
Training loss: 2.6836259109813225
Validation loss: 2.638993198540276

Epoch: 6| Step: 7
Training loss: 2.6398319656185807
Validation loss: 2.653179059821649

Epoch: 6| Step: 8
Training loss: 3.009461107141195
Validation loss: 2.64756000257333

Epoch: 6| Step: 9
Training loss: 2.695686822965488
Validation loss: 2.6444846257132664

Epoch: 6| Step: 10
Training loss: 2.481712978418531
Validation loss: 2.6520866701868293

Epoch: 6| Step: 11
Training loss: 2.419925520357676
Validation loss: 2.608587200987737

Epoch: 6| Step: 12
Training loss: 3.2331422677234363
Validation loss: 2.620020140589497

Epoch: 6| Step: 13
Training loss: 3.0872296296013797
Validation loss: 2.650426230899241

Epoch: 169| Step: 0
Training loss: 3.5218634969934706
Validation loss: 2.681377876403466

Epoch: 6| Step: 1
Training loss: 1.8185088427089768
Validation loss: 2.6669516302202876

Epoch: 6| Step: 2
Training loss: 2.960296158795319
Validation loss: 2.6559137849397487

Epoch: 6| Step: 3
Training loss: 2.6206229820398357
Validation loss: 2.6323065408063338

Epoch: 6| Step: 4
Training loss: 2.610052420575701
Validation loss: 2.650449248589975

Epoch: 6| Step: 5
Training loss: 3.006982624456646
Validation loss: 2.594602658922911

Epoch: 6| Step: 6
Training loss: 2.3510641285965983
Validation loss: 2.6367856150982645

Epoch: 6| Step: 7
Training loss: 2.669781673520353
Validation loss: 2.6249556784298966

Epoch: 6| Step: 8
Training loss: 2.676306546294039
Validation loss: 2.657267420644259

Epoch: 6| Step: 9
Training loss: 2.8519746665417967
Validation loss: 2.617858298250101

Epoch: 6| Step: 10
Training loss: 2.787556388524125
Validation loss: 2.6265169341997288

Epoch: 6| Step: 11
Training loss: 2.267416410240783
Validation loss: 2.608579078382968

Epoch: 6| Step: 12
Training loss: 2.525239472316954
Validation loss: 2.693713081266186

Epoch: 6| Step: 13
Training loss: 1.667675769812833
Validation loss: 2.638393130974613

Epoch: 170| Step: 0
Training loss: 2.396658967986849
Validation loss: 2.604287190919512

Epoch: 6| Step: 1
Training loss: 2.9644204140292385
Validation loss: 2.6028317586769187

Epoch: 6| Step: 2
Training loss: 2.3066870339914827
Validation loss: 2.6455075237218124

Epoch: 6| Step: 3
Training loss: 2.8524375931435064
Validation loss: 2.601082754597664

Epoch: 6| Step: 4
Training loss: 2.518352853971606
Validation loss: 2.739782924923092

Epoch: 6| Step: 5
Training loss: 3.2098056998228466
Validation loss: 2.678403985805432

Epoch: 6| Step: 6
Training loss: 2.6766389906019716
Validation loss: 2.6293629232571765

Epoch: 6| Step: 7
Training loss: 2.544784998927293
Validation loss: 2.674534223535217

Epoch: 6| Step: 8
Training loss: 2.727708810563292
Validation loss: 2.6972228891693124

Epoch: 6| Step: 9
Training loss: 1.9662528777298478
Validation loss: 2.672856003317608

Epoch: 6| Step: 10
Training loss: 2.6950457012427655
Validation loss: 2.643069527060304

Epoch: 6| Step: 11
Training loss: 3.5996113620365513
Validation loss: 2.616016140625752

Epoch: 6| Step: 12
Training loss: 2.7900988793027786
Validation loss: 2.628958983947516

Epoch: 6| Step: 13
Training loss: 2.5974144844612987
Validation loss: 2.6173777335266335

Epoch: 171| Step: 0
Training loss: 2.7185902164904796
Validation loss: 2.6890726050474063

Epoch: 6| Step: 1
Training loss: 3.339621303355981
Validation loss: 2.637603720634815

Epoch: 6| Step: 2
Training loss: 3.0320070245606066
Validation loss: 2.699224264366824

Epoch: 6| Step: 3
Training loss: 3.0419142809546393
Validation loss: 2.669785082382784

Epoch: 6| Step: 4
Training loss: 2.72411422332045
Validation loss: 2.655926594358189

Epoch: 6| Step: 5
Training loss: 2.544102757243996
Validation loss: 2.7051684036848194

Epoch: 6| Step: 6
Training loss: 1.7558929134641061
Validation loss: 2.7010109092516785

Epoch: 6| Step: 7
Training loss: 1.8731051725318904
Validation loss: 2.649060355315526

Epoch: 6| Step: 8
Training loss: 2.395028838937699
Validation loss: 2.6841885215588115

Epoch: 6| Step: 9
Training loss: 2.9172854357535307
Validation loss: 2.6350917250241364

Epoch: 6| Step: 10
Training loss: 2.713994042780051
Validation loss: 2.5840449853111203

Epoch: 6| Step: 11
Training loss: 2.661374523139686
Validation loss: 2.6349765144626716

Epoch: 6| Step: 12
Training loss: 2.9853565139904146
Validation loss: 2.6714569515074262

Epoch: 6| Step: 13
Training loss: 2.9913824607000827
Validation loss: 2.637844574494015

Epoch: 172| Step: 0
Training loss: 2.9361317471352755
Validation loss: 2.6030403799343422

Epoch: 6| Step: 1
Training loss: 2.7570973622672
Validation loss: 2.663004660981108

Epoch: 6| Step: 2
Training loss: 2.416560587253896
Validation loss: 2.681220400761337

Epoch: 6| Step: 3
Training loss: 2.15634818475507
Validation loss: 2.6106401755669744

Epoch: 6| Step: 4
Training loss: 2.7624719609697475
Validation loss: 2.6249035223260386

Epoch: 6| Step: 5
Training loss: 2.801953016084621
Validation loss: 2.6252553037296837

Epoch: 6| Step: 6
Training loss: 2.8811056568456843
Validation loss: 2.5947231459260602

Epoch: 6| Step: 7
Training loss: 2.855568775768164
Validation loss: 2.655593007130638

Epoch: 6| Step: 8
Training loss: 2.08684334391907
Validation loss: 2.6294969030096276

Epoch: 6| Step: 9
Training loss: 3.0390364540376487
Validation loss: 2.605746476596058

Epoch: 6| Step: 10
Training loss: 2.350398082699133
Validation loss: 2.6124683996237175

Epoch: 6| Step: 11
Training loss: 2.1222300708530195
Validation loss: 2.6771831172252534

Epoch: 6| Step: 12
Training loss: 3.682952663261397
Validation loss: 2.6209603315363803

Epoch: 6| Step: 13
Training loss: 3.4781831885557515
Validation loss: 2.63980571077731

Epoch: 173| Step: 0
Training loss: 2.8402451935888546
Validation loss: 2.619799655019868

Epoch: 6| Step: 1
Training loss: 2.397268501219097
Validation loss: 2.65319724173077

Epoch: 6| Step: 2
Training loss: 3.2691644351150035
Validation loss: 2.631275558863927

Epoch: 6| Step: 3
Training loss: 2.775818396506829
Validation loss: 2.6431122834878065

Epoch: 6| Step: 4
Training loss: 2.481528132534184
Validation loss: 2.637906798675451

Epoch: 6| Step: 5
Training loss: 2.7594615123488797
Validation loss: 2.645304085222215

Epoch: 6| Step: 6
Training loss: 2.996455641951766
Validation loss: 2.707414023952317

Epoch: 6| Step: 7
Training loss: 2.5561286058025043
Validation loss: 2.664226534269958

Epoch: 6| Step: 8
Training loss: 2.6994349700844515
Validation loss: 2.6232788607879884

Epoch: 6| Step: 9
Training loss: 1.5127604835612245
Validation loss: 2.6603496255296495

Epoch: 6| Step: 10
Training loss: 2.8442157741196388
Validation loss: 2.5917590946597677

Epoch: 6| Step: 11
Training loss: 3.398734945675675
Validation loss: 2.7150322201338213

Epoch: 6| Step: 12
Training loss: 2.4849318354140126
Validation loss: 2.6356906212648368

Epoch: 6| Step: 13
Training loss: 2.6781328768708916
Validation loss: 2.605281434380441

Epoch: 174| Step: 0
Training loss: 2.196188320972115
Validation loss: 2.635831396961016

Epoch: 6| Step: 1
Training loss: 2.0540676559924425
Validation loss: 2.6535756961095838

Epoch: 6| Step: 2
Training loss: 3.3059105740341406
Validation loss: 2.6392090120929588

Epoch: 6| Step: 3
Training loss: 3.5333216169151047
Validation loss: 2.606182585742169

Epoch: 6| Step: 4
Training loss: 2.59628401916285
Validation loss: 2.645521379224959

Epoch: 6| Step: 5
Training loss: 3.0514928009933366
Validation loss: 2.64285243208904

Epoch: 6| Step: 6
Training loss: 2.9329386257717607
Validation loss: 2.6004895428564048

Epoch: 6| Step: 7
Training loss: 2.2362511500808204
Validation loss: 2.63398971911719

Epoch: 6| Step: 8
Training loss: 1.4365888278582528
Validation loss: 2.618803840882753

Epoch: 6| Step: 9
Training loss: 3.857443136808492
Validation loss: 2.63221311837975

Epoch: 6| Step: 10
Training loss: 2.499267089223632
Validation loss: 2.633755072341133

Epoch: 6| Step: 11
Training loss: 2.305492402811466
Validation loss: 2.6069996469392978

Epoch: 6| Step: 12
Training loss: 2.6910017398869712
Validation loss: 2.6415731998578607

Epoch: 6| Step: 13
Training loss: 2.7497457906963234
Validation loss: 2.6221539088360855

Epoch: 175| Step: 0
Training loss: 2.2681428795806458
Validation loss: 2.6517882358513565

Epoch: 6| Step: 1
Training loss: 2.6927803861224446
Validation loss: 2.626663145037753

Epoch: 6| Step: 2
Training loss: 3.9185861118244794
Validation loss: 2.6196320138794773

Epoch: 6| Step: 3
Training loss: 2.2950194252870864
Validation loss: 2.686400846704679

Epoch: 6| Step: 4
Training loss: 3.222864576599762
Validation loss: 2.5994222811623753

Epoch: 6| Step: 5
Training loss: 1.9494056994242825
Validation loss: 2.734102426470549

Epoch: 6| Step: 6
Training loss: 2.7192406924061183
Validation loss: 2.6503127103384445

Epoch: 6| Step: 7
Training loss: 2.5614786671352
Validation loss: 2.6644532239489345

Epoch: 6| Step: 8
Training loss: 2.2487662429604627
Validation loss: 2.6919621804986607

Epoch: 6| Step: 9
Training loss: 2.182149392332932
Validation loss: 2.6521399581879708

Epoch: 6| Step: 10
Training loss: 3.402253071992345
Validation loss: 2.6513419818996358

Epoch: 6| Step: 11
Training loss: 2.4404698399495475
Validation loss: 2.685895873660408

Epoch: 6| Step: 12
Training loss: 2.736826990738342
Validation loss: 2.639011630701288

Epoch: 6| Step: 13
Training loss: 1.4902300553365475
Validation loss: 2.6607299839382903

Epoch: 176| Step: 0
Training loss: 2.1604662598595366
Validation loss: 2.6279113571101984

Epoch: 6| Step: 1
Training loss: 1.9575074124835334
Validation loss: 2.700892394987723

Epoch: 6| Step: 2
Training loss: 2.5508999526720917
Validation loss: 2.646582445972462

Epoch: 6| Step: 3
Training loss: 2.139431140195378
Validation loss: 2.7196570799663364

Epoch: 6| Step: 4
Training loss: 2.6186094150726786
Validation loss: 2.6737427050022187

Epoch: 6| Step: 5
Training loss: 2.9631894689537583
Validation loss: 2.6445113769769466

Epoch: 6| Step: 6
Training loss: 2.990874717116437
Validation loss: 2.6369234458499315

Epoch: 6| Step: 7
Training loss: 3.2065545307413945
Validation loss: 2.614825810872079

Epoch: 6| Step: 8
Training loss: 3.3481533255704288
Validation loss: 2.591879387445217

Epoch: 6| Step: 9
Training loss: 2.40311574549685
Validation loss: 2.680701542368955

Epoch: 6| Step: 10
Training loss: 2.600494440455289
Validation loss: 2.5984800362530933

Epoch: 6| Step: 11
Training loss: 2.5499956168342766
Validation loss: 2.6940402145060935

Epoch: 6| Step: 12
Training loss: 2.977904970701108
Validation loss: 2.6932099809023784

Epoch: 6| Step: 13
Training loss: 3.065558638325917
Validation loss: 2.6507331631087614

Epoch: 177| Step: 0
Training loss: 2.187614546910235
Validation loss: 2.606568595106765

Epoch: 6| Step: 1
Training loss: 3.621882578041239
Validation loss: 2.675275159328619

Epoch: 6| Step: 2
Training loss: 2.4705141741607157
Validation loss: 2.701457817157878

Epoch: 6| Step: 3
Training loss: 2.7593611996609093
Validation loss: 2.586104777671113

Epoch: 6| Step: 4
Training loss: 2.6684795912672836
Validation loss: 2.6175539928525917

Epoch: 6| Step: 5
Training loss: 2.719073309254882
Validation loss: 2.6148990613206675

Epoch: 6| Step: 6
Training loss: 2.9627533430106863
Validation loss: 2.625999883338596

Epoch: 6| Step: 7
Training loss: 3.1012113357956723
Validation loss: 2.6471905904602697

Epoch: 6| Step: 8
Training loss: 1.8108705891713268
Validation loss: 2.6644360598523056

Epoch: 6| Step: 9
Training loss: 2.473393575889207
Validation loss: 2.6342939535419445

Epoch: 6| Step: 10
Training loss: 2.69292594182867
Validation loss: 2.6823455247610144

Epoch: 6| Step: 11
Training loss: 2.8337276034822585
Validation loss: 2.600348957725041

Epoch: 6| Step: 12
Training loss: 3.081699832169061
Validation loss: 2.6273587846056414

Epoch: 6| Step: 13
Training loss: 2.3501831267408777
Validation loss: 2.604231051397675

Epoch: 178| Step: 0
Training loss: 2.3140711215603655
Validation loss: 2.6576460680883347

Epoch: 6| Step: 1
Training loss: 2.6722126351455717
Validation loss: 2.632876088961137

Epoch: 6| Step: 2
Training loss: 3.3131153326895575
Validation loss: 2.6658910612335047

Epoch: 6| Step: 3
Training loss: 2.3847110376507383
Validation loss: 2.5994744850032525

Epoch: 6| Step: 4
Training loss: 2.70803246416385
Validation loss: 2.6411411096315054

Epoch: 6| Step: 5
Training loss: 2.0731352366579117
Validation loss: 2.6118932451468386

Epoch: 6| Step: 6
Training loss: 2.2788014269794363
Validation loss: 2.6412754576848103

Epoch: 6| Step: 7
Training loss: 2.766740304663983
Validation loss: 2.636180749573129

Epoch: 6| Step: 8
Training loss: 3.6883077221748444
Validation loss: 2.662394576619229

Epoch: 6| Step: 9
Training loss: 2.8350018095249543
Validation loss: 2.5852907662892863

Epoch: 6| Step: 10
Training loss: 2.7846143283590705
Validation loss: 2.699662539769543

Epoch: 6| Step: 11
Training loss: 2.873658738116246
Validation loss: 2.59452247903088

Epoch: 6| Step: 12
Training loss: 2.462774844250217
Validation loss: 2.6100716533167523

Epoch: 6| Step: 13
Training loss: 2.0974909825637
Validation loss: 2.6577477514717773

Epoch: 179| Step: 0
Training loss: 2.472511516270369
Validation loss: 2.6087375329127354

Epoch: 6| Step: 1
Training loss: 2.9219433781583746
Validation loss: 2.64981144423693

Epoch: 6| Step: 2
Training loss: 2.2661197516774947
Validation loss: 2.6230123586025855

Epoch: 6| Step: 3
Training loss: 3.3597112443007013
Validation loss: 2.6506221316867076

Epoch: 6| Step: 4
Training loss: 2.7702506654984895
Validation loss: 2.6405007307094

Epoch: 6| Step: 5
Training loss: 2.8984643158610433
Validation loss: 2.6115552088487544

Epoch: 6| Step: 6
Training loss: 3.20874304859462
Validation loss: 2.655963130856631

Epoch: 6| Step: 7
Training loss: 2.3960242043356845
Validation loss: 2.6580180065967594

Epoch: 6| Step: 8
Training loss: 3.427537109263148
Validation loss: 2.7088592214353215

Epoch: 6| Step: 9
Training loss: 2.250476786641425
Validation loss: 2.6281365730323767

Epoch: 6| Step: 10
Training loss: 2.5127775769605303
Validation loss: 2.7042510839162923

Epoch: 6| Step: 11
Training loss: 2.7372354423156042
Validation loss: 2.6504523312062367

Epoch: 6| Step: 12
Training loss: 2.1981465248093106
Validation loss: 2.690398466400563

Epoch: 6| Step: 13
Training loss: 1.3154344905547521
Validation loss: 2.65125655490708

Epoch: 180| Step: 0
Training loss: 2.1576453959780224
Validation loss: 2.6723851223859194

Epoch: 6| Step: 1
Training loss: 2.765724482067143
Validation loss: 2.692882281274133

Epoch: 6| Step: 2
Training loss: 3.078340629344556
Validation loss: 2.6063907745311923

Epoch: 6| Step: 3
Training loss: 2.9526809277764645
Validation loss: 2.629617309120997

Epoch: 6| Step: 4
Training loss: 2.9561390507143273
Validation loss: 2.7042331125462145

Epoch: 6| Step: 5
Training loss: 2.6587410409881342
Validation loss: 2.66776527922874

Epoch: 6| Step: 6
Training loss: 2.7555536199207413
Validation loss: 2.667213073119977

Epoch: 6| Step: 7
Training loss: 3.042082631831621
Validation loss: 2.633145643513144

Epoch: 6| Step: 8
Training loss: 2.435791590678023
Validation loss: 2.689842332805383

Epoch: 6| Step: 9
Training loss: 3.069603602759837
Validation loss: 2.6302970436720803

Epoch: 6| Step: 10
Training loss: 2.1985558278029487
Validation loss: 2.625913977514526

Epoch: 6| Step: 11
Training loss: 2.3905851074081674
Validation loss: 2.6796605172699177

Epoch: 6| Step: 12
Training loss: 2.6124628493300412
Validation loss: 2.6376848642911854

Epoch: 6| Step: 13
Training loss: 2.834113256782535
Validation loss: 2.668075751316731

Epoch: 181| Step: 0
Training loss: 3.175394595398628
Validation loss: 2.626206932609883

Epoch: 6| Step: 1
Training loss: 2.152433251598732
Validation loss: 2.649761798482623

Epoch: 6| Step: 2
Training loss: 2.9011622369024974
Validation loss: 2.6275309243689957

Epoch: 6| Step: 3
Training loss: 3.1346777027194928
Validation loss: 2.6644463435061896

Epoch: 6| Step: 4
Training loss: 2.69606109395972
Validation loss: 2.6486416879960126

Epoch: 6| Step: 5
Training loss: 2.861168137592103
Validation loss: 2.642758697599351

Epoch: 6| Step: 6
Training loss: 2.062381394183841
Validation loss: 2.646685564684979

Epoch: 6| Step: 7
Training loss: 2.8704643961046092
Validation loss: 2.666238778020046

Epoch: 6| Step: 8
Training loss: 2.9069911873037255
Validation loss: 2.646494120070688

Epoch: 6| Step: 9
Training loss: 2.4586958106100334
Validation loss: 2.600130123829451

Epoch: 6| Step: 10
Training loss: 2.6001286951639133
Validation loss: 2.6138485621775143

Epoch: 6| Step: 11
Training loss: 2.328213274005492
Validation loss: 2.6538741699748147

Epoch: 6| Step: 12
Training loss: 1.8545904068250225
Validation loss: 2.699884759577338

Epoch: 6| Step: 13
Training loss: 3.7621928042093913
Validation loss: 2.649382120989345

Epoch: 182| Step: 0
Training loss: 1.9849423776329613
Validation loss: 2.693533404310268

Epoch: 6| Step: 1
Training loss: 3.2021179104693864
Validation loss: 2.628119163950052

Epoch: 6| Step: 2
Training loss: 2.500868455724314
Validation loss: 2.6086606339852887

Epoch: 6| Step: 3
Training loss: 2.5130205592548966
Validation loss: 2.6368491262320792

Epoch: 6| Step: 4
Training loss: 3.336236515982668
Validation loss: 2.63136589206814

Epoch: 6| Step: 5
Training loss: 1.9051667559470216
Validation loss: 2.632583659339463

Epoch: 6| Step: 6
Training loss: 2.8374649852323173
Validation loss: 2.663194783963585

Epoch: 6| Step: 7
Training loss: 2.091885319967261
Validation loss: 2.5735348247892706

Epoch: 6| Step: 8
Training loss: 2.4279167370730455
Validation loss: 2.60728011404019

Epoch: 6| Step: 9
Training loss: 2.6846998841900684
Validation loss: 2.6573947917564826

Epoch: 6| Step: 10
Training loss: 2.7874452833612993
Validation loss: 2.622332213948082

Epoch: 6| Step: 11
Training loss: 3.2106703301352875
Validation loss: 2.6323224915242553

Epoch: 6| Step: 12
Training loss: 3.7110251326001604
Validation loss: 2.6529534138645423

Epoch: 6| Step: 13
Training loss: 2.329097263164271
Validation loss: 2.565133771928006

Epoch: 183| Step: 0
Training loss: 2.586641152524798
Validation loss: 2.6062521032025514

Epoch: 6| Step: 1
Training loss: 2.6678132532696677
Validation loss: 2.7409590931055683

Epoch: 6| Step: 2
Training loss: 2.537155609061992
Validation loss: 2.5637946056266774

Epoch: 6| Step: 3
Training loss: 1.664048602265542
Validation loss: 2.660978843146151

Epoch: 6| Step: 4
Training loss: 2.7105348491388184
Validation loss: 2.6961466588254677

Epoch: 6| Step: 5
Training loss: 3.3931877892938798
Validation loss: 2.644184314392286

Epoch: 6| Step: 6
Training loss: 2.386757708292415
Validation loss: 2.688800763121397

Epoch: 6| Step: 7
Training loss: 2.6264796854973156
Validation loss: 2.616327843545978

Epoch: 6| Step: 8
Training loss: 2.424913432355668
Validation loss: 2.6338634752769168

Epoch: 6| Step: 9
Training loss: 3.297742395059809
Validation loss: 2.632670343703909

Epoch: 6| Step: 10
Training loss: 2.687142902868813
Validation loss: 2.6173554221047137

Epoch: 6| Step: 11
Training loss: 2.3578777488745457
Validation loss: 2.603188285555205

Epoch: 6| Step: 12
Training loss: 2.258505533369953
Validation loss: 2.6744317812613527

Epoch: 6| Step: 13
Training loss: 3.443587444366632
Validation loss: 2.649228182859839

Epoch: 184| Step: 0
Training loss: 3.7315032004064466
Validation loss: 2.62717099319958

Epoch: 6| Step: 1
Training loss: 2.4999423020380465
Validation loss: 2.6261580862522296

Epoch: 6| Step: 2
Training loss: 3.0489954685616656
Validation loss: 2.686687834213113

Epoch: 6| Step: 3
Training loss: 2.5573483297023016
Validation loss: 2.661755834997777

Epoch: 6| Step: 4
Training loss: 2.7656243965449994
Validation loss: 2.6533159790851517

Epoch: 6| Step: 5
Training loss: 2.6225283657754543
Validation loss: 2.6149188162566954

Epoch: 6| Step: 6
Training loss: 2.379346384007148
Validation loss: 2.6151485841217372

Epoch: 6| Step: 7
Training loss: 2.500980566364913
Validation loss: 2.6719096565985363

Epoch: 6| Step: 8
Training loss: 2.4619834977874415
Validation loss: 2.616034870895529

Epoch: 6| Step: 9
Training loss: 2.789373214895475
Validation loss: 2.651217510988979

Epoch: 6| Step: 10
Training loss: 2.629735580612239
Validation loss: 2.6528262208911007

Epoch: 6| Step: 11
Training loss: 2.5460441497906325
Validation loss: 2.6928031188907835

Epoch: 6| Step: 12
Training loss: 2.8073170695573952
Validation loss: 2.622352762432027

Epoch: 6| Step: 13
Training loss: 2.118900408512072
Validation loss: 2.6623401236235034

Epoch: 185| Step: 0
Training loss: 2.473326678031474
Validation loss: 2.7246165974956784

Epoch: 6| Step: 1
Training loss: 3.102040904933219
Validation loss: 2.670722460020023

Epoch: 6| Step: 2
Training loss: 2.7897160296019146
Validation loss: 2.5987261527614636

Epoch: 6| Step: 3
Training loss: 2.759200397985379
Validation loss: 2.627081083697662

Epoch: 6| Step: 4
Training loss: 2.9958725192319613
Validation loss: 2.636144265653111

Epoch: 6| Step: 5
Training loss: 2.200532402294077
Validation loss: 2.6805984477982303

Epoch: 6| Step: 6
Training loss: 2.3865365366205897
Validation loss: 2.6605617940527666

Epoch: 6| Step: 7
Training loss: 2.869326425123348
Validation loss: 2.5815614392011983

Epoch: 6| Step: 8
Training loss: 2.322997931411748
Validation loss: 2.647594371301526

Epoch: 6| Step: 9
Training loss: 2.984220330988769
Validation loss: 2.6077779660321982

Epoch: 6| Step: 10
Training loss: 2.939196157787887
Validation loss: 2.6322119788594844

Epoch: 6| Step: 11
Training loss: 2.2450666384587796
Validation loss: 2.6797358384357644

Epoch: 6| Step: 12
Training loss: 2.1164597953368025
Validation loss: 2.673420684756393

Epoch: 6| Step: 13
Training loss: 3.7356295852415995
Validation loss: 2.629711787917316

Epoch: 186| Step: 0
Training loss: 3.0703267880949348
Validation loss: 2.649646989717763

Epoch: 6| Step: 1
Training loss: 2.565389167456932
Validation loss: 2.6685951749191124

Epoch: 6| Step: 2
Training loss: 2.7502751646226486
Validation loss: 2.6389928973918524

Epoch: 6| Step: 3
Training loss: 2.2541400120464328
Validation loss: 2.6349246968170905

Epoch: 6| Step: 4
Training loss: 2.7046797145685177
Validation loss: 2.609808071590097

Epoch: 6| Step: 5
Training loss: 2.469502105106461
Validation loss: 2.57818405168261

Epoch: 6| Step: 6
Training loss: 2.888974600115464
Validation loss: 2.6440814374834187

Epoch: 6| Step: 7
Training loss: 2.3120382724352915
Validation loss: 2.6052037303370046

Epoch: 6| Step: 8
Training loss: 2.4579367129106626
Validation loss: 2.6237980522129742

Epoch: 6| Step: 9
Training loss: 3.50629540072336
Validation loss: 2.614321806193428

Epoch: 6| Step: 10
Training loss: 2.6319446435110194
Validation loss: 2.601909649395281

Epoch: 6| Step: 11
Training loss: 2.747831009423188
Validation loss: 2.6202633190820994

Epoch: 6| Step: 12
Training loss: 2.2328767888695653
Validation loss: 2.6261974461126907

Epoch: 6| Step: 13
Training loss: 2.3629058287489766
Validation loss: 2.6191551974804685

Epoch: 187| Step: 0
Training loss: 2.529634407527754
Validation loss: 2.703587243269825

Epoch: 6| Step: 1
Training loss: 2.6219022728975787
Validation loss: 2.6774729081382587

Epoch: 6| Step: 2
Training loss: 2.2015162878012284
Validation loss: 2.662765851850047

Epoch: 6| Step: 3
Training loss: 2.3362362265550782
Validation loss: 2.6448676960330597

Epoch: 6| Step: 4
Training loss: 2.585792744898143
Validation loss: 2.659741531716515

Epoch: 6| Step: 5
Training loss: 2.898932977570759
Validation loss: 2.618202781728299

Epoch: 6| Step: 6
Training loss: 2.9160502917815423
Validation loss: 2.650080055425312

Epoch: 6| Step: 7
Training loss: 2.98760460067928
Validation loss: 2.681987914342938

Epoch: 6| Step: 8
Training loss: 3.335480205273008
Validation loss: 2.6540371116694783

Epoch: 6| Step: 9
Training loss: 2.7453410825071916
Validation loss: 2.647994096011381

Epoch: 6| Step: 10
Training loss: 2.1215851216354076
Validation loss: 2.6607946529974615

Epoch: 6| Step: 11
Training loss: 1.7043386911931842
Validation loss: 2.6151740856258328

Epoch: 6| Step: 12
Training loss: 2.920321291139289
Validation loss: 2.64745551576236

Epoch: 6| Step: 13
Training loss: 2.6345088938289463
Validation loss: 2.6678483104922996

Epoch: 188| Step: 0
Training loss: 2.219424722727382
Validation loss: 2.628794244996356

Epoch: 6| Step: 1
Training loss: 2.3410745227265775
Validation loss: 2.607700196779439

Epoch: 6| Step: 2
Training loss: 2.551463668226683
Validation loss: 2.7104505556889547

Epoch: 6| Step: 3
Training loss: 2.6322625828233095
Validation loss: 2.6066595052123436

Epoch: 6| Step: 4
Training loss: 3.40091616684766
Validation loss: 2.569510346106771

Epoch: 6| Step: 5
Training loss: 2.6743161833719324
Validation loss: 2.6301908291226437

Epoch: 6| Step: 6
Training loss: 2.755069481584476
Validation loss: 2.649855859922361

Epoch: 6| Step: 7
Training loss: 3.158509305079445
Validation loss: 2.6285018308743404

Epoch: 6| Step: 8
Training loss: 2.9110081597033313
Validation loss: 2.6222845976263263

Epoch: 6| Step: 9
Training loss: 2.761113425555966
Validation loss: 2.6356913702157923

Epoch: 6| Step: 10
Training loss: 3.2323814550909398
Validation loss: 2.617020759787072

Epoch: 6| Step: 11
Training loss: 2.059071783918211
Validation loss: 2.678089910394516

Epoch: 6| Step: 12
Training loss: 1.891525558496645
Validation loss: 2.6259164660640137

Epoch: 6| Step: 13
Training loss: 1.581871194160432
Validation loss: 2.638834736291251

Epoch: 189| Step: 0
Training loss: 2.5175191252359843
Validation loss: 2.6726810237668226

Epoch: 6| Step: 1
Training loss: 2.7849209165730655
Validation loss: 2.665589506945929

Epoch: 6| Step: 2
Training loss: 1.8423209390367712
Validation loss: 2.644778915443227

Epoch: 6| Step: 3
Training loss: 2.5066544660650085
Validation loss: 2.6152216530010044

Epoch: 6| Step: 4
Training loss: 2.409921594507756
Validation loss: 2.696899813160966

Epoch: 6| Step: 5
Training loss: 3.423231996734489
Validation loss: 2.691005725861531

Epoch: 6| Step: 6
Training loss: 2.9200698253696227
Validation loss: 2.66956693714203

Epoch: 6| Step: 7
Training loss: 2.882967647523128
Validation loss: 2.6466990062328666

Epoch: 6| Step: 8
Training loss: 2.492672385756135
Validation loss: 2.6490417559724637

Epoch: 6| Step: 9
Training loss: 2.787712048047572
Validation loss: 2.678811021237386

Epoch: 6| Step: 10
Training loss: 2.8558927082990913
Validation loss: 2.684734175662069

Epoch: 6| Step: 11
Training loss: 3.181825411156703
Validation loss: 2.6543590457453528

Epoch: 6| Step: 12
Training loss: 2.4456707871691656
Validation loss: 2.6392356750120474

Epoch: 6| Step: 13
Training loss: 2.5995370122523873
Validation loss: 2.710103432603319

Epoch: 190| Step: 0
Training loss: 3.195368013156224
Validation loss: 2.644508343661901

Epoch: 6| Step: 1
Training loss: 1.8534679024826535
Validation loss: 2.6380635805633452

Epoch: 6| Step: 2
Training loss: 2.8376295018157665
Validation loss: 2.6280478905673417

Epoch: 6| Step: 3
Training loss: 2.5708299481221752
Validation loss: 2.6785031908936756

Epoch: 6| Step: 4
Training loss: 2.6694159541184836
Validation loss: 2.6122402155221818

Epoch: 6| Step: 5
Training loss: 2.1841075204086375
Validation loss: 2.7396842834696096

Epoch: 6| Step: 6
Training loss: 3.0921765574473197
Validation loss: 2.605138946822977

Epoch: 6| Step: 7
Training loss: 3.189756305438699
Validation loss: 2.600015342988967

Epoch: 6| Step: 8
Training loss: 3.20663037042306
Validation loss: 2.6198763869838984

Epoch: 6| Step: 9
Training loss: 2.1366430963097933
Validation loss: 2.615558528850654

Epoch: 6| Step: 10
Training loss: 2.8600376382765313
Validation loss: 2.6621503508030817

Epoch: 6| Step: 11
Training loss: 2.6155268168736403
Validation loss: 2.6572125519192005

Epoch: 6| Step: 12
Training loss: 2.7121653126207845
Validation loss: 2.6330557296659847

Epoch: 6| Step: 13
Training loss: 1.7946787805493227
Validation loss: 2.631396672731809

Epoch: 191| Step: 0
Training loss: 2.4224008296985287
Validation loss: 2.651723308476352

Epoch: 6| Step: 1
Training loss: 2.6131659284158735
Validation loss: 2.62048393586499

Epoch: 6| Step: 2
Training loss: 2.247009303041018
Validation loss: 2.6839277598713944

Epoch: 6| Step: 3
Training loss: 1.9877469107366734
Validation loss: 2.608482292136652

Epoch: 6| Step: 4
Training loss: 3.36246564769569
Validation loss: 2.5977280897886335

Epoch: 6| Step: 5
Training loss: 2.185209001021026
Validation loss: 2.6819281199780423

Epoch: 6| Step: 6
Training loss: 3.4966085896670642
Validation loss: 2.665812862005431

Epoch: 6| Step: 7
Training loss: 3.207186770646749
Validation loss: 2.686296682502677

Epoch: 6| Step: 8
Training loss: 2.5245697032533037
Validation loss: 2.672122138159839

Epoch: 6| Step: 9
Training loss: 2.5580067201396366
Validation loss: 2.650354625422264

Epoch: 6| Step: 10
Training loss: 2.8001197448738373
Validation loss: 2.64433485920121

Epoch: 6| Step: 11
Training loss: 2.138897386619344
Validation loss: 2.6308121205769743

Epoch: 6| Step: 12
Training loss: 2.584787533733374
Validation loss: 2.6134806806027773

Epoch: 6| Step: 13
Training loss: 2.734882765354737
Validation loss: 2.669599817363141

Epoch: 192| Step: 0
Training loss: 2.1640847545815314
Validation loss: 2.564800999146488

Epoch: 6| Step: 1
Training loss: 2.611721331623341
Validation loss: 2.65641445782425

Epoch: 6| Step: 2
Training loss: 2.677109793644819
Validation loss: 2.650516457903546

Epoch: 6| Step: 3
Training loss: 2.5502598274848594
Validation loss: 2.6771037137399465

Epoch: 6| Step: 4
Training loss: 2.940824534733719
Validation loss: 2.66113834027923

Epoch: 6| Step: 5
Training loss: 3.163728069951358
Validation loss: 2.6598235749236263

Epoch: 6| Step: 6
Training loss: 2.361701071342099
Validation loss: 2.6350661234367596

Epoch: 6| Step: 7
Training loss: 2.065995462181817
Validation loss: 2.648351522416116

Epoch: 6| Step: 8
Training loss: 2.4101313214118014
Validation loss: 2.651618001496235

Epoch: 6| Step: 9
Training loss: 3.0791227785801736
Validation loss: 2.65670710568921

Epoch: 6| Step: 10
Training loss: 2.9454674313217333
Validation loss: 2.644582966661301

Epoch: 6| Step: 11
Training loss: 2.6198720344567805
Validation loss: 2.6643190727980057

Epoch: 6| Step: 12
Training loss: 1.9472669718134135
Validation loss: 2.6359596093617013

Epoch: 6| Step: 13
Training loss: 3.995833611248008
Validation loss: 2.6244675584127037

Epoch: 193| Step: 0
Training loss: 2.6477024554973467
Validation loss: 2.5898367940873364

Epoch: 6| Step: 1
Training loss: 2.95088150948906
Validation loss: 2.5796599898893153

Epoch: 6| Step: 2
Training loss: 2.1547672868303636
Validation loss: 2.6587933673632262

Epoch: 6| Step: 3
Training loss: 2.467557788237888
Validation loss: 2.6484615000445224

Epoch: 6| Step: 4
Training loss: 2.002458849042385
Validation loss: 2.6331660745098704

Epoch: 6| Step: 5
Training loss: 2.35023567560053
Validation loss: 2.725441629388741

Epoch: 6| Step: 6
Training loss: 2.7668662868627103
Validation loss: 2.645208420778801

Epoch: 6| Step: 7
Training loss: 2.7633424811984484
Validation loss: 2.639811136572645

Epoch: 6| Step: 8
Training loss: 2.5748043985980837
Validation loss: 2.665116160905087

Epoch: 6| Step: 9
Training loss: 2.279126367671809
Validation loss: 2.671054645306276

Epoch: 6| Step: 10
Training loss: 2.3353359506788225
Validation loss: 2.69751225500731

Epoch: 6| Step: 11
Training loss: 3.0309070511136156
Validation loss: 2.642596053885967

Epoch: 6| Step: 12
Training loss: 3.2157095465189705
Validation loss: 2.5956781028208726

Epoch: 6| Step: 13
Training loss: 3.3491543741626266
Validation loss: 2.639292200597596

Epoch: 194| Step: 0
Training loss: 2.5944771723982663
Validation loss: 2.6555720169192303

Epoch: 6| Step: 1
Training loss: 3.020264530343651
Validation loss: 2.6044575846618687

Epoch: 6| Step: 2
Training loss: 3.1391312572189185
Validation loss: 2.59351914642757

Epoch: 6| Step: 3
Training loss: 2.3983225841515496
Validation loss: 2.6613482062843015

Epoch: 6| Step: 4
Training loss: 2.3448026200700567
Validation loss: 2.5881041830170326

Epoch: 6| Step: 5
Training loss: 2.9852804837486193
Validation loss: 2.581696699115759

Epoch: 6| Step: 6
Training loss: 2.775449383064678
Validation loss: 2.682960253138222

Epoch: 6| Step: 7
Training loss: 2.849693710198231
Validation loss: 2.6238693042496006

Epoch: 6| Step: 8
Training loss: 2.316641115372444
Validation loss: 2.6528347482226056

Epoch: 6| Step: 9
Training loss: 2.185160557589549
Validation loss: 2.676200845417205

Epoch: 6| Step: 10
Training loss: 3.2710239006622395
Validation loss: 2.678393341293136

Epoch: 6| Step: 11
Training loss: 3.0162375030701343
Validation loss: 2.622828541558038

Epoch: 6| Step: 12
Training loss: 2.4273800211524037
Validation loss: 2.6651435996613246

Epoch: 6| Step: 13
Training loss: 2.1925290744989434
Validation loss: 2.709026500385819

Epoch: 195| Step: 0
Training loss: 2.4014607116929243
Validation loss: 2.7002165454209996

Epoch: 6| Step: 1
Training loss: 2.623244107032467
Validation loss: 2.570348956363246

Epoch: 6| Step: 2
Training loss: 2.084149569512847
Validation loss: 2.613163180499594

Epoch: 6| Step: 3
Training loss: 2.5758534915085516
Validation loss: 2.6581741968798887

Epoch: 6| Step: 4
Training loss: 2.1957719532484714
Validation loss: 2.6613725542009474

Epoch: 6| Step: 5
Training loss: 2.595074235151994
Validation loss: 2.61345391285797

Epoch: 6| Step: 6
Training loss: 2.6620183804606152
Validation loss: 2.594549211865392

Epoch: 6| Step: 7
Training loss: 3.9324247560862844
Validation loss: 2.6199602578298977

Epoch: 6| Step: 8
Training loss: 2.435969434605908
Validation loss: 2.6714978386348105

Epoch: 6| Step: 9
Training loss: 2.7756656776201374
Validation loss: 2.6349342511339287

Epoch: 6| Step: 10
Training loss: 1.972077660642786
Validation loss: 2.5979787052299885

Epoch: 6| Step: 11
Training loss: 3.2325928426746278
Validation loss: 2.6441117637399474

Epoch: 6| Step: 12
Training loss: 2.1798270669642847
Validation loss: 2.710262164227286

Epoch: 6| Step: 13
Training loss: 3.229492630452419
Validation loss: 2.6035060006790838

Epoch: 196| Step: 0
Training loss: 2.1421781599535397
Validation loss: 2.6323472666600654

Epoch: 6| Step: 1
Training loss: 2.728333168783243
Validation loss: 2.6707534235056896

Epoch: 6| Step: 2
Training loss: 1.9927875886568138
Validation loss: 2.6676040275442396

Epoch: 6| Step: 3
Training loss: 2.446626352901413
Validation loss: 2.684485507442787

Epoch: 6| Step: 4
Training loss: 3.8955202979870105
Validation loss: 2.6089561282908456

Epoch: 6| Step: 5
Training loss: 2.5924306064540636
Validation loss: 2.6091945979557956

Epoch: 6| Step: 6
Training loss: 2.194712057843968
Validation loss: 2.6625853391623586

Epoch: 6| Step: 7
Training loss: 2.4988859555468603
Validation loss: 2.667863992977708

Epoch: 6| Step: 8
Training loss: 3.770704460400675
Validation loss: 2.6544251439070203

Epoch: 6| Step: 9
Training loss: 2.5129088908877275
Validation loss: 2.684252826973654

Epoch: 6| Step: 10
Training loss: 1.818002438366286
Validation loss: 2.6089090293890584

Epoch: 6| Step: 11
Training loss: 2.052232327030467
Validation loss: 2.653653696588671

Epoch: 6| Step: 12
Training loss: 3.0839686040009986
Validation loss: 2.6603841171594524

Epoch: 6| Step: 13
Training loss: 2.8110025446068407
Validation loss: 2.63788631595793

Epoch: 197| Step: 0
Training loss: 2.7578271968114945
Validation loss: 2.6006730101937343

Epoch: 6| Step: 1
Training loss: 2.915696573145572
Validation loss: 2.630918333430115

Epoch: 6| Step: 2
Training loss: 1.6489873032506157
Validation loss: 2.570622647082791

Epoch: 6| Step: 3
Training loss: 3.4245528103218956
Validation loss: 2.6801371371017675

Epoch: 6| Step: 4
Training loss: 2.355802344743718
Validation loss: 2.614086540418635

Epoch: 6| Step: 5
Training loss: 2.635099781470691
Validation loss: 2.647080847667786

Epoch: 6| Step: 6
Training loss: 1.855193236123767
Validation loss: 2.6060377628926368

Epoch: 6| Step: 7
Training loss: 2.9351810473566564
Validation loss: 2.5771858381633868

Epoch: 6| Step: 8
Training loss: 2.7920895346355543
Validation loss: 2.5583464642569496

Epoch: 6| Step: 9
Training loss: 3.326311503877109
Validation loss: 2.595252527849632

Epoch: 6| Step: 10
Training loss: 2.284582760569767
Validation loss: 2.626193316869313

Epoch: 6| Step: 11
Training loss: 2.7069761152281204
Validation loss: 2.5989036869142996

Epoch: 6| Step: 12
Training loss: 2.7501791115432552
Validation loss: 2.660642645117424

Epoch: 6| Step: 13
Training loss: 1.8477941223706722
Validation loss: 2.613047658467371

Epoch: 198| Step: 0
Training loss: 2.163272093605069
Validation loss: 2.6108336100118246

Epoch: 6| Step: 1
Training loss: 3.15063188058336
Validation loss: 2.647022074903357

Epoch: 6| Step: 2
Training loss: 2.036050962271224
Validation loss: 2.658383999866081

Epoch: 6| Step: 3
Training loss: 2.426925806873855
Validation loss: 2.5836341086065744

Epoch: 6| Step: 4
Training loss: 2.343489263654418
Validation loss: 2.704347443954233

Epoch: 6| Step: 5
Training loss: 2.512806610833003
Validation loss: 2.6104509653979937

Epoch: 6| Step: 6
Training loss: 2.278621256377876
Validation loss: 2.6804310503023014

Epoch: 6| Step: 7
Training loss: 3.536017651224743
Validation loss: 2.661851183079787

Epoch: 6| Step: 8
Training loss: 2.1779302260937254
Validation loss: 2.6954388808049674

Epoch: 6| Step: 9
Training loss: 3.8761532205741913
Validation loss: 2.6365548371928273

Epoch: 6| Step: 10
Training loss: 2.4409239758033956
Validation loss: 2.6311501679083658

Epoch: 6| Step: 11
Training loss: 2.0239009841853974
Validation loss: 2.6927679657509076

Epoch: 6| Step: 12
Training loss: 2.746505597894819
Validation loss: 2.7069537439301294

Epoch: 6| Step: 13
Training loss: 2.7157342781230565
Validation loss: 2.6198890942080717

Epoch: 199| Step: 0
Training loss: 2.5350332362537444
Validation loss: 2.603841147146081

Epoch: 6| Step: 1
Training loss: 2.9030553836092645
Validation loss: 2.6420696860117325

Epoch: 6| Step: 2
Training loss: 2.752412951181746
Validation loss: 2.62282325901305

Epoch: 6| Step: 3
Training loss: 2.561032689241543
Validation loss: 2.6447875831004235

Epoch: 6| Step: 4
Training loss: 3.201969589632245
Validation loss: 2.6704197098476334

Epoch: 6| Step: 5
Training loss: 2.4843028315972333
Validation loss: 2.617372723537348

Epoch: 6| Step: 6
Training loss: 2.5367712393153776
Validation loss: 2.657885218589807

Epoch: 6| Step: 7
Training loss: 2.7603699494253355
Validation loss: 2.6409563290071256

Epoch: 6| Step: 8
Training loss: 2.1088266295669156
Validation loss: 2.598505477386571

Epoch: 6| Step: 9
Training loss: 2.5330835930381075
Validation loss: 2.640981477443316

Epoch: 6| Step: 10
Training loss: 2.8004208895558698
Validation loss: 2.628711916022953

Epoch: 6| Step: 11
Training loss: 2.641903178541022
Validation loss: 2.682317808943575

Epoch: 6| Step: 12
Training loss: 2.78197178422234
Validation loss: 2.6459950333156157

Epoch: 6| Step: 13
Training loss: 2.3778129783987847
Validation loss: 2.616207523505481

Epoch: 200| Step: 0
Training loss: 2.91347548885061
Validation loss: 2.6482984360111037

Epoch: 6| Step: 1
Training loss: 2.71864423874975
Validation loss: 2.6121640286831735

Epoch: 6| Step: 2
Training loss: 2.565685989825854
Validation loss: 2.5976017673233702

Epoch: 6| Step: 3
Training loss: 2.2196552417875663
Validation loss: 2.6002682308677914

Epoch: 6| Step: 4
Training loss: 3.3181271530722083
Validation loss: 2.598307260422497

Epoch: 6| Step: 5
Training loss: 2.5866791275386274
Validation loss: 2.6420172341273154

Epoch: 6| Step: 6
Training loss: 1.91835027501071
Validation loss: 2.6624875678207838

Epoch: 6| Step: 7
Training loss: 2.7316457151858944
Validation loss: 2.6059468389673084

Epoch: 6| Step: 8
Training loss: 2.1183977222436146
Validation loss: 2.6425449056474393

Epoch: 6| Step: 9
Training loss: 2.990272965235149
Validation loss: 2.671744721901857

Epoch: 6| Step: 10
Training loss: 2.6048293122587127
Validation loss: 2.639137094983228

Epoch: 6| Step: 11
Training loss: 2.5033944926640865
Validation loss: 2.6205090870669894

Epoch: 6| Step: 12
Training loss: 2.4036699805625905
Validation loss: 2.6471680625537295

Epoch: 6| Step: 13
Training loss: 2.036137613341163
Validation loss: 2.57309749931477

Epoch: 201| Step: 0
Training loss: 3.0577210488188973
Validation loss: 2.5922477731726192

Epoch: 6| Step: 1
Training loss: 2.14355702324047
Validation loss: 2.6100448496278834

Epoch: 6| Step: 2
Training loss: 3.066140016308677
Validation loss: 2.5795975801080298

Epoch: 6| Step: 3
Training loss: 2.5235316019847702
Validation loss: 2.612391743490249

Epoch: 6| Step: 4
Training loss: 1.456471517193353
Validation loss: 2.657327112925971

Epoch: 6| Step: 5
Training loss: 2.7741280569100004
Validation loss: 2.6331085771815372

Epoch: 6| Step: 6
Training loss: 2.143202295208279
Validation loss: 2.6350875999894368

Epoch: 6| Step: 7
Training loss: 3.0916290719624686
Validation loss: 2.6578218079096554

Epoch: 6| Step: 8
Training loss: 3.096164878318878
Validation loss: 2.6345637405805418

Epoch: 6| Step: 9
Training loss: 2.390296265183787
Validation loss: 2.6503013610135655

Epoch: 6| Step: 10
Training loss: 2.590891814440449
Validation loss: 2.690869502024423

Epoch: 6| Step: 11
Training loss: 2.3157737859167207
Validation loss: 2.58907406247678

Epoch: 6| Step: 12
Training loss: 2.4945929228449293
Validation loss: 2.6429802107773686

Epoch: 6| Step: 13
Training loss: 3.3847305463325816
Validation loss: 2.628160516550776

Epoch: 202| Step: 0
Training loss: 2.3941916991997716
Validation loss: 2.6915315121774905

Epoch: 6| Step: 1
Training loss: 1.6466734066077506
Validation loss: 2.6836496259474494

Epoch: 6| Step: 2
Training loss: 1.500730575031654
Validation loss: 2.625900606280038

Epoch: 6| Step: 3
Training loss: 2.738372235276257
Validation loss: 2.6433623711890237

Epoch: 6| Step: 4
Training loss: 2.271479126915154
Validation loss: 2.658702921769219

Epoch: 6| Step: 5
Training loss: 3.3725005890864828
Validation loss: 2.564334848756654

Epoch: 6| Step: 6
Training loss: 3.0047887093751338
Validation loss: 2.6047953231191703

Epoch: 6| Step: 7
Training loss: 2.42393071697543
Validation loss: 2.653431517967786

Epoch: 6| Step: 8
Training loss: 2.610635418769516
Validation loss: 2.66243609303036

Epoch: 6| Step: 9
Training loss: 3.2587833558816532
Validation loss: 2.6031343805466896

Epoch: 6| Step: 10
Training loss: 3.579431287037516
Validation loss: 2.573077727174813

Epoch: 6| Step: 11
Training loss: 2.850975164256439
Validation loss: 2.6085866093602705

Epoch: 6| Step: 12
Training loss: 2.10357456248677
Validation loss: 2.670225011885882

Epoch: 6| Step: 13
Training loss: 3.0367330140097044
Validation loss: 2.665470742141525

Epoch: 203| Step: 0
Training loss: 2.4771533345522436
Validation loss: 2.6914555324108074

Epoch: 6| Step: 1
Training loss: 3.042313197849793
Validation loss: 2.646897550004174

Epoch: 6| Step: 2
Training loss: 2.731703144952532
Validation loss: 2.6246087524455715

Epoch: 6| Step: 3
Training loss: 1.8395102941832115
Validation loss: 2.7469084880099333

Epoch: 6| Step: 4
Training loss: 2.228184052657201
Validation loss: 2.6363479549210194

Epoch: 6| Step: 5
Training loss: 1.8514462205131406
Validation loss: 2.61125093469128

Epoch: 6| Step: 6
Training loss: 2.884704134627317
Validation loss: 2.609398485912756

Epoch: 6| Step: 7
Training loss: 2.012590119612781
Validation loss: 2.5864440522953482

Epoch: 6| Step: 8
Training loss: 3.458389480931673
Validation loss: 2.630162415560022

Epoch: 6| Step: 9
Training loss: 2.7315832218492235
Validation loss: 2.6068083610331763

Epoch: 6| Step: 10
Training loss: 2.764444131420168
Validation loss: 2.589126900733234

Epoch: 6| Step: 11
Training loss: 2.778315077845464
Validation loss: 2.629896998896962

Epoch: 6| Step: 12
Training loss: 2.4904340835974064
Validation loss: 2.7349851137976073

Epoch: 6| Step: 13
Training loss: 2.9021050212530772
Validation loss: 2.616971190930567

Epoch: 204| Step: 0
Training loss: 2.381821923646761
Validation loss: 2.6548885087009757

Epoch: 6| Step: 1
Training loss: 2.326913608063714
Validation loss: 2.6075608459212622

Epoch: 6| Step: 2
Training loss: 2.604693021350814
Validation loss: 2.6699812853285843

Epoch: 6| Step: 3
Training loss: 3.055366460170141
Validation loss: 2.6243850878467043

Epoch: 6| Step: 4
Training loss: 2.684593314373766
Validation loss: 2.627350070183911

Epoch: 6| Step: 5
Training loss: 2.32646160739593
Validation loss: 2.549205738007379

Epoch: 6| Step: 6
Training loss: 2.572930576631781
Validation loss: 2.6616362653574375

Epoch: 6| Step: 7
Training loss: 2.6859218488218373
Validation loss: 2.6114789598131742

Epoch: 6| Step: 8
Training loss: 2.68040541215745
Validation loss: 2.6591159210863244

Epoch: 6| Step: 9
Training loss: 2.8780836071305833
Validation loss: 2.6358200475298594

Epoch: 6| Step: 10
Training loss: 2.069327757217491
Validation loss: 2.6994085940687276

Epoch: 6| Step: 11
Training loss: 2.596732848829409
Validation loss: 2.6508719233615907

Epoch: 6| Step: 12
Training loss: 2.5929046540184086
Validation loss: 2.588019050976246

Epoch: 6| Step: 13
Training loss: 3.776921592878253
Validation loss: 2.600245719890852

Epoch: 205| Step: 0
Training loss: 2.8404456422960074
Validation loss: 2.6741023451164745

Epoch: 6| Step: 1
Training loss: 2.3016730816102826
Validation loss: 2.6405788931425924

Epoch: 6| Step: 2
Training loss: 2.5825048984654693
Validation loss: 2.7099903373302308

Epoch: 6| Step: 3
Training loss: 2.706485841971646
Validation loss: 2.653563041997189

Epoch: 6| Step: 4
Training loss: 3.1006016239760674
Validation loss: 2.618505422734631

Epoch: 6| Step: 5
Training loss: 2.341248868910419
Validation loss: 2.6546438332775746

Epoch: 6| Step: 6
Training loss: 2.350594457556225
Validation loss: 2.698234387043785

Epoch: 6| Step: 7
Training loss: 2.5372412150297907
Validation loss: 2.629162132917517

Epoch: 6| Step: 8
Training loss: 2.4462785366540016
Validation loss: 2.648613809204339

Epoch: 6| Step: 9
Training loss: 1.868536553584462
Validation loss: 2.6510371112999915

Epoch: 6| Step: 10
Training loss: 3.079055568013992
Validation loss: 2.657865012332801

Epoch: 6| Step: 11
Training loss: 2.999198011648069
Validation loss: 2.687918649256829

Epoch: 6| Step: 12
Training loss: 3.1348001543561694
Validation loss: 2.6349159811483576

Epoch: 6| Step: 13
Training loss: 2.291063599275252
Validation loss: 2.6066293716873132

Epoch: 206| Step: 0
Training loss: 2.1325389421133973
Validation loss: 2.569489197940376

Epoch: 6| Step: 1
Training loss: 2.6675027688896016
Validation loss: 2.6147049295169738

Epoch: 6| Step: 2
Training loss: 2.1678075232138663
Validation loss: 2.6250080913256877

Epoch: 6| Step: 3
Training loss: 2.714605658540145
Validation loss: 2.642368369049637

Epoch: 6| Step: 4
Training loss: 2.407518027962025
Validation loss: 2.6379442125588137

Epoch: 6| Step: 5
Training loss: 2.80392284117366
Validation loss: 2.747383038719877

Epoch: 6| Step: 6
Training loss: 3.2505275591574048
Validation loss: 2.608637156662192

Epoch: 6| Step: 7
Training loss: 3.002089567440495
Validation loss: 2.639398973565061

Epoch: 6| Step: 8
Training loss: 3.2766997258124904
Validation loss: 2.6847062581915084

Epoch: 6| Step: 9
Training loss: 2.564940244339281
Validation loss: 2.6786670548206044

Epoch: 6| Step: 10
Training loss: 3.0463799490152583
Validation loss: 2.654721953986344

Epoch: 6| Step: 11
Training loss: 2.6687651265271786
Validation loss: 2.625796985691044

Epoch: 6| Step: 12
Training loss: 1.8986599010916694
Validation loss: 2.583812776971117

Epoch: 6| Step: 13
Training loss: 1.8229929953444224
Validation loss: 2.6461296687512217

Epoch: 207| Step: 0
Training loss: 2.1751986533460697
Validation loss: 2.6634588700755177

Epoch: 6| Step: 1
Training loss: 2.3847330327036746
Validation loss: 2.6495013853927945

Epoch: 6| Step: 2
Training loss: 2.3749329406908144
Validation loss: 2.7007467204477913

Epoch: 6| Step: 3
Training loss: 2.0992889017778
Validation loss: 2.7043378229881294

Epoch: 6| Step: 4
Training loss: 1.5694186575167397
Validation loss: 2.643382833780532

Epoch: 6| Step: 5
Training loss: 2.9937091673294263
Validation loss: 2.6400673385368116

Epoch: 6| Step: 6
Training loss: 3.2498083791729586
Validation loss: 2.6118616776137067

Epoch: 6| Step: 7
Training loss: 2.8172717834491667
Validation loss: 2.6184833040048576

Epoch: 6| Step: 8
Training loss: 2.3938672388116395
Validation loss: 2.6948976316032622

Epoch: 6| Step: 9
Training loss: 2.9552680419082
Validation loss: 2.6623361650254287

Epoch: 6| Step: 10
Training loss: 2.6228905330827583
Validation loss: 2.6616482338323673

Epoch: 6| Step: 11
Training loss: 2.5593359416734076
Validation loss: 2.624206741001172

Epoch: 6| Step: 12
Training loss: 2.9611784099718803
Validation loss: 2.5987559507780773

Epoch: 6| Step: 13
Training loss: 3.5784237666104306
Validation loss: 2.6395881599240796

Epoch: 208| Step: 0
Training loss: 2.199503309361422
Validation loss: 2.680179273022483

Epoch: 6| Step: 1
Training loss: 2.9575378709627222
Validation loss: 2.544897900837389

Epoch: 6| Step: 2
Training loss: 2.5429199964124503
Validation loss: 2.6155957301930357

Epoch: 6| Step: 3
Training loss: 2.677601705947118
Validation loss: 2.6051722839692477

Epoch: 6| Step: 4
Training loss: 2.2720838364190694
Validation loss: 2.607944564352277

Epoch: 6| Step: 5
Training loss: 3.0863327352713634
Validation loss: 2.6059753532547743

Epoch: 6| Step: 6
Training loss: 2.545068017916282
Validation loss: 2.6303915499522783

Epoch: 6| Step: 7
Training loss: 2.8917768503207126
Validation loss: 2.628027081281961

Epoch: 6| Step: 8
Training loss: 2.5392970519668316
Validation loss: 2.669058567894378

Epoch: 6| Step: 9
Training loss: 3.249788717591403
Validation loss: 2.63476173103034

Epoch: 6| Step: 10
Training loss: 2.1297396367297035
Validation loss: 2.671237685565834

Epoch: 6| Step: 11
Training loss: 2.157867709371328
Validation loss: 2.640551496214375

Epoch: 6| Step: 12
Training loss: 2.4395854538393347
Validation loss: 2.665380081654376

Epoch: 6| Step: 13
Training loss: 2.6296958701079287
Validation loss: 2.6297582159357957

Epoch: 209| Step: 0
Training loss: 3.2543628459283678
Validation loss: 2.6487448010658357

Epoch: 6| Step: 1
Training loss: 1.7680913527824453
Validation loss: 2.6227137516925483

Epoch: 6| Step: 2
Training loss: 3.1582405687328876
Validation loss: 2.6787084472738467

Epoch: 6| Step: 3
Training loss: 2.8691851649453
Validation loss: 2.6458849008457257

Epoch: 6| Step: 4
Training loss: 1.702513278679732
Validation loss: 2.646725061932243

Epoch: 6| Step: 5
Training loss: 3.2268193399024008
Validation loss: 2.683152733301336

Epoch: 6| Step: 6
Training loss: 2.4044949955815786
Validation loss: 2.6532916615882183

Epoch: 6| Step: 7
Training loss: 2.5239999811501965
Validation loss: 2.6688098396343167

Epoch: 6| Step: 8
Training loss: 2.6752387394833423
Validation loss: 2.6142864714893874

Epoch: 6| Step: 9
Training loss: 2.7489206623494695
Validation loss: 2.621962325432345

Epoch: 6| Step: 10
Training loss: 2.251447000393537
Validation loss: 2.64053870007482

Epoch: 6| Step: 11
Training loss: 2.357110054233738
Validation loss: 2.649445904928957

Epoch: 6| Step: 12
Training loss: 2.7604501878154584
Validation loss: 2.631192713190769

Epoch: 6| Step: 13
Training loss: 2.440138147226765
Validation loss: 2.618898896753274

Epoch: 210| Step: 0
Training loss: 3.3240644013447014
Validation loss: 2.718406907364998

Epoch: 6| Step: 1
Training loss: 2.309768300512149
Validation loss: 2.635311040123835

Epoch: 6| Step: 2
Training loss: 2.518979507478026
Validation loss: 2.6138914606679773

Epoch: 6| Step: 3
Training loss: 2.4335377106559433
Validation loss: 2.5981348214157274

Epoch: 6| Step: 4
Training loss: 3.0498267327793536
Validation loss: 2.6617429587624346

Epoch: 6| Step: 5
Training loss: 2.4211204091586462
Validation loss: 2.6232089433312695

Epoch: 6| Step: 6
Training loss: 2.3197824405737357
Validation loss: 2.6366086909371615

Epoch: 6| Step: 7
Training loss: 2.792225729537052
Validation loss: 2.6395551379821893

Epoch: 6| Step: 8
Training loss: 2.7343940080254505
Validation loss: 2.628153976146664

Epoch: 6| Step: 9
Training loss: 3.179504389258791
Validation loss: 2.6601990197048586

Epoch: 6| Step: 10
Training loss: 2.259825973562153
Validation loss: 2.6813211270353503

Epoch: 6| Step: 11
Training loss: 2.582830954484036
Validation loss: 2.605021283765022

Epoch: 6| Step: 12
Training loss: 2.3177724993678055
Validation loss: 2.7098946064971385

Epoch: 6| Step: 13
Training loss: 3.133945326863182
Validation loss: 2.645766943332074

Epoch: 211| Step: 0
Training loss: 3.506108539195991
Validation loss: 2.6547233986594256

Epoch: 6| Step: 1
Training loss: 2.792551374927614
Validation loss: 2.5747054580405466

Epoch: 6| Step: 2
Training loss: 2.283475756786096
Validation loss: 2.579240388502634

Epoch: 6| Step: 3
Training loss: 2.615605847141598
Validation loss: 2.6190528066658603

Epoch: 6| Step: 4
Training loss: 2.780556495870439
Validation loss: 2.6912730499082644

Epoch: 6| Step: 5
Training loss: 2.264791085248385
Validation loss: 2.616798662182735

Epoch: 6| Step: 6
Training loss: 2.7366930046471363
Validation loss: 2.6643283966190694

Epoch: 6| Step: 7
Training loss: 2.007467158560806
Validation loss: 2.6156684660855705

Epoch: 6| Step: 8
Training loss: 3.231983719831953
Validation loss: 2.6027449236782787

Epoch: 6| Step: 9
Training loss: 2.4944822455328897
Validation loss: 2.6154392359504417

Epoch: 6| Step: 10
Training loss: 1.9661595089333652
Validation loss: 2.655735829418639

Epoch: 6| Step: 11
Training loss: 2.571593177159061
Validation loss: 2.678533064259359

Epoch: 6| Step: 12
Training loss: 2.919063255604813
Validation loss: 2.674079084270312

Epoch: 6| Step: 13
Training loss: 2.570908033953971
Validation loss: 2.644074577717011

Epoch: 212| Step: 0
Training loss: 1.8365563181678493
Validation loss: 2.6655627844847563

Epoch: 6| Step: 1
Training loss: 2.2765323508628525
Validation loss: 2.5714690561838287

Epoch: 6| Step: 2
Training loss: 2.85086694882878
Validation loss: 2.6192391207829213

Epoch: 6| Step: 3
Training loss: 2.634088495678147
Validation loss: 2.6203256662724455

Epoch: 6| Step: 4
Training loss: 2.79993735652058
Validation loss: 2.6396494766895002

Epoch: 6| Step: 5
Training loss: 2.2253448904814275
Validation loss: 2.6907529572809934

Epoch: 6| Step: 6
Training loss: 2.545437459764483
Validation loss: 2.657066302785846

Epoch: 6| Step: 7
Training loss: 2.719610143940115
Validation loss: 2.6442804647661133

Epoch: 6| Step: 8
Training loss: 2.5984814243882184
Validation loss: 2.6349129688944557

Epoch: 6| Step: 9
Training loss: 2.6383180190425284
Validation loss: 2.548576227179073

Epoch: 6| Step: 10
Training loss: 2.64790973637412
Validation loss: 2.638838959419275

Epoch: 6| Step: 11
Training loss: 3.365207452826872
Validation loss: 2.601041820614052

Epoch: 6| Step: 12
Training loss: 2.9682759759820656
Validation loss: 2.6127608263111117

Epoch: 6| Step: 13
Training loss: 2.132003015741502
Validation loss: 2.6679887183061055

Epoch: 213| Step: 0
Training loss: 2.3290017544456023
Validation loss: 2.6895975897205844

Epoch: 6| Step: 1
Training loss: 2.750207979833985
Validation loss: 2.621281894144344

Epoch: 6| Step: 2
Training loss: 2.6291508327033535
Validation loss: 2.5985265418291243

Epoch: 6| Step: 3
Training loss: 3.3031484207867643
Validation loss: 2.6065474097660832

Epoch: 6| Step: 4
Training loss: 2.52437241186022
Validation loss: 2.651111727490932

Epoch: 6| Step: 5
Training loss: 2.2506384473556236
Validation loss: 2.604141333343996

Epoch: 6| Step: 6
Training loss: 2.8075008467743463
Validation loss: 2.605871423395397

Epoch: 6| Step: 7
Training loss: 2.0543701158818886
Validation loss: 2.6651989303406594

Epoch: 6| Step: 8
Training loss: 1.9205576405752822
Validation loss: 2.6756790102079013

Epoch: 6| Step: 9
Training loss: 2.3953679724712984
Validation loss: 2.6920876425009177

Epoch: 6| Step: 10
Training loss: 2.552478079855835
Validation loss: 2.6138007442279094

Epoch: 6| Step: 11
Training loss: 3.0184627483167774
Validation loss: 2.652400834224708

Epoch: 6| Step: 12
Training loss: 2.7919657153235233
Validation loss: 2.7004601547536624

Epoch: 6| Step: 13
Training loss: 3.1117877129860445
Validation loss: 2.608406686470526

Epoch: 214| Step: 0
Training loss: 2.546704151999458
Validation loss: 2.6348859129401814

Epoch: 6| Step: 1
Training loss: 3.1607879648557344
Validation loss: 2.635476478703054

Epoch: 6| Step: 2
Training loss: 2.027159812976923
Validation loss: 2.6878908330562883

Epoch: 6| Step: 3
Training loss: 2.5736954060082002
Validation loss: 2.595744844391793

Epoch: 6| Step: 4
Training loss: 2.388928378564874
Validation loss: 2.651998675507936

Epoch: 6| Step: 5
Training loss: 2.6399469351492755
Validation loss: 2.6279532768358465

Epoch: 6| Step: 6
Training loss: 1.6288542887864157
Validation loss: 2.700141500291993

Epoch: 6| Step: 7
Training loss: 2.35169845644279
Validation loss: 2.61165227876929

Epoch: 6| Step: 8
Training loss: 2.509938702385755
Validation loss: 2.551247193861383

Epoch: 6| Step: 9
Training loss: 2.6693026111230878
Validation loss: 2.6161863162675196

Epoch: 6| Step: 10
Training loss: 2.266536976339081
Validation loss: 2.628058679490683

Epoch: 6| Step: 11
Training loss: 3.1849872932599808
Validation loss: 2.6542175180175

Epoch: 6| Step: 12
Training loss: 3.5732479257008447
Validation loss: 2.6087542625674773

Epoch: 6| Step: 13
Training loss: 2.5145670875797794
Validation loss: 2.638818800649758

Epoch: 215| Step: 0
Training loss: 2.1828404527866385
Validation loss: 2.6036931998423696

Epoch: 6| Step: 1
Training loss: 2.802915560617839
Validation loss: 2.645825384501276

Epoch: 6| Step: 2
Training loss: 2.8749359787156767
Validation loss: 2.5938540666491448

Epoch: 6| Step: 3
Training loss: 2.759195818327016
Validation loss: 2.6634374769516223

Epoch: 6| Step: 4
Training loss: 3.0118827725682418
Validation loss: 2.600579790084655

Epoch: 6| Step: 5
Training loss: 2.336095900252338
Validation loss: 2.6532570661637105

Epoch: 6| Step: 6
Training loss: 2.568687783483254
Validation loss: 2.656984091460103

Epoch: 6| Step: 7
Training loss: 1.9264566038161146
Validation loss: 2.6923687677669013

Epoch: 6| Step: 8
Training loss: 2.438913571235968
Validation loss: 2.642540941649147

Epoch: 6| Step: 9
Training loss: 2.4352501487312863
Validation loss: 2.6570482206805632

Epoch: 6| Step: 10
Training loss: 2.63215515805243
Validation loss: 2.688700677473636

Epoch: 6| Step: 11
Training loss: 2.6493336109582954
Validation loss: 2.642269687593597

Epoch: 6| Step: 12
Training loss: 3.1146316949838466
Validation loss: 2.598354152893948

Epoch: 6| Step: 13
Training loss: 2.8674954864812316
Validation loss: 2.5849176927763753

Epoch: 216| Step: 0
Training loss: 1.8316448918588004
Validation loss: 2.6325431396987122

Epoch: 6| Step: 1
Training loss: 2.6408021404734954
Validation loss: 2.669641244770418

Epoch: 6| Step: 2
Training loss: 2.5927771156988975
Validation loss: 2.640304913009643

Epoch: 6| Step: 3
Training loss: 2.4596973018962243
Validation loss: 2.698647677556043

Epoch: 6| Step: 4
Training loss: 2.5181688040461836
Validation loss: 2.625401520381587

Epoch: 6| Step: 5
Training loss: 2.305718556607978
Validation loss: 2.6321665573747435

Epoch: 6| Step: 6
Training loss: 3.5109988823054747
Validation loss: 2.6701693801920117

Epoch: 6| Step: 7
Training loss: 2.738722304496208
Validation loss: 2.6561759634394897

Epoch: 6| Step: 8
Training loss: 2.5453467903614087
Validation loss: 2.655985283011735

Epoch: 6| Step: 9
Training loss: 2.132103323495784
Validation loss: 2.663310794296277

Epoch: 6| Step: 10
Training loss: 2.7743117982626777
Validation loss: 2.6502759082854515

Epoch: 6| Step: 11
Training loss: 3.145567994369562
Validation loss: 2.6162705327406357

Epoch: 6| Step: 12
Training loss: 3.0227450580816813
Validation loss: 2.607387868528807

Epoch: 6| Step: 13
Training loss: 2.4612536999242125
Validation loss: 2.663585652523217

Epoch: 217| Step: 0
Training loss: 2.6664382320154743
Validation loss: 2.6551088153424294

Epoch: 6| Step: 1
Training loss: 2.5991437969402256
Validation loss: 2.634196877107113

Epoch: 6| Step: 2
Training loss: 2.6539127613669384
Validation loss: 2.583185760009017

Epoch: 6| Step: 3
Training loss: 2.569993205080067
Validation loss: 2.5863716096444858

Epoch: 6| Step: 4
Training loss: 2.4152994782892283
Validation loss: 2.6447642030430467

Epoch: 6| Step: 5
Training loss: 2.707570912567579
Validation loss: 2.6184174773559734

Epoch: 6| Step: 6
Training loss: 2.3235050932974306
Validation loss: 2.6085371578711922

Epoch: 6| Step: 7
Training loss: 2.4047989867146704
Validation loss: 2.6685394333530805

Epoch: 6| Step: 8
Training loss: 3.2772625627794163
Validation loss: 2.6154074490114714

Epoch: 6| Step: 9
Training loss: 2.6307055818483223
Validation loss: 2.594204323814969

Epoch: 6| Step: 10
Training loss: 1.9170544964482086
Validation loss: 2.641516023339343

Epoch: 6| Step: 11
Training loss: 2.2981733947090324
Validation loss: 2.638335165518172

Epoch: 6| Step: 12
Training loss: 2.6094603381792876
Validation loss: 2.625373606700489

Epoch: 6| Step: 13
Training loss: 3.4968406859649783
Validation loss: 2.654067521218675

Epoch: 218| Step: 0
Training loss: 2.7820459148531453
Validation loss: 2.545256743717477

Epoch: 6| Step: 1
Training loss: 2.542750945483662
Validation loss: 2.5885034885456157

Epoch: 6| Step: 2
Training loss: 2.422119620490106
Validation loss: 2.6462928150790055

Epoch: 6| Step: 3
Training loss: 3.3034915428370923
Validation loss: 2.6504035757327276

Epoch: 6| Step: 4
Training loss: 3.3135254909996386
Validation loss: 2.59958608269308

Epoch: 6| Step: 5
Training loss: 2.8786939027648337
Validation loss: 2.6567819138762734

Epoch: 6| Step: 6
Training loss: 2.270520413271486
Validation loss: 2.633687162739245

Epoch: 6| Step: 7
Training loss: 2.5269267520893446
Validation loss: 2.625344920313831

Epoch: 6| Step: 8
Training loss: 2.4182994413027465
Validation loss: 2.6851657613861817

Epoch: 6| Step: 9
Training loss: 2.4933589466159747
Validation loss: 2.6422440323339926

Epoch: 6| Step: 10
Training loss: 2.1087326767260213
Validation loss: 2.640249108214293

Epoch: 6| Step: 11
Training loss: 2.711262532298001
Validation loss: 2.685523720918331

Epoch: 6| Step: 12
Training loss: 2.165810660458473
Validation loss: 2.560749573600073

Epoch: 6| Step: 13
Training loss: 2.866174503335297
Validation loss: 2.6428774325002573

Epoch: 219| Step: 0
Training loss: 2.199517292472431
Validation loss: 2.6496676611387997

Epoch: 6| Step: 1
Training loss: 2.946646067200661
Validation loss: 2.6318258186511243

Epoch: 6| Step: 2
Training loss: 2.2801506842628485
Validation loss: 2.5849820409084168

Epoch: 6| Step: 3
Training loss: 1.6371010126816448
Validation loss: 2.6116288357018713

Epoch: 6| Step: 4
Training loss: 2.6704092187926904
Validation loss: 2.6510826136849697

Epoch: 6| Step: 5
Training loss: 2.3567342569171967
Validation loss: 2.6437985230392

Epoch: 6| Step: 6
Training loss: 2.5408953345734893
Validation loss: 2.6177712972321396

Epoch: 6| Step: 7
Training loss: 2.6345648211853865
Validation loss: 2.6478383266784697

Epoch: 6| Step: 8
Training loss: 2.0330385989884223
Validation loss: 2.5842460213566025

Epoch: 6| Step: 9
Training loss: 2.796998090539471
Validation loss: 2.6134852242648714

Epoch: 6| Step: 10
Training loss: 2.5193814491865116
Validation loss: 2.641615741280668

Epoch: 6| Step: 11
Training loss: 3.3946915249579868
Validation loss: 2.602529228690708

Epoch: 6| Step: 12
Training loss: 3.1858412970834937
Validation loss: 2.6684774114106355

Epoch: 6| Step: 13
Training loss: 3.162684764666611
Validation loss: 2.678417356233061

Epoch: 220| Step: 0
Training loss: 2.097991064192631
Validation loss: 2.67998224882817

Epoch: 6| Step: 1
Training loss: 2.253743554231436
Validation loss: 2.642273465712668

Epoch: 6| Step: 2
Training loss: 2.1888482434823127
Validation loss: 2.645249112752484

Epoch: 6| Step: 3
Training loss: 2.54258141446366
Validation loss: 2.6644299539140324

Epoch: 6| Step: 4
Training loss: 3.03771974373132
Validation loss: 2.596485528383324

Epoch: 6| Step: 5
Training loss: 2.7731045375341568
Validation loss: 2.631881353975852

Epoch: 6| Step: 6
Training loss: 2.7475266170861166
Validation loss: 2.6964274160486057

Epoch: 6| Step: 7
Training loss: 3.0825711588446456
Validation loss: 2.647574597766168

Epoch: 6| Step: 8
Training loss: 2.190649218024064
Validation loss: 2.610850945825559

Epoch: 6| Step: 9
Training loss: 3.0016230325388586
Validation loss: 2.6048258567738563

Epoch: 6| Step: 10
Training loss: 1.5347899953723374
Validation loss: 2.641756303130246

Epoch: 6| Step: 11
Training loss: 3.2743265405932855
Validation loss: 2.5972115533790316

Epoch: 6| Step: 12
Training loss: 2.653159643874871
Validation loss: 2.7081306974901085

Epoch: 6| Step: 13
Training loss: 2.526690108191353
Validation loss: 2.6693683661473244

Epoch: 221| Step: 0
Training loss: 2.361325701766747
Validation loss: 2.579364909766629

Epoch: 6| Step: 1
Training loss: 2.347886059980994
Validation loss: 2.6253906785501457

Epoch: 6| Step: 2
Training loss: 2.434252997145894
Validation loss: 2.5873796871479473

Epoch: 6| Step: 3
Training loss: 2.7056218781676846
Validation loss: 2.6376581103704293

Epoch: 6| Step: 4
Training loss: 2.302201925361709
Validation loss: 2.6202200865861665

Epoch: 6| Step: 5
Training loss: 2.354212285052744
Validation loss: 2.6278755827278575

Epoch: 6| Step: 6
Training loss: 2.734264262545609
Validation loss: 2.6299763810645813

Epoch: 6| Step: 7
Training loss: 2.626768152467752
Validation loss: 2.6959306809052213

Epoch: 6| Step: 8
Training loss: 2.654926104765467
Validation loss: 2.608496742341652

Epoch: 6| Step: 9
Training loss: 2.2109747030949563
Validation loss: 2.7028479518601802

Epoch: 6| Step: 10
Training loss: 2.59021278847536
Validation loss: 2.5907019268889075

Epoch: 6| Step: 11
Training loss: 2.612540694654456
Validation loss: 2.686745766957461

Epoch: 6| Step: 12
Training loss: 2.66939496503798
Validation loss: 2.652913068122509

Epoch: 6| Step: 13
Training loss: 3.74995765662129
Validation loss: 2.662312443164437

Epoch: 222| Step: 0
Training loss: 2.740217930696159
Validation loss: 2.5777683134371405

Epoch: 6| Step: 1
Training loss: 2.100335766425472
Validation loss: 2.569247564303875

Epoch: 6| Step: 2
Training loss: 2.081462159669844
Validation loss: 2.63007295045462

Epoch: 6| Step: 3
Training loss: 2.566647034937435
Validation loss: 2.7096763141355638

Epoch: 6| Step: 4
Training loss: 2.2627532648626283
Validation loss: 2.603270279869939

Epoch: 6| Step: 5
Training loss: 2.722000108683834
Validation loss: 2.697858524650198

Epoch: 6| Step: 6
Training loss: 3.2250069847327008
Validation loss: 2.603653376702512

Epoch: 6| Step: 7
Training loss: 2.418856407013245
Validation loss: 2.592257095133826

Epoch: 6| Step: 8
Training loss: 2.2302121951838743
Validation loss: 2.6540413811208907

Epoch: 6| Step: 9
Training loss: 3.0610681417333656
Validation loss: 2.5811779393240606

Epoch: 6| Step: 10
Training loss: 3.0588026499143495
Validation loss: 2.6467733195095717

Epoch: 6| Step: 11
Training loss: 2.1953002277723592
Validation loss: 2.5689868183202957

Epoch: 6| Step: 12
Training loss: 2.8251267868893093
Validation loss: 2.701822811659944

Epoch: 6| Step: 13
Training loss: 2.621535785542118
Validation loss: 2.660701115087302

Epoch: 223| Step: 0
Training loss: 2.535518579203201
Validation loss: 2.666070460637884

Epoch: 6| Step: 1
Training loss: 2.2429451011439414
Validation loss: 2.593223405644972

Epoch: 6| Step: 2
Training loss: 2.674463813735195
Validation loss: 2.6195872403676153

Epoch: 6| Step: 3
Training loss: 2.870031126431735
Validation loss: 2.639537972236617

Epoch: 6| Step: 4
Training loss: 2.2527548561335955
Validation loss: 2.6677705117016566

Epoch: 6| Step: 5
Training loss: 2.411958734542071
Validation loss: 2.635293318497138

Epoch: 6| Step: 6
Training loss: 2.795924787167356
Validation loss: 2.571457859350411

Epoch: 6| Step: 7
Training loss: 2.8215495009486737
Validation loss: 2.653377136102444

Epoch: 6| Step: 8
Training loss: 2.1209289599171246
Validation loss: 2.567768089156396

Epoch: 6| Step: 9
Training loss: 2.4803319698077595
Validation loss: 2.6545753889752564

Epoch: 6| Step: 10
Training loss: 2.338541779946464
Validation loss: 2.6584244901638097

Epoch: 6| Step: 11
Training loss: 2.988190134691381
Validation loss: 2.64371844170815

Epoch: 6| Step: 12
Training loss: 2.639555042800701
Validation loss: 2.6240818402436337

Epoch: 6| Step: 13
Training loss: 2.178163713633829
Validation loss: 2.6076830553208112

Epoch: 224| Step: 0
Training loss: 2.314215771057177
Validation loss: 2.618789165616187

Epoch: 6| Step: 1
Training loss: 2.3560786177336897
Validation loss: 2.6308098861222873

Epoch: 6| Step: 2
Training loss: 3.542981804904628
Validation loss: 2.593293278405884

Epoch: 6| Step: 3
Training loss: 2.400382579668932
Validation loss: 2.6640195519821406

Epoch: 6| Step: 4
Training loss: 2.5362916822472377
Validation loss: 2.6366074269143143

Epoch: 6| Step: 5
Training loss: 2.278585890208578
Validation loss: 2.635921325056258

Epoch: 6| Step: 6
Training loss: 2.5579423147919544
Validation loss: 2.63412475113573

Epoch: 6| Step: 7
Training loss: 2.44190170753857
Validation loss: 2.629034015148619

Epoch: 6| Step: 8
Training loss: 2.9200685189973963
Validation loss: 2.5825508737492338

Epoch: 6| Step: 9
Training loss: 2.657622577355911
Validation loss: 2.727616972388626

Epoch: 6| Step: 10
Training loss: 2.6910339895289863
Validation loss: 2.6171090552778855

Epoch: 6| Step: 11
Training loss: 2.7575934217714844
Validation loss: 2.604143359336329

Epoch: 6| Step: 12
Training loss: 2.1793181950807816
Validation loss: 2.6751684876601187

Epoch: 6| Step: 13
Training loss: 2.9020775817974758
Validation loss: 2.6303002483463565

Epoch: 225| Step: 0
Training loss: 2.6662665504052776
Validation loss: 2.597168582226866

Epoch: 6| Step: 1
Training loss: 2.796830331456326
Validation loss: 2.6645190976842503

Epoch: 6| Step: 2
Training loss: 2.648130686044609
Validation loss: 2.6194712186956473

Epoch: 6| Step: 3
Training loss: 2.6406821521239814
Validation loss: 2.6157028265269813

Epoch: 6| Step: 4
Training loss: 3.2348496830492492
Validation loss: 2.665508516434418

Epoch: 6| Step: 5
Training loss: 2.3607609196185853
Validation loss: 2.662960325976099

Epoch: 6| Step: 6
Training loss: 2.326695355272176
Validation loss: 2.6614468411346666

Epoch: 6| Step: 7
Training loss: 2.4997970498677176
Validation loss: 2.636068042233417

Epoch: 6| Step: 8
Training loss: 2.6702084167802687
Validation loss: 2.605742829494327

Epoch: 6| Step: 9
Training loss: 2.283137964211328
Validation loss: 2.6044804485332764

Epoch: 6| Step: 10
Training loss: 2.497148031458212
Validation loss: 2.6483482989284335

Epoch: 6| Step: 11
Training loss: 2.411992145114337
Validation loss: 2.7434203039383975

Epoch: 6| Step: 12
Training loss: 2.9445513240041894
Validation loss: 2.6490138784878763

Epoch: 6| Step: 13
Training loss: 2.4431566966985154
Validation loss: 2.551216151605457

Epoch: 226| Step: 0
Training loss: 2.283464898080411
Validation loss: 2.6615552239009257

Epoch: 6| Step: 1
Training loss: 2.7717309133760715
Validation loss: 2.6514394347168992

Epoch: 6| Step: 2
Training loss: 2.592097203922202
Validation loss: 2.644652974339204

Epoch: 6| Step: 3
Training loss: 3.044965096510113
Validation loss: 2.633383246644917

Epoch: 6| Step: 4
Training loss: 3.0556130336403102
Validation loss: 2.5999635572380018

Epoch: 6| Step: 5
Training loss: 2.294810087037986
Validation loss: 2.710192391753925

Epoch: 6| Step: 6
Training loss: 2.6073362872189
Validation loss: 2.6829467906862567

Epoch: 6| Step: 7
Training loss: 2.7952074588765643
Validation loss: 2.630094728033807

Epoch: 6| Step: 8
Training loss: 1.8930027409617818
Validation loss: 2.645219127111264

Epoch: 6| Step: 9
Training loss: 1.8919653436861879
Validation loss: 2.6326422772790963

Epoch: 6| Step: 10
Training loss: 2.860188853024111
Validation loss: 2.739549107366828

Epoch: 6| Step: 11
Training loss: 2.4851506779694295
Validation loss: 2.5905720723197327

Epoch: 6| Step: 12
Training loss: 2.526090284580995
Validation loss: 2.631499656833082

Epoch: 6| Step: 13
Training loss: 2.31990474110738
Validation loss: 2.6226694540457367

Epoch: 227| Step: 0
Training loss: 2.8010718542032564
Validation loss: 2.621797486153498

Epoch: 6| Step: 1
Training loss: 2.346811050376799
Validation loss: 2.633676649959096

Epoch: 6| Step: 2
Training loss: 2.255256869621204
Validation loss: 2.606241109903732

Epoch: 6| Step: 3
Training loss: 3.2190425702800054
Validation loss: 2.5907150285567737

Epoch: 6| Step: 4
Training loss: 2.615756517610886
Validation loss: 2.5814801938491065

Epoch: 6| Step: 5
Training loss: 2.7970899786989314
Validation loss: 2.6240253680285006

Epoch: 6| Step: 6
Training loss: 2.3886767657924683
Validation loss: 2.6871111016799483

Epoch: 6| Step: 7
Training loss: 2.6592607377246056
Validation loss: 2.6577923595914985

Epoch: 6| Step: 8
Training loss: 2.6195721594360464
Validation loss: 2.612071563159907

Epoch: 6| Step: 9
Training loss: 2.9209808776710138
Validation loss: 2.662938616447332

Epoch: 6| Step: 10
Training loss: 2.32248347281662
Validation loss: 2.569903198531648

Epoch: 6| Step: 11
Training loss: 2.3772885188601522
Validation loss: 2.656111040045526

Epoch: 6| Step: 12
Training loss: 2.958304570734315
Validation loss: 2.624367041386923

Epoch: 6| Step: 13
Training loss: 2.42036144583891
Validation loss: 2.6513976025317896

Epoch: 228| Step: 0
Training loss: 3.027848370241454
Validation loss: 2.6587457830721535

Epoch: 6| Step: 1
Training loss: 2.445072345092389
Validation loss: 2.6250873849976055

Epoch: 6| Step: 2
Training loss: 2.7479920425855098
Validation loss: 2.5608587724197975

Epoch: 6| Step: 3
Training loss: 2.484325864293974
Validation loss: 2.68703604258897

Epoch: 6| Step: 4
Training loss: 3.2506516610232903
Validation loss: 2.599405307020329

Epoch: 6| Step: 5
Training loss: 2.406257629382436
Validation loss: 2.6371422100439803

Epoch: 6| Step: 6
Training loss: 2.3590017869852824
Validation loss: 2.685242750680527

Epoch: 6| Step: 7
Training loss: 3.1529253076961155
Validation loss: 2.5934326930595426

Epoch: 6| Step: 8
Training loss: 2.3665692116815853
Validation loss: 2.5810540160607998

Epoch: 6| Step: 9
Training loss: 2.25935759689361
Validation loss: 2.6670065715747633

Epoch: 6| Step: 10
Training loss: 1.9509209976585993
Validation loss: 2.6160452708265343

Epoch: 6| Step: 11
Training loss: 2.192031091288575
Validation loss: 2.6760410447092142

Epoch: 6| Step: 12
Training loss: 2.596293110386241
Validation loss: 2.652812899296714

Epoch: 6| Step: 13
Training loss: 2.6159067236926754
Validation loss: 2.6552924643483387

Epoch: 229| Step: 0
Training loss: 2.6006664302343077
Validation loss: 2.6504727429296904

Epoch: 6| Step: 1
Training loss: 2.652231655083655
Validation loss: 2.6452498493056513

Epoch: 6| Step: 2
Training loss: 3.1006751340516585
Validation loss: 2.5626830469078143

Epoch: 6| Step: 3
Training loss: 2.027096654280372
Validation loss: 2.640615115796768

Epoch: 6| Step: 4
Training loss: 2.299653636726077
Validation loss: 2.640874761662642

Epoch: 6| Step: 5
Training loss: 1.8905324361541325
Validation loss: 2.6071044581188483

Epoch: 6| Step: 6
Training loss: 3.1372974284763187
Validation loss: 2.6162034372891916

Epoch: 6| Step: 7
Training loss: 1.9651295509050313
Validation loss: 2.665238079166048

Epoch: 6| Step: 8
Training loss: 2.775359183770272
Validation loss: 2.594009488238318

Epoch: 6| Step: 9
Training loss: 2.030779505305764
Validation loss: 2.5666026995464937

Epoch: 6| Step: 10
Training loss: 1.950704310453978
Validation loss: 2.610203350715064

Epoch: 6| Step: 11
Training loss: 3.086188429275843
Validation loss: 2.624066817383336

Epoch: 6| Step: 12
Training loss: 3.386109892466194
Validation loss: 2.6303308972328465

Epoch: 6| Step: 13
Training loss: 2.731109500300311
Validation loss: 2.6852706396605193

Epoch: 230| Step: 0
Training loss: 2.297967145082351
Validation loss: 2.681884922752712

Epoch: 6| Step: 1
Training loss: 2.0403447705061364
Validation loss: 2.625763317760537

Epoch: 6| Step: 2
Training loss: 2.2995555572666233
Validation loss: 2.6309023693268494

Epoch: 6| Step: 3
Training loss: 2.8544664619949223
Validation loss: 2.620201870548702

Epoch: 6| Step: 4
Training loss: 2.315934594754389
Validation loss: 2.6071179454204

Epoch: 6| Step: 5
Training loss: 3.347064220732115
Validation loss: 2.689135567683546

Epoch: 6| Step: 6
Training loss: 2.6490746015943025
Validation loss: 2.7204700470220633

Epoch: 6| Step: 7
Training loss: 2.9498692887653144
Validation loss: 2.6613547257989323

Epoch: 6| Step: 8
Training loss: 3.0183283098650504
Validation loss: 2.682495379614692

Epoch: 6| Step: 9
Training loss: 2.4209057252688813
Validation loss: 2.575556908237701

Epoch: 6| Step: 10
Training loss: 3.122861053874187
Validation loss: 2.6563101581321757

Epoch: 6| Step: 11
Training loss: 2.2946488368161604
Validation loss: 2.694416322199467

Epoch: 6| Step: 12
Training loss: 2.2366221405387945
Validation loss: 2.677358556113467

Epoch: 6| Step: 13
Training loss: 1.8106001400648235
Validation loss: 2.6045856937744856

Epoch: 231| Step: 0
Training loss: 2.633821107459395
Validation loss: 2.7002821272618966

Epoch: 6| Step: 1
Training loss: 2.4127294322599577
Validation loss: 2.626997326016506

Epoch: 6| Step: 2
Training loss: 2.6455564779577028
Validation loss: 2.614332118310203

Epoch: 6| Step: 3
Training loss: 1.947303029335309
Validation loss: 2.6754718857669473

Epoch: 6| Step: 4
Training loss: 3.3079693598037436
Validation loss: 2.5917190179152607

Epoch: 6| Step: 5
Training loss: 2.0115985723357293
Validation loss: 2.649408933112202

Epoch: 6| Step: 6
Training loss: 2.136312777432186
Validation loss: 2.65120395987462

Epoch: 6| Step: 7
Training loss: 3.006784397140685
Validation loss: 2.643885885956057

Epoch: 6| Step: 8
Training loss: 2.1738415055321574
Validation loss: 2.620288684710403

Epoch: 6| Step: 9
Training loss: 2.7053835920149747
Validation loss: 2.648914211613311

Epoch: 6| Step: 10
Training loss: 2.763815077451571
Validation loss: 2.6395722589393946

Epoch: 6| Step: 11
Training loss: 2.8497144589517376
Validation loss: 2.6316440789426245

Epoch: 6| Step: 12
Training loss: 2.5978589889458075
Validation loss: 2.6631192770213117

Epoch: 6| Step: 13
Training loss: 2.921425198290893
Validation loss: 2.655145737722297

Epoch: 232| Step: 0
Training loss: 3.0650191553211132
Validation loss: 2.611379518490285

Epoch: 6| Step: 1
Training loss: 3.262008782015357
Validation loss: 2.662402504227749

Epoch: 6| Step: 2
Training loss: 2.0480499389788496
Validation loss: 2.609965081266364

Epoch: 6| Step: 3
Training loss: 2.4882329579791818
Validation loss: 2.61499564536247

Epoch: 6| Step: 4
Training loss: 2.445302944956871
Validation loss: 2.598284741829466

Epoch: 6| Step: 5
Training loss: 3.1426312315859235
Validation loss: 2.563280148405336

Epoch: 6| Step: 6
Training loss: 2.7850317800136564
Validation loss: 2.6682382504345474

Epoch: 6| Step: 7
Training loss: 2.7936517480560283
Validation loss: 2.6060364860092364

Epoch: 6| Step: 8
Training loss: 2.487430061622317
Validation loss: 2.656240553238904

Epoch: 6| Step: 9
Training loss: 2.9566580815353674
Validation loss: 2.5660835018594295

Epoch: 6| Step: 10
Training loss: 1.969744476554632
Validation loss: 2.605360094509957

Epoch: 6| Step: 11
Training loss: 2.3899058338592245
Validation loss: 2.6760764664324106

Epoch: 6| Step: 12
Training loss: 2.6561512648239702
Validation loss: 2.6763266851596743

Epoch: 6| Step: 13
Training loss: 2.147178697275154
Validation loss: 2.590355662602782

Epoch: 233| Step: 0
Training loss: 3.0488933431625576
Validation loss: 2.6035287557303626

Epoch: 6| Step: 1
Training loss: 2.380253152126216
Validation loss: 2.61248971652781

Epoch: 6| Step: 2
Training loss: 2.688428407924398
Validation loss: 2.6408083049258737

Epoch: 6| Step: 3
Training loss: 2.5735437553070155
Validation loss: 2.6635537404358316

Epoch: 6| Step: 4
Training loss: 2.5340825938769895
Validation loss: 2.6087243979359256

Epoch: 6| Step: 5
Training loss: 2.6496007834532405
Validation loss: 2.679284606875558

Epoch: 6| Step: 6
Training loss: 1.6950395074251743
Validation loss: 2.6481750011656247

Epoch: 6| Step: 7
Training loss: 2.7116906606702504
Validation loss: 2.6321194793349507

Epoch: 6| Step: 8
Training loss: 2.2200062378804315
Validation loss: 2.656747496099639

Epoch: 6| Step: 9
Training loss: 3.0663533783260344
Validation loss: 2.582836806670389

Epoch: 6| Step: 10
Training loss: 3.135818979468852
Validation loss: 2.6493298700018326

Epoch: 6| Step: 11
Training loss: 2.0673334532959844
Validation loss: 2.5860365565573216

Epoch: 6| Step: 12
Training loss: 2.6959211021730303
Validation loss: 2.6711446544327004

Epoch: 6| Step: 13
Training loss: 2.283830515711139
Validation loss: 2.695814304563915

Epoch: 234| Step: 0
Training loss: 2.6155738524765058
Validation loss: 2.6041833502122254

Epoch: 6| Step: 1
Training loss: 2.771272399839346
Validation loss: 2.6694744259165475

Epoch: 6| Step: 2
Training loss: 2.1197316554117385
Validation loss: 2.6806280864588716

Epoch: 6| Step: 3
Training loss: 2.645644253760519
Validation loss: 2.6678932095288905

Epoch: 6| Step: 4
Training loss: 2.4923922176645483
Validation loss: 2.7160988275063307

Epoch: 6| Step: 5
Training loss: 1.8208777078186922
Validation loss: 2.638238370909754

Epoch: 6| Step: 6
Training loss: 2.8034801381514667
Validation loss: 2.641084960442041

Epoch: 6| Step: 7
Training loss: 2.4580438949973793
Validation loss: 2.5446480913129217

Epoch: 6| Step: 8
Training loss: 2.7914669667646232
Validation loss: 2.635271585824137

Epoch: 6| Step: 9
Training loss: 2.6720190176715324
Validation loss: 2.577359355001004

Epoch: 6| Step: 10
Training loss: 3.0414257912212586
Validation loss: 2.566949736086987

Epoch: 6| Step: 11
Training loss: 2.647510827810535
Validation loss: 2.5901525828006475

Epoch: 6| Step: 12
Training loss: 2.6228821703455534
Validation loss: 2.6748111742161567

Epoch: 6| Step: 13
Training loss: 2.0654893654572852
Validation loss: 2.606909262031466

Epoch: 235| Step: 0
Training loss: 1.8948041267118156
Validation loss: 2.6252251102241146

Epoch: 6| Step: 1
Training loss: 3.376330360718855
Validation loss: 2.6253546198375757

Epoch: 6| Step: 2
Training loss: 2.269901212651721
Validation loss: 2.553029835926223

Epoch: 6| Step: 3
Training loss: 2.7569841648403903
Validation loss: 2.657266289938542

Epoch: 6| Step: 4
Training loss: 2.2368584549604553
Validation loss: 2.5903535862391824

Epoch: 6| Step: 5
Training loss: 2.447586708286364
Validation loss: 2.6203506423999943

Epoch: 6| Step: 6
Training loss: 3.005025627801313
Validation loss: 2.5866733995079256

Epoch: 6| Step: 7
Training loss: 2.4666496710148813
Validation loss: 2.658252790554476

Epoch: 6| Step: 8
Training loss: 2.715208180070288
Validation loss: 2.591196790443437

Epoch: 6| Step: 9
Training loss: 2.75872260359663
Validation loss: 2.637119596297961

Epoch: 6| Step: 10
Training loss: 2.0276877050847366
Validation loss: 2.638002916436029

Epoch: 6| Step: 11
Training loss: 2.6062887980182734
Validation loss: 2.622799984215001

Epoch: 6| Step: 12
Training loss: 2.6860757646817857
Validation loss: 2.6282387874887223

Epoch: 6| Step: 13
Training loss: 2.3905988704275654
Validation loss: 2.6319868847152765

Epoch: 236| Step: 0
Training loss: 1.944894646191391
Validation loss: 2.677329643457453

Epoch: 6| Step: 1
Training loss: 1.9818939558390005
Validation loss: 2.666317085904522

Epoch: 6| Step: 2
Training loss: 2.5802642270008196
Validation loss: 2.6569403854456985

Epoch: 6| Step: 3
Training loss: 2.6875961641361767
Validation loss: 2.590074354605738

Epoch: 6| Step: 4
Training loss: 2.377271770349128
Validation loss: 2.6082137846465074

Epoch: 6| Step: 5
Training loss: 3.450538184164316
Validation loss: 2.6905949650976404

Epoch: 6| Step: 6
Training loss: 3.165174500775799
Validation loss: 2.580268441667899

Epoch: 6| Step: 7
Training loss: 2.6481369883320176
Validation loss: 2.6120837381280118

Epoch: 6| Step: 8
Training loss: 2.9665647796393855
Validation loss: 2.6417168849235977

Epoch: 6| Step: 9
Training loss: 2.7920105470878953
Validation loss: 2.624830688782311

Epoch: 6| Step: 10
Training loss: 2.6788789736075826
Validation loss: 2.6319132419615836

Epoch: 6| Step: 11
Training loss: 2.0683893448312682
Validation loss: 2.6876539704692415

Epoch: 6| Step: 12
Training loss: 1.461037861849769
Validation loss: 2.622410745848489

Epoch: 6| Step: 13
Training loss: 2.104745149566285
Validation loss: 2.613776404345703

Epoch: 237| Step: 0
Training loss: 2.571844600901089
Validation loss: 2.612691588004661

Epoch: 6| Step: 1
Training loss: 2.7311726155437333
Validation loss: 2.639872893904331

Epoch: 6| Step: 2
Training loss: 2.6397172620397704
Validation loss: 2.609409740016072

Epoch: 6| Step: 3
Training loss: 2.5676357627863333
Validation loss: 2.665347869796759

Epoch: 6| Step: 4
Training loss: 2.4406117847978686
Validation loss: 2.5739626688541457

Epoch: 6| Step: 5
Training loss: 2.7172345728248937
Validation loss: 2.658388113824971

Epoch: 6| Step: 6
Training loss: 2.463830706446877
Validation loss: 2.648646392023168

Epoch: 6| Step: 7
Training loss: 2.555056110818538
Validation loss: 2.635030017625064

Epoch: 6| Step: 8
Training loss: 2.4894901614664167
Validation loss: 2.6508090934626822

Epoch: 6| Step: 9
Training loss: 2.5003501646859227
Validation loss: 2.7332680163418996

Epoch: 6| Step: 10
Training loss: 2.51591793273966
Validation loss: 2.609482731841706

Epoch: 6| Step: 11
Training loss: 3.604004799326285
Validation loss: 2.631148999671812

Epoch: 6| Step: 12
Training loss: 2.3495678727566447
Validation loss: 2.651331551209086

Epoch: 6| Step: 13
Training loss: 1.4109104073628047
Validation loss: 2.6418158859146756

Epoch: 238| Step: 0
Training loss: 3.368867459487643
Validation loss: 2.565528674510283

Epoch: 6| Step: 1
Training loss: 2.49590586162597
Validation loss: 2.647525177322244

Epoch: 6| Step: 2
Training loss: 3.741402243012445
Validation loss: 2.666759527484114

Epoch: 6| Step: 3
Training loss: 2.635274488712585
Validation loss: 2.629592704223229

Epoch: 6| Step: 4
Training loss: 2.2831580138828373
Validation loss: 2.626346579684326

Epoch: 6| Step: 5
Training loss: 2.4667311513908823
Validation loss: 2.6839071116134114

Epoch: 6| Step: 6
Training loss: 2.9171934106293897
Validation loss: 2.6035533942569438

Epoch: 6| Step: 7
Training loss: 2.136869603050091
Validation loss: 2.663193747223232

Epoch: 6| Step: 8
Training loss: 2.116786341650647
Validation loss: 2.635243619092945

Epoch: 6| Step: 9
Training loss: 2.122562356668651
Validation loss: 2.6538773770906094

Epoch: 6| Step: 10
Training loss: 2.3487227519811333
Validation loss: 2.5955825916319855

Epoch: 6| Step: 11
Training loss: 2.385836024396655
Validation loss: 2.657760342253552

Epoch: 6| Step: 12
Training loss: 2.211447289670327
Validation loss: 2.5605744981863996

Epoch: 6| Step: 13
Training loss: 2.3019052036695404
Validation loss: 2.6445312451529395

Epoch: 239| Step: 0
Training loss: 2.4994599712758463
Validation loss: 2.638338376947582

Epoch: 6| Step: 1
Training loss: 2.706531120658376
Validation loss: 2.638241922560097

Epoch: 6| Step: 2
Training loss: 2.102133067222913
Validation loss: 2.5818930169065357

Epoch: 6| Step: 3
Training loss: 2.559380376900974
Validation loss: 2.6624021604706485

Epoch: 6| Step: 4
Training loss: 3.157694873006374
Validation loss: 2.661440341110745

Epoch: 6| Step: 5
Training loss: 2.4165471694166
Validation loss: 2.611473139416954

Epoch: 6| Step: 6
Training loss: 2.737111057886908
Validation loss: 2.6505529790274087

Epoch: 6| Step: 7
Training loss: 3.1867929310171164
Validation loss: 2.596643547007731

Epoch: 6| Step: 8
Training loss: 3.174984014275625
Validation loss: 2.659581980697487

Epoch: 6| Step: 9
Training loss: 2.1112840843724268
Validation loss: 2.6434611582952385

Epoch: 6| Step: 10
Training loss: 2.4961199214321437
Validation loss: 2.701715469250044

Epoch: 6| Step: 11
Training loss: 2.0252079232929048
Validation loss: 2.6281863034351507

Epoch: 6| Step: 12
Training loss: 2.723851120968108
Validation loss: 2.640414960245028

Epoch: 6| Step: 13
Training loss: 1.7441759607851457
Validation loss: 2.647114424601111

Epoch: 240| Step: 0
Training loss: 2.932653609185252
Validation loss: 2.614911447633989

Epoch: 6| Step: 1
Training loss: 2.3632791314233788
Validation loss: 2.564597519171025

Epoch: 6| Step: 2
Training loss: 2.827452184406049
Validation loss: 2.6525421713535398

Epoch: 6| Step: 3
Training loss: 2.534065470390917
Validation loss: 2.6021488377282407

Epoch: 6| Step: 4
Training loss: 3.04897576316141
Validation loss: 2.6546872207572023

Epoch: 6| Step: 5
Training loss: 2.5976008129657853
Validation loss: 2.645301485048101

Epoch: 6| Step: 6
Training loss: 2.2724689111377083
Validation loss: 2.6169443315368137

Epoch: 6| Step: 7
Training loss: 2.0137909817920945
Validation loss: 2.656160983114746

Epoch: 6| Step: 8
Training loss: 2.5782474373152127
Validation loss: 2.602831592221565

Epoch: 6| Step: 9
Training loss: 2.946652540141402
Validation loss: 2.6485203173351786

Epoch: 6| Step: 10
Training loss: 2.0873173068387834
Validation loss: 2.716486511835034

Epoch: 6| Step: 11
Training loss: 2.2548255037514906
Validation loss: 2.6074246260173104

Epoch: 6| Step: 12
Training loss: 2.813700949378192
Validation loss: 2.61575738595823

Epoch: 6| Step: 13
Training loss: 1.9809811623306854
Validation loss: 2.672877259673273

Epoch: 241| Step: 0
Training loss: 3.0605956404159795
Validation loss: 2.5926927155405757

Epoch: 6| Step: 1
Training loss: 2.8267311328458358
Validation loss: 2.6051359404855723

Epoch: 6| Step: 2
Training loss: 2.550486806141765
Validation loss: 2.692528073591084

Epoch: 6| Step: 3
Training loss: 1.9606410558576373
Validation loss: 2.695272656122903

Epoch: 6| Step: 4
Training loss: 2.8349123276167534
Validation loss: 2.6261066676410665

Epoch: 6| Step: 5
Training loss: 2.544954289473635
Validation loss: 2.6133801961635204

Epoch: 6| Step: 6
Training loss: 2.5629660950083983
Validation loss: 2.651888583556176

Epoch: 6| Step: 7
Training loss: 2.3639119969558524
Validation loss: 2.652666741985781

Epoch: 6| Step: 8
Training loss: 2.4169896227890435
Validation loss: 2.6578513677897755

Epoch: 6| Step: 9
Training loss: 2.6399058429226354
Validation loss: 2.6126855367775734

Epoch: 6| Step: 10
Training loss: 2.4575298634263976
Validation loss: 2.7299965732701255

Epoch: 6| Step: 11
Training loss: 2.355110508134105
Validation loss: 2.622429531625621

Epoch: 6| Step: 12
Training loss: 2.833891495721296
Validation loss: 2.602812727540816

Epoch: 6| Step: 13
Training loss: 2.6412131653296544
Validation loss: 2.656935539791245

Epoch: 242| Step: 0
Training loss: 3.02242528250375
Validation loss: 2.5386082219968187

Epoch: 6| Step: 1
Training loss: 2.2220053633205397
Validation loss: 2.62671153304859

Epoch: 6| Step: 2
Training loss: 2.788069689915443
Validation loss: 2.5884833606719497

Epoch: 6| Step: 3
Training loss: 2.0642290670454555
Validation loss: 2.693141854199088

Epoch: 6| Step: 4
Training loss: 2.16269086756181
Validation loss: 2.6418453065962653

Epoch: 6| Step: 5
Training loss: 2.3166308237866176
Validation loss: 2.5659277095785216

Epoch: 6| Step: 6
Training loss: 3.1189606864875645
Validation loss: 2.621565150226089

Epoch: 6| Step: 7
Training loss: 2.1001105415678003
Validation loss: 2.636656308181075

Epoch: 6| Step: 8
Training loss: 2.464577734568136
Validation loss: 2.588587021064647

Epoch: 6| Step: 9
Training loss: 2.7983229314971623
Validation loss: 2.637563910869331

Epoch: 6| Step: 10
Training loss: 2.218533142667638
Validation loss: 2.620381938413368

Epoch: 6| Step: 11
Training loss: 2.9061187386352394
Validation loss: 2.5730370615477

Epoch: 6| Step: 12
Training loss: 2.965181957148914
Validation loss: 2.6201858685485897

Epoch: 6| Step: 13
Training loss: 3.314148690534079
Validation loss: 2.6193820608123652

Epoch: 243| Step: 0
Training loss: 2.9685437582555076
Validation loss: 2.6167330361231222

Epoch: 6| Step: 1
Training loss: 2.438122009729245
Validation loss: 2.6085765772249236

Epoch: 6| Step: 2
Training loss: 2.371234820472663
Validation loss: 2.637927618462045

Epoch: 6| Step: 3
Training loss: 2.8245349670071693
Validation loss: 2.5934968635316182

Epoch: 6| Step: 4
Training loss: 2.5230347870051233
Validation loss: 2.637050700072914

Epoch: 6| Step: 5
Training loss: 3.1878640957992754
Validation loss: 2.5570600619589214

Epoch: 6| Step: 6
Training loss: 2.7113671745562664
Validation loss: 2.637207201854322

Epoch: 6| Step: 7
Training loss: 2.429136943689822
Validation loss: 2.66458402306843

Epoch: 6| Step: 8
Training loss: 2.0248987525777475
Validation loss: 2.667320333500052

Epoch: 6| Step: 9
Training loss: 3.067211808250673
Validation loss: 2.6681294271601557

Epoch: 6| Step: 10
Training loss: 2.2824191925017394
Validation loss: 2.670730122933014

Epoch: 6| Step: 11
Training loss: 2.646361761314357
Validation loss: 2.696364591357544

Epoch: 6| Step: 12
Training loss: 2.6585185517586982
Validation loss: 2.697187969473436

Epoch: 6| Step: 13
Training loss: 1.513931508101114
Validation loss: 2.6373317196514034

Epoch: 244| Step: 0
Training loss: 2.1025141153304
Validation loss: 2.6041260527038155

Epoch: 6| Step: 1
Training loss: 2.223014708778774
Validation loss: 2.555126218620654

Epoch: 6| Step: 2
Training loss: 2.4986129727750406
Validation loss: 2.625219459950307

Epoch: 6| Step: 3
Training loss: 2.8304983054841477
Validation loss: 2.6364989744144784

Epoch: 6| Step: 4
Training loss: 3.084272413470575
Validation loss: 2.6476524787486513

Epoch: 6| Step: 5
Training loss: 3.0096475923379997
Validation loss: 2.5573027895221117

Epoch: 6| Step: 6
Training loss: 2.4669797320637
Validation loss: 2.631961064936428

Epoch: 6| Step: 7
Training loss: 1.7617619883439444
Validation loss: 2.659650792567728

Epoch: 6| Step: 8
Training loss: 3.2024499693632085
Validation loss: 2.6476296052239654

Epoch: 6| Step: 9
Training loss: 2.2198232284824955
Validation loss: 2.599618014766613

Epoch: 6| Step: 10
Training loss: 2.5497214670089305
Validation loss: 2.608642048791818

Epoch: 6| Step: 11
Training loss: 2.3456466121679123
Validation loss: 2.590754263400657

Epoch: 6| Step: 12
Training loss: 2.513094179865243
Validation loss: 2.6094758842782193

Epoch: 6| Step: 13
Training loss: 2.3769803073052875
Validation loss: 2.633168688614524

Epoch: 245| Step: 0
Training loss: 2.6997670391035014
Validation loss: 2.58905131108834

Epoch: 6| Step: 1
Training loss: 2.361192117186553
Validation loss: 2.6582482944799146

Epoch: 6| Step: 2
Training loss: 2.4434546094549816
Validation loss: 2.570968130887023

Epoch: 6| Step: 3
Training loss: 2.6174616883542807
Validation loss: 2.6258154450705713

Epoch: 6| Step: 4
Training loss: 2.3781100539591216
Validation loss: 2.6259337511180703

Epoch: 6| Step: 5
Training loss: 2.9262401592703497
Validation loss: 2.63649592701925

Epoch: 6| Step: 6
Training loss: 2.89161838267651
Validation loss: 2.7164267718732886

Epoch: 6| Step: 7
Training loss: 2.224157486752884
Validation loss: 2.663187588380388

Epoch: 6| Step: 8
Training loss: 2.612672652238766
Validation loss: 2.6730632585224523

Epoch: 6| Step: 9
Training loss: 2.4025480850282275
Validation loss: 2.6871828257887365

Epoch: 6| Step: 10
Training loss: 2.8736947455285704
Validation loss: 2.632151404368676

Epoch: 6| Step: 11
Training loss: 2.1048436979857765
Validation loss: 2.5973251350095348

Epoch: 6| Step: 12
Training loss: 2.500244224063353
Validation loss: 2.661610325771595

Epoch: 6| Step: 13
Training loss: 2.476257883104604
Validation loss: 2.596452456876085

Epoch: 246| Step: 0
Training loss: 2.7616372534828355
Validation loss: 2.637372464139486

Epoch: 6| Step: 1
Training loss: 2.792397948938657
Validation loss: 2.5760144198156807

Epoch: 6| Step: 2
Training loss: 2.2232495741196585
Validation loss: 2.6062660119805297

Epoch: 6| Step: 3
Training loss: 1.8256601524429505
Validation loss: 2.6178046727977615

Epoch: 6| Step: 4
Training loss: 2.763404773974348
Validation loss: 2.6631964608445284

Epoch: 6| Step: 5
Training loss: 2.8408488471839517
Validation loss: 2.6405819212628954

Epoch: 6| Step: 6
Training loss: 2.6133804188430987
Validation loss: 2.5759283935904067

Epoch: 6| Step: 7
Training loss: 2.4237772700333307
Validation loss: 2.5808213935815405

Epoch: 6| Step: 8
Training loss: 2.8325531577284515
Validation loss: 2.563918925145815

Epoch: 6| Step: 9
Training loss: 2.580260992969432
Validation loss: 2.5707331756782468

Epoch: 6| Step: 10
Training loss: 2.2542290679511474
Validation loss: 2.5891648036437416

Epoch: 6| Step: 11
Training loss: 2.7553778862417384
Validation loss: 2.654620862580256

Epoch: 6| Step: 12
Training loss: 2.7709132782916517
Validation loss: 2.6227392891150445

Epoch: 6| Step: 13
Training loss: 1.532821238392722
Validation loss: 2.6479013597087233

Epoch: 247| Step: 0
Training loss: 2.6476561707569513
Validation loss: 2.551464663956078

Epoch: 6| Step: 1
Training loss: 2.3023162539846296
Validation loss: 2.640279731427474

Epoch: 6| Step: 2
Training loss: 3.0515732756706186
Validation loss: 2.5882266940281147

Epoch: 6| Step: 3
Training loss: 3.1039052422207654
Validation loss: 2.621928960258172

Epoch: 6| Step: 4
Training loss: 2.584450838943549
Validation loss: 2.6703810488390327

Epoch: 6| Step: 5
Training loss: 1.96025468709118
Validation loss: 2.5949008531795745

Epoch: 6| Step: 6
Training loss: 2.3257703714881943
Validation loss: 2.55603976744736

Epoch: 6| Step: 7
Training loss: 2.1743452994129293
Validation loss: 2.590153192495403

Epoch: 6| Step: 8
Training loss: 2.6958437188806808
Validation loss: 2.594793229252402

Epoch: 6| Step: 9
Training loss: 2.8858718972012016
Validation loss: 2.618553842049693

Epoch: 6| Step: 10
Training loss: 2.3994520197572586
Validation loss: 2.6189266924767494

Epoch: 6| Step: 11
Training loss: 2.214534569745007
Validation loss: 2.6015810002736472

Epoch: 6| Step: 12
Training loss: 3.0449575797698163
Validation loss: 2.568757217844594

Epoch: 6| Step: 13
Training loss: 2.086973811549631
Validation loss: 2.6026899447061203

Epoch: 248| Step: 0
Training loss: 2.605978942973389
Validation loss: 2.6745839505468028

Epoch: 6| Step: 1
Training loss: 2.5900234430496716
Validation loss: 2.636811119293802

Epoch: 6| Step: 2
Training loss: 2.1368624623174344
Validation loss: 2.645449096850349

Epoch: 6| Step: 3
Training loss: 2.411350541695778
Validation loss: 2.618517532053026

Epoch: 6| Step: 4
Training loss: 2.6563761961635692
Validation loss: 2.5979505640064056

Epoch: 6| Step: 5
Training loss: 2.784644123947204
Validation loss: 2.650137463140878

Epoch: 6| Step: 6
Training loss: 2.3987412648640785
Validation loss: 2.621700342052015

Epoch: 6| Step: 7
Training loss: 3.4657354228914206
Validation loss: 2.5805850754236577

Epoch: 6| Step: 8
Training loss: 2.3714466617898777
Validation loss: 2.605631491558879

Epoch: 6| Step: 9
Training loss: 2.725510708608884
Validation loss: 2.6391064502543764

Epoch: 6| Step: 10
Training loss: 1.7358747304423232
Validation loss: 2.5638263400243213

Epoch: 6| Step: 11
Training loss: 2.844870713284731
Validation loss: 2.5718599158456374

Epoch: 6| Step: 12
Training loss: 2.2624172258778827
Validation loss: 2.677831141616496

Epoch: 6| Step: 13
Training loss: 2.477514138282445
Validation loss: 2.6437101370972886

Epoch: 249| Step: 0
Training loss: 2.631838292844493
Validation loss: 2.653594855893723

Epoch: 6| Step: 1
Training loss: 2.315611215568421
Validation loss: 2.57114737928594

Epoch: 6| Step: 2
Training loss: 2.3436427791229733
Validation loss: 2.6328675558967785

Epoch: 6| Step: 3
Training loss: 3.0955960709506116
Validation loss: 2.6035784864788467

Epoch: 6| Step: 4
Training loss: 2.3175428924377157
Validation loss: 2.5407771028640016

Epoch: 6| Step: 5
Training loss: 3.734320348874421
Validation loss: 2.5889648862699777

Epoch: 6| Step: 6
Training loss: 2.9340693142952277
Validation loss: 2.5383315581113237

Epoch: 6| Step: 7
Training loss: 2.0534318343394817
Validation loss: 2.7042065747658346

Epoch: 6| Step: 8
Training loss: 1.970604764602772
Validation loss: 2.668693630300127

Epoch: 6| Step: 9
Training loss: 3.275129877674656
Validation loss: 2.6021905192945516

Epoch: 6| Step: 10
Training loss: 2.4388183549758056
Validation loss: 2.65317570402494

Epoch: 6| Step: 11
Training loss: 1.7829500083483236
Validation loss: 2.5901583095707297

Epoch: 6| Step: 12
Training loss: 2.585488640590037
Validation loss: 2.6095790831124446

Epoch: 6| Step: 13
Training loss: 2.2068822759801665
Validation loss: 2.6512439506439973

Epoch: 250| Step: 0
Training loss: 2.666281930666986
Validation loss: 2.684379555610016

Epoch: 6| Step: 1
Training loss: 2.557217433082497
Validation loss: 2.666372067255165

Epoch: 6| Step: 2
Training loss: 2.793192991844846
Validation loss: 2.6645030404799614

Epoch: 6| Step: 3
Training loss: 2.5416597668496785
Validation loss: 2.6480626997706374

Epoch: 6| Step: 4
Training loss: 2.692140786268809
Validation loss: 2.644821808533909

Epoch: 6| Step: 5
Training loss: 2.36679325660672
Validation loss: 2.5997571888605604

Epoch: 6| Step: 6
Training loss: 1.924553408156437
Validation loss: 2.6318294442192776

Epoch: 6| Step: 7
Training loss: 2.4963523002525743
Validation loss: 2.6441438484204665

Epoch: 6| Step: 8
Training loss: 2.1411858262546275
Validation loss: 2.6994882759539047

Epoch: 6| Step: 9
Training loss: 2.8232764733844284
Validation loss: 2.6198716039006475

Epoch: 6| Step: 10
Training loss: 2.732021256063943
Validation loss: 2.650058146059591

Epoch: 6| Step: 11
Training loss: 3.158350179689381
Validation loss: 2.632176412917871

Epoch: 6| Step: 12
Training loss: 2.5665543279792926
Validation loss: 2.620395796650232

Epoch: 6| Step: 13
Training loss: 1.8939522713888088
Validation loss: 2.628249171805558

Epoch: 251| Step: 0
Training loss: 3.0313351019485086
Validation loss: 2.6018759108095435

Epoch: 6| Step: 1
Training loss: 2.392266202562612
Validation loss: 2.6285701602027527

Epoch: 6| Step: 2
Training loss: 2.2005398781458285
Validation loss: 2.6196098224567996

Epoch: 6| Step: 3
Training loss: 3.455193499875518
Validation loss: 2.6073110895731846

Epoch: 6| Step: 4
Training loss: 2.4675889000922333
Validation loss: 2.6291296733141856

Epoch: 6| Step: 5
Training loss: 2.152316943103821
Validation loss: 2.5647924460035725

Epoch: 6| Step: 6
Training loss: 2.861312293311577
Validation loss: 2.646080444154832

Epoch: 6| Step: 7
Training loss: 2.9190155561972904
Validation loss: 2.627491941589829

Epoch: 6| Step: 8
Training loss: 2.572114724242114
Validation loss: 2.661147359262796

Epoch: 6| Step: 9
Training loss: 1.8306970353831673
Validation loss: 2.5997337105158254

Epoch: 6| Step: 10
Training loss: 2.2944133828282274
Validation loss: 2.653290537884129

Epoch: 6| Step: 11
Training loss: 2.778595589943526
Validation loss: 2.630784672610656

Epoch: 6| Step: 12
Training loss: 1.9369229103310193
Validation loss: 2.7310623668425142

Epoch: 6| Step: 13
Training loss: 1.9739004913417593
Validation loss: 2.6015242239016576

Epoch: 252| Step: 0
Training loss: 2.92026446830066
Validation loss: 2.6620185749954812

Epoch: 6| Step: 1
Training loss: 2.5447639187957662
Validation loss: 2.7109647927206675

Epoch: 6| Step: 2
Training loss: 2.8970447083178037
Validation loss: 2.616003541006616

Epoch: 6| Step: 3
Training loss: 1.8201292543311103
Validation loss: 2.656618100260463

Epoch: 6| Step: 4
Training loss: 2.1454932551352406
Validation loss: 2.615189004684475

Epoch: 6| Step: 5
Training loss: 3.33322869772396
Validation loss: 2.630367714215593

Epoch: 6| Step: 6
Training loss: 2.590289461611208
Validation loss: 2.6754511722492915

Epoch: 6| Step: 7
Training loss: 2.8566020590005756
Validation loss: 2.639402524624962

Epoch: 6| Step: 8
Training loss: 2.4035794189359176
Validation loss: 2.639443653825943

Epoch: 6| Step: 9
Training loss: 2.4625668899048936
Validation loss: 2.5471340490345526

Epoch: 6| Step: 10
Training loss: 2.405953327071899
Validation loss: 2.6303824262450033

Epoch: 6| Step: 11
Training loss: 2.4056936834713283
Validation loss: 2.590891714502772

Epoch: 6| Step: 12
Training loss: 2.7096618817253098
Validation loss: 2.6802633544484866

Epoch: 6| Step: 13
Training loss: 2.450884822739975
Validation loss: 2.6703220189436223

Epoch: 253| Step: 0
Training loss: 2.583272523061739
Validation loss: 2.639383550292946

Epoch: 6| Step: 1
Training loss: 2.5768108370849436
Validation loss: 2.631873879184014

Epoch: 6| Step: 2
Training loss: 2.353940046987606
Validation loss: 2.6466446410134905

Epoch: 6| Step: 3
Training loss: 2.007555043379201
Validation loss: 2.639397332072409

Epoch: 6| Step: 4
Training loss: 1.8007594043126525
Validation loss: 2.64256728088018

Epoch: 6| Step: 5
Training loss: 3.108146079578943
Validation loss: 2.560630933061853

Epoch: 6| Step: 6
Training loss: 2.6684675294995914
Validation loss: 2.591937630728154

Epoch: 6| Step: 7
Training loss: 2.1472011268482007
Validation loss: 2.6446634861394562

Epoch: 6| Step: 8
Training loss: 2.602408240145359
Validation loss: 2.577315082035074

Epoch: 6| Step: 9
Training loss: 3.366650036182182
Validation loss: 2.6239382251362975

Epoch: 6| Step: 10
Training loss: 2.666311975573456
Validation loss: 2.61495335713413

Epoch: 6| Step: 11
Training loss: 2.28823566801621
Validation loss: 2.675736731953894

Epoch: 6| Step: 12
Training loss: 2.178175535122043
Validation loss: 2.4845106186279757

Epoch: 6| Step: 13
Training loss: 2.4631579841625766
Validation loss: 2.6306444298576124

Epoch: 254| Step: 0
Training loss: 2.195919726685136
Validation loss: 2.588795622707839

Epoch: 6| Step: 1
Training loss: 2.3386825711649397
Validation loss: 2.6437882463422335

Epoch: 6| Step: 2
Training loss: 2.1023623848056974
Validation loss: 2.6462830605480683

Epoch: 6| Step: 3
Training loss: 2.2783016853208746
Validation loss: 2.5862156725458654

Epoch: 6| Step: 4
Training loss: 2.5472301399369517
Validation loss: 2.5820219144527825

Epoch: 6| Step: 5
Training loss: 2.725214146590207
Validation loss: 2.6594640609966675

Epoch: 6| Step: 6
Training loss: 2.7288223127009266
Validation loss: 2.61838334933599

Epoch: 6| Step: 7
Training loss: 2.791550837908463
Validation loss: 2.6219244546951392

Epoch: 6| Step: 8
Training loss: 2.490811150270091
Validation loss: 2.64569036536589

Epoch: 6| Step: 9
Training loss: 3.111709102047716
Validation loss: 2.5626691096639944

Epoch: 6| Step: 10
Training loss: 2.941555389230357
Validation loss: 2.6907895191811613

Epoch: 6| Step: 11
Training loss: 3.0556904348794034
Validation loss: 2.5847073677512213

Epoch: 6| Step: 12
Training loss: 1.81199849524025
Validation loss: 2.5639071019019943

Epoch: 6| Step: 13
Training loss: 2.661830291336758
Validation loss: 2.6035657478960808

Epoch: 255| Step: 0
Training loss: 2.5092616187451187
Validation loss: 2.6229949145329607

Epoch: 6| Step: 1
Training loss: 2.922600803904696
Validation loss: 2.6556615593894413

Epoch: 6| Step: 2
Training loss: 2.3930589838852705
Validation loss: 2.580965251452549

Epoch: 6| Step: 3
Training loss: 2.2414947396564897
Validation loss: 2.700600387789502

Epoch: 6| Step: 4
Training loss: 3.6026915396201877
Validation loss: 2.7331851912580363

Epoch: 6| Step: 5
Training loss: 2.4773263806155517
Validation loss: 2.545369258593676

Epoch: 6| Step: 6
Training loss: 2.2457054266898755
Validation loss: 2.6466972559393316

Epoch: 6| Step: 7
Training loss: 2.538576237992681
Validation loss: 2.5931456665259205

Epoch: 6| Step: 8
Training loss: 2.667481585995899
Validation loss: 2.6379710797107987

Epoch: 6| Step: 9
Training loss: 2.420670732912714
Validation loss: 2.603978349993407

Epoch: 6| Step: 10
Training loss: 2.3752830738221777
Validation loss: 2.71949746193212

Epoch: 6| Step: 11
Training loss: 2.6715756075692916
Validation loss: 2.659101606163717

Epoch: 6| Step: 12
Training loss: 2.0981459516627434
Validation loss: 2.607117296426735

Epoch: 6| Step: 13
Training loss: 2.105705403632523
Validation loss: 2.598396397523559

Epoch: 256| Step: 0
Training loss: 2.917905344650816
Validation loss: 2.667177511578419

Epoch: 6| Step: 1
Training loss: 2.0749451825358096
Validation loss: 2.5994862258658835

Epoch: 6| Step: 2
Training loss: 3.0985878773727347
Validation loss: 2.7232809551358836

Epoch: 6| Step: 3
Training loss: 1.9607993757380002
Validation loss: 2.6339007767494937

Epoch: 6| Step: 4
Training loss: 1.845642476372114
Validation loss: 2.649511579939557

Epoch: 6| Step: 5
Training loss: 2.377415081637607
Validation loss: 2.6215755678231583

Epoch: 6| Step: 6
Training loss: 2.7003795816136926
Validation loss: 2.622695232360451

Epoch: 6| Step: 7
Training loss: 2.396908151330185
Validation loss: 2.6018236615458306

Epoch: 6| Step: 8
Training loss: 2.348270177305533
Validation loss: 2.6553839316990318

Epoch: 6| Step: 9
Training loss: 2.396008382843077
Validation loss: 2.5841988659368873

Epoch: 6| Step: 10
Training loss: 3.2550224230765976
Validation loss: 2.6487450894910807

Epoch: 6| Step: 11
Training loss: 3.3547342582325914
Validation loss: 2.6439291406631655

Epoch: 6| Step: 12
Training loss: 2.2940201436549392
Validation loss: 2.5638786806985694

Epoch: 6| Step: 13
Training loss: 2.157051379791361
Validation loss: 2.5731540630361645

Epoch: 257| Step: 0
Training loss: 2.379689355500087
Validation loss: 2.599605266638402

Epoch: 6| Step: 1
Training loss: 2.3757698417572812
Validation loss: 2.600923476909549

Epoch: 6| Step: 2
Training loss: 2.676605231394384
Validation loss: 2.68414616490948

Epoch: 6| Step: 3
Training loss: 2.889670384495483
Validation loss: 2.602208508721478

Epoch: 6| Step: 4
Training loss: 2.663781114859263
Validation loss: 2.6349393746463865

Epoch: 6| Step: 5
Training loss: 1.778445126857836
Validation loss: 2.6509734662195763

Epoch: 6| Step: 6
Training loss: 2.5821483314273723
Validation loss: 2.605011282184629

Epoch: 6| Step: 7
Training loss: 2.4299320208299022
Validation loss: 2.606367195614363

Epoch: 6| Step: 8
Training loss: 1.6303461603598475
Validation loss: 2.5875253432494487

Epoch: 6| Step: 9
Training loss: 2.7413730553013975
Validation loss: 2.555251530747247

Epoch: 6| Step: 10
Training loss: 3.2901283403774366
Validation loss: 2.5270047833875906

Epoch: 6| Step: 11
Training loss: 2.4450110106425056
Validation loss: 2.6309092644125727

Epoch: 6| Step: 12
Training loss: 2.238299784159193
Validation loss: 2.628747293806777

Epoch: 6| Step: 13
Training loss: 2.6510956064868516
Validation loss: 2.684729588340074

Epoch: 258| Step: 0
Training loss: 2.368045462558551
Validation loss: 2.65455397351249

Epoch: 6| Step: 1
Training loss: 2.6541772272288147
Validation loss: 2.660735533751593

Epoch: 6| Step: 2
Training loss: 2.1754943548930177
Validation loss: 2.6437206410098804

Epoch: 6| Step: 3
Training loss: 2.071300112682688
Validation loss: 2.6426452851799134

Epoch: 6| Step: 4
Training loss: 2.2035242895731306
Validation loss: 2.5761111212483483

Epoch: 6| Step: 5
Training loss: 2.6080448620805035
Validation loss: 2.581188926142103

Epoch: 6| Step: 6
Training loss: 2.210921540219561
Validation loss: 2.574842691559568

Epoch: 6| Step: 7
Training loss: 2.938085943991807
Validation loss: 2.588412099233973

Epoch: 6| Step: 8
Training loss: 2.986042295939501
Validation loss: 2.587425822523929

Epoch: 6| Step: 9
Training loss: 2.9470148403284653
Validation loss: 2.599227458962532

Epoch: 6| Step: 10
Training loss: 2.4180742527341543
Validation loss: 2.652971112223427

Epoch: 6| Step: 11
Training loss: 2.195298381502087
Validation loss: 2.648421108136923

Epoch: 6| Step: 12
Training loss: 2.932185458512192
Validation loss: 2.622625106775244

Epoch: 6| Step: 13
Training loss: 2.6292934727706965
Validation loss: 2.6000668812109566

Epoch: 259| Step: 0
Training loss: 2.4769896129934006
Validation loss: 2.660959322255475

Epoch: 6| Step: 1
Training loss: 2.3881489016692803
Validation loss: 2.6407541543309496

Epoch: 6| Step: 2
Training loss: 2.8197851982554516
Validation loss: 2.706297008742048

Epoch: 6| Step: 3
Training loss: 3.36083243049315
Validation loss: 2.6287094340208523

Epoch: 6| Step: 4
Training loss: 2.6611069200288515
Validation loss: 2.5971389752633316

Epoch: 6| Step: 5
Training loss: 2.42001970661431
Validation loss: 2.6306885435152103

Epoch: 6| Step: 6
Training loss: 2.513593339026626
Validation loss: 2.5670830105944504

Epoch: 6| Step: 7
Training loss: 2.45107411953352
Validation loss: 2.6451826980733983

Epoch: 6| Step: 8
Training loss: 2.2011636430913066
Validation loss: 2.6524982563549786

Epoch: 6| Step: 9
Training loss: 2.3782364727667327
Validation loss: 2.6428428093946006

Epoch: 6| Step: 10
Training loss: 2.552934984585871
Validation loss: 2.6574318753161923

Epoch: 6| Step: 11
Training loss: 1.9894743751396142
Validation loss: 2.582880653973141

Epoch: 6| Step: 12
Training loss: 2.697698626059753
Validation loss: 2.673768857675721

Epoch: 6| Step: 13
Training loss: 2.09854771941697
Validation loss: 2.6795998386191826

Epoch: 260| Step: 0
Training loss: 3.588190173175339
Validation loss: 2.6173432755765726

Epoch: 6| Step: 1
Training loss: 1.7719725889750952
Validation loss: 2.535881214511584

Epoch: 6| Step: 2
Training loss: 2.6267040716047854
Validation loss: 2.6419174119844926

Epoch: 6| Step: 3
Training loss: 3.060270159395462
Validation loss: 2.5862487748383036

Epoch: 6| Step: 4
Training loss: 2.9507271856395443
Validation loss: 2.604053251360418

Epoch: 6| Step: 5
Training loss: 2.320020355431279
Validation loss: 2.5476946231305697

Epoch: 6| Step: 6
Training loss: 2.298269873340719
Validation loss: 2.6620776522653395

Epoch: 6| Step: 7
Training loss: 2.2250372765665287
Validation loss: 2.66672344942037

Epoch: 6| Step: 8
Training loss: 2.2810392935653394
Validation loss: 2.5698391102878837

Epoch: 6| Step: 9
Training loss: 2.3534878677694078
Validation loss: 2.664607024291741

Epoch: 6| Step: 10
Training loss: 2.3272469932314626
Validation loss: 2.660445942814284

Epoch: 6| Step: 11
Training loss: 2.6425724410103784
Validation loss: 2.6092565395519993

Epoch: 6| Step: 12
Training loss: 2.7160817349344857
Validation loss: 2.6303356369304987

Epoch: 6| Step: 13
Training loss: 2.44466120909966
Validation loss: 2.6534093097103453

Epoch: 261| Step: 0
Training loss: 2.1283048847819406
Validation loss: 2.606012860602258

Epoch: 6| Step: 1
Training loss: 2.547479382282714
Validation loss: 2.6542022310800473

Epoch: 6| Step: 2
Training loss: 3.7974966034864615
Validation loss: 2.603863228788211

Epoch: 6| Step: 3
Training loss: 2.227671350466877
Validation loss: 2.6165670933878493

Epoch: 6| Step: 4
Training loss: 2.37508412262357
Validation loss: 2.619837008484096

Epoch: 6| Step: 5
Training loss: 3.053300235213527
Validation loss: 2.6163207748108523

Epoch: 6| Step: 6
Training loss: 2.545067362165529
Validation loss: 2.6905880829023516

Epoch: 6| Step: 7
Training loss: 2.2210413961181055
Validation loss: 2.6601334570063813

Epoch: 6| Step: 8
Training loss: 2.8436000910221417
Validation loss: 2.5170599818411508

Epoch: 6| Step: 9
Training loss: 2.090713234537689
Validation loss: 2.6696986995061955

Epoch: 6| Step: 10
Training loss: 1.8549297634102102
Validation loss: 2.5828343679301637

Epoch: 6| Step: 11
Training loss: 2.6416396499680275
Validation loss: 2.567489222962951

Epoch: 6| Step: 12
Training loss: 2.466897680015483
Validation loss: 2.53257532642375

Epoch: 6| Step: 13
Training loss: 2.598387651085754
Validation loss: 2.5964372741535184

Epoch: 262| Step: 0
Training loss: 2.1497299468303726
Validation loss: 2.6027556805762253

Epoch: 6| Step: 1
Training loss: 2.050126383537503
Validation loss: 2.6724590437254196

Epoch: 6| Step: 2
Training loss: 2.153506427083058
Validation loss: 2.5658744105735565

Epoch: 6| Step: 3
Training loss: 2.58259417100909
Validation loss: 2.6402105113031893

Epoch: 6| Step: 4
Training loss: 2.936919296979441
Validation loss: 2.6380641855018023

Epoch: 6| Step: 5
Training loss: 2.848973434008388
Validation loss: 2.558426123523592

Epoch: 6| Step: 6
Training loss: 2.237601771251208
Validation loss: 2.5951790211960266

Epoch: 6| Step: 7
Training loss: 2.2444286244635356
Validation loss: 2.647185806370968

Epoch: 6| Step: 8
Training loss: 2.4015764701402187
Validation loss: 2.6440826998724143

Epoch: 6| Step: 9
Training loss: 2.4977049783744643
Validation loss: 2.6180585611289375

Epoch: 6| Step: 10
Training loss: 2.8242991160332456
Validation loss: 2.673951895259549

Epoch: 6| Step: 11
Training loss: 3.0705766637015364
Validation loss: 2.6129190704184833

Epoch: 6| Step: 12
Training loss: 2.95679096974154
Validation loss: 2.6251654370157076

Epoch: 6| Step: 13
Training loss: 2.337549068323501
Validation loss: 2.57919887278959

Epoch: 263| Step: 0
Training loss: 2.3085825963404423
Validation loss: 2.622484425717534

Epoch: 6| Step: 1
Training loss: 1.4085725466401275
Validation loss: 2.6440504253801453

Epoch: 6| Step: 2
Training loss: 2.9305286878305346
Validation loss: 2.630267555222326

Epoch: 6| Step: 3
Training loss: 2.550622534962187
Validation loss: 2.6844627347983745

Epoch: 6| Step: 4
Training loss: 3.503195938358535
Validation loss: 2.606372528725265

Epoch: 6| Step: 5
Training loss: 2.64201688480685
Validation loss: 2.6450736802984633

Epoch: 6| Step: 6
Training loss: 2.5538356655725694
Validation loss: 2.629053444471564

Epoch: 6| Step: 7
Training loss: 2.524390923340518
Validation loss: 2.5865188954776177

Epoch: 6| Step: 8
Training loss: 2.9811423804093873
Validation loss: 2.6119381981513756

Epoch: 6| Step: 9
Training loss: 2.0960840908173477
Validation loss: 2.562650628593732

Epoch: 6| Step: 10
Training loss: 2.0559509801995275
Validation loss: 2.617883157391097

Epoch: 6| Step: 11
Training loss: 1.8647613724539365
Validation loss: 2.655944698578381

Epoch: 6| Step: 12
Training loss: 2.734927661085545
Validation loss: 2.6214585251627374

Epoch: 6| Step: 13
Training loss: 2.490010329994927
Validation loss: 2.685034248178082

Epoch: 264| Step: 0
Training loss: 2.3624677787077073
Validation loss: 2.639894940241039

Epoch: 6| Step: 1
Training loss: 2.629797411756252
Validation loss: 2.6158257453553144

Epoch: 6| Step: 2
Training loss: 2.292890973047394
Validation loss: 2.6822332461659872

Epoch: 6| Step: 3
Training loss: 2.540371695227797
Validation loss: 2.6186633539644193

Epoch: 6| Step: 4
Training loss: 2.4376242190278052
Validation loss: 2.711941888949088

Epoch: 6| Step: 5
Training loss: 2.5561667543021445
Validation loss: 2.5852305273041467

Epoch: 6| Step: 6
Training loss: 2.6691529088217085
Validation loss: 2.6360582401412134

Epoch: 6| Step: 7
Training loss: 2.1461736785702237
Validation loss: 2.6305982952259197

Epoch: 6| Step: 8
Training loss: 2.7422362755244127
Validation loss: 2.6142715276675337

Epoch: 6| Step: 9
Training loss: 2.331854476490767
Validation loss: 2.6742968662435604

Epoch: 6| Step: 10
Training loss: 2.410597700499012
Validation loss: 2.647430517912516

Epoch: 6| Step: 11
Training loss: 3.139139763663056
Validation loss: 2.6004372529210578

Epoch: 6| Step: 12
Training loss: 2.024289574041109
Validation loss: 2.6205400637339684

Epoch: 6| Step: 13
Training loss: 2.258401232985492
Validation loss: 2.5890881665143115

Epoch: 265| Step: 0
Training loss: 2.3348110379006344
Validation loss: 2.654089423567085

Epoch: 6| Step: 1
Training loss: 2.441362206633975
Validation loss: 2.6036396577876215

Epoch: 6| Step: 2
Training loss: 1.7549265589114695
Validation loss: 2.5971841782111627

Epoch: 6| Step: 3
Training loss: 2.6988648818893846
Validation loss: 2.6262443345336526

Epoch: 6| Step: 4
Training loss: 2.0617806307174535
Validation loss: 2.637417371192626

Epoch: 6| Step: 5
Training loss: 2.798725560206384
Validation loss: 2.6160728063122916

Epoch: 6| Step: 6
Training loss: 2.57008031474685
Validation loss: 2.6051173827947633

Epoch: 6| Step: 7
Training loss: 3.155570986386152
Validation loss: 2.6851524589323943

Epoch: 6| Step: 8
Training loss: 2.3718032403878913
Validation loss: 2.677578815394664

Epoch: 6| Step: 9
Training loss: 3.365519878477796
Validation loss: 2.588681312792565

Epoch: 6| Step: 10
Training loss: 2.309575164338191
Validation loss: 2.6451447633864267

Epoch: 6| Step: 11
Training loss: 2.25167053514097
Validation loss: 2.64544369521646

Epoch: 6| Step: 12
Training loss: 2.507286420646814
Validation loss: 2.662350883354133

Epoch: 6| Step: 13
Training loss: 2.3160248775364916
Validation loss: 2.5976179084474076

Epoch: 266| Step: 0
Training loss: 2.8559249325672034
Validation loss: 2.561821454297107

Epoch: 6| Step: 1
Training loss: 2.0319653938530564
Validation loss: 2.546713045739804

Epoch: 6| Step: 2
Training loss: 2.3112665959572665
Validation loss: 2.682131475979043

Epoch: 6| Step: 3
Training loss: 2.7185953030476844
Validation loss: 2.5126714573330267

Epoch: 6| Step: 4
Training loss: 3.100077775779399
Validation loss: 2.610884153087517

Epoch: 6| Step: 5
Training loss: 2.098517725838979
Validation loss: 2.6671013791810196

Epoch: 6| Step: 6
Training loss: 2.0917445584975596
Validation loss: 2.578851492438004

Epoch: 6| Step: 7
Training loss: 3.066251986565551
Validation loss: 2.5478834255416203

Epoch: 6| Step: 8
Training loss: 2.728984380172027
Validation loss: 2.572741501815472

Epoch: 6| Step: 9
Training loss: 2.7548252601386
Validation loss: 2.6160409947326992

Epoch: 6| Step: 10
Training loss: 2.6305415379939494
Validation loss: 2.537996902441045

Epoch: 6| Step: 11
Training loss: 2.1393497873214207
Validation loss: 2.60339506929465

Epoch: 6| Step: 12
Training loss: 2.226356470045592
Validation loss: 2.631070709102393

Epoch: 6| Step: 13
Training loss: 2.0450486050078327
Validation loss: 2.6481475056642703

Epoch: 267| Step: 0
Training loss: 2.053880424235575
Validation loss: 2.65451032020036

Epoch: 6| Step: 1
Training loss: 2.100184219091238
Validation loss: 2.6252571093330848

Epoch: 6| Step: 2
Training loss: 2.2027108093938605
Validation loss: 2.674959631181976

Epoch: 6| Step: 3
Training loss: 3.4699144213234705
Validation loss: 2.6007484483622263

Epoch: 6| Step: 4
Training loss: 2.9453474695370994
Validation loss: 2.6772501801610655

Epoch: 6| Step: 5
Training loss: 2.2070154780271625
Validation loss: 2.506258982510156

Epoch: 6| Step: 6
Training loss: 2.6199587597404044
Validation loss: 2.633633188901898

Epoch: 6| Step: 7
Training loss: 2.4605343443022627
Validation loss: 2.580647300391182

Epoch: 6| Step: 8
Training loss: 2.120619128888337
Validation loss: 2.6292729648797626

Epoch: 6| Step: 9
Training loss: 2.622943072278275
Validation loss: 2.5611726307820994

Epoch: 6| Step: 10
Training loss: 2.514231420215612
Validation loss: 2.651145646939281

Epoch: 6| Step: 11
Training loss: 2.8173976216844325
Validation loss: 2.64735456134727

Epoch: 6| Step: 12
Training loss: 1.7456416626492481
Validation loss: 2.665656895215815

Epoch: 6| Step: 13
Training loss: 2.6498394971501082
Validation loss: 2.6640404515768465

Epoch: 268| Step: 0
Training loss: 2.042655381043701
Validation loss: 2.605975761512964

Epoch: 6| Step: 1
Training loss: 2.677818246942773
Validation loss: 2.6612364761980793

Epoch: 6| Step: 2
Training loss: 2.5704367935135544
Validation loss: 2.6261337476623927

Epoch: 6| Step: 3
Training loss: 3.2275575299679677
Validation loss: 2.659077944144967

Epoch: 6| Step: 4
Training loss: 2.67484274785239
Validation loss: 2.6925419070732586

Epoch: 6| Step: 5
Training loss: 2.5950166298217656
Validation loss: 2.6220508852070346

Epoch: 6| Step: 6
Training loss: 1.960613208719487
Validation loss: 2.6587731950061504

Epoch: 6| Step: 7
Training loss: 2.9019052166488097
Validation loss: 2.645536726983222

Epoch: 6| Step: 8
Training loss: 2.592137122512611
Validation loss: 2.5610835494762503

Epoch: 6| Step: 9
Training loss: 2.2419674861772476
Validation loss: 2.6238470646375323

Epoch: 6| Step: 10
Training loss: 2.4924116362707665
Validation loss: 2.6384045606736684

Epoch: 6| Step: 11
Training loss: 2.2238356640565824
Validation loss: 2.6009641727498622

Epoch: 6| Step: 12
Training loss: 2.8151691910358982
Validation loss: 2.591846835798127

Epoch: 6| Step: 13
Training loss: 2.2157630694457007
Validation loss: 2.6363563342611624

Epoch: 269| Step: 0
Training loss: 3.0861201365060698
Validation loss: 2.625612423813826

Epoch: 6| Step: 1
Training loss: 2.2059523384361466
Validation loss: 2.6156443200047383

Epoch: 6| Step: 2
Training loss: 2.166984265842889
Validation loss: 2.607984711233748

Epoch: 6| Step: 3
Training loss: 2.3004678664969775
Validation loss: 2.6218176213033457

Epoch: 6| Step: 4
Training loss: 2.487129555727131
Validation loss: 2.691187487268676

Epoch: 6| Step: 5
Training loss: 2.154549633149374
Validation loss: 2.6118801932747573

Epoch: 6| Step: 6
Training loss: 2.5633859731017345
Validation loss: 2.7349048744500113

Epoch: 6| Step: 7
Training loss: 2.271411530498458
Validation loss: 2.6318807500514487

Epoch: 6| Step: 8
Training loss: 2.7182111534978293
Validation loss: 2.567578265743828

Epoch: 6| Step: 9
Training loss: 3.23465686988867
Validation loss: 2.623732966659636

Epoch: 6| Step: 10
Training loss: 2.3581512511182643
Validation loss: 2.593153564614374

Epoch: 6| Step: 11
Training loss: 2.324069388583142
Validation loss: 2.5893359737225423

Epoch: 6| Step: 12
Training loss: 2.6204069007970174
Validation loss: 2.6837179840602396

Epoch: 6| Step: 13
Training loss: 2.0957941353723957
Validation loss: 2.6485918180190473

Epoch: 270| Step: 0
Training loss: 2.488740935450418
Validation loss: 2.6332821382562033

Epoch: 6| Step: 1
Training loss: 2.044974340077329
Validation loss: 2.57718758493359

Epoch: 6| Step: 2
Training loss: 2.656896534942167
Validation loss: 2.533430221202035

Epoch: 6| Step: 3
Training loss: 2.531126231240576
Validation loss: 2.5937049032541712

Epoch: 6| Step: 4
Training loss: 1.933387267522379
Validation loss: 2.638527891001977

Epoch: 6| Step: 5
Training loss: 2.313726666877437
Validation loss: 2.6219170128725753

Epoch: 6| Step: 6
Training loss: 3.1689108542521773
Validation loss: 2.6053272350386556

Epoch: 6| Step: 7
Training loss: 2.592269842807119
Validation loss: 2.6126294001111607

Epoch: 6| Step: 8
Training loss: 2.088219012850396
Validation loss: 2.6511633032149917

Epoch: 6| Step: 9
Training loss: 2.8224932832866045
Validation loss: 2.559856486889958

Epoch: 6| Step: 10
Training loss: 2.803109492808712
Validation loss: 2.5936024595824163

Epoch: 6| Step: 11
Training loss: 2.6288943694301103
Validation loss: 2.593562163218068

Epoch: 6| Step: 12
Training loss: 2.6293259352269787
Validation loss: 2.5926324497850173

Epoch: 6| Step: 13
Training loss: 2.3576052261768377
Validation loss: 2.6260363598076335

Epoch: 271| Step: 0
Training loss: 2.6317910043706045
Validation loss: 2.5530763349620575

Epoch: 6| Step: 1
Training loss: 3.140271219093627
Validation loss: 2.579137036317369

Epoch: 6| Step: 2
Training loss: 2.8171979027004364
Validation loss: 2.6458689563133695

Epoch: 6| Step: 3
Training loss: 2.418752022675844
Validation loss: 2.6087696477802638

Epoch: 6| Step: 4
Training loss: 1.5495249850981299
Validation loss: 2.6922006690019913

Epoch: 6| Step: 5
Training loss: 2.324963567304751
Validation loss: 2.5729029236894334

Epoch: 6| Step: 6
Training loss: 2.062640329846689
Validation loss: 2.5904658292182785

Epoch: 6| Step: 7
Training loss: 3.3521617006980664
Validation loss: 2.600951038928922

Epoch: 6| Step: 8
Training loss: 2.5588442148400343
Validation loss: 2.540548415139001

Epoch: 6| Step: 9
Training loss: 2.6895831706201894
Validation loss: 2.6629582166923815

Epoch: 6| Step: 10
Training loss: 2.839555602429209
Validation loss: 2.5807376613625936

Epoch: 6| Step: 11
Training loss: 2.2032241257897285
Validation loss: 2.6071282044154613

Epoch: 6| Step: 12
Training loss: 2.9126951880804475
Validation loss: 2.628013668121592

Epoch: 6| Step: 13
Training loss: 2.03527527093187
Validation loss: 2.660840359457158

Epoch: 272| Step: 0
Training loss: 2.433215753336049
Validation loss: 2.6246489335496936

Epoch: 6| Step: 1
Training loss: 1.613050393496883
Validation loss: 2.570102845053352

Epoch: 6| Step: 2
Training loss: 3.140088998784602
Validation loss: 2.610721714408623

Epoch: 6| Step: 3
Training loss: 3.6721141980766094
Validation loss: 2.6143556587317085

Epoch: 6| Step: 4
Training loss: 2.0062717804959416
Validation loss: 2.588696135962562

Epoch: 6| Step: 5
Training loss: 2.41231495834436
Validation loss: 2.640286537454752

Epoch: 6| Step: 6
Training loss: 2.4212245929194403
Validation loss: 2.6382454683753283

Epoch: 6| Step: 7
Training loss: 2.9888666514530984
Validation loss: 2.6320578527368874

Epoch: 6| Step: 8
Training loss: 1.3929833120974502
Validation loss: 2.6548919989691946

Epoch: 6| Step: 9
Training loss: 2.330501700157817
Validation loss: 2.6438942598293718

Epoch: 6| Step: 10
Training loss: 3.0684882027080844
Validation loss: 2.6532540785974437

Epoch: 6| Step: 11
Training loss: 1.8709755623269988
Validation loss: 2.7116151294774404

Epoch: 6| Step: 12
Training loss: 3.070237486410689
Validation loss: 2.63616842526884

Epoch: 6| Step: 13
Training loss: 2.0192745790864177
Validation loss: 2.6726975891317784

Epoch: 273| Step: 0
Training loss: 3.02677508519907
Validation loss: 2.6002152606242253

Epoch: 6| Step: 1
Training loss: 2.3986901762133437
Validation loss: 2.6272544204071315

Epoch: 6| Step: 2
Training loss: 2.511110602953624
Validation loss: 2.596267387878597

Epoch: 6| Step: 3
Training loss: 2.4254415523019333
Validation loss: 2.5988443661886

Epoch: 6| Step: 4
Training loss: 2.09368452282908
Validation loss: 2.6431822433117556

Epoch: 6| Step: 5
Training loss: 2.5890807441800714
Validation loss: 2.612266111475298

Epoch: 6| Step: 6
Training loss: 3.177202833252534
Validation loss: 2.6392987804222985

Epoch: 6| Step: 7
Training loss: 2.2359668956346432
Validation loss: 2.615213614720389

Epoch: 6| Step: 8
Training loss: 2.4974572602090803
Validation loss: 2.6435948764123554

Epoch: 6| Step: 9
Training loss: 2.7604504469238123
Validation loss: 2.6038432225999975

Epoch: 6| Step: 10
Training loss: 2.600910276843182
Validation loss: 2.548232858488535

Epoch: 6| Step: 11
Training loss: 2.122771272431638
Validation loss: 2.6473000091320134

Epoch: 6| Step: 12
Training loss: 2.5805866857794695
Validation loss: 2.6320574261221426

Epoch: 6| Step: 13
Training loss: 1.2880664098038825
Validation loss: 2.607144509772449

Epoch: 274| Step: 0
Training loss: 2.9938842106243815
Validation loss: 2.613556305259335

Epoch: 6| Step: 1
Training loss: 2.0576062955780774
Validation loss: 2.6667695926086683

Epoch: 6| Step: 2
Training loss: 2.2808419476663384
Validation loss: 2.6771793797534604

Epoch: 6| Step: 3
Training loss: 2.0776185300503776
Validation loss: 2.6990466611419963

Epoch: 6| Step: 4
Training loss: 2.9844568051615354
Validation loss: 2.6266178725802245

Epoch: 6| Step: 5
Training loss: 2.472160012347087
Validation loss: 2.610505801540944

Epoch: 6| Step: 6
Training loss: 2.640141279168315
Validation loss: 2.564332750324034

Epoch: 6| Step: 7
Training loss: 2.41689295092995
Validation loss: 2.6529869792840066

Epoch: 6| Step: 8
Training loss: 2.410515509589734
Validation loss: 2.622167719578516

Epoch: 6| Step: 9
Training loss: 2.74957324097892
Validation loss: 2.6793744935758337

Epoch: 6| Step: 10
Training loss: 2.380808703765034
Validation loss: 2.6540280144308683

Epoch: 6| Step: 11
Training loss: 2.321859030585224
Validation loss: 2.566321407123214

Epoch: 6| Step: 12
Training loss: 2.6884809965796164
Validation loss: 2.571671247791306

Epoch: 6| Step: 13
Training loss: 2.177517922083507
Validation loss: 2.587449807878143

Epoch: 275| Step: 0
Training loss: 2.6772399045130673
Validation loss: 2.6817317022521774

Epoch: 6| Step: 1
Training loss: 2.7836881944349785
Validation loss: 2.6446047943969755

Epoch: 6| Step: 2
Training loss: 2.118665116221727
Validation loss: 2.5804628771833067

Epoch: 6| Step: 3
Training loss: 1.9018308351461481
Validation loss: 2.653474921405636

Epoch: 6| Step: 4
Training loss: 1.8278217553230343
Validation loss: 2.6799436387184405

Epoch: 6| Step: 5
Training loss: 2.501614716727675
Validation loss: 2.5970656838925077

Epoch: 6| Step: 6
Training loss: 2.7297290678740596
Validation loss: 2.5789295550801863

Epoch: 6| Step: 7
Training loss: 2.464862128187725
Validation loss: 2.578921387774968

Epoch: 6| Step: 8
Training loss: 2.659492219343026
Validation loss: 2.6359556782532203

Epoch: 6| Step: 9
Training loss: 2.4238615686905067
Validation loss: 2.5683135838760194

Epoch: 6| Step: 10
Training loss: 3.2907743733439587
Validation loss: 2.6427890729862376

Epoch: 6| Step: 11
Training loss: 2.0005872579516413
Validation loss: 2.6235217518821674

Epoch: 6| Step: 12
Training loss: 2.678963521688399
Validation loss: 2.549371764463893

Epoch: 6| Step: 13
Training loss: 2.744537476864556
Validation loss: 2.6124241215725825

Epoch: 276| Step: 0
Training loss: 2.253531122311399
Validation loss: 2.623061159940866

Epoch: 6| Step: 1
Training loss: 2.6044158409437217
Validation loss: 2.5602682696447037

Epoch: 6| Step: 2
Training loss: 2.186587661133895
Validation loss: 2.5914317422187407

Epoch: 6| Step: 3
Training loss: 3.3497221190938338
Validation loss: 2.5510643685072987

Epoch: 6| Step: 4
Training loss: 1.988353075929757
Validation loss: 2.660615045280455

Epoch: 6| Step: 5
Training loss: 2.078341479964861
Validation loss: 2.6371403649437766

Epoch: 6| Step: 6
Training loss: 2.260636935657382
Validation loss: 2.601642477706875

Epoch: 6| Step: 7
Training loss: 3.657649367457694
Validation loss: 2.6498488109689453

Epoch: 6| Step: 8
Training loss: 2.4911588740394635
Validation loss: 2.575769686375693

Epoch: 6| Step: 9
Training loss: 2.1441539995412593
Validation loss: 2.622071183644994

Epoch: 6| Step: 10
Training loss: 2.651964388025685
Validation loss: 2.6421795045000307

Epoch: 6| Step: 11
Training loss: 2.1359594136071847
Validation loss: 2.6693607607904277

Epoch: 6| Step: 12
Training loss: 2.5257513344783935
Validation loss: 2.555648219155682

Epoch: 6| Step: 13
Training loss: 1.7222884081698215
Validation loss: 2.730022103944615

Epoch: 277| Step: 0
Training loss: 1.9640395716237005
Validation loss: 2.6133064440358242

Epoch: 6| Step: 1
Training loss: 2.310780685087348
Validation loss: 2.5529338669182966

Epoch: 6| Step: 2
Training loss: 3.001535976119957
Validation loss: 2.6525616000350873

Epoch: 6| Step: 3
Training loss: 2.9961632990318354
Validation loss: 2.5908133295238907

Epoch: 6| Step: 4
Training loss: 1.7833300709323217
Validation loss: 2.6067724465261137

Epoch: 6| Step: 5
Training loss: 2.2684452787529463
Validation loss: 2.6091735223665067

Epoch: 6| Step: 6
Training loss: 2.4098464049467077
Validation loss: 2.5356713312782326

Epoch: 6| Step: 7
Training loss: 2.5332040661741697
Validation loss: 2.5996119745264523

Epoch: 6| Step: 8
Training loss: 2.3291273583477157
Validation loss: 2.666515820669298

Epoch: 6| Step: 9
Training loss: 2.501015170930274
Validation loss: 2.602041765809393

Epoch: 6| Step: 10
Training loss: 3.0652397512537277
Validation loss: 2.59526583077857

Epoch: 6| Step: 11
Training loss: 2.4772058848573084
Validation loss: 2.5714764406238153

Epoch: 6| Step: 12
Training loss: 2.7216063654850386
Validation loss: 2.599608874028746

Epoch: 6| Step: 13
Training loss: 2.283500710731364
Validation loss: 2.5772632778350113

Epoch: 278| Step: 0
Training loss: 2.8281913454482717
Validation loss: 2.6837499544141465

Epoch: 6| Step: 1
Training loss: 2.6752486318391013
Validation loss: 2.600478613921934

Epoch: 6| Step: 2
Training loss: 2.3143739067072993
Validation loss: 2.601833205381572

Epoch: 6| Step: 3
Training loss: 2.82106967388603
Validation loss: 2.6772798664215927

Epoch: 6| Step: 4
Training loss: 2.384167195435294
Validation loss: 2.6669304938963188

Epoch: 6| Step: 5
Training loss: 2.977734112379875
Validation loss: 2.646137981269827

Epoch: 6| Step: 6
Training loss: 3.004530347026166
Validation loss: 2.5682385565363495

Epoch: 6| Step: 7
Training loss: 2.625930530375872
Validation loss: 2.6513261311014933

Epoch: 6| Step: 8
Training loss: 2.2741210539108456
Validation loss: 2.604173919339489

Epoch: 6| Step: 9
Training loss: 1.7091295976244254
Validation loss: 2.6164760532974496

Epoch: 6| Step: 10
Training loss: 2.2673986398402604
Validation loss: 2.5727137143098937

Epoch: 6| Step: 11
Training loss: 2.0701869710617467
Validation loss: 2.5838255434853394

Epoch: 6| Step: 12
Training loss: 2.6612379924741587
Validation loss: 2.6086279404075325

Epoch: 6| Step: 13
Training loss: 2.1772204147573198
Validation loss: 2.623135275994265

Epoch: 279| Step: 0
Training loss: 2.1314571112179737
Validation loss: 2.6341799255889273

Epoch: 6| Step: 1
Training loss: 2.2968000542486884
Validation loss: 2.675694698535441

Epoch: 6| Step: 2
Training loss: 2.7383613520291856
Validation loss: 2.6174964708939377

Epoch: 6| Step: 3
Training loss: 2.3753730079463065
Validation loss: 2.6451563907005657

Epoch: 6| Step: 4
Training loss: 2.3497309348100726
Validation loss: 2.5996498310685525

Epoch: 6| Step: 5
Training loss: 3.1179316117749547
Validation loss: 2.5729778359412103

Epoch: 6| Step: 6
Training loss: 2.2075689420378466
Validation loss: 2.5991731946507786

Epoch: 6| Step: 7
Training loss: 2.2860494840444194
Validation loss: 2.6500716440225482

Epoch: 6| Step: 8
Training loss: 3.2439999581465147
Validation loss: 2.6519043773396778

Epoch: 6| Step: 9
Training loss: 2.6833030398852498
Validation loss: 2.640204129892864

Epoch: 6| Step: 10
Training loss: 2.312736086779528
Validation loss: 2.571536750576164

Epoch: 6| Step: 11
Training loss: 2.2906086878176217
Validation loss: 2.5822342487247503

Epoch: 6| Step: 12
Training loss: 2.227201992355475
Validation loss: 2.551175247038341

Epoch: 6| Step: 13
Training loss: 2.8781081274741256
Validation loss: 2.574844376197838

Epoch: 280| Step: 0
Training loss: 2.289904755190005
Validation loss: 2.674471028825164

Epoch: 6| Step: 1
Training loss: 2.4559723675319654
Validation loss: 2.6540722417092217

Epoch: 6| Step: 2
Training loss: 2.735898884795399
Validation loss: 2.6294368373080723

Epoch: 6| Step: 3
Training loss: 2.4424855036388324
Validation loss: 2.6208197000183735

Epoch: 6| Step: 4
Training loss: 2.4222305529078834
Validation loss: 2.5719854064392402

Epoch: 6| Step: 5
Training loss: 1.6991553283782077
Validation loss: 2.695936361753445

Epoch: 6| Step: 6
Training loss: 2.3899249878288504
Validation loss: 2.5736989779961355

Epoch: 6| Step: 7
Training loss: 2.4407947476368332
Validation loss: 2.6313519717713096

Epoch: 6| Step: 8
Training loss: 2.490043363538279
Validation loss: 2.6406166361471044

Epoch: 6| Step: 9
Training loss: 2.36582761675377
Validation loss: 2.664097894304689

Epoch: 6| Step: 10
Training loss: 2.3919054977669587
Validation loss: 2.6088274014635653

Epoch: 6| Step: 11
Training loss: 3.388832427077361
Validation loss: 2.6013920250304254

Epoch: 6| Step: 12
Training loss: 1.745723471754503
Validation loss: 2.5833287627715276

Epoch: 6| Step: 13
Training loss: 2.99095841704669
Validation loss: 2.5692585352858064

Epoch: 281| Step: 0
Training loss: 2.617092757147083
Validation loss: 2.5568147565516894

Epoch: 6| Step: 1
Training loss: 2.6081220165448618
Validation loss: 2.619579531585603

Epoch: 6| Step: 2
Training loss: 2.3072217553241314
Validation loss: 2.571772219508647

Epoch: 6| Step: 3
Training loss: 2.0463381929681126
Validation loss: 2.574882293210755

Epoch: 6| Step: 4
Training loss: 2.489909120149815
Validation loss: 2.6085828856421216

Epoch: 6| Step: 5
Training loss: 2.860534932987926
Validation loss: 2.6092666407965326

Epoch: 6| Step: 6
Training loss: 2.666483117780277
Validation loss: 2.5755146134826066

Epoch: 6| Step: 7
Training loss: 1.932953823045224
Validation loss: 2.5378311531159254

Epoch: 6| Step: 8
Training loss: 3.056303645562226
Validation loss: 2.6311154596616975

Epoch: 6| Step: 9
Training loss: 2.7829841607945593
Validation loss: 2.6116437524355627

Epoch: 6| Step: 10
Training loss: 2.537232663959782
Validation loss: 2.6316081760555714

Epoch: 6| Step: 11
Training loss: 2.126313869227963
Validation loss: 2.5677572026605064

Epoch: 6| Step: 12
Training loss: 2.2673289238470837
Validation loss: 2.603400930399661

Epoch: 6| Step: 13
Training loss: 2.392867389242199
Validation loss: 2.574751000571798

Epoch: 282| Step: 0
Training loss: 2.6611236740095383
Validation loss: 2.644011590170546

Epoch: 6| Step: 1
Training loss: 1.6683610727225178
Validation loss: 2.56724154881229

Epoch: 6| Step: 2
Training loss: 1.9333489773654495
Validation loss: 2.600233188786294

Epoch: 6| Step: 3
Training loss: 3.486473785691352
Validation loss: 2.681602477576763

Epoch: 6| Step: 4
Training loss: 2.626075161139362
Validation loss: 2.6059376456623493

Epoch: 6| Step: 5
Training loss: 1.9101804017956459
Validation loss: 2.662984190320731

Epoch: 6| Step: 6
Training loss: 2.458172022381646
Validation loss: 2.670754902702193

Epoch: 6| Step: 7
Training loss: 2.851141744429093
Validation loss: 2.5104731806692717

Epoch: 6| Step: 8
Training loss: 2.4499273172613267
Validation loss: 2.617815867259194

Epoch: 6| Step: 9
Training loss: 2.630168549391002
Validation loss: 2.579553385807001

Epoch: 6| Step: 10
Training loss: 2.3850673325348906
Validation loss: 2.6422386736307786

Epoch: 6| Step: 11
Training loss: 2.6151644502939577
Validation loss: 2.593303098798381

Epoch: 6| Step: 12
Training loss: 2.605532346575554
Validation loss: 2.595326887848508

Epoch: 6| Step: 13
Training loss: 2.5668445137466867
Validation loss: 2.645594060800103

Epoch: 283| Step: 0
Training loss: 1.8424284126318768
Validation loss: 2.6687420401036968

Epoch: 6| Step: 1
Training loss: 2.670331453330877
Validation loss: 2.6861119979846357

Epoch: 6| Step: 2
Training loss: 2.8712051888980996
Validation loss: 2.5995597764051603

Epoch: 6| Step: 3
Training loss: 2.615786231391511
Validation loss: 2.5871440820012936

Epoch: 6| Step: 4
Training loss: 2.3066987136128767
Validation loss: 2.6213707199338976

Epoch: 6| Step: 5
Training loss: 1.9276983224885123
Validation loss: 2.6914625857445156

Epoch: 6| Step: 6
Training loss: 2.985319138021086
Validation loss: 2.6454995716496734

Epoch: 6| Step: 7
Training loss: 3.4187058357022257
Validation loss: 2.6036056974268216

Epoch: 6| Step: 8
Training loss: 1.8862377367069723
Validation loss: 2.551966318474446

Epoch: 6| Step: 9
Training loss: 2.758095097313799
Validation loss: 2.6591850395402297

Epoch: 6| Step: 10
Training loss: 2.6887748710726993
Validation loss: 2.5722939266271445

Epoch: 6| Step: 11
Training loss: 2.0646884751581007
Validation loss: 2.581558545428118

Epoch: 6| Step: 12
Training loss: 2.241436024917148
Validation loss: 2.5569067999716286

Epoch: 6| Step: 13
Training loss: 2.169637172092747
Validation loss: 2.66461286235874

Epoch: 284| Step: 0
Training loss: 2.6416484948464865
Validation loss: 2.633756207300252

Epoch: 6| Step: 1
Training loss: 2.2367028334754484
Validation loss: 2.674609388572506

Epoch: 6| Step: 2
Training loss: 1.9775210984909382
Validation loss: 2.6514487840081165

Epoch: 6| Step: 3
Training loss: 2.6280990653737186
Validation loss: 2.6383970613663825

Epoch: 6| Step: 4
Training loss: 2.4953895017128667
Validation loss: 2.566381634936165

Epoch: 6| Step: 5
Training loss: 1.7770059453191784
Validation loss: 2.6193887493737615

Epoch: 6| Step: 6
Training loss: 2.4183499185250623
Validation loss: 2.5688697298212517

Epoch: 6| Step: 7
Training loss: 2.66785954577246
Validation loss: 2.5518899219412976

Epoch: 6| Step: 8
Training loss: 2.939015423703421
Validation loss: 2.5976703340868874

Epoch: 6| Step: 9
Training loss: 2.753956029996672
Validation loss: 2.626824550102586

Epoch: 6| Step: 10
Training loss: 1.9279026317504668
Validation loss: 2.570724740002417

Epoch: 6| Step: 11
Training loss: 2.7642399827420814
Validation loss: 2.560749468481527

Epoch: 6| Step: 12
Training loss: 2.8125837525507227
Validation loss: 2.6529236679865944

Epoch: 6| Step: 13
Training loss: 1.5028375172253092
Validation loss: 2.6018235866611668

Epoch: 285| Step: 0
Training loss: 3.1808605982513307
Validation loss: 2.669074468025302

Epoch: 6| Step: 1
Training loss: 1.937628095760817
Validation loss: 2.619202928442188

Epoch: 6| Step: 2
Training loss: 2.046552210391814
Validation loss: 2.651034723694193

Epoch: 6| Step: 3
Training loss: 2.4253687116186238
Validation loss: 2.6984439178973236

Epoch: 6| Step: 4
Training loss: 3.3276842568710956
Validation loss: 2.6995450166303887

Epoch: 6| Step: 5
Training loss: 2.404420032957065
Validation loss: 2.677722216097947

Epoch: 6| Step: 6
Training loss: 2.346504322346336
Validation loss: 2.6219231063491413

Epoch: 6| Step: 7
Training loss: 2.363095110664122
Validation loss: 2.5790937863847754

Epoch: 6| Step: 8
Training loss: 2.0386287768709814
Validation loss: 2.5201844526313475

Epoch: 6| Step: 9
Training loss: 2.790032055304904
Validation loss: 2.594546854288474

Epoch: 6| Step: 10
Training loss: 2.741269993324271
Validation loss: 2.5775483064087474

Epoch: 6| Step: 11
Training loss: 2.1785892467976167
Validation loss: 2.488190636781744

Epoch: 6| Step: 12
Training loss: 2.5504225848230595
Validation loss: 2.5308669881783707

Epoch: 6| Step: 13
Training loss: 2.667343222704251
Validation loss: 2.5720048052218956

Epoch: 286| Step: 0
Training loss: 2.262123190340789
Validation loss: 2.605696004071904

Epoch: 6| Step: 1
Training loss: 2.9789363176262524
Validation loss: 2.6700020979305816

Epoch: 6| Step: 2
Training loss: 2.1538851388609954
Validation loss: 2.644099328058308

Epoch: 6| Step: 3
Training loss: 2.642137083252725
Validation loss: 2.5497743817610417

Epoch: 6| Step: 4
Training loss: 1.998402374650844
Validation loss: 2.6099421303812855

Epoch: 6| Step: 5
Training loss: 2.493641970022602
Validation loss: 2.5963203651045657

Epoch: 6| Step: 6
Training loss: 3.488320618478853
Validation loss: 2.597758659140905

Epoch: 6| Step: 7
Training loss: 2.274478634629749
Validation loss: 2.6018639462267275

Epoch: 6| Step: 8
Training loss: 3.363117776723668
Validation loss: 2.5715891047885244

Epoch: 6| Step: 9
Training loss: 2.572795375997269
Validation loss: 2.6784594770945094

Epoch: 6| Step: 10
Training loss: 2.2358628234548776
Validation loss: 2.5659764636204945

Epoch: 6| Step: 11
Training loss: 2.0626700360115082
Validation loss: 2.651438917916087

Epoch: 6| Step: 12
Training loss: 2.075296412978443
Validation loss: 2.521054952146566

Epoch: 6| Step: 13
Training loss: 1.5239364198302963
Validation loss: 2.6212964356498367

Epoch: 287| Step: 0
Training loss: 2.1994403300619294
Validation loss: 2.562325425382916

Epoch: 6| Step: 1
Training loss: 3.0269697979723738
Validation loss: 2.5485146184147336

Epoch: 6| Step: 2
Training loss: 2.770613056882541
Validation loss: 2.6056025848696893

Epoch: 6| Step: 3
Training loss: 2.9743931191396102
Validation loss: 2.567784720326317

Epoch: 6| Step: 4
Training loss: 2.1875906789241046
Validation loss: 2.5770722318941015

Epoch: 6| Step: 5
Training loss: 1.8624938324691758
Validation loss: 2.6271191816341686

Epoch: 6| Step: 6
Training loss: 2.4375780533251126
Validation loss: 2.625677965611052

Epoch: 6| Step: 7
Training loss: 2.6188105318998827
Validation loss: 2.6040512124997184

Epoch: 6| Step: 8
Training loss: 2.3577075649241235
Validation loss: 2.6566345486612897

Epoch: 6| Step: 9
Training loss: 2.222249454755284
Validation loss: 2.49924930048296

Epoch: 6| Step: 10
Training loss: 2.4952057645419874
Validation loss: 2.628442703149009

Epoch: 6| Step: 11
Training loss: 2.942735591975981
Validation loss: 2.560428546472214

Epoch: 6| Step: 12
Training loss: 2.228293084309171
Validation loss: 2.5397513506013585

Epoch: 6| Step: 13
Training loss: 2.0939108943325504
Validation loss: 2.6082201941978034

Epoch: 288| Step: 0
Training loss: 1.983214752541869
Validation loss: 2.6343415474242304

Epoch: 6| Step: 1
Training loss: 2.3275568736141437
Validation loss: 2.647107415802523

Epoch: 6| Step: 2
Training loss: 2.2419267562621967
Validation loss: 2.6254734915087807

Epoch: 6| Step: 3
Training loss: 2.2778582507031975
Validation loss: 2.601277322538304

Epoch: 6| Step: 4
Training loss: 2.1385480174251996
Validation loss: 2.588351888321562

Epoch: 6| Step: 5
Training loss: 2.337547742386669
Validation loss: 2.5965250028399276

Epoch: 6| Step: 6
Training loss: 2.670917808002199
Validation loss: 2.638492092473311

Epoch: 6| Step: 7
Training loss: 2.8836371010059243
Validation loss: 2.5772375603632054

Epoch: 6| Step: 8
Training loss: 3.1954247191480176
Validation loss: 2.5414807012727856

Epoch: 6| Step: 9
Training loss: 2.205769135804731
Validation loss: 2.6157147268290615

Epoch: 6| Step: 10
Training loss: 2.414176666621797
Validation loss: 2.5903768279568054

Epoch: 6| Step: 11
Training loss: 2.489883745229544
Validation loss: 2.6015934805426713

Epoch: 6| Step: 12
Training loss: 1.64431485816067
Validation loss: 2.6198142316630073

Epoch: 6| Step: 13
Training loss: 3.896505178907495
Validation loss: 2.596060251676263

Epoch: 289| Step: 0
Training loss: 2.0705877157136703
Validation loss: 2.655161700892459

Epoch: 6| Step: 1
Training loss: 2.334478018043806
Validation loss: 2.5944412704899764

Epoch: 6| Step: 2
Training loss: 2.6931939243678142
Validation loss: 2.592790668630284

Epoch: 6| Step: 3
Training loss: 2.082079688219085
Validation loss: 2.62244730254485

Epoch: 6| Step: 4
Training loss: 2.1330724983896423
Validation loss: 2.608215087985464

Epoch: 6| Step: 5
Training loss: 1.6256922201171908
Validation loss: 2.6608359130380497

Epoch: 6| Step: 6
Training loss: 2.665129417154196
Validation loss: 2.675938559047994

Epoch: 6| Step: 7
Training loss: 1.9649882633159625
Validation loss: 2.6219690533660036

Epoch: 6| Step: 8
Training loss: 2.5133854155199202
Validation loss: 2.624919341254963

Epoch: 6| Step: 9
Training loss: 2.2748570156228105
Validation loss: 2.552738168133975

Epoch: 6| Step: 10
Training loss: 3.0600799029022094
Validation loss: 2.5499116666334407

Epoch: 6| Step: 11
Training loss: 2.742692775853637
Validation loss: 2.7062320695277533

Epoch: 6| Step: 12
Training loss: 3.0655455723854557
Validation loss: 2.572524843293202

Epoch: 6| Step: 13
Training loss: 1.7475657562850913
Validation loss: 2.5916482905837137

Epoch: 290| Step: 0
Training loss: 2.4465590154818155
Validation loss: 2.6794147767042014

Epoch: 6| Step: 1
Training loss: 2.3823102578084216
Validation loss: 2.6546717240685416

Epoch: 6| Step: 2
Training loss: 2.327130098706854
Validation loss: 2.644973480158654

Epoch: 6| Step: 3
Training loss: 2.525601524993465
Validation loss: 2.6112149919450816

Epoch: 6| Step: 4
Training loss: 2.930803010284931
Validation loss: 2.5648427369152396

Epoch: 6| Step: 5
Training loss: 2.9026342069498643
Validation loss: 2.6215223196102735

Epoch: 6| Step: 6
Training loss: 2.823471202554195
Validation loss: 2.6269225440544224

Epoch: 6| Step: 7
Training loss: 2.37202849965721
Validation loss: 2.566971644714116

Epoch: 6| Step: 8
Training loss: 2.4067764697118617
Validation loss: 2.6584352001672915

Epoch: 6| Step: 9
Training loss: 1.985372157630358
Validation loss: 2.5747484715309663

Epoch: 6| Step: 10
Training loss: 2.469287379242319
Validation loss: 2.574030943051362

Epoch: 6| Step: 11
Training loss: 3.0728187329909833
Validation loss: 2.612772964706755

Epoch: 6| Step: 12
Training loss: 1.1443145859343187
Validation loss: 2.543825446822519

Epoch: 6| Step: 13
Training loss: 3.0454721204439497
Validation loss: 2.5603167769952564

Epoch: 291| Step: 0
Training loss: 2.1160890326707555
Validation loss: 2.644755993802233

Epoch: 6| Step: 1
Training loss: 2.274428528493605
Validation loss: 2.637842532595447

Epoch: 6| Step: 2
Training loss: 1.9978708616647163
Validation loss: 2.754127069907561

Epoch: 6| Step: 3
Training loss: 2.726039891041367
Validation loss: 2.635481386185655

Epoch: 6| Step: 4
Training loss: 2.8900446128701685
Validation loss: 2.6478909430579107

Epoch: 6| Step: 5
Training loss: 1.875723127158126
Validation loss: 2.604389381647458

Epoch: 6| Step: 6
Training loss: 2.1528331940877727
Validation loss: 2.588224936879082

Epoch: 6| Step: 7
Training loss: 2.2958402833181464
Validation loss: 2.5944400615148173

Epoch: 6| Step: 8
Training loss: 3.2881497455384348
Validation loss: 2.6020163434878403

Epoch: 6| Step: 9
Training loss: 2.2702659691428653
Validation loss: 2.6520743308657924

Epoch: 6| Step: 10
Training loss: 2.0235966800246987
Validation loss: 2.5989267515548446

Epoch: 6| Step: 11
Training loss: 3.03506324262259
Validation loss: 2.643307884972209

Epoch: 6| Step: 12
Training loss: 2.4608772391555513
Validation loss: 2.6498830716477255

Epoch: 6| Step: 13
Training loss: 2.6597814982166517
Validation loss: 2.563193742799267

Epoch: 292| Step: 0
Training loss: 1.7836314561210924
Validation loss: 2.561298553915103

Epoch: 6| Step: 1
Training loss: 2.3496933919673184
Validation loss: 2.6766571185087114

Epoch: 6| Step: 2
Training loss: 2.949537570722488
Validation loss: 2.68826649508102

Epoch: 6| Step: 3
Training loss: 2.2188434849776217
Validation loss: 2.551055705997614

Epoch: 6| Step: 4
Training loss: 2.5547811975124377
Validation loss: 2.641203271679917

Epoch: 6| Step: 5
Training loss: 3.1174135819290805
Validation loss: 2.6795862588275807

Epoch: 6| Step: 6
Training loss: 2.466298491691967
Validation loss: 2.6007720545619537

Epoch: 6| Step: 7
Training loss: 1.9797327603990005
Validation loss: 2.5447273190415136

Epoch: 6| Step: 8
Training loss: 2.4926226484145
Validation loss: 2.573625479311722

Epoch: 6| Step: 9
Training loss: 1.980065840869095
Validation loss: 2.595513201269568

Epoch: 6| Step: 10
Training loss: 1.8509157234184797
Validation loss: 2.6200081345968016

Epoch: 6| Step: 11
Training loss: 2.5070135917766834
Validation loss: 2.603242817741931

Epoch: 6| Step: 12
Training loss: 2.7490915185008857
Validation loss: 2.6952648841678886

Epoch: 6| Step: 13
Training loss: 3.4480578498324266
Validation loss: 2.598990973791392

Epoch: 293| Step: 0
Training loss: 2.434274544559133
Validation loss: 2.6087856500348545

Epoch: 6| Step: 1
Training loss: 2.668568310594298
Validation loss: 2.61579424047075

Epoch: 6| Step: 2
Training loss: 2.382417139491779
Validation loss: 2.5858154367204174

Epoch: 6| Step: 3
Training loss: 2.5690677492705007
Validation loss: 2.5622193837878586

Epoch: 6| Step: 4
Training loss: 2.639662166422862
Validation loss: 2.5950932578383115

Epoch: 6| Step: 5
Training loss: 2.220844408571875
Validation loss: 2.5935618815060537

Epoch: 6| Step: 6
Training loss: 2.046000519529633
Validation loss: 2.5583378735017974

Epoch: 6| Step: 7
Training loss: 3.043728029771035
Validation loss: 2.6651563430759557

Epoch: 6| Step: 8
Training loss: 2.186331736725398
Validation loss: 2.548821250269137

Epoch: 6| Step: 9
Training loss: 2.5125588633156393
Validation loss: 2.6407693550528624

Epoch: 6| Step: 10
Training loss: 2.4312072122530264
Validation loss: 2.5955147391493543

Epoch: 6| Step: 11
Training loss: 1.7629393009808565
Validation loss: 2.5940356669914943

Epoch: 6| Step: 12
Training loss: 2.6192398450748704
Validation loss: 2.6521229463948695

Epoch: 6| Step: 13
Training loss: 2.6879667719535645
Validation loss: 2.656321707619609

Epoch: 294| Step: 0
Training loss: 1.8172635588140769
Validation loss: 2.6677312261019246

Epoch: 6| Step: 1
Training loss: 2.7572101226919665
Validation loss: 2.5918841489918933

Epoch: 6| Step: 2
Training loss: 2.670967170904906
Validation loss: 2.6148730228124712

Epoch: 6| Step: 3
Training loss: 2.6635340728671406
Validation loss: 2.561049035818511

Epoch: 6| Step: 4
Training loss: 2.689344438560503
Validation loss: 2.6832588386729856

Epoch: 6| Step: 5
Training loss: 3.1826523962938156
Validation loss: 2.6276014663716727

Epoch: 6| Step: 6
Training loss: 2.510802960782374
Validation loss: 2.5644022986044694

Epoch: 6| Step: 7
Training loss: 2.3434634224210416
Validation loss: 2.610714322156159

Epoch: 6| Step: 8
Training loss: 2.383018609810286
Validation loss: 2.63872991466953

Epoch: 6| Step: 9
Training loss: 2.121652996601537
Validation loss: 2.6212383689025534

Epoch: 6| Step: 10
Training loss: 2.187113591534324
Validation loss: 2.5145932675872675

Epoch: 6| Step: 11
Training loss: 1.8116247760570159
Validation loss: 2.579165295344693

Epoch: 6| Step: 12
Training loss: 2.4221266092839504
Validation loss: 2.618860780060175

Epoch: 6| Step: 13
Training loss: 2.8130569754213215
Validation loss: 2.643579976077313

Epoch: 295| Step: 0
Training loss: 2.840510608816455
Validation loss: 2.6448432233162134

Epoch: 6| Step: 1
Training loss: 2.0740716167213376
Validation loss: 2.638986071027877

Epoch: 6| Step: 2
Training loss: 2.5547681323284386
Validation loss: 2.6514824951349225

Epoch: 6| Step: 3
Training loss: 2.535705318857223
Validation loss: 2.568412304030322

Epoch: 6| Step: 4
Training loss: 1.400825932944813
Validation loss: 2.606918726278285

Epoch: 6| Step: 5
Training loss: 2.1190303650751092
Validation loss: 2.6293473250892037

Epoch: 6| Step: 6
Training loss: 2.040985253213018
Validation loss: 2.638788656444345

Epoch: 6| Step: 7
Training loss: 2.347513457920876
Validation loss: 2.559475291873655

Epoch: 6| Step: 8
Training loss: 2.8401755200802787
Validation loss: 2.55930875988747

Epoch: 6| Step: 9
Training loss: 2.878414117165044
Validation loss: 2.615828778609032

Epoch: 6| Step: 10
Training loss: 2.1030320485675547
Validation loss: 2.6322762392404075

Epoch: 6| Step: 11
Training loss: 2.627140625569197
Validation loss: 2.5731157957568063

Epoch: 6| Step: 12
Training loss: 2.0199412182479475
Validation loss: 2.6524335899242044

Epoch: 6| Step: 13
Training loss: 3.1082026893085186
Validation loss: 2.582861829183306

Epoch: 296| Step: 0
Training loss: 2.390507115468181
Validation loss: 2.6575947358617023

Epoch: 6| Step: 1
Training loss: 1.7860121396838669
Validation loss: 2.5826653646708015

Epoch: 6| Step: 2
Training loss: 3.043888447646179
Validation loss: 2.6267492849941574

Epoch: 6| Step: 3
Training loss: 1.6189536066034977
Validation loss: 2.6252397241233867

Epoch: 6| Step: 4
Training loss: 2.93806289798726
Validation loss: 2.5734589983147886

Epoch: 6| Step: 5
Training loss: 2.3081912546696697
Validation loss: 2.6283574994575143

Epoch: 6| Step: 6
Training loss: 2.3701261403119434
Validation loss: 2.5765788891790176

Epoch: 6| Step: 7
Training loss: 2.4778025317511765
Validation loss: 2.5876288300041757

Epoch: 6| Step: 8
Training loss: 2.0372874985793428
Validation loss: 2.631605436680734

Epoch: 6| Step: 9
Training loss: 2.745669162533143
Validation loss: 2.5824712533187406

Epoch: 6| Step: 10
Training loss: 2.5522883637779294
Validation loss: 2.5101852807342206

Epoch: 6| Step: 11
Training loss: 2.656245422359337
Validation loss: 2.62291222368594

Epoch: 6| Step: 12
Training loss: 2.508924196255956
Validation loss: 2.636525280659395

Epoch: 6| Step: 13
Training loss: 2.3174840468564355
Validation loss: 2.6210353970689586

Epoch: 297| Step: 0
Training loss: 2.867884912307197
Validation loss: 2.719696190503313

Epoch: 6| Step: 1
Training loss: 2.752756731081393
Validation loss: 2.66398885955521

Epoch: 6| Step: 2
Training loss: 2.1415790742805845
Validation loss: 2.656102251049171

Epoch: 6| Step: 3
Training loss: 2.6400023860631623
Validation loss: 2.55523606308513

Epoch: 6| Step: 4
Training loss: 1.6725006358967984
Validation loss: 2.5916753888927264

Epoch: 6| Step: 5
Training loss: 2.730499573016522
Validation loss: 2.623124772723114

Epoch: 6| Step: 6
Training loss: 2.459721146572612
Validation loss: 2.6869873808564653

Epoch: 6| Step: 7
Training loss: 3.1684756549600026
Validation loss: 2.611715123056563

Epoch: 6| Step: 8
Training loss: 2.1754145698510468
Validation loss: 2.6454087112782094

Epoch: 6| Step: 9
Training loss: 1.864919905591782
Validation loss: 2.602205644805153

Epoch: 6| Step: 10
Training loss: 2.547834531552412
Validation loss: 2.5971393187747456

Epoch: 6| Step: 11
Training loss: 2.204897877410832
Validation loss: 2.646478462068842

Epoch: 6| Step: 12
Training loss: 2.131393911028012
Validation loss: 2.611979355440581

Epoch: 6| Step: 13
Training loss: 2.3395638274559807
Validation loss: 2.646869604414163

Epoch: 298| Step: 0
Training loss: 2.0919685186493653
Validation loss: 2.6225129498386144

Epoch: 6| Step: 1
Training loss: 2.19653536041856
Validation loss: 2.674394593126426

Epoch: 6| Step: 2
Training loss: 2.765539997755775
Validation loss: 2.59238692166691

Epoch: 6| Step: 3
Training loss: 2.3541482795289843
Validation loss: 2.585145392856688

Epoch: 6| Step: 4
Training loss: 3.3016804029117037
Validation loss: 2.6042700988574006

Epoch: 6| Step: 5
Training loss: 2.37914917555847
Validation loss: 2.621589613373575

Epoch: 6| Step: 6
Training loss: 1.9355003743980634
Validation loss: 2.593915432693676

Epoch: 6| Step: 7
Training loss: 2.5235343418494245
Validation loss: 2.5076972843722354

Epoch: 6| Step: 8
Training loss: 2.275173507613451
Validation loss: 2.5504565658027163

Epoch: 6| Step: 9
Training loss: 1.9759835462078204
Validation loss: 2.5880707567691754

Epoch: 6| Step: 10
Training loss: 2.138922689701985
Validation loss: 2.6494060021672343

Epoch: 6| Step: 11
Training loss: 3.0595421033350854
Validation loss: 2.545013698315617

Epoch: 6| Step: 12
Training loss: 2.4480651377569944
Validation loss: 2.628080136244926

Epoch: 6| Step: 13
Training loss: 2.7727330132437804
Validation loss: 2.6172397011412127

Epoch: 299| Step: 0
Training loss: 2.5081178473326164
Validation loss: 2.62919216664006

Epoch: 6| Step: 1
Training loss: 3.025272098630461
Validation loss: 2.574592610115071

Epoch: 6| Step: 2
Training loss: 2.52361096237687
Validation loss: 2.5766657383948437

Epoch: 6| Step: 3
Training loss: 2.448626335569373
Validation loss: 2.5922188883299033

Epoch: 6| Step: 4
Training loss: 1.8995114652082308
Validation loss: 2.616305649574063

Epoch: 6| Step: 5
Training loss: 2.459475709823521
Validation loss: 2.5530611563688796

Epoch: 6| Step: 6
Training loss: 2.838787905777185
Validation loss: 2.5287695190464046

Epoch: 6| Step: 7
Training loss: 1.8461440109791794
Validation loss: 2.5913867970521407

Epoch: 6| Step: 8
Training loss: 2.4020110605510885
Validation loss: 2.6336550655324746

Epoch: 6| Step: 9
Training loss: 2.189008138391415
Validation loss: 2.5620098650715173

Epoch: 6| Step: 10
Training loss: 2.700111605845395
Validation loss: 2.6133108442853303

Epoch: 6| Step: 11
Training loss: 1.841915058053765
Validation loss: 2.626975023103894

Epoch: 6| Step: 12
Training loss: 2.1232586626051093
Validation loss: 2.5911774977449125

Epoch: 6| Step: 13
Training loss: 3.2455501904636077
Validation loss: 2.661243685726695

Epoch: 300| Step: 0
Training loss: 2.676147257700417
Validation loss: 2.715797159759886

Epoch: 6| Step: 1
Training loss: 2.7006238711106905
Validation loss: 2.607189449766271

Epoch: 6| Step: 2
Training loss: 2.103208896726391
Validation loss: 2.61071839045072

Epoch: 6| Step: 3
Training loss: 3.045771628892858
Validation loss: 2.581385135567051

Epoch: 6| Step: 4
Training loss: 2.735269280380608
Validation loss: 2.609918834518219

Epoch: 6| Step: 5
Training loss: 2.2481913184617404
Validation loss: 2.6080153667919013

Epoch: 6| Step: 6
Training loss: 2.0736683260681024
Validation loss: 2.6093109134779193

Epoch: 6| Step: 7
Training loss: 2.6634590606550805
Validation loss: 2.5737328010695264

Epoch: 6| Step: 8
Training loss: 1.8340441091801296
Validation loss: 2.586826726373462

Epoch: 6| Step: 9
Training loss: 2.1872660920561304
Validation loss: 2.6014746490035647

Epoch: 6| Step: 10
Training loss: 2.5349254532486416
Validation loss: 2.6650443109069486

Epoch: 6| Step: 11
Training loss: 2.3209901584349204
Validation loss: 2.586753590287975

Epoch: 6| Step: 12
Training loss: 2.4798053485097986
Validation loss: 2.517855202447967

Epoch: 6| Step: 13
Training loss: 2.6363248403678234
Validation loss: 2.572451822803254

Epoch: 301| Step: 0
Training loss: 2.1798328638314226
Validation loss: 2.634668109587988

Epoch: 6| Step: 1
Training loss: 2.1464168409530693
Validation loss: 2.5974082940079373

Epoch: 6| Step: 2
Training loss: 2.7733934855662388
Validation loss: 2.6595064309480194

Epoch: 6| Step: 3
Training loss: 2.7063093007134142
Validation loss: 2.59550509009919

Epoch: 6| Step: 4
Training loss: 2.8123678388273397
Validation loss: 2.6155066019293898

Epoch: 6| Step: 5
Training loss: 2.0603551404797
Validation loss: 2.7238427641970846

Epoch: 6| Step: 6
Training loss: 2.0515263248458804
Validation loss: 2.5675093606527652

Epoch: 6| Step: 7
Training loss: 2.5505034454627546
Validation loss: 2.5797394421866247

Epoch: 6| Step: 8
Training loss: 1.648775183635008
Validation loss: 2.6090280715952248

Epoch: 6| Step: 9
Training loss: 1.8110612223033173
Validation loss: 2.643611981874041

Epoch: 6| Step: 10
Training loss: 2.962276427769948
Validation loss: 2.6102501335835475

Epoch: 6| Step: 11
Training loss: 3.158189083485715
Validation loss: 2.564416554329427

Epoch: 6| Step: 12
Training loss: 2.408409635749653
Validation loss: 2.598604264011017

Epoch: 6| Step: 13
Training loss: 2.329632367121985
Validation loss: 2.5624282750842258

Epoch: 302| Step: 0
Training loss: 2.0145419264137465
Validation loss: 2.6444922822540646

Epoch: 6| Step: 1
Training loss: 2.7121805205059206
Validation loss: 2.5950570829036956

Epoch: 6| Step: 2
Training loss: 2.7463716499287694
Validation loss: 2.5957841987590227

Epoch: 6| Step: 3
Training loss: 2.9085756246497425
Validation loss: 2.586862595217366

Epoch: 6| Step: 4
Training loss: 2.199822080526996
Validation loss: 2.583458456475316

Epoch: 6| Step: 5
Training loss: 2.3239288405720346
Validation loss: 2.6912147421333614

Epoch: 6| Step: 6
Training loss: 2.6859561122850804
Validation loss: 2.625204523677106

Epoch: 6| Step: 7
Training loss: 2.415235314761563
Validation loss: 2.582226708402231

Epoch: 6| Step: 8
Training loss: 2.539618985742334
Validation loss: 2.587222779296916

Epoch: 6| Step: 9
Training loss: 1.973251283245764
Validation loss: 2.63004601772819

Epoch: 6| Step: 10
Training loss: 1.9069420855789185
Validation loss: 2.5946809887088547

Epoch: 6| Step: 11
Training loss: 2.5215787389754514
Validation loss: 2.599468773826122

Epoch: 6| Step: 12
Training loss: 2.804875444580924
Validation loss: 2.629682960701557

Epoch: 6| Step: 13
Training loss: 2.25082043418686
Validation loss: 2.543569793046414

Epoch: 303| Step: 0
Training loss: 3.030888486718193
Validation loss: 2.59197092353211

Epoch: 6| Step: 1
Training loss: 1.768008690760902
Validation loss: 2.687781934170358

Epoch: 6| Step: 2
Training loss: 2.8210367979281825
Validation loss: 2.6608470141381364

Epoch: 6| Step: 3
Training loss: 2.193157835589833
Validation loss: 2.6280635588789

Epoch: 6| Step: 4
Training loss: 2.4504364247772275
Validation loss: 2.6047834910349197

Epoch: 6| Step: 5
Training loss: 1.8560518974661366
Validation loss: 2.5700194908106218

Epoch: 6| Step: 6
Training loss: 1.8910871208936446
Validation loss: 2.648123067130282

Epoch: 6| Step: 7
Training loss: 2.447524852373234
Validation loss: 2.530459137765759

Epoch: 6| Step: 8
Training loss: 2.2543839026207375
Validation loss: 2.621089601957398

Epoch: 6| Step: 9
Training loss: 2.7401044710109947
Validation loss: 2.5374828443518616

Epoch: 6| Step: 10
Training loss: 2.9613217227827837
Validation loss: 2.5634414530125778

Epoch: 6| Step: 11
Training loss: 2.294755853369745
Validation loss: 2.598319020372543

Epoch: 6| Step: 12
Training loss: 2.9079847183350727
Validation loss: 2.6597239574471443

Epoch: 6| Step: 13
Training loss: 2.101140997497199
Validation loss: 2.6448823060827915

Epoch: 304| Step: 0
Training loss: 3.1417131199593955
Validation loss: 2.585317474596572

Epoch: 6| Step: 1
Training loss: 2.5580360794923074
Validation loss: 2.622432066006452

Epoch: 6| Step: 2
Training loss: 2.632650489237078
Validation loss: 2.572733781211815

Epoch: 6| Step: 3
Training loss: 2.4850350708664615
Validation loss: 2.5812718680574593

Epoch: 6| Step: 4
Training loss: 2.148262044504611
Validation loss: 2.5476382750223947

Epoch: 6| Step: 5
Training loss: 1.9346186224091722
Validation loss: 2.575180616693876

Epoch: 6| Step: 6
Training loss: 2.2961486913669615
Validation loss: 2.5616540520414723

Epoch: 6| Step: 7
Training loss: 2.6049694400686176
Validation loss: 2.608716595142689

Epoch: 6| Step: 8
Training loss: 2.5298219584969046
Validation loss: 2.5688795966766986

Epoch: 6| Step: 9
Training loss: 2.2368722045574003
Validation loss: 2.566109579377804

Epoch: 6| Step: 10
Training loss: 2.5559390674068085
Validation loss: 2.6052153400873177

Epoch: 6| Step: 11
Training loss: 2.5241316558065523
Validation loss: 2.628230199863756

Epoch: 6| Step: 12
Training loss: 2.473792901112871
Validation loss: 2.6325250147749286

Epoch: 6| Step: 13
Training loss: 2.352883003020618
Validation loss: 2.650744980614776

Epoch: 305| Step: 0
Training loss: 2.2726399179490078
Validation loss: 2.485859437811304

Epoch: 6| Step: 1
Training loss: 2.644727240417903
Validation loss: 2.630505045055869

Epoch: 6| Step: 2
Training loss: 2.4205602214959807
Validation loss: 2.6410868629684314

Epoch: 6| Step: 3
Training loss: 2.5658140384666765
Validation loss: 2.5822243693589346

Epoch: 6| Step: 4
Training loss: 2.3311157474263626
Validation loss: 2.667802723136237

Epoch: 6| Step: 5
Training loss: 2.6540443687668556
Validation loss: 2.6121185225972448

Epoch: 6| Step: 6
Training loss: 2.253877054484871
Validation loss: 2.6121049060470867

Epoch: 6| Step: 7
Training loss: 2.1506805363085872
Validation loss: 2.6493049082233364

Epoch: 6| Step: 8
Training loss: 2.9580956663558866
Validation loss: 2.634323934109426

Epoch: 6| Step: 9
Training loss: 2.2222989135330304
Validation loss: 2.61684481477638

Epoch: 6| Step: 10
Training loss: 3.399114010879888
Validation loss: 2.592150208025464

Epoch: 6| Step: 11
Training loss: 1.8685290253803832
Validation loss: 2.6017722394145926

Epoch: 6| Step: 12
Training loss: 1.962990282859596
Validation loss: 2.6463621652795593

Epoch: 6| Step: 13
Training loss: 1.9319368295392265
Validation loss: 2.6333323254264664

Epoch: 306| Step: 0
Training loss: 1.934018113549508
Validation loss: 2.6175062612046993

Epoch: 6| Step: 1
Training loss: 2.0821848055842
Validation loss: 2.667249838514947

Epoch: 6| Step: 2
Training loss: 2.1083437058667336
Validation loss: 2.554151915604812

Epoch: 6| Step: 3
Training loss: 2.4241342159165495
Validation loss: 2.647277527671712

Epoch: 6| Step: 4
Training loss: 2.4222197256551743
Validation loss: 2.625158265123879

Epoch: 6| Step: 5
Training loss: 2.551825924302658
Validation loss: 2.6240041340908675

Epoch: 6| Step: 6
Training loss: 2.56365289572102
Validation loss: 2.534793526146687

Epoch: 6| Step: 7
Training loss: 2.5762940349637584
Validation loss: 2.553882751225237

Epoch: 6| Step: 8
Training loss: 2.816462374695418
Validation loss: 2.5588073706419503

Epoch: 6| Step: 9
Training loss: 2.6330861478592644
Validation loss: 2.6147621363941846

Epoch: 6| Step: 10
Training loss: 3.416157723334542
Validation loss: 2.560510547903662

Epoch: 6| Step: 11
Training loss: 2.218467586972648
Validation loss: 2.606797797878528

Epoch: 6| Step: 12
Training loss: 2.113891513447992
Validation loss: 2.541775743620847

Epoch: 6| Step: 13
Training loss: 1.8627383802822297
Validation loss: 2.605133119150391

Epoch: 307| Step: 0
Training loss: 1.7932652579413217
Validation loss: 2.6380123497899497

Epoch: 6| Step: 1
Training loss: 2.276148906308409
Validation loss: 2.5594524807091195

Epoch: 6| Step: 2
Training loss: 3.0584008946522476
Validation loss: 2.593609564535444

Epoch: 6| Step: 3
Training loss: 1.9999986290927003
Validation loss: 2.580963292688769

Epoch: 6| Step: 4
Training loss: 2.739198278096362
Validation loss: 2.6176980238353287

Epoch: 6| Step: 5
Training loss: 2.5946830082555516
Validation loss: 2.6144646855977807

Epoch: 6| Step: 6
Training loss: 2.423808156929484
Validation loss: 2.5963407946003936

Epoch: 6| Step: 7
Training loss: 2.709983811840398
Validation loss: 2.601761301580657

Epoch: 6| Step: 8
Training loss: 2.1707618110965416
Validation loss: 2.5930703418338816

Epoch: 6| Step: 9
Training loss: 1.7417886730821412
Validation loss: 2.5463029893638205

Epoch: 6| Step: 10
Training loss: 2.868269630388228
Validation loss: 2.5258569624295784

Epoch: 6| Step: 11
Training loss: 2.6397161782026575
Validation loss: 2.5823511248793465

Epoch: 6| Step: 12
Training loss: 2.1982485865563794
Validation loss: 2.6357345580640317

Epoch: 6| Step: 13
Training loss: 2.8787368041318713
Validation loss: 2.65164343747455

Epoch: 308| Step: 0
Training loss: 2.920876398644288
Validation loss: 2.600600685914285

Epoch: 6| Step: 1
Training loss: 2.022223030807464
Validation loss: 2.666850682287866

Epoch: 6| Step: 2
Training loss: 2.2113089636946395
Validation loss: 2.6874950148471117

Epoch: 6| Step: 3
Training loss: 1.943499720120735
Validation loss: 2.5818225099263197

Epoch: 6| Step: 4
Training loss: 2.402842896252234
Validation loss: 2.6889188912380977

Epoch: 6| Step: 5
Training loss: 2.253387655961475
Validation loss: 2.6396729535223327

Epoch: 6| Step: 6
Training loss: 2.2637199021544507
Validation loss: 2.597542510132041

Epoch: 6| Step: 7
Training loss: 1.881019910257798
Validation loss: 2.5660444807452714

Epoch: 6| Step: 8
Training loss: 2.4330387860400005
Validation loss: 2.5381105921420755

Epoch: 6| Step: 9
Training loss: 3.2714902052186856
Validation loss: 2.6210907609843463

Epoch: 6| Step: 10
Training loss: 2.2314501205158814
Validation loss: 2.552705802286507

Epoch: 6| Step: 11
Training loss: 2.375259686377107
Validation loss: 2.57253918804184

Epoch: 6| Step: 12
Training loss: 2.804954239851105
Validation loss: 2.5848173684597855

Epoch: 6| Step: 13
Training loss: 1.8612136085083255
Validation loss: 2.585465592904739

Epoch: 309| Step: 0
Training loss: 1.7762152474189534
Validation loss: 2.5907098027408497

Epoch: 6| Step: 1
Training loss: 2.6006195833992742
Validation loss: 2.61119777636273

Epoch: 6| Step: 2
Training loss: 2.3488068006630134
Validation loss: 2.588338935146117

Epoch: 6| Step: 3
Training loss: 1.8532651002362128
Validation loss: 2.6217003127163894

Epoch: 6| Step: 4
Training loss: 1.836604350302694
Validation loss: 2.6379579445201355

Epoch: 6| Step: 5
Training loss: 2.581182712666229
Validation loss: 2.626925210239871

Epoch: 6| Step: 6
Training loss: 3.2769453604516725
Validation loss: 2.572676476828051

Epoch: 6| Step: 7
Training loss: 3.27519568521153
Validation loss: 2.5368829679027365

Epoch: 6| Step: 8
Training loss: 2.2356847378942803
Validation loss: 2.6139151315768547

Epoch: 6| Step: 9
Training loss: 2.138082288880257
Validation loss: 2.6486801223632797

Epoch: 6| Step: 10
Training loss: 2.3240525643055654
Validation loss: 2.658837387136308

Epoch: 6| Step: 11
Training loss: 1.9806324065416934
Validation loss: 2.5587671875693645

Epoch: 6| Step: 12
Training loss: 3.09334153070131
Validation loss: 2.5912577969683723

Epoch: 6| Step: 13
Training loss: 2.012124977947414
Validation loss: 2.56150424207548

Epoch: 310| Step: 0
Training loss: 2.1184422902504525
Validation loss: 2.6209369003210368

Epoch: 6| Step: 1
Training loss: 2.7335529072499436
Validation loss: 2.596127253500425

Epoch: 6| Step: 2
Training loss: 2.7929364822764517
Validation loss: 2.5870204514645154

Epoch: 6| Step: 3
Training loss: 2.4272935855373214
Validation loss: 2.5998059179029984

Epoch: 6| Step: 4
Training loss: 2.4636262283705364
Validation loss: 2.6053188297015684

Epoch: 6| Step: 5
Training loss: 3.1477887642453206
Validation loss: 2.6003316386552733

Epoch: 6| Step: 6
Training loss: 2.33556646251743
Validation loss: 2.596301843144326

Epoch: 6| Step: 7
Training loss: 2.3545152749282825
Validation loss: 2.642363749896654

Epoch: 6| Step: 8
Training loss: 1.9809390380583805
Validation loss: 2.625918505520819

Epoch: 6| Step: 9
Training loss: 2.075327316573641
Validation loss: 2.632635670105881

Epoch: 6| Step: 10
Training loss: 2.108045144670819
Validation loss: 2.6504848208157066

Epoch: 6| Step: 11
Training loss: 2.2231574540963908
Validation loss: 2.6454629875460483

Epoch: 6| Step: 12
Training loss: 2.667549066780523
Validation loss: 2.671827824278119

Epoch: 6| Step: 13
Training loss: 2.5268165474810442
Validation loss: 2.6369739676635504

Epoch: 311| Step: 0
Training loss: 2.045370699387423
Validation loss: 2.563028296620175

Epoch: 6| Step: 1
Training loss: 1.9424826019568435
Validation loss: 2.5529923354390256

Epoch: 6| Step: 2
Training loss: 2.4093045750083673
Validation loss: 2.5873239476837666

Epoch: 6| Step: 3
Training loss: 2.422263132803659
Validation loss: 2.638565962598749

Epoch: 6| Step: 4
Training loss: 1.6474994322525458
Validation loss: 2.6548048543522635

Epoch: 6| Step: 5
Training loss: 2.477366993679885
Validation loss: 2.681749396143011

Epoch: 6| Step: 6
Training loss: 3.384537677606455
Validation loss: 2.578663001383185

Epoch: 6| Step: 7
Training loss: 2.3026273150870633
Validation loss: 2.53717730915427

Epoch: 6| Step: 8
Training loss: 2.3501578663496496
Validation loss: 2.5942799194502797

Epoch: 6| Step: 9
Training loss: 2.3581815821302006
Validation loss: 2.6149715450285873

Epoch: 6| Step: 10
Training loss: 2.3148733795669547
Validation loss: 2.5752724188118075

Epoch: 6| Step: 11
Training loss: 2.5963149659243414
Validation loss: 2.6691641443732332

Epoch: 6| Step: 12
Training loss: 3.1425590064093702
Validation loss: 2.6333838054430223

Epoch: 6| Step: 13
Training loss: 2.254923625591558
Validation loss: 2.6378616142265754

Epoch: 312| Step: 0
Training loss: 2.330060832494246
Validation loss: 2.633458220909762

Epoch: 6| Step: 1
Training loss: 2.0575483588541577
Validation loss: 2.5682076058599357

Epoch: 6| Step: 2
Training loss: 2.892989063114362
Validation loss: 2.6632278814706765

Epoch: 6| Step: 3
Training loss: 2.845263570902146
Validation loss: 2.584545575177262

Epoch: 6| Step: 4
Training loss: 2.005604996193626
Validation loss: 2.6223011802409695

Epoch: 6| Step: 5
Training loss: 3.3548567794497752
Validation loss: 2.6400093263279265

Epoch: 6| Step: 6
Training loss: 2.2080064087719444
Validation loss: 2.6411519790199907

Epoch: 6| Step: 7
Training loss: 2.0017073019806704
Validation loss: 2.647038779537058

Epoch: 6| Step: 8
Training loss: 2.2121313531515687
Validation loss: 2.611139700056786

Epoch: 6| Step: 9
Training loss: 2.4343493713675204
Validation loss: 2.643877438362681

Epoch: 6| Step: 10
Training loss: 1.9479775920730582
Validation loss: 2.6116725392526257

Epoch: 6| Step: 11
Training loss: 2.4753038354738144
Validation loss: 2.5758973850296703

Epoch: 6| Step: 12
Training loss: 2.0247779441871154
Validation loss: 2.5974440132735146

Epoch: 6| Step: 13
Training loss: 2.223479589411063
Validation loss: 2.602415529898688

Epoch: 313| Step: 0
Training loss: 2.239042089546279
Validation loss: 2.6058892978870314

Epoch: 6| Step: 1
Training loss: 2.284432894994598
Validation loss: 2.6496687326812696

Epoch: 6| Step: 2
Training loss: 2.29069216266753
Validation loss: 2.6447997344449714

Epoch: 6| Step: 3
Training loss: 2.1047425442006356
Validation loss: 2.6002907840437826

Epoch: 6| Step: 4
Training loss: 2.3914793395295066
Validation loss: 2.5726774464104647

Epoch: 6| Step: 5
Training loss: 2.344655383394823
Validation loss: 2.5843823261764483

Epoch: 6| Step: 6
Training loss: 2.2144897823963627
Validation loss: 2.618330631504448

Epoch: 6| Step: 7
Training loss: 2.778587180999025
Validation loss: 2.5812039740937096

Epoch: 6| Step: 8
Training loss: 2.4274253986182424
Validation loss: 2.6234897081542816

Epoch: 6| Step: 9
Training loss: 2.4748209416515987
Validation loss: 2.601284851987755

Epoch: 6| Step: 10
Training loss: 2.5911916961956143
Validation loss: 2.6487706159687274

Epoch: 6| Step: 11
Training loss: 2.4246554257699837
Validation loss: 2.6248640815326185

Epoch: 6| Step: 12
Training loss: 2.256970839386838
Validation loss: 2.5586013519542403

Epoch: 6| Step: 13
Training loss: 2.3770484121589863
Validation loss: 2.631280057183633

Epoch: 314| Step: 0
Training loss: 2.1581693206487196
Validation loss: 2.5595707021185725

Epoch: 6| Step: 1
Training loss: 2.4238741591367847
Validation loss: 2.5310569648053836

Epoch: 6| Step: 2
Training loss: 2.3328496113691375
Validation loss: 2.6179378652763066

Epoch: 6| Step: 3
Training loss: 1.9666695880329397
Validation loss: 2.628906035461744

Epoch: 6| Step: 4
Training loss: 2.577990719159262
Validation loss: 2.626154497759418

Epoch: 6| Step: 5
Training loss: 2.9231688546770784
Validation loss: 2.541054370650906

Epoch: 6| Step: 6
Training loss: 2.0646586825584192
Validation loss: 2.5661496220015683

Epoch: 6| Step: 7
Training loss: 2.003814278735874
Validation loss: 2.5698718000408483

Epoch: 6| Step: 8
Training loss: 2.5130408620612696
Validation loss: 2.597393883775556

Epoch: 6| Step: 9
Training loss: 2.0750491676480194
Validation loss: 2.6014444238853844

Epoch: 6| Step: 10
Training loss: 2.6613902004252736
Validation loss: 2.596056060671978

Epoch: 6| Step: 11
Training loss: 2.4556624780029486
Validation loss: 2.59968142312814

Epoch: 6| Step: 12
Training loss: 2.0345222525327724
Validation loss: 2.6542910470819843

Epoch: 6| Step: 13
Training loss: 2.5985988656299233
Validation loss: 2.5473316255627236

Epoch: 315| Step: 0
Training loss: 2.5890613139212544
Validation loss: 2.5981647544868225

Epoch: 6| Step: 1
Training loss: 2.305830849702594
Validation loss: 2.6550175567356074

Epoch: 6| Step: 2
Training loss: 2.6934813540294638
Validation loss: 2.579159699227041

Epoch: 6| Step: 3
Training loss: 2.594235294397043
Validation loss: 2.561023938324454

Epoch: 6| Step: 4
Training loss: 2.1817287061868855
Validation loss: 2.6864590833739608

Epoch: 6| Step: 5
Training loss: 2.562977630017518
Validation loss: 2.6259180183553594

Epoch: 6| Step: 6
Training loss: 2.3796147135613275
Validation loss: 2.5637075868760935

Epoch: 6| Step: 7
Training loss: 2.5758757055872796
Validation loss: 2.614136616558922

Epoch: 6| Step: 8
Training loss: 2.4193876229392712
Validation loss: 2.5863933745695293

Epoch: 6| Step: 9
Training loss: 2.7606812164407164
Validation loss: 2.624234984101305

Epoch: 6| Step: 10
Training loss: 2.306273764717868
Validation loss: 2.5359629441879434

Epoch: 6| Step: 11
Training loss: 2.6468822672810597
Validation loss: 2.6750663988676036

Epoch: 6| Step: 12
Training loss: 1.2106341566567655
Validation loss: 2.6028193621561804

Epoch: 6| Step: 13
Training loss: 2.780226444105834
Validation loss: 2.6378868222938685

Epoch: 316| Step: 0
Training loss: 2.1377862080592642
Validation loss: 2.6784877515966765

Epoch: 6| Step: 1
Training loss: 2.083334223429172
Validation loss: 2.5908414344781137

Epoch: 6| Step: 2
Training loss: 2.5472965008707544
Validation loss: 2.651739775637621

Epoch: 6| Step: 3
Training loss: 2.2032545335715
Validation loss: 2.5739872676933713

Epoch: 6| Step: 4
Training loss: 2.242431627334819
Validation loss: 2.687684653049111

Epoch: 6| Step: 5
Training loss: 2.554264138515561
Validation loss: 2.6554861226238677

Epoch: 6| Step: 6
Training loss: 2.155866284712722
Validation loss: 2.6747155779031244

Epoch: 6| Step: 7
Training loss: 2.2215476866692527
Validation loss: 2.7066901839599686

Epoch: 6| Step: 8
Training loss: 2.470302238660199
Validation loss: 2.670378372279567

Epoch: 6| Step: 9
Training loss: 3.1559312111787836
Validation loss: 2.6240294049387707

Epoch: 6| Step: 10
Training loss: 2.3704434906202936
Validation loss: 2.53881995520098

Epoch: 6| Step: 11
Training loss: 2.826171959360961
Validation loss: 2.595053035993853

Epoch: 6| Step: 12
Training loss: 1.9932760219351413
Validation loss: 2.5510342907807217

Epoch: 6| Step: 13
Training loss: 2.401008842944504
Validation loss: 2.624766498108685

Epoch: 317| Step: 0
Training loss: 1.9929001075949413
Validation loss: 2.5364441987586934

Epoch: 6| Step: 1
Training loss: 1.9451143707736094
Validation loss: 2.6030634886795343

Epoch: 6| Step: 2
Training loss: 2.3996552100470003
Validation loss: 2.618883945967951

Epoch: 6| Step: 3
Training loss: 2.690800525287675
Validation loss: 2.7050352822978816

Epoch: 6| Step: 4
Training loss: 3.1512340308287516
Validation loss: 2.586241579284093

Epoch: 6| Step: 5
Training loss: 2.2030584447019796
Validation loss: 2.6055735558554067

Epoch: 6| Step: 6
Training loss: 2.48814336613285
Validation loss: 2.5866609736169432

Epoch: 6| Step: 7
Training loss: 2.9202897774601717
Validation loss: 2.6612121183664095

Epoch: 6| Step: 8
Training loss: 2.0232590998062334
Validation loss: 2.6226982009753734

Epoch: 6| Step: 9
Training loss: 2.0565735026217253
Validation loss: 2.7115473574156157

Epoch: 6| Step: 10
Training loss: 2.3654107706080345
Validation loss: 2.5702456221769445

Epoch: 6| Step: 11
Training loss: 2.3793495905135407
Validation loss: 2.5815952744568675

Epoch: 6| Step: 12
Training loss: 2.765622327555427
Validation loss: 2.5679520204294257

Epoch: 6| Step: 13
Training loss: 2.2275524414945105
Validation loss: 2.5994937664205033

Epoch: 318| Step: 0
Training loss: 2.196352674920819
Validation loss: 2.652468272443486

Epoch: 6| Step: 1
Training loss: 2.1322642309836795
Validation loss: 2.53826020469467

Epoch: 6| Step: 2
Training loss: 2.3048602540523904
Validation loss: 2.597304132877283

Epoch: 6| Step: 3
Training loss: 2.8344880911105377
Validation loss: 2.592737619282276

Epoch: 6| Step: 4
Training loss: 3.0226605030541607
Validation loss: 2.572534459450706

Epoch: 6| Step: 5
Training loss: 1.785571227474048
Validation loss: 2.5320691254804006

Epoch: 6| Step: 6
Training loss: 2.654898625106941
Validation loss: 2.605799755969365

Epoch: 6| Step: 7
Training loss: 2.0281342304883725
Validation loss: 2.5846476438371626

Epoch: 6| Step: 8
Training loss: 2.226838318990802
Validation loss: 2.6118556283900176

Epoch: 6| Step: 9
Training loss: 2.2020652873714237
Validation loss: 2.5915525972430453

Epoch: 6| Step: 10
Training loss: 2.605858540581301
Validation loss: 2.6837623639824977

Epoch: 6| Step: 11
Training loss: 2.0976721622708854
Validation loss: 2.6190614968166446

Epoch: 6| Step: 12
Training loss: 2.760580084420001
Validation loss: 2.629581800703355

Epoch: 6| Step: 13
Training loss: 3.01577521231699
Validation loss: 2.684914487302472

Epoch: 319| Step: 0
Training loss: 1.982905286657558
Validation loss: 2.615231357721509

Epoch: 6| Step: 1
Training loss: 2.7619094459058635
Validation loss: 2.6232043637378157

Epoch: 6| Step: 2
Training loss: 2.2817323775636495
Validation loss: 2.510642685432212

Epoch: 6| Step: 3
Training loss: 1.9697050170022683
Validation loss: 2.62249919761252

Epoch: 6| Step: 4
Training loss: 1.9808057991053871
Validation loss: 2.6382868536821933

Epoch: 6| Step: 5
Training loss: 1.7693327735597193
Validation loss: 2.6090305929550994

Epoch: 6| Step: 6
Training loss: 2.7054125857933196
Validation loss: 2.591371284397931

Epoch: 6| Step: 7
Training loss: 1.9382539943268653
Validation loss: 2.624874570030661

Epoch: 6| Step: 8
Training loss: 2.1706152905906873
Validation loss: 2.6057360065374016

Epoch: 6| Step: 9
Training loss: 2.842824932170587
Validation loss: 2.6497416725018432

Epoch: 6| Step: 10
Training loss: 2.759369062371956
Validation loss: 2.59651339125788

Epoch: 6| Step: 11
Training loss: 2.350036531529654
Validation loss: 2.625486455788478

Epoch: 6| Step: 12
Training loss: 3.250751995238317
Validation loss: 2.6383199624319706

Epoch: 6| Step: 13
Training loss: 3.063784894180337
Validation loss: 2.6544158046161335

Epoch: 320| Step: 0
Training loss: 2.0914114802754336
Validation loss: 2.662557865376553

Epoch: 6| Step: 1
Training loss: 2.214840305332418
Validation loss: 2.574490777127134

Epoch: 6| Step: 2
Training loss: 1.9312227142282927
Validation loss: 2.604380551978729

Epoch: 6| Step: 3
Training loss: 2.226764121045412
Validation loss: 2.6224412620979303

Epoch: 6| Step: 4
Training loss: 2.5975634565486785
Validation loss: 2.5715134153434054

Epoch: 6| Step: 5
Training loss: 2.882907772815929
Validation loss: 2.607889448256633

Epoch: 6| Step: 6
Training loss: 2.2174934805136646
Validation loss: 2.563330101692855

Epoch: 6| Step: 7
Training loss: 2.1027009851142155
Validation loss: 2.533715262333017

Epoch: 6| Step: 8
Training loss: 2.585853782750796
Validation loss: 2.58607551987832

Epoch: 6| Step: 9
Training loss: 2.7009475846583957
Validation loss: 2.6172784237594193

Epoch: 6| Step: 10
Training loss: 1.803799761788276
Validation loss: 2.5676635792867346

Epoch: 6| Step: 11
Training loss: 2.7751920066597418
Validation loss: 2.642511900281078

Epoch: 6| Step: 12
Training loss: 2.5350157429885334
Validation loss: 2.6311346680270398

Epoch: 6| Step: 13
Training loss: 2.8711673234089354
Validation loss: 2.6691622119155247

Epoch: 321| Step: 0
Training loss: 2.5767696632766786
Validation loss: 2.621144983311034

Epoch: 6| Step: 1
Training loss: 2.08644080787138
Validation loss: 2.6031566031044076

Epoch: 6| Step: 2
Training loss: 2.763820943417896
Validation loss: 2.5357616662405733

Epoch: 6| Step: 3
Training loss: 2.2929036587732
Validation loss: 2.6332561695662156

Epoch: 6| Step: 4
Training loss: 1.6299530251877958
Validation loss: 2.6489694515881745

Epoch: 6| Step: 5
Training loss: 2.1940238673008197
Validation loss: 2.647819922075094

Epoch: 6| Step: 6
Training loss: 2.005570997329586
Validation loss: 2.5925987481896113

Epoch: 6| Step: 7
Training loss: 2.3032092509911726
Validation loss: 2.5556657462382706

Epoch: 6| Step: 8
Training loss: 2.484277495384174
Validation loss: 2.5619355372129498

Epoch: 6| Step: 9
Training loss: 2.490947833611079
Validation loss: 2.617524356924796

Epoch: 6| Step: 10
Training loss: 2.3988898531014784
Validation loss: 2.595328226305017

Epoch: 6| Step: 11
Training loss: 2.748412627801046
Validation loss: 2.6135400948350767

Epoch: 6| Step: 12
Training loss: 2.21306515819331
Validation loss: 2.6385240346481544

Epoch: 6| Step: 13
Training loss: 2.4219084706608522
Validation loss: 2.5931288084902238

Epoch: 322| Step: 0
Training loss: 1.9109409335363674
Validation loss: 2.5556747181320447

Epoch: 6| Step: 1
Training loss: 2.0297367034187164
Validation loss: 2.6202243044936395

Epoch: 6| Step: 2
Training loss: 1.933529692850714
Validation loss: 2.5656452649939565

Epoch: 6| Step: 3
Training loss: 2.409618645407689
Validation loss: 2.5966241071916176

Epoch: 6| Step: 4
Training loss: 2.814544443294298
Validation loss: 2.7285698697900407

Epoch: 6| Step: 5
Training loss: 1.9143183945853361
Validation loss: 2.632170385058194

Epoch: 6| Step: 6
Training loss: 2.1585499756634134
Validation loss: 2.6631237850878624

Epoch: 6| Step: 7
Training loss: 2.6447571695989445
Validation loss: 2.6098798430852876

Epoch: 6| Step: 8
Training loss: 2.7565033915121915
Validation loss: 2.5305337574915385

Epoch: 6| Step: 9
Training loss: 2.5912301565791553
Validation loss: 2.5749314163334343

Epoch: 6| Step: 10
Training loss: 3.4540848584643453
Validation loss: 2.6168993621542267

Epoch: 6| Step: 11
Training loss: 2.333917465208553
Validation loss: 2.5994579974091976

Epoch: 6| Step: 12
Training loss: 1.525103865666587
Validation loss: 2.5652984757091066

Epoch: 6| Step: 13
Training loss: 2.131206089137947
Validation loss: 2.566453087045095

Epoch: 323| Step: 0
Training loss: 2.6034374182388245
Validation loss: 2.5370720999676153

Epoch: 6| Step: 1
Training loss: 3.1388760531752866
Validation loss: 2.608923310181131

Epoch: 6| Step: 2
Training loss: 2.8671542381415356
Validation loss: 2.6998808702707406

Epoch: 6| Step: 3
Training loss: 2.184722008381444
Validation loss: 2.596948062752518

Epoch: 6| Step: 4
Training loss: 2.1600809756747936
Validation loss: 2.6023859796735733

Epoch: 6| Step: 5
Training loss: 2.85325726874146
Validation loss: 2.5682470373119464

Epoch: 6| Step: 6
Training loss: 2.349682636339664
Validation loss: 2.651629403194745

Epoch: 6| Step: 7
Training loss: 1.9865877325049626
Validation loss: 2.5618854969423843

Epoch: 6| Step: 8
Training loss: 1.9137151909072518
Validation loss: 2.6216111739244767

Epoch: 6| Step: 9
Training loss: 2.2443798658105236
Validation loss: 2.6909577261042186

Epoch: 6| Step: 10
Training loss: 2.334543686252725
Validation loss: 2.6093384979231686

Epoch: 6| Step: 11
Training loss: 2.1315177368958054
Validation loss: 2.575114892701609

Epoch: 6| Step: 12
Training loss: 2.0226759490066475
Validation loss: 2.6209886531453153

Epoch: 6| Step: 13
Training loss: 2.1423604571236536
Validation loss: 2.4917551841518737

Epoch: 324| Step: 0
Training loss: 2.3881174537361756
Validation loss: 2.6451315969445774

Epoch: 6| Step: 1
Training loss: 2.209900521848729
Validation loss: 2.6255070625828996

Epoch: 6| Step: 2
Training loss: 2.0359583352253154
Validation loss: 2.6036963141841363

Epoch: 6| Step: 3
Training loss: 2.2145210044417665
Validation loss: 2.5521323491693155

Epoch: 6| Step: 4
Training loss: 2.0359507234602106
Validation loss: 2.646741322883332

Epoch: 6| Step: 5
Training loss: 3.3381977509193734
Validation loss: 2.6295507784601266

Epoch: 6| Step: 6
Training loss: 2.685591618945442
Validation loss: 2.5866258477904043

Epoch: 6| Step: 7
Training loss: 2.0109731533206663
Validation loss: 2.6821652248905017

Epoch: 6| Step: 8
Training loss: 1.9296016287905902
Validation loss: 2.6661645794106534

Epoch: 6| Step: 9
Training loss: 2.4589772000863355
Validation loss: 2.6285960425479407

Epoch: 6| Step: 10
Training loss: 2.2227525740469023
Validation loss: 2.534073098379035

Epoch: 6| Step: 11
Training loss: 2.4808442559950556
Validation loss: 2.573471564158677

Epoch: 6| Step: 12
Training loss: 2.8394427534547133
Validation loss: 2.6953925749951853

Epoch: 6| Step: 13
Training loss: 1.9544030242462431
Validation loss: 2.6325164138647934

Epoch: 325| Step: 0
Training loss: 2.3276732345671216
Validation loss: 2.578901166227111

Epoch: 6| Step: 1
Training loss: 2.470562233507545
Validation loss: 2.593539168497784

Epoch: 6| Step: 2
Training loss: 2.012550315464891
Validation loss: 2.695291430090916

Epoch: 6| Step: 3
Training loss: 1.7824736290648924
Validation loss: 2.6698115446096407

Epoch: 6| Step: 4
Training loss: 2.943807121095222
Validation loss: 2.573272761808338

Epoch: 6| Step: 5
Training loss: 2.3997727445455888
Validation loss: 2.7019299325259527

Epoch: 6| Step: 6
Training loss: 1.893224961924617
Validation loss: 2.6123954058430217

Epoch: 6| Step: 7
Training loss: 2.4223537833195423
Validation loss: 2.5915968599451658

Epoch: 6| Step: 8
Training loss: 2.1408951860310212
Validation loss: 2.5896665510365287

Epoch: 6| Step: 9
Training loss: 2.488729631157622
Validation loss: 2.572862142704458

Epoch: 6| Step: 10
Training loss: 3.147379732992952
Validation loss: 2.611459886653265

Epoch: 6| Step: 11
Training loss: 2.163798512356267
Validation loss: 2.5911423708135644

Epoch: 6| Step: 12
Training loss: 2.5163317333274797
Validation loss: 2.660978889390318

Epoch: 6| Step: 13
Training loss: 2.0739542474583517
Validation loss: 2.6147653748148643

Epoch: 326| Step: 0
Training loss: 2.027654194077905
Validation loss: 2.615113737023036

Epoch: 6| Step: 1
Training loss: 1.788720377230925
Validation loss: 2.5686447967526553

Epoch: 6| Step: 2
Training loss: 2.088154960721098
Validation loss: 2.6381956797956576

Epoch: 6| Step: 3
Training loss: 2.681087739743085
Validation loss: 2.62877690560933

Epoch: 6| Step: 4
Training loss: 2.0314335666753736
Validation loss: 2.6359325680407366

Epoch: 6| Step: 5
Training loss: 2.2887908461888027
Validation loss: 2.5919992404510244

Epoch: 6| Step: 6
Training loss: 2.1654711383806684
Validation loss: 2.545819665129531

Epoch: 6| Step: 7
Training loss: 2.951169128214721
Validation loss: 2.605715731378435

Epoch: 6| Step: 8
Training loss: 2.4060299264912794
Validation loss: 2.614917743709658

Epoch: 6| Step: 9
Training loss: 1.832939654766391
Validation loss: 2.59507515487482

Epoch: 6| Step: 10
Training loss: 2.6251345100453993
Validation loss: 2.5802535541850773

Epoch: 6| Step: 11
Training loss: 2.5049422050707335
Validation loss: 2.6292881569004756

Epoch: 6| Step: 12
Training loss: 2.977439771118336
Validation loss: 2.721601727276734

Epoch: 6| Step: 13
Training loss: 2.952714518119335
Validation loss: 2.639102798741261

Epoch: 327| Step: 0
Training loss: 2.012871569338411
Validation loss: 2.5891462403962944

Epoch: 6| Step: 1
Training loss: 2.35798179468661
Validation loss: 2.647749397827759

Epoch: 6| Step: 2
Training loss: 2.0014092725459505
Validation loss: 2.608176279462069

Epoch: 6| Step: 3
Training loss: 3.147615008203539
Validation loss: 2.681956940045697

Epoch: 6| Step: 4
Training loss: 1.9060112225181127
Validation loss: 2.5346432457266057

Epoch: 6| Step: 5
Training loss: 2.306631115692719
Validation loss: 2.624710723360582

Epoch: 6| Step: 6
Training loss: 1.851486912725657
Validation loss: 2.615659309889728

Epoch: 6| Step: 7
Training loss: 2.2129001061690095
Validation loss: 2.6321703344120375

Epoch: 6| Step: 8
Training loss: 2.4043776919233593
Validation loss: 2.653036714463299

Epoch: 6| Step: 9
Training loss: 2.3361673401506415
Validation loss: 2.6309116985411194

Epoch: 6| Step: 10
Training loss: 2.8540140561330425
Validation loss: 2.662395023408434

Epoch: 6| Step: 11
Training loss: 1.9929721857667122
Validation loss: 2.551239520755704

Epoch: 6| Step: 12
Training loss: 2.116315260825552
Validation loss: 2.643561763903892

Epoch: 6| Step: 13
Training loss: 3.4036681863546474
Validation loss: 2.5692722062910467

Epoch: 328| Step: 0
Training loss: 2.9697957656459204
Validation loss: 2.5676773706078735

Epoch: 6| Step: 1
Training loss: 2.5056468133126755
Validation loss: 2.603884382802116

Epoch: 6| Step: 2
Training loss: 2.9093276924523837
Validation loss: 2.613023694199784

Epoch: 6| Step: 3
Training loss: 2.1202785548259766
Validation loss: 2.5899452089744637

Epoch: 6| Step: 4
Training loss: 2.277902106119997
Validation loss: 2.5803378594832136

Epoch: 6| Step: 5
Training loss: 2.382019911726869
Validation loss: 2.587449085586148

Epoch: 6| Step: 6
Training loss: 1.8200200709609116
Validation loss: 2.6045493283255126

Epoch: 6| Step: 7
Training loss: 2.2510852315824543
Validation loss: 2.6055875164666684

Epoch: 6| Step: 8
Training loss: 2.3770362757962733
Validation loss: 2.7155560185673644

Epoch: 6| Step: 9
Training loss: 2.793455452294279
Validation loss: 2.5533133928746636

Epoch: 6| Step: 10
Training loss: 1.7571219889412903
Validation loss: 2.5561878216339933

Epoch: 6| Step: 11
Training loss: 2.091623393468571
Validation loss: 2.5340877027760405

Epoch: 6| Step: 12
Training loss: 2.084528872459479
Validation loss: 2.6032543574547

Epoch: 6| Step: 13
Training loss: 1.934215222293932
Validation loss: 2.6296739517662413

Epoch: 329| Step: 0
Training loss: 2.2357071326666738
Validation loss: 2.5678235352886993

Epoch: 6| Step: 1
Training loss: 1.8096263730649382
Validation loss: 2.607991431974236

Epoch: 6| Step: 2
Training loss: 2.2471798070617566
Validation loss: 2.540779890725708

Epoch: 6| Step: 3
Training loss: 1.9970554491156853
Validation loss: 2.615301301223845

Epoch: 6| Step: 4
Training loss: 2.434311468546541
Validation loss: 2.6429605365791526

Epoch: 6| Step: 5
Training loss: 2.365013005097906
Validation loss: 2.5033112162978224

Epoch: 6| Step: 6
Training loss: 2.0708942099922663
Validation loss: 2.564709276021661

Epoch: 6| Step: 7
Training loss: 2.7388399128364096
Validation loss: 2.6566618318416344

Epoch: 6| Step: 8
Training loss: 2.2825776508739604
Validation loss: 2.568686438131552

Epoch: 6| Step: 9
Training loss: 2.637682477234136
Validation loss: 2.5929275564839225

Epoch: 6| Step: 10
Training loss: 2.2564517874052346
Validation loss: 2.5464185069954395

Epoch: 6| Step: 11
Training loss: 2.3729939270391935
Validation loss: 2.638928109852445

Epoch: 6| Step: 12
Training loss: 2.730961265403811
Validation loss: 2.571390713217537

Epoch: 6| Step: 13
Training loss: 2.763157665281358
Validation loss: 2.6620930913970455

Epoch: 330| Step: 0
Training loss: 2.349336197622215
Validation loss: 2.5551607139552024

Epoch: 6| Step: 1
Training loss: 2.072152410609067
Validation loss: 2.574395375123601

Epoch: 6| Step: 2
Training loss: 1.8555851628777091
Validation loss: 2.5959913229177687

Epoch: 6| Step: 3
Training loss: 2.413697051500229
Validation loss: 2.5146486658641196

Epoch: 6| Step: 4
Training loss: 1.905307223960425
Validation loss: 2.6297418538694948

Epoch: 6| Step: 5
Training loss: 2.8284583132421335
Validation loss: 2.6591914973555717

Epoch: 6| Step: 6
Training loss: 2.0666318023981316
Validation loss: 2.579952193352496

Epoch: 6| Step: 7
Training loss: 2.4289192383407556
Validation loss: 2.6352670768070876

Epoch: 6| Step: 8
Training loss: 2.5117686787295477
Validation loss: 2.583040479507007

Epoch: 6| Step: 9
Training loss: 2.373902519030813
Validation loss: 2.6114581726242494

Epoch: 6| Step: 10
Training loss: 3.1194578235218913
Validation loss: 2.6524823912034057

Epoch: 6| Step: 11
Training loss: 2.2488202074848136
Validation loss: 2.544992695124289

Epoch: 6| Step: 12
Training loss: 2.4840365965108435
Validation loss: 2.5800931635321915

Epoch: 6| Step: 13
Training loss: 2.883427252002438
Validation loss: 2.6547454597626663

Epoch: 331| Step: 0
Training loss: 2.236312239811213
Validation loss: 2.642442563512395

Epoch: 6| Step: 1
Training loss: 2.1455478169631848
Validation loss: 2.5353081836189126

Epoch: 6| Step: 2
Training loss: 2.2517703826683144
Validation loss: 2.5604393549918605

Epoch: 6| Step: 3
Training loss: 2.623438052551684
Validation loss: 2.666187878536782

Epoch: 6| Step: 4
Training loss: 1.9461266219687123
Validation loss: 2.6740960359567088

Epoch: 6| Step: 5
Training loss: 1.4209822482531103
Validation loss: 2.5953201856776746

Epoch: 6| Step: 6
Training loss: 2.0296935941092236
Validation loss: 2.635202968159169

Epoch: 6| Step: 7
Training loss: 2.4641336666611355
Validation loss: 2.6042706894966767

Epoch: 6| Step: 8
Training loss: 3.0659079760373267
Validation loss: 2.5526086982645166

Epoch: 6| Step: 9
Training loss: 2.6331315116158933
Validation loss: 2.532243253977959

Epoch: 6| Step: 10
Training loss: 2.577609848804471
Validation loss: 2.6807917095703675

Epoch: 6| Step: 11
Training loss: 2.8094742499653313
Validation loss: 2.635509020151714

Epoch: 6| Step: 12
Training loss: 2.612810716905591
Validation loss: 2.616777434753367

Epoch: 6| Step: 13
Training loss: 2.626357953459682
Validation loss: 2.578749287811735

Epoch: 332| Step: 0
Training loss: 2.024954679947446
Validation loss: 2.523067267258465

Epoch: 6| Step: 1
Training loss: 2.3162045061282877
Validation loss: 2.6453054720453055

Epoch: 6| Step: 2
Training loss: 2.982867274473342
Validation loss: 2.553960236985231

Epoch: 6| Step: 3
Training loss: 2.3770973581830344
Validation loss: 2.6438317014288604

Epoch: 6| Step: 4
Training loss: 1.9485781425369195
Validation loss: 2.625608032951918

Epoch: 6| Step: 5
Training loss: 2.0872600805870962
Validation loss: 2.613420709800887

Epoch: 6| Step: 6
Training loss: 2.2923197307034235
Validation loss: 2.477577132834799

Epoch: 6| Step: 7
Training loss: 2.821951096903816
Validation loss: 2.5955207711456025

Epoch: 6| Step: 8
Training loss: 2.3164026475849413
Validation loss: 2.558373296527821

Epoch: 6| Step: 9
Training loss: 2.2361679886033596
Validation loss: 2.5208901812751194

Epoch: 6| Step: 10
Training loss: 2.7993546900317985
Validation loss: 2.6039899681605276

Epoch: 6| Step: 11
Training loss: 2.663750235863205
Validation loss: 2.634861188917973

Epoch: 6| Step: 12
Training loss: 2.0013002698828464
Validation loss: 2.627127942685973

Epoch: 6| Step: 13
Training loss: 2.461791359651709
Validation loss: 2.679901542140648

Epoch: 333| Step: 0
Training loss: 2.240337392738152
Validation loss: 2.5672625262613455

Epoch: 6| Step: 1
Training loss: 2.399517499582873
Validation loss: 2.6176832140738506

Epoch: 6| Step: 2
Training loss: 2.8844561762767915
Validation loss: 2.591529556993146

Epoch: 6| Step: 3
Training loss: 1.5817037361123565
Validation loss: 2.5784145576698734

Epoch: 6| Step: 4
Training loss: 2.348195044310734
Validation loss: 2.616679076055673

Epoch: 6| Step: 5
Training loss: 2.2241063541464117
Validation loss: 2.646075811136105

Epoch: 6| Step: 6
Training loss: 2.226842173361973
Validation loss: 2.5620540968264267

Epoch: 6| Step: 7
Training loss: 3.210202023812739
Validation loss: 2.5244782538966133

Epoch: 6| Step: 8
Training loss: 2.2323721064963147
Validation loss: 2.5934655361793992

Epoch: 6| Step: 9
Training loss: 2.2504792232914643
Validation loss: 2.6496921879842907

Epoch: 6| Step: 10
Training loss: 2.151801454659481
Validation loss: 2.648849632862704

Epoch: 6| Step: 11
Training loss: 2.3337584062944896
Validation loss: 2.5943906417644205

Epoch: 6| Step: 12
Training loss: 2.5070939505235357
Validation loss: 2.614548165258424

Epoch: 6| Step: 13
Training loss: 3.0197861182662
Validation loss: 2.6492615003341977

Epoch: 334| Step: 0
Training loss: 2.531672312981556
Validation loss: 2.6088951062048142

Epoch: 6| Step: 1
Training loss: 1.7567260097104953
Validation loss: 2.598451200957249

Epoch: 6| Step: 2
Training loss: 2.266031794366225
Validation loss: 2.579630645087465

Epoch: 6| Step: 3
Training loss: 2.7392153377945814
Validation loss: 2.714666196904653

Epoch: 6| Step: 4
Training loss: 2.6465515803851547
Validation loss: 2.6125709493833336

Epoch: 6| Step: 5
Training loss: 1.9303722325044386
Validation loss: 2.6651542576541805

Epoch: 6| Step: 6
Training loss: 2.288254110136939
Validation loss: 2.6136935738793667

Epoch: 6| Step: 7
Training loss: 2.022161014850922
Validation loss: 2.6094383785672717

Epoch: 6| Step: 8
Training loss: 2.2503391646023956
Validation loss: 2.4946240952357535

Epoch: 6| Step: 9
Training loss: 1.7566721290102922
Validation loss: 2.677632952748094

Epoch: 6| Step: 10
Training loss: 3.1933992435871326
Validation loss: 2.6159164425319306

Epoch: 6| Step: 11
Training loss: 2.443388843434906
Validation loss: 2.527868163181574

Epoch: 6| Step: 12
Training loss: 2.386376489051457
Validation loss: 2.6471315470267323

Epoch: 6| Step: 13
Training loss: 2.081205222074844
Validation loss: 2.562184298096682

Epoch: 335| Step: 0
Training loss: 1.8355346887106445
Validation loss: 2.6448289842936585

Epoch: 6| Step: 1
Training loss: 2.1803368042264712
Validation loss: 2.6360374046174764

Epoch: 6| Step: 2
Training loss: 2.4669259974618463
Validation loss: 2.708809432754255

Epoch: 6| Step: 3
Training loss: 2.3440836351075247
Validation loss: 2.676234375033474

Epoch: 6| Step: 4
Training loss: 2.6628878064761103
Validation loss: 2.603589865189571

Epoch: 6| Step: 5
Training loss: 2.286119984913019
Validation loss: 2.628241046563959

Epoch: 6| Step: 6
Training loss: 1.559770718133198
Validation loss: 2.702227393943106

Epoch: 6| Step: 7
Training loss: 2.3263212039141363
Validation loss: 2.655468969111543

Epoch: 6| Step: 8
Training loss: 2.8411622062978235
Validation loss: 2.6565645151129105

Epoch: 6| Step: 9
Training loss: 2.176408605344923
Validation loss: 2.5958637629290284

Epoch: 6| Step: 10
Training loss: 2.08971734065705
Validation loss: 2.676513744550224

Epoch: 6| Step: 11
Training loss: 2.1020475487235597
Validation loss: 2.675353426467146

Epoch: 6| Step: 12
Training loss: 2.9042875165346027
Validation loss: 2.590232366474506

Epoch: 6| Step: 13
Training loss: 2.3757713470704185
Validation loss: 2.637898545255669

Epoch: 336| Step: 0
Training loss: 2.4707845681981846
Validation loss: 2.7150113806883267

Epoch: 6| Step: 1
Training loss: 2.4486291592483913
Validation loss: 2.642306617651135

Epoch: 6| Step: 2
Training loss: 3.65783435370147
Validation loss: 2.5864066507072128

Epoch: 6| Step: 3
Training loss: 1.7679039080600945
Validation loss: 2.59483787731373

Epoch: 6| Step: 4
Training loss: 1.9974586911280698
Validation loss: 2.6137020474264463

Epoch: 6| Step: 5
Training loss: 2.2629785274038112
Validation loss: 2.626073587463938

Epoch: 6| Step: 6
Training loss: 2.1695415668290328
Validation loss: 2.5617368688791586

Epoch: 6| Step: 7
Training loss: 1.9715061574283952
Validation loss: 2.66444561129749

Epoch: 6| Step: 8
Training loss: 2.457106742244961
Validation loss: 2.674401474815647

Epoch: 6| Step: 9
Training loss: 2.176654195394419
Validation loss: 2.480983784982925

Epoch: 6| Step: 10
Training loss: 2.185418473768139
Validation loss: 2.6426531527112544

Epoch: 6| Step: 11
Training loss: 2.108575966284075
Validation loss: 2.5563204407435647

Epoch: 6| Step: 12
Training loss: 2.1441804637185817
Validation loss: 2.6112186009686558

Epoch: 6| Step: 13
Training loss: 2.8258001561543544
Validation loss: 2.57324045000681

Epoch: 337| Step: 0
Training loss: 2.624154999376827
Validation loss: 2.605628051896131

Epoch: 6| Step: 1
Training loss: 2.4160130592523763
Validation loss: 2.6520310205062034

Epoch: 6| Step: 2
Training loss: 2.3124786582168175
Validation loss: 2.603229333998406

Epoch: 6| Step: 3
Training loss: 2.2224939484830326
Validation loss: 2.624987987484965

Epoch: 6| Step: 4
Training loss: 2.371551620291559
Validation loss: 2.594050598912198

Epoch: 6| Step: 5
Training loss: 2.259109071986853
Validation loss: 2.610651928079769

Epoch: 6| Step: 6
Training loss: 1.9947588912090648
Validation loss: 2.6731702275825597

Epoch: 6| Step: 7
Training loss: 2.7456332128494427
Validation loss: 2.5890869070161906

Epoch: 6| Step: 8
Training loss: 2.5419619862905294
Validation loss: 2.5754519449774635

Epoch: 6| Step: 9
Training loss: 2.116020077846293
Validation loss: 2.6273484367754794

Epoch: 6| Step: 10
Training loss: 2.716770021153678
Validation loss: 2.630646572847139

Epoch: 6| Step: 11
Training loss: 1.9958790404223379
Validation loss: 2.5699708004995636

Epoch: 6| Step: 12
Training loss: 2.4151881288027575
Validation loss: 2.6125091805747913

Epoch: 6| Step: 13
Training loss: 2.349777507394909
Validation loss: 2.591004679217554

Epoch: 338| Step: 0
Training loss: 1.8227026968220015
Validation loss: 2.5107989991280073

Epoch: 6| Step: 1
Training loss: 2.5817777708349134
Validation loss: 2.6000103892709605

Epoch: 6| Step: 2
Training loss: 2.581370951702876
Validation loss: 2.63662235790242

Epoch: 6| Step: 3
Training loss: 2.5537713417509575
Validation loss: 2.633993328080769

Epoch: 6| Step: 4
Training loss: 2.238732417307551
Validation loss: 2.6094795654598477

Epoch: 6| Step: 5
Training loss: 2.00713506172501
Validation loss: 2.621669181565567

Epoch: 6| Step: 6
Training loss: 2.464918422625827
Validation loss: 2.587170886121111

Epoch: 6| Step: 7
Training loss: 1.1539831364455655
Validation loss: 2.592053082295291

Epoch: 6| Step: 8
Training loss: 2.0295583870386498
Validation loss: 2.586433190388295

Epoch: 6| Step: 9
Training loss: 2.9222154062028047
Validation loss: 2.5925935751178533

Epoch: 6| Step: 10
Training loss: 2.5319348574389613
Validation loss: 2.5915157828006126

Epoch: 6| Step: 11
Training loss: 2.290113604863556
Validation loss: 2.636109448595668

Epoch: 6| Step: 12
Training loss: 1.9893273260436661
Validation loss: 2.6104733073517976

Epoch: 6| Step: 13
Training loss: 2.3942272497368684
Validation loss: 2.596020535615091

Epoch: 339| Step: 0
Training loss: 1.8602765886713306
Validation loss: 2.5905955030690544

Epoch: 6| Step: 1
Training loss: 2.7074291382707183
Validation loss: 2.579162886928229

Epoch: 6| Step: 2
Training loss: 2.2044340532751843
Validation loss: 2.557499452169334

Epoch: 6| Step: 3
Training loss: 1.9289488826720291
Validation loss: 2.6225028654012257

Epoch: 6| Step: 4
Training loss: 2.089959428384312
Validation loss: 2.574859416424227

Epoch: 6| Step: 5
Training loss: 2.7582786101322836
Validation loss: 2.566044923330235

Epoch: 6| Step: 6
Training loss: 2.775337879128009
Validation loss: 2.578259605953337

Epoch: 6| Step: 7
Training loss: 2.4026011755496253
Validation loss: 2.6220569275309886

Epoch: 6| Step: 8
Training loss: 2.813807882749885
Validation loss: 2.6072873390426694

Epoch: 6| Step: 9
Training loss: 2.809327858602545
Validation loss: 2.6084930101413697

Epoch: 6| Step: 10
Training loss: 1.662365903680756
Validation loss: 2.558420768625998

Epoch: 6| Step: 11
Training loss: 2.226964439118448
Validation loss: 2.576180913801824

Epoch: 6| Step: 12
Training loss: 2.0166354936234376
Validation loss: 2.571393933480419

Epoch: 6| Step: 13
Training loss: 2.2171888635051853
Validation loss: 2.6498026595003377

Epoch: 340| Step: 0
Training loss: 2.466137433197206
Validation loss: 2.5629319177879326

Epoch: 6| Step: 1
Training loss: 1.9701093794379698
Validation loss: 2.6117189728604995

Epoch: 6| Step: 2
Training loss: 2.0362606749421643
Validation loss: 2.5768018562067154

Epoch: 6| Step: 3
Training loss: 2.4262447190853704
Validation loss: 2.6130905053550597

Epoch: 6| Step: 4
Training loss: 1.7369378202703734
Validation loss: 2.5455455348756693

Epoch: 6| Step: 5
Training loss: 1.9538503291849663
Validation loss: 2.6977294262690528

Epoch: 6| Step: 6
Training loss: 2.351186221614987
Validation loss: 2.5787356571071847

Epoch: 6| Step: 7
Training loss: 2.533393329194362
Validation loss: 2.609627165070236

Epoch: 6| Step: 8
Training loss: 2.087184119166837
Validation loss: 2.557752921823734

Epoch: 6| Step: 9
Training loss: 2.886143855558913
Validation loss: 2.6523297039607714

Epoch: 6| Step: 10
Training loss: 2.5705352964918133
Validation loss: 2.539898185678945

Epoch: 6| Step: 11
Training loss: 1.9785839494542155
Validation loss: 2.5582883034894772

Epoch: 6| Step: 12
Training loss: 2.4360384349453033
Validation loss: 2.560214702619804

Epoch: 6| Step: 13
Training loss: 3.542196136989084
Validation loss: 2.610268355231383

Epoch: 341| Step: 0
Training loss: 2.382215981781711
Validation loss: 2.5770588818040205

Epoch: 6| Step: 1
Training loss: 2.1183450497539096
Validation loss: 2.584732157918018

Epoch: 6| Step: 2
Training loss: 1.9404869435909817
Validation loss: 2.5901523907863604

Epoch: 6| Step: 3
Training loss: 1.7797934617004427
Validation loss: 2.601220895322594

Epoch: 6| Step: 4
Training loss: 3.273424098458545
Validation loss: 2.63236546292797

Epoch: 6| Step: 5
Training loss: 2.4514950725358853
Validation loss: 2.595612080048296

Epoch: 6| Step: 6
Training loss: 2.014004432900635
Validation loss: 2.528431101491234

Epoch: 6| Step: 7
Training loss: 2.4568175691439116
Validation loss: 2.6196773434548613

Epoch: 6| Step: 8
Training loss: 2.5696779528754456
Validation loss: 2.6420066361119736

Epoch: 6| Step: 9
Training loss: 1.55527810998215
Validation loss: 2.6809934133474527

Epoch: 6| Step: 10
Training loss: 2.3253571102752404
Validation loss: 2.539925961769062

Epoch: 6| Step: 11
Training loss: 2.5876898691294454
Validation loss: 2.5784929845067612

Epoch: 6| Step: 12
Training loss: 2.796256055488561
Validation loss: 2.6212948199853217

Epoch: 6| Step: 13
Training loss: 2.069309898741909
Validation loss: 2.5950875528252455

Epoch: 342| Step: 0
Training loss: 2.1131167532876414
Validation loss: 2.4889839040427213

Epoch: 6| Step: 1
Training loss: 2.0752019760922424
Validation loss: 2.5609376553037495

Epoch: 6| Step: 2
Training loss: 2.488312006929466
Validation loss: 2.5245438602653367

Epoch: 6| Step: 3
Training loss: 2.2824528279605767
Validation loss: 2.5542850278329814

Epoch: 6| Step: 4
Training loss: 2.0154398751816966
Validation loss: 2.7031767602683563

Epoch: 6| Step: 5
Training loss: 2.387983870280886
Validation loss: 2.5966179000444627

Epoch: 6| Step: 6
Training loss: 2.2317962704384375
Validation loss: 2.5266117932177727

Epoch: 6| Step: 7
Training loss: 2.6774704550600976
Validation loss: 2.588041388465155

Epoch: 6| Step: 8
Training loss: 2.057092108081598
Validation loss: 2.638744759325169

Epoch: 6| Step: 9
Training loss: 2.3345169289784584
Validation loss: 2.5868842886224632

Epoch: 6| Step: 10
Training loss: 2.854636179228323
Validation loss: 2.6583832910609884

Epoch: 6| Step: 11
Training loss: 1.8161347873425855
Validation loss: 2.6016721979794424

Epoch: 6| Step: 12
Training loss: 2.388864704374374
Validation loss: 2.630181795609961

Epoch: 6| Step: 13
Training loss: 3.283946645807414
Validation loss: 2.544032984546643

Epoch: 343| Step: 0
Training loss: 2.1656609426270794
Validation loss: 2.5501679533054102

Epoch: 6| Step: 1
Training loss: 2.200567289384963
Validation loss: 2.53916939661054

Epoch: 6| Step: 2
Training loss: 2.3443275248745166
Validation loss: 2.6635884899046847

Epoch: 6| Step: 3
Training loss: 2.1654454849064675
Validation loss: 2.595873094619378

Epoch: 6| Step: 4
Training loss: 2.1314714288767562
Validation loss: 2.6237011639258316

Epoch: 6| Step: 5
Training loss: 3.0281776510253544
Validation loss: 2.6649805472570423

Epoch: 6| Step: 6
Training loss: 2.7019137276091683
Validation loss: 2.648274745230244

Epoch: 6| Step: 7
Training loss: 2.350360144756244
Validation loss: 2.5746376582717647

Epoch: 6| Step: 8
Training loss: 2.2314030015135264
Validation loss: 2.5928759485315105

Epoch: 6| Step: 9
Training loss: 2.390522474695933
Validation loss: 2.6840369082584687

Epoch: 6| Step: 10
Training loss: 2.3870785406109727
Validation loss: 2.587751507664066

Epoch: 6| Step: 11
Training loss: 2.301262434429037
Validation loss: 2.5425265189324

Epoch: 6| Step: 12
Training loss: 1.934094974789433
Validation loss: 2.6797174596581135

Epoch: 6| Step: 13
Training loss: 1.4714078190116542
Validation loss: 2.533995437507502

Epoch: 344| Step: 0
Training loss: 2.198325373780034
Validation loss: 2.645051790525122

Epoch: 6| Step: 1
Training loss: 2.3640647913385293
Validation loss: 2.62014740366513

Epoch: 6| Step: 2
Training loss: 2.848685205583919
Validation loss: 2.535225743190844

Epoch: 6| Step: 3
Training loss: 2.6045419854866223
Validation loss: 2.6103790239896374

Epoch: 6| Step: 4
Training loss: 2.5673012762228566
Validation loss: 2.6633414882805764

Epoch: 6| Step: 5
Training loss: 2.3723494144480863
Validation loss: 2.605351151036163

Epoch: 6| Step: 6
Training loss: 2.6016811767636177
Validation loss: 2.5362927182996495

Epoch: 6| Step: 7
Training loss: 1.4770777373573318
Validation loss: 2.5540918776853947

Epoch: 6| Step: 8
Training loss: 2.3766184863556665
Validation loss: 2.5652943643645103

Epoch: 6| Step: 9
Training loss: 2.1517334226756626
Validation loss: 2.6167851591377524

Epoch: 6| Step: 10
Training loss: 2.694403542102198
Validation loss: 2.6741015954191933

Epoch: 6| Step: 11
Training loss: 1.42585783452279
Validation loss: 2.673588352419912

Epoch: 6| Step: 12
Training loss: 2.1953025084570226
Validation loss: 2.5876496461413714

Epoch: 6| Step: 13
Training loss: 2.627276568726464
Validation loss: 2.5192926964050746

Epoch: 345| Step: 0
Training loss: 2.375279259576465
Validation loss: 2.5989823556139555

Epoch: 6| Step: 1
Training loss: 2.5372215757161976
Validation loss: 2.5462987718376424

Epoch: 6| Step: 2
Training loss: 1.9605276583778477
Validation loss: 2.5850307083075155

Epoch: 6| Step: 3
Training loss: 2.376939684188067
Validation loss: 2.611967887645907

Epoch: 6| Step: 4
Training loss: 2.8783447049226827
Validation loss: 2.55474392644001

Epoch: 6| Step: 5
Training loss: 2.3921568706004193
Validation loss: 2.6440876912478863

Epoch: 6| Step: 6
Training loss: 2.1455498171667644
Validation loss: 2.5866927718856085

Epoch: 6| Step: 7
Training loss: 1.968499848958524
Validation loss: 2.5957864623762283

Epoch: 6| Step: 8
Training loss: 2.708620867993666
Validation loss: 2.638336643456368

Epoch: 6| Step: 9
Training loss: 2.2460967221447725
Validation loss: 2.6316549709955646

Epoch: 6| Step: 10
Training loss: 2.4104027521582996
Validation loss: 2.6790792664114966

Epoch: 6| Step: 11
Training loss: 2.292206775711652
Validation loss: 2.553840574342084

Epoch: 6| Step: 12
Training loss: 1.9699929567395087
Validation loss: 2.564357235596732

Epoch: 6| Step: 13
Training loss: 1.9270736350425477
Validation loss: 2.5723674902656017

Epoch: 346| Step: 0
Training loss: 2.9298636014781647
Validation loss: 2.657470688051688

Epoch: 6| Step: 1
Training loss: 2.0936124386363613
Validation loss: 2.592555821220335

Epoch: 6| Step: 2
Training loss: 1.9659465629867174
Validation loss: 2.6093440607575107

Epoch: 6| Step: 3
Training loss: 1.2440578367274757
Validation loss: 2.626217134607261

Epoch: 6| Step: 4
Training loss: 2.2175683111874402
Validation loss: 2.5477940073806966

Epoch: 6| Step: 5
Training loss: 2.442144029148659
Validation loss: 2.620375296412796

Epoch: 6| Step: 6
Training loss: 2.4069295146655447
Validation loss: 2.6022874011358312

Epoch: 6| Step: 7
Training loss: 2.460957069924668
Validation loss: 2.5607003065673903

Epoch: 6| Step: 8
Training loss: 2.9590433549196176
Validation loss: 2.6035647750466633

Epoch: 6| Step: 9
Training loss: 1.6800717646166443
Validation loss: 2.6560341908410985

Epoch: 6| Step: 10
Training loss: 2.6806032267687048
Validation loss: 2.6194566068682037

Epoch: 6| Step: 11
Training loss: 2.552150574920663
Validation loss: 2.599337961653148

Epoch: 6| Step: 12
Training loss: 2.083825116923184
Validation loss: 2.621088411631299

Epoch: 6| Step: 13
Training loss: 1.980246928355798
Validation loss: 2.696513630994432

Epoch: 347| Step: 0
Training loss: 2.0497707238729843
Validation loss: 2.539452437755877

Epoch: 6| Step: 1
Training loss: 2.3066154045774057
Validation loss: 2.57350237532033

Epoch: 6| Step: 2
Training loss: 2.1453031113232286
Validation loss: 2.6095451627151927

Epoch: 6| Step: 3
Training loss: 2.240124647384947
Validation loss: 2.5381757390808257

Epoch: 6| Step: 4
Training loss: 2.1502786411435393
Validation loss: 2.6193162547928606

Epoch: 6| Step: 5
Training loss: 2.497860278929344
Validation loss: 2.557617862084894

Epoch: 6| Step: 6
Training loss: 2.1291335798207247
Validation loss: 2.62553627251499

Epoch: 6| Step: 7
Training loss: 1.8533087756681967
Validation loss: 2.5608262709457055

Epoch: 6| Step: 8
Training loss: 2.2909958522297855
Validation loss: 2.5630897275572577

Epoch: 6| Step: 9
Training loss: 2.554531920942372
Validation loss: 2.595457151497901

Epoch: 6| Step: 10
Training loss: 2.2244964115442274
Validation loss: 2.7651134731905396

Epoch: 6| Step: 11
Training loss: 2.878203556011782
Validation loss: 2.5701112508509447

Epoch: 6| Step: 12
Training loss: 2.727795341298762
Validation loss: 2.5616018970957093

Epoch: 6| Step: 13
Training loss: 2.5788691516000224
Validation loss: 2.6621803768548444

Epoch: 348| Step: 0
Training loss: 1.997108037540994
Validation loss: 2.668791365441582

Epoch: 6| Step: 1
Training loss: 2.172284753142776
Validation loss: 2.5499037361513603

Epoch: 6| Step: 2
Training loss: 2.585773935360088
Validation loss: 2.589373721103117

Epoch: 6| Step: 3
Training loss: 2.240066535336206
Validation loss: 2.65473942520727

Epoch: 6| Step: 4
Training loss: 2.171798594935288
Validation loss: 2.6882368347809495

Epoch: 6| Step: 5
Training loss: 2.9021272026592904
Validation loss: 2.5321363859175827

Epoch: 6| Step: 6
Training loss: 2.438599949634107
Validation loss: 2.574653416626112

Epoch: 6| Step: 7
Training loss: 2.6820305459532463
Validation loss: 2.6402574829412626

Epoch: 6| Step: 8
Training loss: 2.018016490600473
Validation loss: 2.597401557727751

Epoch: 6| Step: 9
Training loss: 2.440319484681646
Validation loss: 2.5809141532556046

Epoch: 6| Step: 10
Training loss: 1.7766518388359631
Validation loss: 2.6173540811997302

Epoch: 6| Step: 11
Training loss: 2.553925566835071
Validation loss: 2.59965549352675

Epoch: 6| Step: 12
Training loss: 2.140526985096376
Validation loss: 2.5717472824848393

Epoch: 6| Step: 13
Training loss: 1.9708520475739708
Validation loss: 2.644371233994949

Epoch: 349| Step: 0
Training loss: 1.7145552338174443
Validation loss: 2.535373828259877

Epoch: 6| Step: 1
Training loss: 2.3865163564323297
Validation loss: 2.6192950707673748

Epoch: 6| Step: 2
Training loss: 2.1474648233181646
Validation loss: 2.6733698222813707

Epoch: 6| Step: 3
Training loss: 2.336604504740215
Validation loss: 2.7231109075214963

Epoch: 6| Step: 4
Training loss: 2.7126409362181416
Validation loss: 2.6548261364624754

Epoch: 6| Step: 5
Training loss: 2.6358883602715313
Validation loss: 2.6593219730055155

Epoch: 6| Step: 6
Training loss: 1.7681267492852673
Validation loss: 2.62506843610506

Epoch: 6| Step: 7
Training loss: 2.9570241547553584
Validation loss: 2.6351905001646703

Epoch: 6| Step: 8
Training loss: 1.9578926794586966
Validation loss: 2.6222594957163086

Epoch: 6| Step: 9
Training loss: 2.1691970232572255
Validation loss: 2.5417890520921835

Epoch: 6| Step: 10
Training loss: 2.6383852517117727
Validation loss: 2.592682248139488

Epoch: 6| Step: 11
Training loss: 2.260878649026745
Validation loss: 2.614164261880488

Epoch: 6| Step: 12
Training loss: 2.22708477118945
Validation loss: 2.605660385137026

Epoch: 6| Step: 13
Training loss: 2.1335693804963554
Validation loss: 2.6271069826649645

Epoch: 350| Step: 0
Training loss: 2.034775476840111
Validation loss: 2.6075021960383213

Epoch: 6| Step: 1
Training loss: 2.6576077749624325
Validation loss: 2.620192505158846

Epoch: 6| Step: 2
Training loss: 2.273030457647953
Validation loss: 2.492187384788862

Epoch: 6| Step: 3
Training loss: 2.446704602306888
Validation loss: 2.4822506579510537

Epoch: 6| Step: 4
Training loss: 2.7123363744368545
Validation loss: 2.583701093327038

Epoch: 6| Step: 5
Training loss: 2.429606641791607
Validation loss: 2.582683289587664

Epoch: 6| Step: 6
Training loss: 2.9830757228794273
Validation loss: 2.563817496649663

Epoch: 6| Step: 7
Training loss: 2.1574845028140555
Validation loss: 2.573255420903045

Epoch: 6| Step: 8
Training loss: 1.9773714724511113
Validation loss: 2.588893605408285

Epoch: 6| Step: 9
Training loss: 2.20807259897766
Validation loss: 2.5634196482257217

Epoch: 6| Step: 10
Training loss: 1.6018810420642366
Validation loss: 2.563228022545711

Epoch: 6| Step: 11
Training loss: 1.780017493301327
Validation loss: 2.6414288372962234

Epoch: 6| Step: 12
Training loss: 2.3195649557982807
Validation loss: 2.5567765525460935

Epoch: 6| Step: 13
Training loss: 2.36282066712105
Validation loss: 2.5949275346948264

Epoch: 351| Step: 0
Training loss: 2.4276027751188307
Validation loss: 2.6067511005709294

Epoch: 6| Step: 1
Training loss: 2.201003114718045
Validation loss: 2.5823253245507845

Epoch: 6| Step: 2
Training loss: 1.7671745724799661
Validation loss: 2.6009946705569127

Epoch: 6| Step: 3
Training loss: 2.2309360315307623
Validation loss: 2.640582400868678

Epoch: 6| Step: 4
Training loss: 3.182017079861955
Validation loss: 2.599526224284003

Epoch: 6| Step: 5
Training loss: 2.46412399108832
Validation loss: 2.5830006863252106

Epoch: 6| Step: 6
Training loss: 2.0649112131829925
Validation loss: 2.56852296467086

Epoch: 6| Step: 7
Training loss: 1.9808937233767991
Validation loss: 2.559036531439561

Epoch: 6| Step: 8
Training loss: 2.442784571864366
Validation loss: 2.5423589725471962

Epoch: 6| Step: 9
Training loss: 2.4055485879720324
Validation loss: 2.6050841797664344

Epoch: 6| Step: 10
Training loss: 2.086234082343539
Validation loss: 2.6212889558580486

Epoch: 6| Step: 11
Training loss: 1.6382942719458182
Validation loss: 2.5889240745925663

Epoch: 6| Step: 12
Training loss: 3.0104512319373398
Validation loss: 2.6613504112460458

Epoch: 6| Step: 13
Training loss: 1.9085302004264804
Validation loss: 2.5911048124498963

Epoch: 352| Step: 0
Training loss: 2.1376019592952886
Validation loss: 2.5533683396306066

Epoch: 6| Step: 1
Training loss: 2.4110032730871427
Validation loss: 2.5350553367759114

Epoch: 6| Step: 2
Training loss: 2.288447274605623
Validation loss: 2.6856550956093894

Epoch: 6| Step: 3
Training loss: 2.553074505422201
Validation loss: 2.5997157542561684

Epoch: 6| Step: 4
Training loss: 2.189930029321758
Validation loss: 2.587289037947668

Epoch: 6| Step: 5
Training loss: 2.3726439585287276
Validation loss: 2.6570241631175535

Epoch: 6| Step: 6
Training loss: 2.794391915055359
Validation loss: 2.500917190560915

Epoch: 6| Step: 7
Training loss: 1.9724932008343266
Validation loss: 2.5698179373931387

Epoch: 6| Step: 8
Training loss: 2.1854858935373684
Validation loss: 2.514303559036915

Epoch: 6| Step: 9
Training loss: 2.3713028892526835
Validation loss: 2.5779269264478843

Epoch: 6| Step: 10
Training loss: 1.5558324843603404
Validation loss: 2.547006160404466

Epoch: 6| Step: 11
Training loss: 2.0671509985321395
Validation loss: 2.5890348680184796

Epoch: 6| Step: 12
Training loss: 2.007157868414997
Validation loss: 2.507432946403867

Epoch: 6| Step: 13
Training loss: 2.4679044410221986
Validation loss: 2.6229234286028276

Epoch: 353| Step: 0
Training loss: 2.0168614106951352
Validation loss: 2.6646145720209624

Epoch: 6| Step: 1
Training loss: 2.3488871922402144
Validation loss: 2.6517094389732176

Epoch: 6| Step: 2
Training loss: 2.3599440538919563
Validation loss: 2.6286430530048235

Epoch: 6| Step: 3
Training loss: 1.8752837919997893
Validation loss: 2.613943726651204

Epoch: 6| Step: 4
Training loss: 2.5911962047390116
Validation loss: 2.653043526899469

Epoch: 6| Step: 5
Training loss: 2.394805743118161
Validation loss: 2.5865586196660644

Epoch: 6| Step: 6
Training loss: 2.6103546679157548
Validation loss: 2.6435821202179093

Epoch: 6| Step: 7
Training loss: 2.2934871263094903
Validation loss: 2.6555086108574133

Epoch: 6| Step: 8
Training loss: 2.5029204476699816
Validation loss: 2.558200367389594

Epoch: 6| Step: 9
Training loss: 2.309109754389904
Validation loss: 2.549315236715008

Epoch: 6| Step: 10
Training loss: 2.283037504351791
Validation loss: 2.5891585281165845

Epoch: 6| Step: 11
Training loss: 2.039943460915147
Validation loss: 2.5917497333194945

Epoch: 6| Step: 12
Training loss: 2.3694728986257214
Validation loss: 2.6575788885944878

Epoch: 6| Step: 13
Training loss: 2.5691862566565358
Validation loss: 2.6748231776665636

Epoch: 354| Step: 0
Training loss: 1.8241198102435057
Validation loss: 2.5566792180877815

Epoch: 6| Step: 1
Training loss: 2.490722512666017
Validation loss: 2.6138245106055784

Epoch: 6| Step: 2
Training loss: 2.2923056896399876
Validation loss: 2.5629911794858584

Epoch: 6| Step: 3
Training loss: 1.9272633511428072
Validation loss: 2.5214945177666164

Epoch: 6| Step: 4
Training loss: 2.3137016267423793
Validation loss: 2.6129329250662785

Epoch: 6| Step: 5
Training loss: 1.8890054244513348
Validation loss: 2.56783825722575

Epoch: 6| Step: 6
Training loss: 2.135251728914251
Validation loss: 2.626387204686083

Epoch: 6| Step: 7
Training loss: 2.2478959524233195
Validation loss: 2.59299899339638

Epoch: 6| Step: 8
Training loss: 2.1915559496551187
Validation loss: 2.5592878384503983

Epoch: 6| Step: 9
Training loss: 2.9399927803521813
Validation loss: 2.6020926550276173

Epoch: 6| Step: 10
Training loss: 2.717739750622163
Validation loss: 2.5947814780228935

Epoch: 6| Step: 11
Training loss: 2.3857299954278113
Validation loss: 2.582045268398838

Epoch: 6| Step: 12
Training loss: 1.8689008058663703
Validation loss: 2.471848507731123

Epoch: 6| Step: 13
Training loss: 2.4934110597575248
Validation loss: 2.5822215527747

Epoch: 355| Step: 0
Training loss: 1.8507575365691424
Validation loss: 2.5651036093181183

Epoch: 6| Step: 1
Training loss: 2.5906133414490475
Validation loss: 2.6376580661472415

Epoch: 6| Step: 2
Training loss: 1.8155925281660859
Validation loss: 2.5934559131142225

Epoch: 6| Step: 3
Training loss: 3.0808152578819525
Validation loss: 2.564912531238336

Epoch: 6| Step: 4
Training loss: 1.9225770861942073
Validation loss: 2.6204504872979024

Epoch: 6| Step: 5
Training loss: 2.557275050796219
Validation loss: 2.5777695496244775

Epoch: 6| Step: 6
Training loss: 2.5999378710439554
Validation loss: 2.604138725541049

Epoch: 6| Step: 7
Training loss: 2.007400054723973
Validation loss: 2.5934916709987377

Epoch: 6| Step: 8
Training loss: 1.996542803574195
Validation loss: 2.5628670970487732

Epoch: 6| Step: 9
Training loss: 2.453086804135114
Validation loss: 2.594620974651743

Epoch: 6| Step: 10
Training loss: 3.305198684006648
Validation loss: 2.6393627507328086

Epoch: 6| Step: 11
Training loss: 2.1085185254852408
Validation loss: 2.6654451563061885

Epoch: 6| Step: 12
Training loss: 1.8477298004156988
Validation loss: 2.554519480711566

Epoch: 6| Step: 13
Training loss: 2.4995946555547035
Validation loss: 2.5386846011557127

Epoch: 356| Step: 0
Training loss: 2.086938282206207
Validation loss: 2.546512795677823

Epoch: 6| Step: 1
Training loss: 2.349344925176721
Validation loss: 2.6590907600133096

Epoch: 6| Step: 2
Training loss: 2.0839271716317342
Validation loss: 2.652379947301604

Epoch: 6| Step: 3
Training loss: 2.983275525547066
Validation loss: 2.533413744990371

Epoch: 6| Step: 4
Training loss: 2.527702671607368
Validation loss: 2.614300413030274

Epoch: 6| Step: 5
Training loss: 2.153743448009477
Validation loss: 2.5659516141413437

Epoch: 6| Step: 6
Training loss: 2.46817280263003
Validation loss: 2.5110923039340096

Epoch: 6| Step: 7
Training loss: 1.626931802854916
Validation loss: 2.515206244734402

Epoch: 6| Step: 8
Training loss: 1.7079945515226347
Validation loss: 2.7040057037722596

Epoch: 6| Step: 9
Training loss: 1.9636478007510123
Validation loss: 2.558627111459632

Epoch: 6| Step: 10
Training loss: 2.154610715608606
Validation loss: 2.674525214707855

Epoch: 6| Step: 11
Training loss: 3.366548765277173
Validation loss: 2.599899906285832

Epoch: 6| Step: 12
Training loss: 2.507733875598927
Validation loss: 2.6441184716732056

Epoch: 6| Step: 13
Training loss: 1.7352176715503225
Validation loss: 2.5778049403324705

Epoch: 357| Step: 0
Training loss: 2.6871698753399134
Validation loss: 2.606587996164182

Epoch: 6| Step: 1
Training loss: 2.045626077299129
Validation loss: 2.6230493750657375

Epoch: 6| Step: 2
Training loss: 1.9309742455999797
Validation loss: 2.6041109147205406

Epoch: 6| Step: 3
Training loss: 2.2713858139421377
Validation loss: 2.6008473636887635

Epoch: 6| Step: 4
Training loss: 1.7059753085067977
Validation loss: 2.590604913111842

Epoch: 6| Step: 5
Training loss: 2.632196280700175
Validation loss: 2.6258609217421944

Epoch: 6| Step: 6
Training loss: 2.5620890962473135
Validation loss: 2.550387737916671

Epoch: 6| Step: 7
Training loss: 1.6372100893760584
Validation loss: 2.583012087699186

Epoch: 6| Step: 8
Training loss: 1.9533539294544677
Validation loss: 2.6435706498697824

Epoch: 6| Step: 9
Training loss: 1.9948623950129045
Validation loss: 2.5668207613209533

Epoch: 6| Step: 10
Training loss: 2.6398964503238793
Validation loss: 2.609902433041112

Epoch: 6| Step: 11
Training loss: 2.790540543973044
Validation loss: 2.6657207023133735

Epoch: 6| Step: 12
Training loss: 2.6877289607967025
Validation loss: 2.5804918985847713

Epoch: 6| Step: 13
Training loss: 2.3533656915415846
Validation loss: 2.5148661722518946

Epoch: 358| Step: 0
Training loss: 2.0928069310928032
Validation loss: 2.6383507649634694

Epoch: 6| Step: 1
Training loss: 2.716255183348821
Validation loss: 2.5685701403929264

Epoch: 6| Step: 2
Training loss: 2.6013861702396026
Validation loss: 2.554839490298105

Epoch: 6| Step: 3
Training loss: 2.2280801519773146
Validation loss: 2.593087323830201

Epoch: 6| Step: 4
Training loss: 2.114881322250057
Validation loss: 2.6182913384399753

Epoch: 6| Step: 5
Training loss: 2.001324453499799
Validation loss: 2.52126125431548

Epoch: 6| Step: 6
Training loss: 1.9966866943212551
Validation loss: 2.5387312821518657

Epoch: 6| Step: 7
Training loss: 2.208995060173925
Validation loss: 2.6177606221125234

Epoch: 6| Step: 8
Training loss: 2.0669890593233204
Validation loss: 2.659822911802586

Epoch: 6| Step: 9
Training loss: 1.754031850145043
Validation loss: 2.57451441099217

Epoch: 6| Step: 10
Training loss: 2.655581580938537
Validation loss: 2.6525166091676518

Epoch: 6| Step: 11
Training loss: 3.1637877545163238
Validation loss: 2.5849250754925412

Epoch: 6| Step: 12
Training loss: 2.317460384750448
Validation loss: 2.492046463178292

Epoch: 6| Step: 13
Training loss: 2.591187095633041
Validation loss: 2.6669648187094044

Epoch: 359| Step: 0
Training loss: 2.51391742636241
Validation loss: 2.5736320477207286

Epoch: 6| Step: 1
Training loss: 2.3669316622527177
Validation loss: 2.579527050139611

Epoch: 6| Step: 2
Training loss: 2.7607045341436502
Validation loss: 2.5970207612061897

Epoch: 6| Step: 3
Training loss: 1.807828341639685
Validation loss: 2.6598926012571047

Epoch: 6| Step: 4
Training loss: 2.0379387693182136
Validation loss: 2.6792366736600637

Epoch: 6| Step: 5
Training loss: 2.625392248728993
Validation loss: 2.6484797675780403

Epoch: 6| Step: 6
Training loss: 2.201015355148031
Validation loss: 2.5978225993992865

Epoch: 6| Step: 7
Training loss: 1.5835141614082562
Validation loss: 2.6466790458438463

Epoch: 6| Step: 8
Training loss: 1.8586966294897844
Validation loss: 2.6748489555747477

Epoch: 6| Step: 9
Training loss: 2.082375904063134
Validation loss: 2.603249198171451

Epoch: 6| Step: 10
Training loss: 2.187716446113662
Validation loss: 2.568713205308185

Epoch: 6| Step: 11
Training loss: 1.8001747682286273
Validation loss: 2.618484231170308

Epoch: 6| Step: 12
Training loss: 2.9763266802910766
Validation loss: 2.5372305097686305

Epoch: 6| Step: 13
Training loss: 3.0363434147667587
Validation loss: 2.62301281112257

Epoch: 360| Step: 0
Training loss: 2.43448187969278
Validation loss: 2.590368562147554

Epoch: 6| Step: 1
Training loss: 2.393289813635106
Validation loss: 2.6878048055486

Epoch: 6| Step: 2
Training loss: 2.2541084926053463
Validation loss: 2.594299550752125

Epoch: 6| Step: 3
Training loss: 1.4844646226028013
Validation loss: 2.6082276751002738

Epoch: 6| Step: 4
Training loss: 2.4338907761653426
Validation loss: 2.552608593815044

Epoch: 6| Step: 5
Training loss: 2.6799360777220547
Validation loss: 2.5807605992860125

Epoch: 6| Step: 6
Training loss: 2.182997729689518
Validation loss: 2.569266872003371

Epoch: 6| Step: 7
Training loss: 2.1015672648209227
Validation loss: 2.6506563340114413

Epoch: 6| Step: 8
Training loss: 2.6908046011179825
Validation loss: 2.6449420995334

Epoch: 6| Step: 9
Training loss: 2.535632072666413
Validation loss: 2.68708481745043

Epoch: 6| Step: 10
Training loss: 2.097034440324882
Validation loss: 2.610597197135601

Epoch: 6| Step: 11
Training loss: 2.460818333238287
Validation loss: 2.5918297507180847

Epoch: 6| Step: 12
Training loss: 1.9111016865000117
Validation loss: 2.613495176740638

Epoch: 6| Step: 13
Training loss: 2.512496709109756
Validation loss: 2.6243978103602026

Epoch: 361| Step: 0
Training loss: 2.3851513000097055
Validation loss: 2.6500816100082702

Epoch: 6| Step: 1
Training loss: 2.457150115274881
Validation loss: 2.593694463659886

Epoch: 6| Step: 2
Training loss: 2.413450589448887
Validation loss: 2.6118554045989

Epoch: 6| Step: 3
Training loss: 1.5437399952676265
Validation loss: 2.5562386709548353

Epoch: 6| Step: 4
Training loss: 2.2975296852095175
Validation loss: 2.596196384535438

Epoch: 6| Step: 5
Training loss: 2.1809977213389837
Validation loss: 2.649409177921919

Epoch: 6| Step: 6
Training loss: 2.4541354679872818
Validation loss: 2.6357362971571923

Epoch: 6| Step: 7
Training loss: 2.2441155521064537
Validation loss: 2.6150142221635213

Epoch: 6| Step: 8
Training loss: 1.6159100485826783
Validation loss: 2.548790100012664

Epoch: 6| Step: 9
Training loss: 2.395174372622702
Validation loss: 2.567551401365481

Epoch: 6| Step: 10
Training loss: 2.5944782751338664
Validation loss: 2.6239534827278077

Epoch: 6| Step: 11
Training loss: 2.175253456518954
Validation loss: 2.5419393346436783

Epoch: 6| Step: 12
Training loss: 2.15470698336063
Validation loss: 2.6000385456682955

Epoch: 6| Step: 13
Training loss: 2.1361439156572897
Validation loss: 2.5650689638548863

Epoch: 362| Step: 0
Training loss: 2.199177336768713
Validation loss: 2.58308319292582

Epoch: 6| Step: 1
Training loss: 1.4838937079518275
Validation loss: 2.5789726169084206

Epoch: 6| Step: 2
Training loss: 2.536024136100498
Validation loss: 2.7074917100073037

Epoch: 6| Step: 3
Training loss: 2.1434791638531974
Validation loss: 2.6455698952022497

Epoch: 6| Step: 4
Training loss: 2.116213979397618
Validation loss: 2.5068674127293735

Epoch: 6| Step: 5
Training loss: 2.404802159283164
Validation loss: 2.612481636477005

Epoch: 6| Step: 6
Training loss: 2.0455944918913787
Validation loss: 2.5401224407469494

Epoch: 6| Step: 7
Training loss: 2.0118585926819614
Validation loss: 2.542828433721391

Epoch: 6| Step: 8
Training loss: 2.5296980256208603
Validation loss: 2.584397965098655

Epoch: 6| Step: 9
Training loss: 2.8190129633209966
Validation loss: 2.5337456893267034

Epoch: 6| Step: 10
Training loss: 1.9912219531328454
Validation loss: 2.5778438371296977

Epoch: 6| Step: 11
Training loss: 2.0772044502026983
Validation loss: 2.6730008058967183

Epoch: 6| Step: 12
Training loss: 2.526329721498137
Validation loss: 2.587560346396165

Epoch: 6| Step: 13
Training loss: 2.428993346725404
Validation loss: 2.593487546026601

Epoch: 363| Step: 0
Training loss: 2.1727684982367386
Validation loss: 2.6668204531112343

Epoch: 6| Step: 1
Training loss: 2.155645202736709
Validation loss: 2.5457933289199177

Epoch: 6| Step: 2
Training loss: 2.2530723364570666
Validation loss: 2.6883783796142966

Epoch: 6| Step: 3
Training loss: 1.6655292046860022
Validation loss: 2.590922801860774

Epoch: 6| Step: 4
Training loss: 2.423589481037417
Validation loss: 2.636158184956398

Epoch: 6| Step: 5
Training loss: 2.4341540724826736
Validation loss: 2.6302298313571226

Epoch: 6| Step: 6
Training loss: 1.849499933857954
Validation loss: 2.5462215281555483

Epoch: 6| Step: 7
Training loss: 2.3837982640133757
Validation loss: 2.6771940231821674

Epoch: 6| Step: 8
Training loss: 2.0235124375300657
Validation loss: 2.5885761567604693

Epoch: 6| Step: 9
Training loss: 2.154289017331828
Validation loss: 2.5122428205304983

Epoch: 6| Step: 10
Training loss: 2.7094703243958476
Validation loss: 2.586441384028024

Epoch: 6| Step: 11
Training loss: 2.460112902833921
Validation loss: 2.610314556502319

Epoch: 6| Step: 12
Training loss: 2.3062519518009186
Validation loss: 2.587128124252204

Epoch: 6| Step: 13
Training loss: 3.151679478348127
Validation loss: 2.58747638887596

Epoch: 364| Step: 0
Training loss: 1.9666965614352796
Validation loss: 2.5470663381684684

Epoch: 6| Step: 1
Training loss: 2.2375806740650086
Validation loss: 2.578705745058389

Epoch: 6| Step: 2
Training loss: 2.975420074297119
Validation loss: 2.6250995025293

Epoch: 6| Step: 3
Training loss: 1.7203686115146555
Validation loss: 2.588592289790091

Epoch: 6| Step: 4
Training loss: 2.0945833739667767
Validation loss: 2.6034137446278107

Epoch: 6| Step: 5
Training loss: 2.4599948591473213
Validation loss: 2.71201050758601

Epoch: 6| Step: 6
Training loss: 3.1749024623997433
Validation loss: 2.635618082897322

Epoch: 6| Step: 7
Training loss: 2.075680090435323
Validation loss: 2.6339200840337806

Epoch: 6| Step: 8
Training loss: 2.4455802210299042
Validation loss: 2.5829284071427976

Epoch: 6| Step: 9
Training loss: 1.9509544824230451
Validation loss: 2.6171876890512715

Epoch: 6| Step: 10
Training loss: 2.6730208588944757
Validation loss: 2.6376343390851615

Epoch: 6| Step: 11
Training loss: 2.0392523783120056
Validation loss: 2.5667918190596617

Epoch: 6| Step: 12
Training loss: 2.2997763856737863
Validation loss: 2.566566767810685

Epoch: 6| Step: 13
Training loss: 2.312505258090253
Validation loss: 2.5620672919584293

Epoch: 365| Step: 0
Training loss: 2.511791744328383
Validation loss: 2.5791218560324696

Epoch: 6| Step: 1
Training loss: 2.495574085185298
Validation loss: 2.570359671801587

Epoch: 6| Step: 2
Training loss: 2.4260698966817102
Validation loss: 2.654031627056432

Epoch: 6| Step: 3
Training loss: 1.671138422914164
Validation loss: 2.582380877063195

Epoch: 6| Step: 4
Training loss: 2.4669325693824473
Validation loss: 2.616892718171996

Epoch: 6| Step: 5
Training loss: 2.468325035120761
Validation loss: 2.530912536059018

Epoch: 6| Step: 6
Training loss: 2.739307771658945
Validation loss: 2.518824539093343

Epoch: 6| Step: 7
Training loss: 1.9902575550470227
Validation loss: 2.5269410974896065

Epoch: 6| Step: 8
Training loss: 2.1638245159080096
Validation loss: 2.587023873256274

Epoch: 6| Step: 9
Training loss: 2.3670738872797776
Validation loss: 2.662815000025408

Epoch: 6| Step: 10
Training loss: 1.8951813830931852
Validation loss: 2.638468839298432

Epoch: 6| Step: 11
Training loss: 2.5285042835430893
Validation loss: 2.587570198949285

Epoch: 6| Step: 12
Training loss: 2.0419814457512784
Validation loss: 2.577257876530706

Epoch: 6| Step: 13
Training loss: 1.870735404914387
Validation loss: 2.630452982415554

Epoch: 366| Step: 0
Training loss: 3.0764060860739932
Validation loss: 2.5506769788487174

Epoch: 6| Step: 1
Training loss: 2.3960905738613
Validation loss: 2.603678067219437

Epoch: 6| Step: 2
Training loss: 1.4822482483599821
Validation loss: 2.6003271291910726

Epoch: 6| Step: 3
Training loss: 1.7272083576199846
Validation loss: 2.5885525076766998

Epoch: 6| Step: 4
Training loss: 2.4156827458318118
Validation loss: 2.600418349181771

Epoch: 6| Step: 5
Training loss: 1.3730922816271802
Validation loss: 2.64100904124049

Epoch: 6| Step: 6
Training loss: 2.4094581520387073
Validation loss: 2.577837370945797

Epoch: 6| Step: 7
Training loss: 2.2799339156026828
Validation loss: 2.5843242622973137

Epoch: 6| Step: 8
Training loss: 1.8509649930268175
Validation loss: 2.5539408778112045

Epoch: 6| Step: 9
Training loss: 2.478529284524515
Validation loss: 2.6956860554956656

Epoch: 6| Step: 10
Training loss: 1.6591253692734607
Validation loss: 2.608265708341035

Epoch: 6| Step: 11
Training loss: 2.6747465708819638
Validation loss: 2.619661458620394

Epoch: 6| Step: 12
Training loss: 2.944648161824437
Validation loss: 2.5801627351027427

Epoch: 6| Step: 13
Training loss: 2.391973975062331
Validation loss: 2.616741759450208

Epoch: 367| Step: 0
Training loss: 1.6125604899098092
Validation loss: 2.582967898720331

Epoch: 6| Step: 1
Training loss: 2.3993230421278917
Validation loss: 2.581183187417631

Epoch: 6| Step: 2
Training loss: 2.5234152022283043
Validation loss: 2.54135333920006

Epoch: 6| Step: 3
Training loss: 3.2852407256343046
Validation loss: 2.7630312231089884

Epoch: 6| Step: 4
Training loss: 2.033369161988492
Validation loss: 2.61753769553338

Epoch: 6| Step: 5
Training loss: 2.2876194907075647
Validation loss: 2.6455310057431713

Epoch: 6| Step: 6
Training loss: 1.6673701550031312
Validation loss: 2.6381815176168657

Epoch: 6| Step: 7
Training loss: 2.6334467726630555
Validation loss: 2.609218210273953

Epoch: 6| Step: 8
Training loss: 1.4887714529853946
Validation loss: 2.686666124140711

Epoch: 6| Step: 9
Training loss: 2.239371095995171
Validation loss: 2.5420459237077124

Epoch: 6| Step: 10
Training loss: 2.4455205566815126
Validation loss: 2.648262587565446

Epoch: 6| Step: 11
Training loss: 1.9753944654919595
Validation loss: 2.6026903968195003

Epoch: 6| Step: 12
Training loss: 2.2729360545235058
Validation loss: 2.6687975151948566

Epoch: 6| Step: 13
Training loss: 2.5349068305897373
Validation loss: 2.6125413472072805

Epoch: 368| Step: 0
Training loss: 2.0592806573076734
Validation loss: 2.6339430143220603

Epoch: 6| Step: 1
Training loss: 2.1173428974624233
Validation loss: 2.5320126290988676

Epoch: 6| Step: 2
Training loss: 1.8398896229850492
Validation loss: 2.6438794140275768

Epoch: 6| Step: 3
Training loss: 2.0460103079497953
Validation loss: 2.56279065884519

Epoch: 6| Step: 4
Training loss: 2.0490248942913154
Validation loss: 2.611482058979895

Epoch: 6| Step: 5
Training loss: 2.214924590504127
Validation loss: 2.61532686005306

Epoch: 6| Step: 6
Training loss: 2.0948487999736347
Validation loss: 2.6026995365849213

Epoch: 6| Step: 7
Training loss: 3.1353255012582557
Validation loss: 2.565528260814923

Epoch: 6| Step: 8
Training loss: 2.644366531088027
Validation loss: 2.5764263484874643

Epoch: 6| Step: 9
Training loss: 1.9879714334726606
Validation loss: 2.6390895730136656

Epoch: 6| Step: 10
Training loss: 2.052503229805453
Validation loss: 2.6924073948914162

Epoch: 6| Step: 11
Training loss: 2.7567988361776843
Validation loss: 2.578095314051359

Epoch: 6| Step: 12
Training loss: 2.302685090784091
Validation loss: 2.56694273910901

Epoch: 6| Step: 13
Training loss: 1.363292923579475
Validation loss: 2.5170091731576925

Epoch: 369| Step: 0
Training loss: 2.386921326176964
Validation loss: 2.6190856828481897

Epoch: 6| Step: 1
Training loss: 2.2753667347190034
Validation loss: 2.6297496478955424

Epoch: 6| Step: 2
Training loss: 1.9620801780331296
Validation loss: 2.6049662868993555

Epoch: 6| Step: 3
Training loss: 2.829175216669376
Validation loss: 2.535825108373361

Epoch: 6| Step: 4
Training loss: 1.8675076517461566
Validation loss: 2.5804883340128546

Epoch: 6| Step: 5
Training loss: 1.7383364550793208
Validation loss: 2.64050330939689

Epoch: 6| Step: 6
Training loss: 2.1986690396600106
Validation loss: 2.5561674633692175

Epoch: 6| Step: 7
Training loss: 2.158477959027929
Validation loss: 2.6031440180594534

Epoch: 6| Step: 8
Training loss: 2.5631739962810136
Validation loss: 2.6286724748305756

Epoch: 6| Step: 9
Training loss: 2.2038695247474602
Validation loss: 2.5209610887245377

Epoch: 6| Step: 10
Training loss: 2.0867730799507243
Validation loss: 2.622833797701734

Epoch: 6| Step: 11
Training loss: 2.23244686563276
Validation loss: 2.62131221962264

Epoch: 6| Step: 12
Training loss: 1.8559100138332167
Validation loss: 2.601733315572527

Epoch: 6| Step: 13
Training loss: 3.0127603632057287
Validation loss: 2.6189035406516727

Epoch: 370| Step: 0
Training loss: 2.41593381578221
Validation loss: 2.6452218116831716

Epoch: 6| Step: 1
Training loss: 2.077953130742369
Validation loss: 2.622735902190322

Epoch: 6| Step: 2
Training loss: 1.9572407806370355
Validation loss: 2.5632309230108947

Epoch: 6| Step: 3
Training loss: 2.0740033341383737
Validation loss: 2.567731982034481

Epoch: 6| Step: 4
Training loss: 2.190419238299865
Validation loss: 2.6457312669769824

Epoch: 6| Step: 5
Training loss: 2.6788147152814794
Validation loss: 2.5866771701284033

Epoch: 6| Step: 6
Training loss: 2.067628898984539
Validation loss: 2.6336393730546126

Epoch: 6| Step: 7
Training loss: 2.1632843271042805
Validation loss: 2.5820160360938207

Epoch: 6| Step: 8
Training loss: 2.151071716049442
Validation loss: 2.64067502917028

Epoch: 6| Step: 9
Training loss: 2.4170728758627544
Validation loss: 2.7031230112068845

Epoch: 6| Step: 10
Training loss: 2.2470389060984277
Validation loss: 2.5854877402627

Epoch: 6| Step: 11
Training loss: 2.0805276161200044
Validation loss: 2.6806295343847863

Epoch: 6| Step: 12
Training loss: 2.93167640821766
Validation loss: 2.5742768396518856

Epoch: 6| Step: 13
Training loss: 1.890971317572005
Validation loss: 2.648102028357463

Epoch: 371| Step: 0
Training loss: 2.7002793697359504
Validation loss: 2.6446066444679017

Epoch: 6| Step: 1
Training loss: 2.9618253559396295
Validation loss: 2.61188687650885

Epoch: 6| Step: 2
Training loss: 1.911123518416817
Validation loss: 2.533815542947158

Epoch: 6| Step: 3
Training loss: 1.9809780933068137
Validation loss: 2.5043288796924243

Epoch: 6| Step: 4
Training loss: 2.0040418790907077
Validation loss: 2.6121032061815814

Epoch: 6| Step: 5
Training loss: 2.5387114766370926
Validation loss: 2.6270993730400956

Epoch: 6| Step: 6
Training loss: 2.2552091908324785
Validation loss: 2.6204279134316533

Epoch: 6| Step: 7
Training loss: 1.9997531023217245
Validation loss: 2.5371038452665147

Epoch: 6| Step: 8
Training loss: 1.537659911236718
Validation loss: 2.527241143205163

Epoch: 6| Step: 9
Training loss: 2.385675630019706
Validation loss: 2.584102453272016

Epoch: 6| Step: 10
Training loss: 1.9053468910030351
Validation loss: 2.5907324514953807

Epoch: 6| Step: 11
Training loss: 2.2019396900784263
Validation loss: 2.642987045254785

Epoch: 6| Step: 12
Training loss: 1.8972011354924374
Validation loss: 2.6264731662856313

Epoch: 6| Step: 13
Training loss: 2.4485117304004675
Validation loss: 2.5814925448725177

Epoch: 372| Step: 0
Training loss: 1.729938089883659
Validation loss: 2.5918426340242813

Epoch: 6| Step: 1
Training loss: 2.420845649762319
Validation loss: 2.6399165474534456

Epoch: 6| Step: 2
Training loss: 2.078534078847675
Validation loss: 2.5067783733575895

Epoch: 6| Step: 3
Training loss: 2.1142239821196394
Validation loss: 2.5387218989639027

Epoch: 6| Step: 4
Training loss: 2.9726224037679763
Validation loss: 2.575700517692227

Epoch: 6| Step: 5
Training loss: 1.5138683560735635
Validation loss: 2.5730304109154134

Epoch: 6| Step: 6
Training loss: 1.9456451009121918
Validation loss: 2.5350446475659942

Epoch: 6| Step: 7
Training loss: 2.3823270709753115
Validation loss: 2.607758053777398

Epoch: 6| Step: 8
Training loss: 1.8094011980179503
Validation loss: 2.6367738779519243

Epoch: 6| Step: 9
Training loss: 2.9560069397572573
Validation loss: 2.534527265245589

Epoch: 6| Step: 10
Training loss: 2.6735215495467983
Validation loss: 2.5759517336133495

Epoch: 6| Step: 11
Training loss: 2.1708708712895
Validation loss: 2.6061382156510287

Epoch: 6| Step: 12
Training loss: 2.4361513759640077
Validation loss: 2.5438779536264957

Epoch: 6| Step: 13
Training loss: 2.374328417942383
Validation loss: 2.5705111303703347

Epoch: 373| Step: 0
Training loss: 2.1912718814991172
Validation loss: 2.608828764439372

Epoch: 6| Step: 1
Training loss: 2.289176755794274
Validation loss: 2.527911915315796

Epoch: 6| Step: 2
Training loss: 1.6274517343984831
Validation loss: 2.6626224755982504

Epoch: 6| Step: 3
Training loss: 2.230054399314368
Validation loss: 2.600980594614583

Epoch: 6| Step: 4
Training loss: 2.5224193491296742
Validation loss: 2.6628347422230423

Epoch: 6| Step: 5
Training loss: 2.6065610228917238
Validation loss: 2.6656380240945166

Epoch: 6| Step: 6
Training loss: 1.5685633696528487
Validation loss: 2.686721596500456

Epoch: 6| Step: 7
Training loss: 2.204611202571645
Validation loss: 2.6047777442562583

Epoch: 6| Step: 8
Training loss: 2.8847254580501684
Validation loss: 2.57467627134588

Epoch: 6| Step: 9
Training loss: 2.482440507220104
Validation loss: 2.6139894535029793

Epoch: 6| Step: 10
Training loss: 2.3619245686191332
Validation loss: 2.6014884680262345

Epoch: 6| Step: 11
Training loss: 1.9669066382410016
Validation loss: 2.578787948674896

Epoch: 6| Step: 12
Training loss: 2.8724383676422582
Validation loss: 2.5757460700002897

Epoch: 6| Step: 13
Training loss: 1.8698299974286587
Validation loss: 2.6107725620902857

Epoch: 374| Step: 0
Training loss: 2.001541259081161
Validation loss: 2.6274988719689976

Epoch: 6| Step: 1
Training loss: 1.8070224997592672
Validation loss: 2.6136684492927826

Epoch: 6| Step: 2
Training loss: 2.37033727604007
Validation loss: 2.641878976271051

Epoch: 6| Step: 3
Training loss: 2.512160575296292
Validation loss: 2.6612520897543717

Epoch: 6| Step: 4
Training loss: 2.130139362987669
Validation loss: 2.6092493023168624

Epoch: 6| Step: 5
Training loss: 1.760291762877422
Validation loss: 2.5058105572438993

Epoch: 6| Step: 6
Training loss: 2.1211949108300834
Validation loss: 2.6482458461208864

Epoch: 6| Step: 7
Training loss: 2.62977900762341
Validation loss: 2.573143042907134

Epoch: 6| Step: 8
Training loss: 2.06883088844028
Validation loss: 2.622510889159912

Epoch: 6| Step: 9
Training loss: 2.1956029950914266
Validation loss: 2.576722936151816

Epoch: 6| Step: 10
Training loss: 2.5554623609863576
Validation loss: 2.606154530152924

Epoch: 6| Step: 11
Training loss: 2.674144650902908
Validation loss: 2.571523552193732

Epoch: 6| Step: 12
Training loss: 2.6284640026649906
Validation loss: 2.5732172697030298

Epoch: 6| Step: 13
Training loss: 2.6879574585965553
Validation loss: 2.613074542217118

Epoch: 375| Step: 0
Training loss: 1.72527890369419
Validation loss: 2.568236512202073

Epoch: 6| Step: 1
Training loss: 1.934647706364572
Validation loss: 2.6359412375550186

Epoch: 6| Step: 2
Training loss: 2.1135889982134985
Validation loss: 2.5343701269260404

Epoch: 6| Step: 3
Training loss: 2.7258686396070275
Validation loss: 2.5706284582496366

Epoch: 6| Step: 4
Training loss: 2.6063937213889994
Validation loss: 2.5484939322787366

Epoch: 6| Step: 5
Training loss: 1.6980737094764
Validation loss: 2.633545046842437

Epoch: 6| Step: 6
Training loss: 1.7042470613028713
Validation loss: 2.582828190174983

Epoch: 6| Step: 7
Training loss: 2.3038523049699244
Validation loss: 2.534627185013252

Epoch: 6| Step: 8
Training loss: 2.840059002008179
Validation loss: 2.547269990721916

Epoch: 6| Step: 9
Training loss: 1.9309380683706707
Validation loss: 2.6557743966546794

Epoch: 6| Step: 10
Training loss: 2.7405347054547144
Validation loss: 2.658119430780165

Epoch: 6| Step: 11
Training loss: 1.356501996233969
Validation loss: 2.6440363304359287

Epoch: 6| Step: 12
Training loss: 2.227735886162746
Validation loss: 2.57486491485657

Epoch: 6| Step: 13
Training loss: 1.77790726332513
Validation loss: 2.589877483981143

Epoch: 376| Step: 0
Training loss: 1.9750091721526968
Validation loss: 2.6206207936798407

Epoch: 6| Step: 1
Training loss: 1.9557760938220023
Validation loss: 2.643689160177972

Epoch: 6| Step: 2
Training loss: 2.245092019317118
Validation loss: 2.6039079787863737

Epoch: 6| Step: 3
Training loss: 2.1848552519735525
Validation loss: 2.6057603693800395

Epoch: 6| Step: 4
Training loss: 2.885220646081458
Validation loss: 2.6370523177500824

Epoch: 6| Step: 5
Training loss: 2.4361134033115013
Validation loss: 2.6579286640781907

Epoch: 6| Step: 6
Training loss: 1.6388863206114106
Validation loss: 2.526477501003758

Epoch: 6| Step: 7
Training loss: 1.6558319139914468
Validation loss: 2.597963079477759

Epoch: 6| Step: 8
Training loss: 2.007955820631072
Validation loss: 2.622275134089777

Epoch: 6| Step: 9
Training loss: 1.927678347993766
Validation loss: 2.5418532918446877

Epoch: 6| Step: 10
Training loss: 2.5501768088284824
Validation loss: 2.5015989010264277

Epoch: 6| Step: 11
Training loss: 2.070007762433669
Validation loss: 2.602381628431966

Epoch: 6| Step: 12
Training loss: 3.1949979072289336
Validation loss: 2.609267762827118

Epoch: 6| Step: 13
Training loss: 3.0037165508717623
Validation loss: 2.602075309139729

Epoch: 377| Step: 0
Training loss: 2.029435623903504
Validation loss: 2.5913308153284618

Epoch: 6| Step: 1
Training loss: 2.375911638068209
Validation loss: 2.6286037283011585

Epoch: 6| Step: 2
Training loss: 2.4897006551213776
Validation loss: 2.636390940449619

Epoch: 6| Step: 3
Training loss: 2.2262555897988983
Validation loss: 2.561399737357121

Epoch: 6| Step: 4
Training loss: 1.8870086131341532
Validation loss: 2.6613209952298735

Epoch: 6| Step: 5
Training loss: 2.0952241177732587
Validation loss: 2.631454860686169

Epoch: 6| Step: 6
Training loss: 2.0541443777777304
Validation loss: 2.569678140433743

Epoch: 6| Step: 7
Training loss: 2.1856380712932606
Validation loss: 2.612248113780742

Epoch: 6| Step: 8
Training loss: 2.1629128828207285
Validation loss: 2.5422196058279263

Epoch: 6| Step: 9
Training loss: 2.527628533239146
Validation loss: 2.6340294067385503

Epoch: 6| Step: 10
Training loss: 1.6557202481628326
Validation loss: 2.556427756425576

Epoch: 6| Step: 11
Training loss: 2.553912683982365
Validation loss: 2.4878201770893686

Epoch: 6| Step: 12
Training loss: 2.201988414016719
Validation loss: 2.6173139076028984

Epoch: 6| Step: 13
Training loss: 2.2937636289269614
Validation loss: 2.591336300081145

Epoch: 378| Step: 0
Training loss: 2.3083774833267166
Validation loss: 2.5969986608704447

Epoch: 6| Step: 1
Training loss: 1.6812411907206333
Validation loss: 2.635952523247517

Epoch: 6| Step: 2
Training loss: 1.8394749103648618
Validation loss: 2.5863863766675284

Epoch: 6| Step: 3
Training loss: 2.3402417183603075
Validation loss: 2.608925866034728

Epoch: 6| Step: 4
Training loss: 1.584433608316037
Validation loss: 2.575837485708172

Epoch: 6| Step: 5
Training loss: 2.4124463050677845
Validation loss: 2.624127660559849

Epoch: 6| Step: 6
Training loss: 2.6385878430249177
Validation loss: 2.5743490331143053

Epoch: 6| Step: 7
Training loss: 2.094584284576611
Validation loss: 2.5854984013874285

Epoch: 6| Step: 8
Training loss: 3.0481345678745995
Validation loss: 2.6075615744401954

Epoch: 6| Step: 9
Training loss: 2.686712282643877
Validation loss: 2.6199363000373626

Epoch: 6| Step: 10
Training loss: 2.196555332243238
Validation loss: 2.5921301826442438

Epoch: 6| Step: 11
Training loss: 2.3780005724483537
Validation loss: 2.558555296009536

Epoch: 6| Step: 12
Training loss: 2.0844071736061696
Validation loss: 2.617929545474016

Epoch: 6| Step: 13
Training loss: 1.749211065387074
Validation loss: 2.512056585994584

Epoch: 379| Step: 0
Training loss: 1.9189130086339479
Validation loss: 2.6067454358236883

Epoch: 6| Step: 1
Training loss: 2.414024871236619
Validation loss: 2.612423990074848

Epoch: 6| Step: 2
Training loss: 2.507628341995841
Validation loss: 2.5735390136193557

Epoch: 6| Step: 3
Training loss: 2.0700823961896204
Validation loss: 2.5916005417923755

Epoch: 6| Step: 4
Training loss: 1.9909848640973997
Validation loss: 2.582333469177027

Epoch: 6| Step: 5
Training loss: 2.2669089000892186
Validation loss: 2.5565918784342494

Epoch: 6| Step: 6
Training loss: 2.240792614827078
Validation loss: 2.6548040943772073

Epoch: 6| Step: 7
Training loss: 2.119828607360737
Validation loss: 2.5916739432017075

Epoch: 6| Step: 8
Training loss: 2.650870496898501
Validation loss: 2.509598650588393

Epoch: 6| Step: 9
Training loss: 1.8082158330312987
Validation loss: 2.680793560009885

Epoch: 6| Step: 10
Training loss: 2.275269284921829
Validation loss: 2.6557002918110313

Epoch: 6| Step: 11
Training loss: 2.219383364258552
Validation loss: 2.6653523433151034

Epoch: 6| Step: 12
Training loss: 2.9568667649513443
Validation loss: 2.642151137873916

Epoch: 6| Step: 13
Training loss: 1.8048390906934857
Validation loss: 2.5529853885752223

Epoch: 380| Step: 0
Training loss: 1.9365173432085458
Validation loss: 2.554086064024739

Epoch: 6| Step: 1
Training loss: 2.310817312503071
Validation loss: 2.570495283789811

Epoch: 6| Step: 2
Training loss: 1.855441187603673
Validation loss: 2.52826278426456

Epoch: 6| Step: 3
Training loss: 2.9122911239184353
Validation loss: 2.5752731365551527

Epoch: 6| Step: 4
Training loss: 1.7428364592805623
Validation loss: 2.5515579764440823

Epoch: 6| Step: 5
Training loss: 2.2256465701070547
Validation loss: 2.537293564066275

Epoch: 6| Step: 6
Training loss: 2.7098180564810908
Validation loss: 2.5994391970061095

Epoch: 6| Step: 7
Training loss: 2.421676332262374
Validation loss: 2.5685886746871986

Epoch: 6| Step: 8
Training loss: 1.8194638349100019
Validation loss: 2.668514804976303

Epoch: 6| Step: 9
Training loss: 1.8149217671749867
Validation loss: 2.646103326226641

Epoch: 6| Step: 10
Training loss: 2.2512771372666
Validation loss: 2.5466322922567817

Epoch: 6| Step: 11
Training loss: 1.5998483556172032
Validation loss: 2.5590562808319

Epoch: 6| Step: 12
Training loss: 2.0533348823929596
Validation loss: 2.543628125066441

Epoch: 6| Step: 13
Training loss: 2.781593815843994
Validation loss: 2.647885491218847

Epoch: 381| Step: 0
Training loss: 2.6075867332889917
Validation loss: 2.6572107168961914

Epoch: 6| Step: 1
Training loss: 2.2986283649003196
Validation loss: 2.653077767581458

Epoch: 6| Step: 2
Training loss: 2.537982981150556
Validation loss: 2.56490937080437

Epoch: 6| Step: 3
Training loss: 1.9539416017503024
Validation loss: 2.5785214663401885

Epoch: 6| Step: 4
Training loss: 2.383310534850586
Validation loss: 2.565012250825157

Epoch: 6| Step: 5
Training loss: 1.5660221075931007
Validation loss: 2.5587442057782646

Epoch: 6| Step: 6
Training loss: 1.5283070524085303
Validation loss: 2.594544315889137

Epoch: 6| Step: 7
Training loss: 2.560272551273438
Validation loss: 2.52287732409309

Epoch: 6| Step: 8
Training loss: 2.950723307239883
Validation loss: 2.587629325368959

Epoch: 6| Step: 9
Training loss: 2.240909012547062
Validation loss: 2.6129982784047794

Epoch: 6| Step: 10
Training loss: 1.978095504275677
Validation loss: 2.620860031161237

Epoch: 6| Step: 11
Training loss: 1.7875746491323665
Validation loss: 2.5873703084763378

Epoch: 6| Step: 12
Training loss: 1.8449224203489758
Validation loss: 2.6033086046458216

Epoch: 6| Step: 13
Training loss: 2.3147351571964827
Validation loss: 2.590295831389987

Epoch: 382| Step: 0
Training loss: 2.227362773363113
Validation loss: 2.5298267689502594

Epoch: 6| Step: 1
Training loss: 1.8731907698775943
Validation loss: 2.5941633361417864

Epoch: 6| Step: 2
Training loss: 1.963943973142239
Validation loss: 2.5358073476073453

Epoch: 6| Step: 3
Training loss: 2.8281811450422274
Validation loss: 2.587241802240119

Epoch: 6| Step: 4
Training loss: 2.536709584371434
Validation loss: 2.5786383596597937

Epoch: 6| Step: 5
Training loss: 2.047490617034242
Validation loss: 2.68223292406613

Epoch: 6| Step: 6
Training loss: 1.6736319748601154
Validation loss: 2.5067811059661507

Epoch: 6| Step: 7
Training loss: 2.0676602631049055
Validation loss: 2.6063188705616653

Epoch: 6| Step: 8
Training loss: 1.9540765504318172
Validation loss: 2.525858464568088

Epoch: 6| Step: 9
Training loss: 2.003367688121937
Validation loss: 2.67235039904514

Epoch: 6| Step: 10
Training loss: 1.9849258018866502
Validation loss: 2.543632092030627

Epoch: 6| Step: 11
Training loss: 2.3190361648378155
Validation loss: 2.631391024993151

Epoch: 6| Step: 12
Training loss: 2.0617357629881377
Validation loss: 2.6144569097419494

Epoch: 6| Step: 13
Training loss: 3.1726474666967035
Validation loss: 2.580600748782333

Epoch: 383| Step: 0
Training loss: 1.9833894219468289
Validation loss: 2.6225673998517762

Epoch: 6| Step: 1
Training loss: 1.9843288626526223
Validation loss: 2.6027418141079757

Epoch: 6| Step: 2
Training loss: 1.9983909810298692
Validation loss: 2.6404026455095355

Epoch: 6| Step: 3
Training loss: 1.909751552780405
Validation loss: 2.5182709859313155

Epoch: 6| Step: 4
Training loss: 3.2149567705869955
Validation loss: 2.6334123117772026

Epoch: 6| Step: 5
Training loss: 1.5110125013196571
Validation loss: 2.6211410681284733

Epoch: 6| Step: 6
Training loss: 2.892232581909921
Validation loss: 2.427683335748501

Epoch: 6| Step: 7
Training loss: 2.5714775621954695
Validation loss: 2.5899248814669504

Epoch: 6| Step: 8
Training loss: 1.7902313811718094
Validation loss: 2.608057516367297

Epoch: 6| Step: 9
Training loss: 2.1760907868982593
Validation loss: 2.5941673958042384

Epoch: 6| Step: 10
Training loss: 1.6315366880387654
Validation loss: 2.6591707505376965

Epoch: 6| Step: 11
Training loss: 2.286742092126819
Validation loss: 2.6185468644993906

Epoch: 6| Step: 12
Training loss: 2.17424222527077
Validation loss: 2.4768940848639627

Epoch: 6| Step: 13
Training loss: 2.209733399238295
Validation loss: 2.579775531305

Epoch: 384| Step: 0
Training loss: 1.9521925264296558
Validation loss: 2.4505090559671965

Epoch: 6| Step: 1
Training loss: 2.1595981421880754
Validation loss: 2.4892730382219215

Epoch: 6| Step: 2
Training loss: 1.8072809517695776
Validation loss: 2.559147035514892

Epoch: 6| Step: 3
Training loss: 1.787759964718985
Validation loss: 2.5296036807585955

Epoch: 6| Step: 4
Training loss: 2.202915912202586
Validation loss: 2.6477832393215737

Epoch: 6| Step: 5
Training loss: 2.3377817075975957
Validation loss: 2.558981353750819

Epoch: 6| Step: 6
Training loss: 2.7753413153716937
Validation loss: 2.57415644084333

Epoch: 6| Step: 7
Training loss: 2.228598430141597
Validation loss: 2.641192707282705

Epoch: 6| Step: 8
Training loss: 2.2921126422997267
Validation loss: 2.6093524609882355

Epoch: 6| Step: 9
Training loss: 2.431990240617043
Validation loss: 2.5567922966521945

Epoch: 6| Step: 10
Training loss: 2.2575035015767635
Validation loss: 2.6107832741295978

Epoch: 6| Step: 11
Training loss: 1.7197344648189394
Validation loss: 2.545775374866246

Epoch: 6| Step: 12
Training loss: 2.125418453528645
Validation loss: 2.627912365821509

Epoch: 6| Step: 13
Training loss: 2.3081592338082966
Validation loss: 2.6108192051444563

Epoch: 385| Step: 0
Training loss: 1.6251321885556083
Validation loss: 2.6264539697047256

Epoch: 6| Step: 1
Training loss: 2.484601568291286
Validation loss: 2.619324254057127

Epoch: 6| Step: 2
Training loss: 2.89704223940167
Validation loss: 2.5976574402074797

Epoch: 6| Step: 3
Training loss: 1.9829366682657272
Validation loss: 2.5347803609730866

Epoch: 6| Step: 4
Training loss: 2.3103825953327313
Validation loss: 2.5416125455352905

Epoch: 6| Step: 5
Training loss: 2.075134649848641
Validation loss: 2.5570073461013236

Epoch: 6| Step: 6
Training loss: 2.0162534695032
Validation loss: 2.664978525188001

Epoch: 6| Step: 7
Training loss: 1.7247371086261438
Validation loss: 2.579878238832802

Epoch: 6| Step: 8
Training loss: 2.100640644263794
Validation loss: 2.64445827746557

Epoch: 6| Step: 9
Training loss: 1.958015118440235
Validation loss: 2.66366572654067

Epoch: 6| Step: 10
Training loss: 2.768421892483202
Validation loss: 2.616981782574279

Epoch: 6| Step: 11
Training loss: 2.033784429613949
Validation loss: 2.662488603873241

Epoch: 6| Step: 12
Training loss: 1.9945290361893437
Validation loss: 2.595215359893048

Epoch: 6| Step: 13
Training loss: 2.58670336857874
Validation loss: 2.614199826730109

Epoch: 386| Step: 0
Training loss: 1.7365228910598693
Validation loss: 2.6313395157321886

Epoch: 6| Step: 1
Training loss: 2.539525761524152
Validation loss: 2.604926190929154

Epoch: 6| Step: 2
Training loss: 1.8782271270151323
Validation loss: 2.551069851398459

Epoch: 6| Step: 3
Training loss: 1.9699478743768426
Validation loss: 2.5568145359643504

Epoch: 6| Step: 4
Training loss: 2.667337680872538
Validation loss: 2.61989954782549

Epoch: 6| Step: 5
Training loss: 1.8463266762505952
Validation loss: 2.580235755462674

Epoch: 6| Step: 6
Training loss: 1.8739859063871442
Validation loss: 2.5297339783834443

Epoch: 6| Step: 7
Training loss: 2.6513634107362605
Validation loss: 2.6347461940146455

Epoch: 6| Step: 8
Training loss: 2.158214061588523
Validation loss: 2.597975590941685

Epoch: 6| Step: 9
Training loss: 2.222737557209573
Validation loss: 2.7491635722043664

Epoch: 6| Step: 10
Training loss: 1.9981821858966384
Validation loss: 2.552646158189536

Epoch: 6| Step: 11
Training loss: 2.083588037815567
Validation loss: 2.5844995768531254

Epoch: 6| Step: 12
Training loss: 2.517796686716314
Validation loss: 2.5540827717524768

Epoch: 6| Step: 13
Training loss: 2.7311522756591464
Validation loss: 2.586741754964107

Epoch: 387| Step: 0
Training loss: 2.9001670263137567
Validation loss: 2.5697628275923736

Epoch: 6| Step: 1
Training loss: 2.0152608853079172
Validation loss: 2.5123018737950633

Epoch: 6| Step: 2
Training loss: 1.8710532930655217
Validation loss: 2.498579382526294

Epoch: 6| Step: 3
Training loss: 2.1181125098181273
Validation loss: 2.5825314112371083

Epoch: 6| Step: 4
Training loss: 2.035050577945758
Validation loss: 2.59277663318278

Epoch: 6| Step: 5
Training loss: 1.8437866595228285
Validation loss: 2.5717867583518212

Epoch: 6| Step: 6
Training loss: 2.046545919507568
Validation loss: 2.548067275971046

Epoch: 6| Step: 7
Training loss: 2.2246915753511165
Validation loss: 2.5459169988906964

Epoch: 6| Step: 8
Training loss: 2.779069881860505
Validation loss: 2.6276039533229745

Epoch: 6| Step: 9
Training loss: 2.4465294877798667
Validation loss: 2.607481360431935

Epoch: 6| Step: 10
Training loss: 1.9477696354771945
Validation loss: 2.6273001834417666

Epoch: 6| Step: 11
Training loss: 2.4913219515396126
Validation loss: 2.561249808919407

Epoch: 6| Step: 12
Training loss: 2.020208544022209
Validation loss: 2.5777141045973897

Epoch: 6| Step: 13
Training loss: 1.7644663697278316
Validation loss: 2.5512838779412497

Epoch: 388| Step: 0
Training loss: 2.6772638598973946
Validation loss: 2.6112170173580007

Epoch: 6| Step: 1
Training loss: 2.5832025638419926
Validation loss: 2.541184054919095

Epoch: 6| Step: 2
Training loss: 2.910351228262765
Validation loss: 2.553793900496516

Epoch: 6| Step: 3
Training loss: 1.9811199253837315
Validation loss: 2.5668936758355905

Epoch: 6| Step: 4
Training loss: 2.2232192253368694
Validation loss: 2.5870985282333194

Epoch: 6| Step: 5
Training loss: 2.0269346908639734
Validation loss: 2.6199715536515082

Epoch: 6| Step: 6
Training loss: 1.543639836260971
Validation loss: 2.567884817566554

Epoch: 6| Step: 7
Training loss: 2.310531603262083
Validation loss: 2.551796073559702

Epoch: 6| Step: 8
Training loss: 1.738016446978466
Validation loss: 2.514918402423303

Epoch: 6| Step: 9
Training loss: 1.8573152048185166
Validation loss: 2.5561127472845167

Epoch: 6| Step: 10
Training loss: 1.6912510472510818
Validation loss: 2.464706080847173

Epoch: 6| Step: 11
Training loss: 2.2301471966116244
Validation loss: 2.6595342273670033

Epoch: 6| Step: 12
Training loss: 1.7760404062872597
Validation loss: 2.57070045200236

Epoch: 6| Step: 13
Training loss: 1.9381701633243487
Validation loss: 2.545529559566397

Epoch: 389| Step: 0
Training loss: 2.8214148060633577
Validation loss: 2.5953677178698125

Epoch: 6| Step: 1
Training loss: 2.987791652090023
Validation loss: 2.543112057553289

Epoch: 6| Step: 2
Training loss: 1.7424568002345406
Validation loss: 2.5886373062541765

Epoch: 6| Step: 3
Training loss: 2.6154499720049684
Validation loss: 2.587431625676326

Epoch: 6| Step: 4
Training loss: 2.0844629912555566
Validation loss: 2.5815599059189545

Epoch: 6| Step: 5
Training loss: 1.949419947696444
Validation loss: 2.542535444427141

Epoch: 6| Step: 6
Training loss: 2.323428851626526
Validation loss: 2.589542396439701

Epoch: 6| Step: 7
Training loss: 1.7342543001532669
Validation loss: 2.5691954178228973

Epoch: 6| Step: 8
Training loss: 2.0421182820644583
Validation loss: 2.6125938820813075

Epoch: 6| Step: 9
Training loss: 1.9619485748582157
Validation loss: 2.5589935498876444

Epoch: 6| Step: 10
Training loss: 1.9598907473340434
Validation loss: 2.5630709464525387

Epoch: 6| Step: 11
Training loss: 1.866675142995572
Validation loss: 2.5542597735470043

Epoch: 6| Step: 12
Training loss: 2.3179664953803916
Validation loss: 2.46503875773838

Epoch: 6| Step: 13
Training loss: 1.8904534884756736
Validation loss: 2.5918062782081472

Epoch: 390| Step: 0
Training loss: 2.0146490292125283
Validation loss: 2.5808199984310454

Epoch: 6| Step: 1
Training loss: 1.9114683672427661
Validation loss: 2.5273787437139275

Epoch: 6| Step: 2
Training loss: 2.3771797015765648
Validation loss: 2.6036337410955643

Epoch: 6| Step: 3
Training loss: 1.5601267529613696
Validation loss: 2.5715658816856775

Epoch: 6| Step: 4
Training loss: 1.7800104613478918
Validation loss: 2.5108072961320254

Epoch: 6| Step: 5
Training loss: 2.3159124610380166
Validation loss: 2.590889045868527

Epoch: 6| Step: 6
Training loss: 2.4245708597110056
Validation loss: 2.612628289336775

Epoch: 6| Step: 7
Training loss: 2.389644845726765
Validation loss: 2.5341260682554907

Epoch: 6| Step: 8
Training loss: 2.3874656395162224
Validation loss: 2.46667078161132

Epoch: 6| Step: 9
Training loss: 2.0628784294902007
Validation loss: 2.554552675600464

Epoch: 6| Step: 10
Training loss: 1.9675632714806564
Validation loss: 2.5453996399452206

Epoch: 6| Step: 11
Training loss: 2.6031719189796907
Validation loss: 2.559977336425597

Epoch: 6| Step: 12
Training loss: 2.1072761548901817
Validation loss: 2.5930823455077614

Epoch: 6| Step: 13
Training loss: 2.2587475803786607
Validation loss: 2.5626685844649093

Epoch: 391| Step: 0
Training loss: 1.8952139656637645
Validation loss: 2.6450632825575617

Epoch: 6| Step: 1
Training loss: 2.81294382620065
Validation loss: 2.5238974628974584

Epoch: 6| Step: 2
Training loss: 2.24226363315323
Validation loss: 2.5580505851631417

Epoch: 6| Step: 3
Training loss: 2.1188349208861346
Validation loss: 2.586911811930296

Epoch: 6| Step: 4
Training loss: 2.6261385310545884
Validation loss: 2.6094041183740226

Epoch: 6| Step: 5
Training loss: 2.010705666861154
Validation loss: 2.598148221086048

Epoch: 6| Step: 6
Training loss: 1.9304971579387762
Validation loss: 2.5646060879583885

Epoch: 6| Step: 7
Training loss: 2.7817805780667313
Validation loss: 2.6087264980036204

Epoch: 6| Step: 8
Training loss: 2.0465013002735875
Validation loss: 2.605090167955015

Epoch: 6| Step: 9
Training loss: 2.570784597898374
Validation loss: 2.5325496835642154

Epoch: 6| Step: 10
Training loss: 1.4559983588618157
Validation loss: 2.564346520569451

Epoch: 6| Step: 11
Training loss: 1.7382210367467974
Validation loss: 2.5687205547556022

Epoch: 6| Step: 12
Training loss: 2.7465365881657315
Validation loss: 2.561182991735603

Epoch: 6| Step: 13
Training loss: 2.5161347435499106
Validation loss: 2.506896320750308

Epoch: 392| Step: 0
Training loss: 1.9956976988489614
Validation loss: 2.5227918129929296

Epoch: 6| Step: 1
Training loss: 2.148240957806892
Validation loss: 2.476967336967204

Epoch: 6| Step: 2
Training loss: 1.760744760250131
Validation loss: 2.578055920363712

Epoch: 6| Step: 3
Training loss: 2.4151409419220538
Validation loss: 2.626754277587582

Epoch: 6| Step: 4
Training loss: 3.179362962361414
Validation loss: 2.541569824095224

Epoch: 6| Step: 5
Training loss: 2.307957492165861
Validation loss: 2.6995654109028178

Epoch: 6| Step: 6
Training loss: 2.037676460722247
Validation loss: 2.503372026608182

Epoch: 6| Step: 7
Training loss: 2.679566583602328
Validation loss: 2.6221360327819765

Epoch: 6| Step: 8
Training loss: 2.5177156279119823
Validation loss: 2.5392102664075273

Epoch: 6| Step: 9
Training loss: 1.88382791703547
Validation loss: 2.6112907401408245

Epoch: 6| Step: 10
Training loss: 1.6605036114082246
Validation loss: 2.6083270763783593

Epoch: 6| Step: 11
Training loss: 2.1647185835624243
Validation loss: 2.6530864255193802

Epoch: 6| Step: 12
Training loss: 1.978220850835461
Validation loss: 2.574442313781332

Epoch: 6| Step: 13
Training loss: 2.1313280242330377
Validation loss: 2.5265444912345605

Epoch: 393| Step: 0
Training loss: 1.911648843887822
Validation loss: 2.607122893500121

Epoch: 6| Step: 1
Training loss: 2.6362940919606523
Validation loss: 2.5233211096183616

Epoch: 6| Step: 2
Training loss: 1.6756278725883678
Validation loss: 2.572651263571041

Epoch: 6| Step: 3
Training loss: 1.6180288733745922
Validation loss: 2.594480103144357

Epoch: 6| Step: 4
Training loss: 2.384999556631371
Validation loss: 2.5460933218293422

Epoch: 6| Step: 5
Training loss: 2.6297992249643407
Validation loss: 2.587258429612718

Epoch: 6| Step: 6
Training loss: 2.8706763554486483
Validation loss: 2.594981864078496

Epoch: 6| Step: 7
Training loss: 1.8269831033644641
Validation loss: 2.6666949766397043

Epoch: 6| Step: 8
Training loss: 2.529555613123387
Validation loss: 2.569019219546445

Epoch: 6| Step: 9
Training loss: 1.8498912624673054
Validation loss: 2.651458035128092

Epoch: 6| Step: 10
Training loss: 2.0885089925618514
Validation loss: 2.5684375918377595

Epoch: 6| Step: 11
Training loss: 1.8706208907775914
Validation loss: 2.633162231722638

Epoch: 6| Step: 12
Training loss: 2.311025097613727
Validation loss: 2.643023513285223

Epoch: 6| Step: 13
Training loss: 2.1300442235233144
Validation loss: 2.5803993363417415

Epoch: 394| Step: 0
Training loss: 3.332607635339487
Validation loss: 2.586821900514973

Epoch: 6| Step: 1
Training loss: 1.4955358834663084
Validation loss: 2.645846310571522

Epoch: 6| Step: 2
Training loss: 2.1377840890656854
Validation loss: 2.477303912548163

Epoch: 6| Step: 3
Training loss: 2.74713453644264
Validation loss: 2.624489475301933

Epoch: 6| Step: 4
Training loss: 2.064122457737992
Validation loss: 2.563837882162251

Epoch: 6| Step: 5
Training loss: 1.5462218167474204
Validation loss: 2.6052114737844536

Epoch: 6| Step: 6
Training loss: 1.7965755047197252
Validation loss: 2.7034400738772355

Epoch: 6| Step: 7
Training loss: 2.091809640483924
Validation loss: 2.557110506949161

Epoch: 6| Step: 8
Training loss: 2.256266662028916
Validation loss: 2.629989715006136

Epoch: 6| Step: 9
Training loss: 2.3277077524986853
Validation loss: 2.5809012789687524

Epoch: 6| Step: 10
Training loss: 2.0081551700988705
Validation loss: 2.5633931878082645

Epoch: 6| Step: 11
Training loss: 2.217755161816487
Validation loss: 2.5778819477044386

Epoch: 6| Step: 12
Training loss: 1.6216347400675937
Validation loss: 2.4904612883024466

Epoch: 6| Step: 13
Training loss: 2.253651411171424
Validation loss: 2.5579058715288268

Epoch: 395| Step: 0
Training loss: 1.9456863963203135
Validation loss: 2.6335130958706956

Epoch: 6| Step: 1
Training loss: 2.3482784011765667
Validation loss: 2.528586612593984

Epoch: 6| Step: 2
Training loss: 2.3361628497070925
Validation loss: 2.5909639654687444

Epoch: 6| Step: 3
Training loss: 2.135936865984384
Validation loss: 2.5312677866661364

Epoch: 6| Step: 4
Training loss: 1.5176604456034999
Validation loss: 2.5438673685056967

Epoch: 6| Step: 5
Training loss: 2.2668115074031223
Validation loss: 2.5252303526965516

Epoch: 6| Step: 6
Training loss: 1.8279135818171364
Validation loss: 2.6069456496304313

Epoch: 6| Step: 7
Training loss: 2.0748557856437837
Validation loss: 2.549721510243671

Epoch: 6| Step: 8
Training loss: 2.384208895395864
Validation loss: 2.534159110955061

Epoch: 6| Step: 9
Training loss: 2.3536631177850165
Validation loss: 2.544659628761303

Epoch: 6| Step: 10
Training loss: 1.9031191269857552
Validation loss: 2.6231076607158

Epoch: 6| Step: 11
Training loss: 2.6862082814793116
Validation loss: 2.58806767612422

Epoch: 6| Step: 12
Training loss: 2.099993832897032
Validation loss: 2.6386520112834946

Epoch: 6| Step: 13
Training loss: 3.2096306956206826
Validation loss: 2.553348712912844

Epoch: 396| Step: 0
Training loss: 1.9594552566664563
Validation loss: 2.644854715285595

Epoch: 6| Step: 1
Training loss: 1.8846059148451724
Validation loss: 2.5973306959366917

Epoch: 6| Step: 2
Training loss: 2.2061199636203552
Validation loss: 2.5965752572236256

Epoch: 6| Step: 3
Training loss: 1.9543609370746442
Validation loss: 2.5797105494604784

Epoch: 6| Step: 4
Training loss: 2.0729468517565808
Validation loss: 2.650480530159531

Epoch: 6| Step: 5
Training loss: 2.505973165162908
Validation loss: 2.599997821535597

Epoch: 6| Step: 6
Training loss: 2.649022580676611
Validation loss: 2.6886584872581922

Epoch: 6| Step: 7
Training loss: 2.346912945518076
Validation loss: 2.5974278523159966

Epoch: 6| Step: 8
Training loss: 1.8345213277704562
Validation loss: 2.5930891632020057

Epoch: 6| Step: 9
Training loss: 2.0353325531315902
Validation loss: 2.5611870766483658

Epoch: 6| Step: 10
Training loss: 1.9677562324775144
Validation loss: 2.5203303139723685

Epoch: 6| Step: 11
Training loss: 2.52588263466584
Validation loss: 2.552917729471199

Epoch: 6| Step: 12
Training loss: 2.1844706676746446
Validation loss: 2.5923906508486163

Epoch: 6| Step: 13
Training loss: 2.2917493863059697
Validation loss: 2.6078524682699045

Epoch: 397| Step: 0
Training loss: 2.250060186640762
Validation loss: 2.4547661278698842

Epoch: 6| Step: 1
Training loss: 3.0989007169779614
Validation loss: 2.5221412687380758

Epoch: 6| Step: 2
Training loss: 1.6296180249452823
Validation loss: 2.5550627871660474

Epoch: 6| Step: 3
Training loss: 2.070682593321032
Validation loss: 2.5891103115993466

Epoch: 6| Step: 4
Training loss: 1.8692257023724856
Validation loss: 2.651339949429016

Epoch: 6| Step: 5
Training loss: 2.4746201657223295
Validation loss: 2.564736550507345

Epoch: 6| Step: 6
Training loss: 1.7875061595250423
Validation loss: 2.6410221646538967

Epoch: 6| Step: 7
Training loss: 1.8550813611842363
Validation loss: 2.6099859545063433

Epoch: 6| Step: 8
Training loss: 2.362258260963796
Validation loss: 2.571736316138747

Epoch: 6| Step: 9
Training loss: 2.084235822386198
Validation loss: 2.5533893467181996

Epoch: 6| Step: 10
Training loss: 1.5924875083445391
Validation loss: 2.5617850562103284

Epoch: 6| Step: 11
Training loss: 2.55945611063667
Validation loss: 2.5741665608122246

Epoch: 6| Step: 12
Training loss: 2.3040441617309644
Validation loss: 2.4617487203051756

Epoch: 6| Step: 13
Training loss: 2.404658100625139
Validation loss: 2.527372665228453

Epoch: 398| Step: 0
Training loss: 1.588199899732017
Validation loss: 2.581438130211473

Epoch: 6| Step: 1
Training loss: 2.406706531367088
Validation loss: 2.5953500465060237

Epoch: 6| Step: 2
Training loss: 2.425721491816275
Validation loss: 2.592373428926469

Epoch: 6| Step: 3
Training loss: 1.8896903257631168
Validation loss: 2.6306536337854984

Epoch: 6| Step: 4
Training loss: 2.4603408332355166
Validation loss: 2.5625463622086255

Epoch: 6| Step: 5
Training loss: 1.9841336080955259
Validation loss: 2.600362216835862

Epoch: 6| Step: 6
Training loss: 2.523598491623386
Validation loss: 2.536205129439622

Epoch: 6| Step: 7
Training loss: 2.1059576539132223
Validation loss: 2.549063791832074

Epoch: 6| Step: 8
Training loss: 1.586392943282214
Validation loss: 2.432610672521929

Epoch: 6| Step: 9
Training loss: 2.683120708057837
Validation loss: 2.5581497705193423

Epoch: 6| Step: 10
Training loss: 2.0104357730043225
Validation loss: 2.5924754158479533

Epoch: 6| Step: 11
Training loss: 2.388346564910007
Validation loss: 2.6090094914757103

Epoch: 6| Step: 12
Training loss: 2.301675256892183
Validation loss: 2.6103921859959445

Epoch: 6| Step: 13
Training loss: 2.3648756969601497
Validation loss: 2.5486447509209795

Epoch: 399| Step: 0
Training loss: 1.8695106259717642
Validation loss: 2.563902796345901

Epoch: 6| Step: 1
Training loss: 2.6326627151035855
Validation loss: 2.628723362947304

Epoch: 6| Step: 2
Training loss: 2.4339522928845763
Validation loss: 2.578624786528936

Epoch: 6| Step: 3
Training loss: 2.257882509829096
Validation loss: 2.5584173366357743

Epoch: 6| Step: 4
Training loss: 2.435453485015335
Validation loss: 2.5854995396820026

Epoch: 6| Step: 5
Training loss: 2.180425484807909
Validation loss: 2.5305017833781602

Epoch: 6| Step: 6
Training loss: 2.176872377046313
Validation loss: 2.6130806043163255

Epoch: 6| Step: 7
Training loss: 1.991218600555387
Validation loss: 2.5582499521332047

Epoch: 6| Step: 8
Training loss: 1.9518999453955952
Validation loss: 2.6191521582910386

Epoch: 6| Step: 9
Training loss: 1.9365894269833277
Validation loss: 2.593873313742939

Epoch: 6| Step: 10
Training loss: 2.6059130700134254
Validation loss: 2.692394310082897

Epoch: 6| Step: 11
Training loss: 2.248046238664658
Validation loss: 2.6142162390007226

Epoch: 6| Step: 12
Training loss: 2.0586887171228168
Validation loss: 2.5946438678959023

Epoch: 6| Step: 13
Training loss: 2.5259375691676387
Validation loss: 2.500984570223416

Epoch: 400| Step: 0
Training loss: 1.967998785173615
Validation loss: 2.584691333462938

Epoch: 6| Step: 1
Training loss: 1.5456473362870933
Validation loss: 2.6036570769472327

Epoch: 6| Step: 2
Training loss: 1.8324852484594611
Validation loss: 2.61183655896231

Epoch: 6| Step: 3
Training loss: 1.8439660026618654
Validation loss: 2.5555087866686406

Epoch: 6| Step: 4
Training loss: 2.100203177296257
Validation loss: 2.5619002029683524

Epoch: 6| Step: 5
Training loss: 2.8274246950518354
Validation loss: 2.535306034870806

Epoch: 6| Step: 6
Training loss: 1.9442214050740831
Validation loss: 2.5080901615707303

Epoch: 6| Step: 7
Training loss: 2.1759708123353247
Validation loss: 2.588821898747095

Epoch: 6| Step: 8
Training loss: 2.321968797557856
Validation loss: 2.5731899595761902

Epoch: 6| Step: 9
Training loss: 2.0213098128132163
Validation loss: 2.577890221727955

Epoch: 6| Step: 10
Training loss: 2.089268000787302
Validation loss: 2.5786712515259023

Epoch: 6| Step: 11
Training loss: 1.8411688760469263
Validation loss: 2.550462090207194

Epoch: 6| Step: 12
Training loss: 2.07036155786511
Validation loss: 2.5667125392831664

Epoch: 6| Step: 13
Training loss: 2.6993017777344335
Validation loss: 2.5687336148434388

Epoch: 401| Step: 0
Training loss: 2.167274487653556
Validation loss: 2.6346430643613394

Epoch: 6| Step: 1
Training loss: 1.5737591775470523
Validation loss: 2.5418500281054115

Epoch: 6| Step: 2
Training loss: 2.1317811365637382
Validation loss: 2.6761173212992255

Epoch: 6| Step: 3
Training loss: 2.330134196857814
Validation loss: 2.654182468137452

Epoch: 6| Step: 4
Training loss: 1.808784359471804
Validation loss: 2.5652017064609156

Epoch: 6| Step: 5
Training loss: 2.3599887074992383
Validation loss: 2.624076568281661

Epoch: 6| Step: 6
Training loss: 2.142240930693642
Validation loss: 2.5836080110052646

Epoch: 6| Step: 7
Training loss: 2.033754653221955
Validation loss: 2.699273425883301

Epoch: 6| Step: 8
Training loss: 2.8250612978066063
Validation loss: 2.555756880616247

Epoch: 6| Step: 9
Training loss: 1.6953680495201449
Validation loss: 2.654124184903382

Epoch: 6| Step: 10
Training loss: 2.1721684099877883
Validation loss: 2.6246213508023843

Epoch: 6| Step: 11
Training loss: 2.508384948233215
Validation loss: 2.671304174150441

Epoch: 6| Step: 12
Training loss: 2.6833458665195726
Validation loss: 2.610506391751411

Epoch: 6| Step: 13
Training loss: 1.1117940505925197
Validation loss: 2.5719228453152967

Epoch: 402| Step: 0
Training loss: 2.0493698640312856
Validation loss: 2.538040152702435

Epoch: 6| Step: 1
Training loss: 2.617556144600436
Validation loss: 2.654083425191071

Epoch: 6| Step: 2
Training loss: 1.6751135716438075
Validation loss: 2.581339780594914

Epoch: 6| Step: 3
Training loss: 1.84953383681218
Validation loss: 2.6088437541782317

Epoch: 6| Step: 4
Training loss: 1.7085249103341098
Validation loss: 2.510201737834061

Epoch: 6| Step: 5
Training loss: 1.6632113720221136
Validation loss: 2.5574368273872023

Epoch: 6| Step: 6
Training loss: 2.199368134704958
Validation loss: 2.566569296922716

Epoch: 6| Step: 7
Training loss: 2.4758211103163505
Validation loss: 2.576943652332229

Epoch: 6| Step: 8
Training loss: 1.9853170967018814
Validation loss: 2.506683435859609

Epoch: 6| Step: 9
Training loss: 2.233197949229834
Validation loss: 2.653294997914065

Epoch: 6| Step: 10
Training loss: 2.173488319620076
Validation loss: 2.5362373955411393

Epoch: 6| Step: 11
Training loss: 2.873316728170729
Validation loss: 2.5440974019247355

Epoch: 6| Step: 12
Training loss: 1.945874971629062
Validation loss: 2.5002634237823735

Epoch: 6| Step: 13
Training loss: 1.9057003542075694
Validation loss: 2.63894602856376

Epoch: 403| Step: 0
Training loss: 2.1108775121154673
Validation loss: 2.59286451044396

Epoch: 6| Step: 1
Training loss: 2.139423562250107
Validation loss: 2.5615763906848192

Epoch: 6| Step: 2
Training loss: 2.2150083342797955
Validation loss: 2.586074391750523

Epoch: 6| Step: 3
Training loss: 2.5699539630195316
Validation loss: 2.6333515409860664

Epoch: 6| Step: 4
Training loss: 1.8714136156859422
Validation loss: 2.5716935199270243

Epoch: 6| Step: 5
Training loss: 2.5338562158077744
Validation loss: 2.612077486257081

Epoch: 6| Step: 6
Training loss: 2.107618716913424
Validation loss: 2.517796501402458

Epoch: 6| Step: 7
Training loss: 1.9707621630775158
Validation loss: 2.5425834794256152

Epoch: 6| Step: 8
Training loss: 1.810912785595958
Validation loss: 2.6436508268328227

Epoch: 6| Step: 9
Training loss: 2.6588398593339555
Validation loss: 2.550201054045801

Epoch: 6| Step: 10
Training loss: 1.8000153011095532
Validation loss: 2.690468705503714

Epoch: 6| Step: 11
Training loss: 2.5406995924243607
Validation loss: 2.5794757684102523

Epoch: 6| Step: 12
Training loss: 1.6672158607995142
Validation loss: 2.6352971328837893

Epoch: 6| Step: 13
Training loss: 1.4256972196716824
Validation loss: 2.602890744268368

Epoch: 404| Step: 0
Training loss: 1.8830330114119775
Validation loss: 2.546106784944781

Epoch: 6| Step: 1
Training loss: 2.502469940767193
Validation loss: 2.576329316580974

Epoch: 6| Step: 2
Training loss: 1.972852157080583
Validation loss: 2.615394028963286

Epoch: 6| Step: 3
Training loss: 2.6831461215215313
Validation loss: 2.6250917445028774

Epoch: 6| Step: 4
Training loss: 2.239657899073609
Validation loss: 2.622156369668163

Epoch: 6| Step: 5
Training loss: 1.7708946516602992
Validation loss: 2.527042290105101

Epoch: 6| Step: 6
Training loss: 2.1641847872009117
Validation loss: 2.5877993705697766

Epoch: 6| Step: 7
Training loss: 2.11076953143434
Validation loss: 2.5927404155435534

Epoch: 6| Step: 8
Training loss: 2.05691094718593
Validation loss: 2.597258009119406

Epoch: 6| Step: 9
Training loss: 1.8608047373935226
Validation loss: 2.6296494653611524

Epoch: 6| Step: 10
Training loss: 2.4037349487404778
Validation loss: 2.5942375593657543

Epoch: 6| Step: 11
Training loss: 1.7128181050693816
Validation loss: 2.538178805538419

Epoch: 6| Step: 12
Training loss: 2.526592538026353
Validation loss: 2.5222373787333283

Epoch: 6| Step: 13
Training loss: 2.166552381680327
Validation loss: 2.446378645635074

Epoch: 405| Step: 0
Training loss: 1.9546701651581337
Validation loss: 2.5087898248102523

Epoch: 6| Step: 1
Training loss: 2.3818450464603904
Validation loss: 2.5554798416919895

Epoch: 6| Step: 2
Training loss: 2.447805188393457
Validation loss: 2.552952023683772

Epoch: 6| Step: 3
Training loss: 2.252439236345286
Validation loss: 2.5737201687674034

Epoch: 6| Step: 4
Training loss: 1.9289860859908474
Validation loss: 2.6179832800021794

Epoch: 6| Step: 5
Training loss: 2.0695179692235013
Validation loss: 2.6467944763567344

Epoch: 6| Step: 6
Training loss: 2.467960762670331
Validation loss: 2.5524134486250505

Epoch: 6| Step: 7
Training loss: 2.530272683688618
Validation loss: 2.646747596515203

Epoch: 6| Step: 8
Training loss: 2.2552062306970626
Validation loss: 2.591728643472864

Epoch: 6| Step: 9
Training loss: 1.7728862830075132
Validation loss: 2.491373330389688

Epoch: 6| Step: 10
Training loss: 1.8088261432346047
Validation loss: 2.653878231032836

Epoch: 6| Step: 11
Training loss: 1.6772699035109504
Validation loss: 2.623701759961932

Epoch: 6| Step: 12
Training loss: 2.4230251411522254
Validation loss: 2.5355629748199804

Epoch: 6| Step: 13
Training loss: 2.922390652610435
Validation loss: 2.6480058802387054

Epoch: 406| Step: 0
Training loss: 2.036543067931907
Validation loss: 2.58649620685343

Epoch: 6| Step: 1
Training loss: 2.166933984649589
Validation loss: 2.613184992066817

Epoch: 6| Step: 2
Training loss: 2.1154798539603745
Validation loss: 2.605077724119612

Epoch: 6| Step: 3
Training loss: 2.8696408286957746
Validation loss: 2.5295170835619896

Epoch: 6| Step: 4
Training loss: 1.802846126047734
Validation loss: 2.5986249863109023

Epoch: 6| Step: 5
Training loss: 2.1783932360599785
Validation loss: 2.641483137594535

Epoch: 6| Step: 6
Training loss: 1.9275954794582755
Validation loss: 2.592190860616382

Epoch: 6| Step: 7
Training loss: 1.4060696804149682
Validation loss: 2.601708863780741

Epoch: 6| Step: 8
Training loss: 2.3709881678896987
Validation loss: 2.705891932610003

Epoch: 6| Step: 9
Training loss: 1.7223952045868252
Validation loss: 2.6391852882892115

Epoch: 6| Step: 10
Training loss: 2.349383183957495
Validation loss: 2.509006347310724

Epoch: 6| Step: 11
Training loss: 2.1647049263613023
Validation loss: 2.576553623565725

Epoch: 6| Step: 12
Training loss: 1.5220923329290992
Validation loss: 2.5626320983709046

Epoch: 6| Step: 13
Training loss: 2.028373559611928
Validation loss: 2.5640019872836013

Epoch: 407| Step: 0
Training loss: 2.46358209836228
Validation loss: 2.5685714518708114

Epoch: 6| Step: 1
Training loss: 1.1714225404198673
Validation loss: 2.5996137831484067

Epoch: 6| Step: 2
Training loss: 2.5299693506065535
Validation loss: 2.640552112718774

Epoch: 6| Step: 3
Training loss: 1.457619555953288
Validation loss: 2.574335951722266

Epoch: 6| Step: 4
Training loss: 2.3415633109781266
Validation loss: 2.657422288050069

Epoch: 6| Step: 5
Training loss: 1.7069414407600039
Validation loss: 2.501506281911857

Epoch: 6| Step: 6
Training loss: 1.9817885115274023
Validation loss: 2.525582283416152

Epoch: 6| Step: 7
Training loss: 2.237142063259742
Validation loss: 2.566145239786614

Epoch: 6| Step: 8
Training loss: 2.634553780603897
Validation loss: 2.5717523973058443

Epoch: 6| Step: 9
Training loss: 2.2775715473548384
Validation loss: 2.59908780573574

Epoch: 6| Step: 10
Training loss: 2.4914602336615266
Validation loss: 2.582427889967274

Epoch: 6| Step: 11
Training loss: 2.620990688611621
Validation loss: 2.5857004725517885

Epoch: 6| Step: 12
Training loss: 1.9954382012188256
Validation loss: 2.6480398694826377

Epoch: 6| Step: 13
Training loss: 2.5202290359743715
Validation loss: 2.5307698069693663

Epoch: 408| Step: 0
Training loss: 1.9859885316500343
Validation loss: 2.616590683265401

Epoch: 6| Step: 1
Training loss: 2.4520759040073927
Validation loss: 2.6114643484245503

Epoch: 6| Step: 2
Training loss: 1.7627545544927024
Validation loss: 2.5907709414556246

Epoch: 6| Step: 3
Training loss: 1.7887197774257237
Validation loss: 2.599116931846829

Epoch: 6| Step: 4
Training loss: 2.149933339349725
Validation loss: 2.641712709095962

Epoch: 6| Step: 5
Training loss: 2.2828269629049673
Validation loss: 2.505451177233974

Epoch: 6| Step: 6
Training loss: 1.6431419321191139
Validation loss: 2.654313707701627

Epoch: 6| Step: 7
Training loss: 2.0109764729645385
Validation loss: 2.562416469474102

Epoch: 6| Step: 8
Training loss: 1.802504370865304
Validation loss: 2.5058731494212596

Epoch: 6| Step: 9
Training loss: 2.50705068074914
Validation loss: 2.562123318730659

Epoch: 6| Step: 10
Training loss: 2.514133935533424
Validation loss: 2.5919570003565737

Epoch: 6| Step: 11
Training loss: 3.006641665380813
Validation loss: 2.645585194227763

Epoch: 6| Step: 12
Training loss: 2.086494971372796
Validation loss: 2.6610296038245567

Epoch: 6| Step: 13
Training loss: 1.6363382921519973
Validation loss: 2.5610280164837707

Epoch: 409| Step: 0
Training loss: 2.238024525457729
Validation loss: 2.5365259375836984

Epoch: 6| Step: 1
Training loss: 1.8181645240828181
Validation loss: 2.5766514409958483

Epoch: 6| Step: 2
Training loss: 1.4336975226405957
Validation loss: 2.5607146980330704

Epoch: 6| Step: 3
Training loss: 2.311579959437811
Validation loss: 2.609754320014233

Epoch: 6| Step: 4
Training loss: 1.9500992187298125
Validation loss: 2.477069100435709

Epoch: 6| Step: 5
Training loss: 2.345066565441181
Validation loss: 2.5746444692960675

Epoch: 6| Step: 6
Training loss: 2.210296322215809
Validation loss: 2.5825513283955757

Epoch: 6| Step: 7
Training loss: 2.216143084000265
Validation loss: 2.574943935167445

Epoch: 6| Step: 8
Training loss: 2.1225771836264657
Validation loss: 2.544201580485578

Epoch: 6| Step: 9
Training loss: 1.869603592986938
Validation loss: 2.517040745245259

Epoch: 6| Step: 10
Training loss: 1.9887550254197228
Validation loss: 2.6566441937747474

Epoch: 6| Step: 11
Training loss: 2.7683050241540568
Validation loss: 2.634524218163362

Epoch: 6| Step: 12
Training loss: 2.3352294665357736
Validation loss: 2.5604438621160543

Epoch: 6| Step: 13
Training loss: 2.380183936953291
Validation loss: 2.53917135227762

Epoch: 410| Step: 0
Training loss: 2.0486457678095817
Validation loss: 2.5860132698835465

Epoch: 6| Step: 1
Training loss: 2.2570252415467142
Validation loss: 2.518823445983999

Epoch: 6| Step: 2
Training loss: 2.664798310540247
Validation loss: 2.4564869974014307

Epoch: 6| Step: 3
Training loss: 1.3601930721761106
Validation loss: 2.5770798151521763

Epoch: 6| Step: 4
Training loss: 2.7306720183190913
Validation loss: 2.5623106627668295

Epoch: 6| Step: 5
Training loss: 1.8383604253926655
Validation loss: 2.5401100147236204

Epoch: 6| Step: 6
Training loss: 1.9590519202198147
Validation loss: 2.7128223395328064

Epoch: 6| Step: 7
Training loss: 2.0313325131603186
Validation loss: 2.5850789592652323

Epoch: 6| Step: 8
Training loss: 2.0141086049274075
Validation loss: 2.613290185954606

Epoch: 6| Step: 9
Training loss: 2.166195585928889
Validation loss: 2.6132172749712255

Epoch: 6| Step: 10
Training loss: 2.239464358932555
Validation loss: 2.585417779507089

Epoch: 6| Step: 11
Training loss: 1.4236965877437675
Validation loss: 2.5285721163379753

Epoch: 6| Step: 12
Training loss: 2.557609450309269
Validation loss: 2.5101160829331186

Epoch: 6| Step: 13
Training loss: 2.0242656647852373
Validation loss: 2.5835004197414424

Epoch: 411| Step: 0
Training loss: 2.414361336491904
Validation loss: 2.609848055231123

Epoch: 6| Step: 1
Training loss: 2.60993458121444
Validation loss: 2.518717026362996

Epoch: 6| Step: 2
Training loss: 2.1602222508424145
Validation loss: 2.6250028576032065

Epoch: 6| Step: 3
Training loss: 1.4307786290252131
Validation loss: 2.552748405650913

Epoch: 6| Step: 4
Training loss: 2.1973355023611036
Validation loss: 2.558230245619684

Epoch: 6| Step: 5
Training loss: 2.5939858570639798
Validation loss: 2.618844706235732

Epoch: 6| Step: 6
Training loss: 1.655682736546069
Validation loss: 2.6396436008930184

Epoch: 6| Step: 7
Training loss: 2.08913813292174
Validation loss: 2.6243837534640275

Epoch: 6| Step: 8
Training loss: 2.172880530003538
Validation loss: 2.5708267052143308

Epoch: 6| Step: 9
Training loss: 1.3714155813862172
Validation loss: 2.511403128225287

Epoch: 6| Step: 10
Training loss: 2.214984330924866
Validation loss: 2.6234260885856058

Epoch: 6| Step: 11
Training loss: 2.232759438505545
Validation loss: 2.56988381081941

Epoch: 6| Step: 12
Training loss: 2.548748894991034
Validation loss: 2.597987753025495

Epoch: 6| Step: 13
Training loss: 2.3126535106947093
Validation loss: 2.570141499325504

Epoch: 412| Step: 0
Training loss: 2.8299915203061796
Validation loss: 2.5886371319536803

Epoch: 6| Step: 1
Training loss: 1.620402213898867
Validation loss: 2.4850063779319136

Epoch: 6| Step: 2
Training loss: 1.9130158968961402
Validation loss: 2.544561740132229

Epoch: 6| Step: 3
Training loss: 2.2781682558492533
Validation loss: 2.558224871271854

Epoch: 6| Step: 4
Training loss: 2.0600254357258314
Validation loss: 2.5829558872465825

Epoch: 6| Step: 5
Training loss: 2.344271283989076
Validation loss: 2.5320491301578767

Epoch: 6| Step: 6
Training loss: 2.207643461134351
Validation loss: 2.6179760600368676

Epoch: 6| Step: 7
Training loss: 2.1469252934457703
Validation loss: 2.585921253252075

Epoch: 6| Step: 8
Training loss: 2.427157836119849
Validation loss: 2.637236125689021

Epoch: 6| Step: 9
Training loss: 2.2193894875090368
Validation loss: 2.6351411908865345

Epoch: 6| Step: 10
Training loss: 1.8937547488514999
Validation loss: 2.5773204553681106

Epoch: 6| Step: 11
Training loss: 2.7996554912070524
Validation loss: 2.5704554948684395

Epoch: 6| Step: 12
Training loss: 1.951411235435508
Validation loss: 2.630713606900072

Epoch: 6| Step: 13
Training loss: 1.64982936728222
Validation loss: 2.5685225354881815

Epoch: 413| Step: 0
Training loss: 2.780531801225394
Validation loss: 2.531278224449944

Epoch: 6| Step: 1
Training loss: 2.2513258524416386
Validation loss: 2.588289003703006

Epoch: 6| Step: 2
Training loss: 2.6232203854389122
Validation loss: 2.590653914251363

Epoch: 6| Step: 3
Training loss: 2.1364328587161934
Validation loss: 2.5990549172698914

Epoch: 6| Step: 4
Training loss: 1.812524334974366
Validation loss: 2.5795345546246984

Epoch: 6| Step: 5
Training loss: 2.8058703805101404
Validation loss: 2.5904284312668424

Epoch: 6| Step: 6
Training loss: 1.7189489076132727
Validation loss: 2.5563163209767117

Epoch: 6| Step: 7
Training loss: 2.0320058736716256
Validation loss: 2.5872766046093294

Epoch: 6| Step: 8
Training loss: 2.341764499163709
Validation loss: 2.6189663685377256

Epoch: 6| Step: 9
Training loss: 1.4669525835920274
Validation loss: 2.5281749354592287

Epoch: 6| Step: 10
Training loss: 2.2010219627854837
Validation loss: 2.6654220863322107

Epoch: 6| Step: 11
Training loss: 1.8925040499241983
Validation loss: 2.631896406259799

Epoch: 6| Step: 12
Training loss: 2.0647970182028534
Validation loss: 2.580546132521855

Epoch: 6| Step: 13
Training loss: 1.7954394369510305
Validation loss: 2.53103892850194

Epoch: 414| Step: 0
Training loss: 1.7599886161262643
Validation loss: 2.570715920358555

Epoch: 6| Step: 1
Training loss: 1.9739867303125913
Validation loss: 2.543852074497951

Epoch: 6| Step: 2
Training loss: 1.8516759395052438
Validation loss: 2.607664574743836

Epoch: 6| Step: 3
Training loss: 2.4455645251577813
Validation loss: 2.5614889127550584

Epoch: 6| Step: 4
Training loss: 2.250494372839038
Validation loss: 2.5876930096664856

Epoch: 6| Step: 5
Training loss: 1.8436599321510763
Validation loss: 2.5683238002335087

Epoch: 6| Step: 6
Training loss: 1.9169360952774837
Validation loss: 2.5787541511453758

Epoch: 6| Step: 7
Training loss: 1.771212488610435
Validation loss: 2.6220002542871073

Epoch: 6| Step: 8
Training loss: 2.1328575492824187
Validation loss: 2.553655741114743

Epoch: 6| Step: 9
Training loss: 2.0397081777869612
Validation loss: 2.55997407976995

Epoch: 6| Step: 10
Training loss: 2.647565489941477
Validation loss: 2.65710009508473

Epoch: 6| Step: 11
Training loss: 2.397034076052189
Validation loss: 2.517274053527706

Epoch: 6| Step: 12
Training loss: 1.9187916157834923
Validation loss: 2.5506369888177445

Epoch: 6| Step: 13
Training loss: 2.1755101362030396
Validation loss: 2.545544104781147

Epoch: 415| Step: 0
Training loss: 2.7106489308263777
Validation loss: 2.6520725570534656

Epoch: 6| Step: 1
Training loss: 2.049294475940706
Validation loss: 2.6210253715016583

Epoch: 6| Step: 2
Training loss: 1.3378929416608591
Validation loss: 2.5935798615904506

Epoch: 6| Step: 3
Training loss: 2.846100893935757
Validation loss: 2.5740281274612618

Epoch: 6| Step: 4
Training loss: 2.216748261443833
Validation loss: 2.631818312286999

Epoch: 6| Step: 5
Training loss: 2.4055618689348726
Validation loss: 2.5412767426551617

Epoch: 6| Step: 6
Training loss: 2.010120060309919
Validation loss: 2.675760020546155

Epoch: 6| Step: 7
Training loss: 1.7107511793436625
Validation loss: 2.622048015587141

Epoch: 6| Step: 8
Training loss: 1.9434467238535331
Validation loss: 2.57252674021877

Epoch: 6| Step: 9
Training loss: 2.035333138830828
Validation loss: 2.6335153864398224

Epoch: 6| Step: 10
Training loss: 1.9333806700775944
Validation loss: 2.6510391865522114

Epoch: 6| Step: 11
Training loss: 2.071302645007918
Validation loss: 2.5823796758438404

Epoch: 6| Step: 12
Training loss: 1.8780430577535019
Validation loss: 2.5975787363169105

Epoch: 6| Step: 13
Training loss: 2.5609368929998997
Validation loss: 2.5528537078895672

Epoch: 416| Step: 0
Training loss: 2.2778426551366664
Validation loss: 2.5682570258448876

Epoch: 6| Step: 1
Training loss: 1.9172800851616008
Validation loss: 2.525602239596594

Epoch: 6| Step: 2
Training loss: 2.290944546298554
Validation loss: 2.550607976995878

Epoch: 6| Step: 3
Training loss: 1.5825747462935837
Validation loss: 2.5401374463607627

Epoch: 6| Step: 4
Training loss: 2.2281178178711603
Validation loss: 2.5750866867895246

Epoch: 6| Step: 5
Training loss: 1.8653771470636584
Validation loss: 2.6047574114433276

Epoch: 6| Step: 6
Training loss: 1.9342610142268382
Validation loss: 2.6129504539701105

Epoch: 6| Step: 7
Training loss: 2.4638362221845296
Validation loss: 2.595846711200342

Epoch: 6| Step: 8
Training loss: 2.070779769276356
Validation loss: 2.540893942724255

Epoch: 6| Step: 9
Training loss: 2.0333841703136257
Validation loss: 2.5565717419898

Epoch: 6| Step: 10
Training loss: 2.4732985302652026
Validation loss: 2.506850245749751

Epoch: 6| Step: 11
Training loss: 1.5287915170666762
Validation loss: 2.5800175168891992

Epoch: 6| Step: 12
Training loss: 2.173009562373462
Validation loss: 2.617583913447929

Epoch: 6| Step: 13
Training loss: 3.0674184112766336
Validation loss: 2.597285695909203

Epoch: 417| Step: 0
Training loss: 1.51973583736808
Validation loss: 2.5114841621153365

Epoch: 6| Step: 1
Training loss: 1.9374643137937073
Validation loss: 2.6260869822231774

Epoch: 6| Step: 2
Training loss: 2.1724702307589707
Validation loss: 2.529514601523407

Epoch: 6| Step: 3
Training loss: 2.028500618264826
Validation loss: 2.5783681556585925

Epoch: 6| Step: 4
Training loss: 1.6125492531994614
Validation loss: 2.5450799906261294

Epoch: 6| Step: 5
Training loss: 2.0999094761910624
Validation loss: 2.512436541067783

Epoch: 6| Step: 6
Training loss: 2.1185827408659357
Validation loss: 2.52473394104354

Epoch: 6| Step: 7
Training loss: 2.4747497470607795
Validation loss: 2.5142874703610407

Epoch: 6| Step: 8
Training loss: 1.6841159373625427
Validation loss: 2.5300142539817414

Epoch: 6| Step: 9
Training loss: 1.7954328637739987
Validation loss: 2.5565011593961655

Epoch: 6| Step: 10
Training loss: 2.3012108393646753
Validation loss: 2.563976305774843

Epoch: 6| Step: 11
Training loss: 3.366331482873885
Validation loss: 2.639756115266884

Epoch: 6| Step: 12
Training loss: 1.8130201711400493
Validation loss: 2.558523591924012

Epoch: 6| Step: 13
Training loss: 2.0114539703632635
Validation loss: 2.598379337749389

Epoch: 418| Step: 0
Training loss: 1.3971460015523165
Validation loss: 2.567943412890645

Epoch: 6| Step: 1
Training loss: 2.0065286888430953
Validation loss: 2.62320278052183

Epoch: 6| Step: 2
Training loss: 2.0795473666307855
Validation loss: 2.577191236137073

Epoch: 6| Step: 3
Training loss: 1.81200086363715
Validation loss: 2.544627417065912

Epoch: 6| Step: 4
Training loss: 2.6450440037894305
Validation loss: 2.613560418175022

Epoch: 6| Step: 5
Training loss: 2.1492059616435006
Validation loss: 2.570473112974148

Epoch: 6| Step: 6
Training loss: 1.6860898801935758
Validation loss: 2.6145021937265764

Epoch: 6| Step: 7
Training loss: 1.8758950322478944
Validation loss: 2.5846206578241717

Epoch: 6| Step: 8
Training loss: 2.4963613733805343
Validation loss: 2.6202306460181584

Epoch: 6| Step: 9
Training loss: 1.84933827396293
Validation loss: 2.592729523159421

Epoch: 6| Step: 10
Training loss: 2.4481812246224237
Validation loss: 2.563916900864757

Epoch: 6| Step: 11
Training loss: 2.398486108939681
Validation loss: 2.5991657182640546

Epoch: 6| Step: 12
Training loss: 1.8576724808964327
Validation loss: 2.529381708060803

Epoch: 6| Step: 13
Training loss: 3.1385284561974784
Validation loss: 2.6603495571106395

Epoch: 419| Step: 0
Training loss: 2.370413115345581
Validation loss: 2.603756762987359

Epoch: 6| Step: 1
Training loss: 1.9882157770255178
Validation loss: 2.5905969805341287

Epoch: 6| Step: 2
Training loss: 2.807856222840791
Validation loss: 2.5128049417362037

Epoch: 6| Step: 3
Training loss: 1.921635806698029
Validation loss: 2.5822225609672596

Epoch: 6| Step: 4
Training loss: 1.8065999124424548
Validation loss: 2.5639437268335588

Epoch: 6| Step: 5
Training loss: 1.8916862598810495
Validation loss: 2.6568022200395616

Epoch: 6| Step: 6
Training loss: 2.153387630041857
Validation loss: 2.5651785784398755

Epoch: 6| Step: 7
Training loss: 2.579032044808085
Validation loss: 2.592189401861528

Epoch: 6| Step: 8
Training loss: 1.8622054027062338
Validation loss: 2.584044139542563

Epoch: 6| Step: 9
Training loss: 2.236289957711964
Validation loss: 2.576703873358691

Epoch: 6| Step: 10
Training loss: 1.99394728781645
Validation loss: 2.5605730289287334

Epoch: 6| Step: 11
Training loss: 1.8460286171328542
Validation loss: 2.628955349544959

Epoch: 6| Step: 12
Training loss: 2.3865815917716597
Validation loss: 2.5955649197557196

Epoch: 6| Step: 13
Training loss: 1.9563788204008352
Validation loss: 2.607991464413047

Epoch: 420| Step: 0
Training loss: 2.7255153448680276
Validation loss: 2.5968873093551976

Epoch: 6| Step: 1
Training loss: 2.3464156187578804
Validation loss: 2.6151117871716574

Epoch: 6| Step: 2
Training loss: 1.8812986120489068
Validation loss: 2.59568977789251

Epoch: 6| Step: 3
Training loss: 2.799103429847909
Validation loss: 2.6081973287075155

Epoch: 6| Step: 4
Training loss: 1.3189239423396937
Validation loss: 2.54519299024801

Epoch: 6| Step: 5
Training loss: 2.0624256698623773
Validation loss: 2.587787916482971

Epoch: 6| Step: 6
Training loss: 1.9176396167163996
Validation loss: 2.608894595224799

Epoch: 6| Step: 7
Training loss: 2.037860618459603
Validation loss: 2.5821340604144036

Epoch: 6| Step: 8
Training loss: 1.9592922649529332
Validation loss: 2.4871912656998956

Epoch: 6| Step: 9
Training loss: 2.1257536056723056
Validation loss: 2.607347513843521

Epoch: 6| Step: 10
Training loss: 1.9698865728110364
Validation loss: 2.5705287640518497

Epoch: 6| Step: 11
Training loss: 2.000349848666309
Validation loss: 2.57984520981941

Epoch: 6| Step: 12
Training loss: 1.997382955165629
Validation loss: 2.618209575134745

Epoch: 6| Step: 13
Training loss: 2.4622810692455164
Validation loss: 2.46436443602049

Epoch: 421| Step: 0
Training loss: 2.0882576030244344
Validation loss: 2.539781766854775

Epoch: 6| Step: 1
Training loss: 2.119091233763412
Validation loss: 2.6143543501189064

Epoch: 6| Step: 2
Training loss: 3.0837646560722702
Validation loss: 2.5364231463371874

Epoch: 6| Step: 3
Training loss: 2.1798193013256593
Validation loss: 2.609153632552839

Epoch: 6| Step: 4
Training loss: 1.7693990695923758
Validation loss: 2.5758732791663155

Epoch: 6| Step: 5
Training loss: 2.2383449472148316
Validation loss: 2.6654665217748046

Epoch: 6| Step: 6
Training loss: 2.141406174290575
Validation loss: 2.598720849337667

Epoch: 6| Step: 7
Training loss: 2.043561393597725
Validation loss: 2.5995144766986287

Epoch: 6| Step: 8
Training loss: 1.616392446968804
Validation loss: 2.691412079466918

Epoch: 6| Step: 9
Training loss: 2.1105188729735374
Validation loss: 2.5833382846283346

Epoch: 6| Step: 10
Training loss: 1.4894350240364351
Validation loss: 2.5950002433211967

Epoch: 6| Step: 11
Training loss: 2.0745733213084128
Validation loss: 2.6347538671790125

Epoch: 6| Step: 12
Training loss: 2.391514531612411
Validation loss: 2.727474333905155

Epoch: 6| Step: 13
Training loss: 2.2162192512182126
Validation loss: 2.5742663710632936

Epoch: 422| Step: 0
Training loss: 2.3603311584373565
Validation loss: 2.629580152107494

Epoch: 6| Step: 1
Training loss: 1.666652758858191
Validation loss: 2.5984719077056586

Epoch: 6| Step: 2
Training loss: 2.6375044944688733
Validation loss: 2.5768770232123077

Epoch: 6| Step: 3
Training loss: 1.8336947763938913
Validation loss: 2.5873063779356347

Epoch: 6| Step: 4
Training loss: 1.5778616506076355
Validation loss: 2.576467828278629

Epoch: 6| Step: 5
Training loss: 2.545580575968869
Validation loss: 2.6833929515257053

Epoch: 6| Step: 6
Training loss: 2.377311384900255
Validation loss: 2.5162390136201784

Epoch: 6| Step: 7
Training loss: 1.745171766489652
Validation loss: 2.5640417093769345

Epoch: 6| Step: 8
Training loss: 1.6524946716499702
Validation loss: 2.4531848618786896

Epoch: 6| Step: 9
Training loss: 2.043774068614846
Validation loss: 2.62782487282102

Epoch: 6| Step: 10
Training loss: 2.2207979234039867
Validation loss: 2.618512690192573

Epoch: 6| Step: 11
Training loss: 1.628973138474162
Validation loss: 2.560746626274629

Epoch: 6| Step: 12
Training loss: 1.9966499165939968
Validation loss: 2.5522796401331855

Epoch: 6| Step: 13
Training loss: 1.3980147932304094
Validation loss: 2.5570982898004186

Epoch: 423| Step: 0
Training loss: 1.953541947683085
Validation loss: 2.6116966749372237

Epoch: 6| Step: 1
Training loss: 2.118709115953316
Validation loss: 2.5669915827305685

Epoch: 6| Step: 2
Training loss: 1.6271935110199087
Validation loss: 2.5307218663294413

Epoch: 6| Step: 3
Training loss: 1.7984197859301845
Validation loss: 2.5440414049349904

Epoch: 6| Step: 4
Training loss: 1.6049900501453813
Validation loss: 2.5194801747018936

Epoch: 6| Step: 5
Training loss: 2.882991795533805
Validation loss: 2.542149199567051

Epoch: 6| Step: 6
Training loss: 1.7842772341800155
Validation loss: 2.581899712229029

Epoch: 6| Step: 7
Training loss: 1.7713764330227106
Validation loss: 2.607635887217857

Epoch: 6| Step: 8
Training loss: 1.872484045024376
Validation loss: 2.6294982474719575

Epoch: 6| Step: 9
Training loss: 2.2001669213519968
Validation loss: 2.6458235435185222

Epoch: 6| Step: 10
Training loss: 2.0758376763154303
Validation loss: 2.5798920771462557

Epoch: 6| Step: 11
Training loss: 2.51649355850896
Validation loss: 2.530933659641105

Epoch: 6| Step: 12
Training loss: 2.4068836517297356
Validation loss: 2.5728042961280337

Epoch: 6| Step: 13
Training loss: 2.312416281344589
Validation loss: 2.505221881428593

Epoch: 424| Step: 0
Training loss: 2.1214048603562143
Validation loss: 2.5620735287784697

Epoch: 6| Step: 1
Training loss: 1.9920207832738275
Validation loss: 2.57394893511377

Epoch: 6| Step: 2
Training loss: 2.679820243728353
Validation loss: 2.6430939638232918

Epoch: 6| Step: 3
Training loss: 2.229021608380556
Validation loss: 2.4724430195176503

Epoch: 6| Step: 4
Training loss: 2.236732572938535
Validation loss: 2.5837808261785105

Epoch: 6| Step: 5
Training loss: 2.4248525712335622
Validation loss: 2.6220357441379836

Epoch: 6| Step: 6
Training loss: 1.883072704522148
Validation loss: 2.526812676880891

Epoch: 6| Step: 7
Training loss: 1.7878227769422617
Validation loss: 2.6277055504425144

Epoch: 6| Step: 8
Training loss: 1.5851961855607364
Validation loss: 2.5342626191963995

Epoch: 6| Step: 9
Training loss: 1.7621748306406166
Validation loss: 2.5469319910753963

Epoch: 6| Step: 10
Training loss: 2.4059900911338006
Validation loss: 2.557002534647417

Epoch: 6| Step: 11
Training loss: 1.9391744207870056
Validation loss: 2.590572349408854

Epoch: 6| Step: 12
Training loss: 1.7530993536230928
Validation loss: 2.580483865375887

Epoch: 6| Step: 13
Training loss: 2.1644424490535417
Validation loss: 2.62545966202695

Epoch: 425| Step: 0
Training loss: 2.4537135104683836
Validation loss: 2.58594638371984

Epoch: 6| Step: 1
Training loss: 2.798502954412976
Validation loss: 2.620537472250062

Epoch: 6| Step: 2
Training loss: 1.849587525960741
Validation loss: 2.5456315153148084

Epoch: 6| Step: 3
Training loss: 1.5894608470010105
Validation loss: 2.5479315780549303

Epoch: 6| Step: 4
Training loss: 2.183553569062331
Validation loss: 2.5631899061275893

Epoch: 6| Step: 5
Training loss: 2.0078509731540106
Validation loss: 2.5996833520103397

Epoch: 6| Step: 6
Training loss: 1.7385085053783043
Validation loss: 2.5683439573320155

Epoch: 6| Step: 7
Training loss: 1.2341401564854433
Validation loss: 2.5877510712683023

Epoch: 6| Step: 8
Training loss: 2.1882462454804705
Validation loss: 2.5744107525675024

Epoch: 6| Step: 9
Training loss: 2.2991474354423476
Validation loss: 2.5959698453540683

Epoch: 6| Step: 10
Training loss: 2.623197936070437
Validation loss: 2.5358664061217198

Epoch: 6| Step: 11
Training loss: 2.0437552869069258
Validation loss: 2.545400341940007

Epoch: 6| Step: 12
Training loss: 1.972913306077984
Validation loss: 2.549638527350238

Epoch: 6| Step: 13
Training loss: 2.0123664479930836
Validation loss: 2.5474442213864448

Epoch: 426| Step: 0
Training loss: 1.9201041646358037
Validation loss: 2.5815889249184467

Epoch: 6| Step: 1
Training loss: 2.2451970441702613
Validation loss: 2.5137820419327275

Epoch: 6| Step: 2
Training loss: 1.6142660834255746
Validation loss: 2.5861310572590575

Epoch: 6| Step: 3
Training loss: 2.4064325040493886
Validation loss: 2.639639568438014

Epoch: 6| Step: 4
Training loss: 1.9328701322161574
Validation loss: 2.5884336469363385

Epoch: 6| Step: 5
Training loss: 2.819915997221243
Validation loss: 2.5841123165289948

Epoch: 6| Step: 6
Training loss: 1.3745296714247217
Validation loss: 2.5703342971802607

Epoch: 6| Step: 7
Training loss: 1.50494570789438
Validation loss: 2.5611373936172805

Epoch: 6| Step: 8
Training loss: 2.2696128738616386
Validation loss: 2.536094012887167

Epoch: 6| Step: 9
Training loss: 2.3229539010067315
Validation loss: 2.553253438657015

Epoch: 6| Step: 10
Training loss: 2.1002432500646533
Validation loss: 2.6370853195087163

Epoch: 6| Step: 11
Training loss: 1.7043546384875803
Validation loss: 2.553223887754222

Epoch: 6| Step: 12
Training loss: 2.2776006485005866
Validation loss: 2.5969259894392134

Epoch: 6| Step: 13
Training loss: 1.7248420255997783
Validation loss: 2.5177161920172915

Epoch: 427| Step: 0
Training loss: 1.2111255622773485
Validation loss: 2.6422403395550673

Epoch: 6| Step: 1
Training loss: 2.09460147226297
Validation loss: 2.6488673325096452

Epoch: 6| Step: 2
Training loss: 2.1562159438830037
Validation loss: 2.5819281137866366

Epoch: 6| Step: 3
Training loss: 2.409143763824436
Validation loss: 2.5158760548316623

Epoch: 6| Step: 4
Training loss: 2.212623411713016
Validation loss: 2.6138103855676422

Epoch: 6| Step: 5
Training loss: 2.106489907023899
Validation loss: 2.518507059437704

Epoch: 6| Step: 6
Training loss: 2.4552698174342895
Validation loss: 2.5398755398508412

Epoch: 6| Step: 7
Training loss: 2.034271926729832
Validation loss: 2.4854734941792316

Epoch: 6| Step: 8
Training loss: 3.1178406148306084
Validation loss: 2.4916289246794525

Epoch: 6| Step: 9
Training loss: 1.4949878559448593
Validation loss: 2.5798840877800306

Epoch: 6| Step: 10
Training loss: 1.6348738366776279
Validation loss: 2.5365302299792165

Epoch: 6| Step: 11
Training loss: 1.8578896881058806
Validation loss: 2.571391468932842

Epoch: 6| Step: 12
Training loss: 1.5160275740669829
Validation loss: 2.6204689970578667

Epoch: 6| Step: 13
Training loss: 2.5143075656405784
Validation loss: 2.6538888685797173

Epoch: 428| Step: 0
Training loss: 1.6610086563959607
Validation loss: 2.5453473503574147

Epoch: 6| Step: 1
Training loss: 1.5666792862295968
Validation loss: 2.628284136394131

Epoch: 6| Step: 2
Training loss: 2.2840612151632533
Validation loss: 2.624538689709659

Epoch: 6| Step: 3
Training loss: 1.9851538263671684
Validation loss: 2.555230150695288

Epoch: 6| Step: 4
Training loss: 2.3062459557970767
Validation loss: 2.5120848454589346

Epoch: 6| Step: 5
Training loss: 2.179501980232167
Validation loss: 2.610902041374535

Epoch: 6| Step: 6
Training loss: 1.77080040695396
Validation loss: 2.5142203753228727

Epoch: 6| Step: 7
Training loss: 1.6650829499577096
Validation loss: 2.52223786051413

Epoch: 6| Step: 8
Training loss: 2.3196716451122334
Validation loss: 2.654243772284393

Epoch: 6| Step: 9
Training loss: 2.0886793083314052
Validation loss: 2.5966645475719052

Epoch: 6| Step: 10
Training loss: 2.0789937662872466
Validation loss: 2.5743963022341085

Epoch: 6| Step: 11
Training loss: 1.8065255453213047
Validation loss: 2.5808247153180965

Epoch: 6| Step: 12
Training loss: 2.5030942841168056
Validation loss: 2.6671002401486508

Epoch: 6| Step: 13
Training loss: 1.6040762921261893
Validation loss: 2.6329155280387435

Epoch: 429| Step: 0
Training loss: 2.2117951687486244
Validation loss: 2.6039913356373425

Epoch: 6| Step: 1
Training loss: 1.9578111506987943
Validation loss: 2.446562190482311

Epoch: 6| Step: 2
Training loss: 2.9134406277636593
Validation loss: 2.538222309243881

Epoch: 6| Step: 3
Training loss: 2.0069242063541037
Validation loss: 2.6164902212632435

Epoch: 6| Step: 4
Training loss: 2.142005197014724
Validation loss: 2.4941370778342806

Epoch: 6| Step: 5
Training loss: 2.2102604021307197
Validation loss: 2.6152788926868356

Epoch: 6| Step: 6
Training loss: 1.9636003264578639
Validation loss: 2.5339843118292382

Epoch: 6| Step: 7
Training loss: 2.6878397527226054
Validation loss: 2.5548434077439586

Epoch: 6| Step: 8
Training loss: 1.5799364325858058
Validation loss: 2.5868548097280337

Epoch: 6| Step: 9
Training loss: 1.8174502418139888
Validation loss: 2.546040827988073

Epoch: 6| Step: 10
Training loss: 2.3158246447205832
Validation loss: 2.555912361037691

Epoch: 6| Step: 11
Training loss: 1.1627058277651081
Validation loss: 2.5000300928581196

Epoch: 6| Step: 12
Training loss: 1.8482777233833467
Validation loss: 2.5875350597055884

Epoch: 6| Step: 13
Training loss: 2.430041909817952
Validation loss: 2.589843071930497

Epoch: 430| Step: 0
Training loss: 1.1255121125120675
Validation loss: 2.51387317367546

Epoch: 6| Step: 1
Training loss: 1.9833912250607415
Validation loss: 2.5495028788758223

Epoch: 6| Step: 2
Training loss: 1.815075064543943
Validation loss: 2.540219164239316

Epoch: 6| Step: 3
Training loss: 2.3107660339584988
Validation loss: 2.6057315644729306

Epoch: 6| Step: 4
Training loss: 2.0235076067352407
Validation loss: 2.5447398313205998

Epoch: 6| Step: 5
Training loss: 2.4594838526677103
Validation loss: 2.4760012104622486

Epoch: 6| Step: 6
Training loss: 2.460751190399189
Validation loss: 2.6236048475987386

Epoch: 6| Step: 7
Training loss: 2.6073846592908243
Validation loss: 2.578707630975197

Epoch: 6| Step: 8
Training loss: 1.4674241595191315
Validation loss: 2.5192661246068075

Epoch: 6| Step: 9
Training loss: 1.7741127913098036
Validation loss: 2.6492090805231956

Epoch: 6| Step: 10
Training loss: 2.395088267919725
Validation loss: 2.5571130343858246

Epoch: 6| Step: 11
Training loss: 1.730313950755562
Validation loss: 2.6336994606919504

Epoch: 6| Step: 12
Training loss: 2.0808830602181216
Validation loss: 2.586465435008332

Epoch: 6| Step: 13
Training loss: 2.197161889912393
Validation loss: 2.5787259422907747

Epoch: 431| Step: 0
Training loss: 1.4285850234747195
Validation loss: 2.55586505800297

Epoch: 6| Step: 1
Training loss: 1.7707585337679752
Validation loss: 2.5068224935766623

Epoch: 6| Step: 2
Training loss: 2.3426209845795753
Validation loss: 2.593854767884734

Epoch: 6| Step: 3
Training loss: 2.834765315492783
Validation loss: 2.593694641574172

Epoch: 6| Step: 4
Training loss: 2.1586197809064265
Validation loss: 2.5684870637909674

Epoch: 6| Step: 5
Training loss: 1.4848752433698942
Validation loss: 2.5634067420807183

Epoch: 6| Step: 6
Training loss: 2.0564278893788344
Validation loss: 2.521492752749215

Epoch: 6| Step: 7
Training loss: 2.020074000372259
Validation loss: 2.5733535330616815

Epoch: 6| Step: 8
Training loss: 2.3082525062411086
Validation loss: 2.6277151797888108

Epoch: 6| Step: 9
Training loss: 1.7154974245537393
Validation loss: 2.4975952129073

Epoch: 6| Step: 10
Training loss: 2.450381159813538
Validation loss: 2.5981904394628845

Epoch: 6| Step: 11
Training loss: 1.758402136349964
Validation loss: 2.562436484953574

Epoch: 6| Step: 12
Training loss: 2.0357663929515937
Validation loss: 2.4805793890623993

Epoch: 6| Step: 13
Training loss: 2.17839673836079
Validation loss: 2.579951449087886

Epoch: 432| Step: 0
Training loss: 1.786206693878462
Validation loss: 2.6048178341458685

Epoch: 6| Step: 1
Training loss: 2.249739313918575
Validation loss: 2.6665050960118344

Epoch: 6| Step: 2
Training loss: 2.3739187891502245
Validation loss: 2.577621567920517

Epoch: 6| Step: 3
Training loss: 2.380757230299642
Validation loss: 2.517699562058256

Epoch: 6| Step: 4
Training loss: 2.401748806856744
Validation loss: 2.686612710814278

Epoch: 6| Step: 5
Training loss: 2.429722040550305
Validation loss: 2.5648666675823617

Epoch: 6| Step: 6
Training loss: 2.5781766019338703
Validation loss: 2.6151589870871668

Epoch: 6| Step: 7
Training loss: 1.5822979737541796
Validation loss: 2.5585179797158646

Epoch: 6| Step: 8
Training loss: 1.5310548930527512
Validation loss: 2.5823452055740046

Epoch: 6| Step: 9
Training loss: 1.9863968408752282
Validation loss: 2.4617320496767277

Epoch: 6| Step: 10
Training loss: 2.21040084310675
Validation loss: 2.6548592233882657

Epoch: 6| Step: 11
Training loss: 1.9628148306262034
Validation loss: 2.6493788213445173

Epoch: 6| Step: 12
Training loss: 1.7164754903072994
Validation loss: 2.6522329706226024

Epoch: 6| Step: 13
Training loss: 1.4476770801970418
Validation loss: 2.4997710399994135

Epoch: 433| Step: 0
Training loss: 1.3695658895373752
Validation loss: 2.553343702794462

Epoch: 6| Step: 1
Training loss: 1.649537645930828
Validation loss: 2.51779672846284

Epoch: 6| Step: 2
Training loss: 2.363629982179417
Validation loss: 2.5932673590737796

Epoch: 6| Step: 3
Training loss: 3.128374337882985
Validation loss: 2.5699465323079402

Epoch: 6| Step: 4
Training loss: 1.7603835905981864
Validation loss: 2.54339749936281

Epoch: 6| Step: 5
Training loss: 2.109594602103302
Validation loss: 2.6821678571902496

Epoch: 6| Step: 6
Training loss: 2.0892921932059454
Validation loss: 2.5940714149078743

Epoch: 6| Step: 7
Training loss: 2.19516034125018
Validation loss: 2.518251654238667

Epoch: 6| Step: 8
Training loss: 1.965905208052601
Validation loss: 2.5471005169110095

Epoch: 6| Step: 9
Training loss: 1.7055323674092255
Validation loss: 2.554215988956734

Epoch: 6| Step: 10
Training loss: 2.14078381916825
Validation loss: 2.603102708273057

Epoch: 6| Step: 11
Training loss: 2.1471078538176167
Validation loss: 2.549878059437801

Epoch: 6| Step: 12
Training loss: 1.8439502284062543
Validation loss: 2.497465290508044

Epoch: 6| Step: 13
Training loss: 2.067637085988314
Validation loss: 2.587226501058868

Epoch: 434| Step: 0
Training loss: 2.039953044650156
Validation loss: 2.524626248400893

Epoch: 6| Step: 1
Training loss: 1.4192898063674726
Validation loss: 2.5738730590854875

Epoch: 6| Step: 2
Training loss: 2.381101901037114
Validation loss: 2.6541390173501163

Epoch: 6| Step: 3
Training loss: 1.8826357176797104
Validation loss: 2.650197261844691

Epoch: 6| Step: 4
Training loss: 1.8662764110088859
Validation loss: 2.6413933663412323

Epoch: 6| Step: 5
Training loss: 2.5198126584004332
Validation loss: 2.5988928104970865

Epoch: 6| Step: 6
Training loss: 1.8064430582430657
Validation loss: 2.5377509645626017

Epoch: 6| Step: 7
Training loss: 1.7207137939953718
Validation loss: 2.570127706264756

Epoch: 6| Step: 8
Training loss: 1.8599878150786933
Validation loss: 2.527173329464359

Epoch: 6| Step: 9
Training loss: 1.7555127507167463
Validation loss: 2.5895372019173313

Epoch: 6| Step: 10
Training loss: 2.0331856528052703
Validation loss: 2.608165592100958

Epoch: 6| Step: 11
Training loss: 2.007379032352587
Validation loss: 2.589320482939665

Epoch: 6| Step: 12
Training loss: 2.301348527231963
Validation loss: 2.6700638540225543

Epoch: 6| Step: 13
Training loss: 3.360821080020354
Validation loss: 2.608844758961305

Epoch: 435| Step: 0
Training loss: 2.3353653529232896
Validation loss: 2.5431623386908355

Epoch: 6| Step: 1
Training loss: 1.5462011545741692
Validation loss: 2.589066673768208

Epoch: 6| Step: 2
Training loss: 2.2033253030827824
Validation loss: 2.5258464677342594

Epoch: 6| Step: 3
Training loss: 2.009757795402023
Validation loss: 2.4422289167548783

Epoch: 6| Step: 4
Training loss: 1.7902707346970104
Validation loss: 2.657213351726414

Epoch: 6| Step: 5
Training loss: 1.8591457193523409
Validation loss: 2.5513734219800375

Epoch: 6| Step: 6
Training loss: 2.3227495438424715
Validation loss: 2.5037146724688757

Epoch: 6| Step: 7
Training loss: 1.8700514022371892
Validation loss: 2.5425311409954947

Epoch: 6| Step: 8
Training loss: 2.0976981899394964
Validation loss: 2.526010976710032

Epoch: 6| Step: 9
Training loss: 2.0302728503411247
Validation loss: 2.655064322420101

Epoch: 6| Step: 10
Training loss: 2.14363499102143
Validation loss: 2.54911083589265

Epoch: 6| Step: 11
Training loss: 2.45553722959712
Validation loss: 2.5220880446110123

Epoch: 6| Step: 12
Training loss: 2.266449981972351
Validation loss: 2.5572681837359372

Epoch: 6| Step: 13
Training loss: 1.6523741951520676
Validation loss: 2.5148210208272954

Epoch: 436| Step: 0
Training loss: 2.009286302474712
Validation loss: 2.559654594930789

Epoch: 6| Step: 1
Training loss: 2.8118778812269043
Validation loss: 2.5336888640499864

Epoch: 6| Step: 2
Training loss: 2.0007409868877453
Validation loss: 2.592677256679237

Epoch: 6| Step: 3
Training loss: 2.201293183769078
Validation loss: 2.5673014359947124

Epoch: 6| Step: 4
Training loss: 1.9257853355132246
Validation loss: 2.5798606740247223

Epoch: 6| Step: 5
Training loss: 2.0092044265513005
Validation loss: 2.6687673589822887

Epoch: 6| Step: 6
Training loss: 2.823271406531176
Validation loss: 2.528872476424382

Epoch: 6| Step: 7
Training loss: 2.070421439129703
Validation loss: 2.56325249936836

Epoch: 6| Step: 8
Training loss: 2.0038095194352787
Validation loss: 2.5868586697718166

Epoch: 6| Step: 9
Training loss: 1.9120455332804944
Validation loss: 2.6424549293770436

Epoch: 6| Step: 10
Training loss: 1.8449861940523828
Validation loss: 2.6965549729172675

Epoch: 6| Step: 11
Training loss: 1.8659614144656524
Validation loss: 2.5929802054833826

Epoch: 6| Step: 12
Training loss: 1.8398280699885845
Validation loss: 2.5510034609941767

Epoch: 6| Step: 13
Training loss: 2.151519008133184
Validation loss: 2.5899012654858162

Epoch: 437| Step: 0
Training loss: 1.6112921693431554
Validation loss: 2.621312137470726

Epoch: 6| Step: 1
Training loss: 2.25016233070558
Validation loss: 2.576536679854743

Epoch: 6| Step: 2
Training loss: 1.5623812058112894
Validation loss: 2.4094751838067823

Epoch: 6| Step: 3
Training loss: 1.9472778075056167
Validation loss: 2.5837328764276317

Epoch: 6| Step: 4
Training loss: 2.524606062119471
Validation loss: 2.6470283275313773

Epoch: 6| Step: 5
Training loss: 2.0837709984410697
Validation loss: 2.55044546167331

Epoch: 6| Step: 6
Training loss: 1.9236730212896174
Validation loss: 2.532402496302467

Epoch: 6| Step: 7
Training loss: 1.9674356099586832
Validation loss: 2.5702162536739985

Epoch: 6| Step: 8
Training loss: 2.243535185070194
Validation loss: 2.6375666673830267

Epoch: 6| Step: 9
Training loss: 1.6752571762562012
Validation loss: 2.57785555418753

Epoch: 6| Step: 10
Training loss: 2.228490804254852
Validation loss: 2.6151731219962135

Epoch: 6| Step: 11
Training loss: 2.523752765625661
Validation loss: 2.568402976374788

Epoch: 6| Step: 12
Training loss: 2.205808371630949
Validation loss: 2.5382716146293616

Epoch: 6| Step: 13
Training loss: 1.247944333635359
Validation loss: 2.5842601239673955

Epoch: 438| Step: 0
Training loss: 2.787179519636763
Validation loss: 2.6085589786356715

Epoch: 6| Step: 1
Training loss: 2.106789820286493
Validation loss: 2.5893387974191113

Epoch: 6| Step: 2
Training loss: 2.3230330319759482
Validation loss: 2.568937955253035

Epoch: 6| Step: 3
Training loss: 2.2252619642710267
Validation loss: 2.6056800881165683

Epoch: 6| Step: 4
Training loss: 1.8343242943691396
Validation loss: 2.590838849899763

Epoch: 6| Step: 5
Training loss: 1.637783678249207
Validation loss: 2.54859990218832

Epoch: 6| Step: 6
Training loss: 1.9174592687466
Validation loss: 2.4865656676424295

Epoch: 6| Step: 7
Training loss: 1.895199875972256
Validation loss: 2.5116344349655844

Epoch: 6| Step: 8
Training loss: 1.5612928686678005
Validation loss: 2.6066113085182403

Epoch: 6| Step: 9
Training loss: 2.1482748074053104
Validation loss: 2.6099268832125686

Epoch: 6| Step: 10
Training loss: 2.196854562243793
Validation loss: 2.6198852730448

Epoch: 6| Step: 11
Training loss: 2.181652646215202
Validation loss: 2.55365964632181

Epoch: 6| Step: 12
Training loss: 2.156875519621175
Validation loss: 2.664829100429375

Epoch: 6| Step: 13
Training loss: 1.8771545111582042
Validation loss: 2.548198141600953

Epoch: 439| Step: 0
Training loss: 1.9883656661844011
Validation loss: 2.5767388011434105

Epoch: 6| Step: 1
Training loss: 2.0985001157733776
Validation loss: 2.5539933949765574

Epoch: 6| Step: 2
Training loss: 2.443712192252691
Validation loss: 2.5655416309355514

Epoch: 6| Step: 3
Training loss: 2.3948952427772188
Validation loss: 2.614252119890028

Epoch: 6| Step: 4
Training loss: 2.4839820791018834
Validation loss: 2.4923519625837325

Epoch: 6| Step: 5
Training loss: 1.6601785097312831
Validation loss: 2.4971607431265457

Epoch: 6| Step: 6
Training loss: 2.5321429526063652
Validation loss: 2.5534525391283136

Epoch: 6| Step: 7
Training loss: 1.7110282142315012
Validation loss: 2.5081757548269072

Epoch: 6| Step: 8
Training loss: 1.3951574463678427
Validation loss: 2.5550055610508404

Epoch: 6| Step: 9
Training loss: 1.677552467583098
Validation loss: 2.508750224223281

Epoch: 6| Step: 10
Training loss: 1.9072301877285696
Validation loss: 2.5587047811760364

Epoch: 6| Step: 11
Training loss: 2.0138480463673076
Validation loss: 2.5939105513344565

Epoch: 6| Step: 12
Training loss: 2.5622666415514264
Validation loss: 2.6136478845187643

Epoch: 6| Step: 13
Training loss: 1.9258364655972535
Validation loss: 2.5271705884728037

Epoch: 440| Step: 0
Training loss: 2.2174117659740986
Validation loss: 2.5679345797009248

Epoch: 6| Step: 1
Training loss: 1.1792976796367638
Validation loss: 2.550627513236903

Epoch: 6| Step: 2
Training loss: 1.727568113471993
Validation loss: 2.557178701748552

Epoch: 6| Step: 3
Training loss: 2.485214667306717
Validation loss: 2.6033888763217417

Epoch: 6| Step: 4
Training loss: 2.3625579988333754
Validation loss: 2.516841550701149

Epoch: 6| Step: 5
Training loss: 1.694695637363521
Validation loss: 2.552696915365244

Epoch: 6| Step: 6
Training loss: 1.6311128522140075
Validation loss: 2.507593556746301

Epoch: 6| Step: 7
Training loss: 1.64533922367546
Validation loss: 2.5705266826434454

Epoch: 6| Step: 8
Training loss: 2.1283690728532774
Validation loss: 2.6201805390928015

Epoch: 6| Step: 9
Training loss: 2.477837363792024
Validation loss: 2.578213461672387

Epoch: 6| Step: 10
Training loss: 2.4763329817738757
Validation loss: 2.5326663305651755

Epoch: 6| Step: 11
Training loss: 2.2040502891272586
Validation loss: 2.6156388097743433

Epoch: 6| Step: 12
Training loss: 2.3838176670882096
Validation loss: 2.5499134511895867

Epoch: 6| Step: 13
Training loss: 2.1702457601723126
Validation loss: 2.576110306212849

Epoch: 441| Step: 0
Training loss: 1.4812629602565435
Validation loss: 2.560268812358564

Epoch: 6| Step: 1
Training loss: 2.651548375916502
Validation loss: 2.609063492252949

Epoch: 6| Step: 2
Training loss: 2.112741228584893
Validation loss: 2.5200559847580557

Epoch: 6| Step: 3
Training loss: 1.746925036646948
Validation loss: 2.5961569371751523

Epoch: 6| Step: 4
Training loss: 2.379614613369232
Validation loss: 2.555293724472254

Epoch: 6| Step: 5
Training loss: 1.817151251158302
Validation loss: 2.655713689662716

Epoch: 6| Step: 6
Training loss: 1.783024556472789
Validation loss: 2.5861127844980354

Epoch: 6| Step: 7
Training loss: 2.0782688636029234
Validation loss: 2.619096266919708

Epoch: 6| Step: 8
Training loss: 1.5477400393577574
Validation loss: 2.620958094551499

Epoch: 6| Step: 9
Training loss: 2.2094938599638647
Validation loss: 2.552974306490857

Epoch: 6| Step: 10
Training loss: 1.4202141756073086
Validation loss: 2.5211767621891443

Epoch: 6| Step: 11
Training loss: 2.4643925708799324
Validation loss: 2.627717388582216

Epoch: 6| Step: 12
Training loss: 2.1520723424472665
Validation loss: 2.5162593566819353

Epoch: 6| Step: 13
Training loss: 1.7112121361611097
Validation loss: 2.5251508239062286

Epoch: 442| Step: 0
Training loss: 2.0569220746106325
Validation loss: 2.574288919505718

Epoch: 6| Step: 1
Training loss: 1.878128430050782
Validation loss: 2.57249243988132

Epoch: 6| Step: 2
Training loss: 1.8295361541778752
Validation loss: 2.5294979042017767

Epoch: 6| Step: 3
Training loss: 2.116719662260705
Validation loss: 2.53728238161752

Epoch: 6| Step: 4
Training loss: 1.7724320170247334
Validation loss: 2.4700714589208146

Epoch: 6| Step: 5
Training loss: 2.253972044303448
Validation loss: 2.5237318562092708

Epoch: 6| Step: 6
Training loss: 2.6156280882166563
Validation loss: 2.5115577644759637

Epoch: 6| Step: 7
Training loss: 2.044737420420832
Validation loss: 2.6106828866830236

Epoch: 6| Step: 8
Training loss: 1.8992634926864385
Validation loss: 2.593210639921457

Epoch: 6| Step: 9
Training loss: 1.938808675993468
Validation loss: 2.5334212960103932

Epoch: 6| Step: 10
Training loss: 1.8573905549081253
Validation loss: 2.4740352512874026

Epoch: 6| Step: 11
Training loss: 2.580262933388751
Validation loss: 2.653751008966069

Epoch: 6| Step: 12
Training loss: 1.76813733438752
Validation loss: 2.5380969613635815

Epoch: 6| Step: 13
Training loss: 2.149078162645025
Validation loss: 2.6032958155040906

Epoch: 443| Step: 0
Training loss: 1.87157534332633
Validation loss: 2.5273438027468065

Epoch: 6| Step: 1
Training loss: 1.685030507793501
Validation loss: 2.5791507732451597

Epoch: 6| Step: 2
Training loss: 2.445116321628471
Validation loss: 2.4637691511838296

Epoch: 6| Step: 3
Training loss: 1.4189277537572835
Validation loss: 2.5266934747118195

Epoch: 6| Step: 4
Training loss: 2.047839337968699
Validation loss: 2.644767364984949

Epoch: 6| Step: 5
Training loss: 1.69613163579362
Validation loss: 2.5556023758244404

Epoch: 6| Step: 6
Training loss: 1.471184923909134
Validation loss: 2.4539319152082233

Epoch: 6| Step: 7
Training loss: 2.2228299091525634
Validation loss: 2.5881858137558607

Epoch: 6| Step: 8
Training loss: 2.260826976001808
Validation loss: 2.549291375771106

Epoch: 6| Step: 9
Training loss: 2.1578798630217726
Validation loss: 2.5579507214640635

Epoch: 6| Step: 10
Training loss: 2.269463805675472
Validation loss: 2.496320474211212

Epoch: 6| Step: 11
Training loss: 2.107588626179148
Validation loss: 2.533384205531912

Epoch: 6| Step: 12
Training loss: 1.8335362741103307
Validation loss: 2.608374634459356

Epoch: 6| Step: 13
Training loss: 2.5799765671545645
Validation loss: 2.51157031032651

Epoch: 444| Step: 0
Training loss: 1.7438071894411187
Validation loss: 2.541454813368806

Epoch: 6| Step: 1
Training loss: 1.9089393405898565
Validation loss: 2.541349691485652

Epoch: 6| Step: 2
Training loss: 1.7621411411379322
Validation loss: 2.5991734510963798

Epoch: 6| Step: 3
Training loss: 1.8655861088518577
Validation loss: 2.50768394014187

Epoch: 6| Step: 4
Training loss: 2.3303319724007174
Validation loss: 2.4954188221351266

Epoch: 6| Step: 5
Training loss: 1.5020935231082306
Validation loss: 2.557448415403097

Epoch: 6| Step: 6
Training loss: 2.447891386726735
Validation loss: 2.5954663404404346

Epoch: 6| Step: 7
Training loss: 2.166550951092921
Validation loss: 2.502188248877668

Epoch: 6| Step: 8
Training loss: 1.9158113547656384
Validation loss: 2.5608271168742265

Epoch: 6| Step: 9
Training loss: 2.6572480963157235
Validation loss: 2.495245648921666

Epoch: 6| Step: 10
Training loss: 1.6925284735173562
Validation loss: 2.6021822910113874

Epoch: 6| Step: 11
Training loss: 2.569021532692362
Validation loss: 2.595032440271407

Epoch: 6| Step: 12
Training loss: 1.6693355490230037
Validation loss: 2.598938626085533

Epoch: 6| Step: 13
Training loss: 1.977034440824514
Validation loss: 2.517251110471765

Epoch: 445| Step: 0
Training loss: 2.1327242990218935
Validation loss: 2.570867234786641

Epoch: 6| Step: 1
Training loss: 2.231195922538175
Validation loss: 2.5534321103614976

Epoch: 6| Step: 2
Training loss: 1.972105164553811
Validation loss: 2.5739517995942047

Epoch: 6| Step: 3
Training loss: 1.7732808048073956
Validation loss: 2.597481004254926

Epoch: 6| Step: 4
Training loss: 1.922781133645437
Validation loss: 2.5436481790350074

Epoch: 6| Step: 5
Training loss: 1.977271092472975
Validation loss: 2.5064904683787828

Epoch: 6| Step: 6
Training loss: 2.1503477170233807
Validation loss: 2.623432136537051

Epoch: 6| Step: 7
Training loss: 3.1142967032692392
Validation loss: 2.602773747849045

Epoch: 6| Step: 8
Training loss: 1.2307252646809619
Validation loss: 2.5683623560112983

Epoch: 6| Step: 9
Training loss: 2.194961031000848
Validation loss: 2.4795319441565917

Epoch: 6| Step: 10
Training loss: 1.4876612375530578
Validation loss: 2.606463407310136

Epoch: 6| Step: 11
Training loss: 1.782826913546338
Validation loss: 2.532745857184666

Epoch: 6| Step: 12
Training loss: 2.0933199768288233
Validation loss: 2.5726778011599514

Epoch: 6| Step: 13
Training loss: 0.9528369468287708
Validation loss: 2.5504811491097574

Epoch: 446| Step: 0
Training loss: 1.740312328369439
Validation loss: 2.59332162339364

Epoch: 6| Step: 1
Training loss: 1.6981624433189322
Validation loss: 2.598644628195522

Epoch: 6| Step: 2
Training loss: 2.0127674517412135
Validation loss: 2.5598082822827144

Epoch: 6| Step: 3
Training loss: 1.9300910435089638
Validation loss: 2.588559995899848

Epoch: 6| Step: 4
Training loss: 2.1455482614530306
Validation loss: 2.5695679874830883

Epoch: 6| Step: 5
Training loss: 1.8123550357067624
Validation loss: 2.575936348449715

Epoch: 6| Step: 6
Training loss: 2.022339629804447
Validation loss: 2.5333581782219947

Epoch: 6| Step: 7
Training loss: 1.8535365916474182
Validation loss: 2.584935012968112

Epoch: 6| Step: 8
Training loss: 1.6118959108544197
Validation loss: 2.435977577094958

Epoch: 6| Step: 9
Training loss: 3.0606503253096977
Validation loss: 2.5943712799299905

Epoch: 6| Step: 10
Training loss: 2.546073178878044
Validation loss: 2.586056397153435

Epoch: 6| Step: 11
Training loss: 2.2428679281154187
Validation loss: 2.6316134658075896

Epoch: 6| Step: 12
Training loss: 2.189687125966914
Validation loss: 2.56954135891228

Epoch: 6| Step: 13
Training loss: 1.6789836739660269
Validation loss: 2.584725788313958

Epoch: 447| Step: 0
Training loss: 2.6106010800124944
Validation loss: 2.53903127646357

Epoch: 6| Step: 1
Training loss: 1.908210746570309
Validation loss: 2.6145987679160303

Epoch: 6| Step: 2
Training loss: 1.2637868649079798
Validation loss: 2.5940743016403243

Epoch: 6| Step: 3
Training loss: 1.4007168314089387
Validation loss: 2.612177728345751

Epoch: 6| Step: 4
Training loss: 1.7743797991755914
Validation loss: 2.4770689441583778

Epoch: 6| Step: 5
Training loss: 1.641634385361185
Validation loss: 2.539657103628558

Epoch: 6| Step: 6
Training loss: 2.214882071565523
Validation loss: 2.506542392372803

Epoch: 6| Step: 7
Training loss: 2.0789341319385195
Validation loss: 2.5173647166787254

Epoch: 6| Step: 8
Training loss: 1.770224462813311
Validation loss: 2.510698074385523

Epoch: 6| Step: 9
Training loss: 2.1756381359322945
Validation loss: 2.6103629313285506

Epoch: 6| Step: 10
Training loss: 2.2911566311240064
Validation loss: 2.581344259171312

Epoch: 6| Step: 11
Training loss: 2.1020121607406
Validation loss: 2.4540462421800355

Epoch: 6| Step: 12
Training loss: 1.9389747421484627
Validation loss: 2.5733526354622707

Epoch: 6| Step: 13
Training loss: 1.8071950690612124
Validation loss: 2.5635523682307957

Epoch: 448| Step: 0
Training loss: 1.5645213975427568
Validation loss: 2.5841765636850824

Epoch: 6| Step: 1
Training loss: 1.9103579424447448
Validation loss: 2.526145050162599

Epoch: 6| Step: 2
Training loss: 2.316404706108518
Validation loss: 2.606199295401771

Epoch: 6| Step: 3
Training loss: 1.6718637341271274
Validation loss: 2.4574875079557175

Epoch: 6| Step: 4
Training loss: 1.8153536464121112
Validation loss: 2.4984336960892546

Epoch: 6| Step: 5
Training loss: 2.0689017617607885
Validation loss: 2.6014526545023906

Epoch: 6| Step: 6
Training loss: 1.9027303502591004
Validation loss: 2.6433349235824823

Epoch: 6| Step: 7
Training loss: 1.941692246799301
Validation loss: 2.5960503241992066

Epoch: 6| Step: 8
Training loss: 2.170382748614211
Validation loss: 2.5378574941694674

Epoch: 6| Step: 9
Training loss: 1.6655000020659603
Validation loss: 2.571441810238197

Epoch: 6| Step: 10
Training loss: 2.6029883707191943
Validation loss: 2.4797000695521327

Epoch: 6| Step: 11
Training loss: 1.9411966068664992
Validation loss: 2.4990526044954344

Epoch: 6| Step: 12
Training loss: 2.0969733861817934
Validation loss: 2.5048834275977705

Epoch: 6| Step: 13
Training loss: 2.4019032640503983
Validation loss: 2.609178733800792

Epoch: 449| Step: 0
Training loss: 1.779290778173727
Validation loss: 2.4953849813648388

Epoch: 6| Step: 1
Training loss: 1.5788734851667108
Validation loss: 2.6033626586818865

Epoch: 6| Step: 2
Training loss: 1.946205271339824
Validation loss: 2.636209237332556

Epoch: 6| Step: 3
Training loss: 1.605483303328959
Validation loss: 2.6688693092979348

Epoch: 6| Step: 4
Training loss: 2.2080487361795242
Validation loss: 2.530621033083725

Epoch: 6| Step: 5
Training loss: 2.2582890096821577
Validation loss: 2.6028658128545787

Epoch: 6| Step: 6
Training loss: 1.781510651909104
Validation loss: 2.5478296212734275

Epoch: 6| Step: 7
Training loss: 2.077969193891998
Validation loss: 2.6543293078930215

Epoch: 6| Step: 8
Training loss: 2.164366001922295
Validation loss: 2.5760207074597417

Epoch: 6| Step: 9
Training loss: 2.0858570326239705
Validation loss: 2.5933111031717226

Epoch: 6| Step: 10
Training loss: 2.562592946669651
Validation loss: 2.569047264553898

Epoch: 6| Step: 11
Training loss: 2.4966658293345345
Validation loss: 2.6253096236270523

Epoch: 6| Step: 12
Training loss: 2.177309112766072
Validation loss: 2.540814397197939

Epoch: 6| Step: 13
Training loss: 1.8760645069833801
Validation loss: 2.57023118832382

Epoch: 450| Step: 0
Training loss: 2.6593665296551907
Validation loss: 2.600685930524053

Epoch: 6| Step: 1
Training loss: 2.0855148973172963
Validation loss: 2.5838315610984046

Epoch: 6| Step: 2
Training loss: 1.8096894802951533
Validation loss: 2.5271654737056317

Epoch: 6| Step: 3
Training loss: 1.9234507234120366
Validation loss: 2.548000290176994

Epoch: 6| Step: 4
Training loss: 2.3302299661076993
Validation loss: 2.5625072472142447

Epoch: 6| Step: 5
Training loss: 1.6645716215190334
Validation loss: 2.4765789150093735

Epoch: 6| Step: 6
Training loss: 1.8586628295324297
Validation loss: 2.5524103184147218

Epoch: 6| Step: 7
Training loss: 1.7169629603608159
Validation loss: 2.589455869207966

Epoch: 6| Step: 8
Training loss: 1.4214711716204613
Validation loss: 2.6520127938678595

Epoch: 6| Step: 9
Training loss: 2.7910617533583113
Validation loss: 2.564043650072584

Epoch: 6| Step: 10
Training loss: 1.562661200791023
Validation loss: 2.4836955447697826

Epoch: 6| Step: 11
Training loss: 2.0850996413538083
Validation loss: 2.5598581823921007

Epoch: 6| Step: 12
Training loss: 1.4274762673083703
Validation loss: 2.49682953900301

Epoch: 6| Step: 13
Training loss: 2.4256219243357187
Validation loss: 2.6159959451425037

Epoch: 451| Step: 0
Training loss: 2.1354707912625948
Validation loss: 2.610562098769602

Epoch: 6| Step: 1
Training loss: 2.055804047156235
Validation loss: 2.5445172355378483

Epoch: 6| Step: 2
Training loss: 2.048156104411856
Validation loss: 2.522032072784542

Epoch: 6| Step: 3
Training loss: 1.8234253818400215
Validation loss: 2.5894053311160428

Epoch: 6| Step: 4
Training loss: 2.367445424950364
Validation loss: 2.5813902690301234

Epoch: 6| Step: 5
Training loss: 2.106364949426119
Validation loss: 2.5789175576021095

Epoch: 6| Step: 6
Training loss: 1.9532827084765274
Validation loss: 2.602580830410236

Epoch: 6| Step: 7
Training loss: 1.4662802201560914
Validation loss: 2.6039721923733508

Epoch: 6| Step: 8
Training loss: 2.8209328431496385
Validation loss: 2.5030673662472327

Epoch: 6| Step: 9
Training loss: 1.9674689348378545
Validation loss: 2.579345267170654

Epoch: 6| Step: 10
Training loss: 1.721506232288878
Validation loss: 2.6026832063359477

Epoch: 6| Step: 11
Training loss: 1.7344714988462793
Validation loss: 2.611289455026775

Epoch: 6| Step: 12
Training loss: 2.1041272477590236
Validation loss: 2.556326448892134

Epoch: 6| Step: 13
Training loss: 1.7261363750742913
Validation loss: 2.5016913937404484

Epoch: 452| Step: 0
Training loss: 2.8582551357890793
Validation loss: 2.609121580383201

Epoch: 6| Step: 1
Training loss: 1.5497342281754365
Validation loss: 2.540924992535255

Epoch: 6| Step: 2
Training loss: 2.3430619310635117
Validation loss: 2.5499938403784466

Epoch: 6| Step: 3
Training loss: 2.0988328642217455
Validation loss: 2.571193981404025

Epoch: 6| Step: 4
Training loss: 1.423526684911895
Validation loss: 2.612337087269871

Epoch: 6| Step: 5
Training loss: 2.20908572017604
Validation loss: 2.577105999752899

Epoch: 6| Step: 6
Training loss: 1.6290469028846577
Validation loss: 2.5321166189273794

Epoch: 6| Step: 7
Training loss: 2.0309361141943794
Validation loss: 2.51718907518179

Epoch: 6| Step: 8
Training loss: 1.578371840708489
Validation loss: 2.5800191146817872

Epoch: 6| Step: 9
Training loss: 2.0394331204277707
Validation loss: 2.6287050307775677

Epoch: 6| Step: 10
Training loss: 2.6751521129675315
Validation loss: 2.605719559546744

Epoch: 6| Step: 11
Training loss: 1.6430762008669801
Validation loss: 2.511459375724073

Epoch: 6| Step: 12
Training loss: 1.5201101107618264
Validation loss: 2.5385430982755692

Epoch: 6| Step: 13
Training loss: 2.07251561820446
Validation loss: 2.532746596089198

Epoch: 453| Step: 0
Training loss: 1.9396119451273401
Validation loss: 2.540453164389936

Epoch: 6| Step: 1
Training loss: 1.9594097493328544
Validation loss: 2.550468175481683

Epoch: 6| Step: 2
Training loss: 2.091039468824217
Validation loss: 2.5518896080023064

Epoch: 6| Step: 3
Training loss: 1.9506369650833444
Validation loss: 2.459307010752886

Epoch: 6| Step: 4
Training loss: 1.9233610409151807
Validation loss: 2.5791658181785104

Epoch: 6| Step: 5
Training loss: 1.3479456936257381
Validation loss: 2.553878319352544

Epoch: 6| Step: 6
Training loss: 1.6606099305422106
Validation loss: 2.4715637054576716

Epoch: 6| Step: 7
Training loss: 2.459388754199101
Validation loss: 2.4468152163906387

Epoch: 6| Step: 8
Training loss: 1.9343987532776505
Validation loss: 2.609631206570703

Epoch: 6| Step: 9
Training loss: 1.2227322978296442
Validation loss: 2.480903999809413

Epoch: 6| Step: 10
Training loss: 2.5408291817949493
Validation loss: 2.6245423644161345

Epoch: 6| Step: 11
Training loss: 1.9577047746130791
Validation loss: 2.5133337175600663

Epoch: 6| Step: 12
Training loss: 1.9216729654946145
Validation loss: 2.555854187007958

Epoch: 6| Step: 13
Training loss: 1.9008143737641245
Validation loss: 2.490126728431182

Epoch: 454| Step: 0
Training loss: 1.867112289893157
Validation loss: 2.581585405555423

Epoch: 6| Step: 1
Training loss: 1.5492950928499722
Validation loss: 2.4888119028624454

Epoch: 6| Step: 2
Training loss: 2.6164278208907565
Validation loss: 2.572206449404568

Epoch: 6| Step: 3
Training loss: 1.6142171957325877
Validation loss: 2.571983430869053

Epoch: 6| Step: 4
Training loss: 1.4494807990948277
Validation loss: 2.562369855791787

Epoch: 6| Step: 5
Training loss: 2.549900060453025
Validation loss: 2.577742276787361

Epoch: 6| Step: 6
Training loss: 1.6404452270832766
Validation loss: 2.5485709260230567

Epoch: 6| Step: 7
Training loss: 2.4442192778293834
Validation loss: 2.516529213989294

Epoch: 6| Step: 8
Training loss: 2.1668505835113385
Validation loss: 2.550354399354153

Epoch: 6| Step: 9
Training loss: 1.8184448615444844
Validation loss: 2.5875655790680696

Epoch: 6| Step: 10
Training loss: 1.3777831261199456
Validation loss: 2.5456072235544176

Epoch: 6| Step: 11
Training loss: 2.2993722432133747
Validation loss: 2.553271385309307

Epoch: 6| Step: 12
Training loss: 2.4285023242671495
Validation loss: 2.6275265132966332

Epoch: 6| Step: 13
Training loss: 2.0406146810133428
Validation loss: 2.548917319808826

Epoch: 455| Step: 0
Training loss: 1.7529316596654991
Validation loss: 2.411024100023716

Epoch: 6| Step: 1
Training loss: 2.067490522185331
Validation loss: 2.536117003824422

Epoch: 6| Step: 2
Training loss: 2.750870133502133
Validation loss: 2.5282314364782144

Epoch: 6| Step: 3
Training loss: 1.9597603961889272
Validation loss: 2.5174438875587297

Epoch: 6| Step: 4
Training loss: 1.826336890940164
Validation loss: 2.5290501133870453

Epoch: 6| Step: 5
Training loss: 1.992576351737075
Validation loss: 2.5956242146871604

Epoch: 6| Step: 6
Training loss: 1.9111397986267304
Validation loss: 2.616949941879382

Epoch: 6| Step: 7
Training loss: 1.924186804781551
Validation loss: 2.508572268822868

Epoch: 6| Step: 8
Training loss: 1.5544012371651226
Validation loss: 2.45831893310445

Epoch: 6| Step: 9
Training loss: 2.1651852996676686
Validation loss: 2.3945339576044637

Epoch: 6| Step: 10
Training loss: 1.8770330215581652
Validation loss: 2.6068494085285105

Epoch: 6| Step: 11
Training loss: 1.9857458951106333
Validation loss: 2.58298802193264

Epoch: 6| Step: 12
Training loss: 1.9940818606095723
Validation loss: 2.6128088031110486

Epoch: 6| Step: 13
Training loss: 2.5970758463727517
Validation loss: 2.6194583117487205

Epoch: 456| Step: 0
Training loss: 2.139394587505962
Validation loss: 2.605704736800555

Epoch: 6| Step: 1
Training loss: 1.4641189613162389
Validation loss: 2.4664971126920667

Epoch: 6| Step: 2
Training loss: 1.833436666813231
Validation loss: 2.4967715203202885

Epoch: 6| Step: 3
Training loss: 2.3351475837676885
Validation loss: 2.553806670513306

Epoch: 6| Step: 4
Training loss: 1.6923795018766306
Validation loss: 2.702743403756864

Epoch: 6| Step: 5
Training loss: 2.928887423304473
Validation loss: 2.5784914489027613

Epoch: 6| Step: 6
Training loss: 2.0874748137091075
Validation loss: 2.571967715961541

Epoch: 6| Step: 7
Training loss: 1.823420347837502
Validation loss: 2.5409387105497223

Epoch: 6| Step: 8
Training loss: 2.224641526737589
Validation loss: 2.6426478016283674

Epoch: 6| Step: 9
Training loss: 1.9466404805751918
Validation loss: 2.5226462189765053

Epoch: 6| Step: 10
Training loss: 2.141724018956799
Validation loss: 2.5415657540523124

Epoch: 6| Step: 11
Training loss: 1.9569000382894313
Validation loss: 2.5849212413225913

Epoch: 6| Step: 12
Training loss: 1.8549912008812008
Validation loss: 2.4882272974731476

Epoch: 6| Step: 13
Training loss: 1.567530582865803
Validation loss: 2.6247367453425974

Epoch: 457| Step: 0
Training loss: 1.4321795980363266
Validation loss: 2.5605038281903933

Epoch: 6| Step: 1
Training loss: 1.7260570217716524
Validation loss: 2.450166860284697

Epoch: 6| Step: 2
Training loss: 2.1847244092387785
Validation loss: 2.5129885887862766

Epoch: 6| Step: 3
Training loss: 2.4056362013284738
Validation loss: 2.5601519519947407

Epoch: 6| Step: 4
Training loss: 1.9178816082148193
Validation loss: 2.540055544181866

Epoch: 6| Step: 5
Training loss: 2.0412779717009304
Validation loss: 2.627140995408453

Epoch: 6| Step: 6
Training loss: 2.441465917239625
Validation loss: 2.642941421921802

Epoch: 6| Step: 7
Training loss: 2.1335252402336633
Validation loss: 2.6172020882530678

Epoch: 6| Step: 8
Training loss: 1.8820871562579722
Validation loss: 2.600284146920392

Epoch: 6| Step: 9
Training loss: 1.9561225167072902
Validation loss: 2.5314327575588016

Epoch: 6| Step: 10
Training loss: 1.7632800709420904
Validation loss: 2.617591542900167

Epoch: 6| Step: 11
Training loss: 2.416063682923152
Validation loss: 2.4943948391119948

Epoch: 6| Step: 12
Training loss: 1.972659754986057
Validation loss: 2.4928534507115483

Epoch: 6| Step: 13
Training loss: 2.4556075248378026
Validation loss: 2.5702922506189614

Epoch: 458| Step: 0
Training loss: 1.6929790417297208
Validation loss: 2.589932446889754

Epoch: 6| Step: 1
Training loss: 2.749825125249223
Validation loss: 2.5622167173082078

Epoch: 6| Step: 2
Training loss: 2.067742130442133
Validation loss: 2.678320456689929

Epoch: 6| Step: 3
Training loss: 2.2612375857727827
Validation loss: 2.5574838146621017

Epoch: 6| Step: 4
Training loss: 1.7793195871689496
Validation loss: 2.689152787675387

Epoch: 6| Step: 5
Training loss: 1.63251963640119
Validation loss: 2.5855395046091942

Epoch: 6| Step: 6
Training loss: 2.094599992533931
Validation loss: 2.637485108447476

Epoch: 6| Step: 7
Training loss: 1.9695375471910994
Validation loss: 2.5137255210718914

Epoch: 6| Step: 8
Training loss: 1.81682294762488
Validation loss: 2.5060801024183132

Epoch: 6| Step: 9
Training loss: 2.015303238610678
Validation loss: 2.629669003224198

Epoch: 6| Step: 10
Training loss: 1.6123218408384923
Validation loss: 2.6344977829495826

Epoch: 6| Step: 11
Training loss: 2.0099562544356218
Validation loss: 2.5385125990123627

Epoch: 6| Step: 12
Training loss: 1.616856195541758
Validation loss: 2.518627840983778

Epoch: 6| Step: 13
Training loss: 2.0483253523958487
Validation loss: 2.5706636580623776

Epoch: 459| Step: 0
Training loss: 1.7473937108974007
Validation loss: 2.5104372441278993

Epoch: 6| Step: 1
Training loss: 2.117818027650673
Validation loss: 2.534445110963828

Epoch: 6| Step: 2
Training loss: 1.9084085219228748
Validation loss: 2.461533271226832

Epoch: 6| Step: 3
Training loss: 1.3764424993752205
Validation loss: 2.567407450417345

Epoch: 6| Step: 4
Training loss: 1.826921702782118
Validation loss: 2.54529977140838

Epoch: 6| Step: 5
Training loss: 2.165018139205956
Validation loss: 2.6046825608369795

Epoch: 6| Step: 6
Training loss: 2.045260192808392
Validation loss: 2.4589109567747744

Epoch: 6| Step: 7
Training loss: 2.90770217546831
Validation loss: 2.6002094909320497

Epoch: 6| Step: 8
Training loss: 2.0431036530806375
Validation loss: 2.611738528049273

Epoch: 6| Step: 9
Training loss: 1.5709549078537441
Validation loss: 2.525825829392888

Epoch: 6| Step: 10
Training loss: 2.238797805590949
Validation loss: 2.557534853227899

Epoch: 6| Step: 11
Training loss: 1.7261302976657507
Validation loss: 2.4923988582092336

Epoch: 6| Step: 12
Training loss: 2.1266701810482886
Validation loss: 2.5868296841212794

Epoch: 6| Step: 13
Training loss: 2.3163358475020095
Validation loss: 2.518068917389682

Epoch: 460| Step: 0
Training loss: 2.795751761673921
Validation loss: 2.534944769536431

Epoch: 6| Step: 1
Training loss: 1.9417528422582753
Validation loss: 2.5421047717360126

Epoch: 6| Step: 2
Training loss: 2.067516929806235
Validation loss: 2.581106250727704

Epoch: 6| Step: 3
Training loss: 2.358790445228646
Validation loss: 2.5407144392398635

Epoch: 6| Step: 4
Training loss: 1.9867165634857278
Validation loss: 2.5267853065464676

Epoch: 6| Step: 5
Training loss: 1.690631292475979
Validation loss: 2.5614087612290755

Epoch: 6| Step: 6
Training loss: 1.369395538412843
Validation loss: 2.6543895578456627

Epoch: 6| Step: 7
Training loss: 1.847633281024647
Validation loss: 2.602429512869056

Epoch: 6| Step: 8
Training loss: 1.4906968265398588
Validation loss: 2.5017170147323546

Epoch: 6| Step: 9
Training loss: 2.0706645162480757
Validation loss: 2.5780271216364534

Epoch: 6| Step: 10
Training loss: 1.5879346177504425
Validation loss: 2.5443403036139443

Epoch: 6| Step: 11
Training loss: 2.0388814911576767
Validation loss: 2.5417103288740828

Epoch: 6| Step: 12
Training loss: 1.898436746479403
Validation loss: 2.5196454147492684

Epoch: 6| Step: 13
Training loss: 2.023612349920069
Validation loss: 2.6402136709306507

Epoch: 461| Step: 0
Training loss: 1.4686004887229525
Validation loss: 2.6475028895021366

Epoch: 6| Step: 1
Training loss: 2.2129182064697717
Validation loss: 2.56432502539792

Epoch: 6| Step: 2
Training loss: 1.8031969396563525
Validation loss: 2.6054484629217516

Epoch: 6| Step: 3
Training loss: 1.5230247525303284
Validation loss: 2.6401017125555137

Epoch: 6| Step: 4
Training loss: 1.4459859567754358
Validation loss: 2.655798353563973

Epoch: 6| Step: 5
Training loss: 1.8152525160235784
Validation loss: 2.5467836096989322

Epoch: 6| Step: 6
Training loss: 2.67615322673928
Validation loss: 2.4736356729261826

Epoch: 6| Step: 7
Training loss: 1.9160451157659715
Validation loss: 2.66380085278394

Epoch: 6| Step: 8
Training loss: 1.8138924873060616
Validation loss: 2.530716358094297

Epoch: 6| Step: 9
Training loss: 2.345031591336815
Validation loss: 2.5486161051992564

Epoch: 6| Step: 10
Training loss: 2.1443897193663677
Validation loss: 2.5276778708217758

Epoch: 6| Step: 11
Training loss: 1.5063740089621531
Validation loss: 2.5823143887314486

Epoch: 6| Step: 12
Training loss: 2.1164843528307946
Validation loss: 2.5473367823633493

Epoch: 6| Step: 13
Training loss: 2.0177728608828187
Validation loss: 2.513629615967029

Epoch: 462| Step: 0
Training loss: 1.4566717036587173
Validation loss: 2.5181522198349096

Epoch: 6| Step: 1
Training loss: 1.9263745490819872
Validation loss: 2.4930437316836564

Epoch: 6| Step: 2
Training loss: 2.30142446441974
Validation loss: 2.562606483165904

Epoch: 6| Step: 3
Training loss: 2.059741516377317
Validation loss: 2.655199468330079

Epoch: 6| Step: 4
Training loss: 2.16690867857484
Validation loss: 2.5796064518718955

Epoch: 6| Step: 5
Training loss: 1.9167560542727358
Validation loss: 2.5225708710021335

Epoch: 6| Step: 6
Training loss: 2.06420527389617
Validation loss: 2.6732908790034835

Epoch: 6| Step: 7
Training loss: 2.942654409449011
Validation loss: 2.5310974824614174

Epoch: 6| Step: 8
Training loss: 2.0049315686807803
Validation loss: 2.5767920923140037

Epoch: 6| Step: 9
Training loss: 1.879664278085139
Validation loss: 2.4801061753962537

Epoch: 6| Step: 10
Training loss: 1.8789029507994683
Validation loss: 2.551697084297248

Epoch: 6| Step: 11
Training loss: 1.1273006121655855
Validation loss: 2.5298878508800504

Epoch: 6| Step: 12
Training loss: 1.8657958139404287
Validation loss: 2.550918713841985

Epoch: 6| Step: 13
Training loss: 1.2519390325601158
Validation loss: 2.534111148949763

Epoch: 463| Step: 0
Training loss: 2.1239540667551045
Validation loss: 2.533045153574822

Epoch: 6| Step: 1
Training loss: 1.6437918480017124
Validation loss: 2.6441865899000674

Epoch: 6| Step: 2
Training loss: 1.8278807778534858
Validation loss: 2.598414322449278

Epoch: 6| Step: 3
Training loss: 1.6778099034176146
Validation loss: 2.598494043854125

Epoch: 6| Step: 4
Training loss: 2.6579718899126674
Validation loss: 2.558019192518883

Epoch: 6| Step: 5
Training loss: 1.8428672358298803
Validation loss: 2.595475421687377

Epoch: 6| Step: 6
Training loss: 2.276641685140266
Validation loss: 2.5298476259649374

Epoch: 6| Step: 7
Training loss: 2.262843878309447
Validation loss: 2.5511923049234677

Epoch: 6| Step: 8
Training loss: 1.8927324387634177
Validation loss: 2.581832372956677

Epoch: 6| Step: 9
Training loss: 1.7827129045328058
Validation loss: 2.648622442049749

Epoch: 6| Step: 10
Training loss: 1.9204593810235553
Validation loss: 2.5556304567179002

Epoch: 6| Step: 11
Training loss: 1.6559131207734918
Validation loss: 2.6063757746192175

Epoch: 6| Step: 12
Training loss: 2.143589612115831
Validation loss: 2.448348014981473

Epoch: 6| Step: 13
Training loss: 2.481943151863481
Validation loss: 2.569105932154677

Epoch: 464| Step: 0
Training loss: 1.349425108678464
Validation loss: 2.509884665885173

Epoch: 6| Step: 1
Training loss: 2.081353225668339
Validation loss: 2.6603476201773746

Epoch: 6| Step: 2
Training loss: 1.6514315059685762
Validation loss: 2.514080768264081

Epoch: 6| Step: 3
Training loss: 2.2696588844744445
Validation loss: 2.5943541610784058

Epoch: 6| Step: 4
Training loss: 1.8517204893286041
Validation loss: 2.6303296282438704

Epoch: 6| Step: 5
Training loss: 2.0282700026861282
Validation loss: 2.625824668365603

Epoch: 6| Step: 6
Training loss: 1.5727187362665744
Validation loss: 2.602530164495055

Epoch: 6| Step: 7
Training loss: 2.5135587179209242
Validation loss: 2.619948361155695

Epoch: 6| Step: 8
Training loss: 2.3266736313388643
Validation loss: 2.5354549008880936

Epoch: 6| Step: 9
Training loss: 2.067369319563609
Validation loss: 2.511766384303779

Epoch: 6| Step: 10
Training loss: 1.7377782886953705
Validation loss: 2.5777165601162944

Epoch: 6| Step: 11
Training loss: 2.327054180712848
Validation loss: 2.577089810733608

Epoch: 6| Step: 12
Training loss: 1.5798913116735784
Validation loss: 2.4842630274568043

Epoch: 6| Step: 13
Training loss: 1.8096835517346184
Validation loss: 2.5201439975596434

Epoch: 465| Step: 0
Training loss: 1.7681943714911335
Validation loss: 2.5285010096704585

Epoch: 6| Step: 1
Training loss: 2.2092671369367336
Validation loss: 2.6040243143531447

Epoch: 6| Step: 2
Training loss: 2.2245039140388623
Validation loss: 2.47577458927957

Epoch: 6| Step: 3
Training loss: 2.051387907851712
Validation loss: 2.577342718473485

Epoch: 6| Step: 4
Training loss: 2.118633831969282
Validation loss: 2.651407865205716

Epoch: 6| Step: 5
Training loss: 1.9089380291831044
Validation loss: 2.476543892913147

Epoch: 6| Step: 6
Training loss: 1.6065969099965078
Validation loss: 2.568889379166899

Epoch: 6| Step: 7
Training loss: 2.615658168058305
Validation loss: 2.662818896295356

Epoch: 6| Step: 8
Training loss: 2.0590135410524986
Validation loss: 2.4986015551371414

Epoch: 6| Step: 9
Training loss: 1.8504348733486302
Validation loss: 2.5445193503120707

Epoch: 6| Step: 10
Training loss: 1.4343810037724127
Validation loss: 2.5531742776954625

Epoch: 6| Step: 11
Training loss: 2.96574265595361
Validation loss: 2.6019593036946613

Epoch: 6| Step: 12
Training loss: 1.848090800180795
Validation loss: 2.479420571799706

Epoch: 6| Step: 13
Training loss: 1.848847406489489
Validation loss: 2.5911637899479794

Epoch: 466| Step: 0
Training loss: 1.3741790748407663
Validation loss: 2.54246434713225

Epoch: 6| Step: 1
Training loss: 2.294647382187848
Validation loss: 2.4680712384531973

Epoch: 6| Step: 2
Training loss: 2.2123022820873963
Validation loss: 2.5152216884634147

Epoch: 6| Step: 3
Training loss: 1.660269197099973
Validation loss: 2.553294499696705

Epoch: 6| Step: 4
Training loss: 1.8445211834372306
Validation loss: 2.5012704533435532

Epoch: 6| Step: 5
Training loss: 2.1199436617508973
Validation loss: 2.54673430401901

Epoch: 6| Step: 6
Training loss: 2.013523040806376
Validation loss: 2.590443417628704

Epoch: 6| Step: 7
Training loss: 1.8599856359686011
Validation loss: 2.5435900999495233

Epoch: 6| Step: 8
Training loss: 1.9537968204914065
Validation loss: 2.5674317186446265

Epoch: 6| Step: 9
Training loss: 2.604066485703253
Validation loss: 2.525501423744215

Epoch: 6| Step: 10
Training loss: 2.1628683493130043
Validation loss: 2.5561483957149074

Epoch: 6| Step: 11
Training loss: 1.6797068040315148
Validation loss: 2.493825837828826

Epoch: 6| Step: 12
Training loss: 2.2435547385087484
Validation loss: 2.632202016314713

Epoch: 6| Step: 13
Training loss: 2.065314828551312
Validation loss: 2.582044473108186

Epoch: 467| Step: 0
Training loss: 2.2488501047581306
Validation loss: 2.5521568892131103

Epoch: 6| Step: 1
Training loss: 2.276743579121997
Validation loss: 2.464238720128599

Epoch: 6| Step: 2
Training loss: 2.0844142652756594
Validation loss: 2.555106494035068

Epoch: 6| Step: 3
Training loss: 1.9002580116162304
Validation loss: 2.6000041675297583

Epoch: 6| Step: 4
Training loss: 1.777314976050567
Validation loss: 2.5546765196291648

Epoch: 6| Step: 5
Training loss: 1.5092094946685193
Validation loss: 2.5738778021498026

Epoch: 6| Step: 6
Training loss: 1.5897869128065885
Validation loss: 2.506611285865519

Epoch: 6| Step: 7
Training loss: 2.3654829378192033
Validation loss: 2.5722720872505698

Epoch: 6| Step: 8
Training loss: 2.0826889058650315
Validation loss: 2.579964554671898

Epoch: 6| Step: 9
Training loss: 2.0817308620738166
Validation loss: 2.4999001965033685

Epoch: 6| Step: 10
Training loss: 1.7411751307530092
Validation loss: 2.489607637643483

Epoch: 6| Step: 11
Training loss: 1.5096497879892867
Validation loss: 2.5958063519017

Epoch: 6| Step: 12
Training loss: 1.9141325023072882
Validation loss: 2.4904965732721838

Epoch: 6| Step: 13
Training loss: 1.5590590927199954
Validation loss: 2.417390265954947

Epoch: 468| Step: 0
Training loss: 2.6271639487602925
Validation loss: 2.5409637698358973

Epoch: 6| Step: 1
Training loss: 1.3512262356033184
Validation loss: 2.5657683947561702

Epoch: 6| Step: 2
Training loss: 2.1956391549678935
Validation loss: 2.641726658255944

Epoch: 6| Step: 3
Training loss: 1.7175924391211872
Validation loss: 2.5469638505228285

Epoch: 6| Step: 4
Training loss: 2.1361508355693113
Validation loss: 2.537621109898765

Epoch: 6| Step: 5
Training loss: 1.683836103020519
Validation loss: 2.547855299512971

Epoch: 6| Step: 6
Training loss: 1.5646705809680903
Validation loss: 2.5170467901171705

Epoch: 6| Step: 7
Training loss: 2.2715185922159464
Validation loss: 2.420721115149798

Epoch: 6| Step: 8
Training loss: 2.0414331912494017
Validation loss: 2.580884820727024

Epoch: 6| Step: 9
Training loss: 1.6504634321958258
Validation loss: 2.5857834754773315

Epoch: 6| Step: 10
Training loss: 2.1672478654371075
Validation loss: 2.6219774415038435

Epoch: 6| Step: 11
Training loss: 1.7195918709010205
Validation loss: 2.461225279717634

Epoch: 6| Step: 12
Training loss: 2.163316288172143
Validation loss: 2.575964699316747

Epoch: 6| Step: 13
Training loss: 1.8025982806412664
Validation loss: 2.547237726489117

Epoch: 469| Step: 0
Training loss: 2.4685635073757997
Validation loss: 2.505741246816598

Epoch: 6| Step: 1
Training loss: 1.4292928849399418
Validation loss: 2.5643860333853024

Epoch: 6| Step: 2
Training loss: 1.9680775296206336
Validation loss: 2.612018222292127

Epoch: 6| Step: 3
Training loss: 1.9502832109244341
Validation loss: 2.6590364456829994

Epoch: 6| Step: 4
Training loss: 1.7460082713801865
Validation loss: 2.547377798885894

Epoch: 6| Step: 5
Training loss: 1.78139642481708
Validation loss: 2.562002528894368

Epoch: 6| Step: 6
Training loss: 1.7542800335106483
Validation loss: 2.5224348076435796

Epoch: 6| Step: 7
Training loss: 1.9449588193677148
Validation loss: 2.5488664340604563

Epoch: 6| Step: 8
Training loss: 2.2554664963280544
Validation loss: 2.6080676335598425

Epoch: 6| Step: 9
Training loss: 1.8433639639481845
Validation loss: 2.556123151815324

Epoch: 6| Step: 10
Training loss: 1.4675260273121642
Validation loss: 2.554469658967096

Epoch: 6| Step: 11
Training loss: 1.7668903509120186
Validation loss: 2.641200783944833

Epoch: 6| Step: 12
Training loss: 2.4806309924794556
Validation loss: 2.5247421780377723

Epoch: 6| Step: 13
Training loss: 2.3213968023285214
Validation loss: 2.6271871917277547

Epoch: 470| Step: 0
Training loss: 2.082747974812823
Validation loss: 2.566357258383253

Epoch: 6| Step: 1
Training loss: 1.6599093623867271
Validation loss: 2.5313590656839016

Epoch: 6| Step: 2
Training loss: 2.2653845297693955
Validation loss: 2.518014477071155

Epoch: 6| Step: 3
Training loss: 1.4628598218865643
Validation loss: 2.619793491040371

Epoch: 6| Step: 4
Training loss: 2.3027904914573507
Validation loss: 2.5297498431615777

Epoch: 6| Step: 5
Training loss: 1.9353973916048317
Validation loss: 2.539912401293521

Epoch: 6| Step: 6
Training loss: 1.9541709235605211
Validation loss: 2.541506566721471

Epoch: 6| Step: 7
Training loss: 2.405616577799705
Validation loss: 2.6136424112758654

Epoch: 6| Step: 8
Training loss: 2.283051497985986
Validation loss: 2.5765066517312594

Epoch: 6| Step: 9
Training loss: 1.2139822306173091
Validation loss: 2.568767223854805

Epoch: 6| Step: 10
Training loss: 2.196357885412901
Validation loss: 2.5498081542074487

Epoch: 6| Step: 11
Training loss: 1.7457798754656706
Validation loss: 2.515500806920998

Epoch: 6| Step: 12
Training loss: 1.8187785090673263
Validation loss: 2.5717787477933394

Epoch: 6| Step: 13
Training loss: 1.9727195200829697
Validation loss: 2.5300392851851186

Epoch: 471| Step: 0
Training loss: 1.7867880944129713
Validation loss: 2.6334174917933906

Epoch: 6| Step: 1
Training loss: 2.3089843006550277
Validation loss: 2.5466933254518906

Epoch: 6| Step: 2
Training loss: 2.248428219583219
Validation loss: 2.667287660658914

Epoch: 6| Step: 3
Training loss: 2.3173189214683347
Validation loss: 2.5884547259937625

Epoch: 6| Step: 4
Training loss: 2.0946050008433823
Validation loss: 2.576078780362254

Epoch: 6| Step: 5
Training loss: 2.09545396388427
Validation loss: 2.5595655168814533

Epoch: 6| Step: 6
Training loss: 1.7650845130808528
Validation loss: 2.558693293031827

Epoch: 6| Step: 7
Training loss: 1.9365267616508912
Validation loss: 2.572688590104819

Epoch: 6| Step: 8
Training loss: 2.8945220246985244
Validation loss: 2.577838493727893

Epoch: 6| Step: 9
Training loss: 1.5519415600775681
Validation loss: 2.4932484129757326

Epoch: 6| Step: 10
Training loss: 1.3015773044215915
Validation loss: 2.455168152828408

Epoch: 6| Step: 11
Training loss: 2.083177891336485
Validation loss: 2.5242385144071418

Epoch: 6| Step: 12
Training loss: 1.9668651822756975
Validation loss: 2.4428157179763144

Epoch: 6| Step: 13
Training loss: 1.033803033725319
Validation loss: 2.5960177172112133

Epoch: 472| Step: 0
Training loss: 1.8551895092097161
Validation loss: 2.529234455032244

Epoch: 6| Step: 1
Training loss: 1.8466424398634826
Validation loss: 2.529510401612639

Epoch: 6| Step: 2
Training loss: 1.7659578262857725
Validation loss: 2.5351467069502522

Epoch: 6| Step: 3
Training loss: 2.135916550595645
Validation loss: 2.518796254481944

Epoch: 6| Step: 4
Training loss: 2.0886213203391826
Validation loss: 2.5202634016782395

Epoch: 6| Step: 5
Training loss: 2.1776752549430345
Validation loss: 2.591518175779994

Epoch: 6| Step: 6
Training loss: 2.232093660084934
Validation loss: 2.6296151721170546

Epoch: 6| Step: 7
Training loss: 2.272024233191833
Validation loss: 2.5181905618770615

Epoch: 6| Step: 8
Training loss: 2.564709989724059
Validation loss: 2.4993472559738676

Epoch: 6| Step: 9
Training loss: 1.71697156969904
Validation loss: 2.593885290474931

Epoch: 6| Step: 10
Training loss: 1.5573793044250852
Validation loss: 2.470837320359369

Epoch: 6| Step: 11
Training loss: 1.7419414260949766
Validation loss: 2.4876448404587665

Epoch: 6| Step: 12
Training loss: 1.8556915470678004
Validation loss: 2.579436068322937

Epoch: 6| Step: 13
Training loss: 2.1888278745591263
Validation loss: 2.5478673255336672

Epoch: 473| Step: 0
Training loss: 1.6563273717694018
Validation loss: 2.667919198052291

Epoch: 6| Step: 1
Training loss: 2.5727025199040034
Validation loss: 2.588178478971123

Epoch: 6| Step: 2
Training loss: 2.0437075735932244
Validation loss: 2.541592033200933

Epoch: 6| Step: 3
Training loss: 2.371543175526482
Validation loss: 2.5360545808823427

Epoch: 6| Step: 4
Training loss: 1.668118543844639
Validation loss: 2.592280474061576

Epoch: 6| Step: 5
Training loss: 1.6949408339130008
Validation loss: 2.4977949313453363

Epoch: 6| Step: 6
Training loss: 2.2606134167902567
Validation loss: 2.602826734478386

Epoch: 6| Step: 7
Training loss: 2.105890518436528
Validation loss: 2.6217058679001566

Epoch: 6| Step: 8
Training loss: 1.8698676757097832
Validation loss: 2.6087106152784236

Epoch: 6| Step: 9
Training loss: 2.3605682185229337
Validation loss: 2.617595188183873

Epoch: 6| Step: 10
Training loss: 2.11369142059781
Validation loss: 2.469034742656096

Epoch: 6| Step: 11
Training loss: 1.320714720004073
Validation loss: 2.484716932464225

Epoch: 6| Step: 12
Training loss: 1.593597853635009
Validation loss: 2.556584793945584

Epoch: 6| Step: 13
Training loss: 1.5299208964674063
Validation loss: 2.594257768095911

Epoch: 474| Step: 0
Training loss: 1.891789479687241
Validation loss: 2.6470664018044894

Epoch: 6| Step: 1
Training loss: 1.981953262039788
Validation loss: 2.661165081158554

Epoch: 6| Step: 2
Training loss: 1.6253316980895613
Validation loss: 2.579977107710001

Epoch: 6| Step: 3
Training loss: 2.104035351372847
Validation loss: 2.5904152113690917

Epoch: 6| Step: 4
Training loss: 2.2464304265333666
Validation loss: 2.591035210151618

Epoch: 6| Step: 5
Training loss: 1.505046303375805
Validation loss: 2.6142338799192903

Epoch: 6| Step: 6
Training loss: 2.2275279311153264
Validation loss: 2.6668303199767647

Epoch: 6| Step: 7
Training loss: 1.6701597167064837
Validation loss: 2.5531284331197983

Epoch: 6| Step: 8
Training loss: 1.9750258914843855
Validation loss: 2.515336069196883

Epoch: 6| Step: 9
Training loss: 1.8504723023323584
Validation loss: 2.6191766018876597

Epoch: 6| Step: 10
Training loss: 2.8985520003495657
Validation loss: 2.6167493913578483

Epoch: 6| Step: 11
Training loss: 1.6759873199028743
Validation loss: 2.548618817091197

Epoch: 6| Step: 12
Training loss: 1.9620281697077662
Validation loss: 2.520256999341625

Epoch: 6| Step: 13
Training loss: 2.1523294604150767
Validation loss: 2.548607647618617

Epoch: 475| Step: 0
Training loss: 1.6098883837755125
Validation loss: 2.562517108554988

Epoch: 6| Step: 1
Training loss: 2.526735589321187
Validation loss: 2.577069107760367

Epoch: 6| Step: 2
Training loss: 1.9985068230912144
Validation loss: 2.5135025398403466

Epoch: 6| Step: 3
Training loss: 2.701891755602078
Validation loss: 2.6224723899488467

Epoch: 6| Step: 4
Training loss: 1.708643381159302
Validation loss: 2.510829846772569

Epoch: 6| Step: 5
Training loss: 1.4984396129987057
Validation loss: 2.5531811668118163

Epoch: 6| Step: 6
Training loss: 1.8268398756317206
Validation loss: 2.5316321822414514

Epoch: 6| Step: 7
Training loss: 1.6433249645651977
Validation loss: 2.503235134763984

Epoch: 6| Step: 8
Training loss: 1.8109608396090888
Validation loss: 2.6238913844160408

Epoch: 6| Step: 9
Training loss: 1.2628456020382708
Validation loss: 2.5973530367477786

Epoch: 6| Step: 10
Training loss: 2.0670866395964502
Validation loss: 2.511534573217941

Epoch: 6| Step: 11
Training loss: 2.129819005878841
Validation loss: 2.5486926974332875

Epoch: 6| Step: 12
Training loss: 1.8034037858782608
Validation loss: 2.5189233698917106

Epoch: 6| Step: 13
Training loss: 2.2973593895257953
Validation loss: 2.5014330827561593

Epoch: 476| Step: 0
Training loss: 2.301980915351723
Validation loss: 2.586264093699131

Epoch: 6| Step: 1
Training loss: 2.031062190836823
Validation loss: 2.5184999502690397

Epoch: 6| Step: 2
Training loss: 1.8266706632073855
Validation loss: 2.551800210670691

Epoch: 6| Step: 3
Training loss: 1.669429809173284
Validation loss: 2.5549996140126177

Epoch: 6| Step: 4
Training loss: 1.8845541721775216
Validation loss: 2.5960691856818996

Epoch: 6| Step: 5
Training loss: 2.5683469358657898
Validation loss: 2.60704952093226

Epoch: 6| Step: 6
Training loss: 1.1170981311398978
Validation loss: 2.5395323565517662

Epoch: 6| Step: 7
Training loss: 1.857962705092108
Validation loss: 2.5504687212860686

Epoch: 6| Step: 8
Training loss: 2.5020158269977757
Validation loss: 2.5575683101935076

Epoch: 6| Step: 9
Training loss: 1.9709764636960345
Validation loss: 2.5121144312701533

Epoch: 6| Step: 10
Training loss: 0.9979834489768669
Validation loss: 2.5932832968393846

Epoch: 6| Step: 11
Training loss: 1.7299900469190466
Validation loss: 2.5381653528927517

Epoch: 6| Step: 12
Training loss: 2.0088386733512866
Validation loss: 2.521474586012134

Epoch: 6| Step: 13
Training loss: 1.7803620919539926
Validation loss: 2.550964560945689

Epoch: 477| Step: 0
Training loss: 2.624393574739093
Validation loss: 2.5162142119176316

Epoch: 6| Step: 1
Training loss: 1.8602935061069061
Validation loss: 2.5376352165344542

Epoch: 6| Step: 2
Training loss: 1.974581785226239
Validation loss: 2.694417781745135

Epoch: 6| Step: 3
Training loss: 2.0643836003400695
Validation loss: 2.4901604543190663

Epoch: 6| Step: 4
Training loss: 1.573825077026476
Validation loss: 2.520126545393785

Epoch: 6| Step: 5
Training loss: 1.8928811979179128
Validation loss: 2.6417525058333475

Epoch: 6| Step: 6
Training loss: 1.7469729401185554
Validation loss: 2.477018426735615

Epoch: 6| Step: 7
Training loss: 1.9223358098073615
Validation loss: 2.479678433021994

Epoch: 6| Step: 8
Training loss: 2.3108356775803154
Validation loss: 2.489292123796464

Epoch: 6| Step: 9
Training loss: 2.0317940790260782
Validation loss: 2.6836038685324413

Epoch: 6| Step: 10
Training loss: 1.6740677616392032
Validation loss: 2.546092122620857

Epoch: 6| Step: 11
Training loss: 1.625920768444951
Validation loss: 2.5270113248605357

Epoch: 6| Step: 12
Training loss: 1.4067958196374533
Validation loss: 2.522590289006859

Epoch: 6| Step: 13
Training loss: 1.945911606297343
Validation loss: 2.6067934682610643

Epoch: 478| Step: 0
Training loss: 1.792322910983489
Validation loss: 2.5632043806315785

Epoch: 6| Step: 1
Training loss: 2.421896559096331
Validation loss: 2.5718262106860785

Epoch: 6| Step: 2
Training loss: 2.216689751679336
Validation loss: 2.5857710185409104

Epoch: 6| Step: 3
Training loss: 1.9194823467280533
Validation loss: 2.549240492461076

Epoch: 6| Step: 4
Training loss: 1.8406467507701214
Validation loss: 2.4503595678059717

Epoch: 6| Step: 5
Training loss: 2.479278134530165
Validation loss: 2.5579928846972178

Epoch: 6| Step: 6
Training loss: 1.6877783086654659
Validation loss: 2.470676691595723

Epoch: 6| Step: 7
Training loss: 1.7166106347627628
Validation loss: 2.612624963879542

Epoch: 6| Step: 8
Training loss: 2.471432930133734
Validation loss: 2.4567747234708377

Epoch: 6| Step: 9
Training loss: 1.8405686426521042
Validation loss: 2.5569100144128867

Epoch: 6| Step: 10
Training loss: 1.7282109051231769
Validation loss: 2.4760057651630847

Epoch: 6| Step: 11
Training loss: 1.9370373819630622
Validation loss: 2.652679272804463

Epoch: 6| Step: 12
Training loss: 1.7637531181540391
Validation loss: 2.5215349354119816

Epoch: 6| Step: 13
Training loss: 1.468434888435959
Validation loss: 2.5474324228190173

Epoch: 479| Step: 0
Training loss: 2.4823654012311507
Validation loss: 2.665323509140564

Epoch: 6| Step: 1
Training loss: 1.6904480226294785
Validation loss: 2.537585619444749

Epoch: 6| Step: 2
Training loss: 2.427830320566123
Validation loss: 2.581076337347578

Epoch: 6| Step: 3
Training loss: 2.1255835685516984
Validation loss: 2.4956671442840244

Epoch: 6| Step: 4
Training loss: 1.4053091504593813
Validation loss: 2.544911724867373

Epoch: 6| Step: 5
Training loss: 1.9776116402576662
Validation loss: 2.575435266763757

Epoch: 6| Step: 6
Training loss: 1.956470888969725
Validation loss: 2.5790842389173623

Epoch: 6| Step: 7
Training loss: 1.9185575059390247
Validation loss: 2.590490833459199

Epoch: 6| Step: 8
Training loss: 1.6433124148344476
Validation loss: 2.58016422947143

Epoch: 6| Step: 9
Training loss: 1.772927635269512
Validation loss: 2.629605436638249

Epoch: 6| Step: 10
Training loss: 1.4685629867641872
Validation loss: 2.5664813998281075

Epoch: 6| Step: 11
Training loss: 1.8285736446388474
Validation loss: 2.6351954422294717

Epoch: 6| Step: 12
Training loss: 2.0288477851396625
Validation loss: 2.6582068264650296

Epoch: 6| Step: 13
Training loss: 0.6916956969185918
Validation loss: 2.6200903574215104

Epoch: 480| Step: 0
Training loss: 1.945118599538849
Validation loss: 2.552201055674914

Epoch: 6| Step: 1
Training loss: 2.1195714837771593
Validation loss: 2.6075618310439816

Epoch: 6| Step: 2
Training loss: 1.188716967551958
Validation loss: 2.507001949591535

Epoch: 6| Step: 3
Training loss: 1.3296590584605574
Validation loss: 2.544320185072854

Epoch: 6| Step: 4
Training loss: 2.102596326474312
Validation loss: 2.5463959392898645

Epoch: 6| Step: 5
Training loss: 1.8795874742639764
Validation loss: 2.514067763321749

Epoch: 6| Step: 6
Training loss: 2.726085806987169
Validation loss: 2.549134931343827

Epoch: 6| Step: 7
Training loss: 1.6548824062232108
Validation loss: 2.5697976013139274

Epoch: 6| Step: 8
Training loss: 1.7036288154923749
Validation loss: 2.582546663799719

Epoch: 6| Step: 9
Training loss: 2.031072051249823
Validation loss: 2.599720354024872

Epoch: 6| Step: 10
Training loss: 1.9454005577655258
Validation loss: 2.5026423016536605

Epoch: 6| Step: 11
Training loss: 2.3082064386002825
Validation loss: 2.584324433912703

Epoch: 6| Step: 12
Training loss: 2.310839907717876
Validation loss: 2.485840864218754

Epoch: 6| Step: 13
Training loss: 2.020005308843001
Validation loss: 2.482235012184476

Epoch: 481| Step: 0
Training loss: 1.666080308130328
Validation loss: 2.575997806946283

Epoch: 6| Step: 1
Training loss: 1.9002310361434096
Validation loss: 2.5511426422944328

Epoch: 6| Step: 2
Training loss: 2.1186310186145882
Validation loss: 2.6038495434693805

Epoch: 6| Step: 3
Training loss: 2.253053288899228
Validation loss: 2.501275104496079

Epoch: 6| Step: 4
Training loss: 1.6694430908575653
Validation loss: 2.557373451238556

Epoch: 6| Step: 5
Training loss: 1.9054446160609047
Validation loss: 2.550841386945432

Epoch: 6| Step: 6
Training loss: 2.5265715892017244
Validation loss: 2.6733200156266506

Epoch: 6| Step: 7
Training loss: 2.31146784249393
Validation loss: 2.583053074168457

Epoch: 6| Step: 8
Training loss: 2.102350363832615
Validation loss: 2.5395363188094704

Epoch: 6| Step: 9
Training loss: 1.971387096081291
Validation loss: 2.6114351214752514

Epoch: 6| Step: 10
Training loss: 1.5794481075320572
Validation loss: 2.559213756596685

Epoch: 6| Step: 11
Training loss: 1.2388884683122667
Validation loss: 2.5500999218776608

Epoch: 6| Step: 12
Training loss: 1.5537474584213424
Validation loss: 2.5961566488323724

Epoch: 6| Step: 13
Training loss: 1.5904092368809437
Validation loss: 2.5799810863535164

Epoch: 482| Step: 0
Training loss: 1.8498060047401537
Validation loss: 2.4963482211853196

Epoch: 6| Step: 1
Training loss: 2.1820607818123863
Validation loss: 2.5565538546053452

Epoch: 6| Step: 2
Training loss: 1.7389041084758299
Validation loss: 2.538900622941529

Epoch: 6| Step: 3
Training loss: 1.7918152267018563
Validation loss: 2.5588771642747434

Epoch: 6| Step: 4
Training loss: 1.4923300150775523
Validation loss: 2.5220350623034786

Epoch: 6| Step: 5
Training loss: 2.1150123148530318
Validation loss: 2.581678224170696

Epoch: 6| Step: 6
Training loss: 1.8623966060332215
Validation loss: 2.5381225118165744

Epoch: 6| Step: 7
Training loss: 1.5307787734546352
Validation loss: 2.6279243054610752

Epoch: 6| Step: 8
Training loss: 1.5647802118132592
Validation loss: 2.656462101246598

Epoch: 6| Step: 9
Training loss: 1.514528644873975
Validation loss: 2.5703979681448015

Epoch: 6| Step: 10
Training loss: 2.1536661782893196
Validation loss: 2.521252994764053

Epoch: 6| Step: 11
Training loss: 2.3843966861803576
Validation loss: 2.5212200157720472

Epoch: 6| Step: 12
Training loss: 2.077788591045092
Validation loss: 2.5812472403144895

Epoch: 6| Step: 13
Training loss: 1.800029804724727
Validation loss: 2.5200853091363418

Epoch: 483| Step: 0
Training loss: 1.771880621791849
Validation loss: 2.58925974463244

Epoch: 6| Step: 1
Training loss: 2.040808386981857
Validation loss: 2.5805062819996927

Epoch: 6| Step: 2
Training loss: 1.6101553793381471
Validation loss: 2.574184902438635

Epoch: 6| Step: 3
Training loss: 2.9843698871029503
Validation loss: 2.4967854290736686

Epoch: 6| Step: 4
Training loss: 1.8996945838400807
Validation loss: 2.5648029522617186

Epoch: 6| Step: 5
Training loss: 2.0483445577828654
Validation loss: 2.519675033878792

Epoch: 6| Step: 6
Training loss: 1.775813859068722
Validation loss: 2.4929787894992335

Epoch: 6| Step: 7
Training loss: 1.8973537538483518
Validation loss: 2.520068784332651

Epoch: 6| Step: 8
Training loss: 1.633867643829916
Validation loss: 2.639667800349675

Epoch: 6| Step: 9
Training loss: 1.3836970975113874
Validation loss: 2.573875786199133

Epoch: 6| Step: 10
Training loss: 1.9540146899417876
Validation loss: 2.6032991164420443

Epoch: 6| Step: 11
Training loss: 2.151505045514991
Validation loss: 2.541922237861859

Epoch: 6| Step: 12
Training loss: 2.0458266507393748
Validation loss: 2.5452194636104077

Epoch: 6| Step: 13
Training loss: 1.8247411988580897
Validation loss: 2.568023719846788

Epoch: 484| Step: 0
Training loss: 1.4383651783505829
Validation loss: 2.5882368268315608

Epoch: 6| Step: 1
Training loss: 1.962927063561036
Validation loss: 2.5685117490060154

Epoch: 6| Step: 2
Training loss: 2.0209625307712287
Validation loss: 2.5757363777484916

Epoch: 6| Step: 3
Training loss: 2.1191329744965586
Validation loss: 2.5619106950698756

Epoch: 6| Step: 4
Training loss: 1.8627909849063813
Validation loss: 2.643043926122476

Epoch: 6| Step: 5
Training loss: 1.8485580082593844
Validation loss: 2.5250590564924975

Epoch: 6| Step: 6
Training loss: 1.6872999284608485
Validation loss: 2.6045392304402557

Epoch: 6| Step: 7
Training loss: 2.105777526748014
Validation loss: 2.4974714381910275

Epoch: 6| Step: 8
Training loss: 2.0508759976252824
Validation loss: 2.517594235415132

Epoch: 6| Step: 9
Training loss: 2.54810682592023
Validation loss: 2.5207910818086163

Epoch: 6| Step: 10
Training loss: 1.12840751005944
Validation loss: 2.5709215326523753

Epoch: 6| Step: 11
Training loss: 1.7576569212834998
Validation loss: 2.5532039827978625

Epoch: 6| Step: 12
Training loss: 1.9551811686522038
Validation loss: 2.4989255472839034

Epoch: 6| Step: 13
Training loss: 1.7960264773254397
Validation loss: 2.556142131399793

Epoch: 485| Step: 0
Training loss: 1.9926328871769337
Validation loss: 2.509370599080142

Epoch: 6| Step: 1
Training loss: 1.9929138056390052
Validation loss: 2.600262619532681

Epoch: 6| Step: 2
Training loss: 2.0944829768046604
Validation loss: 2.5681653368112194

Epoch: 6| Step: 3
Training loss: 1.8240762855070292
Validation loss: 2.5231106657356004

Epoch: 6| Step: 4
Training loss: 2.029007245746006
Validation loss: 2.518323233543262

Epoch: 6| Step: 5
Training loss: 1.7646827546642414
Validation loss: 2.49811794440932

Epoch: 6| Step: 6
Training loss: 2.035606759083029
Validation loss: 2.6126522533062078

Epoch: 6| Step: 7
Training loss: 2.6991913679530986
Validation loss: 2.6462769882883848

Epoch: 6| Step: 8
Training loss: 1.080063997421167
Validation loss: 2.513796438889429

Epoch: 6| Step: 9
Training loss: 1.6018121292213257
Validation loss: 2.541614881606929

Epoch: 6| Step: 10
Training loss: 1.976052380500777
Validation loss: 2.5292720052117486

Epoch: 6| Step: 11
Training loss: 1.594936527555803
Validation loss: 2.589783324896258

Epoch: 6| Step: 12
Training loss: 2.573792765309784
Validation loss: 2.470594903450852

Epoch: 6| Step: 13
Training loss: 2.3320594670874555
Validation loss: 2.4889536699048778

Epoch: 486| Step: 0
Training loss: 2.476237086147351
Validation loss: 2.5381443834302884

Epoch: 6| Step: 1
Training loss: 2.08062868667418
Validation loss: 2.5086547246928466

Epoch: 6| Step: 2
Training loss: 1.8488694577056983
Validation loss: 2.494555259154767

Epoch: 6| Step: 3
Training loss: 1.5013775857520917
Validation loss: 2.4851023766936127

Epoch: 6| Step: 4
Training loss: 1.82334483613193
Validation loss: 2.5602207146469547

Epoch: 6| Step: 5
Training loss: 2.0227140215789383
Validation loss: 2.607080157986786

Epoch: 6| Step: 6
Training loss: 1.5560102347010398
Validation loss: 2.5070831666387585

Epoch: 6| Step: 7
Training loss: 1.8605578851303979
Validation loss: 2.4757595000685635

Epoch: 6| Step: 8
Training loss: 1.4921042533941207
Validation loss: 2.4962170764426888

Epoch: 6| Step: 9
Training loss: 1.4878606727651884
Validation loss: 2.5666121975547758

Epoch: 6| Step: 10
Training loss: 1.8541148817853192
Validation loss: 2.5356294742768912

Epoch: 6| Step: 11
Training loss: 1.8672668567856265
Validation loss: 2.618165896494018

Epoch: 6| Step: 12
Training loss: 2.478267143184831
Validation loss: 2.515809649742353

Epoch: 6| Step: 13
Training loss: 2.275506405483778
Validation loss: 2.5810509985552557

Epoch: 487| Step: 0
Training loss: 1.1184669584118347
Validation loss: 2.569968300670945

Epoch: 6| Step: 1
Training loss: 2.2760073894186355
Validation loss: 2.581272560296547

Epoch: 6| Step: 2
Training loss: 1.9223535453660308
Validation loss: 2.5418147338660786

Epoch: 6| Step: 3
Training loss: 2.0917060326548467
Validation loss: 2.488947695339929

Epoch: 6| Step: 4
Training loss: 2.225334605227854
Validation loss: 2.5639653341879303

Epoch: 6| Step: 5
Training loss: 2.3954476972175747
Validation loss: 2.583791256217969

Epoch: 6| Step: 6
Training loss: 1.5820487315777962
Validation loss: 2.5536923875838693

Epoch: 6| Step: 7
Training loss: 1.5553805086252457
Validation loss: 2.5509317665822415

Epoch: 6| Step: 8
Training loss: 1.7433590905430532
Validation loss: 2.6510293353754317

Epoch: 6| Step: 9
Training loss: 2.573167230140474
Validation loss: 2.5992433241825794

Epoch: 6| Step: 10
Training loss: 1.7104331888879178
Validation loss: 2.603403272080736

Epoch: 6| Step: 11
Training loss: 1.6931499980941271
Validation loss: 2.545313532823718

Epoch: 6| Step: 12
Training loss: 1.8327383535335362
Validation loss: 2.5177869984489067

Epoch: 6| Step: 13
Training loss: 2.1338019119678897
Validation loss: 2.617926890691614

Epoch: 488| Step: 0
Training loss: 2.068451012156479
Validation loss: 2.4775668289027046

Epoch: 6| Step: 1
Training loss: 2.561862307961697
Validation loss: 2.5797039667152792

Epoch: 6| Step: 2
Training loss: 1.535541204666696
Validation loss: 2.516556081588053

Epoch: 6| Step: 3
Training loss: 1.5235666073597727
Validation loss: 2.5219665992965146

Epoch: 6| Step: 4
Training loss: 1.666139551095029
Validation loss: 2.662329022971638

Epoch: 6| Step: 5
Training loss: 1.698233483211592
Validation loss: 2.5471986944538094

Epoch: 6| Step: 6
Training loss: 2.260543597007894
Validation loss: 2.61275760797349

Epoch: 6| Step: 7
Training loss: 1.8727630622967368
Validation loss: 2.4915893147451476

Epoch: 6| Step: 8
Training loss: 1.5961375584801019
Validation loss: 2.5770565321014254

Epoch: 6| Step: 9
Training loss: 2.300536889148383
Validation loss: 2.51673088308267

Epoch: 6| Step: 10
Training loss: 2.301873406091947
Validation loss: 2.5989917155629114

Epoch: 6| Step: 11
Training loss: 1.6769590706923116
Validation loss: 2.52686572438555

Epoch: 6| Step: 12
Training loss: 1.7312890168899189
Validation loss: 2.549476464069515

Epoch: 6| Step: 13
Training loss: 1.1988883790466933
Validation loss: 2.573652909330792

Epoch: 489| Step: 0
Training loss: 1.7498743829601417
Validation loss: 2.5200782176446572

Epoch: 6| Step: 1
Training loss: 1.8050104818277528
Validation loss: 2.6070768883863358

Epoch: 6| Step: 2
Training loss: 2.1766931893026276
Validation loss: 2.598668486325199

Epoch: 6| Step: 3
Training loss: 2.004456561635325
Validation loss: 2.5139739388296767

Epoch: 6| Step: 4
Training loss: 1.7864612842531735
Validation loss: 2.622209788806511

Epoch: 6| Step: 5
Training loss: 1.9858092884182665
Validation loss: 2.554247638112355

Epoch: 6| Step: 6
Training loss: 1.7254115622668411
Validation loss: 2.5735522913189364

Epoch: 6| Step: 7
Training loss: 1.2907408913958345
Validation loss: 2.5783565592510334

Epoch: 6| Step: 8
Training loss: 1.6734907952093405
Validation loss: 2.5262111257265407

Epoch: 6| Step: 9
Training loss: 2.0184649192363953
Validation loss: 2.5193891430024893

Epoch: 6| Step: 10
Training loss: 1.8021030167697232
Validation loss: 2.4293559866144236

Epoch: 6| Step: 11
Training loss: 1.980760962844356
Validation loss: 2.5861802115647228

Epoch: 6| Step: 12
Training loss: 2.6047014424866792
Validation loss: 2.58198701990885

Epoch: 6| Step: 13
Training loss: 1.6697988007461093
Validation loss: 2.565407299026171

Epoch: 490| Step: 0
Training loss: 1.7187706685990927
Validation loss: 2.493100858182617

Epoch: 6| Step: 1
Training loss: 2.237619032437419
Validation loss: 2.561014770950964

Epoch: 6| Step: 2
Training loss: 1.849615433389959
Validation loss: 2.5508309538357925

Epoch: 6| Step: 3
Training loss: 1.6153672151012672
Validation loss: 2.663858696216066

Epoch: 6| Step: 4
Training loss: 2.50630898727293
Validation loss: 2.5089064397119927

Epoch: 6| Step: 5
Training loss: 1.7450052918187215
Validation loss: 2.5307392226366643

Epoch: 6| Step: 6
Training loss: 1.5157270888720944
Validation loss: 2.586865833878889

Epoch: 6| Step: 7
Training loss: 2.6141551200296336
Validation loss: 2.5621391940774902

Epoch: 6| Step: 8
Training loss: 1.7314950211861235
Validation loss: 2.5382136685574888

Epoch: 6| Step: 9
Training loss: 1.8330991190797876
Validation loss: 2.5201871381521097

Epoch: 6| Step: 10
Training loss: 1.96509891620187
Validation loss: 2.5132844411234836

Epoch: 6| Step: 11
Training loss: 1.8809898703554362
Validation loss: 2.54595995047511

Epoch: 6| Step: 12
Training loss: 1.3128460473321564
Validation loss: 2.5338252468225333

Epoch: 6| Step: 13
Training loss: 2.4762206217656515
Validation loss: 2.579583165786994

Epoch: 491| Step: 0
Training loss: 2.072328672609472
Validation loss: 2.6252534600403434

Epoch: 6| Step: 1
Training loss: 1.5628609812508305
Validation loss: 2.5068792201847336

Epoch: 6| Step: 2
Training loss: 1.5318791401004448
Validation loss: 2.5465997984724975

Epoch: 6| Step: 3
Training loss: 1.9937626614063948
Validation loss: 2.491627711604337

Epoch: 6| Step: 4
Training loss: 2.019298901648594
Validation loss: 2.5094111706232893

Epoch: 6| Step: 5
Training loss: 1.6681362666538895
Validation loss: 2.5493802275543205

Epoch: 6| Step: 6
Training loss: 1.226714203801451
Validation loss: 2.5296004721566074

Epoch: 6| Step: 7
Training loss: 1.7686129243931716
Validation loss: 2.488842018206191

Epoch: 6| Step: 8
Training loss: 1.711766986872393
Validation loss: 2.514167383226708

Epoch: 6| Step: 9
Training loss: 1.7359042599686256
Validation loss: 2.541406724757515

Epoch: 6| Step: 10
Training loss: 2.9331237985448775
Validation loss: 2.5969721299527735

Epoch: 6| Step: 11
Training loss: 1.9359189627608893
Validation loss: 2.542135498673517

Epoch: 6| Step: 12
Training loss: 1.8137830599526414
Validation loss: 2.636689095157561

Epoch: 6| Step: 13
Training loss: 1.453104490730183
Validation loss: 2.4893405476873736

Epoch: 492| Step: 0
Training loss: 2.5970778660314027
Validation loss: 2.561644380528705

Epoch: 6| Step: 1
Training loss: 1.6320626759368144
Validation loss: 2.5980880739835284

Epoch: 6| Step: 2
Training loss: 1.9275589914361397
Validation loss: 2.582908783706312

Epoch: 6| Step: 3
Training loss: 1.8573503771317346
Validation loss: 2.489266417145281

Epoch: 6| Step: 4
Training loss: 1.8455130988901294
Validation loss: 2.529118675561437

Epoch: 6| Step: 5
Training loss: 1.8469009629956497
Validation loss: 2.572971751095995

Epoch: 6| Step: 6
Training loss: 1.7904848000595774
Validation loss: 2.480128806722502

Epoch: 6| Step: 7
Training loss: 1.4878358349635747
Validation loss: 2.557023405604167

Epoch: 6| Step: 8
Training loss: 1.7547128432660992
Validation loss: 2.5091758244724907

Epoch: 6| Step: 9
Training loss: 1.1639172764252124
Validation loss: 2.615056149623347

Epoch: 6| Step: 10
Training loss: 2.4148032030436624
Validation loss: 2.571114697774243

Epoch: 6| Step: 11
Training loss: 2.008510245713228
Validation loss: 2.542059350774848

Epoch: 6| Step: 12
Training loss: 1.9034026095358905
Validation loss: 2.489631239099376

Epoch: 6| Step: 13
Training loss: 2.100530661791612
Validation loss: 2.58461219209107

Epoch: 493| Step: 0
Training loss: 1.5639815363855116
Validation loss: 2.5598907872907644

Epoch: 6| Step: 1
Training loss: 1.40876985063758
Validation loss: 2.532332267598909

Epoch: 6| Step: 2
Training loss: 1.278090325890167
Validation loss: 2.5733124424130343

Epoch: 6| Step: 3
Training loss: 1.826161691565858
Validation loss: 2.5361755759949527

Epoch: 6| Step: 4
Training loss: 2.1490324549081468
Validation loss: 2.6144380318681097

Epoch: 6| Step: 5
Training loss: 1.955767316653558
Validation loss: 2.74302395307901

Epoch: 6| Step: 6
Training loss: 1.7453749711238096
Validation loss: 2.5279813399265483

Epoch: 6| Step: 7
Training loss: 1.8680558998394365
Validation loss: 2.620006211382346

Epoch: 6| Step: 8
Training loss: 1.9443551277658262
Validation loss: 2.630194963786527

Epoch: 6| Step: 9
Training loss: 1.7936939111108063
Validation loss: 2.573554949042157

Epoch: 6| Step: 10
Training loss: 2.7371246463768264
Validation loss: 2.582137257350559

Epoch: 6| Step: 11
Training loss: 2.107798460509964
Validation loss: 2.5722232801133886

Epoch: 6| Step: 12
Training loss: 1.9495953213325246
Validation loss: 2.56704563450941

Epoch: 6| Step: 13
Training loss: 1.9489822397102998
Validation loss: 2.533431494202997

Epoch: 494| Step: 0
Training loss: 1.8864127912102253
Validation loss: 2.5148661895816002

Epoch: 6| Step: 1
Training loss: 1.3214765755391926
Validation loss: 2.6443995811685372

Epoch: 6| Step: 2
Training loss: 2.6948146194367215
Validation loss: 2.6310301681099606

Epoch: 6| Step: 3
Training loss: 2.033317804537817
Validation loss: 2.570287766250171

Epoch: 6| Step: 4
Training loss: 1.6814796999892179
Validation loss: 2.5446748776173607

Epoch: 6| Step: 5
Training loss: 2.2656111091977187
Validation loss: 2.5226402149610454

Epoch: 6| Step: 6
Training loss: 0.9954683621953215
Validation loss: 2.574258740678233

Epoch: 6| Step: 7
Training loss: 2.197380856353457
Validation loss: 2.566924504531254

Epoch: 6| Step: 8
Training loss: 1.3426417726641604
Validation loss: 2.530903735696205

Epoch: 6| Step: 9
Training loss: 1.6334220077162387
Validation loss: 2.5637842307287917

Epoch: 6| Step: 10
Training loss: 1.7703214990264229
Validation loss: 2.6144533571585056

Epoch: 6| Step: 11
Training loss: 1.6516277664843906
Validation loss: 2.587733724353259

Epoch: 6| Step: 12
Training loss: 1.8494735071698498
Validation loss: 2.5435581760703347

Epoch: 6| Step: 13
Training loss: 1.0939553749181532
Validation loss: 2.4018772006026037

Epoch: 495| Step: 0
Training loss: 2.4226607493949572
Validation loss: 2.5437052126753197

Epoch: 6| Step: 1
Training loss: 1.693048890896702
Validation loss: 2.581672873809862

Epoch: 6| Step: 2
Training loss: 1.5114246644209868
Validation loss: 2.6013463659849934

Epoch: 6| Step: 3
Training loss: 2.049387081909863
Validation loss: 2.527512729905201

Epoch: 6| Step: 4
Training loss: 1.900681288192065
Validation loss: 2.5510978344603776

Epoch: 6| Step: 5
Training loss: 1.8521615519990067
Validation loss: 2.545387597229762

Epoch: 6| Step: 6
Training loss: 1.7368676770835922
Validation loss: 2.558165759715512

Epoch: 6| Step: 7
Training loss: 1.7892366682672312
Validation loss: 2.5724522941830865

Epoch: 6| Step: 8
Training loss: 1.3958660757675059
Validation loss: 2.5909478491857336

Epoch: 6| Step: 9
Training loss: 2.301182762046422
Validation loss: 2.498873002330454

Epoch: 6| Step: 10
Training loss: 1.7423772323684956
Validation loss: 2.544038178264817

Epoch: 6| Step: 11
Training loss: 2.0111891558674215
Validation loss: 2.5213757576050106

Epoch: 6| Step: 12
Training loss: 1.9489612600391895
Validation loss: 2.6508564604607576

Epoch: 6| Step: 13
Training loss: 2.495137253772051
Validation loss: 2.4905920716897914

Epoch: 496| Step: 0
Training loss: 1.6891810909283318
Validation loss: 2.526926246346555

Epoch: 6| Step: 1
Training loss: 2.050736141617
Validation loss: 2.5951158925392876

Epoch: 6| Step: 2
Training loss: 1.762581962681707
Validation loss: 2.4589420518814475

Epoch: 6| Step: 3
Training loss: 2.1591600324891247
Validation loss: 2.4980574746834536

Epoch: 6| Step: 4
Training loss: 1.741004576465041
Validation loss: 2.6276907434244516

Epoch: 6| Step: 5
Training loss: 1.4554193902975365
Validation loss: 2.4984949903948612

Epoch: 6| Step: 6
Training loss: 2.213769184462372
Validation loss: 2.5691669852716146

Epoch: 6| Step: 7
Training loss: 2.0040064260566304
Validation loss: 2.6131656792297253

Epoch: 6| Step: 8
Training loss: 1.9183659967623956
Validation loss: 2.5402660945661486

Epoch: 6| Step: 9
Training loss: 2.576679633758934
Validation loss: 2.51067190736856

Epoch: 6| Step: 10
Training loss: 2.0397433609441227
Validation loss: 2.5421710304864136

Epoch: 6| Step: 11
Training loss: 1.7284076204339842
Validation loss: 2.501863009003212

Epoch: 6| Step: 12
Training loss: 1.5365897515770073
Validation loss: 2.553978169636844

Epoch: 6| Step: 13
Training loss: 1.5511763139141033
Validation loss: 2.503388515184988

Epoch: 497| Step: 0
Training loss: 1.7733351892208244
Validation loss: 2.5294875523137645

Epoch: 6| Step: 1
Training loss: 1.4195833287949595
Validation loss: 2.5579979278023175

Epoch: 6| Step: 2
Training loss: 2.129202557862842
Validation loss: 2.67556821009313

Epoch: 6| Step: 3
Training loss: 2.534682595510797
Validation loss: 2.597682473914392

Epoch: 6| Step: 4
Training loss: 1.7788740005216939
Validation loss: 2.6594016693059332

Epoch: 6| Step: 5
Training loss: 1.8699538037514918
Validation loss: 2.598847911008929

Epoch: 6| Step: 6
Training loss: 1.3441427233590086
Validation loss: 2.5243526368833806

Epoch: 6| Step: 7
Training loss: 1.3732349163888893
Validation loss: 2.532671265181225

Epoch: 6| Step: 8
Training loss: 1.5836134545672211
Validation loss: 2.5084923968868984

Epoch: 6| Step: 9
Training loss: 1.4629608667110943
Validation loss: 2.503700305086209

Epoch: 6| Step: 10
Training loss: 1.70761999107985
Validation loss: 2.5552946123629674

Epoch: 6| Step: 11
Training loss: 1.8858819531443847
Validation loss: 2.5480754787876103

Epoch: 6| Step: 12
Training loss: 2.515436674852231
Validation loss: 2.651290929865476

Epoch: 6| Step: 13
Training loss: 2.5234575300337014
Validation loss: 2.5557755630005863

Epoch: 498| Step: 0
Training loss: 2.5968423816087554
Validation loss: 2.5191360559253306

Epoch: 6| Step: 1
Training loss: 2.0309356446205604
Validation loss: 2.5426986417559516

Epoch: 6| Step: 2
Training loss: 1.4089879826181462
Validation loss: 2.4475231953192287

Epoch: 6| Step: 3
Training loss: 1.4788172224022682
Validation loss: 2.5465747830699694

Epoch: 6| Step: 4
Training loss: 1.8574348393097115
Validation loss: 2.484580023972377

Epoch: 6| Step: 5
Training loss: 1.6069585936742263
Validation loss: 2.681909862328837

Epoch: 6| Step: 6
Training loss: 1.442393473984167
Validation loss: 2.500698639555788

Epoch: 6| Step: 7
Training loss: 1.7848239313905596
Validation loss: 2.5325161547186523

Epoch: 6| Step: 8
Training loss: 1.8011138675029816
Validation loss: 2.50291807445905

Epoch: 6| Step: 9
Training loss: 1.8479139216881815
Validation loss: 2.505817832343784

Epoch: 6| Step: 10
Training loss: 2.1712410639709114
Validation loss: 2.523761850969077

Epoch: 6| Step: 11
Training loss: 1.697318160777115
Validation loss: 2.6143628573161597

Epoch: 6| Step: 12
Training loss: 2.094759797230523
Validation loss: 2.495432058333418

Epoch: 6| Step: 13
Training loss: 1.370443032114409
Validation loss: 2.5972057735593537

Epoch: 499| Step: 0
Training loss: 2.1044924140806143
Validation loss: 2.538719199220821

Epoch: 6| Step: 1
Training loss: 2.097910831851163
Validation loss: 2.4716101688373495

Epoch: 6| Step: 2
Training loss: 1.682048610769528
Validation loss: 2.520754829621014

Epoch: 6| Step: 3
Training loss: 1.254576791936079
Validation loss: 2.6353188974485415

Epoch: 6| Step: 4
Training loss: 1.489504013972974
Validation loss: 2.4592066201460288

Epoch: 6| Step: 5
Training loss: 2.1850459911473155
Validation loss: 2.5190502926477034

Epoch: 6| Step: 6
Training loss: 1.8990819645609631
Validation loss: 2.4977704371072456

Epoch: 6| Step: 7
Training loss: 1.7318587049022582
Validation loss: 2.596808678871842

Epoch: 6| Step: 8
Training loss: 1.836173054619643
Validation loss: 2.573001591310191

Epoch: 6| Step: 9
Training loss: 1.348935744441347
Validation loss: 2.475542154281138

Epoch: 6| Step: 10
Training loss: 2.023737351281998
Validation loss: 2.552198751391613

Epoch: 6| Step: 11
Training loss: 2.407549816657994
Validation loss: 2.5138994639078738

Epoch: 6| Step: 12
Training loss: 1.8399075053643046
Validation loss: 2.5090233434629825

Epoch: 6| Step: 13
Training loss: 2.1249266219092213
Validation loss: 2.5993604977509728

Epoch: 500| Step: 0
Training loss: 1.339705924460676
Validation loss: 2.6103865340606114

Epoch: 6| Step: 1
Training loss: 1.6765814873437
Validation loss: 2.4996317797383285

Epoch: 6| Step: 2
Training loss: 2.1191737018587933
Validation loss: 2.5618223109048204

Epoch: 6| Step: 3
Training loss: 2.189463905491691
Validation loss: 2.5482167405672946

Epoch: 6| Step: 4
Training loss: 1.6737616046164205
Validation loss: 2.5941721788453243

Epoch: 6| Step: 5
Training loss: 1.5171314107346614
Validation loss: 2.57631539544552

Epoch: 6| Step: 6
Training loss: 2.082042472193607
Validation loss: 2.4766855713605804

Epoch: 6| Step: 7
Training loss: 1.8670375875521412
Validation loss: 2.4691706899055785

Epoch: 6| Step: 8
Training loss: 2.350858766818696
Validation loss: 2.512754638760183

Epoch: 6| Step: 9
Training loss: 1.622835992547203
Validation loss: 2.5187066545937227

Epoch: 6| Step: 10
Training loss: 1.720222397332089
Validation loss: 2.591200279933107

Epoch: 6| Step: 11
Training loss: 1.8997982470157229
Validation loss: 2.520653404934053

Epoch: 6| Step: 12
Training loss: 2.0674373599691576
Validation loss: 2.5725103380196885

Epoch: 6| Step: 13
Training loss: 1.213811896147474
Validation loss: 2.4500883144260164

Epoch: 501| Step: 0
Training loss: 1.1633947108308027
Validation loss: 2.6489839712705443

Epoch: 6| Step: 1
Training loss: 2.06472958362082
Validation loss: 2.4663087720181833

Epoch: 6| Step: 2
Training loss: 1.2656491124246285
Validation loss: 2.525668286729885

Epoch: 6| Step: 3
Training loss: 1.7981244594452503
Validation loss: 2.5920241369290604

Epoch: 6| Step: 4
Training loss: 1.7662494871620682
Validation loss: 2.4953965493300476

Epoch: 6| Step: 5
Training loss: 2.096430414996958
Validation loss: 2.5284795514545313

Epoch: 6| Step: 6
Training loss: 1.5879772580245517
Validation loss: 2.633230170439378

Epoch: 6| Step: 7
Training loss: 2.6606551499346507
Validation loss: 2.444621368787781

Epoch: 6| Step: 8
Training loss: 2.2578061641617415
Validation loss: 2.550209120319593

Epoch: 6| Step: 9
Training loss: 1.3439460877464928
Validation loss: 2.61719736052388

Epoch: 6| Step: 10
Training loss: 1.6798988386759526
Validation loss: 2.5514340262597397

Epoch: 6| Step: 11
Training loss: 1.8572324702367193
Validation loss: 2.6275619099678686

Epoch: 6| Step: 12
Training loss: 2.167646284435888
Validation loss: 2.538660620602289

Epoch: 6| Step: 13
Training loss: 1.6646752460616647
Validation loss: 2.5332071082895786

Epoch: 502| Step: 0
Training loss: 1.8491172901292738
Validation loss: 2.5830536984412533

Epoch: 6| Step: 1
Training loss: 2.088785919848542
Validation loss: 2.60670573012392

Epoch: 6| Step: 2
Training loss: 1.3068311064914069
Validation loss: 2.588351752629511

Epoch: 6| Step: 3
Training loss: 2.1495266459823963
Validation loss: 2.5823043145924487

Epoch: 6| Step: 4
Training loss: 2.0617652509099136
Validation loss: 2.666702761200716

Epoch: 6| Step: 5
Training loss: 2.331100917273045
Validation loss: 2.532104295360006

Epoch: 6| Step: 6
Training loss: 1.9478525025378761
Validation loss: 2.5264275828931546

Epoch: 6| Step: 7
Training loss: 1.056387259238305
Validation loss: 2.643930723103557

Epoch: 6| Step: 8
Training loss: 1.657069741125317
Validation loss: 2.4732471366509317

Epoch: 6| Step: 9
Training loss: 2.149729503205155
Validation loss: 2.5762503024420096

Epoch: 6| Step: 10
Training loss: 2.051463219011918
Validation loss: 2.619981761337532

Epoch: 6| Step: 11
Training loss: 1.9202854437043297
Validation loss: 2.548690820991545

Epoch: 6| Step: 12
Training loss: 1.734807003621219
Validation loss: 2.6140356081301452

Epoch: 6| Step: 13
Training loss: 1.8321371800231936
Validation loss: 2.6179860209006556

Epoch: 503| Step: 0
Training loss: 1.7993865000763745
Validation loss: 2.5731356184160505

Epoch: 6| Step: 1
Training loss: 1.693061283189854
Validation loss: 2.4811197393148507

Epoch: 6| Step: 2
Training loss: 2.6494290906491864
Validation loss: 2.5700347857082044

Epoch: 6| Step: 3
Training loss: 2.221634722244143
Validation loss: 2.6709811554071052

Epoch: 6| Step: 4
Training loss: 1.5690011389578096
Validation loss: 2.551369674043137

Epoch: 6| Step: 5
Training loss: 1.42283204116992
Validation loss: 2.506176335295518

Epoch: 6| Step: 6
Training loss: 2.0781152481194476
Validation loss: 2.4848409422026987

Epoch: 6| Step: 7
Training loss: 1.6106631854811262
Validation loss: 2.502344497512996

Epoch: 6| Step: 8
Training loss: 1.634896148976513
Validation loss: 2.5546328274813437

Epoch: 6| Step: 9
Training loss: 1.6736843977728861
Validation loss: 2.5892117359458613

Epoch: 6| Step: 10
Training loss: 1.5572918112594214
Validation loss: 2.633474830513908

Epoch: 6| Step: 11
Training loss: 2.0373666076056662
Validation loss: 2.517135290065004

Epoch: 6| Step: 12
Training loss: 1.9007489610493802
Validation loss: 2.551292856200773

Epoch: 6| Step: 13
Training loss: 1.8455693595087252
Validation loss: 2.5231469999044833

Epoch: 504| Step: 0
Training loss: 1.9325455107271068
Validation loss: 2.549646358108361

Epoch: 6| Step: 1
Training loss: 2.145361901011066
Validation loss: 2.6406968455216853

Epoch: 6| Step: 2
Training loss: 1.8471312472600565
Validation loss: 2.448809082763733

Epoch: 6| Step: 3
Training loss: 1.6617234675201902
Validation loss: 2.4720216523946656

Epoch: 6| Step: 4
Training loss: 1.7264949733595776
Validation loss: 2.565447596939233

Epoch: 6| Step: 5
Training loss: 1.3340435322145623
Validation loss: 2.489716350763723

Epoch: 6| Step: 6
Training loss: 1.3125152587003661
Validation loss: 2.4743635407719498

Epoch: 6| Step: 7
Training loss: 1.762952148662266
Validation loss: 2.5745588277122535

Epoch: 6| Step: 8
Training loss: 1.7514175395889287
Validation loss: 2.560844184548672

Epoch: 6| Step: 9
Training loss: 2.0392930642215763
Validation loss: 2.50391847481651

Epoch: 6| Step: 10
Training loss: 2.1261488109194793
Validation loss: 2.4819721745884227

Epoch: 6| Step: 11
Training loss: 1.9279149366109536
Validation loss: 2.5586157542239625

Epoch: 6| Step: 12
Training loss: 2.2241661695315664
Validation loss: 2.637766740206503

Epoch: 6| Step: 13
Training loss: 1.7224350698604733
Validation loss: 2.5352521436726945

Epoch: 505| Step: 0
Training loss: 2.2780000712568023
Validation loss: 2.487840584565512

Epoch: 6| Step: 1
Training loss: 1.4344646916157642
Validation loss: 2.5147111501976878

Epoch: 6| Step: 2
Training loss: 1.9178664419076115
Validation loss: 2.508238579276726

Epoch: 6| Step: 3
Training loss: 1.4480286516021
Validation loss: 2.7114006115725684

Epoch: 6| Step: 4
Training loss: 2.129523007707699
Validation loss: 2.5937154149599846

Epoch: 6| Step: 5
Training loss: 1.6318710752547372
Validation loss: 2.669343728131375

Epoch: 6| Step: 6
Training loss: 1.9038704575659828
Validation loss: 2.6063640239721355

Epoch: 6| Step: 7
Training loss: 1.7443414894966438
Validation loss: 2.5642285323417666

Epoch: 6| Step: 8
Training loss: 1.625710698750394
Validation loss: 2.6716374184486598

Epoch: 6| Step: 9
Training loss: 2.0420825560616995
Validation loss: 2.5657896929906836

Epoch: 6| Step: 10
Training loss: 1.5440024474524832
Validation loss: 2.5208352384777863

Epoch: 6| Step: 11
Training loss: 1.8312309810965763
Validation loss: 2.548553511597639

Epoch: 6| Step: 12
Training loss: 2.6886835375400846
Validation loss: 2.596567974769635

Epoch: 6| Step: 13
Training loss: 1.5631902314569044
Validation loss: 2.653701057251127

Epoch: 506| Step: 0
Training loss: 1.208077973754499
Validation loss: 2.561333457564649

Epoch: 6| Step: 1
Training loss: 1.9944170275509474
Validation loss: 2.5500733674843477

Epoch: 6| Step: 2
Training loss: 2.8258171148874394
Validation loss: 2.5581986387206257

Epoch: 6| Step: 3
Training loss: 1.595730019089458
Validation loss: 2.4981226794246174

Epoch: 6| Step: 4
Training loss: 1.638198802439648
Validation loss: 2.529698230331218

Epoch: 6| Step: 5
Training loss: 1.5603393111092365
Validation loss: 2.5830240061132326

Epoch: 6| Step: 6
Training loss: 1.9627741992640806
Validation loss: 2.64415527362186

Epoch: 6| Step: 7
Training loss: 1.4232031519376216
Validation loss: 2.637432284959211

Epoch: 6| Step: 8
Training loss: 1.6072847439939686
Validation loss: 2.5488244236109985

Epoch: 6| Step: 9
Training loss: 1.9999063589108945
Validation loss: 2.4527457572237927

Epoch: 6| Step: 10
Training loss: 1.7509288366465285
Validation loss: 2.5823711620615577

Epoch: 6| Step: 11
Training loss: 1.9009290757651842
Validation loss: 2.5254622831519007

Epoch: 6| Step: 12
Training loss: 1.4254445971878738
Validation loss: 2.4310432753003184

Epoch: 6| Step: 13
Training loss: 1.6592509595124743
Validation loss: 2.513901079249108

Epoch: 507| Step: 0
Training loss: 1.5071354269878943
Validation loss: 2.6491366297404064

Epoch: 6| Step: 1
Training loss: 1.4424695897326456
Validation loss: 2.6045905757968604

Epoch: 6| Step: 2
Training loss: 1.7586678691413553
Validation loss: 2.538287696722502

Epoch: 6| Step: 3
Training loss: 0.8148545846922817
Validation loss: 2.559869196619079

Epoch: 6| Step: 4
Training loss: 2.010966988253223
Validation loss: 2.578313682018264

Epoch: 6| Step: 5
Training loss: 2.9355395653913483
Validation loss: 2.607232737075067

Epoch: 6| Step: 6
Training loss: 1.7326474908357412
Validation loss: 2.542508648691001

Epoch: 6| Step: 7
Training loss: 1.3888412350850556
Validation loss: 2.5877057639723797

Epoch: 6| Step: 8
Training loss: 2.0874614506434277
Validation loss: 2.5552079487617085

Epoch: 6| Step: 9
Training loss: 1.5790564177316904
Validation loss: 2.6403392722839985

Epoch: 6| Step: 10
Training loss: 2.0988900021267987
Validation loss: 2.6559356175262248

Epoch: 6| Step: 11
Training loss: 1.9443797744108688
Validation loss: 2.542575480713551

Epoch: 6| Step: 12
Training loss: 1.7731082963610514
Validation loss: 2.639232698771839

Epoch: 6| Step: 13
Training loss: 2.0968860654354198
Validation loss: 2.526481350808538

Epoch: 508| Step: 0
Training loss: 1.537342950506862
Validation loss: 2.4684694950389265

Epoch: 6| Step: 1
Training loss: 1.5938826113113684
Validation loss: 2.6440241348598286

Epoch: 6| Step: 2
Training loss: 1.2188858543384495
Validation loss: 2.5348534962528704

Epoch: 6| Step: 3
Training loss: 1.8746050736635704
Validation loss: 2.4993934408247718

Epoch: 6| Step: 4
Training loss: 1.9301075960714522
Validation loss: 2.5163011619879248

Epoch: 6| Step: 5
Training loss: 1.8975057316870687
Validation loss: 2.5880693630501916

Epoch: 6| Step: 6
Training loss: 1.647982421540516
Validation loss: 2.5191058452933692

Epoch: 6| Step: 7
Training loss: 1.628687123441219
Validation loss: 2.5297636425494567

Epoch: 6| Step: 8
Training loss: 2.2417091630313357
Validation loss: 2.5625701852666527

Epoch: 6| Step: 9
Training loss: 2.509853495087508
Validation loss: 2.4836250804269997

Epoch: 6| Step: 10
Training loss: 1.4650319703294956
Validation loss: 2.5059679518883007

Epoch: 6| Step: 11
Training loss: 2.17263385496425
Validation loss: 2.5369743283375548

Epoch: 6| Step: 12
Training loss: 1.9119614883917673
Validation loss: 2.515306284821442

Epoch: 6| Step: 13
Training loss: 1.6394797551335227
Validation loss: 2.5792702496238045

Epoch: 509| Step: 0
Training loss: 1.7084381102398107
Validation loss: 2.5824234782937636

Epoch: 6| Step: 1
Training loss: 1.7874222611815753
Validation loss: 2.6648922510576267

Epoch: 6| Step: 2
Training loss: 2.1101805102617814
Validation loss: 2.5058212893132494

Epoch: 6| Step: 3
Training loss: 2.0053218132374653
Validation loss: 2.5647567547907237

Epoch: 6| Step: 4
Training loss: 1.867591782220542
Validation loss: 2.6069608783418277

Epoch: 6| Step: 5
Training loss: 1.1641232263483352
Validation loss: 2.5063757248822185

Epoch: 6| Step: 6
Training loss: 2.281011908661069
Validation loss: 2.4929908797143576

Epoch: 6| Step: 7
Training loss: 2.275426774290368
Validation loss: 2.51323931432523

Epoch: 6| Step: 8
Training loss: 1.6754747657344151
Validation loss: 2.588168213209138

Epoch: 6| Step: 9
Training loss: 1.5079605741380997
Validation loss: 2.492008228111704

Epoch: 6| Step: 10
Training loss: 1.912667462864778
Validation loss: 2.6418491221973057

Epoch: 6| Step: 11
Training loss: 2.4352235189379887
Validation loss: 2.4602438953708217

Epoch: 6| Step: 12
Training loss: 1.8893559507973812
Validation loss: 2.453371145224313

Epoch: 6| Step: 13
Training loss: 1.3077747116189766
Validation loss: 2.5349562945142607

Epoch: 510| Step: 0
Training loss: 1.86511121413167
Validation loss: 2.606655287975717

Epoch: 6| Step: 1
Training loss: 1.7802785935068302
Validation loss: 2.5616411089791282

Epoch: 6| Step: 2
Training loss: 2.0893120490383517
Validation loss: 2.52882578071066

Epoch: 6| Step: 3
Training loss: 1.4556682849179419
Validation loss: 2.4670981938754317

Epoch: 6| Step: 4
Training loss: 1.705639234506513
Validation loss: 2.5091280612938722

Epoch: 6| Step: 5
Training loss: 1.9652153861929837
Validation loss: 2.625774953767937

Epoch: 6| Step: 6
Training loss: 1.6904867373072883
Validation loss: 2.4679978734453987

Epoch: 6| Step: 7
Training loss: 1.977797292167792
Validation loss: 2.4367901420773452

Epoch: 6| Step: 8
Training loss: 1.470865795364425
Validation loss: 2.426035261865389

Epoch: 6| Step: 9
Training loss: 2.7154108347139183
Validation loss: 2.483733165671593

Epoch: 6| Step: 10
Training loss: 1.505612047518974
Validation loss: 2.5683064578552712

Epoch: 6| Step: 11
Training loss: 1.5539570534956513
Validation loss: 2.6147291450613372

Epoch: 6| Step: 12
Training loss: 1.8581516504926712
Validation loss: 2.581672313749178

Epoch: 6| Step: 13
Training loss: 1.80736353252194
Validation loss: 2.6149208025263735

Epoch: 511| Step: 0
Training loss: 2.3894638532741013
Validation loss: 2.447026220175604

Epoch: 6| Step: 1
Training loss: 1.8613812818272
Validation loss: 2.522489448309918

Epoch: 6| Step: 2
Training loss: 1.4230302581947845
Validation loss: 2.4960204563077286

Epoch: 6| Step: 3
Training loss: 1.7148384667664913
Validation loss: 2.631419105737925

Epoch: 6| Step: 4
Training loss: 1.7648312295078643
Validation loss: 2.4822908640927475

Epoch: 6| Step: 5
Training loss: 1.8928599113382416
Validation loss: 2.632012358949697

Epoch: 6| Step: 6
Training loss: 2.3426614903953884
Validation loss: 2.5213959087429627

Epoch: 6| Step: 7
Training loss: 1.7763959768016517
Validation loss: 2.572281465657513

Epoch: 6| Step: 8
Training loss: 1.9869611813459107
Validation loss: 2.489087254156568

Epoch: 6| Step: 9
Training loss: 1.5665149983924822
Validation loss: 2.5685655871441124

Epoch: 6| Step: 10
Training loss: 1.7256362294595404
Validation loss: 2.5430894227028085

Epoch: 6| Step: 11
Training loss: 2.2686772274399654
Validation loss: 2.46711551926213

Epoch: 6| Step: 12
Training loss: 1.701122892005226
Validation loss: 2.4450658554378792

Epoch: 6| Step: 13
Training loss: 1.8000270894449326
Validation loss: 2.583088987969867

Epoch: 512| Step: 0
Training loss: 1.5007353410743631
Validation loss: 2.5433348861891947

Epoch: 6| Step: 1
Training loss: 2.25679938477809
Validation loss: 2.512286594776105

Epoch: 6| Step: 2
Training loss: 2.1028862510171105
Validation loss: 2.52550801377546

Epoch: 6| Step: 3
Training loss: 2.0608248988605093
Validation loss: 2.5043070352108328

Epoch: 6| Step: 4
Training loss: 1.6161005910215778
Validation loss: 2.648971297159095

Epoch: 6| Step: 5
Training loss: 1.342462321912386
Validation loss: 2.6639006931252793

Epoch: 6| Step: 6
Training loss: 1.388366837404462
Validation loss: 2.576556399084012

Epoch: 6| Step: 7
Training loss: 1.4829038055253787
Validation loss: 2.606974197245214

Epoch: 6| Step: 8
Training loss: 2.1600773333022008
Validation loss: 2.603380281565651

Epoch: 6| Step: 9
Training loss: 2.2212847348117957
Validation loss: 2.717477397130938

Epoch: 6| Step: 10
Training loss: 2.00444086093305
Validation loss: 2.564958113218579

Epoch: 6| Step: 11
Training loss: 1.7607586394952055
Validation loss: 2.594467600514994

Epoch: 6| Step: 12
Training loss: 1.6046040751938349
Validation loss: 2.6956041888911306

Epoch: 6| Step: 13
Training loss: 3.1073563507096207
Validation loss: 2.555659506319743

Epoch: 513| Step: 0
Training loss: 1.493306005403831
Validation loss: 2.4493632911700542

Epoch: 6| Step: 1
Training loss: 1.7671295102535385
Validation loss: 2.5268435146957966

Epoch: 6| Step: 2
Training loss: 1.5413242509688725
Validation loss: 2.646123636830346

Epoch: 6| Step: 3
Training loss: 2.5996104755585576
Validation loss: 2.605234124392367

Epoch: 6| Step: 4
Training loss: 1.7447214900085783
Validation loss: 2.4991644498736756

Epoch: 6| Step: 5
Training loss: 2.5329350643637123
Validation loss: 2.628340411764422

Epoch: 6| Step: 6
Training loss: 2.40351196665728
Validation loss: 2.554735070692243

Epoch: 6| Step: 7
Training loss: 2.0538056660570936
Validation loss: 2.509959800246972

Epoch: 6| Step: 8
Training loss: 1.6345100157422987
Validation loss: 2.573122212034354

Epoch: 6| Step: 9
Training loss: 1.84775580043241
Validation loss: 2.586309862393815

Epoch: 6| Step: 10
Training loss: 1.760772383225204
Validation loss: 2.5473666174302787

Epoch: 6| Step: 11
Training loss: 1.3806935255279995
Validation loss: 2.597607326671392

Epoch: 6| Step: 12
Training loss: 1.596623765625249
Validation loss: 2.4987452208846173

Epoch: 6| Step: 13
Training loss: 1.6905711449244085
Validation loss: 2.630971004636979

Epoch: 514| Step: 0
Training loss: 1.581151647109931
Validation loss: 2.579608678007026

Epoch: 6| Step: 1
Training loss: 2.11584790631815
Validation loss: 2.5589915021749583

Epoch: 6| Step: 2
Training loss: 1.5040795164495055
Validation loss: 2.5024209144887783

Epoch: 6| Step: 3
Training loss: 1.671518590852836
Validation loss: 2.5420624720485083

Epoch: 6| Step: 4
Training loss: 1.83922500086879
Validation loss: 2.5334204166445717

Epoch: 6| Step: 5
Training loss: 2.837977660722295
Validation loss: 2.5045891674316216

Epoch: 6| Step: 6
Training loss: 1.3961673830293189
Validation loss: 2.6269998252503193

Epoch: 6| Step: 7
Training loss: 1.503466256912688
Validation loss: 2.4705232186952952

Epoch: 6| Step: 8
Training loss: 1.6277858622541517
Validation loss: 2.4789678708130185

Epoch: 6| Step: 9
Training loss: 1.9392342957803381
Validation loss: 2.605241959264425

Epoch: 6| Step: 10
Training loss: 1.40544054258581
Validation loss: 2.4994668351023424

Epoch: 6| Step: 11
Training loss: 1.861009280264139
Validation loss: 2.6173022956876966

Epoch: 6| Step: 12
Training loss: 1.8928012145589121
Validation loss: 2.5651963257317423

Epoch: 6| Step: 13
Training loss: 1.9937649932584571
Validation loss: 2.595705763993739

Epoch: 515| Step: 0
Training loss: 1.8088706280411178
Validation loss: 2.615340440223744

Epoch: 6| Step: 1
Training loss: 1.299138816443633
Validation loss: 2.6616867221411593

Epoch: 6| Step: 2
Training loss: 2.1574288062309446
Validation loss: 2.523705348419408

Epoch: 6| Step: 3
Training loss: 1.9646501388868578
Validation loss: 2.523030567163004

Epoch: 6| Step: 4
Training loss: 1.860749321815073
Validation loss: 2.6690562790130743

Epoch: 6| Step: 5
Training loss: 1.6969845871638478
Validation loss: 2.517652460554987

Epoch: 6| Step: 6
Training loss: 2.336038134394265
Validation loss: 2.5871933607404

Epoch: 6| Step: 7
Training loss: 1.8747546989197883
Validation loss: 2.4334879519546213

Epoch: 6| Step: 8
Training loss: 1.7333424561822897
Validation loss: 2.591642494894795

Epoch: 6| Step: 9
Training loss: 1.786734186196711
Validation loss: 2.461213056375947

Epoch: 6| Step: 10
Training loss: 1.87769740310118
Validation loss: 2.5995730641956367

Epoch: 6| Step: 11
Training loss: 1.5033357405096999
Validation loss: 2.4960326683921736

Epoch: 6| Step: 12
Training loss: 1.5919929243246822
Validation loss: 2.5069814311951046

Epoch: 6| Step: 13
Training loss: 2.3248410201324266
Validation loss: 2.5765450885421983

Epoch: 516| Step: 0
Training loss: 1.975610435888328
Validation loss: 2.512316813938735

Epoch: 6| Step: 1
Training loss: 1.7436528223229881
Validation loss: 2.5871201720957084

Epoch: 6| Step: 2
Training loss: 1.67060318818073
Validation loss: 2.564903538684029

Epoch: 6| Step: 3
Training loss: 2.032660126894628
Validation loss: 2.5298863106003298

Epoch: 6| Step: 4
Training loss: 2.402805488686336
Validation loss: 2.4894575438298014

Epoch: 6| Step: 5
Training loss: 2.3157816104207853
Validation loss: 2.613773603126147

Epoch: 6| Step: 6
Training loss: 1.726136444135629
Validation loss: 2.535360945178116

Epoch: 6| Step: 7
Training loss: 1.760106196667509
Validation loss: 2.5885769777746566

Epoch: 6| Step: 8
Training loss: 1.202143380149039
Validation loss: 2.6949804652287974

Epoch: 6| Step: 9
Training loss: 1.709629900406022
Validation loss: 2.574424903080693

Epoch: 6| Step: 10
Training loss: 1.2645419160616254
Validation loss: 2.5541042878794395

Epoch: 6| Step: 11
Training loss: 1.8915153487709875
Validation loss: 2.5422736468089364

Epoch: 6| Step: 12
Training loss: 2.180455773156756
Validation loss: 2.581007743943883

Epoch: 6| Step: 13
Training loss: 1.8094837478873382
Validation loss: 2.5178337359768728

Epoch: 517| Step: 0
Training loss: 1.2116530734475515
Validation loss: 2.5843450276767226

Epoch: 6| Step: 1
Training loss: 2.1838826379088387
Validation loss: 2.5261989245587597

Epoch: 6| Step: 2
Training loss: 1.8993094996524318
Validation loss: 2.521421514558262

Epoch: 6| Step: 3
Training loss: 1.4038954626654983
Validation loss: 2.4946095650223326

Epoch: 6| Step: 4
Training loss: 1.9024763433161112
Validation loss: 2.549171095715586

Epoch: 6| Step: 5
Training loss: 1.9652672495146228
Validation loss: 2.4993428463822083

Epoch: 6| Step: 6
Training loss: 1.7237559158411788
Validation loss: 2.4926010140067305

Epoch: 6| Step: 7
Training loss: 2.1364475894126516
Validation loss: 2.5829656605925786

Epoch: 6| Step: 8
Training loss: 1.2502658561276219
Validation loss: 2.4817189130684962

Epoch: 6| Step: 9
Training loss: 2.201035394643094
Validation loss: 2.663697739304719

Epoch: 6| Step: 10
Training loss: 2.102867430378942
Validation loss: 2.586464750106114

Epoch: 6| Step: 11
Training loss: 1.6138137049551746
Validation loss: 2.4950492034557823

Epoch: 6| Step: 12
Training loss: 1.7131036432403968
Validation loss: 2.6170368864470417

Epoch: 6| Step: 13
Training loss: 1.478722984860447
Validation loss: 2.606750748491512

Epoch: 518| Step: 0
Training loss: 1.5712872416863284
Validation loss: 2.5835091550565945

Epoch: 6| Step: 1
Training loss: 1.4468132681478953
Validation loss: 2.5336118020536746

Epoch: 6| Step: 2
Training loss: 1.5094508623917977
Validation loss: 2.5261445833347733

Epoch: 6| Step: 3
Training loss: 1.9350956796061394
Validation loss: 2.5789920973307643

Epoch: 6| Step: 4
Training loss: 1.5216949669726076
Validation loss: 2.5372657677469923

Epoch: 6| Step: 5
Training loss: 1.7152759467907535
Validation loss: 2.6310470941257753

Epoch: 6| Step: 6
Training loss: 1.9357958651773108
Validation loss: 2.461181996211416

Epoch: 6| Step: 7
Training loss: 1.5251796835431868
Validation loss: 2.5048898221493365

Epoch: 6| Step: 8
Training loss: 2.437895718266491
Validation loss: 2.600461506685582

Epoch: 6| Step: 9
Training loss: 2.178488124532247
Validation loss: 2.6198925611383252

Epoch: 6| Step: 10
Training loss: 1.7462505637122236
Validation loss: 2.605090100052872

Epoch: 6| Step: 11
Training loss: 1.556908099888106
Validation loss: 2.6063837693371434

Epoch: 6| Step: 12
Training loss: 2.292365597577966
Validation loss: 2.5952607020417857

Epoch: 6| Step: 13
Training loss: 1.9465676666695824
Validation loss: 2.5388808591378536

Epoch: 519| Step: 0
Training loss: 1.9286556187675998
Validation loss: 2.55110954171224

Epoch: 6| Step: 1
Training loss: 1.7529515852131565
Validation loss: 2.4696271456252052

Epoch: 6| Step: 2
Training loss: 1.931583785560191
Validation loss: 2.4908163324843953

Epoch: 6| Step: 3
Training loss: 1.9095701476919613
Validation loss: 2.533855400333451

Epoch: 6| Step: 4
Training loss: 1.3114222688490829
Validation loss: 2.4962240775620503

Epoch: 6| Step: 5
Training loss: 1.3950813982059396
Validation loss: 2.45246213389861

Epoch: 6| Step: 6
Training loss: 1.4827698712507167
Validation loss: 2.5992246282550444

Epoch: 6| Step: 7
Training loss: 1.5734667626607948
Validation loss: 2.548057130319132

Epoch: 6| Step: 8
Training loss: 1.7555872416688245
Validation loss: 2.523090226519594

Epoch: 6| Step: 9
Training loss: 1.8295478174591746
Validation loss: 2.568344538266153

Epoch: 6| Step: 10
Training loss: 1.8190235600762368
Validation loss: 2.544659972304851

Epoch: 6| Step: 11
Training loss: 2.9636903713217797
Validation loss: 2.5058822484366754

Epoch: 6| Step: 12
Training loss: 1.3493590723169302
Validation loss: 2.5332825821449054

Epoch: 6| Step: 13
Training loss: 2.1654792857724074
Validation loss: 2.58288324055961

Epoch: 520| Step: 0
Training loss: 1.7970583614834652
Validation loss: 2.533175364252783

Epoch: 6| Step: 1
Training loss: 1.5502927380659277
Validation loss: 2.5673277023525967

Epoch: 6| Step: 2
Training loss: 1.7794232286965772
Validation loss: 2.587166652971375

Epoch: 6| Step: 3
Training loss: 2.4035986623271812
Validation loss: 2.5715213858540755

Epoch: 6| Step: 4
Training loss: 1.3817719245884288
Validation loss: 2.5120855383940297

Epoch: 6| Step: 5
Training loss: 1.7705970232497412
Validation loss: 2.583628467593834

Epoch: 6| Step: 6
Training loss: 1.6572275695617888
Validation loss: 2.4384986150731676

Epoch: 6| Step: 7
Training loss: 1.8908988186875675
Validation loss: 2.649292858826648

Epoch: 6| Step: 8
Training loss: 1.5481093134911192
Validation loss: 2.5697967284101875

Epoch: 6| Step: 9
Training loss: 2.0771456827379478
Validation loss: 2.452816866183309

Epoch: 6| Step: 10
Training loss: 1.8860506568974496
Validation loss: 2.5864973437177157

Epoch: 6| Step: 11
Training loss: 2.098675073736883
Validation loss: 2.677932766972903

Epoch: 6| Step: 12
Training loss: 1.9272488772109049
Validation loss: 2.48585909542318

Epoch: 6| Step: 13
Training loss: 1.8845103352851071
Validation loss: 2.590421070173245

Epoch: 521| Step: 0
Training loss: 1.6104480906484815
Validation loss: 2.5871923391259903

Epoch: 6| Step: 1
Training loss: 1.8982844035893043
Validation loss: 2.5141661861247

Epoch: 6| Step: 2
Training loss: 1.5119273906712138
Validation loss: 2.5675841417118863

Epoch: 6| Step: 3
Training loss: 2.286550034847069
Validation loss: 2.4967278195726403

Epoch: 6| Step: 4
Training loss: 1.8487653891314313
Validation loss: 2.4717776818034958

Epoch: 6| Step: 5
Training loss: 1.6641212417192184
Validation loss: 2.554771700675647

Epoch: 6| Step: 6
Training loss: 2.474392394418803
Validation loss: 2.6277067114293997

Epoch: 6| Step: 7
Training loss: 1.4460190978892953
Validation loss: 2.5044249045002607

Epoch: 6| Step: 8
Training loss: 1.6869366729871111
Validation loss: 2.4829318012725046

Epoch: 6| Step: 9
Training loss: 1.679086196081869
Validation loss: 2.5416394989912523

Epoch: 6| Step: 10
Training loss: 1.7584067463426931
Validation loss: 2.595427357093498

Epoch: 6| Step: 11
Training loss: 1.7255755058797948
Validation loss: 2.6405407486263686

Epoch: 6| Step: 12
Training loss: 1.7597458443498433
Validation loss: 2.520863209358143

Epoch: 6| Step: 13
Training loss: 1.7236997596771981
Validation loss: 2.5628521514956217

Epoch: 522| Step: 0
Training loss: 1.685855063755479
Validation loss: 2.5060106869163703

Epoch: 6| Step: 1
Training loss: 1.6120588275739072
Validation loss: 2.6122214869951663

Epoch: 6| Step: 2
Training loss: 1.8109834837979244
Validation loss: 2.5708587900773674

Epoch: 6| Step: 3
Training loss: 1.6824738568206306
Validation loss: 2.4806115570959566

Epoch: 6| Step: 4
Training loss: 2.2620994761320716
Validation loss: 2.5814114632024507

Epoch: 6| Step: 5
Training loss: 1.610359261276321
Validation loss: 2.4756300130054187

Epoch: 6| Step: 6
Training loss: 1.2316158699913702
Validation loss: 2.557813418046907

Epoch: 6| Step: 7
Training loss: 1.6696646508993993
Validation loss: 2.5435107571725135

Epoch: 6| Step: 8
Training loss: 1.2053620979166868
Validation loss: 2.5337106322822605

Epoch: 6| Step: 9
Training loss: 2.0335647305423215
Validation loss: 2.6918905308776355

Epoch: 6| Step: 10
Training loss: 2.5127057498933048
Validation loss: 2.5766180691450704

Epoch: 6| Step: 11
Training loss: 1.2219435104324539
Validation loss: 2.4019132116122353

Epoch: 6| Step: 12
Training loss: 1.8501545506435644
Validation loss: 2.6461845609244614

Epoch: 6| Step: 13
Training loss: 1.8591512337042233
Validation loss: 2.4207321926834817

Epoch: 523| Step: 0
Training loss: 1.8583368560803244
Validation loss: 2.5521114050648315

Epoch: 6| Step: 1
Training loss: 1.7011399205882347
Validation loss: 2.4966019435294733

Epoch: 6| Step: 2
Training loss: 2.779347486966699
Validation loss: 2.609533442549587

Epoch: 6| Step: 3
Training loss: 1.092173939458355
Validation loss: 2.5085300265891606

Epoch: 6| Step: 4
Training loss: 1.400951533863131
Validation loss: 2.5561621197867725

Epoch: 6| Step: 5
Training loss: 2.350448496611527
Validation loss: 2.681891670512963

Epoch: 6| Step: 6
Training loss: 1.2122553391735325
Validation loss: 2.578268176068566

Epoch: 6| Step: 7
Training loss: 1.8613217845060226
Validation loss: 2.607110198785474

Epoch: 6| Step: 8
Training loss: 1.208754707177355
Validation loss: 2.6163256633517777

Epoch: 6| Step: 9
Training loss: 1.457813206516107
Validation loss: 2.596590317700204

Epoch: 6| Step: 10
Training loss: 1.8517676774957075
Validation loss: 2.50645413925135

Epoch: 6| Step: 11
Training loss: 2.224401234844258
Validation loss: 2.580921788796829

Epoch: 6| Step: 12
Training loss: 1.7331875697003818
Validation loss: 2.575618348913899

Epoch: 6| Step: 13
Training loss: 1.3674120909279746
Validation loss: 2.530314819779211

Epoch: 524| Step: 0
Training loss: 1.7538008966218073
Validation loss: 2.5636287597228296

Epoch: 6| Step: 1
Training loss: 1.2898705002005424
Validation loss: 2.5937469992414566

Epoch: 6| Step: 2
Training loss: 2.0598858536881623
Validation loss: 2.602824289844265

Epoch: 6| Step: 3
Training loss: 1.470402944055252
Validation loss: 2.567384079650013

Epoch: 6| Step: 4
Training loss: 1.6829601963297944
Validation loss: 2.580412904609109

Epoch: 6| Step: 5
Training loss: 1.5095111982922735
Validation loss: 2.5143606014289643

Epoch: 6| Step: 6
Training loss: 1.7039247087670784
Validation loss: 2.6382683999384273

Epoch: 6| Step: 7
Training loss: 1.792185560390018
Validation loss: 2.5866581053708964

Epoch: 6| Step: 8
Training loss: 2.533568933055444
Validation loss: 2.5598514514522845

Epoch: 6| Step: 9
Training loss: 1.842289879876498
Validation loss: 2.484182296526367

Epoch: 6| Step: 10
Training loss: 1.9276694428891548
Validation loss: 2.568228912814345

Epoch: 6| Step: 11
Training loss: 1.226690200669749
Validation loss: 2.5424130609833275

Epoch: 6| Step: 12
Training loss: 1.9887836173888886
Validation loss: 2.4521618978525983

Epoch: 6| Step: 13
Training loss: 1.4088870436615866
Validation loss: 2.607862617223782

Epoch: 525| Step: 0
Training loss: 1.9632157545174194
Validation loss: 2.4153367019068774

Epoch: 6| Step: 1
Training loss: 1.6376003904363616
Validation loss: 2.5588137216076414

Epoch: 6| Step: 2
Training loss: 1.9589558349234273
Validation loss: 2.5955130531115445

Epoch: 6| Step: 3
Training loss: 1.479646398986574
Validation loss: 2.4707999451098273

Epoch: 6| Step: 4
Training loss: 1.5073666086220354
Validation loss: 2.685955689458778

Epoch: 6| Step: 5
Training loss: 1.770456101871714
Validation loss: 2.627666405371877

Epoch: 6| Step: 6
Training loss: 2.0652580316154445
Validation loss: 2.521711838293532

Epoch: 6| Step: 7
Training loss: 1.6575363490058843
Validation loss: 2.6228157131999237

Epoch: 6| Step: 8
Training loss: 1.4490993070092564
Validation loss: 2.520104378039179

Epoch: 6| Step: 9
Training loss: 1.9078126974519694
Validation loss: 2.5878395456608194

Epoch: 6| Step: 10
Training loss: 2.267880494348304
Validation loss: 2.526017787673749

Epoch: 6| Step: 11
Training loss: 1.6320813746079836
Validation loss: 2.5517678831590946

Epoch: 6| Step: 12
Training loss: 1.7111423317564232
Validation loss: 2.5991381323809075

Epoch: 6| Step: 13
Training loss: 2.2456404518808295
Validation loss: 2.5452572800635638

Epoch: 526| Step: 0
Training loss: 1.9884554144043192
Validation loss: 2.5987419209129317

Epoch: 6| Step: 1
Training loss: 1.859344097489723
Validation loss: 2.5620148622454244

Epoch: 6| Step: 2
Training loss: 1.0514675012446681
Validation loss: 2.56274574255969

Epoch: 6| Step: 3
Training loss: 1.4329101429389866
Validation loss: 2.518484284375504

Epoch: 6| Step: 4
Training loss: 1.6800949667020169
Validation loss: 2.531401621193105

Epoch: 6| Step: 5
Training loss: 2.5533397047330215
Validation loss: 2.530398397882869

Epoch: 6| Step: 6
Training loss: 1.7946346746392372
Validation loss: 2.542123156108015

Epoch: 6| Step: 7
Training loss: 1.2508674472745884
Validation loss: 2.6069713641321393

Epoch: 6| Step: 8
Training loss: 1.8737593042754683
Validation loss: 2.628248783589304

Epoch: 6| Step: 9
Training loss: 1.410112544093083
Validation loss: 2.5123755256692353

Epoch: 6| Step: 10
Training loss: 2.089371387183021
Validation loss: 2.486321925017702

Epoch: 6| Step: 11
Training loss: 1.646073078447565
Validation loss: 2.5844100943615373

Epoch: 6| Step: 12
Training loss: 1.9554472888191017
Validation loss: 2.487408499545447

Epoch: 6| Step: 13
Training loss: 1.662498563034469
Validation loss: 2.5417554716441635

Epoch: 527| Step: 0
Training loss: 2.0477339711261093
Validation loss: 2.5548894974883165

Epoch: 6| Step: 1
Training loss: 1.9837256743412506
Validation loss: 2.560826892878388

Epoch: 6| Step: 2
Training loss: 2.4884478694398395
Validation loss: 2.5336476056843034

Epoch: 6| Step: 3
Training loss: 2.100787732563678
Validation loss: 2.552503455219178

Epoch: 6| Step: 4
Training loss: 1.5648915108806796
Validation loss: 2.5353982746906714

Epoch: 6| Step: 5
Training loss: 1.8210631693232526
Validation loss: 2.5777557337303634

Epoch: 6| Step: 6
Training loss: 1.0393672868966595
Validation loss: 2.534355083118396

Epoch: 6| Step: 7
Training loss: 2.642616920158225
Validation loss: 2.5429388204890397

Epoch: 6| Step: 8
Training loss: 1.313249283310197
Validation loss: 2.6090249783569446

Epoch: 6| Step: 9
Training loss: 1.5212427224053338
Validation loss: 2.4763726649207656

Epoch: 6| Step: 10
Training loss: 1.089080871689778
Validation loss: 2.5146750845982178

Epoch: 6| Step: 11
Training loss: 1.7258872528470088
Validation loss: 2.508437441106234

Epoch: 6| Step: 12
Training loss: 1.7920919697185431
Validation loss: 2.6526485003866354

Epoch: 6| Step: 13
Training loss: 1.5907939349025548
Validation loss: 2.4613016734466755

Epoch: 528| Step: 0
Training loss: 1.80046082002045
Validation loss: 2.596087943339906

Epoch: 6| Step: 1
Training loss: 1.8275592939409306
Validation loss: 2.559157852452213

Epoch: 6| Step: 2
Training loss: 1.4782752543369042
Validation loss: 2.604451120079428

Epoch: 6| Step: 3
Training loss: 2.664725391775711
Validation loss: 2.5243701674812624

Epoch: 6| Step: 4
Training loss: 1.921998679050464
Validation loss: 2.557128930812389

Epoch: 6| Step: 5
Training loss: 1.565625688320473
Validation loss: 2.596040131041415

Epoch: 6| Step: 6
Training loss: 1.484894511011401
Validation loss: 2.60087636167014

Epoch: 6| Step: 7
Training loss: 1.3787009542946527
Validation loss: 2.5025244190884672

Epoch: 6| Step: 8
Training loss: 1.3210604202695218
Validation loss: 2.6359934271561922

Epoch: 6| Step: 9
Training loss: 1.844775545066669
Validation loss: 2.571541650479584

Epoch: 6| Step: 10
Training loss: 2.083453925139385
Validation loss: 2.536600498098994

Epoch: 6| Step: 11
Training loss: 1.242396978793183
Validation loss: 2.611601175320967

Epoch: 6| Step: 12
Training loss: 1.7370547650389105
Validation loss: 2.5741022819258843

Epoch: 6| Step: 13
Training loss: 1.5756868469374923
Validation loss: 2.4169173961017067

Epoch: 529| Step: 0
Training loss: 1.7029518249381874
Validation loss: 2.5010174844445245

Epoch: 6| Step: 1
Training loss: 1.8383560158974983
Validation loss: 2.4663962008746334

Epoch: 6| Step: 2
Training loss: 2.033093129754604
Validation loss: 2.503623687551241

Epoch: 6| Step: 3
Training loss: 1.6072423934388644
Validation loss: 2.530707721157452

Epoch: 6| Step: 4
Training loss: 1.9504829542270357
Validation loss: 2.520274246145526

Epoch: 6| Step: 5
Training loss: 1.1162766698404414
Validation loss: 2.5265580463425343

Epoch: 6| Step: 6
Training loss: 1.2282698587108478
Validation loss: 2.5636557057060414

Epoch: 6| Step: 7
Training loss: 2.5216375492059577
Validation loss: 2.713328521169242

Epoch: 6| Step: 8
Training loss: 1.2860206549307236
Validation loss: 2.568428154479103

Epoch: 6| Step: 9
Training loss: 1.4578600615074817
Validation loss: 2.568297364389239

Epoch: 6| Step: 10
Training loss: 1.8435609364961894
Validation loss: 2.5544365412804466

Epoch: 6| Step: 11
Training loss: 1.5816273868427915
Validation loss: 2.53112579166545

Epoch: 6| Step: 12
Training loss: 2.067910467176069
Validation loss: 2.5502786496572534

Epoch: 6| Step: 13
Training loss: 1.7079382959159415
Validation loss: 2.602939954374546

Epoch: 530| Step: 0
Training loss: 1.538065941090253
Validation loss: 2.5271638201789246

Epoch: 6| Step: 1
Training loss: 1.648496075353327
Validation loss: 2.5514017272667058

Epoch: 6| Step: 2
Training loss: 2.0947710650502893
Validation loss: 2.5370285694655097

Epoch: 6| Step: 3
Training loss: 1.63590892340505
Validation loss: 2.5721662314680613

Epoch: 6| Step: 4
Training loss: 1.885542161112556
Validation loss: 2.5462846130205814

Epoch: 6| Step: 5
Training loss: 1.814932145040435
Validation loss: 2.498728735524977

Epoch: 6| Step: 6
Training loss: 1.9296216451550618
Validation loss: 2.5224854491122586

Epoch: 6| Step: 7
Training loss: 1.7277300585132886
Validation loss: 2.5276171939279233

Epoch: 6| Step: 8
Training loss: 1.985507551783598
Validation loss: 2.6409447113524624

Epoch: 6| Step: 9
Training loss: 1.8037868085186612
Validation loss: 2.5757231580872735

Epoch: 6| Step: 10
Training loss: 1.750964920507344
Validation loss: 2.4321382579648425

Epoch: 6| Step: 11
Training loss: 2.48914325820172
Validation loss: 2.481669852869184

Epoch: 6| Step: 12
Training loss: 1.3131592321132564
Validation loss: 2.6736331171874643

Epoch: 6| Step: 13
Training loss: 1.4049535073023856
Validation loss: 2.504042262567481

Epoch: 531| Step: 0
Training loss: 2.2061230976901234
Validation loss: 2.5263863500375754

Epoch: 6| Step: 1
Training loss: 2.0676101033461864
Validation loss: 2.564400362179054

Epoch: 6| Step: 2
Training loss: 1.5781570280243151
Validation loss: 2.5043529125991633

Epoch: 6| Step: 3
Training loss: 1.8018757107005867
Validation loss: 2.5546217023671343

Epoch: 6| Step: 4
Training loss: 1.6345105992040927
Validation loss: 2.4258519742079856

Epoch: 6| Step: 5
Training loss: 1.5110188916916938
Validation loss: 2.526055951464475

Epoch: 6| Step: 6
Training loss: 1.6849563642788872
Validation loss: 2.553534175758465

Epoch: 6| Step: 7
Training loss: 1.4213021769881158
Validation loss: 2.564955097766473

Epoch: 6| Step: 8
Training loss: 2.440551803604894
Validation loss: 2.5661859212192275

Epoch: 6| Step: 9
Training loss: 1.7568477441498076
Validation loss: 2.601214015169133

Epoch: 6| Step: 10
Training loss: 1.4813392515696622
Validation loss: 2.5837957985108044

Epoch: 6| Step: 11
Training loss: 1.748328023283646
Validation loss: 2.634243560856922

Epoch: 6| Step: 12
Training loss: 2.0377459605783828
Validation loss: 2.659012708846196

Epoch: 6| Step: 13
Training loss: 1.4863906025130593
Validation loss: 2.587427303780559

Epoch: 532| Step: 0
Training loss: 1.7028539599409924
Validation loss: 2.586873791772325

Epoch: 6| Step: 1
Training loss: 1.5939096856994068
Validation loss: 2.6182318949443406

Epoch: 6| Step: 2
Training loss: 1.955948276834439
Validation loss: 2.611567180077924

Epoch: 6| Step: 3
Training loss: 1.5484547880653063
Validation loss: 2.528156776177315

Epoch: 6| Step: 4
Training loss: 1.9713152567065098
Validation loss: 2.5390151819153752

Epoch: 6| Step: 5
Training loss: 2.5603927693960236
Validation loss: 2.561096842701023

Epoch: 6| Step: 6
Training loss: 1.1488120577615069
Validation loss: 2.5306115063621815

Epoch: 6| Step: 7
Training loss: 2.12886996457036
Validation loss: 2.5309031988406696

Epoch: 6| Step: 8
Training loss: 1.7306911075925426
Validation loss: 2.52322664874965

Epoch: 6| Step: 9
Training loss: 1.4405569660398738
Validation loss: 2.5351293454244512

Epoch: 6| Step: 10
Training loss: 1.6877278068212311
Validation loss: 2.5493628427915684

Epoch: 6| Step: 11
Training loss: 1.4857006377599369
Validation loss: 2.5227733507507213

Epoch: 6| Step: 12
Training loss: 1.7968224559233312
Validation loss: 2.6009779402742286

Epoch: 6| Step: 13
Training loss: 2.174113485383562
Validation loss: 2.5191824722891916

Epoch: 533| Step: 0
Training loss: 1.8953956755574803
Validation loss: 2.503522931795715

Epoch: 6| Step: 1
Training loss: 1.8047487983366706
Validation loss: 2.506348508802957

Epoch: 6| Step: 2
Training loss: 1.623618198651603
Validation loss: 2.569945235497433

Epoch: 6| Step: 3
Training loss: 2.7478747391894323
Validation loss: 2.499388757450831

Epoch: 6| Step: 4
Training loss: 1.3988574372485152
Validation loss: 2.559793923778162

Epoch: 6| Step: 5
Training loss: 1.8821844422608325
Validation loss: 2.5278613561892773

Epoch: 6| Step: 6
Training loss: 1.6009751149899671
Validation loss: 2.5155009027198996

Epoch: 6| Step: 7
Training loss: 1.2763322564199637
Validation loss: 2.5270280391194673

Epoch: 6| Step: 8
Training loss: 1.4742185365224905
Validation loss: 2.53135617528615

Epoch: 6| Step: 9
Training loss: 1.4989001692496766
Validation loss: 2.4888939246400428

Epoch: 6| Step: 10
Training loss: 1.0375535376649816
Validation loss: 2.447148698522486

Epoch: 6| Step: 11
Training loss: 1.4698475734027954
Validation loss: 2.523828685748177

Epoch: 6| Step: 12
Training loss: 2.018742715450407
Validation loss: 2.4795839912033935

Epoch: 6| Step: 13
Training loss: 2.1861475442093314
Validation loss: 2.5347328314674114

Epoch: 534| Step: 0
Training loss: 2.21709380324865
Validation loss: 2.5329591547895154

Epoch: 6| Step: 1
Training loss: 1.6730193740397854
Validation loss: 2.516116054155416

Epoch: 6| Step: 2
Training loss: 1.3674115678553187
Validation loss: 2.470570214252986

Epoch: 6| Step: 3
Training loss: 1.592492224346443
Validation loss: 2.5746517886191196

Epoch: 6| Step: 4
Training loss: 1.7153653196714806
Validation loss: 2.5387636716565845

Epoch: 6| Step: 5
Training loss: 1.946243798571282
Validation loss: 2.5737703305542396

Epoch: 6| Step: 6
Training loss: 1.531214421695848
Validation loss: 2.5652657841414577

Epoch: 6| Step: 7
Training loss: 1.7654135923499152
Validation loss: 2.561392529046146

Epoch: 6| Step: 8
Training loss: 2.3553814974640925
Validation loss: 2.6213162176793565

Epoch: 6| Step: 9
Training loss: 1.6842548108082438
Validation loss: 2.5763069282935356

Epoch: 6| Step: 10
Training loss: 2.0619500322845914
Validation loss: 2.467777684305538

Epoch: 6| Step: 11
Training loss: 1.3979278147101806
Validation loss: 2.5694984902245794

Epoch: 6| Step: 12
Training loss: 1.5736973658721767
Validation loss: 2.55596631311229

Epoch: 6| Step: 13
Training loss: 1.7091462674435547
Validation loss: 2.488570228363684

Epoch: 535| Step: 0
Training loss: 1.9648699597531218
Validation loss: 2.5159147627272613

Epoch: 6| Step: 1
Training loss: 1.8182378250945987
Validation loss: 2.523172776424397

Epoch: 6| Step: 2
Training loss: 0.9568385338889172
Validation loss: 2.5272117872303927

Epoch: 6| Step: 3
Training loss: 1.7737437248522225
Validation loss: 2.505642862945751

Epoch: 6| Step: 4
Training loss: 1.5198402384822043
Validation loss: 2.574410317395667

Epoch: 6| Step: 5
Training loss: 1.8862489229860258
Validation loss: 2.5556147245138443

Epoch: 6| Step: 6
Training loss: 1.7267453196125104
Validation loss: 2.6205359823168557

Epoch: 6| Step: 7
Training loss: 0.8767706462407752
Validation loss: 2.5155707513779815

Epoch: 6| Step: 8
Training loss: 1.491806860503534
Validation loss: 2.5656613093978864

Epoch: 6| Step: 9
Training loss: 1.662967088521629
Validation loss: 2.5214194861528187

Epoch: 6| Step: 10
Training loss: 2.807968218544758
Validation loss: 2.61759054392309

Epoch: 6| Step: 11
Training loss: 1.8322877358688456
Validation loss: 2.5325371586355927

Epoch: 6| Step: 12
Training loss: 1.5228951295650912
Validation loss: 2.5612942539831804

Epoch: 6| Step: 13
Training loss: 1.9149114477734266
Validation loss: 2.511676092698938

Epoch: 536| Step: 0
Training loss: 1.8313659891624574
Validation loss: 2.486455210404232

Epoch: 6| Step: 1
Training loss: 1.6754800307934579
Validation loss: 2.541353591392511

Epoch: 6| Step: 2
Training loss: 2.1937403360789745
Validation loss: 2.610220272316719

Epoch: 6| Step: 3
Training loss: 1.9319511449414113
Validation loss: 2.56255382538337

Epoch: 6| Step: 4
Training loss: 1.4772669812070696
Validation loss: 2.5344889407360225

Epoch: 6| Step: 5
Training loss: 1.7731320290330363
Validation loss: 2.57888632552609

Epoch: 6| Step: 6
Training loss: 1.135280787652171
Validation loss: 2.5675704137920285

Epoch: 6| Step: 7
Training loss: 1.4547993028005042
Validation loss: 2.5185063306063302

Epoch: 6| Step: 8
Training loss: 1.961525148890272
Validation loss: 2.609302763651016

Epoch: 6| Step: 9
Training loss: 1.4610607074864115
Validation loss: 2.6020589168442805

Epoch: 6| Step: 10
Training loss: 2.680061425458786
Validation loss: 2.6195057876255805

Epoch: 6| Step: 11
Training loss: 1.3901996604999143
Validation loss: 2.565520916212281

Epoch: 6| Step: 12
Training loss: 1.8341135257831822
Validation loss: 2.5248386764040562

Epoch: 6| Step: 13
Training loss: 1.9673774415443415
Validation loss: 2.4628331995609716

Epoch: 537| Step: 0
Training loss: 1.4375155904173251
Validation loss: 2.595678207512553

Epoch: 6| Step: 1
Training loss: 1.5036218944089053
Validation loss: 2.656144487383337

Epoch: 6| Step: 2
Training loss: 1.8466922108000141
Validation loss: 2.539520472770055

Epoch: 6| Step: 3
Training loss: 1.1496708792884591
Validation loss: 2.552818595909853

Epoch: 6| Step: 4
Training loss: 2.042649895199946
Validation loss: 2.630064373692242

Epoch: 6| Step: 5
Training loss: 2.4954636424707846
Validation loss: 2.5793111956632306

Epoch: 6| Step: 6
Training loss: 1.858365145298385
Validation loss: 2.535524871216208

Epoch: 6| Step: 7
Training loss: 0.7912358860366119
Validation loss: 2.4997559889796874

Epoch: 6| Step: 8
Training loss: 1.9481012661479162
Validation loss: 2.511592116133389

Epoch: 6| Step: 9
Training loss: 1.7072752335203434
Validation loss: 2.5460328139579342

Epoch: 6| Step: 10
Training loss: 1.7562524951632006
Validation loss: 2.482916596550582

Epoch: 6| Step: 11
Training loss: 2.0298932753070944
Validation loss: 2.5127789456144884

Epoch: 6| Step: 12
Training loss: 1.932831030026721
Validation loss: 2.6350272920231137

Epoch: 6| Step: 13
Training loss: 1.500990381717045
Validation loss: 2.506682293478724

Epoch: 538| Step: 0
Training loss: 2.3091385613223263
Validation loss: 2.5584305314857128

Epoch: 6| Step: 1
Training loss: 1.263778988574579
Validation loss: 2.611120726036703

Epoch: 6| Step: 2
Training loss: 1.4720079527982164
Validation loss: 2.4966092351946965

Epoch: 6| Step: 3
Training loss: 1.4507044659387063
Validation loss: 2.542979010716632

Epoch: 6| Step: 4
Training loss: 1.81682255393995
Validation loss: 2.627659239330516

Epoch: 6| Step: 5
Training loss: 1.7155180628511335
Validation loss: 2.5858701657449092

Epoch: 6| Step: 6
Training loss: 1.5898381263577213
Validation loss: 2.579256375173895

Epoch: 6| Step: 7
Training loss: 1.7456594861615986
Validation loss: 2.581800919955984

Epoch: 6| Step: 8
Training loss: 1.698816501755729
Validation loss: 2.4797345585848602

Epoch: 6| Step: 9
Training loss: 1.70128609309985
Validation loss: 2.461736551632306

Epoch: 6| Step: 10
Training loss: 1.5717888719385402
Validation loss: 2.421440849331669

Epoch: 6| Step: 11
Training loss: 1.8320419213608445
Validation loss: 2.5681409133011894

Epoch: 6| Step: 12
Training loss: 1.776351081393449
Validation loss: 2.5995945548883097

Epoch: 6| Step: 13
Training loss: 1.3489838625972705
Validation loss: 2.43116078339479

Epoch: 539| Step: 0
Training loss: 1.7537919242997482
Validation loss: 2.586901480690217

Epoch: 6| Step: 1
Training loss: 2.24620297373698
Validation loss: 2.4886767746151803

Epoch: 6| Step: 2
Training loss: 1.7801950241790754
Validation loss: 2.5690214907803317

Epoch: 6| Step: 3
Training loss: 1.6416720727486196
Validation loss: 2.65529149789934

Epoch: 6| Step: 4
Training loss: 1.6931797095070928
Validation loss: 2.4481474293525074

Epoch: 6| Step: 5
Training loss: 1.7541062001055636
Validation loss: 2.557810999548461

Epoch: 6| Step: 6
Training loss: 1.7206595477021336
Validation loss: 2.5162015149977695

Epoch: 6| Step: 7
Training loss: 1.7401270292763653
Validation loss: 2.5485986272077645

Epoch: 6| Step: 8
Training loss: 1.4213833640139903
Validation loss: 2.5755567161306425

Epoch: 6| Step: 9
Training loss: 1.5898462993779467
Validation loss: 2.5021808617930734

Epoch: 6| Step: 10
Training loss: 1.6864813096395916
Validation loss: 2.5648427059297685

Epoch: 6| Step: 11
Training loss: 1.3654500329825408
Validation loss: 2.560508116934407

Epoch: 6| Step: 12
Training loss: 2.0592970976617213
Validation loss: 2.4930744966984517

Epoch: 6| Step: 13
Training loss: 1.3296140513771306
Validation loss: 2.467996540724711

Epoch: 540| Step: 0
Training loss: 1.30512586527433
Validation loss: 2.498156482083021

Epoch: 6| Step: 1
Training loss: 2.1708099168721406
Validation loss: 2.560858746391554

Epoch: 6| Step: 2
Training loss: 1.2446592678169581
Validation loss: 2.5426983957463243

Epoch: 6| Step: 3
Training loss: 2.4303536927699327
Validation loss: 2.5408293603840413

Epoch: 6| Step: 4
Training loss: 1.8058844226087796
Validation loss: 2.560485093698879

Epoch: 6| Step: 5
Training loss: 1.774304014413873
Validation loss: 2.541635149661663

Epoch: 6| Step: 6
Training loss: 1.524938460187095
Validation loss: 2.62462303181596

Epoch: 6| Step: 7
Training loss: 1.4769718470644164
Validation loss: 2.4462344007562553

Epoch: 6| Step: 8
Training loss: 1.8950348174990588
Validation loss: 2.471216618834582

Epoch: 6| Step: 9
Training loss: 1.3875221611521358
Validation loss: 2.547497720823734

Epoch: 6| Step: 10
Training loss: 1.5001486863512894
Validation loss: 2.5467053197136007

Epoch: 6| Step: 11
Training loss: 1.562152366113374
Validation loss: 2.615796491672284

Epoch: 6| Step: 12
Training loss: 1.7940488400227468
Validation loss: 2.4596630525194625

Epoch: 6| Step: 13
Training loss: 2.038810392849998
Validation loss: 2.4672098564712326

Epoch: 541| Step: 0
Training loss: 1.464993481930759
Validation loss: 2.504604370579222

Epoch: 6| Step: 1
Training loss: 1.9498591469976732
Validation loss: 2.4953611086546776

Epoch: 6| Step: 2
Training loss: 1.4045430738227467
Validation loss: 2.46508115505919

Epoch: 6| Step: 3
Training loss: 1.4841865821514584
Validation loss: 2.6943446084378713

Epoch: 6| Step: 4
Training loss: 1.5867300073552069
Validation loss: 2.5084474076987435

Epoch: 6| Step: 5
Training loss: 1.8629402152444268
Validation loss: 2.5270935787854896

Epoch: 6| Step: 6
Training loss: 2.487603159543362
Validation loss: 2.511864723267601

Epoch: 6| Step: 7
Training loss: 1.7055671750866075
Validation loss: 2.5722622603177676

Epoch: 6| Step: 8
Training loss: 1.703470737466823
Validation loss: 2.5416931185933658

Epoch: 6| Step: 9
Training loss: 1.6360709790825676
Validation loss: 2.5568513893273797

Epoch: 6| Step: 10
Training loss: 1.6904573311575644
Validation loss: 2.5754995293034084

Epoch: 6| Step: 11
Training loss: 1.8250240533367137
Validation loss: 2.60015665801869

Epoch: 6| Step: 12
Training loss: 1.1232456727919866
Validation loss: 2.591189218818418

Epoch: 6| Step: 13
Training loss: 2.3802966234344507
Validation loss: 2.5317752444596224

Epoch: 542| Step: 0
Training loss: 1.3861135962257372
Validation loss: 2.5468173775142655

Epoch: 6| Step: 1
Training loss: 1.488779059830322
Validation loss: 2.455987430087806

Epoch: 6| Step: 2
Training loss: 2.479339102082988
Validation loss: 2.5642665573398316

Epoch: 6| Step: 3
Training loss: 2.0805670365120204
Validation loss: 2.578167943015732

Epoch: 6| Step: 4
Training loss: 1.7046574688721605
Validation loss: 2.501011796496259

Epoch: 6| Step: 5
Training loss: 1.1948665210763447
Validation loss: 2.5544982942448753

Epoch: 6| Step: 6
Training loss: 1.9601284348972454
Validation loss: 2.5679444112148775

Epoch: 6| Step: 7
Training loss: 1.934266745846005
Validation loss: 2.5205024268822287

Epoch: 6| Step: 8
Training loss: 1.2578938143965568
Validation loss: 2.486776774814463

Epoch: 6| Step: 9
Training loss: 2.074610671321498
Validation loss: 2.6136237835276335

Epoch: 6| Step: 10
Training loss: 1.8104466613227999
Validation loss: 2.5555280737746444

Epoch: 6| Step: 11
Training loss: 1.7691219437502097
Validation loss: 2.59143290066041

Epoch: 6| Step: 12
Training loss: 1.2447627022963357
Validation loss: 2.589362660106352

Epoch: 6| Step: 13
Training loss: 2.1870401171513842
Validation loss: 2.4997573073320316

Epoch: 543| Step: 0
Training loss: 2.183201080665307
Validation loss: 2.6471571258648536

Epoch: 6| Step: 1
Training loss: 1.4338476803271814
Validation loss: 2.5046281142453433

Epoch: 6| Step: 2
Training loss: 1.5143960906105747
Validation loss: 2.5576853527526655

Epoch: 6| Step: 3
Training loss: 1.421500942786753
Validation loss: 2.6041138464380307

Epoch: 6| Step: 4
Training loss: 1.8172664451343077
Validation loss: 2.643151052862369

Epoch: 6| Step: 5
Training loss: 1.729121318666787
Validation loss: 2.627308261828974

Epoch: 6| Step: 6
Training loss: 1.904921897628791
Validation loss: 2.5730326955465403

Epoch: 6| Step: 7
Training loss: 1.740843660875763
Validation loss: 2.554292336494386

Epoch: 6| Step: 8
Training loss: 1.9528690628208607
Validation loss: 2.4943227401528762

Epoch: 6| Step: 9
Training loss: 1.8189006782330395
Validation loss: 2.616513573744266

Epoch: 6| Step: 10
Training loss: 1.523225740240494
Validation loss: 2.5270336000315203

Epoch: 6| Step: 11
Training loss: 1.6599050533763566
Validation loss: 2.571905525211874

Epoch: 6| Step: 12
Training loss: 1.4069284286081178
Validation loss: 2.5977752966676126

Epoch: 6| Step: 13
Training loss: 1.8276678964746513
Validation loss: 2.5583983639095194

Epoch: 544| Step: 0
Training loss: 1.1759731605023143
Validation loss: 2.4511447592699995

Epoch: 6| Step: 1
Training loss: 1.7209831295749225
Validation loss: 2.5949591565834504

Epoch: 6| Step: 2
Training loss: 1.8276031270916093
Validation loss: 2.7243588641182486

Epoch: 6| Step: 3
Training loss: 1.4933689094177227
Validation loss: 2.5195217607120264

Epoch: 6| Step: 4
Training loss: 2.6513869704602655
Validation loss: 2.5782111552818563

Epoch: 6| Step: 5
Training loss: 1.8872907888916661
Validation loss: 2.515905793740939

Epoch: 6| Step: 6
Training loss: 1.6860467516524964
Validation loss: 2.4969023556450347

Epoch: 6| Step: 7
Training loss: 1.7976914914227469
Validation loss: 2.4878270276887955

Epoch: 6| Step: 8
Training loss: 1.8080194274061132
Validation loss: 2.513236723895934

Epoch: 6| Step: 9
Training loss: 1.7142337070251026
Validation loss: 2.608827581293868

Epoch: 6| Step: 10
Training loss: 1.7916981302500168
Validation loss: 2.557035247142015

Epoch: 6| Step: 11
Training loss: 1.8179256524263125
Validation loss: 2.554282856909615

Epoch: 6| Step: 12
Training loss: 1.079881205206572
Validation loss: 2.426339696554425

Epoch: 6| Step: 13
Training loss: 2.3847645252672014
Validation loss: 2.572776636846142

Epoch: 545| Step: 0
Training loss: 1.336803445635475
Validation loss: 2.4677428422082097

Epoch: 6| Step: 1
Training loss: 1.7908267188833906
Validation loss: 2.462574236541873

Epoch: 6| Step: 2
Training loss: 2.375877118018846
Validation loss: 2.425911579115576

Epoch: 6| Step: 3
Training loss: 1.7983135270143722
Validation loss: 2.5232627201358473

Epoch: 6| Step: 4
Training loss: 1.2868218107935807
Validation loss: 2.480938674639233

Epoch: 6| Step: 5
Training loss: 1.1196619121279838
Validation loss: 2.6242399067447133

Epoch: 6| Step: 6
Training loss: 2.373454142971088
Validation loss: 2.5049405726944904

Epoch: 6| Step: 7
Training loss: 1.9914987607698753
Validation loss: 2.576854586955248

Epoch: 6| Step: 8
Training loss: 1.39122416414879
Validation loss: 2.551910098844834

Epoch: 6| Step: 9
Training loss: 0.8605171589822381
Validation loss: 2.4690040861576814

Epoch: 6| Step: 10
Training loss: 1.7768546636694384
Validation loss: 2.6802595820558355

Epoch: 6| Step: 11
Training loss: 2.189338783184583
Validation loss: 2.601589605408303

Epoch: 6| Step: 12
Training loss: 1.2693333867744894
Validation loss: 2.49928089895156

Epoch: 6| Step: 13
Training loss: 1.5918109542130425
Validation loss: 2.526283044745428

Epoch: 546| Step: 0
Training loss: 2.1961004940378595
Validation loss: 2.513100670327324

Epoch: 6| Step: 1
Training loss: 1.7284578302926148
Validation loss: 2.5769598581870214

Epoch: 6| Step: 2
Training loss: 1.9113468134169314
Validation loss: 2.5396803701877544

Epoch: 6| Step: 3
Training loss: 1.82561901515984
Validation loss: 2.599339227033096

Epoch: 6| Step: 4
Training loss: 1.2695055680244882
Validation loss: 2.553636638141108

Epoch: 6| Step: 5
Training loss: 1.4242723815830691
Validation loss: 2.41979275735988

Epoch: 6| Step: 6
Training loss: 1.4316203908284029
Validation loss: 2.617757832011702

Epoch: 6| Step: 7
Training loss: 1.5901792579943752
Validation loss: 2.4817382860637895

Epoch: 6| Step: 8
Training loss: 1.2259735345613147
Validation loss: 2.595978612776066

Epoch: 6| Step: 9
Training loss: 1.5988118439047425
Validation loss: 2.5125191007184093

Epoch: 6| Step: 10
Training loss: 2.1305246903251804
Validation loss: 2.5874862442257314

Epoch: 6| Step: 11
Training loss: 2.05106245746863
Validation loss: 2.6480630720124863

Epoch: 6| Step: 12
Training loss: 1.8572013395134956
Validation loss: 2.56336650409383

Epoch: 6| Step: 13
Training loss: 1.8029372410062765
Validation loss: 2.501637319489818

Epoch: 547| Step: 0
Training loss: 1.900735853149318
Validation loss: 2.4065041963796996

Epoch: 6| Step: 1
Training loss: 1.3309397322453957
Validation loss: 2.610187111610126

Epoch: 6| Step: 2
Training loss: 1.693875877516956
Validation loss: 2.627116823034589

Epoch: 6| Step: 3
Training loss: 1.6176931723993477
Validation loss: 2.4646407612379897

Epoch: 6| Step: 4
Training loss: 1.5356348276968859
Validation loss: 2.5154781513973714

Epoch: 6| Step: 5
Training loss: 2.2799095500605984
Validation loss: 2.5161120132420773

Epoch: 6| Step: 6
Training loss: 1.2386244048685864
Validation loss: 2.5777944502693857

Epoch: 6| Step: 7
Training loss: 1.2497090000936864
Validation loss: 2.610759709352609

Epoch: 6| Step: 8
Training loss: 1.6980901368191417
Validation loss: 2.614747336476298

Epoch: 6| Step: 9
Training loss: 1.2048551331493014
Validation loss: 2.5534687971874837

Epoch: 6| Step: 10
Training loss: 2.5895541160042117
Validation loss: 2.4811194148713342

Epoch: 6| Step: 11
Training loss: 1.7258166605268224
Validation loss: 2.597769602478936

Epoch: 6| Step: 12
Training loss: 1.598192567974593
Validation loss: 2.63429692903631

Epoch: 6| Step: 13
Training loss: 1.8101178003408618
Validation loss: 2.5156785687548187

Epoch: 548| Step: 0
Training loss: 1.8296391663979894
Validation loss: 2.4894979631084246

Epoch: 6| Step: 1
Training loss: 1.7894763717690236
Validation loss: 2.56251183523851

Epoch: 6| Step: 2
Training loss: 1.3516558135349914
Validation loss: 2.4780806467605623

Epoch: 6| Step: 3
Training loss: 1.8356837969862076
Validation loss: 2.600698467333144

Epoch: 6| Step: 4
Training loss: 1.5073469164603417
Validation loss: 2.5741369482260503

Epoch: 6| Step: 5
Training loss: 2.5429986579882478
Validation loss: 2.5182767015767302

Epoch: 6| Step: 6
Training loss: 1.6203617511499844
Validation loss: 2.5317446034162527

Epoch: 6| Step: 7
Training loss: 1.5236495432859931
Validation loss: 2.557991924581885

Epoch: 6| Step: 8
Training loss: 2.275534485292654
Validation loss: 2.5828197066558003

Epoch: 6| Step: 9
Training loss: 1.5825869490855835
Validation loss: 2.494657168908703

Epoch: 6| Step: 10
Training loss: 1.5044933411693941
Validation loss: 2.558767089382711

Epoch: 6| Step: 11
Training loss: 1.3414157287227213
Validation loss: 2.5354335642150185

Epoch: 6| Step: 12
Training loss: 1.5765669279159202
Validation loss: 2.5587628182596394

Epoch: 6| Step: 13
Training loss: 2.7262571322327256
Validation loss: 2.604720828908807

Epoch: 549| Step: 0
Training loss: 2.777553030034847
Validation loss: 2.5591529699099484

Epoch: 6| Step: 1
Training loss: 1.7201110306100427
Validation loss: 2.5145986169247845

Epoch: 6| Step: 2
Training loss: 1.962025921653274
Validation loss: 2.535673915470452

Epoch: 6| Step: 3
Training loss: 1.181274256381503
Validation loss: 2.667219239007447

Epoch: 6| Step: 4
Training loss: 1.533158650330265
Validation loss: 2.5398574803748537

Epoch: 6| Step: 5
Training loss: 1.4882886190557394
Validation loss: 2.550998201060537

Epoch: 6| Step: 6
Training loss: 1.5569284668343737
Validation loss: 2.468049798093058

Epoch: 6| Step: 7
Training loss: 1.8894028299485923
Validation loss: 2.6231472979709745

Epoch: 6| Step: 8
Training loss: 1.2911953476365852
Validation loss: 2.602942179267099

Epoch: 6| Step: 9
Training loss: 1.6489297574768833
Validation loss: 2.5210810835935415

Epoch: 6| Step: 10
Training loss: 2.1904607082692524
Validation loss: 2.613432330134092

Epoch: 6| Step: 11
Training loss: 1.3991302820094227
Validation loss: 2.493328398976629

Epoch: 6| Step: 12
Training loss: 1.4537208730021636
Validation loss: 2.5964680699975102

Epoch: 6| Step: 13
Training loss: 1.096143501441421
Validation loss: 2.4808578954646228

Epoch: 550| Step: 0
Training loss: 1.949709476934667
Validation loss: 2.554717386198924

Epoch: 6| Step: 1
Training loss: 1.717857267710016
Validation loss: 2.5616227766151467

Epoch: 6| Step: 2
Training loss: 2.4948880383401053
Validation loss: 2.451104375353279

Epoch: 6| Step: 3
Training loss: 1.9060638837165438
Validation loss: 2.519087398779745

Epoch: 6| Step: 4
Training loss: 1.7769336940049323
Validation loss: 2.610916074629294

Epoch: 6| Step: 5
Training loss: 1.742534791005267
Validation loss: 2.511874230765725

Epoch: 6| Step: 6
Training loss: 1.087967984583984
Validation loss: 2.6011836382018454

Epoch: 6| Step: 7
Training loss: 1.784336294098456
Validation loss: 2.5952964172795476

Epoch: 6| Step: 8
Training loss: 1.5747501053944075
Validation loss: 2.5131538394595765

Epoch: 6| Step: 9
Training loss: 1.4858158547141274
Validation loss: 2.6565221522817875

Epoch: 6| Step: 10
Training loss: 0.7031384996601743
Validation loss: 2.6471495516026766

Epoch: 6| Step: 11
Training loss: 2.245931868317203
Validation loss: 2.5627984804265087

Epoch: 6| Step: 12
Training loss: 1.670516130330119
Validation loss: 2.5946817514732516

Epoch: 6| Step: 13
Training loss: 1.8050297664396435
Validation loss: 2.520018201117049

Epoch: 551| Step: 0
Training loss: 1.5850468281467942
Validation loss: 2.541152055415106

Epoch: 6| Step: 1
Training loss: 1.404646064732746
Validation loss: 2.5085502477029005

Epoch: 6| Step: 2
Training loss: 1.687203981785713
Validation loss: 2.602635796912107

Epoch: 6| Step: 3
Training loss: 1.2642009871435693
Validation loss: 2.515191417564533

Epoch: 6| Step: 4
Training loss: 1.5157288191327016
Validation loss: 2.5099134313964537

Epoch: 6| Step: 5
Training loss: 2.048707331177589
Validation loss: 2.543058291452702

Epoch: 6| Step: 6
Training loss: 1.7102354516675127
Validation loss: 2.573108237680153

Epoch: 6| Step: 7
Training loss: 2.164708671086313
Validation loss: 2.5631959861893523

Epoch: 6| Step: 8
Training loss: 1.5147408334870545
Validation loss: 2.5577149097425393

Epoch: 6| Step: 9
Training loss: 1.6714764414093313
Validation loss: 2.5575734323208335

Epoch: 6| Step: 10
Training loss: 2.4794491091423234
Validation loss: 2.5126307716145786

Epoch: 6| Step: 11
Training loss: 1.943962885247234
Validation loss: 2.610865147261964

Epoch: 6| Step: 12
Training loss: 1.4312466317349575
Validation loss: 2.6000592713269484

Epoch: 6| Step: 13
Training loss: 1.7466530128241389
Validation loss: 2.5649650816279808

Epoch: 552| Step: 0
Training loss: 1.777242066545282
Validation loss: 2.561473653902541

Epoch: 6| Step: 1
Training loss: 1.3110981221058513
Validation loss: 2.4319330637828838

Epoch: 6| Step: 2
Training loss: 1.6325584834607167
Validation loss: 2.5755302649421856

Epoch: 6| Step: 3
Training loss: 1.2380987568384338
Validation loss: 2.5380030943705587

Epoch: 6| Step: 4
Training loss: 1.6513758500659843
Validation loss: 2.541090657085958

Epoch: 6| Step: 5
Training loss: 1.3442800496655118
Validation loss: 2.4881158918900494

Epoch: 6| Step: 6
Training loss: 1.5120246833925948
Validation loss: 2.5169744574598147

Epoch: 6| Step: 7
Training loss: 2.010778944616073
Validation loss: 2.5223535350471917

Epoch: 6| Step: 8
Training loss: 2.3786843482944096
Validation loss: 2.6442608768336178

Epoch: 6| Step: 9
Training loss: 1.4545391134102188
Validation loss: 2.4919205507605637

Epoch: 6| Step: 10
Training loss: 2.0076797382086067
Validation loss: 2.56618951065298

Epoch: 6| Step: 11
Training loss: 1.7841173483695785
Validation loss: 2.574002692394208

Epoch: 6| Step: 12
Training loss: 1.5818424065049381
Validation loss: 2.5111669366345692

Epoch: 6| Step: 13
Training loss: 1.9445640012527903
Validation loss: 2.5361535458850497

Epoch: 553| Step: 0
Training loss: 2.4426804292192568
Validation loss: 2.5035909622151804

Epoch: 6| Step: 1
Training loss: 1.650185909779476
Validation loss: 2.5413038686449454

Epoch: 6| Step: 2
Training loss: 1.4012271611771088
Validation loss: 2.573782510897201

Epoch: 6| Step: 3
Training loss: 1.3464056431898557
Validation loss: 2.540531920509096

Epoch: 6| Step: 4
Training loss: 1.6443689406662831
Validation loss: 2.46848718883221

Epoch: 6| Step: 5
Training loss: 1.5443943053659508
Validation loss: 2.6444400723104278

Epoch: 6| Step: 6
Training loss: 1.6017374082748828
Validation loss: 2.5195767484313465

Epoch: 6| Step: 7
Training loss: 1.3844754839180318
Validation loss: 2.5121143302395534

Epoch: 6| Step: 8
Training loss: 1.794361977737566
Validation loss: 2.5296766596462565

Epoch: 6| Step: 9
Training loss: 1.4381250598149824
Validation loss: 2.5285677212124646

Epoch: 6| Step: 10
Training loss: 1.6826689054098416
Validation loss: 2.5444908092757412

Epoch: 6| Step: 11
Training loss: 1.9596700029499956
Validation loss: 2.507757866673592

Epoch: 6| Step: 12
Training loss: 1.6544322709452017
Validation loss: 2.557554614216171

Epoch: 6| Step: 13
Training loss: 2.0799254455409666
Validation loss: 2.6098800081088287

Epoch: 554| Step: 0
Training loss: 2.0244864907674858
Validation loss: 2.505293000563669

Epoch: 6| Step: 1
Training loss: 0.9998161027617708
Validation loss: 2.504691177115824

Epoch: 6| Step: 2
Training loss: 2.585342384847161
Validation loss: 2.5153799812188193

Epoch: 6| Step: 3
Training loss: 1.7751660766275856
Validation loss: 2.4827506622327085

Epoch: 6| Step: 4
Training loss: 1.9071929975565107
Validation loss: 2.554741024367183

Epoch: 6| Step: 5
Training loss: 1.5464085347618453
Validation loss: 2.547687926468145

Epoch: 6| Step: 6
Training loss: 1.9019741192730573
Validation loss: 2.527065576433253

Epoch: 6| Step: 7
Training loss: 1.6979739485675385
Validation loss: 2.5021218544948143

Epoch: 6| Step: 8
Training loss: 2.0030915684521275
Validation loss: 2.517543593315384

Epoch: 6| Step: 9
Training loss: 1.7799898341242208
Validation loss: 2.677677729364189

Epoch: 6| Step: 10
Training loss: 1.3161524859150706
Validation loss: 2.504109096419867

Epoch: 6| Step: 11
Training loss: 1.225281356108297
Validation loss: 2.535543744128303

Epoch: 6| Step: 12
Training loss: 1.6182530527732857
Validation loss: 2.543550843620588

Epoch: 6| Step: 13
Training loss: 1.0306483160727742
Validation loss: 2.585902761893903

Epoch: 555| Step: 0
Training loss: 1.4290372276448906
Validation loss: 2.5248468988414956

Epoch: 6| Step: 1
Training loss: 1.131336276310375
Validation loss: 2.6099463712835345

Epoch: 6| Step: 2
Training loss: 1.7280941896641022
Validation loss: 2.547515128377758

Epoch: 6| Step: 3
Training loss: 1.546209018568176
Validation loss: 2.52649322793682

Epoch: 6| Step: 4
Training loss: 1.9357127898979138
Validation loss: 2.4478809505065953

Epoch: 6| Step: 5
Training loss: 1.9621037514461892
Validation loss: 2.6045318344206985

Epoch: 6| Step: 6
Training loss: 1.3500277675316106
Validation loss: 2.5126430299955667

Epoch: 6| Step: 7
Training loss: 1.393790809820768
Validation loss: 2.559179626433739

Epoch: 6| Step: 8
Training loss: 1.9749683087860495
Validation loss: 2.4528941603730936

Epoch: 6| Step: 9
Training loss: 1.6224366290584877
Validation loss: 2.5875628208077996

Epoch: 6| Step: 10
Training loss: 1.6997254065726066
Validation loss: 2.573058875500942

Epoch: 6| Step: 11
Training loss: 1.8620500955654726
Validation loss: 2.56277567183243

Epoch: 6| Step: 12
Training loss: 2.2598757704627936
Validation loss: 2.5326702529530754

Epoch: 6| Step: 13
Training loss: 1.433931482431212
Validation loss: 2.519366739188059

Epoch: 556| Step: 0
Training loss: 2.1192223036534523
Validation loss: 2.569617747450955

Epoch: 6| Step: 1
Training loss: 1.6726515918223175
Validation loss: 2.420383613680513

Epoch: 6| Step: 2
Training loss: 2.183743766858748
Validation loss: 2.5557314111656058

Epoch: 6| Step: 3
Training loss: 2.1475386525273814
Validation loss: 2.518024343651729

Epoch: 6| Step: 4
Training loss: 1.746759821006865
Validation loss: 2.497753451625914

Epoch: 6| Step: 5
Training loss: 1.483022374694942
Validation loss: 2.5546843399620878

Epoch: 6| Step: 6
Training loss: 1.602945168207657
Validation loss: 2.512481730241694

Epoch: 6| Step: 7
Training loss: 1.3351566642818622
Validation loss: 2.4709000991720678

Epoch: 6| Step: 8
Training loss: 1.1250212985247876
Validation loss: 2.4792102042270554

Epoch: 6| Step: 9
Training loss: 1.3666826896581081
Validation loss: 2.5044334447512844

Epoch: 6| Step: 10
Training loss: 2.1981452232473977
Validation loss: 2.608190023660587

Epoch: 6| Step: 11
Training loss: 1.6184845666252659
Validation loss: 2.46298347946007

Epoch: 6| Step: 12
Training loss: 1.308278697790547
Validation loss: 2.5432239611891867

Epoch: 6| Step: 13
Training loss: 1.7133366037899127
Validation loss: 2.4914020775928307

Epoch: 557| Step: 0
Training loss: 1.495784398857332
Validation loss: 2.6588487858381518

Epoch: 6| Step: 1
Training loss: 1.5197651739428177
Validation loss: 2.48565308627343

Epoch: 6| Step: 2
Training loss: 2.1453485651172937
Validation loss: 2.5216404060106985

Epoch: 6| Step: 3
Training loss: 1.5320978736688895
Validation loss: 2.513337956743037

Epoch: 6| Step: 4
Training loss: 2.417501031506544
Validation loss: 2.487547453705271

Epoch: 6| Step: 5
Training loss: 1.9937463981571966
Validation loss: 2.608235613030871

Epoch: 6| Step: 6
Training loss: 1.8966941835299074
Validation loss: 2.5837691161468253

Epoch: 6| Step: 7
Training loss: 1.5600580588565203
Validation loss: 2.502762664702795

Epoch: 6| Step: 8
Training loss: 1.257123011813261
Validation loss: 2.6315459841405375

Epoch: 6| Step: 9
Training loss: 1.548547784321145
Validation loss: 2.485479632328208

Epoch: 6| Step: 10
Training loss: 1.5624538414812912
Validation loss: 2.477437711557909

Epoch: 6| Step: 11
Training loss: 1.1859413760075412
Validation loss: 2.574025699298667

Epoch: 6| Step: 12
Training loss: 1.6532981767428747
Validation loss: 2.470723736114569

Epoch: 6| Step: 13
Training loss: 1.6611366877434957
Validation loss: 2.4999776059860226

Epoch: 558| Step: 0
Training loss: 1.4315927453250827
Validation loss: 2.533139021613922

Epoch: 6| Step: 1
Training loss: 1.5502962752179306
Validation loss: 2.618194968995346

Epoch: 6| Step: 2
Training loss: 2.523703829761968
Validation loss: 2.5074284222070933

Epoch: 6| Step: 3
Training loss: 1.8788141874413196
Validation loss: 2.511923037329409

Epoch: 6| Step: 4
Training loss: 2.0659795367399036
Validation loss: 2.518782931393738

Epoch: 6| Step: 5
Training loss: 1.8536182049582939
Validation loss: 2.586145236824713

Epoch: 6| Step: 6
Training loss: 1.8864854624956746
Validation loss: 2.536167082992777

Epoch: 6| Step: 7
Training loss: 1.6051766159947563
Validation loss: 2.5967537588317877

Epoch: 6| Step: 8
Training loss: 1.7240453123833495
Validation loss: 2.514758474999088

Epoch: 6| Step: 9
Training loss: 1.8782080227342253
Validation loss: 2.5056724777566934

Epoch: 6| Step: 10
Training loss: 1.473595357713418
Validation loss: 2.5237965860563967

Epoch: 6| Step: 11
Training loss: 1.3659853636542565
Validation loss: 2.4735324446838804

Epoch: 6| Step: 12
Training loss: 1.171645129228778
Validation loss: 2.559294639989687

Epoch: 6| Step: 13
Training loss: 1.7137301572267234
Validation loss: 2.4567119124087275

Epoch: 559| Step: 0
Training loss: 2.115876978148237
Validation loss: 2.53444716333605

Epoch: 6| Step: 1
Training loss: 1.7092623239373939
Validation loss: 2.6802160499439065

Epoch: 6| Step: 2
Training loss: 1.6028763011149754
Validation loss: 2.4952217779607198

Epoch: 6| Step: 3
Training loss: 1.473844903506154
Validation loss: 2.4738778975687143

Epoch: 6| Step: 4
Training loss: 1.984369653409228
Validation loss: 2.656058395395207

Epoch: 6| Step: 5
Training loss: 1.4005924435891193
Validation loss: 2.4826612845612384

Epoch: 6| Step: 6
Training loss: 1.93900056381965
Validation loss: 2.4978344408200837

Epoch: 6| Step: 7
Training loss: 2.4998240408963017
Validation loss: 2.4710324381624487

Epoch: 6| Step: 8
Training loss: 1.3357790133512975
Validation loss: 2.4987180376297844

Epoch: 6| Step: 9
Training loss: 1.3517421536860792
Validation loss: 2.528923352907702

Epoch: 6| Step: 10
Training loss: 1.369178499359123
Validation loss: 2.575611686035209

Epoch: 6| Step: 11
Training loss: 1.5334963767124254
Validation loss: 2.558863147191442

Epoch: 6| Step: 12
Training loss: 1.3739966286197263
Validation loss: 2.5698061078700496

Epoch: 6| Step: 13
Training loss: 1.9979807077379506
Validation loss: 2.494701116593886

Epoch: 560| Step: 0
Training loss: 1.9936736902443708
Validation loss: 2.484442299975891

Epoch: 6| Step: 1
Training loss: 1.898125454095881
Validation loss: 2.4283894487243205

Epoch: 6| Step: 2
Training loss: 1.5359011485706175
Validation loss: 2.5673289495585427

Epoch: 6| Step: 3
Training loss: 1.4980028685630153
Validation loss: 2.431241706960324

Epoch: 6| Step: 4
Training loss: 2.2283140554381213
Validation loss: 2.542296488080664

Epoch: 6| Step: 5
Training loss: 1.2669311188819443
Validation loss: 2.4842854764429987

Epoch: 6| Step: 6
Training loss: 1.3887855708582357
Validation loss: 2.558891619092323

Epoch: 6| Step: 7
Training loss: 1.1393799976400396
Validation loss: 2.5029320238267414

Epoch: 6| Step: 8
Training loss: 1.563004831776439
Validation loss: 2.5557251488377157

Epoch: 6| Step: 9
Training loss: 1.4242853547727254
Validation loss: 2.5790985939014477

Epoch: 6| Step: 10
Training loss: 1.6090928358106633
Validation loss: 2.5429919005698127

Epoch: 6| Step: 11
Training loss: 1.7248546041497361
Validation loss: 2.542657073857055

Epoch: 6| Step: 12
Training loss: 1.6555786931613603
Validation loss: 2.608023422343578

Epoch: 6| Step: 13
Training loss: 1.2349473133509075
Validation loss: 2.4993861870276755

Epoch: 561| Step: 0
Training loss: 1.5266526944272085
Validation loss: 2.5127258710859133

Epoch: 6| Step: 1
Training loss: 1.663327193443163
Validation loss: 2.546165183694013

Epoch: 6| Step: 2
Training loss: 1.6694916466535104
Validation loss: 2.5790862080543464

Epoch: 6| Step: 3
Training loss: 2.4885091871843525
Validation loss: 2.451425408144938

Epoch: 6| Step: 4
Training loss: 1.3963523108718912
Validation loss: 2.613505131140346

Epoch: 6| Step: 5
Training loss: 1.6776619696841601
Validation loss: 2.559550703291229

Epoch: 6| Step: 6
Training loss: 1.4479186609194994
Validation loss: 2.5199650674538536

Epoch: 6| Step: 7
Training loss: 1.5988559089518768
Validation loss: 2.528574592204622

Epoch: 6| Step: 8
Training loss: 1.535781383632771
Validation loss: 2.5654414277800925

Epoch: 6| Step: 9
Training loss: 1.8847753020517442
Validation loss: 2.5355773128133268

Epoch: 6| Step: 10
Training loss: 1.7703664126692593
Validation loss: 2.6567581660633612

Epoch: 6| Step: 11
Training loss: 1.0637403989329453
Validation loss: 2.561332456163231

Epoch: 6| Step: 12
Training loss: 1.4443526921515955
Validation loss: 2.5758221098148533

Epoch: 6| Step: 13
Training loss: 1.4879034569092577
Validation loss: 2.5307132451130676

Epoch: 562| Step: 0
Training loss: 1.9410783272002858
Validation loss: 2.5009749347107935

Epoch: 6| Step: 1
Training loss: 1.2398615239100677
Validation loss: 2.559147065567569

Epoch: 6| Step: 2
Training loss: 1.7372090322440201
Validation loss: 2.4858893945270157

Epoch: 6| Step: 3
Training loss: 2.395162527188234
Validation loss: 2.6105770481131443

Epoch: 6| Step: 4
Training loss: 1.5157267742790446
Validation loss: 2.5346141747392665

Epoch: 6| Step: 5
Training loss: 2.007927086080049
Validation loss: 2.546456231142681

Epoch: 6| Step: 6
Training loss: 1.5837755924074954
Validation loss: 2.4818647243548484

Epoch: 6| Step: 7
Training loss: 1.5365965010593612
Validation loss: 2.5587004919142036

Epoch: 6| Step: 8
Training loss: 1.2687741883325827
Validation loss: 2.481523986742593

Epoch: 6| Step: 9
Training loss: 1.7051836922771573
Validation loss: 2.488063436005262

Epoch: 6| Step: 10
Training loss: 1.6004213314821005
Validation loss: 2.4981041970101923

Epoch: 6| Step: 11
Training loss: 1.7676688998186245
Validation loss: 2.5471813597186634

Epoch: 6| Step: 12
Training loss: 1.4293215757593363
Validation loss: 2.5748849087402284

Epoch: 6| Step: 13
Training loss: 1.141185466032275
Validation loss: 2.580567204479771

Epoch: 563| Step: 0
Training loss: 2.4423133080624133
Validation loss: 2.5798286782608124

Epoch: 6| Step: 1
Training loss: 1.233417187666763
Validation loss: 2.5835194095624465

Epoch: 6| Step: 2
Training loss: 1.5340688023114282
Validation loss: 2.5565109516478803

Epoch: 6| Step: 3
Training loss: 1.777278555208827
Validation loss: 2.5363812229044904

Epoch: 6| Step: 4
Training loss: 1.2621444598096858
Validation loss: 2.589742238544517

Epoch: 6| Step: 5
Training loss: 1.853863730668416
Validation loss: 2.6282450711465506

Epoch: 6| Step: 6
Training loss: 1.2041181453358059
Validation loss: 2.608378568312941

Epoch: 6| Step: 7
Training loss: 1.9787549310021522
Validation loss: 2.5121972382572237

Epoch: 6| Step: 8
Training loss: 1.3774824707660571
Validation loss: 2.5728142186410903

Epoch: 6| Step: 9
Training loss: 1.5903169644713444
Validation loss: 2.5844565545411475

Epoch: 6| Step: 10
Training loss: 2.10496421529839
Validation loss: 2.5293483176340885

Epoch: 6| Step: 11
Training loss: 1.235502331847673
Validation loss: 2.414295673110577

Epoch: 6| Step: 12
Training loss: 1.8732339170939771
Validation loss: 2.535674723788252

Epoch: 6| Step: 13
Training loss: 1.610185733767693
Validation loss: 2.458782968511799

Epoch: 564| Step: 0
Training loss: 2.424866139758203
Validation loss: 2.5023130955049036

Epoch: 6| Step: 1
Training loss: 1.6061877197778476
Validation loss: 2.5450241870030172

Epoch: 6| Step: 2
Training loss: 1.3978689732306104
Validation loss: 2.554623636671321

Epoch: 6| Step: 3
Training loss: 1.470623363748492
Validation loss: 2.5448681249736183

Epoch: 6| Step: 4
Training loss: 1.8875875743229837
Validation loss: 2.5512580297224283

Epoch: 6| Step: 5
Training loss: 1.6034749591610005
Validation loss: 2.587413447309988

Epoch: 6| Step: 6
Training loss: 1.3990105674840805
Validation loss: 2.5084228406716744

Epoch: 6| Step: 7
Training loss: 1.528576131744687
Validation loss: 2.4926373588817397

Epoch: 6| Step: 8
Training loss: 2.0697241756939855
Validation loss: 2.6411681791596737

Epoch: 6| Step: 9
Training loss: 1.5410369755531412
Validation loss: 2.4679157477333145

Epoch: 6| Step: 10
Training loss: 1.5198160017478106
Validation loss: 2.5180964292984953

Epoch: 6| Step: 11
Training loss: 1.4218240246700384
Validation loss: 2.6169391522208882

Epoch: 6| Step: 12
Training loss: 1.247096934441396
Validation loss: 2.470480940192694

Epoch: 6| Step: 13
Training loss: 1.4412764824239839
Validation loss: 2.497553019560052

Epoch: 565| Step: 0
Training loss: 1.8479177922958965
Validation loss: 2.568855690419178

Epoch: 6| Step: 1
Training loss: 2.546196221077242
Validation loss: 2.5559903228736798

Epoch: 6| Step: 2
Training loss: 1.765183114989309
Validation loss: 2.4453705748622756

Epoch: 6| Step: 3
Training loss: 1.6828280165726432
Validation loss: 2.498137244620221

Epoch: 6| Step: 4
Training loss: 1.291982776149112
Validation loss: 2.5652571001317357

Epoch: 6| Step: 5
Training loss: 1.8345434862058057
Validation loss: 2.556721113510039

Epoch: 6| Step: 6
Training loss: 1.831706980168198
Validation loss: 2.477155163244585

Epoch: 6| Step: 7
Training loss: 1.5158047913556765
Validation loss: 2.452085047916501

Epoch: 6| Step: 8
Training loss: 1.5372848701387123
Validation loss: 2.5259546848278718

Epoch: 6| Step: 9
Training loss: 1.3489734349332152
Validation loss: 2.486148551249122

Epoch: 6| Step: 10
Training loss: 1.4390008803438485
Validation loss: 2.5306219640746876

Epoch: 6| Step: 11
Training loss: 1.8140700544648498
Validation loss: 2.499762511509583

Epoch: 6| Step: 12
Training loss: 1.3878965292326435
Validation loss: 2.557328060873523

Epoch: 6| Step: 13
Training loss: 1.2169326045229911
Validation loss: 2.4763725479386154

Epoch: 566| Step: 0
Training loss: 1.5066568165572471
Validation loss: 2.560382795741039

Epoch: 6| Step: 1
Training loss: 1.7810506876480061
Validation loss: 2.5777464229773464

Epoch: 6| Step: 2
Training loss: 0.987602785048685
Validation loss: 2.4495614517563844

Epoch: 6| Step: 3
Training loss: 1.4884900524818028
Validation loss: 2.5792641209806577

Epoch: 6| Step: 4
Training loss: 1.0666706470077478
Validation loss: 2.5379143402537556

Epoch: 6| Step: 5
Training loss: 1.7806071409680206
Validation loss: 2.4799377002128673

Epoch: 6| Step: 6
Training loss: 1.6183415961848533
Validation loss: 2.4922503427672864

Epoch: 6| Step: 7
Training loss: 1.5188448024721228
Validation loss: 2.602601084679772

Epoch: 6| Step: 8
Training loss: 2.366980817477746
Validation loss: 2.501293737717619

Epoch: 6| Step: 9
Training loss: 1.7937819687390357
Validation loss: 2.469353969180223

Epoch: 6| Step: 10
Training loss: 1.080518691314768
Validation loss: 2.5606165831749896

Epoch: 6| Step: 11
Training loss: 1.6607396435889166
Validation loss: 2.5897966410701776

Epoch: 6| Step: 12
Training loss: 1.6865784283250387
Validation loss: 2.5246572865626926

Epoch: 6| Step: 13
Training loss: 1.6024469678081241
Validation loss: 2.4652239540052165

Epoch: 567| Step: 0
Training loss: 1.6266248355760742
Validation loss: 2.5255748348278213

Epoch: 6| Step: 1
Training loss: 1.9423474614995762
Validation loss: 2.563915750988413

Epoch: 6| Step: 2
Training loss: 1.7638859919860495
Validation loss: 2.5186912067871385

Epoch: 6| Step: 3
Training loss: 1.3969161639879522
Validation loss: 2.392048426931859

Epoch: 6| Step: 4
Training loss: 1.2324549554172632
Validation loss: 2.576821454517975

Epoch: 6| Step: 5
Training loss: 1.5420285994305656
Validation loss: 2.5232428338451767

Epoch: 6| Step: 6
Training loss: 2.1018091220156467
Validation loss: 2.620125431864837

Epoch: 6| Step: 7
Training loss: 1.557617493632415
Validation loss: 2.4828705192523284

Epoch: 6| Step: 8
Training loss: 1.2090276608706545
Validation loss: 2.598860026099983

Epoch: 6| Step: 9
Training loss: 0.9108016055049827
Validation loss: 2.6418735139663108

Epoch: 6| Step: 10
Training loss: 2.4999540324753466
Validation loss: 2.525576782750494

Epoch: 6| Step: 11
Training loss: 1.5012537167365752
Validation loss: 2.5162176372833693

Epoch: 6| Step: 12
Training loss: 1.6070313657205157
Validation loss: 2.5295727286263463

Epoch: 6| Step: 13
Training loss: 2.0679459775586677
Validation loss: 2.6049078797518623

Epoch: 568| Step: 0
Training loss: 1.5220272481536967
Validation loss: 2.5603113744850017

Epoch: 6| Step: 1
Training loss: 1.64530364900909
Validation loss: 2.4284149193642413

Epoch: 6| Step: 2
Training loss: 1.7831822672999769
Validation loss: 2.547626858736001

Epoch: 6| Step: 3
Training loss: 1.346828217368804
Validation loss: 2.5733784057057236

Epoch: 6| Step: 4
Training loss: 1.3330781463959638
Validation loss: 2.4279884897911264

Epoch: 6| Step: 5
Training loss: 1.6300559983258927
Validation loss: 2.584037024658631

Epoch: 6| Step: 6
Training loss: 1.6285623237646953
Validation loss: 2.6010212471792022

Epoch: 6| Step: 7
Training loss: 1.6437067787666992
Validation loss: 2.425777455974022

Epoch: 6| Step: 8
Training loss: 1.9570199200878997
Validation loss: 2.4965322295755876

Epoch: 6| Step: 9
Training loss: 1.6833881155233785
Validation loss: 2.5852693252705805

Epoch: 6| Step: 10
Training loss: 1.0558635230341025
Validation loss: 2.592430596565118

Epoch: 6| Step: 11
Training loss: 1.3881401406758755
Validation loss: 2.5470014609069316

Epoch: 6| Step: 12
Training loss: 2.4829706985459263
Validation loss: 2.5912637903963627

Epoch: 6| Step: 13
Training loss: 1.3304209442420352
Validation loss: 2.5102149338704924

Epoch: 569| Step: 0
Training loss: 1.7582901369306039
Validation loss: 2.4828244276758014

Epoch: 6| Step: 1
Training loss: 1.3363783705653427
Validation loss: 2.626361342058221

Epoch: 6| Step: 2
Training loss: 1.5924583885948569
Validation loss: 2.5426455111898125

Epoch: 6| Step: 3
Training loss: 1.6407287564847388
Validation loss: 2.5628152808904057

Epoch: 6| Step: 4
Training loss: 1.907670039326212
Validation loss: 2.5986801045552395

Epoch: 6| Step: 5
Training loss: 1.3985120870635919
Validation loss: 2.4740809822875756

Epoch: 6| Step: 6
Training loss: 1.2881690425830328
Validation loss: 2.533038144921251

Epoch: 6| Step: 7
Training loss: 1.6675703300960503
Validation loss: 2.576639915463497

Epoch: 6| Step: 8
Training loss: 1.5972241701123435
Validation loss: 2.597439353708868

Epoch: 6| Step: 9
Training loss: 1.4885558027802392
Validation loss: 2.4961689441141677

Epoch: 6| Step: 10
Training loss: 1.458682681428726
Validation loss: 2.503803117884567

Epoch: 6| Step: 11
Training loss: 2.4829006978832875
Validation loss: 2.6288088273518118

Epoch: 6| Step: 12
Training loss: 1.3878650494362834
Validation loss: 2.5135694719840154

Epoch: 6| Step: 13
Training loss: 2.3393998529009377
Validation loss: 2.514705936687659

Epoch: 570| Step: 0
Training loss: 1.1671164985110962
Validation loss: 2.5301011948810275

Epoch: 6| Step: 1
Training loss: 1.4927111600577119
Validation loss: 2.6113009601620507

Epoch: 6| Step: 2
Training loss: 1.7370759021029416
Validation loss: 2.5849834898461115

Epoch: 6| Step: 3
Training loss: 2.610576878223562
Validation loss: 2.5594828471381397

Epoch: 6| Step: 4
Training loss: 1.2544019438278455
Validation loss: 2.47726915631332

Epoch: 6| Step: 5
Training loss: 1.0847073180449704
Validation loss: 2.493960763670085

Epoch: 6| Step: 6
Training loss: 1.659978879541448
Validation loss: 2.4393175362433905

Epoch: 6| Step: 7
Training loss: 1.3224182040874097
Validation loss: 2.5515054332651053

Epoch: 6| Step: 8
Training loss: 1.413502408379472
Validation loss: 2.533448868881915

Epoch: 6| Step: 9
Training loss: 1.8100639283498068
Validation loss: 2.486223534704306

Epoch: 6| Step: 10
Training loss: 1.1289970599018804
Validation loss: 2.4818983838151922

Epoch: 6| Step: 11
Training loss: 1.4093661221311293
Validation loss: 2.476988052239461

Epoch: 6| Step: 12
Training loss: 1.74559515676587
Validation loss: 2.495414008534429

Epoch: 6| Step: 13
Training loss: 1.468819961504876
Validation loss: 2.5240268179779575

Epoch: 571| Step: 0
Training loss: 1.252107940956723
Validation loss: 2.5799587625465716

Epoch: 6| Step: 1
Training loss: 1.6516139084710535
Validation loss: 2.6446774856521578

Epoch: 6| Step: 2
Training loss: 1.6151923066903064
Validation loss: 2.5602815330578785

Epoch: 6| Step: 3
Training loss: 1.7448267083895668
Validation loss: 2.5573591041248496

Epoch: 6| Step: 4
Training loss: 1.5078695019635426
Validation loss: 2.5980178259385514

Epoch: 6| Step: 5
Training loss: 1.2658038542786612
Validation loss: 2.5994678872167705

Epoch: 6| Step: 6
Training loss: 1.5836908371856055
Validation loss: 2.5543800669016368

Epoch: 6| Step: 7
Training loss: 1.259810477944256
Validation loss: 2.513379865720828

Epoch: 6| Step: 8
Training loss: 2.0971562022188825
Validation loss: 2.4655663765398117

Epoch: 6| Step: 9
Training loss: 1.6377515788867731
Validation loss: 2.5092555510318006

Epoch: 6| Step: 10
Training loss: 1.3765882509141691
Validation loss: 2.4510495987362035

Epoch: 6| Step: 11
Training loss: 2.29912576231381
Validation loss: 2.52873322004364

Epoch: 6| Step: 12
Training loss: 1.2565241784905241
Validation loss: 2.602776077289856

Epoch: 6| Step: 13
Training loss: 1.841931108617481
Validation loss: 2.424731089697457

Epoch: 572| Step: 0
Training loss: 0.9629188827484746
Validation loss: 2.434126166849087

Epoch: 6| Step: 1
Training loss: 1.3648074987583385
Validation loss: 2.4471564067741745

Epoch: 6| Step: 2
Training loss: 1.754936340568581
Validation loss: 2.5063671268097383

Epoch: 6| Step: 3
Training loss: 1.729162269801176
Validation loss: 2.5894810584348678

Epoch: 6| Step: 4
Training loss: 2.178274263934847
Validation loss: 2.4835297332060793

Epoch: 6| Step: 5
Training loss: 1.5943814690913631
Validation loss: 2.468801120671669

Epoch: 6| Step: 6
Training loss: 0.9174479853882422
Validation loss: 2.485915676483232

Epoch: 6| Step: 7
Training loss: 1.983832097316766
Validation loss: 2.5791824036844915

Epoch: 6| Step: 8
Training loss: 1.7415808061794074
Validation loss: 2.5074889864668606

Epoch: 6| Step: 9
Training loss: 1.6624819991205626
Validation loss: 2.546118390292521

Epoch: 6| Step: 10
Training loss: 2.2599748334918153
Validation loss: 2.5570733901361886

Epoch: 6| Step: 11
Training loss: 0.9987779242917114
Validation loss: 2.5570071556084257

Epoch: 6| Step: 12
Training loss: 0.9791543668961925
Validation loss: 2.5646115059122927

Epoch: 6| Step: 13
Training loss: 1.9255045910673798
Validation loss: 2.520788585076173

Epoch: 573| Step: 0
Training loss: 1.1659407855222488
Validation loss: 2.572770630244726

Epoch: 6| Step: 1
Training loss: 1.6647960496689702
Validation loss: 2.6124786366266664

Epoch: 6| Step: 2
Training loss: 2.0382015120560477
Validation loss: 2.56748342216466

Epoch: 6| Step: 3
Training loss: 1.2725606134214367
Validation loss: 2.4874628109686525

Epoch: 6| Step: 4
Training loss: 2.036131407373616
Validation loss: 2.6100975147996883

Epoch: 6| Step: 5
Training loss: 1.773485897260873
Validation loss: 2.535743115437983

Epoch: 6| Step: 6
Training loss: 2.411328690561401
Validation loss: 2.5415074806116924

Epoch: 6| Step: 7
Training loss: 1.8205278130103741
Validation loss: 2.548609392851934

Epoch: 6| Step: 8
Training loss: 1.245415673475145
Validation loss: 2.548716497595517

Epoch: 6| Step: 9
Training loss: 1.3175535550895738
Validation loss: 2.611505369857572

Epoch: 6| Step: 10
Training loss: 1.6727594905886776
Validation loss: 2.6037343003861766

Epoch: 6| Step: 11
Training loss: 1.1068535747640775
Validation loss: 2.5159199971686026

Epoch: 6| Step: 12
Training loss: 1.479528928999229
Validation loss: 2.542243761552275

Epoch: 6| Step: 13
Training loss: 1.2010875145045756
Validation loss: 2.5407107502471837

Epoch: 574| Step: 0
Training loss: 1.6044528094966244
Validation loss: 2.574900951326341

Epoch: 6| Step: 1
Training loss: 1.216921094306474
Validation loss: 2.5049435263224495

Epoch: 6| Step: 2
Training loss: 1.2803777656558823
Validation loss: 2.486103968750301

Epoch: 6| Step: 3
Training loss: 1.9068889485126916
Validation loss: 2.5610461398893634

Epoch: 6| Step: 4
Training loss: 1.5058405339389573
Validation loss: 2.5556017257861723

Epoch: 6| Step: 5
Training loss: 1.6915891341433449
Validation loss: 2.5608127921132104

Epoch: 6| Step: 6
Training loss: 1.2239920537104751
Validation loss: 2.592785033696452

Epoch: 6| Step: 7
Training loss: 1.3426515392112952
Validation loss: 2.5021405807948436

Epoch: 6| Step: 8
Training loss: 2.6021084599214586
Validation loss: 2.5294538298376885

Epoch: 6| Step: 9
Training loss: 1.1518785475181061
Validation loss: 2.5867226639235343

Epoch: 6| Step: 10
Training loss: 1.4677493968423738
Validation loss: 2.5007291499596107

Epoch: 6| Step: 11
Training loss: 1.939417351799047
Validation loss: 2.568665940393615

Epoch: 6| Step: 12
Training loss: 1.5069750896488447
Validation loss: 2.578972810749139

Epoch: 6| Step: 13
Training loss: 1.4457964937351997
Validation loss: 2.5327909441371244

Epoch: 575| Step: 0
Training loss: 2.7484671915867507
Validation loss: 2.4591577801032836

Epoch: 6| Step: 1
Training loss: 1.7451146600210783
Validation loss: 2.534864329880867

Epoch: 6| Step: 2
Training loss: 1.1736094545632334
Validation loss: 2.502184478496023

Epoch: 6| Step: 3
Training loss: 1.4878427254920328
Validation loss: 2.594703549446006

Epoch: 6| Step: 4
Training loss: 1.461103378915251
Validation loss: 2.5538776437798814

Epoch: 6| Step: 5
Training loss: 1.2556267933811351
Validation loss: 2.5369230600457997

Epoch: 6| Step: 6
Training loss: 1.7762288044383676
Validation loss: 2.6064826203063607

Epoch: 6| Step: 7
Training loss: 1.4806191561749849
Validation loss: 2.5882142235928813

Epoch: 6| Step: 8
Training loss: 1.8114180130627209
Validation loss: 2.5303641556415926

Epoch: 6| Step: 9
Training loss: 1.2682162472839078
Validation loss: 2.4950104050934416

Epoch: 6| Step: 10
Training loss: 1.4855833255249054
Validation loss: 2.5484697060288335

Epoch: 6| Step: 11
Training loss: 1.809011061044662
Validation loss: 2.5585996736547

Epoch: 6| Step: 12
Training loss: 1.5233594825525871
Validation loss: 2.5244170877885175

Epoch: 6| Step: 13
Training loss: 1.4457508144227948
Validation loss: 2.5153483434409587

Epoch: 576| Step: 0
Training loss: 1.328962353795312
Validation loss: 2.45675073228065

Epoch: 6| Step: 1
Training loss: 1.5681821121999593
Validation loss: 2.5632038510414032

Epoch: 6| Step: 2
Training loss: 2.247012592288878
Validation loss: 2.5384964183634326

Epoch: 6| Step: 3
Training loss: 1.224385997105546
Validation loss: 2.450062709153979

Epoch: 6| Step: 4
Training loss: 1.7006730093833355
Validation loss: 2.5952459479766765

Epoch: 6| Step: 5
Training loss: 1.6611028149389477
Validation loss: 2.4810664390823374

Epoch: 6| Step: 6
Training loss: 1.3698723289421237
Validation loss: 2.569041401911304

Epoch: 6| Step: 7
Training loss: 1.6624508785935819
Validation loss: 2.523096751723766

Epoch: 6| Step: 8
Training loss: 1.485648241579456
Validation loss: 2.5073540156357534

Epoch: 6| Step: 9
Training loss: 1.3589118519308212
Validation loss: 2.6398227621295063

Epoch: 6| Step: 10
Training loss: 2.021389547141754
Validation loss: 2.5764975364614076

Epoch: 6| Step: 11
Training loss: 1.3617783709029327
Validation loss: 2.5894316232442316

Epoch: 6| Step: 12
Training loss: 1.5660393872721698
Validation loss: 2.51542643631731

Epoch: 6| Step: 13
Training loss: 1.6043757595510733
Validation loss: 2.532914327912518

Epoch: 577| Step: 0
Training loss: 1.2702609737968054
Validation loss: 2.5708306930330855

Epoch: 6| Step: 1
Training loss: 1.3705314939708177
Validation loss: 2.5507579932370987

Epoch: 6| Step: 2
Training loss: 1.404620519278029
Validation loss: 2.5062716622887233

Epoch: 6| Step: 3
Training loss: 1.1761255108814668
Validation loss: 2.496862746201491

Epoch: 6| Step: 4
Training loss: 1.4726814247630622
Validation loss: 2.4511656373418576

Epoch: 6| Step: 5
Training loss: 1.8223424243178081
Validation loss: 2.5241922783608444

Epoch: 6| Step: 6
Training loss: 1.9693096515899207
Validation loss: 2.4637420377866284

Epoch: 6| Step: 7
Training loss: 2.3745467104756464
Validation loss: 2.517413868439098

Epoch: 6| Step: 8
Training loss: 1.5609674185481255
Validation loss: 2.5814640789369965

Epoch: 6| Step: 9
Training loss: 1.650807922696623
Validation loss: 2.4986049051234756

Epoch: 6| Step: 10
Training loss: 1.742439901774106
Validation loss: 2.5302642164665765

Epoch: 6| Step: 11
Training loss: 1.7216861960579615
Validation loss: 2.5812758258351063

Epoch: 6| Step: 12
Training loss: 1.2144435701825655
Validation loss: 2.542722770748502

Epoch: 6| Step: 13
Training loss: 1.492056716060841
Validation loss: 2.41422283913024

Epoch: 578| Step: 0
Training loss: 1.6606433109053513
Validation loss: 2.5361144493984478

Epoch: 6| Step: 1
Training loss: 1.6007542501307075
Validation loss: 2.586690997837155

Epoch: 6| Step: 2
Training loss: 2.0617784336091147
Validation loss: 2.47715836008947

Epoch: 6| Step: 3
Training loss: 1.6115475406954742
Validation loss: 2.4976426998428303

Epoch: 6| Step: 4
Training loss: 1.1724407102157672
Validation loss: 2.51006444224125

Epoch: 6| Step: 5
Training loss: 1.1377355478400275
Validation loss: 2.635207993864989

Epoch: 6| Step: 6
Training loss: 1.6112883961721558
Validation loss: 2.3849716219163204

Epoch: 6| Step: 7
Training loss: 1.0872408503298505
Validation loss: 2.583779310088601

Epoch: 6| Step: 8
Training loss: 1.9624083576551605
Validation loss: 2.5049353234974676

Epoch: 6| Step: 9
Training loss: 1.4397353331740677
Validation loss: 2.4606019837818307

Epoch: 6| Step: 10
Training loss: 2.2661157536919556
Validation loss: 2.6232460303162775

Epoch: 6| Step: 11
Training loss: 1.711622266605228
Validation loss: 2.5377294633360434

Epoch: 6| Step: 12
Training loss: 1.8050262661658034
Validation loss: 2.51930980429416

Epoch: 6| Step: 13
Training loss: 1.782740788935755
Validation loss: 2.484128635785749

Epoch: 579| Step: 0
Training loss: 2.03924337586027
Validation loss: 2.5593854623469254

Epoch: 6| Step: 1
Training loss: 1.5773335351183373
Validation loss: 2.3969626416596483

Epoch: 6| Step: 2
Training loss: 2.3572856418084798
Validation loss: 2.514069312783065

Epoch: 6| Step: 3
Training loss: 1.67042335877474
Validation loss: 2.4255065566924903

Epoch: 6| Step: 4
Training loss: 1.1040881266941323
Validation loss: 2.4881384173913967

Epoch: 6| Step: 5
Training loss: 1.6789513682626327
Validation loss: 2.6074667512218768

Epoch: 6| Step: 6
Training loss: 1.4647202910213148
Validation loss: 2.432178108283937

Epoch: 6| Step: 7
Training loss: 1.1008648658546742
Validation loss: 2.660343038987314

Epoch: 6| Step: 8
Training loss: 1.7307139754645087
Validation loss: 2.4909502316058205

Epoch: 6| Step: 9
Training loss: 1.0117925668541796
Validation loss: 2.5450699745909113

Epoch: 6| Step: 10
Training loss: 1.6539657964064352
Validation loss: 2.468009555235997

Epoch: 6| Step: 11
Training loss: 1.7160793710283528
Validation loss: 2.564248999566499

Epoch: 6| Step: 12
Training loss: 1.4878059489300857
Validation loss: 2.5567987408587194

Epoch: 6| Step: 13
Training loss: 1.0710984289065726
Validation loss: 2.4071303793214316

Epoch: 580| Step: 0
Training loss: 1.480636707934316
Validation loss: 2.527635283046495

Epoch: 6| Step: 1
Training loss: 1.9171843313425705
Validation loss: 2.3051697596483227

Epoch: 6| Step: 2
Training loss: 1.3415056159619574
Validation loss: 2.506129305690119

Epoch: 6| Step: 3
Training loss: 1.2839670911832028
Validation loss: 2.5316098452546627

Epoch: 6| Step: 4
Training loss: 1.3907102065824595
Validation loss: 2.4972857374098694

Epoch: 6| Step: 5
Training loss: 2.3844757778723626
Validation loss: 2.5795741080981074

Epoch: 6| Step: 6
Training loss: 1.05915243460885
Validation loss: 2.6047454719069667

Epoch: 6| Step: 7
Training loss: 2.0035021636623718
Validation loss: 2.55009470783266

Epoch: 6| Step: 8
Training loss: 1.756003232839993
Validation loss: 2.5486529740083195

Epoch: 6| Step: 9
Training loss: 1.8103771932649617
Validation loss: 2.5302840637849413

Epoch: 6| Step: 10
Training loss: 1.4231920116464116
Validation loss: 2.519624678811253

Epoch: 6| Step: 11
Training loss: 1.4363896601331076
Validation loss: 2.4241177170389716

Epoch: 6| Step: 12
Training loss: 1.4489773860348816
Validation loss: 2.5066068563245425

Epoch: 6| Step: 13
Training loss: 1.4462803255032353
Validation loss: 2.5847726980665446

Epoch: 581| Step: 0
Training loss: 1.1572838362672948
Validation loss: 2.5869039017221693

Epoch: 6| Step: 1
Training loss: 1.7632941330492755
Validation loss: 2.4358633382325983

Epoch: 6| Step: 2
Training loss: 1.4071059271245097
Validation loss: 2.7238594278309805

Epoch: 6| Step: 3
Training loss: 1.827981666097375
Validation loss: 2.437825752537963

Epoch: 6| Step: 4
Training loss: 1.940066329962597
Validation loss: 2.6204772383592436

Epoch: 6| Step: 5
Training loss: 1.007678473971796
Validation loss: 2.4376120645421144

Epoch: 6| Step: 6
Training loss: 1.3874683771739722
Validation loss: 2.499105751934236

Epoch: 6| Step: 7
Training loss: 2.037518965744025
Validation loss: 2.4592456190315852

Epoch: 6| Step: 8
Training loss: 2.2342355324493495
Validation loss: 2.581675334500576

Epoch: 6| Step: 9
Training loss: 1.2141809648724853
Validation loss: 2.5414472942874258

Epoch: 6| Step: 10
Training loss: 1.3425011265073343
Validation loss: 2.4724042707980542

Epoch: 6| Step: 11
Training loss: 1.8208736487958603
Validation loss: 2.5267214598810264

Epoch: 6| Step: 12
Training loss: 1.5553611177828817
Validation loss: 2.471480841953674

Epoch: 6| Step: 13
Training loss: 1.706056154858592
Validation loss: 2.5379963443585645

Epoch: 582| Step: 0
Training loss: 1.8250387501195326
Validation loss: 2.5287556452955253

Epoch: 6| Step: 1
Training loss: 1.3364389827969625
Validation loss: 2.5123655869045387

Epoch: 6| Step: 2
Training loss: 1.6090438650255674
Validation loss: 2.552184040693519

Epoch: 6| Step: 3
Training loss: 1.32510135011104
Validation loss: 2.5133111261438987

Epoch: 6| Step: 4
Training loss: 1.791173297759888
Validation loss: 2.5097583000555344

Epoch: 6| Step: 5
Training loss: 1.2961624669948797
Validation loss: 2.47385104729878

Epoch: 6| Step: 6
Training loss: 1.5338341064523024
Validation loss: 2.506776156690335

Epoch: 6| Step: 7
Training loss: 1.7037206885432579
Validation loss: 2.499831100624077

Epoch: 6| Step: 8
Training loss: 1.4234058397542868
Validation loss: 2.4282942199254025

Epoch: 6| Step: 9
Training loss: 1.7029486748649365
Validation loss: 2.5324519706737267

Epoch: 6| Step: 10
Training loss: 1.7467832974571134
Validation loss: 2.5298246793885397

Epoch: 6| Step: 11
Training loss: 1.8037397530014183
Validation loss: 2.5807857909327017

Epoch: 6| Step: 12
Training loss: 2.310022625172445
Validation loss: 2.53738930068394

Epoch: 6| Step: 13
Training loss: 1.3420702615500244
Validation loss: 2.465918197613989

Epoch: 583| Step: 0
Training loss: 1.5388415802540079
Validation loss: 2.491782397067881

Epoch: 6| Step: 1
Training loss: 2.165976438864426
Validation loss: 2.5694681603481753

Epoch: 6| Step: 2
Training loss: 1.1126737308936967
Validation loss: 2.420059064213655

Epoch: 6| Step: 3
Training loss: 1.4019001123540544
Validation loss: 2.5456740709070824

Epoch: 6| Step: 4
Training loss: 1.8334465497633776
Validation loss: 2.509303739856858

Epoch: 6| Step: 5
Training loss: 1.8166693384110055
Validation loss: 2.523480931730586

Epoch: 6| Step: 6
Training loss: 1.4872892983855848
Validation loss: 2.531837517744128

Epoch: 6| Step: 7
Training loss: 2.1794228888791998
Validation loss: 2.5155338542683072

Epoch: 6| Step: 8
Training loss: 1.3179349541076248
Validation loss: 2.484342134619103

Epoch: 6| Step: 9
Training loss: 1.4382047998602085
Validation loss: 2.5781779363672213

Epoch: 6| Step: 10
Training loss: 1.4493215683813718
Validation loss: 2.51233616629793

Epoch: 6| Step: 11
Training loss: 1.307025208490595
Validation loss: 2.4868463406137646

Epoch: 6| Step: 12
Training loss: 1.7482969989522403
Validation loss: 2.543382152131363

Epoch: 6| Step: 13
Training loss: 1.0732655127839505
Validation loss: 2.5667590686067694

Epoch: 584| Step: 0
Training loss: 1.5460731663039706
Validation loss: 2.4630578879061558

Epoch: 6| Step: 1
Training loss: 1.1099086069165323
Validation loss: 2.52768550084442

Epoch: 6| Step: 2
Training loss: 1.6368534879374208
Validation loss: 2.5786266148420283

Epoch: 6| Step: 3
Training loss: 1.6498561738647697
Validation loss: 2.6131269432483464

Epoch: 6| Step: 4
Training loss: 1.242379851413431
Validation loss: 2.5292911556241156

Epoch: 6| Step: 5
Training loss: 1.3300012238575747
Validation loss: 2.536903031232639

Epoch: 6| Step: 6
Training loss: 2.340893237808566
Validation loss: 2.4871543253493575

Epoch: 6| Step: 7
Training loss: 1.728758369254529
Validation loss: 2.4425655167300984

Epoch: 6| Step: 8
Training loss: 1.5259131246163207
Validation loss: 2.5194946174473647

Epoch: 6| Step: 9
Training loss: 1.445472502228841
Validation loss: 2.5229127430291935

Epoch: 6| Step: 10
Training loss: 1.6050024538823557
Validation loss: 2.581240315860991

Epoch: 6| Step: 11
Training loss: 1.4566405235202515
Validation loss: 2.597307163085436

Epoch: 6| Step: 12
Training loss: 1.3396607654948098
Validation loss: 2.5263322076805275

Epoch: 6| Step: 13
Training loss: 1.6070031771435573
Validation loss: 2.572861132338581

Epoch: 585| Step: 0
Training loss: 1.8898303040510651
Validation loss: 2.5845631884908316

Epoch: 6| Step: 1
Training loss: 1.0932697876823714
Validation loss: 2.5896776562728276

Epoch: 6| Step: 2
Training loss: 1.301489330859131
Validation loss: 2.5413876290735855

Epoch: 6| Step: 3
Training loss: 1.4598397603348432
Validation loss: 2.452959242524851

Epoch: 6| Step: 4
Training loss: 1.4596873763877964
Validation loss: 2.4807742004970423

Epoch: 6| Step: 5
Training loss: 1.2010377886605605
Validation loss: 2.4838675952537432

Epoch: 6| Step: 6
Training loss: 1.5918125268833632
Validation loss: 2.5361729569348297

Epoch: 6| Step: 7
Training loss: 1.7317921419673137
Validation loss: 2.4683305548366534

Epoch: 6| Step: 8
Training loss: 1.1436908748332386
Validation loss: 2.6087956224047364

Epoch: 6| Step: 9
Training loss: 1.5344231094929204
Validation loss: 2.5101176782399763

Epoch: 6| Step: 10
Training loss: 1.3143286454773968
Validation loss: 2.5664215624354596

Epoch: 6| Step: 11
Training loss: 1.5608736347807475
Validation loss: 2.5175873975895593

Epoch: 6| Step: 12
Training loss: 2.2508833528695122
Validation loss: 2.5139711661109048

Epoch: 6| Step: 13
Training loss: 1.6848953773776993
Validation loss: 2.569678878694994

Epoch: 586| Step: 0
Training loss: 1.5508913246120233
Validation loss: 2.521856529663368

Epoch: 6| Step: 1
Training loss: 1.7705098324157673
Validation loss: 2.4485808850917383

Epoch: 6| Step: 2
Training loss: 1.6980225309667645
Validation loss: 2.582874045560491

Epoch: 6| Step: 3
Training loss: 1.1263576368916233
Validation loss: 2.521448817041752

Epoch: 6| Step: 4
Training loss: 1.6801781226144323
Validation loss: 2.454664605328441

Epoch: 6| Step: 5
Training loss: 1.322017133569999
Validation loss: 2.4767528784378814

Epoch: 6| Step: 6
Training loss: 1.6915605928335216
Validation loss: 2.620843578328837

Epoch: 6| Step: 7
Training loss: 1.3751923686622998
Validation loss: 2.4667309788693004

Epoch: 6| Step: 8
Training loss: 1.1460723396490904
Validation loss: 2.5291713290521183

Epoch: 6| Step: 9
Training loss: 2.666490091994637
Validation loss: 2.5617006697420095

Epoch: 6| Step: 10
Training loss: 1.756089514733957
Validation loss: 2.6452363277074653

Epoch: 6| Step: 11
Training loss: 1.7160894435789287
Validation loss: 2.494192237694828

Epoch: 6| Step: 12
Training loss: 0.9512789624851681
Validation loss: 2.5046205644451476

Epoch: 6| Step: 13
Training loss: 1.6947055556404491
Validation loss: 2.5063200547552604

Epoch: 587| Step: 0
Training loss: 1.8180766638778754
Validation loss: 2.5277936381932102

Epoch: 6| Step: 1
Training loss: 1.774033097733593
Validation loss: 2.508262768917557

Epoch: 6| Step: 2
Training loss: 1.7465467441439924
Validation loss: 2.579187622043496

Epoch: 6| Step: 3
Training loss: 1.6430693809176267
Validation loss: 2.5173492260120653

Epoch: 6| Step: 4
Training loss: 1.329652693009381
Validation loss: 2.5864633684070206

Epoch: 6| Step: 5
Training loss: 1.574338771135183
Validation loss: 2.6187087913515343

Epoch: 6| Step: 6
Training loss: 0.968010866543568
Validation loss: 2.4885641112299863

Epoch: 6| Step: 7
Training loss: 1.7566626963247833
Validation loss: 2.626105291667856

Epoch: 6| Step: 8
Training loss: 1.4840045667511215
Validation loss: 2.5651815086803325

Epoch: 6| Step: 9
Training loss: 1.6645987636088113
Validation loss: 2.5115938186993043

Epoch: 6| Step: 10
Training loss: 1.50450982206415
Validation loss: 2.486189182090138

Epoch: 6| Step: 11
Training loss: 1.4492101129238495
Validation loss: 2.567036385776791

Epoch: 6| Step: 12
Training loss: 2.0426910970279373
Validation loss: 2.4992330061644066

Epoch: 6| Step: 13
Training loss: 0.9293131034367307
Validation loss: 2.559284416638231

Epoch: 588| Step: 0
Training loss: 1.6504109940033715
Validation loss: 2.4589745613559195

Epoch: 6| Step: 1
Training loss: 1.2088802952252546
Validation loss: 2.568706087382249

Epoch: 6| Step: 2
Training loss: 1.6097440574217576
Validation loss: 2.522130559355768

Epoch: 6| Step: 3
Training loss: 1.5224548300571052
Validation loss: 2.497985842690082

Epoch: 6| Step: 4
Training loss: 1.7319863856883981
Validation loss: 2.361423112807169

Epoch: 6| Step: 5
Training loss: 1.3376627707147
Validation loss: 2.5338924535624985

Epoch: 6| Step: 6
Training loss: 1.3803947562749017
Validation loss: 2.555405302328458

Epoch: 6| Step: 7
Training loss: 2.666607756758718
Validation loss: 2.4440369552648797

Epoch: 6| Step: 8
Training loss: 1.7219604332528533
Validation loss: 2.310289616404001

Epoch: 6| Step: 9
Training loss: 1.337037999585354
Validation loss: 2.554718548243382

Epoch: 6| Step: 10
Training loss: 1.590433072425363
Validation loss: 2.558232083497743

Epoch: 6| Step: 11
Training loss: 1.2271499684779763
Validation loss: 2.529690801969517

Epoch: 6| Step: 12
Training loss: 1.5807937868621673
Validation loss: 2.483491699926511

Epoch: 6| Step: 13
Training loss: 1.4338894988544015
Validation loss: 2.5333929041797605

Epoch: 589| Step: 0
Training loss: 1.4679019996039533
Validation loss: 2.60555929507625

Epoch: 6| Step: 1
Training loss: 1.3176886314557674
Validation loss: 2.478558927481764

Epoch: 6| Step: 2
Training loss: 1.7086096826969541
Validation loss: 2.521193342774596

Epoch: 6| Step: 3
Training loss: 1.8005694018555456
Validation loss: 2.6255899285022237

Epoch: 6| Step: 4
Training loss: 1.1799810688472208
Validation loss: 2.5056313637717684

Epoch: 6| Step: 5
Training loss: 1.8294039434053302
Validation loss: 2.4645172610685915

Epoch: 6| Step: 6
Training loss: 1.5043438163412919
Validation loss: 2.487360842992476

Epoch: 6| Step: 7
Training loss: 1.410791481209959
Validation loss: 2.5389335424143895

Epoch: 6| Step: 8
Training loss: 2.3695173726617207
Validation loss: 2.6127408372304877

Epoch: 6| Step: 9
Training loss: 1.3211412255471673
Validation loss: 2.569318590977792

Epoch: 6| Step: 10
Training loss: 1.4986536023316042
Validation loss: 2.593112110503759

Epoch: 6| Step: 11
Training loss: 1.4650868125165275
Validation loss: 2.4949647730906532

Epoch: 6| Step: 12
Training loss: 1.2203140493229252
Validation loss: 2.6077548597412363

Epoch: 6| Step: 13
Training loss: 1.7128744091975803
Validation loss: 2.5219767279255

Epoch: 590| Step: 0
Training loss: 1.6981027029270375
Validation loss: 2.5404350817735426

Epoch: 6| Step: 1
Training loss: 1.4777067080516186
Validation loss: 2.4842762972943873

Epoch: 6| Step: 2
Training loss: 1.6301790017443702
Validation loss: 2.5322742701511505

Epoch: 6| Step: 3
Training loss: 1.8727996631209745
Validation loss: 2.445295371347773

Epoch: 6| Step: 4
Training loss: 1.327411684449869
Validation loss: 2.522654346427275

Epoch: 6| Step: 5
Training loss: 1.5566779195608875
Validation loss: 2.505764245126362

Epoch: 6| Step: 6
Training loss: 1.3896504105254353
Validation loss: 2.470582166125977

Epoch: 6| Step: 7
Training loss: 1.4469658545028938
Validation loss: 2.629956044212221

Epoch: 6| Step: 8
Training loss: 2.3198987803904987
Validation loss: 2.522328235476039

Epoch: 6| Step: 9
Training loss: 1.450384694073687
Validation loss: 2.5208479323981807

Epoch: 6| Step: 10
Training loss: 1.5179483754925265
Validation loss: 2.532884864613219

Epoch: 6| Step: 11
Training loss: 1.3854735465551267
Validation loss: 2.502604817495176

Epoch: 6| Step: 12
Training loss: 1.663053466336522
Validation loss: 2.593686910198776

Epoch: 6| Step: 13
Training loss: 0.875245025932258
Validation loss: 2.490297982008557

Epoch: 591| Step: 0
Training loss: 1.2334629987309231
Validation loss: 2.476786881143334

Epoch: 6| Step: 1
Training loss: 1.465609500371967
Validation loss: 2.561039529190577

Epoch: 6| Step: 2
Training loss: 1.7385876331991403
Validation loss: 2.4669889537464664

Epoch: 6| Step: 3
Training loss: 1.2560427518481267
Validation loss: 2.4824782142665938

Epoch: 6| Step: 4
Training loss: 1.2730219812525616
Validation loss: 2.4143351983498906

Epoch: 6| Step: 5
Training loss: 1.4346170956622473
Validation loss: 2.4152351183941394

Epoch: 6| Step: 6
Training loss: 1.2274505898967247
Validation loss: 2.386202238492062

Epoch: 6| Step: 7
Training loss: 1.502985367663763
Validation loss: 2.6071042358865526

Epoch: 6| Step: 8
Training loss: 1.320373804599084
Validation loss: 2.5419783869250585

Epoch: 6| Step: 9
Training loss: 1.3742384101888325
Validation loss: 2.487338332093566

Epoch: 6| Step: 10
Training loss: 1.2362765381281795
Validation loss: 2.5592772063761875

Epoch: 6| Step: 11
Training loss: 1.499534534714283
Validation loss: 2.5598482837683383

Epoch: 6| Step: 12
Training loss: 2.3889373606808606
Validation loss: 2.6279520018211215

Epoch: 6| Step: 13
Training loss: 1.664687706353125
Validation loss: 2.5463207604865583

Epoch: 592| Step: 0
Training loss: 1.1916719234235011
Validation loss: 2.553417311388649

Epoch: 6| Step: 1
Training loss: 1.426144571912798
Validation loss: 2.463579965100481

Epoch: 6| Step: 2
Training loss: 1.3238351992240536
Validation loss: 2.526577184095166

Epoch: 6| Step: 3
Training loss: 1.4248453491349213
Validation loss: 2.469207807413995

Epoch: 6| Step: 4
Training loss: 1.4130908304273444
Validation loss: 2.4700860442217194

Epoch: 6| Step: 5
Training loss: 1.234966957020904
Validation loss: 2.5051069017602527

Epoch: 6| Step: 6
Training loss: 1.6115816413966115
Validation loss: 2.511860969451874

Epoch: 6| Step: 7
Training loss: 1.7022665117448725
Validation loss: 2.4286538491887124

Epoch: 6| Step: 8
Training loss: 1.1859145874705015
Validation loss: 2.538340099419613

Epoch: 6| Step: 9
Training loss: 2.27361283822351
Validation loss: 2.522545912035642

Epoch: 6| Step: 10
Training loss: 1.328643876984862
Validation loss: 2.478592653555633

Epoch: 6| Step: 11
Training loss: 1.672988307015918
Validation loss: 2.63773636238276

Epoch: 6| Step: 12
Training loss: 1.8747068811817866
Validation loss: 2.4739898836793484

Epoch: 6| Step: 13
Training loss: 1.1487022665606341
Validation loss: 2.4619489433528043

Epoch: 593| Step: 0
Training loss: 1.8743001903475833
Validation loss: 2.4792857635699423

Epoch: 6| Step: 1
Training loss: 2.1536075045870073
Validation loss: 2.466319935842609

Epoch: 6| Step: 2
Training loss: 1.5602860596836763
Validation loss: 2.46463234002287

Epoch: 6| Step: 3
Training loss: 1.4090543970148732
Validation loss: 2.521957281816466

Epoch: 6| Step: 4
Training loss: 1.3156216600969195
Validation loss: 2.513377077046708

Epoch: 6| Step: 5
Training loss: 1.5149784872208396
Validation loss: 2.5204350787348457

Epoch: 6| Step: 6
Training loss: 1.2702489144903033
Validation loss: 2.463972135798585

Epoch: 6| Step: 7
Training loss: 1.5000081062097859
Validation loss: 2.6141426791372626

Epoch: 6| Step: 8
Training loss: 1.283856322910234
Validation loss: 2.4991863823879252

Epoch: 6| Step: 9
Training loss: 1.083534326003448
Validation loss: 2.564186273184381

Epoch: 6| Step: 10
Training loss: 1.7998046875
Validation loss: 2.559037498175563

Epoch: 6| Step: 11
Training loss: 1.6323493410140517
Validation loss: 2.643373445777742

Epoch: 6| Step: 12
Training loss: 1.7333522220951763
Validation loss: 2.490680697981916

Epoch: 6| Step: 13
Training loss: 1.383867367916099
Validation loss: 2.5273323130462546

Epoch: 594| Step: 0
Training loss: 1.0503137392254107
Validation loss: 2.514313160294434

Epoch: 6| Step: 1
Training loss: 0.9622610018372033
Validation loss: 2.550140047500353

Epoch: 6| Step: 2
Training loss: 1.4315511927962743
Validation loss: 2.5958081681132503

Epoch: 6| Step: 3
Training loss: 1.6185535061264469
Validation loss: 2.536615095019239

Epoch: 6| Step: 4
Training loss: 1.1200085215584958
Validation loss: 2.582921497121626

Epoch: 6| Step: 5
Training loss: 1.4958982016153195
Validation loss: 2.521524955988695

Epoch: 6| Step: 6
Training loss: 2.602359683956585
Validation loss: 2.5434001775087087

Epoch: 6| Step: 7
Training loss: 1.751010602970144
Validation loss: 2.582623891358012

Epoch: 6| Step: 8
Training loss: 1.7101867979762233
Validation loss: 2.479528092797142

Epoch: 6| Step: 9
Training loss: 1.2116067821093732
Validation loss: 2.4892326997421863

Epoch: 6| Step: 10
Training loss: 1.5547822702938245
Validation loss: 2.4829134742329955

Epoch: 6| Step: 11
Training loss: 1.4190901428366325
Validation loss: 2.6045902765763977

Epoch: 6| Step: 12
Training loss: 2.062858088070072
Validation loss: 2.5528974284781216

Epoch: 6| Step: 13
Training loss: 1.7033050161995207
Validation loss: 2.5107977309888714

Epoch: 595| Step: 0
Training loss: 1.2867826704165701
Validation loss: 2.5989463743897723

Epoch: 6| Step: 1
Training loss: 1.483933794806896
Validation loss: 2.5887307425051986

Epoch: 6| Step: 2
Training loss: 2.451706202655241
Validation loss: 2.578593267559517

Epoch: 6| Step: 3
Training loss: 1.2717222117287728
Validation loss: 2.4722372814431255

Epoch: 6| Step: 4
Training loss: 1.2653960503607136
Validation loss: 2.564015312370766

Epoch: 6| Step: 5
Training loss: 0.9611921205692964
Validation loss: 2.5068678616714006

Epoch: 6| Step: 6
Training loss: 1.367828480463974
Validation loss: 2.528485174064107

Epoch: 6| Step: 7
Training loss: 1.3302452665781375
Validation loss: 2.435915651608683

Epoch: 6| Step: 8
Training loss: 1.7833681061583972
Validation loss: 2.465548454868342

Epoch: 6| Step: 9
Training loss: 1.229776532877433
Validation loss: 2.4793817563506972

Epoch: 6| Step: 10
Training loss: 1.4011468481503955
Validation loss: 2.458428907822099

Epoch: 6| Step: 11
Training loss: 1.4532396825020242
Validation loss: 2.559750433152108

Epoch: 6| Step: 12
Training loss: 1.7929574471576606
Validation loss: 2.4474738267456067

Epoch: 6| Step: 13
Training loss: 1.9299852396346246
Validation loss: 2.5567070966387853

Epoch: 596| Step: 0
Training loss: 1.088213997520299
Validation loss: 2.548428098468944

Epoch: 6| Step: 1
Training loss: 1.7291222149141157
Validation loss: 2.443744059836795

Epoch: 6| Step: 2
Training loss: 1.5122244528732895
Validation loss: 2.6151898114620784

Epoch: 6| Step: 3
Training loss: 1.5676877684738781
Validation loss: 2.5313729545358234

Epoch: 6| Step: 4
Training loss: 1.7793984410330037
Validation loss: 2.5068910347429427

Epoch: 6| Step: 5
Training loss: 1.2301004009828254
Validation loss: 2.5437892709525456

Epoch: 6| Step: 6
Training loss: 1.4290162058259037
Validation loss: 2.474298833569681

Epoch: 6| Step: 7
Training loss: 1.3330590542177267
Validation loss: 2.632624361430328

Epoch: 6| Step: 8
Training loss: 1.4207004264950658
Validation loss: 2.6418904665789054

Epoch: 6| Step: 9
Training loss: 1.4411605997803059
Validation loss: 2.5739608860317365

Epoch: 6| Step: 10
Training loss: 1.658386292242949
Validation loss: 2.535946408612499

Epoch: 6| Step: 11
Training loss: 1.3555160646123376
Validation loss: 2.5882259214373677

Epoch: 6| Step: 12
Training loss: 2.546854592458021
Validation loss: 2.493035488676506

Epoch: 6| Step: 13
Training loss: 2.133885152298662
Validation loss: 2.6477393359223056

Epoch: 597| Step: 0
Training loss: 1.5973402237724958
Validation loss: 2.525814718985507

Epoch: 6| Step: 1
Training loss: 1.3849057232964013
Validation loss: 2.539220767456403

Epoch: 6| Step: 2
Training loss: 1.3424424307927234
Validation loss: 2.506529694530866

Epoch: 6| Step: 3
Training loss: 1.841091631820381
Validation loss: 2.5232268732893504

Epoch: 6| Step: 4
Training loss: 1.5403687796020964
Validation loss: 2.5722719317740346

Epoch: 6| Step: 5
Training loss: 1.1583167498016653
Validation loss: 2.5359935666122344

Epoch: 6| Step: 6
Training loss: 1.4898870820903714
Validation loss: 2.499324558648624

Epoch: 6| Step: 7
Training loss: 1.5663698720156272
Validation loss: 2.4959453147254202

Epoch: 6| Step: 8
Training loss: 1.3789837088725658
Validation loss: 2.5996952516829377

Epoch: 6| Step: 9
Training loss: 1.5805246974001377
Validation loss: 2.581994027748514

Epoch: 6| Step: 10
Training loss: 1.1052697208097355
Validation loss: 2.5805656944493798

Epoch: 6| Step: 11
Training loss: 1.2203325609421616
Validation loss: 2.544415540932999

Epoch: 6| Step: 12
Training loss: 2.502719734902845
Validation loss: 2.5372866090789805

Epoch: 6| Step: 13
Training loss: 1.5563112913264665
Validation loss: 2.476549256116193

Epoch: 598| Step: 0
Training loss: 1.550022045101783
Validation loss: 2.479214747862206

Epoch: 6| Step: 1
Training loss: 1.2929819342641158
Validation loss: 2.5087364666207193

Epoch: 6| Step: 2
Training loss: 1.477657255398478
Validation loss: 2.547353320486655

Epoch: 6| Step: 3
Training loss: 1.7115074845645457
Validation loss: 2.525448581060445

Epoch: 6| Step: 4
Training loss: 1.5150485171364458
Validation loss: 2.6133177254543276

Epoch: 6| Step: 5
Training loss: 1.644498992386089
Validation loss: 2.475089427533516

Epoch: 6| Step: 6
Training loss: 1.1339204828684002
Validation loss: 2.4333535626635774

Epoch: 6| Step: 7
Training loss: 1.2610661853419376
Validation loss: 2.5071140405747085

Epoch: 6| Step: 8
Training loss: 1.4469899109262607
Validation loss: 2.6019861916599583

Epoch: 6| Step: 9
Training loss: 1.4752055396714532
Validation loss: 2.537543749567245

Epoch: 6| Step: 10
Training loss: 1.4334218600384394
Validation loss: 2.440127712517049

Epoch: 6| Step: 11
Training loss: 1.8376432246228311
Validation loss: 2.4287839471066754

Epoch: 6| Step: 12
Training loss: 1.7558542151794319
Validation loss: 2.5497164045173677

Epoch: 6| Step: 13
Training loss: 2.7260551964425654
Validation loss: 2.492092078665143

Epoch: 599| Step: 0
Training loss: 1.4271529614617122
Validation loss: 2.534485364062423

Epoch: 6| Step: 1
Training loss: 1.2978752599063978
Validation loss: 2.606205757123439

Epoch: 6| Step: 2
Training loss: 1.7992361726302424
Validation loss: 2.4927382198705788

Epoch: 6| Step: 3
Training loss: 1.1250972705751334
Validation loss: 2.515713379783259

Epoch: 6| Step: 4
Training loss: 1.512177075048382
Validation loss: 2.49468393448788

Epoch: 6| Step: 5
Training loss: 1.0194326184967255
Validation loss: 2.58489036741885

Epoch: 6| Step: 6
Training loss: 1.3045389696195053
Validation loss: 2.501578246080385

Epoch: 6| Step: 7
Training loss: 1.9905044926408453
Validation loss: 2.543749138878634

Epoch: 6| Step: 8
Training loss: 2.533456194140363
Validation loss: 2.532712479731203

Epoch: 6| Step: 9
Training loss: 1.0226389557823754
Validation loss: 2.535042620959523

Epoch: 6| Step: 10
Training loss: 1.2659535864507376
Validation loss: 2.500841569252986

Epoch: 6| Step: 11
Training loss: 1.467278006690152
Validation loss: 2.499990243790161

Epoch: 6| Step: 12
Training loss: 1.7325382989170415
Validation loss: 2.5347301421409543

Epoch: 6| Step: 13
Training loss: 1.3785758338550063
Validation loss: 2.5627216190253606

Epoch: 600| Step: 0
Training loss: 2.0389489620943517
Validation loss: 2.4601687599066513

Epoch: 6| Step: 1
Training loss: 1.3714755578166447
Validation loss: 2.5078742765573434

Epoch: 6| Step: 2
Training loss: 1.4178695433830373
Validation loss: 2.4989005901589354

Epoch: 6| Step: 3
Training loss: 1.5191530673948865
Validation loss: 2.595561640588159

Epoch: 6| Step: 4
Training loss: 1.1314816253592879
Validation loss: 2.53508389808325

Epoch: 6| Step: 5
Training loss: 1.0784142147746059
Validation loss: 2.496818620430597

Epoch: 6| Step: 6
Training loss: 1.4361583419516626
Validation loss: 2.4746452983090816

Epoch: 6| Step: 7
Training loss: 1.6072880815559532
Validation loss: 2.4447045769493734

Epoch: 6| Step: 8
Training loss: 1.8166466994748567
Validation loss: 2.4949620193200315

Epoch: 6| Step: 9
Training loss: 1.1101032606843468
Validation loss: 2.5176287216010045

Epoch: 6| Step: 10
Training loss: 1.614604711903785
Validation loss: 2.5557995284127997

Epoch: 6| Step: 11
Training loss: 1.203638734993279
Validation loss: 2.5268310487357932

Epoch: 6| Step: 12
Training loss: 1.7631168611670616
Validation loss: 2.4815941192150053

Epoch: 6| Step: 13
Training loss: 2.033766610723091
Validation loss: 2.541543600195154

Epoch: 601| Step: 0
Training loss: 1.241607962677803
Validation loss: 2.601292671159968

Epoch: 6| Step: 1
Training loss: 1.4172065304589823
Validation loss: 2.493904840053623

Epoch: 6| Step: 2
Training loss: 2.364421878181574
Validation loss: 2.5968855245015208

Epoch: 6| Step: 3
Training loss: 1.033534553891414
Validation loss: 2.5421134395352087

Epoch: 6| Step: 4
Training loss: 1.5223094970082123
Validation loss: 2.479219421779526

Epoch: 6| Step: 5
Training loss: 1.3050920236230514
Validation loss: 2.5467695371271732

Epoch: 6| Step: 6
Training loss: 1.7649537557535977
Validation loss: 2.5514658063817564

Epoch: 6| Step: 7
Training loss: 1.7077537421809696
Validation loss: 2.4971134246347844

Epoch: 6| Step: 8
Training loss: 1.317230238396479
Validation loss: 2.507016984719546

Epoch: 6| Step: 9
Training loss: 1.3651972644220771
Validation loss: 2.4460620687290007

Epoch: 6| Step: 10
Training loss: 1.4562110535484911
Validation loss: 2.5786956384295805

Epoch: 6| Step: 11
Training loss: 1.5681223613037192
Validation loss: 2.5974839779994117

Epoch: 6| Step: 12
Training loss: 1.554256360258674
Validation loss: 2.5155232135733145

Epoch: 6| Step: 13
Training loss: 1.4622767220930166
Validation loss: 2.5249133018100562

Epoch: 602| Step: 0
Training loss: 1.931628529016096
Validation loss: 2.5505158510040333

Epoch: 6| Step: 1
Training loss: 2.0625812630105553
Validation loss: 2.408774494337987

Epoch: 6| Step: 2
Training loss: 1.7628850692096838
Validation loss: 2.5435564445054144

Epoch: 6| Step: 3
Training loss: 1.2500920261840058
Validation loss: 2.4400343969964355

Epoch: 6| Step: 4
Training loss: 1.3224676476543413
Validation loss: 2.584271960736351

Epoch: 6| Step: 5
Training loss: 0.7307093422979124
Validation loss: 2.450792649035434

Epoch: 6| Step: 6
Training loss: 1.6983401778622593
Validation loss: 2.4587992457285437

Epoch: 6| Step: 7
Training loss: 1.0706602213912193
Validation loss: 2.437586755736321

Epoch: 6| Step: 8
Training loss: 1.1557051947389552
Validation loss: 2.409158418969544

Epoch: 6| Step: 9
Training loss: 1.2885361030148061
Validation loss: 2.4838307442942065

Epoch: 6| Step: 10
Training loss: 1.4528657415312123
Validation loss: 2.530531996752737

Epoch: 6| Step: 11
Training loss: 2.5628581843440115
Validation loss: 2.4768228644724415

Epoch: 6| Step: 12
Training loss: 1.2186432816169792
Validation loss: 2.5462862485929967

Epoch: 6| Step: 13
Training loss: 1.6627182523260042
Validation loss: 2.4013564167072152

Epoch: 603| Step: 0
Training loss: 1.804923038057115
Validation loss: 2.472495110029148

Epoch: 6| Step: 1
Training loss: 1.3571628680223848
Validation loss: 2.55403250083763

Epoch: 6| Step: 2
Training loss: 1.3848352670307518
Validation loss: 2.560123614275255

Epoch: 6| Step: 3
Training loss: 1.5112171375876058
Validation loss: 2.564146194901246

Epoch: 6| Step: 4
Training loss: 1.198348335221728
Validation loss: 2.4710073871029783

Epoch: 6| Step: 5
Training loss: 2.2857186432354126
Validation loss: 2.5038621398266607

Epoch: 6| Step: 6
Training loss: 1.2361815547992057
Validation loss: 2.5170064893388377

Epoch: 6| Step: 7
Training loss: 1.7710521637586372
Validation loss: 2.5999416061577283

Epoch: 6| Step: 8
Training loss: 1.4617473785027186
Validation loss: 2.475772106172524

Epoch: 6| Step: 9
Training loss: 1.4843006316177165
Validation loss: 2.5765925024390897

Epoch: 6| Step: 10
Training loss: 1.3032732396690836
Validation loss: 2.5318343990534675

Epoch: 6| Step: 11
Training loss: 1.0414056959673015
Validation loss: 2.503535306965167

Epoch: 6| Step: 12
Training loss: 1.7437466200929106
Validation loss: 2.4427734285164555

Epoch: 6| Step: 13
Training loss: 2.0133243412591746
Validation loss: 2.4793719758783928

Epoch: 604| Step: 0
Training loss: 1.3496033686326185
Validation loss: 2.3980993927946517

Epoch: 6| Step: 1
Training loss: 1.5241878911134914
Validation loss: 2.503966646565253

Epoch: 6| Step: 2
Training loss: 1.0488988188320247
Validation loss: 2.5687893021091943

Epoch: 6| Step: 3
Training loss: 1.875571481715939
Validation loss: 2.5844955892946064

Epoch: 6| Step: 4
Training loss: 1.269855633888104
Validation loss: 2.4305250448566955

Epoch: 6| Step: 5
Training loss: 1.4656012852423668
Validation loss: 2.4414428534932466

Epoch: 6| Step: 6
Training loss: 1.2019392338180315
Validation loss: 2.4446248441312988

Epoch: 6| Step: 7
Training loss: 2.397464119778947
Validation loss: 2.4683000562916453

Epoch: 6| Step: 8
Training loss: 1.3445180427926653
Validation loss: 2.5100368075696675

Epoch: 6| Step: 9
Training loss: 1.5383412176545275
Validation loss: 2.5615093818535284

Epoch: 6| Step: 10
Training loss: 1.3982583895587959
Validation loss: 2.536273528518739

Epoch: 6| Step: 11
Training loss: 1.4209046458734642
Validation loss: 2.5894513705048583

Epoch: 6| Step: 12
Training loss: 1.374148321813891
Validation loss: 2.5126714359070443

Epoch: 6| Step: 13
Training loss: 1.5428260447506588
Validation loss: 2.4171110893064798

Epoch: 605| Step: 0
Training loss: 1.4825650875991567
Validation loss: 2.502258627950724

Epoch: 6| Step: 1
Training loss: 1.526343132507988
Validation loss: 2.4862636657725985

Epoch: 6| Step: 2
Training loss: 1.7387125573147826
Validation loss: 2.5597312790150646

Epoch: 6| Step: 3
Training loss: 0.8561514999648303
Validation loss: 2.401236823391841

Epoch: 6| Step: 4
Training loss: 1.0274621583416275
Validation loss: 2.5941810640124956

Epoch: 6| Step: 5
Training loss: 1.4883735207617366
Validation loss: 2.453198804568738

Epoch: 6| Step: 6
Training loss: 2.3380360442581907
Validation loss: 2.539924404361967

Epoch: 6| Step: 7
Training loss: 1.1873592494068927
Validation loss: 2.492023428799275

Epoch: 6| Step: 8
Training loss: 1.4577275880082856
Validation loss: 2.5111242454577467

Epoch: 6| Step: 9
Training loss: 1.1960581529379541
Validation loss: 2.5613742639640735

Epoch: 6| Step: 10
Training loss: 1.54658767651954
Validation loss: 2.500096128522955

Epoch: 6| Step: 11
Training loss: 1.5909760213372075
Validation loss: 2.448831967733748

Epoch: 6| Step: 12
Training loss: 1.2911105907329343
Validation loss: 2.5576243152371947

Epoch: 6| Step: 13
Training loss: 0.8748537009413001
Validation loss: 2.524139078184135

Epoch: 606| Step: 0
Training loss: 1.3151921409666811
Validation loss: 2.4353493541493076

Epoch: 6| Step: 1
Training loss: 1.2716807786517645
Validation loss: 2.5205373782686027

Epoch: 6| Step: 2
Training loss: 1.4176359600547943
Validation loss: 2.4962441811512326

Epoch: 6| Step: 3
Training loss: 1.034613931495054
Validation loss: 2.6626227105276454

Epoch: 6| Step: 4
Training loss: 1.9247256591304225
Validation loss: 2.562747256087572

Epoch: 6| Step: 5
Training loss: 1.8447929923686242
Validation loss: 2.557839754775651

Epoch: 6| Step: 6
Training loss: 1.639388644895731
Validation loss: 2.505345131005711

Epoch: 6| Step: 7
Training loss: 1.3419134764003364
Validation loss: 2.5280483141382897

Epoch: 6| Step: 8
Training loss: 1.4783446037926564
Validation loss: 2.383555931663849

Epoch: 6| Step: 9
Training loss: 1.28111080250916
Validation loss: 2.3904883243558364

Epoch: 6| Step: 10
Training loss: 2.2536069780395396
Validation loss: 2.4930031189793276

Epoch: 6| Step: 11
Training loss: 1.1671340664604077
Validation loss: 2.5187638697894625

Epoch: 6| Step: 12
Training loss: 1.6997897186374111
Validation loss: 2.573823333077838

Epoch: 6| Step: 13
Training loss: 1.7239172508976481
Validation loss: 2.455253850423335

Epoch: 607| Step: 0
Training loss: 1.9530723869866715
Validation loss: 2.5846362848895934

Epoch: 6| Step: 1
Training loss: 1.5535611620534038
Validation loss: 2.596101358512585

Epoch: 6| Step: 2
Training loss: 1.2788732861166305
Validation loss: 2.552184866383292

Epoch: 6| Step: 3
Training loss: 2.522969677906571
Validation loss: 2.5219832905722623

Epoch: 6| Step: 4
Training loss: 0.8846313846298981
Validation loss: 2.4962580517631254

Epoch: 6| Step: 5
Training loss: 1.7656666573530537
Validation loss: 2.5632293617609054

Epoch: 6| Step: 6
Training loss: 1.377469013509455
Validation loss: 2.503637252072007

Epoch: 6| Step: 7
Training loss: 1.629563891806034
Validation loss: 2.453268973490878

Epoch: 6| Step: 8
Training loss: 1.245818104645566
Validation loss: 2.5134749995770065

Epoch: 6| Step: 9
Training loss: 1.5637414959158673
Validation loss: 2.5247827980487507

Epoch: 6| Step: 10
Training loss: 1.0721941925880627
Validation loss: 2.4798303727207327

Epoch: 6| Step: 11
Training loss: 1.3534522544040766
Validation loss: 2.546019226600044

Epoch: 6| Step: 12
Training loss: 1.4158522939207618
Validation loss: 2.4676713893854094

Epoch: 6| Step: 13
Training loss: 1.3486188463817945
Validation loss: 2.5871144356277034

Epoch: 608| Step: 0
Training loss: 1.1937858456327728
Validation loss: 2.57144083919291

Epoch: 6| Step: 1
Training loss: 1.546907212663728
Validation loss: 2.50958494667083

Epoch: 6| Step: 2
Training loss: 1.8204239577850763
Validation loss: 2.435991005775358

Epoch: 6| Step: 3
Training loss: 1.511495805412123
Validation loss: 2.577916199204692

Epoch: 6| Step: 4
Training loss: 1.5737855376699526
Validation loss: 2.6118679692626183

Epoch: 6| Step: 5
Training loss: 1.110181488458934
Validation loss: 2.493245084582848

Epoch: 6| Step: 6
Training loss: 1.4281041283616127
Validation loss: 2.50500529687672

Epoch: 6| Step: 7
Training loss: 2.3112555583517724
Validation loss: 2.45943080903771

Epoch: 6| Step: 8
Training loss: 1.513157753540661
Validation loss: 2.5165949308095588

Epoch: 6| Step: 9
Training loss: 1.3515531506518215
Validation loss: 2.5073464934700245

Epoch: 6| Step: 10
Training loss: 1.3689521953743362
Validation loss: 2.495898031738025

Epoch: 6| Step: 11
Training loss: 1.7942027248380161
Validation loss: 2.4966948749841285

Epoch: 6| Step: 12
Training loss: 1.587289844329478
Validation loss: 2.52666062710199

Epoch: 6| Step: 13
Training loss: 1.206958854997999
Validation loss: 2.519387314438646

Epoch: 609| Step: 0
Training loss: 1.4643124036317139
Validation loss: 2.4727129227051203

Epoch: 6| Step: 1
Training loss: 1.2494555241186012
Validation loss: 2.4954445948510875

Epoch: 6| Step: 2
Training loss: 1.7799248032277273
Validation loss: 2.5974371941789314

Epoch: 6| Step: 3
Training loss: 2.0871183217774503
Validation loss: 2.486813775926135

Epoch: 6| Step: 4
Training loss: 1.368659268163339
Validation loss: 2.487105402775824

Epoch: 6| Step: 5
Training loss: 1.5209547107632735
Validation loss: 2.516414094887936

Epoch: 6| Step: 6
Training loss: 1.3537127638862165
Validation loss: 2.5236444927131916

Epoch: 6| Step: 7
Training loss: 1.3648669794963026
Validation loss: 2.515202420480627

Epoch: 6| Step: 8
Training loss: 1.062646631332771
Validation loss: 2.4546320001291906

Epoch: 6| Step: 9
Training loss: 1.750527166256567
Validation loss: 2.4909643735527482

Epoch: 6| Step: 10
Training loss: 1.1980398142444568
Validation loss: 2.449807137739302

Epoch: 6| Step: 11
Training loss: 1.339292896796449
Validation loss: 2.59373709750435

Epoch: 6| Step: 12
Training loss: 1.5149067228703563
Validation loss: 2.4587753076571586

Epoch: 6| Step: 13
Training loss: 1.4180793824136433
Validation loss: 2.5055135154269794

Epoch: 610| Step: 0
Training loss: 1.6692107175415762
Validation loss: 2.5136309061350595

Epoch: 6| Step: 1
Training loss: 1.3540039942920545
Validation loss: 2.5578928553791656

Epoch: 6| Step: 2
Training loss: 1.6773899422029857
Validation loss: 2.6358231200218736

Epoch: 6| Step: 3
Training loss: 2.2391691194479932
Validation loss: 2.470994656054321

Epoch: 6| Step: 4
Training loss: 1.4336805603186662
Validation loss: 2.551320314305734

Epoch: 6| Step: 5
Training loss: 1.3418424951163732
Validation loss: 2.6234411356362815

Epoch: 6| Step: 6
Training loss: 1.2330318338008142
Validation loss: 2.556076657054937

Epoch: 6| Step: 7
Training loss: 1.5519033067313193
Validation loss: 2.666403481227016

Epoch: 6| Step: 8
Training loss: 1.443398027328363
Validation loss: 2.5009279538796085

Epoch: 6| Step: 9
Training loss: 1.5768327615579159
Validation loss: 2.5669924865490237

Epoch: 6| Step: 10
Training loss: 1.7267812875067365
Validation loss: 2.599727189318398

Epoch: 6| Step: 11
Training loss: 1.5417222021599133
Validation loss: 2.5493120408548298

Epoch: 6| Step: 12
Training loss: 1.3109109432545023
Validation loss: 2.584118859274246

Epoch: 6| Step: 13
Training loss: 1.285145721856216
Validation loss: 2.5786960639307854

Epoch: 611| Step: 0
Training loss: 1.367695741191151
Validation loss: 2.476197527135943

Epoch: 6| Step: 1
Training loss: 0.980163648332051
Validation loss: 2.531877494360382

Epoch: 6| Step: 2
Training loss: 1.578494491379037
Validation loss: 2.552448326130063

Epoch: 6| Step: 3
Training loss: 1.015290307870602
Validation loss: 2.441886770693003

Epoch: 6| Step: 4
Training loss: 1.512261896859467
Validation loss: 2.4675678544918864

Epoch: 6| Step: 5
Training loss: 1.7616158939625086
Validation loss: 2.4669069674753628

Epoch: 6| Step: 6
Training loss: 1.2593014357215817
Validation loss: 2.52845198725526

Epoch: 6| Step: 7
Training loss: 0.9113542915181665
Validation loss: 2.4986045942367245

Epoch: 6| Step: 8
Training loss: 1.5291699664975076
Validation loss: 2.5498089238601014

Epoch: 6| Step: 9
Training loss: 1.6402070012525882
Validation loss: 2.502939280662883

Epoch: 6| Step: 10
Training loss: 1.4512431767686889
Validation loss: 2.540600888258261

Epoch: 6| Step: 11
Training loss: 2.2951618474933233
Validation loss: 2.5349258962101886

Epoch: 6| Step: 12
Training loss: 1.6030943453053383
Validation loss: 2.4643456920993545

Epoch: 6| Step: 13
Training loss: 1.5619767648089713
Validation loss: 2.4748595157982756

Epoch: 612| Step: 0
Training loss: 1.1951013515699378
Validation loss: 2.564258537285411

Epoch: 6| Step: 1
Training loss: 1.7718282111447343
Validation loss: 2.5408515507377776

Epoch: 6| Step: 2
Training loss: 1.2507454556663378
Validation loss: 2.587817931590865

Epoch: 6| Step: 3
Training loss: 1.1112926725555345
Validation loss: 2.568932027993838

Epoch: 6| Step: 4
Training loss: 1.536020516124443
Validation loss: 2.457971579282332

Epoch: 6| Step: 5
Training loss: 1.56904649706203
Validation loss: 2.500331735648563

Epoch: 6| Step: 6
Training loss: 1.086693480010661
Validation loss: 2.573584459746179

Epoch: 6| Step: 7
Training loss: 1.6353555250786147
Validation loss: 2.5965110413884385

Epoch: 6| Step: 8
Training loss: 1.0037174269924236
Validation loss: 2.490856525928222

Epoch: 6| Step: 9
Training loss: 2.1220897492854105
Validation loss: 2.528362559201954

Epoch: 6| Step: 10
Training loss: 1.281207665465091
Validation loss: 2.503187008338645

Epoch: 6| Step: 11
Training loss: 1.3771052716114467
Validation loss: 2.562385223363331

Epoch: 6| Step: 12
Training loss: 1.6275878254387999
Validation loss: 2.4069536296620613

Epoch: 6| Step: 13
Training loss: 1.3227159192617826
Validation loss: 2.5143971122547604

Epoch: 613| Step: 0
Training loss: 1.5918365660791591
Validation loss: 2.568373546875508

Epoch: 6| Step: 1
Training loss: 1.2980144963917073
Validation loss: 2.5294442637536556

Epoch: 6| Step: 2
Training loss: 1.2843667245862793
Validation loss: 2.501357331508971

Epoch: 6| Step: 3
Training loss: 0.9011240059747504
Validation loss: 2.543038878521305

Epoch: 6| Step: 4
Training loss: 1.196505231983751
Validation loss: 2.421371201675733

Epoch: 6| Step: 5
Training loss: 1.7305856497311243
Validation loss: 2.5622739724699817

Epoch: 6| Step: 6
Training loss: 2.5358312146189155
Validation loss: 2.612577420858895

Epoch: 6| Step: 7
Training loss: 1.2904387092534781
Validation loss: 2.5028647472936574

Epoch: 6| Step: 8
Training loss: 1.291118946644404
Validation loss: 2.5170805403003356

Epoch: 6| Step: 9
Training loss: 1.704167458208393
Validation loss: 2.6101388121001974

Epoch: 6| Step: 10
Training loss: 1.334879495275412
Validation loss: 2.4195669671518467

Epoch: 6| Step: 11
Training loss: 1.5553609644946274
Validation loss: 2.49913626691038

Epoch: 6| Step: 12
Training loss: 1.2580782212772188
Validation loss: 2.507387597735556

Epoch: 6| Step: 13
Training loss: 1.0621213799345681
Validation loss: 2.490589828264485

Epoch: 614| Step: 0
Training loss: 2.4414656242780177
Validation loss: 2.520957124728783

Epoch: 6| Step: 1
Training loss: 1.7864738293152713
Validation loss: 2.527720956363938

Epoch: 6| Step: 2
Training loss: 1.4230408971275073
Validation loss: 2.569349656984522

Epoch: 6| Step: 3
Training loss: 1.6231928827414563
Validation loss: 2.4651442905328342

Epoch: 6| Step: 4
Training loss: 1.0216343260889809
Validation loss: 2.529041918299812

Epoch: 6| Step: 5
Training loss: 1.3738597129767478
Validation loss: 2.522854675873769

Epoch: 6| Step: 6
Training loss: 1.1342610010290866
Validation loss: 2.5368053000783553

Epoch: 6| Step: 7
Training loss: 1.6525960959513852
Validation loss: 2.6029487278663264

Epoch: 6| Step: 8
Training loss: 1.6376038845975913
Validation loss: 2.4687854187453375

Epoch: 6| Step: 9
Training loss: 1.3942545127364698
Validation loss: 2.4278977117674216

Epoch: 6| Step: 10
Training loss: 1.265253742537346
Validation loss: 2.5275127572911353

Epoch: 6| Step: 11
Training loss: 1.458100036852157
Validation loss: 2.490332275370745

Epoch: 6| Step: 12
Training loss: 1.5023638060882978
Validation loss: 2.607296892376669

Epoch: 6| Step: 13
Training loss: 1.431628551146009
Validation loss: 2.5850584566355206

Epoch: 615| Step: 0
Training loss: 1.4735392950984438
Validation loss: 2.560564330004998

Epoch: 6| Step: 1
Training loss: 1.4140861045595485
Validation loss: 2.5090454329756486

Epoch: 6| Step: 2
Training loss: 1.0994933695608409
Validation loss: 2.517571245380406

Epoch: 6| Step: 3
Training loss: 1.170034565537276
Validation loss: 2.567641839309597

Epoch: 6| Step: 4
Training loss: 1.7496894833416743
Validation loss: 2.5431685744946955

Epoch: 6| Step: 5
Training loss: 1.4628561548060461
Validation loss: 2.6045150953614296

Epoch: 6| Step: 6
Training loss: 1.5671039654118115
Validation loss: 2.5322129354824523

Epoch: 6| Step: 7
Training loss: 1.718776355888124
Validation loss: 2.5086816132679224

Epoch: 6| Step: 8
Training loss: 1.1461391156559153
Validation loss: 2.5351282881660326

Epoch: 6| Step: 9
Training loss: 1.3238512277486734
Validation loss: 2.5833873779513254

Epoch: 6| Step: 10
Training loss: 1.5708459356124571
Validation loss: 2.5674119118581675

Epoch: 6| Step: 11
Training loss: 1.3872764218251759
Validation loss: 2.6748972443962917

Epoch: 6| Step: 12
Training loss: 1.2848567903625379
Validation loss: 2.408784209180363

Epoch: 6| Step: 13
Training loss: 3.17145163430723
Validation loss: 2.5052209317885716

Epoch: 616| Step: 0
Training loss: 2.1916213312524655
Validation loss: 2.47921450279152

Epoch: 6| Step: 1
Training loss: 1.2580617811652084
Validation loss: 2.5477111976717204

Epoch: 6| Step: 2
Training loss: 1.2077240668489297
Validation loss: 2.4229578218073904

Epoch: 6| Step: 3
Training loss: 1.1438638349073014
Validation loss: 2.400868257665073

Epoch: 6| Step: 4
Training loss: 1.775053388840359
Validation loss: 2.5654432090282615

Epoch: 6| Step: 5
Training loss: 1.1851509350611604
Validation loss: 2.4548237984147967

Epoch: 6| Step: 6
Training loss: 1.7527130078041384
Validation loss: 2.5169098679169846

Epoch: 6| Step: 7
Training loss: 1.319751868768212
Validation loss: 2.5488817985596666

Epoch: 6| Step: 8
Training loss: 1.2820496273641424
Validation loss: 2.527158837781942

Epoch: 6| Step: 9
Training loss: 1.3403153993446688
Validation loss: 2.440168585394102

Epoch: 6| Step: 10
Training loss: 1.9050061279358512
Validation loss: 2.478144923140932

Epoch: 6| Step: 11
Training loss: 1.128861528718564
Validation loss: 2.4585985909985757

Epoch: 6| Step: 12
Training loss: 1.4031836244701985
Validation loss: 2.492909350608746

Epoch: 6| Step: 13
Training loss: 1.1692785873099345
Validation loss: 2.5274003548049344

Epoch: 617| Step: 0
Training loss: 1.343215081845006
Validation loss: 2.5181869498376726

Epoch: 6| Step: 1
Training loss: 1.3566503733672712
Validation loss: 2.563741972747474

Epoch: 6| Step: 2
Training loss: 1.8394167135202897
Validation loss: 2.5293187489404882

Epoch: 6| Step: 3
Training loss: 1.395056788474741
Validation loss: 2.5799951556383562

Epoch: 6| Step: 4
Training loss: 1.8972962642251088
Validation loss: 2.467318554312248

Epoch: 6| Step: 5
Training loss: 1.231747595451583
Validation loss: 2.490027758499652

Epoch: 6| Step: 6
Training loss: 0.9339886711912052
Validation loss: 2.588938733480047

Epoch: 6| Step: 7
Training loss: 1.4771632027206485
Validation loss: 2.4884288196293047

Epoch: 6| Step: 8
Training loss: 1.303209575588859
Validation loss: 2.603635505568958

Epoch: 6| Step: 9
Training loss: 2.139810560344391
Validation loss: 2.4532757617341194

Epoch: 6| Step: 10
Training loss: 1.37419746560274
Validation loss: 2.5266652923936532

Epoch: 6| Step: 11
Training loss: 1.1332702764097895
Validation loss: 2.4591219745754733

Epoch: 6| Step: 12
Training loss: 1.6299537565540436
Validation loss: 2.5696585993794514

Epoch: 6| Step: 13
Training loss: 0.932195789940982
Validation loss: 2.4431502234665476

Epoch: 618| Step: 0
Training loss: 1.5107724877779116
Validation loss: 2.4541344599281287

Epoch: 6| Step: 1
Training loss: 1.3737984956437372
Validation loss: 2.5518090635432626

Epoch: 6| Step: 2
Training loss: 1.2635734791012403
Validation loss: 2.5765831238040953

Epoch: 6| Step: 3
Training loss: 1.6342987888867848
Validation loss: 2.6622590506304156

Epoch: 6| Step: 4
Training loss: 1.530033484697127
Validation loss: 2.488177745343985

Epoch: 6| Step: 5
Training loss: 1.0865805937802244
Validation loss: 2.470629829844533

Epoch: 6| Step: 6
Training loss: 2.1546557517475544
Validation loss: 2.422646026722561

Epoch: 6| Step: 7
Training loss: 1.5038043891792965
Validation loss: 2.4623337443381206

Epoch: 6| Step: 8
Training loss: 1.0480554103326032
Validation loss: 2.475093040320961

Epoch: 6| Step: 9
Training loss: 1.5089696683470661
Validation loss: 2.5541261210023176

Epoch: 6| Step: 10
Training loss: 1.411714152933984
Validation loss: 2.494441888005054

Epoch: 6| Step: 11
Training loss: 1.3842448774025622
Validation loss: 2.4193805785501894

Epoch: 6| Step: 12
Training loss: 1.5647140837723958
Validation loss: 2.5282446043196214

Epoch: 6| Step: 13
Training loss: 1.4114556494355344
Validation loss: 2.616263292370563

Epoch: 619| Step: 0
Training loss: 1.4737051307118316
Validation loss: 2.489915944409668

Epoch: 6| Step: 1
Training loss: 1.2863201216406142
Validation loss: 2.570667726912646

Epoch: 6| Step: 2
Training loss: 1.8323140200635202
Validation loss: 2.538983534728

Epoch: 6| Step: 3
Training loss: 1.175493731148967
Validation loss: 2.551312044549676

Epoch: 6| Step: 4
Training loss: 1.495557484742826
Validation loss: 2.5932927811573188

Epoch: 6| Step: 5
Training loss: 1.6834160164396434
Validation loss: 2.602663853986534

Epoch: 6| Step: 6
Training loss: 2.562631929304388
Validation loss: 2.4931916045042244

Epoch: 6| Step: 7
Training loss: 1.1998371430990216
Validation loss: 2.535413660138371

Epoch: 6| Step: 8
Training loss: 1.2674802204522446
Validation loss: 2.555904362914311

Epoch: 6| Step: 9
Training loss: 1.7481008851642157
Validation loss: 2.5356071280170855

Epoch: 6| Step: 10
Training loss: 1.7292157667917958
Validation loss: 2.520234348936303

Epoch: 6| Step: 11
Training loss: 1.1670956617632786
Validation loss: 2.5401773286875393

Epoch: 6| Step: 12
Training loss: 1.0338239048805604
Validation loss: 2.4924726497628082

Epoch: 6| Step: 13
Training loss: 1.3206921996437895
Validation loss: 2.4855269670455096

Epoch: 620| Step: 0
Training loss: 1.5569040417805138
Validation loss: 2.5462423948530737

Epoch: 6| Step: 1
Training loss: 1.4245927429483516
Validation loss: 2.5398778250335976

Epoch: 6| Step: 2
Training loss: 1.1741895071767752
Validation loss: 2.547221814631099

Epoch: 6| Step: 3
Training loss: 1.3326418196050849
Validation loss: 2.5765828213311064

Epoch: 6| Step: 4
Training loss: 1.441550146844257
Validation loss: 2.420308650626144

Epoch: 6| Step: 5
Training loss: 2.252969689379919
Validation loss: 2.496518911924933

Epoch: 6| Step: 6
Training loss: 1.385242589851226
Validation loss: 2.494380441172763

Epoch: 6| Step: 7
Training loss: 1.7119852977148124
Validation loss: 2.505089593515313

Epoch: 6| Step: 8
Training loss: 1.6927622233884563
Validation loss: 2.443843648472734

Epoch: 6| Step: 9
Training loss: 1.633121005030409
Validation loss: 2.5634975597578364

Epoch: 6| Step: 10
Training loss: 1.21559134782434
Validation loss: 2.451082426258831

Epoch: 6| Step: 11
Training loss: 1.1549303927233592
Validation loss: 2.589694688235081

Epoch: 6| Step: 12
Training loss: 1.271016634036149
Validation loss: 2.5017453346307192

Epoch: 6| Step: 13
Training loss: 1.5024396606871562
Validation loss: 2.528519677480737

Epoch: 621| Step: 0
Training loss: 2.066227867344858
Validation loss: 2.5345833930329245

Epoch: 6| Step: 1
Training loss: 1.22830887405667
Validation loss: 2.495655854928241

Epoch: 6| Step: 2
Training loss: 1.3311244529302446
Validation loss: 2.581395910961415

Epoch: 6| Step: 3
Training loss: 1.3326112262045142
Validation loss: 2.5035210988113397

Epoch: 6| Step: 4
Training loss: 1.256414169288463
Validation loss: 2.5247991620300896

Epoch: 6| Step: 5
Training loss: 1.5603211278999656
Validation loss: 2.6314707737007352

Epoch: 6| Step: 6
Training loss: 1.3202827043952163
Validation loss: 2.5748011268433495

Epoch: 6| Step: 7
Training loss: 1.4933918192315374
Validation loss: 2.494288019614314

Epoch: 6| Step: 8
Training loss: 0.9913869616929551
Validation loss: 2.5224655577101616

Epoch: 6| Step: 9
Training loss: 1.0734225009719875
Validation loss: 2.5265281913213173

Epoch: 6| Step: 10
Training loss: 1.599342929508116
Validation loss: 2.5009875080223267

Epoch: 6| Step: 11
Training loss: 1.622380860220291
Validation loss: 2.5188784138346074

Epoch: 6| Step: 12
Training loss: 1.2102614453709695
Validation loss: 2.5143864483965594

Epoch: 6| Step: 13
Training loss: 1.6061894268088308
Validation loss: 2.5595066366102324

Epoch: 622| Step: 0
Training loss: 1.4016873409335615
Validation loss: 2.4956939909682028

Epoch: 6| Step: 1
Training loss: 0.8013960548387549
Validation loss: 2.408267684531711

Epoch: 6| Step: 2
Training loss: 1.6864452597959798
Validation loss: 2.5916095905872782

Epoch: 6| Step: 3
Training loss: 1.574693631847061
Validation loss: 2.586144021493063

Epoch: 6| Step: 4
Training loss: 1.2808800139862797
Validation loss: 2.4358559336623906

Epoch: 6| Step: 5
Training loss: 1.5726840202960994
Validation loss: 2.5205850305172466

Epoch: 6| Step: 6
Training loss: 0.9538493296443757
Validation loss: 2.534870209875781

Epoch: 6| Step: 7
Training loss: 1.2591945566252387
Validation loss: 2.453270143878984

Epoch: 6| Step: 8
Training loss: 1.3519484128872663
Validation loss: 2.5187858748964485

Epoch: 6| Step: 9
Training loss: 2.306851266776601
Validation loss: 2.473616966093584

Epoch: 6| Step: 10
Training loss: 1.5863032177714822
Validation loss: 2.5709038807241664

Epoch: 6| Step: 11
Training loss: 1.468675570935584
Validation loss: 2.428641788091308

Epoch: 6| Step: 12
Training loss: 1.406967446311884
Validation loss: 2.5102051724255636

Epoch: 6| Step: 13
Training loss: 1.2771933464138625
Validation loss: 2.5738894735169637

Epoch: 623| Step: 0
Training loss: 1.2298289255250279
Validation loss: 2.4659707191233307

Epoch: 6| Step: 1
Training loss: 1.1897676800502128
Validation loss: 2.5041250713312375

Epoch: 6| Step: 2
Training loss: 1.6488610758467879
Validation loss: 2.483192952566686

Epoch: 6| Step: 3
Training loss: 1.9492646175637336
Validation loss: 2.5763181936097377

Epoch: 6| Step: 4
Training loss: 1.765221136034631
Validation loss: 2.426901619907789

Epoch: 6| Step: 5
Training loss: 2.2399407271649308
Validation loss: 2.5243800975735895

Epoch: 6| Step: 6
Training loss: 1.24806535734004
Validation loss: 2.5806053145726606

Epoch: 6| Step: 7
Training loss: 1.4559461219271934
Validation loss: 2.5244531299785007

Epoch: 6| Step: 8
Training loss: 1.2487582714887506
Validation loss: 2.491386968811343

Epoch: 6| Step: 9
Training loss: 1.8426551801118323
Validation loss: 2.475499867255726

Epoch: 6| Step: 10
Training loss: 1.69200564153105
Validation loss: 2.5923153452590997

Epoch: 6| Step: 11
Training loss: 1.214867496565039
Validation loss: 2.511010830637061

Epoch: 6| Step: 12
Training loss: 0.8885614682875997
Validation loss: 2.641300782643095

Epoch: 6| Step: 13
Training loss: 1.12758752165998
Validation loss: 2.554610620356472

Epoch: 624| Step: 0
Training loss: 1.0949316453718945
Validation loss: 2.513708597507424

Epoch: 6| Step: 1
Training loss: 1.6311255688911503
Validation loss: 2.6108789980803104

Epoch: 6| Step: 2
Training loss: 1.6865150968326617
Validation loss: 2.4415203056355517

Epoch: 6| Step: 3
Training loss: 1.21019540012931
Validation loss: 2.554841053664768

Epoch: 6| Step: 4
Training loss: 1.7315060367682782
Validation loss: 2.5856246449185574

Epoch: 6| Step: 5
Training loss: 1.5379856428113678
Validation loss: 2.6327509110464398

Epoch: 6| Step: 6
Training loss: 1.4640930693701093
Validation loss: 2.555233716390714

Epoch: 6| Step: 7
Training loss: 1.3557057462064699
Validation loss: 2.545961292731914

Epoch: 6| Step: 8
Training loss: 1.1464937329925793
Validation loss: 2.573672097320475

Epoch: 6| Step: 9
Training loss: 1.722777070460126
Validation loss: 2.553069123233682

Epoch: 6| Step: 10
Training loss: 1.3011871254541727
Validation loss: 2.529939177125438

Epoch: 6| Step: 11
Training loss: 0.8074417384951982
Validation loss: 2.5486328548076735

Epoch: 6| Step: 12
Training loss: 0.9631118984432882
Validation loss: 2.4921032031128276

Epoch: 6| Step: 13
Training loss: 2.6429936546800863
Validation loss: 2.550017947592843

Epoch: 625| Step: 0
Training loss: 1.6889457866986448
Validation loss: 2.525407202282643

Epoch: 6| Step: 1
Training loss: 1.6785099603825029
Validation loss: 2.457403565772405

Epoch: 6| Step: 2
Training loss: 1.0084012699623086
Validation loss: 2.5258036034543534

Epoch: 6| Step: 3
Training loss: 1.2630418389005784
Validation loss: 2.5196905285607136

Epoch: 6| Step: 4
Training loss: 1.6054235298860826
Validation loss: 2.4372065851070897

Epoch: 6| Step: 5
Training loss: 2.453502844607296
Validation loss: 2.5288464533669415

Epoch: 6| Step: 6
Training loss: 1.318995976219952
Validation loss: 2.5652276545291093

Epoch: 6| Step: 7
Training loss: 1.6555083431677702
Validation loss: 2.5961137268750014

Epoch: 6| Step: 8
Training loss: 1.6042952135113215
Validation loss: 2.480209142438428

Epoch: 6| Step: 9
Training loss: 1.2594668011774377
Validation loss: 2.4960590700161056

Epoch: 6| Step: 10
Training loss: 1.047855601165184
Validation loss: 2.6565727332193254

Epoch: 6| Step: 11
Training loss: 1.6374194846123753
Validation loss: 2.529244549488331

Epoch: 6| Step: 12
Training loss: 1.0206839523529407
Validation loss: 2.563309651384142

Epoch: 6| Step: 13
Training loss: 1.422273936217262
Validation loss: 2.494919047774243

Epoch: 626| Step: 0
Training loss: 1.2187793434718732
Validation loss: 2.5454398507405362

Epoch: 6| Step: 1
Training loss: 1.3696292544005797
Validation loss: 2.4824590690766226

Epoch: 6| Step: 2
Training loss: 1.4463700008475724
Validation loss: 2.558145927284933

Epoch: 6| Step: 3
Training loss: 2.2568840044846095
Validation loss: 2.4968221145021756

Epoch: 6| Step: 4
Training loss: 1.3404307066791121
Validation loss: 2.537831467278744

Epoch: 6| Step: 5
Training loss: 1.0873056479234464
Validation loss: 2.6167634696707944

Epoch: 6| Step: 6
Training loss: 1.3052425003552335
Validation loss: 2.5723278827869276

Epoch: 6| Step: 7
Training loss: 1.3170323001026019
Validation loss: 2.6476196319451404

Epoch: 6| Step: 8
Training loss: 1.1977109096568177
Validation loss: 2.5856097942248244

Epoch: 6| Step: 9
Training loss: 1.0329159083228323
Validation loss: 2.6106988934130193

Epoch: 6| Step: 10
Training loss: 1.710206036564016
Validation loss: 2.577712210991906

Epoch: 6| Step: 11
Training loss: 2.0317091202883573
Validation loss: 2.5221675347896766

Epoch: 6| Step: 12
Training loss: 0.9690294170421967
Validation loss: 2.6447064974239725

Epoch: 6| Step: 13
Training loss: 1.6528664341646704
Validation loss: 2.5139786659053276

Epoch: 627| Step: 0
Training loss: 1.2201763511835784
Validation loss: 2.5600201252112926

Epoch: 6| Step: 1
Training loss: 1.1706801362910142
Validation loss: 2.35052259778819

Epoch: 6| Step: 2
Training loss: 1.6009280553089031
Validation loss: 2.4834142710425047

Epoch: 6| Step: 3
Training loss: 1.351559368857577
Validation loss: 2.5542868785863497

Epoch: 6| Step: 4
Training loss: 1.264241816718434
Validation loss: 2.534129967645245

Epoch: 6| Step: 5
Training loss: 1.081098684847403
Validation loss: 2.609493778289319

Epoch: 6| Step: 6
Training loss: 1.6232839473180918
Validation loss: 2.466505938096151

Epoch: 6| Step: 7
Training loss: 2.4223390196231347
Validation loss: 2.646796032869462

Epoch: 6| Step: 8
Training loss: 1.4548903376097508
Validation loss: 2.469865634359496

Epoch: 6| Step: 9
Training loss: 1.679622631151102
Validation loss: 2.5394733802649387

Epoch: 6| Step: 10
Training loss: 1.1272473670114853
Validation loss: 2.592287798228816

Epoch: 6| Step: 11
Training loss: 1.264115221883307
Validation loss: 2.563013825122738

Epoch: 6| Step: 12
Training loss: 1.4388645164327216
Validation loss: 2.4784770260411837

Epoch: 6| Step: 13
Training loss: 1.5648147984081888
Validation loss: 2.387401196115225

Epoch: 628| Step: 0
Training loss: 1.4274508798836445
Validation loss: 2.545747637422069

Epoch: 6| Step: 1
Training loss: 1.7405991776638112
Validation loss: 2.603670239703035

Epoch: 6| Step: 2
Training loss: 1.600330157786861
Validation loss: 2.4537015474756756

Epoch: 6| Step: 3
Training loss: 1.297587555152774
Validation loss: 2.5695134889090854

Epoch: 6| Step: 4
Training loss: 1.2841964894635147
Validation loss: 2.5834134678580045

Epoch: 6| Step: 5
Training loss: 1.414710049391566
Validation loss: 2.5450152672144646

Epoch: 6| Step: 6
Training loss: 2.114797672126287
Validation loss: 2.5442883600311927

Epoch: 6| Step: 7
Training loss: 1.4406344200372434
Validation loss: 2.6762724332540784

Epoch: 6| Step: 8
Training loss: 1.4411784666626881
Validation loss: 2.5749508964650674

Epoch: 6| Step: 9
Training loss: 1.4839259221232182
Validation loss: 2.6354500335859936

Epoch: 6| Step: 10
Training loss: 1.8223658428866099
Validation loss: 2.659771736286951

Epoch: 6| Step: 11
Training loss: 1.1735859905215458
Validation loss: 2.689739826870102

Epoch: 6| Step: 12
Training loss: 1.4619306972375232
Validation loss: 2.514702150412553

Epoch: 6| Step: 13
Training loss: 1.1926567643967974
Validation loss: 2.5735714436996506

Epoch: 629| Step: 0
Training loss: 1.4422959473938677
Validation loss: 2.5152036252435046

Epoch: 6| Step: 1
Training loss: 1.4723843999022264
Validation loss: 2.502002261883593

Epoch: 6| Step: 2
Training loss: 1.1364017319795972
Validation loss: 2.5093558743276874

Epoch: 6| Step: 3
Training loss: 1.374364922986595
Validation loss: 2.4494084131386247

Epoch: 6| Step: 4
Training loss: 2.2959765279414137
Validation loss: 2.5502521946341727

Epoch: 6| Step: 5
Training loss: 0.9762600544840349
Validation loss: 2.470702259628259

Epoch: 6| Step: 6
Training loss: 1.3439133123472384
Validation loss: 2.516726757081366

Epoch: 6| Step: 7
Training loss: 1.7207518277328298
Validation loss: 2.593027391034384

Epoch: 6| Step: 8
Training loss: 1.5373869164291385
Validation loss: 2.523556106245185

Epoch: 6| Step: 9
Training loss: 1.2589084281585323
Validation loss: 2.5170178917297448

Epoch: 6| Step: 10
Training loss: 1.1362585335590463
Validation loss: 2.4381854952637942

Epoch: 6| Step: 11
Training loss: 1.5675419141407003
Validation loss: 2.4931740017179447

Epoch: 6| Step: 12
Training loss: 1.451508227628227
Validation loss: 2.489118487257934

Epoch: 6| Step: 13
Training loss: 1.9218218416135013
Validation loss: 2.5037945631967213

Epoch: 630| Step: 0
Training loss: 1.4052091349191078
Validation loss: 2.5563519505226404

Epoch: 6| Step: 1
Training loss: 0.9295571500292993
Validation loss: 2.531648050313892

Epoch: 6| Step: 2
Training loss: 1.3727668921703178
Validation loss: 2.482041980919131

Epoch: 6| Step: 3
Training loss: 1.7984723496229789
Validation loss: 2.5160349758496525

Epoch: 6| Step: 4
Training loss: 2.3046214983266378
Validation loss: 2.512064160390884

Epoch: 6| Step: 5
Training loss: 1.3133438667288053
Validation loss: 2.5702261143628298

Epoch: 6| Step: 6
Training loss: 1.3037625991929365
Validation loss: 2.5604519286620744

Epoch: 6| Step: 7
Training loss: 1.3524048225632765
Validation loss: 2.4962093142868125

Epoch: 6| Step: 8
Training loss: 1.4724072314121341
Validation loss: 2.5880278463236044

Epoch: 6| Step: 9
Training loss: 0.8965353691540708
Validation loss: 2.552362713935945

Epoch: 6| Step: 10
Training loss: 1.1862237496883317
Validation loss: 2.4843505210132264

Epoch: 6| Step: 11
Training loss: 1.214241590018755
Validation loss: 2.6367100354000876

Epoch: 6| Step: 12
Training loss: 1.6680868852933943
Validation loss: 2.5123926622929447

Epoch: 6| Step: 13
Training loss: 1.2912830993309707
Validation loss: 2.5688227901350706

Epoch: 631| Step: 0
Training loss: 1.3772632006256493
Validation loss: 2.4783826987735944

Epoch: 6| Step: 1
Training loss: 1.2192881936400783
Validation loss: 2.623521532994893

Epoch: 6| Step: 2
Training loss: 1.6359858727066687
Validation loss: 2.5838146631290897

Epoch: 6| Step: 3
Training loss: 1.2988536401981579
Validation loss: 2.4899732862954482

Epoch: 6| Step: 4
Training loss: 1.5424662484011327
Validation loss: 2.4449269766872184

Epoch: 6| Step: 5
Training loss: 2.2065242218686643
Validation loss: 2.613148703122162

Epoch: 6| Step: 6
Training loss: 1.245884701404478
Validation loss: 2.534201482876328

Epoch: 6| Step: 7
Training loss: 1.2352202696257553
Validation loss: 2.552585254272413

Epoch: 6| Step: 8
Training loss: 0.9532064809522041
Validation loss: 2.5570796446506687

Epoch: 6| Step: 9
Training loss: 1.108205904602502
Validation loss: 2.5494828986124327

Epoch: 6| Step: 10
Training loss: 1.0518448562518785
Validation loss: 2.5272698460782026

Epoch: 6| Step: 11
Training loss: 1.59299413671091
Validation loss: 2.4668592505312605

Epoch: 6| Step: 12
Training loss: 1.4350624980010263
Validation loss: 2.4950196546942354

Epoch: 6| Step: 13
Training loss: 1.6230882990539606
Validation loss: 2.629437534904077

Epoch: 632| Step: 0
Training loss: 2.3146578026256095
Validation loss: 2.4938429919233522

Epoch: 6| Step: 1
Training loss: 1.3177901784133979
Validation loss: 2.4734309295672126

Epoch: 6| Step: 2
Training loss: 1.7903389853757172
Validation loss: 2.4860626069390483

Epoch: 6| Step: 3
Training loss: 1.4524762746215936
Validation loss: 2.5133109721200917

Epoch: 6| Step: 4
Training loss: 1.1565340054167992
Validation loss: 2.6146774448279033

Epoch: 6| Step: 5
Training loss: 1.297492190651738
Validation loss: 2.5159457514396024

Epoch: 6| Step: 6
Training loss: 1.345870983356935
Validation loss: 2.441319365893512

Epoch: 6| Step: 7
Training loss: 1.3291233125430362
Validation loss: 2.459384368863212

Epoch: 6| Step: 8
Training loss: 1.5109452824357645
Validation loss: 2.4832960559017905

Epoch: 6| Step: 9
Training loss: 1.1596634457148636
Validation loss: 2.5567872982950437

Epoch: 6| Step: 10
Training loss: 1.4441644181140285
Validation loss: 2.5536862597975745

Epoch: 6| Step: 11
Training loss: 0.8856588742946244
Validation loss: 2.592755934343321

Epoch: 6| Step: 12
Training loss: 1.6484885546836823
Validation loss: 2.507167395459721

Epoch: 6| Step: 13
Training loss: 1.2497240715656632
Validation loss: 2.592694566563463

Epoch: 633| Step: 0
Training loss: 2.357774102951879
Validation loss: 2.456330855305136

Epoch: 6| Step: 1
Training loss: 1.148136696379531
Validation loss: 2.4892890558197944

Epoch: 6| Step: 2
Training loss: 1.7279439379463521
Validation loss: 2.4915551595841507

Epoch: 6| Step: 3
Training loss: 1.0831876008729964
Validation loss: 2.515391051595269

Epoch: 6| Step: 4
Training loss: 1.2154862155485757
Validation loss: 2.3880568979884336

Epoch: 6| Step: 5
Training loss: 1.3659170296801395
Validation loss: 2.498374827062668

Epoch: 6| Step: 6
Training loss: 1.441683610732039
Validation loss: 2.497846908831656

Epoch: 6| Step: 7
Training loss: 1.833403181421635
Validation loss: 2.505615044451262

Epoch: 6| Step: 8
Training loss: 1.3123540342999611
Validation loss: 2.4801241076434306

Epoch: 6| Step: 9
Training loss: 1.4294065605919322
Validation loss: 2.590871426085041

Epoch: 6| Step: 10
Training loss: 1.0430298405161247
Validation loss: 2.5903472438188992

Epoch: 6| Step: 11
Training loss: 1.2524000967846287
Validation loss: 2.5379814942689856

Epoch: 6| Step: 12
Training loss: 1.4624056859049872
Validation loss: 2.553891099989214

Epoch: 6| Step: 13
Training loss: 1.3900185452054281
Validation loss: 2.529663554997962

Epoch: 634| Step: 0
Training loss: 1.4257264009141697
Validation loss: 2.5355558740405586

Epoch: 6| Step: 1
Training loss: 1.4133438897788275
Validation loss: 2.6258669943510604

Epoch: 6| Step: 2
Training loss: 1.4323389033995741
Validation loss: 2.616259505107157

Epoch: 6| Step: 3
Training loss: 1.1826586160876777
Validation loss: 2.6917903982063396

Epoch: 6| Step: 4
Training loss: 2.1994053166937717
Validation loss: 2.601178518669264

Epoch: 6| Step: 5
Training loss: 1.0995909450470405
Validation loss: 2.4870639622711264

Epoch: 6| Step: 6
Training loss: 1.5082502767270805
Validation loss: 2.5446236884096534

Epoch: 6| Step: 7
Training loss: 1.3289488985729703
Validation loss: 2.597866932407648

Epoch: 6| Step: 8
Training loss: 1.5557739448893066
Validation loss: 2.4730926404892877

Epoch: 6| Step: 9
Training loss: 1.2915345042305222
Validation loss: 2.5196533946822965

Epoch: 6| Step: 10
Training loss: 1.0669588327125983
Validation loss: 2.551474210278414

Epoch: 6| Step: 11
Training loss: 1.128485049965486
Validation loss: 2.5394477374032864

Epoch: 6| Step: 12
Training loss: 1.06496468946636
Validation loss: 2.5959158660012447

Epoch: 6| Step: 13
Training loss: 1.325237006457104
Validation loss: 2.5227988145454865

Epoch: 635| Step: 0
Training loss: 1.1235687900699658
Validation loss: 2.518167559979612

Epoch: 6| Step: 1
Training loss: 1.2465674955698758
Validation loss: 2.578578598078428

Epoch: 6| Step: 2
Training loss: 1.2365846774503575
Validation loss: 2.6401303240524334

Epoch: 6| Step: 3
Training loss: 1.677084960304877
Validation loss: 2.4808291666179962

Epoch: 6| Step: 4
Training loss: 1.1363605577253773
Validation loss: 2.5962215873601315

Epoch: 6| Step: 5
Training loss: 1.4091540127409212
Validation loss: 2.5608619188321082

Epoch: 6| Step: 6
Training loss: 1.0246505537058856
Validation loss: 2.4599077144826733

Epoch: 6| Step: 7
Training loss: 1.5504918825391587
Validation loss: 2.453026806614167

Epoch: 6| Step: 8
Training loss: 0.8260914648438218
Validation loss: 2.5565448737634915

Epoch: 6| Step: 9
Training loss: 1.1845023818952218
Validation loss: 2.5509701706772043

Epoch: 6| Step: 10
Training loss: 1.3495848193881332
Validation loss: 2.5737520382671635

Epoch: 6| Step: 11
Training loss: 1.5879623941153367
Validation loss: 2.6111278702125267

Epoch: 6| Step: 12
Training loss: 2.3784485926386356
Validation loss: 2.4847156427593156

Epoch: 6| Step: 13
Training loss: 1.5983601630660296
Validation loss: 2.5382246403556388

Epoch: 636| Step: 0
Training loss: 2.1423986284985186
Validation loss: 2.580446679419535

Epoch: 6| Step: 1
Training loss: 1.4014892950258167
Validation loss: 2.4875286268224768

Epoch: 6| Step: 2
Training loss: 1.2046242327472443
Validation loss: 2.49254666540678

Epoch: 6| Step: 3
Training loss: 1.5087802923743896
Validation loss: 2.6058961106047507

Epoch: 6| Step: 4
Training loss: 1.4294830342820768
Validation loss: 2.6030082249125734

Epoch: 6| Step: 5
Training loss: 0.9037233845233026
Validation loss: 2.5947782344212498

Epoch: 6| Step: 6
Training loss: 1.853511637451256
Validation loss: 2.6936748145348255

Epoch: 6| Step: 7
Training loss: 1.4973459605881658
Validation loss: 2.441723044697677

Epoch: 6| Step: 8
Training loss: 1.3666436557848474
Validation loss: 2.6742703554122156

Epoch: 6| Step: 9
Training loss: 1.2882473767085638
Validation loss: 2.4967143166000385

Epoch: 6| Step: 10
Training loss: 1.1798020869302406
Validation loss: 2.4961905486258167

Epoch: 6| Step: 11
Training loss: 1.4501728711173982
Validation loss: 2.4496784535367864

Epoch: 6| Step: 12
Training loss: 1.065076117235607
Validation loss: 2.4354130261731886

Epoch: 6| Step: 13
Training loss: 1.938386468210979
Validation loss: 2.5679367770196064

Epoch: 637| Step: 0
Training loss: 1.4402919690520122
Validation loss: 2.5287529100742763

Epoch: 6| Step: 1
Training loss: 1.2421681144689198
Validation loss: 2.6106584710876533

Epoch: 6| Step: 2
Training loss: 1.2656704929793956
Validation loss: 2.52280811469091

Epoch: 6| Step: 3
Training loss: 1.905678209942553
Validation loss: 2.5948715226588215

Epoch: 6| Step: 4
Training loss: 0.9804463782930751
Validation loss: 2.6468726195263312

Epoch: 6| Step: 5
Training loss: 1.5335990637494306
Validation loss: 2.625048282919527

Epoch: 6| Step: 6
Training loss: 1.847077034938729
Validation loss: 2.5683600727156617

Epoch: 6| Step: 7
Training loss: 1.198677263807809
Validation loss: 2.606911612361969

Epoch: 6| Step: 8
Training loss: 1.1547743169747633
Validation loss: 2.4303798253002875

Epoch: 6| Step: 9
Training loss: 1.5336919503391664
Validation loss: 2.583830438936174

Epoch: 6| Step: 10
Training loss: 1.2579500585173546
Validation loss: 2.609514982936411

Epoch: 6| Step: 11
Training loss: 1.060653091085637
Validation loss: 2.478555879317964

Epoch: 6| Step: 12
Training loss: 1.1582302971622909
Validation loss: 2.503886588806852

Epoch: 6| Step: 13
Training loss: 2.5835094289339975
Validation loss: 2.4347322514437386

Epoch: 638| Step: 0
Training loss: 1.2452549039188514
Validation loss: 2.536707970416324

Epoch: 6| Step: 1
Training loss: 1.211184962428989
Validation loss: 2.573547161148286

Epoch: 6| Step: 2
Training loss: 1.260472866518357
Validation loss: 2.5069633760944603

Epoch: 6| Step: 3
Training loss: 2.268569085760647
Validation loss: 2.556814920989512

Epoch: 6| Step: 4
Training loss: 1.4898338729619012
Validation loss: 2.5380927918155316

Epoch: 6| Step: 5
Training loss: 1.2893544646720556
Validation loss: 2.4977885093929673

Epoch: 6| Step: 6
Training loss: 1.5148177996060839
Validation loss: 2.545105593864594

Epoch: 6| Step: 7
Training loss: 1.5122034050045317
Validation loss: 2.5648498865527762

Epoch: 6| Step: 8
Training loss: 1.5978059208908133
Validation loss: 2.5021613899073283

Epoch: 6| Step: 9
Training loss: 1.1647996040846602
Validation loss: 2.4895267546218602

Epoch: 6| Step: 10
Training loss: 1.2853533005307778
Validation loss: 2.5202474344604857

Epoch: 6| Step: 11
Training loss: 1.22110550008967
Validation loss: 2.5290726143883338

Epoch: 6| Step: 12
Training loss: 1.1316813642327386
Validation loss: 2.412154769254431

Epoch: 6| Step: 13
Training loss: 1.5772289338252181
Validation loss: 2.5038740925092267

Epoch: 639| Step: 0
Training loss: 1.097754423156459
Validation loss: 2.5360262640223885

Epoch: 6| Step: 1
Training loss: 1.3410769645514249
Validation loss: 2.541556477154433

Epoch: 6| Step: 2
Training loss: 1.3185909265695217
Validation loss: 2.5842079252726666

Epoch: 6| Step: 3
Training loss: 1.3965635050515848
Validation loss: 2.492445236098791

Epoch: 6| Step: 4
Training loss: 2.2870612135327293
Validation loss: 2.548279241838235

Epoch: 6| Step: 5
Training loss: 1.3088917862565579
Validation loss: 2.6843635961955132

Epoch: 6| Step: 6
Training loss: 1.6636571972627872
Validation loss: 2.5480210281118096

Epoch: 6| Step: 7
Training loss: 1.6800397636612385
Validation loss: 2.5518974740460316

Epoch: 6| Step: 8
Training loss: 1.6294503526782464
Validation loss: 2.5699990256503855

Epoch: 6| Step: 9
Training loss: 1.1638069640414563
Validation loss: 2.5390972852572227

Epoch: 6| Step: 10
Training loss: 1.4047208313175177
Validation loss: 2.5365074247129296

Epoch: 6| Step: 11
Training loss: 1.2052053325662977
Validation loss: 2.50003237446978

Epoch: 6| Step: 12
Training loss: 1.2046814795911396
Validation loss: 2.432000515227555

Epoch: 6| Step: 13
Training loss: 1.071526333345132
Validation loss: 2.501577161831917

Epoch: 640| Step: 0
Training loss: 1.1839347826452224
Validation loss: 2.4493674599971116

Epoch: 6| Step: 1
Training loss: 1.0229775946056916
Validation loss: 2.496603174724687

Epoch: 6| Step: 2
Training loss: 1.4468336194178764
Validation loss: 2.508587017591858

Epoch: 6| Step: 3
Training loss: 1.7653239845986812
Validation loss: 2.5153489743250894

Epoch: 6| Step: 4
Training loss: 1.6307920521985746
Validation loss: 2.5202524066163514

Epoch: 6| Step: 5
Training loss: 1.6348264402610484
Validation loss: 2.454649251622371

Epoch: 6| Step: 6
Training loss: 1.196487049145875
Validation loss: 2.5464816941982784

Epoch: 6| Step: 7
Training loss: 1.140585284652113
Validation loss: 2.602062300140547

Epoch: 6| Step: 8
Training loss: 0.8640139823108901
Validation loss: 2.6248938597136435

Epoch: 6| Step: 9
Training loss: 1.2109500022981114
Validation loss: 2.5513041174156994

Epoch: 6| Step: 10
Training loss: 2.4191702228782375
Validation loss: 2.4483316981241887

Epoch: 6| Step: 11
Training loss: 1.0278500081934434
Validation loss: 2.5641159156936033

Epoch: 6| Step: 12
Training loss: 1.6099446594015117
Validation loss: 2.577252160884026

Epoch: 6| Step: 13
Training loss: 1.217144128225035
Validation loss: 2.641316464544626

Epoch: 641| Step: 0
Training loss: 1.221971118785495
Validation loss: 2.5614877998207057

Epoch: 6| Step: 1
Training loss: 1.5966232429816676
Validation loss: 2.532875560981487

Epoch: 6| Step: 2
Training loss: 1.917571358776608
Validation loss: 2.4056752198537827

Epoch: 6| Step: 3
Training loss: 1.1739427761253192
Validation loss: 2.5385528068017464

Epoch: 6| Step: 4
Training loss: 0.9698455215125715
Validation loss: 2.499345216833588

Epoch: 6| Step: 5
Training loss: 1.185933636042114
Validation loss: 2.4729427644752877

Epoch: 6| Step: 6
Training loss: 2.277860030056351
Validation loss: 2.5642643598754082

Epoch: 6| Step: 7
Training loss: 1.3618802192101294
Validation loss: 2.4397055242640127

Epoch: 6| Step: 8
Training loss: 1.4723933058524616
Validation loss: 2.4675345200629133

Epoch: 6| Step: 9
Training loss: 1.588229022501944
Validation loss: 2.5607884621604198

Epoch: 6| Step: 10
Training loss: 1.0861395778215506
Validation loss: 2.574306676688358

Epoch: 6| Step: 11
Training loss: 1.4823659049463669
Validation loss: 2.5240398218835707

Epoch: 6| Step: 12
Training loss: 0.7532434663156872
Validation loss: 2.5378751819991434

Epoch: 6| Step: 13
Training loss: 1.496813727858942
Validation loss: 2.4521664855943395

Epoch: 642| Step: 0
Training loss: 1.0172879030333946
Validation loss: 2.416425383859778

Epoch: 6| Step: 1
Training loss: 1.2631572636594368
Validation loss: 2.4679228223871146

Epoch: 6| Step: 2
Training loss: 1.989915157694822
Validation loss: 2.4415937428005527

Epoch: 6| Step: 3
Training loss: 1.631923305654132
Validation loss: 2.525659204184179

Epoch: 6| Step: 4
Training loss: 1.1107501251543461
Validation loss: 2.4973705810192692

Epoch: 6| Step: 5
Training loss: 1.5360940102577085
Validation loss: 2.5301060625589646

Epoch: 6| Step: 6
Training loss: 1.2408531267488814
Validation loss: 2.5034742292521734

Epoch: 6| Step: 7
Training loss: 1.5780239261703741
Validation loss: 2.583356284265521

Epoch: 6| Step: 8
Training loss: 1.424286777631497
Validation loss: 2.535090516801498

Epoch: 6| Step: 9
Training loss: 1.3552258628436713
Validation loss: 2.553089353576363

Epoch: 6| Step: 10
Training loss: 1.3461087837641692
Validation loss: 2.423106352290704

Epoch: 6| Step: 11
Training loss: 1.274360462683902
Validation loss: 2.4445128766493576

Epoch: 6| Step: 12
Training loss: 2.252767556205584
Validation loss: 2.4564022508093513

Epoch: 6| Step: 13
Training loss: 1.3567017765250882
Validation loss: 2.4703820351930834

Epoch: 643| Step: 0
Training loss: 1.2340637973634647
Validation loss: 2.5729856325328866

Epoch: 6| Step: 1
Training loss: 1.310130387143638
Validation loss: 2.4340820233507983

Epoch: 6| Step: 2
Training loss: 0.8580866780236411
Validation loss: 2.5185454215254515

Epoch: 6| Step: 3
Training loss: 2.2509052786638635
Validation loss: 2.47418145322669

Epoch: 6| Step: 4
Training loss: 1.579677233865434
Validation loss: 2.4491462689598498

Epoch: 6| Step: 5
Training loss: 1.6832655301303259
Validation loss: 2.593187269379635

Epoch: 6| Step: 6
Training loss: 1.5368602507179423
Validation loss: 2.557787124145389

Epoch: 6| Step: 7
Training loss: 1.4024107340591752
Validation loss: 2.5321478538195032

Epoch: 6| Step: 8
Training loss: 1.0694412249286847
Validation loss: 2.5419530527310283

Epoch: 6| Step: 9
Training loss: 1.3585382275810094
Validation loss: 2.490313312036246

Epoch: 6| Step: 10
Training loss: 1.2815519302776903
Validation loss: 2.4696474138175506

Epoch: 6| Step: 11
Training loss: 1.0213266984020217
Validation loss: 2.449566768332658

Epoch: 6| Step: 12
Training loss: 1.21560316482978
Validation loss: 2.476305644631101

Epoch: 6| Step: 13
Training loss: 1.1875333781319797
Validation loss: 2.5823449683051303

Epoch: 644| Step: 0
Training loss: 1.3426894504984153
Validation loss: 2.4936675508644752

Epoch: 6| Step: 1
Training loss: 1.1240592838142713
Validation loss: 2.47209160748413

Epoch: 6| Step: 2
Training loss: 1.1194788769479382
Validation loss: 2.430282337948855

Epoch: 6| Step: 3
Training loss: 1.3222141903856814
Validation loss: 2.448073571979512

Epoch: 6| Step: 4
Training loss: 1.2827040167599544
Validation loss: 2.5303951102506628

Epoch: 6| Step: 5
Training loss: 1.4798919439820724
Validation loss: 2.499695408631847

Epoch: 6| Step: 6
Training loss: 1.2532587488958375
Validation loss: 2.5368405225333053

Epoch: 6| Step: 7
Training loss: 1.1489543659952146
Validation loss: 2.425997474310989

Epoch: 6| Step: 8
Training loss: 1.3918468379651903
Validation loss: 2.633950644080839

Epoch: 6| Step: 9
Training loss: 2.2799616271688223
Validation loss: 2.5477870634487765

Epoch: 6| Step: 10
Training loss: 1.1008070932553438
Validation loss: 2.553665041320412

Epoch: 6| Step: 11
Training loss: 1.6732185170625695
Validation loss: 2.4552792282324845

Epoch: 6| Step: 12
Training loss: 0.964586169497534
Validation loss: 2.5573497822671256

Epoch: 6| Step: 13
Training loss: 1.304063796393095
Validation loss: 2.5720898383812942

Epoch: 645| Step: 0
Training loss: 1.224935339174808
Validation loss: 2.4816871385082497

Epoch: 6| Step: 1
Training loss: 1.5757670396685115
Validation loss: 2.4869313970839126

Epoch: 6| Step: 2
Training loss: 1.2601223699245019
Validation loss: 2.4044096287601686

Epoch: 6| Step: 3
Training loss: 1.3320914336001897
Validation loss: 2.5621040612606008

Epoch: 6| Step: 4
Training loss: 1.156421545551459
Validation loss: 2.528009970000449

Epoch: 6| Step: 5
Training loss: 1.2244758107236595
Validation loss: 2.461157893820281

Epoch: 6| Step: 6
Training loss: 1.182160167131063
Validation loss: 2.471848763903458

Epoch: 6| Step: 7
Training loss: 1.511420484192073
Validation loss: 2.5063202823439172

Epoch: 6| Step: 8
Training loss: 1.5184622095534814
Validation loss: 2.5985510423106013

Epoch: 6| Step: 9
Training loss: 1.5960343389521736
Validation loss: 2.545461840766283

Epoch: 6| Step: 10
Training loss: 1.1690376009478094
Validation loss: 2.6720897869120064

Epoch: 6| Step: 11
Training loss: 2.446564375257486
Validation loss: 2.5527885227840965

Epoch: 6| Step: 12
Training loss: 1.2584440174222935
Validation loss: 2.463673081819449

Epoch: 6| Step: 13
Training loss: 1.5033834762556315
Validation loss: 2.56577010333752

Epoch: 646| Step: 0
Training loss: 1.053437007336995
Validation loss: 2.615432434858131

Epoch: 6| Step: 1
Training loss: 1.0967353405847728
Validation loss: 2.439532835064261

Epoch: 6| Step: 2
Training loss: 1.2711487779856991
Validation loss: 2.548320564109205

Epoch: 6| Step: 3
Training loss: 1.2345879769385446
Validation loss: 2.5413052668267953

Epoch: 6| Step: 4
Training loss: 1.5909572891266426
Validation loss: 2.5415368227688706

Epoch: 6| Step: 5
Training loss: 1.1184840115225954
Validation loss: 2.431041827411802

Epoch: 6| Step: 6
Training loss: 0.9832102227059004
Validation loss: 2.5374143490535017

Epoch: 6| Step: 7
Training loss: 1.3645435162430501
Validation loss: 2.5337492791860052

Epoch: 6| Step: 8
Training loss: 1.6144057965857916
Validation loss: 2.5249948468638506

Epoch: 6| Step: 9
Training loss: 2.126695517500734
Validation loss: 2.5345939102169694

Epoch: 6| Step: 10
Training loss: 1.079851288800204
Validation loss: 2.5168544195895284

Epoch: 6| Step: 11
Training loss: 1.6716108737406585
Validation loss: 2.4638232959230875

Epoch: 6| Step: 12
Training loss: 1.0088401109421654
Validation loss: 2.5416160057649897

Epoch: 6| Step: 13
Training loss: 1.2777516591586195
Validation loss: 2.5252922960271316

Epoch: 647| Step: 0
Training loss: 1.2207422845281413
Validation loss: 2.4488116654469474

Epoch: 6| Step: 1
Training loss: 0.9974934635569634
Validation loss: 2.553816560431336

Epoch: 6| Step: 2
Training loss: 1.0421963807146575
Validation loss: 2.5489633225959656

Epoch: 6| Step: 3
Training loss: 1.4923226659781355
Validation loss: 2.4940883410549555

Epoch: 6| Step: 4
Training loss: 1.648286134541024
Validation loss: 2.5101851612426582

Epoch: 6| Step: 5
Training loss: 1.2453100436580082
Validation loss: 2.566926038565789

Epoch: 6| Step: 6
Training loss: 1.1408199509494537
Validation loss: 2.4469841375850416

Epoch: 6| Step: 7
Training loss: 1.261186800565166
Validation loss: 2.5314016981610123

Epoch: 6| Step: 8
Training loss: 1.3836464818537342
Validation loss: 2.5643192879231766

Epoch: 6| Step: 9
Training loss: 0.8290087464840955
Validation loss: 2.6117697824769954

Epoch: 6| Step: 10
Training loss: 1.3406256793538398
Validation loss: 2.549262379307546

Epoch: 6| Step: 11
Training loss: 1.4005724843370804
Validation loss: 2.4249335615340772

Epoch: 6| Step: 12
Training loss: 2.301102983294703
Validation loss: 2.5006599180814097

Epoch: 6| Step: 13
Training loss: 1.1635116195328012
Validation loss: 2.5752754898758967

Epoch: 648| Step: 0
Training loss: 0.9591966693161763
Validation loss: 2.4551520347931937

Epoch: 6| Step: 1
Training loss: 1.219839733728438
Validation loss: 2.521429101491875

Epoch: 6| Step: 2
Training loss: 1.4891868099109065
Validation loss: 2.5322103052368927

Epoch: 6| Step: 3
Training loss: 1.0995167884672512
Validation loss: 2.5477228807390078

Epoch: 6| Step: 4
Training loss: 1.4908047005960283
Validation loss: 2.54877661888438

Epoch: 6| Step: 5
Training loss: 2.133638438619667
Validation loss: 2.425094396020228

Epoch: 6| Step: 6
Training loss: 1.5903835270725089
Validation loss: 2.503232369608828

Epoch: 6| Step: 7
Training loss: 1.0575417784967132
Validation loss: 2.557900432355839

Epoch: 6| Step: 8
Training loss: 1.248695169339093
Validation loss: 2.552997388422042

Epoch: 6| Step: 9
Training loss: 1.2913826609705423
Validation loss: 2.5432677203106384

Epoch: 6| Step: 10
Training loss: 1.241279173985482
Validation loss: 2.474005879504957

Epoch: 6| Step: 11
Training loss: 1.5683880300980086
Validation loss: 2.5323357420278922

Epoch: 6| Step: 12
Training loss: 1.472475885734576
Validation loss: 2.4822757917716256

Epoch: 6| Step: 13
Training loss: 1.5692023153336105
Validation loss: 2.514242144380724

Epoch: 649| Step: 0
Training loss: 0.8614937759236571
Validation loss: 2.453263614778206

Epoch: 6| Step: 1
Training loss: 1.285712912914512
Validation loss: 2.616434983399596

Epoch: 6| Step: 2
Training loss: 1.3524190580929167
Validation loss: 2.4839021832998105

Epoch: 6| Step: 3
Training loss: 1.357612783056893
Validation loss: 2.4728171638306726

Epoch: 6| Step: 4
Training loss: 1.5136077670396075
Validation loss: 2.542896995907569

Epoch: 6| Step: 5
Training loss: 0.996493210822529
Validation loss: 2.550301373998382

Epoch: 6| Step: 6
Training loss: 1.1189943654086396
Validation loss: 2.5598757592651595

Epoch: 6| Step: 7
Training loss: 1.4686949699319356
Validation loss: 2.526277911944678

Epoch: 6| Step: 8
Training loss: 1.2841393990234344
Validation loss: 2.3739892625555266

Epoch: 6| Step: 9
Training loss: 1.1621459955167552
Validation loss: 2.55606570672278

Epoch: 6| Step: 10
Training loss: 1.2284073289161308
Validation loss: 2.359956771337526

Epoch: 6| Step: 11
Training loss: 2.1648371993385305
Validation loss: 2.545946735299822

Epoch: 6| Step: 12
Training loss: 1.7926501155120895
Validation loss: 2.447215012997287

Epoch: 6| Step: 13
Training loss: 1.6257087189068828
Validation loss: 2.5387850591061354

Epoch: 650| Step: 0
Training loss: 1.0456262228913575
Validation loss: 2.4835073976475606

Epoch: 6| Step: 1
Training loss: 1.271770579857522
Validation loss: 2.4664975523519743

Epoch: 6| Step: 2
Training loss: 1.706207286034578
Validation loss: 2.3995514861633946

Epoch: 6| Step: 3
Training loss: 1.2516266252756114
Validation loss: 2.5250537486058184

Epoch: 6| Step: 4
Training loss: 1.2884079167062106
Validation loss: 2.4485317964556335

Epoch: 6| Step: 5
Training loss: 1.2025902785992648
Validation loss: 2.497358076753784

Epoch: 6| Step: 6
Training loss: 1.3834069908402238
Validation loss: 2.5801958464932895

Epoch: 6| Step: 7
Training loss: 1.2584473328813688
Validation loss: 2.5538118313045834

Epoch: 6| Step: 8
Training loss: 2.3686120307620047
Validation loss: 2.5504581202965615

Epoch: 6| Step: 9
Training loss: 1.7781684052276527
Validation loss: 2.57857157399711

Epoch: 6| Step: 10
Training loss: 1.6133484907200133
Validation loss: 2.515526074264535

Epoch: 6| Step: 11
Training loss: 1.4688330281915711
Validation loss: 2.5122659389213213

Epoch: 6| Step: 12
Training loss: 0.982594711844332
Validation loss: 2.5375074447408665

Epoch: 6| Step: 13
Training loss: 0.9155713205583835
Validation loss: 2.516369681331354

Testing loss: 2.904278428031157
